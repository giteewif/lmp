here pin
INFO 01-07 10:09:08.100524.100524 pinpool.py:28] Initializing PinnedMemoryPool with 2GB total, allocating in 1024MB chunks...
DEBUG 01-07 10:09:08.946213.946213 pinpool.py:40] Allocated chunk 1: 536870912 elements (1024.0 MB)
DEBUG 01-07 10:09:09.393197.393197 pinpool.py:40] Allocated chunk 2: 536870912 elements (1024.0 MB)
INFO 01-07 10:09:09.394097.394097 pinpool.py:52] Successfully allocated 2 chunks, total 1073741824 elements (2048.0 MB) in 1.294s
DEBUG 01-07 10:09:10.794501.794501 cuda_memory_view.py:388] 
DEBUG 01-07 10:09:10.794501.794501 cuda_memory_view.py:388] restore_tensors_from_shared_memory_names time: 0.014835834503173828
DEBUG 01-07 10:09:13.526683.526683 cuda_h.py:10] start generate_input_ids
generate input ids cost 13.01975393295288 s
DEBUG 01-07 10:09:39.516689.516689 cuda_h.py:19] end generate_input_ids cost 25.989622354507446 seconds
DEBUG 01-07 10:09:39.516908.516908 cuda_h.py:10] start init_cache
DEBUG 01-07 10:09:39.517040.517040 cuda_h.py:19] end init_cache cost 0.00012183189392089844 seconds
DEBUG 01-07 10:09:42.024632.024632 cuda_h.py:10] start init_weights
DEBUG 01-07 10:09:42.025393.025393 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 10:09:42.025315.025315 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 10:09:42.025664.025664 cuda_h.py:19] end allocate_cuda_memory cost 0.0004913806915283203 seconds
DEBUG 01-07 10:09:42.025025.025025 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 10:09:42.025464.025464 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 10:09:42.025876.025876 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 10:09:42.025871.025871 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 2e4530c6-cc8b-456b-a65c-3318d09aec05
DEBUG 01-07 10:09:42.025987.025987 client.py:106] call stub.LoadModelAsync
INFO 01-07 10:09:42.027656.027656 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 2e4530c6-cc8b-456b-a65c-3318d09aec05
DEBUG 01-07 10:09:42.027175.027175 cuda_h.py:19] end load_into_gpu_async cost 0.001478433609008789 seconds
DEBUG 01-07 10:09:42.027593.027593 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 10:09:42.027942.027942 cuda_h.py:19] end restore_tensors2 cost 8.559226989746094e-05 seconds
DEBUG 01-07 10:09:42.027029.027029 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0023331642150878906 seconds
INFO 01-07 10:09:42.027460.027460 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 2e4530c6-cc8b-456b-a65c-3318d09aec05
INFO 01-07 10:13:56.336563.336563 client.py:127] Model loaded
DEBUG 01-07 10:13:56.336866.336866 cuda_h.py:10] start load_qkvogns_weight_l_0
DEBUG 01-07 10:13:56.337564.337564 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 10:13:56.337735.337735 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 10:13:56.338076.338076 cuda_h.py:19] end allocate_cuda_memory cost 0.0009295940399169922 seconds
DEBUG 01-07 10:13:56.338990.338990 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 10:13:56.338894.338894 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 10:13:56.339735.339735 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 10:13:56.339089.339089 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 5016b36b-e77c-4fe9-aa69-69c9041a9460
DEBUG 01-07 10:13:56.339078.339078 client.py:106] call stub.LoadModelAsync
INFO 01-07 10:13:56.341586.341586 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 5016b36b-e77c-4fe9-aa69-69c9041a9460
DEBUG 01-07 10:13:56.341426.341426 cuda_h.py:19] end load_into_gpu_async cost 0.002640247344970703 seconds
DEBUG 01-07 10:13:56.341535.341535 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 10:13:56.342034.342034 cuda_h.py:19] end restore_tensors2 cost 0.0005576610565185547 seconds
DEBUG 01-07 10:13:56.342389.342389 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.004938840866088867 seconds
INFO 01-07 10:13:56.342305.342305 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 5016b36b-e77c-4fe9-aa69-69c9041a9460
INFO 01-07 10:13:56.365906.365906 client.py:127] Model loaded
DEBUG 01-07 10:13:56.367600.367600 cuda_h.py:19] end load_qkvogns_weight_l_0 cost 0.030495166778564453 seconds
DEBUG 01-07 10:13:56.367704.367704 cuda_h.py:19] end init_weights cost 254.3427529335022 seconds
DEBUG 01-07 10:13:56.367257.367257 cuda_h.py:10] start copy_emodel
DEBUG 01-07 10:13:57.275171.275171 cuda_h.py:19] end copy_emodel cost 0.9077332019805908 seconds
DEBUG 01-07 10:13:57.276495.276495 cuda_h.py:10] start init_hmv
DEBUG 01-07 10:13:57.415952.415952 mlpmodule.py:207] restore_hm_state_dict2model loaded 5265 expert tensors (including shared_experts) for Deepseek model
DEBUG 01-07 10:13:57.416258.416258 cuda_h.py:19] end init_hmv cost 0.13962721824645996 seconds
DEBUG 01-07 10:13:57.416756.416756 cuda_h.py:10] start init_inputs_tokens
DEBUG 01-07 10:13:57.498735.498735 cuda_h.py:19] end init_inputs_tokens cost 0.08218932151794434 seconds
DEBUG 01-07 10:13:57.498613.498613 cuda_h.py:10] start prefill_layer
DEBUG 01-07 10:13:57.498635.498635 lmp.py:153] -------------------------------- start prefill layer 0 --------------------------------
DEBUG 01-07 10:13:57.498046.498046 cuda_h.py:10] start start_load_qkvogn_s_weight_l_1
DEBUG 01-07 10:13:57.498578.498578 cuda_h.py:10] start start_load_qkvogn_s_weight_l_1
DEBUG 01-07 10:13:57.498189.498189 cuda_h.py:19] end start_load_qkvogn_s_weight_l_1 cost 3.790855407714844e-05 seconds
DEBUG 01-07 10:13:57.498322.498322 cuda_h.py:19] end start_load_qkvogn_s_weight_l_1 cost 6.961822509765625e-05 seconds
DEBUG 01-07 10:13:57.498588.498588 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-07 10:13:57.498863.498863 mlpmodule.py:367] cuda:1 cuda:1
DEBUG 01-07 10:13:57.498939.498939 cuda_h.py:10] start sllm_worker_task
DEBUG 01-07 10:13:57.499657.499657 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 10:13:57.499852.499852 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 10:13:57.499385.499385 cuda_h.py:19] end allocate_cuda_memory cost 0.0002429485321044922 seconds
DEBUG 01-07 10:13:57.499255.499255 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 10:13:57.499217.499217 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 10:13:57.499053.499053 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 10:13:57.499624.499624 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 29503639-0788-460f-8bde-5882b7745d3d
DEBUG 01-07 10:13:57.499097.499097 client.py:106] call stub.LoadModelAsync
INFO 01-07 10:13:57.501924.501924 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 29503639-0788-460f-8bde-5882b7745d3d
DEBUG 01-07 10:13:57.501058.501058 cuda_h.py:19] end load_into_gpu_async cost 0.001603841781616211 seconds
DEBUG 01-07 10:13:57.501437.501437 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 10:13:57.501368.501368 cuda_h.py:19] end restore_tensors2 cost 8.96453857421875e-05 seconds
DEBUG 01-07 10:13:57.501992.501992 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.002241373062133789 seconds
INFO 01-07 10:13:57.501331.501331 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 29503639-0788-460f-8bde-5882b7745d3d
INFO 01-07 10:13:57.509652.509652 client.py:127] Model loaded
DEBUG 01-07 10:13:57.509371.509371 cuda_h.py:19] end sllm_worker_task cost 0.01081705093383789 seconds
DEBUG 01-07 10:13:57.589666.589666 cuda_h.py:10] start self_attn
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-07 10:13:57.838589.838589 cuda_h.py:19] end self_attn cost 0.24933075904846191 seconds
DEBUG 01-07 10:13:57.839929.839929 cuda_h.py:19] end iln_self_attn_paln cost 0.3404526710510254 seconds
DEBUG 01-07 10:13:57.839455.839455 cuda_h.py:10] start dense_mlp
DEBUG 01-07 10:13:57.845106.845106 cuda_h.py:19] end dense_mlp cost 0.0065495967864990234 seconds
DEBUG 01-07 10:13:57.846355.846355 lmp.py:194] -------------------------------- end prefill layer 0 --------------------------------
DEBUG 01-07 10:13:57.846833.846833 lmp.py:153] -------------------------------- start prefill layer 1 --------------------------------
DEBUG 01-07 10:13:57.846244.846244 cuda_h.py:10] start start_load_qkvogn_s_weight_l_2
DEBUG 01-07 10:13:57.846544.846544 cuda_h.py:10] start start_load_qkvogn_s_weight_l_2
DEBUG 01-07 10:13:57.846479.846479 cuda_h.py:19] end start_load_qkvogn_s_weight_l_2 cost 2.956390380859375e-05 seconds
DEBUG 01-07 10:13:57.846633.846633 cuda_h.py:19] end start_load_qkvogn_s_weight_l_2 cost 7.653236389160156e-05 seconds
DEBUG 01-07 10:13:57.846183.846183 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-07 10:13:57.846583.846583 cuda_h.py:10] start sllm_worker_task
DEBUG 01-07 10:13:57.846179.846179 mlpmodule.py:367] cuda:1 cuda:1
DEBUG 01-07 10:13:57.846659.846659 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 10:13:57.846163.846163 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 10:13:57.847157.847157 cuda_h.py:19] end allocate_cuda_memory cost 0.0002970695495605469 seconds
DEBUG 01-07 10:13:57.847798.847798 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 10:13:57.847623.847623 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 10:13:57.847681.847681 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 10:13:57.847916.847916 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 0b27df8b-70eb-4d9d-8b29-46e56e98276d
DEBUG 01-07 10:13:57.848354.848354 client.py:106] call stub.LoadModelAsync
DEBUG 01-07 10:13:57.848761.848761 cuda_h.py:10] start self_attn
INFO 01-07 10:13:57.849784.849784 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 0b27df8b-70eb-4d9d-8b29-46e56e98276d
DEBUG 01-07 10:13:57.850273.850273 cuda_h.py:19] end load_into_gpu_async cost 0.002584218978881836 seconds
DEBUG 01-07 10:13:57.850349.850349 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 10:13:57.850191.850191 cuda_h.py:19] end restore_tensors2 cost 0.00014281272888183594 seconds
DEBUG 01-07 10:13:57.850757.850757 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.003748178482055664 seconds
INFO 01-07 10:13:57.850114.850114 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 0b27df8b-70eb-4d9d-8b29-46e56e98276d
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-07 10:13:57.851970.851970 cuda_h.py:19] end self_attn cost 0.0034329891204833984 seconds
DEBUG 01-07 10:13:57.852482.852482 cuda_h.py:19] end iln_self_attn_paln cost 0.005738735198974609 seconds
DEBUG 01-07 10:13:57.852603.852603 cuda_h.py:10] start layer_moe_generate_multi_device_1
DEBUG 01-07 10:13:57.852413.852413 cuda_h.py:10] start gate
INFO 01-07 10:13:57.857839.857839 client.py:127] Model loaded
DEBUG 01-07 10:13:57.858294.858294 cuda_h.py:19] end sllm_worker_task cost 0.011851072311401367 seconds
DEBUG 01-07 10:13:57.949081.949081 cuda_h.py:19] end gate cost 0.0976109504699707 seconds
DEBUG 01-07 10:13:57.949959.949959 cuda_h.py:10] start experts_map_get
DEBUG 01-07 10:13:57.950197.950197 lmp.py:744] 
DEBUG 01-07 10:13:57.950197.950197 lmp.py:744] Expert Token Distribution & Multi-Device Allocation:
DEBUG 01-07 10:13:57.950159.950159 lmp.py:745]   Total experts: 64
DEBUG 01-07 10:13:57.950690.950690 lmp.py:746]   CPU experts: 19 (30%)
DEBUG 01-07 10:13:57.950717.950717 lmp.py:747]   GPU experts: 45 (70%)
DEBUG 01-07 10:13:57.950075.950075 lmp.py:748]   Number of GPU devices: 2
DEBUG 01-07 10:13:57.950241.950241 lmp.py:749] 
DEBUG 01-07 10:13:57.950241.950241 lmp.py:749]   Expert ID | Tokens | Device
DEBUG 01-07 10:13:57.950646.950646 lmp.py:750]   -----------------------------------
DEBUG 01-07 10:13:57.950726.950726 lmp.py:767]   Expert 25 |     64 | CPU
DEBUG 01-07 10:13:57.950608.950608 lmp.py:767]   Expert 54 |     67 | CPU
DEBUG 01-07 10:13:57.950012.950012 lmp.py:767]   Expert  3 |     68 | CPU
DEBUG 01-07 10:13:57.950417.950417 lmp.py:767]   Expert 31 |     72 | CPU
DEBUG 01-07 10:13:57.950344.950344 lmp.py:767]   Expert 55 |     72 | CPU
DEBUG 01-07 10:13:57.950034.950034 lmp.py:767]   Expert 62 |     87 | CPU
DEBUG 01-07 10:13:57.950200.950200 lmp.py:767]   Expert 18 |     88 | CPU
DEBUG 01-07 10:13:57.950128.950128 lmp.py:767]   Expert 52 |     98 | CPU
DEBUG 01-07 10:13:57.950294.950294 lmp.py:767]   Expert 22 |    100 | CPU
DEBUG 01-07 10:13:57.950221.950221 lmp.py:767]   Expert 47 |    104 | CPU
DEBUG 01-07 10:13:57.950149.950149 lmp.py:767]   Expert  0 |    113 | CPU
DEBUG 01-07 10:13:57.950746.950746 lmp.py:767]   Expert 37 |    117 | CPU
DEBUG 01-07 10:13:57.950150.950150 lmp.py:767]   Expert 27 |    121 | CPU
DEBUG 01-07 10:13:57.950840.950840 lmp.py:767]   Expert 32 |    123 | CPU
DEBUG 01-07 10:13:57.950529.950529 lmp.py:767]   Expert 41 |    130 | CPU
DEBUG 01-07 10:13:57.950218.950218 lmp.py:767]   Expert 44 |    131 | CPU
DEBUG 01-07 10:13:57.950669.950669 lmp.py:767]   Expert 28 |    136 | CPU
DEBUG 01-07 10:13:57.950597.950597 lmp.py:767]   Expert 13 |    138 | CPU
DEBUG 01-07 10:13:57.950286.950286 lmp.py:767]   Expert 58 |    140 | CPU
DEBUG 01-07 10:13:57.950406.950406 lmp.py:767]   Expert 60 |    144 | GPU0(cuda:1)
DEBUG 01-07 10:13:57.950764.950764 lmp.py:767]   Expert 43 |    147 | GPU1(cuda:2)
DEBUG 01-07 10:13:57.950169.950169 lmp.py:767]   Expert  1 |    150 | GPU0(cuda:1)
DEBUG 01-07 10:13:57.950289.950289 lmp.py:767]   Expert 38 |    153 | GPU1(cuda:2)
DEBUG 01-07 10:13:57.950693.950693 lmp.py:767]   Expert 49 |    154 | GPU0(cuda:1)
DEBUG 01-07 10:13:57.950098.950098 lmp.py:767]   Expert 51 |    155 | GPU0(cuda:1)
DEBUG 01-07 10:13:57.950933.950933 lmp.py:767]   Expert 34 |    161 | GPU1(cuda:2)
DEBUG 01-07 10:13:57.950768.950768 lmp.py:767]   Expert 35 |    164 | GPU0(cuda:1)
DEBUG 01-07 10:13:57.950364.950364 lmp.py:767]   Expert 36 |    168 | GPU1(cuda:2)
DEBUG 01-07 10:13:57.950007.950007 lmp.py:767]   Expert 11 |    170 | GPU1(cuda:2)
DEBUG 01-07 10:13:57.951650.951650 lmp.py:767]   Expert 17 |    170 | GPU0(cuda:1)
DEBUG 01-07 10:13:57.951055.951055 lmp.py:767]   Expert 59 |    174 | GPU1(cuda:2)
DEBUG 01-07 10:13:57.951698.951698 lmp.py:767]   Expert 10 |    180 | GPU0(cuda:1)
DEBUG 01-07 10:13:57.951864.951864 lmp.py:767]   Expert 20 |    182 | GPU0(cuda:1)
DEBUG 01-07 10:13:57.951269.951269 lmp.py:767]   Expert  2 |    186 | GPU1(cuda:2)
DEBUG 01-07 10:13:57.951912.951912 lmp.py:767]   Expert 39 |    189 | GPU0(cuda:1)
DEBUG 01-07 10:13:57.951316.951316 lmp.py:767]   Expert 33 |    197 | GPU1(cuda:2)
DEBUG 01-07 10:13:57.951482.951482 lmp.py:767]   Expert 12 |    198 | GPU0(cuda:1)
DEBUG 01-07 10:13:57.951887.951887 lmp.py:767]   Expert 21 |    198 | GPU1(cuda:2)
DEBUG 01-07 10:13:57.951053.951053 lmp.py:767]   Expert 48 |    198 | GPU0(cuda:1)
DEBUG 01-07 10:13:57.951458.951458 lmp.py:767]   Expert 15 |    199 | GPU1(cuda:2)
DEBUG 01-07 10:13:57.951624.951624 lmp.py:767]   Expert 53 |    204 | GPU1(cuda:2)
DEBUG 01-07 10:13:57.951790.951790 lmp.py:767]   Expert 19 |    220 | GPU0(cuda:1)
DEBUG 01-07 10:13:57.951433.951433 lmp.py:767]   Expert 26 |    221 | GPU0(cuda:1)
DEBUG 01-07 10:13:57.951599.951599 lmp.py:767]   Expert 30 |    221 | GPU0(cuda:1)
DEBUG 01-07 10:13:57.951765.951765 lmp.py:767]   Expert 45 |    221 | GPU1(cuda:2)
DEBUG 01-07 10:13:57.951170.951170 lmp.py:767]   Expert  5 |    227 | GPU1(cuda:2)
DEBUG 01-07 10:13:57.951866.951866 lmp.py:767]   Expert  4 |    229 | GPU1(cuda:2)
DEBUG 01-07 10:13:57.951608.951608 lmp.py:767]   Expert 24 |    229 | GPU0(cuda:1)
DEBUG 01-07 10:13:57.951443.951443 lmp.py:767]   Expert 42 |    242 | GPU1(cuda:2)
DEBUG 01-07 10:13:57.951086.951086 lmp.py:767]   Expert 50 |    245 | GPU0(cuda:1)
DEBUG 01-07 10:13:57.951729.951729 lmp.py:767]   Expert 29 |    254 | GPU0(cuda:1)
DEBUG 01-07 10:13:57.951326.951326 lmp.py:767]   Expert 56 |    262 | GPU1(cuda:2)
DEBUG 01-07 10:13:57.951730.951730 lmp.py:767]   Expert 61 |    270 | GPU0(cuda:1)
DEBUG 01-07 10:13:57.951804.951804 lmp.py:767]   Expert  8 |    283 | GPU1(cuda:2)
DEBUG 01-07 10:13:57.951500.951500 lmp.py:767]   Expert 63 |    285 | GPU0(cuda:1)
DEBUG 01-07 10:13:57.951381.951381 lmp.py:767]   Expert 46 |    294 | GPU1(cuda:2)
DEBUG 01-07 10:13:57.951547.951547 lmp.py:767]   Expert  9 |    300 | GPU0(cuda:1)
DEBUG 01-07 10:13:57.951714.951714 lmp.py:767]   Expert  6 |    316 | GPU0(cuda:1)
DEBUG 01-07 10:13:57.951880.951880 lmp.py:767]   Expert 16 |    316 | GPU1(cuda:2)
DEBUG 01-07 10:13:57.951284.951284 lmp.py:767]   Expert 40 |    319 | GPU1(cuda:2)
DEBUG 01-07 10:13:57.951450.951450 lmp.py:767]   Expert  7 |    322 | GPU0(cuda:1)
DEBUG 01-07 10:13:57.951617.951617 lmp.py:767]   Expert 23 |    325 | GPU1(cuda:2)
DEBUG 01-07 10:13:57.951783.951783 lmp.py:767]   Expert 14 |    413 | GPU1(cuda:2)
DEBUG 01-07 10:13:57.951187.951187 lmp.py:767]   Expert 57 |    464 | GPU0(cuda:1)
DEBUG 01-07 10:13:57.951638.951638 lmp.py:769] 
DEBUG 01-07 10:13:57.951638.951638 lmp.py:769]   Device Token Distribution:
DEBUG 01-07 10:13:57.951566.951566 lmp.py:770]   CPU:   1969 tokens
DEBUG 01-07 10:13:57.951447.951447 lmp.py:774]   cuda:1:   5231 tokens (23 experts)
DEBUG 01-07 10:13:57.951044.951044 lmp.py:774]   cuda:2:   5088 tokens (22 experts)
DEBUG 01-07 10:13:57.951786.951786 lmp.py:775]   Total GPU:  10319 tokens
DEBUG 01-07 10:13:57.951668.951668 lmp.py:776] ============================================================
DEBUG 01-07 10:13:57.951668.951668 lmp.py:776] 
DEBUG 01-07 10:13:57.951986.951986 cuda_h.py:19] end experts_map_get cost 0.0017812252044677734 seconds
DEBUG 01-07 10:13:57.951583.951583 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model_multi_device
DEBUG 01-07 10:13:57.951075.951075 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 10:13:57.953814.953814 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 10:13:57.954960.954960 cuda_h.py:19] end allocate_cuda_memory cost 0.0003058910369873047 seconds
DEBUG 01-07 10:13:57.954538.954538 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 10:13:57.954155.954155 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 10:13:57.954024.954024 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 10:13:57.954058.954058 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, d6f9f565-2979-4899-b858-8c508b274ba7
DEBUG 01-07 10:13:57.954667.954667 client.py:106] call stub.LoadModelAsync
INFO 01-07 10:13:57.956383.956383 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, d6f9f565-2979-4899-b858-8c508b274ba7
DEBUG 01-07 10:13:57.956517.956517 cuda_h.py:19] end load_into_gpu_async cost 0.0023012161254882812 seconds
DEBUG 01-07 10:13:57.956743.956743 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 10:13:57.956533.956533 cuda_h.py:19] end restore_tensors2 cost 0.00020623207092285156 seconds
DEBUG 01-07 10:13:57.956203.956203 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.004984855651855469 seconds
DEBUG 01-07 10:13:57.958295.958295 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 10:13:57.958027.958027 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 10:13:58.105512.105512 cuda_h.py:19] end allocate_cuda_memory cost 0.1463027000427246 seconds
DEBUG 01-07 10:13:58.105255.105255 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 10:13:58.105237.105237 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 10:13:58.105749.105749 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 10:13:58.105988.105988 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, d18b3d8b-f532-4ab7-83dd-1f16a6e98952
DEBUG 01-07 10:13:58.105797.105797 client.py:106] call stub.LoadModelAsync
INFO 01-07 10:13:58.107236.107236 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, d18b3d8b-f532-4ab7-83dd-1f16a6e98952
DEBUG 01-07 10:13:58.108782.108782 cuda_h.py:19] end load_into_gpu_async cost 0.0024428367614746094 seconds
DEBUG 01-07 10:13:58.108075.108075 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 10:13:58.108092.108092 cuda_h.py:19] end restore_tensors2 cost 0.0002849102020263672 seconds
DEBUG 01-07 10:13:58.108783.108783 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.14960026741027832 seconds
DEBUG 01-07 10:13:58.111305.111305 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model_multi_device cost 0.1593799591064453 seconds
DEBUG 01-07 10:13:58.111566.111566 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-07 10:13:58.125730.125730 lmp.py:816] 
DEBUG 01-07 10:13:58.125730.125730 lmp.py:816]   Computing 19 experts on CPU...
DEBUG 01-07 10:13:58.125846.125846 cuda_h.py:19] end cpu_experts_submit cost 0.013851642608642578 seconds
DEBUG 01-07 10:13:58.125125.125125 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-07 10:13:58.138486.138486 mlpmodule.py:749] group tensors cost 0.012946605682373047 s
DEBUG 01-07 10:13:58.140188.140188 mlpmodule.py:787] pad cost 0.0015289783477783203 s
DEBUG 01-07 10:13:58.141550.141550 mlpmodule.py:793] create cpu tensor cost 5.841255187988281e-05 s
DEBUG 01-07 10:13:58.141433.141433 mlpmodule.py:798] move to cpu cost 4.3392181396484375e-05 s
DEBUG 01-07 10:13:58.176157.176157 mlpmodule.py:812] group_w3: shape=torch.Size([19, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=54788096
DEBUG 01-07 10:13:58.176668.176668 mlpmodule.py:813] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-07 10:13:58.183998.183998 mlpmodule.py:818] group_w3 first element: -0.0107421875
WARNING 01-07 10:13:58.183404.183404 mlpmodule.py:828] start einsum2
DEBUG 01-07 10:13:58.204090.204090 mlpmodule.py:838] group einsum cost 0.06302356719970703 s
DEBUG 01-07 10:13:58.204833.204833 mlpmodule.py:846] cpy2cputensor cost 0.00037097930908203125 s
DEBUG 01-07 10:13:58.210813.210813 cuda_h.py:19] end wait_cetm_experts cost 0.08476591110229492 seconds
DEBUG 01-07 10:13:58.210054.210054 cuda_h.py:10] start gpu_sexperts
DEBUG 01-07 10:13:58.210135.210135 cuda_h.py:19] end gpu_sexperts cost 0.0006103515625 seconds
DEBUG 01-07 10:13:58.210522.210522 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-07 10:13:58.210577.210577 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 3.0040740966796875e-05 seconds
DEBUG 01-07 10:13:58.210532.210532 cuda_h.py:10] start wait_experts_multi_device
INFO 01-07 10:13:58.210110.210110 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, d6f9f565-2979-4899-b858-8c508b274ba7
INFO 01-07 10:13:58.211441.211441 client.py:127] Model loaded
INFO 01-07 10:13:58.212390.212390 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, d18b3d8b-f532-4ab7-83dd-1f16a6e98952
INFO 01-07 10:13:58.212545.212545 client.py:127] Model loaded
DEBUG 01-07 10:13:58.212832.212832 cuda_h.py:19] end wait_experts_multi_device cost 0.0017969608306884766 seconds
DEBUG 01-07 10:13:58.212780.212780 cuda_h.py:10] start gpu_experts_multi_device
DEBUG 01-07 10:13:58.212987.212987 lmp.py:867]   Computing 22 experts on cuda:2...
DEBUG 01-07 10:13:58.218739.218739 mlpmodule.py:707]  experts func einsum cost 0.0931704044342041 s
DEBUG 01-07 10:13:58.232430.232430 mlpmodule.py:533] gpu group tensors cost 0.002478361129760742 s
DEBUG 01-07 10:13:58.243120.243120 mlpmodule.py:566] gpu pad cost 0.011047840118408203 s
DEBUG 01-07 10:13:58.300664.300664 mlpmodule.py:584] gpu group einsum cost 0.05731320381164551 s
DEBUG 01-07 10:13:58.304114.304114 mlpmodule.py:656] gpu experts func einsum cost 0.07492828369140625 s
DEBUG 01-07 10:13:58.304159.304159 lmp.py:867]   Computing 23 experts on cuda:1...
DEBUG 01-07 10:13:58.306973.306973 mlpmodule.py:533] gpu group tensors cost 0.0008513927459716797 s
DEBUG 01-07 10:13:58.307943.307943 mlpmodule.py:566] gpu pad cost 0.0010421276092529297 s
DEBUG 01-07 10:13:58.308620.308620 mlpmodule.py:584] gpu group einsum cost 0.0007493495941162109 s
DEBUG 01-07 10:13:58.309477.309477 mlpmodule.py:656] gpu experts func einsum cost 0.004456043243408203 s
DEBUG 01-07 10:13:58.309884.309884 cuda_h.py:19] end gpu_experts_multi_device cost 0.09702658653259277 seconds
DEBUG 01-07 10:13:58.309278.309278 cuda_h.py:19] end layer_moe_generate_multi_device_1 cost 0.45780467987060547 seconds
DEBUG 01-07 10:13:58.310184.310184 lmp.py:194] -------------------------------- end prefill layer 1 --------------------------------
DEBUG 01-07 10:13:58.310047.310047 lmp.py:153] -------------------------------- start prefill layer 2 --------------------------------
DEBUG 01-07 10:13:58.310789.310789 cuda_h.py:10] start start_load_qkvogn_s_weight_l_3
DEBUG 01-07 10:13:58.310049.310049 cuda_h.py:10] start start_load_qkvogn_s_weight_l_3
DEBUG 01-07 10:13:58.310938.310938 cuda_h.py:19] end start_load_qkvogn_s_weight_l_3 cost 3.24249267578125e-05 seconds
DEBUG 01-07 10:13:58.310900.310900 cuda_h.py:19] end start_load_qkvogn_s_weight_l_3 cost 7.772445678710938e-05 seconds
DEBUG 01-07 10:13:58.310973.310973 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-07 10:13:58.310439.310439 mlpmodule.py:367] cuda:1 cuda:1
DEBUG 01-07 10:13:58.310018.310018 cuda_h.py:10] start sllm_worker_task
DEBUG 01-07 10:13:58.310392.310392 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 10:13:58.310196.310196 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 10:13:58.310065.310065 cuda_h.py:19] end allocate_cuda_memory cost 0.000209808349609375 seconds
DEBUG 01-07 10:13:58.310565.310565 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 10:13:58.311718.311718 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 10:13:58.311661.311661 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 10:13:58.311755.311755 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 5286488c-a5a7-4335-a225-b04e88a580db
DEBUG 01-07 10:13:58.311129.311129 client.py:106] call stub.LoadModelAsync
DEBUG 01-07 10:13:58.311734.311734 cuda_h.py:10] start self_attn
INFO 01-07 10:13:58.312102.312102 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 5286488c-a5a7-4335-a225-b04e88a580db
DEBUG 01-07 10:13:58.312483.312483 cuda_h.py:19] end load_into_gpu_async cost 0.0014715194702148438 seconds
DEBUG 01-07 10:13:58.312452.312452 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 10:13:58.312880.312880 cuda_h.py:19] end restore_tensors2 cost 9.274482727050781e-05 seconds
DEBUG 01-07 10:13:58.312332.312332 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.002121448516845703 seconds
INFO 01-07 10:13:58.312010.312010 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 5286488c-a5a7-4335-a225-b04e88a580db
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-07 10:13:58.314253.314253 cuda_h.py:19] end self_attn cost 0.003162384033203125 seconds
DEBUG 01-07 10:13:58.315429.315429 cuda_h.py:19] end iln_self_attn_paln cost 0.004658222198486328 seconds
DEBUG 01-07 10:13:58.315066.315066 cuda_h.py:10] start layer_moe_generate_multi_device_2
DEBUG 01-07 10:13:58.315921.315921 cuda_h.py:10] start gate
DEBUG 01-07 10:13:58.315666.315666 cuda_h.py:19] end gate cost 0.0006518363952636719 seconds
DEBUG 01-07 10:13:58.315734.315734 cuda_h.py:10] start experts_map_get
DEBUG 01-07 10:13:58.316218.316218 lmp.py:744] 
DEBUG 01-07 10:13:58.316218.316218 lmp.py:744] Expert Token Distribution & Multi-Device Allocation:
DEBUG 01-07 10:13:58.316649.316649 lmp.py:745]   Total experts: 64
DEBUG 01-07 10:13:58.316445.316445 lmp.py:746]   CPU experts: 19 (30%)
DEBUG 01-07 10:13:58.316664.316664 lmp.py:747]   GPU experts: 45 (70%)
DEBUG 01-07 10:13:58.316784.316784 lmp.py:748]   Number of GPU devices: 2
DEBUG 01-07 10:13:58.316712.316712 lmp.py:749] 
DEBUG 01-07 10:13:58.316712.316712 lmp.py:749]   Expert ID | Tokens | Device
DEBUG 01-07 10:13:58.316593.316593 lmp.py:750]   -----------------------------------
DEBUG 01-07 10:13:58.316164.316164 lmp.py:767]   Expert 58 |     50 | CPU
DEBUG 01-07 10:13:58.316522.316522 lmp.py:767]   Expert 27 |     56 | CPU
DEBUG 01-07 10:13:58.316642.316642 lmp.py:767]   Expert  3 |     68 | CPU
DEBUG 01-07 10:13:58.316046.316046 lmp.py:767]   Expert 17 |     84 | CPU
DEBUG 01-07 10:13:58.316451.316451 lmp.py:767]   Expert 24 |     86 | CPU
DEBUG 01-07 10:13:58.316855.316855 lmp.py:767]   Expert  0 |     88 | CPU
DEBUG 01-07 10:13:58.316498.316498 lmp.py:767]   Expert 28 |    105 | CPU
DEBUG 01-07 10:13:58.316141.316141 lmp.py:767]   Expert 34 |    116 | CPU
DEBUG 01-07 10:13:58.316546.316546 lmp.py:767]   Expert 51 |    118 | CPU
DEBUG 01-07 10:13:58.316427.316427 lmp.py:767]   Expert 32 |    120 | CPU
DEBUG 01-07 10:13:58.316355.316355 lmp.py:767]   Expert  9 |    130 | CPU
DEBUG 01-07 10:13:58.316283.316283 lmp.py:767]   Expert 15 |    134 | CPU
DEBUG 01-07 10:13:58.316210.316210 lmp.py:767]   Expert  7 |    135 | CPU
DEBUG 01-07 10:13:58.316900.316900 lmp.py:767]   Expert 23 |    136 | CPU
DEBUG 01-07 10:13:58.316589.316589 lmp.py:767]   Expert 26 |    138 | CPU
DEBUG 01-07 10:13:58.316278.316278 lmp.py:767]   Expert 30 |    144 | CPU
DEBUG 01-07 10:13:58.316206.316206 lmp.py:767]   Expert 45 |    146 | CPU
DEBUG 01-07 10:13:58.316895.316895 lmp.py:767]   Expert 62 |    147 | CPU
DEBUG 01-07 10:13:58.316346.316346 lmp.py:767]   Expert 57 |    150 | CPU
DEBUG 01-07 10:13:58.316943.316943 lmp.py:767]   Expert  1 |    152 | GPU1(cuda:2)
DEBUG 01-07 10:13:58.316778.316778 lmp.py:767]   Expert 36 |    155 | GPU1(cuda:2)
DEBUG 01-07 10:13:58.316613.316613 lmp.py:767]   Expert  8 |    158 | GPU0(cuda:1)
DEBUG 01-07 10:13:58.316733.316733 lmp.py:767]   Expert 29 |    161 | GPU0(cuda:1)
DEBUG 01-07 10:13:58.316091.316091 lmp.py:767]   Expert 25 |    164 | GPU1(cuda:2)
DEBUG 01-07 10:13:58.316449.316449 lmp.py:767]   Expert 54 |    169 | GPU0(cuda:1)
DEBUG 01-07 10:13:58.316807.316807 lmp.py:767]   Expert  6 |    170 | GPU0(cuda:1)
DEBUG 01-07 10:13:58.316450.316450 lmp.py:767]   Expert 49 |    170 | GPU1(cuda:2)
DEBUG 01-07 10:13:58.316093.316093 lmp.py:767]   Expert 48 |    172 | GPU1(cuda:2)
DEBUG 01-07 10:13:58.316736.316736 lmp.py:767]   Expert 12 |    175 | GPU0(cuda:1)
DEBUG 01-07 10:13:58.316379.316379 lmp.py:767]   Expert 35 |    176 | GPU1(cuda:2)
DEBUG 01-07 10:13:58.316022.316022 lmp.py:767]   Expert 37 |    177 | GPU1(cuda:2)
DEBUG 01-07 10:13:58.316189.316189 lmp.py:767]   Expert 60 |    186 | GPU0(cuda:1)
DEBUG 01-07 10:13:58.316355.316355 lmp.py:767]   Expert 13 |    188 | GPU1(cuda:2)
DEBUG 01-07 10:13:58.316521.316521 lmp.py:767]   Expert 53 |    189 | GPU0(cuda:1)
DEBUG 01-07 10:13:58.317402.317402 lmp.py:767]   Expert 33 |    190 | GPU0(cuda:1)
DEBUG 01-07 10:13:58.317284.317284 lmp.py:767]   Expert 10 |    195 | GPU1(cuda:2)
DEBUG 01-07 10:13:58.317072.317072 lmp.py:767]   Expert 16 |    195 | GPU1(cuda:2)
DEBUG 01-07 10:13:58.317954.317954 lmp.py:767]   Expert 21 |    198 | GPU0(cuda:1)
DEBUG 01-07 10:13:58.317358.317358 lmp.py:767]   Expert 40 |    200 | GPU0(cuda:1)
DEBUG 01-07 10:13:58.317524.317524 lmp.py:767]   Expert 43 |    202 | GPU1(cuda:2)
DEBUG 01-07 10:13:58.317929.317929 lmp.py:767]   Expert 38 |    205 | GPU1(cuda:2)
DEBUG 01-07 10:13:58.317095.317095 lmp.py:767]   Expert  5 |    208 | GPU0(cuda:1)
DEBUG 01-07 10:13:58.317500.317500 lmp.py:767]   Expert 44 |    216 | GPU0(cuda:1)
DEBUG 01-07 10:13:58.317666.317666 lmp.py:767]   Expert 52 |    216 | GPU1(cuda:2)
DEBUG 01-07 10:13:58.317070.317070 lmp.py:767]   Expert 41 |    217 | GPU0(cuda:1)
DEBUG 01-07 10:13:58.317236.317236 lmp.py:767]   Expert 50 |    217 | GPU1(cuda:2)
DEBUG 01-07 10:13:58.317641.317641 lmp.py:767]   Expert 19 |    219 | GPU1(cuda:2)
DEBUG 01-07 10:13:58.317238.317238 lmp.py:767]   Expert  4 |    222 | GPU0(cuda:1)
DEBUG 01-07 10:13:58.317358.317358 lmp.py:767]   Expert 59 |    223 | GPU0(cuda:1)
DEBUG 01-07 10:13:58.317000.317000 lmp.py:767]   Expert 55 |    233 | GPU1(cuda:2)
DEBUG 01-07 10:13:58.317120.317120 lmp.py:767]   Expert 31 |    240 | GPU0(cuda:1)
DEBUG 01-07 10:13:58.317286.317286 lmp.py:767]   Expert 56 |    241 | GPU1(cuda:2)
DEBUG 01-07 10:13:58.317214.317214 lmp.py:767]   Expert 20 |    251 | GPU0(cuda:1)
DEBUG 01-07 10:13:58.317380.317380 lmp.py:767]   Expert 39 |    253 | GPU1(cuda:2)
DEBUG 01-07 10:13:58.317739.317739 lmp.py:767]   Expert 22 |    264 | GPU0(cuda:1)
DEBUG 01-07 10:13:58.317097.317097 lmp.py:767]   Expert  2 |    267 | GPU1(cuda:2)
DEBUG 01-07 10:13:58.317693.317693 lmp.py:767]   Expert 63 |    275 | GPU0(cuda:1)
DEBUG 01-07 10:13:58.317813.317813 lmp.py:767]   Expert 47 |    276 | GPU1(cuda:2)
DEBUG 01-07 10:13:58.317171.317171 lmp.py:767]   Expert 42 |    303 | GPU0(cuda:1)
DEBUG 01-07 10:13:58.317291.317291 lmp.py:767]   Expert 18 |    315 | GPU1(cuda:2)
DEBUG 01-07 10:13:58.317173.317173 lmp.py:767]   Expert 14 |    319 | GPU0(cuda:1)
DEBUG 01-07 10:13:58.317769.317769 lmp.py:767]   Expert 46 |    367 | GPU1(cuda:2)
DEBUG 01-07 10:13:58.317889.317889 lmp.py:767]   Expert 11 |    388 | GPU1(cuda:2)
DEBUG 01-07 10:13:58.317724.317724 lmp.py:767]   Expert 61 |    460 | GPU0(cuda:1)
DEBUG 01-07 10:13:58.317559.317559 lmp.py:769] 
DEBUG 01-07 10:13:58.317559.317559 lmp.py:769]   Device Token Distribution:
DEBUG 01-07 10:13:58.317156.317156 lmp.py:770]   CPU:   2151 tokens
DEBUG 01-07 10:13:58.317945.317945 lmp.py:774]   cuda:1:   4994 tokens (22 experts)
DEBUG 01-07 10:13:58.317064.317064 lmp.py:774]   cuda:2:   5143 tokens (23 experts)
DEBUG 01-07 10:13:58.317184.317184 lmp.py:775]   Total GPU:  10137 tokens
DEBUG 01-07 10:13:58.317827.317827 lmp.py:776] ============================================================
DEBUG 01-07 10:13:58.317827.317827 lmp.py:776] 
DEBUG 01-07 10:13:58.317908.317908 cuda_h.py:19] end experts_map_get cost 0.001783609390258789 seconds
DEBUG 01-07 10:13:58.317504.317504 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model_multi_device
DEBUG 01-07 10:13:58.317181.317181 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 10:13:58.317310.317310 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 10:13:58.319515.319515 cuda_h.py:19] end allocate_cuda_memory cost 0.00173187255859375 seconds
DEBUG 01-07 10:13:58.319835.319835 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 10:13:58.319876.319876 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 10:13:58.319830.319830 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 10:13:58.319388.319388 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 746e7d20-7e25-4bb0-92c4-6ccbe185a222
DEBUG 01-07 10:13:58.319617.319617 client.py:106] call stub.LoadModelAsync
INFO 01-07 10:13:58.320404.320404 client.py:127] Model loaded
DEBUG 01-07 10:13:58.320883.320883 cuda_h.py:19] end sllm_worker_task cost 0.010298013687133789 seconds
INFO 01-07 10:13:58.320926.320926 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 746e7d20-7e25-4bb0-92c4-6ccbe185a222
DEBUG 01-07 10:13:58.321730.321730 cuda_h.py:19] end load_into_gpu_async cost 0.0013990402221679688 seconds
DEBUG 01-07 10:13:58.321579.321579 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 10:13:58.321626.321626 cuda_h.py:19] end restore_tensors2 cost 0.00018596649169921875 seconds
DEBUG 01-07 10:13:58.321634.321634 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.003610849380493164 seconds
DEBUG 01-07 10:13:58.323928.323928 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 10:13:58.323098.323098 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 10:13:58.323767.323767 cuda_h.py:19] end allocate_cuda_memory cost 0.00017189979553222656 seconds
DEBUG 01-07 10:13:58.323471.323471 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 10:13:58.323751.323751 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 10:13:58.323414.323414 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 10:13:58.323302.323302 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 4d63badd-21d8-4faf-82be-ea11fd7a6456
DEBUG 01-07 10:13:58.323432.323432 client.py:106] call stub.LoadModelAsync
INFO 01-07 10:13:58.324482.324482 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 4d63badd-21d8-4faf-82be-ea11fd7a6456
DEBUG 01-07 10:13:58.324457.324457 cuda_h.py:19] end load_into_gpu_async cost 0.0013267993927001953 seconds
DEBUG 01-07 10:13:58.325968.325968 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 10:13:58.325975.325975 cuda_h.py:19] end restore_tensors2 cost 0.00019025802612304688 seconds
DEBUG 01-07 10:13:58.325937.325937 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0019881725311279297 seconds
DEBUG 01-07 10:13:58.327430.327430 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model_multi_device cost 0.009434223175048828 seconds
DEBUG 01-07 10:13:58.327167.327167 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-07 10:13:58.327229.327229 lmp.py:816] 
DEBUG 01-07 10:13:58.327229.327229 lmp.py:816]   Computing 19 experts on CPU...
DEBUG 01-07 10:13:58.327549.327549 cuda_h.py:19] end cpu_experts_submit cost 0.00011181831359863281 seconds
DEBUG 01-07 10:13:58.327583.327583 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-07 10:13:58.337483.337483 mlpmodule.py:749] group tensors cost 0.010044097900390625 s
DEBUG 01-07 10:13:58.341130.341130 mlpmodule.py:787] pad cost 0.002820730209350586 s
DEBUG 01-07 10:13:58.341264.341264 mlpmodule.py:793] create cpu tensor cost 9.489059448242188e-05 s
DEBUG 01-07 10:13:58.341502.341502 mlpmodule.py:798] move to cpu cost 6.961822509765625e-05 s
DEBUG 01-07 10:13:58.353855.353855 mlpmodule.py:812] group_w3: shape=torch.Size([19, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=54788096
DEBUG 01-07 10:13:58.353460.353460 mlpmodule.py:813] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-07 10:13:58.353504.353504 mlpmodule.py:818] group_w3 first element: -0.0380859375
WARNING 01-07 10:13:58.354310.354310 mlpmodule.py:828] start einsum2
DEBUG 01-07 10:13:58.372956.372956 mlpmodule.py:838] group einsum cost 0.030430078506469727 s
DEBUG 01-07 10:13:58.373953.373953 mlpmodule.py:846] cpy2cputensor cost 0.0004899501800537109 s
DEBUG 01-07 10:13:58.375701.375701 cuda_h.py:19] end wait_cetm_experts cost 0.0483551025390625 seconds
DEBUG 01-07 10:13:58.375041.375041 cuda_h.py:10] start gpu_sexperts
DEBUG 01-07 10:13:58.376391.376391 cuda_h.py:19] end gpu_sexperts cost 0.0005085468292236328 seconds
DEBUG 01-07 10:13:58.376095.376095 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-07 10:13:58.376628.376628 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 3.409385681152344e-05 seconds
DEBUG 01-07 10:13:58.376715.376715 cuda_h.py:10] start wait_experts_multi_device
INFO 01-07 10:13:58.376140.376140 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 746e7d20-7e25-4bb0-92c4-6ccbe185a222
INFO 01-07 10:13:58.377899.377899 client.py:127] Model loaded
INFO 01-07 10:13:58.377139.377139 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 4d63badd-21d8-4faf-82be-ea11fd7a6456
INFO 01-07 10:13:58.378381.378381 client.py:127] Model loaded
DEBUG 01-07 10:13:58.378377.378377 cuda_h.py:19] end wait_experts_multi_device cost 0.0015437602996826172 seconds
DEBUG 01-07 10:13:58.378086.378086 cuda_h.py:10] start gpu_experts_multi_device
DEBUG 01-07 10:13:58.378393.378393 lmp.py:867]   Computing 23 experts on cuda:2...
DEBUG 01-07 10:13:58.384965.384965 mlpmodule.py:707]  experts func einsum cost 0.05732250213623047 s
DEBUG 01-07 10:13:58.385910.385910 mlpmodule.py:533] gpu group tensors cost 0.0062372684478759766 s
DEBUG 01-07 10:13:58.386239.386239 mlpmodule.py:566] gpu pad cost 0.0012531280517578125 s
DEBUG 01-07 10:13:58.387750.387750 mlpmodule.py:584] gpu group einsum cost 0.0005567073822021484 s
DEBUG 01-07 10:13:58.389264.389264 mlpmodule.py:656] gpu experts func einsum cost 0.010085344314575195 s
DEBUG 01-07 10:13:58.389783.389783 lmp.py:867]   Computing 22 experts on cuda:1...
DEBUG 01-07 10:13:58.389533.389533 mlpmodule.py:533] gpu group tensors cost 0.00035643577575683594 s
DEBUG 01-07 10:13:58.390449.390449 mlpmodule.py:566] gpu pad cost 0.0010066032409667969 s
DEBUG 01-07 10:13:58.391797.391797 mlpmodule.py:584] gpu group einsum cost 0.0006554126739501953 s
DEBUG 01-07 10:13:58.393805.393805 mlpmodule.py:656] gpu experts func einsum cost 0.003752470016479492 s
DEBUG 01-07 10:13:58.393696.393696 cuda_h.py:19] end gpu_experts_multi_device cost 0.015193462371826172 seconds
DEBUG 01-07 10:13:58.393288.393288 cuda_h.py:19] end layer_moe_generate_multi_device_2 cost 0.07839846611022949 seconds
DEBUG 01-07 10:13:58.393314.393314 lmp.py:194] -------------------------------- end prefill layer 2 --------------------------------
DEBUG 01-07 10:13:58.393653.393653 lmp.py:153] -------------------------------- start prefill layer 3 --------------------------------
DEBUG 01-07 10:13:58.393324.393324 cuda_h.py:10] start start_load_qkvogn_s_weight_l_4
DEBUG 01-07 10:13:58.393318.393318 cuda_h.py:10] start start_load_qkvogn_s_weight_l_4
DEBUG 01-07 10:13:58.393300.393300 cuda_h.py:19] end start_load_qkvogn_s_weight_l_4 cost 2.6941299438476562e-05 seconds
DEBUG 01-07 10:13:58.393003.393003 cuda_h.py:19] end start_load_qkvogn_s_weight_l_4 cost 5.936622619628906e-05 seconds
DEBUG 01-07 10:13:58.393507.393507 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-07 10:13:58.393383.393383 cuda_h.py:10] start sllm_worker_task
DEBUG 01-07 10:13:58.394307.394307 mlpmodule.py:367] cuda:1 cuda:1
DEBUG 01-07 10:13:58.394501.394501 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 10:13:58.394127.394127 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 10:13:58.394750.394750 cuda_h.py:19] end allocate_cuda_memory cost 0.00017595291137695312 seconds
DEBUG 01-07 10:13:58.394713.394713 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 10:13:58.394568.394568 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 10:13:58.394484.394484 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 10:13:58.394041.394041 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 8327e394-d91a-4406-b34b-61c6e10bf6d8
DEBUG 01-07 10:13:58.394474.394474 client.py:106] call stub.LoadModelAsync
DEBUG 01-07 10:13:58.394813.394813 cuda_h.py:10] start self_attn
INFO 01-07 10:13:58.395543.395543 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 8327e394-d91a-4406-b34b-61c6e10bf6d8
DEBUG 01-07 10:13:58.395326.395326 cuda_h.py:19] end load_into_gpu_async cost 0.0008742809295654297 seconds
DEBUG 01-07 10:13:58.395466.395466 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 10:13:58.395873.395873 cuda_h.py:19] end restore_tensors2 cost 6.29425048828125e-05 seconds
DEBUG 01-07 10:13:58.395675.395675 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0013737678527832031 seconds
INFO 01-07 10:13:58.395803.395803 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 8327e394-d91a-4406-b34b-61c6e10bf6d8
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-07 10:13:58.398258.398258 cuda_h.py:19] end self_attn cost 0.0037398338317871094 seconds
DEBUG 01-07 10:13:58.399527.399527 cuda_h.py:19] end iln_self_attn_paln cost 0.005045175552368164 seconds
DEBUG 01-07 10:13:58.399694.399694 cuda_h.py:10] start layer_moe_generate_multi_device_3
DEBUG 01-07 10:13:58.399550.399550 cuda_h.py:10] start gate
DEBUG 01-07 10:13:58.399526.399526 cuda_h.py:19] end gate cost 0.0006511211395263672 seconds
DEBUG 01-07 10:13:58.399309.399309 cuda_h.py:10] start experts_map_get
DEBUG 01-07 10:13:58.400647.400647 lmp.py:744] 
DEBUG 01-07 10:13:58.400647.400647 lmp.py:744] Expert Token Distribution & Multi-Device Allocation:
DEBUG 01-07 10:13:58.400900.400900 lmp.py:745]   Total experts: 64
DEBUG 01-07 10:13:58.400888.400888 lmp.py:746]   CPU experts: 19 (30%)
DEBUG 01-07 10:13:58.400869.400869 lmp.py:747]   GPU experts: 45 (70%)
DEBUG 01-07 10:13:58.400942.400942 lmp.py:748]   Number of GPU devices: 2
DEBUG 01-07 10:13:58.400314.400314 lmp.py:749] 
DEBUG 01-07 10:13:58.400314.400314 lmp.py:749]   Expert ID | Tokens | Device
DEBUG 01-07 10:13:58.400672.400672 lmp.py:750]   -----------------------------------
DEBUG 01-07 10:13:58.400706.400706 lmp.py:767]   Expert  1 |     50 | CPU
DEBUG 01-07 10:13:58.400064.400064 lmp.py:767]   Expert 27 |     62 | CPU
DEBUG 01-07 10:13:58.400707.400707 lmp.py:767]   Expert  7 |     75 | CPU
DEBUG 01-07 10:13:58.400112.400112 lmp.py:767]   Expert 48 |     82 | CPU
DEBUG 01-07 10:13:58.400516.400516 lmp.py:767]   Expert 15 |     98 | CPU
DEBUG 01-07 10:13:58.400444.400444 lmp.py:767]   Expert 30 |    110 | CPU
DEBUG 01-07 10:13:58.400372.400372 lmp.py:767]   Expert 32 |    117 | CPU
DEBUG 01-07 10:13:58.400061.400061 lmp.py:767]   Expert 61 |    117 | CPU
DEBUG 01-07 10:13:58.400989.400989 lmp.py:767]   Expert 45 |    118 | CPU
DEBUG 01-07 10:13:58.400678.400678 lmp.py:767]   Expert 18 |    119 | CPU
DEBUG 01-07 10:13:58.400606.400606 lmp.py:767]   Expert 34 |    133 | CPU
DEBUG 01-07 10:13:58.400533.400533 lmp.py:767]   Expert 39 |    134 | CPU
DEBUG 01-07 10:13:58.400653.400653 lmp.py:767]   Expert 36 |    138 | CPU
DEBUG 01-07 10:13:58.400819.400819 lmp.py:767]   Expert 11 |    139 | CPU
DEBUG 01-07 10:13:58.400224.400224 lmp.py:767]   Expert 26 |    139 | CPU
DEBUG 01-07 10:13:58.400867.400867 lmp.py:767]   Expert  5 |    140 | CPU
DEBUG 01-07 10:13:58.400795.400795 lmp.py:767]   Expert  6 |    143 | CPU
DEBUG 01-07 10:13:58.400484.400484 lmp.py:767]   Expert 59 |    143 | CPU
DEBUG 01-07 10:13:58.400173.400173 lmp.py:767]   Expert 51 |    145 | CPU
DEBUG 01-07 10:13:58.400770.400770 lmp.py:767]   Expert 49 |    153 | GPU1(cuda:2)
DEBUG 01-07 10:13:58.400651.400651 lmp.py:767]   Expert 23 |    156 | GPU1(cuda:2)
DEBUG 01-07 10:13:58.400533.400533 lmp.py:767]   Expert  2 |    157 | GPU0(cuda:1)
DEBUG 01-07 10:13:58.400414.400414 lmp.py:767]   Expert  9 |    158 | GPU1(cuda:2)
DEBUG 01-07 10:13:58.400057.400057 lmp.py:767]   Expert 50 |    165 | GPU0(cuda:1)
DEBUG 01-07 10:13:58.400230.400230 lmp.py:767]   Expert 56 |    167 | GPU1(cuda:2)
DEBUG 01-07 10:13:58.400065.400065 lmp.py:767]   Expert 40 |    168 | GPU1(cuda:2)
DEBUG 01-07 10:13:58.400423.400423 lmp.py:767]   Expert 52 |    168 | GPU0(cuda:1)
DEBUG 01-07 10:13:58.400782.400782 lmp.py:767]   Expert 16 |    170 | GPU0(cuda:1)
DEBUG 01-07 10:13:58.400425.400425 lmp.py:767]   Expert 35 |    171 | GPU0(cuda:1)
DEBUG 01-07 10:13:58.400829.400829 lmp.py:767]   Expert  4 |    184 | GPU1(cuda:2)
DEBUG 01-07 10:13:58.400472.400472 lmp.py:767]   Expert 13 |    190 | GPU1(cuda:2)
DEBUG 01-07 10:13:58.400115.400115 lmp.py:767]   Expert 37 |    190 | GPU1(cuda:2)
DEBUG 01-07 10:13:58.401758.401758 lmp.py:767]   Expert 42 |    190 | GPU0(cuda:1)
DEBUG 01-07 10:13:58.401401.401401 lmp.py:767]   Expert 17 |    197 | GPU0(cuda:1)
DEBUG 01-07 10:13:58.401806.401806 lmp.py:767]   Expert 38 |    197 | GPU1(cuda:2)
DEBUG 01-07 10:13:58.401449.401449 lmp.py:767]   Expert 62 |    197 | GPU0(cuda:1)
DEBUG 01-07 10:13:58.401091.401091 lmp.py:767]   Expert 21 |    203 | GPU0(cuda:1)
DEBUG 01-07 10:13:58.401450.401450 lmp.py:767]   Expert  3 |    208 | GPU1(cuda:2)
DEBUG 01-07 10:13:58.401570.401570 lmp.py:767]   Expert 44 |    209 | GPU1(cuda:2)
DEBUG 01-07 10:13:58.401689.401689 lmp.py:767]   Expert 28 |    212 | GPU1(cuda:2)
DEBUG 01-07 10:13:58.401524.401524 lmp.py:767]   Expert 60 |    212 | GPU0(cuda:1)
DEBUG 01-07 10:13:58.401644.401644 lmp.py:767]   Expert 58 |    213 | GPU0(cuda:1)
DEBUG 01-07 10:13:58.401287.401287 lmp.py:767]   Expert 10 |    214 | GPU0(cuda:1)
DEBUG 01-07 10:13:58.401692.401692 lmp.py:767]   Expert 47 |    214 | GPU1(cuda:2)
DEBUG 01-07 10:13:58.401096.401096 lmp.py:767]   Expert 53 |    216 | GPU0(cuda:1)
DEBUG 01-07 10:13:58.401739.401739 lmp.py:767]   Expert 55 |    221 | GPU1(cuda:2)
DEBUG 01-07 10:13:58.401144.401144 lmp.py:767]   Expert 20 |    223 | GPU1(cuda:2)
DEBUG 01-07 10:13:58.401310.401310 lmp.py:767]   Expert 57 |    227 | GPU0(cuda:1)
DEBUG 01-07 10:13:58.401715.401715 lmp.py:767]   Expert 33 |    229 | GPU0(cuda:1)
DEBUG 01-07 10:13:58.401119.401119 lmp.py:767]   Expert 31 |    236 | GPU1(cuda:2)
DEBUG 01-07 10:13:58.401762.401762 lmp.py:767]   Expert 46 |    237 | GPU0(cuda:1)
DEBUG 01-07 10:13:58.401405.401405 lmp.py:767]   Expert  8 |    241 | GPU1(cuda:2)
DEBUG 01-07 10:13:58.401717.401717 lmp.py:767]   Expert 19 |    244 | GPU0(cuda:1)
DEBUG 01-07 10:13:58.401552.401552 lmp.py:767]   Expert 24 |    247 | GPU1(cuda:2)
DEBUG 01-07 10:13:58.401626.401626 lmp.py:767]   Expert 14 |    263 | GPU0(cuda:1)
DEBUG 01-07 10:13:58.401222.401222 lmp.py:767]   Expert 63 |    267 | GPU1(cuda:2)
DEBUG 01-07 10:13:58.401819.401819 lmp.py:767]   Expert 29 |    275 | GPU0(cuda:1)
DEBUG 01-07 10:13:58.401654.401654 lmp.py:767]   Expert 12 |    276 | GPU1(cuda:2)
DEBUG 01-07 10:13:58.401774.401774 lmp.py:767]   Expert 22 |    278 | GPU1(cuda:2)
DEBUG 01-07 10:13:58.401132.401132 lmp.py:767]   Expert  0 |    295 | GPU0(cuda:1)
DEBUG 01-07 10:13:58.401490.401490 lmp.py:767]   Expert 43 |    311 | GPU0(cuda:1)
DEBUG 01-07 10:13:58.401610.401610 lmp.py:767]   Expert 54 |    341 | GPU1(cuda:2)
DEBUG 01-07 10:13:58.401730.401730 lmp.py:767]   Expert 41 |    383 | GPU1(cuda:2)
DEBUG 01-07 10:13:58.401850.401850 lmp.py:767]   Expert 25 |    413 | GPU0(cuda:1)
DEBUG 01-07 10:13:58.401016.401016 lmp.py:769] 
DEBUG 01-07 10:13:58.401016.401016 lmp.py:769]   Device Token Distribution:
DEBUG 01-07 10:13:58.401136.401136 lmp.py:770]   CPU:   2202 tokens
DEBUG 01-07 10:13:58.401209.401209 lmp.py:774]   cuda:1:   4967 tokens (22 experts)
DEBUG 01-07 10:13:58.401567.401567 lmp.py:774]   cuda:2:   5119 tokens (23 experts)
DEBUG 01-07 10:13:58.401972.401972 lmp.py:775]   Total GPU:  10086 tokens
DEBUG 01-07 10:13:58.401138.401138 lmp.py:776] ============================================================
DEBUG 01-07 10:13:58.401138.401138 lmp.py:776] 
DEBUG 01-07 10:13:58.401940.401940 cuda_h.py:19] end experts_map_get cost 0.0017993450164794922 seconds
DEBUG 01-07 10:13:58.401729.401729 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model_multi_device
DEBUG 01-07 10:13:58.401360.401360 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 10:13:58.401072.401072 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 10:13:58.402496.402496 cuda_h.py:19] end allocate_cuda_memory cost 0.00017547607421875 seconds
DEBUG 01-07 10:13:58.402452.402452 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 10:13:58.402115.402115 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 10:13:58.402163.402163 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 10:13:58.402528.402528 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, e83547af-eced-45e8-869c-9014822af8a5
DEBUG 01-07 10:13:58.402241.402241 client.py:106] call stub.LoadModelAsync
INFO 01-07 10:13:58.402392.402392 client.py:127] Model loaded
DEBUG 01-07 10:13:58.402457.402457 cuda_h.py:19] end sllm_worker_task cost 0.008785247802734375 seconds
INFO 01-07 10:13:58.403554.403554 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, e83547af-eced-45e8-869c-9014822af8a5
DEBUG 01-07 10:13:58.403927.403927 cuda_h.py:19] end load_into_gpu_async cost 0.0009138584136962891 seconds
DEBUG 01-07 10:13:58.403915.403915 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 10:13:58.403507.403507 cuda_h.py:19] end restore_tensors2 cost 0.00022721290588378906 seconds
DEBUG 01-07 10:13:58.403356.403356 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0016560554504394531 seconds
DEBUG 01-07 10:13:58.405070.405070 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 10:13:58.405862.405862 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 10:13:58.405492.405492 cuda_h.py:19] end allocate_cuda_memory cost 0.0001785755157470703 seconds
DEBUG 01-07 10:13:58.405958.405958 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 10:13:58.405191.405191 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 10:13:58.405285.405285 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 10:13:58.405173.405173 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, f450656e-7894-48de-bfa2-0c609bb2cc22
DEBUG 01-07 10:13:58.406071.406071 client.py:106] call stub.LoadModelAsync
INFO 01-07 10:13:58.406738.406738 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, f450656e-7894-48de-bfa2-0c609bb2cc22
DEBUG 01-07 10:13:58.406759.406759 cuda_h.py:19] end load_into_gpu_async cost 0.0011548995971679688 seconds
DEBUG 01-07 10:13:58.407316.407316 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 10:13:58.407754.407754 cuda_h.py:19] end restore_tensors2 cost 0.00019216537475585938 seconds
DEBUG 01-07 10:13:58.407808.407808 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0018205642700195312 seconds
DEBUG 01-07 10:13:58.409061.409061 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model_multi_device cost 0.007513761520385742 seconds
DEBUG 01-07 10:13:58.409897.409897 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-07 10:13:58.409344.409344 lmp.py:816] 
DEBUG 01-07 10:13:58.409344.409344 lmp.py:816]   Computing 19 experts on CPU...
DEBUG 01-07 10:13:58.409041.409041 cuda_h.py:19] end cpu_experts_submit cost 0.00011038780212402344 seconds
DEBUG 01-07 10:13:58.409267.409267 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-07 10:13:58.415795.415795 mlpmodule.py:749] group tensors cost 0.005937814712524414 s
DEBUG 01-07 10:13:58.418035.418035 mlpmodule.py:787] pad cost 0.001909494400024414 s
DEBUG 01-07 10:13:58.418643.418643 mlpmodule.py:793] create cpu tensor cost 6.651878356933594e-05 s
DEBUG 01-07 10:13:58.418144.418144 mlpmodule.py:798] move to cpu cost 5.173683166503906e-05 s
DEBUG 01-07 10:13:58.430813.430813 mlpmodule.py:812] group_w3: shape=torch.Size([19, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=54788096
DEBUG 01-07 10:13:58.430111.430111 mlpmodule.py:813] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-07 10:13:58.430545.430545 mlpmodule.py:818] group_w3 first element: -0.054931640625
WARNING 01-07 10:13:58.430814.430814 mlpmodule.py:828] start einsum2
DEBUG 01-07 10:13:58.450340.450340 mlpmodule.py:838] group einsum cost 0.03146004676818848 s
DEBUG 01-07 10:13:58.450634.450634 mlpmodule.py:846] cpy2cputensor cost 0.0003955364227294922 s
DEBUG 01-07 10:13:58.453320.453320 cuda_h.py:19] end wait_cetm_experts cost 0.04405951499938965 seconds
DEBUG 01-07 10:13:58.453866.453866 cuda_h.py:10] start gpu_sexperts
DEBUG 01-07 10:13:58.454951.454951 cuda_h.py:19] end gpu_sexperts cost 0.0005023479461669922 seconds
DEBUG 01-07 10:13:58.454456.454456 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-07 10:13:58.454260.454260 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.47955322265625e-05 seconds
DEBUG 01-07 10:13:58.454870.454870 cuda_h.py:10] start wait_experts_multi_device
INFO 01-07 10:13:58.454772.454772 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, e83547af-eced-45e8-869c-9014822af8a5
INFO 01-07 10:13:58.455874.455874 client.py:127] Model loaded
INFO 01-07 10:13:58.455618.455618 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, f450656e-7894-48de-bfa2-0c609bb2cc22
INFO 01-07 10:13:58.455989.455989 client.py:127] Model loaded
DEBUG 01-07 10:13:58.455733.455733 cuda_h.py:19] end wait_experts_multi_device cost 0.0014116764068603516 seconds
DEBUG 01-07 10:13:58.455535.455535 cuda_h.py:10] start gpu_experts_multi_device
DEBUG 01-07 10:13:58.455073.455073 lmp.py:867]   Computing 23 experts on cuda:2...
DEBUG 01-07 10:13:58.457019.457019 mlpmodule.py:533] gpu group tensors cost 0.0004780292510986328 s
DEBUG 01-07 10:13:58.458527.458527 mlpmodule.py:566] gpu pad cost 0.0012569427490234375 s
DEBUG 01-07 10:13:58.459853.459853 mlpmodule.py:584] gpu group einsum cost 0.0005469322204589844 s
DEBUG 01-07 10:13:58.461843.461843 mlpmodule.py:656] gpu experts func einsum cost 0.004526615142822266 s
DEBUG 01-07 10:13:58.461860.461860 lmp.py:867]   Computing 22 experts on cuda:1...
DEBUG 01-07 10:13:58.462805.462805 mlpmodule.py:533] gpu group tensors cost 0.0004494190216064453 s
DEBUG 01-07 10:13:58.462059.462059 mlpmodule.py:707]  experts func einsum cost 0.053206682205200195 s
DEBUG 01-07 10:13:58.463202.463202 mlpmodule.py:566] gpu pad cost 0.0013148784637451172 s
DEBUG 01-07 10:13:58.464557.464557 mlpmodule.py:584] gpu group einsum cost 0.0006334781646728516 s
DEBUG 01-07 10:13:58.466963.466963 mlpmodule.py:656] gpu experts func einsum cost 0.004393577575683594 s
DEBUG 01-07 10:13:58.466033.466033 cuda_h.py:19] end gpu_experts_multi_device cost 0.010274648666381836 seconds
DEBUG 01-07 10:13:58.466095.466095 cuda_h.py:19] end layer_moe_generate_multi_device_3 cost 0.06711840629577637 seconds
DEBUG 01-07 10:13:58.466505.466505 lmp.py:194] -------------------------------- end prefill layer 3 --------------------------------
DEBUG 01-07 10:13:58.466990.466990 lmp.py:153] -------------------------------- start prefill layer 4 --------------------------------
DEBUG 01-07 10:13:58.466686.466686 cuda_h.py:10] start start_load_qkvogn_s_weight_l_5
DEBUG 01-07 10:13:58.466681.466681 cuda_h.py:10] start start_load_qkvogn_s_weight_l_5
DEBUG 01-07 10:13:58.466325.466325 cuda_h.py:19] end start_load_qkvogn_s_weight_l_5 cost 2.7418136596679688e-05 seconds
DEBUG 01-07 10:13:58.466220.466220 cuda_h.py:19] end start_load_qkvogn_s_weight_l_5 cost 5.841255187988281e-05 seconds
DEBUG 01-07 10:13:58.466962.466962 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-07 10:13:58.466428.466428 mlpmodule.py:367] cuda:1 cuda:1
DEBUG 01-07 10:13:58.466484.466484 cuda_h.py:10] start sllm_worker_task
DEBUG 01-07 10:13:58.466248.466248 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 10:13:58.466289.466289 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 10:13:58.467702.467702 cuda_h.py:19] end allocate_cuda_memory cost 0.0002307891845703125 seconds
DEBUG 01-07 10:13:58.467526.467526 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 10:13:58.467111.467111 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 10:13:58.467602.467602 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 10:13:58.467351.467351 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 7001e614-1aac-49a3-a2e4-64776bb87e08
DEBUG 01-07 10:13:58.467076.467076 client.py:106] call stub.LoadModelAsync
DEBUG 01-07 10:13:58.467229.467229 cuda_h.py:10] start self_attn
INFO 01-07 10:13:58.468403.468403 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 7001e614-1aac-49a3-a2e4-64776bb87e08
DEBUG 01-07 10:13:58.468433.468433 cuda_h.py:19] end load_into_gpu_async cost 0.0011143684387207031 seconds
DEBUG 01-07 10:13:58.468573.468573 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 10:13:58.468556.468556 cuda_h.py:19] end restore_tensors2 cost 6.389617919921875e-05 seconds
DEBUG 01-07 10:13:58.468027.468027 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0016884803771972656 seconds
INFO 01-07 10:13:58.468255.468255 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 7001e614-1aac-49a3-a2e4-64776bb87e08
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-07 10:13:58.471982.471982 cuda_h.py:19] end self_attn cost 0.0038280487060546875 seconds
DEBUG 01-07 10:13:58.471489.471489 cuda_h.py:19] end iln_self_attn_paln cost 0.005201816558837891 seconds
DEBUG 01-07 10:13:58.471841.471841 cuda_h.py:10] start layer_moe_generate_multi_device_4
DEBUG 01-07 10:13:58.471743.471743 cuda_h.py:10] start gate
DEBUG 01-07 10:13:58.472150.472150 cuda_h.py:19] end gate cost 0.0006525516510009766 seconds
DEBUG 01-07 10:13:58.472648.472648 cuda_h.py:10] start experts_map_get
DEBUG 01-07 10:13:58.473053.473053 lmp.py:744] 
DEBUG 01-07 10:13:58.473053.473053 lmp.py:744] Expert Token Distribution & Multi-Device Allocation:
DEBUG 01-07 10:13:58.473908.473908 lmp.py:745]   Total experts: 64
DEBUG 01-07 10:13:58.473657.473657 lmp.py:746]   CPU experts: 19 (30%)
DEBUG 01-07 10:13:58.473877.473877 lmp.py:747]   GPU experts: 45 (70%)
DEBUG 01-07 10:13:58.473473.473473 lmp.py:748]   Number of GPU devices: 2
DEBUG 01-07 10:13:58.473355.473355 lmp.py:749] 
DEBUG 01-07 10:13:58.473355.473355 lmp.py:749]   Expert ID | Tokens | Device
DEBUG 01-07 10:13:58.473236.473236 lmp.py:750]   -----------------------------------
DEBUG 01-07 10:13:58.473270.473270 lmp.py:767]   Expert 14 |     64 | CPU
DEBUG 01-07 10:13:58.473913.473913 lmp.py:767]   Expert 57 |     72 | CPU
DEBUG 01-07 10:13:58.473318.473318 lmp.py:767]   Expert 13 |     76 | CPU
DEBUG 01-07 10:13:58.473245.473245 lmp.py:767]   Expert 26 |     81 | CPU
DEBUG 01-07 10:13:58.473411.473411 lmp.py:767]   Expert 31 |     90 | CPU
DEBUG 01-07 10:13:58.473578.473578 lmp.py:767]   Expert 54 |     91 | CPU
DEBUG 01-07 10:13:58.473505.473505 lmp.py:767]   Expert 11 |     93 | CPU
DEBUG 01-07 10:13:58.473387.473387 lmp.py:767]   Expert 45 |     95 | CPU
DEBUG 01-07 10:13:58.473030.473030 lmp.py:767]   Expert 58 |    103 | CPU
DEBUG 01-07 10:13:58.473911.473911 lmp.py:767]   Expert 51 |    107 | CPU
DEBUG 01-07 10:13:58.473554.473554 lmp.py:767]   Expert 30 |    108 | CPU
DEBUG 01-07 10:13:58.473720.473720 lmp.py:767]   Expert 36 |    110 | CPU
DEBUG 01-07 10:13:58.473409.473409 lmp.py:767]   Expert 10 |    114 | CPU
DEBUG 01-07 10:13:58.473099.473099 lmp.py:767]   Expert 32 |    114 | CPU
DEBUG 01-07 10:13:58.473788.473788 lmp.py:767]   Expert 20 |    127 | CPU
DEBUG 01-07 10:13:58.473716.473716 lmp.py:767]   Expert  8 |    136 | CPU
DEBUG 01-07 10:13:58.473405.473405 lmp.py:767]   Expert  4 |    138 | CPU
DEBUG 01-07 10:13:58.473333.473333 lmp.py:767]   Expert 63 |    139 | CPU
DEBUG 01-07 10:13:58.473022.473022 lmp.py:767]   Expert 53 |    140 | CPU
DEBUG 01-07 10:13:58.473380.473380 lmp.py:767]   Expert 34 |    143 | GPU0(cuda:1)
DEBUG 01-07 10:13:58.473407.473407 lmp.py:767]   Expert 61 |    143 | GPU1(cuda:2)
DEBUG 01-07 10:13:58.473958.473958 lmp.py:767]   Expert 16 |    147 | GPU1(cuda:2)
DEBUG 01-07 10:13:58.473793.473793 lmp.py:767]   Expert 47 |    148 | GPU0(cuda:1)
DEBUG 01-07 10:13:58.473151.473151 lmp.py:767]   Expert 28 |    158 | GPU0(cuda:1)
DEBUG 01-07 10:13:58.473986.473986 lmp.py:767]   Expert 60 |    158 | GPU1(cuda:2)
DEBUG 01-07 10:13:58.473629.473629 lmp.py:767]   Expert 17 |    164 | GPU0(cuda:1)
DEBUG 01-07 10:13:58.473272.473272 lmp.py:767]   Expert 42 |    164 | GPU1(cuda:2)
DEBUG 01-07 10:13:58.473438.473438 lmp.py:767]   Expert 29 |    170 | GPU1(cuda:2)
DEBUG 01-07 10:13:58.473843.473843 lmp.py:767]   Expert 44 |    171 | GPU0(cuda:1)
DEBUG 01-07 10:13:58.473247.473247 lmp.py:767]   Expert 27 |    175 | GPU1(cuda:2)
DEBUG 01-07 10:13:58.473652.473652 lmp.py:767]   Expert  7 |    176 | GPU0(cuda:1)
DEBUG 01-07 10:13:58.473056.473056 lmp.py:767]   Expert 41 |    179 | GPU1(cuda:2)
DEBUG 01-07 10:13:58.473461.473461 lmp.py:767]   Expert 48 |    184 | GPU1(cuda:2)
DEBUG 01-07 10:13:58.473058.473058 lmp.py:767]   Expert 56 |    184 | GPU0(cuda:1)
DEBUG 01-07 10:13:58.473939.473939 lmp.py:767]   Expert  9 |    186 | GPU0(cuda:1)
DEBUG 01-07 10:13:58.473297.473297 lmp.py:767]   Expert  3 |    188 | GPU1(cuda:2)
DEBUG 01-07 10:13:58.473656.473656 lmp.py:767]   Expert  2 |    189 | GPU0(cuda:1)
DEBUG 01-07 10:13:58.473014.473014 lmp.py:767]   Expert 15 |    190 | GPU1(cuda:2)
DEBUG 01-07 10:13:58.473895.473895 lmp.py:767]   Expert 24 |    193 | GPU0(cuda:1)
DEBUG 01-07 10:13:58.473300.473300 lmp.py:767]   Expert  0 |    194 | GPU1(cuda:2)
DEBUG 01-07 10:13:58.473704.473704 lmp.py:767]   Expert 18 |    200 | GPU0(cuda:1)
DEBUG 01-07 10:13:58.473109.473109 lmp.py:767]   Expert 55 |    208 | GPU1(cuda:2)
DEBUG 01-07 10:13:58.474513.474513 lmp.py:767]   Expert 40 |    213 | GPU0(cuda:1)
DEBUG 01-07 10:13:58.474918.474918 lmp.py:767]   Expert 38 |    216 | GPU1(cuda:2)
DEBUG 01-07 10:13:58.474322.474322 lmp.py:767]   Expert 22 |    217 | GPU1(cuda:2)
DEBUG 01-07 10:13:58.474489.474489 lmp.py:767]   Expert 23 |    217 | GPU0(cuda:1)
DEBUG 01-07 10:13:58.474893.474893 lmp.py:767]   Expert  6 |    222 | GPU1(cuda:2)
DEBUG 01-07 10:13:58.474298.474298 lmp.py:767]   Expert 37 |    222 | GPU0(cuda:1)
DEBUG 01-07 10:13:58.474464.474464 lmp.py:767]   Expert 46 |    233 | GPU0(cuda:1)
DEBUG 01-07 10:13:58.474868.474868 lmp.py:767]   Expert 19 |    243 | GPU1(cuda:2)
DEBUG 01-07 10:13:58.474750.474750 lmp.py:767]   Expert 39 |    248 | GPU0(cuda:1)
DEBUG 01-07 10:13:58.474108.474108 lmp.py:767]   Expert 25 |    251 | GPU1(cuda:2)
DEBUG 01-07 10:13:58.474989.474989 lmp.py:767]   Expert 12 |    259 | GPU0(cuda:1)
DEBUG 01-07 10:13:58.474732.474732 lmp.py:767]   Expert 50 |    261 | GPU1(cuda:2)
DEBUG 01-07 10:13:58.474567.474567 lmp.py:767]   Expert 62 |    270 | GPU0(cuda:1)
DEBUG 01-07 10:13:58.474925.474925 lmp.py:767]   Expert 21 |    279 | GPU1(cuda:2)
DEBUG 01-07 10:13:58.474283.474283 lmp.py:767]   Expert 35 |    286 | GPU0(cuda:1)
DEBUG 01-07 10:13:58.474642.474642 lmp.py:767]   Expert 49 |    290 | GPU1(cuda:2)
DEBUG 01-07 10:13:58.474000.474000 lmp.py:767]   Expert 33 |    299 | GPU1(cuda:2)
DEBUG 01-07 10:13:58.474835.474835 lmp.py:767]   Expert 52 |    299 | GPU0(cuda:1)
DEBUG 01-07 10:13:58.474955.474955 lmp.py:767]   Expert  1 |    349 | GPU0(cuda:1)
DEBUG 01-07 10:13:58.474313.474313 lmp.py:767]   Expert  5 |    381 | GPU1(cuda:2)
DEBUG 01-07 10:13:58.474910.474910 lmp.py:767]   Expert 43 |    438 | GPU1(cuda:2)
DEBUG 01-07 10:13:58.474506.474506 lmp.py:767]   Expert 59 |    585 | GPU0(cuda:1)
DEBUG 01-07 10:13:58.474149.474149 lmp.py:769] 
DEBUG 01-07 10:13:58.474149.474149 lmp.py:769]   Device Token Distribution:
DEBUG 01-07 10:13:58.474984.474984 lmp.py:770]   CPU:   1998 tokens
DEBUG 01-07 10:13:58.474535.474535 lmp.py:774]   cuda:1:   5093 tokens (22 experts)
DEBUG 01-07 10:13:58.474131.474131 lmp.py:774]   cuda:2:   5197 tokens (23 experts)
DEBUG 01-07 10:13:58.474774.474774 lmp.py:775]   Total GPU:  10290 tokens
DEBUG 01-07 10:13:58.474940.474940 lmp.py:776] ============================================================
DEBUG 01-07 10:13:58.474940.474940 lmp.py:776] 
DEBUG 01-07 10:13:58.474544.474544 cuda_h.py:19] end experts_map_get cost 0.0017886161804199219 seconds
DEBUG 01-07 10:13:58.474816.474816 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model_multi_device
DEBUG 01-07 10:13:58.474208.474208 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 10:13:58.474113.474113 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 10:13:58.474259.474259 cuda_h.py:19] end allocate_cuda_memory cost 0.00017976760864257812 seconds
DEBUG 01-07 10:13:58.475295.475295 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 10:13:58.475104.475104 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 10:13:58.475629.475629 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 10:13:58.475470.475470 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, d7a10053-a6a0-4e84-ab74-a11500505e1e
DEBUG 01-07 10:13:58.475237.475237 client.py:106] call stub.LoadModelAsync
INFO 01-07 10:13:58.475103.475103 client.py:127] Model loaded
DEBUG 01-07 10:13:58.475753.475753 cuda_h.py:19] end sllm_worker_task cost 0.008977413177490234 seconds
INFO 01-07 10:13:58.475527.475527 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, d7a10053-a6a0-4e84-ab74-a11500505e1e
DEBUG 01-07 10:13:58.476939.476939 cuda_h.py:19] end load_into_gpu_async cost 0.0010030269622802734 seconds
DEBUG 01-07 10:13:58.476973.476973 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 10:13:58.476908.476908 cuda_h.py:19] end restore_tensors2 cost 0.0002090930938720703 seconds
DEBUG 01-07 10:13:58.476532.476532 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0017235279083251953 seconds
DEBUG 01-07 10:13:58.478580.478580 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 10:13:58.478650.478650 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 10:13:58.478353.478353 cuda_h.py:19] end allocate_cuda_memory cost 0.0001964569091796875 seconds
DEBUG 01-07 10:13:58.478289.478289 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 10:13:58.478615.478615 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 10:13:58.478278.478278 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 10:13:58.478643.478643 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, cd825b40-41f7-4720-8c80-726a7c750250
DEBUG 01-07 10:13:58.478104.478104 client.py:106] call stub.LoadModelAsync
INFO 01-07 10:13:58.479354.479354 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, cd825b40-41f7-4720-8c80-726a7c750250
DEBUG 01-07 10:13:58.479945.479945 cuda_h.py:19] end load_into_gpu_async cost 0.0009796619415283203 seconds
DEBUG 01-07 10:13:58.479503.479503 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 10:13:58.479139.479139 cuda_h.py:19] end restore_tensors2 cost 0.00019788742065429688 seconds
DEBUG 01-07 10:13:58.479717.479717 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0016658306121826172 seconds
DEBUG 01-07 10:13:58.481884.481884 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model_multi_device cost 0.007149696350097656 seconds
DEBUG 01-07 10:13:58.481522.481522 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-07 10:13:58.481584.481584 lmp.py:816] 
DEBUG 01-07 10:13:58.481584.481584 lmp.py:816]   Computing 19 experts on CPU...
DEBUG 01-07 10:13:58.481858.481858 cuda_h.py:19] end cpu_experts_submit cost 0.000110626220703125 seconds
DEBUG 01-07 10:13:58.481130.481130 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-07 10:13:58.487886.487886 mlpmodule.py:749] group tensors cost 0.005611419677734375 s
DEBUG 01-07 10:13:58.490736.490736 mlpmodule.py:787] pad cost 0.00164794921875 s
DEBUG 01-07 10:13:58.490794.490794 mlpmodule.py:793] create cpu tensor cost 5.8650970458984375e-05 s
DEBUG 01-07 10:13:58.490413.490413 mlpmodule.py:798] move to cpu cost 4.410743713378906e-05 s
DEBUG 01-07 10:13:58.501165.501165 mlpmodule.py:812] group_w3: shape=torch.Size([19, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=54788096
DEBUG 01-07 10:13:58.501479.501479 mlpmodule.py:813] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-07 10:13:58.501954.501954 mlpmodule.py:818] group_w3 first element: 0.0086669921875
WARNING 01-07 10:13:58.501495.501495 mlpmodule.py:828] start einsum2
DEBUG 01-07 10:13:58.519246.519246 mlpmodule.py:838] group einsum cost 0.029128551483154297 s
DEBUG 01-07 10:13:58.520335.520335 mlpmodule.py:846] cpy2cputensor cost 0.0004513263702392578 s
DEBUG 01-07 10:13:58.522475.522475 cuda_h.py:19] end wait_cetm_experts cost 0.040866851806640625 seconds
DEBUG 01-07 10:13:58.522921.522921 cuda_h.py:10] start gpu_sexperts
DEBUG 01-07 10:13:58.523569.523569 cuda_h.py:19] end gpu_sexperts cost 0.0004963874816894531 seconds
DEBUG 01-07 10:13:58.523882.523882 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-07 10:13:58.523023.523023 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.3365020751953125e-05 seconds
DEBUG 01-07 10:13:58.523349.523349 cuda_h.py:10] start wait_experts_multi_device
INFO 01-07 10:13:58.523774.523774 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, d7a10053-a6a0-4e84-ab74-a11500505e1e
INFO 01-07 10:13:58.524785.524785 client.py:127] Model loaded
INFO 01-07 10:13:58.524311.524311 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, cd825b40-41f7-4720-8c80-726a7c750250
INFO 01-07 10:13:58.525035.525035 client.py:127] Model loaded
DEBUG 01-07 10:13:58.525063.525063 cuda_h.py:19] end wait_experts_multi_device cost 0.0017235279083251953 seconds
DEBUG 01-07 10:13:58.525534.525534 cuda_h.py:10] start gpu_experts_multi_device
DEBUG 01-07 10:13:58.525591.525591 lmp.py:867]   Computing 23 experts on cuda:2...
DEBUG 01-07 10:13:58.526636.526636 mlpmodule.py:533] gpu group tensors cost 0.0004761219024658203 s
DEBUG 01-07 10:13:58.528191.528191 mlpmodule.py:566] gpu pad cost 0.0012540817260742188 s
DEBUG 01-07 10:13:58.528927.528927 mlpmodule.py:584] gpu group einsum cost 0.0005769729614257812 s
DEBUG 01-07 10:13:58.530031.530031 mlpmodule.py:656] gpu experts func einsum cost 0.004561424255371094 s
DEBUG 01-07 10:13:58.531339.531339 lmp.py:867]   Computing 22 experts on cuda:1...
DEBUG 01-07 10:13:58.531185.531185 mlpmodule.py:533] gpu group tensors cost 0.0004420280456542969 s
DEBUG 01-07 10:13:58.532137.532137 mlpmodule.py:707]  experts func einsum cost 0.05072641372680664 s
DEBUG 01-07 10:13:58.534754.534754 mlpmodule.py:566] gpu pad cost 0.0021088123321533203 s
DEBUG 01-07 10:13:58.534382.534382 mlpmodule.py:584] gpu group einsum cost 0.0006527900695800781 s
DEBUG 01-07 10:13:58.536158.536158 mlpmodule.py:656] gpu experts func einsum cost 0.00516200065612793 s
DEBUG 01-07 10:13:58.536240.536240 cuda_h.py:19] end gpu_experts_multi_device cost 0.011164188385009766 seconds
DEBUG 01-07 10:13:58.536309.536309 cuda_h.py:19] end layer_moe_generate_multi_device_4 cost 0.06478118896484375 seconds
DEBUG 01-07 10:13:58.536165.536165 lmp.py:194] -------------------------------- end prefill layer 4 --------------------------------
DEBUG 01-07 10:13:58.537041.537041 lmp.py:153] -------------------------------- start prefill layer 5 --------------------------------
DEBUG 01-07 10:13:58.537121.537121 cuda_h.py:10] start start_load_qkvogn_s_weight_l_6
DEBUG 01-07 10:13:58.537785.537785 cuda_h.py:10] start start_load_qkvogn_s_weight_l_6
DEBUG 01-07 10:13:58.537720.537720 cuda_h.py:19] end start_load_qkvogn_s_weight_l_6 cost 2.7179718017578125e-05 seconds
DEBUG 01-07 10:13:58.537423.537423 cuda_h.py:19] end start_load_qkvogn_s_weight_l_6 cost 6.127357482910156e-05 seconds
DEBUG 01-07 10:13:58.537974.537974 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-07 10:13:58.537704.537704 cuda_h.py:10] start sllm_worker_task
DEBUG 01-07 10:13:58.537807.537807 mlpmodule.py:367] cuda:1 cuda:1
DEBUG 01-07 10:13:58.537238.537238 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 10:13:58.537103.537103 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 10:13:58.537330.537330 cuda_h.py:19] end allocate_cuda_memory cost 0.0001990795135498047 seconds
DEBUG 01-07 10:13:58.537623.537623 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 10:13:58.537671.537671 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 10:13:58.537971.537971 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 10:13:58.537004.537004 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 6db152b3-c7e2-4da9-8c09-813135e4e349
DEBUG 01-07 10:13:58.537629.537629 client.py:106] call stub.LoadModelAsync
DEBUG 01-07 10:13:58.538187.538187 cuda_h.py:10] start self_attn
INFO 01-07 10:13:58.538224.538224 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 6db152b3-c7e2-4da9-8c09-813135e4e349
DEBUG 01-07 10:13:58.538769.538769 cuda_h.py:19] end load_into_gpu_async cost 0.0009505748748779297 seconds
DEBUG 01-07 10:13:58.538803.538803 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 10:13:58.538369.538369 cuda_h.py:19] end restore_tensors2 cost 6.29425048828125e-05 seconds
DEBUG 01-07 10:13:58.538887.538887 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0014767646789550781 seconds
INFO 01-07 10:13:58.539723.539723 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 6db152b3-c7e2-4da9-8c09-813135e4e349
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-07 10:13:58.542042.542042 cuda_h.py:19] end self_attn cost 0.0037267208099365234 seconds
DEBUG 01-07 10:13:58.542213.542213 cuda_h.py:19] end iln_self_attn_paln cost 0.0050656795501708984 seconds
DEBUG 01-07 10:13:58.542565.542565 cuda_h.py:10] start layer_moe_generate_multi_device_5
DEBUG 01-07 10:13:58.542203.542203 cuda_h.py:10] start gate
DEBUG 01-07 10:13:58.543226.543226 cuda_h.py:19] end gate cost 0.0006489753723144531 seconds
DEBUG 01-07 10:13:58.543724.543724 cuda_h.py:10] start experts_map_get
DEBUG 01-07 10:13:58.543976.543976 lmp.py:744] 
DEBUG 01-07 10:13:58.543976.543976 lmp.py:744] Expert Token Distribution & Multi-Device Allocation:
DEBUG 01-07 10:13:58.543037.543037 lmp.py:745]   Total experts: 64
DEBUG 01-07 10:13:58.543501.543501 lmp.py:746]   CPU experts: 19 (30%)
DEBUG 01-07 10:13:58.543244.543244 lmp.py:747]   GPU experts: 45 (70%)
DEBUG 01-07 10:13:58.543840.543840 lmp.py:748]   Number of GPU devices: 2
DEBUG 01-07 10:13:58.543006.543006 lmp.py:749] 
DEBUG 01-07 10:13:58.543006.543006 lmp.py:749]   Expert ID | Tokens | Device
DEBUG 01-07 10:13:58.543649.543649 lmp.py:750]   -----------------------------------
DEBUG 01-07 10:13:58.543014.543014 lmp.py:767]   Expert 34 |     24 | CPU
DEBUG 01-07 10:13:58.543657.543657 lmp.py:767]   Expert 45 |     65 | CPU
DEBUG 01-07 10:13:58.543062.543062 lmp.py:767]   Expert 22 |     72 | CPU
DEBUG 01-07 10:13:58.543228.543228 lmp.py:767]   Expert 57 |     78 | CPU
DEBUG 01-07 10:13:58.543156.543156 lmp.py:767]   Expert 17 |     96 | CPU
DEBUG 01-07 10:13:58.543084.543084 lmp.py:767]   Expert 15 |     98 | CPU
DEBUG 01-07 10:13:58.543442.543442 lmp.py:767]   Expert  4 |    101 | CPU
DEBUG 01-07 10:13:58.543085.543085 lmp.py:767]   Expert 28 |    106 | CPU
DEBUG 01-07 10:13:58.543728.543728 lmp.py:767]   Expert 32 |    111 | CPU
DEBUG 01-07 10:13:58.543132.543132 lmp.py:767]   Expert 60 |    114 | CPU
DEBUG 01-07 10:13:58.543537.543537 lmp.py:767]   Expert 36 |    124 | CPU
DEBUG 01-07 10:13:58.543226.543226 lmp.py:767]   Expert 14 |    126 | CPU
DEBUG 01-07 10:13:58.543677.543677 lmp.py:767]   Expert 12 |    127 | CPU
DEBUG 01-07 10:13:58.543605.543605 lmp.py:767]   Expert 16 |    127 | CPU
DEBUG 01-07 10:13:58.544294.544294 lmp.py:767]   Expert 25 |    131 | CPU
DEBUG 01-07 10:13:58.544745.544745 lmp.py:767]   Expert 52 |    131 | CPU
DEBUG 01-07 10:13:58.544434.544434 lmp.py:767]   Expert  8 |    133 | CPU
DEBUG 01-07 10:13:58.544124.544124 lmp.py:767]   Expert  2 |    139 | CPU
DEBUG 01-07 10:13:58.544005.544005 lmp.py:767]   Expert 35 |    143 | CPU
DEBUG 01-07 10:13:58.544840.544840 lmp.py:767]   Expert  5 |    146 | GPU0(cuda:1)
DEBUG 01-07 10:13:58.544913.544913 lmp.py:767]   Expert 30 |    152 | GPU1(cuda:2)
DEBUG 01-07 10:13:58.544272.544272 lmp.py:767]   Expert 23 |    155 | GPU0(cuda:1)
DEBUG 01-07 10:13:58.544868.544868 lmp.py:767]   Expert 39 |    156 | GPU1(cuda:2)
DEBUG 01-07 10:13:58.544511.544511 lmp.py:767]   Expert 61 |    157 | GPU0(cuda:1)
DEBUG 01-07 10:13:58.544154.544154 lmp.py:767]   Expert  0 |    160 | GPU1(cuda:2)
DEBUG 01-07 10:13:58.544559.544559 lmp.py:767]   Expert 13 |    169 | GPU0(cuda:1)
DEBUG 01-07 10:13:58.544963.544963 lmp.py:767]   Expert  3 |    170 | GPU0(cuda:1)
DEBUG 01-07 10:13:58.544368.544368 lmp.py:767]   Expert 42 |    170 | GPU1(cuda:2)
DEBUG 01-07 10:13:58.544534.544534 lmp.py:767]   Expert 31 |    173 | GPU1(cuda:2)
DEBUG 01-07 10:13:58.544892.544892 lmp.py:767]   Expert 41 |    174 | GPU1(cuda:2)
DEBUG 01-07 10:13:58.544774.544774 lmp.py:767]   Expert 44 |    174 | GPU0(cuda:1)
DEBUG 01-07 10:13:58.544655.544655 lmp.py:767]   Expert 46 |    176 | GPU0(cuda:1)
DEBUG 01-07 10:13:58.544775.544775 lmp.py:767]   Expert  9 |    177 | GPU1(cuda:2)
DEBUG 01-07 10:13:58.544418.544418 lmp.py:767]   Expert 43 |    182 | GPU0(cuda:1)
DEBUG 01-07 10:13:58.544822.544822 lmp.py:767]   Expert 27 |    191 | GPU0(cuda:1)
DEBUG 01-07 10:13:58.544227.544227 lmp.py:767]   Expert 62 |    191 | GPU1(cuda:2)
DEBUG 01-07 10:13:58.544069.544069 lmp.py:767]   Expert 26 |    192 | GPU0(cuda:1)
DEBUG 01-07 10:13:58.544712.544712 lmp.py:767]   Expert 50 |    192 | GPU1(cuda:2)
DEBUG 01-07 10:13:58.544116.544116 lmp.py:767]   Expert 51 |    193 | GPU1(cuda:2)
DEBUG 01-07 10:13:58.544283.544283 lmp.py:767]   Expert 18 |    194 | GPU0(cuda:1)
DEBUG 01-07 10:13:58.544687.544687 lmp.py:767]   Expert 49 |    195 | GPU1(cuda:2)
DEBUG 01-07 10:13:58.544853.544853 lmp.py:767]   Expert 11 |    201 | GPU0(cuda:1)
DEBUG 01-07 10:13:58.544496.544496 lmp.py:767]   Expert 47 |    203 | GPU1(cuda:2)
DEBUG 01-07 10:13:58.544378.544378 lmp.py:767]   Expert 19 |    204 | GPU1(cuda:2)
DEBUG 01-07 10:13:58.544736.544736 lmp.py:767]   Expert 20 |    204 | GPU0(cuda:1)
DEBUG 01-07 10:13:58.544379.544379 lmp.py:767]   Expert 63 |    207 | GPU0(cuda:1)
DEBUG 01-07 10:13:58.544783.544783 lmp.py:767]   Expert 55 |    209 | GPU1(cuda:2)
DEBUG 01-07 10:13:58.544950.544950 lmp.py:767]   Expert 56 |    211 | GPU0(cuda:1)
DEBUG 01-07 10:13:58.544116.544116 lmp.py:767]   Expert 38 |    217 | GPU1(cuda:2)
DEBUG 01-07 10:13:58.544805.544805 lmp.py:767]   Expert 48 |    229 | GPU0(cuda:1)
DEBUG 01-07 10:13:58.544971.544971 lmp.py:767]   Expert  1 |    235 | GPU1(cuda:2)
DEBUG 01-07 10:13:58.544137.544137 lmp.py:767]   Expert 10 |    241 | GPU0(cuda:1)
DEBUG 01-07 10:13:58.544303.544303 lmp.py:767]   Expert 54 |    245 | GPU1(cuda:2)
DEBUG 01-07 10:13:58.544900.544900 lmp.py:767]   Expert 21 |    248 | GPU0(cuda:1)
DEBUG 01-07 10:13:58.544020.544020 lmp.py:767]   Expert  7 |    251 | GPU1(cuda:2)
DEBUG 01-07 10:13:58.544140.544140 lmp.py:767]   Expert 33 |    259 | GPU0(cuda:1)
DEBUG 01-07 10:13:58.544259.544259 lmp.py:767]   Expert 29 |    260 | GPU1(cuda:2)
DEBUG 01-07 10:13:58.544095.544095 lmp.py:767]   Expert 40 |    265 | GPU0(cuda:1)
DEBUG 01-07 10:13:58.544691.544691 lmp.py:767]   Expert 24 |    270 | GPU1(cuda:2)
DEBUG 01-07 10:13:58.544288.544288 lmp.py:767]   Expert 59 |    299 | GPU0(cuda:1)
DEBUG 01-07 10:13:58.544600.544600 lmp.py:767]   Expert 37 |    332 | GPU1(cuda:2)
DEBUG 01-07 10:13:58.544958.544958 lmp.py:767]   Expert 58 |    366 | GPU1(cuda:2)
DEBUG 01-07 10:13:58.544078.544078 lmp.py:767]   Expert  6 |    389 | GPU1(cuda:2)
DEBUG 01-07 10:13:58.544436.544436 lmp.py:767]   Expert 53 |    858 | GPU0(cuda:1)
DEBUG 01-07 10:13:58.544364.544364 lmp.py:769] 
DEBUG 01-07 10:13:58.544364.544364 lmp.py:769]   Device Token Distribution:
DEBUG 01-07 10:13:58.544484.544484 lmp.py:770]   CPU:   2046 tokens
DEBUG 01-07 10:13:58.544319.544319 lmp.py:774]   cuda:1:   5128 tokens (22 experts)
DEBUG 01-07 10:13:58.544200.544200 lmp.py:774]   cuda:2:   5114 tokens (23 experts)
DEBUG 01-07 10:13:58.544797.544797 lmp.py:775]   Total GPU:  10242 tokens
DEBUG 01-07 10:13:58.544678.544678 lmp.py:776] ============================================================
DEBUG 01-07 10:13:58.544678.544678 lmp.py:776] 
DEBUG 01-07 10:13:58.545997.545997 cuda_h.py:19] end experts_map_get cost 0.0017864704132080078 seconds
DEBUG 01-07 10:13:58.545984.545984 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model_multi_device
DEBUG 01-07 10:13:58.545661.545661 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 10:13:58.545380.545380 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 10:13:58.545308.545308 cuda_h.py:19] end allocate_cuda_memory cost 0.0001919269561767578 seconds
DEBUG 01-07 10:13:58.545940.545940 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 10:13:58.545504.545504 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 10:13:58.545313.545313 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 10:13:58.545440.545440 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, b9e2159f-1438-4ea0-9676-59c6b9556c0b
DEBUG 01-07 10:13:58.545789.545789 client.py:106] call stub.LoadModelAsync
INFO 01-07 10:13:58.545761.545761 client.py:127] Model loaded
DEBUG 01-07 10:13:58.546439.546439 cuda_h.py:19] end sllm_worker_task cost 0.008963823318481445 seconds
INFO 01-07 10:13:58.546184.546184 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, b9e2159f-1438-4ea0-9676-59c6b9556c0b
DEBUG 01-07 10:13:58.546406.546406 cuda_h.py:19] end load_into_gpu_async cost 0.0010116100311279297 seconds
DEBUG 01-07 10:13:58.546016.546016 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 10:13:58.546263.546263 cuda_h.py:19] end restore_tensors2 cost 0.00022673606872558594 seconds
DEBUG 01-07 10:13:58.546748.546748 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0017554759979248047 seconds
DEBUG 01-07 10:13:58.548684.548684 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 10:13:58.548767.548767 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 10:13:58.549676.549676 cuda_h.py:19] end allocate_cuda_memory cost 0.0002079010009765625 seconds
DEBUG 01-07 10:13:58.549996.549996 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 10:13:58.549037.549037 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 10:13:58.549654.549654 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 10:13:58.549688.549688 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 42206531-ceda-45fb-b202-fbf1177a51b3
DEBUG 01-07 10:13:58.549487.549487 client.py:106] call stub.LoadModelAsync
INFO 01-07 10:13:58.550251.550251 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 42206531-ceda-45fb-b202-fbf1177a51b3
DEBUG 01-07 10:13:58.550749.550749 cuda_h.py:19] end load_into_gpu_async cost 0.0010845661163330078 seconds
DEBUG 01-07 10:13:58.550545.550545 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 10:13:58.550672.550672 cuda_h.py:19] end restore_tensors2 cost 0.0002090930938720703 seconds
DEBUG 01-07 10:13:58.550918.550918 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0018041133880615234 seconds
DEBUG 01-07 10:13:58.552490.552490 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model_multi_device cost 0.0073664188385009766 seconds
DEBUG 01-07 10:13:58.552604.552604 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-07 10:13:58.552905.552905 lmp.py:816] 
DEBUG 01-07 10:13:58.552905.552905 lmp.py:816]   Computing 19 experts on CPU...
DEBUG 01-07 10:13:58.552364.552364 cuda_h.py:19] end cpu_experts_submit cost 0.00010991096496582031 seconds
DEBUG 01-07 10:13:58.552398.552398 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-07 10:13:58.558160.558160 mlpmodule.py:749] group tensors cost 0.005803108215332031 s
DEBUG 01-07 10:13:58.560458.560458 mlpmodule.py:787] pad cost 0.00167083740234375 s
DEBUG 01-07 10:13:58.561947.561947 mlpmodule.py:793] create cpu tensor cost 5.9604644775390625e-05 s
DEBUG 01-07 10:13:58.561951.561951 mlpmodule.py:798] move to cpu cost 4.553794860839844e-05 s
DEBUG 01-07 10:13:58.572005.572005 mlpmodule.py:812] group_w3: shape=torch.Size([19, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=54788096
DEBUG 01-07 10:13:58.572441.572441 mlpmodule.py:813] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-07 10:13:58.572068.572068 mlpmodule.py:818] group_w3 first element: -0.010498046875
WARNING 01-07 10:13:58.572357.572357 mlpmodule.py:828] start einsum2
DEBUG 01-07 10:13:58.592220.592220 mlpmodule.py:838] group einsum cost 0.03127455711364746 s
DEBUG 01-07 10:13:58.593770.593770 mlpmodule.py:846] cpy2cputensor cost 0.0004246234893798828 s
DEBUG 01-07 10:13:58.595081.595081 cuda_h.py:19] end wait_cetm_experts cost 0.04308271408081055 seconds
DEBUG 01-07 10:13:58.595388.595388 cuda_h.py:10] start gpu_sexperts
DEBUG 01-07 10:13:58.596355.596355 cuda_h.py:19] end gpu_sexperts cost 0.0005640983581542969 seconds
DEBUG 01-07 10:13:58.596483.596483 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-07 10:13:58.596856.596856 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.384185791015625e-05 seconds
DEBUG 01-07 10:13:58.596274.596274 cuda_h.py:10] start wait_experts_multi_device
INFO 01-07 10:13:58.596176.596176 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, b9e2159f-1438-4ea0-9676-59c6b9556c0b
INFO 01-07 10:13:58.597603.597603 client.py:127] Model loaded
INFO 01-07 10:13:58.597916.597916 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 42206531-ceda-45fb-b202-fbf1177a51b3
INFO 01-07 10:13:58.598798.598798 client.py:127] Model loaded
DEBUG 01-07 10:13:58.598204.598204 cuda_h.py:19] end wait_experts_multi_device cost 0.0014264583587646484 seconds
DEBUG 01-07 10:13:58.598053.598053 cuda_h.py:10] start gpu_experts_multi_device
DEBUG 01-07 10:13:58.598498.598498 lmp.py:867]   Computing 23 experts on cuda:2...
DEBUG 01-07 10:13:58.599206.599206 mlpmodule.py:533] gpu group tensors cost 0.0004968643188476562 s
DEBUG 01-07 10:13:58.600741.600741 mlpmodule.py:566] gpu pad cost 0.0012798309326171875 s
DEBUG 01-07 10:13:58.601608.601608 mlpmodule.py:584] gpu group einsum cost 0.0005304813385009766 s
DEBUG 01-07 10:13:58.603882.603882 mlpmodule.py:656] gpu experts func einsum cost 0.004472017288208008 s
DEBUG 01-07 10:13:58.603898.603898 lmp.py:867]   Computing 22 experts on cuda:1...
DEBUG 01-07 10:13:58.604087.604087 mlpmodule.py:533] gpu group tensors cost 0.00042557716369628906 s
DEBUG 01-07 10:13:58.605700.605700 mlpmodule.py:707]  experts func einsum cost 0.053201913833618164 s
DEBUG 01-07 10:13:58.607164.607164 mlpmodule.py:566] gpu pad cost 0.002837657928466797 s
DEBUG 01-07 10:13:58.608163.608163 mlpmodule.py:584] gpu group einsum cost 0.0008628368377685547 s
DEBUG 01-07 10:13:58.609059.609059 mlpmodule.py:656] gpu experts func einsum cost 0.00591731071472168 s
DEBUG 01-07 10:13:58.609797.609797 cuda_h.py:19] end gpu_experts_multi_device cost 0.01172018051147461 seconds
DEBUG 01-07 10:13:58.609098.609098 cuda_h.py:19] end layer_moe_generate_multi_device_5 cost 0.06749773025512695 seconds
DEBUG 01-07 10:13:58.610668.610668 lmp.py:194] -------------------------------- end prefill layer 5 --------------------------------
DEBUG 01-07 10:13:58.610583.610583 lmp.py:153] -------------------------------- start prefill layer 6 --------------------------------
DEBUG 01-07 10:13:58.610776.610776 cuda_h.py:10] start start_load_qkvogn_s_weight_l_7
DEBUG 01-07 10:13:58.610294.610294 cuda_h.py:10] start start_load_qkvogn_s_weight_l_7
DEBUG 01-07 10:13:58.610700.610700 cuda_h.py:19] end start_load_qkvogn_s_weight_l_7 cost 2.765655517578125e-05 seconds
DEBUG 01-07 10:13:58.610449.610449 cuda_h.py:19] end start_load_qkvogn_s_weight_l_7 cost 5.745887756347656e-05 seconds
DEBUG 01-07 10:13:58.610999.610999 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-07 10:13:58.610014.610014 cuda_h.py:10] start sllm_worker_task
DEBUG 01-07 10:13:58.610474.610474 mlpmodule.py:367] cuda:1 cuda:1
DEBUG 01-07 10:13:58.610144.610144 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 10:13:58.610155.610155 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 10:13:58.610447.610447 cuda_h.py:19] end allocate_cuda_memory cost 0.00017547607421875 seconds
DEBUG 01-07 10:13:58.610482.610482 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 10:13:58.610953.610953 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 10:13:58.611061.611061 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 10:13:58.611525.611525 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 3cf8da5a-2e36-4860-9279-55c0ac4da6fb
DEBUG 01-07 10:13:58.611720.611720 client.py:106] call stub.LoadModelAsync
DEBUG 01-07 10:13:58.611530.611530 cuda_h.py:10] start self_attn
INFO 01-07 10:13:58.611222.611222 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 3cf8da5a-2e36-4860-9279-55c0ac4da6fb
DEBUG 01-07 10:13:58.611965.611965 cuda_h.py:19] end load_into_gpu_async cost 0.0009560585021972656 seconds
DEBUG 01-07 10:13:58.611761.611761 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 10:13:58.612883.612883 cuda_h.py:19] end restore_tensors2 cost 6.461143493652344e-05 seconds
DEBUG 01-07 10:13:58.612447.612447 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.001432180404663086 seconds
INFO 01-07 10:13:58.612336.612336 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 3cf8da5a-2e36-4860-9279-55c0ac4da6fb
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-07 10:13:58.615184.615184 cuda_h.py:19] end self_attn cost 0.0036513805389404297 seconds
DEBUG 01-07 10:13:58.615075.615075 cuda_h.py:19] end iln_self_attn_paln cost 0.0050127506256103516 seconds
DEBUG 01-07 10:13:58.615474.615474 cuda_h.py:10] start layer_moe_generate_multi_device_6
DEBUG 01-07 10:13:58.615615.615615 cuda_h.py:10] start gate
DEBUG 01-07 10:13:58.616670.616670 cuda_h.py:19] end gate cost 0.0006372928619384766 seconds
DEBUG 01-07 10:13:58.616215.616215 cuda_h.py:10] start experts_map_get
DEBUG 01-07 10:13:58.616904.616904 lmp.py:744] 
DEBUG 01-07 10:13:58.616904.616904 lmp.py:744] Expert Token Distribution & Multi-Device Allocation:
DEBUG 01-07 10:13:58.616336.616336 lmp.py:745]   Total experts: 64
DEBUG 01-07 10:13:58.616131.616131 lmp.py:746]   CPU experts: 19 (30%)
DEBUG 01-07 10:13:58.616397.616397 lmp.py:747]   GPU experts: 45 (70%)
DEBUG 01-07 10:13:58.616517.616517 lmp.py:748]   Number of GPU devices: 2
DEBUG 01-07 10:13:58.616921.616921 lmp.py:749] 
DEBUG 01-07 10:13:58.616921.616921 lmp.py:749]   Expert ID | Tokens | Device
DEBUG 01-07 10:13:58.616564.616564 lmp.py:750]   -----------------------------------
DEBUG 01-07 10:13:58.616929.616929 lmp.py:767]   Expert  1 |     45 | CPU
DEBUG 01-07 10:13:58.616811.616811 lmp.py:767]   Expert  7 |     62 | CPU
DEBUG 01-07 10:13:58.616977.616977 lmp.py:767]   Expert 37 |     70 | CPU
DEBUG 01-07 10:13:58.616381.616381 lmp.py:767]   Expert 54 |     77 | CPU
DEBUG 01-07 10:13:58.616309.616309 lmp.py:767]   Expert 17 |     81 | CPU
DEBUG 01-07 10:13:58.616237.616237 lmp.py:767]   Expert 18 |     82 | CPU
DEBUG 01-07 10:13:58.616926.616926 lmp.py:767]   Expert  9 |     93 | CPU
DEBUG 01-07 10:13:58.616615.616615 lmp.py:767]   Expert 13 |     95 | CPU
DEBUG 01-07 10:13:58.616305.616305 lmp.py:767]   Expert 22 |    100 | CPU
DEBUG 01-07 10:13:58.616186.616186 lmp.py:767]   Expert 58 |    100 | CPU
DEBUG 01-07 10:13:58.616591.616591 lmp.py:767]   Expert  0 |    106 | CPU
DEBUG 01-07 10:13:58.616280.616280 lmp.py:767]   Expert 26 |    117 | CPU
DEBUG 01-07 10:13:58.616400.616400 lmp.py:767]   Expert 16 |    119 | CPU
DEBUG 01-07 10:13:58.616281.616281 lmp.py:767]   Expert 10 |    122 | CPU
DEBUG 01-07 10:13:58.617970.617970 lmp.py:767]   Expert 63 |    129 | CPU
DEBUG 01-07 10:13:58.617183.617183 lmp.py:767]   Expert 59 |    132 | CPU
DEBUG 01-07 10:13:58.617634.617634 lmp.py:767]   Expert 43 |    142 | CPU
DEBUG 01-07 10:13:58.617085.617085 lmp.py:767]   Expert 28 |    144 | CPU
DEBUG 01-07 10:13:58.617774.617774 lmp.py:767]   Expert 62 |    144 | CPU
DEBUG 01-07 10:13:58.617894.617894 lmp.py:767]   Expert 33 |    148 | GPU1(cuda:2)
DEBUG 01-07 10:13:58.617113.617113 lmp.py:767]   Expert 29 |    150 | GPU0(cuda:1)
DEBUG 01-07 10:13:58.617816.617816 lmp.py:767]   Expert  2 |    158 | GPU1(cuda:2)
DEBUG 01-07 10:13:58.617512.617512 lmp.py:767]   Expert 51 |    164 | GPU0(cuda:1)
DEBUG 01-07 10:13:58.617777.617777 lmp.py:767]   Expert 55 |    165 | GPU1(cuda:2)
DEBUG 01-07 10:13:58.617374.617374 lmp.py:767]   Expert 45 |    166 | GPU1(cuda:2)
DEBUG 01-07 10:13:58.617017.617017 lmp.py:767]   Expert 53 |    166 | GPU0(cuda:1)
DEBUG 01-07 10:13:58.617422.617422 lmp.py:767]   Expert  3 |    167 | GPU0(cuda:1)
DEBUG 01-07 10:13:58.617588.617588 lmp.py:767]   Expert 11 |    167 | GPU1(cuda:2)
DEBUG 01-07 10:13:58.617754.617754 lmp.py:767]   Expert 23 |    167 | GPU0(cuda:1)
DEBUG 01-07 10:13:58.617920.617920 lmp.py:767]   Expert 32 |    169 | GPU1(cuda:2)
DEBUG 01-07 10:13:58.617848.617848 lmp.py:767]   Expert 40 |    171 | GPU0(cuda:1)
DEBUG 01-07 10:13:58.617775.617775 lmp.py:767]   Expert 14 |    172 | GPU1(cuda:2)
DEBUG 01-07 10:13:58.617895.617895 lmp.py:767]   Expert 34 |    173 | GPU0(cuda:1)
DEBUG 01-07 10:13:58.617538.617538 lmp.py:767]   Expert 52 |    180 | GPU1(cuda:2)
DEBUG 01-07 10:13:58.617943.617943 lmp.py:767]   Expert 41 |    182 | GPU0(cuda:1)
DEBUG 01-07 10:13:58.617586.617586 lmp.py:767]   Expert 42 |    183 | GPU1(cuda:2)
DEBUG 01-07 10:13:58.617990.617990 lmp.py:767]   Expert 21 |    186 | GPU0(cuda:1)
DEBUG 01-07 10:13:58.617918.617918 lmp.py:767]   Expert 57 |    195 | GPU1(cuda:2)
DEBUG 01-07 10:13:58.617607.617607 lmp.py:767]   Expert 30 |    199 | GPU0(cuda:1)
DEBUG 01-07 10:13:58.617535.617535 lmp.py:767]   Expert 15 |    200 | GPU1(cuda:2)
DEBUG 01-07 10:13:58.617986.617986 lmp.py:767]   Expert 35 |    208 | GPU0(cuda:1)
DEBUG 01-07 10:13:58.617914.617914 lmp.py:767]   Expert 12 |    217 | GPU1(cuda:2)
DEBUG 01-07 10:13:58.617603.617603 lmp.py:767]   Expert  4 |    219 | GPU0(cuda:1)
DEBUG 01-07 10:13:58.617292.617292 lmp.py:767]   Expert 46 |    229 | GPU0(cuda:1)
DEBUG 01-07 10:13:58.617220.617220 lmp.py:767]   Expert 50 |    229 | GPU1(cuda:2)
DEBUG 01-07 10:13:58.617386.617386 lmp.py:767]   Expert 19 |    231 | GPU0(cuda:1)
DEBUG 01-07 10:13:58.617314.617314 lmp.py:767]   Expert 24 |    231 | GPU1(cuda:2)
DEBUG 01-07 10:13:58.617003.617003 lmp.py:767]   Expert 49 |    233 | GPU1(cuda:2)
DEBUG 01-07 10:13:58.617169.617169 lmp.py:767]   Expert 44 |    236 | GPU0(cuda:1)
DEBUG 01-07 10:13:58.617574.617574 lmp.py:767]   Expert 38 |    237 | GPU1(cuda:2)
DEBUG 01-07 10:13:58.617978.617978 lmp.py:767]   Expert  8 |    238 | GPU0(cuda:1)
DEBUG 01-07 10:13:58.617860.617860 lmp.py:767]   Expert  6 |    246 | GPU1(cuda:2)
DEBUG 01-07 10:13:58.617980.617980 lmp.py:767]   Expert 47 |    249 | GPU0(cuda:1)
DEBUG 01-07 10:13:58.617146.617146 lmp.py:767]   Expert 31 |    256 | GPU1(cuda:2)
DEBUG 01-07 10:13:58.617789.617789 lmp.py:767]   Expert 61 |    263 | GPU0(cuda:1)
DEBUG 01-07 10:13:58.617909.617909 lmp.py:767]   Expert 39 |    278 | GPU1(cuda:2)
DEBUG 01-07 10:13:58.617552.617552 lmp.py:767]   Expert  5 |    303 | GPU0(cuda:1)
DEBUG 01-07 10:13:58.617195.617195 lmp.py:767]   Expert 27 |    306 | GPU0(cuda:1)
DEBUG 01-07 10:13:58.617553.617553 lmp.py:767]   Expert 36 |    306 | GPU1(cuda:2)
DEBUG 01-07 10:13:58.617196.617196 lmp.py:767]   Expert 60 |    331 | GPU1(cuda:2)
DEBUG 01-07 10:13:58.617316.617316 lmp.py:767]   Expert 20 |    337 | GPU0(cuda:1)
DEBUG 01-07 10:13:58.617674.617674 lmp.py:767]   Expert 48 |    365 | GPU1(cuda:2)
DEBUG 01-07 10:13:58.617794.617794 lmp.py:767]   Expert 25 |    398 | GPU1(cuda:2)
DEBUG 01-07 10:13:58.617152.617152 lmp.py:767]   Expert 56 |    554 | GPU0(cuda:1)
DEBUG 01-07 10:13:58.617556.617556 lmp.py:769] 
DEBUG 01-07 10:13:58.617556.617556 lmp.py:769]   Device Token Distribution:
DEBUG 01-07 10:13:58.617438.617438 lmp.py:770]   CPU:   1960 tokens
DEBUG 01-07 10:13:58.617034.617034 lmp.py:774]   cuda:1:   5098 tokens (22 experts)
DEBUG 01-07 10:13:58.617393.617393 lmp.py:774]   cuda:2:   5230 tokens (23 experts)
DEBUG 01-07 10:13:58.617036.617036 lmp.py:775]   Total GPU:  10328 tokens
DEBUG 01-07 10:13:58.617202.617202 lmp.py:776] ============================================================
DEBUG 01-07 10:13:58.617202.617202 lmp.py:776] 
DEBUG 01-07 10:13:58.618044.618044 cuda_h.py:19] end experts_map_get cost 0.0017750263214111328 seconds
DEBUG 01-07 10:13:58.618071.618071 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model_multi_device
DEBUG 01-07 10:13:58.618986.618986 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 10:13:58.618221.618221 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 10:13:58.618926.618926 cuda_h.py:19] end allocate_cuda_memory cost 0.00023889541625976562 seconds
DEBUG 01-07 10:13:58.618438.618438 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 10:13:58.618240.618240 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 10:13:58.618957.618957 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 10:13:58.618799.618799 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, ea889314-f2c5-4c5e-9283-6d72c5d3b86f
DEBUG 01-07 10:13:58.618081.618081 client.py:106] call stub.LoadModelAsync
INFO 01-07 10:13:58.619786.619786 client.py:127] Model loaded
INFO 01-07 10:13:58.619388.619388 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, ea889314-f2c5-4c5e-9283-6d72c5d3b86f
DEBUG 01-07 10:13:58.619992.619992 cuda_h.py:19] end load_into_gpu_async cost 0.0009033679962158203 seconds
DEBUG 01-07 10:13:58.619265.619265 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 10:13:58.619982.619982 cuda_h.py:19] end restore_tensors2 cost 0.00022292137145996094 seconds
DEBUG 01-07 10:13:58.619844.619844 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0016627311706542969 seconds
DEBUG 01-07 10:13:58.620875.620875 cuda_h.py:19] end sllm_worker_task cost 0.009562969207763672 seconds
DEBUG 01-07 10:13:58.621391.621391 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 10:13:58.621276.621276 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 10:13:58.622171.622171 cuda_h.py:19] end allocate_cuda_memory cost 0.00019979476928710938 seconds
DEBUG 01-07 10:13:58.622014.622014 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 10:13:58.622532.622532 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 10:13:58.622910.622910 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 10:13:58.622514.622514 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 88d3db3b-5c2d-4c14-b87e-5ad6d4fc7b52
DEBUG 01-07 10:13:58.622743.622743 client.py:106] call stub.LoadModelAsync
INFO 01-07 10:13:58.623963.623963 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 88d3db3b-5c2d-4c14-b87e-5ad6d4fc7b52
DEBUG 01-07 10:13:58.623839.623839 cuda_h.py:19] end load_into_gpu_async cost 0.0010666847229003906 seconds
DEBUG 01-07 10:13:58.623681.623681 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 10:13:58.623371.623371 cuda_h.py:19] end restore_tensors2 cost 0.0002033710479736328 seconds
DEBUG 01-07 10:13:58.623663.623663 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.001760244369506836 seconds
DEBUG 01-07 10:13:58.625216.625216 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model_multi_device cost 0.007488727569580078 seconds
DEBUG 01-07 10:13:58.625231.625231 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-07 10:13:58.625817.625817 lmp.py:816] 
DEBUG 01-07 10:13:58.625817.625817 lmp.py:816]   Computing 19 experts on CPU...
DEBUG 01-07 10:13:58.625607.625607 cuda_h.py:19] end cpu_experts_submit cost 0.00010704994201660156 seconds
DEBUG 01-07 10:13:58.625687.625687 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-07 10:13:58.631947.631947 mlpmodule.py:749] group tensors cost 0.005644798278808594 s
DEBUG 01-07 10:13:58.633482.633482 mlpmodule.py:787] pad cost 0.0014681816101074219 s
DEBUG 01-07 10:13:58.633566.633566 mlpmodule.py:793] create cpu tensor cost 5.269050598144531e-05 s
DEBUG 01-07 10:13:58.633933.633933 mlpmodule.py:798] move to cpu cost 4.100799560546875e-05 s
DEBUG 01-07 10:13:58.645584.645584 mlpmodule.py:812] group_w3: shape=torch.Size([19, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=54788096
DEBUG 01-07 10:13:58.645619.645619 mlpmodule.py:813] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-07 10:13:58.645664.645664 mlpmodule.py:818] group_w3 first element: -0.003631591796875
WARNING 01-07 10:13:58.645629.645629 mlpmodule.py:828] start einsum2
DEBUG 01-07 10:13:58.665715.665715 mlpmodule.py:838] group einsum cost 0.03116893768310547 s
DEBUG 01-07 10:13:58.665255.665255 mlpmodule.py:846] cpy2cputensor cost 0.0004851818084716797 s
DEBUG 01-07 10:13:58.668254.668254 cuda_h.py:19] end wait_cetm_experts cost 0.0426023006439209 seconds
DEBUG 01-07 10:13:58.668555.668555 cuda_h.py:10] start gpu_sexperts
DEBUG 01-07 10:13:58.669699.669699 cuda_h.py:19] end gpu_sexperts cost 0.0004839897155761719 seconds
DEBUG 01-07 10:13:58.669489.669489 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-07 10:13:58.669954.669954 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.3365020751953125e-05 seconds
DEBUG 01-07 10:13:58.669134.669134 cuda_h.py:10] start wait_experts_multi_device
INFO 01-07 10:13:58.669367.669367 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, ea889314-f2c5-4c5e-9283-6d72c5d3b86f
INFO 01-07 10:13:58.670615.670615 client.py:127] Model loaded
INFO 01-07 10:13:58.670472.670472 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 88d3db3b-5c2d-4c14-b87e-5ad6d4fc7b52
INFO 01-07 10:13:58.670235.670235 client.py:127] Model loaded
DEBUG 01-07 10:13:58.670522.670522 cuda_h.py:19] end wait_experts_multi_device cost 0.0014843940734863281 seconds
DEBUG 01-07 10:13:58.670755.670755 cuda_h.py:10] start gpu_experts_multi_device
DEBUG 01-07 10:13:58.670962.670962 lmp.py:867]   Computing 23 experts on cuda:2...
DEBUG 01-07 10:13:58.671365.671365 mlpmodule.py:533] gpu group tensors cost 0.0004916191101074219 s
DEBUG 01-07 10:13:58.673455.673455 mlpmodule.py:566] gpu pad cost 0.0012712478637695312 s
DEBUG 01-07 10:13:58.673144.673144 mlpmodule.py:584] gpu group einsum cost 0.0005087852478027344 s
DEBUG 01-07 10:13:58.675734.675734 mlpmodule.py:656] gpu experts func einsum cost 0.004416227340698242 s
DEBUG 01-07 10:13:58.676254.676254 lmp.py:867]   Computing 22 experts on cuda:1...
DEBUG 01-07 10:13:58.676423.676423 mlpmodule.py:533] gpu group tensors cost 0.0004553794860839844 s
DEBUG 01-07 10:13:58.678564.678564 mlpmodule.py:566] gpu pad cost 0.0011715888977050781 s
DEBUG 01-07 10:13:58.678997.678997 mlpmodule.py:707]  experts func einsum cost 0.05247139930725098 s
DEBUG 01-07 10:13:58.678180.678180 mlpmodule.py:584] gpu group einsum cost 0.0005261898040771484 s
DEBUG 01-07 10:13:58.680490.680490 mlpmodule.py:656] gpu experts func einsum cost 0.004226207733154297 s
DEBUG 01-07 10:13:58.680950.680950 cuda_h.py:19] end gpu_experts_multi_device cost 0.009942054748535156 seconds
DEBUG 01-07 10:13:58.680489.680489 cuda_h.py:19] end layer_moe_generate_multi_device_6 cost 0.06528949737548828 seconds
DEBUG 01-07 10:13:58.681736.681736 lmp.py:194] -------------------------------- end prefill layer 6 --------------------------------
DEBUG 01-07 10:13:58.681221.681221 lmp.py:153] -------------------------------- start prefill layer 7 --------------------------------
DEBUG 01-07 10:13:58.681685.681685 cuda_h.py:10] start start_load_qkvogn_s_weight_l_8
DEBUG 01-07 10:13:58.681733.681733 cuda_h.py:10] start start_load_qkvogn_s_weight_l_8
DEBUG 01-07 10:13:58.681060.681060 cuda_h.py:19] end start_load_qkvogn_s_weight_l_8 cost 3.457069396972656e-05 seconds
DEBUG 01-07 10:13:58.681385.681385 cuda_h.py:19] end start_load_qkvogn_s_weight_l_8 cost 6.723403930664062e-05 seconds
DEBUG 01-07 10:13:58.681412.681412 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-07 10:13:58.681110.681110 mlpmodule.py:367] cuda:1 cuda:1
DEBUG 01-07 10:13:58.681721.681721 cuda_h.py:10] start sllm_worker_task
DEBUG 01-07 10:13:58.681001.681001 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 10:13:58.681447.681447 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 10:13:58.681073.681073 cuda_h.py:19] end allocate_cuda_memory cost 0.0002875328063964844 seconds
DEBUG 01-07 10:13:58.681784.681784 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 10:13:58.681732.681732 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 10:13:58.681409.681409 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 10:13:58.681443.681443 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, e0284423-6537-4d77-baa5-6fdff3dbbe86
DEBUG 01-07 10:13:58.682591.682591 client.py:106] call stub.LoadModelAsync
DEBUG 01-07 10:13:58.682323.682323 cuda_h.py:10] start self_attn
INFO 01-07 10:13:58.682766.682766 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, e0284423-6537-4d77-baa5-6fdff3dbbe86
DEBUG 01-07 10:13:58.682741.682741 cuda_h.py:19] end load_into_gpu_async cost 0.0010590553283691406 seconds
DEBUG 01-07 10:13:58.682822.682822 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 10:13:58.683328.683328 cuda_h.py:19] end restore_tensors2 cost 6.747245788574219e-05 seconds
DEBUG 01-07 10:13:58.683654.683654 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0016455650329589844 seconds
INFO 01-07 10:13:58.683437.683437 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, e0284423-6537-4d77-baa5-6fdff3dbbe86
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-07 10:13:58.686628.686628 cuda_h.py:19] end self_attn cost 0.0037081241607666016 seconds
DEBUG 01-07 10:13:58.686010.686010 cuda_h.py:19] end iln_self_attn_paln cost 0.005151033401489258 seconds
DEBUG 01-07 10:13:58.686131.686131 cuda_h.py:10] start layer_moe_generate_multi_device_7
DEBUG 01-07 10:13:58.686509.686509 cuda_h.py:10] start gate
DEBUG 01-07 10:13:58.687088.687088 cuda_h.py:19] end gate cost 0.0006401538848876953 seconds
DEBUG 01-07 10:13:58.687057.687057 cuda_h.py:10] start experts_map_get
DEBUG 01-07 10:13:58.687633.687633 lmp.py:744] 
DEBUG 01-07 10:13:58.687633.687633 lmp.py:744] Expert Token Distribution & Multi-Device Allocation:
DEBUG 01-07 10:13:58.687296.687296 lmp.py:745]   Total experts: 64
DEBUG 01-07 10:13:58.687853.687853 lmp.py:746]   CPU experts: 19 (30%)
DEBUG 01-07 10:13:58.687119.687119 lmp.py:747]   GPU experts: 45 (70%)
DEBUG 01-07 10:13:58.687954.687954 lmp.py:748]   Number of GPU devices: 2
DEBUG 01-07 10:13:58.687073.687073 lmp.py:749] 
DEBUG 01-07 10:13:58.687073.687073 lmp.py:749]   Expert ID | Tokens | Device
DEBUG 01-07 10:13:58.687432.687432 lmp.py:750]   -----------------------------------
DEBUG 01-07 10:13:58.687227.687227 lmp.py:767]   Expert 50 |     44 | CPU
DEBUG 01-07 10:13:58.687347.687347 lmp.py:767]   Expert  3 |     53 | CPU
DEBUG 01-07 10:13:58.687752.687752 lmp.py:767]   Expert 46 |     55 | CPU
DEBUG 01-07 10:13:58.687395.687395 lmp.py:767]   Expert  1 |     79 | CPU
DEBUG 01-07 10:13:58.687799.687799 lmp.py:767]   Expert  4 |     87 | CPU
DEBUG 01-07 10:13:58.687965.687965 lmp.py:767]   Expert 29 |     88 | CPU
DEBUG 01-07 10:13:58.687893.687893 lmp.py:767]   Expert 40 |     94 | CPU
DEBUG 01-07 10:13:58.687059.687059 lmp.py:767]   Expert 15 |     95 | CPU
DEBUG 01-07 10:13:58.687464.687464 lmp.py:767]   Expert  8 |    109 | CPU
DEBUG 01-07 10:13:58.687107.687107 lmp.py:767]   Expert 41 |    112 | CPU
DEBUG 01-07 10:13:58.687511.687511 lmp.py:767]   Expert 28 |    114 | CPU
DEBUG 01-07 10:13:58.687154.687154 lmp.py:767]   Expert 16 |    126 | CPU
DEBUG 01-07 10:13:58.687797.687797 lmp.py:767]   Expert 27 |    128 | CPU
DEBUG 01-07 10:13:58.688679.688679 lmp.py:767]   Expert 48 |    129 | CPU
DEBUG 01-07 10:13:58.688845.688845 lmp.py:767]   Expert  6 |    130 | CPU
DEBUG 01-07 10:13:58.688772.688772 lmp.py:767]   Expert 13 |    131 | CPU
DEBUG 01-07 10:13:58.688462.688462 lmp.py:767]   Expert  7 |    133 | CPU
DEBUG 01-07 10:13:58.688389.688389 lmp.py:767]   Expert 54 |    135 | CPU
DEBUG 01-07 10:13:58.688079.688079 lmp.py:767]   Expert 51 |    138 | CPU
DEBUG 01-07 10:13:58.688437.688437 lmp.py:767]   Expert 18 |    140 | GPU0(cuda:1)
DEBUG 01-07 10:13:58.688557.688557 lmp.py:767]   Expert 60 |    140 | GPU0(cuda:1)
DEBUG 01-07 10:13:58.688869.688869 lmp.py:767]   Expert 39 |    141 | GPU1(cuda:2)
DEBUG 01-07 10:13:58.688942.688942 lmp.py:767]   Expert 56 |    145 | GPU1(cuda:2)
DEBUG 01-07 10:13:58.688539.688539 lmp.py:767]   Expert 14 |    146 | GPU0(cuda:1)
DEBUG 01-07 10:13:58.688135.688135 lmp.py:767]   Expert 43 |    146 | GPU0(cuda:1)
DEBUG 01-07 10:13:58.688494.688494 lmp.py:767]   Expert 20 |    148 | GPU1(cuda:2)
DEBUG 01-07 10:13:58.688375.688375 lmp.py:767]   Expert 52 |    149 | GPU1(cuda:2)
DEBUG 01-07 10:13:58.688018.688018 lmp.py:767]   Expert 55 |    151 | GPU0(cuda:1)
DEBUG 01-07 10:13:58.688661.688661 lmp.py:767]   Expert 36 |    152 | GPU1(cuda:2)
DEBUG 01-07 10:13:58.688542.688542 lmp.py:767]   Expert 45 |    155 | GPU0(cuda:1)
DEBUG 01-07 10:13:58.688185.688185 lmp.py:767]   Expert 10 |    156 | GPU1(cuda:2)
DEBUG 01-07 10:13:58.688828.688828 lmp.py:767]   Expert 11 |    157 | GPU0(cuda:1)
DEBUG 01-07 10:13:58.688710.688710 lmp.py:767]   Expert  5 |    159 | GPU0(cuda:1)
DEBUG 01-07 10:13:58.688353.688353 lmp.py:767]   Expert 62 |    165 | GPU1(cuda:2)
DEBUG 01-07 10:13:58.688234.688234 lmp.py:767]   Expert 57 |    172 | GPU1(cuda:2)
DEBUG 01-07 10:13:58.688745.688745 lmp.py:767]   Expert 33 |    177 | GPU0(cuda:1)
DEBUG 01-07 10:13:58.688342.688342 lmp.py:767]   Expert 44 |    178 | GPU1(cuda:2)
DEBUG 01-07 10:13:58.688700.688700 lmp.py:767]   Expert 58 |    181 | GPU0(cuda:1)
DEBUG 01-07 10:13:58.688343.688343 lmp.py:767]   Expert 53 |    183 | GPU1(cuda:2)
DEBUG 01-07 10:13:58.688463.688463 lmp.py:767]   Expert 25 |    184 | GPU0(cuda:1)
DEBUG 01-07 10:13:58.688867.688867 lmp.py:767]   Expert 32 |    189 | GPU1(cuda:2)
DEBUG 01-07 10:13:58.688510.688510 lmp.py:767]   Expert  2 |    192 | GPU0(cuda:1)
DEBUG 01-07 10:13:58.688153.688153 lmp.py:767]   Expert 35 |    200 | GPU0(cuda:1)
DEBUG 01-07 10:13:58.688796.688796 lmp.py:767]   Expert 63 |    200 | GPU1(cuda:2)
DEBUG 01-07 10:13:58.688439.688439 lmp.py:767]   Expert 31 |    201 | GPU1(cuda:2)
DEBUG 01-07 10:13:58.688844.688844 lmp.py:767]   Expert 21 |    203 | GPU0(cuda:1)
DEBUG 01-07 10:13:58.688248.688248 lmp.py:767]   Expert 49 |    205 | GPU1(cuda:2)
DEBUG 01-07 10:13:58.688653.688653 lmp.py:767]   Expert 17 |    209 | GPU0(cuda:1)
DEBUG 01-07 10:13:58.688057.688057 lmp.py:767]   Expert 42 |    221 | GPU1(cuda:2)
DEBUG 01-07 10:13:58.688700.688700 lmp.py:767]   Expert 34 |    223 | GPU0(cuda:1)
DEBUG 01-07 10:13:58.688297.688297 lmp.py:767]   Expert 37 |    227 | GPU1(cuda:2)
DEBUG 01-07 10:13:58.688894.688894 lmp.py:767]   Expert 59 |    232 | GPU0(cuda:1)
DEBUG 01-07 10:13:58.688252.688252 lmp.py:767]   Expert  0 |    239 | GPU1(cuda:2)
DEBUG 01-07 10:13:58.688372.688372 lmp.py:767]   Expert 22 |    241 | GPU0(cuda:1)
DEBUG 01-07 10:13:58.688015.688015 lmp.py:767]   Expert 19 |    257 | GPU0(cuda:1)
DEBUG 01-07 10:13:58.688134.688134 lmp.py:767]   Expert 24 |    286 | GPU1(cuda:2)
DEBUG 01-07 10:13:58.688539.688539 lmp.py:767]   Expert 61 |    289 | GPU0(cuda:1)
DEBUG 01-07 10:13:58.688943.688943 lmp.py:767]   Expert 30 |    301 | GPU1(cuda:2)
DEBUG 01-07 10:13:58.688586.688586 lmp.py:767]   Expert 47 |    320 | GPU1(cuda:2)
DEBUG 01-07 10:13:58.688753.688753 lmp.py:767]   Expert 38 |    366 | GPU0(cuda:1)
DEBUG 01-07 10:13:58.688634.688634 lmp.py:767]   Expert 26 |    372 | GPU0(cuda:1)
DEBUG 01-07 10:13:58.688039.688039 lmp.py:767]   Expert 12 |    425 | GPU1(cuda:2)
DEBUG 01-07 10:13:58.688681.688681 lmp.py:767]   Expert  9 |    681 | GPU1(cuda:2)
DEBUG 01-07 10:13:58.688278.688278 lmp.py:767]   Expert 23 |    704 | GPU0(cuda:1)
DEBUG 01-07 10:13:58.688444.688444 lmp.py:769] 
DEBUG 01-07 10:13:58.688444.688444 lmp.py:769]   Device Token Distribution:
DEBUG 01-07 10:13:58.688326.688326 lmp.py:770]   CPU:   1980 tokens
DEBUG 01-07 10:13:58.688161.688161 lmp.py:774]   cuda:1:   5224 tokens (23 experts)
DEBUG 01-07 10:13:58.688804.688804 lmp.py:774]   cuda:2:   5084 tokens (22 experts)
DEBUG 01-07 10:13:58.688493.688493 lmp.py:775]   Total GPU:  10308 tokens
DEBUG 01-07 10:13:58.689182.689182 lmp.py:776] ============================================================
DEBUG 01-07 10:13:58.689182.689182 lmp.py:776] 
DEBUG 01-07 10:13:58.689070.689070 cuda_h.py:19] end experts_map_get cost 0.0017726421356201172 seconds
DEBUG 01-07 10:13:58.689952.689952 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model_multi_device
DEBUG 01-07 10:13:58.689298.689298 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 10:13:58.689341.689341 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 10:13:58.689209.689209 cuda_h.py:19] end allocate_cuda_memory cost 0.0001876354217529297 seconds
DEBUG 01-07 10:13:58.689191.689191 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 10:13:58.689563.689563 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 10:13:58.689326.689326 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 10:13:58.689929.689929 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, c4dbe148-22d1-4fd3-8119-6d5688337e08
DEBUG 01-07 10:13:58.689649.689649 client.py:106] call stub.LoadModelAsync
INFO 01-07 10:13:58.689495.689495 client.py:127] Model loaded
DEBUG 01-07 10:13:58.690090.690090 cuda_h.py:19] end sllm_worker_task cost 0.008774280548095703 seconds
INFO 01-07 10:13:58.690268.690268 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, c4dbe148-22d1-4fd3-8119-6d5688337e08
DEBUG 01-07 10:13:58.690912.690912 cuda_h.py:19] end load_into_gpu_async cost 0.0009219646453857422 seconds
DEBUG 01-07 10:13:58.690992.690992 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 10:13:58.690093.690093 cuda_h.py:19] end restore_tensors2 cost 0.00022673606872558594 seconds
DEBUG 01-07 10:13:58.690194.690194 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0016231536865234375 seconds
DEBUG 01-07 10:13:58.692906.692906 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 10:13:58.692824.692824 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 10:13:58.692918.692918 cuda_h.py:19] end allocate_cuda_memory cost 0.00020694732666015625 seconds
DEBUG 01-07 10:13:58.693900.693900 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 10:13:58.693941.693941 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 10:13:58.693035.693035 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 10:13:58.693400.693400 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, ae1e2d2d-872f-4252-a2b8-7df907f42e9c
DEBUG 01-07 10:13:58.693000.693000 client.py:106] call stub.LoadModelAsync
INFO 01-07 10:13:58.693427.693427 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, ae1e2d2d-872f-4252-a2b8-7df907f42e9c
DEBUG 01-07 10:13:58.693157.693157 cuda_h.py:19] end load_into_gpu_async cost 0.0008947849273681641 seconds
DEBUG 01-07 10:13:58.693952.693952 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 10:13:58.694145.694145 cuda_h.py:19] end restore_tensors2 cost 0.0001876354217529297 seconds
DEBUG 01-07 10:13:58.694292.694292 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0015714168548583984 seconds
DEBUG 01-07 10:13:58.695469.695469 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model_multi_device cost 0.006921052932739258 seconds
DEBUG 01-07 10:13:58.696861.696861 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-07 10:13:58.696394.696394 lmp.py:816] 
DEBUG 01-07 10:13:58.696394.696394 lmp.py:816]   Computing 19 experts on CPU...
DEBUG 01-07 10:13:58.696661.696661 cuda_h.py:19] end cpu_experts_submit cost 0.0001049041748046875 seconds
DEBUG 01-07 10:13:58.696218.696218 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-07 10:13:58.701699.701699 mlpmodule.py:749] group tensors cost 0.005518674850463867 s
DEBUG 01-07 10:13:58.704261.704261 mlpmodule.py:787] pad cost 0.0014476776123046875 s
DEBUG 01-07 10:13:58.704723.704723 mlpmodule.py:793] create cpu tensor cost 5.340576171875e-05 s
DEBUG 01-07 10:13:58.704375.704375 mlpmodule.py:798] move to cpu cost 4.172325134277344e-05 s
DEBUG 01-07 10:13:58.715806.715806 mlpmodule.py:812] group_w3: shape=torch.Size([19, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=54788096
DEBUG 01-07 10:13:58.715728.715728 mlpmodule.py:813] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-07 10:13:58.715766.715766 mlpmodule.py:818] group_w3 first element: 0.01263427734375
WARNING 01-07 10:13:58.715208.715208 mlpmodule.py:828] start einsum2
DEBUG 01-07 10:13:58.735531.735531 mlpmodule.py:838] group einsum cost 0.03127121925354004 s
DEBUG 01-07 10:13:58.736745.736745 mlpmodule.py:846] cpy2cputensor cost 0.00044035911560058594 s
DEBUG 01-07 10:13:58.738834.738834 cuda_h.py:19] end wait_cetm_experts cost 0.04265189170837402 seconds
DEBUG 01-07 10:13:58.739234.739234 cuda_h.py:10] start gpu_sexperts
DEBUG 01-07 10:13:58.739789.739789 cuda_h.py:19] end gpu_sexperts cost 0.0005054473876953125 seconds
DEBUG 01-07 10:13:58.739771.739771 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-07 10:13:58.739237.739237 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.4080276489257812e-05 seconds
DEBUG 01-07 10:13:58.739655.739655 cuda_h.py:10] start wait_experts_multi_device
INFO 01-07 10:13:58.739080.739080 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, c4dbe148-22d1-4fd3-8119-6d5688337e08
INFO 01-07 10:13:58.740182.740182 client.py:127] Model loaded
INFO 01-07 10:13:58.740403.740403 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, ae1e2d2d-872f-4252-a2b8-7df907f42e9c
INFO 01-07 10:13:58.741754.741754 client.py:127] Model loaded
DEBUG 01-07 10:13:58.741629.741629 cuda_h.py:19] end wait_experts_multi_device cost 0.0013895034790039062 seconds
DEBUG 01-07 10:13:58.741578.741578 cuda_h.py:10] start gpu_experts_multi_device
DEBUG 01-07 10:13:58.741500.741500 lmp.py:867]   Computing 22 experts on cuda:2...
DEBUG 01-07 10:13:58.742590.742590 mlpmodule.py:533] gpu group tensors cost 0.00047206878662109375 s
DEBUG 01-07 10:13:58.743600.743600 mlpmodule.py:566] gpu pad cost 0.0012102127075195312 s
DEBUG 01-07 10:13:58.744176.744176 mlpmodule.py:584] gpu group einsum cost 0.0005300045013427734 s
DEBUG 01-07 10:13:58.746978.746978 mlpmodule.py:656] gpu experts func einsum cost 0.004339694976806641 s
DEBUG 01-07 10:13:58.746020.746020 lmp.py:867]   Computing 23 experts on cuda:1...
DEBUG 01-07 10:13:58.747442.747442 mlpmodule.py:533] gpu group tensors cost 0.00044846534729003906 s
DEBUG 01-07 10:13:58.748885.748885 mlpmodule.py:566] gpu pad cost 0.0012867450714111328 s
DEBUG 01-07 10:13:58.749291.749291 mlpmodule.py:707]  experts func einsum cost 0.05270886421203613 s
DEBUG 01-07 10:13:58.749063.749063 mlpmodule.py:584] gpu group einsum cost 0.0005083084106445312 s
DEBUG 01-07 10:13:58.751144.751144 mlpmodule.py:656] gpu experts func einsum cost 0.004407167434692383 s
DEBUG 01-07 10:13:58.751989.751989 cuda_h.py:19] end gpu_experts_multi_device cost 0.010067939758300781 seconds
DEBUG 01-07 10:13:58.751766.751766 cuda_h.py:19] end layer_moe_generate_multi_device_7 cost 0.0648341178894043 seconds
DEBUG 01-07 10:13:58.751715.751715 lmp.py:194] -------------------------------- end prefill layer 7 --------------------------------
DEBUG 01-07 10:13:58.751200.751200 lmp.py:153] -------------------------------- start prefill layer 8 --------------------------------
DEBUG 01-07 10:13:58.751518.751518 cuda_h.py:10] start start_load_qkvogn_s_weight_l_9
DEBUG 01-07 10:13:58.751612.751612 cuda_h.py:10] start start_load_qkvogn_s_weight_l_9
DEBUG 01-07 10:13:58.751110.751110 cuda_h.py:19] end start_load_qkvogn_s_weight_l_9 cost 2.6464462280273438e-05 seconds
DEBUG 01-07 10:13:58.751529.751529 cuda_h.py:19] end start_load_qkvogn_s_weight_l_9 cost 5.7220458984375e-05 seconds
DEBUG 01-07 10:13:58.751794.751794 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-07 10:13:58.751160.751160 mlpmodule.py:367] cuda:1 cuda:1
DEBUG 01-07 10:13:58.751726.751726 cuda_h.py:10] start sllm_worker_task
DEBUG 01-07 10:13:58.751880.751880 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 10:13:58.752333.752333 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 10:13:58.752019.752019 cuda_h.py:19] end allocate_cuda_memory cost 0.0002956390380859375 seconds
DEBUG 01-07 10:13:58.752201.752201 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 10:13:58.752772.752772 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 10:13:58.752356.752356 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 10:13:58.752675.752675 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, b79003ee-14e1-4072-984b-cdd92a4e176b
DEBUG 01-07 10:13:58.752684.752684 client.py:106] call stub.LoadModelAsync
DEBUG 01-07 10:13:58.752937.752937 cuda_h.py:10] start self_attn
INFO 01-07 10:13:58.753488.753488 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, b79003ee-14e1-4072-984b-cdd92a4e176b
DEBUG 01-07 10:13:58.753370.753370 cuda_h.py:19] end load_into_gpu_async cost 0.0008623600006103516 seconds
DEBUG 01-07 10:13:58.753404.753404 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 10:13:58.753957.753957 cuda_h.py:19] end restore_tensors2 cost 6.67572021484375e-05 seconds
DEBUG 01-07 10:13:58.753283.753283 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0014948844909667969 seconds
INFO 01-07 10:13:58.753165.753165 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, b79003ee-14e1-4072-984b-cdd92a4e176b
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-07 10:13:58.756770.756770 cuda_h.py:19] end self_attn cost 0.0036773681640625 seconds
DEBUG 01-07 10:13:58.756509.756509 cuda_h.py:19] end iln_self_attn_paln cost 0.005097627639770508 seconds
DEBUG 01-07 10:13:58.756815.756815 cuda_h.py:10] start layer_moe_generate_multi_device_8
DEBUG 01-07 10:13:58.756909.756909 cuda_h.py:10] start gate
DEBUG 01-07 10:13:58.757388.757388 cuda_h.py:19] end gate cost 0.0006375312805175781 seconds
DEBUG 01-07 10:13:58.757026.757026 cuda_h.py:10] start experts_map_get
DEBUG 01-07 10:13:58.758662.758662 lmp.py:744] 
DEBUG 01-07 10:13:58.758662.758662 lmp.py:744] Expert Token Distribution & Multi-Device Allocation:
DEBUG 01-07 10:13:58.758008.758008 lmp.py:745]   Total experts: 64
DEBUG 01-07 10:13:58.758042.758042 lmp.py:746]   CPU experts: 19 (30%)
DEBUG 01-07 10:13:58.758069.758069 lmp.py:747]   GPU experts: 45 (70%)
DEBUG 01-07 10:13:58.758188.758188 lmp.py:748]   Number of GPU devices: 2
DEBUG 01-07 10:13:58.758355.758355 lmp.py:749] 
DEBUG 01-07 10:13:58.758355.758355 lmp.py:749]   Expert ID | Tokens | Device
DEBUG 01-07 10:13:58.758282.758282 lmp.py:750]   -----------------------------------
DEBUG 01-07 10:13:58.758985.758985 lmp.py:767]   Expert 38 |     11 | CPU
DEBUG 01-07 10:13:58.758390.758390 lmp.py:767]   Expert 39 |     60 | CPU
DEBUG 01-07 10:13:58.758556.758556 lmp.py:767]   Expert  7 |     69 | CPU
DEBUG 01-07 10:13:58.758768.758768 lmp.py:767]   Expert 30 |     74 | CPU
DEBUG 01-07 10:13:58.758742.758742 lmp.py:767]   Expert 14 |     93 | CPU
DEBUG 01-07 10:13:58.758862.758862 lmp.py:767]   Expert 24 |     94 | CPU
DEBUG 01-07 10:13:58.758075.758075 lmp.py:767]   Expert 27 |     94 | CPU
DEBUG 01-07 10:13:58.758287.758287 lmp.py:767]   Expert 36 |     95 | CPU
DEBUG 01-07 10:13:58.758261.758261 lmp.py:767]   Expert 40 |     98 | CPU
DEBUG 01-07 10:13:58.758712.758712 lmp.py:767]   Expert 17 |    102 | CPU
DEBUG 01-07 10:13:58.758448.758448 lmp.py:767]   Expert 16 |    104 | CPU
DEBUG 01-07 10:13:58.758422.758422 lmp.py:767]   Expert 32 |    104 | CPU
DEBUG 01-07 10:13:58.758157.758157 lmp.py:767]   Expert 48 |    110 | CPU
DEBUG 01-07 10:13:58.758131.758131 lmp.py:767]   Expert 18 |    111 | CPU
DEBUG 01-07 10:13:58.758867.758867 lmp.py:767]   Expert 12 |    115 | CPU
DEBUG 01-07 10:13:58.758510.758510 lmp.py:767]   Expert  1 |    116 | CPU
DEBUG 01-07 10:13:58.758438.758438 lmp.py:767]   Expert  6 |    126 | CPU
DEBUG 01-07 10:13:58.758127.758127 lmp.py:767]   Expert 59 |    131 | CPU
DEBUG 01-07 10:13:58.758816.758816 lmp.py:767]   Expert 42 |    139 | CPU
DEBUG 01-07 10:13:58.758936.758936 lmp.py:767]   Expert  0 |    141 | GPU1(cuda:2)
DEBUG 01-07 10:13:58.758294.758294 lmp.py:767]   Expert 22 |    145 | GPU1(cuda:2)
DEBUG 01-07 10:13:58.758606.758606 lmp.py:767]   Expert 53 |    145 | GPU0(cuda:1)
DEBUG 01-07 10:13:58.758772.758772 lmp.py:767]   Expert 51 |    147 | GPU0(cuda:1)
DEBUG 01-07 10:13:58.758700.758700 lmp.py:767]   Expert  8 |    162 | GPU1(cuda:2)
DEBUG 01-07 10:13:58.758389.758389 lmp.py:767]   Expert 44 |    167 | GPU0(cuda:1)
DEBUG 01-07 10:13:58.758079.758079 lmp.py:767]   Expert 15 |    169 | GPU0(cuda:1)
DEBUG 01-07 10:13:58.758391.758391 lmp.py:767]   Expert 60 |    169 | GPU1(cuda:2)
DEBUG 01-07 10:13:58.758226.758226 lmp.py:767]   Expert 29 |    171 | GPU1(cuda:2)
DEBUG 01-07 10:13:58.758630.758630 lmp.py:767]   Expert 54 |    172 | GPU0(cuda:1)
DEBUG 01-07 10:13:58.758512.758512 lmp.py:767]   Expert 33 |    178 | GPU0(cuda:1)
DEBUG 01-07 10:13:58.758393.758393 lmp.py:767]   Expert 35 |    178 | GPU1(cuda:2)
DEBUG 01-07 10:13:58.758274.758274 lmp.py:767]   Expert 34 |    180 | GPU1(cuda:2)
DEBUG 01-07 10:13:58.758441.758441 lmp.py:767]   Expert 47 |    188 | GPU0(cuda:1)
DEBUG 01-07 10:13:58.758753.758753 lmp.py:767]   Expert  9 |    193 | GPU1(cuda:2)
DEBUG 01-07 10:13:58.758919.758919 lmp.py:767]   Expert 19 |    194 | GPU0(cuda:1)
DEBUG 01-07 10:13:58.758608.758608 lmp.py:767]   Expert 56 |    196 | GPU1(cuda:2)
DEBUG 01-07 10:13:58.758774.758774 lmp.py:767]   Expert  3 |    199 | GPU1(cuda:2)
DEBUG 01-07 10:13:58.758702.758702 lmp.py:767]   Expert 46 |    199 | GPU0(cuda:1)
DEBUG 01-07 10:13:58.758060.758060 lmp.py:767]   Expert 21 |    200 | GPU1(cuda:2)
DEBUG 01-07 10:13:58.758703.758703 lmp.py:767]   Expert 45 |    200 | GPU0(cuda:1)
DEBUG 01-07 10:13:58.758108.758108 lmp.py:767]   Expert 49 |    201 | GPU0(cuda:1)
DEBUG 01-07 10:13:58.758512.758512 lmp.py:767]   Expert 20 |    202 | GPU1(cuda:2)
DEBUG 01-07 10:13:58.758917.758917 lmp.py:767]   Expert 28 |    207 | GPU0(cuda:1)
DEBUG 01-07 10:13:58.759083.759083 lmp.py:767]   Expert  2 |    224 | GPU0(cuda:1)
DEBUG 01-07 10:13:58.759249.759249 lmp.py:767]   Expert 57 |    224 | GPU1(cuda:2)
DEBUG 01-07 10:13:58.759322.759322 lmp.py:767]   Expert 43 |    225 | GPU1(cuda:2)
DEBUG 01-07 10:13:58.759250.759250 lmp.py:767]   Expert  4 |    228 | GPU0(cuda:1)
DEBUG 01-07 10:13:58.759939.759939 lmp.py:767]   Expert 13 |    231 | GPU1(cuda:2)
DEBUG 01-07 10:13:58.759867.759867 lmp.py:767]   Expert 10 |    239 | GPU0(cuda:1)
DEBUG 01-07 10:13:58.759795.759795 lmp.py:767]   Expert 50 |    243 | GPU1(cuda:2)
DEBUG 01-07 10:13:58.759915.759915 lmp.py:767]   Expert 41 |    244 | GPU0(cuda:1)
DEBUG 01-07 10:13:58.759796.759796 lmp.py:767]   Expert 26 |    250 | GPU1(cuda:2)
DEBUG 01-07 10:13:58.759724.759724 lmp.py:767]   Expert 63 |    255 | GPU0(cuda:1)
DEBUG 01-07 10:13:58.759128.759128 lmp.py:767]   Expert 37 |    258 | GPU1(cuda:2)
DEBUG 01-07 10:13:58.759295.759295 lmp.py:767]   Expert 61 |    271 | GPU0(cuda:1)
DEBUG 01-07 10:13:58.759560.759560 lmp.py:767]   Expert 31 |    272 | GPU1(cuda:2)
DEBUG 01-07 10:13:58.759157.759157 lmp.py:767]   Expert 52 |    306 | GPU0(cuda:1)
DEBUG 01-07 10:13:58.759800.759800 lmp.py:767]   Expert 58 |    322 | GPU1(cuda:2)
DEBUG 01-07 10:13:58.759443.759443 lmp.py:767]   Expert 62 |    324 | GPU0(cuda:1)
DEBUG 01-07 10:13:58.759086.759086 lmp.py:767]   Expert 55 |    341 | GPU1(cuda:2)
DEBUG 01-07 10:13:58.759205.759205 lmp.py:767]   Expert 11 |    375 | GPU0(cuda:1)
DEBUG 01-07 10:13:58.759186.759186 lmp.py:767]   Expert 23 |    381 | GPU1(cuda:2)
DEBUG 01-07 10:13:58.759021.759021 lmp.py:767]   Expert 25 |    407 | GPU1(cuda:2)
DEBUG 01-07 10:13:58.759618.759618 lmp.py:767]   Expert  5 |    519 | GPU0(cuda:1)
DEBUG 01-07 10:13:58.759023.759023 lmp.py:769] 
DEBUG 01-07 10:13:58.759023.759023 lmp.py:769]   Device Token Distribution:
DEBUG 01-07 10:13:58.759381.759381 lmp.py:770]   CPU:   1846 tokens
DEBUG 01-07 10:13:58.759931.759931 lmp.py:774]   cuda:1:   5152 tokens (22 experts)
DEBUG 01-07 10:13:58.759481.759481 lmp.py:774]   cuda:2:   5290 tokens (23 experts)
DEBUG 01-07 10:13:58.759648.759648 lmp.py:775]   Total GPU:  10442 tokens
DEBUG 01-07 10:13:58.759337.759337 lmp.py:776] ============================================================
DEBUG 01-07 10:13:58.759337.759337 lmp.py:776] 
DEBUG 01-07 10:13:58.759702.759702 cuda_h.py:19] end experts_map_get cost 0.0017693042755126953 seconds
DEBUG 01-07 10:13:58.759537.759537 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model_multi_device
DEBUG 01-07 10:13:58.759413.759413 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 10:13:58.759456.759456 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 10:13:58.759219.759219 cuda_h.py:19] end allocate_cuda_memory cost 0.00021409988403320312 seconds
DEBUG 01-07 10:13:58.759023.759023 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 10:13:58.760110.760110 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 10:13:58.760442.760442 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 10:13:58.760138.760138 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, af6d6552-74ab-4497-b59a-10d488ccc251
DEBUG 01-07 10:13:58.760527.760527 client.py:106] call stub.LoadModelAsync
INFO 01-07 10:13:58.760486.760486 client.py:127] Model loaded
DEBUG 01-07 10:13:58.760564.760564 cuda_h.py:19] end sllm_worker_task cost 0.008756637573242188 seconds
INFO 01-07 10:13:58.760058.760058 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, af6d6552-74ab-4497-b59a-10d488ccc251
DEBUG 01-07 10:13:58.760663.760663 cuda_h.py:19] end load_into_gpu_async cost 0.0008974075317382812 seconds
DEBUG 01-07 10:13:58.760697.760697 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 10:13:58.761308.761308 cuda_h.py:19] end restore_tensors2 cost 0.00021457672119140625 seconds
DEBUG 01-07 10:13:58.761647.761647 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0016252994537353516 seconds
DEBUG 01-07 10:13:58.763973.763973 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 10:13:58.763805.763805 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 10:13:58.763660.763660 cuda_h.py:19] end allocate_cuda_memory cost 0.0002067089080810547 seconds
DEBUG 01-07 10:13:58.763172.763172 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 10:13:58.763452.763452 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 10:13:58.763022.763022 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 10:13:58.763579.763579 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 97b6ae09-17a5-47d4-b5fe-4239500ad3ec
DEBUG 01-07 10:13:58.763385.763385 client.py:106] call stub.LoadModelAsync
INFO 01-07 10:13:58.764236.764236 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 97b6ae09-17a5-47d4-b5fe-4239500ad3ec
DEBUG 01-07 10:13:58.764119.764119 cuda_h.py:19] end load_into_gpu_async cost 0.0009431838989257812 seconds
DEBUG 01-07 10:13:58.764199.764199 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 10:13:58.764697.764697 cuda_h.py:19] end restore_tensors2 cost 0.0002014636993408203 seconds
DEBUG 01-07 10:13:58.764897.764897 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0016512870788574219 seconds
DEBUG 01-07 10:13:58.766701.766701 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model_multi_device cost 0.007040262222290039 seconds
DEBUG 01-07 10:13:58.766193.766193 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-07 10:13:58.766871.766871 lmp.py:816] 
DEBUG 01-07 10:13:58.766871.766871 lmp.py:816]   Computing 19 experts on CPU...
DEBUG 01-07 10:13:58.766422.766422 cuda_h.py:19] end cpu_experts_submit cost 0.00010585784912109375 seconds
DEBUG 01-07 10:13:58.766264.766264 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-07 10:13:58.776302.776302 mlpmodule.py:749] group tensors cost 0.009692907333374023 s
DEBUG 01-07 10:13:58.778852.778852 mlpmodule.py:787] pad cost 0.001264333724975586 s
DEBUG 01-07 10:13:58.778789.778789 mlpmodule.py:793] create cpu tensor cost 3.886222839355469e-05 s
DEBUG 01-07 10:13:58.778592.778592 mlpmodule.py:798] move to cpu cost 3.1948089599609375e-05 s
DEBUG 01-07 10:13:58.789495.789495 mlpmodule.py:812] group_w3: shape=torch.Size([19, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=54788096
DEBUG 01-07 10:13:58.789853.789853 mlpmodule.py:813] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-07 10:13:58.789187.789187 mlpmodule.py:818] group_w3 first element: -0.03369140625
WARNING 01-07 10:13:58.789463.789463 mlpmodule.py:828] start einsum2
DEBUG 01-07 10:13:58.809165.809165 mlpmodule.py:838] group einsum cost 0.03029632568359375 s
DEBUG 01-07 10:13:58.809416.809416 mlpmodule.py:846] cpy2cputensor cost 0.0003800392150878906 s
DEBUG 01-07 10:13:58.812528.812528 cuda_h.py:19] end wait_cetm_experts cost 0.045407772064208984 seconds
DEBUG 01-07 10:13:58.812696.812696 cuda_h.py:10] start gpu_sexperts
DEBUG 01-07 10:13:58.812378.812378 cuda_h.py:19] end gpu_sexperts cost 0.0005283355712890625 seconds
DEBUG 01-07 10:13:58.812082.812082 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-07 10:13:58.813455.813455 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.3603439331054688e-05 seconds
DEBUG 01-07 10:13:58.813588.813588 cuda_h.py:10] start wait_experts_multi_device
INFO 01-07 10:13:58.813252.813252 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, af6d6552-74ab-4497-b59a-10d488ccc251
INFO 01-07 10:13:58.814129.814129 client.py:127] Model loaded
INFO 01-07 10:13:58.814535.814535 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 97b6ae09-17a5-47d4-b5fe-4239500ad3ec
INFO 01-07 10:13:58.814138.814138 client.py:127] Model loaded
DEBUG 01-07 10:13:58.814113.814113 cuda_h.py:19] end wait_experts_multi_device cost 0.0014088153839111328 seconds
DEBUG 01-07 10:13:58.814916.814916 cuda_h.py:10] start gpu_experts_multi_device
DEBUG 01-07 10:13:58.814407.814407 lmp.py:867]   Computing 23 experts on cuda:2...
DEBUG 01-07 10:13:58.815453.815453 mlpmodule.py:533] gpu group tensors cost 0.0004961490631103516 s
DEBUG 01-07 10:13:58.817744.817744 mlpmodule.py:566] gpu pad cost 0.0013070106506347656 s
DEBUG 01-07 10:13:58.817221.817221 mlpmodule.py:584] gpu group einsum cost 0.0005252361297607422 s
DEBUG 01-07 10:13:58.819178.819178 mlpmodule.py:656] gpu experts func einsum cost 0.0045430660247802734 s
DEBUG 01-07 10:13:58.820319.820319 lmp.py:867]   Computing 22 experts on cuda:1...
DEBUG 01-07 10:13:58.820218.820218 mlpmodule.py:533] gpu group tensors cost 0.0004544258117675781 s
DEBUG 01-07 10:13:58.822226.822226 mlpmodule.py:566] gpu pad cost 0.0011763572692871094 s
DEBUG 01-07 10:13:58.822029.822029 mlpmodule.py:707]  experts func einsum cost 0.05557513236999512 s
DEBUG 01-07 10:13:58.822040.822040 mlpmodule.py:584] gpu group einsum cost 0.0004961490631103516 s
DEBUG 01-07 10:13:58.824926.824926 mlpmodule.py:656] gpu experts func einsum cost 0.00420689582824707 s
DEBUG 01-07 10:13:58.824824.824824 cuda_h.py:19] end gpu_experts_multi_device cost 0.010085344314575195 seconds
DEBUG 01-07 10:13:58.824462.824462 cuda_h.py:19] end layer_moe_generate_multi_device_8 cost 0.06775569915771484 seconds
DEBUG 01-07 10:13:58.824497.824497 lmp.py:194] -------------------------------- end prefill layer 8 --------------------------------
DEBUG 01-07 10:13:58.825366.825366 lmp.py:153] -------------------------------- start prefill layer 9 --------------------------------
DEBUG 01-07 10:13:58.825062.825062 cuda_h.py:10] start start_load_qkvogn_s_weight_l_10
DEBUG 01-07 10:13:58.825010.825010 cuda_h.py:10] start start_load_qkvogn_s_weight_l_10
DEBUG 01-07 10:13:58.825323.825323 cuda_h.py:19] end start_load_qkvogn_s_weight_l_10 cost 2.9087066650390625e-05 seconds
DEBUG 01-07 10:13:58.825741.825741 cuda_h.py:19] end start_load_qkvogn_s_weight_l_10 cost 5.984306335449219e-05 seconds
DEBUG 01-07 10:13:58.825007.825007 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-07 10:13:58.825975.825975 cuda_h.py:10] start sllm_worker_task
DEBUG 01-07 10:13:58.825209.825209 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 10:13:58.825416.825416 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 10:13:58.825945.825945 cuda_h.py:19] end allocate_cuda_memory cost 0.0003204345703125 seconds
DEBUG 01-07 10:13:58.825967.825967 mlpmodule.py:367] cuda:1 cuda:1
DEBUG 01-07 10:13:58.825658.825658 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 10:13:58.825542.825542 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 10:13:58.825364.825364 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 10:13:58.825637.825637 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 65483245-93bb-4fad-bec4-4ee07f1a848c
DEBUG 01-07 10:13:58.826600.826600 client.py:106] call stub.LoadModelAsync
DEBUG 01-07 10:13:58.826669.826669 cuda_h.py:10] start self_attn
INFO 01-07 10:13:58.826798.826798 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 65483245-93bb-4fad-bec4-4ee07f1a848c
DEBUG 01-07 10:13:58.826773.826773 cuda_h.py:19] end load_into_gpu_async cost 0.0009789466857910156 seconds
DEBUG 01-07 10:13:58.826761.826761 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 10:13:58.827651.827651 cuda_h.py:19] end restore_tensors2 cost 6.914138793945312e-05 seconds
DEBUG 01-07 10:13:58.827215.827215 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0017321109771728516 seconds
INFO 01-07 10:13:58.827052.827052 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 65483245-93bb-4fad-bec4-4ee07f1a848c
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-07 10:13:58.830319.830319 cuda_h.py:19] end self_attn cost 0.0037183761596679688 seconds
DEBUG 01-07 10:13:58.830256.830256 cuda_h.py:19] end iln_self_attn_paln cost 0.005244731903076172 seconds
DEBUG 01-07 10:13:58.830086.830086 cuda_h.py:10] start layer_moe_generate_multi_device_9
DEBUG 01-07 10:13:58.830464.830464 cuda_h.py:10] start gate
DEBUG 01-07 10:13:58.831957.831957 cuda_h.py:19] end gate cost 0.0006449222564697266 seconds
DEBUG 01-07 10:13:58.831787.831787 cuda_h.py:10] start experts_map_get
DEBUG 01-07 10:13:58.831562.831562 lmp.py:744] 
DEBUG 01-07 10:13:58.831562.831562 lmp.py:744] Expert Token Distribution & Multi-Device Allocation:
DEBUG 01-07 10:13:58.831417.831417 lmp.py:745]   Total experts: 64
DEBUG 01-07 10:13:58.831021.831021 lmp.py:746]   CPU experts: 19 (30%)
DEBUG 01-07 10:13:58.831001.831001 lmp.py:747]   GPU experts: 45 (70%)
DEBUG 01-07 10:13:58.831837.831837 lmp.py:748]   Number of GPU devices: 2
DEBUG 01-07 10:13:58.831479.831479 lmp.py:749] 
DEBUG 01-07 10:13:58.831479.831479 lmp.py:749]   Expert ID | Tokens | Device
DEBUG 01-07 10:13:58.831838.831838 lmp.py:750]   -----------------------------------
DEBUG 01-07 10:13:58.831395.831395 lmp.py:767]   Expert 24 |     40 | CPU
DEBUG 01-07 10:13:58.831515.831515 lmp.py:767]   Expert  2 |     46 | CPU
DEBUG 01-07 10:13:58.831681.831681 lmp.py:767]   Expert 26 |     61 | CPU
DEBUG 01-07 10:13:58.831847.831847 lmp.py:767]   Expert 32 |     65 | CPU
DEBUG 01-07 10:13:58.831251.831251 lmp.py:767]   Expert 19 |     69 | CPU
DEBUG 01-07 10:13:58.831656.831656 lmp.py:767]   Expert 50 |     71 | CPU
DEBUG 01-07 10:13:58.831061.831061 lmp.py:767]   Expert 15 |     81 | CPU
DEBUG 01-07 10:13:58.831704.831704 lmp.py:767]   Expert  4 |     82 | CPU
DEBUG 01-07 10:13:58.831539.831539 lmp.py:767]   Expert  7 |     82 | CPU
DEBUG 01-07 10:13:58.831897.831897 lmp.py:767]   Expert 60 |     82 | CPU
DEBUG 01-07 10:13:58.831540.831540 lmp.py:767]   Expert 28 |     83 | CPU
DEBUG 01-07 10:13:58.832898.832898 lmp.py:767]   Expert 59 |     89 | CPU
DEBUG 01-07 10:13:58.832303.832303 lmp.py:767]   Expert 49 |     98 | CPU
DEBUG 01-07 10:13:58.832230.832230 lmp.py:767]   Expert 23 |    100 | CPU
DEBUG 01-07 10:13:58.832396.832396 lmp.py:767]   Expert  5 |    104 | CPU
DEBUG 01-07 10:13:58.832324.832324 lmp.py:767]   Expert 12 |    105 | CPU
DEBUG 01-07 10:13:58.832490.832490 lmp.py:767]   Expert 10 |    111 | CPU
DEBUG 01-07 10:13:58.832418.832418 lmp.py:767]   Expert 27 |    113 | CPU
DEBUG 01-07 10:13:58.832584.832584 lmp.py:767]   Expert 41 |    122 | CPU
DEBUG 01-07 10:13:58.832942.832942 lmp.py:767]   Expert  3 |    125 | GPU1(cuda:2)
DEBUG 01-07 10:13:58.832016.832016 lmp.py:767]   Expert 25 |    127 | GPU0(cuda:1)
DEBUG 01-07 10:13:58.832328.832328 lmp.py:767]   Expert 20 |    129 | GPU0(cuda:1)
DEBUG 01-07 10:13:58.832924.832924 lmp.py:767]   Expert 40 |    129 | GPU1(cuda:2)
DEBUG 01-07 10:13:58.832760.832760 lmp.py:767]   Expert 13 |    130 | GPU1(cuda:2)
DEBUG 01-07 10:13:58.832641.832641 lmp.py:767]   Expert 16 |    134 | GPU1(cuda:2)
DEBUG 01-07 10:13:58.832522.832522 lmp.py:767]   Expert 37 |    144 | GPU0(cuda:1)
DEBUG 01-07 10:13:58.832404.832404 lmp.py:767]   Expert 35 |    146 | GPU0(cuda:1)
DEBUG 01-07 10:13:58.832285.832285 lmp.py:767]   Expert 17 |    149 | GPU1(cuda:2)
DEBUG 01-07 10:13:58.832928.832928 lmp.py:767]   Expert 47 |    152 | GPU1(cuda:2)
DEBUG 01-07 10:13:58.832048.832048 lmp.py:767]   Expert 22 |    158 | GPU0(cuda:1)
DEBUG 01-07 10:13:58.832168.832168 lmp.py:767]   Expert 53 |    166 | GPU0(cuda:1)
DEBUG 01-07 10:13:58.832049.832049 lmp.py:767]   Expert 39 |    172 | GPU1(cuda:2)
DEBUG 01-07 10:13:58.832455.832455 lmp.py:767]   Expert 38 |    177 | GPU0(cuda:1)
DEBUG 01-07 10:13:58.832290.832290 lmp.py:767]   Expert 44 |    179 | GPU1(cuda:2)
DEBUG 01-07 10:13:58.832171.832171 lmp.py:767]   Expert 58 |    180 | GPU0(cuda:1)
DEBUG 01-07 10:13:58.832291.832291 lmp.py:767]   Expert 36 |    181 | GPU1(cuda:2)
DEBUG 01-07 10:13:58.832411.832411 lmp.py:767]   Expert 52 |    184 | GPU0(cuda:1)
DEBUG 01-07 10:13:58.832008.832008 lmp.py:767]   Expert 18 |    187 | GPU1(cuda:2)
DEBUG 01-07 10:13:58.832889.832889 lmp.py:767]   Expert 62 |    197 | GPU1(cuda:2)
DEBUG 01-07 10:13:58.832009.832009 lmp.py:767]   Expert 48 |    209 | GPU0(cuda:1)
DEBUG 01-07 10:13:58.832129.832129 lmp.py:767]   Expert 11 |    211 | GPU1(cuda:2)
DEBUG 01-07 10:13:58.832010.832010 lmp.py:767]   Expert 30 |    217 | GPU0(cuda:1)
DEBUG 01-07 10:13:58.832130.832130 lmp.py:767]   Expert 14 |    219 | GPU1(cuda:2)
DEBUG 01-07 10:13:58.832250.832250 lmp.py:767]   Expert  1 |    230 | GPU0(cuda:1)
DEBUG 01-07 10:13:58.832893.832893 lmp.py:767]   Expert 31 |    236 | GPU0(cuda:1)
DEBUG 01-07 10:13:58.832774.832774 lmp.py:767]   Expert 42 |    236 | GPU1(cuda:2)
DEBUG 01-07 10:13:58.832655.832655 lmp.py:767]   Expert 45 |    238 | GPU1(cuda:2)
DEBUG 01-07 10:13:58.832014.832014 lmp.py:767]   Expert  6 |    239 | GPU0(cuda:1)
DEBUG 01-07 10:13:58.832610.832610 lmp.py:767]   Expert 51 |    241 | GPU0(cuda:1)
DEBUG 01-07 10:13:58.832207.832207 lmp.py:767]   Expert 29 |    263 | GPU1(cuda:2)
DEBUG 01-07 10:13:58.832804.832804 lmp.py:767]   Expert 34 |    264 | GPU0(cuda:1)
DEBUG 01-07 10:13:58.832400.832400 lmp.py:767]   Expert 33 |    273 | GPU1(cuda:2)
DEBUG 01-07 10:13:58.832520.832520 lmp.py:767]   Expert 57 |    294 | GPU1(cuda:2)
DEBUG 01-07 10:13:58.832640.832640 lmp.py:767]   Expert 61 |    306 | GPU0(cuda:1)
DEBUG 01-07 10:13:58.832521.832521 lmp.py:767]   Expert 43 |    307 | GPU0(cuda:1)
DEBUG 01-07 10:13:58.832164.832164 lmp.py:767]   Expert  0 |    321 | GPU1(cuda:2)
DEBUG 01-07 10:13:58.832046.832046 lmp.py:767]   Expert 46 |    351 | GPU0(cuda:1)
DEBUG 01-07 10:13:58.832165.832165 lmp.py:767]   Expert  8 |    386 | GPU1(cuda:2)
DEBUG 01-07 10:13:58.832808.832808 lmp.py:767]   Expert 56 |    390 | GPU0(cuda:1)
DEBUG 01-07 10:13:58.832690.832690 lmp.py:767]   Expert  9 |    391 | GPU1(cuda:2)
DEBUG 01-07 10:13:58.832571.832571 lmp.py:767]   Expert 54 |    394 | GPU0(cuda:1)
DEBUG 01-07 10:13:58.832453.832453 lmp.py:767]   Expert 63 |    409 | GPU1(cuda:2)
DEBUG 01-07 10:13:58.832096.832096 lmp.py:767]   Expert 55 |    425 | GPU1(cuda:2)
DEBUG 01-07 10:13:58.832739.832739 lmp.py:767]   Expert 21 |    488 | GPU0(cuda:1)
DEBUG 01-07 10:13:58.833666.833666 lmp.py:769] 
DEBUG 01-07 10:13:58.833666.833666 lmp.py:769]   Device Token Distribution:
DEBUG 01-07 10:13:58.833071.833071 lmp.py:770]   CPU:   1604 tokens
DEBUG 01-07 10:13:58.833667.833667 lmp.py:774]   cuda:1:   5283 tokens (22 experts)
DEBUG 01-07 10:13:58.833549.833549 lmp.py:774]   cuda:2:   5401 tokens (23 experts)
DEBUG 01-07 10:13:58.833192.833192 lmp.py:775]   Total GPU:  10684 tokens
DEBUG 01-07 10:13:58.833073.833073 lmp.py:776] ============================================================
DEBUG 01-07 10:13:58.833073.833073 lmp.py:776] 
DEBUG 01-07 10:13:58.833630.833630 cuda_h.py:19] end experts_map_get cost 0.001821279525756836 seconds
DEBUG 01-07 10:13:58.833465.833465 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model_multi_device
DEBUG 01-07 10:13:58.833288.833288 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 10:13:58.833662.833662 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 10:13:58.833361.833361 cuda_h.py:19] end allocate_cuda_memory cost 0.00027179718017578125 seconds
DEBUG 01-07 10:13:58.833840.833840 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 10:13:58.833027.833027 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 10:13:58.833697.833697 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 10:13:58.833254.833254 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, e726e20d-3327-43a6-88a8-995593e50ad6
DEBUG 01-07 10:13:58.833166.833166 client.py:106] call stub.LoadModelAsync
INFO 01-07 10:13:58.833347.833347 client.py:127] Model loaded
DEBUG 01-07 10:13:58.834429.834429 cuda_h.py:19] end sllm_worker_task cost 0.009116649627685547 seconds
INFO 01-07 10:13:58.834561.834561 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, e726e20d-3327-43a6-88a8-995593e50ad6
DEBUG 01-07 10:13:58.834497.834497 cuda_h.py:19] end load_into_gpu_async cost 0.0009775161743164062 seconds
DEBUG 01-07 10:13:58.834246.834246 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 10:13:58.834056.834056 cuda_h.py:19] end restore_tensors2 cost 0.00022101402282714844 seconds
DEBUG 01-07 10:13:58.834203.834203 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0017762184143066406 seconds
DEBUG 01-07 10:13:58.836727.836727 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 10:13:58.836242.836242 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 10:13:58.837223.837223 cuda_h.py:19] end allocate_cuda_memory cost 0.0001938343048095703 seconds
DEBUG 01-07 10:13:58.837589.837589 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 10:13:58.837915.837915 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 10:13:58.837009.837009 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 10:13:58.837420.837420 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 1edd8f34-95b4-4ddd-ac48-b10f17ecaf28
DEBUG 01-07 10:13:58.837511.837511 client.py:106] call stub.LoadModelAsync
INFO 01-07 10:13:58.838190.838190 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 1edd8f34-95b4-4ddd-ac48-b10f17ecaf28
DEBUG 01-07 10:13:58.838781.838781 cuda_h.py:19] end load_into_gpu_async cost 0.0009529590606689453 seconds
DEBUG 01-07 10:13:58.838815.838815 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 10:13:58.838326.838326 cuda_h.py:19] end restore_tensors2 cost 0.00021076202392578125 seconds
DEBUG 01-07 10:13:58.838665.838665 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0016586780548095703 seconds
DEBUG 01-07 10:13:58.840939.840939 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model_multi_device cost 0.00720524787902832 seconds
DEBUG 01-07 10:13:58.840306.840306 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-07 10:13:58.840414.840414 lmp.py:816] 
DEBUG 01-07 10:13:58.840414.840414 lmp.py:816]   Computing 19 experts on CPU...
DEBUG 01-07 10:13:58.840019.840019 cuda_h.py:19] end cpu_experts_submit cost 0.00011110305786132812 seconds
DEBUG 01-07 10:13:58.840622.840622 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-07 10:13:58.845034.845034 mlpmodule.py:749] group tensors cost 0.005028486251831055 s
DEBUG 01-07 10:13:58.847740.847740 mlpmodule.py:787] pad cost 0.001222372055053711 s
DEBUG 01-07 10:13:58.847572.847572 mlpmodule.py:793] create cpu tensor cost 4.76837158203125e-05 s
DEBUG 01-07 10:13:58.847541.847541 mlpmodule.py:798] move to cpu cost 3.695487976074219e-05 s
DEBUG 01-07 10:13:58.858569.858569 mlpmodule.py:812] group_w3: shape=torch.Size([19, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=54788096
DEBUG 01-07 10:13:58.858045.858045 mlpmodule.py:813] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-07 10:13:58.859903.859903 mlpmodule.py:818] group_w3 first element: 0.0157470703125
WARNING 01-07 10:13:58.859887.859887 mlpmodule.py:828] start einsum2
DEBUG 01-07 10:13:58.879844.879844 mlpmodule.py:838] group einsum cost 0.03170418739318848 s
DEBUG 01-07 10:13:58.880686.880686 mlpmodule.py:846] cpy2cputensor cost 0.0004038810729980469 s
DEBUG 01-07 10:13:58.882270.882270 cuda_h.py:19] end wait_cetm_experts cost 0.0422520637512207 seconds
DEBUG 01-07 10:13:58.882147.882147 cuda_h.py:10] start gpu_sexperts
DEBUG 01-07 10:13:58.883080.883080 cuda_h.py:19] end gpu_sexperts cost 0.0005035400390625 seconds
DEBUG 01-07 10:13:58.883115.883115 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-07 10:13:58.883203.883203 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.5033950805664062e-05 seconds
DEBUG 01-07 10:13:58.883621.883621 cuda_h.py:10] start wait_experts_multi_device
INFO 01-07 10:13:58.883000.883000 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, e726e20d-3327-43a6-88a8-995593e50ad6
INFO 01-07 10:13:58.884659.884659 client.py:127] Model loaded
INFO 01-07 10:13:58.884688.884688 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 1edd8f34-95b4-4ddd-ac48-b10f17ecaf28
INFO 01-07 10:13:58.885297.885297 client.py:127] Model loaded
DEBUG 01-07 10:13:58.885743.885743 cuda_h.py:19] end wait_experts_multi_device cost 0.0014274120330810547 seconds
DEBUG 01-07 10:13:58.885353.885353 cuda_h.py:10] start gpu_experts_multi_device
DEBUG 01-07 10:13:58.885706.885706 lmp.py:867]   Computing 23 experts on cuda:2...
DEBUG 01-07 10:13:58.886346.886346 mlpmodule.py:533] gpu group tensors cost 0.00048422813415527344 s
DEBUG 01-07 10:13:58.887815.887815 mlpmodule.py:566] gpu pad cost 0.001264810562133789 s
DEBUG 01-07 10:13:58.888961.888961 mlpmodule.py:584] gpu group einsum cost 0.0005276203155517578 s
DEBUG 01-07 10:13:58.890063.890063 mlpmodule.py:656] gpu experts func einsum cost 0.00448918342590332 s
DEBUG 01-07 10:13:58.890073.890073 lmp.py:867]   Computing 22 experts on cuda:1...
DEBUG 01-07 10:13:58.891315.891315 mlpmodule.py:533] gpu group tensors cost 0.0004267692565917969 s
DEBUG 01-07 10:13:58.892590.892590 mlpmodule.py:566] gpu pad cost 0.001234292984008789 s
DEBUG 01-07 10:13:58.893212.893212 mlpmodule.py:707]  experts func einsum cost 0.05229759216308594 s
DEBUG 01-07 10:13:58.893976.893976 mlpmodule.py:584] gpu group einsum cost 0.0005643367767333984 s
DEBUG 01-07 10:13:58.895226.895226 mlpmodule.py:656] gpu experts func einsum cost 0.0042934417724609375 s
DEBUG 01-07 10:13:58.895309.895309 cuda_h.py:19] end gpu_experts_multi_device cost 0.010118722915649414 seconds
DEBUG 01-07 10:13:58.895623.895623 cuda_h.py:19] end layer_moe_generate_multi_device_9 cost 0.06485772132873535 seconds
DEBUG 01-07 10:13:58.895241.895241 lmp.py:194] -------------------------------- end prefill layer 9 --------------------------------
DEBUG 01-07 10:13:58.895156.895156 lmp.py:153] -------------------------------- start prefill layer 10 --------------------------------
DEBUG 01-07 10:13:58.895329.895329 cuda_h.py:10] start start_load_qkvogn_s_weight_l_11
DEBUG 01-07 10:13:58.895800.895800 cuda_h.py:10] start start_load_qkvogn_s_weight_l_11
DEBUG 01-07 10:13:58.895967.895967 cuda_h.py:19] end start_load_qkvogn_s_weight_l_11 cost 2.7179718017578125e-05 seconds
DEBUG 01-07 10:13:58.895432.895432 cuda_h.py:19] end start_load_qkvogn_s_weight_l_11 cost 5.698204040527344e-05 seconds
DEBUG 01-07 10:13:58.895982.895982 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-07 10:13:58.895487.895487 mlpmodule.py:367] cuda:1 cuda:1
DEBUG 01-07 10:13:58.895384.895384 cuda_h.py:10] start sllm_worker_task
DEBUG 01-07 10:13:58.896923.896923 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 10:13:58.896229.896229 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 10:13:58.896955.896955 cuda_h.py:19] end allocate_cuda_memory cost 0.00027823448181152344 seconds
DEBUG 01-07 10:13:58.896415.896415 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 10:13:58.896271.896271 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 10:13:58.896232.896232 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 10:13:58.896743.896743 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 207e1fcc-8e26-4fe5-95ea-e530c6740abf
DEBUG 01-07 10:13:58.896414.896414 client.py:106] call stub.LoadModelAsync
DEBUG 01-07 10:13:58.896183.896183 cuda_h.py:10] start self_attn
INFO 01-07 10:13:58.897454.897454 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 207e1fcc-8e26-4fe5-95ea-e530c6740abf
DEBUG 01-07 10:13:58.897483.897483 cuda_h.py:19] end load_into_gpu_async cost 0.0007882118225097656 seconds
DEBUG 01-07 10:13:58.897040.897040 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 10:13:58.897023.897023 cuda_h.py:19] end restore_tensors2 cost 6.67572021484375e-05 seconds
DEBUG 01-07 10:13:58.897348.897348 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0014073848724365234 seconds
INFO 01-07 10:13:58.897032.897032 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 207e1fcc-8e26-4fe5-95ea-e530c6740abf
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-07 10:13:58.900458.900458 cuda_h.py:19] end self_attn cost 0.0035810470581054688 seconds
DEBUG 01-07 10:13:58.900057.900057 cuda_h.py:19] end iln_self_attn_paln cost 0.004976987838745117 seconds
DEBUG 01-07 10:13:58.900026.900026 cuda_h.py:10] start layer_moe_generate_multi_device_10
DEBUG 01-07 10:13:58.900974.900974 cuda_h.py:10] start gate
DEBUG 01-07 10:13:58.901453.901453 cuda_h.py:19] end gate cost 0.0006361007690429688 seconds
DEBUG 01-07 10:13:58.901852.901852 cuda_h.py:10] start experts_map_get
DEBUG 01-07 10:13:58.902918.902918 lmp.py:744] 
DEBUG 01-07 10:13:58.902918.902918 lmp.py:744] Expert Token Distribution & Multi-Device Allocation:
DEBUG 01-07 10:13:58.902535.902535 lmp.py:745]   Total experts: 64
DEBUG 01-07 10:13:58.902093.902093 lmp.py:746]   CPU experts: 19 (30%)
DEBUG 01-07 10:13:58.902312.902312 lmp.py:747]   GPU experts: 45 (70%)
DEBUG 01-07 10:13:58.902908.902908 lmp.py:748]   Number of GPU devices: 2
DEBUG 01-07 10:13:58.902790.902790 lmp.py:749] 
DEBUG 01-07 10:13:58.902790.902790 lmp.py:749]   Expert ID | Tokens | Device
DEBUG 01-07 10:13:58.902910.902910 lmp.py:750]   -----------------------------------
DEBUG 01-07 10:13:58.902467.902467 lmp.py:767]   Expert 43 |     17 | CPU
DEBUG 01-07 10:13:58.902825.902825 lmp.py:767]   Expert 27 |     33 | CPU
DEBUG 01-07 10:13:58.902468.902468 lmp.py:767]   Expert 26 |     53 | CPU
DEBUG 01-07 10:13:58.902634.902634 lmp.py:767]   Expert 34 |     53 | CPU
DEBUG 01-07 10:13:58.902323.902323 lmp.py:767]   Expert 56 |     55 | CPU
DEBUG 01-07 10:13:58.902728.902728 lmp.py:767]   Expert  3 |     56 | CPU
DEBUG 01-07 10:13:58.902609.902609 lmp.py:767]   Expert  4 |     65 | CPU
DEBUG 01-07 10:13:58.902491.902491 lmp.py:767]   Expert 61 |     80 | CPU
DEBUG 01-07 10:13:58.902134.902134 lmp.py:767]   Expert 14 |     93 | CPU
DEBUG 01-07 10:13:58.902253.902253 lmp.py:767]   Expert 38 |    100 | CPU
DEBUG 01-07 10:13:58.902135.902135 lmp.py:767]   Expert  2 |    112 | CPU
DEBUG 01-07 10:13:58.902301.902301 lmp.py:767]   Expert 22 |    119 | CPU
DEBUG 01-07 10:13:58.902229.902229 lmp.py:767]   Expert 17 |    126 | CPU
DEBUG 01-07 10:13:58.902918.902918 lmp.py:767]   Expert 47 |    128 | CPU
DEBUG 01-07 10:13:58.902846.902846 lmp.py:767]   Expert 37 |    131 | CPU
DEBUG 01-07 10:13:58.902012.902012 lmp.py:767]   Expert 55 |    132 | CPU
DEBUG 01-07 10:13:58.902178.902178 lmp.py:767]   Expert 54 |    136 | CPU
DEBUG 01-07 10:13:58.902106.902106 lmp.py:767]   Expert 28 |    138 | CPU
DEBUG 01-07 10:13:58.902272.902272 lmp.py:767]   Expert  5 |    143 | CPU
DEBUG 01-07 10:13:58.902584.902584 lmp.py:767]   Expert  7 |    144 | GPU0(cuda:1)
DEBUG 01-07 10:13:58.902657.902657 lmp.py:767]   Expert 15 |    144 | GPU0(cuda:1)
DEBUG 01-07 10:13:58.902446.902446 lmp.py:767]   Expert 48 |    147 | GPU1(cuda:2)
DEBUG 01-07 10:13:58.902804.902804 lmp.py:767]   Expert 51 |    148 | GPU1(cuda:2)
DEBUG 01-07 10:13:58.902924.902924 lmp.py:767]   Expert 60 |    148 | GPU0(cuda:1)
DEBUG 01-07 10:13:58.902282.902282 lmp.py:767]   Expert 45 |    149 | GPU0(cuda:1)
DEBUG 01-07 10:13:58.902164.902164 lmp.py:767]   Expert 12 |    151 | GPU1(cuda:2)
DEBUG 01-07 10:13:58.902045.902045 lmp.py:767]   Expert 63 |    153 | GPU0(cuda:1)
DEBUG 01-07 10:13:58.902165.902165 lmp.py:767]   Expert 19 |    157 | GPU1(cuda:2)
DEBUG 01-07 10:13:58.902285.902285 lmp.py:767]   Expert 57 |    168 | GPU0(cuda:1)
DEBUG 01-07 10:13:58.902928.902928 lmp.py:767]   Expert  6 |    169 | GPU1(cuda:2)
DEBUG 01-07 10:13:58.902286.902286 lmp.py:767]   Expert 52 |    172 | GPU1(cuda:2)
DEBUG 01-07 10:13:58.902883.902883 lmp.py:767]   Expert 50 |    180 | GPU0(cuda:1)
DEBUG 01-07 10:13:58.902479.902479 lmp.py:767]   Expert 18 |    181 | GPU1(cuda:2)
DEBUG 01-07 10:13:58.902837.902837 lmp.py:767]   Expert 44 |    182 | GPU0(cuda:1)
DEBUG 01-07 10:13:58.902957.902957 lmp.py:767]   Expert 31 |    187 | GPU0(cuda:1)
DEBUG 01-07 10:13:58.902077.902077 lmp.py:767]   Expert 13 |    190 | GPU1(cuda:2)
DEBUG 01-07 10:13:58.902197.902197 lmp.py:767]   Expert 30 |    192 | GPU0(cuda:1)
DEBUG 01-07 10:13:58.902317.902317 lmp.py:767]   Expert 23 |    194 | GPU1(cuda:2)
DEBUG 01-07 10:13:58.902960.902960 lmp.py:767]   Expert 59 |    195 | GPU0(cuda:1)
DEBUG 01-07 10:13:58.902841.902841 lmp.py:767]   Expert 53 |    196 | GPU1(cuda:2)
DEBUG 01-07 10:13:58.902484.902484 lmp.py:767]   Expert 39 |    198 | GPU0(cuda:1)
DEBUG 01-07 10:13:58.902365.902365 lmp.py:767]   Expert 20 |    199 | GPU1(cuda:2)
DEBUG 01-07 10:13:58.902724.902724 lmp.py:767]   Expert 21 |    200 | GPU1(cuda:2)
DEBUG 01-07 10:13:58.902320.902320 lmp.py:767]   Expert 29 |    200 | GPU0(cuda:1)
DEBUG 01-07 10:13:58.902679.902679 lmp.py:767]   Expert 36 |    212 | GPU0(cuda:1)
DEBUG 01-07 10:13:58.903275.903275 lmp.py:767]   Expert 16 |    213 | GPU1(cuda:2)
DEBUG 01-07 10:13:58.903157.903157 lmp.py:767]   Expert 41 |    215 | GPU0(cuda:1)
DEBUG 01-07 10:13:58.903276.903276 lmp.py:767]   Expert 25 |    217 | GPU1(cuda:2)
DEBUG 01-07 10:13:58.903158.903158 lmp.py:767]   Expert 32 |    223 | GPU0(cuda:1)
DEBUG 01-07 10:13:58.903562.903562 lmp.py:767]   Expert 49 |    224 | GPU1(cuda:2)
DEBUG 01-07 10:13:58.903444.903444 lmp.py:767]   Expert 46 |    237 | GPU1(cuda:2)
DEBUG 01-07 10:13:58.903848.903848 lmp.py:767]   Expert  8 |    247 | GPU0(cuda:1)
DEBUG 01-07 10:13:58.903491.903491 lmp.py:767]   Expert 42 |    248 | GPU0(cuda:1)
DEBUG 01-07 10:13:58.903134.903134 lmp.py:767]   Expert 10 |    251 | GPU1(cuda:2)
DEBUG 01-07 10:13:58.903539.903539 lmp.py:767]   Expert 62 |    269 | GPU1(cuda:2)
DEBUG 01-07 10:13:58.903612.903612 lmp.py:767]   Expert 35 |    280 | GPU0(cuda:1)
DEBUG 01-07 10:13:58.903971.903971 lmp.py:767]   Expert 33 |    291 | GPU1(cuda:2)
DEBUG 01-07 10:13:58.903329.903329 lmp.py:767]   Expert  9 |    294 | GPU0(cuda:1)
DEBUG 01-07 10:13:58.903925.903925 lmp.py:767]   Expert 58 |    299 | GPU0(cuda:1)
DEBUG 01-07 10:13:58.903568.903568 lmp.py:767]   Expert 40 |    391 | GPU1(cuda:2)
DEBUG 01-07 10:13:58.903973.903973 lmp.py:767]   Expert 11 |    420 | GPU0(cuda:1)
DEBUG 01-07 10:13:58.903854.903854 lmp.py:767]   Expert  0 |    427 | GPU1(cuda:2)
DEBUG 01-07 10:13:58.903497.903497 lmp.py:767]   Expert 24 |    564 | GPU1(cuda:2)
DEBUG 01-07 10:13:58.903379.903379 lmp.py:767]   Expert  1 |    652 | GPU0(cuda:1)
DEBUG 01-07 10:13:58.903306.903306 lmp.py:769] 
DEBUG 01-07 10:13:58.903306.903306 lmp.py:769]   Device Token Distribution:
DEBUG 01-07 10:13:58.903473.903473 lmp.py:770]   CPU:   1770 tokens
DEBUG 01-07 10:13:58.903784.903784 lmp.py:774]   cuda:1:   5330 tokens (23 experts)
DEBUG 01-07 10:13:58.903381.903381 lmp.py:774]   cuda:2:   5188 tokens (22 experts)
DEBUG 01-07 10:13:58.903024.903024 lmp.py:775]   Total GPU:  10518 tokens
DEBUG 01-07 10:13:58.903667.903667 lmp.py:776] ============================================================
DEBUG 01-07 10:13:58.903667.903667 lmp.py:776] 
DEBUG 01-07 10:13:58.903794.903794 cuda_h.py:19] end experts_map_get cost 0.001789093017578125 seconds
DEBUG 01-07 10:13:58.903913.903913 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model_multi_device
DEBUG 01-07 10:13:58.903736.903736 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 10:13:58.903064.903064 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 10:13:58.903025.903025 cuda_h.py:19] end allocate_cuda_memory cost 0.00018477439880371094 seconds
DEBUG 01-07 10:13:58.903405.903405 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 10:13:58.903446.903446 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 10:13:58.903255.903255 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 10:13:58.904858.904858 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 9d2d0c09-2ec9-43d5-a34b-8cf243118690
DEBUG 01-07 10:13:58.904002.904002 client.py:106] call stub.LoadModelAsync
INFO 01-07 10:13:58.904079.904079 client.py:127] Model loaded
DEBUG 01-07 10:13:58.904980.904980 cuda_h.py:19] end sllm_worker_task cost 0.008644819259643555 seconds
INFO 01-07 10:13:58.904279.904279 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 9d2d0c09-2ec9-43d5-a34b-8cf243118690
DEBUG 01-07 10:13:58.904692.904692 cuda_h.py:19] end load_into_gpu_async cost 0.0010223388671875 seconds
DEBUG 01-07 10:13:58.904010.904010 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 10:13:58.905688.905688 cuda_h.py:19] end restore_tensors2 cost 0.00022840499877929688 seconds
DEBUG 01-07 10:13:58.905742.905742 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0017375946044921875 seconds
DEBUG 01-07 10:13:58.907885.907885 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 10:13:58.907525.907525 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 10:13:58.907136.907136 cuda_h.py:19] end allocate_cuda_memory cost 0.0002009868621826172 seconds
DEBUG 01-07 10:13:58.907833.907833 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 10:13:58.907681.907681 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 10:13:58.907345.907345 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 10:13:58.907995.907995 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 5abe1e4a-fbdd-4329-9700-5ad5df3c9ffc
DEBUG 01-07 10:13:58.907734.907734 client.py:106] call stub.LoadModelAsync
INFO 01-07 10:13:58.908438.908438 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 5abe1e4a-fbdd-4329-9700-5ad5df3c9ffc
DEBUG 01-07 10:13:58.908268.908268 cuda_h.py:19] end load_into_gpu_async cost 0.0008862018585205078 seconds
DEBUG 01-07 10:13:58.908586.908586 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 10:13:58.908660.908660 cuda_h.py:19] end restore_tensors2 cost 0.0002052783966064453 seconds
DEBUG 01-07 10:13:58.908284.908284 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0015795230865478516 seconds
DEBUG 01-07 10:13:58.910297.910297 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model_multi_device cost 0.007069110870361328 seconds
DEBUG 01-07 10:13:58.910881.910881 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-07 10:13:58.910036.910036 lmp.py:816] 
DEBUG 01-07 10:13:58.910036.910036 lmp.py:816]   Computing 19 experts on CPU...
DEBUG 01-07 10:13:58.910449.910449 cuda_h.py:19] end cpu_experts_submit cost 0.00010967254638671875 seconds
DEBUG 01-07 10:13:58.910052.910052 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-07 10:13:58.920649.920649 mlpmodule.py:749] group tensors cost 0.009792804718017578 s
DEBUG 01-07 10:13:58.922284.922284 mlpmodule.py:787] pad cost 0.0009481906890869141 s
DEBUG 01-07 10:13:58.922698.922698 mlpmodule.py:793] create cpu tensor cost 3.910064697265625e-05 s
DEBUG 01-07 10:13:58.922024.922024 mlpmodule.py:798] move to cpu cost 3.123283386230469e-05 s
DEBUG 01-07 10:13:58.932584.932584 mlpmodule.py:812] group_w3: shape=torch.Size([19, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=54788096
DEBUG 01-07 10:13:58.932345.932345 mlpmodule.py:813] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-07 10:13:58.933487.933487 mlpmodule.py:818] group_w3 first element: -0.0213623046875
WARNING 01-07 10:13:58.933710.933710 mlpmodule.py:828] start einsum2
DEBUG 01-07 10:13:58.951739.951739 mlpmodule.py:838] group einsum cost 0.02938246726989746 s
DEBUG 01-07 10:13:58.952185.952185 mlpmodule.py:846] cpy2cputensor cost 0.0004246234893798828 s
DEBUG 01-07 10:13:58.955385.955385 cuda_h.py:19] end wait_cetm_experts cost 0.045111656188964844 seconds
DEBUG 01-07 10:13:58.956785.956785 cuda_h.py:10] start gpu_sexperts
DEBUG 01-07 10:13:58.956301.956301 cuda_h.py:19] end gpu_sexperts cost 0.0005135536193847656 seconds
DEBUG 01-07 10:13:58.956190.956190 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-07 10:13:58.956987.956987 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.3126602172851562e-05 seconds
DEBUG 01-07 10:13:58.956405.956405 cuda_h.py:10] start wait_experts_multi_device
INFO 01-07 10:13:58.956221.956221 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 9d2d0c09-2ec9-43d5-a34b-8cf243118690
INFO 01-07 10:13:58.957164.957164 client.py:127] Model loaded
INFO 01-07 10:13:58.957377.957377 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 5abe1e4a-fbdd-4329-9700-5ad5df3c9ffc
INFO 01-07 10:13:58.958770.958770 client.py:127] Model loaded
DEBUG 01-07 10:13:58.958838.958838 cuda_h.py:19] end wait_experts_multi_device cost 0.0014481544494628906 seconds
DEBUG 01-07 10:13:58.958210.958210 cuda_h.py:10] start gpu_experts_multi_device
DEBUG 01-07 10:13:58.958702.958702 lmp.py:867]   Computing 22 experts on cuda:2...
DEBUG 01-07 10:13:58.959494.959494 mlpmodule.py:533] gpu group tensors cost 0.0004591941833496094 s
DEBUG 01-07 10:13:58.960047.960047 mlpmodule.py:566] gpu pad cost 0.0012221336364746094 s
DEBUG 01-07 10:13:58.961431.961431 mlpmodule.py:584] gpu group einsum cost 0.0005271434783935547 s
DEBUG 01-07 10:13:58.963286.963286 mlpmodule.py:656] gpu experts func einsum cost 0.004343986511230469 s
DEBUG 01-07 10:13:58.963991.963991 lmp.py:867]   Computing 23 experts on cuda:1...
DEBUG 01-07 10:13:58.964598.964598 mlpmodule.py:533] gpu group tensors cost 0.0004475116729736328 s
DEBUG 01-07 10:13:58.965510.965510 mlpmodule.py:566] gpu pad cost 0.001283407211303711 s
DEBUG 01-07 10:13:58.966538.966538 mlpmodule.py:707]  experts func einsum cost 0.055162668228149414 s
DEBUG 01-07 10:13:58.966595.966595 mlpmodule.py:584] gpu group einsum cost 0.0004856586456298828 s
DEBUG 01-07 10:13:58.968389.968389 mlpmodule.py:656] gpu experts func einsum cost 0.004295825958251953 s
DEBUG 01-07 10:13:58.968889.968889 cuda_h.py:19] end gpu_experts_multi_device cost 0.00995182991027832 seconds
DEBUG 01-07 10:13:58.968805.968805 cuda_h.py:19] end layer_moe_generate_multi_device_10 cost 0.06736445426940918 seconds
DEBUG 01-07 10:13:58.968661.968661 lmp.py:194] -------------------------------- end prefill layer 10 --------------------------------
DEBUG 01-07 10:13:58.968530.968530 lmp.py:153] -------------------------------- start prefill layer 11 --------------------------------
DEBUG 01-07 10:13:58.968226.968226 cuda_h.py:10] start start_load_qkvogn_s_weight_l_12
DEBUG 01-07 10:13:58.968505.968505 cuda_h.py:10] start start_load_qkvogn_s_weight_l_12
DEBUG 01-07 10:13:58.968865.968865 cuda_h.py:19] end start_load_qkvogn_s_weight_l_12 cost 2.7894973754882812e-05 seconds
DEBUG 01-07 10:13:58.968899.968899 cuda_h.py:19] end start_load_qkvogn_s_weight_l_12 cost 5.7697296142578125e-05 seconds
DEBUG 01-07 10:13:58.968688.968688 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-07 10:13:58.968702.968702 cuda_h.py:10] start sllm_worker_task
DEBUG 01-07 10:13:58.968778.968778 mlpmodule.py:367] cuda:1 cuda:1
DEBUG 01-07 10:13:58.968733.968733 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 10:13:58.969160.969160 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 10:13:58.969541.969541 cuda_h.py:19] end allocate_cuda_memory cost 0.000244140625 seconds
DEBUG 01-07 10:13:58.969550.969550 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 10:13:58.969558.969558 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 10:13:58.969996.969996 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 10:13:58.969077.969077 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, b4900347-1622-487f-9591-f00b9d148830
DEBUG 01-07 10:13:58.969132.969132 client.py:106] call stub.LoadModelAsync
DEBUG 01-07 10:13:58.969743.969743 cuda_h.py:10] start self_attn
INFO 01-07 10:13:58.970286.970286 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, b4900347-1622-487f-9591-f00b9d148830
DEBUG 01-07 10:13:58.970069.970069 cuda_h.py:19] end load_into_gpu_async cost 0.0008399486541748047 seconds
DEBUG 01-07 10:13:58.970150.970150 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 10:13:58.970841.970841 cuda_h.py:19] end restore_tensors2 cost 6.341934204101562e-05 seconds
DEBUG 01-07 10:13:58.970167.970167 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0013930797576904297 seconds
INFO 01-07 10:13:58.970089.970089 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, b4900347-1622-487f-9591-f00b9d148830
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-07 10:13:58.973851.973851 cuda_h.py:19] end self_attn cost 0.0035657882690429688 seconds
DEBUG 01-07 10:13:58.973874.973874 cuda_h.py:19] end iln_self_attn_paln cost 0.004954338073730469 seconds
DEBUG 01-07 10:13:58.973750.973750 cuda_h.py:10] start layer_moe_generate_multi_device_11
DEBUG 01-07 10:13:58.973175.973175 cuda_h.py:10] start gate
DEBUG 01-07 10:13:58.974740.974740 cuda_h.py:19] end gate cost 0.0006299018859863281 seconds
DEBUG 01-07 10:13:58.974470.974470 cuda_h.py:10] start experts_map_get
DEBUG 01-07 10:13:58.974099.974099 lmp.py:744] 
DEBUG 01-07 10:13:58.974099.974099 lmp.py:744] Expert Token Distribution & Multi-Device Allocation:
DEBUG 01-07 10:13:58.974776.974776 lmp.py:745]   Total experts: 64
DEBUG 01-07 10:13:58.974810.974810 lmp.py:746]   CPU experts: 19 (30%)
DEBUG 01-07 10:13:58.974361.974361 lmp.py:747]   GPU experts: 45 (70%)
DEBUG 01-07 10:13:58.975242.975242 lmp.py:748]   Number of GPU devices: 2
DEBUG 01-07 10:13:58.975693.975693 lmp.py:749] 
DEBUG 01-07 10:13:58.975693.975693 lmp.py:749]   Expert ID | Tokens | Device
DEBUG 01-07 10:13:58.975859.975859 lmp.py:750]   -----------------------------------
DEBUG 01-07 10:13:58.975224.975224 lmp.py:767]   Expert 39 |     17 | CPU
DEBUG 01-07 10:13:58.975390.975390 lmp.py:767]   Expert 13 |     18 | CPU
DEBUG 01-07 10:13:58.975841.975841 lmp.py:767]   Expert 49 |     38 | CPU
DEBUG 01-07 10:13:58.975054.975054 lmp.py:767]   Expert 35 |     55 | CPU
DEBUG 01-07 10:13:58.975743.975743 lmp.py:767]   Expert 19 |     64 | CPU
DEBUG 01-07 10:13:58.975955.975955 lmp.py:767]   Expert 32 |     73 | CPU
DEBUG 01-07 10:13:58.975598.975598 lmp.py:767]   Expert  9 |     74 | CPU
DEBUG 01-07 10:13:58.975764.975764 lmp.py:767]   Expert 26 |     74 | CPU
DEBUG 01-07 10:13:58.975454.975454 lmp.py:767]   Expert 41 |     74 | CPU
DEBUG 01-07 10:13:58.975381.975381 lmp.py:767]   Expert 33 |     81 | CPU
DEBUG 01-07 10:13:58.975309.975309 lmp.py:767]   Expert 46 |     85 | CPU
DEBUG 01-07 10:13:58.975760.975760 lmp.py:767]   Expert 23 |     88 | CPU
DEBUG 01-07 10:13:58.975496.975496 lmp.py:767]   Expert 18 |     89 | CPU
DEBUG 01-07 10:13:58.975993.975993 lmp.py:767]   Expert 31 |     92 | CPU
DEBUG 01-07 10:13:58.975967.975967 lmp.py:767]   Expert 38 |     98 | CPU
DEBUG 01-07 10:13:58.975703.975703 lmp.py:767]   Expert 17 |    102 | CPU
DEBUG 01-07 10:13:58.975438.975438 lmp.py:767]   Expert  6 |    103 | CPU
DEBUG 01-07 10:13:58.975174.975174 lmp.py:767]   Expert  3 |    106 | CPU
DEBUG 01-07 10:13:58.975148.975148 lmp.py:767]   Expert 20 |    119 | CPU
DEBUG 01-07 10:13:58.975552.975552 lmp.py:767]   Expert 62 |    128 | GPU1(cuda:2)
DEBUG 01-07 10:13:58.975672.975672 lmp.py:767]   Expert 40 |    131 | GPU0(cuda:1)
DEBUG 01-07 10:13:58.975792.975792 lmp.py:767]   Expert 61 |    132 | GPU1(cuda:2)
DEBUG 01-07 10:13:58.975673.975673 lmp.py:767]   Expert 44 |    134 | GPU0(cuda:1)
DEBUG 01-07 10:13:58.975555.975555 lmp.py:767]   Expert 43 |    136 | GPU0(cuda:1)
DEBUG 01-07 10:13:58.975483.975483 lmp.py:767]   Expert 50 |    136 | GPU1(cuda:2)
DEBUG 01-07 10:13:58.975172.975172 lmp.py:767]   Expert 15 |    137 | GPU0(cuda:1)
DEBUG 01-07 10:13:58.975100.975100 lmp.py:767]   Expert 16 |    137 | GPU1(cuda:2)
DEBUG 01-07 10:13:58.975266.975266 lmp.py:767]   Expert 42 |    141 | GPU1(cuda:2)
DEBUG 01-07 10:13:58.975955.975955 lmp.py:767]   Expert 63 |    142 | GPU0(cuda:1)
DEBUG 01-07 10:13:58.975883.975883 lmp.py:767]   Expert 59 |    143 | GPU1(cuda:2)
DEBUG 01-07 10:13:58.975810.975810 lmp.py:767]   Expert  2 |    144 | GPU0(cuda:1)
DEBUG 01-07 10:13:58.975500.975500 lmp.py:767]   Expert 36 |    153 | GPU0(cuda:1)
DEBUG 01-07 10:13:58.975427.975427 lmp.py:767]   Expert 10 |    159 | GPU1(cuda:2)
DEBUG 01-07 10:13:58.975309.975309 lmp.py:767]   Expert  5 |    182 | GPU1(cuda:2)
DEBUG 01-07 10:13:58.975713.975713 lmp.py:767]   Expert 34 |    186 | GPU0(cuda:1)
DEBUG 01-07 10:13:58.975118.975118 lmp.py:767]   Expert 27 |    187 | GPU0(cuda:1)
DEBUG 01-07 10:13:58.975999.975999 lmp.py:767]   Expert 45 |    191 | GPU1(cuda:2)
DEBUG 01-07 10:13:58.975165.975165 lmp.py:767]   Expert 52 |    194 | GPU0(cuda:1)
DEBUG 01-07 10:13:58.975093.975093 lmp.py:767]   Expert 60 |    200 | GPU1(cuda:2)
DEBUG 01-07 10:13:58.975259.975259 lmp.py:767]   Expert 48 |    208 | GPU0(cuda:1)
DEBUG 01-07 10:13:58.975710.975710 lmp.py:767]   Expert 51 |    210 | GPU1(cuda:2)
DEBUG 01-07 10:13:58.975876.975876 lmp.py:767]   Expert 56 |    213 | GPU1(cuda:2)
DEBUG 01-07 10:13:58.975566.975566 lmp.py:767]   Expert 24 |    228 | GPU0(cuda:1)
DEBUG 01-07 10:13:58.975493.975493 lmp.py:767]   Expert 53 |    231 | GPU1(cuda:2)
DEBUG 01-07 10:13:58.975136.975136 lmp.py:767]   Expert  7 |    233 | GPU0(cuda:1)
DEBUG 01-07 10:13:58.975779.975779 lmp.py:767]   Expert  8 |    243 | GPU1(cuda:2)
DEBUG 01-07 10:13:58.975422.975422 lmp.py:767]   Expert 57 |    250 | GPU0(cuda:1)
DEBUG 01-07 10:13:58.975827.975827 lmp.py:767]   Expert 47 |    253 | GPU1(cuda:2)
DEBUG 01-07 10:13:58.975231.975231 lmp.py:767]   Expert 29 |    260 | GPU0(cuda:1)
DEBUG 01-07 10:13:58.975398.975398 lmp.py:767]   Expert 21 |    263 | GPU0(cuda:1)
DEBUG 01-07 10:13:58.975325.975325 lmp.py:767]   Expert  0 |    286 | GPU1(cuda:2)
DEBUG 01-07 10:13:58.975253.975253 lmp.py:767]   Expert 14 |    290 | GPU1(cuda:2)
DEBUG 01-07 10:13:58.975419.975419 lmp.py:767]   Expert  4 |    291 | GPU0(cuda:1)
DEBUG 01-07 10:13:58.975108.975108 lmp.py:767]   Expert 22 |    316 | GPU0(cuda:1)
DEBUG 01-07 10:13:58.975798.975798 lmp.py:767]   Expert 37 |    316 | GPU1(cuda:2)
DEBUG 01-07 10:13:58.975487.975487 lmp.py:767]   Expert 58 |    317 | GPU1(cuda:2)
DEBUG 01-07 10:13:58.976368.976368 lmp.py:767]   Expert 55 |    318 | GPU0(cuda:1)
DEBUG 01-07 10:13:58.976488.976488 lmp.py:767]   Expert  1 |    320 | GPU0(cuda:1)
DEBUG 01-07 10:13:58.976131.976131 lmp.py:767]   Expert 54 |    335 | GPU1(cuda:2)
DEBUG 01-07 10:13:58.976251.976251 lmp.py:767]   Expert 28 |    361 | GPU0(cuda:1)
DEBUG 01-07 10:13:58.976609.976609 lmp.py:767]   Expert 12 |    380 | GPU1(cuda:2)
DEBUG 01-07 10:13:58.976206.976206 lmp.py:767]   Expert 25 |    395 | GPU1(cuda:2)
DEBUG 01-07 10:13:58.976564.976564 lmp.py:767]   Expert 11 |    400 | GPU1(cuda:2)
DEBUG 01-07 10:13:58.976445.976445 lmp.py:767]   Expert 30 |    828 | GPU0(cuda:1)
DEBUG 01-07 10:13:58.976896.976896 lmp.py:769] 
DEBUG 01-07 10:13:58.976896.976896 lmp.py:769]   Device Token Distribution:
DEBUG 01-07 10:13:58.976063.976063 lmp.py:770]   CPU:   1450 tokens
DEBUG 01-07 10:13:58.976944.976944 lmp.py:774]   cuda:1:   5420 tokens (22 experts)
DEBUG 01-07 10:13:58.976587.976587 lmp.py:774]   cuda:2:   5418 tokens (23 experts)
DEBUG 01-07 10:13:58.976753.976753 lmp.py:775]   Total GPU:  10838 tokens
DEBUG 01-07 10:13:58.976442.976442 lmp.py:776] ============================================================
DEBUG 01-07 10:13:58.976442.976442 lmp.py:776] 
DEBUG 01-07 10:13:58.976331.976331 cuda_h.py:19] end experts_map_get cost 0.0017292499542236328 seconds
DEBUG 01-07 10:13:58.976689.976689 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model_multi_device
DEBUG 01-07 10:13:58.976843.976843 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 10:13:58.976561.976561 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 10:13:58.976327.976327 cuda_h.py:19] end allocate_cuda_memory cost 0.00028228759765625 seconds
DEBUG 01-07 10:13:58.976038.976038 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 10:13:58.976317.976317 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 10:13:58.976649.976649 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 10:13:58.976776.976776 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 5c22e48f-6df7-42a5-9690-2e8bca8c1f5d
DEBUG 01-07 10:13:58.977827.977827 client.py:106] call stub.LoadModelAsync
INFO 01-07 10:13:58.977779.977779 client.py:127] Model loaded
DEBUG 01-07 10:13:58.977228.977228 cuda_h.py:19] end sllm_worker_task cost 0.008655548095703125 seconds
INFO 01-07 10:13:58.977693.977693 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 5c22e48f-6df7-42a5-9690-2e8bca8c1f5d
DEBUG 01-07 10:13:58.977768.977768 cuda_h.py:19] end load_into_gpu_async cost 0.0009970664978027344 seconds
DEBUG 01-07 10:13:58.977802.977802 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 10:13:58.978995.978995 cuda_h.py:19] end restore_tensors2 cost 0.00022411346435546875 seconds
DEBUG 01-07 10:13:58.978142.978142 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0018138885498046875 seconds
DEBUG 01-07 10:13:58.979302.979302 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 10:13:58.980035.980035 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 10:13:58.980182.980182 cuda_h.py:19] end allocate_cuda_memory cost 0.00021219253540039062 seconds
DEBUG 01-07 10:13:58.980601.980601 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 10:13:58.980404.980404 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 10:13:58.980590.980590 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 10:13:58.980001.980001 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 5e93395d-6524-4f53-97e8-e6031de091d9
DEBUG 01-07 10:13:58.980284.980284 client.py:106] call stub.LoadModelAsync
INFO 01-07 10:13:58.981869.981869 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 5e93395d-6524-4f53-97e8-e6031de091d9
DEBUG 01-07 10:13:58.981029.981029 cuda_h.py:19] end load_into_gpu_async cost 0.0008802413940429688 seconds
DEBUG 01-07 10:13:58.981348.981348 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 10:13:58.981461.981461 cuda_h.py:19] end restore_tensors2 cost 0.00019931793212890625 seconds
DEBUG 01-07 10:13:58.981324.981324 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0015845298767089844 seconds
DEBUG 01-07 10:13:58.983405.983405 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model_multi_device cost 0.00713801383972168 seconds
DEBUG 01-07 10:13:58.983228.983228 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-07 10:13:58.983714.983714 lmp.py:816] 
DEBUG 01-07 10:13:58.983714.983714 lmp.py:816]   Computing 19 experts on CPU...
DEBUG 01-07 10:13:58.983074.983074 cuda_h.py:19] end cpu_experts_submit cost 0.00010395050048828125 seconds
DEBUG 01-07 10:13:58.983154.983154 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-07 10:13:58.988790.988790 mlpmodule.py:749] group tensors cost 0.005224466323852539 s
DEBUG 01-07 10:13:58.990193.990193 mlpmodule.py:787] pad cost 0.0012264251708984375 s
DEBUG 01-07 10:13:58.991395.991395 mlpmodule.py:793] create cpu tensor cost 4.601478576660156e-05 s
DEBUG 01-07 10:13:58.991266.991266 mlpmodule.py:798] move to cpu cost 3.5762786865234375e-05 s
DEBUG 01-07 10:13:59.001906.001906 mlpmodule.py:812] group_w3: shape=torch.Size([19, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=54788096
DEBUG 01-07 10:13:59.001720.001720 mlpmodule.py:813] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-07 10:13:59.001147.001147 mlpmodule.py:818] group_w3 first element: 0.01373291015625
WARNING 01-07 10:13:59.001654.001654 mlpmodule.py:828] start einsum2
DEBUG 01-07 10:13:59.022929.022929 mlpmodule.py:838] group einsum cost 0.030811786651611328 s
DEBUG 01-07 10:13:59.022294.022294 mlpmodule.py:846] cpy2cputensor cost 0.0004000663757324219 s
DEBUG 01-07 10:13:59.025515.025515 cuda_h.py:19] end wait_cetm_experts cost 0.041584014892578125 seconds
DEBUG 01-07 10:13:59.025875.025875 cuda_h.py:10] start gpu_sexperts
DEBUG 01-07 10:13:59.025430.025430 cuda_h.py:19] end gpu_sexperts cost 0.0005068778991699219 seconds
DEBUG 01-07 10:13:59.025611.025611 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-07 10:13:59.026077.026077 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.3603439331054688e-05 seconds
DEBUG 01-07 10:13:59.026495.026495 cuda_h.py:10] start wait_experts_multi_device
INFO 01-07 10:13:59.026589.026589 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 5c22e48f-6df7-42a5-9690-2e8bca8c1f5d
INFO 01-07 10:13:59.027699.027699 client.py:127] Model loaded
INFO 01-07 10:13:59.027582.027582 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 5e93395d-6524-4f53-97e8-e6031de091d9
INFO 01-07 10:13:59.027377.027377 client.py:127] Model loaded
DEBUG 01-07 10:13:59.027730.027730 cuda_h.py:19] end wait_experts_multi_device cost 0.001440286636352539 seconds
DEBUG 01-07 10:13:59.027578.027578 cuda_h.py:10] start gpu_experts_multi_device
DEBUG 01-07 10:13:59.027831.027831 lmp.py:867]   Computing 23 experts on cuda:2...
DEBUG 01-07 10:13:59.028739.028739 mlpmodule.py:533] gpu group tensors cost 0.0005471706390380859 s
DEBUG 01-07 10:13:59.030822.030822 mlpmodule.py:566] gpu pad cost 0.0012290477752685547 s
DEBUG 01-07 10:13:59.030292.030292 mlpmodule.py:584] gpu group einsum cost 0.0005283355712890625 s
DEBUG 01-07 10:13:59.032182.032182 mlpmodule.py:656] gpu experts func einsum cost 0.004491090774536133 s
DEBUG 01-07 10:13:59.033755.033755 lmp.py:867]   Computing 22 experts on cuda:1...
DEBUG 01-07 10:13:59.033103.033103 mlpmodule.py:533] gpu group tensors cost 0.0004382133483886719 s
DEBUG 01-07 10:13:59.034132.034132 mlpmodule.py:566] gpu pad cost 0.0011937618255615234 s
DEBUG 01-07 10:13:59.035454.035454 mlpmodule.py:707]  experts func einsum cost 0.051375389099121094 s
DEBUG 01-07 10:13:59.035123.035123 mlpmodule.py:584] gpu group einsum cost 0.00044655799865722656 s
DEBUG 01-07 10:13:59.037020.037020 mlpmodule.py:656] gpu experts func einsum cost 0.0044841766357421875 s
DEBUG 01-07 10:13:59.037387.037387 cuda_h.py:19] end gpu_experts_multi_device cost 0.010293006896972656 seconds
DEBUG 01-07 10:13:59.037357.037357 cuda_h.py:19] end layer_moe_generate_multi_device_11 cost 0.06418180465698242 seconds
DEBUG 01-07 10:13:59.038883.038883 lmp.py:194] -------------------------------- end prefill layer 11 --------------------------------
DEBUG 01-07 10:13:59.038567.038567 lmp.py:153] -------------------------------- start prefill layer 12 --------------------------------
DEBUG 01-07 10:13:59.038786.038786 cuda_h.py:10] start start_load_qkvogn_s_weight_l_13
DEBUG 01-07 10:13:59.038257.038257 cuda_h.py:10] start start_load_qkvogn_s_weight_l_13
DEBUG 01-07 10:13:59.038855.038855 cuda_h.py:19] end start_load_qkvogn_s_weight_l_13 cost 2.8133392333984375e-05 seconds
DEBUG 01-07 10:13:59.038261.038261 cuda_h.py:10] start sllm_worker_task
DEBUG 01-07 10:13:59.038005.038005 cuda_h.py:19] end start_load_qkvogn_s_weight_l_13 cost 0.00012183189392089844 seconds
DEBUG 01-07 10:13:59.038053.038053 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 10:13:59.038823.038823 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-07 10:13:59.038765.038765 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 10:13:59.039280.039280 cuda_h.py:19] end allocate_cuda_memory cost 0.0002658367156982422 seconds
DEBUG 01-07 10:13:59.039588.039588 mlpmodule.py:367] cuda:1 cuda:1
DEBUG 01-07 10:13:59.039848.039848 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 10:13:59.039586.039586 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 10:13:59.039647.039647 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 10:13:59.039588.039588 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 93733e83-f938-4796-acc2-1430e8ac1949
DEBUG 01-07 10:13:59.039167.039167 client.py:106] call stub.LoadModelAsync
DEBUG 01-07 10:13:59.039720.039720 cuda_h.py:10] start self_attn
INFO 01-07 10:13:59.040184.040184 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 93733e83-f938-4796-acc2-1430e8ac1949
DEBUG 01-07 10:13:59.040491.040491 cuda_h.py:19] end load_into_gpu_async cost 0.0009126663208007812 seconds
DEBUG 01-07 10:13:59.040286.040286 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 10:13:59.040124.040124 cuda_h.py:19] end restore_tensors2 cost 6.556510925292969e-05 seconds
DEBUG 01-07 10:13:59.040403.040403 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0016493797302246094 seconds
INFO 01-07 10:13:59.040855.040855 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 93733e83-f938-4796-acc2-1430e8ac1949
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-07 10:13:59.043008.043008 cuda_h.py:19] end self_attn cost 0.003592252731323242 seconds
DEBUG 01-07 10:13:59.043237.043237 cuda_h.py:19] end iln_self_attn_paln cost 0.004934072494506836 seconds
DEBUG 01-07 10:13:59.043351.043351 cuda_h.py:10] start layer_moe_generate_multi_device_12
DEBUG 01-07 10:13:59.043491.043491 cuda_h.py:10] start gate
DEBUG 01-07 10:13:59.044084.044084 cuda_h.py:19] end gate cost 0.0006489753723144531 seconds
DEBUG 01-07 10:13:59.044198.044198 cuda_h.py:10] start experts_map_get
DEBUG 01-07 10:13:59.044595.044595 lmp.py:744] 
DEBUG 01-07 10:13:59.044595.044595 lmp.py:744] Expert Token Distribution & Multi-Device Allocation:
DEBUG 01-07 10:13:59.044974.044974 lmp.py:745]   Total experts: 64
DEBUG 01-07 10:13:59.044531.044531 lmp.py:746]   CPU experts: 19 (30%)
DEBUG 01-07 10:13:59.044273.044273 lmp.py:747]   GPU experts: 45 (70%)
DEBUG 01-07 10:13:59.044109.044109 lmp.py:748]   Number of GPU devices: 2
DEBUG 01-07 10:13:59.045990.045990 lmp.py:749] 
DEBUG 01-07 10:13:59.045990.045990 lmp.py:749]   Expert ID | Tokens | Device
DEBUG 01-07 10:13:59.045110.045110 lmp.py:750]   -----------------------------------
DEBUG 01-07 10:13:59.045905.045905 lmp.py:767]   Expert 12 |     20 | CPU
DEBUG 01-07 10:13:59.045264.045264 lmp.py:767]   Expert 47 |     25 | CPU
DEBUG 01-07 10:13:59.045668.045668 lmp.py:767]   Expert 27 |     31 | CPU
DEBUG 01-07 10:13:59.045311.045311 lmp.py:767]   Expert 38 |     32 | CPU
DEBUG 01-07 10:13:59.045477.045477 lmp.py:767]   Expert 16 |     34 | CPU
DEBUG 01-07 10:13:59.045882.045882 lmp.py:767]   Expert 52 |     40 | CPU
DEBUG 01-07 10:13:59.045525.045525 lmp.py:767]   Expert 63 |     44 | CPU
DEBUG 01-07 10:13:59.045406.045406 lmp.py:767]   Expert  4 |     59 | CPU
DEBUG 01-07 10:13:59.045049.045049 lmp.py:767]   Expert 43 |     59 | CPU
DEBUG 01-07 10:13:59.045930.045930 lmp.py:767]   Expert 44 |     63 | CPU
DEBUG 01-07 10:13:59.045050.045050 lmp.py:767]   Expert 61 |     64 | CPU
DEBUG 01-07 10:13:59.045455.045455 lmp.py:767]   Expert 34 |     75 | CPU
DEBUG 01-07 10:13:59.045383.045383 lmp.py:767]   Expert 53 |     81 | CPU
DEBUG 01-07 10:13:59.045310.045310 lmp.py:767]   Expert  0 |     87 | CPU
DEBUG 01-07 10:13:59.045476.045476 lmp.py:767]   Expert 32 |     92 | CPU
DEBUG 01-07 10:13:59.045166.045166 lmp.py:767]   Expert 37 |     93 | CPU
DEBUG 01-07 10:13:59.045332.045332 lmp.py:767]   Expert 13 |    101 | CPU
DEBUG 01-07 10:13:59.045260.045260 lmp.py:767]   Expert 39 |    112 | CPU
DEBUG 01-07 10:13:59.045426.045426 lmp.py:767]   Expert 21 |    118 | CPU
DEBUG 01-07 10:13:59.045546.045546 lmp.py:767]   Expert 11 |    120 | GPU0(cuda:1)
DEBUG 01-07 10:13:59.045334.045334 lmp.py:767]   Expert 20 |    127 | GPU1(cuda:2)
DEBUG 01-07 10:13:59.045169.045169 lmp.py:767]   Expert  8 |    129 | GPU0(cuda:1)
DEBUG 01-07 10:13:59.045243.045243 lmp.py:767]   Expert 14 |    135 | GPU0(cuda:1)
DEBUG 01-07 10:13:59.045839.045839 lmp.py:767]   Expert 60 |    135 | GPU1(cuda:2)
DEBUG 01-07 10:13:59.045198.045198 lmp.py:767]   Expert 57 |    140 | GPU1(cuda:2)
DEBUG 01-07 10:13:59.045841.045841 lmp.py:767]   Expert 22 |    141 | GPU0(cuda:1)
DEBUG 01-07 10:13:59.045722.045722 lmp.py:767]   Expert 45 |    152 | GPU0(cuda:1)
DEBUG 01-07 10:13:59.045365.045365 lmp.py:767]   Expert 17 |    157 | GPU0(cuda:1)
DEBUG 01-07 10:13:59.045246.045246 lmp.py:767]   Expert 18 |    157 | GPU1(cuda:2)
DEBUG 01-07 10:13:59.045366.045366 lmp.py:767]   Expert  2 |    158 | GPU1(cuda:2)
DEBUG 01-07 10:13:59.045009.045009 lmp.py:767]   Expert 23 |    161 | GPU0(cuda:1)
DEBUG 01-07 10:13:59.045367.045367 lmp.py:767]   Expert  7 |    162 | GPU1(cuda:2)
DEBUG 01-07 10:13:59.045249.045249 lmp.py:767]   Expert 58 |    163 | GPU0(cuda:1)
DEBUG 01-07 10:13:59.045369.045369 lmp.py:767]   Expert 30 |    165 | GPU1(cuda:2)
DEBUG 01-07 10:13:59.045250.045250 lmp.py:767]   Expert 42 |    172 | GPU1(cuda:2)
DEBUG 01-07 10:13:59.045085.045085 lmp.py:767]   Expert 48 |    179 | GPU0(cuda:1)
DEBUG 01-07 10:13:59.045920.045920 lmp.py:767]   Expert 49 |    179 | GPU0(cuda:1)
DEBUG 01-07 10:13:59.045278.045278 lmp.py:767]   Expert 55 |    182 | GPU0(cuda:1)
DEBUG 01-07 10:13:59.045113.045113 lmp.py:767]   Expert 62 |    182 | GPU1(cuda:2)
DEBUG 01-07 10:13:59.045710.045710 lmp.py:767]   Expert 35 |    184 | GPU1(cuda:2)
DEBUG 01-07 10:13:59.045592.045592 lmp.py:767]   Expert 51 |    187 | GPU0(cuda:1)
DEBUG 01-07 10:13:59.045473.045473 lmp.py:767]   Expert 29 |    190 | GPU1(cuda:2)
DEBUG 01-07 10:13:59.045831.045831 lmp.py:767]   Expert 25 |    192 | GPU0(cuda:1)
DEBUG 01-07 10:13:59.045474.045474 lmp.py:767]   Expert 36 |    195 | GPU1(cuda:2)
DEBUG 01-07 10:13:59.045356.045356 lmp.py:767]   Expert  6 |    196 | GPU0(cuda:1)
DEBUG 01-07 10:13:59.045714.045714 lmp.py:767]   Expert  1 |    197 | GPU1(cuda:2)
DEBUG 01-07 10:13:59.045787.045787 lmp.py:767]   Expert 31 |    207 | GPU1(cuda:2)
DEBUG 01-07 10:13:59.045861.045861 lmp.py:767]   Expert 28 |    221 | GPU0(cuda:1)
DEBUG 01-07 10:13:59.045696.045696 lmp.py:767]   Expert 54 |    225 | GPU0(cuda:1)
DEBUG 01-07 10:13:59.045054.045054 lmp.py:767]   Expert  5 |    229 | GPU1(cuda:2)
DEBUG 01-07 10:13:59.045412.045412 lmp.py:767]   Expert 41 |    231 | GPU0(cuda:1)
DEBUG 01-07 10:13:59.045294.045294 lmp.py:767]   Expert 19 |    238 | GPU1(cuda:2)
DEBUG 01-07 10:13:59.045937.045937 lmp.py:767]   Expert  9 |    239 | GPU1(cuda:2)
DEBUG 01-07 10:13:59.046818.046818 lmp.py:767]   Expert 24 |    253 | GPU0(cuda:1)
DEBUG 01-07 10:13:59.046699.046699 lmp.py:767]   Expert 50 |    289 | GPU0(cuda:1)
DEBUG 01-07 10:13:59.046581.046581 lmp.py:767]   Expert 46 |    306 | GPU1(cuda:2)
DEBUG 01-07 10:13:59.046462.046462 lmp.py:767]   Expert 59 |    313 | GPU0(cuda:1)
DEBUG 01-07 10:13:59.046344.046344 lmp.py:767]   Expert 56 |    376 | GPU1(cuda:2)
DEBUG 01-07 10:13:59.046225.046225 lmp.py:767]   Expert 26 |    405 | GPU0(cuda:1)
DEBUG 01-07 10:13:59.046868.046868 lmp.py:767]   Expert 33 |    423 | GPU1(cuda:2)
DEBUG 01-07 10:13:59.046226.046226 lmp.py:767]   Expert  3 |    588 | GPU0(cuda:1)
DEBUG 01-07 10:13:59.046346.046346 lmp.py:767]   Expert 10 |    643 | GPU1(cuda:2)
DEBUG 01-07 10:13:59.046704.046704 lmp.py:767]   Expert 15 |    644 | GPU1(cuda:2)
DEBUG 01-07 10:13:59.046824.046824 lmp.py:767]   Expert 40 |    791 | GPU0(cuda:1)
DEBUG 01-07 10:13:59.046752.046752 lmp.py:769] 
DEBUG 01-07 10:13:59.046752.046752 lmp.py:769]   Device Token Distribution:
DEBUG 01-07 10:13:59.046156.046156 lmp.py:770]   CPU:   1230 tokens
DEBUG 01-07 10:13:59.046276.046276 lmp.py:774]   cuda:1:   5589 tokens (23 experts)
DEBUG 01-07 10:13:59.046919.046919 lmp.py:774]   cuda:2:   5469 tokens (22 experts)
DEBUG 01-07 10:13:59.046608.046608 lmp.py:775]   Total GPU:  11058 tokens
DEBUG 01-07 10:13:59.046298.046298 lmp.py:776] ============================================================
DEBUG 01-07 10:13:59.046298.046298 lmp.py:776] 
DEBUG 01-07 10:13:59.046947.046947 cuda_h.py:19] end experts_map_get cost 0.0017876625061035156 seconds
DEBUG 01-07 10:13:59.046829.046829 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model_multi_device
DEBUG 01-07 10:13:59.046936.046936 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 10:13:59.046178.046178 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 10:13:59.046180.046180 cuda_h.py:19] end allocate_cuda_memory cost 0.0002148151397705078 seconds
DEBUG 01-07 10:13:59.046037.046037 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 10:13:59.046793.046793 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 10:13:59.046410.046410 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 10:13:59.046775.046775 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 63d2fef7-ffe4-430d-a524-06e771584b56
DEBUG 01-07 10:13:59.047031.047031 client.py:106] call stub.LoadModelAsync
INFO 01-07 10:13:59.047798.047798 client.py:127] Model loaded
DEBUG 01-07 10:13:59.047393.047393 cuda_h.py:19] end sllm_worker_task cost 0.008962154388427734 seconds
INFO 01-07 10:13:59.047509.047509 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 63d2fef7-ffe4-430d-a524-06e771584b56
DEBUG 01-07 10:13:59.047220.047220 cuda_h.py:19] end load_into_gpu_async cost 0.0010845661163330078 seconds
DEBUG 01-07 10:13:59.047261.047261 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 10:13:59.048560.048560 cuda_h.py:19] end restore_tensors2 cost 0.00022983551025390625 seconds
DEBUG 01-07 10:13:59.048615.048615 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0018470287322998047 seconds
DEBUG 01-07 10:13:59.050281.050281 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 10:13:59.050212.050212 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 10:13:59.050102.050102 cuda_h.py:19] end allocate_cuda_memory cost 0.0002315044403076172 seconds
DEBUG 01-07 10:13:59.050674.050674 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 10:13:59.050238.050238 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 10:13:59.050901.050901 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 10:13:59.050551.050551 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, c9186689-e15c-4ac5-a7b8-b6754d4d8b0a
DEBUG 01-07 10:13:59.050496.050496 client.py:106] call stub.LoadModelAsync
INFO 01-07 10:13:59.051002.051002 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, c9186689-e15c-4ac5-a7b8-b6754d4d8b0a
DEBUG 01-07 10:13:59.051925.051925 cuda_h.py:19] end load_into_gpu_async cost 0.0009255409240722656 seconds
DEBUG 01-07 10:13:59.051005.051005 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 10:13:59.051139.051139 cuda_h.py:19] end restore_tensors2 cost 0.00021457672119140625 seconds
DEBUG 01-07 10:13:59.051001.051001 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0016758441925048828 seconds
DEBUG 01-07 10:13:59.053189.053189 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model_multi_device cost 0.007365703582763672 seconds
DEBUG 01-07 10:13:59.053727.053727 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-07 10:13:59.053551.053551 lmp.py:816] 
DEBUG 01-07 10:13:59.053551.053551 lmp.py:816]   Computing 19 experts on CPU...
DEBUG 01-07 10:13:59.053963.053963 cuda_h.py:19] end cpu_experts_submit cost 0.00011038780212402344 seconds
DEBUG 01-07 10:13:59.053282.053282 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-07 10:13:59.063343.063343 mlpmodule.py:749] group tensors cost 0.009608268737792969 s
DEBUG 01-07 10:13:59.065780.065780 mlpmodule.py:787] pad cost 0.0009524822235107422 s
DEBUG 01-07 10:13:59.065671.065671 mlpmodule.py:793] create cpu tensor cost 3.933906555175781e-05 s
DEBUG 01-07 10:13:59.065951.065951 mlpmodule.py:798] move to cpu cost 3.123283386230469e-05 s
DEBUG 01-07 10:13:59.075340.075340 mlpmodule.py:812] group_w3: shape=torch.Size([19, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=54788096
DEBUG 01-07 10:13:59.075525.075525 mlpmodule.py:813] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-07 10:13:59.075144.075144 mlpmodule.py:818] group_w3 first element: -0.0162353515625
WARNING 01-07 10:13:59.076599.076599 mlpmodule.py:828] start einsum2
DEBUG 01-07 10:13:59.095741.095741 mlpmodule.py:838] group einsum cost 0.03042125701904297 s
DEBUG 01-07 10:13:59.096071.096071 mlpmodule.py:846] cpy2cputensor cost 0.0003628730773925781 s
DEBUG 01-07 10:13:59.099043.099043 cuda_h.py:19] end wait_cetm_experts cost 0.045038461685180664 seconds
DEBUG 01-07 10:13:59.099589.099589 cuda_h.py:10] start gpu_sexperts
DEBUG 01-07 10:13:59.099932.099932 cuda_h.py:19] end gpu_sexperts cost 0.0004897117614746094 seconds
DEBUG 01-07 10:13:59.099106.099106 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-07 10:13:59.099618.099618 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.2649765014648438e-05 seconds
DEBUG 01-07 10:13:59.099797.099797 cuda_h.py:10] start wait_experts_multi_device
INFO 01-07 10:13:59.099461.099461 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 63d2fef7-ffe4-430d-a524-06e771584b56
INFO 01-07 10:13:59.100299.100299 client.py:127] Model loaded
INFO 01-07 10:13:59.100374.100374 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, c9186689-e15c-4ac5-a7b8-b6754d4d8b0a
INFO 01-07 10:13:59.101753.101753 client.py:127] Model loaded
DEBUG 01-07 10:13:59.101245.101245 cuda_h.py:19] end wait_experts_multi_device cost 0.0014579296112060547 seconds
DEBUG 01-07 10:13:59.101855.101855 cuda_h.py:10] start gpu_experts_multi_device
DEBUG 01-07 10:13:59.101393.101393 lmp.py:867]   Computing 22 experts on cuda:2...
DEBUG 01-07 10:13:59.102754.102754 mlpmodule.py:533] gpu group tensors cost 0.000461578369140625 s
DEBUG 01-07 10:13:59.103440.103440 mlpmodule.py:566] gpu pad cost 0.0012154579162597656 s
DEBUG 01-07 10:13:59.104201.104201 mlpmodule.py:584] gpu group einsum cost 0.0005249977111816406 s
DEBUG 01-07 10:13:59.106155.106155 mlpmodule.py:656] gpu experts func einsum cost 0.004304647445678711 s
DEBUG 01-07 10:13:59.106058.106058 lmp.py:867]   Computing 23 experts on cuda:1...
DEBUG 01-07 10:13:59.107427.107427 mlpmodule.py:533] gpu group tensors cost 0.0004436969757080078 s
DEBUG 01-07 10:13:59.108014.108014 mlpmodule.py:566] gpu pad cost 0.0012543201446533203 s
DEBUG 01-07 10:13:59.109091.109091 mlpmodule.py:584] gpu group einsum cost 0.0004448890686035156 s
DEBUG 01-07 10:13:59.111920.111920 mlpmodule.py:656] gpu experts func einsum cost 0.004282474517822266 s
DEBUG 01-07 10:13:59.111287.111287 cuda_h.py:19] end gpu_experts_multi_device cost 0.009911060333251953 seconds
DEBUG 01-07 10:13:59.111734.111734 cuda_h.py:19] end layer_moe_generate_multi_device_12 cost 0.06756210327148438 seconds
DEBUG 01-07 10:13:59.111266.111266 lmp.py:194] -------------------------------- end prefill layer 12 --------------------------------
DEBUG 01-07 10:13:59.111705.111705 lmp.py:153] -------------------------------- start prefill layer 13 --------------------------------
DEBUG 01-07 10:13:59.111216.111216 cuda_h.py:10] start start_load_qkvogn_s_weight_l_14
DEBUG 01-07 10:13:59.111548.111548 cuda_h.py:10] start start_load_qkvogn_s_weight_l_14
DEBUG 01-07 10:13:59.111954.111954 cuda_h.py:19] end start_load_qkvogn_s_weight_l_14 cost 2.7894973754882812e-05 seconds
DEBUG 01-07 10:13:59.111372.111372 cuda_h.py:19] end start_load_qkvogn_s_weight_l_14 cost 5.841255187988281e-05 seconds
DEBUG 01-07 10:13:59.111114.111114 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-07 10:13:59.111335.111335 mlpmodule.py:367] cuda:1 cuda:1
DEBUG 01-07 10:13:59.111423.111423 cuda_h.py:10] start sllm_worker_task
DEBUG 01-07 10:13:59.112803.112803 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 10:13:59.112679.112679 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 10:13:59.112154.112154 cuda_h.py:19] end allocate_cuda_memory cost 0.0007002353668212891 seconds
DEBUG 01-07 10:13:59.112249.112249 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 10:13:59.112150.112150 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 10:13:59.112543.112543 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 10:13:59.112577.112577 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 9c2546a1-75ff-4808-b46f-cc6631929dbd
DEBUG 01-07 10:13:59.113347.113347 client.py:106] call stub.LoadModelAsync
DEBUG 01-07 10:13:59.113875.113875 mlpmodule.py:707]  experts func einsum cost 0.059139251708984375 s
DEBUG 01-07 10:13:59.113453.113453 cuda_h.py:10] start self_attn
INFO 01-07 10:13:59.113501.113501 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 9c2546a1-75ff-4808-b46f-cc6631929dbd
DEBUG 01-07 10:13:59.113696.113696 cuda_h.py:19] end load_into_gpu_async cost 0.0008578300476074219 seconds
DEBUG 01-07 10:13:59.113445.113445 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 10:13:59.113097.113097 cuda_h.py:19] end restore_tensors2 cost 6.914138793945312e-05 seconds
DEBUG 01-07 10:13:59.113091.113091 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0018687248229980469 seconds
INFO 01-07 10:13:59.113286.113286 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 9c2546a1-75ff-4808-b46f-cc6631929dbd
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-07 10:13:59.117378.117378 cuda_h.py:19] end self_attn cost 0.003637552261352539 seconds
DEBUG 01-07 10:13:59.117793.117793 cuda_h.py:19] end iln_self_attn_paln cost 0.005597114562988281 seconds
DEBUG 01-07 10:13:59.117284.117284 cuda_h.py:10] start layer_moe_generate_multi_device_13
DEBUG 01-07 10:13:59.117709.117709 cuda_h.py:10] start gate
DEBUG 01-07 10:13:59.118526.118526 cuda_h.py:19] end gate cost 0.0006403923034667969 seconds
DEBUG 01-07 10:13:59.118495.118495 cuda_h.py:10] start experts_map_get
DEBUG 01-07 10:13:59.118899.118899 lmp.py:744] 
DEBUG 01-07 10:13:59.118899.118899 lmp.py:744] Expert Token Distribution & Multi-Device Allocation:
DEBUG 01-07 10:13:59.118530.118530 lmp.py:745]   Total experts: 64
DEBUG 01-07 10:13:59.118041.118041 lmp.py:746]   CPU experts: 19 (30%)
DEBUG 01-07 10:13:59.118545.118545 lmp.py:747]   GPU experts: 45 (70%)
DEBUG 01-07 10:13:59.118426.118426 lmp.py:748]   Number of GPU devices: 2
DEBUG 01-07 10:13:59.118354.118354 lmp.py:749] 
DEBUG 01-07 10:13:59.118354.118354 lmp.py:749]   Expert ID | Tokens | Device
DEBUG 01-07 10:13:59.118520.118520 lmp.py:750]   -----------------------------------
DEBUG 01-07 10:13:59.118408.118408 lmp.py:767]   Expert 42 |     24 | CPU
DEBUG 01-07 10:13:59.118813.118813 lmp.py:767]   Expert 19 |     25 | CPU
DEBUG 01-07 10:13:59.118740.118740 lmp.py:767]   Expert 30 |     29 | CPU
DEBUG 01-07 10:13:59.118191.118191 lmp.py:767]   Expert 32 |     44 | CPU
DEBUG 01-07 10:13:59.118119.118119 lmp.py:767]   Expert  6 |     56 | CPU
DEBUG 01-07 10:13:59.118570.118570 lmp.py:767]   Expert 53 |     73 | CPU
DEBUG 01-07 10:13:59.118021.118021 lmp.py:767]   Expert  5 |     74 | CPU
DEBUG 01-07 10:13:59.118472.118472 lmp.py:767]   Expert  1 |     77 | CPU
DEBUG 01-07 10:13:59.118922.118922 lmp.py:767]   Expert 13 |    117 | CPU
DEBUG 01-07 10:13:59.118896.118896 lmp.py:767]   Expert  9 |    124 | CPU
DEBUG 01-07 10:13:59.118347.118347 lmp.py:767]   Expert 58 |    128 | CPU
DEBUG 01-07 10:13:59.118560.118560 lmp.py:767]   Expert 63 |    128 | CPU
DEBUG 01-07 10:13:59.119011.119011 lmp.py:767]   Expert 34 |    130 | CPU
DEBUG 01-07 10:13:59.119130.119130 lmp.py:767]   Expert 50 |    132 | CPU
DEBUG 01-07 10:13:59.119012.119012 lmp.py:767]   Expert 26 |    136 | CPU
DEBUG 01-07 10:13:59.119940.119940 lmp.py:767]   Expert 11 |    138 | CPU
DEBUG 01-07 10:13:59.119106.119106 lmp.py:767]   Expert 31 |    138 | CPU
DEBUG 01-07 10:13:59.119318.119318 lmp.py:767]   Expert 18 |    141 | CPU
DEBUG 01-07 10:13:59.119531.119531 lmp.py:767]   Expert 40 |    145 | CPU
DEBUG 01-07 10:13:59.119174.119174 lmp.py:767]   Expert 59 |    145 | GPU1(cuda:2)
DEBUG 01-07 10:13:59.119578.119578 lmp.py:767]   Expert 12 |    146 | GPU1(cuda:2)
DEBUG 01-07 10:13:59.119744.119744 lmp.py:767]   Expert 56 |    148 | GPU0(cuda:1)
DEBUG 01-07 10:13:59.119910.119910 lmp.py:767]   Expert 46 |    149 | GPU0(cuda:1)
DEBUG 01-07 10:13:59.119315.119315 lmp.py:767]   Expert 48 |    149 | GPU1(cuda:2)
DEBUG 01-07 10:13:59.119243.119243 lmp.py:767]   Expert  4 |    150 | GPU1(cuda:2)
DEBUG 01-07 10:13:59.119409.119409 lmp.py:767]   Expert  2 |    151 | GPU0(cuda:1)
DEBUG 01-07 10:13:59.119575.119575 lmp.py:767]   Expert 20 |    155 | GPU0(cuda:1)
DEBUG 01-07 10:13:59.119503.119503 lmp.py:767]   Expert 61 |    157 | GPU1(cuda:2)
DEBUG 01-07 10:13:59.119907.119907 lmp.py:767]   Expert 33 |    158 | GPU0(cuda:1)
DEBUG 01-07 10:13:59.119550.119550 lmp.py:767]   Expert 10 |    164 | GPU1(cuda:2)
DEBUG 01-07 10:13:59.119193.119193 lmp.py:767]   Expert 35 |    164 | GPU1(cuda:2)
DEBUG 01-07 10:13:59.119075.119075 lmp.py:767]   Expert 55 |    172 | GPU0(cuda:1)
DEBUG 01-07 10:13:59.119956.119956 lmp.py:767]   Expert 51 |    174 | GPU0(cuda:1)
DEBUG 01-07 10:13:59.119599.119599 lmp.py:767]   Expert 36 |    180 | GPU1(cuda:2)
DEBUG 01-07 10:13:59.119765.119765 lmp.py:767]   Expert  8 |    181 | GPU0(cuda:1)
DEBUG 01-07 10:13:59.119931.119931 lmp.py:767]   Expert 37 |    188 | GPU1(cuda:2)
DEBUG 01-07 10:13:59.119097.119097 lmp.py:767]   Expert 52 |    188 | GPU1(cuda:2)
DEBUG 01-07 10:13:59.119025.119025 lmp.py:767]   Expert 57 |    203 | GPU0(cuda:1)
DEBUG 01-07 10:13:59.119430.119430 lmp.py:767]   Expert  0 |    204 | GPU0(cuda:1)
DEBUG 01-07 10:13:59.119596.119596 lmp.py:767]   Expert 39 |    218 | GPU1(cuda:2)
DEBUG 01-07 10:13:59.119477.119477 lmp.py:767]   Expert 25 |    226 | GPU1(cuda:2)
DEBUG 01-07 10:13:59.119120.119120 lmp.py:767]   Expert 38 |    237 | GPU0(cuda:1)
DEBUG 01-07 10:13:59.119002.119002 lmp.py:767]   Expert 62 |    242 | GPU0(cuda:1)
DEBUG 01-07 10:13:59.119121.119121 lmp.py:767]   Expert  7 |    243 | GPU1(cuda:2)
DEBUG 01-07 10:13:59.119764.119764 lmp.py:767]   Expert 27 |    249 | GPU1(cuda:2)
DEBUG 01-07 10:13:59.119930.119930 lmp.py:767]   Expert  3 |    250 | GPU0(cuda:1)
DEBUG 01-07 10:13:59.119097.119097 lmp.py:767]   Expert 24 |    250 | GPU0(cuda:1)
DEBUG 01-07 10:13:59.119024.119024 lmp.py:767]   Expert 28 |    255 | GPU1(cuda:2)
DEBUG 01-07 10:13:59.119952.119952 lmp.py:767]   Expert 60 |    259 | GPU0(cuda:1)
DEBUG 01-07 10:13:59.119118.119118 lmp.py:767]   Expert 21 |    260 | GPU1(cuda:2)
DEBUG 01-07 10:13:59.119284.119284 lmp.py:767]   Expert 16 |    267 | GPU1(cuda:2)
DEBUG 01-07 10:13:59.119974.119974 lmp.py:767]   Expert 49 |    267 | GPU0(cuda:1)
DEBUG 01-07 10:13:59.119901.119901 lmp.py:767]   Expert 43 |    269 | GPU0(cuda:1)
DEBUG 01-07 10:13:59.119829.119829 lmp.py:767]   Expert 23 |    270 | GPU1(cuda:2)
DEBUG 01-07 10:13:59.119757.119757 lmp.py:767]   Expert 29 |    277 | GPU0(cuda:1)
DEBUG 01-07 10:13:59.119353.119353 lmp.py:767]   Expert 15 |    287 | GPU1(cuda:2)
DEBUG 01-07 10:13:59.119712.119712 lmp.py:767]   Expert 22 |    295 | GPU0(cuda:1)
DEBUG 01-07 10:13:59.119308.119308 lmp.py:767]   Expert 41 |    296 | GPU0(cuda:1)
DEBUG 01-07 10:13:59.119428.119428 lmp.py:767]   Expert 47 |    296 | GPU1(cuda:2)
DEBUG 01-07 10:13:59.119071.119071 lmp.py:767]   Expert 44 |    302 | GPU1(cuda:2)
DEBUG 01-07 10:13:59.119714.119714 lmp.py:767]   Expert 54 |    351 | GPU0(cuda:1)
DEBUG 01-07 10:13:59.119119.119119 lmp.py:767]   Expert 14 |    374 | GPU1(cuda:2)
DEBUG 01-07 10:13:59.119762.119762 lmp.py:767]   Expert 17 |    408 | GPU1(cuda:2)
DEBUG 01-07 10:13:59.119405.119405 lmp.py:767]   Expert 45 |    455 | GPU0(cuda:1)
DEBUG 01-07 10:13:59.119094.119094 lmp.py:769] 
DEBUG 01-07 10:13:59.119094.119094 lmp.py:769]   Device Token Distribution:
DEBUG 01-07 10:13:59.119498.119498 lmp.py:770]   CPU:   1859 tokens
DEBUG 01-07 10:13:59.119334.119334 lmp.py:774]   cuda:1:   5143 tokens (22 experts)
DEBUG 01-07 10:13:59.119930.119930 lmp.py:774]   cuda:2:   5286 tokens (23 experts)
DEBUG 01-07 10:13:59.119335.119335 lmp.py:775]   Total GPU:  10429 tokens
DEBUG 01-07 10:13:59.119978.119978 lmp.py:776] ============================================================
DEBUG 01-07 10:13:59.119978.119978 lmp.py:776] 
DEBUG 01-07 10:13:59.120058.120058 cuda_h.py:19] end experts_map_get cost 0.001756429672241211 seconds
DEBUG 01-07 10:13:59.120655.120655 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model_multi_device
DEBUG 01-07 10:13:59.120193.120193 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 10:13:59.120666.120666 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 10:13:59.120840.120840 cuda_h.py:19] end allocate_cuda_memory cost 0.00019979476928710938 seconds
DEBUG 01-07 10:13:59.120027.120027 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 10:13:59.120545.120545 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 10:13:59.120831.120831 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 10:13:59.120527.120527 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 26280acc-ead5-419f-8c94-a90abd38ccc8
DEBUG 01-07 10:13:59.120194.120194 client.py:106] call stub.LoadModelAsync
INFO 01-07 10:13:59.120550.120550 client.py:127] Model loaded
DEBUG 01-07 10:13:59.121377.121377 cuda_h.py:19] end sllm_worker_task cost 0.009238004684448242 seconds
INFO 01-07 10:13:59.121651.121651 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 26280acc-ead5-419f-8c94-a90abd38ccc8
DEBUG 01-07 10:13:59.121202.121202 cuda_h.py:19] end load_into_gpu_async cost 0.0010449886322021484 seconds
DEBUG 01-07 10:13:59.121713.121713 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 10:13:59.121669.121669 cuda_h.py:19] end restore_tensors2 cost 0.00022363662719726562 seconds
DEBUG 01-07 10:13:59.121577.121577 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.001771688461303711 seconds
DEBUG 01-07 10:13:59.123605.123605 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 10:13:59.123834.123834 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 10:13:59.124287.124287 cuda_h.py:19] end allocate_cuda_memory cost 0.00021338462829589844 seconds
DEBUG 01-07 10:13:59.124746.124746 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 10:13:59.124356.124356 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 10:13:59.124019.124019 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 10:13:59.124146.124146 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 4a6280f7-5926-49b8-a59d-21d3c8bd13c6
DEBUG 01-07 10:13:59.124170.124170 client.py:106] call stub.LoadModelAsync
INFO 01-07 10:13:59.125793.125793 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 4a6280f7-5926-49b8-a59d-21d3c8bd13c6
DEBUG 01-07 10:13:59.125106.125106 cuda_h.py:19] end load_into_gpu_async cost 0.0010416507720947266 seconds
DEBUG 01-07 10:13:59.125286.125286 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 10:13:59.125221.125221 cuda_h.py:19] end restore_tensors2 cost 0.00020623207092285156 seconds
DEBUG 01-07 10:13:59.125428.125428 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0017893314361572266 seconds
DEBUG 01-07 10:13:59.127801.127801 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model_multi_device cost 0.007314443588256836 seconds
DEBUG 01-07 10:13:59.127909.127909 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-07 10:13:59.127348.127348 lmp.py:816] 
DEBUG 01-07 10:13:59.127348.127348 lmp.py:816]   Computing 19 experts on CPU...
DEBUG 01-07 10:13:59.127377.127377 cuda_h.py:19] end cpu_experts_submit cost 0.00010752677917480469 seconds
DEBUG 01-07 10:13:59.127218.127218 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-07 10:13:59.133609.133609 mlpmodule.py:749] group tensors cost 0.005381584167480469 s
DEBUG 01-07 10:13:59.134626.134626 mlpmodule.py:787] pad cost 0.0010306835174560547 s
DEBUG 01-07 10:13:59.134199.134199 mlpmodule.py:793] create cpu tensor cost 4.220008850097656e-05 s
DEBUG 01-07 10:13:59.134678.134678 mlpmodule.py:798] move to cpu cost 3.3855438232421875e-05 s
DEBUG 01-07 10:13:59.145406.145406 mlpmodule.py:812] group_w3: shape=torch.Size([19, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=54788096
DEBUG 01-07 10:13:59.145889.145889 mlpmodule.py:813] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-07 10:13:59.145177.145177 mlpmodule.py:818] group_w3 first element: -0.0211181640625
WARNING 01-07 10:13:59.145685.145685 mlpmodule.py:828] start einsum2
DEBUG 01-07 10:13:59.166286.166286 mlpmodule.py:838] group einsum cost 0.031127452850341797 s
DEBUG 01-07 10:13:59.166786.166786 mlpmodule.py:846] cpy2cputensor cost 0.00048732757568359375 s
DEBUG 01-07 10:13:59.169853.169853 cuda_h.py:19] end wait_cetm_experts cost 0.041857242584228516 seconds
DEBUG 01-07 10:13:59.169300.169300 cuda_h.py:10] start gpu_sexperts
DEBUG 01-07 10:13:59.170134.170134 cuda_h.py:19] end gpu_sexperts cost 0.0005350112915039062 seconds
DEBUG 01-07 10:13:59.170877.170877 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-07 10:13:59.170250.170250 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.5033950805664062e-05 seconds
DEBUG 01-07 10:13:59.170430.170430 cuda_h.py:10] start wait_experts_multi_device
INFO 01-07 10:13:59.170617.170617 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 26280acc-ead5-419f-8c94-a90abd38ccc8
INFO 01-07 10:13:59.171284.171284 client.py:127] Model loaded
INFO 01-07 10:13:59.171167.171167 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 4a6280f7-5926-49b8-a59d-21d3c8bd13c6
INFO 01-07 10:13:59.171646.171646 client.py:127] Model loaded
DEBUG 01-07 10:13:59.171621.171621 cuda_h.py:19] end wait_experts_multi_device cost 0.0015141963958740234 seconds
DEBUG 01-07 10:13:59.171231.171231 cuda_h.py:10] start gpu_experts_multi_device
DEBUG 01-07 10:13:59.171723.171723 lmp.py:867]   Computing 23 experts on cuda:2...
DEBUG 01-07 10:13:59.173388.173388 mlpmodule.py:533] gpu group tensors cost 0.0004878044128417969 s
DEBUG 01-07 10:13:59.174506.174506 mlpmodule.py:566] gpu pad cost 0.001287698745727539 s
DEBUG 01-07 10:13:59.175752.175752 mlpmodule.py:584] gpu group einsum cost 0.0005667209625244141 s
DEBUG 01-07 10:13:59.177644.177644 mlpmodule.py:656] gpu experts func einsum cost 0.004574298858642578 s
DEBUG 01-07 10:13:59.177078.177078 lmp.py:867]   Computing 22 experts on cuda:1...
DEBUG 01-07 10:13:59.178435.178435 mlpmodule.py:533] gpu group tensors cost 0.00044035911560058594 s
DEBUG 01-07 10:13:59.179936.179936 mlpmodule.py:566] gpu pad cost 0.0012595653533935547 s
DEBUG 01-07 10:13:59.180444.180444 mlpmodule.py:584] gpu group einsum cost 0.0004832744598388672 s
DEBUG 01-07 10:13:59.182100.182100 mlpmodule.py:656] gpu experts func einsum cost 0.004302501678466797 s
DEBUG 01-07 10:13:59.182792.182792 cuda_h.py:19] end gpu_experts_multi_device cost 0.010391473770141602 seconds
DEBUG 01-07 10:13:59.182185.182185 cuda_h.py:19] end layer_moe_generate_multi_device_13 cost 0.06485557556152344 seconds
DEBUG 01-07 10:13:59.182299.182299 lmp.py:194] -------------------------------- end prefill layer 13 --------------------------------
DEBUG 01-07 10:13:59.182639.182639 lmp.py:153] -------------------------------- start prefill layer 14 --------------------------------
DEBUG 01-07 10:13:59.182958.182958 cuda_h.py:10] start start_load_qkvogn_s_weight_l_15
DEBUG 01-07 10:13:59.182873.182873 cuda_h.py:10] start start_load_qkvogn_s_weight_l_15
DEBUG 01-07 10:13:59.182663.182663 cuda_h.py:19] end start_load_qkvogn_s_weight_l_15 cost 2.8371810913085938e-05 seconds
DEBUG 01-07 10:13:59.182697.182697 cuda_h.py:19] end start_load_qkvogn_s_weight_l_15 cost 5.841255187988281e-05 seconds
DEBUG 01-07 10:13:59.182532.182532 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-07 10:13:59.182931.182931 cuda_h.py:10] start sllm_worker_task
DEBUG 01-07 10:13:59.182470.182470 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 10:13:59.183306.183306 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 10:13:59.183251.183251 cuda_h.py:19] end allocate_cuda_memory cost 0.0002753734588623047 seconds
DEBUG 01-07 10:13:59.183843.183843 mlpmodule.py:367] cuda:1 cuda:1
DEBUG 01-07 10:13:59.183341.183341 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 10:13:59.183961.183961 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 10:13:59.183545.183545 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 10:13:59.183056.183056 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, fc9712b8-280a-4733-a4de-caa54583e1eb
DEBUG 01-07 10:13:59.183780.183780 client.py:106] call stub.LoadModelAsync
DEBUG 01-07 10:13:59.183552.183552 mlpmodule.py:707]  experts func einsum cost 0.056130170822143555 s
DEBUG 01-07 10:13:59.184323.184323 cuda_h.py:10] start self_attn
INFO 01-07 10:13:59.184080.184080 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, fc9712b8-280a-4733-a4de-caa54583e1eb
DEBUG 01-07 10:13:59.184685.184685 cuda_h.py:19] end load_into_gpu_async cost 0.0010607242584228516 seconds
DEBUG 01-07 10:13:59.184957.184957 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 10:13:59.184630.184630 cuda_h.py:19] end restore_tensors2 cost 6.628036499023438e-05 seconds
DEBUG 01-07 10:13:59.184101.184101 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0017995834350585938 seconds
INFO 01-07 10:13:59.184838.184838 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, fc9712b8-280a-4733-a4de-caa54583e1eb
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-07 10:13:59.187441.187441 cuda_h.py:19] end self_attn cost 0.0036382675170898438 seconds
DEBUG 01-07 10:13:59.188471.188471 cuda_h.py:19] end iln_self_attn_paln cost 0.005263805389404297 seconds
DEBUG 01-07 10:13:59.188393.188393 cuda_h.py:10] start layer_moe_generate_multi_device_14
DEBUG 01-07 10:13:59.188818.188818 cuda_h.py:10] start gate
DEBUG 01-07 10:13:59.188214.188214 cuda_h.py:19] end gate cost 0.0007150173187255859 seconds
DEBUG 01-07 10:13:59.189613.189613 cuda_h.py:10] start experts_map_get
DEBUG 01-07 10:13:59.189283.189283 lmp.py:744] 
DEBUG 01-07 10:13:59.189283.189283 lmp.py:744] Expert Token Distribution & Multi-Device Allocation:
DEBUG 01-07 10:13:59.189205.189205 lmp.py:745]   Total experts: 64
DEBUG 01-07 10:13:59.189954.189954 lmp.py:746]   CPU experts: 19 (30%)
DEBUG 01-07 10:13:59.189220.189220 lmp.py:747]   GPU experts: 45 (70%)
DEBUG 01-07 10:13:59.189101.189101 lmp.py:748]   Number of GPU devices: 2
DEBUG 01-07 10:13:59.189029.189029 lmp.py:749] 
DEBUG 01-07 10:13:59.189029.189029 lmp.py:749]   Expert ID | Tokens | Device
DEBUG 01-07 10:13:59.189433.189433 lmp.py:750]   -----------------------------------
DEBUG 01-07 10:13:59.189798.189798 lmp.py:767]   Expert 34 |     29 | CPU
DEBUG 01-07 10:13:59.189203.189203 lmp.py:767]   Expert  7 |     30 | CPU
DEBUG 01-07 10:13:59.189369.189369 lmp.py:767]   Expert 13 |     44 | CPU
DEBUG 01-07 10:13:59.189820.189820 lmp.py:767]   Expert 54 |     75 | CPU
DEBUG 01-07 10:13:59.189509.189509 lmp.py:767]   Expert 18 |     85 | CPU
DEBUG 01-07 10:13:59.189198.189198 lmp.py:767]   Expert 49 |     86 | CPU
DEBUG 01-07 10:13:59.189285.189285 lmp.py:767]   Expert 39 |     87 | CPU
DEBUG 01-07 10:13:59.189604.189604 lmp.py:767]   Expert 59 |    103 | CPU
DEBUG 01-07 10:13:59.189009.189009 lmp.py:767]   Expert 16 |    104 | CPU
DEBUG 01-07 10:13:59.189413.189413 lmp.py:767]   Expert  0 |    109 | CPU
DEBUG 01-07 10:13:59.189818.189818 lmp.py:767]   Expert 21 |    109 | CPU
DEBUG 01-07 10:13:59.189746.189746 lmp.py:767]   Expert 41 |    118 | CPU
DEBUG 01-07 10:13:59.189912.189912 lmp.py:767]   Expert 45 |    120 | CPU
DEBUG 01-07 10:13:59.189601.189601 lmp.py:767]   Expert 22 |    123 | CPU
DEBUG 01-07 10:13:59.189052.189052 lmp.py:767]   Expert 15 |    124 | CPU
DEBUG 01-07 10:13:59.189741.189741 lmp.py:767]   Expert 17 |    130 | CPU
DEBUG 01-07 10:13:59.189715.189715 lmp.py:767]   Expert  8 |    135 | CPU
DEBUG 01-07 10:13:59.189166.189166 lmp.py:767]   Expert 61 |    135 | CPU
DEBUG 01-07 10:13:59.189485.189485 lmp.py:767]   Expert 52 |    137 | CPU
DEBUG 01-07 10:13:59.189605.189605 lmp.py:767]   Expert 35 |    140 | GPU1(cuda:2)
DEBUG 01-07 10:13:59.189248.189248 lmp.py:767]   Expert 12 |    143 | GPU1(cuda:2)
DEBUG 01-07 10:13:59.189652.189652 lmp.py:767]   Expert 48 |    143 | GPU0(cuda:1)
DEBUG 01-07 10:13:59.190295.190295 lmp.py:767]   Expert 38 |    144 | GPU1(cuda:2)
DEBUG 01-07 10:13:59.190938.190938 lmp.py:767]   Expert 31 |    153 | GPU1(cuda:2)
DEBUG 01-07 10:13:59.190403.190403 lmp.py:767]   Expert 36 |    153 | GPU0(cuda:1)
DEBUG 01-07 10:13:59.190522.190522 lmp.py:767]   Expert 50 |    158 | GPU1(cuda:2)
DEBUG 01-07 10:13:59.190927.190927 lmp.py:767]   Expert 53 |    158 | GPU0(cuda:1)
DEBUG 01-07 10:13:59.190808.190808 lmp.py:767]   Expert 40 |    163 | GPU0(cuda:1)
DEBUG 01-07 10:13:59.190928.190928 lmp.py:767]   Expert 60 |    163 | GPU0(cuda:1)
DEBUG 01-07 10:13:59.190810.190810 lmp.py:767]   Expert 27 |    174 | GPU1(cuda:2)
DEBUG 01-07 10:13:59.190976.190976 lmp.py:767]   Expert 19 |    196 | GPU0(cuda:1)
DEBUG 01-07 10:13:59.190380.190380 lmp.py:767]   Expert  4 |    198 | GPU1(cuda:2)
DEBUG 01-07 10:13:59.190546.190546 lmp.py:767]   Expert 29 |    203 | GPU1(cuda:2)
DEBUG 01-07 10:13:59.190474.190474 lmp.py:767]   Expert 30 |    206 | GPU0(cuda:1)
DEBUG 01-07 10:13:59.190462.190462 lmp.py:767]   Expert 11 |    219 | GPU0(cuda:1)
DEBUG 01-07 10:13:59.190019.190019 lmp.py:767]   Expert 26 |    219 | GPU1(cuda:2)
DEBUG 01-07 10:13:59.190377.190377 lmp.py:767]   Expert 20 |    222 | GPU0(cuda:1)
DEBUG 01-07 10:13:59.190497.190497 lmp.py:767]   Expert  6 |    225 | GPU1(cuda:2)
DEBUG 01-07 10:13:59.190140.190140 lmp.py:767]   Expert 57 |    225 | GPU1(cuda:2)
DEBUG 01-07 10:13:59.190783.190783 lmp.py:767]   Expert 43 |    228 | GPU0(cuda:1)
DEBUG 01-07 10:13:59.190141.190141 lmp.py:767]   Expert 46 |    229 | GPU0(cuda:1)
DEBUG 01-07 10:13:59.190307.190307 lmp.py:767]   Expert 23 |    241 | GPU0(cuda:1)
DEBUG 01-07 10:13:59.190473.190473 lmp.py:767]   Expert 33 |    241 | GPU1(cuda:2)
DEBUG 01-07 10:13:59.190639.190639 lmp.py:767]   Expert  2 |    242 | GPU1(cuda:2)
DEBUG 01-07 10:13:59.190806.190806 lmp.py:767]   Expert 42 |    248 | GPU0(cuda:1)
DEBUG 01-07 10:13:59.190124.190124 lmp.py:767]   Expert 56 |    251 | GPU1(cuda:2)
DEBUG 01-07 10:13:59.190529.190529 lmp.py:767]   Expert 32 |    253 | GPU1(cuda:2)
DEBUG 01-07 10:13:59.190655.190655 lmp.py:767]   Expert 55 |    253 | GPU0(cuda:1)
DEBUG 01-07 10:13:59.190298.190298 lmp.py:767]   Expert 28 |    261 | GPU0(cuda:1)
DEBUG 01-07 10:13:59.190180.190180 lmp.py:767]   Expert  9 |    262 | GPU1(cuda:2)
DEBUG 01-07 10:13:59.190061.190061 lmp.py:767]   Expert  3 |    264 | GPU1(cuda:2)
DEBUG 01-07 10:13:59.190850.190850 lmp.py:767]   Expert 14 |    264 | GPU0(cuda:1)
DEBUG 01-07 10:13:59.190685.190685 lmp.py:767]   Expert 44 |    269 | GPU0(cuda:1)
DEBUG 01-07 10:13:59.190566.190566 lmp.py:767]   Expert 51 |    275 | GPU0(cuda:1)
DEBUG 01-07 10:13:59.190448.190448 lmp.py:767]   Expert 58 |    275 | GPU1(cuda:2)
DEBUG 01-07 10:13:59.190568.190568 lmp.py:767]   Expert  1 |    277 | GPU1(cuda:2)
DEBUG 01-07 10:13:59.190409.190409 lmp.py:767]   Expert 37 |    284 | GPU0(cuda:1)
DEBUG 01-07 10:13:59.190397.190397 lmp.py:767]   Expert 47 |    287 | GPU1(cuda:2)
DEBUG 01-07 10:13:59.190947.190947 lmp.py:767]   Expert 63 |    289 | GPU0(cuda:1)
DEBUG 01-07 10:13:59.190783.190783 lmp.py:767]   Expert 24 |    306 | GPU1(cuda:2)
DEBUG 01-07 10:13:59.190379.190379 lmp.py:767]   Expert 62 |    308 | GPU0(cuda:1)
DEBUG 01-07 10:13:59.190976.190976 lmp.py:767]   Expert 10 |    309 | GPU1(cuda:2)
DEBUG 01-07 10:13:59.190572.190572 lmp.py:767]   Expert 25 |    319 | GPU1(cuda:2)
DEBUG 01-07 10:13:59.190454.190454 lmp.py:767]   Expert  5 |    365 | GPU0(cuda:1)
DEBUG 01-07 10:13:59.190382.190382 lmp.py:769] 
DEBUG 01-07 10:13:59.190382.190382 lmp.py:769]   Device Token Distribution:
DEBUG 01-07 10:13:59.190025.190025 lmp.py:770]   CPU:   1883 tokens
DEBUG 01-07 10:13:59.190098.190098 lmp.py:774]   cuda:1:   5137 tokens (22 experts)
DEBUG 01-07 10:13:59.190979.190979 lmp.py:774]   cuda:2:   5268 tokens (23 experts)
DEBUG 01-07 10:13:59.190252.190252 lmp.py:775]   Total GPU:  10405 tokens
DEBUG 01-07 10:13:59.190094.190094 lmp.py:776] ============================================================
DEBUG 01-07 10:13:59.190094.190094 lmp.py:776] 
DEBUG 01-07 10:13:59.190843.190843 cuda_h.py:19] end experts_map_get cost 0.0018951892852783203 seconds
DEBUG 01-07 10:13:59.190870.190870 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model_multi_device
DEBUG 01-07 10:13:59.190408.190408 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 10:13:59.191015.191015 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 10:13:59.191944.191944 cuda_h.py:19] end allocate_cuda_memory cost 0.0002281665802001953 seconds
DEBUG 01-07 10:13:59.191787.191787 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 10:13:59.191636.191636 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 10:13:59.191776.191776 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 10:13:59.191380.191380 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 95f179be-1255-44b8-827b-7650adfb03c7
DEBUG 01-07 10:13:59.191696.191696 client.py:106] call stub.LoadModelAsync
INFO 01-07 10:13:59.191123.191123 client.py:127] Model loaded
DEBUG 01-07 10:13:59.192463.192463 cuda_h.py:19] end sllm_worker_task cost 0.009266853332519531 seconds
INFO 01-07 10:13:59.192695.192695 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 95f179be-1255-44b8-827b-7650adfb03c7
DEBUG 01-07 10:13:59.192975.192975 cuda_h.py:19] end load_into_gpu_async cost 0.001230001449584961 seconds
DEBUG 01-07 10:13:59.192255.192255 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 10:13:59.192217.192217 cuda_h.py:19] end restore_tensors2 cost 0.0002276897430419922 seconds
DEBUG 01-07 10:13:59.193840.193840 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0020132064819335938 seconds
DEBUG 01-07 10:13:59.194173.194173 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 10:13:59.194005.194005 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 10:13:59.195464.195464 cuda_h.py:19] end allocate_cuda_memory cost 0.0002281665802001953 seconds
DEBUG 01-07 10:13:59.195990.195990 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 10:13:59.195945.195945 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 10:13:59.195906.195906 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 10:13:59.195662.195662 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 1381ea69-0838-4b0c-b81d-ea58eba1d4ed
DEBUG 01-07 10:13:59.195602.195602 client.py:106] call stub.LoadModelAsync
INFO 01-07 10:13:59.196269.196269 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 1381ea69-0838-4b0c-b81d-ea58eba1d4ed
DEBUG 01-07 10:13:59.196172.196172 cuda_h.py:19] end load_into_gpu_async cost 0.0012519359588623047 seconds
DEBUG 01-07 10:13:59.196935.196935 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 10:13:59.196972.196972 cuda_h.py:19] end restore_tensors2 cost 0.00027370452880859375 seconds
DEBUG 01-07 10:13:59.197186.197186 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.002101421356201172 seconds
DEBUG 01-07 10:13:59.199532.199532 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model_multi_device cost 0.008464574813842773 seconds
DEBUG 01-07 10:13:59.199322.199322 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-07 10:13:59.199981.199981 lmp.py:816] 
DEBUG 01-07 10:13:59.199981.199981 lmp.py:816]   Computing 19 experts on CPU...
DEBUG 01-07 10:13:59.199983.199983 cuda_h.py:19] end cpu_experts_submit cost 0.0001354217529296875 seconds
DEBUG 01-07 10:13:59.199170.199170 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-07 10:13:59.205743.205743 mlpmodule.py:749] group tensors cost 0.005296468734741211 s
DEBUG 01-07 10:13:59.206411.206411 mlpmodule.py:787] pad cost 0.0011043548583984375 s
DEBUG 01-07 10:13:59.207361.207361 mlpmodule.py:793] create cpu tensor cost 4.315376281738281e-05 s
DEBUG 01-07 10:13:59.207556.207556 mlpmodule.py:798] move to cpu cost 3.314018249511719e-05 s
DEBUG 01-07 10:13:59.217425.217425 mlpmodule.py:812] group_w3: shape=torch.Size([19, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=54788096
DEBUG 01-07 10:13:59.217424.217424 mlpmodule.py:813] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-07 10:13:59.218136.218136 mlpmodule.py:818] group_w3 first element: 0.000789642333984375
WARNING 01-07 10:13:59.218213.218213 mlpmodule.py:828] start einsum2
DEBUG 01-07 10:13:59.238927.238927 mlpmodule.py:838] group einsum cost 0.03158068656921387 s
DEBUG 01-07 10:13:59.239100.239100 mlpmodule.py:846] cpy2cputensor cost 0.0004115104675292969 s
DEBUG 01-07 10:13:59.241817.241817 cuda_h.py:19] end wait_cetm_experts cost 0.04220938682556152 seconds
DEBUG 01-07 10:13:59.242078.242078 cuda_h.py:10] start gpu_sexperts
DEBUG 01-07 10:13:59.242408.242408 cuda_h.py:19] end gpu_sexperts cost 0.0005133152008056641 seconds
DEBUG 01-07 10:13:59.242710.242710 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-07 10:13:59.242758.242758 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.6464462280273438e-05 seconds
DEBUG 01-07 10:13:59.242091.242091 cuda_h.py:10] start wait_experts_multi_device
INFO 01-07 10:13:59.242284.242284 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 95f179be-1255-44b8-827b-7650adfb03c7
INFO 01-07 10:13:59.243592.243592 client.py:127] Model loaded
INFO 01-07 10:13:59.243972.243972 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 1381ea69-0838-4b0c-b81d-ea58eba1d4ed
INFO 01-07 10:13:59.244538.244538 client.py:127] Model loaded
DEBUG 01-07 10:13:59.244136.244136 cuda_h.py:19] end wait_experts_multi_device cost 0.0015065670013427734 seconds
DEBUG 01-07 10:13:59.244958.244958 cuda_h.py:10] start gpu_experts_multi_device
DEBUG 01-07 10:13:59.244642.244642 lmp.py:867]   Computing 23 experts on cuda:2...
DEBUG 01-07 10:13:59.245794.245794 mlpmodule.py:533] gpu group tensors cost 0.00047779083251953125 s
DEBUG 01-07 10:13:59.246580.246580 mlpmodule.py:566] gpu pad cost 0.0012543201446533203 s
DEBUG 01-07 10:13:59.247845.247845 mlpmodule.py:584] gpu group einsum cost 0.0005450248718261719 s
DEBUG 01-07 10:13:59.249212.249212 mlpmodule.py:656] gpu experts func einsum cost 0.004474163055419922 s
DEBUG 01-07 10:13:59.249428.249428 lmp.py:867]   Computing 22 experts on cuda:1...
DEBUG 01-07 10:13:59.250074.250074 mlpmodule.py:533] gpu group tensors cost 0.0004341602325439453 s
DEBUG 01-07 10:13:59.250903.250903 mlpmodule.py:707]  experts func einsum cost 0.051041364669799805 s
DEBUG 01-07 10:13:59.252200.252200 mlpmodule.py:566] gpu pad cost 0.0013270378112792969 s
DEBUG 01-07 10:13:59.252419.252419 mlpmodule.py:584] gpu group einsum cost 0.0004994869232177734 s
DEBUG 01-07 10:13:59.254484.254484 mlpmodule.py:656] gpu experts func einsum cost 0.00435185432434082 s
DEBUG 01-07 10:13:59.254182.254182 cuda_h.py:19] end gpu_experts_multi_device cost 0.01021265983581543 seconds
DEBUG 01-07 10:13:59.254006.254006 cuda_h.py:19] end layer_moe_generate_multi_device_14 cost 0.06653809547424316 seconds
DEBUG 01-07 10:13:59.254034.254034 lmp.py:194] -------------------------------- end prefill layer 14 --------------------------------
DEBUG 01-07 10:13:59.255042.255042 lmp.py:153] -------------------------------- start prefill layer 15 --------------------------------
DEBUG 01-07 10:13:59.255976.255976 cuda_h.py:10] start start_load_qkvogn_s_weight_l_16
DEBUG 01-07 10:13:59.255362.255362 cuda_h.py:10] start start_load_qkvogn_s_weight_l_16
DEBUG 01-07 10:13:59.255158.255158 cuda_h.py:19] end start_load_qkvogn_s_weight_l_16 cost 3.0994415283203125e-05 seconds
DEBUG 01-07 10:13:59.255710.255710 cuda_h.py:19] end start_load_qkvogn_s_weight_l_16 cost 9.202957153320312e-05 seconds
DEBUG 01-07 10:13:59.255545.255545 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-07 10:13:59.255143.255143 mlpmodule.py:367] cuda:1 cuda:1
DEBUG 01-07 10:13:59.255562.255562 cuda_h.py:10] start sllm_worker_task
DEBUG 01-07 10:13:59.255511.255511 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 10:13:59.255917.255917 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 10:13:59.255345.255345 cuda_h.py:19] end allocate_cuda_memory cost 0.00028133392333984375 seconds
DEBUG 01-07 10:13:59.255454.255454 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 10:13:59.255071.255071 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 10:13:59.255940.255940 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 10:13:59.255689.255689 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, e2d2f933-e82c-4166-a7c9-b348664741bb
DEBUG 01-07 10:13:59.256460.256460 client.py:106] call stub.LoadModelAsync
DEBUG 01-07 10:13:59.256600.256600 cuda_h.py:10] start self_attn
INFO 01-07 10:13:59.256781.256781 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, e2d2f933-e82c-4166-a7c9-b348664741bb
DEBUG 01-07 10:13:59.256677.256677 cuda_h.py:19] end load_into_gpu_async cost 0.0009019374847412109 seconds
DEBUG 01-07 10:13:59.256711.256711 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 10:13:59.256655.256655 cuda_h.py:19] end restore_tensors2 cost 6.961822509765625e-05 seconds
DEBUG 01-07 10:13:59.256172.256172 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0015070438385009766 seconds
INFO 01-07 10:13:59.257976.257976 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, e2d2f933-e82c-4166-a7c9-b348664741bb
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-07 10:13:59.259738.259738 cuda_h.py:19] end self_attn cost 0.003656625747680664 seconds
DEBUG 01-07 10:13:59.260252.260252 cuda_h.py:19] end iln_self_attn_paln cost 0.005057811737060547 seconds
DEBUG 01-07 10:13:59.260651.260651 cuda_h.py:10] start layer_moe_generate_multi_device_15
DEBUG 01-07 10:13:59.260599.260599 cuda_h.py:10] start gate
DEBUG 01-07 10:13:59.261668.261668 cuda_h.py:19] end gate cost 0.0006411075592041016 seconds
DEBUG 01-07 10:13:59.261828.261828 cuda_h.py:10] start experts_map_get
DEBUG 01-07 10:13:59.261710.261710 lmp.py:744] 
DEBUG 01-07 10:13:59.261710.261710 lmp.py:744] Expert Token Distribution & Multi-Device Allocation:
DEBUG 01-07 10:13:59.261565.261565 lmp.py:745]   Total experts: 64
DEBUG 01-07 10:13:59.261884.261884 lmp.py:746]   CPU experts: 19 (30%)
DEBUG 01-07 10:13:59.261626.261626 lmp.py:747]   GPU experts: 45 (70%)
DEBUG 01-07 10:13:59.261223.261223 lmp.py:748]   Number of GPU devices: 2
DEBUG 01-07 10:13:59.261581.261581 lmp.py:749] 
DEBUG 01-07 10:13:59.261581.261581 lmp.py:749]   Expert ID | Tokens | Device
DEBUG 01-07 10:13:59.261939.261939 lmp.py:750]   -----------------------------------
DEBUG 01-07 10:13:59.261781.261781 lmp.py:767]   Expert 15 |     64 | CPU
DEBUG 01-07 10:13:59.261662.261662 lmp.py:767]   Expert 41 |     69 | CPU
DEBUG 01-07 10:13:59.261067.261067 lmp.py:767]   Expert  0 |     76 | CPU
DEBUG 01-07 10:13:59.261948.261948 lmp.py:767]   Expert 63 |     76 | CPU
DEBUG 01-07 10:13:59.261591.261591 lmp.py:767]   Expert 20 |     83 | CPU
DEBUG 01-07 10:13:59.261757.261757 lmp.py:767]   Expert 45 |     88 | CPU
DEBUG 01-07 10:13:59.261639.261639 lmp.py:767]   Expert  7 |     90 | CPU
DEBUG 01-07 10:13:59.261282.261282 lmp.py:767]   Expert 28 |     98 | CPU
DEBUG 01-07 10:13:59.261163.261163 lmp.py:767]   Expert 54 |    105 | CPU
DEBUG 01-07 10:13:59.261806.261806 lmp.py:767]   Expert 12 |    110 | CPU
DEBUG 01-07 10:13:59.261926.261926 lmp.py:767]   Expert 52 |    120 | CPU
DEBUG 01-07 10:13:59.261092.261092 lmp.py:767]   Expert 40 |    121 | CPU
DEBUG 01-07 10:13:59.261497.261497 lmp.py:767]   Expert  5 |    123 | CPU
DEBUG 01-07 10:13:59.261186.261186 lmp.py:767]   Expert 59 |    123 | CPU
DEBUG 01-07 10:13:59.261114.261114 lmp.py:767]   Expert  4 |    130 | CPU
DEBUG 01-07 10:13:59.261280.261280 lmp.py:767]   Expert 34 |    131 | CPU
DEBUG 01-07 10:13:59.261208.261208 lmp.py:767]   Expert 62 |    131 | CPU
DEBUG 01-07 10:13:59.261374.261374 lmp.py:767]   Expert 55 |    138 | CPU
DEBUG 01-07 10:13:59.261301.261301 lmp.py:767]   Expert 13 |    139 | CPU
DEBUG 01-07 10:13:59.262898.262898 lmp.py:767]   Expert 21 |    139 | GPU1(cuda:2)
DEBUG 01-07 10:13:59.262733.262733 lmp.py:767]   Expert 14 |    141 | GPU0(cuda:1)
DEBUG 01-07 10:13:59.262568.262568 lmp.py:767]   Expert 42 |    141 | GPU1(cuda:2)
DEBUG 01-07 10:13:59.262403.262403 lmp.py:767]   Expert 61 |    141 | GPU0(cuda:1)
DEBUG 01-07 10:13:59.262762.262762 lmp.py:767]   Expert 10 |    144 | GPU1(cuda:2)
DEBUG 01-07 10:13:59.262358.262358 lmp.py:767]   Expert 22 |    147 | GPU0(cuda:1)
DEBUG 01-07 10:13:59.262240.262240 lmp.py:767]   Expert 51 |    154 | GPU1(cuda:2)
DEBUG 01-07 10:13:59.262883.262883 lmp.py:767]   Expert 32 |    158 | GPU0(cuda:1)
DEBUG 01-07 10:13:59.262764.262764 lmp.py:767]   Expert 25 |    166 | GPU1(cuda:2)
DEBUG 01-07 10:13:59.262645.262645 lmp.py:767]   Expert 50 |    171 | GPU0(cuda:1)
DEBUG 01-07 10:13:59.262527.262527 lmp.py:767]   Expert 53 |    175 | GPU1(cuda:2)
DEBUG 01-07 10:13:59.262170.262170 lmp.py:767]   Expert 47 |    177 | GPU0(cuda:1)
DEBUG 01-07 10:13:59.262051.262051 lmp.py:767]   Expert 19 |    178 | GPU1(cuda:2)
DEBUG 01-07 10:13:59.262409.262409 lmp.py:767]   Expert  1 |    179 | GPU0(cuda:1)
DEBUG 01-07 10:13:59.262244.262244 lmp.py:767]   Expert 26 |    180 | GPU1(cuda:2)
DEBUG 01-07 10:13:59.262603.262603 lmp.py:767]   Expert 35 |    181 | GPU0(cuda:1)
DEBUG 01-07 10:13:59.262961.262961 lmp.py:767]   Expert  6 |    182 | GPU1(cuda:2)
DEBUG 01-07 10:13:59.262081.262081 lmp.py:767]   Expert  2 |    184 | GPU0(cuda:1)
DEBUG 01-07 10:13:59.262724.262724 lmp.py:767]   Expert 11 |    185 | GPU0(cuda:1)
DEBUG 01-07 10:13:59.262367.262367 lmp.py:767]   Expert 30 |    185 | GPU1(cuda:2)
DEBUG 01-07 10:13:59.262248.262248 lmp.py:767]   Expert 56 |    191 | GPU1(cuda:2)
DEBUG 01-07 10:13:59.262891.262891 lmp.py:767]   Expert 57 |    192 | GPU0(cuda:1)
DEBUG 01-07 10:13:59.262772.262772 lmp.py:767]   Expert 48 |    204 | GPU1(cuda:2)
DEBUG 01-07 10:13:59.262654.262654 lmp.py:767]   Expert 44 |    209 | GPU0(cuda:1)
DEBUG 01-07 10:13:59.262012.262012 lmp.py:767]   Expert 24 |    210 | GPU1(cuda:2)
DEBUG 01-07 10:13:59.262370.262370 lmp.py:767]   Expert 46 |    216 | GPU0(cuda:1)
DEBUG 01-07 10:13:59.262728.262728 lmp.py:767]   Expert 16 |    220 | GPU1(cuda:2)
DEBUG 01-07 10:13:59.262848.262848 lmp.py:767]   Expert 18 |    227 | GPU0(cuda:1)
DEBUG 01-07 10:13:59.262160.262160 lmp.py:767]   Expert 39 |    230 | GPU1(cuda:2)
DEBUG 01-07 10:13:59.262803.262803 lmp.py:767]   Expert 29 |    231 | GPU0(cuda:1)
DEBUG 01-07 10:13:59.262446.262446 lmp.py:767]   Expert 37 |    242 | GPU1(cuda:2)
DEBUG 01-07 10:13:59.262851.262851 lmp.py:767]   Expert 31 |    255 | GPU0(cuda:1)
DEBUG 01-07 10:13:59.262732.262732 lmp.py:767]   Expert  3 |    256 | GPU0(cuda:1)
DEBUG 01-07 10:13:59.262137.262137 lmp.py:767]   Expert 36 |    256 | GPU1(cuda:2)
DEBUG 01-07 10:13:59.262018.262018 lmp.py:767]   Expert 60 |    257 | GPU1(cuda:2)
DEBUG 01-07 10:13:59.262899.262899 lmp.py:767]   Expert 38 |    264 | GPU0(cuda:1)
DEBUG 01-07 10:13:59.262781.262781 lmp.py:767]   Expert  9 |    267 | GPU0(cuda:1)
DEBUG 01-07 10:13:59.262424.262424 lmp.py:767]   Expert 17 |    267 | GPU1(cuda:2)
DEBUG 01-07 10:13:59.262782.262782 lmp.py:767]   Expert 23 |    275 | GPU1(cuda:2)
DEBUG 01-07 10:13:59.262902.262902 lmp.py:767]   Expert 27 |    352 | GPU0(cuda:1)
DEBUG 01-07 10:13:59.262499.262499 lmp.py:767]   Expert 43 |    354 | GPU1(cuda:2)
DEBUG 01-07 10:13:59.262857.262857 lmp.py:767]   Expert  8 |    398 | GPU0(cuda:1)
DEBUG 01-07 10:13:59.262500.262500 lmp.py:767]   Expert 33 |    401 | GPU1(cuda:2)
DEBUG 01-07 10:13:59.262143.262143 lmp.py:767]   Expert 58 |    444 | GPU1(cuda:2)
DEBUG 01-07 10:13:59.262786.262786 lmp.py:767]   Expert 49 |    547 | GPU0(cuda:1)
DEBUG 01-07 10:13:59.262237.262237 lmp.py:769] 
DEBUG 01-07 10:13:59.262237.262237 lmp.py:769]   Device Token Distribution:
DEBUG 01-07 10:13:59.262118.262118 lmp.py:770]   CPU:   2015 tokens
DEBUG 01-07 10:13:59.262476.262476 lmp.py:774]   cuda:1:   5078 tokens (22 experts)
DEBUG 01-07 10:13:59.262596.262596 lmp.py:774]   cuda:2:   5195 tokens (23 experts)
DEBUG 01-07 10:13:59.262762.262762 lmp.py:775]   Total GPU:  10273 tokens
DEBUG 01-07 10:13:59.262644.262644 lmp.py:776] ============================================================
DEBUG 01-07 10:13:59.262644.262644 lmp.py:776] 
DEBUG 01-07 10:13:59.262009.262009 cuda_h.py:19] end experts_map_get cost 0.0017893314361572266 seconds
DEBUG 01-07 10:13:59.262559.262559 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model_multi_device
DEBUG 01-07 10:13:59.262382.262382 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 10:13:59.263902.263902 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 10:13:59.263353.263353 cuda_h.py:19] end allocate_cuda_memory cost 0.0001971721649169922 seconds
DEBUG 01-07 10:13:59.263017.263017 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 10:13:59.263489.263489 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 10:13:59.263775.263775 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 10:13:59.263709.263709 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 530da3db-a991-47e9-9848-5cd9acd9b1a3
DEBUG 01-07 10:13:59.263760.263760 client.py:106] call stub.LoadModelAsync
INFO 01-07 10:13:59.263242.263242 client.py:127] Model loaded
DEBUG 01-07 10:13:59.264599.264599 cuda_h.py:19] end sllm_worker_task cost 0.008738517761230469 seconds
INFO 01-07 10:13:59.264183.264183 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 530da3db-a991-47e9-9848-5cd9acd9b1a3
DEBUG 01-07 10:13:59.264596.264596 cuda_h.py:19] end load_into_gpu_async cost 0.0010251998901367188 seconds
DEBUG 01-07 10:13:59.264868.264868 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 10:13:59.264161.264161 cuda_h.py:19] end restore_tensors2 cost 0.00022649765014648438 seconds
DEBUG 01-07 10:13:59.264262.264262 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0017507076263427734 seconds
DEBUG 01-07 10:13:59.266065.266065 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 10:13:59.266473.266473 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 10:13:59.266197.266197 cuda_h.py:19] end allocate_cuda_memory cost 0.0002155303955078125 seconds
DEBUG 01-07 10:13:59.267702.267702 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 10:13:59.267312.267312 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 10:13:59.267975.267975 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 10:13:59.267340.267340 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 89a45f06-ac8e-44c6-b551-406849c07f54
DEBUG 01-07 10:13:59.267948.267948 client.py:106] call stub.LoadModelAsync
INFO 01-07 10:13:59.268548.268548 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 89a45f06-ac8e-44c6-b551-406849c07f54
DEBUG 01-07 10:13:59.268232.268232 cuda_h.py:19] end load_into_gpu_async cost 0.0011682510375976562 seconds
DEBUG 01-07 10:13:59.268359.268359 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 10:13:59.268247.268247 cuda_h.py:19] end restore_tensors2 cost 0.00020885467529296875 seconds
DEBUG 01-07 10:13:59.268209.268209 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.001882314682006836 seconds
DEBUG 01-07 10:13:59.270754.270754 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model_multi_device cost 0.00738525390625 seconds
DEBUG 01-07 10:13:59.270954.270954 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-07 10:13:59.270824.270824 lmp.py:816] 
DEBUG 01-07 10:13:59.270824.270824 lmp.py:816]   Computing 19 experts on CPU...
DEBUG 01-07 10:13:59.270330.270330 cuda_h.py:19] end cpu_experts_submit cost 0.00010848045349121094 seconds
DEBUG 01-07 10:13:59.270410.270410 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-07 10:13:59.276034.276034 mlpmodule.py:749] group tensors cost 0.005457639694213867 s
DEBUG 01-07 10:13:59.278594.278594 mlpmodule.py:787] pad cost 0.001199960708618164 s
DEBUG 01-07 10:13:59.278505.278505 mlpmodule.py:793] create cpu tensor cost 4.601478576660156e-05 s
DEBUG 01-07 10:13:59.278375.278375 mlpmodule.py:798] move to cpu cost 3.647804260253906e-05 s
DEBUG 01-07 10:13:59.288459.288459 mlpmodule.py:812] group_w3: shape=torch.Size([19, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=54788096
DEBUG 01-07 10:13:59.288262.288262 mlpmodule.py:813] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-07 10:13:59.288835.288835 mlpmodule.py:818] group_w3 first element: -0.0595703125
WARNING 01-07 10:13:59.288104.288104 mlpmodule.py:828] start einsum2
DEBUG 01-07 10:13:59.307479.307479 mlpmodule.py:838] group einsum cost 0.02892279624938965 s
DEBUG 01-07 10:13:59.307329.307329 mlpmodule.py:846] cpy2cputensor cost 0.00045943260192871094 s
DEBUG 01-07 10:13:59.310285.310285 cuda_h.py:19] end wait_cetm_experts cost 0.039926767349243164 seconds
DEBUG 01-07 10:13:59.310155.310155 cuda_h.py:10] start gpu_sexperts
DEBUG 01-07 10:13:59.311400.311400 cuda_h.py:19] end gpu_sexperts cost 0.00055694580078125 seconds
DEBUG 01-07 10:13:59.311151.311151 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-07 10:13:59.311915.311915 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 3.1948089599609375e-05 seconds
DEBUG 01-07 10:13:59.311386.311386 cuda_h.py:10] start wait_experts_multi_device
INFO 01-07 10:13:59.311049.311049 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 530da3db-a991-47e9-9848-5cd9acd9b1a3
INFO 01-07 10:13:59.312726.312726 client.py:127] Model loaded
INFO 01-07 10:13:59.312708.312708 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 89a45f06-ac8e-44c6-b551-406849c07f54
INFO 01-07 10:13:59.313994.313994 client.py:127] Model loaded
DEBUG 01-07 10:13:59.313605.313605 cuda_h.py:19] end wait_experts_multi_device cost 0.0021653175354003906 seconds
DEBUG 01-07 10:13:59.313792.313792 cuda_h.py:10] start gpu_experts_multi_device
DEBUG 01-07 10:13:59.313568.313568 lmp.py:867]   Computing 23 experts on cuda:2...
DEBUG 01-07 10:13:59.314085.314085 mlpmodule.py:533] gpu group tensors cost 0.00047898292541503906 s
DEBUG 01-07 10:13:59.316686.316686 mlpmodule.py:566] gpu pad cost 0.001294851303100586 s
DEBUG 01-07 10:13:59.316643.316643 mlpmodule.py:584] gpu group einsum cost 0.0006008148193359375 s
DEBUG 01-07 10:13:59.318195.318195 mlpmodule.py:656] gpu experts func einsum cost 0.004563570022583008 s
DEBUG 01-07 10:13:59.319483.319483 lmp.py:867]   Computing 22 experts on cuda:1...
DEBUG 01-07 10:13:59.319260.319260 mlpmodule.py:707]  experts func einsum cost 0.049216508865356445 s
DEBUG 01-07 10:13:59.320259.320259 mlpmodule.py:533] gpu group tensors cost 0.0005393028259277344 s
DEBUG 01-07 10:13:59.321794.321794 mlpmodule.py:566] gpu pad cost 0.0012691020965576172 s
DEBUG 01-07 10:13:59.321912.321912 mlpmodule.py:584] gpu group einsum cost 0.00047516822814941406 s
DEBUG 01-07 10:13:59.323525.323525 mlpmodule.py:656] gpu experts func einsum cost 0.004321575164794922 s
DEBUG 01-07 10:13:59.323932.323932 cuda_h.py:19] end gpu_experts_multi_device cost 0.01029205322265625 seconds
DEBUG 01-07 10:13:59.324133.324133 cuda_h.py:19] end layer_moe_generate_multi_device_15 cost 0.06363439559936523 seconds
DEBUG 01-07 10:13:59.324948.324948 lmp.py:194] -------------------------------- end prefill layer 15 --------------------------------
DEBUG 01-07 10:13:59.324030.324030 lmp.py:153] -------------------------------- start prefill layer 16 --------------------------------
DEBUG 01-07 10:13:59.324760.324760 cuda_h.py:10] start start_load_qkvogn_s_weight_l_17
DEBUG 01-07 10:13:59.324946.324946 cuda_h.py:10] start start_load_qkvogn_s_weight_l_17
DEBUG 01-07 10:13:59.324889.324889 cuda_h.py:19] end start_load_qkvogn_s_weight_l_17 cost 2.8848648071289062e-05 seconds
DEBUG 01-07 10:13:59.324830.324830 cuda_h.py:19] end start_load_qkvogn_s_weight_l_17 cost 6.079673767089844e-05 seconds
DEBUG 01-07 10:13:59.324904.324904 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-07 10:13:59.324999.324999 mlpmodule.py:367] cuda:1 cuda:1
DEBUG 01-07 10:13:59.324279.324279 cuda_h.py:10] start sllm_worker_task
DEBUG 01-07 10:13:59.324275.324275 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 10:13:59.324104.324104 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 10:13:59.325280.325280 cuda_h.py:19] end allocate_cuda_memory cost 0.00027060508728027344 seconds
DEBUG 01-07 10:13:59.325243.325243 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 10:13:59.325489.325489 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 10:13:59.325550.325550 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 10:13:59.325108.325108 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 0bc25c79-261a-47b9-822d-4943ef875ea1
DEBUG 01-07 10:13:59.325302.325302 client.py:106] call stub.LoadModelAsync
DEBUG 01-07 10:13:59.325158.325158 cuda_h.py:10] start self_attn
INFO 01-07 10:13:59.325510.325510 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 0bc25c79-261a-47b9-822d-4943ef875ea1
DEBUG 01-07 10:13:59.326208.326208 cuda_h.py:19] end load_into_gpu_async cost 0.0008871555328369141 seconds
DEBUG 01-07 10:13:59.326957.326957 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 10:13:59.326794.326794 cuda_h.py:19] end restore_tensors2 cost 6.4849853515625e-05 seconds
DEBUG 01-07 10:13:59.326835.326835 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0014696121215820312 seconds
INFO 01-07 10:13:59.326134.326134 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 0bc25c79-261a-47b9-822d-4943ef875ea1
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-07 10:13:59.329263.329263 cuda_h.py:19] end self_attn cost 0.0036678314208984375 seconds
DEBUG 01-07 10:13:59.329677.329677 cuda_h.py:19] end iln_self_attn_paln cost 0.005071878433227539 seconds
DEBUG 01-07 10:13:59.329520.329520 cuda_h.py:10] start layer_moe_generate_multi_device_16
DEBUG 01-07 10:13:59.329801.329801 cuda_h.py:10] start gate
DEBUG 01-07 10:13:59.330691.330691 cuda_h.py:19] end gate cost 0.0006558895111083984 seconds
DEBUG 01-07 10:13:59.330044.330044 cuda_h.py:10] start experts_map_get
DEBUG 01-07 10:13:59.330084.330084 lmp.py:744] 
DEBUG 01-07 10:13:59.330084.330084 lmp.py:744] Expert Token Distribution & Multi-Device Allocation:
DEBUG 01-07 10:13:59.330768.330768 lmp.py:745]   Total experts: 64
DEBUG 01-07 10:13:59.330040.330040 lmp.py:746]   CPU experts: 19 (30%)
DEBUG 01-07 10:13:59.330829.330829 lmp.py:747]   GPU experts: 45 (70%)
DEBUG 01-07 10:13:59.330472.330472 lmp.py:748]   Number of GPU devices: 2
DEBUG 01-07 10:13:59.330638.330638 lmp.py:749] 
DEBUG 01-07 10:13:59.330638.330638 lmp.py:749]   Expert ID | Tokens | Device
DEBUG 01-07 10:13:59.331328.331328 lmp.py:750]   -----------------------------------
DEBUG 01-07 10:13:59.331454.331454 lmp.py:767]   Expert 58 |     36 | CPU
DEBUG 01-07 10:13:59.331097.331097 lmp.py:767]   Expert 47 |     59 | CPU
DEBUG 01-07 10:13:59.331025.331025 lmp.py:767]   Expert 31 |     61 | CPU
DEBUG 01-07 10:13:59.331158.331158 lmp.py:767]   Expert 49 |     61 | CPU
DEBUG 01-07 10:13:59.331046.331046 lmp.py:767]   Expert  4 |     64 | CPU
DEBUG 01-07 10:13:59.331736.331736 lmp.py:767]   Expert 45 |     70 | CPU
DEBUG 01-07 10:13:59.331663.331663 lmp.py:767]   Expert 38 |     71 | CPU
DEBUG 01-07 10:13:59.331591.331591 lmp.py:767]   Expert 41 |     83 | CPU
DEBUG 01-07 10:13:59.331280.331280 lmp.py:767]   Expert 43 |     83 | CPU
DEBUG 01-07 10:13:59.331970.331970 lmp.py:767]   Expert 33 |     95 | CPU
DEBUG 01-07 10:13:59.331944.331944 lmp.py:767]   Expert 50 |     97 | CPU
DEBUG 01-07 10:13:59.331395.331395 lmp.py:767]   Expert 57 |    100 | CPU
DEBUG 01-07 10:13:59.331130.331130 lmp.py:767]   Expert 11 |    110 | CPU
DEBUG 01-07 10:13:59.331104.331104 lmp.py:767]   Expert  2 |    116 | CPU
DEBUG 01-07 10:13:59.331317.331317 lmp.py:767]   Expert 51 |    116 | CPU
DEBUG 01-07 10:13:59.331397.331397 lmp.py:767]   Expert  0 |    120 | CPU
DEBUG 01-07 10:13:59.331325.331325 lmp.py:767]   Expert 14 |    123 | CPU
DEBUG 01-07 10:13:59.331299.331299 lmp.py:767]   Expert 54 |    126 | CPU
DEBUG 01-07 10:13:59.331035.331035 lmp.py:767]   Expert 26 |    141 | CPU
DEBUG 01-07 10:13:59.331592.331592 lmp.py:767]   Expert 56 |    142 | GPU1(cuda:2)
DEBUG 01-07 10:13:59.331904.331904 lmp.py:767]   Expert 34 |    144 | GPU1(cuda:2)
DEBUG 01-07 10:13:59.331500.331500 lmp.py:767]   Expert 27 |    156 | GPU0(cuda:1)
DEBUG 01-07 10:13:59.331143.331143 lmp.py:767]   Expert 10 |    158 | GPU0(cuda:1)
DEBUG 01-07 10:13:59.331025.331025 lmp.py:767]   Expert 28 |    158 | GPU0(cuda:1)
DEBUG 01-07 10:13:59.331906.331906 lmp.py:767]   Expert 55 |    158 | GPU1(cuda:2)
DEBUG 01-07 10:13:59.331310.331310 lmp.py:767]   Expert 25 |    163 | GPU1(cuda:2)
DEBUG 01-07 10:13:59.331238.331238 lmp.py:767]   Expert  9 |    176 | GPU0(cuda:1)
DEBUG 01-07 10:13:59.331166.331166 lmp.py:767]   Expert 13 |    183 | GPU1(cuda:2)
DEBUG 01-07 10:13:59.331094.331094 lmp.py:767]   Expert 61 |    186 | GPU0(cuda:1)
DEBUG 01-07 10:13:59.331545.331545 lmp.py:767]   Expert 48 |    188 | GPU1(cuda:2)
DEBUG 01-07 10:13:59.331824.331824 lmp.py:767]   Expert  7 |    193 | GPU0(cuda:1)
DEBUG 01-07 10:13:59.331182.331182 lmp.py:767]   Expert  6 |    194 | GPU1(cuda:2)
DEBUG 01-07 10:13:59.331825.331825 lmp.py:767]   Expert 46 |    201 | GPU0(cuda:1)
DEBUG 01-07 10:13:59.331183.331183 lmp.py:767]   Expert 24 |    202 | GPU1(cuda:2)
DEBUG 01-07 10:13:59.331826.331826 lmp.py:767]   Expert 42 |    203 | GPU0(cuda:1)
DEBUG 01-07 10:13:59.331231.331231 lmp.py:767]   Expert 18 |    204 | GPU1(cuda:2)
DEBUG 01-07 10:13:59.331635.331635 lmp.py:767]   Expert 40 |    208 | GPU0(cuda:1)
DEBUG 01-07 10:13:59.331563.331563 lmp.py:767]   Expert 63 |    213 | GPU1(cuda:2)
DEBUG 01-07 10:13:59.331491.331491 lmp.py:767]   Expert 29 |    214 | GPU0(cuda:1)
DEBUG 01-07 10:13:59.331180.331180 lmp.py:767]   Expert 59 |    217 | GPU1(cuda:2)
DEBUG 01-07 10:13:59.331869.331869 lmp.py:767]   Expert 12 |    219 | GPU0(cuda:1)
DEBUG 01-07 10:13:59.331711.331711 lmp.py:767]   Expert 21 |    222 | GPU1(cuda:2)
DEBUG 01-07 10:13:59.331315.331315 lmp.py:767]   Expert 22 |    224 | GPU1(cuda:2)
DEBUG 01-07 10:13:59.331958.331958 lmp.py:767]   Expert 32 |    224 | GPU0(cuda:1)
DEBUG 01-07 10:13:59.331600.331600 lmp.py:767]   Expert 19 |    231 | GPU0(cuda:1)
DEBUG 01-07 10:13:59.331482.331482 lmp.py:767]   Expert 36 |    233 | GPU1(cuda:2)
DEBUG 01-07 10:13:59.331125.331125 lmp.py:767]   Expert  3 |    242 | GPU0(cuda:1)
DEBUG 01-07 10:13:59.331768.331768 lmp.py:767]   Expert 37 |    243 | GPU1(cuda:2)
DEBUG 01-07 10:13:59.331696.331696 lmp.py:767]   Expert  1 |    245 | GPU0(cuda:1)
DEBUG 01-07 10:13:59.331623.331623 lmp.py:767]   Expert 16 |    248 | GPU1(cuda:2)
DEBUG 01-07 10:13:59.331551.331551 lmp.py:767]   Expert 20 |    259 | GPU0(cuda:1)
DEBUG 01-07 10:13:59.331479.331479 lmp.py:767]   Expert  8 |    260 | GPU1(cuda:2)
DEBUG 01-07 10:13:59.331274.331274 lmp.py:767]   Expert  5 |    264 | GPU0(cuda:1)
DEBUG 01-07 10:13:59.332785.332785 lmp.py:767]   Expert 30 |    269 | GPU1(cuda:2)
DEBUG 01-07 10:13:59.332382.332382 lmp.py:767]   Expert 15 |    274 | GPU0(cuda:1)
DEBUG 01-07 10:13:59.332740.332740 lmp.py:767]   Expert 62 |    277 | GPU1(cuda:2)
DEBUG 01-07 10:13:59.332098.332098 lmp.py:767]   Expert 39 |    293 | GPU0(cuda:1)
DEBUG 01-07 10:13:59.332172.332172 lmp.py:767]   Expert 35 |    302 | GPU1(cuda:2)
DEBUG 01-07 10:13:59.332768.332768 lmp.py:767]   Expert 17 |    307 | GPU0(cuda:1)
DEBUG 01-07 10:13:59.332888.332888 lmp.py:767]   Expert 60 |    313 | GPU1(cuda:2)
DEBUG 01-07 10:13:59.332531.332531 lmp.py:767]   Expert 52 |    357 | GPU0(cuda:1)
DEBUG 01-07 10:13:59.332651.332651 lmp.py:767]   Expert 23 |    366 | GPU1(cuda:2)
DEBUG 01-07 10:13:59.332294.332294 lmp.py:767]   Expert 44 |    379 | GPU1(cuda:2)
DEBUG 01-07 10:13:59.332175.332175 lmp.py:767]   Expert 53 |    444 | GPU0(cuda:1)
DEBUG 01-07 10:13:59.332017.332017 lmp.py:769] 
DEBUG 01-07 10:13:59.332017.332017 lmp.py:769]   Device Token Distribution:
DEBUG 01-07 10:13:59.332051.332051 lmp.py:770]   CPU:   1732 tokens
DEBUG 01-07 10:13:59.332317.332317 lmp.py:774]   cuda:1:   5212 tokens (22 experts)
DEBUG 01-07 10:13:59.332390.332390 lmp.py:774]   cuda:2:   5344 tokens (23 experts)
DEBUG 01-07 10:13:59.332795.332795 lmp.py:775]   Total GPU:  10556 tokens
DEBUG 01-07 10:13:59.332199.332199 lmp.py:776] ============================================================
DEBUG 01-07 10:13:59.332199.332199 lmp.py:776] 
DEBUG 01-07 10:13:59.332518.332518 cuda_h.py:19] end experts_map_get cost 0.0018644332885742188 seconds
DEBUG 01-07 10:13:59.332353.332353 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model_multi_device
DEBUG 01-07 10:13:59.332090.332090 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 10:13:59.332922.332922 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 10:13:59.332619.332619 cuda_h.py:19] end allocate_cuda_memory cost 0.0002334117889404297 seconds
DEBUG 01-07 10:13:59.332191.332191 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 10:13:59.332822.332822 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 10:13:59.332121.332121 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 10:13:59.332917.332917 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 291e3c5a-d2c3-497b-a7d6-0a0de5f15c9a
DEBUG 01-07 10:13:59.333544.333544 client.py:106] call stub.LoadModelAsync
INFO 01-07 10:13:59.333702.333702 client.py:127] Model loaded
DEBUG 01-07 10:13:59.333383.333383 cuda_h.py:19] end sllm_worker_task cost 0.008964061737060547 seconds
INFO 01-07 10:13:59.333082.333082 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 291e3c5a-d2c3-497b-a7d6-0a0de5f15c9a
DEBUG 01-07 10:13:59.334024.334024 cuda_h.py:19] end load_into_gpu_async cost 0.0010960102081298828 seconds
DEBUG 01-07 10:13:59.334535.334535 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 10:13:59.334325.334325 cuda_h.py:19] end restore_tensors2 cost 0.00024080276489257812 seconds
DEBUG 01-07 10:13:59.334194.334194 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0019040107727050781 seconds
DEBUG 01-07 10:13:59.336680.336680 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 10:13:59.336988.336988 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 10:13:59.336753.336753 cuda_h.py:19] end allocate_cuda_memory cost 0.00024366378784179688 seconds
DEBUG 01-07 10:13:59.336550.336550 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 10:13:59.336544.336544 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 10:13:59.336730.336730 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 10:13:59.336857.336857 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 4b3db8dc-323a-4645-81c3-336f76b0d6f1
DEBUG 01-07 10:13:59.336915.336915 client.py:106] call stub.LoadModelAsync
INFO 01-07 10:13:59.337968.337968 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 4b3db8dc-323a-4645-81c3-336f76b0d6f1
DEBUG 01-07 10:13:59.337605.337605 cuda_h.py:19] end load_into_gpu_async cost 0.0012371540069580078 seconds
DEBUG 01-07 10:13:59.337162.337162 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 10:13:59.338972.338972 cuda_h.py:19] end restore_tensors2 cost 0.00021886825561523438 seconds
DEBUG 01-07 10:13:59.338364.338364 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.002000093460083008 seconds
DEBUG 01-07 10:13:59.340949.340949 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model_multi_device cost 0.0076808929443359375 seconds
DEBUG 01-07 10:13:59.340772.340772 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-07 10:13:59.340165.340165 lmp.py:816] 
DEBUG 01-07 10:13:59.340165.340165 lmp.py:816]   Computing 19 experts on CPU...
DEBUG 01-07 10:13:59.340193.340193 cuda_h.py:19] end cpu_experts_submit cost 0.00010752677917480469 seconds
DEBUG 01-07 10:13:59.340035.340035 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-07 10:13:59.350772.350772 mlpmodule.py:749] group tensors cost 0.009601831436157227 s
DEBUG 01-07 10:13:59.351574.351574 mlpmodule.py:787] pad cost 0.0009634494781494141 s
DEBUG 01-07 10:13:59.351273.351273 mlpmodule.py:793] create cpu tensor cost 3.8623809814453125e-05 s
DEBUG 01-07 10:13:59.351315.351315 mlpmodule.py:798] move to cpu cost 3.0994415283203125e-05 s
DEBUG 01-07 10:13:59.362649.362649 mlpmodule.py:812] group_w3: shape=torch.Size([19, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=54788096
DEBUG 01-07 10:13:59.362317.362317 mlpmodule.py:813] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-07 10:13:59.362791.362791 mlpmodule.py:818] group_w3 first element: -0.02490234375
WARNING 01-07 10:13:59.362583.362583 mlpmodule.py:828] start einsum2
DEBUG 01-07 10:13:59.383454.383454 mlpmodule.py:838] group einsum cost 0.0317690372467041 s
DEBUG 01-07 10:13:59.384353.384353 mlpmodule.py:846] cpy2cputensor cost 0.0003647804260253906 s
DEBUG 01-07 10:13:59.386526.386526 cuda_h.py:19] end wait_cetm_experts cost 0.04645419120788574 seconds
DEBUG 01-07 10:13:59.386787.386787 cuda_h.py:10] start gpu_sexperts
DEBUG 01-07 10:13:59.387933.387933 cuda_h.py:19] end gpu_sexperts cost 0.0005524158477783203 seconds
DEBUG 01-07 10:13:59.387498.387498 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-07 10:13:59.387633.387633 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.5033950805664062e-05 seconds
DEBUG 01-07 10:13:59.387812.387812 cuda_h.py:10] start wait_experts_multi_device
INFO 01-07 10:13:59.387814.387814 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 291e3c5a-d2c3-497b-a7d6-0a0de5f15c9a
INFO 01-07 10:13:59.388210.388210 client.py:127] Model loaded
INFO 01-07 10:13:59.388861.388861 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 4b3db8dc-323a-4645-81c3-336f76b0d6f1
INFO 01-07 10:13:59.389584.389584 client.py:127] Model loaded
DEBUG 01-07 10:13:59.389705.389705 cuda_h.py:19] end wait_experts_multi_device cost 0.0015020370483398438 seconds
DEBUG 01-07 10:13:59.389030.389030 cuda_h.py:10] start gpu_experts_multi_device
DEBUG 01-07 10:13:59.389284.389284 lmp.py:867]   Computing 23 experts on cuda:2...
DEBUG 01-07 10:13:59.390701.390701 mlpmodule.py:533] gpu group tensors cost 0.0004649162292480469 s
DEBUG 01-07 10:13:59.391448.391448 mlpmodule.py:566] gpu pad cost 0.001295328140258789 s
DEBUG 01-07 10:13:59.392550.392550 mlpmodule.py:584] gpu group einsum cost 0.0005972385406494141 s
DEBUG 01-07 10:13:59.394632.394632 mlpmodule.py:656] gpu experts func einsum cost 0.004558563232421875 s
DEBUG 01-07 10:13:59.394470.394470 lmp.py:867]   Computing 22 experts on cuda:1...
DEBUG 01-07 10:13:59.395304.395304 mlpmodule.py:533] gpu group tensors cost 0.0004558563232421875 s
DEBUG 01-07 10:13:59.395264.395264 mlpmodule.py:707]  experts func einsum cost 0.05556631088256836 s
DEBUG 01-07 10:13:59.396054.396054 mlpmodule.py:566] gpu pad cost 0.0013685226440429688 s
DEBUG 01-07 10:13:59.397794.397794 mlpmodule.py:584] gpu group einsum cost 0.0004646778106689453 s
DEBUG 01-07 10:13:59.399958.399958 mlpmodule.py:656] gpu experts func einsum cost 0.004380226135253906 s
DEBUG 01-07 10:13:59.399226.399226 cuda_h.py:19] end gpu_experts_multi_device cost 0.010368108749389648 seconds
DEBUG 01-07 10:13:59.399620.399620 cuda_h.py:19] end layer_moe_generate_multi_device_16 cost 0.06995511054992676 seconds
DEBUG 01-07 10:13:59.399428.399428 lmp.py:194] -------------------------------- end prefill layer 16 --------------------------------
DEBUG 01-07 10:13:59.399866.399866 lmp.py:153] -------------------------------- start prefill layer 17 --------------------------------
DEBUG 01-07 10:13:59.399801.399801 cuda_h.py:10] start start_load_qkvogn_s_weight_l_18
DEBUG 01-07 10:13:59.400539.400539 cuda_h.py:10] start start_load_qkvogn_s_weight_l_18
DEBUG 01-07 10:13:59.400945.400945 cuda_h.py:19] end start_load_qkvogn_s_weight_l_18 cost 2.6464462280273438e-05 seconds
DEBUG 01-07 10:13:59.400217.400217 cuda_h.py:19] end start_load_qkvogn_s_weight_l_18 cost 5.602836608886719e-05 seconds
DEBUG 01-07 10:13:59.400244.400244 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-07 10:13:59.400213.400213 cuda_h.py:10] start sllm_worker_task
DEBUG 01-07 10:13:59.400626.400626 mlpmodule.py:367] cuda:1 cuda:1
DEBUG 01-07 10:13:59.400820.400820 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 10:13:59.400513.400513 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 10:13:59.400835.400835 cuda_h.py:19] end allocate_cuda_memory cost 0.00030422210693359375 seconds
DEBUG 01-07 10:13:59.400639.400639 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 10:13:59.400110.400110 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 10:13:59.400741.400741 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 10:13:59.400252.400252 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 15c9a82e-cf95-4aa4-81d9-87de7eb9ff43
DEBUG 01-07 10:13:59.400685.400685 client.py:106] call stub.LoadModelAsync
DEBUG 01-07 10:13:59.401649.401649 cuda_h.py:10] start self_attn
INFO 01-07 10:13:59.401798.401798 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 15c9a82e-cf95-4aa4-81d9-87de7eb9ff43
DEBUG 01-07 10:13:59.401535.401535 cuda_h.py:19] end load_into_gpu_async cost 0.0008041858673095703 seconds
DEBUG 01-07 10:13:59.401092.401092 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 10:13:59.401214.401214 cuda_h.py:19] end restore_tensors2 cost 6.461143493652344e-05 seconds
DEBUG 01-07 10:13:59.401016.401016 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0014107227325439453 seconds
INFO 01-07 10:13:59.401350.401350 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 15c9a82e-cf95-4aa4-81d9-87de7eb9ff43
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-07 10:13:59.405033.405033 cuda_h.py:19] end self_attn cost 0.003695964813232422 seconds
DEBUG 01-07 10:13:59.405401.405401 cuda_h.py:19] end iln_self_attn_paln cost 0.0052487850189208984 seconds
DEBUG 01-07 10:13:59.405390.405390 cuda_h.py:10] start layer_moe_generate_multi_device_17
DEBUG 01-07 10:13:59.405345.405345 cuda_h.py:10] start gate
DEBUG 01-07 10:13:59.406077.406077 cuda_h.py:19] end gate cost 0.0006725788116455078 seconds
DEBUG 01-07 10:13:59.406476.406476 cuda_h.py:10] start experts_map_get
DEBUG 01-07 10:13:59.406139.406139 lmp.py:744] 
DEBUG 01-07 10:13:59.406139.406139 lmp.py:744] Expert Token Distribution & Multi-Device Allocation:
DEBUG 01-07 10:13:59.406300.406300 lmp.py:745]   Total experts: 64
DEBUG 01-07 10:13:59.406288.406288 lmp.py:746]   CPU experts: 19 (30%)
DEBUG 01-07 10:13:59.406792.406792 lmp.py:747]   GPU experts: 45 (70%)
DEBUG 01-07 10:13:59.406150.406150 lmp.py:748]   Number of GPU devices: 2
DEBUG 01-07 10:13:59.406554.406554 lmp.py:749] 
DEBUG 01-07 10:13:59.406554.406554 lmp.py:749]   Expert ID | Tokens | Device
DEBUG 01-07 10:13:59.406959.406959 lmp.py:750]   -----------------------------------
DEBUG 01-07 10:13:59.406562.406562 lmp.py:767]   Expert  4 |      9 | CPU
DEBUG 01-07 10:13:59.406444.406444 lmp.py:767]   Expert 28 |     30 | CPU
DEBUG 01-07 10:13:59.406371.406371 lmp.py:767]   Expert  7 |     44 | CPU
DEBUG 01-07 10:13:59.406061.406061 lmp.py:767]   Expert 53 |     58 | CPU
DEBUG 01-07 10:13:59.406988.406988 lmp.py:767]   Expert 52 |     65 | CPU
DEBUG 01-07 10:13:59.406599.406599 lmp.py:767]   Expert 43 |     69 | CPU
DEBUG 01-07 10:13:59.406679.406679 lmp.py:767]   Expert 49 |     79 | CPU
DEBUG 01-07 10:13:59.406084.406084 lmp.py:767]   Expert 12 |     87 | CPU
DEBUG 01-07 10:13:59.406488.406488 lmp.py:767]   Expert 47 |    101 | CPU
DEBUG 01-07 10:13:59.407654.407654 lmp.py:767]   Expert 24 |    103 | CPU
DEBUG 01-07 10:13:59.407582.407582 lmp.py:767]   Expert 33 |    109 | CPU
DEBUG 01-07 10:13:59.407510.407510 lmp.py:767]   Expert  2 |    111 | CPU
DEBUG 01-07 10:13:59.407484.407484 lmp.py:767]   Expert 50 |    112 | CPU
DEBUG 01-07 10:13:59.407696.407696 lmp.py:767]   Expert 15 |    113 | CPU
DEBUG 01-07 10:13:59.407909.407909 lmp.py:767]   Expert 60 |    113 | CPU
DEBUG 01-07 10:13:59.407121.407121 lmp.py:767]   Expert 39 |    115 | CPU
DEBUG 01-07 10:13:59.407109.407109 lmp.py:767]   Expert 25 |    121 | CPU
DEBUG 01-07 10:13:59.407752.407752 lmp.py:767]   Expert 36 |    121 | CPU
DEBUG 01-07 10:13:59.407156.407156 lmp.py:767]   Expert  6 |    124 | CPU
DEBUG 01-07 10:13:59.407753.407753 lmp.py:767]   Expert 61 |    133 | GPU0(cuda:1)
DEBUG 01-07 10:13:59.407350.407350 lmp.py:767]   Expert 59 |    135 | GPU1(cuda:2)
DEBUG 01-07 10:13:59.407946.407946 lmp.py:767]   Expert  3 |    143 | GPU0(cuda:1)
DEBUG 01-07 10:13:59.407589.407589 lmp.py:767]   Expert 58 |    144 | GPU1(cuda:2)
DEBUG 01-07 10:13:59.407994.407994 lmp.py:767]   Expert 27 |    146 | GPU0(cuda:1)
DEBUG 01-07 10:13:59.407398.407398 lmp.py:767]   Expert 30 |    148 | GPU1(cuda:2)
DEBUG 01-07 10:13:59.407564.407564 lmp.py:767]   Expert  8 |    150 | GPU1(cuda:2)
DEBUG 01-07 10:13:59.407122.407122 lmp.py:767]   Expert 31 |    150 | GPU0(cuda:1)
DEBUG 01-07 10:13:59.407155.407155 lmp.py:767]   Expert 38 |    155 | GPU0(cuda:1)
DEBUG 01-07 10:13:59.407229.407229 lmp.py:767]   Expert 14 |    157 | GPU1(cuda:2)
DEBUG 01-07 10:13:59.407349.407349 lmp.py:767]   Expert 40 |    158 | GPU0(cuda:1)
DEBUG 01-07 10:13:59.407230.407230 lmp.py:767]   Expert 57 |    159 | GPU1(cuda:2)
DEBUG 01-07 10:13:59.407112.407112 lmp.py:767]   Expert 10 |    161 | GPU0(cuda:1)
DEBUG 01-07 10:13:59.407755.407755 lmp.py:767]   Expert 37 |    163 | GPU0(cuda:1)
DEBUG 01-07 10:13:59.407159.407159 lmp.py:767]   Expert 41 |    163 | GPU1(cuda:2)
DEBUG 01-07 10:13:59.407325.407325 lmp.py:767]   Expert 32 |    164 | GPU1(cuda:2)
DEBUG 01-07 10:13:59.407730.407730 lmp.py:767]   Expert 46 |    168 | GPU1(cuda:2)
DEBUG 01-07 10:13:59.407658.407658 lmp.py:767]   Expert 54 |    168 | GPU0(cuda:1)
DEBUG 01-07 10:13:59.407023.407023 lmp.py:767]   Expert 19 |    175 | GPU0(cuda:1)
DEBUG 01-07 10:13:59.407341.407341 lmp.py:767]   Expert 11 |    176 | GPU0(cuda:1)
DEBUG 01-07 10:13:59.407699.407699 lmp.py:767]   Expert 42 |    176 | GPU1(cuda:2)
DEBUG 01-07 10:13:59.407581.407581 lmp.py:767]   Expert 34 |    190 | GPU1(cuda:2)
DEBUG 01-07 10:13:59.407985.407985 lmp.py:767]   Expert 18 |    192 | GPU0(cuda:1)
DEBUG 01-07 10:13:59.407105.407105 lmp.py:767]   Expert 26 |    193 | GPU1(cuda:2)
DEBUG 01-07 10:13:59.407987.407987 lmp.py:767]   Expert 22 |    197 | GPU0(cuda:1)
DEBUG 01-07 10:13:59.407630.407630 lmp.py:767]   Expert  0 |    199 | GPU1(cuda:2)
DEBUG 01-07 10:13:59.407557.407557 lmp.py:767]   Expert 56 |    200 | GPU0(cuda:1)
DEBUG 01-07 10:13:59.407723.407723 lmp.py:767]   Expert 44 |    203 | GPU1(cuda:2)
DEBUG 01-07 10:13:59.407651.407651 lmp.py:767]   Expert  1 |    204 | GPU0(cuda:1)
DEBUG 01-07 10:13:59.407340.407340 lmp.py:767]   Expert 51 |    212 | GPU1(cuda:2)
DEBUG 01-07 10:13:59.407659.407659 lmp.py:767]   Expert 20 |    226 | GPU0(cuda:1)
DEBUG 01-07 10:13:59.407494.407494 lmp.py:767]   Expert 29 |    230 | GPU1(cuda:2)
DEBUG 01-07 10:13:59.407528.407528 lmp.py:767]   Expert 48 |    238 | GPU0(cuda:1)
DEBUG 01-07 10:13:59.407125.407125 lmp.py:767]   Expert 45 |    244 | GPU1(cuda:2)
DEBUG 01-07 10:13:59.407960.407960 lmp.py:767]   Expert 16 |    250 | GPU0(cuda:1)
DEBUG 01-07 10:13:59.407318.407318 lmp.py:767]   Expert 21 |    250 | GPU1(cuda:2)
DEBUG 01-07 10:13:59.407676.407676 lmp.py:767]   Expert 35 |    250 | GPU0(cuda:1)
DEBUG 01-07 10:13:59.407273.407273 lmp.py:767]   Expert 55 |    255 | GPU1(cuda:2)
DEBUG 01-07 10:13:59.407631.407631 lmp.py:767]   Expert  5 |    294 | GPU0(cuda:1)
DEBUG 01-07 10:13:59.407513.407513 lmp.py:767]   Expert 23 |    370 | GPU1(cuda:2)
DEBUG 01-07 10:13:59.407394.407394 lmp.py:767]   Expert 13 |    382 | GPU0(cuda:1)
DEBUG 01-07 10:13:59.407275.407275 lmp.py:767]   Expert 17 |    437 | GPU1(cuda:2)
DEBUG 01-07 10:13:59.407157.407157 lmp.py:767]   Expert 63 |    459 | GPU1(cuda:2)
DEBUG 01-07 10:13:59.407038.407038 lmp.py:767]   Expert  9 |    461 | GPU1(cuda:2)
DEBUG 01-07 10:13:59.408158.408158 lmp.py:767]   Expert 62 |   1176 | GPU0(cuda:1)
DEBUG 01-07 10:13:59.408954.408954 lmp.py:769] 
DEBUG 01-07 10:13:59.408954.408954 lmp.py:769]   Device Token Distribution:
DEBUG 01-07 10:13:59.408073.408073 lmp.py:770]   CPU:   1684 tokens
DEBUG 01-07 10:13:59.408061.408061 lmp.py:774]   cuda:1:   5337 tokens (22 experts)
DEBUG 01-07 10:13:59.408134.408134 lmp.py:774]   cuda:2:   5267 tokens (23 experts)
DEBUG 01-07 10:13:59.408553.408553 lmp.py:775]   Total GPU:  10604 tokens
DEBUG 01-07 10:13:59.408196.408196 lmp.py:776] ============================================================
DEBUG 01-07 10:13:59.408196.408196 lmp.py:776] 
DEBUG 01-07 10:13:59.408514.408514 cuda_h.py:19] end experts_map_get cost 0.0018928050994873047 seconds
DEBUG 01-07 10:13:59.408111.408111 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model_multi_device
DEBUG 01-07 10:13:59.408980.408980 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 10:13:59.408858.408858 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 10:13:59.408755.408755 cuda_h.py:19] end allocate_cuda_memory cost 0.000240325927734375 seconds
INFO 01-07 10:13:59.408148.408148 client.py:127] Model loaded
DEBUG 01-07 10:13:59.408873.408873 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 10:13:59.408879.408879 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 10:13:59.409609.409609 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 10:13:59.409418.409418 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, a84dbfa6-2987-42b1-ae10-04fd54aee8a1
DEBUG 01-07 10:13:59.409707.409707 client.py:106] call stub.LoadModelAsync
DEBUG 01-07 10:13:59.409427.409427 cuda_h.py:19] end sllm_worker_task cost 0.009228944778442383 seconds
INFO 01-07 10:13:59.409160.409160 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, a84dbfa6-2987-42b1-ae10-04fd54aee8a1
DEBUG 01-07 10:13:59.409764.409764 cuda_h.py:19] end load_into_gpu_async cost 0.0009331703186035156 seconds
DEBUG 01-07 10:13:59.409467.409467 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 10:13:59.410297.410297 cuda_h.py:19] end restore_tensors2 cost 0.00023484230041503906 seconds
DEBUG 01-07 10:13:59.410928.410928 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.00197601318359375 seconds
DEBUG 01-07 10:13:59.412843.412843 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 10:13:59.412059.412059 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 10:13:59.412162.412162 cuda_h.py:19] end allocate_cuda_memory cost 0.00024700164794921875 seconds
DEBUG 01-07 10:13:59.412766.412766 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 10:13:59.412682.412682 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 10:13:59.412537.412537 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 10:13:59.412233.412233 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 99d91472-dd9a-47e7-9bcb-dba3a89d1207
DEBUG 01-07 10:13:59.412178.412178 client.py:106] call stub.LoadModelAsync
INFO 01-07 10:13:59.413810.413810 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 99d91472-dd9a-47e7-9bcb-dba3a89d1207
DEBUG 01-07 10:13:59.413732.413732 cuda_h.py:19] end load_into_gpu_async cost 0.0009272098541259766 seconds
DEBUG 01-07 10:13:59.413289.413289 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 10:13:59.413576.413576 cuda_h.py:19] end restore_tensors2 cost 0.0002205371856689453 seconds
DEBUG 01-07 10:13:59.413968.413968 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0016913414001464844 seconds
DEBUG 01-07 10:13:59.415533.415533 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model_multi_device cost 0.0074481964111328125 seconds
DEBUG 01-07 10:13:59.415833.415833 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-07 10:13:59.415511.415511 lmp.py:816] 
DEBUG 01-07 10:13:59.415511.415511 lmp.py:816]   Computing 19 experts on CPU...
DEBUG 01-07 10:13:59.415824.415824 cuda_h.py:19] end cpu_experts_submit cost 0.00010657310485839844 seconds
DEBUG 01-07 10:13:59.415951.415951 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-07 10:13:59.427208.427208 mlpmodule.py:749] group tensors cost 0.011716842651367188 s
DEBUG 01-07 10:13:59.429368.429368 mlpmodule.py:787] pad cost 0.0009551048278808594 s
DEBUG 01-07 10:13:59.429497.429497 mlpmodule.py:793] create cpu tensor cost 3.981590270996094e-05 s
DEBUG 01-07 10:13:59.429777.429777 mlpmodule.py:798] move to cpu cost 3.0994415283203125e-05 s
DEBUG 01-07 10:13:59.439314.439314 mlpmodule.py:812] group_w3: shape=torch.Size([19, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=54788096
DEBUG 01-07 10:13:59.440982.440982 mlpmodule.py:813] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-07 10:13:59.440218.440218 mlpmodule.py:818] group_w3 first element: 0.00457763671875
WARNING 01-07 10:13:59.440699.440699 mlpmodule.py:828] start einsum2
DEBUG 01-07 10:13:59.459818.459818 mlpmodule.py:838] group einsum cost 0.030010223388671875 s
DEBUG 01-07 10:13:59.460724.460724 mlpmodule.py:846] cpy2cputensor cost 0.0003638267517089844 s
DEBUG 01-07 10:13:59.462480.462480 cuda_h.py:19] end wait_cetm_experts cost 0.04701089859008789 seconds
DEBUG 01-07 10:13:59.463165.463165 cuda_h.py:10] start gpu_sexperts
DEBUG 01-07 10:13:59.463973.463973 cuda_h.py:19] end gpu_sexperts cost 0.0005502700805664062 seconds
DEBUG 01-07 10:13:59.463915.463915 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-07 10:13:59.463096.463096 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.4557113647460938e-05 seconds
DEBUG 01-07 10:13:59.463707.463707 cuda_h.py:10] start wait_experts_multi_device
INFO 01-07 10:13:59.463185.463185 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, a84dbfa6-2987-42b1-ae10-04fd54aee8a1
INFO 01-07 10:13:59.464983.464983 client.py:127] Model loaded
INFO 01-07 10:13:59.464197.464197 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 99d91472-dd9a-47e7-9bcb-dba3a89d1207
INFO 01-07 10:13:59.465131.465131 client.py:127] Model loaded
DEBUG 01-07 10:13:59.465583.465583 cuda_h.py:19] end wait_experts_multi_device cost 0.0014202594757080078 seconds
DEBUG 01-07 10:13:59.465432.465432 cuda_h.py:10] start gpu_experts_multi_device
DEBUG 01-07 10:13:59.465970.465970 lmp.py:867]   Computing 23 experts on cuda:2...
DEBUG 01-07 10:13:59.466857.466857 mlpmodule.py:533] gpu group tensors cost 0.0004706382751464844 s
DEBUG 01-07 10:13:59.467776.467776 mlpmodule.py:566] gpu pad cost 0.0012843608856201172 s
DEBUG 01-07 10:13:59.468350.468350 mlpmodule.py:584] gpu group einsum cost 0.0006711483001708984 s
DEBUG 01-07 10:13:59.470651.470651 mlpmodule.py:656] gpu experts func einsum cost 0.0046024322509765625 s
DEBUG 01-07 10:13:59.470362.470362 lmp.py:867]   Computing 22 experts on cuda:1...
DEBUG 01-07 10:13:59.471103.471103 mlpmodule.py:533] gpu group tensors cost 0.0004494190216064453 s
DEBUG 01-07 10:13:59.472499.472499 mlpmodule.py:707]  experts func einsum cost 0.05623054504394531 s
DEBUG 01-07 10:13:59.473986.473986 mlpmodule.py:566] gpu pad cost 0.0017802715301513672 s
DEBUG 01-07 10:13:59.474481.474481 mlpmodule.py:584] gpu group einsum cost 0.0008785724639892578 s
DEBUG 01-07 10:13:59.476628.476628 mlpmodule.py:656] gpu experts func einsum cost 0.005051851272583008 s
DEBUG 01-07 10:13:59.476074.476074 cuda_h.py:19] end gpu_experts_multi_device cost 0.011049509048461914 seconds
DEBUG 01-07 10:13:59.476143.476143 cuda_h.py:19] end layer_moe_generate_multi_device_17 cost 0.0709228515625 seconds
DEBUG 01-07 10:13:59.476536.476536 lmp.py:194] -------------------------------- end prefill layer 17 --------------------------------
DEBUG 01-07 10:13:59.476226.476226 lmp.py:153] -------------------------------- start prefill layer 18 --------------------------------
DEBUG 01-07 10:13:59.476161.476161 cuda_h.py:10] start start_load_qkvogn_s_weight_l_19
DEBUG 01-07 10:13:59.476632.476632 cuda_h.py:10] start start_load_qkvogn_s_weight_l_19
DEBUG 01-07 10:13:59.476422.476422 cuda_h.py:19] end start_load_qkvogn_s_weight_l_19 cost 2.8371810913085938e-05 seconds
DEBUG 01-07 10:13:59.476741.476741 cuda_h.py:19] end start_load_qkvogn_s_weight_l_19 cost 5.817413330078125e-05 seconds
DEBUG 01-07 10:13:59.476861.476861 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-07 10:13:59.476770.476770 mlpmodule.py:367] cuda:1 cuda:1
DEBUG 01-07 10:13:59.477574.477574 cuda_h.py:10] start sllm_worker_task
DEBUG 01-07 10:13:59.477238.477238 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 10:13:59.477591.477591 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 10:13:59.477684.477684 cuda_h.py:19] end allocate_cuda_memory cost 0.0001766681671142578 seconds
DEBUG 01-07 10:13:59.477719.477719 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 10:13:59.477237.477237 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 10:13:59.477914.477914 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 10:13:59.477994.477994 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, aef19c93-c63e-40bc-9dc0-3a329ba44826
DEBUG 01-07 10:13:59.477665.477665 client.py:106] call stub.LoadModelAsync
DEBUG 01-07 10:13:59.477398.477398 cuda_h.py:10] start self_attn
INFO 01-07 10:13:59.478391.478391 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, aef19c93-c63e-40bc-9dc0-3a329ba44826
DEBUG 01-07 10:13:59.478505.478505 cuda_h.py:19] end load_into_gpu_async cost 0.0008990764617919922 seconds
DEBUG 01-07 10:13:59.478301.478301 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 10:13:59.478662.478662 cuda_h.py:19] end restore_tensors2 cost 6.4849853515625e-05 seconds
DEBUG 01-07 10:13:59.478033.478033 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0013628005981445312 seconds
INFO 01-07 10:13:59.478446.478446 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, aef19c93-c63e-40bc-9dc0-3a329ba44826
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-07 10:13:59.481919.481919 cuda_h.py:19] end self_attn cost 0.0036220550537109375 seconds
DEBUG 01-07 10:13:59.481671.481671 cuda_h.py:19] end iln_self_attn_paln cost 0.00499415397644043 seconds
DEBUG 01-07 10:13:59.481732.481732 cuda_h.py:10] start layer_moe_generate_multi_device_18
DEBUG 01-07 10:13:59.481680.481680 cuda_h.py:10] start gate
DEBUG 01-07 10:13:59.482857.482857 cuda_h.py:19] end gate cost 0.0006947517395019531 seconds
DEBUG 01-07 10:13:59.482779.482779 cuda_h.py:10] start experts_map_get
DEBUG 01-07 10:13:59.483574.483574 lmp.py:744] 
DEBUG 01-07 10:13:59.483574.483574 lmp.py:744] Expert Token Distribution & Multi-Device Allocation:
DEBUG 01-07 10:13:59.483351.483351 lmp.py:745]   Total experts: 64
DEBUG 01-07 10:13:59.483338.483338 lmp.py:746]   CPU experts: 19 (30%)
DEBUG 01-07 10:13:59.483127.483127 lmp.py:747]   GPU experts: 45 (70%)
DEBUG 01-07 10:13:59.483724.483724 lmp.py:748]   Number of GPU devices: 2
DEBUG 01-07 10:13:59.483890.483890 lmp.py:749] 
DEBUG 01-07 10:13:59.483890.483890 lmp.py:749]   Expert ID | Tokens | Device
DEBUG 01-07 10:13:59.483579.483579 lmp.py:750]   -----------------------------------
DEBUG 01-07 10:13:59.483183.483183 lmp.py:767]   Expert 32 |     36 | CPU
DEBUG 01-07 10:13:59.483587.483587 lmp.py:767]   Expert 30 |     55 | CPU
DEBUG 01-07 10:13:59.483515.483515 lmp.py:767]   Expert  5 |     57 | CPU
DEBUG 01-07 10:13:59.483966.483966 lmp.py:767]   Expert 46 |     74 | CPU
DEBUG 01-07 10:13:59.483940.483940 lmp.py:767]   Expert 40 |     93 | CPU
DEBUG 01-07 10:13:59.483080.483080 lmp.py:767]   Expert  8 |     94 | CPU
DEBUG 01-07 10:13:59.483961.483961 lmp.py:767]   Expert 12 |    102 | CPU
DEBUG 01-07 10:13:59.483366.483366 lmp.py:767]   Expert 17 |    103 | CPU
DEBUG 01-07 10:13:59.483532.483532 lmp.py:767]   Expert 27 |    109 | CPU
DEBUG 01-07 10:13:59.483460.483460 lmp.py:767]   Expert  3 |    115 | CPU
DEBUG 01-07 10:13:59.483626.483626 lmp.py:767]   Expert 60 |    116 | CPU
DEBUG 01-07 10:13:59.483077.483077 lmp.py:767]   Expert 58 |    117 | CPU
DEBUG 01-07 10:13:59.483289.483289 lmp.py:767]   Expert 21 |    119 | CPU
DEBUG 01-07 10:13:59.483502.483502 lmp.py:767]   Expert 29 |    119 | CPU
DEBUG 01-07 10:13:59.483714.483714 lmp.py:767]   Expert 28 |    124 | CPU
DEBUG 01-07 10:13:59.483688.483688 lmp.py:767]   Expert 25 |    126 | CPU
DEBUG 01-07 10:13:59.483139.483139 lmp.py:767]   Expert 35 |    132 | CPU
DEBUG 01-07 10:13:59.483411.483411 lmp.py:767]   Expert 19 |    134 | CPU
DEBUG 01-07 10:13:59.483538.483538 lmp.py:767]   Expert 41 |    135 | CPU
DEBUG 01-07 10:13:59.483612.483612 lmp.py:767]   Expert  0 |    142 | GPU0(cuda:1)
DEBUG 01-07 10:13:59.483162.483162 lmp.py:767]   Expert  6 |    143 | GPU1(cuda:2)
DEBUG 01-07 10:13:59.483759.483759 lmp.py:767]   Expert 52 |    146 | GPU1(cuda:2)
DEBUG 01-07 10:13:59.483402.483402 lmp.py:767]   Expert 56 |    148 | GPU0(cuda:1)
DEBUG 01-07 10:13:59.483283.483283 lmp.py:767]   Expert 54 |    150 | GPU0(cuda:1)
DEBUG 01-07 10:13:59.483687.483687 lmp.py:767]   Expert 37 |    153 | GPU1(cuda:2)
DEBUG 01-07 10:13:59.483854.483854 lmp.py:767]   Expert 48 |    157 | GPU1(cuda:2)
DEBUG 01-07 10:13:59.483304.483304 lmp.py:767]   Expert 63 |    157 | GPU0(cuda:1)
DEBUG 01-07 10:13:59.483232.483232 lmp.py:767]   Expert 53 |    159 | GPU0(cuda:1)
DEBUG 01-07 10:13:59.483551.483551 lmp.py:767]   Expert 36 |    167 | GPU1(cuda:2)
DEBUG 01-07 10:13:59.483154.483154 lmp.py:767]   Expert 59 |    168 | GPU1(cuda:2)
DEBUG 01-07 10:13:59.483274.483274 lmp.py:767]   Expert  9 |    182 | GPU0(cuda:1)
DEBUG 01-07 10:13:59.483156.483156 lmp.py:767]   Expert  1 |    186 | GPU0(cuda:1)
DEBUG 01-07 10:13:59.483275.483275 lmp.py:767]   Expert 39 |    186 | GPU1(cuda:2)
DEBUG 01-07 10:13:59.483680.483680 lmp.py:767]   Expert 20 |    195 | GPU1(cuda:2)
DEBUG 01-07 10:13:59.483277.483277 lmp.py:767]   Expert 11 |    202 | GPU1(cuda:2)
DEBUG 01-07 10:13:59.483443.483443 lmp.py:767]   Expert 61 |    202 | GPU0(cuda:1)
DEBUG 01-07 10:13:59.483609.483609 lmp.py:767]   Expert  7 |    204 | GPU1(cuda:2)
DEBUG 01-07 10:13:59.483537.483537 lmp.py:767]   Expert 42 |    204 | GPU0(cuda:1)
DEBUG 01-07 10:13:59.484464.484464 lmp.py:767]   Expert 43 |    205 | GPU0(cuda:1)
DEBUG 01-07 10:13:59.484498.484498 lmp.py:767]   Expert 34 |    206 | GPU1(cuda:2)
DEBUG 01-07 10:13:59.484141.484141 lmp.py:767]   Expert 47 |    209 | GPU0(cuda:1)
DEBUG 01-07 10:13:59.484506.484506 lmp.py:767]   Expert 55 |    215 | GPU1(cuda:2)
DEBUG 01-07 10:13:59.484388.484388 lmp.py:767]   Expert 13 |    219 | GPU0(cuda:1)
DEBUG 01-07 10:13:59.484031.484031 lmp.py:767]   Expert 16 |    221 | GPU1(cuda:2)
DEBUG 01-07 10:13:59.484912.484912 lmp.py:767]   Expert 57 |    224 | GPU0(cuda:1)
DEBUG 01-07 10:13:59.484793.484793 lmp.py:767]   Expert 18 |    230 | GPU1(cuda:2)
DEBUG 01-07 10:13:59.484913.484913 lmp.py:767]   Expert 15 |    234 | GPU0(cuda:1)
DEBUG 01-07 10:13:59.484079.484079 lmp.py:767]   Expert  4 |    241 | GPU1(cuda:2)
DEBUG 01-07 10:13:59.484245.484245 lmp.py:767]   Expert 45 |    243 | GPU0(cuda:1)
DEBUG 01-07 10:13:59.484173.484173 lmp.py:767]   Expert 22 |    245 | GPU0(cuda:1)
DEBUG 01-07 10:13:59.484101.484101 lmp.py:767]   Expert 33 |    245 | GPU1(cuda:2)
DEBUG 01-07 10:13:59.484850.484850 lmp.py:767]   Expert 31 |    247 | GPU0(cuda:1)
DEBUG 01-07 10:13:59.484400.484400 lmp.py:767]   Expert 50 |    247 | GPU1(cuda:2)
DEBUG 01-07 10:13:59.484282.484282 lmp.py:767]   Expert 51 |    255 | GPU1(cuda:2)
DEBUG 01-07 10:13:59.484925.484925 lmp.py:767]   Expert 49 |    264 | GPU0(cuda:1)
DEBUG 01-07 10:13:59.484528.484528 lmp.py:767]   Expert 38 |    276 | GPU1(cuda:2)
DEBUG 01-07 10:13:59.484125.484125 lmp.py:767]   Expert 26 |    277 | GPU0(cuda:1)
DEBUG 01-07 10:13:59.484920.484920 lmp.py:767]   Expert 10 |    290 | GPU1(cuda:2)
DEBUG 01-07 10:13:59.484709.484709 lmp.py:767]   Expert 44 |    291 | GPU0(cuda:1)
DEBUG 01-07 10:13:59.484067.484067 lmp.py:767]   Expert  2 |    299 | GPU1(cuda:2)
DEBUG 01-07 10:13:59.484101.484101 lmp.py:767]   Expert 24 |    304 | GPU0(cuda:1)
DEBUG 01-07 10:13:59.484983.484983 lmp.py:767]   Expert 14 |    313 | GPU1(cuda:2)
DEBUG 01-07 10:13:59.484103.484103 lmp.py:767]   Expert 23 |    405 | GPU1(cuda:2)
DEBUG 01-07 10:13:59.484746.484746 lmp.py:767]   Expert 62 |    672 | GPU0(cuda:1)
DEBUG 01-07 10:13:59.484673.484673 lmp.py:769] 
DEBUG 01-07 10:13:59.484673.484673 lmp.py:769]   Device Token Distribution:
DEBUG 01-07 10:13:59.484422.484422 lmp.py:770]   CPU:   1960 tokens
DEBUG 01-07 10:13:59.484887.484887 lmp.py:774]   cuda:1:   5164 tokens (22 experts)
DEBUG 01-07 10:13:59.484722.484722 lmp.py:774]   cuda:2:   5164 tokens (23 experts)
DEBUG 01-07 10:13:59.484603.484603 lmp.py:775]   Total GPU:  10328 tokens
DEBUG 01-07 10:13:59.484770.484770 lmp.py:776] ============================================================
DEBUG 01-07 10:13:59.484770.484770 lmp.py:776] 
DEBUG 01-07 10:13:59.484565.484565 cuda_h.py:19] end experts_map_get cost 0.0018835067749023438 seconds
DEBUG 01-07 10:13:59.484923.484923 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model_multi_device
DEBUG 01-07 10:13:59.484223.484223 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 10:13:59.484048.484048 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 10:13:59.485322.485322 cuda_h.py:19] end allocate_cuda_memory cost 0.00023627281188964844 seconds
DEBUG 01-07 10:13:59.485417.485417 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 10:13:59.485411.485411 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 10:13:59.485267.485267 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 10:13:59.485725.485725 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 908de111-7125-42e2-8aa1-74136504750a
DEBUG 01-07 10:13:59.485981.485981 client.py:106] call stub.LoadModelAsync
INFO 01-07 10:13:59.485739.485739 client.py:127] Model loaded
DEBUG 01-07 10:13:59.485674.485674 cuda_h.py:19] end sllm_worker_task cost 0.008855104446411133 seconds
INFO 01-07 10:13:59.486807.486807 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 908de111-7125-42e2-8aa1-74136504750a
DEBUG 01-07 10:13:59.486432.486432 cuda_h.py:19] end load_into_gpu_async cost 0.0009951591491699219 seconds
DEBUG 01-07 10:13:59.486373.486373 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 10:13:59.486203.486203 cuda_h.py:19] end restore_tensors2 cost 0.0002346038818359375 seconds
DEBUG 01-07 10:13:59.486072.486072 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0017969608306884766 seconds
DEBUG 01-07 10:13:59.488133.488133 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 10:13:59.488409.488409 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 10:13:59.488358.488358 cuda_h.py:19] end allocate_cuda_memory cost 0.0002040863037109375 seconds
DEBUG 01-07 10:13:59.488937.488937 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 10:13:59.488931.488931 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 10:13:59.488117.488117 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 10:13:59.488767.488767 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, ee9ba6c6-0ab6-4f91-a678-e48c81d6c2e8
DEBUG 01-07 10:13:59.489414.489414 client.py:106] call stub.LoadModelAsync
INFO 01-07 10:13:59.489775.489775 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, ee9ba6c6-0ab6-4f91-a678-e48c81d6c2e8
DEBUG 01-07 10:13:59.489935.489935 cuda_h.py:19] end load_into_gpu_async cost 0.0009133815765380859 seconds
DEBUG 01-07 10:13:59.489254.489254 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 10:13:59.490506.490506 cuda_h.py:19] end restore_tensors2 cost 0.00019669532775878906 seconds
DEBUG 01-07 10:13:59.490653.490653 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0016231536865234375 seconds
DEBUG 01-07 10:13:59.491809.491809 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model_multi_device cost 0.007226467132568359 seconds
DEBUG 01-07 10:13:59.491062.491062 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-07 10:13:59.492694.492694 lmp.py:816] 
DEBUG 01-07 10:13:59.492694.492694 lmp.py:816]   Computing 19 experts on CPU...
DEBUG 01-07 10:13:59.492722.492722 cuda_h.py:19] end cpu_experts_submit cost 0.00010728836059570312 seconds
DEBUG 01-07 10:13:59.492802.492802 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-07 10:13:59.497301.497301 mlpmodule.py:749] group tensors cost 0.0052530765533447266 s
DEBUG 01-07 10:13:59.499345.499345 mlpmodule.py:787] pad cost 0.0012288093566894531 s
DEBUG 01-07 10:13:59.499594.499594 mlpmodule.py:793] create cpu tensor cost 4.6253204345703125e-05 s
DEBUG 01-07 10:13:59.499133.499133 mlpmodule.py:798] move to cpu cost 3.647804260253906e-05 s
DEBUG 01-07 10:13:59.510167.510167 mlpmodule.py:812] group_w3: shape=torch.Size([19, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=54788096
DEBUG 01-07 10:13:59.510365.510365 mlpmodule.py:813] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-07 10:13:59.510130.510130 mlpmodule.py:818] group_w3 first element: 0.0264892578125
WARNING 01-07 10:13:59.510498.510498 mlpmodule.py:828] start einsum2
DEBUG 01-07 10:13:59.530530.530530 mlpmodule.py:838] group einsum cost 0.030369281768798828 s
DEBUG 01-07 10:13:59.530638.530638 mlpmodule.py:846] cpy2cputensor cost 0.00044035911560058594 s
DEBUG 01-07 10:13:59.533337.533337 cuda_h.py:19] end wait_cetm_experts cost 0.041265010833740234 seconds
DEBUG 01-07 10:13:59.533638.533638 cuda_h.py:10] start gpu_sexperts
DEBUG 01-07 10:13:59.534331.534331 cuda_h.py:19] end gpu_sexperts cost 0.0004687309265136719 seconds
DEBUG 01-07 10:13:59.534982.534982 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-07 10:13:59.534878.534878 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.4080276489257812e-05 seconds
DEBUG 01-07 10:13:59.534342.534342 cuda_h.py:10] start wait_experts_multi_device
INFO 01-07 10:13:59.534052.534052 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 908de111-7125-42e2-8aa1-74136504750a
INFO 01-07 10:13:59.535400.535400 client.py:127] Model loaded
INFO 01-07 10:13:59.535051.535051 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, ee9ba6c6-0ab6-4f91-a678-e48c81d6c2e8
INFO 01-07 10:13:59.535098.535098 client.py:127] Model loaded
DEBUG 01-07 10:13:59.535080.535080 cuda_h.py:19] end wait_experts_multi_device cost 0.001636505126953125 seconds
DEBUG 01-07 10:13:59.535929.535929 cuda_h.py:10] start gpu_experts_multi_device
DEBUG 01-07 10:13:59.535944.535944 lmp.py:867]   Computing 23 experts on cuda:2...
DEBUG 01-07 10:13:59.537362.537362 mlpmodule.py:533] gpu group tensors cost 0.0004794597625732422 s
DEBUG 01-07 10:13:59.538652.538652 mlpmodule.py:566] gpu pad cost 0.00127410888671875 s
DEBUG 01-07 10:13:59.539442.539442 mlpmodule.py:584] gpu group einsum cost 0.0005888938903808594 s
DEBUG 01-07 10:13:59.541937.541937 mlpmodule.py:656] gpu experts func einsum cost 0.004590749740600586 s
DEBUG 01-07 10:13:59.541324.541324 lmp.py:867]   Computing 22 experts on cuda:1...
DEBUG 01-07 10:13:59.542112.542112 mlpmodule.py:533] gpu group tensors cost 0.0004391670227050781 s
DEBUG 01-07 10:13:59.543658.543658 mlpmodule.py:707]  experts func einsum cost 0.050759077072143555 s
DEBUG 01-07 10:13:59.543877.543877 mlpmodule.py:566] gpu pad cost 0.0014121532440185547 s
DEBUG 01-07 10:13:59.544606.544606 mlpmodule.py:584] gpu group einsum cost 0.0004949569702148438 s
DEBUG 01-07 10:13:59.546678.546678 mlpmodule.py:656] gpu experts func einsum cost 0.004472970962524414 s
DEBUG 01-07 10:13:59.546038.546038 cuda_h.py:19] end gpu_experts_multi_device cost 0.010550260543823242 seconds
DEBUG 01-07 10:13:59.546584.546584 cuda_h.py:19] end layer_moe_generate_multi_device_18 cost 0.06457400321960449 seconds
DEBUG 01-07 10:13:59.546976.546976 lmp.py:194] -------------------------------- end prefill layer 18 --------------------------------
DEBUG 01-07 10:13:59.546937.546937 lmp.py:153] -------------------------------- start prefill layer 19 --------------------------------
DEBUG 01-07 10:13:59.546156.546156 cuda_h.py:10] start start_load_qkvogn_s_weight_l_20
DEBUG 01-07 10:13:59.546197.546197 cuda_h.py:10] start start_load_qkvogn_s_weight_l_20
DEBUG 01-07 10:13:59.546365.546365 cuda_h.py:19] end start_load_qkvogn_s_weight_l_20 cost 2.7418136596679688e-05 seconds
DEBUG 01-07 10:13:59.546591.546591 cuda_h.py:19] end start_load_qkvogn_s_weight_l_20 cost 5.745887756347656e-05 seconds
DEBUG 01-07 10:13:59.546664.546664 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-07 10:13:59.546739.546739 mlpmodule.py:367] cuda:1 cuda:1
DEBUG 01-07 10:13:59.547642.547642 cuda_h.py:10] start sllm_worker_task
DEBUG 01-07 10:13:59.547306.547306 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 10:13:59.547613.547613 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 10:13:59.547524.547524 cuda_h.py:19] end allocate_cuda_memory cost 0.0002856254577636719 seconds
DEBUG 01-07 10:13:59.547202.547202 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 10:13:59.547296.547296 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 10:13:59.547880.547880 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 10:13:59.547676.547676 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 4c773b21-8264-4dc9-b4d0-309b48765b5c
DEBUG 01-07 10:13:59.547539.547539 client.py:106] call stub.LoadModelAsync
DEBUG 01-07 10:13:59.548971.548971 cuda_h.py:10] start self_attn
INFO 01-07 10:13:59.548950.548950 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 4c773b21-8264-4dc9-b4d0-309b48765b5c
DEBUG 01-07 10:13:59.548402.548402 cuda_h.py:19] end load_into_gpu_async cost 0.000990152359008789 seconds
DEBUG 01-07 10:13:59.548482.548482 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 10:13:59.548903.548903 cuda_h.py:19] end restore_tensors2 cost 7.367134094238281e-05 seconds
DEBUG 01-07 10:13:59.548182.548182 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0015974044799804688 seconds
INFO 01-07 10:13:59.548926.548926 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 4c773b21-8264-4dc9-b4d0-309b48765b5c
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-07 10:13:59.551741.551741 cuda_h.py:19] end self_attn cost 0.0037336349487304688 seconds
DEBUG 01-07 10:13:59.552831.552831 cuda_h.py:19] end iln_self_attn_paln cost 0.0051496028900146484 seconds
DEBUG 01-07 10:13:59.552183.552183 cuda_h.py:10] start layer_moe_generate_multi_device_19
DEBUG 01-07 10:13:59.552324.552324 cuda_h.py:10] start gate
DEBUG 01-07 10:13:59.552381.552381 cuda_h.py:19] end gate cost 0.0006761550903320312 seconds
DEBUG 01-07 10:13:59.552687.552687 cuda_h.py:10] start experts_map_get
DEBUG 01-07 10:13:59.553184.553184 lmp.py:744] 
DEBUG 01-07 10:13:59.553184.553184 lmp.py:744] Expert Token Distribution & Multi-Device Allocation:
DEBUG 01-07 10:13:59.553562.553562 lmp.py:745]   Total experts: 64
DEBUG 01-07 10:13:59.553358.553358 lmp.py:746]   CPU experts: 19 (30%)
DEBUG 01-07 10:13:59.553862.553862 lmp.py:747]   GPU experts: 45 (70%)
DEBUG 01-07 10:13:59.553220.553220 lmp.py:748]   Number of GPU devices: 2
DEBUG 01-07 10:13:59.553101.553101 lmp.py:749] 
DEBUG 01-07 10:13:59.553101.553101 lmp.py:749]   Expert ID | Tokens | Device
DEBUG 01-07 10:13:59.553983.553983 lmp.py:750]   -----------------------------------
DEBUG 01-07 10:13:59.553825.553825 lmp.py:767]   Expert 44 |     40 | CPU
DEBUG 01-07 10:13:59.553421.553421 lmp.py:767]   Expert  1 |     46 | CPU
DEBUG 01-07 10:13:59.553064.553064 lmp.py:767]   Expert 60 |     64 | CPU
DEBUG 01-07 10:13:59.553184.553184 lmp.py:767]   Expert 28 |     66 | CPU
DEBUG 01-07 10:13:59.553589.553589 lmp.py:767]   Expert 48 |     76 | CPU
DEBUG 01-07 10:13:59.553755.553755 lmp.py:767]   Expert 27 |     84 | CPU
DEBUG 01-07 10:13:59.553398.553398 lmp.py:767]   Expert  0 |    101 | CPU
DEBUG 01-07 10:13:59.553564.553564 lmp.py:767]   Expert 62 |    109 | CPU
DEBUG 01-07 10:13:59.553969.553969 lmp.py:767]   Expert 59 |    111 | CPU
DEBUG 01-07 10:13:59.553088.553088 lmp.py:767]   Expert 30 |    113 | CPU
DEBUG 01-07 10:13:59.553208.553208 lmp.py:767]   Expert 22 |    115 | CPU
DEBUG 01-07 10:13:59.553090.553090 lmp.py:767]   Expert 42 |    116 | CPU
DEBUG 01-07 10:13:59.553686.553686 lmp.py:767]   Expert 58 |    120 | CPU
DEBUG 01-07 10:13:59.553091.553091 lmp.py:767]   Expert 16 |    124 | CPU
DEBUG 01-07 10:13:59.553257.553257 lmp.py:767]   Expert  8 |    125 | CPU
DEBUG 01-07 10:13:59.553423.553423 lmp.py:767]   Expert 12 |    125 | CPU
DEBUG 01-07 10:13:59.553351.553351 lmp.py:767]   Expert 50 |    135 | CPU
DEBUG 01-07 10:13:59.553517.553517 lmp.py:767]   Expert 56 |    142 | CPU
DEBUG 01-07 10:13:59.553683.553683 lmp.py:767]   Expert  5 |    145 | CPU
DEBUG 01-07 10:13:59.553803.553803 lmp.py:767]   Expert 57 |    146 | GPU0(cuda:1)
DEBUG 01-07 10:13:59.553399.553399 lmp.py:767]   Expert 55 |    151 | GPU0(cuda:1)
DEBUG 01-07 10:13:59.553711.553711 lmp.py:767]   Expert 26 |    153 | GPU1(cuda:2)
DEBUG 01-07 10:13:59.553023.553023 lmp.py:767]   Expert 15 |    155 | GPU1(cuda:2)
DEBUG 01-07 10:13:59.553335.553335 lmp.py:767]   Expert 32 |    155 | GPU0(cuda:1)
DEBUG 01-07 10:13:59.553170.553170 lmp.py:767]   Expert 47 |    160 | GPU1(cuda:2)
DEBUG 01-07 10:13:59.553767.553767 lmp.py:767]   Expert 24 |    161 | GPU0(cuda:1)
DEBUG 01-07 10:13:59.553648.553648 lmp.py:767]   Expert 34 |    164 | GPU0(cuda:1)
DEBUG 01-07 10:13:59.554530.554530 lmp.py:767]   Expert  2 |    166 | GPU1(cuda:2)
DEBUG 01-07 10:13:59.554650.554650 lmp.py:767]   Expert 52 |    168 | GPU0(cuda:1)
DEBUG 01-07 10:13:59.554054.554054 lmp.py:767]   Expert 40 |    170 | GPU0(cuda:1)
DEBUG 01-07 10:13:59.554174.554174 lmp.py:767]   Expert 54 |    170 | GPU1(cuda:2)
DEBUG 01-07 10:13:59.554055.554055 lmp.py:767]   Expert  6 |    172 | GPU1(cuda:2)
DEBUG 01-07 10:13:59.554460.554460 lmp.py:767]   Expert 13 |    173 | GPU1(cuda:2)
DEBUG 01-07 10:13:59.554341.554341 lmp.py:767]   Expert 18 |    173 | GPU0(cuda:1)
DEBUG 01-07 10:13:59.554176.554176 lmp.py:767]   Expert  3 |    174 | GPU1(cuda:2)
DEBUG 01-07 10:13:59.554535.554535 lmp.py:767]   Expert 41 |    174 | GPU0(cuda:1)
DEBUG 01-07 10:13:59.554416.554416 lmp.py:767]   Expert 20 |    180 | GPU0(cuda:1)
DEBUG 01-07 10:13:59.554774.554774 lmp.py:767]   Expert 19 |    181 | GPU1(cuda:2)
DEBUG 01-07 10:13:59.554894.554894 lmp.py:767]   Expert 46 |    182 | GPU1(cuda:2)
DEBUG 01-07 10:13:59.554775.554775 lmp.py:767]   Expert 37 |    189 | GPU0(cuda:1)
DEBUG 01-07 10:13:59.554895.554895 lmp.py:767]   Expert 25 |    191 | GPU1(cuda:2)
DEBUG 01-07 10:13:59.554777.554777 lmp.py:767]   Expert 17 |    195 | GPU0(cuda:1)
DEBUG 01-07 10:13:59.554420.554420 lmp.py:767]   Expert 51 |    196 | GPU0(cuda:1)
DEBUG 01-07 10:13:59.554301.554301 lmp.py:767]   Expert 43 |    201 | GPU1(cuda:2)
DEBUG 01-07 10:13:59.554944.554944 lmp.py:767]   Expert 35 |    202 | GPU0(cuda:1)
DEBUG 01-07 10:13:59.554825.554825 lmp.py:767]   Expert 11 |    205 | GPU1(cuda:2)
DEBUG 01-07 10:13:59.554707.554707 lmp.py:767]   Expert 31 |    206 | GPU0(cuda:1)
DEBUG 01-07 10:13:59.554065.554065 lmp.py:767]   Expert 23 |    211 | GPU1(cuda:2)
DEBUG 01-07 10:13:59.554423.554423 lmp.py:767]   Expert 39 |    223 | GPU0(cuda:1)
DEBUG 01-07 10:13:59.554020.554020 lmp.py:767]   Expert 49 |    224 | GPU1(cuda:2)
DEBUG 01-07 10:13:59.554616.554616 lmp.py:767]   Expert 53 |    231 | GPU0(cuda:1)
DEBUG 01-07 10:13:59.554736.554736 lmp.py:767]   Expert 10 |    236 | GPU1(cuda:2)
DEBUG 01-07 10:13:59.554141.554141 lmp.py:767]   Expert 33 |    248 | GPU0(cuda:1)
DEBUG 01-07 10:13:59.554022.554022 lmp.py:767]   Expert 36 |    265 | GPU1(cuda:2)
DEBUG 01-07 10:13:59.554665.554665 lmp.py:767]   Expert 38 |    266 | GPU1(cuda:2)
DEBUG 01-07 10:13:59.554547.554547 lmp.py:767]   Expert  4 |    305 | GPU0(cuda:1)
DEBUG 01-07 10:13:59.554428.554428 lmp.py:767]   Expert 21 |    331 | GPU0(cuda:1)
DEBUG 01-07 10:13:59.554548.554548 lmp.py:767]   Expert 14 |    345 | GPU1(cuda:2)
DEBUG 01-07 10:13:59.554952.554952 lmp.py:767]   Expert 63 |    368 | GPU0(cuda:1)
DEBUG 01-07 10:13:59.554787.554787 lmp.py:767]   Expert 45 |    373 | GPU1(cuda:2)
DEBUG 01-07 10:13:59.554384.554384 lmp.py:767]   Expert 61 |    390 | GPU0(cuda:1)
DEBUG 01-07 10:13:59.554981.554981 lmp.py:767]   Expert  9 |    397 | GPU1(cuda:2)
DEBUG 01-07 10:13:59.554339.554339 lmp.py:767]   Expert 29 |    493 | GPU1(cuda:2)
DEBUG 01-07 10:13:59.554220.554220 lmp.py:767]   Expert  7 |    512 | GPU0(cuda:1)
DEBUG 01-07 10:13:59.554910.554910 lmp.py:769] 
DEBUG 01-07 10:13:59.554910.554910 lmp.py:769]   Device Token Distribution:
DEBUG 01-07 10:13:59.554314.554314 lmp.py:770]   CPU:   1957 tokens
DEBUG 01-07 10:13:59.554434.554434 lmp.py:774]   cuda:1:   5238 tokens (23 experts)
DEBUG 01-07 10:13:59.554839.554839 lmp.py:774]   cuda:2:   5093 tokens (22 experts)
DEBUG 01-07 10:13:59.554005.554005 lmp.py:775]   Total GPU:  10331 tokens
DEBUG 01-07 10:13:59.554694.554694 lmp.py:776] ============================================================
DEBUG 01-07 10:13:59.554694.554694 lmp.py:776] 
DEBUG 01-07 10:13:59.554821.554821 cuda_h.py:19] end experts_map_get cost 0.0017902851104736328 seconds
DEBUG 01-07 10:13:59.554940.554940 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model_multi_device
DEBUG 01-07 10:13:59.554048.554048 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 10:13:59.554720.554720 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 10:13:59.555868.555868 cuda_h.py:19] end allocate_cuda_memory cost 0.00021529197692871094 seconds
DEBUG 01-07 10:13:59.555321.555321 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 10:13:59.555600.555600 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 10:13:59.555648.555648 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 10:13:59.555013.555013 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 80de1c24-c978-4bbe-aa78-60bfd81230c4
DEBUG 01-07 10:13:59.555031.555031 client.py:106] call stub.LoadModelAsync
INFO 01-07 10:13:59.555638.555638 client.py:127] Model loaded
DEBUG 01-07 10:13:59.556094.556094 cuda_h.py:19] end sllm_worker_task cost 0.008905172348022461 seconds
INFO 01-07 10:13:59.556160.556160 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 80de1c24-c978-4bbe-aa78-60bfd81230c4
DEBUG 01-07 10:13:59.556056.556056 cuda_h.py:19] end load_into_gpu_async cost 0.0011413097381591797 seconds
DEBUG 01-07 10:13:59.556567.556567 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 10:13:59.556251.556251 cuda_h.py:19] end restore_tensors2 cost 0.00023412704467773438 seconds
DEBUG 01-07 10:13:59.556305.556305 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0019218921661376953 seconds
DEBUG 01-07 10:13:59.558680.558680 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 10:13:59.558651.558651 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 10:13:59.559129.559129 cuda_h.py:19] end allocate_cuda_memory cost 0.000209808349609375 seconds
DEBUG 01-07 10:13:59.559780.559780 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 10:13:59.559152.559152 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 10:13:59.559385.559385 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 10:13:59.559750.559750 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 3f10ae7e-2eef-438b-b60b-6217882689ed
DEBUG 01-07 10:13:59.559635.559635 client.py:106] call stub.LoadModelAsync
INFO 01-07 10:13:59.560623.560623 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 3f10ae7e-2eef-438b-b60b-6217882689ed
DEBUG 01-07 10:13:59.560406.560406 cuda_h.py:19] end load_into_gpu_async cost 0.0010628700256347656 seconds
DEBUG 01-07 10:13:59.560963.560963 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 10:13:59.560514.560514 cuda_h.py:19] end restore_tensors2 cost 0.00020503997802734375 seconds
DEBUG 01-07 10:13:59.560237.560237 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0017666816711425781 seconds
DEBUG 01-07 10:13:59.562011.562011 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model_multi_device cost 0.00743556022644043 seconds
DEBUG 01-07 10:13:59.562788.562788 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-07 10:13:59.562896.562896 lmp.py:816] 
DEBUG 01-07 10:13:59.562896.562896 lmp.py:816]   Computing 19 experts on CPU...
DEBUG 01-07 10:13:59.562740.562740 cuda_h.py:19] end cpu_experts_submit cost 0.00011181831359863281 seconds
DEBUG 01-07 10:13:59.562343.562343 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-07 10:13:59.567055.567055 mlpmodule.py:749] group tensors cost 0.00531005859375 s
DEBUG 01-07 10:13:59.569781.569781 mlpmodule.py:787] pad cost 0.0012426376342773438 s
DEBUG 01-07 10:13:59.569315.569315 mlpmodule.py:793] create cpu tensor cost 4.6253204345703125e-05 s
DEBUG 01-07 10:13:59.570138.570138 mlpmodule.py:798] move to cpu cost 3.647804260253906e-05 s
DEBUG 01-07 10:13:59.580038.580038 mlpmodule.py:812] group_w3: shape=torch.Size([19, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=54788096
DEBUG 01-07 10:13:59.580662.580662 mlpmodule.py:813] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-07 10:13:59.580235.580235 mlpmodule.py:818] group_w3 first element: -0.0034942626953125
WARNING 01-07 10:13:59.580273.580273 mlpmodule.py:828] start einsum2
DEBUG 01-07 10:13:59.599657.599657 mlpmodule.py:838] group einsum cost 0.029439687728881836 s
DEBUG 01-07 10:13:59.600970.600970 mlpmodule.py:846] cpy2cputensor cost 0.00045299530029296875 s
DEBUG 01-07 10:13:59.602621.602621 cuda_h.py:19] end wait_cetm_experts cost 0.04029226303100586 seconds
DEBUG 01-07 10:13:59.602981.602981 cuda_h.py:10] start gpu_sexperts
DEBUG 01-07 10:13:59.603305.603305 cuda_h.py:19] end gpu_sexperts cost 0.0005106925964355469 seconds
DEBUG 01-07 10:13:59.603678.603678 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-07 10:13:59.603766.603766 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.574920654296875e-05 seconds
DEBUG 01-07 10:13:59.603422.603422 cuda_h.py:10] start wait_experts_multi_device
INFO 01-07 10:13:59.603324.603324 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 80de1c24-c978-4bbe-aa78-60bfd81230c4
INFO 01-07 10:13:59.606750.606750 client.py:127] Model loaded
INFO 01-07 10:13:59.606891.606891 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 3f10ae7e-2eef-438b-b60b-6217882689ed
INFO 01-07 10:13:59.606132.606132 client.py:127] Model loaded
DEBUG 01-07 10:13:59.606014.606014 cuda_h.py:19] end wait_experts_multi_device cost 0.003000974655151367 seconds
DEBUG 01-07 10:13:59.606009.606009 cuda_h.py:10] start gpu_experts_multi_device
DEBUG 01-07 10:13:59.606454.606454 lmp.py:867]   Computing 22 experts on cuda:2...
DEBUG 01-07 10:13:59.607704.607704 mlpmodule.py:533] gpu group tensors cost 0.00045943260192871094 s
DEBUG 01-07 10:13:59.609297.609297 mlpmodule.py:566] gpu pad cost 0.0012483596801757812 s
DEBUG 01-07 10:13:59.609908.609908 mlpmodule.py:584] gpu group einsum cost 0.0005574226379394531 s
DEBUG 01-07 10:13:59.611106.611106 mlpmodule.py:707]  experts func einsum cost 0.04918551445007324 s
DEBUG 01-07 10:13:59.611202.611202 mlpmodule.py:656] gpu experts func einsum cost 0.0044786930084228516 s
DEBUG 01-07 10:13:59.612418.612418 lmp.py:867]   Computing 23 experts on cuda:1...
DEBUG 01-07 10:13:59.612112.612112 mlpmodule.py:533] gpu group tensors cost 0.0004420280456542969 s
DEBUG 01-07 10:13:59.614850.614850 mlpmodule.py:566] gpu pad cost 0.0012242794036865234 s
DEBUG 01-07 10:13:59.614344.614344 mlpmodule.py:584] gpu group einsum cost 0.00043773651123046875 s
DEBUG 01-07 10:13:59.616048.616048 mlpmodule.py:656] gpu experts func einsum cost 0.0040819644927978516 s
DEBUG 01-07 10:13:59.616648.616648 cuda_h.py:19] end gpu_experts_multi_device cost 0.009956121444702148 seconds
DEBUG 01-07 10:13:59.616279.616279 cuda_h.py:19] end layer_moe_generate_multi_device_19 cost 0.06454229354858398 seconds
DEBUG 01-07 10:13:59.616631.616631 lmp.py:194] -------------------------------- end prefill layer 19 --------------------------------
DEBUG 01-07 10:13:59.617116.617116 lmp.py:153] -------------------------------- start prefill layer 20 --------------------------------
DEBUG 01-07 10:13:59.617097.617097 cuda_h.py:10] start start_load_qkvogn_s_weight_l_21
DEBUG 01-07 10:13:59.617807.617807 cuda_h.py:10] start start_load_qkvogn_s_weight_l_21
DEBUG 01-07 10:13:59.617404.617404 cuda_h.py:19] end start_load_qkvogn_s_weight_l_21 cost 2.8133392333984375e-05 seconds
DEBUG 01-07 10:13:59.617346.617346 cuda_h.py:19] end start_load_qkvogn_s_weight_l_21 cost 5.888938903808594e-05 seconds
DEBUG 01-07 10:13:59.617181.617181 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-07 10:13:59.617719.617719 cuda_h.py:10] start sllm_worker_task
DEBUG 01-07 10:13:59.617575.617575 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 10:13:59.617266.617266 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 10:13:59.617660.617660 cuda_h.py:19] end allocate_cuda_memory cost 0.0002562999725341797 seconds
DEBUG 01-07 10:13:59.617053.617053 mlpmodule.py:367] cuda:1 cuda:1
DEBUG 01-07 10:13:59.617121.617121 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 10:13:59.617720.617720 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 10:13:59.617304.617304 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 10:13:59.617577.617577 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 76f18a79-2c97-456c-acc6-c33ab736cf26
DEBUG 01-07 10:13:59.617632.617632 client.py:106] call stub.LoadModelAsync
DEBUG 01-07 10:13:59.618655.618655 cuda_h.py:10] start self_attn
INFO 01-07 10:13:59.618297.618297 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 76f18a79-2c97-456c-acc6-c33ab736cf26
DEBUG 01-07 10:13:59.618034.618034 cuda_h.py:19] end load_into_gpu_async cost 0.0008640289306640625 seconds
DEBUG 01-07 10:13:59.618114.618114 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 10:13:59.618190.618190 cuda_h.py:19] end restore_tensors2 cost 6.580352783203125e-05 seconds
DEBUG 01-07 10:13:59.618992.618992 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.001539468765258789 seconds
INFO 01-07 10:13:59.618305.618305 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 76f18a79-2c97-456c-acc6-c33ab736cf26
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-07 10:13:59.621712.621712 cuda_h.py:19] end self_attn cost 0.0035982131958007812 seconds
DEBUG 01-07 10:13:59.622908.622908 cuda_h.py:19] end iln_self_attn_paln cost 0.005072116851806641 seconds
DEBUG 01-07 10:13:59.622400.622400 cuda_h.py:10] start layer_moe_generate_multi_device_20
DEBUG 01-07 10:13:59.622586.622586 cuda_h.py:10] start gate
DEBUG 01-07 10:13:59.623827.623827 cuda_h.py:19] end gate cost 0.000637054443359375 seconds
DEBUG 01-07 10:13:59.623272.623272 cuda_h.py:10] start experts_map_get
DEBUG 01-07 10:13:59.623815.623815 lmp.py:744] 
DEBUG 01-07 10:13:59.623815.623815 lmp.py:744] Expert Token Distribution & Multi-Device Allocation:
DEBUG 01-07 10:13:59.623016.623016 lmp.py:745]   Total experts: 64
DEBUG 01-07 10:13:59.623050.623050 lmp.py:746]   CPU experts: 19 (30%)
DEBUG 01-07 10:13:59.623315.623315 lmp.py:747]   GPU experts: 45 (70%)
DEBUG 01-07 10:13:59.623912.623912 lmp.py:748]   Number of GPU devices: 2
DEBUG 01-07 10:13:59.623316.623316 lmp.py:749] 
DEBUG 01-07 10:13:59.623316.623316 lmp.py:749]   Expert ID | Tokens | Device
DEBUG 01-07 10:13:59.623721.623721 lmp.py:750]   -----------------------------------
DEBUG 01-07 10:13:59.623847.623847 lmp.py:767]   Expert 54 |     22 | CPU
DEBUG 01-07 10:13:59.623490.623490 lmp.py:767]   Expert  3 |     33 | CPU
DEBUG 01-07 10:13:59.623657.623657 lmp.py:767]   Expert  8 |     41 | CPU
DEBUG 01-07 10:13:59.623346.623346 lmp.py:767]   Expert 28 |     44 | CPU
DEBUG 01-07 10:13:59.623035.623035 lmp.py:767]   Expert 43 |     55 | CPU
DEBUG 01-07 10:13:59.623963.623963 lmp.py:767]   Expert 63 |     56 | CPU
DEBUG 01-07 10:13:59.623652.623652 lmp.py:767]   Expert 36 |     72 | CPU
DEBUG 01-07 10:13:59.623295.623295 lmp.py:767]   Expert  6 |     74 | CPU
DEBUG 01-07 10:13:59.623700.623700 lmp.py:767]   Expert 38 |     75 | CPU
DEBUG 01-07 10:13:59.623627.623627 lmp.py:767]   Expert 39 |     91 | CPU
DEBUG 01-07 10:13:59.623794.623794 lmp.py:767]   Expert 57 |    102 | CPU
DEBUG 01-07 10:13:59.623483.623483 lmp.py:767]   Expert 12 |    103 | CPU
DEBUG 01-07 10:13:59.623695.623695 lmp.py:767]   Expert 41 |    103 | CPU
DEBUG 01-07 10:13:59.623908.623908 lmp.py:767]   Expert 52 |    106 | CPU
DEBUG 01-07 10:13:59.623643.623643 lmp.py:767]   Expert 19 |    121 | CPU
DEBUG 01-07 10:13:59.623094.623094 lmp.py:767]   Expert 47 |    121 | CPU
DEBUG 01-07 10:13:59.623307.623307 lmp.py:767]   Expert 13 |    133 | CPU
DEBUG 01-07 10:13:59.623042.623042 lmp.py:767]   Expert 22 |    140 | CPU
DEBUG 01-07 10:13:59.623255.623255 lmp.py:767]   Expert 46 |    154 | CPU
DEBUG 01-07 10:13:59.623898.623898 lmp.py:767]   Expert 50 |    155 | GPU0(cuda:1)
DEBUG 01-07 10:13:59.623018.623018 lmp.py:767]   Expert 40 |    163 | GPU0(cuda:1)
DEBUG 01-07 10:13:59.623137.623137 lmp.py:767]   Expert 24 |    166 | GPU1(cuda:2)
DEBUG 01-07 10:13:59.623496.623496 lmp.py:767]   Expert 20 |    167 | GPU1(cuda:2)
DEBUG 01-07 10:13:59.624377.624377 lmp.py:767]   Expert 55 |    167 | GPU0(cuda:1)
DEBUG 01-07 10:13:59.624782.624782 lmp.py:767]   Expert 23 |    169 | GPU1(cuda:2)
DEBUG 01-07 10:13:59.624709.624709 lmp.py:767]   Expert 37 |    171 | GPU0(cuda:1)
DEBUG 01-07 10:13:59.624876.624876 lmp.py:767]   Expert 53 |    174 | GPU1(cuda:2)
DEBUG 01-07 10:13:59.624042.624042 lmp.py:767]   Expert 49 |    176 | GPU0(cuda:1)
DEBUG 01-07 10:13:59.624208.624208 lmp.py:767]   Expert  2 |    178 | GPU1(cuda:2)
DEBUG 01-07 10:13:59.624136.624136 lmp.py:767]   Expert 61 |    179 | GPU0(cuda:1)
DEBUG 01-07 10:13:59.624586.624586 lmp.py:767]   Expert 42 |    180 | GPU0(cuda:1)
DEBUG 01-07 10:13:59.624991.624991 lmp.py:767]   Expert 21 |    184 | GPU1(cuda:2)
DEBUG 01-07 10:13:59.624634.624634 lmp.py:767]   Expert 18 |    190 | GPU1(cuda:2)
DEBUG 01-07 10:13:59.624038.624038 lmp.py:767]   Expert 33 |    190 | GPU0(cuda:1)
DEBUG 01-07 10:13:59.624920.624920 lmp.py:767]   Expert 32 |    197 | GPU1(cuda:2)
DEBUG 01-07 10:13:59.624324.624324 lmp.py:767]   Expert  0 |    199 | GPU0(cuda:1)
DEBUG 01-07 10:13:59.624491.624491 lmp.py:767]   Expert  5 |    203 | GPU0(cuda:1)
DEBUG 01-07 10:13:59.624418.624418 lmp.py:767]   Expert 30 |    203 | GPU1(cuda:2)
DEBUG 01-07 10:13:59.624584.624584 lmp.py:767]   Expert 14 |    204 | GPU0(cuda:1)
DEBUG 01-07 10:13:59.624512.624512 lmp.py:767]   Expert 16 |    204 | GPU1(cuda:2)
DEBUG 01-07 10:13:59.624440.624440 lmp.py:767]   Expert 31 |    209 | GPU1(cuda:2)
DEBUG 01-07 10:13:59.624129.624129 lmp.py:767]   Expert  7 |    211 | GPU0(cuda:1)
DEBUG 01-07 10:13:59.624295.624295 lmp.py:767]   Expert 34 |    211 | GPU0(cuda:1)
DEBUG 01-07 10:13:59.624223.624223 lmp.py:767]   Expert 60 |    215 | GPU1(cuda:2)
DEBUG 01-07 10:13:59.624866.624866 lmp.py:767]   Expert 62 |    217 | GPU0(cuda:1)
DEBUG 01-07 10:13:59.624138.624138 lmp.py:767]   Expert 59 |    219 | GPU1(cuda:2)
DEBUG 01-07 10:13:59.624258.624258 lmp.py:767]   Expert 17 |    220 | GPU0(cuda:1)
DEBUG 01-07 10:13:59.624140.624140 lmp.py:767]   Expert  9 |    223 | GPU1(cuda:2)
DEBUG 01-07 10:13:59.624498.624498 lmp.py:767]   Expert 10 |    226 | GPU0(cuda:1)
DEBUG 01-07 10:13:59.624902.624902 lmp.py:767]   Expert 29 |    228 | GPU1(cuda:2)
DEBUG 01-07 10:13:59.624307.624307 lmp.py:767]   Expert  4 |    237 | GPU1(cuda:2)
DEBUG 01-07 10:13:59.624473.624473 lmp.py:767]   Expert 15 |    237 | GPU0(cuda:1)
DEBUG 01-07 10:13:59.624162.624162 lmp.py:767]   Expert 58 |    240 | GPU0(cuda:1)
DEBUG 01-07 10:13:59.624852.624852 lmp.py:767]   Expert 26 |    245 | GPU1(cuda:2)
DEBUG 01-07 10:13:59.624541.624541 lmp.py:767]   Expert 51 |    251 | GPU0(cuda:1)
DEBUG 01-07 10:13:59.624661.624661 lmp.py:767]   Expert 11 |    255 | GPU1(cuda:2)
DEBUG 01-07 10:13:59.624304.624304 lmp.py:767]   Expert 44 |    270 | GPU1(cuda:2)
DEBUG 01-07 10:13:59.624708.624708 lmp.py:767]   Expert 56 |    288 | GPU0(cuda:1)
DEBUG 01-07 10:13:59.624113.624113 lmp.py:767]   Expert 27 |    289 | GPU0(cuda:1)
DEBUG 01-07 10:13:59.624517.624517 lmp.py:767]   Expert  1 |    335 | GPU1(cuda:2)
DEBUG 01-07 10:13:59.624160.624160 lmp.py:767]   Expert 45 |    369 | GPU0(cuda:1)
DEBUG 01-07 10:13:59.624565.624565 lmp.py:767]   Expert 25 |    460 | GPU1(cuda:2)
DEBUG 01-07 10:13:59.624499.624499 lmp.py:767]   Expert 35 |    516 | GPU1(cuda:2)
DEBUG 01-07 10:13:59.624142.624142 lmp.py:767]   Expert 48 |    652 | GPU0(cuda:1)
DEBUG 01-07 10:13:59.624832.624832 lmp.py:769] 
DEBUG 01-07 10:13:59.624832.624832 lmp.py:769]   Device Token Distribution:
DEBUG 01-07 10:13:59.624998.624998 lmp.py:770]   CPU:   1646 tokens
DEBUG 01-07 10:13:59.624356.624356 lmp.py:774]   cuda:1:   5398 tokens (23 experts)
DEBUG 01-07 10:13:59.624284.624284 lmp.py:774]   cuda:2:   5244 tokens (22 experts)
DEBUG 01-07 10:13:59.624019.624019 lmp.py:775]   Total GPU:  10642 tokens
DEBUG 01-07 10:13:59.624993.624993 lmp.py:776] ============================================================
DEBUG 01-07 10:13:59.624993.624993 lmp.py:776] 
DEBUG 01-07 10:13:59.624405.624405 cuda_h.py:19] end experts_map_get cost 0.0017538070678710938 seconds
DEBUG 01-07 10:13:59.624333.624333 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model_multi_device
DEBUG 01-07 10:13:59.624155.624155 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 10:13:59.625728.625728 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 10:13:59.625319.625319 cuda_h.py:19] end allocate_cuda_memory cost 0.00019311904907226562 seconds
DEBUG 01-07 10:13:59.625870.625870 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 10:13:59.625050.625050 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 10:13:59.625952.625952 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 10:13:59.625125.625125 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 20317530-3f8a-44e1-8452-bf287979c4cb
DEBUG 01-07 10:13:59.625745.625745 client.py:106] call stub.LoadModelAsync
INFO 01-07 10:13:59.625273.625273 client.py:127] Model loaded
DEBUG 01-07 10:13:59.626815.626815 cuda_h.py:19] end sllm_worker_task cost 0.008747577667236328 seconds
INFO 01-07 10:13:59.626048.626048 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 20317530-3f8a-44e1-8452-bf287979c4cb
DEBUG 01-07 10:13:59.626223.626223 cuda_h.py:19] end load_into_gpu_async cost 0.0010023117065429688 seconds
DEBUG 01-07 10:13:59.626972.626972 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 10:13:59.626663.626663 cuda_h.py:19] end restore_tensors2 cost 0.0002384185791015625 seconds
DEBUG 01-07 10:13:59.626240.626240 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.001725912094116211 seconds
DEBUG 01-07 10:13:59.628562.628562 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 10:13:59.628116.628116 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 10:13:59.628170.628170 cuda_h.py:19] end allocate_cuda_memory cost 0.00021219253540039062 seconds
DEBUG 01-07 10:13:59.628914.628914 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 10:13:59.629763.629763 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 10:13:59.629188.629188 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 10:13:59.629599.629599 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, e5d88dd3-81ff-46a2-b810-71d2227dad1c
DEBUG 01-07 10:13:59.629676.629676 client.py:106] call stub.LoadModelAsync
INFO 01-07 10:13:59.629598.629598 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, e5d88dd3-81ff-46a2-b810-71d2227dad1c
DEBUG 01-07 10:13:59.629090.629090 cuda_h.py:19] end load_into_gpu_async cost 0.0008709430694580078 seconds
DEBUG 01-07 10:13:59.629647.629647 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 10:13:59.630509.630509 cuda_h.py:19] end restore_tensors2 cost 0.00018930435180664062 seconds
DEBUG 01-07 10:13:59.630609.630609 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.001565694808959961 seconds
DEBUG 01-07 10:13:59.631629.631629 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model_multi_device cost 0.007040262222290039 seconds
DEBUG 01-07 10:13:59.631829.631829 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-07 10:13:59.632123.632123 lmp.py:816] 
DEBUG 01-07 10:13:59.632123.632123 lmp.py:816]   Computing 19 experts on CPU...
DEBUG 01-07 10:13:59.632197.632197 cuda_h.py:19] end cpu_experts_submit cost 0.0001049041748046875 seconds
DEBUG 01-07 10:13:59.632562.632562 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-07 10:13:59.642849.642849 mlpmodule.py:749] group tensors cost 0.00980997085571289 s
DEBUG 01-07 10:13:59.643395.643395 mlpmodule.py:787] pad cost 0.0009639263153076172 s
DEBUG 01-07 10:13:59.643093.643093 mlpmodule.py:793] create cpu tensor cost 3.9577484130859375e-05 s
DEBUG 01-07 10:13:59.643897.643897 mlpmodule.py:798] move to cpu cost 3.0517578125e-05 s
DEBUG 01-07 10:13:59.654500.654500 mlpmodule.py:812] group_w3: shape=torch.Size([19, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=54788096
DEBUG 01-07 10:13:59.654367.654367 mlpmodule.py:813] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-07 10:13:59.654655.654655 mlpmodule.py:818] group_w3 first element: 0.0205078125
WARNING 01-07 10:13:59.655070.655070 mlpmodule.py:828] start einsum2
DEBUG 01-07 10:13:59.674466.674466 mlpmodule.py:838] group einsum cost 0.0309598445892334 s
DEBUG 01-07 10:13:59.675963.675963 mlpmodule.py:846] cpy2cputensor cost 0.0004181861877441406 s
DEBUG 01-07 10:13:59.678732.678732 cuda_h.py:19] end wait_cetm_experts cost 0.045972585678100586 seconds
DEBUG 01-07 10:13:59.678994.678994 cuda_h.py:10] start gpu_sexperts
DEBUG 01-07 10:13:59.678164.678164 cuda_h.py:19] end gpu_sexperts cost 0.0005056858062744141 seconds
DEBUG 01-07 10:13:59.678862.678862 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-07 10:13:59.678711.678711 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.4557113647460938e-05 seconds
DEBUG 01-07 10:13:59.678368.678368 cuda_h.py:10] start wait_experts_multi_device
INFO 01-07 10:13:59.678078.678078 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 20317530-3f8a-44e1-8452-bf287979c4cb
INFO 01-07 10:13:59.679935.679935 client.py:127] Model loaded
INFO 01-07 10:13:59.679764.679764 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, e5d88dd3-81ff-46a2-b810-71d2227dad1c
INFO 01-07 10:13:59.680242.680242 client.py:127] Model loaded
DEBUG 01-07 10:13:59.680833.680833 cuda_h.py:19] end wait_experts_multi_device cost 0.0014014244079589844 seconds
DEBUG 01-07 10:13:59.680795.680795 cuda_h.py:10] start gpu_experts_multi_device
DEBUG 01-07 10:13:59.680048.680048 lmp.py:867]   Computing 22 experts on cuda:2...
DEBUG 01-07 10:13:59.681192.681192 mlpmodule.py:533] gpu group tensors cost 0.0004642009735107422 s
DEBUG 01-07 10:13:59.682678.682678 mlpmodule.py:566] gpu pad cost 0.0012118816375732422 s
DEBUG 01-07 10:13:59.683532.683532 mlpmodule.py:584] gpu group einsum cost 0.0005257129669189453 s
DEBUG 01-07 10:13:59.685851.685851 mlpmodule.py:656] gpu experts func einsum cost 0.00432133674621582 s
DEBUG 01-07 10:13:59.685224.685224 lmp.py:867]   Computing 23 experts on cuda:1...
DEBUG 01-07 10:13:59.686262.686262 mlpmodule.py:533] gpu group tensors cost 0.0004475116729736328 s
DEBUG 01-07 10:13:59.687594.687594 mlpmodule.py:707]  experts func einsum cost 0.05521225929260254 s
DEBUG 01-07 10:13:59.687958.687958 mlpmodule.py:566] gpu pad cost 0.001363515853881836 s
DEBUG 01-07 10:13:59.688668.688668 mlpmodule.py:584] gpu group einsum cost 0.00034046173095703125 s
DEBUG 01-07 10:13:59.690128.690128 mlpmodule.py:656] gpu experts func einsum cost 0.004175662994384766 s
DEBUG 01-07 10:13:59.690257.690257 cuda_h.py:19] end gpu_experts_multi_device cost 0.00982666015625 seconds
DEBUG 01-07 10:13:59.690896.690896 cuda_h.py:19] end layer_moe_generate_multi_device_20 cost 0.06799674034118652 seconds
DEBUG 01-07 10:13:59.690401.690401 lmp.py:194] -------------------------------- end prefill layer 20 --------------------------------
DEBUG 01-07 10:13:59.690701.690701 lmp.py:153] -------------------------------- start prefill layer 21 --------------------------------
DEBUG 01-07 10:13:59.690112.690112 cuda_h.py:10] start start_load_qkvogn_s_weight_l_22
DEBUG 01-07 10:13:59.690630.690630 cuda_h.py:10] start start_load_qkvogn_s_weight_l_22
DEBUG 01-07 10:13:59.690797.690797 cuda_h.py:19] end start_load_qkvogn_s_weight_l_22 cost 2.6464462280273438e-05 seconds
DEBUG 01-07 10:13:59.690977.690977 cuda_h.py:19] end start_load_qkvogn_s_weight_l_22 cost 5.698204040527344e-05 seconds
DEBUG 01-07 10:13:59.690766.690766 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-07 10:13:59.690317.690317 mlpmodule.py:367] cuda:1 cuda:1
DEBUG 01-07 10:13:59.690591.690591 cuda_h.py:10] start sllm_worker_task
DEBUG 01-07 10:13:59.690315.690315 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 10:13:59.691383.691383 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 10:13:59.691356.691356 cuda_h.py:19] end allocate_cuda_memory cost 0.00033092498779296875 seconds
DEBUG 01-07 10:13:59.691902.691902 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 10:13:59.691949.691949 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 10:13:59.691196.691196 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 10:13:59.691468.691468 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 7f885a88-c5f9-40ed-8fa3-82430255bbca
DEBUG 01-07 10:13:59.691808.691808 client.py:106] call stub.LoadModelAsync
DEBUG 01-07 10:13:59.691339.691339 cuda_h.py:10] start self_attn
INFO 01-07 10:13:59.692439.692439 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 7f885a88-c5f9-40ed-8fa3-82430255bbca
DEBUG 01-07 10:13:59.692414.692414 cuda_h.py:19] end load_into_gpu_async cost 0.0008342266082763672 seconds
DEBUG 01-07 10:13:59.692747.692747 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 10:13:59.692637.692637 cuda_h.py:19] end restore_tensors2 cost 6.866455078125e-05 seconds
DEBUG 01-07 10:13:59.692439.692439 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0015006065368652344 seconds
INFO 01-07 10:13:59.692203.692203 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 7f885a88-c5f9-40ed-8fa3-82430255bbca
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-07 10:13:59.695907.695907 cuda_h.py:19] end self_attn cost 0.0036597251892089844 seconds
DEBUG 01-07 10:13:59.695136.695136 cuda_h.py:19] end iln_self_attn_paln cost 0.005089282989501953 seconds
DEBUG 01-07 10:13:59.695535.695535 cuda_h.py:10] start layer_moe_generate_multi_device_21
DEBUG 01-07 10:13:59.696960.696960 cuda_h.py:10] start gate
DEBUG 01-07 10:13:59.696631.696631 cuda_h.py:19] end gate cost 0.000637054443359375 seconds
DEBUG 01-07 10:13:59.696838.696838 cuda_h.py:10] start experts_map_get
DEBUG 01-07 10:13:59.697090.697090 lmp.py:744] 
DEBUG 01-07 10:13:59.697090.697090 lmp.py:744] Expert Token Distribution & Multi-Device Allocation:
DEBUG 01-07 10:13:59.697959.697959 lmp.py:745]   Total experts: 64
DEBUG 01-07 10:13:59.697231.697231 lmp.py:746]   CPU experts: 19 (30%)
DEBUG 01-07 10:13:59.697020.697020 lmp.py:747]   GPU experts: 45 (70%)
DEBUG 01-07 10:13:59.697617.697617 lmp.py:748]   Number of GPU devices: 2
DEBUG 01-07 10:13:59.697783.697783 lmp.py:749] 
DEBUG 01-07 10:13:59.697783.697783 lmp.py:749]   Expert ID | Tokens | Device
DEBUG 01-07 10:13:59.697187.697187 lmp.py:750]   -----------------------------------
DEBUG 01-07 10:13:59.697267.697267 lmp.py:767]   Expert 44 |     28 | CPU
DEBUG 01-07 10:13:59.697910.697910 lmp.py:767]   Expert  9 |     36 | CPU
DEBUG 01-07 10:13:59.697838.697838 lmp.py:767]   Expert 11 |     38 | CPU
DEBUG 01-07 10:13:59.697289.697289 lmp.py:767]   Expert 56 |     60 | CPU
DEBUG 01-07 10:13:59.697978.697978 lmp.py:767]   Expert 54 |     79 | CPU
DEBUG 01-07 10:13:59.697668.697668 lmp.py:767]   Expert  7 |     92 | CPU
DEBUG 01-07 10:13:59.697880.697880 lmp.py:767]   Expert 47 |     92 | CPU
DEBUG 01-07 10:13:59.697331.697331 lmp.py:767]   Expert 62 |     95 | CPU
DEBUG 01-07 10:13:59.697543.697543 lmp.py:767]   Expert 51 |     98 | CPU
DEBUG 01-07 10:13:59.697186.697186 lmp.py:767]   Expert 60 |    106 | CPU
DEBUG 01-07 10:13:59.697829.697829 lmp.py:767]   Expert 41 |    107 | CPU
DEBUG 01-07 10:13:59.697996.697996 lmp.py:767]   Expert 52 |    110 | CPU
DEBUG 01-07 10:13:59.697639.697639 lmp.py:767]   Expert 22 |    114 | CPU
DEBUG 01-07 10:13:59.697805.697805 lmp.py:767]   Expert 53 |    114 | CPU
DEBUG 01-07 10:13:59.697494.697494 lmp.py:767]   Expert  1 |    125 | CPU
DEBUG 01-07 10:13:59.697945.697945 lmp.py:767]   Expert  6 |    127 | CPU
DEBUG 01-07 10:13:59.697634.697634 lmp.py:767]   Expert  8 |    129 | CPU
DEBUG 01-07 10:13:59.697847.697847 lmp.py:767]   Expert 32 |    129 | CPU
DEBUG 01-07 10:13:59.697821.697821 lmp.py:767]   Expert 48 |    129 | CPU
DEBUG 01-07 10:13:59.697179.697179 lmp.py:767]   Expert  2 |    130 | GPU1(cuda:2)
DEBUG 01-07 10:13:59.697537.697537 lmp.py:767]   Expert 27 |    137 | GPU0(cuda:1)
DEBUG 01-07 10:13:59.697895.697895 lmp.py:767]   Expert 35 |    141 | GPU0(cuda:1)
DEBUG 01-07 10:13:59.697254.697254 lmp.py:767]   Expert 39 |    141 | GPU1(cuda:2)
DEBUG 01-07 10:13:59.697135.697135 lmp.py:767]   Expert 23 |    144 | GPU1(cuda:2)
DEBUG 01-07 10:13:59.697016.697016 lmp.py:767]   Expert 26 |    145 | GPU0(cuda:1)
DEBUG 01-07 10:13:59.697898.697898 lmp.py:767]   Expert 50 |    147 | GPU0(cuda:1)
DEBUG 01-07 10:13:59.697541.697541 lmp.py:767]   Expert 59 |    147 | GPU1(cuda:2)
DEBUG 01-07 10:13:59.697468.697468 lmp.py:767]   Expert 14 |    154 | GPU1(cuda:2)
DEBUG 01-07 10:13:59.697158.697158 lmp.py:767]   Expert 46 |    168 | GPU0(cuda:1)
DEBUG 01-07 10:13:59.697085.697085 lmp.py:767]   Expert 38 |    170 | GPU1(cuda:2)
DEBUG 01-07 10:13:59.697490.697490 lmp.py:767]   Expert  0 |    171 | GPU1(cuda:2)
DEBUG 01-07 10:13:59.697179.697179 lmp.py:767]   Expert 24 |    171 | GPU0(cuda:1)
DEBUG 01-07 10:13:59.697345.697345 lmp.py:767]   Expert 34 |    173 | GPU0(cuda:1)
DEBUG 01-07 10:13:59.697512.697512 lmp.py:767]   Expert  4 |    176 | GPU1(cuda:2)
DEBUG 01-07 10:13:59.697631.697631 lmp.py:767]   Expert 40 |    178 | GPU1(cuda:2)
DEBUG 01-07 10:13:59.697274.697274 lmp.py:767]   Expert 49 |    178 | GPU0(cuda:1)
DEBUG 01-07 10:13:59.697679.697679 lmp.py:767]   Expert 63 |    183 | GPU0(cuda:1)
DEBUG 01-07 10:13:59.697083.697083 lmp.py:767]   Expert  5 |    187 | GPU1(cuda:2)
DEBUG 01-07 10:13:59.697250.697250 lmp.py:767]   Expert 13 |    195 | GPU1(cuda:2)
DEBUG 01-07 10:13:59.697939.697939 lmp.py:767]   Expert 19 |    195 | GPU0(cuda:1)
DEBUG 01-07 10:13:59.697867.697867 lmp.py:767]   Expert 43 |    199 | GPU0(cuda:1)
DEBUG 01-07 10:13:59.697318.697318 lmp.py:767]   Expert 29 |    203 | GPU1(cuda:2)
DEBUG 01-07 10:13:59.698245.698245 lmp.py:767]   Expert 57 |    205 | GPU0(cuda:1)
DEBUG 01-07 10:13:59.698173.698173 lmp.py:767]   Expert 61 |    209 | GPU1(cuda:2)
DEBUG 01-07 10:13:59.698101.698101 lmp.py:767]   Expert 33 |    224 | GPU0(cuda:1)
DEBUG 01-07 10:13:59.698552.698552 lmp.py:767]   Expert 31 |    230 | GPU1(cuda:2)
DEBUG 01-07 10:13:59.698479.698479 lmp.py:767]   Expert 16 |    247 | GPU0(cuda:1)
DEBUG 01-07 10:13:59.698169.698169 lmp.py:767]   Expert 20 |    248 | GPU1(cuda:2)
DEBUG 01-07 10:13:59.698096.698096 lmp.py:767]   Expert 37 |    253 | GPU0(cuda:1)
DEBUG 01-07 10:13:59.698786.698786 lmp.py:767]   Expert  3 |    254 | GPU1(cuda:2)
DEBUG 01-07 10:13:59.698713.698713 lmp.py:767]   Expert 15 |    260 | GPU0(cuda:1)
DEBUG 01-07 10:13:59.698118.698118 lmp.py:767]   Expert 36 |    273 | GPU1(cuda:2)
DEBUG 01-07 10:13:59.698522.698522 lmp.py:767]   Expert 18 |    278 | GPU0(cuda:1)
DEBUG 01-07 10:13:59.698927.698927 lmp.py:767]   Expert 12 |    289 | GPU1(cuda:2)
DEBUG 01-07 10:13:59.698332.698332 lmp.py:767]   Expert 28 |    304 | GPU0(cuda:1)
DEBUG 01-07 10:13:59.698451.698451 lmp.py:767]   Expert 17 |    305 | GPU1(cuda:2)
DEBUG 01-07 10:13:59.698094.698094 lmp.py:767]   Expert 55 |    306 | GPU0(cuda:1)
DEBUG 01-07 10:13:59.698214.698214 lmp.py:767]   Expert 30 |    314 | GPU1(cuda:2)
DEBUG 01-07 10:13:59.698096.698096 lmp.py:767]   Expert 25 |    318 | GPU0(cuda:1)
DEBUG 01-07 10:13:59.698215.698215 lmp.py:767]   Expert 58 |    339 | GPU1(cuda:2)
DEBUG 01-07 10:13:59.698097.698097 lmp.py:767]   Expert 10 |    363 | GPU0(cuda:1)
DEBUG 01-07 10:13:59.698455.698455 lmp.py:767]   Expert 45 |    388 | GPU1(cuda:2)
DEBUG 01-07 10:13:59.698336.698336 lmp.py:767]   Expert 21 |    392 | GPU1(cuda:2)
DEBUG 01-07 10:13:59.698218.698218 lmp.py:767]   Expert 42 |    648 | GPU0(cuda:1)
DEBUG 01-07 10:13:59.698145.698145 lmp.py:769] 
DEBUG 01-07 10:13:59.698145.698145 lmp.py:769]   Device Token Distribution:
DEBUG 01-07 10:13:59.698027.698027 lmp.py:770]   CPU:   1808 tokens
DEBUG 01-07 10:13:59.698862.698862 lmp.py:774]   cuda:1:   5243 tokens (22 experts)
DEBUG 01-07 10:13:59.698697.698697 lmp.py:774]   cuda:2:   5237 tokens (23 experts)
DEBUG 01-07 10:13:59.698340.698340 lmp.py:775]   Total GPU:  10480 tokens
DEBUG 01-07 10:13:59.698745.698745 lmp.py:776] ============================================================
DEBUG 01-07 10:13:59.698745.698745 lmp.py:776] 
DEBUG 01-07 10:13:59.698063.698063 cuda_h.py:19] end experts_map_get cost 0.001752614974975586 seconds
DEBUG 01-07 10:13:59.698660.698660 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model_multi_device
DEBUG 01-07 10:13:59.698483.698483 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 10:13:59.698148.698148 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 10:13:59.698515.698515 cuda_h.py:19] end allocate_cuda_memory cost 0.0002384185791015625 seconds
DEBUG 01-07 10:13:59.699895.699895 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 10:13:59.699459.699459 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 10:13:59.699791.699791 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 10:13:59.699679.699679 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, ce49095a-4701-4568-b592-14ce99113c73
DEBUG 01-07 10:13:59.699485.699485 client.py:106] call stub.LoadModelAsync
INFO 01-07 10:13:59.699781.699781 client.py:127] Model loaded
DEBUG 01-07 10:13:59.699562.699562 cuda_h.py:19] end sllm_worker_task cost 0.008750438690185547 seconds
INFO 01-07 10:13:59.699543.699543 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, ce49095a-4701-4568-b592-14ce99113c73
DEBUG 01-07 10:13:59.700618.700618 cuda_h.py:19] end load_into_gpu_async cost 0.0009932518005371094 seconds
DEBUG 01-07 10:13:59.700175.700175 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 10:13:59.700461.700461 cuda_h.py:19] end restore_tensors2 cost 0.00022149085998535156 seconds
DEBUG 01-07 10:13:59.700416.700416 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0017542839050292969 seconds
DEBUG 01-07 10:13:59.702411.702411 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 10:13:59.702627.702627 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 10:13:59.702536.702536 cuda_h.py:19] end allocate_cuda_memory cost 0.00021195411682128906 seconds
DEBUG 01-07 10:13:59.702518.702518 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 10:13:59.702652.702652 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 10:13:59.702123.702123 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 10:13:59.702534.702534 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 7fe0ff1e-eb1c-43e1-9adf-767d8cc72cdc
DEBUG 01-07 10:13:59.702896.702896 client.py:106] call stub.LoadModelAsync
INFO 01-07 10:13:59.703285.703285 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 7fe0ff1e-eb1c-43e1-9adf-767d8cc72cdc
DEBUG 01-07 10:13:59.703492.703492 cuda_h.py:19] end load_into_gpu_async cost 0.0009684562683105469 seconds
DEBUG 01-07 10:13:59.703334.703334 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 10:13:59.703931.703931 cuda_h.py:19] end restore_tensors2 cost 0.00020575523376464844 seconds
DEBUG 01-07 10:13:59.703793.703793 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0016741752624511719 seconds
DEBUG 01-07 10:13:59.705611.705611 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model_multi_device cost 0.007205486297607422 seconds
DEBUG 01-07 10:13:59.705672.705672 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-07 10:13:59.705919.705919 lmp.py:816] 
DEBUG 01-07 10:13:59.705919.705919 lmp.py:816]   Computing 19 experts on CPU...
DEBUG 01-07 10:13:59.705802.705802 cuda_h.py:19] end cpu_experts_submit cost 0.00010395050048828125 seconds
DEBUG 01-07 10:13:59.705690.705690 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-07 10:13:59.715076.715076 mlpmodule.py:749] group tensors cost 0.009808063507080078 s
DEBUG 01-07 10:13:59.717607.717607 mlpmodule.py:787] pad cost 0.0009515285491943359 s
DEBUG 01-07 10:13:59.717829.717829 mlpmodule.py:793] create cpu tensor cost 3.981590270996094e-05 s
DEBUG 01-07 10:13:59.717394.717394 mlpmodule.py:798] move to cpu cost 3.0994415283203125e-05 s
DEBUG 01-07 10:13:59.728603.728603 mlpmodule.py:812] group_w3: shape=torch.Size([19, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=54788096
DEBUG 01-07 10:13:59.728549.728549 mlpmodule.py:813] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-07 10:13:59.728169.728169 mlpmodule.py:818] group_w3 first element: 0.00066375732421875
WARNING 01-07 10:13:59.728041.728041 mlpmodule.py:828] start einsum2
DEBUG 01-07 10:13:59.747803.747803 mlpmodule.py:838] group einsum cost 0.030138254165649414 s
DEBUG 01-07 10:13:59.748332.748332 mlpmodule.py:846] cpy2cputensor cost 0.0003681182861328125 s
DEBUG 01-07 10:13:59.751445.751445 cuda_h.py:19] end wait_cetm_experts cost 0.04503583908081055 seconds
DEBUG 01-07 10:13:59.751507.751507 cuda_h.py:10] start gpu_sexperts
DEBUG 01-07 10:13:59.751379.751379 cuda_h.py:19] end gpu_sexperts cost 0.0004961490631103516 seconds
DEBUG 01-07 10:13:59.751408.751408 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-07 10:13:59.751396.751396 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.2411346435546875e-05 seconds
DEBUG 01-07 10:13:59.751338.751338 cuda_h.py:10] start wait_experts_multi_device
INFO 01-07 10:13:59.751001.751001 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, ce49095a-4701-4568-b592-14ce99113c73
INFO 01-07 10:13:59.752548.752548 client.py:127] Model loaded
INFO 01-07 10:13:59.752000.752000 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 7fe0ff1e-eb1c-43e1-9adf-767d8cc72cdc
INFO 01-07 10:13:59.753066.753066 client.py:127] Model loaded
DEBUG 01-07 10:13:59.753942.753942 cuda_h.py:19] end wait_experts_multi_device cost 0.0013980865478515625 seconds
DEBUG 01-07 10:13:59.753552.753552 cuda_h.py:10] start gpu_experts_multi_device
DEBUG 01-07 10:13:59.753898.753898 lmp.py:867]   Computing 23 experts on cuda:2...
DEBUG 01-07 10:13:59.754234.754234 mlpmodule.py:533] gpu group tensors cost 0.00046706199645996094 s
DEBUG 01-07 10:13:59.755972.755972 mlpmodule.py:566] gpu pad cost 0.0012214183807373047 s
DEBUG 01-07 10:13:59.756787.756787 mlpmodule.py:584] gpu group einsum cost 0.0005359649658203125 s
DEBUG 01-07 10:13:59.758967.758967 mlpmodule.py:656] gpu experts func einsum cost 0.0043790340423583984 s
DEBUG 01-07 10:13:59.758625.758625 lmp.py:867]   Computing 22 experts on cuda:1...
DEBUG 01-07 10:13:59.759199.759199 mlpmodule.py:533] gpu group tensors cost 0.00042939186096191406 s
DEBUG 01-07 10:13:59.760700.760700 mlpmodule.py:707]  experts func einsum cost 0.05417323112487793 s
DEBUG 01-07 10:13:59.760345.760345 mlpmodule.py:566] gpu pad cost 0.001346588134765625 s
DEBUG 01-07 10:13:59.761820.761820 mlpmodule.py:584] gpu group einsum cost 0.0004432201385498047 s
DEBUG 01-07 10:13:59.763228.763228 mlpmodule.py:656] gpu experts func einsum cost 0.0042781829833984375 s
DEBUG 01-07 10:13:59.763635.763635 cuda_h.py:19] end gpu_experts_multi_device cost 0.009968996047973633 seconds
DEBUG 01-07 10:13:59.763698.763698 cuda_h.py:19] end layer_moe_generate_multi_device_21 cost 0.06733012199401855 seconds
DEBUG 01-07 10:13:59.763421.763421 lmp.py:194] -------------------------------- end prefill layer 21 --------------------------------
DEBUG 01-07 10:13:59.763383.763383 lmp.py:153] -------------------------------- start prefill layer 22 --------------------------------
DEBUG 01-07 10:13:59.763609.763609 cuda_h.py:10] start start_load_qkvogn_s_weight_l_23
DEBUG 01-07 10:13:59.763372.763372 cuda_h.py:10] start start_load_qkvogn_s_weight_l_23
DEBUG 01-07 10:13:59.763062.763062 cuda_h.py:19] end start_load_qkvogn_s_weight_l_23 cost 2.5987625122070312e-05 seconds
DEBUG 01-07 10:13:59.763242.763242 cuda_h.py:19] end start_load_qkvogn_s_weight_l_23 cost 5.650520324707031e-05 seconds
DEBUG 01-07 10:13:59.763031.763031 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-07 10:13:59.763953.763953 cuda_h.py:10] start sllm_worker_task
DEBUG 01-07 10:13:59.763101.763101 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 10:13:59.763930.763930 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 10:13:59.764080.764080 cuda_h.py:19] end allocate_cuda_memory cost 0.00027489662170410156 seconds
DEBUG 01-07 10:13:59.764196.764196 mlpmodule.py:367] cuda:1 cuda:1
DEBUG 01-07 10:13:59.764178.764178 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 10:13:59.764267.764267 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 10:13:59.764805.764805 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 10:13:59.764078.764078 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 6a5af0cc-ef6b-4a60-9e48-3163eb5d6703
DEBUG 01-07 10:13:59.764179.764179 client.py:106] call stub.LoadModelAsync
DEBUG 01-07 10:13:59.764580.764580 cuda_h.py:10] start self_attn
INFO 01-07 10:13:59.765916.765916 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 6a5af0cc-ef6b-4a60-9e48-3163eb5d6703
DEBUG 01-07 10:13:59.765415.765415 cuda_h.py:19] end load_into_gpu_async cost 0.0008466243743896484 seconds
DEBUG 01-07 10:13:59.765972.765972 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 10:13:59.765001.765001 cuda_h.py:19] end restore_tensors2 cost 6.67572021484375e-05 seconds
DEBUG 01-07 10:13:59.765042.765042 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0015764236450195312 seconds
INFO 01-07 10:13:59.765594.765594 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 6a5af0cc-ef6b-4a60-9e48-3163eb5d6703
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-07 10:13:59.768215.768215 cuda_h.py:19] end self_attn cost 0.003674030303955078 seconds
DEBUG 01-07 10:13:59.768192.768192 cuda_h.py:19] end iln_self_attn_paln cost 0.005180835723876953 seconds
DEBUG 01-07 10:13:59.769207.769207 cuda_h.py:10] start layer_moe_generate_multi_device_22
DEBUG 01-07 10:13:59.769585.769585 cuda_h.py:10] start gate
DEBUG 01-07 10:13:59.769442.769442 cuda_h.py:19] end gate cost 0.0006337165832519531 seconds
DEBUG 01-07 10:13:59.769603.769603 cuda_h.py:10] start experts_map_get
DEBUG 01-07 10:13:59.770093.770093 lmp.py:744] 
DEBUG 01-07 10:13:59.770093.770093 lmp.py:744] Expert Token Distribution & Multi-Device Allocation:
DEBUG 01-07 10:13:59.770233.770233 lmp.py:745]   Total experts: 64
DEBUG 01-07 10:13:59.770552.770552 lmp.py:746]   CPU experts: 19 (30%)
DEBUG 01-07 10:13:59.770056.770056 lmp.py:747]   GPU experts: 45 (70%)
DEBUG 01-07 10:13:59.770891.770891 lmp.py:748]   Number of GPU devices: 2
DEBUG 01-07 10:13:59.770772.770772 lmp.py:749] 
DEBUG 01-07 10:13:59.770772.770772 lmp.py:749]   Expert ID | Tokens | Device
DEBUG 01-07 10:13:59.770892.770892 lmp.py:750]   -----------------------------------
DEBUG 01-07 10:13:59.770211.770211 lmp.py:767]   Expert 25 |     15 | CPU
DEBUG 01-07 10:13:59.770569.770569 lmp.py:767]   Expert 48 |     32 | CPU
DEBUG 01-07 10:13:59.770973.770973 lmp.py:767]   Expert 45 |     35 | CPU
DEBUG 01-07 10:13:59.770378.770378 lmp.py:767]   Expert  9 |     61 | CPU
DEBUG 01-07 10:13:59.770782.770782 lmp.py:767]   Expert  0 |     84 | CPU
DEBUG 01-07 10:13:59.770710.770710 lmp.py:767]   Expert 54 |     84 | CPU
DEBUG 01-07 10:13:59.770876.770876 lmp.py:767]   Expert 20 |     86 | CPU
DEBUG 01-07 10:13:59.770804.770804 lmp.py:767]   Expert 57 |     87 | CPU
DEBUG 01-07 10:13:59.770732.770732 lmp.py:767]   Expert 43 |     89 | CPU
DEBUG 01-07 10:13:59.770852.770852 lmp.py:767]   Expert  6 |     90 | CPU
DEBUG 01-07 10:13:59.770495.770495 lmp.py:767]   Expert 47 |     94 | CPU
DEBUG 01-07 10:13:59.770137.770137 lmp.py:767]   Expert 36 |     95 | CPU
DEBUG 01-07 10:13:59.770019.770019 lmp.py:767]   Expert 62 |    100 | CPU
DEBUG 01-07 10:13:59.770900.770900 lmp.py:767]   Expert 13 |    104 | CPU
DEBUG 01-07 10:13:59.770066.770066 lmp.py:767]   Expert 61 |    105 | CPU
DEBUG 01-07 10:13:59.770994.770994 lmp.py:767]   Expert 15 |    106 | CPU
DEBUG 01-07 10:13:59.770683.770683 lmp.py:767]   Expert 50 |    107 | CPU
DEBUG 01-07 10:13:59.770850.770850 lmp.py:767]   Expert 38 |    108 | CPU
DEBUG 01-07 10:13:59.770016.770016 lmp.py:767]   Expert  1 |    111 | CPU
DEBUG 01-07 10:13:59.770089.770089 lmp.py:767]   Expert 46 |    116 | GPU1(cuda:2)
DEBUG 01-07 10:13:59.770401.770401 lmp.py:767]   Expert 37 |    117 | GPU0(cuda:1)
DEBUG 01-07 10:13:59.770951.770951 lmp.py:767]   Expert 14 |    122 | GPU1(cuda:2)
DEBUG 01-07 10:13:59.770786.770786 lmp.py:767]   Expert 21 |    135 | GPU0(cuda:1)
DEBUG 01-07 10:13:59.770622.770622 lmp.py:767]   Expert  7 |    136 | GPU0(cuda:1)
DEBUG 01-07 10:13:59.770218.770218 lmp.py:767]   Expert 28 |    136 | GPU1(cuda:2)
DEBUG 01-07 10:13:59.770815.770815 lmp.py:767]   Expert 52 |    138 | GPU1(cuda:2)
DEBUG 01-07 10:13:59.770173.770173 lmp.py:767]   Expert 44 |    143 | GPU0(cuda:1)
DEBUG 01-07 10:13:59.770054.770054 lmp.py:767]   Expert 24 |    150 | GPU1(cuda:2)
DEBUG 01-07 10:13:59.770936.770936 lmp.py:767]   Expert 10 |    153 | GPU0(cuda:1)
DEBUG 01-07 10:13:59.770056.770056 lmp.py:767]   Expert 42 |    157 | GPU1(cuda:2)
DEBUG 01-07 10:13:59.770937.770937 lmp.py:767]   Expert 11 |    161 | GPU0(cuda:1)
DEBUG 01-07 10:13:59.770057.770057 lmp.py:767]   Expert 35 |    168 | GPU1(cuda:2)
DEBUG 01-07 10:13:59.770938.770938 lmp.py:767]   Expert  2 |    171 | GPU1(cuda:2)
DEBUG 01-07 10:13:59.770820.770820 lmp.py:767]   Expert 26 |    171 | GPU0(cuda:1)
DEBUG 01-07 10:13:59.770178.770178 lmp.py:767]   Expert 31 |    177 | GPU0(cuda:1)
DEBUG 01-07 10:13:59.770013.770013 lmp.py:767]   Expert  3 |    185 | GPU1(cuda:2)
DEBUG 01-07 10:13:59.770610.770610 lmp.py:767]   Expert 19 |    187 | GPU0(cuda:1)
DEBUG 01-07 10:13:59.771968.771968 lmp.py:767]   Expert 32 |    188 | GPU1(cuda:2)
DEBUG 01-07 10:13:59.771849.771849 lmp.py:767]   Expert 12 |    191 | GPU0(cuda:1)
DEBUG 01-07 10:13:59.771207.771207 lmp.py:767]   Expert 60 |    208 | GPU1(cuda:2)
DEBUG 01-07 10:13:59.771327.771327 lmp.py:767]   Expert 56 |    209 | GPU0(cuda:1)
DEBUG 01-07 10:13:59.771209.771209 lmp.py:767]   Expert 40 |    211 | GPU1(cuda:2)
DEBUG 01-07 10:13:59.771090.771090 lmp.py:767]   Expert 41 |    225 | GPU0(cuda:1)
DEBUG 01-07 10:13:59.771210.771210 lmp.py:767]   Expert 53 |    231 | GPU1(cuda:2)
DEBUG 01-07 10:13:59.771330.771330 lmp.py:767]   Expert  8 |    232 | GPU0(cuda:1)
DEBUG 01-07 10:13:59.771211.771211 lmp.py:767]   Expert 16 |    232 | GPU1(cuda:2)
DEBUG 01-07 10:13:59.771854.771854 lmp.py:767]   Expert 23 |    232 | GPU0(cuda:1)
DEBUG 01-07 10:13:59.771735.771735 lmp.py:767]   Expert 58 |    234 | GPU1(cuda:2)
DEBUG 01-07 10:13:59.771378.771378 lmp.py:767]   Expert 51 |    238 | GPU0(cuda:1)
DEBUG 01-07 10:13:59.771260.771260 lmp.py:767]   Expert 59 |    246 | GPU1(cuda:2)
DEBUG 01-07 10:13:59.771380.771380 lmp.py:767]   Expert  4 |    248 | GPU0(cuda:1)
DEBUG 01-07 10:13:59.771738.771738 lmp.py:767]   Expert 55 |    263 | GPU1(cuda:2)
DEBUG 01-07 10:13:59.771096.771096 lmp.py:767]   Expert 49 |    269 | GPU0(cuda:1)
DEBUG 01-07 10:13:59.771693.771693 lmp.py:767]   Expert 29 |    278 | GPU1(cuda:2)
DEBUG 01-07 10:13:59.771528.771528 lmp.py:767]   Expert 34 |    282 | GPU0(cuda:1)
DEBUG 01-07 10:13:59.771409.771409 lmp.py:767]   Expert 18 |    283 | GPU1(cuda:2)
DEBUG 01-07 10:13:59.771291.771291 lmp.py:767]   Expert 63 |    297 | GPU0(cuda:1)
DEBUG 01-07 10:13:59.771172.771172 lmp.py:767]   Expert 27 |    358 | GPU1(cuda:2)
DEBUG 01-07 10:13:59.771815.771815 lmp.py:767]   Expert 39 |    379 | GPU0(cuda:1)
DEBUG 01-07 10:13:59.771458.771458 lmp.py:767]   Expert 17 |    394 | GPU1(cuda:2)
DEBUG 01-07 10:13:59.771339.771339 lmp.py:767]   Expert 22 |    433 | GPU0(cuda:1)
DEBUG 01-07 10:13:59.771221.771221 lmp.py:767]   Expert 33 |    450 | GPU1(cuda:2)
DEBUG 01-07 10:13:59.771579.771579 lmp.py:767]   Expert 30 |    454 | GPU1(cuda:2)
DEBUG 01-07 10:13:59.771699.771699 lmp.py:767]   Expert  5 |    707 | GPU0(cuda:1)
DEBUG 01-07 10:13:59.771103.771103 lmp.py:769] 
DEBUG 01-07 10:13:59.771103.771103 lmp.py:769]   Device Token Distribution:
DEBUG 01-07 10:13:59.771177.771177 lmp.py:770]   CPU:   1593 tokens
DEBUG 01-07 10:13:59.771535.771535 lmp.py:774]   cuda:1:   5322 tokens (22 experts)
DEBUG 01-07 10:13:59.771178.771178 lmp.py:774]   cuda:2:   5373 tokens (23 experts)
DEBUG 01-07 10:13:59.771106.771106 lmp.py:775]   Total GPU:  10695 tokens
DEBUG 01-07 10:13:59.771272.771272 lmp.py:776] ============================================================
DEBUG 01-07 10:13:59.771272.771272 lmp.py:776] 
DEBUG 01-07 10:13:59.771398.771398 cuda_h.py:19] end experts_map_get cost 0.0017876625061035156 seconds
DEBUG 01-07 10:13:59.771280.771280 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model_multi_device
DEBUG 01-07 10:13:59.771672.771672 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 10:13:59.771861.771861 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 10:13:59.772902.772902 cuda_h.py:19] end allocate_cuda_memory cost 0.00020885467529296875 seconds
DEBUG 01-07 10:13:59.772805.772805 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 10:13:59.772846.772846 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 10:13:59.772417.772417 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 10:13:59.772066.772066 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, a19e8dc0-4d11-4063-a21c-b94b5fbbd35a
DEBUG 01-07 10:13:59.772071.772071 client.py:106] call stub.LoadModelAsync
INFO 01-07 10:13:59.772705.772705 client.py:127] Model loaded
DEBUG 01-07 10:13:59.772162.772162 cuda_h.py:19] end sllm_worker_task cost 0.008930683135986328 seconds
INFO 01-07 10:13:59.772808.772808 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, a19e8dc0-4d11-4063-a21c-b94b5fbbd35a
DEBUG 01-07 10:13:59.773552.773552 cuda_h.py:19] end load_into_gpu_async cost 0.000904083251953125 seconds
DEBUG 01-07 10:13:59.773586.773586 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 10:13:59.773853.773853 cuda_h.py:19] end restore_tensors2 cost 0.00024390220642089844 seconds
DEBUG 01-07 10:13:59.773146.773146 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0016608238220214844 seconds
DEBUG 01-07 10:13:59.775060.775060 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 10:13:59.775144.775144 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 10:13:59.775569.775569 cuda_h.py:19] end allocate_cuda_memory cost 0.00020694732666015625 seconds
DEBUG 01-07 10:13:59.775883.775883 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 10:13:59.775016.775016 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 10:13:59.775348.775348 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 10:13:59.775713.775713 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 727df2b2-5139-4f23-b4d3-befdc13dc42a
DEBUG 01-07 10:13:59.775651.775651 client.py:106] call stub.LoadModelAsync
INFO 01-07 10:13:59.776516.776516 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 727df2b2-5139-4f23-b4d3-befdc13dc42a
DEBUG 01-07 10:13:59.776346.776346 cuda_h.py:19] end load_into_gpu_async cost 0.0009431838989257812 seconds
DEBUG 01-07 10:13:59.776187.776187 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 10:13:59.776215.776215 cuda_h.py:19] end restore_tensors2 cost 0.00020694732666015625 seconds
DEBUG 01-07 10:13:59.776269.776269 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0016524791717529297 seconds
DEBUG 01-07 10:13:59.778603.778603 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model_multi_device cost 0.007059574127197266 seconds
DEBUG 01-07 10:13:59.778995.778995 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-07 10:13:59.778674.778674 lmp.py:816] 
DEBUG 01-07 10:13:59.778674.778674 lmp.py:816]   Computing 19 experts on CPU...
DEBUG 01-07 10:13:59.778940.778940 cuda_h.py:19] end cpu_experts_submit cost 0.0001068115234375 seconds
DEBUG 01-07 10:13:59.778259.778259 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-07 10:13:59.784153.784153 mlpmodule.py:749] group tensors cost 0.005404949188232422 s
DEBUG 01-07 10:13:59.786365.786365 mlpmodule.py:787] pad cost 0.0010821819305419922 s
DEBUG 01-07 10:13:59.786640.786640 mlpmodule.py:793] create cpu tensor cost 4.076957702636719e-05 s
DEBUG 01-07 10:13:59.786735.786735 mlpmodule.py:798] move to cpu cost 3.24249267578125e-05 s
DEBUG 01-07 10:13:59.796873.796873 mlpmodule.py:812] group_w3: shape=torch.Size([19, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=54788096
DEBUG 01-07 10:13:59.796939.796939 mlpmodule.py:813] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-07 10:13:59.796698.796698 mlpmodule.py:818] group_w3 first element: -0.018798828125
WARNING 01-07 10:13:59.796444.796444 mlpmodule.py:828] start einsum2
DEBUG 01-07 10:13:59.815771.815771 mlpmodule.py:838] group einsum cost 0.029474973678588867 s
DEBUG 01-07 10:13:59.816023.816023 mlpmodule.py:846] cpy2cputensor cost 0.0004000663757324219 s
DEBUG 01-07 10:13:59.819394.819394 cuda_h.py:19] end wait_cetm_experts cost 0.0401911735534668 seconds
DEBUG 01-07 10:13:59.819510.819510 cuda_h.py:10] start gpu_sexperts
DEBUG 01-07 10:13:59.819535.819535 cuda_h.py:19] end gpu_sexperts cost 0.0005018711090087891 seconds
DEBUG 01-07 10:13:59.819378.819378 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-07 10:13:59.819751.819751 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.574920654296875e-05 seconds
DEBUG 01-07 10:13:59.819169.819169 cuda_h.py:10] start wait_experts_multi_device
INFO 01-07 10:13:59.819978.819978 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, a19e8dc0-4d11-4063-a21c-b94b5fbbd35a
INFO 01-07 10:13:59.820512.820512 client.py:127] Model loaded
INFO 01-07 10:13:59.820587.820587 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 727df2b2-5139-4f23-b4d3-befdc13dc42a
INFO 01-07 10:13:59.821624.821624 client.py:127] Model loaded
DEBUG 01-07 10:13:59.821129.821129 cuda_h.py:19] end wait_experts_multi_device cost 0.0019397735595703125 seconds
DEBUG 01-07 10:13:59.821454.821454 cuda_h.py:10] start gpu_experts_multi_device
DEBUG 01-07 10:13:59.821708.821708 lmp.py:867]   Computing 23 experts on cuda:2...
DEBUG 01-07 10:13:59.823129.823129 mlpmodule.py:533] gpu group tensors cost 0.0004649162292480469 s
DEBUG 01-07 10:13:59.824544.824544 mlpmodule.py:566] gpu pad cost 0.0012629032135009766 s
DEBUG 01-07 10:13:59.825141.825141 mlpmodule.py:584] gpu group einsum cost 0.0005457401275634766 s
DEBUG 01-07 10:13:59.827619.827619 mlpmodule.py:656] gpu experts func einsum cost 0.0044097900390625 s
DEBUG 01-07 10:13:59.827774.827774 lmp.py:867]   Computing 22 experts on cuda:1...
DEBUG 01-07 10:13:59.828996.828996 mlpmodule.py:533] gpu group tensors cost 0.0004191398620605469 s
DEBUG 01-07 10:13:59.828532.828532 mlpmodule.py:707]  experts func einsum cost 0.049173593521118164 s
DEBUG 01-07 10:13:59.829102.829102 mlpmodule.py:566] gpu pad cost 0.0013148784637451172 s
DEBUG 01-07 10:13:59.829396.829396 mlpmodule.py:584] gpu group einsum cost 0.00041985511779785156 s
DEBUG 01-07 10:13:59.831759.831759 mlpmodule.py:656] gpu experts func einsum cost 0.004212141036987305 s
DEBUG 01-07 10:13:59.831920.831920 cuda_h.py:19] end gpu_experts_multi_device cost 0.009936809539794922 seconds
DEBUG 01-07 10:13:59.831837.831837 cuda_h.py:19] end layer_moe_generate_multi_device_22 cost 0.06289958953857422 seconds
DEBUG 01-07 10:13:59.832566.832566 lmp.py:194] -------------------------------- end prefill layer 22 --------------------------------
DEBUG 01-07 10:13:59.832760.832760 lmp.py:153] -------------------------------- start prefill layer 23 --------------------------------
DEBUG 01-07 10:13:59.832932.832932 cuda_h.py:10] start start_load_qkvogn_s_weight_l_24
DEBUG 01-07 10:13:59.832450.832450 cuda_h.py:10] start start_load_qkvogn_s_weight_l_24
DEBUG 01-07 10:13:59.832101.832101 cuda_h.py:19] end start_load_qkvogn_s_weight_l_24 cost 3.123283386230469e-05 seconds
DEBUG 01-07 10:13:59.832296.832296 cuda_h.py:19] end start_load_qkvogn_s_weight_l_24 cost 0.00010824203491210938 seconds
DEBUG 01-07 10:13:59.832561.832561 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-07 10:13:59.832874.832874 mlpmodule.py:367] cuda:1 cuda:1
DEBUG 01-07 10:13:59.832294.832294 cuda_h.py:10] start sllm_worker_task
DEBUG 01-07 10:13:59.832574.832574 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 10:13:59.832781.832781 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 10:13:59.832785.832785 cuda_h.py:19] end allocate_cuda_memory cost 0.00028443336486816406 seconds
DEBUG 01-07 10:13:59.833616.833616 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 10:13:59.833140.833140 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 10:13:59.833724.833724 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 10:13:59.833712.833712 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, dc9e5430-8ab8-4dbc-81f0-e8128513f436
DEBUG 01-07 10:13:59.833622.833622 client.py:106] call stub.LoadModelAsync
DEBUG 01-07 10:13:59.833040.833040 cuda_h.py:10] start self_attn
INFO 01-07 10:13:59.833469.833469 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, dc9e5430-8ab8-4dbc-81f0-e8128513f436
DEBUG 01-07 10:13:59.833636.833636 cuda_h.py:19] end load_into_gpu_async cost 0.0007882118225097656 seconds
DEBUG 01-07 10:13:59.833194.833194 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 10:13:59.834269.834269 cuda_h.py:19] end restore_tensors2 cost 6.437301635742188e-05 seconds
DEBUG 01-07 10:13:59.834833.834833 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0013918876647949219 seconds
INFO 01-07 10:13:59.834961.834961 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, dc9e5430-8ab8-4dbc-81f0-e8128513f436
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-07 10:13:59.837891.837891 cuda_h.py:19] end self_attn cost 0.0035855770111083984 seconds
DEBUG 01-07 10:13:59.837113.837113 cuda_h.py:19] end iln_self_attn_paln cost 0.004977226257324219 seconds
DEBUG 01-07 10:13:59.837035.837035 cuda_h.py:10] start layer_moe_generate_multi_device_23
DEBUG 01-07 10:13:59.837460.837460 cuda_h.py:10] start gate
DEBUG 01-07 10:13:59.838178.838178 cuda_h.py:19] end gate cost 0.0006363391876220703 seconds
DEBUG 01-07 10:13:59.838908.838908 cuda_h.py:10] start experts_map_get
DEBUG 01-07 10:13:59.838345.838345 lmp.py:744] 
DEBUG 01-07 10:13:59.838345.838345 lmp.py:744] Expert Token Distribution & Multi-Device Allocation:
DEBUG 01-07 10:13:59.838008.838008 lmp.py:745]   Total experts: 64
DEBUG 01-07 10:13:59.838088.838088 lmp.py:746]   CPU experts: 19 (30%)
DEBUG 01-07 10:13:59.838831.838831 lmp.py:747]   GPU experts: 45 (70%)
DEBUG 01-07 10:13:59.838189.838189 lmp.py:748]   Number of GPU devices: 2
DEBUG 01-07 10:13:59.838070.838070 lmp.py:749] 
DEBUG 01-07 10:13:59.838070.838070 lmp.py:749]   Expert ID | Tokens | Device
DEBUG 01-07 10:13:59.838952.838952 lmp.py:750]   -----------------------------------
DEBUG 01-07 10:13:59.838747.838747 lmp.py:767]   Expert  5 |     14 | CPU
DEBUG 01-07 10:13:59.838106.838106 lmp.py:767]   Expert 56 |     31 | CPU
DEBUG 01-07 10:13:59.838748.838748 lmp.py:767]   Expert 16 |     82 | CPU
DEBUG 01-07 10:13:59.838391.838391 lmp.py:767]   Expert 27 |     83 | CPU
DEBUG 01-07 10:13:59.838796.838796 lmp.py:767]   Expert 17 |     89 | CPU
DEBUG 01-07 10:13:59.838439.838439 lmp.py:767]   Expert 40 |     93 | CPU
DEBUG 01-07 10:13:59.838844.838844 lmp.py:767]   Expert 63 |     98 | CPU
DEBUG 01-07 10:13:59.838963.838963 lmp.py:767]   Expert 51 |    104 | CPU
DEBUG 01-07 10:13:59.838845.838845 lmp.py:767]   Expert 49 |    105 | CPU
DEBUG 01-07 10:13:59.838249.838249 lmp.py:767]   Expert 28 |    107 | CPU
DEBUG 01-07 10:13:59.838369.838369 lmp.py:767]   Expert 53 |    108 | CPU
DEBUG 01-07 10:13:59.838012.838012 lmp.py:767]   Expert  7 |    112 | CPU
DEBUG 01-07 10:13:59.839417.839417 lmp.py:767]   Expert 38 |    123 | CPU
DEBUG 01-07 10:13:59.839344.839344 lmp.py:767]   Expert 47 |    124 | CPU
DEBUG 01-07 10:13:59.839511.839511 lmp.py:767]   Expert 62 |    125 | CPU
DEBUG 01-07 10:13:59.839200.839200 lmp.py:767]   Expert 37 |    127 | CPU
DEBUG 01-07 10:13:59.839366.839366 lmp.py:767]   Expert 11 |    129 | CPU
DEBUG 01-07 10:13:59.839532.839532 lmp.py:767]   Expert 58 |    130 | CPU
DEBUG 01-07 10:13:59.839698.839698 lmp.py:767]   Expert 57 |    139 | CPU
DEBUG 01-07 10:13:59.839056.839056 lmp.py:767]   Expert 39 |    144 | GPU1(cuda:2)
DEBUG 01-07 10:13:59.839892.839892 lmp.py:767]   Expert 14 |    150 | GPU1(cuda:2)
DEBUG 01-07 10:13:59.839488.839488 lmp.py:767]   Expert 52 |    150 | GPU0(cuda:1)
DEBUG 01-07 10:13:59.839323.839323 lmp.py:767]   Expert  1 |    151 | GPU0(cuda:1)
DEBUG 01-07 10:13:59.839920.839920 lmp.py:767]   Expert 25 |    152 | GPU1(cuda:2)
DEBUG 01-07 10:13:59.839755.839755 lmp.py:767]   Expert 23 |    160 | GPU1(cuda:2)
DEBUG 01-07 10:13:59.839113.839113 lmp.py:767]   Expert 33 |    163 | GPU0(cuda:1)
DEBUG 01-07 10:13:59.839233.839233 lmp.py:767]   Expert 21 |    168 | GPU1(cuda:2)
DEBUG 01-07 10:13:59.839353.839353 lmp.py:767]   Expert  6 |    170 | GPU0(cuda:1)
DEBUG 01-07 10:13:59.839996.839996 lmp.py:767]   Expert 60 |    173 | GPU0(cuda:1)
DEBUG 01-07 10:13:59.839354.839354 lmp.py:767]   Expert 45 |    177 | GPU1(cuda:2)
DEBUG 01-07 10:13:59.839997.839997 lmp.py:767]   Expert 44 |    183 | GPU1(cuda:2)
DEBUG 01-07 10:13:59.839640.839640 lmp.py:767]   Expert 12 |    184 | GPU0(cuda:1)
DEBUG 01-07 10:13:59.839283.839283 lmp.py:767]   Expert 19 |    186 | GPU0(cuda:1)
DEBUG 01-07 10:13:59.839880.839880 lmp.py:767]   Expert  4 |    187 | GPU1(cuda:2)
DEBUG 01-07 10:13:59.839238.839238 lmp.py:767]   Expert 30 |    194 | GPU1(cuda:2)
DEBUG 01-07 10:13:59.839834.839834 lmp.py:767]   Expert 31 |    195 | GPU0(cuda:1)
DEBUG 01-07 10:13:59.839193.839193 lmp.py:767]   Expert 55 |    196 | GPU1(cuda:2)
DEBUG 01-07 10:13:59.839313.839313 lmp.py:767]   Expert  3 |    197 | GPU0(cuda:1)
DEBUG 01-07 10:13:59.839194.839194 lmp.py:767]   Expert 36 |    207 | GPU1(cuda:2)
DEBUG 01-07 10:13:59.839314.839314 lmp.py:767]   Expert  9 |    209 | GPU0(cuda:1)
DEBUG 01-07 10:13:59.839195.839195 lmp.py:767]   Expert  0 |    223 | GPU1(cuda:2)
DEBUG 01-07 10:13:59.839838.839838 lmp.py:767]   Expert 41 |    225 | GPU0(cuda:1)
DEBUG 01-07 10:13:59.839719.839719 lmp.py:767]   Expert 22 |    226 | GPU0(cuda:1)
DEBUG 01-07 10:13:59.839362.839362 lmp.py:767]   Expert 34 |    226 | GPU1(cuda:2)
DEBUG 01-07 10:13:59.839244.839244 lmp.py:767]   Expert 26 |    234 | GPU1(cuda:2)
DEBUG 01-07 10:13:59.839602.839602 lmp.py:767]   Expert 43 |    238 | GPU0(cuda:1)
DEBUG 01-07 10:13:59.839960.839960 lmp.py:767]   Expert 54 |    239 | GPU0(cuda:1)
DEBUG 01-07 10:13:59.839557.839557 lmp.py:767]   Expert 18 |    251 | GPU1(cuda:2)
DEBUG 01-07 10:13:59.839154.839154 lmp.py:767]   Expert 50 |    251 | GPU0(cuda:1)
DEBUG 01-07 10:13:59.839750.839750 lmp.py:767]   Expert 59 |    251 | GPU1(cuda:2)
DEBUG 01-07 10:13:59.839585.839585 lmp.py:767]   Expert 13 |    258 | GPU0(cuda:1)
DEBUG 01-07 10:13:59.839944.839944 lmp.py:767]   Expert 15 |    259 | GPU1(cuda:2)
DEBUG 01-07 10:13:59.839825.839825 lmp.py:767]   Expert 20 |    259 | GPU1(cuda:2)
DEBUG 01-07 10:13:59.839706.839706 lmp.py:767]   Expert 42 |    263 | GPU0(cuda:1)
DEBUG 01-07 10:13:59.839349.839349 lmp.py:767]   Expert 29 |    264 | GPU1(cuda:2)
DEBUG 01-07 10:13:59.839231.839231 lmp.py:767]   Expert 24 |    265 | GPU0(cuda:1)
DEBUG 01-07 10:13:59.839112.839112 lmp.py:767]   Expert 61 |    272 | GPU1(cuda:2)
DEBUG 01-07 10:13:59.839523.839523 lmp.py:767]   Expert 35 |    279 | GPU0(cuda:1)
DEBUG 01-07 10:13:59.839405.839405 lmp.py:767]   Expert 32 |    307 | GPU0(cuda:1)
DEBUG 01-07 10:13:59.839286.839286 lmp.py:767]   Expert  2 |    328 | GPU1(cuda:2)
DEBUG 01-07 10:13:59.839691.839691 lmp.py:767]   Expert  8 |    340 | GPU0(cuda:1)
DEBUG 01-07 10:13:59.839334.839334 lmp.py:767]   Expert 10 |    342 | GPU1(cuda:2)
DEBUG 01-07 10:13:59.839500.839500 lmp.py:767]   Expert 46 |    427 | GPU1(cuda:2)
DEBUG 01-07 10:13:59.839428.839428 lmp.py:767]   Expert 48 |    442 | GPU0(cuda:1)
DEBUG 01-07 10:13:59.839402.839402 lmp.py:769] 
DEBUG 01-07 10:13:59.839402.839402 lmp.py:769]   Device Token Distribution:
DEBUG 01-07 10:13:59.839091.839091 lmp.py:770]   CPU:   1923 tokens
DEBUG 01-07 10:13:59.839972.839972 lmp.py:774]   cuda:1:   5111 tokens (22 experts)
DEBUG 01-07 10:13:59.839662.839662 lmp.py:774]   cuda:2:   5254 tokens (23 experts)
DEBUG 01-07 10:13:59.840351.840351 lmp.py:775]   Total GPU:  10365 tokens
DEBUG 01-07 10:13:59.840040.840040 lmp.py:776] ============================================================
DEBUG 01-07 10:13:59.840040.840040 lmp.py:776] 
DEBUG 01-07 10:13:59.840405.840405 cuda_h.py:19] end experts_map_get cost 0.00177764892578125 seconds
DEBUG 01-07 10:13:59.840525.840525 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model_multi_device
DEBUG 01-07 10:13:59.840109.840109 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 10:13:59.840159.840159 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 10:13:59.840286.840286 cuda_h.py:19] end allocate_cuda_memory cost 0.00020384788513183594 seconds
DEBUG 01-07 10:13:59.840984.840984 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 10:13:59.840031.840031 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 10:13:59.840556.840556 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 10:13:59.840397.840397 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 3fec9bc0-77b4-4157-9914-233e9fa3398f
DEBUG 01-07 10:13:59.840641.840641 client.py:106] call stub.LoadModelAsync
INFO 01-07 10:13:59.840520.840520 client.py:127] Model loaded
DEBUG 01-07 10:13:59.841877.841877 cuda_h.py:19] end sllm_worker_task cost 0.008651971817016602 seconds
INFO 01-07 10:13:59.841055.841055 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 3fec9bc0-77b4-4157-9914-233e9fa3398f
DEBUG 01-07 10:13:59.841560.841560 cuda_h.py:19] end load_into_gpu_async cost 0.0009496212005615234 seconds
DEBUG 01-07 10:13:59.841832.841832 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 10:13:59.841563.841563 cuda_h.py:19] end restore_tensors2 cost 0.00023317337036132812 seconds
DEBUG 01-07 10:13:59.841094.841094 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0016875267028808594 seconds
DEBUG 01-07 10:13:59.843678.843678 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 10:13:59.843365.843365 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 10:13:59.844526.844526 cuda_h.py:19] end allocate_cuda_memory cost 0.0002219676971435547 seconds
DEBUG 01-07 10:13:59.844461.844461 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 10:13:59.844071.844071 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 10:13:59.844496.844496 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 10:13:59.844623.844623 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, b7110f8d-6bf3-4a50-828b-724258c1fd80
DEBUG 01-07 10:13:59.844177.844177 client.py:106] call stub.LoadModelAsync
INFO 01-07 10:13:59.845717.845717 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, b7110f8d-6bf3-4a50-828b-724258c1fd80
DEBUG 01-07 10:13:59.845640.845640 cuda_h.py:19] end load_into_gpu_async cost 0.0009438991546630859 seconds
DEBUG 01-07 10:13:59.845720.845720 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 10:13:59.845078.845078 cuda_h.py:19] end restore_tensors2 cost 0.00020503997802734375 seconds
DEBUG 01-07 10:13:59.845848.845848 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.001657247543334961 seconds
DEBUG 01-07 10:13:59.847167.847167 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model_multi_device cost 0.007084369659423828 seconds
DEBUG 01-07 10:13:59.847321.847321 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-07 10:13:59.847045.847045 lmp.py:816] 
DEBUG 01-07 10:13:59.847045.847045 lmp.py:816]   Computing 19 experts on CPU...
DEBUG 01-07 10:13:59.847696.847696 cuda_h.py:19] end cpu_experts_submit cost 0.00010776519775390625 seconds
DEBUG 01-07 10:13:59.847061.847061 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-07 10:13:59.857812.857812 mlpmodule.py:749] group tensors cost 0.009836196899414062 s
DEBUG 01-07 10:13:59.858097.858097 mlpmodule.py:787] pad cost 0.0009531974792480469 s
DEBUG 01-07 10:13:59.859411.859411 mlpmodule.py:793] create cpu tensor cost 3.790855407714844e-05 s
DEBUG 01-07 10:13:59.859023.859023 mlpmodule.py:798] move to cpu cost 2.956390380859375e-05 s
DEBUG 01-07 10:13:59.869479.869479 mlpmodule.py:812] group_w3: shape=torch.Size([19, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=54788096
DEBUG 01-07 10:13:59.869210.869210 mlpmodule.py:813] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-07 10:13:59.869532.869532 mlpmodule.py:818] group_w3 first element: 0.04248046875
WARNING 01-07 10:13:59.869835.869835 mlpmodule.py:828] start einsum2
DEBUG 01-07 10:13:59.887222.887222 mlpmodule.py:838] group einsum cost 0.02882671356201172 s
DEBUG 01-07 10:13:59.888402.888402 mlpmodule.py:846] cpy2cputensor cost 0.0004324913024902344 s
DEBUG 01-07 10:13:59.891302.891302 cuda_h.py:19] end wait_cetm_experts cost 0.04374432563781738 seconds
DEBUG 01-07 10:13:59.891371.891371 cuda_h.py:10] start gpu_sexperts
DEBUG 01-07 10:13:59.891151.891151 cuda_h.py:19] end gpu_sexperts cost 0.0004961490631103516 seconds
DEBUG 01-07 10:13:59.891848.891848 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-07 10:13:59.891175.891175 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.3126602172851562e-05 seconds
DEBUG 01-07 10:13:59.891070.891070 cuda_h.py:10] start wait_experts_multi_device
INFO 01-07 10:13:59.891925.891925 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 3fec9bc0-77b4-4157-9914-233e9fa3398f
INFO 01-07 10:13:59.892843.892843 client.py:127] Model loaded
INFO 01-07 10:13:59.892103.892103 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, b7110f8d-6bf3-4a50-828b-724258c1fd80
INFO 01-07 10:13:59.893209.893209 client.py:127] Model loaded
DEBUG 01-07 10:13:59.893892.893892 cuda_h.py:19] end wait_experts_multi_device cost 0.001382589340209961 seconds
DEBUG 01-07 10:13:59.893264.893264 cuda_h.py:10] start gpu_experts_multi_device
DEBUG 01-07 10:13:59.893610.893610 lmp.py:867]   Computing 23 experts on cuda:2...
DEBUG 01-07 10:13:59.894052.894052 mlpmodule.py:533] gpu group tensors cost 0.0004665851593017578 s
DEBUG 01-07 10:13:59.895857.895857 mlpmodule.py:566] gpu pad cost 0.0012350082397460938 s
DEBUG 01-07 10:13:59.896488.896488 mlpmodule.py:584] gpu group einsum cost 0.0005664825439453125 s
DEBUG 01-07 10:13:59.898238.898238 mlpmodule.py:656] gpu experts func einsum cost 0.004430294036865234 s
DEBUG 01-07 10:13:59.898704.898704 lmp.py:867]   Computing 22 experts on cuda:1...
DEBUG 01-07 10:13:59.899701.899701 mlpmodule.py:533] gpu group tensors cost 0.0004229545593261719 s
DEBUG 01-07 10:13:59.899658.899658 mlpmodule.py:707]  experts func einsum cost 0.052327871322631836 s
DEBUG 01-07 10:13:59.900144.900144 mlpmodule.py:566] gpu pad cost 0.0013170242309570312 s
DEBUG 01-07 10:13:59.901466.901466 mlpmodule.py:584] gpu group einsum cost 0.00043773651123046875 s
DEBUG 01-07 10:13:59.903425.903425 mlpmodule.py:656] gpu experts func einsum cost 0.004257678985595703 s
DEBUG 01-07 10:13:59.903647.903647 cuda_h.py:19] end gpu_experts_multi_device cost 0.010014772415161133 seconds
DEBUG 01-07 10:13:59.903140.903140 cuda_h.py:19] end layer_moe_generate_multi_device_23 cost 0.06598830223083496 seconds
DEBUG 01-07 10:13:59.903784.903784 lmp.py:194] -------------------------------- end prefill layer 23 --------------------------------
DEBUG 01-07 10:13:59.903991.903991 lmp.py:153] -------------------------------- start prefill layer 24 --------------------------------
DEBUG 01-07 10:13:59.903641.903641 cuda_h.py:10] start start_load_qkvogn_s_weight_l_25
DEBUG 01-07 10:13:59.903397.903397 cuda_h.py:10] start start_load_qkvogn_s_weight_l_25
DEBUG 01-07 10:13:59.903803.903803 cuda_h.py:19] end start_load_qkvogn_s_weight_l_25 cost 2.7418136596679688e-05 seconds
DEBUG 01-07 10:13:59.903982.903982 cuda_h.py:19] end start_load_qkvogn_s_weight_l_25 cost 5.817413330078125e-05 seconds
DEBUG 01-07 10:13:59.903771.903771 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-07 10:13:59.904223.904223 cuda_h.py:10] start sllm_worker_task
DEBUG 01-07 10:13:59.904392.904392 mlpmodule.py:367] cuda:1 cuda:1
DEBUG 01-07 10:13:59.904870.904870 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 10:13:59.904681.904681 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 10:13:59.904309.904309 cuda_h.py:19] end allocate_cuda_memory cost 0.0003209114074707031 seconds
DEBUG 01-07 10:13:59.904881.904881 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 10:13:59.904067.904067 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 10:13:59.904983.904983 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 10:13:59.904778.904778 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, a5dcc71a-10e1-4dc4-9c5c-fa9f2d5d46bf
DEBUG 01-07 10:13:59.904549.904549 client.py:106] call stub.LoadModelAsync
DEBUG 01-07 10:13:59.905897.905897 cuda_h.py:10] start self_attn
INFO 01-07 10:13:59.905875.905875 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, a5dcc71a-10e1-4dc4-9c5c-fa9f2d5d46bf
DEBUG 01-07 10:13:59.905896.905896 cuda_h.py:19] end load_into_gpu_async cost 0.0008208751678466797 seconds
DEBUG 01-07 10:13:59.905692.905692 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 10:13:59.905768.905768 cuda_h.py:19] end restore_tensors2 cost 6.604194641113281e-05 seconds
DEBUG 01-07 10:13:59.905093.905093 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0014486312866210938 seconds
INFO 01-07 10:13:59.905837.905837 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, a5dcc71a-10e1-4dc4-9c5c-fa9f2d5d46bf
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-07 10:13:59.908058.908058 cuda_h.py:19] end self_attn cost 0.0035707950592041016 seconds
DEBUG 01-07 10:13:59.909141.909141 cuda_h.py:19] end iln_self_attn_paln cost 0.005089759826660156 seconds
DEBUG 01-07 10:13:59.909633.909633 cuda_h.py:10] start layer_moe_generate_multi_device_24
DEBUG 01-07 10:13:59.909058.909058 cuda_h.py:10] start gate
DEBUG 01-07 10:13:59.909577.909577 cuda_h.py:19] end gate cost 0.0006299018859863281 seconds
DEBUG 01-07 10:13:59.909307.909307 cuda_h.py:10] start experts_map_get
DEBUG 01-07 10:13:59.910982.910982 lmp.py:744] 
DEBUG 01-07 10:13:59.910982.910982 lmp.py:744] Expert Token Distribution & Multi-Device Allocation:
DEBUG 01-07 10:13:59.910420.910420 lmp.py:745]   Total experts: 64
DEBUG 01-07 10:13:59.910739.910739 lmp.py:746]   CPU experts: 19 (30%)
DEBUG 01-07 10:13:59.910813.910813 lmp.py:747]   GPU experts: 45 (70%)
DEBUG 01-07 10:13:59.910979.910979 lmp.py:748]   Number of GPU devices: 2
DEBUG 01-07 10:13:59.910430.910430 lmp.py:749] 
DEBUG 01-07 10:13:59.910430.910430 lmp.py:749]   Expert ID | Tokens | Device
DEBUG 01-07 10:13:59.910119.910119 lmp.py:750]   -----------------------------------
DEBUG 01-07 10:13:59.910007.910007 lmp.py:767]   Expert 36 |     20 | CPU
DEBUG 01-07 10:13:59.910650.910650 lmp.py:767]   Expert 35 |     30 | CPU
DEBUG 01-07 10:13:59.910101.910101 lmp.py:767]   Expert 46 |     43 | CPU
DEBUG 01-07 10:13:59.910790.910790 lmp.py:767]   Expert 25 |     45 | CPU
DEBUG 01-07 10:13:59.910003.910003 lmp.py:767]   Expert 51 |     53 | CPU
DEBUG 01-07 10:13:59.910454.910454 lmp.py:767]   Expert 16 |     58 | CPU
DEBUG 01-07 10:13:59.910905.910905 lmp.py:767]   Expert  0 |     65 | CPU
DEBUG 01-07 10:13:59.910355.910355 lmp.py:767]   Expert 30 |     65 | CPU
DEBUG 01-07 10:13:59.910568.910568 lmp.py:767]   Expert 43 |     68 | CPU
DEBUG 01-07 10:13:59.910257.910257 lmp.py:767]   Expert 47 |     71 | CPU
DEBUG 01-07 10:13:59.910946.910946 lmp.py:767]   Expert 42 |     73 | CPU
DEBUG 01-07 10:13:59.910159.910159 lmp.py:767]   Expert 44 |     74 | CPU
DEBUG 01-07 10:13:59.910133.910133 lmp.py:767]   Expert 55 |     76 | CPU
DEBUG 01-07 10:13:59.910345.910345 lmp.py:767]   Expert 39 |     77 | CPU
DEBUG 01-07 10:13:59.910081.910081 lmp.py:767]   Expert  2 |     82 | CPU
DEBUG 01-07 10:13:59.910532.910532 lmp.py:767]   Expert  4 |    109 | CPU
DEBUG 01-07 10:13:59.910744.910744 lmp.py:767]   Expert 48 |    116 | CPU
DEBUG 01-07 10:13:59.910672.910672 lmp.py:767]   Expert  6 |    120 | CPU
DEBUG 01-07 10:13:59.910646.910646 lmp.py:767]   Expert 13 |    122 | CPU
DEBUG 01-07 10:13:59.910051.910051 lmp.py:767]   Expert 33 |    123 | GPU0(cuda:1)
DEBUG 01-07 10:13:59.910694.910694 lmp.py:767]   Expert 24 |    124 | GPU1(cuda:2)
DEBUG 01-07 10:13:59.910621.910621 lmp.py:767]   Expert 61 |    124 | GPU1(cuda:2)
DEBUG 01-07 10:13:59.910549.910549 lmp.py:767]   Expert 56 |    131 | GPU0(cuda:1)
DEBUG 01-07 10:13:59.910477.910477 lmp.py:767]   Expert 29 |    133 | GPU1(cuda:2)
DEBUG 01-07 10:13:59.910405.910405 lmp.py:767]   Expert 15 |    135 | GPU0(cuda:1)
DEBUG 01-07 10:13:59.910048.910048 lmp.py:767]   Expert 38 |    136 | GPU1(cuda:2)
DEBUG 01-07 10:13:59.910452.910452 lmp.py:767]   Expert  9 |    143 | GPU0(cuda:1)
DEBUG 01-07 10:13:59.910618.910618 lmp.py:767]   Expert  7 |    144 | GPU1(cuda:2)
DEBUG 01-07 10:13:59.910784.910784 lmp.py:767]   Expert 54 |    146 | GPU0(cuda:1)
DEBUG 01-07 10:13:59.910712.910712 lmp.py:767]   Expert 59 |    147 | GPU1(cuda:2)
DEBUG 01-07 10:13:59.910401.910401 lmp.py:767]   Expert 20 |    149 | GPU0(cuda:1)
DEBUG 01-07 10:13:59.910329.910329 lmp.py:767]   Expert 45 |    157 | GPU1(cuda:2)
DEBUG 01-07 10:13:59.910018.910018 lmp.py:767]   Expert 19 |    158 | GPU0(cuda:1)
DEBUG 01-07 10:13:59.910708.910708 lmp.py:767]   Expert 62 |    161 | GPU0(cuda:1)
DEBUG 01-07 10:13:59.911112.911112 lmp.py:767]   Expert 34 |    184 | GPU1(cuda:2)
DEBUG 01-07 10:13:59.911517.911517 lmp.py:767]   Expert 57 |    188 | GPU1(cuda:2)
DEBUG 01-07 10:13:59.911445.911445 lmp.py:767]   Expert 50 |    196 | GPU0(cuda:1)
DEBUG 01-07 10:13:59.911134.911134 lmp.py:767]   Expert 10 |    204 | GPU0(cuda:1)
DEBUG 01-07 10:13:59.911823.911823 lmp.py:767]   Expert 31 |    206 | GPU1(cuda:2)
DEBUG 01-07 10:13:59.911512.911512 lmp.py:767]   Expert 23 |    207 | GPU1(cuda:2)
DEBUG 01-07 10:13:59.911679.911679 lmp.py:767]   Expert 60 |    214 | GPU0(cuda:1)
DEBUG 01-07 10:13:59.911083.911083 lmp.py:767]   Expert  8 |    219 | GPU1(cuda:2)
DEBUG 01-07 10:13:59.911488.911488 lmp.py:767]   Expert 18 |    220 | GPU1(cuda:2)
DEBUG 01-07 10:13:59.911415.911415 lmp.py:767]   Expert 53 |    220 | GPU0(cuda:1)
DEBUG 01-07 10:13:59.911343.911343 lmp.py:767]   Expert 22 |    221 | GPU0(cuda:1)
DEBUG 01-07 10:13:59.911032.911032 lmp.py:767]   Expert 52 |    225 | GPU0(cuda:1)
DEBUG 01-07 10:13:59.911722.911722 lmp.py:767]   Expert 37 |    233 | GPU1(cuda:2)
DEBUG 01-07 10:13:59.911411.911411 lmp.py:767]   Expert  5 |    243 | GPU0(cuda:1)
DEBUG 01-07 10:13:59.911100.911100 lmp.py:767]   Expert 17 |    245 | GPU1(cuda:2)
DEBUG 01-07 10:13:59.911266.911266 lmp.py:767]   Expert 11 |    257 | GPU1(cuda:2)
DEBUG 01-07 10:13:59.911909.911909 lmp.py:767]   Expert  1 |    269 | GPU0(cuda:1)
DEBUG 01-07 10:13:59.911837.911837 lmp.py:767]   Expert 49 |    279 | GPU1(cuda:2)
DEBUG 01-07 10:13:59.911526.911526 lmp.py:767]   Expert 41 |    284 | GPU0(cuda:1)
DEBUG 01-07 10:13:59.911693.911693 lmp.py:767]   Expert 28 |    285 | GPU1(cuda:2)
DEBUG 01-07 10:13:59.911382.911382 lmp.py:767]   Expert 32 |    289 | GPU0(cuda:1)
DEBUG 01-07 10:13:59.911310.911310 lmp.py:767]   Expert 26 |    291 | GPU1(cuda:2)
DEBUG 01-07 10:13:59.911906.911906 lmp.py:767]   Expert 58 |    296 | GPU0(cuda:1)
DEBUG 01-07 10:13:59.911265.911265 lmp.py:767]   Expert 40 |    302 | GPU1(cuda:2)
DEBUG 01-07 10:13:59.911861.911861 lmp.py:767]   Expert 14 |    307 | GPU0(cuda:1)
DEBUG 01-07 10:13:59.911743.911743 lmp.py:767]   Expert 12 |    328 | GPU1(cuda:2)
DEBUG 01-07 10:13:59.911147.911147 lmp.py:767]   Expert 63 |    336 | GPU0(cuda:1)
DEBUG 01-07 10:13:59.911029.911029 lmp.py:767]   Expert 21 |    384 | GPU1(cuda:2)
DEBUG 01-07 10:13:59.911671.911671 lmp.py:767]   Expert 27 |    665 | GPU1(cuda:2)
DEBUG 01-07 10:13:59.911314.911314 lmp.py:767]   Expert  3 |   1013 | GPU0(cuda:1)
DEBUG 01-07 10:13:59.911242.911242 lmp.py:769] 
DEBUG 01-07 10:13:59.911242.911242 lmp.py:769]   Device Token Distribution:
DEBUG 01-07 10:13:59.911647.911647 lmp.py:770]   CPU:   1367 tokens
DEBUG 01-07 10:13:59.911720.911720 lmp.py:774]   cuda:1:   5463 tokens (22 experts)
DEBUG 01-07 10:13:59.911840.911840 lmp.py:774]   cuda:2:   5458 tokens (23 experts)
DEBUG 01-07 10:13:59.911529.911529 lmp.py:775]   Total GPU:  10921 tokens
DEBUG 01-07 10:13:59.911980.911980 lmp.py:776] ============================================================
DEBUG 01-07 10:13:59.911980.911980 lmp.py:776] 
DEBUG 01-07 10:13:59.911630.911630 cuda_h.py:19] end experts_map_get cost 0.001720428466796875 seconds
DEBUG 01-07 10:13:59.911511.911511 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model_multi_device
DEBUG 01-07 10:13:59.911665.911665 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 10:13:59.911377.911377 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 10:13:59.912839.912839 cuda_h.py:19] end allocate_cuda_memory cost 0.00030922889709472656 seconds
DEBUG 01-07 10:13:59.912742.912742 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 10:13:59.912260.912260 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 10:13:59.912638.912638 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 10:13:59.912811.912811 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, c1495a8b-3c37-47eb-8bfd-b67b0b6260cc
DEBUG 01-07 10:13:59.912591.912591 client.py:106] call stub.LoadModelAsync
INFO 01-07 10:13:59.912887.912887 client.py:127] Model loaded
DEBUG 01-07 10:13:59.912814.912814 cuda_h.py:19] end sllm_worker_task cost 0.008810997009277344 seconds
INFO 01-07 10:13:59.913129.913129 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, c1495a8b-3c37-47eb-8bfd-b67b0b6260cc
DEBUG 01-07 10:13:59.913588.913588 cuda_h.py:19] end load_into_gpu_async cost 0.0009067058563232422 seconds
DEBUG 01-07 10:13:59.913907.913907 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 10:13:59.913624.913624 cuda_h.py:19] end restore_tensors2 cost 0.00022411346435546875 seconds
DEBUG 01-07 10:13:59.913055.913055 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0017406940460205078 seconds
DEBUG 01-07 10:13:59.915076.915076 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 10:13:59.915669.915669 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 10:13:59.915532.915532 cuda_h.py:19] end allocate_cuda_memory cost 0.00021314620971679688 seconds
DEBUG 01-07 10:13:59.915514.915514 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 10:13:59.915648.915648 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 10:13:59.915880.915880 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 10:13:59.915292.915292 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, abcc44e0-d798-4fd7-9c55-cc2b94ac7417
DEBUG 01-07 10:13:59.915184.915184 client.py:106] call stub.LoadModelAsync
INFO 01-07 10:13:59.916889.916889 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, abcc44e0-d798-4fd7-9c55-cc2b94ac7417
DEBUG 01-07 10:13:59.916573.916573 cuda_h.py:19] end load_into_gpu_async cost 0.0009267330169677734 seconds
DEBUG 01-07 10:13:59.916415.916415 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 10:13:59.916965.916965 cuda_h.py:19] end restore_tensors2 cost 0.00020623207092285156 seconds
DEBUG 01-07 10:13:59.916828.916828 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0016312599182128906 seconds
DEBUG 01-07 10:13:59.918736.918736 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model_multi_device cost 0.00709223747253418 seconds
DEBUG 01-07 10:13:59.918129.918129 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-07 10:13:59.918807.918807 lmp.py:816] 
DEBUG 01-07 10:13:59.918807.918807 lmp.py:816]   Computing 19 experts on CPU...
DEBUG 01-07 10:13:59.918881.918881 cuda_h.py:19] end cpu_experts_submit cost 0.00010561943054199219 seconds
DEBUG 01-07 10:13:59.918485.918485 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-07 10:13:59.924635.924635 mlpmodule.py:749] group tensors cost 0.0051572322845458984 s
DEBUG 01-07 10:13:59.926624.926624 mlpmodule.py:787] pad cost 0.001216888427734375 s
DEBUG 01-07 10:13:59.926058.926058 mlpmodule.py:793] create cpu tensor cost 4.5299530029296875e-05 s
DEBUG 01-07 10:13:59.926167.926167 mlpmodule.py:798] move to cpu cost 3.552436828613281e-05 s
DEBUG 01-07 10:13:59.936224.936224 mlpmodule.py:812] group_w3: shape=torch.Size([19, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=54788096
DEBUG 01-07 10:13:59.936449.936449 mlpmodule.py:813] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-07 10:13:59.936168.936168 mlpmodule.py:818] group_w3 first element: 0.00653076171875
WARNING 01-07 10:13:59.936729.936729 mlpmodule.py:828] start einsum2
DEBUG 01-07 10:13:59.955290.955290 mlpmodule.py:838] group einsum cost 0.02890634536743164 s
DEBUG 01-07 10:13:59.955582.955582 mlpmodule.py:846] cpy2cputensor cost 0.00040531158447265625 s
DEBUG 01-07 10:13:59.958596.958596 cuda_h.py:19] end wait_cetm_experts cost 0.03946805000305176 seconds
DEBUG 01-07 10:13:59.958056.958056 cuda_h.py:10] start gpu_sexperts
DEBUG 01-07 10:13:59.959704.959704 cuda_h.py:19] end gpu_sexperts cost 0.0005037784576416016 seconds
DEBUG 01-07 10:13:59.959162.959162 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-07 10:13:59.959582.959582 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.4318695068359375e-05 seconds
DEBUG 01-07 10:13:59.959000.959000 cuda_h.py:10] start wait_experts_multi_device
INFO 01-07 10:13:59.959663.959663 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, c1495a8b-3c37-47eb-8bfd-b67b0b6260cc
INFO 01-07 10:13:59.961892.961892 client.py:127] Model loaded
INFO 01-07 10:13:59.961583.961583 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, abcc44e0-d798-4fd7-9c55-cc2b94ac7417
INFO 01-07 10:13:59.962772.962772 client.py:127] Model loaded
DEBUG 01-07 10:13:59.962171.962171 cuda_h.py:19] end wait_experts_multi_device cost 0.0035016536712646484 seconds
DEBUG 01-07 10:13:59.962305.962305 cuda_h.py:10] start gpu_experts_multi_device
DEBUG 01-07 10:13:59.962319.962319 lmp.py:867]   Computing 23 experts on cuda:2...
DEBUG 01-07 10:13:59.963264.963264 mlpmodule.py:533] gpu group tensors cost 0.0004620552062988281 s
DEBUG 01-07 10:13:59.965701.965701 mlpmodule.py:566] gpu pad cost 0.0013115406036376953 s
DEBUG 01-07 10:13:59.965939.965939 mlpmodule.py:584] gpu group einsum cost 0.0005266666412353516 s
DEBUG 01-07 10:13:59.966224.966224 mlpmodule.py:707]  experts func einsum cost 0.047882080078125 s
DEBUG 01-07 10:13:59.968322.968322 mlpmodule.py:656] gpu experts func einsum cost 0.004575014114379883 s
DEBUG 01-07 10:13:59.968162.968162 lmp.py:867]   Computing 22 experts on cuda:1...
DEBUG 01-07 10:13:59.969821.969821 mlpmodule.py:533] gpu group tensors cost 0.0004189014434814453 s
DEBUG 01-07 10:13:59.970200.970200 mlpmodule.py:566] gpu pad cost 0.001173257827758789 s
DEBUG 01-07 10:13:59.970819.970819 mlpmodule.py:584] gpu group einsum cost 0.00042939186096191406 s
DEBUG 01-07 10:13:59.972664.972664 mlpmodule.py:656] gpu experts func einsum cost 0.0038499832153320312 s
DEBUG 01-07 10:13:59.972786.972786 cuda_h.py:19] end gpu_experts_multi_device cost 0.009806632995605469 seconds
DEBUG 01-07 10:13:59.972511.972511 cuda_h.py:19] end layer_moe_generate_multi_device_24 cost 0.06357455253601074 seconds
DEBUG 01-07 10:13:59.972187.972187 lmp.py:194] -------------------------------- end prefill layer 24 --------------------------------
DEBUG 01-07 10:13:59.972572.972572 lmp.py:153] -------------------------------- start prefill layer 25 --------------------------------
DEBUG 01-07 10:13:59.973984.973984 cuda_h.py:10] start start_load_qkvogn_s_weight_l_26
DEBUG 01-07 10:13:59.973071.973071 cuda_h.py:10] start start_load_qkvogn_s_weight_l_26
DEBUG 01-07 10:13:59.973523.973523 cuda_h.py:19] end start_load_qkvogn_s_weight_l_26 cost 2.7179718017578125e-05 seconds
DEBUG 01-07 10:13:59.973987.973987 cuda_h.py:19] end start_load_qkvogn_s_weight_l_26 cost 5.698204040527344e-05 seconds
DEBUG 01-07 10:13:59.973299.973299 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-07 10:13:59.973851.973851 mlpmodule.py:367] cuda:1 cuda:1
DEBUG 01-07 10:13:59.973316.973316 cuda_h.py:10] start sllm_worker_task
DEBUG 01-07 10:13:59.973312.973312 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 10:13:59.973949.973949 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 10:13:59.973530.973530 cuda_h.py:19] end allocate_cuda_memory cost 0.0002887248992919922 seconds
DEBUG 01-07 10:13:59.973141.973141 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 10:13:59.973374.973374 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 10:13:59.973766.973766 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 10:13:59.973323.973323 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 9495dde1-8f9a-4262-872a-07f89014ac96
DEBUG 01-07 10:13:59.973279.973279 client.py:106] call stub.LoadModelAsync
DEBUG 01-07 10:13:59.974322.974322 cuda_h.py:10] start self_attn
INFO 01-07 10:13:59.974576.974576 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 9495dde1-8f9a-4262-872a-07f89014ac96
DEBUG 01-07 10:13:59.974121.974121 cuda_h.py:19] end load_into_gpu_async cost 0.0009357929229736328 seconds
DEBUG 01-07 10:13:59.974724.974724 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 10:13:59.974846.974846 cuda_h.py:19] end restore_tensors2 cost 6.532669067382812e-05 seconds
DEBUG 01-07 10:13:59.974741.974741 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0015156269073486328 seconds
INFO 01-07 10:13:59.974293.974293 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 9495dde1-8f9a-4262-872a-07f89014ac96
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-07 10:13:59.977414.977414 cuda_h.py:19] end self_attn cost 0.003695249557495117 seconds
DEBUG 01-07 10:13:59.978034.978034 cuda_h.py:19] end iln_self_attn_paln cost 0.005113363265991211 seconds
DEBUG 01-07 10:13:59.978526.978526 cuda_h.py:10] start layer_moe_generate_multi_device_25
DEBUG 01-07 10:13:59.978474.978474 cuda_h.py:10] start gate
DEBUG 01-07 10:13:59.979039.979039 cuda_h.py:19] end gate cost 0.0006299018859863281 seconds
DEBUG 01-07 10:13:59.979008.979008 cuda_h.py:10] start experts_map_get
DEBUG 01-07 10:13:59.979252.979252 lmp.py:744] 
DEBUG 01-07 10:13:59.979252.979252 lmp.py:744] Expert Token Distribution & Multi-Device Allocation:
DEBUG 01-07 10:13:59.979406.979406 lmp.py:745]   Total experts: 64
DEBUG 01-07 10:13:59.979440.979440 lmp.py:746]   CPU experts: 19 (30%)
DEBUG 01-07 10:13:59.979991.979991 lmp.py:747]   GPU experts: 45 (70%)
DEBUG 01-07 10:13:59.979634.979634 lmp.py:748]   Number of GPU devices: 2
DEBUG 01-07 10:13:59.979846.979846 lmp.py:749] 
DEBUG 01-07 10:13:59.979846.979846 lmp.py:749]   Expert ID | Tokens | Device
DEBUG 01-07 10:13:59.979535.979535 lmp.py:750]   -----------------------------------
DEBUG 01-07 10:13:59.979900.979900 lmp.py:767]   Expert 13 |     26 | CPU
DEBUG 01-07 10:13:59.979066.979066 lmp.py:767]   Expert 44 |     39 | CPU
DEBUG 01-07 10:13:59.979994.979994 lmp.py:767]   Expert 25 |     40 | CPU
DEBUG 01-07 10:13:59.979968.979968 lmp.py:767]   Expert  9 |     42 | CPU
DEBUG 01-07 10:13:59.979181.979181 lmp.py:767]   Expert 38 |     48 | CPU
DEBUG 01-07 10:13:59.979632.979632 lmp.py:767]   Expert 16 |     49 | CPU
DEBUG 01-07 10:13:59.979559.979559 lmp.py:767]   Expert 33 |     51 | CPU
DEBUG 01-07 10:13:59.979772.979772 lmp.py:767]   Expert  2 |     53 | CPU
DEBUG 01-07 10:13:59.979746.979746 lmp.py:767]   Expert 22 |     58 | CPU
DEBUG 01-07 10:13:59.979481.979481 lmp.py:767]   Expert 42 |     60 | CPU
DEBUG 01-07 10:13:59.979694.979694 lmp.py:767]   Expert  5 |     67 | CPU
DEBUG 01-07 10:13:59.979906.979906 lmp.py:767]   Expert 23 |     78 | CPU
DEBUG 01-07 10:13:59.979404.979404 lmp.py:767]   Expert 24 |     80 | CPU
DEBUG 01-07 10:13:59.979378.979378 lmp.py:767]   Expert 10 |     85 | CPU
DEBUG 01-07 10:13:59.979544.979544 lmp.py:767]   Expert 59 |    104 | CPU
DEBUG 01-07 10:13:59.979471.979471 lmp.py:767]   Expert 21 |    106 | CPU
DEBUG 01-07 10:13:59.979445.979445 lmp.py:767]   Expert 55 |    113 | CPU
DEBUG 01-07 10:13:59.979420.979420 lmp.py:767]   Expert 46 |    114 | CPU
DEBUG 01-07 10:13:59.979155.979155 lmp.py:767]   Expert 45 |    117 | CPU
DEBUG 01-07 10:13:59.979560.979560 lmp.py:767]   Expert 61 |    118 | GPU0(cuda:1)
DEBUG 01-07 10:13:59.979964.979964 lmp.py:767]   Expert 31 |    123 | GPU0(cuda:1)
DEBUG 01-07 10:13:59.979130.979130 lmp.py:767]   Expert 51 |    138 | GPU1(cuda:2)
DEBUG 01-07 10:13:59.979058.979058 lmp.py:767]   Expert 36 |    139 | GPU0(cuda:1)
DEBUG 01-07 10:13:59.980224.980224 lmp.py:767]   Expert 43 |    141 | GPU1(cuda:2)
DEBUG 01-07 10:13:59.980106.980106 lmp.py:767]   Expert  6 |    143 | GPU1(cuda:2)
DEBUG 01-07 10:13:59.980272.980272 lmp.py:767]   Expert  8 |    146 | GPU0(cuda:1)
DEBUG 01-07 10:13:59.980676.980676 lmp.py:767]   Expert  0 |    150 | GPU0(cuda:1)
DEBUG 01-07 10:13:59.980604.980604 lmp.py:767]   Expert  3 |    155 | GPU1(cuda:2)
DEBUG 01-07 10:13:59.980532.980532 lmp.py:767]   Expert 26 |    158 | GPU0(cuda:1)
DEBUG 01-07 10:13:59.980459.980459 lmp.py:767]   Expert 48 |    160 | GPU1(cuda:2)
DEBUG 01-07 10:13:59.980387.980387 lmp.py:767]   Expert 18 |    161 | GPU1(cuda:2)
DEBUG 01-07 10:13:59.980077.980077 lmp.py:767]   Expert 41 |    168 | GPU0(cuda:1)
DEBUG 01-07 10:13:59.980004.980004 lmp.py:767]   Expert 20 |    174 | GPU1(cuda:2)
DEBUG 01-07 10:13:59.980078.980078 lmp.py:767]   Expert 12 |    176 | GPU0(cuda:1)
DEBUG 01-07 10:13:59.980959.980959 lmp.py:767]   Expert  7 |    180 | GPU0(cuda:1)
DEBUG 01-07 10:13:59.980887.980887 lmp.py:767]   Expert 56 |    185 | GPU1(cuda:2)
DEBUG 01-07 10:13:59.980815.980815 lmp.py:767]   Expert 27 |    192 | GPU1(cuda:2)
DEBUG 01-07 10:13:59.980504.980504 lmp.py:767]   Expert 28 |    192 | GPU0(cuda:1)
DEBUG 01-07 10:13:59.980670.980670 lmp.py:767]   Expert  1 |    193 | GPU0(cuda:1)
DEBUG 01-07 10:13:59.980359.980359 lmp.py:767]   Expert 34 |    195 | GPU1(cuda:2)
DEBUG 01-07 10:13:59.980525.980525 lmp.py:767]   Expert 47 |    202 | GPU1(cuda:2)
DEBUG 01-07 10:13:59.980453.980453 lmp.py:767]   Expert 32 |    211 | GPU0(cuda:1)
DEBUG 01-07 10:13:59.980619.980619 lmp.py:767]   Expert 11 |    214 | GPU1(cuda:2)
DEBUG 01-07 10:13:59.980262.980262 lmp.py:767]   Expert 40 |    228 | GPU0(cuda:1)
DEBUG 01-07 10:13:59.980428.980428 lmp.py:767]   Expert 49 |    237 | GPU1(cuda:2)
DEBUG 01-07 10:13:59.980178.980178 lmp.py:767]   Expert 53 |    238 | GPU0(cuda:1)
DEBUG 01-07 10:13:59.980344.980344 lmp.py:767]   Expert 63 |    240 | GPU1(cuda:2)
DEBUG 01-07 10:13:59.980033.980033 lmp.py:767]   Expert 15 |    244 | GPU0(cuda:1)
DEBUG 01-07 10:13:59.980961.980961 lmp.py:767]   Expert 50 |    246 | GPU1(cuda:2)
DEBUG 01-07 10:13:59.980650.980650 lmp.py:767]   Expert 29 |    249 | GPU0(cuda:1)
DEBUG 01-07 10:13:59.980578.980578 lmp.py:767]   Expert 30 |    250 | GPU1(cuda:2)
DEBUG 01-07 10:13:59.980505.980505 lmp.py:767]   Expert  4 |    251 | GPU0(cuda:1)
DEBUG 01-07 10:13:59.980910.980910 lmp.py:767]   Expert 35 |    268 | GPU1(cuda:2)
DEBUG 01-07 10:13:59.980076.980076 lmp.py:767]   Expert 14 |    275 | GPU0(cuda:1)
DEBUG 01-07 10:13:59.980004.980004 lmp.py:767]   Expert 37 |    303 | GPU0(cuda:1)
DEBUG 01-07 10:13:59.980793.980793 lmp.py:767]   Expert 52 |    338 | GPU1(cuda:2)
DEBUG 01-07 10:13:59.980959.980959 lmp.py:767]   Expert 17 |    363 | GPU0(cuda:1)
DEBUG 01-07 10:13:59.980648.980648 lmp.py:767]   Expert 54 |    375 | GPU1(cuda:2)
DEBUG 01-07 10:13:59.980337.980337 lmp.py:767]   Expert 39 |    390 | GPU0(cuda:1)
DEBUG 01-07 10:13:59.980265.980265 lmp.py:767]   Expert 57 |    414 | GPU1(cuda:2)
DEBUG 01-07 10:13:59.980769.980769 lmp.py:767]   Expert 60 |    457 | GPU0(cuda:1)
DEBUG 01-07 10:13:59.980651.980651 lmp.py:767]   Expert 62 |    460 | GPU1(cuda:2)
DEBUG 01-07 10:13:59.980055.980055 lmp.py:767]   Expert 19 |    539 | GPU1(cuda:2)
DEBUG 01-07 10:13:59.980221.980221 lmp.py:767]   Expert 58 |    579 | GPU0(cuda:1)
DEBUG 01-07 10:13:59.980718.980718 lmp.py:769] 
DEBUG 01-07 10:13:59.980718.980718 lmp.py:769]   Device Token Distribution:
DEBUG 01-07 10:13:59.980408.980408 lmp.py:770]   CPU:   1330 tokens
DEBUG 01-07 10:13:59.980051.980051 lmp.py:774]   cuda:1:   5531 tokens (23 experts)
DEBUG 01-07 10:13:59.980217.980217 lmp.py:774]   cuda:2:   5427 tokens (22 experts)
DEBUG 01-07 10:13:59.980906.980906 lmp.py:775]   Total GPU:  10958 tokens
DEBUG 01-07 10:13:59.980357.980357 lmp.py:776] ============================================================
DEBUG 01-07 10:13:59.980357.980357 lmp.py:776] 
DEBUG 01-07 10:13:59.980484.980484 cuda_h.py:19] end experts_map_get cost 0.001726388931274414 seconds
DEBUG 01-07 10:13:59.980365.980365 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model_multi_device
DEBUG 01-07 10:13:59.980234.980234 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 10:13:59.980708.980708 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 10:13:59.981108.981108 cuda_h.py:19] end allocate_cuda_memory cost 0.0002639293670654297 seconds
DEBUG 01-07 10:13:59.981143.981143 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 10:13:59.981946.981946 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 10:13:59.981516.981516 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 10:13:59.981213.981213 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 4f734443-b618-4c3b-aa37-271cffff931f
DEBUG 01-07 10:13:59.981886.981886 client.py:106] call stub.LoadModelAsync
INFO 01-07 10:13:59.981776.981776 client.py:127] Model loaded
DEBUG 01-07 10:13:59.982798.982798 cuda_h.py:19] end sllm_worker_task cost 0.008785724639892578 seconds
INFO 01-07 10:13:59.982964.982964 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 4f734443-b618-4c3b-aa37-271cffff931f
DEBUG 01-07 10:13:59.982184.982184 cuda_h.py:19] end load_into_gpu_async cost 0.0009813308715820312 seconds
DEBUG 01-07 10:13:59.982887.982887 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 10:13:59.982617.982617 cuda_h.py:19] end restore_tensors2 cost 0.00022673606872558594 seconds
DEBUG 01-07 10:13:59.982149.982149 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0017766952514648438 seconds
DEBUG 01-07 10:13:59.984477.984477 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 10:13:59.984971.984971 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 10:13:59.984019.984019 cuda_h.py:19] end allocate_cuda_memory cost 0.0002086162567138672 seconds
DEBUG 01-07 10:13:59.985478.985478 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 10:13:59.985565.985565 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 10:13:59.985420.985420 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 10:13:59.985308.985308 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 41e005ff-12b8-4b6a-bcb1-e4d74df9f303
DEBUG 01-07 10:13:59.985240.985240 client.py:106] call stub.LoadModelAsync
INFO 01-07 10:13:59.985615.985615 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 41e005ff-12b8-4b6a-bcb1-e4d74df9f303
DEBUG 01-07 10:13:59.985822.985822 cuda_h.py:19] end load_into_gpu_async cost 0.0009603500366210938 seconds
DEBUG 01-07 10:13:59.986664.986664 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 10:13:59.986446.986446 cuda_h.py:19] end restore_tensors2 cost 0.00020170211791992188 seconds
DEBUG 01-07 10:13:59.986070.986070 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0016527175903320312 seconds
DEBUG 01-07 10:13:59.988819.988819 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model_multi_device cost 0.007191658020019531 seconds
DEBUG 01-07 10:13:59.988257.988257 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-07 10:13:59.988697.988697 lmp.py:816] 
DEBUG 01-07 10:13:59.988697.988697 lmp.py:816]   Computing 19 experts on CPU...
DEBUG 01-07 10:13:59.988533.988533 cuda_h.py:19] end cpu_experts_submit cost 0.00010585784912109375 seconds
DEBUG 01-07 10:13:59.988944.988944 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-07 10:13:59.993919.993919 mlpmodule.py:749] group tensors cost 0.005423069000244141 s
DEBUG 01-07 10:13:59.995438.995438 mlpmodule.py:787] pad cost 0.0012619495391845703 s
DEBUG 01-07 10:13:59.995687.995687 mlpmodule.py:793] create cpu tensor cost 4.673004150390625e-05 s
DEBUG 01-07 10:13:59.995511.995511 mlpmodule.py:798] move to cpu cost 3.552436828613281e-05 s
DEBUG 01-07 10:14:00.006426.006426 mlpmodule.py:812] group_w3: shape=torch.Size([19, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=54788096
DEBUG 01-07 10:14:00.006140.006140 mlpmodule.py:813] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-07 10:14:00.006899.006899 mlpmodule.py:818] group_w3 first element: -0.02734375
WARNING 01-07 10:14:00.006175.006175 mlpmodule.py:828] start einsum2
DEBUG 01-07 10:14:00.025779.025779 mlpmodule.py:838] group einsum cost 0.029886245727539062 s
DEBUG 01-07 10:14:00.026090.026090 mlpmodule.py:846] cpy2cputensor cost 0.0003819465637207031 s
DEBUG 01-07 10:14:00.029875.029875 cuda_h.py:19] end wait_cetm_experts cost 0.04081153869628906 seconds
DEBUG 01-07 10:14:00.029852.029852 cuda_h.py:10] start gpu_sexperts
DEBUG 01-07 10:14:00.029221.029221 cuda_h.py:19] end gpu_sexperts cost 0.0005092620849609375 seconds
DEBUG 01-07 10:14:00.029972.029972 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-07 10:14:00.029822.029822 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.47955322265625e-05 seconds
DEBUG 01-07 10:14:00.029478.029478 cuda_h.py:10] start wait_experts_multi_device
INFO 01-07 10:14:00.029141.029141 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 4f734443-b618-4c3b-aa37-271cffff931f
INFO 01-07 10:14:00.032920.032920 client.py:127] Model loaded
INFO 01-07 10:14:00.032141.032141 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 41e005ff-12b8-4b6a-bcb1-e4d74df9f303
INFO 01-07 10:14:00.032329.032329 client.py:127] Model loaded
DEBUG 01-07 10:14:00.032781.032781 cuda_h.py:19] end wait_experts_multi_device cost 0.002896547317504883 seconds
DEBUG 01-07 10:14:00.032868.032868 cuda_h.py:10] start gpu_experts_multi_device
DEBUG 01-07 10:14:00.032691.032691 lmp.py:867]   Computing 22 experts on cuda:2...
DEBUG 01-07 10:14:00.034477.034477 mlpmodule.py:533] gpu group tensors cost 0.00046563148498535156 s
DEBUG 01-07 10:14:00.035115.035115 mlpmodule.py:566] gpu pad cost 0.0012171268463134766 s
DEBUG 01-07 10:14:00.035705.035705 mlpmodule.py:584] gpu group einsum cost 0.000537872314453125 s
DEBUG 01-07 10:14:00.037055.037055 mlpmodule.py:707]  experts func einsum cost 0.04908895492553711 s
DEBUG 01-07 10:14:00.038544.038544 mlpmodule.py:656] gpu experts func einsum cost 0.004444122314453125 s
DEBUG 01-07 10:14:00.038937.038937 lmp.py:867]   Computing 23 experts on cuda:1...
DEBUG 01-07 10:14:00.039432.039432 mlpmodule.py:533] gpu group tensors cost 0.0004394054412841797 s
DEBUG 01-07 10:14:00.040786.040786 mlpmodule.py:566] gpu pad cost 0.0012235641479492188 s
DEBUG 01-07 10:14:00.040605.040605 mlpmodule.py:584] gpu group einsum cost 0.0004706382751464844 s
DEBUG 01-07 10:14:00.042210.042210 mlpmodule.py:656] gpu experts func einsum cost 0.004103422164916992 s
DEBUG 01-07 10:14:00.042994.042994 cuda_h.py:19] end gpu_experts_multi_device cost 0.00986170768737793 seconds
DEBUG 01-07 10:14:00.042341.042341 cuda_h.py:19] end layer_moe_generate_multi_device_25 cost 0.06447672843933105 seconds
DEBUG 01-07 10:14:00.043594.043594 lmp.py:194] -------------------------------- end prefill layer 25 --------------------------------
DEBUG 01-07 10:14:00.043317.043317 lmp.py:153] -------------------------------- start prefill layer 26 --------------------------------
DEBUG 01-07 10:14:00.043775.043775 cuda_h.py:10] start start_load_qkvogn_s_weight_l_27
DEBUG 01-07 10:14:00.043100.043100 cuda_h.py:10] start start_load_qkvogn_s_weight_l_27
DEBUG 01-07 10:14:00.043744.043744 cuda_h.py:19] end start_load_qkvogn_s_weight_l_27 cost 2.7894973754882812e-05 seconds
DEBUG 01-07 10:14:00.043825.043825 cuda_h.py:19] end start_load_qkvogn_s_weight_l_27 cost 5.650520324707031e-05 seconds
DEBUG 01-07 10:14:00.043613.043613 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-07 10:14:00.043429.043429 cuda_h.py:10] start sllm_worker_task
DEBUG 01-07 10:14:00.043771.043771 mlpmodule.py:367] cuda:1 cuda:1
DEBUG 01-07 10:14:00.043249.043249 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 10:14:00.043822.043822 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 10:14:00.043925.043925 cuda_h.py:19] end allocate_cuda_memory cost 0.0002853870391845703 seconds
DEBUG 01-07 10:14:00.043842.043842 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 10:14:00.043174.043174 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 10:14:00.044043.044043 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 10:14:00.044031.044031 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 9786bce8-3dac-4a66-9d2c-fe895d1b3d22
DEBUG 01-07 10:14:00.044510.044510 client.py:106] call stub.LoadModelAsync
DEBUG 01-07 10:14:00.044301.044301 cuda_h.py:10] start self_attn
INFO 01-07 10:14:00.044464.044464 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 9786bce8-3dac-4a66-9d2c-fe895d1b3d22
DEBUG 01-07 10:14:00.044486.044486 cuda_h.py:19] end load_into_gpu_async cost 0.0010027885437011719 seconds
DEBUG 01-07 10:14:00.045805.045805 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 10:14:00.045357.045357 cuda_h.py:19] end restore_tensors2 cost 6.556510925292969e-05 seconds
DEBUG 01-07 10:14:00.045444.045444 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0016026496887207031 seconds
INFO 01-07 10:14:00.045996.045996 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 9786bce8-3dac-4a66-9d2c-fe895d1b3d22
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-07 10:14:00.048047.048047 cuda_h.py:19] end self_attn cost 0.0036516189575195312 seconds
DEBUG 01-07 10:14:00.048269.048269 cuda_h.py:19] end iln_self_attn_paln cost 0.0050678253173828125 seconds
DEBUG 01-07 10:14:00.048238.048238 cuda_h.py:10] start layer_moe_generate_multi_device_26
DEBUG 01-07 10:14:00.048332.048332 cuda_h.py:10] start gate
DEBUG 01-07 10:14:00.049427.049427 cuda_h.py:19] end gate cost 0.00063323974609375 seconds
DEBUG 01-07 10:14:00.049111.049111 cuda_h.py:10] start experts_map_get
DEBUG 01-07 10:14:00.049018.049018 lmp.py:744] 
DEBUG 01-07 10:14:00.049018.049018 lmp.py:744] Expert Token Distribution & Multi-Device Allocation:
DEBUG 01-07 10:14:00.049171.049171 lmp.py:745]   Total experts: 64
DEBUG 01-07 10:14:00.049205.049205 lmp.py:746]   CPU experts: 19 (30%)
DEBUG 01-07 10:14:00.049517.049517 lmp.py:747]   GPU experts: 45 (70%)
DEBUG 01-07 10:14:00.049399.049399 lmp.py:748]   Number of GPU devices: 2
DEBUG 01-07 10:14:00.049088.049088 lmp.py:749] 
DEBUG 01-07 10:14:00.049088.049088 lmp.py:749]   Expert ID | Tokens | Device
DEBUG 01-07 10:14:00.049016.049016 lmp.py:750]   -----------------------------------
DEBUG 01-07 10:14:00.049334.049334 lmp.py:767]   Expert 20 |     10 | CPU
DEBUG 01-07 10:14:00.049977.049977 lmp.py:767]   Expert 61 |     12 | CPU
DEBUG 01-07 10:14:00.049143.049143 lmp.py:767]   Expert 11 |     28 | CPU
DEBUG 01-07 10:14:00.049310.049310 lmp.py:767]   Expert  7 |     40 | CPU
DEBUG 01-07 10:14:00.049714.049714 lmp.py:767]   Expert 62 |     40 | CPU
DEBUG 01-07 10:14:00.049357.049357 lmp.py:767]   Expert  3 |     42 | CPU
DEBUG 01-07 10:14:00.049046.049046 lmp.py:767]   Expert 51 |     43 | CPU
DEBUG 01-07 10:14:00.049736.049736 lmp.py:767]   Expert 30 |     51 | CPU
DEBUG 01-07 10:14:00.049948.049948 lmp.py:767]   Expert 17 |     52 | CPU
DEBUG 01-07 10:14:00.049399.049399 lmp.py:767]   Expert  6 |     57 | CPU
DEBUG 01-07 10:14:00.049612.049612 lmp.py:767]   Expert 29 |     57 | CPU
DEBUG 01-07 10:14:00.049301.049301 lmp.py:767]   Expert  9 |     64 | CPU
DEBUG 01-07 10:14:00.049275.049275 lmp.py:767]   Expert 63 |     75 | CPU
DEBUG 01-07 10:14:00.049203.049203 lmp.py:767]   Expert 38 |     76 | CPU
DEBUG 01-07 10:14:00.049653.049653 lmp.py:767]   Expert 55 |     84 | CPU
DEBUG 01-07 10:14:00.050866.050866 lmp.py:767]   Expert 59 |     87 | CPU
DEBUG 01-07 10:14:00.050840.050840 lmp.py:767]   Expert 48 |     90 | CPU
DEBUG 01-07 10:14:00.050291.050291 lmp.py:767]   Expert 19 |     91 | CPU
DEBUG 01-07 10:14:00.050265.050265 lmp.py:767]   Expert  8 |     92 | CPU
DEBUG 01-07 10:14:00.050146.050146 lmp.py:767]   Expert 49 |    102 | GPU1(cuda:2)
DEBUG 01-07 10:14:00.050743.050743 lmp.py:767]   Expert 22 |    106 | GPU0(cuda:1)
DEBUG 01-07 10:14:00.050624.050624 lmp.py:767]   Expert 24 |    110 | GPU1(cuda:2)
DEBUG 01-07 10:14:00.050267.050267 lmp.py:767]   Expert 36 |    115 | GPU0(cuda:1)
DEBUG 01-07 10:14:00.050387.050387 lmp.py:767]   Expert 34 |    118 | GPU0(cuda:1)
DEBUG 01-07 10:14:00.050792.050792 lmp.py:767]   Expert 42 |    118 | GPU1(cuda:2)
DEBUG 01-07 10:14:00.050196.050196 lmp.py:767]   Expert 39 |    120 | GPU0(cuda:1)
DEBUG 01-07 10:14:00.050601.050601 lmp.py:767]   Expert 50 |    120 | GPU1(cuda:2)
DEBUG 01-07 10:14:00.050767.050767 lmp.py:767]   Expert  4 |    131 | GPU1(cuda:2)
DEBUG 01-07 10:14:00.050410.050410 lmp.py:767]   Expert 37 |    141 | GPU0(cuda:1)
DEBUG 01-07 10:14:00.050576.050576 lmp.py:767]   Expert 41 |    145 | GPU1(cuda:2)
DEBUG 01-07 10:14:00.050981.050981 lmp.py:767]   Expert 15 |    146 | GPU0(cuda:1)
DEBUG 01-07 10:14:00.050147.050147 lmp.py:767]   Expert 23 |    155 | GPU1(cuda:2)
DEBUG 01-07 10:14:00.050074.050074 lmp.py:767]   Expert 60 |    163 | GPU0(cuda:1)
DEBUG 01-07 10:14:00.050433.050433 lmp.py:767]   Expert 56 |    164 | GPU1(cuda:2)
DEBUG 01-07 10:14:00.050599.050599 lmp.py:767]   Expert 16 |    166 | GPU0(cuda:1)
DEBUG 01-07 10:14:00.050765.050765 lmp.py:767]   Expert 44 |    168 | GPU1(cuda:2)
DEBUG 01-07 10:14:00.050931.050931 lmp.py:767]   Expert 21 |    179 | GPU0(cuda:1)
DEBUG 01-07 10:14:00.050336.050336 lmp.py:767]   Expert  1 |    180 | GPU1(cuda:2)
DEBUG 01-07 10:14:00.050740.050740 lmp.py:767]   Expert 43 |    183 | GPU0(cuda:1)
DEBUG 01-07 10:14:00.050668.050668 lmp.py:767]   Expert 53 |    190 | GPU1(cuda:2)
DEBUG 01-07 10:14:00.050549.050549 lmp.py:767]   Expert 47 |    198 | GPU0(cuda:1)
DEBUG 01-07 10:14:00.050669.050669 lmp.py:767]   Expert 12 |    200 | GPU1(cuda:2)
DEBUG 01-07 10:14:00.050074.050074 lmp.py:767]   Expert 33 |    203 | GPU0(cuda:1)
DEBUG 01-07 10:14:00.050240.050240 lmp.py:767]   Expert 13 |    206 | GPU1(cuda:2)
DEBUG 01-07 10:14:00.050644.050644 lmp.py:767]   Expert 32 |    225 | GPU0(cuda:1)
DEBUG 01-07 10:14:00.050811.050811 lmp.py:767]   Expert 28 |    231 | GPU1(cuda:2)
DEBUG 01-07 10:14:00.050215.050215 lmp.py:767]   Expert  0 |    251 | GPU0(cuda:1)
DEBUG 01-07 10:14:00.050381.050381 lmp.py:767]   Expert 26 |    257 | GPU0(cuda:1)
DEBUG 01-07 10:14:00.050024.050024 lmp.py:767]   Expert 54 |    257 | GPU1(cuda:2)
DEBUG 01-07 10:14:00.050906.050906 lmp.py:767]   Expert 31 |    258 | GPU1(cuda:2)
DEBUG 01-07 10:14:00.050072.050072 lmp.py:767]   Expert 10 |    263 | GPU0(cuda:1)
DEBUG 01-07 10:14:00.050238.050238 lmp.py:767]   Expert 18 |    265 | GPU1(cuda:2)
DEBUG 01-07 10:14:00.050404.050404 lmp.py:767]   Expert 57 |    275 | GPU0(cuda:1)
DEBUG 01-07 10:14:00.050809.050809 lmp.py:767]   Expert  2 |    283 | GPU1(cuda:2)
DEBUG 01-07 10:14:00.050975.050975 lmp.py:767]   Expert 58 |    298 | GPU0(cuda:1)
DEBUG 01-07 10:14:00.050333.050333 lmp.py:767]   Expert 40 |    341 | GPU1(cuda:2)
DEBUG 01-07 10:14:00.050168.050168 lmp.py:767]   Expert 45 |    365 | GPU0(cuda:1)
DEBUG 01-07 10:14:00.050526.050526 lmp.py:767]   Expert 25 |    372 | GPU1(cuda:2)
DEBUG 01-07 10:14:00.050646.050646 lmp.py:767]   Expert  5 |    442 | GPU0(cuda:1)
DEBUG 01-07 10:14:00.050766.050766 lmp.py:767]   Expert 35 |    462 | GPU1(cuda:2)
DEBUG 01-07 10:14:00.050647.050647 lmp.py:767]   Expert 27 |    487 | GPU0(cuda:1)
DEBUG 01-07 10:14:00.050005.050005 lmp.py:767]   Expert 46 |    557 | GPU1(cuda:2)
DEBUG 01-07 10:14:00.050364.050364 lmp.py:767]   Expert 52 |    598 | GPU1(cuda:2)
DEBUG 01-07 10:14:00.050484.050484 lmp.py:767]   Expert 14 |    883 | GPU0(cuda:1)
DEBUG 01-07 10:14:00.050127.050127 lmp.py:769] 
DEBUG 01-07 10:14:00.050127.050127 lmp.py:769]   Device Token Distribution:
DEBUG 01-07 10:14:00.050723.050723 lmp.py:770]   CPU:   1091 tokens
DEBUG 01-07 10:14:00.050558.050558 lmp.py:774]   cuda:1:   5584 tokens (22 experts)
DEBUG 01-07 10:14:00.050916.050916 lmp.py:774]   cuda:2:   5613 tokens (23 experts)
DEBUG 01-07 10:14:00.050321.050321 lmp.py:775]   Total GPU:  11197 tokens
DEBUG 01-07 10:14:00.050487.050487 lmp.py:776] ============================================================
DEBUG 01-07 10:14:00.050487.050487 lmp.py:776] 
DEBUG 01-07 10:14:00.050091.050091 cuda_h.py:19] end experts_map_get cost 0.0017461776733398438 seconds
DEBUG 01-07 10:14:00.050210.050210 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model_multi_device
DEBUG 01-07 10:14:00.051603.051603 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 10:14:00.051745.051745 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 10:14:00.051655.051655 cuda_h.py:19] end allocate_cuda_memory cost 0.00025153160095214844 seconds
DEBUG 01-07 10:14:00.051082.051082 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 10:14:00.051553.051553 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 10:14:00.051362.051362 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 10:14:00.051488.051488 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 1911aaa2-0f3e-4f72-a70e-650dd6265c26
DEBUG 01-07 10:14:00.051625.051625 client.py:106] call stub.LoadModelAsync
INFO 01-07 10:14:00.051578.051578 client.py:127] Model loaded
DEBUG 01-07 10:14:00.052710.052710 cuda_h.py:19] end sllm_worker_task cost 0.008841991424560547 seconds
INFO 01-07 10:14:00.052435.052435 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 1911aaa2-0f3e-4f72-a70e-650dd6265c26
DEBUG 01-07 10:14:00.052702.052702 cuda_h.py:19] end load_into_gpu_async cost 0.0010914802551269531 seconds
DEBUG 01-07 10:14:00.052974.052974 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 10:14:00.052041.052041 cuda_h.py:19] end restore_tensors2 cost 0.0002009868621826172 seconds
DEBUG 01-07 10:14:00.052188.052188 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0018482208251953125 seconds
DEBUG 01-07 10:14:00.054904.054904 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 10:14:00.054551.054551 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 10:14:00.055089.055089 cuda_h.py:19] end allocate_cuda_memory cost 0.0002186298370361328 seconds
DEBUG 01-07 10:14:00.055740.055740 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 10:14:00.055827.055827 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 10:14:00.055729.055729 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 10:14:00.055379.055379 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 571916f7-ecb5-43d2-8067-33613fe2a86c
DEBUG 01-07 10:14:00.055317.055317 client.py:106] call stub.LoadModelAsync
INFO 01-07 10:14:00.056106.056106 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 571916f7-ecb5-43d2-8067-33613fe2a86c
DEBUG 01-07 10:14:00.056313.056313 cuda_h.py:19] end load_into_gpu_async cost 0.001058816909790039 seconds
DEBUG 01-07 10:14:00.056393.056393 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 10:14:00.056587.056587 cuda_h.py:19] end restore_tensors2 cost 0.0002231597900390625 seconds
DEBUG 01-07 10:14:00.056416.056416 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0018053054809570312 seconds
DEBUG 01-07 10:14:00.058399.058399 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model_multi_device cost 0.0073812007904052734 seconds
DEBUG 01-07 10:14:00.058553.058553 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-07 10:14:00.058469.058469 lmp.py:816] 
DEBUG 01-07 10:14:00.058469.058469 lmp.py:816]   Computing 19 experts on CPU...
DEBUG 01-07 10:14:00.058974.058974 cuda_h.py:19] end cpu_experts_submit cost 0.0001068115234375 seconds
DEBUG 01-07 10:14:00.058101.058101 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-07 10:14:00.064523.064523 mlpmodule.py:749] group tensors cost 0.005548954010009766 s
DEBUG 01-07 10:14:00.066319.066319 mlpmodule.py:787] pad cost 0.0013089179992675781 s
DEBUG 01-07 10:14:00.066906.066906 mlpmodule.py:793] create cpu tensor cost 4.76837158203125e-05 s
DEBUG 01-07 10:14:00.066306.066306 mlpmodule.py:798] move to cpu cost 3.6716461181640625e-05 s
DEBUG 01-07 10:14:00.076876.076876 mlpmodule.py:812] group_w3: shape=torch.Size([19, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=54788096
DEBUG 01-07 10:14:00.076465.076465 mlpmodule.py:813] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-07 10:14:00.077276.077276 mlpmodule.py:818] group_w3 first element: -0.0024261474609375
WARNING 01-07 10:14:00.077168.077168 mlpmodule.py:828] start einsum2
DEBUG 01-07 10:14:00.097447.097447 mlpmodule.py:838] group einsum cost 0.030426025390625 s
DEBUG 01-07 10:14:00.097631.097631 mlpmodule.py:846] cpy2cputensor cost 0.00034880638122558594 s
DEBUG 01-07 10:14:00.100029.100029 cuda_h.py:19] end wait_cetm_experts cost 0.04151034355163574 seconds
DEBUG 01-07 10:14:00.100674.100674 cuda_h.py:10] start gpu_sexperts
DEBUG 01-07 10:14:00.100071.100071 cuda_h.py:19] end gpu_sexperts cost 0.0005314350128173828 seconds
DEBUG 01-07 10:14:00.100000.100000 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-07 10:14:00.100942.100942 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.288818359375e-05 seconds
DEBUG 01-07 10:14:00.100314.100314 cuda_h.py:10] start wait_experts_multi_device
INFO 01-07 10:14:00.101693.101693 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 1911aaa2-0f3e-4f72-a70e-650dd6265c26
INFO 01-07 10:14:00.102738.102738 client.py:127] Model loaded
INFO 01-07 10:14:00.102197.102197 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 571916f7-ecb5-43d2-8067-33613fe2a86c
INFO 01-07 10:14:00.103436.103436 client.py:127] Model loaded
DEBUG 01-07 10:14:00.103073.103073 cuda_h.py:19] end wait_experts_multi_device cost 0.002073526382446289 seconds
DEBUG 01-07 10:14:00.103445.103445 cuda_h.py:10] start gpu_experts_multi_device
DEBUG 01-07 10:14:00.103029.103029 lmp.py:867]   Computing 23 experts on cuda:2...
DEBUG 01-07 10:14:00.104054.104054 mlpmodule.py:533] gpu group tensors cost 0.0004773139953613281 s
DEBUG 01-07 10:14:00.105027.105027 mlpmodule.py:566] gpu pad cost 0.001287698745727539 s
DEBUG 01-07 10:14:00.106287.106287 mlpmodule.py:584] gpu group einsum cost 0.0005762577056884766 s
DEBUG 01-07 10:14:00.108818.108818 mlpmodule.py:656] gpu experts func einsum cost 0.004482746124267578 s
DEBUG 01-07 10:14:00.108793.108793 mlpmodule.py:707]  experts func einsum cost 0.049828529357910156 s
DEBUG 01-07 10:14:00.108162.108162 lmp.py:867]   Computing 22 experts on cuda:1...
DEBUG 01-07 10:14:00.109610.109610 mlpmodule.py:533] gpu group tensors cost 0.00041794776916503906 s
DEBUG 01-07 10:14:00.110625.110625 mlpmodule.py:566] gpu pad cost 0.0011839866638183594 s
DEBUG 01-07 10:14:00.111745.111745 mlpmodule.py:584] gpu group einsum cost 0.0007593631744384766 s
DEBUG 01-07 10:14:00.113516.113516 mlpmodule.py:656] gpu experts func einsum cost 0.004351377487182617 s
DEBUG 01-07 10:14:00.113599.113599 cuda_h.py:19] end gpu_experts_multi_device cost 0.010303497314453125 seconds
DEBUG 01-07 10:14:00.113277.113277 cuda_h.py:19] end layer_moe_generate_multi_device_26 cost 0.06502532958984375 seconds
DEBUG 01-07 10:14:00.113351.113351 lmp.py:194] -------------------------------- end prefill layer 26 --------------------------------
DEBUG 01-07 10:14:00.113028.113028 lmp.py:153] -------------------------------- start prefill layer 27 --------------------------------
DEBUG 01-07 10:14:00.113486.113486 cuda_h.py:10] start start_load_qkvogn_s_weight_l_28
DEBUG 01-07 10:14:00.113441.113441 cuda_h.py:19] end start_load_qkvogn_s_weight_l_28 cost 1.049041748046875e-05 seconds
DEBUG 01-07 10:14:00.113660.113660 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-07 10:14:00.113304.113304 mlpmodule.py:367] cuda:1 cuda:1
DEBUG 01-07 10:14:00.114770.114770 cuda_h.py:10] start self_attn
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-07 10:14:00.116791.116791 cuda_h.py:19] end self_attn cost 0.002562999725341797 seconds
DEBUG 01-07 10:14:00.117338.117338 cuda_h.py:19] end iln_self_attn_paln cost 0.003209352493286133 seconds
DEBUG 01-07 10:14:00.117876.117876 cuda_h.py:10] start layer_moe_generate_multi_device_27
DEBUG 01-07 10:14:00.117539.117539 cuda_h.py:10] start gate
DEBUG 01-07 10:14:00.117314.117314 cuda_h.py:19] end gate cost 0.0005738735198974609 seconds
DEBUG 01-07 10:14:00.117998.117998 cuda_h.py:10] start experts_map_get
DEBUG 01-07 10:14:00.118064.118064 lmp.py:744] 
DEBUG 01-07 10:14:00.118064.118064 lmp.py:744] Expert Token Distribution & Multi-Device Allocation:
DEBUG 01-07 10:14:00.118536.118536 lmp.py:745]   Total experts: 64
DEBUG 01-07 10:14:00.118901.118901 lmp.py:746]   CPU experts: 19 (30%)
DEBUG 01-07 10:14:00.118689.118689 lmp.py:747]   GPU experts: 45 (70%)
DEBUG 01-07 10:14:00.118856.118856 lmp.py:748]   Number of GPU devices: 2
DEBUG 01-07 10:14:00.118306.118306 lmp.py:749] 
DEBUG 01-07 10:14:00.118306.118306 lmp.py:749]   Expert ID | Tokens | Device
DEBUG 01-07 10:14:00.118996.118996 lmp.py:750]   -----------------------------------
DEBUG 01-07 10:14:00.118361.118361 lmp.py:767]   Expert 18 |     66 | CPU
DEBUG 01-07 10:14:00.118765.118765 lmp.py:767]   Expert 54 |     70 | CPU
DEBUG 01-07 10:14:00.118455.118455 lmp.py:767]   Expert 47 |     71 | CPU
DEBUG 01-07 10:14:00.118667.118667 lmp.py:767]   Expert 23 |     75 | CPU
DEBUG 01-07 10:14:00.118641.118641 lmp.py:767]   Expert 44 |     82 | CPU
DEBUG 01-07 10:14:00.118854.118854 lmp.py:767]   Expert 48 |     83 | CPU
DEBUG 01-07 10:14:00.118828.118828 lmp.py:767]   Expert 45 |     87 | CPU
DEBUG 01-07 10:14:00.118755.118755 lmp.py:767]   Expert 20 |     92 | CPU
DEBUG 01-07 10:14:00.118206.118206 lmp.py:767]   Expert 31 |     96 | CPU
DEBUG 01-07 10:14:00.118657.118657 lmp.py:767]   Expert 36 |    109 | CPU
DEBUG 01-07 10:14:00.118631.118631 lmp.py:767]   Expert 33 |    118 | CPU
DEBUG 01-07 10:14:00.118082.118082 lmp.py:767]   Expert 61 |    119 | CPU
DEBUG 01-07 10:14:00.118533.118533 lmp.py:767]   Expert 42 |    121 | CPU
DEBUG 01-07 10:14:00.118745.118745 lmp.py:767]   Expert 10 |    123 | CPU
DEBUG 01-07 10:14:00.118719.118719 lmp.py:767]   Expert 24 |    123 | CPU
DEBUG 01-07 10:14:00.118409.118409 lmp.py:767]   Expert 43 |    124 | CPU
DEBUG 01-07 10:14:00.118098.118098 lmp.py:767]   Expert 49 |    128 | CPU
DEBUG 01-07 10:14:00.118787.118787 lmp.py:767]   Expert 56 |    131 | CPU
DEBUG 01-07 10:14:00.118761.118761 lmp.py:767]   Expert 11 |    132 | CPU
DEBUG 01-07 10:14:00.118643.118643 lmp.py:767]   Expert  6 |    136 | GPU1(cuda:2)
DEBUG 01-07 10:14:00.118286.118286 lmp.py:767]   Expert 51 |    141 | GPU0(cuda:1)
DEBUG 01-07 10:14:00.118690.118690 lmp.py:767]   Expert 17 |    149 | GPU1(cuda:2)
DEBUG 01-07 10:14:00.118572.118572 lmp.py:767]   Expert  0 |    150 | GPU0(cuda:1)
DEBUG 01-07 10:14:00.118215.118215 lmp.py:767]   Expert  5 |    152 | GPU1(cuda:2)
DEBUG 01-07 10:14:00.118096.118096 lmp.py:767]   Expert 12 |    156 | GPU0(cuda:1)
DEBUG 01-07 10:14:00.118739.118739 lmp.py:767]   Expert 40 |    157 | GPU1(cuda:2)
DEBUG 01-07 10:14:00.118905.118905 lmp.py:767]   Expert 57 |    158 | GPU0(cuda:1)
DEBUG 01-07 10:14:00.118071.118071 lmp.py:767]   Expert 55 |    161 | GPU1(cuda:2)
DEBUG 01-07 10:14:00.118237.118237 lmp.py:767]   Expert 59 |    162 | GPU0(cuda:1)
DEBUG 01-07 10:14:00.118165.118165 lmp.py:767]   Expert 26 |    163 | GPU1(cuda:2)
DEBUG 01-07 10:14:00.118331.118331 lmp.py:767]   Expert 46 |    168 | GPU0(cuda:1)
DEBUG 01-07 10:14:00.118736.118736 lmp.py:767]   Expert 38 |    170 | GPU1(cuda:2)
DEBUG 01-07 10:14:00.118379.118379 lmp.py:767]   Expert 13 |    171 | GPU1(cuda:2)
DEBUG 01-07 10:14:00.118068.118068 lmp.py:767]   Expert 58 |    171 | GPU0(cuda:1)
DEBUG 01-07 10:14:00.118234.118234 lmp.py:767]   Expert 35 |    173 | GPU0(cuda:1)
DEBUG 01-07 10:14:00.118400.118400 lmp.py:767]   Expert 50 |    174 | GPU1(cuda:2)
DEBUG 01-07 10:14:00.118328.118328 lmp.py:767]   Expert 30 |    176 | GPU0(cuda:1)
DEBUG 01-07 10:14:00.119256.119256 lmp.py:767]   Expert  7 |    179 | GPU1(cuda:2)
DEBUG 01-07 10:14:00.119422.119422 lmp.py:767]   Expert 16 |    182 | GPU0(cuda:1)
DEBUG 01-07 10:14:00.119350.119350 lmp.py:767]   Expert 15 |    201 | GPU0(cuda:1)
DEBUG 01-07 10:14:00.119039.119039 lmp.py:767]   Expert 32 |    201 | GPU1(cuda:2)
DEBUG 01-07 10:14:00.119967.119967 lmp.py:767]   Expert 14 |    203 | GPU1(cuda:2)
DEBUG 01-07 10:14:00.119610.119610 lmp.py:767]   Expert  1 |    216 | GPU1(cuda:2)
DEBUG 01-07 10:14:00.119253.119253 lmp.py:767]   Expert  3 |    216 | GPU0(cuda:1)
DEBUG 01-07 10:14:00.119657.119657 lmp.py:767]   Expert  4 |    228 | GPU0(cuda:1)
DEBUG 01-07 10:14:00.119585.119585 lmp.py:767]   Expert 39 |    236 | GPU1(cuda:2)
DEBUG 01-07 10:14:00.119751.119751 lmp.py:767]   Expert 34 |    240 | GPU0(cuda:1)
DEBUG 01-07 10:14:00.119156.119156 lmp.py:767]   Expert 52 |    244 | GPU1(cuda:2)
DEBUG 01-07 10:14:00.119560.119560 lmp.py:767]   Expert 28 |    246 | GPU0(cuda:1)
DEBUG 01-07 10:14:00.119203.119203 lmp.py:767]   Expert 22 |    254 | GPU1(cuda:2)
DEBUG 01-07 10:14:00.119131.119131 lmp.py:767]   Expert 25 |    257 | GPU0(cuda:1)
DEBUG 01-07 10:14:00.119059.119059 lmp.py:767]   Expert  2 |    273 | GPU1(cuda:2)
DEBUG 01-07 10:14:00.119986.119986 lmp.py:767]   Expert 21 |    280 | GPU0(cuda:1)
DEBUG 01-07 10:14:00.119676.119676 lmp.py:767]   Expert 41 |    283 | GPU1(cuda:2)
DEBUG 01-07 10:14:00.119603.119603 lmp.py:767]   Expert 60 |    284 | GPU0(cuda:1)
DEBUG 01-07 10:14:00.119531.119531 lmp.py:767]   Expert 62 |    288 | GPU1(cuda:2)
DEBUG 01-07 10:14:00.119459.119459 lmp.py:767]   Expert 29 |    294 | GPU1(cuda:2)
DEBUG 01-07 10:14:00.119387.119387 lmp.py:767]   Expert 63 |    294 | GPU0(cuda:1)
DEBUG 01-07 10:14:00.119076.119076 lmp.py:767]   Expert 27 |    300 | GPU0(cuda:1)
DEBUG 01-07 10:14:00.119480.119480 lmp.py:767]   Expert 37 |    330 | GPU1(cuda:2)
DEBUG 01-07 10:14:00.119839.119839 lmp.py:767]   Expert 53 |    332 | GPU0(cuda:1)
DEBUG 01-07 10:14:00.119958.119958 lmp.py:767]   Expert  8 |    334 | GPU1(cuda:2)
DEBUG 01-07 10:14:00.119601.119601 lmp.py:767]   Expert 19 |    444 | GPU1(cuda:2)
DEBUG 01-07 10:14:00.119768.119768 lmp.py:767]   Expert  9 |    611 | GPU0(cuda:1)
DEBUG 01-07 10:14:00.119742.119742 lmp.py:769] 
DEBUG 01-07 10:14:00.119742.119742 lmp.py:769]   Device Token Distribution:
DEBUG 01-07 10:14:00.119431.119431 lmp.py:770]   CPU:   1950 tokens
DEBUG 01-07 10:14:00.119312.119312 lmp.py:774]   cuda:1:   5126 tokens (22 experts)
DEBUG 01-07 10:14:00.119763.119763 lmp.py:774]   cuda:2:   5212 tokens (23 experts)
DEBUG 01-07 10:14:00.119976.119976 lmp.py:775]   Total GPU:  10338 tokens
DEBUG 01-07 10:14:00.119665.119665 lmp.py:776] ============================================================
DEBUG 01-07 10:14:00.119665.119665 lmp.py:776] 
DEBUG 01-07 10:14:00.119315.119315 cuda_h.py:19] end experts_map_get cost 0.001714468002319336 seconds
DEBUG 01-07 10:14:00.119958.119958 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model_multi_device
DEBUG 01-07 10:14:00.119542.119542 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 10:14:00.119731.119731 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 10:14:00.120422.120422 cuda_h.py:19] end allocate_cuda_memory cost 0.000232696533203125 seconds
DEBUG 01-07 10:14:00.120219.120219 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 10:14:00.120544.120544 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 10:14:00.120360.120360 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 10:14:00.120487.120487 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 402e1676-a851-4fc4-ae49-6cbac43216aa
DEBUG 01-07 10:14:00.120260.120260 client.py:106] call stub.LoadModelAsync
INFO 01-07 10:14:00.121097.121097 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 402e1676-a851-4fc4-ae49-6cbac43216aa
DEBUG 01-07 10:14:00.121357.121357 cuda_h.py:19] end load_into_gpu_async cost 0.001125335693359375 seconds
DEBUG 01-07 10:14:00.121629.121629 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 10:14:00.121823.121823 cuda_h.py:19] end restore_tensors2 cost 0.00022482872009277344 seconds
DEBUG 01-07 10:14:00.121970.121970 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0018739700317382812 seconds
DEBUG 01-07 10:14:00.123323.123323 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 10:14:00.123486.123486 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 10:14:00.123633.123633 cuda_h.py:19] end allocate_cuda_memory cost 0.00021123886108398438 seconds
DEBUG 01-07 10:14:00.123377.123377 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 10:14:00.123656.123656 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 10:14:00.123465.123465 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 10:14:00.123353.123353 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 9da5955c-daae-4a11-be21-f88156cc8c2e
DEBUG 01-07 10:14:00.124252.124252 client.py:106] call stub.LoadModelAsync
INFO 01-07 10:14:00.124325.124325 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 9da5955c-daae-4a11-be21-f88156cc8c2e
DEBUG 01-07 10:14:00.124677.124677 cuda_h.py:19] end load_into_gpu_async cost 0.0010333061218261719 seconds
DEBUG 01-07 10:14:00.124281.124281 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 10:14:00.125778.125778 cuda_h.py:19] end restore_tensors2 cost 0.00020265579223632812 seconds
DEBUG 01-07 10:14:00.125117.125117 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.001733541488647461 seconds
DEBUG 01-07 10:14:00.126232.126232 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model_multi_device cost 0.007374763488769531 seconds
DEBUG 01-07 10:14:00.127432.127432 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-07 10:14:00.127872.127872 lmp.py:816] 
DEBUG 01-07 10:14:00.127872.127872 lmp.py:816]   Computing 19 experts on CPU...
DEBUG 01-07 10:14:00.127377.127377 cuda_h.py:19] end cpu_experts_submit cost 0.00010704994201660156 seconds
DEBUG 01-07 10:14:00.127265.127265 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-07 10:14:00.132489.132489 mlpmodule.py:749] group tensors cost 0.005163669586181641 s
DEBUG 01-07 10:14:00.134053.134053 mlpmodule.py:787] pad cost 0.0012669563293457031 s
DEBUG 01-07 10:14:00.134779.134779 mlpmodule.py:793] create cpu tensor cost 4.673004150390625e-05 s
DEBUG 01-07 10:14:00.134140.134140 mlpmodule.py:798] move to cpu cost 4.506111145019531e-05 s
DEBUG 01-07 10:14:00.145923.145923 mlpmodule.py:812] group_w3: shape=torch.Size([19, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=54788096
DEBUG 01-07 10:14:00.145353.145353 mlpmodule.py:813] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-07 10:14:00.145780.145780 mlpmodule.py:818] group_w3 first element: -0.01263427734375
WARNING 01-07 10:14:00.145764.145764 mlpmodule.py:828] start einsum2
DEBUG 01-07 10:14:00.167991.167991 mlpmodule.py:838] group einsum cost 0.03284740447998047 s
DEBUG 01-07 10:14:00.168375.168375 mlpmodule.py:846] cpy2cputensor cost 0.0004112720489501953 s
DEBUG 01-07 10:14:00.170369.170369 cuda_h.py:19] end wait_cetm_experts cost 0.043608903884887695 seconds
DEBUG 01-07 10:14:00.170730.170730 cuda_h.py:10] start gpu_sexperts
DEBUG 01-07 10:14:00.171616.171616 cuda_h.py:19] end gpu_sexperts cost 0.0005030632019042969 seconds
DEBUG 01-07 10:14:00.171220.171220 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-07 10:14:00.171434.171434 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 1.2159347534179688e-05 seconds
DEBUG 01-07 10:14:00.171329.171329 cuda_h.py:10] start wait_experts_multi_device
INFO 01-07 10:14:00.171807.171807 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 402e1676-a851-4fc4-ae49-6cbac43216aa
INFO 01-07 10:14:00.172697.172697 client.py:127] Model loaded
INFO 01-07 10:14:00.172434.172434 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 9da5955c-daae-4a11-be21-f88156cc8c2e
INFO 01-07 10:14:00.172931.172931 client.py:127] Model loaded
DEBUG 01-07 10:14:00.173614.173614 cuda_h.py:19] end wait_experts_multi_device cost 0.0013704299926757812 seconds
DEBUG 01-07 10:14:00.173748.173748 cuda_h.py:10] start gpu_experts_multi_device
DEBUG 01-07 10:14:00.173902.173902 lmp.py:867]   Computing 23 experts on cuda:2...
DEBUG 01-07 10:14:00.174807.174807 mlpmodule.py:533] gpu group tensors cost 0.0004668235778808594 s
DEBUG 01-07 10:14:00.175016.175016 mlpmodule.py:566] gpu pad cost 0.0012538433074951172 s
DEBUG 01-07 10:14:00.176992.176992 mlpmodule.py:584] gpu group einsum cost 0.0004076957702636719 s
DEBUG 01-07 10:14:00.177466.177466 mlpmodule.py:656] gpu experts func einsum cost 0.004149675369262695 s
DEBUG 01-07 10:14:00.178522.178522 lmp.py:867]   Computing 22 experts on cuda:1...
DEBUG 01-07 10:14:00.178665.178665 mlpmodule.py:533] gpu group tensors cost 0.00042176246643066406 s
DEBUG 01-07 10:14:00.179234.179234 mlpmodule.py:707]  experts func einsum cost 0.05175948143005371 s
DEBUG 01-07 10:14:00.180829.180829 mlpmodule.py:566] gpu pad cost 0.0012907981872558594 s
DEBUG 01-07 10:14:00.180763.180763 mlpmodule.py:584] gpu group einsum cost 0.0005049705505371094 s
DEBUG 01-07 10:14:00.182231.182231 mlpmodule.py:656] gpu experts func einsum cost 0.0042803287506103516 s
DEBUG 01-07 10:14:00.182023.182023 cuda_h.py:19] end gpu_experts_multi_device cost 0.009759902954101562 seconds
DEBUG 01-07 10:14:00.182184.182184 cuda_h.py:19] end layer_moe_generate_multi_device_27 cost 0.06575250625610352 seconds
DEBUG 01-07 10:14:00.183762.183762 lmp.py:194] -------------------------------- end prefill layer 27 --------------------------------
DEBUG 01-07 10:14:00.183029.183029 cuda_h.py:19] end prefill_layer cost 2.6846513748168945 seconds
DEBUG 01-07 10:14:02.373438.373438 cuda_h.py:10] start generate_input_ids
generate input ids cost 0.09838986396789551 s
DEBUG 01-07 10:14:02.727782.727782 cuda_h.py:19] end generate_input_ids cost 0.35252857208251953 seconds
DEBUG 01-07 10:14:02.727939.727939 cuda_h.py:10] start init_cache
DEBUG 01-07 10:14:02.727797.727797 cuda_h.py:19] end init_cache cost 5.0067901611328125e-05 seconds
DEBUG 01-07 10:14:05.216170.216170 cuda_h.py:10] start init_weights
DEBUG 01-07 10:14:05.217642.217642 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 10:14:05.218083.218083 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 10:14:05.219903.219903 cuda_h.py:19] end allocate_cuda_memory cost 0.0010116100311279297 seconds
DEBUG 01-07 10:14:05.219852.219852 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 10:14:05.219277.219277 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 10:14:05.219815.219815 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 10:14:05.219803.219803 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 95581e4f-f627-4c88-956e-77cfaa09a73f
DEBUG 01-07 10:14:05.219150.219150 client.py:106] call stub.LoadModelAsync
INFO 01-07 10:14:05.222699.222699 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 95581e4f-f627-4c88-956e-77cfaa09a73f
DEBUG 01-07 10:14:05.222343.222343 cuda_h.py:19] end load_into_gpu_async cost 0.0023653507232666016 seconds
DEBUG 01-07 10:14:05.222185.222185 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 10:14:05.222247.222247 cuda_h.py:19] end restore_tensors2 cost 5.4836273193359375e-05 seconds
DEBUG 01-07 10:14:05.222666.222666 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0039594173431396484 seconds
INFO 01-07 10:14:05.222208.222208 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 95581e4f-f627-4c88-956e-77cfaa09a73f
INFO 01-07 10:14:05.299432.299432 client.py:127] Model loaded
DEBUG 01-07 10:14:05.300165.300165 cuda_h.py:10] start load_qkvogns_weight_l_0
DEBUG 01-07 10:14:05.300766.300766 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 10:14:05.300445.300445 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 10:14:05.300600.300600 cuda_h.py:19] end allocate_cuda_memory cost 0.0003762245178222656 seconds
DEBUG 01-07 10:14:05.300128.300128 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 10:14:05.300097.300097 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 10:14:05.301134.301134 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 10:14:05.301706.301706 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 6062cdef-4764-4bcc-a646-864b2e0d26f6
DEBUG 01-07 10:14:05.301175.301175 client.py:106] call stub.LoadModelAsync
INFO 01-07 10:14:05.302511.302511 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 6062cdef-4764-4bcc-a646-864b2e0d26f6
DEBUG 01-07 10:14:05.302012.302012 cuda_h.py:19] end load_into_gpu_async cost 0.0014064311981201172 seconds
DEBUG 01-07 10:14:05.302438.302438 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 10:14:05.302339.302339 cuda_h.py:19] end restore_tensors2 cost 0.00013637542724609375 seconds
DEBUG 01-07 10:14:05.302740.302740 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0024976730346679688 seconds
INFO 01-07 10:14:05.302596.302596 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 6062cdef-4764-4bcc-a646-864b2e0d26f6
INFO 01-07 10:14:05.319447.319447 client.py:127] Model loaded
DEBUG 01-07 10:14:05.319224.319224 cuda_h.py:19] end load_qkvogns_weight_l_0 cost 0.0196533203125 seconds
DEBUG 01-07 10:14:05.319206.319206 cuda_h.py:19] end init_weights cost 0.10229778289794922 seconds
DEBUG 01-07 10:14:05.319584.319584 cuda_h.py:10] start copy_emodel
DEBUG 01-07 10:14:06.087019.087019 cuda_h.py:19] end copy_emodel cost 0.7672231197357178 seconds
DEBUG 01-07 10:14:06.088813.088813 cuda_h.py:10] start init_hmv
DEBUG 01-07 10:14:06.229668.229668 mlpmodule.py:207] restore_hm_state_dict2model loaded 5265 expert tensors (including shared_experts) for Deepseek model
DEBUG 01-07 10:14:06.230459.230459 cuda_h.py:19] end init_hmv cost 0.14224839210510254 seconds
DEBUG 01-07 10:14:06.230050.230050 cuda_h.py:10] start init_inputs_tokens
DEBUG 01-07 10:14:06.230770.230770 cuda_h.py:19] end init_inputs_tokens cost 0.00028967857360839844 seconds
DEBUG 01-07 10:14:06.230016.230016 cuda_h.py:10] start prefill_layer
DEBUG 01-07 10:14:06.230779.230779 lmp.py:153] -------------------------------- start prefill layer 0 --------------------------------
DEBUG 01-07 10:14:06.230760.230760 cuda_h.py:10] start start_load_qkvogn_s_weight_l_1
DEBUG 01-07 10:14:06.230794.230794 cuda_h.py:10] start start_load_qkvogn_s_weight_l_1
DEBUG 01-07 10:14:06.231306.231306 cuda_h.py:19] end start_load_qkvogn_s_weight_l_1 cost 3.4332275390625e-05 seconds
DEBUG 01-07 10:14:06.231624.231624 cuda_h.py:19] end start_load_qkvogn_s_weight_l_1 cost 6.508827209472656e-05 seconds
DEBUG 01-07 10:14:06.231744.231744 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-07 10:14:06.231587.231587 mlpmodule.py:367] cuda:1 cuda:1
DEBUG 01-07 10:14:06.231411.231411 cuda_h.py:10] start sllm_worker_task
DEBUG 01-07 10:14:06.231760.231760 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 10:14:06.231233.231233 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 10:14:06.231681.231681 cuda_h.py:19] end allocate_cuda_memory cost 0.00028395652770996094 seconds
DEBUG 01-07 10:14:06.231956.231956 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 10:14:06.231017.231017 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 10:14:06.231284.231284 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 10:14:06.232093.232093 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 45f49ff5-c02d-49cb-9945-4954497993d8
DEBUG 01-07 10:14:06.232898.232898 client.py:106] call stub.LoadModelAsync
DEBUG 01-07 10:14:06.232019.232019 cuda_h.py:10] start self_attn
INFO 01-07 10:14:06.233672.233672 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 45f49ff5-c02d-49cb-9945-4954497993d8
DEBUG 01-07 10:14:06.233285.233285 cuda_h.py:19] end load_into_gpu_async cost 0.0016677379608154297 seconds
DEBUG 01-07 10:14:06.233644.233644 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 10:14:06.233338.233338 cuda_h.py:19] end restore_tensors2 cost 0.00010585784912109375 seconds
DEBUG 01-07 10:14:06.233652.233652 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.002436399459838867 seconds
INFO 01-07 10:14:06.233197.233197 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 45f49ff5-c02d-49cb-9945-4954497993d8
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-07 10:14:06.235080.235080 cuda_h.py:19] end self_attn cost 0.0033512115478515625 seconds
DEBUG 01-07 10:14:06.236779.236779 cuda_h.py:19] end iln_self_attn_paln cost 0.004978656768798828 seconds
DEBUG 01-07 10:14:06.236748.236748 cuda_h.py:10] start dense_mlp
INFO 01-07 10:14:06.242260.242260 client.py:127] Model loaded
DEBUG 01-07 10:14:06.243903.243903 cuda_h.py:19] end sllm_worker_task cost 0.011968374252319336 seconds
DEBUG 01-07 10:14:06.243545.243545 cuda_h.py:19] end dense_mlp cost 0.007358551025390625 seconds
DEBUG 01-07 10:14:06.243483.243483 lmp.py:194] -------------------------------- end prefill layer 0 --------------------------------
DEBUG 01-07 10:14:06.243936.243936 lmp.py:153] -------------------------------- start prefill layer 1 --------------------------------
DEBUG 01-07 10:14:06.243632.243632 cuda_h.py:10] start start_load_qkvogn_s_weight_l_2
DEBUG 01-07 10:14:06.243672.243672 cuda_h.py:10] start start_load_qkvogn_s_weight_l_2
DEBUG 01-07 10:14:06.243879.243879 cuda_h.py:19] end start_load_qkvogn_s_weight_l_2 cost 2.288818359375e-05 seconds
DEBUG 01-07 10:14:06.243105.243105 cuda_h.py:19] end start_load_qkvogn_s_weight_l_2 cost 5.1975250244140625e-05 seconds
DEBUG 01-07 10:14:06.243656.243656 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-07 10:14:06.243459.243459 mlpmodule.py:367] cuda:1 cuda:1
DEBUG 01-07 10:14:06.244739.244739 cuda_h.py:10] start sllm_worker_task
DEBUG 01-07 10:14:06.244160.244160 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 10:14:06.244925.244925 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 10:14:06.244282.244282 cuda_h.py:19] end allocate_cuda_memory cost 0.0002732276916503906 seconds
DEBUG 01-07 10:14:06.244949.244949 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 10:14:06.244004.244004 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 10:14:06.244941.244941 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 10:14:06.244599.244599 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, d5c79856-ace3-459c-ba7d-51308c8c4cf5
DEBUG 01-07 10:14:06.245895.245895 client.py:106] call stub.LoadModelAsync
DEBUG 01-07 10:14:06.245126.245126 cuda_h.py:10] start self_attn
INFO 01-07 10:14:06.246692.246692 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, d5c79856-ace3-459c-ba7d-51308c8c4cf5
DEBUG 01-07 10:14:06.246994.246994 cuda_h.py:19] end load_into_gpu_async cost 0.0016739368438720703 seconds
DEBUG 01-07 10:14:06.246805.246805 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 10:14:06.246288.246288 cuda_h.py:19] end restore_tensors2 cost 0.00010657310485839844 seconds
DEBUG 01-07 10:14:06.246310.246310 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.002630949020385742 seconds
INFO 01-07 10:14:06.246228.246228 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, d5c79856-ace3-459c-ba7d-51308c8c4cf5
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-07 10:14:06.248165.248165 cuda_h.py:19] end self_attn cost 0.0030395984649658203 seconds
DEBUG 01-07 10:14:06.248644.248644 cuda_h.py:19] end iln_self_attn_paln cost 0.0047724246978759766 seconds
DEBUG 01-07 10:14:06.248566.248566 cuda_h.py:10] start layer_moe_generate_multi_device_1
DEBUG 01-07 10:14:06.248468.248468 cuda_h.py:10] start gate
DEBUG 01-07 10:14:06.249928.249928 cuda_h.py:19] end gate cost 0.0006568431854248047 seconds
DEBUG 01-07 10:14:06.249281.249281 cuda_h.py:10] start experts_map_get
DEBUG 01-07 10:14:06.249034.249034 lmp.py:744] 
DEBUG 01-07 10:14:06.249034.249034 lmp.py:744] Expert Token Distribution & Multi-Device Allocation:
DEBUG 01-07 10:14:06.249936.249936 lmp.py:745]   Total experts: 64
DEBUG 01-07 10:14:06.249347.249347 lmp.py:746]   CPU experts: 19 (30%)
DEBUG 01-07 10:14:06.249374.249374 lmp.py:747]   GPU experts: 45 (70%)
DEBUG 01-07 10:14:06.249733.249733 lmp.py:748]   Number of GPU devices: 2
DEBUG 01-07 10:14:06.249899.249899 lmp.py:749] 
DEBUG 01-07 10:14:06.249899.249899 lmp.py:749]   Expert ID | Tokens | Device
DEBUG 01-07 10:14:06.249780.249780 lmp.py:750]   -----------------------------------
DEBUG 01-07 10:14:06.250145.250145 lmp.py:767]   Expert 25 |     64 | CPU
DEBUG 01-07 10:14:06.250311.250311 lmp.py:767]   Expert 54 |     67 | CPU
DEBUG 01-07 10:14:06.250001.250001 lmp.py:767]   Expert  3 |     68 | CPU
DEBUG 01-07 10:14:06.250452.250452 lmp.py:767]   Expert 31 |     72 | CPU
DEBUG 01-07 10:14:06.250187.250187 lmp.py:767]   Expert 55 |     72 | CPU
DEBUG 01-07 10:14:06.250400.250400 lmp.py:767]   Expert 62 |     87 | CPU
DEBUG 01-07 10:14:06.250374.250374 lmp.py:767]   Expert 18 |     88 | CPU
DEBUG 01-07 10:14:06.250348.250348 lmp.py:767]   Expert 52 |     98 | CPU
DEBUG 01-07 10:14:06.250322.250322 lmp.py:767]   Expert 22 |    100 | CPU
DEBUG 01-07 10:14:06.250057.250057 lmp.py:767]   Expert 47 |    104 | CPU
DEBUG 01-07 10:14:06.250224.250224 lmp.py:767]   Expert  0 |    113 | CPU
DEBUG 01-07 10:14:06.250012.250012 lmp.py:767]   Expert 37 |    117 | CPU
DEBUG 01-07 10:14:06.250225.250225 lmp.py:767]   Expert 27 |    121 | CPU
DEBUG 01-07 10:14:06.250199.250199 lmp.py:767]   Expert 32 |    123 | CPU
DEBUG 01-07 10:14:06.250173.250173 lmp.py:767]   Expert 41 |    130 | CPU
DEBUG 01-07 10:14:06.250908.250908 lmp.py:767]   Expert 44 |    131 | CPU
DEBUG 01-07 10:14:06.250883.250883 lmp.py:767]   Expert 28 |    136 | CPU
DEBUG 01-07 10:14:06.250618.250618 lmp.py:767]   Expert 13 |    138 | CPU
DEBUG 01-07 10:14:06.250354.250354 lmp.py:767]   Expert 58 |    140 | CPU
DEBUG 01-07 10:14:06.250758.250758 lmp.py:767]   Expert 60 |    144 | GPU0(cuda:1)
DEBUG 01-07 10:14:06.250924.250924 lmp.py:767]   Expert 43 |    147 | GPU1(cuda:2)
DEBUG 01-07 10:14:06.250091.250091 lmp.py:767]   Expert  1 |    150 | GPU0(cuda:1)
DEBUG 01-07 10:14:06.250495.250495 lmp.py:767]   Expert 38 |    153 | GPU1(cuda:2)
DEBUG 01-07 10:14:06.250522.250522 lmp.py:767]   Expert 49 |    154 | GPU0(cuda:1)
DEBUG 01-07 10:14:06.250834.250834 lmp.py:767]   Expert 51 |    155 | GPU0(cuda:1)
DEBUG 01-07 10:14:06.250623.250623 lmp.py:767]   Expert 34 |    161 | GPU1(cuda:2)
DEBUG 01-07 10:14:06.250504.250504 lmp.py:767]   Expert 35 |    164 | GPU0(cuda:1)
DEBUG 01-07 10:14:06.250386.250386 lmp.py:767]   Expert 36 |    168 | GPU1(cuda:2)
DEBUG 01-07 10:14:06.250029.250029 lmp.py:767]   Expert 11 |    170 | GPU1(cuda:2)
DEBUG 01-07 10:14:06.250864.250864 lmp.py:767]   Expert 17 |    170 | GPU0(cuda:1)
DEBUG 01-07 10:14:06.250745.250745 lmp.py:767]   Expert 59 |    174 | GPU1(cuda:2)
DEBUG 01-07 10:14:06.250150.250150 lmp.py:767]   Expert 10 |    180 | GPU0(cuda:1)
DEBUG 01-07 10:14:06.250793.250793 lmp.py:767]   Expert 20 |    182 | GPU0(cuda:1)
DEBUG 01-07 10:14:06.250674.250674 lmp.py:767]   Expert  2 |    186 | GPU1(cuda:2)
DEBUG 01-07 10:14:06.250556.250556 lmp.py:767]   Expert 39 |    189 | GPU0(cuda:1)
DEBUG 01-07 10:14:06.250437.250437 lmp.py:767]   Expert 33 |    197 | GPU1(cuda:2)
DEBUG 01-07 10:14:06.250510.250510 lmp.py:767]   Expert 12 |    198 | GPU0(cuda:1)
DEBUG 01-07 10:14:06.250822.250822 lmp.py:767]   Expert 21 |    198 | GPU1(cuda:2)
DEBUG 01-07 10:14:06.250465.250465 lmp.py:767]   Expert 48 |    198 | GPU0(cuda:1)
DEBUG 01-07 10:14:06.250585.250585 lmp.py:767]   Expert 15 |    199 | GPU1(cuda:2)
DEBUG 01-07 10:14:06.250990.250990 lmp.py:767]   Expert 53 |    204 | GPU1(cuda:2)
DEBUG 01-07 10:14:06.250871.250871 lmp.py:767]   Expert 19 |    220 | GPU0(cuda:1)
DEBUG 01-07 10:14:06.250514.250514 lmp.py:767]   Expert 26 |    221 | GPU0(cuda:1)
DEBUG 01-07 10:14:06.250919.250919 lmp.py:767]   Expert 30 |    221 | GPU0(cuda:1)
DEBUG 01-07 10:14:06.250800.250800 lmp.py:767]   Expert 45 |    221 | GPU1(cuda:2)
DEBUG 01-07 10:14:06.250158.250158 lmp.py:767]   Expert  5 |    227 | GPU1(cuda:2)
DEBUG 01-07 10:14:06.250278.250278 lmp.py:767]   Expert  4 |    229 | GPU1(cuda:2)
DEBUG 01-07 10:14:06.250159.250159 lmp.py:767]   Expert 24 |    229 | GPU0(cuda:1)
DEBUG 01-07 10:14:06.250041.250041 lmp.py:767]   Expert 42 |    242 | GPU1(cuda:2)
DEBUG 01-07 10:14:06.250922.250922 lmp.py:767]   Expert 50 |    245 | GPU0(cuda:1)
DEBUG 01-07 10:14:06.250804.250804 lmp.py:767]   Expert 29 |    254 | GPU0(cuda:1)
DEBUG 01-07 10:14:06.250447.250447 lmp.py:767]   Expert 56 |    262 | GPU1(cuda:2)
DEBUG 01-07 10:14:06.250520.250520 lmp.py:767]   Expert 61 |    270 | GPU0(cuda:1)
DEBUG 01-07 10:14:06.250594.250594 lmp.py:767]   Expert  8 |    283 | GPU1(cuda:2)
DEBUG 01-07 10:14:06.250058.250058 lmp.py:767]   Expert 63 |    285 | GPU0(cuda:1)
DEBUG 01-07 10:14:06.250701.250701 lmp.py:767]   Expert 46 |    294 | GPU1(cuda:2)
DEBUG 01-07 10:14:06.250390.250390 lmp.py:767]   Expert  9 |    300 | GPU0(cuda:1)
DEBUG 01-07 10:14:06.251603.251603 lmp.py:767]   Expert  6 |    316 | GPU0(cuda:1)
DEBUG 01-07 10:14:06.251054.251054 lmp.py:767]   Expert 16 |    316 | GPU1(cuda:2)
DEBUG 01-07 10:14:06.251981.251981 lmp.py:767]   Expert 40 |    319 | GPU1(cuda:2)
DEBUG 01-07 10:14:06.251432.251432 lmp.py:767]   Expert  7 |    322 | GPU0(cuda:1)
DEBUG 01-07 10:14:06.251122.251122 lmp.py:767]   Expert 23 |    325 | GPU1(cuda:2)
DEBUG 01-07 10:14:06.251572.251572 lmp.py:767]   Expert 14 |    413 | GPU1(cuda:2)
DEBUG 01-07 10:14:06.251262.251262 lmp.py:767]   Expert 57 |    464 | GPU0(cuda:1)
DEBUG 01-07 10:14:06.251951.251951 lmp.py:769] 
DEBUG 01-07 10:14:06.251951.251951 lmp.py:769]   Device Token Distribution:
DEBUG 01-07 10:14:06.251594.251594 lmp.py:770]   CPU:   1969 tokens
DEBUG 01-07 10:14:06.251191.251191 lmp.py:774]   cuda:1:   5231 tokens (23 experts)
DEBUG 01-07 10:14:06.251880.251880 lmp.py:774]   cuda:2:   5088 tokens (22 experts)
DEBUG 01-07 10:14:06.251854.251854 lmp.py:775]   Total GPU:  10319 tokens
DEBUG 01-07 10:14:06.251113.251113 lmp.py:776] ============================================================
DEBUG 01-07 10:14:06.251113.251113 lmp.py:776] 
DEBUG 01-07 10:14:06.251524.251524 cuda_h.py:19] end experts_map_get cost 0.0016956329345703125 seconds
DEBUG 01-07 10:14:06.251929.251929 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model_multi_device
DEBUG 01-07 10:14:06.251367.251367 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 10:14:06.251311.251311 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 10:14:06.252814.252814 cuda_h.py:19] end allocate_cuda_memory cost 0.0011446475982666016 seconds
DEBUG 01-07 10:14:06.252187.252187 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 10:14:06.252420.252420 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 10:14:06.252673.252673 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 10:14:06.252992.252992 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 7aab7a3b-0a78-4037-b0fb-1cd131eed919
DEBUG 01-07 10:14:06.252010.252010 client.py:106] call stub.LoadModelAsync
INFO 01-07 10:14:06.254116.254116 client.py:127] Model loaded
DEBUG 01-07 10:14:06.255436.255436 cuda_h.py:19] end sllm_worker_task cost 0.011011600494384766 seconds
INFO 01-07 10:14:06.255587.255587 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 7aab7a3b-0a78-4037-b0fb-1cd131eed919
DEBUG 01-07 10:14:06.255376.255376 cuda_h.py:19] end load_into_gpu_async cost 0.003055572509765625 seconds
DEBUG 01-07 10:14:06.255887.255887 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 10:14:06.256552.256552 cuda_h.py:19] end restore_tensors2 cost 0.0002536773681640625 seconds
DEBUG 01-07 10:14:06.256521.256521 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.004761934280395508 seconds
DEBUG 01-07 10:14:06.258083.258083 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 10:14:06.258028.258028 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 10:14:06.258794.258794 cuda_h.py:19] end allocate_cuda_memory cost 0.0004901885986328125 seconds
DEBUG 01-07 10:14:06.258445.258445 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 10:14:06.258486.258486 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 10:14:06.258911.258911 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 10:14:06.258799.258799 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 941a632c-9ea1-4e08-9674-11162f6fb8ca
DEBUG 01-07 10:14:06.258982.258982 client.py:106] call stub.LoadModelAsync
INFO 01-07 10:14:06.260621.260621 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 941a632c-9ea1-4e08-9674-11162f6fb8ca
DEBUG 01-07 10:14:06.260212.260212 cuda_h.py:19] end load_into_gpu_async cost 0.0019025802612304688 seconds
DEBUG 01-07 10:14:06.260815.260815 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 10:14:06.260738.260738 cuda_h.py:19] end restore_tensors2 cost 0.0002353191375732422 seconds
DEBUG 01-07 10:14:06.261991.261991 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0029234886169433594 seconds
DEBUG 01-07 10:14:06.262270.262270 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model_multi_device cost 0.01156759262084961 seconds
DEBUG 01-07 10:14:06.262915.262915 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-07 10:14:06.262838.262838 lmp.py:816] 
DEBUG 01-07 10:14:06.262838.262838 lmp.py:816]   Computing 19 experts on CPU...
DEBUG 01-07 10:14:06.263542.263542 cuda_h.py:19] end cpu_experts_submit cost 0.00011897087097167969 seconds
DEBUG 01-07 10:14:06.263099.263099 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-07 10:14:06.273879.273879 mlpmodule.py:749] group tensors cost 0.010597467422485352 s
DEBUG 01-07 10:14:06.276628.276628 mlpmodule.py:787] pad cost 0.0014157295227050781 s
DEBUG 01-07 10:14:06.276997.276997 mlpmodule.py:793] create cpu tensor cost 5.53131103515625e-05 s
DEBUG 01-07 10:14:06.276371.276371 mlpmodule.py:798] move to cpu cost 4.8160552978515625e-05 s
DEBUG 01-07 10:14:06.286746.286746 mlpmodule.py:812] group_w3: shape=torch.Size([19, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=54788096
DEBUG 01-07 10:14:06.286991.286991 mlpmodule.py:813] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-07 10:14:06.286418.286418 mlpmodule.py:818] group_w3 first element: -0.0107421875
WARNING 01-07 10:14:06.286833.286833 mlpmodule.py:828] start einsum2
DEBUG 01-07 10:14:06.301023.301023 mlpmodule.py:838] group einsum cost 0.024721860885620117 s
DEBUG 01-07 10:14:06.301005.301005 mlpmodule.py:846] cpy2cputensor cost 0.00046133995056152344 s
DEBUG 01-07 10:14:06.304217.304217 cuda_h.py:19] end wait_cetm_experts cost 0.041263580322265625 seconds
DEBUG 01-07 10:14:06.304460.304460 cuda_h.py:10] start gpu_sexperts
DEBUG 01-07 10:14:06.305405.305405 cuda_h.py:19] end gpu_sexperts cost 0.00051116943359375 seconds
DEBUG 01-07 10:14:06.305871.305871 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-07 10:14:06.305436.305436 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.5510787963867188e-05 seconds
DEBUG 01-07 10:14:06.305093.305093 cuda_h.py:10] start wait_experts_multi_device
INFO 01-07 10:14:06.305147.305147 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 7aab7a3b-0a78-4037-b0fb-1cd131eed919
INFO 01-07 10:14:06.306613.306613 client.py:127] Model loaded
INFO 01-07 10:14:06.306595.306595 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 941a632c-9ea1-4e08-9674-11162f6fb8ca
INFO 01-07 10:14:06.306603.306603 client.py:127] Model loaded
DEBUG 01-07 10:14:06.306293.306293 cuda_h.py:19] end wait_experts_multi_device cost 0.0014102458953857422 seconds
DEBUG 01-07 10:14:06.306619.306619 cuda_h.py:10] start gpu_experts_multi_device
DEBUG 01-07 10:14:06.306395.306395 lmp.py:867]   Computing 22 experts on cuda:2...
DEBUG 01-07 10:14:06.308675.308675 mlpmodule.py:533] gpu group tensors cost 0.0008847713470458984 s
DEBUG 01-07 10:14:06.310690.310690 mlpmodule.py:566] gpu pad cost 0.0013451576232910156 s
DEBUG 01-07 10:14:06.311136.311136 mlpmodule.py:584] gpu group einsum cost 0.0010004043579101562 s
DEBUG 01-07 10:14:06.312506.312506 mlpmodule.py:707]  experts func einsum cost 0.049546003341674805 s
DEBUG 01-07 10:14:06.313917.313917 mlpmodule.py:656] gpu experts func einsum cost 0.005346059799194336 s
DEBUG 01-07 10:14:06.313318.313318 lmp.py:867]   Computing 23 experts on cuda:1...
DEBUG 01-07 10:14:06.314870.314870 mlpmodule.py:533] gpu group tensors cost 0.0009469985961914062 s
DEBUG 01-07 10:14:06.316443.316443 mlpmodule.py:566] gpu pad cost 0.0012371540069580078 s
DEBUG 01-07 10:14:06.316754.316754 mlpmodule.py:584] gpu group einsum cost 0.0005202293395996094 s
DEBUG 01-07 10:14:06.318551.318551 mlpmodule.py:656] gpu experts func einsum cost 0.0044727325439453125 s
DEBUG 01-07 10:14:06.318494.318494 cuda_h.py:19] end gpu_experts_multi_device cost 0.011676788330078125 seconds
DEBUG 01-07 10:14:06.318172.318172 cuda_h.py:19] end layer_moe_generate_multi_device_1 cost 0.06969380378723145 seconds
DEBUG 01-07 10:14:06.318121.318121 lmp.py:194] -------------------------------- end prefill layer 1 --------------------------------
DEBUG 01-07 10:14:06.318712.318712 lmp.py:153] -------------------------------- start prefill layer 2 --------------------------------
DEBUG 01-07 10:14:06.318931.318931 cuda_h.py:10] start start_load_qkvogn_s_weight_l_3
DEBUG 01-07 10:14:06.318946.318946 cuda_h.py:10] start start_load_qkvogn_s_weight_l_3
DEBUG 01-07 10:14:06.318590.318590 cuda_h.py:19] end start_load_qkvogn_s_weight_l_3 cost 2.765655517578125e-05 seconds
DEBUG 01-07 10:14:06.318624.318624 cuda_h.py:19] end start_load_qkvogn_s_weight_l_3 cost 5.6743621826171875e-05 seconds
DEBUG 01-07 10:14:06.318982.318982 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-07 10:14:06.318918.318918 mlpmodule.py:367] cuda:1 cuda:1
DEBUG 01-07 10:14:06.319914.319914 cuda_h.py:10] start sllm_worker_task
DEBUG 01-07 10:14:06.319294.319294 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 10:14:06.319269.319269 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 10:14:06.319209.319209 cuda_h.py:19] end allocate_cuda_memory cost 0.00016927719116210938 seconds
DEBUG 01-07 10:14:06.319311.319311 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 10:14:06.319928.319928 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 10:14:06.319844.319844 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 10:14:06.319593.319593 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 8ad948cf-045d-4afb-b242-542e5d8d4901
DEBUG 01-07 10:14:06.319410.319410 client.py:106] call stub.LoadModelAsync
DEBUG 01-07 10:14:06.319233.319233 cuda_h.py:10] start self_attn
INFO 01-07 10:14:06.320484.320484 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 8ad948cf-045d-4afb-b242-542e5d8d4901
DEBUG 01-07 10:14:06.320174.320174 cuda_h.py:19] end load_into_gpu_async cost 0.0010237693786621094 seconds
DEBUG 01-07 10:14:06.320732.320732 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 10:14:06.320854.320854 cuda_h.py:19] end restore_tensors2 cost 6.413459777832031e-05 seconds
DEBUG 01-07 10:14:06.320941.320941 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.001499176025390625 seconds
INFO 01-07 10:14:06.320214.320214 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 8ad948cf-045d-4afb-b242-542e5d8d4901
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-07 10:14:06.323209.323209 cuda_h.py:19] end self_attn cost 0.0037763118743896484 seconds
DEBUG 01-07 10:14:06.324816.324816 cuda_h.py:19] end iln_self_attn_paln cost 0.005080223083496094 seconds
DEBUG 01-07 10:14:06.324407.324407 cuda_h.py:10] start layer_moe_generate_multi_device_2
DEBUG 01-07 10:14:06.324832.324832 cuda_h.py:10] start gate
DEBUG 01-07 10:14:06.324630.324630 cuda_h.py:19] end gate cost 0.0006604194641113281 seconds
DEBUG 01-07 10:14:06.324221.324221 cuda_h.py:10] start experts_map_get
DEBUG 01-07 10:14:06.325294.325294 lmp.py:744] 
DEBUG 01-07 10:14:06.325294.325294 lmp.py:744] Expert Token Distribution & Multi-Device Allocation:
DEBUG 01-07 10:14:06.325163.325163 lmp.py:745]   Total experts: 64
DEBUG 01-07 10:14:06.325435.325435 lmp.py:746]   CPU experts: 19 (30%)
DEBUG 01-07 10:14:06.325463.325463 lmp.py:747]   GPU experts: 45 (70%)
DEBUG 01-07 10:14:06.325106.325106 lmp.py:748]   Number of GPU devices: 2
DEBUG 01-07 10:14:06.325510.325510 lmp.py:749] 
DEBUG 01-07 10:14:06.325510.325510 lmp.py:749]   Expert ID | Tokens | Device
DEBUG 01-07 10:14:06.325676.325676 lmp.py:750]   -----------------------------------
DEBUG 01-07 10:14:06.325280.325280 lmp.py:767]   Expert 58 |     52 | CPU
DEBUG 01-07 10:14:06.325446.325446 lmp.py:767]   Expert 27 |     55 | CPU
DEBUG 01-07 10:14:06.325897.325897 lmp.py:767]   Expert  3 |     69 | CPU
DEBUG 01-07 10:14:06.325586.325586 lmp.py:767]   Expert 17 |     84 | CPU
DEBUG 01-07 10:14:06.325037.325037 lmp.py:767]   Expert 24 |     88 | CPU
DEBUG 01-07 10:14:06.325965.325965 lmp.py:767]   Expert  0 |     89 | CPU
DEBUG 01-07 10:14:06.325416.325416 lmp.py:767]   Expert 28 |    105 | CPU
DEBUG 01-07 10:14:06.325628.325628 lmp.py:767]   Expert 34 |    114 | CPU
DEBUG 01-07 10:14:06.325840.325840 lmp.py:767]   Expert 51 |    116 | CPU
DEBUG 01-07 10:14:06.325530.325530 lmp.py:767]   Expert 32 |    121 | CPU
DEBUG 01-07 10:14:06.325696.325696 lmp.py:767]   Expert  9 |    129 | CPU
DEBUG 01-07 10:14:06.325624.325624 lmp.py:767]   Expert  7 |    135 | CPU
DEBUG 01-07 10:14:06.325551.325551 lmp.py:767]   Expert 15 |    135 | CPU
DEBUG 01-07 10:14:06.325717.325717 lmp.py:767]   Expert 23 |    135 | CPU
DEBUG 01-07 10:14:06.325930.325930 lmp.py:767]   Expert 26 |    138 | CPU
DEBUG 01-07 10:14:06.325142.325142 lmp.py:767]   Expert 30 |    141 | CPU
DEBUG 01-07 10:14:06.325640.325640 lmp.py:767]   Expert 45 |    145 | CPU
DEBUG 01-07 10:14:06.325852.325852 lmp.py:767]   Expert 62 |    149 | CPU
DEBUG 01-07 10:14:06.325588.325588 lmp.py:767]   Expert 57 |    151 | CPU
DEBUG 01-07 10:14:06.325992.325992 lmp.py:767]   Expert  1 |    153 | GPU1(cuda:2)
DEBUG 01-07 10:14:06.325350.325350 lmp.py:767]   Expert 36 |    156 | GPU1(cuda:2)
DEBUG 01-07 10:14:06.325755.325755 lmp.py:767]   Expert  8 |    160 | GPU0(cuda:1)
DEBUG 01-07 10:14:06.325875.325875 lmp.py:767]   Expert 25 |    161 | GPU1(cuda:2)
DEBUG 01-07 10:14:06.325518.325518 lmp.py:767]   Expert 29 |    164 | GPU0(cuda:1)
DEBUG 01-07 10:14:06.325638.325638 lmp.py:767]   Expert 54 |    167 | GPU1(cuda:2)
DEBUG 01-07 10:14:06.325757.325757 lmp.py:767]   Expert  6 |    168 | GPU1(cuda:2)
DEBUG 01-07 10:14:06.325639.325639 lmp.py:767]   Expert 48 |    168 | GPU0(cuda:1)
DEBUG 01-07 10:14:06.325805.325805 lmp.py:767]   Expert 49 |    169 | GPU0(cuda:1)
DEBUG 01-07 10:14:06.325733.325733 lmp.py:767]   Expert 35 |    174 | GPU1(cuda:2)
DEBUG 01-07 10:14:06.325899.325899 lmp.py:767]   Expert 12 |    175 | GPU0(cuda:1)
DEBUG 01-07 10:14:06.325827.325827 lmp.py:767]   Expert 37 |    177 | GPU0(cuda:1)
DEBUG 01-07 10:14:06.325993.325993 lmp.py:767]   Expert 60 |    187 | GPU1(cuda:2)
DEBUG 01-07 10:14:06.325920.325920 lmp.py:767]   Expert 13 |    188 | GPU1(cuda:2)
DEBUG 01-07 10:14:06.325087.325087 lmp.py:767]   Expert 33 |    190 | GPU0(cuda:1)
DEBUG 01-07 10:14:06.325445.325445 lmp.py:767]   Expert 10 |    192 | GPU0(cuda:1)
DEBUG 01-07 10:14:06.326803.326803 lmp.py:767]   Expert 53 |    194 | GPU1(cuda:2)
DEBUG 01-07 10:14:06.326684.326684 lmp.py:767]   Expert 16 |    195 | GPU0(cuda:1)
DEBUG 01-07 10:14:06.326566.326566 lmp.py:767]   Expert 21 |    196 | GPU1(cuda:2)
DEBUG 01-07 10:14:06.326732.326732 lmp.py:767]   Expert 40 |    199 | GPU1(cuda:2)
DEBUG 01-07 10:14:06.326660.326660 lmp.py:767]   Expert 43 |    202 | GPU0(cuda:1)
DEBUG 01-07 10:14:06.326587.326587 lmp.py:767]   Expert 38 |    206 | GPU0(cuda:1)
DEBUG 01-07 10:14:06.326515.326515 lmp.py:767]   Expert  5 |    207 | GPU1(cuda:2)
DEBUG 01-07 10:14:06.326681.326681 lmp.py:767]   Expert 19 |    216 | GPU1(cuda:2)
DEBUG 01-07 10:14:06.326609.326609 lmp.py:767]   Expert 52 |    216 | GPU0(cuda:1)
DEBUG 01-07 10:14:06.326537.326537 lmp.py:767]   Expert 50 |    217 | GPU0(cuda:1)
DEBUG 01-07 10:14:06.326703.326703 lmp.py:767]   Expert 41 |    218 | GPU1(cuda:2)
DEBUG 01-07 10:14:06.326630.326630 lmp.py:767]   Expert 44 |    218 | GPU1(cuda:2)
DEBUG 01-07 10:14:06.326558.326558 lmp.py:767]   Expert 59 |    223 | GPU0(cuda:1)
DEBUG 01-07 10:14:06.326248.326248 lmp.py:767]   Expert  4 |    224 | GPU0(cuda:1)
DEBUG 01-07 10:14:06.326890.326890 lmp.py:767]   Expert 55 |    232 | GPU1(cuda:2)
DEBUG 01-07 10:14:06.326010.326010 lmp.py:767]   Expert 56 |    238 | GPU0(cuda:1)
DEBUG 01-07 10:14:06.326130.326130 lmp.py:767]   Expert 31 |    241 | GPU1(cuda:2)
DEBUG 01-07 10:14:06.326488.326488 lmp.py:767]   Expert 20 |    249 | GPU0(cuda:1)
DEBUG 01-07 10:14:06.326370.326370 lmp.py:767]   Expert 39 |    250 | GPU1(cuda:2)
DEBUG 01-07 10:14:06.326536.326536 lmp.py:767]   Expert 22 |    268 | GPU0(cuda:1)
DEBUG 01-07 10:14:06.326417.326417 lmp.py:767]   Expert  2 |    270 | GPU1(cuda:2)
DEBUG 01-07 10:14:06.326537.326537 lmp.py:767]   Expert 63 |    274 | GPU0(cuda:1)
DEBUG 01-07 10:14:06.326418.326418 lmp.py:767]   Expert 47 |    276 | GPU1(cuda:2)
DEBUG 01-07 10:14:06.326300.326300 lmp.py:767]   Expert 42 |    303 | GPU0(cuda:1)
DEBUG 01-07 10:14:06.326181.326181 lmp.py:767]   Expert 18 |    315 | GPU1(cuda:2)
DEBUG 01-07 10:14:06.326539.326539 lmp.py:767]   Expert 14 |    321 | GPU0(cuda:1)
DEBUG 01-07 10:14:06.326375.326375 lmp.py:767]   Expert 46 |    366 | GPU1(cuda:2)
DEBUG 01-07 10:14:06.326448.326448 lmp.py:767]   Expert 11 |    392 | GPU1(cuda:2)
DEBUG 01-07 10:14:06.326045.326045 lmp.py:767]   Expert 61 |    462 | GPU0(cuda:1)
DEBUG 01-07 10:14:06.326926.326926 lmp.py:769] 
DEBUG 01-07 10:14:06.326926.326926 lmp.py:769]   Device Token Distribution:
DEBUG 01-07 10:14:06.326807.326807 lmp.py:770]   CPU:   2151 tokens
DEBUG 01-07 10:14:06.326643.326643 lmp.py:774]   cuda:1:   4993 tokens (22 experts)
DEBUG 01-07 10:14:06.326524.326524 lmp.py:774]   cuda:2:   5144 tokens (23 experts)
DEBUG 01-07 10:14:06.326690.326690 lmp.py:775]   Total GPU:  10137 tokens
DEBUG 01-07 10:14:06.326379.326379 lmp.py:776] ============================================================
DEBUG 01-07 10:14:06.326379.326379 lmp.py:776] 
DEBUG 01-07 10:14:06.326744.326744 cuda_h.py:19] end experts_map_get cost 0.0017614364624023438 seconds
DEBUG 01-07 10:14:06.326341.326341 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model_multi_device
DEBUG 01-07 10:14:06.326879.326879 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 10:14:06.326545.326545 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 10:14:06.327128.327128 cuda_h.py:19] end allocate_cuda_memory cost 0.00018739700317382812 seconds
DEBUG 01-07 10:14:06.327455.327455 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 10:14:06.327973.327973 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 10:14:06.327497.327497 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 10:14:06.327624.327624 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 305fe12d-90ee-4033-a0a0-134303a11a78
DEBUG 01-07 10:14:06.327874.327874 client.py:106] call stub.LoadModelAsync
INFO 01-07 10:14:06.327952.327952 client.py:127] Model loaded
DEBUG 01-07 10:14:06.327977.327977 cuda_h.py:19] end sllm_worker_task cost 0.008758306503295898 seconds
INFO 01-07 10:14:06.328258.328258 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 305fe12d-90ee-4033-a0a0-134303a11a78
DEBUG 01-07 10:14:06.328625.328625 cuda_h.py:19] end load_into_gpu_async cost 0.0010755062103271484 seconds
DEBUG 01-07 10:14:06.328089.328089 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 10:14:06.328331.328331 cuda_h.py:19] end restore_tensors2 cost 0.0002925395965576172 seconds
DEBUG 01-07 10:14:06.328638.328638 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0018703937530517578 seconds
DEBUG 01-07 10:14:06.330389.330389 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 10:14:06.330804.330804 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 10:14:06.330373.330373 cuda_h.py:19] end allocate_cuda_memory cost 0.0001723766326904297 seconds
DEBUG 01-07 10:14:06.330594.330594 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 10:14:06.330489.330489 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 10:14:06.330675.330675 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 10:14:06.330133.330133 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, c03d2b96-e9e9-444d-b0d4-814880c9f638
DEBUG 01-07 10:14:06.331846.331846 client.py:106] call stub.LoadModelAsync
INFO 01-07 10:14:06.331132.331132 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, c03d2b96-e9e9-444d-b0d4-814880c9f638
DEBUG 01-07 10:14:06.331484.331484 cuda_h.py:19] end load_into_gpu_async cost 0.0010478496551513672 seconds
DEBUG 01-07 10:14:06.331803.331803 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 10:14:06.332622.332622 cuda_h.py:19] end restore_tensors2 cost 0.0002980232238769531 seconds
DEBUG 01-07 10:14:06.332213.332213 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.001817464828491211 seconds
DEBUG 01-07 10:14:06.334131.334131 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model_multi_device cost 0.007543087005615234 seconds
DEBUG 01-07 10:14:06.334583.334583 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-07 10:14:06.334215.334215 lmp.py:816] 
DEBUG 01-07 10:14:06.334215.334215 lmp.py:816]   Computing 19 experts on CPU...
DEBUG 01-07 10:14:06.334197.334197 cuda_h.py:19] end cpu_experts_submit cost 0.00010824203491210938 seconds
DEBUG 01-07 10:14:06.334800.334800 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-07 10:14:06.340732.340732 mlpmodule.py:749] group tensors cost 0.005543231964111328 s
DEBUG 01-07 10:14:06.342825.342825 mlpmodule.py:787] pad cost 0.0012450218200683594 s
DEBUG 01-07 10:14:06.342313.342313 mlpmodule.py:793] create cpu tensor cost 4.673004150390625e-05 s
DEBUG 01-07 10:14:06.342898.342898 mlpmodule.py:798] move to cpu cost 3.62396240234375e-05 s
DEBUG 01-07 10:14:06.352058.352058 mlpmodule.py:812] group_w3: shape=torch.Size([19, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=54788096
DEBUG 01-07 10:14:06.352865.352865 mlpmodule.py:813] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-07 10:14:06.353677.353677 mlpmodule.py:818] group_w3 first element: -0.0380859375
WARNING 01-07 10:14:06.353184.353184 mlpmodule.py:828] start einsum2
DEBUG 01-07 10:14:06.370597.370597 mlpmodule.py:838] group einsum cost 0.027712583541870117 s
DEBUG 01-07 10:14:06.370744.370744 mlpmodule.py:846] cpy2cputensor cost 0.0004487037658691406 s
DEBUG 01-07 10:14:06.373627.373627 cuda_h.py:19] end wait_cetm_experts cost 0.038870811462402344 seconds
DEBUG 01-07 10:14:06.373179.373179 cuda_h.py:10] start gpu_sexperts
DEBUG 01-07 10:14:06.373681.373681 cuda_h.py:19] end gpu_sexperts cost 0.0005028247833251953 seconds
DEBUG 01-07 10:14:06.374425.374425 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-07 10:14:06.374844.374844 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.3126602172851562e-05 seconds
DEBUG 01-07 10:14:06.374262.374262 cuda_h.py:10] start wait_experts_multi_device
INFO 01-07 10:14:06.374210.374210 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 305fe12d-90ee-4033-a0a0-134303a11a78
INFO 01-07 10:14:06.375550.375550 client.py:127] Model loaded
INFO 01-07 10:14:06.375002.375002 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, c03d2b96-e9e9-444d-b0d4-814880c9f638
INFO 01-07 10:14:06.375387.375387 client.py:127] Model loaded
DEBUG 01-07 10:14:06.375693.375693 cuda_h.py:19] end wait_experts_multi_device cost 0.0013759136199951172 seconds
DEBUG 01-07 10:14:06.375588.375588 cuda_h.py:10] start gpu_experts_multi_device
DEBUG 01-07 10:14:06.375126.375126 lmp.py:867]   Computing 23 experts on cuda:2...
DEBUG 01-07 10:14:06.382557.382557 mlpmodule.py:707]  experts func einsum cost 0.04798722267150879 s
DEBUG 01-07 10:14:06.382210.382210 mlpmodule.py:533] gpu group tensors cost 0.006571531295776367 s
DEBUG 01-07 10:14:06.384010.384010 mlpmodule.py:566] gpu pad cost 0.0012483596801757812 s
DEBUG 01-07 10:14:06.384041.384041 mlpmodule.py:584] gpu group einsum cost 0.0004899501800537109 s
DEBUG 01-07 10:14:06.386422.386422 mlpmodule.py:656] gpu experts func einsum cost 0.01014089584350586 s
DEBUG 01-07 10:14:06.386710.386710 lmp.py:867]   Computing 22 experts on cuda:1...
DEBUG 01-07 10:14:06.387315.387315 mlpmodule.py:533] gpu group tensors cost 0.0003733634948730469 s
DEBUG 01-07 10:14:06.388437.388437 mlpmodule.py:566] gpu pad cost 0.0010197162628173828 s
DEBUG 01-07 10:14:06.389554.389554 mlpmodule.py:584] gpu group einsum cost 0.0006616115570068359 s
DEBUG 01-07 10:14:06.390529.390529 mlpmodule.py:656] gpu experts func einsum cost 0.0037963390350341797 s
DEBUG 01-07 10:14:06.390095.390095 cuda_h.py:19] end gpu_experts_multi_device cost 0.015304088592529297 seconds
DEBUG 01-07 10:14:06.390919.390919 cuda_h.py:19] end layer_moe_generate_multi_device_2 cost 0.06688666343688965 seconds
DEBUG 01-07 10:14:06.391093.391093 lmp.py:194] -------------------------------- end prefill layer 2 --------------------------------
DEBUG 01-07 10:14:06.391400.391400 lmp.py:153] -------------------------------- start prefill layer 3 --------------------------------
DEBUG 01-07 10:14:06.391096.391096 cuda_h.py:10] start start_load_qkvogn_s_weight_l_4
DEBUG 01-07 10:14:06.391375.391375 cuda_h.py:10] start start_load_qkvogn_s_weight_l_4
DEBUG 01-07 10:14:06.391642.391642 cuda_h.py:19] end start_load_qkvogn_s_weight_l_4 cost 2.8848648071289062e-05 seconds
DEBUG 01-07 10:14:06.391629.391629 cuda_h.py:19] end start_load_qkvogn_s_weight_l_4 cost 5.984306335449219e-05 seconds
DEBUG 01-07 10:14:06.391941.391941 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-07 10:14:06.391287.391287 cuda_h.py:10] start sllm_worker_task
DEBUG 01-07 10:14:06.391608.391608 mlpmodule.py:367] cuda:1 cuda:1
DEBUG 01-07 10:14:06.391802.391802 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 10:14:06.391997.391997 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 10:14:06.391250.391250 cuda_h.py:19] end allocate_cuda_memory cost 0.0001838207244873047 seconds
DEBUG 01-07 10:14:06.392729.392729 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 10:14:06.392154.392154 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 10:14:06.392785.392785 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 10:14:06.392772.392772 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, b41c54bb-68d3-4a33-bad7-5dbd97ccd6ac
DEBUG 01-07 10:14:06.392920.392920 client.py:106] call stub.LoadModelAsync
DEBUG 01-07 10:14:06.392380.392380 cuda_h.py:10] start self_attn
INFO 01-07 10:14:06.392423.392423 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, b41c54bb-68d3-4a33-bad7-5dbd97ccd6ac
DEBUG 01-07 10:14:06.393981.393981 cuda_h.py:19] end load_into_gpu_async cost 0.0009601116180419922 seconds
DEBUG 01-07 10:14:06.393492.393492 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 10:14:06.393230.393230 cuda_h.py:19] end restore_tensors2 cost 6.270408630371094e-05 seconds
DEBUG 01-07 10:14:06.393794.393794 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0014503002166748047 seconds
INFO 01-07 10:14:06.393107.393107 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, b41c54bb-68d3-4a33-bad7-5dbd97ccd6ac
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-07 10:14:06.396473.396473 cuda_h.py:19] end self_attn cost 0.0037279129028320312 seconds
DEBUG 01-07 10:14:06.396332.396332 cuda_h.py:19] end iln_self_attn_paln cost 0.0051043033599853516 seconds
DEBUG 01-07 10:14:06.396446.396446 cuda_h.py:10] start layer_moe_generate_multi_device_3
DEBUG 01-07 10:14:06.396871.396871 cuda_h.py:10] start gate
DEBUG 01-07 10:14:06.397371.397371 cuda_h.py:19] end gate cost 0.0006508827209472656 seconds
DEBUG 01-07 10:14:06.397008.397008 cuda_h.py:10] start experts_map_get
DEBUG 01-07 10:14:06.397989.397989 lmp.py:744] 
DEBUG 01-07 10:14:06.397989.397989 lmp.py:744] Expert Token Distribution & Multi-Device Allocation:
DEBUG 01-07 10:14:06.397844.397844 lmp.py:745]   Total experts: 64
DEBUG 01-07 10:14:06.397401.397401 lmp.py:746]   CPU experts: 19 (30%)
DEBUG 01-07 10:14:06.397144.397144 lmp.py:747]   GPU experts: 45 (70%)
DEBUG 01-07 10:14:06.397740.397740 lmp.py:748]   Number of GPU devices: 2
DEBUG 01-07 10:14:06.397860.397860 lmp.py:749] 
DEBUG 01-07 10:14:06.397860.397860 lmp.py:749]   Expert ID | Tokens | Device
DEBUG 01-07 10:14:06.397741.397741 lmp.py:750]   -----------------------------------
DEBUG 01-07 10:14:06.397822.397822 lmp.py:767]   Expert  1 |     47 | CPU
DEBUG 01-07 10:14:06.397942.397942 lmp.py:767]   Expert 27 |     62 | CPU
DEBUG 01-07 10:14:06.398108.398108 lmp.py:767]   Expert  7 |     76 | CPU
DEBUG 01-07 10:14:06.398274.398274 lmp.py:767]   Expert 48 |     83 | CPU
DEBUG 01-07 10:14:06.398678.398678 lmp.py:767]   Expert 15 |     99 | CPU
DEBUG 01-07 10:14:06.398606.398606 lmp.py:767]   Expert 30 |    104 | CPU
DEBUG 01-07 10:14:06.398772.398772 lmp.py:767]   Expert 61 |    116 | CPU
DEBUG 01-07 10:14:06.398892.398892 lmp.py:767]   Expert 32 |    118 | CPU
DEBUG 01-07 10:14:06.398535.398535 lmp.py:767]   Expert 18 |    119 | CPU
DEBUG 01-07 10:14:06.398178.398178 lmp.py:767]   Expert 45 |    119 | CPU
DEBUG 01-07 10:14:06.398821.398821 lmp.py:767]   Expert 34 |    133 | CPU
DEBUG 01-07 10:14:06.398464.398464 lmp.py:767]   Expert  5 |    134 | CPU
DEBUG 01-07 10:14:06.398392.398392 lmp.py:767]   Expert 39 |    136 | CPU
DEBUG 01-07 10:14:06.398081.398081 lmp.py:767]   Expert 11 |    139 | CPU
DEBUG 01-07 10:14:06.398247.398247 lmp.py:767]   Expert 36 |    139 | CPU
DEBUG 01-07 10:14:06.398175.398175 lmp.py:767]   Expert 26 |    141 | CPU
DEBUG 01-07 10:14:06.398102.398102 lmp.py:767]   Expert  6 |    142 | CPU
DEBUG 01-07 10:14:06.398030.398030 lmp.py:767]   Expert 51 |    144 | CPU
DEBUG 01-07 10:14:06.398958.398958 lmp.py:767]   Expert 59 |    144 | CPU
DEBUG 01-07 10:14:06.398793.398793 lmp.py:767]   Expert 23 |    155 | GPU0(cuda:1)
DEBUG 01-07 10:14:06.398343.398343 lmp.py:767]   Expert 49 |    156 | GPU0(cuda:1)
DEBUG 01-07 10:14:06.398370.398370 lmp.py:767]   Expert  2 |    157 | GPU1(cuda:2)
DEBUG 01-07 10:14:06.398206.398206 lmp.py:767]   Expert  9 |    160 | GPU1(cuda:2)
DEBUG 01-07 10:14:06.398517.398517 lmp.py:767]   Expert 50 |    165 | GPU0(cuda:1)
DEBUG 01-07 10:14:06.398399.398399 lmp.py:767]   Expert 56 |    167 | GPU1(cuda:2)
DEBUG 01-07 10:14:06.398042.398042 lmp.py:767]   Expert 52 |    168 | GPU0(cuda:1)
DEBUG 01-07 10:14:06.398685.398685 lmp.py:767]   Expert 40 |    169 | GPU1(cuda:2)
DEBUG 01-07 10:14:06.398566.398566 lmp.py:767]   Expert 16 |    172 | GPU0(cuda:1)
DEBUG 01-07 10:14:06.398971.398971 lmp.py:767]   Expert 35 |    172 | GPU0(cuda:1)
DEBUG 01-07 10:14:06.398375.398375 lmp.py:767]   Expert  4 |    181 | GPU1(cuda:2)
DEBUG 01-07 10:14:06.398018.398018 lmp.py:767]   Expert 13 |    189 | GPU1(cuda:2)
DEBUG 01-07 10:14:06.398661.398661 lmp.py:767]   Expert 42 |    189 | GPU0(cuda:1)
DEBUG 01-07 10:14:06.398543.398543 lmp.py:767]   Expert 37 |    191 | GPU1(cuda:2)
DEBUG 01-07 10:14:06.398901.398901 lmp.py:767]   Expert 38 |    197 | GPU0(cuda:1)
DEBUG 01-07 10:14:06.398736.398736 lmp.py:767]   Expert 62 |    198 | GPU1(cuda:2)
DEBUG 01-07 10:14:06.398856.398856 lmp.py:767]   Expert 17 |    199 | GPU0(cuda:1)
DEBUG 01-07 10:14:06.398976.398976 lmp.py:767]   Expert 21 |    202 | GPU0(cuda:1)
DEBUG 01-07 10:14:06.398619.398619 lmp.py:767]   Expert  3 |    209 | GPU1(cuda:2)
DEBUG 01-07 10:14:06.398262.398262 lmp.py:767]   Expert 44 |    210 | GPU1(cuda:2)
DEBUG 01-07 10:14:06.398666.398666 lmp.py:767]   Expert 58 |    213 | GPU1(cuda:2)
DEBUG 01-07 10:14:06.398832.398832 lmp.py:767]   Expert 60 |    213 | GPU0(cuda:1)
DEBUG 01-07 10:14:06.398475.398475 lmp.py:767]   Expert 10 |    214 | GPU1(cuda:2)
DEBUG 01-07 10:14:06.398641.398641 lmp.py:767]   Expert 28 |    214 | GPU0(cuda:1)
DEBUG 01-07 10:14:06.398046.398046 lmp.py:767]   Expert 47 |    215 | GPU0(cuda:1)
DEBUG 01-07 10:14:06.398689.398689 lmp.py:767]   Expert 53 |    221 | GPU0(cuda:1)
DEBUG 01-07 10:14:06.398570.398570 lmp.py:767]   Expert 55 |    221 | GPU1(cuda:2)
DEBUG 01-07 10:14:06.398690.398690 lmp.py:767]   Expert 20 |    224 | GPU1(cuda:2)
DEBUG 01-07 10:14:06.398810.398810 lmp.py:767]   Expert 57 |    225 | GPU0(cuda:1)
DEBUG 01-07 10:14:06.398930.398930 lmp.py:767]   Expert 33 |    227 | GPU0(cuda:1)
DEBUG 01-07 10:14:06.398050.398050 lmp.py:767]   Expert 31 |    237 | GPU0(cuda:1)
DEBUG 01-07 10:14:06.398123.398123 lmp.py:767]   Expert 46 |    237 | GPU1(cuda:2)
DEBUG 01-07 10:14:06.398243.398243 lmp.py:767]   Expert  8 |    241 | GPU1(cuda:2)
DEBUG 01-07 10:14:06.398886.398886 lmp.py:767]   Expert 24 |    242 | GPU0(cuda:1)
DEBUG 01-07 10:14:06.398529.398529 lmp.py:767]   Expert 19 |    245 | GPU1(cuda:2)
DEBUG 01-07 10:14:06.398933.398933 lmp.py:767]   Expert 14 |    266 | GPU1(cuda:2)
DEBUG 01-07 10:14:06.398338.398338 lmp.py:767]   Expert 63 |    266 | GPU0(cuda:1)
DEBUG 01-07 10:14:06.398742.398742 lmp.py:767]   Expert 12 |    275 | GPU0(cuda:1)
DEBUG 01-07 10:14:06.398385.398385 lmp.py:767]   Expert 29 |    276 | GPU1(cuda:2)
DEBUG 01-07 10:14:06.399220.399220 lmp.py:767]   Expert 22 |    279 | GPU1(cuda:2)
DEBUG 01-07 10:14:06.399817.399817 lmp.py:767]   Expert  0 |    294 | GPU0(cuda:1)
DEBUG 01-07 10:14:06.399175.399175 lmp.py:767]   Expert 43 |    308 | GPU0(cuda:1)
DEBUG 01-07 10:14:06.399772.399772 lmp.py:767]   Expert 54 |    338 | GPU1(cuda:2)
DEBUG 01-07 10:14:06.399369.399369 lmp.py:767]   Expert 41 |    384 | GPU1(cuda:2)
DEBUG 01-07 10:14:06.399012.399012 lmp.py:767]   Expert 25 |    412 | GPU0(cuda:1)
DEBUG 01-07 10:14:06.399701.399701 lmp.py:769] 
DEBUG 01-07 10:14:06.399701.399701 lmp.py:769]   Device Token Distribution:
DEBUG 01-07 10:14:06.399105.399105 lmp.py:770]   CPU:   2195 tokens
DEBUG 01-07 10:14:06.399464.399464 lmp.py:774]   cuda:1:   5124 tokens (23 experts)
DEBUG 01-07 10:14:06.399107.399107 lmp.py:774]   cuda:2:   4969 tokens (22 experts)
DEBUG 01-07 10:14:06.399511.399511 lmp.py:775]   Total GPU:  10093 tokens
DEBUG 01-07 10:14:06.399201.399201 lmp.py:776] ============================================================
DEBUG 01-07 10:14:06.399201.399201 lmp.py:776] 
DEBUG 01-07 10:14:06.399089.399089 cuda_h.py:19] end experts_map_get cost 0.0017864704132080078 seconds
DEBUG 01-07 10:14:06.399447.399447 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model_multi_device
DEBUG 01-07 10:14:06.399124.399124 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 10:14:06.399405.399405 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 10:14:06.399174.399174 cuda_h.py:19] end allocate_cuda_memory cost 0.0001842975616455078 seconds
DEBUG 01-07 10:14:06.399554.399554 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 10:14:06.399072.399072 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 10:14:06.399642.399642 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 10:14:06.399531.399531 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, e49707c7-6d0d-4b76-aa1e-94fa0b94b647
DEBUG 01-07 10:14:06.399403.399403 client.py:106] call stub.LoadModelAsync
INFO 01-07 10:14:06.400554.400554 client.py:127] Model loaded
DEBUG 01-07 10:14:06.400530.400530 cuda_h.py:19] end sllm_worker_task cost 0.008895635604858398 seconds
INFO 01-07 10:14:06.400450.400450 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, e49707c7-6d0d-4b76-aa1e-94fa0b94b647
DEBUG 01-07 10:14:06.400816.400816 cuda_h.py:19] end load_into_gpu_async cost 0.001073598861694336 seconds
DEBUG 01-07 10:14:06.400804.400804 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 10:14:06.401530.401530 cuda_h.py:19] end restore_tensors2 cost 0.0002989768981933594 seconds
DEBUG 01-07 10:14:06.401598.401598 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0018711090087890625 seconds
DEBUG 01-07 10:14:06.403159.403159 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 10:14:06.403905.403905 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 10:14:06.403574.403574 cuda_h.py:19] end allocate_cuda_memory cost 0.00017547607421875 seconds
DEBUG 01-07 10:14:06.403603.403603 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 10:14:06.403451.403451 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 10:14:06.403876.403876 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 10:14:06.403526.403526 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 1bc6438e-8310-4a13-9373-c54c9b157909
DEBUG 01-07 10:14:06.403193.403193 client.py:106] call stub.LoadModelAsync
INFO 01-07 10:14:06.404772.404772 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 1bc6438e-8310-4a13-9373-c54c9b157909
DEBUG 01-07 10:14:06.404509.404509 cuda_h.py:19] end load_into_gpu_async cost 0.0011286735534667969 seconds
DEBUG 01-07 10:14:06.404020.404020 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 10:14:06.404467.404467 cuda_h.py:19] end restore_tensors2 cost 0.0002689361572265625 seconds
DEBUG 01-07 10:14:06.405389.405389 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0018703937530517578 seconds
DEBUG 01-07 10:14:06.406947.406947 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model_multi_device cost 0.007571220397949219 seconds
DEBUG 01-07 10:14:06.406875.406875 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-07 10:14:06.406984.406984 lmp.py:816] 
DEBUG 01-07 10:14:06.406984.406984 lmp.py:816]   Computing 19 experts on CPU...
DEBUG 01-07 10:14:06.407012.407012 cuda_h.py:19] end cpu_experts_submit cost 0.0001087188720703125 seconds
DEBUG 01-07 10:14:06.407331.407331 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-07 10:14:06.414948.414948 mlpmodule.py:749] group tensors cost 0.007181644439697266 s
DEBUG 01-07 10:14:06.416664.416664 mlpmodule.py:787] pad cost 0.0010328292846679688 s
DEBUG 01-07 10:14:06.416985.416985 mlpmodule.py:793] create cpu tensor cost 4.100799560546875e-05 s
DEBUG 01-07 10:14:06.416173.416173 mlpmodule.py:798] move to cpu cost 3.218650817871094e-05 s
DEBUG 01-07 10:14:06.427793.427793 mlpmodule.py:812] group_w3: shape=torch.Size([19, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=54788096
DEBUG 01-07 10:14:06.427799.427799 mlpmodule.py:813] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-07 10:14:06.427988.427988 mlpmodule.py:818] group_w3 first element: -0.054931640625
WARNING 01-07 10:14:06.427350.427350 mlpmodule.py:828] start einsum2
DEBUG 01-07 10:14:06.443678.443678 mlpmodule.py:838] group einsum cost 0.026485919952392578 s
DEBUG 01-07 10:14:06.443873.443873 mlpmodule.py:846] cpy2cputensor cost 0.0004527568817138672 s
DEBUG 01-07 10:14:06.446278.446278 cuda_h.py:19] end wait_cetm_experts cost 0.0393064022064209 seconds
DEBUG 01-07 10:14:06.446261.446261 cuda_h.py:10] start gpu_sexperts
DEBUG 01-07 10:14:06.447591.447591 cuda_h.py:19] end gpu_sexperts cost 0.0005159378051757812 seconds
DEBUG 01-07 10:14:06.447580.447580 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-07 10:14:06.447523.447523 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.3603439331054688e-05 seconds
DEBUG 01-07 10:14:06.447941.447941 cuda_h.py:10] start wait_experts_multi_device
INFO 01-07 10:14:06.447650.447650 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, e49707c7-6d0d-4b76-aa1e-94fa0b94b647
INFO 01-07 10:14:06.448706.448706 client.py:127] Model loaded
INFO 01-07 10:14:06.448165.448165 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 1bc6438e-8310-4a13-9373-c54c9b157909
INFO 01-07 10:14:06.449126.449126 client.py:127] Model loaded
DEBUG 01-07 10:14:06.449764.449764 cuda_h.py:19] end wait_experts_multi_device cost 0.0018038749694824219 seconds
DEBUG 01-07 10:14:06.449374.449374 cuda_h.py:10] start gpu_experts_multi_device
DEBUG 01-07 10:14:06.449150.449150 lmp.py:867]   Computing 22 experts on cuda:2...
DEBUG 01-07 10:14:06.450818.450818 mlpmodule.py:533] gpu group tensors cost 0.0004951953887939453 s
DEBUG 01-07 10:14:06.451867.451867 mlpmodule.py:566] gpu pad cost 0.0012018680572509766 s
DEBUG 01-07 10:14:06.452445.452445 mlpmodule.py:584] gpu group einsum cost 0.0005743503570556641 s
DEBUG 01-07 10:14:06.454909.454909 mlpmodule.py:656] gpu experts func einsum cost 0.004389524459838867 s
DEBUG 01-07 10:14:06.454800.454800 lmp.py:867]   Computing 23 experts on cuda:1...
DEBUG 01-07 10:14:06.455388.455388 mlpmodule.py:707]  experts func einsum cost 0.0480504035949707 s
DEBUG 01-07 10:14:06.455691.455691 mlpmodule.py:533] gpu group tensors cost 0.0005970001220703125 s
DEBUG 01-07 10:14:06.456808.456808 mlpmodule.py:566] gpu pad cost 0.0012421607971191406 s
DEBUG 01-07 10:14:06.457111.457111 mlpmodule.py:584] gpu group einsum cost 0.00047707557678222656 s
DEBUG 01-07 10:14:06.459097.459097 mlpmodule.py:656] gpu experts func einsum cost 0.004412651062011719 s
DEBUG 01-07 10:14:06.459233.459233 cuda_h.py:19] end gpu_experts_multi_device cost 0.010190486907958984 seconds
DEBUG 01-07 10:14:06.459149.459149 cuda_h.py:19] end layer_moe_generate_multi_device_3 cost 0.06270813941955566 seconds
DEBUG 01-07 10:14:06.459621.459621 lmp.py:194] -------------------------------- end prefill layer 3 --------------------------------
DEBUG 01-07 10:14:06.459636.459636 lmp.py:153] -------------------------------- start prefill layer 4 --------------------------------
DEBUG 01-07 10:14:06.459093.459093 cuda_h.py:10] start start_load_qkvogn_s_weight_l_5
DEBUG 01-07 10:14:06.459373.459373 cuda_h.py:10] start start_load_qkvogn_s_weight_l_5
DEBUG 01-07 10:14:06.459494.459494 cuda_h.py:19] end start_load_qkvogn_s_weight_l_5 cost 2.765655517578125e-05 seconds
DEBUG 01-07 10:14:06.459766.459766 cuda_h.py:19] end start_load_qkvogn_s_weight_l_5 cost 5.745887756347656e-05 seconds
DEBUG 01-07 10:14:06.459124.459124 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-07 10:14:06.459391.459391 mlpmodule.py:367] cuda:1 cuda:1
DEBUG 01-07 10:14:06.459678.459678 cuda_h.py:10] start sllm_worker_task
DEBUG 01-07 10:14:06.460104.460104 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 10:14:06.460126.460126 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 10:14:06.460751.460751 cuda_h.py:19] end allocate_cuda_memory cost 0.00025200843811035156 seconds
DEBUG 01-07 10:14:06.460489.460489 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 10:14:06.460729.460729 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 10:14:06.460029.460029 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 10:14:06.460778.460778 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 408262a4-dd7c-4346-b3fd-770f94ab8a6b
DEBUG 01-07 10:14:06.460449.460449 client.py:106] call stub.LoadModelAsync
DEBUG 01-07 10:14:06.460597.460597 cuda_h.py:10] start self_attn
INFO 01-07 10:14:06.461518.461518 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 408262a4-dd7c-4346-b3fd-770f94ab8a6b
DEBUG 01-07 10:14:06.461917.461917 cuda_h.py:19] end load_into_gpu_async cost 0.0008766651153564453 seconds
DEBUG 01-07 10:14:06.461282.461282 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 10:14:06.461405.461405 cuda_h.py:19] end restore_tensors2 cost 6.461143493652344e-05 seconds
DEBUG 01-07 10:14:06.461968.461968 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0014486312866210938 seconds
INFO 01-07 10:14:06.461427.461427 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 408262a4-dd7c-4346-b3fd-770f94ab8a6b
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-07 10:14:06.464357.464357 cuda_h.py:19] end self_attn cost 0.0036573410034179688 seconds
DEBUG 01-07 10:14:06.464294.464294 cuda_h.py:19] end iln_self_attn_paln cost 0.0050470829010009766 seconds
DEBUG 01-07 10:14:06.464170.464170 cuda_h.py:10] start layer_moe_generate_multi_device_4
DEBUG 01-07 10:14:06.464833.464833 cuda_h.py:10] start gate
DEBUG 01-07 10:14:06.465711.465711 cuda_h.py:19] end gate cost 0.0006482601165771484 seconds
DEBUG 01-07 10:14:06.465348.465348 cuda_h.py:10] start experts_map_get
DEBUG 01-07 10:14:06.466646.466646 lmp.py:744] 
DEBUG 01-07 10:14:06.466646.466646 lmp.py:744] Expert Token Distribution & Multi-Device Allocation:
DEBUG 01-07 10:14:06.466753.466753 lmp.py:745]   Total experts: 64
DEBUG 01-07 10:14:06.466310.466310 lmp.py:746]   CPU experts: 19 (30%)
DEBUG 01-07 10:14:06.466861.466861 lmp.py:747]   GPU experts: 45 (70%)
DEBUG 01-07 10:14:06.466504.466504 lmp.py:748]   Number of GPU devices: 2
DEBUG 01-07 10:14:06.466193.466193 lmp.py:749] 
DEBUG 01-07 10:14:06.466193.466193 lmp.py:749]   Expert ID | Tokens | Device
DEBUG 01-07 10:14:06.466359.466359 lmp.py:750]   -----------------------------------
DEBUG 01-07 10:14:06.466486.466486 lmp.py:767]   Expert 14 |     61 | CPU
DEBUG 01-07 10:14:06.466414.466414 lmp.py:767]   Expert 57 |     70 | CPU
DEBUG 01-07 10:14:06.466864.466864 lmp.py:767]   Expert 13 |     74 | CPU
DEBUG 01-07 10:14:06.466838.466838 lmp.py:767]   Expert 26 |     79 | CPU
DEBUG 01-07 10:14:06.466051.466051 lmp.py:767]   Expert 54 |     92 | CPU
DEBUG 01-07 10:14:06.466740.466740 lmp.py:767]   Expert 11 |     93 | CPU
DEBUG 01-07 10:14:06.466714.466714 lmp.py:767]   Expert 31 |     93 | CPU
DEBUG 01-07 10:14:06.466165.466165 lmp.py:767]   Expert 58 |    100 | CPU
DEBUG 01-07 10:14:06.466093.466093 lmp.py:767]   Expert 45 |    101 | CPU
DEBUG 01-07 10:14:06.466782.466782 lmp.py:767]   Expert 30 |    108 | CPU
DEBUG 01-07 10:14:06.466710.466710 lmp.py:767]   Expert 36 |    112 | CPU
DEBUG 01-07 10:14:06.466161.466161 lmp.py:767]   Expert 51 |    113 | CPU
DEBUG 01-07 10:14:06.466896.466896 lmp.py:767]   Expert 10 |    114 | CPU
DEBUG 01-07 10:14:06.466870.466870 lmp.py:767]   Expert 32 |    117 | CPU
DEBUG 01-07 10:14:06.466606.466606 lmp.py:767]   Expert  8 |    127 | CPU
DEBUG 01-07 10:14:06.466819.466819 lmp.py:767]   Expert 20 |    129 | CPU
DEBUG 01-07 10:14:06.466793.466793 lmp.py:767]   Expert  4 |    138 | CPU
DEBUG 01-07 10:14:06.466528.466528 lmp.py:767]   Expert 63 |    141 | CPU
DEBUG 01-07 10:14:06.466502.466502 lmp.py:767]   Expert 53 |    143 | CPU
DEBUG 01-07 10:14:06.466384.466384 lmp.py:767]   Expert 61 |    143 | GPU1(cuda:2)
DEBUG 01-07 10:14:06.466980.466980 lmp.py:767]   Expert 34 |    146 | GPU0(cuda:1)
DEBUG 01-07 10:14:06.466339.466339 lmp.py:767]   Expert 16 |    149 | GPU1(cuda:2)
DEBUG 01-07 10:14:06.466220.466220 lmp.py:767]   Expert 47 |    150 | GPU0(cuda:1)
DEBUG 01-07 10:14:06.466578.466578 lmp.py:767]   Expert 60 |    156 | GPU1(cuda:2)
DEBUG 01-07 10:14:06.466506.466506 lmp.py:767]   Expert 28 |    160 | GPU0(cuda:1)
DEBUG 01-07 10:14:06.466434.466434 lmp.py:767]   Expert 42 |    162 | GPU1(cuda:2)
DEBUG 01-07 10:14:06.466123.466123 lmp.py:767]   Expert 17 |    164 | GPU0(cuda:1)
DEBUG 01-07 10:14:06.466812.466812 lmp.py:767]   Expert 29 |    167 | GPU1(cuda:2)
DEBUG 01-07 10:14:06.466740.466740 lmp.py:767]   Expert  7 |    171 | GPU1(cuda:2)
DEBUG 01-07 10:14:06.466191.466191 lmp.py:767]   Expert 44 |    171 | GPU0(cuda:1)
DEBUG 01-07 10:14:06.466119.466119 lmp.py:767]   Expert 27 |    177 | GPU0(cuda:1)
DEBUG 01-07 10:14:06.466046.466046 lmp.py:767]   Expert  9 |    184 | GPU1(cuda:2)
DEBUG 01-07 10:14:06.466689.466689 lmp.py:767]   Expert 41 |    185 | GPU0(cuda:1)
DEBUG 01-07 10:14:06.466332.466332 lmp.py:767]   Expert 48 |    185 | GPU1(cuda:2)
DEBUG 01-07 10:14:06.466975.466975 lmp.py:767]   Expert 56 |    185 | GPU0(cuda:1)
DEBUG 01-07 10:14:06.466380.466380 lmp.py:767]   Expert  2 |    186 | GPU1(cuda:2)
DEBUG 01-07 10:14:06.466784.466784 lmp.py:767]   Expert  3 |    189 | GPU0(cuda:1)
DEBUG 01-07 10:14:06.466474.466474 lmp.py:767]   Expert 24 |    191 | GPU1(cuda:2)
DEBUG 01-07 10:14:06.466163.466163 lmp.py:767]   Expert 15 |    194 | GPU0(cuda:1)
DEBUG 01-07 10:14:06.466614.466614 lmp.py:767]   Expert 18 |    199 | GPU1(cuda:2)
DEBUG 01-07 10:14:06.466303.466303 lmp.py:767]   Expert  0 |    203 | GPU1(cuda:2)
DEBUG 01-07 10:14:06.466992.466992 lmp.py:767]   Expert 55 |    203 | GPU0(cuda:1)
DEBUG 01-07 10:14:06.466443.466443 lmp.py:767]   Expert 40 |    209 | GPU0(cuda:1)
DEBUG 01-07 10:14:06.466609.466609 lmp.py:767]   Expert 38 |    213 | GPU1(cuda:2)
DEBUG 01-07 10:14:06.467822.467822 lmp.py:767]   Expert 23 |    214 | GPU0(cuda:1)
DEBUG 01-07 10:14:06.467750.467750 lmp.py:767]   Expert 22 |    216 | GPU1(cuda:2)
DEBUG 01-07 10:14:06.467200.467200 lmp.py:767]   Expert  6 |    224 | GPU1(cuda:2)
DEBUG 01-07 10:14:06.467651.467651 lmp.py:767]   Expert 37 |    224 | GPU0(cuda:1)
DEBUG 01-07 10:14:06.467056.467056 lmp.py:767]   Expert 46 |    234 | GPU0(cuda:1)
DEBUG 01-07 10:14:06.467222.467222 lmp.py:767]   Expert 19 |    242 | GPU1(cuda:2)
DEBUG 01-07 10:14:06.467627.467627 lmp.py:767]   Expert 39 |    247 | GPU0(cuda:1)
DEBUG 01-07 10:14:06.467031.467031 lmp.py:767]   Expert 25 |    248 | GPU1(cuda:2)
DEBUG 01-07 10:14:06.467436.467436 lmp.py:767]   Expert 12 |    261 | GPU1(cuda:2)
DEBUG 01-07 10:14:06.467363.467363 lmp.py:767]   Expert 50 |    261 | GPU0(cuda:1)
DEBUG 01-07 10:14:06.467814.467814 lmp.py:767]   Expert 62 |    275 | GPU0(cuda:1)
DEBUG 01-07 10:14:06.467504.467504 lmp.py:767]   Expert 35 |    278 | GPU1(cuda:2)
DEBUG 01-07 10:14:06.467147.467147 lmp.py:767]   Expert 21 |    282 | GPU0(cuda:1)
DEBUG 01-07 10:14:06.467028.467028 lmp.py:767]   Expert 49 |    294 | GPU1(cuda:2)
DEBUG 01-07 10:14:06.467671.467671 lmp.py:767]   Expert 33 |    296 | GPU0(cuda:1)
DEBUG 01-07 10:14:06.467552.467552 lmp.py:767]   Expert 52 |    299 | GPU1(cuda:2)
DEBUG 01-07 10:14:06.467911.467911 lmp.py:767]   Expert  1 |    349 | GPU0(cuda:1)
DEBUG 01-07 10:14:06.467269.467269 lmp.py:767]   Expert  5 |    380 | GPU1(cuda:2)
DEBUG 01-07 10:14:06.467389.467389 lmp.py:767]   Expert 43 |    438 | GPU1(cuda:2)
DEBUG 01-07 10:14:06.467508.467508 lmp.py:767]   Expert 59 |    579 | GPU0(cuda:1)
DEBUG 01-07 10:14:06.467436.467436 lmp.py:769] 
DEBUG 01-07 10:14:06.467436.467436 lmp.py:769]   Device Token Distribution:
DEBUG 01-07 10:14:06.467318.467318 lmp.py:770]   CPU:   2005 tokens
DEBUG 01-07 10:14:06.467199.467199 lmp.py:774]   cuda:1:   5094 tokens (22 experts)
DEBUG 01-07 10:14:06.467365.467365 lmp.py:774]   cuda:2:   5189 tokens (23 experts)
DEBUG 01-07 10:14:06.467816.467816 lmp.py:775]   Total GPU:  10283 tokens
DEBUG 01-07 10:14:06.467028.467028 lmp.py:776] ============================================================
DEBUG 01-07 10:14:06.467028.467028 lmp.py:776] 
DEBUG 01-07 10:14:06.467155.467155 cuda_h.py:19] end experts_map_get cost 0.0017247200012207031 seconds
DEBUG 01-07 10:14:06.467798.467798 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model_multi_device
DEBUG 01-07 10:14:06.467144.467144 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 10:14:06.467617.467617 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 10:14:06.467449.467449 cuda_h.py:19] end allocate_cuda_memory cost 0.00026416778564453125 seconds
DEBUG 01-07 10:14:06.467021.467021 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 10:14:06.468015.468015 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 10:14:06.468632.468632 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 10:14:06.468282.468282 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, a777f874-0c08-4957-9169-70989a3ea9e7
DEBUG 01-07 10:14:06.468962.468962 client.py:106] call stub.LoadModelAsync
INFO 01-07 10:14:06.468293.468293 client.py:127] Model loaded
DEBUG 01-07 10:14:06.468742.468742 cuda_h.py:19] end sllm_worker_task cost 0.008758544921875 seconds
INFO 01-07 10:14:06.469754.469754 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, a777f874-0c08-4957-9169-70989a3ea9e7
DEBUG 01-07 10:14:06.469789.469789 cuda_h.py:19] end load_into_gpu_async cost 0.0011649131774902344 seconds
DEBUG 01-07 10:14:06.469777.469777 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 10:14:06.469338.469338 cuda_h.py:19] end restore_tensors2 cost 0.0003173351287841797 seconds
DEBUG 01-07 10:14:06.469022.469022 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0020639896392822266 seconds
DEBUG 01-07 10:14:06.471362.471362 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 10:14:06.471969.471969 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 10:14:06.471203.471203 cuda_h.py:19] end allocate_cuda_memory cost 0.00020456314086914062 seconds
DEBUG 01-07 10:14:06.471330.471330 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 10:14:06.471417.471417 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 10:14:06.471319.471319 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 10:14:06.471684.471684 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 9c26f68f-85fa-44ca-8f04-912418ab83f8
DEBUG 01-07 10:14:06.472120.472120 client.py:106] call stub.LoadModelAsync
INFO 01-07 10:14:06.473335.473335 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 9c26f68f-85fa-44ca-8f04-912418ab83f8
DEBUG 01-07 10:14:06.473833.473833 cuda_h.py:19] end load_into_gpu_async cost 0.0011467933654785156 seconds
DEBUG 01-07 10:14:06.473629.473629 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 10:14:06.473151.473151 cuda_h.py:19] end restore_tensors2 cost 0.0003237724304199219 seconds
DEBUG 01-07 10:14:06.473980.473980 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.001981973648071289 seconds
DEBUG 01-07 10:14:06.475401.475401 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model_multi_device cost 0.007898092269897461 seconds
DEBUG 01-07 10:14:06.475992.475992 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-07 10:14:06.475578.475578 lmp.py:816] 
DEBUG 01-07 10:14:06.475578.475578 lmp.py:816]   Computing 19 experts on CPU...
DEBUG 01-07 10:14:06.475129.475129 cuda_h.py:19] end cpu_experts_submit cost 0.0001087188720703125 seconds
DEBUG 01-07 10:14:06.475256.475256 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-07 10:14:06.481992.481992 mlpmodule.py:749] group tensors cost 0.00564265251159668 s
DEBUG 01-07 10:14:06.483570.483570 mlpmodule.py:787] pad cost 0.0012357234954833984 s
DEBUG 01-07 10:14:06.483296.483296 mlpmodule.py:793] create cpu tensor cost 4.7206878662109375e-05 s
DEBUG 01-07 10:14:06.483358.483358 mlpmodule.py:798] move to cpu cost 3.62396240234375e-05 s
DEBUG 01-07 10:14:06.495834.495834 mlpmodule.py:812] group_w3: shape=torch.Size([19, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=54788096
DEBUG 01-07 10:14:06.495218.495218 mlpmodule.py:813] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-07 10:14:06.495076.495076 mlpmodule.py:818] group_w3 first element: 0.0086669921875
WARNING 01-07 10:14:06.495537.495537 mlpmodule.py:828] start einsum2
DEBUG 01-07 10:14:06.510850.510850 mlpmodule.py:838] group einsum cost 0.02685856819152832 s
DEBUG 01-07 10:14:06.511124.511124 mlpmodule.py:846] cpy2cputensor cost 0.0004553794860839844 s
DEBUG 01-07 10:14:06.513580.513580 cuda_h.py:19] end wait_cetm_experts cost 0.03832554817199707 seconds
DEBUG 01-07 10:14:06.514378.514378 cuda_h.py:10] start gpu_sexperts
DEBUG 01-07 10:14:06.514715.514715 cuda_h.py:19] end gpu_sexperts cost 0.0005190372467041016 seconds
DEBUG 01-07 10:14:06.514850.514850 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-07 10:14:06.514176.514176 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.5510787963867188e-05 seconds
DEBUG 01-07 10:14:06.514594.514594 cuda_h.py:10] start wait_experts_multi_device
INFO 01-07 10:14:06.514973.514973 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, a777f874-0c08-4957-9169-70989a3ea9e7
INFO 01-07 10:14:06.516976.516976 client.py:127] Model loaded
INFO 01-07 10:14:06.516580.516580 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 9c26f68f-85fa-44ca-8f04-912418ab83f8
INFO 01-07 10:14:06.517335.517335 client.py:127] Model loaded
DEBUG 01-07 10:14:06.517410.517410 cuda_h.py:19] end wait_experts_multi_device cost 0.0029578208923339844 seconds
DEBUG 01-07 10:14:06.517689.517689 cuda_h.py:10] start gpu_experts_multi_device
DEBUG 01-07 10:14:06.517657.517657 lmp.py:867]   Computing 23 experts on cuda:2...
DEBUG 01-07 10:14:06.519743.519743 mlpmodule.py:533] gpu group tensors cost 0.0005011558532714844 s
DEBUG 01-07 10:14:06.520015.520015 mlpmodule.py:566] gpu pad cost 0.0013244152069091797 s
DEBUG 01-07 10:14:06.520271.520271 mlpmodule.py:584] gpu group einsum cost 0.000438690185546875 s
DEBUG 01-07 10:14:06.522302.522302 mlpmodule.py:656] gpu experts func einsum cost 0.004321575164794922 s
DEBUG 01-07 10:14:06.523219.523219 lmp.py:867]   Computing 22 experts on cuda:1...
DEBUG 01-07 10:14:06.523268.523268 mlpmodule.py:707]  experts func einsum cost 0.04810023307800293 s
DEBUG 01-07 10:14:06.524188.524188 mlpmodule.py:533] gpu group tensors cost 0.0005559921264648438 s
DEBUG 01-07 10:14:06.525571.525571 mlpmodule.py:566] gpu pad cost 0.0014717578887939453 s
DEBUG 01-07 10:14:06.526596.526596 mlpmodule.py:584] gpu group einsum cost 0.0006864070892333984 s
DEBUG 01-07 10:14:06.528381.528381 mlpmodule.py:656] gpu experts func einsum cost 0.00456690788269043 s
DEBUG 01-07 10:14:06.528762.528762 cuda_h.py:19] end gpu_experts_multi_device cost 0.010277748107910156 seconds
DEBUG 01-07 10:14:06.528871.528871 cuda_h.py:19] end layer_moe_generate_multi_device_4 cost 0.0632328987121582 seconds
DEBUG 01-07 10:14:06.528224.528224 lmp.py:194] -------------------------------- end prefill layer 4 --------------------------------
DEBUG 01-07 10:14:06.528133.528133 lmp.py:153] -------------------------------- start prefill layer 5 --------------------------------
DEBUG 01-07 10:14:06.528637.528637 cuda_h.py:10] start start_load_qkvogn_s_weight_l_6
DEBUG 01-07 10:14:06.528201.528201 cuda_h.py:10] start start_load_qkvogn_s_weight_l_6
DEBUG 01-07 10:14:06.528083.528083 cuda_h.py:19] end start_load_qkvogn_s_weight_l_6 cost 2.7894973754882812e-05 seconds
DEBUG 01-07 10:14:06.528985.528985 cuda_h.py:19] end start_load_qkvogn_s_weight_l_6 cost 5.7697296142578125e-05 seconds
DEBUG 01-07 10:14:06.528774.528774 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-07 10:14:06.528332.528332 mlpmodule.py:367] cuda:1 cuda:1
DEBUG 01-07 10:14:06.528705.528705 cuda_h.py:10] start sllm_worker_task
DEBUG 01-07 10:14:06.528370.528370 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 10:14:06.528153.528153 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 10:14:06.529424.529424 cuda_h.py:19] end allocate_cuda_memory cost 0.0001659393310546875 seconds
DEBUG 01-07 10:14:06.529188.529188 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 10:14:06.529090.529090 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 10:14:06.529767.529767 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 10:14:06.529086.529086 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, e794388f-8efa-4762-a223-e0989d8dbb18
DEBUG 01-07 10:14:06.529426.529426 client.py:106] call stub.LoadModelAsync
DEBUG 01-07 10:14:06.529349.529349 cuda_h.py:10] start self_attn
INFO 01-07 10:14:06.529976.529976 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, e794388f-8efa-4762-a223-e0989d8dbb18
DEBUG 01-07 10:14:06.530044.530044 cuda_h.py:19] end load_into_gpu_async cost 0.0008091926574707031 seconds
DEBUG 01-07 10:14:06.530125.530125 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 10:14:06.530485.530485 cuda_h.py:19] end restore_tensors2 cost 6.4849853515625e-05 seconds
DEBUG 01-07 10:14:06.530334.530334 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.001277923583984375 seconds
INFO 01-07 10:14:06.530992.530992 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, e794388f-8efa-4762-a223-e0989d8dbb18
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-07 10:14:06.533439.533439 cuda_h.py:19] end self_attn cost 0.0036187171936035156 seconds
DEBUG 01-07 10:14:06.533304.533304 cuda_h.py:19] end iln_self_attn_paln cost 0.004924774169921875 seconds
DEBUG 01-07 10:14:06.533988.533988 cuda_h.py:10] start layer_moe_generate_multi_device_5
DEBUG 01-07 10:14:06.533174.533174 cuda_h.py:10] start gate
DEBUG 01-07 10:14:06.534237.534237 cuda_h.py:19] end gate cost 0.0006437301635742188 seconds
DEBUG 01-07 10:14:06.534973.534973 cuda_h.py:10] start experts_map_get
DEBUG 01-07 10:14:06.534602.534602 lmp.py:744] 
DEBUG 01-07 10:14:06.534602.534602 lmp.py:744] Expert Token Distribution & Multi-Device Allocation:
DEBUG 01-07 10:14:06.534219.534219 lmp.py:745]   Total experts: 64
DEBUG 01-07 10:14:06.534300.534300 lmp.py:746]   CPU experts: 19 (30%)
DEBUG 01-07 10:14:06.534327.534327 lmp.py:747]   GPU experts: 45 (70%)
DEBUG 01-07 10:14:06.534685.534685 lmp.py:748]   Number of GPU devices: 2
DEBUG 01-07 10:14:06.534328.534328 lmp.py:749] 
DEBUG 01-07 10:14:06.534328.534328 lmp.py:749]   Expert ID | Tokens | Device
DEBUG 01-07 10:14:06.534448.534448 lmp.py:750]   -----------------------------------
DEBUG 01-07 10:14:06.534290.534290 lmp.py:767]   Expert 34 |     23 | CPU
DEBUG 01-07 10:14:06.534410.534410 lmp.py:767]   Expert 45 |     65 | CPU
DEBUG 01-07 10:14:06.535814.535814 lmp.py:767]   Expert 22 |     77 | CPU
DEBUG 01-07 10:14:06.535457.535457 lmp.py:767]   Expert 57 |     77 | CPU
DEBUG 01-07 10:14:06.535623.535623 lmp.py:767]   Expert 17 |     96 | CPU
DEBUG 01-07 10:14:06.535028.535028 lmp.py:767]   Expert 15 |     99 | CPU
DEBUG 01-07 10:14:06.535909.535909 lmp.py:767]   Expert  4 |    100 | CPU
DEBUG 01-07 10:14:06.535552.535552 lmp.py:767]   Expert 28 |    107 | CPU
DEBUG 01-07 10:14:06.535957.535957 lmp.py:767]   Expert 32 |    114 | CPU
DEBUG 01-07 10:14:06.535123.535123 lmp.py:767]   Expert 60 |    116 | CPU
DEBUG 01-07 10:14:06.535289.535289 lmp.py:767]   Expert 36 |    122 | CPU
DEBUG 01-07 10:14:06.535694.535694 lmp.py:767]   Expert 14 |    127 | CPU
DEBUG 01-07 10:14:06.535621.535621 lmp.py:767]   Expert  8 |    128 | CPU
DEBUG 01-07 10:14:06.535980.535980 lmp.py:767]   Expert 12 |    128 | CPU
DEBUG 01-07 10:14:06.535099.535099 lmp.py:767]   Expert 25 |    129 | CPU
DEBUG 01-07 10:14:06.535981.535981 lmp.py:767]   Expert 52 |    130 | CPU
DEBUG 01-07 10:14:06.535862.535862 lmp.py:767]   Expert 16 |    131 | CPU
DEBUG 01-07 10:14:06.535267.535267 lmp.py:767]   Expert  2 |    137 | CPU
DEBUG 01-07 10:14:06.535433.535433 lmp.py:767]   Expert 35 |    144 | CPU
DEBUG 01-07 10:14:06.535314.535314 lmp.py:767]   Expert  5 |    147 | GPU0(cuda:1)
DEBUG 01-07 10:14:06.535434.535434 lmp.py:767]   Expert 23 |    156 | GPU1(cuda:2)
DEBUG 01-07 10:14:06.535315.535315 lmp.py:767]   Expert 39 |    156 | GPU0(cuda:1)
DEBUG 01-07 10:14:06.535958.535958 lmp.py:767]   Expert 61 |    156 | GPU1(cuda:2)
DEBUG 01-07 10:14:06.535078.535078 lmp.py:767]   Expert  0 |    159 | GPU1(cuda:2)
DEBUG 01-07 10:14:06.535960.535960 lmp.py:767]   Expert 30 |    160 | GPU0(cuda:1)
DEBUG 01-07 10:14:06.535603.535603 lmp.py:767]   Expert 42 |    165 | GPU0(cuda:1)
DEBUG 01-07 10:14:06.535484.535484 lmp.py:767]   Expert 13 |    171 | GPU1(cuda:2)
DEBUG 01-07 10:14:06.535842.535842 lmp.py:767]   Expert  3 |    172 | GPU0(cuda:1)
DEBUG 01-07 10:14:06.535200.535200 lmp.py:767]   Expert 31 |    174 | GPU1(cuda:2)
DEBUG 01-07 10:14:06.535320.535320 lmp.py:767]   Expert  9 |    176 | GPU0(cuda:1)
DEBUG 01-07 10:14:06.535917.535917 lmp.py:767]   Expert 41 |    177 | GPU0(cuda:1)
DEBUG 01-07 10:14:06.535798.535798 lmp.py:767]   Expert 44 |    177 | GPU1(cuda:2)
DEBUG 01-07 10:14:06.535441.535441 lmp.py:767]   Expert 46 |    179 | GPU1(cuda:2)
DEBUG 01-07 10:14:06.535323.535323 lmp.py:767]   Expert 43 |    180 | GPU0(cuda:1)
DEBUG 01-07 10:14:06.535204.535204 lmp.py:767]   Expert 62 |    186 | GPU1(cuda:2)
DEBUG 01-07 10:14:06.535085.535085 lmp.py:767]   Expert 26 |    191 | GPU1(cuda:2)
DEBUG 01-07 10:14:06.535728.535728 lmp.py:767]   Expert 50 |    191 | GPU0(cuda:1)
DEBUG 01-07 10:14:06.535371.535371 lmp.py:767]   Expert 18 |    192 | GPU0(cuda:1)
DEBUG 01-07 10:14:06.535776.535776 lmp.py:767]   Expert 49 |    193 | GPU0(cuda:1)
DEBUG 01-07 10:14:06.535657.535657 lmp.py:767]   Expert 51 |    193 | GPU1(cuda:2)
DEBUG 01-07 10:14:06.535300.535300 lmp.py:767]   Expert 27 |    194 | GPU1(cuda:2)
DEBUG 01-07 10:14:06.535943.535943 lmp.py:767]   Expert 47 |    201 | GPU0(cuda:1)
DEBUG 01-07 10:14:06.535586.535586 lmp.py:767]   Expert 11 |    202 | GPU1(cuda:2)
DEBUG 01-07 10:14:06.535468.535468 lmp.py:767]   Expert 20 |    203 | GPU0(cuda:1)
DEBUG 01-07 10:14:06.535541.535541 lmp.py:767]   Expert 63 |    204 | GPU1(cuda:2)
DEBUG 01-07 10:14:06.535899.535899 lmp.py:767]   Expert 19 |    206 | GPU0(cuda:1)
DEBUG 01-07 10:14:06.535258.535258 lmp.py:767]   Expert 55 |    207 | GPU1(cuda:2)
DEBUG 01-07 10:14:06.535377.535377 lmp.py:767]   Expert 56 |    213 | GPU0(cuda:1)
DEBUG 01-07 10:14:06.535259.535259 lmp.py:767]   Expert 38 |    219 | GPU1(cuda:2)
DEBUG 01-07 10:14:06.535140.535140 lmp.py:767]   Expert 48 |    221 | GPU0(cuda:1)
DEBUG 01-07 10:14:06.535022.535022 lmp.py:767]   Expert  1 |    237 | GPU1(cuda:2)
DEBUG 01-07 10:14:06.535141.535141 lmp.py:767]   Expert 10 |    241 | GPU0(cuda:1)
DEBUG 01-07 10:14:06.535546.535546 lmp.py:767]   Expert 54 |    246 | GPU1(cuda:2)
DEBUG 01-07 10:14:06.535189.535189 lmp.py:767]   Expert  7 |    247 | GPU0(cuda:1)
DEBUG 01-07 10:14:06.535832.535832 lmp.py:767]   Expert 21 |    249 | GPU1(cuda:2)
DEBUG 01-07 10:14:06.535475.535475 lmp.py:767]   Expert 33 |    255 | GPU0(cuda:1)
DEBUG 01-07 10:14:06.535879.535879 lmp.py:767]   Expert 29 |    260 | GPU1(cuda:2)
DEBUG 01-07 10:14:06.535761.535761 lmp.py:767]   Expert 40 |    266 | GPU0(cuda:1)
DEBUG 01-07 10:14:06.536881.536881 lmp.py:767]   Expert 24 |    272 | GPU1(cuda:2)
DEBUG 01-07 10:14:06.536000.536000 lmp.py:767]   Expert 59 |    295 | GPU0(cuda:1)
DEBUG 01-07 10:14:06.536597.536597 lmp.py:767]   Expert 37 |    335 | GPU1(cuda:2)
DEBUG 01-07 10:14:06.536955.536955 lmp.py:767]   Expert 58 |    366 | GPU1(cuda:2)
DEBUG 01-07 10:14:06.536552.536552 lmp.py:767]   Expert  6 |    390 | GPU1(cuda:2)
DEBUG 01-07 10:14:06.536672.536672 lmp.py:767]   Expert 53 |    858 | GPU0(cuda:1)
DEBUG 01-07 10:14:06.536123.536123 lmp.py:769] 
DEBUG 01-07 10:14:06.536123.536123 lmp.py:769]   Device Token Distribution:
DEBUG 01-07 10:14:06.536527.536527 lmp.py:770]   CPU:   2050 tokens
DEBUG 01-07 10:14:06.536124.536124 lmp.py:774]   cuda:1:   5115 tokens (22 experts)
DEBUG 01-07 10:14:06.536767.536767 lmp.py:774]   cuda:2:   5123 tokens (23 experts)
DEBUG 01-07 10:14:06.536695.536695 lmp.py:775]   Total GPU:  10238 tokens
DEBUG 01-07 10:14:06.536145.536145 lmp.py:776] ============================================================
DEBUG 01-07 10:14:06.536145.536145 lmp.py:776] 
DEBUG 01-07 10:14:06.536511.536511 cuda_h.py:19] end experts_map_get cost 0.0017719268798828125 seconds
DEBUG 01-07 10:14:06.536107.536107 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model_multi_device
DEBUG 01-07 10:14:06.536830.536830 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 10:14:06.536357.536357 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 10:14:06.536862.536862 cuda_h.py:19] end allocate_cuda_memory cost 0.00019931793212890625 seconds
DEBUG 01-07 10:14:06.536765.536765 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 10:14:06.536759.536759 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 10:14:06.536045.536045 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 10:14:06.536648.536648 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 02fceb2f-cfdd-4b87-a7ff-5279b8b219b9
DEBUG 01-07 10:14:06.536614.536614 client.py:106] call stub.LoadModelAsync
INFO 01-07 10:14:06.537539.537539 client.py:127] Model loaded
DEBUG 01-07 10:14:06.537270.537270 cuda_h.py:19] end sllm_worker_task cost 0.008702993392944336 seconds
INFO 01-07 10:14:06.537606.537606 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 02fceb2f-cfdd-4b87-a7ff-5279b8b219b9
DEBUG 01-07 10:14:06.537880.537880 cuda_h.py:19] end load_into_gpu_async cost 0.0010344982147216797 seconds
DEBUG 01-07 10:14:06.537675.537675 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 10:14:06.538846.538846 cuda_h.py:19] end restore_tensors2 cost 0.0003116130828857422 seconds
DEBUG 01-07 10:14:06.538198.538198 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.001863718032836914 seconds
DEBUG 01-07 10:14:06.540294.540294 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 10:14:06.540801.540801 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 10:14:06.540127.540127 cuda_h.py:19] end allocate_cuda_memory cost 0.000202178955078125 seconds
DEBUG 01-07 10:14:06.540778.540778 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 10:14:06.540673.540673 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 10:14:06.540098.540098 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 10:14:06.540317.540317 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, b6f3d86e-1317-44d6-b937-1a08332142a3
DEBUG 01-07 10:14:06.540461.540461 client.py:106] call stub.LoadModelAsync
INFO 01-07 10:14:06.541450.541450 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, b6f3d86e-1317-44d6-b937-1a08332142a3
DEBUG 01-07 10:14:06.541088.541088 cuda_h.py:19] end load_into_gpu_async cost 0.0011112689971923828 seconds
DEBUG 01-07 10:14:06.541645.541645 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 10:14:06.541093.541093 cuda_h.py:19] end restore_tensors2 cost 0.0003044605255126953 seconds
DEBUG 01-07 10:14:06.542446.542446 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0019180774688720703 seconds
DEBUG 01-07 10:14:06.543701.543701 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model_multi_device cost 0.007609844207763672 seconds
DEBUG 01-07 10:14:06.543768.543768 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-07 10:14:06.544923.544923 lmp.py:816] 
DEBUG 01-07 10:14:06.544923.544923 lmp.py:816]   Computing 19 experts on CPU...
DEBUG 01-07 10:14:06.544336.544336 cuda_h.py:19] end cpu_experts_submit cost 0.00011014938354492188 seconds
DEBUG 01-07 10:14:06.544655.544655 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-07 10:14:06.550037.550037 mlpmodule.py:749] group tensors cost 0.006333112716674805 s
DEBUG 01-07 10:14:06.553296.553296 mlpmodule.py:787] pad cost 0.0017230510711669922 s
DEBUG 01-07 10:14:06.553970.553970 mlpmodule.py:793] create cpu tensor cost 5.91278076171875e-05 s
DEBUG 01-07 10:14:06.553173.553173 mlpmodule.py:798] move to cpu cost 4.57763671875e-05 s
DEBUG 01-07 10:14:06.564506.564506 mlpmodule.py:812] group_w3: shape=torch.Size([19, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=54788096
DEBUG 01-07 10:14:06.564327.564327 mlpmodule.py:813] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-07 10:14:06.564585.564585 mlpmodule.py:818] group_w3 first element: -0.010498046875
WARNING 01-07 10:14:06.564881.564881 mlpmodule.py:828] start einsum2
DEBUG 01-07 10:14:06.579067.579067 mlpmodule.py:838] group einsum cost 0.026401281356811523 s
DEBUG 01-07 10:14:06.580633.580633 mlpmodule.py:846] cpy2cputensor cost 0.0004870891571044922 s
DEBUG 01-07 10:14:06.583363.583363 cuda_h.py:19] end wait_cetm_experts cost 0.03910017013549805 seconds
DEBUG 01-07 10:14:06.583584.583584 cuda_h.py:10] start gpu_sexperts
DEBUG 01-07 10:14:06.583484.583484 cuda_h.py:19] end gpu_sexperts cost 0.0005140304565429688 seconds
DEBUG 01-07 10:14:06.583804.583804 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-07 10:14:06.584938.584938 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.6464462280273438e-05 seconds
DEBUG 01-07 10:14:06.584880.584880 cuda_h.py:10] start wait_experts_multi_device
INFO 01-07 10:14:06.584305.584305 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 02fceb2f-cfdd-4b87-a7ff-5279b8b219b9
INFO 01-07 10:14:06.584858.584858 client.py:127] Model loaded
INFO 01-07 10:14:06.585886.585886 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, b6f3d86e-1317-44d6-b937-1a08332142a3
INFO 01-07 10:14:06.586936.586936 client.py:127] Model loaded
DEBUG 01-07 10:14:06.586912.586912 cuda_h.py:19] end wait_experts_multi_device cost 0.002310037612915039 seconds
DEBUG 01-07 10:14:06.586098.586098 cuda_h.py:10] start gpu_experts_multi_device
DEBUG 01-07 10:14:06.586782.586782 lmp.py:867]   Computing 23 experts on cuda:2...
DEBUG 01-07 10:14:06.587551.587551 mlpmodule.py:533] gpu group tensors cost 0.0005223751068115234 s
DEBUG 01-07 10:14:06.589201.589201 mlpmodule.py:566] gpu pad cost 0.0013628005981445312 s
DEBUG 01-07 10:14:06.589349.589349 mlpmodule.py:584] gpu group einsum cost 0.0005800724029541016 s
DEBUG 01-07 10:14:06.591415.591415 mlpmodule.py:656] gpu experts func einsum cost 0.004777431488037109 s
DEBUG 01-07 10:14:06.592314.592314 lmp.py:867]   Computing 22 experts on cuda:1...
DEBUG 01-07 10:14:06.593982.593982 mlpmodule.py:533] gpu group tensors cost 0.0004572868347167969 s
DEBUG 01-07 10:14:06.593089.593089 mlpmodule.py:707]  experts func einsum cost 0.04926490783691406 s
DEBUG 01-07 10:14:06.594860.594860 mlpmodule.py:566] gpu pad cost 0.0016336441040039062 s
DEBUG 01-07 10:14:06.595482.595482 mlpmodule.py:584] gpu group einsum cost 0.0010657310485839844 s
DEBUG 01-07 10:14:06.597415.597415 mlpmodule.py:656] gpu experts func einsum cost 0.004885196685791016 s
DEBUG 01-07 10:14:06.597299.597299 cuda_h.py:19] end gpu_experts_multi_device cost 0.011109113693237305 seconds
DEBUG 01-07 10:14:06.597030.597030 cuda_h.py:19] end layer_moe_generate_multi_device_5 cost 0.06394147872924805 seconds
DEBUG 01-07 10:14:06.597522.597522 lmp.py:194] -------------------------------- end prefill layer 5 --------------------------------
DEBUG 01-07 10:14:06.597000.597000 lmp.py:153] -------------------------------- start prefill layer 6 --------------------------------
DEBUG 01-07 10:14:06.597981.597981 cuda_h.py:10] start start_load_qkvogn_s_weight_l_7
DEBUG 01-07 10:14:06.597281.597281 cuda_h.py:10] start start_load_qkvogn_s_weight_l_7
DEBUG 01-07 10:14:06.598448.598448 cuda_h.py:19] end start_load_qkvogn_s_weight_l_7 cost 2.6941299438476562e-05 seconds
DEBUG 01-07 10:14:06.598767.598767 cuda_h.py:19] end start_load_qkvogn_s_weight_l_7 cost 5.602836608886719e-05 seconds
DEBUG 01-07 10:14:06.598125.598125 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-07 10:14:06.598008.598008 mlpmodule.py:367] cuda:1 cuda:1
DEBUG 01-07 10:14:06.598010.598010 cuda_h.py:10] start sllm_worker_task
DEBUG 01-07 10:14:06.598762.598762 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 10:14:06.598883.598883 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 10:14:06.598538.598538 cuda_h.py:19] end allocate_cuda_memory cost 0.00016880035400390625 seconds
DEBUG 01-07 10:14:06.598289.598289 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 10:14:06.598283.598283 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 10:14:06.598722.598722 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 10:14:06.598425.598425 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 8e7a6176-e5ad-41a4-aaf9-01ed1b2140aa
DEBUG 01-07 10:14:06.598811.598811 client.py:106] call stub.LoadModelAsync
DEBUG 01-07 10:14:06.599297.599297 cuda_h.py:10] start self_attn
INFO 01-07 10:14:06.599703.599703 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 8e7a6176-e5ad-41a4-aaf9-01ed1b2140aa
DEBUG 01-07 10:14:06.599963.599963 cuda_h.py:19] end load_into_gpu_async cost 0.0009219646453857422 seconds
DEBUG 01-07 10:14:06.599282.599282 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 10:14:06.599596.599596 cuda_h.py:19] end restore_tensors2 cost 6.580352783203125e-05 seconds
DEBUG 01-07 10:14:06.599445.599445 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0013844966888427734 seconds
INFO 01-07 10:14:06.599353.599353 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 8e7a6176-e5ad-41a4-aaf9-01ed1b2140aa
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-07 10:14:06.602972.602972 cuda_h.py:19] end self_attn cost 0.0037012100219726562 seconds
DEBUG 01-07 10:14:06.603731.603731 cuda_h.py:19] end iln_self_attn_paln cost 0.005018472671508789 seconds
DEBUG 01-07 10:14:06.603415.603415 cuda_h.py:10] start layer_moe_generate_multi_device_6
DEBUG 01-07 10:14:06.603840.603840 cuda_h.py:10] start gate
DEBUG 01-07 10:14:06.603856.603856 cuda_h.py:19] end gate cost 0.0006451606750488281 seconds
DEBUG 01-07 10:14:06.603732.603732 cuda_h.py:10] start experts_map_get
DEBUG 01-07 10:14:06.604275.604275 lmp.py:744] 
DEBUG 01-07 10:14:06.604275.604275 lmp.py:744] Expert Token Distribution & Multi-Device Allocation:
DEBUG 01-07 10:14:06.604912.604912 lmp.py:745]   Total experts: 64
DEBUG 01-07 10:14:06.604661.604661 lmp.py:746]   CPU experts: 19 (30%)
DEBUG 01-07 10:14:06.604126.604126 lmp.py:747]   GPU experts: 45 (70%)
DEBUG 01-07 10:14:06.604007.604007 lmp.py:748]   Number of GPU devices: 2
DEBUG 01-07 10:14:06.604412.604412 lmp.py:749] 
DEBUG 01-07 10:14:06.604412.604412 lmp.py:749]   Expert ID | Tokens | Device
DEBUG 01-07 10:14:06.604340.604340 lmp.py:750]   -----------------------------------
DEBUG 01-07 10:14:06.604943.604943 lmp.py:767]   Expert  1 |     42 | CPU
DEBUG 01-07 10:14:06.604109.604109 lmp.py:767]   Expert  7 |     58 | CPU
DEBUG 01-07 10:14:06.604798.604798 lmp.py:767]   Expert 37 |     74 | CPU
DEBUG 01-07 10:14:06.604249.604249 lmp.py:767]   Expert 54 |     79 | CPU
DEBUG 01-07 10:14:06.604462.604462 lmp.py:767]   Expert 17 |     84 | CPU
DEBUG 01-07 10:14:06.604674.604674 lmp.py:767]   Expert 18 |     84 | CPU
DEBUG 01-07 10:14:06.604364.604364 lmp.py:767]   Expert  9 |     93 | CPU
DEBUG 01-07 10:14:06.604814.604814 lmp.py:767]   Expert 13 |     94 | CPU
DEBUG 01-07 10:14:06.604265.604265 lmp.py:767]   Expert 22 |    103 | CPU
DEBUG 01-07 10:14:06.604193.604193 lmp.py:767]   Expert 58 |    103 | CPU
DEBUG 01-07 10:14:06.604121.604121 lmp.py:767]   Expert  0 |    108 | CPU
DEBUG 01-07 10:14:06.604048.604048 lmp.py:767]   Expert 16 |    114 | CPU
DEBUG 01-07 10:14:06.604215.604215 lmp.py:767]   Expert 26 |    116 | CPU
DEBUG 01-07 10:14:06.604904.604904 lmp.py:767]   Expert 10 |    124 | CPU
DEBUG 01-07 10:14:06.604878.604878 lmp.py:767]   Expert 63 |    124 | CPU
DEBUG 01-07 10:14:06.604090.604090 lmp.py:767]   Expert 59 |    127 | CPU
DEBUG 01-07 10:14:06.604541.604541 lmp.py:767]   Expert 33 |    144 | CPU
DEBUG 01-07 10:14:06.604515.604515 lmp.py:767]   Expert 43 |    144 | CPU
DEBUG 01-07 10:14:06.604728.604728 lmp.py:767]   Expert 62 |    145 | CPU
DEBUG 01-07 10:14:06.604609.604609 lmp.py:767]   Expert 28 |    148 | GPU1(cuda:2)
DEBUG 01-07 10:14:06.604252.604252 lmp.py:767]   Expert 29 |    154 | GPU1(cuda:2)
DEBUG 01-07 10:14:06.604849.604849 lmp.py:767]   Expert  2 |    158 | GPU0(cuda:1)
DEBUG 01-07 10:14:06.604730.604730 lmp.py:767]   Expert 45 |    164 | GPU1(cuda:2)
DEBUG 01-07 10:14:06.604612.604612 lmp.py:767]   Expert 51 |    164 | GPU0(cuda:1)
DEBUG 01-07 10:14:06.604970.604970 lmp.py:767]   Expert 55 |    164 | GPU1(cuda:2)
DEBUG 01-07 10:14:06.604374.604374 lmp.py:767]   Expert 11 |    165 | GPU1(cuda:2)
DEBUG 01-07 10:14:06.604541.604541 lmp.py:767]   Expert 53 |    165 | GPU0(cuda:1)
DEBUG 01-07 10:14:06.604945.604945 lmp.py:767]   Expert  3 |    166 | GPU0(cuda:1)
DEBUG 01-07 10:14:06.604111.604111 lmp.py:767]   Expert 40 |    167 | GPU0(cuda:1)
DEBUG 01-07 10:14:06.605277.605277 lmp.py:767]   Expert 23 |    170 | GPU0(cuda:1)
DEBUG 01-07 10:14:06.605444.605444 lmp.py:767]   Expert 32 |    170 | GPU1(cuda:2)
DEBUG 01-07 10:14:06.605610.605610 lmp.py:767]   Expert 14 |    172 | GPU1(cuda:2)
DEBUG 01-07 10:14:06.605776.605776 lmp.py:767]   Expert 34 |    174 | GPU0(cuda:1)
DEBUG 01-07 10:14:06.605465.605465 lmp.py:767]   Expert 41 |    180 | GPU1(cuda:2)
DEBUG 01-07 10:14:06.605585.605585 lmp.py:767]   Expert 52 |    181 | GPU0(cuda:1)
DEBUG 01-07 10:14:06.605705.605705 lmp.py:767]   Expert 42 |    184 | GPU1(cuda:2)
DEBUG 01-07 10:14:06.605348.605348 lmp.py:767]   Expert 21 |    186 | GPU0(cuda:1)
DEBUG 01-07 10:14:06.605991.605991 lmp.py:767]   Expert 57 |    194 | GPU1(cuda:2)
DEBUG 01-07 10:14:06.605634.605634 lmp.py:767]   Expert 30 |    195 | GPU0(cuda:1)
DEBUG 01-07 10:14:06.605800.605800 lmp.py:767]   Expert 15 |    202 | GPU1(cuda:2)
DEBUG 01-07 10:14:06.605489.605489 lmp.py:767]   Expert 35 |    208 | GPU0(cuda:1)
DEBUG 01-07 10:14:06.605417.605417 lmp.py:767]   Expert 12 |    217 | GPU1(cuda:2)
DEBUG 01-07 10:14:06.605345.605345 lmp.py:767]   Expert  4 |    218 | GPU0(cuda:1)
DEBUG 01-07 10:14:06.605034.605034 lmp.py:767]   Expert 50 |    226 | GPU1(cuda:2)
DEBUG 01-07 10:14:06.605962.605962 lmp.py:767]   Expert 19 |    228 | GPU0(cuda:1)
DEBUG 01-07 10:14:06.605889.605889 lmp.py:767]   Expert 46 |    229 | GPU1(cuda:2)
DEBUG 01-07 10:14:06.605532.605532 lmp.py:767]   Expert 24 |    231 | GPU0(cuda:1)
DEBUG 01-07 10:14:06.605381.605381 lmp.py:767]   Expert  8 |    233 | GPU1(cuda:2)
DEBUG 01-07 10:14:06.605024.605024 lmp.py:767]   Expert 49 |    234 | GPU0(cuda:1)
DEBUG 01-07 10:14:06.605144.605144 lmp.py:767]   Expert 44 |    236 | GPU1(cuda:2)
DEBUG 01-07 10:14:06.605071.605071 lmp.py:767]   Expert 38 |    239 | GPU0(cuda:1)
DEBUG 01-07 10:14:06.605238.605238 lmp.py:767]   Expert  6 |    248 | GPU1(cuda:2)
DEBUG 01-07 10:14:06.605404.605404 lmp.py:767]   Expert 47 |    249 | GPU0(cuda:1)
DEBUG 01-07 10:14:06.605331.605331 lmp.py:767]   Expert 61 |    253 | GPU1(cuda:2)
DEBUG 01-07 10:14:06.605213.605213 lmp.py:767]   Expert 31 |    256 | GPU0(cuda:1)
DEBUG 01-07 10:14:06.605333.605333 lmp.py:767]   Expert 39 |    281 | GPU1(cuda:2)
DEBUG 01-07 10:14:06.605214.605214 lmp.py:767]   Expert  5 |    303 | GPU0(cuda:1)
DEBUG 01-07 10:14:06.605287.605287 lmp.py:767]   Expert 27 |    311 | GPU1(cuda:2)
DEBUG 01-07 10:14:06.605646.605646 lmp.py:767]   Expert 36 |    312 | GPU0(cuda:1)
DEBUG 01-07 10:14:06.605004.605004 lmp.py:767]   Expert 60 |    338 | GPU1(cuda:2)
DEBUG 01-07 10:14:06.605554.605554 lmp.py:767]   Expert 20 |    341 | GPU0(cuda:1)
DEBUG 01-07 10:14:06.605674.605674 lmp.py:767]   Expert 48 |    369 | GPU1(cuda:2)
DEBUG 01-07 10:14:06.605555.605555 lmp.py:767]   Expert 25 |    398 | GPU1(cuda:2)
DEBUG 01-07 10:14:06.605675.605675 lmp.py:767]   Expert 56 |    547 | GPU0(cuda:1)
DEBUG 01-07 10:14:06.605365.605365 lmp.py:769] 
DEBUG 01-07 10:14:06.605365.605365 lmp.py:769]   Device Token Distribution:
DEBUG 01-07 10:14:06.605769.605769 lmp.py:770]   CPU:   1960 tokens
DEBUG 01-07 10:14:06.605604.605604 lmp.py:774]   cuda:1:   5092 tokens (22 experts)
DEBUG 01-07 10:14:06.605486.605486 lmp.py:774]   cuda:2:   5236 tokens (23 experts)
DEBUG 01-07 10:14:06.605367.605367 lmp.py:775]   Total GPU:  10328 tokens
DEBUG 01-07 10:14:06.605533.605533 lmp.py:776] ============================================================
DEBUG 01-07 10:14:06.605533.605533 lmp.py:776] 
DEBUG 01-07 10:14:06.605613.605613 cuda_h.py:19] end experts_map_get cost 0.0017802715301513672 seconds
DEBUG 01-07 10:14:06.605210.605210 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model_multi_device
DEBUG 01-07 10:14:06.605794.605794 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 10:14:06.605884.605884 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 10:14:06.606170.606170 cuda_h.py:19] end allocate_cuda_memory cost 0.000213623046875 seconds
DEBUG 01-07 10:14:06.606881.606881 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 10:14:06.606512.606512 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 10:14:06.606149.606149 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 10:14:06.606276.606276 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 43409b11-876d-4884-89a7-150326cd026d
DEBUG 01-07 10:14:06.606009.606009 client.py:106] call stub.LoadModelAsync
INFO 01-07 10:14:06.606479.606479 client.py:127] Model loaded
DEBUG 01-07 10:14:06.607610.607610 cuda_h.py:19] end sllm_worker_task cost 0.008738279342651367 seconds
INFO 01-07 10:14:06.607476.607476 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 43409b11-876d-4884-89a7-150326cd026d
DEBUG 01-07 10:14:06.607889.607889 cuda_h.py:19] end load_into_gpu_async cost 0.000978231430053711 seconds
DEBUG 01-07 10:14:06.607969.607969 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 10:14:06.607980.607980 cuda_h.py:19] end restore_tensors2 cost 0.0002987384796142578 seconds
DEBUG 01-07 10:14:06.607141.607141 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0018129348754882812 seconds
DEBUG 01-07 10:14:06.609011.609011 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 10:14:06.609526.609526 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 10:14:06.609825.609825 cuda_h.py:19] end allocate_cuda_memory cost 0.00021696090698242188 seconds
DEBUG 01-07 10:14:06.609000.609000 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 10:14:06.610848.610848 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 10:14:06.610796.610796 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 10:14:06.610685.610685 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 12026544-4bff-4765-8efa-61397812a3aa
DEBUG 01-07 10:14:06.610405.610405 client.py:106] call stub.LoadModelAsync
INFO 01-07 10:14:06.611309.611309 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 12026544-4bff-4765-8efa-61397812a3aa
DEBUG 01-07 10:14:06.611185.611185 cuda_h.py:19] end load_into_gpu_async cost 0.0011594295501708984 seconds
DEBUG 01-07 10:14:06.611504.611504 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 10:14:06.611872.611872 cuda_h.py:19] end restore_tensors2 cost 0.0002810955047607422 seconds
DEBUG 01-07 10:14:06.611224.611224 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.001963376998901367 seconds
DEBUG 01-07 10:14:06.613281.613281 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model_multi_device cost 0.007645606994628906 seconds
DEBUG 01-07 10:14:06.613257.613257 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-07 10:14:06.613034.613034 lmp.py:816] 
DEBUG 01-07 10:14:06.613034.613034 lmp.py:816]   Computing 19 experts on CPU...
DEBUG 01-07 10:14:06.613540.613540 cuda_h.py:19] end cpu_experts_submit cost 0.00010991096496582031 seconds
DEBUG 01-07 10:14:06.613097.613097 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-07 10:14:06.619637.619637 mlpmodule.py:749] group tensors cost 0.0059244632720947266 s
DEBUG 01-07 10:14:06.621817.621817 mlpmodule.py:787] pad cost 0.00135040283203125 s
DEBUG 01-07 10:14:06.622477.622477 mlpmodule.py:793] create cpu tensor cost 6.389617919921875e-05 s
DEBUG 01-07 10:14:06.622566.622566 mlpmodule.py:798] move to cpu cost 4.553794860839844e-05 s
DEBUG 01-07 10:14:06.634300.634300 mlpmodule.py:812] group_w3: shape=torch.Size([19, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=54788096
DEBUG 01-07 10:14:06.634320.634320 mlpmodule.py:813] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-07 10:14:06.635131.635131 mlpmodule.py:818] group_w3 first element: -0.003631591796875
WARNING 01-07 10:14:06.635023.635023 mlpmodule.py:828] start einsum2
DEBUG 01-07 10:14:06.649931.649931 mlpmodule.py:838] group einsum cost 0.02759861946105957 s
DEBUG 01-07 10:14:06.650767.650767 mlpmodule.py:846] cpy2cputensor cost 0.0004477500915527344 s
DEBUG 01-07 10:14:06.653371.653371 cuda_h.py:19] end wait_cetm_experts cost 0.03941178321838379 seconds
DEBUG 01-07 10:14:06.653216.653216 cuda_h.py:10] start gpu_sexperts
DEBUG 01-07 10:14:06.653691.653691 cuda_h.py:19] end gpu_sexperts cost 0.0005176067352294922 seconds
DEBUG 01-07 10:14:06.653111.653111 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-07 10:14:06.653676.653676 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.574920654296875e-05 seconds
DEBUG 01-07 10:14:06.653617.653617 cuda_h.py:10] start wait_experts_multi_device
INFO 01-07 10:14:06.653327.653327 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 43409b11-876d-4884-89a7-150326cd026d
INFO 01-07 10:14:06.655869.655869 client.py:127] Model loaded
INFO 01-07 10:14:06.655971.655971 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 12026544-4bff-4765-8efa-61397812a3aa
INFO 01-07 10:14:06.660829.660829 client.py:127] Model loaded
DEBUG 01-07 10:14:06.660672.660672 cuda_h.py:19] end wait_experts_multi_device cost 0.006363391876220703 seconds
DEBUG 01-07 10:14:06.660097.660097 cuda_h.py:10] start gpu_experts_multi_device
DEBUG 01-07 10:14:06.660848.660848 lmp.py:867]   Computing 23 experts on cuda:2...
DEBUG 01-07 10:14:06.661823.661823 mlpmodule.py:533] gpu group tensors cost 0.0005011558532714844 s
DEBUG 01-07 10:14:06.662971.662971 mlpmodule.py:707]  experts func einsum cost 0.04912972450256348 s
DEBUG 01-07 10:14:06.663091.663091 mlpmodule.py:566] gpu pad cost 0.001390218734741211 s
DEBUG 01-07 10:14:06.663445.663445 mlpmodule.py:584] gpu group einsum cost 0.0004305839538574219 s
DEBUG 01-07 10:14:06.665243.665243 mlpmodule.py:656] gpu experts func einsum cost 0.0043239593505859375 s
DEBUG 01-07 10:14:06.665920.665920 lmp.py:867]   Computing 22 experts on cuda:1...
DEBUG 01-07 10:14:06.666459.666459 mlpmodule.py:533] gpu group tensors cost 0.0004248619079589844 s
DEBUG 01-07 10:14:06.667408.667408 mlpmodule.py:566] gpu pad cost 0.0009980201721191406 s
DEBUG 01-07 10:14:06.667818.667818 mlpmodule.py:584] gpu group einsum cost 0.0003209114074707031 s
DEBUG 01-07 10:14:06.669889.669889 mlpmodule.py:656] gpu experts func einsum cost 0.0033752918243408203 s
DEBUG 01-07 10:14:06.669243.669243 cuda_h.py:19] end gpu_experts_multi_device cost 0.009051799774169922 seconds
DEBUG 01-07 10:14:06.669921.669921 cuda_h.py:19] end layer_moe_generate_multi_device_6 cost 0.06632041931152344 seconds
DEBUG 01-07 10:14:06.669770.669770 lmp.py:194] -------------------------------- end prefill layer 6 --------------------------------
DEBUG 01-07 10:14:06.669454.669454 lmp.py:153] -------------------------------- start prefill layer 7 --------------------------------
DEBUG 01-07 10:14:06.669435.669435 cuda_h.py:10] start start_load_qkvogn_s_weight_l_8
DEBUG 01-07 10:14:06.669237.669237 cuda_h.py:10] start start_load_qkvogn_s_weight_l_8
DEBUG 01-07 10:14:06.669073.669073 cuda_h.py:19] end start_load_qkvogn_s_weight_l_8 cost 2.7894973754882812e-05 seconds
DEBUG 01-07 10:14:06.669299.669299 cuda_h.py:19] end start_load_qkvogn_s_weight_l_8 cost 5.817413330078125e-05 seconds
DEBUG 01-07 10:14:06.669658.669658 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-07 10:14:06.670070.670070 mlpmodule.py:367] cuda:1 cuda:1
DEBUG 01-07 10:14:06.670013.670013 cuda_h.py:10] start sllm_worker_task
DEBUG 01-07 10:14:06.670631.670631 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 10:14:06.670606.670606 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 10:14:06.670391.670391 cuda_h.py:19] end allocate_cuda_memory cost 0.0002636909484863281 seconds
DEBUG 01-07 10:14:06.670824.670824 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 10:14:06.670726.670726 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 10:14:06.670495.670495 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 10:14:06.670576.670576 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, eae12e44-efd1-4c69-84f2-235bb5b415f5
DEBUG 01-07 10:14:06.670062.670062 client.py:106] call stub.LoadModelAsync
DEBUG 01-07 10:14:06.671885.671885 cuda_h.py:10] start self_attn
INFO 01-07 10:14:06.671971.671971 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, eae12e44-efd1-4c69-84f2-235bb5b415f5
DEBUG 01-07 10:14:06.671278.671278 cuda_h.py:19] end load_into_gpu_async cost 0.0008633136749267578 seconds
DEBUG 01-07 10:14:06.671073.671073 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 10:14:06.671626.671626 cuda_h.py:19] end restore_tensors2 cost 6.556510925292969e-05 seconds
DEBUG 01-07 10:14:06.671428.671428 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0014328956604003906 seconds
INFO 01-07 10:14:06.671450.671450 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, eae12e44-efd1-4c69-84f2-235bb5b415f5
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-07 10:14:06.674493.674493 cuda_h.py:19] end self_attn cost 0.0034770965576171875 seconds
DEBUG 01-07 10:14:06.674046.674046 cuda_h.py:19] end iln_self_attn_paln cost 0.004858493804931641 seconds
DEBUG 01-07 10:14:06.674730.674730 cuda_h.py:10] start layer_moe_generate_multi_device_7
DEBUG 01-07 10:14:06.674870.674870 cuda_h.py:10] start gate
DEBUG 01-07 10:14:06.675014.675014 cuda_h.py:19] end gate cost 0.0007040500640869141 seconds
DEBUG 01-07 10:14:06.675936.675936 cuda_h.py:10] start experts_map_get
DEBUG 01-07 10:14:06.676486.676486 lmp.py:744] 
DEBUG 01-07 10:14:06.676486.676486 lmp.py:744] Expert Token Distribution & Multi-Device Allocation:
DEBUG 01-07 10:14:06.676355.676355 lmp.py:745]   Total experts: 64
DEBUG 01-07 10:14:06.676436.676436 lmp.py:746]   CPU experts: 19 (30%)
DEBUG 01-07 10:14:06.676986.676986 lmp.py:747]   GPU experts: 45 (70%)
DEBUG 01-07 10:14:06.676629.676629 lmp.py:748]   Number of GPU devices: 2
DEBUG 01-07 10:14:06.676080.676080 lmp.py:749] 
DEBUG 01-07 10:14:06.676080.676080 lmp.py:749]   Expert ID | Tokens | Device
DEBUG 01-07 10:14:06.676246.676246 lmp.py:750]   -----------------------------------
DEBUG 01-07 10:14:06.676611.676611 lmp.py:767]   Expert 50 |     45 | CPU
DEBUG 01-07 10:14:06.676777.676777 lmp.py:767]   Expert  3 |     53 | CPU
DEBUG 01-07 10:14:06.676705.676705 lmp.py:767]   Expert 46 |     54 | CPU
DEBUG 01-07 10:14:06.676394.676394 lmp.py:767]   Expert  1 |     77 | CPU
DEBUG 01-07 10:14:06.676607.676607 lmp.py:767]   Expert  4 |     87 | CPU
DEBUG 01-07 10:14:06.676058.676058 lmp.py:767]   Expert 29 |     88 | CPU
DEBUG 01-07 10:14:06.676138.676138 lmp.py:767]   Expert 40 |     95 | CPU
DEBUG 01-07 10:14:06.676304.676304 lmp.py:767]   Expert 15 |     96 | CPU
DEBUG 01-07 10:14:06.676708.676708 lmp.py:767]   Expert  8 |    109 | CPU
DEBUG 01-07 10:14:06.676159.676159 lmp.py:767]   Expert 28 |    110 | CPU
DEBUG 01-07 10:14:06.676326.676326 lmp.py:767]   Expert 41 |    113 | CPU
DEBUG 01-07 10:14:06.676776.676776 lmp.py:767]   Expert 27 |    125 | CPU
DEBUG 01-07 10:14:06.676227.676227 lmp.py:767]   Expert 48 |    127 | CPU
DEBUG 01-07 10:14:06.676678.676678 lmp.py:767]   Expert  6 |    128 | CPU
DEBUG 01-07 10:14:06.676414.676414 lmp.py:767]   Expert 16 |    128 | CPU
DEBUG 01-07 10:14:06.676388.676388 lmp.py:767]   Expert 54 |    131 | CPU
DEBUG 01-07 10:14:06.676362.676362 lmp.py:767]   Expert 13 |    132 | CPU
DEBUG 01-07 10:14:06.676098.676098 lmp.py:767]   Expert 39 |    137 | CPU
DEBUG 01-07 10:14:06.676310.676310 lmp.py:767]   Expert 51 |    137 | CPU
DEBUG 01-07 10:14:06.676715.676715 lmp.py:767]   Expert 60 |    138 | GPU0(cuda:1)
DEBUG 01-07 10:14:06.676073.676073 lmp.py:767]   Expert  7 |    140 | GPU0(cuda:1)
DEBUG 01-07 10:14:06.676431.676431 lmp.py:767]   Expert 18 |    141 | GPU1(cuda:2)
DEBUG 01-07 10:14:06.676789.676789 lmp.py:767]   Expert 14 |    144 | GPU1(cuda:2)
DEBUG 01-07 10:14:06.676671.676671 lmp.py:767]   Expert 43 |    147 | GPU1(cuda:2)
DEBUG 01-07 10:14:06.676075.676075 lmp.py:767]   Expert 56 |    147 | GPU0(cuda:1)
DEBUG 01-07 10:14:06.676241.676241 lmp.py:767]   Expert 52 |    148 | GPU0(cuda:1)
DEBUG 01-07 10:14:06.676407.676407 lmp.py:767]   Expert 36 |    149 | GPU1(cuda:2)
DEBUG 01-07 10:14:06.676574.676574 lmp.py:767]   Expert 20 |    150 | GPU0(cuda:1)
DEBUG 01-07 10:14:06.676501.676501 lmp.py:767]   Expert 55 |    152 | GPU0(cuda:1)
DEBUG 01-07 10:14:06.676952.676952 lmp.py:767]   Expert 45 |    158 | GPU1(cuda:2)
DEBUG 01-07 10:14:06.676880.676880 lmp.py:767]   Expert 10 |    160 | GPU0(cuda:1)
DEBUG 01-07 10:14:06.676808.676808 lmp.py:767]   Expert 11 |    161 | GPU1(cuda:2)
DEBUG 01-07 10:14:06.676735.676735 lmp.py:767]   Expert  5 |    162 | GPU1(cuda:2)
DEBUG 01-07 10:14:06.676425.676425 lmp.py:767]   Expert 62 |    167 | GPU0(cuda:1)
DEBUG 01-07 10:14:06.676591.676591 lmp.py:767]   Expert 33 |    175 | GPU0(cuda:1)
DEBUG 01-07 10:14:06.676757.676757 lmp.py:767]   Expert 57 |    175 | GPU1(cuda:2)
DEBUG 01-07 10:14:06.676161.676161 lmp.py:767]   Expert 44 |    177 | GPU0(cuda:1)
DEBUG 01-07 10:14:06.676804.676804 lmp.py:767]   Expert 58 |    177 | GPU1(cuda:2)
DEBUG 01-07 10:14:06.676686.676686 lmp.py:767]   Expert 53 |    181 | GPU1(cuda:2)
DEBUG 01-07 10:14:06.676614.676614 lmp.py:767]   Expert 25 |    183 | GPU0(cuda:1)
DEBUG 01-07 10:14:06.676303.676303 lmp.py:767]   Expert 32 |    190 | GPU0(cuda:1)
DEBUG 01-07 10:14:06.676992.676992 lmp.py:767]   Expert  2 |    195 | GPU1(cuda:2)
DEBUG 01-07 10:14:06.677681.677681 lmp.py:767]   Expert 31 |    197 | GPU1(cuda:2)
DEBUG 01-07 10:14:06.677371.677371 lmp.py:767]   Expert 35 |    200 | GPU1(cuda:2)
DEBUG 01-07 10:14:06.677822.677822 lmp.py:767]   Expert 63 |    200 | GPU0(cuda:1)
DEBUG 01-07 10:14:06.677511.677511 lmp.py:767]   Expert 49 |    201 | GPU0(cuda:1)
DEBUG 01-07 10:14:06.677962.677962 lmp.py:767]   Expert 21 |    204 | GPU1(cuda:2)
DEBUG 01-07 10:14:06.677366.677366 lmp.py:767]   Expert 17 |    209 | GPU0(cuda:1)
DEBUG 01-07 10:14:06.677533.677533 lmp.py:767]   Expert 42 |    216 | GPU1(cuda:2)
DEBUG 01-07 10:14:06.677699.677699 lmp.py:767]   Expert 34 |    219 | GPU0(cuda:1)
DEBUG 01-07 10:14:06.677103.677103 lmp.py:767]   Expert 37 |    229 | GPU1(cuda:2)
DEBUG 01-07 10:14:06.677269.677269 lmp.py:767]   Expert 59 |    230 | GPU0(cuda:1)
DEBUG 01-07 10:14:06.677197.677197 lmp.py:767]   Expert  0 |    245 | GPU1(cuda:2)
DEBUG 01-07 10:14:06.677886.677886 lmp.py:767]   Expert 22 |    246 | GPU0(cuda:1)
DEBUG 01-07 10:14:06.677814.677814 lmp.py:767]   Expert 19 |    260 | GPU0(cuda:1)
DEBUG 01-07 10:14:06.677695.677695 lmp.py:767]   Expert 24 |    286 | GPU1(cuda:2)
DEBUG 01-07 10:14:06.677100.677100 lmp.py:767]   Expert 61 |    289 | GPU0(cuda:1)
DEBUG 01-07 10:14:06.677981.677981 lmp.py:767]   Expert 30 |    299 | GPU1(cuda:2)
DEBUG 01-07 10:14:06.677624.677624 lmp.py:767]   Expert 47 |    320 | GPU1(cuda:2)
DEBUG 01-07 10:14:06.677267.677267 lmp.py:767]   Expert 38 |    364 | GPU0(cuda:1)
DEBUG 01-07 10:14:06.677672.677672 lmp.py:767]   Expert 26 |    378 | GPU0(cuda:1)
DEBUG 01-07 10:14:06.677745.677745 lmp.py:767]   Expert 12 |    430 | GPU1(cuda:2)
DEBUG 01-07 10:14:06.677104.677104 lmp.py:767]   Expert  9 |    673 | GPU1(cuda:2)
DEBUG 01-07 10:14:06.677462.677462 lmp.py:767]   Expert 23 |    704 | GPU0(cuda:1)
DEBUG 01-07 10:14:06.677628.677628 lmp.py:769] 
DEBUG 01-07 10:14:06.677628.677628 lmp.py:769]   Device Token Distribution:
DEBUG 01-07 10:14:06.677225.677225 lmp.py:770]   CPU:   1972 tokens
DEBUG 01-07 10:14:06.677821.677821 lmp.py:774]   cuda:1:   5227 tokens (23 experts)
DEBUG 01-07 10:14:06.677703.677703 lmp.py:774]   cuda:2:   5089 tokens (22 experts)
DEBUG 01-07 10:14:06.677869.677869 lmp.py:775]   Total GPU:  10316 tokens
DEBUG 01-07 10:14:06.677035.677035 lmp.py:776] ============================================================
DEBUG 01-07 10:14:06.677035.677035 lmp.py:776] 
DEBUG 01-07 10:14:06.677400.677400 cuda_h.py:19] end experts_map_get cost 0.0017521381378173828 seconds
DEBUG 01-07 10:14:06.677281.677281 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model_multi_device
DEBUG 01-07 10:14:06.677674.677674 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 10:14:06.677439.677439 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 10:14:06.678581.678581 cuda_h.py:19] end allocate_cuda_memory cost 0.0004572868347167969 seconds
DEBUG 01-07 10:14:06.678199.678199 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 10:14:06.678909.678909 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 10:14:06.678241.678241 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 10:14:06.678653.678653 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, c583110e-16fa-4487-a4f8-bccc2faf69b3
DEBUG 01-07 10:14:06.678379.678379 client.py:106] call stub.LoadModelAsync
INFO 01-07 10:14:06.678513.678513 client.py:127] Model loaded
DEBUG 01-07 10:14:06.679916.679916 cuda_h.py:19] end sllm_worker_task cost 0.00892019271850586 seconds
INFO 01-07 10:14:06.679871.679871 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, c583110e-16fa-4487-a4f8-bccc2faf69b3
DEBUG 01-07 10:14:06.679614.679614 cuda_h.py:19] end load_into_gpu_async cost 0.0012903213500976562 seconds
DEBUG 01-07 10:14:06.679079.679079 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 10:14:06.679494.679494 cuda_h.py:19] end restore_tensors2 cost 0.0003151893615722656 seconds
DEBUG 01-07 10:14:06.679893.679893 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.002386808395385742 seconds
DEBUG 01-07 10:14:06.681581.681581 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 10:14:06.682890.682890 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 10:14:06.682209.682209 cuda_h.py:19] end allocate_cuda_memory cost 0.0001971721649169922 seconds
DEBUG 01-07 10:14:06.682999.682999 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 10:14:06.682371.682371 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 10:14:06.682034.682034 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 10:14:06.682207.682207 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 29753c64-22be-4db8-9dd3-4f4810f72bd2
DEBUG 01-07 10:14:06.682052.682052 client.py:106] call stub.LoadModelAsync
INFO 01-07 10:14:06.683009.683009 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 29753c64-22be-4db8-9dd3-4f4810f72bd2
DEBUG 01-07 10:14:06.683647.683647 cuda_h.py:19] end load_into_gpu_async cost 0.0013248920440673828 seconds
DEBUG 01-07 10:14:06.683204.683204 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 10:14:06.683054.683054 cuda_h.py:19] end restore_tensors2 cost 0.0002498626708984375 seconds
DEBUG 01-07 10:14:06.684354.684354 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0020596981048583984 seconds
DEBUG 01-07 10:14:06.685985.685985 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model_multi_device cost 0.008322000503540039 seconds
DEBUG 01-07 10:14:06.685821.685821 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-07 10:14:06.686499.686499 lmp.py:816] 
DEBUG 01-07 10:14:06.686499.686499 lmp.py:816]   Computing 19 experts on CPU...
DEBUG 01-07 10:14:06.686720.686720 cuda_h.py:19] end cpu_experts_submit cost 0.00010824203491210938 seconds
DEBUG 01-07 10:14:06.686277.686277 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-07 10:14:06.692525.692525 mlpmodule.py:749] group tensors cost 0.006092071533203125 s
DEBUG 01-07 10:14:06.694797.694797 mlpmodule.py:787] pad cost 0.001661539077758789 s
DEBUG 01-07 10:14:06.695160.695160 mlpmodule.py:793] create cpu tensor cost 7.200241088867188e-05 s
DEBUG 01-07 10:14:06.695277.695277 mlpmodule.py:798] move to cpu cost 5.1975250244140625e-05 s
DEBUG 01-07 10:14:06.708883.708883 mlpmodule.py:812] group_w3: shape=torch.Size([19, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=54788096
DEBUG 01-07 10:14:06.708856.708856 mlpmodule.py:813] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-07 10:14:06.708999.708999 mlpmodule.py:818] group_w3 first element: 0.01263427734375
WARNING 01-07 10:14:06.708314.708314 mlpmodule.py:828] start einsum2
DEBUG 01-07 10:14:06.724245.724245 mlpmodule.py:838] group einsum cost 0.029013633728027344 s
DEBUG 01-07 10:14:06.724155.724155 mlpmodule.py:846] cpy2cputensor cost 0.00044417381286621094 s
DEBUG 01-07 10:14:06.727533.727533 cuda_h.py:19] end wait_cetm_experts cost 0.04143500328063965 seconds
DEBUG 01-07 10:14:06.727523.727523 cuda_h.py:10] start gpu_sexperts
DEBUG 01-07 10:14:06.728059.728059 cuda_h.py:19] end gpu_sexperts cost 0.0005252361297607422 seconds
DEBUG 01-07 10:14:06.728955.728955 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-07 10:14:06.728136.728136 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.4080276489257812e-05 seconds
DEBUG 01-07 10:14:06.728727.728727 cuda_h.py:10] start wait_experts_multi_device
INFO 01-07 10:14:06.728775.728775 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, c583110e-16fa-4487-a4f8-bccc2faf69b3
INFO 01-07 10:14:06.732968.732968 client.py:127] Model loaded
INFO 01-07 10:14:06.732573.732573 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 29753c64-22be-4db8-9dd3-4f4810f72bd2
INFO 01-07 10:14:06.733117.733117 client.py:127] Model loaded
DEBUG 01-07 10:14:06.733285.733285 cuda_h.py:19] end wait_experts_multi_device cost 0.005539417266845703 seconds
DEBUG 01-07 10:14:06.734325.734325 cuda_h.py:10] start gpu_experts_multi_device
DEBUG 01-07 10:14:06.734678.734678 lmp.py:867]   Computing 22 experts on cuda:2...
DEBUG 01-07 10:14:06.735902.735902 mlpmodule.py:533] gpu group tensors cost 0.0004870891571044922 s
DEBUG 01-07 10:14:06.736992.736992 mlpmodule.py:566] gpu pad cost 0.0012302398681640625 s
DEBUG 01-07 10:14:06.737840.737840 mlpmodule.py:584] gpu group einsum cost 0.0005626678466796875 s
DEBUG 01-07 10:14:06.737634.737634 mlpmodule.py:707]  experts func einsum cost 0.05131220817565918 s
DEBUG 01-07 10:14:06.739175.739175 mlpmodule.py:656] gpu experts func einsum cost 0.004477262496948242 s
DEBUG 01-07 10:14:06.739814.739814 lmp.py:867]   Computing 23 experts on cuda:1...
DEBUG 01-07 10:14:06.740339.740339 mlpmodule.py:533] gpu group tensors cost 0.00038504600524902344 s
DEBUG 01-07 10:14:06.741927.741927 mlpmodule.py:566] gpu pad cost 0.0010819435119628906 s
DEBUG 01-07 10:14:06.741675.741675 mlpmodule.py:584] gpu group einsum cost 0.00032210350036621094 s
DEBUG 01-07 10:14:06.743290.743290 mlpmodule.py:656] gpu experts func einsum cost 0.003474712371826172 s
DEBUG 01-07 10:14:06.743830.743830 cuda_h.py:19] end gpu_experts_multi_device cost 0.009296178817749023 seconds
DEBUG 01-07 10:14:06.743031.743031 cuda_h.py:19] end layer_moe_generate_multi_device_7 cost 0.06848549842834473 seconds
DEBUG 01-07 10:14:06.743933.743933 lmp.py:194] -------------------------------- end prefill layer 7 --------------------------------
DEBUG 01-07 10:14:06.743955.743955 lmp.py:153] -------------------------------- start prefill layer 8 --------------------------------
DEBUG 01-07 10:14:06.743936.743936 cuda_h.py:10] start start_load_qkvogn_s_weight_l_9
DEBUG 01-07 10:14:06.743261.743261 cuda_h.py:10] start start_load_qkvogn_s_weight_l_9
DEBUG 01-07 10:14:06.743428.743428 cuda_h.py:19] end start_load_qkvogn_s_weight_l_9 cost 2.6464462280273438e-05 seconds
DEBUG 01-07 10:14:06.743416.743416 cuda_h.py:19] end start_load_qkvogn_s_weight_l_9 cost 5.626678466796875e-05 seconds
DEBUG 01-07 10:14:06.743013.743013 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-07 10:14:06.743240.743240 mlpmodule.py:367] cuda:1 cuda:1
DEBUG 01-07 10:14:06.743805.743805 cuda_h.py:10] start sllm_worker_task
DEBUG 01-07 10:14:06.744946.744946 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 10:14:06.744637.744637 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 10:14:06.744574.744574 cuda_h.py:19] end allocate_cuda_memory cost 0.00027060508728027344 seconds
DEBUG 01-07 10:14:06.744637.744637 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 10:14:06.744492.744492 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 10:14:06.744123.744123 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 10:14:06.744918.744918 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, cb247c28-7e63-4b44-b5e3-72759ebf96a8
DEBUG 01-07 10:14:06.744589.744589 client.py:106] call stub.LoadModelAsync
DEBUG 01-07 10:14:06.744598.744598 cuda_h.py:10] start self_attn
INFO 01-07 10:14:06.745181.745181 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, cb247c28-7e63-4b44-b5e3-72759ebf96a8
DEBUG 01-07 10:14:06.745249.745249 cuda_h.py:19] end load_into_gpu_async cost 0.0008378028869628906 seconds
DEBUG 01-07 10:14:06.745329.745329 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 10:14:06.745027.745027 cuda_h.py:19] end restore_tensors2 cost 6.771087646484375e-05 seconds
DEBUG 01-07 10:14:06.745591.745591 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0014269351959228516 seconds
INFO 01-07 10:14:06.745851.745851 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, cb247c28-7e63-4b44-b5e3-72759ebf96a8
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-07 10:14:06.748807.748807 cuda_h.py:19] end self_attn cost 0.0036020278930664062 seconds
DEBUG 01-07 10:14:06.748360.748360 cuda_h.py:19] end iln_self_attn_paln cost 0.004997730255126953 seconds
DEBUG 01-07 10:14:06.748328.748328 cuda_h.py:10] start layer_moe_generate_multi_device_8
DEBUG 01-07 10:14:06.748230.748230 cuda_h.py:10] start gate
DEBUG 01-07 10:14:06.749047.749047 cuda_h.py:19] end gate cost 0.0006392002105712891 seconds
DEBUG 01-07 10:14:06.749969.749969 cuda_h.py:10] start experts_map_get
DEBUG 01-07 10:14:06.750036.750036 lmp.py:744] 
DEBUG 01-07 10:14:06.750036.750036 lmp.py:744] Expert Token Distribution & Multi-Device Allocation:
DEBUG 01-07 10:14:06.750368.750368 lmp.py:745]   Total experts: 64
DEBUG 01-07 10:14:06.750402.750402 lmp.py:746]   CPU experts: 19 (30%)
DEBUG 01-07 10:14:06.750906.750906 lmp.py:747]   GPU experts: 45 (70%)
DEBUG 01-07 10:14:06.750264.750264 lmp.py:748]   Number of GPU devices: 2
DEBUG 01-07 10:14:06.750669.750669 lmp.py:749] 
DEBUG 01-07 10:14:06.750669.750669 lmp.py:749]   Expert ID | Tokens | Device
DEBUG 01-07 10:14:06.750550.750550 lmp.py:750]   -----------------------------------
DEBUG 01-07 10:14:06.750869.750869 lmp.py:767]   Expert 38 |     13 | CPU
DEBUG 01-07 10:14:06.750989.750989 lmp.py:767]   Expert 39 |     61 | CPU
DEBUG 01-07 10:14:06.750393.750393 lmp.py:767]   Expert  7 |     75 | CPU
DEBUG 01-07 10:14:06.750798.750798 lmp.py:767]   Expert 30 |     77 | CPU
DEBUG 01-07 10:14:06.750964.750964 lmp.py:767]   Expert 24 |     91 | CPU
DEBUG 01-07 10:14:06.750130.750130 lmp.py:767]   Expert 14 |     92 | CPU
DEBUG 01-07 10:14:06.750058.750058 lmp.py:767]   Expert 27 |     93 | CPU
DEBUG 01-07 10:14:06.750416.750416 lmp.py:767]   Expert 36 |     94 | CPU
DEBUG 01-07 10:14:06.750298.750298 lmp.py:767]   Expert 17 |     98 | CPU
DEBUG 01-07 10:14:06.750940.750940 lmp.py:767]   Expert 40 |     98 | CPU
DEBUG 01-07 10:14:06.750060.750060 lmp.py:767]   Expert 32 |    100 | CPU
DEBUG 01-07 10:14:06.750942.750942 lmp.py:767]   Expert 16 |    103 | CPU
DEBUG 01-07 10:14:06.750346.750346 lmp.py:767]   Expert 18 |    106 | CPU
DEBUG 01-07 10:14:06.750274.750274 lmp.py:767]   Expert  1 |    113 | CPU
DEBUG 01-07 10:14:06.750440.750440 lmp.py:767]   Expert 12 |    113 | CPU
DEBUG 01-07 10:14:06.750129.750129 lmp.py:767]   Expert 48 |    115 | CPU
DEBUG 01-07 10:14:06.750296.750296 lmp.py:767]   Expert  6 |    125 | CPU
DEBUG 01-07 10:14:06.750462.750462 lmp.py:767]   Expert 59 |    128 | CPU
DEBUG 01-07 10:14:06.750389.750389 lmp.py:767]   Expert 42 |    135 | CPU
DEBUG 01-07 10:14:06.750224.750224 lmp.py:767]   Expert  0 |    138 | GPU1(cuda:2)
DEBUG 01-07 10:14:06.750536.750536 lmp.py:767]   Expert 22 |    144 | GPU1(cuda:2)
DEBUG 01-07 10:14:06.750848.750848 lmp.py:767]   Expert 53 |    144 | GPU0(cuda:1)
DEBUG 01-07 10:14:06.750445.750445 lmp.py:767]   Expert 51 |    148 | GPU0(cuda:1)
DEBUG 01-07 10:14:06.750280.750280 lmp.py:767]   Expert  8 |    164 | GPU1(cuda:2)
DEBUG 01-07 10:14:06.750638.750638 lmp.py:767]   Expert 60 |    167 | GPU0(cuda:1)
DEBUG 01-07 10:14:06.750520.750520 lmp.py:767]   Expert 29 |    171 | GPU1(cuda:2)
DEBUG 01-07 10:14:06.750401.750401 lmp.py:767]   Expert 15 |    173 | GPU0(cuda:1)
DEBUG 01-07 10:14:06.750282.750282 lmp.py:767]   Expert 44 |    173 | GPU1(cuda:2)
DEBUG 01-07 10:14:06.750164.750164 lmp.py:767]   Expert 54 |    173 | GPU0(cuda:1)
DEBUG 01-07 10:14:06.750522.750522 lmp.py:767]   Expert 33 |    177 | GPU1(cuda:2)
DEBUG 01-07 10:14:06.750403.750403 lmp.py:767]   Expert 34 |    181 | GPU0(cuda:1)
DEBUG 01-07 10:14:06.750523.750523 lmp.py:767]   Expert 35 |    185 | GPU1(cuda:2)
DEBUG 01-07 10:14:06.750881.750881 lmp.py:767]   Expert 47 |    190 | GPU0(cuda:1)
DEBUG 01-07 10:14:06.750193.750193 lmp.py:767]   Expert  9 |    192 | GPU1(cuda:2)
DEBUG 01-07 10:14:06.750028.750028 lmp.py:767]   Expert 19 |    195 | GPU0(cuda:1)
DEBUG 01-07 10:14:06.750863.750863 lmp.py:767]   Expert 56 |    197 | GPU1(cuda:2)
DEBUG 01-07 10:14:06.750983.750983 lmp.py:767]   Expert  3 |    199 | GPU0(cuda:1)
DEBUG 01-07 10:14:06.750626.750626 lmp.py:767]   Expert 46 |    201 | GPU1(cuda:2)
DEBUG 01-07 10:14:06.750508.750508 lmp.py:767]   Expert 20 |    202 | GPU0(cuda:1)
DEBUG 01-07 10:14:06.750389.750389 lmp.py:767]   Expert 21 |    203 | GPU1(cuda:2)
DEBUG 01-07 10:14:06.750270.750270 lmp.py:767]   Expert 45 |    205 | GPU0(cuda:1)
DEBUG 01-07 10:14:06.750913.750913 lmp.py:767]   Expert 49 |    209 | GPU1(cuda:2)
DEBUG 01-07 10:14:06.751556.751556 lmp.py:767]   Expert 28 |    210 | GPU0(cuda:1)
DEBUG 01-07 10:14:06.751153.751153 lmp.py:767]   Expert  2 |    221 | GPU1(cuda:2)
DEBUG 01-07 10:14:06.751227.751227 lmp.py:767]   Expert 43 |    223 | GPU1(cuda:2)
DEBUG 01-07 10:14:06.751823.751823 lmp.py:767]   Expert 57 |    223 | GPU0(cuda:1)
DEBUG 01-07 10:14:06.751420.751420 lmp.py:767]   Expert 13 |    225 | GPU0(cuda:1)
DEBUG 01-07 10:14:06.751778.751778 lmp.py:767]   Expert  4 |    226 | GPU1(cuda:2)
DEBUG 01-07 10:14:06.751183.751183 lmp.py:767]   Expert 50 |    238 | GPU0(cuda:1)
DEBUG 01-07 10:14:06.751826.751826 lmp.py:767]   Expert 10 |    241 | GPU0(cuda:1)
DEBUG 01-07 10:14:06.751469.751469 lmp.py:767]   Expert 41 |    241 | GPU1(cuda:2)
DEBUG 01-07 10:14:06.751112.751112 lmp.py:767]   Expert 26 |    248 | GPU1(cuda:2)
DEBUG 01-07 10:14:06.751993.751993 lmp.py:767]   Expert 63 |    257 | GPU0(cuda:1)
DEBUG 01-07 10:14:06.751398.751398 lmp.py:767]   Expert 37 |    261 | GPU1(cuda:2)
DEBUG 01-07 10:14:06.751040.751040 lmp.py:767]   Expert 61 |    265 | GPU0(cuda:1)
DEBUG 01-07 10:14:06.751922.751922 lmp.py:767]   Expert 31 |    269 | GPU1(cuda:2)
DEBUG 01-07 10:14:06.751042.751042 lmp.py:767]   Expert 52 |    305 | GPU0(cuda:1)
DEBUG 01-07 10:14:06.751115.751115 lmp.py:767]   Expert 58 |    315 | GPU1(cuda:2)
DEBUG 01-07 10:14:06.751712.751712 lmp.py:767]   Expert 62 |    329 | GPU0(cuda:1)
DEBUG 01-07 10:14:06.751547.751547 lmp.py:767]   Expert 55 |    341 | GPU1(cuda:2)
DEBUG 01-07 10:14:06.751190.751190 lmp.py:767]   Expert 23 |    377 | GPU0(cuda:1)
DEBUG 01-07 10:14:06.751833.751833 lmp.py:767]   Expert 11 |    384 | GPU1(cuda:2)
DEBUG 01-07 10:14:06.751476.751476 lmp.py:767]   Expert 25 |    411 | GPU1(cuda:2)
DEBUG 01-07 10:14:06.751880.751880 lmp.py:767]   Expert  5 |    517 | GPU0(cuda:1)
DEBUG 01-07 10:14:06.751570.751570 lmp.py:769] 
DEBUG 01-07 10:14:06.751570.751570 lmp.py:769]   Device Token Distribution:
DEBUG 01-07 10:14:06.751736.751736 lmp.py:770]   CPU:   1830 tokens
DEBUG 01-07 10:14:06.751856.751856 lmp.py:774]   cuda:1:   5164 tokens (22 experts)
DEBUG 01-07 10:14:06.751499.751499 lmp.py:774]   cuda:2:   5294 tokens (23 experts)
DEBUG 01-07 10:14:06.751426.751426 lmp.py:775]   Total GPU:  10458 tokens
DEBUG 01-07 10:14:06.751308.751308 lmp.py:776] ============================================================
DEBUG 01-07 10:14:06.751308.751308 lmp.py:776] 
DEBUG 01-07 10:14:06.751150.751150 cuda_h.py:19] end experts_map_get cost 0.0017895698547363281 seconds
DEBUG 01-07 10:14:06.751985.751985 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model_multi_device
DEBUG 01-07 10:14:06.751900.751900 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 10:14:06.751513.751513 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 10:14:06.751010.751010 cuda_h.py:19] end allocate_cuda_memory cost 0.00019502639770507812 seconds
DEBUG 01-07 10:14:06.751913.751913 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 10:14:06.752669.752669 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 10:14:06.752240.752240 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 10:14:06.752890.752890 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 85570380-da11-45ce-9df4-9f0507f80af3
DEBUG 01-07 10:14:06.752431.752431 client.py:106] call stub.LoadModelAsync
INFO 01-07 10:14:06.752820.752820 client.py:127] Model loaded
DEBUG 01-07 10:14:06.752512.752512 cuda_h.py:19] end sllm_worker_task cost 0.008773088455200195 seconds
INFO 01-07 10:14:06.752534.752534 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 85570380-da11-45ce-9df4-9f0507f80af3
DEBUG 01-07 10:14:06.753226.753226 cuda_h.py:19] end load_into_gpu_async cost 0.0010051727294921875 seconds
DEBUG 01-07 10:14:06.753360.753360 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 10:14:06.753774.753774 cuda_h.py:19] end restore_tensors2 cost 0.00028014183044433594 seconds
DEBUG 01-07 10:14:06.753941.753941 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0017924308776855469 seconds
DEBUG 01-07 10:14:06.755797.755797 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 10:14:06.755682.755682 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 10:14:06.755637.755637 cuda_h.py:19] end allocate_cuda_memory cost 0.00020933151245117188 seconds
DEBUG 01-07 10:14:06.755335.755335 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 10:14:06.755375.755375 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 10:14:06.755231.755231 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 10:14:06.755642.755642 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 41869faa-511b-4580-b4e7-e906d15a5ff3
DEBUG 01-07 10:14:06.755693.755693 client.py:106] call stub.LoadModelAsync
INFO 01-07 10:14:06.756784.756784 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 41869faa-511b-4580-b4e7-e906d15a5ff3
DEBUG 01-07 10:14:06.756137.756137 cuda_h.py:19] end load_into_gpu_async cost 0.001191854476928711 seconds
DEBUG 01-07 10:14:06.756217.756217 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 10:14:06.757498.757498 cuda_h.py:19] end restore_tensors2 cost 0.00025272369384765625 seconds
DEBUG 01-07 10:14:06.757082.757082 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0019500255584716797 seconds
DEBUG 01-07 10:14:06.759629.759629 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model_multi_device cost 0.00754094123840332 seconds
DEBUG 01-07 10:14:06.759028.759028 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-07 10:14:06.759706.759706 lmp.py:816] 
DEBUG 01-07 10:14:06.759706.759706 lmp.py:816]   Computing 19 experts on CPU...
DEBUG 01-07 10:14:06.759734.759734 cuda_h.py:19] end cpu_experts_submit cost 0.00010728836059570312 seconds
DEBUG 01-07 10:14:06.759576.759576 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-07 10:14:06.771201.771201 mlpmodule.py:749] group tensors cost 0.012204885482788086 s
DEBUG 01-07 10:14:06.773383.773383 mlpmodule.py:787] pad cost 0.0009646415710449219 s
DEBUG 01-07 10:14:06.773512.773512 mlpmodule.py:793] create cpu tensor cost 4.076957702636719e-05 s
DEBUG 01-07 10:14:06.773077.773077 mlpmodule.py:798] move to cpu cost 3.075599670410156e-05 s
DEBUG 01-07 10:14:06.785758.785758 mlpmodule.py:812] group_w3: shape=torch.Size([19, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=54788096
DEBUG 01-07 10:14:06.785625.785625 mlpmodule.py:813] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-07 10:14:06.785436.785436 mlpmodule.py:818] group_w3 first element: -0.03369140625
WARNING 01-07 10:14:06.785990.785990 mlpmodule.py:828] start einsum2
DEBUG 01-07 10:14:06.800971.800971 mlpmodule.py:838] group einsum cost 0.0266263484954834 s
DEBUG 01-07 10:14:06.800824.800824 mlpmodule.py:846] cpy2cputensor cost 0.0005354881286621094 s
DEBUG 01-07 10:14:06.803891.803891 cuda_h.py:19] end wait_cetm_experts cost 0.04418063163757324 seconds
DEBUG 01-07 10:14:06.803027.803027 cuda_h.py:10] start gpu_sexperts
DEBUG 01-07 10:14:06.804617.804617 cuda_h.py:19] end gpu_sexperts cost 0.0005586147308349609 seconds
DEBUG 01-07 10:14:06.804858.804858 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-07 10:14:06.804563.804563 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 4.76837158203125e-05 seconds
DEBUG 01-07 10:14:06.804664.804664 cuda_h.py:10] start wait_experts_multi_device
INFO 01-07 10:14:06.804658.804658 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 85570380-da11-45ce-9df4-9f0507f80af3
INFO 01-07 10:14:06.805871.805871 client.py:127] Model loaded
INFO 01-07 10:14:06.805131.805131 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 41869faa-511b-4580-b4e7-e906d15a5ff3
INFO 01-07 10:14:06.805364.805364 client.py:127] Model loaded
DEBUG 01-07 10:14:06.805001.805001 cuda_h.py:19] end wait_experts_multi_device cost 0.001344442367553711 seconds
DEBUG 01-07 10:14:06.805512.805512 cuda_h.py:10] start gpu_experts_multi_device
DEBUG 01-07 10:14:06.805759.805759 lmp.py:867]   Computing 23 experts on cuda:2...
DEBUG 01-07 10:14:06.806355.806355 mlpmodule.py:533] gpu group tensors cost 0.0004248619079589844 s
DEBUG 01-07 10:14:06.808930.808930 mlpmodule.py:566] gpu pad cost 0.0011019706726074219 s
DEBUG 01-07 10:14:06.808144.808144 mlpmodule.py:584] gpu group einsum cost 0.0005877017974853516 s
DEBUG 01-07 10:14:06.810966.810966 mlpmodule.py:656] gpu experts func einsum cost 0.0040361881256103516 s
DEBUG 01-07 10:14:06.810379.810379 lmp.py:867]   Computing 22 experts on cuda:1...
DEBUG 01-07 10:14:06.811884.811884 mlpmodule.py:533] gpu group tensors cost 0.0003886222839355469 s
DEBUG 01-07 10:14:06.812683.812683 mlpmodule.py:566] gpu pad cost 0.0010607242584228516 s
DEBUG 01-07 10:14:06.813613.813613 mlpmodule.py:584] gpu group einsum cost 0.0004153251647949219 s
DEBUG 01-07 10:14:06.813110.813110 mlpmodule.py:707]  experts func einsum cost 0.05421924591064453 s
DEBUG 01-07 10:14:06.814741.814741 mlpmodule.py:656] gpu experts func einsum cost 0.003825664520263672 s
DEBUG 01-07 10:14:06.814546.814546 cuda_h.py:19] end gpu_experts_multi_device cost 0.00909280776977539 seconds
DEBUG 01-07 10:14:06.815085.815085 cuda_h.py:19] end layer_moe_generate_multi_device_8 cost 0.06608295440673828 seconds
DEBUG 01-07 10:14:06.815179.815179 lmp.py:194] -------------------------------- end prefill layer 8 --------------------------------
DEBUG 01-07 10:14:06.815896.815896 lmp.py:153] -------------------------------- start prefill layer 9 --------------------------------
DEBUG 01-07 10:14:06.815546.815546 cuda_h.py:10] start start_load_qkvogn_s_weight_l_10
DEBUG 01-07 10:14:06.815017.815017 cuda_h.py:10] start start_load_qkvogn_s_weight_l_10
DEBUG 01-07 10:14:06.815376.815376 cuda_h.py:19] end start_load_qkvogn_s_weight_l_10 cost 2.7418136596679688e-05 seconds
DEBUG 01-07 10:14:06.815556.815556 cuda_h.py:19] end start_load_qkvogn_s_weight_l_10 cost 5.817413330078125e-05 seconds
DEBUG 01-07 10:14:06.815822.815822 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-07 10:14:06.815711.815711 mlpmodule.py:367] cuda:1 cuda:1
DEBUG 01-07 10:14:06.815561.815561 cuda_h.py:10] start sllm_worker_task
DEBUG 01-07 10:14:06.815987.815987 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 10:14:06.815340.815340 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 10:14:06.816509.816509 cuda_h.py:19] end allocate_cuda_memory cost 0.0002655982971191406 seconds
DEBUG 01-07 10:14:06.816219.816219 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 10:14:06.816691.816691 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 10:14:06.816129.816129 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 10:14:06.816117.816117 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, e522f139-1921-4109-ac8e-662083035e96
DEBUG 01-07 10:14:06.816888.816888 client.py:106] call stub.LoadModelAsync
DEBUG 01-07 10:14:06.816990.816990 cuda_h.py:10] start self_attn
INFO 01-07 10:14:06.816200.816200 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, e522f139-1921-4109-ac8e-662083035e96
DEBUG 01-07 10:14:06.816890.816890 cuda_h.py:19] end load_into_gpu_async cost 0.0008132457733154297 seconds
DEBUG 01-07 10:14:06.816163.816163 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 10:14:06.817954.817954 cuda_h.py:19] end restore_tensors2 cost 6.604194641113281e-05 seconds
DEBUG 01-07 10:14:06.817279.817279 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0013797283172607422 seconds
INFO 01-07 10:14:06.817414.817414 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, e522f139-1921-4109-ac8e-662083035e96
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-07 10:14:06.820772.820772 cuda_h.py:19] end self_attn cost 0.0037071704864501953 seconds
DEBUG 01-07 10:14:06.820155.820155 cuda_h.py:19] end iln_self_attn_paln cost 0.005165815353393555 seconds
DEBUG 01-07 10:14:06.820792.820792 cuda_h.py:10] start layer_moe_generate_multi_device_9
DEBUG 01-07 10:14:06.820409.820409 cuda_h.py:10] start gate
DEBUG 01-07 10:14:06.821524.821524 cuda_h.py:19] end gate cost 0.0006477832794189453 seconds
DEBUG 01-07 10:14:06.821831.821831 cuda_h.py:10] start experts_map_get
DEBUG 01-07 10:14:06.821089.821089 lmp.py:744] 
DEBUG 01-07 10:14:06.821089.821089 lmp.py:744] Expert Token Distribution & Multi-Device Allocation:
DEBUG 01-07 10:14:06.821706.821706 lmp.py:745]   Total experts: 64
DEBUG 01-07 10:14:06.821548.821548 lmp.py:746]   CPU experts: 19 (30%)
DEBUG 01-07 10:14:06.821814.821814 lmp.py:747]   GPU experts: 45 (70%)
DEBUG 01-07 10:14:06.822457.822457 lmp.py:748]   Number of GPU devices: 2
DEBUG 01-07 10:14:06.822623.822623 lmp.py:749] 
DEBUG 01-07 10:14:06.822623.822623 lmp.py:749]   Expert ID | Tokens | Device
DEBUG 01-07 10:14:06.822027.822027 lmp.py:750]   -----------------------------------
DEBUG 01-07 10:14:06.822108.822108 lmp.py:767]   Expert 24 |     42 | CPU
DEBUG 01-07 10:14:06.822989.822989 lmp.py:767]   Expert  2 |     44 | CPU
DEBUG 01-07 10:14:06.822155.822155 lmp.py:767]   Expert 32 |     63 | CPU
DEBUG 01-07 10:14:06.822037.822037 lmp.py:767]   Expert 19 |     71 | CPU
DEBUG 01-07 10:14:06.822680.822680 lmp.py:767]   Expert 26 |     71 | CPU
DEBUG 01-07 10:14:06.822846.822846 lmp.py:767]   Expert 50 |     72 | CPU
DEBUG 01-07 10:14:06.822535.822535 lmp.py:767]   Expert 15 |     79 | CPU
DEBUG 01-07 10:14:06.822463.822463 lmp.py:767]   Expert  4 |     82 | CPU
DEBUG 01-07 10:14:06.822390.822390 lmp.py:767]   Expert  7 |     82 | CPU
DEBUG 01-07 10:14:06.822841.822841 lmp.py:767]   Expert 28 |     83 | CPU
DEBUG 01-07 10:14:06.822531.822531 lmp.py:767]   Expert 60 |     85 | CPU
DEBUG 01-07 10:14:06.822220.822220 lmp.py:767]   Expert 59 |     87 | CPU
DEBUG 01-07 10:14:06.822625.822625 lmp.py:767]   Expert 49 |     96 | CPU
DEBUG 01-07 10:14:06.822791.822791 lmp.py:767]   Expert 23 |     98 | CPU
DEBUG 01-07 10:14:06.822480.822480 lmp.py:767]   Expert  5 |     99 | CPU
DEBUG 01-07 10:14:06.822931.822931 lmp.py:767]   Expert 12 |    106 | CPU
DEBUG 01-07 10:14:06.822620.822620 lmp.py:767]   Expert 27 |    106 | CPU
DEBUG 01-07 10:14:06.822548.822548 lmp.py:767]   Expert 10 |    111 | CPU
DEBUG 01-07 10:14:06.822237.822237 lmp.py:767]   Expert 41 |    120 | CPU
DEBUG 01-07 10:14:06.822595.822595 lmp.py:767]   Expert  3 |    124 | GPU1(cuda:2)
DEBUG 01-07 10:14:06.822669.822669 lmp.py:767]   Expert 20 |    128 | GPU0(cuda:1)
DEBUG 01-07 10:14:06.822027.822027 lmp.py:767]   Expert 13 |    129 | GPU0(cuda:1)
DEBUG 01-07 10:14:06.822147.822147 lmp.py:767]   Expert 25 |    129 | GPU1(cuda:2)
DEBUG 01-07 10:14:06.822790.822790 lmp.py:767]   Expert 40 |    130 | GPU1(cuda:2)
DEBUG 01-07 10:14:06.822194.822194 lmp.py:767]   Expert 16 |    137 | GPU1(cuda:2)
DEBUG 01-07 10:14:06.822837.822837 lmp.py:767]   Expert 37 |    146 | GPU0(cuda:1)
DEBUG 01-07 10:14:06.822196.822196 lmp.py:767]   Expert 17 |    148 | GPU0(cuda:1)
DEBUG 01-07 10:14:06.822315.822315 lmp.py:767]   Expert 35 |    152 | GPU1(cuda:2)
DEBUG 01-07 10:14:06.822197.822197 lmp.py:767]   Expert 22 |    153 | GPU0(cuda:1)
DEBUG 01-07 10:14:06.822840.822840 lmp.py:767]   Expert 47 |    155 | GPU1(cuda:2)
DEBUG 01-07 10:14:06.822483.822483 lmp.py:767]   Expert 53 |    163 | GPU1(cuda:2)
DEBUG 01-07 10:14:06.822364.822364 lmp.py:767]   Expert 39 |    169 | GPU0(cuda:1)
DEBUG 01-07 10:14:06.822769.822769 lmp.py:767]   Expert 44 |    178 | GPU1(cuda:2)
DEBUG 01-07 10:14:06.822412.822412 lmp.py:767]   Expert 38 |    179 | GPU0(cuda:1)
DEBUG 01-07 10:14:06.822770.822770 lmp.py:767]   Expert 36 |    180 | GPU1(cuda:2)
DEBUG 01-07 10:14:06.822413.822413 lmp.py:767]   Expert 58 |    183 | GPU0(cuda:1)
DEBUG 01-07 10:14:06.822056.822056 lmp.py:767]   Expert 18 |    185 | GPU1(cuda:2)
DEBUG 01-07 10:14:06.822699.822699 lmp.py:767]   Expert 52 |    187 | GPU0(cuda:1)
DEBUG 01-07 10:14:06.822103.822103 lmp.py:767]   Expert 62 |    193 | GPU0(cuda:1)
DEBUG 01-07 10:14:06.822508.822508 lmp.py:767]   Expert 11 |    209 | GPU0(cuda:1)
DEBUG 01-07 10:14:06.822389.822389 lmp.py:767]   Expert 48 |    209 | GPU1(cuda:2)
DEBUG 01-07 10:14:06.822032.822032 lmp.py:767]   Expert 30 |    217 | GPU1(cuda:2)
DEBUG 01-07 10:14:06.822914.822914 lmp.py:767]   Expert 14 |    224 | GPU0(cuda:1)
DEBUG 01-07 10:14:06.822557.822557 lmp.py:767]   Expert  1 |    228 | GPU1(cuda:2)
DEBUG 01-07 10:14:06.822961.822961 lmp.py:767]   Expert 51 |    232 | GPU0(cuda:1)
DEBUG 01-07 10:14:06.822081.822081 lmp.py:767]   Expert 31 |    235 | GPU0(cuda:1)
DEBUG 01-07 10:14:06.822439.822439 lmp.py:767]   Expert 42 |    235 | GPU1(cuda:2)
DEBUG 01-07 10:14:06.822321.822321 lmp.py:767]   Expert 45 |    238 | GPU1(cuda:2)
DEBUG 01-07 10:14:06.822964.822964 lmp.py:767]   Expert  6 |    239 | GPU1(cuda:2)
DEBUG 01-07 10:14:06.822368.822368 lmp.py:767]   Expert 34 |    267 | GPU0(cuda:1)
DEBUG 01-07 10:14:06.822011.822011 lmp.py:767]   Expert 29 |    269 | GPU0(cuda:1)
DEBUG 01-07 10:14:06.822893.822893 lmp.py:767]   Expert 33 |    272 | GPU1(cuda:2)
DEBUG 01-07 10:14:06.822297.822297 lmp.py:767]   Expert 57 |    292 | GPU0(cuda:1)
DEBUG 01-07 10:14:06.822894.822894 lmp.py:767]   Expert 61 |    308 | GPU1(cuda:2)
DEBUG 01-07 10:14:06.823014.823014 lmp.py:767]   Expert 43 |    311 | GPU0(cuda:1)
DEBUG 01-07 10:14:06.823895.823895 lmp.py:767]   Expert  0 |    314 | GPU1(cuda:2)
DEBUG 01-07 10:14:06.823300.823300 lmp.py:767]   Expert 46 |    356 | GPU0(cuda:1)
DEBUG 01-07 10:14:06.823943.823943 lmp.py:767]   Expert  8 |    380 | GPU1(cuda:2)
DEBUG 01-07 10:14:06.823586.823586 lmp.py:767]   Expert  9 |    393 | GPU0(cuda:1)
DEBUG 01-07 10:14:06.823229.823229 lmp.py:767]   Expert 54 |    397 | GPU1(cuda:2)
DEBUG 01-07 10:14:06.823110.823110 lmp.py:767]   Expert 56 |    398 | GPU0(cuda:1)
DEBUG 01-07 10:14:06.823468.823468 lmp.py:767]   Expert 63 |    410 | GPU1(cuda:2)
DEBUG 01-07 10:14:06.823350.823350 lmp.py:767]   Expert 55 |    424 | GPU1(cuda:2)
DEBUG 01-07 10:14:06.823754.823754 lmp.py:767]   Expert 21 |    486 | GPU0(cuda:1)
DEBUG 01-07 10:14:06.823443.823443 lmp.py:769] 
DEBUG 01-07 10:14:06.823443.823443 lmp.py:769]   Device Token Distribution:
DEBUG 01-07 10:14:06.823848.823848 lmp.py:770]   CPU:   1597 tokens
DEBUG 01-07 10:14:06.823729.823729 lmp.py:774]   cuda:1:   5287 tokens (22 experts)
DEBUG 01-07 10:14:06.823134.823134 lmp.py:774]   cuda:2:   5404 tokens (23 experts)
DEBUG 01-07 10:14:06.823300.823300 lmp.py:775]   Total GPU:  10691 tokens
DEBUG 01-07 10:14:06.823751.823751 lmp.py:776] ============================================================
DEBUG 01-07 10:14:06.823751.823751 lmp.py:776] 
DEBUG 01-07 10:14:06.823401.823401 cuda_h.py:19] end experts_map_get cost 0.0017614364624023438 seconds
DEBUG 01-07 10:14:06.823997.823997 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model_multi_device
DEBUG 01-07 10:14:06.823389.823389 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 10:14:06.823625.823625 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 10:14:06.823814.823814 cuda_h.py:19] end allocate_cuda_memory cost 0.0002772808074951172 seconds
DEBUG 01-07 10:14:06.823201.823201 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 10:14:06.823626.823626 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 10:14:06.823488.823488 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 10:14:06.823376.823376 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 3cc12dd5-cd58-4dac-bb3c-337f01c3f13a
DEBUG 01-07 10:14:06.824255.824255 client.py:106] call stub.LoadModelAsync
INFO 01-07 10:14:06.824360.824360 client.py:127] Model loaded
DEBUG 01-07 10:14:06.824445.824445 cuda_h.py:19] end sllm_worker_task cost 0.008941411972045898 seconds
INFO 01-07 10:14:06.824522.824522 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 3cc12dd5-cd58-4dac-bb3c-337f01c3f13a
DEBUG 01-07 10:14:06.824127.824127 cuda_h.py:19] end load_into_gpu_async cost 0.0009300708770751953 seconds
DEBUG 01-07 10:14:06.824976.824976 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 10:14:06.825933.825933 cuda_h.py:19] end restore_tensors2 cost 0.0002944469451904297 seconds
DEBUG 01-07 10:14:06.825663.825663 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0018301010131835938 seconds
DEBUG 01-07 10:14:06.827454.827454 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 10:14:06.827346.827346 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 10:14:06.827646.827646 cuda_h.py:19] end allocate_cuda_memory cost 0.00021791458129882812 seconds
DEBUG 01-07 10:14:06.827012.827012 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 10:14:06.827576.827576 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 10:14:06.827001.827001 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 10:14:06.827650.827650 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, a76cb553-eb26-4819-ab7e-431e33a02587
DEBUG 01-07 10:14:06.827178.827178 client.py:106] call stub.LoadModelAsync
INFO 01-07 10:14:06.828254.828254 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, a76cb553-eb26-4819-ab7e-431e33a02587
DEBUG 01-07 10:14:06.828812.828812 cuda_h.py:19] end load_into_gpu_async cost 0.0011191368103027344 seconds
DEBUG 01-07 10:14:06.828899.828899 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 10:14:06.828193.828193 cuda_h.py:19] end restore_tensors2 cost 0.00026106834411621094 seconds
DEBUG 01-07 10:14:06.829208.829208 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0019083023071289062 seconds
DEBUG 01-07 10:14:06.830648.830648 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model_multi_device cost 0.007546663284301758 seconds
DEBUG 01-07 10:14:06.830147.830147 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-07 10:14:06.831447.831447 lmp.py:816] 
DEBUG 01-07 10:14:06.831447.831447 lmp.py:816]   Computing 19 experts on CPU...
DEBUG 01-07 10:14:06.831205.831205 cuda_h.py:19] end cpu_experts_submit cost 0.0001201629638671875 seconds
DEBUG 01-07 10:14:06.831523.831523 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-07 10:14:06.837562.837562 mlpmodule.py:749] group tensors cost 0.0057599544525146484 s
DEBUG 01-07 10:14:06.838760.838760 mlpmodule.py:787] pad cost 0.0012364387512207031 s
DEBUG 01-07 10:14:06.839155.839155 mlpmodule.py:793] create cpu tensor cost 4.8160552978515625e-05 s
DEBUG 01-07 10:14:06.839701.839701 mlpmodule.py:798] move to cpu cost 4.0531158447265625e-05 s
DEBUG 01-07 10:14:06.850025.850025 mlpmodule.py:812] group_w3: shape=torch.Size([19, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=54788096
DEBUG 01-07 10:14:06.850038.850038 mlpmodule.py:813] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-07 10:14:06.850711.850711 mlpmodule.py:818] group_w3 first element: 0.0157470703125
WARNING 01-07 10:14:06.850026.850026 mlpmodule.py:828] start einsum2
DEBUG 01-07 10:14:06.866063.866063 mlpmodule.py:838] group einsum cost 0.02753305435180664 s
DEBUG 01-07 10:14:06.867063.867063 mlpmodule.py:846] cpy2cputensor cost 0.0003952980041503906 s
DEBUG 01-07 10:14:06.870563.870563 cuda_h.py:19] end wait_cetm_experts cost 0.03890204429626465 seconds
DEBUG 01-07 10:14:06.870940.870940 cuda_h.py:10] start gpu_sexperts
DEBUG 01-07 10:14:06.871343.871343 cuda_h.py:19] end gpu_sexperts cost 0.0008535385131835938 seconds
DEBUG 01-07 10:14:06.871446.871446 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-07 10:14:06.871120.871120 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 4.267692565917969e-05 seconds
DEBUG 01-07 10:14:06.871110.871110 cuda_h.py:10] start wait_experts_multi_device
INFO 01-07 10:14:06.871218.871218 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 3cc12dd5-cd58-4dac-bb3c-337f01c3f13a
INFO 01-07 10:14:06.872293.872293 client.py:127] Model loaded
INFO 01-07 10:14:06.873697.873697 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, a76cb553-eb26-4819-ab7e-431e33a02587
INFO 01-07 10:14:06.877845.877845 client.py:127] Model loaded
DEBUG 01-07 10:14:06.878188.878188 cuda_h.py:19] end wait_experts_multi_device cost 0.006399631500244141 seconds
DEBUG 01-07 10:14:06.878920.878920 cuda_h.py:10] start gpu_experts_multi_device
DEBUG 01-07 10:14:06.878467.878467 lmp.py:867]   Computing 23 experts on cuda:2...
DEBUG 01-07 10:14:06.880748.880748 mlpmodule.py:707]  experts func einsum cost 0.04931497573852539 s
DEBUG 01-07 10:14:06.880561.880561 mlpmodule.py:533] gpu group tensors cost 0.0011649131774902344 s
DEBUG 01-07 10:14:06.883182.883182 mlpmodule.py:566] gpu pad cost 0.0023686885833740234 s
DEBUG 01-07 10:14:06.884136.884136 mlpmodule.py:584] gpu group einsum cost 0.0008640289306640625 s
DEBUG 01-07 10:14:06.887372.887372 mlpmodule.py:656] gpu experts func einsum cost 0.007989645004272461 s
DEBUG 01-07 10:14:06.888467.888467 lmp.py:867]   Computing 22 experts on cuda:1...
DEBUG 01-07 10:14:06.889740.889740 mlpmodule.py:533] gpu group tensors cost 0.0006792545318603516 s
DEBUG 01-07 10:14:06.891873.891873 mlpmodule.py:566] gpu pad cost 0.0020706653594970703 s
DEBUG 01-07 10:14:06.892045.892045 mlpmodule.py:584] gpu group einsum cost 0.0006945133209228516 s
DEBUG 01-07 10:14:06.894081.894081 mlpmodule.py:656] gpu experts func einsum cost 0.00532841682434082 s
DEBUG 01-07 10:14:06.894097.894097 cuda_h.py:19] end gpu_experts_multi_device cost 0.015896320343017578 seconds
DEBUG 01-07 10:14:06.894365.894365 cuda_h.py:19] end layer_moe_generate_multi_device_9 cost 0.07346153259277344 seconds
DEBUG 01-07 10:14:06.894705.894705 lmp.py:194] -------------------------------- end prefill layer 9 --------------------------------
DEBUG 01-07 10:14:06.894488.894488 lmp.py:153] -------------------------------- start prefill layer 10 --------------------------------
DEBUG 01-07 10:14:06.894138.894138 cuda_h.py:10] start start_load_qkvogn_s_weight_l_11
DEBUG 01-07 10:14:06.894655.894655 cuda_h.py:10] start start_load_qkvogn_s_weight_l_11
DEBUG 01-07 10:14:06.894299.894299 cuda_h.py:19] end start_load_qkvogn_s_weight_l_11 cost 2.7418136596679688e-05 seconds
DEBUG 01-07 10:14:06.894333.894333 cuda_h.py:19] end start_load_qkvogn_s_weight_l_11 cost 5.7220458984375e-05 seconds
DEBUG 01-07 10:14:06.894930.894930 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-07 10:14:06.894667.894667 cuda_h.py:10] start sllm_worker_task
DEBUG 01-07 10:14:06.894670.894670 mlpmodule.py:367] cuda:1 cuda:1
DEBUG 01-07 10:14:06.894394.894394 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 10:14:06.895471.895471 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 10:14:06.895449.895449 cuda_h.py:19] end allocate_cuda_memory cost 0.0002880096435546875 seconds
DEBUG 01-07 10:14:06.895479.895479 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 10:14:06.895917.895917 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 10:14:06.895561.895561 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 10:14:06.895032.895032 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 40a13e0f-3bd5-4c54-b788-5affd4fbcf4a
DEBUG 01-07 10:14:06.895916.895916 client.py:106] call stub.LoadModelAsync
DEBUG 01-07 10:14:06.895991.895991 cuda_h.py:10] start self_attn
INFO 01-07 10:14:06.896441.896441 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 40a13e0f-3bd5-4c54-b788-5affd4fbcf4a
DEBUG 01-07 10:14:06.896397.896397 cuda_h.py:19] end load_into_gpu_async cost 0.0010898113250732422 seconds
DEBUG 01-07 10:14:06.896061.896061 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 10:14:06.896594.896594 cuda_h.py:19] end restore_tensors2 cost 7.843971252441406e-05 seconds
DEBUG 01-07 10:14:06.896264.896264 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0017673969268798828 seconds
INFO 01-07 10:14:06.896917.896917 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 40a13e0f-3bd5-4c54-b788-5affd4fbcf4a
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-07 10:14:06.899474.899474 cuda_h.py:19] end self_attn cost 0.0038704872131347656 seconds
DEBUG 01-07 10:14:06.900326.900326 cuda_h.py:19] end iln_self_attn_paln cost 0.005457162857055664 seconds
DEBUG 01-07 10:14:06.900870.900870 cuda_h.py:10] start layer_moe_generate_multi_device_10
DEBUG 01-07 10:14:06.900249.900249 cuda_h.py:10] start gate
DEBUG 01-07 10:14:06.900133.900133 cuda_h.py:19] end gate cost 0.0006520748138427734 seconds
DEBUG 01-07 10:14:06.900155.900155 cuda_h.py:10] start experts_map_get
DEBUG 01-07 10:14:06.901651.901651 lmp.py:744] 
DEBUG 01-07 10:14:06.901651.901651 lmp.py:744] Expert Token Distribution & Multi-Device Allocation:
DEBUG 01-07 10:14:06.901937.901937 lmp.py:745]   Total experts: 64
DEBUG 01-07 10:14:06.901018.901018 lmp.py:746]   CPU experts: 19 (30%)
DEBUG 01-07 10:14:06.901621.901621 lmp.py:747]   GPU experts: 45 (70%)
DEBUG 01-07 10:14:06.901039.901039 lmp.py:748]   Number of GPU devices: 2
DEBUG 01-07 10:14:06.901351.901351 lmp.py:749] 
DEBUG 01-07 10:14:06.901351.901351 lmp.py:749]   Expert ID | Tokens | Device
DEBUG 01-07 10:14:06.901709.901709 lmp.py:750]   -----------------------------------
DEBUG 01-07 10:14:06.901220.901220 lmp.py:767]   Expert 43 |     18 | CPU
DEBUG 01-07 10:14:06.901578.901578 lmp.py:767]   Expert 27 |     36 | CPU
DEBUG 01-07 10:14:06.901221.901221 lmp.py:767]   Expert 34 |     51 | CPU
DEBUG 01-07 10:14:06.901110.901110 lmp.py:767]   Expert  3 |     52 | CPU
DEBUG 01-07 10:14:06.901852.901852 lmp.py:767]   Expert 56 |     54 | CPU
DEBUG 01-07 10:14:06.901594.901594 lmp.py:767]   Expert 26 |     57 | CPU
DEBUG 01-07 10:14:06.901867.901867 lmp.py:767]   Expert  4 |     69 | CPU
DEBUG 01-07 10:14:06.901748.901748 lmp.py:767]   Expert 61 |     76 | CPU
DEBUG 01-07 10:14:06.901914.901914 lmp.py:767]   Expert 14 |     90 | CPU
DEBUG 01-07 10:14:06.901080.901080 lmp.py:767]   Expert 38 |    106 | CPU
DEBUG 01-07 10:14:06.901247.901247 lmp.py:767]   Expert  2 |    117 | CPU
DEBUG 01-07 10:14:06.901413.901413 lmp.py:767]   Expert 17 |    121 | CPU
DEBUG 01-07 10:14:06.901340.901340 lmp.py:767]   Expert 22 |    123 | CPU
DEBUG 01-07 10:14:06.901467.901467 lmp.py:767]   Expert 47 |    127 | CPU
DEBUG 01-07 10:14:06.901064.901064 lmp.py:767]   Expert 37 |    130 | CPU
DEBUG 01-07 10:14:06.901144.901144 lmp.py:767]   Expert 54 |    133 | CPU
DEBUG 01-07 10:14:06.901979.901979 lmp.py:767]   Expert 55 |    133 | CPU
DEBUG 01-07 10:14:06.901145.901145 lmp.py:767]   Expert 28 |    134 | CPU
DEBUG 01-07 10:14:06.901311.901311 lmp.py:767]   Expert 15 |    142 | CPU
DEBUG 01-07 10:14:06.901623.901623 lmp.py:767]   Expert 51 |    144 | GPU1(cuda:2)
DEBUG 01-07 10:14:06.901180.901180 lmp.py:767]   Expert  5 |    145 | GPU1(cuda:2)
DEBUG 01-07 10:14:06.901731.901731 lmp.py:767]   Expert 48 |    145 | GPU0(cuda:1)
DEBUG 01-07 10:14:06.902480.902480 lmp.py:767]   Expert  7 |    149 | GPU1(cuda:2)
DEBUG 01-07 10:14:06.902030.902030 lmp.py:767]   Expert 19 |    149 | GPU0(cuda:1)
DEBUG 01-07 10:14:06.902912.902912 lmp.py:767]   Expert 45 |    150 | GPU1(cuda:2)
DEBUG 01-07 10:14:06.902793.902793 lmp.py:767]   Expert 63 |    150 | GPU0(cuda:1)
DEBUG 01-07 10:14:06.902198.902198 lmp.py:767]   Expert 12 |    154 | GPU0(cuda:1)
DEBUG 01-07 10:14:06.902841.902841 lmp.py:767]   Expert 60 |    155 | GPU1(cuda:2)
DEBUG 01-07 10:14:06.902722.902722 lmp.py:767]   Expert  6 |    160 | GPU0(cuda:1)
DEBUG 01-07 10:14:06.902226.902226 lmp.py:767]   Expert 57 |    163 | GPU1(cuda:2)
DEBUG 01-07 10:14:06.902690.902690 lmp.py:767]   Expert 52 |    170 | GPU1(cuda:2)
DEBUG 01-07 10:14:06.902916.902916 lmp.py:767]   Expert 50 |    183 | GPU0(cuda:1)
DEBUG 01-07 10:14:06.902328.902328 lmp.py:767]   Expert 18 |    184 | GPU0(cuda:1)
DEBUG 01-07 10:14:06.902693.902693 lmp.py:767]   Expert 44 |    184 | GPU1(cuda:2)
DEBUG 01-07 10:14:06.902819.902819 lmp.py:767]   Expert 13 |    186 | GPU0(cuda:1)
DEBUG 01-07 10:14:06.902654.902654 lmp.py:767]   Expert 31 |    186 | GPU1(cuda:2)
DEBUG 01-07 10:14:06.902297.902297 lmp.py:767]   Expert 21 |    192 | GPU1(cuda:2)
DEBUG 01-07 10:14:06.902417.902417 lmp.py:767]   Expert 30 |    193 | GPU0(cuda:1)
DEBUG 01-07 10:14:06.902299.902299 lmp.py:767]   Expert 20 |    194 | GPU1(cuda:2)
DEBUG 01-07 10:14:06.902617.902617 lmp.py:767]   Expert 23 |    196 | GPU0(cuda:1)
DEBUG 01-07 10:14:06.902452.902452 lmp.py:767]   Expert 53 |    197 | GPU0(cuda:1)
DEBUG 01-07 10:14:06.902486.902486 lmp.py:767]   Expert 59 |    197 | GPU1(cuda:2)
DEBUG 01-07 10:14:06.902706.902706 lmp.py:767]   Expert 29 |    199 | GPU1(cuda:2)
DEBUG 01-07 10:14:06.902825.902825 lmp.py:767]   Expert 39 |    201 | GPU0(cuda:1)
DEBUG 01-07 10:14:06.902707.902707 lmp.py:767]   Expert 36 |    212 | GPU1(cuda:2)
DEBUG 01-07 10:14:06.902350.902350 lmp.py:767]   Expert 25 |    213 | GPU0(cuda:1)
DEBUG 01-07 10:14:06.902139.902139 lmp.py:767]   Expert 16 |    214 | GPU1(cuda:2)
DEBUG 01-07 10:14:06.902504.902504 lmp.py:767]   Expert 41 |    215 | GPU0(cuda:1)
DEBUG 01-07 10:14:06.902107.902107 lmp.py:767]   Expert 49 |    220 | GPU1(cuda:2)
DEBUG 01-07 10:14:06.902141.902141 lmp.py:767]   Expert 32 |    221 | GPU0(cuda:1)
DEBUG 01-07 10:14:06.902599.902599 lmp.py:767]   Expert 46 |    229 | GPU0(cuda:1)
DEBUG 01-07 10:14:06.902718.902718 lmp.py:767]   Expert  8 |    248 | GPU1(cuda:2)
DEBUG 01-07 10:14:06.902600.902600 lmp.py:767]   Expert 10 |    251 | GPU0(cuda:1)
DEBUG 01-07 10:14:06.902243.902243 lmp.py:767]   Expert 42 |    252 | GPU1(cuda:2)
DEBUG 01-07 10:14:06.902124.902124 lmp.py:767]   Expert 62 |    264 | GPU1(cuda:2)
DEBUG 01-07 10:14:06.902244.902244 lmp.py:767]   Expert 35 |    279 | GPU0(cuda:1)
DEBUG 01-07 10:14:06.902324.902324 lmp.py:767]   Expert  9 |    289 | GPU1(cuda:2)
DEBUG 01-07 10:14:06.902398.902398 lmp.py:767]   Expert 33 |    291 | GPU0(cuda:1)
DEBUG 01-07 10:14:06.902379.902379 lmp.py:767]   Expert 58 |    294 | GPU0(cuda:1)
DEBUG 01-07 10:14:06.902366.902366 lmp.py:767]   Expert 40 |    396 | GPU1(cuda:2)
DEBUG 01-07 10:14:06.902724.902724 lmp.py:767]   Expert  0 |    434 | GPU0(cuda:1)
DEBUG 01-07 10:14:06.902844.902844 lmp.py:767]   Expert 11 |    445 | GPU1(cuda:2)
DEBUG 01-07 10:14:06.902726.902726 lmp.py:767]   Expert 24 |    563 | GPU1(cuda:2)
DEBUG 01-07 10:14:06.902369.902369 lmp.py:767]   Expert  1 |    663 | GPU0(cuda:1)
DEBUG 01-07 10:14:06.902296.902296 lmp.py:769] 
DEBUG 01-07 10:14:06.902296.902296 lmp.py:769]   Device Token Distribution:
DEBUG 01-07 10:14:06.902178.902178 lmp.py:770]   CPU:   1769 tokens
DEBUG 01-07 10:14:06.902251.902251 lmp.py:774]   cuda:1:   5188 tokens (22 experts)
DEBUG 01-07 10:14:06.902285.902285 lmp.py:774]   cuda:2:   5331 tokens (23 experts)
DEBUG 01-07 10:14:06.902359.902359 lmp.py:775]   Total GPU:  10519 tokens
DEBUG 01-07 10:14:06.902194.902194 lmp.py:776] ============================================================
DEBUG 01-07 10:14:06.902194.902194 lmp.py:776] 
DEBUG 01-07 10:14:06.902619.902619 cuda_h.py:19] end experts_map_get cost 0.0019626617431640625 seconds
DEBUG 01-07 10:14:06.903169.903169 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model_multi_device
DEBUG 01-07 10:14:06.903661.903661 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 10:14:06.903062.903062 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 10:14:06.903920.903920 cuda_h.py:19] end allocate_cuda_memory cost 0.00027489662170410156 seconds
DEBUG 01-07 10:14:06.903790.903790 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 10:14:06.903408.903408 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 10:14:06.903661.903661 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 10:14:06.903410.903410 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 02e59e95-b800-4bda-93b0-6297f74b33c2
DEBUG 01-07 10:14:06.903435.903435 client.py:106] call stub.LoadModelAsync
INFO 01-07 10:14:06.904958.904958 client.py:127] Model loaded
DEBUG 01-07 10:14:06.904073.904073 cuda_h.py:19] end sllm_worker_task cost 0.009804725646972656 seconds
INFO 01-07 10:14:06.904919.904919 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 02e59e95-b800-4bda-93b0-6297f74b33c2
DEBUG 01-07 10:14:06.904413.904413 cuda_h.py:19] end load_into_gpu_async cost 0.0013318061828613281 seconds
DEBUG 01-07 10:14:06.904944.904944 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 10:14:06.905777.905777 cuda_h.py:19] end restore_tensors2 cost 0.00032401084899902344 seconds
DEBUG 01-07 10:14:06.905528.905528 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.002335786819458008 seconds
DEBUG 01-07 10:14:06.907198.907198 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 10:14:06.907349.907349 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 10:14:06.908564.908564 cuda_h.py:19] end allocate_cuda_memory cost 0.0002512931823730469 seconds
DEBUG 01-07 10:14:06.908189.908189 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 10:14:06.908972.908972 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 10:14:06.908318.908318 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 10:14:06.908121.908121 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 0b8375c5-ab23-4f30-85f5-570281ed7d9a
DEBUG 01-07 10:14:06.908073.908073 client.py:106] call stub.LoadModelAsync
INFO 01-07 10:14:06.909913.909913 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 0b8375c5-ab23-4f30-85f5-570281ed7d9a
DEBUG 01-07 10:14:06.909233.909233 cuda_h.py:19] end load_into_gpu_async cost 0.0010683536529541016 seconds
DEBUG 01-07 10:14:06.909943.909943 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 10:14:06.909551.909551 cuda_h.py:19] end restore_tensors2 cost 0.0003094673156738281 seconds
DEBUG 01-07 10:14:06.909056.909056 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.002007722854614258 seconds
DEBUG 01-07 10:14:06.912387.912387 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model_multi_device cost 0.009434223175048828 seconds
DEBUG 01-07 10:14:06.912078.912078 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-07 10:14:06.912605.912605 lmp.py:816] 
DEBUG 01-07 10:14:06.912605.912605 lmp.py:816]   Computing 19 experts on CPU...
DEBUG 01-07 10:14:06.912633.912633 cuda_h.py:19] end cpu_experts_submit cost 0.00012636184692382812 seconds
DEBUG 01-07 10:14:06.912768.912768 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-07 10:14:06.926444.926444 mlpmodule.py:749] group tensors cost 0.013525724411010742 s
DEBUG 01-07 10:14:06.928221.928221 mlpmodule.py:787] pad cost 0.0011031627655029297 s
DEBUG 01-07 10:14:06.928609.928609 mlpmodule.py:793] create cpu tensor cost 4.935264587402344e-05 s
DEBUG 01-07 10:14:06.928711.928711 mlpmodule.py:798] move to cpu cost 3.361701965332031e-05 s
DEBUG 01-07 10:14:06.938542.938542 mlpmodule.py:812] group_w3: shape=torch.Size([19, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=54788096
DEBUG 01-07 10:14:06.938402.938402 mlpmodule.py:813] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-07 10:14:06.938260.938260 mlpmodule.py:818] group_w3 first element: -0.0213623046875
WARNING 01-07 10:14:06.939814.939814 mlpmodule.py:828] start einsum2
DEBUG 01-07 10:14:06.955418.955418 mlpmodule.py:838] group einsum cost 0.026597976684570312 s
DEBUG 01-07 10:14:06.955286.955286 mlpmodule.py:846] cpy2cputensor cost 0.00041294097900390625 s
DEBUG 01-07 10:14:06.959250.959250 cuda_h.py:19] end wait_cetm_experts cost 0.046201467514038086 seconds
DEBUG 01-07 10:14:06.959544.959544 cuda_h.py:10] start gpu_sexperts
DEBUG 01-07 10:14:06.959933.959933 cuda_h.py:19] end gpu_sexperts cost 0.00047469139099121094 seconds
DEBUG 01-07 10:14:06.959299.959299 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-07 10:14:06.959917.959917 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.5510787963867188e-05 seconds
DEBUG 01-07 10:14:06.959197.959197 cuda_h.py:10] start wait_experts_multi_device
INFO 01-07 10:14:06.959953.959953 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 02e59e95-b800-4bda-93b0-6297f74b33c2
INFO 01-07 10:14:06.960644.960644 client.py:127] Model loaded
INFO 01-07 10:14:06.960957.960957 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 0b8375c5-ab23-4f30-85f5-570281ed7d9a
INFO 01-07 10:14:06.961666.961666 client.py:127] Model loaded
DEBUG 01-07 10:14:06.961357.961357 cuda_h.py:19] end wait_experts_multi_device cost 0.0013849735260009766 seconds
DEBUG 01-07 10:14:06.961020.961020 cuda_h.py:10] start gpu_experts_multi_device
DEBUG 01-07 10:14:06.961458.961458 lmp.py:867]   Computing 23 experts on cuda:2...
DEBUG 01-07 10:14:06.962684.962684 mlpmodule.py:533] gpu group tensors cost 0.00042438507080078125 s
DEBUG 01-07 10:14:06.963951.963951 mlpmodule.py:566] gpu pad cost 0.001190185546875 s
DEBUG 01-07 10:14:06.964409.964409 mlpmodule.py:584] gpu group einsum cost 0.0005533695220947266 s
DEBUG 01-07 10:14:06.966636.966636 mlpmodule.py:656] gpu experts func einsum cost 0.004320621490478516 s
DEBUG 01-07 10:14:06.966798.966798 lmp.py:867]   Computing 22 experts on cuda:1...
DEBUG 01-07 10:14:06.967935.967935 mlpmodule.py:533] gpu group tensors cost 0.00042438507080078125 s
DEBUG 01-07 10:14:06.968250.968250 mlpmodule.py:566] gpu pad cost 0.0012247562408447266 s
DEBUG 01-07 10:14:06.968842.968842 mlpmodule.py:707]  experts func einsum cost 0.056084632873535156 s
DEBUG 01-07 10:14:06.969480.969480 mlpmodule.py:584] gpu group einsum cost 0.00047206878662109375 s
DEBUG 01-07 10:14:06.971619.971619 mlpmodule.py:656] gpu experts func einsum cost 0.004228353500366211 s
DEBUG 01-07 10:14:06.971657.971657 cuda_h.py:19] end gpu_experts_multi_device cost 0.009884834289550781 seconds
DEBUG 01-07 10:14:06.971137.971137 cuda_h.py:19] end layer_moe_generate_multi_device_10 cost 0.07102108001708984 seconds
DEBUG 01-07 10:14:06.971246.971246 lmp.py:194] -------------------------------- end prefill layer 10 --------------------------------
DEBUG 01-07 10:14:06.971029.971029 lmp.py:153] -------------------------------- start prefill layer 11 --------------------------------
DEBUG 01-07 10:14:06.971938.971938 cuda_h.py:10] start start_load_qkvogn_s_weight_l_12
DEBUG 01-07 10:14:06.971330.971330 cuda_h.py:10] start start_load_qkvogn_s_weight_l_12
DEBUG 01-07 10:14:06.971272.971272 cuda_h.py:19] end start_load_qkvogn_s_weight_l_12 cost 3.0040740966796875e-05 seconds
DEBUG 01-07 10:14:06.971552.971552 cuda_h.py:19] end start_load_qkvogn_s_weight_l_12 cost 6.508827209472656e-05 seconds
DEBUG 01-07 10:14:06.971069.971069 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-07 10:14:06.971204.971204 cuda_h.py:10] start sllm_worker_task
DEBUG 01-07 10:14:06.971498.971498 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 10:14:06.972711.972711 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 10:14:06.972417.972417 cuda_h.py:19] end allocate_cuda_memory cost 0.0002753734588623047 seconds
DEBUG 01-07 10:14:06.972373.972373 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 10:14:06.972229.972229 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 10:14:06.972667.972667 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 10:14:06.972224.972224 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 702a6f60-ad60-499c-9b80-cec3cabd459d
DEBUG 01-07 10:14:06.972134.972134 client.py:106] call stub.LoadModelAsync
DEBUG 01-07 10:14:06.972012.972012 mlpmodule.py:367] cuda:1 cuda:1
DEBUG 01-07 10:14:06.973170.973170 cuda_h.py:10] start self_attn
INFO 01-07 10:14:06.973933.973933 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 702a6f60-ad60-499c-9b80-cec3cabd459d
DEBUG 01-07 10:14:06.973716.973716 cuda_h.py:19] end load_into_gpu_async cost 0.0009210109710693359 seconds
DEBUG 01-07 10:14:06.973750.973750 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 10:14:06.973018.973018 cuda_h.py:19] end restore_tensors2 cost 6.699562072753906e-05 seconds
DEBUG 01-07 10:14:06.973582.973582 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0015034675598144531 seconds
INFO 01-07 10:14:06.973624.973624 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 702a6f60-ad60-499c-9b80-cec3cabd459d
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-07 10:14:06.976670.976670 cuda_h.py:19] end self_attn cost 0.003774881362915039 seconds
DEBUG 01-07 10:14:06.977794.977794 cuda_h.py:19] end iln_self_attn_paln cost 0.005372047424316406 seconds
DEBUG 01-07 10:14:06.977438.977438 cuda_h.py:10] start layer_moe_generate_multi_device_11
DEBUG 01-07 10:14:06.977976.977976 cuda_h.py:10] start gate
DEBUG 01-07 10:14:06.978311.978311 cuda_h.py:19] end gate cost 0.0006651878356933594 seconds
DEBUG 01-07 10:14:06.978001.978001 cuda_h.py:10] start experts_map_get
DEBUG 01-07 10:14:06.978479.978479 lmp.py:744] 
DEBUG 01-07 10:14:06.978479.978479 lmp.py:744] Expert Token Distribution & Multi-Device Allocation:
DEBUG 01-07 10:14:06.978149.978149 lmp.py:745]   Total experts: 64
DEBUG 01-07 10:14:06.978335.978335 lmp.py:746]   CPU experts: 19 (30%)
DEBUG 01-07 10:14:06.978608.978608 lmp.py:747]   GPU experts: 45 (70%)
DEBUG 01-07 10:14:06.978681.978681 lmp.py:748]   Number of GPU devices: 2
DEBUG 01-07 10:14:06.978655.978655 lmp.py:749] 
DEBUG 01-07 10:14:06.978655.978655 lmp.py:749]   Expert ID | Tokens | Device
DEBUG 01-07 10:14:06.978345.978345 lmp.py:750]   -----------------------------------
DEBUG 01-07 10:14:06.978710.978710 lmp.py:767]   Expert 39 |     14 | CPU
DEBUG 01-07 10:14:06.978114.978114 lmp.py:767]   Expert 13 |     18 | CPU
DEBUG 01-07 10:14:06.978857.978857 lmp.py:767]   Expert 49 |     37 | CPU
DEBUG 01-07 10:14:06.978990.978990 lmp.py:767]   Expert 35 |     53 | CPU
DEBUG 01-07 10:14:06.978063.978063 lmp.py:767]   Expert 19 |     63 | CPU
DEBUG 01-07 10:14:06.978991.978991 lmp.py:767]   Expert 32 |     74 | CPU
DEBUG 01-07 10:14:06.978442.978442 lmp.py:767]   Expert 33 |     76 | CPU
DEBUG 01-07 10:14:06.978416.978416 lmp.py:767]   Expert 41 |     77 | CPU
DEBUG 01-07 10:14:06.978629.978629 lmp.py:767]   Expert  9 |     79 | CPU
DEBUG 01-07 10:14:06.978841.978841 lmp.py:767]   Expert 26 |     80 | CPU
DEBUG 01-07 10:14:06.978577.978577 lmp.py:767]   Expert 23 |     84 | CPU
DEBUG 01-07 10:14:06.978743.978743 lmp.py:767]   Expert 46 |     86 | CPU
DEBUG 01-07 10:14:06.978207.978207 lmp.py:767]   Expert 31 |     89 | CPU
DEBUG 01-07 10:14:06.978804.978804 lmp.py:767]   Expert 18 |     91 | CPU
DEBUG 01-07 10:14:06.978016.978016 lmp.py:767]   Expert 38 |     98 | CPU
DEBUG 01-07 10:14:06.978467.978467 lmp.py:767]   Expert  3 |    101 | CPU
DEBUG 01-07 10:14:06.978971.978971 lmp.py:767]   Expert  6 |    104 | CPU
DEBUG 01-07 10:14:06.979959.979959 lmp.py:767]   Expert 17 |    106 | CPU
DEBUG 01-07 10:14:06.979271.979271 lmp.py:767]   Expert 20 |    116 | CPU
DEBUG 01-07 10:14:06.979106.979106 lmp.py:767]   Expert 40 |    129 | GPU1(cuda:2)
DEBUG 01-07 10:14:06.979656.979656 lmp.py:767]   Expert 59 |    131 | GPU1(cuda:2)
DEBUG 01-07 10:14:06.979014.979014 lmp.py:767]   Expert 62 |    131 | GPU0(cuda:1)
DEBUG 01-07 10:14:06.979134.979134 lmp.py:767]   Expert 16 |    132 | GPU0(cuda:1)
DEBUG 01-07 10:14:06.979022.979022 lmp.py:767]   Expert 61 |    132 | GPU0(cuda:1)
DEBUG 01-07 10:14:06.979103.979103 lmp.py:767]   Expert 43 |    137 | GPU1(cuda:2)
DEBUG 01-07 10:14:06.979130.979130 lmp.py:767]   Expert 44 |    139 | GPU0(cuda:1)
DEBUG 01-07 10:14:06.979011.979011 lmp.py:767]   Expert 15 |    140 | GPU1(cuda:2)
DEBUG 01-07 10:14:06.979131.979131 lmp.py:767]   Expert 50 |    140 | GPU0(cuda:1)
DEBUG 01-07 10:14:06.979012.979012 lmp.py:767]   Expert 63 |    140 | GPU1(cuda:2)
DEBUG 01-07 10:14:06.979132.979132 lmp.py:767]   Expert 42 |    146 | GPU0(cuda:1)
DEBUG 01-07 10:14:06.979206.979206 lmp.py:767]   Expert  2 |    148 | GPU1(cuda:2)
DEBUG 01-07 10:14:06.979624.979624 lmp.py:767]   Expert 36 |    150 | GPU1(cuda:2)
DEBUG 01-07 10:14:06.979174.979174 lmp.py:767]   Expert 10 |    158 | GPU0(cuda:1)
DEBUG 01-07 10:14:06.979294.979294 lmp.py:767]   Expert  5 |    182 | GPU0(cuda:1)
DEBUG 01-07 10:14:06.979414.979414 lmp.py:767]   Expert 34 |    185 | GPU1(cuda:2)
DEBUG 01-07 10:14:06.979534.979534 lmp.py:767]   Expert 27 |    186 | GPU1(cuda:2)
DEBUG 01-07 10:14:06.979415.979415 lmp.py:767]   Expert 52 |    189 | GPU0(cuda:1)
DEBUG 01-07 10:14:06.979535.979535 lmp.py:767]   Expert 60 |    195 | GPU1(cuda:2)
DEBUG 01-07 10:14:06.979655.979655 lmp.py:767]   Expert 45 |    196 | GPU0(cuda:1)
DEBUG 01-07 10:14:06.979774.979774 lmp.py:767]   Expert 48 |    203 | GPU0(cuda:1)
DEBUG 01-07 10:14:06.979656.979656 lmp.py:767]   Expert 51 |    213 | GPU1(cuda:2)
DEBUG 01-07 10:14:06.979398.979398 lmp.py:767]   Expert 56 |    215 | GPU1(cuda:2)
DEBUG 01-07 10:14:06.979386.979386 lmp.py:767]   Expert  7 |    229 | GPU1(cuda:2)
DEBUG 01-07 10:14:06.979175.979175 lmp.py:767]   Expert 24 |    229 | GPU0(cuda:1)
DEBUG 01-07 10:14:06.979294.979294 lmp.py:767]   Expert 53 |    234 | GPU0(cuda:1)
DEBUG 01-07 10:14:06.979653.979653 lmp.py:767]   Expert  8 |    238 | GPU0(cuda:1)
DEBUG 01-07 10:14:06.979534.979534 lmp.py:767]   Expert 57 |    250 | GPU1(cuda:2)
DEBUG 01-07 10:14:06.979654.979654 lmp.py:767]   Expert 47 |    254 | GPU1(cuda:2)
DEBUG 01-07 10:14:06.979297.979297 lmp.py:767]   Expert 29 |    260 | GPU0(cuda:1)
DEBUG 01-07 10:14:06.979370.979370 lmp.py:767]   Expert 21 |    266 | GPU0(cuda:1)
DEBUG 01-07 10:14:06.979603.979603 lmp.py:767]   Expert  4 |    283 | GPU1(cuda:2)
DEBUG 01-07 10:14:06.979392.979392 lmp.py:767]   Expert  0 |    285 | GPU1(cuda:2)
DEBUG 01-07 10:14:06.979273.979273 lmp.py:767]   Expert 14 |    285 | GPU0(cuda:1)
DEBUG 01-07 10:14:06.979155.979155 lmp.py:767]   Expert 55 |    316 | GPU0(cuda:1)
DEBUG 01-07 10:14:06.979798.979798 lmp.py:767]   Expert 37 |    318 | GPU1(cuda:2)
DEBUG 01-07 10:14:06.979202.979202 lmp.py:767]   Expert  1 |    319 | GPU0(cuda:1)
DEBUG 01-07 10:14:06.979084.979084 lmp.py:767]   Expert 22 |    322 | GPU1(cuda:2)
DEBUG 01-07 10:14:06.979727.979727 lmp.py:767]   Expert 58 |    326 | GPU0(cuda:1)
DEBUG 01-07 10:14:06.979608.979608 lmp.py:767]   Expert 54 |    331 | GPU1(cuda:2)
DEBUG 01-07 10:14:06.979735.979735 lmp.py:767]   Expert 28 |    364 | GPU0(cuda:1)
DEBUG 01-07 10:14:06.979868.979868 lmp.py:767]   Expert 12 |    373 | GPU1(cuda:2)
DEBUG 01-07 10:14:06.979432.979432 lmp.py:767]   Expert 25 |    399 | GPU1(cuda:2)
DEBUG 01-07 10:14:06.979757.979757 lmp.py:767]   Expert 11 |    407 | GPU1(cuda:2)
DEBUG 01-07 10:14:06.979652.979652 lmp.py:767]   Expert 30 |    837 | GPU0(cuda:1)
DEBUG 01-07 10:14:06.979031.979031 lmp.py:769] 
DEBUG 01-07 10:14:06.979031.979031 lmp.py:769]   Device Token Distribution:
DEBUG 01-07 10:14:06.980787.980787 lmp.py:770]   CPU:   1446 tokens
DEBUG 01-07 10:14:06.980020.980020 lmp.py:774]   cuda:1:   5422 tokens (22 experts)
DEBUG 01-07 10:14:06.980908.980908 lmp.py:774]   cuda:2:   5420 tokens (23 experts)
DEBUG 01-07 10:14:06.980949.980949 lmp.py:775]   Total GPU:  10842 tokens
DEBUG 01-07 10:14:06.980082.980082 lmp.py:776] ============================================================
DEBUG 01-07 10:14:06.980082.980082 lmp.py:776] 
DEBUG 01-07 10:14:06.980991.980991 cuda_h.py:19] end experts_map_get cost 0.0020215511322021484 seconds
DEBUG 01-07 10:14:06.980608.980608 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model_multi_device
DEBUG 01-07 10:14:06.980471.980471 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
INFO 01-07 10:14:06.980374.980374 client.py:127] Model loaded
DEBUG 01-07 10:14:06.980876.980876 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 10:14:06.980002.980002 cuda_h.py:19] end allocate_cuda_memory cost 0.00018835067749023438 seconds
DEBUG 01-07 10:14:06.980137.980137 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 10:14:06.980655.980655 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 10:14:06.981656.981656 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 10:14:06.981544.981544 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, fb0cae6b-f6aa-412c-bcc0-d7798e8fcfc2
DEBUG 01-07 10:14:06.981463.981463 client.py:106] call stub.LoadModelAsync
DEBUG 01-07 10:14:06.981459.981459 cuda_h.py:19] end sllm_worker_task cost 0.009521961212158203 seconds
INFO 01-07 10:14:06.981581.981581 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, fb0cae6b-f6aa-412c-bcc0-d7798e8fcfc2
DEBUG 01-07 10:14:06.982921.982921 cuda_h.py:19] end load_into_gpu_async cost 0.0010328292846679688 seconds
DEBUG 01-07 10:14:06.982684.982684 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 10:14:06.982283.982283 cuda_h.py:19] end restore_tensors2 cost 0.00027108192443847656 seconds
DEBUG 01-07 10:14:06.982120.982120 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0020301342010498047 seconds
DEBUG 01-07 10:14:06.984440.984440 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 10:14:06.984737.984737 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 10:14:06.984342.984342 cuda_h.py:19] end allocate_cuda_memory cost 0.00022339820861816406 seconds
DEBUG 01-07 10:14:06.984337.984337 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 10:14:06.985584.985584 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 10:14:06.985492.985492 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 10:14:06.985096.985096 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 0fea578d-45e4-410f-93fe-09be597dcd4b
DEBUG 01-07 10:14:06.985538.985538 client.py:106] call stub.LoadModelAsync
INFO 01-07 10:14:06.986224.986224 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 0fea578d-45e4-410f-93fe-09be597dcd4b
DEBUG 01-07 10:14:06.986902.986902 cuda_h.py:19] end load_into_gpu_async cost 0.0013883113861083984 seconds
DEBUG 01-07 10:14:06.986162.986162 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 10:14:06.986112.986112 cuda_h.py:19] end restore_tensors2 cost 0.00024580955505371094 seconds
DEBUG 01-07 10:14:06.986796.986796 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0022356510162353516 seconds
DEBUG 01-07 10:14:06.988211.988211 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model_multi_device cost 0.008689403533935547 seconds
DEBUG 01-07 10:14:06.988624.988624 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-07 10:14:06.989309.989309 lmp.py:816] 
DEBUG 01-07 10:14:06.989309.989309 lmp.py:816]   Computing 19 experts on CPU...
DEBUG 01-07 10:14:06.989244.989244 cuda_h.py:19] end cpu_experts_submit cost 0.000110626220703125 seconds
DEBUG 01-07 10:14:06.989563.989563 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-07 10:14:06.995924.995924 mlpmodule.py:749] group tensors cost 0.005894899368286133 s
DEBUG 01-07 10:14:06.997937.997937 mlpmodule.py:787] pad cost 0.0014846324920654297 s
DEBUG 01-07 10:14:06.997306.997306 mlpmodule.py:793] create cpu tensor cost 5.3882598876953125e-05 s
DEBUG 01-07 10:14:06.997243.997243 mlpmodule.py:798] move to cpu cost 4.124641418457031e-05 s
DEBUG 01-07 10:14:07.009981.009981 mlpmodule.py:812] group_w3: shape=torch.Size([19, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=54788096
DEBUG 01-07 10:14:07.009417.009417 mlpmodule.py:813] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-07 10:14:07.009374.009374 mlpmodule.py:818] group_w3 first element: 0.01373291015625
WARNING 01-07 10:14:07.009982.009982 mlpmodule.py:828] start einsum2
DEBUG 01-07 10:14:07.026853.026853 mlpmodule.py:838] group einsum cost 0.028796672821044922 s
DEBUG 01-07 10:14:07.027522.027522 mlpmodule.py:846] cpy2cputensor cost 0.0003800392150878906 s
DEBUG 01-07 10:14:07.029577.029577 cuda_h.py:19] end wait_cetm_experts cost 0.04052019119262695 seconds
DEBUG 01-07 10:14:07.029891.029891 cuda_h.py:10] start gpu_sexperts
DEBUG 01-07 10:14:07.030937.030937 cuda_h.py:19] end gpu_sexperts cost 0.0005147457122802734 seconds
DEBUG 01-07 10:14:07.030449.030449 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-07 10:14:07.030060.030060 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.5987625122070312e-05 seconds
DEBUG 01-07 10:14:07.030432.030432 cuda_h.py:10] start wait_experts_multi_device
INFO 01-07 10:14:07.030810.030810 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, fb0cae6b-f6aa-412c-bcc0-d7798e8fcfc2
INFO 01-07 10:14:07.031232.031232 client.py:127] Model loaded
INFO 01-07 10:14:07.031088.031088 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 0fea578d-45e4-410f-93fe-09be597dcd4b
INFO 01-07 10:14:07.035990.035990 client.py:127] Model loaded
DEBUG 01-07 10:14:07.035926.035926 cuda_h.py:19] end wait_experts_multi_device cost 0.004827260971069336 seconds
DEBUG 01-07 10:14:07.035635.035635 cuda_h.py:10] start gpu_experts_multi_device
DEBUG 01-07 10:14:07.035081.035081 lmp.py:867]   Computing 23 experts on cuda:2...
DEBUG 01-07 10:14:07.036526.036526 mlpmodule.py:533] gpu group tensors cost 0.0005280971527099609 s
DEBUG 01-07 10:14:07.038473.038473 mlpmodule.py:566] gpu pad cost 0.001302957534790039 s
DEBUG 01-07 10:14:07.038729.038729 mlpmodule.py:584] gpu group einsum cost 0.00047135353088378906 s
DEBUG 01-07 10:14:07.039881.039881 mlpmodule.py:707]  experts func einsum cost 0.050510406494140625 s
DEBUG 01-07 10:14:07.040423.040423 mlpmodule.py:656] gpu experts func einsum cost 0.004557132720947266 s
DEBUG 01-07 10:14:07.041831.041831 lmp.py:867]   Computing 22 experts on cuda:1...
DEBUG 01-07 10:14:07.041857.041857 mlpmodule.py:533] gpu group tensors cost 0.0004413127899169922 s
DEBUG 01-07 10:14:07.042498.042498 mlpmodule.py:566] gpu pad cost 0.001085519790649414 s
DEBUG 01-07 10:14:07.043488.043488 mlpmodule.py:584] gpu group einsum cost 0.0004565715789794922 s
DEBUG 01-07 10:14:07.045119.045119 mlpmodule.py:656] gpu experts func einsum cost 0.003724336624145508 s
DEBUG 01-07 10:14:07.045049.045049 cuda_h.py:19] end gpu_experts_multi_device cost 0.009755849838256836 seconds
DEBUG 01-07 10:14:07.045502.045502 cuda_h.py:19] end layer_moe_generate_multi_device_11 cost 0.06795120239257812 seconds
DEBUG 01-07 10:14:07.045869.045869 lmp.py:194] -------------------------------- end prefill layer 11 --------------------------------
DEBUG 01-07 10:14:07.045321.045321 lmp.py:153] -------------------------------- start prefill layer 12 --------------------------------
DEBUG 01-07 10:14:07.045732.045732 cuda_h.py:10] start start_load_qkvogn_s_weight_l_13
DEBUG 01-07 10:14:07.045488.045488 cuda_h.py:10] start start_load_qkvogn_s_weight_l_13
DEBUG 01-07 10:14:07.045915.045915 cuda_h.py:19] end start_load_qkvogn_s_weight_l_13 cost 4.0531158447265625e-05 seconds
DEBUG 01-07 10:14:07.045810.045810 cuda_h.py:19] end start_load_qkvogn_s_weight_l_13 cost 7.414817810058594e-05 seconds
DEBUG 01-07 10:14:07.045929.045929 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-07 10:14:07.045328.045328 cuda_h.py:10] start sllm_worker_task
DEBUG 01-07 10:14:07.045993.045993 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 10:14:07.045160.045160 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 10:14:07.046628.046628 cuda_h.py:19] end allocate_cuda_memory cost 0.0002758502960205078 seconds
DEBUG 01-07 10:14:07.046762.046762 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 10:14:07.046472.046472 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 10:14:07.046149.046149 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 10:14:07.046229.046229 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, fc96d92f-fe46-440c-a18b-f0d6156704c1
DEBUG 01-07 10:14:07.046900.046900 client.py:106] call stub.LoadModelAsync
DEBUG 01-07 10:14:07.046434.046434 mlpmodule.py:367] cuda:1 cuda:1
DEBUG 01-07 10:14:07.046836.046836 cuda_h.py:10] start self_attn
INFO 01-07 10:14:07.047415.047415 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, fc96d92f-fe46-440c-a18b-f0d6156704c1
DEBUG 01-07 10:14:07.047960.047960 cuda_h.py:19] end load_into_gpu_async cost 0.0009214878082275391 seconds
DEBUG 01-07 10:14:07.047994.047994 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 10:14:07.047884.047884 cuda_h.py:19] end restore_tensors2 cost 6.937980651855469e-05 seconds
DEBUG 01-07 10:14:07.047925.047925 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0014977455139160156 seconds
INFO 01-07 10:14:07.047391.047391 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, fc96d92f-fe46-440c-a18b-f0d6156704c1
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-07 10:14:07.050344.050344 cuda_h.py:19] end self_attn cost 0.0036547183990478516 seconds
DEBUG 01-07 10:14:07.050156.050156 cuda_h.py:19] end iln_self_attn_paln cost 0.005159139633178711 seconds
DEBUG 01-07 10:14:07.051125.051125 cuda_h.py:10] start layer_moe_generate_multi_device_12
DEBUG 01-07 10:14:07.051146.051146 cuda_h.py:10] start gate
DEBUG 01-07 10:14:07.051826.051826 cuda_h.py:19] end gate cost 0.0006701946258544922 seconds
DEBUG 01-07 10:14:07.051225.051225 cuda_h.py:10] start experts_map_get
DEBUG 01-07 10:14:07.052610.052610 lmp.py:744] 
DEBUG 01-07 10:14:07.052610.052610 lmp.py:744] Expert Token Distribution & Multi-Device Allocation:
DEBUG 01-07 10:14:07.052340.052340 lmp.py:745]   Total experts: 64
DEBUG 01-07 10:14:07.052374.052374 lmp.py:746]   CPU experts: 19 (30%)
DEBUG 01-07 10:14:07.052686.052686 lmp.py:747]   GPU experts: 45 (70%)
DEBUG 01-07 10:14:07.052852.052852 lmp.py:748]   Number of GPU devices: 2
DEBUG 01-07 10:14:07.052541.052541 lmp.py:749] 
DEBUG 01-07 10:14:07.052541.052541 lmp.py:749]   Expert ID | Tokens | Device
DEBUG 01-07 10:14:07.052668.052668 lmp.py:750]   -----------------------------------
DEBUG 01-07 10:14:07.052622.052622 lmp.py:767]   Expert 12 |     15 | CPU
DEBUG 01-07 10:14:07.052981.052981 lmp.py:767]   Expert 47 |     25 | CPU
DEBUG 01-07 10:14:07.052908.052908 lmp.py:767]   Expert 38 |     29 | CPU
DEBUG 01-07 10:14:07.052896.052896 lmp.py:767]   Expert 52 |     34 | CPU
DEBUG 01-07 10:14:07.052016.052016 lmp.py:767]   Expert 27 |     36 | CPU
DEBUG 01-07 10:14:07.052420.052420 lmp.py:767]   Expert 16 |     38 | CPU
DEBUG 01-07 10:14:07.052348.052348 lmp.py:767]   Expert 63 |     48 | CPU
DEBUG 01-07 10:14:07.052799.052799 lmp.py:767]   Expert  4 |     57 | CPU
DEBUG 01-07 10:14:07.052488.052488 lmp.py:767]   Expert 43 |     60 | CPU
DEBUG 01-07 10:14:07.052999.052999 lmp.py:767]   Expert 44 |     62 | CPU
DEBUG 01-07 10:14:07.052165.052165 lmp.py:767]   Expert 61 |     66 | CPU
DEBUG 01-07 10:14:07.052855.052855 lmp.py:767]   Expert 34 |     71 | CPU
DEBUG 01-07 10:14:07.052305.052305 lmp.py:767]   Expert 53 |     79 | CPU
DEBUG 01-07 10:14:07.052279.052279 lmp.py:767]   Expert 32 |     86 | CPU
DEBUG 01-07 10:14:07.052598.052598 lmp.py:767]   Expert  0 |     87 | CPU
DEBUG 01-07 10:14:07.052241.052241 lmp.py:767]   Expert 37 |     91 | CPU
DEBUG 01-07 10:14:07.052646.052646 lmp.py:767]   Expert 13 |    105 | CPU
DEBUG 01-07 10:14:07.052335.052335 lmp.py:767]   Expert 39 |    111 | CPU
DEBUG 01-07 10:14:07.052786.052786 lmp.py:767]   Expert 21 |    117 | CPU
DEBUG 01-07 10:14:07.052906.052906 lmp.py:767]   Expert 11 |    118 | GPU1(cuda:2)
DEBUG 01-07 10:14:07.052701.052701 lmp.py:767]   Expert 20 |    126 | GPU1(cuda:2)
DEBUG 01-07 10:14:07.052450.052450 lmp.py:767]   Expert  8 |    129 | GPU0(cuda:1)
DEBUG 01-07 10:14:07.052047.052047 lmp.py:767]   Expert 14 |    137 | GPU1(cuda:2)
DEBUG 01-07 10:14:07.052405.052405 lmp.py:767]   Expert 60 |    138 | GPU0(cuda:1)
DEBUG 01-07 10:14:07.052048.052048 lmp.py:767]   Expert 22 |    139 | GPU1(cuda:2)
DEBUG 01-07 10:14:07.052214.052214 lmp.py:767]   Expert 57 |    140 | GPU0(cuda:1)
DEBUG 01-07 10:14:07.052381.052381 lmp.py:767]   Expert 17 |    155 | GPU0(cuda:1)
DEBUG 01-07 10:14:07.052461.052461 lmp.py:767]   Expert  2 |    158 | GPU1(cuda:2)
DEBUG 01-07 10:14:07.052779.052779 lmp.py:767]   Expert 45 |    160 | GPU0(cuda:1)
DEBUG 01-07 10:14:07.052899.052899 lmp.py:767]   Expert 23 |    161 | GPU1(cuda:2)
DEBUG 01-07 10:14:07.052019.052019 lmp.py:767]   Expert 18 |    162 | GPU0(cuda:1)
DEBUG 01-07 10:14:07.053947.053947 lmp.py:767]   Expert  7 |    163 | GPU1(cuda:2)
DEBUG 01-07 10:14:07.053113.053113 lmp.py:767]   Expert 30 |    163 | GPU0(cuda:1)
DEBUG 01-07 10:14:07.053279.053279 lmp.py:767]   Expert 58 |    163 | GPU1(cuda:2)
DEBUG 01-07 10:14:07.053836.053836 lmp.py:767]   Expert 42 |    170 | GPU1(cuda:2)
DEBUG 01-07 10:14:07.053678.053678 lmp.py:767]   Expert 49 |    173 | GPU0(cuda:1)
DEBUG 01-07 10:14:07.053559.053559 lmp.py:767]   Expert 55 |    178 | GPU0(cuda:1)
DEBUG 01-07 10:14:07.053441.053441 lmp.py:767]   Expert 62 |    178 | GPU1(cuda:2)
DEBUG 01-07 10:14:07.053369.053369 lmp.py:767]   Expert 35 |    181 | GPU0(cuda:1)
DEBUG 01-07 10:14:07.053012.053012 lmp.py:767]   Expert 48 |    181 | GPU1(cuda:2)
DEBUG 01-07 10:14:07.053939.053939 lmp.py:767]   Expert 29 |    184 | GPU1(cuda:2)
DEBUG 01-07 10:14:07.053066.053066 lmp.py:767]   Expert 51 |    187 | GPU0(cuda:1)
DEBUG 01-07 10:14:07.053716.053716 lmp.py:767]   Expert 25 |    193 | GPU1(cuda:2)
DEBUG 01-07 10:14:07.053312.053312 lmp.py:767]   Expert  6 |    196 | GPU0(cuda:1)
DEBUG 01-07 10:14:07.053955.053955 lmp.py:767]   Expert  1 |    200 | GPU0(cuda:1)
DEBUG 01-07 10:14:07.053360.053360 lmp.py:767]   Expert 36 |    200 | GPU1(cuda:2)
DEBUG 01-07 10:14:07.053288.053288 lmp.py:767]   Expert 31 |    207 | GPU0(cuda:1)
DEBUG 01-07 10:14:07.053454.053454 lmp.py:767]   Expert 28 |    218 | GPU1(cuda:2)
DEBUG 01-07 10:14:07.053157.053157 lmp.py:767]   Expert  5 |    227 | GPU1(cuda:2)
DEBUG 01-07 10:14:07.053952.053952 lmp.py:767]   Expert 41 |    227 | GPU0(cuda:1)
DEBUG 01-07 10:14:07.053833.053833 lmp.py:767]   Expert 54 |    233 | GPU0(cuda:1)
DEBUG 01-07 10:14:07.053238.053238 lmp.py:767]   Expert 19 |    237 | GPU1(cuda:2)
DEBUG 01-07 10:14:07.053404.053404 lmp.py:767]   Expert  9 |    241 | GPU1(cuda:2)
DEBUG 01-07 10:14:07.053093.053093 lmp.py:767]   Expert 24 |    255 | GPU0(cuda:1)
DEBUG 01-07 10:14:07.053260.053260 lmp.py:767]   Expert 50 |    281 | GPU1(cuda:2)
DEBUG 01-07 10:14:07.053909.053909 lmp.py:767]   Expert 46 |    305 | GPU0(cuda:1)
DEBUG 01-07 10:14:07.053791.053791 lmp.py:767]   Expert 59 |    310 | GPU0(cuda:1)
DEBUG 01-07 10:14:07.053719.053719 lmp.py:767]   Expert 56 |    378 | GPU1(cuda:2)
DEBUG 01-07 10:14:07.053276.053276 lmp.py:767]   Expert 26 |    401 | GPU0(cuda:1)
DEBUG 01-07 10:14:07.053157.053157 lmp.py:767]   Expert 33 |    424 | GPU1(cuda:2)
DEBUG 01-07 10:14:07.053562.053562 lmp.py:767]   Expert  3 |    594 | GPU0(cuda:1)
DEBUG 01-07 10:14:07.053251.053251 lmp.py:767]   Expert 15 |    650 | GPU1(cuda:2)
DEBUG 01-07 10:14:07.053417.053417 lmp.py:767]   Expert 10 |    666 | GPU1(cuda:2)
DEBUG 01-07 10:14:07.053345.053345 lmp.py:767]   Expert 40 |    784 | GPU0(cuda:1)
DEBUG 01-07 10:14:07.053319.053319 lmp.py:769] 
DEBUG 01-07 10:14:07.053319.053319 lmp.py:769]   Device Token Distribution:
DEBUG 01-07 10:14:07.053161.053161 lmp.py:770]   CPU:   1217 tokens
DEBUG 01-07 10:14:07.053711.053711 lmp.py:774]   cuda:1:   5478 tokens (22 experts)
DEBUG 01-07 10:14:07.053592.053592 lmp.py:774]   cuda:2:   5593 tokens (23 experts)
DEBUG 01-07 10:14:07.053282.053282 lmp.py:775]   Total GPU:  11071 tokens
DEBUG 01-07 10:14:07.053256.053256 lmp.py:776] ============================================================
DEBUG 01-07 10:14:07.053256.053256 lmp.py:776] 
DEBUG 01-07 10:14:07.053628.053628 cuda_h.py:19] end experts_map_get cost 0.0019121170043945312 seconds
DEBUG 01-07 10:14:07.053469.053469 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model_multi_device
DEBUG 01-07 10:14:07.053484.053484 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 10:14:07.053223.053223 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 10:14:07.054439.054439 cuda_h.py:19] end allocate_cuda_memory cost 0.0002644062042236328 seconds
DEBUG 01-07 10:14:07.054235.054235 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 10:14:07.054991.054991 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 10:14:07.054946.054946 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 10:14:07.054835.054835 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 255640ec-f9c5-4420-8580-c81852d31480
DEBUG 01-07 10:14:07.054662.054662 client.py:106] call stub.LoadModelAsync
INFO 01-07 10:14:07.054528.054528 client.py:127] Model loaded
DEBUG 01-07 10:14:07.055020.055020 cuda_h.py:19] end sllm_worker_task cost 0.009324073791503906 seconds
INFO 01-07 10:14:07.055021.055021 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 255640ec-f9c5-4420-8580-c81852d31480
DEBUG 01-07 10:14:07.055016.055016 cuda_h.py:19] end load_into_gpu_async cost 0.0011391639709472656 seconds
DEBUG 01-07 10:14:07.055196.055196 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 10:14:07.055571.055571 cuda_h.py:19] end restore_tensors2 cost 0.00028443336486816406 seconds
DEBUG 01-07 10:14:07.055016.055016 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0020203590393066406 seconds
DEBUG 01-07 10:14:07.057158.057158 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 10:14:07.057533.057533 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 10:14:07.058152.058152 cuda_h.py:19] end allocate_cuda_memory cost 0.00024056434631347656 seconds
DEBUG 01-07 10:14:07.058432.058432 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 10:14:07.058950.058950 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 10:14:07.058613.058613 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 10:14:07.058309.058309 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 5c7cd7e3-33e8-4cdd-ac42-8ca6fc4d683a
DEBUG 01-07 10:14:07.058566.058566 client.py:106] call stub.LoadModelAsync
INFO 01-07 10:14:07.059482.059482 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 5c7cd7e3-33e8-4cdd-ac42-8ca6fc4d683a
DEBUG 01-07 10:14:07.059358.059358 cuda_h.py:19] end load_into_gpu_async cost 0.0011067390441894531 seconds
DEBUG 01-07 10:14:07.059153.059153 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 10:14:07.059011.059011 cuda_h.py:19] end restore_tensors2 cost 0.0002548694610595703 seconds
DEBUG 01-07 10:14:07.059171.059171 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0019161701202392578 seconds
DEBUG 01-07 10:14:07.061129.061129 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model_multi_device cost 0.0077972412109375 seconds
DEBUG 01-07 10:14:07.061005.061005 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-07 10:14:07.061875.061875 lmp.py:816] 
DEBUG 01-07 10:14:07.061875.061875 lmp.py:816]   Computing 19 experts on CPU...
DEBUG 01-07 10:14:07.061857.061857 cuda_h.py:19] end cpu_experts_submit cost 0.00010848045349121094 seconds
DEBUG 01-07 10:14:07.061937.061937 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-07 10:14:07.073836.073836 mlpmodule.py:749] group tensors cost 0.011696577072143555 s
DEBUG 01-07 10:14:07.075598.075598 mlpmodule.py:787] pad cost 0.0009794235229492188 s
DEBUG 01-07 10:14:07.075866.075866 mlpmodule.py:793] create cpu tensor cost 3.886222839355469e-05 s
DEBUG 01-07 10:14:07.075431.075431 mlpmodule.py:798] move to cpu cost 3.075599670410156e-05 s
DEBUG 01-07 10:14:07.085223.085223 mlpmodule.py:812] group_w3: shape=torch.Size([19, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=54788096
DEBUG 01-07 10:14:07.086520.086520 mlpmodule.py:813] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-07 10:14:07.086762.086762 mlpmodule.py:818] group_w3 first element: -0.0162353515625
WARNING 01-07 10:14:07.086462.086462 mlpmodule.py:828] start einsum2
DEBUG 01-07 10:14:07.100147.100147 mlpmodule.py:838] group einsum cost 0.024468421936035156 s
DEBUG 01-07 10:14:07.100645.100645 mlpmodule.py:846] cpy2cputensor cost 0.0004222393035888672 s
DEBUG 01-07 10:14:07.103380.103380 cuda_h.py:19] end wait_cetm_experts cost 0.04146933555603027 seconds
DEBUG 01-07 10:14:07.103648.103648 cuda_h.py:10] start gpu_sexperts
DEBUG 01-07 10:14:07.104813.104813 cuda_h.py:19] end gpu_sexperts cost 0.0005340576171875 seconds
DEBUG 01-07 10:14:07.104186.104186 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-07 10:14:07.104705.104705 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.6464462280273438e-05 seconds
DEBUG 01-07 10:14:07.104315.104315 cuda_h.py:10] start wait_experts_multi_device
INFO 01-07 10:14:07.104383.104383 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 255640ec-f9c5-4420-8580-c81852d31480
INFO 01-07 10:14:07.105768.105768 client.py:127] Model loaded
INFO 01-07 10:14:07.105910.105910 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 5c7cd7e3-33e8-4cdd-ac42-8ca6fc4d683a
INFO 01-07 10:14:07.106734.106734 client.py:127] Model loaded
DEBUG 01-07 10:14:07.106524.106524 cuda_h.py:19] end wait_experts_multi_device cost 0.0026504993438720703 seconds
DEBUG 01-07 10:14:07.106519.106519 cuda_h.py:10] start gpu_experts_multi_device
DEBUG 01-07 10:14:07.106533.106533 lmp.py:867]   Computing 23 experts on cuda:2...
DEBUG 01-07 10:14:07.108010.108010 mlpmodule.py:533] gpu group tensors cost 0.0005135536193847656 s
DEBUG 01-07 10:14:07.109188.109188 mlpmodule.py:566] gpu pad cost 0.0012934207916259766 s
DEBUG 01-07 10:14:07.110243.110243 mlpmodule.py:584] gpu group einsum cost 0.0005609989166259766 s
DEBUG 01-07 10:14:07.115878.115878 mlpmodule.py:656] gpu experts func einsum cost 0.007648944854736328 s
DEBUG 01-07 10:14:07.115425.115425 lmp.py:867]   Computing 22 experts on cuda:1...
DEBUG 01-07 10:14:07.116227.116227 mlpmodule.py:533] gpu group tensors cost 0.0003643035888671875 s
DEBUG 01-07 10:14:07.117629.117629 mlpmodule.py:566] gpu pad cost 0.0010488033294677734 s
DEBUG 01-07 10:14:07.117365.117365 mlpmodule.py:707]  experts func einsum cost 0.05579042434692383 s
DEBUG 01-07 10:14:07.117262.117262 mlpmodule.py:584] gpu group einsum cost 0.0004680156707763672 s
DEBUG 01-07 10:14:07.119740.119740 mlpmodule.py:656] gpu experts func einsum cost 0.003621816635131836 s
DEBUG 01-07 10:14:07.119432.119432 cuda_h.py:19] end gpu_experts_multi_device cost 0.012619972229003906 seconds
DEBUG 01-07 10:14:07.119693.119693 cuda_h.py:19] end layer_moe_generate_multi_device_12 cost 0.06856131553649902 seconds
DEBUG 01-07 10:14:07.119720.119720 lmp.py:194] -------------------------------- end prefill layer 12 --------------------------------
DEBUG 01-07 10:14:07.119655.119655 lmp.py:153] -------------------------------- start prefill layer 13 --------------------------------
DEBUG 01-07 10:14:07.119636.119636 cuda_h.py:10] start start_load_qkvogn_s_weight_l_14
DEBUG 01-07 10:14:07.119485.119485 cuda_h.py:10] start start_load_qkvogn_s_weight_l_14
DEBUG 01-07 10:14:07.119798.119798 cuda_h.py:19] end start_load_qkvogn_s_weight_l_14 cost 2.7894973754882812e-05 seconds
DEBUG 01-07 10:14:07.119594.119594 cuda_h.py:19] end start_load_qkvogn_s_weight_l_14 cost 5.7697296142578125e-05 seconds
DEBUG 01-07 10:14:07.120713.120713 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-07 10:14:07.120390.120390 cuda_h.py:10] start sllm_worker_task
DEBUG 01-07 10:14:07.120042.120042 mlpmodule.py:367] cuda:1 cuda:1
DEBUG 01-07 10:14:07.120044.120044 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 10:14:07.120239.120239 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 10:14:07.120250.120250 cuda_h.py:19] end allocate_cuda_memory cost 0.0002868175506591797 seconds
DEBUG 01-07 10:14:07.120385.120385 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 10:14:07.120856.120856 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 10:14:07.120725.120725 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 10:14:07.120044.120044 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 0d806d30-8a5e-4f7e-9c6f-71fbe02832b1
DEBUG 01-07 10:14:07.120715.120715 client.py:106] call stub.LoadModelAsync
DEBUG 01-07 10:14:07.121433.121433 cuda_h.py:10] start self_attn
INFO 01-07 10:14:07.121262.121262 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 0d806d30-8a5e-4f7e-9c6f-71fbe02832b1
DEBUG 01-07 10:14:07.121105.121105 cuda_h.py:19] end load_into_gpu_async cost 0.0009210109710693359 seconds
DEBUG 01-07 10:14:07.121570.121570 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 10:14:07.121454.121454 cuda_h.py:19] end restore_tensors2 cost 6.413459777832031e-05 seconds
DEBUG 01-07 10:14:07.121779.121779 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0015060901641845703 seconds
INFO 01-07 10:14:07.121470.121470 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 0d806d30-8a5e-4f7e-9c6f-71fbe02832b1
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-07 10:14:07.124942.124942 cuda_h.py:19] end self_attn cost 0.003647327423095703 seconds
DEBUG 01-07 10:14:07.125886.125886 cuda_h.py:19] end iln_self_attn_paln cost 0.005119800567626953 seconds
DEBUG 01-07 10:14:07.125285.125285 cuda_h.py:10] start layer_moe_generate_multi_device_13
DEBUG 01-07 10:14:07.125425.125425 cuda_h.py:10] start gate
DEBUG 01-07 10:14:07.125096.125096 cuda_h.py:19] end gate cost 0.0006368160247802734 seconds
DEBUG 01-07 10:14:07.125449.125449 cuda_h.py:10] start experts_map_get
DEBUG 01-07 10:14:07.126826.126826 lmp.py:744] 
DEBUG 01-07 10:14:07.126826.126826 lmp.py:744] Expert Token Distribution & Multi-Device Allocation:
DEBUG 01-07 10:14:07.126489.126489 lmp.py:745]   Total experts: 64
DEBUG 01-07 10:14:07.126570.126570 lmp.py:746]   CPU experts: 19 (30%)
DEBUG 01-07 10:14:07.126074.126074 lmp.py:747]   GPU experts: 45 (70%)
DEBUG 01-07 10:14:07.126432.126432 lmp.py:748]   Number of GPU devices: 2
DEBUG 01-07 10:14:07.126598.126598 lmp.py:749] 
DEBUG 01-07 10:14:07.126598.126598 lmp.py:749]   Expert ID | Tokens | Device
DEBUG 01-07 10:14:07.126479.126479 lmp.py:750]   -----------------------------------
DEBUG 01-07 10:14:07.126321.126321 lmp.py:767]   Expert 19 |     24 | CPU
DEBUG 01-07 10:14:07.126918.126918 lmp.py:767]   Expert 42 |     26 | CPU
DEBUG 01-07 10:14:07.126038.126038 lmp.py:767]   Expert 30 |     28 | CPU
DEBUG 01-07 10:14:07.126873.126873 lmp.py:767]   Expert 32 |     44 | CPU
DEBUG 01-07 10:14:07.126516.126516 lmp.py:767]   Expert  6 |     59 | CPU
DEBUG 01-07 10:14:07.126920.126920 lmp.py:767]   Expert 53 |     73 | CPU
DEBUG 01-07 10:14:07.126848.126848 lmp.py:767]   Expert  1 |     76 | CPU
DEBUG 01-07 10:14:07.126253.126253 lmp.py:767]   Expert  5 |     78 | CPU
DEBUG 01-07 10:14:07.126896.126896 lmp.py:767]   Expert  9 |    118 | CPU
DEBUG 01-07 10:14:07.126300.126300 lmp.py:767]   Expert 13 |    119 | CPU
DEBUG 01-07 10:14:07.126943.126943 lmp.py:767]   Expert 58 |    130 | CPU
DEBUG 01-07 10:14:07.126348.126348 lmp.py:767]   Expert 34 |    131 | CPU
DEBUG 01-07 10:14:07.126275.126275 lmp.py:767]   Expert 50 |    132 | CPU
DEBUG 01-07 10:14:07.126442.126442 lmp.py:767]   Expert 59 |    132 | CPU
DEBUG 01-07 10:14:07.126369.126369 lmp.py:767]   Expert 18 |    135 | CPU
DEBUG 01-07 10:14:07.126297.126297 lmp.py:767]   Expert 63 |    135 | CPU
DEBUG 01-07 10:14:07.126225.126225 lmp.py:767]   Expert 31 |    136 | CPU
DEBUG 01-07 10:14:07.126629.126629 lmp.py:767]   Expert 26 |    140 | CPU
DEBUG 01-07 10:14:07.126319.126319 lmp.py:767]   Expert 40 |    144 | CPU
DEBUG 01-07 10:14:07.126154.126154 lmp.py:767]   Expert 56 |    146 | GPU0(cuda:1)
DEBUG 01-07 10:14:07.126181.126181 lmp.py:767]   Expert 11 |    147 | GPU0(cuda:1)
DEBUG 01-07 10:14:07.126016.126016 lmp.py:767]   Expert 20 |    148 | GPU1(cuda:2)
DEBUG 01-07 10:14:07.126374.126374 lmp.py:767]   Expert 12 |    149 | GPU1(cuda:2)
DEBUG 01-07 10:14:07.126255.126255 lmp.py:767]   Expert 48 |    150 | GPU0(cuda:1)
DEBUG 01-07 10:14:07.126137.126137 lmp.py:767]   Expert  2 |    152 | GPU0(cuda:1)
DEBUG 01-07 10:14:07.126018.126018 lmp.py:767]   Expert 46 |    153 | GPU1(cuda:2)
DEBUG 01-07 10:14:07.126661.126661 lmp.py:767]   Expert 61 |    155 | GPU1(cuda:2)
DEBUG 01-07 10:14:07.126781.126781 lmp.py:767]   Expert  4 |    156 | GPU0(cuda:1)
DEBUG 01-07 10:14:07.126855.126855 lmp.py:767]   Expert 33 |    157 | GPU1(cuda:2)
DEBUG 01-07 10:14:07.127690.127690 lmp.py:767]   Expert 10 |    164 | GPU0(cuda:1)
DEBUG 01-07 10:14:07.127333.127333 lmp.py:767]   Expert 35 |    165 | GPU0(cuda:1)
DEBUG 01-07 10:14:07.127452.127452 lmp.py:767]   Expert 55 |    173 | GPU1(cuda:2)
DEBUG 01-07 10:14:07.127095.127095 lmp.py:767]   Expert 51 |    175 | GPU1(cuda:2)
DEBUG 01-07 10:14:07.127977.127977 lmp.py:767]   Expert  8 |    178 | GPU0(cuda:1)
DEBUG 01-07 10:14:07.127620.127620 lmp.py:767]   Expert 36 |    178 | GPU0(cuda:1)
DEBUG 01-07 10:14:07.127263.127263 lmp.py:767]   Expert 37 |    186 | GPU1(cuda:2)
DEBUG 01-07 10:14:07.127906.127906 lmp.py:767]   Expert 52 |    188 | GPU0(cuda:1)
DEBUG 01-07 10:14:07.127502.127502 lmp.py:767]   Expert 57 |    198 | GPU1(cuda:2)
DEBUG 01-07 10:14:07.127337.127337 lmp.py:767]   Expert  0 |    200 | GPU1(cuda:2)
DEBUG 01-07 10:14:07.127219.127219 lmp.py:767]   Expert 39 |    218 | GPU0(cuda:1)
DEBUG 01-07 10:14:07.127862.127862 lmp.py:767]   Expert 25 |    231 | GPU0(cuda:1)
DEBUG 01-07 10:14:07.127266.127266 lmp.py:767]   Expert 62 |    237 | GPU1(cuda:2)
DEBUG 01-07 10:14:07.127671.127671 lmp.py:767]   Expert 38 |    243 | GPU0(cuda:1)
DEBUG 01-07 10:14:07.127837.127837 lmp.py:767]   Expert  7 |    247 | GPU1(cuda:2)
DEBUG 01-07 10:14:07.127242.127242 lmp.py:767]   Expert 27 |    248 | GPU0(cuda:1)
DEBUG 01-07 10:14:07.127646.127646 lmp.py:767]   Expert  3 |    250 | GPU1(cuda:2)
DEBUG 01-07 10:14:07.127812.127812 lmp.py:767]   Expert 28 |    251 | GPU0(cuda:1)
DEBUG 01-07 10:14:07.127171.127171 lmp.py:767]   Expert 24 |    253 | GPU1(cuda:2)
DEBUG 01-07 10:14:07.127006.127006 lmp.py:767]   Expert 60 |    254 | GPU0(cuda:1)
DEBUG 01-07 10:14:07.127887.127887 lmp.py:767]   Expert 49 |    255 | GPU1(cuda:2)
DEBUG 01-07 10:14:07.127292.127292 lmp.py:767]   Expert 16 |    261 | GPU1(cuda:2)
DEBUG 01-07 10:14:07.127173.127173 lmp.py:767]   Expert 21 |    261 | GPU0(cuda:1)
DEBUG 01-07 10:14:07.127816.127816 lmp.py:767]   Expert 43 |    268 | GPU0(cuda:1)
DEBUG 01-07 10:14:07.127220.127220 lmp.py:767]   Expert 23 |    272 | GPU0(cuda:1)
DEBUG 01-07 10:14:07.127863.127863 lmp.py:767]   Expert 29 |    272 | GPU1(cuda:2)
DEBUG 01-07 10:14:07.127506.127506 lmp.py:767]   Expert 15 |    292 | GPU0(cuda:1)
DEBUG 01-07 10:14:07.127911.127911 lmp.py:767]   Expert 22 |    292 | GPU1(cuda:2)
DEBUG 01-07 10:14:07.127792.127792 lmp.py:767]   Expert 47 |    294 | GPU1(cuda:2)
DEBUG 01-07 10:14:07.127912.127912 lmp.py:767]   Expert 44 |    303 | GPU0(cuda:1)
DEBUG 01-07 10:14:07.127509.127509 lmp.py:767]   Expert 41 |    305 | GPU1(cuda:2)
DEBUG 01-07 10:14:07.127390.127390 lmp.py:767]   Expert 54 |    357 | GPU0(cuda:1)
DEBUG 01-07 10:14:07.127033.127033 lmp.py:767]   Expert 14 |    373 | GPU1(cuda:2)
DEBUG 01-07 10:14:07.127153.127153 lmp.py:767]   Expert 17 |    408 | GPU1(cuda:2)
DEBUG 01-07 10:14:07.127273.127273 lmp.py:767]   Expert 45 |    465 | GPU0(cuda:1)
DEBUG 01-07 10:14:07.127724.127724 lmp.py:769] 
DEBUG 01-07 10:14:07.127724.127724 lmp.py:769]   Device Token Distribution:
DEBUG 01-07 10:14:07.127128.127128 lmp.py:770]   CPU:   1860 tokens
DEBUG 01-07 10:14:07.127725.127725 lmp.py:774]   cuda:1:   5287 tokens (23 experts)
DEBUG 01-07 10:14:07.127798.127798 lmp.py:774]   cuda:2:   5141 tokens (22 experts)
DEBUG 01-07 10:14:07.127441.127441 lmp.py:775]   Total GPU:  10428 tokens
DEBUG 01-07 10:14:07.127561.127561 lmp.py:776] ============================================================
DEBUG 01-07 10:14:07.127561.127561 lmp.py:776] 
DEBUG 01-07 10:14:07.127449.127449 cuda_h.py:19] end experts_map_get cost 0.0017626285552978516 seconds
DEBUG 01-07 10:14:07.127331.127331 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model_multi_device
DEBUG 01-07 10:14:07.127485.127485 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 10:14:07.127389.127389 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 10:14:07.128411.128411 cuda_h.py:19] end allocate_cuda_memory cost 0.00022983551025390625 seconds
DEBUG 01-07 10:14:07.128983.128983 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 10:14:07.128739.128739 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 10:14:07.128309.128309 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 10:14:07.128959.128959 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 4322107d-5285-48b5-9d50-99a3bdfed7c0
DEBUG 01-07 10:14:07.128507.128507 client.py:106] call stub.LoadModelAsync
INFO 01-07 10:14:07.128281.128281 client.py:127] Model loaded
DEBUG 01-07 10:14:07.129806.129806 cuda_h.py:19] end sllm_worker_task cost 0.008920431137084961 seconds
INFO 01-07 10:14:07.129820.129820 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 4322107d-5285-48b5-9d50-99a3bdfed7c0
DEBUG 01-07 10:14:07.129709.129709 cuda_h.py:19] end load_into_gpu_async cost 0.001100301742553711 seconds
DEBUG 01-07 10:14:07.129697.129697 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 10:14:07.129442.129442 cuda_h.py:19] end restore_tensors2 cost 0.00027871131896972656 seconds
DEBUG 01-07 10:14:07.129927.129927 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0019190311431884766 seconds
DEBUG 01-07 10:14:07.131891.131891 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 10:14:07.131346.131346 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 10:14:07.132771.132771 cuda_h.py:19] end allocate_cuda_memory cost 0.00020551681518554688 seconds
DEBUG 01-07 10:14:07.132992.132992 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 10:14:07.132033.132033 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 10:14:07.132219.132219 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 10:14:07.132677.132677 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 970f585e-df31-4aa5-83b8-47cf1bcc827b
DEBUG 01-07 10:14:07.132568.132568 client.py:106] call stub.LoadModelAsync
INFO 01-07 10:14:07.133343.133343 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 970f585e-df31-4aa5-83b8-47cf1bcc827b
DEBUG 01-07 10:14:07.133365.133365 cuda_h.py:19] end load_into_gpu_async cost 0.001226663589477539 seconds
DEBUG 01-07 10:14:07.133399.133399 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 10:14:07.133937.133937 cuda_h.py:19] end restore_tensors2 cost 0.00023102760314941406 seconds
DEBUG 01-07 10:14:07.133899.133899 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.001959085464477539 seconds
DEBUG 01-07 10:14:07.135304.135304 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model_multi_device cost 0.007678508758544922 seconds
DEBUG 01-07 10:14:07.135365.135365 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-07 10:14:07.135043.135043 lmp.py:816] 
DEBUG 01-07 10:14:07.135043.135043 lmp.py:816]   Computing 19 experts on CPU...
DEBUG 01-07 10:14:07.135595.135595 cuda_h.py:19] end cpu_experts_submit cost 0.00010704994201660156 seconds
DEBUG 01-07 10:14:07.135198.135198 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-07 10:14:07.145881.145881 mlpmodule.py:749] group tensors cost 0.01017451286315918 s
DEBUG 01-07 10:14:07.147341.147341 mlpmodule.py:787] pad cost 0.0009510517120361328 s
DEBUG 01-07 10:14:07.147324.147324 mlpmodule.py:793] create cpu tensor cost 4.00543212890625e-05 s
DEBUG 01-07 10:14:07.147697.147697 mlpmodule.py:798] move to cpu cost 2.9802322387695312e-05 s
DEBUG 01-07 10:14:07.160681.160681 mlpmodule.py:812] group_w3: shape=torch.Size([19, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=54788096
DEBUG 01-07 10:14:07.160449.160449 mlpmodule.py:813] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-07 10:14:07.161353.161353 mlpmodule.py:818] group_w3 first element: -0.0211181640625
WARNING 01-07 10:14:07.161344.161344 mlpmodule.py:828] start einsum2
DEBUG 01-07 10:14:07.177286.177286 mlpmodule.py:838] group einsum cost 0.029184818267822266 s
DEBUG 01-07 10:14:07.177361.177361 mlpmodule.py:846] cpy2cputensor cost 0.0004439353942871094 s
DEBUG 01-07 10:14:07.180335.180335 cuda_h.py:19] end wait_cetm_experts cost 0.044579505920410156 seconds
DEBUG 01-07 10:14:07.180947.180947 cuda_h.py:10] start gpu_sexperts
DEBUG 01-07 10:14:07.180490.180490 cuda_h.py:19] end gpu_sexperts cost 0.0005304813385009766 seconds
DEBUG 01-07 10:14:07.181671.181671 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-07 10:14:07.181713.181713 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.6702880859375e-05 seconds
DEBUG 01-07 10:14:07.181654.181654 cuda_h.py:10] start wait_experts_multi_device
INFO 01-07 10:14:07.181079.181079 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 4322107d-5285-48b5-9d50-99a3bdfed7c0
INFO 01-07 10:14:07.182330.182330 client.py:127] Model loaded
INFO 01-07 10:14:07.182802.182802 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 970f585e-df31-4aa5-83b8-47cf1bcc827b
INFO 01-07 10:14:07.183889.183889 client.py:127] Model loaded
DEBUG 01-07 10:14:07.183825.183825 cuda_h.py:19] end wait_experts_multi_device cost 0.0026929378509521484 seconds
DEBUG 01-07 10:14:07.183865.183865 cuda_h.py:10] start gpu_experts_multi_device
DEBUG 01-07 10:14:07.183834.183834 lmp.py:867]   Computing 22 experts on cuda:2...
DEBUG 01-07 10:14:07.185929.185929 mlpmodule.py:533] gpu group tensors cost 0.0004909038543701172 s
DEBUG 01-07 10:14:07.186987.186987 mlpmodule.py:566] gpu pad cost 0.001277923583984375 s
DEBUG 01-07 10:14:07.187081.187081 mlpmodule.py:584] gpu group einsum cost 0.0005555152893066406 s
DEBUG 01-07 10:14:07.189545.189545 mlpmodule.py:656] gpu experts func einsum cost 0.004458427429199219 s
DEBUG 01-07 10:14:07.189019.189019 lmp.py:867]   Computing 23 experts on cuda:1...
DEBUG 01-07 10:14:07.190200.190200 mlpmodule.py:533] gpu group tensors cost 0.0004742145538330078 s
DEBUG 01-07 10:14:07.191284.191284 mlpmodule.py:566] gpu pad cost 0.0012676715850830078 s
DEBUG 01-07 10:14:07.192316.192316 mlpmodule.py:584] gpu group einsum cost 0.0004811286926269531 s
DEBUG 01-07 10:14:07.193181.193181 mlpmodule.py:707]  experts func einsum cost 0.05813145637512207 s
DEBUG 01-07 10:14:07.194033.194033 mlpmodule.py:656] gpu experts func einsum cost 0.0043866634368896484 s
DEBUG 01-07 10:14:07.194415.194415 cuda_h.py:19] end gpu_experts_multi_device cost 0.010452985763549805 seconds
DEBUG 01-07 10:14:07.194815.194815 cuda_h.py:19] end layer_moe_generate_multi_device_13 cost 0.06921529769897461 seconds
DEBUG 01-07 10:14:07.194082.194082 lmp.py:194] -------------------------------- end prefill layer 13 --------------------------------
DEBUG 01-07 10:14:07.194488.194488 lmp.py:153] -------------------------------- start prefill layer 14 --------------------------------
DEBUG 01-07 10:14:07.194615.194615 cuda_h.py:10] start start_load_qkvogn_s_weight_l_15
DEBUG 01-07 10:14:07.194371.194371 cuda_h.py:10] start start_load_qkvogn_s_weight_l_15
DEBUG 01-07 10:14:07.194922.194922 cuda_h.py:19] end start_load_qkvogn_s_weight_l_15 cost 2.9325485229492188e-05 seconds
DEBUG 01-07 10:14:07.194037.194037 cuda_h.py:19] end start_load_qkvogn_s_weight_l_15 cost 8.177757263183594e-05 seconds
DEBUG 01-07 10:14:07.194839.194839 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-07 10:14:07.195192.195192 cuda_h.py:10] start sllm_worker_task
DEBUG 01-07 10:14:07.195902.195902 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 10:14:07.195639.195639 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 10:14:07.195292.195292 cuda_h.py:19] end allocate_cuda_memory cost 0.00027060508728027344 seconds
DEBUG 01-07 10:14:07.195222.195222 mlpmodule.py:367] cuda:1 cuda:1
DEBUG 01-07 10:14:07.195528.195528 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 10:14:07.195472.195472 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 10:14:07.195010.195010 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 10:14:07.195998.195998 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, e35fc045-bf67-4e32-80a4-1f13b5495171
DEBUG 01-07 10:14:07.195530.195530 client.py:106] call stub.LoadModelAsync
DEBUG 01-07 10:14:07.196779.196779 cuda_h.py:10] start self_attn
INFO 01-07 10:14:07.196788.196788 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, e35fc045-bf67-4e32-80a4-1f13b5495171
DEBUG 01-07 10:14:07.196525.196525 cuda_h.py:19] end load_into_gpu_async cost 0.0009877681732177734 seconds
DEBUG 01-07 10:14:07.196844.196844 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 10:14:07.196158.196158 cuda_h.py:19] end restore_tensors2 cost 6.651878356933594e-05 seconds
DEBUG 01-07 10:14:07.196291.196291 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0016942024230957031 seconds
INFO 01-07 10:14:07.196485.196485 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, e35fc045-bf67-4e32-80a4-1f13b5495171
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-07 10:14:07.199016.199016 cuda_h.py:19] end self_attn cost 0.0036592483520507812 seconds
DEBUG 01-07 10:14:07.200762.200762 cuda_h.py:19] end iln_self_attn_paln cost 0.0051801204681396484 seconds
DEBUG 01-07 10:14:07.200003.200003 cuda_h.py:10] start layer_moe_generate_multi_device_14
DEBUG 01-07 10:14:07.200481.200481 cuda_h.py:10] start gate
DEBUG 01-07 10:14:07.200670.200670 cuda_h.py:19] end gate cost 0.0006670951843261719 seconds
DEBUG 01-07 10:14:07.201545.201545 cuda_h.py:10] start experts_map_get
DEBUG 01-07 10:14:07.201725.201725 lmp.py:744] 
DEBUG 01-07 10:14:07.201725.201725 lmp.py:744] Expert Token Distribution & Multi-Device Allocation:
DEBUG 01-07 10:14:07.201740.201740 lmp.py:745]   Total experts: 64
DEBUG 01-07 10:14:07.201535.201535 lmp.py:746]   CPU experts: 19 (30%)
DEBUG 01-07 10:14:07.201847.201847 lmp.py:747]   GPU experts: 45 (70%)
DEBUG 01-07 10:14:07.201013.201013 lmp.py:748]   Number of GPU devices: 2
DEBUG 01-07 10:14:07.201702.201702 lmp.py:749] 
DEBUG 01-07 10:14:07.201702.201702 lmp.py:749]   Expert ID | Tokens | Device
DEBUG 01-07 10:14:07.201153.201153 lmp.py:750]   -----------------------------------
DEBUG 01-07 10:14:07.201823.201823 lmp.py:767]   Expert  7 |     29 | CPU
DEBUG 01-07 10:14:07.201943.201943 lmp.py:767]   Expert 34 |     32 | CPU
DEBUG 01-07 10:14:07.201633.201633 lmp.py:767]   Expert 13 |     42 | CPU
DEBUG 01-07 10:14:07.201560.201560 lmp.py:767]   Expert 39 |     79 | CPU
DEBUG 01-07 10:14:07.201250.201250 lmp.py:767]   Expert 54 |     80 | CPU
DEBUG 01-07 10:14:07.201700.201700 lmp.py:767]   Expert 18 |     87 | CPU
DEBUG 01-07 10:14:07.201913.201913 lmp.py:767]   Expert 49 |     89 | CPU
DEBUG 01-07 10:14:07.201808.201808 lmp.py:767]   Expert 21 |     99 | CPU
DEBUG 01-07 10:14:07.201120.201120 lmp.py:767]   Expert 16 |    105 | CPU
DEBUG 01-07 10:14:07.201286.201286 lmp.py:767]   Expert 59 |    106 | CPU
DEBUG 01-07 10:14:07.201498.201498 lmp.py:767]   Expert  0 |    109 | CPU
DEBUG 01-07 10:14:07.201949.201949 lmp.py:767]   Expert 15 |    116 | CPU
DEBUG 01-07 10:14:07.201162.201162 lmp.py:767]   Expert 41 |    118 | CPU
DEBUG 01-07 10:14:07.201613.201613 lmp.py:767]   Expert 22 |    120 | CPU
DEBUG 01-07 10:14:07.201216.201216 lmp.py:767]   Expert 45 |    124 | CPU
DEBUG 01-07 10:14:07.201535.201535 lmp.py:767]   Expert 17 |    126 | CPU
DEBUG 01-07 10:14:07.201701.201701 lmp.py:767]   Expert 61 |    131 | CPU
DEBUG 01-07 10:14:07.201629.201629 lmp.py:767]   Expert  8 |    134 | CPU
DEBUG 01-07 10:14:07.201841.201841 lmp.py:767]   Expert 52 |    137 | CPU
DEBUG 01-07 10:14:07.201723.201723 lmp.py:767]   Expert 12 |    140 | GPU0(cuda:1)
DEBUG 01-07 10:14:07.201081.201081 lmp.py:767]   Expert 38 |    143 | GPU1(cuda:2)
DEBUG 01-07 10:14:07.202201.202201 lmp.py:767]   Expert 35 |    144 | GPU0(cuda:1)
DEBUG 01-07 10:14:07.202804.202804 lmp.py:767]   Expert 48 |    145 | GPU0(cuda:1)
DEBUG 01-07 10:14:07.202315.202315 lmp.py:767]   Expert 31 |    154 | GPU1(cuda:2)
DEBUG 01-07 10:14:07.202435.202435 lmp.py:767]   Expert 36 |    157 | GPU1(cuda:2)
DEBUG 01-07 10:14:07.202316.202316 lmp.py:767]   Expert 50 |    157 | GPU0(cuda:1)
DEBUG 01-07 10:14:07.202959.202959 lmp.py:767]   Expert 53 |    158 | GPU0(cuda:1)
DEBUG 01-07 10:14:07.202125.202125 lmp.py:767]   Expert 40 |    160 | GPU1(cuda:2)
DEBUG 01-07 10:14:07.202291.202291 lmp.py:767]   Expert 60 |    164 | GPU1(cuda:2)
DEBUG 01-07 10:14:07.202219.202219 lmp.py:767]   Expert 27 |    172 | GPU0(cuda:1)
DEBUG 01-07 10:14:07.202147.202147 lmp.py:767]   Expert 19 |    193 | GPU1(cuda:2)
DEBUG 01-07 10:14:07.202313.202313 lmp.py:767]   Expert  4 |    198 | GPU0(cuda:1)
DEBUG 01-07 10:14:07.202241.202241 lmp.py:767]   Expert 29 |    200 | GPU0(cuda:1)
DEBUG 01-07 10:14:07.202559.202559 lmp.py:767]   Expert 30 |    208 | GPU1(cuda:2)
DEBUG 01-07 10:14:07.202209.202209 lmp.py:767]   Expert 20 |    219 | GPU0(cuda:1)
DEBUG 01-07 10:14:07.202329.202329 lmp.py:767]   Expert 11 |    220 | GPU1(cuda:2)
DEBUG 01-07 10:14:07.202687.202687 lmp.py:767]   Expert  6 |    223 | GPU0(cuda:1)
DEBUG 01-07 10:14:07.202092.202092 lmp.py:767]   Expert 26 |    223 | GPU1(cuda:2)
DEBUG 01-07 10:14:07.202496.202496 lmp.py:767]   Expert 57 |    223 | GPU0(cuda:1)
DEBUG 01-07 10:14:07.202424.202424 lmp.py:767]   Expert 43 |    230 | GPU0(cuda:1)
DEBUG 01-07 10:14:07.202113.202113 lmp.py:767]   Expert 46 |    230 | GPU1(cuda:2)
DEBUG 01-07 10:14:07.202279.202279 lmp.py:767]   Expert 42 |    237 | GPU1(cuda:2)
DEBUG 01-07 10:14:07.202969.202969 lmp.py:767]   Expert 33 |    239 | GPU0(cuda:1)
DEBUG 01-07 10:14:07.202896.202896 lmp.py:767]   Expert  2 |    241 | GPU1(cuda:2)
DEBUG 01-07 10:14:07.202824.202824 lmp.py:767]   Expert 23 |    244 | GPU0(cuda:1)
DEBUG 01-07 10:14:07.202381.202381 lmp.py:767]   Expert 32 |    252 | GPU1(cuda:2)
DEBUG 01-07 10:14:07.202700.202700 lmp.py:767]   Expert 55 |    253 | GPU0(cuda:1)
DEBUG 01-07 10:14:07.202820.202820 lmp.py:767]   Expert 56 |    256 | GPU1(cuda:2)
DEBUG 01-07 10:14:07.202939.202939 lmp.py:767]   Expert 28 |    259 | GPU0(cuda:1)
DEBUG 01-07 10:14:07.202106.202106 lmp.py:767]   Expert  9 |    260 | GPU1(cuda:2)
DEBUG 01-07 10:14:07.202225.202225 lmp.py:767]   Expert  3 |    265 | GPU0(cuda:1)
DEBUG 01-07 10:14:07.202107.202107 lmp.py:767]   Expert 51 |    270 | GPU1(cuda:2)
DEBUG 01-07 10:14:07.202750.202750 lmp.py:767]   Expert 14 |    272 | GPU0(cuda:1)
DEBUG 01-07 10:14:07.202261.202261 lmp.py:767]   Expert 44 |    277 | GPU1(cuda:2)
DEBUG 01-07 10:14:07.202811.202811 lmp.py:767]   Expert  1 |    281 | GPU1(cuda:2)
DEBUG 01-07 10:14:07.202931.202931 lmp.py:767]   Expert 58 |    281 | GPU0(cuda:1)
DEBUG 01-07 10:14:07.202812.202812 lmp.py:767]   Expert 37 |    285 | GPU0(cuda:1)
DEBUG 01-07 10:14:07.202515.202515 lmp.py:767]   Expert 63 |    286 | GPU1(cuda:2)
DEBUG 01-07 10:14:07.202873.202873 lmp.py:767]   Expert 47 |    298 | GPU0(cuda:1)
DEBUG 01-07 10:14:07.202708.202708 lmp.py:767]   Expert 62 |    300 | GPU1(cuda:2)
DEBUG 01-07 10:14:07.202590.202590 lmp.py:767]   Expert 10 |    309 | GPU0(cuda:1)
DEBUG 01-07 10:14:07.202233.202233 lmp.py:767]   Expert 24 |    311 | GPU1(cuda:2)
DEBUG 01-07 10:14:07.202876.202876 lmp.py:767]   Expert 25 |    321 | GPU1(cuda:2)
DEBUG 01-07 10:14:07.202433.202433 lmp.py:767]   Expert  5 |    367 | GPU0(cuda:1)
DEBUG 01-07 10:14:07.202798.202798 lmp.py:769] 
DEBUG 01-07 10:14:07.202798.202798 lmp.py:769]   Device Token Distribution:
DEBUG 01-07 10:14:07.202633.202633 lmp.py:770]   CPU:   1863 tokens
DEBUG 01-07 10:14:07.202706.202706 lmp.py:774]   cuda:1:   5281 tokens (23 experts)
DEBUG 01-07 10:14:07.202065.202065 lmp.py:774]   cuda:2:   5144 tokens (22 experts)
DEBUG 01-07 10:14:07.202469.202469 lmp.py:775]   Total GPU:  10425 tokens
DEBUG 01-07 10:14:07.202158.202158 lmp.py:776] ============================================================
DEBUG 01-07 10:14:07.202158.202158 lmp.py:776] 
DEBUG 01-07 10:14:07.202523.202523 cuda_h.py:19] end experts_map_get cost 0.0018854141235351562 seconds
DEBUG 01-07 10:14:07.202273.202273 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model_multi_device
DEBUG 01-07 10:14:07.203202.203202 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 10:14:07.203119.203119 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 10:14:07.203618.203618 cuda_h.py:19] end allocate_cuda_memory cost 0.00022077560424804688 seconds
DEBUG 01-07 10:14:07.203097.203097 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 10:14:07.203522.203522 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 10:14:07.203570.203570 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 10:14:07.203902.203902 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, c2e7953a-d5e0-40a3-9049-0c7e2fbd4b60
DEBUG 01-07 10:14:07.203649.203649 client.py:106] call stub.LoadModelAsync
INFO 01-07 10:14:07.203244.203244 client.py:127] Model loaded
DEBUG 01-07 10:14:07.204879.204879 cuda_h.py:19] end sllm_worker_task cost 0.009184122085571289 seconds
INFO 01-07 10:14:07.204747.204747 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, c2e7953a-d5e0-40a3-9049-0c7e2fbd4b60
DEBUG 01-07 10:14:07.204782.204782 cuda_h.py:19] end load_into_gpu_async cost 0.0010325908660888672 seconds
DEBUG 01-07 10:14:07.204531.204531 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 10:14:07.204046.204046 cuda_h.py:19] end restore_tensors2 cost 0.00031757354736328125 seconds
DEBUG 01-07 10:14:07.204584.204584 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0019073486328125 seconds
DEBUG 01-07 10:14:07.206629.206629 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 10:14:07.207183.207183 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 10:14:07.207351.207351 cuda_h.py:19] end allocate_cuda_memory cost 0.00022482872009277344 seconds
DEBUG 01-07 10:14:07.207353.207353 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 10:14:07.207347.207347 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 10:14:07.207772.207772 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 10:14:07.207866.207866 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 964c09e4-30e0-4015-b1e6-5bcc2c883069
DEBUG 01-07 10:14:07.207401.207401 client.py:106] call stub.LoadModelAsync
INFO 01-07 10:14:07.208003.208003 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 964c09e4-30e0-4015-b1e6-5bcc2c883069
DEBUG 01-07 10:14:07.208309.208309 cuda_h.py:19] end load_into_gpu_async cost 0.001233816146850586 seconds
DEBUG 01-07 10:14:07.208866.208866 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 10:14:07.208221.208221 cuda_h.py:19] end restore_tensors2 cost 0.0002701282501220703 seconds
DEBUG 01-07 10:14:07.208626.208626 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.002048969268798828 seconds
DEBUG 01-07 10:14:07.210582.210582 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model_multi_device cost 0.00781393051147461 seconds
DEBUG 01-07 10:14:07.210557.210557 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-07 10:14:07.210474.210474 lmp.py:816] 
DEBUG 01-07 10:14:07.210474.210474 lmp.py:816]   Computing 19 experts on CPU...
DEBUG 01-07 10:14:07.211310.211310 cuda_h.py:19] end cpu_experts_submit cost 0.00010585784912109375 seconds
DEBUG 01-07 10:14:07.211913.211913 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-07 10:14:07.216269.216269 mlpmodule.py:749] group tensors cost 0.0055408477783203125 s
DEBUG 01-07 10:14:07.218089.218089 mlpmodule.py:787] pad cost 0.0010952949523925781 s
DEBUG 01-07 10:14:07.218609.218609 mlpmodule.py:793] create cpu tensor cost 4.315376281738281e-05 s
DEBUG 01-07 10:14:07.218565.218565 mlpmodule.py:798] move to cpu cost 3.314018249511719e-05 s
DEBUG 01-07 10:14:07.231975.231975 mlpmodule.py:812] group_w3: shape=torch.Size([19, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=54788096
DEBUG 01-07 10:14:07.231120.231120 mlpmodule.py:813] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-07 10:14:07.231839.231839 mlpmodule.py:818] group_w3 first element: 0.000789642333984375
WARNING 01-07 10:14:07.231724.231724 mlpmodule.py:828] start einsum2
DEBUG 01-07 10:14:07.245951.245951 mlpmodule.py:838] group einsum cost 0.02706432342529297 s
DEBUG 01-07 10:14:07.246397.246397 mlpmodule.py:846] cpy2cputensor cost 0.0004398822784423828 s
DEBUG 01-07 10:14:07.249444.249444 cuda_h.py:19] end wait_cetm_experts cost 0.03795170783996582 seconds
DEBUG 01-07 10:14:07.249573.249573 cuda_h.py:10] start gpu_sexperts
DEBUG 01-07 10:14:07.249805.249805 cuda_h.py:19] end gpu_sexperts cost 0.0005464553833007812 seconds
DEBUG 01-07 10:14:07.249409.249409 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-07 10:14:07.249544.249544 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.4318695068359375e-05 seconds
DEBUG 01-07 10:14:07.249200.249200 cuda_h.py:10] start wait_experts_multi_device
INFO 01-07 10:14:07.249102.249102 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, c2e7953a-d5e0-40a3-9049-0c7e2fbd4b60
INFO 01-07 10:14:07.255522.255522 client.py:127] Model loaded
INFO 01-07 10:14:07.255073.255073 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 964c09e4-30e0-4015-b1e6-5bcc2c883069
INFO 01-07 10:14:07.256464.256464 client.py:127] Model loaded
DEBUG 01-07 10:14:07.256538.256538 cuda_h.py:19] end wait_experts_multi_device cost 0.007101297378540039 seconds
DEBUG 01-07 10:14:07.257387.257387 cuda_h.py:10] start gpu_experts_multi_device
DEBUG 01-07 10:14:07.257733.257733 lmp.py:867]   Computing 22 experts on cuda:2...
DEBUG 01-07 10:14:07.258498.258498 mlpmodule.py:707]  experts func einsum cost 0.04701828956604004 s
DEBUG 01-07 10:14:07.258477.258477 mlpmodule.py:533] gpu group tensors cost 0.0005481243133544922 s
DEBUG 01-07 10:14:07.259873.259873 mlpmodule.py:566] gpu pad cost 0.0012531280517578125 s
DEBUG 01-07 10:14:07.260723.260723 mlpmodule.py:584] gpu group einsum cost 0.0005872249603271484 s
DEBUG 01-07 10:14:07.262719.262719 mlpmodule.py:656] gpu experts func einsum cost 0.004418849945068359 s
DEBUG 01-07 10:14:07.262185.262185 lmp.py:867]   Computing 23 experts on cuda:1...
DEBUG 01-07 10:14:07.263945.263945 mlpmodule.py:533] gpu group tensors cost 0.00041031837463378906 s
DEBUG 01-07 10:14:07.264810.264810 mlpmodule.py:566] gpu pad cost 0.001077890396118164 s
DEBUG 01-07 10:14:07.264743.264743 mlpmodule.py:584] gpu group einsum cost 0.0004868507385253906 s
DEBUG 01-07 10:14:07.266964.266964 mlpmodule.py:656] gpu experts func einsum cost 0.003760814666748047 s
DEBUG 01-07 10:14:07.266695.266695 cuda_h.py:19] end gpu_experts_multi_device cost 0.009575366973876953 seconds
DEBUG 01-07 10:14:07.266943.266943 cuda_h.py:19] end layer_moe_generate_multi_device_14 cost 0.06642699241638184 seconds
DEBUG 01-07 10:14:07.266562.266562 lmp.py:194] -------------------------------- end prefill layer 14 --------------------------------
DEBUG 01-07 10:14:07.267139.267139 lmp.py:153] -------------------------------- start prefill layer 15 --------------------------------
DEBUG 01-07 10:14:07.267358.267358 cuda_h.py:10] start start_load_qkvogn_s_weight_l_16
DEBUG 01-07 10:14:07.267757.267757 cuda_h.py:10] start start_load_qkvogn_s_weight_l_16
DEBUG 01-07 10:14:07.267070.267070 cuda_h.py:19] end start_load_qkvogn_s_weight_l_16 cost 2.6941299438476562e-05 seconds
DEBUG 01-07 10:14:07.267794.267794 cuda_h.py:19] end start_load_qkvogn_s_weight_l_16 cost 7.343292236328125e-05 seconds
DEBUG 01-07 10:14:07.267629.267629 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-07 10:14:07.267300.267300 mlpmodule.py:367] cuda:1 cuda:1
DEBUG 01-07 10:14:07.267918.267918 cuda_h.py:10] start sllm_worker_task
DEBUG 01-07 10:14:07.267106.267106 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 10:14:07.267889.267889 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 10:14:07.267509.267509 cuda_h.py:19] end allocate_cuda_memory cost 0.0002827644348144531 seconds
DEBUG 01-07 10:14:07.267426.267426 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 10:14:07.267520.267520 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 10:14:07.267958.267958 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 10:14:07.267277.267277 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 829cb2eb-def2-45ca-b4da-8da5f78809e1
DEBUG 01-07 10:14:07.268902.268902 client.py:106] call stub.LoadModelAsync
DEBUG 01-07 10:14:07.268421.268421 cuda_h.py:10] start self_attn
INFO 01-07 10:14:07.268529.268529 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 829cb2eb-def2-45ca-b4da-8da5f78809e1
DEBUG 01-07 10:14:07.268266.268266 cuda_h.py:19] end load_into_gpu_async cost 0.0009367465972900391 seconds
DEBUG 01-07 10:14:07.268585.268585 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 10:14:07.268422.268422 cuda_h.py:19] end restore_tensors2 cost 6.604194641113281e-05 seconds
DEBUG 01-07 10:14:07.268748.268748 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0015311241149902344 seconds
INFO 01-07 10:14:07.269339.269339 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 829cb2eb-def2-45ca-b4da-8da5f78809e1
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-07 10:14:07.272076.272076 cuda_h.py:19] end self_attn cost 0.00365447998046875 seconds
DEBUG 01-07 10:14:07.272034.272034 cuda_h.py:19] end iln_self_attn_paln cost 0.005133867263793945 seconds
DEBUG 01-07 10:14:07.272983.272983 cuda_h.py:10] start layer_moe_generate_multi_device_15
DEBUG 01-07 10:14:07.272124.272124 cuda_h.py:10] start gate
DEBUG 01-07 10:14:07.273585.273585 cuda_h.py:19] end gate cost 0.0006930828094482422 seconds
DEBUG 01-07 10:14:07.273984.273984 cuda_h.py:10] start experts_map_get
DEBUG 01-07 10:14:07.273256.273256 lmp.py:744] 
DEBUG 01-07 10:14:07.273256.273256 lmp.py:744] Expert Token Distribution & Multi-Device Allocation:
DEBUG 01-07 10:14:07.273748.273748 lmp.py:745]   Total experts: 64
DEBUG 01-07 10:14:07.273543.273543 lmp.py:746]   CPU experts: 19 (30%)
DEBUG 01-07 10:14:07.273332.273332 lmp.py:747]   GPU experts: 45 (70%)
DEBUG 01-07 10:14:07.273498.273498 lmp.py:748]   Number of GPU devices: 2
DEBUG 01-07 10:14:07.273472.273472 lmp.py:749] 
DEBUG 01-07 10:14:07.273472.273472 lmp.py:749]   Expert ID | Tokens | Device
DEBUG 01-07 10:14:07.273638.273638 lmp.py:750]   -----------------------------------
DEBUG 01-07 10:14:07.273718.273718 lmp.py:767]   Expert 15 |     64 | CPU
DEBUG 01-07 10:14:07.273885.273885 lmp.py:767]   Expert 41 |     69 | CPU
DEBUG 01-07 10:14:07.273740.273740 lmp.py:767]   Expert 63 |     76 | CPU
DEBUG 01-07 10:14:07.273621.273621 lmp.py:767]   Expert  0 |     78 | CPU
DEBUG 01-07 10:14:07.273788.273788 lmp.py:767]   Expert 20 |     83 | CPU
DEBUG 01-07 10:14:07.273477.273477 lmp.py:767]   Expert  7 |     92 | CPU
DEBUG 01-07 10:14:07.273451.273451 lmp.py:767]   Expert 28 |     98 | CPU
DEBUG 01-07 10:14:07.273902.273902 lmp.py:767]   Expert 54 |     99 | CPU
DEBUG 01-07 10:14:07.273353.273353 lmp.py:767]   Expert 45 |    101 | CPU
DEBUG 01-07 10:14:07.274565.274565 lmp.py:767]   Expert 12 |    116 | CPU
DEBUG 01-07 10:14:07.274791.274791 lmp.py:767]   Expert 52 |    116 | CPU
DEBUG 01-07 10:14:07.274957.274957 lmp.py:767]   Expert  5 |    123 | CPU
DEBUG 01-07 10:14:07.274514.274514 lmp.py:767]   Expert 40 |    123 | CPU
DEBUG 01-07 10:14:07.274919.274919 lmp.py:767]   Expert  4 |    126 | CPU
DEBUG 01-07 10:14:07.274847.274847 lmp.py:767]   Expert 34 |    126 | CPU
DEBUG 01-07 10:14:07.274298.274298 lmp.py:767]   Expert 59 |    126 | CPU
DEBUG 01-07 10:14:07.274272.274272 lmp.py:767]   Expert 62 |    128 | CPU
DEBUG 01-07 10:14:07.274484.274484 lmp.py:767]   Expert 61 |    134 | CPU
DEBUG 01-07 10:14:07.274697.274697 lmp.py:767]   Expert 55 |    136 | CPU
DEBUG 01-07 10:14:07.274101.274101 lmp.py:767]   Expert 42 |    139 | GPU1(cuda:2)
DEBUG 01-07 10:14:07.274566.274566 lmp.py:767]   Expert 13 |    140 | GPU0(cuda:1)
DEBUG 01-07 10:14:07.274076.274076 lmp.py:767]   Expert 21 |    141 | GPU1(cuda:2)
DEBUG 01-07 10:14:07.274435.274435 lmp.py:767]   Expert 22 |    143 | GPU0(cuda:1)
DEBUG 01-07 10:14:07.274316.274316 lmp.py:767]   Expert 14 |    146 | GPU1(cuda:2)
DEBUG 01-07 10:14:07.274244.274244 lmp.py:767]   Expert 10 |    153 | GPU0(cuda:1)
DEBUG 01-07 10:14:07.274171.274171 lmp.py:767]   Expert 51 |    157 | GPU1(cuda:2)
DEBUG 01-07 10:14:07.274099.274099 lmp.py:767]   Expert 32 |    159 | GPU0(cuda:1)
DEBUG 01-07 10:14:07.274265.274265 lmp.py:767]   Expert 25 |    166 | GPU1(cuda:2)
DEBUG 01-07 10:14:07.274299.274299 lmp.py:767]   Expert 50 |    171 | GPU1(cuda:2)
DEBUG 01-07 10:14:07.274379.274379 lmp.py:767]   Expert 53 |    171 | GPU0(cuda:1)
DEBUG 01-07 10:14:07.274499.274499 lmp.py:767]   Expert  2 |    176 | GPU1(cuda:2)
DEBUG 01-07 10:14:07.274142.274142 lmp.py:767]   Expert 47 |    176 | GPU0(cuda:1)
DEBUG 01-07 10:14:07.274024.274024 lmp.py:767]   Expert  1 |    177 | GPU1(cuda:2)
DEBUG 01-07 10:14:07.274951.274951 lmp.py:767]   Expert 19 |    177 | GPU0(cuda:1)
DEBUG 01-07 10:14:07.274118.274118 lmp.py:767]   Expert 35 |    179 | GPU0(cuda:1)
DEBUG 01-07 10:14:07.274045.274045 lmp.py:767]   Expert 26 |    183 | GPU0(cuda:1)
DEBUG 01-07 10:14:07.274211.274211 lmp.py:767]   Expert 30 |    183 | GPU1(cuda:2)
DEBUG 01-07 10:14:07.274484.274484 lmp.py:767]   Expert  6 |    185 | GPU1(cuda:2)
DEBUG 01-07 10:14:07.274041.274041 lmp.py:767]   Expert 11 |    188 | GPU0(cuda:1)
DEBUG 01-07 10:14:07.274161.274161 lmp.py:767]   Expert 57 |    189 | GPU1(cuda:2)
DEBUG 01-07 10:14:07.274565.274565 lmp.py:767]   Expert 56 |    191 | GPU0(cuda:1)
DEBUG 01-07 10:14:07.274447.274447 lmp.py:767]   Expert 48 |    207 | GPU1(cuda:2)
DEBUG 01-07 10:14:07.274328.274328 lmp.py:767]   Expert 24 |    209 | GPU0(cuda:1)
DEBUG 01-07 10:14:07.274494.274494 lmp.py:767]   Expert 16 |    210 | GPU0(cuda:1)
DEBUG 01-07 10:14:07.274183.274183 lmp.py:767]   Expert 44 |    210 | GPU1(cuda:2)
DEBUG 01-07 10:14:07.274588.274588 lmp.py:767]   Expert 46 |    214 | GPU1(cuda:2)
DEBUG 01-07 10:14:07.274516.274516 lmp.py:767]   Expert 39 |    222 | GPU0(cuda:1)
DEBUG 01-07 10:14:07.274443.274443 lmp.py:767]   Expert 18 |    230 | GPU1(cuda:2)
DEBUG 01-07 10:14:07.274808.274808 lmp.py:767]   Expert 29 |    234 | GPU0(cuda:1)
DEBUG 01-07 10:14:07.274173.274173 lmp.py:767]   Expert 37 |    243 | GPU1(cuda:2)
DEBUG 01-07 10:14:07.274724.274724 lmp.py:767]   Expert  3 |    246 | GPU0(cuda:1)
DEBUG 01-07 10:14:07.274559.274559 lmp.py:767]   Expert 31 |    250 | GPU1(cuda:2)
DEBUG 01-07 10:14:07.274917.274917 lmp.py:767]   Expert 36 |    258 | GPU0(cuda:1)
DEBUG 01-07 10:14:07.274037.274037 lmp.py:767]   Expert  9 |    266 | GPU1(cuda:2)
DEBUG 01-07 10:14:07.274918.274918 lmp.py:767]   Expert 17 |    266 | GPU0(cuda:1)
DEBUG 01-07 10:14:07.274561.274561 lmp.py:767]   Expert 60 |    266 | GPU1(cuda:2)
DEBUG 01-07 10:14:07.274204.274204 lmp.py:767]   Expert 38 |    267 | GPU0(cuda:1)
DEBUG 01-07 10:14:07.274808.274808 lmp.py:767]   Expert 23 |    274 | GPU1(cuda:2)
DEBUG 01-07 10:14:07.274126.274126 lmp.py:767]   Expert 43 |    354 | GPU0(cuda:1)
DEBUG 01-07 10:14:07.274961.274961 lmp.py:767]   Expert 27 |    357 | GPU1(cuda:2)
DEBUG 01-07 10:14:07.274558.274558 lmp.py:767]   Expert 33 |    402 | GPU0(cuda:1)
DEBUG 01-07 10:14:07.275393.275393 lmp.py:767]   Expert  8 |    405 | GPU1(cuda:2)
DEBUG 01-07 10:14:07.275513.275513 lmp.py:767]   Expert 58 |    446 | GPU1(cuda:2)
DEBUG 01-07 10:14:07.275586.275586 lmp.py:767]   Expert 49 |    548 | GPU0(cuda:1)
DEBUG 01-07 10:14:07.275753.275753 lmp.py:769] 
DEBUG 01-07 10:14:07.275753.275753 lmp.py:769]   Device Token Distribution:
DEBUG 01-07 10:14:07.275872.275872 lmp.py:770]   CPU:   2014 tokens
DEBUG 01-07 10:14:07.275708.275708 lmp.py:774]   cuda:1:   5076 tokens (22 experts)
DEBUG 01-07 10:14:07.275589.275589 lmp.py:774]   cuda:2:   5198 tokens (23 experts)
DEBUG 01-07 10:14:07.275623.275623 lmp.py:775]   Total GPU:  10274 tokens
DEBUG 01-07 10:14:07.275418.275418 lmp.py:776] ============================================================
DEBUG 01-07 10:14:07.275418.275418 lmp.py:776] 
DEBUG 01-07 10:14:07.275737.275737 cuda_h.py:19] end experts_map_get cost 0.0018961429595947266 seconds
DEBUG 01-07 10:14:07.275572.275572 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model_multi_device
DEBUG 01-07 10:14:07.275203.275203 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 10:14:07.275942.275942 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 10:14:07.275693.275693 cuda_h.py:19] end allocate_cuda_memory cost 0.00023746490478515625 seconds
DEBUG 01-07 10:14:07.275742.275742 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 10:14:07.275213.275213 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 10:14:07.275499.275499 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 10:14:07.275579.275579 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, c10a8517-6e5a-4915-959b-91b3055930e0
DEBUG 01-07 10:14:07.275486.275486 client.py:106] call stub.LoadModelAsync
INFO 01-07 10:14:07.276650.276650 client.py:127] Model loaded
DEBUG 01-07 10:14:07.276974.276974 cuda_h.py:19] end sllm_worker_task cost 0.00910329818725586 seconds
INFO 01-07 10:14:07.276376.276376 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, c10a8517-6e5a-4915-959b-91b3055930e0
DEBUG 01-07 10:14:07.276677.276677 cuda_h.py:19] end load_into_gpu_async cost 0.0009984970092773438 seconds
DEBUG 01-07 10:14:07.276287.276287 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 10:14:07.277483.277483 cuda_h.py:19] end restore_tensors2 cost 0.0002932548522949219 seconds
DEBUG 01-07 10:14:07.277545.277545 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0018799304962158203 seconds
DEBUG 01-07 10:14:07.279633.279633 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 10:14:07.279578.279578 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 10:14:07.279672.279672 cuda_h.py:19] end allocate_cuda_memory cost 0.00020813941955566406 seconds
DEBUG 01-07 10:14:07.279701.279701 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 10:14:07.279549.279549 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 10:14:07.279664.279664 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 10:14:07.279744.279744 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, a7c30375-0aca-441d-9661-015b07d411da
DEBUG 01-07 10:14:07.279365.279365 client.py:106] call stub.LoadModelAsync
INFO 01-07 10:14:07.280234.280234 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, a7c30375-0aca-441d-9661-015b07d411da
DEBUG 01-07 10:14:07.280832.280832 cuda_h.py:19] end load_into_gpu_async cost 0.0011188983917236328 seconds
DEBUG 01-07 10:14:07.280820.280820 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 10:14:07.280758.280758 cuda_h.py:19] end restore_tensors2 cost 0.00031304359436035156 seconds
DEBUG 01-07 10:14:07.281349.281349 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0019462108612060547 seconds
DEBUG 01-07 10:14:07.282440.282440 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model_multi_device cost 0.0077016353607177734 seconds
DEBUG 01-07 10:14:07.282515.282515 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-07 10:14:07.283001.283001 lmp.py:816] 
DEBUG 01-07 10:14:07.283001.283001 lmp.py:816]   Computing 19 experts on CPU...
DEBUG 01-07 10:14:07.283890.283890 cuda_h.py:19] end cpu_experts_submit cost 0.0001087188720703125 seconds
DEBUG 01-07 10:14:07.283971.283971 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-07 10:14:07.289540.289540 mlpmodule.py:749] group tensors cost 0.0057904720306396484 s
DEBUG 01-07 10:14:07.291096.291096 mlpmodule.py:787] pad cost 0.0013928413391113281 s
DEBUG 01-07 10:14:07.291028.291028 mlpmodule.py:793] create cpu tensor cost 5.221366882324219e-05 s
DEBUG 01-07 10:14:07.291865.291865 mlpmodule.py:798] move to cpu cost 4.076957702636719e-05 s
DEBUG 01-07 10:14:07.302138.302138 mlpmodule.py:812] group_w3: shape=torch.Size([19, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=54788096
DEBUG 01-07 10:14:07.303144.303144 mlpmodule.py:813] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-07 10:14:07.303247.303247 mlpmodule.py:818] group_w3 first element: -0.0595703125
WARNING 01-07 10:14:07.303185.303185 mlpmodule.py:828] start einsum2
DEBUG 01-07 10:14:07.321082.321082 mlpmodule.py:838] group einsum cost 0.029915809631347656 s
DEBUG 01-07 10:14:07.322428.322428 mlpmodule.py:846] cpy2cputensor cost 0.0004334449768066406 s
DEBUG 01-07 10:14:07.324242.324242 cuda_h.py:19] end wait_cetm_experts cost 0.041483402252197266 seconds
DEBUG 01-07 10:14:07.324536.324536 cuda_h.py:10] start gpu_sexperts
DEBUG 01-07 10:14:07.325483.325483 cuda_h.py:19] end gpu_sexperts cost 0.0005471706390380859 seconds
DEBUG 01-07 10:14:07.325280.325280 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-07 10:14:07.325414.325414 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.4557113647460938e-05 seconds
DEBUG 01-07 10:14:07.325832.325832 cuda_h.py:10] start wait_experts_multi_device
INFO 01-07 10:14:07.325257.325257 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, c10a8517-6e5a-4915-959b-91b3055930e0
INFO 01-07 10:14:07.326738.326738 client.py:127] Model loaded
INFO 01-07 10:14:07.326720.326720 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, a7c30375-0aca-441d-9661-015b07d411da
INFO 01-07 10:14:07.330358.330358 client.py:127] Model loaded
DEBUG 01-07 10:14:07.330930.330930 cuda_h.py:19] end wait_experts_multi_device cost 0.0054471492767333984 seconds
DEBUG 01-07 10:14:07.331308.331308 cuda_h.py:10] start gpu_experts_multi_device
DEBUG 01-07 10:14:07.331515.331515 lmp.py:867]   Computing 23 experts on cuda:2...
DEBUG 01-07 10:14:07.332356.332356 mlpmodule.py:533] gpu group tensors cost 0.0004999637603759766 s
DEBUG 01-07 10:14:07.333053.333053 mlpmodule.py:707]  experts func einsum cost 0.05018258094787598 s
DEBUG 01-07 10:14:07.333672.333672 mlpmodule.py:566] gpu pad cost 0.0014650821685791016 s
DEBUG 01-07 10:14:07.334059.334059 mlpmodule.py:584] gpu group einsum cost 0.0005745887756347656 s
DEBUG 01-07 10:14:07.336274.336274 mlpmodule.py:656] gpu experts func einsum cost 0.004757881164550781 s
DEBUG 01-07 10:14:07.336667.336667 lmp.py:867]   Computing 22 experts on cuda:1...
DEBUG 01-07 10:14:07.337358.337358 mlpmodule.py:533] gpu group tensors cost 0.0003802776336669922 s
DEBUG 01-07 10:14:07.338308.338308 mlpmodule.py:566] gpu pad cost 0.0010340213775634766 s
DEBUG 01-07 10:14:07.339715.339715 mlpmodule.py:584] gpu group einsum cost 0.00041484832763671875 s
DEBUG 01-07 10:14:07.340730.340730 mlpmodule.py:656] gpu experts func einsum cost 0.003568410873413086 s
DEBUG 01-07 10:14:07.340991.340991 cuda_h.py:19] end gpu_experts_multi_device cost 0.009673833847045898 seconds
DEBUG 01-07 10:14:07.340245.340245 cuda_h.py:19] end layer_moe_generate_multi_device_15 cost 0.06831693649291992 seconds
DEBUG 01-07 10:14:07.341201.341201 lmp.py:194] -------------------------------- end prefill layer 15 --------------------------------
DEBUG 01-07 10:14:07.341248.341248 lmp.py:153] -------------------------------- start prefill layer 16 --------------------------------
DEBUG 01-07 10:14:07.341467.341467 cuda_h.py:10] start start_load_qkvogn_s_weight_l_17
DEBUG 01-07 10:14:07.341270.341270 cuda_h.py:10] start start_load_qkvogn_s_weight_l_17
DEBUG 01-07 10:14:07.341722.341722 cuda_h.py:19] end start_load_qkvogn_s_weight_l_17 cost 2.6226043701171875e-05 seconds
DEBUG 01-07 10:14:07.341279.341279 cuda_h.py:19] end start_load_qkvogn_s_weight_l_17 cost 5.53131103515625e-05 seconds
DEBUG 01-07 10:14:07.341160.341160 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-07 10:14:07.341606.341606 cuda_h.py:10] start sllm_worker_task
DEBUG 01-07 10:14:07.341496.341496 mlpmodule.py:367] cuda:1 cuda:1
DEBUG 01-07 10:14:07.341928.341928 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 10:14:07.341170.341170 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 10:14:07.341293.341293 cuda_h.py:19] end allocate_cuda_memory cost 0.0002646446228027344 seconds
DEBUG 01-07 10:14:07.341501.341501 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 10:14:07.341071.341071 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 10:14:07.341656.341656 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 10:14:07.342213.342213 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 89bf982c-c531-4a10-83ca-ae6f23f221bd
DEBUG 01-07 10:14:07.342030.342030 client.py:106] call stub.LoadModelAsync
DEBUG 01-07 10:14:07.342363.342363 cuda_h.py:10] start self_attn
INFO 01-07 10:14:07.342987.342987 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 89bf982c-c531-4a10-83ca-ae6f23f221bd
DEBUG 01-07 10:14:07.342247.342247 cuda_h.py:19] end load_into_gpu_async cost 0.0009021759033203125 seconds
DEBUG 01-07 10:14:07.342719.342719 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 10:14:07.342649.342649 cuda_h.py:19] end restore_tensors2 cost 6.365776062011719e-05 seconds
DEBUG 01-07 10:14:07.342974.342974 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0014913082122802734 seconds
INFO 01-07 10:14:07.343195.343195 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 89bf982c-c531-4a10-83ca-ae6f23f221bd
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-07 10:14:07.346063.346063 cuda_h.py:19] end self_attn cost 0.0036513805389404297 seconds
DEBUG 01-07 10:14:07.346769.346769 cuda_h.py:19] end iln_self_attn_paln cost 0.005089521408081055 seconds
DEBUG 01-07 10:14:07.346121.346121 cuda_h.py:10] start layer_moe_generate_multi_device_16
DEBUG 01-07 10:14:07.346023.346023 cuda_h.py:10] start gate
DEBUG 01-07 10:14:07.347410.347410 cuda_h.py:19] end gate cost 0.0006384849548339844 seconds
DEBUG 01-07 10:14:07.347047.347047 cuda_h.py:10] start experts_map_get
DEBUG 01-07 10:14:07.347868.347868 lmp.py:744] 
DEBUG 01-07 10:14:07.347868.347868 lmp.py:744] Expert Token Distribution & Multi-Device Allocation:
DEBUG 01-07 10:14:07.347499.347499 lmp.py:745]   Total experts: 64
DEBUG 01-07 10:14:07.347579.347579 lmp.py:746]   CPU experts: 19 (30%)
DEBUG 01-07 10:14:07.347368.347368 lmp.py:747]   GPU experts: 45 (70%)
DEBUG 01-07 10:14:07.347773.347773 lmp.py:748]   Number of GPU devices: 2
DEBUG 01-07 10:14:07.347224.347224 lmp.py:749] 
DEBUG 01-07 10:14:07.347224.347224 lmp.py:749]   Expert ID | Tokens | Device
DEBUG 01-07 10:14:07.347913.347913 lmp.py:750]   -----------------------------------
DEBUG 01-07 10:14:07.347801.347801 lmp.py:767]   Expert 58 |     37 | CPU
DEBUG 01-07 10:14:07.347490.347490 lmp.py:767]   Expert 31 |     60 | CPU
DEBUG 01-07 10:14:07.347464.347464 lmp.py:767]   Expert 47 |     63 | CPU
DEBUG 01-07 10:14:07.347915.347915 lmp.py:767]   Expert 45 |     65 | CPU
DEBUG 01-07 10:14:07.347651.347651 lmp.py:767]   Expert 49 |     65 | CPU
DEBUG 01-07 10:14:07.347863.347863 lmp.py:767]   Expert  4 |     67 | CPU
DEBUG 01-07 10:14:07.347076.347076 lmp.py:767]   Expert 38 |     67 | CPU
DEBUG 01-07 10:14:07.347719.347719 lmp.py:767]   Expert 43 |     80 | CPU
DEBUG 01-07 10:14:07.347408.347408 lmp.py:767]   Expert 41 |     82 | CPU
DEBUG 01-07 10:14:07.347621.347621 lmp.py:767]   Expert 33 |     95 | CPU
DEBUG 01-07 10:14:07.347310.347310 lmp.py:767]   Expert 57 |     97 | CPU
DEBUG 01-07 10:14:07.347999.347999 lmp.py:767]   Expert 50 |    104 | CPU
DEBUG 01-07 10:14:07.347212.347212 lmp.py:767]   Expert 11 |    108 | CPU
DEBUG 01-07 10:14:07.347186.347186 lmp.py:767]   Expert 51 |    114 | CPU
DEBUG 01-07 10:14:07.347398.347398 lmp.py:767]   Expert  2 |    117 | CPU
DEBUG 01-07 10:14:07.347611.347611 lmp.py:767]   Expert  0 |    120 | CPU
DEBUG 01-07 10:14:07.347346.347346 lmp.py:767]   Expert 14 |    124 | CPU
DEBUG 01-07 10:14:07.347320.347320 lmp.py:767]   Expert 56 |    131 | CPU
DEBUG 01-07 10:14:07.348817.348817 lmp.py:767]   Expert 26 |    139 | CPU
DEBUG 01-07 10:14:07.348984.348984 lmp.py:767]   Expert 34 |    140 | GPU0(cuda:1)
DEBUG 01-07 10:14:07.348296.348296 lmp.py:767]   Expert 54 |    140 | GPU0(cuda:1)
DEBUG 01-07 10:14:07.348892.348892 lmp.py:767]   Expert 27 |    153 | GPU1(cuda:2)
DEBUG 01-07 10:14:07.348774.348774 lmp.py:767]   Expert 28 |    155 | GPU1(cuda:2)
DEBUG 01-07 10:14:07.348417.348417 lmp.py:767]   Expert 55 |    161 | GPU0(cuda:1)
DEBUG 01-07 10:14:07.348583.348583 lmp.py:767]   Expert 10 |    165 | GPU0(cuda:1)
DEBUG 01-07 10:14:07.348272.348272 lmp.py:767]   Expert 25 |    167 | GPU1(cuda:2)
DEBUG 01-07 10:14:07.348200.348200 lmp.py:767]   Expert  9 |    178 | GPU1(cuda:2)
DEBUG 01-07 10:14:07.348651.348651 lmp.py:767]   Expert 13 |    178 | GPU0(cuda:1)
DEBUG 01-07 10:14:07.348101.348101 lmp.py:767]   Expert 61 |    183 | GPU1(cuda:2)
DEBUG 01-07 10:14:07.348029.348029 lmp.py:767]   Expert  6 |    189 | GPU0(cuda:1)
DEBUG 01-07 10:14:07.348957.348957 lmp.py:767]   Expert 48 |    189 | GPU0(cuda:1)
DEBUG 01-07 10:14:07.348885.348885 lmp.py:767]   Expert 24 |    196 | GPU1(cuda:2)
DEBUG 01-07 10:14:07.348812.348812 lmp.py:767]   Expert  7 |    197 | GPU0(cuda:1)
DEBUG 01-07 10:14:07.348455.348455 lmp.py:767]   Expert 42 |    198 | GPU1(cuda:2)
DEBUG 01-07 10:14:07.348860.348860 lmp.py:767]   Expert 46 |    199 | GPU1(cuda:2)
DEBUG 01-07 10:14:07.348503.348503 lmp.py:767]   Expert 18 |    203 | GPU0(cuda:1)
DEBUG 01-07 10:14:07.348146.348146 lmp.py:767]   Expert 40 |    213 | GPU0(cuda:1)
DEBUG 01-07 10:14:07.348312.348312 lmp.py:767]   Expert 22 |    214 | GPU1(cuda:2)
DEBUG 01-07 10:14:07.348001.348001 lmp.py:767]   Expert 59 |    215 | GPU0(cuda:1)
DEBUG 01-07 10:14:07.348929.348929 lmp.py:767]   Expert 63 |    217 | GPU1(cuda:2)
DEBUG 01-07 10:14:07.348817.348817 lmp.py:767]   Expert 12 |    218 | GPU1(cuda:2)
DEBUG 01-07 10:14:07.348460.348460 lmp.py:767]   Expert 29 |    218 | GPU0(cuda:1)
DEBUG 01-07 10:14:07.348149.348149 lmp.py:767]   Expert 21 |    220 | GPU1(cuda:2)
DEBUG 01-07 10:14:07.348077.348077 lmp.py:767]   Expert 19 |    225 | GPU0(cuda:1)
DEBUG 01-07 10:14:07.348005.348005 lmp.py:767]   Expert 32 |    227 | GPU0(cuda:1)
DEBUG 01-07 10:14:07.348886.348886 lmp.py:767]   Expert  3 |    237 | GPU1(cuda:2)
DEBUG 01-07 10:14:07.348291.348291 lmp.py:767]   Expert 36 |    241 | GPU0(cuda:1)
DEBUG 01-07 10:14:07.348695.348695 lmp.py:767]   Expert  1 |    248 | GPU1(cuda:2)
DEBUG 01-07 10:14:07.348100.348100 lmp.py:767]   Expert 37 |    250 | GPU0(cuda:1)
DEBUG 01-07 10:14:07.348266.348266 lmp.py:767]   Expert 16 |    254 | GPU1(cuda:2)
DEBUG 01-07 10:14:07.348955.348955 lmp.py:767]   Expert  5 |    263 | GPU0(cuda:1)
DEBUG 01-07 10:14:07.348406.348406 lmp.py:767]   Expert  8 |    265 | GPU0(cuda:1)
DEBUG 01-07 10:14:07.348334.348334 lmp.py:767]   Expert 20 |    265 | GPU1(cuda:2)
DEBUG 01-07 10:14:07.348546.348546 lmp.py:767]   Expert 30 |    268 | GPU1(cuda:2)
DEBUG 01-07 10:14:07.348236.348236 lmp.py:767]   Expert 15 |    270 | GPU0(cuda:1)
DEBUG 01-07 10:14:07.348925.348925 lmp.py:767]   Expert 62 |    273 | GPU1(cuda:2)
DEBUG 01-07 10:14:07.348806.348806 lmp.py:767]   Expert 35 |    296 | GPU0(cuda:1)
DEBUG 01-07 10:14:07.348403.348403 lmp.py:767]   Expert 39 |    301 | GPU1(cuda:2)
DEBUG 01-07 10:14:07.348761.348761 lmp.py:767]   Expert 17 |    304 | GPU0(cuda:1)
DEBUG 01-07 10:14:07.348881.348881 lmp.py:767]   Expert 60 |    309 | GPU1(cuda:2)
DEBUG 01-07 10:14:07.348239.348239 lmp.py:767]   Expert 52 |    355 | GPU0(cuda:1)
DEBUG 01-07 10:14:07.348121.348121 lmp.py:767]   Expert 23 |    376 | GPU1(cuda:2)
DEBUG 01-07 10:14:07.348764.348764 lmp.py:767]   Expert 44 |    381 | GPU1(cuda:2)
DEBUG 01-07 10:14:07.348645.348645 lmp.py:767]   Expert 53 |    439 | GPU0(cuda:1)
DEBUG 01-07 10:14:07.348096.348096 lmp.py:769] 
DEBUG 01-07 10:14:07.348096.348096 lmp.py:769]   Device Token Distribution:
DEBUG 01-07 10:14:07.348739.348739 lmp.py:770]   CPU:   1735 tokens
DEBUG 01-07 10:14:07.348336.348336 lmp.py:774]   cuda:1:   5343 tokens (23 experts)
DEBUG 01-07 10:14:07.348740.348740 lmp.py:774]   cuda:2:   5210 tokens (22 experts)
DEBUG 01-07 10:14:07.348860.348860 lmp.py:775]   Total GPU:  10553 tokens
DEBUG 01-07 10:14:07.348741.348741 lmp.py:776] ============================================================
DEBUG 01-07 10:14:07.348741.348741 lmp.py:776] 
DEBUG 01-07 10:14:07.348106.348106 cuda_h.py:19] end experts_map_get cost 0.001735687255859375 seconds
DEBUG 01-07 10:14:07.348703.348703 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model_multi_device
DEBUG 01-07 10:14:07.348003.348003 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 10:14:07.349860.349860 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 10:14:07.349554.349554 cuda_h.py:19] end allocate_cuda_memory cost 0.0003027915954589844 seconds
DEBUG 01-07 10:14:07.349841.349841 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 10:14:07.349835.349835 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 10:14:07.349644.349644 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 10:14:07.349009.349009 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 88b56971-e224-487b-b5b6-0ae74dda6a23
DEBUG 01-07 10:14:07.349127.349127 client.py:106] call stub.LoadModelAsync
INFO 01-07 10:14:07.349801.349801 client.py:127] Model loaded
DEBUG 01-07 10:14:07.350148.350148 cuda_h.py:19] end sllm_worker_task cost 0.008941888809204102 seconds
INFO 01-07 10:14:07.350421.350421 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 88b56971-e224-487b-b5b6-0ae74dda6a23
DEBUG 01-07 10:14:07.350344.350344 cuda_h.py:19] end load_into_gpu_async cost 0.0013532638549804688 seconds
DEBUG 01-07 10:14:07.350930.350930 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 10:14:07.351412.351412 cuda_h.py:19] end restore_tensors2 cost 0.0003185272216796875 seconds
DEBUG 01-07 10:14:07.351917.351917 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.002371072769165039 seconds
DEBUG 01-07 10:14:07.354478.354478 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 10:14:07.354986.354986 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 10:14:07.354440.354440 cuda_h.py:19] end allocate_cuda_memory cost 0.00024890899658203125 seconds
DEBUG 01-07 10:14:07.354588.354588 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 10:14:07.354020.354020 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 10:14:07.354982.354982 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 10:14:07.354023.354023 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 269c062a-f3cf-4aff-aa20-538a2fbf0ffa
DEBUG 01-07 10:14:07.354075.354075 client.py:106] call stub.LoadModelAsync
INFO 01-07 10:14:07.355513.355513 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 269c062a-f3cf-4aff-aa20-538a2fbf0ffa
DEBUG 01-07 10:14:07.355025.355025 cuda_h.py:19] end load_into_gpu_async cost 0.0011246204376220703 seconds
DEBUG 01-07 10:14:07.355258.355258 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 10:14:07.356690.356690 cuda_h.py:19] end restore_tensors2 cost 0.00041294097900390625 seconds
DEBUG 01-07 10:14:07.356006.356006 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0022330284118652344 seconds
DEBUG 01-07 10:14:07.358832.358832 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model_multi_device cost 0.009960651397705078 seconds
DEBUG 01-07 10:14:07.359259.359259 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-07 10:14:07.359540.359540 lmp.py:816] 
DEBUG 01-07 10:14:07.359540.359540 lmp.py:816]   Computing 19 experts on CPU...
DEBUG 01-07 10:14:07.359496.359496 cuda_h.py:19] end cpu_experts_submit cost 0.0001385211944580078 seconds
DEBUG 01-07 10:14:07.359206.359206 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-07 10:14:07.366277.366277 mlpmodule.py:749] group tensors cost 0.007084846496582031 s
DEBUG 01-07 10:14:07.369547.369547 mlpmodule.py:787] pad cost 0.0017123222351074219 s
DEBUG 01-07 10:14:07.369744.369744 mlpmodule.py:793] create cpu tensor cost 5.91278076171875e-05 s
DEBUG 01-07 10:14:07.369410.369410 mlpmodule.py:798] move to cpu cost 4.506111145019531e-05 s
DEBUG 01-07 10:14:07.381425.381425 mlpmodule.py:812] group_w3: shape=torch.Size([19, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=54788096
DEBUG 01-07 10:14:07.381424.381424 mlpmodule.py:813] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-07 10:14:07.382328.382328 mlpmodule.py:818] group_w3 first element: -0.02490234375
WARNING 01-07 10:14:07.382074.382074 mlpmodule.py:828] start einsum2
DEBUG 01-07 10:14:07.396080.396080 mlpmodule.py:838] group einsum cost 0.027433156967163086 s
DEBUG 01-07 10:14:07.397440.397440 mlpmodule.py:846] cpy2cputensor cost 0.00044155120849609375 s
DEBUG 01-07 10:14:07.400334.400334 cuda_h.py:19] end wait_cetm_experts cost 0.04076385498046875 seconds
DEBUG 01-07 10:14:07.400119.400119 cuda_h.py:10] start gpu_sexperts
DEBUG 01-07 10:14:07.400198.400198 cuda_h.py:19] end gpu_sexperts cost 0.0005376338958740234 seconds
DEBUG 01-07 10:14:07.400863.400863 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-07 10:14:07.400712.400712 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.4557113647460938e-05 seconds
DEBUG 01-07 10:14:07.400654.400654 cuda_h.py:10] start wait_experts_multi_device
INFO 01-07 10:14:07.400602.400602 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 88b56971-e224-487b-b5b6-0ae74dda6a23
INFO 01-07 10:14:07.402991.402991 client.py:127] Model loaded
INFO 01-07 10:14:07.402926.402926 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 269c062a-f3cf-4aff-aa20-538a2fbf0ffa
INFO 01-07 10:14:07.404014.404014 client.py:127] Model loaded
DEBUG 01-07 10:14:07.404704.404704 cuda_h.py:19] end wait_experts_multi_device cost 0.0036568641662597656 seconds
DEBUG 01-07 10:14:07.404507.404507 cuda_h.py:10] start gpu_experts_multi_device
DEBUG 01-07 10:14:07.404190.404190 lmp.py:867]   Computing 22 experts on cuda:2...
DEBUG 01-07 10:14:07.405190.405190 mlpmodule.py:533] gpu group tensors cost 0.0004763603210449219 s
DEBUG 01-07 10:14:07.407001.407001 mlpmodule.py:566] gpu pad cost 0.0012364387512207031 s
DEBUG 01-07 10:14:07.407433.407433 mlpmodule.py:584] gpu group einsum cost 0.0005562305450439453 s
DEBUG 01-07 10:14:07.408199.408199 mlpmodule.py:707]  experts func einsum cost 0.04950428009033203 s
DEBUG 01-07 10:14:07.409000.409000 mlpmodule.py:656] gpu experts func einsum cost 0.004511833190917969 s
DEBUG 01-07 10:14:07.410898.410898 lmp.py:867]   Computing 23 experts on cuda:1...
DEBUG 01-07 10:14:07.410831.410831 mlpmodule.py:533] gpu group tensors cost 0.00046753883361816406 s
DEBUG 01-07 10:14:07.412020.412020 mlpmodule.py:566] gpu pad cost 0.0012421607971191406 s
DEBUG 01-07 10:14:07.412826.412826 mlpmodule.py:584] gpu group einsum cost 0.0004563331604003906 s
DEBUG 01-07 10:14:07.414281.414281 mlpmodule.py:656] gpu experts func einsum cost 0.004031181335449219 s
DEBUG 01-07 10:14:07.414324.414324 cuda_h.py:19] end gpu_experts_multi_device cost 0.009949445724487305 seconds
DEBUG 01-07 10:14:07.414970.414970 cuda_h.py:19] end layer_moe_generate_multi_device_16 cost 0.0682225227355957 seconds
DEBUG 01-07 10:14:07.414633.414633 lmp.py:194] -------------------------------- end prefill layer 16 --------------------------------
DEBUG 01-07 10:14:07.414158.414158 lmp.py:153] -------------------------------- start prefill layer 17 --------------------------------
DEBUG 01-07 10:14:07.414377.414377 cuda_h.py:10] start start_load_qkvogn_s_weight_l_18
DEBUG 01-07 10:14:07.414749.414749 cuda_h.py:10] start start_load_qkvogn_s_weight_l_18
DEBUG 01-07 10:14:07.415201.415201 cuda_h.py:19] end start_load_qkvogn_s_weight_l_18 cost 2.7894973754882812e-05 seconds
DEBUG 01-07 10:14:07.415639.415639 cuda_h.py:19] end start_load_qkvogn_s_weight_l_18 cost 7.390975952148438e-05 seconds
DEBUG 01-07 10:14:07.415236.415236 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-07 10:14:07.415920.415920 cuda_h.py:10] start sllm_worker_task
DEBUG 01-07 10:14:07.415823.415823 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 10:14:07.415990.415990 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 10:14:07.415704.415704 cuda_h.py:19] end allocate_cuda_memory cost 0.0003161430358886719 seconds
DEBUG 01-07 10:14:07.415389.415389 mlpmodule.py:367] cuda:1 cuda:1
DEBUG 01-07 10:14:07.415318.415318 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 10:14:07.415778.415778 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 10:14:07.415508.415508 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 10:14:07.415303.415303 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, f58123c2-d252-4798-b1c6-c4c6c8eb144f
DEBUG 01-07 10:14:07.415405.415405 client.py:106] call stub.LoadModelAsync
DEBUG 01-07 10:14:07.416302.416302 cuda_h.py:10] start self_attn
INFO 01-07 10:14:07.416079.416079 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, f58123c2-d252-4798-b1c6-c4c6c8eb144f
DEBUG 01-07 10:14:07.416816.416816 cuda_h.py:19] end load_into_gpu_async cost 0.0009419918060302734 seconds
DEBUG 01-07 10:14:07.416850.416850 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 10:14:07.416595.416595 cuda_h.py:19] end restore_tensors2 cost 6.67572021484375e-05 seconds
DEBUG 01-07 10:14:07.416967.416967 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.001687765121459961 seconds
INFO 01-07 10:14:07.416935.416935 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, f58123c2-d252-4798-b1c6-c4c6c8eb144f
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-07 10:14:07.419055.419055 cuda_h.py:19] end self_attn cost 0.0036559104919433594 seconds
DEBUG 01-07 10:14:07.420476.420476 cuda_h.py:19] end iln_self_attn_paln cost 0.0051691532135009766 seconds
DEBUG 01-07 10:14:07.420637.420637 cuda_h.py:10] start layer_moe_generate_multi_device_17
DEBUG 01-07 10:14:07.420585.420585 cuda_h.py:10] start gate
DEBUG 01-07 10:14:07.421476.421476 cuda_h.py:19] end gate cost 0.0006489753723144531 seconds
DEBUG 01-07 10:14:07.421067.421067 cuda_h.py:10] start experts_map_get
DEBUG 01-07 10:14:07.421564.421564 lmp.py:744] 
DEBUG 01-07 10:14:07.421564.421564 lmp.py:744] Expert Token Distribution & Multi-Device Allocation:
DEBUG 01-07 10:14:07.421134.421134 lmp.py:745]   Total experts: 64
DEBUG 01-07 10:14:07.421692.421692 lmp.py:746]   CPU experts: 19 (30%)
DEBUG 01-07 10:14:07.421434.421434 lmp.py:747]   GPU experts: 45 (70%)
DEBUG 01-07 10:14:07.421792.421792 lmp.py:748]   Number of GPU devices: 2
DEBUG 01-07 10:14:07.421197.421197 lmp.py:749] 
DEBUG 01-07 10:14:07.421197.421197 lmp.py:749]   Expert ID | Tokens | Device
DEBUG 01-07 10:14:07.421601.421601 lmp.py:750]   -----------------------------------
DEBUG 01-07 10:14:07.421397.421397 lmp.py:767]   Expert  4 |      9 | CPU
DEBUG 01-07 10:14:07.421278.421278 lmp.py:767]   Expert 28 |     27 | CPU
DEBUG 01-07 10:14:07.421683.421683 lmp.py:767]   Expert  7 |     43 | CPU
DEBUG 01-07 10:14:07.421849.421849 lmp.py:767]   Expert 53 |     55 | CPU
DEBUG 01-07 10:14:07.421777.421777 lmp.py:767]   Expert 52 |     66 | CPU
DEBUG 01-07 10:14:07.421466.421466 lmp.py:767]   Expert 43 |     76 | CPU
DEBUG 01-07 10:14:07.421632.421632 lmp.py:767]   Expert 49 |     81 | CPU
DEBUG 01-07 10:14:07.421037.421037 lmp.py:767]   Expert 12 |     89 | CPU
DEBUG 01-07 10:14:07.421203.421203 lmp.py:767]   Expert 47 |    100 | CPU
DEBUG 01-07 10:14:07.421130.421130 lmp.py:767]   Expert 24 |    102 | CPU
DEBUG 01-07 10:14:07.421058.421058 lmp.py:767]   Expert 33 |    107 | CPU
DEBUG 01-07 10:14:07.421986.421986 lmp.py:767]   Expert 50 |    111 | CPU
DEBUG 01-07 10:14:07.421675.421675 lmp.py:767]   Expert 15 |    112 | CPU
DEBUG 01-07 10:14:07.421603.421603 lmp.py:767]   Expert 39 |    113 | CPU
DEBUG 01-07 10:14:07.421815.421815 lmp.py:767]   Expert  2 |    114 | CPU
DEBUG 01-07 10:14:07.421505.421505 lmp.py:767]   Expert 60 |    117 | CPU
DEBUG 01-07 10:14:07.421148.421148 lmp.py:767]   Expert 25 |    124 | CPU
DEBUG 01-07 10:14:07.421314.421314 lmp.py:767]   Expert 36 |    124 | CPU
DEBUG 01-07 10:14:07.421242.421242 lmp.py:767]   Expert  6 |    128 | CPU
DEBUG 01-07 10:14:07.422361.422361 lmp.py:767]   Expert 61 |    137 | GPU0(cuda:1)
DEBUG 01-07 10:14:07.422243.422243 lmp.py:767]   Expert 59 |    139 | GPU1(cuda:2)
DEBUG 01-07 10:14:07.422363.422363 lmp.py:767]   Expert  3 |    143 | GPU0(cuda:1)
DEBUG 01-07 10:14:07.422006.422006 lmp.py:767]   Expert 27 |    147 | GPU0(cuda:1)
DEBUG 01-07 10:14:07.422125.422125 lmp.py:767]   Expert 58 |    147 | GPU1(cuda:2)
DEBUG 01-07 10:14:07.422007.422007 lmp.py:767]   Expert  8 |    152 | GPU0(cuda:1)
DEBUG 01-07 10:14:07.422888.422888 lmp.py:767]   Expert 31 |    152 | GPU1(cuda:2)
DEBUG 01-07 10:14:07.422723.422723 lmp.py:767]   Expert 30 |    154 | GPU0(cuda:1)
DEBUG 01-07 10:14:07.422843.422843 lmp.py:767]   Expert 40 |    154 | GPU1(cuda:2)
DEBUG 01-07 10:14:07.422724.422724 lmp.py:767]   Expert 10 |    158 | GPU1(cuda:2)
DEBUG 01-07 10:14:07.422367.422367 lmp.py:767]   Expert 37 |    160 | GPU0(cuda:1)
DEBUG 01-07 10:14:07.422010.422010 lmp.py:767]   Expert 38 |    160 | GPU1(cuda:2)
DEBUG 01-07 10:14:07.422892.422892 lmp.py:767]   Expert 41 |    160 | GPU0(cuda:1)
DEBUG 01-07 10:14:07.422773.422773 lmp.py:767]   Expert 57 |    161 | GPU1(cuda:2)
DEBUG 01-07 10:14:07.422655.422655 lmp.py:767]   Expert 14 |    162 | GPU0(cuda:1)
DEBUG 01-07 10:14:07.422536.422536 lmp.py:767]   Expert 46 |    163 | GPU1(cuda:2)
DEBUG 01-07 10:14:07.422656.422656 lmp.py:767]   Expert 32 |    164 | GPU0(cuda:1)
DEBUG 01-07 10:14:07.422537.422537 lmp.py:767]   Expert 54 |    171 | GPU1(cuda:2)
DEBUG 01-07 10:14:07.422419.422419 lmp.py:767]   Expert 19 |    173 | GPU1(cuda:2)
DEBUG 01-07 10:14:07.422061.422061 lmp.py:767]   Expert 42 |    173 | GPU0(cuda:1)
DEBUG 01-07 10:14:07.422181.422181 lmp.py:767]   Expert 11 |    182 | GPU0(cuda:1)
DEBUG 01-07 10:14:07.422063.422063 lmp.py:767]   Expert 34 |    188 | GPU1(cuda:2)
DEBUG 01-07 10:14:07.422944.422944 lmp.py:767]   Expert 18 |    193 | GPU0(cuda:1)
DEBUG 01-07 10:14:07.422064.422064 lmp.py:767]   Expert  0 |    194 | GPU1(cuda:2)
DEBUG 01-07 10:14:07.422184.422184 lmp.py:767]   Expert 26 |    195 | GPU0(cuda:1)
DEBUG 01-07 10:14:07.422827.422827 lmp.py:767]   Expert 22 |    197 | GPU0(cuda:1)
DEBUG 01-07 10:14:07.422423.422423 lmp.py:767]   Expert 56 |    197 | GPU1(cuda:2)
DEBUG 01-07 10:14:07.422020.422020 lmp.py:767]   Expert 44 |    204 | GPU1(cuda:2)
DEBUG 01-07 10:14:07.422901.422901 lmp.py:767]   Expert  1 |    205 | GPU0(cuda:1)
DEBUG 01-07 10:14:07.422783.422783 lmp.py:767]   Expert 51 |    206 | GPU1(cuda:2)
DEBUG 01-07 10:14:07.422426.422426 lmp.py:767]   Expert 20 |    228 | GPU0(cuda:1)
DEBUG 01-07 10:14:07.422307.422307 lmp.py:767]   Expert 29 |    231 | GPU1(cuda:2)
DEBUG 01-07 10:14:07.422950.422950 lmp.py:767]   Expert 45 |    233 | GPU0(cuda:1)
DEBUG 01-07 10:14:07.422832.422832 lmp.py:767]   Expert 48 |    236 | GPU1(cuda:2)
DEBUG 01-07 10:14:07.422474.422474 lmp.py:767]   Expert 35 |    250 | GPU1(cuda:2)
DEBUG 01-07 10:14:07.422117.422117 lmp.py:767]   Expert 55 |    250 | GPU0(cuda:1)
DEBUG 01-07 10:14:07.422237.422237 lmp.py:767]   Expert 16 |    251 | GPU0(cuda:1)
DEBUG 01-07 10:14:07.422311.422311 lmp.py:767]   Expert 21 |    253 | GPU1(cuda:2)
DEBUG 01-07 10:14:07.422431.422431 lmp.py:767]   Expert  5 |    294 | GPU0(cuda:1)
DEBUG 01-07 10:14:07.422074.422074 lmp.py:767]   Expert 23 |    368 | GPU1(cuda:2)
DEBUG 01-07 10:14:07.422717.422717 lmp.py:767]   Expert 13 |    387 | GPU0(cuda:1)
DEBUG 01-07 10:14:07.422836.422836 lmp.py:767]   Expert 17 |    437 | GPU1(cuda:2)
DEBUG 01-07 10:14:07.422479.422479 lmp.py:767]   Expert  9 |    443 | GPU1(cuda:2)
DEBUG 01-07 10:14:07.422599.422599 lmp.py:767]   Expert 63 |    458 | GPU1(cuda:2)
DEBUG 01-07 10:14:07.422242.422242 lmp.py:767]   Expert 62 |   1180 | GPU0(cuda:1)
DEBUG 01-07 10:14:07.422647.422647 lmp.py:769] 
DEBUG 01-07 10:14:07.422647.422647 lmp.py:769]   Device Token Distribution:
DEBUG 01-07 10:14:07.422528.422528 lmp.py:770]   CPU:   1698 tokens
DEBUG 01-07 10:14:07.422886.422886 lmp.py:774]   cuda:1:   5347 tokens (22 experts)
DEBUG 01-07 10:14:07.422529.422529 lmp.py:774]   cuda:2:   5243 tokens (23 experts)
DEBUG 01-07 10:14:07.422934.422934 lmp.py:775]   Total GPU:  10590 tokens
DEBUG 01-07 10:14:07.422623.422623 lmp.py:776] ============================================================
DEBUG 01-07 10:14:07.422623.422623 lmp.py:776] 
DEBUG 01-07 10:14:07.422511.422511 cuda_h.py:19] end experts_map_get cost 0.0017731189727783203 seconds
DEBUG 01-07 10:14:07.422393.422393 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model_multi_device
DEBUG 01-07 10:14:07.422070.422070 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 10:14:07.423272.423272 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 10:14:07.423804.423804 cuda_h.py:19] end allocate_cuda_memory cost 0.00020742416381835938 seconds
DEBUG 01-07 10:14:07.423263.423263 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 10:14:07.423588.423588 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 10:14:07.423967.423967 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 10:14:07.423616.423616 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 55931835-1516-474a-bb18-ac0f3ce9ae38
DEBUG 01-07 10:14:07.423727.423727 client.py:106] call stub.LoadModelAsync
INFO 01-07 10:14:07.423123.423123 client.py:127] Model loaded
DEBUG 01-07 10:14:07.424725.424725 cuda_h.py:19] end sllm_worker_task cost 0.008954286575317383 seconds
INFO 01-07 10:14:07.424435.424435 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 55931835-1516-474a-bb18-ac0f3ce9ae38
DEBUG 01-07 10:14:07.424577.424577 cuda_h.py:19] end load_into_gpu_async cost 0.001043081283569336 seconds
DEBUG 01-07 10:14:07.424803.424803 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 10:14:07.424872.424872 cuda_h.py:19] end restore_tensors2 cost 0.0002722740173339844 seconds
DEBUG 01-07 10:14:07.424880.424880 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0018393993377685547 seconds
DEBUG 01-07 10:14:07.426916.426916 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 10:14:07.426854.426854 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 10:14:07.427379.427379 cuda_h.py:19] end allocate_cuda_memory cost 0.0002086162567138672 seconds
DEBUG 01-07 10:14:07.427553.427553 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 10:14:07.427594.427594 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 10:14:07.427734.427734 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 10:14:07.427384.427384 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 15a9ffc0-9101-4904-9a45-796fc39f623d
DEBUG 01-07 10:14:07.427481.427481 client.py:106] call stub.LoadModelAsync
INFO 01-07 10:14:07.428388.428388 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 15a9ffc0-9101-4904-9a45-796fc39f623d
DEBUG 01-07 10:14:07.428025.428025 cuda_h.py:19] end load_into_gpu_async cost 0.0010182857513427734 seconds
DEBUG 01-07 10:14:07.428821.428821 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 10:14:07.428592.428592 cuda_h.py:19] end restore_tensors2 cost 0.0002620220184326172 seconds
DEBUG 01-07 10:14:07.428653.428653 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0017893314361572266 seconds
DEBUG 01-07 10:14:07.430808.430808 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model_multi_device cost 0.007443428039550781 seconds
DEBUG 01-07 10:14:07.430969.430969 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-07 10:14:07.430270.430270 lmp.py:816] 
DEBUG 01-07 10:14:07.430270.430270 lmp.py:816]   Computing 19 experts on CPU...
DEBUG 01-07 10:14:07.430298.430298 cuda_h.py:19] end cpu_experts_submit cost 0.00010848045349121094 seconds
DEBUG 01-07 10:14:07.430948.430948 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-07 10:14:07.441787.441787 mlpmodule.py:749] group tensors cost 0.010713338851928711 s
DEBUG 01-07 10:14:07.443418.443418 mlpmodule.py:787] pad cost 0.0009469985961914062 s
DEBUG 01-07 10:14:07.443017.443017 mlpmodule.py:793] create cpu tensor cost 3.814697265625e-05 s
DEBUG 01-07 10:14:07.443152.443152 mlpmodule.py:798] move to cpu cost 3.0040740966796875e-05 s
DEBUG 01-07 10:14:07.454543.454543 mlpmodule.py:812] group_w3: shape=torch.Size([19, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=54788096
DEBUG 01-07 10:14:07.454072.454072 mlpmodule.py:813] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-07 10:14:07.454507.454507 mlpmodule.py:818] group_w3 first element: 0.00457763671875
WARNING 01-07 10:14:07.454683.454683 mlpmodule.py:828] start einsum2
DEBUG 01-07 10:14:07.470079.470079 mlpmodule.py:838] group einsum cost 0.027608156204223633 s
DEBUG 01-07 10:14:07.471748.471748 mlpmodule.py:846] cpy2cputensor cost 0.0004088878631591797 s
DEBUG 01-07 10:14:07.474229.474229 cuda_h.py:19] end wait_cetm_experts cost 0.043562889099121094 seconds
DEBUG 01-07 10:14:07.474768.474768 cuda_h.py:10] start gpu_sexperts
DEBUG 01-07 10:14:07.474138.474138 cuda_h.py:19] end gpu_sexperts cost 0.000507354736328125 seconds
DEBUG 01-07 10:14:07.474034.474034 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-07 10:14:07.474884.474884 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.47955322265625e-05 seconds
DEBUG 01-07 10:14:07.475779.475779 cuda_h.py:10] start wait_experts_multi_device
INFO 01-07 10:14:07.475965.475965 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 55931835-1516-474a-bb18-ac0f3ce9ae38
INFO 01-07 10:14:07.475465.475465 client.py:127] Model loaded
INFO 01-07 10:14:07.475878.475878 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 15a9ffc0-9101-4904-9a45-796fc39f623d
INFO 01-07 10:14:07.476283.476283 client.py:127] Model loaded
DEBUG 01-07 10:14:07.476927.476927 cuda_h.py:19] end wait_experts_multi_device cost 0.0018339157104492188 seconds
DEBUG 01-07 10:14:07.476014.476014 cuda_h.py:10] start gpu_experts_multi_device
DEBUG 01-07 10:14:07.476837.476837 lmp.py:867]   Computing 23 experts on cuda:2...
DEBUG 01-07 10:14:07.478088.478088 mlpmodule.py:533] gpu group tensors cost 0.0005059242248535156 s
DEBUG 01-07 10:14:07.479716.479716 mlpmodule.py:566] gpu pad cost 0.0012764930725097656 s
DEBUG 01-07 10:14:07.480154.480154 mlpmodule.py:584] gpu group einsum cost 0.0005619525909423828 s
DEBUG 01-07 10:14:07.482966.482966 mlpmodule.py:656] gpu experts func einsum cost 0.004559993743896484 s
DEBUG 01-07 10:14:07.482684.482684 lmp.py:867]   Computing 22 experts on cuda:1...
DEBUG 01-07 10:14:07.483110.483110 mlpmodule.py:707]  experts func einsum cost 0.052397966384887695 s
DEBUG 01-07 10:14:07.483407.483407 mlpmodule.py:533] gpu group tensors cost 0.0005536079406738281 s
DEBUG 01-07 10:14:07.484711.484711 mlpmodule.py:566] gpu pad cost 0.0014841556549072266 s
DEBUG 01-07 10:14:07.485391.485391 mlpmodule.py:584] gpu group einsum cost 0.0008463859558105469 s
DEBUG 01-07 10:14:07.487631.487631 mlpmodule.py:656] gpu experts func einsum cost 0.0048673152923583984 s
DEBUG 01-07 10:14:07.487939.487939 cuda_h.py:19] end gpu_experts_multi_device cost 0.010765552520751953 seconds
DEBUG 01-07 10:14:07.487332.487332 cuda_h.py:19] end layer_moe_generate_multi_device_17 cost 0.06740784645080566 seconds
DEBUG 01-07 10:14:07.488757.488757 lmp.py:194] -------------------------------- end prefill layer 17 --------------------------------
DEBUG 01-07 10:14:07.488249.488249 lmp.py:153] -------------------------------- start prefill layer 18 --------------------------------
DEBUG 01-07 10:14:07.488991.488991 cuda_h.py:10] start start_load_qkvogn_s_weight_l_19
DEBUG 01-07 10:14:07.488079.488079 cuda_h.py:10] start start_load_qkvogn_s_weight_l_19
DEBUG 01-07 10:14:07.488127.488127 cuda_h.py:19] end start_load_qkvogn_s_weight_l_19 cost 4.458427429199219e-05 seconds
DEBUG 01-07 10:14:07.488353.488353 cuda_h.py:19] end start_load_qkvogn_s_weight_l_19 cost 7.557868957519531e-05 seconds
DEBUG 01-07 10:14:07.488712.488712 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-07 10:14:07.488071.488071 mlpmodule.py:367] cuda:1 cuda:1
DEBUG 01-07 10:14:07.488736.488736 cuda_h.py:10] start sllm_worker_task
DEBUG 01-07 10:14:07.488143.488143 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 10:14:07.488025.488025 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 10:14:07.488370.488370 cuda_h.py:19] end allocate_cuda_memory cost 0.00018525123596191406 seconds
DEBUG 01-07 10:14:07.488359.488359 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 10:14:07.488115.488115 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 10:14:07.488222.488222 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 10:14:07.488256.488256 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 632b9d91-e8d4-41e8-9e1d-8f18627fa7f2
DEBUG 01-07 10:14:07.488212.488212 client.py:106] call stub.LoadModelAsync
DEBUG 01-07 10:14:07.489943.489943 cuda_h.py:10] start self_attn
INFO 01-07 10:14:07.489366.489366 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 632b9d91-e8d4-41e8-9e1d-8f18627fa7f2
DEBUG 01-07 10:14:07.489196.489196 cuda_h.py:19] end load_into_gpu_async cost 0.0008313655853271484 seconds
DEBUG 01-07 10:14:07.489515.489515 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 10:14:07.489922.489922 cuda_h.py:19] end restore_tensors2 cost 6.29425048828125e-05 seconds
DEBUG 01-07 10:14:07.489009.489009 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0013074874877929688 seconds
INFO 01-07 10:14:07.489123.489123 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 632b9d91-e8d4-41e8-9e1d-8f18627fa7f2
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-07 10:14:07.492225.492225 cuda_h.py:19] end self_attn cost 0.0036220550537109375 seconds
DEBUG 01-07 10:14:07.493991.493991 cuda_h.py:19] end iln_self_attn_paln cost 0.004952907562255859 seconds
DEBUG 01-07 10:14:07.493913.493913 cuda_h.py:10] start layer_moe_generate_multi_device_18
DEBUG 01-07 10:14:07.493576.493576 cuda_h.py:10] start gate
DEBUG 01-07 10:14:07.493970.493970 cuda_h.py:19] end gate cost 0.0006427764892578125 seconds
DEBUG 01-07 10:14:07.494561.494561 cuda_h.py:10] start experts_map_get
DEBUG 01-07 10:14:07.494581.494581 lmp.py:744] 
DEBUG 01-07 10:14:07.494581.494581 lmp.py:744] Expert Token Distribution & Multi-Device Allocation:
DEBUG 01-07 10:14:07.494960.494960 lmp.py:745]   Total experts: 64
DEBUG 01-07 10:14:07.494278.494278 lmp.py:746]   CPU experts: 19 (30%)
DEBUG 01-07 10:14:07.494544.494544 lmp.py:747]   GPU experts: 45 (70%)
DEBUG 01-07 10:14:07.494664.494664 lmp.py:748]   Number of GPU devices: 2
DEBUG 01-07 10:14:07.494068.494068 lmp.py:749] 
DEBUG 01-07 10:14:07.494068.494068 lmp.py:749]   Expert ID | Tokens | Device
DEBUG 01-07 10:14:07.494427.494427 lmp.py:750]   -----------------------------------
DEBUG 01-07 10:14:07.494745.494745 lmp.py:767]   Expert 32 |     33 | CPU
DEBUG 01-07 10:14:07.494865.494865 lmp.py:767]   Expert  5 |     48 | CPU
DEBUG 01-07 10:14:07.494508.494508 lmp.py:767]   Expert 30 |     55 | CPU
DEBUG 01-07 10:14:07.494436.494436 lmp.py:767]   Expert 46 |     71 | CPU
DEBUG 01-07 10:14:07.494079.494079 lmp.py:767]   Expert  8 |     90 | CPU
DEBUG 01-07 10:14:07.494675.494675 lmp.py:767]   Expert 40 |     92 | CPU
DEBUG 01-07 10:14:07.494795.494795 lmp.py:767]   Expert 12 |    100 | CPU
DEBUG 01-07 10:14:07.494961.494961 lmp.py:767]   Expert 27 |    105 | CPU
DEBUG 01-07 10:14:07.494127.494127 lmp.py:767]   Expert 60 |    110 | CPU
DEBUG 01-07 10:14:07.494294.494294 lmp.py:767]   Expert 58 |    112 | CPU
DEBUG 01-07 10:14:07.494744.494744 lmp.py:767]   Expert  3 |    113 | CPU
DEBUG 01-07 10:14:07.494672.494672 lmp.py:767]   Expert 17 |    113 | CPU
DEBUG 01-07 10:14:07.494361.494361 lmp.py:767]   Expert 28 |    119 | CPU
DEBUG 01-07 10:14:07.494051.494051 lmp.py:767]   Expert 29 |    119 | CPU
DEBUG 01-07 10:14:07.494217.494217 lmp.py:767]   Expert 21 |    123 | CPU
DEBUG 01-07 10:14:07.494906.494906 lmp.py:767]   Expert 35 |    129 | CPU
DEBUG 01-07 10:14:07.494072.494072 lmp.py:767]   Expert 41 |    129 | CPU
DEBUG 01-07 10:14:07.494477.494477 lmp.py:767]   Expert 25 |    131 | CPU
DEBUG 01-07 10:14:07.494358.494358 lmp.py:767]   Expert 19 |    134 | CPU
DEBUG 01-07 10:14:07.494717.494717 lmp.py:767]   Expert 52 |    137 | GPU1(cuda:2)
DEBUG 01-07 10:14:07.494313.494313 lmp.py:767]   Expert 54 |    144 | GPU0(cuda:1)
DEBUG 01-07 10:14:07.494671.494671 lmp.py:767]   Expert  0 |    146 | GPU0(cuda:1)
DEBUG 01-07 10:14:07.494553.494553 lmp.py:767]   Expert  6 |    146 | GPU1(cuda:2)
DEBUG 01-07 10:14:07.494434.494434 lmp.py:767]   Expert 37 |    147 | GPU0(cuda:1)
DEBUG 01-07 10:14:07.495077.495077 lmp.py:767]   Expert 56 |    152 | GPU1(cuda:2)
DEBUG 01-07 10:14:07.495959.495959 lmp.py:767]   Expert 48 |    155 | GPU0(cuda:1)
DEBUG 01-07 10:14:07.495602.495602 lmp.py:767]   Expert 53 |    161 | GPU0(cuda:1)
DEBUG 01-07 10:14:07.495198.495198 lmp.py:767]   Expert 63 |    161 | GPU1(cuda:2)
DEBUG 01-07 10:14:07.495080.495080 lmp.py:767]   Expert 36 |    163 | GPU1(cuda:2)
DEBUG 01-07 10:14:07.495961.495961 lmp.py:767]   Expert 59 |    166 | GPU1(cuda:2)
DEBUG 01-07 10:14:07.495604.495604 lmp.py:767]   Expert  9 |    183 | GPU0(cuda:1)
DEBUG 01-07 10:14:07.495247.495247 lmp.py:767]   Expert  1 |    184 | GPU0(cuda:1)
DEBUG 01-07 10:14:07.495128.495128 lmp.py:767]   Expert 39 |    190 | GPU1(cuda:2)
DEBUG 01-07 10:14:07.495010.495010 lmp.py:767]   Expert 20 |    197 | GPU0(cuda:1)
DEBUG 01-07 10:14:07.495891.495891 lmp.py:767]   Expert 43 |    198 | GPU1(cuda:2)
DEBUG 01-07 10:14:07.495534.495534 lmp.py:767]   Expert 61 |    200 | GPU1(cuda:2)
DEBUG 01-07 10:14:07.495892.495892 lmp.py:767]   Expert 42 |    202 | GPU0(cuda:1)
DEBUG 01-07 10:14:07.495774.495774 lmp.py:767]   Expert 11 |    203 | GPU0(cuda:1)
DEBUG 01-07 10:14:07.495417.495417 lmp.py:767]   Expert  7 |    206 | GPU1(cuda:2)
DEBUG 01-07 10:14:07.495821.495821 lmp.py:767]   Expert 47 |    209 | GPU0(cuda:1)
DEBUG 01-07 10:14:07.495226.495226 lmp.py:767]   Expert 34 |    210 | GPU1(cuda:2)
DEBUG 01-07 10:14:07.495869.495869 lmp.py:767]   Expert 16 |    217 | GPU0(cuda:1)
DEBUG 01-07 10:14:07.495512.495512 lmp.py:767]   Expert 55 |    218 | GPU1(cuda:2)
DEBUG 01-07 10:14:07.495916.495916 lmp.py:767]   Expert 13 |    222 | GPU1(cuda:2)
DEBUG 01-07 10:14:07.495036.495036 lmp.py:767]   Expert 57 |    222 | GPU0(cuda:1)
DEBUG 01-07 10:14:07.495917.495917 lmp.py:767]   Expert 18 |    229 | GPU1(cuda:2)
DEBUG 01-07 10:14:07.495037.495037 lmp.py:767]   Expert 15 |    238 | GPU0(cuda:1)
DEBUG 01-07 10:14:07.495396.495396 lmp.py:767]   Expert  4 |    240 | GPU1(cuda:2)
DEBUG 01-07 10:14:07.495515.495515 lmp.py:767]   Expert 22 |    245 | GPU1(cuda:2)
DEBUG 01-07 10:14:07.495158.495158 lmp.py:767]   Expert 45 |    245 | GPU0(cuda:1)
DEBUG 01-07 10:14:07.495040.495040 lmp.py:767]   Expert 33 |    247 | GPU0(cuda:1)
DEBUG 01-07 10:14:07.495683.495683 lmp.py:767]   Expert 31 |    249 | GPU1(cuda:2)
DEBUG 01-07 10:14:07.495564.495564 lmp.py:767]   Expert 50 |    252 | GPU0(cuda:1)
DEBUG 01-07 10:14:07.495207.495207 lmp.py:767]   Expert 51 |    255 | GPU1(cuda:2)
DEBUG 01-07 10:14:07.495612.495612 lmp.py:767]   Expert 49 |    268 | GPU0(cuda:1)
DEBUG 01-07 10:14:07.495255.495255 lmp.py:767]   Expert 38 |    272 | GPU1(cuda:2)
DEBUG 01-07 10:14:07.495613.495613 lmp.py:767]   Expert 26 |    282 | GPU0(cuda:1)
DEBUG 01-07 10:14:07.495448.495448 lmp.py:767]   Expert 10 |    290 | GPU1(cuda:2)
DEBUG 01-07 10:14:07.495091.495091 lmp.py:767]   Expert 44 |    295 | GPU0(cuda:1)
DEBUG 01-07 10:14:07.495734.495734 lmp.py:767]   Expert  2 |    298 | GPU1(cuda:2)
DEBUG 01-07 10:14:07.495377.495377 lmp.py:767]   Expert 24 |    306 | GPU0(cuda:1)
DEBUG 01-07 10:14:07.495781.495781 lmp.py:767]   Expert 14 |    314 | GPU1(cuda:2)
DEBUG 01-07 10:14:07.495424.495424 lmp.py:767]   Expert 23 |    417 | GPU1(cuda:2)
DEBUG 01-07 10:14:07.495829.495829 lmp.py:767]   Expert 62 |    681 | GPU0(cuda:1)
DEBUG 01-07 10:14:07.495518.495518 lmp.py:769] 
DEBUG 01-07 10:14:07.495518.495518 lmp.py:769]   Device Token Distribution:
DEBUG 01-07 10:14:07.495400.495400 lmp.py:770]   CPU:   1926 tokens
DEBUG 01-07 10:14:07.495758.495758 lmp.py:774]   cuda:1:   5184 tokens (22 experts)
DEBUG 01-07 10:14:07.495162.495162 lmp.py:774]   cuda:2:   5178 tokens (23 experts)
DEBUG 01-07 10:14:07.495852.495852 lmp.py:775]   Total GPU:  10362 tokens
DEBUG 01-07 10:14:07.495303.495303 lmp.py:776] ============================================================
DEBUG 01-07 10:14:07.495303.495303 lmp.py:776] 
DEBUG 01-07 10:14:07.495191.495191 cuda_h.py:19] end experts_map_get cost 0.00177001953125 seconds
DEBUG 01-07 10:14:07.495834.495834 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model_multi_device
DEBUG 01-07 10:14:07.495464.495464 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 10:14:07.495991.495991 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 10:14:07.496654.496654 cuda_h.py:19] end allocate_cuda_memory cost 0.0001747608184814453 seconds
DEBUG 01-07 10:14:07.496689.496689 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 10:14:07.496537.496537 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 10:14:07.496631.496631 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 10:14:07.496520.496520 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 472ebeb3-c3cc-4c4a-8eee-b86d74aef79f
DEBUG 01-07 10:14:07.496598.496598 client.py:106] call stub.LoadModelAsync
INFO 01-07 10:14:07.496732.496732 client.py:127] Model loaded
DEBUG 01-07 10:14:07.497006.497006 cuda_h.py:19] end sllm_worker_task cost 0.008573293685913086 seconds
INFO 01-07 10:14:07.497795.497795 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 472ebeb3-c3cc-4c4a-8eee-b86d74aef79f
DEBUG 01-07 10:14:07.497446.497446 cuda_h.py:19] end load_into_gpu_async cost 0.0010182857513427734 seconds
DEBUG 01-07 10:14:07.497195.497195 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 10:14:07.497721.497721 cuda_h.py:19] end restore_tensors2 cost 0.0002567768096923828 seconds
DEBUG 01-07 10:14:07.497921.497921 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0017535686492919922 seconds
DEBUG 01-07 10:14:07.499439.499439 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 10:14:07.499516.499516 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 10:14:07.499180.499180 cuda_h.py:19] end allocate_cuda_memory cost 0.00020551681518554688 seconds
DEBUG 01-07 10:14:07.499354.499354 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 10:14:07.499488.499488 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 10:14:07.499197.499197 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 10:14:07.499132.499132 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 29bbb80e-3c1b-4a1b-bd80-18d0251645e4
DEBUG 01-07 10:14:07.500991.500991 client.py:106] call stub.LoadModelAsync
INFO 01-07 10:14:07.501033.501033 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 29bbb80e-3c1b-4a1b-bd80-18d0251645e4
DEBUG 01-07 10:14:07.501432.501432 cuda_h.py:19] end load_into_gpu_async cost 0.001116037368774414 seconds
DEBUG 01-07 10:14:07.501513.501513 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 10:14:07.501601.501601 cuda_h.py:19] end restore_tensors2 cost 0.0002522468566894531 seconds
DEBUG 01-07 10:14:07.501040.501040 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0018661022186279297 seconds
DEBUG 01-07 10:14:07.503181.503181 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model_multi_device cost 0.007393836975097656 seconds
DEBUG 01-07 10:14:07.503673.503673 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-07 10:14:07.503351.503351 lmp.py:816] 
DEBUG 01-07 10:14:07.503351.503351 lmp.py:816]   Computing 19 experts on CPU...
DEBUG 01-07 10:14:07.503572.503572 cuda_h.py:19] end cpu_experts_submit cost 0.00010895729064941406 seconds
DEBUG 01-07 10:14:07.503175.503175 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-07 10:14:07.509998.509998 mlpmodule.py:749] group tensors cost 0.00584721565246582 s
DEBUG 01-07 10:14:07.511106.511106 mlpmodule.py:787] pad cost 0.0012233257293701172 s
DEBUG 01-07 10:14:07.511971.511971 mlpmodule.py:793] create cpu tensor cost 3.743171691894531e-05 s
DEBUG 01-07 10:14:07.511628.511628 mlpmodule.py:798] move to cpu cost 2.9325485229492188e-05 s
DEBUG 01-07 10:14:07.523080.523080 mlpmodule.py:812] group_w3: shape=torch.Size([19, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=54788096
DEBUG 01-07 10:14:07.523709.523709 mlpmodule.py:813] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-07 10:14:07.523951.523951 mlpmodule.py:818] group_w3 first element: 0.0264892578125
WARNING 01-07 10:14:07.523558.523558 mlpmodule.py:828] start einsum2
DEBUG 01-07 10:14:07.539336.539336 mlpmodule.py:838] group einsum cost 0.027971982955932617 s
DEBUG 01-07 10:14:07.540828.540828 mlpmodule.py:846] cpy2cputensor cost 0.00043773651123046875 s
DEBUG 01-07 10:14:07.542431.542431 cuda_h.py:19] end wait_cetm_experts cost 0.03943681716918945 seconds
DEBUG 01-07 10:14:07.543486.543486 cuda_h.py:10] start gpu_sexperts
DEBUG 01-07 10:14:07.543194.543194 cuda_h.py:19] end gpu_sexperts cost 0.0005130767822265625 seconds
DEBUG 01-07 10:14:07.543606.543606 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-07 10:14:07.543410.543410 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.5272369384765625e-05 seconds
DEBUG 01-07 10:14:07.543318.543318 cuda_h.py:10] start wait_experts_multi_device
INFO 01-07 10:14:07.543459.543459 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 472ebeb3-c3cc-4c4a-8eee-b86d74aef79f
INFO 01-07 10:14:07.544503.544503 client.py:127] Model loaded
INFO 01-07 10:14:07.544009.544009 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 29bbb80e-3c1b-4a1b-bd80-18d0251645e4
INFO 01-07 10:14:07.549997.549997 client.py:127] Model loaded
DEBUG 01-07 10:14:07.549356.549356 cuda_h.py:19] end wait_experts_multi_device cost 0.005650520324707031 seconds
DEBUG 01-07 10:14:07.549205.549205 cuda_h.py:10] start gpu_experts_multi_device
DEBUG 01-07 10:14:07.549220.549220 lmp.py:867]   Computing 23 experts on cuda:2...
DEBUG 01-07 10:14:07.550484.550484 mlpmodule.py:533] gpu group tensors cost 0.0004949569702148438 s
DEBUG 01-07 10:14:07.551046.551046 mlpmodule.py:707]  experts func einsum cost 0.04824686050415039 s
DEBUG 01-07 10:14:07.552474.552474 mlpmodule.py:566] gpu pad cost 0.0013990402221679688 s
DEBUG 01-07 10:14:07.552840.552840 mlpmodule.py:584] gpu group einsum cost 0.0005617141723632812 s
DEBUG 01-07 10:14:07.554160.554160 mlpmodule.py:656] gpu experts func einsum cost 0.0046460628509521484 s
DEBUG 01-07 10:14:07.555070.555070 lmp.py:867]   Computing 22 experts on cuda:1...
DEBUG 01-07 10:14:07.555025.555025 mlpmodule.py:533] gpu group tensors cost 0.0003750324249267578 s
DEBUG 01-07 10:14:07.556632.556632 mlpmodule.py:566] gpu pad cost 0.0010607242584228516 s
DEBUG 01-07 10:14:07.557446.557446 mlpmodule.py:584] gpu group einsum cost 0.00032830238342285156 s
DEBUG 01-07 10:14:07.558087.558087 mlpmodule.py:656] gpu experts func einsum cost 0.0034058094024658203 s
DEBUG 01-07 10:14:07.558514.558514 cuda_h.py:19] end gpu_experts_multi_device cost 0.009398221969604492 seconds
DEBUG 01-07 10:14:07.558192.558192 cuda_h.py:19] end layer_moe_generate_multi_device_18 cost 0.06566071510314941 seconds
DEBUG 01-07 10:14:07.559187.559187 lmp.py:194] -------------------------------- end prefill layer 18 --------------------------------
DEBUG 01-07 10:14:07.559234.559234 lmp.py:153] -------------------------------- start prefill layer 19 --------------------------------
DEBUG 01-07 10:14:07.559215.559215 cuda_h.py:10] start start_load_qkvogn_s_weight_l_20
DEBUG 01-07 10:14:07.559256.559256 cuda_h.py:10] start start_load_qkvogn_s_weight_l_20
DEBUG 01-07 10:14:07.559993.559993 cuda_h.py:19] end start_load_qkvogn_s_weight_l_20 cost 2.6941299438476562e-05 seconds
DEBUG 01-07 10:14:07.559312.559312 cuda_h.py:19] end start_load_qkvogn_s_weight_l_20 cost 5.507469177246094e-05 seconds
DEBUG 01-07 10:14:07.559193.559193 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-07 10:14:07.559016.559016 cuda_h.py:10] start sllm_worker_task
DEBUG 01-07 10:14:07.559277.559277 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 10:14:07.559537.559537 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 10:14:07.559177.559177 cuda_h.py:19] end allocate_cuda_memory cost 0.00029754638671875 seconds
DEBUG 01-07 10:14:07.559908.559908 mlpmodule.py:367] cuda:1 cuda:1
DEBUG 01-07 10:14:07.560976.560976 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 10:14:07.560721.560721 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 10:14:07.560928.560928 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 10:14:07.560200.560200 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 5adef3ff-6df4-487d-92b8-0d1c0b4e1165
DEBUG 01-07 10:14:07.560918.560918 client.py:106] call stub.LoadModelAsync
DEBUG 01-07 10:14:07.560398.560398 cuda_h.py:10] start self_attn
INFO 01-07 10:14:07.561798.561798 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 5adef3ff-6df4-487d-92b8-0d1c0b4e1165
DEBUG 01-07 10:14:07.561104.561104 cuda_h.py:19] end load_into_gpu_async cost 0.0009508132934570312 seconds
DEBUG 01-07 10:14:07.561423.561423 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 10:14:07.561353.561353 cuda_h.py:19] end restore_tensors2 cost 6.341934204101562e-05 seconds
DEBUG 01-07 10:14:07.561201.561201 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0016684532165527344 seconds
INFO 01-07 10:14:07.561839.561839 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 5adef3ff-6df4-487d-92b8-0d1c0b4e1165
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-07 10:14:07.564595.564595 cuda_h.py:19] end self_attn cost 0.0036666393280029297 seconds
DEBUG 01-07 10:14:07.564785.564785 cuda_h.py:19] end iln_self_attn_paln cost 0.0051839351654052734 seconds
DEBUG 01-07 10:14:07.564376.564376 cuda_h.py:10] start layer_moe_generate_multi_device_19
DEBUG 01-07 10:14:07.564277.564277 cuda_h.py:10] start gate
DEBUG 01-07 10:14:07.565711.565711 cuda_h.py:19] end gate cost 0.0006377696990966797 seconds
DEBUG 01-07 10:14:07.565110.565110 cuda_h.py:10] start experts_map_get
DEBUG 01-07 10:14:07.565361.565361 lmp.py:744] 
DEBUG 01-07 10:14:07.565361.565361 lmp.py:744] Expert Token Distribution & Multi-Device Allocation:
DEBUG 01-07 10:14:07.565277.565277 lmp.py:745]   Total experts: 64
DEBUG 01-07 10:14:07.565834.565834 lmp.py:746]   CPU experts: 19 (30%)
DEBUG 01-07 10:14:07.565384.565384 lmp.py:747]   GPU experts: 45 (70%)
DEBUG 01-07 10:14:07.565789.565789 lmp.py:748]   Number of GPU devices: 2
DEBUG 01-07 10:14:07.565239.565239 lmp.py:749] 
DEBUG 01-07 10:14:07.565239.565239 lmp.py:749]   Expert ID | Tokens | Device
DEBUG 01-07 10:14:07.565167.565167 lmp.py:750]   -----------------------------------
DEBUG 01-07 10:14:07.565486.565486 lmp.py:767]   Expert 44 |     40 | CPU
DEBUG 01-07 10:14:07.565652.565652 lmp.py:767]   Expert  1 |     51 | CPU
DEBUG 01-07 10:14:07.565864.565864 lmp.py:767]   Expert 60 |     59 | CPU
DEBUG 01-07 10:14:07.565077.565077 lmp.py:767]   Expert 28 |     67 | CPU
DEBUG 01-07 10:14:07.566766.566766 lmp.py:767]   Expert 48 |     81 | CPU
DEBUG 01-07 10:14:07.566932.566932 lmp.py:767]   Expert 27 |     82 | CPU
DEBUG 01-07 10:14:07.566575.566575 lmp.py:767]   Expert  0 |    103 | CPU
DEBUG 01-07 10:14:07.566026.566026 lmp.py:767]   Expert 62 |    107 | CPU
DEBUG 01-07 10:14:07.566239.566239 lmp.py:767]   Expert 30 |    112 | CPU
DEBUG 01-07 10:14:07.566451.566451 lmp.py:767]   Expert 42 |    112 | CPU
DEBUG 01-07 10:14:07.566664.566664 lmp.py:767]   Expert 22 |    115 | CPU
DEBUG 01-07 10:14:07.566638.566638 lmp.py:767]   Expert 59 |    117 | CPU
DEBUG 01-07 10:14:07.566850.566850 lmp.py:767]   Expert 58 |    120 | CPU
DEBUG 01-07 10:14:07.566586.566586 lmp.py:767]   Expert 12 |    127 | CPU
DEBUG 01-07 10:14:07.566798.566798 lmp.py:767]   Expert 16 |    127 | CPU
DEBUG 01-07 10:14:07.566726.566726 lmp.py:767]   Expert  8 |    130 | CPU
DEBUG 01-07 10:14:07.566654.566654 lmp.py:767]   Expert 50 |    136 | CPU
DEBUG 01-07 10:14:07.566628.566628 lmp.py:767]   Expert 56 |    140 | CPU
DEBUG 01-07 10:14:07.566840.566840 lmp.py:767]   Expert  5 |    147 | CPU
DEBUG 01-07 10:14:07.566245.566245 lmp.py:767]   Expert 55 |    148 | GPU0(cuda:1)
DEBUG 01-07 10:14:07.566411.566411 lmp.py:767]   Expert 15 |    155 | GPU0(cuda:1)
DEBUG 01-07 10:14:07.566815.566815 lmp.py:767]   Expert 26 |    155 | GPU1(cuda:2)
DEBUG 01-07 10:14:07.566982.566982 lmp.py:767]   Expert 32 |    156 | GPU0(cuda:1)
DEBUG 01-07 10:14:07.566148.566148 lmp.py:767]   Expert 57 |    158 | GPU1(cuda:2)
DEBUG 01-07 10:14:07.566314.566314 lmp.py:767]   Expert 24 |    159 | GPU1(cuda:2)
DEBUG 01-07 10:14:07.566480.566480 lmp.py:767]   Expert 47 |    161 | GPU0(cuda:1)
DEBUG 01-07 10:14:07.566884.566884 lmp.py:767]   Expert  2 |    165 | GPU0(cuda:1)
DEBUG 01-07 10:14:07.566289.566289 lmp.py:767]   Expert 52 |    165 | GPU1(cuda:2)
DEBUG 01-07 10:14:07.566217.566217 lmp.py:767]   Expert 34 |    167 | GPU0(cuda:1)
DEBUG 01-07 10:14:07.566621.566621 lmp.py:767]   Expert 13 |    169 | GPU1(cuda:2)
DEBUG 01-07 10:14:07.566549.566549 lmp.py:767]   Expert 40 |    170 | GPU1(cuda:2)
DEBUG 01-07 10:14:07.566000.566000 lmp.py:767]   Expert  3 |    171 | GPU0(cuda:1)
DEBUG 01-07 10:14:07.566166.566166 lmp.py:767]   Expert 18 |    171 | GPU1(cuda:2)
DEBUG 01-07 10:14:07.566094.566094 lmp.py:767]   Expert 54 |    171 | GPU0(cuda:1)
DEBUG 01-07 10:14:07.566783.566783 lmp.py:767]   Expert 41 |    172 | GPU0(cuda:1)
DEBUG 01-07 10:14:07.566711.566711 lmp.py:767]   Expert  6 |    174 | GPU1(cuda:2)
DEBUG 01-07 10:14:07.566400.566400 lmp.py:767]   Expert 20 |    181 | GPU0(cuda:1)
DEBUG 01-07 10:14:07.566043.566043 lmp.py:767]   Expert 19 |    182 | GPU1(cuda:2)
DEBUG 01-07 10:14:07.566686.566686 lmp.py:767]   Expert 46 |    183 | GPU0(cuda:1)
DEBUG 01-07 10:14:07.566614.566614 lmp.py:767]   Expert 37 |    186 | GPU1(cuda:2)
DEBUG 01-07 10:14:07.566541.566541 lmp.py:767]   Expert 51 |    190 | GPU1(cuda:2)
DEBUG 01-07 10:14:07.566992.566992 lmp.py:767]   Expert 25 |    196 | GPU0(cuda:1)
DEBUG 01-07 10:14:07.566682.566682 lmp.py:767]   Expert 43 |    201 | GPU0(cuda:1)
DEBUG 01-07 10:14:07.566133.566133 lmp.py:767]   Expert 31 |    204 | GPU0(cuda:1)
DEBUG 01-07 10:14:07.566299.566299 lmp.py:767]   Expert 35 |    204 | GPU1(cuda:2)
DEBUG 01-07 10:14:07.566226.566226 lmp.py:767]   Expert 11 |    205 | GPU1(cuda:2)
DEBUG 01-07 10:14:07.566869.566869 lmp.py:767]   Expert 17 |    209 | GPU1(cuda:2)
DEBUG 01-07 10:14:07.566274.566274 lmp.py:767]   Expert 23 |    209 | GPU0(cuda:1)
DEBUG 01-07 10:14:07.566202.566202 lmp.py:767]   Expert 49 |    218 | GPU1(cuda:2)
DEBUG 01-07 10:14:07.566129.566129 lmp.py:767]   Expert 39 |    225 | GPU0(cuda:1)
DEBUG 01-07 10:14:07.566580.566580 lmp.py:767]   Expert 53 |    228 | GPU1(cuda:2)
DEBUG 01-07 10:14:07.566270.566270 lmp.py:767]   Expert 10 |    231 | GPU0(cuda:1)
DEBUG 01-07 10:14:07.566197.566197 lmp.py:767]   Expert 33 |    247 | GPU1(cuda:2)
DEBUG 01-07 10:14:07.566887.566887 lmp.py:767]   Expert 36 |    262 | GPU0(cuda:1)
DEBUG 01-07 10:14:07.566814.566814 lmp.py:767]   Expert 38 |    266 | GPU0(cuda:1)
DEBUG 01-07 10:14:07.566934.566934 lmp.py:767]   Expert  4 |    308 | GPU1(cuda:2)
DEBUG 01-07 10:14:07.566769.566769 lmp.py:767]   Expert 21 |    333 | GPU0(cuda:1)
DEBUG 01-07 10:14:07.566127.566127 lmp.py:767]   Expert 14 |    342 | GPU1(cuda:2)
DEBUG 01-07 10:14:07.566009.566009 lmp.py:767]   Expert 63 |    365 | GPU0(cuda:1)
DEBUG 01-07 10:14:07.566890.566890 lmp.py:767]   Expert 45 |    375 | GPU1(cuda:2)
DEBUG 01-07 10:14:07.566772.566772 lmp.py:767]   Expert  9 |    389 | GPU1(cuda:2)
DEBUG 01-07 10:14:07.566415.566415 lmp.py:767]   Expert 61 |    389 | GPU0(cuda:1)
DEBUG 01-07 10:14:07.567058.567058 lmp.py:767]   Expert 29 |    480 | GPU1(cuda:2)
DEBUG 01-07 10:14:07.567939.567939 lmp.py:767]   Expert  7 |    520 | GPU0(cuda:1)
DEBUG 01-07 10:14:07.567628.567628 lmp.py:769] 
DEBUG 01-07 10:14:07.567628.567628 lmp.py:769]   Device Token Distribution:
DEBUG 01-07 10:14:07.567510.567510 lmp.py:770]   CPU:   1973 tokens
DEBUG 01-07 10:14:07.567583.567583 lmp.py:774]   cuda:1:   5231 tokens (23 experts)
DEBUG 01-07 10:14:07.567703.567703 lmp.py:774]   cuda:2:   5084 tokens (22 experts)
DEBUG 01-07 10:14:07.567869.567869 lmp.py:775]   Total GPU:  10315 tokens
DEBUG 01-07 10:14:07.567320.567320 lmp.py:776] ============================================================
DEBUG 01-07 10:14:07.567320.567320 lmp.py:776] 
DEBUG 01-07 10:14:07.567447.567447 cuda_h.py:19] end experts_map_get cost 0.001729726791381836 seconds
DEBUG 01-07 10:14:07.567805.567805 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model_multi_device
DEBUG 01-07 10:14:07.567912.567912 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 10:14:07.567823.567823 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 10:14:07.567037.567037 cuda_h.py:19] end allocate_cuda_memory cost 0.0002300739288330078 seconds
DEBUG 01-07 10:14:07.567894.567894 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 10:14:07.567173.567173 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 10:14:07.567836.567836 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 10:14:07.567533.567533 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, f4a6aaf7-d00c-488f-aa75-8eec0e2f0398
DEBUG 01-07 10:14:07.567412.567412 client.py:106] call stub.LoadModelAsync
INFO 01-07 10:14:07.568403.568403 client.py:127] Model loaded
DEBUG 01-07 10:14:07.568442.568442 cuda_h.py:19] end sllm_worker_task cost 0.008901834487915039 seconds
INFO 01-07 10:14:07.568606.568606 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, f4a6aaf7-d00c-488f-aa75-8eec0e2f0398
DEBUG 01-07 10:14:07.568634.568634 cuda_h.py:19] end load_into_gpu_async cost 0.0011103153228759766 seconds
DEBUG 01-07 10:14:07.568344.568344 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 10:14:07.569751.569751 cuda_h.py:19] end restore_tensors2 cost 0.00027489662170410156 seconds
DEBUG 01-07 10:14:07.569521.569521 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0019369125366210938 seconds
DEBUG 01-07 10:14:07.571015.571015 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 10:14:07.571801.571801 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 10:14:07.571445.571445 cuda_h.py:19] end allocate_cuda_memory cost 0.00022602081298828125 seconds
DEBUG 01-07 10:14:07.571335.571335 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 10:14:07.571137.571137 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 10:14:07.571085.571085 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 10:14:07.571450.571450 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 562bfba7-d9a4-48f9-81ab-819bac5b9805
DEBUG 01-07 10:14:07.571826.571826 client.py:106] call stub.LoadModelAsync
INFO 01-07 10:14:07.572027.572027 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 562bfba7-d9a4-48f9-81ab-819bac5b9805
DEBUG 01-07 10:14:07.572380.572380 cuda_h.py:19] end load_into_gpu_async cost 0.0009143352508544922 seconds
DEBUG 01-07 10:14:07.572414.572414 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 10:14:07.572105.572105 cuda_h.py:19] end restore_tensors2 cost 0.0002384185791015625 seconds
DEBUG 01-07 10:14:07.572258.572258 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0016741752624511719 seconds
DEBUG 01-07 10:14:07.574842.574842 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model_multi_device cost 0.007409334182739258 seconds
DEBUG 01-07 10:14:07.574333.574333 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-07 10:14:07.574488.574488 lmp.py:816] 
DEBUG 01-07 10:14:07.574488.574488 lmp.py:816]   Computing 19 experts on CPU...
DEBUG 01-07 10:14:07.574040.574040 cuda_h.py:19] end cpu_experts_submit cost 0.0001068115234375 seconds
DEBUG 01-07 10:14:07.574405.574405 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-07 10:14:07.582654.582654 mlpmodule.py:749] group tensors cost 0.0073125362396240234 s
DEBUG 01-07 10:14:07.584525.584525 mlpmodule.py:787] pad cost 0.0011184215545654297 s
DEBUG 01-07 10:14:07.584860.584860 mlpmodule.py:793] create cpu tensor cost 4.482269287109375e-05 s
DEBUG 01-07 10:14:07.584485.584485 mlpmodule.py:798] move to cpu cost 3.361701965332031e-05 s
DEBUG 01-07 10:14:07.597373.597373 mlpmodule.py:812] group_w3: shape=torch.Size([19, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=54788096
DEBUG 01-07 10:14:07.597134.597134 mlpmodule.py:813] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-07 10:14:07.597415.597415 mlpmodule.py:818] group_w3 first element: -0.0034942626953125
WARNING 01-07 10:14:07.597254.597254 mlpmodule.py:828] start einsum2
DEBUG 01-07 10:14:07.616112.616112 mlpmodule.py:838] group einsum cost 0.03191113471984863 s
DEBUG 01-07 10:14:07.616750.616750 mlpmodule.py:846] cpy2cputensor cost 0.0004088878631591797 s
DEBUG 01-07 10:14:07.619909.619909 cuda_h.py:19] end wait_cetm_experts cost 0.044673919677734375 seconds
DEBUG 01-07 10:14:07.619925.619925 cuda_h.py:10] start gpu_sexperts
DEBUG 01-07 10:14:07.620572.620572 cuda_h.py:19] end gpu_sexperts cost 0.0005035400390625 seconds
DEBUG 01-07 10:14:07.620230.620230 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-07 10:14:07.620411.620411 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.5272369384765625e-05 seconds
DEBUG 01-07 10:14:07.620352.620352 cuda_h.py:10] start wait_experts_multi_device
INFO 01-07 10:14:07.620585.620585 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, f4a6aaf7-d00c-488f-aa75-8eec0e2f0398
INFO 01-07 10:14:07.621272.621272 client.py:127] Model loaded
INFO 01-07 10:14:07.621062.621062 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 562bfba7-d9a4-48f9-81ab-819bac5b9805
INFO 01-07 10:14:07.621380.621380 client.py:127] Model loaded
DEBUG 01-07 10:14:07.621925.621925 cuda_h.py:19] end wait_experts_multi_device cost 0.0014450550079345703 seconds
DEBUG 01-07 10:14:07.621774.621774 cuda_h.py:10] start gpu_experts_multi_device
DEBUG 01-07 10:14:07.621312.621312 lmp.py:867]   Computing 22 experts on cuda:2...
DEBUG 01-07 10:14:07.623424.623424 mlpmodule.py:533] gpu group tensors cost 0.00048279762268066406 s
DEBUG 01-07 10:14:07.624659.624659 mlpmodule.py:566] gpu pad cost 0.0012326240539550781 s
DEBUG 01-07 10:14:07.624250.624250 mlpmodule.py:584] gpu group einsum cost 0.0005476474761962891 s
DEBUG 01-07 10:14:07.626157.626157 mlpmodule.py:656] gpu experts func einsum cost 0.0043964385986328125 s
DEBUG 01-07 10:14:07.627352.627352 lmp.py:867]   Computing 23 experts on cuda:1...
DEBUG 01-07 10:14:07.627709.627709 mlpmodule.py:533] gpu group tensors cost 0.00046324729919433594 s
DEBUG 01-07 10:14:07.628141.628141 mlpmodule.py:707]  experts func einsum cost 0.05330085754394531 s
DEBUG 01-07 10:14:07.629379.629379 mlpmodule.py:566] gpu pad cost 0.0013790130615234375 s
DEBUG 01-07 10:14:07.629921.629921 mlpmodule.py:584] gpu group einsum cost 0.00045609474182128906 s
DEBUG 01-07 10:14:07.631041.631041 mlpmodule.py:656] gpu experts func einsum cost 0.0044651031494140625 s
DEBUG 01-07 10:14:07.632793.632793 cuda_h.py:19] end gpu_experts_multi_device cost 0.010238170623779297 seconds
DEBUG 01-07 10:14:07.632339.632339 cuda_h.py:19] end layer_moe_generate_multi_device_19 cost 0.06749844551086426 seconds
DEBUG 01-07 10:14:07.632056.632056 lmp.py:194] -------------------------------- end prefill layer 19 --------------------------------
DEBUG 01-07 10:14:07.632216.632216 lmp.py:153] -------------------------------- start prefill layer 20 --------------------------------
DEBUG 01-07 10:14:07.632912.632912 cuda_h.py:10] start start_load_qkvogn_s_weight_l_21
DEBUG 01-07 10:14:07.632430.632430 cuda_h.py:10] start start_load_qkvogn_s_weight_l_21
DEBUG 01-07 10:14:07.632882.632882 cuda_h.py:19] end start_load_qkvogn_s_weight_l_21 cost 2.574920654296875e-05 seconds
DEBUG 01-07 10:14:07.632539.632539 cuda_h.py:19] end start_load_qkvogn_s_weight_l_21 cost 5.6743621826171875e-05 seconds
DEBUG 01-07 10:14:07.632850.632850 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-07 10:14:07.632879.632879 mlpmodule.py:367] cuda:1 cuda:1
DEBUG 01-07 10:14:07.632782.632782 cuda_h.py:10] start sllm_worker_task
DEBUG 01-07 10:14:07.632745.632745 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 10:14:07.632759.632759 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 10:14:07.633604.633604 cuda_h.py:19] end allocate_cuda_memory cost 0.0002732276916503906 seconds
DEBUG 01-07 10:14:07.633097.633097 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 10:14:07.633906.633906 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 10:14:07.633014.633014 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 10:14:07.633048.633048 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 75e92a92-e18f-478c-b67a-50999617e029
DEBUG 01-07 10:14:07.633480.633480 client.py:106] call stub.LoadModelAsync
DEBUG 01-07 10:14:07.633919.633919 cuda_h.py:10] start self_attn
INFO 01-07 10:14:07.634822.634822 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 75e92a92-e18f-478c-b67a-50999617e029
DEBUG 01-07 10:14:07.634844.634844 cuda_h.py:19] end load_into_gpu_async cost 0.0009024143218994141 seconds
DEBUG 01-07 10:14:07.634401.634401 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 10:14:07.634569.634569 cuda_h.py:19] end restore_tensors2 cost 6.389617919921875e-05 seconds
DEBUG 01-07 10:14:07.634372.634372 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.00148773193359375 seconds
INFO 01-07 10:14:07.634692.634692 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 75e92a92-e18f-478c-b67a-50999617e029
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-07 10:14:07.637494.637494 cuda_h.py:19] end self_attn cost 0.0036618709564208984 seconds
DEBUG 01-07 10:14:07.637392.637392 cuda_h.py:19] end iln_self_attn_paln cost 0.005074739456176758 seconds
DEBUG 01-07 10:14:07.637745.637745 cuda_h.py:10] start layer_moe_generate_multi_device_20
DEBUG 01-07 10:14:07.637170.637170 cuda_h.py:10] start gate
DEBUG 01-07 10:14:07.638802.638802 cuda_h.py:19] end gate cost 0.0006425380706787109 seconds
DEBUG 01-07 10:14:07.638154.638154 cuda_h.py:10] start experts_map_get
DEBUG 01-07 10:14:07.638506.638506 lmp.py:744] 
DEBUG 01-07 10:14:07.638506.638506 lmp.py:744] Expert Token Distribution & Multi-Device Allocation:
DEBUG 01-07 10:14:07.638136.638136 lmp.py:745]   Total experts: 64
DEBUG 01-07 10:14:07.638455.638455 lmp.py:746]   CPU experts: 19 (30%)
DEBUG 01-07 10:14:07.639005.639005 lmp.py:747]   GPU experts: 45 (70%)
DEBUG 01-07 10:14:07.639887.639887 lmp.py:748]   Number of GPU devices: 2
DEBUG 01-07 10:14:07.639861.639861 lmp.py:749] 
DEBUG 01-07 10:14:07.639861.639861 lmp.py:749]   Expert ID | Tokens | Device
DEBUG 01-07 10:14:07.639788.639788 lmp.py:750]   -----------------------------------
DEBUG 01-07 10:14:07.639153.639153 lmp.py:767]   Expert 54 |     26 | CPU
DEBUG 01-07 10:14:07.639319.639319 lmp.py:767]   Expert  3 |     36 | CPU
DEBUG 01-07 10:14:07.639009.639009 lmp.py:767]   Expert  8 |     40 | CPU
DEBUG 01-07 10:14:07.639698.639698 lmp.py:767]   Expert 28 |     45 | CPU
DEBUG 01-07 10:14:07.639911.639911 lmp.py:767]   Expert 43 |     55 | CPU
DEBUG 01-07 10:14:07.639838.639838 lmp.py:767]   Expert 63 |     55 | CPU
DEBUG 01-07 10:14:07.639243.639243 lmp.py:767]   Expert 36 |     68 | CPU
DEBUG 01-07 10:14:07.639694.639694 lmp.py:767]   Expert 38 |     75 | CPU
DEBUG 01-07 10:14:07.639668.639668 lmp.py:767]   Expert  6 |     84 | CPU
DEBUG 01-07 10:14:07.639642.639642 lmp.py:767]   Expert 39 |     89 | CPU
DEBUG 01-07 10:14:07.639616.639616 lmp.py:767]   Expert 57 |    105 | CPU
DEBUG 01-07 10:14:07.639351.639351 lmp.py:767]   Expert 12 |    106 | CPU
DEBUG 01-07 10:14:07.639802.639802 lmp.py:767]   Expert 41 |    107 | CPU
DEBUG 01-07 10:14:07.639538.639538 lmp.py:767]   Expert 52 |    109 | CPU
DEBUG 01-07 10:14:07.639274.639274 lmp.py:767]   Expert 19 |    122 | CPU
DEBUG 01-07 10:14:07.639009.639009 lmp.py:767]   Expert 47 |    123 | CPU
DEBUG 01-07 10:14:07.639222.639222 lmp.py:767]   Expert 13 |    132 | CPU
DEBUG 01-07 10:14:07.639196.639196 lmp.py:767]   Expert 22 |    139 | CPU
DEBUG 01-07 10:14:07.639931.639931 lmp.py:767]   Expert 46 |    146 | CPU
DEBUG 01-07 10:14:07.639336.639336 lmp.py:767]   Expert 50 |    150 | GPU0(cuda:1)
DEBUG 01-07 10:14:07.639740.639740 lmp.py:767]   Expert 40 |    163 | GPU0(cuda:1)
DEBUG 01-07 10:14:07.639622.639622 lmp.py:767]   Expert 55 |    164 | GPU1(cuda:2)
DEBUG 01-07 10:14:07.639550.639550 lmp.py:767]   Expert 20 |    166 | GPU0(cuda:1)
DEBUG 01-07 10:14:07.639954.639954 lmp.py:767]   Expert 37 |    167 | GPU1(cuda:2)
DEBUG 01-07 10:14:07.639882.639882 lmp.py:767]   Expert 24 |    168 | GPU1(cuda:2)
DEBUG 01-07 10:14:07.639810.639810 lmp.py:767]   Expert 21 |    170 | GPU0(cuda:1)
DEBUG 01-07 10:14:07.639737.639737 lmp.py:767]   Expert 53 |    171 | GPU1(cuda:2)
DEBUG 01-07 10:14:07.639427.639427 lmp.py:767]   Expert 49 |    174 | GPU0(cuda:1)
DEBUG 01-07 10:14:07.639593.639593 lmp.py:767]   Expert 23 |    175 | GPU0(cuda:1)
DEBUG 01-07 10:14:07.639759.639759 lmp.py:767]   Expert 42 |    179 | GPU1(cuda:2)
DEBUG 01-07 10:14:07.639210.639210 lmp.py:767]   Expert  2 |    181 | GPU1(cuda:2)
DEBUG 01-07 10:14:07.639137.639137 lmp.py:767]   Expert 61 |    183 | GPU0(cuda:1)
DEBUG 01-07 10:14:07.639065.639065 lmp.py:767]   Expert 33 |    187 | GPU0(cuda:1)
DEBUG 01-07 10:14:07.639947.639947 lmp.py:767]   Expert 18 |    191 | GPU1(cuda:2)
DEBUG 01-07 10:14:07.639828.639828 lmp.py:767]   Expert  7 |    192 | GPU1(cuda:2)
DEBUG 01-07 10:14:07.639756.639756 lmp.py:767]   Expert  0 |    196 | GPU0(cuda:1)
DEBUG 01-07 10:14:07.639683.639683 lmp.py:767]   Expert 32 |    199 | GPU0(cuda:1)
DEBUG 01-07 10:14:07.639611.639611 lmp.py:767]   Expert 16 |    201 | GPU1(cuda:2)
DEBUG 01-07 10:14:07.639777.639777 lmp.py:767]   Expert 30 |    203 | GPU1(cuda:2)
DEBUG 01-07 10:14:07.639705.639705 lmp.py:767]   Expert  5 |    205 | GPU0(cuda:1)
DEBUG 01-07 10:14:07.639633.639633 lmp.py:767]   Expert 34 |    210 | GPU1(cuda:2)
DEBUG 01-07 10:14:07.639322.639322 lmp.py:767]   Expert 14 |    211 | GPU0(cuda:1)
DEBUG 01-07 10:14:07.639965.639965 lmp.py:767]   Expert 31 |    213 | GPU0(cuda:1)
DEBUG 01-07 10:14:07.639085.639085 lmp.py:767]   Expert 60 |    217 | GPU1(cuda:2)
DEBUG 01-07 10:14:07.639251.639251 lmp.py:767]   Expert 59 |    218 | GPU0(cuda:1)
DEBUG 01-07 10:14:07.639179.639179 lmp.py:767]   Expert  9 |    221 | GPU1(cuda:2)
DEBUG 01-07 10:14:07.639106.639106 lmp.py:767]   Expert 62 |    222 | GPU0(cuda:1)
DEBUG 01-07 10:14:07.639557.639557 lmp.py:767]   Expert 17 |    225 | GPU1(cuda:2)
DEBUG 01-07 10:14:07.639485.639485 lmp.py:767]   Expert 29 |    227 | GPU0(cuda:1)
DEBUG 01-07 10:14:07.639413.639413 lmp.py:767]   Expert 10 |    228 | GPU1(cuda:2)
DEBUG 01-07 10:14:07.639340.639340 lmp.py:767]   Expert 15 |    228 | GPU1(cuda:2)
DEBUG 01-07 10:14:07.639030.639030 lmp.py:767]   Expert 58 |    237 | GPU0(cuda:1)
DEBUG 01-07 10:14:07.639196.639196 lmp.py:767]   Expert  4 |    239 | GPU1(cuda:2)
DEBUG 01-07 10:14:07.639839.639839 lmp.py:767]   Expert 26 |    247 | GPU0(cuda:1)
DEBUG 01-07 10:14:07.639482.639482 lmp.py:767]   Expert 51 |    253 | GPU0(cuda:1)
DEBUG 01-07 10:14:07.640171.640171 lmp.py:767]   Expert 11 |    265 | GPU1(cuda:2)
DEBUG 01-07 10:14:07.640529.640529 lmp.py:767]   Expert 44 |    268 | GPU1(cuda:2)
DEBUG 01-07 10:14:07.640411.640411 lmp.py:767]   Expert 56 |    286 | GPU0(cuda:1)
DEBUG 01-07 10:14:07.640054.640054 lmp.py:767]   Expert 27 |    294 | GPU0(cuda:1)
DEBUG 01-07 10:14:07.640458.640458 lmp.py:767]   Expert  1 |    334 | GPU1(cuda:2)
DEBUG 01-07 10:14:07.640101.640101 lmp.py:767]   Expert 45 |    373 | GPU0(cuda:1)
DEBUG 01-07 10:14:07.640459.640459 lmp.py:767]   Expert 25 |    466 | GPU1(cuda:2)
DEBUG 01-07 10:14:07.640579.640579 lmp.py:767]   Expert 35 |    520 | GPU1(cuda:2)
DEBUG 01-07 10:14:07.640699.640699 lmp.py:767]   Expert 48 |    639 | GPU0(cuda:1)
DEBUG 01-07 10:14:07.640388.640388 lmp.py:769] 
DEBUG 01-07 10:14:07.640388.640388 lmp.py:769]   Device Token Distribution:
DEBUG 01-07 10:14:07.640555.640555 lmp.py:770]   CPU:   1662 tokens
DEBUG 01-07 10:14:07.640674.640674 lmp.py:774]   cuda:1:   5388 tokens (23 experts)
DEBUG 01-07 10:14:07.640079.640079 lmp.py:774]   cuda:2:   5238 tokens (22 experts)
DEBUG 01-07 10:14:07.640483.640483 lmp.py:775]   Total GPU:  10626 tokens
DEBUG 01-07 10:14:07.640173.640173 lmp.py:776] ============================================================
DEBUG 01-07 10:14:07.640173.640173 lmp.py:776] 
DEBUG 01-07 10:14:07.640823.640823 cuda_h.py:19] end experts_map_get cost 0.001728057861328125 seconds
DEBUG 01-07 10:14:07.640419.640419 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model_multi_device
DEBUG 01-07 10:14:07.640527.640527 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 10:14:07.640497.640497 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 10:14:07.640269.640269 cuda_h.py:19] end allocate_cuda_memory cost 0.00025153160095214844 seconds
DEBUG 01-07 10:14:07.640165.640165 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 10:14:07.640682.640682 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 10:14:07.640445.640445 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 10:14:07.640572.640572 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, beef391e-cde3-4131-b50d-e53cc56acd21
DEBUG 01-07 10:14:07.641643.641643 client.py:106] call stub.LoadModelAsync
INFO 01-07 10:14:07.641130.641130 client.py:127] Model loaded
DEBUG 01-07 10:14:07.641586.641586 cuda_h.py:19] end sllm_worker_task cost 0.008918046951293945 seconds
INFO 01-07 10:14:07.641377.641377 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, beef391e-cde3-4131-b50d-e53cc56acd21
DEBUG 01-07 10:14:07.641028.641028 cuda_h.py:19] end load_into_gpu_async cost 0.0010254383087158203 seconds
DEBUG 01-07 10:14:07.641062.641062 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 10:14:07.642979.642979 cuda_h.py:19] end restore_tensors2 cost 0.0002658367156982422 seconds
DEBUG 01-07 10:14:07.642702.642702 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0018634796142578125 seconds
DEBUG 01-07 10:14:07.644701.644701 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 10:14:07.644347.644347 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 10:14:07.644170.644170 cuda_h.py:19] end allocate_cuda_memory cost 0.000217437744140625 seconds
DEBUG 01-07 10:14:07.644583.644583 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 10:14:07.644624.644624 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 10:14:07.644764.644764 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 10:14:07.644175.644175 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 0a3726e7-e518-4874-a6ac-fcfdfc87e63f
DEBUG 01-07 10:14:07.644835.644835 client.py:106] call stub.LoadModelAsync
INFO 01-07 10:14:07.645782.645782 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 0a3726e7-e518-4874-a6ac-fcfdfc87e63f
DEBUG 01-07 10:14:07.645518.645518 cuda_h.py:19] end load_into_gpu_async cost 0.001008749008178711 seconds
DEBUG 01-07 10:14:07.645552.645552 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 10:14:07.645422.645422 cuda_h.py:19] end restore_tensors2 cost 0.0002295970916748047 seconds
DEBUG 01-07 10:14:07.645145.645145 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0017499923706054688 seconds
DEBUG 01-07 10:14:07.647874.647874 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model_multi_device cost 0.007436513900756836 seconds
DEBUG 01-07 10:14:07.647512.647512 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-07 10:14:07.647812.647812 lmp.py:816] 
DEBUG 01-07 10:14:07.647812.647812 lmp.py:816]   Computing 19 experts on CPU...
DEBUG 01-07 10:14:07.647841.647841 cuda_h.py:19] end cpu_experts_submit cost 0.00010752677917480469 seconds
DEBUG 01-07 10:14:07.647729.647729 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-07 10:14:07.658355.658355 mlpmodule.py:749] group tensors cost 0.0100555419921875 s
DEBUG 01-07 10:14:07.660925.660925 mlpmodule.py:787] pad cost 0.0012192726135253906 s
DEBUG 01-07 10:14:07.660412.660412 mlpmodule.py:793] create cpu tensor cost 4.839897155761719e-05 s
DEBUG 01-07 10:14:07.660044.660044 mlpmodule.py:798] move to cpu cost 3.5762786865234375e-05 s
DEBUG 01-07 10:14:07.674162.674162 mlpmodule.py:812] group_w3: shape=torch.Size([19, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=54788096
DEBUG 01-07 10:14:07.674215.674215 mlpmodule.py:813] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-07 10:14:07.674311.674311 mlpmodule.py:818] group_w3 first element: 0.0205078125
WARNING 01-07 10:14:07.674487.674487 mlpmodule.py:828] start einsum2
DEBUG 01-07 10:14:07.694679.694679 mlpmodule.py:838] group einsum cost 0.03390932083129883 s
DEBUG 01-07 10:14:07.694136.694136 mlpmodule.py:846] cpy2cputensor cost 0.00040149688720703125 s
DEBUG 01-07 10:14:07.697655.697655 cuda_h.py:19] end wait_cetm_experts cost 0.04954934120178223 seconds
DEBUG 01-07 10:14:07.697307.697307 cuda_h.py:10] start gpu_sexperts
DEBUG 01-07 10:14:07.698954.698954 cuda_h.py:19] end gpu_sexperts cost 0.0005033016204833984 seconds
DEBUG 01-07 10:14:07.698135.698135 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-07 10:14:07.698316.698316 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.4318695068359375e-05 seconds
DEBUG 01-07 10:14:07.698973.698973 cuda_h.py:10] start wait_experts_multi_device
INFO 01-07 10:14:07.698205.698205 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, beef391e-cde3-4131-b50d-e53cc56acd21
INFO 01-07 10:14:07.699560.699560 client.py:127] Model loaded
INFO 01-07 10:14:07.699350.699350 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 0a3726e7-e518-4874-a6ac-fcfdfc87e63f
INFO 01-07 10:14:07.699377.699377 client.py:127] Model loaded
DEBUG 01-07 10:14:07.699683.699683 cuda_h.py:19] end wait_experts_multi_device cost 0.0014061927795410156 seconds
DEBUG 01-07 10:14:07.699055.699055 cuda_h.py:10] start gpu_experts_multi_device
DEBUG 01-07 10:14:07.699401.699401 lmp.py:867]   Computing 22 experts on cuda:2...
DEBUG 01-07 10:14:07.701314.701314 mlpmodule.py:533] gpu group tensors cost 0.0004832744598388672 s
DEBUG 01-07 10:14:07.702622.702622 mlpmodule.py:566] gpu pad cost 0.0012202262878417969 s
DEBUG 01-07 10:14:07.702920.702920 mlpmodule.py:584] gpu group einsum cost 0.0005311965942382812 s
DEBUG 01-07 10:14:07.704769.704769 mlpmodule.py:656] gpu experts func einsum cost 0.004400968551635742 s
DEBUG 01-07 10:14:07.705680.705680 lmp.py:867]   Computing 23 experts on cuda:1...
DEBUG 01-07 10:14:07.706473.706473 mlpmodule.py:533] gpu group tensors cost 0.0004620552062988281 s
DEBUG 01-07 10:14:07.707265.707265 mlpmodule.py:566] gpu pad cost 0.001230478286743164 s
DEBUG 01-07 10:14:07.707970.707970 mlpmodule.py:584] gpu group einsum cost 0.0004200935363769531 s
DEBUG 01-07 10:14:07.709634.709634 mlpmodule.py:656] gpu experts func einsum cost 0.004266977310180664 s
DEBUG 01-07 10:14:07.709193.709193 cuda_h.py:19] end gpu_experts_multi_device cost 0.010046243667602539 seconds
DEBUG 01-07 10:14:07.709448.709448 cuda_h.py:19] end layer_moe_generate_multi_device_20 cost 0.0721886157989502 seconds
DEBUG 01-07 10:14:07.710126.710126 lmp.py:194] -------------------------------- end prefill layer 20 --------------------------------
DEBUG 01-07 10:14:07.710956.710956 lmp.py:153] -------------------------------- start prefill layer 21 --------------------------------
DEBUG 01-07 10:14:07.710175.710175 cuda_h.py:10] start start_load_qkvogn_s_weight_l_22
DEBUG 01-07 10:14:07.710646.710646 cuda_h.py:10] start start_load_qkvogn_s_weight_l_22
DEBUG 01-07 10:14:07.710483.710483 cuda_h.py:19] end start_load_qkvogn_s_weight_l_22 cost 2.7418136596679688e-05 seconds
DEBUG 01-07 10:14:07.710259.710259 cuda_h.py:19] end start_load_qkvogn_s_weight_l_22 cost 7.700920104980469e-05 seconds
DEBUG 01-07 10:14:07.710048.710048 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-07 10:14:07.710507.710507 mlpmodule.py:367] cuda:1 cuda:1
DEBUG 01-07 10:14:07.710641.710641 cuda_h.py:10] start sllm_worker_task
DEBUG 01-07 10:14:07.710067.710067 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 10:14:07.710481.710481 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 10:14:07.713462.713462 cuda_h.py:19] end allocate_cuda_memory cost 0.002346038818359375 seconds
DEBUG 01-07 10:14:07.713280.713280 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 10:14:07.713089.713089 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 10:14:07.713103.713103 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 10:14:07.713760.713760 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 332394cb-dcf9-4977-a978-aae4c64b0ef0
DEBUG 01-07 10:14:07.713107.713107 client.py:106] call stub.LoadModelAsync
DEBUG 01-07 10:14:07.713045.713045 mlpmodule.py:707]  experts func einsum cost 0.06549739837646484 s
DEBUG 01-07 10:14:07.713856.713856 cuda_h.py:10] start self_attn
INFO 01-07 10:14:07.714024.714024 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 332394cb-dcf9-4977-a978-aae4c64b0ef0
DEBUG 01-07 10:14:07.714814.714814 cuda_h.py:19] end load_into_gpu_async cost 0.001096487045288086 seconds
DEBUG 01-07 10:14:07.714086.714086 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 10:14:07.714593.714593 cuda_h.py:19] end restore_tensors2 cost 6.628036499023438e-05 seconds
DEBUG 01-07 10:14:07.714442.714442 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.003786325454711914 seconds
INFO 01-07 10:14:07.714033.714033 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 332394cb-dcf9-4977-a978-aae4c64b0ef0
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-07 10:14:07.717637.717637 cuda_h.py:19] end self_attn cost 0.003664255142211914 seconds
DEBUG 01-07 10:14:07.717812.717812 cuda_h.py:19] end iln_self_attn_paln cost 0.007380962371826172 seconds
DEBUG 01-07 10:14:07.717086.717086 cuda_h.py:10] start layer_moe_generate_multi_device_21
DEBUG 01-07 10:14:07.718087.718087 cuda_h.py:10] start gate
DEBUG 01-07 10:14:07.718964.718964 cuda_h.py:19] end gate cost 0.0006470680236816406 seconds
DEBUG 01-07 10:14:07.718079.718079 cuda_h.py:10] start experts_map_get
DEBUG 01-07 10:14:07.719761.719761 lmp.py:744] 
DEBUG 01-07 10:14:07.719761.719761 lmp.py:744] Expert Token Distribution & Multi-Device Allocation:
DEBUG 01-07 10:14:07.719915.719915 lmp.py:745]   Total experts: 64
DEBUG 01-07 10:14:07.719948.719948 lmp.py:746]   CPU experts: 19 (30%)
DEBUG 01-07 10:14:07.719260.719260 lmp.py:747]   GPU experts: 45 (70%)
DEBUG 01-07 10:14:07.719665.719665 lmp.py:748]   Number of GPU devices: 2
DEBUG 01-07 10:14:07.719116.719116 lmp.py:749] 
DEBUG 01-07 10:14:07.719116.719116 lmp.py:749]   Expert ID | Tokens | Device
DEBUG 01-07 10:14:07.719044.719044 lmp.py:750]   -----------------------------------
DEBUG 01-07 10:14:07.719647.719647 lmp.py:767]   Expert 44 |     34 | CPU
DEBUG 01-07 10:14:07.719336.719336 lmp.py:767]   Expert  9 |     36 | CPU
DEBUG 01-07 10:14:07.719549.719549 lmp.py:767]   Expert 11 |     40 | CPU
DEBUG 01-07 10:14:07.719761.719761 lmp.py:767]   Expert 56 |     55 | CPU
DEBUG 01-07 10:14:07.719974.719974 lmp.py:767]   Expert 54 |     76 | CPU
DEBUG 01-07 10:14:07.719425.719425 lmp.py:767]   Expert 47 |     93 | CPU
DEBUG 01-07 10:14:07.719352.719352 lmp.py:767]   Expert 62 |     93 | CPU
DEBUG 01-07 10:14:07.719042.719042 lmp.py:767]   Expert  7 |     95 | CPU
DEBUG 01-07 10:14:07.719731.719731 lmp.py:767]   Expert 51 |    102 | CPU
DEBUG 01-07 10:14:07.719943.719943 lmp.py:767]   Expert 60 |    106 | CPU
DEBUG 01-07 10:14:07.719156.719156 lmp.py:767]   Expert 53 |    109 | CPU
DEBUG 01-07 10:14:07.719607.719607 lmp.py:767]   Expert 52 |    110 | CPU
DEBUG 01-07 10:14:07.719581.719581 lmp.py:767]   Expert 41 |    111 | CPU
DEBUG 01-07 10:14:07.719032.719032 lmp.py:767]   Expert 22 |    115 | CPU
DEBUG 01-07 10:14:07.719244.719244 lmp.py:767]   Expert  6 |    126 | CPU
DEBUG 01-07 10:14:07.719457.719457 lmp.py:767]   Expert 32 |    127 | CPU
DEBUG 01-07 10:14:07.719669.719669 lmp.py:767]   Expert  8 |    129 | CPU
DEBUG 01-07 10:14:07.719358.719358 lmp.py:767]   Expert  1 |    130 | CPU
DEBUG 01-07 10:14:07.719332.719332 lmp.py:767]   Expert  2 |    130 | CPU
DEBUG 01-07 10:14:07.719498.719498 lmp.py:767]   Expert 48 |    132 | GPU1(cuda:2)
DEBUG 01-07 10:14:07.719380.719380 lmp.py:767]   Expert 35 |    139 | GPU0(cuda:1)
DEBUG 01-07 10:14:07.719308.719308 lmp.py:767]   Expert 23 |    140 | GPU0(cuda:1)
DEBUG 01-07 10:14:07.719235.719235 lmp.py:767]   Expert 27 |    140 | GPU1(cuda:2)
DEBUG 01-07 10:14:07.719401.719401 lmp.py:767]   Expert 39 |    142 | GPU0(cuda:1)
DEBUG 01-07 10:14:07.719329.719329 lmp.py:767]   Expert 50 |    147 | GPU0(cuda:1)
DEBUG 01-07 10:14:07.719495.719495 lmp.py:767]   Expert 59 |    147 | GPU1(cuda:2)
DEBUG 01-07 10:14:07.719661.719661 lmp.py:767]   Expert 14 |    149 | GPU1(cuda:2)
DEBUG 01-07 10:14:07.719589.719589 lmp.py:767]   Expert 26 |    149 | GPU1(cuda:2)
DEBUG 01-07 10:14:07.719517.719517 lmp.py:767]   Expert 46 |    165 | GPU0(cuda:1)
DEBUG 01-07 10:14:07.719352.719352 lmp.py:767]   Expert 38 |    167 | GPU1(cuda:2)
DEBUG 01-07 10:14:07.719757.719757 lmp.py:767]   Expert 34 |    168 | GPU0(cuda:1)
DEBUG 01-07 10:14:07.719923.719923 lmp.py:767]   Expert  0 |    169 | GPU1(cuda:2)
DEBUG 01-07 10:14:07.719612.719612 lmp.py:767]   Expert  4 |    170 | GPU1(cuda:2)
DEBUG 01-07 10:14:07.719301.719301 lmp.py:767]   Expert 24 |    170 | GPU0(cuda:1)
DEBUG 01-07 10:14:07.719991.719991 lmp.py:767]   Expert 49 |    172 | GPU0(cuda:1)
DEBUG 01-07 10:14:07.719680.719680 lmp.py:767]   Expert 40 |    179 | GPU1(cuda:2)
DEBUG 01-07 10:14:07.719369.719369 lmp.py:767]   Expert  5 |    181 | GPU0(cuda:1)
DEBUG 01-07 10:14:07.719058.719058 lmp.py:767]   Expert 63 |    189 | GPU1(cuda:2)
DEBUG 01-07 10:14:07.719940.719940 lmp.py:767]   Expert 19 |    194 | GPU0(cuda:1)
DEBUG 01-07 10:14:07.719344.719344 lmp.py:767]   Expert 13 |    196 | GPU0(cuda:1)
DEBUG 01-07 10:14:07.719511.719511 lmp.py:767]   Expert 29 |    196 | GPU1(cuda:2)
DEBUG 01-07 10:14:07.719200.719200 lmp.py:767]   Expert 43 |    197 | GPU1(cuda:2)
DEBUG 01-07 10:14:07.720128.720128 lmp.py:767]   Expert 61 |    208 | GPU0(cuda:1)
DEBUG 01-07 10:14:07.720055.720055 lmp.py:767]   Expert 57 |    213 | GPU1(cuda:2)
DEBUG 01-07 10:14:07.720506.720506 lmp.py:767]   Expert 31 |    223 | GPU1(cuda:2)
DEBUG 01-07 10:14:07.720195.720195 lmp.py:767]   Expert 33 |    223 | GPU0(cuda:1)
DEBUG 01-07 10:14:07.720123.720123 lmp.py:767]   Expert 16 |    241 | GPU0(cuda:1)
DEBUG 01-07 10:14:07.720289.720289 lmp.py:767]   Expert 20 |    251 | GPU1(cuda:2)
DEBUG 01-07 10:14:07.720217.720217 lmp.py:767]   Expert  3 |    255 | GPU0(cuda:1)
DEBUG 01-07 10:14:07.720145.720145 lmp.py:767]   Expert 15 |    261 | GPU1(cuda:2)
DEBUG 01-07 10:14:07.720072.720072 lmp.py:767]   Expert 37 |    264 | GPU0(cuda:1)
DEBUG 01-07 10:14:07.720477.720477 lmp.py:767]   Expert 36 |    272 | GPU1(cuda:2)
DEBUG 01-07 10:14:07.720405.720405 lmp.py:767]   Expert 18 |    277 | GPU0(cuda:1)
DEBUG 01-07 10:14:07.720094.720094 lmp.py:767]   Expert 12 |    283 | GPU1(cuda:2)
DEBUG 01-07 10:14:07.720022.720022 lmp.py:767]   Expert 28 |    305 | GPU0(cuda:1)
DEBUG 01-07 10:14:07.720949.720949 lmp.py:767]   Expert 17 |    307 | GPU1(cuda:2)
DEBUG 01-07 10:14:07.720831.720831 lmp.py:767]   Expert 55 |    309 | GPU0(cuda:1)
DEBUG 01-07 10:14:07.720474.720474 lmp.py:767]   Expert 25 |    317 | GPU1(cuda:2)
DEBUG 01-07 10:14:07.720117.720117 lmp.py:767]   Expert 30 |    326 | GPU0(cuda:1)
DEBUG 01-07 10:14:07.720998.720998 lmp.py:767]   Expert 58 |    342 | GPU1(cuda:2)
DEBUG 01-07 10:14:07.720403.720403 lmp.py:767]   Expert 10 |    366 | GPU0(cuda:1)
DEBUG 01-07 10:14:07.720715.720715 lmp.py:767]   Expert 45 |    386 | GPU1(cuda:2)
DEBUG 01-07 10:14:07.720073.720073 lmp.py:767]   Expert 21 |    393 | GPU1(cuda:2)
DEBUG 01-07 10:14:07.720193.720193 lmp.py:767]   Expert 42 |    651 | GPU0(cuda:1)
DEBUG 01-07 10:14:07.720227.720227 lmp.py:769] 
DEBUG 01-07 10:14:07.720227.720227 lmp.py:769]   Device Token Distribution:
DEBUG 01-07 10:14:07.720062.720062 lmp.py:770]   CPU:   1817 tokens
DEBUG 01-07 10:14:07.720374.720374 lmp.py:774]   cuda:1:   5239 tokens (22 experts)
DEBUG 01-07 10:14:07.720017.720017 lmp.py:774]   cuda:2:   5232 tokens (23 experts)
DEBUG 01-07 10:14:07.720183.720183 lmp.py:775]   Total GPU:  10471 tokens
DEBUG 01-07 10:14:07.720872.720872 lmp.py:776] ============================================================
DEBUG 01-07 10:14:07.720872.720872 lmp.py:776] 
DEBUG 01-07 10:14:07.720999.720999 cuda_h.py:19] end experts_map_get cost 0.001737356185913086 seconds
DEBUG 01-07 10:14:07.720595.720595 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model_multi_device
DEBUG 01-07 10:14:07.720656.720656 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 10:14:07.720375.720375 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 10:14:07.720152.720152 cuda_h.py:19] end allocate_cuda_memory cost 0.000225067138671875 seconds
DEBUG 01-07 10:14:07.721201.721201 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 10:14:07.721957.721957 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 10:14:07.721051.721051 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 10:14:07.721462.721462 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 966ea136-49af-4697-a8cd-ef4c96b2d384
DEBUG 01-07 10:14:07.721573.721573 client.py:106] call stub.LoadModelAsync
INFO 01-07 10:14:07.721962.721962 client.py:127] Model loaded
DEBUG 01-07 10:14:07.721703.721703 cuda_h.py:19] end sllm_worker_task cost 0.011073112487792969 seconds
INFO 01-07 10:14:07.721059.721059 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 966ea136-49af-4697-a8cd-ef4c96b2d384
DEBUG 01-07 10:14:07.721233.721233 cuda_h.py:19] end load_into_gpu_async cost 0.0009396076202392578 seconds
DEBUG 01-07 10:14:07.722029.722029 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 10:14:07.722277.722277 cuda_h.py:19] end restore_tensors2 cost 0.00026416778564453125 seconds
DEBUG 01-07 10:14:07.722239.722239 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0017414093017578125 seconds
DEBUG 01-07 10:14:07.724916.724916 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 10:14:07.724662.724662 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 10:14:07.724552.724552 cuda_h.py:19] end allocate_cuda_memory cost 0.00023174285888671875 seconds
DEBUG 01-07 10:14:07.724918.724918 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 10:14:07.724005.724005 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 10:14:07.724715.724715 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 10:14:07.724841.724841 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 7b0eef6e-8ca5-4462-93e2-d531cca6edd2
DEBUG 01-07 10:14:07.724793.724793 client.py:106] call stub.LoadModelAsync
INFO 01-07 10:14:07.725925.725925 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 7b0eef6e-8ca5-4462-93e2-d531cca6edd2
DEBUG 01-07 10:14:07.725754.725754 cuda_h.py:19] end load_into_gpu_async cost 0.0010066032409667969 seconds
DEBUG 01-07 10:14:07.725073.725073 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 10:14:07.725685.725685 cuda_h.py:19] end restore_tensors2 cost 0.0002503395080566406 seconds
DEBUG 01-07 10:14:07.726838.726838 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0017883777618408203 seconds
DEBUG 01-07 10:14:07.727417.727417 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model_multi_device cost 0.007321357727050781 seconds
DEBUG 01-07 10:14:07.727671.727671 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-07 10:14:07.727779.727779 lmp.py:816] 
DEBUG 01-07 10:14:07.727779.727779 lmp.py:816]   Computing 19 experts on CPU...
DEBUG 01-07 10:14:07.728676.728676 cuda_h.py:19] end cpu_experts_submit cost 0.00010895729064941406 seconds
DEBUG 01-07 10:14:07.728756.728756 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-07 10:14:07.738750.738750 mlpmodule.py:749] group tensors cost 0.009985923767089844 s
DEBUG 01-07 10:14:07.739072.739072 mlpmodule.py:787] pad cost 0.0010139942169189453 s
DEBUG 01-07 10:14:07.740347.740347 mlpmodule.py:793] create cpu tensor cost 4.0531158447265625e-05 s
DEBUG 01-07 10:14:07.740773.740773 mlpmodule.py:798] move to cpu cost 3.170967102050781e-05 s
DEBUG 01-07 10:14:07.752362.752362 mlpmodule.py:812] group_w3: shape=torch.Size([19, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=54788096
DEBUG 01-07 10:14:07.752606.752606 mlpmodule.py:813] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-07 10:14:07.752895.752895 mlpmodule.py:818] group_w3 first element: 0.00066375732421875
WARNING 01-07 10:14:07.752025.752025 mlpmodule.py:828] start einsum2
DEBUG 01-07 10:14:07.773789.773789 mlpmodule.py:838] group einsum cost 0.03304576873779297 s
DEBUG 01-07 10:14:07.773053.773053 mlpmodule.py:846] cpy2cputensor cost 0.0003616809844970703 s
DEBUG 01-07 10:14:07.776483.776483 cuda_h.py:19] end wait_cetm_experts cost 0.04817509651184082 seconds
DEBUG 01-07 10:14:07.776586.776586 cuda_h.py:10] start gpu_sexperts
DEBUG 01-07 10:14:07.776273.776273 cuda_h.py:19] end gpu_sexperts cost 0.0004973411560058594 seconds
DEBUG 01-07 10:14:07.777732.777732 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-07 10:14:07.777866.777866 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.384185791015625e-05 seconds
DEBUG 01-07 10:14:07.777523.777523 cuda_h.py:10] start wait_experts_multi_device
INFO 01-07 10:14:07.777186.777186 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 966ea136-49af-4697-a8cd-ef4c96b2d384
INFO 01-07 10:14:07.778680.778680 client.py:127] Model loaded
INFO 01-07 10:14:07.778132.778132 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 7b0eef6e-8ca5-4462-93e2-d531cca6edd2
INFO 01-07 10:14:07.778443.778443 client.py:127] Model loaded
DEBUG 01-07 10:14:07.778750.778750 cuda_h.py:19] end wait_experts_multi_device cost 0.0014007091522216797 seconds
DEBUG 01-07 10:14:07.778837.778837 cuda_h.py:10] start gpu_experts_multi_device
DEBUG 01-07 10:14:07.778183.778183 lmp.py:867]   Computing 23 experts on cuda:2...
DEBUG 01-07 10:14:07.779348.779348 mlpmodule.py:533] gpu group tensors cost 0.0004961490631103516 s
DEBUG 01-07 10:14:07.781785.781785 mlpmodule.py:566] gpu pad cost 0.001312255859375 s
DEBUG 01-07 10:14:07.781548.781548 mlpmodule.py:584] gpu group einsum cost 0.0005435943603515625 s
DEBUG 01-07 10:14:07.783173.783173 mlpmodule.py:656] gpu experts func einsum cost 0.0045816898345947266 s
DEBUG 01-07 10:14:07.784435.784435 lmp.py:867]   Computing 22 experts on cuda:1...
DEBUG 01-07 10:14:07.784515.784515 mlpmodule.py:533] gpu group tensors cost 0.0004475116729736328 s
DEBUG 01-07 10:14:07.785388.785388 mlpmodule.py:707]  experts func einsum cost 0.05713629722595215 s
DEBUG 01-07 10:14:07.786229.786229 mlpmodule.py:566] gpu pad cost 0.001306295394897461 s
DEBUG 01-07 10:14:07.786664.786664 mlpmodule.py:584] gpu group einsum cost 0.0004496574401855469 s
DEBUG 01-07 10:14:07.788214.788214 mlpmodule.py:656] gpu experts func einsum cost 0.0043332576751708984 s
DEBUG 01-07 10:14:07.788211.788211 cuda_h.py:19] end gpu_experts_multi_device cost 0.010360240936279297 seconds
DEBUG 01-07 10:14:07.789426.789426 cuda_h.py:19] end layer_moe_generate_multi_device_21 cost 0.07103919982910156 seconds
DEBUG 01-07 10:14:07.789203.789203 lmp.py:194] -------------------------------- end prefill layer 21 --------------------------------
DEBUG 01-07 10:14:07.789204.789204 lmp.py:153] -------------------------------- start prefill layer 22 --------------------------------
DEBUG 01-07 10:14:07.789662.789662 cuda_h.py:10] start start_load_qkvogn_s_weight_l_23
DEBUG 01-07 10:14:07.789179.789179 cuda_h.py:10] start start_load_qkvogn_s_weight_l_23
DEBUG 01-07 10:14:07.789777.789777 cuda_h.py:19] end start_load_qkvogn_s_weight_l_23 cost 2.765655517578125e-05 seconds
DEBUG 01-07 10:14:07.789480.789480 cuda_h.py:19] end start_load_qkvogn_s_weight_l_23 cost 5.745887756347656e-05 seconds
DEBUG 01-07 10:14:07.789269.789269 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-07 10:14:07.789920.789920 mlpmodule.py:367] cuda:1 cuda:1
DEBUG 01-07 10:14:07.789545.789545 cuda_h.py:10] start sllm_worker_task
DEBUG 01-07 10:14:07.789064.789064 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 10:14:07.789986.789986 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 10:14:07.790646.790646 cuda_h.py:19] end allocate_cuda_memory cost 0.0003123283386230469 seconds
DEBUG 01-07 10:14:07.790384.790384 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 10:14:07.790955.790955 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 10:14:07.790062.790062 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 10:14:07.790765.790765 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 36ca5ed3-0f5a-4108-adbe-1bd22795ddda
DEBUG 01-07 10:14:07.790775.790775 client.py:106] call stub.LoadModelAsync
DEBUG 01-07 10:14:07.790684.790684 cuda_h.py:10] start self_attn
INFO 01-07 10:14:07.790570.790570 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 36ca5ed3-0f5a-4108-adbe-1bd22795ddda
DEBUG 01-07 10:14:07.791115.791115 cuda_h.py:19] end load_into_gpu_async cost 0.0008203983306884766 seconds
DEBUG 01-07 10:14:07.791480.791480 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 10:14:07.791695.791695 cuda_h.py:19] end restore_tensors2 cost 6.389617919921875e-05 seconds
DEBUG 01-07 10:14:07.791543.791543 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0014481544494628906 seconds
INFO 01-07 10:14:07.791803.791803 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 36ca5ed3-0f5a-4108-adbe-1bd22795ddda
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-07 10:14:07.794368.794368 cuda_h.py:19] end self_attn cost 0.0035669803619384766 seconds
DEBUG 01-07 10:14:07.794763.794763 cuda_h.py:19] end iln_self_attn_paln cost 0.0050394535064697266 seconds
DEBUG 01-07 10:14:07.794924.794924 cuda_h.py:10] start layer_moe_generate_multi_device_22
DEBUG 01-07 10:14:07.794348.794348 cuda_h.py:10] start gate
DEBUG 01-07 10:14:07.795073.795073 cuda_h.py:19] end gate cost 0.0006413459777832031 seconds
DEBUG 01-07 10:14:07.795187.795187 cuda_h.py:10] start experts_map_get
DEBUG 01-07 10:14:07.795393.795393 lmp.py:744] 
DEBUG 01-07 10:14:07.795393.795393 lmp.py:744] Expert Token Distribution & Multi-Device Allocation:
DEBUG 01-07 10:14:07.795308.795308 lmp.py:745]   Total experts: 64
DEBUG 01-07 10:14:07.795342.795342 lmp.py:746]   CPU experts: 19 (30%)
DEBUG 01-07 10:14:07.795892.795892 lmp.py:747]   GPU experts: 45 (70%)
DEBUG 01-07 10:14:07.795058.795058 lmp.py:748]   Number of GPU devices: 2
DEBUG 01-07 10:14:07.795748.795748 lmp.py:749] 
DEBUG 01-07 10:14:07.795748.795748 lmp.py:749]   Expert ID | Tokens | Device
DEBUG 01-07 10:14:07.795437.795437 lmp.py:750]   -----------------------------------
DEBUG 01-07 10:14:07.795802.795802 lmp.py:767]   Expert 25 |     15 | CPU
DEBUG 01-07 10:14:07.795968.795968 lmp.py:767]   Expert 48 |     36 | CPU
DEBUG 01-07 10:14:07.795181.795181 lmp.py:767]   Expert 45 |     38 | CPU
DEBUG 01-07 10:14:07.795108.795108 lmp.py:767]   Expert  9 |     63 | CPU
DEBUG 01-07 10:14:07.795559.795559 lmp.py:767]   Expert 54 |     84 | CPU
DEBUG 01-07 10:14:07.796964.796964 lmp.py:767]   Expert 43 |     87 | CPU
DEBUG 01-07 10:14:07.796891.796891 lmp.py:767]   Expert 57 |     87 | CPU
DEBUG 01-07 10:14:07.796866.796866 lmp.py:767]   Expert 20 |     88 | CPU
DEBUG 01-07 10:14:07.796078.796078 lmp.py:767]   Expert 47 |     89 | CPU
DEBUG 01-07 10:14:07.796767.796767 lmp.py:767]   Expert  0 |     90 | CPU
DEBUG 01-07 10:14:07.796741.796741 lmp.py:767]   Expert  6 |     93 | CPU
DEBUG 01-07 10:14:07.796192.796192 lmp.py:767]   Expert 36 |     98 | CPU
DEBUG 01-07 10:14:07.796405.796405 lmp.py:767]   Expert 50 |    102 | CPU
DEBUG 01-07 10:14:07.796379.796379 lmp.py:767]   Expert 13 |    104 | CPU
DEBUG 01-07 10:14:07.796591.796591 lmp.py:767]   Expert 15 |    105 | CPU
DEBUG 01-07 10:14:07.796042.796042 lmp.py:767]   Expert 61 |    105 | CPU
DEBUG 01-07 10:14:07.796255.796255 lmp.py:767]   Expert 62 |    107 | CPU
DEBUG 01-07 10:14:07.796705.796705 lmp.py:767]   Expert  1 |    110 | CPU
DEBUG 01-07 10:14:07.796918.796918 lmp.py:767]   Expert 38 |    110 | CPU
DEBUG 01-07 10:14:07.796561.796561 lmp.py:767]   Expert 46 |    113 | GPU1(cuda:2)
DEBUG 01-07 10:14:07.796681.796681 lmp.py:767]   Expert 37 |    114 | GPU0(cuda:1)
DEBUG 01-07 10:14:07.796324.796324 lmp.py:767]   Expert 14 |    124 | GPU1(cuda:2)
DEBUG 01-07 10:14:07.796728.796728 lmp.py:767]   Expert  7 |    134 | GPU0(cuda:1)
DEBUG 01-07 10:14:07.796133.796133 lmp.py:767]   Expert 21 |    137 | GPU1(cuda:2)
DEBUG 01-07 10:14:07.796299.796299 lmp.py:767]   Expert 28 |    140 | GPU0(cuda:1)
DEBUG 01-07 10:14:07.796180.796180 lmp.py:767]   Expert 44 |    144 | GPU0(cuda:1)
DEBUG 01-07 10:14:07.796539.796539 lmp.py:767]   Expert 52 |    144 | GPU1(cuda:2)
DEBUG 01-07 10:14:07.796943.796943 lmp.py:767]   Expert 24 |    150 | GPU1(cuda:2)
DEBUG 01-07 10:14:07.796388.796388 lmp.py:767]   Expert 10 |    151 | GPU0(cuda:1)
DEBUG 01-07 10:14:07.796031.796031 lmp.py:767]   Expert 42 |    157 | GPU1(cuda:2)
DEBUG 01-07 10:14:07.796913.796913 lmp.py:767]   Expert 11 |    161 | GPU0(cuda:1)
DEBUG 01-07 10:14:07.796033.796033 lmp.py:767]   Expert  2 |    165 | GPU1(cuda:2)
DEBUG 01-07 10:14:07.796676.796676 lmp.py:767]   Expert 26 |    166 | GPU0(cuda:1)
DEBUG 01-07 10:14:07.796603.796603 lmp.py:767]   Expert 35 |    169 | GPU1(cuda:2)
DEBUG 01-07 10:14:07.796293.796293 lmp.py:767]   Expert 31 |    180 | GPU1(cuda:2)
DEBUG 01-07 10:14:07.796220.796220 lmp.py:767]   Expert 32 |    180 | GPU0(cuda:1)
DEBUG 01-07 10:14:07.796386.796386 lmp.py:767]   Expert  3 |    186 | GPU0(cuda:1)
DEBUG 01-07 10:14:07.796314.796314 lmp.py:767]   Expert 12 |    187 | GPU0(cuda:1)
DEBUG 01-07 10:14:07.796242.796242 lmp.py:767]   Expert 19 |    187 | GPU1(cuda:2)
DEBUG 01-07 10:14:07.796646.796646 lmp.py:767]   Expert 56 |    208 | GPU1(cuda:2)
DEBUG 01-07 10:14:07.796813.796813 lmp.py:767]   Expert 60 |    211 | GPU0(cuda:1)
DEBUG 01-07 10:14:07.796502.796502 lmp.py:767]   Expert 40 |    212 | GPU1(cuda:2)
DEBUG 01-07 10:14:07.796430.796430 lmp.py:767]   Expert 41 |    216 | GPU0(cuda:1)
DEBUG 01-07 10:14:07.796880.796880 lmp.py:767]   Expert 53 |    227 | GPU1(cuda:2)
DEBUG 01-07 10:14:07.796570.796570 lmp.py:767]   Expert 58 |    231 | GPU0(cuda:1)
DEBUG 01-07 10:14:07.796497.796497 lmp.py:767]   Expert 23 |    232 | GPU1(cuda:2)
DEBUG 01-07 10:14:07.796187.796187 lmp.py:767]   Expert  8 |    235 | GPU0(cuda:1)
DEBUG 01-07 10:14:07.796114.796114 lmp.py:767]   Expert 59 |    240 | GPU1(cuda:2)
DEBUG 01-07 10:14:07.796996.796996 lmp.py:767]   Expert 16 |    242 | GPU0(cuda:1)
DEBUG 01-07 10:14:07.796924.796924 lmp.py:767]   Expert 51 |    244 | GPU1(cuda:2)
DEBUG 01-07 10:14:07.796613.796613 lmp.py:767]   Expert  4 |    245 | GPU0(cuda:1)
DEBUG 01-07 10:14:07.796064.796064 lmp.py:767]   Expert 55 |    264 | GPU1(cuda:2)
DEBUG 01-07 10:14:07.796992.796992 lmp.py:767]   Expert 49 |    273 | GPU0(cuda:1)
DEBUG 01-07 10:14:07.796681.796681 lmp.py:767]   Expert 29 |    274 | GPU1(cuda:2)
DEBUG 01-07 10:14:07.796324.796324 lmp.py:767]   Expert 18 |    281 | GPU0(cuda:1)
DEBUG 01-07 10:14:07.796967.796967 lmp.py:767]   Expert 34 |    287 | GPU1(cuda:2)
DEBUG 01-07 10:14:07.796563.796563 lmp.py:767]   Expert 63 |    289 | GPU0(cuda:1)
DEBUG 01-07 10:14:07.796922.796922 lmp.py:767]   Expert 27 |    353 | GPU1(cuda:2)
DEBUG 01-07 10:14:07.796803.796803 lmp.py:767]   Expert 39 |    379 | GPU0(cuda:1)
DEBUG 01-07 10:14:07.796684.796684 lmp.py:767]   Expert 17 |    395 | GPU1(cuda:2)
DEBUG 01-07 10:14:07.796327.796327 lmp.py:767]   Expert 22 |    421 | GPU0(cuda:1)
DEBUG 01-07 10:14:07.796970.796970 lmp.py:767]   Expert 30 |    453 | GPU1(cuda:2)
DEBUG 01-07 10:14:07.797852.797852 lmp.py:767]   Expert 33 |    464 | GPU1(cuda:2)
DEBUG 01-07 10:14:07.797256.797256 lmp.py:767]   Expert  5 |    712 | GPU0(cuda:1)
DEBUG 01-07 10:14:07.797946.797946 lmp.py:769] 
DEBUG 01-07 10:14:07.797946.797946 lmp.py:769]   Device Token Distribution:
DEBUG 01-07 10:14:07.797542.797542 lmp.py:770]   CPU:   1611 tokens
DEBUG 01-07 10:14:07.797377.797377 lmp.py:774]   cuda:1:   5298 tokens (22 experts)
DEBUG 01-07 10:14:07.797020.797020 lmp.py:774]   cuda:2:   5379 tokens (23 experts)
DEBUG 01-07 10:14:07.797186.797186 lmp.py:775]   Total GPU:  10677 tokens
DEBUG 01-07 10:14:07.797876.797876 lmp.py:776] ============================================================
DEBUG 01-07 10:14:07.797876.797876 lmp.py:776] 
DEBUG 01-07 10:14:07.797241.797241 cuda_h.py:19] end experts_map_get cost 0.001766204833984375 seconds
DEBUG 01-07 10:14:07.797361.797361 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model_multi_device
DEBUG 01-07 10:14:07.797660.797660 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 10:14:07.797379.797379 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 10:14:07.797494.797494 cuda_h.py:19] end allocate_cuda_memory cost 0.00022649765014648438 seconds
DEBUG 01-07 10:14:07.797019.797019 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 10:14:07.797967.797967 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 10:14:07.797631.797631 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 10:14:07.797042.797042 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, f7d4e6a9-eebd-438d-b713-af9b695a300d
DEBUG 01-07 10:14:07.797769.797769 client.py:106] call stub.LoadModelAsync
INFO 01-07 10:14:07.797857.797857 client.py:127] Model loaded
DEBUG 01-07 10:14:07.798283.798283 cuda_h.py:19] end sllm_worker_task cost 0.008728981018066406 seconds
INFO 01-07 10:14:07.798122.798122 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, f7d4e6a9-eebd-438d-b713-af9b695a300d
DEBUG 01-07 10:14:07.798680.798680 cuda_h.py:19] end load_into_gpu_async cost 0.0011200904846191406 seconds
DEBUG 01-07 10:14:07.798145.798145 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 10:14:07.799386.799386 cuda_h.py:19] end restore_tensors2 cost 0.0002579689025878906 seconds
DEBUG 01-07 10:14:07.799586.799586 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0019230842590332031 seconds
DEBUG 01-07 10:14:07.801562.801562 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 10:14:07.801970.801970 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 10:14:07.801846.801846 cuda_h.py:19] end allocate_cuda_memory cost 0.0002224445343017578 seconds
DEBUG 01-07 10:14:07.801544.801544 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 10:14:07.801107.801107 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 10:14:07.801056.801056 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 10:14:07.801421.801421 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 8517fc09-2d5a-4340-9806-2f39a43dc387
DEBUG 01-07 10:14:07.801710.801710 client.py:106] call stub.LoadModelAsync
INFO 01-07 10:14:07.802304.802304 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 8517fc09-2d5a-4340-9806-2f39a43dc387
DEBUG 01-07 10:14:07.802942.802942 cuda_h.py:19] end load_into_gpu_async cost 0.0011744499206542969 seconds
DEBUG 01-07 10:14:07.802737.802737 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 10:14:07.802852.802852 cuda_h.py:19] end restore_tensors2 cost 0.00023555755615234375 seconds
DEBUG 01-07 10:14:07.802337.802337 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0019261837005615234 seconds
DEBUG 01-07 10:14:07.804446.804446 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model_multi_device cost 0.007655620574951172 seconds
DEBUG 01-07 10:14:07.804222.804222 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-07 10:14:07.804377.804377 lmp.py:816] 
DEBUG 01-07 10:14:07.804377.804377 lmp.py:816]   Computing 19 experts on CPU...
DEBUG 01-07 10:14:07.805928.805928 cuda_h.py:19] end cpu_experts_submit cost 0.00010752677917480469 seconds
DEBUG 01-07 10:14:07.805009.805009 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-07 10:14:07.810211.810211 mlpmodule.py:749] group tensors cost 0.005713701248168945 s
DEBUG 01-07 10:14:07.812164.812164 mlpmodule.py:787] pad cost 0.0012395381927490234 s
DEBUG 01-07 10:14:07.812698.812698 mlpmodule.py:793] create cpu tensor cost 4.744529724121094e-05 s
DEBUG 01-07 10:14:07.813522.813522 mlpmodule.py:798] move to cpu cost 3.62396240234375e-05 s
DEBUG 01-07 10:14:07.825785.825785 mlpmodule.py:812] group_w3: shape=torch.Size([19, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=54788096
DEBUG 01-07 10:14:07.825314.825314 mlpmodule.py:813] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-07 10:14:07.825934.825934 mlpmodule.py:818] group_w3 first element: -0.018798828125
WARNING 01-07 10:14:07.825965.825965 mlpmodule.py:828] start einsum2
DEBUG 01-07 10:14:07.843230.843230 mlpmodule.py:838] group einsum cost 0.029967308044433594 s
DEBUG 01-07 10:14:07.843865.843865 mlpmodule.py:846] cpy2cputensor cost 0.00036787986755371094 s
DEBUG 01-07 10:14:07.846072.846072 cuda_h.py:19] end wait_cetm_experts cost 0.04118633270263672 seconds
DEBUG 01-07 10:14:07.846254.846254 cuda_h.py:10] start gpu_sexperts
DEBUG 01-07 10:14:07.846630.846630 cuda_h.py:19] end gpu_sexperts cost 0.0005125999450683594 seconds
DEBUG 01-07 10:14:07.847116.847116 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-07 10:14:07.847727.847727 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.4557113647460938e-05 seconds
DEBUG 01-07 10:14:07.847622.847622 cuda_h.py:10] start wait_experts_multi_device
INFO 01-07 10:14:07.847286.847286 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, f7d4e6a9-eebd-438d-b713-af9b695a300d
INFO 01-07 10:14:07.848541.848541 client.py:127] Model loaded
INFO 01-07 10:14:07.848615.848615 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 8517fc09-2d5a-4340-9806-2f39a43dc387
INFO 01-07 10:14:07.852194.852194 client.py:127] Model loaded
DEBUG 01-07 10:14:07.852011.852011 cuda_h.py:19] end wait_experts_multi_device cost 0.005836963653564453 seconds
DEBUG 01-07 10:14:07.853151.853151 cuda_h.py:10] start gpu_experts_multi_device
DEBUG 01-07 10:14:07.853073.853073 lmp.py:867]   Computing 23 experts on cuda:2...
DEBUG 01-07 10:14:07.854278.854278 mlpmodule.py:533] gpu group tensors cost 0.0005013942718505859 s
DEBUG 01-07 10:14:07.855218.855218 mlpmodule.py:707]  experts func einsum cost 0.05004429817199707 s
DEBUG 01-07 10:14:07.855216.855216 mlpmodule.py:566] gpu pad cost 0.0014264583587646484 s
DEBUG 01-07 10:14:07.856068.856068 mlpmodule.py:584] gpu group einsum cost 0.0004277229309082031 s
DEBUG 01-07 10:14:07.858690.858690 mlpmodule.py:656] gpu experts func einsum cost 0.004492998123168945 s
DEBUG 01-07 10:14:07.858950.858950 lmp.py:867]   Computing 22 experts on cuda:1...
DEBUG 01-07 10:14:07.859336.859336 mlpmodule.py:533] gpu group tensors cost 0.000370025634765625 s
DEBUG 01-07 10:14:07.860763.860763 mlpmodule.py:566] gpu pad cost 0.0010342597961425781 s
DEBUG 01-07 10:14:07.860892.860892 mlpmodule.py:584] gpu group einsum cost 0.0004169940948486328 s
DEBUG 01-07 10:14:07.862244.862244 mlpmodule.py:656] gpu experts func einsum cost 0.003567934036254883 s
DEBUG 01-07 10:14:07.862373.862373 cuda_h.py:19] end gpu_experts_multi_device cost 0.009368658065795898 seconds
DEBUG 01-07 10:14:07.862767.862767 cuda_h.py:19] end layer_moe_generate_multi_device_22 cost 0.06786799430847168 seconds
DEBUG 01-07 10:14:07.862126.862126 lmp.py:194] -------------------------------- end prefill layer 22 --------------------------------
DEBUG 01-07 10:14:07.862810.862810 lmp.py:153] -------------------------------- start prefill layer 23 --------------------------------
DEBUG 01-07 10:14:07.862029.862029 cuda_h.py:10] start start_load_qkvogn_s_weight_l_24
DEBUG 01-07 10:14:07.862547.862547 cuda_h.py:10] start start_load_qkvogn_s_weight_l_24
DEBUG 01-07 10:14:07.862092.862092 cuda_h.py:19] end start_load_qkvogn_s_weight_l_24 cost 2.5272369384765625e-05 seconds
DEBUG 01-07 10:14:07.862887.862887 cuda_h.py:19] end start_load_qkvogn_s_weight_l_24 cost 5.435943603515625e-05 seconds
DEBUG 01-07 10:14:07.862722.862722 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-07 10:14:07.863751.863751 mlpmodule.py:367] cuda:1 cuda:1
DEBUG 01-07 10:14:07.863124.863124 cuda_h.py:10] start sllm_worker_task
DEBUG 01-07 10:14:07.863073.863073 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 10:14:07.863856.863856 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 10:14:07.863522.863522 cuda_h.py:19] end allocate_cuda_memory cost 0.0002810955047607422 seconds
DEBUG 01-07 10:14:07.863624.863624 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 10:14:07.863526.863526 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 10:14:07.863964.863964 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 10:14:07.863760.863760 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 8a985a0b-f1a1-420d-8d10-f2c7aedda150
DEBUG 01-07 10:14:07.863954.863954 client.py:106] call stub.LoadModelAsync
DEBUG 01-07 10:14:07.864248.864248 cuda_h.py:10] start self_attn
INFO 01-07 10:14:07.864364.864364 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 8a985a0b-f1a1-420d-8d10-f2c7aedda150
DEBUG 01-07 10:14:07.864193.864193 cuda_h.py:19] end load_into_gpu_async cost 0.0009486675262451172 seconds
DEBUG 01-07 10:14:07.864274.864274 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 10:14:07.864588.864588 cuda_h.py:19] end restore_tensors2 cost 6.604194641113281e-05 seconds
DEBUG 01-07 10:14:07.864390.864390 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0015366077423095703 seconds
INFO 01-07 10:14:07.864518.864518 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 8a985a0b-f1a1-420d-8d10-f2c7aedda150
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-07 10:14:07.867174.867174 cuda_h.py:19] end self_attn cost 0.0036766529083251953 seconds
DEBUG 01-07 10:14:07.868973.868973 cuda_h.py:19] end iln_self_attn_paln cost 0.005072116851806641 seconds
DEBUG 01-07 10:14:07.868325.868325 cuda_h.py:10] start layer_moe_generate_multi_device_23
DEBUG 01-07 10:14:07.868750.868750 cuda_h.py:10] start gate
DEBUG 01-07 10:14:07.868204.868204 cuda_h.py:19] end gate cost 0.0006525516510009766 seconds
DEBUG 01-07 10:14:07.868364.868364 cuda_h.py:10] start experts_map_get
DEBUG 01-07 10:14:07.869377.869377 lmp.py:744] 
DEBUG 01-07 10:14:07.869377.869377 lmp.py:744] Expert Token Distribution & Multi-Device Allocation:
DEBUG 01-07 10:14:07.869293.869293 lmp.py:745]   Total experts: 64
DEBUG 01-07 10:14:07.869565.869565 lmp.py:746]   CPU experts: 19 (30%)
DEBUG 01-07 10:14:07.869592.869592 lmp.py:747]   GPU experts: 45 (70%)
DEBUG 01-07 10:14:07.869235.869235 lmp.py:748]   Number of GPU devices: 2
DEBUG 01-07 10:14:07.869686.869686 lmp.py:749] 
DEBUG 01-07 10:14:07.869686.869686 lmp.py:749]   Expert ID | Tokens | Device
DEBUG 01-07 10:14:07.869137.869137 lmp.py:750]   -----------------------------------
DEBUG 01-07 10:14:07.869787.869787 lmp.py:767]   Expert  5 |     14 | CPU
DEBUG 01-07 10:14:07.869714.869714 lmp.py:767]   Expert 56 |     35 | CPU
DEBUG 01-07 10:14:07.869927.869927 lmp.py:767]   Expert 27 |     73 | CPU
DEBUG 01-07 10:14:07.869139.869139 lmp.py:767]   Expert 16 |     79 | CPU
DEBUG 01-07 10:14:07.869875.869875 lmp.py:767]   Expert 17 |     87 | CPU
DEBUG 01-07 10:14:07.869803.869803 lmp.py:767]   Expert 40 |     91 | CPU
DEBUG 01-07 10:14:07.869015.869015 lmp.py:767]   Expert 63 |     96 | CPU
DEBUG 01-07 10:14:07.869181.869181 lmp.py:767]   Expert 51 |    103 | CPU
DEBUG 01-07 10:14:07.869394.869394 lmp.py:767]   Expert 49 |    105 | CPU
DEBUG 01-07 10:14:07.869129.869129 lmp.py:767]   Expert 53 |    105 | CPU
DEBUG 01-07 10:14:07.869342.869342 lmp.py:767]   Expert  7 |    107 | CPU
DEBUG 01-07 10:14:07.869316.869316 lmp.py:767]   Expert 28 |    108 | CPU
DEBUG 01-07 10:14:07.869290.869290 lmp.py:767]   Expert 37 |    119 | CPU
DEBUG 01-07 10:14:07.869787.869787 lmp.py:767]   Expert 38 |    125 | CPU
DEBUG 01-07 10:14:07.869000.869000 lmp.py:767]   Expert 47 |    125 | CPU
DEBUG 01-07 10:14:07.869212.869212 lmp.py:767]   Expert 62 |    131 | CPU
DEBUG 01-07 10:14:07.869948.869948 lmp.py:767]   Expert 11 |    133 | CPU
DEBUG 01-07 10:14:07.869399.869399 lmp.py:767]   Expert 58 |    133 | CPU
DEBUG 01-07 10:14:07.869088.869088 lmp.py:767]   Expert 57 |    139 | CPU
DEBUG 01-07 10:14:07.869685.869685 lmp.py:767]   Expert 39 |    144 | GPU0(cuda:1)
DEBUG 01-07 10:14:07.869566.869566 lmp.py:767]   Expert 52 |    148 | GPU1(cuda:2)
DEBUG 01-07 10:14:07.869732.869732 lmp.py:767]   Expert  1 |    149 | GPU0(cuda:1)
DEBUG 01-07 10:14:07.869898.869898 lmp.py:767]   Expert 14 |    152 | GPU1(cuda:2)
DEBUG 01-07 10:14:07.869064.869064 lmp.py:767]   Expert 25 |    154 | GPU0(cuda:1)
DEBUG 01-07 10:14:07.869992.869992 lmp.py:767]   Expert 33 |    156 | GPU0(cuda:1)
DEBUG 01-07 10:14:07.869158.869158 lmp.py:767]   Expert 23 |    163 | GPU1(cuda:2)
DEBUG 01-07 10:14:07.869086.869086 lmp.py:767]   Expert 21 |    170 | GPU1(cuda:2)
DEBUG 01-07 10:14:07.869490.869490 lmp.py:767]   Expert  6 |    174 | GPU0(cuda:1)
DEBUG 01-07 10:14:07.869657.869657 lmp.py:767]   Expert 60 |    175 | GPU0(cuda:1)
DEBUG 01-07 10:14:07.869107.869107 lmp.py:767]   Expert 44 |    177 | GPU0(cuda:1)
DEBUG 01-07 10:14:07.869989.869989 lmp.py:767]   Expert 45 |    177 | GPU1(cuda:2)
DEBUG 01-07 10:14:07.869632.869632 lmp.py:767]   Expert 19 |    182 | GPU1(cuda:2)
DEBUG 01-07 10:14:07.869275.869275 lmp.py:767]   Expert  4 |    185 | GPU1(cuda:2)
DEBUG 01-07 10:14:07.869679.869679 lmp.py:767]   Expert 12 |    185 | GPU0(cuda:1)
DEBUG 01-07 10:14:07.870130.870130 lmp.py:767]   Expert  3 |    193 | GPU0(cuda:1)
DEBUG 01-07 10:14:07.870773.870773 lmp.py:767]   Expert 30 |    195 | GPU1(cuda:2)
DEBUG 01-07 10:14:07.870224.870224 lmp.py:767]   Expert 55 |    197 | GPU0(cuda:1)
DEBUG 01-07 10:14:07.870390.870390 lmp.py:767]   Expert 31 |    198 | GPU1(cuda:2)
DEBUG 01-07 10:14:07.870318.870318 lmp.py:767]   Expert 36 |    201 | GPU1(cuda:2)
DEBUG 01-07 10:14:07.870246.870246 lmp.py:767]   Expert  9 |    213 | GPU0(cuda:1)
DEBUG 01-07 10:14:07.870412.870412 lmp.py:767]   Expert  0 |    219 | GPU1(cuda:2)
DEBUG 01-07 10:14:07.870055.870055 lmp.py:767]   Expert 34 |    223 | GPU0(cuda:1)
DEBUG 01-07 10:14:07.870936.870936 lmp.py:767]   Expert 41 |    225 | GPU1(cuda:2)
DEBUG 01-07 10:14:07.870341.870341 lmp.py:767]   Expert 22 |    227 | GPU0(cuda:1)
DEBUG 01-07 10:14:07.870507.870507 lmp.py:767]   Expert 54 |    238 | GPU1(cuda:2)
DEBUG 01-07 10:14:07.870435.870435 lmp.py:767]   Expert 26 |    240 | GPU0(cuda:1)
DEBUG 01-07 10:14:07.870124.870124 lmp.py:767]   Expert 43 |    240 | GPU0(cuda:1)
DEBUG 01-07 10:14:07.870052.870052 lmp.py:767]   Expert 18 |    251 | GPU1(cuda:2)
DEBUG 01-07 10:14:07.870979.870979 lmp.py:767]   Expert 59 |    254 | GPU1(cuda:2)
DEBUG 01-07 10:14:07.870669.870669 lmp.py:767]   Expert 13 |    255 | GPU1(cuda:2)
DEBUG 01-07 10:14:07.870596.870596 lmp.py:767]   Expert 50 |    255 | GPU0(cuda:1)
DEBUG 01-07 10:14:07.870524.870524 lmp.py:767]   Expert 15 |    259 | GPU1(cuda:2)
DEBUG 01-07 10:14:07.870213.870213 lmp.py:767]   Expert 20 |    259 | GPU0(cuda:1)
DEBUG 01-07 10:14:07.870856.870856 lmp.py:767]   Expert 42 |    264 | GPU0(cuda:1)
DEBUG 01-07 10:14:07.870023.870023 lmp.py:767]   Expert 24 |    265 | GPU1(cuda:2)
DEBUG 01-07 10:14:07.870142.870142 lmp.py:767]   Expert 29 |    274 | GPU1(cuda:2)
DEBUG 01-07 10:14:07.870024.870024 lmp.py:767]   Expert 61 |    274 | GPU0(cuda:1)
DEBUG 01-07 10:14:07.870667.870667 lmp.py:767]   Expert 35 |    278 | GPU0(cuda:1)
DEBUG 01-07 10:14:07.870548.870548 lmp.py:767]   Expert 32 |    296 | GPU0(cuda:1)
DEBUG 01-07 10:14:07.870953.870953 lmp.py:767]   Expert  2 |    330 | GPU1(cuda:2)
DEBUG 01-07 10:14:07.870596.870596 lmp.py:767]   Expert  8 |    340 | GPU0(cuda:1)
DEBUG 01-07 10:14:07.870239.870239 lmp.py:767]   Expert 10 |    345 | GPU1(cuda:2)
DEBUG 01-07 10:14:07.870358.870358 lmp.py:767]   Expert 46 |    432 | GPU1(cuda:2)
DEBUG 01-07 10:14:07.870478.870478 lmp.py:767]   Expert 48 |    449 | GPU0(cuda:1)
DEBUG 01-07 10:14:07.870883.870883 lmp.py:769] 
DEBUG 01-07 10:14:07.870883.870883 lmp.py:769]   Device Token Distribution:
DEBUG 01-07 10:14:07.870764.870764 lmp.py:770]   CPU:   1908 tokens
DEBUG 01-07 10:14:07.870122.870122 lmp.py:774]   cuda:1:   5262 tokens (23 experts)
DEBUG 01-07 10:14:07.870004.870004 lmp.py:774]   cuda:2:   5118 tokens (22 experts)
DEBUG 01-07 10:14:07.870170.870170 lmp.py:775]   Total GPU:  10380 tokens
DEBUG 01-07 10:14:07.870098.870098 lmp.py:776] ============================================================
DEBUG 01-07 10:14:07.870098.870098 lmp.py:776] 
DEBUG 01-07 10:14:07.870747.870747 cuda_h.py:19] end experts_map_get cost 0.0017282962799072266 seconds
DEBUG 01-07 10:14:07.870390.870390 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model_multi_device
DEBUG 01-07 10:14:07.870829.870829 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 10:14:07.870647.870647 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 10:14:07.871345.871345 cuda_h.py:19] end allocate_cuda_memory cost 0.00023603439331054688 seconds
DEBUG 01-07 10:14:07.871241.871241 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 10:14:07.871328.871328 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 10:14:07.871707.871707 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 10:14:07.871833.871833 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 83c51c67-05ae-4375-bdac-0d4d6edc5323
DEBUG 01-07 10:14:07.871289.871289 client.py:106] call stub.LoadModelAsync
INFO 01-07 10:14:07.871387.871387 client.py:127] Model loaded
DEBUG 01-07 10:14:07.871412.871412 cuda_h.py:19] end sllm_worker_task cost 0.008748769760131836 seconds
INFO 01-07 10:14:07.872858.872858 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 83c51c67-05ae-4375-bdac-0d4d6edc5323
DEBUG 01-07 10:14:07.872986.872986 cuda_h.py:19] end load_into_gpu_async cost 0.0010445117950439453 seconds
DEBUG 01-07 10:14:07.872973.872973 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 10:14:07.872897.872897 cuda_h.py:19] end restore_tensors2 cost 0.00026988983154296875 seconds
DEBUG 01-07 10:14:07.872574.872574 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0018622875213623047 seconds
DEBUG 01-07 10:14:07.874241.874241 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 10:14:07.874928.874928 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 10:14:07.874406.874406 cuda_h.py:19] end allocate_cuda_memory cost 0.00020956993103027344 seconds
DEBUG 01-07 10:14:07.874626.874626 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 10:14:07.874237.874237 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 10:14:07.874662.874662 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 10:14:07.875596.875596 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 29631de0-07e4-4c58-a1f5-0621b92d3278
DEBUG 01-07 10:14:07.875587.875587 client.py:106] call stub.LoadModelAsync
INFO 01-07 10:14:07.876941.876941 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 29631de0-07e4-4c58-a1f5-0621b92d3278
DEBUG 01-07 10:14:07.876247.876247 cuda_h.py:19] end load_into_gpu_async cost 0.0010945796966552734 seconds
DEBUG 01-07 10:14:07.876850.876850 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 10:14:07.876991.876991 cuda_h.py:19] end restore_tensors2 cost 0.00021910667419433594 seconds
DEBUG 01-07 10:14:07.876714.876714 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0018086433410644531 seconds
DEBUG 01-07 10:14:07.878112.878112 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model_multi_device cost 0.0074939727783203125 seconds
DEBUG 01-07 10:14:07.878889.878889 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-07 10:14:07.878044.878044 lmp.py:816] 
DEBUG 01-07 10:14:07.878044.878044 lmp.py:816]   Computing 19 experts on CPU...
DEBUG 01-07 10:14:07.878264.878264 cuda_h.py:19] end cpu_experts_submit cost 0.00010895729064941406 seconds
DEBUG 01-07 10:14:07.878391.878391 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-07 10:14:07.889181.889181 mlpmodule.py:749] group tensors cost 0.011022090911865234 s
DEBUG 01-07 10:14:07.891539.891539 mlpmodule.py:787] pad cost 0.0009622573852539062 s
DEBUG 01-07 10:14:07.891807.891807 mlpmodule.py:793] create cpu tensor cost 3.8623809814453125e-05 s
DEBUG 01-07 10:14:07.891133.891133 mlpmodule.py:798] move to cpu cost 2.9802322387695312e-05 s
DEBUG 01-07 10:14:07.905142.905142 mlpmodule.py:812] group_w3: shape=torch.Size([19, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=54788096
DEBUG 01-07 10:14:07.906387.906387 mlpmodule.py:813] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-07 10:14:07.906576.906576 mlpmodule.py:818] group_w3 first element: 0.04248046875
WARNING 01-07 10:14:07.906322.906322 mlpmodule.py:828] start einsum2
DEBUG 01-07 10:14:07.922518.922518 mlpmodule.py:838] group einsum cost 0.0313875675201416 s
DEBUG 01-07 10:14:07.923848.923848 mlpmodule.py:846] cpy2cputensor cost 0.0003674030303955078 s
DEBUG 01-07 10:14:07.926014.926014 cuda_h.py:19] end wait_cetm_experts cost 0.04764151573181152 seconds
DEBUG 01-07 10:14:07.926335.926335 cuda_h.py:10] start gpu_sexperts
DEBUG 01-07 10:14:07.926267.926267 cuda_h.py:19] end gpu_sexperts cost 0.0005006790161132812 seconds
DEBUG 01-07 10:14:07.926402.926402 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-07 10:14:07.926252.926252 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.4557113647460938e-05 seconds
DEBUG 01-07 10:14:07.926670.926670 cuda_h.py:10] start wait_experts_multi_device
INFO 01-07 10:14:07.926141.926141 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 83c51c67-05ae-4375-bdac-0d4d6edc5323
INFO 01-07 10:14:07.927158.927158 client.py:127] Model loaded
INFO 01-07 10:14:07.927901.927901 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 29631de0-07e4-4c58-a1f5-0621b92d3278
INFO 01-07 10:14:07.928868.928868 client.py:127] Model loaded
DEBUG 01-07 10:14:07.928175.928175 cuda_h.py:19] end wait_experts_multi_device cost 0.0013954639434814453 seconds
DEBUG 01-07 10:14:07.928977.928977 cuda_h.py:10] start gpu_experts_multi_device
DEBUG 01-07 10:14:07.928276.928276 lmp.py:867]   Computing 22 experts on cuda:2...
DEBUG 01-07 10:14:07.929527.929527 mlpmodule.py:533] gpu group tensors cost 0.0004897117614746094 s
DEBUG 01-07 10:14:07.930272.930272 mlpmodule.py:566] gpu pad cost 0.0012216567993164062 s
DEBUG 01-07 10:14:07.931664.931664 mlpmodule.py:584] gpu group einsum cost 0.0005321502685546875 s
DEBUG 01-07 10:14:07.933558.933558 mlpmodule.py:656] gpu experts func einsum cost 0.0043756961822509766 s
DEBUG 01-07 10:14:07.933084.933084 lmp.py:867]   Computing 23 experts on cuda:1...
DEBUG 01-07 10:14:07.934626.934626 mlpmodule.py:533] gpu group tensors cost 0.0004622936248779297 s
DEBUG 01-07 10:14:07.934093.934093 mlpmodule.py:707]  experts func einsum cost 0.056267499923706055 s
DEBUG 01-07 10:14:07.935409.935409 mlpmodule.py:566] gpu pad cost 0.0013587474822998047 s
DEBUG 01-07 10:14:07.936044.936044 mlpmodule.py:584] gpu group einsum cost 0.00043773651123046875 s
DEBUG 01-07 10:14:07.938489.938489 mlpmodule.py:656] gpu experts func einsum cost 0.004469156265258789 s
DEBUG 01-07 10:14:07.938717.938717 cuda_h.py:19] end gpu_experts_multi_device cost 0.0102081298828125 seconds
DEBUG 01-07 10:14:07.938548.938548 cuda_h.py:19] end layer_moe_generate_multi_device_23 cost 0.07049989700317383 seconds
DEBUG 01-07 10:14:07.938887.938887 lmp.py:194] -------------------------------- end prefill layer 23 --------------------------------
DEBUG 01-07 10:14:07.938511.938511 lmp.py:153] -------------------------------- start prefill layer 24 --------------------------------
DEBUG 01-07 10:14:07.938207.938207 cuda_h.py:10] start start_load_qkvogn_s_weight_l_25
DEBUG 01-07 10:14:07.938440.938440 cuda_h.py:10] start start_load_qkvogn_s_weight_l_25
DEBUG 01-07 10:14:07.939322.939322 cuda_h.py:19] end start_load_qkvogn_s_weight_l_25 cost 2.7418136596679688e-05 seconds
DEBUG 01-07 10:14:07.939787.939787 cuda_h.py:19] end start_load_qkvogn_s_weight_l_25 cost 5.7697296142578125e-05 seconds
DEBUG 01-07 10:14:07.939337.939337 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-07 10:14:07.939604.939604 mlpmodule.py:367] cuda:1 cuda:1
DEBUG 01-07 10:14:07.939931.939931 cuda_h.py:10] start sllm_worker_task
DEBUG 01-07 10:14:07.939020.939020 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 10:14:07.939181.939181 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 10:14:07.939318.939318 cuda_h.py:19] end allocate_cuda_memory cost 0.00031113624572753906 seconds
DEBUG 01-07 10:14:07.939791.939791 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 10:14:07.939262.939262 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 10:14:07.939131.939131 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 10:14:07.939927.939927 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 1596c66b-3cfa-4221-b788-21a00f002b08
DEBUG 01-07 10:14:07.939936.939936 client.py:106] call stub.LoadModelAsync
DEBUG 01-07 10:14:07.940707.940707 cuda_h.py:10] start self_attn
INFO 01-07 10:14:07.940172.940172 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 1596c66b-3cfa-4221-b788-21a00f002b08
DEBUG 01-07 10:14:07.940552.940552 cuda_h.py:19] end load_into_gpu_async cost 0.0009503364562988281 seconds
DEBUG 01-07 10:14:07.940255.940255 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 10:14:07.940331.940331 cuda_h.py:19] end restore_tensors2 cost 6.580352783203125e-05 seconds
DEBUG 01-07 10:14:07.940895.940895 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.00156402587890625 seconds
INFO 01-07 10:14:07.940599.940599 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 1596c66b-3cfa-4221-b788-21a00f002b08
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-07 10:14:07.943843.943843 cuda_h.py:19] end self_attn cost 0.003619670867919922 seconds
DEBUG 01-07 10:14:07.944688.944688 cuda_h.py:19] end iln_self_attn_paln cost 0.0051097869873046875 seconds
DEBUG 01-07 10:14:07.944802.944802 cuda_h.py:10] start layer_moe_generate_multi_device_24
DEBUG 01-07 10:14:07.944704.944704 cuda_h.py:10] start gate
DEBUG 01-07 10:14:07.944442.944442 cuda_h.py:19] end gate cost 0.0006518363952636719 seconds
DEBUG 01-07 10:14:07.945841.945841 cuda_h.py:10] start experts_map_get
DEBUG 01-07 10:14:07.945047.945047 lmp.py:744] 
DEBUG 01-07 10:14:07.945047.945047 lmp.py:744] Expert Token Distribution & Multi-Device Allocation:
DEBUG 01-07 10:14:07.945425.945425 lmp.py:745]   Total experts: 64
DEBUG 01-07 10:14:07.945744.945744 lmp.py:746]   CPU experts: 19 (30%)
DEBUG 01-07 10:14:07.945486.945486 lmp.py:747]   GPU experts: 45 (70%)
DEBUG 01-07 10:14:07.945321.945321 lmp.py:748]   Number of GPU devices: 2
DEBUG 01-07 10:14:07.945726.945726 lmp.py:749] 
DEBUG 01-07 10:14:07.945726.945726 lmp.py:749]   Expert ID | Tokens | Device
DEBUG 01-07 10:14:07.945131.945131 lmp.py:750]   -----------------------------------
DEBUG 01-07 10:14:07.945211.945211 lmp.py:767]   Expert 36 |     22 | CPU
DEBUG 01-07 10:14:07.945331.945331 lmp.py:767]   Expert 35 |     29 | CPU
DEBUG 01-07 10:14:07.945735.945735 lmp.py:767]   Expert 46 |     44 | CPU
DEBUG 01-07 10:14:07.945186.945186 lmp.py:767]   Expert 25 |     46 | CPU
DEBUG 01-07 10:14:07.945591.945591 lmp.py:767]   Expert 51 |     56 | CPU
DEBUG 01-07 10:14:07.945518.945518 lmp.py:767]   Expert 16 |     60 | CPU
DEBUG 01-07 10:14:07.945684.945684 lmp.py:767]   Expert  0 |     63 | CPU
DEBUG 01-07 10:14:07.945089.945089 lmp.py:767]   Expert 30 |     63 | CPU
DEBUG 01-07 10:14:07.945732.945732 lmp.py:767]   Expert 43 |     66 | CPU
DEBUG 01-07 10:14:07.945375.945375 lmp.py:767]   Expert 47 |     68 | CPU
DEBUG 01-07 10:14:07.945018.945018 lmp.py:767]   Expert 42 |     74 | CPU
DEBUG 01-07 10:14:07.945423.945423 lmp.py:767]   Expert 39 |     76 | CPU
DEBUG 01-07 10:14:07.945589.945589 lmp.py:767]   Expert 44 |     76 | CPU
DEBUG 01-07 10:14:07.945516.945516 lmp.py:767]   Expert 55 |     76 | CPU
DEBUG 01-07 10:14:07.945206.945206 lmp.py:767]   Expert  2 |     85 | CPU
DEBUG 01-07 10:14:07.945372.945372 lmp.py:767]   Expert  4 |    106 | CPU
DEBUG 01-07 10:14:07.945300.945300 lmp.py:767]   Expert 48 |    116 | CPU
DEBUG 01-07 10:14:07.945989.945989 lmp.py:767]   Expert 33 |    120 | CPU
DEBUG 01-07 10:14:07.945917.945917 lmp.py:767]   Expert  6 |    123 | CPU
DEBUG 01-07 10:14:07.945275.945275 lmp.py:767]   Expert 13 |    126 | GPU1(cuda:2)
DEBUG 01-07 10:14:07.945633.945633 lmp.py:767]   Expert 24 |    126 | GPU0(cuda:1)
DEBUG 01-07 10:14:07.945468.945468 lmp.py:767]   Expert 61 |    127 | GPU0(cuda:1)
DEBUG 01-07 10:14:07.945065.945065 lmp.py:767]   Expert 56 |    128 | GPU1(cuda:2)
DEBUG 01-07 10:14:07.945661.945661 lmp.py:767]   Expert 15 |    134 | GPU1(cuda:2)
DEBUG 01-07 10:14:07.946258.946258 lmp.py:767]   Expert 29 |    134 | GPU0(cuda:1)
DEBUG 01-07 10:14:07.946139.946139 lmp.py:767]   Expert 38 |    136 | GPU0(cuda:1)
DEBUG 01-07 10:14:07.946259.946259 lmp.py:767]   Expert  7 |    143 | GPU1(cuda:2)
DEBUG 01-07 10:14:07.946664.946664 lmp.py:767]   Expert  9 |    147 | GPU0(cuda:1)
DEBUG 01-07 10:14:07.946068.946068 lmp.py:767]   Expert 20 |    152 | GPU0(cuda:1)
DEBUG 01-07 10:14:07.946711.946711 lmp.py:767]   Expert 54 |    152 | GPU1(cuda:2)
DEBUG 01-07 10:14:07.946831.946831 lmp.py:767]   Expert 59 |    153 | GPU1(cuda:2)
DEBUG 01-07 10:14:07.946236.946236 lmp.py:767]   Expert 45 |    155 | GPU0(cuda:1)
DEBUG 01-07 10:14:07.946356.946356 lmp.py:767]   Expert 62 |    156 | GPU1(cuda:2)
DEBUG 01-07 10:14:07.946714.946714 lmp.py:767]   Expert 19 |    158 | GPU1(cuda:2)
DEBUG 01-07 10:14:07.946072.946072 lmp.py:767]   Expert 34 |    183 | GPU0(cuda:1)
DEBUG 01-07 10:14:07.946430.946430 lmp.py:767]   Expert 57 |    183 | GPU0(cuda:1)
DEBUG 01-07 10:14:07.946265.946265 lmp.py:767]   Expert 50 |    190 | GPU1(cuda:2)
DEBUG 01-07 10:14:07.946623.946623 lmp.py:767]   Expert 31 |    200 | GPU1(cuda:2)
DEBUG 01-07 10:14:07.946505.946505 lmp.py:767]   Expert 23 |    205 | GPU0(cuda:1)
DEBUG 01-07 10:14:07.946148.946148 lmp.py:767]   Expert 10 |    207 | GPU0(cuda:1)
DEBUG 01-07 10:14:07.946552.946552 lmp.py:767]   Expert 60 |    214 | GPU1(cuda:2)
DEBUG 01-07 10:14:07.946195.946195 lmp.py:767]   Expert  8 |    215 | GPU1(cuda:2)
DEBUG 01-07 10:14:07.946315.946315 lmp.py:767]   Expert 18 |    219 | GPU0(cuda:1)
DEBUG 01-07 10:14:07.946958.946958 lmp.py:767]   Expert 53 |    224 | GPU1(cuda:2)
DEBUG 01-07 10:14:07.946840.946840 lmp.py:767]   Expert 22 |    225 | GPU0(cuda:1)
DEBUG 01-07 10:14:07.946483.946483 lmp.py:767]   Expert 52 |    228 | GPU0(cuda:1)
DEBUG 01-07 10:14:07.946841.946841 lmp.py:767]   Expert 37 |    232 | GPU1(cuda:2)
DEBUG 01-07 10:14:07.946437.946437 lmp.py:767]   Expert  5 |    238 | GPU1(cuda:2)
DEBUG 01-07 10:14:07.946557.946557 lmp.py:767]   Expert 17 |    244 | GPU0(cuda:1)
DEBUG 01-07 10:14:07.946154.946154 lmp.py:767]   Expert 11 |    263 | GPU0(cuda:1)
DEBUG 01-07 10:14:07.946274.946274 lmp.py:767]   Expert  1 |    270 | GPU1(cuda:2)
DEBUG 01-07 10:14:07.946155.946155 lmp.py:767]   Expert 49 |    274 | GPU1(cuda:2)
DEBUG 01-07 10:14:07.946798.946798 lmp.py:767]   Expert 41 |    279 | GPU0(cuda:1)
DEBUG 01-07 10:14:07.946679.946679 lmp.py:767]   Expert 26 |    285 | GPU0(cuda:1)
DEBUG 01-07 10:14:07.946322.946322 lmp.py:767]   Expert 28 |    287 | GPU1(cuda:2)
DEBUG 01-07 10:14:07.946204.946204 lmp.py:767]   Expert 58 |    290 | GPU1(cuda:2)
DEBUG 01-07 10:14:07.946085.946085 lmp.py:767]   Expert 32 |    300 | GPU0(cuda:1)
DEBUG 01-07 10:14:07.946967.946967 lmp.py:767]   Expert 40 |    303 | GPU1(cuda:2)
DEBUG 01-07 10:14:07.946086.946086 lmp.py:767]   Expert 14 |    310 | GPU0(cuda:1)
DEBUG 01-07 10:14:07.946206.946206 lmp.py:767]   Expert 12 |    323 | GPU1(cuda:2)
DEBUG 01-07 10:14:07.946564.946564 lmp.py:767]   Expert 63 |    334 | GPU0(cuda:1)
DEBUG 01-07 10:14:07.946923.946923 lmp.py:767]   Expert 21 |    383 | GPU1(cuda:2)
DEBUG 01-07 10:14:07.946519.946519 lmp.py:767]   Expert 27 |    664 | GPU1(cuda:2)
DEBUG 01-07 10:14:07.946639.946639 lmp.py:767]   Expert  3 |   1020 | GPU0(cuda:1)
DEBUG 01-07 10:14:07.946090.946090 lmp.py:769] 
DEBUG 01-07 10:14:07.946090.946090 lmp.py:769]   Device Token Distribution:
DEBUG 01-07 10:14:07.946495.946495 lmp.py:770]   CPU:   1369 tokens
DEBUG 01-07 10:14:07.946614.946614 lmp.py:774]   cuda:1:   5462 tokens (22 experts)
DEBUG 01-07 10:14:07.946257.946257 lmp.py:774]   cuda:2:   5457 tokens (23 experts)
DEBUG 01-07 10:14:07.946424.946424 lmp.py:775]   Total GPU:  10919 tokens
DEBUG 01-07 10:14:07.946874.946874 lmp.py:776] ============================================================
DEBUG 01-07 10:14:07.946874.946874 lmp.py:776] 
DEBUG 01-07 10:14:07.946286.946286 cuda_h.py:19] end experts_map_get cost 0.0017745494842529297 seconds
DEBUG 01-07 10:14:07.946121.946121 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model_multi_device
DEBUG 01-07 10:14:07.946182.946182 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 10:14:07.947278.947278 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 10:14:07.947813.947813 cuda_h.py:19] end allocate_cuda_memory cost 0.0003266334533691406 seconds
DEBUG 01-07 10:14:07.947385.947385 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 10:14:07.947857.947857 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 10:14:07.947904.947904 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 10:14:07.947600.947600 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 6d9b88cf-791f-428a-a505-10dc1194cd20
DEBUG 01-07 10:14:07.947857.947857 client.py:106] call stub.LoadModelAsync
INFO 01-07 10:14:07.947532.947532 client.py:127] Model loaded
DEBUG 01-07 10:14:07.948326.948326 cuda_h.py:19] end sllm_worker_task cost 0.008934259414672852 seconds
INFO 01-07 10:14:07.948728.948728 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 6d9b88cf-791f-428a-a505-10dc1194cd20
DEBUG 01-07 10:14:07.948286.948286 cuda_h.py:19] end load_into_gpu_async cost 0.0011568069458007812 seconds
DEBUG 01-07 10:14:07.948512.948512 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 10:14:07.948256.948256 cuda_h.py:19] end restore_tensors2 cost 0.00024318695068359375 seconds
DEBUG 01-07 10:14:07.948834.948834 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.002038717269897461 seconds
DEBUG 01-07 10:14:07.950260.950260 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 10:14:07.950013.950013 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 10:14:07.951750.951750 cuda_h.py:19] end allocate_cuda_memory cost 0.0002238750457763672 seconds
DEBUG 01-07 10:14:07.951924.951924 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 10:14:07.951535.951535 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 10:14:07.951960.951960 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 10:14:07.951086.951086 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 9cf4b079-b1f9-4f8c-bb4f-9f5473dba3f4
DEBUG 01-07 10:14:07.951661.951661 client.py:106] call stub.LoadModelAsync
INFO 01-07 10:14:07.952568.952568 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 9cf4b079-b1f9-4f8c-bb4f-9f5473dba3f4
DEBUG 01-07 10:14:07.952397.952397 cuda_h.py:19] end load_into_gpu_async cost 0.0012302398681640625 seconds
DEBUG 01-07 10:14:07.952193.952193 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 10:14:07.952632.952632 cuda_h.py:19] end restore_tensors2 cost 0.0002288818359375 seconds
DEBUG 01-07 10:14:07.952116.952116 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0019867420196533203 seconds
DEBUG 01-07 10:14:07.954537.954537 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model_multi_device cost 0.007864713668823242 seconds
DEBUG 01-07 10:14:07.954075.954075 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-07 10:14:07.954038.954038 lmp.py:816] 
DEBUG 01-07 10:14:07.954038.954038 lmp.py:816]   Computing 19 experts on CPU...
DEBUG 01-07 10:14:07.954497.954497 cuda_h.py:19] end cpu_experts_submit cost 0.00010824203491210938 seconds
DEBUG 01-07 10:14:07.954908.954908 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-07 10:14:07.961712.961712 mlpmodule.py:749] group tensors cost 0.0068476200103759766 s
DEBUG 01-07 10:14:07.964413.964413 mlpmodule.py:787] pad cost 0.0016682147979736328 s
DEBUG 01-07 10:14:07.964610.964610 mlpmodule.py:793] create cpu tensor cost 6.008148193359375e-05 s
DEBUG 01-07 10:14:07.964037.964037 mlpmodule.py:798] move to cpu cost 4.458427429199219e-05 s
DEBUG 01-07 10:14:07.980264.980264 mlpmodule.py:812] group_w3: shape=torch.Size([19, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=54788096
DEBUG 01-07 10:14:07.980270.980270 mlpmodule.py:813] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-07 10:14:07.980552.980552 mlpmodule.py:818] group_w3 first element: 0.00653076171875
WARNING 01-07 10:14:07.981059.981059 mlpmodule.py:828] start einsum2
DEBUG 01-07 10:14:08.000296.000296 mlpmodule.py:838] group einsum cost 0.03590846061706543 s
DEBUG 01-07 10:14:08.001137.001137 mlpmodule.py:846] cpy2cputensor cost 0.0003981590270996094 s
DEBUG 01-07 10:14:08.003753.003753 cuda_h.py:19] end wait_cetm_experts cost 0.04893207550048828 seconds
DEBUG 01-07 10:14:08.004061.004061 cuda_h.py:10] start gpu_sexperts
DEBUG 01-07 10:14:08.004372.004372 cuda_h.py:19] end gpu_sexperts cost 0.0005359649658203125 seconds
DEBUG 01-07 10:14:08.004162.004162 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-07 10:14:08.004713.004713 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.09808349609375e-05 seconds
DEBUG 01-07 10:14:08.004555.004555 cuda_h.py:10] start wait_experts_multi_device
INFO 01-07 10:14:08.004265.004265 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 6d9b88cf-791f-428a-a505-10dc1194cd20
INFO 01-07 10:14:08.005643.005643 client.py:127] Model loaded
INFO 01-07 10:14:08.005976.005976 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 9cf4b079-b1f9-4f8c-bb4f-9f5473dba3f4
INFO 01-07 10:14:08.006044.006044 client.py:127] Model loaded
DEBUG 01-07 10:14:08.006556.006556 cuda_h.py:19] end wait_experts_multi_device cost 0.0013759136199951172 seconds
DEBUG 01-07 10:14:08.006504.006504 cuda_h.py:10] start gpu_experts_multi_device
DEBUG 01-07 10:14:08.006519.006519 lmp.py:867]   Computing 23 experts on cuda:2...
DEBUG 01-07 10:14:08.007068.007068 mlpmodule.py:533] gpu group tensors cost 0.0005016326904296875 s
DEBUG 01-07 10:14:08.008193.008193 mlpmodule.py:566] gpu pad cost 0.0012886524200439453 s
DEBUG 01-07 10:14:08.009731.009731 mlpmodule.py:584] gpu group einsum cost 0.0005714893341064453 s
DEBUG 01-07 10:14:08.011860.011860 mlpmodule.py:656] gpu experts func einsum cost 0.004563331604003906 s
DEBUG 01-07 10:14:08.011022.011022 lmp.py:867]   Computing 22 experts on cuda:1...
DEBUG 01-07 10:14:08.012921.012921 mlpmodule.py:707]  experts func einsum cost 0.057021379470825195 s
DEBUG 01-07 10:14:08.012530.012530 mlpmodule.py:533] gpu group tensors cost 0.00047659873962402344 s
DEBUG 01-07 10:14:08.013811.013811 mlpmodule.py:566] gpu pad cost 0.0011870861053466797 s
DEBUG 01-07 10:14:08.014668.014668 mlpmodule.py:584] gpu group einsum cost 0.00042319297790527344 s
DEBUG 01-07 10:14:08.016164.016164 mlpmodule.py:656] gpu experts func einsum cost 0.004178762435913086 s
DEBUG 01-07 10:14:08.016406.016406 cuda_h.py:19] end gpu_experts_multi_device cost 0.010290861129760742 seconds
DEBUG 01-07 10:14:08.016283.016283 cuda_h.py:19] end layer_moe_generate_multi_device_24 cost 0.07226920127868652 seconds
DEBUG 01-07 10:14:08.016715.016715 lmp.py:194] -------------------------------- end prefill layer 24 --------------------------------
DEBUG 01-07 10:14:08.016260.016260 lmp.py:153] -------------------------------- start prefill layer 25 --------------------------------
DEBUG 01-07 10:14:08.016956.016956 cuda_h.py:10] start start_load_qkvogn_s_weight_l_26
DEBUG 01-07 10:14:08.016473.016473 cuda_h.py:10] start start_load_qkvogn_s_weight_l_26
DEBUG 01-07 10:14:08.016356.016356 cuda_h.py:19] end start_load_qkvogn_s_weight_l_26 cost 2.6702880859375e-05 seconds
DEBUG 01-07 10:14:08.017297.017297 cuda_h.py:19] end start_load_qkvogn_s_weight_l_26 cost 5.7697296142578125e-05 seconds
DEBUG 01-07 10:14:08.017040.017040 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-07 10:14:08.017445.017445 cuda_h.py:10] start sllm_worker_task
DEBUG 01-07 10:14:08.017621.017621 mlpmodule.py:367] cuda:1 cuda:1
DEBUG 01-07 10:14:08.017305.017305 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 10:14:08.017493.017493 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 10:14:08.017220.017220 cuda_h.py:19] end allocate_cuda_memory cost 0.0002887248992919922 seconds
DEBUG 01-07 10:14:08.017215.017215 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 10:14:08.017925.017925 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 10:14:08.017363.017363 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 10:14:08.017159.017159 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 9d500f8e-abcd-4b7a-9b70-fdd192b46acc
DEBUG 01-07 10:14:08.017261.017261 client.py:106] call stub.LoadModelAsync
DEBUG 01-07 10:14:08.018972.018972 cuda_h.py:10] start self_attn
INFO 01-07 10:14:08.018091.018091 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 9d500f8e-abcd-4b7a-9b70-fdd192b46acc
DEBUG 01-07 10:14:08.018682.018682 cuda_h.py:19] end load_into_gpu_async cost 0.0010495185852050781 seconds
DEBUG 01-07 10:14:08.018001.018001 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 10:14:08.018745.018745 cuda_h.py:19] end restore_tensors2 cost 6.723403930664062e-05 seconds
DEBUG 01-07 10:14:08.018356.018356 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.001638650894165039 seconds
INFO 01-07 10:14:08.019318.019318 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 9d500f8e-abcd-4b7a-9b70-fdd192b46acc
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-07 10:14:08.022841.022841 cuda_h.py:19] end self_attn cost 0.003949165344238281 seconds
DEBUG 01-07 10:14:08.022628.022628 cuda_h.py:19] end iln_self_attn_paln cost 0.005459308624267578 seconds
DEBUG 01-07 10:14:08.022172.022172 cuda_h.py:10] start layer_moe_generate_multi_device_25
DEBUG 01-07 10:14:08.022120.022120 cuda_h.py:10] start gate
DEBUG 01-07 10:14:08.023382.023382 cuda_h.py:19] end gate cost 0.0006511211395263672 seconds
DEBUG 01-07 10:14:08.023450.023450 cuda_h.py:10] start experts_map_get
DEBUG 01-07 10:14:08.023946.023946 lmp.py:744] 
DEBUG 01-07 10:14:08.023946.023946 lmp.py:744] Expert Token Distribution & Multi-Device Allocation:
DEBUG 01-07 10:14:08.023345.023345 lmp.py:745]   Total experts: 64
DEBUG 01-07 10:14:08.023618.023618 lmp.py:746]   CPU experts: 19 (30%)
DEBUG 01-07 10:14:08.023407.023407 lmp.py:747]   GPU experts: 45 (70%)
DEBUG 01-07 10:14:08.023573.023573 lmp.py:748]   Number of GPU devices: 2
DEBUG 01-07 10:14:08.023024.023024 lmp.py:749] 
DEBUG 01-07 10:14:08.023024.023024 lmp.py:749]   Expert ID | Tokens | Device
DEBUG 01-07 10:14:08.023951.023951 lmp.py:750]   -----------------------------------
DEBUG 01-07 10:14:08.023839.023839 lmp.py:767]   Expert 13 |     29 | CPU
DEBUG 01-07 10:14:08.023006.023006 lmp.py:767]   Expert 25 |     39 | CPU
DEBUG 01-07 10:14:08.023933.023933 lmp.py:767]   Expert 44 |     39 | CPU
DEBUG 01-07 10:14:08.023576.023576 lmp.py:767]   Expert  9 |     41 | CPU
DEBUG 01-07 10:14:08.023027.023027 lmp.py:767]   Expert 16 |     48 | CPU
DEBUG 01-07 10:14:08.023478.023478 lmp.py:767]   Expert 22 |     51 | CPU
DEBUG 01-07 10:14:08.023452.023452 lmp.py:767]   Expert 38 |     53 | CPU
DEBUG 01-07 10:14:08.024665.024665 lmp.py:767]   Expert  2 |     56 | CPU
DEBUG 01-07 10:14:08.024115.024115 lmp.py:767]   Expert 33 |     57 | CPU
DEBUG 01-07 10:14:08.024328.024328 lmp.py:767]   Expert 42 |     59 | CPU
DEBUG 01-07 10:14:08.024779.024779 lmp.py:767]   Expert  5 |     66 | CPU
DEBUG 01-07 10:14:08.024468.024468 lmp.py:767]   Expert 23 |     77 | CPU
DEBUG 01-07 10:14:08.024396.024396 lmp.py:767]   Expert 24 |     84 | CPU
DEBUG 01-07 10:14:08.024847.024847 lmp.py:767]   Expert 10 |     87 | CPU
DEBUG 01-07 10:14:08.024298.024298 lmp.py:767]   Expert 59 |    101 | CPU
DEBUG 01-07 10:14:08.024272.024272 lmp.py:767]   Expert 21 |    107 | CPU
DEBUG 01-07 10:14:08.024246.024246 lmp.py:767]   Expert 61 |    114 | CPU
DEBUG 01-07 10:14:08.024697.024697 lmp.py:767]   Expert 46 |    116 | CPU
DEBUG 01-07 10:14:08.024147.024147 lmp.py:767]   Expert 55 |    116 | CPU
DEBUG 01-07 10:14:08.024029.024029 lmp.py:767]   Expert 31 |    118 | GPU0(cuda:1)
DEBUG 01-07 10:14:08.024672.024672 lmp.py:767]   Expert 45 |    121 | GPU0(cuda:1)
DEBUG 01-07 10:14:08.024792.024792 lmp.py:767]   Expert 36 |    139 | GPU1(cuda:2)
DEBUG 01-07 10:14:08.024388.024388 lmp.py:767]   Expert 51 |    142 | GPU1(cuda:2)
DEBUG 01-07 10:14:08.024793.024793 lmp.py:767]   Expert  6 |    145 | GPU0(cuda:1)
DEBUG 01-07 10:14:08.024482.024482 lmp.py:767]   Expert 43 |    145 | GPU0(cuda:1)
DEBUG 01-07 10:14:08.024887.024887 lmp.py:767]   Expert  8 |    147 | GPU1(cuda:2)
DEBUG 01-07 10:14:08.024053.024053 lmp.py:767]   Expert  3 |    151 | GPU0(cuda:1)
DEBUG 01-07 10:14:08.024934.024934 lmp.py:767]   Expert  0 |    154 | GPU1(cuda:2)
DEBUG 01-07 10:14:08.024385.024385 lmp.py:767]   Expert 18 |    157 | GPU0(cuda:1)
DEBUG 01-07 10:14:08.024611.024611 lmp.py:767]   Expert 48 |    158 | GPU1(cuda:2)
DEBUG 01-07 10:14:08.024731.024731 lmp.py:767]   Expert 26 |    161 | GPU1(cuda:2)
DEBUG 01-07 10:14:08.024374.024374 lmp.py:767]   Expert 41 |    166 | GPU0(cuda:1)
DEBUG 01-07 10:14:08.024494.024494 lmp.py:767]   Expert  7 |    175 | GPU0(cuda:1)
DEBUG 01-07 10:14:08.024898.024898 lmp.py:767]   Expert 12 |    176 | GPU1(cuda:2)
DEBUG 01-07 10:14:08.024018.024018 lmp.py:767]   Expert 20 |    186 | GPU0(cuda:1)
DEBUG 01-07 10:14:08.024899.024899 lmp.py:767]   Expert 28 |    187 | GPU1(cuda:2)
DEBUG 01-07 10:14:08.024542.024542 lmp.py:767]   Expert 56 |    188 | GPU0(cuda:1)
DEBUG 01-07 10:14:08.024709.024709 lmp.py:767]   Expert 27 |    190 | GPU1(cuda:2)
DEBUG 01-07 10:14:08.024636.024636 lmp.py:767]   Expert 34 |    195 | GPU0(cuda:1)
DEBUG 01-07 10:14:08.024087.024087 lmp.py:767]   Expert  1 |    196 | GPU1(cuda:2)
DEBUG 01-07 10:14:08.024015.024015 lmp.py:767]   Expert 47 |    200 | GPU0(cuda:1)
DEBUG 01-07 10:14:08.024181.024181 lmp.py:767]   Expert 11 |    216 | GPU1(cuda:2)
DEBUG 01-07 10:14:08.024870.024870 lmp.py:767]   Expert 32 |    219 | GPU0(cuda:1)
DEBUG 01-07 10:14:08.024798.024798 lmp.py:767]   Expert 40 |    222 | GPU1(cuda:2)
DEBUG 01-07 10:14:08.024487.024487 lmp.py:767]   Expert 49 |    232 | GPU0(cuda:1)
DEBUG 01-07 10:14:08.024130.024130 lmp.py:767]   Expert 53 |    234 | GPU1(cuda:2)
DEBUG 01-07 10:14:08.024535.024535 lmp.py:767]   Expert 15 |    241 | GPU0(cuda:1)
DEBUG 01-07 10:14:08.024178.024178 lmp.py:767]   Expert 63 |    244 | GPU1(cuda:2)
DEBUG 01-07 10:14:08.024821.024821 lmp.py:767]   Expert 50 |    246 | GPU0(cuda:1)
DEBUG 01-07 10:14:08.024510.024510 lmp.py:767]   Expert 29 |    247 | GPU0(cuda:1)
DEBUG 01-07 10:14:08.024438.024438 lmp.py:767]   Expert 30 |    247 | GPU1(cuda:2)
DEBUG 01-07 10:14:08.024889.024889 lmp.py:767]   Expert  4 |    249 | GPU1(cuda:2)
DEBUG 01-07 10:14:08.024816.024816 lmp.py:767]   Expert 35 |    274 | GPU0(cuda:1)
DEBUG 01-07 10:14:08.024506.024506 lmp.py:767]   Expert 14 |    275 | GPU1(cuda:2)
DEBUG 01-07 10:14:08.024433.024433 lmp.py:767]   Expert 37 |    303 | GPU1(cuda:2)
DEBUG 01-07 10:14:08.024315.024315 lmp.py:767]   Expert 52 |    338 | GPU0(cuda:1)
DEBUG 01-07 10:14:08.024958.024958 lmp.py:767]   Expert 17 |    355 | GPU0(cuda:1)
DEBUG 01-07 10:14:08.024031.024031 lmp.py:767]   Expert 54 |    373 | GPU1(cuda:2)
DEBUG 01-07 10:14:08.024151.024151 lmp.py:767]   Expert 39 |    390 | GPU0(cuda:1)
DEBUG 01-07 10:14:08.024509.024509 lmp.py:767]   Expert 57 |    409 | GPU1(cuda:2)
DEBUG 01-07 10:14:08.024391.024391 lmp.py:767]   Expert 60 |    456 | GPU0(cuda:1)
DEBUG 01-07 10:14:08.024987.024987 lmp.py:767]   Expert 62 |    457 | GPU1(cuda:2)
DEBUG 01-07 10:14:08.024107.024107 lmp.py:767]   Expert 19 |    544 | GPU1(cuda:2)
DEBUG 01-07 10:14:08.024750.024750 lmp.py:767]   Expert 58 |    580 | GPU0(cuda:1)
DEBUG 01-07 10:14:08.025678.025678 lmp.py:769] 
DEBUG 01-07 10:14:08.025678.025678 lmp.py:769]   Device Token Distribution:
DEBUG 01-07 10:14:08.025082.025082 lmp.py:770]   CPU:   1340 tokens
DEBUG 01-07 10:14:08.025441.025441 lmp.py:774]   cuda:1:   5525 tokens (23 experts)
DEBUG 01-07 10:14:08.025084.025084 lmp.py:774]   cuda:2:   5423 tokens (22 experts)
DEBUG 01-07 10:14:08.025011.025011 lmp.py:775]   Total GPU:  10948 tokens
DEBUG 01-07 10:14:08.025701.025701 lmp.py:776] ============================================================
DEBUG 01-07 10:14:08.025701.025701 lmp.py:776] 
DEBUG 01-07 10:14:08.025019.025019 cuda_h.py:19] end experts_map_get cost 0.0017600059509277344 seconds
DEBUG 01-07 10:14:08.025139.025139 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model_multi_device
DEBUG 01-07 10:14:08.025485.025485 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 10:14:08.025350.025350 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 10:14:08.025121.025121 cuda_h.py:19] end allocate_cuda_memory cost 0.0002536773681640625 seconds
DEBUG 01-07 10:14:08.025971.025971 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 10:14:08.025111.025111 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 10:14:08.025874.025874 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 10:14:08.025000.025000 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, e46a512f-466e-4eae-8e20-059aad8620d9
DEBUG 01-07 10:14:08.025974.025974 client.py:106] call stub.LoadModelAsync
INFO 01-07 10:14:08.026466.026466 client.py:127] Model loaded
DEBUG 01-07 10:14:08.026323.026323 cuda_h.py:19] end sllm_worker_task cost 0.00925135612487793 seconds
INFO 01-07 10:14:08.027156.027156 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, e46a512f-466e-4eae-8e20-059aad8620d9
DEBUG 01-07 10:14:08.027674.027674 cuda_h.py:19] end load_into_gpu_async cost 0.0013957023620605469 seconds
DEBUG 01-07 10:14:08.027569.027569 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 10:14:08.027467.027467 cuda_h.py:19] end restore_tensors2 cost 0.0002701282501220703 seconds
DEBUG 01-07 10:14:08.027549.027549 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.002270221710205078 seconds
DEBUG 01-07 10:14:08.029729.029729 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 10:14:08.029913.029913 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 10:14:08.029875.029875 cuda_h.py:19] end allocate_cuda_memory cost 0.00021338462829589844 seconds
DEBUG 01-07 10:14:08.029002.029002 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 10:14:08.029566.029566 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 10:14:08.030230.030230 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 10:14:08.030687.030687 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, b31eef7b-d9cc-4a75-9217-7280d8d866be
DEBUG 01-07 10:14:08.030732.030732 client.py:106] call stub.LoadModelAsync
INFO 01-07 10:14:08.031087.031087 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, b31eef7b-d9cc-4a75-9217-7280d8d866be
DEBUG 01-07 10:14:08.031162.031162 cuda_h.py:19] end load_into_gpu_async cost 0.001560211181640625 seconds
DEBUG 01-07 10:14:08.031388.031388 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 10:14:08.031808.031808 cuda_h.py:19] end restore_tensors2 cost 0.0002448558807373047 seconds
DEBUG 01-07 10:14:08.031472.031472 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.002348661422729492 seconds
DEBUG 01-07 10:14:08.033212.033212 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model_multi_device cost 0.008661985397338867 seconds
DEBUG 01-07 10:14:08.033333.033333 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-07 10:14:08.033587.033587 lmp.py:816] 
DEBUG 01-07 10:14:08.033587.033587 lmp.py:816]   Computing 19 experts on CPU...
DEBUG 01-07 10:14:08.034569.034569 cuda_h.py:19] end cpu_experts_submit cost 0.00011014938354492188 seconds
DEBUG 01-07 10:14:08.034696.034696 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-07 10:14:08.040807.040807 mlpmodule.py:749] group tensors cost 0.005960702896118164 s
DEBUG 01-07 10:14:08.042960.042960 mlpmodule.py:787] pad cost 0.001220703125 s
DEBUG 01-07 10:14:08.042540.042540 mlpmodule.py:793] create cpu tensor cost 4.6253204345703125e-05 s
DEBUG 01-07 10:14:08.042126.042126 mlpmodule.py:798] move to cpu cost 3.5762786865234375e-05 s
DEBUG 01-07 10:14:08.056853.056853 mlpmodule.py:812] group_w3: shape=torch.Size([19, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=54788096
DEBUG 01-07 10:14:08.056648.056648 mlpmodule.py:813] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-07 10:14:08.056890.056890 mlpmodule.py:818] group_w3 first element: -0.02734375
WARNING 01-07 10:14:08.056590.056590 mlpmodule.py:828] start einsum2
DEBUG 01-07 10:14:08.071238.071238 mlpmodule.py:838] group einsum cost 0.02938675880432129 s
DEBUG 01-07 10:14:08.072537.072537 mlpmodule.py:846] cpy2cputensor cost 0.0003960132598876953 s
DEBUG 01-07 10:14:08.074696.074696 cuda_h.py:19] end wait_cetm_experts cost 0.04089617729187012 seconds
DEBUG 01-07 10:14:08.075878.075878 cuda_h.py:10] start gpu_sexperts
DEBUG 01-07 10:14:08.075221.075221 cuda_h.py:19] end gpu_sexperts cost 0.0005238056182861328 seconds
DEBUG 01-07 10:14:08.075694.075694 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-07 10:14:08.075405.075405 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.7418136596679688e-05 seconds
DEBUG 01-07 10:14:08.075823.075823 cuda_h.py:10] start wait_experts_multi_device
INFO 01-07 10:14:08.075447.075447 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, e46a512f-466e-4eae-8e20-059aad8620d9
INFO 01-07 10:14:08.081173.081173 client.py:127] Model loaded
INFO 01-07 10:14:08.081844.081844 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, b31eef7b-d9cc-4a75-9217-7280d8d866be
INFO 01-07 10:14:08.082386.082386 client.py:127] Model loaded
DEBUG 01-07 10:14:08.083673.083673 cuda_h.py:19] end wait_experts_multi_device cost 0.007155179977416992 seconds
DEBUG 01-07 10:14:08.083674.083674 cuda_h.py:10] start gpu_experts_multi_device
DEBUG 01-07 10:14:08.083404.083404 lmp.py:867]   Computing 22 experts on cuda:2...
DEBUG 01-07 10:14:08.083441.083441 mlpmodule.py:707]  experts func einsum cost 0.04924464225769043 s
DEBUG 01-07 10:14:08.084936.084936 mlpmodule.py:533] gpu group tensors cost 0.0004954338073730469 s
DEBUG 01-07 10:14:08.085225.085225 mlpmodule.py:566] gpu pad cost 0.0012156963348388672 s
DEBUG 01-07 10:14:08.086723.086723 mlpmodule.py:584] gpu group einsum cost 0.00054168701171875 s
DEBUG 01-07 10:14:08.088805.088805 mlpmodule.py:656] gpu experts func einsum cost 0.004300355911254883 s
DEBUG 01-07 10:14:08.088484.088484 lmp.py:867]   Computing 23 experts on cuda:1...
DEBUG 01-07 10:14:08.089221.089221 mlpmodule.py:533] gpu group tensors cost 0.00038743019104003906 s
DEBUG 01-07 10:14:08.090490.090490 mlpmodule.py:566] gpu pad cost 0.0010571479797363281 s
DEBUG 01-07 10:14:08.090685.090685 mlpmodule.py:584] gpu group einsum cost 0.00039839744567871094 s
DEBUG 01-07 10:14:08.092343.092343 mlpmodule.py:656] gpu experts func einsum cost 0.0036368370056152344 s
DEBUG 01-07 10:14:08.092309.092309 cuda_h.py:19] end gpu_experts_multi_device cost 0.009427309036254883 seconds
DEBUG 01-07 10:14:08.092901.092901 cuda_h.py:19] end layer_moe_generate_multi_device_25 cost 0.06999540328979492 seconds
DEBUG 01-07 10:14:08.092558.092558 lmp.py:194] -------------------------------- end prefill layer 25 --------------------------------
DEBUG 01-07 10:14:08.092480.092480 lmp.py:153] -------------------------------- start prefill layer 26 --------------------------------
DEBUG 01-07 10:14:08.092938.092938 cuda_h.py:10] start start_load_qkvogn_s_weight_l_27
DEBUG 01-07 10:14:08.092502.092502 cuda_h.py:10] start start_load_qkvogn_s_weight_l_27
DEBUG 01-07 10:14:08.092384.092384 cuda_h.py:19] end start_load_qkvogn_s_weight_l_27 cost 2.7179718017578125e-05 seconds
DEBUG 01-07 10:14:08.093134.093134 cuda_h.py:19] end start_load_qkvogn_s_weight_l_27 cost 5.7220458984375e-05 seconds
DEBUG 01-07 10:14:08.093730.093730 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-07 10:14:08.093314.093314 cuda_h.py:10] start sllm_worker_task
DEBUG 01-07 10:14:08.093874.093874 mlpmodule.py:367] cuda:1 cuda:1
DEBUG 01-07 10:14:08.093114.093114 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 10:14:08.093025.093025 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 10:14:08.093883.093883 cuda_h.py:19] end allocate_cuda_memory cost 0.00028061866760253906 seconds
DEBUG 01-07 10:14:08.093462.093462 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 10:14:08.093840.093840 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 10:14:08.093755.093755 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 10:14:08.093551.093551 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 79576acd-2ffd-4496-9c60-c32f544e889b
DEBUG 01-07 10:14:08.093507.093507 client.py:106] call stub.LoadModelAsync
DEBUG 01-07 10:14:08.094687.094687 cuda_h.py:10] start self_attn
INFO 01-07 10:14:08.095860.095860 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 79576acd-2ffd-4496-9c60-c32f544e889b
DEBUG 01-07 10:14:08.095928.095928 cuda_h.py:19] end load_into_gpu_async cost 0.0014336109161376953 seconds
DEBUG 01-07 10:14:08.095247.095247 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 10:14:08.095084.095084 cuda_h.py:19] end restore_tensors2 cost 6.437301635742188e-05 seconds
DEBUG 01-07 10:14:08.095171.095171 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0020258426666259766 seconds
INFO 01-07 10:14:08.095007.095007 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 79576acd-2ffd-4496-9c60-c32f544e889b
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-07 10:14:08.097010.097010 cuda_h.py:19] end self_attn cost 0.003442049026489258 seconds
DEBUG 01-07 10:14:08.097477.097477 cuda_h.py:19] end iln_self_attn_paln cost 0.004875659942626953 seconds
DEBUG 01-07 10:14:08.097638.097638 cuda_h.py:10] start layer_moe_generate_multi_device_26
DEBUG 01-07 10:14:08.098685.098685 cuda_h.py:10] start gate
DEBUG 01-07 10:14:08.098326.098326 cuda_h.py:19] end gate cost 0.0007202625274658203 seconds
DEBUG 01-07 10:14:08.098348.098348 cuda_h.py:10] start experts_map_get
DEBUG 01-07 10:14:08.099169.099169 lmp.py:744] 
DEBUG 01-07 10:14:08.099169.099169 lmp.py:744] Expert Token Distribution & Multi-Device Allocation:
DEBUG 01-07 10:14:08.099356.099356 lmp.py:745]   Total experts: 64
DEBUG 01-07 10:14:08.099198.099198 lmp.py:746]   CPU experts: 19 (30%)
DEBUG 01-07 10:14:08.099225.099225 lmp.py:747]   GPU experts: 45 (70%)
DEBUG 01-07 10:14:08.099821.099821 lmp.py:748]   Number of GPU devices: 2
DEBUG 01-07 10:14:08.099464.099464 lmp.py:749] 
DEBUG 01-07 10:14:08.099464.099464 lmp.py:749]   Expert ID | Tokens | Device
DEBUG 01-07 10:14:08.099630.099630 lmp.py:750]   -----------------------------------
DEBUG 01-07 10:14:08.099757.099757 lmp.py:767]   Expert 20 |      9 | CPU
DEBUG 01-07 10:14:08.099162.099162 lmp.py:767]   Expert 61 |     12 | CPU
DEBUG 01-07 10:14:08.099328.099328 lmp.py:767]   Expert 11 |     28 | CPU
DEBUG 01-07 10:14:08.099017.099017 lmp.py:767]   Expert  7 |     36 | CPU
DEBUG 01-07 10:14:08.099706.099706 lmp.py:767]   Expert  3 |     43 | CPU
DEBUG 01-07 10:14:08.099396.099396 lmp.py:767]   Expert 62 |     45 | CPU
DEBUG 01-07 10:14:08.099370.099370 lmp.py:767]   Expert 51 |     47 | CPU
DEBUG 01-07 10:14:08.099582.099582 lmp.py:767]   Expert 30 |     50 | CPU
DEBUG 01-07 10:14:08.099510.099510 lmp.py:767]   Expert 17 |     52 | CPU
DEBUG 01-07 10:14:08.099153.099153 lmp.py:767]   Expert 29 |     57 | CPU
DEBUG 01-07 10:14:08.099796.099796 lmp.py:767]   Expert  6 |     62 | CPU
DEBUG 01-07 10:14:08.099200.099200 lmp.py:767]   Expert  9 |     69 | CPU
DEBUG 01-07 10:14:08.099651.099651 lmp.py:767]   Expert 63 |     75 | CPU
DEBUG 01-07 10:14:08.099625.099625 lmp.py:767]   Expert 38 |     77 | CPU
DEBUG 01-07 10:14:08.099076.099076 lmp.py:767]   Expert 59 |     81 | CPU
DEBUG 01-07 10:14:08.099203.099203 lmp.py:767]   Expert 55 |     82 | CPU
DEBUG 01-07 10:14:08.099654.099654 lmp.py:767]   Expert 19 |     92 | CPU
DEBUG 01-07 10:14:08.099628.099628 lmp.py:767]   Expert  8 |     94 | CPU
DEBUG 01-07 10:14:08.099602.099602 lmp.py:767]   Expert 48 |     94 | CPU
DEBUG 01-07 10:14:08.099483.099483 lmp.py:767]   Expert 49 |    105 | GPU1(cuda:2)
DEBUG 01-07 10:14:08.099603.099603 lmp.py:767]   Expert 22 |    107 | GPU0(cuda:1)
DEBUG 01-07 10:14:08.099630.099630 lmp.py:767]   Expert 36 |    111 | GPU1(cuda:2)
DEBUG 01-07 10:14:08.099704.099704 lmp.py:767]   Expert 24 |    113 | GPU0(cuda:1)
DEBUG 01-07 10:14:08.099777.099777 lmp.py:767]   Expert 50 |    116 | GPU1(cuda:2)
DEBUG 01-07 10:14:08.099897.099897 lmp.py:767]   Expert 34 |    117 | GPU1(cuda:2)
DEBUG 01-07 10:14:08.099540.099540 lmp.py:767]   Expert 42 |    117 | GPU0(cuda:1)
DEBUG 01-07 10:14:08.099183.099183 lmp.py:767]   Expert 39 |    120 | GPU0(cuda:1)
DEBUG 01-07 10:14:08.099303.099303 lmp.py:767]   Expert  4 |    128 | GPU1(cuda:2)
DEBUG 01-07 10:14:08.099946.099946 lmp.py:767]   Expert 15 |    143 | GPU0(cuda:1)
DEBUG 01-07 10:14:08.099589.099589 lmp.py:767]   Expert 37 |    146 | GPU1(cuda:2)
DEBUG 01-07 10:14:08.099470.099470 lmp.py:767]   Expert 23 |    154 | GPU0(cuda:1)
DEBUG 01-07 10:14:08.099782.099782 lmp.py:767]   Expert 41 |    156 | GPU1(cuda:2)
DEBUG 01-07 10:14:08.099902.099902 lmp.py:767]   Expert 56 |    160 | GPU0(cuda:1)
DEBUG 01-07 10:14:08.099783.099783 lmp.py:767]   Expert 16 |    166 | GPU1(cuda:2)
DEBUG 01-07 10:14:08.099665.099665 lmp.py:767]   Expert  1 |    169 | GPU0(cuda:1)
DEBUG 01-07 10:14:08.099546.099546 lmp.py:767]   Expert 44 |    169 | GPU1(cuda:2)
DEBUG 01-07 10:14:08.099666.099666 lmp.py:767]   Expert 60 |    169 | GPU0(cuda:1)
DEBUG 01-07 10:14:08.100547.100547 lmp.py:767]   Expert 43 |    180 | GPU1(cuda:2)
DEBUG 01-07 10:14:08.100905.100905 lmp.py:767]   Expert 21 |    183 | GPU0(cuda:1)
DEBUG 01-07 10:14:08.100502.100502 lmp.py:767]   Expert 53 |    189 | GPU1(cuda:2)
DEBUG 01-07 10:14:08.100814.100814 lmp.py:767]   Expert 47 |    195 | GPU0(cuda:1)
DEBUG 01-07 10:14:08.100695.100695 lmp.py:767]   Expert 33 |    196 | GPU1(cuda:2)
DEBUG 01-07 10:14:08.100577.100577 lmp.py:767]   Expert 12 |    202 | GPU0(cuda:1)
DEBUG 01-07 10:14:08.100220.100220 lmp.py:767]   Expert 13 |    209 | GPU1(cuda:2)
DEBUG 01-07 10:14:08.100101.100101 lmp.py:767]   Expert 32 |    224 | GPU0(cuda:1)
DEBUG 01-07 10:14:08.100982.100982 lmp.py:767]   Expert 28 |    229 | GPU1(cuda:2)
DEBUG 01-07 10:14:08.100341.100341 lmp.py:767]   Expert  0 |    252 | GPU0(cuda:1)
DEBUG 01-07 10:14:08.100984.100984 lmp.py:767]   Expert 31 |    257 | GPU0(cuda:1)
DEBUG 01-07 10:14:08.100865.100865 lmp.py:767]   Expert 54 |    257 | GPU1(cuda:2)
DEBUG 01-07 10:14:08.100462.100462 lmp.py:767]   Expert 26 |    261 | GPU1(cuda:2)
DEBUG 01-07 10:14:08.100343.100343 lmp.py:767]   Expert 10 |    266 | GPU0(cuda:1)
DEBUG 01-07 10:14:08.100986.100986 lmp.py:767]   Expert 18 |    272 | GPU1(cuda:2)
DEBUG 01-07 10:14:08.100106.100106 lmp.py:767]   Expert 57 |    273 | GPU0(cuda:1)
DEBUG 01-07 10:14:08.100987.100987 lmp.py:767]   Expert  2 |    285 | GPU1(cuda:2)
DEBUG 01-07 10:14:08.100107.100107 lmp.py:767]   Expert 58 |    301 | GPU0(cuda:1)
DEBUG 01-07 10:14:08.100750.100750 lmp.py:767]   Expert 40 |    339 | GPU1(cuda:2)
DEBUG 01-07 10:14:08.100631.100631 lmp.py:767]   Expert 25 |    361 | GPU0(cuda:1)
DEBUG 01-07 10:14:08.100274.100274 lmp.py:767]   Expert 45 |    365 | GPU1(cuda:2)
DEBUG 01-07 10:14:08.100216.100216 lmp.py:767]   Expert  5 |    440 | GPU0(cuda:1)
DEBUG 01-07 10:14:08.100051.100051 lmp.py:767]   Expert 35 |    458 | GPU1(cuda:2)
DEBUG 01-07 10:14:08.100932.100932 lmp.py:767]   Expert 27 |    482 | GPU0(cuda:1)
DEBUG 01-07 10:14:08.100814.100814 lmp.py:767]   Expert 46 |    546 | GPU1(cuda:2)
DEBUG 01-07 10:14:08.100695.100695 lmp.py:767]   Expert 52 |    599 | GPU1(cuda:2)
DEBUG 01-07 10:14:08.100338.100338 lmp.py:767]   Expert 14 |    896 | GPU0(cuda:1)
DEBUG 01-07 10:14:08.100027.100027 lmp.py:769] 
DEBUG 01-07 10:14:08.100027.100027 lmp.py:769]   Device Token Distribution:
DEBUG 01-07 10:14:08.100385.100385 lmp.py:770]   CPU:   1105 tokens
DEBUG 01-07 10:14:08.100413.100413 lmp.py:774]   cuda:1:   5584 tokens (22 experts)
DEBUG 01-07 10:14:08.100009.100009 lmp.py:774]   cuda:2:   5599 tokens (23 experts)
DEBUG 01-07 10:14:08.100414.100414 lmp.py:775]   Total GPU:  11183 tokens
DEBUG 01-07 10:14:08.100342.100342 lmp.py:776] ============================================================
DEBUG 01-07 10:14:08.100342.100342 lmp.py:776] 
DEBUG 01-07 10:14:08.100230.100230 cuda_h.py:19] end experts_map_get cost 0.0017800331115722656 seconds
DEBUG 01-07 10:14:08.100111.100111 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model_multi_device
DEBUG 01-07 10:14:08.100219.100219 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 10:14:08.100600.100600 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 10:14:08.101450.101450 cuda_h.py:19] end allocate_cuda_memory cost 0.0008387565612792969 seconds
DEBUG 01-07 10:14:08.101313.101313 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 10:14:08.101785.101785 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 10:14:08.101309.101309 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 10:14:08.101720.101720 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 442590a3-204a-4290-8e83-a41e7d6b4bc7
DEBUG 01-07 10:14:08.101401.101401 client.py:106] call stub.LoadModelAsync
INFO 01-07 10:14:08.102711.102711 client.py:127] Model loaded
DEBUG 01-07 10:14:08.102581.102581 cuda_h.py:19] end sllm_worker_task cost 0.009404420852661133 seconds
INFO 01-07 10:14:08.102820.102820 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 442590a3-204a-4290-8e83-a41e7d6b4bc7
DEBUG 01-07 10:14:08.102472.102472 cuda_h.py:19] end load_into_gpu_async cost 0.0011248588562011719 seconds
DEBUG 01-07 10:14:08.102334.102334 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 10:14:08.103536.103536 cuda_h.py:19] end restore_tensors2 cost 0.0002586841583251953 seconds
DEBUG 01-07 10:14:08.103995.103995 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0025832653045654297 seconds
DEBUG 01-07 10:14:08.105531.105531 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 10:14:08.105337.105337 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 10:14:08.105942.105942 cuda_h.py:19] end allocate_cuda_memory cost 0.0002288818359375 seconds
DEBUG 01-07 10:14:08.105123.105123 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 10:14:08.105448.105448 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 10:14:08.105403.105403 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 10:14:08.105014.105014 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 4b74f84b-bd08-429f-8435-228ba47200c2
DEBUG 01-07 10:14:08.105972.105972 client.py:106] call stub.LoadModelAsync
INFO 01-07 10:14:08.106409.106409 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 4b74f84b-bd08-429f-8435-228ba47200c2
DEBUG 01-07 10:14:08.106960.106960 cuda_h.py:19] end load_into_gpu_async cost 0.0010421276092529297 seconds
DEBUG 01-07 10:14:08.106994.106994 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 10:14:08.107719.107719 cuda_h.py:19] end restore_tensors2 cost 0.000255584716796875 seconds
DEBUG 01-07 10:14:08.107178.107178 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.001855611801147461 seconds
DEBUG 01-07 10:14:08.109073.109073 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model_multi_device cost 0.008505582809448242 seconds
DEBUG 01-07 10:14:08.109531.109531 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-07 10:14:08.109024.109024 lmp.py:816] 
DEBUG 01-07 10:14:08.109024.109024 lmp.py:816]   Computing 19 experts on CPU...
DEBUG 01-07 10:14:08.109768.109768 cuda_h.py:19] end cpu_experts_submit cost 0.00010991096496582031 seconds
DEBUG 01-07 10:14:08.109563.109563 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-07 10:14:08.116133.116133 mlpmodule.py:749] group tensors cost 0.007382392883300781 s
DEBUG 01-07 10:14:08.119280.119280 mlpmodule.py:787] pad cost 0.0016553401947021484 s
DEBUG 01-07 10:14:08.119808.119808 mlpmodule.py:793] create cpu tensor cost 5.817413330078125e-05 s
DEBUG 01-07 10:14:08.119474.119474 mlpmodule.py:798] move to cpu cost 4.506111145019531e-05 s
DEBUG 01-07 10:14:08.131595.131595 mlpmodule.py:812] group_w3: shape=torch.Size([19, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=54788096
DEBUG 01-07 10:14:08.132124.132124 mlpmodule.py:813] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-07 10:14:08.132697.132697 mlpmodule.py:818] group_w3 first element: -0.0024261474609375
WARNING 01-07 10:14:08.132489.132489 mlpmodule.py:828] start einsum2
DEBUG 01-07 10:14:08.148851.148851 mlpmodule.py:838] group einsum cost 0.028760433197021484 s
DEBUG 01-07 10:14:08.149644.149644 mlpmodule.py:846] cpy2cputensor cost 0.0003437995910644531 s
DEBUG 01-07 10:14:08.151200.151200 cuda_h.py:19] end wait_cetm_experts cost 0.042101383209228516 seconds
DEBUG 01-07 10:14:08.151951.151951 cuda_h.py:10] start gpu_sexperts
DEBUG 01-07 10:14:08.152765.152765 cuda_h.py:19] end gpu_sexperts cost 0.0005185604095458984 seconds
DEBUG 01-07 10:14:08.152807.152807 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-07 10:14:08.152372.152372 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.6226043701171875e-05 seconds
DEBUG 01-07 10:14:08.152505.152505 cuda_h.py:10] start wait_experts_multi_device
INFO 01-07 10:14:08.152580.152580 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 442590a3-204a-4290-8e83-a41e7d6b4bc7
INFO 01-07 10:14:08.154501.154501 client.py:127] Model loaded
INFO 01-07 10:14:08.154404.154404 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 4b74f84b-bd08-429f-8435-228ba47200c2
INFO 01-07 10:14:08.159709.159709 client.py:127] Model loaded
DEBUG 01-07 10:14:08.159281.159281 cuda_h.py:19] end wait_experts_multi_device cost 0.00747227668762207 seconds
DEBUG 01-07 10:14:08.159182.159182 cuda_h.py:10] start gpu_experts_multi_device
DEBUG 01-07 10:14:08.159820.159820 lmp.py:867]   Computing 23 experts on cuda:2...
DEBUG 01-07 10:14:08.160904.160904 mlpmodule.py:707]  experts func einsum cost 0.0511937141418457 s
DEBUG 01-07 10:14:08.161315.161315 mlpmodule.py:533] gpu group tensors cost 0.0004966259002685547 s
DEBUG 01-07 10:14:08.162850.162850 mlpmodule.py:566] gpu pad cost 0.0012660026550292969 s
DEBUG 01-07 10:14:08.163010.163010 mlpmodule.py:584] gpu group einsum cost 0.0005383491516113281 s
DEBUG 01-07 10:14:08.165861.165861 mlpmodule.py:656] gpu experts func einsum cost 0.004345893859863281 s
DEBUG 01-07 10:14:08.165320.165320 lmp.py:867]   Computing 22 experts on cuda:1...
DEBUG 01-07 10:14:08.166871.166871 mlpmodule.py:533] gpu group tensors cost 0.0003600120544433594 s
DEBUG 01-07 10:14:08.167125.167125 mlpmodule.py:566] gpu pad cost 0.0010111331939697266 s
DEBUG 01-07 10:14:08.167193.167193 mlpmodule.py:584] gpu group einsum cost 0.0003752708435058594 s
DEBUG 01-07 10:14:08.169904.169904 mlpmodule.py:656] gpu experts func einsum cost 0.003509044647216797 s
DEBUG 01-07 10:14:08.169887.169887 cuda_h.py:19] end gpu_experts_multi_device cost 0.009337186813354492 seconds
DEBUG 01-07 10:14:08.169949.169949 cuda_h.py:19] end layer_moe_generate_multi_device_26 cost 0.07137203216552734 seconds
DEBUG 01-07 10:14:08.169043.169043 lmp.py:194] -------------------------------- end prefill layer 26 --------------------------------
DEBUG 01-07 10:14:08.169581.169581 lmp.py:153] -------------------------------- start prefill layer 27 --------------------------------
DEBUG 01-07 10:14:08.169324.169324 cuda_h.py:10] start start_load_qkvogn_s_weight_l_28
DEBUG 01-07 10:14:08.169299.169299 cuda_h.py:19] end start_load_qkvogn_s_weight_l_28 cost 2.574920654296875e-05 seconds
DEBUG 01-07 10:14:08.169611.169611 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-07 10:14:08.169162.169162 mlpmodule.py:367] cuda:1 cuda:1
DEBUG 01-07 10:14:08.170543.170543 cuda_h.py:10] start self_attn
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-07 10:14:08.172996.172996 cuda_h.py:19] end self_attn cost 0.002595186233520508 seconds
DEBUG 01-07 10:14:08.173317.173317 cuda_h.py:19] end iln_self_attn_paln cost 0.0032660961151123047 seconds
DEBUG 01-07 10:14:08.173955.173955 cuda_h.py:10] start layer_moe_generate_multi_device_27
DEBUG 01-07 10:14:08.173618.173618 cuda_h.py:10] start gate
DEBUG 01-07 10:14:08.173361.173361 cuda_h.py:19] end gate cost 0.0005848407745361328 seconds
DEBUG 01-07 10:14:08.173713.173713 cuda_h.py:10] start experts_map_get
DEBUG 01-07 10:14:08.174495.174495 lmp.py:744] 
DEBUG 01-07 10:14:08.174495.174495 lmp.py:744] Expert Token Distribution & Multi-Device Allocation:
DEBUG 01-07 10:14:08.174920.174920 lmp.py:745]   Total experts: 64
DEBUG 01-07 10:14:08.174046.174046 lmp.py:746]   CPU experts: 19 (30%)
DEBUG 01-07 10:14:08.174835.174835 lmp.py:747]   GPU experts: 45 (70%)
DEBUG 01-07 10:14:08.174716.174716 lmp.py:748]   Number of GPU devices: 2
DEBUG 01-07 10:14:08.174929.174929 lmp.py:749] 
DEBUG 01-07 10:14:08.174929.174929 lmp.py:749]   Expert ID | Tokens | Device
DEBUG 01-07 10:14:08.174380.174380 lmp.py:750]   -----------------------------------
DEBUG 01-07 10:14:08.174268.174268 lmp.py:767]   Expert 18 |     64 | CPU
DEBUG 01-07 10:14:08.174434.174434 lmp.py:767]   Expert 47 |     71 | CPU
DEBUG 01-07 10:14:08.174647.174647 lmp.py:767]   Expert 54 |     73 | CPU
DEBUG 01-07 10:14:08.174859.174859 lmp.py:767]   Expert 23 |     79 | CPU
DEBUG 01-07 10:14:08.174595.174595 lmp.py:767]   Expert 48 |     81 | CPU
DEBUG 01-07 10:14:08.174046.174046 lmp.py:767]   Expert 44 |     83 | CPU
DEBUG 01-07 10:14:08.174735.174735 lmp.py:767]   Expert 20 |     90 | CPU
DEBUG 01-07 10:14:08.174186.174186 lmp.py:767]   Expert 45 |     90 | CPU
DEBUG 01-07 10:14:08.174921.174921 lmp.py:767]   Expert 31 |     97 | CPU
DEBUG 01-07 10:14:08.174895.174895 lmp.py:767]   Expert 36 |    105 | CPU
DEBUG 01-07 10:14:08.174393.174393 lmp.py:767]   Expert 61 |    113 | CPU
DEBUG 01-07 10:14:08.174128.174128 lmp.py:767]   Expert 42 |    117 | CPU
DEBUG 01-07 10:14:08.174625.174625 lmp.py:767]   Expert 33 |    121 | CPU
DEBUG 01-07 10:14:08.174361.174361 lmp.py:767]   Expert 10 |    122 | CPU
DEBUG 01-07 10:14:08.174858.174858 lmp.py:767]   Expert 24 |    124 | CPU
DEBUG 01-07 10:14:08.174832.174832 lmp.py:767]   Expert 43 |    124 | CPU
DEBUG 01-07 10:14:08.174998.174998 lmp.py:767]   Expert 56 |    127 | CPU
DEBUG 01-07 10:14:08.174449.174449 lmp.py:767]   Expert 11 |    128 | CPU
DEBUG 01-07 10:14:08.174662.174662 lmp.py:767]   Expert 49 |    130 | CPU
DEBUG 01-07 10:14:08.174066.174066 lmp.py:767]   Expert  6 |    138 | GPU1(cuda:2)
DEBUG 01-07 10:14:08.174471.174471 lmp.py:767]   Expert 51 |    141 | GPU0(cuda:1)
DEBUG 01-07 10:14:08.174399.174399 lmp.py:767]   Expert  0 |    146 | GPU1(cuda:2)
DEBUG 01-07 10:14:08.174326.174326 lmp.py:767]   Expert 17 |    152 | GPU0(cuda:1)
DEBUG 01-07 10:14:08.174016.174016 lmp.py:767]   Expert 40 |    154 | GPU1(cuda:2)
DEBUG 01-07 10:14:08.174705.174705 lmp.py:767]   Expert  5 |    158 | GPU1(cuda:2)
DEBUG 01-07 10:14:08.174917.174917 lmp.py:767]   Expert 12 |    158 | GPU0(cuda:1)
DEBUG 01-07 10:14:08.174607.174607 lmp.py:767]   Expert 55 |    160 | GPU0(cuda:1)
DEBUG 01-07 10:14:08.174058.174058 lmp.py:767]   Expert 57 |    161 | GPU1(cuda:2)
DEBUG 01-07 10:14:08.174462.174462 lmp.py:767]   Expert 59 |    163 | GPU0(cuda:1)
DEBUG 01-07 10:14:08.174390.174390 lmp.py:767]   Expert 38 |    165 | GPU1(cuda:2)
DEBUG 01-07 10:14:08.174794.174794 lmp.py:767]   Expert 26 |    166 | GPU0(cuda:1)
DEBUG 01-07 10:14:08.174484.174484 lmp.py:767]   Expert 13 |    167 | GPU1(cuda:2)
DEBUG 01-07 10:14:08.174696.174696 lmp.py:767]   Expert 46 |    168 | GPU0(cuda:1)
DEBUG 01-07 10:14:08.174386.174386 lmp.py:767]   Expert 58 |    172 | GPU1(cuda:2)
DEBUG 01-07 10:14:08.174075.174075 lmp.py:767]   Expert 35 |    173 | GPU0(cuda:1)
DEBUG 01-07 10:14:08.174764.174764 lmp.py:767]   Expert  7 |    176 | GPU1(cuda:2)
DEBUG 01-07 10:14:08.174453.174453 lmp.py:767]   Expert 30 |    179 | GPU1(cuda:2)
DEBUG 01-07 10:14:08.174666.174666 lmp.py:767]   Expert 50 |    179 | GPU0(cuda:1)
DEBUG 01-07 10:14:08.174070.174070 lmp.py:767]   Expert 16 |    182 | GPU0(cuda:1)
DEBUG 01-07 10:14:08.174475.174475 lmp.py:767]   Expert 32 |    197 | GPU1(cuda:2)
DEBUG 01-07 10:14:08.175118.175118 lmp.py:767]   Expert 15 |    202 | GPU0(cuda:1)
DEBUG 01-07 10:14:08.175284.175284 lmp.py:767]   Expert 14 |    204 | GPU1(cuda:2)
DEBUG 01-07 10:14:08.175973.175973 lmp.py:767]   Expert  1 |    214 | GPU0(cuda:1)
DEBUG 01-07 10:14:08.175424.175424 lmp.py:767]   Expert  3 |    219 | GPU1(cuda:2)
DEBUG 01-07 10:14:08.175352.175352 lmp.py:767]   Expert  4 |    220 | GPU0(cuda:1)
DEBUG 01-07 10:14:08.175280.175280 lmp.py:767]   Expert 39 |    233 | GPU1(cuda:2)
DEBUG 01-07 10:14:08.175731.175731 lmp.py:767]   Expert 34 |    240 | GPU0(cuda:1)
DEBUG 01-07 10:14:08.175181.175181 lmp.py:767]   Expert 28 |    247 | GPU0(cuda:1)
DEBUG 01-07 10:14:08.175586.175586 lmp.py:767]   Expert 52 |    247 | GPU1(cuda:2)
DEBUG 01-07 10:14:08.175991.175991 lmp.py:767]   Expert 22 |    257 | GPU1(cuda:2)
DEBUG 01-07 10:14:08.175362.175362 lmp.py:767]   Expert 25 |    258 | GPU0(cuda:1)
DEBUG 01-07 10:14:08.175005.175005 lmp.py:767]   Expert  2 |    272 | GPU1(cuda:2)
DEBUG 01-07 10:14:08.175933.175933 lmp.py:767]   Expert 21 |    279 | GPU0(cuda:1)
DEBUG 01-07 10:14:08.175861.175861 lmp.py:767]   Expert 41 |    281 | GPU1(cuda:2)
DEBUG 01-07 10:14:08.175789.175789 lmp.py:767]   Expert 60 |    284 | GPU0(cuda:1)
DEBUG 01-07 10:14:08.175478.175478 lmp.py:767]   Expert 29 |    289 | GPU1(cuda:2)
DEBUG 01-07 10:14:08.175929.175929 lmp.py:767]   Expert 63 |    292 | GPU0(cuda:1)
DEBUG 01-07 10:14:08.175618.175618 lmp.py:767]   Expert 62 |    294 | GPU1(cuda:2)
DEBUG 01-07 10:14:08.175307.175307 lmp.py:767]   Expert 27 |    303 | GPU0(cuda:1)
DEBUG 01-07 10:14:08.175997.175997 lmp.py:767]   Expert 37 |    332 | GPU0(cuda:1)
DEBUG 01-07 10:14:08.175447.175447 lmp.py:767]   Expert 53 |    332 | GPU1(cuda:2)
DEBUG 01-07 10:14:08.175898.175898 lmp.py:767]   Expert  8 |    335 | GPU1(cuda:2)
DEBUG 01-07 10:14:08.175065.175065 lmp.py:767]   Expert 19 |    437 | GPU1(cuda:2)
DEBUG 01-07 10:14:08.175231.175231 lmp.py:767]   Expert  9 |    623 | GPU0(cuda:1)
DEBUG 01-07 10:14:08.175158.175158 lmp.py:769] 
DEBUG 01-07 10:14:08.175158.175158 lmp.py:769]   Device Token Distribution:
DEBUG 01-07 10:14:08.175563.175563 lmp.py:770]   CPU:   1939 tokens
DEBUG 01-07 10:14:08.175683.175683 lmp.py:774]   cuda:1:   5136 tokens (22 experts)
DEBUG 01-07 10:14:08.175326.175326 lmp.py:774]   cuda:2:   5213 tokens (23 experts)
DEBUG 01-07 10:14:08.175538.175538 lmp.py:775]   Total GPU:  10349 tokens
DEBUG 01-07 10:14:08.175227.175227 lmp.py:776] ============================================================
DEBUG 01-07 10:14:08.175227.175227 lmp.py:776] 
DEBUG 01-07 10:14:08.175116.175116 cuda_h.py:19] end experts_map_get cost 0.0017075538635253906 seconds
DEBUG 01-07 10:14:08.175997.175997 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model_multi_device
DEBUG 01-07 10:14:08.175297.175297 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 10:14:08.175876.175876 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 10:14:08.176338.176338 cuda_h.py:19] end allocate_cuda_memory cost 0.00030875205993652344 seconds
DEBUG 01-07 10:14:08.176426.176426 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 10:14:08.176514.176514 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 10:14:08.176806.176806 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 10:14:08.176218.176218 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, f8103dae-f8fa-4c09-b919-80d62fc9e67b
DEBUG 01-07 10:14:08.176859.176859 client.py:106] call stub.LoadModelAsync
INFO 01-07 10:14:08.177861.177861 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, f8103dae-f8fa-4c09-b919-80d62fc9e67b
DEBUG 01-07 10:14:08.177604.177604 cuda_h.py:19] end load_into_gpu_async cost 0.0013298988342285156 seconds
DEBUG 01-07 10:14:08.177162.177162 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 10:14:08.177159.177159 cuda_h.py:19] end restore_tensors2 cost 0.00028514862060546875 seconds
DEBUG 01-07 10:14:08.177532.177532 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0022537708282470703 seconds
DEBUG 01-07 10:14:08.179161.179161 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 10:14:08.180212.180212 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 10:14:08.180970.180970 cuda_h.py:19] end allocate_cuda_memory cost 0.00023794174194335938 seconds
DEBUG 01-07 10:14:08.180820.180820 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 10:14:08.180026.180026 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 10:14:08.180319.180319 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 10:14:08.180399.180399 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 8ce7a508-5ab8-45fc-aa91-47c5d79169e5
DEBUG 01-07 10:14:08.208013.208013 client.py:106] call stub.LoadModelAsync
INFO 01-07 10:14:08.210197.210197 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 8ce7a508-5ab8-45fc-aa91-47c5d79169e5
DEBUG 01-07 10:14:08.210511.210511 cuda_h.py:19] end load_into_gpu_async cost 0.029895782470703125 seconds
DEBUG 01-07 10:14:08.210260.210260 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 10:14:08.210767.210767 cuda_h.py:19] end restore_tensors2 cost 0.00027370452880859375 seconds
DEBUG 01-07 10:14:08.210702.210702 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.03074359893798828 seconds
DEBUG 01-07 10:14:08.212140.212140 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model_multi_device cost 0.03708529472351074 seconds
DEBUG 01-07 10:14:08.212076.212076 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-07 10:14:08.212861.212861 lmp.py:816] 
DEBUG 01-07 10:14:08.212861.212861 lmp.py:816]   Computing 19 experts on CPU...
DEBUG 01-07 10:14:08.212095.212095 cuda_h.py:19] end cpu_experts_submit cost 0.00012230873107910156 seconds
DEBUG 01-07 10:14:08.212288.212288 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-07 10:14:08.223567.223567 mlpmodule.py:749] group tensors cost 0.010713338851928711 s
DEBUG 01-07 10:14:08.226481.226481 mlpmodule.py:787] pad cost 0.0017349720001220703 s
DEBUG 01-07 10:14:08.226400.226400 mlpmodule.py:793] create cpu tensor cost 6.29425048828125e-05 s
DEBUG 01-07 10:14:08.226457.226457 mlpmodule.py:798] move to cpu cost 4.9114227294921875e-05 s
DEBUG 01-07 10:14:08.240216.240216 mlpmodule.py:812] group_w3: shape=torch.Size([19, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=54788096
DEBUG 01-07 10:14:08.241778.241778 mlpmodule.py:813] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-07 10:14:08.241729.241729 mlpmodule.py:818] group_w3 first element: -0.01263427734375
WARNING 01-07 10:14:08.241931.241931 mlpmodule.py:828] start einsum2
DEBUG 01-07 10:14:08.259772.259772 mlpmodule.py:838] group einsum cost 0.03264784812927246 s
DEBUG 01-07 10:14:08.259718.259718 mlpmodule.py:846] cpy2cputensor cost 0.0003631114959716797 s
DEBUG 01-07 10:14:08.262036.262036 cuda_h.py:19] end wait_cetm_experts cost 0.049592018127441406 seconds
DEBUG 01-07 10:14:08.262927.262927 cuda_h.py:10] start gpu_sexperts
DEBUG 01-07 10:14:08.263720.263720 cuda_h.py:19] end gpu_sexperts cost 0.0005040168762207031 seconds
DEBUG 01-07 10:14:08.263616.263616 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-07 10:14:08.263876.263876 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 1.1920928955078125e-05 seconds
DEBUG 01-07 10:14:08.263056.263056 cuda_h.py:10] start wait_experts_multi_device
INFO 01-07 10:14:08.263203.263203 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, f8103dae-f8fa-4c09-b919-80d62fc9e67b
INFO 01-07 10:14:08.264590.264590 client.py:127] Model loaded
INFO 01-07 10:14:08.264333.264333 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 8ce7a508-5ab8-45fc-aa91-47c5d79169e5
INFO 01-07 10:14:08.264303.264303 client.py:127] Model loaded
DEBUG 01-07 10:14:08.264630.264630 cuda_h.py:19] end wait_experts_multi_device cost 0.0014753341674804688 seconds
DEBUG 01-07 10:14:08.264386.264386 cuda_h.py:10] start gpu_experts_multi_device
DEBUG 01-07 10:14:08.264592.264592 lmp.py:867]   Computing 23 experts on cuda:2...
DEBUG 01-07 10:14:08.266367.266367 mlpmodule.py:533] gpu group tensors cost 0.0004730224609375 s
DEBUG 01-07 10:14:08.267663.267663 mlpmodule.py:566] gpu pad cost 0.0012743473052978516 s
DEBUG 01-07 10:14:08.268565.268565 mlpmodule.py:584] gpu group einsum cost 0.0005562305450439453 s
DEBUG 01-07 10:14:08.270854.270854 mlpmodule.py:656] gpu experts func einsum cost 0.004555702209472656 s
DEBUG 01-07 10:14:08.270884.270884 lmp.py:867]   Computing 22 experts on cuda:1...
DEBUG 01-07 10:14:08.270868.270868 mlpmodule.py:707]  experts func einsum cost 0.057704925537109375 s
DEBUG 01-07 10:14:08.271928.271928 mlpmodule.py:533] gpu group tensors cost 0.0004475116729736328 s
DEBUG 01-07 10:14:08.272574.272574 mlpmodule.py:566] gpu pad cost 0.00121307373046875 s
DEBUG 01-07 10:14:08.273491.273491 mlpmodule.py:584] gpu group einsum cost 0.0004317760467529297 s
DEBUG 01-07 10:14:08.275410.275410 mlpmodule.py:656] gpu experts func einsum cost 0.004177570343017578 s
DEBUG 01-07 10:14:08.275831.275831 cuda_h.py:19] end gpu_experts_multi_device cost 0.010306835174560547 seconds
DEBUG 01-07 10:14:08.275960.275960 cuda_h.py:19] end layer_moe_generate_multi_device_27 cost 0.10218620300292969 seconds
DEBUG 01-07 10:14:08.275214.275214 lmp.py:194] -------------------------------- end prefill layer 27 --------------------------------
DEBUG 01-07 10:14:08.275666.275666 cuda_h.py:19] end prefill_layer cost 2.0446932315826416 seconds
DEBUG 01-07 10:14:10.469387.469387 cuda_h.py:10] start generate_input_ids
generate input ids cost 0.09496450424194336 s
DEBUG 01-07 10:14:10.840865.840865 cuda_h.py:19] end generate_input_ids cost 0.36878490447998047 seconds
DEBUG 01-07 10:14:10.840918.840918 cuda_h.py:10] start init_cache
DEBUG 01-07 10:14:10.840120.840120 cuda_h.py:19] end init_cache cost 5.7220458984375e-05 seconds
DEBUG 01-07 10:14:13.179797.179797 cuda_h.py:10] start init_weights
DEBUG 01-07 10:14:13.180299.180299 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 10:14:13.181735.181735 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 10:14:13.182322.182322 cuda_h.py:19] end allocate_cuda_memory cost 0.001140594482421875 seconds
DEBUG 01-07 10:14:13.182093.182093 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 10:14:13.183710.183710 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 10:14:13.183354.183354 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 10:14:13.183249.183249 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 8d384903-0c23-46d4-9e7b-034c6fde0b57
DEBUG 01-07 10:14:13.183670.183670 client.py:106] call stub.LoadModelAsync
INFO 01-07 10:14:13.184858.184858 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 8d384903-0c23-46d4-9e7b-034c6fde0b57
DEBUG 01-07 10:14:13.184363.184363 cuda_h.py:19] end load_into_gpu_async cost 0.001499176025390625 seconds
DEBUG 01-07 10:14:13.184397.184397 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 10:14:13.184426.184426 cuda_h.py:19] end restore_tensors2 cost 6.341934204101562e-05 seconds
DEBUG 01-07 10:14:13.184036.184036 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0034761428833007812 seconds
INFO 01-07 10:14:13.184078.184078 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 8d384903-0c23-46d4-9e7b-034c6fde0b57
INFO 01-07 10:14:13.263307.263307 client.py:127] Model loaded
DEBUG 01-07 10:14:13.263126.263126 cuda_h.py:10] start load_qkvogns_weight_l_0
DEBUG 01-07 10:14:13.263582.263582 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 10:14:13.263659.263659 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 10:14:13.264143.264143 cuda_h.py:19] end allocate_cuda_memory cost 0.000339508056640625 seconds
DEBUG 01-07 10:14:13.264764.264764 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 10:14:13.264377.264377 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 10:14:13.264320.264320 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 10:14:13.264939.264939 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, f4a146b4-a4dc-4242-90a7-3a7a0f4b49ea
DEBUG 01-07 10:14:13.264792.264792 client.py:106] call stub.LoadModelAsync
INFO 01-07 10:14:13.266272.266272 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, f4a146b4-a4dc-4242-90a7-3a7a0f4b49ea
DEBUG 01-07 10:14:13.266405.266405 cuda_h.py:19] end load_into_gpu_async cost 0.0020072460174560547 seconds
DEBUG 01-07 10:14:13.266818.266818 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 10:14:13.266489.266489 cuda_h.py:19] end restore_tensors2 cost 0.00015783309936523438 seconds
DEBUG 01-07 10:14:13.266916.266916 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.003179788589477539 seconds
INFO 01-07 10:14:13.266303.266303 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, f4a146b4-a4dc-4242-90a7-3a7a0f4b49ea
INFO 01-07 10:14:13.283638.283638 client.py:127] Model loaded
DEBUG 01-07 10:14:13.284580.284580 cuda_h.py:19] end load_qkvogns_weight_l_0 cost 0.020739316940307617 seconds
DEBUG 01-07 10:14:13.284078.284078 cuda_h.py:19] end init_weights cost 0.1041879653930664 seconds
DEBUG 01-07 10:14:13.284617.284617 cuda_h.py:10] start copy_emodel
DEBUG 01-07 10:14:14.385395.385395 cuda_h.py:19] end copy_emodel cost 1.1006803512573242 seconds
DEBUG 01-07 10:14:14.386020.386020 cuda_h.py:10] start init_hmv
DEBUG 01-07 10:14:14.529740.529740 mlpmodule.py:207] restore_hm_state_dict2model loaded 5265 expert tensors (including shared_experts) for Deepseek model
DEBUG 01-07 10:14:14.530455.530455 cuda_h.py:19] end init_hmv cost 0.14425277709960938 seconds
DEBUG 01-07 10:14:14.530807.530807 cuda_h.py:10] start init_inputs_tokens
DEBUG 01-07 10:14:14.530281.530281 cuda_h.py:19] end init_inputs_tokens cost 0.00028514862060546875 seconds
DEBUG 01-07 10:14:14.531097.531097 cuda_h.py:10] start prefill_layer
DEBUG 01-07 10:14:14.531536.531536 lmp.py:153] -------------------------------- start prefill layer 0 --------------------------------
DEBUG 01-07 10:14:14.531954.531954 cuda_h.py:10] start start_load_qkvogn_s_weight_l_1
DEBUG 01-07 10:14:14.531279.531279 cuda_h.py:10] start start_load_qkvogn_s_weight_l_1
DEBUG 01-07 10:14:14.531944.531944 cuda_h.py:19] end start_load_qkvogn_s_weight_l_1 cost 3.981590270996094e-05 seconds
DEBUG 01-07 10:14:14.531621.531621 cuda_h.py:19] end start_load_qkvogn_s_weight_l_1 cost 9.012222290039062e-05 seconds
DEBUG 01-07 10:14:14.531171.531171 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-07 10:14:14.531630.531630 mlpmodule.py:367] cuda:1 cuda:1
DEBUG 01-07 10:14:14.531057.531057 cuda_h.py:10] start sllm_worker_task
DEBUG 01-07 10:14:14.531396.531396 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 10:14:14.531010.531010 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 10:14:14.532837.532837 cuda_h.py:19] end allocate_cuda_memory cost 0.00046133995056152344 seconds
DEBUG 01-07 10:14:14.532822.532822 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 10:14:14.532514.532514 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 10:14:14.532074.532074 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 10:14:14.532261.532261 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 804be68d-dfff-4674-b3ee-8bc650afcfe5
DEBUG 01-07 10:14:14.532015.532015 client.py:106] call stub.LoadModelAsync
DEBUG 01-07 10:14:14.533467.533467 cuda_h.py:10] start self_attn
INFO 01-07 10:14:14.534779.534779 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 804be68d-dfff-4674-b3ee-8bc650afcfe5
DEBUG 01-07 10:14:14.534724.534724 cuda_h.py:19] end load_into_gpu_async cost 0.0019083023071289062 seconds
DEBUG 01-07 10:14:14.534541.534541 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 10:14:14.534097.534097 cuda_h.py:19] end restore_tensors2 cost 0.0001266002655029297 seconds
DEBUG 01-07 10:14:14.534027.534027 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0031456947326660156 seconds
INFO 01-07 10:14:14.534356.534356 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 804be68d-dfff-4674-b3ee-8bc650afcfe5
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-07 10:14:14.537982.537982 cuda_h.py:19] end self_attn cost 0.003854036331176758 seconds
DEBUG 01-07 10:14:14.537966.537966 cuda_h.py:19] end iln_self_attn_paln cost 0.0061032772064208984 seconds
DEBUG 01-07 10:14:14.537696.537696 cuda_h.py:10] start dense_mlp
INFO 01-07 10:14:14.543077.543077 client.py:127] Model loaded
DEBUG 01-07 10:14:14.544647.544647 cuda_h.py:19] end sllm_worker_task cost 0.012645959854125977 seconds
DEBUG 01-07 10:14:14.544031.544031 cuda_h.py:19] end dense_mlp cost 0.006983757019042969 seconds
DEBUG 01-07 10:14:14.544856.544856 lmp.py:194] -------------------------------- end prefill layer 0 --------------------------------
DEBUG 01-07 10:14:14.544234.544234 lmp.py:153] -------------------------------- start prefill layer 1 --------------------------------
DEBUG 01-07 10:14:14.544215.544215 cuda_h.py:10] start start_load_qkvogn_s_weight_l_2
DEBUG 01-07 10:14:14.544978.544978 cuda_h.py:10] start start_load_qkvogn_s_weight_l_2
DEBUG 01-07 10:14:14.544668.544668 cuda_h.py:19] end start_load_qkvogn_s_weight_l_2 cost 2.288818359375e-05 seconds
DEBUG 01-07 10:14:14.544087.544087 cuda_h.py:19] end start_load_qkvogn_s_weight_l_2 cost 5.3882598876953125e-05 seconds
DEBUG 01-07 10:14:14.544829.544829 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-07 10:14:14.544871.544871 mlpmodule.py:367] cuda:1 cuda:1
DEBUG 01-07 10:14:14.544251.544251 cuda_h.py:10] start sllm_worker_task
DEBUG 01-07 10:14:14.545328.545328 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 10:14:14.545796.545796 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 10:14:14.545825.545825 cuda_h.py:19] end allocate_cuda_memory cost 0.0003600120544433594 seconds
DEBUG 01-07 10:14:14.545903.545903 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 10:14:14.545470.545470 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 10:14:14.546924.546924 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 10:14:14.546570.546570 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, c21ee239-329b-4f78-a82f-f65580c73919
DEBUG 01-07 10:14:14.546245.546245 client.py:106] call stub.LoadModelAsync
DEBUG 01-07 10:14:14.546360.546360 cuda_h.py:10] start self_attn
INFO 01-07 10:14:14.547090.547090 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, c21ee239-329b-4f78-a82f-f65580c73919
DEBUG 01-07 10:14:14.547824.547824 cuda_h.py:19] end load_into_gpu_async cost 0.001659393310546875 seconds
DEBUG 01-07 10:14:14.547807.547807 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 10:14:14.547675.547675 cuda_h.py:19] end restore_tensors2 cost 0.0001289844512939453 seconds
DEBUG 01-07 10:14:14.547195.547195 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.002858877182006836 seconds
INFO 01-07 10:14:14.548001.548001 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, c21ee239-329b-4f78-a82f-f65580c73919
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-07 10:14:14.550181.550181 cuda_h.py:19] end self_attn cost 0.0035924911499023438 seconds
DEBUG 01-07 10:14:14.550404.550404 cuda_h.py:19] end iln_self_attn_paln cost 0.005659818649291992 seconds
DEBUG 01-07 10:14:14.550902.550902 cuda_h.py:10] start layer_moe_generate_multi_device_1
DEBUG 01-07 10:14:14.550903.550903 cuda_h.py:10] start gate
DEBUG 01-07 10:14:14.551331.551331 cuda_h.py:19] end gate cost 0.0008730888366699219 seconds
DEBUG 01-07 10:14:14.551214.551214 cuda_h.py:10] start experts_map_get
DEBUG 01-07 10:14:14.551737.551737 lmp.py:744] 
DEBUG 01-07 10:14:14.551737.551737 lmp.py:744] Expert Token Distribution & Multi-Device Allocation:
DEBUG 01-07 10:14:14.551089.551089 lmp.py:745]   Total experts: 64
DEBUG 01-07 10:14:14.551176.551176 lmp.py:746]   CPU experts: 19 (30%)
DEBUG 01-07 10:14:14.551257.551257 lmp.py:747]   GPU experts: 45 (70%)
DEBUG 01-07 10:14:14.552953.552953 lmp.py:748]   Number of GPU devices: 2
DEBUG 01-07 10:14:14.552980.552980 lmp.py:749] 
DEBUG 01-07 10:14:14.552980.552980 lmp.py:749]   Expert ID | Tokens | Device
DEBUG 01-07 10:14:14.552961.552961 lmp.py:750]   -----------------------------------
DEBUG 01-07 10:14:14.552525.552525 lmp.py:767]   Expert 25 |     64 | CPU
DEBUG 01-07 10:14:14.552936.552936 lmp.py:767]   Expert 54 |     67 | CPU
DEBUG 01-07 10:14:14.552109.552109 lmp.py:767]   Expert  3 |     68 | CPU
DEBUG 01-07 10:14:14.552613.552613 lmp.py:767]   Expert 31 |     72 | CPU
DEBUG 01-07 10:14:14.552878.552878 lmp.py:767]   Expert 55 |     72 | CPU
DEBUG 01-07 10:14:14.552144.552144 lmp.py:767]   Expert 62 |     87 | CPU
DEBUG 01-07 10:14:14.552648.552648 lmp.py:767]   Expert 18 |     88 | CPU
DEBUG 01-07 10:14:14.552397.552397 lmp.py:767]   Expert 52 |     98 | CPU
DEBUG 01-07 10:14:14.552431.552431 lmp.py:767]   Expert 22 |    100 | CPU
DEBUG 01-07 10:14:14.552458.552458 lmp.py:767]   Expert 47 |    104 | CPU
DEBUG 01-07 10:14:14.552916.552916 lmp.py:767]   Expert  0 |    113 | CPU
DEBUG 01-07 10:14:14.552897.552897 lmp.py:767]   Expert 37 |    117 | CPU
DEBUG 01-07 10:14:14.552116.552116 lmp.py:767]   Expert 27 |    121 | CPU
DEBUG 01-07 10:14:14.552382.552382 lmp.py:767]   Expert 32 |    123 | CPU
DEBUG 01-07 10:14:14.552694.552694 lmp.py:767]   Expert 41 |    130 | CPU
DEBUG 01-07 10:14:14.552357.552357 lmp.py:767]   Expert 44 |    131 | CPU
DEBUG 01-07 10:14:14.552907.552907 lmp.py:767]   Expert 28 |    136 | CPU
DEBUG 01-07 10:14:14.552126.552126 lmp.py:767]   Expert 13 |    138 | CPU
DEBUG 01-07 10:14:14.552591.552591 lmp.py:767]   Expert 58 |    140 | CPU
DEBUG 01-07 10:14:14.552579.552579 lmp.py:767]   Expert 60 |    144 | GPU0(cuda:1)
DEBUG 01-07 10:14:14.552705.552705 lmp.py:767]   Expert 43 |    147 | GPU1(cuda:2)
DEBUG 01-07 10:14:14.552640.552640 lmp.py:767]   Expert  1 |    150 | GPU0(cuda:1)
DEBUG 01-07 10:14:14.552289.552289 lmp.py:767]   Expert 38 |    153 | GPU1(cuda:2)
DEBUG 01-07 10:14:14.552985.552985 lmp.py:767]   Expert 49 |    154 | GPU0(cuda:1)
DEBUG 01-07 10:14:14.552728.552728 lmp.py:767]   Expert 51 |    155 | GPU0(cuda:1)
DEBUG 01-07 10:14:14.552186.552186 lmp.py:767]   Expert 34 |    161 | GPU1(cuda:2)
DEBUG 01-07 10:14:14.552166.552166 lmp.py:767]   Expert 35 |    164 | GPU0(cuda:1)
DEBUG 01-07 10:14:14.552670.552670 lmp.py:767]   Expert 36 |    168 | GPU1(cuda:2)
DEBUG 01-07 10:14:14.552274.552274 lmp.py:767]   Expert 11 |    170 | GPU1(cuda:2)
DEBUG 01-07 10:14:14.552069.552069 lmp.py:767]   Expert 17 |    170 | GPU0(cuda:1)
DEBUG 01-07 10:14:14.552527.552527 lmp.py:767]   Expert 59 |    174 | GPU1(cuda:2)
DEBUG 01-07 10:14:14.552561.552561 lmp.py:767]   Expert 10 |    180 | GPU0(cuda:1)
DEBUG 01-07 10:14:14.552688.552688 lmp.py:767]   Expert 20 |    182 | GPU0(cuda:1)
DEBUG 01-07 10:14:14.552907.552907 lmp.py:767]   Expert  2 |    186 | GPU1(cuda:2)
DEBUG 01-07 10:14:14.552987.552987 lmp.py:767]   Expert 39 |    189 | GPU0(cuda:1)
DEBUG 01-07 10:14:14.552160.552160 lmp.py:767]   Expert 33 |    197 | GPU1(cuda:2)
DEBUG 01-07 10:14:14.552333.552333 lmp.py:767]   Expert 12 |    198 | GPU0(cuda:1)
DEBUG 01-07 10:14:14.552791.552791 lmp.py:767]   Expert 21 |    198 | GPU1(cuda:2)
DEBUG 01-07 10:14:14.552772.552772 lmp.py:767]   Expert 48 |    198 | GPU0(cuda:1)
DEBUG 01-07 10:14:14.552276.552276 lmp.py:767]   Expert 15 |    199 | GPU1(cuda:2)
DEBUG 01-07 10:14:14.552018.552018 lmp.py:767]   Expert 53 |    204 | GPU1(cuda:2)
DEBUG 01-07 10:14:14.552482.552482 lmp.py:767]   Expert 19 |    220 | GPU0(cuda:1)
DEBUG 01-07 10:14:14.553993.553993 lmp.py:767]   Expert 26 |    221 | GPU0(cuda:1)
DEBUG 01-07 10:14:14.553212.553212 lmp.py:767]   Expert 30 |    221 | GPU0(cuda:1)
DEBUG 01-07 10:14:14.553862.553862 lmp.py:767]   Expert 45 |    221 | GPU1(cuda:2)
DEBUG 01-07 10:14:14.553035.553035 lmp.py:767]   Expert  5 |    227 | GPU1(cuda:2)
DEBUG 01-07 10:14:14.553446.553446 lmp.py:767]   Expert  4 |    229 | GPU1(cuda:2)
DEBUG 01-07 10:14:14.553427.553427 lmp.py:767]   Expert 24 |    229 | GPU0(cuda:1)
DEBUG 01-07 10:14:14.553170.553170 lmp.py:767]   Expert 42 |    242 | GPU1(cuda:2)
DEBUG 01-07 10:14:14.553912.553912 lmp.py:767]   Expert 50 |    245 | GPU0(cuda:1)
DEBUG 01-07 10:14:14.553562.553562 lmp.py:767]   Expert 29 |    254 | GPU0(cuda:1)
DEBUG 01-07 10:14:14.553980.553980 lmp.py:767]   Expert 56 |    262 | GPU1(cuda:2)
DEBUG 01-07 10:14:14.553167.553167 lmp.py:767]   Expert 61 |    270 | GPU0(cuda:1)
DEBUG 01-07 10:14:14.553055.553055 lmp.py:767]   Expert  8 |    283 | GPU1(cuda:2)
DEBUG 01-07 10:14:14.553228.553228 lmp.py:767]   Expert 63 |    285 | GPU0(cuda:1)
DEBUG 01-07 10:14:14.553639.553639 lmp.py:767]   Expert 46 |    294 | GPU1(cuda:2)
DEBUG 01-07 10:14:14.553381.553381 lmp.py:767]   Expert  9 |    300 | GPU0(cuda:1)
DEBUG 01-07 10:14:14.553647.553647 lmp.py:767]   Expert  6 |    316 | GPU0(cuda:1)
DEBUG 01-07 10:14:14.553628.553628 lmp.py:767]   Expert 16 |    316 | GPU1(cuda:2)
DEBUG 01-07 10:14:14.553370.553370 lmp.py:767]   Expert 40 |    319 | GPU1(cuda:2)
DEBUG 01-07 10:14:14.553881.553881 lmp.py:767]   Expert  7 |    322 | GPU0(cuda:1)
DEBUG 01-07 10:14:14.553392.553392 lmp.py:767]   Expert 23 |    325 | GPU1(cuda:2)
DEBUG 01-07 10:14:14.553611.553611 lmp.py:767]   Expert 14 |    413 | GPU1(cuda:2)
DEBUG 01-07 10:14:14.553022.553022 lmp.py:767]   Expert 57 |    464 | GPU0(cuda:1)
DEBUG 01-07 10:14:14.553765.553765 lmp.py:769] 
DEBUG 01-07 10:14:14.553765.553765 lmp.py:769]   Device Token Distribution:
DEBUG 01-07 10:14:14.553984.553984 lmp.py:770]   CPU:   1969 tokens
DEBUG 01-07 10:14:14.553919.553919 lmp.py:774]   cuda:1:   5231 tokens (23 experts)
DEBUG 01-07 10:14:14.553661.553661 lmp.py:774]   cuda:2:   5088 tokens (22 experts)
DEBUG 01-07 10:14:14.553450.553450 lmp.py:775]   Total GPU:  10319 tokens
DEBUG 01-07 10:14:14.553000.553000 lmp.py:776] ============================================================
DEBUG 01-07 10:14:14.553000.553000 lmp.py:776] 
DEBUG 01-07 10:14:14.553663.553663 cuda_h.py:19] end experts_map_get cost 0.0021240711212158203 seconds
DEBUG 01-07 10:14:14.553320.553320 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model_multi_device
DEBUG 01-07 10:14:14.553726.553726 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 10:14:14.553902.553902 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 10:14:14.554709.554709 cuda_h.py:19] end allocate_cuda_memory cost 0.0009047985076904297 seconds
DEBUG 01-07 10:14:14.554420.554420 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 10:14:14.554282.554282 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 10:14:14.554396.554396 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 10:14:14.554576.554576 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 6111b6d4-8f59-4f72-92cd-cb0e1771f2a5
DEBUG 01-07 10:14:14.555635.555635 client.py:106] call stub.LoadModelAsync
INFO 01-07 10:14:14.555176.555176 client.py:127] Model loaded
DEBUG 01-07 10:14:14.556501.556501 cuda_h.py:19] end sllm_worker_task cost 0.01150059700012207 seconds
INFO 01-07 10:14:14.556069.556069 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 6111b6d4-8f59-4f72-92cd-cb0e1771f2a5
DEBUG 01-07 10:14:14.556152.556152 cuda_h.py:19] end load_into_gpu_async cost 0.0018661022186279297 seconds
DEBUG 01-07 10:14:14.556452.556452 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 10:14:14.557509.557509 cuda_h.py:19] end restore_tensors2 cost 0.00028967857360839844 seconds
DEBUG 01-07 10:14:14.557399.557399 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.003452301025390625 seconds
DEBUG 01-07 10:14:14.559134.559134 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 10:14:14.559470.559470 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 10:14:14.560066.560066 cuda_h.py:19] end allocate_cuda_memory cost 0.0005402565002441406 seconds
DEBUG 01-07 10:14:14.560862.560862 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 10:14:14.560380.560380 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 10:14:14.560043.560043 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 10:14:14.560408.560408 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 07fdea47-7c6c-4fc8-801f-196fa034e77b
DEBUG 01-07 10:14:14.560626.560626 client.py:106] call stub.LoadModelAsync
INFO 01-07 10:14:14.561915.561915 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 07fdea47-7c6c-4fc8-801f-196fa034e77b
DEBUG 01-07 10:14:14.561430.561430 cuda_h.py:19] end load_into_gpu_async cost 0.001271963119506836 seconds
DEBUG 01-07 10:14:14.561665.561665 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 10:14:14.562523.562523 cuda_h.py:19] end restore_tensors2 cost 0.0005953311920166016 seconds
DEBUG 01-07 10:14:14.562780.562780 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.002990245819091797 seconds
DEBUG 01-07 10:14:14.568769.568769 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model_multi_device cost 0.014355659484863281 seconds
DEBUG 01-07 10:14:14.568603.568603 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-07 10:14:14.568195.568195 lmp.py:816] 
DEBUG 01-07 10:14:14.568195.568195 lmp.py:816]   Computing 19 experts on CPU...
DEBUG 01-07 10:14:14.568169.568169 cuda_h.py:19] end cpu_experts_submit cost 0.00036787986755371094 seconds
DEBUG 01-07 10:14:14.568436.568436 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-07 10:14:14.580711.580711 mlpmodule.py:749] group tensors cost 0.011043548583984375 s
DEBUG 01-07 10:14:14.582964.582964 mlpmodule.py:787] pad cost 0.0012559890747070312 s
DEBUG 01-07 10:14:14.582180.582180 mlpmodule.py:793] create cpu tensor cost 5.602836608886719e-05 s
DEBUG 01-07 10:14:14.582376.582376 mlpmodule.py:798] move to cpu cost 6.175041198730469e-05 s
DEBUG 01-07 10:14:14.592597.592597 mlpmodule.py:812] group_w3: shape=torch.Size([19, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=54788096
DEBUG 01-07 10:14:14.592841.592841 mlpmodule.py:813] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-07 10:14:14.592077.592077 mlpmodule.py:818] group_w3 first element: -0.0107421875
WARNING 01-07 10:14:14.592772.592772 mlpmodule.py:828] start einsum2
DEBUG 01-07 10:14:14.606398.606398 mlpmodule.py:838] group einsum cost 0.02429366111755371 s
DEBUG 01-07 10:14:14.607729.607729 mlpmodule.py:846] cpy2cputensor cost 0.0003669261932373047 s
DEBUG 01-07 10:14:14.610752.610752 cuda_h.py:19] end wait_cetm_experts cost 0.04117870330810547 seconds
DEBUG 01-07 10:14:14.610458.610458 cuda_h.py:10] start gpu_sexperts
DEBUG 01-07 10:14:14.610549.610549 cuda_h.py:19] end gpu_sexperts cost 0.0005140304565429688 seconds
DEBUG 01-07 10:14:14.610214.610214 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-07 10:14:14.610209.610209 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.5033950805664062e-05 seconds
DEBUG 01-07 10:14:14.610211.610211 cuda_h.py:10] start wait_experts_multi_device
INFO 01-07 10:14:14.610682.610682 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 6111b6d4-8f59-4f72-92cd-cb0e1771f2a5
INFO 01-07 10:14:14.611189.611189 client.py:127] Model loaded
INFO 01-07 10:14:14.611548.611548 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 07fdea47-7c6c-4fc8-801f-196fa034e77b
INFO 01-07 10:14:14.612861.612861 client.py:127] Model loaded
DEBUG 01-07 10:14:14.612287.612287 cuda_h.py:19] end wait_experts_multi_device cost 0.0014646053314208984 seconds
DEBUG 01-07 10:14:14.612090.612090 cuda_h.py:10] start gpu_experts_multi_device
DEBUG 01-07 10:14:14.612389.612389 lmp.py:867]   Computing 22 experts on cuda:2...
DEBUG 01-07 10:14:14.614217.614217 mlpmodule.py:533] gpu group tensors cost 0.0009007453918457031 s
DEBUG 01-07 10:14:14.616921.616921 mlpmodule.py:566] gpu pad cost 0.001360177993774414 s
DEBUG 01-07 10:14:14.617436.617436 mlpmodule.py:584] gpu group einsum cost 0.0010852813720703125 s
DEBUG 01-07 10:14:14.617552.617552 mlpmodule.py:707]  experts func einsum cost 0.04863619804382324 s
DEBUG 01-07 10:14:14.619052.619052 mlpmodule.py:656] gpu experts func einsum cost 0.005448102951049805 s
DEBUG 01-07 10:14:14.619274.619274 lmp.py:867]   Computing 23 experts on cuda:1...
DEBUG 01-07 10:14:14.620126.620126 mlpmodule.py:533] gpu group tensors cost 0.0010292530059814453 s
DEBUG 01-07 10:14:14.622700.622700 mlpmodule.py:566] gpu pad cost 0.0012352466583251953 s
DEBUG 01-07 10:14:14.622664.622664 mlpmodule.py:584] gpu group einsum cost 0.0006511211395263672 s
DEBUG 01-07 10:14:14.624852.624852 mlpmodule.py:656] gpu experts func einsum cost 0.0046918392181396484 s
DEBUG 01-07 10:14:14.624351.624351 cuda_h.py:19] end gpu_experts_multi_device cost 0.01213836669921875 seconds
DEBUG 01-07 10:14:14.624321.624321 cuda_h.py:19] end layer_moe_generate_multi_device_1 cost 0.074188232421875 seconds
DEBUG 01-07 10:14:14.624017.624017 lmp.py:194] -------------------------------- end prefill layer 1 --------------------------------
DEBUG 01-07 10:14:14.624178.624178 lmp.py:153] -------------------------------- start prefill layer 2 --------------------------------
DEBUG 01-07 10:14:14.625351.625351 cuda_h.py:10] start start_load_qkvogn_s_weight_l_3
DEBUG 01-07 10:14:14.625630.625630 cuda_h.py:10] start start_load_qkvogn_s_weight_l_3
DEBUG 01-07 10:14:14.625751.625751 cuda_h.py:19] end start_load_qkvogn_s_weight_l_3 cost 2.7894973754882812e-05 seconds
DEBUG 01-07 10:14:14.625785.625785 cuda_h.py:19] end start_load_qkvogn_s_weight_l_3 cost 5.7220458984375e-05 seconds
DEBUG 01-07 10:14:14.625143.625143 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-07 10:14:14.625695.625695 mlpmodule.py:367] cuda:1 cuda:1
DEBUG 01-07 10:14:14.625260.625260 cuda_h.py:10] start sllm_worker_task
DEBUG 01-07 10:14:14.625924.625924 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 10:14:14.625277.625277 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 10:14:14.625867.625867 cuda_h.py:19] end allocate_cuda_memory cost 0.0001888275146484375 seconds
DEBUG 01-07 10:14:14.625930.625930 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 10:14:14.625090.625090 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 10:14:14.625887.625887 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 10:14:14.625875.625875 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, aa5a655e-4a05-4783-a6c9-59a7605b701a
DEBUG 01-07 10:14:14.625453.625453 client.py:106] call stub.LoadModelAsync
DEBUG 01-07 10:14:14.626626.626626 cuda_h.py:10] start self_attn
INFO 01-07 10:14:14.626855.626855 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, aa5a655e-4a05-4783-a6c9-59a7605b701a
DEBUG 01-07 10:14:14.626208.626208 cuda_h.py:19] end load_into_gpu_async cost 0.0009286403656005859 seconds
DEBUG 01-07 10:14:14.626526.626526 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 10:14:14.626172.626172 cuda_h.py:19] end restore_tensors2 cost 6.461143493652344e-05 seconds
DEBUG 01-07 10:14:14.626020.626020 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0014433860778808594 seconds
INFO 01-07 10:14:14.626102.626102 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, aa5a655e-4a05-4783-a6c9-59a7605b701a
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-07 10:14:14.629903.629903 cuda_h.py:19] end self_attn cost 0.0036890506744384766 seconds
DEBUG 01-07 10:14:14.630822.630822 cuda_h.py:19] end iln_self_attn_paln cost 0.0050008296966552734 seconds
DEBUG 01-07 10:14:14.630790.630790 cuda_h.py:10] start layer_moe_generate_multi_device_2
DEBUG 01-07 10:14:14.630977.630977 cuda_h.py:10] start gate
DEBUG 01-07 10:14:14.630794.630794 cuda_h.py:19] end gate cost 0.0006392002105712891 seconds
DEBUG 01-07 10:14:14.630431.630431 cuda_h.py:10] start experts_map_get
DEBUG 01-07 10:14:14.631597.631597 lmp.py:744] 
DEBUG 01-07 10:14:14.631597.631597 lmp.py:744] Expert Token Distribution & Multi-Device Allocation:
DEBUG 01-07 10:14:14.631996.631996 lmp.py:745]   Total experts: 64
DEBUG 01-07 10:14:14.631315.631315 lmp.py:746]   CPU experts: 19 (30%)
DEBUG 01-07 10:14:14.631150.631150 lmp.py:747]   GPU experts: 45 (70%)
DEBUG 01-07 10:14:14.631554.631554 lmp.py:748]   Number of GPU devices: 2
DEBUG 01-07 10:14:14.631005.631005 lmp.py:749] 
DEBUG 01-07 10:14:14.631005.631005 lmp.py:749]   Expert ID | Tokens | Device
DEBUG 01-07 10:14:14.631171.631171 lmp.py:750]   -----------------------------------
DEBUG 01-07 10:14:14.631252.631252 lmp.py:767]   Expert 58 |     50 | CPU
DEBUG 01-07 10:14:14.631656.631656 lmp.py:767]   Expert 27 |     56 | CPU
DEBUG 01-07 10:14:14.631299.631299 lmp.py:767]   Expert  3 |     68 | CPU
DEBUG 01-07 10:14:14.631465.631465 lmp.py:767]   Expert 17 |     84 | CPU
DEBUG 01-07 10:14:14.631393.631393 lmp.py:767]   Expert 24 |     86 | CPU
DEBUG 01-07 10:14:14.631082.631082 lmp.py:767]   Expert  0 |     88 | CPU
DEBUG 01-07 10:14:14.631533.631533 lmp.py:767]   Expert 28 |    105 | CPU
DEBUG 01-07 10:14:14.631984.631984 lmp.py:767]   Expert 34 |    116 | CPU
DEBUG 01-07 10:14:14.631197.631197 lmp.py:767]   Expert 51 |    118 | CPU
DEBUG 01-07 10:14:14.631171.631171 lmp.py:767]   Expert 32 |    120 | CPU
DEBUG 01-07 10:14:14.631383.631383 lmp.py:767]   Expert  9 |    130 | CPU
DEBUG 01-07 10:14:14.631311.631311 lmp.py:767]   Expert 15 |    134 | CPU
DEBUG 01-07 10:14:14.631477.631477 lmp.py:767]   Expert  7 |    135 | CPU
DEBUG 01-07 10:14:14.631928.631928 lmp.py:767]   Expert 23 |    136 | CPU
DEBUG 01-07 10:14:14.631663.631663 lmp.py:767]   Expert 26 |    138 | CPU
DEBUG 01-07 10:14:14.631876.631876 lmp.py:767]   Expert 30 |    144 | CPU
DEBUG 01-07 10:14:14.631088.631088 lmp.py:767]   Expert 45 |    146 | CPU
DEBUG 01-07 10:14:14.631062.631062 lmp.py:767]   Expert 62 |    147 | CPU
DEBUG 01-07 10:14:14.631036.631036 lmp.py:767]   Expert 57 |    150 | CPU
DEBUG 01-07 10:14:14.631679.631679 lmp.py:767]   Expert  1 |    152 | GPU1(cuda:2)
DEBUG 01-07 10:14:14.631561.631561 lmp.py:767]   Expert 36 |    155 | GPU1(cuda:2)
DEBUG 01-07 10:14:14.631681.631681 lmp.py:767]   Expert  8 |    158 | GPU0(cuda:1)
DEBUG 01-07 10:14:14.631085.631085 lmp.py:767]   Expert 29 |    161 | GPU0(cuda:1)
DEBUG 01-07 10:14:14.631251.631251 lmp.py:767]   Expert 25 |    164 | GPU1(cuda:2)
DEBUG 01-07 10:14:14.631417.631417 lmp.py:767]   Expert 54 |    169 | GPU0(cuda:1)
DEBUG 01-07 10:14:14.631584.631584 lmp.py:767]   Expert  6 |    170 | GPU0(cuda:1)
DEBUG 01-07 10:14:14.631465.631465 lmp.py:767]   Expert 49 |    170 | GPU1(cuda:2)
DEBUG 01-07 10:14:14.631346.631346 lmp.py:767]   Expert 48 |    172 | GPU1(cuda:2)
DEBUG 01-07 10:14:14.632513.632513 lmp.py:767]   Expert 12 |    175 | GPU0(cuda:1)
DEBUG 01-07 10:14:14.632917.632917 lmp.py:767]   Expert 35 |    176 | GPU1(cuda:2)
DEBUG 01-07 10:14:14.632322.632322 lmp.py:767]   Expert 37 |    177 | GPU1(cuda:2)
DEBUG 01-07 10:14:14.632488.632488 lmp.py:767]   Expert 60 |    186 | GPU0(cuda:1)
DEBUG 01-07 10:14:14.632131.632131 lmp.py:767]   Expert 13 |    188 | GPU1(cuda:2)
DEBUG 01-07 10:14:14.632251.632251 lmp.py:767]   Expert 53 |    189 | GPU0(cuda:1)
DEBUG 01-07 10:14:14.632655.632655 lmp.py:767]   Expert 33 |    190 | GPU0(cuda:1)
DEBUG 01-07 10:14:14.632344.632344 lmp.py:767]   Expert 10 |    195 | GPU1(cuda:2)
DEBUG 01-07 10:14:14.632511.632511 lmp.py:767]   Expert 16 |    195 | GPU1(cuda:2)
DEBUG 01-07 10:14:14.632438.632438 lmp.py:767]   Expert 21 |    198 | GPU0(cuda:1)
DEBUG 01-07 10:14:14.632366.632366 lmp.py:767]   Expert 40 |    200 | GPU0(cuda:1)
DEBUG 01-07 10:14:14.632294.632294 lmp.py:767]   Expert 43 |    202 | GPU1(cuda:2)
DEBUG 01-07 10:14:14.632937.632937 lmp.py:767]   Expert 38 |    205 | GPU1(cuda:2)
DEBUG 01-07 10:14:14.632580.632580 lmp.py:767]   Expert  5 |    208 | GPU0(cuda:1)
DEBUG 01-07 10:14:14.632507.632507 lmp.py:767]   Expert 44 |    216 | GPU0(cuda:1)
DEBUG 01-07 10:14:14.632197.632197 lmp.py:767]   Expert 52 |    216 | GPU1(cuda:2)
DEBUG 01-07 10:14:14.632124.632124 lmp.py:767]   Expert 41 |    217 | GPU0(cuda:1)
DEBUG 01-07 10:14:14.632052.632052 lmp.py:767]   Expert 50 |    217 | GPU1(cuda:2)
DEBUG 01-07 10:14:14.632980.632980 lmp.py:767]   Expert 19 |    219 | GPU1(cuda:2)
DEBUG 01-07 10:14:14.632146.632146 lmp.py:767]   Expert  4 |    222 | GPU0(cuda:1)
DEBUG 01-07 10:14:14.632074.632074 lmp.py:767]   Expert 59 |    223 | GPU0(cuda:1)
DEBUG 01-07 10:14:14.632478.632478 lmp.py:767]   Expert 55 |    233 | GPU1(cuda:2)
DEBUG 01-07 10:14:14.632274.632274 lmp.py:767]   Expert 31 |    240 | GPU0(cuda:1)
DEBUG 01-07 10:14:14.632678.632678 lmp.py:767]   Expert 56 |    241 | GPU1(cuda:2)
DEBUG 01-07 10:14:14.632606.632606 lmp.py:767]   Expert 20 |    251 | GPU0(cuda:1)
DEBUG 01-07 10:14:14.632295.632295 lmp.py:767]   Expert 39 |    253 | GPU1(cuda:2)
DEBUG 01-07 10:14:14.632985.632985 lmp.py:767]   Expert 22 |    264 | GPU0(cuda:1)
DEBUG 01-07 10:14:14.632866.632866 lmp.py:767]   Expert  2 |    267 | GPU1(cuda:2)
DEBUG 01-07 10:14:14.632747.632747 lmp.py:767]   Expert 63 |    275 | GPU0(cuda:1)
DEBUG 01-07 10:14:14.632629.632629 lmp.py:767]   Expert 47 |    276 | GPU1(cuda:2)
DEBUG 01-07 10:14:14.632987.632987 lmp.py:767]   Expert 42 |    303 | GPU0(cuda:1)
DEBUG 01-07 10:14:14.632630.632630 lmp.py:767]   Expert 18 |    315 | GPU1(cuda:2)
DEBUG 01-07 10:14:14.632035.632035 lmp.py:767]   Expert 14 |    319 | GPU0(cuda:1)
DEBUG 01-07 10:14:14.632916.632916 lmp.py:767]   Expert 46 |    367 | GPU1(cuda:2)
DEBUG 01-07 10:14:14.632321.632321 lmp.py:767]   Expert 11 |    388 | GPU1(cuda:2)
DEBUG 01-07 10:14:14.632964.632964 lmp.py:767]   Expert 61 |    460 | GPU0(cuda:1)
DEBUG 01-07 10:14:14.632891.632891 lmp.py:769] 
DEBUG 01-07 10:14:14.632891.632891 lmp.py:769]   Device Token Distribution:
DEBUG 01-07 10:14:14.632249.632249 lmp.py:770]   CPU:   2151 tokens
DEBUG 01-07 10:14:14.632323.632323 lmp.py:774]   cuda:1:   4994 tokens (22 experts)
DEBUG 01-07 10:14:14.632966.632966 lmp.py:774]   cuda:2:   5143 tokens (23 experts)
DEBUG 01-07 10:14:14.632894.632894 lmp.py:775]   Total GPU:  10137 tokens
DEBUG 01-07 10:14:14.632345.632345 lmp.py:776] ============================================================
DEBUG 01-07 10:14:14.632345.632345 lmp.py:776] 
DEBUG 01-07 10:14:14.632710.632710 cuda_h.py:19] end experts_map_get cost 0.0017571449279785156 seconds
DEBUG 01-07 10:14:14.632591.632591 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model_multi_device
DEBUG 01-07 10:14:14.632745.632745 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 10:14:14.632808.632808 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 10:14:14.633032.633032 cuda_h.py:19] end allocate_cuda_memory cost 0.00030732154846191406 seconds
DEBUG 01-07 10:14:14.633444.633444 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 10:14:14.633770.633770 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 10:14:14.633433.633433 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 10:14:14.633129.633129 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 3df00d5a-35df-4e63-904f-7e4635c1a8d5
DEBUG 01-07 10:14:14.633465.633465 client.py:106] call stub.LoadModelAsync
INFO 01-07 10:14:14.633947.633947 client.py:127] Model loaded
DEBUG 01-07 10:14:14.634542.634542 cuda_h.py:19] end sllm_worker_task cost 0.008743524551391602 seconds
INFO 01-07 10:14:14.634681.634681 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 3df00d5a-35df-4e63-904f-7e4635c1a8d5
DEBUG 01-07 10:14:14.634114.634114 cuda_h.py:19] end load_into_gpu_async cost 0.0009877681732177734 seconds
DEBUG 01-07 10:14:14.634347.634347 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 10:14:14.634471.634471 cuda_h.py:19] end restore_tensors2 cost 0.0003063678741455078 seconds
DEBUG 01-07 10:14:14.634022.634022 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.001928567886352539 seconds
DEBUG 01-07 10:14:14.636817.636817 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 10:14:14.636935.636935 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 10:14:14.637956.637956 cuda_h.py:19] end allocate_cuda_memory cost 0.0001838207244873047 seconds
DEBUG 01-07 10:14:14.637190.637190 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 10:14:14.637377.637377 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 10:14:14.637947.637947 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 10:14:14.637458.637458 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 824077ca-2720-475d-9b09-813de17a5faa
DEBUG 01-07 10:14:14.637867.637867 client.py:106] call stub.LoadModelAsync
INFO 01-07 10:14:14.638549.638549 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 824077ca-2720-475d-9b09-813de17a5faa
DEBUG 01-07 10:14:14.638200.638200 cuda_h.py:19] end load_into_gpu_async cost 0.0010612010955810547 seconds
DEBUG 01-07 10:14:14.638334.638334 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 10:14:14.638934.638934 cuda_h.py:19] end restore_tensors2 cost 0.0003077983856201172 seconds
DEBUG 01-07 10:14:14.638916.638916 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0018966197967529297 seconds
DEBUG 01-07 10:14:14.640004.640004 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model_multi_device cost 0.007966279983520508 seconds
DEBUG 01-07 10:14:14.640523.640523 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-07 10:14:14.640585.640585 lmp.py:816] 
DEBUG 01-07 10:14:14.640585.640585 lmp.py:816]   Computing 19 experts on CPU...
DEBUG 01-07 10:14:14.640190.640190 cuda_h.py:19] end cpu_experts_submit cost 0.00011110305786132812 seconds
DEBUG 01-07 10:14:14.641330.641330 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-07 10:14:14.646575.646575 mlpmodule.py:749] group tensors cost 0.005552053451538086 s
DEBUG 01-07 10:14:14.648941.648941 mlpmodule.py:787] pad cost 0.0012500286102294922 s
DEBUG 01-07 10:14:14.648627.648627 mlpmodule.py:793] create cpu tensor cost 5.0067901611328125e-05 s
DEBUG 01-07 10:14:14.648597.648597 mlpmodule.py:798] move to cpu cost 3.790855407714844e-05 s
DEBUG 01-07 10:14:14.658890.658890 mlpmodule.py:812] group_w3: shape=torch.Size([19, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=54788096
DEBUG 01-07 10:14:14.658042.658042 mlpmodule.py:813] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-07 10:14:14.658992.658992 mlpmodule.py:818] group_w3 first element: -0.0380859375
WARNING 01-07 10:14:14.658076.658076 mlpmodule.py:828] start einsum2
DEBUG 01-07 10:14:14.674940.674940 mlpmodule.py:838] group einsum cost 0.024988412857055664 s
DEBUG 01-07 10:14:14.674941.674941 mlpmodule.py:846] cpy2cputensor cost 0.0004100799560546875 s
DEBUG 01-07 10:14:14.677265.677265 cuda_h.py:19] end wait_cetm_experts cost 0.036385297775268555 seconds
DEBUG 01-07 10:14:14.677818.677818 cuda_h.py:10] start gpu_sexperts
DEBUG 01-07 10:14:14.678704.678704 cuda_h.py:19] end gpu_sexperts cost 0.0005047321319580078 seconds
DEBUG 01-07 10:14:14.678786.678786 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-07 10:14:14.678920.678920 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.5272369384765625e-05 seconds
DEBUG 01-07 10:14:14.678861.678861 cuda_h.py:10] start wait_experts_multi_device
INFO 01-07 10:14:14.678101.678101 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 3df00d5a-35df-4e63-904f-7e4635c1a8d5
INFO 01-07 10:14:14.679390.679390 client.py:127] Model loaded
INFO 01-07 10:14:14.679293.679293 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 824077ca-2720-475d-9b09-813de17a5faa
INFO 01-07 10:14:14.681180.681180 client.py:127] Model loaded
DEBUG 01-07 10:14:14.681175.681175 cuda_h.py:19] end wait_experts_multi_device cost 0.003006458282470703 seconds
DEBUG 01-07 10:14:14.681838.681838 cuda_h.py:10] start gpu_experts_multi_device
DEBUG 01-07 10:14:14.681045.681045 lmp.py:867]   Computing 23 experts on cuda:2...
DEBUG 01-07 10:14:14.685085.685085 mlpmodule.py:707]  experts func einsum cost 0.04453420639038086 s
DEBUG 01-07 10:14:14.686282.686282 mlpmodule.py:533] gpu group tensors cost 0.0040400028228759766 s
DEBUG 01-07 10:14:14.687121.687121 mlpmodule.py:566] gpu pad cost 0.0012445449829101562 s
DEBUG 01-07 10:14:14.687840.687840 mlpmodule.py:584] gpu group einsum cost 0.00043654441833496094 s
DEBUG 01-07 10:14:14.689424.689424 mlpmodule.py:656] gpu experts func einsum cost 0.00769805908203125 s
DEBUG 01-07 10:14:14.689592.689592 lmp.py:867]   Computing 22 experts on cuda:1...
DEBUG 01-07 10:14:14.690521.690521 mlpmodule.py:533] gpu group tensors cost 0.00039505958557128906 s
DEBUG 01-07 10:14:14.691556.691556 mlpmodule.py:566] gpu pad cost 0.0009920597076416016 s
DEBUG 01-07 10:14:14.692610.692610 mlpmodule.py:584] gpu group einsum cost 0.0005486011505126953 s
DEBUG 01-07 10:14:14.693356.693356 mlpmodule.py:656] gpu experts func einsum cost 0.003574371337890625 s
DEBUG 01-07 10:14:14.693465.693465 cuda_h.py:19] end gpu_experts_multi_device cost 0.01254725456237793 seconds
DEBUG 01-07 10:14:14.693614.693614 cuda_h.py:19] end layer_moe_generate_multi_device_2 cost 0.06372904777526855 seconds
DEBUG 01-07 10:14:14.694834.694834 lmp.py:194] -------------------------------- end prefill layer 2 --------------------------------
DEBUG 01-07 10:14:14.694756.694756 lmp.py:153] -------------------------------- start prefill layer 3 --------------------------------
DEBUG 01-07 10:14:14.694214.694214 cuda_h.py:10] start start_load_qkvogn_s_weight_l_4
DEBUG 01-07 10:14:14.694493.694493 cuda_h.py:10] start start_load_qkvogn_s_weight_l_4
DEBUG 01-07 10:14:14.694091.694091 cuda_h.py:19] end start_load_qkvogn_s_weight_l_4 cost 2.7418136596679688e-05 seconds
DEBUG 01-07 10:14:14.694840.694840 cuda_h.py:19] end start_load_qkvogn_s_weight_l_4 cost 5.793571472167969e-05 seconds
DEBUG 01-07 10:14:14.694913.694913 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-07 10:14:14.694942.694942 mlpmodule.py:367] cuda:1 cuda:1
DEBUG 01-07 10:14:14.694123.694123 cuda_h.py:10] start sllm_worker_task
DEBUG 01-07 10:14:14.694947.694947 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 10:14:14.694637.694637 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 10:14:14.694512.694512 cuda_h.py:19] end allocate_cuda_memory cost 0.0001900196075439453 seconds
DEBUG 01-07 10:14:14.694667.694667 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 10:14:14.695523.695523 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 10:14:14.695438.695438 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 10:14:14.695664.695664 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 6463ac95-9a20-42a1-81de-a843d5e4f427
DEBUG 01-07 10:14:14.695143.695143 client.py:106] call stub.LoadModelAsync
DEBUG 01-07 10:14:14.695845.695845 cuda_h.py:10] start self_attn
INFO 01-07 10:14:14.695026.695026 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 6463ac95-9a20-42a1-81de-a843d5e4f427
DEBUG 01-07 10:14:14.695332.695332 cuda_h.py:19] end load_into_gpu_async cost 0.000843048095703125 seconds
DEBUG 01-07 10:14:14.695128.695128 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 10:14:14.695581.695581 cuda_h.py:19] end restore_tensors2 cost 6.318092346191406e-05 seconds
DEBUG 01-07 10:14:14.695999.695999 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.001341104507446289 seconds
INFO 01-07 10:14:14.696398.696398 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 6463ac95-9a20-42a1-81de-a843d5e4f427
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-07 10:14:14.699772.699772 cuda_h.py:19] end self_attn cost 0.0036764144897460938 seconds
DEBUG 01-07 10:14:14.699948.699948 cuda_h.py:19] end iln_self_attn_paln cost 0.004948616027832031 seconds
DEBUG 01-07 10:14:14.699962.699962 cuda_h.py:10] start layer_moe_generate_multi_device_3
DEBUG 01-07 10:14:14.699910.699910 cuda_h.py:10] start gate
DEBUG 01-07 10:14:14.700575.700575 cuda_h.py:19] end gate cost 0.0006320476531982422 seconds
DEBUG 01-07 10:14:14.700259.700259 cuda_h.py:10] start experts_map_get
DEBUG 01-07 10:14:14.700346.700346 lmp.py:744] 
DEBUG 01-07 10:14:14.700346.700346 lmp.py:744] Expert Token Distribution & Multi-Device Allocation:
DEBUG 01-07 10:14:14.700023.700023 lmp.py:745]   Total experts: 64
DEBUG 01-07 10:14:14.700295.700295 lmp.py:746]   CPU experts: 19 (30%)
DEBUG 01-07 10:14:14.700845.700845 lmp.py:747]   GPU experts: 45 (70%)
DEBUG 01-07 10:14:14.700250.700250 lmp.py:748]   Number of GPU devices: 2
DEBUG 01-07 10:14:14.700462.700462 lmp.py:749] 
DEBUG 01-07 10:14:14.700462.700462 lmp.py:749]   Expert ID | Tokens | Device
DEBUG 01-07 10:14:14.700390.700390 lmp.py:750]   -----------------------------------
DEBUG 01-07 10:14:14.700801.700801 lmp.py:767]   Expert  1 |     48 | CPU
DEBUG 01-07 10:14:14.700967.700967 lmp.py:767]   Expert 27 |     62 | CPU
DEBUG 01-07 10:14:14.700657.700657 lmp.py:767]   Expert 48 |     75 | CPU
DEBUG 01-07 10:14:14.700584.700584 lmp.py:767]   Expert  7 |     79 | CPU
DEBUG 01-07 10:14:14.700035.700035 lmp.py:767]   Expert 15 |    101 | CPU
DEBUG 01-07 10:14:14.700248.700248 lmp.py:767]   Expert 30 |    112 | CPU
DEBUG 01-07 10:14:14.700460.700460 lmp.py:767]   Expert 61 |    114 | CPU
DEBUG 01-07 10:14:14.700541.700541 lmp.py:767]   Expert 32 |    118 | CPU
DEBUG 01-07 10:14:14.700753.700753 lmp.py:767]   Expert 18 |    119 | CPU
DEBUG 01-07 10:14:14.700204.700204 lmp.py:767]   Expert 45 |    120 | CPU
DEBUG 01-07 10:14:14.700416.700416 lmp.py:767]   Expert 34 |    132 | CPU
DEBUG 01-07 10:14:14.700106.700106 lmp.py:767]   Expert 39 |    133 | CPU
DEBUG 01-07 10:14:14.700033.700033 lmp.py:767]   Expert  5 |    140 | CPU
DEBUG 01-07 10:14:14.700961.700961 lmp.py:767]   Expert 36 |    140 | CPU
DEBUG 01-07 10:14:14.701935.701935 lmp.py:767]   Expert 26 |    141 | CPU
DEBUG 01-07 10:14:14.701671.701671 lmp.py:767]   Expert  6 |    142 | CPU
DEBUG 01-07 10:14:14.701645.701645 lmp.py:767]   Expert 11 |    142 | CPU
DEBUG 01-07 10:14:14.701380.701380 lmp.py:767]   Expert 59 |    144 | CPU
DEBUG 01-07 10:14:14.701116.701116 lmp.py:767]   Expert 51 |    147 | CPU
DEBUG 01-07 10:14:14.701759.701759 lmp.py:767]   Expert 49 |    153 | GPU0(cuda:1)
DEBUG 01-07 10:14:14.701164.701164 lmp.py:767]   Expert 23 |    154 | GPU0(cuda:1)
DEBUG 01-07 10:14:14.701045.701045 lmp.py:767]   Expert  2 |    156 | GPU1(cuda:2)
DEBUG 01-07 10:14:14.701450.701450 lmp.py:767]   Expert  9 |    158 | GPU0(cuda:1)
DEBUG 01-07 10:14:14.701331.701331 lmp.py:767]   Expert 50 |    164 | GPU1(cuda:2)
DEBUG 01-07 10:14:14.701974.701974 lmp.py:767]   Expert 56 |    166 | GPU0(cuda:1)
DEBUG 01-07 10:14:14.701140.701140 lmp.py:767]   Expert 40 |    168 | GPU1(cuda:2)
DEBUG 01-07 10:14:14.701306.701306 lmp.py:767]   Expert 52 |    169 | GPU0(cuda:1)
DEBUG 01-07 10:14:14.701234.701234 lmp.py:767]   Expert 35 |    171 | GPU1(cuda:2)
DEBUG 01-07 10:14:14.701162.701162 lmp.py:767]   Expert 16 |    172 | GPU1(cuda:2)
DEBUG 01-07 10:14:14.701328.701328 lmp.py:767]   Expert  4 |    187 | GPU0(cuda:1)
DEBUG 01-07 10:14:14.701732.701732 lmp.py:767]   Expert 13 |    191 | GPU0(cuda:1)
DEBUG 01-07 10:14:14.701375.701375 lmp.py:767]   Expert 42 |    191 | GPU1(cuda:2)
DEBUG 01-07 10:14:14.701303.701303 lmp.py:767]   Expert 37 |    192 | GPU0(cuda:1)
DEBUG 01-07 10:14:14.701992.701992 lmp.py:767]   Expert 62 |    197 | GPU1(cuda:2)
DEBUG 01-07 10:14:14.701158.701158 lmp.py:767]   Expert 17 |    198 | GPU1(cuda:2)
DEBUG 01-07 10:14:14.701848.701848 lmp.py:767]   Expert 38 |    198 | GPU0(cuda:1)
DEBUG 01-07 10:14:14.701776.701776 lmp.py:767]   Expert 21 |    203 | GPU1(cuda:2)
DEBUG 01-07 10:14:14.701703.701703 lmp.py:767]   Expert 44 |    206 | GPU0(cuda:1)
DEBUG 01-07 10:14:14.701869.701869 lmp.py:767]   Expert  3 |    207 | GPU0(cuda:1)
DEBUG 01-07 10:14:14.701797.701797 lmp.py:767]   Expert 58 |    209 | GPU1(cuda:2)
DEBUG 01-07 10:14:14.701202.701202 lmp.py:767]   Expert 60 |    213 | GPU0(cuda:1)
DEBUG 01-07 10:14:14.701845.701845 lmp.py:767]   Expert 10 |    214 | GPU1(cuda:2)
DEBUG 01-07 10:14:14.701772.701772 lmp.py:767]   Expert 28 |    215 | GPU0(cuda:1)
DEBUG 01-07 10:14:14.701938.701938 lmp.py:767]   Expert 47 |    216 | GPU1(cuda:2)
DEBUG 01-07 10:14:14.701628.701628 lmp.py:767]   Expert 53 |    219 | GPU0(cuda:1)
DEBUG 01-07 10:14:14.701794.701794 lmp.py:767]   Expert 33 |    220 | GPU1(cuda:2)
DEBUG 01-07 10:14:14.701245.701245 lmp.py:767]   Expert 55 |    221 | GPU0(cuda:1)
DEBUG 01-07 10:14:14.701411.701411 lmp.py:767]   Expert 20 |    222 | GPU1(cuda:2)
DEBUG 01-07 10:14:14.701577.701577 lmp.py:767]   Expert 57 |    231 | GPU0(cuda:1)
DEBUG 01-07 10:14:14.701982.701982 lmp.py:767]   Expert 31 |    234 | GPU1(cuda:2)
DEBUG 01-07 10:14:14.701909.701909 lmp.py:767]   Expert 46 |    236 | GPU0(cuda:1)
DEBUG 01-07 10:14:14.701837.701837 lmp.py:767]   Expert  8 |    238 | GPU1(cuda:2)
DEBUG 01-07 10:14:14.701526.701526 lmp.py:767]   Expert 19 |    241 | GPU0(cuda:1)
DEBUG 01-07 10:14:14.701216.701216 lmp.py:767]   Expert 24 |    244 | GPU1(cuda:2)
DEBUG 01-07 10:14:14.701667.701667 lmp.py:767]   Expert 14 |    267 | GPU0(cuda:1)
DEBUG 01-07 10:14:14.701356.701356 lmp.py:767]   Expert 63 |    269 | GPU1(cuda:2)
DEBUG 01-07 10:14:14.701999.701999 lmp.py:767]   Expert 22 |    277 | GPU1(cuda:2)
DEBUG 01-07 10:14:14.701357.701357 lmp.py:767]   Expert 29 |    277 | GPU0(cuda:1)
DEBUG 01-07 10:14:14.701238.701238 lmp.py:767]   Expert 12 |    278 | GPU1(cuda:2)
DEBUG 01-07 10:14:14.701358.701358 lmp.py:767]   Expert  0 |    294 | GPU0(cuda:1)
DEBUG 01-07 10:14:14.701240.701240 lmp.py:767]   Expert 43 |    311 | GPU0(cuda:1)
DEBUG 01-07 10:14:14.701121.701121 lmp.py:767]   Expert 54 |    340 | GPU1(cuda:2)
DEBUG 01-07 10:14:14.701241.701241 lmp.py:767]   Expert 41 |    382 | GPU1(cuda:2)
DEBUG 01-07 10:14:14.701122.701122 lmp.py:767]   Expert 25 |    410 | GPU0(cuda:1)
DEBUG 01-07 10:14:14.701812.701812 lmp.py:769] 
DEBUG 01-07 10:14:14.701812.701812 lmp.py:769]   Device Token Distribution:
DEBUG 01-07 10:14:14.701170.701170 lmp.py:770]   CPU:   2209 tokens
DEBUG 01-07 10:14:14.701482.701482 lmp.py:774]   cuda:1:   5116 tokens (23 experts)
DEBUG 01-07 10:14:14.701363.701363 lmp.py:774]   cuda:2:   4963 tokens (22 experts)
DEBUG 01-07 10:14:14.701529.701529 lmp.py:775]   Total GPU:  10079 tokens
DEBUG 01-07 10:14:14.701219.701219 lmp.py:776] ============================================================
DEBUG 01-07 10:14:14.701219.701219 lmp.py:776] 
DEBUG 01-07 10:14:14.701107.701107 cuda_h.py:19] end experts_map_get cost 0.001756429672241211 seconds
DEBUG 01-07 10:14:14.701227.701227 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model_multi_device
DEBUG 01-07 10:14:14.702903.702903 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 10:14:14.702722.702722 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 10:14:14.702709.702709 cuda_h.py:19] end allocate_cuda_memory cost 0.00016927719116210938 seconds
DEBUG 01-07 10:14:14.702022.702022 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 10:14:14.702917.702917 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 10:14:14.702772.702772 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 10:14:14.702660.702660 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 34397c5f-af17-48e3-9fdf-22c8f0e1a91f
DEBUG 01-07 10:14:14.702003.702003 client.py:106] call stub.LoadModelAsync
INFO 01-07 10:14:14.702243.702243 client.py:127] Model loaded
DEBUG 01-07 10:14:14.703444.703444 cuda_h.py:19] end sllm_worker_task cost 0.008723258972167969 seconds
INFO 01-07 10:14:14.703323.703323 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 34397c5f-af17-48e3-9fdf-22c8f0e1a91f
DEBUG 01-07 10:14:14.703981.703981 cuda_h.py:19] end load_into_gpu_async cost 0.0011324882507324219 seconds
DEBUG 01-07 10:14:14.703161.703161 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 10:14:14.703019.703019 cuda_h.py:19] end restore_tensors2 cost 0.00029087066650390625 seconds
DEBUG 01-07 10:14:14.703465.703465 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0019009113311767578 seconds
DEBUG 01-07 10:14:14.705961.705961 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 10:14:14.706582.706582 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 10:14:14.706536.706536 cuda_h.py:19] end allocate_cuda_memory cost 0.00017404556274414062 seconds
DEBUG 01-07 10:14:14.706611.706611 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 10:14:14.706943.706943 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 10:14:14.706560.706560 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 10:14:14.706495.706495 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 9925599b-4194-460e-8d10-6090c13f1774
DEBUG 01-07 10:14:14.706493.706493 client.py:106] call stub.LoadModelAsync
INFO 01-07 10:14:14.707996.707996 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 9925599b-4194-460e-8d10-6090c13f1774
DEBUG 01-07 10:14:14.707680.707680 cuda_h.py:19] end load_into_gpu_async cost 0.0010325908660888672 seconds
DEBUG 01-07 10:14:14.707237.707237 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 10:14:14.707240.707240 cuda_h.py:19] end restore_tensors2 cost 0.0002574920654296875 seconds
DEBUG 01-07 10:14:14.707731.707731 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.00177001953125 seconds
DEBUG 01-07 10:14:14.709026.709026 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model_multi_device cost 0.007618904113769531 seconds
DEBUG 01-07 10:14:14.709531.709531 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-07 10:14:14.709593.709593 lmp.py:816] 
DEBUG 01-07 10:14:14.709593.709593 lmp.py:816]   Computing 19 experts on CPU...
DEBUG 01-07 10:14:14.709906.709906 cuda_h.py:19] end cpu_experts_submit cost 0.00010752677917480469 seconds
DEBUG 01-07 10:14:14.709225.709225 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-07 10:14:14.716047.716047 mlpmodule.py:749] group tensors cost 0.006566762924194336 s
DEBUG 01-07 10:14:14.719488.719488 mlpmodule.py:787] pad cost 0.0016548633575439453 s
DEBUG 01-07 10:14:14.719454.719454 mlpmodule.py:793] create cpu tensor cost 6.127357482910156e-05 s
DEBUG 01-07 10:14:14.719073.719073 mlpmodule.py:798] move to cpu cost 4.57763671875e-05 s
DEBUG 01-07 10:14:14.729919.729919 mlpmodule.py:812] group_w3: shape=torch.Size([19, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=54788096
DEBUG 01-07 10:14:14.729502.729502 mlpmodule.py:813] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-07 10:14:14.729221.729221 mlpmodule.py:818] group_w3 first element: -0.054931640625
WARNING 01-07 10:14:14.729874.729874 mlpmodule.py:828] start einsum2
DEBUG 01-07 10:14:14.744272.744272 mlpmodule.py:838] group einsum cost 0.0252225399017334 s
DEBUG 01-07 10:14:14.745193.745193 mlpmodule.py:846] cpy2cputensor cost 0.0003807544708251953 s
DEBUG 01-07 10:14:14.747458.747458 cuda_h.py:19] end wait_cetm_experts cost 0.03797793388366699 seconds
DEBUG 01-07 10:14:14.747587.747587 cuda_h.py:10] start gpu_sexperts
DEBUG 01-07 10:14:14.748668.748668 cuda_h.py:19] end gpu_sexperts cost 0.0005781650543212891 seconds
DEBUG 01-07 10:14:14.748127.748127 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-07 10:14:14.748115.748115 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.4080276489257812e-05 seconds
DEBUG 01-07 10:14:14.748587.748587 cuda_h.py:10] start wait_experts_multi_device
INFO 01-07 10:14:14.748681.748681 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 34397c5f-af17-48e3-9fdf-22c8f0e1a91f
INFO 01-07 10:14:14.749192.749192 client.py:127] Model loaded
INFO 01-07 10:14:14.749684.749684 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 9925599b-4194-460e-8d10-6090c13f1774
INFO 01-07 10:14:14.750259.750259 client.py:127] Model loaded
DEBUG 01-07 10:14:14.750420.750420 cuda_h.py:19] end wait_experts_multi_device cost 0.0013201236724853516 seconds
DEBUG 01-07 10:14:14.750315.750315 cuda_h.py:10] start gpu_experts_multi_device
DEBUG 01-07 10:14:14.750376.750376 lmp.py:867]   Computing 22 experts on cuda:2...
DEBUG 01-07 10:14:14.751494.751494 mlpmodule.py:533] gpu group tensors cost 0.0004832744598388672 s
DEBUG 01-07 10:14:14.752947.752947 mlpmodule.py:566] gpu pad cost 0.0012226104736328125 s
DEBUG 01-07 10:14:14.753048.753048 mlpmodule.py:584] gpu group einsum cost 0.0005729198455810547 s
DEBUG 01-07 10:14:14.755982.755982 mlpmodule.py:656] gpu experts func einsum cost 0.004390239715576172 s
DEBUG 01-07 10:14:14.755879.755879 lmp.py:867]   Computing 23 experts on cuda:1...
DEBUG 01-07 10:14:14.756557.756557 mlpmodule.py:707]  experts func einsum cost 0.04614877700805664 s
DEBUG 01-07 10:14:14.756688.756688 mlpmodule.py:533] gpu group tensors cost 0.00054931640625 s
DEBUG 01-07 10:14:14.757639.757639 mlpmodule.py:566] gpu pad cost 0.0012173652648925781 s
DEBUG 01-07 10:14:14.758286.758286 mlpmodule.py:584] gpu group einsum cost 0.0004515647888183594 s
DEBUG 01-07 10:14:14.760743.760743 mlpmodule.py:656] gpu experts func einsum cost 0.0043506622314453125 s
DEBUG 01-07 10:14:14.760342.760342 cuda_h.py:19] end gpu_experts_multi_device cost 0.010068893432617188 seconds
DEBUG 01-07 10:14:14.760219.760219 cuda_h.py:19] end layer_moe_generate_multi_device_3 cost 0.06083345413208008 seconds
DEBUG 01-07 10:14:14.760500.760500 lmp.py:194] -------------------------------- end prefill layer 3 --------------------------------
DEBUG 01-07 10:14:14.760760.760760 lmp.py:153] -------------------------------- start prefill layer 4 --------------------------------
DEBUG 01-07 10:14:14.760409.760409 cuda_h.py:10] start start_load_qkvogn_s_weight_l_5
DEBUG 01-07 10:14:14.760165.760165 cuda_h.py:10] start start_load_qkvogn_s_weight_l_5
DEBUG 01-07 10:14:14.760525.760525 cuda_h.py:19] end start_load_qkvogn_s_weight_l_5 cost 2.6941299438476562e-05 seconds
DEBUG 01-07 10:14:14.760181.760181 cuda_h.py:19] end start_load_qkvogn_s_weight_l_5 cost 5.841255187988281e-05 seconds
DEBUG 01-07 10:14:14.760685.760685 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-07 10:14:14.760999.760999 mlpmodule.py:367] cuda:1 cuda:1
DEBUG 01-07 10:14:14.760703.760703 cuda_h.py:10] start sllm_worker_task
DEBUG 01-07 10:14:14.760460.760460 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 10:14:14.761720.761720 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 10:14:14.761220.761220 cuda_h.py:19] end allocate_cuda_memory cost 0.00026535987854003906 seconds
DEBUG 01-07 10:14:14.761421.761421 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 10:14:14.761277.761277 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 10:14:14.761000.761000 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 10:14:14.761987.761987 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, f57c1529-cc62-47a3-99e9-070d6b5a1276
DEBUG 01-07 10:14:14.761612.761612 client.py:106] call stub.LoadModelAsync
DEBUG 01-07 10:14:14.761554.761554 cuda_h.py:10] start self_attn
INFO 01-07 10:14:14.762218.762218 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, f57c1529-cc62-47a3-99e9-070d6b5a1276
DEBUG 01-07 10:14:14.762717.762717 cuda_h.py:19] end load_into_gpu_async cost 0.0008859634399414062 seconds
DEBUG 01-07 10:14:14.762533.762533 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 10:14:14.762470.762470 cuda_h.py:19] end restore_tensors2 cost 6.794929504394531e-05 seconds
DEBUG 01-07 10:14:14.762272.762272 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0014827251434326172 seconds
INFO 01-07 10:14:14.762287.762287 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, f57c1529-cc62-47a3-99e9-070d6b5a1276
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-07 10:14:14.765765.765765 cuda_h.py:19] end self_attn cost 0.0036773681640625 seconds
DEBUG 01-07 10:14:14.765034.765034 cuda_h.py:19] end iln_self_attn_paln cost 0.005038022994995117 seconds
DEBUG 01-07 10:14:14.765956.765956 cuda_h.py:10] start layer_moe_generate_multi_device_4
DEBUG 01-07 10:14:14.765858.765858 cuda_h.py:10] start gate
DEBUG 01-07 10:14:14.766052.766052 cuda_h.py:19] end gate cost 0.0006375312805175781 seconds
DEBUG 01-07 10:14:14.766928.766928 cuda_h.py:10] start experts_map_get
DEBUG 01-07 10:14:14.767578.767578 lmp.py:744] 
DEBUG 01-07 10:14:14.767578.767578 lmp.py:744] Expert Token Distribution & Multi-Device Allocation:
DEBUG 01-07 10:14:14.767785.767785 lmp.py:745]   Total experts: 64
DEBUG 01-07 10:14:14.767057.767057 lmp.py:746]   CPU experts: 19 (30%)
DEBUG 01-07 10:14:14.767607.767607 lmp.py:747]   GPU experts: 45 (70%)
DEBUG 01-07 10:14:14.767535.767535 lmp.py:748]   Number of GPU devices: 2
DEBUG 01-07 10:14:14.767271.767271 lmp.py:749] 
DEBUG 01-07 10:14:14.767271.767271 lmp.py:749]   Expert ID | Tokens | Device
DEBUG 01-07 10:14:14.767245.767245 lmp.py:750]   -----------------------------------
DEBUG 01-07 10:14:14.767610.767610 lmp.py:767]   Expert 14 |     66 | CPU
DEBUG 01-07 10:14:14.767014.767014 lmp.py:767]   Expert 57 |     73 | CPU
DEBUG 01-07 10:14:14.767419.767419 lmp.py:767]   Expert 13 |     75 | CPU
DEBUG 01-07 10:14:14.767631.767631 lmp.py:767]   Expert 26 |     77 | CPU
DEBUG 01-07 10:14:14.767844.767844 lmp.py:767]   Expert 11 |     90 | CPU
DEBUG 01-07 10:14:14.767056.767056 lmp.py:767]   Expert 31 |     91 | CPU
DEBUG 01-07 10:14:14.767792.767792 lmp.py:767]   Expert 54 |     92 | CPU
DEBUG 01-07 10:14:14.767766.767766 lmp.py:767]   Expert 45 |     95 | CPU
DEBUG 01-07 10:14:14.767501.767501 lmp.py:767]   Expert 30 |    104 | CPU
DEBUG 01-07 10:14:14.767714.767714 lmp.py:767]   Expert 58 |    104 | CPU
DEBUG 01-07 10:14:14.767165.767165 lmp.py:767]   Expert 51 |    105 | CPU
DEBUG 01-07 10:14:14.767900.767900 lmp.py:767]   Expert 10 |    113 | CPU
DEBUG 01-07 10:14:14.767636.767636 lmp.py:767]   Expert 32 |    114 | CPU
DEBUG 01-07 10:14:14.767133.767133 lmp.py:767]   Expert 36 |    115 | CPU
DEBUG 01-07 10:14:14.767107.767107 lmp.py:767]   Expert 20 |    130 | CPU
DEBUG 01-07 10:14:14.767081.767081 lmp.py:767]   Expert  8 |    135 | CPU
DEBUG 01-07 10:14:14.767817.767817 lmp.py:767]   Expert 63 |    137 | CPU
DEBUG 01-07 10:14:14.767791.767791 lmp.py:767]   Expert  4 |    138 | CPU
DEBUG 01-07 10:14:14.767527.767527 lmp.py:767]   Expert 53 |    140 | CPU
DEBUG 01-07 10:14:14.767931.767931 lmp.py:767]   Expert 34 |    142 | GPU1(cuda:2)
DEBUG 01-07 10:14:14.767243.767243 lmp.py:767]   Expert 61 |    143 | GPU0(cuda:1)
DEBUG 01-07 10:14:14.767363.767363 lmp.py:767]   Expert 16 |    144 | GPU1(cuda:2)
DEBUG 01-07 10:14:14.767291.767291 lmp.py:767]   Expert 47 |    145 | GPU0(cuda:1)
DEBUG 01-07 10:14:14.767218.767218 lmp.py:767]   Expert 28 |    159 | GPU1(cuda:2)
DEBUG 01-07 10:14:14.767146.767146 lmp.py:767]   Expert 60 |    160 | GPU0(cuda:1)
DEBUG 01-07 10:14:14.767789.767789 lmp.py:767]   Expert 17 |    161 | GPU1(cuda:2)
DEBUG 01-07 10:14:14.767194.767194 lmp.py:767]   Expert 42 |    166 | GPU0(cuda:1)
DEBUG 01-07 10:14:14.767121.767121 lmp.py:767]   Expert 44 |    168 | GPU1(cuda:2)
DEBUG 01-07 10:14:14.767287.767287 lmp.py:767]   Expert  7 |    175 | GPU1(cuda:2)
DEBUG 01-07 10:14:14.767738.767738 lmp.py:767]   Expert 29 |    175 | GPU0(cuda:1)
DEBUG 01-07 10:14:14.767428.767428 lmp.py:767]   Expert 27 |    177 | GPU0(cuda:1)
DEBUG 01-07 10:14:14.767117.767117 lmp.py:767]   Expert 41 |    181 | GPU1(cuda:2)
DEBUG 01-07 10:14:14.767806.767806 lmp.py:767]   Expert  9 |    182 | GPU0(cuda:1)
DEBUG 01-07 10:14:14.767211.767211 lmp.py:767]   Expert 48 |    183 | GPU1(cuda:2)
DEBUG 01-07 10:14:14.767854.767854 lmp.py:767]   Expert 56 |    185 | GPU0(cuda:1)
DEBUG 01-07 10:14:14.767020.767020 lmp.py:767]   Expert  3 |    188 | GPU1(cuda:2)
DEBUG 01-07 10:14:14.767948.767948 lmp.py:767]   Expert  2 |    189 | GPU0(cuda:1)
DEBUG 01-07 10:14:14.767637.767637 lmp.py:767]   Expert 15 |    190 | GPU1(cuda:2)
DEBUG 01-07 10:14:14.767803.767803 lmp.py:767]   Expert  0 |    194 | GPU1(cuda:2)
DEBUG 01-07 10:14:14.767492.767492 lmp.py:767]   Expert 24 |    194 | GPU0(cuda:1)
DEBUG 01-07 10:14:14.767420.767420 lmp.py:767]   Expert 18 |    200 | GPU0(cuda:1)
DEBUG 01-07 10:14:14.767063.767063 lmp.py:767]   Expert 55 |    208 | GPU1(cuda:2)
DEBUG 01-07 10:14:14.767991.767991 lmp.py:767]   Expert 23 |    211 | GPU0(cuda:1)
DEBUG 01-07 10:14:14.767919.767919 lmp.py:767]   Expert 40 |    216 | GPU1(cuda:2)
DEBUG 01-07 10:14:14.767608.767608 lmp.py:767]   Expert 22 |    217 | GPU1(cuda:2)
DEBUG 01-07 10:14:14.767059.767059 lmp.py:767]   Expert 38 |    217 | GPU0(cuda:1)
DEBUG 01-07 10:14:14.768748.768748 lmp.py:767]   Expert 37 |    223 | GPU0(cuda:1)
DEBUG 01-07 10:14:14.768437.768437 lmp.py:767]   Expert  6 |    224 | GPU1(cuda:2)
DEBUG 01-07 10:14:14.768842.768842 lmp.py:767]   Expert 46 |    234 | GPU0(cuda:1)
DEBUG 01-07 10:14:14.768246.768246 lmp.py:767]   Expert 19 |    244 | GPU0(cuda:1)
DEBUG 01-07 10:14:14.768413.768413 lmp.py:767]   Expert 39 |    244 | GPU1(cuda:2)
DEBUG 01-07 10:14:14.768102.768102 lmp.py:767]   Expert 25 |    253 | GPU1(cuda:2)
DEBUG 01-07 10:14:14.768791.768791 lmp.py:767]   Expert 50 |    259 | GPU0(cuda:1)
DEBUG 01-07 10:14:14.768242.768242 lmp.py:767]   Expert 12 |    261 | GPU1(cuda:2)
DEBUG 01-07 10:14:14.768931.768931 lmp.py:767]   Expert 62 |    276 | GPU0(cuda:1)
DEBUG 01-07 10:14:14.768621.768621 lmp.py:767]   Expert 21 |    285 | GPU1(cuda:2)
DEBUG 01-07 10:14:14.768787.768787 lmp.py:767]   Expert 35 |    286 | GPU0(cuda:1)
DEBUG 01-07 10:14:14.768191.768191 lmp.py:767]   Expert 49 |    292 | GPU1(cuda:2)
DEBUG 01-07 10:14:14.768119.768119 lmp.py:767]   Expert 33 |    293 | GPU0(cuda:1)
DEBUG 01-07 10:14:14.768047.768047 lmp.py:767]   Expert 52 |    300 | GPU1(cuda:2)
DEBUG 01-07 10:14:14.768498.768498 lmp.py:767]   Expert  1 |    347 | GPU0(cuda:1)
DEBUG 01-07 10:14:14.768187.768187 lmp.py:767]   Expert  5 |    382 | GPU1(cuda:2)
DEBUG 01-07 10:14:14.768115.768115 lmp.py:767]   Expert 43 |    440 | GPU1(cuda:2)
DEBUG 01-07 10:14:14.768804.768804 lmp.py:767]   Expert 59 |    581 | GPU0(cuda:1)
DEBUG 01-07 10:14:14.768255.768255 lmp.py:769] 
DEBUG 01-07 10:14:14.768255.768255 lmp.py:769]   Device Token Distribution:
DEBUG 01-07 10:14:14.768421.768421 lmp.py:770]   CPU:   1994 tokens
DEBUG 01-07 10:14:14.768826.768826 lmp.py:774]   cuda:1:   5087 tokens (22 experts)
DEBUG 01-07 10:14:14.768038.768038 lmp.py:774]   cuda:2:   5207 tokens (23 experts)
DEBUG 01-07 10:14:14.768489.768489 lmp.py:775]   Total GPU:  10294 tokens
DEBUG 01-07 10:14:14.768331.768331 lmp.py:776] ============================================================
DEBUG 01-07 10:14:14.768331.768331 lmp.py:776] 
DEBUG 01-07 10:14:14.768941.768941 cuda_h.py:19] end experts_map_get cost 0.0017304420471191406 seconds
DEBUG 01-07 10:14:14.768776.768776 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model_multi_device
DEBUG 01-07 10:14:14.768407.768407 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 10:14:14.768410.768410 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 10:14:14.768199.768199 cuda_h.py:19] end allocate_cuda_memory cost 0.00019931793212890625 seconds
DEBUG 01-07 10:14:14.768751.768751 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 10:14:14.768169.768169 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 10:14:14.768025.768025 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 10:14:14.768436.768436 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, e7d2f144-1fa4-45f0-977c-2f9a3f8fd7c3
DEBUG 01-07 10:14:14.769348.769348 client.py:106] call stub.LoadModelAsync
INFO 01-07 10:14:14.769730.769730 client.py:127] Model loaded
DEBUG 01-07 10:14:14.769419.769419 cuda_h.py:19] end sllm_worker_task cost 0.008678197860717773 seconds
INFO 01-07 10:14:14.769946.769946 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, e7d2f144-1fa4-45f0-977c-2f9a3f8fd7c3
DEBUG 01-07 10:14:14.769835.769835 cuda_h.py:19] end load_into_gpu_async cost 0.0009102821350097656 seconds
DEBUG 01-07 10:14:14.769393.769393 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 10:14:14.770642.770642 cuda_h.py:19] end restore_tensors2 cost 0.0003001689910888672 seconds
DEBUG 01-07 10:14:14.770895.770895 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0017085075378417969 seconds
DEBUG 01-07 10:14:14.772281.772281 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 10:14:14.772934.772934 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 10:14:14.772975.772975 cuda_h.py:19] end allocate_cuda_memory cost 0.00020384788513183594 seconds
DEBUG 01-07 10:14:14.772196.772196 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 10:14:14.772044.772044 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 10:14:14.772661.772661 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 10:14:14.772311.772311 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, b7c7a255-9956-402a-b773-a2b1257bb41d
DEBUG 01-07 10:14:14.772541.772541 client.py:106] call stub.LoadModelAsync
INFO 01-07 10:14:14.773727.773727 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, b7c7a255-9956-402a-b773-a2b1257bb41d
DEBUG 01-07 10:14:14.773887.773887 cuda_h.py:19] end load_into_gpu_async cost 0.0010404586791992188 seconds
DEBUG 01-07 10:14:14.773206.773206 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 10:14:14.773833.773833 cuda_h.py:19] end restore_tensors2 cost 0.00029659271240234375 seconds
DEBUG 01-07 10:14:14.773993.773993 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0018417835235595703 seconds
DEBUG 01-07 10:14:14.775632.775632 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model_multi_device cost 0.007348060607910156 seconds
DEBUG 01-07 10:14:14.775892.775892 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-07 10:14:14.775855.775855 lmp.py:816] 
DEBUG 01-07 10:14:14.775855.775855 lmp.py:816]   Computing 19 experts on CPU...
DEBUG 01-07 10:14:14.776976.776976 cuda_h.py:19] end cpu_experts_submit cost 0.00010395050048828125 seconds
DEBUG 01-07 10:14:14.776818.776818 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-07 10:14:14.781229.781229 mlpmodule.py:749] group tensors cost 0.005619525909423828 s
DEBUG 01-07 10:14:14.783882.783882 mlpmodule.py:787] pad cost 0.0010759830474853516 s
DEBUG 01-07 10:14:14.783694.783694 mlpmodule.py:793] create cpu tensor cost 4.4345855712890625e-05 s
DEBUG 01-07 10:14:14.783365.783365 mlpmodule.py:798] move to cpu cost 3.3855438232421875e-05 s
DEBUG 01-07 10:14:14.793473.793473 mlpmodule.py:812] group_w3: shape=torch.Size([19, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=54788096
DEBUG 01-07 10:14:14.793208.793208 mlpmodule.py:813] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-07 10:14:14.793781.793781 mlpmodule.py:818] group_w3 first element: 0.0086669921875
WARNING 01-07 10:14:14.793627.793627 mlpmodule.py:828] start einsum2
DEBUG 01-07 10:14:14.808692.808692 mlpmodule.py:838] group einsum cost 0.024526357650756836 s
DEBUG 01-07 10:14:14.808820.808820 mlpmodule.py:846] cpy2cputensor cost 0.0004088878631591797 s
DEBUG 01-07 10:14:14.811344.811344 cuda_h.py:19] end wait_cetm_experts cost 0.035456180572509766 seconds
DEBUG 01-07 10:14:14.811566.811566 cuda_h.py:10] start gpu_sexperts
DEBUG 01-07 10:14:14.812306.812306 cuda_h.py:19] end gpu_sexperts cost 0.0005028247833251953 seconds
DEBUG 01-07 10:14:14.812341.812341 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-07 10:14:14.812807.812807 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.384185791015625e-05 seconds
DEBUG 01-07 10:14:14.812271.812271 cuda_h.py:10] start wait_experts_multi_device
INFO 01-07 10:14:14.812743.812743 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, e7d2f144-1fa4-45f0-977c-2f9a3f8fd7c3
INFO 01-07 10:14:14.813251.813251 client.py:127] Model loaded
INFO 01-07 10:14:14.813941.813941 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, b7c7a255-9956-402a-b773-a2b1257bb41d
INFO 01-07 10:14:14.816424.816424 client.py:127] Model loaded
DEBUG 01-07 10:14:14.816400.816400 cuda_h.py:19] end wait_experts_multi_device cost 0.003997087478637695 seconds
DEBUG 01-07 10:14:14.816248.816248 cuda_h.py:10] start gpu_experts_multi_device
DEBUG 01-07 10:14:14.816237.816237 lmp.py:867]   Computing 23 experts on cuda:2...
DEBUG 01-07 10:14:14.817462.817462 mlpmodule.py:533] gpu group tensors cost 0.0005068778991699219 s
DEBUG 01-07 10:14:14.818030.818030 mlpmodule.py:566] gpu pad cost 0.0012695789337158203 s
DEBUG 01-07 10:14:14.819475.819475 mlpmodule.py:584] gpu group einsum cost 0.0005714893341064453 s
DEBUG 01-07 10:14:14.820123.820123 mlpmodule.py:707]  experts func einsum cost 0.04421663284301758 s
DEBUG 01-07 10:14:14.821342.821342 mlpmodule.py:656] gpu experts func einsum cost 0.004839420318603516 s
DEBUG 01-07 10:14:14.822460.822460 lmp.py:867]   Computing 22 experts on cuda:1...
DEBUG 01-07 10:14:14.823027.823027 mlpmodule.py:533] gpu group tensors cost 0.0004520416259765625 s
DEBUG 01-07 10:14:14.824718.824718 mlpmodule.py:566] gpu pad cost 0.0014019012451171875 s
DEBUG 01-07 10:14:14.825293.825293 mlpmodule.py:584] gpu group einsum cost 0.0006499290466308594 s
DEBUG 01-07 10:14:14.826270.826270 mlpmodule.py:656] gpu experts func einsum cost 0.004353523254394531 s
DEBUG 01-07 10:14:14.827759.827759 cuda_h.py:19] end gpu_experts_multi_device cost 0.010656595230102539 seconds
DEBUG 01-07 10:14:14.827013.827013 cuda_h.py:19] end layer_moe_generate_multi_device_4 cost 0.06121373176574707 seconds
DEBUG 01-07 10:14:14.827657.827657 lmp.py:194] -------------------------------- end prefill layer 4 --------------------------------
DEBUG 01-07 10:14:14.827340.827340 lmp.py:153] -------------------------------- start prefill layer 5 --------------------------------
DEBUG 01-07 10:14:14.827037.827037 cuda_h.py:10] start start_load_qkvogn_s_weight_l_6
DEBUG 01-07 10:14:14.827508.827508 cuda_h.py:10] start start_load_qkvogn_s_weight_l_6
DEBUG 01-07 10:14:14.827390.827390 cuda_h.py:19] end start_load_qkvogn_s_weight_l_6 cost 2.7418136596679688e-05 seconds
DEBUG 01-07 10:14:14.827762.827762 cuda_h.py:19] end start_load_qkvogn_s_weight_l_6 cost 6.008148193359375e-05 seconds
DEBUG 01-07 10:14:14.827551.827551 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-07 10:14:14.827480.827480 cuda_h.py:10] start sllm_worker_task
DEBUG 01-07 10:14:14.827563.827563 mlpmodule.py:367] cuda:1 cuda:1
DEBUG 01-07 10:14:14.827809.827809 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 10:14:14.827687.827687 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 10:14:14.828423.828423 cuda_h.py:19] end allocate_cuda_memory cost 0.00018477439880371094 seconds
DEBUG 01-07 10:14:14.828300.828300 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 10:14:14.828593.828593 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 10:14:14.828038.828038 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 10:14:14.828199.828199 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, bbf83c8b-b083-456c-a505-99f3cc3a0c57
DEBUG 01-07 10:14:14.828182.828182 client.py:106] call stub.LoadModelAsync
DEBUG 01-07 10:14:14.828772.828772 cuda_h.py:10] start self_attn
INFO 01-07 10:14:14.829497.829497 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, bbf83c8b-b083-456c-a505-99f3cc3a0c57
DEBUG 01-07 10:14:14.829612.829612 cuda_h.py:19] end load_into_gpu_async cost 0.0009586811065673828 seconds
DEBUG 01-07 10:14:14.829157.829157 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 10:14:14.829009.829009 cuda_h.py:19] end restore_tensors2 cost 9.822845458984375e-05 seconds
DEBUG 01-07 10:14:14.829905.829905 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0015873908996582031 seconds
INFO 01-07 10:14:14.829192.829192 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, bbf83c8b-b083-456c-a505-99f3cc3a0c57
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-07 10:14:14.832570.832570 cuda_h.py:19] end self_attn cost 0.003797292709350586 seconds
DEBUG 01-07 10:14:14.832508.832508 cuda_h.py:19] end iln_self_attn_paln cost 0.005206584930419922 seconds
DEBUG 01-07 10:14:14.832668.832668 cuda_h.py:10] start layer_moe_generate_multi_device_5
DEBUG 01-07 10:14:14.832285.832285 cuda_h.py:10] start gate
DEBUG 01-07 10:14:14.833857.833857 cuda_h.py:19] end gate cost 0.0006339550018310547 seconds
DEBUG 01-07 10:14:14.833495.833495 cuda_h.py:10] start experts_map_get
DEBUG 01-07 10:14:14.834237.834237 lmp.py:744] 
DEBUG 01-07 10:14:14.834237.834237 lmp.py:744] Expert Token Distribution & Multi-Device Allocation:
DEBUG 01-07 10:14:14.834152.834152 lmp.py:745]   Total experts: 64
DEBUG 01-07 10:14:14.834471.834471 lmp.py:746]   CPU experts: 19 (30%)
DEBUG 01-07 10:14:14.834498.834498 lmp.py:747]   GPU experts: 45 (70%)
DEBUG 01-07 10:14:14.834902.834902 lmp.py:748]   Number of GPU devices: 2
DEBUG 01-07 10:14:14.834592.834592 lmp.py:749] 
DEBUG 01-07 10:14:14.834592.834592 lmp.py:749]   Expert ID | Tokens | Device
DEBUG 01-07 10:14:14.834520.834520 lmp.py:750]   -----------------------------------
DEBUG 01-07 10:14:14.834646.834646 lmp.py:767]   Expert 34 |     25 | CPU
DEBUG 01-07 10:14:14.834289.834289 lmp.py:767]   Expert 45 |     61 | CPU
DEBUG 01-07 10:14:14.834978.834978 lmp.py:767]   Expert 22 |     73 | CPU
DEBUG 01-07 10:14:14.834668.834668 lmp.py:767]   Expert 57 |     78 | CPU
DEBUG 01-07 10:14:14.834834.834834 lmp.py:767]   Expert 17 |     94 | CPU
DEBUG 01-07 10:14:14.834285.834285 lmp.py:767]   Expert 15 |     96 | CPU
DEBUG 01-07 10:14:14.834736.834736 lmp.py:767]   Expert  4 |    101 | CPU
DEBUG 01-07 10:14:14.834186.834186 lmp.py:767]   Expert 28 |    110 | CPU
DEBUG 01-07 10:14:14.834637.834637 lmp.py:767]   Expert 32 |    114 | CPU
DEBUG 01-07 10:14:14.834088.834088 lmp.py:767]   Expert 60 |    115 | CPU
DEBUG 01-07 10:14:14.834539.834539 lmp.py:767]   Expert 16 |    121 | CPU
DEBUG 01-07 10:14:14.834752.834752 lmp.py:767]   Expert 36 |    122 | CPU
DEBUG 01-07 10:14:14.834156.834156 lmp.py:767]   Expert 52 |    126 | CPU
DEBUG 01-07 10:14:14.834038.834038 lmp.py:767]   Expert 14 |    127 | CPU
DEBUG 01-07 10:14:14.834488.834488 lmp.py:767]   Expert 12 |    129 | CPU
DEBUG 01-07 10:14:14.834224.834224 lmp.py:767]   Expert 25 |    129 | CPU
DEBUG 01-07 10:14:14.834198.834198 lmp.py:767]   Expert  2 |    138 | CPU
DEBUG 01-07 10:14:14.834411.834411 lmp.py:767]   Expert  8 |    138 | CPU
DEBUG 01-07 10:14:14.834146.834146 lmp.py:767]   Expert  5 |    145 | CPU
DEBUG 01-07 10:14:14.834266.834266 lmp.py:767]   Expert 35 |    145 | GPU0(cuda:1)
DEBUG 01-07 10:14:14.834386.834386 lmp.py:767]   Expert 23 |    152 | GPU1(cuda:2)
DEBUG 01-07 10:14:14.834790.834790 lmp.py:767]   Expert 30 |    153 | GPU0(cuda:1)
DEBUG 01-07 10:14:14.834718.834718 lmp.py:767]   Expert 61 |    154 | GPU1(cuda:2)
DEBUG 01-07 10:14:14.834407.834407 lmp.py:767]   Expert 39 |    155 | GPU0(cuda:1)
DEBUG 01-07 10:14:14.834574.834574 lmp.py:767]   Expert  0 |    164 | GPU1(cuda:2)
DEBUG 01-07 10:14:14.834501.834501 lmp.py:767]   Expert  3 |    168 | GPU0(cuda:1)
DEBUG 01-07 10:14:14.834429.834429 lmp.py:767]   Expert 42 |    170 | GPU1(cuda:2)
DEBUG 01-07 10:14:14.834357.834357 lmp.py:767]   Expert 13 |    172 | GPU0(cuda:1)
DEBUG 01-07 10:14:14.834284.834284 lmp.py:767]   Expert 44 |    173 | GPU1(cuda:2)
DEBUG 01-07 10:14:14.834212.834212 lmp.py:767]   Expert 41 |    175 | GPU0(cuda:1)
DEBUG 01-07 10:14:14.834332.834332 lmp.py:767]   Expert  9 |    176 | GPU1(cuda:2)
DEBUG 01-07 10:14:14.834260.834260 lmp.py:767]   Expert 31 |    178 | GPU0(cuda:1)
DEBUG 01-07 10:14:14.834426.834426 lmp.py:767]   Expert 46 |    180 | GPU1(cuda:2)
DEBUG 01-07 10:14:14.834592.834592 lmp.py:767]   Expert 43 |    184 | GPU0(cuda:1)
DEBUG 01-07 10:14:14.834281.834281 lmp.py:767]   Expert 26 |    186 | GPU1(cuda:2)
DEBUG 01-07 10:14:14.834209.834209 lmp.py:767]   Expert 62 |    188 | GPU0(cuda:1)
DEBUG 01-07 10:14:14.834137.834137 lmp.py:767]   Expert 18 |    194 | GPU0(cuda:1)
DEBUG 01-07 10:14:14.834064.834064 lmp.py:767]   Expert 51 |    194 | GPU1(cuda:2)
DEBUG 01-07 10:14:14.834707.834707 lmp.py:767]   Expert 27 |    195 | GPU1(cuda:2)
DEBUG 01-07 10:14:14.834112.834112 lmp.py:767]   Expert 49 |    196 | GPU0(cuda:1)
DEBUG 01-07 10:14:14.834040.834040 lmp.py:767]   Expert 50 |    197 | GPU1(cuda:2)
DEBUG 01-07 10:14:14.834967.834967 lmp.py:767]   Expert 11 |    201 | GPU0(cuda:1)
DEBUG 01-07 10:14:14.834418.834418 lmp.py:767]   Expert 20 |    202 | GPU0(cuda:1)
DEBUG 01-07 10:14:14.834346.834346 lmp.py:767]   Expert 47 |    202 | GPU1(cuda:2)
DEBUG 01-07 10:14:14.834035.834035 lmp.py:767]   Expert 19 |    204 | GPU1(cuda:2)
DEBUG 01-07 10:14:14.834963.834963 lmp.py:767]   Expert 55 |    207 | GPU1(cuda:2)
DEBUG 01-07 10:14:14.834036.834036 lmp.py:767]   Expert 63 |    207 | GPU0(cuda:1)
DEBUG 01-07 10:14:14.834156.834156 lmp.py:767]   Expert 56 |    212 | GPU0(cuda:1)
DEBUG 01-07 10:14:14.834322.834322 lmp.py:767]   Expert 38 |    217 | GPU1(cuda:2)
DEBUG 01-07 10:14:14.835489.835489 lmp.py:767]   Expert 48 |    224 | GPU0(cuda:1)
DEBUG 01-07 10:14:14.835655.835655 lmp.py:767]   Expert  1 |    235 | GPU1(cuda:2)
DEBUG 01-07 10:14:14.835582.835582 lmp.py:767]   Expert 10 |    242 | GPU0(cuda:1)
DEBUG 01-07 10:14:14.835510.835510 lmp.py:767]   Expert 54 |    246 | GPU1(cuda:2)
DEBUG 01-07 10:14:14.835199.835199 lmp.py:767]   Expert  7 |    249 | GPU0(cuda:1)
DEBUG 01-07 10:14:14.835127.835127 lmp.py:767]   Expert 21 |    254 | GPU1(cuda:2)
DEBUG 01-07 10:14:14.835009.835009 lmp.py:767]   Expert 33 |    255 | GPU0(cuda:1)
DEBUG 01-07 10:14:14.835605.835605 lmp.py:767]   Expert 29 |    258 | GPU1(cuda:2)
DEBUG 01-07 10:14:14.835487.835487 lmp.py:767]   Expert 24 |    268 | GPU0(cuda:1)
DEBUG 01-07 10:14:14.835130.835130 lmp.py:767]   Expert 40 |    269 | GPU1(cuda:2)
DEBUG 01-07 10:14:14.835773.835773 lmp.py:767]   Expert 59 |    296 | GPU0(cuda:1)
DEBUG 01-07 10:14:14.835654.835654 lmp.py:767]   Expert 37 |    338 | GPU1(cuda:2)
DEBUG 01-07 10:14:14.835297.835297 lmp.py:767]   Expert 58 |    366 | GPU1(cuda:2)
DEBUG 01-07 10:14:14.835940.835940 lmp.py:767]   Expert  6 |    384 | GPU1(cuda:2)
DEBUG 01-07 10:14:14.835060.835060 lmp.py:767]   Expert 53 |    861 | GPU0(cuda:1)
DEBUG 01-07 10:14:14.835464.835464 lmp.py:769] 
DEBUG 01-07 10:14:14.835464.835464 lmp.py:769]   Device Token Distribution:
DEBUG 01-07 10:14:14.835822.835822 lmp.py:770]   CPU:   2042 tokens
DEBUG 01-07 10:14:14.835181.835181 lmp.py:774]   cuda:1:   5125 tokens (22 experts)
DEBUG 01-07 10:14:14.835062.835062 lmp.py:774]   cuda:2:   5121 tokens (23 experts)
DEBUG 01-07 10:14:14.835467.835467 lmp.py:775]   Total GPU:  10246 tokens
DEBUG 01-07 10:14:14.835918.835918 lmp.py:776] ============================================================
DEBUG 01-07 10:14:14.835918.835918 lmp.py:776] 
DEBUG 01-07 10:14:14.835044.835044 cuda_h.py:19] end experts_map_get cost 0.0017464160919189453 seconds
DEBUG 01-07 10:14:14.835594.835594 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model_multi_device
DEBUG 01-07 10:14:14.835318.835318 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 10:14:14.835421.835421 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 10:14:14.835722.835722 cuda_h.py:19] end allocate_cuda_memory cost 0.00026035308837890625 seconds
DEBUG 01-07 10:14:14.835678.835678 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 10:14:14.835388.835388 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 10:14:14.835813.835813 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 10:14:14.836270.836270 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 60ab9fd3-9a52-41ab-8d5b-dea84fa38b1e
DEBUG 01-07 10:14:14.836752.836752 client.py:106] call stub.LoadModelAsync
INFO 01-07 10:14:14.836512.836512 client.py:127] Model loaded
DEBUG 01-07 10:14:14.836002.836002 cuda_h.py:19] end sllm_worker_task cost 0.0089263916015625 seconds
INFO 01-07 10:14:14.836601.836601 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 60ab9fd3-9a52-41ab-8d5b-dea84fa38b1e
DEBUG 01-07 10:14:14.837444.837444 cuda_h.py:19] end load_into_gpu_async cost 0.0010924339294433594 seconds
DEBUG 01-07 10:14:14.837432.837432 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 10:14:14.837582.837582 cuda_h.py:19] end restore_tensors2 cost 0.00029587745666503906 seconds
DEBUG 01-07 10:14:14.837073.837073 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.001974821090698242 seconds
DEBUG 01-07 10:14:14.839560.839560 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 10:14:14.839644.839644 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 10:14:14.839446.839446 cuda_h.py:19] end allocate_cuda_memory cost 0.0002033710479736328 seconds
DEBUG 01-07 10:14:14.839190.839190 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 10:14:14.839800.839800 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 10:14:14.839702.839702 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 10:14:14.839590.839590 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 71efab76-0e37-426a-b4a5-848389a06233
DEBUG 01-07 10:14:14.839966.839966 client.py:106] call stub.LoadModelAsync
INFO 01-07 10:14:14.840245.840245 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 71efab76-0e37-426a-b4a5-848389a06233
DEBUG 01-07 10:14:14.840360.840360 cuda_h.py:19] end load_into_gpu_async cost 0.0010771751403808594 seconds
DEBUG 01-07 10:14:14.840155.840155 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 10:14:14.841782.841782 cuda_h.py:19] end restore_tensors2 cost 0.0002956390380859375 seconds
DEBUG 01-07 10:14:14.841989.841989 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0018761157989501953 seconds
DEBUG 01-07 10:14:14.843702.843702 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model_multi_device cost 0.007742643356323242 seconds
DEBUG 01-07 10:14:14.843015.843015 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-07 10:14:14.843078.843078 lmp.py:816] 
DEBUG 01-07 10:14:14.843078.843078 lmp.py:816]   Computing 19 experts on CPU...
DEBUG 01-07 10:14:14.843868.843868 cuda_h.py:19] end cpu_experts_submit cost 0.00010561943054199219 seconds
DEBUG 01-07 10:14:14.843948.843948 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-07 10:14:14.850391.850391 mlpmodule.py:749] group tensors cost 0.0069577693939208984 s
DEBUG 01-07 10:14:14.852656.852656 mlpmodule.py:787] pad cost 0.0014955997467041016 s
DEBUG 01-07 10:14:14.852030.852030 mlpmodule.py:793] create cpu tensor cost 4.1961669921875e-05 s
DEBUG 01-07 10:14:14.853503.853503 mlpmodule.py:798] move to cpu cost 3.218650817871094e-05 s
DEBUG 01-07 10:14:14.863085.863085 mlpmodule.py:812] group_w3: shape=torch.Size([19, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=54788096
DEBUG 01-07 10:14:14.863436.863436 mlpmodule.py:813] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-07 10:14:14.863148.863148 mlpmodule.py:818] group_w3 first element: -0.010498046875
WARNING 01-07 10:14:14.863127.863127 mlpmodule.py:828] start einsum2
DEBUG 01-07 10:14:14.878263.878263 mlpmodule.py:838] group einsum cost 0.025401592254638672 s
DEBUG 01-07 10:14:14.879178.879178 mlpmodule.py:846] cpy2cputensor cost 0.000392913818359375 s
DEBUG 01-07 10:14:14.881451.881451 cuda_h.py:19] end wait_cetm_experts cost 0.03831791877746582 seconds
DEBUG 01-07 10:14:14.881626.881626 cuda_h.py:10] start gpu_sexperts
DEBUG 01-07 10:14:14.882896.882896 cuda_h.py:19] end gpu_sexperts cost 0.0005054473876953125 seconds
DEBUG 01-07 10:14:14.882177.882177 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-07 10:14:14.882073.882073 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.47955322265625e-05 seconds
DEBUG 01-07 10:14:14.882968.882968 cuda_h.py:10] start wait_experts_multi_device
INFO 01-07 10:14:14.882585.882585 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 60ab9fd3-9a52-41ab-8d5b-dea84fa38b1e
INFO 01-07 10:14:14.883152.883152 client.py:127] Model loaded
INFO 01-07 10:14:14.883002.883002 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 71efab76-0e37-426a-b4a5-848389a06233
INFO 01-07 10:14:14.884770.884770 client.py:127] Model loaded
DEBUG 01-07 10:14:14.884799.884799 cuda_h.py:19] end wait_experts_multi_device cost 0.0016345977783203125 seconds
DEBUG 01-07 10:14:14.884031.884031 cuda_h.py:10] start gpu_experts_multi_device
DEBUG 01-07 10:14:14.884569.884569 lmp.py:867]   Computing 23 experts on cuda:2...
DEBUG 01-07 10:14:14.885106.885106 mlpmodule.py:533] gpu group tensors cost 0.0005047321319580078 s
DEBUG 01-07 10:14:14.886529.886529 mlpmodule.py:566] gpu pad cost 0.0013020038604736328 s
DEBUG 01-07 10:14:14.887837.887837 mlpmodule.py:584] gpu group einsum cost 0.0005939006805419922 s
DEBUG 01-07 10:14:14.889890.889890 mlpmodule.py:656] gpu experts func einsum cost 0.004735469818115234 s
DEBUG 01-07 10:14:14.890637.890637 lmp.py:867]   Computing 22 experts on cuda:1...
DEBUG 01-07 10:14:14.890669.890669 mlpmodule.py:533] gpu group tensors cost 0.0004608631134033203 s
DEBUG 01-07 10:14:14.891648.891648 mlpmodule.py:707]  experts func einsum cost 0.047692298889160156 s
DEBUG 01-07 10:14:14.892585.892585 mlpmodule.py:566] gpu pad cost 0.0015969276428222656 s
DEBUG 01-07 10:14:14.893246.893246 mlpmodule.py:584] gpu group einsum cost 0.0012271404266357422 s
DEBUG 01-07 10:14:14.895722.895722 mlpmodule.py:656] gpu experts func einsum cost 0.005204677581787109 s
DEBUG 01-07 10:14:14.895144.895144 cuda_h.py:19] end gpu_experts_multi_device cost 0.01143026351928711 seconds
DEBUG 01-07 10:14:14.895067.895067 cuda_h.py:19] end layer_moe_generate_multi_device_5 cost 0.06290435791015625 seconds
DEBUG 01-07 10:14:14.896837.896837 lmp.py:194] -------------------------------- end prefill layer 5 --------------------------------
DEBUG 01-07 10:14:14.896282.896282 lmp.py:153] -------------------------------- start prefill layer 6 --------------------------------
DEBUG 01-07 10:14:14.896455.896455 cuda_h.py:10] start start_load_qkvogn_s_weight_l_7
DEBUG 01-07 10:14:14.896496.896496 cuda_h.py:10] start start_load_qkvogn_s_weight_l_7
DEBUG 01-07 10:14:14.896617.896617 cuda_h.py:19] end start_load_qkvogn_s_weight_l_7 cost 2.765655517578125e-05 seconds
DEBUG 01-07 10:14:14.896604.896604 cuda_h.py:19] end start_load_qkvogn_s_weight_l_7 cost 5.8650970458984375e-05 seconds
DEBUG 01-07 10:14:14.896678.896678 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-07 10:14:14.896713.896713 mlpmodule.py:367] cuda:1 cuda:1
DEBUG 01-07 10:14:14.896940.896940 cuda_h.py:10] start sllm_worker_task
DEBUG 01-07 10:14:14.896128.896128 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 10:14:14.896527.896527 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 10:14:14.896613.896613 cuda_h.py:19] end allocate_cuda_memory cost 0.000171661376953125 seconds
DEBUG 01-07 10:14:14.896245.896245 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 10:14:14.896862.896862 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 10:14:14.896301.896301 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 10:14:14.896904.896904 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, aff2637b-526f-4224-af95-bf9efa806821
DEBUG 01-07 10:14:14.896860.896860 client.py:106] call stub.LoadModelAsync
DEBUG 01-07 10:14:14.897908.897908 cuda_h.py:10] start self_attn
INFO 01-07 10:14:14.897056.897056 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, aff2637b-526f-4224-af95-bf9efa806821
DEBUG 01-07 10:14:14.897601.897601 cuda_h.py:19] end load_into_gpu_async cost 0.0008957386016845703 seconds
DEBUG 01-07 10:14:14.897919.897919 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 10:14:14.897280.897280 cuda_h.py:19] end restore_tensors2 cost 6.628036499023438e-05 seconds
DEBUG 01-07 10:14:14.897890.897890 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0013761520385742188 seconds
INFO 01-07 10:14:14.897005.897005 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, aff2637b-526f-4224-af95-bf9efa806821
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-07 10:14:14.900975.900975 cuda_h.py:19] end self_attn cost 0.0037097930908203125 seconds
DEBUG 01-07 10:14:14.901416.901416 cuda_h.py:19] end iln_self_attn_paln cost 0.005004405975341797 seconds
DEBUG 01-07 10:14:14.901623.901623 cuda_h.py:10] start layer_moe_generate_multi_device_6
DEBUG 01-07 10:14:14.901525.901525 cuda_h.py:10] start gate
DEBUG 01-07 10:14:14.902594.902594 cuda_h.py:19] end gate cost 0.0006496906280517578 seconds
DEBUG 01-07 10:14:14.902708.902708 cuda_h.py:10] start experts_map_get
DEBUG 01-07 10:14:14.902643.902643 lmp.py:744] 
DEBUG 01-07 10:14:14.902643.902643 lmp.py:744] Expert Token Distribution & Multi-Device Allocation:
DEBUG 01-07 10:14:14.902498.902498 lmp.py:745]   Total experts: 64
DEBUG 01-07 10:14:14.902877.902877 lmp.py:746]   CPU experts: 19 (30%)
DEBUG 01-07 10:14:14.902381.902381 lmp.py:747]   GPU experts: 45 (70%)
DEBUG 01-07 10:14:14.902785.902785 lmp.py:748]   Number of GPU devices: 2
DEBUG 01-07 10:14:14.902236.902236 lmp.py:749] 
DEBUG 01-07 10:14:14.902236.902236 lmp.py:749]   Expert ID | Tokens | Device
DEBUG 01-07 10:14:14.902925.902925 lmp.py:750]   -----------------------------------
DEBUG 01-07 10:14:14.902052.902052 lmp.py:767]   Expert  1 |     44 | CPU
DEBUG 01-07 10:14:14.902695.902695 lmp.py:767]   Expert  7 |     56 | CPU
DEBUG 01-07 10:14:14.902861.902861 lmp.py:767]   Expert 37 |     70 | CPU
DEBUG 01-07 10:14:14.902789.902789 lmp.py:767]   Expert 54 |     82 | CPU
DEBUG 01-07 10:14:14.902240.902240 lmp.py:767]   Expert 17 |     83 | CPU
DEBUG 01-07 10:14:14.902929.902929 lmp.py:767]   Expert 18 |     83 | CPU
DEBUG 01-07 10:14:14.902903.902903 lmp.py:767]   Expert 13 |     91 | CPU
DEBUG 01-07 10:14:14.902115.902115 lmp.py:767]   Expert  9 |     92 | CPU
DEBUG 01-07 10:14:14.902566.902566 lmp.py:767]   Expert 22 |    100 | CPU
DEBUG 01-07 10:14:14.902540.902540 lmp.py:767]   Expert 58 |    100 | CPU
DEBUG 01-07 10:14:14.902991.902991 lmp.py:767]   Expert  0 |    105 | CPU
DEBUG 01-07 10:14:14.902204.902204 lmp.py:767]   Expert 26 |    116 | CPU
DEBUG 01-07 10:14:14.902370.902370 lmp.py:767]   Expert 16 |    117 | CPU
DEBUG 01-07 10:14:14.902821.902821 lmp.py:767]   Expert 10 |    121 | CPU
DEBUG 01-07 10:14:14.902272.902272 lmp.py:767]   Expert 63 |    128 | CPU
DEBUG 01-07 10:14:14.902246.902246 lmp.py:767]   Expert 59 |    129 | CPU
DEBUG 01-07 10:14:14.902220.902220 lmp.py:767]   Expert 62 |    144 | CPU
DEBUG 01-07 10:14:14.902194.902194 lmp.py:767]   Expert 33 |    145 | CPU
DEBUG 01-07 10:14:14.902598.902598 lmp.py:767]   Expert 28 |    147 | CPU
DEBUG 01-07 10:14:14.902718.902718 lmp.py:767]   Expert 43 |    147 | GPU1(cuda:2)
DEBUG 01-07 10:14:14.903361.903361 lmp.py:767]   Expert 29 |    152 | GPU0(cuda:1)
DEBUG 01-07 10:14:14.903766.903766 lmp.py:767]   Expert  2 |    157 | GPU1(cuda:2)
DEBUG 01-07 10:14:14.903932.903932 lmp.py:767]   Expert 51 |    162 | GPU0(cuda:1)
DEBUG 01-07 10:14:14.903621.903621 lmp.py:767]   Expert 45 |    165 | GPU0(cuda:1)
DEBUG 01-07 10:14:14.903787.903787 lmp.py:767]   Expert 55 |    165 | GPU1(cuda:2)
DEBUG 01-07 10:14:14.903715.903715 lmp.py:767]   Expert  3 |    167 | GPU0(cuda:1)
DEBUG 01-07 10:14:14.903881.903881 lmp.py:767]   Expert 53 |    167 | GPU1(cuda:2)
DEBUG 01-07 10:14:14.903286.903286 lmp.py:767]   Expert 23 |    169 | GPU1(cuda:2)
DEBUG 01-07 10:14:14.903213.903213 lmp.py:767]   Expert 11 |    170 | GPU0(cuda:1)
DEBUG 01-07 10:14:14.903141.903141 lmp.py:767]   Expert 32 |    170 | GPU1(cuda:2)
DEBUG 01-07 10:14:14.903592.903592 lmp.py:767]   Expert 40 |    170 | GPU0(cuda:1)
DEBUG 01-07 10:14:14.903281.903281 lmp.py:767]   Expert 14 |    173 | GPU1(cuda:2)
DEBUG 01-07 10:14:14.903971.903971 lmp.py:767]   Expert 34 |    175 | GPU0(cuda:1)
DEBUG 01-07 10:14:14.903421.903421 lmp.py:767]   Expert 52 |    176 | GPU1(cuda:2)
DEBUG 01-07 10:14:14.903588.903588 lmp.py:767]   Expert 41 |    181 | GPU0(cuda:1)
DEBUG 01-07 10:14:14.903754.903754 lmp.py:767]   Expert 42 |    183 | GPU1(cuda:2)
DEBUG 01-07 10:14:14.903205.903205 lmp.py:767]   Expert 21 |    192 | GPU0(cuda:1)
DEBUG 01-07 10:14:14.903894.903894 lmp.py:767]   Expert 57 |    195 | GPU1(cuda:2)
DEBUG 01-07 10:14:14.903583.903583 lmp.py:767]   Expert 30 |    196 | GPU0(cuda:1)
DEBUG 01-07 10:14:14.903034.903034 lmp.py:767]   Expert 15 |    200 | GPU1(cuda:2)
DEBUG 01-07 10:14:14.903962.903962 lmp.py:767]   Expert 35 |    204 | GPU0(cuda:1)
DEBUG 01-07 10:14:14.903413.903413 lmp.py:767]   Expert 12 |    217 | GPU1(cuda:2)
DEBUG 01-07 10:14:14.903817.903817 lmp.py:767]   Expert  4 |    221 | GPU0(cuda:1)
DEBUG 01-07 10:14:14.903460.903460 lmp.py:767]   Expert 46 |    226 | GPU1(cuda:2)
DEBUG 01-07 10:14:14.903149.903149 lmp.py:767]   Expert 50 |    227 | GPU0(cuda:1)
DEBUG 01-07 10:14:14.903077.903077 lmp.py:767]   Expert 19 |    230 | GPU1(cuda:2)
DEBUG 01-07 10:14:14.903005.903005 lmp.py:767]   Expert 24 |    233 | GPU1(cuda:2)
DEBUG 01-07 10:14:14.903171.903171 lmp.py:767]   Expert 49 |    233 | GPU0(cuda:1)
DEBUG 01-07 10:14:14.903337.903337 lmp.py:767]   Expert  8 |    235 | GPU0(cuda:1)
DEBUG 01-07 10:14:14.903503.903503 lmp.py:767]   Expert 44 |    236 | GPU1(cuda:2)
DEBUG 01-07 10:14:14.903908.903908 lmp.py:767]   Expert 38 |    242 | GPU0(cuda:1)
DEBUG 01-07 10:14:14.903836.903836 lmp.py:767]   Expert 47 |    248 | GPU1(cuda:2)
DEBUG 01-07 10:14:14.903763.903763 lmp.py:767]   Expert 31 |    251 | GPU0(cuda:1)
DEBUG 01-07 10:14:14.903976.903976 lmp.py:767]   Expert  6 |    252 | GPU1(cuda:2)
DEBUG 01-07 10:14:14.903665.903665 lmp.py:767]   Expert 61 |    262 | GPU0(cuda:1)
DEBUG 01-07 10:14:14.903831.903831 lmp.py:767]   Expert 39 |    279 | GPU1(cuda:2)
DEBUG 01-07 10:14:14.903521.903521 lmp.py:767]   Expert  5 |    300 | GPU0(cuda:1)
DEBUG 01-07 10:14:14.903164.903164 lmp.py:767]   Expert 27 |    309 | GPU1(cuda:2)
DEBUG 01-07 10:14:14.903806.903806 lmp.py:767]   Expert 36 |    310 | GPU0(cuda:1)
DEBUG 01-07 10:14:14.903165.903165 lmp.py:767]   Expert 60 |    335 | GPU1(cuda:2)
DEBUG 01-07 10:14:14.903761.903761 lmp.py:767]   Expert 20 |    336 | GPU0(cuda:1)
DEBUG 01-07 10:14:14.903643.903643 lmp.py:767]   Expert 48 |    372 | GPU1(cuda:2)
DEBUG 01-07 10:14:14.903286.903286 lmp.py:767]   Expert 25 |    394 | GPU1(cuda:2)
DEBUG 01-07 10:14:14.903929.903929 lmp.py:767]   Expert 56 |    551 | GPU0(cuda:1)
DEBUG 01-07 10:14:14.903618.903618 lmp.py:769] 
DEBUG 01-07 10:14:14.903618.903618 lmp.py:769]   Device Token Distribution:
DEBUG 01-07 10:14:14.903738.903738 lmp.py:770]   CPU:   1953 tokens
DEBUG 01-07 10:14:14.903334.903334 lmp.py:774]   cuda:1:   5102 tokens (22 experts)
DEBUG 01-07 10:14:14.903216.903216 lmp.py:774]   cuda:2:   5233 tokens (23 experts)
DEBUG 01-07 10:14:14.903382.903382 lmp.py:775]   Total GPU:  10335 tokens
DEBUG 01-07 10:14:14.903071.903071 lmp.py:776] ============================================================
DEBUG 01-07 10:14:14.903071.903071 lmp.py:776] 
DEBUG 01-07 10:14:14.903198.903198 cuda_h.py:19] end experts_map_get cost 0.0017375946044921875 seconds
DEBUG 01-07 10:14:14.903318.903318 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model_multi_device
DEBUG 01-07 10:14:14.903710.903710 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 10:14:14.904237.904237 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 10:14:14.904999.904999 cuda_h.py:19] end allocate_cuda_memory cost 0.0001785755157470703 seconds
DEBUG 01-07 10:14:14.904365.904365 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 10:14:14.904214.904214 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 10:14:14.904976.904976 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 10:14:14.904779.904779 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, ebd33e4d-da97-405c-856f-7b7470fff59e
DEBUG 01-07 10:14:14.904360.904360 client.py:106] call stub.LoadModelAsync
INFO 01-07 10:14:14.904058.904058 client.py:127] Model loaded
DEBUG 01-07 10:14:14.905948.905948 cuda_h.py:19] end sllm_worker_task cost 0.008853673934936523 seconds
INFO 01-07 10:14:14.905714.905714 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, ebd33e4d-da97-405c-856f-7b7470fff59e
DEBUG 01-07 10:14:14.905796.905796 cuda_h.py:19] end load_into_gpu_async cost 0.001163482666015625 seconds
DEBUG 01-07 10:14:14.905545.905545 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 10:14:14.905503.905503 cuda_h.py:19] end restore_tensors2 cost 0.0002949237823486328 seconds
DEBUG 01-07 10:14:14.905233.905233 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0019431114196777344 seconds
DEBUG 01-07 10:14:14.907441.907441 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 10:14:14.907678.907678 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 10:14:14.908527.908527 cuda_h.py:19] end allocate_cuda_memory cost 0.00020170211791992188 seconds
DEBUG 01-07 10:14:14.908032.908032 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 10:14:14.908642.908642 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 10:14:14.908498.908498 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 10:14:14.908432.908432 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 2bffe08c-36d3-4495-99d8-cf606e6dd586
DEBUG 01-07 10:14:14.908106.908106 client.py:106] call stub.LoadModelAsync
INFO 01-07 10:14:14.909922.909922 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 2bffe08c-36d3-4495-99d8-cf606e6dd586
DEBUG 01-07 10:14:14.909752.909752 cuda_h.py:19] end load_into_gpu_async cost 0.0010962486267089844 seconds
DEBUG 01-07 10:14:14.909786.909786 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 10:14:14.909604.909604 cuda_h.py:19] end restore_tensors2 cost 0.00029754638671875 seconds
DEBUG 01-07 10:14:14.909003.909003 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0019001960754394531 seconds
DEBUG 01-07 10:14:14.911253.911253 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model_multi_device cost 0.007720470428466797 seconds
DEBUG 01-07 10:14:14.911658.911658 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-07 10:14:14.911813.911813 lmp.py:816] 
DEBUG 01-07 10:14:14.911813.911813 lmp.py:816]   Computing 19 experts on CPU...
DEBUG 01-07 10:14:14.911319.911319 cuda_h.py:19] end cpu_experts_submit cost 0.00010752677917480469 seconds
DEBUG 01-07 10:14:14.911207.911207 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-07 10:14:14.918629.918629 mlpmodule.py:749] group tensors cost 0.0065348148345947266 s
DEBUG 01-07 10:14:14.921342.921342 mlpmodule.py:787] pad cost 0.0016665458679199219 s
DEBUG 01-07 10:14:14.921592.921592 mlpmodule.py:793] create cpu tensor cost 6.079673767089844e-05 s
DEBUG 01-07 10:14:14.921689.921689 mlpmodule.py:798] move to cpu cost 4.553794860839844e-05 s
DEBUG 01-07 10:14:14.931395.931395 mlpmodule.py:812] group_w3: shape=torch.Size([19, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=54788096
DEBUG 01-07 10:14:14.931315.931315 mlpmodule.py:813] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-07 10:14:14.931034.931034 mlpmodule.py:818] group_w3 first element: -0.003631591796875
WARNING 01-07 10:14:14.931118.931118 mlpmodule.py:828] start einsum2
DEBUG 01-07 10:14:14.946505.946505 mlpmodule.py:838] group einsum cost 0.02507162094116211 s
DEBUG 01-07 10:14:14.947962.947962 mlpmodule.py:846] cpy2cputensor cost 0.00039005279541015625 s
DEBUG 01-07 10:14:14.949226.949226 cuda_h.py:19] end wait_cetm_experts cost 0.037928104400634766 seconds
DEBUG 01-07 10:14:14.949117.949117 cuda_h.py:10] start gpu_sexperts
DEBUG 01-07 10:14:14.950963.950963 cuda_h.py:19] end gpu_sexperts cost 0.0005092620849609375 seconds
DEBUG 01-07 10:14:14.950575.950575 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-07 10:14:14.950517.950517 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.4318695068359375e-05 seconds
DEBUG 01-07 10:14:14.950982.950982 cuda_h.py:10] start wait_experts_multi_device
INFO 01-07 10:14:14.950930.950930 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, ebd33e4d-da97-405c-856f-7b7470fff59e
INFO 01-07 10:14:14.952816.952816 client.py:127] Model loaded
INFO 01-07 10:14:14.952745.952745 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 2bffe08c-36d3-4495-99d8-cf606e6dd586
INFO 01-07 10:14:14.952813.952813 client.py:127] Model loaded
DEBUG 01-07 10:14:14.952881.952881 cuda_h.py:19] end wait_experts_multi_device cost 0.0018963813781738281 seconds
DEBUG 01-07 10:14:14.952823.952823 cuda_h.py:10] start gpu_experts_multi_device
DEBUG 01-07 10:14:14.952884.952884 lmp.py:867]   Computing 23 experts on cuda:2...
DEBUG 01-07 10:14:14.953520.953520 mlpmodule.py:533] gpu group tensors cost 0.0005102157592773438 s
DEBUG 01-07 10:14:14.955360.955360 mlpmodule.py:566] gpu pad cost 0.0012924671173095703 s
DEBUG 01-07 10:14:14.955846.955846 mlpmodule.py:584] gpu group einsum cost 0.0005886554718017578 s
DEBUG 01-07 10:14:14.958999.958999 mlpmodule.py:656] gpu experts func einsum cost 0.00472712516784668 s
DEBUG 01-07 10:14:14.958486.958486 lmp.py:867]   Computing 22 experts on cuda:1...
DEBUG 01-07 10:14:14.959681.959681 mlpmodule.py:707]  experts func einsum cost 0.04707908630371094 s
DEBUG 01-07 10:14:14.959309.959309 mlpmodule.py:533] gpu group tensors cost 0.0005598068237304688 s
DEBUG 01-07 10:14:14.960896.960896 mlpmodule.py:566] gpu pad cost 0.0012359619140625 s
DEBUG 01-07 10:14:14.961889.961889 mlpmodule.py:584] gpu group einsum cost 0.00047206878662109375 s
DEBUG 01-07 10:14:14.963549.963549 mlpmodule.py:656] gpu experts func einsum cost 0.004358053207397461 s
DEBUG 01-07 10:14:14.963547.963547 cuda_h.py:19] end gpu_experts_multi_device cost 0.010512113571166992 seconds
DEBUG 01-07 10:14:14.963755.963755 cuda_h.py:19] end layer_moe_generate_multi_device_6 cost 0.06186485290527344 seconds
DEBUG 01-07 10:14:14.963584.963584 lmp.py:194] -------------------------------- end prefill layer 6 --------------------------------
DEBUG 01-07 10:14:14.963036.963036 lmp.py:153] -------------------------------- start prefill layer 7 --------------------------------
DEBUG 01-07 10:14:14.963401.963401 cuda_h.py:10] start start_load_qkvogn_s_weight_l_8
DEBUG 01-07 10:14:14.963726.963726 cuda_h.py:10] start start_load_qkvogn_s_weight_l_8
DEBUG 01-07 10:14:14.963516.963516 cuda_h.py:19] end start_load_qkvogn_s_weight_l_8 cost 2.9087066650390625e-05 seconds
DEBUG 01-07 10:14:14.963789.963789 cuda_h.py:19] end start_load_qkvogn_s_weight_l_8 cost 5.91278076171875e-05 seconds
DEBUG 01-07 10:14:14.963147.963147 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-07 10:14:14.963254.963254 cuda_h.py:10] start sllm_worker_task
DEBUG 01-07 10:14:14.963715.963715 mlpmodule.py:367] cuda:1 cuda:1
DEBUG 01-07 10:14:14.963623.963623 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 10:14:14.963627.963627 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 10:14:14.964180.964180 cuda_h.py:19] end allocate_cuda_memory cost 0.0002663135528564453 seconds
DEBUG 01-07 10:14:14.964122.964122 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 10:14:14.964547.964547 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 10:14:14.964330.964330 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 10:14:14.964318.964318 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, a2150826-3fc9-41ba-9774-b7bffa3f1cc7
DEBUG 01-07 10:14:14.964989.964989 client.py:106] call stub.LoadModelAsync
DEBUG 01-07 10:14:14.964191.964191 cuda_h.py:10] start self_attn
INFO 01-07 10:14:14.965548.965548 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, a2150826-3fc9-41ba-9774-b7bffa3f1cc7
DEBUG 01-07 10:14:14.965139.965139 cuda_h.py:19] end load_into_gpu_async cost 0.0008585453033447266 seconds
DEBUG 01-07 10:14:14.965696.965696 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 10:14:14.965103.965103 cuda_h.py:19] end restore_tensors2 cost 6.437301635742188e-05 seconds
DEBUG 01-07 10:14:14.965952.965952 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0014190673828125 seconds
INFO 01-07 10:14:14.965026.965026 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, a2150826-3fc9-41ba-9774-b7bffa3f1cc7
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-07 10:14:14.968964.968964 cuda_h.py:19] end self_attn cost 0.0036318302154541016 seconds
DEBUG 01-07 10:14:14.968743.968743 cuda_h.py:19] end iln_self_attn_paln cost 0.005116462707519531 seconds
DEBUG 01-07 10:14:14.968950.968950 cuda_h.py:10] start layer_moe_generate_multi_device_7
DEBUG 01-07 10:14:14.968329.968329 cuda_h.py:10] start gate
DEBUG 01-07 10:14:14.969292.969292 cuda_h.py:19] end gate cost 0.0006415843963623047 seconds
DEBUG 01-07 10:14:14.969552.969552 cuda_h.py:10] start experts_map_get
DEBUG 01-07 10:14:14.970678.970678 lmp.py:744] 
DEBUG 01-07 10:14:14.970678.970678 lmp.py:744] Expert Token Distribution & Multi-Device Allocation:
DEBUG 01-07 10:14:14.970070.970070 lmp.py:745]   Total experts: 64
DEBUG 01-07 10:14:14.970581.970581 lmp.py:746]   CPU experts: 19 (30%)
DEBUG 01-07 10:14:14.970654.970654 lmp.py:747]   GPU experts: 45 (70%)
DEBUG 01-07 10:14:14.970820.970820 lmp.py:748]   Number of GPU devices: 2
DEBUG 01-07 10:14:14.970033.970033 lmp.py:749] 
DEBUG 01-07 10:14:14.970033.970033 lmp.py:749]   Expert ID | Tokens | Device
DEBUG 01-07 10:14:14.970199.970199 lmp.py:750]   -----------------------------------
DEBUG 01-07 10:14:14.970041.970041 lmp.py:767]   Expert 50 |     45 | CPU
DEBUG 01-07 10:14:14.970445.970445 lmp.py:767]   Expert  3 |     56 | CPU
DEBUG 01-07 10:14:14.970896.970896 lmp.py:767]   Expert 46 |     56 | CPU
DEBUG 01-07 10:14:14.970301.970301 lmp.py:767]   Expert  1 |     76 | CPU
DEBUG 01-07 10:14:14.970467.970467 lmp.py:767]   Expert  4 |     85 | CPU
DEBUG 01-07 10:14:14.970156.970156 lmp.py:767]   Expert 29 |     86 | CPU
DEBUG 01-07 10:14:14.970369.970369 lmp.py:767]   Expert 40 |     92 | CPU
DEBUG 01-07 10:14:14.970820.970820 lmp.py:767]   Expert 15 |     97 | CPU
DEBUG 01-07 10:14:14.970794.970794 lmp.py:767]   Expert  8 |    111 | CPU
DEBUG 01-07 10:14:14.970768.970768 lmp.py:767]   Expert 41 |    112 | CPU
DEBUG 01-07 10:14:14.970457.970457 lmp.py:767]   Expert 28 |    114 | CPU
DEBUG 01-07 10:14:14.970146.970146 lmp.py:767]   Expert 48 |    124 | CPU
DEBUG 01-07 10:14:14.970359.970359 lmp.py:767]   Expert 16 |    126 | CPU
DEBUG 01-07 10:14:14.970571.970571 lmp.py:767]   Expert 27 |    129 | CPU
DEBUG 01-07 10:14:14.970307.970307 lmp.py:767]   Expert  6 |    130 | CPU
DEBUG 01-07 10:14:14.970281.970281 lmp.py:767]   Expert 13 |    134 | CPU
DEBUG 01-07 10:14:14.970017.970017 lmp.py:767]   Expert 54 |    135 | CPU
DEBUG 01-07 10:14:14.970991.970991 lmp.py:767]   Expert  7 |    136 | CPU
DEBUG 01-07 10:14:14.970680.970680 lmp.py:767]   Expert 51 |    138 | CPU
DEBUG 01-07 10:14:14.970561.970561 lmp.py:767]   Expert 18 |    139 | GPU1(cuda:2)
DEBUG 01-07 10:14:14.970204.970204 lmp.py:767]   Expert 60 |    139 | GPU1(cuda:2)
DEBUG 01-07 10:14:14.970609.970609 lmp.py:767]   Expert 14 |    142 | GPU0(cuda:1)
DEBUG 01-07 10:14:14.970537.970537 lmp.py:767]   Expert 39 |    142 | GPU0(cuda:1)
DEBUG 01-07 10:14:14.970703.970703 lmp.py:767]   Expert 56 |    145 | GPU1(cuda:2)
DEBUG 01-07 10:14:14.970869.970869 lmp.py:767]   Expert 20 |    147 | GPU1(cuda:2)
DEBUG 01-07 10:14:14.970558.970558 lmp.py:767]   Expert 36 |    148 | GPU0(cuda:1)
DEBUG 01-07 10:14:14.970963.970963 lmp.py:767]   Expert 43 |    148 | GPU0(cuda:1)
DEBUG 01-07 10:14:14.970844.970844 lmp.py:767]   Expert 52 |    150 | GPU1(cuda:2)
DEBUG 01-07 10:14:14.970010.970010 lmp.py:767]   Expert 55 |    152 | GPU0(cuda:1)
DEBUG 01-07 10:14:14.970176.970176 lmp.py:767]   Expert  5 |    154 | GPU1(cuda:2)
DEBUG 01-07 10:14:14.970104.970104 lmp.py:767]   Expert 45 |    155 | GPU1(cuda:2)
DEBUG 01-07 10:14:14.970793.970793 lmp.py:767]   Expert 10 |    159 | GPU0(cuda:1)
DEBUG 01-07 10:14:14.970721.970721 lmp.py:767]   Expert 11 |    162 | GPU1(cuda:2)
DEBUG 01-07 10:14:14.970126.970126 lmp.py:767]   Expert 62 |    164 | GPU0(cuda:1)
DEBUG 01-07 10:14:14.970530.970530 lmp.py:767]   Expert 44 |    171 | GPU0(cuda:1)
DEBUG 01-07 10:14:14.970696.970696 lmp.py:767]   Expert 57 |    175 | GPU1(cuda:2)
DEBUG 01-07 10:14:14.970624.970624 lmp.py:767]   Expert 33 |    179 | GPU0(cuda:1)
DEBUG 01-07 10:14:14.970552.970552 lmp.py:767]   Expert 58 |    180 | GPU1(cuda:2)
DEBUG 01-07 10:14:14.970480.970480 lmp.py:767]   Expert 53 |    183 | GPU1(cuda:2)
DEBUG 01-07 10:14:14.970407.970407 lmp.py:767]   Expert 25 |    186 | GPU0(cuda:1)
DEBUG 01-07 10:14:14.970097.970097 lmp.py:767]   Expert 32 |    191 | GPU0(cuda:1)
DEBUG 01-07 10:14:14.970786.970786 lmp.py:767]   Expert  2 |    192 | GPU1(cuda:2)
DEBUG 01-07 10:14:14.970190.970190 lmp.py:767]   Expert 31 |    197 | GPU0(cuda:1)
DEBUG 01-07 10:14:14.970357.970357 lmp.py:767]   Expert 35 |    198 | GPU1(cuda:2)
DEBUG 01-07 10:14:14.970046.970046 lmp.py:767]   Expert 49 |    201 | GPU0(cuda:1)
DEBUG 01-07 10:14:14.970212.970212 lmp.py:767]   Expert 63 |    202 | GPU1(cuda:2)
DEBUG 01-07 10:14:14.970140.970140 lmp.py:767]   Expert 21 |    205 | GPU0(cuda:1)
DEBUG 01-07 10:14:14.970067.970067 lmp.py:767]   Expert 17 |    211 | GPU1(cuda:2)
DEBUG 01-07 10:14:14.970995.970995 lmp.py:767]   Expert 42 |    217 | GPU0(cuda:1)
DEBUG 01-07 10:14:14.971161.971161 lmp.py:767]   Expert 34 |    223 | GPU1(cuda:2)
DEBUG 01-07 10:14:14.971566.971566 lmp.py:767]   Expert 59 |    228 | GPU0(cuda:1)
DEBUG 01-07 10:14:14.971970.971970 lmp.py:767]   Expert 37 |    229 | GPU1(cuda:2)
DEBUG 01-07 10:14:14.971898.971898 lmp.py:767]   Expert  0 |    238 | GPU0(cuda:1)
DEBUG 01-07 10:14:14.971826.971826 lmp.py:767]   Expert 22 |    240 | GPU1(cuda:2)
DEBUG 01-07 10:14:14.971754.971754 lmp.py:767]   Expert 19 |    260 | GPU1(cuda:2)
DEBUG 01-07 10:14:14.971920.971920 lmp.py:767]   Expert 24 |    284 | GPU0(cuda:1)
DEBUG 01-07 10:14:14.971801.971801 lmp.py:767]   Expert 61 |    286 | GPU0(cuda:1)
DEBUG 01-07 10:14:14.971682.971682 lmp.py:767]   Expert 30 |    303 | GPU1(cuda:2)
DEBUG 01-07 10:14:14.971279.971279 lmp.py:767]   Expert 47 |    320 | GPU1(cuda:2)
DEBUG 01-07 10:14:14.971399.971399 lmp.py:767]   Expert 38 |    361 | GPU0(cuda:1)
DEBUG 01-07 10:14:14.971280.971280 lmp.py:767]   Expert 26 |    375 | GPU0(cuda:1)
DEBUG 01-07 10:14:14.971923.971923 lmp.py:767]   Expert 12 |    432 | GPU1(cuda:2)
DEBUG 01-07 10:14:14.971566.971566 lmp.py:767]   Expert  9 |    683 | GPU1(cuda:2)
DEBUG 01-07 10:14:14.971925.971925 lmp.py:767]   Expert 23 |    710 | GPU0(cuda:1)
DEBUG 01-07 10:14:14.971329.971329 lmp.py:769] 
DEBUG 01-07 10:14:14.971329.971329 lmp.py:769]   Device Token Distribution:
DEBUG 01-07 10:14:14.971972.971972 lmp.py:770]   CPU:   1982 tokens
DEBUG 01-07 10:14:14.971330.971330 lmp.py:774]   cuda:1:   5084 tokens (22 experts)
DEBUG 01-07 10:14:14.971212.971212 lmp.py:774]   cuda:2:   5222 tokens (23 experts)
DEBUG 01-07 10:14:14.971378.971378 lmp.py:775]   Total GPU:  10306 tokens
DEBUG 01-07 10:14:14.971306.971306 lmp.py:776] ============================================================
DEBUG 01-07 10:14:14.971306.971306 lmp.py:776] 
DEBUG 01-07 10:14:14.971432.971432 cuda_h.py:19] end experts_map_get cost 0.0017440319061279297 seconds
DEBUG 01-07 10:14:14.971790.971790 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model_multi_device
DEBUG 01-07 10:14:14.971613.971613 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 10:14:14.971147.971147 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 10:14:14.971121.971121 cuda_h.py:19] end allocate_cuda_memory cost 0.00019431114196777344 seconds
DEBUG 01-07 10:14:14.971263.971263 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 10:14:14.971303.971303 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 10:14:14.971112.971112 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 10:14:14.971762.971762 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 436e9fda-f794-448b-a4be-09b6aa211389
DEBUG 01-07 10:14:14.972390.972390 client.py:106] call stub.LoadModelAsync
INFO 01-07 10:14:14.972809.972809 client.py:127] Model loaded
DEBUG 01-07 10:14:14.972135.972135 cuda_h.py:19] end sllm_worker_task cost 0.008773565292358398 seconds
INFO 01-07 10:14:14.972658.972658 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 436e9fda-f794-448b-a4be-09b6aa211389
DEBUG 01-07 10:14:14.972885.972885 cuda_h.py:19] end load_into_gpu_async cost 0.0009534358978271484 seconds
DEBUG 01-07 10:14:14.972111.972111 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 10:14:14.973307.973307 cuda_h.py:19] end restore_tensors2 cost 0.00029468536376953125 seconds
DEBUG 01-07 10:14:14.973276.973276 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0017650127410888672 seconds
DEBUG 01-07 10:14:14.975589.975589 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 10:14:14.975150.975150 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 10:14:14.975198.975198 cuda_h.py:19] end allocate_cuda_memory cost 0.00020837783813476562 seconds
DEBUG 01-07 10:14:14.975180.975180 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 10:14:14.975505.975505 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 10:14:14.975169.975169 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 10:14:14.975103.975103 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 1952bf6c-aec2-453a-9679-dc2021110309
DEBUG 01-07 10:14:14.975048.975048 client.py:106] call stub.LoadModelAsync
INFO 01-07 10:14:14.976766.976766 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 1952bf6c-aec2-453a-9679-dc2021110309
DEBUG 01-07 10:14:14.976596.976596 cuda_h.py:19] end load_into_gpu_async cost 0.001117706298828125 seconds
DEBUG 01-07 10:14:14.976391.976391 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 10:14:14.977335.977335 cuda_h.py:19] end restore_tensors2 cost 0.00028395652770996094 seconds
DEBUG 01-07 10:14:14.977688.977688 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0019152164459228516 seconds
DEBUG 01-07 10:14:14.978897.978897 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model_multi_device cost 0.007495403289794922 seconds
DEBUG 01-07 10:14:14.978349.978349 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-07 10:14:14.979742.979742 lmp.py:816] 
DEBUG 01-07 10:14:14.979742.979742 lmp.py:816]   Computing 19 experts on CPU...
DEBUG 01-07 10:14:14.979532.979532 cuda_h.py:19] end cpu_experts_submit cost 0.00010800361633300781 seconds
DEBUG 01-07 10:14:14.979420.979420 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-07 10:14:14.984978.984978 mlpmodule.py:749] group tensors cost 0.00565791130065918 s
DEBUG 01-07 10:14:14.986898.986898 mlpmodule.py:787] pad cost 0.0011065006256103516 s
DEBUG 01-07 10:14:14.986948.986948 mlpmodule.py:793] create cpu tensor cost 4.458427429199219e-05 s
DEBUG 01-07 10:14:14.986335.986335 mlpmodule.py:798] move to cpu cost 3.361701965332031e-05 s
DEBUG 01-07 10:14:14.996064.996064 mlpmodule.py:812] group_w3: shape=torch.Size([19, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=54788096
DEBUG 01-07 10:14:14.996971.996971 mlpmodule.py:813] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-07 10:14:14.997590.997590 mlpmodule.py:818] group_w3 first element: 0.01263427734375
WARNING 01-07 10:14:14.997720.997720 mlpmodule.py:828] start einsum2
DEBUG 01-07 10:14:15.012033.012033 mlpmodule.py:838] group einsum cost 0.025326013565063477 s
DEBUG 01-07 10:14:15.012526.012526 mlpmodule.py:846] cpy2cputensor cost 0.00042819976806640625 s
DEBUG 01-07 10:14:15.015666.015666 cuda_h.py:19] end wait_cetm_experts cost 0.03637075424194336 seconds
DEBUG 01-07 10:14:15.015848.015848 cuda_h.py:10] start gpu_sexperts
DEBUG 01-07 10:14:15.016933.016933 cuda_h.py:19] end gpu_sexperts cost 0.0005102157592773438 seconds
DEBUG 01-07 10:14:15.016776.016776 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-07 10:14:15.016195.016195 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.5272369384765625e-05 seconds
DEBUG 01-07 10:14:15.016613.016613 cuda_h.py:10] start wait_experts_multi_device
INFO 01-07 10:14:15.016066.016066 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 436e9fda-f794-448b-a4be-09b6aa211389
INFO 01-07 10:14:15.017214.017214 client.py:127] Model loaded
INFO 01-07 10:14:15.017428.017428 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 1952bf6c-aec2-453a-9679-dc2021110309
INFO 01-07 10:14:15.019476.019476 client.py:127] Model loaded
DEBUG 01-07 10:14:15.019020.019020 cuda_h.py:19] end wait_experts_multi_device cost 0.003219127655029297 seconds
DEBUG 01-07 10:14:15.019823.019823 cuda_h.py:10] start gpu_experts_multi_device
DEBUG 01-07 10:14:15.019884.019884 lmp.py:867]   Computing 23 experts on cuda:2...
DEBUG 01-07 10:14:15.020746.020746 mlpmodule.py:533] gpu group tensors cost 0.0005624294281005859 s
DEBUG 01-07 10:14:15.022654.022654 mlpmodule.py:566] gpu pad cost 0.0013396739959716797 s
DEBUG 01-07 10:14:15.022703.022703 mlpmodule.py:584] gpu group einsum cost 0.0005807876586914062 s
DEBUG 01-07 10:14:15.024936.024936 mlpmodule.py:707]  experts func einsum cost 0.045357704162597656 s
DEBUG 01-07 10:14:15.025269.025269 mlpmodule.py:656] gpu experts func einsum cost 0.0049130916595458984 s
DEBUG 01-07 10:14:15.025216.025216 lmp.py:867]   Computing 22 experts on cuda:1...
DEBUG 01-07 10:14:15.026367.026367 mlpmodule.py:533] gpu group tensors cost 0.0004515647888183594 s
DEBUG 01-07 10:14:15.027529.027529 mlpmodule.py:566] gpu pad cost 0.0012211799621582031 s
DEBUG 01-07 10:14:15.028520.028520 mlpmodule.py:584] gpu group einsum cost 0.0004401206970214844 s
DEBUG 01-07 10:14:15.029088.029088 mlpmodule.py:656] gpu experts func einsum cost 0.004003286361694336 s
DEBUG 01-07 10:14:15.030530.030530 cuda_h.py:19] end gpu_experts_multi_device cost 0.010431051254272461 seconds
DEBUG 01-07 10:14:15.030454.030454 cuda_h.py:19] end layer_moe_generate_multi_device_7 cost 0.06129646301269531 seconds
DEBUG 01-07 10:14:15.030594.030594 lmp.py:194] -------------------------------- end prefill layer 7 --------------------------------
DEBUG 01-07 10:14:15.030324.030324 lmp.py:153] -------------------------------- start prefill layer 8 --------------------------------
DEBUG 01-07 10:14:15.030782.030782 cuda_h.py:10] start start_load_qkvogn_s_weight_l_9
DEBUG 01-07 10:14:15.030584.030584 cuda_h.py:10] start start_load_qkvogn_s_weight_l_9
DEBUG 01-07 10:14:15.030182.030182 cuda_h.py:19] end start_load_qkvogn_s_weight_l_9 cost 2.86102294921875e-05 seconds
DEBUG 01-07 10:14:15.030693.030693 cuda_h.py:19] end start_load_qkvogn_s_weight_l_9 cost 5.8650970458984375e-05 seconds
DEBUG 01-07 10:14:15.030528.030528 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-07 10:14:15.030589.030589 cuda_h.py:10] start sllm_worker_task
DEBUG 01-07 10:14:15.030818.030818 mlpmodule.py:367] cuda:1 cuda:1
DEBUG 01-07 10:14:15.030011.030011 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 10:14:15.030445.030445 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 10:14:15.031786.031786 cuda_h.py:19] end allocate_cuda_memory cost 0.0002498626708984375 seconds
DEBUG 01-07 10:14:15.031318.031318 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 10:14:15.031697.031697 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 10:14:15.031420.031420 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 10:14:15.031500.031500 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 15f04e7f-9a6e-40b6-97c2-473817214530
DEBUG 01-07 10:14:15.031364.031364 client.py:106] call stub.LoadModelAsync
DEBUG 01-07 10:14:15.031564.031564 cuda_h.py:10] start self_attn
INFO 01-07 10:14:15.032087.032087 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 15f04e7f-9a6e-40b6-97c2-473817214530
DEBUG 01-07 10:14:15.032201.032201 cuda_h.py:19] end load_into_gpu_async cost 0.0008285045623779297 seconds
DEBUG 01-07 10:14:15.032805.032805 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 10:14:15.032881.032881 cuda_h.py:19] end restore_tensors2 cost 6.508827209472656e-05 seconds
DEBUG 01-07 10:14:15.032491.032491 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0013892650604248047 seconds
INFO 01-07 10:14:15.032559.032559 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 15f04e7f-9a6e-40b6-97c2-473817214530
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-07 10:14:15.035879.035879 cuda_h.py:19] end self_attn cost 0.003611326217651367 seconds
DEBUG 01-07 10:14:15.035075.035075 cuda_h.py:19] end iln_self_attn_paln cost 0.005045413970947266 seconds
DEBUG 01-07 10:14:15.035044.035044 cuda_h.py:10] start layer_moe_generate_multi_device_8
DEBUG 01-07 10:14:15.035423.035423 cuda_h.py:10] start gate
DEBUG 01-07 10:14:15.036274.036274 cuda_h.py:19] end gate cost 0.0006632804870605469 seconds
DEBUG 01-07 10:14:15.036534.036534 cuda_h.py:10] start experts_map_get
DEBUG 01-07 10:14:15.036037.036037 lmp.py:744] 
DEBUG 01-07 10:14:15.036037.036037 lmp.py:744] Expert Token Distribution & Multi-Device Allocation:
DEBUG 01-07 10:14:15.036383.036383 lmp.py:745]   Total experts: 64
DEBUG 01-07 10:14:15.037656.037656 lmp.py:746]   CPU experts: 19 (30%)
DEBUG 01-07 10:14:15.037968.037968 lmp.py:747]   GPU experts: 45 (70%)
DEBUG 01-07 10:14:15.037372.037372 lmp.py:748]   Number of GPU devices: 2
DEBUG 01-07 10:14:15.037585.037585 lmp.py:749] 
DEBUG 01-07 10:14:15.037585.037585 lmp.py:749]   Expert ID | Tokens | Device
DEBUG 01-07 10:14:15.037751.037751 lmp.py:750]   -----------------------------------
DEBUG 01-07 10:14:15.037977.037977 lmp.py:767]   Expert 38 |     12 | CPU
DEBUG 01-07 10:14:15.037335.037335 lmp.py:767]   Expert 39 |     62 | CPU
DEBUG 01-07 10:14:15.037501.037501 lmp.py:767]   Expert  7 |     67 | CPU
DEBUG 01-07 10:14:15.037190.037190 lmp.py:767]   Expert 30 |     78 | CPU
DEBUG 01-07 10:14:15.037641.037641 lmp.py:767]   Expert 17 |     93 | CPU
DEBUG 01-07 10:14:15.037854.037854 lmp.py:767]   Expert 27 |     94 | CPU
DEBUG 01-07 10:14:15.037020.037020 lmp.py:767]   Expert 14 |     97 | CPU
DEBUG 01-07 10:14:15.037663.037663 lmp.py:767]   Expert 24 |     97 | CPU
DEBUG 01-07 10:14:15.037352.037352 lmp.py:767]   Expert 36 |     98 | CPU
DEBUG 01-07 10:14:15.037565.037565 lmp.py:767]   Expert 32 |    100 | CPU
DEBUG 01-07 10:14:15.037777.037777 lmp.py:767]   Expert 40 |    101 | CPU
DEBUG 01-07 10:14:15.037751.037751 lmp.py:767]   Expert 16 |    102 | CPU
DEBUG 01-07 10:14:15.037202.037202 lmp.py:767]   Expert 18 |    111 | CPU
DEBUG 01-07 10:14:15.037414.037414 lmp.py:767]   Expert 12 |    112 | CPU
DEBUG 01-07 10:14:15.037389.037389 lmp.py:767]   Expert 48 |    114 | CPU
DEBUG 01-07 10:14:15.037555.037555 lmp.py:767]   Expert  1 |    121 | CPU
DEBUG 01-07 10:14:15.037959.037959 lmp.py:767]   Expert  6 |    126 | CPU
DEBUG 01-07 10:14:15.037410.037410 lmp.py:767]   Expert 59 |    126 | CPU
DEBUG 01-07 10:14:15.037861.037861 lmp.py:767]   Expert 42 |    137 | CPU
DEBUG 01-07 10:14:15.037266.037266 lmp.py:767]   Expert 53 |    142 | GPU1(cuda:2)
DEBUG 01-07 10:14:15.037624.037624 lmp.py:767]   Expert 51 |    144 | GPU0(cuda:1)
DEBUG 01-07 10:14:15.037028.037028 lmp.py:767]   Expert  0 |    146 | GPU1(cuda:2)
DEBUG 01-07 10:14:15.037433.037433 lmp.py:767]   Expert 22 |    148 | GPU0(cuda:1)
DEBUG 01-07 10:14:15.037553.037553 lmp.py:767]   Expert  8 |    155 | GPU1(cuda:2)
DEBUG 01-07 10:14:15.037434.037434 lmp.py:767]   Expert 44 |    167 | GPU1(cuda:2)
DEBUG 01-07 10:14:15.037839.037839 lmp.py:767]   Expert 60 |    167 | GPU0(cuda:1)
DEBUG 01-07 10:14:15.037766.037766 lmp.py:767]   Expert 54 |    170 | GPU0(cuda:1)
DEBUG 01-07 10:14:15.037694.037694 lmp.py:767]   Expert 35 |    171 | GPU1(cuda:2)
DEBUG 01-07 10:14:15.037383.037383 lmp.py:767]   Expert 29 |    172 | GPU0(cuda:1)
DEBUG 01-07 10:14:15.037073.037073 lmp.py:767]   Expert 15 |    179 | GPU1(cuda:2)
DEBUG 01-07 10:14:15.037000.037000 lmp.py:767]   Expert 33 |    181 | GPU0(cuda:1)
DEBUG 01-07 10:14:15.037643.037643 lmp.py:767]   Expert 34 |    186 | GPU1(cuda:2)
DEBUG 01-07 10:14:15.037286.037286 lmp.py:767]   Expert  9 |    189 | GPU1(cuda:2)
DEBUG 01-07 10:14:15.037214.037214 lmp.py:767]   Expert 47 |    189 | GPU0(cuda:1)
DEBUG 01-07 10:14:15.037380.037380 lmp.py:767]   Expert 19 |    192 | GPU0(cuda:1)
DEBUG 01-07 10:14:15.037831.037831 lmp.py:767]   Expert  3 |    195 | GPU1(cuda:2)
DEBUG 01-07 10:14:15.037520.037520 lmp.py:767]   Expert 21 |    196 | GPU1(cuda:2)
DEBUG 01-07 10:14:15.037210.037210 lmp.py:767]   Expert 56 |    196 | GPU0(cuda:1)
DEBUG 01-07 10:14:15.037899.037899 lmp.py:767]   Expert 20 |    200 | GPU1(cuda:2)
DEBUG 01-07 10:14:15.037350.037350 lmp.py:767]   Expert 49 |    200 | GPU0(cuda:1)
DEBUG 01-07 10:14:15.037231.037231 lmp.py:767]   Expert 45 |    202 | GPU0(cuda:1)
DEBUG 01-07 10:14:15.037113.037113 lmp.py:767]   Expert 46 |    203 | GPU1(cuda:2)
DEBUG 01-07 10:14:15.037040.037040 lmp.py:767]   Expert 28 |    207 | GPU0(cuda:1)
DEBUG 01-07 10:14:15.037730.037730 lmp.py:767]   Expert 57 |    221 | GPU1(cuda:2)
DEBUG 01-07 10:14:15.037419.037419 lmp.py:767]   Expert  2 |    222 | GPU1(cuda:2)
DEBUG 01-07 10:14:15.037108.037108 lmp.py:767]   Expert 43 |    222 | GPU0(cuda:1)
DEBUG 01-07 10:14:15.037798.037798 lmp.py:767]   Expert  4 |    226 | GPU0(cuda:1)
DEBUG 01-07 10:14:15.037487.037487 lmp.py:767]   Expert 13 |    229 | GPU1(cuda:2)
DEBUG 01-07 10:14:15.037415.037415 lmp.py:767]   Expert 10 |    241 | GPU0(cuda:1)
DEBUG 01-07 10:14:15.037819.037819 lmp.py:767]   Expert 41 |    242 | GPU1(cuda:2)
DEBUG 01-07 10:14:15.037747.037747 lmp.py:767]   Expert 50 |    244 | GPU0(cuda:1)
DEBUG 01-07 10:14:15.037198.037198 lmp.py:767]   Expert 26 |    248 | GPU1(cuda:2)
DEBUG 01-07 10:14:15.037887.037887 lmp.py:767]   Expert 63 |    260 | GPU0(cuda:1)
DEBUG 01-07 10:14:15.037576.037576 lmp.py:767]   Expert 37 |    262 | GPU1(cuda:2)
DEBUG 01-07 10:14:15.038789.038789 lmp.py:767]   Expert 31 |    268 | GPU0(cuda:1)
DEBUG 01-07 10:14:15.038717.038717 lmp.py:767]   Expert 61 |    272 | GPU1(cuda:2)
DEBUG 01-07 10:14:15.038121.038121 lmp.py:767]   Expert 52 |    306 | GPU0(cuda:1)
DEBUG 01-07 10:14:15.038764.038764 lmp.py:767]   Expert 58 |    315 | GPU1(cuda:2)
DEBUG 01-07 10:14:15.038169.038169 lmp.py:767]   Expert 62 |    323 | GPU0(cuda:1)
DEBUG 01-07 10:14:15.038765.038765 lmp.py:767]   Expert 55 |    345 | GPU1(cuda:2)
DEBUG 01-07 10:14:15.038885.038885 lmp.py:767]   Expert 11 |    380 | GPU0(cuda:1)
DEBUG 01-07 10:14:15.038528.038528 lmp.py:767]   Expert 23 |    387 | GPU1(cuda:2)
DEBUG 01-07 10:14:15.038171.038171 lmp.py:767]   Expert 25 |    410 | GPU1(cuda:2)
DEBUG 01-07 10:14:15.038814.038814 lmp.py:767]   Expert  5 |    520 | GPU0(cuda:1)
DEBUG 01-07 10:14:15.038503.038503 lmp.py:769] 
DEBUG 01-07 10:14:15.038503.038503 lmp.py:769]   Device Token Distribution:
DEBUG 01-07 10:14:15.038146.038146 lmp.py:770]   CPU:   1848 tokens
DEBUG 01-07 10:14:15.038981.038981 lmp.py:774]   cuda:1:   5158 tokens (22 experts)
DEBUG 01-07 10:14:15.038101.038101 lmp.py:774]   cuda:2:   5282 tokens (23 experts)
DEBUG 01-07 10:14:15.038744.038744 lmp.py:775]   Total GPU:  10440 tokens
DEBUG 01-07 10:14:15.038910.038910 lmp.py:776] ============================================================
DEBUG 01-07 10:14:15.038910.038910 lmp.py:776] 
DEBUG 01-07 10:14:15.038275.038275 cuda_h.py:19] end experts_map_get cost 0.0017461776733398438 seconds
DEBUG 01-07 10:14:15.038157.038157 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model_multi_device
DEBUG 01-07 10:14:15.038118.038118 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 10:14:15.038175.038175 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 10:14:15.038885.038885 cuda_h.py:19] end allocate_cuda_memory cost 0.0002105236053466797 seconds
DEBUG 01-07 10:14:15.038212.038212 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 10:14:15.038776.038776 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 10:14:15.038823.038823 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 10:14:15.038950.038950 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 2df4930e-b366-4127-9b1f-4a79efa8a972
DEBUG 01-07 10:14:15.039524.039524 client.py:106] call stub.LoadModelAsync
INFO 01-07 10:14:15.039129.039129 client.py:127] Model loaded
DEBUG 01-07 10:14:15.039195.039195 cuda_h.py:19] end sllm_worker_task cost 0.008847713470458984 seconds
INFO 01-07 10:14:15.039389.039389 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 2df4930e-b366-4127-9b1f-4a79efa8a972
DEBUG 01-07 10:14:15.039332.039332 cuda_h.py:19] end load_into_gpu_async cost 0.0011794567108154297 seconds
DEBUG 01-07 10:14:15.040512.040512 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 10:14:15.040204.040204 cuda_h.py:19] end restore_tensors2 cost 0.000274658203125 seconds
DEBUG 01-07 10:14:15.040219.040219 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.001981973648071289 seconds
DEBUG 01-07 10:14:15.042036.042036 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 10:14:15.042756.042756 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 10:14:15.042864.042864 cuda_h.py:19] end allocate_cuda_memory cost 0.0002167224884033203 seconds
DEBUG 01-07 10:14:15.042323.042323 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 10:14:15.042695.042695 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 10:14:15.042120.042120 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 10:14:15.042531.042531 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 95c117ef-d214-440f-9a4f-dba96951188e
DEBUG 01-07 10:14:15.042198.042198 client.py:106] call stub.LoadModelAsync
INFO 01-07 10:14:15.043166.043166 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 95c117ef-d214-440f-9a4f-dba96951188e
DEBUG 01-07 10:14:15.043234.043234 cuda_h.py:19] end load_into_gpu_async cost 0.0010619163513183594 seconds
DEBUG 01-07 10:14:15.043314.043314 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 10:14:15.044768.044768 cuda_h.py:19] end restore_tensors2 cost 0.00027370452880859375 seconds
DEBUG 01-07 10:14:15.044405.044405 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0018591880798339844 seconds
DEBUG 01-07 10:14:15.046913.046913 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model_multi_device cost 0.007729053497314453 seconds
DEBUG 01-07 10:14:15.046756.046756 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-07 10:14:15.046626.046626 lmp.py:816] 
DEBUG 01-07 10:14:15.046626.046626 lmp.py:816]   Computing 19 experts on CPU...
DEBUG 01-07 10:14:15.046416.046416 cuda_h.py:19] end cpu_experts_submit cost 0.00010752677917480469 seconds
DEBUG 01-07 10:14:15.046828.046828 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-07 10:14:15.057029.057029 mlpmodule.py:749] group tensors cost 0.010825872421264648 s
DEBUG 01-07 10:14:15.058495.058495 mlpmodule.py:787] pad cost 0.0009675025939941406 s
DEBUG 01-07 10:14:15.058531.058531 mlpmodule.py:793] create cpu tensor cost 3.933906555175781e-05 s
DEBUG 01-07 10:14:15.059335.059335 mlpmodule.py:798] move to cpu cost 3.147125244140625e-05 s
DEBUG 01-07 10:14:15.068784.068784 mlpmodule.py:812] group_w3: shape=torch.Size([19, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=54788096
DEBUG 01-07 10:14:15.068036.068036 mlpmodule.py:813] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-07 10:14:15.069139.069139 mlpmodule.py:818] group_w3 first element: -0.03369140625
WARNING 01-07 10:14:15.069938.069938 mlpmodule.py:828] start einsum2
DEBUG 01-07 10:14:15.084028.084028 mlpmodule.py:838] group einsum cost 0.025188684463500977 s
DEBUG 01-07 10:14:15.084798.084798 mlpmodule.py:846] cpy2cputensor cost 0.0004227161407470703 s
DEBUG 01-07 10:14:15.087938.087938 cuda_h.py:19] end wait_cetm_experts cost 0.04122567176818848 seconds
DEBUG 01-07 10:14:15.087444.087444 cuda_h.py:10] start gpu_sexperts
DEBUG 01-07 10:14:15.088039.088039 cuda_h.py:19] end gpu_sexperts cost 0.0005004405975341797 seconds
DEBUG 01-07 10:14:15.088412.088412 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-07 10:14:15.088308.088308 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.4318695068359375e-05 seconds
DEBUG 01-07 10:14:15.088680.088680 cuda_h.py:10] start wait_experts_multi_device
INFO 01-07 10:14:15.088655.088655 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 2df4930e-b366-4127-9b1f-4a79efa8a972
INFO 01-07 10:14:15.089008.089008 client.py:127] Model loaded
INFO 01-07 10:14:15.089182.089182 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 95c117ef-d214-440f-9a4f-dba96951188e
INFO 01-07 10:14:15.089183.089183 client.py:127] Model loaded
DEBUG 01-07 10:14:15.089297.089297 cuda_h.py:19] end wait_experts_multi_device cost 0.0014066696166992188 seconds
DEBUG 01-07 10:14:15.089623.089623 cuda_h.py:10] start gpu_experts_multi_device
DEBUG 01-07 10:14:15.089969.089969 lmp.py:867]   Computing 23 experts on cuda:2...
DEBUG 01-07 10:14:15.091703.091703 mlpmodule.py:533] gpu group tensors cost 0.0005075931549072266 s
DEBUG 01-07 10:14:15.092677.092677 mlpmodule.py:566] gpu pad cost 0.0013155937194824219 s
DEBUG 01-07 10:14:15.092675.092675 mlpmodule.py:584] gpu group einsum cost 0.0004372596740722656 s
DEBUG 01-07 10:14:15.094013.094013 mlpmodule.py:656] gpu experts func einsum cost 0.0044252872467041016 s
DEBUG 01-07 10:14:15.095515.095515 lmp.py:867]   Computing 22 experts on cuda:1...
DEBUG 01-07 10:14:15.096129.096129 mlpmodule.py:533] gpu group tensors cost 0.0004496574401855469 s
DEBUG 01-07 10:14:15.097954.097954 mlpmodule.py:566] gpu pad cost 0.0012536048889160156 s
DEBUG 01-07 10:14:15.097224.097224 mlpmodule.py:707]  experts func einsum cost 0.05108475685119629 s
DEBUG 01-07 10:14:15.097012.097012 mlpmodule.py:584] gpu group einsum cost 0.00045180320739746094 s
DEBUG 01-07 10:14:15.099101.099101 mlpmodule.py:656] gpu experts func einsum cost 0.0041866302490234375 s
DEBUG 01-07 10:14:15.099649.099649 cuda_h.py:19] end gpu_experts_multi_device cost 0.01003265380859375 seconds
DEBUG 01-07 10:14:15.099380.099380 cuda_h.py:19] end layer_moe_generate_multi_device_8 cost 0.06419181823730469 seconds
DEBUG 01-07 10:14:15.100275.100275 lmp.py:194] -------------------------------- end prefill layer 8 --------------------------------
DEBUG 01-07 10:14:15.100528.100528 lmp.py:153] -------------------------------- start prefill layer 9 --------------------------------
DEBUG 01-07 10:14:15.100178.100178 cuda_h.py:10] start start_load_qkvogn_s_weight_l_10
DEBUG 01-07 10:14:15.100696.100696 cuda_h.py:10] start start_load_qkvogn_s_weight_l_10
DEBUG 01-07 10:14:15.100340.100340 cuda_h.py:19] end start_load_qkvogn_s_weight_l_10 cost 2.8133392333984375e-05 seconds
DEBUG 01-07 10:14:15.100149.100149 cuda_h.py:19] end start_load_qkvogn_s_weight_l_10 cost 5.817413330078125e-05 seconds
DEBUG 01-07 10:14:15.100084.100084 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-07 10:14:15.100589.100589 mlpmodule.py:367] cuda:1 cuda:1
DEBUG 01-07 10:14:15.100246.100246 cuda_h.py:10] start sllm_worker_task
DEBUG 01-07 10:14:15.100242.100242 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 10:14:15.100072.100072 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 10:14:15.100467.100467 cuda_h.py:19] end allocate_cuda_memory cost 0.00029158592224121094 seconds
DEBUG 01-07 10:14:15.101205.101205 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 10:14:15.101537.101537 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 10:14:15.101737.101737 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 10:14:15.101533.101533 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, b06f53c2-c138-46a2-a64e-0ba400ef42a0
DEBUG 01-07 10:14:15.101919.101919 client.py:106] call stub.LoadModelAsync
DEBUG 01-07 10:14:15.101497.101497 cuda_h.py:10] start self_attn
INFO 01-07 10:14:15.101933.101933 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, b06f53c2-c138-46a2-a64e-0ba400ef42a0
DEBUG 01-07 10:14:15.101147.101147 cuda_h.py:19] end load_into_gpu_async cost 0.0008006095886230469 seconds
DEBUG 01-07 10:14:15.101942.101942 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 10:14:15.102972.102972 cuda_h.py:19] end restore_tensors2 cost 6.723403930664062e-05 seconds
DEBUG 01-07 10:14:15.102867.102867 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0014154911041259766 seconds
INFO 01-07 10:14:15.102372.102372 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, b06f53c2-c138-46a2-a64e-0ba400ef42a0
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-07 10:14:15.105700.105700 cuda_h.py:19] end self_attn cost 0.0036339759826660156 seconds
DEBUG 01-07 10:14:15.105572.105572 cuda_h.py:19] end iln_self_attn_paln cost 0.005069732666015625 seconds
DEBUG 01-07 10:14:15.105256.105256 cuda_h.py:10] start layer_moe_generate_multi_device_9
DEBUG 01-07 10:14:15.105396.105396 cuda_h.py:10] start gate
DEBUG 01-07 10:14:15.106405.106405 cuda_h.py:19] end gate cost 0.0006401538848876953 seconds
DEBUG 01-07 10:14:15.106043.106043 cuda_h.py:10] start experts_map_get
DEBUG 01-07 10:14:15.106354.106354 lmp.py:744] 
DEBUG 01-07 10:14:15.106354.106354 lmp.py:744] Expert Token Distribution & Multi-Device Allocation:
DEBUG 01-07 10:14:15.106985.106985 lmp.py:745]   Total experts: 64
DEBUG 01-07 10:14:15.106542.106542 lmp.py:746]   CPU experts: 19 (30%)
DEBUG 01-07 10:14:15.106854.106854 lmp.py:747]   GPU experts: 45 (70%)
DEBUG 01-07 10:14:15.106259.106259 lmp.py:748]   Number of GPU devices: 2
DEBUG 01-07 10:14:15.106233.106233 lmp.py:749] 
DEBUG 01-07 10:14:15.106233.106233 lmp.py:749]   Expert ID | Tokens | Device
DEBUG 01-07 10:14:15.106922.106922 lmp.py:750]   -----------------------------------
DEBUG 01-07 10:14:15.106049.106049 lmp.py:767]   Expert 24 |     42 | CPU
DEBUG 01-07 10:14:15.106691.106691 lmp.py:767]   Expert  2 |     43 | CPU
DEBUG 01-07 10:14:15.106096.106096 lmp.py:767]   Expert 32 |     62 | CPU
DEBUG 01-07 10:14:15.106262.106262 lmp.py:767]   Expert 26 |     65 | CPU
DEBUG 01-07 10:14:15.106713.106713 lmp.py:767]   Expert 19 |     66 | CPU
DEBUG 01-07 10:14:15.106926.106926 lmp.py:767]   Expert 50 |     74 | CPU
DEBUG 01-07 10:14:15.106138.106138 lmp.py:767]   Expert  7 |     80 | CPU
DEBUG 01-07 10:14:15.107350.107350 lmp.py:767]   Expert 15 |     80 | CPU
DEBUG 01-07 10:14:15.107563.107563 lmp.py:767]   Expert 28 |     81 | CPU
DEBUG 01-07 10:14:15.107299.107299 lmp.py:767]   Expert  4 |     84 | CPU
DEBUG 01-07 10:14:15.107226.107226 lmp.py:767]   Expert 60 |     85 | CPU
DEBUG 01-07 10:14:15.107631.107631 lmp.py:767]   Expert 59 |     92 | CPU
DEBUG 01-07 10:14:15.107843.107843 lmp.py:767]   Expert 49 |    100 | CPU
DEBUG 01-07 10:14:15.107817.107817 lmp.py:767]   Expert  5 |    101 | CPU
DEBUG 01-07 10:14:15.107791.107791 lmp.py:767]   Expert 23 |    101 | CPU
DEBUG 01-07 10:14:15.107527.107527 lmp.py:767]   Expert 12 |    105 | CPU
DEBUG 01-07 10:14:15.107501.107501 lmp.py:767]   Expert 10 |    108 | CPU
DEBUG 01-07 10:14:15.107475.107475 lmp.py:767]   Expert 27 |    111 | CPU
DEBUG 01-07 10:14:15.107211.107211 lmp.py:767]   Expert 41 |    114 | CPU
DEBUG 01-07 10:14:15.107569.107569 lmp.py:767]   Expert  3 |    127 | GPU1(cuda:2)
DEBUG 01-07 10:14:15.107881.107881 lmp.py:767]   Expert 20 |    128 | GPU1(cuda:2)
DEBUG 01-07 10:14:15.107001.107001 lmp.py:767]   Expert 25 |    128 | GPU0(cuda:1)
DEBUG 01-07 10:14:15.107405.107405 lmp.py:767]   Expert 16 |    131 | GPU1(cuda:2)
DEBUG 01-07 10:14:15.107048.107048 lmp.py:767]   Expert 40 |    131 | GPU0(cuda:1)
DEBUG 01-07 10:14:15.107214.107214 lmp.py:767]   Expert 13 |    132 | GPU1(cuda:2)
DEBUG 01-07 10:14:15.107380.107380 lmp.py:767]   Expert 37 |    137 | GPU0(cuda:1)
DEBUG 01-07 10:14:15.107308.107308 lmp.py:767]   Expert 17 |    142 | GPU1(cuda:2)
DEBUG 01-07 10:14:15.107428.107428 lmp.py:767]   Expert 35 |    145 | GPU0(cuda:1)
DEBUG 01-07 10:14:15.107833.107833 lmp.py:767]   Expert 47 |    149 | GPU0(cuda:1)
DEBUG 01-07 10:14:15.107999.107999 lmp.py:767]   Expert 22 |    158 | GPU1(cuda:2)
DEBUG 01-07 10:14:15.107926.107926 lmp.py:767]   Expert 53 |    168 | GPU1(cuda:2)
DEBUG 01-07 10:14:15.107093.107093 lmp.py:767]   Expert 39 |    170 | GPU0(cuda:1)
DEBUG 01-07 10:14:15.107020.107020 lmp.py:767]   Expert 36 |    178 | GPU1(cuda:2)
DEBUG 01-07 10:14:15.107186.107186 lmp.py:767]   Expert 38 |    179 | GPU0(cuda:1)
DEBUG 01-07 10:14:15.107114.107114 lmp.py:767]   Expert 52 |    179 | GPU0(cuda:1)
DEBUG 01-07 10:14:15.107996.107996 lmp.py:767]   Expert 44 |    185 | GPU1(cuda:2)
DEBUG 01-07 10:14:15.107638.107638 lmp.py:767]   Expert 18 |    186 | GPU0(cuda:1)
DEBUG 01-07 10:14:15.107805.107805 lmp.py:767]   Expert 58 |    189 | GPU1(cuda:2)
DEBUG 01-07 10:14:15.107732.107732 lmp.py:767]   Expert 62 |    198 | GPU1(cuda:2)
DEBUG 01-07 10:14:15.107422.107422 lmp.py:767]   Expert 48 |    207 | GPU0(cuda:1)
DEBUG 01-07 10:14:15.107873.107873 lmp.py:767]   Expert 11 |    214 | GPU1(cuda:2)
DEBUG 01-07 10:14:15.107800.107800 lmp.py:767]   Expert 14 |    221 | GPU1(cuda:2)
DEBUG 01-07 10:14:15.107490.107490 lmp.py:767]   Expert 30 |    221 | GPU0(cuda:1)
DEBUG 01-07 10:14:15.107417.107417 lmp.py:767]   Expert  1 |    230 | GPU0(cuda:1)
DEBUG 01-07 10:14:15.107060.107060 lmp.py:767]   Expert 42 |    231 | GPU1(cuda:2)
DEBUG 01-07 10:14:15.107703.107703 lmp.py:767]   Expert  6 |    237 | GPU0(cuda:1)
DEBUG 01-07 10:14:15.107393.107393 lmp.py:767]   Expert 45 |    238 | GPU1(cuda:2)
DEBUG 01-07 10:14:15.107082.107082 lmp.py:767]   Expert 31 |    239 | GPU0(cuda:1)
DEBUG 01-07 10:14:15.107010.107010 lmp.py:767]   Expert 51 |    240 | GPU0(cuda:1)
DEBUG 01-07 10:14:15.107460.107460 lmp.py:767]   Expert 34 |    269 | GPU1(cuda:2)
DEBUG 01-07 10:14:15.107388.107388 lmp.py:767]   Expert 29 |    271 | GPU0(cuda:1)
DEBUG 01-07 10:14:15.107839.107839 lmp.py:767]   Expert 33 |    273 | GPU1(cuda:2)
DEBUG 01-07 10:14:15.107290.107290 lmp.py:767]   Expert 57 |    296 | GPU1(cuda:2)
DEBUG 01-07 10:14:15.107741.107741 lmp.py:767]   Expert 61 |    296 | GPU0(cuda:1)
DEBUG 01-07 10:14:15.107145.107145 lmp.py:767]   Expert 43 |    309 | GPU0(cuda:1)
DEBUG 01-07 10:14:15.107265.107265 lmp.py:767]   Expert  0 |    319 | GPU1(cuda:2)
DEBUG 01-07 10:14:15.107147.107147 lmp.py:767]   Expert 46 |    356 | GPU0(cuda:1)
DEBUG 01-07 10:14:15.107028.107028 lmp.py:767]   Expert  8 |    382 | GPU1(cuda:2)
DEBUG 01-07 10:14:15.107909.107909 lmp.py:767]   Expert  9 |    391 | GPU0(cuda:1)
DEBUG 01-07 10:14:15.107791.107791 lmp.py:767]   Expert 56 |    395 | GPU1(cuda:2)
DEBUG 01-07 10:14:15.107434.107434 lmp.py:767]   Expert 54 |    398 | GPU0(cuda:1)
DEBUG 01-07 10:14:15.107315.107315 lmp.py:767]   Expert 63 |    409 | GPU1(cuda:2)
DEBUG 01-07 10:14:15.107673.107673 lmp.py:767]   Expert 55 |    427 | GPU1(cuda:2)
DEBUG 01-07 10:14:15.107316.107316 lmp.py:767]   Expert 21 |    485 | GPU0(cuda:1)
DEBUG 01-07 10:14:15.107006.107006 lmp.py:769] 
DEBUG 01-07 10:14:15.107006.107006 lmp.py:769]   Device Token Distribution:
DEBUG 01-07 10:14:15.107649.107649 lmp.py:770]   CPU:   1594 tokens
DEBUG 01-07 10:14:15.108007.108007 lmp.py:774]   cuda:1:   5284 tokens (22 experts)
DEBUG 01-07 10:14:15.108888.108888 lmp.py:774]   cuda:2:   5410 tokens (23 experts)
DEBUG 01-07 10:14:15.108054.108054 lmp.py:775]   Total GPU:  10694 tokens
DEBUG 01-07 10:14:15.108558.108558 lmp.py:776] ============================================================
DEBUG 01-07 10:14:15.108558.108558 lmp.py:776] 
DEBUG 01-07 10:14:15.108970.108970 cuda_h.py:19] end experts_map_get cost 0.001743316650390625 seconds
DEBUG 01-07 10:14:15.108136.108136 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model_multi_device
DEBUG 01-07 10:14:15.108290.108290 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 10:14:15.108055.108055 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 10:14:15.108302.108302 cuda_h.py:19] end allocate_cuda_memory cost 0.00021886825561523438 seconds
DEBUG 01-07 10:14:15.108906.108906 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 10:14:15.108755.108755 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 10:14:15.108041.108041 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 10:14:15.108452.108452 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 2aeb9c82-0856-4956-954c-0226d4244486
DEBUG 01-07 10:14:15.108318.108318 client.py:106] call stub.LoadModelAsync
INFO 01-07 10:14:15.108837.108837 client.py:127] Model loaded
DEBUG 01-07 10:14:15.109633.109633 cuda_h.py:19] end sllm_worker_task cost 0.008716344833374023 seconds
INFO 01-07 10:14:15.109086.109086 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 2aeb9c82-0856-4956-954c-0226d4244486
DEBUG 01-07 10:14:15.109929.109929 cuda_h.py:19] end load_into_gpu_async cost 0.0010387897491455078 seconds
DEBUG 01-07 10:14:15.109678.109678 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 10:14:15.109284.109284 cuda_h.py:19] end restore_tensors2 cost 0.0002815723419189453 seconds
DEBUG 01-07 10:14:15.110299.110299 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0018470287322998047 seconds
DEBUG 01-07 10:14:15.111453.111453 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 10:14:15.111776.111776 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 10:14:15.112685.112685 cuda_h.py:19] end allocate_cuda_memory cost 0.0002105236053466797 seconds
DEBUG 01-07 10:14:15.112859.112859 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 10:14:15.112661.112661 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 10:14:15.112371.112371 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 10:14:15.112544.112544 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 637cf5f0-400e-4fd4-b086-95918aee8243
DEBUG 01-07 10:14:15.112178.112178 client.py:106] call stub.LoadModelAsync
INFO 01-07 10:14:15.113028.113028 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 637cf5f0-400e-4fd4-b086-95918aee8243
DEBUG 01-07 10:14:15.113904.113904 cuda_h.py:19] end load_into_gpu_async cost 0.0009145736694335938 seconds
DEBUG 01-07 10:14:15.113222.113222 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 10:14:15.113491.113491 cuda_h.py:19] end restore_tensors2 cost 0.0002779960632324219 seconds
DEBUG 01-07 10:14:15.113698.113698 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.001705169677734375 seconds
DEBUG 01-07 10:14:15.115298.115298 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model_multi_device cost 0.007398128509521484 seconds
DEBUG 01-07 10:14:15.115081.115081 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-07 10:14:15.115998.115998 lmp.py:816] 
DEBUG 01-07 10:14:15.115998.115998 lmp.py:816]   Computing 19 experts on CPU...
DEBUG 01-07 10:14:15.115119.115119 cuda_h.py:19] end cpu_experts_submit cost 0.00010466575622558594 seconds
DEBUG 01-07 10:14:15.115292.115292 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-07 10:14:15.121885.121885 mlpmodule.py:749] group tensors cost 0.005499601364135742 s
DEBUG 01-07 10:14:15.123155.123155 mlpmodule.py:787] pad cost 0.0013189315795898438 s
DEBUG 01-07 10:14:15.123847.123847 mlpmodule.py:793] create cpu tensor cost 5.221366882324219e-05 s
DEBUG 01-07 10:14:15.123585.123585 mlpmodule.py:798] move to cpu cost 3.8623809814453125e-05 s
DEBUG 01-07 10:14:15.131000.131000 mlpmodule.py:812] group_w3: shape=torch.Size([19, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=54788096
DEBUG 01-07 10:14:15.131198.131198 mlpmodule.py:813] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-07 10:14:15.131473.131473 mlpmodule.py:818] group_w3 first element: 0.0157470703125
WARNING 01-07 10:14:15.131742.131742 mlpmodule.py:828] start einsum2
DEBUG 01-07 10:14:15.144581.144581 mlpmodule.py:838] group einsum cost 0.021150588989257812 s
DEBUG 01-07 10:14:15.145249.145249 mlpmodule.py:846] cpy2cputensor cost 0.000362396240234375 s
DEBUG 01-07 10:14:15.148858.148858 cuda_h.py:19] end wait_cetm_experts cost 0.03229403495788574 seconds
DEBUG 01-07 10:14:15.148888.148888 cuda_h.py:10] start gpu_sexperts
DEBUG 01-07 10:14:15.148470.148470 cuda_h.py:19] end gpu_sexperts cost 0.0005292892456054688 seconds
DEBUG 01-07 10:14:15.148558.148558 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-07 10:14:15.148408.148408 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.7179718017578125e-05 seconds
DEBUG 01-07 10:14:15.148587.148587 cuda_h.py:10] start wait_experts_multi_device
INFO 01-07 10:14:15.148012.148012 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 2aeb9c82-0856-4956-954c-0226d4244486
INFO 01-07 10:14:15.150236.150236 client.py:127] Model loaded
INFO 01-07 10:14:15.150099.150099 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 637cf5f0-400e-4fd4-b086-95918aee8243
INFO 01-07 10:14:15.155771.155771 client.py:127] Model loaded
DEBUG 01-07 10:14:15.155813.155813 cuda_h.py:19] end wait_experts_multi_device cost 0.006910562515258789 seconds
DEBUG 01-07 10:14:15.155523.155523 cuda_h.py:10] start gpu_experts_multi_device
DEBUG 01-07 10:14:15.155207.155207 lmp.py:867]   Computing 23 experts on cuda:2...
DEBUG 01-07 10:14:15.157260.157260 mlpmodule.py:533] gpu group tensors cost 0.0005042552947998047 s
DEBUG 01-07 10:14:15.157552.157552 mlpmodule.py:707]  experts func einsum cost 0.04147171974182129 s
DEBUG 01-07 10:14:15.158012.158012 mlpmodule.py:566] gpu pad cost 0.001428842544555664 s
DEBUG 01-07 10:14:15.159481.159481 mlpmodule.py:584] gpu group einsum cost 0.00046062469482421875 s
DEBUG 01-07 10:14:15.161980.161980 mlpmodule.py:656] gpu experts func einsum cost 0.0044078826904296875 s
DEBUG 01-07 10:14:15.161672.161672 lmp.py:867]   Computing 22 experts on cuda:1...
DEBUG 01-07 10:14:15.161939.161939 mlpmodule.py:533] gpu group tensors cost 0.00037360191345214844 s
DEBUG 01-07 10:14:15.163426.163426 mlpmodule.py:566] gpu pad cost 0.0010433197021484375 s
DEBUG 01-07 10:14:15.163331.163331 mlpmodule.py:584] gpu group einsum cost 0.0004496574401855469 s
DEBUG 01-07 10:14:15.165268.165268 mlpmodule.py:656] gpu experts func einsum cost 0.0036699771881103516 s
DEBUG 01-07 10:14:15.165199.165199 cuda_h.py:19] end gpu_experts_multi_device cost 0.009492874145507812 seconds
DEBUG 01-07 10:14:15.165739.165739 cuda_h.py:19] end layer_moe_generate_multi_device_9 cost 0.0598759651184082 seconds
DEBUG 01-07 10:14:15.165674.165674 lmp.py:194] -------------------------------- end prefill layer 9 --------------------------------
DEBUG 01-07 10:14:15.165483.165483 lmp.py:153] -------------------------------- start prefill layer 10 --------------------------------
DEBUG 01-07 10:14:15.165748.165748 cuda_h.py:10] start start_load_qkvogn_s_weight_l_11
DEBUG 01-07 10:14:15.165789.165789 cuda_h.py:10] start start_load_qkvogn_s_weight_l_11
DEBUG 01-07 10:14:15.165148.165148 cuda_h.py:19] end start_load_qkvogn_s_weight_l_11 cost 2.765655517578125e-05 seconds
DEBUG 01-07 10:14:15.165898.165898 cuda_h.py:19] end start_load_qkvogn_s_weight_l_11 cost 5.793571472167969e-05 seconds
DEBUG 01-07 10:14:15.165256.165256 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-07 10:14:15.165079.165079 cuda_h.py:10] start sllm_worker_task
DEBUG 01-07 10:14:15.165174.165174 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 10:14:15.166579.166579 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 10:14:15.166026.166026 cuda_h.py:19] end allocate_cuda_memory cost 0.0002598762512207031 seconds
DEBUG 01-07 10:14:15.166473.166473 mlpmodule.py:367] cuda:1 cuda:1
DEBUG 01-07 10:14:15.166541.166541 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 10:14:15.166663.166663 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 10:14:15.166247.166247 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 10:14:15.166043.166043 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 7c0d6714-d14f-49ed-b9a0-516ddab12520
DEBUG 01-07 10:14:15.166999.166999 client.py:106] call stub.LoadModelAsync
DEBUG 01-07 10:14:15.167695.167695 cuda_h.py:10] start self_attn
INFO 01-07 10:14:15.167744.167744 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 7c0d6714-d14f-49ed-b9a0-516ddab12520
DEBUG 01-07 10:14:15.167719.167719 cuda_h.py:19] end load_into_gpu_async cost 0.0008838176727294922 seconds
DEBUG 01-07 10:14:15.167799.167799 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 10:14:15.167160.167160 cuda_h.py:19] end restore_tensors2 cost 6.437301635742188e-05 seconds
DEBUG 01-07 10:14:15.167247.167247 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0015668869018554688 seconds
INFO 01-07 10:14:15.167971.167971 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 7c0d6714-d14f-49ed-b9a0-516ddab12520
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-07 10:14:15.171284.171284 cuda_h.py:19] end self_attn cost 0.00408482551574707 seconds
DEBUG 01-07 10:14:15.171821.171821 cuda_h.py:19] end iln_self_attn_paln cost 0.005756378173828125 seconds
DEBUG 01-07 10:14:15.171948.171948 cuda_h.py:10] start layer_moe_generate_multi_device_10
DEBUG 01-07 10:14:15.171294.171294 cuda_h.py:10] start gate
DEBUG 01-07 10:14:15.172976.172976 cuda_h.py:19] end gate cost 0.0007402896881103516 seconds
DEBUG 01-07 10:14:15.172726.172726 cuda_h.py:10] start experts_map_get
DEBUG 01-07 10:14:15.173280.173280 lmp.py:744] 
DEBUG 01-07 10:14:15.173280.173280 lmp.py:744] Expert Token Distribution & Multi-Device Allocation:
DEBUG 01-07 10:14:15.173864.173864 lmp.py:745]   Total experts: 64
DEBUG 01-07 10:14:15.173097.173097 lmp.py:746]   CPU experts: 19 (30%)
DEBUG 01-07 10:14:15.173800.173800 lmp.py:747]   GPU experts: 45 (70%)
DEBUG 01-07 10:14:15.173404.173404 lmp.py:748]   Number of GPU devices: 2
DEBUG 01-07 10:14:15.173338.173338 lmp.py:749] 
DEBUG 01-07 10:14:15.173338.173338 lmp.py:749]   Expert ID | Tokens | Device
DEBUG 01-07 10:14:15.173465.173465 lmp.py:750]   -----------------------------------
DEBUG 01-07 10:14:15.173505.173505 lmp.py:767]   Expert 43 |     19 | CPU
DEBUG 01-07 10:14:15.173394.173394 lmp.py:767]   Expert 27 |     35 | CPU
DEBUG 01-07 10:14:15.173759.173759 lmp.py:767]   Expert 34 |     51 | CPU
DEBUG 01-07 10:14:15.173885.173885 lmp.py:767]   Expert 56 |     51 | CPU
DEBUG 01-07 10:14:15.173820.173820 lmp.py:767]   Expert 26 |     53 | CPU
DEBUG 01-07 10:14:15.173516.173516 lmp.py:767]   Expert  3 |     55 | CPU
DEBUG 01-07 10:14:15.173212.173212 lmp.py:767]   Expert  4 |     68 | CPU
DEBUG 01-07 10:14:15.173670.173670 lmp.py:767]   Expert 61 |     81 | CPU
DEBUG 01-07 10:14:15.173558.173558 lmp.py:767]   Expert 14 |     92 | CPU
DEBUG 01-07 10:14:15.173969.173969 lmp.py:767]   Expert 38 |     98 | CPU
DEBUG 01-07 10:14:15.173142.173142 lmp.py:767]   Expert  2 |    116 | CPU
DEBUG 01-07 10:14:15.173838.173838 lmp.py:767]   Expert 22 |    121 | CPU
DEBUG 01-07 10:14:15.173534.173534 lmp.py:767]   Expert 17 |    123 | CPU
DEBUG 01-07 10:14:15.173753.173753 lmp.py:767]   Expert 37 |    125 | CPU
DEBUG 01-07 10:14:15.173688.173688 lmp.py:767]   Expert 47 |    128 | CPU
DEBUG 01-07 10:14:15.173861.173861 lmp.py:767]   Expert 55 |    130 | CPU
DEBUG 01-07 10:14:15.173511.173511 lmp.py:767]   Expert 54 |    133 | CPU
DEBUG 01-07 10:14:15.173207.173207 lmp.py:767]   Expert 28 |    139 | CPU
DEBUG 01-07 10:14:15.173426.173426 lmp.py:767]   Expert  7 |    142 | CPU
DEBUG 01-07 10:14:15.173553.173553 lmp.py:767]   Expert 15 |    143 | GPU0(cuda:1)
DEBUG 01-07 10:14:15.173679.173679 lmp.py:767]   Expert 48 |    145 | GPU0(cuda:1)
DEBUG 01-07 10:14:15.173759.173759 lmp.py:767]   Expert 60 |    149 | GPU1(cuda:2)
DEBUG 01-07 10:14:15.173078.173078 lmp.py:767]   Expert  5 |    150 | GPU1(cuda:2)
DEBUG 01-07 10:14:15.173920.173920 lmp.py:767]   Expert 51 |    150 | GPU0(cuda:1)
DEBUG 01-07 10:14:15.173285.173285 lmp.py:767]   Expert 12 |    154 | GPU1(cuda:2)
DEBUG 01-07 10:14:15.173935.173935 lmp.py:767]   Expert 63 |    154 | GPU0(cuda:1)
DEBUG 01-07 10:14:15.173823.173823 lmp.py:767]   Expert 19 |    156 | GPU1(cuda:2)
DEBUG 01-07 10:14:15.173857.173857 lmp.py:767]   Expert 45 |    158 | GPU0(cuda:1)
DEBUG 01-07 10:14:15.173699.173699 lmp.py:767]   Expert  6 |    165 | GPU1(cuda:2)
DEBUG 01-07 10:14:15.173825.173825 lmp.py:767]   Expert 52 |    170 | GPU0(cuda:1)
DEBUG 01-07 10:14:15.174475.174475 lmp.py:767]   Expert 57 |    171 | GPU0(cuda:1)
DEBUG 01-07 10:14:15.174363.174363 lmp.py:767]   Expert 18 |    178 | GPU1(cuda:2)
DEBUG 01-07 10:14:15.174490.174490 lmp.py:767]   Expert 44 |    179 | GPU1(cuda:2)
DEBUG 01-07 10:14:15.174332.174332 lmp.py:767]   Expert 50 |    179 | GPU0(cuda:1)
DEBUG 01-07 10:14:15.174174.174174 lmp.py:767]   Expert 30 |    188 | GPU1(cuda:2)
DEBUG 01-07 10:14:15.174062.174062 lmp.py:767]   Expert 23 |    189 | GPU0(cuda:1)
DEBUG 01-07 10:14:15.174188.174188 lmp.py:767]   Expert 31 |    189 | GPU0(cuda:1)
DEBUG 01-07 10:14:15.174077.174077 lmp.py:767]   Expert 13 |    190 | GPU1(cuda:2)
DEBUG 01-07 10:14:15.174965.174965 lmp.py:767]   Expert 39 |    195 | GPU0(cuda:1)
DEBUG 01-07 10:14:15.174853.174853 lmp.py:767]   Expert 53 |    198 | GPU1(cuda:2)
DEBUG 01-07 10:14:15.174887.174887 lmp.py:767]   Expert 16 |    201 | GPU1(cuda:2)
DEBUG 01-07 10:14:15.174967.174967 lmp.py:767]   Expert 20 |    201 | GPU0(cuda:1)
DEBUG 01-07 10:14:15.174048.174048 lmp.py:767]   Expert 21 |    202 | GPU0(cuda:1)
DEBUG 01-07 10:14:15.174889.174889 lmp.py:767]   Expert 59 |    203 | GPU1(cuda:2)
DEBUG 01-07 10:14:15.174493.174493 lmp.py:767]   Expert 29 |    206 | GPU1(cuda:2)
DEBUG 01-07 10:14:15.174096.174096 lmp.py:767]   Expert 36 |    211 | GPU0(cuda:1)
DEBUG 01-07 10:14:15.174892.174892 lmp.py:767]   Expert 41 |    214 | GPU0(cuda:1)
DEBUG 01-07 10:14:15.174687.174687 lmp.py:767]   Expert 25 |    215 | GPU1(cuda:2)
DEBUG 01-07 10:14:15.174768.174768 lmp.py:767]   Expert 32 |    223 | GPU0(cuda:1)
DEBUG 01-07 10:14:15.174609.174609 lmp.py:767]   Expert 49 |    224 | GPU1(cuda:2)
DEBUG 01-07 10:14:15.174213.174213 lmp.py:767]   Expert 46 |    235 | GPU1(cuda:2)
DEBUG 01-07 10:14:15.174293.174293 lmp.py:767]   Expert 42 |    248 | GPU0(cuda:1)
DEBUG 01-07 10:14:15.174135.174135 lmp.py:767]   Expert 10 |    249 | GPU1(cuda:2)
DEBUG 01-07 10:14:15.174738.174738 lmp.py:767]   Expert  8 |    251 | GPU0(cuda:1)
DEBUG 01-07 10:14:15.174580.174580 lmp.py:767]   Expert 62 |    262 | GPU0(cuda:1)
DEBUG 01-07 10:14:15.174422.174422 lmp.py:767]   Expert 35 |    278 | GPU1(cuda:2)
DEBUG 01-07 10:14:15.174264.174264 lmp.py:767]   Expert  9 |    289 | GPU1(cuda:2)
DEBUG 01-07 10:14:15.174106.174106 lmp.py:767]   Expert 58 |    297 | GPU0(cuda:1)
DEBUG 01-07 10:14:15.174663.174663 lmp.py:767]   Expert 33 |    298 | GPU0(cuda:1)
DEBUG 01-07 10:14:15.174459.174459 lmp.py:767]   Expert 40 |    389 | GPU1(cuda:2)
DEBUG 01-07 10:14:15.174777.174777 lmp.py:767]   Expert  0 |    423 | GPU0(cuda:1)
DEBUG 01-07 10:14:15.174619.174619 lmp.py:767]   Expert 11 |    438 | GPU1(cuda:2)
DEBUG 01-07 10:14:15.174938.174938 lmp.py:767]   Expert 24 |    560 | GPU1(cuda:2)
DEBUG 01-07 10:14:15.174541.174541 lmp.py:767]   Expert  1 |    661 | GPU0(cuda:1)
DEBUG 01-07 10:14:15.174668.174668 lmp.py:769] 
DEBUG 01-07 10:14:15.174668.174668 lmp.py:769]   Device Token Distribution:
DEBUG 01-07 10:14:15.174510.174510 lmp.py:770]   CPU:   1760 tokens
DEBUG 01-07 10:14:15.174067.174067 lmp.py:774]   cuda:1:   5334 tokens (23 experts)
DEBUG 01-07 10:14:15.174147.174147 lmp.py:774]   cuda:2:   5194 tokens (22 experts)
DEBUG 01-07 10:14:15.174035.174035 lmp.py:775]   Total GPU:  10528 tokens
DEBUG 01-07 10:14:15.174400.174400 lmp.py:776] ============================================================
DEBUG 01-07 10:14:15.174400.174400 lmp.py:776] 
DEBUG 01-07 10:14:15.174918.174918 cuda_h.py:19] end experts_map_get cost 0.0023157596588134766 seconds
DEBUG 01-07 10:14:15.174237.174237 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model_multi_device
DEBUG 01-07 10:14:15.175503.175503 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 10:14:15.175302.175302 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 10:14:15.175556.175556 cuda_h.py:19] end allocate_cuda_memory cost 0.0002155303955078125 seconds
DEBUG 01-07 10:14:15.175195.175195 cuda_h.py:10] start load_into_gpu_async
INFO 01-07 10:14:15.175237.175237 client.py:127] Model loaded
DEBUG 01-07 10:14:15.175033.175033 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 10:14:15.175676.175676 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 10:14:15.175154.175154 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 45ebf150-67af-411f-97a6-1cfb91792796
DEBUG 01-07 10:14:15.176597.176597 client.py:106] call stub.LoadModelAsync
DEBUG 01-07 10:14:15.176026.176026 cuda_h.py:19] end sllm_worker_task cost 0.010424613952636719 seconds
INFO 01-07 10:14:15.176300.176300 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 45ebf150-67af-411f-97a6-1cfb91792796
DEBUG 01-07 10:14:15.176780.176780 cuda_h.py:19] end load_into_gpu_async cost 0.0013227462768554688 seconds
DEBUG 01-07 10:14:15.177350.177350 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 10:14:15.177832.177832 cuda_h.py:19] end restore_tensors2 cost 0.00032210350036621094 seconds
DEBUG 01-07 10:14:15.177676.177676 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0023429393768310547 seconds
DEBUG 01-07 10:14:15.179208.179208 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 10:14:15.179245.179245 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 10:14:15.179485.179485 cuda_h.py:19] end allocate_cuda_memory cost 0.00021004676818847656 seconds
DEBUG 01-07 10:14:15.179182.179182 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 10:14:15.179508.179508 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 10:14:15.179648.179648 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 10:14:15.179583.179583 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 5564e383-782e-474d-93f5-c1d3d12faf9f
DEBUG 01-07 10:14:15.180104.180104 client.py:106] call stub.LoadModelAsync
INFO 01-07 10:14:15.181405.181405 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 5564e383-782e-474d-93f5-c1d3d12faf9f
DEBUG 01-07 10:14:15.181711.181711 cuda_h.py:19] end load_into_gpu_async cost 0.0011315345764160156 seconds
DEBUG 01-07 10:14:15.181745.181745 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 10:14:15.181019.181019 cuda_h.py:19] end restore_tensors2 cost 0.0002465248107910156 seconds
DEBUG 01-07 10:14:15.181988.181988 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0018928050994873047 seconds
DEBUG 01-07 10:14:15.183142.183142 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model_multi_device cost 0.008219480514526367 seconds
DEBUG 01-07 10:14:15.183587.183587 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-07 10:14:15.183981.183981 lmp.py:816] 
DEBUG 01-07 10:14:15.183981.183981 lmp.py:816]   Computing 19 experts on CPU...
DEBUG 01-07 10:14:15.183678.183678 cuda_h.py:19] end cpu_experts_submit cost 0.00010967254638671875 seconds
DEBUG 01-07 10:14:15.183043.183043 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-07 10:14:15.195928.195928 mlpmodule.py:749] group tensors cost 0.01147007942199707 s
DEBUG 01-07 10:14:15.197815.197815 mlpmodule.py:787] pad cost 0.0015375614166259766 s
DEBUG 01-07 10:14:15.197005.197005 mlpmodule.py:793] create cpu tensor cost 5.8650970458984375e-05 s
DEBUG 01-07 10:14:15.197617.197617 mlpmodule.py:798] move to cpu cost 4.38690185546875e-05 s
DEBUG 01-07 10:14:15.207385.207385 mlpmodule.py:812] group_w3: shape=torch.Size([19, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=54788096
DEBUG 01-07 10:14:15.207728.207728 mlpmodule.py:813] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-07 10:14:15.207302.207302 mlpmodule.py:818] group_w3 first element: -0.0213623046875
WARNING 01-07 10:14:15.207670.207670 mlpmodule.py:828] start einsum2
DEBUG 01-07 10:14:15.222104.222104 mlpmodule.py:838] group einsum cost 0.024519681930541992 s
DEBUG 01-07 10:14:15.222283.222283 mlpmodule.py:846] cpy2cputensor cost 0.000377655029296875 s
DEBUG 01-07 10:14:15.226651.226651 cuda_h.py:19] end wait_cetm_experts cost 0.04264497756958008 seconds
DEBUG 01-07 10:14:15.226250.226250 cuda_h.py:10] start gpu_sexperts
DEBUG 01-07 10:14:15.226037.226037 cuda_h.py:19] end gpu_sexperts cost 0.0005018711090087891 seconds
DEBUG 01-07 10:14:15.226880.226880 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-07 10:14:15.226968.226968 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.6226043701171875e-05 seconds
DEBUG 01-07 10:14:15.226101.226101 cuda_h.py:10] start wait_experts_multi_device
INFO 01-07 10:14:15.226765.226765 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 45ebf150-67af-411f-97a6-1cfb91792796
INFO 01-07 10:14:15.227622.227622 client.py:127] Model loaded
INFO 01-07 10:14:15.227505.227505 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 5564e383-782e-474d-93f5-c1d3d12faf9f
INFO 01-07 10:14:15.228770.228770 client.py:127] Model loaded
DEBUG 01-07 10:14:15.228930.228930 cuda_h.py:19] end wait_experts_multi_device cost 0.0013880729675292969 seconds
DEBUG 01-07 10:14:15.228714.228714 cuda_h.py:10] start gpu_experts_multi_device
DEBUG 01-07 10:14:15.228397.228397 lmp.py:867]   Computing 22 experts on cuda:2...
DEBUG 01-07 10:14:15.229582.229582 mlpmodule.py:533] gpu group tensors cost 0.0004913806915283203 s
DEBUG 01-07 10:14:15.230844.230844 mlpmodule.py:566] gpu pad cost 0.0012521743774414062 s
DEBUG 01-07 10:14:15.231211.231211 mlpmodule.py:584] gpu group einsum cost 0.0005679130554199219 s
DEBUG 01-07 10:14:15.233117.233117 mlpmodule.py:656] gpu experts func einsum cost 0.004608154296875 s
DEBUG 01-07 10:14:15.234572.234572 lmp.py:867]   Computing 23 experts on cuda:1...
DEBUG 01-07 10:14:15.234948.234948 mlpmodule.py:533] gpu group tensors cost 0.0004744529724121094 s
DEBUG 01-07 10:14:15.235342.235342 mlpmodule.py:707]  experts func einsum cost 0.05192995071411133 s
DEBUG 01-07 10:14:15.236918.236918 mlpmodule.py:566] gpu pad cost 0.0013911724090576172 s
DEBUG 01-07 10:14:15.236010.236010 mlpmodule.py:584] gpu group einsum cost 0.000499725341796875 s
DEBUG 01-07 10:14:15.238851.238851 mlpmodule.py:656] gpu experts func einsum cost 0.0044748783111572266 s
DEBUG 01-07 10:14:15.238272.238272 cuda_h.py:19] end gpu_experts_multi_device cost 0.010529279708862305 seconds
DEBUG 01-07 10:14:15.239957.239957 cuda_h.py:19] end layer_moe_generate_multi_device_10 cost 0.06727838516235352 seconds
DEBUG 01-07 10:14:15.239012.239012 lmp.py:194] -------------------------------- end prefill layer 10 --------------------------------
DEBUG 01-07 10:14:15.239490.239490 lmp.py:153] -------------------------------- start prefill layer 11 --------------------------------
DEBUG 01-07 10:14:15.239425.239425 cuda_h.py:10] start start_load_qkvogn_s_weight_l_12
DEBUG 01-07 10:14:15.239419.239419 cuda_h.py:10] start start_load_qkvogn_s_weight_l_12
DEBUG 01-07 10:14:15.239302.239302 cuda_h.py:19] end start_load_qkvogn_s_weight_l_12 cost 2.7418136596679688e-05 seconds
DEBUG 01-07 10:14:15.239859.239859 cuda_h.py:19] end start_load_qkvogn_s_weight_l_12 cost 5.650520324707031e-05 seconds
DEBUG 01-07 10:14:15.239217.239217 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-07 10:14:15.239278.239278 cuda_h.py:10] start sllm_worker_task
DEBUG 01-07 10:14:15.239977.239977 mlpmodule.py:367] cuda:1 cuda:1
DEBUG 01-07 10:14:15.239931.239931 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 10:14:15.239703.239703 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 10:14:15.240263.240263 cuda_h.py:19] end allocate_cuda_memory cost 0.00026988983154296875 seconds
DEBUG 01-07 10:14:15.240160.240160 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 10:14:15.240869.240869 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 10:14:15.240308.240308 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 10:14:15.240626.240626 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 462a13f7-947c-4001-b9e8-e412a6d894ac
DEBUG 01-07 10:14:15.240867.240867 client.py:106] call stub.LoadModelAsync
DEBUG 01-07 10:14:15.240083.240083 cuda_h.py:10] start self_attn
INFO 01-07 10:14:15.240400.240400 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 462a13f7-947c-4001-b9e8-e412a6d894ac
DEBUG 01-07 10:14:15.241183.241183 cuda_h.py:19] end load_into_gpu_async cost 0.0008625984191894531 seconds
DEBUG 01-07 10:14:15.241502.241502 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 10:14:15.241101.241101 cuda_h.py:19] end restore_tensors2 cost 6.556510925292969e-05 seconds
DEBUG 01-07 10:14:15.241711.241711 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0014331340789794922 seconds
INFO 01-07 10:14:15.241931.241931 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 462a13f7-947c-4001-b9e8-e412a6d894ac
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-07 10:14:15.244259.244259 cuda_h.py:19] end self_attn cost 0.003614664077758789 seconds
DEBUG 01-07 10:14:15.244170.244170 cuda_h.py:19] end iln_self_attn_paln cost 0.005097866058349609 seconds
DEBUG 01-07 10:14:15.244854.244854 cuda_h.py:10] start layer_moe_generate_multi_device_11
DEBUG 01-07 10:14:15.244517.244517 cuda_h.py:10] start gate
DEBUG 01-07 10:14:15.245765.245765 cuda_h.py:19] end gate cost 0.0006406307220458984 seconds
DEBUG 01-07 10:14:15.245310.245310 cuda_h.py:10] start experts_map_get
DEBUG 01-07 10:14:15.245952.245952 lmp.py:744] 
DEBUG 01-07 10:14:15.245952.245952 lmp.py:744] Expert Token Distribution & Multi-Device Allocation:
DEBUG 01-07 10:14:15.245629.245629 lmp.py:745]   Total experts: 64
DEBUG 01-07 10:14:15.245948.245948 lmp.py:746]   CPU experts: 19 (30%)
DEBUG 01-07 10:14:15.245498.245498 lmp.py:747]   GPU experts: 45 (70%)
DEBUG 01-07 10:14:15.245903.245903 lmp.py:748]   Number of GPU devices: 2
DEBUG 01-07 10:14:15.245592.245592 lmp.py:749] 
DEBUG 01-07 10:14:15.245592.245592 lmp.py:749]   Expert ID | Tokens | Device
DEBUG 01-07 10:14:15.245520.245520 lmp.py:750]   -----------------------------------
DEBUG 01-07 10:14:15.245408.245408 lmp.py:767]   Expert 39 |     14 | CPU
DEBUG 01-07 10:14:15.246289.246289 lmp.py:767]   Expert 13 |     17 | CPU
DEBUG 01-07 10:14:15.246456.246456 lmp.py:767]   Expert 49 |     39 | CPU
DEBUG 01-07 10:14:15.246145.246145 lmp.py:767]   Expert 35 |     50 | CPU
DEBUG 01-07 10:14:15.246834.246834 lmp.py:767]   Expert 19 |     62 | CPU
DEBUG 01-07 10:14:15.246285.246285 lmp.py:767]   Expert  9 |     77 | CPU
DEBUG 01-07 10:14:15.246498.246498 lmp.py:767]   Expert 26 |     77 | CPU
DEBUG 01-07 10:14:15.246710.246710 lmp.py:767]   Expert 32 |     77 | CPU
DEBUG 01-07 10:14:15.246399.246399 lmp.py:767]   Expert 41 |     79 | CPU
DEBUG 01-07 10:14:15.246373.246373 lmp.py:767]   Expert 46 |     84 | CPU
DEBUG 01-07 10:14:15.246347.246347 lmp.py:767]   Expert 23 |     85 | CPU
DEBUG 01-07 10:14:15.246275.246275 lmp.py:767]   Expert 33 |     86 | CPU
DEBUG 01-07 10:14:15.246726.246726 lmp.py:767]   Expert 31 |     90 | CPU
DEBUG 01-07 10:14:15.246700.246700 lmp.py:767]   Expert 18 |     91 | CPU
DEBUG 01-07 10:14:15.246674.246674 lmp.py:767]   Expert 38 |     98 | CPU
DEBUG 01-07 10:14:15.246648.246648 lmp.py:767]   Expert  3 |    104 | CPU
DEBUG 01-07 10:14:15.246384.246384 lmp.py:767]   Expert  6 |    106 | CPU
DEBUG 01-07 10:14:15.246881.246881 lmp.py:767]   Expert 17 |    106 | CPU
DEBUG 01-07 10:14:15.246378.246378 lmp.py:767]   Expert 20 |    116 | CPU
DEBUG 01-07 10:14:15.246544.246544 lmp.py:767]   Expert 40 |    130 | GPU0(cuda:1)
DEBUG 01-07 10:14:15.246141.246141 lmp.py:767]   Expert 61 |    130 | GPU1(cuda:2)
DEBUG 01-07 10:14:15.246545.246545 lmp.py:767]   Expert 44 |    131 | GPU0(cuda:1)
DEBUG 01-07 10:14:15.246712.246712 lmp.py:767]   Expert 62 |    132 | GPU1(cuda:2)
DEBUG 01-07 10:14:15.246639.246639 lmp.py:767]   Expert 16 |    133 | GPU1(cuda:2)
DEBUG 01-07 10:14:15.246329.246329 lmp.py:767]   Expert 59 |    133 | GPU0(cuda:1)
DEBUG 01-07 10:14:15.246256.246256 lmp.py:767]   Expert 15 |    135 | GPU1(cuda:2)
DEBUG 01-07 10:14:15.246184.246184 lmp.py:767]   Expert 43 |    135 | GPU0(cuda:1)
DEBUG 01-07 10:14:15.246827.246827 lmp.py:767]   Expert 50 |    138 | GPU1(cuda:2)
DEBUG 01-07 10:14:15.246232.246232 lmp.py:767]   Expert 63 |    139 | GPU0(cuda:1)
DEBUG 01-07 10:14:15.246398.246398 lmp.py:767]   Expert  2 |    142 | GPU1(cuda:2)
DEBUG 01-07 10:14:15.246087.246087 lmp.py:767]   Expert 42 |    144 | GPU0(cuda:1)
DEBUG 01-07 10:14:15.246253.246253 lmp.py:767]   Expert 36 |    152 | GPU0(cuda:1)
DEBUG 01-07 10:14:15.246181.246181 lmp.py:767]   Expert 10 |    160 | GPU1(cuda:2)
DEBUG 01-07 10:14:15.246870.246870 lmp.py:767]   Expert  5 |    183 | GPU1(cuda:2)
DEBUG 01-07 10:14:15.246798.246798 lmp.py:767]   Expert 34 |    183 | GPU0(cuda:1)
DEBUG 01-07 10:14:15.246726.246726 lmp.py:767]   Expert 27 |    188 | GPU1(cuda:2)
DEBUG 01-07 10:14:15.246369.246369 lmp.py:767]   Expert 52 |    188 | GPU0(cuda:1)
DEBUG 01-07 10:14:15.246535.246535 lmp.py:767]   Expert 45 |    190 | GPU1(cuda:2)
DEBUG 01-07 10:14:15.246224.246224 lmp.py:767]   Expert 60 |    197 | GPU0(cuda:1)
DEBUG 01-07 10:14:15.246913.246913 lmp.py:767]   Expert 48 |    203 | GPU1(cuda:2)
DEBUG 01-07 10:14:15.246364.246364 lmp.py:767]   Expert 51 |    211 | GPU0(cuda:1)
DEBUG 01-07 10:14:15.246054.246054 lmp.py:767]   Expert 56 |    212 | GPU0(cuda:1)
DEBUG 01-07 10:14:15.246981.246981 lmp.py:767]   Expert  7 |    229 | GPU1(cuda:2)
DEBUG 01-07 10:14:15.246671.246671 lmp.py:767]   Expert 53 |    233 | GPU0(cuda:1)
DEBUG 01-07 10:14:15.246598.246598 lmp.py:767]   Expert 24 |    234 | GPU1(cuda:2)
DEBUG 01-07 10:14:15.246003.246003 lmp.py:767]   Expert  8 |    240 | GPU1(cuda:2)
DEBUG 01-07 10:14:15.246407.246407 lmp.py:767]   Expert 47 |    253 | GPU1(cuda:2)
DEBUG 01-07 10:14:15.246858.246858 lmp.py:767]   Expert 57 |    253 | GPU0(cuda:1)
DEBUG 01-07 10:14:15.246786.246786 lmp.py:767]   Expert 29 |    262 | GPU0(cuda:1)
DEBUG 01-07 10:14:15.246475.246475 lmp.py:767]   Expert 21 |    266 | GPU0(cuda:1)
DEBUG 01-07 10:14:15.246880.246880 lmp.py:767]   Expert 14 |    287 | GPU1(cuda:2)
DEBUG 01-07 10:14:15.246284.246284 lmp.py:767]   Expert  0 |    288 | GPU1(cuda:2)
DEBUG 01-07 10:14:15.246974.246974 lmp.py:767]   Expert  4 |    288 | GPU0(cuda:1)
DEBUG 01-07 10:14:15.246663.246663 lmp.py:767]   Expert 55 |    316 | GPU0(cuda:1)
DEBUG 01-07 10:14:15.246875.246875 lmp.py:767]   Expert 22 |    317 | GPU1(cuda:2)
DEBUG 01-07 10:14:15.246565.246565 lmp.py:767]   Expert  1 |    319 | GPU1(cuda:2)
DEBUG 01-07 10:14:15.246208.246208 lmp.py:767]   Expert 37 |    319 | GPU0(cuda:1)
DEBUG 01-07 10:14:15.246851.246851 lmp.py:767]   Expert 58 |    321 | GPU0(cuda:1)
DEBUG 01-07 10:14:15.246494.246494 lmp.py:767]   Expert 54 |    331 | GPU1(cuda:2)
DEBUG 01-07 10:14:15.246852.246852 lmp.py:767]   Expert 28 |    364 | GPU0(cuda:1)
DEBUG 01-07 10:14:15.246495.246495 lmp.py:767]   Expert 12 |    378 | GPU1(cuda:2)
DEBUG 01-07 10:14:15.247138.247138 lmp.py:767]   Expert 25 |    398 | GPU1(cuda:2)
DEBUG 01-07 10:14:15.247542.247542 lmp.py:767]   Expert 11 |    407 | GPU1(cuda:2)
DEBUG 01-07 10:14:15.247424.247424 lmp.py:767]   Expert 30 |    838 | GPU0(cuda:1)
DEBUG 01-07 10:14:15.247875.247875 lmp.py:769] 
DEBUG 01-07 10:14:15.247875.247875 lmp.py:769]   Device Token Distribution:
DEBUG 01-07 10:14:15.247041.247041 lmp.py:770]   CPU:   1458 tokens
DEBUG 01-07 10:14:15.247637.247637 lmp.py:774]   cuda:1:   5415 tokens (22 experts)
DEBUG 01-07 10:14:15.247042.247042 lmp.py:774]   cuda:2:   5415 tokens (23 experts)
DEBUG 01-07 10:14:15.247970.247970 lmp.py:775]   Total GPU:  10830 tokens
DEBUG 01-07 10:14:15.247182.247182 lmp.py:776] ============================================================
DEBUG 01-07 10:14:15.247182.247182 lmp.py:776] 
DEBUG 01-07 10:14:15.247832.247832 cuda_h.py:19] end experts_map_get cost 0.001726388931274414 seconds
DEBUG 01-07 10:14:15.247713.247713 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model_multi_device
DEBUG 01-07 10:14:15.247536.247536 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 10:14:15.247878.247878 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 10:14:15.247111.247111 cuda_h.py:19] end allocate_cuda_memory cost 0.00020933151245117188 seconds
DEBUG 01-07 10:14:15.247120.247120 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 10:14:15.247399.247399 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 10:14:15.247255.247255 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 10:14:15.247428.247428 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, fda18310-33ab-4793-887a-4e9e79a9196d
DEBUG 01-07 10:14:15.247678.247678 client.py:106] call stub.LoadModelAsync
INFO 01-07 10:14:15.248437.248437 client.py:127] Model loaded
DEBUG 01-07 10:14:15.248231.248231 cuda_h.py:19] end sllm_worker_task cost 0.008757352828979492 seconds
INFO 01-07 10:14:15.248161.248161 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, fda18310-33ab-4793-887a-4e9e79a9196d
DEBUG 01-07 10:14:15.248957.248957 cuda_h.py:19] end load_into_gpu_async cost 0.0010404586791992188 seconds
DEBUG 01-07 10:14:15.248422.248422 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 10:14:15.249842.249842 cuda_h.py:19] end restore_tensors2 cost 0.00024962425231933594 seconds
DEBUG 01-07 10:14:15.249618.249618 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.001828908920288086 seconds
DEBUG 01-07 10:14:15.250038.250038 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 10:14:15.251360.251360 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 10:14:15.251878.251878 cuda_h.py:19] end allocate_cuda_memory cost 0.00020384788513183594 seconds
DEBUG 01-07 10:14:15.251622.251622 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 10:14:15.251470.251470 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 10:14:15.251134.251134 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 10:14:15.251307.251307 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 2af83a49-f839-4729-b23a-6dae322d6719
DEBUG 01-07 10:14:15.251212.251212 client.py:106] call stub.LoadModelAsync
INFO 01-07 10:14:15.252604.252604 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 2af83a49-f839-4729-b23a-6dae322d6719
DEBUG 01-07 10:14:15.252242.252242 cuda_h.py:19] end load_into_gpu_async cost 0.0008828639984130859 seconds
DEBUG 01-07 10:14:15.252322.252322 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 10:14:15.252073.252073 cuda_h.py:19] end restore_tensors2 cost 0.000247955322265625 seconds
DEBUG 01-07 10:14:15.252041.252041 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0016393661499023438 seconds
DEBUG 01-07 10:14:15.254893.254893 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model_multi_device cost 0.0073053836822509766 seconds
DEBUG 01-07 10:14:15.254715.254715 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-07 10:14:15.254824.254824 lmp.py:816] 
DEBUG 01-07 10:14:15.254824.254824 lmp.py:816]   Computing 19 experts on CPU...
DEBUG 01-07 10:14:15.254329.254329 cuda_h.py:19] end cpu_experts_submit cost 0.00010943412780761719 seconds
DEBUG 01-07 10:14:15.254456.254456 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-07 10:14:15.260463.260463 mlpmodule.py:749] group tensors cost 0.005414485931396484 s
DEBUG 01-07 10:14:15.262024.262024 mlpmodule.py:787] pad cost 0.0013689994812011719 s
DEBUG 01-07 10:14:15.262532.262532 mlpmodule.py:793] create cpu tensor cost 5.412101745605469e-05 s
DEBUG 01-07 10:14:15.262846.262846 mlpmodule.py:798] move to cpu cost 4.0531158447265625e-05 s
DEBUG 01-07 10:14:15.269698.269698 mlpmodule.py:812] group_w3: shape=torch.Size([19, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=54788096
DEBUG 01-07 10:14:15.269950.269950 mlpmodule.py:813] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-07 10:14:15.269900.269900 mlpmodule.py:818] group_w3 first element: 0.01373291015625
WARNING 01-07 10:14:15.270375.270375 mlpmodule.py:828] start einsum2
DEBUG 01-07 10:14:15.281018.281018 mlpmodule.py:838] group einsum cost 0.01868152618408203 s
DEBUG 01-07 10:14:15.281011.281011 mlpmodule.py:846] cpy2cputensor cost 0.0003819465637207031 s
DEBUG 01-07 10:14:15.284026.284026 cuda_h.py:19] end wait_cetm_experts cost 0.029836654663085938 seconds
DEBUG 01-07 10:14:15.284585.284585 cuda_h.py:10] start gpu_sexperts
DEBUG 01-07 10:14:15.285101.285101 cuda_h.py:19] end gpu_sexperts cost 0.0005109310150146484 seconds
DEBUG 01-07 10:14:15.285235.285235 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-07 10:14:15.285370.285370 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.5272369384765625e-05 seconds
DEBUG 01-07 10:14:15.285980.285980 cuda_h.py:10] start wait_experts_multi_device
INFO 01-07 10:14:15.285166.285166 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, fda18310-33ab-4793-887a-4e9e79a9196d
INFO 01-07 10:14:15.290039.290039 client.py:127] Model loaded
INFO 01-07 10:14:15.291426.291426 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 2af83a49-f839-4729-b23a-6dae322d6719
DEBUG 01-07 10:14:15.294708.294708 mlpmodule.py:707]  experts func einsum cost 0.03924846649169922 s
INFO 01-07 10:14:15.295240.295240 client.py:127] Model loaded
DEBUG 01-07 10:14:15.295765.295765 cuda_h.py:19] end wait_experts_multi_device cost 0.010167360305786133 seconds
DEBUG 01-07 10:14:15.295429.295429 cuda_h.py:10] start gpu_experts_multi_device
DEBUG 01-07 10:14:15.295443.295443 lmp.py:867]   Computing 23 experts on cuda:2...
DEBUG 01-07 10:14:15.296831.296831 mlpmodule.py:533] gpu group tensors cost 0.0004329681396484375 s
DEBUG 01-07 10:14:15.297361.297361 mlpmodule.py:566] gpu pad cost 0.0011391639709472656 s
DEBUG 01-07 10:14:15.298557.298557 mlpmodule.py:584] gpu group einsum cost 0.0004124641418457031 s
DEBUG 01-07 10:14:15.300525.300525 mlpmodule.py:656] gpu experts func einsum cost 0.0037550926208496094 s
DEBUG 01-07 10:14:15.300773.300773 lmp.py:867]   Computing 22 experts on cuda:1...
DEBUG 01-07 10:14:15.301364.301364 mlpmodule.py:533] gpu group tensors cost 0.0003733634948730469 s
DEBUG 01-07 10:14:15.302366.302366 mlpmodule.py:566] gpu pad cost 0.0010025501251220703 s
DEBUG 01-07 10:14:15.302759.302759 mlpmodule.py:584] gpu group einsum cost 0.0004119873046875 s
DEBUG 01-07 10:14:15.304787.304787 mlpmodule.py:656] gpu experts func einsum cost 0.003493785858154297 s
DEBUG 01-07 10:14:15.304233.304233 cuda_h.py:19] end gpu_experts_multi_device cost 0.008570194244384766 seconds
DEBUG 01-07 10:14:15.304911.304911 cuda_h.py:19] end layer_moe_generate_multi_device_11 cost 0.05963301658630371 seconds
DEBUG 01-07 10:14:15.304105.304105 lmp.py:194] -------------------------------- end prefill layer 11 --------------------------------
DEBUG 01-07 10:14:15.304159.304159 lmp.py:153] -------------------------------- start prefill layer 12 --------------------------------
DEBUG 01-07 10:14:15.304286.304286 cuda_h.py:10] start start_load_qkvogn_s_weight_l_13
DEBUG 01-07 10:14:15.304280.304280 cuda_h.py:10] start start_load_qkvogn_s_weight_l_13
DEBUG 01-07 10:14:15.304878.304878 cuda_h.py:19] end start_load_qkvogn_s_weight_l_13 cost 2.8133392333984375e-05 seconds
DEBUG 01-07 10:14:15.304674.304674 cuda_h.py:19] end start_load_qkvogn_s_weight_l_13 cost 5.7697296142578125e-05 seconds
DEBUG 01-07 10:14:15.304270.304270 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-07 10:14:15.304398.304398 mlpmodule.py:367] cuda:1 cuda:1
DEBUG 01-07 10:14:15.304533.304533 cuda_h.py:10] start sllm_worker_task
DEBUG 01-07 10:14:15.304767.304767 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 10:14:15.305504.305504 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 10:14:15.305585.305585 cuda_h.py:19] end allocate_cuda_memory cost 0.00023674964904785156 seconds
DEBUG 01-07 10:14:15.305879.305879 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 10:14:15.305020.305020 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 10:14:15.305935.305935 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 10:14:15.305254.305254 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 8baa2aaf-0c44-423a-aabc-7fd6968b3c8d
DEBUG 01-07 10:14:15.305832.305832 client.py:106] call stub.LoadModelAsync
DEBUG 01-07 10:14:15.305549.305549 cuda_h.py:10] start self_attn
INFO 01-07 10:14:15.306149.306149 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 8baa2aaf-0c44-423a-aabc-7fd6968b3c8d
DEBUG 01-07 10:14:15.306456.306456 cuda_h.py:19] end load_into_gpu_async cost 0.0009531974792480469 seconds
DEBUG 01-07 10:14:15.306013.306013 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 10:14:15.306327.306327 cuda_h.py:19] end restore_tensors2 cost 6.580352783203125e-05 seconds
DEBUG 01-07 10:14:15.306176.306176 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0014989376068115234 seconds
INFO 01-07 10:14:15.306688.306688 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 8baa2aaf-0c44-423a-aabc-7fd6968b3c8d
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-07 10:14:15.309927.309927 cuda_h.py:19] end self_attn cost 0.0036923885345458984 seconds
DEBUG 01-07 10:14:15.309480.309480 cuda_h.py:19] end iln_self_attn_paln cost 0.005040884017944336 seconds
DEBUG 01-07 10:14:15.309356.309356 cuda_h.py:10] start layer_moe_generate_multi_device_12
DEBUG 01-07 10:14:15.309496.309496 cuda_h.py:10] start gate
DEBUG 01-07 10:14:15.310406.310406 cuda_h.py:19] end gate cost 0.0006361007690429688 seconds
DEBUG 01-07 10:14:15.310805.310805 cuda_h.py:10] start experts_map_get
DEBUG 01-07 10:14:15.311494.311494 lmp.py:744] 
DEBUG 01-07 10:14:15.311494.311494 lmp.py:744] Expert Token Distribution & Multi-Device Allocation:
DEBUG 01-07 10:14:15.311634.311634 lmp.py:745]   Total experts: 64
DEBUG 01-07 10:14:15.311237.311237 lmp.py:746]   CPU experts: 19 (30%)
DEBUG 01-07 10:14:15.311980.311980 lmp.py:747]   GPU experts: 45 (70%)
DEBUG 01-07 10:14:15.311099.311099 lmp.py:748]   Number of GPU devices: 2
DEBUG 01-07 10:14:15.311504.311504 lmp.py:749] 
DEBUG 01-07 10:14:15.311504.311504 lmp.py:749]   Expert ID | Tokens | Device
DEBUG 01-07 10:14:15.311909.311909 lmp.py:750]   -----------------------------------
DEBUG 01-07 10:14:15.311750.311750 lmp.py:767]   Expert 12 |     17 | CPU
DEBUG 01-07 10:14:15.311109.311109 lmp.py:767]   Expert 47 |     25 | CPU
DEBUG 01-07 10:14:15.311275.311275 lmp.py:767]   Expert 38 |     30 | CPU
DEBUG 01-07 10:14:15.311918.311918 lmp.py:767]   Expert 27 |     33 | CPU
DEBUG 01-07 10:14:15.311561.311561 lmp.py:767]   Expert 16 |     37 | CPU
DEBUG 01-07 10:14:15.311727.311727 lmp.py:767]   Expert 52 |     37 | CPU
DEBUG 01-07 10:14:15.311893.311893 lmp.py:767]   Expert 63 |     46 | CPU
DEBUG 01-07 10:14:15.311059.311059 lmp.py:767]   Expert  4 |     57 | CPU
DEBUG 01-07 10:14:15.311987.311987 lmp.py:767]   Expert 61 |     63 | CPU
DEBUG 01-07 10:14:15.311915.311915 lmp.py:767]   Expert 44 |     67 | CPU
DEBUG 01-07 10:14:15.311842.311842 lmp.py:767]   Expert 43 |     69 | CPU
DEBUG 01-07 10:14:15.311532.311532 lmp.py:767]   Expert 34 |     74 | CPU
DEBUG 01-07 10:14:15.311175.311175 lmp.py:767]   Expert  0 |     80 | CPU
DEBUG 01-07 10:14:15.311818.311818 lmp.py:767]   Expert 53 |     80 | CPU
DEBUG 01-07 10:14:15.311507.311507 lmp.py:767]   Expert 32 |     91 | CPU
DEBUG 01-07 10:14:15.311435.311435 lmp.py:767]   Expert 37 |     92 | CPU
DEBUG 01-07 10:14:15.311124.311124 lmp.py:767]   Expert 13 |    100 | CPU
DEBUG 01-07 10:14:15.311290.311290 lmp.py:767]   Expert 21 |    115 | CPU
DEBUG 01-07 10:14:15.311741.311741 lmp.py:767]   Expert 39 |    116 | CPU
DEBUG 01-07 10:14:15.311099.311099 lmp.py:767]   Expert 11 |    120 | GPU0(cuda:1)
DEBUG 01-07 10:14:15.311888.311888 lmp.py:767]   Expert 20 |    125 | GPU0(cuda:1)
DEBUG 01-07 10:14:15.311961.311961 lmp.py:767]   Expert 60 |    129 | GPU1(cuda:2)
DEBUG 01-07 10:14:15.311081.311081 lmp.py:767]   Expert  8 |    130 | GPU1(cuda:2)
DEBUG 01-07 10:14:15.311963.311963 lmp.py:767]   Expert 57 |    136 | GPU0(cuda:1)
DEBUG 01-07 10:14:15.311844.311844 lmp.py:767]   Expert 14 |    137 | GPU0(cuda:1)
DEBUG 01-07 10:14:15.311487.311487 lmp.py:767]   Expert 22 |    143 | GPU1(cuda:2)
DEBUG 01-07 10:14:15.311607.311607 lmp.py:767]   Expert 45 |    153 | GPU0(cuda:1)
DEBUG 01-07 10:14:15.311250.311250 lmp.py:767]   Expert  2 |    154 | GPU1(cuda:2)
DEBUG 01-07 10:14:15.311370.311370 lmp.py:767]   Expert 18 |    160 | GPU1(cuda:2)
DEBUG 01-07 10:14:15.311251.311251 lmp.py:767]   Expert 23 |    160 | GPU0(cuda:1)
DEBUG 01-07 10:14:15.311132.311132 lmp.py:767]   Expert 17 |    161 | GPU0(cuda:1)
DEBUG 01-07 10:14:15.311014.311014 lmp.py:767]   Expert 58 |    163 | GPU1(cuda:2)
DEBUG 01-07 10:14:15.311657.311657 lmp.py:767]   Expert  7 |    165 | GPU1(cuda:2)
DEBUG 01-07 10:14:15.311300.311300 lmp.py:767]   Expert 30 |    165 | GPU0(cuda:1)
DEBUG 01-07 10:14:15.311943.311943 lmp.py:767]   Expert 42 |    171 | GPU1(cuda:2)
DEBUG 01-07 10:14:15.311347.311347 lmp.py:767]   Expert 55 |    179 | GPU1(cuda:2)
DEBUG 01-07 10:14:15.311752.311752 lmp.py:767]   Expert 62 |    179 | GPU0(cuda:1)
DEBUG 01-07 10:14:15.311156.311156 lmp.py:767]   Expert 49 |    180 | GPU1(cuda:2)
DEBUG 01-07 10:14:15.311276.311276 lmp.py:767]   Expert 51 |    180 | GPU0(cuda:1)
DEBUG 01-07 10:14:15.311396.311396 lmp.py:767]   Expert 35 |    183 | GPU1(cuda:2)
DEBUG 01-07 10:14:15.311039.311039 lmp.py:767]   Expert 48 |    183 | GPU0(cuda:1)
DEBUG 01-07 10:14:15.311443.311443 lmp.py:767]   Expert 29 |    186 | GPU0(cuda:1)
DEBUG 01-07 10:14:15.311848.311848 lmp.py:767]   Expert 25 |    191 | GPU1(cuda:2)
DEBUG 01-07 10:14:15.311014.311014 lmp.py:767]   Expert 36 |    195 | GPU0(cuda:1)
DEBUG 01-07 10:14:15.311896.311896 lmp.py:767]   Expert  1 |    198 | GPU1(cuda:2)
DEBUG 01-07 10:14:15.311777.311777 lmp.py:767]   Expert  6 |    200 | GPU0(cuda:1)
DEBUG 01-07 10:14:15.312135.312135 lmp.py:767]   Expert 31 |    204 | GPU0(cuda:1)
DEBUG 01-07 10:14:15.312778.312778 lmp.py:767]   Expert 28 |    222 | GPU1(cuda:2)
DEBUG 01-07 10:14:15.312183.312183 lmp.py:767]   Expert 54 |    229 | GPU0(cuda:1)
DEBUG 01-07 10:14:15.312587.312587 lmp.py:767]   Expert 41 |    231 | GPU1(cuda:2)
DEBUG 01-07 10:14:15.312230.312230 lmp.py:767]   Expert  5 |    234 | GPU1(cuda:2)
DEBUG 01-07 10:14:15.312873.312873 lmp.py:767]   Expert 19 |    238 | GPU0(cuda:1)
DEBUG 01-07 10:14:15.312278.312278 lmp.py:767]   Expert  9 |    246 | GPU1(cuda:2)
DEBUG 01-07 10:14:15.312921.312921 lmp.py:767]   Expert 24 |    252 | GPU0(cuda:1)
DEBUG 01-07 10:14:15.312041.312041 lmp.py:767]   Expert 50 |    284 | GPU1(cuda:2)
DEBUG 01-07 10:14:15.312399.312399 lmp.py:767]   Expert 46 |    303 | GPU0(cuda:1)
DEBUG 01-07 10:14:15.312042.312042 lmp.py:767]   Expert 59 |    311 | GPU0(cuda:1)
DEBUG 01-07 10:14:15.312685.312685 lmp.py:767]   Expert 56 |    380 | GPU1(cuda:2)
DEBUG 01-07 10:14:15.312328.312328 lmp.py:767]   Expert 26 |    403 | GPU0(cuda:1)
DEBUG 01-07 10:14:15.312732.312732 lmp.py:767]   Expert 33 |    422 | GPU1(cuda:2)
DEBUG 01-07 10:14:15.312614.312614 lmp.py:767]   Expert  3 |    582 | GPU0(cuda:1)
DEBUG 01-07 10:14:15.312018.312018 lmp.py:767]   Expert 15 |    646 | GPU1(cuda:2)
DEBUG 01-07 10:14:15.312661.312661 lmp.py:767]   Expert 10 |    660 | GPU1(cuda:2)
DEBUG 01-07 10:14:15.312781.312781 lmp.py:767]   Expert 40 |    786 | GPU0(cuda:1)
DEBUG 01-07 10:14:15.312709.312709 lmp.py:769] 
DEBUG 01-07 10:14:15.312709.312709 lmp.py:769]   Device Token Distribution:
DEBUG 01-07 10:14:15.312352.312352 lmp.py:770]   CPU:   1229 tokens
DEBUG 01-07 10:14:15.312233.312233 lmp.py:774]   cuda:1:   5588 tokens (23 experts)
DEBUG 01-07 10:14:15.312876.312876 lmp.py:774]   cuda:2:   5471 tokens (22 experts)
DEBUG 01-07 10:14:15.312241.312241 lmp.py:775]   Total GPU:  11059 tokens
DEBUG 01-07 10:14:15.312930.312930 lmp.py:776] ============================================================
DEBUG 01-07 10:14:15.312930.312930 lmp.py:776] 
DEBUG 01-07 10:14:15.312819.312819 cuda_h.py:19] end experts_map_get cost 0.0017724037170410156 seconds
DEBUG 01-07 10:14:15.312654.312654 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model_multi_device
DEBUG 01-07 10:14:15.312953.312953 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 10:14:15.312216.312216 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 10:14:15.312826.312826 cuda_h.py:19] end allocate_cuda_memory cost 0.0002079010009765625 seconds
DEBUG 01-07 10:14:15.312921.312921 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 10:14:15.312247.312247 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 10:14:15.312102.312102 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 10:14:15.313037.313037 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 65809062-6614-4334-aae3-7da76305dd63
DEBUG 01-07 10:14:15.313572.313572 client.py:106] call stub.LoadModelAsync
INFO 01-07 10:14:15.313007.313007 client.py:127] Model loaded
DEBUG 01-07 10:14:15.313877.313877 cuda_h.py:19] end sllm_worker_task cost 0.008823156356811523 seconds
INFO 01-07 10:14:15.313763.313763 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 65809062-6614-4334-aae3-7da76305dd63
DEBUG 01-07 10:14:15.314037.314037 cuda_h.py:19] end load_into_gpu_async cost 0.001035451889038086 seconds
DEBUG 01-07 10:14:15.314263.314263 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 10:14:15.314094.314094 cuda_h.py:19] end restore_tensors2 cost 0.00027060508728027344 seconds
DEBUG 01-07 10:14:15.314539.314539 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0018498897552490234 seconds
DEBUG 01-07 10:14:15.316630.316630 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 10:14:15.316496.316496 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 10:14:15.316021.316021 cuda_h.py:19] end allocate_cuda_memory cost 0.00020599365234375 seconds
DEBUG 01-07 10:14:15.316241.316241 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 10:14:15.316851.316851 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 10:14:15.316323.316323 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 10:14:15.316304.316304 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 11578865-bb42-429b-8b7b-fc2622d640be
DEBUG 01-07 10:14:15.316864.316864 client.py:106] call stub.LoadModelAsync
INFO 01-07 10:14:15.317132.317132 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 11578865-bb42-429b-8b7b-fc2622d640be
DEBUG 01-07 10:14:15.317723.317723 cuda_h.py:19] end load_into_gpu_async cost 0.0010962486267089844 seconds
DEBUG 01-07 10:14:15.317803.317803 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 10:14:15.318249.318249 cuda_h.py:19] end restore_tensors2 cost 0.00023031234741210938 seconds
DEBUG 01-07 10:14:15.318595.318595 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0018553733825683594 seconds
DEBUG 01-07 10:14:15.320205.320205 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model_multi_device cost 0.007542848587036133 seconds
DEBUG 01-07 10:14:15.320220.320220 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-07 10:14:15.320898.320898 lmp.py:816] 
DEBUG 01-07 10:14:15.320898.320898 lmp.py:816]   Computing 19 experts on CPU...
DEBUG 01-07 10:14:15.320118.320118 cuda_h.py:19] end cpu_experts_submit cost 0.00010800361633300781 seconds
DEBUG 01-07 10:14:15.320530.320530 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-07 10:14:15.332992.332992 mlpmodule.py:749] group tensors cost 0.011883974075317383 s
DEBUG 01-07 10:14:15.333320.333320 mlpmodule.py:787] pad cost 0.0009560585021972656 s
DEBUG 01-07 10:14:15.334118.334118 mlpmodule.py:793] create cpu tensor cost 4.00543212890625e-05 s
DEBUG 01-07 10:14:15.334875.334875 mlpmodule.py:798] move to cpu cost 3.147125244140625e-05 s
DEBUG 01-07 10:14:15.340754.340754 mlpmodule.py:812] group_w3: shape=torch.Size([19, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=54788096
DEBUG 01-07 10:14:15.341966.341966 mlpmodule.py:813] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-07 10:14:15.341539.341539 mlpmodule.py:818] group_w3 first element: -0.0162353515625
WARNING 01-07 10:14:15.341239.341239 mlpmodule.py:828] start einsum2
DEBUG 01-07 10:14:15.352612.352612 mlpmodule.py:838] group einsum cost 0.018374204635620117 s
DEBUG 01-07 10:14:15.353168.353168 mlpmodule.py:846] cpy2cputensor cost 0.0003819465637207031 s
DEBUG 01-07 10:14:15.355560.355560 cuda_h.py:19] end wait_cetm_experts cost 0.0354764461517334 seconds
DEBUG 01-07 10:14:15.355934.355934 cuda_h.py:10] start gpu_sexperts
DEBUG 01-07 10:14:15.356391.356391 cuda_h.py:19] end gpu_sexperts cost 0.0005371570587158203 seconds
DEBUG 01-07 10:14:15.356241.356241 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-07 10:14:15.356376.356376 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.574920654296875e-05 seconds
DEBUG 01-07 10:14:15.356555.356555 cuda_h.py:10] start wait_experts_multi_device
INFO 01-07 10:14:15.356934.356934 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 65809062-6614-4334-aae3-7da76305dd63
INFO 01-07 10:14:15.357330.357330 client.py:127] Model loaded
INFO 01-07 10:14:15.357405.357405 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 11578865-bb42-429b-8b7b-fc2622d640be
INFO 01-07 10:14:15.359301.359301 client.py:127] Model loaded
DEBUG 01-07 10:14:15.359130.359130 cuda_h.py:19] end wait_experts_multi_device cost 0.0030968189239501953 seconds
DEBUG 01-07 10:14:15.359979.359979 cuda_h.py:10] start gpu_experts_multi_device
DEBUG 01-07 10:14:15.359755.359755 lmp.py:867]   Computing 22 experts on cuda:2...
DEBUG 01-07 10:14:15.360054.360054 mlpmodule.py:533] gpu group tensors cost 0.0004875659942626953 s
DEBUG 01-07 10:14:15.362905.362905 mlpmodule.py:566] gpu pad cost 0.0012285709381103516 s
DEBUG 01-07 10:14:15.362675.362675 mlpmodule.py:584] gpu group einsum cost 0.0005617141723632812 s
DEBUG 01-07 10:14:15.367351.367351 mlpmodule.py:656] gpu experts func einsum cost 0.007203578948974609 s
DEBUG 01-07 10:14:15.368937.368937 lmp.py:867]   Computing 23 experts on cuda:1...
DEBUG 01-07 10:14:15.368204.368204 mlpmodule.py:533] gpu group tensors cost 0.0003914833068847656 s
DEBUG 01-07 10:14:15.369434.369434 mlpmodule.py:566] gpu pad cost 0.0010614395141601562 s
DEBUG 01-07 10:14:15.369300.369300 mlpmodule.py:707]  experts func einsum cost 0.04956197738647461 s
DEBUG 01-07 10:14:15.370094.370094 mlpmodule.py:584] gpu group einsum cost 0.0004642009735107422 s
DEBUG 01-07 10:14:15.371084.371084 mlpmodule.py:656] gpu experts func einsum cost 0.003708362579345703 s
DEBUG 01-07 10:14:15.372722.372722 cuda_h.py:19] end gpu_experts_multi_device cost 0.012283086776733398 seconds
DEBUG 01-07 10:14:15.372069.372069 cuda_h.py:19] end layer_moe_generate_multi_device_12 cost 0.06222391128540039 seconds
DEBUG 01-07 10:14:15.372792.372792 lmp.py:194] -------------------------------- end prefill layer 12 --------------------------------
DEBUG 01-07 10:14:15.372330.372330 lmp.py:153] -------------------------------- start prefill layer 13 --------------------------------
DEBUG 01-07 10:14:15.372979.372979 cuda_h.py:10] start start_load_qkvogn_s_weight_l_14
DEBUG 01-07 10:14:15.372543.372543 cuda_h.py:10] start start_load_qkvogn_s_weight_l_14
DEBUG 01-07 10:14:15.372949.372949 cuda_h.py:19] end start_load_qkvogn_s_weight_l_14 cost 2.6941299438476562e-05 seconds
DEBUG 01-07 10:14:15.372414.372414 cuda_h.py:19] end start_load_qkvogn_s_weight_l_14 cost 5.817413330078125e-05 seconds
DEBUG 01-07 10:14:15.372964.372964 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-07 10:14:15.372370.372370 mlpmodule.py:367] cuda:1 cuda:1
DEBUG 01-07 10:14:15.372981.372981 cuda_h.py:10] start sllm_worker_task
DEBUG 01-07 10:14:15.372785.372785 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 10:14:15.372568.372568 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 10:14:15.373081.373081 cuda_h.py:19] end allocate_cuda_memory cost 0.0002741813659667969 seconds
DEBUG 01-07 10:14:15.373547.373547 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 10:14:15.373303.373303 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 10:14:15.373218.373218 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 10:14:15.373060.373060 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, d95cbc5a-72eb-4c62-8b15-0d0a88e75eff
DEBUG 01-07 10:14:15.373970.373970 client.py:106] call stub.LoadModelAsync
DEBUG 01-07 10:14:15.373397.373397 cuda_h.py:10] start self_attn
INFO 01-07 10:14:15.374150.374150 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, d95cbc5a-72eb-4c62-8b15-0d0a88e75eff
DEBUG 01-07 10:14:15.374980.374980 cuda_h.py:19] end load_into_gpu_async cost 0.001024484634399414 seconds
DEBUG 01-07 10:14:15.374743.374743 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 10:14:15.374441.374441 cuda_h.py:19] end restore_tensors2 cost 6.580352783203125e-05 seconds
DEBUG 01-07 10:14:15.374528.374528 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0016050338745117188 seconds
INFO 01-07 10:14:15.374716.374716 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, d95cbc5a-72eb-4c62-8b15-0d0a88e75eff
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-07 10:14:15.377736.377736 cuda_h.py:19] end self_attn cost 0.0037360191345214844 seconds
DEBUG 01-07 10:14:15.377090.377090 cuda_h.py:19] end iln_self_attn_paln cost 0.005120992660522461 seconds
DEBUG 01-07 10:14:15.377058.377058 cuda_h.py:10] start layer_moe_generate_multi_device_13
DEBUG 01-07 10:14:15.377152.377152 cuda_h.py:10] start gate
DEBUG 01-07 10:14:15.378301.378301 cuda_h.py:19] end gate cost 0.0006363391876220703 seconds
DEBUG 01-07 10:14:15.378699.378699 cuda_h.py:10] start experts_map_get
DEBUG 01-07 10:14:15.378799.378799 lmp.py:744] 
DEBUG 01-07 10:14:15.378799.378799 lmp.py:744] Expert Token Distribution & Multi-Device Allocation:
DEBUG 01-07 10:14:15.378085.378085 lmp.py:745]   Total experts: 64
DEBUG 01-07 10:14:15.378165.378165 lmp.py:746]   CPU experts: 19 (30%)
DEBUG 01-07 10:14:15.378715.378715 lmp.py:747]   GPU experts: 45 (70%)
DEBUG 01-07 10:14:15.378358.378358 lmp.py:748]   Number of GPU devices: 2
DEBUG 01-07 10:14:15.379094.379094 lmp.py:749] 
DEBUG 01-07 10:14:15.379094.379094 lmp.py:749]   Expert ID | Tokens | Device
DEBUG 01-07 10:14:15.379260.379260 lmp.py:750]   -----------------------------------
DEBUG 01-07 10:14:15.379625.379625 lmp.py:767]   Expert 30 |     22 | CPU
DEBUG 01-07 10:14:15.379791.379791 lmp.py:767]   Expert 42 |     22 | CPU
DEBUG 01-07 10:14:15.379765.379765 lmp.py:767]   Expert 19 |     23 | CPU
DEBUG 01-07 10:14:15.379216.379216 lmp.py:767]   Expert 32 |     48 | CPU
DEBUG 01-07 10:14:15.379336.379336 lmp.py:767]   Expert  6 |     56 | CPU
DEBUG 01-07 10:14:15.379025.379025 lmp.py:767]   Expert 53 |     74 | CPU
DEBUG 01-07 10:14:15.379476.379476 lmp.py:767]   Expert  5 |     77 | CPU
DEBUG 01-07 10:14:15.379450.379450 lmp.py:767]   Expert  1 |     80 | CPU
DEBUG 01-07 10:14:15.379662.379662 lmp.py:767]   Expert 13 |    116 | CPU
DEBUG 01-07 10:14:15.379875.379875 lmp.py:767]   Expert  9 |    122 | CPU
DEBUG 01-07 10:14:15.379087.379087 lmp.py:767]   Expert 58 |    129 | CPU
DEBUG 01-07 10:14:15.379777.379777 lmp.py:767]   Expert 50 |    131 | CPU
DEBUG 01-07 10:14:15.379181.379181 lmp.py:767]   Expert 34 |    132 | CPU
DEBUG 01-07 10:14:15.379871.379871 lmp.py:767]   Expert 26 |    136 | CPU
DEBUG 01-07 10:14:15.379321.379321 lmp.py:767]   Expert 59 |    136 | CPU
DEBUG 01-07 10:14:15.379011.379011 lmp.py:767]   Expert 63 |    137 | CPU
DEBUG 01-07 10:14:15.379223.379223 lmp.py:767]   Expert 11 |    139 | CPU
DEBUG 01-07 10:14:15.379913.379913 lmp.py:767]   Expert 31 |    139 | CPU
DEBUG 01-07 10:14:15.379125.379125 lmp.py:767]   Expert 56 |    145 | CPU
DEBUG 01-07 10:14:15.379006.379006 lmp.py:767]   Expert 12 |    146 | GPU0(cuda:1)
DEBUG 01-07 10:14:15.379365.379365 lmp.py:767]   Expert 40 |    146 | GPU1(cuda:2)
DEBUG 01-07 10:14:15.379246.379246 lmp.py:767]   Expert 18 |    147 | GPU1(cuda:2)
DEBUG 01-07 10:14:15.379651.379651 lmp.py:767]   Expert 20 |    147 | GPU1(cuda:2)
DEBUG 01-07 10:14:15.379770.379770 lmp.py:767]   Expert 48 |    152 | GPU0(cuda:1)
DEBUG 01-07 10:14:15.379175.379175 lmp.py:767]   Expert  4 |    153 | GPU0(cuda:1)
DEBUG 01-07 10:14:15.379103.379103 lmp.py:767]   Expert 46 |    153 | GPU1(cuda:2)
DEBUG 01-07 10:14:15.379269.379269 lmp.py:767]   Expert  2 |    154 | GPU1(cuda:2)
DEBUG 01-07 10:14:15.379673.379673 lmp.py:767]   Expert 33 |    155 | GPU0(cuda:1)
DEBUG 01-07 10:14:15.379078.379078 lmp.py:767]   Expert 61 |    157 | GPU0(cuda:1)
DEBUG 01-07 10:14:15.379244.379244 lmp.py:767]   Expert 35 |    162 | GPU1(cuda:2)
DEBUG 01-07 10:14:15.379410.379410 lmp.py:767]   Expert 10 |    167 | GPU1(cuda:2)
DEBUG 01-07 10:14:15.379815.379815 lmp.py:767]   Expert 55 |    171 | GPU0(cuda:1)
DEBUG 01-07 10:14:15.379742.379742 lmp.py:767]   Expert 36 |    177 | GPU0(cuda:1)
DEBUG 01-07 10:14:15.379147.379147 lmp.py:767]   Expert 51 |    178 | GPU1(cuda:2)
DEBUG 01-07 10:14:15.379313.379313 lmp.py:767]   Expert  8 |    179 | GPU1(cuda:2)
DEBUG 01-07 10:14:15.379195.379195 lmp.py:767]   Expert 52 |    186 | GPU0(cuda:1)
DEBUG 01-07 10:14:15.379361.379361 lmp.py:767]   Expert 37 |    188 | GPU0(cuda:1)
DEBUG 01-07 10:14:15.379527.379527 lmp.py:767]   Expert  0 |    203 | GPU1(cuda:2)
DEBUG 01-07 10:14:15.379693.379693 lmp.py:767]   Expert 57 |    205 | GPU1(cuda:2)
DEBUG 01-07 10:14:15.379382.379382 lmp.py:767]   Expert 39 |    219 | GPU0(cuda:1)
DEBUG 01-07 10:14:15.379548.379548 lmp.py:767]   Expert 25 |    225 | GPU0(cuda:1)
DEBUG 01-07 10:14:15.379191.379191 lmp.py:767]   Expert 62 |    235 | GPU1(cuda:2)
DEBUG 01-07 10:14:15.379596.379596 lmp.py:767]   Expert 38 |    241 | GPU1(cuda:2)
DEBUG 01-07 10:14:15.379524.379524 lmp.py:767]   Expert  7 |    247 | GPU0(cuda:1)
DEBUG 01-07 10:14:15.379451.379451 lmp.py:767]   Expert 27 |    251 | GPU0(cuda:1)
DEBUG 01-07 10:14:15.379617.379617 lmp.py:767]   Expert  3 |    253 | GPU1(cuda:2)
DEBUG 01-07 10:14:15.379784.379784 lmp.py:767]   Expert 28 |    254 | GPU0(cuda:1)
DEBUG 01-07 10:14:15.379950.379950 lmp.py:767]   Expert 24 |    255 | GPU1(cuda:2)
DEBUG 01-07 10:14:15.379070.379070 lmp.py:767]   Expert 60 |    259 | GPU1(cuda:2)
DEBUG 01-07 10:14:15.379189.379189 lmp.py:767]   Expert 21 |    263 | GPU0(cuda:1)
DEBUG 01-07 10:14:15.379832.379832 lmp.py:767]   Expert 16 |    265 | GPU0(cuda:1)
DEBUG 01-07 10:14:15.379999.379999 lmp.py:767]   Expert 43 |    265 | GPU1(cuda:2)
DEBUG 01-07 10:14:15.379165.379165 lmp.py:767]   Expert 49 |    267 | GPU0(cuda:1)
DEBUG 01-07 10:14:15.379569.379569 lmp.py:767]   Expert 23 |    274 | GPU1(cuda:2)
DEBUG 01-07 10:14:15.379735.379735 lmp.py:767]   Expert 29 |    276 | GPU0(cuda:1)
DEBUG 01-07 10:14:15.379901.379901 lmp.py:767]   Expert 22 |    281 | GPU1(cuda:2)
DEBUG 01-07 10:14:15.380260.380260 lmp.py:767]   Expert 47 |    292 | GPU0(cuda:1)
DEBUG 01-07 10:14:15.380380.380380 lmp.py:767]   Expert 15 |    293 | GPU1(cuda:2)
DEBUG 01-07 10:14:15.380738.380738 lmp.py:767]   Expert 41 |    302 | GPU0(cuda:1)
DEBUG 01-07 10:14:15.380858.380858 lmp.py:767]   Expert 44 |    307 | GPU1(cuda:2)
DEBUG 01-07 10:14:15.380739.380739 lmp.py:767]   Expert 54 |    342 | GPU0(cuda:1)
DEBUG 01-07 10:14:15.380859.380859 lmp.py:767]   Expert 14 |    374 | GPU1(cuda:2)
DEBUG 01-07 10:14:15.380217.380217 lmp.py:767]   Expert 17 |    405 | GPU1(cuda:2)
DEBUG 01-07 10:14:15.380052.380052 lmp.py:767]   Expert 45 |    453 | GPU0(cuda:1)
DEBUG 01-07 10:14:15.380933.380933 lmp.py:769] 
DEBUG 01-07 10:14:15.380933.380933 lmp.py:769]   Device Token Distribution:
DEBUG 01-07 10:14:15.380576.380576 lmp.py:770]   CPU:   1864 tokens
DEBUG 01-07 10:14:15.380650.380650 lmp.py:774]   cuda:1:   5141 tokens (22 experts)
DEBUG 01-07 10:14:15.380531.380531 lmp.py:774]   cuda:2:   5283 tokens (23 experts)
DEBUG 01-07 10:14:15.380697.380697 lmp.py:775]   Total GPU:  10424 tokens
DEBUG 01-07 10:14:15.380864.380864 lmp.py:776] ============================================================
DEBUG 01-07 10:14:15.380864.380864 lmp.py:776] 
DEBUG 01-07 10:14:15.380752.380752 cuda_h.py:19] end experts_map_get cost 0.0017306804656982422 seconds
DEBUG 01-07 10:14:15.380587.380587 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model_multi_device
DEBUG 01-07 10:14:15.380741.380741 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 10:14:15.380804.380804 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 10:14:15.380019.380019 cuda_h.py:19] end allocate_cuda_memory cost 0.00026488304138183594 seconds
DEBUG 01-07 10:14:15.380922.380922 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 10:14:15.380917.380917 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 10:14:15.380011.380011 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 10:14:15.380945.380945 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, e335af0f-2155-4b9e-a79e-cf26f6a8b433
DEBUG 01-07 10:14:15.381712.381712 client.py:106] call stub.LoadModelAsync
INFO 01-07 10:14:15.381816.381816 client.py:127] Model loaded
DEBUG 01-07 10:14:15.381604.381604 cuda_h.py:19] end sllm_worker_task cost 0.008854389190673828 seconds
INFO 01-07 10:14:15.381591.381591 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, e335af0f-2155-4b9e-a79e-cf26f6a8b433
DEBUG 01-07 10:14:15.381103.381103 cuda_h.py:19] end load_into_gpu_async cost 0.001012563705444336 seconds
DEBUG 01-07 10:14:15.381806.381806 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 10:14:15.382703.382703 cuda_h.py:19] end restore_tensors2 cost 0.00025010108947753906 seconds
DEBUG 01-07 10:14:15.382525.382525 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.001856088638305664 seconds
DEBUG 01-07 10:14:15.384594.384594 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 10:14:15.384631.384631 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 10:14:15.384488.384488 cuda_h.py:19] end allocate_cuda_memory cost 0.00024199485778808594 seconds
DEBUG 01-07 10:14:15.384093.384093 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 10:14:15.384418.384418 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 10:14:15.384320.384320 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 10:14:15.384778.384778 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, b3b8d4e9-2644-4a16-a4a5-82b22436593a
DEBUG 01-07 10:14:15.384438.384438 client.py:106] call stub.LoadModelAsync
INFO 01-07 10:14:15.385289.385289 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, b3b8d4e9-2644-4a16-a4a5-82b22436593a
DEBUG 01-07 10:14:15.385834.385834 cuda_h.py:19] end load_into_gpu_async cost 0.0009360313415527344 seconds
DEBUG 01-07 10:14:15.385629.385629 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 10:14:15.385235.385235 cuda_h.py:19] end restore_tensors2 cost 0.0002446174621582031 seconds
DEBUG 01-07 10:14:15.385580.385580 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.001729726791381836 seconds
DEBUG 01-07 10:14:15.387895.387895 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model_multi_device cost 0.007399320602416992 seconds
DEBUG 01-07 10:14:15.387625.387625 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-07 10:14:15.387972.387972 lmp.py:816] 
DEBUG 01-07 10:14:15.387972.387972 lmp.py:816]   Computing 19 experts on CPU...
DEBUG 01-07 10:14:15.387808.387808 cuda_h.py:19] end cpu_experts_submit cost 0.0001068115234375 seconds
DEBUG 01-07 10:14:15.387458.387458 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-07 10:14:15.399139.399139 mlpmodule.py:749] group tensors cost 0.011499881744384766 s
DEBUG 01-07 10:14:15.401955.401955 mlpmodule.py:787] pad cost 0.001382589340209961 s
DEBUG 01-07 10:14:15.401184.401184 mlpmodule.py:793] create cpu tensor cost 4.100799560546875e-05 s
DEBUG 01-07 10:14:15.401405.401405 mlpmodule.py:798] move to cpu cost 5.8650970458984375e-05 s
DEBUG 01-07 10:14:15.409326.409326 mlpmodule.py:812] group_w3: shape=torch.Size([19, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=54788096
DEBUG 01-07 10:14:15.409756.409756 mlpmodule.py:813] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-07 10:14:15.409044.409044 mlpmodule.py:818] group_w3 first element: -0.0211181640625
WARNING 01-07 10:14:15.409744.409744 mlpmodule.py:828] start einsum2
DEBUG 01-07 10:14:15.421302.421302 mlpmodule.py:838] group einsum cost 0.019789695739746094 s
DEBUG 01-07 10:14:15.422185.422185 mlpmodule.py:846] cpy2cputensor cost 0.0004451274871826172 s
DEBUG 01-07 10:14:15.425612.425612 cuda_h.py:19] end wait_cetm_experts cost 0.037184953689575195 seconds
DEBUG 01-07 10:14:15.425165.425165 cuda_h.py:10] start gpu_sexperts
DEBUG 01-07 10:14:15.425852.425852 cuda_h.py:19] end gpu_sexperts cost 0.0004992485046386719 seconds
DEBUG 01-07 10:14:15.425357.425357 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-07 10:14:15.425299.425299 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.4318695068359375e-05 seconds
DEBUG 01-07 10:14:15.425194.425194 cuda_h.py:10] start wait_experts_multi_device
INFO 01-07 10:14:15.425811.425811 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, e335af0f-2155-4b9e-a79e-cf26f6a8b433
INFO 01-07 10:14:15.426622.426622 client.py:127] Model loaded
INFO 01-07 10:14:15.426644.426644 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, b3b8d4e9-2644-4a16-a4a5-82b22436593a
INFO 01-07 10:14:15.429273.429273 client.py:127] Model loaded
DEBUG 01-07 10:14:15.429487.429487 cuda_h.py:19] end wait_experts_multi_device cost 0.003555774688720703 seconds
DEBUG 01-07 10:14:15.429858.429858 cuda_h.py:10] start gpu_experts_multi_device
DEBUG 01-07 10:14:15.429496.429496 lmp.py:867]   Computing 23 experts on cuda:2...
DEBUG 01-07 10:14:15.430548.430548 mlpmodule.py:533] gpu group tensors cost 0.0005011558532714844 s
DEBUG 01-07 10:14:15.432011.432011 mlpmodule.py:566] gpu pad cost 0.0012962818145751953 s
DEBUG 01-07 10:14:15.432175.432175 mlpmodule.py:584] gpu group einsum cost 0.00046324729919433594 s
DEBUG 01-07 10:14:15.434015.434015 mlpmodule.py:656] gpu experts func einsum cost 0.004357099533081055 s
DEBUG 01-07 10:14:15.434462.434462 lmp.py:867]   Computing 22 experts on cuda:1...
DEBUG 01-07 10:14:15.435420.435420 mlpmodule.py:533] gpu group tensors cost 0.0004570484161376953 s
DEBUG 01-07 10:14:15.436001.436001 mlpmodule.py:566] gpu pad cost 0.0012481212615966797 s
DEBUG 01-07 10:14:15.437675.437675 mlpmodule.py:584] gpu group einsum cost 0.0004909038543701172 s
DEBUG 01-07 10:14:15.438680.438680 mlpmodule.py:707]  experts func einsum cost 0.05023002624511719 s
DEBUG 01-07 10:14:15.439514.439514 mlpmodule.py:656] gpu experts func einsum cost 0.00424504280090332 s
DEBUG 01-07 10:14:15.439392.439392 cuda_h.py:19] end gpu_experts_multi_device cost 0.009983539581298828 seconds
DEBUG 01-07 10:14:15.439508.439508 cuda_h.py:19] end layer_moe_generate_multi_device_13 cost 0.06185173988342285 seconds
DEBUG 01-07 10:14:15.439993.439993 lmp.py:194] -------------------------------- end prefill layer 13 --------------------------------
DEBUG 01-07 10:14:15.439710.439710 lmp.py:153] -------------------------------- start prefill layer 14 --------------------------------
DEBUG 01-07 10:14:15.439452.439452 cuda_h.py:10] start start_load_qkvogn_s_weight_l_15
DEBUG 01-07 10:14:15.439254.439254 cuda_h.py:10] start start_load_qkvogn_s_weight_l_15
DEBUG 01-07 10:14:15.440091.440091 cuda_h.py:19] end start_load_qkvogn_s_weight_l_15 cost 2.9087066650390625e-05 seconds
DEBUG 01-07 10:14:15.440555.440555 cuda_h.py:19] end start_load_qkvogn_s_weight_l_15 cost 5.984306335449219e-05 seconds
DEBUG 01-07 10:14:15.440913.440913 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-07 10:14:15.440498.440498 cuda_h.py:10] start sllm_worker_task
DEBUG 01-07 10:14:15.440700.440700 mlpmodule.py:367] cuda:1 cuda:1
DEBUG 01-07 10:14:15.440609.440609 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 10:14:15.440996.440996 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 10:14:15.440855.440855 cuda_h.py:19] end allocate_cuda_memory cost 0.0002727508544921875 seconds
DEBUG 01-07 10:14:15.440864.440864 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 10:14:15.440004.440004 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 10:14:15.440920.440920 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 10:14:15.440953.440953 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, bf4ff246-17cb-409e-b384-60bd5bf8cb41
DEBUG 01-07 10:14:15.440771.440771 client.py:106] call stub.LoadModelAsync
DEBUG 01-07 10:14:15.441348.441348 cuda_h.py:10] start self_attn
INFO 01-07 10:14:15.441935.441935 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, bf4ff246-17cb-409e-b384-60bd5bf8cb41
DEBUG 01-07 10:14:15.441480.441480 cuda_h.py:19] end load_into_gpu_async cost 0.0009467601776123047 seconds
DEBUG 01-07 10:14:15.441752.441752 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 10:14:15.441782.441782 cuda_h.py:19] end restore_tensors2 cost 6.747245788574219e-05 seconds
DEBUG 01-07 10:14:15.441345.441345 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0015418529510498047 seconds
INFO 01-07 10:14:15.441626.441626 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, bf4ff246-17cb-409e-b384-60bd5bf8cb41
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-07 10:14:15.445225.445225 cuda_h.py:19] end self_attn cost 0.0037779808044433594 seconds
DEBUG 01-07 10:14:15.445931.445931 cuda_h.py:19] end iln_self_attn_paln cost 0.00525212287902832 seconds
DEBUG 01-07 10:14:15.445853.445853 cuda_h.py:10] start layer_moe_generate_multi_device_14
DEBUG 01-07 10:14:15.445517.445517 cuda_h.py:10] start gate
DEBUG 01-07 10:14:15.446679.446679 cuda_h.py:19] end gate cost 0.00064849853515625 seconds
DEBUG 01-07 10:14:15.446793.446793 cuda_h.py:10] start experts_map_get
DEBUG 01-07 10:14:15.446104.446104 lmp.py:744] 
DEBUG 01-07 10:14:15.446104.446104 lmp.py:744] Expert Token Distribution & Multi-Device Allocation:
DEBUG 01-07 10:14:15.446973.446973 lmp.py:745]   Total experts: 64
DEBUG 01-07 10:14:15.446769.446769 lmp.py:746]   CPU experts: 19 (30%)
DEBUG 01-07 10:14:15.446842.446842 lmp.py:747]   GPU experts: 45 (70%)
DEBUG 01-07 10:14:15.446247.446247 lmp.py:748]   Number of GPU devices: 2
DEBUG 01-07 10:14:15.446175.446175 lmp.py:749] 
DEBUG 01-07 10:14:15.446175.446175 lmp.py:749]   Expert ID | Tokens | Device
DEBUG 01-07 10:14:15.446102.446102 lmp.py:750]   -----------------------------------
DEBUG 01-07 10:14:15.446706.446706 lmp.py:767]   Expert  7 |     28 | CPU
DEBUG 01-07 10:14:15.446826.446826 lmp.py:767]   Expert 34 |     30 | CPU
DEBUG 01-07 10:14:15.446469.446469 lmp.py:767]   Expert 13 |     41 | CPU
DEBUG 01-07 10:14:15.446158.446158 lmp.py:767]   Expert 54 |     78 | CPU
DEBUG 01-07 10:14:15.446847.446847 lmp.py:767]   Expert 18 |     81 | CPU
DEBUG 01-07 10:14:15.446298.446298 lmp.py:767]   Expert 49 |     85 | CPU
DEBUG 01-07 10:14:15.446511.446511 lmp.py:767]   Expert 39 |     88 | CPU
DEBUG 01-07 10:14:15.446961.446961 lmp.py:767]   Expert 21 |    104 | CPU
DEBUG 01-07 10:14:15.446889.446889 lmp.py:767]   Expert  0 |    105 | CPU
DEBUG 01-07 10:14:15.446340.446340 lmp.py:767]   Expert 59 |    106 | CPU
DEBUG 01-07 10:14:15.446506.446506 lmp.py:767]   Expert 16 |    109 | CPU
DEBUG 01-07 10:14:15.446672.446672 lmp.py:767]   Expert 15 |    119 | CPU
DEBUG 01-07 10:14:15.446123.446123 lmp.py:767]   Expert 41 |    119 | CPU
DEBUG 01-07 10:14:15.446574.446574 lmp.py:767]   Expert 45 |    120 | CPU
DEBUG 01-07 10:14:15.446025.446025 lmp.py:767]   Expert 22 |    121 | CPU
DEBUG 01-07 10:14:15.446714.446714 lmp.py:767]   Expert 61 |    128 | CPU
DEBUG 01-07 10:14:15.446450.446450 lmp.py:767]   Expert 52 |    131 | CPU
DEBUG 01-07 10:14:15.447662.447662 lmp.py:767]   Expert 17 |    132 | CPU
DEBUG 01-07 10:14:15.447590.447590 lmp.py:767]   Expert  8 |    134 | CPU
DEBUG 01-07 10:14:15.447710.447710 lmp.py:767]   Expert 35 |    139 | GPU0(cuda:1)
DEBUG 01-07 10:14:15.447830.447830 lmp.py:767]   Expert 38 |    140 | GPU1(cuda:2)
DEBUG 01-07 10:14:15.447234.447234 lmp.py:767]   Expert 12 |    141 | GPU0(cuda:1)
DEBUG 01-07 10:14:15.447400.447400 lmp.py:767]   Expert 48 |    144 | GPU0(cuda:1)
DEBUG 01-07 10:14:15.447567.447567 lmp.py:767]   Expert 36 |    155 | GPU1(cuda:2)
DEBUG 01-07 10:14:15.447733.447733 lmp.py:767]   Expert 50 |    157 | GPU1(cuda:2)
DEBUG 01-07 10:14:15.447899.447899 lmp.py:767]   Expert 53 |    157 | GPU0(cuda:1)
DEBUG 01-07 10:14:15.447780.447780 lmp.py:767]   Expert 31 |    160 | GPU0(cuda:1)
DEBUG 01-07 10:14:15.447662.447662 lmp.py:767]   Expert 40 |    162 | GPU1(cuda:2)
DEBUG 01-07 10:14:15.447066.447066 lmp.py:767]   Expert 60 |    164 | GPU1(cuda:2)
DEBUG 01-07 10:14:15.447232.447232 lmp.py:767]   Expert 27 |    171 | GPU0(cuda:1)
DEBUG 01-07 10:14:15.447398.447398 lmp.py:767]   Expert 19 |    194 | GPU0(cuda:1)
DEBUG 01-07 10:14:15.447803.447803 lmp.py:767]   Expert  4 |    202 | GPU1(cuda:2)
DEBUG 01-07 10:14:15.447731.447731 lmp.py:767]   Expert 29 |    202 | GPU1(cuda:2)
DEBUG 01-07 10:14:15.447658.447658 lmp.py:767]   Expert 30 |    207 | GPU0(cuda:1)
DEBUG 01-07 10:14:15.447586.447586 lmp.py:767]   Expert 11 |    215 | GPU1(cuda:2)
DEBUG 01-07 10:14:15.447752.447752 lmp.py:767]   Expert 20 |    217 | GPU0(cuda:1)
DEBUG 01-07 10:14:15.447157.447157 lmp.py:767]   Expert 57 |    220 | GPU1(cuda:2)
DEBUG 01-07 10:14:15.447561.447561 lmp.py:767]   Expert 26 |    224 | GPU0(cuda:1)
DEBUG 01-07 10:14:15.447728.447728 lmp.py:767]   Expert 43 |    227 | GPU1(cuda:2)
DEBUG 01-07 10:14:15.447417.447417 lmp.py:767]   Expert  6 |    228 | GPU0(cuda:1)
DEBUG 01-07 10:14:15.447583.447583 lmp.py:767]   Expert 46 |    228 | GPU0(cuda:1)
DEBUG 01-07 10:14:15.447511.447511 lmp.py:767]   Expert 33 |    238 | GPU1(cuda:2)
DEBUG 01-07 10:14:15.447200.447200 lmp.py:767]   Expert 23 |    242 | GPU1(cuda:2)
DEBUG 01-07 10:14:15.447366.447366 lmp.py:767]   Expert 42 |    245 | GPU0(cuda:1)
DEBUG 01-07 10:14:15.447724.447724 lmp.py:767]   Expert  2 |    246 | GPU0(cuda:1)
DEBUG 01-07 10:14:15.447367.447367 lmp.py:767]   Expert 56 |    251 | GPU1(cuda:2)
DEBUG 01-07 10:14:15.447533.447533 lmp.py:767]   Expert 28 |    254 | GPU0(cuda:1)
DEBUG 01-07 10:14:15.447223.447223 lmp.py:767]   Expert 32 |    257 | GPU1(cuda:2)
DEBUG 01-07 10:14:15.447912.447912 lmp.py:767]   Expert 55 |    258 | GPU0(cuda:1)
DEBUG 01-07 10:14:15.447840.447840 lmp.py:767]   Expert  9 |    263 | GPU1(cuda:2)
DEBUG 01-07 10:14:15.447006.447006 lmp.py:767]   Expert  3 |    269 | GPU0(cuda:1)
DEBUG 01-07 10:14:15.447934.447934 lmp.py:767]   Expert 14 |    271 | GPU0(cuda:1)
DEBUG 01-07 10:14:15.447338.447338 lmp.py:767]   Expert 51 |    271 | GPU1(cuda:2)
DEBUG 01-07 10:14:15.447743.447743 lmp.py:767]   Expert  1 |    281 | GPU0(cuda:1)
DEBUG 01-07 10:14:15.447909.447909 lmp.py:767]   Expert 58 |    281 | GPU1(cuda:2)
DEBUG 01-07 10:14:15.447790.447790 lmp.py:767]   Expert 44 |    282 | GPU1(cuda:2)
DEBUG 01-07 10:14:15.447672.447672 lmp.py:767]   Expert 63 |    286 | GPU0(cuda:1)
DEBUG 01-07 10:14:15.447315.447315 lmp.py:767]   Expert 37 |    290 | GPU1(cuda:2)
DEBUG 01-07 10:14:15.447719.447719 lmp.py:767]   Expert 47 |    292 | GPU0(cuda:1)
DEBUG 01-07 10:14:15.447362.447362 lmp.py:767]   Expert 10 |    303 | GPU1(cuda:2)
DEBUG 01-07 10:14:15.447482.447482 lmp.py:767]   Expert 62 |    306 | GPU0(cuda:1)
DEBUG 01-07 10:14:15.447602.447602 lmp.py:767]   Expert 24 |    313 | GPU1(cuda:2)
DEBUG 01-07 10:14:15.447245.447245 lmp.py:767]   Expert 25 |    314 | GPU1(cuda:2)
DEBUG 01-07 10:14:15.447888.447888 lmp.py:767]   Expert  5 |    362 | GPU0(cuda:1)
DEBUG 01-07 10:14:15.447339.447339 lmp.py:769] 
DEBUG 01-07 10:14:15.447339.447339 lmp.py:769]   Device Token Distribution:
DEBUG 01-07 10:14:15.447220.447220 lmp.py:770]   CPU:   1859 tokens
DEBUG 01-07 10:14:15.447817.447817 lmp.py:774]   cuda:1:   5280 tokens (23 experts)
DEBUG 01-07 10:14:15.447652.447652 lmp.py:774]   cuda:2:   5149 tokens (22 experts)
DEBUG 01-07 10:14:15.447772.447772 lmp.py:775]   Total GPU:  10429 tokens
DEBUG 01-07 10:14:15.447222.447222 lmp.py:776] ============================================================
DEBUG 01-07 10:14:15.447222.447222 lmp.py:776] 
DEBUG 01-07 10:14:15.447587.447587 cuda_h.py:19] end experts_map_get cost 0.0017516613006591797 seconds
DEBUG 01-07 10:14:15.447946.447946 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model_multi_device
DEBUG 01-07 10:14:15.448007.448007 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 10:14:15.448832.448832 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 10:14:15.448515.448515 cuda_h.py:19] end allocate_cuda_memory cost 0.0001895427703857422 seconds
DEBUG 01-07 10:14:15.448478.448478 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 10:14:15.448711.448711 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 10:14:15.448804.448804 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 10:14:15.448507.448507 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 6ba01eb7-42d4-4e2b-83b8-905291ea1616
DEBUG 01-07 10:14:15.448334.448334 client.py:106] call stub.LoadModelAsync
INFO 01-07 10:14:15.448206.448206 client.py:127] Model loaded
DEBUG 01-07 10:14:15.449609.449609 cuda_h.py:19] end sllm_worker_task cost 0.008923530578613281 seconds
INFO 01-07 10:14:15.449420.449420 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 6ba01eb7-42d4-4e2b-83b8-905291ea1616
DEBUG 01-07 10:14:15.449694.449694 cuda_h.py:19] end load_into_gpu_async cost 0.001073598861694336 seconds
DEBUG 01-07 10:14:15.449443.449443 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 10:14:15.449969.449969 cuda_h.py:19] end restore_tensors2 cost 0.0002586841583251953 seconds
DEBUG 01-07 10:14:15.449838.449838 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0018534660339355469 seconds
DEBUG 01-07 10:14:15.451354.451354 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 10:14:15.451107.451107 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 10:14:15.452062.452062 cuda_h.py:19] end allocate_cuda_memory cost 0.0002105236053466797 seconds
DEBUG 01-07 10:14:15.452521.452521 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 10:14:15.452846.452846 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 10:14:15.452510.452510 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 10:14:15.452444.452444 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, be30bc49-bc86-4fae-95be-ef9c90b152d3
DEBUG 01-07 10:14:15.452826.452826 client.py:106] call stub.LoadModelAsync
INFO 01-07 10:14:15.453096.453096 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, be30bc49-bc86-4fae-95be-ef9c90b152d3
DEBUG 01-07 10:14:15.453257.453257 cuda_h.py:19] end load_into_gpu_async cost 0.0011780261993408203 seconds
DEBUG 01-07 10:14:15.453145.453145 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 10:14:15.453869.453869 cuda_h.py:19] end restore_tensors2 cost 0.00022864341735839844 seconds
DEBUG 01-07 10:14:15.453115.453115 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0019125938415527344 seconds
DEBUG 01-07 10:14:15.455705.455705 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model_multi_device cost 0.007626771926879883 seconds
DEBUG 01-07 10:14:15.455859.455859 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-07 10:14:15.455206.455206 lmp.py:816] 
DEBUG 01-07 10:14:15.455206.455206 lmp.py:816]   Computing 19 experts on CPU...
DEBUG 01-07 10:14:15.455665.455665 cuda_h.py:19] end cpu_experts_submit cost 0.00011038780212402344 seconds
DEBUG 01-07 10:14:15.455361.455361 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-07 10:14:15.461891.461891 mlpmodule.py:749] group tensors cost 0.0054171085357666016 s
DEBUG 01-07 10:14:15.463347.463347 mlpmodule.py:787] pad cost 0.0012362003326416016 s
DEBUG 01-07 10:14:15.463504.463504 mlpmodule.py:793] create cpu tensor cost 4.7206878662109375e-05 s
DEBUG 01-07 10:14:15.463334.463334 mlpmodule.py:798] move to cpu cost 3.7670135498046875e-05 s
DEBUG 01-07 10:14:15.470012.470012 mlpmodule.py:812] group_w3: shape=torch.Size([19, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=54788096
DEBUG 01-07 10:14:15.470456.470456 mlpmodule.py:813] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-07 10:14:15.470459.470459 mlpmodule.py:818] group_w3 first element: 0.000789642333984375
WARNING 01-07 10:14:15.470113.470113 mlpmodule.py:828] start einsum2
DEBUG 01-07 10:14:15.481209.481209 mlpmodule.py:838] group einsum cost 0.018116235733032227 s
DEBUG 01-07 10:14:15.482992.482992 mlpmodule.py:846] cpy2cputensor cost 0.0004420280456542969 s
DEBUG 01-07 10:14:15.485256.485256 cuda_h.py:19] end wait_cetm_experts cost 0.02926802635192871 seconds
DEBUG 01-07 10:14:15.485776.485776 cuda_h.py:10] start gpu_sexperts
DEBUG 01-07 10:14:15.485504.485504 cuda_h.py:19] end gpu_sexperts cost 0.0005242824554443359 seconds
DEBUG 01-07 10:14:15.485215.485215 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-07 10:14:15.485826.485826 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.5510787963867188e-05 seconds
DEBUG 01-07 10:14:15.485728.485728 cuda_h.py:10] start wait_experts_multi_device
INFO 01-07 10:14:15.485107.485107 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 6ba01eb7-42d4-4e2b-83b8-905291ea1616
INFO 01-07 10:14:15.492676.492676 client.py:127] Model loaded
INFO 01-07 10:14:15.492572.492572 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, be30bc49-bc86-4fae-95be-ef9c90b152d3
DEBUG 01-07 10:14:15.493160.493160 mlpmodule.py:707]  experts func einsum cost 0.03758120536804199 s
INFO 01-07 10:14:15.494550.494550 client.py:127] Model loaded
DEBUG 01-07 10:14:15.494923.494923 cuda_h.py:19] end wait_experts_multi_device cost 0.00896000862121582 seconds
DEBUG 01-07 10:14:15.494964.494964 cuda_h.py:10] start gpu_experts_multi_device
DEBUG 01-07 10:14:15.495694.495694 lmp.py:867]   Computing 22 experts on cuda:2...
DEBUG 01-07 10:14:15.496517.496517 mlpmodule.py:533] gpu group tensors cost 0.0004887580871582031 s
DEBUG 01-07 10:14:15.497100.497100 mlpmodule.py:566] gpu pad cost 0.0011415481567382812 s
DEBUG 01-07 10:14:15.498458.498458 mlpmodule.py:584] gpu group einsum cost 0.0005056858062744141 s
DEBUG 01-07 10:14:15.499765.499765 mlpmodule.py:656] gpu experts func einsum cost 0.003938913345336914 s
DEBUG 01-07 10:14:15.499761.499761 lmp.py:867]   Computing 23 experts on cuda:1...
DEBUG 01-07 10:14:15.500671.500671 mlpmodule.py:533] gpu group tensors cost 0.0003991127014160156 s
DEBUG 01-07 10:14:15.501708.501708 mlpmodule.py:566] gpu pad cost 0.0010628700256347656 s
DEBUG 01-07 10:14:15.502903.502903 mlpmodule.py:584] gpu group einsum cost 0.0003948211669921875 s
DEBUG 01-07 10:14:15.503237.503237 mlpmodule.py:656] gpu experts func einsum cost 0.0036606788635253906 s
DEBUG 01-07 10:14:15.504194.504194 cuda_h.py:19] end gpu_experts_multi_device cost 0.009025096893310547 seconds
DEBUG 01-07 10:14:15.504065.504065 cuda_h.py:19] end layer_moe_generate_multi_device_14 cost 0.058693647384643555 seconds
DEBUG 01-07 10:14:15.504152.504152 lmp.py:194] -------------------------------- end prefill layer 14 --------------------------------
DEBUG 01-07 10:14:15.504260.504260 lmp.py:153] -------------------------------- start prefill layer 15 --------------------------------
DEBUG 01-07 10:14:15.504148.504148 cuda_h.py:10] start start_load_qkvogn_s_weight_l_16
DEBUG 01-07 10:14:15.504950.504950 cuda_h.py:10] start start_load_qkvogn_s_weight_l_16
DEBUG 01-07 10:14:15.504786.504786 cuda_h.py:19] end start_load_qkvogn_s_weight_l_16 cost 2.8371810913085938e-05 seconds
DEBUG 01-07 10:14:15.504820.504820 cuda_h.py:19] end start_load_qkvogn_s_weight_l_16 cost 5.817413330078125e-05 seconds
DEBUG 01-07 10:14:15.504655.504655 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-07 10:14:15.504670.504670 cuda_h.py:10] start sllm_worker_task
DEBUG 01-07 10:14:15.504050.504050 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 10:14:15.504979.504979 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 10:14:15.505095.505095 cuda_h.py:19] end allocate_cuda_memory cost 0.00026226043701171875 seconds
DEBUG 01-07 10:14:15.505826.505826 mlpmodule.py:367] cuda:1 cuda:1
DEBUG 01-07 10:14:15.505940.505940 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 10:14:15.505507.505507 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 10:14:15.505091.505091 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 10:14:15.505125.505125 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 3028abe2-2b61-48d6-abdd-789e770ade61
DEBUG 01-07 10:14:15.505558.505558 client.py:106] call stub.LoadModelAsync
DEBUG 01-07 10:14:15.505640.505640 cuda_h.py:10] start self_attn
INFO 01-07 10:14:15.506993.506993 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 3028abe2-2b61-48d6-abdd-789e770ade61
DEBUG 01-07 10:14:15.506584.506584 cuda_h.py:19] end load_into_gpu_async cost 0.0009357929229736328 seconds
DEBUG 01-07 10:14:15.506711.506711 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 10:14:15.506071.506071 cuda_h.py:19] end restore_tensors2 cost 6.532669067382812e-05 seconds
DEBUG 01-07 10:14:15.506635.506635 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0016281604766845703 seconds
INFO 01-07 10:14:15.506511.506511 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 3028abe2-2b61-48d6-abdd-789e770ade61
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-07 10:14:15.509941.509941 cuda_h.py:19] end self_attn cost 0.0036025047302246094 seconds
DEBUG 01-07 10:14:15.509633.509633 cuda_h.py:19] end iln_self_attn_paln cost 0.005046844482421875 seconds
DEBUG 01-07 10:14:15.509655.509655 cuda_h.py:10] start layer_moe_generate_multi_device_15
DEBUG 01-07 10:14:15.509272.509272 cuda_h.py:10] start gate
DEBUG 01-07 10:14:15.510897.510897 cuda_h.py:19] end gate cost 0.0006377696990966797 seconds
DEBUG 01-07 10:14:15.510488.510488 cuda_h.py:10] start experts_map_get
DEBUG 01-07 10:14:15.510501.510501 lmp.py:744] 
DEBUG 01-07 10:14:15.510501.510501 lmp.py:744] Expert Token Distribution & Multi-Device Allocation:
DEBUG 01-07 10:14:15.510602.510602 lmp.py:745]   Total experts: 64
DEBUG 01-07 10:14:15.510682.510682 lmp.py:746]   CPU experts: 19 (30%)
DEBUG 01-07 10:14:15.510948.510948 lmp.py:747]   GPU experts: 45 (70%)
DEBUG 01-07 10:14:15.510352.510352 lmp.py:748]   Number of GPU devices: 2
DEBUG 01-07 10:14:15.510803.510803 lmp.py:749] 
DEBUG 01-07 10:14:15.510803.510803 lmp.py:749]   Expert ID | Tokens | Device
DEBUG 01-07 10:14:15.510969.510969 lmp.py:750]   -----------------------------------
DEBUG 01-07 10:14:15.510811.510811 lmp.py:767]   Expert 15 |     63 | CPU
DEBUG 01-07 10:14:15.511216.511216 lmp.py:767]   Expert 41 |     70 | CPU
DEBUG 01-07 10:14:15.511097.511097 lmp.py:767]   Expert 63 |     74 | CPU
DEBUG 01-07 10:14:15.511217.511217 lmp.py:767]   Expert  0 |     78 | CPU
DEBUG 01-07 10:14:15.511622.511622 lmp.py:767]   Expert 20 |     82 | CPU
DEBUG 01-07 10:14:15.511834.511834 lmp.py:767]   Expert  7 |     90 | CPU
DEBUG 01-07 10:14:15.511285.511285 lmp.py:767]   Expert 28 |     91 | CPU
DEBUG 01-07 10:14:15.511497.511497 lmp.py:767]   Expert 45 |     93 | CPU
DEBUG 01-07 10:14:15.511471.511471 lmp.py:767]   Expert 12 |    108 | CPU
DEBUG 01-07 10:14:15.511922.511922 lmp.py:767]   Expert 54 |    108 | CPU
DEBUG 01-07 10:14:15.511135.511135 lmp.py:767]   Expert 40 |    120 | CPU
DEBUG 01-07 10:14:15.511347.511347 lmp.py:767]   Expert 52 |    120 | CPU
DEBUG 01-07 10:14:15.511275.511275 lmp.py:767]   Expert 59 |    126 | CPU
DEBUG 01-07 10:14:15.511203.511203 lmp.py:767]   Expert  5 |    128 | CPU
DEBUG 01-07 10:14:15.511654.511654 lmp.py:767]   Expert 34 |    129 | CPU
DEBUG 01-07 10:14:15.511866.511866 lmp.py:767]   Expert  4 |    130 | CPU
DEBUG 01-07 10:14:15.511840.511840 lmp.py:767]   Expert 62 |    130 | CPU
DEBUG 01-07 10:14:15.511814.511814 lmp.py:767]   Expert 13 |    136 | CPU
DEBUG 01-07 10:14:15.511027.511027 lmp.py:767]   Expert 61 |    138 | CPU
DEBUG 01-07 10:14:15.511908.511908 lmp.py:767]   Expert 21 |    141 | GPU0(cuda:1)
DEBUG 01-07 10:14:15.511313.511313 lmp.py:767]   Expert 55 |    141 | GPU1(cuda:2)
DEBUG 01-07 10:14:15.511194.511194 lmp.py:767]   Expert 42 |    142 | GPU1(cuda:2)
DEBUG 01-07 10:14:15.511075.511075 lmp.py:767]   Expert 14 |    146 | GPU0(cuda:1)
DEBUG 01-07 10:14:15.511480.511480 lmp.py:767]   Expert 22 |    147 | GPU1(cuda:2)
DEBUG 01-07 10:14:15.511169.511169 lmp.py:767]   Expert 10 |    149 | GPU0(cuda:1)
DEBUG 01-07 10:14:15.511097.511097 lmp.py:767]   Expert 51 |    154 | GPU1(cuda:2)
DEBUG 01-07 10:14:15.511501.511501 lmp.py:767]   Expert 32 |    158 | GPU0(cuda:1)
DEBUG 01-07 10:14:15.511668.511668 lmp.py:767]   Expert 25 |    161 | GPU1(cuda:2)
DEBUG 01-07 10:14:15.511595.511595 lmp.py:767]   Expert 50 |    168 | GPU0(cuda:1)
DEBUG 01-07 10:14:15.511761.511761 lmp.py:767]   Expert 53 |    174 | GPU1(cuda:2)
DEBUG 01-07 10:14:15.511689.511689 lmp.py:767]   Expert 19 |    175 | GPU0(cuda:1)
DEBUG 01-07 10:14:15.511332.511332 lmp.py:767]   Expert 26 |    177 | GPU1(cuda:2)
DEBUG 01-07 10:14:15.511975.511975 lmp.py:767]   Expert 47 |    178 | GPU0(cuda:1)
DEBUG 01-07 10:14:15.511856.511856 lmp.py:767]   Expert  1 |    179 | GPU1(cuda:2)
DEBUG 01-07 10:14:15.511738.511738 lmp.py:767]   Expert  6 |    180 | GPU0(cuda:1)
DEBUG 01-07 10:14:15.511142.511142 lmp.py:767]   Expert  2 |    182 | GPU0(cuda:1)
DEBUG 01-07 10:14:15.511024.511024 lmp.py:767]   Expert 35 |    182 | GPU1(cuda:2)
DEBUG 01-07 10:14:15.511190.511190 lmp.py:767]   Expert 30 |    185 | GPU1(cuda:2)
DEBUG 01-07 10:14:15.511356.511356 lmp.py:767]   Expert 57 |    188 | GPU0(cuda:1)
DEBUG 01-07 10:14:15.511284.511284 lmp.py:767]   Expert 56 |    190 | GPU1(cuda:2)
DEBUG 01-07 10:14:15.511973.511973 lmp.py:767]   Expert 11 |    192 | GPU0(cuda:1)
DEBUG 01-07 10:14:15.511139.511139 lmp.py:767]   Expert 48 |    204 | GPU1(cuda:2)
DEBUG 01-07 10:14:15.511067.511067 lmp.py:767]   Expert 44 |    210 | GPU0(cuda:1)
DEBUG 01-07 10:14:15.511233.511233 lmp.py:767]   Expert 24 |    212 | GPU1(cuda:2)
DEBUG 01-07 10:14:15.511115.511115 lmp.py:767]   Expert 16 |    214 | GPU0(cuda:1)
DEBUG 01-07 10:14:15.511519.511519 lmp.py:767]   Expert 46 |    220 | GPU1(cuda:2)
DEBUG 01-07 10:14:15.511447.511447 lmp.py:767]   Expert 18 |    228 | GPU0(cuda:1)
DEBUG 01-07 10:14:15.511375.511375 lmp.py:767]   Expert 39 |    229 | GPU1(cuda:2)
DEBUG 01-07 10:14:15.511302.511302 lmp.py:767]   Expert 29 |    231 | GPU0(cuda:1)
DEBUG 01-07 10:14:15.511230.511230 lmp.py:767]   Expert 37 |    235 | GPU1(cuda:2)
DEBUG 01-07 10:14:15.511919.511919 lmp.py:767]   Expert 31 |    252 | GPU0(cuda:1)
DEBUG 01-07 10:14:15.511085.511085 lmp.py:767]   Expert  3 |    256 | GPU1(cuda:2)
DEBUG 01-07 10:14:15.511728.511728 lmp.py:767]   Expert 36 |    257 | GPU1(cuda:2)
DEBUG 01-07 10:14:15.511371.511371 lmp.py:767]   Expert 60 |    257 | GPU0(cuda:1)
DEBUG 01-07 10:14:15.511537.511537 lmp.py:767]   Expert 38 |    260 | GPU0(cuda:1)
DEBUG 01-07 10:14:15.511657.511657 lmp.py:767]   Expert  9 |    264 | GPU1(cuda:2)
DEBUG 01-07 10:14:15.511539.511539 lmp.py:767]   Expert 17 |    267 | GPU0(cuda:1)
DEBUG 01-07 10:14:15.511658.511658 lmp.py:767]   Expert 23 |    275 | GPU1(cuda:2)
DEBUG 01-07 10:14:15.511778.511778 lmp.py:767]   Expert 27 |    350 | GPU0(cuda:1)
DEBUG 01-07 10:14:15.512137.512137 lmp.py:767]   Expert 43 |    358 | GPU1(cuda:2)
DEBUG 01-07 10:14:15.512733.512733 lmp.py:767]   Expert 33 |    403 | GPU0(cuda:1)
DEBUG 01-07 10:14:15.512568.512568 lmp.py:767]   Expert  8 |    409 | GPU1(cuda:2)
DEBUG 01-07 10:14:15.512688.512688 lmp.py:767]   Expert 58 |    445 | GPU1(cuda:2)
DEBUG 01-07 10:14:15.512331.512331 lmp.py:767]   Expert 49 |    549 | GPU0(cuda:1)
DEBUG 01-07 10:14:15.512259.512259 lmp.py:769] 
DEBUG 01-07 10:14:15.512259.512259 lmp.py:769]   Device Token Distribution:
DEBUG 01-07 10:14:15.512140.512140 lmp.py:770]   CPU:   2014 tokens
DEBUG 01-07 10:14:15.512498.512498 lmp.py:774]   cuda:1:   5078 tokens (22 experts)
DEBUG 01-07 10:14:15.512380.512380 lmp.py:774]   cuda:2:   5196 tokens (23 experts)
DEBUG 01-07 10:14:15.512261.512261 lmp.py:775]   Total GPU:  10274 tokens
DEBUG 01-07 10:14:15.512189.512189 lmp.py:776] ============================================================
DEBUG 01-07 10:14:15.512189.512189 lmp.py:776] 
DEBUG 01-07 10:14:15.512792.512792 cuda_h.py:19] end experts_map_get cost 0.0017404556274414062 seconds
DEBUG 01-07 10:14:15.512389.512389 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model_multi_device
DEBUG 01-07 10:14:15.512689.512689 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 10:14:15.512951.512951 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 10:14:15.512100.512100 cuda_h.py:19] end allocate_cuda_memory cost 0.00025010108947753906 seconds
DEBUG 01-07 10:14:15.512579.512579 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 10:14:15.512719.512719 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 10:14:15.512528.512528 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 10:14:15.512330.512330 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 44222818-d6e9-4d13-a6f0-4d26045450d1
DEBUG 01-07 10:14:15.513879.513879 client.py:106] call stub.LoadModelAsync
INFO 01-07 10:14:15.513023.513023 client.py:127] Model loaded
DEBUG 01-07 10:14:15.513988.513988 cuda_h.py:19] end sllm_worker_task cost 0.00883936882019043 seconds
INFO 01-07 10:14:15.513359.513359 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 44222818-d6e9-4d13-a6f0-4d26045450d1
DEBUG 01-07 10:14:15.513632.513632 cuda_h.py:19] end load_into_gpu_async cost 0.0011622905731201172 seconds
DEBUG 01-07 10:14:15.513335.513335 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 10:14:15.514901.514901 cuda_h.py:19] end restore_tensors2 cost 0.00025177001953125 seconds
DEBUG 01-07 10:14:15.514385.514385 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.002000570297241211 seconds
DEBUG 01-07 10:14:15.516407.516407 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 10:14:15.516153.516153 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 10:14:15.516407.516407 cuda_h.py:19] end allocate_cuda_memory cost 0.00021910667419433594 seconds
DEBUG 01-07 10:14:15.516535.516535 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 10:14:15.516576.516576 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 10:14:15.516285.516285 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 10:14:15.516981.516981 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 74134aeb-ef6f-4837-9384-eb9ee92396de
DEBUG 01-07 10:14:15.516973.516973 client.py:106] call stub.LoadModelAsync
INFO 01-07 10:14:15.517371.517371 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 74134aeb-ef6f-4837-9384-eb9ee92396de
DEBUG 01-07 10:14:15.517009.517009 cuda_h.py:19] end load_into_gpu_async cost 0.0012655258178710938 seconds
DEBUG 01-07 10:14:15.517327.517327 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 10:14:15.518840.518840 cuda_h.py:19] end restore_tensors2 cost 0.00024700164794921875 seconds
DEBUG 01-07 10:14:15.518278.518278 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0020334720611572266 seconds
DEBUG 01-07 10:14:15.520574.520574 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model_multi_device cost 0.007867574691772461 seconds
DEBUG 01-07 10:14:15.520112.520112 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-07 10:14:15.520982.520982 lmp.py:816] 
DEBUG 01-07 10:14:15.520982.520982 lmp.py:816]   Computing 19 experts on CPU...
DEBUG 01-07 10:14:15.520964.520964 cuda_h.py:19] end cpu_experts_submit cost 0.00010848045349121094 seconds
DEBUG 01-07 10:14:15.520137.520137 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-07 10:14:15.526904.526904 mlpmodule.py:749] group tensors cost 0.005543231964111328 s
DEBUG 01-07 10:14:15.528361.528361 mlpmodule.py:787] pad cost 0.0017445087432861328 s
DEBUG 01-07 10:14:15.528949.528949 mlpmodule.py:793] create cpu tensor cost 6.175041198730469e-05 s
DEBUG 01-07 10:14:15.528191.528191 mlpmodule.py:798] move to cpu cost 4.57763671875e-05 s
DEBUG 01-07 10:14:15.535032.535032 mlpmodule.py:812] group_w3: shape=torch.Size([19, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=54788096
DEBUG 01-07 10:14:15.535753.535753 mlpmodule.py:813] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-07 10:14:15.536763.536763 mlpmodule.py:818] group_w3 first element: -0.0595703125
WARNING 01-07 10:14:15.536271.536271 mlpmodule.py:828] start einsum2
DEBUG 01-07 10:14:15.547788.547788 mlpmodule.py:838] group einsum cost 0.018529415130615234 s
DEBUG 01-07 10:14:15.548155.548155 mlpmodule.py:846] cpy2cputensor cost 0.00043511390686035156 s
DEBUG 01-07 10:14:15.550144.550144 cuda_h.py:19] end wait_cetm_experts cost 0.03043508529663086 seconds
DEBUG 01-07 10:14:15.550227.550227 cuda_h.py:10] start gpu_sexperts
DEBUG 01-07 10:14:15.551988.551988 cuda_h.py:19] end gpu_sexperts cost 0.0005156993865966797 seconds
DEBUG 01-07 10:14:15.551659.551659 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-07 10:14:15.551986.551986 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.6226043701171875e-05 seconds
DEBUG 01-07 10:14:15.551165.551165 cuda_h.py:10] start wait_experts_multi_device
INFO 01-07 10:14:15.551789.551789 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 44222818-d6e9-4d13-a6f0-4d26045450d1
INFO 01-07 10:14:15.555656.555656 client.py:127] Model loaded
INFO 01-07 10:14:15.556168.556168 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 74134aeb-ef6f-4837-9384-eb9ee92396de
DEBUG 01-07 10:14:15.559769.559769 mlpmodule.py:707]  experts func einsum cost 0.03871321678161621 s
INFO 01-07 10:14:15.560105.560105 client.py:127] Model loaded
DEBUG 01-07 10:14:15.560723.560723 cuda_h.py:19] end wait_experts_multi_device cost 0.00929403305053711 seconds
DEBUG 01-07 10:14:15.560194.560194 cuda_h.py:10] start gpu_experts_multi_device
DEBUG 01-07 10:14:15.561163.561163 lmp.py:867]   Computing 23 experts on cuda:2...
DEBUG 01-07 10:14:15.562553.562553 mlpmodule.py:533] gpu group tensors cost 0.0004999637603759766 s
DEBUG 01-07 10:14:15.563917.563917 mlpmodule.py:566] gpu pad cost 0.0011191368103027344 s
DEBUG 01-07 10:14:15.563730.563730 mlpmodule.py:584] gpu group einsum cost 0.0005042552947998047 s
DEBUG 01-07 10:14:15.565333.565333 mlpmodule.py:656] gpu experts func einsum cost 0.004026889801025391 s
DEBUG 01-07 10:14:15.566819.566819 lmp.py:867]   Computing 22 experts on cuda:1...
DEBUG 01-07 10:14:15.566774.566774 mlpmodule.py:533] gpu group tensors cost 0.0003726482391357422 s
DEBUG 01-07 10:14:15.567061.567061 mlpmodule.py:566] gpu pad cost 0.0010027885437011719 s
DEBUG 01-07 10:14:15.568858.568858 mlpmodule.py:584] gpu group einsum cost 0.0003871917724609375 s
DEBUG 01-07 10:14:15.569363.569363 mlpmodule.py:656] gpu experts func einsum cost 0.003510713577270508 s
DEBUG 01-07 10:14:15.569591.569591 cuda_h.py:19] end gpu_experts_multi_device cost 0.008866310119628906 seconds
DEBUG 01-07 10:14:15.569773.569773 cuda_h.py:19] end layer_moe_generate_multi_device_15 cost 0.06027507781982422 seconds
DEBUG 01-07 10:14:15.570815.570815 lmp.py:194] -------------------------------- end prefill layer 15 --------------------------------
DEBUG 01-07 10:14:15.570690.570690 lmp.py:153] -------------------------------- start prefill layer 16 --------------------------------
DEBUG 01-07 10:14:15.570910.570910 cuda_h.py:10] start start_load_qkvogn_s_weight_l_17
DEBUG 01-07 10:14:15.570427.570427 cuda_h.py:10] start start_load_qkvogn_s_weight_l_17
DEBUG 01-07 10:14:15.570548.570548 cuda_h.py:19] end start_load_qkvogn_s_weight_l_17 cost 2.8371810913085938e-05 seconds
DEBUG 01-07 10:14:15.570059.570059 cuda_h.py:19] end start_load_qkvogn_s_weight_l_17 cost 5.841255187988281e-05 seconds
DEBUG 01-07 10:14:15.570371.570371 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-07 10:14:15.570902.570902 cuda_h.py:10] start sllm_worker_task
DEBUG 01-07 10:14:15.570819.570819 mlpmodule.py:367] cuda:1 cuda:1
DEBUG 01-07 10:14:15.570775.570775 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 10:14:15.570500.570500 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 10:14:15.571146.571146 cuda_h.py:19] end allocate_cuda_memory cost 0.0002644062042236328 seconds
DEBUG 01-07 10:14:15.571255.571255 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 10:14:15.571633.571633 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 10:14:15.571072.571072 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 10:14:15.571867.571867 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 7af67018-8039-4b9d-b0f3-2eaa4179290e
DEBUG 01-07 10:14:15.571731.571731 client.py:106] call stub.LoadModelAsync
DEBUG 01-07 10:14:15.571402.571402 cuda_h.py:10] start self_attn
INFO 01-07 10:14:15.572298.572298 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 7af67018-8039-4b9d-b0f3-2eaa4179290e
DEBUG 01-07 10:14:15.572188.572188 cuda_h.py:19] end load_into_gpu_async cost 0.001321554183959961 seconds
DEBUG 01-07 10:14:15.572506.572506 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 10:14:15.572105.572105 cuda_h.py:19] end restore_tensors2 cost 6.556510925292969e-05 seconds
DEBUG 01-07 10:14:15.572192.572192 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0019009113311767578 seconds
INFO 01-07 10:14:15.572420.572420 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 7af67018-8039-4b9d-b0f3-2eaa4179290e
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-07 10:14:15.575052.575052 cuda_h.py:19] end self_attn cost 0.003543853759765625 seconds
DEBUG 01-07 10:14:15.575612.575612 cuda_h.py:19] end iln_self_attn_paln cost 0.0049364566802978516 seconds
DEBUG 01-07 10:14:15.575534.575534 cuda_h.py:10] start layer_moe_generate_multi_device_16
DEBUG 01-07 10:14:15.575959.575959 cuda_h.py:10] start gate
DEBUG 01-07 10:14:15.576527.576527 cuda_h.py:19] end gate cost 0.0007004737854003906 seconds
DEBUG 01-07 10:14:15.576356.576356 cuda_h.py:10] start experts_map_get
DEBUG 01-07 10:14:15.576946.576946 lmp.py:744] 
DEBUG 01-07 10:14:15.576946.576946 lmp.py:744] Expert Token Distribution & Multi-Device Allocation:
DEBUG 01-07 10:14:15.576086.576086 lmp.py:745]   Total experts: 64
DEBUG 01-07 10:14:15.576928.576928 lmp.py:746]   CPU experts: 19 (30%)
DEBUG 01-07 10:14:15.576478.576478 lmp.py:747]   GPU experts: 45 (70%)
DEBUG 01-07 10:14:15.576836.576836 lmp.py:748]   Number of GPU devices: 2
DEBUG 01-07 10:14:15.576049.576049 lmp.py:749] 
DEBUG 01-07 10:14:15.576049.576049 lmp.py:749]   Expert ID | Tokens | Device
DEBUG 01-07 10:14:15.576169.576169 lmp.py:750]   -----------------------------------
DEBUG 01-07 10:14:15.576295.576295 lmp.py:767]   Expert 58 |     31 | CPU
DEBUG 01-07 10:14:15.576461.576461 lmp.py:767]   Expert 47 |     54 | CPU
DEBUG 01-07 10:14:15.576912.576912 lmp.py:767]   Expert 31 |     63 | CPU
DEBUG 01-07 10:14:15.576363.576363 lmp.py:767]   Expert 49 |     63 | CPU
DEBUG 01-07 10:14:15.576337.576337 lmp.py:767]   Expert  4 |     65 | CPU
DEBUG 01-07 10:14:15.576026.576026 lmp.py:767]   Expert 38 |     68 | CPU
DEBUG 01-07 10:14:15.576477.576477 lmp.py:767]   Expert 45 |     69 | CPU
DEBUG 01-07 10:14:15.576451.576451 lmp.py:767]   Expert 43 |     73 | CPU
DEBUG 01-07 10:14:15.577141.577141 lmp.py:767]   Expert 41 |     82 | CPU
DEBUG 01-07 10:14:15.577545.577545 lmp.py:767]   Expert 33 |    100 | CPU
DEBUG 01-07 10:14:15.577142.577142 lmp.py:767]   Expert 50 |    102 | CPU
DEBUG 01-07 10:14:15.577023.577023 lmp.py:767]   Expert 11 |    104 | CPU
DEBUG 01-07 10:14:15.577666.577666 lmp.py:767]   Expert 57 |    106 | CPU
DEBUG 01-07 10:14:15.577832.577832 lmp.py:767]   Expert 51 |    110 | CPU
DEBUG 01-07 10:14:15.577760.577760 lmp.py:767]   Expert  2 |    113 | CPU
DEBUG 01-07 10:14:15.577449.577449 lmp.py:767]   Expert 14 |    118 | CPU
DEBUG 01-07 10:14:15.577139.577139 lmp.py:767]   Expert  0 |    125 | CPU
DEBUG 01-07 10:14:15.577305.577305 lmp.py:767]   Expert 54 |    131 | CPU
DEBUG 01-07 10:14:15.577233.577233 lmp.py:767]   Expert 56 |    137 | CPU
DEBUG 01-07 10:14:15.577591.577591 lmp.py:767]   Expert 26 |    141 | GPU1(cuda:2)
DEBUG 01-07 10:14:15.577664.577664 lmp.py:767]   Expert 34 |    141 | GPU1(cuda:2)
DEBUG 01-07 10:14:15.577261.577261 lmp.py:767]   Expert 27 |    150 | GPU0(cuda:1)
DEBUG 01-07 10:14:15.577096.577096 lmp.py:767]   Expert 28 |    158 | GPU1(cuda:2)
DEBUG 01-07 10:14:15.577454.577454 lmp.py:767]   Expert 55 |    159 | GPU0(cuda:1)
DEBUG 01-07 10:14:15.577097.577097 lmp.py:767]   Expert 25 |    162 | GPU0(cuda:1)
DEBUG 01-07 10:14:15.577979.577979 lmp.py:767]   Expert 10 |    167 | GPU1(cuda:2)
DEBUG 01-07 10:14:15.577383.577383 lmp.py:767]   Expert 13 |    177 | GPU0(cuda:1)
DEBUG 01-07 10:14:15.577265.577265 lmp.py:767]   Expert  9 |    181 | GPU1(cuda:2)
DEBUG 01-07 10:14:15.577669.577669 lmp.py:767]   Expert 61 |    185 | GPU0(cuda:1)
DEBUG 01-07 10:14:15.577312.577312 lmp.py:767]   Expert 48 |    188 | GPU1(cuda:2)
DEBUG 01-07 10:14:15.577717.577717 lmp.py:767]   Expert  7 |    194 | GPU0(cuda:1)
DEBUG 01-07 10:14:15.577836.577836 lmp.py:767]   Expert  6 |    196 | GPU1(cuda:2)
DEBUG 01-07 10:14:15.577003.577003 lmp.py:767]   Expert 46 |    197 | GPU0(cuda:1)
DEBUG 01-07 10:14:15.577122.577122 lmp.py:767]   Expert 24 |    200 | GPU1(cuda:2)
DEBUG 01-07 10:14:15.577481.577481 lmp.py:767]   Expert 42 |    203 | GPU0(cuda:1)
DEBUG 01-07 10:14:15.577600.577600 lmp.py:767]   Expert 18 |    204 | GPU1(cuda:2)
DEBUG 01-07 10:14:15.577197.577197 lmp.py:767]   Expert 40 |    215 | GPU1(cuda:2)
DEBUG 01-07 10:14:15.577840.577840 lmp.py:767]   Expert 59 |    215 | GPU0(cuda:1)
DEBUG 01-07 10:14:15.577483.577483 lmp.py:767]   Expert 21 |    216 | GPU0(cuda:1)
DEBUG 01-07 10:14:15.577126.577126 lmp.py:767]   Expert 29 |    217 | GPU1(cuda:2)
DEBUG 01-07 10:14:15.577292.577292 lmp.py:767]   Expert 63 |    218 | GPU0(cuda:1)
DEBUG 01-07 10:14:15.577697.577697 lmp.py:767]   Expert 12 |    220 | GPU0(cuda:1)
DEBUG 01-07 10:14:15.577578.577578 lmp.py:767]   Expert 22 |    220 | GPU1(cuda:2)
DEBUG 01-07 10:14:15.577506.577506 lmp.py:767]   Expert 19 |    226 | GPU1(cuda:2)
DEBUG 01-07 10:14:15.577387.577387 lmp.py:767]   Expert 32 |    228 | GPU0(cuda:1)
DEBUG 01-07 10:14:15.577984.577984 lmp.py:767]   Expert 36 |    234 | GPU1(cuda:2)
DEBUG 01-07 10:14:15.577819.577819 lmp.py:767]   Expert  3 |    240 | GPU0(cuda:1)
DEBUG 01-07 10:14:15.577939.577939 lmp.py:767]   Expert 37 |    248 | GPU1(cuda:2)
DEBUG 01-07 10:14:15.577582.577582 lmp.py:767]   Expert  1 |    253 | GPU0(cuda:1)
DEBUG 01-07 10:14:15.577225.577225 lmp.py:767]   Expert 16 |    254 | GPU1(cuda:2)
DEBUG 01-07 10:14:15.577629.577629 lmp.py:767]   Expert  5 |    261 | GPU0(cuda:1)
DEBUG 01-07 10:14:15.577272.577272 lmp.py:767]   Expert 20 |    263 | GPU1(cuda:2)
DEBUG 01-07 10:14:15.577438.577438 lmp.py:767]   Expert 30 |    267 | GPU0(cuda:1)
DEBUG 01-07 10:14:15.577320.577320 lmp.py:767]   Expert 62 |    270 | GPU1(cuda:2)
DEBUG 01-07 10:14:15.577201.577201 lmp.py:767]   Expert  8 |    272 | GPU0(cuda:1)
DEBUG 01-07 10:14:15.577559.577559 lmp.py:767]   Expert 15 |    274 | GPU1(cuda:2)
DEBUG 01-07 10:14:15.577441.577441 lmp.py:767]   Expert 39 |    298 | GPU0(cuda:1)
DEBUG 01-07 10:14:15.577037.577037 lmp.py:767]   Expert 35 |    299 | GPU1(cuda:2)
DEBUG 01-07 10:14:15.577634.577634 lmp.py:767]   Expert 17 |    310 | GPU0(cuda:1)
DEBUG 01-07 10:14:15.577277.577277 lmp.py:767]   Expert 60 |    317 | GPU1(cuda:2)
DEBUG 01-07 10:14:15.577682.577682 lmp.py:767]   Expert 52 |    353 | GPU0(cuda:1)
DEBUG 01-07 10:14:15.577848.577848 lmp.py:767]   Expert 23 |    364 | GPU1(cuda:2)
DEBUG 01-07 10:14:15.577252.577252 lmp.py:767]   Expert 44 |    377 | GPU1(cuda:2)
DEBUG 01-07 10:14:15.577418.577418 lmp.py:767]   Expert 53 |    442 | GPU0(cuda:1)
DEBUG 01-07 10:14:15.577631.577631 lmp.py:769] 
DEBUG 01-07 10:14:15.577631.577631 lmp.py:769]   Device Token Distribution:
DEBUG 01-07 10:14:15.578035.578035 lmp.py:770]   CPU:   1714 tokens
DEBUG 01-07 10:14:15.578870.578870 lmp.py:774]   cuda:1:   5220 tokens (22 experts)
DEBUG 01-07 10:14:15.578752.578752 lmp.py:774]   cuda:2:   5354 tokens (23 experts)
DEBUG 01-07 10:14:15.578395.578395 lmp.py:775]   Total GPU:  10574 tokens
DEBUG 01-07 10:14:15.578561.578561 lmp.py:776] ============================================================
DEBUG 01-07 10:14:15.578561.578561 lmp.py:776] 
DEBUG 01-07 10:14:15.578641.578641 cuda_h.py:19] end experts_map_get cost 0.0017616748809814453 seconds
DEBUG 01-07 10:14:15.578238.578238 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model_multi_device
DEBUG 01-07 10:14:15.578438.578438 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 10:14:15.578687.578687 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 10:14:15.578681.578681 cuda_h.py:19] end allocate_cuda_memory cost 0.0005955696105957031 seconds
DEBUG 01-07 10:14:15.578776.578776 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 10:14:15.579817.579817 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 10:14:15.579964.579964 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 10:14:15.579614.579614 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, b42a5e70-748e-470e-bef3-c81463eb1a67
DEBUG 01-07 10:14:15.579241.579241 client.py:106] call stub.LoadModelAsync
INFO 01-07 10:14:15.579683.579683 client.py:127] Model loaded
DEBUG 01-07 10:14:15.580222.580222 cuda_h.py:19] end sllm_worker_task cost 0.009392976760864258 seconds
INFO 01-07 10:14:15.581341.581341 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, b42a5e70-748e-470e-bef3-c81463eb1a67
DEBUG 01-07 10:14:15.581853.581853 cuda_h.py:19] end load_into_gpu_async cost 0.002060413360595703 seconds
DEBUG 01-07 10:14:15.581841.581841 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 10:14:15.581598.581598 cuda_h.py:19] end restore_tensors2 cost 0.0002532005310058594 seconds
DEBUG 01-07 10:14:15.581130.581130 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0032269954681396484 seconds
DEBUG 01-07 10:14:15.583237.583237 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 10:14:15.583884.583884 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 10:14:15.583422.583422 cuda_h.py:19] end allocate_cuda_memory cost 0.0002181529998779297 seconds
DEBUG 01-07 10:14:15.583027.583027 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 10:14:15.583068.583068 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 10:14:15.583731.583731 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 10:14:15.583619.583619 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 55eff698-28ad-43bd-b07b-733975c50d1f
DEBUG 01-07 10:14:15.583372.583372 client.py:106] call stub.LoadModelAsync
INFO 01-07 10:14:15.585310.585310 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 55eff698-28ad-43bd-b07b-733975c50d1f
DEBUG 01-07 10:14:15.585139.585139 cuda_h.py:19] end load_into_gpu_async cost 0.0017359256744384766 seconds
DEBUG 01-07 10:14:15.585173.585173 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 10:14:15.585341.585341 cuda_h.py:19] end restore_tensors2 cost 0.00023889541625976562 seconds
DEBUG 01-07 10:14:15.585495.585495 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0024912357330322266 seconds
DEBUG 01-07 10:14:15.587439.587439 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model_multi_device cost 0.009528636932373047 seconds
DEBUG 01-07 10:14:15.587977.587977 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-07 10:14:15.587940.587940 lmp.py:816] 
DEBUG 01-07 10:14:15.587940.587940 lmp.py:816]   Computing 19 experts on CPU...
DEBUG 01-07 10:14:15.587922.587922 cuda_h.py:19] end cpu_experts_submit cost 0.00010800361633300781 seconds
DEBUG 01-07 10:14:15.587287.587287 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-07 10:14:15.599498.599498 mlpmodule.py:749] group tensors cost 0.011322498321533203 s
DEBUG 01-07 10:14:15.601843.601843 mlpmodule.py:787] pad cost 0.0010864734649658203 s
DEBUG 01-07 10:14:15.601701.601701 mlpmodule.py:793] create cpu tensor cost 4.3392181396484375e-05 s
DEBUG 01-07 10:14:15.601565.601565 mlpmodule.py:798] move to cpu cost 3.504753112792969e-05 s
DEBUG 01-07 10:14:15.608367.608367 mlpmodule.py:812] group_w3: shape=torch.Size([19, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=54788096
DEBUG 01-07 10:14:15.608249.608249 mlpmodule.py:813] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-07 10:14:15.608835.608835 mlpmodule.py:818] group_w3 first element: -0.02490234375
WARNING 01-07 10:14:15.608893.608893 mlpmodule.py:828] start einsum2
DEBUG 01-07 10:14:15.620625.620625 mlpmodule.py:838] group einsum cost 0.018912076950073242 s
DEBUG 01-07 10:14:15.620262.620262 mlpmodule.py:846] cpy2cputensor cost 0.0004119873046875 s
DEBUG 01-07 10:14:15.623037.623037 cuda_h.py:19] end wait_cetm_experts cost 0.03562211990356445 seconds
DEBUG 01-07 10:14:15.623842.623842 cuda_h.py:10] start gpu_sexperts
DEBUG 01-07 10:14:15.624874.624874 cuda_h.py:19] end gpu_sexperts cost 0.0005049705505371094 seconds
DEBUG 01-07 10:14:15.624054.624054 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-07 10:14:15.624805.624805 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.4318695068359375e-05 seconds
DEBUG 01-07 10:14:15.624508.624508 cuda_h.py:10] start wait_experts_multi_device
INFO 01-07 10:14:15.624920.624920 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, b42a5e70-748e-470e-bef3-c81463eb1a67
INFO 01-07 10:14:15.625022.625022 client.py:127] Model loaded
INFO 01-07 10:14:15.625336.625336 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 55eff698-28ad-43bd-b07b-733975c50d1f
INFO 01-07 10:14:15.628275.628275 client.py:127] Model loaded
DEBUG 01-07 10:14:15.628350.628350 cuda_h.py:19] end wait_experts_multi_device cost 0.004555463790893555 seconds
DEBUG 01-07 10:14:15.628437.628437 cuda_h.py:10] start gpu_experts_multi_device
DEBUG 01-07 10:14:15.629803.629803 lmp.py:867]   Computing 23 experts on cuda:2...
DEBUG 01-07 10:14:15.630279.630279 mlpmodule.py:533] gpu group tensors cost 0.0004982948303222656 s
DEBUG 01-07 10:14:15.631443.631443 mlpmodule.py:566] gpu pad cost 0.0012505054473876953 s
DEBUG 01-07 10:14:15.632706.632706 mlpmodule.py:707]  experts func einsum cost 0.044045209884643555 s
DEBUG 01-07 10:14:15.632716.632716 mlpmodule.py:584] gpu group einsum cost 0.0005903244018554688 s
DEBUG 01-07 10:14:15.634493.634493 mlpmodule.py:656] gpu experts func einsum cost 0.00451970100402832 s
DEBUG 01-07 10:14:15.634589.634589 lmp.py:867]   Computing 22 experts on cuda:1...
DEBUG 01-07 10:14:15.635620.635620 mlpmodule.py:533] gpu group tensors cost 0.00044083595275878906 s
DEBUG 01-07 10:14:15.636367.636367 mlpmodule.py:566] gpu pad cost 0.0010912418365478516 s
DEBUG 01-07 10:14:15.636221.636221 mlpmodule.py:584] gpu group einsum cost 0.0003223419189453125 s
DEBUG 01-07 10:14:15.638902.638902 mlpmodule.py:656] gpu experts func einsum cost 0.003528594970703125 s
DEBUG 01-07 10:14:15.638686.638686 cuda_h.py:19] end gpu_experts_multi_device cost 0.009378194808959961 seconds
DEBUG 01-07 10:14:15.638172.638172 cuda_h.py:19] end layer_moe_generate_multi_device_16 cost 0.0629415512084961 seconds
DEBUG 01-07 10:14:15.638829.638829 lmp.py:194] -------------------------------- end prefill layer 16 --------------------------------
DEBUG 01-07 10:14:15.638944.638944 lmp.py:153] -------------------------------- start prefill layer 17 --------------------------------
DEBUG 01-07 10:14:15.638163.638163 cuda_h.py:10] start start_load_qkvogn_s_weight_l_18
DEBUG 01-07 10:14:15.638442.638442 cuda_h.py:10] start start_load_qkvogn_s_weight_l_18
DEBUG 01-07 10:14:15.638040.638040 cuda_h.py:19] end start_load_qkvogn_s_weight_l_18 cost 2.8848648071289062e-05 seconds
DEBUG 01-07 10:14:15.638743.638743 cuda_h.py:19] end start_load_qkvogn_s_weight_l_18 cost 5.936622619628906e-05 seconds
DEBUG 01-07 10:14:15.638578.638578 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-07 10:14:15.638778.638778 cuda_h.py:10] start sllm_worker_task
DEBUG 01-07 10:14:15.639589.639589 mlpmodule.py:367] cuda:1 cuda:1
DEBUG 01-07 10:14:15.639935.639935 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 10:14:15.639323.639323 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 10:14:15.639181.639181 cuda_h.py:19] end allocate_cuda_memory cost 0.0002799034118652344 seconds
DEBUG 01-07 10:14:15.639813.639813 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 10:14:15.639192.639192 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 10:14:15.639869.639869 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 10:14:15.639380.639380 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, aabe7808-6db2-4a01-a3b4-0ca94486fa1d
DEBUG 01-07 10:14:15.639243.639243 client.py:106] call stub.LoadModelAsync
DEBUG 01-07 10:14:15.640476.640476 cuda_h.py:10] start self_attn
INFO 01-07 10:14:15.641285.641285 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, aabe7808-6db2-4a01-a3b4-0ca94486fa1d
DEBUG 01-07 10:14:15.641068.641068 cuda_h.py:19] end load_into_gpu_async cost 0.0014538764953613281 seconds
DEBUG 01-07 10:14:15.641864.641864 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 10:14:15.641178.641178 cuda_h.py:19] end restore_tensors2 cost 6.580352783203125e-05 seconds
DEBUG 01-07 10:14:15.641742.641742 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0020515918731689453 seconds
INFO 01-07 10:14:15.641379.641379 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, aabe7808-6db2-4a01-a3b4-0ca94486fa1d
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-07 10:14:15.643904.643904 cuda_h.py:19] end self_attn cost 0.0034143924713134766 seconds
DEBUG 01-07 10:14:15.643073.643073 cuda_h.py:19] end iln_self_attn_paln cost 0.004806995391845703 seconds
DEBUG 01-07 10:14:15.643757.643757 cuda_h.py:10] start layer_moe_generate_multi_device_17
DEBUG 01-07 10:14:15.643658.643658 cuda_h.py:10] start gate
DEBUG 01-07 10:14:15.644315.644315 cuda_h.py:19] end gate cost 0.0008025169372558594 seconds
DEBUG 01-07 10:14:15.644622.644622 cuda_h.py:10] start experts_map_get
DEBUG 01-07 10:14:15.645343.645343 lmp.py:744] 
DEBUG 01-07 10:14:15.645343.645343 lmp.py:744] Expert Token Distribution & Multi-Device Allocation:
DEBUG 01-07 10:14:15.645768.645768 lmp.py:745]   Total experts: 64
DEBUG 01-07 10:14:15.645133.645133 lmp.py:746]   CPU experts: 19 (30%)
DEBUG 01-07 10:14:15.645445.645445 lmp.py:747]   GPU experts: 45 (70%)
DEBUG 01-07 10:14:15.645327.645327 lmp.py:748]   Number of GPU devices: 2
DEBUG 01-07 10:14:15.645016.645016 lmp.py:749] 
DEBUG 01-07 10:14:15.645016.645016 lmp.py:749]   Expert ID | Tokens | Device
DEBUG 01-07 10:14:15.645182.645182 lmp.py:750]   -----------------------------------
DEBUG 01-07 10:14:15.645786.645786 lmp.py:767]   Expert  4 |     10 | CPU
DEBUG 01-07 10:14:15.645190.645190 lmp.py:767]   Expert 28 |     27 | CPU
DEBUG 01-07 10:14:15.645879.645879 lmp.py:767]   Expert  7 |     44 | CPU
DEBUG 01-07 10:14:15.645569.645569 lmp.py:767]   Expert 53 |     53 | CPU
DEBUG 01-07 10:14:15.645543.645543 lmp.py:767]   Expert 52 |     67 | CPU
DEBUG 01-07 10:14:15.645755.645755 lmp.py:767]   Expert 43 |     73 | CPU
DEBUG 01-07 10:14:15.645683.645683 lmp.py:767]   Expert 49 |     85 | CPU
DEBUG 01-07 10:14:15.645611.645611 lmp.py:767]   Expert 12 |     90 | CPU
DEBUG 01-07 10:14:15.645300.645300 lmp.py:767]   Expert 47 |    100 | CPU
DEBUG 01-07 10:14:15.645228.645228 lmp.py:767]   Expert 24 |    102 | CPU
DEBUG 01-07 10:14:15.645155.645155 lmp.py:767]   Expert 33 |    108 | CPU
DEBUG 01-07 10:14:15.645606.645606 lmp.py:767]   Expert  2 |    110 | CPU
DEBUG 01-07 10:14:15.645819.645819 lmp.py:767]   Expert 15 |    110 | CPU
DEBUG 01-07 10:14:15.645554.645554 lmp.py:767]   Expert 50 |    113 | CPU
DEBUG 01-07 10:14:15.645528.645528 lmp.py:767]   Expert 60 |    113 | CPU
DEBUG 01-07 10:14:15.645264.645264 lmp.py:767]   Expert 39 |    116 | CPU
DEBUG 01-07 10:14:15.645238.645238 lmp.py:767]   Expert 36 |    118 | CPU
DEBUG 01-07 10:14:15.645212.645212 lmp.py:767]   Expert  6 |    127 | CPU
DEBUG 01-07 10:14:15.645140.645140 lmp.py:767]   Expert 61 |    129 | CPU
DEBUG 01-07 10:14:15.645498.645498 lmp.py:767]   Expert 25 |    131 | GPU0(cuda:1)
DEBUG 01-07 10:14:15.645618.645618 lmp.py:767]   Expert 59 |    141 | GPU1(cuda:2)
DEBUG 01-07 10:14:15.645499.645499 lmp.py:767]   Expert 58 |    142 | GPU0(cuda:1)
DEBUG 01-07 10:14:15.645381.645381 lmp.py:767]   Expert  3 |    144 | GPU1(cuda:2)
DEBUG 01-07 10:14:15.645547.645547 lmp.py:767]   Expert 27 |    145 | GPU0(cuda:1)
DEBUG 01-07 10:14:15.645713.645713 lmp.py:767]   Expert 31 |    147 | GPU1(cuda:2)
DEBUG 01-07 10:14:15.645879.645879 lmp.py:767]   Expert 30 |    155 | GPU0(cuda:1)
DEBUG 01-07 10:14:15.645476.645476 lmp.py:767]   Expert 10 |    156 | GPU0(cuda:1)
DEBUG 01-07 10:14:15.645357.645357 lmp.py:767]   Expert 40 |    156 | GPU1(cuda:2)
DEBUG 01-07 10:14:15.645192.645192 lmp.py:767]   Expert 38 |    158 | GPU1(cuda:2)
DEBUG 01-07 10:14:15.645504.645504 lmp.py:767]   Expert  8 |    159 | GPU1(cuda:2)
DEBUG 01-07 10:14:15.645101.645101 lmp.py:767]   Expert 57 |    159 | GPU0(cuda:1)
DEBUG 01-07 10:14:15.645459.645459 lmp.py:767]   Expert 46 |    161 | GPU0(cuda:1)
DEBUG 01-07 10:14:15.645923.645923 lmp.py:767]   Expert 37 |    162 | GPU1(cuda:2)
DEBUG 01-07 10:14:15.645328.645328 lmp.py:767]   Expert 14 |    164 | GPU0(cuda:1)
DEBUG 01-07 10:14:15.645971.645971 lmp.py:767]   Expert 41 |    165 | GPU1(cuda:2)
DEBUG 01-07 10:14:15.645852.645852 lmp.py:767]   Expert 32 |    166 | GPU0(cuda:1)
DEBUG 01-07 10:14:15.645257.645257 lmp.py:767]   Expert 19 |    170 | GPU0(cuda:1)
DEBUG 01-07 10:14:15.645138.645138 lmp.py:767]   Expert 54 |    170 | GPU1(cuda:2)
DEBUG 01-07 10:14:15.645212.645212 lmp.py:767]   Expert 42 |    172 | GPU1(cuda:2)
DEBUG 01-07 10:14:15.645047.645047 lmp.py:767]   Expert 11 |    178 | GPU0(cuda:1)
DEBUG 01-07 10:14:15.646882.646882 lmp.py:767]   Expert 34 |    186 | GPU1(cuda:2)
DEBUG 01-07 10:14:15.646717.646717 lmp.py:767]   Expert  0 |    196 | GPU0(cuda:1)
DEBUG 01-07 10:14:15.646075.646075 lmp.py:767]   Expert 18 |    197 | GPU1(cuda:2)
DEBUG 01-07 10:14:15.646957.646957 lmp.py:767]   Expert 26 |    198 | GPU0(cuda:1)
DEBUG 01-07 10:14:15.646076.646076 lmp.py:767]   Expert 22 |    199 | GPU0(cuda:1)
DEBUG 01-07 10:14:15.646958.646958 lmp.py:767]   Expert 56 |    199 | GPU1(cuda:2)
DEBUG 01-07 10:14:15.646839.646839 lmp.py:767]   Expert  1 |    203 | GPU0(cuda:1)
DEBUG 01-07 10:14:15.646482.646482 lmp.py:767]   Expert 44 |    203 | GPU1(cuda:2)
DEBUG 01-07 10:14:15.646887.646887 lmp.py:767]   Expert 51 |    209 | GPU1(cuda:2)
DEBUG 01-07 10:14:15.646245.646245 lmp.py:767]   Expert 20 |    223 | GPU0(cuda:1)
DEBUG 01-07 10:14:15.646319.646319 lmp.py:767]   Expert 45 |    231 | GPU1(cuda:2)
DEBUG 01-07 10:14:15.646438.646438 lmp.py:767]   Expert 48 |    232 | GPU0(cuda:1)
DEBUG 01-07 10:14:15.646273.646273 lmp.py:767]   Expert 29 |    233 | GPU1(cuda:2)
DEBUG 01-07 10:14:15.646916.646916 lmp.py:767]   Expert 16 |    247 | GPU0(cuda:1)
DEBUG 01-07 10:14:15.646036.646036 lmp.py:767]   Expert 21 |    248 | GPU1(cuda:2)
DEBUG 01-07 10:14:15.646156.646156 lmp.py:767]   Expert 35 |    250 | GPU0(cuda:1)
DEBUG 01-07 10:14:15.646799.646799 lmp.py:767]   Expert 55 |    251 | GPU1(cuda:2)
DEBUG 01-07 10:14:15.646204.646204 lmp.py:767]   Expert  5 |    296 | GPU0(cuda:1)
DEBUG 01-07 10:14:15.646847.646847 lmp.py:767]   Expert 23 |    374 | GPU1(cuda:2)
DEBUG 01-07 10:14:15.646489.646489 lmp.py:767]   Expert 13 |    384 | GPU0(cuda:1)
DEBUG 01-07 10:14:15.646132.646132 lmp.py:767]   Expert 17 |    437 | GPU1(cuda:2)
DEBUG 01-07 10:14:15.646775.646775 lmp.py:767]   Expert 63 |    458 | GPU1(cuda:2)
DEBUG 01-07 10:14:15.646134.646134 lmp.py:767]   Expert  9 |    459 | GPU1(cuda:2)
DEBUG 01-07 10:14:15.646969.646969 lmp.py:767]   Expert 62 |   1179 | GPU0(cuda:1)
DEBUG 01-07 10:14:15.646327.646327 lmp.py:769] 
DEBUG 01-07 10:14:15.646327.646327 lmp.py:769]   Device Token Distribution:
DEBUG 01-07 10:14:15.646208.646208 lmp.py:770]   CPU:   1695 tokens
DEBUG 01-07 10:14:15.646567.646567 lmp.py:774]   cuda:1:   5334 tokens (22 experts)
DEBUG 01-07 10:14:15.646448.646448 lmp.py:774]   cuda:2:   5259 tokens (23 experts)
DEBUG 01-07 10:14:15.646376.646376 lmp.py:775]   Total GPU:  10593 tokens
DEBUG 01-07 10:14:15.646303.646303 lmp.py:776] ============================================================
DEBUG 01-07 10:14:15.646303.646303 lmp.py:776] 
DEBUG 01-07 10:14:15.646715.646715 cuda_h.py:19] end experts_map_get cost 0.0017604827880859375 seconds
DEBUG 01-07 10:14:15.646596.646596 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model_multi_device
DEBUG 01-07 10:14:15.646227.646227 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 10:14:15.646429.646429 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 10:14:15.647625.647625 cuda_h.py:19] end allocate_cuda_memory cost 0.0006732940673828125 seconds
DEBUG 01-07 10:14:15.647866.647866 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 10:14:15.647622.647622 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 10:14:15.647623.647623 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 10:14:15.647227.647227 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, bb1de0ab-23aa-4dbd-a110-521252de1953
DEBUG 01-07 10:14:15.647092.647092 client.py:106] call stub.LoadModelAsync
INFO 01-07 10:14:15.648466.648466 client.py:127] Model loaded
DEBUG 01-07 10:14:15.648825.648825 cuda_h.py:19] end sllm_worker_task cost 0.00936746597290039 seconds
INFO 01-07 10:14:15.649996.649996 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, bb1de0ab-23aa-4dbd-a110-521252de1953
DEBUG 01-07 10:14:15.649746.649746 cuda_h.py:19] end load_into_gpu_async cost 0.002125978469848633 seconds
DEBUG 01-07 10:14:15.649780.649780 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 10:14:15.649107.649107 cuda_h.py:19] end restore_tensors2 cost 0.00025200843811035156 seconds
DEBUG 01-07 10:14:15.650592.650592 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0033714771270751953 seconds
DEBUG 01-07 10:14:15.651456.651456 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 10:14:15.652440.652440 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 10:14:15.652011.652011 cuda_h.py:19] end allocate_cuda_memory cost 0.00020766258239746094 seconds
DEBUG 01-07 10:14:15.652755.652755 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 10:14:15.652796.652796 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 10:14:15.652459.652459 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 10:14:15.652930.652930 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, e4eb2689-c011-4441-8178-b1c18d6d7837
DEBUG 01-07 10:14:15.652544.652544 client.py:106] call stub.LoadModelAsync
INFO 01-07 10:14:15.654859.654859 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, e4eb2689-c011-4441-8178-b1c18d6d7837
DEBUG 01-07 10:14:15.654497.654497 cuda_h.py:19] end load_into_gpu_async cost 0.0017435550689697266 seconds
DEBUG 01-07 10:14:15.654339.654339 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 10:14:15.654916.654916 cuda_h.py:19] end restore_tensors2 cost 0.0002257823944091797 seconds
DEBUG 01-07 10:14:15.654355.654355 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0024738311767578125 seconds
DEBUG 01-07 10:14:15.656438.656438 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model_multi_device cost 0.009688138961791992 seconds
DEBUG 01-07 10:14:15.656599.656599 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-07 10:14:15.656621.656621 lmp.py:816] 
DEBUG 01-07 10:14:15.656621.656621 lmp.py:816]   Computing 19 experts on CPU...
DEBUG 01-07 10:14:15.656603.656603 cuda_h.py:19] end cpu_experts_submit cost 0.00011610984802246094 seconds
DEBUG 01-07 10:14:15.656532.656532 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-07 10:14:15.668462.668462 mlpmodule.py:749] group tensors cost 0.012001991271972656 s
DEBUG 01-07 10:14:15.670450.670450 mlpmodule.py:787] pad cost 0.0009543895721435547 s
DEBUG 01-07 10:14:15.670533.670533 mlpmodule.py:793] create cpu tensor cost 3.910064697265625e-05 s
DEBUG 01-07 10:14:15.670244.670244 mlpmodule.py:798] move to cpu cost 3.2901763916015625e-05 s
DEBUG 01-07 10:14:15.678253.678253 mlpmodule.py:812] group_w3: shape=torch.Size([19, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=54788096
DEBUG 01-07 10:14:15.678504.678504 mlpmodule.py:813] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-07 10:14:15.678726.678726 mlpmodule.py:818] group_w3 first element: 0.00457763671875
WARNING 01-07 10:14:15.678929.678929 mlpmodule.py:828] start einsum2
DEBUG 01-07 10:14:15.690064.690064 mlpmodule.py:838] group einsum cost 0.019872665405273438 s
DEBUG 01-07 10:14:15.691496.691496 mlpmodule.py:846] cpy2cputensor cost 0.0004417896270751953 s
DEBUG 01-07 10:14:15.693014.693014 cuda_h.py:19] end wait_cetm_experts cost 0.03706026077270508 seconds
DEBUG 01-07 10:14:15.693335.693335 cuda_h.py:10] start gpu_sexperts
DEBUG 01-07 10:14:15.694565.694565 cuda_h.py:19] end gpu_sexperts cost 0.0005114078521728516 seconds
DEBUG 01-07 10:14:15.694839.694839 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-07 10:14:15.694212.694212 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.5033950805664062e-05 seconds
DEBUG 01-07 10:14:15.694491.694491 cuda_h.py:10] start wait_experts_multi_device
INFO 01-07 10:14:15.694015.694015 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, bb1de0ab-23aa-4dbd-a110-521252de1953
INFO 01-07 10:14:15.695890.695890 client.py:127] Model loaded
INFO 01-07 10:14:15.695018.695018 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, e4eb2689-c011-4441-8178-b1c18d6d7837
INFO 01-07 10:14:15.697993.697993 client.py:127] Model loaded
DEBUG 01-07 10:14:15.697968.697968 cuda_h.py:19] end wait_experts_multi_device cost 0.003337860107421875 seconds
DEBUG 01-07 10:14:15.697340.697340 cuda_h.py:10] start gpu_experts_multi_device
DEBUG 01-07 10:14:15.697401.697401 lmp.py:867]   Computing 23 experts on cuda:2...
DEBUG 01-07 10:14:15.699626.699626 mlpmodule.py:533] gpu group tensors cost 0.000514984130859375 s
DEBUG 01-07 10:14:15.700955.700955 mlpmodule.py:566] gpu pad cost 0.0012662410736083984 s
DEBUG 01-07 10:14:15.701267.701267 mlpmodule.py:584] gpu group einsum cost 0.0005490779876708984 s
DEBUG 01-07 10:14:15.701456.701456 mlpmodule.py:707]  experts func einsum cost 0.04526853561401367 s
DEBUG 01-07 10:14:15.703374.703374 mlpmodule.py:656] gpu experts func einsum cost 0.004645586013793945 s
DEBUG 01-07 10:14:15.703781.703781 lmp.py:867]   Computing 22 experts on cuda:1...
DEBUG 01-07 10:14:15.704057.704057 mlpmodule.py:533] gpu group tensors cost 0.0004458427429199219 s
DEBUG 01-07 10:14:15.705270.705270 mlpmodule.py:566] gpu pad cost 0.0015380382537841797 s
DEBUG 01-07 10:14:15.706691.706691 mlpmodule.py:584] gpu group einsum cost 0.0008342266082763672 s
DEBUG 01-07 10:14:15.708806.708806 mlpmodule.py:656] gpu experts func einsum cost 0.004614591598510742 s
DEBUG 01-07 10:14:15.708505.708505 cuda_h.py:19] end gpu_experts_multi_device cost 0.010626554489135742 seconds
DEBUG 01-07 10:14:15.708375.708375 cuda_h.py:19] end layer_moe_generate_multi_device_17 cost 0.06471657752990723 seconds
DEBUG 01-07 10:14:15.708932.708932 lmp.py:194] -------------------------------- end prefill layer 17 --------------------------------
DEBUG 01-07 10:14:15.708570.708570 lmp.py:153] -------------------------------- start prefill layer 18 --------------------------------
DEBUG 01-07 10:14:15.708027.708027 cuda_h.py:10] start start_load_qkvogn_s_weight_l_19
DEBUG 01-07 10:14:15.708068.708068 cuda_h.py:10] start start_load_qkvogn_s_weight_l_19
DEBUG 01-07 10:14:15.708904.708904 cuda_h.py:19] end start_load_qkvogn_s_weight_l_19 cost 2.8371810913085938e-05 seconds
DEBUG 01-07 10:14:15.709223.709223 cuda_h.py:19] end start_load_qkvogn_s_weight_l_19 cost 5.745887756347656e-05 seconds
DEBUG 01-07 10:14:15.709535.709535 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-07 10:14:15.709504.709504 cuda_h.py:10] start sllm_worker_task
DEBUG 01-07 10:14:15.709360.709360 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 10:14:15.709097.709097 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 10:14:15.709847.709847 cuda_h.py:19] end allocate_cuda_memory cost 0.0002028942108154297 seconds
DEBUG 01-07 10:14:15.709240.709240 mlpmodule.py:367] cuda:1 cuda:1
DEBUG 01-07 10:14:15.709831.709831 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 10:14:15.709099.709099 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 10:14:15.709445.709445 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 10:14:15.709240.709240 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 198a0f89-03fb-443b-8787-ed19a956bfa8
DEBUG 01-07 10:14:15.709243.709243 client.py:106] call stub.LoadModelAsync
DEBUG 01-07 10:14:15.710398.710398 cuda_h.py:10] start self_attn
INFO 01-07 10:14:15.710846.710846 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 198a0f89-03fb-443b-8787-ed19a956bfa8
DEBUG 01-07 10:14:15.710438.710438 cuda_h.py:19] end load_into_gpu_async cost 0.0008120536804199219 seconds
DEBUG 01-07 10:14:15.710518.710518 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 10:14:15.710878.710878 cuda_h.py:19] end restore_tensors2 cost 6.556510925292969e-05 seconds
DEBUG 01-07 10:14:15.710442.710442 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0014328956604003906 seconds
INFO 01-07 10:14:15.710232.710232 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 198a0f89-03fb-443b-8787-ed19a956bfa8
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-07 10:14:15.713367.713367 cuda_h.py:19] end self_attn cost 0.0035676956176757812 seconds
DEBUG 01-07 10:14:15.714325.714325 cuda_h.py:19] end iln_self_attn_paln cost 0.004978179931640625 seconds
DEBUG 01-07 10:14:15.714294.714294 cuda_h.py:10] start layer_moe_generate_multi_device_18
DEBUG 01-07 10:14:15.714719.714719 cuda_h.py:10] start gate
DEBUG 01-07 10:14:15.714112.714112 cuda_h.py:19] end gate cost 0.0006420612335205078 seconds
DEBUG 01-07 10:14:15.714034.714034 cuda_h.py:10] start experts_map_get
DEBUG 01-07 10:14:15.715571.715571 lmp.py:744] 
DEBUG 01-07 10:14:15.715571.715571 lmp.py:744] Expert Token Distribution & Multi-Device Allocation:
DEBUG 01-07 10:14:15.715201.715201 lmp.py:745]   Total experts: 64
DEBUG 01-07 10:14:15.715235.715235 lmp.py:746]   CPU experts: 19 (30%)
DEBUG 01-07 10:14:15.715262.715262 lmp.py:747]   GPU experts: 45 (70%)
DEBUG 01-07 10:14:15.715382.715382 lmp.py:748]   Number of GPU devices: 2
DEBUG 01-07 10:14:15.715548.715548 lmp.py:749] 
DEBUG 01-07 10:14:15.715548.715548 lmp.py:749]   Expert ID | Tokens | Device
DEBUG 01-07 10:14:15.715953.715953 lmp.py:750]   -----------------------------------
DEBUG 01-07 10:14:15.715556.715556 lmp.py:767]   Expert 32 |     29 | CPU
DEBUG 01-07 10:14:15.715961.715961 lmp.py:767]   Expert 30 |     51 | CPU
DEBUG 01-07 10:14:15.715127.715127 lmp.py:767]   Expert  5 |     52 | CPU
DEBUG 01-07 10:14:15.715055.715055 lmp.py:767]   Expert 46 |     68 | CPU
DEBUG 01-07 10:14:15.715982.715982 lmp.py:767]   Expert 40 |     86 | CPU
DEBUG 01-07 10:14:15.715957.715957 lmp.py:767]   Expert  8 |     94 | CPU
DEBUG 01-07 10:14:15.715407.715407 lmp.py:767]   Expert 12 |     99 | CPU
DEBUG 01-07 10:14:15.715097.715097 lmp.py:767]   Expert 17 |    107 | CPU
DEBUG 01-07 10:14:15.715309.715309 lmp.py:767]   Expert 27 |    110 | CPU
DEBUG 01-07 10:14:15.715998.715998 lmp.py:767]   Expert  3 |    111 | CPU
DEBUG 01-07 10:14:15.715926.715926 lmp.py:767]   Expert 60 |    112 | CPU
DEBUG 01-07 10:14:15.715854.715854 lmp.py:767]   Expert 58 |    115 | CPU
DEBUG 01-07 10:14:15.715782.715782 lmp.py:767]   Expert 29 |    122 | CPU
DEBUG 01-07 10:14:15.715709.715709 lmp.py:767]   Expert 28 |    125 | CPU
DEBUG 01-07 10:14:15.715875.715875 lmp.py:767]   Expert 21 |    126 | CPU
DEBUG 01-07 10:14:15.715088.715088 lmp.py:767]   Expert 25 |    127 | CPU
DEBUG 01-07 10:14:15.715254.715254 lmp.py:767]   Expert 35 |    131 | CPU
DEBUG 01-07 10:14:15.715467.715467 lmp.py:767]   Expert 41 |    131 | CPU
DEBUG 01-07 10:14:15.715679.715679 lmp.py:767]   Expert 19 |    132 | CPU
DEBUG 01-07 10:14:15.715322.715322 lmp.py:767]   Expert 52 |    142 | GPU0(cuda:1)
DEBUG 01-07 10:14:15.715442.715442 lmp.py:767]   Expert 54 |    143 | GPU1(cuda:2)
DEBUG 01-07 10:14:15.715085.715085 lmp.py:767]   Expert  6 |    144 | GPU0(cuda:1)
DEBUG 01-07 10:14:15.715728.715728 lmp.py:767]   Expert  0 |    145 | GPU1(cuda:2)
DEBUG 01-07 10:14:15.715132.715132 lmp.py:767]   Expert 56 |    150 | GPU0(cuda:1)
DEBUG 01-07 10:14:15.715775.715775 lmp.py:767]   Expert 37 |    152 | GPU1(cuda:2)
DEBUG 01-07 10:14:15.715703.715703 lmp.py:767]   Expert 48 |    157 | GPU0(cuda:1)
DEBUG 01-07 10:14:15.715823.715823 lmp.py:767]   Expert 53 |    159 | GPU1(cuda:2)
DEBUG 01-07 10:14:15.715466.715466 lmp.py:767]   Expert 63 |    162 | GPU0(cuda:1)
DEBUG 01-07 10:14:15.715109.715109 lmp.py:767]   Expert 36 |    165 | GPU1(cuda:2)
DEBUG 01-07 10:14:15.715467.715467 lmp.py:767]   Expert 59 |    166 | GPU1(cuda:2)
DEBUG 01-07 10:14:15.715587.715587 lmp.py:767]   Expert  9 |    179 | GPU0(cuda:1)
DEBUG 01-07 10:14:15.715230.715230 lmp.py:767]   Expert 39 |    187 | GPU0(cuda:1)
DEBUG 01-07 10:14:15.715111.715111 lmp.py:767]   Expert  1 |    192 | GPU1(cuda:2)
DEBUG 01-07 10:14:15.715516.715516 lmp.py:767]   Expert 20 |    192 | GPU1(cuda:2)
DEBUG 01-07 10:14:15.715682.715682 lmp.py:767]   Expert 43 |    198 | GPU0(cuda:1)
DEBUG 01-07 10:14:15.716848.716848 lmp.py:767]   Expert 42 |    204 | GPU0(cuda:1)
DEBUG 01-07 10:14:15.716014.716014 lmp.py:767]   Expert 61 |    204 | GPU1(cuda:2)
DEBUG 01-07 10:14:15.716180.716180 lmp.py:767]   Expert 11 |    205 | GPU0(cuda:1)
DEBUG 01-07 10:14:15.716346.716346 lmp.py:767]   Expert  7 |    208 | GPU1(cuda:2)
DEBUG 01-07 10:14:15.716513.716513 lmp.py:767]   Expert 34 |    208 | GPU0(cuda:1)
DEBUG 01-07 10:14:15.716917.716917 lmp.py:767]   Expert 55 |    208 | GPU1(cuda:2)
DEBUG 01-07 10:14:15.716560.716560 lmp.py:767]   Expert 47 |    211 | GPU1(cuda:2)
DEBUG 01-07 10:14:15.716965.716965 lmp.py:767]   Expert 16 |    216 | GPU0(cuda:1)
DEBUG 01-07 10:14:15.716608.716608 lmp.py:767]   Expert 13 |    219 | GPU1(cuda:2)
DEBUG 01-07 10:14:15.716012.716012 lmp.py:767]   Expert 57 |    224 | GPU0(cuda:1)
DEBUG 01-07 10:14:15.716132.716132 lmp.py:767]   Expert 18 |    230 | GPU1(cuda:2)
DEBUG 01-07 10:14:15.716775.716775 lmp.py:767]   Expert 15 |    239 | GPU0(cuda:1)
DEBUG 01-07 10:14:15.716941.716941 lmp.py:767]   Expert  4 |    242 | GPU1(cuda:2)
DEBUG 01-07 10:14:15.716869.716869 lmp.py:767]   Expert 33 |    243 | GPU1(cuda:2)
DEBUG 01-07 10:14:15.716797.716797 lmp.py:767]   Expert 45 |    243 | GPU0(cuda:1)
DEBUG 01-07 10:14:15.716963.716963 lmp.py:767]   Expert 31 |    248 | GPU1(cuda:2)
DEBUG 01-07 10:14:15.716652.716652 lmp.py:767]   Expert 50 |    248 | GPU0(cuda:1)
DEBUG 01-07 10:14:15.716580.716580 lmp.py:767]   Expert 22 |    249 | GPU0(cuda:1)
DEBUG 01-07 10:14:15.716746.716746 lmp.py:767]   Expert 51 |    255 | GPU1(cuda:2)
DEBUG 01-07 10:14:15.716389.716389 lmp.py:767]   Expert 49 |    273 | GPU0(cuda:1)
DEBUG 01-07 10:14:15.716747.716747 lmp.py:767]   Expert 38 |    275 | GPU1(cuda:2)
DEBUG 01-07 10:14:15.716867.716867 lmp.py:767]   Expert 26 |    278 | GPU0(cuda:1)
DEBUG 01-07 10:14:15.716901.716901 lmp.py:767]   Expert 10 |    288 | GPU1(cuda:2)
DEBUG 01-07 10:14:15.716451.716451 lmp.py:767]   Expert 44 |    292 | GPU0(cuda:1)
DEBUG 01-07 10:14:15.716809.716809 lmp.py:767]   Expert 24 |    298 | GPU1(cuda:2)
DEBUG 01-07 10:14:15.716168.716168 lmp.py:767]   Expert  2 |    311 | GPU0(cuda:1)
DEBUG 01-07 10:14:15.716526.716526 lmp.py:767]   Expert 14 |    318 | GPU1(cuda:2)
DEBUG 01-07 10:14:15.716646.716646 lmp.py:767]   Expert 23 |    417 | GPU1(cuda:2)
DEBUG 01-07 10:14:15.716527.716527 lmp.py:767]   Expert 62 |    673 | GPU0(cuda:1)
DEBUG 01-07 10:14:15.716455.716455 lmp.py:769] 
DEBUG 01-07 10:14:15.716455.716455 lmp.py:769]   Device Token Distribution:
DEBUG 01-07 10:14:15.716336.716336 lmp.py:770]   CPU:   1928 tokens
DEBUG 01-07 10:14:15.716694.716694 lmp.py:774]   cuda:1:   5182 tokens (22 experts)
DEBUG 01-07 10:14:15.716337.716337 lmp.py:774]   cuda:2:   5178 tokens (23 experts)
DEBUG 01-07 10:14:15.716265.716265 lmp.py:775]   Total GPU:  10360 tokens
DEBUG 01-07 10:14:15.716954.716954 lmp.py:776] ============================================================
DEBUG 01-07 10:14:15.716954.716954 lmp.py:776] 
DEBUG 01-07 10:14:15.716796.716796 cuda_h.py:19] end experts_map_get cost 0.0017621517181396484 seconds
DEBUG 01-07 10:14:15.716870.716870 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model_multi_device
DEBUG 01-07 10:14:15.716023.716023 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 10:14:15.716133.716133 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 10:14:15.717559.717559 cuda_h.py:19] end allocate_cuda_memory cost 0.00021123886108398438 seconds
DEBUG 01-07 10:14:15.717316.717316 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 10:14:15.717595.717595 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 10:14:15.717212.717212 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 10:14:15.717100.717100 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, c9c1cf5a-16a6-4848-a6a8-6923a6a26676
DEBUG 01-07 10:14:15.717059.717059 client.py:106] call stub.LoadModelAsync
INFO 01-07 10:14:15.717164.717164 client.py:127] Model loaded
DEBUG 01-07 10:14:15.718173.718173 cuda_h.py:19] end sllm_worker_task cost 0.008850574493408203 seconds
INFO 01-07 10:14:15.718485.718485 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, c9c1cf5a-16a6-4848-a6a8-6923a6a26676
DEBUG 01-07 10:14:15.718905.718905 cuda_h.py:19] end load_into_gpu_async cost 0.001138925552368164 seconds
DEBUG 01-07 10:14:15.718416.718416 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 10:14:15.718266.718266 cuda_h.py:19] end restore_tensors2 cost 0.00025153160095214844 seconds
DEBUG 01-07 10:14:15.718274.718274 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.001917123794555664 seconds
DEBUG 01-07 10:14:15.720429.720429 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 10:14:15.720904.720904 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 10:14:15.720979.720979 cuda_h.py:19] end allocate_cuda_memory cost 0.00022721290588378906 seconds
DEBUG 01-07 10:14:15.720200.720200 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 10:14:15.720810.720810 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 10:14:15.721043.721043 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 10:14:15.721216.721216 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, dc427628-9e4b-418d-b8a8-942312c38ae0
DEBUG 01-07 10:14:15.721637.721637 client.py:106] call stub.LoadModelAsync
INFO 01-07 10:14:15.721311.721311 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, dc427628-9e4b-418d-b8a8-942312c38ae0
DEBUG 01-07 10:14:15.721233.721233 cuda_h.py:19] end load_into_gpu_async cost 0.000978231430053711 seconds
DEBUG 01-07 10:14:15.722552.722552 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 10:14:15.722773.722773 cuda_h.py:19] end restore_tensors2 cost 0.00024318695068359375 seconds
DEBUG 01-07 10:14:15.722688.722688 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0017476081848144531 seconds
DEBUG 01-07 10:14:15.724414.724414 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model_multi_device cost 0.0075380802154541016 seconds
DEBUG 01-07 10:14:15.724721.724721 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-07 10:14:15.724114.724114 lmp.py:816] 
DEBUG 01-07 10:14:15.724114.724114 lmp.py:816]   Computing 19 experts on CPU...
DEBUG 01-07 10:14:15.724057.724057 cuda_h.py:19] end cpu_experts_submit cost 0.00011372566223144531 seconds
DEBUG 01-07 10:14:15.724898.724898 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-07 10:14:15.730202.730202 mlpmodule.py:749] group tensors cost 0.00595402717590332 s
DEBUG 01-07 10:14:15.732244.732244 mlpmodule.py:787] pad cost 0.001672983169555664 s
DEBUG 01-07 10:14:15.733401.733401 mlpmodule.py:793] create cpu tensor cost 6.198883056640625e-05 s
DEBUG 01-07 10:14:15.733167.733167 mlpmodule.py:798] move to cpu cost 4.649162292480469e-05 s
DEBUG 01-07 10:14:15.740276.740276 mlpmodule.py:812] group_w3: shape=torch.Size([19, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=54788096
DEBUG 01-07 10:14:15.740004.740004 mlpmodule.py:813] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-07 10:14:15.740676.740676 mlpmodule.py:818] group_w3 first element: 0.0264892578125
WARNING 01-07 10:14:15.740122.740122 mlpmodule.py:828] start einsum2
DEBUG 01-07 10:14:15.751221.751221 mlpmodule.py:838] group einsum cost 0.018129348754882812 s
DEBUG 01-07 10:14:15.752790.752790 mlpmodule.py:846] cpy2cputensor cost 0.00038695335388183594 s
DEBUG 01-07 10:14:15.754939.754939 cuda_h.py:19] end wait_cetm_experts cost 0.030251026153564453 seconds
DEBUG 01-07 10:14:15.754075.754075 cuda_h.py:10] start gpu_sexperts
DEBUG 01-07 10:14:15.755736.755736 cuda_h.py:19] end gpu_sexperts cost 0.0005130767822265625 seconds
DEBUG 01-07 10:14:15.755871.755871 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-07 10:14:15.755482.755482 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.384185791015625e-05 seconds
DEBUG 01-07 10:14:15.755947.755947 cuda_h.py:10] start wait_experts_multi_device
INFO 01-07 10:14:15.755571.755571 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, c9c1cf5a-16a6-4848-a6a8-6923a6a26676
INFO 01-07 10:14:15.759648.759648 client.py:127] Model loaded
INFO 01-07 10:14:15.759876.759876 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, dc427628-9e4b-418d-b8a8-942312c38ae0
DEBUG 01-07 10:14:15.763509.763509 mlpmodule.py:707]  experts func einsum cost 0.03850269317626953 s
INFO 01-07 10:14:15.764484.764484 client.py:127] Model loaded
DEBUG 01-07 10:14:15.764003.764003 cuda_h.py:19] end wait_experts_multi_device cost 0.009345293045043945 seconds
DEBUG 01-07 10:14:15.764759.764759 cuda_h.py:10] start gpu_experts_multi_device
DEBUG 01-07 10:14:15.765204.765204 lmp.py:867]   Computing 23 experts on cuda:2...
DEBUG 01-07 10:14:15.766103.766103 mlpmodule.py:533] gpu group tensors cost 0.0004930496215820312 s
DEBUG 01-07 10:14:15.767136.767136 mlpmodule.py:566] gpu pad cost 0.0011224746704101562 s
DEBUG 01-07 10:14:15.767106.767106 mlpmodule.py:584] gpu group einsum cost 0.0004057884216308594 s
DEBUG 01-07 10:14:15.769201.769201 mlpmodule.py:656] gpu experts func einsum cost 0.003797292709350586 s
DEBUG 01-07 10:14:15.769369.769369 lmp.py:867]   Computing 22 experts on cuda:1...
DEBUG 01-07 10:14:15.770330.770330 mlpmodule.py:533] gpu group tensors cost 0.00037360191345214844 s
DEBUG 01-07 10:14:15.771459.771459 mlpmodule.py:566] gpu pad cost 0.0010247230529785156 s
DEBUG 01-07 10:14:15.771558.771558 mlpmodule.py:584] gpu group einsum cost 0.0003294944763183594 s
DEBUG 01-07 10:14:15.773756.773756 mlpmodule.py:656] gpu experts func einsum cost 0.0033905506134033203 s
DEBUG 01-07 10:14:15.773839.773839 cuda_h.py:19] end gpu_experts_multi_device cost 0.008491754531860352 seconds
DEBUG 01-07 10:14:15.773855.773855 cuda_h.py:19] end layer_moe_generate_multi_device_18 cost 0.059442996978759766 seconds
DEBUG 01-07 10:14:15.773022.773022 lmp.py:194] -------------------------------- end prefill layer 18 --------------------------------
DEBUG 01-07 10:14:15.773785.773785 lmp.py:153] -------------------------------- start prefill layer 19 --------------------------------
DEBUG 01-07 10:14:15.773481.773481 cuda_h.py:10] start start_load_qkvogn_s_weight_l_20
DEBUG 01-07 10:14:15.773045.773045 cuda_h.py:10] start start_load_qkvogn_s_weight_l_20
DEBUG 01-07 10:14:15.773597.773597 cuda_h.py:19] end start_load_qkvogn_s_weight_l_20 cost 2.9802322387695312e-05 seconds
DEBUG 01-07 10:14:15.773107.773107 cuda_h.py:19] end start_load_qkvogn_s_weight_l_20 cost 5.984306335449219e-05 seconds
DEBUG 01-07 10:14:15.774704.774704 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-07 10:14:15.774110.774110 mlpmodule.py:367] cuda:1 cuda:1
DEBUG 01-07 10:14:15.774768.774768 cuda_h.py:10] start sllm_worker_task
DEBUG 01-07 10:14:15.774115.774115 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 10:14:15.774044.774044 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 10:14:15.774034.774034 cuda_h.py:19] end allocate_cuda_memory cost 0.00027370452880859375 seconds
DEBUG 01-07 10:14:15.774858.774858 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 10:14:15.774190.774190 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 10:14:15.774675.774675 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 10:14:15.774709.774709 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, edf6b1cd-e96d-4c35-9426-2b2e049a1bd8
DEBUG 01-07 10:14:15.774427.774427 client.py:106] call stub.LoadModelAsync
DEBUG 01-07 10:14:15.775089.775089 cuda_h.py:10] start self_attn
INFO 01-07 10:14:15.775037.775037 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, edf6b1cd-e96d-4c35-9426-2b2e049a1bd8
DEBUG 01-07 10:14:15.775436.775436 cuda_h.py:19] end load_into_gpu_async cost 0.0008134841918945312 seconds
DEBUG 01-07 10:14:15.775993.775993 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 10:14:15.775546.775546 cuda_h.py:19] end restore_tensors2 cost 6.628036499023438e-05 seconds
DEBUG 01-07 10:14:15.775395.775395 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0014026165008544922 seconds
INFO 01-07 10:14:15.775224.775224 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, edf6b1cd-e96d-4c35-9426-2b2e049a1bd8
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-07 10:14:15.778263.778263 cuda_h.py:19] end self_attn cost 0.003539562225341797 seconds
DEBUG 01-07 10:14:15.778101.778101 cuda_h.py:19] end iln_self_attn_paln cost 0.004899501800537109 seconds
DEBUG 01-07 10:14:15.778546.778546 cuda_h.py:10] start layer_moe_generate_multi_device_19
DEBUG 01-07 10:14:15.779071.779071 cuda_h.py:10] start gate
DEBUG 01-07 10:14:15.779980.779980 cuda_h.py:19] end gate cost 0.0006353855133056641 seconds
DEBUG 01-07 10:14:15.779379.779379 cuda_h.py:10] start experts_map_get
DEBUG 01-07 10:14:15.780876.780876 lmp.py:744] 
DEBUG 01-07 10:14:15.780876.780876 lmp.py:744] Expert Token Distribution & Multi-Device Allocation:
DEBUG 01-07 10:14:15.780732.780732 lmp.py:745]   Total experts: 64
DEBUG 01-07 10:14:15.780050.780050 lmp.py:746]   CPU experts: 19 (30%)
DEBUG 01-07 10:14:15.780223.780223 lmp.py:747]   GPU experts: 45 (70%)
DEBUG 01-07 10:14:15.780058.780058 lmp.py:748]   Number of GPU devices: 2
DEBUG 01-07 10:14:15.780463.780463 lmp.py:749] 
DEBUG 01-07 10:14:15.780463.780463 lmp.py:749]   Expert ID | Tokens | Device
DEBUG 01-07 10:14:15.780821.780821 lmp.py:750]   -----------------------------------
DEBUG 01-07 10:14:15.780140.780140 lmp.py:767]   Expert 44 |     41 | CPU
DEBUG 01-07 10:14:15.780498.780498 lmp.py:767]   Expert  1 |     50 | CPU
DEBUG 01-07 10:14:15.780903.780903 lmp.py:767]   Expert 28 |     63 | CPU
DEBUG 01-07 10:14:15.780307.780307 lmp.py:767]   Expert 60 |     64 | CPU
DEBUG 01-07 10:14:15.780665.780665 lmp.py:767]   Expert 48 |     74 | CPU
DEBUG 01-07 10:14:15.780461.780461 lmp.py:767]   Expert 27 |     81 | CPU
DEBUG 01-07 10:14:15.780581.780581 lmp.py:767]   Expert  0 |    101 | CPU
DEBUG 01-07 10:14:15.780985.780985 lmp.py:767]   Expert 62 |    107 | CPU
DEBUG 01-07 10:14:15.780913.780913 lmp.py:767]   Expert 30 |    113 | CPU
DEBUG 01-07 10:14:15.780079.780079 lmp.py:767]   Expert 42 |    114 | CPU
DEBUG 01-07 10:14:15.780722.780722 lmp.py:767]   Expert 59 |    114 | CPU
DEBUG 01-07 10:14:15.780650.780650 lmp.py:767]   Expert 22 |    115 | CPU
DEBUG 01-07 10:14:15.780816.780816 lmp.py:767]   Expert 16 |    121 | CPU
DEBUG 01-07 10:14:15.780982.780982 lmp.py:767]   Expert 58 |    122 | CPU
DEBUG 01-07 10:14:15.780910.780910 lmp.py:767]   Expert 12 |    131 | CPU
DEBUG 01-07 10:14:15.780030.780030 lmp.py:767]   Expert  8 |    132 | CPU
DEBUG 01-07 10:14:15.780150.780150 lmp.py:767]   Expert 50 |    136 | CPU
DEBUG 01-07 10:14:15.780077.780077 lmp.py:767]   Expert  5 |    144 | CPU
DEBUG 01-07 10:14:15.780482.780482 lmp.py:767]   Expert 56 |    145 | CPU
DEBUG 01-07 10:14:15.780317.780317 lmp.py:767]   Expert 57 |    148 | GPU1(cuda:2)
DEBUG 01-07 10:14:15.780152.780152 lmp.py:767]   Expert 55 |    149 | GPU1(cuda:2)
DEBUG 01-07 10:14:15.780464.780464 lmp.py:767]   Expert 15 |    153 | GPU0(cuda:1)
DEBUG 01-07 10:14:15.780060.780060 lmp.py:767]   Expert 26 |    153 | GPU0(cuda:1)
DEBUG 01-07 10:14:15.780180.780180 lmp.py:767]   Expert 32 |    155 | GPU1(cuda:2)
DEBUG 01-07 10:14:15.780539.780539 lmp.py:767]   Expert  2 |    160 | GPU1(cuda:2)
DEBUG 01-07 10:14:15.780658.780658 lmp.py:767]   Expert 47 |    162 | GPU0(cuda:1)
DEBUG 01-07 10:14:15.780540.780540 lmp.py:767]   Expert 24 |    164 | GPU0(cuda:1)
DEBUG 01-07 10:14:15.780660.780660 lmp.py:767]   Expert 34 |    165 | GPU1(cuda:2)
DEBUG 01-07 10:14:15.780541.780541 lmp.py:767]   Expert 40 |    168 | GPU0(cuda:1)
DEBUG 01-07 10:14:15.780661.780661 lmp.py:767]   Expert 52 |    168 | GPU1(cuda:2)
DEBUG 01-07 10:14:15.780257.780257 lmp.py:767]   Expert 54 |    168 | GPU0(cuda:1)
DEBUG 01-07 10:14:15.780092.780092 lmp.py:767]   Expert 41 |    169 | GPU1(cuda:2)
DEBUG 01-07 10:14:15.780212.780212 lmp.py:767]   Expert 18 |    172 | GPU1(cuda:2)
DEBUG 01-07 10:14:15.780332.780332 lmp.py:767]   Expert 13 |    174 | GPU0(cuda:1)
DEBUG 01-07 10:14:15.780452.780452 lmp.py:767]   Expert  6 |    175 | GPU0(cuda:1)
DEBUG 01-07 10:14:15.780333.780333 lmp.py:767]   Expert  3 |    176 | GPU1(cuda:2)
DEBUG 01-07 10:14:15.780215.780215 lmp.py:767]   Expert 20 |    183 | GPU1(cuda:2)
DEBUG 01-07 10:14:15.780335.780335 lmp.py:767]   Expert 46 |    184 | GPU0(cuda:1)
DEBUG 01-07 10:14:15.780454.780454 lmp.py:767]   Expert 37 |    185 | GPU0(cuda:1)
DEBUG 01-07 10:14:15.781289.781289 lmp.py:767]   Expert 19 |    188 | GPU1(cuda:2)
DEBUG 01-07 10:14:15.781171.781171 lmp.py:767]   Expert 51 |    192 | GPU1(cuda:2)
DEBUG 01-07 10:14:15.781291.781291 lmp.py:767]   Expert 25 |    195 | GPU0(cuda:1)
DEBUG 01-07 10:14:15.781934.781934 lmp.py:767]   Expert 11 |    202 | GPU0(cuda:1)
DEBUG 01-07 10:14:15.781815.781815 lmp.py:767]   Expert 17 |    202 | GPU1(cuda:2)
DEBUG 01-07 10:14:15.781458.781458 lmp.py:767]   Expert 35 |    202 | GPU0(cuda:1)
DEBUG 01-07 10:14:15.781578.781578 lmp.py:767]   Expert 43 |    202 | GPU1(cuda:2)
DEBUG 01-07 10:14:15.781459.781459 lmp.py:767]   Expert 31 |    203 | GPU1(cuda:2)
DEBUG 01-07 10:14:15.781056.781056 lmp.py:767]   Expert 23 |    207 | GPU0(cuda:1)
DEBUG 01-07 10:14:15.781891.781891 lmp.py:767]   Expert 49 |    219 | GPU1(cuda:2)
DEBUG 01-07 10:14:15.781772.781772 lmp.py:767]   Expert 10 |    227 | GPU1(cuda:2)
DEBUG 01-07 10:14:15.781130.781130 lmp.py:767]   Expert 39 |    227 | GPU0(cuda:1)
DEBUG 01-07 10:14:15.781012.781012 lmp.py:767]   Expert 53 |    228 | GPU0(cuda:1)
DEBUG 01-07 10:14:15.781893.781893 lmp.py:767]   Expert 33 |    246 | GPU1(cuda:2)
DEBUG 01-07 10:14:15.781536.781536 lmp.py:767]   Expert 36 |    267 | GPU0(cuda:1)
DEBUG 01-07 10:14:15.781179.781179 lmp.py:767]   Expert 38 |    267 | GPU0(cuda:1)
DEBUG 01-07 10:14:15.781061.781061 lmp.py:767]   Expert  4 |    308 | GPU1(cuda:2)
DEBUG 01-07 10:14:15.781419.781419 lmp.py:767]   Expert 21 |    336 | GPU0(cuda:1)
DEBUG 01-07 10:14:15.781539.781539 lmp.py:767]   Expert 14 |    347 | GPU1(cuda:2)
DEBUG 01-07 10:14:15.781420.781420 lmp.py:767]   Expert 63 |    370 | GPU0(cuda:1)
DEBUG 01-07 10:14:15.781063.781063 lmp.py:767]   Expert 45 |    371 | GPU1(cuda:2)
DEBUG 01-07 10:14:15.781706.781706 lmp.py:767]   Expert 61 |    390 | GPU0(cuda:1)
DEBUG 01-07 10:14:15.781587.781587 lmp.py:767]   Expert  9 |    395 | GPU1(cuda:2)
DEBUG 01-07 10:14:15.781230.781230 lmp.py:767]   Expert 29 |    487 | GPU1(cuda:2)
DEBUG 01-07 10:14:15.781112.781112 lmp.py:767]   Expert  7 |    511 | GPU0(cuda:1)
DEBUG 01-07 10:14:15.781755.781755 lmp.py:769] 
DEBUG 01-07 10:14:15.781755.781755 lmp.py:769]   Device Token Distribution:
DEBUG 01-07 10:14:15.781351.781351 lmp.py:770]   CPU:   1968 tokens
DEBUG 01-07 10:14:15.781710.781710 lmp.py:774]   cuda:1:   5088 tokens (22 experts)
DEBUG 01-07 10:14:15.781353.781353 lmp.py:774]   cuda:2:   5232 tokens (23 experts)
DEBUG 01-07 10:14:15.781280.781280 lmp.py:775]   Total GPU:  10320 tokens
DEBUG 01-07 10:14:15.781208.781208 lmp.py:776] ============================================================
DEBUG 01-07 10:14:15.781208.781208 lmp.py:776] 
DEBUG 01-07 10:14:15.781335.781335 cuda_h.py:19] end experts_map_get cost 0.001798868179321289 seconds
DEBUG 01-07 10:14:15.781170.781170 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model_multi_device
DEBUG 01-07 10:14:15.781668.781668 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 10:14:15.781248.781248 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 10:14:15.781004.781004 cuda_h.py:19] end allocate_cuda_memory cost 0.00020837783813476562 seconds
DEBUG 01-07 10:14:15.782053.782053 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 10:14:15.782524.782524 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 10:14:15.782526.782526 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 10:14:15.782699.782699 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 9441269a-9285-4ffa-84bf-cda6bd30526c
DEBUG 01-07 10:14:15.782949.782949 client.py:106] call stub.LoadModelAsync
INFO 01-07 10:14:15.782219.782219 client.py:127] Model loaded
DEBUG 01-07 10:14:15.782519.782519 cuda_h.py:19] end sllm_worker_task cost 0.008724451065063477 seconds
INFO 01-07 10:14:15.783486.783486 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 9441269a-9285-4ffa-84bf-cda6bd30526c
DEBUG 01-07 10:14:15.783044.783044 cuda_h.py:19] end load_into_gpu_async cost 0.0010833740234375 seconds
DEBUG 01-07 10:14:15.783270.783270 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 10:14:15.783736.783736 cuda_h.py:19] end restore_tensors2 cost 0.00024962425231933594 seconds
DEBUG 01-07 10:14:15.783744.783744 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0018587112426757812 seconds
DEBUG 01-07 10:14:15.785833.785833 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 10:14:15.785546.785546 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 10:14:15.785105.785105 cuda_h.py:19] end allocate_cuda_memory cost 0.00023245811462402344 seconds
DEBUG 01-07 10:14:15.785041.785041 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 10:14:15.785843.785843 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 10:14:15.785030.785030 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 10:14:15.785203.785203 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 1daedcaa-c383-4576-a9ac-baf946e82d21
DEBUG 01-07 10:14:15.786147.786147 client.py:106] call stub.LoadModelAsync
INFO 01-07 10:14:15.786858.786858 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 1daedcaa-c383-4576-a9ac-baf946e82d21
DEBUG 01-07 10:14:15.786972.786972 cuda_h.py:19] end load_into_gpu_async cost 0.0010759830474853516 seconds
DEBUG 01-07 10:14:15.786529.786529 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 10:14:15.787690.787690 cuda_h.py:19] end restore_tensors2 cost 0.0002334117889404297 seconds
DEBUG 01-07 10:14:15.787413.787413 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.001847982406616211 seconds
DEBUG 01-07 10:14:15.789822.789822 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model_multi_device cost 0.007577657699584961 seconds
DEBUG 01-07 10:14:15.789797.789797 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-07 10:14:15.789190.789190 lmp.py:816] 
DEBUG 01-07 10:14:15.789190.789190 lmp.py:816]   Computing 19 experts on CPU...
DEBUG 01-07 10:14:15.789126.789126 cuda_h.py:19] end cpu_experts_submit cost 0.00010848045349121094 seconds
DEBUG 01-07 10:14:15.789014.789014 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-07 10:14:15.796207.796207 mlpmodule.py:749] group tensors cost 0.006801128387451172 s
DEBUG 01-07 10:14:15.798934.798934 mlpmodule.py:787] pad cost 0.001485586166381836 s
DEBUG 01-07 10:14:15.798540.798540 mlpmodule.py:793] create cpu tensor cost 3.9577484130859375e-05 s
DEBUG 01-07 10:14:15.798510.798510 mlpmodule.py:798] move to cpu cost 4.9114227294921875e-05 s
DEBUG 01-07 10:14:15.805471.805471 mlpmodule.py:812] group_w3: shape=torch.Size([19, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=54788096
DEBUG 01-07 10:14:15.806862.806862 mlpmodule.py:813] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-07 10:14:15.806719.806719 mlpmodule.py:818] group_w3 first element: -0.0034942626953125
WARNING 01-07 10:14:15.806419.806419 mlpmodule.py:828] start einsum2
DEBUG 01-07 10:14:15.817788.817788 mlpmodule.py:838] group einsum cost 0.018517732620239258 s
DEBUG 01-07 10:14:15.818399.818399 mlpmodule.py:846] cpy2cputensor cost 0.00042557716369628906 s
DEBUG 01-07 10:14:15.820871.820871 cuda_h.py:19] end wait_cetm_experts cost 0.03127717971801758 seconds
DEBUG 01-07 10:14:15.820569.820569 cuda_h.py:10] start gpu_sexperts
DEBUG 01-07 10:14:15.821515.821515 cuda_h.py:19] end gpu_sexperts cost 0.0005128383636474609 seconds
DEBUG 01-07 10:14:15.821550.821550 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-07 10:14:15.821923.821923 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.47955322265625e-05 seconds
DEBUG 01-07 10:14:15.821057.821057 cuda_h.py:10] start wait_experts_multi_device
INFO 01-07 10:14:15.821674.821674 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 9441269a-9285-4ffa-84bf-cda6bd30526c
INFO 01-07 10:14:15.825556.825556 client.py:127] Model loaded
INFO 01-07 10:14:15.825167.825167 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 1daedcaa-c383-4576-a9ac-baf946e82d21
DEBUG 01-07 10:14:15.829526.829526 mlpmodule.py:707]  experts func einsum cost 0.03946638107299805 s
INFO 01-07 10:14:15.829059.829059 client.py:127] Model loaded
DEBUG 01-07 10:14:15.829723.829723 cuda_h.py:19] end wait_experts_multi_device cost 0.008393526077270508 seconds
DEBUG 01-07 10:14:15.829194.829194 cuda_h.py:10] start gpu_experts_multi_device
DEBUG 01-07 10:14:15.830209.830209 lmp.py:867]   Computing 23 experts on cuda:2...
DEBUG 01-07 10:14:15.831393.831393 mlpmodule.py:533] gpu group tensors cost 0.0005002021789550781 s
DEBUG 01-07 10:14:15.832723.832723 mlpmodule.py:566] gpu pad cost 0.001268148422241211 s
DEBUG 01-07 10:14:15.833696.833696 mlpmodule.py:584] gpu group einsum cost 0.0005109310150146484 s
DEBUG 01-07 10:14:15.834921.834921 mlpmodule.py:656] gpu experts func einsum cost 0.004191398620605469 s
DEBUG 01-07 10:14:15.835387.835387 lmp.py:867]   Computing 22 experts on cuda:1...
DEBUG 01-07 10:14:15.835316.835316 mlpmodule.py:533] gpu group tensors cost 0.0003714561462402344 s
DEBUG 01-07 10:14:15.836862.836862 mlpmodule.py:566] gpu pad cost 0.001016378402709961 s
DEBUG 01-07 10:14:15.837335.837335 mlpmodule.py:584] gpu group einsum cost 0.0004298686981201172 s
DEBUG 01-07 10:14:15.838184.838184 mlpmodule.py:656] gpu experts func einsum cost 0.003539562225341797 s
DEBUG 01-07 10:14:15.839929.839929 cuda_h.py:19] end gpu_experts_multi_device cost 0.009046077728271484 seconds
DEBUG 01-07 10:14:15.839912.839912 cuda_h.py:19] end layer_moe_generate_multi_device_19 cost 0.06013965606689453 seconds
DEBUG 01-07 10:14:15.839397.839397 lmp.py:194] -------------------------------- end prefill layer 19 --------------------------------
DEBUG 01-07 10:14:15.839359.839359 lmp.py:153] -------------------------------- start prefill layer 20 --------------------------------
DEBUG 01-07 10:14:15.839817.839817 cuda_h.py:10] start start_load_qkvogn_s_weight_l_21
DEBUG 01-07 10:14:15.839142.839142 cuda_h.py:10] start start_load_qkvogn_s_weight_l_21
DEBUG 01-07 10:14:15.839263.839263 cuda_h.py:19] end start_load_qkvogn_s_weight_l_21 cost 2.7894973754882812e-05 seconds
DEBUG 01-07 10:14:15.839012.839012 cuda_h.py:19] end start_load_qkvogn_s_weight_l_21 cost 5.745887756347656e-05 seconds
DEBUG 01-07 10:14:15.839370.839370 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-07 10:14:15.839385.839385 cuda_h.py:10] start sllm_worker_task
DEBUG 01-07 10:14:15.839561.839561 mlpmodule.py:367] cuda:1 cuda:1
DEBUG 01-07 10:14:15.839469.839469 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 10:14:15.839426.839426 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 10:14:15.840212.840212 cuda_h.py:19] end allocate_cuda_memory cost 0.0002865791320800781 seconds
DEBUG 01-07 10:14:15.840844.840844 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 10:14:15.840938.840938 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 10:14:15.840377.840377 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 10:14:15.840848.840848 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 4013346b-51a1-4b3e-94ee-c30f4680c2ae
DEBUG 01-07 10:14:15.840519.840519 client.py:106] call stub.LoadModelAsync
DEBUG 01-07 10:14:15.840520.840520 cuda_h.py:10] start self_attn
INFO 01-07 10:14:15.841122.841122 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 4013346b-51a1-4b3e-94ee-c30f4680c2ae
DEBUG 01-07 10:14:15.841428.841428 cuda_h.py:19] end load_into_gpu_async cost 0.0009932518005371094 seconds
DEBUG 01-07 10:14:15.841462.841462 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 10:14:15.841406.841406 cuda_h.py:19] end restore_tensors2 cost 6.67572021484375e-05 seconds
DEBUG 01-07 10:14:15.841116.841116 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0016167163848876953 seconds
INFO 01-07 10:14:15.841688.841688 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 4013346b-51a1-4b3e-94ee-c30f4680c2ae
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-07 10:14:15.844548.844548 cuda_h.py:19] end self_attn cost 0.0037505626678466797 seconds
DEBUG 01-07 10:14:15.844962.844962 cuda_h.py:19] end iln_self_attn_paln cost 0.005183696746826172 seconds
DEBUG 01-07 10:14:15.844838.844838 cuda_h.py:10] start layer_moe_generate_multi_device_20
DEBUG 01-07 10:14:15.844978.844978 cuda_h.py:10] start gate
DEBUG 01-07 10:14:15.845934.845934 cuda_h.py:19] end gate cost 0.0006363391876220703 seconds
DEBUG 01-07 10:14:15.845333.845333 cuda_h.py:10] start experts_map_get
DEBUG 01-07 10:14:15.846300.846300 lmp.py:744] 
DEBUG 01-07 10:14:15.846300.846300 lmp.py:744] Expert Token Distribution & Multi-Device Allocation:
DEBUG 01-07 10:14:15.846169.846169 lmp.py:745]   Total experts: 64
DEBUG 01-07 10:14:15.846488.846488 lmp.py:746]   CPU experts: 19 (30%)
DEBUG 01-07 10:14:15.846038.846038 lmp.py:747]   GPU experts: 45 (70%)
DEBUG 01-07 10:14:15.846397.846397 lmp.py:748]   Number of GPU devices: 2
DEBUG 01-07 10:14:15.846086.846086 lmp.py:749] 
DEBUG 01-07 10:14:15.846086.846086 lmp.py:749]   Expert ID | Tokens | Device
DEBUG 01-07 10:14:15.846490.846490 lmp.py:750]   -----------------------------------
DEBUG 01-07 10:14:15.846332.846332 lmp.py:767]   Expert 54 |     22 | CPU
DEBUG 01-07 10:14:15.846498.846498 lmp.py:767]   Expert  3 |     34 | CPU
DEBUG 01-07 10:14:15.846949.846949 lmp.py:767]   Expert  8 |     40 | CPU
DEBUG 01-07 10:14:15.846162.846162 lmp.py:767]   Expert 28 |     43 | CPU
DEBUG 01-07 10:14:15.846613.846613 lmp.py:767]   Expert 63 |     53 | CPU
DEBUG 01-07 10:14:15.846064.846064 lmp.py:767]   Expert 43 |     54 | CPU
DEBUG 01-07 10:14:15.846514.846514 lmp.py:767]   Expert 38 |     66 | CPU
DEBUG 01-07 10:14:15.846965.846965 lmp.py:767]   Expert 36 |     67 | CPU
DEBUG 01-07 10:14:15.846655.846655 lmp.py:767]   Expert  6 |     84 | CPU
DEBUG 01-07 10:14:15.846582.846582 lmp.py:767]   Expert 39 |     92 | CPU
DEBUG 01-07 10:14:15.846510.846510 lmp.py:767]   Expert 57 |    100 | CPU
DEBUG 01-07 10:14:15.846438.846438 lmp.py:767]   Expert 12 |    102 | CPU
DEBUG 01-07 10:14:15.846650.846650 lmp.py:767]   Expert 41 |    107 | CPU
DEBUG 01-07 10:14:15.846386.846386 lmp.py:767]   Expert 52 |    108 | CPU
DEBUG 01-07 10:14:15.846360.846360 lmp.py:767]   Expert 19 |    115 | CPU
DEBUG 01-07 10:14:15.846572.846572 lmp.py:767]   Expert 47 |    127 | CPU
DEBUG 01-07 10:14:15.846546.846546 lmp.py:767]   Expert 22 |    131 | CPU
DEBUG 01-07 10:14:15.846520.846520 lmp.py:767]   Expert 13 |    133 | CPU
DEBUG 01-07 10:14:15.846494.846494 lmp.py:767]   Expert 46 |    152 | CPU
DEBUG 01-07 10:14:15.846899.846899 lmp.py:767]   Expert 50 |    153 | GPU0(cuda:1)
DEBUG 01-07 10:14:15.846304.846304 lmp.py:767]   Expert 40 |    163 | GPU0(cuda:1)
DEBUG 01-07 10:14:15.846470.846470 lmp.py:767]   Expert 20 |    165 | GPU1(cuda:2)
DEBUG 01-07 10:14:15.846874.846874 lmp.py:767]   Expert 24 |    165 | GPU1(cuda:2)
DEBUG 01-07 10:14:15.846994.846994 lmp.py:767]   Expert 55 |    167 | GPU0(cuda:1)
DEBUG 01-07 10:14:15.846875.846875 lmp.py:767]   Expert 37 |    168 | GPU1(cuda:2)
DEBUG 01-07 10:14:15.846518.846518 lmp.py:767]   Expert 53 |    172 | GPU0(cuda:1)
DEBUG 01-07 10:14:15.846161.846161 lmp.py:767]   Expert 21 |    177 | GPU0(cuda:1)
DEBUG 01-07 10:14:15.846804.846804 lmp.py:767]   Expert 23 |    177 | GPU1(cuda:2)
DEBUG 01-07 10:14:15.846732.846732 lmp.py:767]   Expert 49 |    179 | GPU1(cuda:2)
DEBUG 01-07 10:14:15.846660.846660 lmp.py:767]   Expert 61 |    181 | GPU0(cuda:1)
DEBUG 01-07 10:14:15.846826.846826 lmp.py:767]   Expert 33 |    184 | GPU1(cuda:2)
DEBUG 01-07 10:14:15.846515.846515 lmp.py:767]   Expert 42 |    185 | GPU0(cuda:1)
DEBUG 01-07 10:14:15.846443.846443 lmp.py:767]   Expert  2 |    186 | GPU0(cuda:1)
DEBUG 01-07 10:14:15.846609.846609 lmp.py:767]   Expert 18 |    195 | GPU1(cuda:2)
DEBUG 01-07 10:14:15.846014.846014 lmp.py:767]   Expert 16 |    199 | GPU1(cuda:2)
DEBUG 01-07 10:14:15.846180.846180 lmp.py:767]   Expert 32 |    199 | GPU0(cuda:1)
DEBUG 01-07 10:14:15.846061.846061 lmp.py:767]   Expert  0 |    200 | GPU1(cuda:2)
DEBUG 01-07 10:14:15.846181.846181 lmp.py:767]   Expert  5 |    202 | GPU1(cuda:2)
DEBUG 01-07 10:14:15.846824.846824 lmp.py:767]   Expert 14 |    202 | GPU0(cuda:1)
DEBUG 01-07 10:14:15.846705.846705 lmp.py:767]   Expert 30 |    203 | GPU0(cuda:1)
DEBUG 01-07 10:14:15.846587.846587 lmp.py:767]   Expert  7 |    205 | GPU0(cuda:1)
DEBUG 01-07 10:14:15.846515.846515 lmp.py:767]   Expert 31 |    212 | GPU1(cuda:2)
DEBUG 01-07 10:14:15.846681.846681 lmp.py:767]   Expert 34 |    213 | GPU1(cuda:2)
DEBUG 01-07 10:14:15.846608.846608 lmp.py:767]   Expert 59 |    218 | GPU0(cuda:1)
DEBUG 01-07 10:14:15.846059.846059 lmp.py:767]   Expert 60 |    219 | GPU0(cuda:1)
DEBUG 01-07 10:14:15.846225.846225 lmp.py:767]   Expert 62 |    220 | GPU1(cuda:2)
DEBUG 01-07 10:14:15.846392.846392 lmp.py:767]   Expert  9 |    223 | GPU1(cuda:2)
DEBUG 01-07 10:14:15.846081.846081 lmp.py:767]   Expert 10 |    226 | GPU1(cuda:2)
DEBUG 01-07 10:14:15.846009.846009 lmp.py:767]   Expert 17 |    226 | GPU0(cuda:1)
DEBUG 01-07 10:14:15.847652.847652 lmp.py:767]   Expert 29 |    230 | GPU0(cuda:1)
DEBUG 01-07 10:14:15.847056.847056 lmp.py:767]   Expert 58 |    234 | GPU1(cuda:2)
DEBUG 01-07 10:14:15.847461.847461 lmp.py:767]   Expert 15 |    238 | GPU0(cuda:1)
DEBUG 01-07 10:14:15.847865.847865 lmp.py:767]   Expert  4 |    240 | GPU1(cuda:2)
DEBUG 01-07 10:14:15.847270.847270 lmp.py:767]   Expert 26 |    245 | GPU0(cuda:1)
DEBUG 01-07 10:14:15.847913.847913 lmp.py:767]   Expert 11 |    252 | GPU1(cuda:2)
DEBUG 01-07 10:14:15.847794.847794 lmp.py:767]   Expert 51 |    256 | GPU0(cuda:1)
DEBUG 01-07 10:14:15.847914.847914 lmp.py:767]   Expert 44 |    269 | GPU1(cuda:2)
DEBUG 01-07 10:14:15.847795.847795 lmp.py:767]   Expert 56 |    283 | GPU0(cuda:1)
DEBUG 01-07 10:14:15.847438.847438 lmp.py:767]   Expert 27 |    292 | GPU0(cuda:1)
DEBUG 01-07 10:14:15.847558.847558 lmp.py:767]   Expert  1 |    339 | GPU1(cuda:2)
DEBUG 01-07 10:14:15.847201.847201 lmp.py:767]   Expert 45 |    366 | GPU0(cuda:1)
DEBUG 01-07 10:14:15.847082.847082 lmp.py:767]   Expert 25 |    469 | GPU1(cuda:2)
DEBUG 01-07 10:14:15.847441.847441 lmp.py:767]   Expert 35 |    522 | GPU1(cuda:2)
DEBUG 01-07 10:14:15.847799.847799 lmp.py:767]   Expert 48 |    639 | GPU0(cuda:1)
DEBUG 01-07 10:14:15.847442.847442 lmp.py:769] 
DEBUG 01-07 10:14:15.847442.847442 lmp.py:769]   Device Token Distribution:
DEBUG 01-07 10:14:15.847800.847800 lmp.py:770]   CPU:   1630 tokens
DEBUG 01-07 10:14:15.847874.847874 lmp.py:774]   cuda:1:   5405 tokens (23 experts)
DEBUG 01-07 10:14:15.847755.847755 lmp.py:774]   cuda:2:   5253 tokens (22 experts)
DEBUG 01-07 10:14:15.847160.847160 lmp.py:775]   Total GPU:  10658 tokens
DEBUG 01-07 10:14:15.847087.847087 lmp.py:776] ============================================================
DEBUG 01-07 10:14:15.847087.847087 lmp.py:776] 
DEBUG 01-07 10:14:15.847691.847691 cuda_h.py:19] end experts_map_get cost 0.0017445087432861328 seconds
DEBUG 01-07 10:14:15.847811.847811 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model_multi_device
DEBUG 01-07 10:14:15.847395.847395 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 10:14:15.847174.847174 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 10:14:15.847323.847323 cuda_h.py:19] end allocate_cuda_memory cost 0.0002880096435546875 seconds
DEBUG 01-07 10:14:15.847849.847849 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 10:14:15.847036.847036 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 10:14:15.848037.848037 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 10:14:15.848879.848879 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 377c2208-c60c-4ce9-ab31-17871c1f9554
DEBUG 01-07 10:14:15.848228.848228 client.py:106] call stub.LoadModelAsync
INFO 01-07 10:14:15.848564.848564 client.py:127] Model loaded
DEBUG 01-07 10:14:15.848358.848358 cuda_h.py:19] end sllm_worker_task cost 0.00894618034362793 seconds
INFO 01-07 10:14:15.849058.849058 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 377c2208-c60c-4ce9-ab31-17871c1f9554
DEBUG 01-07 10:14:15.849431.849431 cuda_h.py:19] end load_into_gpu_async cost 0.0011320114135742188 seconds
DEBUG 01-07 10:14:15.849657.849657 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 10:14:15.849700.849700 cuda_h.py:19] end restore_tensors2 cost 0.0002522468566894531 seconds
DEBUG 01-07 10:14:15.849184.849184 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.001998424530029297 seconds
DEBUG 01-07 10:14:15.851334.851334 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 10:14:15.851458.851458 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 10:14:15.851797.851797 cuda_h.py:19] end allocate_cuda_memory cost 0.0002129077911376953 seconds
DEBUG 01-07 10:14:15.851733.851733 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 10:14:15.851774.851774 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 10:14:15.851152.851152 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 10:14:15.851848.851848 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, a373d55f-76c7-414b-8961-bd656f17e07a
DEBUG 01-07 10:14:15.852740.852740 client.py:106] call stub.LoadModelAsync
INFO 01-07 10:14:15.852638.852638 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, a373d55f-76c7-414b-8961-bd656f17e07a
DEBUG 01-07 10:14:15.852705.852705 cuda_h.py:19] end load_into_gpu_async cost 0.0009307861328125 seconds
DEBUG 01-07 10:14:15.852024.852024 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 10:14:15.853966.853966 cuda_h.py:19] end restore_tensors2 cost 0.00021219253540039062 seconds
DEBUG 01-07 10:14:15.853451.853451 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0016512870788574219 seconds
DEBUG 01-07 10:14:15.854842.854842 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model_multi_device cost 0.007440805435180664 seconds
DEBUG 01-07 10:14:15.854095.854095 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-07 10:14:15.854727.854727 lmp.py:816] 
DEBUG 01-07 10:14:15.854727.854727 lmp.py:816]   Computing 19 experts on CPU...
DEBUG 01-07 10:14:15.855709.855709 cuda_h.py:19] end cpu_experts_submit cost 0.00010728836059570312 seconds
DEBUG 01-07 10:14:15.855597.855597 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-07 10:14:15.866541.866541 mlpmodule.py:749] group tensors cost 0.010857820510864258 s
DEBUG 01-07 10:14:15.868129.868129 mlpmodule.py:787] pad cost 0.0015211105346679688 s
DEBUG 01-07 10:14:15.868604.868604 mlpmodule.py:793] create cpu tensor cost 5.698204040527344e-05 s
DEBUG 01-07 10:14:15.868455.868455 mlpmodule.py:798] move to cpu cost 4.458427429199219e-05 s
DEBUG 01-07 10:14:15.876898.876898 mlpmodule.py:812] group_w3: shape=torch.Size([19, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=54788096
DEBUG 01-07 10:14:15.876799.876799 mlpmodule.py:813] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-07 10:14:15.876233.876233 mlpmodule.py:818] group_w3 first element: 0.0205078125
WARNING 01-07 10:14:15.876669.876669 mlpmodule.py:828] start einsum2
DEBUG 01-07 10:14:15.889763.889763 mlpmodule.py:838] group einsum cost 0.021162986755371094 s
DEBUG 01-07 10:14:15.890361.890361 mlpmodule.py:846] cpy2cputensor cost 0.0004470348358154297 s
DEBUG 01-07 10:14:15.893649.893649 cuda_h.py:19] end wait_cetm_experts cost 0.03809189796447754 seconds
DEBUG 01-07 10:14:15.893347.893347 cuda_h.py:10] start gpu_sexperts
DEBUG 01-07 10:14:15.893949.893949 cuda_h.py:19] end gpu_sexperts cost 0.0005049705505371094 seconds
DEBUG 01-07 10:14:15.893269.893269 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-07 10:14:15.893734.893734 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.4318695068359375e-05 seconds
DEBUG 01-07 10:14:15.894914.894914 cuda_h.py:10] start wait_experts_multi_device
INFO 01-07 10:14:15.894876.894876 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 377c2208-c60c-4ce9-ab31-17871c1f9554
INFO 01-07 10:14:15.895112.895112 client.py:127] Model loaded
INFO 01-07 10:14:15.895465.895465 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, a373d55f-76c7-414b-8961-bd656f17e07a
INFO 01-07 10:14:15.896599.896599 client.py:127] Model loaded
DEBUG 01-07 10:14:15.896097.896097 cuda_h.py:19] end wait_experts_multi_device cost 0.002281665802001953 seconds
DEBUG 01-07 10:14:15.896423.896423 cuda_h.py:10] start gpu_experts_multi_device
DEBUG 01-07 10:14:15.896266.896266 lmp.py:867]   Computing 22 experts on cuda:2...
DEBUG 01-07 10:14:15.897608.897608 mlpmodule.py:533] gpu group tensors cost 0.00047278404235839844 s
DEBUG 01-07 10:14:15.898512.898512 mlpmodule.py:566] gpu pad cost 0.0011990070343017578 s
DEBUG 01-07 10:14:15.899969.899969 mlpmodule.py:584] gpu group einsum cost 0.0005512237548828125 s
DEBUG 01-07 10:14:15.901294.901294 mlpmodule.py:656] gpu experts func einsum cost 0.004350423812866211 s
DEBUG 01-07 10:14:15.901207.901207 mlpmodule.py:707]  experts func einsum cost 0.046373844146728516 s
DEBUG 01-07 10:14:15.901991.901991 lmp.py:867]   Computing 23 experts on cuda:1...
DEBUG 01-07 10:14:15.902236.902236 mlpmodule.py:533] gpu group tensors cost 0.0004703998565673828 s
DEBUG 01-07 10:14:15.903921.903921 mlpmodule.py:566] gpu pad cost 0.001219034194946289 s
DEBUG 01-07 10:14:15.904464.904464 mlpmodule.py:584] gpu group einsum cost 0.00034117698669433594 s
DEBUG 01-07 10:14:15.906831.906831 mlpmodule.py:656] gpu experts func einsum cost 0.0039997100830078125 s
DEBUG 01-07 10:14:15.906371.906371 cuda_h.py:19] end gpu_experts_multi_device cost 0.009888410568237305 seconds
DEBUG 01-07 10:14:15.906872.906872 cuda_h.py:19] end layer_moe_generate_multi_device_20 cost 0.06151151657104492 seconds
DEBUG 01-07 10:14:15.906184.906184 lmp.py:194] -------------------------------- end prefill layer 20 --------------------------------
DEBUG 01-07 10:14:15.906709.906709 lmp.py:153] -------------------------------- start prefill layer 21 --------------------------------
DEBUG 01-07 10:14:15.906690.906690 cuda_h.py:10] start start_load_qkvogn_s_weight_l_22
DEBUG 01-07 10:14:15.906492.906492 cuda_h.py:10] start start_load_qkvogn_s_weight_l_22
DEBUG 01-07 10:14:15.906759.906759 cuda_h.py:19] end start_load_qkvogn_s_weight_l_22 cost 2.9087066650390625e-05 seconds
DEBUG 01-07 10:14:15.906554.906554 cuda_h.py:19] end start_load_qkvogn_s_weight_l_22 cost 5.888938903808594e-05 seconds
DEBUG 01-07 10:14:15.906151.906151 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-07 10:14:15.906941.906941 mlpmodule.py:367] cuda:1 cuda:1
DEBUG 01-07 10:14:15.906314.906314 cuda_h.py:10] start sllm_worker_task
DEBUG 01-07 10:14:15.907455.907455 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 10:14:15.907715.907715 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 10:14:15.907097.907097 cuda_h.py:19] end allocate_cuda_memory cost 0.00028204917907714844 seconds
DEBUG 01-07 10:14:15.907013.907013 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 10:14:15.907107.907107 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 10:14:15.907976.907976 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 10:14:15.907772.907772 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 4b8cea39-57f3-4988-a1e4-145a23af8d95
DEBUG 01-07 10:14:15.907066.907066 client.py:106] call stub.LoadModelAsync
DEBUG 01-07 10:14:15.907637.907637 cuda_h.py:10] start self_attn
INFO 01-07 10:14:15.908079.908079 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 4b8cea39-57f3-4988-a1e4-145a23af8d95
DEBUG 01-07 10:14:15.908683.908683 cuda_h.py:19] end load_into_gpu_async cost 0.000986337661743164 seconds
DEBUG 01-07 10:14:15.908386.908386 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 10:14:15.908369.908369 cuda_h.py:19] end restore_tensors2 cost 6.747245788574219e-05 seconds
DEBUG 01-07 10:14:15.908456.908456 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0015845298767089844 seconds
INFO 01-07 10:14:15.908577.908577 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 4b8cea39-57f3-4988-a1e4-145a23af8d95
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-07 10:14:15.911823.911823 cuda_h.py:19] end self_attn cost 0.003728628158569336 seconds
DEBUG 01-07 10:14:15.911039.911039 cuda_h.py:19] end iln_self_attn_paln cost 0.005118846893310547 seconds
DEBUG 01-07 10:14:15.912113.912113 cuda_h.py:10] start layer_moe_generate_multi_device_21
DEBUG 01-07 10:14:15.912969.912969 cuda_h.py:10] start gate
DEBUG 01-07 10:14:15.912038.912038 cuda_h.py:19] end gate cost 0.0006489753723144531 seconds
DEBUG 01-07 10:14:15.912152.912152 cuda_h.py:10] start experts_map_get
DEBUG 01-07 10:14:15.913781.913781 lmp.py:744] 
DEBUG 01-07 10:14:15.913781.913781 lmp.py:744] Expert Token Distribution & Multi-Device Allocation:
DEBUG 01-07 10:14:15.913412.913412 lmp.py:745]   Total experts: 64
DEBUG 01-07 10:14:15.913207.913207 lmp.py:746]   CPU experts: 19 (30%)
DEBUG 01-07 10:14:15.913235.913235 lmp.py:747]   GPU experts: 45 (70%)
DEBUG 01-07 10:14:15.913639.913639 lmp.py:748]   Number of GPU devices: 2
DEBUG 01-07 10:14:15.913852.913852 lmp.py:749] 
DEBUG 01-07 10:14:15.913852.913852 lmp.py:749]   Expert ID | Tokens | Device
DEBUG 01-07 10:14:15.913779.913779 lmp.py:750]   -----------------------------------
DEBUG 01-07 10:14:15.913429.913429 lmp.py:767]   Expert  9 |     30 | CPU
DEBUG 01-07 10:14:15.913357.913357 lmp.py:767]   Expert 44 |     33 | CPU
DEBUG 01-07 10:14:15.913808.913808 lmp.py:767]   Expert 11 |     34 | CPU
DEBUG 01-07 10:14:15.913782.913782 lmp.py:767]   Expert 56 |     57 | CPU
DEBUG 01-07 10:14:15.913471.913471 lmp.py:767]   Expert 54 |     80 | CPU
DEBUG 01-07 10:14:15.913399.913399 lmp.py:767]   Expert  7 |     88 | CPU
DEBUG 01-07 10:14:15.913611.913611 lmp.py:767]   Expert 62 |     91 | CPU
DEBUG 01-07 10:14:15.913585.913585 lmp.py:767]   Expert 47 |     95 | CPU
DEBUG 01-07 10:14:15.913798.913798 lmp.py:767]   Expert 51 |    104 | CPU
DEBUG 01-07 10:14:15.913010.913010 lmp.py:767]   Expert 60 |    104 | CPU
DEBUG 01-07 10:14:15.913223.913223 lmp.py:767]   Expert 41 |    108 | CPU
DEBUG 01-07 10:14:15.913104.913104 lmp.py:767]   Expert 52 |    108 | CPU
DEBUG 01-07 10:14:15.913793.913793 lmp.py:767]   Expert 22 |    113 | CPU
DEBUG 01-07 10:14:15.913006.913006 lmp.py:767]   Expert 53 |    113 | CPU
DEBUG 01-07 10:14:15.913457.913457 lmp.py:767]   Expert  6 |    126 | CPU
DEBUG 01-07 10:14:15.913431.913431 lmp.py:767]   Expert  8 |    126 | CPU
DEBUG 01-07 10:14:15.913643.913643 lmp.py:767]   Expert  1 |    128 | CPU
DEBUG 01-07 10:14:15.913856.913856 lmp.py:767]   Expert 32 |    129 | CPU
DEBUG 01-07 10:14:15.913830.913830 lmp.py:767]   Expert  2 |    131 | CPU
DEBUG 01-07 10:14:15.913188.913188 lmp.py:767]   Expert 48 |    132 | GPU0(cuda:1)
DEBUG 01-07 10:14:15.913546.913546 lmp.py:767]   Expert 27 |    134 | GPU1(cuda:2)
DEBUG 01-07 10:14:15.913189.913189 lmp.py:767]   Expert 23 |    136 | GPU1(cuda:2)
DEBUG 01-07 10:14:15.913355.913355 lmp.py:767]   Expert 35 |    141 | GPU0(cuda:1)
DEBUG 01-07 10:14:15.913521.913521 lmp.py:767]   Expert 39 |    142 | GPU1(cuda:2)
DEBUG 01-07 10:14:15.913926.913926 lmp.py:767]   Expert 59 |    143 | GPU0(cuda:1)
DEBUG 01-07 10:14:15.913092.913092 lmp.py:767]   Expert 26 |    144 | GPU0(cuda:1)
DEBUG 01-07 10:14:15.913497.913497 lmp.py:767]   Expert 14 |    148 | GPU1(cuda:2)
DEBUG 01-07 10:14:15.913663.913663 lmp.py:767]   Expert 50 |    154 | GPU1(cuda:2)
DEBUG 01-07 10:14:15.913544.913544 lmp.py:767]   Expert 46 |    166 | GPU0(cuda:1)
DEBUG 01-07 10:14:15.913949.913949 lmp.py:767]   Expert 34 |    169 | GPU1(cuda:2)
DEBUG 01-07 10:14:15.913638.913638 lmp.py:767]   Expert 24 |    170 | GPU1(cuda:2)
DEBUG 01-07 10:14:15.913566.913566 lmp.py:767]   Expert 38 |    170 | GPU0(cuda:1)
DEBUG 01-07 10:14:15.913255.913255 lmp.py:767]   Expert  0 |    173 | GPU0(cuda:1)
DEBUG 01-07 10:14:15.913421.913421 lmp.py:767]   Expert  4 |    176 | GPU1(cuda:2)
DEBUG 01-07 10:14:15.913110.913110 lmp.py:767]   Expert 40 |    177 | GPU1(cuda:2)
DEBUG 01-07 10:14:15.913800.913800 lmp.py:767]   Expert 49 |    177 | GPU0(cuda:1)
DEBUG 01-07 10:14:15.913728.913728 lmp.py:767]   Expert  5 |    185 | GPU0(cuda:1)
DEBUG 01-07 10:14:15.913655.913655 lmp.py:767]   Expert 63 |    189 | GPU1(cuda:2)
DEBUG 01-07 10:14:15.913060.913060 lmp.py:767]   Expert 19 |    191 | GPU0(cuda:1)
DEBUG 01-07 10:14:15.914464.914464 lmp.py:767]   Expert 13 |    197 | GPU1(cuda:2)
DEBUG 01-07 10:14:15.914392.914392 lmp.py:767]   Expert 29 |    202 | GPU1(cuda:2)
DEBUG 01-07 10:14:15.914843.914843 lmp.py:767]   Expert 43 |    202 | GPU0(cuda:1)
DEBUG 01-07 10:14:15.914771.914771 lmp.py:767]   Expert 57 |    206 | GPU0(cuda:1)
DEBUG 01-07 10:14:15.914460.914460 lmp.py:767]   Expert 61 |    209 | GPU1(cuda:2)
DEBUG 01-07 10:14:15.914626.914626 lmp.py:767]   Expert 33 |    225 | GPU0(cuda:1)
DEBUG 01-07 10:14:15.914315.914315 lmp.py:767]   Expert 31 |    229 | GPU1(cuda:2)
DEBUG 01-07 10:14:15.914197.914197 lmp.py:767]   Expert 20 |    246 | GPU0(cuda:1)
DEBUG 01-07 10:14:15.914078.914078 lmp.py:767]   Expert  3 |    252 | GPU0(cuda:1)
DEBUG 01-07 10:14:15.914244.914244 lmp.py:767]   Expert 16 |    252 | GPU1(cuda:2)
DEBUG 01-07 10:14:15.914172.914172 lmp.py:767]   Expert 15 |    259 | GPU1(cuda:2)
DEBUG 01-07 10:14:15.914861.914861 lmp.py:767]   Expert 37 |    263 | GPU0(cuda:1)
DEBUG 01-07 10:14:15.914551.914551 lmp.py:767]   Expert 36 |    277 | GPU1(cuda:2)
DEBUG 01-07 10:14:15.914240.914240 lmp.py:767]   Expert 18 |    279 | GPU0(cuda:1)
DEBUG 01-07 10:14:15.914929.914929 lmp.py:767]   Expert 12 |    283 | GPU1(cuda:2)
DEBUG 01-07 10:14:15.914857.914857 lmp.py:767]   Expert 28 |    304 | GPU0(cuda:1)
DEBUG 01-07 10:14:15.914262.914262 lmp.py:767]   Expert 17 |    310 | GPU1(cuda:2)
DEBUG 01-07 10:14:15.914381.914381 lmp.py:767]   Expert 55 |    311 | GPU0(cuda:1)
DEBUG 01-07 10:14:15.914740.914740 lmp.py:767]   Expert 25 |    317 | GPU1(cuda:2)
DEBUG 01-07 10:14:15.914383.914383 lmp.py:767]   Expert 30 |    323 | GPU0(cuda:1)
DEBUG 01-07 10:14:15.914264.914264 lmp.py:767]   Expert 58 |    342 | GPU1(cuda:2)
DEBUG 01-07 10:14:15.914907.914907 lmp.py:767]   Expert 10 |    364 | GPU0(cuda:1)
DEBUG 01-07 10:14:15.914265.914265 lmp.py:767]   Expert 45 |    382 | GPU1(cuda:2)
DEBUG 01-07 10:14:15.914577.914577 lmp.py:767]   Expert 21 |    390 | GPU1(cuda:2)
DEBUG 01-07 10:14:15.914697.914697 lmp.py:767]   Expert 42 |    649 | GPU0(cuda:1)
DEBUG 01-07 10:14:15.914625.914625 lmp.py:769] 
DEBUG 01-07 10:14:15.914625.914625 lmp.py:769]   Device Token Distribution:
DEBUG 01-07 10:14:15.914268.914268 lmp.py:770]   CPU:   1798 tokens
DEBUG 01-07 10:14:15.914626.914626 lmp.py:774]   cuda:1:   5246 tokens (22 experts)
DEBUG 01-07 10:14:15.914507.914507 lmp.py:774]   cuda:2:   5244 tokens (23 experts)
DEBUG 01-07 10:14:15.914673.914673 lmp.py:775]   Total GPU:  10490 tokens
DEBUG 01-07 10:14:15.914078.914078 lmp.py:776] ============================================================
DEBUG 01-07 10:14:15.914078.914078 lmp.py:776] 
DEBUG 01-07 10:14:15.914873.914873 cuda_h.py:19] end experts_map_get cost 0.0017313957214355469 seconds
DEBUG 01-07 10:14:15.914708.914708 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model_multi_device
DEBUG 01-07 10:14:15.914101.914101 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 10:14:15.914502.914502 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 10:14:15.914233.914233 cuda_h.py:19] end allocate_cuda_memory cost 0.0002257823944091797 seconds
DEBUG 01-07 10:14:15.915420.915420 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 10:14:15.915176.915176 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 10:14:15.915840.915840 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 10:14:15.915774.915774 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, a454da95-df4a-47cd-8c31-dee95602cfbc
DEBUG 01-07 10:14:15.915547.915547 client.py:106] call stub.LoadModelAsync
INFO 01-07 10:14:15.915609.915609 client.py:127] Model loaded
DEBUG 01-07 10:14:15.915151.915151 cuda_h.py:19] end sllm_worker_task cost 0.008906841278076172 seconds
INFO 01-07 10:14:15.916420.916420 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, a454da95-df4a-47cd-8c31-dee95602cfbc
DEBUG 01-07 10:14:15.916125.916125 cuda_h.py:19] end load_into_gpu_async cost 0.0012238025665283203 seconds
DEBUG 01-07 10:14:15.916635.916635 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 10:14:15.916525.916525 cuda_h.py:19] end restore_tensors2 cost 0.0002448558807373047 seconds
DEBUG 01-07 10:14:15.916010.916010 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0020177364349365234 seconds
DEBUG 01-07 10:14:15.918912.918912 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 10:14:15.918334.918334 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 10:14:15.918608.918608 cuda_h.py:19] end allocate_cuda_memory cost 0.0002334117889404297 seconds
DEBUG 01-07 10:14:15.918020.918020 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 10:14:15.918823.918823 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 10:14:15.919771.919771 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 10:14:15.919229.919229 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 9a633d12-72ae-4150-af27-baccd9da1e5c
DEBUG 01-07 10:14:15.919127.919127 client.py:106] call stub.LoadModelAsync
INFO 01-07 10:14:15.920695.920695 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 9a633d12-72ae-4150-af27-baccd9da1e5c
DEBUG 01-07 10:14:15.920286.920286 cuda_h.py:19] end load_into_gpu_async cost 0.0015680789947509766 seconds
DEBUG 01-07 10:14:15.920366.920366 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 10:14:15.920706.920706 cuda_h.py:19] end restore_tensors2 cost 0.00022554397583007812 seconds
DEBUG 01-07 10:14:15.920237.920237 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0023267269134521484 seconds
DEBUG 01-07 10:14:15.922895.922895 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model_multi_device cost 0.008116960525512695 seconds
DEBUG 01-07 10:14:15.922917.922917 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-07 10:14:15.922025.922025 lmp.py:816] 
DEBUG 01-07 10:14:15.922025.922025 lmp.py:816]   Computing 19 experts on CPU...
DEBUG 01-07 10:14:15.922338.922338 cuda_h.py:19] end cpu_experts_submit cost 0.00010752677917480469 seconds
DEBUG 01-07 10:14:15.922942.922942 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-07 10:14:15.932809.932809 mlpmodule.py:749] group tensors cost 0.009745597839355469 s
DEBUG 01-07 10:14:15.934552.934552 mlpmodule.py:787] pad cost 0.0009543895721435547 s
DEBUG 01-07 10:14:15.934827.934827 mlpmodule.py:793] create cpu tensor cost 4.1484832763671875e-05 s
DEBUG 01-07 10:14:15.934300.934300 mlpmodule.py:798] move to cpu cost 3.24249267578125e-05 s
DEBUG 01-07 10:14:15.941669.941669 mlpmodule.py:812] group_w3: shape=torch.Size([19, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=54788096
DEBUG 01-07 10:14:15.942728.942728 mlpmodule.py:813] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-07 10:14:15.942784.942784 mlpmodule.py:818] group_w3 first element: 0.00066375732421875
WARNING 01-07 10:14:15.942630.942630 mlpmodule.py:828] start einsum2
DEBUG 01-07 10:14:15.955849.955849 mlpmodule.py:838] group einsum cost 0.020482301712036133 s
DEBUG 01-07 10:14:15.955207.955207 mlpmodule.py:846] cpy2cputensor cost 0.00040841102600097656 s
DEBUG 01-07 10:14:15.958143.958143 cuda_h.py:19] end wait_cetm_experts cost 0.03542637825012207 seconds
DEBUG 01-07 10:14:15.958557.958557 cuda_h.py:10] start gpu_sexperts
DEBUG 01-07 10:14:15.959058.959058 cuda_h.py:19] end gpu_sexperts cost 0.0005009174346923828 seconds
DEBUG 01-07 10:14:15.959047.959047 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-07 10:14:15.959182.959182 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.6226043701171875e-05 seconds
DEBUG 01-07 10:14:15.959600.959600 cuda_h.py:10] start wait_experts_multi_device
INFO 01-07 10:14:15.959555.959555 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, a454da95-df4a-47cd-8c31-dee95602cfbc
INFO 01-07 10:14:15.960062.960062 client.py:127] Model loaded
INFO 01-07 10:14:15.960090.960090 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 9a633d12-72ae-4150-af27-baccd9da1e5c
INFO 01-07 10:14:15.963418.963418 client.py:127] Model loaded
DEBUG 01-07 10:14:15.963492.963492 cuda_h.py:19] end wait_experts_multi_device cost 0.004275798797607422 seconds
DEBUG 01-07 10:14:15.963056.963056 cuda_h.py:10] start gpu_experts_multi_device
DEBUG 01-07 10:14:15.963879.963879 lmp.py:867]   Computing 23 experts on cuda:2...
DEBUG 01-07 10:14:15.964898.964898 mlpmodule.py:533] gpu group tensors cost 0.0005130767822265625 s
DEBUG 01-07 10:14:15.966830.966830 mlpmodule.py:566] gpu pad cost 0.0012524127960205078 s
DEBUG 01-07 10:14:15.966218.966218 mlpmodule.py:584] gpu group einsum cost 0.00043654441833496094 s
DEBUG 01-07 10:14:15.966975.966975 mlpmodule.py:707]  experts func einsum cost 0.04380083084106445 s
DEBUG 01-07 10:14:15.968553.968553 mlpmodule.py:656] gpu experts func einsum cost 0.004436016082763672 s
DEBUG 01-07 10:14:15.968576.968576 lmp.py:867]   Computing 22 experts on cuda:1...
DEBUG 01-07 10:14:15.969230.969230 mlpmodule.py:533] gpu group tensors cost 0.0004477500915527344 s
DEBUG 01-07 10:14:15.970342.970342 mlpmodule.py:566] gpu pad cost 0.0011143684387207031 s
DEBUG 01-07 10:14:15.971583.971583 mlpmodule.py:584] gpu group einsum cost 0.0004374980926513672 s
DEBUG 01-07 10:14:15.972996.972996 mlpmodule.py:656] gpu experts func einsum cost 0.003751516342163086 s
DEBUG 01-07 10:14:15.973635.973635 cuda_h.py:19] end gpu_experts_multi_device cost 0.009527444839477539 seconds
DEBUG 01-07 10:14:15.973790.973790 cuda_h.py:19] end layer_moe_generate_multi_device_21 cost 0.06110715866088867 seconds
DEBUG 01-07 10:14:15.973923.973923 lmp.py:194] -------------------------------- end prefill layer 21 --------------------------------
DEBUG 01-07 10:14:15.973925.973925 lmp.py:153] -------------------------------- start prefill layer 22 --------------------------------
DEBUG 01-07 10:14:15.973859.973859 cuda_h.py:10] start start_load_qkvogn_s_weight_l_23
DEBUG 01-07 10:14:15.973138.973138 cuda_h.py:10] start start_load_qkvogn_s_weight_l_23
DEBUG 01-07 10:14:15.973782.973782 cuda_h.py:19] end start_load_qkvogn_s_weight_l_23 cost 2.86102294921875e-05 seconds
DEBUG 01-07 10:14:15.973008.973008 cuda_h.py:19] end start_load_qkvogn_s_weight_l_23 cost 5.841255187988281e-05 seconds
DEBUG 01-07 10:14:15.973797.973797 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-07 10:14:15.973812.973812 cuda_h.py:10] start sllm_worker_task
DEBUG 01-07 10:14:15.973907.973907 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 10:14:15.973598.973598 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 10:14:15.974377.974377 cuda_h.py:19] end allocate_cuda_memory cost 0.00029540061950683594 seconds
DEBUG 01-07 10:14:15.974784.974784 mlpmodule.py:367] cuda:1 cuda:1
DEBUG 01-07 10:14:15.974090.974090 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 10:14:15.974689.974689 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 10:14:15.974558.974558 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 10:14:15.974354.974354 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 6d017481-df25-4f48-9abd-910ee903f012
DEBUG 01-07 10:14:15.974025.974025 client.py:106] call stub.LoadModelAsync
DEBUG 01-07 10:14:15.974663.974663 cuda_h.py:10] start self_attn
INFO 01-07 10:14:15.975643.975643 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 6d017481-df25-4f48-9abd-910ee903f012
DEBUG 01-07 10:14:15.975380.975380 cuda_h.py:19] end load_into_gpu_async cost 0.0012471675872802734 seconds
DEBUG 01-07 10:14:15.975083.975083 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 10:14:15.975397.975397 cuda_h.py:19] end restore_tensors2 cost 6.604194641113281e-05 seconds
DEBUG 01-07 10:14:15.975530.975530 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.001971721649169922 seconds
INFO 01-07 10:14:15.975128.975128 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 6d017481-df25-4f48-9abd-910ee903f012
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-07 10:14:15.978384.978384 cuda_h.py:19] end self_attn cost 0.003492116928100586 seconds
DEBUG 01-07 10:14:15.978481.978481 cuda_h.py:19] end iln_self_attn_paln cost 0.004970550537109375 seconds
DEBUG 01-07 10:14:15.978211.978211 cuda_h.py:10] start layer_moe_generate_multi_device_22
DEBUG 01-07 10:14:15.978159.978159 cuda_h.py:10] start gate
DEBUG 01-07 10:14:15.979078.979078 cuda_h.py:19] end gate cost 0.0007147789001464844 seconds
DEBUG 01-07 10:14:15.979716.979716 cuda_h.py:10] start experts_map_get
DEBUG 01-07 10:14:15.979014.979014 lmp.py:744] 
DEBUG 01-07 10:14:15.979014.979014 lmp.py:744] Expert Token Distribution & Multi-Device Allocation:
DEBUG 01-07 10:14:15.979200.979200 lmp.py:745]   Total experts: 64
DEBUG 01-07 10:14:15.979327.979327 lmp.py:746]   CPU experts: 19 (30%)
DEBUG 01-07 10:14:15.979354.979354 lmp.py:747]   GPU experts: 45 (70%)
DEBUG 01-07 10:14:15.979520.979520 lmp.py:748]   Number of GPU devices: 2
DEBUG 01-07 10:14:15.979209.979209 lmp.py:749] 
DEBUG 01-07 10:14:15.979209.979209 lmp.py:749]   Expert ID | Tokens | Device
DEBUG 01-07 10:14:15.979137.979137 lmp.py:750]   -----------------------------------
DEBUG 01-07 10:14:15.980741.980741 lmp.py:767]   Expert 25 |     14 | CPU
DEBUG 01-07 10:14:15.980145.980145 lmp.py:767]   Expert 48 |     31 | CPU
DEBUG 01-07 10:14:15.980073.980073 lmp.py:767]   Expert 45 |     37 | CPU
DEBUG 01-07 10:14:15.980762.980762 lmp.py:767]   Expert  9 |     67 | CPU
DEBUG 01-07 10:14:15.980213.980213 lmp.py:767]   Expert  0 |     81 | CPU
DEBUG 01-07 10:14:15.980187.980187 lmp.py:767]   Expert 43 |     83 | CPU
DEBUG 01-07 10:14:15.980400.980400 lmp.py:767]   Expert 20 |     86 | CPU
DEBUG 01-07 10:14:15.980526.980526 lmp.py:767]   Expert 54 |     86 | CPU
DEBUG 01-07 10:14:15.980931.980931 lmp.py:767]   Expert 57 |     87 | CPU
DEBUG 01-07 10:14:15.980382.980382 lmp.py:767]   Expert  6 |     90 | CPU
DEBUG 01-07 10:14:15.980356.980356 lmp.py:767]   Expert 47 |     92 | CPU
DEBUG 01-07 10:14:15.980568.980568 lmp.py:767]   Expert 36 |     94 | CPU
DEBUG 01-07 10:14:15.980781.980781 lmp.py:767]   Expert 62 |    100 | CPU
DEBUG 01-07 10:14:15.980516.980516 lmp.py:767]   Expert 50 |    104 | CPU
DEBUG 01-07 10:14:15.980490.980490 lmp.py:767]   Expert 61 |    104 | CPU
DEBUG 01-07 10:14:15.980226.980226 lmp.py:767]   Expert 15 |    105 | CPU
DEBUG 01-07 10:14:15.980154.980154 lmp.py:767]   Expert 13 |    106 | CPU
DEBUG 01-07 10:14:15.980366.980366 lmp.py:767]   Expert 37 |    112 | CPU
DEBUG 01-07 10:14:15.980102.980102 lmp.py:767]   Expert 38 |    112 | CPU
DEBUG 01-07 10:14:15.980506.980506 lmp.py:767]   Expert  1 |    114 | GPU1(cuda:2)
DEBUG 01-07 10:14:15.980911.980911 lmp.py:767]   Expert 46 |    118 | GPU0(cuda:1)
DEBUG 01-07 10:14:15.980077.980077 lmp.py:767]   Expert 14 |    120 | GPU1(cuda:2)
DEBUG 01-07 10:14:15.980243.980243 lmp.py:767]   Expert 21 |    127 | GPU0(cuda:1)
DEBUG 01-07 10:14:15.980085.980085 lmp.py:767]   Expert  7 |    135 | GPU1(cuda:2)
DEBUG 01-07 10:14:15.980251.980251 lmp.py:767]   Expert 28 |    139 | GPU0(cuda:1)
DEBUG 01-07 10:14:15.980894.980894 lmp.py:767]   Expert 52 |    142 | GPU1(cuda:2)
DEBUG 01-07 10:14:15.980822.980822 lmp.py:767]   Expert 44 |    146 | GPU0(cuda:1)
DEBUG 01-07 10:14:15.980988.980988 lmp.py:767]   Expert 10 |    152 | GPU0(cuda:1)
DEBUG 01-07 10:14:15.980392.980392 lmp.py:767]   Expert 24 |    152 | GPU1(cuda:2)
DEBUG 01-07 10:14:15.980320.980320 lmp.py:767]   Expert 42 |    158 | GPU1(cuda:2)
DEBUG 01-07 10:14:15.980248.980248 lmp.py:767]   Expert 11 |    160 | GPU0(cuda:1)
DEBUG 01-07 10:14:15.980176.980176 lmp.py:767]   Expert  2 |    165 | GPU1(cuda:2)
DEBUG 01-07 10:14:15.980580.980580 lmp.py:767]   Expert 26 |    169 | GPU0(cuda:1)
DEBUG 01-07 10:14:15.980508.980508 lmp.py:767]   Expert 35 |    172 | GPU1(cuda:2)
DEBUG 01-07 10:14:15.980197.980197 lmp.py:767]   Expert 31 |    175 | GPU0(cuda:1)
DEBUG 01-07 10:14:15.980363.980363 lmp.py:767]   Expert  3 |    180 | GPU1(cuda:2)
DEBUG 01-07 10:14:15.980006.980006 lmp.py:767]   Expert 32 |    187 | GPU0(cuda:1)
DEBUG 01-07 10:14:15.980649.980649 lmp.py:767]   Expert 12 |    189 | GPU1(cuda:2)
DEBUG 01-07 10:14:15.980815.980815 lmp.py:767]   Expert 19 |    191 | GPU0(cuda:1)
DEBUG 01-07 10:14:15.980743.980743 lmp.py:767]   Expert 40 |    204 | GPU1(cuda:2)
DEBUG 01-07 10:14:15.980909.980909 lmp.py:767]   Expert 60 |    208 | GPU0(cuda:1)
DEBUG 01-07 10:14:15.980837.980837 lmp.py:767]   Expert 56 |    211 | GPU1(cuda:2)
DEBUG 01-07 10:14:15.980003.980003 lmp.py:767]   Expert 41 |    220 | GPU0(cuda:1)
DEBUG 01-07 10:14:15.980169.980169 lmp.py:767]   Expert  8 |    232 | GPU1(cuda:2)
DEBUG 01-07 10:14:15.980097.980097 lmp.py:767]   Expert 53 |    233 | GPU0(cuda:1)
DEBUG 01-07 10:14:15.980025.980025 lmp.py:767]   Expert 23 |    234 | GPU1(cuda:2)
DEBUG 01-07 10:14:15.980191.980191 lmp.py:767]   Expert 16 |    237 | GPU1(cuda:2)
DEBUG 01-07 10:14:15.980834.980834 lmp.py:767]   Expert 58 |    237 | GPU0(cuda:1)
DEBUG 01-07 10:14:15.980000.980000 lmp.py:767]   Expert 51 |    239 | GPU0(cuda:1)
DEBUG 01-07 10:14:15.980166.980166 lmp.py:767]   Expert 59 |    244 | GPU1(cuda:2)
DEBUG 01-07 10:14:15.980571.980571 lmp.py:767]   Expert  4 |    246 | GPU0(cuda:1)
DEBUG 01-07 10:14:15.980498.980498 lmp.py:767]   Expert 55 |    261 | GPU1(cuda:2)
DEBUG 01-07 10:14:15.980426.980426 lmp.py:767]   Expert 49 |    272 | GPU0(cuda:1)
DEBUG 01-07 10:14:15.980354.980354 lmp.py:767]   Expert 29 |    277 | GPU1(cuda:2)
DEBUG 01-07 10:14:15.980043.980043 lmp.py:767]   Expert 18 |    278 | GPU0(cuda:1)
DEBUG 01-07 10:14:15.980971.980971 lmp.py:767]   Expert 34 |    287 | GPU1(cuda:2)
DEBUG 01-07 10:14:15.980137.980137 lmp.py:767]   Expert 63 |    297 | GPU0(cuda:1)
DEBUG 01-07 10:14:15.980826.980826 lmp.py:767]   Expert 27 |    363 | GPU1(cuda:2)
DEBUG 01-07 10:14:15.980516.980516 lmp.py:767]   Expert 39 |    375 | GPU0(cuda:1)
DEBUG 01-07 10:14:15.981397.981397 lmp.py:767]   Expert 17 |    385 | GPU1(cuda:2)
DEBUG 01-07 10:14:15.981563.981563 lmp.py:767]   Expert 22 |    434 | GPU0(cuda:1)
DEBUG 01-07 10:14:15.981252.981252 lmp.py:767]   Expert 30 |    453 | GPU1(cuda:2)
DEBUG 01-07 10:14:15.981180.981180 lmp.py:767]   Expert 33 |    463 | GPU1(cuda:2)
DEBUG 01-07 10:14:15.981108.981108 lmp.py:767]   Expert  5 |    716 | GPU0(cuda:1)
DEBUG 01-07 10:14:15.981082.981082 lmp.py:769] 
DEBUG 01-07 10:14:15.981082.981082 lmp.py:769]   Device Token Distribution:
DEBUG 01-07 10:14:15.981010.981010 lmp.py:770]   CPU:   1591 tokens
DEBUG 01-07 10:14:15.981653.981653 lmp.py:774]   cuda:1:   5319 tokens (22 experts)
DEBUG 01-07 10:14:15.981057.981057 lmp.py:774]   cuda:2:   5378 tokens (23 experts)
DEBUG 01-07 10:14:15.981700.981700 lmp.py:775]   Total GPU:  10697 tokens
DEBUG 01-07 10:14:15.981436.981436 lmp.py:776] ============================================================
DEBUG 01-07 10:14:15.981436.981436 lmp.py:776] 
DEBUG 01-07 10:14:15.981039.981039 cuda_h.py:19] end experts_map_get cost 0.0017199516296386719 seconds
DEBUG 01-07 10:14:15.981636.981636 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model_multi_device
DEBUG 01-07 10:14:15.981220.981220 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 10:14:15.981760.981760 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 10:14:15.982604.982604 cuda_h.py:19] end allocate_cuda_memory cost 0.0006241798400878906 seconds
DEBUG 01-07 10:14:15.982592.982592 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 10:14:15.982872.982872 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 10:14:15.982065.982065 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 10:14:15.982907.982907 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, f008d92b-81a8-4615-a4cc-9bfcd3824cc8
DEBUG 01-07 10:14:15.982249.982249 client.py:106] call stub.LoadModelAsync
INFO 01-07 10:14:15.982885.982885 client.py:127] Model loaded
DEBUG 01-07 10:14:15.982318.982318 cuda_h.py:19] end sllm_worker_task cost 0.009291410446166992 seconds
INFO 01-07 10:14:15.983779.983779 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, f008d92b-81a8-4615-a4cc-9bfcd3824cc8
DEBUG 01-07 10:14:15.983245.983245 cuda_h.py:19] end load_into_gpu_async cost 0.0016417503356933594 seconds
DEBUG 01-07 10:14:15.983471.983471 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 10:14:15.984678.984678 cuda_h.py:19] end restore_tensors2 cost 0.00023365020751953125 seconds
DEBUG 01-07 10:14:15.984494.984494 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0028128623962402344 seconds
DEBUG 01-07 10:14:15.985112.985112 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 10:14:15.986157.986157 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 10:14:15.986338.986338 cuda_h.py:19] end allocate_cuda_memory cost 0.0002357959747314453 seconds
DEBUG 01-07 10:14:15.986466.986466 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 10:14:15.986268.986268 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 10:14:15.986693.986693 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 10:14:15.986389.986389 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 669391c8-cfb7-476c-9f61-590cef627ace
DEBUG 01-07 10:14:15.986579.986579 client.py:106] call stub.LoadModelAsync
INFO 01-07 10:14:15.988177.988177 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 669391c8-cfb7-476c-9f61-590cef627ace
DEBUG 01-07 10:14:15.988245.988245 cuda_h.py:19] end load_into_gpu_async cost 0.0018773078918457031 seconds
DEBUG 01-07 10:14:15.988564.988564 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 10:14:15.988202.988202 cuda_h.py:19] end restore_tensors2 cost 0.0002269744873046875 seconds
DEBUG 01-07 10:14:15.988879.988879 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0026504993438720703 seconds
DEBUG 01-07 10:14:15.990716.990716 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model_multi_device cost 0.009302139282226562 seconds
DEBUG 01-07 10:14:15.990307.990307 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-07 10:14:15.990986.990986 lmp.py:816] 
DEBUG 01-07 10:14:15.990986.990986 lmp.py:816]   Computing 19 experts on CPU...
DEBUG 01-07 10:14:15.990921.990921 cuda_h.py:19] end cpu_experts_submit cost 0.0001087188720703125 seconds
DEBUG 01-07 10:14:15.990810.990810 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-07 10:14:15.997540.997540 mlpmodule.py:749] group tensors cost 0.007006645202636719 s
DEBUG 01-07 10:14:16.000734.000734 mlpmodule.py:787] pad cost 0.0016529560089111328 s
DEBUG 01-07 10:14:16.000759.000759 mlpmodule.py:793] create cpu tensor cost 6.103515625e-05 s
DEBUG 01-07 10:14:16.000716.000716 mlpmodule.py:798] move to cpu cost 4.8160552978515625e-05 s
DEBUG 01-07 10:14:16.008474.008474 mlpmodule.py:812] group_w3: shape=torch.Size([19, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=54788096
DEBUG 01-07 10:14:16.008056.008056 mlpmodule.py:813] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-07 10:14:16.008967.008967 mlpmodule.py:818] group_w3 first element: -0.018798828125
WARNING 01-07 10:14:16.008562.008562 mlpmodule.py:828] start einsum2
DEBUG 01-07 10:14:16.021877.021877 mlpmodule.py:838] group einsum cost 0.02051544189453125 s
DEBUG 01-07 10:14:16.021155.021155 mlpmodule.py:846] cpy2cputensor cost 0.00038909912109375 s
DEBUG 01-07 10:14:16.024342.024342 cuda_h.py:19] end wait_cetm_experts cost 0.033669233322143555 seconds
DEBUG 01-07 10:14:16.024094.024094 cuda_h.py:10] start gpu_sexperts
DEBUG 01-07 10:14:16.025457.025457 cuda_h.py:19] end gpu_sexperts cost 0.0005040168762207031 seconds
DEBUG 01-07 10:14:16.025068.025068 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-07 10:14:16.025441.025441 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.4318695068359375e-05 seconds
DEBUG 01-07 10:14:16.025098.025098 cuda_h.py:10] start wait_experts_multi_device
INFO 01-07 10:14:16.025622.025622 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, f008d92b-81a8-4615-a4cc-9bfcd3824cc8
INFO 01-07 10:14:16.026714.026714 client.py:127] Model loaded
INFO 01-07 10:14:16.026928.026928 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 669391c8-cfb7-476c-9f61-590cef627ace
INFO 01-07 10:14:16.031004.031004 client.py:127] Model loaded
DEBUG 01-07 10:14:16.032655.032655 cuda_h.py:19] end wait_experts_multi_device cost 0.006735324859619141 seconds
DEBUG 01-07 10:14:16.032411.032411 cuda_h.py:10] start gpu_experts_multi_device
DEBUG 01-07 10:14:16.032903.032903 lmp.py:867]   Computing 23 experts on cuda:2...
DEBUG 01-07 10:14:16.033879.033879 mlpmodule.py:707]  experts func einsum cost 0.042287349700927734 s
DEBUG 01-07 10:14:16.033594.033594 mlpmodule.py:533] gpu group tensors cost 0.0005526542663574219 s
DEBUG 01-07 10:14:16.034671.034671 mlpmodule.py:566] gpu pad cost 0.0012450218200683594 s
DEBUG 01-07 10:14:16.035745.035745 mlpmodule.py:584] gpu group einsum cost 0.0005533695220947266 s
DEBUG 01-07 10:14:16.037386.037386 mlpmodule.py:656] gpu experts func einsum cost 0.00444340705871582 s
DEBUG 01-07 10:14:16.037732.037732 lmp.py:867]   Computing 22 experts on cuda:1...
DEBUG 01-07 10:14:16.038350.038350 mlpmodule.py:533] gpu group tensors cost 0.00036787986755371094 s
DEBUG 01-07 10:14:16.039438.039438 mlpmodule.py:566] gpu pad cost 0.0009944438934326172 s
DEBUG 01-07 10:14:16.039776.039776 mlpmodule.py:584] gpu group einsum cost 0.0003714561462402344 s
DEBUG 01-07 10:14:16.041486.041486 mlpmodule.py:656] gpu experts func einsum cost 0.003452777862548828 s
DEBUG 01-07 10:14:16.041078.041078 cuda_h.py:19] end gpu_experts_multi_device cost 0.009206056594848633 seconds
DEBUG 01-07 10:14:16.041710.041710 cuda_h.py:19] end layer_moe_generate_multi_device_22 cost 0.06273341178894043 seconds
DEBUG 01-07 10:14:16.041506.041506 lmp.py:194] -------------------------------- end prefill layer 22 --------------------------------
DEBUG 01-07 10:14:16.041269.041269 lmp.py:153] -------------------------------- start prefill layer 23 --------------------------------
DEBUG 01-07 10:14:16.041203.041203 cuda_h.py:10] start start_load_qkvogn_s_weight_l_24
DEBUG 01-07 10:14:16.041959.041959 cuda_h.py:10] start start_load_qkvogn_s_weight_l_24
DEBUG 01-07 10:14:16.041696.041696 cuda_h.py:19] end start_load_qkvogn_s_weight_l_24 cost 2.5987625122070312e-05 seconds
DEBUG 01-07 10:14:16.041730.041730 cuda_h.py:19] end start_load_qkvogn_s_weight_l_24 cost 5.4836273193359375e-05 seconds
DEBUG 01-07 10:14:16.041804.041804 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-07 10:14:16.041355.041355 mlpmodule.py:367] cuda:1 cuda:1
DEBUG 01-07 10:14:16.041059.041059 cuda_h.py:10] start sllm_worker_task
DEBUG 01-07 10:14:16.042552.042552 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 10:14:16.042243.042243 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 10:14:16.042108.042108 cuda_h.py:19] end allocate_cuda_memory cost 0.0002868175506591797 seconds
DEBUG 01-07 10:14:16.042527.042527 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 10:14:16.042760.042760 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 10:14:16.042198.042198 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 10:14:16.042755.042755 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 71f57d1c-ce88-4d02-9809-46b5b202872a
DEBUG 01-07 10:14:16.042904.042904 client.py:106] call stub.LoadModelAsync
DEBUG 01-07 10:14:16.042912.042912 cuda_h.py:10] start self_attn
INFO 01-07 10:14:16.043035.043035 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 71f57d1c-ce88-4d02-9809-46b5b202872a
DEBUG 01-07 10:14:16.043580.043580 cuda_h.py:19] end load_into_gpu_async cost 0.0009555816650390625 seconds
DEBUG 01-07 10:14:16.043422.043422 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 10:14:16.043928.043928 cuda_h.py:19] end restore_tensors2 cost 6.723403930664062e-05 seconds
DEBUG 01-07 10:14:16.043062.043062 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0015377998352050781 seconds
INFO 01-07 10:14:16.043428.043428 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 71f57d1c-ce88-4d02-9809-46b5b202872a
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-07 10:14:16.046501.046501 cuda_h.py:19] end self_attn cost 0.003672361373901367 seconds
DEBUG 01-07 10:14:16.046577.046577 cuda_h.py:19] end iln_self_attn_paln cost 0.00507044792175293 seconds
DEBUG 01-07 10:14:16.046214.046214 cuda_h.py:10] start layer_moe_generate_multi_device_23
DEBUG 01-07 10:14:16.046116.046116 cuda_h.py:10] start gate
DEBUG 01-07 10:14:16.047602.047602 cuda_h.py:19] end gate cost 0.0006401538848876953 seconds
DEBUG 01-07 10:14:16.047286.047286 cuda_h.py:10] start experts_map_get
DEBUG 01-07 10:14:16.048491.048491 lmp.py:744] 
DEBUG 01-07 10:14:16.048491.048491 lmp.py:744] Expert Token Distribution & Multi-Device Allocation:
DEBUG 01-07 10:14:16.048824.048824 lmp.py:745]   Total experts: 64
DEBUG 01-07 10:14:16.048619.048619 lmp.py:746]   CPU experts: 19 (30%)
DEBUG 01-07 10:14:16.048362.048362 lmp.py:747]   GPU experts: 45 (70%)
DEBUG 01-07 10:14:16.048243.048243 lmp.py:748]   Number of GPU devices: 2
DEBUG 01-07 10:14:16.048409.048409 lmp.py:749] 
DEBUG 01-07 10:14:16.048409.048409 lmp.py:749]   Expert ID | Tokens | Device
DEBUG 01-07 10:14:16.048052.048052 lmp.py:750]   -----------------------------------
DEBUG 01-07 10:14:16.048132.048132 lmp.py:767]   Expert  5 |     14 | CPU
DEBUG 01-07 10:14:16.048252.048252 lmp.py:767]   Expert 56 |     33 | CPU
DEBUG 01-07 10:14:16.048895.048895 lmp.py:767]   Expert 16 |     81 | CPU
DEBUG 01-07 10:14:16.048253.048253 lmp.py:767]   Expert 27 |     82 | CPU
DEBUG 01-07 10:14:16.048658.048658 lmp.py:767]   Expert 17 |     90 | CPU
DEBUG 01-07 10:14:16.048063.048063 lmp.py:767]   Expert 40 |     94 | CPU
DEBUG 01-07 10:14:16.048229.048229 lmp.py:767]   Expert 53 |     99 | CPU
DEBUG 01-07 10:14:16.048832.048832 lmp.py:767]   Expert 63 |    103 | CPU
DEBUG 01-07 10:14:16.048190.048190 lmp.py:767]   Expert 51 |    104 | CPU
DEBUG 01-07 10:14:16.048833.048833 lmp.py:767]   Expert 49 |    105 | CPU
DEBUG 01-07 10:14:16.048238.048238 lmp.py:767]   Expert 28 |    109 | CPU
DEBUG 01-07 10:14:16.048642.048642 lmp.py:767]   Expert  7 |    111 | CPU
DEBUG 01-07 10:14:16.048809.048809 lmp.py:767]   Expert 37 |    123 | CPU
DEBUG 01-07 10:14:16.048213.048213 lmp.py:767]   Expert 38 |    123 | CPU
DEBUG 01-07 10:14:16.048141.048141 lmp.py:767]   Expert 62 |    123 | CPU
DEBUG 01-07 10:14:16.048069.048069 lmp.py:767]   Expert 47 |    127 | CPU
DEBUG 01-07 10:14:16.048188.048188 lmp.py:767]   Expert 58 |    130 | CPU
DEBUG 01-07 10:14:16.048593.048593 lmp.py:767]   Expert 11 |    131 | CPU
DEBUG 01-07 10:14:16.048997.048997 lmp.py:767]   Expert 57 |    141 | CPU
DEBUG 01-07 10:14:16.048071.048071 lmp.py:767]   Expert 39 |    147 | GPU0(cuda:1)
DEBUG 01-07 10:14:16.048906.048906 lmp.py:767]   Expert  1 |    148 | GPU1(cuda:2)
DEBUG 01-07 10:14:16.048026.048026 lmp.py:767]   Expert 25 |    151 | GPU0(cuda:1)
DEBUG 01-07 10:14:16.048384.048384 lmp.py:767]   Expert 14 |    153 | GPU0(cuda:1)
DEBUG 01-07 10:14:16.048458.048458 lmp.py:767]   Expert 33 |    157 | GPU1(cuda:2)
DEBUG 01-07 10:14:16.048531.048531 lmp.py:767]   Expert 52 |    158 | GPU1(cuda:2)
DEBUG 01-07 10:14:16.048651.048651 lmp.py:767]   Expert 23 |    163 | GPU0(cuda:1)
DEBUG 01-07 10:14:16.048771.048771 lmp.py:767]   Expert  6 |    165 | GPU0(cuda:1)
DEBUG 01-07 10:14:16.048890.048890 lmp.py:767]   Expert 60 |    170 | GPU1(cuda:2)
DEBUG 01-07 10:14:16.048772.048772 lmp.py:767]   Expert 21 |    173 | GPU1(cuda:2)
DEBUG 01-07 10:14:16.048415.048415 lmp.py:767]   Expert 44 |    173 | GPU0(cuda:1)
DEBUG 01-07 10:14:16.048296.048296 lmp.py:767]   Expert 45 |    175 | GPU1(cuda:2)
DEBUG 01-07 10:14:16.048178.048178 lmp.py:767]   Expert 12 |    180 | GPU0(cuda:1)
DEBUG 01-07 10:14:16.048013.048013 lmp.py:767]   Expert 19 |    184 | GPU1(cuda:2)
DEBUG 01-07 10:14:16.048609.048609 lmp.py:767]   Expert  4 |    188 | GPU0(cuda:1)
DEBUG 01-07 10:14:16.048491.048491 lmp.py:767]   Expert  3 |    196 | GPU1(cuda:2)
DEBUG 01-07 10:14:16.048372.048372 lmp.py:767]   Expert 31 |    197 | GPU0(cuda:1)
DEBUG 01-07 10:14:16.048254.048254 lmp.py:767]   Expert 30 |    198 | GPU0(cuda:1)
DEBUG 01-07 10:14:16.048373.048373 lmp.py:767]   Expert 36 |    198 | GPU1(cuda:2)
DEBUG 01-07 10:14:16.048255.048255 lmp.py:767]   Expert 55 |    199 | GPU0(cuda:1)
DEBUG 01-07 10:14:16.048136.048136 lmp.py:767]   Expert  9 |    210 | GPU1(cuda:2)
DEBUG 01-07 10:14:16.048018.048018 lmp.py:767]   Expert 41 |    217 | GPU1(cuda:2)
DEBUG 01-07 10:14:16.049899.049899 lmp.py:767]   Expert  0 |    220 | GPU0(cuda:1)
DEBUG 01-07 10:14:16.049496.049496 lmp.py:767]   Expert 34 |    224 | GPU0(cuda:1)
DEBUG 01-07 10:14:16.049615.049615 lmp.py:767]   Expert 22 |    226 | GPU1(cuda:2)
DEBUG 01-07 10:14:16.049258.049258 lmp.py:767]   Expert 43 |    237 | GPU0(cuda:1)
DEBUG 01-07 10:14:16.049901.049901 lmp.py:767]   Expert 26 |    238 | GPU1(cuda:2)
DEBUG 01-07 10:14:16.049783.049783 lmp.py:767]   Expert 54 |    241 | GPU1(cuda:2)
DEBUG 01-07 10:14:16.049664.049664 lmp.py:767]   Expert 59 |    249 | GPU0(cuda:1)
DEBUG 01-07 10:14:16.049545.049545 lmp.py:767]   Expert 18 |    255 | GPU1(cuda:2)
DEBUG 01-07 10:14:16.049427.049427 lmp.py:767]   Expert 13 |    257 | GPU0(cuda:1)
DEBUG 01-07 10:14:16.049308.049308 lmp.py:767]   Expert 15 |    261 | GPU0(cuda:1)
DEBUG 01-07 10:14:16.049428.049428 lmp.py:767]   Expert 29 |    261 | GPU1(cuda:2)
DEBUG 01-07 10:14:16.049786.049786 lmp.py:767]   Expert 20 |    262 | GPU0(cuda:1)
DEBUG 01-07 10:14:16.049621.049621 lmp.py:767]   Expert 50 |    262 | GPU1(cuda:2)
DEBUG 01-07 10:14:16.049741.049741 lmp.py:767]   Expert 24 |    264 | GPU1(cuda:2)
DEBUG 01-07 10:14:16.049623.049623 lmp.py:767]   Expert 42 |    267 | GPU0(cuda:1)
DEBUG 01-07 10:14:16.049504.049504 lmp.py:767]   Expert 61 |    268 | GPU1(cuda:2)
DEBUG 01-07 10:14:16.049147.049147 lmp.py:767]   Expert 35 |    281 | GPU0(cuda:1)
DEBUG 01-07 10:14:16.049267.049267 lmp.py:767]   Expert 32 |    301 | GPU0(cuda:1)
DEBUG 01-07 10:14:16.049863.049863 lmp.py:767]   Expert  8 |    338 | GPU1(cuda:2)
DEBUG 01-07 10:14:16.049506.049506 lmp.py:767]   Expert  2 |    340 | GPU0(cuda:1)
DEBUG 01-07 10:14:16.049149.049149 lmp.py:767]   Expert 10 |    343 | GPU1(cuda:2)
DEBUG 01-07 10:14:16.049031.049031 lmp.py:767]   Expert 46 |    427 | GPU1(cuda:2)
DEBUG 01-07 10:14:16.049674.049674 lmp.py:767]   Expert 48 |    443 | GPU0(cuda:1)
DEBUG 01-07 10:14:16.049363.049363 lmp.py:769] 
DEBUG 01-07 10:14:16.049363.049363 lmp.py:769]   Device Token Distribution:
DEBUG 01-07 10:14:16.049768.049768 lmp.py:770]   CPU:   1923 tokens
DEBUG 01-07 10:14:16.049080.049080 lmp.py:774]   cuda:1:   5256 tokens (23 experts)
DEBUG 01-07 10:14:16.049199.049199 lmp.py:774]   cuda:2:   5109 tokens (22 experts)
DEBUG 01-07 10:14:16.049365.049365 lmp.py:775]   Total GPU:  10365 tokens
DEBUG 01-07 10:14:16.049055.049055 lmp.py:776] ============================================================
DEBUG 01-07 10:14:16.049055.049055 lmp.py:776] 
DEBUG 01-07 10:14:16.049181.049181 cuda_h.py:19] end experts_map_get cost 0.0017902851104736328 seconds
DEBUG 01-07 10:14:16.049301.049301 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model_multi_device
DEBUG 01-07 10:14:16.049839.049839 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 10:14:16.049717.049717 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 10:14:16.049760.049760 cuda_h.py:19] end allocate_cuda_memory cost 0.000244140625 seconds
DEBUG 01-07 10:14:16.050332.050332 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 10:14:16.050611.050611 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 10:14:16.050989.050989 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 10:14:16.050447.050447 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 3d815a84-e7a0-4297-8066-cfef6a987a94
DEBUG 01-07 10:14:16.050519.050519 client.py:106] call stub.LoadModelAsync
INFO 01-07 10:14:16.050762.050762 client.py:127] Model loaded
DEBUG 01-07 10:14:16.050496.050496 cuda_h.py:19] end sllm_worker_task cost 0.00880885124206543 seconds
INFO 01-07 10:14:16.051002.051002 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 3d815a84-e7a0-4297-8066-cfef6a987a94
DEBUG 01-07 10:14:16.051990.051990 cuda_h.py:19] end load_into_gpu_async cost 0.0010497570037841797 seconds
DEBUG 01-07 10:14:16.051216.051216 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 10:14:16.051398.051398 cuda_h.py:19] end restore_tensors2 cost 0.00024962425231933594 seconds
DEBUG 01-07 10:14:16.051929.051929 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0018694400787353516 seconds
DEBUG 01-07 10:14:16.053749.053749 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 10:14:16.053409.053409 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 10:14:16.053438.053438 cuda_h.py:19] end allocate_cuda_memory cost 0.0002231597900390625 seconds
DEBUG 01-07 10:14:16.053327.053327 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 10:14:16.053130.053130 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 10:14:16.053270.053270 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 10:14:16.053443.053443 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 60f0b326-748f-46e8-9c34-0b9160fef942
DEBUG 01-07 10:14:16.054957.054957 client.py:106] call stub.LoadModelAsync
INFO 01-07 10:14:16.055668.055668 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 60f0b326-748f-46e8-9c34-0b9160fef942
DEBUG 01-07 10:14:16.055497.055497 cuda_h.py:19] end load_into_gpu_async cost 0.0012874603271484375 seconds
DEBUG 01-07 10:14:16.055385.055385 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 10:14:16.055241.055241 cuda_h.py:19] end restore_tensors2 cost 0.00022125244140625 seconds
DEBUG 01-07 10:14:16.055488.055488 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.002035856246948242 seconds
DEBUG 01-07 10:14:16.057807.057807 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model_multi_device cost 0.00775456428527832 seconds
DEBUG 01-07 10:14:16.057113.057113 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-07 10:14:16.057268.057268 lmp.py:816] 
DEBUG 01-07 10:14:16.057268.057268 lmp.py:816]   Computing 19 experts on CPU...
DEBUG 01-07 10:14:16.057012.057012 cuda_h.py:19] end cpu_experts_submit cost 0.00010776519775390625 seconds
DEBUG 01-07 10:14:16.057092.057092 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-07 10:14:16.070321.070321 mlpmodule.py:749] group tensors cost 0.012624025344848633 s
DEBUG 01-07 10:14:16.072499.072499 mlpmodule.py:787] pad cost 0.0014514923095703125 s
DEBUG 01-07 10:14:16.072250.072250 mlpmodule.py:793] create cpu tensor cost 4.076957702636719e-05 s
DEBUG 01-07 10:14:16.072246.072246 mlpmodule.py:798] move to cpu cost 3.218650817871094e-05 s
DEBUG 01-07 10:14:16.080199.080199 mlpmodule.py:812] group_w3: shape=torch.Size([19, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=54788096
DEBUG 01-07 10:14:16.080451.080451 mlpmodule.py:813] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-07 10:14:16.081885.081885 mlpmodule.py:818] group_w3 first element: 0.04248046875
WARNING 01-07 10:14:16.081876.081876 mlpmodule.py:828] start einsum2
DEBUG 01-07 10:14:16.092506.092506 mlpmodule.py:838] group einsum cost 0.019143342971801758 s
DEBUG 01-07 10:14:16.092171.092171 mlpmodule.py:846] cpy2cputensor cost 0.0004870891571044922 s
DEBUG 01-07 10:14:16.095953.095953 cuda_h.py:19] end wait_cetm_experts cost 0.03773951530456543 seconds
DEBUG 01-07 10:14:16.095274.095274 cuda_h.py:10] start gpu_sexperts
DEBUG 01-07 10:14:16.095651.095651 cuda_h.py:19] end gpu_sexperts cost 0.0005104541778564453 seconds
DEBUG 01-07 10:14:16.096401.096401 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-07 10:14:16.096019.096019 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.384185791015625e-05 seconds
DEBUG 01-07 10:14:16.096729.096729 cuda_h.py:10] start wait_experts_multi_device
INFO 01-07 10:14:16.096107.096107 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 3d815a84-e7a0-4297-8066-cfef6a987a94
INFO 01-07 10:14:16.097757.097757 client.py:127] Model loaded
INFO 01-07 10:14:16.097071.097071 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 60f0b326-748f-46e8-9c34-0b9160fef942
INFO 01-07 10:14:16.098327.098327 client.py:127] Model loaded
DEBUG 01-07 10:14:16.098442.098442 cuda_h.py:19] end wait_experts_multi_device cost 0.0020749568939208984 seconds
DEBUG 01-07 10:14:16.098098.098098 cuda_h.py:10] start gpu_experts_multi_device
DEBUG 01-07 10:14:16.098252.098252 lmp.py:867]   Computing 22 experts on cuda:2...
DEBUG 01-07 10:14:16.099131.099131 mlpmodule.py:533] gpu group tensors cost 0.0004744529724121094 s
DEBUG 01-07 10:14:16.100792.100792 mlpmodule.py:566] gpu pad cost 0.0012655258178710938 s
DEBUG 01-07 10:14:16.101229.101229 mlpmodule.py:584] gpu group einsum cost 0.0005385875701904297 s
DEBUG 01-07 10:14:16.103435.103435 mlpmodule.py:707]  experts func einsum cost 0.04552817344665527 s
DEBUG 01-07 10:14:16.103511.103511 mlpmodule.py:656] gpu experts func einsum cost 0.004508256912231445 s
DEBUG 01-07 10:14:16.103435.103435 lmp.py:867]   Computing 23 experts on cuda:1...
DEBUG 01-07 10:14:16.104243.104243 mlpmodule.py:533] gpu group tensors cost 0.0004870891571044922 s
DEBUG 01-07 10:14:16.105384.105384 mlpmodule.py:566] gpu pad cost 0.0012047290802001953 s
DEBUG 01-07 10:14:16.106401.106401 mlpmodule.py:584] gpu group einsum cost 0.0004444122314453125 s
DEBUG 01-07 10:14:16.108877.108877 mlpmodule.py:656] gpu experts func einsum cost 0.004221439361572266 s
DEBUG 01-07 10:14:16.108199.108199 cuda_h.py:19] end gpu_experts_multi_device cost 0.010087728500366211 seconds
DEBUG 01-07 10:14:16.108076.108076 cuda_h.py:19] end layer_moe_generate_multi_device_23 cost 0.06148958206176758 seconds
DEBUG 01-07 10:14:16.108077.108077 lmp.py:194] -------------------------------- end prefill layer 23 --------------------------------
DEBUG 01-07 10:14:16.108317.108317 lmp.py:153] -------------------------------- start prefill layer 24 --------------------------------
DEBUG 01-07 10:14:16.108536.108536 cuda_h.py:10] start start_load_qkvogn_s_weight_l_25
DEBUG 01-07 10:14:16.108292.108292 cuda_h.py:10] start start_load_qkvogn_s_weight_l_25
DEBUG 01-07 10:14:16.108221.108221 cuda_h.py:19] end start_load_qkvogn_s_weight_l_25 cost 2.765655517578125e-05 seconds
DEBUG 01-07 10:14:16.108540.108540 cuda_h.py:19] end start_load_qkvogn_s_weight_l_25 cost 5.5789947509765625e-05 seconds
DEBUG 01-07 10:14:16.108898.108898 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-07 10:14:16.108873.108873 mlpmodule.py:367] cuda:1 cuda:1
DEBUG 01-07 10:14:16.109769.109769 cuda_h.py:10] start sllm_worker_task
DEBUG 01-07 10:14:16.109911.109911 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 10:14:16.109979.109979 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 10:14:16.109069.109069 cuda_h.py:19] end allocate_cuda_memory cost 0.00027680397033691406 seconds
DEBUG 01-07 10:14:16.109111.109111 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 10:14:16.109820.109820 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 10:14:16.109259.109259 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 10:14:16.109054.109054 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 0e203ebb-f8b0-4125-929a-aff13b90a0d0
DEBUG 01-07 10:14:16.109580.109580 client.py:106] call stub.LoadModelAsync
DEBUG 01-07 10:14:16.109768.109768 cuda_h.py:10] start self_attn
INFO 01-07 10:14:16.110702.110702 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 0e203ebb-f8b0-4125-929a-aff13b90a0d0
DEBUG 01-07 10:14:16.111631.111631 cuda_h.py:19] end load_into_gpu_async cost 0.0014734268188476562 seconds
DEBUG 01-07 10:14:16.111950.111950 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 10:14:16.111403.111403 cuda_h.py:19] end restore_tensors2 cost 6.318092346191406e-05 seconds
DEBUG 01-07 10:14:16.111490.111490 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.002046823501586914 seconds
INFO 01-07 10:14:16.111042.111042 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 0e203ebb-f8b0-4125-929a-aff13b90a0d0
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-07 10:14:16.113414.113414 cuda_h.py:19] end self_attn cost 0.0033998489379882812 seconds
DEBUG 01-07 10:14:16.113867.113867 cuda_h.py:19] end iln_self_attn_paln cost 0.004795074462890625 seconds
DEBUG 01-07 10:14:16.113597.113597 cuda_h.py:10] start layer_moe_generate_multi_device_24
DEBUG 01-07 10:14:16.113738.113738 cuda_h.py:10] start gate
DEBUG 01-07 10:14:16.114054.114054 cuda_h.py:19] end gate cost 0.0007269382476806641 seconds
DEBUG 01-07 10:14:16.114407.114407 cuda_h.py:10] start experts_map_get
DEBUG 01-07 10:14:16.115235.115235 lmp.py:744] 
DEBUG 01-07 10:14:16.115235.115235 lmp.py:744] Expert Token Distribution & Multi-Device Allocation:
DEBUG 01-07 10:14:16.115422.115422 lmp.py:745]   Total experts: 64
DEBUG 01-07 10:14:16.115548.115548 lmp.py:746]   CPU experts: 19 (30%)
DEBUG 01-07 10:14:16.115337.115337 lmp.py:747]   GPU experts: 45 (70%)
DEBUG 01-07 10:14:16.115457.115457 lmp.py:748]   Number of GPU devices: 2
DEBUG 01-07 10:14:16.115146.115146 lmp.py:749] 
DEBUG 01-07 10:14:16.115146.115146 lmp.py:749]   Expert ID | Tokens | Device
DEBUG 01-07 10:14:16.115074.115074 lmp.py:750]   -----------------------------------
DEBUG 01-07 10:14:16.115200.115200 lmp.py:767]   Expert 36 |     20 | CPU
DEBUG 01-07 10:14:16.115605.115605 lmp.py:767]   Expert 35 |     29 | CPU
DEBUG 01-07 10:14:16.115056.115056 lmp.py:767]   Expert 46 |     38 | CPU
DEBUG 01-07 10:14:16.115421.115421 lmp.py:767]   Expert 25 |     45 | CPU
DEBUG 01-07 10:14:16.115110.115110 lmp.py:767]   Expert 51 |     53 | CPU
DEBUG 01-07 10:14:16.115323.115323 lmp.py:767]   Expert 16 |     60 | CPU
DEBUG 01-07 10:14:16.115012.115012 lmp.py:767]   Expert  0 |     61 | CPU
DEBUG 01-07 10:14:16.115940.115940 lmp.py:767]   Expert 30 |     66 | CPU
DEBUG 01-07 10:14:16.115629.115629 lmp.py:767]   Expert 44 |     66 | CPU
DEBUG 01-07 10:14:16.115795.115795 lmp.py:767]   Expert 43 |     69 | CPU
DEBUG 01-07 10:14:16.115484.115484 lmp.py:767]   Expert 47 |     69 | CPU
DEBUG 01-07 10:14:16.115412.115412 lmp.py:767]   Expert 39 |     72 | CPU
DEBUG 01-07 10:14:16.115863.115863 lmp.py:767]   Expert 42 |     72 | CPU
DEBUG 01-07 10:14:16.115837.115837 lmp.py:767]   Expert 55 |     76 | CPU
DEBUG 01-07 10:14:16.115049.115049 lmp.py:767]   Expert  2 |     87 | CPU
DEBUG 01-07 10:14:16.115739.115739 lmp.py:767]   Expert  4 |    107 | CPU
DEBUG 01-07 10:14:16.115713.115713 lmp.py:767]   Expert 48 |    111 | CPU
DEBUG 01-07 10:14:16.115925.115925 lmp.py:767]   Expert  6 |    120 | CPU
DEBUG 01-07 10:14:16.115138.115138 lmp.py:767]   Expert 24 |    123 | CPU
DEBUG 01-07 10:14:16.115781.115781 lmp.py:767]   Expert 33 |    123 | GPU0(cuda:1)
DEBUG 01-07 10:14:16.115139.115139 lmp.py:767]   Expert 61 |    125 | GPU1(cuda:2)
DEBUG 01-07 10:14:16.115259.115259 lmp.py:767]   Expert 13 |    128 | GPU0(cuda:1)
DEBUG 01-07 10:14:16.115855.115855 lmp.py:767]   Expert 15 |    134 | GPU1(cuda:2)
DEBUG 01-07 10:14:16.115498.115498 lmp.py:767]   Expert 56 |    135 | GPU0(cuda:1)
DEBUG 01-07 10:14:16.115380.115380 lmp.py:767]   Expert 29 |    136 | GPU1(cuda:2)
DEBUG 01-07 10:14:16.115546.115546 lmp.py:767]   Expert 38 |    137 | GPU0(cuda:1)
DEBUG 01-07 10:14:16.115619.115619 lmp.py:767]   Expert 54 |    140 | GPU1(cuda:2)
DEBUG 01-07 10:14:16.115216.115216 lmp.py:767]   Expert  9 |    142 | GPU0(cuda:1)
DEBUG 01-07 10:14:16.115574.115574 lmp.py:767]   Expert  7 |    145 | GPU0(cuda:1)
DEBUG 01-07 10:14:16.115456.115456 lmp.py:767]   Expert 20 |    145 | GPU1(cuda:2)
DEBUG 01-07 10:14:16.115337.115337 lmp.py:767]   Expert 59 |    149 | GPU1(cuda:2)
DEBUG 01-07 10:14:16.115457.115457 lmp.py:767]   Expert 45 |    158 | GPU1(cuda:2)
DEBUG 01-07 10:14:16.115292.115292 lmp.py:767]   Expert 62 |    158 | GPU0(cuda:1)
DEBUG 01-07 10:14:16.115889.115889 lmp.py:767]   Expert 19 |    163 | GPU1(cuda:2)
DEBUG 01-07 10:14:16.115962.115962 lmp.py:767]   Expert 34 |    186 | GPU0(cuda:1)
DEBUG 01-07 10:14:16.115559.115559 lmp.py:767]   Expert 57 |    192 | GPU0(cuda:1)
DEBUG 01-07 10:14:16.115632.115632 lmp.py:767]   Expert 50 |    196 | GPU1(cuda:2)
DEBUG 01-07 10:14:16.115752.115752 lmp.py:767]   Expert 31 |    202 | GPU0(cuda:1)
DEBUG 01-07 10:14:16.115633.115633 lmp.py:767]   Expert 23 |    205 | GPU1(cuda:2)
DEBUG 01-07 10:14:16.115515.115515 lmp.py:767]   Expert 10 |    209 | GPU1(cuda:2)
DEBUG 01-07 10:14:16.115158.115158 lmp.py:767]   Expert  8 |    216 | GPU0(cuda:1)
DEBUG 01-07 10:14:16.115278.115278 lmp.py:767]   Expert 18 |    219 | GPU0(cuda:1)
DEBUG 01-07 10:14:16.115159.115159 lmp.py:767]   Expert 60 |    220 | GPU1(cuda:2)
DEBUG 01-07 10:14:16.115040.115040 lmp.py:767]   Expert 53 |    221 | GPU0(cuda:1)
DEBUG 01-07 10:14:16.115922.115922 lmp.py:767]   Expert 22 |    222 | GPU1(cuda:2)
DEBUG 01-07 10:14:16.115042.115042 lmp.py:767]   Expert 52 |    226 | GPU1(cuda:2)
DEBUG 01-07 10:14:16.115638.115638 lmp.py:767]   Expert 37 |    230 | GPU0(cuda:1)
DEBUG 01-07 10:14:16.116758.116758 lmp.py:767]   Expert  5 |    241 | GPU1(cuda:2)
DEBUG 01-07 10:14:16.116639.116639 lmp.py:767]   Expert 17 |    243 | GPU0(cuda:1)
DEBUG 01-07 10:14:16.116998.116998 lmp.py:767]   Expert 11 |    263 | GPU0(cuda:1)
DEBUG 01-07 10:14:16.116879.116879 lmp.py:767]   Expert  1 |    272 | GPU1(cuda:2)
DEBUG 01-07 10:14:16.116522.116522 lmp.py:767]   Expert 49 |    280 | GPU1(cuda:2)
DEBUG 01-07 10:14:16.116403.116403 lmp.py:767]   Expert 28 |    285 | GPU1(cuda:2)
DEBUG 01-07 10:14:16.116285.116285 lmp.py:767]   Expert 41 |    285 | GPU0(cuda:1)
DEBUG 01-07 10:14:16.116928.116928 lmp.py:767]   Expert 26 |    286 | GPU0(cuda:1)
DEBUG 01-07 10:14:16.116670.116670 lmp.py:767]   Expert 58 |    290 | GPU0(cuda:1)
DEBUG 01-07 10:14:16.116313.116313 lmp.py:767]   Expert 32 |    293 | GPU1(cuda:2)
DEBUG 01-07 10:14:16.116195.116195 lmp.py:767]   Expert 40 |    304 | GPU1(cuda:2)
DEBUG 01-07 10:14:16.116076.116076 lmp.py:767]   Expert 14 |    313 | GPU0(cuda:1)
DEBUG 01-07 10:14:16.116719.116719 lmp.py:767]   Expert 12 |    327 | GPU1(cuda:2)
DEBUG 01-07 10:14:16.116885.116885 lmp.py:767]   Expert 63 |    336 | GPU0(cuda:1)
DEBUG 01-07 10:14:16.116813.116813 lmp.py:767]   Expert 21 |    376 | GPU1(cuda:2)
DEBUG 01-07 10:14:16.116741.116741 lmp.py:767]   Expert 27 |    664 | GPU1(cuda:2)
DEBUG 01-07 10:14:16.116907.116907 lmp.py:767]   Expert  3 |   1024 | GPU0(cuda:1)
DEBUG 01-07 10:14:16.116404.116404 lmp.py:769] 
DEBUG 01-07 10:14:16.116404.116404 lmp.py:769]   Device Token Distribution:
DEBUG 01-07 10:14:16.116855.116855 lmp.py:770]   CPU:   1344 tokens
DEBUG 01-07 10:14:16.116259.116259 lmp.py:774]   cuda:1:   5474 tokens (22 experts)
DEBUG 01-07 10:14:16.116949.116949 lmp.py:774]   cuda:2:   5470 tokens (23 experts)
DEBUG 01-07 10:14:16.116638.116638 lmp.py:775]   Total GPU:  10944 tokens
DEBUG 01-07 10:14:16.116718.116718 lmp.py:776] ============================================================
DEBUG 01-07 10:14:16.116718.116718 lmp.py:776] 
DEBUG 01-07 10:14:16.116606.116606 cuda_h.py:19] end experts_map_get cost 0.001768350601196289 seconds
DEBUG 01-07 10:14:16.116249.116249 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model_multi_device
DEBUG 01-07 10:14:16.116595.116595 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 10:14:16.116705.116705 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 10:14:16.117117.117117 cuda_h.py:19] end allocate_cuda_memory cost 0.0007994174957275391 seconds
DEBUG 01-07 10:14:16.117927.117927 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 10:14:16.117551.117551 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 10:14:16.117645.117645 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 10:14:16.117103.117103 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, e23d50b0-b7d6-4e0e-bf75-5262cba552dc
DEBUG 01-07 10:14:16.117730.117730 client.py:106] call stub.LoadModelAsync
INFO 01-07 10:14:16.117265.117265 client.py:127] Model loaded
DEBUG 01-07 10:14:16.118429.118429 cuda_h.py:19] end sllm_worker_task cost 0.009163141250610352 seconds
INFO 01-07 10:14:16.118712.118712 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, e23d50b0-b7d6-4e0e-bf75-5262cba552dc
DEBUG 01-07 10:14:16.118271.118271 cuda_h.py:19] end load_into_gpu_async cost 0.0009205341339111328 seconds
DEBUG 01-07 10:14:16.118543.118543 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 10:14:16.118565.118565 cuda_h.py:19] end restore_tensors2 cost 0.00023818016052246094 seconds
DEBUG 01-07 10:14:16.118619.118619 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.002277851104736328 seconds
DEBUG 01-07 10:14:16.120370.120370 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 10:14:16.120500.120500 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 10:14:16.121754.121754 cuda_h.py:19] end allocate_cuda_memory cost 0.00021958351135253906 seconds
DEBUG 01-07 10:14:16.121213.121213 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 10:14:16.121061.121061 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 10:14:16.121202.121202 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 10:14:16.121613.121613 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 8990f504-f028-47b4-8390-807110aefc71
DEBUG 01-07 10:14:16.121134.121134 client.py:106] call stub.LoadModelAsync
INFO 01-07 10:14:16.122133.122133 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 8990f504-f028-47b4-8390-807110aefc71
DEBUG 01-07 10:14:16.122771.122771 cuda_h.py:19] end load_into_gpu_async cost 0.0010123252868652344 seconds
DEBUG 01-07 10:14:16.122566.122566 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 10:14:16.122714.122714 cuda_h.py:19] end restore_tensors2 cost 0.00022482872009277344 seconds
DEBUG 01-07 10:14:16.122437.122437 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0017559528350830078 seconds
DEBUG 01-07 10:14:16.124162.124162 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model_multi_device cost 0.007844924926757812 seconds
DEBUG 01-07 10:14:16.124508.124508 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-07 10:14:16.124338.124338 lmp.py:816] 
DEBUG 01-07 10:14:16.124338.124338 lmp.py:816]   Computing 19 experts on CPU...
DEBUG 01-07 10:14:16.124652.124652 cuda_h.py:19] end cpu_experts_submit cost 0.00011372566223144531 seconds
DEBUG 01-07 10:14:16.124209.124209 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-07 10:14:16.131234.131234 mlpmodule.py:749] group tensors cost 0.006929636001586914 s
DEBUG 01-07 10:14:16.133448.133448 mlpmodule.py:787] pad cost 0.0013051033020019531 s
DEBUG 01-07 10:14:16.133961.133961 mlpmodule.py:793] create cpu tensor cost 4.100799560546875e-05 s
DEBUG 01-07 10:14:16.133434.133434 mlpmodule.py:798] move to cpu cost 3.24249267578125e-05 s
DEBUG 01-07 10:14:16.140886.140886 mlpmodule.py:812] group_w3: shape=torch.Size([19, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=54788096
DEBUG 01-07 10:14:16.140336.140336 mlpmodule.py:813] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-07 10:14:16.141671.141671 mlpmodule.py:818] group_w3 first element: 0.00653076171875
WARNING 01-07 10:14:16.141231.141231 mlpmodule.py:828] start einsum2
DEBUG 01-07 10:14:16.152954.152954 mlpmodule.py:838] group einsum cost 0.01842498779296875 s
DEBUG 01-07 10:14:16.153534.153534 mlpmodule.py:846] cpy2cputensor cost 0.00039839744567871094 s
DEBUG 01-07 10:14:16.155336.155336 cuda_h.py:19] end wait_cetm_experts cost 0.03105306625366211 seconds
DEBUG 01-07 10:14:16.155511.155511 cuda_h.py:10] start gpu_sexperts
DEBUG 01-07 10:14:16.156450.156450 cuda_h.py:19] end gpu_sexperts cost 0.0005075931549072266 seconds
DEBUG 01-07 10:14:16.156916.156916 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-07 10:14:16.156740.156740 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.4080276489257812e-05 seconds
DEBUG 01-07 10:14:16.156311.156311 cuda_h.py:10] start wait_experts_multi_device
INFO 01-07 10:14:16.156404.156404 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, e23d50b0-b7d6-4e0e-bf75-5262cba552dc
INFO 01-07 10:14:16.161096.161096 client.py:127] Model loaded
INFO 01-07 10:14:16.161753.161753 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 8990f504-f028-47b4-8390-807110aefc71
DEBUG 01-07 10:14:16.163979.163979 mlpmodule.py:707]  experts func einsum cost 0.03889131546020508 s
INFO 01-07 10:14:16.165057.165057 client.py:127] Model loaded
DEBUG 01-07 10:14:16.165774.165774 cuda_h.py:19] end wait_experts_multi_device cost 0.009261846542358398 seconds
DEBUG 01-07 10:14:16.165007.165007 cuda_h.py:10] start gpu_experts_multi_device
DEBUG 01-07 10:14:16.165737.165737 lmp.py:867]   Computing 23 experts on cuda:2...
DEBUG 01-07 10:14:16.166683.166683 mlpmodule.py:533] gpu group tensors cost 0.0004944801330566406 s
DEBUG 01-07 10:14:16.168246.168246 mlpmodule.py:566] gpu pad cost 0.001125335693359375 s
DEBUG 01-07 10:14:16.168421.168421 mlpmodule.py:584] gpu group einsum cost 0.0004246234893798828 s
DEBUG 01-07 10:14:16.170204.170204 mlpmodule.py:656] gpu experts func einsum cost 0.0037953853607177734 s
DEBUG 01-07 10:14:16.170876.170876 lmp.py:867]   Computing 22 experts on cuda:1...
DEBUG 01-07 10:14:16.171910.171910 mlpmodule.py:533] gpu group tensors cost 0.00036334991455078125 s
DEBUG 01-07 10:14:16.172521.172521 mlpmodule.py:566] gpu pad cost 0.0009951591491699219 s
DEBUG 01-07 10:14:16.172715.172715 mlpmodule.py:584] gpu group einsum cost 0.0004062652587890625 s
DEBUG 01-07 10:14:16.174319.174319 mlpmodule.py:656] gpu experts func einsum cost 0.003473520278930664 s
DEBUG 01-07 10:14:16.174765.174765 cuda_h.py:19] end gpu_experts_multi_device cost 0.008571863174438477 seconds
DEBUG 01-07 10:14:16.174490.174490 cuda_h.py:19] end layer_moe_generate_multi_device_24 cost 0.06063508987426758 seconds
DEBUG 01-07 10:14:16.174531.174531 lmp.py:194] -------------------------------- end prefill layer 24 --------------------------------
DEBUG 01-07 10:14:16.174307.174307 lmp.py:153] -------------------------------- start prefill layer 25 --------------------------------
DEBUG 01-07 10:14:16.174765.174765 cuda_h.py:10] start start_load_qkvogn_s_weight_l_26
DEBUG 01-07 10:14:16.174806.174806 cuda_h.py:10] start start_load_qkvogn_s_weight_l_26
DEBUG 01-07 10:14:16.174927.174927 cuda_h.py:19] end start_load_qkvogn_s_weight_l_26 cost 2.7894973754882812e-05 seconds
DEBUG 01-07 10:14:16.174484.174484 cuda_h.py:19] end start_load_qkvogn_s_weight_l_26 cost 5.698204040527344e-05 seconds
DEBUG 01-07 10:14:16.174365.174365 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-07 10:14:16.174903.174903 cuda_h.py:10] start sllm_worker_task
DEBUG 01-07 10:14:16.175794.175794 mlpmodule.py:367] cuda:1 cuda:1
DEBUG 01-07 10:14:16.175894.175894 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 10:14:16.175713.175713 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 10:14:16.175809.175809 cuda_h.py:19] end allocate_cuda_memory cost 0.0002815723419189453 seconds
DEBUG 01-07 10:14:16.175613.175613 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 10:14:16.175084.175084 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 10:14:16.175807.175807 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 10:14:16.175126.175126 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 8aa59130-c1c3-496b-bf91-a026f2ff6231
DEBUG 01-07 10:14:16.175513.175513 client.py:106] call stub.LoadModelAsync
DEBUG 01-07 10:14:16.176377.176377 cuda_h.py:10] start self_attn
INFO 01-07 10:14:16.176576.176576 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 8aa59130-c1c3-496b-bf91-a026f2ff6231
DEBUG 01-07 10:14:16.176227.176227 cuda_h.py:19] end load_into_gpu_async cost 0.000911712646484375 seconds
DEBUG 01-07 10:14:16.176215.176215 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 10:14:16.176099.176099 cuda_h.py:19] end restore_tensors2 cost 6.437301635742188e-05 seconds
DEBUG 01-07 10:14:16.176424.176424 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.001493215560913086 seconds
INFO 01-07 10:14:16.176744.176744 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 8aa59130-c1c3-496b-bf91-a026f2ff6231
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-07 10:14:16.179750.179750 cuda_h.py:19] end self_attn cost 0.003585338592529297 seconds
DEBUG 01-07 10:14:16.179250.179250 cuda_h.py:19] end iln_self_attn_paln cost 0.005048513412475586 seconds
DEBUG 01-07 10:14:16.180219.180219 cuda_h.py:10] start layer_moe_generate_multi_device_25
DEBUG 01-07 10:14:16.180790.180790 cuda_h.py:10] start gate
DEBUG 01-07 10:14:16.180137.180137 cuda_h.py:19] end gate cost 0.0006418228149414062 seconds
DEBUG 01-07 10:14:16.180251.180251 cuda_h.py:10] start experts_map_get
DEBUG 01-07 10:14:16.181973.181973 lmp.py:744] 
DEBUG 01-07 10:14:16.181973.181973 lmp.py:744] Expert Token Distribution & Multi-Device Allocation:
DEBUG 01-07 10:14:16.181020.181020 lmp.py:745]   Total experts: 64
DEBUG 01-07 10:14:16.181385.181385 lmp.py:746]   CPU experts: 19 (30%)
DEBUG 01-07 10:14:16.181936.181936 lmp.py:747]   GPU experts: 45 (70%)
DEBUG 01-07 10:14:16.181340.181340 lmp.py:748]   Number of GPU devices: 2
DEBUG 01-07 10:14:16.181029.181029 lmp.py:749] 
DEBUG 01-07 10:14:16.181029.181029 lmp.py:749]   Expert ID | Tokens | Device
DEBUG 01-07 10:14:16.181957.181957 lmp.py:750]   -----------------------------------
DEBUG 01-07 10:14:16.181845.181845 lmp.py:767]   Expert 13 |     27 | CPU
DEBUG 01-07 10:14:16.181011.181011 lmp.py:767]   Expert  9 |     37 | CPU
DEBUG 01-07 10:14:16.181701.181701 lmp.py:767]   Expert 44 |     37 | CPU
DEBUG 01-07 10:14:16.181152.181152 lmp.py:767]   Expert 25 |     41 | CPU
DEBUG 01-07 10:14:16.181079.181079 lmp.py:767]   Expert 38 |     45 | CPU
DEBUG 01-07 10:14:16.181530.181530 lmp.py:767]   Expert 16 |     48 | CPU
DEBUG 01-07 10:14:16.181504.181504 lmp.py:767]   Expert 22 |     51 | CPU
DEBUG 01-07 10:14:16.181955.181955 lmp.py:767]   Expert 33 |     53 | CPU
DEBUG 01-07 10:14:16.181644.181644 lmp.py:767]   Expert  2 |     59 | CPU
DEBUG 01-07 10:14:16.181618.181618 lmp.py:767]   Expert 42 |     62 | CPU
DEBUG 01-07 10:14:16.181831.181831 lmp.py:767]   Expert  5 |     65 | CPU
DEBUG 01-07 10:14:16.181043.181043 lmp.py:767]   Expert 23 |     79 | CPU
DEBUG 01-07 10:14:16.181017.181017 lmp.py:767]   Expert 10 |     82 | CPU
DEBUG 01-07 10:14:16.181468.181468 lmp.py:767]   Expert 24 |     82 | CPU
DEBUG 01-07 10:14:16.181634.181634 lmp.py:767]   Expert 59 |    102 | CPU
DEBUG 01-07 10:14:16.181847.181847 lmp.py:767]   Expert 21 |    105 | CPU
DEBUG 01-07 10:14:16.181821.181821 lmp.py:767]   Expert 55 |    111 | CPU
DEBUG 01-07 10:14:16.181033.181033 lmp.py:767]   Expert 46 |    114 | CPU
DEBUG 01-07 10:14:16.181484.181484 lmp.py:767]   Expert 45 |    118 | CPU
DEBUG 01-07 10:14:16.181889.181889 lmp.py:767]   Expert 61 |    119 | GPU0(cuda:1)
DEBUG 01-07 10:14:16.181486.181486 lmp.py:767]   Expert 31 |    125 | GPU0(cuda:1)
DEBUG 01-07 10:14:16.181367.181367 lmp.py:767]   Expert 51 |    136 | GPU1(cuda:2)
DEBUG 01-07 10:14:16.181248.181248 lmp.py:767]   Expert 36 |    137 | GPU1(cuda:2)
DEBUG 01-07 10:14:16.181653.181653 lmp.py:767]   Expert  6 |    146 | GPU0(cuda:1)
DEBUG 01-07 10:14:16.181534.181534 lmp.py:767]   Expert  0 |    148 | GPU0(cuda:1)
DEBUG 01-07 10:14:16.181224.181224 lmp.py:767]   Expert  8 |    153 | GPU1(cuda:2)
DEBUG 01-07 10:14:16.181628.181628 lmp.py:767]   Expert 43 |    153 | GPU1(cuda:2)
DEBUG 01-07 10:14:16.181794.181794 lmp.py:767]   Expert 18 |    155 | GPU0(cuda:1)
DEBUG 01-07 10:14:16.181960.181960 lmp.py:767]   Expert  3 |    159 | GPU0(cuda:1)
DEBUG 01-07 10:14:16.181365.181365 lmp.py:767]   Expert 26 |    159 | GPU1(cuda:2)
DEBUG 01-07 10:14:16.181485.181485 lmp.py:767]   Expert 48 |    163 | GPU1(cuda:2)
DEBUG 01-07 10:14:16.181412.181412 lmp.py:767]   Expert 41 |    166 | GPU0(cuda:1)
DEBUG 01-07 10:14:16.181340.181340 lmp.py:767]   Expert 12 |    174 | GPU1(cuda:2)
DEBUG 01-07 10:14:16.181268.181268 lmp.py:767]   Expert 20 |    178 | GPU0(cuda:1)
DEBUG 01-07 10:14:16.181434.181434 lmp.py:767]   Expert  7 |    180 | GPU0(cuda:1)
DEBUG 01-07 10:14:16.181362.181362 lmp.py:767]   Expert 28 |    188 | GPU1(cuda:2)
DEBUG 01-07 10:14:16.181289.181289 lmp.py:767]   Expert 56 |    189 | GPU0(cuda:1)
DEBUG 01-07 10:14:16.181456.181456 lmp.py:767]   Expert 27 |    190 | GPU1(cuda:2)
DEBUG 01-07 10:14:16.181099.181099 lmp.py:767]   Expert 34 |    194 | GPU1(cuda:2)
DEBUG 01-07 10:14:16.181265.181265 lmp.py:767]   Expert  1 |    199 | GPU0(cuda:1)
DEBUG 01-07 10:14:16.181192.181192 lmp.py:767]   Expert 47 |    201 | GPU0(cuda:1)
DEBUG 01-07 10:14:16.182120.182120 lmp.py:767]   Expert 11 |    210 | GPU1(cuda:2)
DEBUG 01-07 10:14:16.182809.182809 lmp.py:767]   Expert 32 |    218 | GPU0(cuda:1)
DEBUG 01-07 10:14:16.182737.182737 lmp.py:767]   Expert 40 |    223 | GPU1(cuda:2)
DEBUG 01-07 10:14:16.182665.182665 lmp.py:767]   Expert 49 |    230 | GPU0(cuda:1)
DEBUG 01-07 10:14:16.182593.182593 lmp.py:767]   Expert 53 |    233 | GPU1(cuda:2)
DEBUG 01-07 10:14:16.182997.182997 lmp.py:767]   Expert 29 |    239 | GPU0(cuda:1)
DEBUG 01-07 10:14:16.182402.182402 lmp.py:767]   Expert 63 |    243 | GPU1(cuda:2)
DEBUG 01-07 10:14:16.182568.182568 lmp.py:767]   Expert  4 |    246 | GPU1(cuda:2)
DEBUG 01-07 10:14:16.182496.182496 lmp.py:767]   Expert 15 |    246 | GPU0(cuda:1)
DEBUG 01-07 10:14:16.182662.182662 lmp.py:767]   Expert 30 |    249 | GPU1(cuda:2)
DEBUG 01-07 10:14:16.182828.182828 lmp.py:767]   Expert 50 |    249 | GPU0(cuda:1)
DEBUG 01-07 10:14:16.182232.182232 lmp.py:767]   Expert 35 |    270 | GPU0(cuda:1)
DEBUG 01-07 10:14:16.182637.182637 lmp.py:767]   Expert 14 |    271 | GPU1(cuda:2)
DEBUG 01-07 10:14:16.182565.182565 lmp.py:767]   Expert 37 |    305 | GPU1(cuda:2)
DEBUG 01-07 10:14:16.182731.182731 lmp.py:767]   Expert 52 |    335 | GPU0(cuda:1)
DEBUG 01-07 10:14:16.182612.182612 lmp.py:767]   Expert 17 |    360 | GPU0(cuda:1)
DEBUG 01-07 10:14:16.182494.182494 lmp.py:767]   Expert 54 |    382 | GPU1(cuda:2)
DEBUG 01-07 10:14:16.182375.182375 lmp.py:767]   Expert 39 |    391 | GPU0(cuda:1)
DEBUG 01-07 10:14:16.182018.182018 lmp.py:767]   Expert 57 |    410 | GPU1(cuda:2)
DEBUG 01-07 10:14:16.182899.182899 lmp.py:767]   Expert 60 |    458 | GPU0(cuda:1)
DEBUG 01-07 10:14:16.182258.182258 lmp.py:767]   Expert 62 |    462 | GPU1(cuda:2)
DEBUG 01-07 10:14:16.182901.182901 lmp.py:767]   Expert 19 |    547 | GPU1(cuda:2)
DEBUG 01-07 10:14:16.182544.182544 lmp.py:767]   Expert 58 |    581 | GPU0(cuda:1)
DEBUG 01-07 10:14:16.182233.182233 lmp.py:769] 
DEBUG 01-07 10:14:16.182233.182233 lmp.py:769]   Device Token Distribution:
DEBUG 01-07 10:14:16.182637.182637 lmp.py:770]   CPU:   1318 tokens
DEBUG 01-07 10:14:16.182757.182757 lmp.py:774]   cuda:1:   5542 tokens (23 experts)
DEBUG 01-07 10:14:16.182400.182400 lmp.py:774]   cuda:2:   5428 tokens (22 experts)
DEBUG 01-07 10:14:16.182043.182043 lmp.py:775]   Total GPU:  10970 tokens
DEBUG 01-07 10:14:16.182209.182209 lmp.py:776] ============================================================
DEBUG 01-07 10:14:16.182209.182209 lmp.py:776] 
DEBUG 01-07 10:14:16.182574.182574 cuda_h.py:19] end experts_map_get cost 0.0017189979553222656 seconds
DEBUG 01-07 10:14:16.182456.182456 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model_multi_device
DEBUG 01-07 10:14:16.182133.182133 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 10:14:16.182627.182627 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 10:14:16.183116.183116 cuda_h.py:19] end allocate_cuda_memory cost 0.0003273487091064453 seconds
DEBUG 01-07 10:14:16.183549.183549 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 10:14:16.183497.183497 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 10:14:16.183590.183590 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 10:14:16.183763.183763 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 955abed9-d24d-4e6d-ad02-f5cdc98d40a9
DEBUG 01-07 10:14:16.183345.183345 client.py:106] call stub.LoadModelAsync
INFO 01-07 10:14:16.183826.183826 client.py:127] Model loaded
DEBUG 01-07 10:14:16.183746.183746 cuda_h.py:19] end sllm_worker_task cost 0.008813142776489258 seconds
INFO 01-07 10:14:16.184668.184668 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 955abed9-d24d-4e6d-ad02-f5cdc98d40a9
DEBUG 01-07 10:14:16.184226.184226 cuda_h.py:19] end load_into_gpu_async cost 0.001027822494506836 seconds
DEBUG 01-07 10:14:16.184691.184691 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 10:14:16.184879.184879 cuda_h.py:19] end restore_tensors2 cost 0.0002541542053222656 seconds
DEBUG 01-07 10:14:16.184702.184702 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0019419193267822266 seconds
DEBUG 01-07 10:14:16.186191.186191 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 10:14:16.186937.186937 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 10:14:16.186542.186542 cuda_h.py:19] end allocate_cuda_memory cost 0.0002334117889404297 seconds
DEBUG 01-07 10:14:16.186477.186477 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 10:14:16.186326.186326 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 10:14:16.187036.187036 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 10:14:16.187970.187970 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, c01135a2-f59f-4eff-ac6c-79d0462d8198
DEBUG 01-07 10:14:16.187293.187293 client.py:106] call stub.LoadModelAsync
INFO 01-07 10:14:16.188250.188250 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, c01135a2-f59f-4eff-ac6c-79d0462d8198
DEBUG 01-07 10:14:16.188887.188887 cuda_h.py:19] end load_into_gpu_async cost 0.0013244152069091797 seconds
DEBUG 01-07 10:14:16.188729.188729 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 10:14:16.188307.188307 cuda_h.py:19] end restore_tensors2 cost 0.00022602081298828125 seconds
DEBUG 01-07 10:14:16.188653.188653 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0020813941955566406 seconds
DEBUG 01-07 10:14:16.190958.190958 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model_multi_device cost 0.007856130599975586 seconds
DEBUG 01-07 10:14:16.190350.190350 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-07 10:14:16.190221.190221 lmp.py:816] 
DEBUG 01-07 10:14:16.190221.190221 lmp.py:816]   Computing 19 experts on CPU...
DEBUG 01-07 10:14:16.190580.190580 cuda_h.py:19] end cpu_experts_submit cost 0.00010633468627929688 seconds
DEBUG 01-07 10:14:16.190230.190230 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-07 10:14:16.198804.198804 mlpmodule.py:749] group tensors cost 0.007711172103881836 s
DEBUG 01-07 10:14:16.201835.201835 mlpmodule.py:787] pad cost 0.002150297164916992 s
DEBUG 01-07 10:14:16.201424.201424 mlpmodule.py:793] create cpu tensor cost 7.605552673339844e-05 s
DEBUG 01-07 10:14:16.201084.201084 mlpmodule.py:798] move to cpu cost 5.793571472167969e-05 s
DEBUG 01-07 10:14:16.209445.209445 mlpmodule.py:812] group_w3: shape=torch.Size([19, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=54788096
DEBUG 01-07 10:14:16.209365.209365 mlpmodule.py:813] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-07 10:14:16.209726.209726 mlpmodule.py:818] group_w3 first element: -0.02734375
WARNING 01-07 10:14:16.209736.209736 mlpmodule.py:828] start einsum2
DEBUG 01-07 10:14:16.220222.220222 mlpmodule.py:838] group einsum cost 0.018247127532958984 s
DEBUG 01-07 10:14:16.220216.220216 mlpmodule.py:846] cpy2cputensor cost 0.000400543212890625 s
DEBUG 01-07 10:14:16.223131.223131 cuda_h.py:19] end wait_cetm_experts cost 0.03281712532043457 seconds
DEBUG 01-07 10:14:16.223075.223075 cuda_h.py:10] start gpu_sexperts
DEBUG 01-07 10:14:16.224028.224028 cuda_h.py:19] end gpu_sexperts cost 0.0005109310150146484 seconds
DEBUG 01-07 10:14:16.224017.224017 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-07 10:14:16.224920.224920 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.6702880859375e-05 seconds
DEBUG 01-07 10:14:16.224437.224437 cuda_h.py:10] start wait_experts_multi_device
INFO 01-07 10:14:16.224591.224591 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 955abed9-d24d-4e6d-ad02-f5cdc98d40a9
INFO 01-07 10:14:16.227243.227243 client.py:127] Model loaded
INFO 01-07 10:14:16.227609.227609 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, c01135a2-f59f-4eff-ac6c-79d0462d8198
INFO 01-07 10:14:16.229180.229180 client.py:127] Model loaded
DEBUG 01-07 10:14:16.229824.229824 cuda_h.py:19] end wait_experts_multi_device cost 0.005581378936767578 seconds
DEBUG 01-07 10:14:16.229434.229434 cuda_h.py:10] start gpu_experts_multi_device
DEBUG 01-07 10:14:16.230449.230449 lmp.py:867]   Computing 22 experts on cuda:2...
DEBUG 01-07 10:14:16.231819.231819 mlpmodule.py:533] gpu group tensors cost 0.00048542022705078125 s
DEBUG 01-07 10:14:16.231492.231492 mlpmodule.py:707]  experts func einsum cost 0.04054856300354004 s
DEBUG 01-07 10:14:16.232178.232178 mlpmodule.py:566] gpu pad cost 0.0013511180877685547 s
DEBUG 01-07 10:14:16.233129.233129 mlpmodule.py:584] gpu group einsum cost 0.0004494190216064453 s
DEBUG 01-07 10:14:16.234925.234925 mlpmodule.py:656] gpu experts func einsum cost 0.004252433776855469 s
DEBUG 01-07 10:14:16.235742.235742 lmp.py:867]   Computing 23 experts on cuda:1...
DEBUG 01-07 10:14:16.235639.235639 mlpmodule.py:533] gpu group tensors cost 0.0003781318664550781 s
DEBUG 01-07 10:14:16.237254.237254 mlpmodule.py:566] gpu pad cost 0.001102447509765625 s
DEBUG 01-07 10:14:16.237302.237302 mlpmodule.py:584] gpu group einsum cost 0.0003917217254638672 s
DEBUG 01-07 10:14:16.239584.239584 mlpmodule.py:656] gpu experts func einsum cost 0.003673076629638672 s
DEBUG 01-07 10:14:16.239011.239011 cuda_h.py:19] end gpu_experts_multi_device cost 0.009280681610107422 seconds
DEBUG 01-07 10:14:16.239404.239404 cuda_h.py:19] end layer_moe_generate_multi_device_25 cost 0.059304237365722656 seconds
DEBUG 01-07 10:14:16.239856.239856 lmp.py:194] -------------------------------- end prefill layer 25 --------------------------------
DEBUG 01-07 10:14:16.239334.239334 lmp.py:153] -------------------------------- start prefill layer 26 --------------------------------
DEBUG 01-07 10:14:16.239791.239791 cuda_h.py:10] start start_load_qkvogn_s_weight_l_27
DEBUG 01-07 10:14:16.239355.239355 cuda_h.py:10] start start_load_qkvogn_s_weight_l_27
DEBUG 01-07 10:14:16.239284.239284 cuda_h.py:19] end start_load_qkvogn_s_weight_l_27 cost 2.7179718017578125e-05 seconds
DEBUG 01-07 10:14:16.239603.239603 cuda_h.py:19] end start_load_qkvogn_s_weight_l_27 cost 5.5789947509765625e-05 seconds
DEBUG 01-07 10:14:16.239199.239199 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-07 10:14:16.239844.239844 mlpmodule.py:367] cuda:1 cuda:1
DEBUG 01-07 10:14:16.239263.239263 cuda_h.py:10] start sllm_worker_task
DEBUG 01-07 10:14:16.239710.239710 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 10:14:16.240307.240307 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 10:14:16.240623.240623 cuda_h.py:19] end allocate_cuda_memory cost 0.00030303001403808594 seconds
DEBUG 01-07 10:14:16.240792.240792 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 10:14:16.240839.240839 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 10:14:16.240232.240232 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 10:14:16.240312.240312 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, ac7bf7d0-9fb2-425b-9852-56473659784d
DEBUG 01-07 10:14:16.240314.240314 client.py:106] call stub.LoadModelAsync
DEBUG 01-07 10:14:16.240215.240215 cuda_h.py:10] start self_attn
INFO 01-07 10:14:16.241711.241711 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, ac7bf7d0-9fb2-425b-9852-56473659784d
DEBUG 01-07 10:14:16.241515.241515 cuda_h.py:19] end load_into_gpu_async cost 0.001375436782836914 seconds
DEBUG 01-07 10:14:16.241741.241741 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 10:14:16.241247.241247 cuda_h.py:19] end restore_tensors2 cost 6.747245788574219e-05 seconds
DEBUG 01-07 10:14:16.241096.241096 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0020067691802978516 seconds
INFO 01-07 10:14:16.242587.242587 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, ac7bf7d0-9fb2-425b-9852-56473659784d
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-07 10:14:16.244854.244854 cuda_h.py:19] end self_attn cost 0.0033936500549316406 seconds
DEBUG 01-07 10:14:16.244520.244520 cuda_h.py:19] end iln_self_attn_paln cost 0.004807710647583008 seconds
DEBUG 01-07 10:14:16.244966.244966 cuda_h.py:10] start layer_moe_generate_multi_device_26
DEBUG 01-07 10:14:16.244821.244821 cuda_h.py:10] start gate
DEBUG 01-07 10:14:16.245763.245763 cuda_h.py:19] end gate cost 0.0008015632629394531 seconds
DEBUG 01-07 10:14:16.245162.245162 cuda_h.py:10] start experts_map_get
DEBUG 01-07 10:14:16.245930.245930 lmp.py:744] 
DEBUG 01-07 10:14:16.245930.245930 lmp.py:744] Expert Token Distribution & Multi-Device Allocation:
DEBUG 01-07 10:14:16.245355.245355 lmp.py:745]   Total experts: 64
DEBUG 01-07 10:14:16.246958.246958 lmp.py:746]   CPU experts: 19 (30%)
DEBUG 01-07 10:14:16.246270.246270 lmp.py:747]   GPU experts: 45 (70%)
DEBUG 01-07 10:14:16.246436.246436 lmp.py:748]   Number of GPU devices: 2
DEBUG 01-07 10:14:16.246126.246126 lmp.py:749] 
DEBUG 01-07 10:14:16.246126.246126 lmp.py:749]   Expert ID | Tokens | Device
DEBUG 01-07 10:14:16.246292.246292 lmp.py:750]   -----------------------------------
DEBUG 01-07 10:14:16.246895.246895 lmp.py:767]   Expert 20 |      9 | CPU
DEBUG 01-07 10:14:16.246300.246300 lmp.py:767]   Expert 61 |     10 | CPU
DEBUG 01-07 10:14:16.246512.246512 lmp.py:767]   Expert 11 |     26 | CPU
DEBUG 01-07 10:14:16.246963.246963 lmp.py:767]   Expert  7 |     34 | CPU
DEBUG 01-07 10:14:16.246176.246176 lmp.py:767]   Expert 62 |     42 | CPU
DEBUG 01-07 10:14:16.246388.246388 lmp.py:767]   Expert  3 |     45 | CPU
DEBUG 01-07 10:14:16.246554.246554 lmp.py:767]   Expert 51 |     46 | CPU
DEBUG 01-07 10:14:16.246244.246244 lmp.py:767]   Expert 30 |     50 | CPU
DEBUG 01-07 10:14:16.246456.246456 lmp.py:767]   Expert 17 |     52 | CPU
DEBUG 01-07 10:14:16.246430.246430 lmp.py:767]   Expert 29 |     56 | CPU
DEBUG 01-07 10:14:16.246404.246404 lmp.py:767]   Expert  6 |     58 | CPU
DEBUG 01-07 10:14:16.246617.246617 lmp.py:767]   Expert  9 |     64 | CPU
DEBUG 01-07 10:14:16.246591.246591 lmp.py:767]   Expert 38 |     74 | CPU
DEBUG 01-07 10:14:16.246326.246326 lmp.py:767]   Expert 63 |     79 | CPU
DEBUG 01-07 10:14:16.246062.246062 lmp.py:767]   Expert 55 |     82 | CPU
DEBUG 01-07 10:14:16.246943.246943 lmp.py:767]   Expert 59 |     84 | CPU
DEBUG 01-07 10:14:16.246871.246871 lmp.py:767]   Expert 19 |     93 | CPU
DEBUG 01-07 10:14:16.246845.246845 lmp.py:767]   Expert  8 |     96 | CPU
DEBUG 01-07 10:14:16.246057.246057 lmp.py:767]   Expert 48 |     97 | CPU
DEBUG 01-07 10:14:16.246700.246700 lmp.py:767]   Expert 22 |    104 | GPU0(cuda:1)
DEBUG 01-07 10:14:16.246582.246582 lmp.py:767]   Expert 49 |    104 | GPU1(cuda:2)
DEBUG 01-07 10:14:16.246225.246225 lmp.py:767]   Expert 24 |    113 | GPU1(cuda:2)
DEBUG 01-07 10:14:16.246775.246775 lmp.py:767]   Expert 34 |    113 | GPU0(cuda:1)
DEBUG 01-07 10:14:16.246133.246133 lmp.py:767]   Expert 36 |    113 | GPU1(cuda:2)
DEBUG 01-07 10:14:16.246968.246968 lmp.py:767]   Expert 42 |    117 | GPU0(cuda:1)
DEBUG 01-07 10:14:16.246804.246804 lmp.py:767]   Expert 50 |    118 | GPU1(cuda:2)
DEBUG 01-07 10:14:16.246685.246685 lmp.py:767]   Expert 39 |    125 | GPU0(cuda:1)
DEBUG 01-07 10:14:16.246328.246328 lmp.py:767]   Expert  4 |    134 | GPU1(cuda:2)
DEBUG 01-07 10:14:16.246971.246971 lmp.py:767]   Expert 37 |    142 | GPU0(cuda:1)
DEBUG 01-07 10:14:16.246614.246614 lmp.py:767]   Expert 15 |    146 | GPU1(cuda:2)
DEBUG 01-07 10:14:16.246495.246495 lmp.py:767]   Expert 41 |    150 | GPU0(cuda:1)
DEBUG 01-07 10:14:16.246377.246377 lmp.py:767]   Expert 23 |    157 | GPU1(cuda:2)
DEBUG 01-07 10:14:16.246020.246020 lmp.py:767]   Expert 56 |    163 | GPU0(cuda:1)
DEBUG 01-07 10:14:16.246378.246378 lmp.py:767]   Expert 16 |    165 | GPU1(cuda:2)
DEBUG 01-07 10:14:16.246259.246259 lmp.py:767]   Expert 44 |    172 | GPU0(cuda:1)
DEBUG 01-07 10:14:16.246141.246141 lmp.py:767]   Expert  1 |    173 | GPU1(cuda:2)
DEBUG 01-07 10:14:16.246022.246022 lmp.py:767]   Expert 60 |    176 | GPU0(cuda:1)
DEBUG 01-07 10:14:16.246903.246903 lmp.py:767]   Expert 43 |    178 | GPU1(cuda:2)
DEBUG 01-07 10:14:16.246785.246785 lmp.py:767]   Expert 21 |    182 | GPU0(cuda:1)
DEBUG 01-07 10:14:16.246428.246428 lmp.py:767]   Expert 53 |    193 | GPU1(cuda:2)
DEBUG 01-07 10:14:16.246309.246309 lmp.py:767]   Expert 47 |    198 | GPU0(cuda:1)
DEBUG 01-07 10:14:16.246667.246667 lmp.py:767]   Expert 12 |    200 | GPU1(cuda:2)
DEBUG 01-07 10:14:16.246264.246264 lmp.py:767]   Expert 33 |    201 | GPU0(cuda:1)
DEBUG 01-07 10:14:16.246145.246145 lmp.py:767]   Expert 13 |    207 | GPU1(cuda:2)
DEBUG 01-07 10:14:16.246788.246788 lmp.py:767]   Expert 32 |    223 | GPU0(cuda:1)
DEBUG 01-07 10:14:16.246431.246431 lmp.py:767]   Expert 28 |    228 | GPU1(cuda:2)
DEBUG 01-07 10:14:16.246313.246313 lmp.py:767]   Expert  0 |    253 | GPU0(cuda:1)
DEBUG 01-07 10:14:16.246909.246909 lmp.py:767]   Expert 54 |    258 | GPU1(cuda:2)
DEBUG 01-07 10:14:16.246268.246268 lmp.py:767]   Expert 31 |    259 | GPU0(cuda:1)
DEBUG 01-07 10:14:16.246149.246149 lmp.py:767]   Expert 26 |    264 | GPU1(cuda:2)
DEBUG 01-07 10:14:16.246792.246792 lmp.py:767]   Expert 10 |    265 | GPU0(cuda:1)
DEBUG 01-07 10:14:16.246435.246435 lmp.py:767]   Expert 18 |    271 | GPU0(cuda:1)
DEBUG 01-07 10:14:16.247316.247316 lmp.py:767]   Expert 57 |    271 | GPU1(cuda:2)
DEBUG 01-07 10:14:16.247959.247959 lmp.py:767]   Expert  2 |    285 | GPU1(cuda:2)
DEBUG 01-07 10:14:16.247079.247079 lmp.py:767]   Expert 58 |    294 | GPU0(cuda:1)
DEBUG 01-07 10:14:16.247437.247437 lmp.py:767]   Expert 40 |    337 | GPU1(cuda:2)
DEBUG 01-07 10:14:16.247557.247557 lmp.py:767]   Expert 45 |    361 | GPU0(cuda:1)
DEBUG 01-07 10:14:16.247439.247439 lmp.py:767]   Expert 25 |    362 | GPU1(cuda:2)
DEBUG 01-07 10:14:16.247082.247082 lmp.py:767]   Expert  5 |    441 | GPU0(cuda:1)
DEBUG 01-07 10:14:16.247725.247725 lmp.py:767]   Expert 35 |    464 | GPU1(cuda:2)
DEBUG 01-07 10:14:16.247606.247606 lmp.py:767]   Expert 27 |    482 | GPU0(cuda:1)
DEBUG 01-07 10:14:16.247249.247249 lmp.py:767]   Expert 46 |    551 | GPU1(cuda:2)
DEBUG 01-07 10:14:16.247130.247130 lmp.py:767]   Expert 52 |    600 | GPU1(cuda:2)
DEBUG 01-07 10:14:16.247012.247012 lmp.py:767]   Expert 14 |    878 | GPU0(cuda:1)
DEBUG 01-07 10:14:16.247178.247178 lmp.py:769] 
DEBUG 01-07 10:14:16.247178.247178 lmp.py:769]   Device Token Distribution:
DEBUG 01-07 10:14:16.247821.247821 lmp.py:770]   CPU:   1097 tokens
DEBUG 01-07 10:14:16.247179.247179 lmp.py:774]   cuda:1:   5570 tokens (22 experts)
DEBUG 01-07 10:14:16.247822.247822 lmp.py:774]   cuda:2:   5621 tokens (23 experts)
DEBUG 01-07 10:14:16.247227.247227 lmp.py:775]   Total GPU:  11191 tokens
DEBUG 01-07 10:14:16.247154.247154 lmp.py:776] ============================================================
DEBUG 01-07 10:14:16.247154.247154 lmp.py:776] 
DEBUG 01-07 10:14:16.247281.247281 cuda_h.py:19] end experts_map_get cost 0.001744985580444336 seconds
DEBUG 01-07 10:14:16.247639.247639 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model_multi_device
DEBUG 01-07 10:14:16.247747.247747 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 10:14:16.247426.247426 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 10:14:16.248107.248107 cuda_h.py:19] end allocate_cuda_memory cost 0.0007143020629882812 seconds
DEBUG 01-07 10:14:16.248440.248440 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 10:14:16.248103.248103 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 10:14:16.248396.248396 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 10:14:16.248761.248761 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, ce0ab861-55b5-43c9-9459-ca0cddc21757
DEBUG 01-07 10:14:16.248673.248673 client.py:106] call stub.LoadModelAsync
INFO 01-07 10:14:16.248388.248388 client.py:127] Model loaded
DEBUG 01-07 10:14:16.249037.249037 cuda_h.py:19] end sllm_worker_task cost 0.009196996688842773 seconds
INFO 01-07 10:14:16.249372.249372 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, ce0ab861-55b5-43c9-9459-ca0cddc21757
DEBUG 01-07 10:14:16.249169.249169 cuda_h.py:19] end load_into_gpu_async cost 0.0011699199676513672 seconds
DEBUG 01-07 10:14:16.249918.249918 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 10:14:16.249364.249364 cuda_h.py:19] end restore_tensors2 cost 0.00023412704467773438 seconds
DEBUG 01-07 10:14:16.249048.249048 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0024406909942626953 seconds
DEBUG 01-07 10:14:16.251162.251162 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 10:14:16.251670.251670 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 10:14:16.252958.252958 cuda_h.py:19] end allocate_cuda_memory cost 0.00024366378784179688 seconds
DEBUG 01-07 10:14:16.252609.252609 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 10:14:16.252411.252411 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 10:14:16.252597.252597 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 10:14:16.252532.252532 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 35dc06ea-70a1-4937-94b9-995bba39137b
DEBUG 01-07 10:14:16.252252.252252 client.py:106] call stub.LoadModelAsync
INFO 01-07 10:14:16.253133.253133 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 35dc06ea-70a1-4937-94b9-995bba39137b
DEBUG 01-07 10:14:16.253816.253816 cuda_h.py:19] end load_into_gpu_async cost 0.0010344982147216797 seconds
DEBUG 01-07 10:14:16.253420.253420 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 10:14:16.253435.253435 cuda_h.py:19] end restore_tensors2 cost 0.0002319812774658203 seconds
DEBUG 01-07 10:14:16.253966.253966 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0018079280853271484 seconds
DEBUG 01-07 10:14:16.255545.255545 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model_multi_device cost 0.00805044174194336 seconds
DEBUG 01-07 10:14:16.255130.255130 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-07 10:14:16.255092.255092 lmp.py:816] 
DEBUG 01-07 10:14:16.255092.255092 lmp.py:816]   Computing 19 experts on CPU...
DEBUG 01-07 10:14:16.255598.255598 cuda_h.py:19] end cpu_experts_submit cost 0.00010728836059570312 seconds
DEBUG 01-07 10:14:16.255247.255247 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-07 10:14:16.262846.262846 mlpmodule.py:749] group tensors cost 0.007029294967651367 s
DEBUG 01-07 10:14:16.265614.265614 mlpmodule.py:787] pad cost 0.0016019344329833984 s
DEBUG 01-07 10:14:16.265604.265604 mlpmodule.py:793] create cpu tensor cost 4.00543212890625e-05 s
DEBUG 01-07 10:14:16.265792.265792 mlpmodule.py:798] move to cpu cost 3.266334533691406e-05 s
DEBUG 01-07 10:14:16.272540.272540 mlpmodule.py:812] group_w3: shape=torch.Size([19, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=54788096
DEBUG 01-07 10:14:16.273844.273844 mlpmodule.py:813] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-07 10:14:16.273397.273397 mlpmodule.py:818] group_w3 first element: -0.0024261474609375
WARNING 01-07 10:14:16.273414.273414 mlpmodule.py:828] start einsum2
DEBUG 01-07 10:14:16.286562.286562 mlpmodule.py:838] group einsum cost 0.020925521850585938 s
DEBUG 01-07 10:14:16.286163.286163 mlpmodule.py:846] cpy2cputensor cost 0.0003452301025390625 s
DEBUG 01-07 10:14:16.289999.289999 cuda_h.py:19] end wait_cetm_experts cost 0.03386735916137695 seconds
DEBUG 01-07 10:14:16.289466.289466 cuda_h.py:10] start gpu_sexperts
DEBUG 01-07 10:14:16.290305.290305 cuda_h.py:19] end gpu_sexperts cost 0.0005040168762207031 seconds
DEBUG 01-07 10:14:16.290586.290586 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-07 10:14:16.290104.290104 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.5033950805664062e-05 seconds
DEBUG 01-07 10:14:16.290576.290576 cuda_h.py:10] start wait_experts_multi_device
INFO 01-07 10:14:16.290193.290193 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, ce0ab861-55b5-43c9-9459-ca0cddc21757
INFO 01-07 10:14:16.291945.291945 client.py:127] Model loaded
INFO 01-07 10:14:16.291304.291304 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 35dc06ea-70a1-4937-94b9-995bba39137b
INFO 01-07 10:14:16.295294.295294 client.py:127] Model loaded
DEBUG 01-07 10:14:16.295984.295984 cuda_h.py:19] end wait_experts_multi_device cost 0.005256175994873047 seconds
DEBUG 01-07 10:14:16.295356.295356 cuda_h.py:10] start gpu_experts_multi_device
DEBUG 01-07 10:14:16.295656.295656 lmp.py:867]   Computing 23 experts on cuda:2...
DEBUG 01-07 10:14:16.296047.296047 mlpmodule.py:533] gpu group tensors cost 0.0005195140838623047 s
DEBUG 01-07 10:14:16.297267.297267 mlpmodule.py:707]  experts func einsum cost 0.04138660430908203 s
DEBUG 01-07 10:14:16.298294.298294 mlpmodule.py:566] gpu pad cost 0.0013737678527832031 s
DEBUG 01-07 10:14:16.298097.298097 mlpmodule.py:584] gpu group einsum cost 0.0005481243133544922 s
DEBUG 01-07 10:14:16.301616.301616 mlpmodule.py:656] gpu experts func einsum cost 0.004662990570068359 s
DEBUG 01-07 10:14:16.301327.301327 lmp.py:867]   Computing 22 experts on cuda:1...
DEBUG 01-07 10:14:16.302045.302045 mlpmodule.py:533] gpu group tensors cost 0.0003876686096191406 s
DEBUG 01-07 10:14:16.303261.303261 mlpmodule.py:566] gpu pad cost 0.0010521411895751953 s
DEBUG 01-07 10:14:16.303826.303826 mlpmodule.py:584] gpu group einsum cost 0.0003948211669921875 s
DEBUG 01-07 10:14:16.305364.305364 mlpmodule.py:656] gpu experts func einsum cost 0.003571748733520508 s
DEBUG 01-07 10:14:16.305433.305433 cuda_h.py:19] end gpu_experts_multi_device cost 0.009579658508300781 seconds
DEBUG 01-07 10:14:16.305065.305065 cuda_h.py:19] end layer_moe_generate_multi_device_26 cost 0.060682058334350586 seconds
DEBUG 01-07 10:14:16.305423.305423 lmp.py:194] -------------------------------- end prefill layer 26 --------------------------------
DEBUG 01-07 10:14:16.305425.305425 lmp.py:153] -------------------------------- start prefill layer 27 --------------------------------
DEBUG 01-07 10:14:16.305359.305359 cuda_h.py:10] start start_load_qkvogn_s_weight_l_28
DEBUG 01-07 10:14:16.305791.305791 cuda_h.py:19] end start_load_qkvogn_s_weight_l_28 cost 1.0967254638671875e-05 seconds
DEBUG 01-07 10:14:16.305864.305864 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-07 10:14:16.305647.305647 mlpmodule.py:367] cuda:1 cuda:1
DEBUG 01-07 10:14:16.306690.306690 cuda_h.py:10] start self_attn
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-07 10:14:16.308214.308214 cuda_h.py:19] end self_attn cost 0.002546072006225586 seconds
DEBUG 01-07 10:14:16.308052.308052 cuda_h.py:19] end iln_self_attn_paln cost 0.0032002925872802734 seconds
DEBUG 01-07 10:14:16.308259.308259 cuda_h.py:10] start layer_moe_generate_multi_device_27
DEBUG 01-07 10:14:16.309161.309161 cuda_h.py:10] start gate
DEBUG 01-07 10:14:16.309227.309227 cuda_h.py:19] end gate cost 0.0005779266357421875 seconds
DEBUG 01-07 10:14:16.309626.309626 cuda_h.py:10] start experts_map_get
DEBUG 01-07 10:14:16.310732.310732 lmp.py:744] 
DEBUG 01-07 10:14:16.310732.310732 lmp.py:744] Expert Token Distribution & Multi-Device Allocation:
DEBUG 01-07 10:14:16.310442.310442 lmp.py:745]   Total experts: 64
DEBUG 01-07 10:14:16.310092.310092 lmp.py:746]   CPU experts: 19 (30%)
DEBUG 01-07 10:14:16.310880.310880 lmp.py:747]   GPU experts: 45 (70%)
DEBUG 01-07 10:14:16.310047.310047 lmp.py:748]   Number of GPU devices: 2
DEBUG 01-07 10:14:16.310736.310736 lmp.py:749] 
DEBUG 01-07 10:14:16.310736.310736 lmp.py:749]   Expert ID | Tokens | Device
DEBUG 01-07 10:14:16.310664.310664 lmp.py:750]   -----------------------------------
DEBUG 01-07 10:14:16.310313.310313 lmp.py:767]   Expert 18 |     65 | CPU
DEBUG 01-07 10:14:16.310718.310718 lmp.py:767]   Expert 47 |     66 | CPU
DEBUG 01-07 10:14:16.310646.310646 lmp.py:767]   Expert 54 |     74 | CPU
DEBUG 01-07 10:14:16.310812.310812 lmp.py:767]   Expert 23 |     76 | CPU
DEBUG 01-07 10:14:16.310739.310739 lmp.py:767]   Expert 44 |     79 | CPU
DEBUG 01-07 10:14:16.310429.310429 lmp.py:767]   Expert 48 |     83 | CPU
DEBUG 01-07 10:14:16.310880.310880 lmp.py:767]   Expert 45 |     85 | CPU
DEBUG 01-07 10:14:16.310854.310854 lmp.py:767]   Expert 20 |     92 | CPU
DEBUG 01-07 10:14:16.310305.310305 lmp.py:767]   Expert 31 |     97 | CPU
DEBUG 01-07 10:14:16.310517.310517 lmp.py:767]   Expert 36 |    104 | CPU
DEBUG 01-07 10:14:16.310445.310445 lmp.py:767]   Expert 61 |    112 | CPU
DEBUG 01-07 10:14:16.310372.310372 lmp.py:767]   Expert 42 |    117 | CPU
DEBUG 01-07 10:14:16.310823.310823 lmp.py:767]   Expert 33 |    119 | CPU
DEBUG 01-07 10:14:16.310036.310036 lmp.py:767]   Expert 24 |    121 | CPU
DEBUG 01-07 10:14:16.310248.310248 lmp.py:767]   Expert 10 |    123 | CPU
DEBUG 01-07 10:14:16.310699.310699 lmp.py:767]   Expert 43 |    124 | CPU
DEBUG 01-07 10:14:16.310388.310388 lmp.py:767]   Expert 49 |    126 | CPU
DEBUG 01-07 10:14:16.310316.310316 lmp.py:767]   Expert 11 |    127 | CPU
DEBUG 01-07 10:14:16.310767.310767 lmp.py:767]   Expert 56 |    132 | CPU
DEBUG 01-07 10:14:16.310410.310410 lmp.py:767]   Expert  6 |    140 | GPU1(cuda:2)
DEBUG 01-07 10:14:16.310815.310815 lmp.py:767]   Expert 51 |    143 | GPU0(cuda:1)
DEBUG 01-07 10:14:16.310458.310458 lmp.py:767]   Expert 17 |    145 | GPU1(cuda:2)
DEBUG 01-07 10:14:16.310101.310101 lmp.py:767]   Expert  0 |    148 | GPU0(cuda:1)
DEBUG 01-07 10:14:16.310744.310744 lmp.py:767]   Expert 12 |    154 | GPU1(cuda:2)
DEBUG 01-07 10:14:16.310625.310625 lmp.py:767]   Expert  5 |    155 | GPU0(cuda:1)
DEBUG 01-07 10:14:16.310553.310553 lmp.py:767]   Expert 40 |    156 | GPU1(cuda:2)
DEBUG 01-07 10:14:16.310480.310480 lmp.py:767]   Expert 59 |    161 | GPU0(cuda:1)
DEBUG 01-07 10:14:16.310646.310646 lmp.py:767]   Expert 57 |    164 | GPU1(cuda:2)
DEBUG 01-07 10:14:16.310813.310813 lmp.py:767]   Expert 26 |    165 | GPU1(cuda:2)
DEBUG 01-07 10:14:16.310740.310740 lmp.py:767]   Expert 55 |    165 | GPU0(cuda:1)
DEBUG 01-07 10:14:16.310668.310668 lmp.py:767]   Expert 38 |    169 | GPU0(cuda:1)
DEBUG 01-07 10:14:16.310549.310549 lmp.py:767]   Expert 13 |    170 | GPU1(cuda:2)
DEBUG 01-07 10:14:16.310431.310431 lmp.py:767]   Expert 30 |    172 | GPU1(cuda:2)
DEBUG 01-07 10:14:16.310359.310359 lmp.py:767]   Expert 46 |    172 | GPU0(cuda:1)
DEBUG 01-07 10:14:16.310763.310763 lmp.py:767]   Expert 58 |    173 | GPU0(cuda:1)
DEBUG 01-07 10:14:16.310929.310929 lmp.py:767]   Expert 35 |    174 | GPU1(cuda:2)
DEBUG 01-07 10:14:16.310380.310380 lmp.py:767]   Expert 50 |    178 | GPU0(cuda:1)
DEBUG 01-07 10:14:16.310069.310069 lmp.py:767]   Expert  7 |    180 | GPU1(cuda:2)
DEBUG 01-07 10:14:16.310997.310997 lmp.py:767]   Expert 16 |    181 | GPU0(cuda:1)
DEBUG 01-07 10:14:16.310640.310640 lmp.py:767]   Expert 14 |    202 | GPU1(cuda:2)
DEBUG 01-07 10:14:16.310045.310045 lmp.py:767]   Expert 15 |    203 | GPU0(cuda:1)
DEBUG 01-07 10:14:16.310211.310211 lmp.py:767]   Expert 32 |    204 | GPU1(cuda:2)
DEBUG 01-07 10:14:16.310377.310377 lmp.py:767]   Expert  1 |    213 | GPU0(cuda:1)
DEBUG 01-07 10:14:16.310543.310543 lmp.py:767]   Expert  3 |    225 | GPU1(cuda:2)
DEBUG 01-07 10:14:16.310471.310471 lmp.py:767]   Expert  4 |    227 | GPU0(cuda:1)
DEBUG 01-07 10:14:16.310399.310399 lmp.py:767]   Expert 39 |    236 | GPU1(cuda:2)
DEBUG 01-07 10:14:16.310849.310849 lmp.py:767]   Expert 52 |    244 | GPU0(cuda:1)
DEBUG 01-07 10:14:16.311254.311254 lmp.py:767]   Expert 34 |    246 | GPU1(cuda:2)
DEBUG 01-07 10:14:16.311135.311135 lmp.py:767]   Expert 25 |    249 | GPU0(cuda:1)
DEBUG 01-07 10:14:16.311302.311302 lmp.py:767]   Expert 28 |    251 | GPU1(cuda:2)
DEBUG 01-07 10:14:16.311229.311229 lmp.py:767]   Expert 22 |    254 | GPU0(cuda:1)
DEBUG 01-07 10:14:16.311157.311157 lmp.py:767]   Expert  2 |    274 | GPU1(cuda:2)
DEBUG 01-07 10:14:16.311846.311846 lmp.py:767]   Expert 21 |    277 | GPU0(cuda:1)
DEBUG 01-07 10:14:16.311012.311012 lmp.py:767]   Expert 62 |    282 | GPU1(cuda:2)
DEBUG 01-07 10:14:16.311417.311417 lmp.py:767]   Expert 41 |    285 | GPU1(cuda:2)
DEBUG 01-07 10:14:16.311298.311298 lmp.py:767]   Expert 60 |    285 | GPU0(cuda:1)
DEBUG 01-07 10:14:16.311941.311941 lmp.py:767]   Expert 63 |    287 | GPU0(cuda:1)
DEBUG 01-07 10:14:16.311107.311107 lmp.py:767]   Expert 29 |    290 | GPU1(cuda:2)
DEBUG 01-07 10:14:16.311512.311512 lmp.py:767]   Expert 27 |    302 | GPU0(cuda:1)
DEBUG 01-07 10:14:16.311440.311440 lmp.py:767]   Expert 37 |    330 | GPU1(cuda:2)
DEBUG 01-07 10:14:16.311367.311367 lmp.py:767]   Expert  8 |    334 | GPU0(cuda:1)
DEBUG 01-07 10:14:16.311772.311772 lmp.py:767]   Expert 53 |    339 | GPU1(cuda:2)
DEBUG 01-07 10:14:16.311177.311177 lmp.py:767]   Expert 19 |    441 | GPU1(cuda:2)
DEBUG 01-07 10:14:16.311104.311104 lmp.py:767]   Expert  9 |    621 | GPU0(cuda:1)
DEBUG 01-07 10:14:16.311840.311840 lmp.py:769] 
DEBUG 01-07 10:14:16.311840.311840 lmp.py:769]   Device Token Distribution:
DEBUG 01-07 10:14:16.311768.311768 lmp.py:770]   CPU:   1922 tokens
DEBUG 01-07 10:14:16.311411.311411 lmp.py:774]   cuda:1:   5141 tokens (22 experts)
DEBUG 01-07 10:14:16.311292.311292 lmp.py:774]   cuda:2:   5225 tokens (23 experts)
DEBUG 01-07 10:14:16.311981.311981 lmp.py:775]   Total GPU:  10366 tokens
DEBUG 01-07 10:14:16.311432.311432 lmp.py:776] ============================================================
DEBUG 01-07 10:14:16.311432.311432 lmp.py:776] 
DEBUG 01-07 10:14:16.311082.311082 cuda_h.py:19] end experts_map_get cost 0.0017120838165283203 seconds
DEBUG 01-07 10:14:16.311963.311963 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model_multi_device
DEBUG 01-07 10:14:16.311548.311548 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 10:14:16.311134.311134 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 10:14:16.311178.311178 cuda_h.py:19] end allocate_cuda_memory cost 0.0002818107604980469 seconds
DEBUG 01-07 10:14:16.311988.311988 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 10:14:16.311221.311221 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 10:14:16.312660.312660 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 10:14:16.312025.312025 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 9ae7c55f-9ad7-4f13-8274-7516ca34377b
DEBUG 01-07 10:14:16.312672.312672 client.py:106] call stub.LoadModelAsync
INFO 01-07 10:14:16.313734.313734 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 9ae7c55f-9ad7-4f13-8274-7516ca34377b
DEBUG 01-07 10:14:16.313709.313709 cuda_h.py:19] end load_into_gpu_async cost 0.0011324882507324219 seconds
DEBUG 01-07 10:14:16.313790.313790 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 10:14:16.313547.313547 cuda_h.py:19] end restore_tensors2 cost 0.0002536773681640625 seconds
DEBUG 01-07 10:14:16.313648.313648 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0019845962524414062 seconds
DEBUG 01-07 10:14:16.315153.315153 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-07 10:14:16.315582.315582 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-07 10:14:16.315180.315180 cuda_h.py:19] end allocate_cuda_memory cost 0.00022792816162109375 seconds
DEBUG 01-07 10:14:16.315831.315831 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-07 10:14:16.315349.315349 sllm_store_c.py:27] get device uuid map
DEBUG 01-07 10:14:16.315966.315966 sllm_store_c.py:29] call client load into gpu
DEBUG 01-07 10:14:16.315377.315377 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, b89ed0f3-123c-44be-96a6-5b039863006f
DEBUG 01-07 10:14:16.316336.316336 client.py:106] call stub.LoadModelAsync
INFO 01-07 10:14:16.316628.316628 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, b89ed0f3-123c-44be-96a6-5b039863006f
DEBUG 01-07 10:14:16.316219.316219 cuda_h.py:19] end load_into_gpu_async cost 0.0010612010955810547 seconds
DEBUG 01-07 10:14:16.316776.316776 cuda_h.py:10] start restore_tensors2
DEBUG 01-07 10:14:16.317361.317361 cuda_h.py:19] end restore_tensors2 cost 0.00023102760314941406 seconds
DEBUG 01-07 10:14:16.317607.317607 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0018274784088134766 seconds
DEBUG 01-07 10:14:16.319808.319808 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model_multi_device cost 0.007584810256958008 seconds
DEBUG 01-07 10:14:16.319445.319445 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-07 10:14:16.319885.319885 lmp.py:816] 
DEBUG 01-07 10:14:16.319885.319885 lmp.py:816]   Computing 19 experts on CPU...
DEBUG 01-07 10:14:16.319728.319728 cuda_h.py:19] end cpu_experts_submit cost 0.00011086463928222656 seconds
DEBUG 01-07 10:14:16.319854.319854 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-07 10:14:16.326316.326316 mlpmodule.py:749] group tensors cost 0.0070993900299072266 s
DEBUG 01-07 10:14:16.328087.328087 mlpmodule.py:787] pad cost 0.0011448860168457031 s
DEBUG 01-07 10:14:16.328755.328755 mlpmodule.py:793] create cpu tensor cost 4.76837158203125e-05 s
DEBUG 01-07 10:14:16.328056.328056 mlpmodule.py:798] move to cpu cost 3.6716461181640625e-05 s
DEBUG 01-07 10:14:16.335180.335180 mlpmodule.py:812] group_w3: shape=torch.Size([19, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=54788096
DEBUG 01-07 10:14:16.335146.335146 mlpmodule.py:813] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-07 10:14:16.335965.335965 mlpmodule.py:818] group_w3 first element: -0.01263427734375
WARNING 01-07 10:14:16.335380.335380 mlpmodule.py:828] start einsum2
DEBUG 01-07 10:14:16.346763.346763 mlpmodule.py:838] group einsum cost 0.018065214157104492 s
DEBUG 01-07 10:14:16.347990.347990 mlpmodule.py:846] cpy2cputensor cost 0.0004494190216064453 s
DEBUG 01-07 10:14:16.350734.350734 cuda_h.py:19] end wait_cetm_experts cost 0.030765533447265625 seconds
DEBUG 01-07 10:14:16.350631.350631 cuda_h.py:10] start gpu_sexperts
DEBUG 01-07 10:14:16.350709.350709 cuda_h.py:19] end gpu_sexperts cost 0.0005040168762207031 seconds
DEBUG 01-07 10:14:16.350513.350513 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-07 10:14:16.350249.350249 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 1.2874603271484375e-05 seconds
DEBUG 01-07 10:14:16.350767.350767 cuda_h.py:10] start wait_experts_multi_device
INFO 01-07 10:14:16.350338.350338 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 9ae7c55f-9ad7-4f13-8274-7516ca34377b
INFO 01-07 10:14:16.355282.355282 client.py:127] Model loaded
INFO 01-07 10:14:16.355370.355370 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, b89ed0f3-123c-44be-96a6-5b039863006f
DEBUG 01-07 10:14:16.357712.357712 mlpmodule.py:707]  experts func einsum cost 0.03852438926696777 s
INFO 01-07 10:14:16.359569.359569 client.py:127] Model loaded
DEBUG 01-07 10:14:16.359087.359087 cuda_h.py:19] end wait_experts_multi_device cost 0.008946418762207031 seconds
DEBUG 01-07 10:14:16.359843.359843 cuda_h.py:10] start gpu_experts_multi_device
DEBUG 01-07 10:14:16.359289.359289 lmp.py:867]   Computing 23 experts on cuda:2...
DEBUG 01-07 10:14:16.361605.361605 mlpmodule.py:533] gpu group tensors cost 0.0004665851593017578 s
DEBUG 01-07 10:14:16.362177.362177 mlpmodule.py:566] gpu pad cost 0.0012023448944091797 s
DEBUG 01-07 10:14:16.362535.362535 mlpmodule.py:584] gpu group einsum cost 0.0005066394805908203 s
DEBUG 01-07 10:14:16.364614.364614 mlpmodule.py:656] gpu experts func einsum cost 0.004091501235961914 s
DEBUG 01-07 10:14:16.364344.364344 lmp.py:867]   Computing 22 experts on cuda:1...
DEBUG 01-07 10:14:16.365736.365736 mlpmodule.py:533] gpu group tensors cost 0.0003483295440673828 s
DEBUG 01-07 10:14:16.366539.366539 mlpmodule.py:566] gpu pad cost 0.0009965896606445312 s
DEBUG 01-07 10:14:16.367004.367004 mlpmodule.py:584] gpu group einsum cost 0.0003914833068847656 s
DEBUG 01-07 10:14:16.368820.368820 mlpmodule.py:656] gpu experts func einsum cost 0.003464937210083008 s
DEBUG 01-07 10:14:16.368989.368989 cuda_h.py:19] end gpu_experts_multi_device cost 0.008856773376464844 seconds
DEBUG 01-07 10:14:16.368620.368620 cuda_h.py:19] end layer_moe_generate_multi_device_27 cost 0.05982232093811035 seconds
DEBUG 01-07 10:14:16.369449.369449 lmp.py:194] -------------------------------- end prefill layer 27 --------------------------------
DEBUG 01-07 10:14:16.369457.369457 cuda_h.py:19] end prefill_layer cost 1.8380508422851562 seconds
Collecting data...
Generating '/tmp/nsys-report-d227.qdstrm'
[1/1] [0%                          ] report1.nsys-rep[1/1] [0%                          ] report1.nsys-rep[1/1] [5%                          ] report1.nsys-rep[1/1] [5%                          ] report1.nsys-rep[1/1] [6%                          ] report1.nsys-rep[1/1] [5%                          ] report1.nsys-rep[1/1] [0%                          ] report1.nsys-rep[1/1] [5%                          ] report1.nsys-rep[1/1] [6%                          ] report1.nsys-rep[1/1] [7%                          ] report1.nsys-rep[1/1] [8%                          ] report1.nsys-rep[1/1] [9%                          ] report1.nsys-rep[1/1] [10%                         ] report1.nsys-rep[1/1] [11%                         ] report1.nsys-rep[1/1] [12%                         ] report1.nsys-rep[1/1] [13%                         ] report1.nsys-rep[1/1] [14%                         ] report1.nsys-rep[1/1] [=15%                        ] report1.nsys-rep[1/1] [=16%                        ] report1.nsys-rep[1/1] [=17%                        ] report1.nsys-rep[1/1] [==18%                       ] report1.nsys-rep[1/1] [==19%                       ] report1.nsys-rep[1/1] [==20%                       ] report1.nsys-rep[1/1] [==21%                       ] report1.nsys-rep[1/1] [===22%                      ] report1.nsys-rep[1/1] [===23%                      ] report1.nsys-rep[1/1] [===24%                      ] report1.nsys-rep[1/1] [====25%                     ] report1.nsys-rep[1/1] [====26%                     ] report1.nsys-rep[1/1] [====27%                     ] report1.nsys-rep[1/1] [====28%                     ] report1.nsys-rep[1/1] [=====29%                    ] report1.nsys-rep[1/1] [=====30%                    ] report1.nsys-rep[1/1] [=====31%                    ] report1.nsys-rep[1/1] [=====32%                    ] report1.nsys-rep[1/1] [======34%                   ] report1.nsys-rep[1/1] [=======36%                  ] report1.nsys-rep[1/1] [=======38%                  ] report1.nsys-rep[1/1] [========40%                 ] report1.nsys-rep[1/1] [========42%                 ] report1.nsys-rep[1/1] [=========44%                ] report1.nsys-rep[1/1] [=========46%                ] report1.nsys-rep[1/1] [==========48%               ] report1.nsys-rep[1/1] [===========50%              ] report1.nsys-rep[1/1] [========================100%] report1.nsys-rep[1/1] [========================100%] report1.nsys-rep
Generated:
	/mnt/zhengcf3/lmp/examples/report1.nsys-rep
