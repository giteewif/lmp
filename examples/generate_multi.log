here pin
INFO 01-13 08:46:08.297845.297845 pinpool.py:28] Initializing PinnedMemoryPool with 2GB total, allocating in 1024MB chunks...
DEBUG 01-13 08:46:09.137626.137626 pinpool.py:40] Allocated chunk 1: 536870912 elements (1024.0 MB)
DEBUG 01-13 08:46:09.570160.570160 pinpool.py:40] Allocated chunk 2: 536870912 elements (1024.0 MB)
INFO 01-13 08:46:09.570821.570821 pinpool.py:52] Successfully allocated 2 chunks, total 1073741824 elements (2048.0 MB) in 1.273s
DEBUG 01-13 08:46:09.713307.713307 cuda_memory_view.py:567] 
DEBUG 01-13 08:46:09.713307.713307 cuda_memory_view.py:567] restore_tensors_from_shared_memory_names time: 0.013977766036987305
DEBUG 01-13 08:46:09.730787.730787 cuda_h.py:10] start init_mp_process
DEBUG 01-13 08:46:09.761795.761795 cuda_h.py:19] end init_mp_process cost 0.031191587448120117 seconds
DEBUG 01-13 08:46:11.763267.763267 cuda_h.py:10] start generate_input_ids
generate input ids cost 0.11835598945617676 s
DEBUG 01-13 08:46:12.265322.265322 cuda_h.py:19] end generate_input_ids cost 0.5014333724975586 seconds
DEBUG 01-13 08:46:12.265460.265460 cuda_h.py:10] start init_cache
DEBUG 01-13 08:46:12.265948.265948 cuda_h.py:19] end init_cache cost 9.107589721679688e-05 seconds
here pin
INFO 01-13 08:46:13.632161.632161 pinpool.py:28] Initializing PinnedMemoryPool with 2GB total, allocating in 1024MB chunks...
DEBUG 01-13 08:46:14.428236.428236 pinpool.py:40] Allocated chunk 1: 536870912 elements (1024.0 MB)
DEBUG 01-13 08:46:14.854050.854050 pinpool.py:40] Allocated chunk 2: 536870912 elements (1024.0 MB)
INFO 01-13 08:46:14.854314.854314 pinpool.py:52] Successfully allocated 2 chunks, total 1073741824 elements (2048.0 MB) in 1.222s
DEBUG 01-13 08:46:14.863321.863321 cpu_thread_manager_mp.py:80] 初始化
DEBUG 01-13 08:46:14.968741.968741 cuda_memory_view.py:567] 
DEBUG 01-13 08:46:14.968741.968741 cuda_memory_view.py:567] restore_tensors_from_shared_memory_names time: 0.01910853385925293
DEBUG 01-13 08:46:15.081247.081247 cuda_h.py:10] start init_meta_layer
DEBUG 01-13 08:46:15.082308.082308 cuda_h.py:19] end init_meta_layer cost 1.5974044799804688e-05 seconds
DEBUG 01-13 08:46:15.082210.082210 cuda_h.py:10] start init_weights
DEBUG 01-13 08:46:15.082602.082602 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-13 08:46:15.082941.082941 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-13 08:46:15.082166.082166 cuda_h.py:19] end allocate_cuda_memory cost 0.0005431175231933594 seconds
DEBUG 01-13 08:46:15.082594.082594 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-13 08:46:15.082715.082715 sllm_store_c.py:27] get device uuid map
DEBUG 01-13 08:46:15.082101.082101 sllm_store_c.py:29] call client load into gpu
DEBUG 01-13 08:46:15.082380.082380 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 61286455-c2e3-41c0-a444-17083cf5dc95
DEBUG 01-13 08:46:15.083145.083145 client.py:106] call stub.LoadModelAsync
INFO 01-13 08:46:15.084656.084656 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 61286455-c2e3-41c0-a444-17083cf5dc95
DEBUG 01-13 08:46:15.084368.084368 cuda_h.py:19] end load_into_gpu_async cost 0.001706838607788086 seconds
DEBUG 01-13 08:46:15.084693.084693 cuda_h.py:10] start restore_tensors2
DEBUG 01-13 08:46:15.084479.084479 cuda_h.py:19] end restore_tensors2 cost 8.678436279296875e-05 seconds
DEBUG 01-13 08:46:15.084857.084857 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.002655506134033203 seconds
DEBUG 01-13 08:46:15.084891.084891 cuda_h.py:10] start restore2model
DEBUG 01-13 08:46:15.085773.085773 cuda_h.py:19] end restore2model cost 0.00020313262939453125 seconds
INFO 01-13 08:46:15.085490.085490 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 61286455-c2e3-41c0-a444-17083cf5dc95
INFO 01-13 08:46:15.161570.161570 client.py:127] Model loaded
DEBUG 01-13 08:46:15.161648.161648 cuda_h.py:10] start load_qkvogns_weight_l_0
DEBUG 01-13 08:46:15.161031.161031 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-13 08:46:15.162307.162307 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-13 08:46:15.162363.162363 cuda_h.py:19] end allocate_cuda_memory cost 0.0003933906555175781 seconds
DEBUG 01-13 08:46:15.162196.162196 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-13 08:46:15.162610.162610 sllm_store_c.py:27] get device uuid map
DEBUG 01-13 08:46:15.162037.162037 sllm_store_c.py:29] call client load into gpu
DEBUG 01-13 08:46:15.162715.162715 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 4f276058-5cdf-4864-99f9-f9863d59101c
DEBUG 01-13 08:46:15.163642.163642 client.py:106] call stub.LoadModelAsync
INFO 01-13 08:46:15.164356.164356 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 4f276058-5cdf-4864-99f9-f9863d59101c
DEBUG 01-13 08:46:15.164917.164917 cuda_h.py:19] end load_into_gpu_async cost 0.0020470619201660156 seconds
DEBUG 01-13 08:46:15.164211.164211 cuda_h.py:10] start restore_tensors2
DEBUG 01-13 08:46:15.165113.165113 cuda_h.py:19] end restore_tensors2 cost 0.0001614093780517578 seconds
DEBUG 01-13 08:46:15.165673.165673 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.003263235092163086 seconds
INFO 01-13 08:46:15.165636.165636 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 4f276058-5cdf-4864-99f9-f9863d59101c
INFO 01-13 08:46:15.181166.181166 client.py:127] Model loaded
DEBUG 01-13 08:46:15.181647.181647 cuda_h.py:10] start restore2model
DEBUG 01-13 08:46:15.182118.182118 cuda_h.py:19] end restore2model cost 0.0010797977447509766 seconds
DEBUG 01-13 08:46:15.183930.183930 cuda_h.py:19] end load_qkvogns_weight_l_0 cost 0.02117633819580078 seconds
DEBUG 01-13 08:46:15.183967.183967 cuda_h.py:19] end init_weights cost 0.10107970237731934 seconds
DEBUG 01-13 08:46:15.183214.183214 cuda_h.py:10] start copy_emodel
DEBUG 01-13 08:46:15.957260.957260 cuda_h.py:19] end copy_emodel cost 0.7746071815490723 seconds
DEBUG 01-13 08:46:15.958384.958384 cuda_h.py:10] start init_inputs_tokens
DEBUG 01-13 08:46:16.032281.032281 cuda_h.py:19] end init_inputs_tokens cost 0.07377219200134277 seconds
DEBUG 01-13 08:46:16.032497.032497 cuda_h.py:10] start prefill_layer
DEBUG 01-13 08:46:16.032188.032188 lmp.py:1493] -------------------------------- start prefill layer 0 --------------------------------
DEBUG 01-13 08:46:16.032414.032414 cuda_h.py:10] start start_load_qkvogn_s_weight_l_1
DEBUG 01-13 08:46:16.032170.032170 cuda_h.py:10] start start_load_qkvogn_s_weight_l_1
DEBUG 01-13 08:46:16.032735.032735 cuda_h.py:19] end start_load_qkvogn_s_weight_l_1 cost 3.695487976074219e-05 seconds
DEBUG 01-13 08:46:16.032273.032273 cuda_h.py:19] end start_load_qkvogn_s_weight_l_1 cost 8.606910705566406e-05 seconds
DEBUG 01-13 08:46:16.032731.032731 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-13 08:46:16.033807.033807 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-13 08:46:16.033459.033459 cuda_h.py:10] start sllm_worker_task
DEBUG 01-13 08:46:16.033992.033992 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-13 08:46:16.033895.033895 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-13 08:46:16.033924.033924 cuda_h.py:19] end allocate_cuda_memory cost 0.00022363662719726562 seconds
DEBUG 01-13 08:46:16.033086.033086 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-13 08:46:16.033286.033286 sllm_store_c.py:27] get device uuid map
DEBUG 01-13 08:46:16.033884.033884 sllm_store_c.py:29] call client load into gpu
DEBUG 01-13 08:46:16.033786.033786 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 81a798ed-455b-47a3-b217-f9aa0bcca0d5
DEBUG 01-13 08:46:16.033928.033928 client.py:106] call stub.LoadModelAsync
INFO 01-13 08:46:16.035198.035198 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 81a798ed-455b-47a3-b217-f9aa0bcca0d5
DEBUG 01-13 08:46:16.035101.035101 cuda_h.py:19] end load_into_gpu_async cost 0.0015819072723388672 seconds
DEBUG 01-13 08:46:16.035333.035333 cuda_h.py:10] start restore_tensors2
DEBUG 01-13 08:46:16.035033.035033 cuda_h.py:19] end restore_tensors2 cost 9.584426879882812e-05 seconds
DEBUG 01-13 08:46:16.035372.035372 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.002203702926635742 seconds
INFO 01-13 08:46:16.035758.035758 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 81a798ed-455b-47a3-b217-f9aa0bcca0d5
INFO 01-13 08:46:16.042134.042134 client.py:127] Model loaded
DEBUG 01-13 08:46:16.042600.042600 cuda_h.py:10] start restore2model
DEBUG 01-13 08:46:16.043358.043358 cuda_h.py:19] end restore2model cost 0.00044798851013183594 seconds
DEBUG 01-13 08:46:16.043148.043148 cuda_h.py:19] end sllm_worker_task cost 0.009995460510253906 seconds
DEBUG 01-13 08:46:16.121807.121807 cuda_h.py:10] start self_attn
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-13 08:46:16.362611.362611 cuda_h.py:19] end self_attn cost 0.24140000343322754 seconds
DEBUG 01-13 08:46:16.363178.363178 cuda_h.py:19] end iln_self_attn_paln cost 0.33016490936279297 seconds
DEBUG 01-13 08:46:16.363657.363657 cuda_h.py:10] start dense_mlp
DEBUG 01-13 08:46:16.369001.369001 cuda_h.py:19] end dense_mlp cost 0.006461620330810547 seconds
DEBUG 01-13 08:46:16.369270.369270 lmp.py:1550] -------------------------------- end prefill layer 0 --------------------------------
DEBUG 01-13 08:46:16.369609.369609 lmp.py:1493] -------------------------------- start prefill layer 1 --------------------------------
DEBUG 01-13 08:46:16.369272.369272 cuda_h.py:10] start start_load_qkvogn_s_weight_l_2
DEBUG 01-13 08:46:16.369889.369889 cuda_h.py:10] start start_load_qkvogn_s_weight_l_2
DEBUG 01-13 08:46:16.369024.369024 cuda_h.py:19] end start_load_qkvogn_s_weight_l_2 cost 3.0517578125e-05 seconds
DEBUG 01-13 08:46:16.370350.370350 cuda_h.py:19] end start_load_qkvogn_s_weight_l_2 cost 6.508827209472656e-05 seconds
DEBUG 01-13 08:46:16.370092.370092 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-13 08:46:16.370592.370592 cuda_h.py:10] start sllm_worker_task
DEBUG 01-13 08:46:16.370678.370678 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-13 08:46:16.370111.370111 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-13 08:46:16.370668.370668 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-13 08:46:16.371710.371710 cuda_h.py:19] end allocate_cuda_memory cost 0.0003123283386230469 seconds
DEBUG 01-13 08:46:16.371543.371543 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-13 08:46:16.371891.371891 sllm_store_c.py:27] get device uuid map
DEBUG 01-13 08:46:16.371903.371903 sllm_store_c.py:29] call client load into gpu
DEBUG 01-13 08:46:16.371522.371522 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, a6e27bc7-08fd-4400-a68c-5f40b4e889b8
DEBUG 01-13 08:46:16.371106.371106 client.py:106] call stub.LoadModelAsync
DEBUG 01-13 08:46:16.371751.371751 cuda_h.py:10] start self_attn
INFO 01-13 08:46:16.374748.374748 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, a6e27bc7-08fd-4400-a68c-5f40b4e889b8
DEBUG 01-13 08:46:16.374158.374158 cuda_h.py:19] end load_into_gpu_async cost 0.0030002593994140625 seconds
DEBUG 01-13 08:46:16.374057.374057 cuda_h.py:10] start restore_tensors2
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
DEBUG 01-13 08:46:16.374459.374459 cuda_h.py:19] end restore_tensors2 cost 0.00014710426330566406 seconds
DEBUG 01-13 08:46:16.374900.374900 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.00439453125 seconds
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
INFO 01-13 08:46:16.375164.375164 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, a6e27bc7-08fd-4400-a68c-5f40b4e889b8
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-13 08:46:16.376813.376813 cuda_h.py:19] end self_attn cost 0.003992319107055664 seconds
DEBUG 01-13 08:46:16.376150.376150 cuda_h.py:19] end iln_self_attn_paln cost 0.0064351558685302734 seconds
DEBUG 01-13 08:46:16.376192.376192 cuda_h.py:10] start layer_moe_generate_mp_l_2
DEBUG 01-13 08:46:16.376438.376438 cuda_h.py:10] start gate
INFO 01-13 08:46:16.382574.382574 client.py:127] Model loaded
DEBUG 01-13 08:46:16.382492.382492 cuda_h.py:10] start restore2model
DEBUG 01-13 08:46:16.383503.383503 cuda_h.py:19] end restore2model cost 0.001035451889038086 seconds
DEBUG 01-13 08:46:16.383997.383997 cuda_h.py:19] end sllm_worker_task cost 0.01324152946472168 seconds
DEBUG 01-13 08:46:16.471843.471843 cuda_h.py:19] end gate cost 0.09509062767028809 seconds
DEBUG 01-13 08:46:16.471298.471298 cuda_h.py:10] start experts_map_get
DEBUG 01-13 08:46:16.472216.472216 lmp.py:1611] 
DEBUG 01-13 08:46:16.472216.472216 lmp.py:1611] Expert Token Distribution & Device Allocation:
DEBUG 01-13 08:46:16.472794.472794 lmp.py:1612]   Total experts: 64
DEBUG 01-13 08:46:16.472781.472781 lmp.py:1613]   CPU experts: 32 (50%)
DEBUG 01-13 08:46:16.472762.472762 lmp.py:1614]   GPU experts: 32 (50%)
DEBUG 01-13 08:46:16.472120.472120 lmp.py:1615] 
DEBUG 01-13 08:46:16.472120.472120 lmp.py:1615]   Expert ID | Tokens | Device
DEBUG 01-13 08:46:16.472909.472909 lmp.py:1616]   -----------------------------------
DEBUG 01-13 08:46:16.472943.472943 lmp.py:1622]   Expert 25 |     64 | CPU
DEBUG 01-13 08:46:16.472255.472255 lmp.py:1622]   Expert 54 |     67 | CPU
DEBUG 01-13 08:46:16.472852.472852 lmp.py:1622]   Expert  3 |     68 | CPU
DEBUG 01-13 08:46:16.472210.472210 lmp.py:1622]   Expert 31 |     72 | CPU
DEBUG 01-13 08:46:16.472807.472807 lmp.py:1622]   Expert 55 |     72 | CPU
DEBUG 01-13 08:46:16.472926.472926 lmp.py:1622]   Expert 62 |     87 | CPU
DEBUG 01-13 08:46:16.472046.472046 lmp.py:1622]   Expert 18 |     88 | CPU
DEBUG 01-13 08:46:16.472404.472404 lmp.py:1622]   Expert 52 |     98 | CPU
DEBUG 01-13 08:46:16.472001.472001 lmp.py:1622]   Expert 22 |    100 | CPU
DEBUG 01-13 08:46:16.472121.472121 lmp.py:1622]   Expert 47 |    104 | CPU
DEBUG 01-13 08:46:16.472479.472479 lmp.py:1622]   Expert  0 |    113 | CPU
DEBUG 01-13 08:46:16.472076.472076 lmp.py:1622]   Expert 37 |    117 | CPU
DEBUG 01-13 08:46:16.472196.472196 lmp.py:1622]   Expert 27 |    121 | CPU
DEBUG 01-13 08:46:16.472077.472077 lmp.py:1622]   Expert 32 |    123 | CPU
DEBUG 01-13 08:46:16.472197.472197 lmp.py:1622]   Expert 41 |    130 | CPU
DEBUG 01-13 08:46:16.472840.472840 lmp.py:1622]   Expert 44 |    131 | CPU
DEBUG 01-13 08:46:16.472721.472721 lmp.py:1622]   Expert 28 |    136 | CPU
DEBUG 01-13 08:46:16.472841.472841 lmp.py:1622]   Expert 13 |    138 | CPU
DEBUG 01-13 08:46:16.472722.472722 lmp.py:1622]   Expert 58 |    140 | CPU
DEBUG 01-13 08:46:16.472604.472604 lmp.py:1622]   Expert 60 |    144 | CPU
DEBUG 01-13 08:46:16.472724.472724 lmp.py:1622]   Expert 43 |    147 | CPU
DEBUG 01-13 08:46:16.472605.472605 lmp.py:1622]   Expert  1 |    150 | CPU
DEBUG 01-13 08:46:16.473500.473500 lmp.py:1622]   Expert 38 |    153 | CPU
DEBUG 01-13 08:46:16.473381.473381 lmp.py:1622]   Expert 49 |    154 | CPU
DEBUG 01-13 08:46:16.473548.473548 lmp.py:1622]   Expert 51 |    155 | CPU
DEBUG 01-13 08:46:16.473475.473475 lmp.py:1622]   Expert 34 |    161 | CPU
DEBUG 01-13 08:46:16.473403.473403 lmp.py:1622]   Expert 35 |    164 | CPU
DEBUG 01-13 08:46:16.473331.473331 lmp.py:1622]   Expert 36 |    168 | CPU
DEBUG 01-13 08:46:16.473497.473497 lmp.py:1622]   Expert 11 |    170 | CPU
DEBUG 01-13 08:46:16.473425.473425 lmp.py:1622]   Expert 17 |    170 | CPU
DEBUG 01-13 08:46:16.473114.473114 lmp.py:1622]   Expert 59 |    174 | CPU
DEBUG 01-13 08:46:16.473803.473803 lmp.py:1622]   Expert 10 |    180 | CPU
DEBUG 01-13 08:46:16.473731.473731 lmp.py:1622]   Expert 20 |    182 | GPU
DEBUG 01-13 08:46:16.473420.473420 lmp.py:1622]   Expert  2 |    186 | GPU
DEBUG 01-13 08:46:16.473348.473348 lmp.py:1622]   Expert 39 |    189 | GPU
DEBUG 01-13 08:46:16.473037.473037 lmp.py:1622]   Expert 33 |    197 | GPU
DEBUG 01-13 08:46:16.473965.473965 lmp.py:1622]   Expert 12 |    198 | GPU
DEBUG 01-13 08:46:16.473893.473893 lmp.py:1622]   Expert 21 |    198 | GPU
DEBUG 01-13 08:46:16.473582.473582 lmp.py:1622]   Expert 48 |    198 | GPU
DEBUG 01-13 08:46:16.473510.473510 lmp.py:1622]   Expert 15 |    199 | GPU
DEBUG 01-13 08:46:16.473199.473199 lmp.py:1622]   Expert 53 |    204 | GPU
DEBUG 01-13 08:46:16.473127.473127 lmp.py:1622]   Expert 19 |    220 | GPU
DEBUG 01-13 08:46:16.473054.473054 lmp.py:1622]   Expert 26 |    221 | GPU
DEBUG 01-13 08:46:16.473982.473982 lmp.py:1622]   Expert 30 |    221 | GPU
DEBUG 01-13 08:46:16.473910.473910 lmp.py:1622]   Expert 45 |    221 | GPU
DEBUG 01-13 08:46:16.473599.473599 lmp.py:1622]   Expert  5 |    227 | GPU
DEBUG 01-13 08:46:16.473288.473288 lmp.py:1622]   Expert  4 |    229 | GPU
DEBUG 01-13 08:46:16.473216.473216 lmp.py:1622]   Expert 24 |    229 | GPU
DEBUG 01-13 08:46:16.473290.473290 lmp.py:1622]   Expert 42 |    242 | GPU
DEBUG 01-13 08:46:16.473979.473979 lmp.py:1622]   Expert 50 |    245 | GPU
DEBUG 01-13 08:46:16.473907.473907 lmp.py:1622]   Expert 29 |    254 | GPU
DEBUG 01-13 08:46:16.473596.473596 lmp.py:1622]   Expert 56 |    262 | GPU
DEBUG 01-13 08:46:16.473524.473524 lmp.py:1622]   Expert 61 |    270 | GPU
DEBUG 01-13 08:46:16.473213.473213 lmp.py:1622]   Expert  8 |    283 | GPU
DEBUG 01-13 08:46:16.473902.473902 lmp.py:1622]   Expert 63 |    285 | GPU
DEBUG 01-13 08:46:16.473353.473353 lmp.py:1622]   Expert 46 |    294 | GPU
DEBUG 01-13 08:46:16.473281.473281 lmp.py:1622]   Expert  9 |    300 | GPU
DEBUG 01-13 08:46:16.473970.473970 lmp.py:1622]   Expert  6 |    316 | GPU
DEBUG 01-13 08:46:16.473659.473659 lmp.py:1622]   Expert 16 |    316 | GPU
DEBUG 01-13 08:46:16.473587.473587 lmp.py:1622]   Expert 40 |    319 | GPU
DEBUG 01-13 08:46:16.473038.473038 lmp.py:1622]   Expert  7 |    322 | GPU
DEBUG 01-13 08:46:16.473966.473966 lmp.py:1622]   Expert 23 |    325 | GPU
DEBUG 01-13 08:46:16.473893.473893 lmp.py:1622]   Expert 14 |    413 | GPU
DEBUG 01-13 08:46:16.473060.473060 lmp.py:1622]   Expert 57 |    464 | GPU
DEBUG 01-13 08:46:16.473941.473941 lmp.py:1623] 
DEBUG 01-13 08:46:16.473941.473941 lmp.py:1623]   CPU total tokens: 4059 (33.0%)
DEBUG 01-13 08:46:16.473538.473538 lmp.py:1624]   GPU total tokens: 8229 (67.0%)
DEBUG 01-13 08:46:16.473664.473664 cuda_h.py:19] end experts_map_get cost 0.0018031597137451172 seconds
DEBUG 01-13 08:46:16.473139.473139 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-13 08:46:16.473061.473061 lmp.py:1632] 
DEBUG 01-13 08:46:16.473061.473061 lmp.py:1632]   Computing 32 experts on CPU MP...
DEBUG 01-13 08:46:16.475218.475218 cuda_h.py:19] end cpu_experts_submit cost 0.0011310577392578125 seconds
DEBUG 01-13 08:46:16.475564.475564 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-13 08:46:16.475699.475699 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-13 08:46:16.475455.475455 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-13 08:46:16.476877.476877 cuda_h.py:19] end allocate_cuda_memory cost 0.0010387897491455078 seconds
DEBUG 01-13 08:46:16.476755.476755 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-13 08:46:16.476187.476187 sllm_store_c.py:27] get device uuid map
DEBUG 01-13 08:46:16.476037.476037 sllm_store_c.py:29] call client load into gpu
DEBUG 01-13 08:46:16.476230.476230 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, b0a68717-077d-492f-b46f-4d2240d5dd30
DEBUG 01-13 08:46:16.477921.477921 client.py:106] call stub.LoadModelAsync
INFO 01-13 08:46:16.479316.479316 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, b0a68717-077d-492f-b46f-4d2240d5dd30
DEBUG 01-13 08:46:16.479232.479232 cuda_h.py:19] end load_into_gpu_async cost 0.0027341842651367188 seconds
DEBUG 01-13 08:46:16.479472.479472 cuda_h.py:10] start restore_tensors2
DEBUG 01-13 08:46:16.479440.479440 cuda_h.py:19] end restore_tensors2 cost 0.000396728515625 seconds
DEBUG 01-13 08:46:16.479654.479654 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.004748821258544922 seconds
DEBUG 01-13 08:46:16.480192.480192 cuda_h.py:10] start restore2model
DEBUG 01-13 08:46:16.484699.484699 cuda_h.py:19] end restore2model cost 0.0042226314544677734 seconds
DEBUG 01-13 08:46:16.484258.484258 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.009216547012329102 seconds
DEBUG 01-13 08:46:16.484259.484259 cuda_h.py:10] start gpu_sexperts
DEBUG 01-13 08:46:16.485962.485962 cuda_h.py:19] end gpu_sexperts cost 0.0005784034729003906 seconds
DEBUG 01-13 08:46:16.485058.485058 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-13 08:46:16.485669.485669 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.3365020751953125e-05 seconds
DEBUG 01-13 08:46:16.485617.485617 cuda_h.py:10] start wait_experts
INFO 01-13 08:46:16.485049.485049 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, b0a68717-077d-492f-b46f-4d2240d5dd30
INFO 01-13 08:46:16.527241.527241 client.py:127] Model loaded
DEBUG 01-13 08:46:16.527405.527405 cuda_h.py:19] end wait_experts cost 0.04266047477722168 seconds
DEBUG 01-13 08:46:16.528567.528567 cuda_h.py:10] start gpu_experts
DEBUG 01-13 08:46:16.532384.532384 mlpmodule.py:559] gpu group tensors cost 0.003861665725708008 s
DEBUG 01-13 08:46:16.538604.538604 mlpmodule.py:592] gpu pad cost 0.006230831146240234 s
DEBUG 01-13 08:46:16.538535.538535 mlpmodule.py:598] start_w1
DEBUG 01-13 08:46:16.540843.540843 mlpmodule.py:602] start_w3
DEBUG 01-13 08:46:16.541992.541992 mlpmodule.py:608] start_w2
DEBUG 01-13 08:46:16.541796.541796 mlpmodule.py:611] gpu group einsum cost 0.0030679702758789062 s
DEBUG 01-13 08:46:16.551475.551475 mlpmodule.py:683] gpu experts func einsum cost 0.023610830307006836 s
DEBUG 01-13 08:46:16.551181.551181 cuda_h.py:19] end gpu_experts cost 0.023801803588867188 seconds
DEBUG 01-13 08:46:16.551367.551367 cuda_h.py:10] start cpu_thread_manager_mp_wait
DEBUG 01-13 08:46:16.606097.606097 cuda_h.py:10] start experts_func_gpu_einsum_mp
DEBUG 01-13 08:46:16.629075.629075 mlpmodule.py:1006] group tensors cost 0.0042912960052490234 s
DEBUG 01-13 08:46:16.657873.657873 mlpmodule.py:1044] pad cost 0.027820110321044922 s
DEBUG 01-13 08:46:16.657753.657753 mlpmodule.py:1050] create cpu tensor cost 7.82012939453125e-05 s
DEBUG 01-13 08:46:16.658677.658677 mlpmodule.py:1055] move to cpu cost 4.1484832763671875e-05 s
DEBUG 01-13 08:46:16.697313.697313 mlpmodule.py:1069] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-13 08:46:16.697725.697725 mlpmodule.py:1070] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-13 08:46:16.698117.698117 mlpmodule.py:1075] group_w3 first element: -0.0107421875
WARNING 01-13 08:46:16.698393.698393 mlpmodule.py:1085] start einsum2
DEBUG 01-13 08:46:16.713511.713511 mlpmodule.py:1095] group einsum cost 0.05548405647277832 s
DEBUG 01-13 08:46:16.714414.714414 mlpmodule.py:1103] cpy2cputensor cost 0.0006787776947021484 s
DEBUG 01-13 08:46:16.761365.761365 mlpmodule.py:785]  experts func einsum cost 0.13660001754760742 s
DEBUG 01-13 08:46:16.762505.762505 cuda_h.py:19] end experts_func_gpu_einsum_mp cost 0.1556544303894043 seconds
DEBUG 01-13 08:46:16.762306.762306 cuda_h.py:19] end cpu_thread_manager_mp_wait cost 0.2103102207183838 seconds
DEBUG 01-13 08:46:16.762467.762467 cuda_h.py:19] end layer_moe_generate_mp_l_2 cost 0.38593482971191406 seconds
DEBUG 01-13 08:46:16.762674.762674 lmp.py:1550] -------------------------------- end prefill layer 1 --------------------------------
DEBUG 01-13 08:46:16.762457.762457 lmp.py:1493] -------------------------------- start prefill layer 2 --------------------------------
DEBUG 01-13 08:46:16.762942.762942 cuda_h.py:10] start start_load_qkvogn_s_weight_l_3
DEBUG 01-13 08:46:16.762334.762334 cuda_h.py:10] start start_load_qkvogn_s_weight_l_3
DEBUG 01-13 08:46:16.763065.763065 cuda_h.py:19] end start_load_qkvogn_s_weight_l_3 cost 3.910064697265625e-05 seconds
DEBUG 01-13 08:46:16.763656.763656 cuda_h.py:19] end start_load_qkvogn_s_weight_l_3 cost 9.918212890625e-05 seconds
DEBUG 01-13 08:46:16.763320.763320 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-13 08:46:16.763070.763070 cuda_h.py:10] start sllm_worker_task
DEBUG 01-13 08:46:16.763900.763900 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-13 08:46:16.763312.763312 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-13 08:46:16.763576.763576 cuda_h.py:19] end allocate_cuda_memory cost 0.0003237724304199219 seconds
DEBUG 01-13 08:46:16.763374.763374 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-13 08:46:16.763104.763104 sllm_store_c.py:27] get device uuid map
DEBUG 01-13 08:46:16.763424.763424 sllm_store_c.py:29] call client load into gpu
DEBUG 01-13 08:46:16.763525.763525 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, a99b7be7-dd53-4923-85f5-8daadc9a518f
DEBUG 01-13 08:46:16.764674.764674 client.py:106] call stub.LoadModelAsync
DEBUG 01-13 08:46:16.764476.764476 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-13 08:46:16.764499.764499 cuda_h.py:10] start self_attn
INFO 01-13 08:46:16.765988.765988 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, a99b7be7-dd53-4923-85f5-8daadc9a518f
DEBUG 01-13 08:46:16.765614.765614 cuda_h.py:19] end load_into_gpu_async cost 0.001775979995727539 seconds
DEBUG 01-13 08:46:16.765788.765788 cuda_h.py:10] start restore_tensors2
DEBUG 01-13 08:46:16.765044.765044 cuda_h.py:19] end restore_tensors2 cost 7.605552673339844e-05 seconds
DEBUG 01-13 08:46:16.765489.765489 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0025374889373779297 seconds
INFO 01-13 08:46:16.765407.765407 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, a99b7be7-dd53-4923-85f5-8daadc9a518f
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-13 08:46:16.769515.769515 cuda_h.py:19] end self_attn cost 0.004534244537353516 seconds
DEBUG 01-13 08:46:16.769726.769726 cuda_h.py:19] end iln_self_attn_paln cost 0.006540775299072266 seconds
DEBUG 01-13 08:46:16.769543.769543 cuda_h.py:10] start layer_moe_generate_mp_l_3
DEBUG 01-13 08:46:16.769604.769604 cuda_h.py:10] start gate
DEBUG 01-13 08:46:16.770596.770596 cuda_h.py:19] end gate cost 0.0007257461547851562 seconds
DEBUG 01-13 08:46:16.770949.770949 cuda_h.py:10] start experts_map_get
DEBUG 01-13 08:46:16.770098.770098 lmp.py:1611] 
DEBUG 01-13 08:46:16.770098.770098 lmp.py:1611] Expert Token Distribution & Device Allocation:
DEBUG 01-13 08:46:16.770377.770377 lmp.py:1612]   Total experts: 64
DEBUG 01-13 08:46:16.770311.770311 lmp.py:1613]   CPU experts: 32 (50%)
DEBUG 01-13 08:46:16.771385.771385 lmp.py:1614]   GPU experts: 32 (50%)
DEBUG 01-13 08:46:16.771313.771313 lmp.py:1615] 
DEBUG 01-13 08:46:16.771313.771313 lmp.py:1615]   Expert ID | Tokens | Device
DEBUG 01-13 08:46:16.771717.771717 lmp.py:1616]   -----------------------------------
DEBUG 01-13 08:46:16.771128.771128 lmp.py:1622]   Expert 58 |     51 | CPU
DEBUG 01-13 08:46:16.771295.771295 lmp.py:1622]   Expert 27 |     56 | CPU
DEBUG 01-13 08:46:16.771461.771461 lmp.py:1622]   Expert  3 |     68 | CPU
DEBUG 01-13 08:46:16.771342.771342 lmp.py:1622]   Expert 17 |     83 | CPU
DEBUG 01-13 08:46:16.771985.771985 lmp.py:1622]   Expert 24 |     87 | CPU
DEBUG 01-13 08:46:16.771628.771628 lmp.py:1622]   Expert  0 |     88 | CPU
DEBUG 01-13 08:46:16.771271.771271 lmp.py:1622]   Expert 28 |    106 | CPU
DEBUG 01-13 08:46:16.771722.771722 lmp.py:1622]   Expert 34 |    115 | CPU
DEBUG 01-13 08:46:16.771934.771934 lmp.py:1622]   Expert 51 |    118 | CPU
DEBUG 01-13 08:46:16.771670.771670 lmp.py:1622]   Expert 32 |    120 | CPU
DEBUG 01-13 08:46:16.771121.771121 lmp.py:1622]   Expert  9 |    129 | CPU
DEBUG 01-13 08:46:16.771333.771333 lmp.py:1622]   Expert  7 |    135 | CPU
DEBUG 01-13 08:46:16.771307.771307 lmp.py:1622]   Expert 15 |    135 | CPU
DEBUG 01-13 08:46:16.771520.771520 lmp.py:1622]   Expert 23 |    137 | CPU
DEBUG 01-13 08:46:16.771494.771494 lmp.py:1622]   Expert 26 |    137 | CPU
DEBUG 01-13 08:46:16.771468.771468 lmp.py:1622]   Expert 30 |    144 | CPU
DEBUG 01-13 08:46:16.771680.771680 lmp.py:1622]   Expert 45 |    146 | CPU
DEBUG 01-13 08:46:16.771416.771416 lmp.py:1622]   Expert 62 |    147 | CPU
DEBUG 01-13 08:46:16.771628.771628 lmp.py:1622]   Expert 57 |    151 | CPU
DEBUG 01-13 08:46:16.771841.771841 lmp.py:1622]   Expert  1 |    153 | CPU
DEBUG 01-13 08:46:16.771053.771053 lmp.py:1622]   Expert 36 |    155 | CPU
DEBUG 01-13 08:46:16.771220.771220 lmp.py:1622]   Expert  8 |    159 | CPU
DEBUG 01-13 08:46:16.771863.771863 lmp.py:1622]   Expert 29 |    161 | CPU
DEBUG 01-13 08:46:16.771029.771029 lmp.py:1622]   Expert 25 |    165 | CPU
DEBUG 01-13 08:46:16.771718.771718 lmp.py:1622]   Expert 54 |    166 | CPU
DEBUG 01-13 08:46:16.771930.771930 lmp.py:1622]   Expert  6 |    169 | CPU
DEBUG 01-13 08:46:16.771666.771666 lmp.py:1622]   Expert 49 |    171 | CPU
DEBUG 01-13 08:46:16.771878.771878 lmp.py:1622]   Expert 48 |    174 | CPU
DEBUG 01-13 08:46:16.771091.771091 lmp.py:1622]   Expert 35 |    175 | CPU
DEBUG 01-13 08:46:16.771588.771588 lmp.py:1622]   Expert 37 |    176 | CPU
DEBUG 01-13 08:46:16.771562.771562 lmp.py:1622]   Expert 12 |    177 | CPU
DEBUG 01-13 08:46:16.771298.771298 lmp.py:1622]   Expert 60 |    187 | CPU
DEBUG 01-13 08:46:16.771510.771510 lmp.py:1622]   Expert 13 |    188 | GPU
DEBUG 01-13 08:46:16.771484.771484 lmp.py:1622]   Expert 33 |    189 | GPU
DEBUG 01-13 08:46:16.771174.771174 lmp.py:1622]   Expert 53 |    189 | GPU
DEBUG 01-13 08:46:16.771254.771254 lmp.py:1622]   Expert 16 |    195 | GPU
DEBUG 01-13 08:46:16.771672.771672 lmp.py:1622]   Expert 10 |    196 | GPU
DEBUG 01-13 08:46:16.771607.771607 lmp.py:1622]   Expert 21 |    197 | GPU
DEBUG 01-13 08:46:16.771826.771826 lmp.py:1622]   Expert 40 |    199 | GPU
DEBUG 01-13 08:46:16.771145.771145 lmp.py:1622]   Expert 43 |    202 | GPU
DEBUG 01-13 08:46:16.771218.771218 lmp.py:1622]   Expert 38 |    205 | GPU
DEBUG 01-13 08:46:16.771861.771861 lmp.py:1622]   Expert  5 |    208 | GPU
DEBUG 01-13 08:46:16.771550.771550 lmp.py:1622]   Expert 44 |    216 | GPU
DEBUG 01-13 08:46:16.771001.771001 lmp.py:1622]   Expert 52 |    216 | GPU
DEBUG 01-13 08:46:16.771690.771690 lmp.py:1622]   Expert 19 |    217 | GPU
DEBUG 01-13 08:46:16.771903.771903 lmp.py:1622]   Expert 50 |    217 | GPU
DEBUG 01-13 08:46:16.771592.771592 lmp.py:1622]   Expert 41 |    218 | GPU
DEBUG 01-13 08:46:16.771043.771043 lmp.py:1622]   Expert  4 |    221 | GPU
DEBUG 01-13 08:46:16.771732.771732 lmp.py:1622]   Expert 59 |    223 | GPU
DEBUG 01-13 08:46:16.771706.771706 lmp.py:1622]   Expert 55 |    232 | GPU
DEBUG 01-13 08:46:16.771157.771157 lmp.py:1622]   Expert 31 |    241 | GPU
DEBUG 01-13 08:46:16.771992.771992 lmp.py:1622]   Expert 56 |    241 | GPU
DEBUG 01-13 08:46:16.771397.771397 lmp.py:1622]   Expert 20 |    251 | GPU
DEBUG 01-13 08:46:16.771802.771802 lmp.py:1622]   Expert 39 |    252 | GPU
DEBUG 01-13 08:46:16.771921.771921 lmp.py:1622]   Expert 22 |    266 | GPU
DEBUG 01-13 08:46:16.772134.772134 lmp.py:1622]   Expert  2 |    268 | GPU
DEBUG 01-13 08:46:16.772585.772585 lmp.py:1622]   Expert 47 |    276 | GPU
DEBUG 01-13 08:46:16.772797.772797 lmp.py:1622]   Expert 63 |    276 | GPU
DEBUG 01-13 08:46:16.772771.772771 lmp.py:1622]   Expert 42 |    303 | GPU
DEBUG 01-13 08:46:16.772699.772699 lmp.py:1622]   Expert 18 |    313 | GPU
DEBUG 01-13 08:46:16.772249.772249 lmp.py:1622]   Expert 14 |    318 | GPU
DEBUG 01-13 08:46:16.772700.772700 lmp.py:1622]   Expert 46 |    367 | GPU
DEBUG 01-13 08:46:16.772436.772436 lmp.py:1622]   Expert 11 |    388 | GPU
DEBUG 01-13 08:46:16.772887.772887 lmp.py:1622]   Expert 61 |    459 | GPU
DEBUG 01-13 08:46:16.772530.772530 lmp.py:1623] 
DEBUG 01-13 08:46:16.772530.772530 lmp.py:1623]   CPU total tokens: 4341 (35.3%)
DEBUG 01-13 08:46:16.772696.772696 lmp.py:1624]   GPU total tokens: 7947 (64.7%)
DEBUG 01-13 08:46:16.772869.772869 cuda_h.py:19] end experts_map_get cost 0.0015273094177246094 seconds
DEBUG 01-13 08:46:16.772580.772580 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-13 08:46:16.772143.772143 lmp.py:1632] 
DEBUG 01-13 08:46:16.772143.772143 lmp.py:1632]   Computing 32 experts on CPU MP...
DEBUG 01-13 08:46:16.772642.772642 cuda_h.py:19] end cpu_experts_submit cost 5.078315734863281e-05 seconds
DEBUG 01-13 08:46:16.772756.772756 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-13 08:46:16.772374.772374 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-13 08:46:16.772028.772028 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-13 08:46:16.772499.772499 cuda_h.py:19] end allocate_cuda_memory cost 0.0002052783966064453 seconds
DEBUG 01-13 08:46:16.772303.772303 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-13 08:46:16.772927.772927 sllm_store_c.py:27] get device uuid map
DEBUG 01-13 08:46:16.772557.772557 sllm_store_c.py:29] call client load into gpu
DEBUG 01-13 08:46:16.773068.773068 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 1123ee69-6b6b-4706-bb34-4edcb6d01c03
DEBUG 01-13 08:46:16.773445.773445 client.py:106] call stub.LoadModelAsync
INFO 01-13 08:46:16.773859.773859 client.py:127] Model loaded
DEBUG 01-13 08:46:16.773404.773404 cuda_h.py:10] start restore2model
DEBUG 01-13 08:46:16.774138.774138 cuda_h.py:19] end restore2model cost 0.00032973289489746094 seconds
INFO 01-13 08:46:16.774790.774790 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 1123ee69-6b6b-4706-bb34-4edcb6d01c03
DEBUG 01-13 08:46:16.774018.774018 cuda_h.py:19] end sllm_worker_task cost 0.011042356491088867 seconds
DEBUG 01-13 08:46:16.774417.774417 cuda_h.py:19] end load_into_gpu_async cost 0.001383066177368164 seconds
DEBUG 01-13 08:46:16.774152.774152 cuda_h.py:10] start experts_func_gpu_einsum_mp
DEBUG 01-13 08:46:16.774207.774207 cuda_h.py:10] start restore_tensors2
DEBUG 01-13 08:46:16.774395.774395 cuda_h.py:19] end restore_tensors2 cost 0.0002491474151611328 seconds
DEBUG 01-13 08:46:16.774118.774118 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0022039413452148438 seconds
DEBUG 01-13 08:46:16.774781.774781 cuda_h.py:10] start restore2model
DEBUG 01-13 08:46:16.777772.777772 cuda_h.py:19] end restore2model cost 0.002665996551513672 seconds
DEBUG 01-13 08:46:16.777622.777622 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.005063533782958984 seconds
DEBUG 01-13 08:46:16.777133.777133 cuda_h.py:10] start gpu_sexperts
DEBUG 01-13 08:46:16.777429.777429 cuda_h.py:19] end gpu_sexperts cost 0.0002911090850830078 seconds
DEBUG 01-13 08:46:16.777973.777973 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-13 08:46:16.777703.777703 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 1.811981201171875e-05 seconds
DEBUG 01-13 08:46:16.777591.777591 cuda_h.py:10] start wait_experts
INFO 01-13 08:46:16.777526.777526 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 1123ee69-6b6b-4706-bb34-4edcb6d01c03
DEBUG 01-13 08:46:16.780502.780502 mlpmodule.py:1006] group tensors cost 0.00484919548034668 s
DEBUG 01-13 08:46:16.782231.782231 mlpmodule.py:1044] pad cost 0.0020225048065185547 s
DEBUG 01-13 08:46:16.782618.782618 mlpmodule.py:1050] create cpu tensor cost 4.9114227294921875e-05 s
DEBUG 01-13 08:46:16.782158.782158 mlpmodule.py:1055] move to cpu cost 3.886222839355469e-05 s
DEBUG 01-13 08:46:16.793185.793185 mlpmodule.py:1069] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-13 08:46:16.794294.794294 mlpmodule.py:1070] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-13 08:46:16.794366.794366 mlpmodule.py:1075] group_w3 first element: -0.0380859375
WARNING 01-13 08:46:16.794569.794569 mlpmodule.py:1085] start einsum2
DEBUG 01-13 08:46:16.810467.810467 mlpmodule.py:1095] group einsum cost 0.02794814109802246 s
DEBUG 01-13 08:46:16.811893.811893 mlpmodule.py:1103] cpy2cputensor cost 0.0006992816925048828 s
INFO 01-13 08:46:16.827004.827004 client.py:127] Model loaded
DEBUG 01-13 08:46:16.827028.827028 cuda_h.py:19] end wait_experts cost 0.04919791221618652 seconds
DEBUG 01-13 08:46:16.827552.827552 cuda_h.py:10] start gpu_experts
DEBUG 01-13 08:46:16.827973.827973 mlpmodule.py:559] gpu group tensors cost 0.0006005764007568359 s
DEBUG 01-13 08:46:16.829165.829165 mlpmodule.py:592] gpu pad cost 0.001505136489868164 s
DEBUG 01-13 08:46:16.829075.829075 mlpmodule.py:598] start_w1
DEBUG 01-13 08:46:16.829849.829849 mlpmodule.py:602] start_w3
DEBUG 01-13 08:46:16.830318.830318 mlpmodule.py:608] start_w2
DEBUG 01-13 08:46:16.830336.830336 mlpmodule.py:611] gpu group einsum cost 0.0006835460662841797 s
DEBUG 01-13 08:46:16.832192.832192 mlpmodule.py:683] gpu experts func einsum cost 0.005154132843017578 s
DEBUG 01-13 08:46:16.832161.832161 cuda_h.py:19] end gpu_experts cost 0.005301713943481445 seconds
DEBUG 01-13 08:46:16.832679.832679 cuda_h.py:10] start cpu_thread_manager_mp_wait
DEBUG 01-13 08:46:16.832959.832959 cuda_h.py:19] end cpu_thread_manager_mp_wait cost 3.6716461181640625e-05 seconds
DEBUG 01-13 08:46:16.832306.832306 cuda_h.py:19] end layer_moe_generate_mp_l_3 cost 0.06291890144348145 seconds
DEBUG 01-13 08:46:16.832803.832803 lmp.py:1550] -------------------------------- end prefill layer 2 --------------------------------
DEBUG 01-13 08:46:16.832658.832658 lmp.py:1493] -------------------------------- start prefill layer 3 --------------------------------
DEBUG 01-13 08:46:16.832931.832931 cuda_h.py:10] start start_load_qkvogn_s_weight_l_4
DEBUG 01-13 08:46:16.833302.833302 cuda_h.py:10] start start_load_qkvogn_s_weight_l_4
DEBUG 01-13 08:46:16.833669.833669 cuda_h.py:19] end start_load_qkvogn_s_weight_l_4 cost 3.4332275390625e-05 seconds
DEBUG 01-13 08:46:16.833941.833941 cuda_h.py:19] end start_load_qkvogn_s_weight_l_4 cost 6.270408630371094e-05 seconds
DEBUG 01-13 08:46:16.833968.833968 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-13 08:46:16.833315.833315 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-13 08:46:16.833324.833324 cuda_h.py:10] start sllm_worker_task
DEBUG 01-13 08:46:16.833500.833500 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-13 08:46:16.833713.833713 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-13 08:46:16.833269.833269 cuda_h.py:19] end allocate_cuda_memory cost 0.0003361701965332031 seconds
DEBUG 01-13 08:46:16.833093.833093 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-13 08:46:16.833617.833617 sllm_store_c.py:27] get device uuid map
DEBUG 01-13 08:46:16.833440.833440 sllm_store_c.py:29] call client load into gpu
DEBUG 01-13 08:46:16.833428.833428 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 38cfdd75-188a-4e1a-9f6c-b85dc59b625e
DEBUG 01-13 08:46:16.834828.834828 client.py:106] call stub.LoadModelAsync
DEBUG 01-13 08:46:16.834663.834663 cuda_h.py:10] start self_attn
INFO 01-13 08:46:16.835492.835492 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 38cfdd75-188a-4e1a-9f6c-b85dc59b625e
DEBUG 01-13 08:46:16.835886.835886 cuda_h.py:19] end load_into_gpu_async cost 0.001285552978515625 seconds
DEBUG 01-13 08:46:16.835112.835112 cuda_h.py:10] start restore_tensors2
DEBUG 01-13 08:46:16.835187.835187 cuda_h.py:19] end restore_tensors2 cost 6.437301635742188e-05 seconds
DEBUG 01-13 08:46:16.835275.835275 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0019419193267822266 seconds
INFO 01-13 08:46:16.835541.835541 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 38cfdd75-188a-4e1a-9f6c-b85dc59b625e
DEBUG 01-13 08:46:16.835101.835101 mlpmodule.py:785]  experts func einsum cost 0.060347795486450195 s
DEBUG 01-13 08:46:16.836567.836567 cuda_h.py:19] end experts_func_gpu_einsum_mp cost 0.061951637268066406 seconds
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-13 08:46:16.837051.837051 cuda_h.py:19] end self_attn cost 0.002822399139404297 seconds
DEBUG 01-13 08:46:16.837869.837869 cuda_h.py:19] end iln_self_attn_paln cost 0.0043179988861083984 seconds
DEBUG 01-13 08:46:16.837043.837043 cuda_h.py:10] start layer_moe_generate_mp_l_4
DEBUG 01-13 08:46:16.837137.837137 cuda_h.py:10] start gate
DEBUG 01-13 08:46:16.838438.838438 cuda_h.py:19] end gate cost 0.0006442070007324219 seconds
DEBUG 01-13 08:46:16.838552.838552 cuda_h.py:10] start experts_map_get
DEBUG 01-13 08:46:16.838409.838409 lmp.py:1611] 
DEBUG 01-13 08:46:16.838409.838409 lmp.py:1611] Expert Token Distribution & Device Allocation:
DEBUG 01-13 08:46:16.838734.838734 lmp.py:1612]   Total experts: 64
DEBUG 01-13 08:46:16.838576.838576 lmp.py:1613]   CPU experts: 32 (50%)
DEBUG 01-13 08:46:16.838127.838127 lmp.py:1614]   GPU experts: 32 (50%)
DEBUG 01-13 08:46:16.838008.838008 lmp.py:1615] 
DEBUG 01-13 08:46:16.838008.838008 lmp.py:1615]   Expert ID | Tokens | Device
DEBUG 01-13 08:46:16.838843.838843 lmp.py:1616]   -----------------------------------
DEBUG 01-13 08:46:16.838208.838208 lmp.py:1622]   Expert  1 |     45 | CPU
DEBUG 01-13 08:46:16.838090.838090 lmp.py:1622]   Expert 27 |     62 | CPU
DEBUG 01-13 08:46:16.838640.838640 lmp.py:1622]   Expert  7 |     75 | CPU
DEBUG 01-13 08:46:16.838998.838998 lmp.py:1622]   Expert 48 |     81 | CPU
DEBUG 01-13 08:46:16.838403.838403 lmp.py:1622]   Expert 15 |     99 | CPU
DEBUG 01-13 08:46:16.838284.838284 lmp.py:1622]   Expert 30 |    106 | CPU
DEBUG 01-13 08:46:16.838689.838689 lmp.py:1622]   Expert 61 |    115 | CPU
DEBUG 01-13 08:46:16.838093.838093 lmp.py:1622]   Expert 32 |    119 | CPU
DEBUG 01-13 08:46:16.838167.838167 lmp.py:1622]   Expert 45 |    120 | CPU
DEBUG 01-13 08:46:16.838286.838286 lmp.py:1622]   Expert 18 |    122 | CPU
DEBUG 01-13 08:46:16.838406.838406 lmp.py:1622]   Expert 34 |    132 | CPU
DEBUG 01-13 08:46:16.838526.838526 lmp.py:1622]   Expert 39 |    136 | CPU
DEBUG 01-13 08:46:16.838169.838169 lmp.py:1622]   Expert 26 |    138 | CPU
DEBUG 01-13 08:46:16.838050.838050 lmp.py:1622]   Expert 11 |    139 | CPU
DEBUG 01-13 08:46:16.838455.838455 lmp.py:1622]   Expert 36 |    139 | CPU
DEBUG 01-13 08:46:16.838098.838098 lmp.py:1622]   Expert  5 |    141 | CPU
DEBUG 01-13 08:46:16.838979.838979 lmp.py:1622]   Expert 59 |    142 | CPU
DEBUG 01-13 08:46:16.839622.839622 lmp.py:1622]   Expert 51 |    144 | CPU
DEBUG 01-13 08:46:16.839265.839265 lmp.py:1622]   Expert  6 |    146 | CPU
DEBUG 01-13 08:46:16.839670.839670 lmp.py:1622]   Expert 23 |    154 | CPU
DEBUG 01-13 08:46:16.839551.839551 lmp.py:1622]   Expert 49 |    156 | CPU
DEBUG 01-13 08:46:16.839717.839717 lmp.py:1622]   Expert  9 |    161 | CPU
DEBUG 01-13 08:46:16.839791.839791 lmp.py:1622]   Expert  2 |    162 | CPU
DEBUG 01-13 08:46:16.839672.839672 lmp.py:1622]   Expert 50 |    164 | CPU
DEBUG 01-13 08:46:16.839554.839554 lmp.py:1622]   Expert 56 |    167 | CPU
DEBUG 01-13 08:46:16.839197.839197 lmp.py:1622]   Expert 52 |    169 | CPU
DEBUG 01-13 08:46:16.839601.839601 lmp.py:1622]   Expert 16 |    171 | CPU
DEBUG 01-13 08:46:16.839006.839006 lmp.py:1622]   Expert 35 |    171 | CPU
DEBUG 01-13 08:46:16.839410.839410 lmp.py:1622]   Expert 40 |    172 | CPU
DEBUG 01-13 08:46:16.839815.839815 lmp.py:1622]   Expert  4 |    182 | CPU
DEBUG 01-13 08:46:16.839219.839219 lmp.py:1622]   Expert 37 |    190 | CPU
DEBUG 01-13 08:46:16.839624.839624 lmp.py:1622]   Expert 42 |    191 | CPU
DEBUG 01-13 08:46:16.839790.839790 lmp.py:1622]   Expert 13 |    192 | GPU
DEBUG 01-13 08:46:16.839956.839956 lmp.py:1622]   Expert 62 |    194 | GPU
DEBUG 01-13 08:46:16.839361.839361 lmp.py:1622]   Expert 17 |    197 | GPU
DEBUG 01-13 08:46:16.839765.839765 lmp.py:1622]   Expert 38 |    200 | GPU
DEBUG 01-13 08:46:16.839647.839647 lmp.py:1622]   Expert 21 |    203 | GPU
DEBUG 01-13 08:46:16.839528.839528 lmp.py:1622]   Expert 44 |    208 | GPU
DEBUG 01-13 08:46:16.839410.839410 lmp.py:1622]   Expert  3 |    209 | GPU
DEBUG 01-13 08:46:16.839344.839344 lmp.py:1622]   Expert 58 |    210 | GPU
DEBUG 01-13 08:46:16.839510.839510 lmp.py:1622]   Expert 60 |    210 | GPU
DEBUG 01-13 08:46:16.839723.839723 lmp.py:1622]   Expert 28 |    213 | GPU
DEBUG 01-13 08:46:16.839174.839174 lmp.py:1622]   Expert 53 |    215 | GPU
DEBUG 01-13 08:46:16.839624.839624 lmp.py:1622]   Expert 10 |    216 | GPU
DEBUG 01-13 08:46:16.839837.839837 lmp.py:1622]   Expert 47 |    216 | GPU
DEBUG 01-13 08:46:16.839811.839811 lmp.py:1622]   Expert 55 |    223 | GPU
DEBUG 01-13 08:46:16.839500.839500 lmp.py:1622]   Expert 20 |    224 | GPU
DEBUG 01-13 08:46:16.839713.839713 lmp.py:1622]   Expert 57 |    228 | GPU
DEBUG 01-13 08:46:16.839925.839925 lmp.py:1622]   Expert 33 |    235 | GPU
DEBUG 01-13 08:46:16.839376.839376 lmp.py:1622]   Expert  8 |    236 | GPU
DEBUG 01-13 08:46:16.839589.839589 lmp.py:1622]   Expert 31 |    236 | GPU
DEBUG 01-13 08:46:16.839516.839516 lmp.py:1622]   Expert 46 |    237 | GPU
DEBUG 01-13 08:46:16.839444.839444 lmp.py:1622]   Expert 24 |    244 | GPU
DEBUG 01-13 08:46:16.839372.839372 lmp.py:1622]   Expert 19 |    245 | GPU
DEBUG 01-13 08:46:16.839061.839061 lmp.py:1622]   Expert 14 |    265 | GPU
DEBUG 01-13 08:46:16.839227.839227 lmp.py:1622]   Expert 63 |    266 | GPU
DEBUG 01-13 08:46:16.839916.839916 lmp.py:1622]   Expert 29 |    276 | GPU
DEBUG 01-13 08:46:16.839129.839129 lmp.py:1622]   Expert 22 |    277 | GPU
DEBUG 01-13 08:46:16.839580.839580 lmp.py:1622]   Expert 12 |    278 | GPU
DEBUG 01-13 08:46:16.839031.839031 lmp.py:1622]   Expert  0 |    295 | GPU
DEBUG 01-13 08:46:16.839720.839720 lmp.py:1622]   Expert 43 |    306 | GPU
DEBUG 01-13 08:46:16.839409.839409 lmp.py:1622]   Expert 54 |    336 | GPU
DEBUG 01-13 08:46:16.839622.839622 lmp.py:1622]   Expert 41 |    379 | GPU
DEBUG 01-13 08:46:16.839834.839834 lmp.py:1622]   Expert 25 |    408 | GPU
DEBUG 01-13 08:46:16.839716.839716 lmp.py:1623] 
DEBUG 01-13 08:46:16.839716.839716 lmp.py:1623]   CPU total tokens: 4411 (35.9%)
DEBUG 01-13 08:46:16.839074.839074 lmp.py:1624]   GPU total tokens: 7877 (64.1%)
DEBUG 01-13 08:46:16.839485.839485 cuda_h.py:19] end experts_map_get cost 0.0015377998352050781 seconds
DEBUG 01-13 08:46:16.839666.839666 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-13 08:46:16.839753.839753 lmp.py:1632] 
DEBUG 01-13 08:46:16.839753.839753 lmp.py:1632]   Computing 32 experts on CPU MP...
DEBUG 01-13 08:46:16.840867.840867 cuda_h.py:19] end cpu_experts_submit cost 4.887580871582031e-05 seconds
DEBUG 01-13 08:46:16.840895.840895 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-13 08:46:16.840625.840625 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-13 08:46:16.840556.840556 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-13 08:46:16.841464.841464 cuda_h.py:19] end allocate_cuda_memory cost 0.0013725757598876953 seconds
DEBUG 01-13 08:46:16.841665.841665 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-13 08:46:16.841965.841965 sllm_store_c.py:27] get device uuid map
DEBUG 01-13 08:46:16.841065.841065 sllm_store_c.py:29] call client load into gpu
DEBUG 01-13 08:46:16.841623.841623 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 357aaf88-dcda-4207-a819-39e2d3785996
DEBUG 01-13 08:46:16.841562.841562 client.py:106] call stub.LoadModelAsync
DEBUG 01-13 08:46:16.843144.843144 cuda_h.py:10] start experts_func_gpu_einsum_mp
INFO 01-13 08:46:16.843089.843089 client.py:127] Model loaded
DEBUG 01-13 08:46:16.843501.843501 cuda_h.py:10] start restore2model
DEBUG 01-13 08:46:16.843953.843953 cuda_h.py:19] end restore2model cost 0.0003986358642578125 seconds
DEBUG 01-13 08:46:16.843021.843021 cuda_h.py:19] end sllm_worker_task cost 0.010432958602905273 seconds
INFO 01-13 08:46:16.843046.843046 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 357aaf88-dcda-4207-a819-39e2d3785996
DEBUG 01-13 08:46:16.844035.844035 cuda_h.py:19] end load_into_gpu_async cost 0.00229644775390625 seconds
DEBUG 01-13 08:46:16.844500.844500 cuda_h.py:10] start restore_tensors2
DEBUG 01-13 08:46:16.844012.844012 cuda_h.py:19] end restore_tensors2 cost 0.000247955322265625 seconds
DEBUG 01-13 08:46:16.844258.844258 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.004271030426025391 seconds
DEBUG 01-13 08:46:16.844982.844982 cuda_h.py:10] start restore2model
DEBUG 01-13 08:46:16.847837.847837 cuda_h.py:19] end restore2model cost 0.0025653839111328125 seconds
DEBUG 01-13 08:46:16.847865.847865 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.007012844085693359 seconds
DEBUG 01-13 08:46:16.847661.847661 cuda_h.py:10] start gpu_sexperts
DEBUG 01-13 08:46:16.847730.847730 cuda_h.py:19] end gpu_sexperts cost 0.0002658367156982422 seconds
DEBUG 01-13 08:46:16.847560.847560 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-13 08:46:16.847297.847297 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.2649765014648438e-05 seconds
DEBUG 01-13 08:46:16.847946.847946 cuda_h.py:10] start wait_experts
INFO 01-13 08:46:16.847119.847119 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 357aaf88-dcda-4207-a819-39e2d3785996
DEBUG 01-13 08:46:16.848310.848310 mlpmodule.py:1006] group tensors cost 0.004861116409301758 s
DEBUG 01-13 08:46:16.850348.850348 mlpmodule.py:1044] pad cost 0.0018794536590576172 s
DEBUG 01-13 08:46:16.851875.851875 mlpmodule.py:1050] create cpu tensor cost 5.507469177246094e-05 s
DEBUG 01-13 08:46:16.851817.851817 mlpmodule.py:1055] move to cpu cost 2.8848648071289062e-05 s
DEBUG 01-13 08:46:16.861557.861557 mlpmodule.py:1069] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-13 08:46:16.861838.861838 mlpmodule.py:1070] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-13 08:46:16.861876.861876 mlpmodule.py:1075] group_w3 first element: -0.054931640625
WARNING 01-13 08:46:16.861920.861920 mlpmodule.py:1085] start einsum2
DEBUG 01-13 08:46:16.877112.877112 mlpmodule.py:1095] group einsum cost 0.026320457458496094 s
DEBUG 01-13 08:46:16.878929.878929 mlpmodule.py:1103] cpy2cputensor cost 0.0007495880126953125 s
INFO 01-13 08:46:16.895295.895295 client.py:127] Model loaded
DEBUG 01-13 08:46:16.895129.895129 cuda_h.py:19] end wait_experts cost 0.048316240310668945 seconds
DEBUG 01-13 08:46:16.895991.895991 cuda_h.py:10] start gpu_experts
DEBUG 01-13 08:46:16.896873.896873 mlpmodule.py:559] gpu group tensors cost 0.0007183551788330078 s
DEBUG 01-13 08:46:16.899780.899780 mlpmodule.py:592] gpu pad cost 0.0020046234130859375 s
DEBUG 01-13 08:46:16.899657.899657 mlpmodule.py:598] start_w1
DEBUG 01-13 08:46:16.899240.899240 mlpmodule.py:602] start_w3
DEBUG 01-13 08:46:16.899942.899942 mlpmodule.py:608] start_w2
DEBUG 01-13 08:46:16.900728.900728 mlpmodule.py:611] gpu group einsum cost 0.001135110855102539 s
DEBUG 01-13 08:46:16.903628.903628 mlpmodule.py:683] gpu experts func einsum cost 0.007103681564331055 s
DEBUG 01-13 08:46:16.903884.903884 cuda_h.py:19] end gpu_experts cost 0.007440090179443359 seconds
DEBUG 01-13 08:46:16.903501.903501 cuda_h.py:10] start cpu_thread_manager_mp_wait
DEBUG 01-13 08:46:16.903788.903788 cuda_h.py:19] end cpu_thread_manager_mp_wait cost 3.933906555175781e-05 seconds
DEBUG 01-13 08:46:16.903341.903341 cuda_h.py:19] end layer_moe_generate_mp_l_4 cost 0.06602334976196289 seconds
DEBUG 01-13 08:46:16.903024.903024 lmp.py:1550] -------------------------------- end prefill layer 3 --------------------------------
DEBUG 01-13 08:46:16.903979.903979 lmp.py:1493] -------------------------------- start prefill layer 4 --------------------------------
DEBUG 01-13 08:46:16.903635.903635 cuda_h.py:10] start start_load_qkvogn_s_weight_l_5
DEBUG 01-13 08:46:16.903106.903106 cuda_h.py:10] start start_load_qkvogn_s_weight_l_5
DEBUG 01-13 08:46:16.903764.903764 cuda_h.py:19] end start_load_qkvogn_s_weight_l_5 cost 3.528594970703125e-05 seconds
DEBUG 01-13 08:46:16.903898.903898 cuda_h.py:19] end start_load_qkvogn_s_weight_l_5 cost 6.532669067382812e-05 seconds
DEBUG 01-13 08:46:16.904686.904686 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-13 08:46:16.904344.904344 cuda_h.py:10] start sllm_worker_task
DEBUG 01-13 08:46:16.904388.904388 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-13 08:46:16.904403.904403 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-13 08:46:16.904931.904931 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-13 08:46:16.904106.904106 cuda_h.py:19] end allocate_cuda_memory cost 0.00021123886108398438 seconds
DEBUG 01-13 08:46:16.904103.904103 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-13 08:46:16.904356.904356 sllm_store_c.py:27] get device uuid map
DEBUG 01-13 08:46:16.904053.904053 sllm_store_c.py:29] call client load into gpu
DEBUG 01-13 08:46:16.904677.904677 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, efa351fa-ab4d-482a-a4b3-6011fbed87db
DEBUG 01-13 08:46:16.905641.905641 client.py:106] call stub.LoadModelAsync
DEBUG 01-13 08:46:16.905388.905388 cuda_h.py:10] start self_attn
INFO 01-13 08:46:16.906641.906641 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, efa351fa-ab4d-482a-a4b3-6011fbed87db
DEBUG 01-13 08:46:16.906736.906736 cuda_h.py:19] end load_into_gpu_async cost 0.0016481876373291016 seconds
DEBUG 01-13 08:46:16.906545.906545 cuda_h.py:10] start restore_tensors2
DEBUG 01-13 08:46:16.906810.906810 mlpmodule.py:785]  experts func einsum cost 0.06293773651123047 s
DEBUG 01-13 08:46:16.906085.906085 cuda_h.py:19] end restore_tensors2 cost 8.058547973632812e-05 seconds
DEBUG 01-13 08:46:16.906530.906530 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.002300739288330078 seconds
INFO 01-13 08:46:16.906202.906202 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, efa351fa-ab4d-482a-a4b3-6011fbed87db
DEBUG 01-13 08:46:16.906174.906174 cuda_h.py:19] end experts_func_gpu_einsum_mp cost 0.06371188163757324 seconds
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-13 08:46:16.908116.908116 cuda_h.py:19] end self_attn cost 0.0034906864166259766 seconds
DEBUG 01-13 08:46:16.909161.909161 cuda_h.py:19] end iln_self_attn_paln cost 0.005233287811279297 seconds
DEBUG 01-13 08:46:16.909434.909434 cuda_h.py:10] start layer_moe_generate_mp_l_5
DEBUG 01-13 08:46:16.909151.909151 cuda_h.py:10] start gate
DEBUG 01-13 08:46:16.910905.910905 cuda_h.py:19] end gate cost 0.0007288455963134766 seconds
DEBUG 01-13 08:46:16.910026.910026 cuda_h.py:10] start experts_map_get
DEBUG 01-13 08:46:16.910949.910949 lmp.py:1611] 
DEBUG 01-13 08:46:16.910949.910949 lmp.py:1611] Expert Token Distribution & Device Allocation:
DEBUG 01-13 08:46:16.910619.910619 lmp.py:1612]   Total experts: 64
DEBUG 01-13 08:46:16.910845.910845 lmp.py:1613]   CPU experts: 32 (50%)
DEBUG 01-13 08:46:16.910064.910064 lmp.py:1614]   GPU experts: 32 (50%)
DEBUG 01-13 08:46:16.910853.910853 lmp.py:1615] 
DEBUG 01-13 08:46:16.910853.910853 lmp.py:1615]   Expert ID | Tokens | Device
DEBUG 01-13 08:46:16.910403.910403 lmp.py:1616]   -----------------------------------
DEBUG 01-13 08:46:16.910960.910960 lmp.py:1622]   Expert 14 |     61 | CPU
DEBUG 01-13 08:46:16.910034.910034 lmp.py:1622]   Expert 57 |     73 | CPU
DEBUG 01-13 08:46:16.910869.910869 lmp.py:1622]   Expert 13 |     75 | CPU
DEBUG 01-13 08:46:16.910989.910989 lmp.py:1622]   Expert 26 |     80 | CPU
DEBUG 01-13 08:46:16.910632.910632 lmp.py:1622]   Expert 31 |     89 | CPU
DEBUG 01-13 08:46:16.910036.910036 lmp.py:1622]   Expert 11 |     90 | CPU
DEBUG 01-13 08:46:16.910679.910679 lmp.py:1622]   Expert 54 |     95 | CPU
DEBUG 01-13 08:46:16.910322.910322 lmp.py:1622]   Expert 45 |     98 | CPU
DEBUG 01-13 08:46:16.910919.910919 lmp.py:1622]   Expert 58 |    102 | CPU
DEBUG 01-13 08:46:16.910516.910516 lmp.py:1622]   Expert 30 |    103 | CPU
DEBUG 01-13 08:46:16.911874.911874 lmp.py:1622]   Expert 10 |    108 | CPU
DEBUG 01-13 08:46:16.911994.911994 lmp.py:1622]   Expert 32 |    113 | CPU
DEBUG 01-13 08:46:16.911875.911875 lmp.py:1622]   Expert 36 |    116 | CPU
DEBUG 01-13 08:46:16.911756.911756 lmp.py:1622]   Expert 51 |    117 | CPU
DEBUG 01-13 08:46:16.911399.911399 lmp.py:1622]   Expert  8 |    127 | CPU
DEBUG 01-13 08:46:16.911281.911281 lmp.py:1622]   Expert 20 |    129 | CPU
DEBUG 01-13 08:46:16.911162.911162 lmp.py:1622]   Expert 53 |    137 | CPU
DEBUG 01-13 08:46:16.911044.911044 lmp.py:1622]   Expert  4 |    140 | CPU
DEBUG 01-13 08:46:16.911925.911925 lmp.py:1622]   Expert 34 |    142 | CPU
DEBUG 01-13 08:46:16.911806.911806 lmp.py:1622]   Expert 61 |    142 | CPU
DEBUG 01-13 08:46:16.911926.911926 lmp.py:1622]   Expert 63 |    142 | CPU
DEBUG 01-13 08:46:16.911808.911808 lmp.py:1622]   Expert 16 |    148 | CPU
DEBUG 01-13 08:46:16.911927.911927 lmp.py:1622]   Expert 47 |    149 | CPU
DEBUG 01-13 08:46:16.911286.911286 lmp.py:1622]   Expert 17 |    159 | CPU
DEBUG 01-13 08:46:16.911882.911882 lmp.py:1622]   Expert 60 |    159 | CPU
DEBUG 01-13 08:46:16.911148.911148 lmp.py:1622]   Expert 28 |    160 | CPU
DEBUG 01-13 08:46:16.911460.911460 lmp.py:1622]   Expert 42 |    162 | CPU
DEBUG 01-13 08:46:16.911056.911056 lmp.py:1622]   Expert 29 |    171 | CPU
DEBUG 01-13 08:46:16.911892.911892 lmp.py:1622]   Expert  7 |    172 | CPU
DEBUG 01-13 08:46:16.911250.911250 lmp.py:1622]   Expert 27 |    173 | CPU
DEBUG 01-13 08:46:16.911608.911608 lmp.py:1622]   Expert 44 |    176 | CPU
DEBUG 01-13 08:46:16.911443.911443 lmp.py:1622]   Expert 41 |    179 | CPU
DEBUG 01-13 08:46:16.911040.911040 lmp.py:1622]   Expert  2 |    186 | GPU
DEBUG 01-13 08:46:16.911113.911113 lmp.py:1622]   Expert  3 |    187 | GPU
DEBUG 01-13 08:46:16.911425.911425 lmp.py:1622]   Expert 48 |    189 | GPU
DEBUG 01-13 08:46:16.911737.911737 lmp.py:1622]   Expert 56 |    189 | GPU
DEBUG 01-13 08:46:16.911810.911810 lmp.py:1622]   Expert  9 |    191 | GPU
DEBUG 01-13 08:46:16.911122.911122 lmp.py:1622]   Expert 15 |    193 | GPU
DEBUG 01-13 08:46:16.911196.911196 lmp.py:1622]   Expert  0 |    195 | GPU
DEBUG 01-13 08:46:16.911031.911031 lmp.py:1622]   Expert 24 |    198 | GPU
DEBUG 01-13 08:46:16.911389.911389 lmp.py:1622]   Expert 18 |    202 | GPU
DEBUG 01-13 08:46:16.911986.911986 lmp.py:1622]   Expert 55 |    203 | GPU
DEBUG 01-13 08:46:16.911582.911582 lmp.py:1622]   Expert 40 |    210 | GPU
DEBUG 01-13 08:46:16.911179.911179 lmp.py:1622]   Expert 38 |    215 | GPU
DEBUG 01-13 08:46:16.911014.911014 lmp.py:1622]   Expert 22 |    218 | GPU
DEBUG 01-13 08:46:16.911088.911088 lmp.py:1622]   Expert  6 |    219 | GPU
DEBUG 01-13 08:46:16.911400.911400 lmp.py:1622]   Expert 37 |    219 | GPU
DEBUG 01-13 08:46:16.911950.911950 lmp.py:1622]   Expert 23 |    221 | GPU
DEBUG 01-13 08:46:16.911739.911739 lmp.py:1622]   Expert 46 |    233 | GPU
DEBUG 01-13 08:46:16.911335.911335 lmp.py:1622]   Expert 19 |    244 | GPU
DEBUG 01-13 08:46:16.911694.911694 lmp.py:1622]   Expert 39 |    251 | GPU
DEBUG 01-13 08:46:16.911290.911290 lmp.py:1622]   Expert 25 |    253 | GPU
DEBUG 01-13 08:46:16.911648.911648 lmp.py:1622]   Expert 12 |    258 | GPU
DEBUG 01-13 08:46:16.911245.911245 lmp.py:1622]   Expert 62 |    264 | GPU
DEBUG 01-13 08:46:16.911603.911603 lmp.py:1622]   Expert 50 |    265 | GPU
DEBUG 01-13 08:46:16.911962.911962 lmp.py:1622]   Expert 35 |    277 | GPU
DEBUG 01-13 08:46:16.911320.911320 lmp.py:1622]   Expert 21 |    284 | GPU
DEBUG 01-13 08:46:16.911155.911155 lmp.py:1622]   Expert 49 |    285 | GPU
DEBUG 01-13 08:46:16.911228.911228 lmp.py:1622]   Expert 33 |    304 | GPU
DEBUG 01-13 08:46:16.911302.911302 lmp.py:1622]   Expert 52 |    309 | GPU
DEBUG 01-13 08:46:16.911375.911375 lmp.py:1622]   Expert  1 |    344 | GPU
DEBUG 01-13 08:46:16.911164.911164 lmp.py:1622]   Expert  5 |    375 | GPU
DEBUG 01-13 08:46:16.911761.911761 lmp.py:1622]   Expert 43 |    439 | GPU
DEBUG 01-13 08:46:16.911596.911596 lmp.py:1622]   Expert 59 |    581 | GPU
DEBUG 01-13 08:46:16.912908.912908 lmp.py:1623] 
DEBUG 01-13 08:46:16.912908.912908 lmp.py:1623]   CPU total tokens: 4087 (33.3%)
DEBUG 01-13 08:46:16.912696.912696 lmp.py:1624]   GPU total tokens: 8201 (66.7%)
DEBUG 01-13 08:46:16.912777.912777 cuda_h.py:19] end experts_map_get cost 0.0018215179443359375 seconds
DEBUG 01-13 08:46:16.912355.912355 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-13 08:46:16.912542.912542 lmp.py:1632] 
DEBUG 01-13 08:46:16.912542.912542 lmp.py:1632]   Computing 32 experts on CPU MP...
DEBUG 01-13 08:46:16.912756.912756 cuda_h.py:19] end cpu_experts_submit cost 5.221366882324219e-05 seconds
DEBUG 01-13 08:46:16.912213.912213 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-13 08:46:16.912627.912627 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-13 08:46:16.912744.912744 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-13 08:46:16.913969.913969 cuda_h.py:19] end allocate_cuda_memory cost 0.0009334087371826172 seconds
DEBUG 01-13 08:46:16.913700.913700 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-13 08:46:16.913655.913655 sllm_store_c.py:27] get device uuid map
DEBUG 01-13 08:46:16.914994.914994 sllm_store_c.py:29] call client load into gpu
DEBUG 01-13 08:46:16.914505.914505 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, b8fffe04-933f-4b58-9e28-132ae55fe24c
DEBUG 01-13 08:46:16.914475.914475 cuda_h.py:10] start experts_func_gpu_einsum_mp
DEBUG 01-13 08:46:16.914305.914305 client.py:106] call stub.LoadModelAsync
INFO 01-13 08:46:16.914282.914282 client.py:127] Model loaded
DEBUG 01-13 08:46:16.914815.914815 cuda_h.py:10] start restore2model
DEBUG 01-13 08:46:16.915206.915206 cuda_h.py:19] end restore2model cost 0.0005497932434082031 seconds
INFO 01-13 08:46:16.915772.915772 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, b8fffe04-933f-4b58-9e28-132ae55fe24c
DEBUG 01-13 08:46:16.915258.915258 cuda_h.py:19] end sllm_worker_task cost 0.011099815368652344 seconds
DEBUG 01-13 08:46:16.915128.915128 cuda_h.py:19] end load_into_gpu_async cost 0.001466989517211914 seconds
DEBUG 01-13 08:46:16.915184.915184 cuda_h.py:10] start restore_tensors2
DEBUG 01-13 08:46:16.915731.915731 cuda_h.py:19] end restore_tensors2 cost 0.00030422210693359375 seconds
DEBUG 01-13 08:46:16.915508.915508 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0031256675720214844 seconds
DEBUG 01-13 08:46:16.915079.915079 cuda_h.py:10] start restore2model
DEBUG 01-13 08:46:16.918624.918624 mlpmodule.py:1006] group tensors cost 0.003954410552978516 s
DEBUG 01-13 08:46:16.919634.919634 cuda_h.py:19] end restore2model cost 0.003115415573120117 seconds
DEBUG 01-13 08:46:16.919140.919140 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.00644683837890625 seconds
DEBUG 01-13 08:46:16.919366.919366 cuda_h.py:10] start gpu_sexperts
DEBUG 01-13 08:46:16.919132.919132 cuda_h.py:19] end gpu_sexperts cost 0.0003197193145751953 seconds
DEBUG 01-13 08:46:16.919584.919584 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-13 08:46:16.919791.919791 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 1.5497207641601562e-05 seconds
DEBUG 01-13 08:46:16.919156.919156 cuda_h.py:10] start wait_experts
INFO 01-13 08:46:16.919621.919621 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, b8fffe04-933f-4b58-9e28-132ae55fe24c
DEBUG 01-13 08:46:16.920301.920301 mlpmodule.py:1044] pad cost 0.0015294551849365234 s
DEBUG 01-13 08:46:16.920145.920145 mlpmodule.py:1050] create cpu tensor cost 4.0531158447265625e-05 s
DEBUG 01-13 08:46:16.920571.920571 mlpmodule.py:1055] move to cpu cost 3.0040740966796875e-05 s
DEBUG 01-13 08:46:16.929094.929094 mlpmodule.py:1069] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-13 08:46:16.930236.930236 mlpmodule.py:1070] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-13 08:46:16.930539.930539 mlpmodule.py:1075] group_w3 first element: 0.0086669921875
WARNING 01-13 08:46:16.930054.930054 mlpmodule.py:1085] start einsum2
DEBUG 01-13 08:46:16.943275.943275 mlpmodule.py:1095] group einsum cost 0.022526025772094727 s
DEBUG 01-13 08:46:16.944726.944726 mlpmodule.py:1103] cpy2cputensor cost 0.00089263916015625 s
INFO 01-13 08:46:16.967670.967670 client.py:127] Model loaded
DEBUG 01-13 08:46:16.967945.967945 cuda_h.py:19] end wait_experts cost 0.04780006408691406 seconds
DEBUG 01-13 08:46:16.967605.967605 cuda_h.py:10] start gpu_experts
DEBUG 01-13 08:46:16.968354.968354 mlpmodule.py:559] gpu group tensors cost 0.0006542205810546875 s
DEBUG 01-13 08:46:16.969024.969024 mlpmodule.py:785]  experts func einsum cost 0.05468630790710449 s
DEBUG 01-13 08:46:16.969447.969447 cuda_h.py:19] end experts_func_gpu_einsum_mp cost 0.05546402931213379 seconds
DEBUG 01-13 08:46:16.970732.970732 mlpmodule.py:592] gpu pad cost 0.002315998077392578 s
DEBUG 01-13 08:46:16.970993.970993 mlpmodule.py:598] start_w1
DEBUG 01-13 08:46:16.971059.971059 mlpmodule.py:602] start_w3
DEBUG 01-13 08:46:16.971284.971284 mlpmodule.py:608] start_w2
DEBUG 01-13 08:46:16.971900.971900 mlpmodule.py:611] gpu group einsum cost 0.0009865760803222656 s
DEBUG 01-13 08:46:16.974867.974867 mlpmodule.py:683] gpu experts func einsum cost 0.007075309753417969 s
DEBUG 01-13 08:46:16.974651.974651 cuda_h.py:19] end gpu_experts cost 0.007245540618896484 seconds
DEBUG 01-13 08:46:16.974738.974738 cuda_h.py:10] start cpu_thread_manager_mp_wait
DEBUG 01-13 08:46:16.975164.975164 cuda_h.py:19] end cpu_thread_manager_mp_wait cost 3.719329833984375e-05 seconds
DEBUG 01-13 08:46:16.975478.975478 cuda_h.py:19] end layer_moe_generate_mp_l_5 cost 0.0657644271850586 seconds
DEBUG 01-13 08:46:16.975326.975326 lmp.py:1550] -------------------------------- end prefill layer 4 --------------------------------
DEBUG 01-13 08:46:16.975189.975189 lmp.py:1493] -------------------------------- start prefill layer 5 --------------------------------
DEBUG 01-13 08:46:16.975415.975415 cuda_h.py:10] start start_load_qkvogn_s_weight_l_6
DEBUG 01-13 08:46:16.975217.975217 cuda_h.py:10] start start_load_qkvogn_s_weight_l_6
DEBUG 01-13 08:46:16.975206.975206 cuda_h.py:19] end start_load_qkvogn_s_weight_l_6 cost 3.504753112792969e-05 seconds
DEBUG 01-13 08:46:16.975360.975360 cuda_h.py:19] end start_load_qkvogn_s_weight_l_6 cost 8.130073547363281e-05 seconds
DEBUG 01-13 08:46:16.975453.975453 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-13 08:46:16.975224.975224 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-13 08:46:16.975955.975955 cuda_h.py:10] start sllm_worker_task
DEBUG 01-13 08:46:16.975390.975390 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-13 08:46:16.975531.975531 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-13 08:46:16.976765.976765 cuda_h.py:19] end allocate_cuda_memory cost 0.00021648406982421875 seconds
DEBUG 01-13 08:46:16.976292.976292 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-13 08:46:16.976069.976069 sllm_store_c.py:27] get device uuid map
DEBUG 01-13 08:46:16.976833.976833 sllm_store_c.py:29] call client load into gpu
DEBUG 01-13 08:46:16.976218.976218 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 9352783f-6a13-407e-b307-90f16f067ddd
DEBUG 01-13 08:46:16.976983.976983 client.py:106] call stub.LoadModelAsync
DEBUG 01-13 08:46:16.976441.976441 cuda_h.py:10] start self_attn
INFO 01-13 08:46:16.977500.977500 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 9352783f-6a13-407e-b307-90f16f067ddd
DEBUG 01-13 08:46:16.977754.977754 cuda_h.py:19] end load_into_gpu_async cost 0.0014870166778564453 seconds
DEBUG 01-13 08:46:16.977471.977471 cuda_h.py:10] start restore_tensors2
DEBUG 01-13 08:46:16.977773.977773 cuda_h.py:19] end restore_tensors2 cost 7.987022399902344e-05 seconds
DEBUG 01-13 08:46:16.978907.978907 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.002160310745239258 seconds
INFO 01-13 08:46:16.978757.978757 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 9352783f-6a13-407e-b307-90f16f067ddd
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-13 08:46:16.980789.980789 cuda_h.py:19] end self_attn cost 0.0033829212188720703 seconds
DEBUG 01-13 08:46:16.980099.980099 cuda_h.py:19] end iln_self_attn_paln cost 0.005005598068237305 seconds
DEBUG 01-13 08:46:16.980419.980419 cuda_h.py:10] start layer_moe_generate_mp_l_6
DEBUG 01-13 08:46:16.980897.980897 cuda_h.py:10] start gate
DEBUG 01-13 08:46:16.981121.981121 cuda_h.py:19] end gate cost 0.0007255077362060547 seconds
DEBUG 01-13 08:46:16.981149.981149 cuda_h.py:10] start experts_map_get
DEBUG 01-13 08:46:16.981774.981774 lmp.py:1611] 
DEBUG 01-13 08:46:16.981774.981774 lmp.py:1611] Expert Token Distribution & Device Allocation:
DEBUG 01-13 08:46:16.982060.982060 lmp.py:1612]   Total experts: 64
DEBUG 01-13 08:46:16.982048.982048 lmp.py:1613]   CPU experts: 32 (50%)
DEBUG 01-13 08:46:16.982267.982267 lmp.py:1614]   GPU experts: 32 (50%)
DEBUG 01-13 08:46:16.982056.982056 lmp.py:1615] 
DEBUG 01-13 08:46:16.982056.982056 lmp.py:1615]   Expert ID | Tokens | Device
DEBUG 01-13 08:46:16.982844.982844 lmp.py:1616]   -----------------------------------
DEBUG 01-13 08:46:16.982402.982402 lmp.py:1622]   Expert 34 |     23 | CPU
DEBUG 01-13 08:46:16.982714.982714 lmp.py:1622]   Expert 45 |     64 | CPU
DEBUG 01-13 08:46:16.982072.982072 lmp.py:1622]   Expert 22 |     78 | CPU
DEBUG 01-13 08:46:16.982668.982668 lmp.py:1622]   Expert 57 |     78 | CPU
DEBUG 01-13 08:46:16.982788.982788 lmp.py:1622]   Expert 17 |     91 | CPU
DEBUG 01-13 08:46:16.982146.982146 lmp.py:1622]   Expert 28 |     99 | CPU
DEBUG 01-13 08:46:16.982505.982505 lmp.py:1622]   Expert 15 |    101 | CPU
DEBUG 01-13 08:46:16.982863.982863 lmp.py:1622]   Expert  4 |    103 | CPU
DEBUG 01-13 08:46:16.982744.982744 lmp.py:1622]   Expert 32 |    109 | CPU
DEBUG 01-13 08:46:16.982103.982103 lmp.py:1622]   Expert 52 |    122 | CPU
DEBUG 01-13 08:46:16.982891.982891 lmp.py:1622]   Expert 60 |    124 | CPU
DEBUG 01-13 08:46:16.982157.982157 lmp.py:1622]   Expert 14 |    126 | CPU
DEBUG 01-13 08:46:16.982992.982992 lmp.py:1622]   Expert 36 |    126 | CPU
DEBUG 01-13 08:46:16.982827.982827 lmp.py:1622]   Expert 25 |    129 | CPU
DEBUG 01-13 08:46:16.982662.982662 lmp.py:1622]   Expert  2 |    131 | CPU
DEBUG 01-13 08:46:16.982543.982543 lmp.py:1622]   Expert 12 |    131 | CPU
DEBUG 01-13 08:46:16.982186.982186 lmp.py:1622]   Expert 16 |    131 | CPU
DEBUG 01-13 08:46:16.982068.982068 lmp.py:1622]   Expert  8 |    138 | CPU
DEBUG 01-13 08:46:16.982949.982949 lmp.py:1622]   Expert  5 |    139 | CPU
DEBUG 01-13 08:46:16.982831.982831 lmp.py:1622]   Expert 35 |    140 | CPU
DEBUG 01-13 08:46:16.982474.982474 lmp.py:1622]   Expert 61 |    148 | CPU
DEBUG 01-13 08:46:16.982117.982117 lmp.py:1622]   Expert 30 |    155 | CPU
DEBUG 01-13 08:46:16.982998.982998 lmp.py:1622]   Expert 39 |    158 | CPU
DEBUG 01-13 08:46:16.982879.982879 lmp.py:1622]   Expert  0 |    159 | CPU
DEBUG 01-13 08:46:16.982522.982522 lmp.py:1622]   Expert 23 |    159 | CPU
DEBUG 01-13 08:46:16.982073.982073 lmp.py:1622]   Expert 42 |    166 | CPU
DEBUG 01-13 08:46:16.982053.982053 lmp.py:1622]   Expert 13 |    171 | CPU
DEBUG 01-13 08:46:16.982365.982365 lmp.py:1622]   Expert 46 |    172 | CPU
DEBUG 01-13 08:46:16.982631.982631 lmp.py:1622]   Expert  3 |    175 | CPU
DEBUG 01-13 08:46:16.982943.982943 lmp.py:1622]   Expert 44 |    175 | CPU
DEBUG 01-13 08:46:16.982778.982778 lmp.py:1622]   Expert  9 |    177 | CPU
DEBUG 01-13 08:46:16.982613.982613 lmp.py:1622]   Expert 31 |    177 | CPU
DEBUG 01-13 08:46:16.982971.982971 lmp.py:1622]   Expert 41 |    177 | GPU
DEBUG 01-13 08:46:16.982806.982806 lmp.py:1622]   Expert 43 |    185 | GPU
DEBUG 01-13 08:46:16.982403.982403 lmp.py:1622]   Expert 27 |    187 | GPU
DEBUG 01-13 08:46:16.982761.982761 lmp.py:1622]   Expert 49 |    188 | GPU
DEBUG 01-13 08:46:16.982358.982358 lmp.py:1622]   Expert 26 |    190 | GPU
DEBUG 01-13 08:46:16.982954.982954 lmp.py:1622]   Expert 18 |    192 | GPU
DEBUG 01-13 08:46:16.982313.982313 lmp.py:1622]   Expert 62 |    193 | GPU
DEBUG 01-13 08:46:16.982863.982863 lmp.py:1622]   Expert 50 |    194 | GPU
DEBUG 01-13 08:46:16.982936.982936 lmp.py:1622]   Expert 47 |    196 | GPU
DEBUG 01-13 08:46:16.982010.982010 lmp.py:1622]   Expert 51 |    196 | GPU
DEBUG 01-13 08:46:16.982322.982322 lmp.py:1622]   Expert 11 |    200 | GPU
DEBUG 01-13 08:46:16.982442.982442 lmp.py:1622]   Expert 20 |    201 | GPU
DEBUG 01-13 08:46:16.982038.982038 lmp.py:1622]   Expert 55 |    204 | GPU
DEBUG 01-13 08:46:16.982397.982397 lmp.py:1622]   Expert 19 |    205 | GPU
DEBUG 01-13 08:46:16.983516.983516 lmp.py:1622]   Expert 63 |    211 | GPU
DEBUG 01-13 08:46:16.983113.983113 lmp.py:1622]   Expert 56 |    215 | GPU
DEBUG 01-13 08:46:16.983471.983471 lmp.py:1622]   Expert 38 |    217 | GPU
DEBUG 01-13 08:46:16.983591.983591 lmp.py:1622]   Expert 48 |    232 | GPU
DEBUG 01-13 08:46:16.983711.983711 lmp.py:1622]   Expert  1 |    238 | GPU
DEBUG 01-13 08:46:16.983308.983308 lmp.py:1622]   Expert 10 |    239 | GPU
DEBUG 01-13 08:46:16.983904.983904 lmp.py:1622]   Expert 54 |    244 | GPU
DEBUG 01-13 08:46:16.983739.983739 lmp.py:1622]   Expert  7 |    250 | GPU
DEBUG 01-13 08:46:16.983290.983290 lmp.py:1622]   Expert 21 |    256 | GPU
DEBUG 01-13 08:46:16.983363.983363 lmp.py:1622]   Expert 29 |    260 | GPU
DEBUG 01-13 08:46:16.983960.983960 lmp.py:1622]   Expert 33 |    262 | GPU
DEBUG 01-13 08:46:16.983318.983318 lmp.py:1622]   Expert 40 |    262 | GPU
DEBUG 01-13 08:46:16.983153.983153 lmp.py:1622]   Expert 24 |    271 | GPU
DEBUG 01-13 08:46:16.983511.983511 lmp.py:1622]   Expert 59 |    293 | GPU
DEBUG 01-13 08:46:16.983869.983869 lmp.py:1622]   Expert 37 |    334 | GPU
DEBUG 01-13 08:46:16.983466.983466 lmp.py:1622]   Expert 58 |    371 | GPU
DEBUG 01-13 08:46:16.983063.983063 lmp.py:1622]   Expert  6 |    389 | GPU
DEBUG 01-13 08:46:16.983659.983659 lmp.py:1622]   Expert 53 |    861 | GPU
DEBUG 01-13 08:46:16.983210.983210 lmp.py:1623] 
DEBUG 01-13 08:46:16.983210.983210 lmp.py:1623]   CPU total tokens: 4175 (34.0%)
DEBUG 01-13 08:46:16.983952.983952 lmp.py:1624]   GPU total tokens: 8113 (66.0%)
DEBUG 01-13 08:46:16.983463.983463 cuda_h.py:19] end experts_map_get cost 0.0018143653869628906 seconds
DEBUG 01-13 08:46:16.983942.983942 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-13 08:46:16.983890.983890 lmp.py:1632] 
DEBUG 01-13 08:46:16.983890.983890 lmp.py:1632]   Computing 32 experts on CPU MP...
DEBUG 01-13 08:46:16.983051.983051 cuda_h.py:19] end cpu_experts_submit cost 4.839897155761719e-05 seconds
DEBUG 01-13 08:46:16.983701.983701 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-13 08:46:16.983338.983338 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-13 08:46:16.983965.983965 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-13 08:46:16.985340.985340 cuda_h.py:19] end allocate_cuda_memory cost 0.0012564659118652344 seconds
DEBUG 01-13 08:46:16.985766.985766 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-13 08:46:16.985575.985575 sllm_store_c.py:27] get device uuid map
DEBUG 01-13 08:46:16.985914.985914 sllm_store_c.py:29] call client load into gpu
DEBUG 01-13 08:46:16.985856.985856 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 2e12842c-1fb6-463a-aa45-a7d0924cae7e
DEBUG 01-13 08:46:16.985848.985848 client.py:106] call stub.LoadModelAsync
INFO 01-13 08:46:16.985027.985027 client.py:127] Model loaded
DEBUG 01-13 08:46:16.986884.986884 cuda_h.py:10] start restore2model
DEBUG 01-13 08:46:16.986071.986071 cuda_h.py:10] start experts_func_gpu_einsum_mp
DEBUG 01-13 08:46:16.986044.986044 cuda_h.py:19] end restore2model cost 0.0005495548248291016 seconds
DEBUG 01-13 08:46:16.986662.986662 cuda_h.py:19] end sllm_worker_task cost 0.010915517807006836 seconds
INFO 01-13 08:46:16.987183.987183 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 2e12842c-1fb6-463a-aa45-a7d0924cae7e
DEBUG 01-13 08:46:16.987987.987987 cuda_h.py:19] end load_into_gpu_async cost 0.0027937889099121094 seconds
DEBUG 01-13 08:46:16.987597.987597 cuda_h.py:10] start restore_tensors2
DEBUG 01-13 08:46:16.988952.988952 cuda_h.py:19] end restore_tensors2 cost 0.0003037452697753906 seconds
DEBUG 01-13 08:46:16.988345.988345 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.004717588424682617 seconds
DEBUG 01-13 08:46:16.988498.988498 cuda_h.py:10] start restore2model
DEBUG 01-13 08:46:16.991973.991973 cuda_h.py:19] end restore2model cost 0.003055572509765625 seconds
DEBUG 01-13 08:46:16.991570.991570 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.00795602798461914 seconds
DEBUG 01-13 08:46:16.991294.991294 cuda_h.py:10] start gpu_sexperts
DEBUG 01-13 08:46:16.991809.991809 cuda_h.py:19] end gpu_sexperts cost 0.0003116130828857422 seconds
DEBUG 01-13 08:46:16.991976.991976 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-13 08:46:16.992514.992514 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 1.52587890625e-05 seconds
DEBUG 01-13 08:46:16.992402.992402 cuda_h.py:10] start wait_experts
INFO 01-13 08:46:16.992005.992005 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 2e12842c-1fb6-463a-aa45-a7d0924cae7e
DEBUG 01-13 08:46:16.996929.996929 mlpmodule.py:1006] group tensors cost 0.009616374969482422 s
DEBUG 01-13 08:46:16.998190.998190 mlpmodule.py:1044] pad cost 0.0014889240264892578 s
DEBUG 01-13 08:46:16.998479.998479 mlpmodule.py:1050] create cpu tensor cost 5.507469177246094e-05 s
DEBUG 01-13 08:46:16.998613.998613 mlpmodule.py:1055] move to cpu cost 2.956390380859375e-05 s
DEBUG 01-13 08:46:17.007725.007725 mlpmodule.py:1069] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-13 08:46:17.007291.007291 mlpmodule.py:1070] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-13 08:46:17.007634.007634 mlpmodule.py:1075] group_w3 first element: 0.03369140625
WARNING 01-13 08:46:17.007340.007340 mlpmodule.py:1085] start einsum2
DEBUG 01-13 08:46:17.021780.021780 mlpmodule.py:1095] group einsum cost 0.022516489028930664 s
DEBUG 01-13 08:46:17.022782.022782 mlpmodule.py:1103] cpy2cputensor cost 0.0007269382476806641 s
INFO 01-13 08:46:17.040574.040574 client.py:127] Model loaded
DEBUG 01-13 08:46:17.040796.040796 cuda_h.py:19] end wait_experts cost 0.04826807975769043 seconds
DEBUG 01-13 08:46:17.040429.040429 cuda_h.py:10] start gpu_experts
DEBUG 01-13 08:46:17.041001.041001 mlpmodule.py:559] gpu group tensors cost 0.0006761550903320312 s
DEBUG 01-13 08:46:17.044030.044030 mlpmodule.py:592] gpu pad cost 0.002296924591064453 s
DEBUG 01-13 08:46:17.044238.044238 mlpmodule.py:598] start_w1
DEBUG 01-13 08:46:17.044337.044337 mlpmodule.py:602] start_w3
DEBUG 01-13 08:46:17.044038.044038 mlpmodule.py:608] start_w2
DEBUG 01-13 08:46:17.045090.045090 mlpmodule.py:611] gpu group einsum cost 0.0011205673217773438 s
DEBUG 01-13 08:46:17.045961.045961 mlpmodule.py:785]  experts func einsum cost 0.05884981155395508 s
DEBUG 01-13 08:46:17.046615.046615 cuda_h.py:19] end experts_func_gpu_einsum_mp cost 0.059685468673706055 seconds
DEBUG 01-13 08:46:17.048871.048871 mlpmodule.py:683] gpu experts func einsum cost 0.007311820983886719 s
DEBUG 01-13 08:46:17.048014.048014 cuda_h.py:19] end gpu_experts cost 0.00769352912902832 seconds
DEBUG 01-13 08:46:17.048723.048723 cuda_h.py:10] start cpu_thread_manager_mp_wait
DEBUG 01-13 08:46:17.048024.048024 cuda_h.py:19] end cpu_thread_manager_mp_wait cost 4.7206878662109375e-05 seconds
DEBUG 01-13 08:46:17.048366.048366 cuda_h.py:19] end layer_moe_generate_mp_l_6 cost 0.06779909133911133 seconds
DEBUG 01-13 08:46:17.048989.048989 lmp.py:1550] -------------------------------- end prefill layer 5 --------------------------------
DEBUG 01-13 08:46:17.048712.048712 lmp.py:1493] -------------------------------- start prefill layer 6 --------------------------------
DEBUG 01-13 08:46:17.048634.048634 cuda_h.py:10] start start_load_qkvogn_s_weight_l_7
DEBUG 01-13 08:46:17.048304.048304 cuda_h.py:10] start start_load_qkvogn_s_weight_l_7
DEBUG 01-13 08:46:17.048538.048538 cuda_h.py:19] end start_load_qkvogn_s_weight_l_7 cost 3.552436828613281e-05 seconds
DEBUG 01-13 08:46:17.048817.048817 cuda_h.py:19] end start_load_qkvogn_s_weight_l_7 cost 6.866455078125e-05 seconds
DEBUG 01-13 08:46:17.048037.048037 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-13 08:46:17.049305.049305 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-13 08:46:17.049844.049844 cuda_h.py:10] start sllm_worker_task
DEBUG 01-13 08:46:17.049383.049383 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-13 08:46:17.049689.049689 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-13 08:46:17.049750.049750 cuda_h.py:19] end allocate_cuda_memory cost 0.000186920166015625 seconds
DEBUG 01-13 08:46:17.049553.049553 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-13 08:46:17.049455.049455 sllm_store_c.py:27] get device uuid map
DEBUG 01-13 08:46:17.049609.049609 sllm_store_c.py:29] call client load into gpu
DEBUG 01-13 08:46:17.049788.049788 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, cf3691e8-f332-4e85-aca5-62d62defa591
DEBUG 01-13 08:46:17.049434.049434 client.py:106] call stub.LoadModelAsync
DEBUG 01-13 08:46:17.050791.050791 cuda_h.py:10] start self_attn
INFO 01-13 08:46:17.051670.051670 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, cf3691e8-f332-4e85-aca5-62d62defa591
DEBUG 01-13 08:46:17.051175.051175 cuda_h.py:19] end load_into_gpu_async cost 0.0017240047454833984 seconds
DEBUG 01-13 08:46:17.051766.051766 cuda_h.py:10] start restore_tensors2
DEBUG 01-13 08:46:17.051226.051226 cuda_h.py:19] end restore_tensors2 cost 6.723403930664062e-05 seconds
DEBUG 01-13 08:46:17.051836.051836 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0022330284118652344 seconds
INFO 01-13 08:46:17.051619.051619 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, cf3691e8-f332-4e85-aca5-62d62defa591
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-13 08:46:17.053901.053901 cuda_h.py:19] end self_attn cost 0.0034182071685791016 seconds
DEBUG 01-13 08:46:17.053568.053568 cuda_h.py:19] end iln_self_attn_paln cost 0.004943132400512695 seconds
DEBUG 01-13 08:46:17.054173.054173 cuda_h.py:10] start layer_moe_generate_mp_l_7
DEBUG 01-13 08:46:17.054128.054128 cuda_h.py:10] start gate
DEBUG 01-13 08:46:17.054491.054491 cuda_h.py:19] end gate cost 0.0007228851318359375 seconds
DEBUG 01-13 08:46:17.054612.054612 cuda_h.py:10] start experts_map_get
DEBUG 01-13 08:46:17.055720.055720 lmp.py:1611] 
DEBUG 01-13 08:46:17.055720.055720 lmp.py:1611] Expert Token Distribution & Device Allocation:
DEBUG 01-13 08:46:17.055814.055814 lmp.py:1612]   Total experts: 64
DEBUG 01-13 08:46:17.055609.055609 lmp.py:1613]   CPU experts: 32 (50%)
DEBUG 01-13 08:46:17.055590.055590 lmp.py:1614]   GPU experts: 32 (50%)
DEBUG 01-13 08:46:17.055425.055425 lmp.py:1615] 
DEBUG 01-13 08:46:17.055425.055425 lmp.py:1615]   Expert ID | Tokens | Device
DEBUG 01-13 08:46:17.055499.055499 lmp.py:1616]   -----------------------------------
DEBUG 01-13 08:46:17.055056.055056 lmp.py:1622]   Expert  1 |     46 | CPU
DEBUG 01-13 08:46:17.055606.055606 lmp.py:1622]   Expert  7 |     58 | CPU
DEBUG 01-13 08:46:17.055203.055203 lmp.py:1622]   Expert 37 |     73 | CPU
DEBUG 01-13 08:46:17.055561.055561 lmp.py:1622]   Expert 54 |     78 | CPU
DEBUG 01-13 08:46:17.055443.055443 lmp.py:1622]   Expert 17 |     83 | CPU
DEBUG 01-13 08:46:17.055562.055562 lmp.py:1622]   Expert 18 |     83 | CPU
DEBUG 01-13 08:46:17.055444.055444 lmp.py:1622]   Expert 13 |     94 | CPU
DEBUG 01-13 08:46:17.055756.055756 lmp.py:1622]   Expert  9 |    100 | CPU
DEBUG 01-13 08:46:17.055875.055875 lmp.py:1622]   Expert 58 |    101 | CPU
DEBUG 01-13 08:46:17.055995.055995 lmp.py:1622]   Expert 22 |    104 | CPU
DEBUG 01-13 08:46:17.055877.055877 lmp.py:1622]   Expert  0 |    106 | CPU
DEBUG 01-13 08:46:17.055997.055997 lmp.py:1622]   Expert 16 |    115 | CPU
DEBUG 01-13 08:46:17.055878.055878 lmp.py:1622]   Expert 26 |    116 | CPU
DEBUG 01-13 08:46:17.055521.055521 lmp.py:1622]   Expert 10 |    124 | CPU
DEBUG 01-13 08:46:17.055402.055402 lmp.py:1622]   Expert 63 |    131 | CPU
DEBUG 01-13 08:46:17.055045.055045 lmp.py:1622]   Expert 43 |    141 | CPU
DEBUG 01-13 08:46:17.055165.055165 lmp.py:1622]   Expert 33 |    143 | CPU
DEBUG 01-13 08:46:17.055239.055239 lmp.py:1622]   Expert 62 |    143 | CPU
DEBUG 01-13 08:46:17.055074.055074 lmp.py:1622]   Expert 59 |    144 | CPU
DEBUG 01-13 08:46:17.055670.055670 lmp.py:1622]   Expert 28 |    146 | CPU
DEBUG 01-13 08:46:17.055552.055552 lmp.py:1622]   Expert 29 |    151 | CPU
DEBUG 01-13 08:46:17.055433.055433 lmp.py:1622]   Expert  2 |    158 | CPU
DEBUG 01-13 08:46:17.055838.055838 lmp.py:1622]   Expert 55 |    164 | CPU
DEBUG 01-13 08:46:17.055719.055719 lmp.py:1622]   Expert 45 |    165 | CPU
DEBUG 01-13 08:46:17.055124.055124 lmp.py:1622]   Expert 51 |    165 | CPU
DEBUG 01-13 08:46:17.055912.055912 lmp.py:1622]   Expert 23 |    166 | CPU
DEBUG 01-13 08:46:17.055224.055224 lmp.py:1622]   Expert 32 |    167 | CPU
DEBUG 01-13 08:46:17.055775.055775 lmp.py:1622]   Expert 53 |    167 | CPU
DEBUG 01-13 08:46:17.055371.055371 lmp.py:1622]   Expert  3 |    168 | CPU
DEBUG 01-13 08:46:17.056206.056206 lmp.py:1622]   Expert 40 |    168 | CPU
DEBUG 01-13 08:46:17.056564.056564 lmp.py:1622]   Expert 11 |    171 | CPU
DEBUG 01-13 08:46:17.056161.056161 lmp.py:1622]   Expert 34 |    174 | CPU
DEBUG 01-13 08:46:17.056758.056758 lmp.py:1622]   Expert 52 |    176 | GPU
DEBUG 01-13 08:46:17.056116.056116 lmp.py:1622]   Expert 14 |    177 | GPU
DEBUG 01-13 08:46:17.056713.056713 lmp.py:1622]   Expert 42 |    179 | GPU
DEBUG 01-13 08:46:17.056025.056025 lmp.py:1622]   Expert 41 |    180 | GPU
DEBUG 01-13 08:46:17.056621.056621 lmp.py:1622]   Expert 57 |    190 | GPU
DEBUG 01-13 08:46:17.056456.056456 lmp.py:1622]   Expert 21 |    191 | GPU
DEBUG 01-13 08:46:17.056053.056053 lmp.py:1622]   Expert 30 |    197 | GPU
DEBUG 01-13 08:46:17.056650.056650 lmp.py:1622]   Expert 15 |    208 | GPU
DEBUG 01-13 08:46:17.056485.056485 lmp.py:1622]   Expert 35 |    209 | GPU
DEBUG 01-13 08:46:17.056081.056081 lmp.py:1622]   Expert  4 |    215 | GPU
DEBUG 01-13 08:46:17.056916.056916 lmp.py:1622]   Expert 12 |    215 | GPU
DEBUG 01-13 08:46:17.056513.056513 lmp.py:1622]   Expert 49 |    224 | GPU
DEBUG 01-13 08:46:17.056540.056540 lmp.py:1622]   Expert 50 |    226 | GPU
DEBUG 01-13 08:46:17.056329.056329 lmp.py:1622]   Expert 46 |    228 | GPU
DEBUG 01-13 08:46:17.056164.056164 lmp.py:1622]   Expert 24 |    230 | GPU
DEBUG 01-13 08:46:17.056999.056999 lmp.py:1622]   Expert  8 |    235 | GPU
DEBUG 01-13 08:46:17.056834.056834 lmp.py:1622]   Expert 44 |    237 | GPU
DEBUG 01-13 08:46:17.056252.056252 lmp.py:1622]   Expert 38 |    239 | GPU
DEBUG 01-13 08:46:17.056015.056015 lmp.py:1622]   Expert  6 |    241 | GPU
DEBUG 01-13 08:46:17.056565.056565 lmp.py:1622]   Expert 47 |    247 | GPU
DEBUG 01-13 08:46:17.056116.056116 lmp.py:1622]   Expert 19 |    250 | GPU
DEBUG 01-13 08:46:17.056620.056620 lmp.py:1622]   Expert 31 |    250 | GPU
DEBUG 01-13 08:46:17.056170.056170 lmp.py:1622]   Expert 61 |    251 | GPU
DEBUG 01-13 08:46:17.056005.056005 lmp.py:1622]   Expert 39 |    274 | GPU
DEBUG 01-13 08:46:17.056555.056555 lmp.py:1622]   Expert  5 |    301 | GPU
DEBUG 01-13 08:46:17.056390.056390 lmp.py:1622]   Expert 36 |    301 | GPU
DEBUG 01-13 08:46:17.056464.056464 lmp.py:1622]   Expert 27 |    315 | GPU
DEBUG 01-13 08:46:17.056299.056299 lmp.py:1622]   Expert 60 |    328 | GPU
DEBUG 01-13 08:46:17.056611.056611 lmp.py:1622]   Expert 20 |    344 | GPU
DEBUG 01-13 08:46:17.056161.056161 lmp.py:1622]   Expert 48 |    370 | GPU
DEBUG 01-13 08:46:17.056712.056712 lmp.py:1622]   Expert 25 |    390 | GPU
DEBUG 01-13 08:46:17.056785.056785 lmp.py:1622]   Expert 56 |    557 | GPU
DEBUG 01-13 08:46:17.056812.056812 lmp.py:1623] 
DEBUG 01-13 08:46:17.056812.056812 lmp.py:1623]   CPU total tokens: 4113 (33.5%)
DEBUG 01-13 08:46:17.056839.056839 lmp.py:1624]   GPU total tokens: 8175 (66.5%)
DEBUG 01-13 08:46:17.056635.056635 cuda_h.py:19] end experts_map_get cost 0.0018470287322998047 seconds
DEBUG 01-13 08:46:17.056068.056068 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-13 08:46:17.056162.056162 lmp.py:1632] 
DEBUG 01-13 08:46:17.056162.056162 lmp.py:1632]   Computing 32 experts on CPU MP...
DEBUG 01-13 08:46:17.056422.056422 cuda_h.py:19] end cpu_experts_submit cost 5.1021575927734375e-05 seconds
DEBUG 01-13 08:46:17.056071.056071 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-13 08:46:17.056431.056431 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-13 08:46:17.057084.057084 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-13 08:46:17.058033.058033 cuda_h.py:19] end allocate_cuda_memory cost 0.001066446304321289 seconds
DEBUG 01-13 08:46:17.058599.058599 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-13 08:46:17.058223.058223 sllm_store_c.py:27] get device uuid map
DEBUG 01-13 08:46:17.058754.058754 sllm_store_c.py:29] call client load into gpu
DEBUG 01-13 08:46:17.058504.058504 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, dcdffda2-9699-41a6-90a6-f0e8b341de68
DEBUG 01-13 08:46:17.058235.058235 cuda_h.py:10] start experts_func_gpu_einsum_mp
DEBUG 01-13 08:46:17.058357.058357 client.py:106] call stub.LoadModelAsync
INFO 01-13 08:46:17.059750.059750 client.py:127] Model loaded
DEBUG 01-13 08:46:17.059593.059593 cuda_h.py:10] start restore2model
DEBUG 01-13 08:46:17.059800.059800 cuda_h.py:19] end restore2model cost 0.0003941059112548828 seconds
DEBUG 01-13 08:46:17.059675.059675 cuda_h.py:19] end sllm_worker_task cost 0.010721206665039062 seconds
INFO 01-13 08:46:17.060158.060158 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, dcdffda2-9699-41a6-90a6-f0e8b341de68
DEBUG 01-13 08:46:17.060915.060915 cuda_h.py:19] end load_into_gpu_async cost 0.0022640228271484375 seconds
DEBUG 01-13 08:46:17.060287.060287 cuda_h.py:10] start restore_tensors2
DEBUG 01-13 08:46:17.061788.061788 cuda_h.py:19] end restore_tensors2 cost 0.00030684471130371094 seconds
DEBUG 01-13 08:46:17.061518.061518 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.004354000091552734 seconds
DEBUG 01-13 08:46:17.061804.061804 cuda_h.py:10] start restore2model
DEBUG 01-13 08:46:17.064384.064384 cuda_h.py:19] end restore2model cost 0.0030617713928222656 seconds
DEBUG 01-13 08:46:17.064890.064890 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.0076007843017578125 seconds
DEBUG 01-13 08:46:17.064116.064116 cuda_h.py:10] start gpu_sexperts
DEBUG 01-13 08:46:17.064869.064869 cuda_h.py:19] end gpu_sexperts cost 0.00031065940856933594 seconds
DEBUG 01-13 08:46:17.064228.064228 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-13 08:46:17.065674.065674 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 1.52587890625e-05 seconds
DEBUG 01-13 08:46:17.065046.065046 cuda_h.py:10] start wait_experts
INFO 01-13 08:46:17.065987.065987 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, dcdffda2-9699-41a6-90a6-f0e8b341de68
DEBUG 01-13 08:46:17.068559.068559 mlpmodule.py:1006] group tensors cost 0.00931859016418457 s
DEBUG 01-13 08:46:17.070272.070272 mlpmodule.py:1044] pad cost 0.0015101432800292969 s
DEBUG 01-13 08:46:17.070276.070276 mlpmodule.py:1050] create cpu tensor cost 5.4836273193359375e-05 s
DEBUG 01-13 08:46:17.071934.071934 mlpmodule.py:1055] move to cpu cost 2.9325485229492188e-05 s
DEBUG 01-13 08:46:17.078961.078961 mlpmodule.py:1069] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-13 08:46:17.079910.079910 mlpmodule.py:1070] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-13 08:46:17.079902.079902 mlpmodule.py:1075] group_w3 first element: -0.003631591796875
WARNING 01-13 08:46:17.079291.079291 mlpmodule.py:1085] start einsum2
DEBUG 01-13 08:46:17.093217.093217 mlpmodule.py:1095] group einsum cost 0.022042036056518555 s
DEBUG 01-13 08:46:17.094776.094776 mlpmodule.py:1103] cpy2cputensor cost 0.0007104873657226562 s
INFO 01-13 08:46:17.112919.112919 client.py:127] Model loaded
DEBUG 01-13 08:46:17.113776.113776 cuda_h.py:19] end wait_experts cost 0.04804563522338867 seconds
DEBUG 01-13 08:46:17.113071.113071 cuda_h.py:10] start gpu_experts
DEBUG 01-13 08:46:17.114708.114708 mlpmodule.py:559] gpu group tensors cost 0.0008118152618408203 s
DEBUG 01-13 08:46:17.116191.116191 mlpmodule.py:785]  experts func einsum cost 0.05667686462402344 s
DEBUG 01-13 08:46:17.116999.116999 cuda_h.py:19] end experts_func_gpu_einsum_mp cost 0.05755186080932617 seconds
DEBUG 01-13 08:46:17.116720.116720 mlpmodule.py:592] gpu pad cost 0.002391815185546875 s
DEBUG 01-13 08:46:17.116928.116928 mlpmodule.py:598] start_w1
DEBUG 01-13 08:46:17.117829.117829 mlpmodule.py:602] start_w3
DEBUG 01-13 08:46:17.117339.117339 mlpmodule.py:608] start_w2
DEBUG 01-13 08:46:17.117146.117146 mlpmodule.py:611] gpu group einsum cost 0.0007576942443847656 s
DEBUG 01-13 08:46:17.120151.120151 mlpmodule.py:683] gpu experts func einsum cost 0.007133007049560547 s
DEBUG 01-13 08:46:17.120240.120240 cuda_h.py:19] end gpu_experts cost 0.007354259490966797 seconds
DEBUG 01-13 08:46:17.120188.120188 cuda_h.py:10] start cpu_thread_manager_mp_wait
DEBUG 01-13 08:46:17.120376.120376 cuda_h.py:19] end cpu_thread_manager_mp_wait cost 3.6716461181640625e-05 seconds
DEBUG 01-13 08:46:17.120591.120591 cuda_h.py:19] end layer_moe_generate_mp_l_7 cost 0.0668478012084961 seconds
DEBUG 01-13 08:46:17.121572.121572 lmp.py:1550] -------------------------------- end prefill layer 6 --------------------------------
DEBUG 01-13 08:46:17.121242.121242 lmp.py:1493] -------------------------------- start prefill layer 7 --------------------------------
DEBUG 01-13 08:46:17.121899.121899 cuda_h.py:10] start start_load_qkvogn_s_weight_l_8
DEBUG 01-13 08:46:17.121377.121377 cuda_h.py:10] start start_load_qkvogn_s_weight_l_8
DEBUG 01-13 08:46:17.121796.121796 cuda_h.py:19] end start_load_qkvogn_s_weight_l_8 cost 3.528594970703125e-05 seconds
DEBUG 01-13 08:46:17.121904.121904 cuda_h.py:19] end start_load_qkvogn_s_weight_l_8 cost 8.249282836914062e-05 seconds
DEBUG 01-13 08:46:17.121408.121408 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-13 08:46:17.121271.121271 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-13 08:46:17.121903.121903 cuda_h.py:10] start sllm_worker_task
DEBUG 01-13 08:46:17.121476.121476 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-13 08:46:17.121167.121167 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-13 08:46:17.121439.121439 cuda_h.py:19] end allocate_cuda_memory cost 0.00020074844360351562 seconds
DEBUG 01-13 08:46:17.121766.121766 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-13 08:46:17.122237.122237 sllm_store_c.py:27] get device uuid map
DEBUG 01-13 08:46:17.122822.122822 sllm_store_c.py:29] call client load into gpu
DEBUG 01-13 08:46:17.122240.122240 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 1011cd6f-c7aa-4006-8c77-dcd8d719fb23
DEBUG 01-13 08:46:17.122408.122408 client.py:106] call stub.LoadModelAsync
DEBUG 01-13 08:46:17.122102.122102 cuda_h.py:10] start self_attn
INFO 01-13 08:46:17.123316.123316 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 1011cd6f-c7aa-4006-8c77-dcd8d719fb23
DEBUG 01-13 08:46:17.123867.123867 cuda_h.py:19] end load_into_gpu_async cost 0.0014111995697021484 seconds
DEBUG 01-13 08:46:17.123425.123425 cuda_h.py:10] start restore_tensors2
DEBUG 01-13 08:46:17.123646.123646 cuda_h.py:19] end restore_tensors2 cost 6.67572021484375e-05 seconds
DEBUG 01-13 08:46:17.123018.123018 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0019097328186035156 seconds
INFO 01-13 08:46:17.123338.123338 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 1011cd6f-c7aa-4006-8c77-dcd8d719fb23
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-13 08:46:17.126881.126881 cuda_h.py:19] end self_attn cost 0.004016876220703125 seconds
DEBUG 01-13 08:46:17.126965.126965 cuda_h.py:19] end iln_self_attn_paln cost 0.005539417266845703 seconds
DEBUG 01-13 08:46:17.127669.127669 cuda_h.py:10] start layer_moe_generate_mp_l_8
DEBUG 01-13 08:46:17.127578.127578 cuda_h.py:10] start gate
DEBUG 01-13 08:46:17.127948.127948 cuda_h.py:19] end gate cost 0.0007264614105224609 seconds
DEBUG 01-13 08:46:17.127446.127446 cuda_h.py:10] start experts_map_get
DEBUG 01-13 08:46:17.128025.128025 lmp.py:1611] 
DEBUG 01-13 08:46:17.128025.128025 lmp.py:1611] Expert Token Distribution & Device Allocation:
DEBUG 01-13 08:46:17.128688.128688 lmp.py:1612]   Total experts: 64
DEBUG 01-13 08:46:17.128166.128166 lmp.py:1613]   CPU experts: 32 (50%)
DEBUG 01-13 08:46:17.128743.128743 lmp.py:1614]   GPU experts: 32 (50%)
DEBUG 01-13 08:46:17.128486.128486 lmp.py:1615] 
DEBUG 01-13 08:46:17.128486.128486 lmp.py:1615]   Expert ID | Tokens | Device
DEBUG 01-13 08:46:17.128751.128751 lmp.py:1616]   -----------------------------------
DEBUG 01-13 08:46:17.128262.128262 lmp.py:1622]   Expert 50 |     45 | CPU
DEBUG 01-13 08:46:17.128813.128813 lmp.py:1622]   Expert  3 |     55 | CPU
DEBUG 01-13 08:46:17.128886.128886 lmp.py:1622]   Expert 46 |     56 | CPU
DEBUG 01-13 08:46:17.128959.128959 lmp.py:1622]   Expert  1 |     78 | CPU
DEBUG 01-13 08:46:17.128033.128033 lmp.py:1622]   Expert 29 |     89 | CPU
DEBUG 01-13 08:46:17.128106.128106 lmp.py:1622]   Expert  4 |     91 | CPU
DEBUG 01-13 08:46:17.128703.128703 lmp.py:1622]   Expert 15 |     97 | CPU
DEBUG 01-13 08:46:17.128538.128538 lmp.py:1622]   Expert 40 |     97 | CPU
DEBUG 01-13 08:46:17.128373.128373 lmp.py:1622]   Expert 41 |    110 | CPU
DEBUG 01-13 08:46:17.128970.128970 lmp.py:1622]   Expert  8 |    112 | CPU
DEBUG 01-13 08:46:17.128759.128759 lmp.py:1622]   Expert 28 |    118 | CPU
DEBUG 01-13 08:46:17.128547.128547 lmp.py:1622]   Expert  6 |    127 | CPU
DEBUG 01-13 08:46:17.128336.128336 lmp.py:1622]   Expert 48 |    129 | CPU
DEBUG 01-13 08:46:17.128410.128410 lmp.py:1622]   Expert 13 |    130 | CPU
DEBUG 01-13 08:46:17.128006.128006 lmp.py:1622]   Expert 54 |    130 | CPU
DEBUG 01-13 08:46:17.128841.128841 lmp.py:1622]   Expert 16 |    132 | CPU
DEBUG 01-13 08:46:17.128200.128200 lmp.py:1622]   Expert 27 |    133 | CPU
DEBUG 01-13 08:46:17.128657.128657 lmp.py:1622]   Expert 60 |    134 | CPU
DEBUG 01-13 08:46:17.128930.128930 lmp.py:1622]   Expert  7 |    136 | CPU
DEBUG 01-13 08:46:17.128149.128149 lmp.py:1622]   Expert 39 |    136 | CPU
DEBUG 01-13 08:46:17.128222.128222 lmp.py:1622]   Expert 51 |    137 | CPU
DEBUG 01-13 08:46:17.128296.128296 lmp.py:1622]   Expert 52 |    140 | CPU
DEBUG 01-13 08:46:17.128608.128608 lmp.py:1622]   Expert 14 |    141 | CPU
DEBUG 01-13 08:46:17.128681.128681 lmp.py:1622]   Expert 18 |    142 | CPU
DEBUG 01-13 08:46:17.128516.128516 lmp.py:1622]   Expert 56 |    144 | CPU
DEBUG 01-13 08:46:17.128159.128159 lmp.py:1622]   Expert 43 |    145 | CPU
DEBUG 01-13 08:46:17.128041.128041 lmp.py:1622]   Expert 20 |    146 | CPU
DEBUG 01-13 08:46:17.129922.129922 lmp.py:1622]   Expert 55 |    150 | CPU
DEBUG 01-13 08:46:17.129565.129565 lmp.py:1622]   Expert 36 |    151 | CPU
DEBUG 01-13 08:46:17.129208.129208 lmp.py:1622]   Expert 45 |    158 | CPU
DEBUG 01-13 08:46:17.129851.129851 lmp.py:1622]   Expert 10 |    159 | CPU
DEBUG 01-13 08:46:17.129494.129494 lmp.py:1622]   Expert 62 |    159 | CPU
DEBUG 01-13 08:46:17.129375.129375 lmp.py:1622]   Expert 11 |    160 | GPU
DEBUG 01-13 08:46:17.129687.129687 lmp.py:1622]   Expert  5 |    164 | GPU
DEBUG 01-13 08:46:17.129761.129761 lmp.py:1622]   Expert 57 |    174 | GPU
DEBUG 01-13 08:46:17.129119.129119 lmp.py:1622]   Expert 44 |    177 | GPU
DEBUG 01-13 08:46:17.129192.129192 lmp.py:1622]   Expert 58 |    182 | GPU
DEBUG 01-13 08:46:17.129074.129074 lmp.py:1622]   Expert 33 |    183 | GPU
DEBUG 01-13 08:46:17.129955.129955 lmp.py:1622]   Expert 53 |    183 | GPU
DEBUG 01-13 08:46:17.129598.129598 lmp.py:1622]   Expert 25 |    185 | GPU
DEBUG 01-13 08:46:17.129241.129241 lmp.py:1622]   Expert  2 |    188 | GPU
DEBUG 01-13 08:46:17.129646.129646 lmp.py:1622]   Expert 32 |    190 | GPU
DEBUG 01-13 08:46:17.129289.129289 lmp.py:1622]   Expert 31 |    193 | GPU
DEBUG 01-13 08:46:17.129693.129693 lmp.py:1622]   Expert 49 |    198 | GPU
DEBUG 01-13 08:46:17.129575.129575 lmp.py:1622]   Expert 35 |    200 | GPU
DEBUG 01-13 08:46:17.129218.129218 lmp.py:1622]   Expert 63 |    200 | GPU
DEBUG 01-13 08:46:17.129861.129861 lmp.py:1622]   Expert 21 |    206 | GPU
DEBUG 01-13 08:46:17.129457.129457 lmp.py:1622]   Expert 17 |    208 | GPU
DEBUG 01-13 08:46:17.129531.129531 lmp.py:1622]   Expert 34 |    216 | GPU
DEBUG 01-13 08:46:17.129889.129889 lmp.py:1622]   Expert 42 |    220 | GPU
DEBUG 01-13 08:46:17.129247.129247 lmp.py:1622]   Expert 37 |    228 | GPU
DEBUG 01-13 08:46:17.129036.129036 lmp.py:1622]   Expert 59 |    230 | GPU
DEBUG 01-13 08:46:17.129348.129348 lmp.py:1622]   Expert 22 |    231 | GPU
DEBUG 01-13 08:46:17.129421.129421 lmp.py:1622]   Expert  0 |    246 | GPU
DEBUG 01-13 08:46:17.129018.129018 lmp.py:1622]   Expert 19 |    259 | GPU
DEBUG 01-13 08:46:17.129853.129853 lmp.py:1622]   Expert 24 |    284 | GPU
DEBUG 01-13 08:46:17.129211.129211 lmp.py:1622]   Expert 61 |    284 | GPU
DEBUG 01-13 08:46:17.129570.129570 lmp.py:1622]   Expert 30 |    305 | GPU
DEBUG 01-13 08:46:17.129425.129425 lmp.py:1622]   Expert 47 |    323 | GPU
DEBUG 01-13 08:46:17.129022.129022 lmp.py:1622]   Expert 38 |    363 | GPU
DEBUG 01-13 08:46:17.129380.129380 lmp.py:1622]   Expert 26 |    365 | GPU
DEBUG 01-13 08:46:17.129784.129784 lmp.py:1622]   Expert 12 |    436 | GPU
DEBUG 01-13 08:46:17.129189.129189 lmp.py:1622]   Expert  9 |    678 | GPU
DEBUG 01-13 08:46:17.129117.129117 lmp.py:1622]   Expert 23 |    722 | GPU
DEBUG 01-13 08:46:17.129236.129236 lmp.py:1623] 
DEBUG 01-13 08:46:17.129236.129236 lmp.py:1623]   CPU total tokens: 3907 (31.8%)
DEBUG 01-13 08:46:17.129833.129833 lmp.py:1624]   GPU total tokens: 8381 (68.2%)
DEBUG 01-13 08:46:17.129198.129198 cuda_h.py:19] end experts_map_get cost 0.0018584728240966797 seconds
DEBUG 01-13 08:46:17.129485.129485 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-13 08:46:17.129480.129480 lmp.py:1632] 
DEBUG 01-13 08:46:17.129480.129480 lmp.py:1632]   Computing 32 experts on CPU MP...
DEBUG 01-13 08:46:17.129740.129740 cuda_h.py:19] end cpu_experts_submit cost 5.1021575927734375e-05 seconds
DEBUG 01-13 08:46:17.129389.129389 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-13 08:46:17.129742.129742 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-13 08:46:17.130641.130641 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-13 08:46:17.130484.130484 cuda_h.py:19] end allocate_cuda_memory cost 0.00023484230041503906 seconds
DEBUG 01-13 08:46:17.130816.130816 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-13 08:46:17.130063.130063 sllm_store_c.py:27] get device uuid map
DEBUG 01-13 08:46:17.130223.130223 sllm_store_c.py:29] call client load into gpu
DEBUG 01-13 08:46:17.130641.130641 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 90187094-fa03-4cea-8cb3-7570964b2934
DEBUG 01-13 08:46:17.131918.131918 client.py:106] call stub.LoadModelAsync
INFO 01-13 08:46:17.131686.131686 client.py:127] Model loaded
DEBUG 01-13 08:46:17.131821.131821 cuda_h.py:10] start restore2model
DEBUG 01-13 08:46:17.131102.131102 cuda_h.py:10] start experts_func_gpu_einsum_mp
DEBUG 01-13 08:46:17.131770.131770 cuda_h.py:19] end restore2model cost 0.0004119873046875 seconds
DEBUG 01-13 08:46:17.131791.131791 cuda_h.py:19] end sllm_worker_task cost 0.010210990905761719 seconds
INFO 01-13 08:46:17.132814.132814 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 90187094-fa03-4cea-8cb3-7570964b2934
DEBUG 01-13 08:46:17.132572.132572 cuda_h.py:19] end load_into_gpu_async cost 0.0013530254364013672 seconds
DEBUG 01-13 08:46:17.132705.132705 cuda_h.py:10] start restore_tensors2
DEBUG 01-13 08:46:17.132604.132604 cuda_h.py:19] end restore_tensors2 cost 0.00031876564025878906 seconds
DEBUG 01-13 08:46:17.132380.132380 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.002615213394165039 seconds
DEBUG 01-13 08:46:17.132666.132666 cuda_h.py:10] start restore2model
DEBUG 01-13 08:46:17.135490.135490 cuda_h.py:19] end restore2model cost 0.003000497817993164 seconds
DEBUG 01-13 08:46:17.135988.135988 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.005789995193481445 seconds
DEBUG 01-13 08:46:17.135519.135519 cuda_h.py:10] start gpu_sexperts
DEBUG 01-13 08:46:17.136504.136504 cuda_h.py:19] end gpu_sexperts cost 0.00030803680419921875 seconds
DEBUG 01-13 08:46:17.136764.136764 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-13 08:46:17.136746.136746 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 1.621246337890625e-05 seconds
DEBUG 01-13 08:46:17.136588.136588 cuda_h.py:10] start wait_experts
INFO 01-13 08:46:17.136053.136053 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 90187094-fa03-4cea-8cb3-7570964b2934
DEBUG 01-13 08:46:17.137538.137538 mlpmodule.py:1006] group tensors cost 0.0054399967193603516 s
DEBUG 01-13 08:46:17.140105.140105 mlpmodule.py:1044] pad cost 0.0021049976348876953 s
DEBUG 01-13 08:46:17.140745.140745 mlpmodule.py:1050] create cpu tensor cost 5.14984130859375e-05 s
DEBUG 01-13 08:46:17.140112.140112 mlpmodule.py:1055] move to cpu cost 4.601478576660156e-05 s
DEBUG 01-13 08:46:17.147416.147416 mlpmodule.py:1069] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-13 08:46:17.148889.148889 mlpmodule.py:1070] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-13 08:46:17.148026.148026 mlpmodule.py:1075] group_w3 first element: 0.01263427734375
WARNING 01-13 08:46:17.148926.148926 mlpmodule.py:1085] start einsum2
DEBUG 01-13 08:46:17.161506.161506 mlpmodule.py:1095] group einsum cost 0.020775794982910156 s
DEBUG 01-13 08:46:17.162041.162041 mlpmodule.py:1103] cpy2cputensor cost 0.0006349086761474609 s
INFO 01-13 08:46:17.183343.183343 client.py:127] Model loaded
DEBUG 01-13 08:46:17.184154.184154 cuda_h.py:19] end wait_experts cost 0.047885894775390625 seconds
DEBUG 01-13 08:46:17.184019.184019 cuda_h.py:10] start gpu_experts
DEBUG 01-13 08:46:17.184974.184974 mlpmodule.py:785]  experts func einsum cost 0.052899837493896484 s
DEBUG 01-13 08:46:17.185133.185133 cuda_h.py:19] end experts_func_gpu_einsum_mp cost 0.05384635925292969 seconds
DEBUG 01-13 08:46:17.185860.185860 mlpmodule.py:559] gpu group tensors cost 0.0006322860717773438 s
DEBUG 01-13 08:46:17.187326.187326 mlpmodule.py:592] gpu pad cost 0.0021076202392578125 s
DEBUG 01-13 08:46:17.187335.187335 mlpmodule.py:598] start_w1
DEBUG 01-13 08:46:17.188832.188832 mlpmodule.py:602] start_w3
DEBUG 01-13 08:46:17.188263.188263 mlpmodule.py:608] start_w2
DEBUG 01-13 08:46:17.188111.188111 mlpmodule.py:611] gpu group einsum cost 0.00081634521484375 s
DEBUG 01-13 08:46:17.191544.191544 mlpmodule.py:683] gpu experts func einsum cost 0.007231473922729492 s
DEBUG 01-13 08:46:17.191435.191435 cuda_h.py:19] end gpu_experts cost 0.0074269771575927734 seconds
DEBUG 01-13 08:46:17.192913.192913 cuda_h.py:10] start cpu_thread_manager_mp_wait
DEBUG 01-13 08:46:17.192968.192968 cuda_h.py:19] end cpu_thread_manager_mp_wait cost 3.981590270996094e-05 seconds
DEBUG 01-13 08:46:17.192111.192111 cuda_h.py:19] end layer_moe_generate_mp_l_8 cost 0.06517338752746582 seconds
DEBUG 01-13 08:46:17.192140.192140 lmp.py:1550] -------------------------------- end prefill layer 7 --------------------------------
DEBUG 01-13 08:46:17.192108.192108 lmp.py:1493] -------------------------------- start prefill layer 8 --------------------------------
DEBUG 01-13 08:46:17.192388.192388 cuda_h.py:10] start start_load_qkvogn_s_weight_l_9
DEBUG 01-13 08:46:17.192150.192150 cuda_h.py:10] start start_load_qkvogn_s_weight_l_9
DEBUG 01-13 08:46:17.192576.192576 cuda_h.py:19] end start_load_qkvogn_s_weight_l_9 cost 3.647804260253906e-05 seconds
DEBUG 01-13 08:46:17.192525.192525 cuda_h.py:19] end start_load_qkvogn_s_weight_l_9 cost 7.2479248046875e-05 seconds
DEBUG 01-13 08:46:17.192366.192366 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-13 08:46:17.192137.192137 cuda_h.py:10] start sllm_worker_task
DEBUG 01-13 08:46:17.192427.192427 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-13 08:46:17.192587.192587 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-13 08:46:17.193884.193884 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-13 08:46:17.193948.193948 cuda_h.py:19] end allocate_cuda_memory cost 0.0002789497375488281 seconds
DEBUG 01-13 08:46:17.193838.193838 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-13 08:46:17.193184.193184 sllm_store_c.py:27] get device uuid map
DEBUG 01-13 08:46:17.193212.193212 sllm_store_c.py:29] call client load into gpu
DEBUG 01-13 08:46:17.193690.193690 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, f1fbce47-73c4-4f24-aab1-4cce67eecb82
DEBUG 01-13 08:46:17.193171.193171 client.py:106] call stub.LoadModelAsync
DEBUG 01-13 08:46:17.194845.194845 cuda_h.py:10] start self_attn
INFO 01-13 08:46:17.195100.195100 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, f1fbce47-73c4-4f24-aab1-4cce67eecb82
DEBUG 01-13 08:46:17.195195.195195 cuda_h.py:19] end load_into_gpu_async cost 0.001901865005493164 seconds
DEBUG 01-13 08:46:17.195289.195289 cuda_h.py:10] start restore_tensors2
DEBUG 01-13 08:46:17.195783.195783 cuda_h.py:19] end restore_tensors2 cost 8.153915405273438e-05 seconds
DEBUG 01-13 08:46:17.195599.195599 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.002587556838989258 seconds
INFO 01-13 08:46:17.195654.195654 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, f1fbce47-73c4-4f24-aab1-4cce67eecb82
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-13 08:46:17.198602.198602 cuda_h.py:19] end self_attn cost 0.0039293766021728516 seconds
DEBUG 01-13 08:46:17.198560.198560 cuda_h.py:19] end iln_self_attn_paln cost 0.005761146545410156 seconds
DEBUG 01-13 08:46:17.198927.198927 cuda_h.py:10] start layer_moe_generate_mp_l_9
DEBUG 01-13 08:46:17.198312.198312 cuda_h.py:10] start gate
DEBUG 01-13 08:46:17.199030.199030 cuda_h.py:19] end gate cost 0.0008442401885986328 seconds
DEBUG 01-13 08:46:17.199337.199337 cuda_h.py:10] start experts_map_get
DEBUG 01-13 08:46:17.200484.200484 lmp.py:1611] 
DEBUG 01-13 08:46:17.200484.200484 lmp.py:1611] Expert Token Distribution & Device Allocation:
DEBUG 01-13 08:46:17.200479.200479 lmp.py:1612]   Total experts: 64
DEBUG 01-13 08:46:17.200413.200413 lmp.py:1613]   CPU experts: 32 (50%)
DEBUG 01-13 08:46:17.200394.200394 lmp.py:1614]   GPU experts: 32 (50%)
DEBUG 01-13 08:46:17.200143.200143 lmp.py:1615] 
DEBUG 01-13 08:46:17.200143.200143 lmp.py:1615]   Expert ID | Tokens | Device
DEBUG 01-13 08:46:17.200409.200409 lmp.py:1616]   -----------------------------------
DEBUG 01-13 08:46:17.200205.200205 lmp.py:1622]   Expert 38 |     15 | CPU
DEBUG 01-13 08:46:17.200040.200040 lmp.py:1622]   Expert 39 |     62 | CPU
DEBUG 01-13 08:46:17.200921.200921 lmp.py:1622]   Expert  7 |     72 | CPU
DEBUG 01-13 08:46:17.200710.200710 lmp.py:1622]   Expert 30 |     72 | CPU
DEBUG 01-13 08:46:17.200068.200068 lmp.py:1622]   Expert 24 |     85 | CPU
DEBUG 01-13 08:46:17.200188.200188 lmp.py:1622]   Expert 27 |     92 | CPU
DEBUG 01-13 08:46:17.200069.200069 lmp.py:1622]   Expert 14 |     97 | CPU
DEBUG 01-13 08:46:17.200427.200427 lmp.py:1622]   Expert 32 |     97 | CPU
DEBUG 01-13 08:46:17.200786.200786 lmp.py:1622]   Expert 36 |     97 | CPU
DEBUG 01-13 08:46:17.200667.200667 lmp.py:1622]   Expert 17 |    100 | CPU
DEBUG 01-13 08:46:17.200217.200217 lmp.py:1622]   Expert 16 |    102 | CPU
DEBUG 01-13 08:46:17.200536.200536 lmp.py:1622]   Expert 40 |    106 | CPU
DEBUG 01-13 08:46:17.200133.200133 lmp.py:1622]   Expert 18 |    115 | CPU
DEBUG 01-13 08:46:17.200551.200551 lmp.py:1622]   Expert 48 |    115 | CPU
DEBUG 01-13 08:46:17.200955.200955 lmp.py:1622]   Expert 12 |    116 | CPU
DEBUG 01-13 08:46:17.200122.200122 lmp.py:1622]   Expert  1 |    125 | CPU
DEBUG 01-13 08:46:17.200288.200288 lmp.py:1622]   Expert  6 |    130 | CPU
DEBUG 01-13 08:46:17.200977.200977 lmp.py:1622]   Expert 42 |    139 | CPU
DEBUG 01-13 08:46:17.200143.200143 lmp.py:1622]   Expert 59 |    139 | CPU
DEBUG 01-13 08:46:17.200548.200548 lmp.py:1622]   Expert 22 |    143 | CPU
DEBUG 01-13 08:46:17.200475.200475 lmp.py:1622]   Expert  0 |    146 | CPU
DEBUG 01-13 08:46:17.200403.200403 lmp.py:1622]   Expert 51 |    146 | CPU
DEBUG 01-13 08:46:17.200569.200569 lmp.py:1622]   Expert 53 |    149 | CPU
DEBUG 01-13 08:46:17.200166.200166 lmp.py:1622]   Expert  8 |    158 | CPU
DEBUG 01-13 08:46:17.200286.200286 lmp.py:1622]   Expert 60 |    160 | CPU
DEBUG 01-13 08:46:17.200406.200406 lmp.py:1622]   Expert 15 |    166 | CPU
DEBUG 01-13 08:46:17.200572.200572 lmp.py:1622]   Expert 54 |    170 | CPU
DEBUG 01-13 08:46:17.200499.200499 lmp.py:1622]   Expert 44 |    171 | CPU
DEBUG 01-13 08:46:17.200427.200427 lmp.py:1622]   Expert 29 |    173 | CPU
DEBUG 01-13 08:46:17.200116.200116 lmp.py:1622]   Expert 35 |    179 | CPU
DEBUG 01-13 08:46:17.200806.200806 lmp.py:1622]   Expert 33 |    185 | CPU
DEBUG 01-13 08:46:17.200495.200495 lmp.py:1622]   Expert 34 |    185 | CPU
DEBUG 01-13 08:46:17.200661.200661 lmp.py:1622]   Expert 47 |    187 | GPU
DEBUG 01-13 08:46:17.200827.200827 lmp.py:1622]   Expert 19 |    189 | GPU
DEBUG 01-13 08:46:17.200755.200755 lmp.py:1622]   Expert  9 |    194 | GPU
DEBUG 01-13 08:46:17.200444.200444 lmp.py:1622]   Expert 56 |    195 | GPU
DEBUG 01-13 08:46:17.200087.200087 lmp.py:1622]   Expert  3 |    196 | GPU
DEBUG 01-13 08:46:17.200446.200446 lmp.py:1622]   Expert 20 |    198 | GPU
DEBUG 01-13 08:46:17.200327.200327 lmp.py:1622]   Expert 45 |    199 | GPU
DEBUG 01-13 08:46:17.200208.200208 lmp.py:1622]   Expert 21 |    200 | GPU
DEBUG 01-13 08:46:17.200136.200136 lmp.py:1622]   Expert 28 |    200 | GPU
DEBUG 01-13 08:46:17.200302.200302 lmp.py:1622]   Expert 46 |    202 | GPU
DEBUG 01-13 08:46:17.200991.200991 lmp.py:1622]   Expert 49 |    203 | GPU
DEBUG 01-13 08:46:17.200681.200681 lmp.py:1622]   Expert 57 |    217 | GPU
DEBUG 01-13 08:46:17.200370.200370 lmp.py:1622]   Expert  4 |    224 | GPU
DEBUG 01-13 08:46:17.200298.200298 lmp.py:1622]   Expert 43 |    224 | GPU
DEBUG 01-13 08:46:17.200987.200987 lmp.py:1622]   Expert  2 |    225 | GPU
DEBUG 01-13 08:46:17.200915.200915 lmp.py:1622]   Expert 13 |    225 | GPU
DEBUG 01-13 08:46:17.201319.201319 lmp.py:1622]   Expert 41 |    237 | GPU
DEBUG 01-13 08:46:17.201485.201485 lmp.py:1622]   Expert 50 |    241 | GPU
DEBUG 01-13 08:46:17.201413.201413 lmp.py:1622]   Expert 10 |    248 | GPU
DEBUG 01-13 08:46:17.201295.201295 lmp.py:1622]   Expert 26 |    254 | GPU
DEBUG 01-13 08:46:17.201461.201461 lmp.py:1622]   Expert 37 |    260 | GPU
DEBUG 01-13 08:46:17.201388.201388 lmp.py:1622]   Expert 63 |    261 | GPU
DEBUG 01-13 08:46:17.201078.201078 lmp.py:1622]   Expert 61 |    270 | GPU
DEBUG 01-13 08:46:17.201005.201005 lmp.py:1622]   Expert 31 |    272 | GPU
DEBUG 01-13 08:46:17.201172.201172 lmp.py:1622]   Expert 52 |    303 | GPU
DEBUG 01-13 08:46:17.201623.201623 lmp.py:1622]   Expert 62 |    319 | GPU
DEBUG 01-13 08:46:17.201312.201312 lmp.py:1622]   Expert 58 |    331 | GPU
DEBUG 01-13 08:46:17.201763.201763 lmp.py:1622]   Expert 55 |    341 | GPU
DEBUG 01-13 08:46:17.201452.201452 lmp.py:1622]   Expert 23 |    378 | GPU
DEBUG 01-13 08:46:17.201380.201380 lmp.py:1622]   Expert 11 |    382 | GPU
DEBUG 01-13 08:46:17.201069.201069 lmp.py:1622]   Expert 25 |    394 | GPU
DEBUG 01-13 08:46:17.201189.201189 lmp.py:1622]   Expert  5 |    512 | GPU
DEBUG 01-13 08:46:17.201262.201262 lmp.py:1623] 
DEBUG 01-13 08:46:17.201262.201262 lmp.py:1623]   CPU total tokens: 4007 (32.6%)
DEBUG 01-13 08:46:17.201574.201574 lmp.py:1624]   GPU total tokens: 8281 (67.4%)
DEBUG 01-13 08:46:17.201939.201939 cuda_h.py:19] end experts_map_get cost 0.0017490386962890625 seconds
DEBUG 01-13 08:46:17.201842.201842 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-13 08:46:17.201168.201168 lmp.py:1632] 
DEBUG 01-13 08:46:17.201168.201168 lmp.py:1632]   Computing 32 experts on CPU MP...
DEBUG 01-13 08:46:17.201733.201733 cuda_h.py:19] end cpu_experts_submit cost 6.4849853515625e-05 seconds
DEBUG 01-13 08:46:17.201072.201072 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-13 08:46:17.201730.201730 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-13 08:46:17.201760.201760 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-13 08:46:17.202923.202923 cuda_h.py:19] end allocate_cuda_memory cost 0.0004703998565673828 seconds
DEBUG 01-13 08:46:17.202157.202157 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-13 08:46:17.202536.202536 sllm_store_c.py:27] get device uuid map
DEBUG 01-13 08:46:17.202828.202828 sllm_store_c.py:29] call client load into gpu
DEBUG 01-13 08:46:17.202339.202339 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 8c5568ad-afcb-401a-a6ee-c0ee1fee7046
DEBUG 01-13 08:46:17.202663.202663 client.py:106] call stub.LoadModelAsync
INFO 01-13 08:46:17.203024.203024 client.py:127] Model loaded
DEBUG 01-13 08:46:17.203822.203822 cuda_h.py:10] start restore2model
DEBUG 01-13 08:46:17.203812.203812 cuda_h.py:10] start experts_func_gpu_einsum_mp
DEBUG 01-13 08:46:17.203671.203671 cuda_h.py:19] end restore2model cost 0.0005693435668945312 seconds
INFO 01-13 08:46:17.203469.203469 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 8c5568ad-afcb-401a-a6ee-c0ee1fee7046
DEBUG 01-13 08:46:17.203385.203385 cuda_h.py:19] end sllm_worker_task cost 0.010988473892211914 seconds
DEBUG 01-13 08:46:17.204534.204534 cuda_h.py:19] end load_into_gpu_async cost 0.001712799072265625 seconds
DEBUG 01-13 08:46:17.204881.204881 cuda_h.py:10] start restore_tensors2
DEBUG 01-13 08:46:17.204853.204853 cuda_h.py:19] end restore_tensors2 cost 0.00033545494079589844 seconds
DEBUG 01-13 08:46:17.204299.204299 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0029227733612060547 seconds
DEBUG 01-13 08:46:17.204300.204300 cuda_h.py:10] start restore2model
DEBUG 01-13 08:46:17.207203.207203 cuda_h.py:19] end restore2model cost 0.003023862838745117 seconds
DEBUG 01-13 08:46:17.207463.207463 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.006115436553955078 seconds
DEBUG 01-13 08:46:17.207518.207518 cuda_h.py:10] start gpu_sexperts
DEBUG 01-13 08:46:17.208125.208125 cuda_h.py:19] end gpu_sexperts cost 0.0003063678741455078 seconds
DEBUG 01-13 08:46:17.208385.208385 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-13 08:46:17.208969.208969 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 1.5497207641601562e-05 seconds
DEBUG 01-13 08:46:17.208334.208334 cuda_h.py:10] start wait_experts
INFO 01-13 08:46:17.208607.208607 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 8c5568ad-afcb-401a-a6ee-c0ee1fee7046
DEBUG 01-13 08:46:17.215989.215989 mlpmodule.py:1006] group tensors cost 0.01158285140991211 s
DEBUG 01-13 08:46:17.218405.218405 mlpmodule.py:1044] pad cost 0.0015761852264404297 s
DEBUG 01-13 08:46:17.218832.218832 mlpmodule.py:1050] create cpu tensor cost 5.340576171875e-05 s
DEBUG 01-13 08:46:17.218152.218152 mlpmodule.py:1055] move to cpu cost 2.765655517578125e-05 s
DEBUG 01-13 08:46:17.227195.227195 mlpmodule.py:1069] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-13 08:46:17.228092.228092 mlpmodule.py:1070] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-13 08:46:17.228229.228229 mlpmodule.py:1075] group_w3 first element: 0.0859375
WARNING 01-13 08:46:17.228387.228387 mlpmodule.py:1085] start einsum2
DEBUG 01-13 08:46:17.241365.241365 mlpmodule.py:1095] group einsum cost 0.023078441619873047 s
DEBUG 01-13 08:46:17.242761.242761 mlpmodule.py:1103] cpy2cputensor cost 0.0006420612335205078 s
INFO 01-13 08:46:17.254105.254105 client.py:127] Model loaded
DEBUG 01-13 08:46:17.255372.255372 cuda_h.py:19] end wait_experts cost 0.046942949295043945 seconds
DEBUG 01-13 08:46:17.255070.255070 cuda_h.py:10] start gpu_experts
DEBUG 01-13 08:46:17.256980.256980 mlpmodule.py:559] gpu group tensors cost 0.0007348060607910156 s
DEBUG 01-13 08:46:17.258520.258520 mlpmodule.py:592] gpu pad cost 0.002080678939819336 s
DEBUG 01-13 08:46:17.258073.258073 mlpmodule.py:598] start_w1
DEBUG 01-13 08:46:17.259272.259272 mlpmodule.py:602] start_w3
DEBUG 01-13 08:46:17.259013.259013 mlpmodule.py:608] start_w2
DEBUG 01-13 08:46:17.259397.259397 mlpmodule.py:611] gpu group einsum cost 0.0007646083831787109 s
DEBUG 01-13 08:46:17.260904.260904 mlpmodule.py:785]  experts func einsum cost 0.056125640869140625 s
DEBUG 01-13 08:46:17.260957.260957 cuda_h.py:19] end experts_func_gpu_einsum_mp cost 0.05705571174621582 seconds
DEBUG 01-13 08:46:17.262069.262069 mlpmodule.py:683] gpu experts func einsum cost 0.006969928741455078 s
DEBUG 01-13 08:46:17.262621.262621 cuda_h.py:19] end gpu_experts cost 0.0071675777435302734 seconds
DEBUG 01-13 08:46:17.262755.262755 cuda_h.py:10] start cpu_thread_manager_mp_wait
DEBUG 01-13 08:46:17.262850.262850 cuda_h.py:19] end cpu_thread_manager_mp_wait cost 3.8623809814453125e-05 seconds
DEBUG 01-13 08:46:17.262542.262542 cuda_h.py:19] end layer_moe_generate_mp_l_9 cost 0.06422114372253418 seconds
DEBUG 01-13 08:46:17.263821.263821 lmp.py:1550] -------------------------------- end prefill layer 8 --------------------------------
DEBUG 01-13 08:46:17.263876.263876 lmp.py:1493] -------------------------------- start prefill layer 9 --------------------------------
DEBUG 01-13 08:46:17.263102.263102 cuda_h.py:10] start start_load_qkvogn_s_weight_l_10
DEBUG 01-13 08:46:17.263381.263381 cuda_h.py:10] start start_load_qkvogn_s_weight_l_10
DEBUG 01-13 08:46:17.263985.263985 cuda_h.py:19] end start_load_qkvogn_s_weight_l_10 cost 3.361701965332031e-05 seconds
DEBUG 01-13 08:46:17.263709.263709 cuda_h.py:19] end start_load_qkvogn_s_weight_l_10 cost 7.843971252441406e-05 seconds
DEBUG 01-13 08:46:17.263021.263021 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-13 08:46:17.263983.263983 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-13 08:46:17.263854.263854 cuda_h.py:10] start sllm_worker_task
DEBUG 01-13 08:46:17.263552.263552 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-13 08:46:17.263004.263004 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-13 08:46:17.263226.263226 cuda_h.py:19] end allocate_cuda_memory cost 0.0002689361572265625 seconds
DEBUG 01-13 08:46:17.263918.263918 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-13 08:46:17.264727.264727 sllm_store_c.py:27] get device uuid map
DEBUG 01-13 08:46:17.264881.264881 sllm_store_c.py:29] call client load into gpu
DEBUG 01-13 08:46:17.264061.264061 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, a1f70163-eb28-4153-86d1-e080ff5803c8
DEBUG 01-13 08:46:17.264660.264660 client.py:106] call stub.LoadModelAsync
DEBUG 01-13 08:46:17.264021.264021 cuda_h.py:10] start self_attn
INFO 01-13 08:46:17.265242.265242 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, a1f70163-eb28-4153-86d1-e080ff5803c8
DEBUG 01-13 08:46:17.265939.265939 cuda_h.py:19] end load_into_gpu_async cost 0.0013854503631591797 seconds
DEBUG 01-13 08:46:17.265735.265735 cuda_h.py:10] start restore_tensors2
DEBUG 01-13 08:46:17.265341.265341 cuda_h.py:19] end restore_tensors2 cost 6.890296936035156e-05 seconds
DEBUG 01-13 08:46:17.265951.265951 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0019812583923339844 seconds
INFO 01-13 08:46:17.265416.265416 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, a1f70163-eb28-4153-86d1-e080ff5803c8
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-13 08:46:17.267531.267531 cuda_h.py:19] end self_attn cost 0.0032956600189208984 seconds
DEBUG 01-13 08:46:17.268887.268887 cuda_h.py:19] end iln_self_attn_paln cost 0.0048906803131103516 seconds
DEBUG 01-13 08:46:17.268207.268207 cuda_h.py:10] start layer_moe_generate_mp_l_10
DEBUG 01-13 08:46:17.268162.268162 cuda_h.py:10] start gate
DEBUG 01-13 08:46:17.269069.269069 cuda_h.py:19] end gate cost 0.0007367134094238281 seconds
DEBUG 01-13 08:46:17.269137.269137 cuda_h.py:10] start experts_map_get
DEBUG 01-13 08:46:17.269808.269808 lmp.py:1611] 
DEBUG 01-13 08:46:17.269808.269808 lmp.py:1611] Expert Token Distribution & Device Allocation:
DEBUG 01-13 08:46:17.269849.269849 lmp.py:1612]   Total experts: 64
DEBUG 01-13 08:46:17.269929.269929 lmp.py:1613]   CPU experts: 32 (50%)
DEBUG 01-13 08:46:17.269194.269194 lmp.py:1614]   GPU experts: 32 (50%)
DEBUG 01-13 08:46:17.269029.269029 lmp.py:1615] 
DEBUG 01-13 08:46:17.269029.269029 lmp.py:1615]   Expert ID | Tokens | Device
DEBUG 01-13 08:46:17.269818.269818 lmp.py:1616]   -----------------------------------
DEBUG 01-13 08:46:17.269614.269614 lmp.py:1622]   Expert  2 |     43 | CPU
DEBUG 01-13 08:46:17.269210.269210 lmp.py:1622]   Expert 24 |     43 | CPU
DEBUG 01-13 08:46:17.269092.269092 lmp.py:1622]   Expert 32 |     65 | CPU
DEBUG 01-13 08:46:17.269973.269973 lmp.py:1622]   Expert 19 |     72 | CPU
DEBUG 01-13 08:46:17.269378.269378 lmp.py:1622]   Expert 26 |     74 | CPU
DEBUG 01-13 08:46:17.269782.269782 lmp.py:1622]   Expert 50 |     74 | CPU
DEBUG 01-13 08:46:17.269948.269948 lmp.py:1622]   Expert  7 |     79 | CPU
DEBUG 01-13 08:46:17.269591.269591 lmp.py:1622]   Expert 15 |     82 | CPU
DEBUG 01-13 08:46:17.269519.269519 lmp.py:1622]   Expert 59 |     83 | CPU
DEBUG 01-13 08:46:17.269685.269685 lmp.py:1622]   Expert  4 |     84 | CPU
DEBUG 01-13 08:46:17.269851.269851 lmp.py:1622]   Expert 28 |     87 | CPU
DEBUG 01-13 08:46:17.269018.269018 lmp.py:1622]   Expert 60 |     93 | CPU
DEBUG 01-13 08:46:17.269422.269422 lmp.py:1622]   Expert 49 |    101 | CPU
DEBUG 01-13 08:46:17.269257.269257 lmp.py:1622]   Expert 23 |    102 | CPU
DEBUG 01-13 08:46:17.269092.269092 lmp.py:1622]   Expert 12 |    103 | CPU
DEBUG 01-13 08:46:17.269212.269212 lmp.py:1622]   Expert  5 |    106 | CPU
DEBUG 01-13 08:46:17.270093.270093 lmp.py:1622]   Expert 10 |    107 | CPU
DEBUG 01-13 08:46:17.270213.270213 lmp.py:1622]   Expert 27 |    109 | CPU
DEBUG 01-13 08:46:17.270618.270618 lmp.py:1622]   Expert 41 |    111 | CPU
DEBUG 01-13 08:46:17.270307.270307 lmp.py:1622]   Expert  3 |    121 | CPU
DEBUG 01-13 08:46:17.270473.270473 lmp.py:1622]   Expert 16 |    123 | CPU
DEBUG 01-13 08:46:17.270785.270785 lmp.py:1622]   Expert 40 |    123 | CPU
DEBUG 01-13 08:46:17.270667.270667 lmp.py:1622]   Expert 13 |    124 | CPU
DEBUG 01-13 08:46:17.270548.270548 lmp.py:1622]   Expert 25 |    125 | CPU
DEBUG 01-13 08:46:17.270429.270429 lmp.py:1622]   Expert 20 |    127 | CPU
DEBUG 01-13 08:46:17.270549.270549 lmp.py:1622]   Expert 37 |    135 | CPU
DEBUG 01-13 08:46:17.270384.270384 lmp.py:1622]   Expert 17 |    142 | CPU
DEBUG 01-13 08:46:17.270935.270935 lmp.py:1622]   Expert 35 |    147 | CPU
DEBUG 01-13 08:46:17.270293.270293 lmp.py:1622]   Expert 47 |    153 | CPU
DEBUG 01-13 08:46:17.270651.270651 lmp.py:1622]   Expert 22 |    158 | CPU
DEBUG 01-13 08:46:17.270771.270771 lmp.py:1622]   Expert 53 |    165 | CPU
DEBUG 01-13 08:46:17.270891.270891 lmp.py:1622]   Expert 38 |    173 | CPU
DEBUG 01-13 08:46:17.270249.270249 lmp.py:1622]   Expert 39 |    173 | GPU
DEBUG 01-13 08:46:17.270607.270607 lmp.py:1622]   Expert 36 |    179 | GPU
DEBUG 01-13 08:46:17.270727.270727 lmp.py:1622]   Expert 18 |    187 | GPU
DEBUG 01-13 08:46:17.270847.270847 lmp.py:1622]   Expert 44 |    188 | GPU
DEBUG 01-13 08:46:17.270490.270490 lmp.py:1622]   Expert 52 |    188 | GPU
DEBUG 01-13 08:46:17.270133.270133 lmp.py:1622]   Expert 58 |    192 | GPU
DEBUG 01-13 08:46:17.270252.270252 lmp.py:1622]   Expert 62 |    202 | GPU
DEBUG 01-13 08:46:17.270372.270372 lmp.py:1622]   Expert 11 |    211 | GPU
DEBUG 01-13 08:46:17.270684.270684 lmp.py:1622]   Expert 48 |    212 | GPU
DEBUG 01-13 08:46:17.270281.270281 lmp.py:1622]   Expert 14 |    216 | GPU
DEBUG 01-13 08:46:17.270116.270116 lmp.py:1622]   Expert 30 |    217 | GPU
DEBUG 01-13 08:46:17.270666.270666 lmp.py:1622]   Expert  1 |    228 | GPU
DEBUG 01-13 08:46:17.270263.270263 lmp.py:1622]   Expert  6 |    233 | GPU
DEBUG 01-13 08:46:17.270906.270906 lmp.py:1622]   Expert 51 |    233 | GPU
DEBUG 01-13 08:46:17.270026.270026 lmp.py:1622]   Expert 31 |    237 | GPU
DEBUG 01-13 08:46:17.270145.270145 lmp.py:1622]   Expert 42 |    238 | GPU
DEBUG 01-13 08:46:17.270027.270027 lmp.py:1622]   Expert 45 |    240 | GPU
DEBUG 01-13 08:46:17.270624.270624 lmp.py:1622]   Expert 34 |    267 | GPU
DEBUG 01-13 08:46:17.270743.270743 lmp.py:1622]   Expert 33 |    274 | GPU
DEBUG 01-13 08:46:17.270863.270863 lmp.py:1622]   Expert 29 |    276 | GPU
DEBUG 01-13 08:46:17.270460.270460 lmp.py:1622]   Expert 57 |    294 | GPU
DEBUG 01-13 08:46:17.270533.270533 lmp.py:1622]   Expert 61 |    309 | GPU
DEBUG 01-13 08:46:17.270607.270607 lmp.py:1622]   Expert 43 |    317 | GPU
DEBUG 01-13 08:46:17.270157.270157 lmp.py:1622]   Expert  0 |    324 | GPU
DEBUG 01-13 08:46:17.270754.270754 lmp.py:1622]   Expert 46 |    347 | GPU
DEBUG 01-13 08:46:17.270874.270874 lmp.py:1622]   Expert  8 |    375 | GPU
DEBUG 01-13 08:46:17.270993.270993 lmp.py:1622]   Expert  9 |    392 | GPU
DEBUG 01-13 08:46:17.270113.270113 lmp.py:1622]   Expert 54 |    397 | GPU
DEBUG 01-13 08:46:17.270233.270233 lmp.py:1622]   Expert 56 |    401 | GPU
DEBUG 01-13 08:46:17.270591.270591 lmp.py:1622]   Expert 55 |    410 | GPU
DEBUG 01-13 08:46:17.270473.270473 lmp.py:1622]   Expert 63 |    414 | GPU
DEBUG 01-13 08:46:17.270592.270592 lmp.py:1622]   Expert 21 |    483 | GPU
DEBUG 01-13 08:46:17.270620.270620 lmp.py:1623] 
DEBUG 01-13 08:46:17.270620.270620 lmp.py:1623]   CPU total tokens: 3434 (27.9%)
DEBUG 01-13 08:46:17.270408.270408 lmp.py:1624]   GPU total tokens: 8854 (72.1%)
DEBUG 01-13 08:46:17.270442.270442 cuda_h.py:19] end experts_map_get cost 0.001775503158569336 seconds
DEBUG 01-13 08:46:17.271729.271729 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-13 08:46:17.271009.271009 lmp.py:1632] 
DEBUG 01-13 08:46:17.271009.271009 lmp.py:1632]   Computing 32 experts on CPU MP...
DEBUG 01-13 08:46:17.271891.271891 cuda_h.py:19] end cpu_experts_submit cost 5.030632019042969e-05 seconds
DEBUG 01-13 08:46:17.271541.271541 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-13 08:46:17.271847.271847 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-13 08:46:17.271454.271454 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-13 08:46:17.272247.272247 cuda_h.py:19] end allocate_cuda_memory cost 0.0012853145599365234 seconds
DEBUG 01-13 08:46:17.272481.272481 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-13 08:46:17.272767.272767 sllm_store_c.py:27] get device uuid map
DEBUG 01-13 08:46:17.272106.272106 sllm_store_c.py:29] call client load into gpu
DEBUG 01-13 08:46:17.272378.272378 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, c70fbf80-6700-4852-9100-a6f84726ef67
DEBUG 01-13 08:46:17.272755.272755 client.py:106] call stub.LoadModelAsync
INFO 01-13 08:46:17.273772.273772 client.py:127] Model loaded
DEBUG 01-13 08:46:17.273284.273284 cuda_h.py:10] start restore2model
DEBUG 01-13 08:46:17.273800.273800 cuda_h.py:10] start experts_func_gpu_einsum_mp
DEBUG 01-13 08:46:17.273120.273120 cuda_h.py:19] end restore2model cost 0.00039958953857421875 seconds
DEBUG 01-13 08:46:17.274280.274280 cuda_h.py:19] end sllm_worker_task cost 0.010480403900146484 seconds
INFO 01-13 08:46:17.274595.274595 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, c70fbf80-6700-4852-9100-a6f84726ef67
DEBUG 01-13 08:46:17.274113.274113 cuda_h.py:19] end load_into_gpu_async cost 0.0014481544494628906 seconds
DEBUG 01-13 08:46:17.274201.274201 cuda_h.py:10] start restore_tensors2
DEBUG 01-13 08:46:17.274782.274782 cuda_h.py:19] end restore_tensors2 cost 0.0003306865692138672 seconds
DEBUG 01-13 08:46:17.274095.274095 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.003422260284423828 seconds
DEBUG 01-13 08:46:17.274573.274573 cuda_h.py:10] start restore2model
DEBUG 01-13 08:46:17.277189.277189 cuda_h.py:19] end restore2model cost 0.003125905990600586 seconds
DEBUG 01-13 08:46:17.277217.277217 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.006724834442138672 seconds
DEBUG 01-13 08:46:17.277966.277966 cuda_h.py:10] start gpu_sexperts
DEBUG 01-13 08:46:17.278197.278197 cuda_h.py:19] end gpu_sexperts cost 0.0003046989440917969 seconds
DEBUG 01-13 08:46:17.278503.278503 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-13 08:46:17.278564.278564 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 1.52587890625e-05 seconds
DEBUG 01-13 08:46:17.278737.278737 cuda_h.py:10] start wait_experts
INFO 01-13 08:46:17.278056.278056 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, c70fbf80-6700-4852-9100-a6f84726ef67
DEBUG 01-13 08:46:17.278504.278504 mlpmodule.py:1006] group tensors cost 0.004489898681640625 s
DEBUG 01-13 08:46:17.281121.281121 mlpmodule.py:1044] pad cost 0.0016949176788330078 s
DEBUG 01-13 08:46:17.281634.281634 mlpmodule.py:1050] create cpu tensor cost 4.124641418457031e-05 s
DEBUG 01-13 08:46:17.281915.281915 mlpmodule.py:1055] move to cpu cost 3.0040740966796875e-05 s
DEBUG 01-13 08:46:17.289363.289363 mlpmodule.py:1069] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-13 08:46:17.289783.289783 mlpmodule.py:1070] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-13 08:46:17.289059.289059 mlpmodule.py:1075] group_w3 first element: 0.0157470703125
WARNING 01-13 08:46:17.289064.289064 mlpmodule.py:1085] start einsum2
DEBUG 01-13 08:46:17.303827.303827 mlpmodule.py:1095] group einsum cost 0.02260899543762207 s
DEBUG 01-13 08:46:17.304084.304084 mlpmodule.py:1103] cpy2cputensor cost 0.0006499290466308594 s
INFO 01-13 08:46:17.326879.326879 client.py:127] Model loaded
DEBUG 01-13 08:46:17.326199.326199 cuda_h.py:19] end wait_experts cost 0.04795527458190918 seconds
DEBUG 01-13 08:46:17.326103.326103 cuda_h.py:10] start gpu_experts
DEBUG 01-13 08:46:17.327666.327666 mlpmodule.py:785]  experts func einsum cost 0.0532534122467041 s
DEBUG 01-13 08:46:17.328666.328666 cuda_h.py:19] end experts_func_gpu_einsum_mp cost 0.05408787727355957 seconds
DEBUG 01-13 08:46:17.328229.328229 mlpmodule.py:559] gpu group tensors cost 0.0015399456024169922 s
DEBUG 01-13 08:46:17.333674.333674 mlpmodule.py:592] gpu pad cost 0.004609584808349609 s
DEBUG 01-13 08:46:17.333945.333945 mlpmodule.py:598] start_w1
DEBUG 01-13 08:46:17.333234.333234 mlpmodule.py:602] start_w3
DEBUG 01-13 08:46:17.334600.334600 mlpmodule.py:608] start_w2
DEBUG 01-13 08:46:17.334781.334781 mlpmodule.py:611] gpu group einsum cost 0.0016312599182128906 s
DEBUG 01-13 08:46:17.339061.339061 mlpmodule.py:683] gpu experts func einsum cost 0.012740373611450195 s
DEBUG 01-13 08:46:17.339733.339733 cuda_h.py:19] end gpu_experts cost 0.013000726699829102 seconds
DEBUG 01-13 08:46:17.339211.339211 cuda_h.py:10] start cpu_thread_manager_mp_wait
DEBUG 01-13 08:46:17.339029.339029 cuda_h.py:19] end cpu_thread_manager_mp_wait cost 5.7220458984375e-05 seconds
DEBUG 01-13 08:46:17.339384.339384 cuda_h.py:19] end layer_moe_generate_mp_l_10 cost 0.07151198387145996 seconds
DEBUG 01-13 08:46:17.340807.340807 lmp.py:1550] -------------------------------- end prefill layer 9 --------------------------------
DEBUG 01-13 08:46:17.340636.340636 lmp.py:1493] -------------------------------- start prefill layer 10 --------------------------------
DEBUG 01-13 08:46:17.340161.340161 cuda_h.py:10] start start_load_qkvogn_s_weight_l_11
DEBUG 01-13 08:46:17.340738.340738 cuda_h.py:10] start start_load_qkvogn_s_weight_l_11
DEBUG 01-13 08:46:17.340986.340986 cuda_h.py:19] end start_load_qkvogn_s_weight_l_11 cost 4.363059997558594e-05 seconds
DEBUG 01-13 08:46:17.340139.340139 cuda_h.py:19] end start_load_qkvogn_s_weight_l_11 cost 9.107589721679688e-05 seconds
DEBUG 01-13 08:46:17.340226.340226 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-13 08:46:17.340072.340072 cuda_h.py:10] start sllm_worker_task
DEBUG 01-13 08:46:17.340776.340776 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-13 08:46:17.340892.340892 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-13 08:46:17.341939.341939 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-13 08:46:17.341820.341820 cuda_h.py:19] end allocate_cuda_memory cost 0.0003228187561035156 seconds
DEBUG 01-13 08:46:17.341472.341472 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-13 08:46:17.341725.341725 sllm_store_c.py:27] get device uuid map
DEBUG 01-13 08:46:17.341476.341476 sllm_store_c.py:29] call client load into gpu
DEBUG 01-13 08:46:17.341146.341146 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 4f0690fb-e34e-48fa-abbf-1d810c50c258
DEBUG 01-13 08:46:17.341978.341978 client.py:106] call stub.LoadModelAsync
DEBUG 01-13 08:46:17.342308.342308 cuda_h.py:10] start self_attn
INFO 01-13 08:46:17.343456.343456 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 4f0690fb-e34e-48fa-abbf-1d810c50c258
DEBUG 01-13 08:46:17.343633.343633 cuda_h.py:19] end load_into_gpu_async cost 0.0021750926971435547 seconds
DEBUG 01-13 08:46:17.343402.343402 cuda_h.py:10] start restore_tensors2
DEBUG 01-13 08:46:17.344479.344479 cuda_h.py:19] end restore_tensors2 cost 9.179115295410156e-05 seconds
DEBUG 01-13 08:46:17.344295.344295 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0029659271240234375 seconds
INFO 01-13 08:46:17.344934.344934 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 4f0690fb-e34e-48fa-abbf-1d810c50c258
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-13 08:46:17.347779.347779 cuda_h.py:19] end self_attn cost 0.005048990249633789 seconds
DEBUG 01-13 08:46:17.347670.347670 cuda_h.py:19] end iln_self_attn_paln cost 0.007482290267944336 seconds
DEBUG 01-13 08:46:17.348627.348627 cuda_h.py:10] start layer_moe_generate_mp_l_11
DEBUG 01-13 08:46:17.348403.348403 cuda_h.py:10] start gate
DEBUG 01-13 08:46:17.349448.349448 cuda_h.py:19] end gate cost 0.0008993148803710938 seconds
DEBUG 01-13 08:46:17.349814.349814 cuda_h.py:10] start experts_map_get
DEBUG 01-13 08:46:17.349185.349185 lmp.py:1611] 
DEBUG 01-13 08:46:17.349185.349185 lmp.py:1611] Expert Token Distribution & Device Allocation:
DEBUG 01-13 08:46:17.349524.349524 lmp.py:1612]   Total experts: 64
DEBUG 01-13 08:46:17.349280.349280 lmp.py:1613]   CPU experts: 32 (50%)
DEBUG 01-13 08:46:17.349983.349983 lmp.py:1614]   GPU experts: 32 (50%)
DEBUG 01-13 08:46:17.349586.349586 lmp.py:1615] 
DEBUG 01-13 08:46:17.349586.349586 lmp.py:1615]   Expert ID | Tokens | Device
DEBUG 01-13 08:46:17.349905.349905 lmp.py:1616]   -----------------------------------
DEBUG 01-13 08:46:17.349184.349184 lmp.py:1622]   Expert 43 |     18 | CPU
DEBUG 01-13 08:46:17.349787.349787 lmp.py:1622]   Expert 27 |     34 | CPU
DEBUG 01-13 08:46:17.349199.349199 lmp.py:1622]   Expert 34 |     51 | CPU
DEBUG 01-13 08:46:17.349372.349372 lmp.py:1622]   Expert 56 |     53 | CPU
DEBUG 01-13 08:46:17.349068.349068 lmp.py:1622]   Expert  3 |     57 | CPU
DEBUG 01-13 08:46:17.349241.349241 lmp.py:1622]   Expert 26 |     57 | CPU
DEBUG 01-13 08:46:17.349414.349414 lmp.py:1622]   Expert  4 |     70 | CPU
DEBUG 01-13 08:46:17.350587.350587 lmp.py:1622]   Expert 61 |     76 | CPU
DEBUG 01-13 08:46:17.350429.350429 lmp.py:1622]   Expert 14 |     88 | CPU
DEBUG 01-13 08:46:17.350270.350270 lmp.py:1622]   Expert 38 |    100 | CPU
DEBUG 01-13 08:46:17.350443.350443 lmp.py:1622]   Expert  2 |    114 | CPU
DEBUG 01-13 08:46:17.350616.350616 lmp.py:1622]   Expert 17 |    118 | CPU
DEBUG 01-13 08:46:17.350074.350074 lmp.py:1622]   Expert 22 |    121 | CPU
DEBUG 01-13 08:46:17.350770.350770 lmp.py:1622]   Expert 37 |    127 | CPU
DEBUG 01-13 08:46:17.350466.350466 lmp.py:1622]   Expert 54 |    131 | CPU
DEBUG 01-13 08:46:17.350401.350401 lmp.py:1622]   Expert 47 |    132 | CPU
DEBUG 01-13 08:46:17.350097.350097 lmp.py:1622]   Expert 55 |    132 | CPU
DEBUG 01-13 08:46:17.350793.350793 lmp.py:1622]   Expert 28 |    135 | CPU
DEBUG 01-13 08:46:17.350919.350919 lmp.py:1622]   Expert 15 |    140 | CPU
DEBUG 01-13 08:46:17.350284.350284 lmp.py:1622]   Expert 60 |    140 | CPU
DEBUG 01-13 08:46:17.350411.350411 lmp.py:1622]   Expert 51 |    145 | CPU
DEBUG 01-13 08:46:17.350822.350822 lmp.py:1622]   Expert 45 |    146 | CPU
DEBUG 01-13 08:46:17.350518.350518 lmp.py:1622]   Expert  7 |    149 | CPU
DEBUG 01-13 08:46:17.350738.350738 lmp.py:1622]   Expert 12 |    149 | CPU
DEBUG 01-13 08:46:17.350434.350434 lmp.py:1622]   Expert 63 |    150 | CPU
DEBUG 01-13 08:46:17.350368.350368 lmp.py:1622]   Expert  5 |    153 | CPU
DEBUG 01-13 08:46:17.350064.350064 lmp.py:1622]   Expert 48 |    155 | CPU
DEBUG 01-13 08:46:17.350999.350999 lmp.py:1622]   Expert 19 |    161 | CPU
DEBUG 01-13 08:46:17.350887.350887 lmp.py:1622]   Expert  6 |    165 | CPU
DEBUG 01-13 08:46:17.350729.350729 lmp.py:1622]   Expert 52 |    165 | CPU
DEBUG 01-13 08:46:17.350425.350425 lmp.py:1622]   Expert 18 |    176 | CPU
DEBUG 01-13 08:46:17.350883.350883 lmp.py:1622]   Expert 57 |    179 | CPU
DEBUG 01-13 08:46:17.350340.350340 lmp.py:1622]   Expert 31 |    182 | GPU
DEBUG 01-13 08:46:17.350036.350036 lmp.py:1622]   Expert 50 |    182 | GPU
DEBUG 01-13 08:46:17.350971.350971 lmp.py:1622]   Expert 44 |    183 | GPU
DEBUG 01-13 08:46:17.350667.350667 lmp.py:1622]   Expert 13 |    185 | GPU
DEBUG 01-13 08:46:17.350125.350125 lmp.py:1622]   Expert 30 |    186 | GPU
DEBUG 01-13 08:46:17.350536.350536 lmp.py:1622]   Expert 20 |    189 | GPU
DEBUG 01-13 08:46:17.350424.350424 lmp.py:1622]   Expert 59 |    189 | GPU
DEBUG 01-13 08:46:17.350028.350028 lmp.py:1622]   Expert 23 |    194 | GPU
DEBUG 01-13 08:46:17.350870.350870 lmp.py:1622]   Expert 29 |    194 | GPU
DEBUG 01-13 08:46:17.350566.350566 lmp.py:1622]   Expert 53 |    197 | GPU
DEBUG 01-13 08:46:17.350500.350500 lmp.py:1622]   Expert 39 |    199 | GPU
DEBUG 01-13 08:46:17.350958.350958 lmp.py:1622]   Expert 16 |    203 | GPU
DEBUG 01-13 08:46:17.350415.350415 lmp.py:1622]   Expert 21 |    204 | GPU
DEBUG 01-13 08:46:17.350588.350588 lmp.py:1622]   Expert 36 |    210 | GPU
DEBUG 01-13 08:46:17.350285.350285 lmp.py:1622]   Expert 41 |    210 | GPU
DEBUG 01-13 08:46:17.350981.350981 lmp.py:1622]   Expert 49 |    217 | GPU
DEBUG 01-13 08:46:17.350677.350677 lmp.py:1622]   Expert 25 |    219 | GPU
DEBUG 01-13 08:46:17.350803.350803 lmp.py:1622]   Expert 32 |    221 | GPU
DEBUG 01-13 08:46:17.350930.350930 lmp.py:1622]   Expert 46 |    232 | GPU
DEBUG 01-13 08:46:17.350103.350103 lmp.py:1622]   Expert  8 |    244 | GPU
DEBUG 01-13 08:46:17.351799.351799 lmp.py:1622]   Expert 10 |    250 | GPU
DEBUG 01-13 08:46:17.351257.351257 lmp.py:1622]   Expert 62 |    252 | GPU
DEBUG 01-13 08:46:17.351714.351714 lmp.py:1622]   Expert 42 |    262 | GPU
DEBUG 01-13 08:46:17.351410.351410 lmp.py:1622]   Expert 35 |    277 | GPU
DEBUG 01-13 08:46:17.351868.351868 lmp.py:1622]   Expert  9 |    288 | GPU
DEBUG 01-13 08:46:17.351326.351326 lmp.py:1622]   Expert 33 |    298 | GPU
DEBUG 01-13 08:46:17.351929.351929 lmp.py:1622]   Expert 58 |    316 | GPU
DEBUG 01-13 08:46:17.351533.351533 lmp.py:1622]   Expert 40 |    392 | GPU
DEBUG 01-13 08:46:17.351705.351705 lmp.py:1622]   Expert  0 |    432 | GPU
DEBUG 01-13 08:46:17.351925.351925 lmp.py:1622]   Expert 11 |    459 | GPU
DEBUG 01-13 08:46:17.351621.351621 lmp.py:1622]   Expert 24 |    563 | GPU
DEBUG 01-13 08:46:17.351555.351555 lmp.py:1622]   Expert  1 |    672 | GPU
DEBUG 01-13 08:46:17.351205.351205 lmp.py:1623] 
DEBUG 01-13 08:46:17.351205.351205 lmp.py:1623]   CPU total tokens: 3787 (30.8%)
DEBUG 01-13 08:46:17.351809.351809 lmp.py:1624]   GPU total tokens: 8501 (69.2%)
DEBUG 01-13 08:46:17.351372.351372 cuda_h.py:19] end experts_map_get cost 0.002201557159423828 seconds
DEBUG 01-13 08:46:17.351442.351442 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-13 08:46:17.351251.351251 lmp.py:1632] 
DEBUG 01-13 08:46:17.351251.351251 lmp.py:1632]   Computing 32 experts on CPU MP...
DEBUG 01-13 08:46:17.351293.351293 cuda_h.py:19] end cpu_experts_submit cost 6.508827209472656e-05 seconds
DEBUG 01-13 08:46:17.351234.351234 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-13 08:46:17.351614.351614 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-13 08:46:17.351956.351956 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-13 08:46:17.352158.352158 cuda_h.py:19] end allocate_cuda_memory cost 0.0002472400665283203 seconds
DEBUG 01-13 08:46:17.352399.352399 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-13 08:46:17.352261.352261 sllm_store_c.py:27] get device uuid map
DEBUG 01-13 08:46:17.352561.352561 sllm_store_c.py:29] call client load into gpu
DEBUG 01-13 08:46:17.352409.352409 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 33e04588-d404-4f11-9cc9-09094161edcc
DEBUG 01-13 08:46:17.352039.352039 client.py:106] call stub.LoadModelAsync
INFO 01-13 08:46:17.353978.353978 client.py:127] Model loaded
DEBUG 01-13 08:46:17.353418.353418 cuda_h.py:10] start restore2model
DEBUG 01-13 08:46:17.353246.353246 cuda_h.py:19] end restore2model cost 0.0005571842193603516 seconds
DEBUG 01-13 08:46:17.353811.353811 cuda_h.py:19] end sllm_worker_task cost 0.012854576110839844 seconds
DEBUG 01-13 08:46:17.354452.354452 cuda_h.py:10] start experts_func_gpu_einsum_mp
INFO 01-13 08:46:17.354311.354311 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 33e04588-d404-4f11-9cc9-09094161edcc
DEBUG 01-13 08:46:17.354836.354836 cuda_h.py:19] end load_into_gpu_async cost 0.0021414756774902344 seconds
DEBUG 01-13 08:46:17.354738.354738 cuda_h.py:10] start restore_tensors2
DEBUG 01-13 08:46:17.354118.354118 cuda_h.py:19] end restore_tensors2 cost 0.00042247772216796875 seconds
DEBUG 01-13 08:46:17.354046.354046 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.003201723098754883 seconds
DEBUG 01-13 08:46:17.354485.354485 cuda_h.py:10] start restore2model
DEBUG 01-13 08:46:17.358715.358715 cuda_h.py:19] end restore2model cost 0.003678560256958008 seconds
DEBUG 01-13 08:46:17.358274.358274 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.007092475891113281 seconds
DEBUG 01-13 08:46:17.358553.358553 cuda_h.py:10] start gpu_sexperts
DEBUG 01-13 08:46:17.359441.359441 cuda_h.py:19] end gpu_sexperts cost 0.00037026405334472656 seconds
DEBUG 01-13 08:46:17.359092.359092 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-13 08:46:17.359842.359842 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 1.6450881958007812e-05 seconds
DEBUG 01-13 08:46:17.359446.359446 cuda_h.py:10] start wait_experts
INFO 01-13 08:46:17.359718.359718 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 33e04588-d404-4f11-9cc9-09094161edcc
DEBUG 01-13 08:46:17.371043.371043 mlpmodule.py:1006] group tensors cost 0.01568889617919922 s
DEBUG 01-13 08:46:17.373037.373037 mlpmodule.py:1044] pad cost 0.0016779899597167969 s
DEBUG 01-13 08:46:17.373127.373127 mlpmodule.py:1050] create cpu tensor cost 4.172325134277344e-05 s
DEBUG 01-13 08:46:17.373361.373361 mlpmodule.py:1055] move to cpu cost 3.0517578125e-05 s
DEBUG 01-13 08:46:17.384253.384253 mlpmodule.py:1069] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-13 08:46:17.384236.384236 mlpmodule.py:1070] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-13 08:46:17.384697.384697 mlpmodule.py:1075] group_w3 first element: -0.0213623046875
WARNING 01-13 08:46:17.385596.385596 mlpmodule.py:1085] start einsum2
DEBUG 01-13 08:46:17.398305.398305 mlpmodule.py:1095] group einsum cost 0.024347782135009766 s
DEBUG 01-13 08:46:17.399453.399453 mlpmodule.py:1103] cpy2cputensor cost 0.0006508827209472656 s
INFO 01-13 08:46:17.407813.407813 client.py:127] Model loaded
DEBUG 01-13 08:46:17.407733.407733 cuda_h.py:19] end wait_experts cost 0.04868435859680176 seconds
DEBUG 01-13 08:46:17.408218.408218 cuda_h.py:10] start gpu_experts
DEBUG 01-13 08:46:17.409175.409175 mlpmodule.py:559] gpu group tensors cost 0.0009570121765136719 s
DEBUG 01-13 08:46:17.411526.411526 mlpmodule.py:592] gpu pad cost 0.0019030570983886719 s
DEBUG 01-13 08:46:17.411118.411118 mlpmodule.py:598] start_w1
DEBUG 01-13 08:46:17.411545.411545 mlpmodule.py:602] start_w3
DEBUG 01-13 08:46:17.411129.411129 mlpmodule.py:608] start_w2
DEBUG 01-13 08:46:17.412778.412778 mlpmodule.py:611] gpu group einsum cost 0.0009050369262695312 s
DEBUG 01-13 08:46:17.414482.414482 mlpmodule.py:683] gpu experts func einsum cost 0.006559848785400391 s
DEBUG 01-13 08:46:17.414890.414890 cuda_h.py:19] end gpu_experts cost 0.006784677505493164 seconds
DEBUG 01-13 08:46:17.414738.414738 cuda_h.py:10] start cpu_thread_manager_mp_wait
DEBUG 01-13 08:46:17.414338.414338 cuda_h.py:19] end cpu_thread_manager_mp_wait cost 6.0558319091796875e-05 seconds
DEBUG 01-13 08:46:17.415937.415937 cuda_h.py:19] end layer_moe_generate_mp_l_11 cost 0.06697225570678711 seconds
DEBUG 01-13 08:46:17.415907.415907 lmp.py:1550] -------------------------------- end prefill layer 10 --------------------------------
DEBUG 01-13 08:46:17.415961.415961 lmp.py:1493] -------------------------------- start prefill layer 11 --------------------------------
DEBUG 01-13 08:46:17.415710.415710 cuda_h.py:10] start start_load_qkvogn_s_weight_l_12
DEBUG 01-13 08:46:17.415705.415705 cuda_h.py:10] start start_load_qkvogn_s_weight_l_12
DEBUG 01-13 08:46:17.415184.415184 cuda_h.py:19] end start_load_qkvogn_s_weight_l_12 cost 4.8160552978515625e-05 seconds
DEBUG 01-13 08:46:17.415026.415026 cuda_h.py:19] end start_load_qkvogn_s_weight_l_12 cost 7.534027099609375e-05 seconds
DEBUG 01-13 08:46:17.415384.415384 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-13 08:46:17.415672.415672 cuda_h.py:10] start sllm_worker_task
DEBUG 01-13 08:46:17.415659.415659 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-13 08:46:17.415523.415523 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-13 08:46:17.416158.416158 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-13 08:46:17.416224.416224 cuda_h.py:19] end allocate_cuda_memory cost 0.0003514289855957031 seconds
DEBUG 01-13 08:46:17.416856.416856 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-13 08:46:17.416242.416242 sllm_store_c.py:27] get device uuid map
DEBUG 01-13 08:46:17.416502.416502 sllm_store_c.py:29] call client load into gpu
DEBUG 01-13 08:46:17.416589.416589 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 36bb8d46-d73d-4aff-8829-758ab778bfbc
DEBUG 01-13 08:46:17.416884.416884 client.py:106] call stub.LoadModelAsync
DEBUG 01-13 08:46:17.417493.417493 cuda_h.py:10] start self_attn
INFO 01-13 08:46:17.417662.417662 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 36bb8d46-d73d-4aff-8829-758ab778bfbc
DEBUG 01-13 08:46:17.418699.418699 cuda_h.py:19] end load_into_gpu_async cost 0.0013775825500488281 seconds
DEBUG 01-13 08:46:17.418190.418190 cuda_h.py:10] start restore_tensors2
DEBUG 01-13 08:46:17.418247.418247 cuda_h.py:19] end restore_tensors2 cost 8.20159912109375e-05 seconds
DEBUG 01-13 08:46:17.418195.418195 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0021317005157470703 seconds
INFO 01-13 08:46:17.418747.418747 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 36bb8d46-d73d-4aff-8829-758ab778bfbc
DEBUG 01-13 08:46:17.420941.420941 mlpmodule.py:785]  experts func einsum cost 0.06469917297363281 s
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-13 08:46:17.420335.420335 cuda_h.py:19] end self_attn cost 0.0035195350646972656 seconds
DEBUG 01-13 08:46:17.420291.420291 cuda_h.py:19] end experts_func_gpu_einsum_mp cost 0.0666511058807373 seconds
DEBUG 01-13 08:46:17.421995.421995 cuda_h.py:19] end iln_self_attn_paln cost 0.005544900894165039 seconds
DEBUG 01-13 08:46:17.421150.421150 cuda_h.py:10] start layer_moe_generate_mp_l_12
DEBUG 01-13 08:46:17.421820.421820 cuda_h.py:10] start gate
DEBUG 01-13 08:46:17.422553.422553 cuda_h.py:19] end gate cost 0.001085519790649414 seconds
DEBUG 01-13 08:46:17.422298.422298 cuda_h.py:10] start experts_map_get
DEBUG 01-13 08:46:17.423767.423767 lmp.py:1611] 
DEBUG 01-13 08:46:17.423767.423767 lmp.py:1611] Expert Token Distribution & Device Allocation:
DEBUG 01-13 08:46:17.423768.423768 lmp.py:1612]   Total experts: 64
DEBUG 01-13 08:46:17.423233.423233 lmp.py:1613]   CPU experts: 32 (50%)
DEBUG 01-13 08:46:17.423929.423929 lmp.py:1614]   GPU experts: 32 (50%)
DEBUG 01-13 08:46:17.423002.423002 lmp.py:1615] 
DEBUG 01-13 08:46:17.423002.423002 lmp.py:1615]   Expert ID | Tokens | Device
DEBUG 01-13 08:46:17.423029.423029 lmp.py:1616]   -----------------------------------
DEBUG 01-13 08:46:17.423017.423017 lmp.py:1622]   Expert 39 |     18 | CPU
DEBUG 01-13 08:46:17.423090.423090 lmp.py:1622]   Expert 13 |     25 | CPU
DEBUG 01-13 08:46:17.423925.423925 lmp.py:1622]   Expert 49 |     38 | CPU
DEBUG 01-13 08:46:17.423045.423045 lmp.py:1622]   Expert 35 |     47 | CPU
DEBUG 01-13 08:46:17.423165.423165 lmp.py:1622]   Expert 19 |     59 | CPU
DEBUG 01-13 08:46:17.423523.423523 lmp.py:1622]   Expert 32 |     77 | CPU
DEBUG 01-13 08:46:17.423166.423166 lmp.py:1622]   Expert 41 |     77 | CPU
DEBUG 01-13 08:46:17.423763.423763 lmp.py:1622]   Expert 26 |     78 | CPU
DEBUG 01-13 08:46:17.423883.423883 lmp.py:1622]   Expert 46 |     79 | CPU
DEBUG 01-13 08:46:17.423003.423003 lmp.py:1622]   Expert 33 |     80 | CPU
DEBUG 01-13 08:46:17.423030.423030 lmp.py:1622]   Expert 31 |     81 | CPU
DEBUG 01-13 08:46:17.423057.423057 lmp.py:1622]   Expert 23 |     83 | CPU
DEBUG 01-13 08:46:17.423654.423654 lmp.py:1622]   Expert  9 |     88 | CPU
DEBUG 01-13 08:46:17.423489.423489 lmp.py:1622]   Expert 18 |     94 | CPU
DEBUG 01-13 08:46:17.423370.423370 lmp.py:1622]   Expert 38 |     96 | CPU
DEBUG 01-13 08:46:17.423251.423251 lmp.py:1622]   Expert  6 |    105 | CPU
DEBUG 01-13 08:46:17.423133.423133 lmp.py:1622]   Expert 17 |    109 | CPU
DEBUG 01-13 08:46:17.423537.423537 lmp.py:1622]   Expert  3 |    112 | CPU
DEBUG 01-13 08:46:17.423419.423419 lmp.py:1622]   Expert 20 |    118 | CPU
DEBUG 01-13 08:46:17.423062.423062 lmp.py:1622]   Expert 59 |    122 | CPU
DEBUG 01-13 08:46:17.423420.423420 lmp.py:1622]   Expert 16 |    128 | CPU
DEBUG 01-13 08:46:17.423063.423063 lmp.py:1622]   Expert 61 |    130 | CPU
DEBUG 01-13 08:46:17.423706.423706 lmp.py:1622]   Expert 62 |    131 | CPU
DEBUG 01-13 08:46:17.423448.423448 lmp.py:1622]   Expert 40 |    133 | CPU
DEBUG 01-13 08:46:17.423807.423807 lmp.py:1622]   Expert 43 |    134 | CPU
DEBUG 01-13 08:46:17.423450.423450 lmp.py:1622]   Expert 15 |    136 | CPU
DEBUG 01-13 08:46:17.423093.423093 lmp.py:1622]   Expert 42 |    137 | CPU
DEBUG 01-13 08:46:17.423259.423259 lmp.py:1622]   Expert  2 |    140 | CPU
DEBUG 01-13 08:46:17.423186.423186 lmp.py:1622]   Expert 50 |    140 | CPU
DEBUG 01-13 08:46:17.423114.423114 lmp.py:1622]   Expert 63 |    141 | CPU
DEBUG 01-13 08:46:17.423042.423042 lmp.py:1622]   Expert 44 |    142 | CPU
DEBUG 01-13 08:46:17.423970.423970 lmp.py:1622]   Expert 36 |    146 | CPU
DEBUG 01-13 08:46:17.423659.423659 lmp.py:1622]   Expert 10 |    160 | GPU
DEBUG 01-13 08:46:17.423587.423587 lmp.py:1622]   Expert  5 |    181 | GPU
DEBUG 01-13 08:46:17.423753.423753 lmp.py:1622]   Expert 34 |    183 | GPU
DEBUG 01-13 08:46:17.423680.423680 lmp.py:1622]   Expert 27 |    185 | GPU
DEBUG 01-13 08:46:17.423608.423608 lmp.py:1622]   Expert 45 |    188 | GPU
DEBUG 01-13 08:46:17.423297.423297 lmp.py:1622]   Expert 52 |    191 | GPU
DEBUG 01-13 08:46:17.423464.423464 lmp.py:1622]   Expert 60 |    198 | GPU
DEBUG 01-13 08:46:17.423868.423868 lmp.py:1622]   Expert 48 |    202 | GPU
DEBUG 01-13 08:46:17.423988.423988 lmp.py:1622]   Expert 51 |    211 | GPU
DEBUG 01-13 08:46:17.423631.423631 lmp.py:1622]   Expert 56 |    218 | GPU
DEBUG 01-13 08:46:17.423797.423797 lmp.py:1622]   Expert  7 |    226 | GPU
DEBUG 01-13 08:46:17.423248.423248 lmp.py:1622]   Expert  8 |    232 | GPU
DEBUG 01-13 08:46:17.423176.423176 lmp.py:1622]   Expert 24 |    233 | GPU
DEBUG 01-13 08:46:17.423627.423627 lmp.py:1622]   Expert 53 |    234 | GPU
DEBUG 01-13 08:46:17.424554.424554 lmp.py:1622]   Expert 57 |    249 | GPU
DEBUG 01-13 08:46:17.424482.424482 lmp.py:1622]   Expert 47 |    251 | GPU
DEBUG 01-13 08:46:17.424171.424171 lmp.py:1622]   Expert 29 |    255 | GPU
DEBUG 01-13 08:46:17.424861.424861 lmp.py:1622]   Expert 21 |    266 | GPU
DEBUG 01-13 08:46:17.424027.424027 lmp.py:1622]   Expert  4 |    276 | GPU
DEBUG 01-13 08:46:17.424147.424147 lmp.py:1622]   Expert  0 |    280 | GPU
DEBUG 01-13 08:46:17.424789.424789 lmp.py:1622]   Expert 14 |    296 | GPU
DEBUG 01-13 08:46:17.424432.424432 lmp.py:1622]   Expert 22 |    310 | GPU
DEBUG 01-13 08:46:17.424837.424837 lmp.py:1622]   Expert 55 |    319 | GPU
DEBUG 01-13 08:46:17.424765.424765 lmp.py:1622]   Expert 37 |    323 | GPU
DEBUG 01-13 08:46:17.424454.424454 lmp.py:1622]   Expert  1 |    328 | GPU
DEBUG 01-13 08:46:17.424382.424382 lmp.py:1622]   Expert 58 |    331 | GPU
DEBUG 01-13 08:46:17.424071.424071 lmp.py:1622]   Expert 54 |    338 | GPU
DEBUG 01-13 08:46:17.424237.424237 lmp.py:1622]   Expert 28 |    356 | GPU
DEBUG 01-13 08:46:17.424165.424165 lmp.py:1622]   Expert 12 |    366 | GPU
DEBUG 01-13 08:46:17.424093.424093 lmp.py:1622]   Expert 25 |    398 | GPU
DEBUG 01-13 08:46:17.424020.424020 lmp.py:1622]   Expert 11 |    422 | GPU
DEBUG 01-13 08:46:17.424902.424902 lmp.py:1622]   Expert 30 |    858 | GPU
DEBUG 01-13 08:46:17.424260.424260 lmp.py:1623] 
DEBUG 01-13 08:46:17.424260.424260 lmp.py:1623]   CPU total tokens: 3224 (26.2%)
DEBUG 01-13 08:46:17.424810.424810 lmp.py:1624]   GPU total tokens: 9064 (73.8%)
DEBUG 01-13 08:46:17.424129.424129 cuda_h.py:19] end experts_map_get cost 0.0018296241760253906 seconds
DEBUG 01-13 08:46:17.424133.424133 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-13 08:46:17.424988.424988 lmp.py:1632] 
DEBUG 01-13 08:46:17.424988.424988 lmp.py:1632]   Computing 32 experts on CPU MP...
DEBUG 01-13 08:46:17.424401.424401 cuda_h.py:19] end cpu_experts_submit cost 5.7220458984375e-05 seconds
DEBUG 01-13 08:46:17.424574.424574 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-13 08:46:17.424609.424609 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-13 08:46:17.424130.424130 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-13 08:46:17.425117.425117 cuda_h.py:19] end allocate_cuda_memory cost 0.00037384033203125 seconds
DEBUG 01-13 08:46:17.425538.425538 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-13 08:46:17.425208.425208 sllm_store_c.py:27] get device uuid map
DEBUG 01-13 08:46:17.425739.425739 sllm_store_c.py:29] call client load into gpu
DEBUG 01-13 08:46:17.425011.425011 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 4683b007-be39-41a2-9ad0-90d7422a1fef
DEBUG 01-13 08:46:17.425124.425124 client.py:106] call stub.LoadModelAsync
INFO 01-13 08:46:17.426036.426036 client.py:127] Model loaded
DEBUG 01-13 08:46:17.426203.426203 cuda_h.py:10] start restore2model
DEBUG 01-13 08:46:17.426729.426729 cuda_h.py:10] start experts_func_gpu_einsum_mp
DEBUG 01-13 08:46:17.426739.426739 cuda_h.py:19] end restore2model cost 0.0003628730773925781 seconds
DEBUG 01-13 08:46:17.426078.426078 cuda_h.py:19] end sllm_worker_task cost 0.010689258575439453 seconds
INFO 01-13 08:46:17.426824.426824 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 4683b007-be39-41a2-9ad0-90d7422a1fef
DEBUG 01-13 08:46:17.426873.426873 cuda_h.py:19] end load_into_gpu_async cost 0.0014646053314208984 seconds
DEBUG 01-13 08:46:17.426152.426152 cuda_h.py:10] start restore_tensors2
DEBUG 01-13 08:46:17.427644.427644 cuda_h.py:19] end restore_tensors2 cost 0.0004050731658935547 seconds
DEBUG 01-13 08:46:17.427420.427420 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.002644777297973633 seconds
DEBUG 01-13 08:46:17.427467.427467 cuda_h.py:10] start restore2model
DEBUG 01-13 08:46:17.430850.430850 cuda_h.py:19] end restore2model cost 0.003094911575317383 seconds
DEBUG 01-13 08:46:17.430210.430210 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.005923271179199219 seconds
DEBUG 01-13 08:46:17.430767.430767 cuda_h.py:10] start gpu_sexperts
DEBUG 01-13 08:46:17.430318.430318 cuda_h.py:19] end gpu_sexperts cost 0.0004093647003173828 seconds
DEBUG 01-13 08:46:17.431485.431485 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-13 08:46:17.431838.431838 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 1.9550323486328125e-05 seconds
DEBUG 01-13 08:46:17.431488.431488 cuda_h.py:10] start wait_experts
INFO 01-13 08:46:17.431807.431807 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 4683b007-be39-41a2-9ad0-90d7422a1fef
DEBUG 01-13 08:46:17.435710.435710 mlpmodule.py:1006] group tensors cost 0.008759260177612305 s
DEBUG 01-13 08:46:17.437258.437258 mlpmodule.py:1044] pad cost 0.0015645027160644531 s
DEBUG 01-13 08:46:17.438831.438831 mlpmodule.py:1050] create cpu tensor cost 5.4836273193359375e-05 s
DEBUG 01-13 08:46:17.438774.438774 mlpmodule.py:1055] move to cpu cost 2.8371810913085938e-05 s
DEBUG 01-13 08:46:17.445912.445912 mlpmodule.py:1069] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-13 08:46:17.446470.446470 mlpmodule.py:1070] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-13 08:46:17.446223.446223 mlpmodule.py:1075] group_w3 first element: -0.006134033203125
WARNING 01-13 08:46:17.446089.446089 mlpmodule.py:1085] start einsum2
DEBUG 01-13 08:46:17.460621.460621 mlpmodule.py:1095] group einsum cost 0.022072315216064453 s
DEBUG 01-13 08:46:17.461149.461149 mlpmodule.py:1103] cpy2cputensor cost 0.0005846023559570312 s
INFO 01-13 08:46:17.478973.478973 client.py:127] Model loaded
DEBUG 01-13 08:46:17.478799.478799 cuda_h.py:19] end wait_experts cost 0.04723310470581055 seconds
DEBUG 01-13 08:46:17.478085.478085 cuda_h.py:10] start gpu_experts
DEBUG 01-13 08:46:17.479668.479668 mlpmodule.py:559] gpu group tensors cost 0.0006647109985351562 s
DEBUG 01-13 08:46:17.480182.480182 mlpmodule.py:592] gpu pad cost 0.0016326904296875 s
DEBUG 01-13 08:46:17.481774.481774 mlpmodule.py:598] start_w1
DEBUG 01-13 08:46:17.481609.481609 mlpmodule.py:602] start_w3
DEBUG 01-13 08:46:17.481715.481715 mlpmodule.py:608] start_w2
DEBUG 01-13 08:46:17.481853.481853 mlpmodule.py:611] gpu group einsum cost 0.0007586479187011719 s
DEBUG 01-13 08:46:17.482462.482462 mlpmodule.py:785]  experts func einsum cost 0.05595564842224121 s
DEBUG 01-13 08:46:17.483621.483621 cuda_h.py:19] end experts_func_gpu_einsum_mp cost 0.05663943290710449 seconds
DEBUG 01-13 08:46:17.484658.484658 mlpmodule.py:683] gpu experts func einsum cost 0.005509138107299805 s
DEBUG 01-13 08:46:17.484257.484257 cuda_h.py:19] end gpu_experts cost 0.005682468414306641 seconds
DEBUG 01-13 08:46:17.484628.484628 cuda_h.py:10] start cpu_thread_manager_mp_wait
DEBUG 01-13 08:46:17.484922.484922 cuda_h.py:19] end cpu_thread_manager_mp_wait cost 4.76837158203125e-05 seconds
DEBUG 01-13 08:46:17.484799.484799 cuda_h.py:19] end layer_moe_generate_mp_l_12 cost 0.06308650970458984 seconds
DEBUG 01-13 08:46:17.484327.484327 lmp.py:1550] -------------------------------- end prefill layer 11 --------------------------------
DEBUG 01-13 08:46:17.484434.484434 lmp.py:1493] -------------------------------- start prefill layer 12 --------------------------------
DEBUG 01-13 08:46:17.484137.484137 cuda_h.py:10] start start_load_qkvogn_s_weight_l_13
DEBUG 01-13 08:46:17.484893.484893 cuda_h.py:10] start start_load_qkvogn_s_weight_l_13
DEBUG 01-13 08:46:17.484173.484173 cuda_h.py:19] end start_load_qkvogn_s_weight_l_13 cost 4.124641418457031e-05 seconds
DEBUG 01-13 08:46:17.484207.484207 cuda_h.py:19] end start_load_qkvogn_s_weight_l_13 cost 6.985664367675781e-05 seconds
DEBUG 01-13 08:46:17.484281.484281 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-13 08:46:17.484945.484945 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-13 08:46:17.485142.485142 cuda_h.py:10] start sllm_worker_task
DEBUG 01-13 08:46:17.485025.485025 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-13 08:46:17.485978.485978 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-13 08:46:17.486391.486391 cuda_h.py:19] end allocate_cuda_memory cost 0.0005154609680175781 seconds
DEBUG 01-13 08:46:17.486527.486527 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-13 08:46:17.486051.486051 sllm_store_c.py:27] get device uuid map
DEBUG 01-13 08:46:17.486880.486880 sllm_store_c.py:29] call client load into gpu
DEBUG 01-13 08:46:17.486875.486875 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 7a60ca22-c409-4d86-b862-0be993e20c36
DEBUG 01-13 08:46:17.486964.486964 client.py:106] call stub.LoadModelAsync
DEBUG 01-13 08:46:17.486138.486138 cuda_h.py:10] start self_attn
INFO 01-13 08:46:17.487535.487535 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 7a60ca22-c409-4d86-b862-0be993e20c36
DEBUG 01-13 08:46:17.487628.487628 cuda_h.py:19] end load_into_gpu_async cost 0.0015993118286132812 seconds
DEBUG 01-13 08:46:17.488956.488956 cuda_h.py:10] start restore_tensors2
DEBUG 01-13 08:46:17.488182.488182 cuda_h.py:19] end restore_tensors2 cost 0.00013709068298339844 seconds
DEBUG 01-13 08:46:17.488938.488938 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0028066635131835938 seconds
INFO 01-13 08:46:17.488880.488880 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 7a60ca22-c409-4d86-b862-0be993e20c36
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-13 08:46:17.490578.490578 cuda_h.py:19] end self_attn cost 0.00417017936706543 seconds
DEBUG 01-13 08:46:17.491721.491721 cuda_h.py:19] end iln_self_attn_paln cost 0.006402254104614258 seconds
DEBUG 01-13 08:46:17.491671.491671 cuda_h.py:10] start layer_moe_generate_mp_l_13
DEBUG 01-13 08:46:17.491718.491718 cuda_h.py:10] start gate
DEBUG 01-13 08:46:17.492963.492963 cuda_h.py:19] end gate cost 0.0007421970367431641 seconds
DEBUG 01-13 08:46:17.492845.492845 cuda_h.py:10] start experts_map_get
DEBUG 01-13 08:46:17.492062.492062 lmp.py:1611] 
DEBUG 01-13 08:46:17.492062.492062 lmp.py:1611] Expert Token Distribution & Device Allocation:
DEBUG 01-13 08:46:17.492487.492487 lmp.py:1612]   Total experts: 64
DEBUG 01-13 08:46:17.492852.492852 lmp.py:1613]   CPU experts: 32 (50%)
DEBUG 01-13 08:46:17.492402.492402 lmp.py:1614]   GPU experts: 32 (50%)
DEBUG 01-13 08:46:17.492807.492807 lmp.py:1615] 
DEBUG 01-13 08:46:17.492807.492807 lmp.py:1615]   Expert ID | Tokens | Device
DEBUG 01-13 08:46:17.492165.492165 lmp.py:1616]   -----------------------------------
DEBUG 01-13 08:46:17.492960.492960 lmp.py:1622]   Expert 12 |     14 | CPU
DEBUG 01-13 08:46:17.492842.492842 lmp.py:1622]   Expert 47 |     24 | CPU
DEBUG 01-13 08:46:17.492293.492293 lmp.py:1622]   Expert 27 |     30 | CPU
DEBUG 01-13 08:46:17.492505.492505 lmp.py:1622]   Expert 38 |     30 | CPU
DEBUG 01-13 08:46:17.492718.492718 lmp.py:1622]   Expert 16 |     38 | CPU
DEBUG 01-13 08:46:17.492692.492692 lmp.py:1622]   Expert 52 |     38 | CPU
DEBUG 01-13 08:46:17.492480.492480 lmp.py:1622]   Expert 63 |     46 | CPU
DEBUG 01-13 08:46:17.492508.492508 lmp.py:1622]   Expert 43 |     55 | CPU
DEBUG 01-13 08:46:17.492058.492058 lmp.py:1622]   Expert  4 |     57 | CPU
DEBUG 01-13 08:46:17.492370.492370 lmp.py:1622]   Expert 61 |     68 | CPU
DEBUG 01-13 08:46:17.492728.492728 lmp.py:1622]   Expert 44 |     70 | CPU
DEBUG 01-13 08:46:17.492086.492086 lmp.py:1622]   Expert  0 |     77 | CPU
DEBUG 01-13 08:46:17.492206.492206 lmp.py:1622]   Expert 34 |     77 | CPU
DEBUG 01-13 08:46:17.492280.492280 lmp.py:1622]   Expert 53 |     85 | CPU
DEBUG 01-13 08:46:17.492876.492876 lmp.py:1622]   Expert 37 |     90 | CPU
DEBUG 01-13 08:46:17.492996.492996 lmp.py:1622]   Expert 13 |     92 | CPU
DEBUG 01-13 08:46:17.492354.492354 lmp.py:1622]   Expert 32 |     97 | CPU
DEBUG 01-13 08:46:17.493713.493713 lmp.py:1622]   Expert 39 |    112 | CPU
DEBUG 01-13 08:46:17.493263.493263 lmp.py:1622]   Expert 21 |    117 | CPU
DEBUG 01-13 08:46:17.493813.493813 lmp.py:1622]   Expert 11 |    120 | CPU
DEBUG 01-13 08:46:17.493887.493887 lmp.py:1622]   Expert  8 |    130 | CPU
DEBUG 01-13 08:46:17.493483.493483 lmp.py:1622]   Expert 20 |    131 | CPU
DEBUG 01-13 08:46:17.493795.493795 lmp.py:1622]   Expert 14 |    135 | CPU
DEBUG 01-13 08:46:17.493153.493153 lmp.py:1622]   Expert 60 |    137 | CPU
DEBUG 01-13 08:46:17.493512.493512 lmp.py:1622]   Expert 57 |    140 | CPU
DEBUG 01-13 08:46:17.493393.493393 lmp.py:1622]   Expert 22 |    146 | CPU
DEBUG 01-13 08:46:17.493513.493513 lmp.py:1622]   Expert  2 |    147 | CPU
DEBUG 01-13 08:46:17.493633.493633 lmp.py:1622]   Expert 45 |    154 | CPU
DEBUG 01-13 08:46:17.493753.493753 lmp.py:1622]   Expert 23 |    160 | CPU
DEBUG 01-13 08:46:17.493111.493111 lmp.py:1622]   Expert  7 |    162 | CPU
DEBUG 01-13 08:46:17.493469.493469 lmp.py:1622]   Expert 17 |    162 | CPU
DEBUG 01-13 08:46:17.493350.493350 lmp.py:1622]   Expert 18 |    162 | CPU
DEBUG 01-13 08:46:17.493424.493424 lmp.py:1622]   Expert 58 |    165 | GPU
DEBUG 01-13 08:46:17.493736.493736 lmp.py:1622]   Expert 30 |    167 | GPU
DEBUG 01-13 08:46:17.493048.493048 lmp.py:1622]   Expert 51 |    171 | GPU
DEBUG 01-13 08:46:17.493598.493598 lmp.py:1622]   Expert 55 |    171 | GPU
DEBUG 01-13 08:46:17.493195.493195 lmp.py:1622]   Expert 42 |    173 | GPU
DEBUG 01-13 08:46:17.493030.493030 lmp.py:1622]   Expert 49 |    176 | GPU
DEBUG 01-13 08:46:17.493626.493626 lmp.py:1622]   Expert 62 |    178 | GPU
DEBUG 01-13 08:46:17.493985.493985 lmp.py:1622]   Expert 48 |    180 | GPU
DEBUG 01-13 08:46:17.493581.493581 lmp.py:1622]   Expert 29 |    184 | GPU
DEBUG 01-13 08:46:17.493939.493939 lmp.py:1622]   Expert 35 |    187 | GPU
DEBUG 01-13 08:46:17.493775.493775 lmp.py:1622]   Expert 25 |    199 | GPU
DEBUG 01-13 08:46:17.493848.493848 lmp.py:1622]   Expert  1 |    200 | GPU
DEBUG 01-13 08:46:17.493683.493683 lmp.py:1622]   Expert 36 |    200 | GPU
DEBUG 01-13 08:46:17.493233.493233 lmp.py:1622]   Expert  6 |    203 | GPU
DEBUG 01-13 08:46:17.493022.493022 lmp.py:1622]   Expert 31 |    208 | GPU
DEBUG 01-13 08:46:17.493334.493334 lmp.py:1622]   Expert 28 |    220 | GPU
DEBUG 01-13 08:46:17.493169.493169 lmp.py:1622]   Expert 41 |    220 | GPU
DEBUG 01-13 08:46:17.493527.493527 lmp.py:1622]   Expert 54 |    233 | GPU
DEBUG 01-13 08:46:17.493376.493376 lmp.py:1622]   Expert 19 |    235 | GPU
DEBUG 01-13 08:46:17.493496.493496 lmp.py:1622]   Expert  5 |    237 | GPU
DEBUG 01-13 08:46:17.493616.493616 lmp.py:1622]   Expert 24 |    240 | GPU
DEBUG 01-13 08:46:17.493497.493497 lmp.py:1622]   Expert  9 |    241 | GPU
DEBUG 01-13 08:46:17.493140.493140 lmp.py:1622]   Expert 50 |    289 | GPU
DEBUG 01-13 08:46:17.493021.493021 lmp.py:1622]   Expert 59 |    309 | GPU
DEBUG 01-13 08:46:17.493141.493141 lmp.py:1622]   Expert 46 |    317 | GPU
DEBUG 01-13 08:46:17.493215.493215 lmp.py:1622]   Expert 56 |    383 | GPU
DEBUG 01-13 08:46:17.493573.493573 lmp.py:1622]   Expert 26 |    393 | GPU
DEBUG 01-13 08:46:17.493885.493885 lmp.py:1622]   Expert 33 |    429 | GPU
DEBUG 01-13 08:46:17.493674.493674 lmp.py:1622]   Expert  3 |    574 | GPU
DEBUG 01-13 08:46:17.493032.493032 lmp.py:1622]   Expert 15 |    658 | GPU
DEBUG 01-13 08:46:17.493913.493913 lmp.py:1622]   Expert 10 |    687 | GPU
DEBUG 01-13 08:46:17.493033.493033 lmp.py:1622]   Expert 40 |    758 | GPU
DEBUG 01-13 08:46:17.493345.493345 lmp.py:1623] 
DEBUG 01-13 08:46:17.493345.493345 lmp.py:1623]   CPU total tokens: 3103 (25.3%)
DEBUG 01-13 08:46:17.493108.493108 lmp.py:1624]   GPU total tokens: 9185 (74.7%)
DEBUG 01-13 08:46:17.493903.493903 cuda_h.py:19] end experts_map_get cost 0.001699209213256836 seconds
DEBUG 01-13 08:46:17.494410.494410 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-13 08:46:17.494311.494311 lmp.py:1632] 
DEBUG 01-13 08:46:17.494311.494311 lmp.py:1632]   Computing 32 experts on CPU MP...
DEBUG 01-13 08:46:17.494724.494724 cuda_h.py:19] end cpu_experts_submit cost 5.888938903808594e-05 seconds
DEBUG 01-13 08:46:17.494466.494466 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-13 08:46:17.494045.494045 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-13 08:46:17.494065.494065 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-13 08:46:17.494929.494929 cuda_h.py:19] end allocate_cuda_memory cost 0.0002498626708984375 seconds
DEBUG 01-13 08:46:17.494693.494693 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-13 08:46:17.494316.494316 sllm_store_c.py:27] get device uuid map
DEBUG 01-13 08:46:17.494530.494530 sllm_store_c.py:29] call client load into gpu
DEBUG 01-13 08:46:17.494571.494571 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 99a8a36e-5e1f-42e2-b830-25d7287c4a1a
DEBUG 01-13 08:46:17.495062.495062 client.py:106] call stub.LoadModelAsync
INFO 01-13 08:46:17.496449.496449 client.py:127] Model loaded
DEBUG 01-13 08:46:17.496789.496789 cuda_h.py:10] start restore2model
DEBUG 01-13 08:46:17.496808.496808 cuda_h.py:10] start experts_func_gpu_einsum_mp
DEBUG 01-13 08:46:17.497588.497588 cuda_h.py:19] end restore2model cost 0.0010116100311279297 seconds
INFO 01-13 08:46:17.497593.497593 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 99a8a36e-5e1f-42e2-b830-25d7287c4a1a
DEBUG 01-13 08:46:17.497617.497617 cuda_h.py:19] end sllm_worker_task cost 0.012356281280517578 seconds
DEBUG 01-13 08:46:17.497662.497662 cuda_h.py:19] end load_into_gpu_async cost 0.0029866695404052734 seconds
DEBUG 01-13 08:46:17.497871.497871 cuda_h.py:10] start restore_tensors2
DEBUG 01-13 08:46:17.498706.498706 cuda_h.py:19] end restore_tensors2 cost 0.0003745555877685547 seconds
DEBUG 01-13 08:46:17.498674.498674 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.004124641418457031 seconds
DEBUG 01-13 08:46:17.498305.498305 cuda_h.py:10] start restore2model
DEBUG 01-13 08:46:17.501423.501423 cuda_h.py:19] end restore2model cost 0.00272369384765625 seconds
DEBUG 01-13 08:46:17.501704.501704 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.0070705413818359375 seconds
DEBUG 01-13 08:46:17.501738.501738 cuda_h.py:10] start gpu_sexperts
DEBUG 01-13 08:46:17.501788.501788 cuda_h.py:19] end gpu_sexperts cost 0.0002849102020263672 seconds
DEBUG 01-13 08:46:17.501400.501400 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-13 08:46:17.501799.501799 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 1.9788742065429688e-05 seconds
DEBUG 01-13 08:46:17.501779.501779 cuda_h.py:10] start wait_experts
INFO 01-13 08:46:17.501383.501383 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 99a8a36e-5e1f-42e2-b830-25d7287c4a1a
DEBUG 01-13 08:46:17.505388.505388 mlpmodule.py:1006] group tensors cost 0.008623123168945312 s
DEBUG 01-13 08:46:17.507478.507478 mlpmodule.py:1044] pad cost 0.0014777183532714844 s
DEBUG 01-13 08:46:17.507938.507938 mlpmodule.py:1050] create cpu tensor cost 3.981590270996094e-05 s
DEBUG 01-13 08:46:17.507973.507973 mlpmodule.py:1055] move to cpu cost 2.956390380859375e-05 s
DEBUG 01-13 08:46:17.517405.517405 mlpmodule.py:1069] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-13 08:46:17.518312.518312 mlpmodule.py:1070] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-13 08:46:17.518077.518077 mlpmodule.py:1075] group_w3 first element: -0.0162353515625
WARNING 01-13 08:46:17.518591.518591 mlpmodule.py:1085] start einsum2
DEBUG 01-13 08:46:17.532188.532188 mlpmodule.py:1095] group einsum cost 0.024331331253051758 s
DEBUG 01-13 08:46:17.533944.533944 mlpmodule.py:1103] cpy2cputensor cost 0.0005834102630615234 s
INFO 01-13 08:46:17.550154.550154 client.py:127] Model loaded
DEBUG 01-13 08:46:17.550034.550034 cuda_h.py:19] end wait_experts cost 0.048491477966308594 seconds
DEBUG 01-13 08:46:17.550465.550465 cuda_h.py:10] start gpu_experts
DEBUG 01-13 08:46:17.551288.551288 mlpmodule.py:559] gpu group tensors cost 0.0006976127624511719 s
DEBUG 01-13 08:46:17.552716.552716 mlpmodule.py:592] gpu pad cost 0.0016369819641113281 s
DEBUG 01-13 08:46:17.552063.552063 mlpmodule.py:598] start_w1
DEBUG 01-13 08:46:17.553543.553543 mlpmodule.py:785]  experts func einsum cost 0.05601024627685547 s
DEBUG 01-13 08:46:17.553921.553921 cuda_h.py:19] end experts_func_gpu_einsum_mp cost 0.05673074722290039 seconds
DEBUG 01-13 08:46:17.553143.553143 mlpmodule.py:602] start_w3
DEBUG 01-13 08:46:17.553818.553818 mlpmodule.py:608] start_w2
DEBUG 01-13 08:46:17.553817.553817 mlpmodule.py:611] gpu group einsum cost 0.0007655620574951172 s
DEBUG 01-13 08:46:17.555448.555448 mlpmodule.py:683] gpu experts func einsum cost 0.0054912567138671875 s
DEBUG 01-13 08:46:17.555517.555517 cuda_h.py:19] end gpu_experts cost 0.005664825439453125 seconds
DEBUG 01-13 08:46:17.556697.556697 cuda_h.py:10] start cpu_thread_manager_mp_wait
DEBUG 01-13 08:46:17.556421.556421 cuda_h.py:19] end cpu_thread_manager_mp_wait cost 4.9591064453125e-05 seconds
DEBUG 01-13 08:46:17.556344.556344 cuda_h.py:19] end layer_moe_generate_mp_l_13 cost 0.06479072570800781 seconds
DEBUG 01-13 08:46:17.556429.556429 lmp.py:1550] -------------------------------- end prefill layer 12 --------------------------------
DEBUG 01-13 08:46:17.556245.556245 lmp.py:1493] -------------------------------- start prefill layer 13 --------------------------------
DEBUG 01-13 08:46:17.556424.556424 cuda_h.py:10] start start_load_qkvogn_s_weight_l_14
DEBUG 01-13 08:46:17.556180.556180 cuda_h.py:10] start start_load_qkvogn_s_weight_l_14
DEBUG 01-13 08:46:17.556468.556468 cuda_h.py:19] end start_load_qkvogn_s_weight_l_14 cost 4.5299530029296875e-05 seconds
DEBUG 01-13 08:46:17.556978.556978 cuda_h.py:19] end start_load_qkvogn_s_weight_l_14 cost 7.486343383789062e-05 seconds
DEBUG 01-13 08:46:17.556337.556337 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-13 08:46:17.556485.556485 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-13 08:46:17.556013.556013 cuda_h.py:10] start sllm_worker_task
DEBUG 01-13 08:46:17.557551.557551 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-13 08:46:17.557074.557074 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-13 08:46:17.557445.557445 cuda_h.py:19] end allocate_cuda_memory cost 0.00032901763916015625 seconds
DEBUG 01-13 08:46:17.557991.557991 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-13 08:46:17.557138.557138 sllm_store_c.py:27] get device uuid map
DEBUG 01-13 08:46:17.557590.557590 sllm_store_c.py:29] call client load into gpu
DEBUG 01-13 08:46:17.558200.558200 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 2a9f9d30-5cd3-4f68-91d2-4b48352cc3d2
DEBUG 01-13 08:46:17.558396.558396 client.py:106] call stub.LoadModelAsync
DEBUG 01-13 08:46:17.558558.558558 cuda_h.py:10] start self_attn
INFO 01-13 08:46:17.559205.559205 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 2a9f9d30-5cd3-4f68-91d2-4b48352cc3d2
DEBUG 01-13 08:46:17.559182.559182 cuda_h.py:19] end load_into_gpu_async cost 0.001505136489868164 seconds
DEBUG 01-13 08:46:17.559269.559269 cuda_h.py:10] start restore_tensors2
DEBUG 01-13 08:46:17.559895.559895 cuda_h.py:19] end restore_tensors2 cost 8.130073547363281e-05 seconds
DEBUG 01-13 08:46:17.559267.559267 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.002278566360473633 seconds
INFO 01-13 08:46:17.559945.559945 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 2a9f9d30-5cd3-4f68-91d2-4b48352cc3d2
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-13 08:46:17.563697.563697 cuda_h.py:19] end self_attn cost 0.004842519760131836 seconds
DEBUG 01-13 08:46:17.563515.563515 cuda_h.py:19] end iln_self_attn_paln cost 0.007085084915161133 seconds
DEBUG 01-13 08:46:17.563247.563247 cuda_h.py:10] start layer_moe_generate_mp_l_14
DEBUG 01-13 08:46:17.563453.563453 cuda_h.py:10] start gate
DEBUG 01-13 08:46:17.564234.564234 cuda_h.py:19] end gate cost 0.0009148120880126953 seconds
DEBUG 01-13 08:46:17.565938.565938 cuda_h.py:10] start experts_map_get
DEBUG 01-13 08:46:17.565953.565953 lmp.py:1611] 
DEBUG 01-13 08:46:17.565953.565953 lmp.py:1611] Expert Token Distribution & Device Allocation:
DEBUG 01-13 08:46:17.565630.565630 lmp.py:1612]   Total experts: 64
DEBUG 01-13 08:46:17.565770.565770 lmp.py:1613]   CPU experts: 32 (50%)
DEBUG 01-13 08:46:17.565619.565619 lmp.py:1614]   GPU experts: 32 (50%)
DEBUG 01-13 08:46:17.565845.565845 lmp.py:1615] 
DEBUG 01-13 08:46:17.565845.565845 lmp.py:1615]   Expert ID | Tokens | Device
DEBUG 01-13 08:46:17.565594.565594 lmp.py:1616]   -----------------------------------
DEBUG 01-13 08:46:17.565211.565211 lmp.py:1622]   Expert 19 |     20 | CPU
DEBUG 01-13 08:46:17.565722.565722 lmp.py:1622]   Expert 42 |     22 | CPU
DEBUG 01-13 08:46:17.565041.565041 lmp.py:1622]   Expert 30 |     27 | CPU
DEBUG 01-13 08:46:17.565836.565836 lmp.py:1622]   Expert 32 |     33 | CPU
DEBUG 01-13 08:46:17.565155.565155 lmp.py:1622]   Expert  6 |     52 | CPU
DEBUG 01-13 08:46:17.565997.565997 lmp.py:1622]   Expert 53 |     77 | CPU
DEBUG 01-13 08:46:17.565077.565077 lmp.py:1622]   Expert  1 |     85 | CPU
DEBUG 01-13 08:46:17.566396.566396 lmp.py:1622]   Expert  5 |     86 | CPU
DEBUG 01-13 08:46:17.566714.566714 lmp.py:1622]   Expert  9 |    112 | CPU
DEBUG 01-13 08:46:17.566225.566225 lmp.py:1622]   Expert 13 |    114 | CPU
DEBUG 01-13 08:46:17.566736.566736 lmp.py:1622]   Expert 63 |    125 | CPU
DEBUG 01-13 08:46:17.566008.566008 lmp.py:1622]   Expert 58 |    127 | CPU
DEBUG 01-13 08:46:17.566565.566565 lmp.py:1622]   Expert 34 |    131 | CPU
DEBUG 01-13 08:46:17.566646.566646 lmp.py:1622]   Expert 26 |    132 | CPU
DEBUG 01-13 08:46:17.566487.566487 lmp.py:1622]   Expert 50 |    135 | CPU
DEBUG 01-13 08:46:17.566568.566568 lmp.py:1622]   Expert 59 |    137 | CPU
DEBUG 01-13 08:46:17.566410.566410 lmp.py:1622]   Expert 31 |    138 | CPU
DEBUG 01-13 08:46:17.566775.566775 lmp.py:1622]   Expert 40 |    140 | CPU
DEBUG 01-13 08:46:17.566093.566093 lmp.py:1622]   Expert 18 |    145 | CPU
DEBUG 01-13 08:46:17.566174.566174 lmp.py:1622]   Expert 56 |    148 | CPU
DEBUG 01-13 08:46:17.566684.566684 lmp.py:1622]   Expert 12 |    149 | CPU
DEBUG 01-13 08:46:17.566957.566957 lmp.py:1622]   Expert 20 |    150 | CPU
DEBUG 01-13 08:46:17.566229.566229 lmp.py:1622]   Expert  2 |    151 | CPU
DEBUG 01-13 08:46:17.566548.566548 lmp.py:1622]   Expert 11 |    151 | CPU
DEBUG 01-13 08:46:17.566390.566390 lmp.py:1622]   Expert 48 |    153 | CPU
DEBUG 01-13 08:46:17.566232.566232 lmp.py:1622]   Expert 33 |    156 | CPU
DEBUG 01-13 08:46:17.566073.566073 lmp.py:1622]   Expert 46 |    159 | CPU
DEBUG 01-13 08:46:17.566915.566915 lmp.py:1622]   Expert  4 |    160 | CPU
DEBUG 01-13 08:46:17.566949.566949 lmp.py:1622]   Expert 61 |    161 | CPU
DEBUG 01-13 08:46:17.566983.566983 lmp.py:1622]   Expert 55 |    165 | CPU
DEBUG 01-13 08:46:17.566256.566256 lmp.py:1622]   Expert 10 |    166 | CPU
DEBUG 01-13 08:46:17.566336.566336 lmp.py:1622]   Expert 35 |    168 | CPU
DEBUG 01-13 08:46:17.566654.566654 lmp.py:1622]   Expert  8 |    176 | GPU
DEBUG 01-13 08:46:17.566735.566735 lmp.py:1622]   Expert 36 |    177 | GPU
DEBUG 01-13 08:46:17.566815.566815 lmp.py:1622]   Expert 51 |    177 | GPU
DEBUG 01-13 08:46:17.566895.566895 lmp.py:1622]   Expert 52 |    181 | GPU
DEBUG 01-13 08:46:17.566645.566645 lmp.py:1622]   Expert  0 |    197 | GPU
DEBUG 01-13 08:46:17.566917.566917 lmp.py:1622]   Expert 57 |    198 | GPU
DEBUG 01-13 08:46:17.566712.566712 lmp.py:1622]   Expert 37 |    199 | GPU
DEBUG 01-13 08:46:17.566746.566746 lmp.py:1622]   Expert 39 |    218 | GPU
DEBUG 01-13 08:46:17.566065.566065 lmp.py:1622]   Expert 25 |    231 | GPU
DEBUG 01-13 08:46:17.566384.566384 lmp.py:1622]   Expert 62 |    232 | GPU
DEBUG 01-13 08:46:17.566464.566464 lmp.py:1622]   Expert 27 |    248 | GPU
DEBUG 01-13 08:46:17.566544.566544 lmp.py:1622]   Expert 38 |    251 | GPU
DEBUG 01-13 08:46:17.566625.566625 lmp.py:1622]   Expert  7 |    254 | GPU
DEBUG 01-13 08:46:17.566897.566897 lmp.py:1622]   Expert 16 |    254 | GPU
DEBUG 01-13 08:46:17.566169.566169 lmp.py:1622]   Expert 24 |    255 | GPU
DEBUG 01-13 08:46:17.567442.567442 lmp.py:1622]   Expert 28 |    255 | GPU
DEBUG 01-13 08:46:17.567522.567522 lmp.py:1622]   Expert 60 |    255 | GPU
DEBUG 01-13 08:46:17.567364.567364 lmp.py:1622]   Expert  3 |    257 | GPU
DEBUG 01-13 08:46:17.567206.567206 lmp.py:1622]   Expert 21 |    259 | GPU
DEBUG 01-13 08:46:17.567809.567809 lmp.py:1622]   Expert 49 |    260 | GPU
DEBUG 01-13 08:46:17.567413.567413 lmp.py:1622]   Expert 43 |    266 | GPU
DEBUG 01-13 08:46:17.567016.567016 lmp.py:1622]   Expert 29 |    276 | GPU
DEBUG 01-13 08:46:17.567050.567050 lmp.py:1622]   Expert 23 |    281 | GPU
DEBUG 01-13 08:46:17.567846.567846 lmp.py:1622]   Expert 22 |    282 | GPU
DEBUG 01-13 08:46:17.567403.567403 lmp.py:1622]   Expert 15 |    291 | GPU
DEBUG 01-13 08:46:17.567244.567244 lmp.py:1622]   Expert 44 |    291 | GPU
DEBUG 01-13 08:46:17.567086.567086 lmp.py:1622]   Expert 41 |    295 | GPU
DEBUG 01-13 08:46:17.567928.567928 lmp.py:1622]   Expert 47 |    295 | GPU
DEBUG 01-13 08:46:17.567008.567008 lmp.py:1622]   Expert 14 |    372 | GPU
DEBUG 01-13 08:46:17.567089.567089 lmp.py:1622]   Expert 54 |    375 | GPU
DEBUG 01-13 08:46:17.567414.567414 lmp.py:1622]   Expert 17 |    410 | GPU
DEBUG 01-13 08:46:17.567733.567733 lmp.py:1622]   Expert 45 |    445 | GPU
DEBUG 01-13 08:46:17.567959.567959 lmp.py:1623] 
DEBUG 01-13 08:46:17.567959.567959 lmp.py:1623]   CPU total tokens: 3875 (31.5%)
DEBUG 01-13 08:46:17.567662.567662 lmp.py:1624]   GPU total tokens: 8413 (68.5%)
DEBUG 01-13 08:46:17.567418.567418 cuda_h.py:19] end experts_map_get cost 0.0024216175079345703 seconds
INFO 01-13 08:46:17.567381.567381 client.py:127] Model loaded
DEBUG 01-13 08:46:17.567608.567608 cuda_h.py:10] start restore2model
DEBUG 01-13 08:46:17.567125.567125 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-13 08:46:17.567107.567107 lmp.py:1632] 
DEBUG 01-13 08:46:17.567107.567107 lmp.py:1632]   Computing 32 experts on CPU MP...
DEBUG 01-13 08:46:17.567255.567255 cuda_h.py:19] end cpu_experts_submit cost 7.367134094238281e-05 seconds
DEBUG 01-13 08:46:17.567011.567011 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-13 08:46:17.568682.568682 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-13 08:46:17.568390.568390 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-13 08:46:17.568381.568381 cuda_h.py:19] end allocate_cuda_memory cost 0.0002624988555908203 seconds
DEBUG 01-13 08:46:17.568151.568151 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-13 08:46:17.568206.568206 sllm_store_c.py:27] get device uuid map
DEBUG 01-13 08:46:17.568267.568267 sllm_store_c.py:29] call client load into gpu
DEBUG 01-13 08:46:17.568784.568784 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, ce188843-5c61-4ae5-9c13-4ee4d124bf63
DEBUG 01-13 08:46:17.568328.568328 client.py:106] call stub.LoadModelAsync
DEBUG 01-13 08:46:17.569450.569450 cuda_h.py:19] end restore2model cost 0.0017697811126708984 seconds
DEBUG 01-13 08:46:17.569756.569756 cuda_h.py:19] end sllm_worker_task cost 0.012685298919677734 seconds
INFO 01-13 08:46:17.570172.570172 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, ce188843-5c61-4ae5-9c13-4ee4d124bf63
DEBUG 01-13 08:46:17.570181.570181 cuda_h.py:19] end load_into_gpu_async cost 0.0016274452209472656 seconds
DEBUG 01-13 08:46:17.570944.570944 cuda_h.py:10] start restore_tensors2
DEBUG 01-13 08:46:17.570212.570212 cuda_h.py:10] start experts_func_gpu_einsum_mp
DEBUG 01-13 08:46:17.570715.570715 cuda_h.py:19] end restore_tensors2 cost 0.0004620552062988281 seconds
DEBUG 01-13 08:46:17.570413.570413 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.002786874771118164 seconds
DEBUG 01-13 08:46:17.570089.570089 cuda_h.py:10] start restore2model
DEBUG 01-13 08:46:17.574080.574080 cuda_h.py:19] end restore2model cost 0.0034308433532714844 seconds
DEBUG 01-13 08:46:17.574016.574016 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.006433963775634766 seconds
DEBUG 01-13 08:46:17.574573.574573 cuda_h.py:10] start gpu_sexperts
DEBUG 01-13 08:46:17.574194.574194 cuda_h.py:19] end gpu_sexperts cost 0.0003209114074707031 seconds
DEBUG 01-13 08:46:17.574454.574454 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-13 08:46:17.574753.574753 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 1.5974044799804688e-05 seconds
DEBUG 01-13 08:46:17.574449.574449 cuda_h.py:10] start wait_experts
INFO 01-13 08:46:17.574814.574814 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, ce188843-5c61-4ae5-9c13-4ee4d124bf63
DEBUG 01-13 08:46:17.583971.583971 mlpmodule.py:1006] group tensors cost 0.012479782104492188 s
DEBUG 01-13 08:46:17.585364.585364 mlpmodule.py:1044] pad cost 0.0015025138854980469 s
DEBUG 01-13 08:46:17.585394.585394 mlpmodule.py:1050] create cpu tensor cost 4.00543212890625e-05 s
DEBUG 01-13 08:46:17.585528.585528 mlpmodule.py:1055] move to cpu cost 3.0040740966796875e-05 s
DEBUG 01-13 08:46:17.594428.594428 mlpmodule.py:1069] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-13 08:46:17.594996.594996 mlpmodule.py:1070] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-13 08:46:17.594709.594709 mlpmodule.py:1075] group_w3 first element: -0.0211181640625
WARNING 01-13 08:46:17.594832.594832 mlpmodule.py:1085] start einsum2
DEBUG 01-13 08:46:17.609660.609660 mlpmodule.py:1095] group einsum cost 0.02344202995300293 s
DEBUG 01-13 08:46:17.609681.609681 mlpmodule.py:1103] cpy2cputensor cost 0.0006082057952880859 s
INFO 01-13 08:46:17.622487.622487 client.py:127] Model loaded
DEBUG 01-13 08:46:17.622400.622400 cuda_h.py:19] end wait_experts cost 0.04752540588378906 seconds
DEBUG 01-13 08:46:17.622269.622269 cuda_h.py:10] start gpu_experts
DEBUG 01-13 08:46:17.623214.623214 mlpmodule.py:559] gpu group tensors cost 0.0008089542388916016 s
DEBUG 01-13 08:46:17.625966.625966 mlpmodule.py:592] gpu pad cost 0.0018038749694824219 s
DEBUG 01-13 08:46:17.625420.625420 mlpmodule.py:598] start_w1
DEBUG 01-13 08:46:17.625282.625282 mlpmodule.py:602] start_w3
DEBUG 01-13 08:46:17.626924.626924 mlpmodule.py:608] start_w2
DEBUG 01-13 08:46:17.626539.626539 mlpmodule.py:611] gpu group einsum cost 0.0007891654968261719 s
DEBUG 01-13 08:46:17.628100.628100 mlpmodule.py:785]  experts func einsum cost 0.05728483200073242 s
DEBUG 01-13 08:46:17.628431.628431 mlpmodule.py:683] gpu experts func einsum cost 0.005890607833862305 s
DEBUG 01-13 08:46:17.628869.628869 cuda_h.py:19] end experts_func_gpu_einsum_mp cost 0.058135271072387695 seconds
DEBUG 01-13 08:46:17.628083.628083 cuda_h.py:19] end gpu_experts cost 0.006081819534301758 seconds
DEBUG 01-13 08:46:17.628077.628077 cuda_h.py:10] start cpu_thread_manager_mp_wait
DEBUG 01-13 08:46:17.628948.628948 cuda_h.py:19] end cpu_thread_manager_mp_wait cost 5.125999450683594e-05 seconds
DEBUG 01-13 08:46:17.628732.628732 cuda_h.py:19] end layer_moe_generate_mp_l_14 cost 0.06488919258117676 seconds
DEBUG 01-13 08:46:17.629258.629258 lmp.py:1550] -------------------------------- end prefill layer 13 --------------------------------
DEBUG 01-13 08:46:17.629173.629173 lmp.py:1493] -------------------------------- start prefill layer 14 --------------------------------
DEBUG 01-13 08:46:17.629784.629784 cuda_h.py:10] start start_load_qkvogn_s_weight_l_15
DEBUG 01-13 08:46:17.629778.629778 cuda_h.py:10] start start_load_qkvogn_s_weight_l_15
DEBUG 01-13 08:46:17.629012.629012 cuda_h.py:19] end start_load_qkvogn_s_weight_l_15 cost 4.1961669921875e-05 seconds
DEBUG 01-13 08:46:17.629238.629238 cuda_h.py:19] end start_load_qkvogn_s_weight_l_15 cost 7.104873657226562e-05 seconds
DEBUG 01-13 08:46:17.629027.629027 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-13 08:46:17.629599.629599 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-13 08:46:17.629338.629338 cuda_h.py:10] start sllm_worker_task
DEBUG 01-13 08:46:17.629040.629040 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-13 08:46:17.629903.629903 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-13 08:46:17.630815.630815 cuda_h.py:19] end allocate_cuda_memory cost 0.0002789497375488281 seconds
DEBUG 01-13 08:46:17.630340.630340 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-13 08:46:17.630911.630911 sllm_store_c.py:27] get device uuid map
DEBUG 01-13 08:46:17.630171.630171 sllm_store_c.py:29] call client load into gpu
DEBUG 01-13 08:46:17.630781.630781 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, c1e4b8b5-1eb3-48bf-99fb-23e9c1602e39
DEBUG 01-13 08:46:17.630394.630394 client.py:106] call stub.LoadModelAsync
DEBUG 01-13 08:46:17.630015.630015 cuda_h.py:10] start self_attn
INFO 01-13 08:46:17.631199.631199 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, c1e4b8b5-1eb3-48bf-99fb-23e9c1602e39
DEBUG 01-13 08:46:17.631599.631599 cuda_h.py:19] end load_into_gpu_async cost 0.0013461112976074219 seconds
DEBUG 01-13 08:46:17.631878.631878 cuda_h.py:10] start restore_tensors2
DEBUG 01-13 08:46:17.631689.631689 cuda_h.py:19] end restore_tensors2 cost 7.748603820800781e-05 seconds
DEBUG 01-13 08:46:17.631253.631253 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0019745826721191406 seconds
INFO 01-13 08:46:17.632045.632045 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, c1e4b8b5-1eb3-48bf-99fb-23e9c1602e39
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-13 08:46:17.634091.634091 cuda_h.py:19] end self_attn cost 0.003153085708618164 seconds
DEBUG 01-13 08:46:17.634042.634042 cuda_h.py:19] end iln_self_attn_paln cost 0.004965782165527344 seconds
DEBUG 01-13 08:46:17.634567.634567 cuda_h.py:10] start layer_moe_generate_mp_l_15
DEBUG 01-13 08:46:17.634953.634953 cuda_h.py:10] start gate
DEBUG 01-13 08:46:17.635222.635222 cuda_h.py:19] end gate cost 0.0006868839263916016 seconds
DEBUG 01-13 08:46:17.635774.635774 cuda_h.py:10] start experts_map_get
DEBUG 01-13 08:46:17.635069.635069 lmp.py:1611] 
DEBUG 01-13 08:46:17.635069.635069 lmp.py:1611] Expert Token Distribution & Device Allocation:
DEBUG 01-13 08:46:17.635825.635825 lmp.py:1612]   Total experts: 64
DEBUG 01-13 08:46:17.635952.635952 lmp.py:1613]   CPU experts: 32 (50%)
DEBUG 01-13 08:46:17.635502.635502 lmp.py:1614]   GPU experts: 32 (50%)
DEBUG 01-13 08:46:17.635145.635145 lmp.py:1615] 
DEBUG 01-13 08:46:17.635145.635145 lmp.py:1615]   Expert ID | Tokens | Device
DEBUG 01-13 08:46:17.635364.635364 lmp.py:1616]   -----------------------------------
DEBUG 01-13 08:46:17.635067.635067 lmp.py:1622]   Expert  7 |     32 | CPU
DEBUG 01-13 08:46:17.635333.635333 lmp.py:1622]   Expert 34 |     35 | CPU
DEBUG 01-13 08:46:17.635645.635645 lmp.py:1622]   Expert 13 |     40 | CPU
DEBUG 01-13 08:46:17.635957.635957 lmp.py:1622]   Expert 54 |     78 | CPU
DEBUG 01-13 08:46:17.635792.635792 lmp.py:1622]   Expert 39 |     83 | CPU
DEBUG 01-13 08:46:17.635388.635388 lmp.py:1622]   Expert 18 |     84 | CPU
DEBUG 01-13 08:46:17.635700.635700 lmp.py:1622]   Expert 49 |     86 | CPU
DEBUG 01-13 08:46:17.635251.635251 lmp.py:1622]   Expert 21 |     96 | CPU
DEBUG 01-13 08:46:17.635562.635562 lmp.py:1622]   Expert 59 |    102 | CPU
DEBUG 01-13 08:46:17.635305.635305 lmp.py:1622]   Expert  0 |    110 | CPU
DEBUG 01-13 08:46:17.635140.635140 lmp.py:1622]   Expert 16 |    113 | CPU
DEBUG 01-13 08:46:17.635498.635498 lmp.py:1622]   Expert 15 |    115 | CPU
DEBUG 01-13 08:46:17.635572.635572 lmp.py:1622]   Expert 22 |    115 | CPU
DEBUG 01-13 08:46:17.635168.635168 lmp.py:1622]   Expert 45 |    115 | CPU
DEBUG 01-13 08:46:17.635527.635527 lmp.py:1622]   Expert 41 |    122 | CPU
DEBUG 01-13 08:46:17.636123.636123 lmp.py:1622]   Expert 17 |    126 | CPU
DEBUG 01-13 08:46:17.636720.636720 lmp.py:1622]   Expert 61 |    130 | CPU
DEBUG 01-13 08:46:17.636793.636793 lmp.py:1622]   Expert 52 |    131 | CPU
DEBUG 01-13 08:46:17.636105.636105 lmp.py:1622]   Expert  8 |    132 | CPU
DEBUG 01-13 08:46:17.636179.636179 lmp.py:1622]   Expert 35 |    135 | CPU
DEBUG 01-13 08:46:17.636967.636967 lmp.py:1622]   Expert 12 |    138 | CPU
DEBUG 01-13 08:46:17.636279.636279 lmp.py:1622]   Expert 48 |    142 | CPU
DEBUG 01-13 08:46:17.636591.636591 lmp.py:1622]   Expert 38 |    145 | CPU
DEBUG 01-13 08:46:17.636188.636188 lmp.py:1622]   Expert 31 |    151 | CPU
DEBUG 01-13 08:46:17.636023.636023 lmp.py:1622]   Expert 50 |    156 | CPU
DEBUG 01-13 08:46:17.636381.636381 lmp.py:1622]   Expert 40 |    158 | CPU
DEBUG 01-13 08:46:17.636216.636216 lmp.py:1622]   Expert 36 |    159 | CPU
DEBUG 01-13 08:46:17.636290.636290 lmp.py:1622]   Expert 53 |    161 | CPU
DEBUG 01-13 08:46:17.636363.636363 lmp.py:1622]   Expert 60 |    162 | CPU
DEBUG 01-13 08:46:17.636721.636721 lmp.py:1622]   Expert 27 |    175 | CPU
DEBUG 01-13 08:46:17.636318.636318 lmp.py:1622]   Expert 29 |    195 | CPU
DEBUG 01-13 08:46:17.636107.636107 lmp.py:1622]   Expert 19 |    197 | CPU
DEBUG 01-13 08:46:17.636657.636657 lmp.py:1622]   Expert 30 |    204 | GPU
DEBUG 01-13 08:46:17.636207.636207 lmp.py:1622]   Expert  4 |    210 | GPU
DEBUG 01-13 08:46:17.636519.636519 lmp.py:1622]   Expert 20 |    217 | GPU
DEBUG 01-13 08:46:17.636461.636461 lmp.py:1622]   Expert 11 |    224 | GPU
DEBUG 01-13 08:46:17.636634.636634 lmp.py:1622]   Expert 57 |    224 | GPU
DEBUG 01-13 08:46:17.636661.636661 lmp.py:1622]   Expert 46 |    226 | GPU
DEBUG 01-13 08:46:17.636734.636734 lmp.py:1622]   Expert 26 |    227 | GPU
DEBUG 01-13 08:46:17.636331.636331 lmp.py:1622]   Expert  6 |    228 | GPU
DEBUG 01-13 08:46:17.636689.636689 lmp.py:1622]   Expert 43 |    229 | GPU
DEBUG 01-13 08:46:17.636524.636524 lmp.py:1622]   Expert 33 |    231 | GPU
DEBUG 01-13 08:46:17.636121.636121 lmp.py:1622]   Expert 23 |    240 | GPU
DEBUG 01-13 08:46:17.636718.636718 lmp.py:1622]   Expert 42 |    245 | GPU
DEBUG 01-13 08:46:17.636791.636791 lmp.py:1622]   Expert  2 |    247 | GPU
DEBUG 01-13 08:46:17.636103.636103 lmp.py:1622]   Expert 55 |    247 | GPU
DEBUG 01-13 08:46:17.636415.636415 lmp.py:1622]   Expert 28 |    251 | GPU
DEBUG 01-13 08:46:17.636250.636250 lmp.py:1622]   Expert 56 |    254 | GPU
DEBUG 01-13 08:46:17.636085.636085 lmp.py:1622]   Expert  9 |    262 | GPU
DEBUG 01-13 08:46:17.636920.636920 lmp.py:1622]   Expert 44 |    264 | GPU
DEBUG 01-13 08:46:17.636517.636517 lmp.py:1622]   Expert 32 |    266 | GPU
DEBUG 01-13 08:46:17.636352.636352 lmp.py:1622]   Expert  3 |    270 | GPU
DEBUG 01-13 08:46:17.636187.636187 lmp.py:1622]   Expert 51 |    273 | GPU
DEBUG 01-13 08:46:17.636976.636976 lmp.py:1622]   Expert 14 |    278 | GPU
DEBUG 01-13 08:46:17.636572.636572 lmp.py:1622]   Expert  1 |    283 | GPU
DEBUG 01-13 08:46:17.636930.636930 lmp.py:1622]   Expert 58 |    285 | GPU
DEBUG 01-13 08:46:17.636050.636050 lmp.py:1622]   Expert 62 |    290 | GPU
DEBUG 01-13 08:46:17.636170.636170 lmp.py:1622]   Expert 63 |    291 | GPU
DEBUG 01-13 08:46:17.636528.636528 lmp.py:1622]   Expert 47 |    293 | GPU
DEBUG 01-13 08:46:17.636363.636363 lmp.py:1622]   Expert 37 |    303 | GPU
DEBUG 01-13 08:46:17.636914.636914 lmp.py:1622]   Expert 24 |    310 | GPU
DEBUG 01-13 08:46:17.636464.636464 lmp.py:1622]   Expert 10 |    311 | GPU
DEBUG 01-13 08:46:17.636776.636776 lmp.py:1622]   Expert 25 |    319 | GPU
DEBUG 01-13 08:46:17.636088.636088 lmp.py:1622]   Expert  5 |    367 | GPU
DEBUG 01-13 08:46:17.636353.636353 lmp.py:1623] 
DEBUG 01-13 08:46:17.636353.636353 lmp.py:1623]   CPU total tokens: 3919 (31.9%)
DEBUG 01-13 08:46:17.636857.636857 lmp.py:1624]   GPU total tokens: 8369 (68.1%)
DEBUG 01-13 08:46:17.636891.636891 cuda_h.py:19] end experts_map_get cost 0.0017077922821044922 seconds
DEBUG 01-13 08:46:17.637417.637417 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-13 08:46:17.637458.637458 lmp.py:1632] 
DEBUG 01-13 08:46:17.637458.637458 lmp.py:1632]   Computing 32 experts on CPU MP...
DEBUG 01-13 08:46:17.637724.637724 cuda_h.py:19] end cpu_experts_submit cost 5.650520324707031e-05 seconds
DEBUG 01-13 08:46:17.637944.637944 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-13 08:46:17.637370.637370 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-13 08:46:17.637952.637952 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-13 08:46:17.638623.638623 cuda_h.py:19] end allocate_cuda_memory cost 0.00140380859375 seconds
DEBUG 01-13 08:46:17.639476.639476 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-13 08:46:17.639207.639207 sllm_store_c.py:27] get device uuid map
DEBUG 01-13 08:46:17.639798.639798 sllm_store_c.py:29] call client load into gpu
DEBUG 01-13 08:46:17.639409.639409 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 69d7d316-fa89-4ff8-a634-0218bb5d2219
DEBUG 01-13 08:46:17.639263.639263 client.py:106] call stub.LoadModelAsync
DEBUG 01-13 08:46:17.639395.639395 cuda_h.py:10] start experts_func_gpu_einsum_mp
INFO 01-13 08:46:17.640166.640166 client.py:127] Model loaded
DEBUG 01-13 08:46:17.640931.640931 cuda_h.py:10] start restore2model
DEBUG 01-13 08:46:17.640170.640170 cuda_h.py:19] end restore2model cost 0.0005795955657958984 seconds
DEBUG 01-13 08:46:17.640437.640437 cuda_h.py:19] end sllm_worker_task cost 0.011091470718383789 seconds
INFO 01-13 08:46:17.641147.641147 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 69d7d316-fa89-4ff8-a634-0218bb5d2219
DEBUG 01-13 08:46:17.641549.641549 cuda_h.py:19] end load_into_gpu_async cost 0.0016870498657226562 seconds
DEBUG 01-13 08:46:17.641272.641272 cuda_h.py:10] start restore_tensors2
DEBUG 01-13 08:46:17.641892.641892 cuda_h.py:19] end restore_tensors2 cost 0.0004916191101074219 seconds
DEBUG 01-13 08:46:17.641451.641451 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0045583248138427734 seconds
DEBUG 01-13 08:46:17.641625.641625 cuda_h.py:10] start restore2model
DEBUG 01-13 08:46:17.645586.645586 mlpmodule.py:1006] group tensors cost 0.004737377166748047 s
DEBUG 01-13 08:46:17.646440.646440 cuda_h.py:19] end restore2model cost 0.004304409027099609 seconds
DEBUG 01-13 08:46:17.646635.646635 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.009154796600341797 seconds
DEBUG 01-13 08:46:17.646696.646696 cuda_h.py:10] start gpu_sexperts
DEBUG 01-13 08:46:17.646754.646754 cuda_h.py:19] end gpu_sexperts cost 0.0004742145538330078 seconds
DEBUG 01-13 08:46:17.647399.647399 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-13 08:46:17.647131.647131 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 3.0517578125e-05 seconds
DEBUG 01-13 08:46:17.647423.647423 cuda_h.py:10] start wait_experts
INFO 01-13 08:46:17.647385.647385 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 69d7d316-fa89-4ff8-a634-0218bb5d2219
DEBUG 01-13 08:46:17.647037.647037 mlpmodule.py:1044] pad cost 0.0018067359924316406 s
DEBUG 01-13 08:46:17.647934.647934 mlpmodule.py:1050] create cpu tensor cost 4.172325134277344e-05 s
DEBUG 01-13 08:46:17.647307.647307 mlpmodule.py:1055] move to cpu cost 2.9802322387695312e-05 s
DEBUG 01-13 08:46:17.656329.656329 mlpmodule.py:1069] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-13 08:46:17.656932.656932 mlpmodule.py:1070] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-13 08:46:17.656366.656366 mlpmodule.py:1075] group_w3 first element: 0.000789642333984375
WARNING 01-13 08:46:17.656165.656165 mlpmodule.py:1085] start einsum2
DEBUG 01-13 08:46:17.673441.673441 mlpmodule.py:1095] group einsum cost 0.025862693786621094 s
DEBUG 01-13 08:46:17.674896.674896 mlpmodule.py:1103] cpy2cputensor cost 0.0007207393646240234 s
INFO 01-13 08:46:17.693146.693146 client.py:127] Model loaded
DEBUG 01-13 08:46:17.693433.693433 cuda_h.py:19] end wait_experts cost 0.04648947715759277 seconds
DEBUG 01-13 08:46:17.693416.693416 cuda_h.py:10] start gpu_experts
DEBUG 01-13 08:46:17.695196.695196 mlpmodule.py:559] gpu group tensors cost 0.0015211105346679688 s
DEBUG 01-13 08:46:17.698661.698661 mlpmodule.py:785]  experts func einsum cost 0.058419227600097656 s
DEBUG 01-13 08:46:17.699482.699482 cuda_h.py:19] end experts_func_gpu_einsum_mp cost 0.059302568435668945 seconds
DEBUG 01-13 08:46:17.700746.700746 mlpmodule.py:592] gpu pad cost 0.004394054412841797 s
DEBUG 01-13 08:46:17.700155.700155 mlpmodule.py:598] start_w1
DEBUG 01-13 08:46:17.701266.701266 mlpmodule.py:602] start_w3
DEBUG 01-13 08:46:17.701526.701526 mlpmodule.py:608] start_w2
DEBUG 01-13 08:46:17.701083.701083 mlpmodule.py:611] gpu group einsum cost 0.0015959739685058594 s
DEBUG 01-13 08:46:17.706709.706709 mlpmodule.py:683] gpu experts func einsum cost 0.012307882308959961 s
DEBUG 01-13 08:46:17.706613.706613 cuda_h.py:19] end gpu_experts cost 0.012540102005004883 seconds
DEBUG 01-13 08:46:17.706568.706568 cuda_h.py:10] start cpu_thread_manager_mp_wait
DEBUG 01-13 08:46:17.706598.706598 cuda_h.py:19] end cpu_thread_manager_mp_wait cost 5.340576171875e-05 seconds
DEBUG 01-13 08:46:17.706118.706118 cuda_h.py:19] end layer_moe_generate_mp_l_15 cost 0.0721735954284668 seconds
DEBUG 01-13 08:46:17.706605.706605 lmp.py:1550] -------------------------------- end prefill layer 14 --------------------------------
DEBUG 01-13 08:46:17.707104.707104 lmp.py:1493] -------------------------------- start prefill layer 15 --------------------------------
DEBUG 01-13 08:46:17.707005.707005 cuda_h.py:10] start start_load_qkvogn_s_weight_l_16
DEBUG 01-13 08:46:17.707868.707868 cuda_h.py:10] start start_load_qkvogn_s_weight_l_16
DEBUG 01-13 08:46:17.707069.707069 cuda_h.py:19] end start_load_qkvogn_s_weight_l_16 cost 4.6253204345703125e-05 seconds
DEBUG 01-13 08:46:17.707256.707256 cuda_h.py:19] end start_load_qkvogn_s_weight_l_16 cost 8.20159912109375e-05 seconds
DEBUG 01-13 08:46:17.707813.707813 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-13 08:46:17.707506.707506 cuda_h.py:10] start sllm_worker_task
DEBUG 01-13 08:46:17.707470.707470 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-13 08:46:17.707858.707858 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-13 08:46:17.708562.708562 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-13 08:46:17.708171.708171 cuda_h.py:19] end allocate_cuda_memory cost 0.000316619873046875 seconds
DEBUG 01-13 08:46:17.708015.708015 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-13 08:46:17.708653.708653 sllm_store_c.py:27] get device uuid map
DEBUG 01-13 08:46:17.708868.708868 sllm_store_c.py:29] call client load into gpu
DEBUG 01-13 08:46:17.708684.708684 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, c9781657-b253-45fa-b207-f1f96abb722e
DEBUG 01-13 08:46:17.708476.708476 client.py:106] call stub.LoadModelAsync
DEBUG 01-13 08:46:17.709736.709736 cuda_h.py:10] start self_attn
INFO 01-13 08:46:17.710543.710543 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, c9781657-b253-45fa-b207-f1f96abb722e
DEBUG 01-13 08:46:17.710642.710642 cuda_h.py:19] end load_into_gpu_async cost 0.0018339157104492188 seconds
DEBUG 01-13 08:46:17.710407.710407 cuda_h.py:10] start restore_tensors2
DEBUG 01-13 08:46:17.710347.710347 cuda_h.py:19] end restore_tensors2 cost 0.00010466575622558594 seconds
DEBUG 01-13 08:46:17.710547.710547 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.002730131149291992 seconds
INFO 01-13 08:46:17.710311.710311 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, c9781657-b253-45fa-b207-f1f96abb722e
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-13 08:46:17.715828.715828 cuda_h.py:19] end self_attn cost 0.0055713653564453125 seconds
DEBUG 01-13 08:46:17.715552.715552 cuda_h.py:19] end iln_self_attn_paln cost 0.008407115936279297 seconds
DEBUG 01-13 08:46:17.715078.715078 cuda_h.py:10] start layer_moe_generate_mp_l_16
DEBUG 01-13 08:46:17.715278.715278 cuda_h.py:10] start gate
DEBUG 01-13 08:46:17.716493.716493 cuda_h.py:19] end gate cost 0.0008537769317626953 seconds
DEBUG 01-13 08:46:17.716621.716621 cuda_h.py:10] start experts_map_get
DEBUG 01-13 08:46:17.717621.717621 lmp.py:1611] 
DEBUG 01-13 08:46:17.717621.717621 lmp.py:1611] Expert Token Distribution & Device Allocation:
DEBUG 01-13 08:46:17.717292.717292 lmp.py:1612]   Total experts: 64
DEBUG 01-13 08:46:17.717663.717663 lmp.py:1613]   CPU experts: 32 (50%)
DEBUG 01-13 08:46:17.717174.717174 lmp.py:1614]   GPU experts: 32 (50%)
DEBUG 01-13 08:46:17.717301.717301 lmp.py:1615] 
DEBUG 01-13 08:46:17.717301.717301 lmp.py:1615]   Expert ID | Tokens | Device
DEBUG 01-13 08:46:17.717619.717619 lmp.py:1616]   -----------------------------------
DEBUG 01-13 08:46:17.717660.717660 lmp.py:1622]   Expert 15 |     61 | CPU
DEBUG 01-13 08:46:17.717595.717595 lmp.py:1622]   Expert 41 |     70 | CPU
DEBUG 01-13 08:46:17.717814.717814 lmp.py:1622]   Expert 63 |     74 | CPU
DEBUG 01-13 08:46:17.717894.717894 lmp.py:1622]   Expert  0 |     79 | CPU
DEBUG 01-13 08:46:17.717544.717544 lmp.py:1622]   Expert 20 |     81 | CPU
DEBUG 01-13 08:46:17.717432.717432 lmp.py:1622]   Expert 45 |     88 | CPU
DEBUG 01-13 08:46:17.717797.717797 lmp.py:1622]   Expert 54 |     90 | CPU
DEBUG 01-13 08:46:17.717685.717685 lmp.py:1622]   Expert  7 |    100 | CPU
DEBUG 01-13 08:46:17.717812.717812 lmp.py:1622]   Expert 12 |    107 | CPU
DEBUG 01-13 08:46:17.717939.717939 lmp.py:1622]   Expert 28 |    108 | CPU
DEBUG 01-13 08:46:17.717019.717019 lmp.py:1622]   Expert 40 |    111 | CPU
DEBUG 01-13 08:46:17.717384.717384 lmp.py:1622]   Expert  5 |    119 | CPU
DEBUG 01-13 08:46:17.717272.717272 lmp.py:1622]   Expert 52 |    123 | CPU
DEBUG 01-13 08:46:17.717922.717922 lmp.py:1622]   Expert 62 |    126 | CPU
DEBUG 01-13 08:46:17.717810.717810 lmp.py:1622]   Expert  4 |    127 | CPU
DEBUG 01-13 08:46:17.717698.717698 lmp.py:1622]   Expert 59 |    128 | CPU
DEBUG 01-13 08:46:17.717348.717348 lmp.py:1622]   Expert 34 |    129 | CPU
DEBUG 01-13 08:46:17.717998.717998 lmp.py:1622]   Expert 42 |    133 | CPU
DEBUG 01-13 08:46:17.717647.717647 lmp.py:1622]   Expert 13 |    134 | CPU
DEBUG 01-13 08:46:17.717297.717297 lmp.py:1622]   Expert 61 |    138 | CPU
DEBUG 01-13 08:46:17.717424.717424 lmp.py:1622]   Expert 55 |    139 | CPU
DEBUG 01-13 08:46:17.717266.717266 lmp.py:1622]   Expert 21 |    140 | CPU
DEBUG 01-13 08:46:17.718869.718869 lmp.py:1622]   Expert 10 |    143 | CPU
DEBUG 01-13 08:46:17.718996.718996 lmp.py:1622]   Expert 22 |    147 | CPU
DEBUG 01-13 08:46:17.718646.718646 lmp.py:1622]   Expert 14 |    150 | CPU
DEBUG 01-13 08:46:17.718295.718295 lmp.py:1622]   Expert 51 |    159 | CPU
DEBUG 01-13 08:46:17.718707.718707 lmp.py:1622]   Expert 32 |    161 | CPU
DEBUG 01-13 08:46:17.718356.718356 lmp.py:1622]   Expert 25 |    163 | CPU
DEBUG 01-13 08:46:17.718529.718529 lmp.py:1622]   Expert 50 |    168 | CPU
DEBUG 01-13 08:46:17.718179.718179 lmp.py:1622]   Expert 53 |    169 | CPU
DEBUG 01-13 08:46:17.718544.718544 lmp.py:1622]   Expert 19 |    175 | CPU
DEBUG 01-13 08:46:17.718909.718909 lmp.py:1622]   Expert  1 |    178 | CPU
DEBUG 01-13 08:46:17.718797.718797 lmp.py:1622]   Expert  2 |    178 | GPU
DEBUG 01-13 08:46:17.718209.718209 lmp.py:1622]   Expert 47 |    181 | GPU
DEBUG 01-13 08:46:17.718858.718858 lmp.py:1622]   Expert 26 |    183 | GPU
DEBUG 01-13 08:46:17.718270.718270 lmp.py:1622]   Expert 30 |    184 | GPU
DEBUG 01-13 08:46:17.718158.718158 lmp.py:1622]   Expert 11 |    186 | GPU
DEBUG 01-13 08:46:17.718808.718808 lmp.py:1622]   Expert  6 |    187 | GPU
DEBUG 01-13 08:46:17.718457.718457 lmp.py:1622]   Expert 35 |    187 | GPU
DEBUG 01-13 08:46:17.718107.718107 lmp.py:1622]   Expert 57 |    190 | GPU
DEBUG 01-13 08:46:17.718711.718711 lmp.py:1622]   Expert 56 |    200 | GPU
DEBUG 01-13 08:46:17.718076.718076 lmp.py:1622]   Expert 48 |    201 | GPU
DEBUG 01-13 08:46:17.718918.718918 lmp.py:1622]   Expert 24 |    207 | GPU
DEBUG 01-13 08:46:17.718806.718806 lmp.py:1622]   Expert 46 |    211 | GPU
DEBUG 01-13 08:46:17.718694.718694 lmp.py:1622]   Expert 44 |    213 | GPU
DEBUG 01-13 08:46:17.718105.718105 lmp.py:1622]   Expert 39 |    219 | GPU
DEBUG 01-13 08:46:17.718755.718755 lmp.py:1622]   Expert 16 |    228 | GPU
DEBUG 01-13 08:46:17.718166.718166 lmp.py:1622]   Expert 18 |    228 | GPU
DEBUG 01-13 08:46:17.718816.718816 lmp.py:1622]   Expert 29 |    236 | GPU
DEBUG 01-13 08:46:17.718420.718420 lmp.py:1622]   Expert 37 |    236 | GPU
DEBUG 01-13 08:46:17.718785.718785 lmp.py:1622]   Expert 31 |    249 | GPU
DEBUG 01-13 08:46:17.718150.718150 lmp.py:1622]   Expert 60 |    253 | GPU
DEBUG 01-13 08:46:17.718799.718799 lmp.py:1622]   Expert 38 |    258 | GPU
DEBUG 01-13 08:46:17.718734.718734 lmp.py:1622]   Expert  3 |    259 | GPU
DEBUG 01-13 08:46:17.718907.718907 lmp.py:1622]   Expert 17 |    259 | GPU
DEBUG 01-13 08:46:17.718318.718318 lmp.py:1622]   Expert 36 |    260 | GPU
DEBUG 01-13 08:46:17.718730.718730 lmp.py:1622]   Expert  9 |    262 | GPU
DEBUG 01-13 08:46:17.718902.718902 lmp.py:1622]   Expert 23 |    265 | GPU
DEBUG 01-13 08:46:17.718075.718075 lmp.py:1622]   Expert 27 |    355 | GPU
DEBUG 01-13 08:46:17.718725.718725 lmp.py:1622]   Expert 43 |    362 | GPU
DEBUG 01-13 08:46:17.718852.718852 lmp.py:1622]   Expert 33 |    405 | GPU
DEBUG 01-13 08:46:17.718502.718502 lmp.py:1622]   Expert 58 |    439 | GPU
DEBUG 01-13 08:46:17.718674.718674 lmp.py:1622]   Expert  8 |    443 | GPU
DEBUG 01-13 08:46:17.718609.718609 lmp.py:1622]   Expert 49 |    546 | GPU
DEBUG 01-13 08:46:17.718974.718974 lmp.py:1623] 
DEBUG 01-13 08:46:17.718974.718974 lmp.py:1623]   CPU total tokens: 4018 (32.7%)
DEBUG 01-13 08:46:17.719054.719054 lmp.py:1624]   GPU total tokens: 8270 (67.3%)
DEBUG 01-13 08:46:17.719903.719903 cuda_h.py:19] end experts_map_get cost 0.0022432804107666016 seconds
DEBUG 01-13 08:46:17.719111.719111 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-13 08:46:17.719496.719496 lmp.py:1632] 
DEBUG 01-13 08:46:17.719496.719496 lmp.py:1632]   Computing 32 experts on CPU MP...
DEBUG 01-13 08:46:17.719869.719869 cuda_h.py:19] end cpu_experts_submit cost 6.246566772460938e-05 seconds
DEBUG 01-13 08:46:17.719288.719288 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-13 08:46:17.719893.719893 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-13 08:46:17.719256.719256 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-13 08:46:17.720226.720226 cuda_h.py:19] end allocate_cuda_memory cost 0.00025153160095214844 seconds
DEBUG 01-13 08:46:17.720844.720844 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-13 08:46:17.720322.720322 sllm_store_c.py:27] get device uuid map
DEBUG 01-13 08:46:17.720490.720490 sllm_store_c.py:29] call client load into gpu
DEBUG 01-13 08:46:17.720292.720292 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 8db77435-f069-4d98-8b9d-9f8c81296ece
DEBUG 01-13 08:46:17.720027.720027 cuda_h.py:10] start experts_func_gpu_einsum_mp
DEBUG 01-13 08:46:17.720286.720286 client.py:106] call stub.LoadModelAsync
INFO 01-13 08:46:17.720116.720116 client.py:127] Model loaded
DEBUG 01-13 08:46:17.720220.720220 cuda_h.py:10] start restore2model
DEBUG 01-13 08:46:17.722044.722044 cuda_h.py:19] end restore2model cost 0.0009622573852539062 seconds
INFO 01-13 08:46:17.722234.722234 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 8db77435-f069-4d98-8b9d-9f8c81296ece
DEBUG 01-13 08:46:17.722045.722045 cuda_h.py:19] end sllm_worker_task cost 0.014518499374389648 seconds
DEBUG 01-13 08:46:17.722956.722956 cuda_h.py:19] end load_into_gpu_async cost 0.0021092891693115234 seconds
DEBUG 01-13 08:46:17.722384.722384 cuda_h.py:10] start restore_tensors2
DEBUG 01-13 08:46:17.722108.722108 cuda_h.py:19] end restore_tensors2 cost 0.00042724609375 seconds
DEBUG 01-13 08:46:17.723805.723805 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0032694339752197266 seconds
DEBUG 01-13 08:46:17.723667.723667 cuda_h.py:10] start restore2model
DEBUG 01-13 08:46:17.726942.726942 cuda_h.py:19] end restore2model cost 0.003220796585083008 seconds
DEBUG 01-13 08:46:17.726540.726540 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.006700992584228516 seconds
DEBUG 01-13 08:46:17.726574.726574 cuda_h.py:10] start gpu_sexperts
DEBUG 01-13 08:46:17.726811.726811 cuda_h.py:19] end gpu_sexperts cost 0.0003170967102050781 seconds
DEBUG 01-13 08:46:17.726501.726501 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-13 08:46:17.726324.726324 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 1.52587890625e-05 seconds
DEBUG 01-13 08:46:17.726258.726258 cuda_h.py:10] start wait_experts
INFO 01-13 08:46:17.726915.726915 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 8db77435-f069-4d98-8b9d-9f8c81296ece
DEBUG 01-13 08:46:17.728277.728277 mlpmodule.py:1006] group tensors cost 0.007194042205810547 s
DEBUG 01-13 08:46:17.731402.731402 mlpmodule.py:1044] pad cost 0.002655029296875 s
DEBUG 01-13 08:46:17.731268.731268 mlpmodule.py:1050] create cpu tensor cost 6.175041198730469e-05 s
DEBUG 01-13 08:46:17.732980.732980 mlpmodule.py:1055] move to cpu cost 4.291534423828125e-05 s
DEBUG 01-13 08:46:17.742982.742982 mlpmodule.py:1069] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-13 08:46:17.742604.742604 mlpmodule.py:1070] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-13 08:46:17.742077.742077 mlpmodule.py:1075] group_w3 first element: -0.0595703125
WARNING 01-13 08:46:17.742111.742111 mlpmodule.py:1085] start einsum2
DEBUG 01-13 08:46:17.757335.757335 mlpmodule.py:1095] group einsum cost 0.025726795196533203 s
DEBUG 01-13 08:46:17.758609.758609 mlpmodule.py:1103] cpy2cputensor cost 0.0006513595581054688 s
INFO 01-13 08:46:17.774984.774984 client.py:127] Model loaded
DEBUG 01-13 08:46:17.774240.774240 cuda_h.py:19] end wait_experts cost 0.04727673530578613 seconds
DEBUG 01-13 08:46:17.774142.774142 cuda_h.py:10] start gpu_experts
DEBUG 01-13 08:46:17.774662.774662 mlpmodule.py:559] gpu group tensors cost 0.0006070137023925781 s
DEBUG 01-13 08:46:17.776039.776039 mlpmodule.py:592] gpu pad cost 0.0015096664428710938 s
DEBUG 01-13 08:46:17.776565.776565 mlpmodule.py:598] start_w1
DEBUG 01-13 08:46:17.776246.776246 mlpmodule.py:602] start_w3
DEBUG 01-13 08:46:17.777463.777463 mlpmodule.py:608] start_w2
DEBUG 01-13 08:46:17.777912.777912 mlpmodule.py:611] gpu group einsum cost 0.0006759166717529297 s
DEBUG 01-13 08:46:17.779686.779686 mlpmodule.py:683] gpu experts func einsum cost 0.00508880615234375 s
DEBUG 01-13 08:46:17.779782.779782 cuda_h.py:19] end gpu_experts cost 0.005228281021118164 seconds
DEBUG 01-13 08:46:17.779154.779154 cuda_h.py:10] start cpu_thread_manager_mp_wait
DEBUG 01-13 08:46:17.779150.779150 cuda_h.py:19] end cpu_thread_manager_mp_wait cost 3.6716461181640625e-05 seconds
DEBUG 01-13 08:46:17.779782.779782 cuda_h.py:19] end layer_moe_generate_mp_l_16 cost 0.06389594078063965 seconds
DEBUG 01-13 08:46:17.779915.779915 lmp.py:1550] -------------------------------- end prefill layer 15 --------------------------------
DEBUG 01-13 08:46:17.779824.779824 lmp.py:1493] -------------------------------- start prefill layer 16 --------------------------------
DEBUG 01-13 08:46:17.779381.779381 cuda_h.py:10] start start_load_qkvogn_s_weight_l_17
DEBUG 01-13 08:46:17.780707.780707 cuda_h.py:10] start start_load_qkvogn_s_weight_l_17
DEBUG 01-13 08:46:17.780066.780066 cuda_h.py:19] end start_load_qkvogn_s_weight_l_17 cost 3.0279159545898438e-05 seconds
DEBUG 01-13 08:46:17.780577.780577 cuda_h.py:19] end start_load_qkvogn_s_weight_l_17 cost 5.8650970458984375e-05 seconds
DEBUG 01-13 08:46:17.780220.780220 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-13 08:46:17.780685.780685 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-13 08:46:17.780403.780403 cuda_h.py:10] start sllm_worker_task
DEBUG 01-13 08:46:17.780671.780671 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-13 08:46:17.780898.780898 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-13 08:46:17.780639.780639 cuda_h.py:19] end allocate_cuda_memory cost 0.0003330707550048828 seconds
DEBUG 01-13 08:46:17.780343.780343 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-13 08:46:17.780291.780291 sllm_store_c.py:27] get device uuid map
DEBUG 01-13 08:46:17.780684.780684 sllm_store_c.py:29] call client load into gpu
DEBUG 01-13 08:46:17.780956.780956 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, e5c5ba53-b351-484d-bb9e-cb5e80078269
DEBUG 01-13 08:46:17.781595.781595 client.py:106] call stub.LoadModelAsync
DEBUG 01-13 08:46:17.781392.781392 cuda_h.py:10] start self_attn
DEBUG 01-13 08:46:17.781122.781122 mlpmodule.py:785]  experts func einsum cost 0.0603330135345459 s
DEBUG 01-13 08:46:17.781788.781788 cuda_h.py:19] end experts_func_gpu_einsum_mp cost 0.061167240142822266 seconds
INFO 01-13 08:46:17.782516.782516 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, e5c5ba53-b351-484d-bb9e-cb5e80078269
DEBUG 01-13 08:46:17.782114.782114 cuda_h.py:19] end load_into_gpu_async cost 0.0016243457794189453 seconds
DEBUG 01-13 08:46:17.782671.782671 cuda_h.py:10] start restore_tensors2
DEBUG 01-13 08:46:17.782152.782152 cuda_h.py:19] end restore_tensors2 cost 8.249282836914062e-05 seconds
DEBUG 01-13 08:46:17.782477.782477 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0022809505462646484 seconds
INFO 01-13 08:46:17.782982.782982 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, e5c5ba53-b351-484d-bb9e-cb5e80078269
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-13 08:46:17.784845.784845 cuda_h.py:19] end self_attn cost 0.002802610397338867 seconds
DEBUG 01-13 08:46:17.784962.784962 cuda_h.py:19] end iln_self_attn_paln cost 0.004346370697021484 seconds
DEBUG 01-13 08:46:17.784183.784183 cuda_h.py:10] start layer_moe_generate_mp_l_17
DEBUG 01-13 08:46:17.784561.784561 cuda_h.py:10] start gate
DEBUG 01-13 08:46:17.785881.785881 cuda_h.py:19] end gate cost 0.0006239414215087891 seconds
DEBUG 01-13 08:46:17.785327.785327 cuda_h.py:10] start experts_map_get
DEBUG 01-13 08:46:17.785588.785588 lmp.py:1611] 
DEBUG 01-13 08:46:17.785588.785588 lmp.py:1611] Expert Token Distribution & Device Allocation:
DEBUG 01-13 08:46:17.785119.785119 lmp.py:1612]   Total experts: 64
DEBUG 01-13 08:46:17.785815.785815 lmp.py:1613]   CPU experts: 32 (50%)
DEBUG 01-13 08:46:17.785889.785889 lmp.py:1614]   GPU experts: 32 (50%)
DEBUG 01-13 08:46:17.785294.785294 lmp.py:1615] 
DEBUG 01-13 08:46:17.785294.785294 lmp.py:1615]   Expert ID | Tokens | Device
DEBUG 01-13 08:46:17.785698.785698 lmp.py:1616]   -----------------------------------
DEBUG 01-13 08:46:17.785825.785825 lmp.py:1622]   Expert 58 |     33 | CPU
DEBUG 01-13 08:46:17.785229.785229 lmp.py:1622]   Expert 47 |     58 | CPU
DEBUG 01-13 08:46:17.785680.785680 lmp.py:1622]   Expert 31 |     64 | CPU
DEBUG 01-13 08:46:17.785177.785177 lmp.py:1622]   Expert 49 |     64 | CPU
DEBUG 01-13 08:46:17.785390.785390 lmp.py:1622]   Expert  4 |     68 | CPU
DEBUG 01-13 08:46:17.785887.785887 lmp.py:1622]   Expert 38 |     69 | CPU
DEBUG 01-13 08:46:17.785623.785623 lmp.py:1622]   Expert 45 |     74 | CPU
DEBUG 01-13 08:46:17.785881.785881 lmp.py:1622]   Expert 43 |     78 | CPU
DEBUG 01-13 08:46:17.785855.785855 lmp.py:1622]   Expert 41 |     86 | CPU
DEBUG 01-13 08:46:17.785353.785353 lmp.py:1622]   Expert 50 |    100 | CPU
DEBUG 01-13 08:46:17.785757.785757 lmp.py:1622]   Expert 33 |    101 | CPU
DEBUG 01-13 08:46:17.785970.785970 lmp.py:1622]   Expert 11 |    108 | CPU
DEBUG 01-13 08:46:17.785182.785182 lmp.py:1622]   Expert 51 |    111 | CPU
DEBUG 01-13 08:46:17.785156.785156 lmp.py:1622]   Expert 57 |    113 | CPU
DEBUG 01-13 08:46:17.785607.785607 lmp.py:1622]   Expert  2 |    116 | CPU
DEBUG 01-13 08:46:17.785343.785343 lmp.py:1622]   Expert 54 |    120 | CPU
DEBUG 01-13 08:46:17.785602.785602 lmp.py:1622]   Expert 14 |    126 | CPU
DEBUG 01-13 08:46:17.785860.785860 lmp.py:1622]   Expert 56 |    128 | CPU
DEBUG 01-13 08:46:17.786596.786596 lmp.py:1622]   Expert  0 |    129 | CPU
DEBUG 01-13 08:46:17.786000.786000 lmp.py:1622]   Expert 34 |    133 | CPU
DEBUG 01-13 08:46:17.786167.786167 lmp.py:1622]   Expert 26 |    142 | CPU
DEBUG 01-13 08:46:17.786379.786379 lmp.py:1622]   Expert 28 |    158 | CPU
DEBUG 01-13 08:46:17.786592.786592 lmp.py:1622]   Expert 27 |    160 | CPU
DEBUG 01-13 08:46:17.786042.786042 lmp.py:1622]   Expert 55 |    168 | CPU
DEBUG 01-13 08:46:17.786447.786447 lmp.py:1622]   Expert 10 |    171 | CPU
DEBUG 01-13 08:46:17.786375.786375 lmp.py:1622]   Expert 25 |    171 | CPU
DEBUG 01-13 08:46:17.786302.786302 lmp.py:1622]   Expert 13 |    179 | CPU
DEBUG 01-13 08:46:17.786230.786230 lmp.py:1622]   Expert  9 |    180 | CPU
DEBUG 01-13 08:46:17.786443.786443 lmp.py:1622]   Expert  6 |    182 | CPU
DEBUG 01-13 08:46:17.786655.786655 lmp.py:1622]   Expert 61 |    190 | CPU
DEBUG 01-13 08:46:17.786868.786868 lmp.py:1622]   Expert 24 |    191 | CPU
DEBUG 01-13 08:46:17.786080.786080 lmp.py:1622]   Expert  7 |    192 | CPU
DEBUG 01-13 08:46:17.786769.786769 lmp.py:1622]   Expert 46 |    193 | GPU
DEBUG 01-13 08:46:17.786982.786982 lmp.py:1622]   Expert 48 |    195 | GPU
DEBUG 01-13 08:46:17.786194.786194 lmp.py:1622]   Expert 42 |    202 | GPU
DEBUG 01-13 08:46:17.786645.786645 lmp.py:1622]   Expert 18 |    206 | GPU
DEBUG 01-13 08:46:17.786619.786619 lmp.py:1622]   Expert 22 |    212 | GPU
DEBUG 01-13 08:46:17.786262.786262 lmp.py:1622]   Expert 40 |    212 | GPU
DEBUG 01-13 08:46:17.786428.786428 lmp.py:1622]   Expert 63 |    212 | GPU
DEBUG 01-13 08:46:17.786356.786356 lmp.py:1622]   Expert 59 |    213 | GPU
DEBUG 01-13 08:46:17.786999.786999 lmp.py:1622]   Expert 21 |    214 | GPU
DEBUG 01-13 08:46:17.786211.786211 lmp.py:1622]   Expert 12 |    217 | GPU
DEBUG 01-13 08:46:17.786662.786662 lmp.py:1622]   Expert 32 |    222 | GPU
DEBUG 01-13 08:46:17.786113.786113 lmp.py:1622]   Expert 19 |    223 | GPU
DEBUG 01-13 08:46:17.786564.786564 lmp.py:1622]   Expert 29 |    223 | GPU
DEBUG 01-13 08:46:17.786777.786777 lmp.py:1622]   Expert 36 |    237 | GPU
DEBUG 01-13 08:46:17.786989.786989 lmp.py:1622]   Expert 37 |    243 | GPU
DEBUG 01-13 08:46:17.786440.786440 lmp.py:1622]   Expert  1 |    244 | GPU
DEBUG 01-13 08:46:17.786414.786414 lmp.py:1622]   Expert  3 |    246 | GPU
DEBUG 01-13 08:46:17.786626.786626 lmp.py:1622]   Expert 16 |    257 | GPU
DEBUG 01-13 08:46:17.786600.786600 lmp.py:1622]   Expert  5 |    265 | GPU
DEBUG 01-13 08:46:17.786813.786813 lmp.py:1622]   Expert  8 |    265 | GPU
DEBUG 01-13 08:46:17.786741.786741 lmp.py:1622]   Expert 30 |    266 | GPU
DEBUG 01-13 08:46:17.786668.786668 lmp.py:1622]   Expert 20 |    267 | GPU
DEBUG 01-13 08:46:17.786596.786596 lmp.py:1622]   Expert 15 |    269 | GPU
DEBUG 01-13 08:46:17.786762.786762 lmp.py:1622]   Expert 62 |    279 | GPU
DEBUG 01-13 08:46:17.786451.786451 lmp.py:1622]   Expert 35 |    293 | GPU
DEBUG 01-13 08:46:17.786902.786902 lmp.py:1622]   Expert 17 |    294 | GPU
DEBUG 01-13 08:46:17.786353.786353 lmp.py:1622]   Expert 39 |    299 | GPU
DEBUG 01-13 08:46:17.786804.786804 lmp.py:1622]   Expert 60 |    314 | GPU
DEBUG 01-13 08:46:17.786778.786778 lmp.py:1622]   Expert 52 |    359 | GPU
DEBUG 01-13 08:46:17.786991.786991 lmp.py:1622]   Expert 23 |    369 | GPU
DEBUG 01-13 08:46:17.786442.786442 lmp.py:1622]   Expert 44 |    377 | GPU
DEBUG 01-13 08:46:17.786654.786654 lmp.py:1622]   Expert 53 |    438 | GPU
DEBUG 01-13 08:46:17.786059.786059 lmp.py:1623] 
DEBUG 01-13 08:46:17.786059.786059 lmp.py:1623]   CPU total tokens: 3963 (32.3%)
DEBUG 01-13 08:46:17.786655.786655 lmp.py:1624]   GPU total tokens: 8325 (67.7%)
DEBUG 01-13 08:46:17.786782.786782 cuda_h.py:19] end experts_map_get cost 0.0015022754669189453 seconds
DEBUG 01-13 08:46:17.786055.786055 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-13 08:46:17.786666.786666 lmp.py:1632] 
DEBUG 01-13 08:46:17.786666.786666 lmp.py:1632]   Computing 32 experts on CPU MP...
DEBUG 01-13 08:46:17.786157.786157 cuda_h.py:19] end cpu_experts_submit cost 4.6253204345703125e-05 seconds
DEBUG 01-13 08:46:17.786469.786469 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-13 08:46:17.787060.787060 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-13 08:46:17.787019.787019 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-13 08:46:17.788804.788804 cuda_h.py:19] end allocate_cuda_memory cost 0.0008609294891357422 seconds
DEBUG 01-13 08:46:17.788170.788170 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-13 08:46:17.788449.788449 sllm_store_c.py:27] get device uuid map
DEBUG 01-13 08:46:17.788781.788781 sllm_store_c.py:29] call client load into gpu
DEBUG 01-13 08:46:17.788385.788385 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 7e323454-662f-43a6-865c-a7a3ce57a9b2
DEBUG 01-13 08:46:17.788417.788417 client.py:106] call stub.LoadModelAsync
DEBUG 01-13 08:46:17.789311.789311 cuda_h.py:10] start experts_func_gpu_einsum_mp
INFO 01-13 08:46:17.790043.790043 client.py:127] Model loaded
DEBUG 01-13 08:46:17.790787.790787 cuda_h.py:10] start restore2model
DEBUG 01-13 08:46:17.791676.791676 cuda_h.py:19] end restore2model cost 0.00040602684020996094 seconds
DEBUG 01-13 08:46:17.791313.791313 cuda_h.py:19] end sllm_worker_task cost 0.010873556137084961 seconds
INFO 01-13 08:46:17.791072.791072 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 7e323454-662f-43a6-865c-a7a3ce57a9b2
DEBUG 01-13 08:46:17.791538.791538 cuda_h.py:19] end load_into_gpu_async cost 0.003643512725830078 seconds
DEBUG 01-13 08:46:17.791002.791002 cuda_h.py:10] start restore_tensors2
DEBUG 01-13 08:46:17.792669.792669 cuda_h.py:19] end restore_tensors2 cost 0.0002899169921875 seconds
DEBUG 01-13 08:46:17.792776.792776 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0051386356353759766 seconds
DEBUG 01-13 08:46:17.792678.792678 cuda_h.py:10] start restore2model
DEBUG 01-13 08:46:17.794185.794185 cuda_h.py:19] end restore2model cost 0.002450704574584961 seconds
DEBUG 01-13 08:46:17.794253.794253 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.007753133773803711 seconds
DEBUG 01-13 08:46:17.794638.794638 cuda_h.py:10] start gpu_sexperts
DEBUG 01-13 08:46:17.795793.795793 cuda_h.py:19] end gpu_sexperts cost 0.0002598762512207031 seconds
DEBUG 01-13 08:46:17.795716.795716 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-13 08:46:17.795770.795770 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 1.3828277587890625e-05 seconds
DEBUG 01-13 08:46:17.795035.795035 cuda_h.py:10] start wait_experts
INFO 01-13 08:46:17.795970.795970 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 7e323454-662f-43a6-865c-a7a3ce57a9b2
DEBUG 01-13 08:46:17.798928.798928 mlpmodule.py:1006] group tensors cost 0.00909423828125 s
DEBUG 01-13 08:46:17.800903.800903 mlpmodule.py:1044] pad cost 0.0015718936920166016 s
DEBUG 01-13 08:46:17.801270.801270 mlpmodule.py:1050] create cpu tensor cost 4.1484832763671875e-05 s
DEBUG 01-13 08:46:17.801928.801928 mlpmodule.py:1055] move to cpu cost 2.9325485229492188e-05 s
DEBUG 01-13 08:46:17.810922.810922 mlpmodule.py:1069] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-13 08:46:17.811786.811786 mlpmodule.py:1070] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-13 08:46:17.811499.811499 mlpmodule.py:1075] group_w3 first element: -0.02490234375
WARNING 01-13 08:46:17.811795.811795 mlpmodule.py:1085] start einsum2
DEBUG 01-13 08:46:17.826514.826514 mlpmodule.py:1095] group einsum cost 0.02532029151916504 s
DEBUG 01-13 08:46:17.827268.827268 mlpmodule.py:1103] cpy2cputensor cost 0.0006804466247558594 s
INFO 01-13 08:46:17.844271.844271 client.py:127] Model loaded
DEBUG 01-13 08:46:17.845365.845365 cuda_h.py:19] end wait_experts cost 0.04993438720703125 seconds
DEBUG 01-13 08:46:17.845348.845348 cuda_h.py:10] start gpu_experts
DEBUG 01-13 08:46:17.846822.846822 mlpmodule.py:559] gpu group tensors cost 0.001474618911743164 s
DEBUG 01-13 08:46:17.851611.851611 mlpmodule.py:592] gpu pad cost 0.004426717758178711 s
DEBUG 01-13 08:46:17.851160.851160 mlpmodule.py:598] start_w1
DEBUG 01-13 08:46:17.852602.852602 mlpmodule.py:602] start_w3
DEBUG 01-13 08:46:17.852193.852193 mlpmodule.py:608] start_w2
DEBUG 01-13 08:46:17.853696.853696 mlpmodule.py:611] gpu group einsum cost 0.0015869140625 s
DEBUG 01-13 08:46:17.853845.853845 mlpmodule.py:785]  experts func einsum cost 0.0637824535369873 s
DEBUG 01-13 08:46:17.853725.853725 cuda_h.py:19] end experts_func_gpu_einsum_mp cost 0.06432819366455078 seconds
DEBUG 01-13 08:46:17.858422.858422 mlpmodule.py:683] gpu experts func einsum cost 0.012888908386230469 s
DEBUG 01-13 08:46:17.858764.858764 cuda_h.py:19] end gpu_experts cost 0.013124704360961914 seconds
DEBUG 01-13 08:46:17.858719.858719 cuda_h.py:10] start cpu_thread_manager_mp_wait
DEBUG 01-13 08:46:17.858702.858702 cuda_h.py:19] end cpu_thread_manager_mp_wait cost 5.412101745605469e-05 seconds
DEBUG 01-13 08:46:17.858652.858652 cuda_h.py:19] end layer_moe_generate_mp_l_17 cost 0.07411909103393555 seconds
DEBUG 01-13 08:46:17.858344.858344 lmp.py:1550] -------------------------------- end prefill layer 16 --------------------------------
DEBUG 01-13 08:46:17.859220.859220 lmp.py:1493] -------------------------------- start prefill layer 17 --------------------------------
DEBUG 01-13 08:46:17.859268.859268 cuda_h.py:10] start start_load_qkvogn_s_weight_l_18
DEBUG 01-13 08:46:17.859415.859415 cuda_h.py:10] start start_load_qkvogn_s_weight_l_18
DEBUG 01-13 08:46:17.859470.859470 cuda_h.py:19] end start_load_qkvogn_s_weight_l_18 cost 4.458427429199219e-05 seconds
DEBUG 01-13 08:46:17.859001.859001 cuda_h.py:19] end start_load_qkvogn_s_weight_l_18 cost 8.678436279296875e-05 seconds
DEBUG 01-13 08:46:17.859042.859042 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-13 08:46:17.859019.859019 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-13 08:46:17.859083.859083 cuda_h.py:10] start sllm_worker_task
DEBUG 01-13 08:46:17.859186.859186 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-13 08:46:17.859933.859933 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-13 08:46:17.860477.860477 cuda_h.py:19] end allocate_cuda_memory cost 0.0003695487976074219 seconds
DEBUG 01-13 08:46:17.860553.860553 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-13 08:46:17.860283.860283 sllm_store_c.py:27] get device uuid map
DEBUG 01-13 08:46:17.860471.860471 sllm_store_c.py:29] call client load into gpu
DEBUG 01-13 08:46:17.860856.860856 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, eed96705-5ae1-4cf9-b66d-ba08d4e5550a
DEBUG 01-13 08:46:17.860357.860357 client.py:106] call stub.LoadModelAsync
DEBUG 01-13 08:46:17.861277.861277 cuda_h.py:10] start self_attn
INFO 01-13 08:46:17.862716.862716 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, eed96705-5ae1-4cf9-b66d-ba08d4e5550a
DEBUG 01-13 08:46:17.862048.862048 cuda_h.py:19] end load_into_gpu_async cost 0.0018453598022460938 seconds
DEBUG 01-13 08:46:17.862832.862832 cuda_h.py:10] start restore_tensors2
DEBUG 01-13 08:46:17.862396.862396 cuda_h.py:19] end restore_tensors2 cost 0.00016260147094726562 seconds
DEBUG 01-13 08:46:17.862738.862738 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.002935171127319336 seconds
INFO 01-13 08:46:17.862292.862292 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, eed96705-5ae1-4cf9-b66d-ba08d4e5550a
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-13 08:46:17.865580.865580 cuda_h.py:19] end self_attn cost 0.004619598388671875 seconds
DEBUG 01-13 08:46:17.866560.866560 cuda_h.py:19] end iln_self_attn_paln cost 0.006905555725097656 seconds
DEBUG 01-13 08:46:17.866284.866284 cuda_h.py:10] start layer_moe_generate_mp_l_18
DEBUG 01-13 08:46:17.866391.866391 cuda_h.py:10] start gate
DEBUG 01-13 08:46:17.867188.867188 cuda_h.py:19] end gate cost 0.0007855892181396484 seconds
DEBUG 01-13 08:46:17.867984.867984 cuda_h.py:10] start experts_map_get
DEBUG 01-13 08:46:17.867447.867447 lmp.py:1611] 
DEBUG 01-13 08:46:17.867447.867447 lmp.py:1611] Expert Token Distribution & Device Allocation:
DEBUG 01-13 08:46:17.867018.867018 lmp.py:1612]   Total experts: 64
DEBUG 01-13 08:46:17.867006.867006 lmp.py:1613]   CPU experts: 32 (50%)
DEBUG 01-13 08:46:17.867655.867655 lmp.py:1614]   GPU experts: 32 (50%)
DEBUG 01-13 08:46:17.867398.867398 lmp.py:1615] 
DEBUG 01-13 08:46:17.867398.867398 lmp.py:1615]   Expert ID | Tokens | Device
DEBUG 01-13 08:46:17.867379.867379 lmp.py:1616]   -----------------------------------
DEBUG 01-13 08:46:17.867843.867843 lmp.py:1622]   Expert  4 |     11 | CPU
DEBUG 01-13 08:46:17.867109.867109 lmp.py:1622]   Expert 28 |     26 | CPU
DEBUG 01-13 08:46:17.867421.867421 lmp.py:1622]   Expert  7 |     39 | CPU
DEBUG 01-13 08:46:17.867314.867314 lmp.py:1622]   Expert 52 |     63 | CPU
DEBUG 01-13 08:46:17.868166.868166 lmp.py:1622]   Expert 53 |     63 | CPU
DEBUG 01-13 08:46:17.868790.868790 lmp.py:1622]   Expert 43 |     82 | CPU
DEBUG 01-13 08:46:17.868877.868877 lmp.py:1622]   Expert 49 |     82 | CPU
DEBUG 01-13 08:46:17.868864.868864 lmp.py:1622]   Expert 12 |     86 | CPU
DEBUG 01-13 08:46:17.868282.868282 lmp.py:1622]   Expert 24 |     98 | CPU
DEBUG 01-13 08:46:17.868316.868316 lmp.py:1622]   Expert 47 |    101 | CPU
DEBUG 01-13 08:46:17.868350.868350 lmp.py:1622]   Expert 33 |    106 | CPU
DEBUG 01-13 08:46:17.868907.868907 lmp.py:1622]   Expert 15 |    109 | CPU
DEBUG 01-13 08:46:17.868226.868226 lmp.py:1622]   Expert  2 |    111 | CPU
DEBUG 01-13 08:46:17.868783.868783 lmp.py:1622]   Expert 39 |    112 | CPU
DEBUG 01-13 08:46:17.868864.868864 lmp.py:1622]   Expert 50 |    113 | CPU
DEBUG 01-13 08:46:17.868057.868057 lmp.py:1622]   Expert 60 |    118 | CPU
DEBUG 01-13 08:46:17.868044.868044 lmp.py:1622]   Expert 61 |    119 | CPU
DEBUG 01-13 08:46:17.868893.868893 lmp.py:1622]   Expert 36 |    125 | CPU
DEBUG 01-13 08:46:17.868212.868212 lmp.py:1622]   Expert 25 |    126 | CPU
DEBUG 01-13 08:46:17.868531.868531 lmp.py:1622]   Expert  6 |    127 | CPU
DEBUG 01-13 08:46:17.868849.868849 lmp.py:1622]   Expert 59 |    139 | CPU
DEBUG 01-13 08:46:17.868453.868453 lmp.py:1622]   Expert  3 |    148 | CPU
DEBUG 01-13 08:46:17.868533.868533 lmp.py:1622]   Expert 27 |    148 | CPU
DEBUG 01-13 08:46:17.868044.868044 lmp.py:1622]   Expert 58 |    150 | CPU
DEBUG 01-13 08:46:17.868270.868270 lmp.py:1622]   Expert 31 |    152 | CPU
DEBUG 01-13 08:46:17.868257.868257 lmp.py:1622]   Expert  8 |    153 | CPU
DEBUG 01-13 08:46:17.868815.868815 lmp.py:1622]   Expert 10 |    155 | CPU
DEBUG 01-13 08:46:17.868895.868895 lmp.py:1622]   Expert 40 |    157 | CPU
DEBUG 01-13 08:46:17.868975.868975 lmp.py:1622]   Expert 30 |    159 | CPU
DEBUG 01-13 08:46:17.868817.868817 lmp.py:1622]   Expert 38 |    159 | CPU
DEBUG 01-13 08:46:17.868182.868182 lmp.py:1622]   Expert 57 |    161 | CPU
DEBUG 01-13 08:46:17.868501.868501 lmp.py:1622]   Expert 32 |    162 | CPU
DEBUG 01-13 08:46:17.868773.868773 lmp.py:1622]   Expert 14 |    163 | GPU
DEBUG 01-13 08:46:17.868284.868284 lmp.py:1622]   Expert 41 |    164 | GPU
DEBUG 01-13 08:46:17.868318.868318 lmp.py:1622]   Expert 46 |    165 | GPU
DEBUG 01-13 08:46:17.868921.868921 lmp.py:1622]   Expert 37 |    168 | GPU
DEBUG 01-13 08:46:17.868525.868525 lmp.py:1622]   Expert 54 |    168 | GPU
DEBUG 01-13 08:46:17.868128.868128 lmp.py:1622]   Expert 19 |    169 | GPU
DEBUG 01-13 08:46:17.868493.868493 lmp.py:1622]   Expert 42 |    173 | GPU
DEBUG 01-13 08:46:17.868620.868620 lmp.py:1622]   Expert 11 |    182 | GPU
DEBUG 01-13 08:46:17.869462.869462 lmp.py:1622]   Expert 34 |    184 | GPU
DEBUG 01-13 08:46:17.869972.869972 lmp.py:1622]   Expert  0 |    197 | GPU
DEBUG 01-13 08:46:17.869722.869722 lmp.py:1622]   Expert 18 |    201 | GPU
DEBUG 01-13 08:46:17.869809.869809 lmp.py:1622]   Expert 22 |    201 | GPU
DEBUG 01-13 08:46:17.869796.869796 lmp.py:1622]   Expert  1 |    203 | GPU
DEBUG 01-13 08:46:17.869069.869069 lmp.py:1622]   Expert 51 |    205 | GPU
DEBUG 01-13 08:46:17.869864.869864 lmp.py:1622]   Expert 56 |    205 | GPU
DEBUG 01-13 08:46:17.869421.869421 lmp.py:1622]   Expert 26 |    206 | GPU
DEBUG 01-13 08:46:17.869978.869978 lmp.py:1622]   Expert 44 |    208 | GPU
INFO 01-13 08:46:17.869094.869094 client.py:127] Model loaded
DEBUG 01-13 08:46:17.869017.869017 lmp.py:1622]   Expert 20 |    224 | GPU
DEBUG 01-13 08:46:17.869383.869383 cuda_h.py:10] start restore2model
DEBUG 01-13 08:46:17.869623.869623 lmp.py:1622]   Expert 29 |    224 | GPU
DEBUG 01-13 08:46:17.869208.869208 lmp.py:1622]   Expert 45 |    237 | GPU
DEBUG 01-13 08:46:17.869010.869010 lmp.py:1622]   Expert 48 |    239 | GPU
DEBUG 01-13 08:46:17.870561.870561 cuda_h.py:19] end restore2model cost 0.0006618499755859375 seconds
DEBUG 01-13 08:46:17.870562.870562 lmp.py:1622]   Expert 21 |    245 | GPU
DEBUG 01-13 08:46:17.870704.870704 cuda_h.py:19] end sllm_worker_task cost 0.010561704635620117 seconds
DEBUG 01-13 08:46:17.870779.870779 lmp.py:1622]   Expert 16 |    250 | GPU
DEBUG 01-13 08:46:17.870378.870378 lmp.py:1622]   Expert 35 |    256 | GPU
DEBUG 01-13 08:46:17.870365.870365 lmp.py:1622]   Expert 55 |    256 | GPU
DEBUG 01-13 08:46:17.870445.870445 lmp.py:1622]   Expert  5 |    295 | GPU
DEBUG 01-13 08:46:17.870287.870287 lmp.py:1622]   Expert 23 |    374 | GPU
DEBUG 01-13 08:46:17.870129.870129 lmp.py:1622]   Expert 13 |    386 | GPU
DEBUG 01-13 08:46:17.870733.870733 lmp.py:1622]   Expert 17 |    433 | GPU
DEBUG 01-13 08:46:17.870098.870098 lmp.py:1622]   Expert 63 |    443 | GPU
DEBUG 01-13 08:46:17.870608.870608 lmp.py:1622]   Expert  9 |    444 | GPU
DEBUG 01-13 08:46:17.870642.870642 lmp.py:1622]   Expert 62 |   1160 | GPU
DEBUG 01-13 08:46:17.870345.870345 lmp.py:1623] 
DEBUG 01-13 08:46:17.870345.870345 lmp.py:1623]   CPU total tokens: 3660 (29.8%)
DEBUG 01-13 08:46:17.870571.870571 lmp.py:1624]   GPU total tokens: 8628 (70.2%)
DEBUG 01-13 08:46:17.870096.870096 cuda_h.py:19] end experts_map_get cost 0.003481626510620117 seconds
DEBUG 01-13 08:46:17.870167.870167 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-13 08:46:17.870513.870513 lmp.py:1632] 
DEBUG 01-13 08:46:17.870513.870513 lmp.py:1632]   Computing 32 experts on CPU MP...
DEBUG 01-13 08:46:17.871476.871476 cuda_h.py:19] end cpu_experts_submit cost 7.653236389160156e-05 seconds
DEBUG 01-13 08:46:17.871755.871755 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-13 08:46:17.871870.871870 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-13 08:46:17.871532.871532 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-13 08:46:17.872668.872668 cuda_h.py:19] end allocate_cuda_memory cost 0.0002598762512207031 seconds
DEBUG 01-13 08:46:17.872373.872373 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-13 08:46:17.872957.872957 sllm_store_c.py:27] get device uuid map
DEBUG 01-13 08:46:17.872257.872257 sllm_store_c.py:29] call client load into gpu
DEBUG 01-13 08:46:17.872490.872490 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 2cd3c1f4-b8dc-47a5-83ca-d73d0c54b120
DEBUG 01-13 08:46:17.872848.872848 client.py:106] call stub.LoadModelAsync
DEBUG 01-13 08:46:17.872023.872023 cuda_h.py:10] start experts_func_gpu_einsum_mp
INFO 01-13 08:46:17.873377.873377 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 2cd3c1f4-b8dc-47a5-83ca-d73d0c54b120
DEBUG 01-13 08:46:17.873849.873849 cuda_h.py:19] end load_into_gpu_async cost 0.0017082691192626953 seconds
DEBUG 01-13 08:46:17.873089.873089 cuda_h.py:10] start restore_tensors2
DEBUG 01-13 08:46:17.874517.874517 cuda_h.py:19] end restore_tensors2 cost 0.0004825592041015625 seconds
DEBUG 01-13 08:46:17.874221.874221 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0029213428497314453 seconds
DEBUG 01-13 08:46:17.874282.874282 cuda_h.py:10] start restore2model
DEBUG 01-13 08:46:17.878310.878310 cuda_h.py:19] end restore2model cost 0.003563404083251953 seconds
DEBUG 01-13 08:46:17.878915.878915 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.006719350814819336 seconds
DEBUG 01-13 08:46:17.878618.878618 cuda_h.py:10] start gpu_sexperts
DEBUG 01-13 08:46:17.878779.878779 cuda_h.py:19] end gpu_sexperts cost 0.00043511390686035156 seconds
DEBUG 01-13 08:46:17.878331.878331 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-13 08:46:17.878021.878021 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.0503997802734375e-05 seconds
DEBUG 01-13 08:46:17.878247.878247 cuda_h.py:10] start wait_experts
INFO 01-13 08:46:17.878427.878427 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 2cd3c1f4-b8dc-47a5-83ca-d73d0c54b120
DEBUG 01-13 08:46:17.890124.890124 mlpmodule.py:1006] group tensors cost 0.016952037811279297 s
DEBUG 01-13 08:46:17.893115.893115 mlpmodule.py:1044] pad cost 0.002000093460083008 s
DEBUG 01-13 08:46:17.893794.893794 mlpmodule.py:1050] create cpu tensor cost 4.863739013671875e-05 s
DEBUG 01-13 08:46:17.893857.893857 mlpmodule.py:1055] move to cpu cost 3.647804260253906e-05 s
DEBUG 01-13 08:46:17.903665.903665 mlpmodule.py:1069] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-13 08:46:17.903095.903095 mlpmodule.py:1070] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-13 08:46:17.903569.903569 mlpmodule.py:1075] group_w3 first element: 0.00457763671875
WARNING 01-13 08:46:17.903692.903692 mlpmodule.py:1085] start einsum2
DEBUG 01-13 08:46:17.916759.916759 mlpmodule.py:1095] group einsum cost 0.022912979125976562 s
DEBUG 01-13 08:46:17.917130.917130 mlpmodule.py:1103] cpy2cputensor cost 0.0005931854248046875 s
INFO 01-13 08:46:17.926224.926224 client.py:127] Model loaded
DEBUG 01-13 08:46:17.926455.926455 cuda_h.py:19] end wait_experts cost 0.04751086235046387 seconds
DEBUG 01-13 08:46:17.926523.926523 cuda_h.py:10] start gpu_experts
DEBUG 01-13 08:46:17.927662.927662 mlpmodule.py:559] gpu group tensors cost 0.000667572021484375 s
DEBUG 01-13 08:46:17.929992.929992 mlpmodule.py:592] gpu pad cost 0.0022437572479248047 s
DEBUG 01-13 08:46:17.929525.929525 mlpmodule.py:598] start_w1
DEBUG 01-13 08:46:17.930135.930135 mlpmodule.py:602] start_w3
DEBUG 01-13 08:46:17.930169.930169 mlpmodule.py:608] start_w2
DEBUG 01-13 08:46:17.930693.930693 mlpmodule.py:611] gpu group einsum cost 0.0012428760528564453 s
DEBUG 01-13 08:46:17.933955.933955 mlpmodule.py:683] gpu experts func einsum cost 0.006852865219116211 s
DEBUG 01-13 08:46:17.933454.933454 cuda_h.py:19] end gpu_experts cost 0.007011890411376953 seconds
DEBUG 01-13 08:46:17.933926.933926 cuda_h.py:10] start cpu_thread_manager_mp_wait
DEBUG 01-13 08:46:17.933213.933213 cuda_h.py:19] end cpu_thread_manager_mp_wait cost 3.838539123535156e-05 seconds
DEBUG 01-13 08:46:17.933513.933513 cuda_h.py:19] end layer_moe_generate_mp_l_18 cost 0.0673365592956543 seconds
DEBUG 01-13 08:46:17.933448.933448 lmp.py:1550] -------------------------------- end prefill layer 17 --------------------------------
DEBUG 01-13 08:46:17.933357.933357 lmp.py:1493] -------------------------------- start prefill layer 18 --------------------------------
DEBUG 01-13 08:46:17.933345.933345 cuda_h.py:10] start start_load_qkvogn_s_weight_l_19
DEBUG 01-13 08:46:17.933193.933193 cuda_h.py:10] start start_load_qkvogn_s_weight_l_19
DEBUG 01-13 08:46:17.934752.934752 cuda_h.py:19] end start_load_qkvogn_s_weight_l_19 cost 3.147125244140625e-05 seconds
DEBUG 01-13 08:46:17.934454.934454 cuda_h.py:19] end start_load_qkvogn_s_weight_l_19 cost 6.103515625e-05 seconds
DEBUG 01-13 08:46:17.934482.934482 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-13 08:46:17.934239.934239 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-13 08:46:17.934149.934149 cuda_h.py:10] start sllm_worker_task
DEBUG 01-13 08:46:17.934966.934966 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-13 08:46:17.934080.934080 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-13 08:46:17.934411.934411 cuda_h.py:19] end allocate_cuda_memory cost 0.00017499923706054688 seconds
DEBUG 01-13 08:46:17.934997.934997 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-13 08:46:17.934283.934283 sllm_store_c.py:27] get device uuid map
DEBUG 01-13 08:46:17.934106.934106 sllm_store_c.py:29] call client load into gpu
DEBUG 01-13 08:46:17.934378.934378 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 164de1bb-8c65-40b1-a920-78e81e9f255f
DEBUG 01-13 08:46:17.934447.934447 client.py:106] call stub.LoadModelAsync
DEBUG 01-13 08:46:17.935284.935284 cuda_h.py:10] start self_attn
INFO 01-13 08:46:17.935954.935954 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 164de1bb-8c65-40b1-a920-78e81e9f255f
DEBUG 01-13 08:46:17.936744.936744 cuda_h.py:19] end load_into_gpu_async cost 0.0013229846954345703 seconds
DEBUG 01-13 08:46:17.936255.936255 cuda_h.py:10] start restore_tensors2
DEBUG 01-13 08:46:17.936285.936285 cuda_h.py:19] end restore_tensors2 cost 6.508827209472656e-05 seconds
DEBUG 01-13 08:46:17.936657.936657 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0018153190612792969 seconds
INFO 01-13 08:46:17.936791.936791 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 164de1bb-8c65-40b1-a920-78e81e9f255f
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-13 08:46:17.938230.938230 cuda_h.py:19] end self_attn cost 0.0030968189239501953 seconds
DEBUG 01-13 08:46:17.938889.938889 cuda_h.py:19] end iln_self_attn_paln cost 0.004412174224853516 seconds
DEBUG 01-13 08:46:17.938440.938440 cuda_h.py:10] start layer_moe_generate_mp_l_19
DEBUG 01-13 08:46:17.938388.938388 cuda_h.py:10] start gate
DEBUG 01-13 08:46:17.939238.939238 cuda_h.py:19] end gate cost 0.0006284713745117188 seconds
DEBUG 01-13 08:46:17.939684.939684 cuda_h.py:10] start experts_map_get
DEBUG 01-13 08:46:17.939316.939316 lmp.py:1611] 
DEBUG 01-13 08:46:17.939316.939316 lmp.py:1611] Expert Token Distribution & Device Allocation:
DEBUG 01-13 08:46:17.939178.939178 lmp.py:1612]   Total experts: 64
DEBUG 01-13 08:46:17.939881.939881 lmp.py:1613]   CPU experts: 32 (50%)
DEBUG 01-13 08:46:17.939954.939954 lmp.py:1614]   GPU experts: 32 (50%)
DEBUG 01-13 08:46:17.939928.939928 lmp.py:1615] 
DEBUG 01-13 08:46:17.939928.939928 lmp.py:1615]   Expert ID | Tokens | Device
DEBUG 01-13 08:46:17.939618.939618 lmp.py:1616]   -----------------------------------
DEBUG 01-13 08:46:17.939029.939029 lmp.py:1622]   Expert 32 |     38 | CPU
DEBUG 01-13 08:46:17.939195.939195 lmp.py:1622]   Expert 30 |     47 | CPU
DEBUG 01-13 08:46:17.939408.939408 lmp.py:1622]   Expert  5 |     51 | CPU
DEBUG 01-13 08:46:17.939143.939143 lmp.py:1622]   Expert 46 |     69 | CPU
DEBUG 01-13 08:46:17.939879.939879 lmp.py:1622]   Expert 40 |     76 | CPU
DEBUG 01-13 08:46:17.939615.939615 lmp.py:1622]   Expert  8 |     81 | CPU
DEBUG 01-13 08:46:17.939112.939112 lmp.py:1622]   Expert 12 |     98 | CPU
DEBUG 01-13 08:46:17.939324.939324 lmp.py:1622]   Expert 27 |    103 | CPU
DEBUG 01-13 08:46:17.939537.939537 lmp.py:1622]   Expert 58 |    107 | CPU
DEBUG 01-13 08:46:17.939988.939988 lmp.py:1622]   Expert  3 |    109 | CPU
DEBUG 01-13 08:46:17.939485.939485 lmp.py:1622]   Expert 60 |    110 | CPU
DEBUG 01-13 08:46:17.939220.939220 lmp.py:1622]   Expert 17 |    111 | CPU
DEBUG 01-13 08:46:17.939194.939194 lmp.py:1622]   Expert 21 |    121 | CPU
DEBUG 01-13 08:46:17.939692.939692 lmp.py:1622]   Expert 28 |    121 | CPU
DEBUG 01-13 08:46:17.939427.939427 lmp.py:1622]   Expert 29 |    121 | CPU
DEBUG 01-13 08:46:17.940686.940686 lmp.py:1622]   Expert 25 |    127 | CPU
DEBUG 01-13 08:46:17.940945.940945 lmp.py:1622]   Expert 35 |    128 | CPU
DEBUG 01-13 08:46:17.940442.940442 lmp.py:1622]   Expert 19 |    129 | CPU
DEBUG 01-13 08:46:17.940701.940701 lmp.py:1622]   Expert 41 |    131 | CPU
DEBUG 01-13 08:46:17.940198.940198 lmp.py:1622]   Expert 54 |    135 | CPU
DEBUG 01-13 08:46:17.940934.940934 lmp.py:1622]   Expert 52 |    140 | CPU
DEBUG 01-13 08:46:17.940623.940623 lmp.py:1622]   Expert  0 |    141 | CPU
DEBUG 01-13 08:46:17.940882.940882 lmp.py:1622]   Expert 56 |    150 | CPU
DEBUG 01-13 08:46:17.940617.940617 lmp.py:1622]   Expert  6 |    152 | CPU
DEBUG 01-13 08:46:17.940638.940638 lmp.py:1622]   Expert 37 |    154 | CPU
DEBUG 01-13 08:46:17.940135.940135 lmp.py:1622]   Expert 53 |    161 | CPU
DEBUG 01-13 08:46:17.940394.940394 lmp.py:1622]   Expert 63 |    162 | CPU
DEBUG 01-13 08:46:17.940129.940129 lmp.py:1622]   Expert 36 |    164 | CPU
DEBUG 01-13 08:46:17.940388.940388 lmp.py:1622]   Expert 48 |    166 | CPU
DEBUG 01-13 08:46:17.940885.940885 lmp.py:1622]   Expert 59 |    168 | CPU
DEBUG 01-13 08:46:17.940098.940098 lmp.py:1622]   Expert  9 |    188 | CPU
DEBUG 01-13 08:46:17.940072.940072 lmp.py:1622]   Expert 20 |    192 | CPU
DEBUG 01-13 08:46:17.940569.940569 lmp.py:1622]   Expert 43 |    192 | GPU
DEBUG 01-13 08:46:17.940543.940543 lmp.py:1622]   Expert  1 |    193 | GPU
DEBUG 01-13 08:46:17.940564.940564 lmp.py:1622]   Expert 39 |    193 | GPU
DEBUG 01-13 08:46:17.940822.940822 lmp.py:1622]   Expert 11 |    196 | GPU
DEBUG 01-13 08:46:17.940081.940081 lmp.py:1622]   Expert  7 |    203 | GPU
DEBUG 01-13 08:46:17.940340.940340 lmp.py:1622]   Expert 61 |    203 | GPU
DEBUG 01-13 08:46:17.940599.940599 lmp.py:1622]   Expert 42 |    204 | GPU
DEBUG 01-13 08:46:17.940858.940858 lmp.py:1622]   Expert 34 |    211 | GPU
DEBUG 01-13 08:46:17.940938.940938 lmp.py:1622]   Expert 47 |    211 | GPU
DEBUG 01-13 08:46:17.940673.940673 lmp.py:1622]   Expert 16 |    213 | GPU
DEBUG 01-13 08:46:17.940932.940932 lmp.py:1622]   Expert 55 |    217 | GPU
DEBUG 01-13 08:46:17.940145.940145 lmp.py:1622]   Expert 13 |    222 | GPU
DEBUG 01-13 08:46:17.940880.940880 lmp.py:1622]   Expert 57 |    222 | GPU
DEBUG 01-13 08:46:17.940616.940616 lmp.py:1622]   Expert 18 |    234 | GPU
DEBUG 01-13 08:46:17.940636.940636 lmp.py:1622]   Expert  4 |    237 | GPU
DEBUG 01-13 08:46:17.940372.940372 lmp.py:1622]   Expert 15 |    238 | GPU
DEBUG 01-13 08:46:17.940631.940631 lmp.py:1622]   Expert 45 |    244 | GPU
DEBUG 01-13 08:46:17.940889.940889 lmp.py:1622]   Expert 50 |    245 | GPU
DEBUG 01-13 08:46:17.940387.940387 lmp.py:1622]   Expert 22 |    247 | GPU
DEBUG 01-13 08:46:17.940645.940645 lmp.py:1622]   Expert 33 |    250 | GPU
DEBUG 01-13 08:46:17.940143.940143 lmp.py:1622]   Expert 31 |    251 | GPU
DEBUG 01-13 08:46:17.940355.940355 lmp.py:1622]   Expert 51 |    256 | GPU
DEBUG 01-13 08:46:17.940329.940329 lmp.py:1622]   Expert 38 |    270 | GPU
DEBUG 01-13 08:46:17.940065.940065 lmp.py:1622]   Expert 49 |    270 | GPU
DEBUG 01-13 08:46:17.940324.940324 lmp.py:1622]   Expert 26 |    277 | GPU
DEBUG 01-13 08:46:17.940582.940582 lmp.py:1622]   Expert 10 |    283 | GPU
DEBUG 01-13 08:46:17.940841.940841 lmp.py:1622]   Expert 44 |    295 | GPU
DEBUG 01-13 08:46:17.940100.940100 lmp.py:1622]   Expert 24 |    304 | GPU
DEBUG 01-13 08:46:17.940120.940120 lmp.py:1622]   Expert 14 |    315 | GPU
DEBUG 01-13 08:46:17.940379.940379 lmp.py:1622]   Expert  2 |    323 | GPU
DEBUG 01-13 08:46:17.940400.940400 lmp.py:1622]   Expert 23 |    439 | GPU
DEBUG 01-13 08:46:17.940612.940612 lmp.py:1622]   Expert 62 |    679 | GPU
DEBUG 01-13 08:46:17.940778.940778 lmp.py:1623] 
DEBUG 01-13 08:46:17.940778.940778 lmp.py:1623]   CPU total tokens: 3951 (32.2%)
DEBUG 01-13 08:46:17.940660.940660 lmp.py:1624]   GPU total tokens: 8337 (67.8%)
DEBUG 01-13 08:46:17.940594.940594 cuda_h.py:19] end experts_map_get cost 0.001451253890991211 seconds
DEBUG 01-13 08:46:17.940013.940013 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-13 08:46:17.940193.940193 lmp.py:1632] 
DEBUG 01-13 08:46:17.940193.940193 lmp.py:1632]   Computing 32 experts on CPU MP...
DEBUG 01-13 08:46:17.940969.940969 cuda_h.py:19] end cpu_experts_submit cost 4.506111145019531e-05 seconds
DEBUG 01-13 08:46:17.940209.940209 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-13 08:46:17.941323.941323 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-13 08:46:17.941076.941076 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-13 08:46:17.942652.942652 mlpmodule.py:785]  experts func einsum cost 0.06835794448852539 s
DEBUG 01-13 08:46:17.942677.942677 cuda_h.py:19] end experts_func_gpu_einsum_mp cost 0.06965780258178711 seconds
DEBUG 01-13 08:46:17.942420.942420 cuda_h.py:19] end allocate_cuda_memory cost 0.0013439655303955078 seconds
DEBUG 01-13 08:46:17.942971.942971 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-13 08:46:17.943926.943926 sllm_store_c.py:27] get device uuid map
DEBUG 01-13 08:46:17.943073.943073 sllm_store_c.py:29] call client load into gpu
DEBUG 01-13 08:46:17.943915.943915 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, df34de49-0387-4e3c-a3bf-d0be2da84774
DEBUG 01-13 08:46:17.943232.943232 client.py:106] call stub.LoadModelAsync
DEBUG 01-13 08:46:17.943360.943360 cuda_h.py:10] start experts_func_gpu_einsum_mp
INFO 01-13 08:46:17.943565.943565 client.py:127] Model loaded
DEBUG 01-13 08:46:17.943092.943092 cuda_h.py:10] start restore2model
DEBUG 01-13 08:46:17.943893.943893 cuda_h.py:19] end restore2model cost 0.0003459453582763672 seconds
DEBUG 01-13 08:46:17.943378.943378 cuda_h.py:19] end sllm_worker_task cost 0.00954580307006836 seconds
INFO 01-13 08:46:17.944806.944806 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, df34de49-0387-4e3c-a3bf-d0be2da84774
DEBUG 01-13 08:46:17.944801.944801 cuda_h.py:19] end load_into_gpu_async cost 0.0012042522430419922 seconds
DEBUG 01-13 08:46:17.944550.944550 cuda_h.py:10] start restore_tensors2
DEBUG 01-13 08:46:17.944118.944118 cuda_h.py:19] end restore_tensors2 cost 0.00032329559326171875 seconds
DEBUG 01-13 08:46:17.944895.944895 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0035924911499023438 seconds
DEBUG 01-13 08:46:17.944896.944896 cuda_h.py:10] start restore2model
DEBUG 01-13 08:46:17.947769.947769 cuda_h.py:19] end restore2model cost 0.0025110244750976562 seconds
DEBUG 01-13 08:46:17.947122.947122 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.006269931793212891 seconds
DEBUG 01-13 08:46:17.947487.947487 cuda_h.py:10] start gpu_sexperts
DEBUG 01-13 08:46:17.947517.947517 cuda_h.py:19] end gpu_sexperts cost 0.0002722740173339844 seconds
DEBUG 01-13 08:46:17.947293.947293 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-13 08:46:17.947824.947824 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 1.3828277587890625e-05 seconds
DEBUG 01-13 08:46:17.947044.947044 cuda_h.py:10] start wait_experts
INFO 01-13 08:46:17.947455.947455 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, df34de49-0387-4e3c-a3bf-d0be2da84774
DEBUG 01-13 08:46:17.948655.948655 mlpmodule.py:1006] group tensors cost 0.004628181457519531 s
DEBUG 01-13 08:46:17.950759.950759 mlpmodule.py:1044] pad cost 0.0014677047729492188 s
DEBUG 01-13 08:46:17.950809.950809 mlpmodule.py:1050] create cpu tensor cost 5.507469177246094e-05 s
DEBUG 01-13 08:46:17.950367.950367 mlpmodule.py:1055] move to cpu cost 2.8371810913085938e-05 s
DEBUG 01-13 08:46:17.961212.961212 mlpmodule.py:1069] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-13 08:46:17.961602.961602 mlpmodule.py:1070] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-13 08:46:17.961499.961499 mlpmodule.py:1075] group_w3 first element: 0.0024871826171875
WARNING 01-13 08:46:17.961444.961444 mlpmodule.py:1085] start einsum2
DEBUG 01-13 08:46:17.975331.975331 mlpmodule.py:1095] group einsum cost 0.025143861770629883 s
DEBUG 01-13 08:46:17.979123.979123 mlpmodule.py:1103] cpy2cputensor cost 0.0032532215118408203 s
INFO 01-13 08:46:17.999192.999192 client.py:127] Model loaded
DEBUG 01-13 08:46:17.999216.999216 cuda_h.py:19] end wait_experts cost 0.05219292640686035 seconds
DEBUG 01-13 08:46:17.999164.999164 cuda_h.py:10] start gpu_experts
DEBUG 01-13 08:46:18.000438.000438 mlpmodule.py:559] gpu group tensors cost 0.0005669593811035156 s
DEBUG 01-13 08:46:18.002464.002464 mlpmodule.py:592] gpu pad cost 0.0014994144439697266 s
DEBUG 01-13 08:46:18.002936.002936 mlpmodule.py:598] start_w1
DEBUG 01-13 08:46:18.002345.002345 mlpmodule.py:602] start_w3
DEBUG 01-13 08:46:18.002185.002185 mlpmodule.py:608] start_w2
DEBUG 01-13 08:46:18.002548.002548 mlpmodule.py:611] gpu group einsum cost 0.000659942626953125 s
DEBUG 01-13 08:46:18.003324.003324 mlpmodule.py:785]  experts func einsum cost 0.059418678283691406 s
DEBUG 01-13 08:46:18.003654.003654 cuda_h.py:19] end experts_func_gpu_einsum_mp cost 0.060157060623168945 seconds
DEBUG 01-13 08:46:18.005925.005925 mlpmodule.py:683] gpu experts func einsum cost 0.005038022994995117 s
DEBUG 01-13 08:46:18.005604.005604 cuda_h.py:19] end gpu_experts cost 0.005178928375244141 seconds
DEBUG 01-13 08:46:18.005783.005783 cuda_h.py:10] start cpu_thread_manager_mp_wait
DEBUG 01-13 08:46:18.005156.005156 cuda_h.py:19] end cpu_thread_manager_mp_wait cost 3.5762786865234375e-05 seconds
DEBUG 01-13 08:46:18.005834.005834 cuda_h.py:19] end layer_moe_generate_mp_l_19 cost 0.0667259693145752 seconds
DEBUG 01-13 08:46:18.005265.005265 lmp.py:1550] -------------------------------- end prefill layer 18 --------------------------------
DEBUG 01-13 08:46:18.005949.005949 lmp.py:1493] -------------------------------- start prefill layer 19 --------------------------------
DEBUG 01-13 08:46:18.005076.005076 cuda_h.py:10] start start_load_qkvogn_s_weight_l_20
DEBUG 01-13 08:46:18.005017.005017 cuda_h.py:10] start start_load_qkvogn_s_weight_l_20
DEBUG 01-13 08:46:18.005992.005992 cuda_h.py:19] end start_load_qkvogn_s_weight_l_20 cost 2.6941299438476562e-05 seconds
DEBUG 01-13 08:46:18.005762.005762 cuda_h.py:19] end start_load_qkvogn_s_weight_l_20 cost 7.319450378417969e-05 seconds
DEBUG 01-13 08:46:18.005882.005882 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-13 08:46:18.005063.005063 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-13 08:46:18.005509.005509 cuda_h.py:10] start sllm_worker_task
DEBUG 01-13 08:46:18.006234.006234 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-13 08:46:18.006871.006871 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-13 08:46:18.006987.006987 cuda_h.py:19] end allocate_cuda_memory cost 0.00026297569274902344 seconds
DEBUG 01-13 08:46:18.006089.006089 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-13 08:46:18.006898.006898 sllm_store_c.py:27] get device uuid map
DEBUG 01-13 08:46:18.006052.006052 sllm_store_c.py:29] call client load into gpu
DEBUG 01-13 08:46:18.006847.006847 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, c519db80-7655-46e7-8887-d7d9b9511042
DEBUG 01-13 08:46:18.006009.006009 client.py:106] call stub.LoadModelAsync
DEBUG 01-13 08:46:18.006262.006262 cuda_h.py:10] start self_attn
INFO 01-13 08:46:18.007103.007103 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, c519db80-7655-46e7-8887-d7d9b9511042
DEBUG 01-13 08:46:18.007238.007238 cuda_h.py:19] end load_into_gpu_async cost 0.0014414787292480469 seconds
DEBUG 01-13 08:46:18.007709.007709 cuda_h.py:10] start restore_tensors2
DEBUG 01-13 08:46:18.008527.008527 cuda_h.py:19] end restore_tensors2 cost 7.867813110351562e-05 seconds
DEBUG 01-13 08:46:18.008019.008019 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0020568370819091797 seconds
INFO 01-13 08:46:18.008676.008676 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, c519db80-7655-46e7-8887-d7d9b9511042
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-13 08:46:18.010153.010153 cuda_h.py:19] end self_attn cost 0.0031952857971191406 seconds
DEBUG 01-13 08:46:18.010871.010871 cuda_h.py:19] end iln_self_attn_paln cost 0.004597663879394531 seconds
DEBUG 01-13 08:46:18.010091.010091 cuda_h.py:10] start layer_moe_generate_mp_l_20
DEBUG 01-13 08:46:18.010709.010709 cuda_h.py:10] start gate
DEBUG 01-13 08:46:18.011975.011975 cuda_h.py:19] end gate cost 0.0006201267242431641 seconds
DEBUG 01-13 08:46:18.011467.011467 cuda_h.py:10] start experts_map_get
DEBUG 01-13 08:46:18.011609.011609 lmp.py:1611] 
DEBUG 01-13 08:46:18.011609.011609 lmp.py:1611] Expert Token Distribution & Device Allocation:
DEBUG 01-13 08:46:18.011173.011173 lmp.py:1612]   Total experts: 64
DEBUG 01-13 08:46:18.011584.011584 lmp.py:1613]   CPU experts: 32 (50%)
DEBUG 01-13 08:46:18.011419.011419 lmp.py:1614]   GPU experts: 32 (50%)
DEBUG 01-13 08:46:18.011777.011777 lmp.py:1615] 
DEBUG 01-13 08:46:18.011777.011777 lmp.py:1615]   Expert ID | Tokens | Device
DEBUG 01-13 08:46:18.011944.011944 lmp.py:1616]   -----------------------------------
DEBUG 01-13 08:46:18.011355.011355 lmp.py:1622]   Expert 44 |     35 | CPU
DEBUG 01-13 08:46:18.011952.011952 lmp.py:1622]   Expert  1 |     50 | CPU
DEBUG 01-13 08:46:18.011118.011118 lmp.py:1622]   Expert 28 |     58 | CPU
DEBUG 01-13 08:46:18.011045.011045 lmp.py:1622]   Expert 60 |     65 | CPU
DEBUG 01-13 08:46:18.011735.011735 lmp.py:1622]   Expert 48 |     73 | CPU
DEBUG 01-13 08:46:18.011662.011662 lmp.py:1622]   Expert 27 |     88 | CPU
DEBUG 01-13 08:46:18.011829.011829 lmp.py:1622]   Expert 42 |    100 | CPU
DEBUG 01-13 08:46:18.011948.011948 lmp.py:1622]   Expert  0 |    102 | CPU
DEBUG 01-13 08:46:18.011353.011353 lmp.py:1622]   Expert 22 |    114 | CPU
DEBUG 01-13 08:46:18.011519.011519 lmp.py:1622]   Expert 62 |    116 | CPU
DEBUG 01-13 08:46:18.011970.011970 lmp.py:1622]   Expert 58 |    118 | CPU
DEBUG 01-13 08:46:18.011898.011898 lmp.py:1622]   Expert 30 |    121 | CPU
DEBUG 01-13 08:46:18.011587.011587 lmp.py:1622]   Expert 59 |    121 | CPU
DEBUG 01-13 08:46:18.011276.011276 lmp.py:1622]   Expert 12 |    129 | CPU
DEBUG 01-13 08:46:18.011442.011442 lmp.py:1622]   Expert 16 |    130 | CPU
DEBUG 01-13 08:46:18.011847.011847 lmp.py:1622]   Expert  8 |    131 | CPU
DEBUG 01-13 08:46:18.011728.011728 lmp.py:1622]   Expert 56 |    140 | CPU
DEBUG 01-13 08:46:18.011895.011895 lmp.py:1622]   Expert  5 |    141 | CPU
DEBUG 01-13 08:46:18.011822.011822 lmp.py:1622]   Expert 57 |    144 | CPU
DEBUG 01-13 08:46:18.011512.011512 lmp.py:1622]   Expert 50 |    145 | CPU
DEBUG 01-13 08:46:18.011962.011962 lmp.py:1622]   Expert 15 |    148 | CPU
DEBUG 01-13 08:46:18.011413.011413 lmp.py:1622]   Expert 26 |    154 | CPU
DEBUG 01-13 08:46:18.011103.011103 lmp.py:1622]   Expert 55 |    154 | CPU
DEBUG 01-13 08:46:18.011077.011077 lmp.py:1622]   Expert 54 |    159 | CPU
DEBUG 01-13 08:46:18.012766.012766 lmp.py:1622]   Expert 47 |    162 | CPU
DEBUG 01-13 08:46:18.012217.012217 lmp.py:1622]   Expert 32 |    163 | CPU
DEBUG 01-13 08:46:18.012145.012145 lmp.py:1622]   Expert 52 |    165 | CPU
DEBUG 01-13 08:46:18.012311.012311 lmp.py:1622]   Expert 24 |    167 | CPU
DEBUG 01-13 08:46:18.012523.012523 lmp.py:1622]   Expert 40 |    168 | CPU
DEBUG 01-13 08:46:18.012974.012974 lmp.py:1622]   Expert 41 |    169 | CPU
DEBUG 01-13 08:46:18.012663.012663 lmp.py:1622]   Expert  6 |    171 | CPU
DEBUG 01-13 08:46:18.012114.012114 lmp.py:1622]   Expert 18 |    172 | CPU
DEBUG 01-13 08:46:18.012565.012565 lmp.py:1622]   Expert  3 |    173 | GPU
DEBUG 01-13 08:46:18.012016.012016 lmp.py:1622]   Expert 34 |    173 | GPU
DEBUG 01-13 08:46:18.012705.012705 lmp.py:1622]   Expert  2 |    174 | GPU
DEBUG 01-13 08:46:18.012395.012395 lmp.py:1622]   Expert 13 |    175 | GPU
DEBUG 01-13 08:46:18.012845.012845 lmp.py:1622]   Expert 37 |    180 | GPU
DEBUG 01-13 08:46:18.012250.012250 lmp.py:1622]   Expert 46 |    185 | GPU
DEBUG 01-13 08:46:18.012416.012416 lmp.py:1622]   Expert 20 |    189 | GPU
DEBUG 01-13 08:46:18.012059.012059 lmp.py:1622]   Expert 19 |    190 | GPU
DEBUG 01-13 08:46:18.012748.012748 lmp.py:1622]   Expert 17 |    197 | GPU
DEBUG 01-13 08:46:18.012199.012199 lmp.py:1622]   Expert 25 |    198 | GPU
DEBUG 01-13 08:46:18.012889.012889 lmp.py:1622]   Expert 35 |    198 | GPU
DEBUG 01-13 08:46:18.012101.012101 lmp.py:1622]   Expert 51 |    199 | GPU
DEBUG 01-13 08:46:18.012552.012552 lmp.py:1622]   Expert 43 |    205 | GPU
DEBUG 01-13 08:46:18.012003.012003 lmp.py:1622]   Expert 11 |    207 | GPU
DEBUG 01-13 08:46:18.012692.012692 lmp.py:1622]   Expert 23 |    207 | GPU
DEBUG 01-13 08:46:18.012011.012011 lmp.py:1622]   Expert 31 |    209 | GPU
DEBUG 01-13 08:46:18.012415.012415 lmp.py:1622]   Expert 49 |    217 | GPU
DEBUG 01-13 08:46:18.012582.012582 lmp.py:1622]   Expert 39 |    222 | GPU
DEBUG 01-13 08:46:18.012748.012748 lmp.py:1622]   Expert 10 |    233 | GPU
DEBUG 01-13 08:46:18.012199.012199 lmp.py:1622]   Expert 53 |    234 | GPU
DEBUG 01-13 08:46:18.012888.012888 lmp.py:1622]   Expert 33 |    247 | GPU
DEBUG 01-13 08:46:18.012577.012577 lmp.py:1622]   Expert 36 |    266 | GPU
DEBUG 01-13 08:46:18.012028.012028 lmp.py:1622]   Expert 38 |    269 | GPU
DEBUG 01-13 08:46:18.012717.012717 lmp.py:1622]   Expert  4 |    301 | GPU
DEBUG 01-13 08:46:18.012168.012168 lmp.py:1622]   Expert 21 |    327 | GPU
DEBUG 01-13 08:46:18.012858.012858 lmp.py:1622]   Expert 14 |    341 | GPU
DEBUG 01-13 08:46:18.012308.012308 lmp.py:1622]   Expert 63 |    355 | GPU
DEBUG 01-13 08:46:18.012236.012236 lmp.py:1622]   Expert 45 |    369 | GPU
DEBUG 01-13 08:46:18.012117.012117 lmp.py:1622]   Expert 61 |    381 | GPU
DEBUG 01-13 08:46:18.012284.012284 lmp.py:1622]   Expert  9 |    404 | GPU
DEBUG 01-13 08:46:18.012973.012973 lmp.py:1622]   Expert 29 |    480 | GPU
DEBUG 01-13 08:46:18.012185.012185 lmp.py:1622]   Expert  7 |    510 | GPU
DEBUG 01-13 08:46:18.012590.012590 lmp.py:1623] 
DEBUG 01-13 08:46:18.012590.012590 lmp.py:1623]   CPU total tokens: 4073 (33.1%)
DEBUG 01-13 08:46:18.012233.012233 lmp.py:1624]   GPU total tokens: 8215 (66.9%)
DEBUG 01-13 08:46:18.012167.012167 cuda_h.py:19] end experts_map_get cost 0.0015077590942382812 seconds
DEBUG 01-13 08:46:18.012487.012487 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-13 08:46:18.012382.012382 lmp.py:1632] 
DEBUG 01-13 08:46:18.012382.012382 lmp.py:1632]   Computing 32 experts on CPU MP...
DEBUG 01-13 08:46:18.012682.012682 cuda_h.py:19] end cpu_experts_submit cost 4.5299530029296875e-05 seconds
DEBUG 01-13 08:46:18.012398.012398 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-13 08:46:18.012751.012751 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-13 08:46:18.013643.013643 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-13 08:46:18.014482.014482 cuda_h.py:19] end allocate_cuda_memory cost 0.0009453296661376953 seconds
DEBUG 01-13 08:46:18.014356.014356 cuda_h.py:10] start experts_func_gpu_einsum_mp
DEBUG 01-13 08:46:18.014424.014424 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-13 08:46:18.014703.014703 sllm_store_c.py:27] get device uuid map
DEBUG 01-13 08:46:18.014036.014036 sllm_store_c.py:29] call client load into gpu
DEBUG 01-13 08:46:18.014354.014354 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, e40368e3-984c-472d-9426-1a14cf9a5e58
DEBUG 01-13 08:46:18.014572.014572 client.py:106] call stub.LoadModelAsync
INFO 01-13 08:46:18.014646.014646 client.py:127] Model loaded
DEBUG 01-13 08:46:18.015058.015058 cuda_h.py:10] start restore2model
DEBUG 01-13 08:46:18.015987.015987 cuda_h.py:19] end restore2model cost 0.00040030479431152344 seconds
DEBUG 01-13 08:46:18.015478.015478 cuda_h.py:19] end sllm_worker_task cost 0.00949239730834961 seconds
INFO 01-13 08:46:18.016895.016895 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, e40368e3-984c-472d-9426-1a14cf9a5e58
DEBUG 01-13 08:46:18.016262.016262 cuda_h.py:19] end load_into_gpu_async cost 0.0016372203826904297 seconds
DEBUG 01-13 08:46:18.016726.016726 cuda_h.py:10] start restore_tensors2
DEBUG 01-13 08:46:18.016260.016260 cuda_h.py:19] end restore_tensors2 cost 0.0002980232238769531 seconds
DEBUG 01-13 08:46:18.016606.016606 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.003556966781616211 seconds
DEBUG 01-13 08:46:18.016508.016508 cuda_h.py:10] start restore2model
DEBUG 01-13 08:46:18.019367.019367 cuda_h.py:19] end restore2model cost 0.0025022029876708984 seconds
DEBUG 01-13 08:46:18.019005.019005 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.0062198638916015625 seconds
DEBUG 01-13 08:46:18.019370.019370 cuda_h.py:10] start gpu_sexperts
DEBUG 01-13 08:46:18.019657.019657 cuda_h.py:19] end gpu_sexperts cost 0.0002532005310058594 seconds
DEBUG 01-13 08:46:18.019910.019910 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-13 08:46:18.019395.019395 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 1.4781951904296875e-05 seconds
DEBUG 01-13 08:46:18.019376.019376 cuda_h.py:10] start wait_experts
INFO 01-13 08:46:18.019357.019357 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, e40368e3-984c-472d-9426-1a14cf9a5e58
DEBUG 01-13 08:46:18.019038.019038 mlpmodule.py:1006] group tensors cost 0.004961967468261719 s
DEBUG 01-13 08:46:18.022367.022367 mlpmodule.py:1044] pad cost 0.0016319751739501953 s
DEBUG 01-13 08:46:18.022596.022596 mlpmodule.py:1050] create cpu tensor cost 4.1484832763671875e-05 s
DEBUG 01-13 08:46:18.022836.022836 mlpmodule.py:1055] move to cpu cost 3.147125244140625e-05 s
DEBUG 01-13 08:46:18.031764.031764 mlpmodule.py:1069] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-13 08:46:18.031235.031235 mlpmodule.py:1070] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-13 08:46:18.031808.031808 mlpmodule.py:1075] group_w3 first element: -0.0034942626953125
WARNING 01-13 08:46:18.031649.031649 mlpmodule.py:1085] start einsum2
DEBUG 01-13 08:46:18.047932.047932 mlpmodule.py:1095] group einsum cost 0.0245361328125 s
DEBUG 01-13 08:46:18.047663.047663 mlpmodule.py:1103] cpy2cputensor cost 0.0006394386291503906 s
INFO 01-13 08:46:18.068236.068236 client.py:127] Model loaded
DEBUG 01-13 08:46:18.068445.068445 cuda_h.py:19] end wait_experts cost 0.04910397529602051 seconds
DEBUG 01-13 08:46:18.068486.068486 cuda_h.py:10] start gpu_experts
DEBUG 01-13 08:46:18.069302.069302 mlpmodule.py:559] gpu group tensors cost 0.0005521774291992188 s
DEBUG 01-13 08:46:18.070552.070552 mlpmodule.py:592] gpu pad cost 0.0014562606811523438 s
DEBUG 01-13 08:46:18.070978.070978 mlpmodule.py:598] start_w1
DEBUG 01-13 08:46:18.071724.071724 mlpmodule.py:602] start_w3
DEBUG 01-13 08:46:18.071789.071789 mlpmodule.py:608] start_w2
DEBUG 01-13 08:46:18.071410.071410 mlpmodule.py:611] gpu group einsum cost 0.0006327629089355469 s
DEBUG 01-13 08:46:18.073138.073138 mlpmodule.py:683] gpu experts func einsum cost 0.004963397979736328 s
DEBUG 01-13 08:46:18.073691.073691 cuda_h.py:19] end gpu_experts cost 0.005112171173095703 seconds
DEBUG 01-13 08:46:18.073348.073348 cuda_h.py:10] start cpu_thread_manager_mp_wait
DEBUG 01-13 08:46:18.073674.073674 cuda_h.py:19] end cpu_thread_manager_mp_wait cost 3.647804260253906e-05 seconds
DEBUG 01-13 08:46:18.074876.074876 cuda_h.py:19] end layer_moe_generate_mp_l_20 cost 0.06353878974914551 seconds
DEBUG 01-13 08:46:18.074293.074293 lmp.py:1550] -------------------------------- end prefill layer 19 --------------------------------
DEBUG 01-13 08:46:18.074725.074725 lmp.py:1493] -------------------------------- start prefill layer 20 --------------------------------
DEBUG 01-13 08:46:18.074613.074613 cuda_h.py:10] start start_load_qkvogn_s_weight_l_21
DEBUG 01-13 08:46:18.074839.074839 cuda_h.py:10] start start_load_qkvogn_s_weight_l_21
DEBUG 01-13 08:46:18.074198.074198 cuda_h.py:19] end start_load_qkvogn_s_weight_l_21 cost 2.9325485229492188e-05 seconds
DEBUG 01-13 08:46:18.074471.074471 cuda_h.py:19] end start_load_qkvogn_s_weight_l_21 cost 5.817413330078125e-05 seconds
DEBUG 01-13 08:46:18.074544.074544 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-13 08:46:18.074878.074878 cuda_h.py:10] start sllm_worker_task
DEBUG 01-13 08:46:18.074048.074048 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-13 08:46:18.074102.074102 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-13 08:46:18.074304.074304 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-13 08:46:18.074635.074635 mlpmodule.py:785]  experts func einsum cost 0.059805870056152344 s
DEBUG 01-13 08:46:18.074952.074952 cuda_h.py:19] end experts_func_gpu_einsum_mp cost 0.06045842170715332 seconds
DEBUG 01-13 08:46:18.075164.075164 cuda_h.py:19] end allocate_cuda_memory cost 0.00031566619873046875 seconds
DEBUG 01-13 08:46:18.075219.075219 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-13 08:46:18.075121.075121 sllm_store_c.py:27] get device uuid map
DEBUG 01-13 08:46:18.075275.075275 sllm_store_c.py:29] call client load into gpu
DEBUG 01-13 08:46:18.075786.075786 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 68a29450-1fb6-442a-b512-05cc2fe946d2
DEBUG 01-13 08:46:18.075186.075186 client.py:106] call stub.LoadModelAsync
DEBUG 01-13 08:46:18.075884.075884 cuda_h.py:10] start self_attn
INFO 01-13 08:46:18.076373.076373 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 68a29450-1fb6-442a-b512-05cc2fe946d2
DEBUG 01-13 08:46:18.076402.076402 cuda_h.py:19] end load_into_gpu_async cost 0.0012595653533935547 seconds
DEBUG 01-13 08:46:18.076436.076436 cuda_h.py:10] start restore_tensors2
DEBUG 01-13 08:46:18.076180.076180 cuda_h.py:19] end restore_tensors2 cost 6.723403930664062e-05 seconds
DEBUG 01-13 08:46:18.076029.076029 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0018892288208007812 seconds
INFO 01-13 08:46:18.076912.076912 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 68a29450-1fb6-442a-b512-05cc2fe946d2
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-13 08:46:18.078645.078645 cuda_h.py:19] end self_attn cost 0.002714872360229492 seconds
DEBUG 01-13 08:46:18.078528.078528 cuda_h.py:19] end iln_self_attn_paln cost 0.004244804382324219 seconds
DEBUG 01-13 08:46:18.078649.078649 cuda_h.py:10] start layer_moe_generate_mp_l_21
DEBUG 01-13 08:46:18.078597.078597 cuda_h.py:10] start gate
DEBUG 01-13 08:46:18.079010.079010 cuda_h.py:19] end gate cost 0.0006213188171386719 seconds
DEBUG 01-13 08:46:18.079025.079025 cuda_h.py:10] start experts_map_get
DEBUG 01-13 08:46:18.079120.079120 lmp.py:1611] 
DEBUG 01-13 08:46:18.079120.079120 lmp.py:1611] Expert Token Distribution & Device Allocation:
DEBUG 01-13 08:46:18.079731.079731 lmp.py:1612]   Total experts: 64
DEBUG 01-13 08:46:18.079904.079904 lmp.py:1613]   CPU experts: 32 (50%)
DEBUG 01-13 08:46:18.079739.079739 lmp.py:1614]   GPU experts: 32 (50%)
DEBUG 01-13 08:46:18.079905.079905 lmp.py:1615] 
DEBUG 01-13 08:46:18.079905.079905 lmp.py:1615]   Expert ID | Tokens | Device
DEBUG 01-13 08:46:18.079309.079309 lmp.py:1616]   -----------------------------------
DEBUG 01-13 08:46:18.079005.079005 lmp.py:1622]   Expert 54 |     23 | CPU
DEBUG 01-13 08:46:18.079648.079648 lmp.py:1622]   Expert  3 |     32 | CPU
DEBUG 01-13 08:46:18.079861.079861 lmp.py:1622]   Expert  8 |     36 | CPU
DEBUG 01-13 08:46:18.079358.079358 lmp.py:1622]   Expert 28 |     45 | CPU
DEBUG 01-13 08:46:18.079094.079094 lmp.py:1622]   Expert 43 |     55 | CPU
DEBUG 01-13 08:46:18.079591.079591 lmp.py:1622]   Expert 63 |     57 | CPU
DEBUG 01-13 08:46:18.079850.079850 lmp.py:1622]   Expert 36 |     67 | CPU
DEBUG 01-13 08:46:18.079347.079347 lmp.py:1622]   Expert 38 |     76 | CPU
DEBUG 01-13 08:46:18.080944.080944 lmp.py:1622]   Expert  6 |     78 | CPU
DEBUG 01-13 08:46:18.080587.080587 lmp.py:1622]   Expert 39 |     91 | CPU
DEBUG 01-13 08:46:18.080991.080991 lmp.py:1622]   Expert 57 |    108 | CPU
DEBUG 01-13 08:46:18.080919.080919 lmp.py:1622]   Expert 12 |    110 | CPU
DEBUG 01-13 08:46:18.080131.080131 lmp.py:1622]   Expert 41 |    112 | CPU
DEBUG 01-13 08:46:18.080344.080344 lmp.py:1622]   Expert 52 |    115 | CPU
DEBUG 01-13 08:46:18.080795.080795 lmp.py:1622]   Expert 47 |    123 | CPU
DEBUG 01-13 08:46:18.080769.080769 lmp.py:1622]   Expert 19 |    126 | CPU
DEBUG 01-13 08:46:18.080220.080220 lmp.py:1622]   Expert 13 |    128 | CPU
DEBUG 01-13 08:46:18.080432.080432 lmp.py:1622]   Expert 22 |    138 | CPU
DEBUG 01-13 08:46:18.080644.080644 lmp.py:1622]   Expert 46 |    147 | CPU
DEBUG 01-13 08:46:18.080334.080334 lmp.py:1622]   Expert 50 |    154 | CPU
DEBUG 01-13 08:46:18.080785.080785 lmp.py:1622]   Expert 20 |    162 | CPU
DEBUG 01-13 08:46:18.080189.080189 lmp.py:1622]   Expert 37 |    162 | CPU
DEBUG 01-13 08:46:18.080879.080879 lmp.py:1622]   Expert 21 |    163 | CPU
DEBUG 01-13 08:46:18.080329.080329 lmp.py:1622]   Expert 24 |    164 | CPU
DEBUG 01-13 08:46:18.080257.080257 lmp.py:1622]   Expert 55 |    168 | CPU
DEBUG 01-13 08:46:18.080946.080946 lmp.py:1622]   Expert 40 |    171 | CPU
DEBUG 01-13 08:46:18.080397.080397 lmp.py:1622]   Expert 23 |    177 | CPU
DEBUG 01-13 08:46:18.080610.080610 lmp.py:1622]   Expert 33 |    177 | CPU
DEBUG 01-13 08:46:18.080584.080584 lmp.py:1622]   Expert 49 |    178 | CPU
DEBUG 01-13 08:46:18.080796.080796 lmp.py:1622]   Expert 53 |    178 | CPU
DEBUG 01-13 08:46:18.080247.080247 lmp.py:1622]   Expert 42 |    179 | CPU
DEBUG 01-13 08:46:18.080665.080665 lmp.py:1622]   Expert  2 |    180 | CPU
DEBUG 01-13 08:46:18.080355.080355 lmp.py:1622]   Expert 61 |    182 | GPU
DEBUG 01-13 08:46:18.080428.080428 lmp.py:1622]   Expert 18 |    187 | GPU
DEBUG 01-13 08:46:18.080833.080833 lmp.py:1622]   Expert  7 |    198 | GPU
DEBUG 01-13 08:46:18.080999.080999 lmp.py:1622]   Expert 32 |    199 | GPU
DEBUG 01-13 08:46:18.080927.080927 lmp.py:1622]   Expert  0 |    201 | GPU
DEBUG 01-13 08:46:18.080093.080093 lmp.py:1622]   Expert 16 |    202 | GPU
DEBUG 01-13 08:46:18.080305.080305 lmp.py:1622]   Expert 30 |    202 | GPU
DEBUG 01-13 08:46:18.080518.080518 lmp.py:1622]   Expert  5 |    205 | GPU
DEBUG 01-13 08:46:18.080968.080968 lmp.py:1622]   Expert 14 |    207 | GPU
DEBUG 01-13 08:46:18.080942.080942 lmp.py:1622]   Expert  9 |    215 | GPU
DEBUG 01-13 08:46:18.080155.080155 lmp.py:1622]   Expert 17 |    215 | GPU
DEBUG 01-13 08:46:18.080367.080367 lmp.py:1622]   Expert 62 |    216 | GPU
DEBUG 01-13 08:46:18.080501.080501 lmp.py:1622]   Expert 31 |    218 | GPU
DEBUG 01-13 08:46:18.080667.080667 lmp.py:1622]   Expert 59 |    220 | GPU
DEBUG 01-13 08:46:18.080879.080879 lmp.py:1622]   Expert 60 |    220 | GPU
DEBUG 01-13 08:46:18.080569.080569 lmp.py:1622]   Expert 34 |    223 | GPU
DEBUG 01-13 08:46:18.080304.080304 lmp.py:1622]   Expert 29 |    229 | GPU
DEBUG 01-13 08:46:18.080802.080802 lmp.py:1622]   Expert 10 |    235 | GPU
DEBUG 01-13 08:46:18.080822.080822 lmp.py:1622]   Expert 15 |    236 | GPU
DEBUG 01-13 08:46:18.080319.080319 lmp.py:1622]   Expert 58 |    244 | GPU
DEBUG 01-13 08:46:18.080339.080339 lmp.py:1622]   Expert 26 |    248 | GPU
DEBUG 01-13 08:46:18.080837.080837 lmp.py:1622]   Expert 51 |    248 | GPU
DEBUG 01-13 08:46:18.080095.080095 lmp.py:1622]   Expert  4 |    254 | GPU
DEBUG 01-13 08:46:18.080354.080354 lmp.py:1622]   Expert 11 |    259 | GPU
DEBUG 01-13 08:46:18.080851.080851 lmp.py:1622]   Expert 44 |    265 | GPU
DEBUG 01-13 08:46:18.080779.080779 lmp.py:1622]   Expert 56 |    279 | GPU
DEBUG 01-13 08:46:18.080515.080515 lmp.py:1622]   Expert 27 |    287 | GPU
DEBUG 01-13 08:46:18.080966.080966 lmp.py:1622]   Expert  1 |    328 | GPU
DEBUG 01-13 08:46:18.080178.080178 lmp.py:1622]   Expert 45 |    358 | GPU
DEBUG 01-13 08:46:18.080391.080391 lmp.py:1622]   Expert 25 |    471 | GPU
DEBUG 01-13 08:46:18.080888.080888 lmp.py:1622]   Expert 35 |    523 | GPU
DEBUG 01-13 08:46:18.080147.080147 lmp.py:1622]   Expert 48 |    634 | GPU
DEBUG 01-13 08:46:18.080598.080598 lmp.py:1623] 
DEBUG 01-13 08:46:18.080598.080598 lmp.py:1623]   CPU total tokens: 3880 (31.6%)
DEBUG 01-13 08:46:18.080287.080287 lmp.py:1624]   GPU total tokens: 8408 (68.4%)
DEBUG 01-13 08:46:18.080029.080029 cuda_h.py:19] end experts_map_get cost 0.0014853477478027344 seconds
DEBUG 01-13 08:46:18.081919.081919 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-13 08:46:18.081244.081244 lmp.py:1632] 
DEBUG 01-13 08:46:18.081244.081244 lmp.py:1632]   Computing 32 experts on CPU MP...
DEBUG 01-13 08:46:18.081127.081127 cuda_h.py:19] end cpu_experts_submit cost 5.316734313964844e-05 seconds
DEBUG 01-13 08:46:18.081035.081035 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-13 08:46:18.081481.081481 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-13 08:46:18.081419.081419 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-13 08:46:18.082550.082550 cuda_h.py:19] end allocate_cuda_memory cost 0.0015027523040771484 seconds
DEBUG 01-13 08:46:18.082485.082485 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-13 08:46:18.082764.082764 sllm_store_c.py:27] get device uuid map
DEBUG 01-13 08:46:18.083905.083905 sllm_store_c.py:29] call client load into gpu
DEBUG 01-13 08:46:18.083508.083508 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 04c12073-26ce-492c-8e78-00bb9b6e9704
DEBUG 01-13 08:46:18.083772.083772 client.py:106] call stub.LoadModelAsync
DEBUG 01-13 08:46:18.083162.083162 cuda_h.py:10] start experts_func_gpu_einsum_mp
INFO 01-13 08:46:18.084141.084141 client.py:127] Model loaded
DEBUG 01-13 08:46:18.084599.084599 cuda_h.py:10] start restore2model
DEBUG 01-13 08:46:18.085674.085674 cuda_h.py:19] end restore2model cost 0.0004017353057861328 seconds
DEBUG 01-13 08:46:18.085596.085596 cuda_h.py:19] end sllm_worker_task cost 0.010416507720947266 seconds
INFO 01-13 08:46:18.085946.085946 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 04c12073-26ce-492c-8e78-00bb9b6e9704
DEBUG 01-13 08:46:18.085458.085458 cuda_h.py:19] end load_into_gpu_async cost 0.0025098323822021484 seconds
DEBUG 01-13 08:46:18.085114.085114 cuda_h.py:10] start restore_tensors2
DEBUG 01-13 08:46:18.085390.085390 cuda_h.py:19] end restore_tensors2 cost 0.0002827644348144531 seconds
DEBUG 01-13 08:46:18.085590.085590 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.004621744155883789 seconds
DEBUG 01-13 08:46:18.085160.085160 cuda_h.py:10] start restore2model
DEBUG 01-13 08:46:18.088630.088630 cuda_h.py:19] end restore2model cost 0.0025293827056884766 seconds
DEBUG 01-13 08:46:18.088890.088890 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.007315397262573242 seconds
DEBUG 01-13 08:46:18.088778.088778 cuda_h.py:10] start gpu_sexperts
DEBUG 01-13 08:46:18.088550.088550 cuda_h.py:19] end gpu_sexperts cost 0.0002582073211669922 seconds
DEBUG 01-13 08:46:18.088803.088803 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-13 08:46:18.088764.088764 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 1.5020370483398438e-05 seconds
DEBUG 01-13 08:46:18.088507.088507 cuda_h.py:10] start wait_experts
INFO 01-13 08:46:18.088726.088726 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 04c12073-26ce-492c-8e78-00bb9b6e9704
DEBUG 01-13 08:46:18.093963.093963 mlpmodule.py:1006] group tensors cost 0.009243488311767578 s
DEBUG 01-13 08:46:18.095444.095444 mlpmodule.py:1044] pad cost 0.0015077590942382812 s
DEBUG 01-13 08:46:18.095143.095143 mlpmodule.py:1050] create cpu tensor cost 4.029273986816406e-05 s
DEBUG 01-13 08:46:18.095562.095562 mlpmodule.py:1055] move to cpu cost 3.0040740966796875e-05 s
DEBUG 01-13 08:46:18.104533.104533 mlpmodule.py:1069] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-13 08:46:18.104738.104738 mlpmodule.py:1070] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-13 08:46:18.104185.104185 mlpmodule.py:1075] group_w3 first element: 0.039306640625
WARNING 01-13 08:46:18.104580.104580 mlpmodule.py:1085] start einsum2
DEBUG 01-13 08:46:18.117419.117419 mlpmodule.py:1095] group einsum cost 0.021930932998657227 s
DEBUG 01-13 08:46:18.118473.118473 mlpmodule.py:1103] cpy2cputensor cost 0.0006463527679443359 s
INFO 01-13 08:46:18.136605.136605 client.py:127] Model loaded
DEBUG 01-13 08:46:18.136337.136337 cuda_h.py:19] end wait_experts cost 0.04790806770324707 seconds
DEBUG 01-13 08:46:18.136855.136855 cuda_h.py:10] start gpu_experts
DEBUG 01-13 08:46:18.137247.137247 mlpmodule.py:559] gpu group tensors cost 0.000553131103515625 s
DEBUG 01-13 08:46:18.139020.139020 mlpmodule.py:592] gpu pad cost 0.0014557838439941406 s
DEBUG 01-13 08:46:18.139969.139969 mlpmodule.py:598] start_w1
DEBUG 01-13 08:46:18.139306.139306 mlpmodule.py:602] start_w3
DEBUG 01-13 08:46:18.139284.139284 mlpmodule.py:608] start_w2
DEBUG 01-13 08:46:18.139641.139641 mlpmodule.py:611] gpu group einsum cost 0.0006692409515380859 s
DEBUG 01-13 08:46:18.141475.141475 mlpmodule.py:683] gpu experts func einsum cost 0.004972219467163086 s
DEBUG 01-13 08:46:18.142696.142696 cuda_h.py:19] end gpu_experts cost 0.005125761032104492 seconds
DEBUG 01-13 08:46:18.142399.142399 cuda_h.py:10] start cpu_thread_manager_mp_wait
DEBUG 01-13 08:46:18.142964.142964 cuda_h.py:19] end cpu_thread_manager_mp_wait cost 3.5762786865234375e-05 seconds
DEBUG 01-13 08:46:18.142735.142735 cuda_h.py:19] end layer_moe_generate_mp_l_21 cost 0.0634465217590332 seconds
DEBUG 01-13 08:46:18.142007.142007 lmp.py:1550] -------------------------------- end prefill layer 20 --------------------------------
DEBUG 01-13 08:46:18.142769.142769 lmp.py:1493] -------------------------------- start prefill layer 21 --------------------------------
DEBUG 01-13 08:46:18.142611.142611 cuda_h.py:10] start start_load_qkvogn_s_weight_l_22
DEBUG 01-13 08:46:18.142029.142029 cuda_h.py:10] start start_load_qkvogn_s_weight_l_22
DEBUG 01-13 08:46:18.142720.142720 cuda_h.py:19] end start_load_qkvogn_s_weight_l_22 cost 2.86102294921875e-05 seconds
DEBUG 01-13 08:46:18.142754.142754 cuda_h.py:19] end start_load_qkvogn_s_weight_l_22 cost 5.6743621826171875e-05 seconds
DEBUG 01-13 08:46:18.142589.142589 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-13 08:46:18.142724.142724 cuda_h.py:10] start sllm_worker_task
DEBUG 01-13 08:46:18.142170.142170 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-13 08:46:18.142867.142867 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-13 08:46:18.142400.142400 mlpmodule.py:785]  experts func einsum cost 0.05849766731262207 s
DEBUG 01-13 08:46:18.143286.143286 cuda_h.py:19] end experts_func_gpu_einsum_mp cost 0.0590212345123291 seconds
DEBUG 01-13 08:46:18.142254.142254 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-13 08:46:18.143141.143141 cuda_h.py:19] end allocate_cuda_memory cost 0.00033402442932128906 seconds
DEBUG 01-13 08:46:18.143834.143834 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-13 08:46:18.143119.143119 sllm_store_c.py:27] get device uuid map
DEBUG 01-13 08:46:18.143227.143227 sllm_store_c.py:29] call client load into gpu
DEBUG 01-13 08:46:18.143261.143261 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, e9006507-29d3-46d2-b483-5284a4ec4534
DEBUG 01-13 08:46:18.143231.143231 client.py:106] call stub.LoadModelAsync
DEBUG 01-13 08:46:18.143896.143896 cuda_h.py:10] start self_attn
INFO 01-13 08:46:18.145310.145310 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, e9006507-29d3-46d2-b483-5284a4ec4534
DEBUG 01-13 08:46:18.145099.145099 cuda_h.py:19] end load_into_gpu_async cost 0.001775503158569336 seconds
DEBUG 01-13 08:46:18.145809.145809 cuda_h.py:10] start restore_tensors2
DEBUG 01-13 08:46:18.145792.145792 cuda_h.py:19] end restore_tensors2 cost 6.556510925292969e-05 seconds
DEBUG 01-13 08:46:18.145879.145879 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0025620460510253906 seconds
INFO 01-13 08:46:18.145278.145278 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, e9006507-29d3-46d2-b483-5284a4ec4534
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-13 08:46:18.146890.146890 cuda_h.py:19] end self_attn cost 0.002746105194091797 seconds
DEBUG 01-13 08:46:18.146727.146727 cuda_h.py:19] end iln_self_attn_paln cost 0.0042874813079833984 seconds
DEBUG 01-13 08:46:18.146133.146133 cuda_h.py:10] start layer_moe_generate_mp_l_22
DEBUG 01-13 08:46:18.147081.147081 cuda_h.py:10] start gate
DEBUG 01-13 08:46:18.147022.147022 cuda_h.py:19] end gate cost 0.0005910396575927734 seconds
DEBUG 01-13 08:46:18.147706.147706 cuda_h.py:10] start experts_map_get
DEBUG 01-13 08:46:18.147709.147709 lmp.py:1611] 
DEBUG 01-13 08:46:18.147709.147709 lmp.py:1611] Expert Token Distribution & Device Allocation:
DEBUG 01-13 08:46:18.147319.147319 lmp.py:1612]   Total experts: 64
DEBUG 01-13 08:46:18.148253.148253 lmp.py:1613]   CPU experts: 32 (50%)
DEBUG 01-13 08:46:18.148612.148612 lmp.py:1614]   GPU experts: 32 (50%)
DEBUG 01-13 08:46:18.148539.148539 lmp.py:1615] 
DEBUG 01-13 08:46:18.148539.148539 lmp.py:1615]   Expert ID | Tokens | Device
DEBUG 01-13 08:46:18.148705.148705 lmp.py:1616]   -----------------------------------
DEBUG 01-13 08:46:18.148640.148640 lmp.py:1622]   Expert  9 |     30 | CPU
DEBUG 01-13 08:46:18.148329.148329 lmp.py:1622]   Expert 44 |     30 | CPU
DEBUG 01-13 08:46:18.148542.148542 lmp.py:1622]   Expert 11 |     37 | CPU
DEBUG 01-13 08:46:18.148516.148516 lmp.py:1622]   Expert 56 |     57 | CPU
DEBUG 01-13 08:46:18.148490.148490 lmp.py:1622]   Expert 54 |     66 | CPU
DEBUG 01-13 08:46:18.148702.148702 lmp.py:1622]   Expert  7 |     89 | CPU
DEBUG 01-13 08:46:18.148915.148915 lmp.py:1622]   Expert 62 |     94 | CPU
DEBUG 01-13 08:46:18.148366.148366 lmp.py:1622]   Expert 47 |     99 | CPU
DEBUG 01-13 08:46:18.148817.148817 lmp.py:1622]   Expert 51 |    103 | CPU
DEBUG 01-13 08:46:18.148267.148267 lmp.py:1622]   Expert 52 |    106 | CPU
DEBUG 01-13 08:46:18.148003.148003 lmp.py:1622]   Expert 60 |    106 | CPU
DEBUG 01-13 08:46:18.148216.148216 lmp.py:1622]   Expert 41 |    107 | CPU
DEBUG 01-13 08:46:18.148713.148713 lmp.py:1622]   Expert 53 |    111 | CPU
DEBUG 01-13 08:46:18.148210.148210 lmp.py:1622]   Expert  8 |    121 | CPU
DEBUG 01-13 08:46:18.148469.148469 lmp.py:1622]   Expert 32 |    122 | CPU
DEBUG 01-13 08:46:18.148489.148489 lmp.py:1622]   Expert  6 |    125 | CPU
DEBUG 01-13 08:46:18.148986.148986 lmp.py:1622]   Expert 22 |    125 | CPU
DEBUG 01-13 08:46:18.148676.148676 lmp.py:1622]   Expert  1 |    128 | CPU
DEBUG 01-13 08:46:18.148173.148173 lmp.py:1622]   Expert 27 |    135 | CPU
DEBUG 01-13 08:46:18.148684.148684 lmp.py:1622]   Expert 48 |    135 | CPU
DEBUG 01-13 08:46:18.148824.148824 lmp.py:1622]   Expert 23 |    139 | CPU
DEBUG 01-13 08:46:18.148513.148513 lmp.py:1622]   Expert 35 |    140 | CPU
DEBUG 01-13 08:46:18.148964.148964 lmp.py:1622]   Expert  2 |    143 | CPU
DEBUG 01-13 08:46:18.148415.148415 lmp.py:1622]   Expert 59 |    143 | CPU
DEBUG 01-13 08:46:18.148389.148389 lmp.py:1622]   Expert 39 |    144 | CPU
DEBUG 01-13 08:46:18.148363.148363 lmp.py:1622]   Expert 26 |    145 | CPU
DEBUG 01-13 08:46:18.148860.148860 lmp.py:1622]   Expert 50 |    145 | CPU
DEBUG 01-13 08:46:18.148834.148834 lmp.py:1622]   Expert 14 |    153 | CPU
DEBUG 01-13 08:46:18.148570.148570 lmp.py:1622]   Expert 38 |    166 | CPU
DEBUG 01-13 08:46:18.148305.148305 lmp.py:1622]   Expert 24 |    167 | CPU
DEBUG 01-13 08:46:18.148041.148041 lmp.py:1622]   Expert 49 |    167 | CPU
DEBUG 01-13 08:46:18.148015.148015 lmp.py:1622]   Expert 46 |    170 | CPU
DEBUG 01-13 08:46:18.148751.148751 lmp.py:1622]   Expert 34 |    171 | GPU
DEBUG 01-13 08:46:18.148963.148963 lmp.py:1622]   Expert  0 |    173 | GPU
DEBUG 01-13 08:46:18.148176.148176 lmp.py:1622]   Expert 40 |    182 | GPU
DEBUG 01-13 08:46:18.148627.148627 lmp.py:1622]   Expert  4 |    183 | GPU
DEBUG 01-13 08:46:18.148077.148077 lmp.py:1622]   Expert 63 |    186 | GPU
DEBUG 01-13 08:46:18.148005.148005 lmp.py:1622]   Expert  5 |    189 | GPU
DEBUG 01-13 08:46:18.148979.148979 lmp.py:1622]   Expert 13 |    193 | GPU
DEBUG 01-13 08:46:18.148384.148384 lmp.py:1622]   Expert 19 |    196 | GPU
DEBUG 01-13 08:46:18.148311.148311 lmp.py:1622]   Expert 29 |    205 | GPU
DEBUG 01-13 08:46:18.148001.148001 lmp.py:1622]   Expert 43 |    212 | GPU
DEBUG 01-13 08:46:18.148167.148167 lmp.py:1622]   Expert 61 |    216 | GPU
DEBUG 01-13 08:46:18.148095.148095 lmp.py:1622]   Expert 57 |    218 | GPU
DEBUG 01-13 08:46:18.148022.148022 lmp.py:1622]   Expert 33 |    220 | GPU
DEBUG 01-13 08:46:18.148712.148712 lmp.py:1622]   Expert 31 |    243 | GPU
DEBUG 01-13 08:46:18.148116.148116 lmp.py:1622]   Expert 16 |    249 | GPU
DEBUG 01-13 08:46:18.148282.148282 lmp.py:1622]   Expert 20 |    251 | GPU
DEBUG 01-13 08:46:18.148448.148448 lmp.py:1622]   Expert  3 |    252 | GPU
DEBUG 01-13 08:46:18.148615.148615 lmp.py:1622]   Expert 15 |    258 | GPU
DEBUG 01-13 08:46:18.148781.148781 lmp.py:1622]   Expert 37 |    258 | GPU
DEBUG 01-13 08:46:18.148232.148232 lmp.py:1622]   Expert 12 |    264 | GPU
DEBUG 01-13 08:46:18.148921.148921 lmp.py:1622]   Expert 36 |    274 | GPU
DEBUG 01-13 08:46:18.148610.148610 lmp.py:1622]   Expert 18 |    276 | GPU
DEBUG 01-13 08:46:18.148538.148538 lmp.py:1622]   Expert 28 |    301 | GPU
DEBUG 01-13 08:46:18.149466.149466 lmp.py:1622]   Expert 17 |    308 | GPU
DEBUG 01-13 08:46:18.149393.149393 lmp.py:1622]   Expert 55 |    310 | GPU
DEBUG 01-13 08:46:18.149083.149083 lmp.py:1622]   Expert 30 |    320 | GPU
DEBUG 01-13 08:46:18.149249.149249 lmp.py:1622]   Expert 25 |    325 | GPU
DEBUG 01-13 08:46:18.149177.149177 lmp.py:1622]   Expert 58 |    340 | GPU
DEBUG 01-13 08:46:18.149581.149581 lmp.py:1622]   Expert 10 |    360 | GPU
DEBUG 01-13 08:46:18.149747.149747 lmp.py:1622]   Expert 21 |    373 | GPU
DEBUG 01-13 08:46:18.149629.149629 lmp.py:1622]   Expert 45 |    383 | GPU
DEBUG 01-13 08:46:18.149795.149795 lmp.py:1622]   Expert 42 |    651 | GPU
DEBUG 01-13 08:46:18.149915.149915 lmp.py:1623] 
DEBUG 01-13 08:46:18.149915.149915 lmp.py:1623]   CPU total tokens: 3748 (30.5%)
DEBUG 01-13 08:46:18.149796.149796 lmp.py:1624]   GPU total tokens: 8540 (69.5%)
DEBUG 01-13 08:46:18.149730.149730 cuda_h.py:19] end experts_map_get cost 0.0015003681182861328 seconds
DEBUG 01-13 08:46:18.149004.149004 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-13 08:46:18.149568.149568 lmp.py:1632] 
DEBUG 01-13 08:46:18.149568.149568 lmp.py:1632]   Computing 32 experts on CPU MP...
DEBUG 01-13 08:46:18.149536.149536 cuda_h.py:19] end cpu_experts_submit cost 4.649162292480469e-05 seconds
DEBUG 01-13 08:46:18.149802.149802 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-13 08:46:18.149247.149247 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-13 08:46:18.149040.149040 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-13 08:46:18.151348.151348 cuda_h.py:19] end allocate_cuda_memory cost 0.001844167709350586 seconds
DEBUG 01-13 08:46:18.151806.151806 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-13 08:46:18.151132.151132 sllm_store_c.py:27] get device uuid map
DEBUG 01-13 08:46:18.151703.151703 sllm_store_c.py:29] call client load into gpu
DEBUG 01-13 08:46:18.151591.151591 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, c726a9d9-670e-4e80-9f4a-b806845f7699
DEBUG 01-13 08:46:18.151040.151040 client.py:106] call stub.LoadModelAsync
DEBUG 01-13 08:46:18.152597.152597 cuda_h.py:10] start experts_func_gpu_einsum_mp
INFO 01-13 08:46:18.153870.153870 client.py:127] Model loaded
DEBUG 01-13 08:46:18.153567.153567 cuda_h.py:10] start restore2model
DEBUG 01-13 08:46:18.153132.153132 cuda_h.py:19] end restore2model cost 0.0004112720489501953 seconds
DEBUG 01-13 08:46:18.153677.153677 cuda_h.py:19] end sllm_worker_task cost 0.010984659194946289 seconds
INFO 01-13 08:46:18.154218.154218 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, c726a9d9-670e-4e80-9f4a-b806845f7699
DEBUG 01-13 08:46:18.154538.154538 cuda_h.py:19] end load_into_gpu_async cost 0.0032100677490234375 seconds
DEBUG 01-13 08:46:18.154240.154240 cuda_h.py:10] start restore_tensors2
DEBUG 01-13 08:46:18.155800.155800 cuda_h.py:19] end restore_tensors2 cost 0.00028228759765625 seconds
DEBUG 01-13 08:46:18.155239.155239 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0056591033935546875 seconds
DEBUG 01-13 08:46:18.155617.155617 cuda_h.py:10] start restore2model
DEBUG 01-13 08:46:18.157804.157804 cuda_h.py:19] end restore2model cost 0.0025682449340820312 seconds
DEBUG 01-13 08:46:18.157256.157256 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.008389711380004883 seconds
DEBUG 01-13 08:46:18.157118.157118 cuda_h.py:10] start gpu_sexperts
DEBUG 01-13 08:46:18.158174.158174 cuda_h.py:19] end gpu_sexperts cost 0.00025773048400878906 seconds
DEBUG 01-13 08:46:18.158619.158619 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-13 08:46:18.158674.158674 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 1.33514404296875e-05 seconds
DEBUG 01-13 08:46:18.158178.158178 cuda_h.py:10] start wait_experts
INFO 01-13 08:46:18.158158.158158 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, c726a9d9-670e-4e80-9f4a-b806845f7699
DEBUG 01-13 08:46:18.161784.161784 mlpmodule.py:1006] group tensors cost 0.008724689483642578 s
DEBUG 01-13 08:46:18.164877.164877 mlpmodule.py:1044] pad cost 0.0015168190002441406 s
DEBUG 01-13 08:46:18.164642.164642 mlpmodule.py:1050] create cpu tensor cost 5.4836273193359375e-05 s
DEBUG 01-13 08:46:18.164353.164353 mlpmodule.py:1055] move to cpu cost 3.0279159545898438e-05 s
DEBUG 01-13 08:46:18.170907.170907 mlpmodule.py:1069] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-13 08:46:18.171728.171728 mlpmodule.py:1070] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-13 08:46:18.171347.171347 mlpmodule.py:1075] group_w3 first element: 0.00066375732421875
WARNING 01-13 08:46:18.171630.171630 mlpmodule.py:1085] start einsum2
DEBUG 01-13 08:46:18.183514.183514 mlpmodule.py:1095] group einsum cost 0.01917719841003418 s
DEBUG 01-13 08:46:18.184073.184073 mlpmodule.py:1103] cpy2cputensor cost 0.0006582736968994141 s
DEBUG 01-13 08:46:18.203931.203931 mlpmodule.py:785]  experts func einsum cost 0.05031180381774902 s
DEBUG 01-13 08:46:18.204812.204812 cuda_h.py:19] end experts_func_gpu_einsum_mp cost 0.05146455764770508 seconds
INFO 01-13 08:46:18.205256.205256 client.py:127] Model loaded
DEBUG 01-13 08:46:18.205673.205673 cuda_h.py:19] end wait_experts cost 0.04718756675720215 seconds
DEBUG 01-13 08:46:18.205312.205312 cuda_h.py:10] start gpu_experts
DEBUG 01-13 08:46:18.206712.206712 mlpmodule.py:559] gpu group tensors cost 0.0005211830139160156 s
DEBUG 01-13 08:46:18.207072.207072 mlpmodule.py:592] gpu pad cost 0.0013997554779052734 s
DEBUG 01-13 08:46:18.207922.207922 mlpmodule.py:598] start_w1
DEBUG 01-13 08:46:18.208801.208801 mlpmodule.py:602] start_w3
DEBUG 01-13 08:46:18.208111.208111 mlpmodule.py:608] start_w2
DEBUG 01-13 08:46:18.208407.208407 mlpmodule.py:611] gpu group einsum cost 0.000637054443359375 s
DEBUG 01-13 08:46:18.210493.210493 mlpmodule.py:683] gpu experts func einsum cost 0.004855632781982422 s
DEBUG 01-13 08:46:18.210317.210317 cuda_h.py:19] end gpu_experts cost 0.005031108856201172 seconds
DEBUG 01-13 08:46:18.210119.210119 cuda_h.py:10] start cpu_thread_manager_mp_wait
DEBUG 01-13 08:46:18.210823.210823 cuda_h.py:19] end cpu_thread_manager_mp_wait cost 3.361701965332031e-05 seconds
DEBUG 01-13 08:46:18.210402.210402 cuda_h.py:19] end layer_moe_generate_mp_l_22 cost 0.06379294395446777 seconds
DEBUG 01-13 08:46:18.210250.210250 lmp.py:1550] -------------------------------- end prefill layer 21 --------------------------------
DEBUG 01-13 08:46:18.211244.211244 lmp.py:1493] -------------------------------- start prefill layer 22 --------------------------------
DEBUG 01-13 08:46:18.211371.211371 cuda_h.py:10] start start_load_qkvogn_s_weight_l_23
DEBUG 01-13 08:46:18.211551.211551 cuda_h.py:10] start start_load_qkvogn_s_weight_l_23
DEBUG 01-13 08:46:18.211910.211910 cuda_h.py:19] end start_load_qkvogn_s_weight_l_23 cost 3.0517578125e-05 seconds
DEBUG 01-13 08:46:18.211680.211680 cuda_h.py:19] end start_load_qkvogn_s_weight_l_23 cost 7.390975952148438e-05 seconds
DEBUG 01-13 08:46:18.211893.211893 cuda_h.py:10] start sllm_worker_task
DEBUG 01-13 08:46:18.211862.211862 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-13 08:46:18.211262.211262 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-13 08:46:18.211153.211153 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-13 08:46:18.211738.211738 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-13 08:46:18.211082.211082 cuda_h.py:19] end allocate_cuda_memory cost 0.00028896331787109375 seconds
DEBUG 01-13 08:46:18.212476.212476 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-13 08:46:18.212676.212676 sllm_store_c.py:27] get device uuid map
DEBUG 01-13 08:46:18.212943.212943 sllm_store_c.py:29] call client load into gpu
DEBUG 01-13 08:46:18.212321.212321 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 40dba860-c5ba-4be2-8e97-df9475940294
DEBUG 01-13 08:46:18.212503.212503 client.py:106] call stub.LoadModelAsync
DEBUG 01-13 08:46:18.212236.212236 cuda_h.py:10] start self_attn
INFO 01-13 08:46:18.213488.213488 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 40dba860-c5ba-4be2-8e97-df9475940294
DEBUG 01-13 08:46:18.213756.213756 cuda_h.py:19] end load_into_gpu_async cost 0.0013914108276367188 seconds
DEBUG 01-13 08:46:18.213803.213803 cuda_h.py:10] start restore_tensors2
DEBUG 01-13 08:46:18.213436.213436 cuda_h.py:19] end restore_tensors2 cost 7.963180541992188e-05 seconds
DEBUG 01-13 08:46:18.213298.213298 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0021255016326904297 seconds
INFO 01-13 08:46:18.213863.213863 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 40dba860-c5ba-4be2-8e97-df9475940294
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-13 08:46:18.215496.215496 cuda_h.py:19] end self_attn cost 0.0027654170989990234 seconds
DEBUG 01-13 08:46:18.215711.215711 cuda_h.py:19] end iln_self_attn_paln cost 0.004244804382324219 seconds
DEBUG 01-13 08:46:18.215308.215308 cuda_h.py:10] start layer_moe_generate_mp_l_23
DEBUG 01-13 08:46:18.215256.215256 cuda_h.py:10] start gate
DEBUG 01-13 08:46:18.216623.216623 cuda_h.py:19] end gate cost 0.0006136894226074219 seconds
DEBUG 01-13 08:46:18.216552.216552 cuda_h.py:10] start experts_map_get
DEBUG 01-13 08:46:18.216793.216793 lmp.py:1611] 
DEBUG 01-13 08:46:18.216793.216793 lmp.py:1611] Expert Token Distribution & Device Allocation:
DEBUG 01-13 08:46:18.216880.216880 lmp.py:1612]   Total experts: 64
DEBUG 01-13 08:46:18.216768.216768 lmp.py:1613]   CPU experts: 32 (50%)
DEBUG 01-13 08:46:18.216603.216603 lmp.py:1614]   GPU experts: 32 (50%)
DEBUG 01-13 08:46:18.216531.216531 lmp.py:1615] 
DEBUG 01-13 08:46:18.216531.216531 lmp.py:1615]   Expert ID | Tokens | Device
DEBUG 01-13 08:46:18.216936.216936 lmp.py:1616]   -----------------------------------
DEBUG 01-13 08:46:18.216062.216062 lmp.py:1622]   Expert 25 |     16 | CPU
DEBUG 01-13 08:46:18.216944.216944 lmp.py:1622]   Expert 48 |     34 | CPU
DEBUG 01-13 08:46:18.216633.216633 lmp.py:1622]   Expert 45 |     35 | CPU
DEBUG 01-13 08:46:18.216607.216607 lmp.py:1622]   Expert  9 |     58 | CPU
DEBUG 01-13 08:46:18.216819.216819 lmp.py:1622]   Expert 54 |     73 | CPU
DEBUG 01-13 08:46:18.216555.216555 lmp.py:1622]   Expert 43 |     79 | CPU
DEBUG 01-13 08:46:18.216291.216291 lmp.py:1622]   Expert 20 |     85 | CPU
DEBUG 01-13 08:46:18.216265.216265 lmp.py:1622]   Expert 57 |     86 | CPU
DEBUG 01-13 08:46:18.216762.216762 lmp.py:1622]   Expert 47 |     88 | CPU
DEBUG 01-13 08:46:18.217451.217451 lmp.py:1622]   Expert  6 |     90 | CPU
DEBUG 01-13 08:46:18.217617.217617 lmp.py:1622]   Expert  0 |     91 | CPU
DEBUG 01-13 08:46:18.217452.217452 lmp.py:1622]   Expert 36 |    100 | CPU
DEBUG 01-13 08:46:18.217857.217857 lmp.py:1622]   Expert 62 |    101 | CPU
DEBUG 01-13 08:46:18.217785.217785 lmp.py:1622]   Expert 13 |    103 | CPU
DEBUG 01-13 08:46:18.217474.217474 lmp.py:1622]   Expert 61 |    103 | CPU
DEBUG 01-13 08:46:18.217402.217402 lmp.py:1622]   Expert 15 |    104 | CPU
DEBUG 01-13 08:46:18.217091.217091 lmp.py:1622]   Expert 46 |    106 | CPU
DEBUG 01-13 08:46:18.217257.217257 lmp.py:1622]   Expert 50 |    106 | CPU
DEBUG 01-13 08:46:18.217708.217708 lmp.py:1622]   Expert 37 |    109 | CPU
DEBUG 01-13 08:46:18.217159.217159 lmp.py:1622]   Expert  1 |    110 | CPU
DEBUG 01-13 08:46:18.217848.217848 lmp.py:1622]   Expert 38 |    115 | CPU
DEBUG 01-13 08:46:18.217014.217014 lmp.py:1622]   Expert 14 |    125 | CPU
DEBUG 01-13 08:46:18.217134.217134 lmp.py:1622]   Expert 44 |    130 | CPU
DEBUG 01-13 08:46:18.217539.217539 lmp.py:1622]   Expert 21 |    136 | CPU
DEBUG 01-13 08:46:18.217705.217705 lmp.py:1622]   Expert  7 |    138 | CPU
DEBUG 01-13 08:46:18.217871.217871 lmp.py:1622]   Expert 28 |    139 | CPU
DEBUG 01-13 08:46:18.217560.217560 lmp.py:1622]   Expert 10 |    147 | CPU
DEBUG 01-13 08:46:18.217011.217011 lmp.py:1622]   Expert 52 |    148 | CPU
DEBUG 01-13 08:46:18.217462.217462 lmp.py:1622]   Expert 24 |    157 | CPU
DEBUG 01-13 08:46:18.217151.217151 lmp.py:1622]   Expert 42 |    159 | CPU
DEBUG 01-13 08:46:18.217841.217841 lmp.py:1622]   Expert 11 |    163 | CPU
DEBUG 01-13 08:46:18.217292.217292 lmp.py:1622]   Expert 26 |    164 | CPU
DEBUG 01-13 08:46:18.217742.217742 lmp.py:1622]   Expert 35 |    169 | GPU
DEBUG 01-13 08:46:18.217432.217432 lmp.py:1622]   Expert  2 |    170 | GPU
DEBUG 01-13 08:46:18.217883.217883 lmp.py:1622]   Expert 31 |    174 | GPU
DEBUG 01-13 08:46:18.217333.217333 lmp.py:1622]   Expert  3 |    175 | GPU
DEBUG 01-13 08:46:18.217546.217546 lmp.py:1622]   Expert 32 |    179 | GPU
DEBUG 01-13 08:46:18.217427.217427 lmp.py:1622]   Expert 19 |    186 | GPU
DEBUG 01-13 08:46:18.217832.217832 lmp.py:1622]   Expert 12 |    193 | GPU
DEBUG 01-13 08:46:18.217236.217236 lmp.py:1622]   Expert 60 |    208 | GPU
DEBUG 01-13 08:46:18.217164.217164 lmp.py:1622]   Expert 56 |    210 | GPU
DEBUG 01-13 08:46:18.217284.217284 lmp.py:1622]   Expert 40 |    211 | GPU
DEBUG 01-13 08:46:18.217735.217735 lmp.py:1622]   Expert 41 |    218 | GPU
DEBUG 01-13 08:46:18.217424.217424 lmp.py:1622]   Expert 58 |    228 | GPU
DEBUG 01-13 08:46:18.217352.217352 lmp.py:1622]   Expert 53 |    231 | GPU
DEBUG 01-13 08:46:18.217803.217803 lmp.py:1622]   Expert 16 |    234 | GPU
DEBUG 01-13 08:46:18.217492.217492 lmp.py:1622]   Expert 51 |    234 | GPU
DEBUG 01-13 08:46:18.217943.217943 lmp.py:1622]   Expert 23 |    237 | GPU
DEBUG 01-13 08:46:18.217155.217155 lmp.py:1622]   Expert  8 |    241 | GPU
DEBUG 01-13 08:46:18.217083.217083 lmp.py:1622]   Expert  4 |    255 | GPU
DEBUG 01-13 08:46:18.217249.217249 lmp.py:1622]   Expert 59 |    255 | GPU
DEBUG 01-13 08:46:18.217415.217415 lmp.py:1622]   Expert 49 |    274 | GPU
DEBUG 01-13 08:46:18.217297.217297 lmp.py:1622]   Expert 55 |    279 | GPU
DEBUG 01-13 08:46:18.217940.217940 lmp.py:1622]   Expert 18 |    283 | GPU
DEBUG 01-13 08:46:18.217391.217391 lmp.py:1622]   Expert 29 |    286 | GPU
DEBUG 01-13 08:46:18.217080.217080 lmp.py:1622]   Expert 63 |    296 | GPU
DEBUG 01-13 08:46:18.217531.217531 lmp.py:1622]   Expert 34 |    299 | GPU
DEBUG 01-13 08:46:18.217982.217982 lmp.py:1622]   Expert 27 |    348 | GPU
DEBUG 01-13 08:46:18.217433.217433 lmp.py:1622]   Expert 39 |    366 | GPU
DEBUG 01-13 08:46:18.217884.217884 lmp.py:1622]   Expert 17 |    386 | GPU
DEBUG 01-13 08:46:18.217096.217096 lmp.py:1622]   Expert 22 |    427 | GPU
DEBUG 01-13 08:46:18.217547.217547 lmp.py:1622]   Expert 30 |    443 | GPU
DEBUG 01-13 08:46:18.217475.217475 lmp.py:1622]   Expert 33 |    480 | GPU
DEBUG 01-13 08:46:18.217402.217402 lmp.py:1622]   Expert  5 |    715 | GPU
DEBUG 01-13 08:46:18.217284.217284 lmp.py:1623] 
DEBUG 01-13 08:46:18.217284.217284 lmp.py:1623]   CPU total tokens: 3398 (27.7%)
DEBUG 01-13 08:46:18.217880.217880 lmp.py:1624]   GPU total tokens: 8890 (72.3%)
DEBUG 01-13 08:46:18.217769.217769 cuda_h.py:19] end experts_map_get cost 0.0015020370483398438 seconds
DEBUG 01-13 08:46:18.218088.218088 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-13 08:46:18.218460.218460 lmp.py:1632] 
DEBUG 01-13 08:46:18.218460.218460 lmp.py:1632]   Computing 32 experts on CPU MP...
DEBUG 01-13 08:46:18.218283.218283 cuda_h.py:19] end cpu_experts_submit cost 4.482269287109375e-05 seconds
DEBUG 01-13 08:46:18.218787.218787 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-13 08:46:18.218279.218279 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-13 08:46:18.218422.218422 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-13 08:46:18.219836.219836 cuda_h.py:19] end allocate_cuda_memory cost 0.001430511474609375 seconds
DEBUG 01-13 08:46:18.219818.219818 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-13 08:46:18.219905.219905 sllm_store_c.py:27] get device uuid map
DEBUG 01-13 08:46:18.219806.219806 sllm_store_c.py:29] call client load into gpu
DEBUG 01-13 08:46:18.219456.219456 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, a804c937-97dc-400b-be46-0fd21b19d4b6
DEBUG 01-13 08:46:18.220713.220713 client.py:106] call stub.LoadModelAsync
DEBUG 01-13 08:46:18.220121.220121 cuda_h.py:10] start experts_func_gpu_einsum_mp
INFO 01-13 08:46:18.221438.221438 client.py:127] Model loaded
DEBUG 01-13 08:46:18.221234.221234 cuda_h.py:10] start restore2model
DEBUG 01-13 08:46:18.221451.221451 cuda_h.py:19] end restore2model cost 0.0005018711090087891 seconds
DEBUG 01-13 08:46:18.222732.222732 cuda_h.py:19] end sllm_worker_task cost 0.010678768157958984 seconds
INFO 01-13 08:46:18.222695.222695 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, a804c937-97dc-400b-be46-0fd21b19d4b6
DEBUG 01-13 08:46:18.222585.222585 cuda_h.py:19] end load_into_gpu_async cost 0.0023241043090820312 seconds
DEBUG 01-13 08:46:18.222003.222003 cuda_h.py:10] start restore_tensors2
DEBUG 01-13 08:46:18.222788.222788 cuda_h.py:19] end restore_tensors2 cost 0.0002727508544921875 seconds
DEBUG 01-13 08:46:18.222988.222988 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.004363536834716797 seconds
DEBUG 01-13 08:46:18.222559.222559 cuda_h.py:10] start restore2model
DEBUG 01-13 08:46:18.225672.225672 cuda_h.py:19] end restore2model cost 0.0025463104248046875 seconds
DEBUG 01-13 08:46:18.225124.225124 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.007074117660522461 seconds
DEBUG 01-13 08:46:18.225489.225489 cuda_h.py:10] start gpu_sexperts
DEBUG 01-13 08:46:18.225426.225426 cuda_h.py:19] end gpu_sexperts cost 0.0002608299255371094 seconds
DEBUG 01-13 08:46:18.225607.225607 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-13 08:46:18.225854.225854 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 1.3828277587890625e-05 seconds
DEBUG 01-13 08:46:18.225026.225026 cuda_h.py:10] start wait_experts
INFO 01-13 08:46:18.225584.225584 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, a804c937-97dc-400b-be46-0fd21b19d4b6
DEBUG 01-13 08:46:18.233935.233935 mlpmodule.py:1006] group tensors cost 0.01218724250793457 s
DEBUG 01-13 08:46:18.235773.235773 mlpmodule.py:1044] pad cost 0.0017218589782714844 s
DEBUG 01-13 08:46:18.236989.236989 mlpmodule.py:1050] create cpu tensor cost 7.224082946777344e-05 s
DEBUG 01-13 08:46:18.236204.236204 mlpmodule.py:1055] move to cpu cost 5.245208740234375e-05 s
DEBUG 01-13 08:46:18.247944.247944 mlpmodule.py:1069] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-13 08:46:18.247491.247491 mlpmodule.py:1070] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-13 08:46:18.247483.247483 mlpmodule.py:1075] group_w3 first element: -0.018798828125
WARNING 01-13 08:46:18.248730.248730 mlpmodule.py:1085] start einsum2
DEBUG 01-13 08:46:18.265485.265485 mlpmodule.py:1095] group einsum cost 0.029063701629638672 s
DEBUG 01-13 08:46:18.266038.266038 mlpmodule.py:1103] cpy2cputensor cost 0.0006048679351806641 s
INFO 01-13 08:46:18.277678.277678 client.py:127] Model loaded
DEBUG 01-13 08:46:18.277587.277587 cuda_h.py:19] end wait_experts cost 0.0516815185546875 seconds
DEBUG 01-13 08:46:18.277193.277193 cuda_h.py:10] start gpu_experts
DEBUG 01-13 08:46:18.278530.278530 mlpmodule.py:785]  experts func einsum cost 0.057465314865112305 s
DEBUG 01-13 08:46:18.279560.279560 mlpmodule.py:559] gpu group tensors cost 0.0014672279357910156 s
DEBUG 01-13 08:46:18.279407.279407 cuda_h.py:19] end experts_func_gpu_einsum_mp cost 0.058501243591308594 seconds
DEBUG 01-13 08:46:18.283043.283043 mlpmodule.py:592] gpu pad cost 0.0043828487396240234 s
DEBUG 01-13 08:46:18.283916.283916 mlpmodule.py:598] start_w1
DEBUG 01-13 08:46:18.284465.284465 mlpmodule.py:602] start_w3
DEBUG 01-13 08:46:18.284872.284872 mlpmodule.py:608] start_w2
DEBUG 01-13 08:46:18.285908.285908 mlpmodule.py:611] gpu group einsum cost 0.0011529922485351562 s
DEBUG 01-13 08:46:18.289493.289493 mlpmodule.py:683] gpu experts func einsum cost 0.011926889419555664 s
DEBUG 01-13 08:46:18.289365.289365 cuda_h.py:19] end gpu_experts cost 0.012200593948364258 seconds
DEBUG 01-13 08:46:18.289401.289401 cuda_h.py:10] start cpu_thread_manager_mp_wait
DEBUG 01-13 08:46:18.289809.289809 cuda_h.py:19] end cpu_thread_manager_mp_wait cost 6.4849853515625e-05 seconds
DEBUG 01-13 08:46:18.290582.290582 cuda_h.py:19] end layer_moe_generate_mp_l_23 cost 0.07439160346984863 seconds
DEBUG 01-13 08:46:18.290298.290298 lmp.py:1550] -------------------------------- end prefill layer 22 --------------------------------
DEBUG 01-13 08:46:18.290731.290731 lmp.py:1493] -------------------------------- start prefill layer 23 --------------------------------
DEBUG 01-13 08:46:18.290660.290660 cuda_h.py:10] start start_load_qkvogn_s_weight_l_24
DEBUG 01-13 08:46:18.290596.290596 cuda_h.py:10] start start_load_qkvogn_s_weight_l_24
DEBUG 01-13 08:46:18.290553.290553 cuda_h.py:19] end start_load_qkvogn_s_weight_l_24 cost 5.745887756347656e-05 seconds
DEBUG 01-13 08:46:18.290720.290720 cuda_h.py:19] end start_load_qkvogn_s_weight_l_24 cost 0.00011682510375976562 seconds
DEBUG 01-13 08:46:18.290589.290589 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-13 08:46:18.291090.291090 cuda_h.py:10] start sllm_worker_task
DEBUG 01-13 08:46:18.291264.291264 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-13 08:46:18.291339.291339 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-13 08:46:18.291593.291593 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-13 08:46:18.292820.292820 cuda_h.py:19] end allocate_cuda_memory cost 0.00037741661071777344 seconds
DEBUG 01-13 08:46:18.292539.292539 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-13 08:46:18.292044.292044 sllm_store_c.py:27] get device uuid map
DEBUG 01-13 08:46:18.292100.292100 sllm_store_c.py:29] call client load into gpu
DEBUG 01-13 08:46:18.292896.292896 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 1304355b-285e-461d-8ef3-0c3cdd891c38
DEBUG 01-13 08:46:18.292762.292762 client.py:106] call stub.LoadModelAsync
DEBUG 01-13 08:46:18.293502.293502 cuda_h.py:10] start self_attn
INFO 01-13 08:46:18.293314.293314 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 1304355b-285e-461d-8ef3-0c3cdd891c38
DEBUG 01-13 08:46:18.293225.293225 cuda_h.py:19] end load_into_gpu_async cost 0.0016384124755859375 seconds
DEBUG 01-13 08:46:18.293955.293955 cuda_h.py:10] start restore_tensors2
DEBUG 01-13 08:46:18.294212.294212 cuda_h.py:19] end restore_tensors2 cost 0.000110626220703125 seconds
DEBUG 01-13 08:46:18.294995.294995 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.002547025680541992 seconds
INFO 01-13 08:46:18.294435.294435 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 1304355b-285e-461d-8ef3-0c3cdd891c38
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
INFO 01-13 08:46:18.301514.301514 client.py:127] Model loaded
DEBUG 01-13 08:46:18.301238.301238 cuda_h.py:10] start restore2model
DEBUG 01-13 08:46:18.302763.302763 cuda_h.py:19] end restore2model cost 0.0007848739624023438 seconds
DEBUG 01-13 08:46:18.302602.302602 cuda_h.py:19] end sllm_worker_task cost 0.011414527893066406 seconds
DEBUG 01-13 08:46:18.303699.303699 cuda_h.py:19] end self_attn cost 0.010095834732055664 seconds
DEBUG 01-13 08:46:18.303052.303052 cuda_h.py:19] end iln_self_attn_paln cost 0.012790441513061523 seconds
DEBUG 01-13 08:46:18.303108.303108 cuda_h.py:10] start layer_moe_generate_mp_l_24
DEBUG 01-13 08:46:18.303739.303739 cuda_h.py:10] start gate
DEBUG 01-13 08:46:18.304773.304773 cuda_h.py:19] end gate cost 0.0007903575897216797 seconds
DEBUG 01-13 08:46:18.304186.304186 cuda_h.py:10] start experts_map_get
DEBUG 01-13 08:46:18.305244.305244 lmp.py:1611] 
DEBUG 01-13 08:46:18.305244.305244 lmp.py:1611] Expert Token Distribution & Device Allocation:
DEBUG 01-13 08:46:18.305484.305484 lmp.py:1612]   Total experts: 64
DEBUG 01-13 08:46:18.305094.305094 lmp.py:1613]   CPU experts: 32 (50%)
DEBUG 01-13 08:46:18.305651.305651 lmp.py:1614]   GPU experts: 32 (50%)
DEBUG 01-13 08:46:18.305109.305109 lmp.py:1615] 
DEBUG 01-13 08:46:18.305109.305109 lmp.py:1615]   Expert ID | Tokens | Device
DEBUG 01-13 08:46:18.305328.305328 lmp.py:1616]   -----------------------------------
DEBUG 01-13 08:46:18.305746.305746 lmp.py:1622]   Expert  5 |     14 | CPU
DEBUG 01-13 08:46:18.305443.305443 lmp.py:1622]   Expert 56 |     32 | CPU
DEBUG 01-13 08:46:18.305423.305423 lmp.py:1622]   Expert 27 |     80 | CPU
DEBUG 01-13 08:46:18.305927.305927 lmp.py:1622]   Expert 16 |     84 | CPU
DEBUG 01-13 08:46:18.305339.305339 lmp.py:1622]   Expert 17 |     86 | CPU
DEBUG 01-13 08:46:18.305081.305081 lmp.py:1622]   Expert 40 |     98 | CPU
DEBUG 01-13 08:46:18.305347.305347 lmp.py:1622]   Expert 53 |     98 | CPU
DEBUG 01-13 08:46:18.305612.305612 lmp.py:1622]   Expert 28 |    103 | CPU
DEBUG 01-13 08:46:18.305878.305878 lmp.py:1622]   Expert 49 |    103 | CPU
DEBUG 01-13 08:46:18.305905.305905 lmp.py:1622]   Expert 63 |    103 | CPU
DEBUG 01-13 08:46:18.305409.305409 lmp.py:1622]   Expert  7 |    105 | CPU
DEBUG 01-13 08:46:18.305913.305913 lmp.py:1622]   Expert 51 |    106 | CPU
DEBUG 01-13 08:46:18.305371.305371 lmp.py:1622]   Expert 37 |    115 | CPU
DEBUG 01-13 08:46:18.305828.305828 lmp.py:1622]   Expert 38 |    122 | CPU
DEBUG 01-13 08:46:18.305332.305332 lmp.py:1622]   Expert 58 |    123 | CPU
DEBUG 01-13 08:46:18.305360.305360 lmp.py:1622]   Expert 62 |    125 | CPU
DEBUG 01-13 08:46:18.305387.305387 lmp.py:1622]   Expert 11 |    127 | CPU
DEBUG 01-13 08:46:18.305937.305937 lmp.py:1622]   Expert 47 |    131 | CPU
DEBUG 01-13 08:46:18.305726.305726 lmp.py:1622]   Expert  1 |    142 | CPU
DEBUG 01-13 08:46:18.305991.305991 lmp.py:1622]   Expert 57 |    142 | CPU
DEBUG 01-13 08:46:18.305257.305257 lmp.py:1622]   Expert 39 |    145 | CPU
DEBUG 01-13 08:46:18.305238.305238 lmp.py:1622]   Expert 25 |    148 | CPU
DEBUG 01-13 08:46:18.305695.305695 lmp.py:1622]   Expert 14 |    152 | CPU
DEBUG 01-13 08:46:18.306723.306723 lmp.py:1622]   Expert 33 |    155 | CPU
DEBUG 01-13 08:46:18.306273.306273 lmp.py:1622]   Expert 52 |    159 | CPU
DEBUG 01-13 08:46:18.306300.306300 lmp.py:1622]   Expert 60 |    166 | CPU
DEBUG 01-13 08:46:18.306327.306327 lmp.py:1622]   Expert  6 |    168 | CPU
DEBUG 01-13 08:46:18.306878.306878 lmp.py:1622]   Expert 21 |    168 | CPU
DEBUG 01-13 08:46:18.306905.306905 lmp.py:1622]   Expert 23 |    169 | CPU
DEBUG 01-13 08:46:18.306409.306409 lmp.py:1622]   Expert 44 |    170 | CPU
DEBUG 01-13 08:46:18.306866.306866 lmp.py:1622]   Expert 30 |    176 | CPU
DEBUG 01-13 08:46:18.306324.306324 lmp.py:1622]   Expert 45 |    177 | CPU
DEBUG 01-13 08:46:18.306828.306828 lmp.py:1622]   Expert 19 |    181 | GPU
DEBUG 01-13 08:46:18.306855.306855 lmp.py:1622]   Expert  4 |    187 | GPU
DEBUG 01-13 08:46:18.306121.306121 lmp.py:1622]   Expert 12 |    195 | GPU
DEBUG 01-13 08:46:18.306148.306148 lmp.py:1622]   Expert 31 |    197 | GPU
DEBUG 01-13 08:46:18.306414.306414 lmp.py:1622]   Expert  3 |    198 | GPU
DEBUG 01-13 08:46:18.306202.306202 lmp.py:1622]   Expert 55 |    201 | GPU
DEBUG 01-13 08:46:18.306468.306468 lmp.py:1622]   Expert 36 |    204 | GPU
DEBUG 01-13 08:46:18.306356.306356 lmp.py:1622]   Expert  9 |    213 | GPU
DEBUG 01-13 08:46:18.306860.306860 lmp.py:1622]   Expert 34 |    219 | GPU
DEBUG 01-13 08:46:18.306649.306649 lmp.py:1622]   Expert  0 |    222 | GPU
DEBUG 01-13 08:46:18.306676.306676 lmp.py:1622]   Expert 22 |    225 | GPU
DEBUG 01-13 08:46:18.306703.306703 lmp.py:1622]   Expert 54 |    231 | GPU
DEBUG 01-13 08:46:18.306730.306730 lmp.py:1622]   Expert 26 |    236 | GPU
DEBUG 01-13 08:46:18.306757.306757 lmp.py:1622]   Expert 43 |    240 | GPU
DEBUG 01-13 08:46:18.306785.306785 lmp.py:1622]   Expert 41 |    244 | GPU
DEBUG 01-13 08:46:18.306812.306812 lmp.py:1622]   Expert 59 |    254 | GPU
DEBUG 01-13 08:46:18.306031.306031 lmp.py:1622]   Expert 15 |    255 | GPU
DEBUG 01-13 08:46:18.306535.306535 lmp.py:1622]   Expert 18 |    258 | GPU
DEBUG 01-13 08:46:18.306324.306324 lmp.py:1622]   Expert 13 |    260 | GPU
DEBUG 01-13 08:46:18.306874.306874 lmp.py:1622]   Expert 29 |    261 | GPU
DEBUG 01-13 08:46:18.306901.306901 lmp.py:1622]   Expert 61 |    261 | GPU
DEBUG 01-13 08:46:18.306452.306452 lmp.py:1622]   Expert 20 |    264 | GPU
DEBUG 01-13 08:46:18.306101.306101 lmp.py:1622]   Expert 24 |    266 | GPU
DEBUG 01-13 08:46:18.306321.306321 lmp.py:1622]   Expert 42 |    267 | GPU
DEBUG 01-13 08:46:18.306348.306348 lmp.py:1622]   Expert 50 |    267 | GPU
DEBUG 01-13 08:46:18.306136.306136 lmp.py:1622]   Expert 35 |    278 | GPU
DEBUG 01-13 08:46:18.306687.306687 lmp.py:1622]   Expert 32 |    296 | GPU
DEBUG 01-13 08:46:18.306476.306476 lmp.py:1622]   Expert  2 |    335 | GPU
DEBUG 01-13 08:46:18.306503.306503 lmp.py:1622]   Expert  8 |    344 | GPU
DEBUG 01-13 08:46:18.306291.306291 lmp.py:1622]   Expert 10 |    363 | GPU
DEBUG 01-13 08:46:18.306080.306080 lmp.py:1622]   Expert 48 |    436 | GPU
DEBUG 01-13 08:46:18.306538.306538 lmp.py:1622]   Expert 46 |    438 | GPU
DEBUG 01-13 08:46:18.306188.306188 lmp.py:1623] 
DEBUG 01-13 08:46:18.306188.306188 lmp.py:1623]   CPU total tokens: 3992 (32.5%)
DEBUG 01-13 08:46:18.306645.306645 lmp.py:1624]   GPU total tokens: 8296 (67.5%)
DEBUG 01-13 08:46:18.306110.306110 cuda_h.py:19] end experts_map_get cost 0.002050161361694336 seconds
DEBUG 01-13 08:46:18.306357.306357 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-13 08:46:18.307312.307312 lmp.py:1632] 
DEBUG 01-13 08:46:18.307312.307312 lmp.py:1632]   Computing 32 experts on CPU MP...
DEBUG 01-13 08:46:18.307824.307824 cuda_h.py:19] end cpu_experts_submit cost 6.079673767089844e-05 seconds
DEBUG 01-13 08:46:18.307050.307050 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-13 08:46:18.307808.307808 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-13 08:46:18.307117.307117 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-13 08:46:18.307519.307519 cuda_h.py:19] end allocate_cuda_memory cost 0.0002894401550292969 seconds
DEBUG 01-13 08:46:18.307568.307568 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-13 08:46:18.307046.307046 sllm_store_c.py:27] get device uuid map
DEBUG 01-13 08:46:18.307200.307200 sllm_store_c.py:29] call client load into gpu
DEBUG 01-13 08:46:18.307856.307856 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 44bb8ead-b881-4d8c-b066-3637538f754b
DEBUG 01-13 08:46:18.308399.308399 client.py:106] call stub.LoadModelAsync
INFO 01-13 08:46:18.309979.309979 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 44bb8ead-b881-4d8c-b066-3637538f754b
DEBUG 01-13 08:46:18.309782.309782 cuda_h.py:19] end load_into_gpu_async cost 0.001804351806640625 seconds
DEBUG 01-13 08:46:18.309823.309823 cuda_h.py:10] start restore_tensors2
DEBUG 01-13 08:46:18.309232.309232 cuda_h.py:10] start experts_func_gpu_einsum_mp
DEBUG 01-13 08:46:18.310010.310010 cuda_h.py:19] end restore_tensors2 cost 0.0004227161407470703 seconds
DEBUG 01-13 08:46:18.310701.310701 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.002908468246459961 seconds
DEBUG 01-13 08:46:18.310993.310993 cuda_h.py:10] start restore2model
DEBUG 01-13 08:46:18.313296.313296 cuda_h.py:19] end restore2model cost 0.0032720565795898438 seconds
DEBUG 01-13 08:46:18.313848.313848 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.00638890266418457 seconds
DEBUG 01-13 08:46:18.313882.313882 cuda_h.py:10] start gpu_sexperts
DEBUG 01-13 08:46:18.313887.313887 cuda_h.py:19] end gpu_sexperts cost 0.00032210350036621094 seconds
DEBUG 01-13 08:46:18.313147.313147 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-13 08:46:18.313685.313685 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 1.5974044799804688e-05 seconds
DEBUG 01-13 08:46:18.314381.314381 cuda_h.py:10] start wait_experts
INFO 01-13 08:46:18.314177.314177 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 44bb8ead-b881-4d8c-b066-3637538f754b
DEBUG 01-13 08:46:18.327753.327753 mlpmodule.py:1006] group tensors cost 0.016413450241088867 s
DEBUG 01-13 08:46:18.329537.329537 mlpmodule.py:1044] pad cost 0.002071380615234375 s
DEBUG 01-13 08:46:18.330792.330792 mlpmodule.py:1050] create cpu tensor cost 4.9114227294921875e-05 s
DEBUG 01-13 08:46:18.330331.330331 mlpmodule.py:1055] move to cpu cost 3.552436828613281e-05 s
DEBUG 01-13 08:46:18.340550.340550 mlpmodule.py:1069] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-13 08:46:18.340004.340004 mlpmodule.py:1070] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-13 08:46:18.340883.340883 mlpmodule.py:1075] group_w3 first element: 0.08447265625
WARNING 01-13 08:46:18.340206.340206 mlpmodule.py:1085] start einsum2
DEBUG 01-13 08:46:18.356090.356090 mlpmodule.py:1095] group einsum cost 0.026738405227661133 s
DEBUG 01-13 08:46:18.357662.357662 mlpmodule.py:1103] cpy2cputensor cost 0.000637054443359375 s
INFO 01-13 08:46:18.365714.365714 client.py:127] Model loaded
DEBUG 01-13 08:46:18.365100.365100 cuda_h.py:19] end wait_experts cost 0.05127120018005371 seconds
DEBUG 01-13 08:46:18.365514.365514 cuda_h.py:10] start gpu_experts
DEBUG 01-13 08:46:18.367140.367140 mlpmodule.py:559] gpu group tensors cost 0.0014808177947998047 s
DEBUG 01-13 08:46:18.369898.369898 mlpmodule.py:785]  experts func einsum cost 0.05876660346984863 s
DEBUG 01-13 08:46:18.370913.370913 cuda_h.py:19] end experts_func_gpu_einsum_mp cost 0.06015729904174805 seconds
DEBUG 01-13 08:46:18.370382.370382 mlpmodule.py:592] gpu pad cost 0.0028998851776123047 s
DEBUG 01-13 08:46:18.370771.370771 mlpmodule.py:598] start_w1
DEBUG 01-13 08:46:18.370108.370108 mlpmodule.py:602] start_w3
DEBUG 01-13 08:46:18.370049.370049 mlpmodule.py:608] start_w2
DEBUG 01-13 08:46:18.371875.371875 mlpmodule.py:611] gpu group einsum cost 0.0007495880126953125 s
DEBUG 01-13 08:46:18.374309.374309 mlpmodule.py:683] gpu experts func einsum cost 0.008713722229003906 s
DEBUG 01-13 08:46:18.374942.374942 cuda_h.py:19] end gpu_experts cost 0.008956193923950195 seconds
DEBUG 01-13 08:46:18.374267.374267 cuda_h.py:10] start cpu_thread_manager_mp_wait
DEBUG 01-13 08:46:18.374985.374985 cuda_h.py:19] end cpu_thread_manager_mp_wait cost 4.2438507080078125e-05 seconds
DEBUG 01-13 08:46:18.374008.374008 cuda_h.py:19] end layer_moe_generate_mp_l_24 cost 0.07074475288391113 seconds
DEBUG 01-13 08:46:18.374454.374454 lmp.py:1550] -------------------------------- end prefill layer 23 --------------------------------
DEBUG 01-13 08:46:18.374031.374031 lmp.py:1493] -------------------------------- start prefill layer 24 --------------------------------
DEBUG 01-13 08:46:18.374449.374449 cuda_h.py:10] start start_load_qkvogn_s_weight_l_25
DEBUG 01-13 08:46:18.375397.375397 cuda_h.py:10] start start_load_qkvogn_s_weight_l_25
DEBUG 01-13 08:46:18.375432.375432 cuda_h.py:19] end start_load_qkvogn_s_weight_l_25 cost 3.4809112548828125e-05 seconds
DEBUG 01-13 08:46:18.375109.375109 cuda_h.py:19] end start_load_qkvogn_s_weight_l_25 cost 8.034706115722656e-05 seconds
DEBUG 01-13 08:46:18.375660.375660 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-13 08:46:18.375456.375456 cuda_h.py:10] start sllm_worker_task
DEBUG 01-13 08:46:18.375002.375002 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-13 08:46:18.375693.375693 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-13 08:46:18.376818.376818 cuda_h.py:19] end allocate_cuda_memory cost 0.0009357929229736328 seconds
DEBUG 01-13 08:46:18.376856.376856 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-13 08:46:18.376937.376937 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-13 08:46:18.376318.376318 sllm_store_c.py:27] get device uuid map
DEBUG 01-13 08:46:18.376002.376002 sllm_store_c.py:29] call client load into gpu
DEBUG 01-13 08:46:18.376658.376658 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 855f7dbc-075b-40c7-9474-f72eb434ea5f
DEBUG 01-13 08:46:18.376688.376688 client.py:106] call stub.LoadModelAsync
DEBUG 01-13 08:46:18.377640.377640 cuda_h.py:10] start self_attn
INFO 01-13 08:46:18.378138.378138 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 855f7dbc-075b-40c7-9474-f72eb434ea5f
DEBUG 01-13 08:46:18.378643.378643 cuda_h.py:19] end load_into_gpu_async cost 0.0017859935760498047 seconds
DEBUG 01-13 08:46:18.378915.378915 cuda_h.py:10] start restore_tensors2
DEBUG 01-13 08:46:18.378521.378521 cuda_h.py:19] end restore_tensors2 cost 6.961822509765625e-05 seconds
DEBUG 01-13 08:46:18.378608.378608 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.003223419189453125 seconds
INFO 01-13 08:46:18.378345.378345 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 855f7dbc-075b-40c7-9474-f72eb434ea5f
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-13 08:46:18.380238.380238 cuda_h.py:19] end self_attn cost 0.0033621788024902344 seconds
DEBUG 01-13 08:46:18.380892.380892 cuda_h.py:19] end iln_self_attn_paln cost 0.0057218074798583984 seconds
DEBUG 01-13 08:46:18.380974.380974 cuda_h.py:10] start layer_moe_generate_mp_l_25
DEBUG 01-13 08:46:18.380604.380604 cuda_h.py:10] start gate
DEBUG 01-13 08:46:18.381272.381272 cuda_h.py:19] end gate cost 0.0007367134094238281 seconds
DEBUG 01-13 08:46:18.381294.381294 cuda_h.py:10] start experts_map_get
DEBUG 01-13 08:46:18.382455.382455 lmp.py:1611] 
DEBUG 01-13 08:46:18.382455.382455 lmp.py:1611] Expert Token Distribution & Device Allocation:
DEBUG 01-13 08:46:18.382642.382642 lmp.py:1612]   Total experts: 64
DEBUG 01-13 08:46:18.382676.382676 lmp.py:1613]   CPU experts: 32 (50%)
DEBUG 01-13 08:46:18.382895.382895 lmp.py:1614]   GPU experts: 32 (50%)
DEBUG 01-13 08:46:18.382730.382730 lmp.py:1615] 
DEBUG 01-13 08:46:18.382730.382730 lmp.py:1615]   Expert ID | Tokens | Device
DEBUG 01-13 08:46:18.382565.382565 lmp.py:1616]   -----------------------------------
DEBUG 01-13 08:46:18.382599.382599 lmp.py:1622]   Expert 36 |     21 | CPU
DEBUG 01-13 08:46:18.382626.382626 lmp.py:1622]   Expert 35 |     33 | CPU
DEBUG 01-13 08:46:18.382461.382461 lmp.py:1622]   Expert 25 |     46 | CPU
DEBUG 01-13 08:46:18.382297.382297 lmp.py:1622]   Expert 46 |     47 | CPU
DEBUG 01-13 08:46:18.382893.382893 lmp.py:1622]   Expert 51 |     54 | CPU
DEBUG 01-13 08:46:18.382728.382728 lmp.py:1622]   Expert 16 |     56 | CPU
DEBUG 01-13 08:46:18.382325.382325 lmp.py:1622]   Expert  0 |     62 | CPU
DEBUG 01-13 08:46:18.382637.382637 lmp.py:1622]   Expert 44 |     67 | CPU
DEBUG 01-13 08:46:18.382233.382233 lmp.py:1622]   Expert 30 |     68 | CPU
DEBUG 01-13 08:46:18.382592.382592 lmp.py:1622]   Expert 42 |     68 | CPU
DEBUG 01-13 08:46:18.382427.382427 lmp.py:1622]   Expert 43 |     69 | CPU
DEBUG 01-13 08:46:18.382023.382023 lmp.py:1622]   Expert 39 |     74 | CPU
DEBUG 01-13 08:46:18.382097.382097 lmp.py:1622]   Expert 47 |     74 | CPU
DEBUG 01-13 08:46:18.382932.382932 lmp.py:1622]   Expert 55 |     74 | CPU
DEBUG 01-13 08:46:18.382436.382436 lmp.py:1622]   Expert  2 |     90 | CPU
DEBUG 01-13 08:46:18.382463.382463 lmp.py:1622]   Expert  6 |    108 | CPU
DEBUG 01-13 08:46:18.382298.382298 lmp.py:1622]   Expert  4 |    118 | CPU
DEBUG 01-13 08:46:18.382656.382656 lmp.py:1622]   Expert 61 |    118 | CPU
DEBUG 01-13 08:46:18.382492.382492 lmp.py:1622]   Expert 48 |    119 | CPU
DEBUG 01-13 08:46:18.382850.382850 lmp.py:1622]   Expert 33 |    120 | CPU
DEBUG 01-13 08:46:18.382208.382208 lmp.py:1622]   Expert 13 |    127 | CPU
DEBUG 01-13 08:46:18.382043.382043 lmp.py:1622]   Expert 24 |    128 | CPU
DEBUG 01-13 08:46:18.382845.382845 lmp.py:1622]   Expert 56 |    128 | CPU
DEBUG 01-13 08:46:18.382680.382680 lmp.py:1622]   Expert 15 |    136 | CPU
DEBUG 01-13 08:46:18.382800.382800 lmp.py:1622]   Expert 20 |    140 | CPU
DEBUG 01-13 08:46:18.382682.382682 lmp.py:1622]   Expert 38 |    140 | CPU
DEBUG 01-13 08:46:18.382563.382563 lmp.py:1622]   Expert  9 |    141 | CPU
DEBUG 01-13 08:46:18.382683.382683 lmp.py:1622]   Expert 54 |    143 | CPU
DEBUG 01-13 08:46:18.382564.382564 lmp.py:1622]   Expert  7 |    144 | CPU
DEBUG 01-13 08:46:18.382684.382684 lmp.py:1622]   Expert 29 |    149 | CPU
DEBUG 01-13 08:46:18.383042.383042 lmp.py:1622]   Expert 59 |    153 | CPU
DEBUG 01-13 08:46:18.383924.383924 lmp.py:1622]   Expert 45 |    156 | CPU
DEBUG 01-13 08:46:18.383043.383043 lmp.py:1622]   Expert 62 |    160 | GPU
DEBUG 01-13 08:46:18.383163.383163 lmp.py:1622]   Expert 19 |    166 | GPU
DEBUG 01-13 08:46:18.383045.383045 lmp.py:1622]   Expert 34 |    181 | GPU
DEBUG 01-13 08:46:18.383688.383688 lmp.py:1622]   Expert 57 |    185 | GPU
DEBUG 01-13 08:46:18.383807.383807 lmp.py:1622]   Expert 50 |    196 | GPU
DEBUG 01-13 08:46:18.383166.383166 lmp.py:1622]   Expert 53 |    208 | GPU
DEBUG 01-13 08:46:18.383762.383762 lmp.py:1622]   Expert 10 |    210 | GPU
DEBUG 01-13 08:46:18.383121.383121 lmp.py:1622]   Expert 23 |    210 | GPU
DEBUG 01-13 08:46:18.383002.383002 lmp.py:1622]   Expert  8 |    217 | GPU
DEBUG 01-13 08:46:18.383360.383360 lmp.py:1622]   Expert 31 |    217 | GPU
DEBUG 01-13 08:46:18.383242.383242 lmp.py:1622]   Expert 60 |    217 | GPU
DEBUG 01-13 08:46:18.383123.383123 lmp.py:1622]   Expert 22 |    218 | GPU
DEBUG 01-13 08:46:18.383004.383004 lmp.py:1622]   Expert 52 |    222 | GPU
DEBUG 01-13 08:46:18.383886.383886 lmp.py:1622]   Expert 18 |    224 | GPU
DEBUG 01-13 08:46:18.383482.383482 lmp.py:1622]   Expert 37 |    229 | GPU
DEBUG 01-13 08:46:18.383079.383079 lmp.py:1622]   Expert  5 |    245 | GPU
DEBUG 01-13 08:46:18.383391.383391 lmp.py:1622]   Expert 17 |    248 | GPU
DEBUG 01-13 08:46:18.383749.383749 lmp.py:1622]   Expert 11 |    264 | GPU
DEBUG 01-13 08:46:18.383392.383392 lmp.py:1622]   Expert 28 |    274 | GPU
DEBUG 01-13 08:46:18.383035.383035 lmp.py:1622]   Expert 49 |    275 | GPU
DEBUG 01-13 08:46:18.383917.383917 lmp.py:1622]   Expert 41 |    277 | GPU
DEBUG 01-13 08:46:18.383036.383036 lmp.py:1622]   Expert  1 |    279 | GPU
DEBUG 01-13 08:46:18.383156.383156 lmp.py:1622]   Expert 26 |    281 | GPU
DEBUG 01-13 08:46:18.383514.383514 lmp.py:1622]   Expert 32 |    294 | GPU
DEBUG 01-13 08:46:18.383111.383111 lmp.py:1622]   Expert 58 |    294 | GPU
DEBUG 01-13 08:46:18.383423.383423 lmp.py:1622]   Expert 40 |    304 | GPU
DEBUG 01-13 08:46:18.383543.383543 lmp.py:1622]   Expert 14 |    314 | GPU
DEBUG 01-13 08:46:18.383424.383424 lmp.py:1622]   Expert 12 |    325 | GPU
DEBUG 01-13 08:46:18.383306.383306 lmp.py:1622]   Expert 63 |    331 | GPU
DEBUG 01-13 08:46:18.383425.383425 lmp.py:1622]   Expert 21 |    365 | GPU
DEBUG 01-13 08:46:18.383307.383307 lmp.py:1622]   Expert 27 |    663 | GPU
DEBUG 01-13 08:46:18.383188.383188 lmp.py:1622]   Expert  3 |   1024 | GPU
DEBUG 01-13 08:46:18.383023.383023 lmp.py:1623] 
DEBUG 01-13 08:46:18.383023.383023 lmp.py:1623]   CPU total tokens: 3171 (25.8%)
DEBUG 01-13 08:46:18.383812.383812 lmp.py:1624]   GPU total tokens: 9117 (74.2%)
DEBUG 01-13 08:46:18.383369.383369 cuda_h.py:19] end experts_map_get cost 0.0018160343170166016 seconds
DEBUG 01-13 08:46:18.383610.383610 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-13 08:46:18.383889.383889 lmp.py:1632] 
DEBUG 01-13 08:46:18.383889.383889 lmp.py:1632]   Computing 32 experts on CPU MP...
DEBUG 01-13 08:46:18.383573.383573 cuda_h.py:19] end cpu_experts_submit cost 4.8160552978515625e-05 seconds
DEBUG 01-13 08:46:18.383269.383269 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-13 08:46:18.383337.383337 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-13 08:46:18.384566.384566 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-13 08:46:18.385852.385852 cuda_h.py:19] end allocate_cuda_memory cost 0.001577138900756836 seconds
DEBUG 01-13 08:46:18.385656.385656 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-13 08:46:18.385717.385717 sllm_store_c.py:27] get device uuid map
DEBUG 01-13 08:46:18.385679.385679 sllm_store_c.py:29] call client load into gpu
DEBUG 01-13 08:46:18.385474.385474 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, cf895dbb-fa4b-48bc-a639-7ca4f97dc276
DEBUG 01-13 08:46:18.385506.385506 client.py:106] call stub.LoadModelAsync
INFO 01-13 08:46:18.386065.386065 client.py:127] Model loaded
DEBUG 01-13 08:46:18.386267.386267 cuda_h.py:10] start restore2model
DEBUG 01-13 08:46:18.386990.386990 cuda_h.py:19] end restore2model cost 0.0003864765167236328 seconds
DEBUG 01-13 08:46:18.386566.386566 cuda_h.py:10] start experts_func_gpu_einsum_mp
DEBUG 01-13 08:46:18.387435.387435 cuda_h.py:19] end sllm_worker_task cost 0.01173853874206543 seconds
INFO 01-13 08:46:18.387083.387083 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, cf895dbb-fa4b-48bc-a639-7ca4f97dc276
DEBUG 01-13 08:46:18.388033.388033 cuda_h.py:19] end load_into_gpu_async cost 0.002301454544067383 seconds
DEBUG 01-13 08:46:18.388073.388073 cuda_h.py:10] start restore_tensors2
DEBUG 01-13 08:46:18.388802.388802 cuda_h.py:19] end restore_tensors2 cost 0.00036716461181640625 seconds
DEBUG 01-13 08:46:18.388393.388393 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.00461578369140625 seconds
DEBUG 01-13 08:46:18.388778.388778 cuda_h.py:10] start restore2model
DEBUG 01-13 08:46:18.391013.391013 cuda_h.py:19] end restore2model cost 0.003019571304321289 seconds
DEBUG 01-13 08:46:18.391703.391703 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.007811784744262695 seconds
DEBUG 01-13 08:46:18.391261.391261 cuda_h.py:10] start gpu_sexperts
DEBUG 01-13 08:46:18.392106.392106 cuda_h.py:19] end gpu_sexperts cost 0.00030994415283203125 seconds
DEBUG 01-13 08:46:18.392843.392843 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-13 08:46:18.392620.392620 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 1.5497207641601562e-05 seconds
DEBUG 01-13 08:46:18.392269.392269 cuda_h.py:10] start wait_experts
INFO 01-13 08:46:18.392873.392873 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, cf895dbb-fa4b-48bc-a639-7ca4f97dc276
DEBUG 01-13 08:46:18.397883.397883 mlpmodule.py:1006] group tensors cost 0.0099334716796875 s
DEBUG 01-13 08:46:18.399643.399643 mlpmodule.py:1044] pad cost 0.0015006065368652344 s
DEBUG 01-13 08:46:18.399408.399408 mlpmodule.py:1050] create cpu tensor cost 5.507469177246094e-05 s
DEBUG 01-13 08:46:18.399642.399642 mlpmodule.py:1055] move to cpu cost 3.0040740966796875e-05 s
DEBUG 01-13 08:46:18.409165.409165 mlpmodule.py:1069] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-13 08:46:18.409058.409058 mlpmodule.py:1070] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-13 08:46:18.410254.410254 mlpmodule.py:1075] group_w3 first element: 0.00653076171875
WARNING 01-13 08:46:18.410597.410597 mlpmodule.py:1085] start einsum2
DEBUG 01-13 08:46:18.427359.427359 mlpmodule.py:1095] group einsum cost 0.027665138244628906 s
DEBUG 01-13 08:46:18.428552.428552 mlpmodule.py:1103] cpy2cputensor cost 0.0006003379821777344 s
DEBUG 01-13 08:46:18.440187.440187 mlpmodule.py:785]  experts func einsum cost 0.0528721809387207 s
DEBUG 01-13 08:46:18.440822.440822 cuda_h.py:19] end experts_func_gpu_einsum_mp cost 0.05366373062133789 seconds
INFO 01-13 08:46:18.443281.443281 client.py:127] Model loaded
DEBUG 01-13 08:46:18.444706.444706 cuda_h.py:19] end wait_experts cost 0.05194902420043945 seconds
DEBUG 01-13 08:46:18.444053.444053 cuda_h.py:10] start gpu_experts
DEBUG 01-13 08:46:18.444520.444520 mlpmodule.py:559] gpu group tensors cost 0.0006043910980224609 s
DEBUG 01-13 08:46:18.446002.446002 mlpmodule.py:592] gpu pad cost 0.001867055892944336 s
DEBUG 01-13 08:46:18.446859.446859 mlpmodule.py:598] start_w1
DEBUG 01-13 08:46:18.447222.447222 mlpmodule.py:602] start_w3
DEBUG 01-13 08:46:18.447659.447659 mlpmodule.py:608] start_w2
DEBUG 01-13 08:46:18.447730.447730 mlpmodule.py:611] gpu group einsum cost 0.0007121562957763672 s
DEBUG 01-13 08:46:18.450888.450888 mlpmodule.py:683] gpu experts func einsum cost 0.006249666213989258 s
DEBUG 01-13 08:46:18.450911.450911 cuda_h.py:19] end gpu_experts cost 0.006398677825927734 seconds
DEBUG 01-13 08:46:18.450852.450852 cuda_h.py:10] start cpu_thread_manager_mp_wait
DEBUG 01-13 08:46:18.450563.450563 cuda_h.py:19] end cpu_thread_manager_mp_wait cost 3.7670135498046875e-05 seconds
DEBUG 01-13 08:46:18.450870.450870 cuda_h.py:19] end layer_moe_generate_mp_l_25 cost 0.06986331939697266 seconds
DEBUG 01-13 08:46:18.451037.451037 lmp.py:1550] -------------------------------- end prefill layer 24 --------------------------------
DEBUG 01-13 08:46:18.451661.451661 lmp.py:1493] -------------------------------- start prefill layer 25 --------------------------------
DEBUG 01-13 08:46:18.451933.451933 cuda_h.py:10] start start_load_qkvogn_s_weight_l_26
DEBUG 01-13 08:46:18.451974.451974 cuda_h.py:10] start start_load_qkvogn_s_weight_l_26
DEBUG 01-13 08:46:18.451287.451287 cuda_h.py:19] end start_load_qkvogn_s_weight_l_26 cost 3.0279159545898438e-05 seconds
DEBUG 01-13 08:46:18.451487.451487 cuda_h.py:19] end start_load_qkvogn_s_weight_l_26 cost 7.486343383789062e-05 seconds
DEBUG 01-13 08:46:18.451799.451799 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-13 08:46:18.451086.451086 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-13 08:46:18.451049.451049 cuda_h.py:10] start sllm_worker_task
DEBUG 01-13 08:46:18.451827.451827 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-13 08:46:18.451232.451232 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-13 08:46:18.451675.451675 cuda_h.py:19] end allocate_cuda_memory cost 0.00032591819763183594 seconds
DEBUG 01-13 08:46:18.452983.452983 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-13 08:46:18.452553.452553 sllm_store_c.py:27] get device uuid map
DEBUG 01-13 08:46:18.452469.452469 sllm_store_c.py:29] call client load into gpu
DEBUG 01-13 08:46:18.452502.452502 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 033c19a9-a06b-4a83-9fe8-99e07aacb516
DEBUG 01-13 08:46:18.452995.452995 client.py:106] call stub.LoadModelAsync
DEBUG 01-13 08:46:18.452324.452324 cuda_h.py:10] start self_attn
INFO 01-13 08:46:18.453825.453825 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 033c19a9-a06b-4a83-9fe8-99e07aacb516
DEBUG 01-13 08:46:18.453642.453642 cuda_h.py:19] end load_into_gpu_async cost 0.0018525123596191406 seconds
DEBUG 01-13 08:46:18.453881.453881 cuda_h.py:10] start restore_tensors2
DEBUG 01-13 08:46:18.454653.454653 cuda_h.py:19] end restore_tensors2 cost 7.891654968261719e-05 seconds
DEBUG 01-13 08:46:18.454085.454085 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.002542734146118164 seconds
INFO 01-13 08:46:18.454359.454359 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 033c19a9-a06b-4a83-9fe8-99e07aacb516
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-13 08:46:18.456540.456540 cuda_h.py:19] end self_attn cost 0.0034296512603759766 seconds
DEBUG 01-13 08:46:18.456062.456062 cuda_h.py:19] end iln_self_attn_paln cost 0.005040884017944336 seconds
DEBUG 01-13 08:46:18.456687.456687 cuda_h.py:10] start layer_moe_generate_mp_l_26
DEBUG 01-13 08:46:18.456357.456357 cuda_h.py:10] start gate
DEBUG 01-13 08:46:18.457766.457766 cuda_h.py:19] end gate cost 0.0007216930389404297 seconds
DEBUG 01-13 08:46:18.457834.457834 cuda_h.py:10] start experts_map_get
DEBUG 01-13 08:46:18.457783.457783 lmp.py:1611] 
DEBUG 01-13 08:46:18.457783.457783 lmp.py:1611] Expert Token Distribution & Device Allocation:
DEBUG 01-13 08:46:18.457731.457731 lmp.py:1612]   Total experts: 64
DEBUG 01-13 08:46:18.457050.457050 lmp.py:1613]   CPU experts: 32 (50%)
DEBUG 01-13 08:46:18.457269.457269 lmp.py:1614]   GPU experts: 32 (50%)
DEBUG 01-13 08:46:18.457343.457343 lmp.py:1615] 
DEBUG 01-13 08:46:18.457343.457343 lmp.py:1615]   Expert ID | Tokens | Device
DEBUG 01-13 08:46:18.457131.457131 lmp.py:1616]   -----------------------------------
DEBUG 01-13 08:46:18.457165.457165 lmp.py:1622]   Expert 13 |     31 | CPU
DEBUG 01-13 08:46:18.457477.457477 lmp.py:1622]   Expert 44 |     40 | CPU
DEBUG 01-13 08:46:18.457074.457074 lmp.py:1622]   Expert 25 |     43 | CPU
DEBUG 01-13 08:46:18.457671.457671 lmp.py:1622]   Expert  9 |     44 | CPU
DEBUG 01-13 08:46:18.457790.457790 lmp.py:1622]   Expert 38 |     45 | CPU
DEBUG 01-13 08:46:18.457149.457149 lmp.py:1622]   Expert  2 |     49 | CPU
DEBUG 01-13 08:46:18.457268.457268 lmp.py:1622]   Expert 16 |     51 | CPU
DEBUG 01-13 08:46:18.458150.458150 lmp.py:1622]   Expert 22 |     53 | CPU
DEBUG 01-13 08:46:18.458270.458270 lmp.py:1622]   Expert 33 |     56 | CPU
DEBUG 01-13 08:46:18.458582.458582 lmp.py:1622]   Expert 42 |     57 | CPU
DEBUG 01-13 08:46:18.458655.458655 lmp.py:1622]   Expert  5 |     65 | CPU
DEBUG 01-13 08:46:18.458967.458967 lmp.py:1622]   Expert 24 |     77 | CPU
DEBUG 01-13 08:46:18.458325.458325 lmp.py:1622]   Expert 23 |     79 | CPU
DEBUG 01-13 08:46:18.458207.458207 lmp.py:1622]   Expert 10 |     83 | CPU
DEBUG 01-13 08:46:18.458088.458088 lmp.py:1622]   Expert 59 |     91 | CPU
DEBUG 01-13 08:46:18.458208.458208 lmp.py:1622]   Expert 46 |    102 | CPU
DEBUG 01-13 08:46:18.458328.458328 lmp.py:1622]   Expert 55 |    102 | CPU
DEBUG 01-13 08:46:18.458209.458209 lmp.py:1622]   Expert 21 |    105 | CPU
DEBUG 01-13 08:46:18.458090.458090 lmp.py:1622]   Expert 61 |    118 | CPU
DEBUG 01-13 08:46:18.458733.458733 lmp.py:1622]   Expert 45 |    123 | CPU
DEBUG 01-13 08:46:18.458330.458330 lmp.py:1622]   Expert 31 |    126 | CPU
DEBUG 01-13 08:46:18.458165.458165 lmp.py:1622]   Expert 51 |    138 | CPU
DEBUG 01-13 08:46:18.458762.458762 lmp.py:1622]   Expert  6 |    143 | CPU
DEBUG 01-13 08:46:18.458074.458074 lmp.py:1622]   Expert 36 |    144 | CPU
DEBUG 01-13 08:46:18.458147.458147 lmp.py:1622]   Expert  0 |    152 | CPU
DEBUG 01-13 08:46:18.458744.458744 lmp.py:1622]   Expert 26 |    153 | CPU
DEBUG 01-13 08:46:18.458625.458625 lmp.py:1622]   Expert  8 |    155 | CPU
DEBUG 01-13 08:46:18.458745.458745 lmp.py:1622]   Expert 43 |    157 | CPU
DEBUG 01-13 08:46:18.458626.458626 lmp.py:1622]   Expert 18 |    158 | CPU
DEBUG 01-13 08:46:18.458985.458985 lmp.py:1622]   Expert  3 |    160 | CPU
DEBUG 01-13 08:46:18.458104.458104 lmp.py:1622]   Expert 41 |    168 | CPU
DEBUG 01-13 08:46:18.458986.458986 lmp.py:1622]   Expert 20 |    169 | CPU
DEBUG 01-13 08:46:18.458629.458629 lmp.py:1622]   Expert 48 |    170 | GPU
DEBUG 01-13 08:46:18.458272.458272 lmp.py:1622]   Expert 12 |    176 | GPU
DEBUG 01-13 08:46:18.458868.458868 lmp.py:1622]   Expert  7 |    182 | GPU
DEBUG 01-13 08:46:18.458942.458942 lmp.py:1622]   Expert 27 |    188 | GPU
DEBUG 01-13 08:46:18.458300.458300 lmp.py:1622]   Expert 56 |    188 | GPU
DEBUG 01-13 08:46:18.458135.458135 lmp.py:1622]   Expert 28 |    191 | GPU
DEBUG 01-13 08:46:18.458017.458017 lmp.py:1622]   Expert 34 |    197 | GPU
DEBUG 01-13 08:46:18.458898.458898 lmp.py:1622]   Expert 47 |    198 | GPU
DEBUG 01-13 08:46:18.458018.458018 lmp.py:1622]   Expert  1 |    205 | GPU
DEBUG 01-13 08:46:18.458899.458899 lmp.py:1622]   Expert 32 |    212 | GPU
DEBUG 01-13 08:46:18.458019.458019 lmp.py:1622]   Expert 11 |    219 | GPU
DEBUG 01-13 08:46:18.458139.458139 lmp.py:1622]   Expert 53 |    234 | GPU
DEBUG 01-13 08:46:18.458782.458782 lmp.py:1622]   Expert 49 |    235 | GPU
DEBUG 01-13 08:46:18.458902.458902 lmp.py:1622]   Expert 63 |    236 | GPU
DEBUG 01-13 08:46:18.458783.458783 lmp.py:1622]   Expert 40 |    237 | GPU
DEBUG 01-13 08:46:18.458664.458664 lmp.py:1622]   Expert  4 |    241 | GPU
DEBUG 01-13 08:46:18.458499.458499 lmp.py:1622]   Expert 29 |    245 | GPU
DEBUG 01-13 08:46:18.458096.458096 lmp.py:1622]   Expert 50 |    246 | GPU
DEBUG 01-13 08:46:18.458408.458408 lmp.py:1622]   Expert 15 |    247 | GPU
DEBUG 01-13 08:46:18.458766.458766 lmp.py:1622]   Expert 30 |    251 | GPU
DEBUG 01-13 08:46:18.458648.458648 lmp.py:1622]   Expert 35 |    267 | GPU
DEBUG 01-13 08:46:18.458767.458767 lmp.py:1622]   Expert 14 |    270 | GPU
DEBUG 01-13 08:46:18.458410.458410 lmp.py:1622]   Expert 37 |    308 | GPU
DEBUG 01-13 08:46:18.458530.458530 lmp.py:1622]   Expert 52 |    332 | GPU
DEBUG 01-13 08:46:18.458412.458412 lmp.py:1622]   Expert 17 |    359 | GPU
DEBUG 01-13 08:46:18.458055.458055 lmp.py:1622]   Expert 54 |    377 | GPU
DEBUG 01-13 08:46:18.458698.458698 lmp.py:1622]   Expert 39 |    396 | GPU
DEBUG 01-13 08:46:18.458341.458341 lmp.py:1622]   Expert 57 |    415 | GPU
DEBUG 01-13 08:46:18.458984.458984 lmp.py:1622]   Expert 60 |    455 | GPU
DEBUG 01-13 08:46:18.458295.458295 lmp.py:1622]   Expert 62 |    463 | GPU
DEBUG 01-13 08:46:18.459369.459369 lmp.py:1622]   Expert 19 |    544 | GPU
DEBUG 01-13 08:46:18.459204.459204 lmp.py:1622]   Expert 58 |    567 | GPU
DEBUG 01-13 08:46:18.459993.459993 lmp.py:1623] 
DEBUG 01-13 08:46:18.459993.459993 lmp.py:1623]   CPU total tokens: 3237 (26.3%)
DEBUG 01-13 08:46:18.459543.459543 lmp.py:1624]   GPU total tokens: 9051 (73.7%)
DEBUG 01-13 08:46:18.459146.459146 cuda_h.py:19] end experts_map_get cost 0.0017809867858886719 seconds
DEBUG 01-13 08:46:18.459288.459288 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-13 08:46:18.459090.459090 lmp.py:1632] 
DEBUG 01-13 08:46:18.459090.459090 lmp.py:1632]   Computing 32 experts on CPU MP...
DEBUG 01-13 08:46:18.459204.459204 cuda_h.py:19] end cpu_experts_submit cost 4.9114227294921875e-05 seconds
DEBUG 01-13 08:46:18.459662.459662 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-13 08:46:18.459730.459730 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-13 08:46:18.459291.459291 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-13 08:46:18.460926.460926 cuda_h.py:19] end allocate_cuda_memory cost 0.0011334419250488281 seconds
DEBUG 01-13 08:46:18.460445.460445 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-13 08:46:18.460823.460823 sllm_store_c.py:27] get device uuid map
DEBUG 01-13 08:46:18.461959.461959 sllm_store_c.py:29] call client load into gpu
DEBUG 01-13 08:46:18.461146.461146 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 02f3aa48-6670-4a67-879d-c254ebadf69a
DEBUG 01-13 08:46:18.461708.461708 client.py:106] call stub.LoadModelAsync
DEBUG 01-13 08:46:18.461135.461135 cuda_h.py:10] start experts_func_gpu_einsum_mp
INFO 01-13 08:46:18.461810.461810 client.py:127] Model loaded
DEBUG 01-13 08:46:18.461741.461741 cuda_h.py:10] start restore2model
DEBUG 01-13 08:46:18.462645.462645 cuda_h.py:19] end restore2model cost 0.00044989585876464844 seconds
DEBUG 01-13 08:46:18.462620.462620 cuda_h.py:19] end sllm_worker_task cost 0.010843753814697266 seconds
INFO 01-13 08:46:18.463767.463767 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 02f3aa48-6670-4a67-879d-c254ebadf69a
DEBUG 01-13 08:46:18.463617.463617 cuda_h.py:19] end load_into_gpu_async cost 0.0027234554290771484 seconds
DEBUG 01-13 08:46:18.463995.463995 cuda_h.py:10] start restore_tensors2
DEBUG 01-13 08:46:18.463431.463431 cuda_h.py:19] end restore_tensors2 cost 0.00032806396484375 seconds
DEBUG 01-13 08:46:18.463015.463015 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.004540205001831055 seconds
DEBUG 01-13 08:46:18.463586.463586 cuda_h.py:10] start restore2model
DEBUG 01-13 08:46:18.466310.466310 cuda_h.py:19] end restore2model cost 0.0029952526092529297 seconds
DEBUG 01-13 08:46:18.466292.466292 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.007709980010986328 seconds
DEBUG 01-13 08:46:18.467585.467585 cuda_h.py:10] start gpu_sexperts
DEBUG 01-13 08:46:18.467371.467371 cuda_h.py:19] end gpu_sexperts cost 0.00030159950256347656 seconds
DEBUG 01-13 08:46:18.467677.467677 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-13 08:46:18.467784.467784 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 1.4781951904296875e-05 seconds
DEBUG 01-13 08:46:18.467673.467673 cuda_h.py:10] start wait_experts
INFO 01-13 08:46:18.467991.467991 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 02f3aa48-6670-4a67-879d-c254ebadf69a
DEBUG 01-13 08:46:18.474328.474328 mlpmodule.py:1006] group tensors cost 0.012183427810668945 s
DEBUG 01-13 08:46:18.476176.476176 mlpmodule.py:1044] pad cost 0.0015227794647216797 s
DEBUG 01-13 08:46:18.476874.476874 mlpmodule.py:1050] create cpu tensor cost 4.029273986816406e-05 s
DEBUG 01-13 08:46:18.476009.476009 mlpmodule.py:1055] move to cpu cost 3.0040740966796875e-05 s
DEBUG 01-13 08:46:18.487291.487291 mlpmodule.py:1069] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-13 08:46:18.488336.488336 mlpmodule.py:1070] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-13 08:46:18.488287.488287 mlpmodule.py:1075] group_w3 first element: 0.007110595703125
WARNING 01-13 08:46:18.488218.488218 mlpmodule.py:1085] start einsum2
DEBUG 01-13 08:46:18.505323.505323 mlpmodule.py:1095] group einsum cost 0.028879642486572266 s
DEBUG 01-13 08:46:18.506729.506729 mlpmodule.py:1103] cpy2cputensor cost 0.0006701946258544922 s
DEBUG 01-13 08:46:18.518423.518423 mlpmodule.py:785]  experts func einsum cost 0.05616116523742676 s
DEBUG 01-13 08:46:18.518821.518821 cuda_h.py:19] end experts_func_gpu_einsum_mp cost 0.05699634552001953 seconds
INFO 01-13 08:46:18.519339.519339 client.py:127] Model loaded
DEBUG 01-13 08:46:18.519482.519482 cuda_h.py:19] end wait_experts cost 0.052028656005859375 seconds
DEBUG 01-13 08:46:18.519345.519345 cuda_h.py:10] start gpu_experts
DEBUG 01-13 08:46:18.520147.520147 mlpmodule.py:559] gpu group tensors cost 0.0007302761077880859 s
DEBUG 01-13 08:46:18.522850.522850 mlpmodule.py:592] gpu pad cost 0.0021338462829589844 s
DEBUG 01-13 08:46:18.522244.522244 mlpmodule.py:598] start_w1
DEBUG 01-13 08:46:18.523660.523660 mlpmodule.py:602] start_w3
DEBUG 01-13 08:46:18.523534.523534 mlpmodule.py:608] start_w2
DEBUG 01-13 08:46:18.523295.523295 mlpmodule.py:611] gpu group einsum cost 0.0007388591766357422 s
DEBUG 01-13 08:46:18.526592.526592 mlpmodule.py:683] gpu experts func einsum cost 0.006678104400634766 s
DEBUG 01-13 08:46:18.526853.526853 cuda_h.py:19] end gpu_experts cost 0.006838798522949219 seconds
DEBUG 01-13 08:46:18.526463.526463 cuda_h.py:10] start cpu_thread_manager_mp_wait
DEBUG 01-13 08:46:18.526220.526220 cuda_h.py:19] end cpu_thread_manager_mp_wait cost 3.62396240234375e-05 seconds
DEBUG 01-13 08:46:18.526812.526812 cuda_h.py:19] end layer_moe_generate_mp_l_26 cost 0.07017898559570312 seconds
DEBUG 01-13 08:46:18.526317.526317 lmp.py:1550] -------------------------------- end prefill layer 25 --------------------------------
DEBUG 01-13 08:46:18.526418.526418 lmp.py:1493] -------------------------------- start prefill layer 26 --------------------------------
DEBUG 01-13 08:46:18.526690.526690 cuda_h.py:10] start start_load_qkvogn_s_weight_l_27
DEBUG 01-13 08:46:18.526300.526300 cuda_h.py:10] start start_load_qkvogn_s_weight_l_27
DEBUG 01-13 08:46:18.527805.527805 cuda_h.py:19] end start_load_qkvogn_s_weight_l_27 cost 3.218650817871094e-05 seconds
DEBUG 01-13 08:46:18.527244.527244 cuda_h.py:19] end start_load_qkvogn_s_weight_l_27 cost 7.748603820800781e-05 seconds
DEBUG 01-13 08:46:18.527794.527794 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-13 08:46:18.527704.527704 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-13 08:46:18.527759.527759 cuda_h.py:10] start sllm_worker_task
DEBUG 01-13 08:46:18.527888.527888 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-13 08:46:18.527864.527864 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-13 08:46:18.527406.527406 cuda_h.py:19] end allocate_cuda_memory cost 0.00032973289489746094 seconds
DEBUG 01-13 08:46:18.527540.527540 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-13 08:46:18.527535.527535 sllm_store_c.py:27] get device uuid map
DEBUG 01-13 08:46:18.527450.527450 sllm_store_c.py:29] call client load into gpu
DEBUG 01-13 08:46:18.527484.527484 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 54d0b5dd-9ce5-4443-bd4c-1f8e932ccf09
DEBUG 01-13 08:46:18.528361.528361 client.py:106] call stub.LoadModelAsync
DEBUG 01-13 08:46:18.528034.528034 cuda_h.py:10] start self_attn
INFO 01-13 08:46:18.529428.529428 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 54d0b5dd-9ce5-4443-bd4c-1f8e932ccf09
DEBUG 01-13 08:46:18.529171.529171 cuda_h.py:19] end load_into_gpu_async cost 0.0018029212951660156 seconds
DEBUG 01-13 08:46:18.529536.529536 cuda_h.py:10] start restore_tensors2
DEBUG 01-13 08:46:18.529381.529381 cuda_h.py:19] end restore_tensors2 cost 6.890296936035156e-05 seconds
DEBUG 01-13 08:46:18.529229.529229 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.002429962158203125 seconds
INFO 01-13 08:46:18.529635.529635 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 54d0b5dd-9ce5-4443-bd4c-1f8e932ccf09
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-13 08:46:18.531226.531226 cuda_h.py:19] end self_attn cost 0.003307342529296875 seconds
DEBUG 01-13 08:46:18.532602.532602 cuda_h.py:19] end iln_self_attn_paln cost 0.0049190521240234375 seconds
DEBUG 01-13 08:46:18.532015.532015 cuda_h.py:10] start layer_moe_generate_mp_l_27
DEBUG 01-13 08:46:18.532182.532182 cuda_h.py:10] start gate
DEBUG 01-13 08:46:18.532989.532989 cuda_h.py:19] end gate cost 0.0007317066192626953 seconds
DEBUG 01-13 08:46:18.532819.532819 cuda_h.py:10] start experts_map_get
DEBUG 01-13 08:46:18.533106.533106 lmp.py:1611] 
DEBUG 01-13 08:46:18.533106.533106 lmp.py:1611] Expert Token Distribution & Device Allocation:
DEBUG 01-13 08:46:18.533306.533306 lmp.py:1612]   Total experts: 64
DEBUG 01-13 08:46:18.533817.533817 lmp.py:1613]   CPU experts: 32 (50%)
DEBUG 01-13 08:46:18.533082.533082 lmp.py:1614]   GPU experts: 32 (50%)
DEBUG 01-13 08:46:18.533156.533156 lmp.py:1615] 
DEBUG 01-13 08:46:18.533156.533156 lmp.py:1615]   Expert ID | Tokens | Device
DEBUG 01-13 08:46:18.533991.533991 lmp.py:1616]   -----------------------------------
DEBUG 01-13 08:46:18.533833.533833 lmp.py:1622]   Expert 20 |      8 | CPU
DEBUG 01-13 08:46:18.533668.533668 lmp.py:1622]   Expert 61 |     11 | CPU
DEBUG 01-13 08:46:18.533549.533549 lmp.py:1622]   Expert  3 |     32 | CPU
DEBUG 01-13 08:46:18.533192.533192 lmp.py:1622]   Expert 11 |     34 | CPU
DEBUG 01-13 08:46:18.533835.533835 lmp.py:1622]   Expert  7 |     37 | CPU
DEBUG 01-13 08:46:18.533001.533001 lmp.py:1622]   Expert 51 |     39 | CPU
DEBUG 01-13 08:46:18.533883.533883 lmp.py:1622]   Expert 62 |     47 | CPU
DEBUG 01-13 08:46:18.533287.533287 lmp.py:1622]   Expert 30 |     48 | CPU
DEBUG 01-13 08:46:18.533453.533453 lmp.py:1622]   Expert  6 |     59 | CPU
DEBUG 01-13 08:46:18.533573.533573 lmp.py:1622]   Expert 17 |     61 | CPU
DEBUG 01-13 08:46:18.533454.533454 lmp.py:1622]   Expert 29 |     65 | CPU
DEBUG 01-13 08:46:18.533051.533051 lmp.py:1622]   Expert  9 |     68 | CPU
DEBUG 01-13 08:46:18.533694.533694 lmp.py:1622]   Expert 38 |     76 | CPU
DEBUG 01-13 08:46:18.533860.533860 lmp.py:1622]   Expert 19 |     77 | CPU
DEBUG 01-13 08:46:18.533026.533026 lmp.py:1622]   Expert 63 |     78 | CPU
DEBUG 01-13 08:46:18.533954.533954 lmp.py:1622]   Expert 59 |     79 | CPU
DEBUG 01-13 08:46:18.533120.533120 lmp.py:1622]   Expert 55 |     84 | CPU
DEBUG 01-13 08:46:18.533810.533810 lmp.py:1622]   Expert 48 |    100 | CPU
DEBUG 01-13 08:46:18.533976.533976 lmp.py:1622]   Expert  8 |    102 | CPU
DEBUG 01-13 08:46:18.533903.533903 lmp.py:1622]   Expert 22 |    104 | CPU
DEBUG 01-13 08:46:18.533831.533831 lmp.py:1622]   Expert 24 |    107 | CPU
DEBUG 01-13 08:46:18.533997.533997 lmp.py:1622]   Expert 49 |    111 | CPU
DEBUG 01-13 08:46:18.533925.533925 lmp.py:1622]   Expert 34 |    113 | CPU
DEBUG 01-13 08:46:18.533853.533853 lmp.py:1622]   Expert 36 |    117 | CPU
DEBUG 01-13 08:46:18.534780.534780 lmp.py:1622]   Expert 50 |    117 | CPU
DEBUG 01-13 08:46:18.534470.534470 lmp.py:1622]   Expert 42 |    119 | CPU
DEBUG 01-13 08:46:18.534351.534351 lmp.py:1622]   Expert 39 |    121 | CPU
DEBUG 01-13 08:46:18.534994.534994 lmp.py:1622]   Expert  4 |    125 | CPU
DEBUG 01-13 08:46:18.534922.534922 lmp.py:1622]   Expert 15 |    136 | CPU
DEBUG 01-13 08:46:18.534373.534373 lmp.py:1622]   Expert 37 |    138 | CPU
DEBUG 01-13 08:46:18.534300.534300 lmp.py:1622]   Expert 41 |    147 | CPU
DEBUG 01-13 08:46:18.534990.534990 lmp.py:1622]   Expert 23 |    150 | CPU
DEBUG 01-13 08:46:18.534917.534917 lmp.py:1622]   Expert 16 |    162 | GPU
DEBUG 01-13 08:46:18.534845.534845 lmp.py:1622]   Expert 56 |    165 | GPU
DEBUG 01-13 08:46:18.534773.534773 lmp.py:1622]   Expert  1 |    168 | GPU
DEBUG 01-13 08:46:18.534462.534462 lmp.py:1622]   Expert 43 |    173 | GPU
DEBUG 01-13 08:46:18.534582.534582 lmp.py:1622]   Expert 60 |    176 | GPU
DEBUG 01-13 08:46:18.534271.534271 lmp.py:1622]   Expert 44 |    177 | GPU
DEBUG 01-13 08:46:18.534199.534199 lmp.py:1622]   Expert 21 |    180 | GPU
DEBUG 01-13 08:46:18.534888.534888 lmp.py:1622]   Expert 53 |    186 | GPU
DEBUG 01-13 08:46:18.534054.534054 lmp.py:1622]   Expert 47 |    196 | GPU
DEBUG 01-13 08:46:18.534744.534744 lmp.py:1622]   Expert 12 |    202 | GPU
DEBUG 01-13 08:46:18.534671.534671 lmp.py:1622]   Expert 33 |    206 | GPU
DEBUG 01-13 08:46:18.534599.534599 lmp.py:1622]   Expert 13 |    211 | GPU
DEBUG 01-13 08:46:18.534765.534765 lmp.py:1622]   Expert 32 |    223 | GPU
DEBUG 01-13 08:46:18.534170.534170 lmp.py:1622]   Expert 28 |    226 | GPU
DEBUG 01-13 08:46:18.534528.534528 lmp.py:1622]   Expert  0 |    248 | GPU
DEBUG 01-13 08:46:18.534933.534933 lmp.py:1622]   Expert 54 |    258 | GPU
DEBUG 01-13 08:46:18.534860.534860 lmp.py:1622]   Expert 26 |    261 | GPU
DEBUG 01-13 08:46:18.534788.534788 lmp.py:1622]   Expert 31 |    261 | GPU
DEBUG 01-13 08:46:18.534954.534954 lmp.py:1622]   Expert 10 |    265 | GPU
DEBUG 01-13 08:46:18.534405.534405 lmp.py:1622]   Expert 18 |    271 | GPU
DEBUG 01-13 08:46:18.534571.534571 lmp.py:1622]   Expert 57 |    276 | GPU
DEBUG 01-13 08:46:18.534261.534261 lmp.py:1622]   Expert  2 |    290 | GPU
DEBUG 01-13 08:46:18.534188.534188 lmp.py:1622]   Expert 58 |    300 | GPU
DEBUG 01-13 08:46:18.534546.534546 lmp.py:1622]   Expert 40 |    343 | GPU
DEBUG 01-13 08:46:18.534428.534428 lmp.py:1622]   Expert 45 |    365 | GPU
DEBUG 01-13 08:46:18.534356.534356 lmp.py:1622]   Expert 25 |    368 | GPU
DEBUG 01-13 08:46:18.534045.534045 lmp.py:1622]   Expert  5 |    438 | GPU
DEBUG 01-13 08:46:18.534211.534211 lmp.py:1622]   Expert 35 |    464 | GPU
DEBUG 01-13 08:46:18.534377.534377 lmp.py:1622]   Expert 27 |    485 | GPU
DEBUG 01-13 08:46:18.534066.534066 lmp.py:1622]   Expert 46 |    543 | GPU
DEBUG 01-13 08:46:18.534233.534233 lmp.py:1622]   Expert 52 |    609 | GPU
DEBUG 01-13 08:46:18.534160.534160 lmp.py:1622]   Expert 14 |    882 | GPU
DEBUG 01-13 08:46:18.534280.534280 lmp.py:1623] 
DEBUG 01-13 08:46:18.534280.534280 lmp.py:1623]   CPU total tokens: 2710 (22.1%)
DEBUG 01-13 08:46:18.534877.534877 lmp.py:1624]   GPU total tokens: 9578 (77.9%)
DEBUG 01-13 08:46:18.534195.534195 cuda_h.py:19] end experts_map_get cost 0.0017223358154296875 seconds
DEBUG 01-13 08:46:18.534860.534860 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-13 08:46:18.534854.534854 lmp.py:1632] 
DEBUG 01-13 08:46:18.534854.534854 lmp.py:1632]   Computing 32 experts on CPU MP...
DEBUG 01-13 08:46:18.534684.534684 cuda_h.py:19] end cpu_experts_submit cost 5.0067901611328125e-05 seconds
DEBUG 01-13 08:46:18.534618.534618 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-13 08:46:18.534733.534733 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-13 08:46:18.535340.535340 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-13 08:46:18.536837.536837 cuda_h.py:19] end allocate_cuda_memory cost 0.0017695426940917969 seconds
DEBUG 01-13 08:46:18.536164.536164 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-13 08:46:18.536543.536543 sllm_store_c.py:27] get device uuid map
DEBUG 01-13 08:46:18.537782.537782 sllm_store_c.py:29] call client load into gpu
DEBUG 01-13 08:46:18.537339.537339 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, e00b683a-c552-4f6f-a0a1-f5fc48385ec0
DEBUG 01-13 08:46:18.537371.537371 client.py:106] call stub.LoadModelAsync
INFO 01-13 08:46:18.537402.537402 client.py:127] Model loaded
DEBUG 01-13 08:46:18.537411.537411 cuda_h.py:10] start restore2model
DEBUG 01-13 08:46:18.538690.538690 cuda_h.py:10] start experts_func_gpu_einsum_mp
DEBUG 01-13 08:46:18.538009.538009 cuda_h.py:19] end restore2model cost 0.0003998279571533203 seconds
DEBUG 01-13 08:46:18.538692.538692 cuda_h.py:19] end sllm_worker_task cost 0.010958671569824219 seconds
INFO 01-13 08:46:18.539271.539271 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, e00b683a-c552-4f6f-a0a1-f5fc48385ec0
DEBUG 01-13 08:46:18.539744.539744 cuda_h.py:19] end load_into_gpu_async cost 0.0022513866424560547 seconds
DEBUG 01-13 08:46:18.539116.539116 cuda_h.py:10] start restore_tensors2
DEBUG 01-13 08:46:18.539903.539903 cuda_h.py:19] end restore_tensors2 cost 0.0003409385681152344 seconds
DEBUG 01-13 08:46:18.539679.539679 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0047113895416259766 seconds
DEBUG 01-13 08:46:18.539349.539349 cuda_h.py:10] start restore2model
DEBUG 01-13 08:46:18.542428.542428 cuda_h.py:19] end restore2model cost 0.003115415573120117 seconds
DEBUG 01-13 08:46:18.542371.542371 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.008010625839233398 seconds
DEBUG 01-13 08:46:18.542928.542928 cuda_h.py:10] start gpu_sexperts
DEBUG 01-13 08:46:18.543714.543714 cuda_h.py:19] end gpu_sexperts cost 0.0003018379211425781 seconds
DEBUG 01-13 08:46:18.543020.543020 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-13 08:46:18.543843.543843 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 1.4781951904296875e-05 seconds
DEBUG 01-13 08:46:18.543208.543208 cuda_h.py:10] start wait_experts
INFO 01-13 08:46:18.543765.543765 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, e00b683a-c552-4f6f-a0a1-f5fc48385ec0
DEBUG 01-13 08:46:18.548875.548875 mlpmodule.py:1006] group tensors cost 0.009761333465576172 s
DEBUG 01-13 08:46:18.550751.550751 mlpmodule.py:1044] pad cost 0.0014829635620117188 s
DEBUG 01-13 08:46:18.550847.550847 mlpmodule.py:1050] create cpu tensor cost 5.459785461425781e-05 s
DEBUG 01-13 08:46:18.550074.550074 mlpmodule.py:1055] move to cpu cost 2.9802322387695312e-05 s
DEBUG 01-13 08:46:18.559937.559937 mlpmodule.py:1069] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-13 08:46:18.559929.559929 mlpmodule.py:1070] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-13 08:46:18.559495.559495 mlpmodule.py:1075] group_w3 first element: -0.0024261474609375
WARNING 01-13 08:46:18.559235.559235 mlpmodule.py:1085] start einsum2
DEBUG 01-13 08:46:18.576169.576169 mlpmodule.py:1095] group einsum cost 0.026083946228027344 s
DEBUG 01-13 08:46:18.577698.577698 mlpmodule.py:1103] cpy2cputensor cost 0.0005762577056884766 s
DEBUG 01-13 08:46:18.589480.589480 mlpmodule.py:785]  experts func einsum cost 0.050776004791259766 s
DEBUG 01-13 08:46:18.589679.589679 cuda_h.py:19] end experts_func_gpu_einsum_mp cost 0.051431894302368164 seconds
INFO 01-13 08:46:18.595445.595445 client.py:127] Model loaded
DEBUG 01-13 08:46:18.595994.595994 cuda_h.py:19] end wait_experts cost 0.052288055419921875 seconds
DEBUG 01-13 08:46:18.595790.595790 cuda_h.py:10] start gpu_experts
DEBUG 01-13 08:46:18.596964.596964 mlpmodule.py:559] gpu group tensors cost 0.0009114742279052734 s
DEBUG 01-13 08:46:18.600665.600665 mlpmodule.py:592] gpu pad cost 0.0032334327697753906 s
DEBUG 01-13 08:46:18.600549.600549 mlpmodule.py:598] start_w1
DEBUG 01-13 08:46:18.600766.600766 mlpmodule.py:602] start_w3
DEBUG 01-13 08:46:18.601384.601384 mlpmodule.py:608] start_w2
DEBUG 01-13 08:46:18.601765.601765 mlpmodule.py:611] gpu group einsum cost 0.0011067390441894531 s
DEBUG 01-13 08:46:18.605591.605591 mlpmodule.py:683] gpu experts func einsum cost 0.009948015213012695 s
DEBUG 01-13 08:46:18.605382.605382 cuda_h.py:19] end gpu_experts cost 0.010119915008544922 seconds
DEBUG 01-13 08:46:18.605277.605277 cuda_h.py:10] start cpu_thread_manager_mp_wait
DEBUG 01-13 08:46:18.606604.606604 cuda_h.py:19] end cpu_thread_manager_mp_wait cost 3.5762786865234375e-05 seconds
DEBUG 01-13 08:46:18.606103.606103 cuda_h.py:19] end layer_moe_generate_mp_l_27 cost 0.07399892807006836 seconds
DEBUG 01-13 08:46:18.606078.606078 lmp.py:1550] -------------------------------- end prefill layer 26 --------------------------------
DEBUG 01-13 08:46:18.606463.606463 lmp.py:1493] -------------------------------- start prefill layer 27 --------------------------------
DEBUG 01-13 08:46:18.606020.606020 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-13 08:46:18.606877.606877 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-13 08:46:18.606020.606020 cuda_h.py:10] start self_attn
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-13 08:46:18.609887.609887 cuda_h.py:19] end self_attn cost 0.002901315689086914 seconds
DEBUG 01-13 08:46:18.610468.610468 cuda_h.py:19] end iln_self_attn_paln cost 0.0036346912384033203 seconds
DEBUG 01-13 08:46:18.610165.610165 cuda_h.py:10] start layer_moe_generate_mp_l_28
DEBUG 01-13 08:46:18.610497.610497 cuda_h.py:10] start gate
DEBUG 01-13 08:46:18.610402.610402 cuda_h.py:19] end gate cost 0.0006663799285888672 seconds
DEBUG 01-13 08:46:18.610708.610708 cuda_h.py:10] start experts_map_get
DEBUG 01-13 08:46:18.611544.611544 lmp.py:1611] 
DEBUG 01-13 08:46:18.611544.611544 lmp.py:1611] Expert Token Distribution & Device Allocation:
DEBUG 01-13 08:46:18.611108.611108 lmp.py:1612]   Total experts: 64
DEBUG 01-13 08:46:18.611473.611473 lmp.py:1613]   CPU experts: 32 (50%)
DEBUG 01-13 08:46:18.611023.611023 lmp.py:1614]   GPU experts: 32 (50%)
DEBUG 01-13 08:46:18.611143.611143 lmp.py:1615] 
DEBUG 01-13 08:46:18.611143.611143 lmp.py:1615]   Expert ID | Tokens | Device
DEBUG 01-13 08:46:18.611501.611501 lmp.py:1616]   -----------------------------------
DEBUG 01-13 08:46:18.611820.611820 lmp.py:1622]   Expert 18 |     62 | CPU
DEBUG 01-13 08:46:18.611463.611463 lmp.py:1622]   Expert 54 |     66 | CPU
DEBUG 01-13 08:46:18.611152.611152 lmp.py:1622]   Expert 47 |     67 | CPU
DEBUG 01-13 08:46:18.611603.611603 lmp.py:1622]   Expert 23 |     75 | CPU
DEBUG 01-13 08:46:18.611292.611292 lmp.py:1622]   Expert 44 |     78 | CPU
DEBUG 01-13 08:46:18.611505.611505 lmp.py:1622]   Expert 45 |     81 | CPU
DEBUG 01-13 08:46:18.611956.611956 lmp.py:1622]   Expert 48 |     81 | CPU
DEBUG 01-13 08:46:18.611407.611407 lmp.py:1622]   Expert 20 |     92 | CPU
DEBUG 01-13 08:46:18.611381.611381 lmp.py:1622]   Expert 31 |    104 | CPU
DEBUG 01-13 08:46:18.611308.611308 lmp.py:1622]   Expert 36 |    106 | CPU
DEBUG 01-13 08:46:18.611759.611759 lmp.py:1622]   Expert 61 |    109 | CPU
DEBUG 01-13 08:46:18.611833.611833 lmp.py:1622]   Expert 42 |    116 | CPU
DEBUG 01-13 08:46:18.611714.611714 lmp.py:1622]   Expert 10 |    119 | CPU
DEBUG 01-13 08:46:18.611165.611165 lmp.py:1622]   Expert 24 |    122 | CPU
DEBUG 01-13 08:46:18.611616.611616 lmp.py:1622]   Expert 33 |    125 | CPU
DEBUG 01-13 08:46:18.611828.611828 lmp.py:1622]   Expert 11 |    126 | CPU
DEBUG 01-13 08:46:18.611802.611802 lmp.py:1622]   Expert 43 |    127 | CPU
DEBUG 01-13 08:46:18.611015.611015 lmp.py:1622]   Expert 56 |    130 | CPU
DEBUG 01-13 08:46:18.611466.611466 lmp.py:1622]   Expert 49 |    132 | CPU
DEBUG 01-13 08:46:18.611678.611678 lmp.py:1622]   Expert  6 |    136 | CPU
DEBUG 01-13 08:46:18.611891.611891 lmp.py:1622]   Expert 51 |    143 | CPU
DEBUG 01-13 08:46:18.611103.611103 lmp.py:1622]   Expert  0 |    151 | CPU
DEBUG 01-13 08:46:18.611316.611316 lmp.py:1622]   Expert 17 |    152 | CPU
DEBUG 01-13 08:46:18.611528.611528 lmp.py:1622]   Expert 55 |    157 | CPU
DEBUG 01-13 08:46:18.611502.611502 lmp.py:1622]   Expert 12 |    158 | CPU
DEBUG 01-13 08:46:18.611476.611476 lmp.py:1622]   Expert  5 |    159 | CPU
DEBUG 01-13 08:46:18.611927.611927 lmp.py:1622]   Expert 40 |    160 | CPU
DEBUG 01-13 08:46:18.611570.611570 lmp.py:1622]   Expert 59 |    162 | CPU
DEBUG 01-13 08:46:18.611974.611974 lmp.py:1622]   Expert 26 |    163 | CPU
DEBUG 01-13 08:46:18.612856.612856 lmp.py:1622]   Expert 13 |    167 | CPU
DEBUG 01-13 08:46:18.612307.612307 lmp.py:1622]   Expert 38 |    169 | CPU
DEBUG 01-13 08:46:18.612519.612519 lmp.py:1622]   Expert 57 |    170 | CPU
DEBUG 01-13 08:46:18.612493.612493 lmp.py:1622]   Expert 35 |    171 | GPU
DEBUG 01-13 08:46:18.612706.612706 lmp.py:1622]   Expert 58 |    174 | GPU
DEBUG 01-13 08:46:18.612680.612680 lmp.py:1622]   Expert 46 |    176 | GPU
DEBUG 01-13 08:46:18.612654.612654 lmp.py:1622]   Expert  7 |    177 | GPU
DEBUG 01-13 08:46:18.612628.612628 lmp.py:1622]   Expert 16 |    179 | GPU
DEBUG 01-13 08:46:18.612363.612363 lmp.py:1622]   Expert 30 |    179 | GPU
DEBUG 01-13 08:46:18.612814.612814 lmp.py:1622]   Expert 50 |    185 | GPU
DEBUG 01-13 08:46:18.612219.612219 lmp.py:1622]   Expert 14 |    200 | GPU
DEBUG 01-13 08:46:18.612862.612862 lmp.py:1622]   Expert 15 |    200 | GPU
DEBUG 01-13 08:46:18.612266.612266 lmp.py:1622]   Expert 32 |    200 | GPU
DEBUG 01-13 08:46:18.612386.612386 lmp.py:1622]   Expert  1 |    211 | GPU
DEBUG 01-13 08:46:18.612837.612837 lmp.py:1622]   Expert  4 |    224 | GPU
DEBUG 01-13 08:46:18.612050.612050 lmp.py:1622]   Expert 39 |    229 | GPU
DEBUG 01-13 08:46:18.612500.612500 lmp.py:1622]   Expert  3 |    231 | GPU
DEBUG 01-13 08:46:18.612236.612236 lmp.py:1622]   Expert 52 |    238 | GPU
DEBUG 01-13 08:46:18.612449.612449 lmp.py:1622]   Expert 34 |    239 | GPU
DEBUG 01-13 08:46:18.612423.612423 lmp.py:1622]   Expert 28 |    245 | GPU
DEBUG 01-13 08:46:18.612397.612397 lmp.py:1622]   Expert 25 |    252 | GPU
DEBUG 01-13 08:46:18.612609.612609 lmp.py:1622]   Expert 22 |    260 | GPU
DEBUG 01-13 08:46:18.612345.612345 lmp.py:1622]   Expert 41 |    271 | GPU
DEBUG 01-13 08:46:18.613898.613898 lmp.py:1622]   Expert 29 |    272 | GPU
DEBUG 01-13 08:46:18.613284.613284 lmp.py:1622]   Expert  2 |    280 | GPU
DEBUG 01-13 08:46:18.613450.613450 lmp.py:1622]   Expert 21 |    282 | GPU
DEBUG 01-13 08:46:18.613662.613662 lmp.py:1622]   Expert 60 |    286 | GPU
DEBUG 01-13 08:46:18.613113.613113 lmp.py:1622]   Expert 63 |    288 | GPU
DEBUG 01-13 08:46:18.613564.613564 lmp.py:1622]   Expert 62 |    304 | GPU
DEBUG 01-13 08:46:18.613538.613538 lmp.py:1622]   Expert 27 |    311 | GPU
DEBUG 01-13 08:46:18.614989.614989 lmp.py:1622]   Expert 53 |    330 | GPU
DEBUG 01-13 08:46:18.614963.614963 lmp.py:1622]   Expert  8 |    335 | GPU
DEBUG 01-13 08:46:18.614367.614367 lmp.py:1622]   Expert 37 |    340 | GPU
DEBUG 01-13 08:46:18.614726.614726 lmp.py:1622]   Expert 19 |    435 | GPU
DEBUG 01-13 08:46:18.614038.614038 lmp.py:1622]   Expert  9 |    619 | GPU
DEBUG 01-13 08:46:18.614588.614588 lmp.py:1623] 
DEBUG 01-13 08:46:18.614588.614588 lmp.py:1623]   CPU total tokens: 3965 (32.3%)
DEBUG 01-13 08:46:18.614185.614185 lmp.py:1624]   GPU total tokens: 8323 (67.7%)
DEBUG 01-13 08:46:18.614980.614980 cuda_h.py:19] end experts_map_get cost 0.0031557083129882812 seconds
DEBUG 01-13 08:46:18.614890.614890 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-13 08:46:18.614262.614262 lmp.py:1632] 
DEBUG 01-13 08:46:18.614262.614262 lmp.py:1632]   Computing 32 experts on CPU MP...
DEBUG 01-13 08:46:18.614853.614853 cuda_h.py:19] end cpu_experts_submit cost 4.982948303222656e-05 seconds
DEBUG 01-13 08:46:18.614854.614854 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-13 08:46:18.614876.614876 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-13 08:46:18.614728.614728 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-13 08:46:18.614218.614218 cuda_h.py:19] end allocate_cuda_memory cost 0.00035762786865234375 seconds
DEBUG 01-13 08:46:18.614313.614313 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-13 08:46:18.615738.615738 sllm_store_c.py:27] get device uuid map
DEBUG 01-13 08:46:18.615660.615660 sllm_store_c.py:29] call client load into gpu
DEBUG 01-13 08:46:18.615124.615124 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 9a92dd25-ba47-417d-8a65-de0fef02f14f
DEBUG 01-13 08:46:18.615561.615561 client.py:106] call stub.LoadModelAsync
DEBUG 01-13 08:46:18.616248.616248 cuda_h.py:10] start experts_func_gpu_einsum_mp
INFO 01-13 08:46:18.617333.617333 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 9a92dd25-ba47-417d-8a65-de0fef02f14f
DEBUG 01-13 08:46:18.617368.617368 cuda_h.py:19] end load_into_gpu_async cost 0.0026051998138427734 seconds
DEBUG 01-13 08:46:18.617561.617561 cuda_h.py:10] start restore_tensors2
DEBUG 01-13 08:46:18.618309.618309 cuda_h.py:19] end restore_tensors2 cost 0.0003483295440673828 seconds
DEBUG 01-13 08:46:18.618562.618562 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0036764144897460938 seconds
DEBUG 01-13 08:46:18.618709.618709 cuda_h.py:10] start restore2model
DEBUG 01-13 08:46:18.621879.621879 cuda_h.py:19] end restore2model cost 0.003041505813598633 seconds
DEBUG 01-13 08:46:18.621622.621622 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.006899118423461914 seconds
DEBUG 01-13 08:46:18.621464.621464 cuda_h.py:10] start gpu_sexperts
DEBUG 01-13 08:46:18.621483.621483 cuda_h.py:19] end gpu_sexperts cost 0.000331878662109375 seconds
DEBUG 01-13 08:46:18.621266.621266 cuda_h.py:10] start wait_experts
INFO 01-13 08:46:18.621214.621214 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 9a92dd25-ba47-417d-8a65-de0fef02f14f
DEBUG 01-13 08:46:18.624713.624713 mlpmodule.py:1006] group tensors cost 0.007130622863769531 s
DEBUG 01-13 08:46:18.627203.627203 mlpmodule.py:1044] pad cost 0.0020580291748046875 s
DEBUG 01-13 08:46:18.627345.627345 mlpmodule.py:1050] create cpu tensor cost 5.364418029785156e-05 s
DEBUG 01-13 08:46:18.627857.627857 mlpmodule.py:1055] move to cpu cost 2.8848648071289062e-05 s
DEBUG 01-13 08:46:18.638516.638516 mlpmodule.py:1069] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-13 08:46:18.638746.638746 mlpmodule.py:1070] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-13 08:46:18.639843.639843 mlpmodule.py:1075] group_w3 first element: -0.006439208984375
WARNING 01-13 08:46:18.639728.639728 mlpmodule.py:1085] start einsum2
DEBUG 01-13 08:46:18.655701.655701 mlpmodule.py:1095] group einsum cost 0.0280764102935791 s
DEBUG 01-13 08:46:18.656622.656622 mlpmodule.py:1103] cpy2cputensor cost 0.0006177425384521484 s
DEBUG 01-13 08:46:18.673078.673078 mlpmodule.py:785]  experts func einsum cost 0.05661630630493164 s
DEBUG 01-13 08:46:18.674468.674468 cuda_h.py:19] end experts_func_gpu_einsum_mp cost 0.05752706527709961 seconds
INFO 01-13 08:46:18.674036.674036 client.py:127] Model loaded
DEBUG 01-13 08:46:18.674643.674643 cuda_h.py:19] end wait_experts cost 0.05274844169616699 seconds
DEBUG 01-13 08:46:18.674876.674876 cuda_h.py:10] start gpu_experts
DEBUG 01-13 08:46:18.675918.675918 mlpmodule.py:559] gpu group tensors cost 0.0005586147308349609 s
DEBUG 01-13 08:46:18.676248.676248 mlpmodule.py:592] gpu pad cost 0.0014662742614746094 s
DEBUG 01-13 08:46:18.676389.676389 mlpmodule.py:598] start_w1
DEBUG 01-13 08:46:18.677336.677336 mlpmodule.py:602] start_w3
DEBUG 01-13 08:46:18.677275.677275 mlpmodule.py:608] start_w2
DEBUG 01-13 08:46:18.677367.677367 mlpmodule.py:611] gpu group einsum cost 0.0007190704345703125 s
DEBUG 01-13 08:46:18.679001.679001 mlpmodule.py:683] gpu experts func einsum cost 0.005011558532714844 s
DEBUG 01-13 08:46:18.679726.679726 cuda_h.py:19] end gpu_experts cost 0.005166053771972656 seconds
DEBUG 01-13 08:46:18.679674.679674 cuda_h.py:10] start cpu_thread_manager_mp_wait
DEBUG 01-13 08:46:18.679093.679093 cuda_h.py:19] end cpu_thread_manager_mp_wait cost 3.4809112548828125e-05 seconds
DEBUG 01-13 08:46:18.679394.679394 cuda_h.py:19] end layer_moe_generate_mp_l_28 cost 0.06969571113586426 seconds
DEBUG 01-13 08:46:18.680043.680043 lmp.py:1550] -------------------------------- end prefill layer 27 --------------------------------
DEBUG 01-13 08:46:18.680051.680051 cuda_h.py:19] end prefill_layer cost 2.6474292278289795 seconds
DEBUG 01-13 08:46:20.850748.850748 cuda_h.py:10] start generate_input_ids
generate input ids cost 0.10073637962341309 s
DEBUG 01-13 08:46:21.204743.204743 cuda_h.py:19] end generate_input_ids cost 0.35319042205810547 seconds
DEBUG 01-13 08:46:21.204531.204531 cuda_h.py:10] start init_cache
DEBUG 01-13 08:46:21.204245.204245 cuda_h.py:19] end init_cache cost 8.034706115722656e-05 seconds
DEBUG 01-13 08:46:23.853744.853744 cuda_h.py:10] start init_meta_layer
DEBUG 01-13 08:46:23.854725.854725 cuda_h.py:19] end init_meta_layer cost 1.7642974853515625e-05 seconds
DEBUG 01-13 08:46:23.854999.854999 cuda_h.py:10] start init_weights
DEBUG 01-13 08:46:23.854239.854239 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-13 08:46:23.854432.854432 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-13 08:46:23.856772.856772 cuda_h.py:19] end allocate_cuda_memory cost 0.0020074844360351562 seconds
DEBUG 01-13 08:46:23.857350.857350 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-13 08:46:23.857590.857590 sllm_store_c.py:27] get device uuid map
DEBUG 01-13 08:46:23.857565.857565 sllm_store_c.py:29] call client load into gpu
DEBUG 01-13 08:46:23.857507.857507 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 92d79ca4-460d-4605-8238-e329fb101f51
DEBUG 01-13 08:46:23.857987.857987 client.py:106] call stub.LoadModelAsync
INFO 01-13 08:46:23.859440.859440 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 92d79ca4-460d-4605-8238-e329fb101f51
DEBUG 01-13 08:46:23.859591.859591 cuda_h.py:19] end load_into_gpu_async cost 0.0023703575134277344 seconds
DEBUG 01-13 08:46:23.859607.859607 cuda_h.py:10] start restore_tensors2
DEBUG 01-13 08:46:23.859806.859806 cuda_h.py:19] end restore_tensors2 cost 0.0001342296600341797 seconds
DEBUG 01-13 08:46:23.859563.859563 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.004920244216918945 seconds
DEBUG 01-13 08:46:23.859974.859974 cuda_h.py:10] start restore2model
DEBUG 01-13 08:46:23.860392.860392 cuda_h.py:19] end restore2model cost 0.000179290771484375 seconds
INFO 01-13 08:46:23.860724.860724 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 92d79ca4-460d-4605-8238-e329fb101f51
INFO 01-13 08:46:23.938204.938204 client.py:127] Model loaded
DEBUG 01-13 08:46:23.938243.938243 cuda_h.py:10] start load_qkvogns_weight_l_0
DEBUG 01-13 08:46:23.938334.938334 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-13 08:46:23.939841.939841 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-13 08:46:23.939494.939494 cuda_h.py:19] end allocate_cuda_memory cost 0.00041961669921875 seconds
DEBUG 01-13 08:46:23.939327.939327 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-13 08:46:23.939119.939119 sllm_store_c.py:27] get device uuid map
DEBUG 01-13 08:46:23.939400.939400 sllm_store_c.py:29] call client load into gpu
DEBUG 01-13 08:46:23.940833.940833 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 2ca36226-f1e3-4880-86dd-c651d36f21c8
DEBUG 01-13 08:46:23.940501.940501 client.py:106] call stub.LoadModelAsync
INFO 01-13 08:46:23.941087.941087 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 2ca36226-f1e3-4880-86dd-c651d36f21c8
DEBUG 01-13 08:46:23.942311.942311 cuda_h.py:19] end load_into_gpu_async cost 0.0021698474884033203 seconds
DEBUG 01-13 08:46:23.942241.942241 cuda_h.py:10] start restore_tensors2
DEBUG 01-13 08:46:23.942097.942097 cuda_h.py:19] end restore_tensors2 cost 0.00015807151794433594 seconds
DEBUG 01-13 08:46:23.942186.942186 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0034224987030029297 seconds
INFO 01-13 08:46:23.942580.942580 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 2ca36226-f1e3-4880-86dd-c651d36f21c8
INFO 01-13 08:46:23.957310.957310 client.py:127] Model loaded
DEBUG 01-13 08:46:23.957077.957077 cuda_h.py:10] start restore2model
DEBUG 01-13 08:46:23.958359.958359 cuda_h.py:19] end restore2model cost 0.00101470947265625 seconds
DEBUG 01-13 08:46:23.958351.958351 cuda_h.py:19] end load_qkvogns_weight_l_0 cost 0.019920825958251953 seconds
DEBUG 01-13 08:46:23.958817.958817 cuda_h.py:19] end init_weights cost 0.1041114330291748 seconds
DEBUG 01-13 08:46:23.959773.959773 cuda_h.py:10] start copy_emodel
DEBUG 01-13 08:46:24.749119.749119 cuda_h.py:19] end copy_emodel cost 0.7902882099151611 seconds
DEBUG 01-13 08:46:24.750901.750901 cuda_h.py:10] start init_inputs_tokens
DEBUG 01-13 08:46:24.750084.750084 cuda_h.py:19] end init_inputs_tokens cost 0.0003027915954589844 seconds
DEBUG 01-13 08:46:24.750476.750476 cuda_h.py:10] start prefill_layer
DEBUG 01-13 08:46:24.750670.750670 lmp.py:1493] -------------------------------- start prefill layer 0 --------------------------------
DEBUG 01-13 08:46:24.750796.750796 cuda_h.py:10] start start_load_qkvogn_s_weight_l_1
DEBUG 01-13 08:46:24.750407.750407 cuda_h.py:10] start start_load_qkvogn_s_weight_l_1
DEBUG 01-13 08:46:24.750442.750442 cuda_h.py:19] end start_load_qkvogn_s_weight_l_1 cost 3.24249267578125e-05 seconds
DEBUG 01-13 08:46:24.750165.750165 cuda_h.py:19] end start_load_qkvogn_s_weight_l_1 cost 8.058547973632812e-05 seconds
DEBUG 01-13 08:46:24.750000.750000 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-13 08:46:24.750512.750512 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-13 08:46:24.750296.750296 cuda_h.py:10] start sllm_worker_task
DEBUG 01-13 08:46:24.751155.751155 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-13 08:46:24.751151.751151 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-13 08:46:24.751949.751949 cuda_h.py:19] end allocate_cuda_memory cost 0.00026488304138183594 seconds
DEBUG 01-13 08:46:24.751912.751912 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-13 08:46:24.751716.751716 sllm_store_c.py:27] get device uuid map
DEBUG 01-13 08:46:24.751598.751598 sllm_store_c.py:29] call client load into gpu
DEBUG 01-13 08:46:24.751593.751593 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 9ece3784-6be5-4bf9-88cc-3543a1223246
DEBUG 01-13 08:46:24.751742.751742 client.py:106] call stub.LoadModelAsync
DEBUG 01-13 08:46:24.752641.752641 cuda_h.py:10] start self_attn
INFO 01-13 08:46:24.753018.753018 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 9ece3784-6be5-4bf9-88cc-3543a1223246
DEBUG 01-13 08:46:24.754015.754015 cuda_h.py:19] end load_into_gpu_async cost 0.0023927688598632812 seconds
DEBUG 01-13 08:46:24.754553.754553 cuda_h.py:10] start restore_tensors2
DEBUG 01-13 08:46:24.754703.754703 cuda_h.py:19] end restore_tensors2 cost 9.846687316894531e-05 seconds
DEBUG 01-13 08:46:24.754421.754421 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0031337738037109375 seconds
INFO 01-13 08:46:24.754888.754888 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 9ece3784-6be5-4bf9-88cc-3543a1223246
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-13 08:46:24.759532.759532 cuda_h.py:19] end self_attn cost 0.007489919662475586 seconds
DEBUG 01-13 08:46:24.760616.760616 cuda_h.py:19] end iln_self_attn_paln cost 0.009865045547485352 seconds
DEBUG 01-13 08:46:24.760022.760022 cuda_h.py:10] start dense_mlp
INFO 01-13 08:46:24.762076.762076 client.py:127] Model loaded
DEBUG 01-13 08:46:24.762530.762530 cuda_h.py:10] start restore2model
DEBUG 01-13 08:46:24.763486.763486 cuda_h.py:19] end restore2model cost 0.0006163120269775391 seconds
DEBUG 01-13 08:46:24.763720.763720 cuda_h.py:19] end sllm_worker_task cost 0.012115955352783203 seconds
DEBUG 01-13 08:46:24.763147.763147 cuda_h.py:19] end dense_mlp cost 0.002505779266357422 seconds
DEBUG 01-13 08:46:24.763773.763773 lmp.py:1550] -------------------------------- end prefill layer 0 --------------------------------
DEBUG 01-13 08:46:24.763583.763583 lmp.py:1493] -------------------------------- start prefill layer 1 --------------------------------
DEBUG 01-13 08:46:24.763378.763378 cuda_h.py:10] start start_load_qkvogn_s_weight_l_2
DEBUG 01-13 08:46:24.763909.763909 cuda_h.py:10] start start_load_qkvogn_s_weight_l_2
DEBUG 01-13 08:46:24.763739.763739 cuda_h.py:19] end start_load_qkvogn_s_weight_l_2 cost 2.2172927856445312e-05 seconds
DEBUG 01-13 08:46:24.763826.763826 cuda_h.py:19] end start_load_qkvogn_s_weight_l_2 cost 5.4836273193359375e-05 seconds
DEBUG 01-13 08:46:24.763807.763807 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-13 08:46:24.763345.763345 cuda_h.py:10] start sllm_worker_task
DEBUG 01-13 08:46:24.763692.763692 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-13 08:46:24.763021.763021 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-13 08:46:24.763944.763944 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-13 08:46:24.764727.764727 cuda_h.py:19] end allocate_cuda_memory cost 0.000274658203125 seconds
DEBUG 01-13 08:46:24.764301.764301 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-13 08:46:24.764900.764900 sllm_store_c.py:27] get device uuid map
DEBUG 01-13 08:46:24.764210.764210 sllm_store_c.py:29] call client load into gpu
DEBUG 01-13 08:46:24.764914.764914 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, cee0c8dd-75cd-4535-bfcd-f22c2cca9446
DEBUG 01-13 08:46:24.765138.765138 client.py:106] call stub.LoadModelAsync
DEBUG 01-13 08:46:24.765219.765219 cuda_h.py:10] start self_attn
INFO 01-13 08:46:24.767918.767918 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, cee0c8dd-75cd-4535-bfcd-f22c2cca9446
DEBUG 01-13 08:46:24.767273.767273 cuda_h.py:19] end load_into_gpu_async cost 0.002838134765625 seconds
DEBUG 01-13 08:46:24.767389.767389 cuda_h.py:10] start restore_tensors2
DEBUG 01-13 08:46:24.767754.767754 cuda_h.py:19] end restore_tensors2 cost 0.00010585784912109375 seconds
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
DEBUG 01-13 08:46:24.767502.767502 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0040283203125 seconds
INFO 01-13 08:46:24.768572.768572 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, cee0c8dd-75cd-4535-bfcd-f22c2cca9446
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-13 08:46:24.769332.769332 cuda_h.py:19] end self_attn cost 0.003696918487548828 seconds
DEBUG 01-13 08:46:24.769854.769854 cuda_h.py:19] end iln_self_attn_paln cost 0.005723237991333008 seconds
DEBUG 01-13 08:46:24.769419.769419 cuda_h.py:10] start layer_moe_generate_mp_l_2
DEBUG 01-13 08:46:24.769281.769281 cuda_h.py:10] start gate
DEBUG 01-13 08:46:24.770188.770188 cuda_h.py:19] end gate cost 0.0009465217590332031 seconds
DEBUG 01-13 08:46:24.770687.770687 cuda_h.py:10] start experts_map_get
DEBUG 01-13 08:46:24.771146.771146 lmp.py:1611] 
DEBUG 01-13 08:46:24.771146.771146 lmp.py:1611] Expert Token Distribution & Device Allocation:
DEBUG 01-13 08:46:24.771194.771194 lmp.py:1612]   Total experts: 64
DEBUG 01-13 08:46:24.771420.771420 lmp.py:1613]   CPU experts: 32 (50%)
DEBUG 01-13 08:46:24.771354.771354 lmp.py:1614]   GPU experts: 32 (50%)
DEBUG 01-13 08:46:24.771143.771143 lmp.py:1615] 
DEBUG 01-13 08:46:24.771143.771143 lmp.py:1615]   Expert ID | Tokens | Device
DEBUG 01-13 08:46:24.771886.771886 lmp.py:1616]   -----------------------------------
DEBUG 01-13 08:46:24.771112.771112 lmp.py:1622]   Expert 25 |     64 | CPU
DEBUG 01-13 08:46:24.771424.771424 lmp.py:1622]   Expert 54 |     67 | CPU
DEBUG 01-13 08:46:24.771020.771020 lmp.py:1622]   Expert  3 |     68 | CPU
DEBUG 01-13 08:46:24.771617.771617 lmp.py:1622]   Expert 31 |     72 | CPU
DEBUG 01-13 08:46:24.771929.771929 lmp.py:1622]   Expert 55 |     72 | CPU
DEBUG 01-13 08:46:24.771287.771287 lmp.py:1622]   Expert 62 |     87 | CPU
DEBUG 01-13 08:46:24.771884.771884 lmp.py:1622]   Expert 18 |     88 | CPU
DEBUG 01-13 08:46:24.771719.771719 lmp.py:1622]   Expert 52 |     98 | CPU
DEBUG 01-13 08:46:24.771839.771839 lmp.py:1622]   Expert 22 |    100 | CPU
DEBUG 01-13 08:46:24.771958.771958 lmp.py:1622]   Expert 47 |    104 | CPU
DEBUG 01-13 08:46:24.771555.771555 lmp.py:1622]   Expert  0 |    113 | CPU
DEBUG 01-13 08:46:24.771675.771675 lmp.py:1622]   Expert 37 |    117 | CPU
DEBUG 01-13 08:46:24.771795.771795 lmp.py:1622]   Expert 27 |    121 | CPU
DEBUG 01-13 08:46:24.771345.771345 lmp.py:1622]   Expert 32 |    123 | CPU
DEBUG 01-13 08:46:24.771657.771657 lmp.py:1622]   Expert 41 |    130 | CPU
DEBUG 01-13 08:46:24.771207.771207 lmp.py:1622]   Expert 44 |    131 | CPU
DEBUG 01-13 08:46:24.771565.771565 lmp.py:1622]   Expert 28 |    136 | CPU
DEBUG 01-13 08:46:24.771639.771639 lmp.py:1622]   Expert 13 |    138 | CPU
DEBUG 01-13 08:46:24.771759.771759 lmp.py:1622]   Expert 58 |    140 | CPU
DEBUG 01-13 08:46:24.771878.771878 lmp.py:1622]   Expert 60 |    144 | CPU
DEBUG 01-13 08:46:24.771998.771998 lmp.py:1622]   Expert 43 |    147 | CPU
DEBUG 01-13 08:46:24.771641.771641 lmp.py:1622]   Expert  1 |    150 | CPU
DEBUG 01-13 08:46:24.771284.771284 lmp.py:1622]   Expert 38 |    153 | CPU
DEBUG 01-13 08:46:24.771119.771119 lmp.py:1622]   Expert 49 |    154 | CPU
DEBUG 01-13 08:46:24.771239.771239 lmp.py:1622]   Expert 51 |    155 | CPU
DEBUG 01-13 08:46:24.771313.771313 lmp.py:1622]   Expert 34 |    161 | CPU
DEBUG 01-13 08:46:24.771956.771956 lmp.py:1622]   Expert 35 |    164 | CPU
DEBUG 01-13 08:46:24.771837.771837 lmp.py:1622]   Expert 36 |    168 | CPU
DEBUG 01-13 08:46:24.771149.771149 lmp.py:1622]   Expert 11 |    170 | CPU
DEBUG 01-13 08:46:24.771620.771620 lmp.py:1622]   Expert 17 |    170 | CPU
DEBUG 01-13 08:46:24.771647.771647 lmp.py:1622]   Expert 59 |    174 | CPU
DEBUG 01-13 08:46:24.771529.771529 lmp.py:1622]   Expert 10 |    180 | CPU
DEBUG 01-13 08:46:24.771649.771649 lmp.py:1622]   Expert 20 |    182 | GPU
DEBUG 01-13 08:46:24.771768.771768 lmp.py:1622]   Expert  2 |    186 | GPU
DEBUG 01-13 08:46:24.771127.771127 lmp.py:1622]   Expert 39 |    189 | GPU
DEBUG 01-13 08:46:24.771246.771246 lmp.py:1622]   Expert 33 |    197 | GPU
DEBUG 01-13 08:46:24.771366.771366 lmp.py:1622]   Expert 12 |    198 | GPU
DEBUG 01-13 08:46:24.771724.771724 lmp.py:1622]   Expert 21 |    198 | GPU
DEBUG 01-13 08:46:24.771606.771606 lmp.py:1622]   Expert 48 |    198 | GPU
DEBUG 01-13 08:46:24.771487.771487 lmp.py:1622]   Expert 15 |    199 | GPU
DEBUG 01-13 08:46:24.771322.771322 lmp.py:1622]   Expert 53 |    204 | GPU
DEBUG 01-13 08:46:24.771442.771442 lmp.py:1622]   Expert 19 |    220 | GPU
DEBUG 01-13 08:46:24.771754.771754 lmp.py:1622]   Expert 26 |    221 | GPU
DEBUG 01-13 08:46:24.771543.771543 lmp.py:1622]   Expert 30 |    221 | GPU
DEBUG 01-13 08:46:24.771663.771663 lmp.py:1622]   Expert 45 |    221 | GPU
DEBUG 01-13 08:46:24.771021.771021 lmp.py:1622]   Expert  5 |    227 | GPU
DEBUG 01-13 08:46:24.772141.772141 lmp.py:1622]   Expert  4 |    229 | GPU
DEBUG 01-13 08:46:24.772737.772737 lmp.py:1622]   Expert 24 |    229 | GPU
DEBUG 01-13 08:46:24.772095.772095 lmp.py:1622]   Expert 42 |    242 | GPU
DEBUG 01-13 08:46:24.772454.772454 lmp.py:1622]   Expert 50 |    245 | GPU
DEBUG 01-13 08:46:24.772335.772335 lmp.py:1622]   Expert 29 |    254 | GPU
DEBUG 01-13 08:46:24.772216.772216 lmp.py:1622]   Expert 56 |    262 | GPU
DEBUG 01-13 08:46:24.772336.772336 lmp.py:1622]   Expert 61 |    270 | GPU
DEBUG 01-13 08:46:24.772979.772979 lmp.py:1622]   Expert  8 |    283 | GPU
DEBUG 01-13 08:46:24.772814.772814 lmp.py:1622]   Expert 63 |    285 | GPU
DEBUG 01-13 08:46:24.772934.772934 lmp.py:1622]   Expert 46 |    294 | GPU
DEBUG 01-13 08:46:24.772769.772769 lmp.py:1622]   Expert  9 |    300 | GPU
DEBUG 01-13 08:46:24.772081.772081 lmp.py:1622]   Expert  6 |    316 | GPU
DEBUG 01-13 08:46:24.772585.772585 lmp.py:1622]   Expert 16 |    316 | GPU
DEBUG 01-13 08:46:24.772897.772897 lmp.py:1622]   Expert 40 |    319 | GPU
DEBUG 01-13 08:46:24.772255.772255 lmp.py:1622]   Expert  7 |    322 | GPU
DEBUG 01-13 08:46:24.772613.772613 lmp.py:1622]   Expert 23 |    325 | GPU
DEBUG 01-13 08:46:24.772733.772733 lmp.py:1622]   Expert 14 |    413 | GPU
DEBUG 01-13 08:46:24.772853.772853 lmp.py:1622]   Expert 57 |    464 | GPU
DEBUG 01-13 08:46:24.772165.772165 lmp.py:1623] 
DEBUG 01-13 08:46:24.772165.772165 lmp.py:1623]   CPU total tokens: 4059 (33.0%)
DEBUG 01-13 08:46:24.772715.772715 lmp.py:1624]   GPU total tokens: 8229 (67.0%)
DEBUG 01-13 08:46:24.772816.772816 cuda_h.py:19] end experts_map_get cost 0.0018520355224609375 seconds
DEBUG 01-13 08:46:24.772554.772554 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-13 08:46:24.772933.772933 lmp.py:1632] 
DEBUG 01-13 08:46:24.772933.772933 lmp.py:1632]   Computing 32 experts on CPU MP...
DEBUG 01-13 08:46:24.772398.772398 cuda_h.py:19] end cpu_experts_submit cost 5.936622619628906e-05 seconds
DEBUG 01-13 08:46:24.772545.772545 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-13 08:46:24.772474.772474 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-13 08:46:24.772088.772088 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-13 08:46:24.774425.774425 cuda_h.py:19] end allocate_cuda_memory cost 0.0010001659393310547 seconds
DEBUG 01-13 08:46:24.774566.774566 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-13 08:46:24.774183.774183 sllm_store_c.py:27] get device uuid map
DEBUG 01-13 08:46:24.774423.774423 sllm_store_c.py:29] call client load into gpu
DEBUG 01-13 08:46:24.774695.774695 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 244d32a2-e4b2-4d26-94b7-e56dc0374835
DEBUG 01-13 08:46:24.774638.774638 client.py:106] call stub.LoadModelAsync
DEBUG 01-13 08:46:24.774046.774046 cuda_h.py:10] start experts_func_gpu_einsum_mp
INFO 01-13 08:46:24.775336.775336 client.py:127] Model loaded
DEBUG 01-13 08:46:24.775200.775200 cuda_h.py:10] start restore2model
DEBUG 01-13 08:46:24.776986.776986 cuda_h.py:19] end restore2model cost 0.0008480548858642578 seconds
INFO 01-13 08:46:24.776679.776679 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 244d32a2-e4b2-4d26-94b7-e56dc0374835
DEBUG 01-13 08:46:24.776139.776139 cuda_h.py:19] end sllm_worker_task cost 0.01258087158203125 seconds
DEBUG 01-13 08:46:24.776766.776766 cuda_h.py:19] end load_into_gpu_async cost 0.001967191696166992 seconds
DEBUG 01-13 08:46:24.776749.776749 cuda_h.py:10] start restore_tensors2
DEBUG 01-13 08:46:24.776273.776273 cuda_h.py:19] end restore_tensors2 cost 0.0003905296325683594 seconds
DEBUG 01-13 08:46:24.777162.777162 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.004307985305786133 seconds
DEBUG 01-13 08:46:24.777356.777356 cuda_h.py:10] start restore2model
DEBUG 01-13 08:46:24.780835.780835 cuda_h.py:19] end restore2model cost 0.003198385238647461 seconds
DEBUG 01-13 08:46:24.780069.780069 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.007697582244873047 seconds
DEBUG 01-13 08:46:24.780341.780341 cuda_h.py:10] start gpu_sexperts
DEBUG 01-13 08:46:24.780631.780631 cuda_h.py:19] end gpu_sexperts cost 0.0003108978271484375 seconds
DEBUG 01-13 08:46:24.780322.780322 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-13 08:46:24.780575.780575 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 1.6450881958007812e-05 seconds
DEBUG 01-13 08:46:24.780225.780225 cuda_h.py:10] start wait_experts
INFO 01-13 08:46:24.780212.780212 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 244d32a2-e4b2-4d26-94b7-e56dc0374835
DEBUG 01-13 08:46:24.782582.782582 mlpmodule.py:1006] group tensors cost 0.006835222244262695 s
DEBUG 01-13 08:46:24.784688.784688 mlpmodule.py:1044] pad cost 0.0017490386962890625 s
DEBUG 01-13 08:46:24.785293.785293 mlpmodule.py:1050] create cpu tensor cost 4.100799560546875e-05 s
DEBUG 01-13 08:46:24.785131.785131 mlpmodule.py:1055] move to cpu cost 5.650520324707031e-05 s
DEBUG 01-13 08:46:24.799113.799113 mlpmodule.py:1069] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-13 08:46:24.799072.799072 mlpmodule.py:1070] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-13 08:46:24.799023.799023 mlpmodule.py:1075] group_w3 first element: -0.0107421875
WARNING 01-13 08:46:24.800332.800332 mlpmodule.py:1085] start einsum2
DEBUG 01-13 08:46:24.815357.815357 mlpmodule.py:1095] group einsum cost 0.029826879501342773 s
DEBUG 01-13 08:46:24.815878.815878 mlpmodule.py:1103] cpy2cputensor cost 0.0006947517395019531 s
INFO 01-13 08:46:24.826757.826757 client.py:127] Model loaded
DEBUG 01-13 08:46:24.826405.826405 cuda_h.py:19] end wait_experts cost 0.04587864875793457 seconds
DEBUG 01-13 08:46:24.826387.826387 cuda_h.py:10] start gpu_experts
DEBUG 01-13 08:46:24.828795.828795 mlpmodule.py:559] gpu group tensors cost 0.001405954360961914 s
DEBUG 01-13 08:46:24.830109.830109 mlpmodule.py:592] gpu pad cost 0.0019087791442871094 s
DEBUG 01-13 08:46:24.830351.830351 mlpmodule.py:598] start_w1
DEBUG 01-13 08:46:24.830801.830801 mlpmodule.py:602] start_w3
DEBUG 01-13 08:46:24.831284.831284 mlpmodule.py:608] start_w2
DEBUG 01-13 08:46:24.831261.831261 mlpmodule.py:611] gpu group einsum cost 0.00084686279296875 s
DEBUG 01-13 08:46:24.833303.833303 mlpmodule.py:683] gpu experts func einsum cost 0.006673097610473633 s
DEBUG 01-13 08:46:24.833087.833087 cuda_h.py:19] end gpu_experts cost 0.006829738616943359 seconds
DEBUG 01-13 08:46:24.833412.833412 cuda_h.py:10] start cpu_thread_manager_mp_wait
DEBUG 01-13 08:46:24.833183.833183 cuda_h.py:19] end cpu_thread_manager_mp_wait cost 4.6253204345703125e-05 seconds
DEBUG 01-13 08:46:24.833245.833245 cuda_h.py:19] end layer_moe_generate_mp_l_2 cost 0.06440925598144531 seconds
DEBUG 01-13 08:46:24.834869.834869 lmp.py:1550] -------------------------------- end prefill layer 1 --------------------------------
DEBUG 01-13 08:46:24.834069.834069 lmp.py:1493] -------------------------------- start prefill layer 2 --------------------------------
DEBUG 01-13 08:46:24.834725.834725 cuda_h.py:10] start start_load_qkvogn_s_weight_l_3
DEBUG 01-13 08:46:24.834812.834812 cuda_h.py:10] start start_load_qkvogn_s_weight_l_3
DEBUG 01-13 08:46:24.834079.834079 cuda_h.py:19] end start_load_qkvogn_s_weight_l_3 cost 3.218650817871094e-05 seconds
DEBUG 01-13 08:46:24.834305.834305 cuda_h.py:19] end start_load_qkvogn_s_weight_l_3 cost 6.103515625e-05 seconds
DEBUG 01-13 08:46:24.834140.834140 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-13 08:46:24.834355.834355 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-13 08:46:24.834093.834093 cuda_h.py:10] start sllm_worker_task
DEBUG 01-13 08:46:24.834195.834195 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-13 08:46:24.834647.834647 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-13 08:46:24.834773.834773 cuda_h.py:19] end allocate_cuda_memory cost 0.0001647472381591797 seconds
DEBUG 01-13 08:46:24.834828.834828 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-13 08:46:24.834161.834161 sllm_store_c.py:27] get device uuid map
DEBUG 01-13 08:46:24.834791.834791 sllm_store_c.py:29] call client load into gpu
DEBUG 01-13 08:46:24.834017.834017 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 7ea19050-5e34-49a6-86e5-59f5decb1610
DEBUG 01-13 08:46:24.835901.835901 client.py:106] call stub.LoadModelAsync
DEBUG 01-13 08:46:24.835989.835989 cuda_h.py:10] start self_attn
INFO 01-13 08:46:24.836058.836058 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 7ea19050-5e34-49a6-86e5-59f5decb1610
DEBUG 01-13 08:46:24.836325.836325 cuda_h.py:19] end load_into_gpu_async cost 0.0019466876983642578 seconds
DEBUG 01-13 08:46:24.836644.836644 cuda_h.py:10] start restore_tensors2
DEBUG 01-13 08:46:24.836097.836097 cuda_h.py:19] end restore_tensors2 cost 6.413459777832031e-05 seconds
DEBUG 01-13 08:46:24.837231.837231 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.002417325973510742 seconds
INFO 01-13 08:46:24.837444.837444 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 7ea19050-5e34-49a6-86e5-59f5decb1610
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-13 08:46:24.838328.838328 cuda_h.py:19] end self_attn cost 0.0029642581939697266 seconds
DEBUG 01-13 08:46:24.838279.838279 cuda_h.py:19] end iln_self_attn_paln cost 0.0043184757232666016 seconds
DEBUG 01-13 08:46:24.838977.838977 cuda_h.py:10] start layer_moe_generate_mp_l_3
DEBUG 01-13 08:46:24.838594.838594 cuda_h.py:10] start gate
DEBUG 01-13 08:46:24.839239.839239 cuda_h.py:19] end gate cost 0.0006542205810546875 seconds
DEBUG 01-13 08:46:24.839307.839307 cuda_h.py:10] start experts_map_get
DEBUG 01-13 08:46:24.839747.839747 lmp.py:1611] 
DEBUG 01-13 08:46:24.839747.839747 lmp.py:1611] Expert Token Distribution & Device Allocation:
DEBUG 01-13 08:46:24.839549.839549 lmp.py:1612]   Total experts: 64
DEBUG 01-13 08:46:24.839722.839722 lmp.py:1613]   CPU experts: 32 (50%)
DEBUG 01-13 08:46:24.839319.839319 lmp.py:1614]   GPU experts: 32 (50%)
DEBUG 01-13 08:46:24.839008.839008 lmp.py:1615] 
DEBUG 01-13 08:46:24.839008.839008 lmp.py:1615]   Expert ID | Tokens | Device
DEBUG 01-13 08:46:24.839890.839890 lmp.py:1616]   -----------------------------------
DEBUG 01-13 08:46:24.839301.839301 lmp.py:1622]   Expert 58 |     50 | CPU
DEBUG 01-13 08:46:24.839229.839229 lmp.py:1622]   Expert 27 |     56 | CPU
DEBUG 01-13 08:46:24.839680.839680 lmp.py:1622]   Expert  3 |     68 | CPU
DEBUG 01-13 08:46:24.839892.839892 lmp.py:1622]   Expert 17 |     84 | CPU
DEBUG 01-13 08:46:24.839628.839628 lmp.py:1622]   Expert 24 |     86 | CPU
DEBUG 01-13 08:46:24.839602.839602 lmp.py:1622]   Expert  0 |     88 | CPU
DEBUG 01-13 08:46:24.839337.839337 lmp.py:1622]   Expert 28 |    105 | CPU
DEBUG 01-13 08:46:24.840073.840073 lmp.py:1622]   Expert 34 |    113 | CPU
DEBUG 01-13 08:46:24.840047.840047 lmp.py:1622]   Expert 51 |    118 | CPU
DEBUG 01-13 08:46:24.840498.840498 lmp.py:1622]   Expert 32 |    120 | CPU
DEBUG 01-13 08:46:24.840949.840949 lmp.py:1622]   Expert  9 |    129 | CPU
DEBUG 01-13 08:46:24.840161.840161 lmp.py:1622]   Expert  7 |    136 | CPU
DEBUG 01-13 08:46:24.840374.840374 lmp.py:1622]   Expert 15 |    136 | CPU
DEBUG 01-13 08:46:24.840109.840109 lmp.py:1622]   Expert 23 |    136 | CPU
DEBUG 01-13 08:46:24.840607.840607 lmp.py:1622]   Expert 26 |    136 | CPU
DEBUG 01-13 08:46:24.840104.840104 lmp.py:1622]   Expert 30 |    143 | CPU
DEBUG 01-13 08:46:24.840601.840601 lmp.py:1622]   Expert 45 |    146 | CPU
DEBUG 01-13 08:46:24.840337.840337 lmp.py:1622]   Expert 62 |    147 | CPU
DEBUG 01-13 08:46:24.840834.840834 lmp.py:1622]   Expert 57 |    151 | CPU
DEBUG 01-13 08:46:24.840331.840331 lmp.py:1622]   Expert  1 |    153 | CPU
DEBUG 01-13 08:46:24.840351.840351 lmp.py:1622]   Expert 36 |    155 | CPU
DEBUG 01-13 08:46:24.840372.840372 lmp.py:1622]   Expert 29 |    159 | CPU
DEBUG 01-13 08:46:24.840869.840869 lmp.py:1622]   Expert  8 |    160 | CPU
DEBUG 01-13 08:46:24.840843.840843 lmp.py:1622]   Expert 25 |    163 | CPU
DEBUG 01-13 08:46:24.840294.840294 lmp.py:1622]   Expert  6 |    168 | CPU
DEBUG 01-13 08:46:24.840506.840506 lmp.py:1622]   Expert 54 |    169 | CPU
DEBUG 01-13 08:46:24.840843.840843 mlpmodule.py:785]  experts func einsum cost 0.06449699401855469 s
DEBUG 01-13 08:46:24.840480.840480 lmp.py:1622]   Expert 49 |    171 | CPU
DEBUG 01-13 08:46:24.840514.840514 lmp.py:1622]   Expert 12 |    174 | CPU
DEBUG 01-13 08:46:24.840787.840787 lmp.py:1622]   Expert 35 |    174 | CPU
DEBUG 01-13 08:46:24.840927.840927 lmp.py:1622]   Expert 48 |    175 | CPU
DEBUG 01-13 08:46:24.840199.840199 lmp.py:1622]   Expert 37 |    178 | CPU
DEBUG 01-13 08:46:24.840233.840233 lmp.py:1622]   Expert 13 |    188 | CPU
DEBUG 01-13 08:46:24.840744.840744 lmp.py:1622]   Expert 33 |    189 | GPU
DEBUG 01-13 08:46:24.840493.840493 lmp.py:1622]   Expert 53 |    190 | GPU
DEBUG 01-13 08:46:24.840898.840898 lmp.py:1622]   Expert 60 |    190 | GPU
DEBUG 01-13 08:46:24.840349.840349 lmp.py:1622]   Expert 10 |    194 | GPU
DEBUG 01-13 08:46:24.840038.840038 lmp.py:1622]   Expert 16 |    197 | GPU
DEBUG 01-13 08:46:24.840012.840012 lmp.py:1622]   Expert 21 |    198 | GPU
DEBUG 01-13 08:46:24.840748.840748 lmp.py:1622]   Expert 40 |    201 | GPU
DEBUG 01-13 08:46:24.840483.840483 lmp.py:1622]   Expert 38 |    204 | GPU
DEBUG 01-13 08:46:24.840219.840219 lmp.py:1622]   Expert 43 |    204 | GPU
DEBUG 01-13 08:46:24.840955.840955 lmp.py:1622]   Expert  5 |    207 | GPU
DEBUG 01-13 08:46:24.840452.840452 lmp.py:1622]   Expert 44 |    214 | GPU
DEBUG 01-13 08:46:24.840187.840187 lmp.py:1622]   Expert 19 |    217 | GPU
DEBUG 01-13 08:46:24.840161.840161 lmp.py:1622]   Expert 41 |    218 | GPU
DEBUG 01-13 08:46:24.840659.840659 lmp.py:1622]   Expert 50 |    218 | GPU
DEBUG 01-13 08:46:24.840871.840871 lmp.py:1622]   Expert 52 |    218 | GPU
DEBUG 01-13 08:46:24.840084.840084 lmp.py:1622]   Expert  4 |    220 | GPU
DEBUG 01-13 08:46:24.840534.840534 lmp.py:1622]   Expert 59 |    225 | GPU
DEBUG 01-13 08:46:24.840224.840224 lmp.py:1622]   Expert 55 |    231 | GPU
DEBUG 01-13 08:46:24.840675.840675 lmp.py:1622]   Expert 56 |    238 | GPU
DEBUG 01-13 08:46:24.840410.840410 lmp.py:1622]   Expert 31 |    243 | GPU
DEBUG 01-13 08:46:24.840907.840907 lmp.py:1622]   Expert 20 |    251 | GPU
DEBUG 01-13 08:46:24.840405.840405 lmp.py:1622]   Expert 39 |    252 | GPU
DEBUG 01-13 08:46:24.840140.840140 lmp.py:1622]   Expert 22 |    263 | GPU
DEBUG 01-13 08:46:24.840876.840876 lmp.py:1622]   Expert  2 |    267 | GPU
DEBUG 01-13 08:46:24.840612.840612 lmp.py:1622]   Expert 47 |    276 | GPU
DEBUG 01-13 08:46:24.840109.840109 lmp.py:1622]   Expert 63 |    276 | GPU
DEBUG 01-13 08:46:24.840844.840844 lmp.py:1622]   Expert 42 |    303 | GPU
DEBUG 01-13 08:46:24.840772.840772 lmp.py:1622]   Expert 18 |    314 | GPU
DEBUG 01-13 08:46:24.840746.840746 lmp.py:1622]   Expert 14 |    318 | GPU
DEBUG 01-13 08:46:24.840959.840959 lmp.py:1622]   Expert 46 |    367 | GPU
DEBUG 01-13 08:46:24.840933.840933 lmp.py:1622]   Expert 11 |    388 | GPU
DEBUG 01-13 08:46:24.840145.840145 lmp.py:1622]   Expert 61 |    462 | GPU
DEBUG 01-13 08:46:24.840073.840073 lmp.py:1623] 
DEBUG 01-13 08:46:24.840073.840073 lmp.py:1623]   CPU total tokens: 4335 (35.3%)
DEBUG 01-13 08:46:24.841239.841239 lmp.py:1624]   GPU total tokens: 7953 (64.7%)
DEBUG 01-13 08:46:24.841173.841173 cuda_h.py:19] end experts_map_get cost 0.0015230178833007812 seconds
DEBUG 01-13 08:46:24.841262.841262 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-13 08:46:24.841349.841349 lmp.py:1632] 
DEBUG 01-13 08:46:24.841349.841349 lmp.py:1632]   Computing 32 experts on CPU MP...
DEBUG 01-13 08:46:24.841748.841748 cuda_h.py:19] end cpu_experts_submit cost 4.863739013671875e-05 seconds
DEBUG 01-13 08:46:24.841179.841179 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-13 08:46:24.841784.841784 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-13 08:46:24.841358.841358 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-13 08:46:24.841783.841783 cuda_h.py:19] end experts_func_gpu_einsum_mp cost 0.06640434265136719 seconds
DEBUG 01-13 08:46:24.843423.843423 cuda_h.py:19] end allocate_cuda_memory cost 0.001699209213256836 seconds
DEBUG 01-13 08:46:24.843949.843949 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-13 08:46:24.843626.843626 sllm_store_c.py:27] get device uuid map
DEBUG 01-13 08:46:24.843388.843388 sllm_store_c.py:29] call client load into gpu
DEBUG 01-13 08:46:24.843515.843515 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, f55bd9c0-e933-43d6-a00e-4ecaf6f03816
DEBUG 01-13 08:46:24.843091.843091 client.py:106] call stub.LoadModelAsync
INFO 01-13 08:46:24.843007.843007 client.py:127] Model loaded
DEBUG 01-13 08:46:24.844393.844393 cuda_h.py:10] start restore2model
DEBUG 01-13 08:46:24.844321.844321 cuda_h.py:19] end restore2model cost 0.00036263465881347656 seconds
DEBUG 01-13 08:46:24.844488.844488 cuda_h.py:19] end sllm_worker_task cost 0.009946346282958984 seconds
DEBUG 01-13 08:46:24.844481.844481 cuda_h.py:10] start experts_func_gpu_einsum_mp
INFO 01-13 08:46:24.844995.844995 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, f55bd9c0-e933-43d6-a00e-4ecaf6f03816
DEBUG 01-13 08:46:24.844560.844560 cuda_h.py:19] end load_into_gpu_async cost 0.0015985965728759766 seconds
DEBUG 01-13 08:46:24.844217.844217 cuda_h.py:10] start restore_tensors2
DEBUG 01-13 08:46:24.845437.845437 cuda_h.py:19] end restore_tensors2 cost 0.0004138946533203125 seconds
DEBUG 01-13 08:46:24.845949.845949 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.004090785980224609 seconds
DEBUG 01-13 08:46:24.845665.845665 cuda_h.py:10] start restore2model
DEBUG 01-13 08:46:24.848026.848026 cuda_h.py:19] end restore2model cost 0.0026235580444335938 seconds
DEBUG 01-13 08:46:24.848206.848206 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.006914615631103516 seconds
DEBUG 01-13 08:46:24.848764.848764 cuda_h.py:10] start gpu_sexperts
DEBUG 01-13 08:46:24.848020.848020 cuda_h.py:19] end gpu_sexperts cost 0.0002989768981933594 seconds
DEBUG 01-13 08:46:24.848280.848280 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-13 08:46:24.848957.848957 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 1.3828277587890625e-05 seconds
DEBUG 01-13 08:46:24.848606.848606 cuda_h.py:10] start wait_experts
INFO 01-13 08:46:24.848978.848978 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, f55bd9c0-e933-43d6-a00e-4ecaf6f03816
DEBUG 01-13 08:46:24.849902.849902 mlpmodule.py:1006] group tensors cost 0.004123210906982422 s
DEBUG 01-13 08:46:24.851253.851253 mlpmodule.py:1044] pad cost 0.0014729499816894531 s
DEBUG 01-13 08:46:24.851827.851827 mlpmodule.py:1050] create cpu tensor cost 5.435943603515625e-05 s
DEBUG 01-13 08:46:24.851054.851054 mlpmodule.py:1055] move to cpu cost 2.8133392333984375e-05 s
DEBUG 01-13 08:46:24.862832.862832 mlpmodule.py:1069] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-13 08:46:24.862792.862792 mlpmodule.py:1070] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-13 08:46:24.862127.862127 mlpmodule.py:1075] group_w3 first element: -0.0380859375
WARNING 01-13 08:46:24.863319.863319 mlpmodule.py:1085] start einsum2
DEBUG 01-13 08:46:24.880014.880014 mlpmodule.py:1095] group einsum cost 0.029388427734375 s
DEBUG 01-13 08:46:24.881994.881994 mlpmodule.py:1103] cpy2cputensor cost 0.0007767677307128906 s
INFO 01-13 08:46:24.896932.896932 client.py:127] Model loaded
DEBUG 01-13 08:46:24.896964.896964 cuda_h.py:19] end wait_experts cost 0.04799938201904297 seconds
DEBUG 01-13 08:46:24.896397.896397 cuda_h.py:10] start gpu_experts
DEBUG 01-13 08:46:24.897375.897375 mlpmodule.py:559] gpu group tensors cost 0.0009827613830566406 s
DEBUG 01-13 08:46:24.901986.901986 mlpmodule.py:592] gpu pad cost 0.0034933090209960938 s
DEBUG 01-13 08:46:24.901633.901633 mlpmodule.py:598] start_w1
DEBUG 01-13 08:46:24.902795.902795 mlpmodule.py:602] start_w3
DEBUG 01-13 08:46:24.902203.902203 mlpmodule.py:608] start_w2
DEBUG 01-13 08:46:24.903004.903004 mlpmodule.py:611] gpu group einsum cost 0.0017833709716796875 s
DEBUG 01-13 08:46:24.903939.903939 mlpmodule.py:785]  experts func einsum cost 0.0586240291595459 s
DEBUG 01-13 08:46:24.903870.903870 cuda_h.py:19] end experts_func_gpu_einsum_mp cost 0.05942082405090332 seconds
DEBUG 01-13 08:46:24.907571.907571 mlpmodule.py:683] gpu experts func einsum cost 0.010411500930786133 s
DEBUG 01-13 08:46:24.907443.907443 cuda_h.py:19] end gpu_experts cost 0.010619401931762695 seconds
DEBUG 01-13 08:46:24.907682.907682 cuda_h.py:10] start cpu_thread_manager_mp_wait
DEBUG 01-13 08:46:24.907837.907837 cuda_h.py:19] end cpu_thread_manager_mp_wait cost 4.0531158447265625e-05 seconds
DEBUG 01-13 08:46:24.907496.907496 cuda_h.py:19] end layer_moe_generate_mp_l_3 cost 0.06888937950134277 seconds
DEBUG 01-13 08:46:24.907114.907114 lmp.py:1550] -------------------------------- end prefill layer 2 --------------------------------
DEBUG 01-13 08:46:24.907917.907917 lmp.py:1493] -------------------------------- start prefill layer 3 --------------------------------
DEBUG 01-13 08:46:24.907011.907011 cuda_h.py:10] start start_load_qkvogn_s_weight_l_4
DEBUG 01-13 08:46:24.908443.908443 cuda_h.py:10] start start_load_qkvogn_s_weight_l_4
DEBUG 01-13 08:46:24.908962.908962 cuda_h.py:19] end start_load_qkvogn_s_weight_l_4 cost 3.6716461181640625e-05 seconds
DEBUG 01-13 08:46:24.908884.908884 cuda_h.py:19] end start_load_qkvogn_s_weight_l_4 cost 8.654594421386719e-05 seconds
DEBUG 01-13 08:46:24.908110.908110 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-13 08:46:24.908628.908628 cuda_h.py:10] start sllm_worker_task
DEBUG 01-13 08:46:24.908196.908196 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-13 08:46:24.908032.908032 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-13 08:46:24.908560.908560 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-13 08:46:24.908270.908270 cuda_h.py:19] end allocate_cuda_memory cost 0.00019741058349609375 seconds
DEBUG 01-13 08:46:24.908869.908869 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-13 08:46:24.908116.908116 sllm_store_c.py:27] get device uuid map
DEBUG 01-13 08:46:24.908429.908429 sllm_store_c.py:29] call client load into gpu
DEBUG 01-13 08:46:24.909046.909046 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 3c772e51-4648-41d2-933e-04fd33a245e0
DEBUG 01-13 08:46:24.909328.909328 client.py:106] call stub.LoadModelAsync
DEBUG 01-13 08:46:24.909021.909021 cuda_h.py:10] start self_attn
INFO 01-13 08:46:24.910487.910487 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 3c772e51-4648-41d2-933e-04fd33a245e0
DEBUG 01-13 08:46:24.910980.910980 cuda_h.py:19] end load_into_gpu_async cost 0.0018630027770996094 seconds
DEBUG 01-13 08:46:24.910789.910789 cuda_h.py:10] start restore_tensors2
DEBUG 01-13 08:46:24.910846.910846 cuda_h.py:19] end restore_tensors2 cost 7.748603820800781e-05 seconds
DEBUG 01-13 08:46:24.910576.910576 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0024595260620117188 seconds
INFO 01-13 08:46:24.911479.911479 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 3c772e51-4648-41d2-933e-04fd33a245e0
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-13 08:46:24.912357.912357 cuda_h.py:19] end self_attn cost 0.003444194793701172 seconds
DEBUG 01-13 08:46:24.913151.913151 cuda_h.py:19] end iln_self_attn_paln cost 0.0051572322845458984 seconds
DEBUG 01-13 08:46:24.913908.913908 cuda_h.py:10] start layer_moe_generate_mp_l_4
DEBUG 01-13 08:46:24.913439.913439 cuda_h.py:10] start gate
DEBUG 01-13 08:46:24.914632.914632 cuda_h.py:19] end gate cost 0.0007567405700683594 seconds
DEBUG 01-13 08:46:24.914230.914230 cuda_h.py:10] start experts_map_get
DEBUG 01-13 08:46:24.914034.914034 lmp.py:1611] 
DEBUG 01-13 08:46:24.914034.914034 lmp.py:1611] Expert Token Distribution & Device Allocation:
DEBUG 01-13 08:46:24.914566.914566 lmp.py:1612]   Total experts: 64
DEBUG 01-13 08:46:24.914044.914044 lmp.py:1613]   CPU experts: 32 (50%)
DEBUG 01-13 08:46:24.914131.914131 lmp.py:1614]   GPU experts: 32 (50%)
DEBUG 01-13 08:46:24.914641.914641 lmp.py:1615] 
DEBUG 01-13 08:46:24.914641.914641 lmp.py:1615]   Expert ID | Tokens | Device
DEBUG 01-13 08:46:24.914245.914245 lmp.py:1616]   -----------------------------------
DEBUG 01-13 08:46:24.914517.914517 lmp.py:1622]   Expert  1 |     47 | CPU
DEBUG 01-13 08:46:24.915306.915306 lmp.py:1622]   Expert 27 |     63 | CPU
DEBUG 01-13 08:46:24.915664.915664 lmp.py:1622]   Expert  7 |     76 | CPU
DEBUG 01-13 08:46:24.915784.915784 lmp.py:1622]   Expert 48 |     82 | CPU
DEBUG 01-13 08:46:24.915142.915142 lmp.py:1622]   Expert 15 |     98 | CPU
DEBUG 01-13 08:46:24.915600.915600 lmp.py:1622]   Expert 30 |    109 | CPU
DEBUG 01-13 08:46:24.915449.915449 lmp.py:1622]   Expert 61 |    116 | CPU
DEBUG 01-13 08:46:24.915436.915436 lmp.py:1622]   Expert 45 |    117 | CPU
DEBUG 01-13 08:46:24.915709.915709 lmp.py:1622]   Expert 32 |    120 | CPU
DEBUG 01-13 08:46:24.915266.915266 lmp.py:1622]   Expert 18 |    121 | CPU
DEBUG 01-13 08:46:24.915631.915631 lmp.py:1622]   Expert 34 |    133 | CPU
DEBUG 01-13 08:46:24.915280.915280 lmp.py:1622]   Expert 39 |    136 | CPU
DEBUG 01-13 08:46:24.915877.915877 lmp.py:1622]   Expert 36 |    137 | CPU
DEBUG 01-13 08:46:24.915997.915997 lmp.py:1622]   Expert 26 |    139 | CPU
DEBUG 01-13 08:46:24.915355.915355 lmp.py:1622]   Expert  6 |    142 | CPU
DEBUG 01-13 08:46:24.915859.915859 lmp.py:1622]   Expert 11 |    142 | CPU
DEBUG 01-13 08:46:24.915231.915231 lmp.py:1622]   Expert  5 |    145 | CPU
DEBUG 01-13 08:46:24.915980.915980 lmp.py:1622]   Expert 51 |    145 | CPU
DEBUG 01-13 08:46:24.915776.915776 lmp.py:1622]   Expert 59 |    145 | CPU
DEBUG 01-13 08:46:24.915094.915094 lmp.py:1622]   Expert 49 |    155 | CPU
DEBUG 01-13 08:46:24.915791.915791 lmp.py:1622]   Expert  9 |    156 | CPU
DEBUG 01-13 08:46:24.915149.915149 lmp.py:1622]   Expert 23 |    156 | CPU
DEBUG 01-13 08:46:24.915745.915745 lmp.py:1622]   Expert  2 |    159 | CPU
DEBUG 01-13 08:46:24.915865.915865 lmp.py:1622]   Expert 50 |    165 | CPU
DEBUG 01-13 08:46:24.915985.915985 lmp.py:1622]   Expert 52 |    168 | CPU
DEBUG 01-13 08:46:24.915774.915774 lmp.py:1622]   Expert 56 |    168 | CPU
DEBUG 01-13 08:46:24.915622.915622 lmp.py:1622]   Expert 40 |    170 | CPU
DEBUG 01-13 08:46:24.915047.915047 lmp.py:1622]   Expert 16 |    172 | CPU
DEBUG 01-13 08:46:24.915558.915558 lmp.py:1622]   Expert 35 |    172 | CPU
DEBUG 01-13 08:46:24.915400.915400 lmp.py:1622]   Expert  4 |    187 | CPU
DEBUG 01-13 08:46:24.915527.915527 lmp.py:1622]   Expert 37 |    190 | CPU
DEBUG 01-13 08:46:24.915428.915428 lmp.py:1622]   Expert 13 |    191 | CPU
DEBUG 01-13 08:46:24.915363.915363 lmp.py:1622]   Expert 42 |    191 | GPU
DEBUG 01-13 08:46:24.915059.915059 lmp.py:1622]   Expert 62 |    196 | GPU
DEBUG 01-13 08:46:24.915716.915716 lmp.py:1622]   Expert 17 |    197 | GPU
DEBUG 01-13 08:46:24.915557.915557 lmp.py:1622]   Expert 38 |    197 | GPU
DEBUG 01-13 08:46:24.915638.915638 lmp.py:1622]   Expert 21 |    202 | GPU
DEBUG 01-13 08:46:24.915672.915672 lmp.py:1622]   Expert 44 |    208 | GPU
DEBUG 01-13 08:46:24.915798.915798 lmp.py:1622]   Expert  3 |    210 | GPU
DEBUG 01-13 08:46:24.915064.915064 lmp.py:1622]   Expert 58 |    210 | GPU
DEBUG 01-13 08:46:24.915468.915468 lmp.py:1622]   Expert 60 |    211 | GPU
DEBUG 01-13 08:46:24.915873.915873 lmp.py:1622]   Expert 28 |    213 | GPU
DEBUG 01-13 08:46:24.915801.915801 lmp.py:1622]   Expert 47 |    213 | GPU
DEBUG 01-13 08:46:24.915967.915967 lmp.py:1622]   Expert 10 |    216 | GPU
DEBUG 01-13 08:46:24.915133.915133 lmp.py:1622]   Expert 53 |    217 | GPU
DEBUG 01-13 08:46:24.915061.915061 lmp.py:1622]   Expert 55 |    219 | GPU
DEBUG 01-13 08:46:24.916988.916988 lmp.py:1622]   Expert 20 |    223 | GPU
DEBUG 01-13 08:46:24.916393.916393 lmp.py:1622]   Expert 57 |    224 | GPU
DEBUG 01-13 08:46:24.916658.916658 lmp.py:1622]   Expert 33 |    230 | GPU
DEBUG 01-13 08:46:24.916838.916838 lmp.py:1622]   Expert 46 |    236 | GPU
DEBUG 01-13 08:46:24.916680.916680 lmp.py:1622]   Expert 31 |    238 | GPU
DEBUG 01-13 08:46:24.916760.916760 lmp.py:1622]   Expert  8 |    239 | GPU
DEBUG 01-13 08:46:24.916602.916602 lmp.py:1622]   Expert 19 |    243 | GPU
DEBUG 01-13 08:46:24.916629.916629 lmp.py:1622]   Expert 24 |    244 | GPU
DEBUG 01-13 08:46:24.916511.916511 lmp.py:1622]   Expert 63 |    260 | GPU
DEBUG 01-13 08:46:24.916677.916677 lmp.py:1622]   Expert 14 |    261 | GPU
DEBUG 01-13 08:46:24.916605.916605 lmp.py:1622]   Expert 12 |    276 | GPU
DEBUG 01-13 08:46:24.916009.916009 lmp.py:1622]   Expert 29 |    276 | GPU
DEBUG 01-13 08:46:24.916891.916891 lmp.py:1622]   Expert 22 |    277 | GPU
DEBUG 01-13 08:46:24.916533.916533 lmp.py:1622]   Expert  0 |    293 | GPU
DEBUG 01-13 08:46:24.916700.916700 lmp.py:1622]   Expert 43 |    309 | GPU
DEBUG 01-13 08:46:24.916250.916250 lmp.py:1622]   Expert 54 |    339 | GPU
DEBUG 01-13 08:46:24.916191.916191 lmp.py:1622]   Expert 41 |    386 | GPU
DEBUG 01-13 08:46:24.916272.916272 lmp.py:1622]   Expert 25 |    412 | GPU
DEBUG 01-13 08:46:24.916782.916782 lmp.py:1623] 
DEBUG 01-13 08:46:24.916782.916782 lmp.py:1623]   CPU total tokens: 4422 (36.0%)
DEBUG 01-13 08:46:24.916758.916758 lmp.py:1624]   GPU total tokens: 7866 (64.0%)
DEBUG 01-13 08:46:24.916268.916268 cuda_h.py:19] end experts_map_get cost 0.0020933151245117188 seconds
DEBUG 01-13 08:46:24.916609.916609 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-13 08:46:24.916670.916670 lmp.py:1632] 
DEBUG 01-13 08:46:24.916670.916670 lmp.py:1632]   Computing 32 experts on CPU MP...
DEBUG 01-13 08:46:24.916751.916751 cuda_h.py:19] end cpu_experts_submit cost 6.222724914550781e-05 seconds
DEBUG 01-13 08:46:24.916785.916785 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-13 08:46:24.916179.916179 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-13 08:46:24.916945.916945 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-13 08:46:24.917319.917319 cuda_h.py:19] end allocate_cuda_memory cost 0.0010406970977783203 seconds
DEBUG 01-13 08:46:24.918229.918229 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-13 08:46:24.918429.918429 sllm_store_c.py:27] get device uuid map
DEBUG 01-13 08:46:24.918536.918536 sllm_store_c.py:29] call client load into gpu
DEBUG 01-13 08:46:24.918001.918001 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 24ed1947-eaef-4d38-a60f-0cda283c999f
DEBUG 01-13 08:46:24.918960.918960 client.py:106] call stub.LoadModelAsync
INFO 01-13 08:46:24.918290.918290 client.py:127] Model loaded
DEBUG 01-13 08:46:24.918869.918869 cuda_h.py:10] start restore2model
DEBUG 01-13 08:46:24.919779.919779 cuda_h.py:10] start experts_func_gpu_einsum_mp
DEBUG 01-13 08:46:24.919737.919737 cuda_h.py:19] end restore2model cost 0.0005514621734619141 seconds
DEBUG 01-13 08:46:24.919779.919779 cuda_h.py:19] end sllm_worker_task cost 0.011232614517211914 seconds
INFO 01-13 08:46:24.920471.920471 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 24ed1947-eaef-4d38-a60f-0cda283c999f
DEBUG 01-13 08:46:24.920295.920295 cuda_h.py:19] end load_into_gpu_async cost 0.0023212432861328125 seconds
DEBUG 01-13 08:46:24.920680.920680 cuda_h.py:10] start restore_tensors2
DEBUG 01-13 08:46:24.920014.920014 cuda_h.py:19] end restore_tensors2 cost 0.000453948974609375 seconds
DEBUG 01-13 08:46:24.921295.921295 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0042302608489990234 seconds
DEBUG 01-13 08:46:24.921985.921985 cuda_h.py:10] start restore2model
DEBUG 01-13 08:46:24.924993.924993 cuda_h.py:19] end restore2model cost 0.003164529800415039 seconds
DEBUG 01-13 08:46:24.924035.924035 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.007632017135620117 seconds
DEBUG 01-13 08:46:24.924467.924467 cuda_h.py:10] start gpu_sexperts
DEBUG 01-13 08:46:24.924340.924340 cuda_h.py:19] end gpu_sexperts cost 0.0003142356872558594 seconds
DEBUG 01-13 08:46:24.924368.924368 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-13 08:46:24.924596.924596 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.002716064453125e-05 seconds
DEBUG 01-13 08:46:24.924298.924298 cuda_h.py:10] start wait_experts
INFO 01-13 08:46:24.924154.924154 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 24ed1947-eaef-4d38-a60f-0cda283c999f
DEBUG 01-13 08:46:24.925868.925868 mlpmodule.py:1006] group tensors cost 0.005829811096191406 s
DEBUG 01-13 08:46:24.927449.927449 mlpmodule.py:1044] pad cost 0.0014181137084960938 s
DEBUG 01-13 08:46:24.927379.927379 mlpmodule.py:1050] create cpu tensor cost 3.814697265625e-05 s
DEBUG 01-13 08:46:24.927460.927460 mlpmodule.py:1055] move to cpu cost 2.7418136596679688e-05 s
DEBUG 01-13 08:46:24.937169.937169 mlpmodule.py:1069] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-13 08:46:24.937161.937161 mlpmodule.py:1070] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-13 08:46:24.937350.937350 mlpmodule.py:1075] group_w3 first element: -0.054931640625
WARNING 01-13 08:46:24.937043.937043 mlpmodule.py:1085] start einsum2
DEBUG 01-13 08:46:24.951385.951385 mlpmodule.py:1095] group einsum cost 0.023394107818603516 s
DEBUG 01-13 08:46:24.952756.952756 mlpmodule.py:1103] cpy2cputensor cost 0.0007655620574951172 s
INFO 01-13 08:46:24.972651.972651 client.py:127] Model loaded
DEBUG 01-13 08:46:24.972297.972297 cuda_h.py:19] end wait_experts cost 0.04739046096801758 seconds
DEBUG 01-13 08:46:24.972636.972636 cuda_h.py:10] start gpu_experts
DEBUG 01-13 08:46:24.973502.973502 mlpmodule.py:559] gpu group tensors cost 0.0006046295166015625 s
DEBUG 01-13 08:46:24.974403.974403 mlpmodule.py:592] gpu pad cost 0.0015034675598144531 s
DEBUG 01-13 08:46:24.974783.974783 mlpmodule.py:598] start_w1
DEBUG 01-13 08:46:24.975398.975398 mlpmodule.py:602] start_w3
DEBUG 01-13 08:46:24.975239.975239 mlpmodule.py:608] start_w2
DEBUG 01-13 08:46:24.975206.975206 mlpmodule.py:611] gpu group einsum cost 0.0007660388946533203 s
DEBUG 01-13 08:46:24.977282.977282 mlpmodule.py:683] gpu experts func einsum cost 0.005292177200317383 s
DEBUG 01-13 08:46:24.977060.977060 cuda_h.py:19] end gpu_experts cost 0.0055179595947265625 seconds
DEBUG 01-13 08:46:24.977532.977532 cuda_h.py:10] start cpu_thread_manager_mp_wait
DEBUG 01-13 08:46:24.977150.977150 cuda_h.py:19] end cpu_thread_manager_mp_wait cost 4.029273986816406e-05 seconds
DEBUG 01-13 08:46:24.978881.978881 cuda_h.py:19] end layer_moe_generate_mp_l_4 cost 0.06462216377258301 seconds
DEBUG 01-13 08:46:24.978286.978286 lmp.py:1550] -------------------------------- end prefill layer 3 --------------------------------
DEBUG 01-13 08:46:24.978678.978678 lmp.py:1493] -------------------------------- start prefill layer 4 --------------------------------
DEBUG 01-13 08:46:24.978189.978189 cuda_h.py:10] start start_load_qkvogn_s_weight_l_5
DEBUG 01-13 08:46:24.978468.978468 cuda_h.py:10] start start_load_qkvogn_s_weight_l_5
DEBUG 01-13 08:46:24.978874.978874 cuda_h.py:19] end start_load_qkvogn_s_weight_l_5 cost 2.9087066650390625e-05 seconds
DEBUG 01-13 08:46:24.978478.978478 cuda_h.py:19] end start_load_qkvogn_s_weight_l_5 cost 5.626678466796875e-05 seconds
DEBUG 01-13 08:46:24.978644.978644 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-13 08:46:24.978909.978909 mlpmodule.py:785]  experts func einsum cost 0.058685302734375 s
DEBUG 01-13 08:46:24.978613.978613 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-13 08:46:24.978101.978101 cuda_h.py:19] end experts_func_gpu_einsum_mp cost 0.05936264991760254 seconds
DEBUG 01-13 08:46:24.978291.978291 cuda_h.py:10] start sllm_worker_task
DEBUG 01-13 08:46:24.978911.978911 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-13 08:46:24.978860.978860 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-13 08:46:24.979767.979767 cuda_h.py:19] end allocate_cuda_memory cost 0.0003426074981689453 seconds
DEBUG 01-13 08:46:24.979797.979797 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-13 08:46:24.979043.979043 sllm_store_c.py:27] get device uuid map
DEBUG 01-13 08:46:24.979164.979164 sllm_store_c.py:29] call client load into gpu
DEBUG 01-13 08:46:24.979543.979543 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, c06e3a5f-53a9-40f1-8cb3-cf78a2385189
DEBUG 01-13 08:46:24.979440.979440 client.py:106] call stub.LoadModelAsync
DEBUG 01-13 08:46:24.979289.979289 cuda_h.py:10] start self_attn
INFO 01-13 08:46:24.981766.981766 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, c06e3a5f-53a9-40f1-8cb3-cf78a2385189
DEBUG 01-13 08:46:24.981451.981451 cuda_h.py:19] end load_into_gpu_async cost 0.0018780231475830078 seconds
DEBUG 01-13 08:46:24.981975.981975 cuda_h.py:10] start restore_tensors2
DEBUG 01-13 08:46:24.981654.981654 cuda_h.py:19] end restore_tensors2 cost 7.939338684082031e-05 seconds
DEBUG 01-13 08:46:24.981384.981384 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.002621889114379883 seconds
INFO 01-13 08:46:24.981896.981896 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, c06e3a5f-53a9-40f1-8cb3-cf78a2385189
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-13 08:46:24.982278.982278 cuda_h.py:19] end self_attn cost 0.002937793731689453 seconds
DEBUG 01-13 08:46:24.983560.983560 cuda_h.py:19] end iln_self_attn_paln cost 0.004577159881591797 seconds
DEBUG 01-13 08:46:24.983734.983734 cuda_h.py:10] start layer_moe_generate_mp_l_5
DEBUG 01-13 08:46:24.983112.983112 cuda_h.py:10] start gate
DEBUG 01-13 08:46:24.983784.983784 cuda_h.py:19] end gate cost 0.0006375312805175781 seconds
DEBUG 01-13 08:46:24.983852.983852 cuda_h.py:10] start experts_map_get
DEBUG 01-13 08:46:24.984861.984861 lmp.py:1611] 
DEBUG 01-13 08:46:24.984861.984861 lmp.py:1611] Expert Token Distribution & Device Allocation:
DEBUG 01-13 08:46:24.984187.984187 lmp.py:1612]   Total experts: 64
DEBUG 01-13 08:46:24.984075.984075 lmp.py:1613]   CPU experts: 32 (50%)
DEBUG 01-13 08:46:24.984387.984387 lmp.py:1614]   GPU experts: 32 (50%)
DEBUG 01-13 08:46:24.984791.984791 lmp.py:1615] 
DEBUG 01-13 08:46:24.984791.984791 lmp.py:1615]   Expert ID | Tokens | Device
DEBUG 01-13 08:46:24.984673.984673 lmp.py:1616]   -----------------------------------
DEBUG 01-13 08:46:24.984323.984323 lmp.py:1622]   Expert 14 |     67 | CPU
DEBUG 01-13 08:46:24.984727.984727 lmp.py:1622]   Expert 57 |     71 | CPU
DEBUG 01-13 08:46:24.984655.984655 lmp.py:1622]   Expert 13 |     76 | CPU
DEBUG 01-13 08:46:24.984550.984550 lmp.py:1622]   Expert 26 |     82 | CPU
DEBUG 01-13 08:46:24.984359.984359 lmp.py:1622]   Expert 31 |     87 | CPU
DEBUG 01-13 08:46:24.984287.984287 lmp.py:1622]   Expert 54 |     88 | CPU
DEBUG 01-13 08:46:24.984499.984499 lmp.py:1622]   Expert 45 |     96 | CPU
DEBUG 01-13 08:46:24.984427.984427 lmp.py:1622]   Expert 11 |     97 | CPU
DEBUG 01-13 08:46:24.984355.984355 lmp.py:1622]   Expert 58 |    101 | CPU
DEBUG 01-13 08:46:24.984044.984044 lmp.py:1622]   Expert 30 |    105 | CPU
DEBUG 01-13 08:46:24.984448.984448 lmp.py:1622]   Expert 51 |    110 | CPU
DEBUG 01-13 08:46:24.984853.984853 lmp.py:1622]   Expert 36 |    112 | CPU
DEBUG 01-13 08:46:24.984542.984542 lmp.py:1622]   Expert 10 |    115 | CPU
DEBUG 01-13 08:46:24.984755.984755 lmp.py:1622]   Expert 32 |    117 | CPU
DEBUG 01-13 08:46:24.984921.984921 lmp.py:1622]   Expert  8 |    129 | CPU
DEBUG 01-13 08:46:24.984372.984372 lmp.py:1622]   Expert 20 |    129 | CPU
DEBUG 01-13 08:46:24.984107.984107 lmp.py:1622]   Expert 63 |    138 | CPU
DEBUG 01-13 08:46:24.984843.984843 lmp.py:1622]   Expert 61 |    141 | CPU
DEBUG 01-13 08:46:24.984817.984817 lmp.py:1622]   Expert  4 |    142 | CPU
DEBUG 01-13 08:46:24.984553.984553 lmp.py:1622]   Expert 34 |    142 | CPU
DEBUG 01-13 08:46:24.984527.984527 lmp.py:1622]   Expert 53 |    142 | CPU
DEBUG 01-13 08:46:24.984024.984024 lmp.py:1622]   Expert 47 |    144 | CPU
DEBUG 01-13 08:46:24.984998.984998 lmp.py:1622]   Expert 16 |    149 | CPU
DEBUG 01-13 08:46:24.984972.984972 lmp.py:1622]   Expert 42 |    158 | CPU
DEBUG 01-13 08:46:24.984184.984184 lmp.py:1622]   Expert 60 |    159 | CPU
DEBUG 01-13 08:46:24.984112.984112 lmp.py:1622]   Expert 28 |    160 | CPU
DEBUG 01-13 08:46:24.984563.984563 lmp.py:1622]   Expert 17 |    161 | CPU
DEBUG 01-13 08:46:24.984252.984252 lmp.py:1622]   Expert 29 |    170 | CPU
DEBUG 01-13 08:46:24.984895.984895 lmp.py:1622]   Expert 44 |    172 | CPU
DEBUG 01-13 08:46:24.984823.984823 lmp.py:1622]   Expert 27 |    175 | CPU
DEBUG 01-13 08:46:24.984274.984274 lmp.py:1622]   Expert  7 |    178 | CPU
DEBUG 01-13 08:46:24.984963.984963 lmp.py:1622]   Expert 41 |    179 | CPU
DEBUG 01-13 08:46:24.984653.984653 lmp.py:1622]   Expert 48 |    180 | GPU
DEBUG 01-13 08:46:24.984580.984580 lmp.py:1622]   Expert  9 |    185 | GPU
DEBUG 01-13 08:46:24.984508.984508 lmp.py:1622]   Expert 56 |    185 | GPU
DEBUG 01-13 08:46:24.984197.984197 lmp.py:1622]   Expert  2 |    186 | GPU
DEBUG 01-13 08:46:24.984410.984410 lmp.py:1622]   Expert 15 |    189 | GPU
DEBUG 01-13 08:46:24.984337.984337 lmp.py:1622]   Expert  3 |    194 | GPU
DEBUG 01-13 08:46:24.984272.984272 lmp.py:1622]   Expert 24 |    194 | GPU
DEBUG 01-13 08:46:24.985438.985438 lmp.py:1622]   Expert  0 |    195 | GPU
DEBUG 01-13 08:46:24.985127.985127 lmp.py:1622]   Expert 18 |    201 | GPU
DEBUG 01-13 08:46:24.985817.985817 lmp.py:1622]   Expert 55 |    209 | GPU
DEBUG 01-13 08:46:24.985506.985506 lmp.py:1622]   Expert 40 |    210 | GPU
DEBUG 01-13 08:46:24.985003.985003 lmp.py:1622]   Expert 23 |    214 | GPU
DEBUG 01-13 08:46:24.985216.985216 lmp.py:1622]   Expert 38 |    215 | GPU
DEBUG 01-13 08:46:24.985713.985713 lmp.py:1622]   Expert 22 |    217 | GPU
DEBUG 01-13 08:46:24.985449.985449 lmp.py:1622]   Expert  6 |    223 | GPU
DEBUG 01-13 08:46:24.985707.985707 lmp.py:1622]   Expert 37 |    224 | GPU
DEBUG 01-13 08:46:24.985443.985443 lmp.py:1622]   Expert 46 |    232 | GPU
DEBUG 01-13 08:46:24.985702.985702 lmp.py:1622]   Expert 19 |    245 | GPU
DEBUG 01-13 08:46:24.985437.985437 lmp.py:1622]   Expert 25 |    249 | GPU
DEBUG 01-13 08:46:24.985696.985696 lmp.py:1622]   Expert 39 |    250 | GPU
DEBUG 01-13 08:46:24.985432.985432 lmp.py:1622]   Expert 12 |    261 | GPU
DEBUG 01-13 08:46:24.985883.985883 lmp.py:1622]   Expert 50 |    261 | GPU
DEBUG 01-13 08:46:24.985095.985095 lmp.py:1622]   Expert 62 |    271 | GPU
DEBUG 01-13 08:46:24.985784.985784 lmp.py:1622]   Expert 21 |    281 | GPU
DEBUG 01-13 08:46:24.985235.985235 lmp.py:1622]   Expert 35 |    285 | GPU
DEBUG 01-13 08:46:24.985448.985448 lmp.py:1622]   Expert 49 |    293 | GPU
DEBUG 01-13 08:46:24.985183.985183 lmp.py:1622]   Expert 52 |    299 | GPU
DEBUG 01-13 08:46:24.985681.985681 lmp.py:1622]   Expert 33 |    300 | GPU
DEBUG 01-13 08:46:24.985939.985939 lmp.py:1622]   Expert  1 |    346 | GPU
DEBUG 01-13 08:46:24.985198.985198 lmp.py:1622]   Expert  5 |    382 | GPU
DEBUG 01-13 08:46:24.985934.985934 lmp.py:1622]   Expert 43 |    440 | GPU
DEBUG 01-13 08:46:24.985193.985193 lmp.py:1622]   Expert 59 |    580 | GPU
DEBUG 01-13 08:46:24.985882.985882 lmp.py:1623] 
DEBUG 01-13 08:46:24.985882.985882 lmp.py:1623]   CPU total tokens: 4092 (33.3%)
DEBUG 01-13 08:46:24.985571.985571 lmp.py:1624]   GPU total tokens: 8196 (66.7%)
DEBUG 01-13 08:46:24.985267.985267 cuda_h.py:19] end experts_map_get cost 0.0015072822570800781 seconds
DEBUG 01-13 08:46:24.985925.985925 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-13 08:46:24.985158.985158 lmp.py:1632] 
DEBUG 01-13 08:46:24.985158.985158 lmp.py:1632]   Computing 32 experts on CPU MP...
DEBUG 01-13 08:46:24.985080.985080 cuda_h.py:19] end cpu_experts_submit cost 4.887580871582031e-05 seconds
DEBUG 01-13 08:46:24.985107.985107 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-13 08:46:24.985288.985288 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-13 08:46:24.985247.985247 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-13 08:46:24.987094.987094 cuda_h.py:19] end allocate_cuda_memory cost 0.0015382766723632812 seconds
DEBUG 01-13 08:46:24.987844.987844 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-13 08:46:24.987077.987077 sllm_store_c.py:27] get device uuid map
DEBUG 01-13 08:46:24.987317.987317 sllm_store_c.py:29] call client load into gpu
DEBUG 01-13 08:46:24.988188.988188 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 0d7511d8-ddbe-406c-830e-65bdd2b89f2b
DEBUG 01-13 08:46:24.988777.988777 client.py:106] call stub.LoadModelAsync
DEBUG 01-13 08:46:24.988481.988481 cuda_h.py:10] start experts_func_gpu_einsum_mp
INFO 01-13 08:46:24.989332.989332 client.py:127] Model loaded
DEBUG 01-13 08:46:24.989811.989811 cuda_h.py:10] start restore2model
DEBUG 01-13 08:46:24.989262.989262 cuda_h.py:19] end restore2model cost 0.0005588531494140625 seconds
DEBUG 01-13 08:46:24.989542.989542 cuda_h.py:19] end sllm_worker_task cost 0.011145591735839844 seconds
INFO 01-13 08:46:24.991182.991182 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 0d7511d8-ddbe-406c-830e-65bdd2b89f2b
DEBUG 01-13 08:46:24.991793.991793 cuda_h.py:19] end load_into_gpu_async cost 0.0035789012908935547 seconds
DEBUG 01-13 08:46:24.991019.991019 cuda_h.py:10] start restore_tensors2
DEBUG 01-13 08:46:24.991915.991915 cuda_h.py:19] end restore_tensors2 cost 0.00041222572326660156 seconds
DEBUG 01-13 08:46:24.991182.991182 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.00590205192565918 seconds
DEBUG 01-13 08:46:24.991137.991137 cuda_h.py:10] start restore2model
DEBUG 01-13 08:46:24.994543.994543 cuda_h.py:19] end restore2model cost 0.0026230812072753906 seconds
DEBUG 01-13 08:46:24.994380.994380 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.008694887161254883 seconds
DEBUG 01-13 08:46:24.994242.994242 cuda_h.py:10] start gpu_sexperts
DEBUG 01-13 08:46:24.994980.994980 cuda_h.py:19] end gpu_sexperts cost 0.00026869773864746094 seconds
DEBUG 01-13 08:46:24.994002.994002 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-13 08:46:24.994202.994202 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 1.3828277587890625e-05 seconds
DEBUG 01-13 08:46:24.994468.994468 cuda_h.py:10] start wait_experts
INFO 01-13 08:46:24.994164.994164 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 0d7511d8-ddbe-406c-830e-65bdd2b89f2b
DEBUG 01-13 08:46:24.994403.994403 mlpmodule.py:1006] group tensors cost 0.0053937435150146484 s
DEBUG 01-13 08:46:24.996606.996606 mlpmodule.py:1044] pad cost 0.0017685890197753906 s
DEBUG 01-13 08:46:24.997371.997371 mlpmodule.py:1050] create cpu tensor cost 4.744529724121094e-05 s
DEBUG 01-13 08:46:24.997088.997088 mlpmodule.py:1055] move to cpu cost 3.24249267578125e-05 s
DEBUG 01-13 08:46:25.006662.006662 mlpmodule.py:1069] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-13 08:46:25.006754.006754 mlpmodule.py:1070] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-13 08:46:25.006327.006327 mlpmodule.py:1075] group_w3 first element: 0.0086669921875
WARNING 01-13 08:46:25.006636.006636 mlpmodule.py:1085] start einsum2
DEBUG 01-13 08:46:25.019342.019342 mlpmodule.py:1095] group einsum cost 0.022716999053955078 s
DEBUG 01-13 08:46:25.020843.020843 mlpmodule.py:1103] cpy2cputensor cost 0.0007259845733642578 s
INFO 01-13 08:46:25.042039.042039 client.py:127] Model loaded
DEBUG 01-13 08:46:25.042831.042831 cuda_h.py:19] end wait_experts cost 0.04780697822570801 seconds
DEBUG 01-13 08:46:25.042978.042978 cuda_h.py:10] start gpu_experts
DEBUG 01-13 08:46:25.043546.043546 mlpmodule.py:559] gpu group tensors cost 0.0006377696990966797 s
DEBUG 01-13 08:46:25.045850.045850 mlpmodule.py:592] gpu pad cost 0.002297639846801758 s
DEBUG 01-13 08:46:25.045522.045522 mlpmodule.py:598] start_w1
DEBUG 01-13 08:46:25.046820.046820 mlpmodule.py:785]  experts func einsum cost 0.0568394660949707 s
DEBUG 01-13 08:46:25.046581.046581 mlpmodule.py:602] start_w3
DEBUG 01-13 08:46:25.046049.046049 cuda_h.py:19] end experts_func_gpu_einsum_mp cost 0.05765390396118164 seconds
DEBUG 01-13 08:46:25.046721.046721 mlpmodule.py:608] start_w2
DEBUG 01-13 08:46:25.046138.046138 mlpmodule.py:611] gpu group einsum cost 0.0010128021240234375 s
DEBUG 01-13 08:46:25.049233.049233 mlpmodule.py:683] gpu experts func einsum cost 0.00711512565612793 s
DEBUG 01-13 08:46:25.049177.049177 cuda_h.py:19] end gpu_experts cost 0.007279634475708008 seconds
DEBUG 01-13 08:46:25.050648.050648 cuda_h.py:10] start cpu_thread_manager_mp_wait
DEBUG 01-13 08:46:25.050041.050041 cuda_h.py:19] end cpu_thread_manager_mp_wait cost 3.695487976074219e-05 seconds
DEBUG 01-13 08:46:25.050826.050826 cuda_h.py:19] end layer_moe_generate_mp_l_5 cost 0.06699609756469727 seconds
DEBUG 01-13 08:46:25.050575.050575 lmp.py:1550] -------------------------------- end prefill layer 4 --------------------------------
DEBUG 01-13 08:46:25.050067.050067 lmp.py:1493] -------------------------------- start prefill layer 5 --------------------------------
DEBUG 01-13 08:46:25.050723.050723 cuda_h.py:10] start start_load_qkvogn_s_weight_l_6
DEBUG 01-13 08:46:25.050811.050811 cuda_h.py:10] start start_load_qkvogn_s_weight_l_6
DEBUG 01-13 08:46:25.050170.050170 cuda_h.py:19] end start_load_qkvogn_s_weight_l_6 cost 2.9087066650390625e-05 seconds
DEBUG 01-13 08:46:25.050370.050370 cuda_h.py:19] end start_load_qkvogn_s_weight_l_6 cost 7.414817810058594e-05 seconds
DEBUG 01-13 08:46:25.050565.050565 cuda_h.py:10] start sllm_worker_task
DEBUG 01-13 08:46:25.050421.050421 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-13 08:46:25.050458.050458 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-13 08:46:25.051886.051886 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-13 08:46:25.051106.051106 cuda_h.py:19] end allocate_cuda_memory cost 0.00018668174743652344 seconds
DEBUG 01-13 08:46:25.051686.051686 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-13 08:46:25.051244.051244 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-13 08:46:25.051500.051500 sllm_store_c.py:27] get device uuid map
DEBUG 01-13 08:46:25.051051.051051 sllm_store_c.py:29] call client load into gpu
DEBUG 01-13 08:46:25.051860.051860 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 55970b4a-4682-45b1-9995-901c2232f650
DEBUG 01-13 08:46:25.051950.051950 client.py:106] call stub.LoadModelAsync
DEBUG 01-13 08:46:25.052312.052312 cuda_h.py:10] start self_attn
INFO 01-13 08:46:25.052293.052293 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 55970b4a-4682-45b1-9995-901c2232f650
DEBUG 01-13 08:46:25.052666.052666 cuda_h.py:19] end load_into_gpu_async cost 0.0012116432189941406 seconds
DEBUG 01-13 08:46:25.052853.052853 cuda_h.py:10] start restore_tensors2
DEBUG 01-13 08:46:25.052479.052479 cuda_h.py:19] end restore_tensors2 cost 7.653236389160156e-05 seconds
DEBUG 01-13 08:46:25.052434.052434 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0019385814666748047 seconds
INFO 01-13 08:46:25.052999.052999 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 55970b4a-4682-45b1-9995-901c2232f650
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-13 08:46:25.056479.056479 cuda_h.py:19] end self_attn cost 0.0041201114654541016 seconds
DEBUG 01-13 08:46:25.056419.056419 cuda_h.py:19] end iln_self_attn_paln cost 0.005685091018676758 seconds
DEBUG 01-13 08:46:25.056567.056567 cuda_h.py:10] start layer_moe_generate_mp_l_6
DEBUG 01-13 08:46:25.056390.056390 cuda_h.py:10] start gate
DEBUG 01-13 08:46:25.057965.057965 cuda_h.py:19] end gate cost 0.0007345676422119141 seconds
DEBUG 01-13 08:46:25.057716.057716 cuda_h.py:10] start experts_map_get
DEBUG 01-13 08:46:25.057177.057177 lmp.py:1611] 
DEBUG 01-13 08:46:25.057177.057177 lmp.py:1611] Expert Token Distribution & Device Allocation:
DEBUG 01-13 08:46:25.057364.057364 lmp.py:1612]   Total experts: 64
DEBUG 01-13 08:46:25.057444.057444 lmp.py:1613]   CPU experts: 32 (50%)
DEBUG 01-13 08:46:25.058425.058425 lmp.py:1614]   GPU experts: 32 (50%)
DEBUG 01-13 08:46:25.058783.058783 lmp.py:1615] 
DEBUG 01-13 08:46:25.058783.058783 lmp.py:1615]   Expert ID | Tokens | Device
DEBUG 01-13 08:46:25.058903.058903 lmp.py:1616]   -----------------------------------
DEBUG 01-13 08:46:25.058507.058507 lmp.py:1622]   Expert 34 |     26 | CPU
DEBUG 01-13 08:46:25.058580.058580 lmp.py:1622]   Expert 45 |     62 | CPU
DEBUG 01-13 08:46:25.058223.058223 lmp.py:1622]   Expert 22 |     73 | CPU
DEBUG 01-13 08:46:25.058866.058866 lmp.py:1622]   Expert 57 |     76 | CPU
DEBUG 01-13 08:46:25.058555.058555 lmp.py:1622]   Expert 17 |     97 | CPU
DEBUG 01-13 08:46:25.058960.058960 lmp.py:1622]   Expert  4 |    102 | CPU
DEBUG 01-13 08:46:25.058126.058126 lmp.py:1622]   Expert 15 |    102 | CPU
DEBUG 01-13 08:46:25.058484.058484 lmp.py:1622]   Expert 28 |    105 | CPU
DEBUG 01-13 08:46:25.058319.058319 lmp.py:1622]   Expert 60 |    116 | CPU
DEBUG 01-13 08:46:25.058439.058439 lmp.py:1622]   Expert 32 |    117 | CPU
DEBUG 01-13 08:46:25.058797.058797 lmp.py:1622]   Expert 36 |    122 | CPU
DEBUG 01-13 08:46:25.058440.058440 lmp.py:1622]   Expert 14 |    126 | CPU
DEBUG 01-13 08:46:25.058368.058368 lmp.py:1622]   Expert 52 |    126 | CPU
DEBUG 01-13 08:46:25.058534.058534 lmp.py:1622]   Expert 12 |    129 | CPU
DEBUG 01-13 08:46:25.058223.058223 lmp.py:1622]   Expert 16 |    131 | CPU
DEBUG 01-13 08:46:25.058151.058151 lmp.py:1622]   Expert 25 |    132 | CPU
DEBUG 01-13 08:46:25.058602.058602 lmp.py:1622]   Expert  2 |    138 | CPU
DEBUG 01-13 08:46:25.058530.058530 lmp.py:1622]   Expert  8 |    138 | CPU
DEBUG 01-13 08:46:25.058458.058458 lmp.py:1622]   Expert 35 |    141 | CPU
DEBUG 01-13 08:46:25.058862.058862 lmp.py:1622]   Expert  5 |    143 | CPU
DEBUG 01-13 08:46:25.058743.058743 lmp.py:1622]   Expert 30 |    152 | CPU
DEBUG 01-13 08:46:25.058102.058102 lmp.py:1622]   Expert 61 |    154 | CPU
DEBUG 01-13 08:46:25.058844.058844 lmp.py:1622]   Expert 23 |    158 | CPU
DEBUG 01-13 08:46:25.058202.058202 lmp.py:1622]   Expert 39 |    158 | CPU
DEBUG 01-13 08:46:25.058845.058845 lmp.py:1622]   Expert  0 |    162 | CPU
DEBUG 01-13 08:46:25.058011.058011 lmp.py:1622]   Expert 13 |    165 | CPU
DEBUG 01-13 08:46:25.058701.058701 lmp.py:1622]   Expert 42 |    170 | CPU
DEBUG 01-13 08:46:25.058536.058536 lmp.py:1622]   Expert  3 |    172 | CPU
DEBUG 01-13 08:46:25.058417.058417 lmp.py:1622]   Expert 31 |    174 | CPU
DEBUG 01-13 08:46:25.058299.058299 lmp.py:1622]   Expert 41 |    176 | CPU
DEBUG 01-13 08:46:25.058180.058180 lmp.py:1622]   Expert 44 |    177 | CPU
DEBUG 01-13 08:46:25.058061.058061 lmp.py:1622]   Expert 46 |    177 | CPU
DEBUG 01-13 08:46:25.058373.058373 lmp.py:1622]   Expert  9 |    179 | GPU
DEBUG 01-13 08:46:25.058447.058447 lmp.py:1622]   Expert 43 |    182 | GPU
DEBUG 01-13 08:46:25.058759.058759 lmp.py:1622]   Expert 51 |    188 | GPU
DEBUG 01-13 08:46:25.058117.058117 lmp.py:1622]   Expert 26 |    189 | GPU
DEBUG 01-13 08:46:25.058998.058998 lmp.py:1622]   Expert 18 |    191 | GPU
DEBUG 01-13 08:46:25.058118.058118 lmp.py:1622]   Expert 62 |    192 | GPU
DEBUG 01-13 08:46:25.058238.058238 lmp.py:1622]   Expert 27 |    194 | GPU
DEBUG 01-13 08:46:25.058119.058119 lmp.py:1622]   Expert 50 |    194 | GPU
DEBUG 01-13 08:46:25.058478.058478 lmp.py:1622]   Expert 47 |    196 | GPU
DEBUG 01-13 08:46:25.058597.058597 lmp.py:1622]   Expert 49 |    196 | GPU
DEBUG 01-13 08:46:25.058956.058956 lmp.py:1622]   Expert 11 |    199 | GPU
DEBUG 01-13 08:46:25.058837.058837 lmp.py:1622]   Expert 20 |    205 | GPU
DEBUG 01-13 08:46:25.058195.058195 lmp.py:1622]   Expert 55 |    207 | GPU
DEBUG 01-13 08:46:25.058507.058507 lmp.py:1622]   Expert 19 |    208 | GPU
DEBUG 01-13 08:46:25.058581.058581 lmp.py:1622]   Expert 63 |    210 | GPU
DEBUG 01-13 08:46:25.058893.058893 lmp.py:1622]   Expert 56 |    211 | GPU
DEBUG 01-13 08:46:25.058012.058012 lmp.py:1622]   Expert 38 |    216 | GPU
DEBUG 01-13 08:46:25.058371.058371 lmp.py:1622]   Expert 48 |    223 | GPU
DEBUG 01-13 08:46:25.058014.058014 lmp.py:1622]   Expert  1 |    236 | GPU
DEBUG 01-13 08:46:25.058133.058133 lmp.py:1622]   Expert 10 |    236 | GPU
DEBUG 01-13 08:46:25.059253.059253 lmp.py:1622]   Expert  7 |    242 | GPU
DEBUG 01-13 08:46:25.059135.059135 lmp.py:1622]   Expert 54 |    248 | GPU
DEBUG 01-13 08:46:25.059016.059016 lmp.py:1622]   Expert 21 |    251 | GPU
DEBUG 01-13 08:46:25.059136.059136 lmp.py:1622]   Expert 33 |    258 | GPU
DEBUG 01-13 08:46:25.059971.059971 lmp.py:1622]   Expert 29 |    261 | GPU
DEBUG 01-13 08:46:25.059044.059044 lmp.py:1622]   Expert 40 |    268 | GPU
DEBUG 01-13 08:46:25.059879.059879 lmp.py:1622]   Expert 24 |    270 | GPU
DEBUG 01-13 08:46:25.059191.059191 lmp.py:1622]   Expert 59 |    296 | GPU
DEBUG 01-13 08:46:25.059550.059550 lmp.py:1622]   Expert 37 |    332 | GPU
DEBUG 01-13 08:46:25.059431.059431 lmp.py:1622]   Expert 58 |    370 | GPU
DEBUG 01-13 08:46:25.059312.059312 lmp.py:1622]   Expert  6 |    384 | GPU
DEBUG 01-13 08:46:25.059194.059194 lmp.py:1622]   Expert 53 |    859 | GPU
DEBUG 01-13 08:46:25.059506.059506 lmp.py:1623] 
DEBUG 01-13 08:46:25.059506.059506 lmp.py:1623]   CPU total tokens: 4197 (34.2%)
DEBUG 01-13 08:46:25.059341.059341 lmp.py:1624]   GPU total tokens: 8091 (65.8%)
DEBUG 01-13 08:46:25.059421.059421 cuda_h.py:19] end experts_map_get cost 0.001644134521484375 seconds
DEBUG 01-13 08:46:25.059224.059224 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-13 08:46:25.059649.059649 lmp.py:1632] 
DEBUG 01-13 08:46:25.059649.059649 lmp.py:1632]   Computing 32 experts on CPU MP...
DEBUG 01-13 08:46:25.059294.059294 cuda_h.py:19] end cpu_experts_submit cost 5.054473876953125e-05 seconds
DEBUG 01-13 08:46:25.059513.059513 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-13 08:46:25.059912.059912 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-13 08:46:25.059479.059479 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-13 08:46:25.059773.059773 cuda_h.py:19] end allocate_cuda_memory cost 0.00021529197692871094 seconds
DEBUG 01-13 08:46:25.060186.060186 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-13 08:46:25.060638.060638 sllm_store_c.py:27] get device uuid map
DEBUG 01-13 08:46:25.060567.060567 sllm_store_c.py:29] call client load into gpu
DEBUG 01-13 08:46:25.060462.060462 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 6b469860-de4f-4505-90dd-8a082058387b
DEBUG 01-13 08:46:25.060535.060535 client.py:106] call stub.LoadModelAsync
INFO 01-13 08:46:25.060673.060673 client.py:127] Model loaded
DEBUG 01-13 08:46:25.060163.060163 cuda_h.py:10] start experts_func_gpu_einsum_mp
DEBUG 01-13 08:46:25.060689.060689 cuda_h.py:10] start restore2model
DEBUG 01-13 08:46:25.061531.061531 cuda_h.py:19] end restore2model cost 0.0005650520324707031 seconds
DEBUG 01-13 08:46:25.061526.061526 cuda_h.py:19] end sllm_worker_task cost 0.01076817512512207 seconds
INFO 01-13 08:46:25.061895.061895 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 6b469860-de4f-4505-90dd-8a082058387b
DEBUG 01-13 08:46:25.061335.061335 cuda_h.py:19] end load_into_gpu_async cost 0.001409769058227539 seconds
DEBUG 01-13 08:46:25.061852.061852 cuda_h.py:10] start restore_tensors2
DEBUG 01-13 08:46:25.062953.062953 cuda_h.py:19] end restore_tensors2 cost 0.00039649009704589844 seconds
DEBUG 01-13 08:46:25.062365.062365 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.002837657928466797 seconds
DEBUG 01-13 08:46:25.062658.062658 cuda_h.py:10] start restore2model
DEBUG 01-13 08:46:25.065873.065873 cuda_h.py:19] end restore2model cost 0.002830982208251953 seconds
DEBUG 01-13 08:46:25.065762.065762 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.005850076675415039 seconds
DEBUG 01-13 08:46:25.065227.065227 cuda_h.py:10] start gpu_sexperts
DEBUG 01-13 08:46:25.065874.065874 cuda_h.py:19] end gpu_sexperts cost 0.0003008842468261719 seconds
DEBUG 01-13 08:46:25.065280.065280 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-13 08:46:25.065771.065771 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 1.5497207641601562e-05 seconds
DEBUG 01-13 08:46:25.065136.065136 cuda_h.py:10] start wait_experts
INFO 01-13 08:46:25.065647.065647 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 6b469860-de4f-4505-90dd-8a082058387b
DEBUG 01-13 08:46:25.070523.070523 mlpmodule.py:1006] group tensors cost 0.009347200393676758 s
DEBUG 01-13 08:46:25.072871.072871 mlpmodule.py:1044] pad cost 0.0015347003936767578 s
DEBUG 01-13 08:46:25.072954.072954 mlpmodule.py:1050] create cpu tensor cost 4.124641418457031e-05 s
DEBUG 01-13 08:46:25.073088.073088 mlpmodule.py:1055] move to cpu cost 2.9087066650390625e-05 s
DEBUG 01-13 08:46:25.081964.081964 mlpmodule.py:1069] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-13 08:46:25.082724.082724 mlpmodule.py:1070] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-13 08:46:25.082622.082622 mlpmodule.py:1075] group_w3 first element: 0.03369140625
WARNING 01-13 08:46:25.082898.082898 mlpmodule.py:1085] start einsum2
DEBUG 01-13 08:46:25.096494.096494 mlpmodule.py:1095] group einsum cost 0.02290630340576172 s
DEBUG 01-13 08:46:25.096677.096677 mlpmodule.py:1103] cpy2cputensor cost 0.0007345676422119141 s
INFO 01-13 08:46:25.114021.114021 client.py:127] Model loaded
DEBUG 01-13 08:46:25.114753.114753 cuda_h.py:19] end wait_experts cost 0.04845023155212402 seconds
DEBUG 01-13 08:46:25.114530.114530 cuda_h.py:10] start gpu_experts
DEBUG 01-13 08:46:25.115897.115897 mlpmodule.py:559] gpu group tensors cost 0.0006000995635986328 s
DEBUG 01-13 08:46:25.117308.117308 mlpmodule.py:592] gpu pad cost 0.0019168853759765625 s
DEBUG 01-13 08:46:25.117444.117444 mlpmodule.py:598] start_w1
DEBUG 01-13 08:46:25.117423.117423 mlpmodule.py:602] start_w3
DEBUG 01-13 08:46:25.117097.117097 mlpmodule.py:608] start_w2
DEBUG 01-13 08:46:25.118890.118890 mlpmodule.py:611] gpu group einsum cost 0.0010633468627929688 s
DEBUG 01-13 08:46:25.120941.120941 mlpmodule.py:683] gpu experts func einsum cost 0.005867958068847656 s
DEBUG 01-13 08:46:25.120090.120090 cuda_h.py:19] end gpu_experts cost 0.0060405731201171875 seconds
DEBUG 01-13 08:46:25.120085.120085 cuda_h.py:10] start cpu_thread_manager_mp_wait
DEBUG 01-13 08:46:25.120365.120365 cuda_h.py:19] end cpu_thread_manager_mp_wait cost 3.790855407714844e-05 seconds
DEBUG 01-13 08:46:25.120499.120499 mlpmodule.py:785]  experts func einsum cost 0.05906391143798828 s
DEBUG 01-13 08:46:25.120196.120196 cuda_h.py:19] end layer_moe_generate_mp_l_6 cost 0.06383514404296875 seconds
DEBUG 01-13 08:46:25.120110.120110 lmp.py:1550] -------------------------------- end prefill layer 5 --------------------------------
DEBUG 01-13 08:46:25.120396.120396 lmp.py:1493] -------------------------------- start prefill layer 6 --------------------------------
DEBUG 01-13 08:46:25.120151.120151 cuda_h.py:19] end experts_func_gpu_einsum_mp cost 0.05988645553588867 seconds
DEBUG 01-13 08:46:25.120430.120430 cuda_h.py:10] start start_load_qkvogn_s_weight_l_7
DEBUG 01-13 08:46:25.120564.120564 cuda_h.py:10] start start_load_qkvogn_s_weight_l_7
DEBUG 01-13 08:46:25.120069.120069 cuda_h.py:19] end start_load_qkvogn_s_weight_l_7 cost 3.218650817871094e-05 seconds
DEBUG 01-13 08:46:25.120269.120269 cuda_h.py:19] end start_load_qkvogn_s_weight_l_7 cost 7.772445678710938e-05 seconds
DEBUG 01-13 08:46:25.121627.121627 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-13 08:46:25.121047.121047 cuda_h.py:10] start sllm_worker_task
DEBUG 01-13 08:46:25.121798.121798 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-13 08:46:25.121442.121442 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-13 08:46:25.121086.121086 cuda_h.py:19] end allocate_cuda_memory cost 0.00019502639770507812 seconds
DEBUG 01-13 08:46:25.121778.121778 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-13 08:46:25.121845.121845 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-13 08:46:25.121558.121558 sllm_store_c.py:27] get device uuid map
DEBUG 01-13 08:46:25.121480.121480 sllm_store_c.py:29] call client load into gpu
DEBUG 01-13 08:46:25.121421.121421 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, e3de0a80-07dd-4f69-8f91-4064f329d007
DEBUG 01-13 08:46:25.121722.121722 client.py:106] call stub.LoadModelAsync
DEBUG 01-13 08:46:25.122302.122302 cuda_h.py:10] start self_attn
INFO 01-13 08:46:25.122592.122592 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, e3de0a80-07dd-4f69-8f91-4064f329d007
DEBUG 01-13 08:46:25.122144.122144 cuda_h.py:19] end load_into_gpu_async cost 0.0011000633239746094 seconds
DEBUG 01-13 08:46:25.122416.122416 cuda_h.py:10] start restore_tensors2
DEBUG 01-13 08:46:25.122492.122492 cuda_h.py:19] end restore_tensors2 cost 6.556510925292969e-05 seconds
DEBUG 01-13 08:46:25.122818.122818 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0017361640930175781 seconds
INFO 01-13 08:46:25.122615.122615 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, e3de0a80-07dd-4f69-8f91-4064f329d007
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-13 08:46:25.125279.125279 cuda_h.py:19] end self_attn cost 0.003396272659301758 seconds
DEBUG 01-13 08:46:25.125792.125792 cuda_h.py:19] end iln_self_attn_paln cost 0.004903078079223633 seconds
DEBUG 01-13 08:46:25.125682.125682 cuda_h.py:10] start layer_moe_generate_mp_l_7
DEBUG 01-13 08:46:25.126345.126345 cuda_h.py:10] start gate
DEBUG 01-13 08:46:25.126207.126207 cuda_h.py:19] end gate cost 0.0007781982421875 seconds
DEBUG 01-13 08:46:25.126275.126275 cuda_h.py:10] start experts_map_get
DEBUG 01-13 08:46:25.127145.127145 lmp.py:1611] 
DEBUG 01-13 08:46:25.127145.127145 lmp.py:1611] Expert Token Distribution & Device Allocation:
DEBUG 01-13 08:46:25.127186.127186 lmp.py:1612]   Total experts: 64
DEBUG 01-13 08:46:25.127882.127882 lmp.py:1613]   CPU experts: 32 (50%)
DEBUG 01-13 08:46:25.127956.127956 lmp.py:1614]   GPU experts: 32 (50%)
DEBUG 01-13 08:46:25.127930.127930 lmp.py:1615] 
DEBUG 01-13 08:46:25.127930.127930 lmp.py:1615]   Expert ID | Tokens | Device
DEBUG 01-13 08:46:25.127619.127619 lmp.py:1616]   -----------------------------------
DEBUG 01-13 08:46:25.127030.127030 lmp.py:1622]   Expert  1 |     47 | CPU
DEBUG 01-13 08:46:25.127673.127673 lmp.py:1622]   Expert  7 |     57 | CPU
DEBUG 01-13 08:46:25.127124.127124 lmp.py:1622]   Expert 37 |     74 | CPU
DEBUG 01-13 08:46:25.127529.127529 lmp.py:1622]   Expert 54 |     78 | CPU
DEBUG 01-13 08:46:25.127218.127218 lmp.py:1622]   Expert 18 |     79 | CPU
DEBUG 01-13 08:46:25.127669.127669 lmp.py:1622]   Expert 13 |     89 | CPU
DEBUG 01-13 08:46:25.127358.127358 lmp.py:1622]   Expert  9 |     90 | CPU
DEBUG 01-13 08:46:25.127809.127809 lmp.py:1622]   Expert 17 |     90 | CPU
DEBUG 01-13 08:46:25.127214.127214 lmp.py:1622]   Expert 22 |     97 | CPU
DEBUG 01-13 08:46:25.127618.127618 lmp.py:1622]   Expert 58 |    102 | CPU
DEBUG 01-13 08:46:25.127784.127784 lmp.py:1622]   Expert  0 |    108 | CPU
DEBUG 01-13 08:46:25.127666.127666 lmp.py:1622]   Expert 26 |    118 | CPU
DEBUG 01-13 08:46:25.127355.127355 lmp.py:1622]   Expert 16 |    119 | CPU
DEBUG 01-13 08:46:25.127806.127806 lmp.py:1622]   Expert 10 |    124 | CPU
DEBUG 01-13 08:46:25.127495.127495 lmp.py:1622]   Expert 63 |    128 | CPU
DEBUG 01-13 08:46:25.127946.127946 lmp.py:1622]   Expert 62 |    139 | CPU
DEBUG 01-13 08:46:25.127397.127397 lmp.py:1622]   Expert 43 |    142 | CPU
DEBUG 01-13 08:46:25.127609.127609 lmp.py:1622]   Expert 33 |    144 | CPU
DEBUG 01-13 08:46:25.127822.127822 lmp.py:1622]   Expert 59 |    145 | CPU
DEBUG 01-13 08:46:25.127988.127988 lmp.py:1622]   Expert 28 |    146 | CPU
DEBUG 01-13 08:46:25.127393.127393 lmp.py:1622]   Expert 29 |    155 | CPU
DEBUG 01-13 08:46:25.127559.127559 lmp.py:1622]   Expert  2 |    159 | CPU
DEBUG 01-13 08:46:25.127202.127202 lmp.py:1622]   Expert 51 |    162 | CPU
DEBUG 01-13 08:46:25.127891.127891 lmp.py:1622]   Expert  3 |    164 | CPU
DEBUG 01-13 08:46:25.127103.127103 lmp.py:1622]   Expert 23 |    166 | CPU
DEBUG 01-13 08:46:25.127554.127554 lmp.py:1622]   Expert 55 |    166 | CPU
DEBUG 01-13 08:46:25.127005.127005 lmp.py:1622]   Expert 32 |    167 | CPU
DEBUG 01-13 08:46:25.127456.127456 lmp.py:1622]   Expert 45 |    167 | CPU
DEBUG 01-13 08:46:25.127669.127669 lmp.py:1622]   Expert 53 |    168 | CPU
DEBUG 01-13 08:46:25.127119.127119 lmp.py:1622]   Expert 11 |    170 | CPU
DEBUG 01-13 08:46:25.127809.127809 lmp.py:1622]   Expert 40 |    172 | CPU
DEBUG 01-13 08:46:25.127260.127260 lmp.py:1622]   Expert 14 |    173 | CPU
DEBUG 01-13 08:46:25.127949.127949 lmp.py:1622]   Expert 52 |    177 | GPU
DEBUG 01-13 08:46:25.127354.127354 lmp.py:1622]   Expert 34 |    180 | GPU
DEBUG 01-13 08:46:25.127520.127520 lmp.py:1622]   Expert 42 |    182 | GPU
DEBUG 01-13 08:46:25.127447.127447 lmp.py:1622]   Expert 41 |    184 | GPU
DEBUG 01-13 08:46:25.127852.127852 lmp.py:1622]   Expert 57 |    187 | GPU
DEBUG 01-13 08:46:25.127541.127541 lmp.py:1622]   Expert 21 |    192 | GPU
DEBUG 01-13 08:46:25.127992.127992 lmp.py:1622]   Expert 30 |    203 | GPU
DEBUG 01-13 08:46:25.127205.127205 lmp.py:1622]   Expert 15 |    204 | GPU
DEBUG 01-13 08:46:25.127655.127655 lmp.py:1622]   Expert 35 |    206 | GPU
DEBUG 01-13 08:46:25.127868.127868 lmp.py:1622]   Expert 12 |    217 | GPU
DEBUG 01-13 08:46:25.128842.128842 lmp.py:1622]   Expert  4 |    223 | GPU
DEBUG 01-13 08:46:25.128293.128293 lmp.py:1622]   Expert 49 |    228 | GPU
DEBUG 01-13 08:46:25.128505.128505 lmp.py:1622]   Expert 19 |    230 | GPU
DEBUG 01-13 08:46:25.128956.128956 lmp.py:1622]   Expert 46 |    230 | GPU
DEBUG 01-13 08:46:25.128407.128407 lmp.py:1622]   Expert  8 |    232 | GPU
DEBUG 01-13 08:46:25.128573.128573 lmp.py:1622]   Expert 24 |    232 | GPU
DEBUG 01-13 08:46:25.128501.128501 lmp.py:1622]   Expert 50 |    232 | GPU
DEBUG 01-13 08:46:25.128667.128667 lmp.py:1622]   Expert 44 |    233 | GPU
DEBUG 01-13 08:46:25.128310.128310 lmp.py:1622]   Expert 38 |    237 | GPU
DEBUG 01-13 08:46:25.128999.128999 lmp.py:1622]   Expert  6 |    242 | GPU
DEBUG 01-13 08:46:25.128689.128689 lmp.py:1622]   Expert 47 |    247 | GPU
DEBUG 01-13 08:46:25.128140.128140 lmp.py:1622]   Expert 31 |    252 | GPU
DEBUG 01-13 08:46:25.128590.128590 lmp.py:1622]   Expert 61 |    260 | GPU
DEBUG 01-13 08:46:25.128803.128803 lmp.py:1622]   Expert 39 |    275 | GPU
DEBUG 01-13 08:46:25.128254.128254 lmp.py:1622]   Expert 36 |    300 | GPU
DEBUG 01-13 08:46:25.128705.128705 lmp.py:1622]   Expert  5 |    302 | GPU
DEBUG 01-13 08:46:25.128394.128394 lmp.py:1622]   Expert 27 |    309 | GPU
DEBUG 01-13 08:46:25.128845.128845 lmp.py:1622]   Expert 60 |    329 | GPU
DEBUG 01-13 08:46:25.128534.128534 lmp.py:1622]   Expert 20 |    338 | GPU
DEBUG 01-13 08:46:25.128747.128747 lmp.py:1622]   Expert 48 |    366 | GPU
DEBUG 01-13 08:46:25.128390.128390 lmp.py:1622]   Expert 25 |    401 | GPU
DEBUG 01-13 08:46:25.128317.128317 lmp.py:1622]   Expert 56 |    553 | GPU
DEBUG 01-13 08:46:25.128152.128152 lmp.py:1623] 
DEBUG 01-13 08:46:25.128152.128152 lmp.py:1623]   CPU total tokens: 4105 (33.4%)
DEBUG 01-13 08:46:25.128790.128790 lmp.py:1624]   GPU total tokens: 8183 (66.6%)
DEBUG 01-13 08:46:25.128108.128108 cuda_h.py:19] end experts_map_get cost 0.0015344619750976562 seconds
DEBUG 01-13 08:46:25.128674.128674 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-13 08:46:25.128237.128237 lmp.py:1632] 
DEBUG 01-13 08:46:25.128237.128237 lmp.py:1632]   Computing 32 experts on CPU MP...
DEBUG 01-13 08:46:25.128021.128021 cuda_h.py:19] end cpu_experts_submit cost 4.76837158203125e-05 seconds
DEBUG 01-13 08:46:25.128763.128763 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-13 08:46:25.128731.128731 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-13 08:46:25.128723.128723 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-13 08:46:25.129568.129568 cuda_h.py:19] end allocate_cuda_memory cost 0.0006921291351318359 seconds
DEBUG 01-13 08:46:25.130786.130786 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-13 08:46:25.130883.130883 sllm_store_c.py:27] get device uuid map
DEBUG 01-13 08:46:25.130342.130342 sllm_store_c.py:29] call client load into gpu
DEBUG 01-13 08:46:25.130058.130058 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 03e5927f-898b-4e8e-9e1e-d1d6b50b1d58
DEBUG 01-13 08:46:25.130715.130715 client.py:106] call stub.LoadModelAsync
DEBUG 01-13 08:46:25.130666.130666 cuda_h.py:10] start experts_func_gpu_einsum_mp
INFO 01-13 08:46:25.130606.130606 client.py:127] Model loaded
DEBUG 01-13 08:46:25.130955.130955 cuda_h.py:10] start restore2model
DEBUG 01-13 08:46:25.131866.131866 cuda_h.py:19] end restore2model cost 0.00044989585876464844 seconds
DEBUG 01-13 08:46:25.131510.131510 cuda_h.py:19] end sllm_worker_task cost 0.010187149047851562 seconds
INFO 01-13 08:46:25.131591.131591 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 03e5927f-898b-4e8e-9e1e-d1d6b50b1d58
DEBUG 01-13 08:46:25.131653.131653 cuda_h.py:19] end load_into_gpu_async cost 0.001445770263671875 seconds
DEBUG 01-13 08:46:25.131754.131754 cuda_h.py:10] start restore_tensors2
DEBUG 01-13 08:46:25.132123.132123 cuda_h.py:19] end restore_tensors2 cost 0.0005123615264892578 seconds
DEBUG 01-13 08:46:25.132987.132987 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0036351680755615234 seconds
DEBUG 01-13 08:46:25.132816.132816 cuda_h.py:10] start restore2model
DEBUG 01-13 08:46:25.136846.136846 cuda_h.py:19] end restore2model cost 0.004384517669677734 seconds
DEBUG 01-13 08:46:25.136524.136524 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.008260965347290039 seconds
DEBUG 01-13 08:46:25.136333.136333 cuda_h.py:10] start gpu_sexperts
DEBUG 01-13 08:46:25.137460.137460 cuda_h.py:19] end gpu_sexperts cost 0.00040221214294433594 seconds
DEBUG 01-13 08:46:25.137502.137502 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-13 08:46:25.137260.137260 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.1696090698242188e-05 seconds
DEBUG 01-13 08:46:25.137638.137638 cuda_h.py:10] start wait_experts
INFO 01-13 08:46:25.137971.137971 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 03e5927f-898b-4e8e-9e1e-d1d6b50b1d58
DEBUG 01-13 08:46:25.141226.141226 mlpmodule.py:1006] group tensors cost 0.010287046432495117 s
DEBUG 01-13 08:46:25.143764.143764 mlpmodule.py:1044] pad cost 0.0014922618865966797 s
DEBUG 01-13 08:46:25.143052.143052 mlpmodule.py:1050] create cpu tensor cost 5.5789947509765625e-05 s
DEBUG 01-13 08:46:25.143948.143948 mlpmodule.py:1055] move to cpu cost 3.0040740966796875e-05 s
DEBUG 01-13 08:46:25.151432.151432 mlpmodule.py:1069] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-13 08:46:25.151477.151477 mlpmodule.py:1070] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-13 08:46:25.152613.152613 mlpmodule.py:1075] group_w3 first element: -0.003631591796875
WARNING 01-13 08:46:25.152684.152684 mlpmodule.py:1085] start einsum2
DEBUG 01-13 08:46:25.165685.165685 mlpmodule.py:1095] group einsum cost 0.02213120460510254 s
DEBUG 01-13 08:46:25.166266.166266 mlpmodule.py:1103] cpy2cputensor cost 0.0007138252258300781 s
INFO 01-13 08:46:25.184832.184832 client.py:127] Model loaded
DEBUG 01-13 08:46:25.184988.184988 cuda_h.py:19] end wait_experts cost 0.04719352722167969 seconds
DEBUG 01-13 08:46:25.184652.184652 cuda_h.py:10] start gpu_experts
DEBUG 01-13 08:46:25.185721.185721 mlpmodule.py:559] gpu group tensors cost 0.00058746337890625 s
DEBUG 01-13 08:46:25.187855.187855 mlpmodule.py:592] gpu pad cost 0.0015683174133300781 s
DEBUG 01-13 08:46:25.187753.187753 mlpmodule.py:598] start_w1
DEBUG 01-13 08:46:25.187360.187360 mlpmodule.py:602] start_w3
DEBUG 01-13 08:46:25.187996.187996 mlpmodule.py:608] start_w2
DEBUG 01-13 08:46:25.187532.187532 mlpmodule.py:611] gpu group einsum cost 0.0007131099700927734 s
DEBUG 01-13 08:46:25.188916.188916 mlpmodule.py:785]  experts func einsum cost 0.05761885643005371 s
DEBUG 01-13 08:46:25.189062.189062 cuda_h.py:19] end experts_func_gpu_einsum_mp cost 0.05842947959899902 seconds
DEBUG 01-13 08:46:25.190474.190474 mlpmodule.py:683] gpu experts func einsum cost 0.005288362503051758 s
DEBUG 01-13 08:46:25.190087.190087 cuda_h.py:19] end gpu_experts cost 0.005455493927001953 seconds
DEBUG 01-13 08:46:25.190889.190889 cuda_h.py:10] start cpu_thread_manager_mp_wait
DEBUG 01-13 08:46:25.190183.190183 cuda_h.py:19] end cpu_thread_manager_mp_wait cost 3.743171691894531e-05 seconds
DEBUG 01-13 08:46:25.190192.190192 cuda_h.py:19] end layer_moe_generate_mp_l_7 cost 0.06446266174316406 seconds
DEBUG 01-13 08:46:25.190498.190498 lmp.py:1550] -------------------------------- end prefill layer 6 --------------------------------
DEBUG 01-13 08:46:25.190592.190592 lmp.py:1493] -------------------------------- start prefill layer 7 --------------------------------
DEBUG 01-13 08:46:25.190387.190387 cuda_h.py:10] start start_load_qkvogn_s_weight_l_8
DEBUG 01-13 08:46:25.190620.190620 cuda_h.py:10] start start_load_qkvogn_s_weight_l_8
DEBUG 01-13 08:46:25.190172.190172 cuda_h.py:19] end start_load_qkvogn_s_weight_l_8 cost 3.075599670410156e-05 seconds
DEBUG 01-13 08:46:25.190464.190464 cuda_h.py:19] end start_load_qkvogn_s_weight_l_8 cost 7.367134094238281e-05 seconds
DEBUG 01-13 08:46:25.190869.190869 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-13 08:46:25.190964.190964 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-13 08:46:25.191927.191927 cuda_h.py:10] start sllm_worker_task
DEBUG 01-13 08:46:25.191023.191023 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-13 08:46:25.191495.191495 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-13 08:46:25.191340.191340 cuda_h.py:19] end allocate_cuda_memory cost 0.0002605915069580078 seconds
DEBUG 01-13 08:46:25.191323.191323 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-13 08:46:25.191954.191954 sllm_store_c.py:27] get device uuid map
DEBUG 01-13 08:46:25.191943.191943 sllm_store_c.py:29] call client load into gpu
DEBUG 01-13 08:46:25.191514.191514 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, e4afc7a9-4a3a-487c-b7f3-00b94e30d7f2
DEBUG 01-13 08:46:25.191888.191888 client.py:106] call stub.LoadModelAsync
DEBUG 01-13 08:46:25.192054.192054 cuda_h.py:10] start self_attn
INFO 01-13 08:46:25.192658.192658 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, e4afc7a9-4a3a-487c-b7f3-00b94e30d7f2
DEBUG 01-13 08:46:25.193204.193204 cuda_h.py:19] end load_into_gpu_async cost 0.001340627670288086 seconds
DEBUG 01-13 08:46:25.193775.193775 cuda_h.py:10] start restore_tensors2
DEBUG 01-13 08:46:25.193216.193216 cuda_h.py:19] end restore_tensors2 cost 7.82012939453125e-05 seconds
DEBUG 01-13 08:46:25.193059.193059 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0020177364349365234 seconds
INFO 01-13 08:46:25.193624.193624 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, e4afc7a9-4a3a-487c-b7f3-00b94e30d7f2
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-13 08:46:25.195135.195135 cuda_h.py:19] end self_attn cost 0.003329753875732422 seconds
DEBUG 01-13 08:46:25.195834.195834 cuda_h.py:19] end iln_self_attn_paln cost 0.004861593246459961 seconds
DEBUG 01-13 08:46:25.195577.195577 cuda_h.py:10] start layer_moe_generate_mp_l_8
DEBUG 01-13 08:46:25.195241.195241 cuda_h.py:10] start gate
DEBUG 01-13 08:46:25.196019.196019 cuda_h.py:19] end gate cost 0.000644683837890625 seconds
DEBUG 01-13 08:46:25.196279.196279 cuda_h.py:10] start experts_map_get
DEBUG 01-13 08:46:25.196633.196633 lmp.py:1611] 
DEBUG 01-13 08:46:25.196633.196633 lmp.py:1611] Expert Token Distribution & Device Allocation:
DEBUG 01-13 08:46:25.196819.196819 lmp.py:1612]   Total experts: 64
DEBUG 01-13 08:46:25.196138.196138 lmp.py:1613]   CPU experts: 32 (50%)
DEBUG 01-13 08:46:25.196357.196357 lmp.py:1614]   GPU experts: 32 (50%)
DEBUG 01-13 08:46:25.197477.197477 lmp.py:1615] 
DEBUG 01-13 08:46:25.197477.197477 lmp.py:1615]   Expert ID | Tokens | Device
DEBUG 01-13 08:46:25.197312.197312 lmp.py:1616]   -----------------------------------
DEBUG 01-13 08:46:25.197916.197916 lmp.py:1622]   Expert 50 |     48 | CPU
DEBUG 01-13 08:46:25.197512.197512 lmp.py:1622]   Expert  3 |     52 | CPU
DEBUG 01-13 08:46:25.197917.197917 lmp.py:1622]   Expert 46 |     59 | CPU
DEBUG 01-13 08:46:25.197083.197083 lmp.py:1622]   Expert  1 |     81 | CPU
DEBUG 01-13 08:46:25.197726.197726 lmp.py:1622]   Expert  4 |     85 | CPU
DEBUG 01-13 08:46:25.197892.197892 lmp.py:1622]   Expert 29 |     88 | CPU
DEBUG 01-13 08:46:25.197297.197297 lmp.py:1622]   Expert 15 |     96 | CPU
DEBUG 01-13 08:46:25.197224.197224 lmp.py:1622]   Expert 40 |     98 | CPU
DEBUG 01-13 08:46:25.197589.197589 lmp.py:1622]   Expert  8 |    107 | CPU
DEBUG 01-13 08:46:25.197471.197471 lmp.py:1622]   Expert 41 |    114 | CPU
DEBUG 01-13 08:46:25.197398.197398 lmp.py:1622]   Expert 28 |    116 | CPU
DEBUG 01-13 08:46:25.197565.197565 lmp.py:1622]   Expert  6 |    127 | CPU
DEBUG 01-13 08:46:25.197539.197539 lmp.py:1622]   Expert 48 |    128 | CPU
DEBUG 01-13 08:46:25.197513.197513 lmp.py:1622]   Expert 16 |    130 | CPU
DEBUG 01-13 08:46:25.197010.197010 lmp.py:1622]   Expert 27 |    132 | CPU
DEBUG 01-13 08:46:25.197222.197222 lmp.py:1622]   Expert 13 |    133 | CPU
DEBUG 01-13 08:46:25.197720.197720 lmp.py:1622]   Expert 51 |    135 | CPU
DEBUG 01-13 08:46:25.197455.197455 lmp.py:1622]   Expert 60 |    135 | CPU
DEBUG 01-13 08:46:25.197714.197714 lmp.py:1622]   Expert 54 |    137 | CPU
DEBUG 01-13 08:46:25.197926.197926 lmp.py:1622]   Expert  7 |    139 | CPU
DEBUG 01-13 08:46:25.197424.197424 lmp.py:1622]   Expert 14 |    139 | CPU
DEBUG 01-13 08:46:25.197636.197636 lmp.py:1622]   Expert 18 |    141 | CPU
DEBUG 01-13 08:46:25.197325.197325 lmp.py:1622]   Expert 39 |    142 | CPU
DEBUG 01-13 08:46:25.197015.197015 lmp.py:1622]   Expert 52 |    145 | CPU
DEBUG 01-13 08:46:25.197419.197419 lmp.py:1622]   Expert 55 |    147 | CPU
DEBUG 01-13 08:46:25.197870.197870 lmp.py:1622]   Expert 20 |    148 | CPU
DEBUG 01-13 08:46:25.197321.197321 lmp.py:1622]   Expert 56 |    150 | CPU
DEBUG 01-13 08:46:25.197295.197295 lmp.py:1622]   Expert 43 |    151 | CPU
DEBUG 01-13 08:46:25.197031.197031 lmp.py:1622]   Expert 36 |    152 | CPU
DEBUG 01-13 08:46:25.197766.197766 lmp.py:1622]   Expert 10 |    156 | CPU
DEBUG 01-13 08:46:25.197502.197502 lmp.py:1622]   Expert  5 |    157 | CPU
DEBUG 01-13 08:46:25.197999.197999 lmp.py:1622]   Expert 45 |    160 | CPU
DEBUG 01-13 08:46:25.197735.197735 lmp.py:1622]   Expert 11 |    164 | GPU
DEBUG 01-13 08:46:25.197199.197199 lmp.py:1622]   Expert 62 |    170 | GPU
DEBUG 01-13 08:46:25.197650.197650 lmp.py:1622]   Expert 33 |    178 | GPU
DEBUG 01-13 08:46:25.197863.197863 lmp.py:1622]   Expert 57 |    178 | GPU
DEBUG 01-13 08:46:25.197552.197552 lmp.py:1622]   Expert 44 |    179 | GPU
DEBUG 01-13 08:46:25.197764.197764 lmp.py:1622]   Expert 58 |    181 | GPU
DEBUG 01-13 08:46:25.197023.197023 lmp.py:1622]   Expert 53 |    182 | GPU
DEBUG 01-13 08:46:25.197520.197520 lmp.py:1622]   Expert 25 |    184 | GPU
DEBUG 01-13 08:46:25.197779.197779 lmp.py:1622]   Expert  2 |    186 | GPU
DEBUG 01-13 08:46:25.197038.197038 lmp.py:1622]   Expert 32 |    188 | GPU
DEBUG 01-13 08:46:25.197297.197297 lmp.py:1622]   Expert 31 |    196 | GPU
DEBUG 01-13 08:46:25.197556.197556 lmp.py:1622]   Expert 35 |    196 | GPU
DEBUG 01-13 08:46:25.197814.197814 lmp.py:1622]   Expert 63 |    197 | GPU
DEBUG 01-13 08:46:25.197027.197027 lmp.py:1622]   Expert 49 |    201 | GPU
DEBUG 01-13 08:46:25.197239.197239 lmp.py:1622]   Expert 21 |    205 | GPU
DEBUG 01-13 08:46:25.197929.197929 lmp.py:1622]   Expert 17 |    207 | GPU
DEBUG 01-13 08:46:25.197141.197141 lmp.py:1622]   Expert 42 |    211 | GPU
DEBUG 01-13 08:46:25.197353.197353 lmp.py:1622]   Expert 34 |    213 | GPU
DEBUG 01-13 08:46:25.197851.197851 lmp.py:1622]   Expert 37 |    230 | GPU
DEBUG 01-13 08:46:25.197871.197871 lmp.py:1622]   Expert 59 |    232 | GPU
DEBUG 01-13 08:46:25.197130.197130 lmp.py:1622]   Expert 22 |    233 | GPU
DEBUG 01-13 08:46:25.197865.197865 lmp.py:1622]   Expert  0 |    244 | GPU
DEBUG 01-13 08:46:25.197886.197886 lmp.py:1622]   Expert 19 |    261 | GPU
DEBUG 01-13 08:46:25.197145.197145 lmp.py:1622]   Expert 24 |    283 | GPU
DEBUG 01-13 08:46:25.197165.197165 lmp.py:1622]   Expert 61 |    284 | GPU
DEBUG 01-13 08:46:25.197424.197424 lmp.py:1622]   Expert 30 |    301 | GPU
DEBUG 01-13 08:46:25.198159.198159 lmp.py:1622]   Expert 47 |    319 | GPU
DEBUG 01-13 08:46:25.198372.198372 lmp.py:1622]   Expert 38 |    368 | GPU
DEBUG 01-13 08:46:25.198346.198346 lmp.py:1622]   Expert 26 |    371 | GPU
DEBUG 01-13 08:46:25.198725.198725 lmp.py:1622]   Expert 12 |    429 | GPU
DEBUG 01-13 08:46:25.198891.198891 lmp.py:1622]   Expert  9 |    675 | GPU
DEBUG 01-13 08:46:25.198388.198388 lmp.py:1622]   Expert 23 |    714 | GPU
DEBUG 01-13 08:46:25.198839.198839 lmp.py:1623] 
DEBUG 01-13 08:46:25.198839.198839 lmp.py:1623]   CPU total tokens: 3928 (32.0%)
DEBUG 01-13 08:46:25.198528.198528 lmp.py:1624]   GPU total tokens: 8360 (68.0%)
DEBUG 01-13 08:46:25.198747.198747 cuda_h.py:19] end experts_map_get cost 0.0015106201171875 seconds
DEBUG 01-13 08:46:25.198213.198213 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-13 08:46:25.198823.198823 lmp.py:1632] 
DEBUG 01-13 08:46:25.198823.198823 lmp.py:1632]   Computing 32 experts on CPU MP...
DEBUG 01-13 08:46:25.198130.198130 cuda_h.py:19] end cpu_experts_submit cost 4.982948303222656e-05 seconds
DEBUG 01-13 08:46:25.198110.198110 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-13 08:46:25.198291.198291 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-13 08:46:25.198130.198130 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-13 08:46:25.199143.199143 cuda_h.py:19] end allocate_cuda_memory cost 0.0011320114135742188 seconds
DEBUG 01-13 08:46:25.199562.199562 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-13 08:46:25.199556.199556 sllm_store_c.py:27] get device uuid map
DEBUG 01-13 08:46:25.199101.199101 sllm_store_c.py:29] call client load into gpu
DEBUG 01-13 08:46:25.199897.199897 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 72d79c9d-9014-45f4-ad06-ca0ba427aa77
DEBUG 01-13 08:46:25.200625.200625 client.py:106] call stub.LoadModelAsync
INFO 01-13 08:46:25.200280.200280 client.py:127] Model loaded
DEBUG 01-13 08:46:25.200872.200872 cuda_h.py:10] start restore2model
DEBUG 01-13 08:46:25.201333.201333 cuda_h.py:10] start experts_func_gpu_einsum_mp
DEBUG 01-13 08:46:25.201068.201068 cuda_h.py:19] end restore2model cost 0.0006334781646728516 seconds
INFO 01-13 08:46:25.201303.201303 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 72d79c9d-9014-45f4-ad06-ca0ba427aa77
DEBUG 01-13 08:46:25.201174.201174 cuda_h.py:19] end sllm_worker_task cost 0.010434389114379883 seconds
DEBUG 01-13 08:46:25.201090.201090 cuda_h.py:19] end load_into_gpu_async cost 0.0018970966339111328 seconds
DEBUG 01-13 08:46:25.201907.201907 cuda_h.py:10] start restore_tensors2
DEBUG 01-13 08:46:25.202776.202776 cuda_h.py:19] end restore_tensors2 cost 0.0004010200500488281 seconds
DEBUG 01-13 08:46:25.202288.202288 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.003836393356323242 seconds
DEBUG 01-13 08:46:25.202005.202005 cuda_h.py:10] start restore2model
DEBUG 01-13 08:46:25.204941.204941 cuda_h.py:19] end restore2model cost 0.0026259422302246094 seconds
DEBUG 01-13 08:46:25.205698.205698 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.006661415100097656 seconds
DEBUG 01-13 08:46:25.205732.205732 cuda_h.py:10] start gpu_sexperts
DEBUG 01-13 08:46:25.205829.205829 cuda_h.py:19] end gpu_sexperts cost 0.0002789497375488281 seconds
DEBUG 01-13 08:46:25.205612.205612 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-13 08:46:25.205104.205104 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 1.6450881958007812e-05 seconds
DEBUG 01-13 08:46:25.205800.205800 cuda_h.py:10] start wait_experts
INFO 01-13 08:46:25.205165.205165 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 72d79c9d-9014-45f4-ad06-ca0ba427aa77
DEBUG 01-13 08:46:25.206297.206297 mlpmodule.py:1006] group tensors cost 0.0050313472747802734 s
DEBUG 01-13 08:46:25.209959.209959 mlpmodule.py:1044] pad cost 0.0019948482513427734 s
DEBUG 01-13 08:46:25.209831.209831 mlpmodule.py:1050] create cpu tensor cost 4.839897155761719e-05 s
DEBUG 01-13 08:46:25.209416.209416 mlpmodule.py:1055] move to cpu cost 3.4809112548828125e-05 s
DEBUG 01-13 08:46:25.218689.218689 mlpmodule.py:1069] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-13 08:46:25.218146.218146 mlpmodule.py:1070] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-13 08:46:25.218196.218196 mlpmodule.py:1075] group_w3 first element: 0.01263427734375
WARNING 01-13 08:46:25.218699.218699 mlpmodule.py:1085] start einsum2
DEBUG 01-13 08:46:25.235664.235664 mlpmodule.py:1095] group einsum cost 0.02629256248474121 s
DEBUG 01-13 08:46:25.236791.236791 mlpmodule.py:1103] cpy2cputensor cost 0.0006244182586669922 s
INFO 01-13 08:46:25.252050.252050 client.py:127] Model loaded
DEBUG 01-13 08:46:25.253463.253463 cuda_h.py:19] end wait_experts cost 0.047614097595214844 seconds
DEBUG 01-13 08:46:25.253876.253876 cuda_h.py:10] start gpu_experts
DEBUG 01-13 08:46:25.254727.254727 mlpmodule.py:559] gpu group tensors cost 0.0008518695831298828 s
DEBUG 01-13 08:46:25.256308.256308 mlpmodule.py:592] gpu pad cost 0.0023369789123535156 s
DEBUG 01-13 08:46:25.256808.256808 mlpmodule.py:598] start_w1
DEBUG 01-13 08:46:25.257458.257458 mlpmodule.py:602] start_w3
DEBUG 01-13 08:46:25.257048.257048 mlpmodule.py:608] start_w2
DEBUG 01-13 08:46:25.257910.257910 mlpmodule.py:611] gpu group einsum cost 0.0008482933044433594 s
DEBUG 01-13 08:46:25.259184.259184 mlpmodule.py:785]  experts func einsum cost 0.05763745307922363 s
DEBUG 01-13 08:46:25.259287.259287 cuda_h.py:19] end experts_func_gpu_einsum_mp cost 0.05849337577819824 seconds
DEBUG 01-13 08:46:25.260721.260721 mlpmodule.py:683] gpu experts func einsum cost 0.0074079036712646484 s
DEBUG 01-13 08:46:25.260043.260043 cuda_h.py:19] end gpu_experts cost 0.007668972015380859 seconds
DEBUG 01-13 08:46:25.261574.261574 cuda_h.py:10] start cpu_thread_manager_mp_wait
DEBUG 01-13 08:46:25.261259.261259 cuda_h.py:19] end cpu_thread_manager_mp_wait cost 4.458427429199219e-05 seconds
DEBUG 01-13 08:46:25.261077.261077 cuda_h.py:19] end layer_moe_generate_mp_l_8 cost 0.06532859802246094 seconds
DEBUG 01-13 08:46:25.261676.261676 lmp.py:1550] -------------------------------- end prefill layer 7 --------------------------------
DEBUG 01-13 08:46:25.261598.261598 lmp.py:1493] -------------------------------- start prefill layer 8 --------------------------------
DEBUG 01-13 08:46:25.261791.261791 cuda_h.py:10] start start_load_qkvogn_s_weight_l_9
DEBUG 01-13 08:46:25.261984.261984 cuda_h.py:10] start start_load_qkvogn_s_weight_l_9
DEBUG 01-13 08:46:25.261126.261126 cuda_h.py:19] end start_load_qkvogn_s_weight_l_9 cost 3.8623809814453125e-05 seconds
DEBUG 01-13 08:46:25.261636.261636 cuda_h.py:19] end start_load_qkvogn_s_weight_l_9 cost 6.842613220214844e-05 seconds
DEBUG 01-13 08:46:25.261995.261995 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-13 08:46:25.261090.261090 cuda_h.py:10] start sllm_worker_task
DEBUG 01-13 08:46:25.261651.261651 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-13 08:46:25.261665.261665 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-13 08:46:25.262325.262325 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-13 08:46:25.262639.262639 cuda_h.py:19] end allocate_cuda_memory cost 0.0002205371856689453 seconds
DEBUG 01-13 08:46:25.262861.262861 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-13 08:46:25.262299.262299 sllm_store_c.py:27] get device uuid map
DEBUG 01-13 08:46:25.262897.262897 sllm_store_c.py:29] call client load into gpu
DEBUG 01-13 08:46:25.262706.262706 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, a2e807a5-fc72-447a-81b3-cf3e790b1eda
DEBUG 01-13 08:46:25.262849.262849 client.py:106] call stub.LoadModelAsync
DEBUG 01-13 08:46:25.263125.263125 cuda_h.py:10] start self_attn
INFO 01-13 08:46:25.263982.263982 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, a2e807a5-fc72-447a-81b3-cf3e790b1eda
DEBUG 01-13 08:46:25.263640.263640 cuda_h.py:19] end load_into_gpu_async cost 0.0012679100036621094 seconds
DEBUG 01-13 08:46:25.263065.263065 cuda_h.py:10] start restore_tensors2
DEBUG 01-13 08:46:25.263267.263267 cuda_h.py:19] end restore_tensors2 cost 7.867813110351562e-05 seconds
DEBUG 01-13 08:46:25.263388.263388 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.001895904541015625 seconds
INFO 01-13 08:46:25.264802.264802 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, a2e807a5-fc72-447a-81b3-cf3e790b1eda
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-13 08:46:25.267493.267493 cuda_h.py:19] end self_attn cost 0.0042040348052978516 seconds
DEBUG 01-13 08:46:25.267526.267526 cuda_h.py:19] end iln_self_attn_paln cost 0.005938291549682617 seconds
DEBUG 01-13 08:46:25.267760.267760 cuda_h.py:10] start layer_moe_generate_mp_l_9
DEBUG 01-13 08:46:25.267828.267828 cuda_h.py:10] start gate
DEBUG 01-13 08:46:25.268306.268306 cuda_h.py:19] end gate cost 0.0007922649383544922 seconds
DEBUG 01-13 08:46:25.268481.268481 cuda_h.py:10] start experts_map_get
DEBUG 01-13 08:46:25.269729.269729 lmp.py:1611] 
DEBUG 01-13 08:46:25.269729.269729 lmp.py:1611] Expert Token Distribution & Device Allocation:
DEBUG 01-13 08:46:25.269638.269638 lmp.py:1612]   Total experts: 64
DEBUG 01-13 08:46:25.269924.269924 lmp.py:1613]   CPU experts: 32 (50%)
DEBUG 01-13 08:46:25.269342.269342 lmp.py:1614]   GPU experts: 32 (50%)
DEBUG 01-13 08:46:25.269660.269660 lmp.py:1615] 
DEBUG 01-13 08:46:25.269660.269660 lmp.py:1615]   Expert ID | Tokens | Device
DEBUG 01-13 08:46:25.269171.269171 lmp.py:1616]   -----------------------------------
DEBUG 01-13 08:46:25.269205.269205 lmp.py:1622]   Expert 38 |     14 | CPU
DEBUG 01-13 08:46:25.269802.269802 lmp.py:1622]   Expert 39 |     66 | CPU
DEBUG 01-13 08:46:25.269683.269683 lmp.py:1622]   Expert  7 |     75 | CPU
DEBUG 01-13 08:46:25.269326.269326 lmp.py:1622]   Expert 30 |     75 | CPU
DEBUG 01-13 08:46:25.269969.269969 lmp.py:1622]   Expert 24 |     88 | CPU
DEBUG 01-13 08:46:25.269851.269851 lmp.py:1622]   Expert 27 |     92 | CPU
DEBUG 01-13 08:46:25.269494.269494 lmp.py:1622]   Expert 17 |     96 | CPU
DEBUG 01-13 08:46:25.269051.269051 lmp.py:1622]   Expert 32 |     96 | CPU
DEBUG 01-13 08:46:25.269323.269323 lmp.py:1622]   Expert 14 |     98 | CPU
DEBUG 01-13 08:46:25.269357.269357 lmp.py:1622]   Expert 36 |     99 | CPU
DEBUG 01-13 08:46:25.269928.269928 lmp.py:1622]   Expert 16 |    101 | CPU
DEBUG 01-13 08:46:25.269531.269531 lmp.py:1622]   Expert 40 |    106 | CPU
DEBUG 01-13 08:46:25.269466.269466 lmp.py:1622]   Expert 18 |    113 | CPU
DEBUG 01-13 08:46:25.269400.269400 lmp.py:1622]   Expert 12 |    115 | CPU
DEBUG 01-13 08:46:25.269566.269566 lmp.py:1622]   Expert 48 |    117 | CPU
DEBUG 01-13 08:46:25.269878.269878 lmp.py:1622]   Expert  1 |    120 | CPU
DEBUG 01-13 08:46:25.269574.269574 lmp.py:1622]   Expert  6 |    129 | CPU
DEBUG 01-13 08:46:25.269469.269469 lmp.py:1622]   Expert 42 |    133 | CPU
DEBUG 01-13 08:46:25.269503.269503 lmp.py:1622]   Expert 59 |    135 | CPU
DEBUG 01-13 08:46:25.269299.269299 lmp.py:1622]   Expert  0 |    145 | CPU
DEBUG 01-13 08:46:25.269617.269617 lmp.py:1622]   Expert 22 |    146 | CPU
DEBUG 01-13 08:46:25.269360.269360 lmp.py:1622]   Expert 53 |    150 | CPU
DEBUG 01-13 08:46:25.269241.269241 lmp.py:1622]   Expert 51 |    153 | CPU
DEBUG 01-13 08:46:25.269361.269361 lmp.py:1622]   Expert  8 |    160 | CPU
DEBUG 01-13 08:46:25.269242.269242 lmp.py:1622]   Expert 15 |    163 | CPU
DEBUG 01-13 08:46:25.269885.269885 lmp.py:1622]   Expert 60 |    164 | CPU
DEBUG 01-13 08:46:25.269244.269244 lmp.py:1622]   Expert 44 |    167 | CPU
DEBUG 01-13 08:46:25.269986.269986 lmp.py:1622]   Expert 29 |    173 | CPU
DEBUG 01-13 08:46:25.269404.269404 lmp.py:1622]   Expert 54 |    176 | CPU
DEBUG 01-13 08:46:25.270200.270200 lmp.py:1622]   Expert 35 |    177 | CPU
DEBUG 01-13 08:46:25.270757.270757 lmp.py:1622]   Expert 34 |    178 | CPU
DEBUG 01-13 08:46:25.270599.270599 lmp.py:1622]   Expert 33 |    180 | CPU
DEBUG 01-13 08:46:25.270341.270341 lmp.py:1622]   Expert 19 |    183 | GPU
DEBUG 01-13 08:46:25.270984.270984 lmp.py:1622]   Expert  3 |    189 | GPU
DEBUG 01-13 08:46:25.270104.270104 lmp.py:1622]   Expert 47 |    189 | GPU
DEBUG 01-13 08:46:25.270224.270224 lmp.py:1622]   Expert  9 |    193 | GPU
DEBUG 01-13 08:46:25.270105.270105 lmp.py:1622]   Expert 56 |    198 | GPU
DEBUG 01-13 08:46:25.270748.270748 lmp.py:1622]   Expert 20 |    199 | GPU
DEBUG 01-13 08:46:25.270537.270537 lmp.py:1622]   Expert 49 |    200 | GPU
DEBUG 01-13 08:46:25.270147.270147 lmp.py:1622]   Expert 46 |    201 | GPU
DEBUG 01-13 08:46:25.270704.270704 lmp.py:1622]   Expert 21 |    202 | GPU
DEBUG 01-13 08:46:25.270261.270261 lmp.py:1622]   Expert 45 |    203 | GPU
DEBUG 01-13 08:46:25.270342.270342 lmp.py:1622]   Expert 28 |    205 | GPU
DEBUG 01-13 08:46:25.270799.270799 lmp.py:1622]   Expert  2 |    220 | GPU
DEBUG 01-13 08:46:25.270442.270442 lmp.py:1622]   Expert 57 |    220 | GPU
DEBUG 01-13 08:46:25.270085.270085 lmp.py:1622]   Expert 43 |    223 | GPU
DEBUG 01-13 08:46:25.270443.270443 lmp.py:1622]   Expert  4 |    226 | GPU
DEBUG 01-13 08:46:25.270848.270848 lmp.py:1622]   Expert 13 |    232 | GPU
DEBUG 01-13 08:46:25.270491.270491 lmp.py:1622]   Expert 41 |    234 | GPU
DEBUG 01-13 08:46:25.270134.270134 lmp.py:1622]   Expert 10 |    242 | GPU
DEBUG 01-13 08:46:25.270022.270022 lmp.py:1622]   Expert 50 |    244 | GPU
DEBUG 01-13 08:46:25.270063.270063 lmp.py:1622]   Expert 26 |    249 | GPU
DEBUG 01-13 08:46:25.270574.270574 lmp.py:1622]   Expert 37 |    260 | GPU
DEBUG 01-13 08:46:25.270369.270369 lmp.py:1622]   Expert 63 |    261 | GPU
DEBUG 01-13 08:46:25.270231.270231 lmp.py:1622]   Expert 61 |    269 | GPU
DEBUG 01-13 08:46:25.270590.270590 lmp.py:1622]   Expert 31 |    271 | GPU
DEBUG 01-13 08:46:25.270948.270948 lmp.py:1622]   Expert 52 |    310 | GPU
DEBUG 01-13 08:46:25.270544.270544 lmp.py:1622]   Expert 58 |    322 | GPU
DEBUG 01-13 08:46:25.270664.270664 lmp.py:1622]   Expert 62 |    324 | GPU
DEBUG 01-13 08:46:25.270022.270022 lmp.py:1622]   Expert 55 |    345 | GPU
DEBUG 01-13 08:46:25.270381.270381 lmp.py:1622]   Expert 11 |    370 | GPU
DEBUG 01-13 08:46:25.270739.270739 lmp.py:1622]   Expert 23 |    386 | GPU
DEBUG 01-13 08:46:25.270859.270859 lmp.py:1622]   Expert 25 |    397 | GPU
DEBUG 01-13 08:46:25.270661.270661 lmp.py:1622]   Expert  5 |    521 | GPU
DEBUG 01-13 08:46:25.270410.270410 lmp.py:1623] 
DEBUG 01-13 08:46:25.270410.270410 lmp.py:1623]   CPU total tokens: 4000 (32.6%)
DEBUG 01-13 08:46:25.270113.270113 lmp.py:1624]   GPU total tokens: 8288 (67.4%)
DEBUG 01-13 08:46:25.270723.270723 cuda_h.py:19] end experts_map_get cost 0.0020673274993896484 seconds
DEBUG 01-13 08:46:25.270448.270448 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-13 08:46:25.270211.270211 lmp.py:1632] 
DEBUG 01-13 08:46:25.270211.270211 lmp.py:1632]   Computing 32 experts on CPU MP...
DEBUG 01-13 08:46:25.271683.271683 cuda_h.py:19] end cpu_experts_submit cost 6.961822509765625e-05 seconds
DEBUG 01-13 08:46:25.271863.271863 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-13 08:46:25.271865.271865 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
INFO 01-13 08:46:25.271564.271564 client.py:127] Model loaded
DEBUG 01-13 08:46:25.271151.271151 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-13 08:46:25.271803.271803 cuda_h.py:10] start restore2model
DEBUG 01-13 08:46:25.272971.272971 cuda_h.py:10] start experts_func_gpu_einsum_mp
DEBUG 01-13 08:46:25.272740.272740 cuda_h.py:19] end allocate_cuda_memory cost 0.00021767616271972656 seconds
DEBUG 01-13 08:46:25.272199.272199 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-13 08:46:25.272690.272690 sllm_store_c.py:27] get device uuid map
DEBUG 01-13 08:46:25.272182.272182 sllm_store_c.py:29] call client load into gpu
DEBUG 01-13 08:46:25.272362.272362 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 9451369b-7eb0-4c53-b7e5-8f7c4a781fb4
DEBUG 01-13 08:46:25.273263.273263 client.py:106] call stub.LoadModelAsync
DEBUG 01-13 08:46:25.273800.273800 cuda_h.py:19] end restore2model cost 0.0011248588562011719 seconds
DEBUG 01-13 08:46:25.273160.273160 cuda_h.py:19] end sllm_worker_task cost 0.01143193244934082 seconds
INFO 01-13 08:46:25.274911.274911 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 9451369b-7eb0-4c53-b7e5-8f7c4a781fb4
DEBUG 01-13 08:46:25.274867.274867 cuda_h.py:19] end load_into_gpu_async cost 0.0015325546264648438 seconds
DEBUG 01-13 08:46:25.274107.274107 cuda_h.py:10] start restore_tensors2
DEBUG 01-13 08:46:25.274871.274871 cuda_h.py:19] end restore_tensors2 cost 0.0004210472106933594 seconds
DEBUG 01-13 08:46:25.274151.274151 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.003280162811279297 seconds
DEBUG 01-13 08:46:25.274126.274126 cuda_h.py:10] start restore2model
DEBUG 01-13 08:46:25.278778.278778 cuda_h.py:19] end restore2model cost 0.0032138824462890625 seconds
DEBUG 01-13 08:46:25.278112.278112 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.0072100162506103516 seconds
DEBUG 01-13 08:46:25.278166.278166 cuda_h.py:10] start gpu_sexperts
DEBUG 01-13 08:46:25.278033.278033 cuda_h.py:19] end gpu_sexperts cost 0.0003180503845214844 seconds
DEBUG 01-13 08:46:25.278776.278776 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-13 08:46:25.278566.278566 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 1.8358230590820312e-05 seconds
DEBUG 01-13 08:46:25.278706.278706 cuda_h.py:10] start wait_experts
INFO 01-13 08:46:25.278608.278608 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 9451369b-7eb0-4c53-b7e5-8f7c4a781fb4
DEBUG 01-13 08:46:25.282306.282306 mlpmodule.py:1006] group tensors cost 0.009517908096313477 s
DEBUG 01-13 08:46:25.284113.284113 mlpmodule.py:1044] pad cost 0.0014133453369140625 s
DEBUG 01-13 08:46:25.284613.284613 mlpmodule.py:1050] create cpu tensor cost 3.743171691894531e-05 s
DEBUG 01-13 08:46:25.284781.284781 mlpmodule.py:1055] move to cpu cost 3.9577484130859375e-05 s
DEBUG 01-13 08:46:25.294051.294051 mlpmodule.py:1069] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-13 08:46:25.294832.294832 mlpmodule.py:1070] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-13 08:46:25.294242.294242 mlpmodule.py:1075] group_w3 first element: 0.0859375
WARNING 01-13 08:46:25.294446.294446 mlpmodule.py:1085] start einsum2
DEBUG 01-13 08:46:25.306052.306052 mlpmodule.py:1095] group einsum cost 0.022242307662963867 s
DEBUG 01-13 08:46:25.307849.307849 mlpmodule.py:1103] cpy2cputensor cost 0.0006694793701171875 s
INFO 01-13 08:46:25.325280.325280 client.py:127] Model loaded
DEBUG 01-13 08:46:25.325749.325749 cuda_h.py:19] end wait_experts cost 0.046507835388183594 seconds
DEBUG 01-13 08:46:25.325088.325088 cuda_h.py:10] start gpu_experts
DEBUG 01-13 08:46:25.325854.325854 mlpmodule.py:785]  experts func einsum cost 0.05302095413208008 s
DEBUG 01-13 08:46:25.326112.326112 mlpmodule.py:559] gpu group tensors cost 0.0006144046783447266 s
DEBUG 01-13 08:46:25.326152.326152 cuda_h.py:19] end experts_func_gpu_einsum_mp cost 0.053813934326171875 seconds
DEBUG 01-13 08:46:25.328167.328167 mlpmodule.py:592] gpu pad cost 0.0019791126251220703 s
DEBUG 01-13 08:46:25.328574.328574 mlpmodule.py:598] start_w1
DEBUG 01-13 08:46:25.328297.328297 mlpmodule.py:602] start_w3
DEBUG 01-13 08:46:25.328721.328721 mlpmodule.py:608] start_w2
DEBUG 01-13 08:46:25.329926.329926 mlpmodule.py:611] gpu group einsum cost 0.0008237361907958984 s
DEBUG 01-13 08:46:25.331082.331082 mlpmodule.py:683] gpu experts func einsum cost 0.006459951400756836 s
DEBUG 01-13 08:46:25.332721.332721 cuda_h.py:19] end gpu_experts cost 0.006616353988647461 seconds
DEBUG 01-13 08:46:25.332616.332616 cuda_h.py:10] start cpu_thread_manager_mp_wait
DEBUG 01-13 08:46:25.332803.332803 cuda_h.py:19] end cpu_thread_manager_mp_wait cost 3.6716461181640625e-05 seconds
DEBUG 01-13 08:46:25.332734.332734 cuda_h.py:19] end layer_moe_generate_mp_l_9 cost 0.06444048881530762 seconds
DEBUG 01-13 08:46:25.332319.332319 lmp.py:1550] -------------------------------- end prefill layer 8 --------------------------------
DEBUG 01-13 08:46:25.332420.332420 lmp.py:1493] -------------------------------- start prefill layer 9 --------------------------------
DEBUG 01-13 08:46:25.332408.332408 cuda_h.py:10] start start_load_qkvogn_s_weight_l_10
DEBUG 01-13 08:46:25.332164.332164 cuda_h.py:10] start start_load_qkvogn_s_weight_l_10
DEBUG 01-13 08:46:25.332815.332815 cuda_h.py:19] end start_load_qkvogn_s_weight_l_10 cost 3.1948089599609375e-05 seconds
DEBUG 01-13 08:46:25.332048.332048 cuda_h.py:19] end start_load_qkvogn_s_weight_l_10 cost 6.628036499023438e-05 seconds
DEBUG 01-13 08:46:25.332267.332267 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-13 08:46:25.332256.332256 cuda_h.py:10] start sllm_worker_task
DEBUG 01-13 08:46:25.332762.332762 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-13 08:46:25.332711.332711 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-13 08:46:25.333477.333477 cuda_h.py:19] end allocate_cuda_memory cost 0.0002732276916503906 seconds
DEBUG 01-13 08:46:25.333057.333057 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-13 08:46:25.333523.333523 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-13 08:46:25.333739.333739 sllm_store_c.py:27] get device uuid map
DEBUG 01-13 08:46:25.333721.333721 sllm_store_c.py:29] call client load into gpu
DEBUG 01-13 08:46:25.333133.333133 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 20db762b-480f-4655-adc8-2d98a6e47849
DEBUG 01-13 08:46:25.333660.333660 client.py:106] call stub.LoadModelAsync
DEBUG 01-13 08:46:25.334678.334678 cuda_h.py:10] start self_attn
INFO 01-13 08:46:25.334342.334342 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 20db762b-480f-4655-adc8-2d98a6e47849
DEBUG 01-13 08:46:25.334676.334676 cuda_h.py:19] end load_into_gpu_async cost 0.0012898445129394531 seconds
DEBUG 01-13 08:46:25.334300.334300 cuda_h.py:10] start restore_tensors2
DEBUG 01-13 08:46:25.335641.335641 cuda_h.py:19] end restore_tensors2 cost 7.62939453125e-05 seconds
DEBUG 01-13 08:46:25.335623.335623 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0021352767944335938 seconds
INFO 01-13 08:46:25.335931.335931 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 20db762b-480f-4655-adc8-2d98a6e47849
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-13 08:46:25.337188.337188 cuda_h.py:19] end self_attn cost 0.0037202835083007812 seconds
DEBUG 01-13 08:46:25.338544.338544 cuda_h.py:19] end iln_self_attn_paln cost 0.005475282669067383 seconds
DEBUG 01-13 08:46:25.338394.338394 cuda_h.py:10] start layer_moe_generate_mp_l_10
DEBUG 01-13 08:46:25.338441.338441 cuda_h.py:10] start gate
DEBUG 01-13 08:46:25.339262.339262 cuda_h.py:19] end gate cost 0.0007452964782714844 seconds
DEBUG 01-13 08:46:25.339191.339191 cuda_h.py:10] start experts_map_get
DEBUG 01-13 08:46:25.339630.339630 lmp.py:1611] 
DEBUG 01-13 08:46:25.339630.339630 lmp.py:1611] Expert Token Distribution & Device Allocation:
DEBUG 01-13 08:46:25.339910.339910 lmp.py:1612]   Total experts: 64
DEBUG 01-13 08:46:25.339990.339990 lmp.py:1613]   CPU experts: 32 (50%)
DEBUG 01-13 08:46:25.339878.339878 lmp.py:1614]   GPU experts: 32 (50%)
DEBUG 01-13 08:46:25.339713.339713 lmp.py:1615] 
DEBUG 01-13 08:46:25.339713.339713 lmp.py:1615]   Expert ID | Tokens | Device
DEBUG 01-13 08:46:25.339025.339025 lmp.py:1616]   -----------------------------------
DEBUG 01-13 08:46:25.339026.339026 lmp.py:1622]   Expert 24 |     41 | CPU
DEBUG 01-13 08:46:25.339100.339100 lmp.py:1622]   Expert  2 |     46 | CPU
DEBUG 01-13 08:46:25.339981.339981 lmp.py:1622]   Expert 32 |     63 | CPU
DEBUG 01-13 08:46:25.339386.339386 lmp.py:1622]   Expert 19 |     70 | CPU
DEBUG 01-13 08:46:25.339552.339552 lmp.py:1622]   Expert 26 |     71 | CPU
DEBUG 01-13 08:46:25.339956.339956 lmp.py:1622]   Expert  7 |     76 | CPU
DEBUG 01-13 08:46:25.339076.339076 lmp.py:1622]   Expert 50 |     77 | CPU
DEBUG 01-13 08:46:25.339481.339481 lmp.py:1622]   Expert  4 |     79 | CPU
DEBUG 01-13 08:46:25.339647.339647 lmp.py:1622]   Expert 15 |     83 | CPU
DEBUG 01-13 08:46:25.339813.339813 lmp.py:1622]   Expert 28 |     83 | CPU
DEBUG 01-13 08:46:25.339979.339979 lmp.py:1622]   Expert 59 |     89 | CPU
DEBUG 01-13 08:46:25.339145.339145 lmp.py:1622]   Expert 60 |     90 | CPU
DEBUG 01-13 08:46:25.340311.340311 lmp.py:1622]   Expert 23 |     98 | CPU
DEBUG 01-13 08:46:25.340478.340478 lmp.py:1622]   Expert 49 |     99 | CPU
DEBUG 01-13 08:46:25.340644.340644 lmp.py:1622]   Expert  5 |    101 | CPU
DEBUG 01-13 08:46:25.340048.340048 lmp.py:1622]   Expert 12 |    101 | CPU
DEBUG 01-13 08:46:25.340645.340645 lmp.py:1622]   Expert 10 |    105 | CPU
DEBUG 01-13 08:46:25.340049.340049 lmp.py:1622]   Expert 27 |    110 | CPU
DEBUG 01-13 08:46:25.340692.340692 lmp.py:1622]   Expert 41 |    119 | CPU
DEBUG 01-13 08:46:25.340859.340859 lmp.py:1622]   Expert  3 |    122 | CPU
DEBUG 01-13 08:46:25.340025.340025 lmp.py:1622]   Expert 40 |    124 | CPU
DEBUG 01-13 08:46:25.340429.340429 lmp.py:1622]   Expert 13 |    126 | CPU
DEBUG 01-13 08:46:25.340595.340595 lmp.py:1622]   Expert 20 |    126 | CPU
DEBUG 01-13 08:46:25.340762.340762 lmp.py:1622]   Expert 16 |    129 | CPU
DEBUG 01-13 08:46:25.340928.340928 lmp.py:1622]   Expert 25 |    130 | CPU
DEBUG 01-13 08:46:25.340094.340094 lmp.py:1622]   Expert 17 |    143 | CPU
DEBUG 01-13 08:46:25.340214.340214 lmp.py:1622]   Expert 37 |    144 | CPU
DEBUG 01-13 08:46:25.340333.340333 lmp.py:1622]   Expert 35 |    146 | CPU
DEBUG 01-13 08:46:25.340500.340500 lmp.py:1622]   Expert 22 |    160 | CPU
DEBUG 01-13 08:46:25.340666.340666 lmp.py:1622]   Expert 53 |    164 | CPU
DEBUG 01-13 08:46:25.340832.340832 lmp.py:1622]   Expert 47 |    170 | CPU
DEBUG 01-13 08:46:25.340760.340760 lmp.py:1622]   Expert 38 |    174 | CPU
DEBUG 01-13 08:46:25.340926.340926 lmp.py:1622]   Expert 39 |    175 | GPU
DEBUG 01-13 08:46:25.340853.340853 lmp.py:1622]   Expert 36 |    177 | GPU
DEBUG 01-13 08:46:25.340364.340364 lmp.py:1622]   Expert 44 |    181 | GPU
DEBUG 01-13 08:46:25.340412.340412 lmp.py:1622]   Expert 18 |    185 | GPU
DEBUG 01-13 08:46:25.340008.340008 lmp.py:1622]   Expert 58 |    187 | GPU
DEBUG 01-13 08:46:25.340128.340128 lmp.py:1622]   Expert 52 |    189 | GPU
DEBUG 01-13 08:46:25.340010.340010 lmp.py:1622]   Expert 62 |    194 | GPU
DEBUG 01-13 08:46:25.340891.340891 lmp.py:1622]   Expert 48 |    207 | GPU
DEBUG 01-13 08:46:25.340011.340011 lmp.py:1622]   Expert 11 |    212 | GPU
DEBUG 01-13 08:46:25.340131.340131 lmp.py:1622]   Expert 30 |    213 | GPU
DEBUG 01-13 08:46:25.340489.340489 lmp.py:1622]   Expert 14 |    214 | GPU
DEBUG 01-13 08:46:25.340046.340046 lmp.py:1622]   Expert  1 |    228 | GPU
DEBUG 01-13 08:46:25.340451.340451 lmp.py:1622]   Expert 42 |    234 | GPU
DEBUG 01-13 08:46:25.340855.340855 lmp.py:1622]   Expert 31 |    236 | GPU
DEBUG 01-13 08:46:25.340021.340021 lmp.py:1622]   Expert 45 |    236 | GPU
DEBUG 01-13 08:46:25.340187.340187 lmp.py:1622]   Expert  6 |    237 | GPU
DEBUG 01-13 08:46:25.340115.340115 lmp.py:1622]   Expert 51 |    237 | GPU
DEBUG 01-13 08:46:25.340043.340043 lmp.py:1622]   Expert 29 |    264 | GPU
DEBUG 01-13 08:46:25.340494.340494 lmp.py:1622]   Expert 34 |    272 | GPU
DEBUG 01-13 08:46:25.340660.340660 lmp.py:1622]   Expert 33 |    280 | GPU
DEBUG 01-13 08:46:25.340495.340495 lmp.py:1622]   Expert 57 |    288 | GPU
DEBUG 01-13 08:46:25.340138.340138 lmp.py:1622]   Expert 43 |    305 | GPU
DEBUG 01-13 08:46:25.340304.340304 lmp.py:1622]   Expert 61 |    305 | GPU
DEBUG 01-13 08:46:25.340232.340232 lmp.py:1622]   Expert  0 |    318 | GPU
DEBUG 01-13 08:46:25.340159.340159 lmp.py:1622]   Expert 46 |    363 | GPU
DEBUG 01-13 08:46:25.340326.340326 lmp.py:1622]   Expert  8 |    384 | GPU
DEBUG 01-13 08:46:25.340730.340730 lmp.py:1622]   Expert  9 |    387 | GPU
DEBUG 01-13 08:46:25.340658.340658 lmp.py:1622]   Expert 54 |    402 | GPU
DEBUG 01-13 08:46:25.340586.340586 lmp.py:1622]   Expert 63 |    406 | GPU
DEBUG 01-13 08:46:25.340752.340752 lmp.py:1622]   Expert 56 |    407 | GPU
DEBUG 01-13 08:46:25.340110.340110 lmp.py:1622]   Expert 55 |    421 | GPU
DEBUG 01-13 08:46:25.340991.340991 lmp.py:1622]   Expert 21 |    485 | GPU
DEBUG 01-13 08:46:25.340588.340588 lmp.py:1623] 
DEBUG 01-13 08:46:25.340588.340588 lmp.py:1623]   CPU total tokens: 3459 (28.1%)
DEBUG 01-13 08:46:25.340946.340946 lmp.py:1624]   GPU total tokens: 8829 (71.9%)
DEBUG 01-13 08:46:25.340311.340311 cuda_h.py:19] end experts_map_get cost 0.001779317855834961 seconds
DEBUG 01-13 08:46:25.341691.341691 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-13 08:46:25.341685.341685 lmp.py:1632] 
DEBUG 01-13 08:46:25.341685.341685 lmp.py:1632]   Computing 32 experts on CPU MP...
DEBUG 01-13 08:46:25.341184.341184 cuda_h.py:19] end cpu_experts_submit cost 5.1975250244140625e-05 seconds
DEBUG 01-13 08:46:25.341118.341118 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-13 08:46:25.341994.341994 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-13 08:46:25.341985.341985 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-13 08:46:25.342279.342279 cuda_h.py:19] end allocate_cuda_memory cost 0.000812530517578125 seconds
DEBUG 01-13 08:46:25.342522.342522 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-13 08:46:25.342914.342914 sllm_store_c.py:27] get device uuid map
DEBUG 01-13 08:46:25.342299.342299 sllm_store_c.py:29] call client load into gpu
DEBUG 01-13 08:46:25.342486.342486 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 1795d2a1-bc76-4c3a-b44d-13a72686bd0c
DEBUG 01-13 08:46:25.343360.343360 client.py:106] call stub.LoadModelAsync
INFO 01-13 08:46:25.343060.343060 client.py:127] Model loaded
DEBUG 01-13 08:46:25.343657.343657 cuda_h.py:10] start experts_func_gpu_einsum_mp
DEBUG 01-13 08:46:25.343838.343838 cuda_h.py:10] start restore2model
DEBUG 01-13 08:46:25.343202.343202 cuda_h.py:19] end restore2model cost 0.0005204677581787109 seconds
DEBUG 01-13 08:46:25.343920.343920 cuda_h.py:19] end sllm_worker_task cost 0.011042356491088867 seconds
INFO 01-13 08:46:25.344482.344482 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 1795d2a1-bc76-4c3a-b44d-13a72686bd0c
DEBUG 01-13 08:46:25.344755.344755 cuda_h.py:19] end load_into_gpu_async cost 0.001390218734741211 seconds
DEBUG 01-13 08:46:25.344365.344365 cuda_h.py:10] start restore_tensors2
DEBUG 01-13 08:46:25.344746.344746 cuda_h.py:19] end restore_tensors2 cost 0.00046133995056152344 seconds
DEBUG 01-13 08:46:25.344351.344351 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0035021305084228516 seconds
DEBUG 01-13 08:46:25.344213.344213 cuda_h.py:10] start restore2model
DEBUG 01-13 08:46:25.347280.347280 cuda_h.py:19] end restore2model cost 0.0031371116638183594 seconds
DEBUG 01-13 08:46:25.348454.348454 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.0068247318267822266 seconds
DEBUG 01-13 08:46:25.348772.348772 cuda_h.py:10] start gpu_sexperts
DEBUG 01-13 08:46:25.348512.348512 cuda_h.py:19] end gpu_sexperts cost 0.00030303001403808594 seconds
DEBUG 01-13 08:46:25.348998.348998 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-13 08:46:25.348967.348967 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 1.621246337890625e-05 seconds
DEBUG 01-13 08:46:25.348616.348616 cuda_h.py:10] start wait_experts
INFO 01-13 08:46:25.348981.348981 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 1795d2a1-bc76-4c3a-b44d-13a72686bd0c
DEBUG 01-13 08:46:25.348574.348574 mlpmodule.py:1006] group tensors cost 0.005037546157836914 s
DEBUG 01-13 08:46:25.351227.351227 mlpmodule.py:1044] pad cost 0.0019178390502929688 s
DEBUG 01-13 08:46:25.351045.351045 mlpmodule.py:1050] create cpu tensor cost 4.6253204345703125e-05 s
DEBUG 01-13 08:46:25.351577.351577 mlpmodule.py:1055] move to cpu cost 3.337860107421875e-05 s
DEBUG 01-13 08:46:25.359464.359464 mlpmodule.py:1069] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-13 08:46:25.359231.359231 mlpmodule.py:1070] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-13 08:46:25.360235.360235 mlpmodule.py:1075] group_w3 first element: 0.0157470703125
WARNING 01-13 08:46:25.360981.360981 mlpmodule.py:1085] start einsum2
DEBUG 01-13 08:46:25.373716.373716 mlpmodule.py:1095] group einsum cost 0.021861791610717773 s
DEBUG 01-13 08:46:25.374130.374130 mlpmodule.py:1103] cpy2cputensor cost 0.0007035732269287109 s
INFO 01-13 08:46:25.396146.396146 client.py:127] Model loaded
DEBUG 01-13 08:46:25.396640.396640 cuda_h.py:19] end wait_experts cost 0.04755520820617676 seconds
DEBUG 01-13 08:46:25.396588.396588 cuda_h.py:10] start gpu_experts
DEBUG 01-13 08:46:25.396580.396580 mlpmodule.py:559] gpu group tensors cost 0.0006358623504638672 s
DEBUG 01-13 08:46:25.397905.397905 mlpmodule.py:785]  experts func einsum cost 0.05329775810241699 s
DEBUG 01-13 08:46:25.397506.397506 cuda_h.py:19] end experts_func_gpu_einsum_mp cost 0.054169416427612305 seconds
DEBUG 01-13 08:46:25.398085.398085 mlpmodule.py:592] gpu pad cost 0.0019567012786865234 s
DEBUG 01-13 08:46:25.398603.398603 mlpmodule.py:598] start_w1
DEBUG 01-13 08:46:25.399331.399331 mlpmodule.py:602] start_w3
DEBUG 01-13 08:46:25.399906.399906 mlpmodule.py:608] start_w2
DEBUG 01-13 08:46:25.399243.399243 mlpmodule.py:611] gpu group einsum cost 0.000720977783203125 s
DEBUG 01-13 08:46:25.402010.402010 mlpmodule.py:683] gpu experts func einsum cost 0.006363391876220703 s
DEBUG 01-13 08:46:25.402649.402649 cuda_h.py:19] end gpu_experts cost 0.006513118743896484 seconds
DEBUG 01-13 08:46:25.402544.402544 cuda_h.py:10] start cpu_thread_manager_mp_wait
DEBUG 01-13 08:46:25.402685.402685 cuda_h.py:19] end cpu_thread_manager_mp_wait cost 4.00543212890625e-05 seconds
DEBUG 01-13 08:46:25.402377.402377 cuda_h.py:19] end layer_moe_generate_mp_l_10 cost 0.06452798843383789 seconds
DEBUG 01-13 08:46:25.403491.403491 lmp.py:1550] -------------------------------- end prefill layer 9 --------------------------------
DEBUG 01-13 08:46:25.403492.403492 lmp.py:1493] -------------------------------- start prefill layer 10 --------------------------------
DEBUG 01-13 08:46:25.403288.403288 cuda_h.py:10] start start_load_qkvogn_s_weight_l_11
DEBUG 01-13 08:46:25.403137.403137 cuda_h.py:10] start start_load_qkvogn_s_weight_l_11
DEBUG 01-13 08:46:25.403880.403880 cuda_h.py:19] end start_load_qkvogn_s_weight_l_11 cost 3.147125244140625e-05 seconds
DEBUG 01-13 08:46:25.403557.403557 cuda_h.py:19] end start_load_qkvogn_s_weight_l_11 cost 7.677078247070312e-05 seconds
DEBUG 01-13 08:46:25.403776.403776 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-13 08:46:25.403925.403925 cuda_h.py:10] start sllm_worker_task
DEBUG 01-13 08:46:25.403062.403062 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-13 08:46:25.403831.403831 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-13 08:46:25.403922.403922 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-13 08:46:25.404245.404245 cuda_h.py:19] end allocate_cuda_memory cost 0.0002968311309814453 seconds
DEBUG 01-13 08:46:25.404989.404989 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-13 08:46:25.404097.404097 sllm_store_c.py:27] get device uuid map
DEBUG 01-13 08:46:25.404264.404264 sllm_store_c.py:29] call client load into gpu
DEBUG 01-13 08:46:25.404166.404166 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 4194c210-eeca-4314-8183-d9704705d042
DEBUG 01-13 08:46:25.404574.404574 client.py:106] call stub.LoadModelAsync
DEBUG 01-13 08:46:25.404392.404392 cuda_h.py:10] start self_attn
INFO 01-13 08:46:25.405089.405089 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 4194c210-eeca-4314-8183-d9704705d042
DEBUG 01-13 08:46:25.405654.405654 cuda_h.py:19] end load_into_gpu_async cost 0.0012180805206298828 seconds
DEBUG 01-13 08:46:25.405841.405841 cuda_h.py:10] start restore_tensors2
DEBUG 01-13 08:46:25.405712.405712 cuda_h.py:19] end restore_tensors2 cost 8.058547973632812e-05 seconds
DEBUG 01-13 08:46:25.405574.405574 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.001909017562866211 seconds
INFO 01-13 08:46:25.405232.405232 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 4194c210-eeca-4314-8183-d9704705d042
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-13 08:46:25.408378.408378 cuda_h.py:19] end self_attn cost 0.004065990447998047 seconds
DEBUG 01-13 08:46:25.409337.409337 cuda_h.py:19] end iln_self_attn_paln cost 0.00582432746887207 seconds
DEBUG 01-13 08:46:25.409895.409895 cuda_h.py:10] start layer_moe_generate_mp_l_11
DEBUG 01-13 08:46:25.409903.409903 cuda_h.py:10] start gate
DEBUG 01-13 08:46:25.410909.410909 cuda_h.py:19] end gate cost 0.0007402896881103516 seconds
DEBUG 01-13 08:46:25.410746.410746 cuda_h.py:10] start experts_map_get
DEBUG 01-13 08:46:25.410483.410483 lmp.py:1611] 
DEBUG 01-13 08:46:25.410483.410483 lmp.py:1611] Expert Token Distribution & Device Allocation:
DEBUG 01-13 08:46:25.410047.410047 lmp.py:1612]   Total experts: 64
DEBUG 01-13 08:46:25.410889.410889 lmp.py:1613]   CPU experts: 32 (50%)
DEBUG 01-13 08:46:25.410631.410631 lmp.py:1614]   GPU experts: 32 (50%)
DEBUG 01-13 08:46:25.410751.410751 lmp.py:1615] 
DEBUG 01-13 08:46:25.410751.410751 lmp.py:1615]   Expert ID | Tokens | Device
DEBUG 01-13 08:46:25.410109.410109 lmp.py:1616]   -----------------------------------
DEBUG 01-13 08:46:25.410951.410951 lmp.py:1622]   Expert 43 |     17 | CPU
DEBUG 01-13 08:46:25.410786.410786 lmp.py:1622]   Expert 27 |     31 | CPU
DEBUG 01-13 08:46:25.410668.410668 lmp.py:1622]   Expert 56 |     51 | CPU
DEBUG 01-13 08:46:25.410311.410311 lmp.py:1622]   Expert 34 |     53 | CPU
DEBUG 01-13 08:46:25.410861.410861 lmp.py:1622]   Expert  3 |     55 | CPU
DEBUG 01-13 08:46:25.410742.410742 lmp.py:1622]   Expert 26 |     55 | CPU
DEBUG 01-13 08:46:25.410385.410385 lmp.py:1622]   Expert  4 |     68 | CPU
DEBUG 01-13 08:46:25.410028.410028 lmp.py:1622]   Expert 61 |     81 | CPU
DEBUG 01-13 08:46:25.410910.410910 lmp.py:1622]   Expert 14 |     89 | CPU
DEBUG 01-13 08:46:25.410553.410553 lmp.py:1622]   Expert 38 |     96 | CPU
DEBUG 01-13 08:46:25.410196.410196 lmp.py:1622]   Expert  2 |    114 | CPU
DEBUG 01-13 08:46:25.410839.410839 lmp.py:1622]   Expert 17 |    119 | CPU
DEBUG 01-13 08:46:25.410005.410005 lmp.py:1622]   Expert 22 |    124 | CPU
DEBUG 01-13 08:46:25.410078.410078 lmp.py:1622]   Expert 47 |    129 | CPU
DEBUG 01-13 08:46:25.410198.410198 lmp.py:1622]   Expert 55 |    129 | CPU
DEBUG 01-13 08:46:25.411841.411841 lmp.py:1622]   Expert 37 |    130 | CPU
DEBUG 01-13 08:46:25.411484.411484 lmp.py:1622]   Expert 54 |    133 | CPU
DEBUG 01-13 08:46:25.411889.411889 lmp.py:1622]   Expert 28 |    138 | CPU
DEBUG 01-13 08:46:25.411055.411055 lmp.py:1622]   Expert 15 |    142 | CPU
DEBUG 01-13 08:46:25.411459.411459 lmp.py:1622]   Expert 51 |    143 | CPU
DEBUG 01-13 08:46:25.411864.411864 lmp.py:1622]   Expert 48 |    146 | CPU
DEBUG 01-13 08:46:25.411268.411268 lmp.py:1622]   Expert 45 |    147 | CPU
DEBUG 01-13 08:46:25.411150.411150 lmp.py:1622]   Expert  5 |    148 | CPU
DEBUG 01-13 08:46:25.411270.411270 lmp.py:1622]   Expert 60 |    148 | CPU
DEBUG 01-13 08:46:25.411674.411674 lmp.py:1622]   Expert 12 |    149 | CPU
DEBUG 01-13 08:46:25.411317.411317 lmp.py:1622]   Expert  7 |    151 | CPU
DEBUG 01-13 08:46:25.411391.411391 lmp.py:1622]   Expert 63 |    154 | CPU
DEBUG 01-13 08:46:25.411987.411987 lmp.py:1622]   Expert  6 |    162 | CPU
DEBUG 01-13 08:46:25.411584.411584 lmp.py:1622]   Expert 19 |    162 | CPU
DEBUG 01-13 08:46:25.411942.411942 lmp.py:1622]   Expert 52 |    167 | CPU
DEBUG 01-13 08:46:25.411062.411062 lmp.py:1622]   Expert 57 |    179 | CPU
DEBUG 01-13 08:46:25.411659.411659 lmp.py:1622]   Expert 44 |    182 | CPU
DEBUG 01-13 08:46:25.411494.411494 lmp.py:1622]   Expert 18 |    184 | GPU
DEBUG 01-13 08:46:25.411044.411044 lmp.py:1622]   Expert 50 |    184 | GPU
DEBUG 01-13 08:46:25.411641.411641 lmp.py:1622]   Expert 31 |    185 | GPU
DEBUG 01-13 08:46:25.411237.411237 lmp.py:1622]   Expert 13 |    186 | GPU
DEBUG 01-13 08:46:25.411834.411834 lmp.py:1622]   Expert 30 |    187 | GPU
DEBUG 01-13 08:46:25.411192.411192 lmp.py:1622]   Expert 59 |    189 | GPU
DEBUG 01-13 08:46:25.411789.411789 lmp.py:1622]   Expert 53 |    192 | GPU
DEBUG 01-13 08:46:25.411147.411147 lmp.py:1622]   Expert 29 |    194 | GPU
DEBUG 01-13 08:46:25.411505.411505 lmp.py:1622]   Expert 23 |    196 | GPU
DEBUG 01-13 08:46:25.411579.411579 lmp.py:1622]   Expert 20 |    198 | GPU
DEBUG 01-13 08:46:25.411937.411937 lmp.py:1622]   Expert 39 |    199 | GPU
DEBUG 01-13 08:46:25.411818.411818 lmp.py:1622]   Expert 36 |    207 | GPU
DEBUG 01-13 08:46:25.411177.411177 lmp.py:1622]   Expert 16 |    211 | GPU
DEBUG 01-13 08:46:25.411773.411773 lmp.py:1622]   Expert 21 |    212 | GPU
DEBUG 01-13 08:46:25.411132.411132 lmp.py:1622]   Expert 41 |    213 | GPU
DEBUG 01-13 08:46:25.411490.411490 lmp.py:1622]   Expert 25 |    215 | GPU
DEBUG 01-13 08:46:25.411086.411086 lmp.py:1622]   Expert 46 |    218 | GPU
DEBUG 01-13 08:46:25.411683.411683 lmp.py:1622]   Expert 49 |    223 | GPU
DEBUG 01-13 08:46:25.411518.411518 lmp.py:1622]   Expert 32 |    224 | GPU
DEBUG 01-13 08:46:25.411115.411115 lmp.py:1622]   Expert 10 |    245 | GPU
DEBUG 01-13 08:46:25.411473.411473 lmp.py:1622]   Expert  8 |    248 | GPU
DEBUG 01-13 08:46:25.411593.411593 lmp.py:1622]   Expert 42 |    253 | GPU
DEBUG 01-13 08:46:25.411428.411428 lmp.py:1622]   Expert 62 |    257 | GPU
DEBUG 01-13 08:46:25.411786.411786 lmp.py:1622]   Expert 35 |    278 | GPU
DEBUG 01-13 08:46:25.411098.411098 lmp.py:1622]   Expert 33 |    295 | GPU
DEBUG 01-13 08:46:25.411748.411748 lmp.py:1622]   Expert  9 |    299 | GPU
DEBUG 01-13 08:46:25.411868.411868 lmp.py:1622]   Expert 58 |    301 | GPU
DEBUG 01-13 08:46:25.411511.411511 lmp.py:1622]   Expert 40 |    387 | GPU
DEBUG 01-13 08:46:25.411630.411630 lmp.py:1622]   Expert  0 |    422 | GPU
DEBUG 01-13 08:46:25.411035.411035 lmp.py:1622]   Expert 11 |    458 | GPU
DEBUG 01-13 08:46:25.411678.411678 lmp.py:1622]   Expert 24 |    566 | GPU
DEBUG 01-13 08:46:25.411083.411083 lmp.py:1622]   Expert  1 |    670 | GPU
DEBUG 01-13 08:46:25.411156.411156 lmp.py:1623] 
DEBUG 01-13 08:46:25.411156.411156 lmp.py:1623]   CPU total tokens: 3792 (30.9%)
DEBUG 01-13 08:46:25.411945.411945 lmp.py:1624]   GPU total tokens: 8496 (69.1%)
DEBUG 01-13 08:46:25.411787.411787 cuda_h.py:19] end experts_map_get cost 0.0017905235290527344 seconds
DEBUG 01-13 08:46:25.412690.412690 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-13 08:46:25.412684.412684 lmp.py:1632] 
DEBUG 01-13 08:46:25.412684.412684 lmp.py:1632]   Computing 32 experts on CPU MP...
DEBUG 01-13 08:46:25.412136.412136 cuda_h.py:19] end cpu_experts_submit cost 5.245208740234375e-05 seconds
DEBUG 01-13 08:46:25.412978.412978 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-13 08:46:25.412192.412192 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-13 08:46:25.412421.412421 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-13 08:46:25.414770.414770 cuda_h.py:19] end allocate_cuda_memory cost 0.002222776412963867 seconds
DEBUG 01-13 08:46:25.414814.414814 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-13 08:46:25.414312.414312 sllm_store_c.py:27] get device uuid map
DEBUG 01-13 08:46:25.414758.414758 sllm_store_c.py:29] call client load into gpu
DEBUG 01-13 08:46:25.414891.414891 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, bab980a6-be54-4bcc-835d-0fabdfcf1d27
DEBUG 01-13 08:46:25.415564.415564 client.py:106] call stub.LoadModelAsync
INFO 01-13 08:46:25.416128.416128 client.py:127] Model loaded
DEBUG 01-13 08:46:25.416014.416014 cuda_h.py:10] start restore2model
INFO 01-13 08:46:25.416426.416426 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, bab980a6-be54-4bcc-835d-0fabdfcf1d27
DEBUG 01-13 08:46:25.416282.416282 cuda_h.py:19] end load_into_gpu_async cost 0.0018870830535888672 seconds
DEBUG 01-13 08:46:25.416846.416846 cuda_h.py:10] start restore_tensors2
DEBUG 01-13 08:46:25.416492.416492 cuda_h.py:10] start experts_func_gpu_einsum_mp
DEBUG 01-13 08:46:25.417086.417086 cuda_h.py:19] end restore_tensors2 cost 0.0011975765228271484 seconds
DEBUG 01-13 08:46:25.418565.418565 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.005796909332275391 seconds
DEBUG 01-13 08:46:25.418388.418388 cuda_h.py:10] start restore2model
DEBUG 01-13 08:46:25.419687.419687 cuda_h.py:19] end restore2model cost 0.0011608600616455078 seconds
DEBUG 01-13 08:46:25.419771.419771 cuda_h.py:19] end sllm_worker_task cost 0.01579451560974121 seconds
DEBUG 01-13 08:46:25.422266.422266 cuda_h.py:19] end restore2model cost 0.004224061965942383 seconds
DEBUG 01-13 08:46:25.422435.422435 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.010248661041259766 seconds
DEBUG 01-13 08:46:25.422945.422945 cuda_h.py:10] start gpu_sexperts
DEBUG 01-13 08:46:25.422239.422239 cuda_h.py:19] end gpu_sexperts cost 0.0004296302795410156 seconds
DEBUG 01-13 08:46:25.422936.422936 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-13 08:46:25.423296.423296 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.2411346435546875e-05 seconds
DEBUG 01-13 08:46:25.423614.423614 cuda_h.py:10] start wait_experts
INFO 01-13 08:46:25.423648.423648 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, bab980a6-be54-4bcc-835d-0fabdfcf1d27
DEBUG 01-13 08:46:25.426931.426931 mlpmodule.py:1006] group tensors cost 0.009619712829589844 s
DEBUG 01-13 08:46:25.429916.429916 mlpmodule.py:1044] pad cost 0.0015850067138671875 s
DEBUG 01-13 08:46:25.429568.429568 mlpmodule.py:1050] create cpu tensor cost 4.0531158447265625e-05 s
DEBUG 01-13 08:46:25.429048.429048 mlpmodule.py:1055] move to cpu cost 3.6716461181640625e-05 s
DEBUG 01-13 08:46:25.438646.438646 mlpmodule.py:1069] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-13 08:46:25.438397.438397 mlpmodule.py:1070] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-13 08:46:25.439951.439951 mlpmodule.py:1075] group_w3 first element: -0.0213623046875
WARNING 01-13 08:46:25.439227.439227 mlpmodule.py:1085] start einsum2
DEBUG 01-13 08:46:25.455388.455388 mlpmodule.py:1095] group einsum cost 0.02588200569152832 s
DEBUG 01-13 08:46:25.456478.456478 mlpmodule.py:1103] cpy2cputensor cost 0.0006732940673828125 s
INFO 01-13 08:46:25.468775.468775 client.py:127] Model loaded
DEBUG 01-13 08:46:25.469344.469344 cuda_h.py:19] end wait_experts cost 0.046071767807006836 seconds
DEBUG 01-13 08:46:25.469803.469803 cuda_h.py:10] start gpu_experts
DEBUG 01-13 08:46:25.470528.470528 mlpmodule.py:559] gpu group tensors cost 0.0007507801055908203 s
DEBUG 01-13 08:46:25.472147.472147 mlpmodule.py:592] gpu pad cost 0.002164602279663086 s
DEBUG 01-13 08:46:25.472794.472794 mlpmodule.py:598] start_w1
DEBUG 01-13 08:46:25.472524.472524 mlpmodule.py:602] start_w3
DEBUG 01-13 08:46:25.473299.473299 mlpmodule.py:608] start_w2
DEBUG 01-13 08:46:25.473107.473107 mlpmodule.py:611] gpu group einsum cost 0.0008616447448730469 s
DEBUG 01-13 08:46:25.476360.476360 mlpmodule.py:683] gpu experts func einsum cost 0.0070209503173828125 s
DEBUG 01-13 08:46:25.476391.476391 cuda_h.py:19] end gpu_experts cost 0.007235050201416016 seconds
DEBUG 01-13 08:46:25.476816.476816 cuda_h.py:10] start cpu_thread_manager_mp_wait
DEBUG 01-13 08:46:25.476487.476487 cuda_h.py:19] end cpu_thread_manager_mp_wait cost 4.291534423828125e-05 seconds
DEBUG 01-13 08:46:25.476438.476438 cuda_h.py:19] end layer_moe_generate_mp_l_11 cost 0.06739115715026855 seconds
DEBUG 01-13 08:46:25.477886.477886 lmp.py:1550] -------------------------------- end prefill layer 10 --------------------------------
DEBUG 01-13 08:46:25.477841.477841 lmp.py:1493] -------------------------------- start prefill layer 11 --------------------------------
DEBUG 01-13 08:46:25.477020.477020 cuda_h.py:10] start start_load_qkvogn_s_weight_l_12
DEBUG 01-13 08:46:25.477538.477538 cuda_h.py:10] start start_load_qkvogn_s_weight_l_12
DEBUG 01-13 08:46:25.477242.477242 cuda_h.py:19] end start_load_qkvogn_s_weight_l_12 cost 3.6716461181640625e-05 seconds
DEBUG 01-13 08:46:25.477660.477660 cuda_h.py:19] end start_load_qkvogn_s_weight_l_12 cost 6.794929504394531e-05 seconds
DEBUG 01-13 08:46:25.477926.477926 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-13 08:46:25.477663.477663 mlpmodule.py:785]  experts func einsum cost 0.05996513366699219 s
DEBUG 01-13 08:46:25.477921.477921 cuda_h.py:10] start sllm_worker_task
DEBUG 01-13 08:46:25.477653.477653 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-13 08:46:25.477734.477734 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-13 08:46:25.477735.477735 cuda_h.py:19] end experts_func_gpu_einsum_mp cost 0.06077432632446289 seconds
DEBUG 01-13 08:46:25.477117.477117 cuda_h.py:19] end allocate_cuda_memory cost 0.00031375885009765625 seconds
DEBUG 01-13 08:46:25.477311.477311 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-13 08:46:25.477690.477690 sllm_store_c.py:27] get device uuid map
DEBUG 01-13 08:46:25.477064.477064 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-13 08:46:25.478140.478140 sllm_store_c.py:29] call client load into gpu
DEBUG 01-13 08:46:25.478440.478440 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 94dbe0ee-221d-4446-97ad-8cc06c25fd8d
DEBUG 01-13 08:46:25.478376.478376 client.py:106] call stub.LoadModelAsync
DEBUG 01-13 08:46:25.478535.478535 cuda_h.py:10] start self_attn
INFO 01-13 08:46:25.479366.479366 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 94dbe0ee-221d-4446-97ad-8cc06c25fd8d
DEBUG 01-13 08:46:25.479825.479825 cuda_h.py:19] end load_into_gpu_async cost 0.001466989517211914 seconds
DEBUG 01-13 08:46:25.479104.479104 cuda_h.py:10] start restore_tensors2
DEBUG 01-13 08:46:25.479240.479240 cuda_h.py:19] end restore_tensors2 cost 6.961822509765625e-05 seconds
DEBUG 01-13 08:46:25.479526.479526 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0021224021911621094 seconds
INFO 01-13 08:46:25.479608.479608 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 94dbe0ee-221d-4446-97ad-8cc06c25fd8d
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-13 08:46:25.482485.482485 cuda_h.py:19] end self_attn cost 0.003587961196899414 seconds
DEBUG 01-13 08:46:25.482053.482053 cuda_h.py:19] end iln_self_attn_paln cost 0.005362987518310547 seconds
DEBUG 01-13 08:46:25.482658.482658 cuda_h.py:10] start layer_moe_generate_mp_l_12
DEBUG 01-13 08:46:25.482659.482659 cuda_h.py:10] start gate
DEBUG 01-13 08:46:25.483336.483336 cuda_h.py:19] end gate cost 0.0007748603820800781 seconds
DEBUG 01-13 08:46:25.483854.483854 cuda_h.py:10] start experts_map_get
DEBUG 01-13 08:46:25.484824.484824 lmp.py:1611] 
DEBUG 01-13 08:46:25.484824.484824 lmp.py:1611] Expert Token Distribution & Device Allocation:
DEBUG 01-13 08:46:25.484103.484103 lmp.py:1612]   Total experts: 64
DEBUG 01-13 08:46:25.484183.484183 lmp.py:1613]   CPU experts: 32 (50%)
DEBUG 01-13 08:46:25.484356.484356 lmp.py:1614]   GPU experts: 32 (50%)
DEBUG 01-13 08:46:25.484906.484906 lmp.py:1615] 
DEBUG 01-13 08:46:25.484906.484906 lmp.py:1615]   Expert ID | Tokens | Device
DEBUG 01-13 08:46:25.484457.484457 lmp.py:1616]   -----------------------------------
DEBUG 01-13 08:46:25.484014.484014 lmp.py:1622]   Expert 39 |     14 | CPU
DEBUG 01-13 08:46:25.484326.484326 lmp.py:1622]   Expert 13 |     21 | CPU
DEBUG 01-13 08:46:25.484922.484922 lmp.py:1622]   Expert 49 |     38 | CPU
DEBUG 01-13 08:46:25.484281.484281 lmp.py:1622]   Expert 35 |     49 | CPU
DEBUG 01-13 08:46:25.484400.484400 lmp.py:1622]   Expert 19 |     63 | CPU
DEBUG 01-13 08:46:25.484520.484520 lmp.py:1622]   Expert 32 |     67 | CPU
DEBUG 01-13 08:46:25.484878.484878 lmp.py:1622]   Expert 26 |     73 | CPU
DEBUG 01-13 08:46:25.484521.484521 lmp.py:1622]   Expert 41 |     73 | CPU
DEBUG 01-13 08:46:25.484641.484641 lmp.py:1622]   Expert 46 |     79 | CPU
DEBUG 01-13 08:46:25.484238.484238 lmp.py:1622]   Expert  9 |     82 | CPU
DEBUG 01-13 08:46:25.484418.484418 lmp.py:1622]   Expert 33 |     82 | CPU
DEBUG 01-13 08:46:25.484491.484491 lmp.py:1622]   Expert 31 |     83 | CPU
DEBUG 01-13 08:46:25.484379.484379 lmp.py:1622]   Expert 23 |     89 | CPU
DEBUG 01-13 08:46:25.484499.484499 lmp.py:1622]   Expert 18 |     91 | CPU
DEBUG 01-13 08:46:25.484096.484096 lmp.py:1622]   Expert 38 |     96 | CPU
DEBUG 01-13 08:46:25.484692.484692 lmp.py:1622]   Expert  6 |     99 | CPU
DEBUG 01-13 08:46:25.484574.484574 lmp.py:1622]   Expert 17 |    107 | CPU
DEBUG 01-13 08:46:25.484978.484978 lmp.py:1622]   Expert  3 |    108 | CPU
DEBUG 01-13 08:46:25.484145.484145 lmp.py:1622]   Expert 20 |    115 | CPU
DEBUG 01-13 08:46:25.484549.484549 lmp.py:1622]   Expert 59 |    124 | CPU
DEBUG 01-13 08:46:25.484715.484715 lmp.py:1622]   Expert 62 |    132 | CPU
DEBUG 01-13 08:46:25.484643.484643 lmp.py:1622]   Expert 61 |    133 | CPU
DEBUG 01-13 08:46:25.484809.484809 lmp.py:1622]   Expert 40 |    134 | CPU
DEBUG 01-13 08:46:25.484975.484975 lmp.py:1622]   Expert 15 |    135 | CPU
DEBUG 01-13 08:46:25.484141.484141 lmp.py:1622]   Expert 16 |    135 | CPU
DEBUG 01-13 08:46:25.484307.484307 lmp.py:1622]   Expert 43 |    135 | CPU
DEBUG 01-13 08:46:25.484950.484950 lmp.py:1622]   Expert 50 |    138 | CPU
DEBUG 01-13 08:46:25.484593.484593 lmp.py:1622]   Expert 42 |    145 | CPU
DEBUG 01-13 08:46:25.484236.484236 lmp.py:1622]   Expert 44 |    145 | CPU
DEBUG 01-13 08:46:25.484118.484118 lmp.py:1622]   Expert 63 |    146 | CPU
DEBUG 01-13 08:46:25.484522.484522 lmp.py:1622]   Expert 36 |    149 | CPU
DEBUG 01-13 08:46:25.484688.484688 lmp.py:1622]   Expert  2 |    152 | CPU
DEBUG 01-13 08:46:25.484855.484855 lmp.py:1622]   Expert 10 |    158 | GPU
DEBUG 01-13 08:46:25.484782.484782 lmp.py:1622]   Expert  5 |    180 | GPU
DEBUG 01-13 08:46:25.484710.484710 lmp.py:1622]   Expert 34 |    182 | GPU
DEBUG 01-13 08:46:25.484638.484638 lmp.py:1622]   Expert 27 |    190 | GPU
DEBUG 01-13 08:46:25.484565.484565 lmp.py:1622]   Expert 45 |    191 | GPU
DEBUG 01-13 08:46:25.484016.484016 lmp.py:1622]   Expert 52 |    195 | GPU
DEBUG 01-13 08:46:25.484944.484944 lmp.py:1622]   Expert 48 |    201 | GPU
DEBUG 01-13 08:46:25.484825.484825 lmp.py:1622]   Expert 60 |    201 | GPU
DEBUG 01-13 08:46:25.484230.484230 lmp.py:1622]   Expert 56 |    210 | GPU
DEBUG 01-13 08:46:25.484873.484873 lmp.py:1622]   Expert 51 |    212 | GPU
DEBUG 01-13 08:46:25.484039.484039 lmp.py:1622]   Expert 53 |    223 | GPU
DEBUG 01-13 08:46:25.484397.484397 lmp.py:1622]   Expert  7 |    226 | GPU
DEBUG 01-13 08:46:25.485325.485325 lmp.py:1622]   Expert 24 |    228 | GPU
DEBUG 01-13 08:46:25.485776.485776 lmp.py:1622]   Expert  8 |    232 | GPU
DEBUG 01-13 08:46:25.485465.485465 lmp.py:1622]   Expert 57 |    254 | GPU
DEBUG 01-13 08:46:25.485155.485155 lmp.py:1622]   Expert 29 |    259 | GPU
DEBUG 01-13 08:46:25.485605.485605 lmp.py:1622]   Expert 47 |    260 | GPU
DEBUG 01-13 08:46:25.485056.485056 lmp.py:1622]   Expert 21 |    268 | GPU
DEBUG 01-13 08:46:25.485984.485984 lmp.py:1622]   Expert  0 |    284 | GPU
DEBUG 01-13 08:46:25.485673.485673 lmp.py:1622]   Expert  4 |    284 | GPU
DEBUG 01-13 08:46:25.485555.485555 lmp.py:1622]   Expert 14 |    292 | GPU
DEBUG 01-13 08:46:25.485198.485198 lmp.py:1622]   Expert 55 |    312 | GPU
DEBUG 01-13 08:46:25.485602.485602 lmp.py:1622]   Expert 22 |    316 | GPU
DEBUG 01-13 08:46:25.485007.485007 lmp.py:1622]   Expert 37 |    319 | GPU
DEBUG 01-13 08:46:25.485411.485411 lmp.py:1622]   Expert  1 |    324 | GPU
DEBUG 01-13 08:46:25.485101.485101 lmp.py:1622]   Expert 58 |    336 | GPU
DEBUG 01-13 08:46:25.485028.485028 lmp.py:1622]   Expert 54 |    340 | GPU
DEBUG 01-13 08:46:25.485718.485718 lmp.py:1622]   Expert 28 |    353 | GPU
DEBUG 01-13 08:46:25.485645.485645 lmp.py:1622]   Expert 12 |    373 | GPU
DEBUG 01-13 08:46:25.485096.485096 lmp.py:1622]   Expert 25 |    395 | GPU
DEBUG 01-13 08:46:25.485262.485262 lmp.py:1622]   Expert 11 |    404 | GPU
DEBUG 01-13 08:46:25.485713.485713 lmp.py:1622]   Expert 30 |    854 | GPU
DEBUG 01-13 08:46:25.485356.485356 lmp.py:1623] 
DEBUG 01-13 08:46:25.485356.485356 lmp.py:1623]   CPU total tokens: 3232 (26.3%)
DEBUG 01-13 08:46:25.485907.485907 lmp.py:1624]   GPU total tokens: 9056 (73.7%)
DEBUG 01-13 08:46:25.485510.485510 cuda_h.py:19] end experts_map_get cost 0.0017521381378173828 seconds
DEBUG 01-13 08:46:25.485897.485897 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-13 08:46:25.485328.485328 lmp.py:1632] 
DEBUG 01-13 08:46:25.485328.485328 lmp.py:1632]   Computing 32 experts on CPU MP...
DEBUG 01-13 08:46:25.485880.485880 cuda_h.py:19] end cpu_experts_submit cost 6.103515625e-05 seconds
DEBUG 01-13 08:46:25.485814.485814 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-13 08:46:25.485267.485267 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-13 08:46:25.485987.485987 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-13 08:46:25.486476.486476 cuda_h.py:19] end allocate_cuda_memory cost 0.0011317729949951172 seconds
DEBUG 01-13 08:46:25.487657.487657 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-13 08:46:25.487989.487989 sllm_store_c.py:27] get device uuid map
DEBUG 01-13 08:46:25.487990.487990 sllm_store_c.py:29] call client load into gpu
DEBUG 01-13 08:46:25.487024.487024 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 83f31205-9902-4553-9c8a-5a6a77bc1b02
DEBUG 01-13 08:46:25.487859.487859 client.py:106] call stub.LoadModelAsync
INFO 01-13 08:46:25.487499.487499 client.py:127] Model loaded
DEBUG 01-13 08:46:25.487733.487733 cuda_h.py:10] start restore2model
DEBUG 01-13 08:46:25.488290.488290 cuda_h.py:10] start experts_func_gpu_einsum_mp
DEBUG 01-13 08:46:25.488220.488220 cuda_h.py:19] end restore2model cost 0.0004341602325439453 seconds
DEBUG 01-13 08:46:25.488355.488355 cuda_h.py:19] end sllm_worker_task cost 0.01109004020690918 seconds
INFO 01-13 08:46:25.488782.488782 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 83f31205-9902-4553-9c8a-5a6a77bc1b02
DEBUG 01-13 08:46:25.488255.488255 cuda_h.py:19] end load_into_gpu_async cost 0.0015990734100341797 seconds
DEBUG 01-13 08:46:25.488534.488534 cuda_h.py:10] start restore_tensors2
DEBUG 01-13 08:46:25.489891.489891 cuda_h.py:19] end restore_tensors2 cost 0.0005486011505126953 seconds
DEBUG 01-13 08:46:25.489403.489403 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0036535263061523438 seconds
DEBUG 01-13 08:46:25.489027.489027 cuda_h.py:10] start restore2model
DEBUG 01-13 08:46:25.492661.492661 cuda_h.py:19] end restore2model cost 0.0032782554626464844 seconds
DEBUG 01-13 08:46:25.492809.492809 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.007134437561035156 seconds
DEBUG 01-13 08:46:25.492512.492512 cuda_h.py:10] start gpu_sexperts
DEBUG 01-13 08:46:25.493034.493034 cuda_h.py:19] end gpu_sexperts cost 0.00031280517578125 seconds
DEBUG 01-13 08:46:25.493247.493247 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-13 08:46:25.493501.493501 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 1.6927719116210938e-05 seconds
DEBUG 01-13 08:46:25.493389.493389 cuda_h.py:10] start wait_experts
INFO 01-13 08:46:25.493899.493899 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 83f31205-9902-4553-9c8a-5a6a77bc1b02
DEBUG 01-13 08:46:25.498952.498952 mlpmodule.py:1006] group tensors cost 0.009220361709594727 s
DEBUG 01-13 08:46:25.500178.500178 mlpmodule.py:1044] pad cost 0.0014944076538085938 s
DEBUG 01-13 08:46:25.500275.500275 mlpmodule.py:1050] create cpu tensor cost 5.412101745605469e-05 s
DEBUG 01-13 08:46:25.500502.500502 mlpmodule.py:1055] move to cpu cost 2.8133392333984375e-05 s
DEBUG 01-13 08:46:25.509853.509853 mlpmodule.py:1069] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-13 08:46:25.509849.509849 mlpmodule.py:1070] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-13 08:46:25.510217.510217 mlpmodule.py:1075] group_w3 first element: -0.006134033203125
WARNING 01-13 08:46:25.510898.510898 mlpmodule.py:1085] start einsum2
DEBUG 01-13 08:46:25.524372.524372 mlpmodule.py:1095] group einsum cost 0.024113178253173828 s
DEBUG 01-13 08:46:25.525114.525114 mlpmodule.py:1103] cpy2cputensor cost 0.0006651878356933594 s
INFO 01-13 08:46:25.540602.540602 client.py:127] Model loaded
DEBUG 01-13 08:46:25.540771.540771 cuda_h.py:19] end wait_experts cost 0.04718899726867676 seconds
DEBUG 01-13 08:46:25.540388.540388 cuda_h.py:10] start gpu_experts
DEBUG 01-13 08:46:25.541206.541206 mlpmodule.py:559] gpu group tensors cost 0.0005743503570556641 s
DEBUG 01-13 08:46:25.542199.542199 mlpmodule.py:592] gpu pad cost 0.0015103816986083984 s
DEBUG 01-13 08:46:25.542188.542188 mlpmodule.py:598] start_w1
DEBUG 01-13 08:46:25.543292.543292 mlpmodule.py:602] start_w3
DEBUG 01-13 08:46:25.543185.543185 mlpmodule.py:608] start_w2
DEBUG 01-13 08:46:25.543025.543025 mlpmodule.py:611] gpu group einsum cost 0.0006861686706542969 s
DEBUG 01-13 08:46:25.545026.545026 mlpmodule.py:683] gpu experts func einsum cost 0.005114316940307617 s
DEBUG 01-13 08:46:25.545685.545685 cuda_h.py:19] end gpu_experts cost 0.0052831172943115234 seconds
DEBUG 01-13 08:46:25.545296.545296 cuda_h.py:10] start cpu_thread_manager_mp_wait
DEBUG 01-13 08:46:25.545006.545006 cuda_h.py:19] end cpu_thread_manager_mp_wait cost 3.743171691894531e-05 seconds
DEBUG 01-13 08:46:25.545022.545022 cuda_h.py:19] end layer_moe_generate_mp_l_12 cost 0.06326436996459961 seconds
DEBUG 01-13 08:46:25.546494.546494 lmp.py:1550] -------------------------------- end prefill layer 11 --------------------------------
DEBUG 01-13 08:46:25.546430.546430 lmp.py:1493] -------------------------------- start prefill layer 12 --------------------------------
DEBUG 01-13 08:46:25.546325.546325 cuda_h.py:10] start start_load_qkvogn_s_weight_l_13
DEBUG 01-13 08:46:25.546650.546650 cuda_h.py:10] start start_load_qkvogn_s_weight_l_13
DEBUG 01-13 08:46:25.546394.546394 cuda_h.py:19] end start_load_qkvogn_s_weight_l_13 cost 3.147125244140625e-05 seconds
DEBUG 01-13 08:46:25.546713.546713 cuda_h.py:19] end start_load_qkvogn_s_weight_l_13 cost 5.9604644775390625e-05 seconds
DEBUG 01-13 08:46:25.546594.546594 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-13 08:46:25.546874.546874 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-13 08:46:25.546738.546738 cuda_h.py:10] start sllm_worker_task
DEBUG 01-13 08:46:25.546767.546767 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-13 08:46:25.546557.546557 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-13 08:46:25.547091.547091 cuda_h.py:19] end allocate_cuda_memory cost 0.0004627704620361328 seconds
DEBUG 01-13 08:46:25.547160.547160 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-13 08:46:25.547730.547730 sllm_store_c.py:27] get device uuid map
DEBUG 01-13 08:46:25.547315.547315 sllm_store_c.py:29] call client load into gpu
DEBUG 01-13 08:46:25.547587.547587 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, a32527d9-a083-421c-a98f-d7917bc942dc
DEBUG 01-13 08:46:25.547667.547667 mlpmodule.py:785]  experts func einsum cost 0.05849909782409668 s
DEBUG 01-13 08:46:25.547610.547610 client.py:106] call stub.LoadModelAsync
DEBUG 01-13 08:46:25.547419.547419 cuda_h.py:19] end experts_func_gpu_einsum_mp cost 0.0593717098236084 seconds
DEBUG 01-13 08:46:25.547002.547002 cuda_h.py:10] start self_attn
INFO 01-13 08:46:25.549611.549611 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, a32527d9-a083-421c-a98f-d7917bc942dc
DEBUG 01-13 08:46:25.549819.549819 cuda_h.py:19] end load_into_gpu_async cost 0.0018548965454101562 seconds
DEBUG 01-13 08:46:25.549145.549145 cuda_h.py:10] start restore_tensors2
DEBUG 01-13 08:46:25.549797.549797 cuda_h.py:19] end restore_tensors2 cost 6.747245788574219e-05 seconds
DEBUG 01-13 08:46:25.549884.549884 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.002650737762451172 seconds
INFO 01-13 08:46:25.549627.549627 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, a32527d9-a083-421c-a98f-d7917bc942dc
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-13 08:46:25.550055.550055 cuda_h.py:19] end self_attn cost 0.002892732620239258 seconds
DEBUG 01-13 08:46:25.550720.550720 cuda_h.py:19] end iln_self_attn_paln cost 0.0045244693756103516 seconds
DEBUG 01-13 08:46:25.551179.551179 cuda_h.py:10] start layer_moe_generate_mp_l_13
DEBUG 01-13 08:46:25.551081.551081 cuda_h.py:10] start gate
DEBUG 01-13 08:46:25.551428.551428 cuda_h.py:19] end gate cost 0.0006422996520996094 seconds
DEBUG 01-13 08:46:25.551873.551873 cuda_h.py:10] start experts_map_get
DEBUG 01-13 08:46:25.552890.552890 lmp.py:1611] 
DEBUG 01-13 08:46:25.552890.552890 lmp.py:1611] Expert Token Distribution & Device Allocation:
DEBUG 01-13 08:46:25.552407.552407 lmp.py:1612]   Total experts: 64
DEBUG 01-13 08:46:25.552580.552580 lmp.py:1613]   CPU experts: 32 (50%)
DEBUG 01-13 08:46:25.552892.552892 lmp.py:1614]   GPU experts: 32 (50%)
DEBUG 01-13 08:46:25.552535.552535 lmp.py:1615] 
DEBUG 01-13 08:46:25.552535.552535 lmp.py:1615]   Expert ID | Tokens | Device
DEBUG 01-13 08:46:25.552939.552939 lmp.py:1616]   -----------------------------------
DEBUG 01-13 08:46:25.552112.552112 lmp.py:1622]   Expert 12 |     17 | CPU
DEBUG 01-13 08:46:25.552994.552994 lmp.py:1622]   Expert 47 |     23 | CPU
DEBUG 01-13 08:46:25.552445.552445 lmp.py:1622]   Expert 38 |     29 | CPU
DEBUG 01-13 08:46:25.552657.552657 lmp.py:1622]   Expert 27 |     30 | CPU
DEBUG 01-13 08:46:25.552870.552870 lmp.py:1622]   Expert 16 |     36 | CPU
DEBUG 01-13 08:46:25.552274.552274 lmp.py:1622]   Expert 52 |     38 | CPU
DEBUG 01-13 08:46:25.552963.552963 lmp.py:1622]   Expert 63 |     42 | CPU
DEBUG 01-13 08:46:25.552891.552891 lmp.py:1622]   Expert  4 |     56 | CPU
DEBUG 01-13 08:46:25.552819.552819 lmp.py:1622]   Expert 61 |     58 | CPU
DEBUG 01-13 08:46:25.552031.552031 lmp.py:1622]   Expert 43 |     60 | CPU
DEBUG 01-13 08:46:25.552065.552065 lmp.py:1622]   Expert 44 |     64 | CPU
DEBUG 01-13 08:46:25.552278.552278 lmp.py:1622]   Expert 34 |     70 | CPU
DEBUG 01-13 08:46:25.552729.552729 lmp.py:1622]   Expert 53 |     81 | CPU
DEBUG 01-13 08:46:25.552418.552418 lmp.py:1622]   Expert  0 |     84 | CPU
DEBUG 01-13 08:46:25.552154.552154 lmp.py:1622]   Expert 32 |     89 | CPU
DEBUG 01-13 08:46:25.552366.552366 lmp.py:1622]   Expert 37 |     90 | CPU
DEBUG 01-13 08:46:25.552863.552863 lmp.py:1622]   Expert 13 |     94 | CPU
DEBUG 01-13 08:46:25.552076.552076 lmp.py:1622]   Expert 39 |    108 | CPU
DEBUG 01-13 08:46:25.552765.552765 lmp.py:1622]   Expert 21 |    113 | CPU
DEBUG 01-13 08:46:25.552315.552315 lmp.py:1622]   Expert 11 |    117 | CPU
DEBUG 01-13 08:46:25.552481.552481 lmp.py:1622]   Expert 20 |    124 | CPU
DEBUG 01-13 08:46:25.552409.552409 lmp.py:1622]   Expert 60 |    131 | CPU
DEBUG 01-13 08:46:25.552337.552337 lmp.py:1622]   Expert 14 |    134 | CPU
DEBUG 01-13 08:46:25.552788.552788 lmp.py:1622]   Expert  8 |    136 | CPU
DEBUG 01-13 08:46:25.552523.552523 lmp.py:1622]   Expert 57 |    140 | CPU
DEBUG 01-13 08:46:25.552974.552974 lmp.py:1622]   Expert 22 |    144 | CPU
DEBUG 01-13 08:46:25.552187.552187 lmp.py:1622]   Expert  2 |    153 | CPU
DEBUG 01-13 08:46:25.552161.552161 lmp.py:1622]   Expert  7 |    156 | CPU
DEBUG 01-13 08:46:25.552135.552135 lmp.py:1622]   Expert 17 |    158 | CPU
DEBUG 01-13 08:46:25.552586.552586 lmp.py:1622]   Expert 45 |    158 | CPU
DEBUG 01-13 08:46:25.552560.552560 lmp.py:1622]   Expert 18 |    159 | CPU
DEBUG 01-13 08:46:25.552295.552295 lmp.py:1622]   Expert 30 |    163 | CPU
DEBUG 01-13 08:46:25.552462.552462 lmp.py:1622]   Expert 23 |    165 | GPU
DEBUG 01-13 08:46:25.552058.552058 lmp.py:1622]   Expert 58 |    165 | GPU
DEBUG 01-13 08:46:25.552940.552940 lmp.py:1622]   Expert 42 |    168 | GPU
DEBUG 01-13 08:46:25.552821.552821 lmp.py:1622]   Expert 48 |    174 | GPU
DEBUG 01-13 08:46:25.552510.552510 lmp.py:1622]   Expert 55 |    174 | GPU
DEBUG 01-13 08:46:25.552438.552438 lmp.py:1622]   Expert 49 |    180 | GPU
DEBUG 01-13 08:46:25.552366.552366 lmp.py:1622]   Expert 51 |    183 | GPU
DEBUG 01-13 08:46:25.552293.552293 lmp.py:1622]   Expert 62 |    183 | GPU
DEBUG 01-13 08:46:25.552983.552983 lmp.py:1622]   Expert 29 |    184 | GPU
DEBUG 01-13 08:46:25.552434.552434 lmp.py:1622]   Expert 35 |    185 | GPU
DEBUG 01-13 08:46:25.552123.552123 lmp.py:1622]   Expert  6 |    194 | GPU
DEBUG 01-13 08:46:25.552051.552051 lmp.py:1622]   Expert 25 |    196 | GPU
DEBUG 01-13 08:46:25.552978.552978 lmp.py:1622]   Expert  1 |    200 | GPU
DEBUG 01-13 08:46:25.552860.552860 lmp.py:1622]   Expert 36 |    200 | GPU
DEBUG 01-13 08:46:25.553741.553741 lmp.py:1622]   Expert 31 |    208 | GPU
DEBUG 01-13 08:46:25.553384.553384 lmp.py:1622]   Expert 28 |    221 | GPU
DEBUG 01-13 08:46:25.553027.553027 lmp.py:1622]   Expert 41 |    223 | GPU
DEBUG 01-13 08:46:25.553955.553955 lmp.py:1622]   Expert 54 |    229 | GPU
DEBUG 01-13 08:46:25.553121.553121 lmp.py:1622]   Expert  5 |    230 | GPU
DEBUG 01-13 08:46:25.553049.553049 lmp.py:1622]   Expert 19 |    233 | GPU
DEBUG 01-13 08:46:25.553976.553976 lmp.py:1622]   Expert 24 |    238 | GPU
DEBUG 01-13 08:46:25.553666.553666 lmp.py:1622]   Expert  9 |    244 | GPU
DEBUG 01-13 08:46:25.553355.553355 lmp.py:1622]   Expert 50 |    284 | GPU
DEBUG 01-13 08:46:25.553044.553044 lmp.py:1622]   Expert 59 |    305 | GPU
DEBUG 01-13 08:46:25.553972.553972 lmp.py:1622]   Expert 46 |    313 | GPU
DEBUG 01-13 08:46:25.553377.553377 lmp.py:1622]   Expert 56 |    383 | GPU
DEBUG 01-13 08:46:25.553304.553304 lmp.py:1622]   Expert 26 |    394 | GPU
DEBUG 01-13 08:46:25.553709.553709 lmp.py:1622]   Expert 33 |    425 | GPU
DEBUG 01-13 08:46:25.553590.553590 lmp.py:1622]   Expert  3 |    589 | GPU
DEBUG 01-13 08:46:25.553810.553810 lmp.py:1622]   Expert 15 |    668 | GPU
DEBUG 01-13 08:46:25.553976.553976 lmp.py:1622]   Expert 10 |    710 | GPU
DEBUG 01-13 08:46:25.553950.553950 lmp.py:1622]   Expert 40 |    785 | GPU
DEBUG 01-13 08:46:25.553354.553354 lmp.py:1623] 
DEBUG 01-13 08:46:25.553354.553354 lmp.py:1623]   CPU total tokens: 3055 (24.9%)
DEBUG 01-13 08:46:25.553759.553759 lmp.py:1624]   GPU total tokens: 9233 (75.1%)
DEBUG 01-13 08:46:25.553978.553978 cuda_h.py:19] end experts_map_get cost 0.001523733139038086 seconds
DEBUG 01-13 08:46:25.553205.553205 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-13 08:46:25.553292.553292 lmp.py:1632] 
DEBUG 01-13 08:46:25.553292.553292 lmp.py:1632]   Computing 32 experts on CPU MP...
DEBUG 01-13 08:46:25.553930.553930 cuda_h.py:19] end cpu_experts_submit cost 4.839897155761719e-05 seconds
DEBUG 01-13 08:46:25.553885.553885 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-13 08:46:25.553760.553760 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-13 08:46:25.553348.553348 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-13 08:46:25.555579.555579 cuda_h.py:19] end allocate_cuda_memory cost 0.0017116069793701172 seconds
DEBUG 01-13 08:46:25.555644.555644 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-13 08:46:25.555844.555844 sllm_store_c.py:27] get device uuid map
DEBUG 01-13 08:46:25.555104.555104 sllm_store_c.py:29] call client load into gpu
DEBUG 01-13 08:46:25.555046.555046 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 5bd4a112-be64-4d33-9751-27a9850e1131
DEBUG 01-13 08:46:25.556377.556377 client.py:106] call stub.LoadModelAsync
DEBUG 01-13 08:46:25.556717.556717 cuda_h.py:10] start experts_func_gpu_einsum_mp
INFO 01-13 08:46:25.557510.557510 client.py:127] Model loaded
DEBUG 01-13 08:46:25.557016.557016 cuda_h.py:10] start restore2model
DEBUG 01-13 08:46:25.557747.557747 cuda_h.py:19] end restore2model cost 0.00042748451232910156 seconds
DEBUG 01-13 08:46:25.557007.557007 cuda_h.py:19] end sllm_worker_task cost 0.011102676391601562 seconds
INFO 01-13 08:46:25.558275.558275 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 5bd4a112-be64-4d33-9751-27a9850e1131
DEBUG 01-13 08:46:25.558124.558124 cuda_h.py:19] end load_into_gpu_async cost 0.0026259422302246094 seconds
DEBUG 01-13 08:46:25.558496.558496 cuda_h.py:10] start restore_tensors2
DEBUG 01-13 08:46:25.558458.558458 cuda_h.py:19] end restore_tensors2 cost 0.0003972053527832031 seconds
DEBUG 01-13 08:46:25.559009.559009 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.005415201187133789 seconds
DEBUG 01-13 08:46:25.559964.559964 cuda_h.py:10] start restore2model
DEBUG 01-13 08:46:25.561930.561930 cuda_h.py:19] end restore2model cost 0.002719402313232422 seconds
DEBUG 01-13 08:46:25.561701.561701 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.008339881896972656 seconds
DEBUG 01-13 08:46:25.561517.561517 cuda_h.py:10] start gpu_sexperts
DEBUG 01-13 08:46:25.562818.562818 cuda_h.py:19] end gpu_sexperts cost 0.00026297569274902344 seconds
DEBUG 01-13 08:46:25.562886.562886 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-13 08:46:25.562848.562848 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 1.4066696166992188e-05 seconds
DEBUG 01-13 08:46:25.562590.562590 cuda_h.py:10] start wait_experts
INFO 01-13 08:46:25.562386.562386 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 5bd4a112-be64-4d33-9751-27a9850e1131
DEBUG 01-13 08:46:25.574117.574117 mlpmodule.py:1006] group tensors cost 0.01726388931274414 s
DEBUG 01-13 08:46:25.577561.577561 mlpmodule.py:1044] pad cost 0.0018000602722167969 s
DEBUG 01-13 08:46:25.577446.577446 mlpmodule.py:1050] create cpu tensor cost 5.340576171875e-05 s
DEBUG 01-13 08:46:25.577455.577455 mlpmodule.py:1055] move to cpu cost 4.0531158447265625e-05 s
DEBUG 01-13 08:46:25.587233.587233 mlpmodule.py:1069] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-13 08:46:25.587289.587289 mlpmodule.py:1070] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-13 08:46:25.587595.587595 mlpmodule.py:1075] group_w3 first element: -0.0162353515625
WARNING 01-13 08:46:25.588795.588795 mlpmodule.py:1085] start einsum2
DEBUG 01-13 08:46:25.603853.603853 mlpmodule.py:1095] group einsum cost 0.026248455047607422 s
DEBUG 01-13 08:46:25.604987.604987 mlpmodule.py:1103] cpy2cputensor cost 0.0006814002990722656 s
INFO 01-13 08:46:25.610535.610535 client.py:127] Model loaded
DEBUG 01-13 08:46:25.610102.610102 cuda_h.py:19] end wait_experts cost 0.048089027404785156 seconds
DEBUG 01-13 08:46:25.610819.610819 cuda_h.py:10] start gpu_experts
DEBUG 01-13 08:46:25.611847.611847 mlpmodule.py:559] gpu group tensors cost 0.0007226467132568359 s
DEBUG 01-13 08:46:25.613807.613807 mlpmodule.py:592] gpu pad cost 0.0018930435180664062 s
DEBUG 01-13 08:46:25.613763.613763 mlpmodule.py:598] start_w1
DEBUG 01-13 08:46:25.613260.613260 mlpmodule.py:602] start_w3
DEBUG 01-13 08:46:25.613346.613346 mlpmodule.py:608] start_w2
DEBUG 01-13 08:46:25.614504.614504 mlpmodule.py:611] gpu group einsum cost 0.0007894039154052734 s
DEBUG 01-13 08:46:25.616536.616536 mlpmodule.py:683] gpu experts func einsum cost 0.006288051605224609 s
DEBUG 01-13 08:46:25.616718.616718 cuda_h.py:19] end gpu_experts cost 0.006460905075073242 seconds
DEBUG 01-13 08:46:25.617527.617527 cuda_h.py:10] start cpu_thread_manager_mp_wait
DEBUG 01-13 08:46:25.617914.617914 cuda_h.py:19] end cpu_thread_manager_mp_wait cost 4.029273986816406e-05 seconds
DEBUG 01-13 08:46:25.617222.617222 cuda_h.py:19] end layer_moe_generate_mp_l_13 cost 0.0661170482635498 seconds
DEBUG 01-13 08:46:25.617092.617092 lmp.py:1550] -------------------------------- end prefill layer 12 --------------------------------
DEBUG 01-13 08:46:25.617147.617147 lmp.py:1493] -------------------------------- start prefill layer 13 --------------------------------
DEBUG 01-13 08:46:25.617949.617949 cuda_h.py:10] start start_load_qkvogn_s_weight_l_14
DEBUG 01-13 08:46:25.617089.617089 cuda_h.py:10] start start_load_qkvogn_s_weight_l_14
DEBUG 01-13 08:46:25.617184.617184 cuda_h.py:19] end start_load_qkvogn_s_weight_l_14 cost 3.719329833984375e-05 seconds
DEBUG 01-13 08:46:25.617133.617133 cuda_h.py:10] start sllm_worker_task
DEBUG 01-13 08:46:25.617585.617585 cuda_h.py:19] end start_load_qkvogn_s_weight_l_14 cost 0.00016021728515625 seconds
DEBUG 01-13 08:46:25.617847.617847 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-13 08:46:25.617491.617491 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-13 08:46:25.617076.617076 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-13 08:46:25.618904.618904 cuda_h.py:19] end allocate_cuda_memory cost 0.0003046989440917969 seconds
DEBUG 01-13 08:46:25.618040.618040 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-13 08:46:25.618691.618691 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-13 08:46:25.618509.618509 sllm_store_c.py:27] get device uuid map
DEBUG 01-13 08:46:25.618769.618769 sllm_store_c.py:29] call client load into gpu
DEBUG 01-13 08:46:25.618764.618764 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 898b8794-12a3-4d3c-9cd0-e6cd9b1c724a
DEBUG 01-13 08:46:25.618661.618661 client.py:106] call stub.LoadModelAsync
DEBUG 01-13 08:46:25.619633.619633 mlpmodule.py:785]  experts func einsum cost 0.06178164482116699 s
DEBUG 01-13 08:46:25.619334.619334 cuda_h.py:19] end experts_func_gpu_einsum_mp cost 0.06246066093444824 seconds
DEBUG 01-13 08:46:25.619857.619857 cuda_h.py:10] start self_attn
INFO 01-13 08:46:25.619361.619361 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 898b8794-12a3-4d3c-9cd0-e6cd9b1c724a
DEBUG 01-13 08:46:25.619449.619449 cuda_h.py:19] end load_into_gpu_async cost 0.0009744167327880859 seconds
DEBUG 01-13 08:46:25.619967.619967 cuda_h.py:10] start restore_tensors2
DEBUG 01-13 08:46:25.619864.619864 cuda_h.py:19] end restore_tensors2 cost 7.081031799316406e-05 seconds
DEBUG 01-13 08:46:25.619528.619528 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.001836538314819336 seconds
INFO 01-13 08:46:25.619940.619940 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 898b8794-12a3-4d3c-9cd0-e6cd9b1c724a
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-13 08:46:25.622668.622668 cuda_h.py:19] end self_attn cost 0.0035915374755859375 seconds
DEBUG 01-13 08:46:25.623215.623215 cuda_h.py:19] end iln_self_attn_paln cost 0.005066633224487305 seconds
DEBUG 01-13 08:46:25.623720.623720 cuda_h.py:10] start layer_moe_generate_mp_l_14
DEBUG 01-13 08:46:25.623682.623682 cuda_h.py:10] start gate
DEBUG 01-13 08:46:25.623121.623121 cuda_h.py:19] end gate cost 0.0006401538848876953 seconds
DEBUG 01-13 08:46:25.623097.623097 cuda_h.py:10] start experts_map_get
DEBUG 01-13 08:46:25.624974.624974 lmp.py:1611] 
DEBUG 01-13 08:46:25.624974.624974 lmp.py:1611] Expert Token Distribution & Device Allocation:
DEBUG 01-13 08:46:25.624777.624777 lmp.py:1612]   Total experts: 64
DEBUG 01-13 08:46:25.624711.624711 lmp.py:1613]   CPU experts: 32 (50%)
DEBUG 01-13 08:46:25.624308.624308 lmp.py:1614]   GPU experts: 32 (50%)
DEBUG 01-13 08:46:25.624858.624858 lmp.py:1615] 
DEBUG 01-13 08:46:25.624858.624858 lmp.py:1615]   Expert ID | Tokens | Device
DEBUG 01-13 08:46:25.624786.624786 lmp.py:1616]   -----------------------------------
DEBUG 01-13 08:46:25.624324.624324 lmp.py:1622]   Expert 42 |     23 | CPU
DEBUG 01-13 08:46:25.624682.624682 lmp.py:1622]   Expert 19 |     24 | CPU
DEBUG 01-13 08:46:25.624371.624371 lmp.py:1622]   Expert 30 |     24 | CPU
DEBUG 01-13 08:46:25.624345.624345 lmp.py:1622]   Expert 32 |     36 | CPU
DEBUG 01-13 08:46:25.624319.624319 lmp.py:1622]   Expert  6 |     53 | CPU
DEBUG 01-13 08:46:25.624293.624293 lmp.py:1622]   Expert 53 |     73 | CPU
DEBUG 01-13 08:46:25.624029.624029 lmp.py:1622]   Expert  1 |     80 | CPU
DEBUG 01-13 08:46:25.624480.624480 lmp.py:1622]   Expert  5 |     84 | CPU
DEBUG 01-13 08:46:25.624454.624454 lmp.py:1622]   Expert 13 |    111 | CPU
DEBUG 01-13 08:46:25.624190.624190 lmp.py:1622]   Expert  9 |    119 | CPU
DEBUG 01-13 08:46:25.624164.624164 lmp.py:1622]   Expert 31 |    129 | CPU
DEBUG 01-13 08:46:25.624899.624899 lmp.py:1622]   Expert 18 |    130 | CPU
DEBUG 01-13 08:46:25.624873.624873 lmp.py:1622]   Expert 34 |    130 | CPU
DEBUG 01-13 08:46:25.624801.624801 lmp.py:1622]   Expert 58 |    130 | CPU
DEBUG 01-13 08:46:25.624490.624490 lmp.py:1622]   Expert 63 |    130 | CPU
DEBUG 01-13 08:46:25.624703.624703 lmp.py:1622]   Expert 26 |    131 | CPU
DEBUG 01-13 08:46:25.624677.624677 lmp.py:1622]   Expert 50 |    137 | CPU
DEBUG 01-13 08:46:25.624174.624174 lmp.py:1622]   Expert 59 |    139 | CPU
DEBUG 01-13 08:46:25.624148.624148 lmp.py:1622]   Expert 56 |    140 | CPU
DEBUG 01-13 08:46:25.624645.624645 lmp.py:1622]   Expert 11 |    145 | CPU
DEBUG 01-13 08:46:25.624619.624619 lmp.py:1622]   Expert 40 |    145 | CPU
DEBUG 01-13 08:46:25.624593.624593 lmp.py:1622]   Expert  2 |    148 | CPU
DEBUG 01-13 08:46:25.624091.624091 lmp.py:1622]   Expert 12 |    149 | CPU
DEBUG 01-13 08:46:25.624065.624065 lmp.py:1622]   Expert 46 |    150 | CPU
DEBUG 01-13 08:46:25.624800.624800 lmp.py:1622]   Expert 20 |    151 | CPU
DEBUG 01-13 08:46:25.624774.624774 lmp.py:1622]   Expert 61 |    153 | CPU
DEBUG 01-13 08:46:25.624510.624510 lmp.py:1622]   Expert  4 |    156 | CPU
DEBUG 01-13 08:46:25.624676.624676 lmp.py:1622]   Expert 48 |    156 | CPU
DEBUG 01-13 08:46:25.624365.624365 lmp.py:1622]   Expert 33 |    158 | CPU
DEBUG 01-13 08:46:25.624816.624816 lmp.py:1622]   Expert 10 |    164 | CPU
DEBUG 01-13 08:46:25.624982.624982 lmp.py:1622]   Expert 55 |    167 | CPU
DEBUG 01-13 08:46:25.624956.624956 lmp.py:1622]   Expert 51 |    169 | CPU
DEBUG 01-13 08:46:25.624930.624930 lmp.py:1622]   Expert 35 |    172 | GPU
DEBUG 01-13 08:46:25.624428.624428 lmp.py:1622]   Expert 36 |    176 | GPU
DEBUG 01-13 08:46:25.624402.624402 lmp.py:1622]   Expert  8 |    185 | GPU
DEBUG 01-13 08:46:25.624376.624376 lmp.py:1622]   Expert 52 |    190 | GPU
DEBUG 01-13 08:46:25.624873.624873 lmp.py:1622]   Expert 37 |    192 | GPU
DEBUG 01-13 08:46:25.624847.624847 lmp.py:1622]   Expert 57 |    202 | GPU
DEBUG 01-13 08:46:25.625344.625344 lmp.py:1622]   Expert  0 |    203 | GPU
DEBUG 01-13 08:46:25.625080.625080 lmp.py:1622]   Expert 39 |    215 | GPU
DEBUG 01-13 08:46:25.625531.625531 lmp.py:1622]   Expert 25 |    232 | GPU
DEBUG 01-13 08:46:25.625220.625220 lmp.py:1622]   Expert 62 |    232 | GPU
DEBUG 01-13 08:46:25.625671.625671 lmp.py:1622]   Expert 38 |    246 | GPU
DEBUG 01-13 08:46:25.625122.625122 lmp.py:1622]   Expert 27 |    251 | GPU
DEBUG 01-13 08:46:25.625334.625334 lmp.py:1622]   Expert  7 |    252 | GPU
DEBUG 01-13 08:46:25.625070.625070 lmp.py:1622]   Expert 28 |    254 | GPU
DEBUG 01-13 08:46:25.625567.625567 lmp.py:1622]   Expert 60 |    254 | GPU
DEBUG 01-13 08:46:25.625064.625064 lmp.py:1622]   Expert 16 |    257 | GPU
DEBUG 01-13 08:46:25.625800.625800 lmp.py:1622]   Expert  3 |    258 | GPU
DEBUG 01-13 08:46:25.625535.625535 lmp.py:1622]   Expert 21 |    258 | GPU
DEBUG 01-13 08:46:25.625271.625271 lmp.py:1622]   Expert 24 |    268 | GPU
DEBUG 01-13 08:46:25.625007.625007 lmp.py:1622]   Expert 43 |    269 | GPU
DEBUG 01-13 08:46:25.625219.625219 lmp.py:1622]   Expert 49 |    269 | GPU
DEBUG 01-13 08:46:25.625955.625955 lmp.py:1622]   Expert 29 |    274 | GPU
DEBUG 01-13 08:46:25.625644.625644 lmp.py:1622]   Expert 23 |    285 | GPU
DEBUG 01-13 08:46:25.625572.625572 lmp.py:1622]   Expert 22 |    287 | GPU
DEBUG 01-13 08:46:25.625261.625261 lmp.py:1622]   Expert 15 |    294 | GPU
DEBUG 01-13 08:46:25.625712.625712 lmp.py:1622]   Expert 47 |    296 | GPU
DEBUG 01-13 08:46:25.625163.625163 lmp.py:1622]   Expert 41 |    297 | GPU
DEBUG 01-13 08:46:25.625137.625137 lmp.py:1622]   Expert 44 |    297 | GPU
DEBUG 01-13 08:46:25.625634.625634 lmp.py:1622]   Expert 54 |    368 | GPU
DEBUG 01-13 08:46:25.625370.625370 lmp.py:1622]   Expert 14 |    374 | GPU
DEBUG 01-13 08:46:25.625013.625013 lmp.py:1622]   Expert 17 |    403 | GPU
DEBUG 01-13 08:46:25.625940.625940 lmp.py:1622]   Expert 45 |    444 | GPU
DEBUG 01-13 08:46:25.625583.625583 lmp.py:1623] 
DEBUG 01-13 08:46:25.625583.625583 lmp.py:1623]   CPU total tokens: 3834 (31.2%)
DEBUG 01-13 08:46:25.625703.625703 lmp.py:1624]   GPU total tokens: 8454 (68.8%)
DEBUG 01-13 08:46:25.625115.625115 cuda_h.py:19] end experts_map_get cost 0.0014941692352294922 seconds
DEBUG 01-13 08:46:25.625726.625726 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-13 08:46:25.625581.625581 lmp.py:1632] 
DEBUG 01-13 08:46:25.625581.625581 lmp.py:1632]   Computing 32 experts on CPU MP...
DEBUG 01-13 08:46:25.625378.625378 cuda_h.py:19] end cpu_experts_submit cost 5.412101745605469e-05 seconds
DEBUG 01-13 08:46:25.625359.625359 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-13 08:46:25.625427.625427 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-13 08:46:25.625657.625657 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-13 08:46:25.626307.626307 cuda_h.py:19] end allocate_cuda_memory cost 0.0002720355987548828 seconds
DEBUG 01-13 08:46:25.626051.626051 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-13 08:46:25.626099.626099 sllm_store_c.py:27] get device uuid map
DEBUG 01-13 08:46:25.626584.626584 sllm_store_c.py:29] call client load into gpu
DEBUG 01-13 08:46:25.626710.626710 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 1d62f44a-c387-4e78-b130-9cc8fb378730
DEBUG 01-13 08:46:25.626662.626662 cuda_h.py:10] start experts_func_gpu_einsum_mp
DEBUG 01-13 08:46:25.626757.626757 client.py:106] call stub.LoadModelAsync
INFO 01-13 08:46:25.627392.627392 client.py:127] Model loaded
DEBUG 01-13 08:46:25.627143.627143 cuda_h.py:10] start restore2model
DEBUG 01-13 08:46:25.627460.627460 cuda_h.py:19] end restore2model cost 0.0003418922424316406 seconds
DEBUG 01-13 08:46:25.627230.627230 cuda_h.py:19] end sllm_worker_task cost 0.00967097282409668 seconds
INFO 01-13 08:46:25.627058.627058 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 1d62f44a-c387-4e78-b130-9cc8fb378730
DEBUG 01-13 08:46:25.627901.627901 cuda_h.py:19] end load_into_gpu_async cost 0.0012216567993164062 seconds
DEBUG 01-13 08:46:25.627558.627558 cuda_h.py:10] start restore_tensors2
DEBUG 01-13 08:46:25.628731.628731 cuda_h.py:19] end restore_tensors2 cost 0.00037980079650878906 seconds
DEBUG 01-13 08:46:25.628375.628375 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0025720596313476562 seconds
DEBUG 01-13 08:46:25.628714.628714 cuda_h.py:10] start restore2model
DEBUG 01-13 08:46:25.631130.631130 cuda_h.py:19] end restore2model cost 0.002699613571166992 seconds
DEBUG 01-13 08:46:25.631072.631072 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.005454063415527344 seconds
DEBUG 01-13 08:46:25.631345.631345 cuda_h.py:10] start gpu_sexperts
DEBUG 01-13 08:46:25.631905.631905 cuda_h.py:19] end gpu_sexperts cost 0.0002765655517578125 seconds
DEBUG 01-13 08:46:25.631304.631304 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-13 08:46:25.631557.631557 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 1.9073486328125e-05 seconds
DEBUG 01-13 08:46:25.631207.631207 cuda_h.py:10] start wait_experts
INFO 01-13 08:46:25.631572.631572 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 1d62f44a-c387-4e78-b130-9cc8fb378730
DEBUG 01-13 08:46:25.636702.636702 mlpmodule.py:1006] group tensors cost 0.009439706802368164 s
DEBUG 01-13 08:46:25.639621.639621 mlpmodule.py:1044] pad cost 0.0015561580657958984 s
DEBUG 01-13 08:46:25.639777.639777 mlpmodule.py:1050] create cpu tensor cost 6.031990051269531e-05 s
DEBUG 01-13 08:46:25.639342.639342 mlpmodule.py:1055] move to cpu cost 3.0279159545898438e-05 s
DEBUG 01-13 08:46:25.647320.647320 mlpmodule.py:1069] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-13 08:46:25.647237.647237 mlpmodule.py:1070] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-13 08:46:25.647797.647797 mlpmodule.py:1075] group_w3 first element: -0.0211181640625
WARNING 01-13 08:46:25.647577.647577 mlpmodule.py:1085] start einsum2
DEBUG 01-13 08:46:25.661350.661350 mlpmodule.py:1095] group einsum cost 0.022121429443359375 s
DEBUG 01-13 08:46:25.662973.662973 mlpmodule.py:1103] cpy2cputensor cost 0.0006844997406005859 s
INFO 01-13 08:46:25.679014.679014 client.py:127] Model loaded
DEBUG 01-13 08:46:25.679455.679455 cuda_h.py:19] end wait_experts cost 0.047722816467285156 seconds
DEBUG 01-13 08:46:25.679118.679118 cuda_h.py:10] start gpu_experts
DEBUG 01-13 08:46:25.680764.680764 mlpmodule.py:559] gpu group tensors cost 0.0005941390991210938 s
DEBUG 01-13 08:46:25.681770.681770 mlpmodule.py:785]  experts func einsum cost 0.0536198616027832 s
DEBUG 01-13 08:46:25.681569.681569 cuda_h.py:19] end experts_func_gpu_einsum_mp cost 0.0544581413269043 seconds
DEBUG 01-13 08:46:25.681427.681427 mlpmodule.py:592] gpu pad cost 0.0015454292297363281 s
DEBUG 01-13 08:46:25.681608.681608 mlpmodule.py:598] start_w1
DEBUG 01-13 08:46:25.682076.682076 mlpmodule.py:602] start_w3
DEBUG 01-13 08:46:25.682261.682261 mlpmodule.py:608] start_w2
DEBUG 01-13 08:46:25.682756.682756 mlpmodule.py:611] gpu group einsum cost 0.0006694793701171875 s
DEBUG 01-13 08:46:25.684060.684060 mlpmodule.py:683] gpu experts func einsum cost 0.00510096549987793 s
DEBUG 01-13 08:46:25.684897.684897 cuda_h.py:19] end gpu_experts cost 0.005251884460449219 seconds
DEBUG 01-13 08:46:25.684561.684561 cuda_h.py:10] start cpu_thread_manager_mp_wait
DEBUG 01-13 08:46:25.684364.684364 cuda_h.py:19] end cpu_thread_manager_mp_wait cost 3.719329833984375e-05 seconds
DEBUG 01-13 08:46:25.684950.684950 cuda_h.py:19] end layer_moe_generate_mp_l_14 cost 0.06161952018737793 seconds
DEBUG 01-13 08:46:25.685547.685547 lmp.py:1550] -------------------------------- end prefill layer 13 --------------------------------
DEBUG 01-13 08:46:25.685641.685641 lmp.py:1493] -------------------------------- start prefill layer 14 --------------------------------
DEBUG 01-13 08:46:25.685198.685198 cuda_h.py:10] start start_load_qkvogn_s_weight_l_15
DEBUG 01-13 08:46:25.685808.685808 cuda_h.py:10] start start_load_qkvogn_s_weight_l_15
DEBUG 01-13 08:46:25.685174.685174 cuda_h.py:19] end start_load_qkvogn_s_weight_l_15 cost 3.0994415283203125e-05 seconds
DEBUG 01-13 08:46:25.685877.685877 cuda_h.py:19] end start_load_qkvogn_s_weight_l_15 cost 6.365776062011719e-05 seconds
DEBUG 01-13 08:46:25.685189.685189 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-13 08:46:25.685132.685132 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-13 08:46:25.685565.685565 cuda_h.py:10] start sllm_worker_task
DEBUG 01-13 08:46:25.685117.685117 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-13 08:46:25.685854.685854 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-13 08:46:25.685647.685647 cuda_h.py:19] end allocate_cuda_memory cost 0.0003032684326171875 seconds
DEBUG 01-13 08:46:25.685617.685617 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-13 08:46:25.685903.685903 sllm_store_c.py:27] get device uuid map
DEBUG 01-13 08:46:25.686540.686540 sllm_store_c.py:29] call client load into gpu
DEBUG 01-13 08:46:25.686528.686528 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 469c3da1-664d-412b-adc9-6fff37a741b8
DEBUG 01-13 08:46:25.686636.686636 client.py:106] call stub.LoadModelAsync
DEBUG 01-13 08:46:25.686604.686604 cuda_h.py:10] start self_attn
INFO 01-13 08:46:25.686153.686153 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 469c3da1-664d-412b-adc9-6fff37a741b8
DEBUG 01-13 08:46:25.686413.686413 cuda_h.py:19] end load_into_gpu_async cost 0.0010082721710205078 seconds
DEBUG 01-13 08:46:25.687447.687447 cuda_h.py:10] start restore_tensors2
DEBUG 01-13 08:46:25.687768.687768 cuda_h.py:19] end restore_tensors2 cost 7.081031799316406e-05 seconds
DEBUG 01-13 08:46:25.687332.687332 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0016369819641113281 seconds
INFO 01-13 08:46:25.687487.687487 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 469c3da1-664d-412b-adc9-6fff37a741b8
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-13 08:46:25.689061.689061 cuda_h.py:19] end self_attn cost 0.0035071372985839844 seconds
DEBUG 01-13 08:46:25.690614.690614 cuda_h.py:19] end iln_self_attn_paln cost 0.0049550533294677734 seconds
DEBUG 01-13 08:46:25.690404.690404 cuda_h.py:10] start layer_moe_generate_mp_l_15
DEBUG 01-13 08:46:25.690783.690783 cuda_h.py:10] start gate
DEBUG 01-13 08:46:25.691981.691981 cuda_h.py:19] end gate cost 0.0007455348968505859 seconds
DEBUG 01-13 08:46:25.691380.691380 cuda_h.py:10] start experts_map_get
DEBUG 01-13 08:46:25.691403.691403 lmp.py:1611] 
DEBUG 01-13 08:46:25.691403.691403 lmp.py:1611] Expert Token Distribution & Device Allocation:
DEBUG 01-13 08:46:25.691159.691159 lmp.py:1612]   Total experts: 64
DEBUG 01-13 08:46:25.691047.691047 lmp.py:1613]   CPU experts: 32 (50%)
DEBUG 01-13 08:46:25.691598.691598 lmp.py:1614]   GPU experts: 32 (50%)
DEBUG 01-13 08:46:25.691002.691002 lmp.py:1615] 
DEBUG 01-13 08:46:25.691002.691002 lmp.py:1615]   Expert ID | Tokens | Device
DEBUG 01-13 08:46:25.691122.691122 lmp.py:1616]   -----------------------------------
DEBUG 01-13 08:46:25.691533.691533 lmp.py:1622]   Expert 34 |     25 | CPU
DEBUG 01-13 08:46:25.691461.691461 lmp.py:1622]   Expert  7 |     29 | CPU
DEBUG 01-13 08:46:25.691912.691912 lmp.py:1622]   Expert 13 |     41 | CPU
DEBUG 01-13 08:46:25.691793.691793 lmp.py:1622]   Expert 54 |     74 | CPU
DEBUG 01-13 08:46:25.691960.691960 lmp.py:1622]   Expert 18 |     84 | CPU
DEBUG 01-13 08:46:25.691887.691887 lmp.py:1622]   Expert 49 |     84 | CPU
DEBUG 01-13 08:46:25.691338.691338 lmp.py:1622]   Expert 39 |     95 | CPU
DEBUG 01-13 08:46:25.691266.691266 lmp.py:1622]   Expert 21 |    102 | CPU
DEBUG 01-13 08:46:25.691386.691386 lmp.py:1622]   Expert  0 |    105 | CPU
DEBUG 01-13 08:46:25.691029.691029 lmp.py:1622]   Expert 16 |    105 | CPU
DEBUG 01-13 08:46:25.691910.691910 lmp.py:1622]   Expert 59 |    106 | CPU
DEBUG 01-13 08:46:25.691030.691030 lmp.py:1622]   Expert 22 |    116 | CPU
DEBUG 01-13 08:46:25.691434.691434 lmp.py:1622]   Expert 45 |    117 | CPU
DEBUG 01-13 08:46:25.691885.691885 lmp.py:1622]   Expert 41 |    118 | CPU
DEBUG 01-13 08:46:25.691575.691575 lmp.py:1622]   Expert 15 |    120 | CPU
DEBUG 01-13 08:46:25.691264.691264 lmp.py:1622]   Expert 17 |    120 | CPU
DEBUG 01-13 08:46:25.691192.691192 lmp.py:1622]   Expert 61 |    130 | CPU
DEBUG 01-13 08:46:25.691643.691643 lmp.py:1622]   Expert  8 |    136 | CPU
DEBUG 01-13 08:46:25.691332.691332 lmp.py:1622]   Expert 12 |    138 | CPU
DEBUG 01-13 08:46:25.691021.691021 lmp.py:1622]   Expert 52 |    139 | CPU
DEBUG 01-13 08:46:25.691710.691710 lmp.py:1622]   Expert 48 |    142 | CPU
DEBUG 01-13 08:46:25.691353.691353 lmp.py:1622]   Expert 35 |    144 | CPU
DEBUG 01-13 08:46:25.691996.691996 lmp.py:1622]   Expert 38 |    144 | CPU
DEBUG 01-13 08:46:25.691878.691878 lmp.py:1622]   Expert 31 |    157 | CPU
DEBUG 01-13 08:46:25.691759.691759 lmp.py:1622]   Expert 40 |    158 | CPU
DEBUG 01-13 08:46:25.692925.692925 lmp.py:1622]   Expert 50 |    158 | CPU
DEBUG 01-13 08:46:25.692615.692615 lmp.py:1622]   Expert 53 |    158 | CPU
DEBUG 01-13 08:46:25.692304.692304 lmp.py:1622]   Expert 36 |    161 | CPU
DEBUG 01-13 08:46:25.692993.692993 lmp.py:1622]   Expert 60 |    169 | CPU
DEBUG 01-13 08:46:25.692444.692444 lmp.py:1622]   Expert 27 |    176 | CPU
DEBUG 01-13 08:46:25.692133.692133 lmp.py:1622]   Expert 19 |    194 | CPU
DEBUG 01-13 08:46:25.692823.692823 lmp.py:1622]   Expert 29 |    197 | CPU
DEBUG 01-13 08:46:25.692512.692512 lmp.py:1622]   Expert  4 |    205 | GPU
DEBUG 01-13 08:46:25.692678.692678 lmp.py:1622]   Expert 30 |    205 | GPU
DEBUG 01-13 08:46:25.692036.692036 lmp.py:1622]   Expert 20 |    221 | GPU
DEBUG 01-13 08:46:25.692679.692679 lmp.py:1622]   Expert 11 |    223 | GPU
DEBUG 01-13 08:46:25.692846.692846 lmp.py:1622]   Expert 57 |    223 | GPU
DEBUG 01-13 08:46:25.692250.692250 lmp.py:1622]   Expert 26 |    224 | GPU
DEBUG 01-13 08:46:25.692178.692178 lmp.py:1622]   Expert 46 |    227 | GPU
DEBUG 01-13 08:46:25.692106.692106 lmp.py:1622]   Expert  6 |    228 | GPU
DEBUG 01-13 08:46:25.692556.692556 lmp.py:1622]   Expert 43 |    232 | GPU
DEBUG 01-13 08:46:25.692769.692769 lmp.py:1622]   Expert 23 |    239 | GPU
DEBUG 01-13 08:46:25.692220.692220 lmp.py:1622]   Expert  2 |    242 | GPU
DEBUG 01-13 08:46:25.692909.692909 lmp.py:1622]   Expert 42 |    243 | GPU
DEBUG 01-13 08:46:25.692598.692598 lmp.py:1622]   Expert 33 |    245 | GPU
DEBUG 01-13 08:46:25.692963.692963 lmp.py:1622]   Expert 55 |    253 | GPU
DEBUG 01-13 08:46:25.692414.692414 lmp.py:1622]   Expert 56 |    253 | GPU
DEBUG 01-13 08:46:25.692971.692971 lmp.py:1622]   Expert 28 |    255 | GPU
DEBUG 01-13 08:46:25.692899.692899 lmp.py:1622]   Expert 44 |    256 | GPU
DEBUG 01-13 08:46:25.692588.692588 lmp.py:1622]   Expert  9 |    257 | GPU
DEBUG 01-13 08:46:25.692278.692278 lmp.py:1622]   Expert 32 |    266 | GPU
DEBUG 01-13 08:46:25.692729.692729 lmp.py:1622]   Expert  3 |    270 | GPU
DEBUG 01-13 08:46:25.692895.692895 lmp.py:1622]   Expert  1 |    276 | GPU
DEBUG 01-13 08:46:25.692299.692299 lmp.py:1622]   Expert 58 |    276 | GPU
DEBUG 01-13 08:46:25.692942.692942 lmp.py:1622]   Expert 14 |    277 | GPU
DEBUG 01-13 08:46:25.692300.692300 lmp.py:1622]   Expert 51 |    280 | GPU
DEBUG 01-13 08:46:25.692705.692705 lmp.py:1622]   Expert 47 |    288 | GPU
DEBUG 01-13 08:46:25.692633.692633 lmp.py:1622]   Expert 63 |    288 | GPU
DEBUG 01-13 08:46:25.692322.692322 lmp.py:1622]   Expert 37 |    292 | GPU
DEBUG 01-13 08:46:25.692250.692250 lmp.py:1622]   Expert 62 |    298 | GPU
DEBUG 01-13 08:46:25.692416.692416 lmp.py:1622]   Expert 10 |    308 | GPU
DEBUG 01-13 08:46:25.692344.692344 lmp.py:1622]   Expert 24 |    311 | GPU
DEBUG 01-13 08:46:25.692033.692033 lmp.py:1622]   Expert 25 |    320 | GPU
DEBUG 01-13 08:46:25.692961.692961 lmp.py:1622]   Expert  5 |    365 | GPU
DEBUG 01-13 08:46:25.692842.692842 lmp.py:1623] 
DEBUG 01-13 08:46:25.692842.692842 lmp.py:1623]   CPU total tokens: 3942 (32.1%)
DEBUG 01-13 08:46:25.692962.692962 lmp.py:1624]   GPU total tokens: 8346 (67.9%)
DEBUG 01-13 08:46:25.692373.692373 cuda_h.py:19] end experts_map_get cost 0.0015468597412109375 seconds
DEBUG 01-13 08:46:25.692508.692508 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-13 08:46:25.692264.692264 lmp.py:1632] 
DEBUG 01-13 08:46:25.692264.692264 lmp.py:1632]   Computing 32 experts on CPU MP...
DEBUG 01-13 08:46:25.692947.692947 cuda_h.py:19] end cpu_experts_submit cost 4.76837158203125e-05 seconds
DEBUG 01-13 08:46:25.692736.692736 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-13 08:46:25.692758.692758 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-13 08:46:25.693663.693663 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-13 08:46:25.693581.693581 cuda_h.py:19] end allocate_cuda_memory cost 0.0004668235778808594 seconds
DEBUG 01-13 08:46:25.694849.694849 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-13 08:46:25.694197.694197 sllm_store_c.py:27] get device uuid map
DEBUG 01-13 08:46:25.694880.694880 sllm_store_c.py:29] call client load into gpu
DEBUG 01-13 08:46:25.694583.694583 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, bf45325d-ff8a-4beb-adf4-ae0a547040e6
DEBUG 01-13 08:46:25.694669.694669 client.py:106] call stub.LoadModelAsync
DEBUG 01-13 08:46:25.694656.694656 cuda_h.py:10] start experts_func_gpu_einsum_mp
INFO 01-13 08:46:25.694218.694218 client.py:127] Model loaded
DEBUG 01-13 08:46:25.694074.694074 cuda_h.py:10] start restore2model
DEBUG 01-13 08:46:25.695004.695004 cuda_h.py:19] end restore2model cost 0.0004258155822753906 seconds
DEBUG 01-13 08:46:25.695933.695933 cuda_h.py:19] end sllm_worker_task cost 0.009737014770507812 seconds
INFO 01-13 08:46:25.695625.695625 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, bf45325d-ff8a-4beb-adf4-ae0a547040e6
DEBUG 01-13 08:46:25.695706.695706 cuda_h.py:19] end load_into_gpu_async cost 0.001184701919555664 seconds
DEBUG 01-13 08:46:25.695694.695694 cuda_h.py:10] start restore_tensors2
DEBUG 01-13 08:46:25.695680.695680 cuda_h.py:19] end restore_tensors2 cost 0.0003497600555419922 seconds
DEBUG 01-13 08:46:25.695324.695324 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0028502941131591797 seconds
DEBUG 01-13 08:46:25.695133.695133 cuda_h.py:10] start restore2model
DEBUG 01-13 08:46:25.698867.698867 cuda_h.py:19] end restore2model cost 0.0028960704803466797 seconds
DEBUG 01-13 08:46:25.698300.698300 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.0059392452239990234 seconds
DEBUG 01-13 08:46:25.698771.698771 cuda_h.py:10] start gpu_sexperts
DEBUG 01-13 08:46:25.699075.699075 cuda_h.py:19] end gpu_sexperts cost 0.0003261566162109375 seconds
DEBUG 01-13 08:46:25.699964.699964 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-13 08:46:25.699847.699847 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 1.7404556274414062e-05 seconds
DEBUG 01-13 08:46:25.699504.699504 cuda_h.py:10] start wait_experts
INFO 01-13 08:46:25.699591.699591 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, bf45325d-ff8a-4beb-adf4-ae0a547040e6
DEBUG 01-13 08:46:25.700969.700969 mlpmodule.py:1006] group tensors cost 0.005288839340209961 s
DEBUG 01-13 08:46:25.702411.702411 mlpmodule.py:1044] pad cost 0.001772165298461914 s
DEBUG 01-13 08:46:25.702891.702891 mlpmodule.py:1050] create cpu tensor cost 4.553794860839844e-05 s
DEBUG 01-13 08:46:25.702801.702801 mlpmodule.py:1055] move to cpu cost 3.314018249511719e-05 s
DEBUG 01-13 08:46:25.713177.713177 mlpmodule.py:1069] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-13 08:46:25.713881.713881 mlpmodule.py:1070] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-13 08:46:25.713111.713111 mlpmodule.py:1075] group_w3 first element: 0.000789642333984375
WARNING 01-13 08:46:25.713421.713421 mlpmodule.py:1085] start einsum2
DEBUG 01-13 08:46:25.729445.729445 mlpmodule.py:1095] group einsum cost 0.026658058166503906 s
DEBUG 01-13 08:46:25.730165.730165 mlpmodule.py:1103] cpy2cputensor cost 0.0007245540618896484 s
INFO 01-13 08:46:25.747284.747284 client.py:127] Model loaded
DEBUG 01-13 08:46:25.747056.747056 cuda_h.py:19] end wait_experts cost 0.0482943058013916 seconds
DEBUG 01-13 08:46:25.747958.747958 cuda_h.py:10] start gpu_experts
DEBUG 01-13 08:46:25.748311.748311 mlpmodule.py:559] gpu group tensors cost 0.0005910396575927734 s
DEBUG 01-13 08:46:25.750974.750974 mlpmodule.py:592] gpu pad cost 0.0015053749084472656 s
DEBUG 01-13 08:46:25.750837.750837 mlpmodule.py:598] start_w1
DEBUG 01-13 08:46:25.750869.750869 mlpmodule.py:602] start_w3
DEBUG 01-13 08:46:25.750683.750683 mlpmodule.py:608] start_w2
DEBUG 01-13 08:46:25.750815.750815 mlpmodule.py:611] gpu group einsum cost 0.0007197856903076172 s
DEBUG 01-13 08:46:25.752463.752463 mlpmodule.py:785]  experts func einsum cost 0.05805778503417969 s
DEBUG 01-13 08:46:25.753003.753003 mlpmodule.py:683] gpu experts func einsum cost 0.005212306976318359 s
DEBUG 01-13 08:46:25.753741.753741 cuda_h.py:19] end gpu_experts cost 0.005361080169677734 seconds
DEBUG 01-13 08:46:25.753828.753828 cuda_h.py:10] start cpu_thread_manager_mp_wait
DEBUG 01-13 08:46:25.753777.753777 cuda_h.py:19] end cpu_thread_manager_mp_wait cost 3.9577484130859375e-05 seconds
DEBUG 01-13 08:46:25.753937.753937 cuda_h.py:19] end experts_func_gpu_einsum_mp cost 0.05876874923706055 seconds
DEBUG 01-13 08:46:25.753601.753601 cuda_h.py:19] end layer_moe_generate_mp_l_15 cost 0.06300044059753418 seconds
DEBUG 01-13 08:46:25.753013.753013 lmp.py:1550] -------------------------------- end prefill layer 14 --------------------------------
DEBUG 01-13 08:46:25.753743.753743 lmp.py:1493] -------------------------------- start prefill layer 15 --------------------------------
DEBUG 01-13 08:46:25.753015.753015 cuda_h.py:10] start start_load_qkvogn_s_weight_l_16
DEBUG 01-13 08:46:25.753910.753910 cuda_h.py:10] start start_load_qkvogn_s_weight_l_16
DEBUG 01-13 08:46:25.753985.753985 cuda_h.py:19] end start_load_qkvogn_s_weight_l_16 cost 3.0994415283203125e-05 seconds
DEBUG 01-13 08:46:25.753542.753542 cuda_h.py:19] end start_load_qkvogn_s_weight_l_16 cost 5.888938903808594e-05 seconds
DEBUG 01-13 08:46:25.753231.753231 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-13 08:46:25.753743.753743 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-13 08:46:25.753938.753938 cuda_h.py:10] start sllm_worker_task
DEBUG 01-13 08:46:25.753537.753537 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-13 08:46:25.754704.754704 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-13 08:46:25.754490.754490 cuda_h.py:19] end allocate_cuda_memory cost 0.00029850006103515625 seconds
DEBUG 01-13 08:46:25.754909.754909 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-13 08:46:25.754857.754857 sllm_store_c.py:27] get device uuid map
DEBUG 01-13 08:46:25.754819.754819 sllm_store_c.py:29] call client load into gpu
DEBUG 01-13 08:46:25.754615.754615 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 3074a3d3-062a-4ede-a0e4-91cf89615434
DEBUG 01-13 08:46:25.754531.754531 client.py:106] call stub.LoadModelAsync
DEBUG 01-13 08:46:25.754401.754401 cuda_h.py:10] start self_attn
INFO 01-13 08:46:25.755593.755593 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 3074a3d3-062a-4ede-a0e4-91cf89615434
DEBUG 01-13 08:46:25.755330.755330 cuda_h.py:19] end load_into_gpu_async cost 0.0010495185852050781 seconds
DEBUG 01-13 08:46:25.755125.755125 cuda_h.py:10] start restore_tensors2
DEBUG 01-13 08:46:25.755155.755155 cuda_h.py:19] end restore_tensors2 cost 6.628036499023438e-05 seconds
DEBUG 01-13 08:46:25.755003.755003 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0016465187072753906 seconds
INFO 01-13 08:46:25.755601.755601 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 3074a3d3-062a-4ede-a0e4-91cf89615434
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-13 08:46:25.758351.758351 cuda_h.py:19] end self_attn cost 0.0035669803619384766 seconds
DEBUG 01-13 08:46:25.758460.758460 cuda_h.py:19] end iln_self_attn_paln cost 0.005021810531616211 seconds
DEBUG 01-13 08:46:25.758534.758534 cuda_h.py:10] start layer_moe_generate_mp_l_16
DEBUG 01-13 08:46:25.758721.758721 cuda_h.py:10] start gate
DEBUG 01-13 08:46:25.759770.759770 cuda_h.py:19] end gate cost 0.0006361007690429688 seconds
DEBUG 01-13 08:46:25.759692.759692 cuda_h.py:10] start experts_map_get
DEBUG 01-13 08:46:25.759993.759993 lmp.py:1611] 
DEBUG 01-13 08:46:25.759993.759993 lmp.py:1611] Expert Token Distribution & Device Allocation:
DEBUG 01-13 08:46:25.759034.759034 lmp.py:1612]   Total experts: 64
DEBUG 01-13 08:46:25.759684.759684 lmp.py:1613]   CPU experts: 32 (50%)
DEBUG 01-13 08:46:25.759757.759757 lmp.py:1614]   GPU experts: 32 (50%)
DEBUG 01-13 08:46:25.759400.759400 lmp.py:1615] 
DEBUG 01-13 08:46:25.759400.759400 lmp.py:1615]   Expert ID | Tokens | Device
DEBUG 01-13 08:46:25.760851.760851 lmp.py:1616]   -----------------------------------
DEBUG 01-13 08:46:25.760785.760785 lmp.py:1622]   Expert 15 |     59 | CPU
DEBUG 01-13 08:46:25.760952.760952 lmp.py:1622]   Expert 41 |     73 | CPU
DEBUG 01-13 08:46:25.760595.760595 lmp.py:1622]   Expert 63 |     74 | CPU
DEBUG 01-13 08:46:25.760999.760999 lmp.py:1622]   Expert  0 |     78 | CPU
DEBUG 01-13 08:46:25.760927.760927 lmp.py:1622]   Expert 20 |     83 | CPU
DEBUG 01-13 08:46:25.760855.760855 lmp.py:1622]   Expert  7 |     96 | CPU
DEBUG 01-13 08:46:25.760544.760544 lmp.py:1622]   Expert 45 |     97 | CPU
DEBUG 01-13 08:46:25.760233.760233 lmp.py:1622]   Expert 54 |    100 | CPU
DEBUG 01-13 08:46:25.760115.760115 lmp.py:1622]   Expert 28 |    102 | CPU
DEBUG 01-13 08:46:25.760758.760758 lmp.py:1622]   Expert 12 |    113 | CPU
DEBUG 01-13 08:46:25.760924.760924 lmp.py:1622]   Expert 52 |    116 | CPU
DEBUG 01-13 08:46:25.760328.760328 lmp.py:1622]   Expert 40 |    123 | CPU
DEBUG 01-13 08:46:25.760018.760018 lmp.py:1622]   Expert 59 |    125 | CPU
DEBUG 01-13 08:46:25.760707.760707 lmp.py:1622]   Expert  4 |    126 | CPU
DEBUG 01-13 08:46:25.760158.760158 lmp.py:1622]   Expert  5 |    127 | CPU
DEBUG 01-13 08:46:25.760847.760847 lmp.py:1622]   Expert 34 |    127 | CPU
DEBUG 01-13 08:46:25.760060.760060 lmp.py:1622]   Expert 62 |    131 | CPU
DEBUG 01-13 08:46:25.760272.760272 lmp.py:1622]   Expert 13 |    134 | CPU
DEBUG 01-13 08:46:25.760723.760723 lmp.py:1622]   Expert 55 |    135 | CPU
DEBUG 01-13 08:46:25.760174.760174 lmp.py:1622]   Expert 61 |    138 | CPU
DEBUG 01-13 08:46:25.760863.760863 lmp.py:1622]   Expert 21 |    139 | CPU
DEBUG 01-13 08:46:25.760837.760837 lmp.py:1622]   Expert 10 |    141 | CPU
DEBUG 01-13 08:46:25.760065.760065 lmp.py:1622]   Expert 42 |    141 | CPU
DEBUG 01-13 08:46:25.760092.760092 lmp.py:1622]   Expert 22 |    149 | CPU
DEBUG 01-13 08:46:25.760258.760258 lmp.py:1622]   Expert 14 |    152 | CPU
DEBUG 01-13 08:46:25.760901.760901 lmp.py:1622]   Expert 51 |    157 | CPU
DEBUG 01-13 08:46:25.760544.760544 lmp.py:1622]   Expert 32 |    161 | CPU
DEBUG 01-13 08:46:25.760949.760949 lmp.py:1622]   Expert 25 |    169 | CPU
DEBUG 01-13 08:46:25.760115.760115 lmp.py:1622]   Expert 53 |    170 | CPU
DEBUG 01-13 08:46:25.760042.760042 lmp.py:1622]   Expert 50 |    171 | CPU
DEBUG 01-13 08:46:25.760493.760493 lmp.py:1622]   Expert 26 |    176 | CPU
DEBUG 01-13 08:46:25.760421.760421 lmp.py:1622]   Expert 19 |    177 | CPU
DEBUG 01-13 08:46:25.760587.760587 lmp.py:1622]   Expert  1 |    178 | GPU
DEBUG 01-13 08:46:25.760515.760515 lmp.py:1622]   Expert 35 |    178 | GPU
DEBUG 01-13 08:46:25.760204.760204 lmp.py:1622]   Expert 30 |    179 | GPU
DEBUG 01-13 08:46:25.760893.760893 lmp.py:1622]   Expert  6 |    181 | GPU
DEBUG 01-13 08:46:25.760583.760583 lmp.py:1622]   Expert 47 |    182 | GPU
DEBUG 01-13 08:46:25.760464.760464 lmp.py:1622]   Expert  2 |    183 | GPU
DEBUG 01-13 08:46:25.760107.760107 lmp.py:1622]   Expert 11 |    185 | GPU
DEBUG 01-13 08:46:25.760512.760512 lmp.py:1622]   Expert 57 |    188 | GPU
DEBUG 01-13 08:46:25.760916.760916 lmp.py:1622]   Expert 56 |    190 | GPU
DEBUG 01-13 08:46:25.760798.760798 lmp.py:1622]   Expert 44 |    205 | GPU
DEBUG 01-13 08:46:25.760964.760964 lmp.py:1622]   Expert 48 |    207 | GPU
DEBUG 01-13 08:46:25.761653.761653 lmp.py:1622]   Expert 46 |    211 | GPU
DEBUG 01-13 08:46:25.761104.761104 lmp.py:1622]   Expert 24 |    215 | GPU
DEBUG 01-13 08:46:25.761793.761793 lmp.py:1622]   Expert 39 |    219 | GPU
DEBUG 01-13 08:46:25.761483.761483 lmp.py:1622]   Expert 16 |    221 | GPU
DEBUG 01-13 08:46:25.761172.761172 lmp.py:1622]   Expert 18 |    223 | GPU
DEBUG 01-13 08:46:25.761100.761100 lmp.py:1622]   Expert 29 |    232 | GPU
DEBUG 01-13 08:46:25.761550.761550 lmp.py:1622]   Expert 37 |    238 | GPU
DEBUG 01-13 08:46:25.761670.761670 lmp.py:1622]   Expert  3 |    249 | GPU
DEBUG 01-13 08:46:25.761313.761313 lmp.py:1622]   Expert 31 |    252 | GPU
DEBUG 01-13 08:46:25.761956.761956 lmp.py:1622]   Expert 36 |    256 | GPU
DEBUG 01-13 08:46:25.761599.761599 lmp.py:1622]   Expert 17 |    257 | GPU
DEBUG 01-13 08:46:25.761527.761527 lmp.py:1622]   Expert 38 |    258 | GPU
DEBUG 01-13 08:46:25.761978.761978 lmp.py:1622]   Expert  9 |    261 | GPU
DEBUG 01-13 08:46:25.761667.761667 lmp.py:1622]   Expert 60 |    263 | GPU
DEBUG 01-13 08:46:25.761356.761356 lmp.py:1622]   Expert 23 |    272 | GPU
DEBUG 01-13 08:46:25.761046.761046 lmp.py:1622]   Expert 27 |    355 | GPU
DEBUG 01-13 08:46:25.761973.761973 lmp.py:1622]   Expert 43 |    364 | GPU
DEBUG 01-13 08:46:25.761901.761901 lmp.py:1622]   Expert 33 |    402 | GPU
DEBUG 01-13 08:46:25.761352.761352 lmp.py:1622]   Expert  8 |    441 | GPU
DEBUG 01-13 08:46:25.761280.761280 lmp.py:1622]   Expert 58 |    444 | GPU
DEBUG 01-13 08:46:25.761923.761923 lmp.py:1622]   Expert 49 |    539 | GPU
DEBUG 01-13 08:46:25.761996.761996 lmp.py:1623] 
DEBUG 01-13 08:46:25.761996.761996 lmp.py:1623]   CPU total tokens: 4060 (33.0%)
DEBUG 01-13 08:46:25.761308.761308 lmp.py:1624]   GPU total tokens: 8228 (67.0%)
DEBUG 01-13 08:46:25.761150.761150 cuda_h.py:19] end experts_map_get cost 0.001783609390258789 seconds
DEBUG 01-13 08:46:25.761676.761676 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-13 08:46:25.761524.761524 lmp.py:1632] 
DEBUG 01-13 08:46:25.761524.761524 lmp.py:1632]   Computing 32 experts on CPU MP...
DEBUG 01-13 08:46:25.761222.761222 cuda_h.py:19] end cpu_experts_submit cost 5.7220458984375e-05 seconds
DEBUG 01-13 08:46:25.761202.761202 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-13 08:46:25.761270.761270 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-13 08:46:25.761593.761593 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-13 08:46:25.762773.762773 cuda_h.py:19] end allocate_cuda_memory cost 0.0002052783966064453 seconds
DEBUG 01-13 08:46:25.762424.762424 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-13 08:46:25.762749.762749 sllm_store_c.py:27] get device uuid map
DEBUG 01-13 08:46:25.762227.762227 sllm_store_c.py:29] call client load into gpu
DEBUG 01-13 08:46:25.762877.762877 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, f351994f-1174-4a45-aaf5-2edbc72a6ea2
DEBUG 01-13 08:46:25.762375.762375 client.py:106] call stub.LoadModelAsync
INFO 01-13 08:46:25.762875.762875 client.py:127] Model loaded
DEBUG 01-13 08:46:25.762745.762745 cuda_h.py:10] start restore2model
DEBUG 01-13 08:46:25.763319.763319 cuda_h.py:10] start experts_func_gpu_einsum_mp
INFO 01-13 08:46:25.763027.763027 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, f351994f-1174-4a45-aaf5-2edbc72a6ea2
DEBUG 01-13 08:46:25.763328.763328 cuda_h.py:19] end load_into_gpu_async cost 0.0012636184692382812 seconds
DEBUG 01-13 08:46:25.763667.763667 cuda_h.py:10] start restore_tensors2
DEBUG 01-13 08:46:25.764365.764365 cuda_h.py:19] end restore_tensors2 cost 0.0004200935363769531 seconds
DEBUG 01-13 08:46:25.764751.764751 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.002470254898071289 seconds
DEBUG 01-13 08:46:25.764528.764528 cuda_h.py:10] start restore2model
DEBUG 01-13 08:46:25.764886.764886 cuda_h.py:19] end restore2model cost 0.0005741119384765625 seconds
DEBUG 01-13 08:46:25.764526.764526 cuda_h.py:19] end sllm_worker_task cost 0.010951042175292969 seconds
DEBUG 01-13 08:46:25.768524.768524 cuda_h.py:19] end restore2model cost 0.0038192272186279297 seconds
DEBUG 01-13 08:46:25.768341.768341 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.006504535675048828 seconds
DEBUG 01-13 08:46:25.768574.768574 cuda_h.py:10] start gpu_sexperts
DEBUG 01-13 08:46:25.767998.767998 mlpmodule.py:1006] group tensors cost 0.004064321517944336 s
DEBUG 01-13 08:46:25.768058.768058 cuda_h.py:19] end gpu_sexperts cost 0.00035309791564941406 seconds
DEBUG 01-13 08:46:25.768570.768570 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-13 08:46:25.768406.768406 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 1.7881393432617188e-05 seconds
DEBUG 01-13 08:46:25.768778.768778 cuda_h.py:10] start wait_experts
INFO 01-13 08:46:25.768626.768626 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, f351994f-1174-4a45-aaf5-2edbc72a6ea2
DEBUG 01-13 08:46:25.769947.769947 mlpmodule.py:1044] pad cost 0.0015254020690917969 s
DEBUG 01-13 08:46:25.769507.769507 mlpmodule.py:1050] create cpu tensor cost 4.0531158447265625e-05 s
DEBUG 01-13 08:46:25.769787.769787 mlpmodule.py:1055] move to cpu cost 3.0994415283203125e-05 s
DEBUG 01-13 08:46:25.777981.777981 mlpmodule.py:1069] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-13 08:46:25.777017.777017 mlpmodule.py:1070] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-13 08:46:25.777147.777147 mlpmodule.py:1075] group_w3 first element: -0.0595703125
WARNING 01-13 08:46:25.777059.777059 mlpmodule.py:1085] start einsum2
DEBUG 01-13 08:46:25.791726.791726 mlpmodule.py:1095] group einsum cost 0.02105093002319336 s
DEBUG 01-13 08:46:25.792267.792267 mlpmodule.py:1103] cpy2cputensor cost 0.0007071495056152344 s
INFO 01-13 08:46:25.814242.814242 client.py:127] Model loaded
DEBUG 01-13 08:46:25.815834.815834 cuda_h.py:19] end wait_experts cost 0.046324968338012695 seconds
DEBUG 01-13 08:46:25.815691.815691 cuda_h.py:10] start gpu_experts
DEBUG 01-13 08:46:25.816370.816370 mlpmodule.py:559] gpu group tensors cost 0.0007457733154296875 s
DEBUG 01-13 08:46:25.816828.816828 mlpmodule.py:785]  experts func einsum cost 0.05279231071472168 s
DEBUG 01-13 08:46:25.816071.816071 cuda_h.py:19] end experts_func_gpu_einsum_mp cost 0.0534360408782959 seconds
DEBUG 01-13 08:46:25.818444.818444 mlpmodule.py:592] gpu pad cost 0.002527475357055664 s
DEBUG 01-13 08:46:25.818990.818990 mlpmodule.py:598] start_w1
DEBUG 01-13 08:46:25.819425.819425 mlpmodule.py:602] start_w3
DEBUG 01-13 08:46:25.819102.819102 mlpmodule.py:608] start_w2
DEBUG 01-13 08:46:25.819231.819231 mlpmodule.py:611] gpu group einsum cost 0.0010552406311035156 s
DEBUG 01-13 08:46:25.823977.823977 mlpmodule.py:683] gpu experts func einsum cost 0.008399486541748047 s
DEBUG 01-13 08:46:25.823424.823424 cuda_h.py:19] end gpu_experts cost 0.008618593215942383 seconds
DEBUG 01-13 08:46:25.823909.823909 cuda_h.py:10] start cpu_thread_manager_mp_wait
DEBUG 01-13 08:46:25.823091.823091 cuda_h.py:19] end cpu_thread_manager_mp_wait cost 5.888938903808594e-05 seconds
DEBUG 01-13 08:46:25.824724.824724 cuda_h.py:19] end layer_moe_generate_mp_l_16 cost 0.0651700496673584 seconds
DEBUG 01-13 08:46:25.824991.824991 lmp.py:1550] -------------------------------- end prefill layer 15 --------------------------------
DEBUG 01-13 08:46:25.824489.824489 lmp.py:1493] -------------------------------- start prefill layer 16 --------------------------------
DEBUG 01-13 08:46:25.824444.824444 cuda_h.py:10] start start_load_qkvogn_s_weight_l_17
DEBUG 01-13 08:46:25.824836.824836 cuda_h.py:10] start start_load_qkvogn_s_weight_l_17
DEBUG 01-13 08:46:25.824852.824852 cuda_h.py:19] end start_load_qkvogn_s_weight_l_17 cost 4.6253204345703125e-05 seconds
DEBUG 01-13 08:46:25.824585.824585 cuda_h.py:10] start sllm_worker_task
DEBUG 01-13 08:46:25.824324.824324 cuda_h.py:19] end start_load_qkvogn_s_weight_l_17 cost 0.00028443336486816406 seconds
DEBUG 01-13 08:46:25.825702.825702 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-13 08:46:25.825182.825182 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-13 08:46:25.825810.825810 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-13 08:46:25.825923.825923 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-13 08:46:25.826379.826379 cuda_h.py:19] end allocate_cuda_memory cost 0.00030040740966796875 seconds
DEBUG 01-13 08:46:25.826182.826182 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-13 08:46:25.826157.826157 sllm_store_c.py:27] get device uuid map
DEBUG 01-13 08:46:25.826047.826047 sllm_store_c.py:29] call client load into gpu
DEBUG 01-13 08:46:25.826717.826717 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 320d0ecc-3206-4d9a-adcd-132c51756fa3
DEBUG 01-13 08:46:25.826914.826914 client.py:106] call stub.LoadModelAsync
DEBUG 01-13 08:46:25.826292.826292 cuda_h.py:10] start self_attn
INFO 01-13 08:46:25.827033.827033 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 320d0ecc-3206-4d9a-adcd-132c51756fa3
DEBUG 01-13 08:46:25.827587.827587 cuda_h.py:19] end load_into_gpu_async cost 0.0013663768768310547 seconds
DEBUG 01-13 08:46:25.827271.827271 cuda_h.py:10] start restore_tensors2
DEBUG 01-13 08:46:25.827739.827739 cuda_h.py:19] end restore_tensors2 cost 9.417533874511719e-05 seconds
DEBUG 01-13 08:46:25.827985.827985 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0025224685668945312 seconds
INFO 01-13 08:46:25.827770.827770 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 320d0ecc-3206-4d9a-adcd-132c51756fa3
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-13 08:46:25.831604.831604 cuda_h.py:19] end self_attn cost 0.004491090774536133 seconds
DEBUG 01-13 08:46:25.831486.831486 cuda_h.py:19] end iln_self_attn_paln cost 0.006447315216064453 seconds
DEBUG 01-13 08:46:25.832865.832865 cuda_h.py:10] start layer_moe_generate_mp_l_17
DEBUG 01-13 08:46:25.832489.832489 cuda_h.py:10] start gate
DEBUG 01-13 08:46:25.832008.832008 cuda_h.py:19] end gate cost 0.000835418701171875 seconds
DEBUG 01-13 08:46:25.832991.832991 cuda_h.py:10] start experts_map_get
DEBUG 01-13 08:46:25.833167.833167 lmp.py:1611] 
DEBUG 01-13 08:46:25.833167.833167 lmp.py:1611] Expert Token Distribution & Device Allocation:
DEBUG 01-13 08:46:25.833645.833645 lmp.py:1612]   Total experts: 64
DEBUG 01-13 08:46:25.833553.833553 lmp.py:1613]   CPU experts: 32 (50%)
DEBUG 01-13 08:46:25.833634.833634 lmp.py:1614]   GPU experts: 32 (50%)
DEBUG 01-13 08:46:25.833827.833827 lmp.py:1615] 
DEBUG 01-13 08:46:25.833827.833827 lmp.py:1615]   Expert ID | Tokens | Device
DEBUG 01-13 08:46:25.833252.833252 lmp.py:1616]   -----------------------------------
DEBUG 01-13 08:46:25.833385.833385 lmp.py:1622]   Expert 58 |     31 | CPU
DEBUG 01-13 08:46:25.833604.833604 lmp.py:1622]   Expert 31 |     62 | CPU
DEBUG 01-13 08:46:25.833870.833870 lmp.py:1622]   Expert 47 |     64 | CPU
DEBUG 01-13 08:46:25.833659.833659 lmp.py:1622]   Expert 49 |     64 | CPU
DEBUG 01-13 08:46:25.833209.833209 lmp.py:1622]   Expert 38 |     65 | CPU
DEBUG 01-13 08:46:25.833236.833236 lmp.py:1622]   Expert  4 |     66 | CPU
DEBUG 01-13 08:46:25.833263.833263 lmp.py:1622]   Expert 45 |     72 | CPU
DEBUG 01-13 08:46:25.833814.833814 lmp.py:1622]   Expert 43 |     76 | CPU
DEBUG 01-13 08:46:25.833795.833795 lmp.py:1622]   Expert 41 |     90 | CPU
DEBUG 01-13 08:46:25.833299.833299 lmp.py:1622]   Expert 50 |     96 | CPU
DEBUG 01-13 08:46:25.833564.833564 lmp.py:1622]   Expert 33 |     97 | CPU
DEBUG 01-13 08:46:25.833591.833591 lmp.py:1622]   Expert 11 |    104 | CPU
DEBUG 01-13 08:46:25.833095.833095 lmp.py:1622]   Expert 57 |    105 | CPU
DEBUG 01-13 08:46:25.833361.833361 lmp.py:1622]   Expert  2 |    109 | CPU
DEBUG 01-13 08:46:25.833911.833911 lmp.py:1622]   Expert 51 |    110 | CPU
DEBUG 01-13 08:46:25.834700.834700 lmp.py:1622]   Expert  0 |    119 | CPU
DEBUG 01-13 08:46:25.834204.834204 lmp.py:1622]   Expert 14 |    124 | CPU
DEBUG 01-13 08:46:25.834516.834516 lmp.py:1622]   Expert 54 |    129 | CPU
DEBUG 01-13 08:46:25.834543.834543 lmp.py:1622]   Expert 56 |    129 | CPU
DEBUG 01-13 08:46:25.834285.834285 lmp.py:1622]   Expert 34 |    136 | CPU
DEBUG 01-13 08:46:25.834604.834604 lmp.py:1622]   Expert 26 |    151 | CPU
DEBUG 01-13 08:46:25.834698.834698 lmp.py:1622]   Expert 27 |    154 | CPU
DEBUG 01-13 08:46:25.834248.834248 lmp.py:1622]   Expert 28 |    156 | CPU
DEBUG 01-13 08:46:25.834322.834322 lmp.py:1622]   Expert 10 |    165 | CPU
DEBUG 01-13 08:46:25.834442.834442 lmp.py:1622]   Expert 55 |    169 | CPU
DEBUG 01-13 08:46:25.834800.834800 lmp.py:1622]   Expert 25 |    172 | CPU
DEBUG 01-13 08:46:25.834397.834397 lmp.py:1622]   Expert 13 |    184 | CPU
DEBUG 01-13 08:46:25.834993.834993 lmp.py:1622]   Expert  9 |    187 | CPU
DEBUG 01-13 08:46:25.834351.834351 lmp.py:1622]   Expert 48 |    189 | CPU
DEBUG 01-13 08:46:25.834710.834710 lmp.py:1622]   Expert 61 |    189 | CPU
DEBUG 01-13 08:46:25.834306.834306 lmp.py:1622]   Expert  6 |    190 | CPU
DEBUG 01-13 08:46:25.834665.834665 lmp.py:1622]   Expert  7 |    193 | CPU
DEBUG 01-13 08:46:25.834692.834692 lmp.py:1622]   Expert 46 |    195 | GPU
DEBUG 01-13 08:46:25.834004.834004 lmp.py:1622]   Expert 24 |    197 | GPU
DEBUG 01-13 08:46:25.834839.834839 lmp.py:1622]   Expert 42 |    199 | GPU
DEBUG 01-13 08:46:25.834435.834435 lmp.py:1622]   Expert 18 |    203 | GPU
DEBUG 01-13 08:46:25.834794.834794 lmp.py:1622]   Expert 40 |    209 | GPU
DEBUG 01-13 08:46:25.834152.834152 lmp.py:1622]   Expert 59 |    213 | GPU
DEBUG 01-13 08:46:25.834716.834716 lmp.py:1622]   Expert 12 |    216 | GPU
DEBUG 01-13 08:46:25.834597.834597 lmp.py:1622]   Expert 29 |    218 | GPU
DEBUG 01-13 08:46:25.834717.834717 lmp.py:1622]   Expert 21 |    219 | GPU
DEBUG 01-13 08:46:25.834360.834360 lmp.py:1622]   Expert 22 |    219 | GPU
DEBUG 01-13 08:46:25.834241.834241 lmp.py:1622]   Expert 63 |    221 | GPU
DEBUG 01-13 08:46:25.834838.834838 lmp.py:1622]   Expert 32 |    224 | GPU
DEBUG 01-13 08:46:25.834196.834196 lmp.py:1622]   Expert 19 |    229 | GPU
DEBUG 01-13 08:46:25.834508.834508 lmp.py:1622]   Expert 37 |    231 | GPU
DEBUG 01-13 08:46:25.834866.834866 lmp.py:1622]   Expert 36 |    240 | GPU
DEBUG 01-13 08:46:25.834509.834509 lmp.py:1622]   Expert  3 |    245 | GPU
DEBUG 01-13 08:46:25.834391.834391 lmp.py:1622]   Expert  1 |    249 | GPU
DEBUG 01-13 08:46:25.834034.834034 lmp.py:1622]   Expert 16 |    253 | GPU
DEBUG 01-13 08:46:25.834677.834677 lmp.py:1622]   Expert 30 |    262 | GPU
DEBUG 01-13 08:46:25.834320.834320 lmp.py:1622]   Expert  5 |    263 | GPU
DEBUG 01-13 08:46:25.834963.834963 lmp.py:1622]   Expert  8 |    263 | GPU
DEBUG 01-13 08:46:25.834082.834082 lmp.py:1622]   Expert 15 |    268 | GPU
DEBUG 01-13 08:46:25.834202.834202 lmp.py:1622]   Expert 20 |    268 | GPU
DEBUG 01-13 08:46:25.834084.834084 lmp.py:1622]   Expert 62 |    272 | GPU
DEBUG 01-13 08:46:25.834203.834203 lmp.py:1622]   Expert 35 |    296 | GPU
DEBUG 01-13 08:46:25.834277.834277 lmp.py:1622]   Expert 17 |    298 | GPU
DEBUG 01-13 08:46:25.834350.834350 lmp.py:1622]   Expert 60 |    313 | GPU
DEBUG 01-13 08:46:25.834185.834185 lmp.py:1622]   Expert 39 |    316 | GPU
DEBUG 01-13 08:46:25.834590.834590 lmp.py:1622]   Expert 52 |    358 | GPU
DEBUG 01-13 08:46:25.834994.834994 lmp.py:1622]   Expert 23 |    365 | GPU
DEBUG 01-13 08:46:25.834876.834876 lmp.py:1622]   Expert 44 |    372 | GPU
DEBUG 01-13 08:46:25.834280.834280 lmp.py:1622]   Expert 53 |    447 | GPU
DEBUG 01-13 08:46:25.834116.834116 lmp.py:1623] 
DEBUG 01-13 08:46:25.834116.834116 lmp.py:1623]   CPU total tokens: 3947 (32.1%)
DEBUG 01-13 08:46:25.834904.834904 lmp.py:1624]   GPU total tokens: 8341 (67.9%)
DEBUG 01-13 08:46:25.834746.834746 cuda_h.py:19] end experts_map_get cost 0.0019652843475341797 seconds
DEBUG 01-13 08:46:25.835941.835941 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-13 08:46:25.835366.835366 lmp.py:1632] 
DEBUG 01-13 08:46:25.835366.835366 lmp.py:1632]   Computing 32 experts on CPU MP...
DEBUG 01-13 08:46:25.835970.835970 cuda_h.py:19] end cpu_experts_submit cost 6.008148193359375e-05 seconds
DEBUG 01-13 08:46:25.835097.835097 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-13 08:46:25.835231.835231 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-13 08:46:25.835232.835232 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-13 08:46:25.835763.835763 cuda_h.py:19] end allocate_cuda_memory cost 0.00038504600524902344 seconds
DEBUG 01-13 08:46:25.835103.835103 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-13 08:46:25.835058.835058 sllm_store_c.py:27] get device uuid map
DEBUG 01-13 08:46:25.836841.836841 sllm_store_c.py:29] call client load into gpu
DEBUG 01-13 08:46:25.836451.836451 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, e38a4ed4-ac04-45d5-aeaa-64a148a23709
DEBUG 01-13 08:46:25.836713.836713 client.py:106] call stub.LoadModelAsync
INFO 01-13 08:46:25.837267.837267 client.py:127] Model loaded
DEBUG 01-13 08:46:25.837775.837775 cuda_h.py:10] start restore2model
DEBUG 01-13 08:46:25.837908.837908 cuda_h.py:10] start experts_func_gpu_einsum_mp
INFO 01-13 08:46:25.837787.837787 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, e38a4ed4-ac04-45d5-aeaa-64a148a23709
DEBUG 01-13 08:46:25.837166.837166 cuda_h.py:19] end load_into_gpu_async cost 0.0016596317291259766 seconds
DEBUG 01-13 08:46:25.837777.837777 cuda_h.py:10] start restore_tensors2
DEBUG 01-13 08:46:25.838920.838920 cuda_h.py:19] end restore_tensors2 cost 0.00048828125 seconds
DEBUG 01-13 08:46:25.838966.838966 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0031096935272216797 seconds
DEBUG 01-13 08:46:25.838471.838471 cuda_h.py:10] start restore2model
DEBUG 01-13 08:46:25.839319.839319 cuda_h.py:19] end restore2model cost 0.00075531005859375 seconds
DEBUG 01-13 08:46:25.839934.839934 cuda_h.py:19] end sllm_worker_task cost 0.01428532600402832 seconds
DEBUG 01-13 08:46:25.842282.842282 cuda_h.py:19] end restore2model cost 0.004212856292724609 seconds
DEBUG 01-13 08:46:25.842066.842066 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.0075719356536865234 seconds
DEBUG 01-13 08:46:25.842266.842266 cuda_h.py:10] start gpu_sexperts
DEBUG 01-13 08:46:25.843193.843193 cuda_h.py:19] end gpu_sexperts cost 0.00033473968505859375 seconds
DEBUG 01-13 08:46:25.843360.843360 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-13 08:46:25.843666.843666 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.1219253540039062e-05 seconds
DEBUG 01-13 08:46:25.843316.843316 cuda_h.py:10] start wait_experts
INFO 01-13 08:46:25.843734.843734 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, e38a4ed4-ac04-45d5-aeaa-64a148a23709
DEBUG 01-13 08:46:25.849299.849299 mlpmodule.py:1006] group tensors cost 0.011528968811035156 s
DEBUG 01-13 08:46:25.851454.851454 mlpmodule.py:1044] pad cost 0.0017118453979492188 s
DEBUG 01-13 08:46:25.852034.852034 mlpmodule.py:1050] create cpu tensor cost 5.650520324707031e-05 s
DEBUG 01-13 08:46:25.852314.852314 mlpmodule.py:1055] move to cpu cost 3.123283386230469e-05 s
DEBUG 01-13 08:46:25.861306.861306 mlpmodule.py:1069] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-13 08:46:25.862203.862203 mlpmodule.py:1070] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-13 08:46:25.862963.862963 mlpmodule.py:1075] group_w3 first element: -0.02490234375
WARNING 01-13 08:46:25.862604.862604 mlpmodule.py:1085] start einsum2
DEBUG 01-13 08:46:25.878304.878304 mlpmodule.py:1095] group einsum cost 0.02611255645751953 s
DEBUG 01-13 08:46:25.879549.879549 mlpmodule.py:1103] cpy2cputensor cost 0.0006997585296630859 s
INFO 01-13 08:46:25.889455.889455 client.py:127] Model loaded
DEBUG 01-13 08:46:25.889668.889668 cuda_h.py:19] end wait_experts cost 0.0464472770690918 seconds
DEBUG 01-13 08:46:25.889007.889007 cuda_h.py:10] start gpu_experts
DEBUG 01-13 08:46:25.890652.890652 mlpmodule.py:559] gpu group tensors cost 0.000919342041015625 s
DEBUG 01-13 08:46:25.893370.893370 mlpmodule.py:592] gpu pad cost 0.0023806095123291016 s
DEBUG 01-13 08:46:25.893088.893088 mlpmodule.py:598] start_w1
DEBUG 01-13 08:46:25.893628.893628 mlpmodule.py:602] start_w3
DEBUG 01-13 08:46:25.894225.894225 mlpmodule.py:608] start_w2
DEBUG 01-13 08:46:25.894922.894922 mlpmodule.py:611] gpu group einsum cost 0.0009641647338867188 s
DEBUG 01-13 08:46:25.897187.897187 mlpmodule.py:683] gpu experts func einsum cost 0.007593631744384766 s
DEBUG 01-13 08:46:25.897939.897939 cuda_h.py:19] end gpu_experts cost 0.007819175720214844 seconds
DEBUG 01-13 08:46:25.897033.897033 cuda_h.py:10] start cpu_thread_manager_mp_wait
DEBUG 01-13 08:46:25.897108.897108 cuda_h.py:19] end cpu_thread_manager_mp_wait cost 5.888938903808594e-05 seconds
DEBUG 01-13 08:46:25.897198.897198 cuda_h.py:19] end layer_moe_generate_mp_l_17 cost 0.06587100028991699 seconds
DEBUG 01-13 08:46:25.898913.898913 lmp.py:1550] -------------------------------- end prefill layer 16 --------------------------------
DEBUG 01-13 08:46:25.898206.898206 lmp.py:1493] -------------------------------- start prefill layer 17 --------------------------------
DEBUG 01-13 08:46:25.898908.898908 cuda_h.py:10] start start_load_qkvogn_s_weight_l_18
DEBUG 01-13 08:46:25.898810.898810 cuda_h.py:10] start start_load_qkvogn_s_weight_l_18
DEBUG 01-13 08:46:25.898766.898766 cuda_h.py:19] end start_load_qkvogn_s_weight_l_18 cost 4.6253204345703125e-05 seconds
DEBUG 01-13 08:46:25.898184.898184 cuda_h.py:19] end start_load_qkvogn_s_weight_l_18 cost 7.724761962890625e-05 seconds
DEBUG 01-13 08:46:25.898510.898510 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-13 08:46:25.898552.898552 cuda_h.py:10] start sllm_worker_task
DEBUG 01-13 08:46:25.898365.898365 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-13 08:46:25.898280.898280 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-13 08:46:25.898364.898364 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-13 08:46:25.899094.899094 cuda_h.py:19] end allocate_cuda_memory cost 0.00039458274841308594 seconds
DEBUG 01-13 08:46:25.899924.899924 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-13 08:46:25.899548.899548 sllm_store_c.py:27] get device uuid map
DEBUG 01-13 08:46:25.899882.899882 sllm_store_c.py:29] call client load into gpu
DEBUG 01-13 08:46:25.899253.899253 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 91af73c7-a6f0-49bf-8253-0a064fc05182
DEBUG 01-13 08:46:25.899535.899535 client.py:106] call stub.LoadModelAsync
DEBUG 01-13 08:46:25.900302.900302 cuda_h.py:10] start self_attn
INFO 01-13 08:46:25.900717.900717 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 91af73c7-a6f0-49bf-8253-0a064fc05182
DEBUG 01-13 08:46:25.900745.900745 cuda_h.py:19] end load_into_gpu_async cost 0.0013415813446044922 seconds
DEBUG 01-13 08:46:25.900494.900494 cuda_h.py:10] start restore_tensors2
DEBUG 01-13 08:46:25.900743.900743 cuda_h.py:19] end restore_tensors2 cost 8.177757263183594e-05 seconds
DEBUG 01-13 08:46:25.901738.901738 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.00209808349609375 seconds
INFO 01-13 08:46:25.901455.901455 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 91af73c7-a6f0-49bf-8253-0a064fc05182
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-13 08:46:25.904598.904598 cuda_h.py:19] end self_attn cost 0.0044367313385009766 seconds
DEBUG 01-13 08:46:25.904008.904008 cuda_h.py:19] end iln_self_attn_paln cost 0.0063397884368896484 seconds
DEBUG 01-13 08:46:25.904427.904427 cuda_h.py:10] start layer_moe_generate_mp_l_18
DEBUG 01-13 08:46:25.905528.905528 cuda_h.py:10] start gate
DEBUG 01-13 08:46:25.905189.905189 mlpmodule.py:785]  experts func einsum cost 0.06761384010314941 s
DEBUG 01-13 08:46:25.905073.905073 cuda_h.py:19] end gate cost 0.0008206367492675781 seconds
DEBUG 01-13 08:46:25.905433.905433 cuda_h.py:10] start experts_map_get
DEBUG 01-13 08:46:25.906039.906039 lmp.py:1611] 
DEBUG 01-13 08:46:25.906039.906039 lmp.py:1611] Expert Token Distribution & Device Allocation:
DEBUG 01-13 08:46:25.906372.906372 lmp.py:1612]   Total experts: 64
DEBUG 01-13 08:46:25.906644.906644 lmp.py:1613]   CPU experts: 32 (50%)
DEBUG 01-13 08:46:25.906817.906817 lmp.py:1614]   GPU experts: 32 (50%)
DEBUG 01-13 08:46:25.906129.906129 lmp.py:1615] 
DEBUG 01-13 08:46:25.906129.906129 lmp.py:1615]   Expert ID | Tokens | Device
DEBUG 01-13 08:46:25.906441.906441 lmp.py:1616]   -----------------------------------
DEBUG 01-13 08:46:25.906713.906713 lmp.py:1622]   Expert  4 |      8 | CPU
DEBUG 01-13 08:46:25.906787.906787 lmp.py:1622]   Expert 28 |     28 | CPU
DEBUG 01-13 08:46:25.906668.906668 lmp.py:1622]   Expert  7 |     37 | CPU
DEBUG 01-13 08:46:25.906311.906311 lmp.py:1622]   Expert 53 |     60 | CPU
DEBUG 01-13 08:46:25.906131.906131 cuda_h.py:19] end experts_func_gpu_einsum_mp cost 0.06907987594604492 seconds
DEBUG 01-13 08:46:25.906954.906954 lmp.py:1622]   Expert 52 |     66 | CPU
DEBUG 01-13 08:46:25.906789.906789 lmp.py:1622]   Expert 43 |     73 | CPU
DEBUG 01-13 08:46:25.906671.906671 lmp.py:1622]   Expert 12 |     87 | CPU
DEBUG 01-13 08:46:25.906075.906075 lmp.py:1622]   Expert 49 |     87 | CPU
DEBUG 01-13 08:46:25.906718.906718 lmp.py:1622]   Expert 24 |     91 | CPU
DEBUG 01-13 08:46:25.906030.906030 lmp.py:1622]   Expert 33 |    103 | CPU
DEBUG 01-13 08:46:25.906740.906740 lmp.py:1622]   Expert 47 |    106 | CPU
DEBUG 01-13 08:46:25.906098.906098 lmp.py:1622]   Expert 39 |    108 | CPU
DEBUG 01-13 08:46:25.906218.906218 lmp.py:1622]   Expert 50 |    108 | CPU
DEBUG 01-13 08:46:25.906099.906099 lmp.py:1622]   Expert  2 |    112 | CPU
DEBUG 01-13 08:46:25.906219.906219 lmp.py:1622]   Expert 15 |    116 | CPU
DEBUG 01-13 08:46:25.906100.906100 lmp.py:1622]   Expert 61 |    120 | CPU
DEBUG 01-13 08:46:25.906982.906982 lmp.py:1622]   Expert  6 |    121 | CPU
DEBUG 01-13 08:46:25.906101.906101 lmp.py:1622]   Expert 60 |    121 | CPU
DEBUG 01-13 08:46:25.906221.906221 lmp.py:1622]   Expert 36 |    122 | CPU
DEBUG 01-13 08:46:25.906394.906394 lmp.py:1622]   Expert 25 |    126 | CPU
DEBUG 01-13 08:46:25.906468.906468 lmp.py:1622]   Expert 59 |    144 | CPU
DEBUG 01-13 08:46:25.906872.906872 lmp.py:1622]   Expert  3 |    148 | CPU
DEBUG 01-13 08:46:25.907992.907992 lmp.py:1622]   Expert 27 |    152 | CPU
DEBUG 01-13 08:46:25.907397.907397 lmp.py:1622]   Expert 58 |    152 | CPU
DEBUG 01-13 08:46:25.907324.907324 lmp.py:1622]   Expert 31 |    153 | CPU
DEBUG 01-13 08:46:25.907252.907252 lmp.py:1622]   Expert 30 |    154 | CPU
DEBUG 01-13 08:46:25.907418.907418 lmp.py:1622]   Expert 38 |    154 | CPU
DEBUG 01-13 08:46:25.907108.907108 lmp.py:1622]   Expert  8 |    156 | CPU
DEBUG 01-13 08:46:25.907274.907274 lmp.py:1622]   Expert 10 |    159 | CPU
DEBUG 01-13 08:46:25.907963.907963 lmp.py:1622]   Expert 32 |    159 | CPU
DEBUG 01-13 08:46:25.907652.907652 lmp.py:1622]   Expert 40 |    159 | CPU
DEBUG 01-13 08:46:25.907818.907818 lmp.py:1622]   Expert 37 |    162 | CPU
DEBUG 01-13 08:46:25.907177.907177 lmp.py:1622]   Expert 41 |    162 | GPU
DEBUG 01-13 08:46:25.907157.907157 lmp.py:1622]   Expert 57 |    163 | GPU
DEBUG 01-13 08:46:25.907231.907231 lmp.py:1622]   Expert 14 |    165 | GPU
DEBUG 01-13 08:46:25.907397.907397 lmp.py:1622]   Expert 46 |    168 | GPU
DEBUG 01-13 08:46:25.907563.907563 lmp.py:1622]   Expert 42 |    171 | GPU
DEBUG 01-13 08:46:25.907729.907729 lmp.py:1622]   Expert 54 |    171 | GPU
DEBUG 01-13 08:46:25.907419.907419 lmp.py:1622]   Expert 19 |    172 | GPU
DEBUG 01-13 08:46:25.907346.907346 lmp.py:1622]   Expert 11 |    176 | GPU
DEBUG 01-13 08:46:25.907513.907513 lmp.py:1622]   Expert 34 |    182 | GPU
DEBUG 01-13 08:46:25.907202.907202 lmp.py:1622]   Expert 22 |    192 | GPU
DEBUG 01-13 08:46:25.907130.907130 lmp.py:1622]   Expert 26 |    196 | GPU
DEBUG 01-13 08:46:25.907296.907296 lmp.py:1622]   Expert  0 |    197 | GPU
DEBUG 01-13 08:46:25.907700.907700 lmp.py:1622]   Expert 18 |    198 | GPU
DEBUG 01-13 08:46:25.907966.907966 lmp.py:1622]   Expert  1 |    199 | GPU
DEBUG 01-13 08:46:25.907324.907324 lmp.py:1622]   Expert 56 |    203 | GPU
DEBUG 01-13 08:46:25.907967.907967 lmp.py:1622]   Expert 51 |    208 | GPU
DEBUG 01-13 08:46:25.907895.907895 lmp.py:1622]   Expert 44 |    210 | GPU
DEBUG 01-13 08:46:25.907584.907584 lmp.py:1622]   Expert 20 |    221 | GPU
DEBUG 01-13 08:46:25.907512.907512 lmp.py:1622]   Expert 29 |    229 | GPU
DEBUG 01-13 08:46:25.907963.907963 lmp.py:1622]   Expert 45 |    229 | GPU
DEBUG 01-13 08:46:25.907890.907890 lmp.py:1622]   Expert 48 |    236 | GPU
DEBUG 01-13 08:46:25.907580.907580 lmp.py:1622]   Expert 21 |    244 | GPU
DEBUG 01-13 08:46:25.907269.907269 lmp.py:1622]   Expert 35 |    253 | GPU
DEBUG 01-13 08:46:25.907197.907197 lmp.py:1622]   Expert 16 |    254 | GPU
DEBUG 01-13 08:46:25.907363.907363 lmp.py:1622]   Expert 55 |    267 | GPU
DEBUG 01-13 08:46:25.907052.907052 lmp.py:1622]   Expert  5 |    292 | GPU
DEBUG 01-13 08:46:25.907271.907271 lmp.py:1622]   Expert 23 |    373 | GPU
DEBUG 01-13 08:46:25.907630.907630 lmp.py:1622]   Expert 13 |    389 | GPU
DEBUG 01-13 08:46:25.907034.907034 lmp.py:1622]   Expert 17 |    436 | GPU
DEBUG 01-13 08:46:25.907962.907962 lmp.py:1622]   Expert  9 |    447 | GPU
DEBUG 01-13 08:46:25.907651.907651 lmp.py:1622]   Expert 63 |    450 | GPU
DEBUG 01-13 08:46:25.907340.907340 lmp.py:1622]   Expert 62 |   1183 | GPU
DEBUG 01-13 08:46:25.907460.907460 lmp.py:1623] 
DEBUG 01-13 08:46:25.907460.907460 lmp.py:1623]   CPU total tokens: 3652 (29.7%)
DEBUG 01-13 08:46:25.907819.907819 lmp.py:1624]   GPU total tokens: 8636 (70.3%)
DEBUG 01-13 08:46:25.907468.907468 cuda_h.py:19] end experts_map_get cost 0.0018222332000732422 seconds
DEBUG 01-13 08:46:25.907040.907040 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-13 08:46:25.907942.907942 lmp.py:1632] 
DEBUG 01-13 08:46:25.907942.907942 lmp.py:1632]   Computing 32 experts on CPU MP...
DEBUG 01-13 08:46:25.907977.907977 cuda_h.py:19] end cpu_experts_submit cost 6.103515625e-05 seconds
DEBUG 01-13 08:46:25.907627.907627 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-13 08:46:25.908252.908252 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-13 08:46:25.908079.908079 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-13 08:46:25.908447.908447 cuda_h.py:19] end allocate_cuda_memory cost 0.0002675056457519531 seconds
DEBUG 01-13 08:46:25.908966.908966 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-13 08:46:25.908345.908345 sllm_store_c.py:27] get device uuid map
DEBUG 01-13 08:46:25.908637.908637 sllm_store_c.py:29] call client load into gpu
DEBUG 01-13 08:46:25.908493.908493 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, c169365f-8f4d-4a52-a0a9-85e66dd755f4
DEBUG 01-13 08:46:25.909588.909588 client.py:106] call stub.LoadModelAsync
INFO 01-13 08:46:25.909744.909744 client.py:127] Model loaded
DEBUG 01-13 08:46:25.909693.909693 cuda_h.py:10] start restore2model
INFO 01-13 08:46:25.910745.910745 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, c169365f-8f4d-4a52-a0a9-85e66dd755f4
DEBUG 01-13 08:46:25.910815.910815 cuda_h.py:19] end load_into_gpu_async cost 0.0017826557159423828 seconds
DEBUG 01-13 08:46:25.910194.910194 cuda_h.py:10] start restore_tensors2
DEBUG 01-13 08:46:25.910195.910195 cuda_h.py:10] start experts_func_gpu_einsum_mp
DEBUG 01-13 08:46:25.911934.911934 cuda_h.py:19] end restore_tensors2 cost 0.0005133152008056641 seconds
DEBUG 01-13 08:46:25.911527.911527 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0030531883239746094 seconds
DEBUG 01-13 08:46:25.911218.911218 cuda_h.py:10] start restore2model
DEBUG 01-13 08:46:25.911029.911029 cuda_h.py:19] end restore2model cost 0.00045680999755859375 seconds
DEBUG 01-13 08:46:25.911769.911769 cuda_h.py:19] end sllm_worker_task cost 0.013046741485595703 seconds
DEBUG 01-13 08:46:25.915829.915829 cuda_h.py:19] end restore2model cost 0.0037844181060791016 seconds
DEBUG 01-13 08:46:25.915461.915461 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.007086515426635742 seconds
DEBUG 01-13 08:46:25.915495.915495 cuda_h.py:10] start gpu_sexperts
DEBUG 01-13 08:46:25.915660.915660 cuda_h.py:19] end gpu_sexperts cost 0.00033473968505859375 seconds
DEBUG 01-13 08:46:25.915588.915588 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-13 08:46:25.915325.915325 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 1.9550323486328125e-05 seconds
DEBUG 01-13 08:46:25.915690.915690 cuda_h.py:10] start wait_experts
INFO 01-13 08:46:25.915724.915724 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, c169365f-8f4d-4a52-a0a9-85e66dd755f4
DEBUG 01-13 08:46:25.919687.919687 mlpmodule.py:1006] group tensors cost 0.008322477340698242 s
DEBUG 01-13 08:46:25.921853.921853 mlpmodule.py:1044] pad cost 0.0016033649444580078 s
DEBUG 01-13 08:46:25.921081.921081 mlpmodule.py:1050] create cpu tensor cost 4.0531158447265625e-05 s
DEBUG 01-13 08:46:25.921408.921408 mlpmodule.py:1055] move to cpu cost 3.0994415283203125e-05 s
DEBUG 01-13 08:46:25.930011.930011 mlpmodule.py:1069] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-13 08:46:25.930116.930116 mlpmodule.py:1070] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-13 08:46:25.930497.930497 mlpmodule.py:1075] group_w3 first element: 0.00457763671875
WARNING 01-13 08:46:25.930926.930926 mlpmodule.py:1085] start einsum2
DEBUG 01-13 08:46:25.944465.944465 mlpmodule.py:1095] group einsum cost 0.0223848819732666 s
DEBUG 01-13 08:46:25.944329.944329 mlpmodule.py:1103] cpy2cputensor cost 0.0006766319274902344 s
INFO 01-13 08:46:25.961922.961922 client.py:127] Model loaded
DEBUG 01-13 08:46:25.962068.962068 cuda_h.py:19] end wait_experts cost 0.04643440246582031 seconds
DEBUG 01-13 08:46:25.962500.962500 cuda_h.py:10] start gpu_experts
DEBUG 01-13 08:46:25.963079.963079 mlpmodule.py:559] gpu group tensors cost 0.0007538795471191406 s
DEBUG 01-13 08:46:25.965442.965442 mlpmodule.py:592] gpu pad cost 0.0026464462280273438 s
DEBUG 01-13 08:46:25.965512.965512 mlpmodule.py:598] start_w1
DEBUG 01-13 08:46:25.966562.966562 mlpmodule.py:602] start_w3
DEBUG 01-13 08:46:25.966914.966914 mlpmodule.py:608] start_w2
DEBUG 01-13 08:46:25.967286.967286 mlpmodule.py:611] gpu group einsum cost 0.0013394355773925781 s
DEBUG 01-13 08:46:25.970299.970299 mlpmodule.py:785]  experts func einsum cost 0.05924201011657715 s
DEBUG 01-13 08:46:25.970918.970918 mlpmodule.py:683] gpu experts func einsum cost 0.008013725280761719 s
DEBUG 01-13 08:46:25.970405.970405 cuda_h.py:19] end gpu_experts cost 0.008208036422729492 seconds
DEBUG 01-13 08:46:25.970314.970314 cuda_h.py:10] start cpu_thread_manager_mp_wait
DEBUG 01-13 08:46:25.970495.970495 cuda_h.py:19] end experts_func_gpu_einsum_mp cost 0.05991053581237793 seconds
DEBUG 01-13 08:46:25.970642.970642 cuda_h.py:19] end cpu_thread_manager_mp_wait cost 6.937980651855469e-05 seconds
DEBUG 01-13 08:46:25.970301.970301 cuda_h.py:19] end layer_moe_generate_mp_l_18 cost 0.06560087203979492 seconds
DEBUG 01-13 08:46:25.970531.970531 lmp.py:1550] -------------------------------- end prefill layer 17 --------------------------------
DEBUG 01-13 08:46:25.971678.971678 lmp.py:1493] -------------------------------- start prefill layer 18 --------------------------------
DEBUG 01-13 08:46:25.971142.971142 cuda_h.py:10] start start_load_qkvogn_s_weight_l_19
DEBUG 01-13 08:46:25.971805.971805 cuda_h.py:10] start start_load_qkvogn_s_weight_l_19
DEBUG 01-13 08:46:25.971516.971516 cuda_h.py:19] end start_load_qkvogn_s_weight_l_19 cost 4.076957702636719e-05 seconds
DEBUG 01-13 08:46:25.971519.971519 cuda_h.py:10] start sllm_worker_task
DEBUG 01-13 08:46:25.971878.971878 cuda_h.py:19] end start_load_qkvogn_s_weight_l_19 cost 0.00016736984252929688 seconds
DEBUG 01-13 08:46:25.971193.971193 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-13 08:46:25.971453.971453 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-13 08:46:25.971806.971806 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-13 08:46:25.971625.971625 cuda_h.py:19] end allocate_cuda_memory cost 0.0002281665802001953 seconds
DEBUG 01-13 08:46:25.971543.971543 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-13 08:46:25.971479.971479 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-13 08:46:25.972390.972390 sllm_store_c.py:27] get device uuid map
DEBUG 01-13 08:46:25.972346.972346 sllm_store_c.py:29] call client load into gpu
DEBUG 01-13 08:46:25.972062.972062 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, e1b19596-1551-47f8-8521-7a92a310ab7d
DEBUG 01-13 08:46:25.972463.972463 client.py:106] call stub.LoadModelAsync
DEBUG 01-13 08:46:25.972435.972435 cuda_h.py:10] start self_attn
INFO 01-13 08:46:25.974209.974209 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, e1b19596-1551-47f8-8521-7a92a310ab7d
DEBUG 01-13 08:46:25.974689.974689 cuda_h.py:19] end load_into_gpu_async cost 0.0020122528076171875 seconds
DEBUG 01-13 08:46:25.974736.974736 cuda_h.py:10] start restore_tensors2
DEBUG 01-13 08:46:25.974290.974290 cuda_h.py:19] end restore_tensors2 cost 9.202957153320312e-05 seconds
DEBUG 01-13 08:46:25.974034.974034 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0028688907623291016 seconds
INFO 01-13 08:46:25.974110.974110 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, e1b19596-1551-47f8-8521-7a92a310ab7d
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-13 08:46:25.977744.977744 cuda_h.py:19] end self_attn cost 0.004199504852294922 seconds
DEBUG 01-13 08:46:25.977816.977816 cuda_h.py:19] end iln_self_attn_paln cost 0.0059545040130615234 seconds
DEBUG 01-13 08:46:25.977328.977328 cuda_h.py:10] start layer_moe_generate_mp_l_19
DEBUG 01-13 08:46:25.977521.977521 cuda_h.py:10] start gate
DEBUG 01-13 08:46:25.978622.978622 cuda_h.py:19] end gate cost 0.0008087158203125 seconds
DEBUG 01-13 08:46:25.978551.978551 cuda_h.py:10] start experts_map_get
DEBUG 01-13 08:46:25.979475.979475 lmp.py:1611] 
DEBUG 01-13 08:46:25.979475.979475 lmp.py:1611] Expert Token Distribution & Device Allocation:
DEBUG 01-13 08:46:25.979139.979139 lmp.py:1612]   Total experts: 64
DEBUG 01-13 08:46:25.979649.979649 lmp.py:1613]   CPU experts: 32 (50%)
DEBUG 01-13 08:46:25.979345.979345 lmp.py:1614]   GPU experts: 32 (50%)
DEBUG 01-13 08:46:25.979896.979896 lmp.py:1615] 
DEBUG 01-13 08:46:25.979896.979896 lmp.py:1615]   Expert ID | Tokens | Device
DEBUG 01-13 08:46:25.979400.979400 lmp.py:1616]   -----------------------------------
DEBUG 01-13 08:46:25.979864.979864 lmp.py:1622]   Expert 32 |     32 | CPU
DEBUG 01-13 08:46:25.979176.979176 lmp.py:1622]   Expert 30 |     48 | CPU
DEBUG 01-13 08:46:25.979488.979488 lmp.py:1622]   Expert  5 |     51 | CPU
DEBUG 01-13 08:46:25.979562.979562 lmp.py:1622]   Expert 46 |     71 | CPU
DEBUG 01-13 08:46:25.979397.979397 lmp.py:1622]   Expert 40 |     80 | CPU
DEBUG 01-13 08:46:25.979755.979755 lmp.py:1622]   Expert  8 |     86 | CPU
DEBUG 01-13 08:46:25.979875.979875 lmp.py:1622]   Expert 12 |     98 | CPU
DEBUG 01-13 08:46:25.979471.979471 lmp.py:1622]   Expert 27 |    107 | CPU
DEBUG 01-13 08:46:25.979260.979260 lmp.py:1622]   Expert  3 |    111 | CPU
DEBUG 01-13 08:46:25.979049.979049 lmp.py:1622]   Expert 17 |    112 | CPU
DEBUG 01-13 08:46:25.979314.979314 lmp.py:1622]   Expert 58 |    112 | CPU
DEBUG 01-13 08:46:25.979626.979626 lmp.py:1622]   Expert 60 |    118 | CPU
DEBUG 01-13 08:46:25.979985.979985 lmp.py:1622]   Expert 28 |    119 | CPU
DEBUG 01-13 08:46:25.979866.979866 lmp.py:1622]   Expert 21 |    120 | CPU
DEBUG 01-13 08:46:25.979986.979986 lmp.py:1622]   Expert 29 |    125 | CPU
DEBUG 01-13 08:46:25.979867.979867 lmp.py:1622]   Expert 25 |    126 | CPU
DEBUG 01-13 08:46:25.979225.979225 lmp.py:1622]   Expert 41 |    127 | CPU
DEBUG 01-13 08:46:25.979345.979345 lmp.py:1622]   Expert 35 |    131 | CPU
DEBUG 01-13 08:46:25.979227.979227 lmp.py:1622]   Expert  0 |    137 | CPU
DEBUG 01-13 08:46:25.979108.979108 lmp.py:1622]   Expert 19 |    137 | CPU
DEBUG 01-13 08:46:25.979989.979989 lmp.py:1622]   Expert 52 |    139 | CPU
DEBUG 01-13 08:46:25.979540.979540 lmp.py:1622]   Expert 54 |    143 | CPU
DEBUG 01-13 08:46:25.979898.979898 lmp.py:1622]   Expert  6 |    147 | CPU
DEBUG 01-13 08:46:25.979687.979687 lmp.py:1622]   Expert 56 |    151 | CPU
DEBUG 01-13 08:46:25.979760.979760 lmp.py:1622]   Expert 37 |    154 | CPU
DEBUG 01-13 08:46:25.979118.979118 lmp.py:1622]   Expert 36 |    160 | CPU
DEBUG 01-13 08:46:25.979404.979404 lmp.py:1622]   Expert 48 |    160 | CPU
DEBUG 01-13 08:46:25.979001.979001 lmp.py:1622]   Expert 53 |    160 | CPU
DEBUG 01-13 08:46:25.979359.979359 lmp.py:1622]   Expert 63 |    160 | CPU
DEBUG 01-13 08:46:25.979194.979194 lmp.py:1622]   Expert 59 |    167 | CPU
DEBUG 01-13 08:46:25.979552.979552 lmp.py:1622]   Expert  9 |    183 | CPU
DEBUG 01-13 08:46:25.979388.979388 lmp.py:1622]   Expert  1 |    190 | CPU
DEBUG 01-13 08:46:25.979461.979461 lmp.py:1622]   Expert 39 |    190 | GPU
DEBUG 01-13 08:46:25.979011.979011 lmp.py:1622]   Expert 20 |    194 | GPU
DEBUG 01-13 08:46:25.979277.979277 lmp.py:1622]   Expert  7 |    199 | GPU
DEBUG 01-13 08:46:25.979827.979827 lmp.py:1622]   Expert 43 |    199 | GPU
DEBUG 01-13 08:46:25.979662.979662 lmp.py:1622]   Expert 42 |    202 | GPU
DEBUG 01-13 08:46:25.979021.979021 lmp.py:1622]   Expert 11 |    203 | GPU
DEBUG 01-13 08:46:25.979379.979379 lmp.py:1622]   Expert 61 |    203 | GPU
DEBUG 01-13 08:46:25.979499.979499 lmp.py:1622]   Expert 34 |    210 | GPU
DEBUG 01-13 08:46:25.979857.979857 lmp.py:1622]   Expert 47 |    211 | GPU
DEBUG 01-13 08:46:25.979169.979169 lmp.py:1622]   Expert 16 |    217 | GPU
DEBUG 01-13 08:46:25.979957.979957 lmp.py:1622]   Expert 55 |    219 | GPU
DEBUG 01-13 08:46:25.979746.979746 lmp.py:1622]   Expert 13 |    221 | GPU
DEBUG 01-13 08:46:25.979058.979058 lmp.py:1622]   Expert 57 |    226 | GPU
DEBUG 01-13 08:46:25.980132.980132 lmp.py:1622]   Expert 18 |    230 | GPU
DEBUG 01-13 08:46:25.980251.980251 lmp.py:1622]   Expert 15 |    232 | GPU
DEBUG 01-13 08:46:25.980610.980610 lmp.py:1622]   Expert 22 |    241 | GPU
DEBUG 01-13 08:46:25.980206.980206 lmp.py:1622]   Expert 50 |    241 | GPU
DEBUG 01-13 08:46:25.980565.980565 lmp.py:1622]   Expert  4 |    244 | GPU
DEBUG 01-13 08:46:25.980923.980923 lmp.py:1622]   Expert 31 |    246 | GPU
DEBUG 01-13 08:46:25.980281.980281 lmp.py:1622]   Expert 45 |    246 | GPU
DEBUG 01-13 08:46:25.980878.980878 lmp.py:1622]   Expert 33 |    247 | GPU
DEBUG 01-13 08:46:25.980713.980713 lmp.py:1622]   Expert 51 |    253 | GPU
DEBUG 01-13 08:46:25.980501.980501 lmp.py:1622]   Expert 49 |    264 | GPU
DEBUG 01-13 08:46:25.980529.980529 lmp.py:1622]   Expert 38 |    274 | GPU
DEBUG 01-13 08:46:25.980364.980364 lmp.py:1622]   Expert 26 |    282 | GPU
DEBUG 01-13 08:46:25.980960.980960 lmp.py:1622]   Expert 10 |    289 | GPU
DEBUG 01-13 08:46:25.980557.980557 lmp.py:1622]   Expert 44 |    293 | GPU
DEBUG 01-13 08:46:25.980915.980915 lmp.py:1622]   Expert 24 |    308 | GPU
DEBUG 01-13 08:46:25.980750.980750 lmp.py:1622]   Expert 14 |    312 | GPU
DEBUG 01-13 08:46:25.980108.980108 lmp.py:1622]   Expert  2 |    314 | GPU
DEBUG 01-13 08:46:25.980705.980705 lmp.py:1622]   Expert 23 |    445 | GPU
DEBUG 01-13 08:46:25.980302.980302 lmp.py:1622]   Expert 62 |    671 | GPU
DEBUG 01-13 08:46:25.980852.980852 lmp.py:1623] 
DEBUG 01-13 08:46:25.980852.980852 lmp.py:1623]   CPU total tokens: 3962 (32.2%)
DEBUG 01-13 08:46:25.980986.980986 lmp.py:1624]   GPU total tokens: 8326 (67.8%)
DEBUG 01-13 08:46:25.980927.980927 cuda_h.py:19] end experts_map_get cost 0.0018968582153320312 seconds
DEBUG 01-13 08:46:25.980790.980790 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-13 08:46:25.980930.980930 lmp.py:1632] 
DEBUG 01-13 08:46:25.980930.980930 lmp.py:1632]   Computing 32 experts on CPU MP...
DEBUG 01-13 08:46:25.980436.980436 cuda_h.py:19] end cpu_experts_submit cost 5.7697296142578125e-05 seconds
DEBUG 01-13 08:46:25.980609.980609 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-13 08:46:25.980366.980366 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-13 08:46:25.980107.980107 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-13 08:46:25.981270.981270 cuda_h.py:19] end allocate_cuda_memory cost 0.0002510547637939453 seconds
DEBUG 01-13 08:46:25.981596.981596 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-13 08:46:25.981452.981452 sllm_store_c.py:27] get device uuid map
DEBUG 01-13 08:46:25.981791.981791 sllm_store_c.py:29] call client load into gpu
DEBUG 01-13 08:46:25.981348.981348 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 1b7a4d93-fbd7-4bb3-a28a-06df83709d1a
DEBUG 01-13 08:46:25.981642.981642 client.py:106] call stub.LoadModelAsync
INFO 01-13 08:46:25.982352.982352 client.py:127] Model loaded
DEBUG 01-13 08:46:25.982925.982925 cuda_h.py:10] start restore2model
DEBUG 01-13 08:46:25.983947.983947 cuda_h.py:19] end restore2model cost 0.0005922317504882812 seconds
DEBUG 01-13 08:46:25.983750.983750 cuda_h.py:19] end sllm_worker_task cost 0.01172780990600586 seconds
INFO 01-13 08:46:25.983389.983389 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 1b7a4d93-fbd7-4bb3-a28a-06df83709d1a
DEBUG 01-13 08:46:25.983771.983771 cuda_h.py:10] start experts_func_gpu_einsum_mp
DEBUG 01-13 08:46:25.983862.983862 cuda_h.py:19] end load_into_gpu_async cost 0.002160310745239258 seconds
DEBUG 01-13 08:46:25.983995.983995 cuda_h.py:10] start restore_tensors2
DEBUG 01-13 08:46:25.984643.984643 cuda_h.py:19] end restore_tensors2 cost 0.0005180835723876953 seconds
DEBUG 01-13 08:46:25.984618.984618 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.003353118896484375 seconds
DEBUG 01-13 08:46:25.984772.984772 cuda_h.py:10] start restore2model
DEBUG 01-13 08:46:25.987104.987104 cuda_h.py:19] end restore2model cost 0.0033729076385498047 seconds
DEBUG 01-13 08:46:25.987563.987563 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.006928205490112305 seconds
DEBUG 01-13 08:46:25.987359.987359 cuda_h.py:10] start gpu_sexperts
DEBUG 01-13 08:46:25.987491.987491 cuda_h.py:19] end gpu_sexperts cost 0.00034618377685546875 seconds
DEBUG 01-13 08:46:25.988466.988466 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-13 08:46:25.988865.988865 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 1.8835067749023438e-05 seconds
DEBUG 01-13 08:46:25.988991.988991 cuda_h.py:10] start wait_experts
INFO 01-13 08:46:25.988741.988741 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 1b7a4d93-fbd7-4bb3-a28a-06df83709d1a
DEBUG 01-13 08:46:25.994855.994855 mlpmodule.py:1006] group tensors cost 0.009799480438232422 s
DEBUG 01-13 08:46:25.998387.998387 mlpmodule.py:1044] pad cost 0.0031425952911376953 s
DEBUG 01-13 08:46:25.999120.999120 mlpmodule.py:1050] create cpu tensor cost 6.008148193359375e-05 s
DEBUG 01-13 08:46:25.999254.999254 mlpmodule.py:1055] move to cpu cost 3.0040740966796875e-05 s
DEBUG 01-13 08:46:26.009204.009204 mlpmodule.py:1069] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-13 08:46:26.009037.009037 mlpmodule.py:1070] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-13 08:46:26.009570.009570 mlpmodule.py:1075] group_w3 first element: 0.0024871826171875
WARNING 01-13 08:46:26.009058.009058 mlpmodule.py:1085] start einsum2
DEBUG 01-13 08:46:26.024518.024518 mlpmodule.py:1095] group einsum cost 0.025201797485351562 s
DEBUG 01-13 08:46:26.025591.025591 mlpmodule.py:1103] cpy2cputensor cost 0.0007703304290771484 s
INFO 01-13 08:46:26.035756.035756 client.py:127] Model loaded
DEBUG 01-13 08:46:26.035458.035458 cuda_h.py:19] end wait_experts cost 0.04752230644226074 seconds
DEBUG 01-13 08:46:26.035851.035851 cuda_h.py:10] start gpu_experts
DEBUG 01-13 08:46:26.036064.036064 mlpmodule.py:559] gpu group tensors cost 0.0008928775787353516 s
DEBUG 01-13 08:46:26.039367.039367 mlpmodule.py:592] gpu pad cost 0.0024154186248779297 s
DEBUG 01-13 08:46:26.039370.039370 mlpmodule.py:598] start_w1
DEBUG 01-13 08:46:26.039997.039997 mlpmodule.py:602] start_w3
DEBUG 01-13 08:46:26.040601.040601 mlpmodule.py:608] start_w2
DEBUG 01-13 08:46:26.040807.040807 mlpmodule.py:611] gpu group einsum cost 0.000986337661743164 s
DEBUG 01-13 08:46:26.043826.043826 mlpmodule.py:683] gpu experts func einsum cost 0.007639646530151367 s
DEBUG 01-13 08:46:26.043068.043068 cuda_h.py:19] end gpu_experts cost 0.007853269577026367 seconds
DEBUG 01-13 08:46:26.043208.043208 cuda_h.py:10] start cpu_thread_manager_mp_wait
DEBUG 01-13 08:46:26.043430.043430 cuda_h.py:19] end cpu_thread_manager_mp_wait cost 5.53131103515625e-05 seconds
DEBUG 01-13 08:46:26.043612.043612 cuda_h.py:19] end layer_moe_generate_mp_l_19 cost 0.0662229061126709 seconds
DEBUG 01-13 08:46:26.044009.044009 lmp.py:1550] -------------------------------- end prefill layer 18 --------------------------------
DEBUG 01-13 08:46:26.044546.044546 lmp.py:1493] -------------------------------- start prefill layer 19 --------------------------------
DEBUG 01-13 08:46:26.044441.044441 cuda_h.py:10] start start_load_qkvogn_s_weight_l_20
DEBUG 01-13 08:46:26.044343.044343 cuda_h.py:10] start start_load_qkvogn_s_weight_l_20
DEBUG 01-13 08:46:26.044915.044915 cuda_h.py:19] end start_load_qkvogn_s_weight_l_20 cost 4.291534423828125e-05 seconds
DEBUG 01-13 08:46:26.044532.044532 cuda_h.py:19] end start_load_qkvogn_s_weight_l_20 cost 7.462501525878906e-05 seconds
DEBUG 01-13 08:46:26.044559.044559 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-13 08:46:26.044244.044244 cuda_h.py:10] start sllm_worker_task
DEBUG 01-13 08:46:26.044050.044050 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-13 08:46:26.044489.044489 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-13 08:46:26.045010.045010 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-13 08:46:26.045743.045743 cuda_h.py:19] end allocate_cuda_memory cost 0.00036787986755371094 seconds
DEBUG 01-13 08:46:26.045997.045997 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-13 08:46:26.045698.045698 mlpmodule.py:785]  experts func einsum cost 0.0607151985168457 s
DEBUG 01-13 08:46:26.045575.045575 sllm_store_c.py:27] get device uuid map
DEBUG 01-13 08:46:26.045226.045226 sllm_store_c.py:29] call client load into gpu
DEBUG 01-13 08:46:26.045220.045220 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 43cd9aa1-b375-4ca4-8c63-656389291236
DEBUG 01-13 08:46:26.046363.046363 client.py:106] call stub.LoadModelAsync
DEBUG 01-13 08:46:26.046190.046190 cuda_h.py:19] end experts_func_gpu_einsum_mp cost 0.06276917457580566 seconds
DEBUG 01-13 08:46:26.046300.046300 cuda_h.py:10] start self_attn
INFO 01-13 08:46:26.047289.047289 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 43cd9aa1-b375-4ca4-8c63-656389291236
DEBUG 01-13 08:46:26.047990.047990 cuda_h.py:19] end load_into_gpu_async cost 0.001314401626586914 seconds
DEBUG 01-13 08:46:26.047641.047641 cuda_h.py:10] start restore_tensors2
DEBUG 01-13 08:46:26.047347.047347 cuda_h.py:19] end restore_tensors2 cost 0.00010275840759277344 seconds
DEBUG 01-13 08:46:26.047726.047726 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0023272037506103516 seconds
INFO 01-13 08:46:26.047471.047471 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 43cd9aa1-b375-4ca4-8c63-656389291236
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-13 08:46:26.051045.051045 cuda_h.py:19] end self_attn cost 0.0045702457427978516 seconds
DEBUG 01-13 08:46:26.051098.051098 cuda_h.py:19] end iln_self_attn_paln cost 0.006962776184082031 seconds
DEBUG 01-13 08:46:26.051478.051478 cuda_h.py:10] start layer_moe_generate_mp_l_20
DEBUG 01-13 08:46:26.051771.051771 cuda_h.py:10] start gate
DEBUG 01-13 08:46:26.052190.052190 cuda_h.py:19] end gate cost 0.0007975101470947266 seconds
DEBUG 01-13 08:46:26.052206.052206 cuda_h.py:10] start experts_map_get
DEBUG 01-13 08:46:26.052641.052641 lmp.py:1611] 
DEBUG 01-13 08:46:26.052641.052641 lmp.py:1611] Expert Token Distribution & Device Allocation:
DEBUG 01-13 08:46:26.053688.053688 lmp.py:1612]   Total experts: 64
DEBUG 01-13 08:46:26.053583.053583 lmp.py:1613]   CPU experts: 32 (50%)
DEBUG 01-13 08:46:26.053425.053425 lmp.py:1614]   GPU experts: 32 (50%)
DEBUG 01-13 08:46:26.053883.053883 lmp.py:1615] 
DEBUG 01-13 08:46:26.053883.053883 lmp.py:1615]   Expert ID | Tokens | Device
DEBUG 01-13 08:46:26.053532.053532 lmp.py:1616]   -----------------------------------
DEBUG 01-13 08:46:26.053189.053189 lmp.py:1622]   Expert 44 |     35 | CPU
DEBUG 01-13 08:46:26.053362.053362 lmp.py:1622]   Expert  1 |     50 | CPU
DEBUG 01-13 08:46:26.053104.053104 lmp.py:1622]   Expert 28 |     57 | CPU
DEBUG 01-13 08:46:26.053847.053847 lmp.py:1622]   Expert 60 |     66 | CPU
DEBUG 01-13 08:46:26.053351.053351 lmp.py:1622]   Expert 48 |     72 | CPU
DEBUG 01-13 08:46:26.053570.053570 lmp.py:1622]   Expert 27 |     81 | CPU
DEBUG 01-13 08:46:26.053266.053266 lmp.py:1622]   Expert  0 |    101 | CPU
DEBUG 01-13 08:46:26.053200.053200 lmp.py:1622]   Expert 59 |    108 | CPU
DEBUG 01-13 08:46:26.053420.053420 lmp.py:1622]   Expert 62 |    111 | CPU
DEBUG 01-13 08:46:26.053162.053162 lmp.py:1622]   Expert 30 |    112 | CPU
DEBUG 01-13 08:46:26.053666.053666 lmp.py:1622]   Expert 42 |    112 | CPU
DEBUG 01-13 08:46:26.053932.053932 lmp.py:1622]   Expert 22 |    115 | CPU
DEBUG 01-13 08:46:26.053197.053197 lmp.py:1622]   Expert 58 |    118 | CPU
DEBUG 01-13 08:46:26.053940.053940 lmp.py:1622]   Expert  8 |    127 | CPU
DEBUG 01-13 08:46:26.053397.053397 lmp.py:1622]   Expert 16 |    129 | CPU
DEBUG 01-13 08:46:26.053093.053093 lmp.py:1622]   Expert 12 |    133 | CPU
DEBUG 01-13 08:46:26.053657.053657 lmp.py:1622]   Expert 50 |    137 | CPU
DEBUG 01-13 08:46:26.053923.053923 lmp.py:1622]   Expert 57 |    141 | CPU
DEBUG 01-13 08:46:26.053189.053189 lmp.py:1622]   Expert  5 |    144 | CPU
DEBUG 01-13 08:46:26.053454.053454 lmp.py:1622]   Expert 56 |    145 | CPU
DEBUG 01-13 08:46:26.053481.053481 lmp.py:1622]   Expert 15 |    151 | CPU
DEBUG 01-13 08:46:26.053747.053747 lmp.py:1622]   Expert 26 |    155 | CPU
DEBUG 01-13 08:46:26.053012.053012 lmp.py:1622]   Expert 55 |    155 | CPU
DEBUG 01-13 08:46:26.053516.053516 lmp.py:1622]   Expert 32 |    158 | CPU
DEBUG 01-13 08:46:26.053020.053020 lmp.py:1622]   Expert 47 |    160 | CPU
DEBUG 01-13 08:46:26.053730.053730 lmp.py:1622]   Expert 24 |    162 | CPU
DEBUG 01-13 08:46:26.053996.053996 lmp.py:1622]   Expert  2 |    164 | CPU
DEBUG 01-13 08:46:26.053784.053784 lmp.py:1622]   Expert 40 |    166 | CPU
DEBUG 01-13 08:46:26.053335.053335 lmp.py:1622]   Expert 52 |    167 | CPU
DEBUG 01-13 08:46:26.053647.053647 lmp.py:1622]   Expert 34 |    168 | CPU
DEBUG 01-13 08:46:26.053959.053959 lmp.py:1622]   Expert 41 |    168 | CPU
DEBUG 01-13 08:46:26.053509.053509 lmp.py:1622]   Expert  3 |    172 | CPU
DEBUG 01-13 08:46:26.053536.053536 lmp.py:1622]   Expert  6 |    174 | GPU
DEBUG 01-13 08:46:26.053610.053610 lmp.py:1622]   Expert 13 |    174 | GPU
DEBUG 01-13 08:46:26.053160.053160 lmp.py:1622]   Expert 54 |    174 | GPU
DEBUG 01-13 08:46:26.053472.053472 lmp.py:1622]   Expert 18 |    176 | GPU
DEBUG 01-13 08:46:26.053022.053022 lmp.py:1622]   Expert 20 |    178 | GPU
DEBUG 01-13 08:46:26.053288.053288 lmp.py:1622]   Expert 46 |    182 | GPU
DEBUG 01-13 08:46:26.053553.053553 lmp.py:1622]   Expert 37 |    183 | GPU
DEBUG 01-13 08:46:26.053819.053819 lmp.py:1622]   Expert 19 |    192 | GPU
DEBUG 01-13 08:46:26.053131.053131 lmp.py:1622]   Expert 51 |    196 | GPU
DEBUG 01-13 08:46:26.053681.053681 lmp.py:1622]   Expert 31 |    198 | GPU
DEBUG 01-13 08:46:26.053231.053231 lmp.py:1622]   Expert 25 |    200 | GPU
DEBUG 01-13 08:46:26.054020.054020 lmp.py:1622]   Expert 35 |    202 | GPU
DEBUG 01-13 08:46:26.054809.054809 lmp.py:1622]   Expert 17 |    203 | GPU
DEBUG 01-13 08:46:26.054836.054836 lmp.py:1622]   Expert 23 |    203 | GPU
DEBUG 01-13 08:46:26.054625.054625 lmp.py:1622]   Expert 43 |    203 | GPU
DEBUG 01-13 08:46:26.054937.054937 lmp.py:1622]   Expert 11 |    211 | GPU
DEBUG 01-13 08:46:26.054964.054964 lmp.py:1622]   Expert 49 |    224 | GPU
DEBUG 01-13 08:46:26.054229.054229 lmp.py:1622]   Expert 39 |    226 | GPU
DEBUG 01-13 08:46:26.054495.054495 lmp.py:1622]   Expert 10 |    228 | GPU
DEBUG 01-13 08:46:26.054522.054522 lmp.py:1622]   Expert 53 |    235 | GPU
DEBUG 01-13 08:46:26.054788.054788 lmp.py:1622]   Expert 33 |    246 | GPU
DEBUG 01-13 08:46:26.054576.054576 lmp.py:1622]   Expert 38 |    268 | GPU
DEBUG 01-13 08:46:26.054127.054127 lmp.py:1622]   Expert 36 |    275 | GPU
DEBUG 01-13 08:46:26.054677.054677 lmp.py:1622]   Expert  4 |    303 | GPU
DEBUG 01-13 08:46:26.054704.054704 lmp.py:1622]   Expert 21 |    332 | GPU
DEBUG 01-13 08:46:26.054778.054778 lmp.py:1622]   Expert 14 |    348 | GPU
DEBUG 01-13 08:46:26.054328.054328 lmp.py:1622]   Expert 45 |    363 | GPU
DEBUG 01-13 08:46:26.054402.054402 lmp.py:1622]   Expert 63 |    368 | GPU
DEBUG 01-13 08:46:26.054952.054952 lmp.py:1622]   Expert 61 |    385 | GPU
DEBUG 01-13 08:46:26.054741.054741 lmp.py:1622]   Expert  9 |    386 | GPU
DEBUG 01-13 08:46:26.054006.054006 lmp.py:1622]   Expert 29 |    491 | GPU
DEBUG 01-13 08:46:26.054749.054749 lmp.py:1622]   Expert  7 |    521 | GPU
DEBUG 01-13 08:46:26.054729.054729 lmp.py:1623] 
DEBUG 01-13 08:46:26.054729.054729 lmp.py:1623]   CPU total tokens: 4040 (32.9%)
DEBUG 01-13 08:46:26.054472.054472 lmp.py:1624]   GPU total tokens: 8248 (67.1%)
DEBUG 01-13 08:46:26.054506.054506 cuda_h.py:19] end experts_map_get cost 0.0019986629486083984 seconds
INFO 01-13 08:46:26.054849.054849 client.py:127] Model loaded
DEBUG 01-13 08:46:26.054283.054283 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-13 08:46:26.054590.054590 cuda_h.py:10] start restore2model
DEBUG 01-13 08:46:26.054871.054871 lmp.py:1632] 
DEBUG 01-13 08:46:26.054871.054871 lmp.py:1632]   Computing 32 experts on CPU MP...
DEBUG 01-13 08:46:26.055258.055258 cuda_h.py:19] end cpu_experts_submit cost 0.0002903938293457031 seconds
DEBUG 01-13 08:46:26.055272.055272 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-13 08:46:26.055758.055758 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-13 08:46:26.055176.055176 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-13 08:46:26.055102.055102 cuda_h.py:19] end allocate_cuda_memory cost 0.00032258033752441406 seconds
DEBUG 01-13 08:46:26.055118.055118 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-13 08:46:26.055980.055980 sllm_store_c.py:27] get device uuid map
DEBUG 01-13 08:46:26.056048.056048 sllm_store_c.py:29] call client load into gpu
DEBUG 01-13 08:46:26.056135.056135 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, da9edea8-ab81-4a2d-8a19-2e0ccff26df1
DEBUG 01-13 08:46:26.056338.056338 client.py:106] call stub.LoadModelAsync
DEBUG 01-13 08:46:26.057569.057569 cuda_h.py:10] start experts_func_gpu_einsum_mp
INFO 01-13 08:46:26.057706.057706 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, da9edea8-ab81-4a2d-8a19-2e0ccff26df1
DEBUG 01-13 08:46:26.057808.057808 cuda_h.py:19] end load_into_gpu_async cost 0.0019783973693847656 seconds
DEBUG 01-13 08:46:26.058756.058756 cuda_h.py:10] start restore_tensors2
DEBUG 01-13 08:46:26.058299.058299 cuda_h.py:19] end restore_tensors2 cost 0.0005440711975097656 seconds
DEBUG 01-13 08:46:26.058042.058042 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0033054351806640625 seconds
DEBUG 01-13 08:46:26.058494.058494 cuda_h.py:10] start restore2model
DEBUG 01-13 08:46:26.058723.058723 cuda_h.py:19] end restore2model cost 0.00025343894958496094 seconds
DEBUG 01-13 08:46:26.059288.059288 cuda_h.py:19] end sllm_worker_task cost 0.01456904411315918 seconds
DEBUG 01-13 08:46:26.062875.062875 cuda_h.py:19] end restore2model cost 0.0038166046142578125 seconds
DEBUG 01-13 08:46:26.062594.062594 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.007408857345581055 seconds
DEBUG 01-13 08:46:26.062105.062105 cuda_h.py:10] start gpu_sexperts
DEBUG 01-13 08:46:26.063065.063065 cuda_h.py:19] end gpu_sexperts cost 0.0003540515899658203 seconds
DEBUG 01-13 08:46:26.063683.063683 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-13 08:46:26.063427.063427 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.4318695068359375e-05 seconds
DEBUG 01-13 08:46:26.063269.063269 cuda_h.py:10] start wait_experts
INFO 01-13 08:46:26.063972.063972 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, da9edea8-ab81-4a2d-8a19-2e0ccff26df1
DEBUG 01-13 08:46:26.064491.064491 mlpmodule.py:1006] group tensors cost 0.006253480911254883 s
DEBUG 01-13 08:46:26.068642.068642 mlpmodule.py:1044] pad cost 0.0026433467864990234 s
DEBUG 01-13 08:46:26.068918.068918 mlpmodule.py:1050] create cpu tensor cost 6.389617919921875e-05 s
DEBUG 01-13 08:46:26.068901.068901 mlpmodule.py:1055] move to cpu cost 4.673004150390625e-05 s
DEBUG 01-13 08:46:26.077535.077535 mlpmodule.py:1069] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-13 08:46:26.077501.077501 mlpmodule.py:1070] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-13 08:46:26.077438.077438 mlpmodule.py:1075] group_w3 first element: -0.0034942626953125
WARNING 01-13 08:46:26.078309.078309 mlpmodule.py:1085] start einsum2
DEBUG 01-13 08:46:26.092863.092863 mlpmodule.py:1095] group einsum cost 0.023696422576904297 s
DEBUG 01-13 08:46:26.092277.092277 mlpmodule.py:1103] cpy2cputensor cost 0.0006992816925048828 s
INFO 01-13 08:46:26.109989.109989 client.py:127] Model loaded
DEBUG 01-13 08:46:26.109177.109177 cuda_h.py:19] end wait_experts cost 0.046633005142211914 seconds
DEBUG 01-13 08:46:26.110174.110174 cuda_h.py:10] start gpu_experts
DEBUG 01-13 08:46:26.111452.111452 mlpmodule.py:559] gpu group tensors cost 0.0010251998901367188 s
DEBUG 01-13 08:46:26.114273.114273 mlpmodule.py:592] gpu pad cost 0.0032448768615722656 s
DEBUG 01-13 08:46:26.114408.114408 mlpmodule.py:598] start_w1
DEBUG 01-13 08:46:26.115029.115029 mlpmodule.py:602] start_w3
DEBUG 01-13 08:46:26.115754.115754 mlpmodule.py:608] start_w2
DEBUG 01-13 08:46:26.115874.115874 mlpmodule.py:611] gpu group einsum cost 0.0010464191436767578 s
DEBUG 01-13 08:46:26.119857.119857 mlpmodule.py:785]  experts func einsum cost 0.061124324798583984 s
DEBUG 01-13 08:46:26.119517.119517 cuda_h.py:19] end experts_func_gpu_einsum_mp cost 0.06186246871948242 seconds
DEBUG 01-13 08:46:26.120490.120490 mlpmodule.py:683] gpu experts func einsum cost 0.010468006134033203 s
DEBUG 01-13 08:46:26.120514.120514 cuda_h.py:19] end gpu_experts cost 0.010705709457397461 seconds
DEBUG 01-13 08:46:26.120892.120892 cuda_h.py:10] start cpu_thread_manager_mp_wait
DEBUG 01-13 08:46:26.120962.120962 cuda_h.py:19] end cpu_thread_manager_mp_wait cost 5.316734313964844e-05 seconds
DEBUG 01-13 08:46:26.120952.120952 cuda_h.py:19] end layer_moe_generate_mp_l_20 cost 0.06948518753051758 seconds
DEBUG 01-13 08:46:26.121435.121435 lmp.py:1550] -------------------------------- end prefill layer 19 --------------------------------
DEBUG 01-13 08:46:26.121873.121873 lmp.py:1493] -------------------------------- start prefill layer 20 --------------------------------
DEBUG 01-13 08:46:26.121106.121106 cuda_h.py:10] start start_load_qkvogn_s_weight_l_21
DEBUG 01-13 08:46:26.121346.121346 cuda_h.py:10] start start_load_qkvogn_s_weight_l_21
DEBUG 01-13 08:46:26.121209.121209 cuda_h.py:19] end start_load_qkvogn_s_weight_l_21 cost 4.410743713378906e-05 seconds
DEBUG 01-13 08:46:26.121409.121409 cuda_h.py:19] end start_load_qkvogn_s_weight_l_21 cost 9.036064147949219e-05 seconds
DEBUG 01-13 08:46:26.121205.121205 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-13 08:46:26.121030.121030 cuda_h.py:10] start sllm_worker_task
DEBUG 01-13 08:46:26.122436.122436 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-13 08:46:26.122253.122253 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-13 08:46:26.122564.122564 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-13 08:46:26.122239.122239 cuda_h.py:19] end allocate_cuda_memory cost 0.0002887248992919922 seconds
DEBUG 01-13 08:46:26.122771.122771 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-13 08:46:26.122633.122633 sllm_store_c.py:27] get device uuid map
DEBUG 01-13 08:46:26.122701.122701 sllm_store_c.py:29] call client load into gpu
DEBUG 01-13 08:46:26.122027.122027 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, bb8519a8-4a55-4be5-9689-ff9a9ca9d0ed
DEBUG 01-13 08:46:26.122308.122308 client.py:106] call stub.LoadModelAsync
DEBUG 01-13 08:46:26.123922.123922 cuda_h.py:10] start self_attn
INFO 01-13 08:46:26.123981.123981 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, bb8519a8-4a55-4be5-9689-ff9a9ca9d0ed
DEBUG 01-13 08:46:26.124171.124171 cuda_h.py:19] end load_into_gpu_async cost 0.0012340545654296875 seconds
DEBUG 01-13 08:46:26.124709.124709 cuda_h.py:10] start restore_tensors2
DEBUG 01-13 08:46:26.124647.124647 cuda_h.py:19] end restore_tensors2 cost 9.632110595703125e-05 seconds
DEBUG 01-13 08:46:26.124026.124026 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0019593238830566406 seconds
INFO 01-13 08:46:26.124188.124188 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, bb8519a8-4a55-4be5-9689-ff9a9ca9d0ed
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-13 08:46:26.127103.127103 cuda_h.py:19] end self_attn cost 0.004501819610595703 seconds
DEBUG 01-13 08:46:26.128691.128691 cuda_h.py:19] end iln_self_attn_paln cost 0.006572246551513672 seconds
DEBUG 01-13 08:46:26.128256.128256 cuda_h.py:10] start layer_moe_generate_mp_l_21
DEBUG 01-13 08:46:26.128165.128165 cuda_h.py:10] start gate
DEBUG 01-13 08:46:26.129895.129895 cuda_h.py:19] end gate cost 0.0008153915405273438 seconds
DEBUG 01-13 08:46:26.129116.129116 cuda_h.py:10] start experts_map_get
DEBUG 01-13 08:46:26.129014.129014 lmp.py:1611] 
DEBUG 01-13 08:46:26.129014.129014 lmp.py:1611] Expert Token Distribution & Device Allocation:
DEBUG 01-13 08:46:26.129777.129777 lmp.py:1612]   Total experts: 64
DEBUG 01-13 08:46:26.129718.129718 lmp.py:1613]   CPU experts: 32 (50%)
DEBUG 01-13 08:46:26.129606.129606 lmp.py:1614]   GPU experts: 32 (50%)
DEBUG 01-13 08:46:26.129587.129587 lmp.py:1615] 
DEBUG 01-13 08:46:26.129587.129587 lmp.py:1615]   Expert ID | Tokens | Device
DEBUG 01-13 08:46:26.129522.129522 lmp.py:1616]   -----------------------------------
DEBUG 01-13 08:46:26.129417.129417 lmp.py:1622]   Expert 54 |     25 | CPU
DEBUG 01-13 08:46:26.129113.129113 lmp.py:1622]   Expert  3 |     33 | CPU
DEBUG 01-13 08:46:26.129094.129094 lmp.py:1622]   Expert  8 |     41 | CPU
DEBUG 01-13 08:46:26.130598.130598 lmp.py:1622]   Expert 28 |     45 | CPU
DEBUG 01-13 08:46:26.130386.130386 lmp.py:1622]   Expert 63 |     50 | CPU
DEBUG 01-13 08:46:26.130937.130937 lmp.py:1622]   Expert 43 |     58 | CPU
DEBUG 01-13 08:46:26.130964.130964 lmp.py:1622]   Expert 36 |     67 | CPU
DEBUG 01-13 08:46:26.130037.130037 lmp.py:1622]   Expert 38 |     75 | CPU
DEBUG 01-13 08:46:26.130826.130826 lmp.py:1622]   Expert  6 |     79 | CPU
DEBUG 01-13 08:46:26.130853.130853 lmp.py:1622]   Expert 39 |     91 | CPU
DEBUG 01-13 08:46:26.130596.130596 lmp.py:1622]   Expert 57 |    103 | CPU
DEBUG 01-13 08:46:26.130623.130623 lmp.py:1622]   Expert 12 |    105 | CPU
DEBUG 01-13 08:46:26.130888.130888 lmp.py:1622]   Expert 41 |    106 | CPU
DEBUG 01-13 08:46:26.130392.130392 lmp.py:1622]   Expert 52 |    110 | CPU
DEBUG 01-13 08:46:26.130181.130181 lmp.py:1622]   Expert 47 |    119 | CPU
DEBUG 01-13 08:46:26.130255.130255 lmp.py:1622]   Expert 19 |    125 | CPU
DEBUG 01-13 08:46:26.130043.130043 lmp.py:1622]   Expert 13 |    135 | CPU
DEBUG 01-13 08:46:26.130832.130832 lmp.py:1622]   Expert 22 |    139 | CPU
DEBUG 01-13 08:46:26.130906.130906 lmp.py:1622]   Expert 46 |    148 | CPU
DEBUG 01-13 08:46:26.130456.130456 lmp.py:1622]   Expert 50 |    153 | CPU
DEBUG 01-13 08:46:26.130006.130006 lmp.py:1622]   Expert 21 |    169 | CPU
DEBUG 01-13 08:46:26.130616.130616 lmp.py:1622]   Expert 24 |    169 | CPU
DEBUG 01-13 08:46:26.130366.130366 lmp.py:1622]   Expert 20 |    170 | CPU
DEBUG 01-13 08:46:26.130870.130870 lmp.py:1622]   Expert 40 |    170 | CPU
DEBUG 01-13 08:46:26.130658.130658 lmp.py:1622]   Expert 23 |    171 | CPU
DEBUG 01-13 08:46:26.130838.130838 lmp.py:1622]   Expert 55 |    171 | CPU
DEBUG 01-13 08:46:26.130912.130912 lmp.py:1622]   Expert 37 |    172 | CPU
DEBUG 01-13 08:46:26.130462.130462 lmp.py:1622]   Expert 33 |    176 | CPU
DEBUG 01-13 08:46:26.130727.130727 lmp.py:1622]   Expert 61 |    178 | CPU
DEBUG 01-13 08:46:26.130755.130755 lmp.py:1622]   Expert 49 |    179 | CPU
DEBUG 01-13 08:46:26.130756.130756 lmp.py:1622]   Expert  2 |    181 | CPU
DEBUG 01-13 08:46:26.130021.130021 lmp.py:1622]   Expert 53 |    181 | CPU
DEBUG 01-13 08:46:26.130049.130049 lmp.py:1622]   Expert 42 |    183 | GPU
DEBUG 01-13 08:46:26.130837.130837 lmp.py:1622]   Expert 18 |    195 | GPU
DEBUG 01-13 08:46:26.130388.130388 lmp.py:1622]   Expert 32 |    198 | GPU
DEBUG 01-13 08:46:26.130938.130938 lmp.py:1622]   Expert  0 |    200 | GPU
DEBUG 01-13 08:46:26.130488.130488 lmp.py:1622]   Expert 16 |    201 | GPU
DEBUG 01-13 08:46:26.130039.130039 lmp.py:1622]   Expert 30 |    201 | GPU
DEBUG 01-13 08:46:26.130066.130066 lmp.py:1622]   Expert  5 |    203 | GPU
DEBUG 01-13 08:46:26.130570.130570 lmp.py:1622]   Expert  7 |    203 | GPU
DEBUG 01-13 08:46:26.130120.130120 lmp.py:1622]   Expert 14 |    207 | GPU
DEBUG 01-13 08:46:26.130147.130147 lmp.py:1622]   Expert 60 |    208 | GPU
DEBUG 01-13 08:46:26.130890.130890 lmp.py:1622]   Expert 62 |    213 | GPU
DEBUG 01-13 08:46:26.130917.130917 lmp.py:1622]   Expert  9 |    217 | GPU
DEBUG 01-13 08:46:26.130421.130421 lmp.py:1622]   Expert 34 |    218 | GPU
DEBUG 01-13 08:46:26.130971.130971 lmp.py:1622]   Expert 31 |    221 | GPU
DEBUG 01-13 08:46:26.130521.130521 lmp.py:1622]   Expert 59 |    221 | GPU
DEBUG 01-13 08:46:26.130357.130357 lmp.py:1622]   Expert 17 |    222 | GPU
DEBUG 01-13 08:46:26.130668.130668 lmp.py:1622]   Expert 29 |    225 | GPU
DEBUG 01-13 08:46:26.130742.130742 lmp.py:1622]   Expert 10 |    228 | GPU
DEBUG 01-13 08:46:26.130292.130292 lmp.py:1622]   Expert 15 |    237 | GPU
DEBUG 01-13 08:46:26.130127.130127 lmp.py:1622]   Expert  4 |    242 | GPU
DEBUG 01-13 08:46:26.131916.131916 lmp.py:1622]   Expert 58 |    242 | GPU
DEBUG 01-13 08:46:26.131182.131182 lmp.py:1622]   Expert 26 |    247 | GPU
DEBUG 01-13 08:46:26.131686.131686 lmp.py:1622]   Expert 11 |    249 | GPU
DEBUG 01-13 08:46:26.131666.131666 lmp.py:1622]   Expert 51 |    252 | GPU
DEBUG 01-13 08:46:26.131978.131978 lmp.py:1622]   Expert 44 |    268 | GPU
DEBUG 01-13 08:46:26.131529.131529 lmp.py:1622]   Expert 56 |    280 | GPU
DEBUG 01-13 08:46:26.131364.131364 lmp.py:1622]   Expert 27 |    288 | GPU
DEBUG 01-13 08:46:26.131914.131914 lmp.py:1622]   Expert  1 |    334 | GPU
DEBUG 01-13 08:46:26.131464.131464 lmp.py:1622]   Expert 45 |    353 | GPU
DEBUG 01-13 08:46:26.131015.131015 lmp.py:1622]   Expert 25 |    486 | GPU
DEBUG 01-13 08:46:26.131042.131042 lmp.py:1622]   Expert 35 |    521 | GPU
DEBUG 01-13 08:46:26.131307.131307 lmp.py:1622]   Expert 48 |    631 | GPU
DEBUG 01-13 08:46:26.131527.131527 lmp.py:1623] 
DEBUG 01-13 08:46:26.131527.131527 lmp.py:1623]   CPU total tokens: 3894 (31.7%)
DEBUG 01-13 08:46:26.131700.131700 lmp.py:1624]   GPU total tokens: 8394 (68.3%)
DEBUG 01-13 08:46:26.131403.131403 cuda_h.py:19] end experts_map_get cost 0.0020062923431396484 seconds
INFO 01-13 08:46:26.131486.131486 client.py:127] Model loaded
DEBUG 01-13 08:46:26.131768.131768 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-13 08:46:26.131930.131930 cuda_h.py:10] start restore2model
DEBUG 01-13 08:46:26.131680.131680 lmp.py:1632] 
DEBUG 01-13 08:46:26.131680.131680 lmp.py:1632]   Computing 32 experts on CPU MP...
DEBUG 01-13 08:46:26.132759.132759 cuda_h.py:19] end cpu_experts_submit cost 0.000377655029296875 seconds
DEBUG 01-13 08:46:26.132422.132422 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-13 08:46:26.132802.132802 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-13 08:46:26.132034.132034 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-13 08:46:26.132248.132248 cuda_h.py:19] end allocate_cuda_memory cost 0.00038623809814453125 seconds
DEBUG 01-13 08:46:26.132210.132210 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-13 08:46:26.132973.132973 sllm_store_c.py:27] get device uuid map
DEBUG 01-13 08:46:26.132803.132803 sllm_store_c.py:29] call client load into gpu
DEBUG 01-13 08:46:26.132413.132413 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 5cc53677-4d84-4006-a8de-ae54b988dbd0
DEBUG 01-13 08:46:26.133794.133794 client.py:106] call stub.LoadModelAsync
INFO 01-13 08:46:26.134418.134418 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 5cc53677-4d84-4006-a8de-ae54b988dbd0
DEBUG 01-13 08:46:26.134990.134990 cuda_h.py:19] end load_into_gpu_async cost 0.00208282470703125 seconds
DEBUG 01-13 08:46:26.135746.135746 cuda_h.py:10] start restore_tensors2
DEBUG 01-13 08:46:26.135859.135859 cuda_h.py:10] start experts_func_gpu_einsum_mp
DEBUG 01-13 08:46:26.135606.135606 cuda_h.py:19] end restore_tensors2 cost 0.0005323886871337891 seconds
DEBUG 01-13 08:46:26.135972.135972 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0034673213958740234 seconds
DEBUG 01-13 08:46:26.135524.135524 cuda_h.py:10] start restore2model
DEBUG 01-13 08:46:26.136842.136842 cuda_h.py:19] end restore2model cost 0.0005462169647216797 seconds
DEBUG 01-13 08:46:26.136091.136091 cuda_h.py:19] end sllm_worker_task cost 0.014529943466186523 seconds
DEBUG 01-13 08:46:26.139493.139493 cuda_h.py:19] end restore2model cost 0.00417780876159668 seconds
DEBUG 01-13 08:46:26.140277.140277 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.007907867431640625 seconds
DEBUG 01-13 08:46:26.140762.140762 cuda_h.py:10] start gpu_sexperts
DEBUG 01-13 08:46:26.140417.140417 cuda_h.py:19] end gpu_sexperts cost 0.00034332275390625 seconds
DEBUG 01-13 08:46:26.140737.140737 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-13 08:46:26.140097.140097 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.4080276489257812e-05 seconds
DEBUG 01-13 08:46:26.140654.140654 cuda_h.py:10] start wait_experts
INFO 01-13 08:46:26.140118.140118 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 5cc53677-4d84-4006-a8de-ae54b988dbd0
DEBUG 01-13 08:46:26.147247.147247 mlpmodule.py:1006] group tensors cost 0.010543584823608398 s
DEBUG 01-13 08:46:26.150502.150502 mlpmodule.py:1044] pad cost 0.0024428367614746094 s
DEBUG 01-13 08:46:26.150758.150758 mlpmodule.py:1050] create cpu tensor cost 5.5789947509765625e-05 s
DEBUG 01-13 08:46:26.150436.150436 mlpmodule.py:1055] move to cpu cost 3.910064697265625e-05 s
DEBUG 01-13 08:46:26.160537.160537 mlpmodule.py:1069] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-13 08:46:26.160313.160313 mlpmodule.py:1070] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-13 08:46:26.160384.160384 mlpmodule.py:1075] group_w3 first element: 0.039306640625
WARNING 01-13 08:46:26.160852.160852 mlpmodule.py:1085] start einsum2
DEBUG 01-13 08:46:26.175310.175310 mlpmodule.py:1095] group einsum cost 0.024820327758789062 s
DEBUG 01-13 08:46:26.176957.176957 mlpmodule.py:1103] cpy2cputensor cost 0.0007092952728271484 s
INFO 01-13 08:46:26.186808.186808 client.py:127] Model loaded
DEBUG 01-13 08:46:26.186921.186921 cuda_h.py:19] end wait_experts cost 0.045717477798461914 seconds
DEBUG 01-13 08:46:26.186645.186645 cuda_h.py:10] start gpu_experts
DEBUG 01-13 08:46:26.187118.187118 mlpmodule.py:559] gpu group tensors cost 0.0009305477142333984 s
DEBUG 01-13 08:46:26.190774.190774 mlpmodule.py:592] gpu pad cost 0.0025086402893066406 s
DEBUG 01-13 08:46:26.190871.190871 mlpmodule.py:598] start_w1
DEBUG 01-13 08:46:26.190784.190784 mlpmodule.py:602] start_w3
DEBUG 01-13 08:46:26.190931.190931 mlpmodule.py:608] start_w2
DEBUG 01-13 08:46:26.191569.191569 mlpmodule.py:611] gpu group einsum cost 0.0010752677917480469 s
DEBUG 01-13 08:46:26.194652.194652 mlpmodule.py:683] gpu experts func einsum cost 0.007789134979248047 s
DEBUG 01-13 08:46:26.194689.194689 cuda_h.py:19] end gpu_experts cost 0.008007287979125977 seconds
DEBUG 01-13 08:46:26.194537.194537 cuda_h.py:10] start cpu_thread_manager_mp_wait
DEBUG 01-13 08:46:26.194315.194315 cuda_h.py:19] end cpu_thread_manager_mp_wait cost 5.269050598144531e-05 seconds
DEBUG 01-13 08:46:26.194451.194451 cuda_h.py:19] end layer_moe_generate_mp_l_21 cost 0.06629681587219238 seconds
DEBUG 01-13 08:46:26.195358.195358 lmp.py:1550] -------------------------------- end prefill layer 20 --------------------------------
DEBUG 01-13 08:46:26.195419.195419 lmp.py:1493] -------------------------------- start prefill layer 21 --------------------------------
DEBUG 01-13 08:46:26.195598.195598 cuda_h.py:10] start start_load_qkvogn_s_weight_l_22
DEBUG 01-13 08:46:26.195023.195023 cuda_h.py:10] start start_load_qkvogn_s_weight_l_22
DEBUG 01-13 08:46:26.195311.195311 cuda_h.py:19] end start_load_qkvogn_s_weight_l_22 cost 4.363059997558594e-05 seconds
DEBUG 01-13 08:46:26.195252.195252 cuda_h.py:19] end start_load_qkvogn_s_weight_l_22 cost 7.414817810058594e-05 seconds
DEBUG 01-13 08:46:26.195041.195041 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-13 08:46:26.195533.195533 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-13 08:46:26.195724.195724 cuda_h.py:10] start sllm_worker_task
DEBUG 01-13 08:46:26.195387.195387 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-13 08:46:26.195504.195504 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-13 08:46:26.196495.196495 cuda_h.py:19] end allocate_cuda_memory cost 0.0004417896270751953 seconds
DEBUG 01-13 08:46:26.196493.196493 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-13 08:46:26.196343.196343 sllm_store_c.py:27] get device uuid map
DEBUG 01-13 08:46:26.196916.196916 sllm_store_c.py:29] call client load into gpu
DEBUG 01-13 08:46:26.196514.196514 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 9ca6d5b8-f0f8-474a-a0c0-1d631f174d81
DEBUG 01-13 08:46:26.196963.196963 client.py:106] call stub.LoadModelAsync
DEBUG 01-13 08:46:26.197487.197487 cuda_h.py:10] start self_attn
INFO 01-13 08:46:26.198637.198637 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 9ca6d5b8-f0f8-474a-a0c0-1d631f174d81
DEBUG 01-13 08:46:26.198923.198923 cuda_h.py:19] end load_into_gpu_async cost 0.0016751289367675781 seconds
DEBUG 01-13 08:46:26.198682.198682 cuda_h.py:10] start restore_tensors2
DEBUG 01-13 08:46:26.198759.198759 mlpmodule.py:785]  experts func einsum cost 0.06186509132385254 s
DEBUG 01-13 08:46:26.198160.198160 cuda_h.py:19] end restore_tensors2 cost 0.00014472007751464844 seconds
DEBUG 01-13 08:46:26.198162.198162 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0028798580169677734 seconds
DEBUG 01-13 08:46:26.199162.199162 cuda_h.py:19] end experts_func_gpu_einsum_mp cost 0.06347107887268066 seconds
INFO 01-13 08:46:26.199614.199614 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 9ca6d5b8-f0f8-474a-a0c0-1d631f174d81
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-13 08:46:26.202128.202128 cuda_h.py:19] end self_attn cost 0.0050127506256103516 seconds
DEBUG 01-13 08:46:26.202651.202651 cuda_h.py:19] end iln_self_attn_paln cost 0.00751042366027832 seconds
DEBUG 01-13 08:46:26.202408.202408 cuda_h.py:10] start layer_moe_generate_mp_l_22
DEBUG 01-13 08:46:26.202793.202793 cuda_h.py:10] start gate
DEBUG 01-13 08:46:26.203294.203294 cuda_h.py:19] end gate cost 0.0008566379547119141 seconds
DEBUG 01-13 08:46:26.203945.203945 cuda_h.py:10] start experts_map_get
DEBUG 01-13 08:46:26.204810.204810 lmp.py:1611] 
DEBUG 01-13 08:46:26.204810.204810 lmp.py:1611] Expert Token Distribution & Device Allocation:
DEBUG 01-13 08:46:26.204401.204401 lmp.py:1612]   Total experts: 64
DEBUG 01-13 08:46:26.204912.204912 lmp.py:1613]   CPU experts: 32 (50%)
DEBUG 01-13 08:46:26.204654.204654 lmp.py:1614]   GPU experts: 32 (50%)
DEBUG 01-13 08:46:26.204251.204251 lmp.py:1615] 
DEBUG 01-13 08:46:26.204251.204251 lmp.py:1615]   Expert ID | Tokens | Device
DEBUG 01-13 08:46:26.204755.204755 lmp.py:1616]   -----------------------------------
DEBUG 01-13 08:46:26.204981.204981 lmp.py:1622]   Expert  9 |     26 | CPU
DEBUG 01-13 08:46:26.204293.204293 lmp.py:1622]   Expert 44 |     27 | CPU
DEBUG 01-13 08:46:26.204936.204936 lmp.py:1622]   Expert 11 |     36 | CPU
DEBUG 01-13 08:46:26.204579.204579 lmp.py:1622]   Expert 56 |     59 | CPU
DEBUG 01-13 08:46:26.204222.204222 lmp.py:1622]   Expert 54 |     80 | CPU
DEBUG 01-13 08:46:26.204865.204865 lmp.py:1622]   Expert  7 |     93 | CPU
DEBUG 01-13 08:46:26.204508.204508 lmp.py:1622]   Expert 62 |     94 | CPU
DEBUG 01-13 08:46:26.204674.204674 lmp.py:1622]   Expert 47 |     95 | CPU
DEBUG 01-13 08:46:26.204794.204794 lmp.py:1622]   Expert 51 |    102 | CPU
DEBUG 01-13 08:46:26.204629.204629 lmp.py:1622]   Expert 60 |    107 | CPU
DEBUG 01-13 08:46:26.204987.204987 lmp.py:1622]   Expert 41 |    108 | CPU
DEBUG 01-13 08:46:26.204107.204107 lmp.py:1622]   Expert 53 |    110 | CPU
DEBUG 01-13 08:46:26.204704.204704 lmp.py:1622]   Expert 52 |    111 | CPU
DEBUG 01-13 08:46:26.204108.204108 lmp.py:1622]   Expert 22 |    117 | CPU
DEBUG 01-13 08:46:26.204513.204513 lmp.py:1622]   Expert  8 |    123 | CPU
DEBUG 01-13 08:46:26.204017.204017 lmp.py:1622]   Expert  6 |    125 | CPU
DEBUG 01-13 08:46:26.204759.204759 lmp.py:1622]   Expert 32 |    129 | CPU
DEBUG 01-13 08:46:26.204786.204786 lmp.py:1622]   Expert 48 |    129 | CPU
DEBUG 01-13 08:46:26.204813.204813 lmp.py:1622]   Expert  2 |    133 | CPU
DEBUG 01-13 08:46:26.204364.204364 lmp.py:1622]   Expert 27 |    133 | CPU
DEBUG 01-13 08:46:26.204629.204629 lmp.py:1622]   Expert  1 |    134 | CPU
DEBUG 01-13 08:46:26.204133.204133 lmp.py:1622]   Expert 23 |    139 | CPU
DEBUG 01-13 08:46:26.204114.204114 lmp.py:1622]   Expert 39 |    144 | CPU
DEBUG 01-13 08:46:26.204380.204380 lmp.py:1622]   Expert 59 |    144 | CPU
DEBUG 01-13 08:46:26.205884.205884 lmp.py:1622]   Expert 35 |    145 | CPU
DEBUG 01-13 08:46:26.205672.205672 lmp.py:1622]   Expert 26 |    154 | CPU
DEBUG 01-13 08:46:26.205461.205461 lmp.py:1622]   Expert 50 |    154 | CPU
DEBUG 01-13 08:46:26.205250.205250 lmp.py:1622]   Expert 14 |    160 | CPU
DEBUG 01-13 08:46:26.205562.205562 lmp.py:1622]   Expert 49 |    162 | CPU
DEBUG 01-13 08:46:26.205351.205351 lmp.py:1622]   Expert 24 |    163 | CPU
DEBUG 01-13 08:46:26.205662.205662 lmp.py:1622]   Expert 34 |    167 | CPU
DEBUG 01-13 08:46:26.205736.205736 lmp.py:1622]   Expert 38 |    167 | CPU
DEBUG 01-13 08:46:26.205286.205286 lmp.py:1622]   Expert 46 |    167 | GPU
DEBUG 01-13 08:46:26.205029.205029 lmp.py:1622]   Expert  4 |    170 | GPU
DEBUG 01-13 08:46:26.205771.205771 lmp.py:1622]   Expert  0 |    177 | GPU
DEBUG 01-13 08:46:26.205514.205514 lmp.py:1622]   Expert 40 |    183 | GPU
DEBUG 01-13 08:46:26.205018.205018 lmp.py:1622]   Expert 63 |    187 | GPU
DEBUG 01-13 08:46:26.205568.205568 lmp.py:1622]   Expert  5 |    190 | GPU
DEBUG 01-13 08:46:26.205595.205595 lmp.py:1622]   Expert 13 |    195 | GPU
DEBUG 01-13 08:46:26.205384.205384 lmp.py:1622]   Expert 19 |    195 | GPU
DEBUG 01-13 08:46:26.205457.205457 lmp.py:1622]   Expert 29 |    199 | GPU
DEBUG 01-13 08:46:26.205531.205531 lmp.py:1622]   Expert 43 |    207 | GPU
DEBUG 01-13 08:46:26.205843.205843 lmp.py:1622]   Expert 57 |    208 | GPU
DEBUG 01-13 08:46:26.205393.205393 lmp.py:1622]   Expert 61 |    220 | GPU
DEBUG 01-13 08:46:26.205182.205182 lmp.py:1622]   Expert 33 |    224 | GPU
DEBUG 01-13 08:46:26.205924.205924 lmp.py:1622]   Expert 31 |    238 | GPU
DEBUG 01-13 08:46:26.205872.205872 lmp.py:1622]   Expert 16 |    247 | GPU
DEBUG 01-13 08:46:26.205330.205330 lmp.py:1622]   Expert 37 |    249 | GPU
DEBUG 01-13 08:46:26.205357.205357 lmp.py:1622]   Expert 20 |    254 | GPU
DEBUG 01-13 08:46:26.205623.205623 lmp.py:1622]   Expert  3 |    255 | GPU
DEBUG 01-13 08:46:26.205411.205411 lmp.py:1622]   Expert 15 |    257 | GPU
DEBUG 01-13 08:46:26.205200.205200 lmp.py:1622]   Expert 12 |    269 | GPU
DEBUG 01-13 08:46:26.205466.205466 lmp.py:1622]   Expert 36 |    274 | GPU
DEBUG 01-13 08:46:26.205254.205254 lmp.py:1622]   Expert 18 |    278 | GPU
DEBUG 01-13 08:46:26.205805.205805 lmp.py:1622]   Expert 28 |    299 | GPU
DEBUG 01-13 08:46:26.205845.205845 lmp.py:1622]   Expert 55 |    309 | GPU
DEBUG 01-13 08:46:26.205396.205396 lmp.py:1622]   Expert 25 |    310 | GPU
DEBUG 01-13 08:46:26.205708.205708 lmp.py:1622]   Expert 17 |    314 | GPU
DEBUG 01-13 08:46:26.205258.205258 lmp.py:1622]   Expert 30 |    320 | GPU
DEBUG 01-13 08:46:26.205139.205139 lmp.py:1622]   Expert 58 |    338 | GPU
DEBUG 01-13 08:46:26.205259.205259 lmp.py:1622]   Expert 10 |    366 | GPU
DEBUG 01-13 08:46:26.205617.205617 lmp.py:1622]   Expert 45 |    378 | GPU
DEBUG 01-13 08:46:26.205976.205976 lmp.py:1622]   Expert 21 |    383 | GPU
DEBUG 01-13 08:46:26.205095.205095 lmp.py:1622]   Expert 42 |    658 | GPU
DEBUG 01-13 08:46:26.205646.205646 lmp.py:1623] 
DEBUG 01-13 08:46:26.205646.205646 lmp.py:1623]   CPU total tokens: 3770 (30.7%)
DEBUG 01-13 08:46:26.205911.205911 lmp.py:1624]   GPU total tokens: 8518 (69.3%)
DEBUG 01-13 08:46:26.205376.205376 cuda_h.py:19] end experts_map_get cost 0.0019736289978027344 seconds
DEBUG 01-13 08:46:26.205524.205524 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-13 08:46:26.205618.205618 lmp.py:1632] 
DEBUG 01-13 08:46:26.205618.205618 lmp.py:1632]   Computing 32 experts on CPU MP...
DEBUG 01-13 08:46:26.206984.206984 cuda_h.py:19] end cpu_experts_submit cost 6.0558319091796875e-05 seconds
DEBUG 01-13 08:46:26.206800.206800 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-13 08:46:26.206162.206162 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-13 08:46:26.206155.206155 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-13 08:46:26.207125.207125 cuda_h.py:19] end allocate_cuda_memory cost 0.0004265308380126953 seconds
DEBUG 01-13 08:46:26.207081.207081 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-13 08:46:26.207797.207797 sllm_store_c.py:27] get device uuid map
DEBUG 01-13 08:46:26.207911.207911 sllm_store_c.py:29] call client load into gpu
DEBUG 01-13 08:46:26.207714.207714 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 41183e9d-60c6-49b5-85db-400147acbd33
DEBUG 01-13 08:46:26.207724.207724 client.py:106] call stub.LoadModelAsync
INFO 01-13 08:46:26.208457.208457 client.py:127] Model loaded
DEBUG 01-13 08:46:26.208102.208102 cuda_h.py:10] start experts_func_gpu_einsum_mp
DEBUG 01-13 08:46:26.208933.208933 cuda_h.py:10] start restore2model
INFO 01-13 08:46:26.209031.209031 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 41183e9d-60c6-49b5-85db-400147acbd33
DEBUG 01-13 08:46:26.209861.209861 cuda_h.py:19] end load_into_gpu_async cost 0.0021162033081054688 seconds
DEBUG 01-13 08:46:26.209717.209717 cuda_h.py:10] start restore_tensors2
DEBUG 01-13 08:46:26.210007.210007 cuda_h.py:19] end restore_tensors2 cost 0.0005326271057128906 seconds
DEBUG 01-13 08:46:26.210036.210036 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.003526926040649414 seconds
DEBUG 01-13 08:46:26.210719.210719 cuda_h.py:10] start restore2model
DEBUG 01-13 08:46:26.210768.210768 cuda_h.py:19] end restore2model cost 0.00039768218994140625 seconds
DEBUG 01-13 08:46:26.210331.210331 cuda_h.py:19] end sllm_worker_task cost 0.015155315399169922 seconds
DEBUG 01-13 08:46:26.214263.214263 cuda_h.py:19] end restore2model cost 0.003939390182495117 seconds
DEBUG 01-13 08:46:26.214756.214756 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.007710933685302734 seconds
DEBUG 01-13 08:46:26.214718.214718 cuda_h.py:10] start gpu_sexperts
DEBUG 01-13 08:46:26.214393.214393 cuda_h.py:19] end gpu_sexperts cost 0.0003542900085449219 seconds
DEBUG 01-13 08:46:26.214866.214866 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-13 08:46:26.214271.214271 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.384185791015625e-05 seconds
DEBUG 01-13 08:46:26.214875.214875 cuda_h.py:10] start wait_experts
INFO 01-13 08:46:26.214816.214816 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 41183e9d-60c6-49b5-85db-400147acbd33
DEBUG 01-13 08:46:26.229274.229274 mlpmodule.py:1006] group tensors cost 0.01973867416381836 s
DEBUG 01-13 08:46:26.233097.233097 mlpmodule.py:1044] pad cost 0.003052234649658203 s
DEBUG 01-13 08:46:26.233704.233704 mlpmodule.py:1050] create cpu tensor cost 6.246566772460938e-05 s
DEBUG 01-13 08:46:26.233350.233350 mlpmodule.py:1055] move to cpu cost 4.506111145019531e-05 s
DEBUG 01-13 08:46:26.243080.243080 mlpmodule.py:1069] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-13 08:46:26.243783.243783 mlpmodule.py:1070] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-13 08:46:26.243369.243369 mlpmodule.py:1075] group_w3 first element: 0.00066375732421875
WARNING 01-13 08:46:26.243110.243110 mlpmodule.py:1085] start einsum2
DEBUG 01-13 08:46:26.256768.256768 mlpmodule.py:1095] group einsum cost 0.0224761962890625 s
DEBUG 01-13 08:46:26.257155.257155 mlpmodule.py:1103] cpy2cputensor cost 0.0007510185241699219 s
INFO 01-13 08:46:26.257270.257270 client.py:127] Model loaded
DEBUG 01-13 08:46:26.258821.258821 cuda_h.py:19] end wait_experts cost 0.043230295181274414 seconds
DEBUG 01-13 08:46:26.258260.258260 cuda_h.py:10] start gpu_experts
DEBUG 01-13 08:46:26.259555.259555 mlpmodule.py:559] gpu group tensors cost 0.0009427070617675781 s
DEBUG 01-13 08:46:26.261276.261276 mlpmodule.py:592] gpu pad cost 0.002489328384399414 s
DEBUG 01-13 08:46:26.261789.261789 mlpmodule.py:598] start_w1
DEBUG 01-13 08:46:26.262186.262186 mlpmodule.py:602] start_w3
DEBUG 01-13 08:46:26.262373.262373 mlpmodule.py:608] start_w2
DEBUG 01-13 08:46:26.262792.262792 mlpmodule.py:611] gpu group einsum cost 0.0010538101196289062 s
DEBUG 01-13 08:46:26.266985.266985 mlpmodule.py:683] gpu experts func einsum cost 0.008248090744018555 s
DEBUG 01-13 08:46:26.266439.266439 cuda_h.py:19] end gpu_experts cost 0.008491039276123047 seconds
DEBUG 01-13 08:46:26.266725.266725 cuda_h.py:10] start cpu_thread_manager_mp_wait
DEBUG 01-13 08:46:26.266199.266199 cuda_h.py:19] end cpu_thread_manager_mp_wait cost 6.008148193359375e-05 seconds
DEBUG 01-13 08:46:26.266295.266295 cuda_h.py:19] end layer_moe_generate_mp_l_22 cost 0.06403350830078125 seconds
DEBUG 01-13 08:46:26.267244.267244 lmp.py:1550] -------------------------------- end prefill layer 21 --------------------------------
DEBUG 01-13 08:46:26.267981.267981 lmp.py:1493] -------------------------------- start prefill layer 22 --------------------------------
DEBUG 01-13 08:46:26.267359.267359 cuda_h.py:10] start start_load_qkvogn_s_weight_l_23
DEBUG 01-13 08:46:26.267460.267460 cuda_h.py:10] start start_load_qkvogn_s_weight_l_23
DEBUG 01-13 08:46:26.267059.267059 cuda_h.py:19] end start_load_qkvogn_s_weight_l_23 cost 5.602836608886719e-05 seconds
DEBUG 01-13 08:46:26.267067.267067 cuda_h.py:19] end start_load_qkvogn_s_weight_l_23 cost 0.00010180473327636719 seconds
DEBUG 01-13 08:46:26.267247.267247 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-13 08:46:26.267760.267760 cuda_h.py:10] start sllm_worker_task
DEBUG 01-13 08:46:26.267337.267337 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-13 08:46:26.268776.268776 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-13 08:46:26.268804.268804 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-13 08:46:26.268304.268304 cuda_h.py:19] end allocate_cuda_memory cost 0.0005812644958496094 seconds
DEBUG 01-13 08:46:26.269608.269608 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-13 08:46:26.269672.269672 sllm_store_c.py:27] get device uuid map
DEBUG 01-13 08:46:26.269452.269452 sllm_store_c.py:29] call client load into gpu
DEBUG 01-13 08:46:26.269819.269819 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 425576f9-4d30-412e-b193-aa66a0b4f533
DEBUG 01-13 08:46:26.269224.269224 client.py:106] call stub.LoadModelAsync
DEBUG 01-13 08:46:26.270518.270518 cuda_h.py:10] start self_attn
INFO 01-13 08:46:26.270415.270415 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 425576f9-4d30-412e-b193-aa66a0b4f533
DEBUG 01-13 08:46:26.271096.271096 cuda_h.py:19] end load_into_gpu_async cost 0.0017867088317871094 seconds
DEBUG 01-13 08:46:26.271928.271928 cuda_h.py:10] start restore_tensors2
DEBUG 01-13 08:46:26.271003.271003 cuda_h.py:19] end restore_tensors2 cost 0.00015687942504882812 seconds
DEBUG 01-13 08:46:26.271133.271133 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.003557920455932617 seconds
INFO 01-13 08:46:26.271020.271020 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 425576f9-4d30-412e-b193-aa66a0b4f533
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-13 08:46:26.275864.275864 cuda_h.py:19] end self_attn cost 0.0049135684967041016 seconds
DEBUG 01-13 08:46:26.275301.275301 cuda_h.py:19] end iln_self_attn_paln cost 0.007728099822998047 seconds
DEBUG 01-13 08:46:26.275006.275006 cuda_h.py:10] start layer_moe_generate_mp_l_23
DEBUG 01-13 08:46:26.275345.275345 cuda_h.py:10] start gate
DEBUG 01-13 08:46:26.276697.276697 mlpmodule.py:785]  experts func einsum cost 0.06684041023254395 s
DEBUG 01-13 08:46:26.276744.276744 cuda_h.py:19] end gate cost 0.0008089542388916016 seconds
DEBUG 01-13 08:46:26.276865.276865 cuda_h.py:10] start experts_map_get
DEBUG 01-13 08:46:26.276892.276892 cuda_h.py:19] end experts_func_gpu_einsum_mp cost 0.06848978996276855 seconds
DEBUG 01-13 08:46:26.276532.276532 lmp.py:1611] 
DEBUG 01-13 08:46:26.276532.276532 lmp.py:1611] Expert Token Distribution & Device Allocation:
DEBUG 01-13 08:46:26.277248.277248 lmp.py:1612]   Total experts: 64
DEBUG 01-13 08:46:26.277951.277951 lmp.py:1613]   CPU experts: 32 (50%)
DEBUG 01-13 08:46:26.277362.277362 lmp.py:1614]   GPU experts: 32 (50%)
DEBUG 01-13 08:46:26.277628.277628 lmp.py:1615] 
DEBUG 01-13 08:46:26.277628.277628 lmp.py:1615]   Expert ID | Tokens | Device
DEBUG 01-13 08:46:26.277417.277417 lmp.py:1616]   -----------------------------------
DEBUG 01-13 08:46:26.277358.277358 lmp.py:1622]   Expert 25 |     16 | CPU
DEBUG 01-13 08:46:26.277339.277339 lmp.py:1622]   Expert 48 |     34 | CPU
DEBUG 01-13 08:46:26.277889.277889 lmp.py:1622]   Expert 45 |     36 | CPU
DEBUG 01-13 08:46:26.277553.277553 lmp.py:1622]   Expert  9 |     61 | CPU
DEBUG 01-13 08:46:26.277010.277010 lmp.py:1622]   Expert  0 |     75 | CPU
DEBUG 01-13 08:46:26.277753.277753 lmp.py:1622]   Expert 54 |     78 | CPU
DEBUG 01-13 08:46:26.277257.277257 lmp.py:1622]   Expert 57 |     78 | CPU
DEBUG 01-13 08:46:26.277045.277045 lmp.py:1622]   Expert 20 |     79 | CPU
DEBUG 01-13 08:46:26.277311.277311 lmp.py:1622]   Expert 43 |     79 | CPU
DEBUG 01-13 08:46:26.277623.277623 lmp.py:1622]   Expert 47 |     88 | CPU
DEBUG 01-13 08:46:26.277696.277696 lmp.py:1622]   Expert  6 |     94 | CPU
DEBUG 01-13 08:46:26.277770.277770 lmp.py:1622]   Expert 62 |     97 | CPU
DEBUG 01-13 08:46:26.277082.277082 lmp.py:1622]   Expert 36 |     98 | CPU
DEBUG 01-13 08:46:26.277109.277109 lmp.py:1622]   Expert  1 |    101 | CPU
DEBUG 01-13 08:46:26.277659.277659 lmp.py:1622]   Expert 13 |    102 | CPU
DEBUG 01-13 08:46:26.277163.277163 lmp.py:1622]   Expert 50 |    102 | CPU
DEBUG 01-13 08:46:26.277429.277429 lmp.py:1622]   Expert 61 |    105 | CPU
DEBUG 01-13 08:46:26.277218.277218 lmp.py:1622]   Expert 46 |    106 | CPU
DEBUG 01-13 08:46:26.277291.277291 lmp.py:1622]   Expert 15 |    108 | CPU
DEBUG 01-13 08:46:26.277603.277603 lmp.py:1622]   Expert 37 |    113 | CPU
DEBUG 01-13 08:46:26.277438.277438 lmp.py:1622]   Expert 38 |    113 | CPU
DEBUG 01-13 08:46:26.277512.277512 lmp.py:1622]   Expert 14 |    115 | CPU
DEBUG 01-13 08:46:26.277347.277347 lmp.py:1622]   Expert  7 |    135 | CPU
DEBUG 01-13 08:46:26.277758.277758 lmp.py:1622]   Expert 21 |    136 | CPU
DEBUG 01-13 08:46:26.277070.277070 lmp.py:1622]   Expert 28 |    141 | CPU
DEBUG 01-13 08:46:26.277335.277335 lmp.py:1622]   Expert 44 |    143 | CPU
DEBUG 01-13 08:46:26.277601.277601 lmp.py:1622]   Expert 52 |    144 | CPU
DEBUG 01-13 08:46:26.277151.277151 lmp.py:1622]   Expert 10 |    151 | CPU
DEBUG 01-13 08:46:26.277702.277702 lmp.py:1622]   Expert 11 |    155 | CPU
DEBUG 01-13 08:46:26.277014.277014 lmp.py:1622]   Expert 24 |    155 | CPU
DEBUG 01-13 08:46:26.277624.277624 lmp.py:1622]   Expert 42 |    160 | CPU
DEBUG 01-13 08:46:26.277697.277697 lmp.py:1622]   Expert 26 |    164 | CPU
DEBUG 01-13 08:46:26.277009.277009 lmp.py:1622]   Expert  2 |    166 | GPU
DEBUG 01-13 08:46:26.277798.277798 lmp.py:1622]   Expert 35 |    172 | GPU
DEBUG 01-13 08:46:26.277031.277031 lmp.py:1622]   Expert 31 |    176 | GPU
DEBUG 01-13 08:46:26.277819.277819 lmp.py:1622]   Expert  3 |    180 | GPU
DEBUG 01-13 08:46:26.277708.277708 lmp.py:1622]   Expert 32 |    184 | GPU
DEBUG 01-13 08:46:26.277543.277543 lmp.py:1622]   Expert 12 |    188 | GPU
DEBUG 01-13 08:46:26.277093.277093 lmp.py:1622]   Expert 19 |    188 | GPU
DEBUG 01-13 08:46:26.277094.277094 lmp.py:1622]   Expert 60 |    208 | GPU
DEBUG 01-13 08:46:26.277075.277075 lmp.py:1622]   Expert 56 |    209 | GPU
DEBUG 01-13 08:46:26.277625.277625 lmp.py:1622]   Expert 40 |    216 | GPU
DEBUG 01-13 08:46:26.278937.278937 lmp.py:1622]   Expert 41 |    216 | GPU
DEBUG 01-13 08:46:26.278011.278011 lmp.py:1622]   Expert 53 |    225 | GPU
DEBUG 01-13 08:46:26.278515.278515 lmp.py:1622]   Expert 58 |    227 | GPU
DEBUG 01-13 08:46:26.278019.278019 lmp.py:1622]   Expert 23 |    235 | GPU
DEBUG 01-13 08:46:26.278430.278430 lmp.py:1622]   Expert 16 |    240 | GPU
DEBUG 01-13 08:46:26.278980.278980 lmp.py:1622]   Expert  8 |    242 | GPU
DEBUG 01-13 08:46:26.278292.278292 lmp.py:1622]   Expert 51 |    243 | GPU
DEBUG 01-13 08:46:26.278127.278127 lmp.py:1622]   Expert 59 |    245 | GPU
DEBUG 01-13 08:46:26.278201.278201 lmp.py:1622]   Expert  4 |    247 | GPU
DEBUG 01-13 08:46:26.278719.278719 lmp.py:1622]   Expert 49 |    274 | GPU
DEBUG 01-13 08:46:26.278792.278792 lmp.py:1622]   Expert 55 |    277 | GPU
DEBUG 01-13 08:46:26.278865.278865 lmp.py:1622]   Expert 18 |    280 | GPU
DEBUG 01-13 08:46:26.278323.278323 lmp.py:1622]   Expert 29 |    284 | GPU
DEBUG 01-13 08:46:26.278112.278112 lmp.py:1622]   Expert 34 |    291 | GPU
DEBUG 01-13 08:46:26.278139.278139 lmp.py:1622]   Expert 63 |    301 | GPU
DEBUG 01-13 08:46:26.278974.278974 lmp.py:1622]   Expert 27 |    358 | GPU
DEBUG 01-13 08:46:26.278809.278809 lmp.py:1622]   Expert 39 |    378 | GPU
DEBUG 01-13 08:46:26.278406.278406 lmp.py:1622]   Expert 17 |    400 | GPU
DEBUG 01-13 08:46:26.278003.278003 lmp.py:1622]   Expert 22 |    428 | GPU
DEBUG 01-13 08:46:26.278838.278838 lmp.py:1622]   Expert 30 |    446 | GPU
DEBUG 01-13 08:46:26.278196.278196 lmp.py:1622]   Expert 33 |    470 | GPU
DEBUG 01-13 08:46:26.278508.278508 lmp.py:1622]   Expert  5 |    732 | GPU
DEBUG 01-13 08:46:26.278058.278058 lmp.py:1623] 
DEBUG 01-13 08:46:26.278058.278058 lmp.py:1623]   CPU total tokens: 3362 (27.4%)
DEBUG 01-13 08:46:26.278324.278324 lmp.py:1624]   GPU total tokens: 8926 (72.6%)
DEBUG 01-13 08:46:26.278881.278881 cuda_h.py:19] end experts_map_get cost 0.002019166946411133 seconds
DEBUG 01-13 08:46:26.278036.278036 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-13 08:46:26.278222.278222 lmp.py:1632] 
DEBUG 01-13 08:46:26.278222.278222 lmp.py:1632]   Computing 32 experts on CPU MP...
DEBUG 01-13 08:46:26.278304.278304 cuda_h.py:19] end cpu_experts_submit cost 6.008148193359375e-05 seconds
DEBUG 01-13 08:46:26.278120.278120 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-13 08:46:26.278347.278347 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-13 08:46:26.278546.278546 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-13 08:46:26.279629.279629 cuda_h.py:19] end allocate_cuda_memory cost 0.0002694129943847656 seconds
DEBUG 01-13 08:46:26.279671.279671 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-13 08:46:26.279527.279527 sllm_store_c.py:27] get device uuid map
DEBUG 01-13 08:46:26.279488.279488 sllm_store_c.py:29] call client load into gpu
DEBUG 01-13 08:46:26.279953.279953 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 4f0701dc-10d3-4f27-8239-7ccbe1f65950
DEBUG 01-13 08:46:26.279254.279254 client.py:106] call stub.LoadModelAsync
INFO 01-13 08:46:26.280491.280491 client.py:127] Model loaded
DEBUG 01-13 08:46:26.281153.281153 cuda_h.py:10] start restore2model
INFO 01-13 08:46:26.281455.281455 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 4f0701dc-10d3-4f27-8239-7ccbe1f65950
DEBUG 01-13 08:46:26.281896.281896 cuda_h.py:19] end load_into_gpu_async cost 0.0021300315856933594 seconds
DEBUG 01-13 08:46:26.281083.281083 cuda_h.py:10] start restore_tensors2
DEBUG 01-13 08:46:26.282783.282783 cuda_h.py:19] end restore_tensors2 cost 0.0005190372467041016 seconds
DEBUG 01-13 08:46:26.282266.282266 cuda_h.py:10] start experts_func_gpu_einsum_mp
DEBUG 01-13 08:46:26.282719.282719 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0033724308013916016 seconds
DEBUG 01-13 08:46:26.282264.282264 cuda_h.py:10] start restore2model
DEBUG 01-13 08:46:26.283991.283991 cuda_h.py:19] end restore2model cost 0.0012793540954589844 seconds
DEBUG 01-13 08:46:26.283330.283330 cuda_h.py:19] end sllm_worker_task cost 0.015778064727783203 seconds
DEBUG 01-13 08:46:26.286309.286309 cuda_h.py:19] end restore2model cost 0.004485607147216797 seconds
DEBUG 01-13 08:46:26.286836.286836 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.008121013641357422 seconds
DEBUG 01-13 08:46:26.286016.286016 cuda_h.py:10] start gpu_sexperts
DEBUG 01-13 08:46:26.287664.287664 cuda_h.py:19] end gpu_sexperts cost 0.0003383159637451172 seconds
DEBUG 01-13 08:46:26.287600.287600 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-13 08:46:26.287952.287952 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 1.9788742065429688e-05 seconds
DEBUG 01-13 08:46:26.287649.287649 cuda_h.py:10] start wait_experts
INFO 01-13 08:46:26.287444.287444 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 4f0701dc-10d3-4f27-8239-7ccbe1f65950
DEBUG 01-13 08:46:26.292023.292023 mlpmodule.py:1006] group tensors cost 0.009051322937011719 s
DEBUG 01-13 08:46:26.294757.294757 mlpmodule.py:1044] pad cost 0.0015757083892822266 s
DEBUG 01-13 08:46:26.294436.294436 mlpmodule.py:1050] create cpu tensor cost 5.817413330078125e-05 s
DEBUG 01-13 08:46:26.294240.294240 mlpmodule.py:1055] move to cpu cost 3.075599670410156e-05 s
DEBUG 01-13 08:46:26.303241.303241 mlpmodule.py:1069] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-13 08:46:26.303361.303361 mlpmodule.py:1070] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-13 08:46:26.303062.303062 mlpmodule.py:1075] group_w3 first element: -0.018798828125
WARNING 01-13 08:46:26.303274.303274 mlpmodule.py:1085] start einsum2
DEBUG 01-13 08:46:26.318177.318177 mlpmodule.py:1095] group einsum cost 0.023746013641357422 s
DEBUG 01-13 08:46:26.319452.319452 mlpmodule.py:1103] cpy2cputensor cost 0.0006771087646484375 s
DEBUG 01-13 08:46:26.331852.331852 mlpmodule.py:785]  experts func einsum cost 0.04809975624084473 s
DEBUG 01-13 08:46:26.332748.332748 cuda_h.py:19] end experts_func_gpu_einsum_mp cost 0.0498809814453125 seconds
INFO 01-13 08:46:26.335939.335939 client.py:127] Model loaded
DEBUG 01-13 08:46:26.336597.336597 cuda_h.py:19] end wait_experts cost 0.048632144927978516 seconds
DEBUG 01-13 08:46:26.336110.336110 cuda_h.py:10] start gpu_experts
DEBUG 01-13 08:46:26.338484.338484 mlpmodule.py:559] gpu group tensors cost 0.0016314983367919922 s
DEBUG 01-13 08:46:26.342472.342472 mlpmodule.py:592] gpu pad cost 0.004442930221557617 s
DEBUG 01-13 08:46:26.342595.342595 mlpmodule.py:598] start_w1
DEBUG 01-13 08:46:26.343404.343404 mlpmodule.py:602] start_w3
DEBUG 01-13 08:46:26.343031.343031 mlpmodule.py:608] start_w2
DEBUG 01-13 08:46:26.343193.343193 mlpmodule.py:611] gpu group einsum cost 0.0012476444244384766 s
DEBUG 01-13 08:46:26.348617.348617 mlpmodule.py:683] gpu experts func einsum cost 0.012169361114501953 s
DEBUG 01-13 08:46:26.348598.348598 cuda_h.py:19] end gpu_experts cost 0.01248788833618164 seconds
DEBUG 01-13 08:46:26.348494.348494 cuda_h.py:10] start cpu_thread_manager_mp_wait
DEBUG 01-13 08:46:26.348001.348001 cuda_h.py:19] end cpu_thread_manager_mp_wait cost 6.985664367675781e-05 seconds
DEBUG 01-13 08:46:26.349589.349589 cuda_h.py:19] end layer_moe_generate_mp_l_23 cost 0.0735626220703125 seconds
DEBUG 01-13 08:46:26.349440.349440 lmp.py:1550] -------------------------------- end prefill layer 22 --------------------------------
DEBUG 01-13 08:46:26.349979.349979 lmp.py:1493] -------------------------------- start prefill layer 23 --------------------------------
DEBUG 01-13 08:46:26.349146.349146 cuda_h.py:10] start start_load_qkvogn_s_weight_l_24
DEBUG 01-13 08:46:26.349705.349705 cuda_h.py:10] start start_load_qkvogn_s_weight_l_24
DEBUG 01-13 08:46:26.349331.349331 cuda_h.py:19] end start_load_qkvogn_s_weight_l_24 cost 5.888938903808594e-05 seconds
DEBUG 01-13 08:46:26.349214.349214 cuda_h.py:19] end start_load_qkvogn_s_weight_l_24 cost 0.00011920928955078125 seconds
DEBUG 01-13 08:46:26.349321.349321 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-13 08:46:26.350829.350829 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-13 08:46:26.350358.350358 cuda_h.py:10] start sllm_worker_task
DEBUG 01-13 08:46:26.350433.350433 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-13 08:46:26.350021.350021 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-13 08:46:26.351922.351922 cuda_h.py:19] end allocate_cuda_memory cost 0.00032639503479003906 seconds
DEBUG 01-13 08:46:26.351468.351468 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-13 08:46:26.351814.351814 sllm_store_c.py:27] get device uuid map
DEBUG 01-13 08:46:26.351704.351704 sllm_store_c.py:29] call client load into gpu
DEBUG 01-13 08:46:26.351513.351513 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 432f070a-19f2-4383-af81-e20024cb9017
DEBUG 01-13 08:46:26.351338.351338 client.py:106] call stub.LoadModelAsync
DEBUG 01-13 08:46:26.351962.351962 cuda_h.py:10] start self_attn
INFO 01-13 08:46:26.353556.353556 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 432f070a-19f2-4383-af81-e20024cb9017
DEBUG 01-13 08:46:26.353969.353969 cuda_h.py:19] end load_into_gpu_async cost 0.001865386962890625 seconds
DEBUG 01-13 08:46:26.353448.353448 cuda_h.py:10] start restore_tensors2
DEBUG 01-13 08:46:26.353446.353446 cuda_h.py:19] end restore_tensors2 cost 0.00010633468627929688 seconds
DEBUG 01-13 08:46:26.353884.353884 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0026962757110595703 seconds
INFO 01-13 08:46:26.353264.353264 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 432f070a-19f2-4383-af81-e20024cb9017
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-13 08:46:26.356455.356455 cuda_h.py:19] end self_attn cost 0.004494428634643555 seconds
DEBUG 01-13 08:46:26.356572.356572 cuda_h.py:19] end iln_self_attn_paln cost 0.006839275360107422 seconds
DEBUG 01-13 08:46:26.356137.356137 cuda_h.py:10] start layer_moe_generate_mp_l_24
DEBUG 01-13 08:46:26.356714.356714 cuda_h.py:10] start gate
DEBUG 01-13 08:46:26.357116.357116 cuda_h.py:19] end gate cost 0.0008919239044189453 seconds
DEBUG 01-13 08:46:26.357383.357383 cuda_h.py:10] start experts_map_get
DEBUG 01-13 08:46:26.358553.358553 lmp.py:1611] 
DEBUG 01-13 08:46:26.358553.358553 lmp.py:1611] Expert Token Distribution & Device Allocation:
DEBUG 01-13 08:46:26.358024.358024 lmp.py:1612]   Total experts: 64
DEBUG 01-13 08:46:26.358343.358343 lmp.py:1613]   CPU experts: 32 (50%)
DEBUG 01-13 08:46:26.358609.358609 lmp.py:1614]   GPU experts: 32 (50%)
DEBUG 01-13 08:46:26.358013.358013 lmp.py:1615] 
DEBUG 01-13 08:46:26.358013.358013 lmp.py:1615]   Expert ID | Tokens | Device
DEBUG 01-13 08:46:26.358372.358372 lmp.py:1616]   -----------------------------------
DEBUG 01-13 08:46:26.358644.358644 lmp.py:1622]   Expert  5 |     12 | CPU
DEBUG 01-13 08:46:26.358525.358525 lmp.py:1622]   Expert 56 |     33 | CPU
DEBUG 01-13 08:46:26.358976.358976 lmp.py:1622]   Expert 27 |     77 | CPU
DEBUG 01-13 08:46:26.358189.358189 lmp.py:1622]   Expert 16 |     87 | CPU
DEBUG 01-13 08:46:26.358163.358163 lmp.py:1622]   Expert 40 |     93 | CPU
DEBUG 01-13 08:46:26.358898.358898 lmp.py:1622]   Expert 17 |     96 | CPU
DEBUG 01-13 08:46:26.358872.358872 lmp.py:1622]   Expert 53 |     98 | CPU
DEBUG 01-13 08:46:26.358085.358085 lmp.py:1622]   Expert 51 |    100 | CPU
DEBUG 01-13 08:46:26.358820.358820 lmp.py:1622]   Expert 28 |    102 | CPU
DEBUG 01-13 08:46:26.358033.358033 lmp.py:1622]   Expert 49 |    103 | CPU
DEBUG 01-13 08:46:26.358199.358199 lmp.py:1622]   Expert  7 |    108 | CPU
DEBUG 01-13 08:46:26.358842.358842 lmp.py:1622]   Expert 63 |    109 | CPU
DEBUG 01-13 08:46:26.358770.358770 lmp.py:1622]   Expert 47 |    118 | CPU
DEBUG 01-13 08:46:26.358936.358936 lmp.py:1622]   Expert 58 |    118 | CPU
DEBUG 01-13 08:46:26.358148.358148 lmp.py:1622]   Expert 11 |    123 | CPU
DEBUG 01-13 08:46:26.358361.358361 lmp.py:1622]   Expert 38 |    125 | CPU
DEBUG 01-13 08:46:26.358573.358573 lmp.py:1622]   Expert 37 |    127 | CPU
DEBUG 01-13 08:46:26.358547.358547 lmp.py:1622]   Expert 62 |    132 | CPU
DEBUG 01-13 08:46:26.358521.358521 lmp.py:1622]   Expert 57 |    138 | CPU
DEBUG 01-13 08:46:26.358257.358257 lmp.py:1622]   Expert 39 |    143 | CPU
DEBUG 01-13 08:46:26.358231.358231 lmp.py:1622]   Expert  1 |    147 | CPU
DEBUG 01-13 08:46:26.358205.358205 lmp.py:1622]   Expert 25 |    153 | CPU
DEBUG 01-13 08:46:26.358941.358941 lmp.py:1622]   Expert 14 |    155 | CPU
DEBUG 01-13 08:46:26.358630.358630 lmp.py:1622]   Expert  6 |    164 | CPU
DEBUG 01-13 08:46:26.358558.358558 lmp.py:1622]   Expert 52 |    164 | CPU
DEBUG 01-13 08:46:26.358485.358485 lmp.py:1622]   Expert 23 |    166 | CPU
DEBUG 01-13 08:46:26.358652.358652 lmp.py:1622]   Expert 33 |    166 | CPU
DEBUG 01-13 08:46:26.358626.358626 lmp.py:1622]   Expert 21 |    171 | CPU
DEBUG 01-13 08:46:26.358600.358600 lmp.py:1622]   Expert 45 |    174 | CPU
DEBUG 01-13 08:46:26.358812.358812 lmp.py:1622]   Expert  4 |    175 | CPU
DEBUG 01-13 08:46:26.358548.358548 lmp.py:1622]   Expert 30 |    180 | CPU
DEBUG 01-13 08:46:26.358575.358575 lmp.py:1622]   Expert 44 |    180 | CPU
DEBUG 01-13 08:46:26.358172.358172 lmp.py:1622]   Expert 19 |    181 | GPU
DEBUG 01-13 08:46:26.358053.358053 lmp.py:1622]   Expert 60 |    183 | GPU
DEBUG 01-13 08:46:26.359888.359888 lmp.py:1622]   Expert 31 |    188 | GPU
DEBUG 01-13 08:46:26.359246.359246 lmp.py:1622]   Expert  3 |    190 | GPU
DEBUG 01-13 08:46:26.359273.359273 lmp.py:1622]   Expert 36 |    191 | GPU
DEBUG 01-13 08:46:26.359870.359870 lmp.py:1622]   Expert 12 |    193 | GPU
DEBUG 01-13 08:46:26.359467.359467 lmp.py:1622]   Expert 55 |    203 | GPU
DEBUG 01-13 08:46:26.359779.359779 lmp.py:1622]   Expert  9 |    215 | GPU
DEBUG 01-13 08:46:26.359137.359137 lmp.py:1622]   Expert 41 |    218 | GPU
DEBUG 01-13 08:46:26.359733.359733 lmp.py:1622]   Expert 34 |    225 | GPU
DEBUG 01-13 08:46:26.359092.359092 lmp.py:1622]   Expert 22 |    226 | GPU
DEBUG 01-13 08:46:26.359688.359688 lmp.py:1622]   Expert  0 |    227 | GPU
DEBUG 01-13 08:46:26.359047.359047 lmp.py:1622]   Expert 54 |    234 | GPU
DEBUG 01-13 08:46:26.359405.359405 lmp.py:1622]   Expert 43 |    239 | GPU
DEBUG 01-13 08:46:26.359763.359763 lmp.py:1622]   Expert 26 |    242 | GPU
DEBUG 01-13 08:46:26.359360.359360 lmp.py:1622]   Expert 59 |    253 | GPU
DEBUG 01-13 08:46:26.359718.359718 lmp.py:1622]   Expert 15 |    256 | GPU
DEBUG 01-13 08:46:26.359791.359791 lmp.py:1622]   Expert 18 |    256 | GPU
DEBUG 01-13 08:46:26.359865.359865 lmp.py:1622]   Expert 13 |    257 | GPU
DEBUG 01-13 08:46:26.359700.359700 lmp.py:1622]   Expert 20 |    265 | GPU
DEBUG 01-13 08:46:26.359773.359773 lmp.py:1622]   Expert 24 |    265 | GPU
DEBUG 01-13 08:46:26.359370.359370 lmp.py:1622]   Expert 42 |    268 | GPU
DEBUG 01-13 08:46:26.359490.359490 lmp.py:1622]   Expert 50 |    268 | GPU
DEBUG 01-13 08:46:26.359848.359848 lmp.py:1622]   Expert 61 |    272 | GPU
DEBUG 01-13 08:46:26.359730.359730 lmp.py:1622]   Expert 29 |    274 | GPU
DEBUG 01-13 08:46:26.359849.359849 lmp.py:1622]   Expert 35 |    280 | GPU
DEBUG 01-13 08:46:26.359731.359731 lmp.py:1622]   Expert 32 |    294 | GPU
DEBUG 01-13 08:46:26.359281.359281 lmp.py:1622]   Expert  2 |    323 | GPU
DEBUG 01-13 08:46:26.359593.359593 lmp.py:1622]   Expert  8 |    341 | GPU
DEBUG 01-13 08:46:26.359428.359428 lmp.py:1622]   Expert 10 |    362 | GPU
DEBUG 01-13 08:46:26.359217.359217 lmp.py:1622]   Expert 46 |    423 | GPU
DEBUG 01-13 08:46:26.359813.359813 lmp.py:1622]   Expert 48 |    439 | GPU
DEBUG 01-13 08:46:26.359649.359649 lmp.py:1623] 
DEBUG 01-13 08:46:26.359649.359649 lmp.py:1623]   CPU total tokens: 4037 (32.9%)
DEBUG 01-13 08:46:26.359914.359914 lmp.py:1624]   GPU total tokens: 8251 (67.1%)
DEBUG 01-13 08:46:26.359279.359279 cuda_h.py:19] end experts_map_get cost 0.0016148090362548828 seconds
DEBUG 01-13 08:46:26.359957.359957 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-13 08:46:26.359389.359389 lmp.py:1632] 
DEBUG 01-13 08:46:26.359389.359389 lmp.py:1632]   Computing 32 experts on CPU MP...
DEBUG 01-13 08:46:26.359378.359378 cuda_h.py:19] end cpu_experts_submit cost 6.723403930664062e-05 seconds
DEBUG 01-13 08:46:26.359882.359882 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-13 08:46:26.359486.359486 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-13 08:46:26.360891.360891 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-13 08:46:26.360860.360860 cuda_h.py:19] end allocate_cuda_memory cost 0.000392913818359375 seconds
DEBUG 01-13 08:46:26.360531.360531 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-13 08:46:26.360439.360439 sllm_store_c.py:27] get device uuid map
DEBUG 01-13 08:46:26.361241.361241 sllm_store_c.py:29] call client load into gpu
DEBUG 01-13 08:46:26.361640.361640 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, aefffb21-e277-418b-bd7a-93906287dbde
DEBUG 01-13 08:46:26.361081.361081 client.py:106] call stub.LoadModelAsync
INFO 01-13 08:46:26.362402.362402 client.py:127] Model loaded
DEBUG 01-13 08:46:26.362359.362359 cuda_h.py:10] start restore2model
DEBUG 01-13 08:46:26.362858.362858 cuda_h.py:10] start experts_func_gpu_einsum_mp
DEBUG 01-13 08:46:26.362078.362078 cuda_h.py:19] end restore2model cost 0.0006468296051025391 seconds
DEBUG 01-13 08:46:26.362551.362551 cuda_h.py:19] end sllm_worker_task cost 0.01244974136352539 seconds
INFO 01-13 08:46:26.363637.363637 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, aefffb21-e277-418b-bd7a-93906287dbde
DEBUG 01-13 08:46:26.363752.363752 cuda_h.py:19] end load_into_gpu_async cost 0.003214120864868164 seconds
DEBUG 01-13 08:46:26.363793.363793 cuda_h.py:10] start restore_tensors2
DEBUG 01-13 08:46:26.364578.364578 cuda_h.py:19] end restore_tensors2 cost 0.0004696846008300781 seconds
DEBUG 01-13 08:46:26.364468.364468 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.004559516906738281 seconds
DEBUG 01-13 08:46:26.364536.364536 cuda_h.py:10] start restore2model
DEBUG 01-13 08:46:26.367604.367604 cuda_h.py:19] end restore2model cost 0.002794027328491211 seconds
DEBUG 01-13 08:46:26.367116.367116 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.007560253143310547 seconds
DEBUG 01-13 08:46:26.367216.367216 cuda_h.py:10] start gpu_sexperts
DEBUG 01-13 08:46:26.367519.367519 cuda_h.py:19] end gpu_sexperts cost 0.0002980232238769531 seconds
DEBUG 01-13 08:46:26.367448.367448 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-13 08:46:26.367675.367675 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.1219253540039062e-05 seconds
DEBUG 01-13 08:46:26.367630.367630 cuda_h.py:10] start wait_experts
INFO 01-13 08:46:26.367141.367141 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, aefffb21-e277-418b-bd7a-93906287dbde
DEBUG 01-13 08:46:26.379391.379391 mlpmodule.py:1006] group tensors cost 0.015765666961669922 s
DEBUG 01-13 08:46:26.381598.381598 mlpmodule.py:1044] pad cost 0.0016601085662841797 s
DEBUG 01-13 08:46:26.381887.381887 mlpmodule.py:1050] create cpu tensor cost 4.553794860839844e-05 s
DEBUG 01-13 08:46:26.381697.381697 mlpmodule.py:1055] move to cpu cost 3.457069396972656e-05 s
DEBUG 01-13 08:46:26.391181.391181 mlpmodule.py:1069] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-13 08:46:26.391339.391339 mlpmodule.py:1070] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-13 08:46:26.391276.391276 mlpmodule.py:1075] group_w3 first element: 0.08447265625
WARNING 01-13 08:46:26.391763.391763 mlpmodule.py:1085] start einsum2
DEBUG 01-13 08:46:26.406528.406528 mlpmodule.py:1095] group einsum cost 0.02434825897216797 s
DEBUG 01-13 08:46:26.406058.406058 mlpmodule.py:1103] cpy2cputensor cost 0.0006401538848876953 s
DEBUG 01-13 08:46:26.417130.417130 mlpmodule.py:785]  experts func einsum cost 0.05409646034240723 s
DEBUG 01-13 08:46:26.417382.417382 cuda_h.py:19] end experts_func_gpu_einsum_mp cost 0.05523061752319336 seconds
INFO 01-13 08:46:26.418705.418705 client.py:127] Model loaded
DEBUG 01-13 08:46:26.418985.418985 cuda_h.py:19] end wait_experts cost 0.05089974403381348 seconds
DEBUG 01-13 08:46:26.418121.418121 cuda_h.py:10] start gpu_experts
DEBUG 01-13 08:46:26.420984.420984 mlpmodule.py:559] gpu group tensors cost 0.0016055107116699219 s
DEBUG 01-13 08:46:26.425291.425291 mlpmodule.py:592] gpu pad cost 0.004288911819458008 s
DEBUG 01-13 08:46:26.425078.425078 mlpmodule.py:598] start_w1
DEBUG 01-13 08:46:26.426573.426573 mlpmodule.py:602] start_w3
DEBUG 01-13 08:46:26.426792.426792 mlpmodule.py:608] start_w2
DEBUG 01-13 08:46:26.426223.426223 mlpmodule.py:611] gpu group einsum cost 0.0015447139739990234 s
DEBUG 01-13 08:46:26.432183.432183 mlpmodule.py:683] gpu experts func einsum cost 0.013486862182617188 s
DEBUG 01-13 08:46:26.432957.432957 cuda_h.py:19] end gpu_experts cost 0.013812065124511719 seconds
DEBUG 01-13 08:46:26.432297.432297 cuda_h.py:10] start cpu_thread_manager_mp_wait
DEBUG 01-13 08:46:26.433475.433475 cuda_h.py:19] end cpu_thread_manager_mp_wait cost 7.772445678710938e-05 seconds
DEBUG 01-13 08:46:26.433918.433918 cuda_h.py:19] end layer_moe_generate_mp_l_24 cost 0.07630467414855957 seconds
DEBUG 01-13 08:46:26.433772.433772 lmp.py:1550] -------------------------------- end prefill layer 23 --------------------------------
DEBUG 01-13 08:46:26.433695.433695 lmp.py:1493] -------------------------------- start prefill layer 24 --------------------------------
DEBUG 01-13 08:46:26.434829.434829 cuda_h.py:10] start start_load_qkvogn_s_weight_l_25
DEBUG 01-13 08:46:26.434454.434454 cuda_h.py:10] start start_load_qkvogn_s_weight_l_25
DEBUG 01-13 08:46:26.434585.434585 cuda_h.py:19] end start_load_qkvogn_s_weight_l_25 cost 7.605552673339844e-05 seconds
DEBUG 01-13 08:46:26.434672.434672 cuda_h.py:19] end start_load_qkvogn_s_weight_l_25 cost 0.00011038780212402344 seconds
DEBUG 01-13 08:46:26.434845.434845 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-13 08:46:26.434013.434013 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-13 08:46:26.434840.434840 cuda_h.py:10] start sllm_worker_task
DEBUG 01-13 08:46:26.434616.434616 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-13 08:46:26.434012.434012 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-13 08:46:26.435257.435257 cuda_h.py:19] end allocate_cuda_memory cost 0.0004737377166748047 seconds
DEBUG 01-13 08:46:26.435382.435382 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-13 08:46:26.435213.435213 sllm_store_c.py:27] get device uuid map
DEBUG 01-13 08:46:26.435786.435786 sllm_store_c.py:29] call client load into gpu
DEBUG 01-13 08:46:26.435696.435696 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, b6a17409-9a28-49a2-b446-70112c6b8251
DEBUG 01-13 08:46:26.436113.436113 client.py:106] call stub.LoadModelAsync
DEBUG 01-13 08:46:26.436616.436616 cuda_h.py:10] start self_attn
INFO 01-13 08:46:26.437539.437539 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, b6a17409-9a28-49a2-b446-70112c6b8251
DEBUG 01-13 08:46:26.437645.437645 cuda_h.py:19] end load_into_gpu_async cost 0.0018227100372314453 seconds
DEBUG 01-13 08:46:26.437131.437131 cuda_h.py:10] start restore_tensors2
DEBUG 01-13 08:46:26.437105.437105 cuda_h.py:19] end restore_tensors2 cost 0.0001544952392578125 seconds
DEBUG 01-13 08:46:26.438666.438666 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.003165721893310547 seconds
INFO 01-13 08:46:26.438942.438942 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, b6a17409-9a28-49a2-b446-70112c6b8251
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-13 08:46:26.441097.441097 cuda_h.py:19] end self_attn cost 0.004911661148071289 seconds
DEBUG 01-13 08:46:26.442579.442579 cuda_h.py:19] end iln_self_attn_paln cost 0.007842540740966797 seconds
DEBUG 01-13 08:46:26.442641.442641 cuda_h.py:10] start layer_moe_generate_mp_l_25
DEBUG 01-13 08:46:26.442695.442695 cuda_h.py:10] start gate
DEBUG 01-13 08:46:26.443755.443755 cuda_h.py:19] end gate cost 0.0007376670837402344 seconds
DEBUG 01-13 08:46:26.443373.443373 cuda_h.py:10] start experts_map_get
DEBUG 01-13 08:46:26.443405.443405 lmp.py:1611] 
DEBUG 01-13 08:46:26.443405.443405 lmp.py:1611] Expert Token Distribution & Device Allocation:
DEBUG 01-13 08:46:26.443406.443406 lmp.py:1612]   Total experts: 64
DEBUG 01-13 08:46:26.443109.443109 lmp.py:1613]   CPU experts: 32 (50%)
DEBUG 01-13 08:46:26.443998.443998 lmp.py:1614]   GPU experts: 32 (50%)
DEBUG 01-13 08:46:26.443263.443263 lmp.py:1615] 
DEBUG 01-13 08:46:26.443263.443263 lmp.py:1615]   Expert ID | Tokens | Device
DEBUG 01-13 08:46:26.443721.443721 lmp.py:1616]   -----------------------------------
DEBUG 01-13 08:46:26.443901.443901 lmp.py:1622]   Expert 36 |     18 | CPU
DEBUG 01-13 08:46:26.443928.443928 lmp.py:1622]   Expert 35 |     32 | CPU
DEBUG 01-13 08:46:26.443524.443524 lmp.py:1622]   Expert 25 |     47 | CPU
DEBUG 01-13 08:46:26.443121.443121 lmp.py:1622]   Expert 46 |     48 | CPU
DEBUG 01-13 08:46:26.443718.443718 lmp.py:1622]   Expert 51 |     48 | CPU
DEBUG 01-13 08:46:26.443314.443314 lmp.py:1622]   Expert 16 |     56 | CPU
DEBUG 01-13 08:46:26.443673.443673 lmp.py:1622]   Expert  0 |     57 | CPU
DEBUG 01-13 08:46:26.443508.443508 lmp.py:1622]   Expert 42 |     63 | CPU
DEBUG 01-13 08:46:26.443627.443627 lmp.py:1622]   Expert 43 |     65 | CPU
DEBUG 01-13 08:46:26.443986.443986 lmp.py:1622]   Expert 30 |     71 | CPU
DEBUG 01-13 08:46:26.443874.443874 lmp.py:1622]   Expert 44 |     73 | CPU
DEBUG 01-13 08:46:26.443570.443570 lmp.py:1622]   Expert 47 |     75 | CPU
DEBUG 01-13 08:46:26.443028.443028 lmp.py:1622]   Expert 39 |     76 | CPU
DEBUG 01-13 08:46:26.443485.443485 lmp.py:1622]   Expert 55 |     79 | CPU
DEBUG 01-13 08:46:26.443989.443989 lmp.py:1622]   Expert  2 |     86 | CPU
DEBUG 01-13 08:46:26.443493.443493 lmp.py:1622]   Expert 48 |    106 | CPU
DEBUG 01-13 08:46:26.443236.443236 lmp.py:1622]   Expert  4 |    108 | CPU
DEBUG 01-13 08:46:26.443455.443455 lmp.py:1622]   Expert  6 |    118 | CPU
DEBUG 01-13 08:46:26.444436.444436 lmp.py:1622]   Expert 24 |    120 | CPU
DEBUG 01-13 08:46:26.444893.444893 lmp.py:1622]   Expert 33 |    120 | CPU
DEBUG 01-13 08:46:26.444848.444848 lmp.py:1622]   Expert 61 |    124 | CPU
DEBUG 01-13 08:46:26.444352.444352 lmp.py:1622]   Expert 13 |    127 | CPU
DEBUG 01-13 08:46:26.444903.444903 lmp.py:1622]   Expert 56 |    129 | CPU
DEBUG 01-13 08:46:26.444215.444215 lmp.py:1622]   Expert 15 |    132 | CPU
DEBUG 01-13 08:46:26.444050.444050 lmp.py:1622]   Expert  9 |    135 | CPU
DEBUG 01-13 08:46:26.444646.444646 lmp.py:1622]   Expert 54 |    136 | CPU
DEBUG 01-13 08:46:26.444004.444004 lmp.py:1622]   Expert 20 |    139 | CPU
DEBUG 01-13 08:46:26.444840.444840 lmp.py:1622]   Expert 29 |    143 | CPU
DEBUG 01-13 08:46:26.444959.444959 lmp.py:1622]   Expert 38 |    144 | CPU
DEBUG 01-13 08:46:26.444079.444079 lmp.py:1622]   Expert  7 |    147 | CPU
DEBUG 01-13 08:46:26.444583.444583 lmp.py:1622]   Expert 59 |    150 | CPU
DEBUG 01-13 08:46:26.444657.444657 lmp.py:1622]   Expert 45 |    153 | CPU
DEBUG 01-13 08:46:26.444207.444207 lmp.py:1622]   Expert 62 |    156 | GPU
DEBUG 01-13 08:46:26.444996.444996 lmp.py:1622]   Expert 19 |    165 | GPU
DEBUG 01-13 08:46:26.444831.444831 lmp.py:1622]   Expert 57 |    185 | GPU
DEBUG 01-13 08:46:26.444189.444189 lmp.py:1622]   Expert 34 |    189 | GPU
DEBUG 01-13 08:46:26.444547.444547 lmp.py:1622]   Expert 50 |    195 | GPU
DEBUG 01-13 08:46:26.444727.444727 lmp.py:1622]   Expert 10 |    196 | GPU
DEBUG 01-13 08:46:26.444946.444946 lmp.py:1622]   Expert  8 |    202 | GPU
DEBUG 01-13 08:46:26.444656.444656 lmp.py:1622]   Expert 23 |    205 | GPU
DEBUG 01-13 08:46:26.444776.444776 lmp.py:1622]   Expert 31 |    217 | GPU
DEBUG 01-13 08:46:26.444419.444419 lmp.py:1622]   Expert 18 |    218 | GPU
DEBUG 01-13 08:46:26.444731.444731 lmp.py:1622]   Expert 60 |    219 | GPU
DEBUG 01-13 08:46:26.444566.444566 lmp.py:1622]   Expert 22 |    220 | GPU
DEBUG 01-13 08:46:26.444116.444116 lmp.py:1622]   Expert 52 |    223 | GPU
DEBUG 01-13 08:46:26.444713.444713 lmp.py:1622]   Expert 53 |    225 | GPU
DEBUG 01-13 08:46:26.444309.444309 lmp.py:1622]   Expert 37 |    229 | GPU
DEBUG 01-13 08:46:26.444429.444429 lmp.py:1622]   Expert  5 |    244 | GPU
DEBUG 01-13 08:46:26.444787.444787 lmp.py:1622]   Expert 17 |    250 | GPU
DEBUG 01-13 08:46:26.444669.444669 lmp.py:1622]   Expert 11 |    265 | GPU
DEBUG 01-13 08:46:26.444027.444027 lmp.py:1622]   Expert  1 |    275 | GPU
DEBUG 01-13 08:46:26.444385.444385 lmp.py:1622]   Expert 41 |    278 | GPU
DEBUG 01-13 08:46:26.444220.444220 lmp.py:1622]   Expert 49 |    278 | GPU
DEBUG 01-13 08:46:26.444771.444771 lmp.py:1622]   Expert 28 |    283 | GPU
DEBUG 01-13 08:46:26.444367.444367 lmp.py:1622]   Expert 26 |    286 | GPU
DEBUG 01-13 08:46:26.444679.444679 lmp.py:1622]   Expert 32 |    296 | GPU
DEBUG 01-13 08:46:26.444229.444229 lmp.py:1622]   Expert 58 |    297 | GPU
DEBUG 01-13 08:46:26.444588.444588 lmp.py:1622]   Expert 40 |    304 | GPU
DEBUG 01-13 08:46:26.444707.444707 lmp.py:1622]   Expert 14 |    314 | GPU
DEBUG 01-13 08:46:26.444589.444589 lmp.py:1622]   Expert 12 |    328 | GPU
DEBUG 01-13 08:46:26.444186.444186 lmp.py:1622]   Expert 63 |    333 | GPU
DEBUG 01-13 08:46:26.444305.444305 lmp.py:1622]   Expert 21 |    376 | GPU
DEBUG 01-13 08:46:26.444425.444425 lmp.py:1622]   Expert 27 |    689 | GPU
DEBUG 01-13 08:46:26.444307.444307 lmp.py:1622]   Expert  3 |   1023 | GPU
DEBUG 01-13 08:46:26.444618.444618 lmp.py:1623] 
DEBUG 01-13 08:46:26.444618.444618 lmp.py:1623]   CPU total tokens: 3125 (25.4%)
DEBUG 01-13 08:46:26.444122.444122 lmp.py:1624]   GPU total tokens: 9163 (74.6%)
DEBUG 01-13 08:46:26.444156.444156 cuda_h.py:19] end experts_map_get cost 0.0018093585968017578 seconds
INFO 01-13 08:46:26.445684.445684 client.py:127] Model loaded
DEBUG 01-13 08:46:26.445643.445643 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-13 08:46:26.445871.445871 cuda_h.py:10] start restore2model
DEBUG 01-13 08:46:26.445079.445079 lmp.py:1632] 
DEBUG 01-13 08:46:26.445079.445079 lmp.py:1632]   Computing 32 experts on CPU MP...
DEBUG 01-13 08:46:26.445601.445601 cuda_h.py:19] end cpu_experts_submit cost 0.0003552436828613281 seconds
DEBUG 01-13 08:46:26.445734.445734 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-13 08:46:26.445943.445943 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-13 08:46:26.446698.446698 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-13 08:46:26.446162.446162 cuda_h.py:19] end allocate_cuda_memory cost 0.0003724098205566406 seconds
DEBUG 01-13 08:46:26.446317.446317 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-13 08:46:26.446669.446669 sllm_store_c.py:27] get device uuid map
DEBUG 01-13 08:46:26.446327.446327 sllm_store_c.py:29] call client load into gpu
DEBUG 01-13 08:46:26.446130.446130 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 61033dab-b8e3-407e-aa1d-ca2f684d0325
DEBUG 01-13 08:46:26.447305.447305 client.py:106] call stub.LoadModelAsync
DEBUG 01-13 08:46:26.448913.448913 cuda_h.py:10] start experts_func_gpu_einsum_mp
INFO 01-13 08:46:26.448280.448280 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 61033dab-b8e3-407e-aa1d-ca2f684d0325
DEBUG 01-13 08:46:26.448787.448787 cuda_h.py:19] end load_into_gpu_async cost 0.0019202232360839844 seconds
DEBUG 01-13 08:46:26.448019.448019 cuda_h.py:10] start restore_tensors2
DEBUG 01-13 08:46:26.449845.449845 cuda_h.py:19] end restore_tensors2 cost 0.0005085468292236328 seconds
DEBUG 01-13 08:46:26.449119.449119 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0032646656036376953 seconds
DEBUG 01-13 08:46:26.449432.449432 cuda_h.py:10] start restore2model
DEBUG 01-13 08:46:26.449948.449948 cuda_h.py:19] end restore2model cost 0.0007224082946777344 seconds
DEBUG 01-13 08:46:26.450529.450529 cuda_h.py:19] end sllm_worker_task cost 0.015413522720336914 seconds
DEBUG 01-13 08:46:26.452493.452493 cuda_h.py:19] end restore2model cost 0.003555774688720703 seconds
DEBUG 01-13 08:46:26.452085.452085 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.007081031799316406 seconds
DEBUG 01-13 08:46:26.452119.452119 cuda_h.py:10] start gpu_sexperts
DEBUG 01-13 08:46:26.453845.453845 cuda_h.py:19] end gpu_sexperts cost 0.0002925395965576172 seconds
DEBUG 01-13 08:46:26.453820.453820 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-13 08:46:26.453219.453219 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 1.9311904907226562e-05 seconds
DEBUG 01-13 08:46:26.453392.453392 cuda_h.py:10] start wait_experts
INFO 01-13 08:46:26.453188.453188 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 61033dab-b8e3-407e-aa1d-ca2f684d0325
DEBUG 01-13 08:46:26.462694.462694 mlpmodule.py:1006] group tensors cost 0.013012170791625977 s
DEBUG 01-13 08:46:26.464785.464785 mlpmodule.py:1044] pad cost 0.0014948844909667969 s
DEBUG 01-13 08:46:26.464755.464755 mlpmodule.py:1050] create cpu tensor cost 4.792213439941406e-05 s
DEBUG 01-13 08:46:26.464566.464566 mlpmodule.py:1055] move to cpu cost 3.361701965332031e-05 s
DEBUG 01-13 08:46:26.473665.473665 mlpmodule.py:1069] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-13 08:46:26.473432.473432 mlpmodule.py:1070] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-13 08:46:26.474216.474216 mlpmodule.py:1075] group_w3 first element: 0.00653076171875
WARNING 01-13 08:46:26.474067.474067 mlpmodule.py:1085] start einsum2
DEBUG 01-13 08:46:26.488953.488953 mlpmodule.py:1095] group einsum cost 0.024159669876098633 s
DEBUG 01-13 08:46:26.489980.489980 mlpmodule.py:1103] cpy2cputensor cost 0.0006279945373535156 s
DEBUG 01-13 08:46:26.500485.500485 mlpmodule.py:785]  experts func einsum cost 0.05108785629272461 s
DEBUG 01-13 08:46:26.500609.500609 cuda_h.py:19] end experts_func_gpu_einsum_mp cost 0.052121877670288086 seconds
INFO 01-13 08:46:26.502678.502678 client.py:127] Model loaded
DEBUG 01-13 08:46:26.502256.502256 cuda_h.py:19] end wait_experts cost 0.04927778244018555 seconds
DEBUG 01-13 08:46:26.502756.502756 cuda_h.py:10] start gpu_experts
DEBUG 01-13 08:46:26.504610.504610 mlpmodule.py:559] gpu group tensors cost 0.0015687942504882812 s
DEBUG 01-13 08:46:26.509757.509757 mlpmodule.py:592] gpu pad cost 0.004418611526489258 s
DEBUG 01-13 08:46:26.509974.509974 mlpmodule.py:598] start_w1
DEBUG 01-13 08:46:26.510934.510934 mlpmodule.py:602] start_w3
DEBUG 01-13 08:46:26.510650.510650 mlpmodule.py:608] start_w2
DEBUG 01-13 08:46:26.510915.510915 mlpmodule.py:611] gpu group einsum cost 0.001604318618774414 s
DEBUG 01-13 08:46:26.517645.517645 mlpmodule.py:683] gpu experts func einsum cost 0.014880657196044922 s
DEBUG 01-13 08:46:26.518590.518590 cuda_h.py:19] end gpu_experts cost 0.015152692794799805 seconds
DEBUG 01-13 08:46:26.518220.518220 cuda_h.py:10] start cpu_thread_manager_mp_wait
DEBUG 01-13 08:46:26.518687.518687 cuda_h.py:19] end cpu_thread_manager_mp_wait cost 5.817413330078125e-05 seconds
DEBUG 01-13 08:46:26.518121.518121 cuda_h.py:19] end layer_moe_generate_mp_l_25 cost 0.076019287109375 seconds
DEBUG 01-13 08:46:26.518809.518809 lmp.py:1550] -------------------------------- end prefill layer 24 --------------------------------
DEBUG 01-13 08:46:26.518692.518692 lmp.py:1493] -------------------------------- start prefill layer 25 --------------------------------
DEBUG 01-13 08:46:26.518547.518547 cuda_h.py:10] start start_load_qkvogn_s_weight_l_26
DEBUG 01-13 08:46:26.518648.518648 cuda_h.py:10] start start_load_qkvogn_s_weight_l_26
DEBUG 01-13 08:46:26.518187.518187 cuda_h.py:19] end start_load_qkvogn_s_weight_l_26 cost 4.863739013671875e-05 seconds
DEBUG 01-13 08:46:26.518519.518519 cuda_h.py:19] end start_load_qkvogn_s_weight_l_26 cost 8.678436279296875e-05 seconds
DEBUG 01-13 08:46:26.518315.518315 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-13 08:46:26.518940.518940 cuda_h.py:10] start sllm_worker_task
DEBUG 01-13 08:46:26.519890.519890 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-13 08:46:26.519515.519515 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-13 08:46:26.519723.519723 cuda_h.py:19] end allocate_cuda_memory cost 0.0004222393035888672 seconds
DEBUG 01-13 08:46:26.519045.519045 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-13 08:46:26.519988.519988 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-13 08:46:26.519111.519111 sllm_store_c.py:27] get device uuid map
DEBUG 01-13 08:46:26.520107.520107 sllm_store_c.py:29] call client load into gpu
DEBUG 01-13 08:46:26.520446.520446 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 05d42677-5023-4368-beff-6033eb2dc353
DEBUG 01-13 08:46:26.520238.520238 client.py:106] call stub.LoadModelAsync
DEBUG 01-13 08:46:26.520893.520893 cuda_h.py:10] start self_attn
INFO 01-13 08:46:26.521876.521876 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 05d42677-5023-4368-beff-6033eb2dc353
DEBUG 01-13 08:46:26.521256.521256 cuda_h.py:19] end load_into_gpu_async cost 0.0019350051879882812 seconds
DEBUG 01-13 08:46:26.521111.521111 cuda_h.py:10] start restore_tensors2
DEBUG 01-13 08:46:26.522672.522672 cuda_h.py:19] end restore_tensors2 cost 0.00010085105895996094 seconds
DEBUG 01-13 08:46:26.522455.522455 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0029754638671875 seconds
INFO 01-13 08:46:26.522047.522047 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 05d42677-5023-4368-beff-6033eb2dc353
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-13 08:46:26.524939.524939 cuda_h.py:19] end self_attn cost 0.003644227981567383 seconds
DEBUG 01-13 08:46:26.524554.524554 cuda_h.py:19] end iln_self_attn_paln cost 0.005723237991333008 seconds
DEBUG 01-13 08:46:26.524702.524702 cuda_h.py:10] start layer_moe_generate_mp_l_26
DEBUG 01-13 08:46:26.524333.524333 cuda_h.py:10] start gate
DEBUG 01-13 08:46:26.525246.525246 cuda_h.py:19] end gate cost 0.0007386207580566406 seconds
DEBUG 01-13 08:46:26.525937.525937 cuda_h.py:10] start experts_map_get
DEBUG 01-13 08:46:26.525061.525061 lmp.py:1611] 
DEBUG 01-13 08:46:26.525061.525061 lmp.py:1611] Expert Token Distribution & Device Allocation:
DEBUG 01-13 08:46:26.525486.525486 lmp.py:1612]   Total experts: 64
DEBUG 01-13 08:46:26.526135.526135 lmp.py:1613]   CPU experts: 32 (50%)
DEBUG 01-13 08:46:26.526686.526686 lmp.py:1614]   GPU experts: 32 (50%)
DEBUG 01-13 08:46:26.526567.526567 lmp.py:1615] 
DEBUG 01-13 08:46:26.526567.526567 lmp.py:1615]   Expert ID | Tokens | Device
DEBUG 01-13 08:46:26.526210.526210 lmp.py:1616]   -----------------------------------
DEBUG 01-13 08:46:26.526006.526006 lmp.py:1622]   Expert 13 |     34 | CPU
DEBUG 01-13 08:46:26.526649.526649 lmp.py:1622]   Expert  9 |     41 | CPU
DEBUG 01-13 08:46:26.526338.526338 lmp.py:1622]   Expert 25 |     44 | CPU
DEBUG 01-13 08:46:26.526789.526789 lmp.py:1622]   Expert 44 |     45 | CPU
DEBUG 01-13 08:46:26.526478.526478 lmp.py:1622]   Expert 38 |     46 | CPU
DEBUG 01-13 08:46:26.526214.526214 lmp.py:1622]   Expert 22 |     49 | CPU
DEBUG 01-13 08:46:26.526665.526665 lmp.py:1622]   Expert 33 |     52 | CPU
DEBUG 01-13 08:46:26.526400.526400 lmp.py:1622]   Expert 16 |     54 | CPU
DEBUG 01-13 08:46:26.526374.526374 lmp.py:1622]   Expert  2 |     59 | CPU
DEBUG 01-13 08:46:26.526348.526348 lmp.py:1622]   Expert 42 |     61 | CPU
DEBUG 01-13 08:46:26.526561.526561 lmp.py:1622]   Expert  5 |     68 | CPU
DEBUG 01-13 08:46:26.526727.526727 lmp.py:1622]   Expert 10 |     78 | CPU
DEBUG 01-13 08:46:26.526178.526178 lmp.py:1622]   Expert 24 |     81 | CPU
DEBUG 01-13 08:46:26.526821.526821 lmp.py:1622]   Expert 23 |     84 | CPU
DEBUG 01-13 08:46:26.526987.526987 lmp.py:1622]   Expert 59 |     85 | CPU
DEBUG 01-13 08:46:26.526199.526199 lmp.py:1622]   Expert 21 |    100 | CPU
DEBUG 01-13 08:46:26.526173.526173 lmp.py:1622]   Expert 55 |    105 | CPU
DEBUG 01-13 08:46:26.526624.526624 lmp.py:1622]   Expert 46 |    107 | CPU
DEBUG 01-13 08:46:26.526837.526837 lmp.py:1622]   Expert 61 |    110 | CPU
DEBUG 01-13 08:46:26.526572.526572 lmp.py:1622]   Expert 45 |    122 | CPU
DEBUG 01-13 08:46:26.526546.526546 lmp.py:1622]   Expert 31 |    127 | CPU
DEBUG 01-13 08:46:26.526282.526282 lmp.py:1622]   Expert  6 |    138 | CPU
DEBUG 01-13 08:46:26.526256.526256 lmp.py:1622]   Expert 36 |    138 | CPU
DEBUG 01-13 08:46:26.526945.526945 lmp.py:1622]   Expert 51 |    138 | CPU
DEBUG 01-13 08:46:26.526873.526873 lmp.py:1622]   Expert  0 |    146 | CPU
DEBUG 01-13 08:46:26.526039.526039 lmp.py:1622]   Expert  8 |    155 | CPU
DEBUG 01-13 08:46:26.526205.526205 lmp.py:1622]   Expert 26 |    155 | CPU
DEBUG 01-13 08:46:26.526179.526179 lmp.py:1622]   Expert 43 |    158 | CPU
DEBUG 01-13 08:46:26.526153.526153 lmp.py:1622]   Expert 18 |    160 | CPU
DEBUG 01-13 08:46:26.526128.526128 lmp.py:1622]   Expert  3 |    164 | CPU
DEBUG 01-13 08:46:26.526863.526863 lmp.py:1622]   Expert 41 |    170 | CPU
DEBUG 01-13 08:46:26.526520.526520 lmp.py:1622]   Expert 48 |    171 | CPU
DEBUG 01-13 08:46:26.526447.526447 lmp.py:1622]   Expert 12 |    174 | GPU
DEBUG 01-13 08:46:26.526945.526945 lmp.py:1622]   Expert 20 |    175 | GPU
DEBUG 01-13 08:46:26.526442.526442 lmp.py:1622]   Expert  7 |    176 | GPU
DEBUG 01-13 08:46:26.526939.526939 lmp.py:1622]   Expert 56 |    184 | GPU
DEBUG 01-13 08:46:26.526675.526675 lmp.py:1622]   Expert 34 |    189 | GPU
DEBUG 01-13 08:46:26.526410.526410 lmp.py:1622]   Expert 28 |    194 | GPU
DEBUG 01-13 08:46:26.526100.526100 lmp.py:1622]   Expert 47 |    195 | GPU
DEBUG 01-13 08:46:26.526312.526312 lmp.py:1622]   Expert 27 |    196 | GPU
DEBUG 01-13 08:46:26.526763.526763 lmp.py:1622]   Expert  1 |    198 | GPU
DEBUG 01-13 08:46:26.526260.526260 lmp.py:1622]   Expert 11 |    207 | GPU
DEBUG 01-13 08:46:26.526757.526757 lmp.py:1622]   Expert 32 |    217 | GPU
DEBUG 01-13 08:46:26.526255.526255 lmp.py:1622]   Expert 40 |    231 | GPU
DEBUG 01-13 08:46:26.526990.526990 lmp.py:1622]   Expert 49 |    231 | GPU
DEBUG 01-13 08:46:26.526726.526726 lmp.py:1622]   Expert 53 |    233 | GPU
DEBUG 01-13 08:46:26.526985.526985 lmp.py:1622]   Expert 50 |    246 | GPU
DEBUG 01-13 08:46:26.526959.526959 lmp.py:1622]   Expert 63 |    246 | GPU
DEBUG 01-13 08:46:26.526456.526456 lmp.py:1622]   Expert  4 |    250 | GPU
DEBUG 01-13 08:46:26.526192.526192 lmp.py:1622]   Expert 29 |    250 | GPU
DEBUG 01-13 08:46:26.526450.526450 lmp.py:1622]   Expert 30 |    250 | GPU
DEBUG 01-13 08:46:26.526186.526186 lmp.py:1622]   Expert 15 |    254 | GPU
DEBUG 01-13 08:46:26.526922.526922 lmp.py:1622]   Expert 14 |    267 | GPU
DEBUG 01-13 08:46:26.526896.526896 lmp.py:1622]   Expert 35 |    271 | GPU
DEBUG 01-13 08:46:26.526346.526346 lmp.py:1622]   Expert 37 |    300 | GPU
DEBUG 01-13 08:46:26.526797.526797 lmp.py:1622]   Expert 52 |    329 | GPU
DEBUG 01-13 08:46:26.527248.527248 lmp.py:1622]   Expert 17 |    367 | GPU
DEBUG 01-13 08:46:26.527938.527938 lmp.py:1622]   Expert 54 |    379 | GPU
DEBUG 01-13 08:46:26.527673.527673 lmp.py:1622]   Expert 39 |    390 | GPU
DEBUG 01-13 08:46:26.527170.527170 lmp.py:1622]   Expert 57 |    412 | GPU
DEBUG 01-13 08:46:26.527668.527668 lmp.py:1622]   Expert 60 |    458 | GPU
DEBUG 01-13 08:46:26.527403.527403 lmp.py:1622]   Expert 62 |    463 | GPU
DEBUG 01-13 08:46:26.527139.527139 lmp.py:1622]   Expert 19 |    548 | GPU
DEBUG 01-13 08:46:26.527874.527874 lmp.py:1622]   Expert 58 |    563 | GPU
DEBUG 01-13 08:46:26.527802.527802 lmp.py:1623] 
DEBUG 01-13 08:46:26.527802.527802 lmp.py:1623]   CPU total tokens: 3245 (26.4%)
DEBUG 01-13 08:46:26.527684.527684 lmp.py:1624]   GPU total tokens: 9043 (73.6%)
DEBUG 01-13 08:46:26.527664.527664 cuda_h.py:19] end experts_map_get cost 0.0015261173248291016 seconds
DEBUG 01-13 08:46:26.527614.527614 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-13 08:46:26.527416.527416 lmp.py:1632] 
DEBUG 01-13 08:46:26.527416.527416 lmp.py:1632]   Computing 32 experts on CPU MP...
DEBUG 01-13 08:46:26.527968.527968 cuda_h.py:19] end cpu_experts_submit cost 5.5789947509765625e-05 seconds
DEBUG 01-13 08:46:26.527756.527756 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-13 08:46:26.527460.527460 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-13 08:46:26.527269.527269 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-13 08:46:26.529886.529886 cuda_h.py:19] end allocate_cuda_memory cost 0.0013995170593261719 seconds
DEBUG 01-13 08:46:26.529743.529743 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-13 08:46:26.529360.529360 sllm_store_c.py:27] get device uuid map
DEBUG 01-13 08:46:26.529715.529715 sllm_store_c.py:29] call client load into gpu
DEBUG 01-13 08:46:26.529823.529823 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 52527a34-693b-4a3b-bd3e-e4ab2d9ab49b
DEBUG 01-13 08:46:26.530794.530794 client.py:106] call stub.LoadModelAsync
INFO 01-13 08:46:26.530788.530788 client.py:127] Model loaded
DEBUG 01-13 08:46:26.530591.530591 cuda_h.py:10] start restore2model
DEBUG 01-13 08:46:26.531796.531796 cuda_h.py:10] start experts_func_gpu_einsum_mp
INFO 01-13 08:46:26.531849.531849 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 52527a34-693b-4a3b-bd3e-e4ab2d9ab49b
DEBUG 01-13 08:46:26.531613.531613 cuda_h.py:19] end load_into_gpu_async cost 0.0023963451385498047 seconds
DEBUG 01-13 08:46:26.531415.531415 cuda_h.py:10] start restore_tensors2
DEBUG 01-13 08:46:26.532266.532266 cuda_h.py:19] end restore_tensors2 cost 0.0004589557647705078 seconds
DEBUG 01-13 08:46:26.532817.532817 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.00469660758972168 seconds
DEBUG 01-13 08:46:26.532316.532316 cuda_h.py:10] start restore2model
DEBUG 01-13 08:46:26.534528.534528 cuda_h.py:19] end restore2model cost 0.0018978118896484375 seconds
DEBUG 01-13 08:46:26.534723.534723 cuda_h.py:19] end sllm_worker_task cost 0.01535344123840332 seconds
DEBUG 01-13 08:46:26.536058.536058 cuda_h.py:19] end restore2model cost 0.004717350006103516 seconds
DEBUG 01-13 08:46:26.537485.537485 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.009679555892944336 seconds
DEBUG 01-13 08:46:26.537188.537188 cuda_h.py:10] start gpu_sexperts
DEBUG 01-13 08:46:26.537212.537212 cuda_h.py:19] end gpu_sexperts cost 0.00030112266540527344 seconds
DEBUG 01-13 08:46:26.537194.537194 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-13 08:46:26.537262.537262 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.1219253540039062e-05 seconds
DEBUG 01-13 08:46:26.537435.537435 cuda_h.py:10] start wait_experts
INFO 01-13 08:46:26.537516.537516 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 52527a34-693b-4a3b-bd3e-e4ab2d9ab49b
DEBUG 01-13 08:46:26.549615.549615 mlpmodule.py:1006] group tensors cost 0.016346454620361328 s
DEBUG 01-13 08:46:26.552490.552490 mlpmodule.py:1044] pad cost 0.0027511119842529297 s
DEBUG 01-13 08:46:26.552926.552926 mlpmodule.py:1050] create cpu tensor cost 6.866455078125e-05 s
DEBUG 01-13 08:46:26.552439.552439 mlpmodule.py:1055] move to cpu cost 4.863739013671875e-05 s
DEBUG 01-13 08:46:26.562173.562173 mlpmodule.py:1069] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-13 08:46:26.562001.562001 mlpmodule.py:1070] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-13 08:46:26.562057.562057 mlpmodule.py:1075] group_w3 first element: 0.007110595703125
WARNING 01-13 08:46:26.562069.562069 mlpmodule.py:1085] start einsum2
DEBUG 01-13 08:46:26.579129.579129 mlpmodule.py:1095] group einsum cost 0.026253223419189453 s
DEBUG 01-13 08:46:26.579669.579669 mlpmodule.py:1103] cpy2cputensor cost 0.0006723403930664062 s
INFO 01-13 08:46:26.586764.586764 client.py:127] Model loaded
DEBUG 01-13 08:46:26.586183.586183 cuda_h.py:19] end wait_experts cost 0.048769474029541016 seconds
DEBUG 01-13 08:46:26.586544.586544 cuda_h.py:10] start gpu_experts
DEBUG 01-13 08:46:26.588371.588371 mlpmodule.py:559] gpu group tensors cost 0.001552581787109375 s
DEBUG 01-13 08:46:26.591881.591881 mlpmodule.py:785]  experts func einsum cost 0.059151649475097656 s
DEBUG 01-13 08:46:26.592537.592537 cuda_h.py:19] end experts_func_gpu_einsum_mp cost 0.06068873405456543 seconds
DEBUG 01-13 08:46:26.592037.592037 mlpmodule.py:592] gpu pad cost 0.004528522491455078 s
DEBUG 01-13 08:46:26.593791.593791 mlpmodule.py:598] start_w1
DEBUG 01-13 08:46:26.593978.593978 mlpmodule.py:602] start_w3
DEBUG 01-13 08:46:26.594298.594298 mlpmodule.py:608] start_w2
DEBUG 01-13 08:46:26.594319.594319 mlpmodule.py:611] gpu group einsum cost 0.0017211437225341797 s
DEBUG 01-13 08:46:26.598823.598823 mlpmodule.py:683] gpu experts func einsum cost 0.01190638542175293 s
DEBUG 01-13 08:46:26.598178.598178 cuda_h.py:19] end gpu_experts cost 0.012162208557128906 seconds
DEBUG 01-13 08:46:26.598001.598001 cuda_h.py:10] start cpu_thread_manager_mp_wait
DEBUG 01-13 08:46:26.598243.598243 cuda_h.py:19] end cpu_thread_manager_mp_wait cost 6.413459777832031e-05 seconds
DEBUG 01-13 08:46:26.598353.598353 cuda_h.py:19] end layer_moe_generate_mp_l_26 cost 0.0741734504699707 seconds
DEBUG 01-13 08:46:26.599472.599472 lmp.py:1550] -------------------------------- end prefill layer 25 --------------------------------
DEBUG 01-13 08:46:26.599084.599084 lmp.py:1493] -------------------------------- start prefill layer 26 --------------------------------
DEBUG 01-13 08:46:26.599423.599423 cuda_h.py:10] start start_load_qkvogn_s_weight_l_27
DEBUG 01-13 08:46:26.599292.599292 cuda_h.py:10] start start_load_qkvogn_s_weight_l_27
DEBUG 01-13 08:46:26.599745.599745 cuda_h.py:19] end start_load_qkvogn_s_weight_l_27 cost 4.982948303222656e-05 seconds
DEBUG 01-13 08:46:26.599799.599799 cuda_h.py:19] end start_load_qkvogn_s_weight_l_27 cost 9.512901306152344e-05 seconds
DEBUG 01-13 08:46:26.599125.599125 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-13 08:46:26.599957.599957 cuda_h.py:10] start sllm_worker_task
DEBUG 01-13 08:46:26.600627.600627 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-13 08:46:26.600988.600988 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-13 08:46:26.600426.600426 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-13 08:46:26.600169.600169 cuda_h.py:19] end allocate_cuda_memory cost 0.00038886070251464844 seconds
DEBUG 01-13 08:46:26.600655.600655 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-13 08:46:26.600241.600241 sllm_store_c.py:27] get device uuid map
DEBUG 01-13 08:46:26.601693.601693 sllm_store_c.py:29] call client load into gpu
DEBUG 01-13 08:46:26.601257.601257 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 725fd85f-4cef-4570-b118-f4765ed0869e
DEBUG 01-13 08:46:26.601114.601114 client.py:106] call stub.LoadModelAsync
DEBUG 01-13 08:46:26.601637.601637 cuda_h.py:10] start self_attn
INFO 01-13 08:46:26.602872.602872 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 725fd85f-4cef-4570-b118-f4765ed0869e
DEBUG 01-13 08:46:26.602279.602279 cuda_h.py:19] end load_into_gpu_async cost 0.0019223690032958984 seconds
DEBUG 01-13 08:46:26.602511.602511 cuda_h.py:10] start restore_tensors2
DEBUG 01-13 08:46:26.603827.603827 cuda_h.py:19] end restore_tensors2 cost 0.00010013580322265625 seconds
DEBUG 01-13 08:46:26.603821.603821 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.002751588821411133 seconds
INFO 01-13 08:46:26.603976.603976 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 725fd85f-4cef-4570-b118-f4765ed0869e
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-13 08:46:26.605428.605428 cuda_h.py:19] end self_attn cost 0.003916025161743164 seconds
DEBUG 01-13 08:46:26.605453.605453 cuda_h.py:19] end iln_self_attn_paln cost 0.006201982498168945 seconds
DEBUG 01-13 08:46:26.605648.605648 cuda_h.py:10] start layer_moe_generate_mp_l_27
DEBUG 01-13 08:46:26.606411.606411 cuda_h.py:10] start gate
DEBUG 01-13 08:46:26.606050.606050 cuda_h.py:19] end gate cost 0.0006809234619140625 seconds
DEBUG 01-13 08:46:26.606655.606655 cuda_h.py:10] start experts_map_get
DEBUG 01-13 08:46:26.607249.607249 lmp.py:1611] 
DEBUG 01-13 08:46:26.607249.607249 lmp.py:1611] Expert Token Distribution & Device Allocation:
DEBUG 01-13 08:46:26.607436.607436 lmp.py:1612]   Total experts: 64
DEBUG 01-13 08:46:26.607277.607277 lmp.py:1613]   CPU experts: 32 (50%)
DEBUG 01-13 08:46:26.607543.607543 lmp.py:1614]   GPU experts: 32 (50%)
DEBUG 01-13 08:46:26.607186.607186 lmp.py:1615] 
DEBUG 01-13 08:46:26.607186.607186 lmp.py:1615]   Expert ID | Tokens | Device
DEBUG 01-13 08:46:26.607498.607498 lmp.py:1616]   -----------------------------------
DEBUG 01-13 08:46:26.607863.607863 lmp.py:1622]   Expert 20 |     10 | CPU
DEBUG 01-13 08:46:26.607506.607506 lmp.py:1622]   Expert 61 |     10 | CPU
DEBUG 01-13 08:46:26.607195.607195 lmp.py:1622]   Expert 11 |     32 | CPU
DEBUG 01-13 08:46:26.607123.607123 lmp.py:1622]   Expert  7 |     34 | CPU
DEBUG 01-13 08:46:26.607812.607812 lmp.py:1622]   Expert  3 |     35 | CPU
DEBUG 01-13 08:46:26.607263.607263 lmp.py:1622]   Expert 51 |     38 | CPU
DEBUG 01-13 08:46:26.607237.607237 lmp.py:1622]   Expert 62 |     43 | CPU
DEBUG 01-13 08:46:26.607926.607926 lmp.py:1622]   Expert 30 |     47 | CPU
DEBUG 01-13 08:46:26.607139.607139 lmp.py:1622]   Expert  6 |     56 | CPU
DEBUG 01-13 08:46:26.607828.607828 lmp.py:1622]   Expert 17 |     59 | CPU
DEBUG 01-13 08:46:26.607471.607471 lmp.py:1622]   Expert 29 |     60 | CPU
DEBUG 01-13 08:46:26.607160.607160 lmp.py:1622]   Expert  9 |     67 | CPU
DEBUG 01-13 08:46:26.607803.607803 lmp.py:1622]   Expert 59 |     78 | CPU
DEBUG 01-13 08:46:26.607493.607493 lmp.py:1622]   Expert 38 |     79 | CPU
DEBUG 01-13 08:46:26.607705.607705 lmp.py:1622]   Expert 19 |     80 | CPU
DEBUG 01-13 08:46:26.607679.607679 lmp.py:1622]   Expert 63 |     81 | CPU
DEBUG 01-13 08:46:26.607415.607415 lmp.py:1622]   Expert 55 |     86 | CPU
DEBUG 01-13 08:46:26.607488.607488 lmp.py:1622]   Expert 48 |     97 | CPU
DEBUG 01-13 08:46:26.607085.607085 lmp.py:1622]   Expert  8 |     98 | CPU
DEBUG 01-13 08:46:26.607682.607682 lmp.py:1622]   Expert 22 |    106 | CPU
DEBUG 01-13 08:46:26.607040.607040 lmp.py:1622]   Expert 49 |    107 | CPU
DEBUG 01-13 08:46:26.607637.607637 lmp.py:1622]   Expert 34 |    111 | CPU
DEBUG 01-13 08:46:26.607233.607233 lmp.py:1622]   Expert 24 |    113 | CPU
DEBUG 01-13 08:46:26.607022.607022 lmp.py:1622]   Expert 50 |    114 | CPU
DEBUG 01-13 08:46:26.607334.607334 lmp.py:1622]   Expert 36 |    116 | CPU
DEBUG 01-13 08:46:26.607169.607169 lmp.py:1622]   Expert 42 |    118 | CPU
DEBUG 01-13 08:46:26.607958.607958 lmp.py:1622]   Expert 39 |    124 | CPU
DEBUG 01-13 08:46:26.607793.607793 lmp.py:1622]   Expert  4 |    127 | CPU
DEBUG 01-13 08:46:26.607389.607389 lmp.py:1622]   Expert 37 |    140 | CPU
DEBUG 01-13 08:46:26.607986.607986 lmp.py:1622]   Expert 15 |    144 | CPU
DEBUG 01-13 08:46:26.607344.607344 lmp.py:1622]   Expert 41 |    152 | CPU
DEBUG 01-13 08:46:26.607464.607464 lmp.py:1622]   Expert 23 |    153 | CPU
DEBUG 01-13 08:46:26.607538.607538 lmp.py:1622]   Expert 56 |    165 | GPU
DEBUG 01-13 08:46:26.607657.607657 lmp.py:1622]   Expert  1 |    168 | GPU
DEBUG 01-13 08:46:26.607777.607777 lmp.py:1622]   Expert 16 |    169 | GPU
DEBUG 01-13 08:46:26.607327.607327 lmp.py:1622]   Expert 60 |    170 | GPU
DEBUG 01-13 08:46:26.607163.607163 lmp.py:1622]   Expert 44 |    171 | GPU
DEBUG 01-13 08:46:26.607713.607713 lmp.py:1622]   Expert 21 |    181 | GPU
DEBUG 01-13 08:46:26.607263.607263 lmp.py:1622]   Expert 43 |    183 | GPU
DEBUG 01-13 08:46:26.607621.607621 lmp.py:1622]   Expert 53 |    189 | GPU
DEBUG 01-13 08:46:26.607741.607741 lmp.py:1622]   Expert 47 |    199 | GPU
DEBUG 01-13 08:46:26.608861.608861 lmp.py:1622]   Expert 12 |    204 | GPU
DEBUG 01-13 08:46:26.608458.608458 lmp.py:1622]   Expert 33 |    206 | GPU
DEBUG 01-13 08:46:26.608816.608816 lmp.py:1622]   Expert 13 |    211 | GPU
DEBUG 01-13 08:46:26.608936.608936 lmp.py:1622]   Expert 32 |    227 | GPU
DEBUG 01-13 08:46:26.608817.608817 lmp.py:1622]   Expert 28 |    230 | GPU
DEBUG 01-13 08:46:26.608414.608414 lmp.py:1622]   Expert  0 |    251 | GPU
DEBUG 01-13 08:46:26.608772.608772 lmp.py:1622]   Expert 31 |    259 | GPU
DEBUG 01-13 08:46:26.608130.608130 lmp.py:1622]   Expert 26 |    261 | GPU
DEBUG 01-13 08:46:26.608681.608681 lmp.py:1622]   Expert 54 |    261 | GPU
DEBUG 01-13 08:46:26.608231.608231 lmp.py:1622]   Expert 10 |    266 | GPU
DEBUG 01-13 08:46:26.608304.608304 lmp.py:1622]   Expert 18 |    266 | GPU
DEBUG 01-13 08:46:26.608663.608663 lmp.py:1622]   Expert 57 |    269 | GPU
DEBUG 01-13 08:46:26.608259.608259 lmp.py:1622]   Expert  2 |    294 | GPU
DEBUG 01-13 08:46:26.608902.608902 lmp.py:1622]   Expert 58 |    298 | GPU
DEBUG 01-13 08:46:26.608022.608022 lmp.py:1622]   Expert 40 |    337 | GPU
DEBUG 01-13 08:46:26.608619.608619 lmp.py:1622]   Expert 45 |    359 | GPU
DEBUG 01-13 08:46:26.608738.608738 lmp.py:1622]   Expert 25 |    384 | GPU
DEBUG 01-13 08:46:26.608858.608858 lmp.py:1622]   Expert  5 |    427 | GPU
DEBUG 01-13 08:46:26.608501.608501 lmp.py:1622]   Expert 35 |    447 | GPU
DEBUG 01-13 08:46:26.608621.608621 lmp.py:1622]   Expert 27 |    478 | GPU
DEBUG 01-13 08:46:26.608695.608695 lmp.py:1622]   Expert 46 |    532 | GPU
DEBUG 01-13 08:46:26.608159.608159 lmp.py:1622]   Expert 52 |    620 | GPU
DEBUG 01-13 08:46:26.608901.608901 lmp.py:1622]   Expert 14 |    891 | GPU
DEBUG 01-13 08:46:26.608644.608644 lmp.py:1623] 
DEBUG 01-13 08:46:26.608644.608644 lmp.py:1623]   CPU total tokens: 2715 (22.1%)
DEBUG 01-13 08:46:26.608386.608386 lmp.py:1624]   GPU total tokens: 9573 (77.9%)
DEBUG 01-13 08:46:26.608182.608182 cuda_h.py:19] end experts_map_get cost 0.0016584396362304688 seconds
DEBUG 01-13 08:46:26.608754.608754 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-13 08:46:26.608556.608556 lmp.py:1632] 
DEBUG 01-13 08:46:26.608556.608556 lmp.py:1632]   Computing 32 experts on CPU MP...
DEBUG 01-13 08:46:26.608300.608300 cuda_h.py:19] end cpu_experts_submit cost 5.745887756347656e-05 seconds
DEBUG 01-13 08:46:26.608519.608519 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-13 08:46:26.608223.608223 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-13 08:46:26.608409.608409 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-13 08:46:26.610529.610529 cuda_h.py:19] end allocate_cuda_memory cost 0.0017695426940917969 seconds
DEBUG 01-13 08:46:26.610445.610445 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-13 08:46:26.610182.610182 sllm_store_c.py:27] get device uuid map
DEBUG 01-13 08:46:26.610317.610317 sllm_store_c.py:29] call client load into gpu
DEBUG 01-13 08:46:26.610358.610358 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 16e3f725-a10e-4a0f-a443-0ab3adff94f7
DEBUG 01-13 08:46:26.611273.611273 client.py:106] call stub.LoadModelAsync
INFO 01-13 08:46:26.612560.612560 client.py:127] Model loaded
DEBUG 01-13 08:46:26.612543.612543 cuda_h.py:10] start restore2model
DEBUG 01-13 08:46:26.612365.612365 cuda_h.py:19] end restore2model cost 0.0005574226379394531 seconds
DEBUG 01-13 08:46:26.612740.612740 cuda_h.py:10] start experts_func_gpu_einsum_mp
DEBUG 01-13 08:46:26.612400.612400 cuda_h.py:19] end sllm_worker_task cost 0.012732982635498047 seconds
INFO 01-13 08:46:26.613357.613357 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 16e3f725-a10e-4a0f-a443-0ab3adff94f7
DEBUG 01-13 08:46:26.613965.613965 cuda_h.py:19] end load_into_gpu_async cost 0.002980947494506836 seconds
DEBUG 01-13 08:46:26.613080.613080 cuda_h.py:10] start restore_tensors2
DEBUG 01-13 08:46:26.614570.614570 cuda_h.py:19] end restore_tensors2 cost 0.0005035400390625 seconds
DEBUG 01-13 08:46:26.614068.614068 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.005828142166137695 seconds
DEBUG 01-13 08:46:26.614182.614182 cuda_h.py:10] start restore2model
DEBUG 01-13 08:46:26.619642.619642 cuda_h.py:19] end restore2model cost 0.005094051361083984 seconds
DEBUG 01-13 08:46:26.620961.620961 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.011396408081054688 seconds
DEBUG 01-13 08:46:26.620393.620393 cuda_h.py:10] start gpu_sexperts
DEBUG 01-13 08:46:26.621634.621634 cuda_h.py:19] end gpu_sexperts cost 0.0008292198181152344 seconds
DEBUG 01-13 08:46:26.621286.621286 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-13 08:46:26.621575.621575 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 5.7220458984375e-05 seconds
DEBUG 01-13 08:46:26.621245.621245 cuda_h.py:10] start wait_experts
INFO 01-13 08:46:26.621882.621882 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 16e3f725-a10e-4a0f-a443-0ab3adff94f7
DEBUG 01-13 08:46:26.628362.628362 mlpmodule.py:1006] group tensors cost 0.014268636703491211 s
DEBUG 01-13 08:46:26.631038.631038 mlpmodule.py:1044] pad cost 0.0022568702697753906 s
DEBUG 01-13 08:46:26.631545.631545 mlpmodule.py:1050] create cpu tensor cost 5.984306335449219e-05 s
DEBUG 01-13 08:46:26.631899.631899 mlpmodule.py:1055] move to cpu cost 4.6253204345703125e-05 s
DEBUG 01-13 08:46:26.640939.640939 mlpmodule.py:1069] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-13 08:46:26.640759.640759 mlpmodule.py:1070] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-13 08:46:26.640015.640015 mlpmodule.py:1075] group_w3 first element: -0.0024261474609375
WARNING 01-13 08:46:26.640788.640788 mlpmodule.py:1085] start einsum2
DEBUG 01-13 08:46:26.654463.654463 mlpmodule.py:1095] group einsum cost 0.02307915687561035 s
DEBUG 01-13 08:46:26.655181.655181 mlpmodule.py:1103] cpy2cputensor cost 0.0006542205810546875 s
DEBUG 01-13 08:46:26.667213.667213 mlpmodule.py:785]  experts func einsum cost 0.05356621742248535 s
DEBUG 01-13 08:46:26.667597.667597 cuda_h.py:19] end experts_func_gpu_einsum_mp cost 0.054702043533325195 seconds
INFO 01-13 08:46:26.668219.668219 client.py:127] Model loaded
DEBUG 01-13 08:46:26.668579.668579 cuda_h.py:19] end wait_experts cost 0.04729771614074707 seconds
DEBUG 01-13 08:46:26.668331.668331 cuda_h.py:10] start gpu_experts
DEBUG 01-13 08:46:26.670931.670931 mlpmodule.py:559] gpu group tensors cost 0.0014870166778564453 s
DEBUG 01-13 08:46:26.675543.675543 mlpmodule.py:592] gpu pad cost 0.004477500915527344 s
DEBUG 01-13 08:46:26.675197.675197 mlpmodule.py:598] start_w1
DEBUG 01-13 08:46:26.676425.676425 mlpmodule.py:602] start_w3
DEBUG 01-13 08:46:26.676659.676659 mlpmodule.py:608] start_w2
DEBUG 01-13 08:46:26.676441.676441 mlpmodule.py:611] gpu group einsum cost 0.0017232894897460938 s
DEBUG 01-13 08:46:26.682144.682144 mlpmodule.py:683] gpu experts func einsum cost 0.013599634170532227 s
DEBUG 01-13 08:46:26.682194.682194 cuda_h.py:19] end gpu_experts cost 0.013840436935424805 seconds
DEBUG 01-13 08:46:26.682864.682864 cuda_h.py:10] start cpu_thread_manager_mp_wait
DEBUG 01-13 08:46:26.682140.682140 cuda_h.py:19] end cpu_thread_manager_mp_wait cost 9.512901306152344e-05 seconds
DEBUG 01-13 08:46:26.682567.682567 cuda_h.py:19] end layer_moe_generate_mp_l_27 cost 0.07687258720397949 seconds
DEBUG 01-13 08:46:26.683757.683757 lmp.py:1550] -------------------------------- end prefill layer 26 --------------------------------
DEBUG 01-13 08:46:26.683692.683692 lmp.py:1493] -------------------------------- start prefill layer 27 --------------------------------
DEBUG 01-13 08:46:26.683640.683640 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-13 08:46:26.683332.683332 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-13 08:46:26.683106.683106 cuda_h.py:10] start self_attn
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-13 08:46:26.686385.686385 cuda_h.py:19] end self_attn cost 0.003126382827758789 seconds
DEBUG 01-13 08:46:26.687807.687807 cuda_h.py:19] end iln_self_attn_paln cost 0.003946781158447266 seconds
DEBUG 01-13 08:46:26.687386.687386 cuda_h.py:10] start layer_moe_generate_mp_l_28
DEBUG 01-13 08:46:26.687063.687063 cuda_h.py:10] start gate
DEBUG 01-13 08:46:26.688189.688189 cuda_h.py:19] end gate cost 0.0007524490356445312 seconds
DEBUG 01-13 08:46:26.688601.688601 cuda_h.py:10] start experts_map_get
DEBUG 01-13 08:46:26.688284.688284 lmp.py:1611] 
DEBUG 01-13 08:46:26.688284.688284 lmp.py:1611] Expert Token Distribution & Device Allocation:
DEBUG 01-13 08:46:26.688200.688200 lmp.py:1612]   Total experts: 64
DEBUG 01-13 08:46:26.688585.688585 lmp.py:1613]   CPU experts: 32 (50%)
DEBUG 01-13 08:46:26.688573.688573 lmp.py:1614]   GPU experts: 32 (50%)
DEBUG 01-13 08:46:26.688461.688461 lmp.py:1615] 
DEBUG 01-13 08:46:26.688461.688461 lmp.py:1615]   Expert ID | Tokens | Device
DEBUG 01-13 08:46:26.688111.688111 lmp.py:1616]   -----------------------------------
DEBUG 01-13 08:46:26.688582.688582 lmp.py:1622]   Expert 18 |     67 | CPU
DEBUG 01-13 08:46:26.688709.688709 lmp.py:1622]   Expert 47 |     69 | CPU
DEBUG 01-13 08:46:26.688928.688928 lmp.py:1622]   Expert 54 |     69 | CPU
DEBUG 01-13 08:46:26.688909.688909 lmp.py:1622]   Expert 23 |     74 | CPU
DEBUG 01-13 08:46:26.688890.688890 lmp.py:1622]   Expert 45 |     79 | CPU
DEBUG 01-13 08:46:26.688870.688870 lmp.py:1622]   Expert 44 |     81 | CPU
DEBUG 01-13 08:46:26.689851.689851 lmp.py:1622]   Expert 48 |     82 | CPU
DEBUG 01-13 08:46:26.689832.689832 lmp.py:1622]   Expert 20 |     91 | CPU
DEBUG 01-13 08:46:26.689767.689767 lmp.py:1622]   Expert 31 |     99 | CPU
DEBUG 01-13 08:46:26.689701.689701 lmp.py:1622]   Expert 36 |    101 | CPU
DEBUG 01-13 08:46:26.689305.689305 lmp.py:1622]   Expert 42 |    113 | CPU
DEBUG 01-13 08:46:26.689001.689001 lmp.py:1622]   Expert 61 |    113 | CPU
DEBUG 01-13 08:46:26.689458.689458 lmp.py:1622]   Expert 24 |    117 | CPU
DEBUG 01-13 08:46:26.689201.689201 lmp.py:1622]   Expert 33 |    118 | CPU
DEBUG 01-13 08:46:26.689705.689705 lmp.py:1622]   Expert 10 |    124 | CPU
DEBUG 01-13 08:46:26.689686.689686 lmp.py:1622]   Expert 11 |    125 | CPU
DEBUG 01-13 08:46:26.689190.689190 lmp.py:1622]   Expert 43 |    125 | CPU
DEBUG 01-13 08:46:26.689170.689170 lmp.py:1622]   Expert 49 |    127 | CPU
DEBUG 01-13 08:46:26.689674.689674 lmp.py:1622]   Expert 56 |    130 | CPU
DEBUG 01-13 08:46:26.689940.689940 lmp.py:1622]   Expert 51 |    140 | CPU
DEBUG 01-13 08:46:26.689206.689206 lmp.py:1622]   Expert 17 |    141 | CPU
DEBUG 01-13 08:46:26.689710.689710 lmp.py:1622]   Expert  6 |    143 | CPU
DEBUG 01-13 08:46:26.689214.689214 lmp.py:1622]   Expert  0 |    146 | CPU
DEBUG 01-13 08:46:26.689194.689194 lmp.py:1622]   Expert  5 |    154 | CPU
DEBUG 01-13 08:46:26.689414.689414 lmp.py:1622]   Expert 40 |    156 | CPU
DEBUG 01-13 08:46:26.689348.689348 lmp.py:1622]   Expert 12 |    159 | CPU
DEBUG 01-13 08:46:26.689806.689806 lmp.py:1622]   Expert 55 |    159 | CPU
DEBUG 01-13 08:46:26.689502.689502 lmp.py:1622]   Expert 59 |    161 | CPU
DEBUG 01-13 08:46:26.689483.689483 lmp.py:1622]   Expert 26 |    163 | CPU
DEBUG 01-13 08:46:26.689748.689748 lmp.py:1622]   Expert 13 |    167 | CPU
DEBUG 01-13 08:46:26.689252.689252 lmp.py:1622]   Expert 57 |    167 | CPU
DEBUG 01-13 08:46:26.689518.689518 lmp.py:1622]   Expert 38 |    168 | CPU
DEBUG 01-13 08:46:26.689545.689545 lmp.py:1622]   Expert 58 |    171 | GPU
DEBUG 01-13 08:46:26.689049.689049 lmp.py:1622]   Expert 46 |    172 | GPU
DEBUG 01-13 08:46:26.689553.689553 lmp.py:1622]   Expert 35 |    173 | GPU
DEBUG 01-13 08:46:26.689295.689295 lmp.py:1622]   Expert 30 |    174 | GPU
DEBUG 01-13 08:46:26.689515.689515 lmp.py:1622]   Expert  7 |    182 | GPU
DEBUG 01-13 08:46:26.689972.689972 lmp.py:1622]   Expert 16 |    185 | GPU
DEBUG 01-13 08:46:26.689145.689145 lmp.py:1622]   Expert 50 |    190 | GPU
DEBUG 01-13 08:46:26.689841.689841 lmp.py:1622]   Expert 32 |    197 | GPU
DEBUG 01-13 08:46:26.689345.689345 lmp.py:1622]   Expert 15 |    203 | GPU
DEBUG 01-13 08:46:26.689849.689849 lmp.py:1622]   Expert 14 |    205 | GPU
DEBUG 01-13 08:46:26.689353.689353 lmp.py:1622]   Expert  1 |    216 | GPU
DEBUG 01-13 08:46:26.689619.689619 lmp.py:1622]   Expert  3 |    226 | GPU
DEBUG 01-13 08:46:26.689646.689646 lmp.py:1622]   Expert  4 |    226 | GPU
DEBUG 01-13 08:46:26.689912.689912 lmp.py:1622]   Expert 39 |    232 | GPU
DEBUG 01-13 08:46:26.689369.689369 lmp.py:1622]   Expert 52 |    239 | GPU
DEBUG 01-13 08:46:26.689065.689065 lmp.py:1622]   Expert 34 |    242 | GPU
DEBUG 01-13 08:46:26.689762.689762 lmp.py:1622]   Expert 25 |    249 | GPU
DEBUG 01-13 08:46:26.689458.689458 lmp.py:1622]   Expert 28 |    249 | GPU
DEBUG 01-13 08:46:26.689200.689200 lmp.py:1622]   Expert 22 |    257 | GPU
DEBUG 01-13 08:46:26.689704.689704 lmp.py:1622]   Expert 41 |    266 | GPU
DEBUG 01-13 08:46:26.689446.689446 lmp.py:1622]   Expert  2 |    273 | GPU
DEBUG 01-13 08:46:26.689712.689712 lmp.py:1622]   Expert 21 |    273 | GPU
DEBUG 01-13 08:46:26.690978.690978 lmp.py:1622]   Expert 29 |    287 | GPU
DEBUG 01-13 08:46:26.690482.690482 lmp.py:1622]   Expert 60 |    289 | GPU
DEBUG 01-13 08:46:26.690270.690270 lmp.py:1622]   Expert 63 |    289 | GPU
DEBUG 01-13 08:46:26.690682.690682 lmp.py:1622]   Expert 62 |    294 | GPU
DEBUG 01-13 08:46:26.690139.690139 lmp.py:1622]   Expert 27 |    310 | GPU
DEBUG 01-13 08:46:26.690359.690359 lmp.py:1622]   Expert 53 |    331 | GPU
DEBUG 01-13 08:46:26.690485.690485 lmp.py:1622]   Expert 37 |    333 | GPU
DEBUG 01-13 08:46:26.690705.690705 lmp.py:1622]   Expert  8 |    334 | GPU
DEBUG 01-13 08:46:26.690209.690209 lmp.py:1622]   Expert 19 |    441 | GPU
DEBUG 01-13 08:46:26.690951.690951 lmp.py:1622]   Expert  9 |    652 | GPU
DEBUG 01-13 08:46:26.690885.690885 lmp.py:1623] 
DEBUG 01-13 08:46:26.690885.690885 lmp.py:1623]   CPU total tokens: 3928 (32.0%)
DEBUG 01-13 08:46:26.690535.690535 lmp.py:1624]   GPU total tokens: 8360 (68.0%)
DEBUG 01-13 08:46:26.690430.690430 cuda_h.py:19] end experts_map_get cost 0.0019800662994384766 seconds
DEBUG 01-13 08:46:26.690247.690247 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-13 08:46:26.690394.690394 lmp.py:1632] 
DEBUG 01-13 08:46:26.690394.690394 lmp.py:1632]   Computing 32 experts on CPU MP...
DEBUG 01-13 08:46:26.690582.690582 cuda_h.py:19] end cpu_experts_submit cost 6.723403930664062e-05 seconds
DEBUG 01-13 08:46:26.690808.690808 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-13 08:46:26.690088.690088 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-13 08:46:26.690810.690810 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-13 08:46:26.691447.691447 cuda_h.py:19] end allocate_cuda_memory cost 0.00039076805114746094 seconds
DEBUG 01-13 08:46:26.691187.691187 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-13 08:46:26.691282.691282 sllm_store_c.py:27] get device uuid map
DEBUG 01-13 08:46:26.691636.691636 sllm_store_c.py:29] call client load into gpu
DEBUG 01-13 08:46:26.691014.691014 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, f6d5fd64-65f4-4ad1-8918-436511fee837
DEBUG 01-13 08:46:26.692453.692453 client.py:106] call stub.LoadModelAsync
DEBUG 01-13 08:46:26.692486.692486 cuda_h.py:10] start experts_func_gpu_einsum_mp
INFO 01-13 08:46:26.694603.694603 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, f6d5fd64-65f4-4ad1-8918-436511fee837
DEBUG 01-13 08:46:26.694770.694770 cuda_h.py:19] end load_into_gpu_async cost 0.0027167797088623047 seconds
DEBUG 01-13 08:46:26.694089.694089 cuda_h.py:10] start restore_tensors2
DEBUG 01-13 08:46:26.694836.694836 cuda_h.py:19] end restore_tensors2 cost 0.00034999847412109375 seconds
DEBUG 01-13 08:46:26.694043.694043 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0043604373931884766 seconds
DEBUG 01-13 08:46:26.694429.694429 cuda_h.py:10] start restore2model
DEBUG 01-13 08:46:26.697761.697761 cuda_h.py:19] end restore2model cost 0.002566099166870117 seconds
DEBUG 01-13 08:46:26.697974.697974 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.007120370864868164 seconds
DEBUG 01-13 08:46:26.697360.697360 cuda_h.py:10] start gpu_sexperts
DEBUG 01-13 08:46:26.697469.697469 cuda_h.py:19] end gpu_sexperts cost 0.0002613067626953125 seconds
DEBUG 01-13 08:46:26.698629.698629 cuda_h.py:10] start wait_experts
INFO 01-13 08:46:26.698955.698955 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, f6d5fd64-65f4-4ad1-8918-436511fee837
DEBUG 01-13 08:46:26.699161.699161 mlpmodule.py:1006] group tensors cost 0.006905317306518555 s
DEBUG 01-13 08:46:26.703325.703325 mlpmodule.py:1044] pad cost 0.002587556838989258 s
DEBUG 01-13 08:46:26.703428.703428 mlpmodule.py:1050] create cpu tensor cost 5.698204040527344e-05 s
DEBUG 01-13 08:46:26.703278.703278 mlpmodule.py:1055] move to cpu cost 2.9087066650390625e-05 s
DEBUG 01-13 08:46:26.712583.712583 mlpmodule.py:1069] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-13 08:46:26.712082.712082 mlpmodule.py:1070] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-13 08:46:26.712713.712713 mlpmodule.py:1075] group_w3 first element: -0.006439208984375
WARNING 01-13 08:46:26.712390.712390 mlpmodule.py:1085] start einsum2
DEBUG 01-13 08:46:26.727544.727544 mlpmodule.py:1095] group einsum cost 0.02409219741821289 s
DEBUG 01-13 08:46:26.728674.728674 mlpmodule.py:1103] cpy2cputensor cost 0.0006818771362304688 s
DEBUG 01-13 08:46:26.743248.743248 mlpmodule.py:785]  experts func einsum cost 0.05067777633666992 s
DEBUG 01-13 08:46:26.743129.743129 cuda_h.py:19] end experts_func_gpu_einsum_mp cost 0.05151486396789551 seconds
INFO 01-13 08:46:26.749336.749336 client.py:127] Model loaded
DEBUG 01-13 08:46:26.749841.749841 cuda_h.py:19] end wait_experts cost 0.05174374580383301 seconds
DEBUG 01-13 08:46:26.749685.749685 cuda_h.py:10] start gpu_experts
DEBUG 01-13 08:46:26.751356.751356 mlpmodule.py:559] gpu group tensors cost 0.0014374256134033203 s
DEBUG 01-13 08:46:26.756269.756269 mlpmodule.py:592] gpu pad cost 0.0043599605560302734 s
DEBUG 01-13 08:46:26.756333.756333 mlpmodule.py:598] start_w1
DEBUG 01-13 08:46:26.756610.756610 mlpmodule.py:602] start_w3
DEBUG 01-13 08:46:26.757830.757830 mlpmodule.py:608] start_w2
DEBUG 01-13 08:46:26.757307.757307 mlpmodule.py:611] gpu group einsum cost 0.0015947818756103516 s
DEBUG 01-13 08:46:26.763356.763356 mlpmodule.py:683] gpu experts func einsum cost 0.013497352600097656 s
DEBUG 01-13 08:46:26.763492.763492 cuda_h.py:19] end gpu_experts cost 0.013730525970458984 seconds
DEBUG 01-13 08:46:26.763023.763023 cuda_h.py:10] start cpu_thread_manager_mp_wait
DEBUG 01-13 08:46:26.763793.763793 cuda_h.py:19] end cpu_thread_manager_mp_wait cost 3.910064697265625e-05 seconds
DEBUG 01-13 08:46:26.763552.763552 cuda_h.py:19] end layer_moe_generate_mp_l_28 cost 0.0765218734741211 seconds
DEBUG 01-13 08:46:26.764402.764402 lmp.py:1550] -------------------------------- end prefill layer 27 --------------------------------
DEBUG 01-13 08:46:26.764993.764993 cuda_h.py:19] end prefill_layer cost 2.013624668121338 seconds
DEBUG 01-13 08:46:28.933033.933033 cuda_h.py:10] start generate_input_ids
generate input ids cost 0.09284400939941406 s
DEBUG 01-13 08:46:29.289717.289717 cuda_h.py:19] end generate_input_ids cost 0.3548853397369385 seconds
DEBUG 01-13 08:46:29.289848.289848 cuda_h.py:10] start init_cache
DEBUG 01-13 08:46:29.289474.289474 cuda_h.py:19] end init_cache cost 7.081031799316406e-05 seconds
DEBUG 01-13 08:46:31.714886.714886 cuda_h.py:10] start init_meta_layer
DEBUG 01-13 08:46:31.716150.716150 cuda_h.py:19] end init_meta_layer cost 1.2874603271484375e-05 seconds
DEBUG 01-13 08:46:31.716050.716050 cuda_h.py:10] start init_weights
DEBUG 01-13 08:46:31.716435.716435 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-13 08:46:31.716721.716721 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-13 08:46:31.719109.719109 cuda_h.py:19] end allocate_cuda_memory cost 0.002045154571533203 seconds
DEBUG 01-13 08:46:31.719528.719528 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-13 08:46:31.719046.719046 sllm_store_c.py:27] get device uuid map
DEBUG 01-13 08:46:31.719722.719722 sllm_store_c.py:29] call client load into gpu
DEBUG 01-13 08:46:31.719803.719803 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, a94a27e4-3966-42ea-8b69-3da4fd8990c2
DEBUG 01-13 08:46:31.719064.719064 client.py:106] call stub.LoadModelAsync
INFO 01-13 08:46:31.721839.721839 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, a94a27e4-3966-42ea-8b69-3da4fd8990c2
DEBUG 01-13 08:46:31.721705.721705 cuda_h.py:19] end load_into_gpu_async cost 0.0020742416381835938 seconds
DEBUG 01-13 08:46:31.721145.721145 cuda_h.py:10] start restore_tensors2
DEBUG 01-13 08:46:31.721433.721433 cuda_h.py:19] end restore_tensors2 cost 5.054473876953125e-05 seconds
DEBUG 01-13 08:46:31.721183.721183 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.004496097564697266 seconds
DEBUG 01-13 08:46:31.721355.721355 cuda_h.py:10] start restore2model
DEBUG 01-13 08:46:31.721507.721507 cuda_h.py:19] end restore2model cost 0.00015974044799804688 seconds
INFO 01-13 08:46:31.721263.721263 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, a94a27e4-3966-42ea-8b69-3da4fd8990c2
INFO 01-13 08:46:31.800026.800026 client.py:127] Model loaded
DEBUG 01-13 08:46:31.800093.800093 cuda_h.py:10] start load_qkvogns_weight_l_0
DEBUG 01-13 08:46:31.800422.800422 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-13 08:46:31.800069.800069 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-13 08:46:31.801581.801581 cuda_h.py:19] end allocate_cuda_memory cost 0.0003924369812011719 seconds
DEBUG 01-13 08:46:31.801732.801732 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-13 08:46:31.801616.801616 sllm_store_c.py:27] get device uuid map
DEBUG 01-13 08:46:31.801222.801222 sllm_store_c.py:29] call client load into gpu
DEBUG 01-13 08:46:31.801555.801555 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 306915a5-c6d7-4185-9e2d-d0655589ae1e
DEBUG 01-13 08:46:31.801024.801024 client.py:106] call stub.LoadModelAsync
INFO 01-13 08:46:31.803580.803580 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 306915a5-c6d7-4185-9e2d-d0655589ae1e
DEBUG 01-13 08:46:31.803798.803798 cuda_h.py:19] end load_into_gpu_async cost 0.0020570755004882812 seconds
DEBUG 01-13 08:46:31.803244.803244 cuda_h.py:10] start restore_tensors2
DEBUG 01-13 08:46:31.803589.803589 cuda_h.py:19] end restore_tensors2 cost 0.00013208389282226562 seconds
DEBUG 01-13 08:46:31.803427.803427 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0032236576080322266 seconds
INFO 01-13 08:46:31.803767.803767 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 306915a5-c6d7-4185-9e2d-d0655589ae1e
INFO 01-13 08:46:31.818134.818134 client.py:127] Model loaded
DEBUG 01-13 08:46:31.819132.819132 cuda_h.py:10] start restore2model
DEBUG 01-13 08:46:31.819184.819184 cuda_h.py:19] end restore2model cost 0.0008540153503417969 seconds
DEBUG 01-13 08:46:31.820168.820168 cuda_h.py:19] end load_qkvogns_weight_l_0 cost 0.01954483985900879 seconds
DEBUG 01-13 08:46:31.820045.820045 cuda_h.py:19] end init_weights cost 0.1032552719116211 seconds
DEBUG 01-13 08:46:31.820101.820101 cuda_h.py:10] start copy_emodel
DEBUG 01-13 08:46:32.563727.563727 cuda_h.py:19] end copy_emodel cost 0.7434847354888916 seconds
DEBUG 01-13 08:46:32.564985.564985 cuda_h.py:10] start init_inputs_tokens
DEBUG 01-13 08:46:32.564246.564246 cuda_h.py:19] end init_inputs_tokens cost 0.0002574920654296875 seconds
DEBUG 01-13 08:46:32.564639.564639 cuda_h.py:10] start prefill_layer
DEBUG 01-13 08:46:32.565017.565017 lmp.py:1493] -------------------------------- start prefill layer 0 --------------------------------
DEBUG 01-13 08:46:32.565905.565905 cuda_h.py:10] start start_load_qkvogn_s_weight_l_1
DEBUG 01-13 08:46:32.565509.565509 cuda_h.py:10] start start_load_qkvogn_s_weight_l_1
DEBUG 01-13 08:46:32.565445.565445 cuda_h.py:19] end start_load_qkvogn_s_weight_l_1 cost 3.24249267578125e-05 seconds
DEBUG 01-13 08:46:32.565314.565314 cuda_h.py:19] end start_load_qkvogn_s_weight_l_1 cost 8.177757263183594e-05 seconds
DEBUG 01-13 08:46:32.565433.565433 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-13 08:46:32.565892.565892 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-13 08:46:32.565531.565531 cuda_h.py:10] start sllm_worker_task
DEBUG 01-13 08:46:32.565239.565239 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-13 08:46:32.565387.565387 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-13 08:46:32.565154.565154 cuda_h.py:19] end allocate_cuda_memory cost 0.00030493736267089844 seconds
DEBUG 01-13 08:46:32.566481.566481 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-13 08:46:32.566318.566318 sllm_store_c.py:27] get device uuid map
DEBUG 01-13 08:46:32.566473.566473 sllm_store_c.py:29] call client load into gpu
DEBUG 01-13 08:46:32.566858.566858 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 29f1cfbf-0966-4089-b005-233c6c36318c
DEBUG 01-13 08:46:32.566637.566637 client.py:106] call stub.LoadModelAsync
DEBUG 01-13 08:46:32.566705.566705 cuda_h.py:10] start self_attn
INFO 01-13 08:46:32.567345.567345 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 29f1cfbf-0966-4089-b005-233c6c36318c
DEBUG 01-13 08:46:32.567440.567440 cuda_h.py:19] end load_into_gpu_async cost 0.001668691635131836 seconds
DEBUG 01-13 08:46:32.567964.567964 cuda_h.py:10] start restore_tensors2
DEBUG 01-13 08:46:32.567187.567187 cuda_h.py:19] end restore_tensors2 cost 9.131431579589844e-05 seconds
DEBUG 01-13 08:46:32.567149.567149 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.002412080764770508 seconds
INFO 01-13 08:46:32.568304.568304 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 29f1cfbf-0966-4089-b005-233c6c36318c
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-13 08:46:32.570694.570694 cuda_h.py:19] end self_attn cost 0.004143238067626953 seconds
DEBUG 01-13 08:46:32.571207.571207 cuda_h.py:19] end iln_self_attn_paln cost 0.00587916374206543 seconds
DEBUG 01-13 08:46:32.571222.571222 cuda_h.py:10] start dense_mlp
INFO 01-13 08:46:32.577500.577500 client.py:127] Model loaded
DEBUG 01-13 08:46:32.577756.577756 cuda_h.py:10] start restore2model
DEBUG 01-13 08:46:32.577590.577590 cuda_h.py:19] end restore2model cost 0.0007102489471435547 seconds
DEBUG 01-13 08:46:32.578109.578109 cuda_h.py:19] end sllm_worker_task cost 0.012553215026855469 seconds
DEBUG 01-13 08:46:32.578132.578132 cuda_h.py:19] end dense_mlp cost 0.006952047348022461 seconds
DEBUG 01-13 08:46:32.578122.578122 lmp.py:1550] -------------------------------- end prefill layer 0 --------------------------------
DEBUG 01-13 08:46:32.578308.578308 lmp.py:1493] -------------------------------- start prefill layer 1 --------------------------------
DEBUG 01-13 08:46:32.578150.578150 cuda_h.py:10] start start_load_qkvogn_s_weight_l_2
DEBUG 01-13 08:46:32.578853.578853 cuda_h.py:10] start start_load_qkvogn_s_weight_l_2
DEBUG 01-13 08:46:32.578437.578437 cuda_h.py:19] end start_load_qkvogn_s_weight_l_2 cost 1.9788742065429688e-05 seconds
DEBUG 01-13 08:46:32.578140.578140 cuda_h.py:19] end start_load_qkvogn_s_weight_l_2 cost 4.9591064453125e-05 seconds
DEBUG 01-13 08:46:32.578929.578929 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-13 08:46:32.578719.578719 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-13 08:46:32.578655.578655 cuda_h.py:10] start sllm_worker_task
DEBUG 01-13 08:46:32.578743.578743 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-13 08:46:32.578044.578044 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-13 08:46:32.578166.578166 cuda_h.py:19] end allocate_cuda_memory cost 0.0002288818359375 seconds
DEBUG 01-13 08:46:32.579276.579276 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-13 08:46:32.579364.579364 sllm_store_c.py:27] get device uuid map
DEBUG 01-13 08:46:32.579320.579320 sllm_store_c.py:29] call client load into gpu
DEBUG 01-13 08:46:32.579932.579932 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, d241155d-5d50-49d4-ae17-7c4ad52a31a1
DEBUG 01-13 08:46:32.579910.579910 client.py:106] call stub.LoadModelAsync
DEBUG 01-13 08:46:32.579834.579834 cuda_h.py:10] start self_attn
INFO 01-13 08:46:32.580566.580566 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, d241155d-5d50-49d4-ae17-7c4ad52a31a1
DEBUG 01-13 08:46:32.580755.580755 cuda_h.py:19] end load_into_gpu_async cost 0.0013728141784667969 seconds
DEBUG 01-13 08:46:32.580605.580605 cuda_h.py:10] start restore_tensors2
DEBUG 01-13 08:46:32.580908.580908 cuda_h.py:19] end restore_tensors2 cost 9.298324584960938e-05 seconds
DEBUG 01-13 08:46:32.580950.580950 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0021643638610839844 seconds
INFO 01-13 08:46:32.580502.580502 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, d241155d-5d50-49d4-ae17-7c4ad52a31a1
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-13 08:46:32.582980.582980 cuda_h.py:19] end self_attn cost 0.0029201507568359375 seconds
DEBUG 01-13 08:46:32.582844.582844 cuda_h.py:19] end iln_self_attn_paln cost 0.004368305206298828 seconds
DEBUG 01-13 08:46:32.582403.582403 cuda_h.py:10] start layer_moe_generate_mp_l_2
DEBUG 01-13 08:46:32.582735.582735 cuda_h.py:10] start gate
DEBUG 01-13 08:46:32.583699.583699 cuda_h.py:19] end gate cost 0.0006773471832275391 seconds
DEBUG 01-13 08:46:32.583052.583052 cuda_h.py:10] start experts_map_get
DEBUG 01-13 08:46:32.583552.583552 lmp.py:1611] 
DEBUG 01-13 08:46:32.583552.583552 lmp.py:1611] Expert Token Distribution & Device Allocation:
DEBUG 01-13 08:46:32.583069.583069 lmp.py:1612]   Total experts: 64
DEBUG 01-13 08:46:32.583196.583196 lmp.py:1613]   CPU experts: 32 (50%)
DEBUG 01-13 08:46:32.584746.584746 lmp.py:1614]   GPU experts: 32 (50%)
DEBUG 01-13 08:46:32.584674.584674 lmp.py:1615] 
DEBUG 01-13 08:46:32.584674.584674 lmp.py:1615]   Expert ID | Tokens | Device
DEBUG 01-13 08:46:32.584079.584079 lmp.py:1616]   -----------------------------------
DEBUG 01-13 08:46:32.584728.584728 lmp.py:1622]   Expert 25 |     64 | CPU
DEBUG 01-13 08:46:32.584418.584418 lmp.py:1622]   Expert 54 |     67 | CPU
DEBUG 01-13 08:46:32.584630.584630 lmp.py:1622]   Expert  3 |     68 | CPU
DEBUG 01-13 08:46:32.584366.584366 lmp.py:1622]   Expert 31 |     72 | CPU
DEBUG 01-13 08:46:32.584863.584863 lmp.py:1622]   Expert 55 |     72 | CPU
DEBUG 01-13 08:46:32.584599.584599 lmp.py:1622]   Expert 62 |     87 | CPU
DEBUG 01-13 08:46:32.584334.584334 lmp.py:1622]   Expert 18 |     88 | CPU
DEBUG 01-13 08:46:32.584262.584262 lmp.py:1622]   Expert 52 |     98 | CPU
DEBUG 01-13 08:46:32.584236.584236 lmp.py:1622]   Expert 22 |    100 | CPU
DEBUG 01-13 08:46:32.584448.584448 lmp.py:1622]   Expert 47 |    104 | CPU
DEBUG 01-13 08:46:32.584615.584615 lmp.py:1622]   Expert  0 |    113 | CPU
DEBUG 01-13 08:46:32.584112.584112 lmp.py:1622]   Expert 37 |    117 | CPU
DEBUG 01-13 08:46:32.584371.584371 lmp.py:1622]   Expert 27 |    121 | CPU
DEBUG 01-13 08:46:32.584537.584537 lmp.py:1622]   Expert 32 |    123 | CPU
DEBUG 01-13 08:46:32.584226.584226 lmp.py:1622]   Expert 41 |    130 | CPU
DEBUG 01-13 08:46:32.584677.584677 lmp.py:1622]   Expert 44 |    131 | CPU
DEBUG 01-13 08:46:32.584128.584128 lmp.py:1622]   Expert 28 |    136 | CPU
DEBUG 01-13 08:46:32.584817.584817 lmp.py:1622]   Expert 13 |    138 | CPU
DEBUG 01-13 08:46:32.584268.584268 lmp.py:1622]   Expert 58 |    140 | CPU
DEBUG 01-13 08:46:32.584719.584719 lmp.py:1622]   Expert 60 |    144 | CPU
DEBUG 01-13 08:46:32.584621.584621 lmp.py:1622]   Expert 43 |    147 | CPU
DEBUG 01-13 08:46:32.584071.584071 lmp.py:1622]   Expert  1 |    150 | CPU
DEBUG 01-13 08:46:32.584761.584761 lmp.py:1622]   Expert 38 |    153 | CPU
DEBUG 01-13 08:46:32.584994.584994 lmp.py:1622]   Expert 49 |    154 | CPU
DEBUG 01-13 08:46:32.584637.584637 lmp.py:1622]   Expert 51 |    155 | CPU
DEBUG 01-13 08:46:32.584372.584372 lmp.py:1622]   Expert 34 |    161 | CPU
DEBUG 01-13 08:46:32.584108.584108 lmp.py:1622]   Expert 35 |    164 | CPU
DEBUG 01-13 08:46:32.584367.584367 lmp.py:1622]   Expert 36 |    168 | CPU
DEBUG 01-13 08:46:32.584864.584864 lmp.py:1622]   Expert 11 |    170 | CPU
DEBUG 01-13 08:46:32.584123.584123 lmp.py:1622]   Expert 17 |    170 | CPU
DEBUG 01-13 08:46:32.584858.584858 lmp.py:1622]   Expert 59 |    174 | CPU
DEBUG 01-13 08:46:32.584117.584117 lmp.py:1622]   Expert 10 |    180 | CPU
DEBUG 01-13 08:46:32.584091.584091 lmp.py:1622]   Expert 20 |    182 | GPU
DEBUG 01-13 08:46:32.584588.584588 lmp.py:1622]   Expert  2 |    186 | GPU
DEBUG 01-13 08:46:32.584562.584562 lmp.py:1622]   Expert 39 |    189 | GPU
DEBUG 01-13 08:46:32.584298.584298 lmp.py:1622]   Expert 33 |    197 | GPU
DEBUG 01-13 08:46:32.584795.584795 lmp.py:1622]   Expert 12 |    198 | GPU
DEBUG 01-13 08:46:32.584054.584054 lmp.py:1622]   Expert 21 |    198 | GPU
DEBUG 01-13 08:46:32.584790.584790 lmp.py:1622]   Expert 48 |    198 | GPU
DEBUG 01-13 08:46:32.584048.584048 lmp.py:1622]   Expert 15 |    199 | GPU
DEBUG 01-13 08:46:32.584261.584261 lmp.py:1622]   Expert 53 |    204 | GPU
DEBUG 01-13 08:46:32.584520.584520 lmp.py:1622]   Expert 19 |    220 | GPU
DEBUG 01-13 08:46:32.584209.584209 lmp.py:1622]   Expert 26 |    221 | GPU
DEBUG 01-13 08:46:32.584898.584898 lmp.py:1622]   Expert 30 |    221 | GPU
DEBUG 01-13 08:46:32.584634.584634 lmp.py:1622]   Expert 45 |    221 | GPU
DEBUG 01-13 08:46:32.584369.584369 lmp.py:1622]   Expert  5 |    227 | GPU
DEBUG 01-13 08:46:32.584105.584105 lmp.py:1622]   Expert  4 |    229 | GPU
DEBUG 01-13 08:46:32.584602.584602 lmp.py:1622]   Expert 24 |    229 | GPU
DEBUG 01-13 08:46:32.584861.584861 lmp.py:1622]   Expert 42 |    242 | GPU
DEBUG 01-13 08:46:32.584358.584358 lmp.py:1622]   Expert 50 |    245 | GPU
DEBUG 01-13 08:46:32.584617.584617 lmp.py:1622]   Expert 29 |    254 | GPU
DEBUG 01-13 08:46:32.584876.584876 lmp.py:1622]   Expert 56 |    262 | GPU
DEBUG 01-13 08:46:32.584373.584373 lmp.py:1622]   Expert 61 |    270 | GPU
DEBUG 01-13 08:46:32.584632.584632 lmp.py:1622]   Expert  8 |    283 | GPU
DEBUG 01-13 08:46:32.584129.584129 lmp.py:1622]   Expert 63 |    285 | GPU
DEBUG 01-13 08:46:32.584626.584626 lmp.py:1622]   Expert 46 |    294 | GPU
DEBUG 01-13 08:46:32.584124.584124 lmp.py:1622]   Expert  9 |    300 | GPU
DEBUG 01-13 08:46:32.585382.585382 lmp.py:1622]   Expert  6 |    316 | GPU
DEBUG 01-13 08:46:32.585641.585641 lmp.py:1622]   Expert 16 |    316 | GPU
DEBUG 01-13 08:46:32.585615.585615 lmp.py:1622]   Expert 40 |    319 | GPU
DEBUG 01-13 08:46:32.585066.585066 lmp.py:1622]   Expert  7 |    322 | GPU
DEBUG 01-13 08:46:32.585994.585994 lmp.py:1622]   Expert 23 |    325 | GPU
DEBUG 01-13 08:46:32.585445.585445 lmp.py:1622]   Expert 14 |    413 | GPU
DEBUG 01-13 08:46:32.585372.585372 lmp.py:1622]   Expert 57 |    464 | GPU
DEBUG 01-13 08:46:32.585300.585300 lmp.py:1623] 
DEBUG 01-13 08:46:32.585300.585300 lmp.py:1623]   CPU total tokens: 4059 (33.0%)
DEBUG 01-13 08:46:32.585466.585466 lmp.py:1624]   GPU total tokens: 8229 (67.0%)
DEBUG 01-13 08:46:32.585924.585924 cuda_h.py:19] end experts_map_get cost 0.0014925003051757812 seconds
DEBUG 01-13 08:46:32.585542.585542 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-13 08:46:32.585775.585775 lmp.py:1632] 
DEBUG 01-13 08:46:32.585775.585775 lmp.py:1632]   Computing 32 experts on CPU MP...
DEBUG 01-13 08:46:32.585035.585035 cuda_h.py:19] end cpu_experts_submit cost 5.340576171875e-05 seconds
DEBUG 01-13 08:46:32.585539.585539 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-13 08:46:32.585130.585130 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-13 08:46:32.585492.585492 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-13 08:46:32.586378.586378 cuda_h.py:19] end allocate_cuda_memory cost 0.0013227462768554688 seconds
DEBUG 01-13 08:46:32.586765.586765 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-13 08:46:32.586402.586402 sllm_store_c.py:27] get device uuid map
DEBUG 01-13 08:46:32.587258.587258 sllm_store_c.py:29] call client load into gpu
DEBUG 01-13 08:46:32.587861.587861 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 5bc23b13-ecd7-4c9d-80f2-0fd198d17edb
DEBUG 01-13 08:46:32.587883.587883 client.py:106] call stub.LoadModelAsync
DEBUG 01-13 08:46:32.588458.588458 cuda_h.py:10] start experts_func_gpu_einsum_mp
INFO 01-13 08:46:32.588520.588520 client.py:127] Model loaded
DEBUG 01-13 08:46:32.588264.588264 cuda_h.py:10] start restore2model
DEBUG 01-13 08:46:32.589948.589948 cuda_h.py:19] end restore2model cost 0.0009603500366210938 seconds
DEBUG 01-13 08:46:32.589355.589355 cuda_h.py:19] end sllm_worker_task cost 0.011158943176269531 seconds
INFO 01-13 08:46:32.590261.590261 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 5bc23b13-ecd7-4c9d-80f2-0fd198d17edb
DEBUG 01-13 08:46:32.590032.590032 cuda_h.py:19] end load_into_gpu_async cost 0.003341197967529297 seconds
DEBUG 01-13 08:46:32.590850.590850 cuda_h.py:10] start restore_tensors2
DEBUG 01-13 08:46:32.592462.592462 cuda_h.py:19] end restore_tensors2 cost 0.0015232563018798828 seconds
DEBUG 01-13 08:46:32.592503.592503 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.006941080093383789 seconds
DEBUG 01-13 08:46:32.592664.592664 cuda_h.py:10] start restore2model
DEBUG 01-13 08:46:32.595397.595397 mlpmodule.py:1006] group tensors cost 0.006054401397705078 s
DEBUG 01-13 08:46:32.598347.598347 mlpmodule.py:1044] pad cost 0.0025823116302490234 s
DEBUG 01-13 08:46:32.598259.598259 mlpmodule.py:1050] create cpu tensor cost 6.246566772460938e-05 s
DEBUG 01-13 08:46:32.598302.598302 mlpmodule.py:1055] move to cpu cost 4.3392181396484375e-05 s
DEBUG 01-13 08:46:32.601112.601112 cuda_h.py:19] end restore2model cost 0.008726119995117188 seconds
DEBUG 01-13 08:46:32.601441.601441 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.016231298446655273 seconds
DEBUG 01-13 08:46:32.601296.601296 cuda_h.py:10] start gpu_sexperts
DEBUG 01-13 08:46:32.602399.602399 cuda_h.py:19] end gpu_sexperts cost 0.0006663799285888672 seconds
DEBUG 01-13 08:46:32.602508.602508 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-13 08:46:32.602987.602987 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 3.337860107421875e-05 seconds
DEBUG 01-13 08:46:32.602181.602181 cuda_h.py:10] start wait_experts
INFO 01-13 08:46:32.602997.602997 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 5bc23b13-ecd7-4c9d-80f2-0fd198d17edb
DEBUG 01-13 08:46:32.607734.607734 mlpmodule.py:1069] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-13 08:46:32.607773.607773 mlpmodule.py:1070] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-13 08:46:32.607816.607816 mlpmodule.py:1075] group_w3 first element: -0.0107421875
WARNING 01-13 08:46:32.607932.607932 mlpmodule.py:1085] start einsum2
DEBUG 01-13 08:46:32.620561.620561 mlpmodule.py:1095] group einsum cost 0.02194690704345703 s
DEBUG 01-13 08:46:32.621310.621310 mlpmodule.py:1103] cpy2cputensor cost 0.0007212162017822266 s
INFO 01-13 08:46:32.639006.639006 client.py:127] Model loaded
DEBUG 01-13 08:46:32.639151.639151 cuda_h.py:19] end wait_experts cost 0.03742671012878418 seconds
DEBUG 01-13 08:46:32.640544.640544 cuda_h.py:10] start gpu_experts
DEBUG 01-13 08:46:32.642890.642890 mlpmodule.py:559] gpu group tensors cost 0.002615690231323242 s
DEBUG 01-13 08:46:32.647035.647035 mlpmodule.py:592] gpu pad cost 0.004760265350341797 s
DEBUG 01-13 08:46:32.647093.647093 mlpmodule.py:598] start_w1
DEBUG 01-13 08:46:32.648944.648944 mlpmodule.py:602] start_w3
DEBUG 01-13 08:46:32.648591.648591 mlpmodule.py:785]  experts func einsum cost 0.05972766876220703 s
DEBUG 01-13 08:46:32.649695.649695 mlpmodule.py:608] start_w2
DEBUG 01-13 08:46:32.649342.649342 cuda_h.py:19] end experts_func_gpu_einsum_mp cost 0.061277151107788086 seconds
DEBUG 01-13 08:46:32.650110.650110 mlpmodule.py:611] gpu group einsum cost 0.002289295196533203 s
DEBUG 01-13 08:46:32.653390.653390 mlpmodule.py:683] gpu experts func einsum cost 0.013608455657958984 s
DEBUG 01-13 08:46:32.653725.653725 cuda_h.py:19] end gpu_experts cost 0.01382303237915039 seconds
DEBUG 01-13 08:46:32.654348.654348 cuda_h.py:10] start cpu_thread_manager_mp_wait
DEBUG 01-13 08:46:32.654769.654769 cuda_h.py:19] end cpu_thread_manager_mp_wait cost 5.888938903808594e-05 seconds
DEBUG 01-13 08:46:32.654104.654104 cuda_h.py:19] end layer_moe_generate_mp_l_2 cost 0.07133960723876953 seconds
DEBUG 01-13 08:46:32.654943.654943 lmp.py:1550] -------------------------------- end prefill layer 1 --------------------------------
DEBUG 01-13 08:46:32.654925.654925 lmp.py:1493] -------------------------------- start prefill layer 2 --------------------------------
DEBUG 01-13 08:46:32.654065.654065 cuda_h.py:10] start start_load_qkvogn_s_weight_l_3
DEBUG 01-13 08:46:32.654212.654212 cuda_h.py:10] start start_load_qkvogn_s_weight_l_3
DEBUG 01-13 08:46:32.654082.654082 cuda_h.py:19] end start_load_qkvogn_s_weight_l_3 cost 4.76837158203125e-05 seconds
DEBUG 01-13 08:46:32.654368.654368 cuda_h.py:19] end start_load_qkvogn_s_weight_l_3 cost 8.654594421386719e-05 seconds
DEBUG 01-13 08:46:32.654210.654210 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-13 08:46:32.654632.654632 cuda_h.py:10] start sllm_worker_task
DEBUG 01-13 08:46:32.655218.655218 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-13 08:46:32.655798.655798 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-13 08:46:32.655388.655388 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-13 08:46:32.655420.655420 cuda_h.py:19] end allocate_cuda_memory cost 0.0003097057342529297 seconds
DEBUG 01-13 08:46:32.656397.656397 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-13 08:46:32.656888.656888 sllm_store_c.py:27] get device uuid map
DEBUG 01-13 08:46:32.656069.656069 sllm_store_c.py:29] call client load into gpu
DEBUG 01-13 08:46:32.656408.656408 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, dcaf355c-7550-47e0-afae-76554bc2eaf5
DEBUG 01-13 08:46:32.656817.656817 client.py:106] call stub.LoadModelAsync
DEBUG 01-13 08:46:32.656023.656023 cuda_h.py:10] start self_attn
INFO 01-13 08:46:32.658722.658722 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, dcaf355c-7550-47e0-afae-76554bc2eaf5
DEBUG 01-13 08:46:32.658050.658050 cuda_h.py:19] end load_into_gpu_async cost 0.0020465850830078125 seconds
DEBUG 01-13 08:46:32.658773.658773 cuda_h.py:10] start restore_tensors2
DEBUG 01-13 08:46:32.658877.658877 cuda_h.py:19] end restore_tensors2 cost 0.00011038780212402344 seconds
DEBUG 01-13 08:46:32.658885.658885 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0028307437896728516 seconds
INFO 01-13 08:46:32.658537.658537 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, dcaf355c-7550-47e0-afae-76554bc2eaf5
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-13 08:46:32.660972.660972 cuda_h.py:19] end self_attn cost 0.004106998443603516 seconds
DEBUG 01-13 08:46:32.661515.661515 cuda_h.py:19] end iln_self_attn_paln cost 0.006510257720947266 seconds
DEBUG 01-13 08:46:32.661187.661187 cuda_h.py:10] start layer_moe_generate_mp_l_3
DEBUG 01-13 08:46:32.661162.661162 cuda_h.py:10] start gate
DEBUG 01-13 08:46:32.662391.662391 cuda_h.py:19] end gate cost 0.0008709430694580078 seconds
DEBUG 01-13 08:46:32.662512.662512 cuda_h.py:10] start experts_map_get
DEBUG 01-13 08:46:32.662392.662392 lmp.py:1611] 
DEBUG 01-13 08:46:32.662392.662392 lmp.py:1611] Expert Token Distribution & Device Allocation:
DEBUG 01-13 08:46:32.662294.662294 lmp.py:1612]   Total experts: 64
DEBUG 01-13 08:46:32.662182.662182 lmp.py:1613]   CPU experts: 32 (50%)
DEBUG 01-13 08:46:32.662447.662447 lmp.py:1614]   GPU experts: 32 (50%)
DEBUG 01-13 08:46:32.662329.662329 lmp.py:1615] 
DEBUG 01-13 08:46:32.662329.662329 lmp.py:1615]   Expert ID | Tokens | Device
DEBUG 01-13 08:46:32.662886.662886 lmp.py:1616]   -----------------------------------
DEBUG 01-13 08:46:32.662781.662781 lmp.py:1622]   Expert 58 |     50 | CPU
DEBUG 01-13 08:46:32.662285.662285 lmp.py:1622]   Expert 27 |     58 | CPU
DEBUG 01-13 08:46:32.663597.663597 lmp.py:1622]   Expert  3 |     70 | CPU
DEBUG 01-13 08:46:32.663670.663670 lmp.py:1622]   Expert 17 |     79 | CPU
DEBUG 01-13 08:46:32.663744.663744 lmp.py:1622]   Expert 24 |     86 | CPU
DEBUG 01-13 08:46:32.663155.663155 lmp.py:1622]   Expert  0 |     91 | CPU
DEBUG 01-13 08:46:32.663467.663467 lmp.py:1622]   Expert 28 |    102 | CPU
DEBUG 01-13 08:46:32.663064.663064 lmp.py:1622]   Expert 34 |    115 | CPU
DEBUG 01-13 08:46:32.663376.663376 lmp.py:1622]   Expert 51 |    118 | CPU
DEBUG 01-13 08:46:32.663734.663734 lmp.py:1622]   Expert  9 |    122 | CPU
DEBUG 01-13 08:46:32.663092.663092 lmp.py:1622]   Expert 32 |    122 | CPU
DEBUG 01-13 08:46:32.663881.663881 lmp.py:1622]   Expert 15 |    132 | CPU
DEBUG 01-13 08:46:32.663669.663669 lmp.py:1622]   Expert  7 |    133 | CPU
DEBUG 01-13 08:46:32.663935.663935 lmp.py:1622]   Expert 23 |    135 | CPU
DEBUG 01-13 08:46:32.663300.663300 lmp.py:1622]   Expert 26 |    136 | CPU
DEBUG 01-13 08:46:32.663135.663135 lmp.py:1622]   Expert 45 |    146 | CPU
DEBUG 01-13 08:46:32.663732.663732 lmp.py:1622]   Expert 30 |    147 | CPU
DEBUG 01-13 08:46:32.663090.663090 lmp.py:1622]   Expert  1 |    148 | CPU
DEBUG 01-13 08:46:32.663687.663687 lmp.py:1622]   Expert 62 |    149 | CPU
DEBUG 01-13 08:46:32.663806.663806 lmp.py:1622]   Expert 57 |    151 | CPU
DEBUG 01-13 08:46:32.663165.663165 lmp.py:1622]   Expert 29 |    159 | CPU
DEBUG 01-13 08:46:32.663761.663761 lmp.py:1622]   Expert  8 |    160 | CPU
DEBUG 01-13 08:46:32.663358.663358 lmp.py:1622]   Expert 36 |    160 | CPU
DEBUG 01-13 08:46:32.663955.663955 lmp.py:1622]   Expert 25 |    165 | CPU
DEBUG 01-13 08:46:32.663790.663790 lmp.py:1622]   Expert  6 |    170 | CPU
DEBUG 01-13 08:46:32.663863.663863 lmp.py:1622]   Expert 49 |    172 | CPU
DEBUG 01-13 08:46:32.663175.663175 lmp.py:1622]   Expert 35 |    173 | CPU
DEBUG 01-13 08:46:32.663110.663110 lmp.py:1622]   Expert 37 |    174 | CPU
DEBUG 01-13 08:46:32.663183.663183 lmp.py:1622]   Expert 54 |    177 | CPU
DEBUG 01-13 08:46:32.663541.663541 lmp.py:1622]   Expert 12 |    180 | CPU
DEBUG 01-13 08:46:32.663423.663423 lmp.py:1622]   Expert 48 |    181 | CPU
DEBUG 01-13 08:46:32.663543.663543 lmp.py:1622]   Expert 13 |    184 | CPU
DEBUG 01-13 08:46:32.663139.663139 lmp.py:1622]   Expert 53 |    187 | GPU
DEBUG 01-13 08:46:32.663497.663497 lmp.py:1622]   Expert 33 |    190 | GPU
DEBUG 01-13 08:46:32.663856.663856 lmp.py:1622]   Expert 10 |    192 | GPU
DEBUG 01-13 08:46:32.663168.663168 lmp.py:1622]   Expert 60 |    195 | GPU
DEBUG 01-13 08:46:32.663433.663433 lmp.py:1622]   Expert 21 |    196 | GPU
DEBUG 01-13 08:46:32.663745.663745 lmp.py:1622]   Expert 16 |    197 | GPU
DEBUG 01-13 08:46:32.663918.663918 lmp.py:1622]   Expert 40 |    198 | GPU
DEBUG 01-13 08:46:32.663276.663276 lmp.py:1622]   Expert 38 |    202 | GPU
DEBUG 01-13 08:46:32.663634.663634 lmp.py:1622]   Expert 43 |    205 | GPU
DEBUG 01-13 08:46:32.663516.663516 lmp.py:1622]   Expert  5 |    207 | GPU
DEBUG 01-13 08:46:32.663874.663874 lmp.py:1622]   Expert 44 |    213 | GPU
DEBUG 01-13 08:46:32.663232.663232 lmp.py:1622]   Expert 52 |    214 | GPU
DEBUG 01-13 08:46:32.663352.663352 lmp.py:1622]   Expert 59 |    216 | GPU
DEBUG 01-13 08:46:32.663233.663233 lmp.py:1622]   Expert 19 |    218 | GPU
DEBUG 01-13 08:46:32.663830.663830 lmp.py:1622]   Expert 50 |    218 | GPU
DEBUG 01-13 08:46:32.663904.663904 lmp.py:1622]   Expert  4 |    220 | GPU
DEBUG 01-13 08:46:32.663977.663977 lmp.py:1622]   Expert 41 |    224 | GPU
DEBUG 01-13 08:46:32.663812.663812 lmp.py:1622]   Expert 55 |    235 | GPU
DEBUG 01-13 08:46:32.663270.663270 lmp.py:1622]   Expert 56 |    241 | GPU
DEBUG 01-13 08:46:32.663390.663390 lmp.py:1622]   Expert 31 |    245 | GPU
DEBUG 01-13 08:46:32.663748.663748 lmp.py:1622]   Expert 39 |    254 | GPU
DEBUG 01-13 08:46:32.663629.663629 lmp.py:1622]   Expert 20 |    255 | GPU
DEBUG 01-13 08:46:32.664749.664749 lmp.py:1622]   Expert  2 |    263 | GPU
DEBUG 01-13 08:46:32.664869.664869 lmp.py:1622]   Expert 22 |    263 | GPU
DEBUG 01-13 08:46:32.664227.664227 lmp.py:1622]   Expert 63 |    274 | GPU
DEBUG 01-13 08:46:32.664585.664585 lmp.py:1622]   Expert 47 |    276 | GPU
DEBUG 01-13 08:46:32.664944.664944 lmp.py:1622]   Expert 42 |    303 | GPU
DEBUG 01-13 08:46:32.664779.664779 lmp.py:1622]   Expert 18 |    307 | GPU
DEBUG 01-13 08:46:32.664614.664614 lmp.py:1622]   Expert 14 |    314 | GPU
DEBUG 01-13 08:46:32.664164.664164 lmp.py:1622]   Expert 46 |    369 | GPU
DEBUG 01-13 08:46:32.664906.664906 lmp.py:1622]   Expert 11 |    392 | GPU
DEBUG 01-13 08:46:32.664265.664265 lmp.py:1622]   Expert 61 |    460 | GPU
DEBUG 01-13 08:46:32.664053.664053 lmp.py:1623] 
DEBUG 01-13 08:46:32.664053.664053 lmp.py:1623]   CPU total tokens: 4345 (35.4%)
DEBUG 01-13 08:46:32.664842.664842 lmp.py:1624]   GPU total tokens: 7943 (64.6%)
DEBUG 01-13 08:46:32.664922.664922 cuda_h.py:19] end experts_map_get cost 0.0017485618591308594 seconds
DEBUG 01-13 08:46:32.664395.664395 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-13 08:46:32.664966.664966 lmp.py:1632] 
DEBUG 01-13 08:46:32.664966.664966 lmp.py:1632]   Computing 32 experts on CPU MP...
DEBUG 01-13 08:46:32.664630.664630 cuda_h.py:19] end cpu_experts_submit cost 7.104873657226562e-05 seconds
DEBUG 01-13 08:46:32.664803.664803 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-13 08:46:32.664600.664600 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-13 08:46:32.664674.664674 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-13 08:46:32.665765.665765 cuda_h.py:19] end allocate_cuda_memory cost 0.0003108978271484375 seconds
DEBUG 01-13 08:46:32.665906.665906 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-13 08:46:32.665907.665907 sllm_store_c.py:27] get device uuid map
DEBUG 01-13 08:46:32.665744.665744 sllm_store_c.py:29] call client load into gpu
DEBUG 01-13 08:46:32.665354.665354 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 6d4b62b0-5bd2-4eae-9ba2-7f2c0ac51bd2
DEBUG 01-13 08:46:32.665303.665303 client.py:106] call stub.LoadModelAsync
INFO 01-13 08:46:32.666438.666438 client.py:127] Model loaded
DEBUG 01-13 08:46:32.666971.666971 cuda_h.py:10] start restore2model
DEBUG 01-13 08:46:32.667473.667473 cuda_h.py:19] end restore2model cost 0.0004913806915283203 seconds
DEBUG 01-13 08:46:32.667024.667024 cuda_h.py:19] end sllm_worker_task cost 0.011755704879760742 seconds
INFO 01-13 08:46:32.667306.667306 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 6d4b62b0-5bd2-4eae-9ba2-7f2c0ac51bd2
DEBUG 01-13 08:46:32.667276.667276 cuda_h.py:19] end load_into_gpu_async cost 0.002306222915649414 seconds
DEBUG 01-13 08:46:32.667555.667555 cuda_h.py:10] start restore_tensors2
DEBUG 01-13 08:46:32.667520.667520 cuda_h.py:10] start experts_func_gpu_einsum_mp
DEBUG 01-13 08:46:32.668831.668831 cuda_h.py:19] end restore_tensors2 cost 0.0004863739013671875 seconds
DEBUG 01-13 08:46:32.668741.668741 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0035858154296875 seconds
DEBUG 01-13 08:46:32.668054.668054 cuda_h.py:10] start restore2model
DEBUG 01-13 08:46:32.671523.671523 cuda_h.py:19] end restore2model cost 0.002912759780883789 seconds
DEBUG 01-13 08:46:32.671493.671493 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.006737232208251953 seconds
DEBUG 01-13 08:46:32.671812.671812 cuda_h.py:10] start gpu_sexperts
DEBUG 01-13 08:46:32.671850.671850 cuda_h.py:19] end gpu_sexperts cost 0.0003135204315185547 seconds
DEBUG 01-13 08:46:32.671825.671825 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-13 08:46:32.671462.671462 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 1.8835067749023438e-05 seconds
DEBUG 01-13 08:46:32.671589.671589 cuda_h.py:10] start wait_experts
INFO 01-13 08:46:32.671100.671100 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 6d4b62b0-5bd2-4eae-9ba2-7f2c0ac51bd2
DEBUG 01-13 08:46:32.676414.676414 mlpmodule.py:1006] group tensors cost 0.007969856262207031 s
DEBUG 01-13 08:46:32.680851.680851 mlpmodule.py:1044] pad cost 0.0034155845642089844 s
DEBUG 01-13 08:46:32.680095.680095 mlpmodule.py:1050] create cpu tensor cost 9.393692016601562e-05 s
DEBUG 01-13 08:46:32.681663.681663 mlpmodule.py:1055] move to cpu cost 7.390975952148438e-05 s
DEBUG 01-13 08:46:32.691797.691797 mlpmodule.py:1069] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-13 08:46:32.691009.691009 mlpmodule.py:1070] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-13 08:46:32.691530.691530 mlpmodule.py:1075] group_w3 first element: -0.0380859375
WARNING 01-13 08:46:32.691452.691452 mlpmodule.py:1085] start einsum2
DEBUG 01-13 08:46:32.707510.707510 mlpmodule.py:1095] group einsum cost 0.02618408203125 s
DEBUG 01-13 08:46:32.708138.708138 mlpmodule.py:1103] cpy2cputensor cost 0.0007271766662597656 s
INFO 01-13 08:46:32.720238.720238 client.py:127] Model loaded
DEBUG 01-13 08:46:32.720140.720140 cuda_h.py:19] end wait_experts cost 0.049048662185668945 seconds
DEBUG 01-13 08:46:32.720647.720647 cuda_h.py:10] start gpu_experts
DEBUG 01-13 08:46:32.722672.722672 mlpmodule.py:559] gpu group tensors cost 0.001537322998046875 s
DEBUG 01-13 08:46:32.727325.727325 mlpmodule.py:592] gpu pad cost 0.0043413639068603516 s
DEBUG 01-13 08:46:32.727874.727874 mlpmodule.py:598] start_w1
DEBUG 01-13 08:46:32.727348.727348 mlpmodule.py:602] start_w3
DEBUG 01-13 08:46:32.728283.728283 mlpmodule.py:608] start_w2
DEBUG 01-13 08:46:32.728338.728338 mlpmodule.py:611] gpu group einsum cost 0.0016045570373535156 s
DEBUG 01-13 08:46:32.732643.732643 mlpmodule.py:785]  experts func einsum cost 0.06390762329101562 s
DEBUG 01-13 08:46:32.732115.732115 cuda_h.py:19] end experts_func_gpu_einsum_mp cost 0.06511044502258301 seconds
DEBUG 01-13 08:46:32.733606.733606 mlpmodule.py:683] gpu experts func einsum cost 0.012631654739379883 s
DEBUG 01-13 08:46:32.733777.733777 cuda_h.py:19] end gpu_experts cost 0.012911081314086914 seconds
DEBUG 01-13 08:46:32.733408.733408 cuda_h.py:10] start cpu_thread_manager_mp_wait
DEBUG 01-13 08:46:32.734497.734497 cuda_h.py:19] end cpu_thread_manager_mp_wait cost 6.079673767089844e-05 seconds
DEBUG 01-13 08:46:32.734640.734640 cuda_h.py:19] end layer_moe_generate_mp_l_3 cost 0.07261466979980469 seconds
DEBUG 01-13 08:46:32.734619.734619 lmp.py:1550] -------------------------------- end prefill layer 2 --------------------------------
DEBUG 01-13 08:46:32.734654.734654 lmp.py:1493] -------------------------------- start prefill layer 3 --------------------------------
DEBUG 01-13 08:46:32.734417.734417 cuda_h.py:10] start start_load_qkvogn_s_weight_l_4
DEBUG 01-13 08:46:32.734617.734617 cuda_h.py:10] start start_load_qkvogn_s_weight_l_4
DEBUG 01-13 08:46:32.734494.734494 cuda_h.py:19] end start_load_qkvogn_s_weight_l_4 cost 5.078315734863281e-05 seconds
DEBUG 01-13 08:46:32.734780.734780 cuda_h.py:19] end start_load_qkvogn_s_weight_l_4 cost 8.940696716308594e-05 seconds
DEBUG 01-13 08:46:32.734575.734575 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-13 08:46:32.734044.734044 cuda_h.py:10] start sllm_worker_task
DEBUG 01-13 08:46:32.735523.735523 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-13 08:46:32.735209.735209 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-13 08:46:32.735635.735635 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-13 08:46:32.735953.735953 cuda_h.py:19] end allocate_cuda_memory cost 0.0003485679626464844 seconds
DEBUG 01-13 08:46:32.736645.736645 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-13 08:46:32.736706.736706 sllm_store_c.py:27] get device uuid map
DEBUG 01-13 08:46:32.736979.736979 sllm_store_c.py:29] call client load into gpu
DEBUG 01-13 08:46:32.736650.736650 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 93fa9cae-2123-4dba-b159-69a2eb9b15cf
DEBUG 01-13 08:46:32.736667.736667 client.py:106] call stub.LoadModelAsync
DEBUG 01-13 08:46:32.736251.736251 cuda_h.py:10] start self_attn
INFO 01-13 08:46:32.737868.737868 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 93fa9cae-2123-4dba-b159-69a2eb9b15cf
DEBUG 01-13 08:46:32.738666.738666 cuda_h.py:19] end load_into_gpu_async cost 0.001969575881958008 seconds
DEBUG 01-13 08:46:32.738051.738051 cuda_h.py:10] start restore_tensors2
DEBUG 01-13 08:46:32.738096.738096 cuda_h.py:19] end restore_tensors2 cost 9.918212890625e-05 seconds
DEBUG 01-13 08:46:32.738104.738104 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0027723312377929688 seconds
INFO 01-13 08:46:32.738782.738782 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 93fa9cae-2123-4dba-b159-69a2eb9b15cf
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-13 08:46:32.741831.741831 cuda_h.py:19] end self_attn cost 0.004364013671875 seconds
DEBUG 01-13 08:46:32.741110.741110 cuda_h.py:19] end iln_self_attn_paln cost 0.006815433502197266 seconds
DEBUG 01-13 08:46:32.741556.741556 cuda_h.py:10] start layer_moe_generate_mp_l_4
DEBUG 01-13 08:46:32.741717.741717 cuda_h.py:10] start gate
DEBUG 01-13 08:46:32.742712.742712 cuda_h.py:19] end gate cost 0.0007905960083007812 seconds
DEBUG 01-13 08:46:32.742409.742409 cuda_h.py:10] start experts_map_get
DEBUG 01-13 08:46:32.742209.742209 lmp.py:1611] 
DEBUG 01-13 08:46:32.742209.742209 lmp.py:1611] Expert Token Distribution & Device Allocation:
DEBUG 01-13 08:46:32.743826.743826 lmp.py:1612]   Total experts: 64
DEBUG 01-13 08:46:32.743575.743575 lmp.py:1613]   CPU experts: 32 (50%)
DEBUG 01-13 08:46:32.743271.743271 lmp.py:1614]   GPU experts: 32 (50%)
DEBUG 01-13 08:46:32.743013.743013 lmp.py:1615] 
DEBUG 01-13 08:46:32.743013.743013 lmp.py:1615]   Expert ID | Tokens | Device
DEBUG 01-13 08:46:32.743709.743709 lmp.py:1616]   -----------------------------------
DEBUG 01-13 08:46:32.743651.743651 lmp.py:1622]   Expert  1 |     45 | CPU
DEBUG 01-13 08:46:32.743393.743393 lmp.py:1622]   Expert 27 |     60 | CPU
DEBUG 01-13 08:46:32.743705.743705 lmp.py:1622]   Expert 48 |     79 | CPU
DEBUG 01-13 08:46:32.743778.743778 lmp.py:1622]   Expert  7 |     84 | CPU
DEBUG 01-13 08:46:32.743567.743567 lmp.py:1622]   Expert 15 |    101 | CPU
DEBUG 01-13 08:46:32.743641.743641 lmp.py:1622]   Expert 30 |    106 | CPU
DEBUG 01-13 08:46:32.743953.743953 lmp.py:1622]   Expert 61 |    109 | CPU
DEBUG 01-13 08:46:32.743788.743788 lmp.py:1622]   Expert 32 |    116 | CPU
DEBUG 01-13 08:46:32.743338.743338 lmp.py:1622]   Expert 18 |    118 | CPU
DEBUG 01-13 08:46:32.743411.743411 lmp.py:1622]   Expert 45 |    120 | CPU
DEBUG 01-13 08:46:32.743962.743962 lmp.py:1622]   Expert 34 |    132 | CPU
DEBUG 01-13 08:46:32.743320.743320 lmp.py:1622]   Expert  5 |    134 | CPU
DEBUG 01-13 08:46:32.743394.743394 lmp.py:1622]   Expert 11 |    136 | CPU
DEBUG 01-13 08:46:32.743752.743752 lmp.py:1622]   Expert 36 |    137 | CPU
DEBUG 01-13 08:46:32.743348.743348 lmp.py:1622]   Expert 26 |    138 | CPU
DEBUG 01-13 08:46:32.743945.743945 lmp.py:1622]   Expert 39 |    140 | CPU
DEBUG 01-13 08:46:32.743303.743303 lmp.py:1622]   Expert  6 |    141 | CPU
DEBUG 01-13 08:46:32.743138.743138 lmp.py:1622]   Expert 59 |    146 | CPU
DEBUG 01-13 08:46:32.743973.743973 lmp.py:1622]   Expert 23 |    154 | CPU
DEBUG 01-13 08:46:32.743285.743285 lmp.py:1622]   Expert 51 |    154 | CPU
DEBUG 01-13 08:46:32.743312.743312 lmp.py:1622]   Expert  2 |    160 | CPU
DEBUG 01-13 08:46:32.743340.743340 lmp.py:1622]   Expert 49 |    161 | CPU
DEBUG 01-13 08:46:32.743413.743413 lmp.py:1622]   Expert  9 |    162 | CPU
DEBUG 01-13 08:46:32.743771.743771 lmp.py:1622]   Expert 56 |    166 | CPU
DEBUG 01-13 08:46:32.743130.743130 lmp.py:1622]   Expert 50 |    168 | CPU
DEBUG 01-13 08:46:32.743965.743965 lmp.py:1622]   Expert 52 |    169 | CPU
DEBUG 01-13 08:46:32.743561.743561 lmp.py:1622]   Expert 35 |    172 | CPU
DEBUG 01-13 08:46:32.743158.743158 lmp.py:1622]   Expert 40 |    172 | CPU
DEBUG 01-13 08:46:32.743516.743516 lmp.py:1622]   Expert 16 |    174 | CPU
DEBUG 01-13 08:46:32.743113.743113 lmp.py:1622]   Expert  4 |    185 | CPU
DEBUG 01-13 08:46:32.743709.743709 lmp.py:1622]   Expert 37 |    186 | CPU
DEBUG 01-13 08:46:32.743591.743591 lmp.py:1622]   Expert 42 |    189 | CPU
DEBUG 01-13 08:46:32.743426.743426 lmp.py:1622]   Expert 13 |    193 | GPU
DEBUG 01-13 08:46:32.743976.743976 lmp.py:1622]   Expert 62 |    196 | GPU
DEBUG 01-13 08:46:32.743811.743811 lmp.py:1622]   Expert 17 |    198 | GPU
DEBUG 01-13 08:46:32.743170.743170 lmp.py:1622]   Expert 38 |    198 | GPU
DEBUG 01-13 08:46:32.743528.743528 lmp.py:1622]   Expert 21 |    201 | GPU
DEBUG 01-13 08:46:32.743886.743886 lmp.py:1622]   Expert 28 |    205 | GPU
DEBUG 01-13 08:46:32.743006.743006 lmp.py:1622]   Expert 58 |    208 | GPU
DEBUG 01-13 08:46:32.743079.743079 lmp.py:1622]   Expert  3 |    211 | GPU
DEBUG 01-13 08:46:32.743676.743676 lmp.py:1622]   Expert 60 |    211 | GPU
DEBUG 01-13 08:46:32.743273.743273 lmp.py:1622]   Expert 10 |    213 | GPU
DEBUG 01-13 08:46:32.743869.743869 lmp.py:1622]   Expert 44 |    215 | GPU
DEBUG 01-13 08:46:32.743466.743466 lmp.py:1622]   Expert 47 |    218 | GPU
DEBUG 01-13 08:46:32.743493.743493 lmp.py:1622]   Expert 55 |    220 | GPU
DEBUG 01-13 08:46:32.743043.743043 lmp.py:1622]   Expert 57 |    220 | GPU
DEBUG 01-13 08:46:32.744594.744594 lmp.py:1622]   Expert 53 |    221 | GPU
DEBUG 01-13 08:46:32.744952.744952 lmp.py:1622]   Expert 20 |    223 | GPU
DEBUG 01-13 08:46:32.744595.744595 lmp.py:1622]   Expert 31 |    235 | GPU
DEBUG 01-13 08:46:32.744476.744476 lmp.py:1622]   Expert  8 |    236 | GPU
DEBUG 01-13 08:46:32.744073.744073 lmp.py:1622]   Expert 46 |    237 | GPU
DEBUG 01-13 08:46:32.744193.744193 lmp.py:1622]   Expert 33 |    241 | GPU
DEBUG 01-13 08:46:32.744313.744313 lmp.py:1622]   Expert 19 |    243 | GPU
DEBUG 01-13 08:46:32.744194.744194 lmp.py:1622]   Expert 24 |    243 | GPU
DEBUG 01-13 08:46:32.744075.744075 lmp.py:1622]   Expert 63 |    260 | GPU
DEBUG 01-13 08:46:32.744434.744434 lmp.py:1622]   Expert 14 |    265 | GPU
DEBUG 01-13 08:46:32.744222.744222 lmp.py:1622]   Expert 22 |    276 | GPU
DEBUG 01-13 08:46:32.744773.744773 lmp.py:1622]   Expert 12 |    277 | GPU
DEBUG 01-13 08:46:32.744323.744323 lmp.py:1622]   Expert 29 |    282 | GPU
DEBUG 01-13 08:46:32.744920.744920 lmp.py:1622]   Expert  0 |    292 | GPU
DEBUG 01-13 08:46:32.744278.744278 lmp.py:1622]   Expert 43 |    305 | GPU
DEBUG 01-13 08:46:32.744636.744636 lmp.py:1622]   Expert 54 |    337 | GPU
DEBUG 01-13 08:46:32.744756.744756 lmp.py:1622]   Expert 41 |    380 | GPU
DEBUG 01-13 08:46:32.744876.744876 lmp.py:1622]   Expert 25 |    414 | GPU
DEBUG 01-13 08:46:32.744949.744949 lmp.py:1623] 
DEBUG 01-13 08:46:32.744949.744949 lmp.py:1623]   CPU total tokens: 4414 (35.9%)
DEBUG 01-13 08:46:32.744261.744261 lmp.py:1624]   GPU total tokens: 7874 (64.1%)
DEBUG 01-13 08:46:32.744209.744209 cuda_h.py:19] end experts_map_get cost 0.0017197132110595703 seconds
DEBUG 01-13 08:46:32.744742.744742 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-13 08:46:32.744882.744882 lmp.py:1632] 
DEBUG 01-13 08:46:32.744882.744882 lmp.py:1632]   Computing 32 experts on CPU MP...
DEBUG 01-13 08:46:32.744586.744586 cuda_h.py:19] end cpu_experts_submit cost 6.270408630371094e-05 seconds
DEBUG 01-13 08:46:32.744613.744613 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-13 08:46:32.744310.744310 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-13 08:46:32.744012.744012 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-13 08:46:32.745747.745747 cuda_h.py:19] end allocate_cuda_memory cost 0.0003273487091064453 seconds
DEBUG 01-13 08:46:32.745080.745080 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-13 08:46:32.745081.745081 sllm_store_c.py:27] get device uuid map
DEBUG 01-13 08:46:32.745195.745195 sllm_store_c.py:29] call client load into gpu
DEBUG 01-13 08:46:32.745521.745521 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, b7fcf1a8-6cca-4318-a1e1-341859b3f80a
DEBUG 01-13 08:46:32.745993.745993 client.py:106] call stub.LoadModelAsync
INFO 01-13 08:46:32.746834.746834 client.py:127] Model loaded
DEBUG 01-13 08:46:32.746715.746715 cuda_h.py:10] start restore2model
DEBUG 01-13 08:46:32.747959.747959 cuda_h.py:10] start experts_func_gpu_einsum_mp
DEBUG 01-13 08:46:32.748669.748669 cuda_h.py:19] end restore2model cost 0.001096963882446289 seconds
INFO 01-13 08:46:32.748932.748932 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, b7fcf1a8-6cca-4318-a1e1-341859b3f80a
DEBUG 01-13 08:46:32.748486.748486 cuda_h.py:19] end sllm_worker_task cost 0.013046026229858398 seconds
DEBUG 01-13 08:46:32.748796.748796 cuda_h.py:19] end load_into_gpu_async cost 0.0031516551971435547 seconds
DEBUG 01-13 08:46:32.748880.748880 cuda_h.py:10] start restore_tensors2
DEBUG 01-13 08:46:32.749675.749675 cuda_h.py:19] end restore_tensors2 cost 0.0005538463592529297 seconds
DEBUG 01-13 08:46:32.749624.749624 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.004593849182128906 seconds
DEBUG 01-13 08:46:32.749030.749030 cuda_h.py:10] start restore2model
DEBUG 01-13 08:46:32.752954.752954 cuda_h.py:19] end restore2model cost 0.002863645553588867 seconds
DEBUG 01-13 08:46:32.752434.752434 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.007676362991333008 seconds
DEBUG 01-13 08:46:32.752514.752514 cuda_h.py:10] start gpu_sexperts
DEBUG 01-13 08:46:32.752936.752936 cuda_h.py:19] end gpu_sexperts cost 0.0003142356872558594 seconds
DEBUG 01-13 08:46:32.752726.752726 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-13 08:46:32.752178.752178 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.193450927734375e-05 seconds
DEBUG 01-13 08:46:32.752351.752351 cuda_h.py:10] start wait_experts
INFO 01-13 08:46:32.752862.752862 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, b7fcf1a8-6cca-4318-a1e1-341859b3f80a
DEBUG 01-13 08:46:32.754270.754270 mlpmodule.py:1006] group tensors cost 0.006582021713256836 s
DEBUG 01-13 08:46:32.757955.757955 mlpmodule.py:1044] pad cost 0.002108335494995117 s
DEBUG 01-13 08:46:32.757257.757257 mlpmodule.py:1050] create cpu tensor cost 5.555152893066406e-05 s
DEBUG 01-13 08:46:32.757981.757981 mlpmodule.py:1055] move to cpu cost 3.9577484130859375e-05 s
DEBUG 01-13 08:46:32.770967.770967 mlpmodule.py:1069] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-13 08:46:32.770237.770237 mlpmodule.py:1070] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-13 08:46:32.770366.770366 mlpmodule.py:1075] group_w3 first element: -0.054931640625
WARNING 01-13 08:46:32.770152.770152 mlpmodule.py:1085] start einsum2
DEBUG 01-13 08:46:32.786267.786267 mlpmodule.py:1095] group einsum cost 0.02863788604736328 s
DEBUG 01-13 08:46:32.786231.786231 mlpmodule.py:1103] cpy2cputensor cost 0.0006771087646484375 s
INFO 01-13 08:46:32.798611.798611 client.py:127] Model loaded
DEBUG 01-13 08:46:32.799193.799193 cuda_h.py:19] end wait_experts cost 0.04625415802001953 seconds
DEBUG 01-13 08:46:32.799924.799924 cuda_h.py:10] start gpu_experts
DEBUG 01-13 08:46:32.800989.800989 mlpmodule.py:559] gpu group tensors cost 0.00154876708984375 s
DEBUG 01-13 08:46:32.805329.805329 mlpmodule.py:592] gpu pad cost 0.004873037338256836 s
DEBUG 01-13 08:46:32.806752.806752 mlpmodule.py:598] start_w1
DEBUG 01-13 08:46:32.806320.806320 mlpmodule.py:602] start_w3
DEBUG 01-13 08:46:32.807938.807938 mlpmodule.py:608] start_w2
DEBUG 01-13 08:46:32.807925.807925 mlpmodule.py:611] gpu group einsum cost 0.001600027084350586 s
DEBUG 01-13 08:46:32.812454.812454 mlpmodule.py:785]  experts func einsum cost 0.0646977424621582 s
DEBUG 01-13 08:46:32.813296.813296 cuda_h.py:19] end experts_func_gpu_einsum_mp cost 0.06594705581665039 seconds
DEBUG 01-13 08:46:32.813637.813637 mlpmodule.py:683] gpu experts func einsum cost 0.014400243759155273 s
DEBUG 01-13 08:46:32.813940.813940 cuda_h.py:19] end gpu_experts cost 0.01465749740600586 seconds
DEBUG 01-13 08:46:32.813564.813564 cuda_h.py:10] start cpu_thread_manager_mp_wait
DEBUG 01-13 08:46:32.814925.814925 cuda_h.py:19] end cpu_thread_manager_mp_wait cost 5.435943603515625e-05 seconds
DEBUG 01-13 08:46:32.814498.814498 cuda_h.py:19] end layer_moe_generate_mp_l_4 cost 0.07238578796386719 seconds
DEBUG 01-13 08:46:32.814575.814575 lmp.py:1550] -------------------------------- end prefill layer 3 --------------------------------
DEBUG 01-13 08:46:32.814650.814650 lmp.py:1493] -------------------------------- start prefill layer 4 --------------------------------
DEBUG 01-13 08:46:32.814598.814598 cuda_h.py:10] start start_load_qkvogn_s_weight_l_5
DEBUG 01-13 08:46:32.814745.814745 cuda_h.py:10] start start_load_qkvogn_s_weight_l_5
DEBUG 01-13 08:46:32.814085.814085 cuda_h.py:19] end start_load_qkvogn_s_weight_l_5 cost 4.267692565917969e-05 seconds
DEBUG 01-13 08:46:32.814510.814510 cuda_h.py:19] end start_load_qkvogn_s_weight_l_5 cost 7.867813110351562e-05 seconds
DEBUG 01-13 08:46:32.814114.814114 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-13 08:46:32.814646.814646 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-13 08:46:32.814558.814558 cuda_h.py:10] start sllm_worker_task
DEBUG 01-13 08:46:32.815931.815931 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-13 08:46:32.815119.815119 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-13 08:46:32.815045.815045 cuda_h.py:19] end allocate_cuda_memory cost 0.0004680156707763672 seconds
DEBUG 01-13 08:46:32.815832.815832 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-13 08:46:32.816318.816318 sllm_store_c.py:27] get device uuid map
DEBUG 01-13 08:46:32.816580.816580 sllm_store_c.py:29] call client load into gpu
DEBUG 01-13 08:46:32.816192.816192 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 9d0c7d17-e156-48b7-b840-f523bc637694
DEBUG 01-13 08:46:32.816450.816450 client.py:106] call stub.LoadModelAsync
DEBUG 01-13 08:46:32.816282.816282 cuda_h.py:10] start self_attn
INFO 01-13 08:46:32.818829.818829 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 9d0c7d17-e156-48b7-b840-f523bc637694
DEBUG 01-13 08:46:32.818365.818365 cuda_h.py:19] end load_into_gpu_async cost 0.002376556396484375 seconds
DEBUG 01-13 08:46:32.818003.818003 cuda_h.py:10] start restore_tensors2
DEBUG 01-13 08:46:32.818197.818197 cuda_h.py:19] end restore_tensors2 cost 0.00016927719116210938 seconds
DEBUG 01-13 08:46:32.818200.818200 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.003637075424194336 seconds
INFO 01-13 08:46:32.819411.819411 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 9d0c7d17-e156-48b7-b840-f523bc637694
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-13 08:46:32.821991.821991 cuda_h.py:19] end self_attn cost 0.004458904266357422 seconds
DEBUG 01-13 08:46:32.821330.821330 cuda_h.py:19] end iln_self_attn_paln cost 0.007004499435424805 seconds
DEBUG 01-13 08:46:32.821816.821816 cuda_h.py:10] start layer_moe_generate_mp_l_5
DEBUG 01-13 08:46:32.821685.821685 cuda_h.py:10] start gate
DEBUG 01-13 08:46:32.822996.822996 cuda_h.py:19] end gate cost 0.0009584426879882812 seconds
DEBUG 01-13 08:46:32.822608.822608 cuda_h.py:10] start experts_map_get
DEBUG 01-13 08:46:32.823310.823310 lmp.py:1611] 
DEBUG 01-13 08:46:32.823310.823310 lmp.py:1611] Expert Token Distribution & Device Allocation:
DEBUG 01-13 08:46:32.823934.823934 lmp.py:1612]   Total experts: 64
DEBUG 01-13 08:46:32.823843.823843 lmp.py:1613]   CPU experts: 32 (50%)
DEBUG 01-13 08:46:32.823439.823439 lmp.py:1614]   GPU experts: 32 (50%)
DEBUG 01-13 08:46:32.823129.823129 lmp.py:1615] 
DEBUG 01-13 08:46:32.823129.823129 lmp.py:1615]   Expert ID | Tokens | Device
DEBUG 01-13 08:46:32.823249.823249 lmp.py:1616]   -----------------------------------
DEBUG 01-13 08:46:32.823375.823375 lmp.py:1622]   Expert 14 |     64 | CPU
DEBUG 01-13 08:46:32.823018.823018 lmp.py:1622]   Expert 13 |     73 | CPU
DEBUG 01-13 08:46:32.823184.823184 lmp.py:1622]   Expert 57 |     73 | CPU
DEBUG 01-13 08:46:32.823158.823158 lmp.py:1622]   Expert 26 |     88 | CPU
DEBUG 01-13 08:46:32.823609.823609 lmp.py:1622]   Expert 31 |     88 | CPU
DEBUG 01-13 08:46:32.823060.823060 lmp.py:1622]   Expert 11 |     90 | CPU
DEBUG 01-13 08:46:32.823988.823988 lmp.py:1622]   Expert 54 |     94 | CPU
DEBUG 01-13 08:46:32.823777.823777 lmp.py:1622]   Expert 45 |     99 | CPU
DEBUG 01-13 08:46:32.823327.823327 lmp.py:1622]   Expert 30 |    101 | CPU
DEBUG 01-13 08:46:32.823924.823924 lmp.py:1622]   Expert 58 |    104 | CPU
DEBUG 01-13 08:46:32.823520.823520 lmp.py:1622]   Expert 51 |    108 | CPU
DEBUG 01-13 08:46:32.823170.823170 lmp.py:1622]   Expert 10 |    115 | CPU
DEBUG 01-13 08:46:32.823482.823482 lmp.py:1622]   Expert 32 |    115 | CPU
DEBUG 01-13 08:46:32.823032.823032 lmp.py:1622]   Expert 36 |    116 | CPU
DEBUG 01-13 08:46:32.823821.823821 lmp.py:1622]   Expert  8 |    129 | CPU
DEBUG 01-13 08:46:32.823133.823133 lmp.py:1622]   Expert 20 |    131 | CPU
DEBUG 01-13 08:46:32.823445.823445 lmp.py:1622]   Expert 63 |    136 | CPU
DEBUG 01-13 08:46:32.823518.823518 lmp.py:1622]   Expert 53 |    137 | CPU
DEBUG 01-13 08:46:32.823876.823876 lmp.py:1622]   Expert 61 |    142 | CPU
DEBUG 01-13 08:46:32.823235.823235 lmp.py:1622]   Expert  4 |    143 | CPU
DEBUG 01-13 08:46:32.823831.823831 lmp.py:1622]   Expert 34 |    144 | CPU
DEBUG 01-13 08:46:32.823713.823713 lmp.py:1622]   Expert 47 |    145 | CPU
DEBUG 01-13 08:46:32.823071.823071 lmp.py:1622]   Expert 16 |    149 | CPU
DEBUG 01-13 08:46:32.823304.823304 lmp.py:1622]   Expert 60 |    156 | CPU
DEBUG 01-13 08:46:32.823616.823616 lmp.py:1622]   Expert 28 |    159 | CPU
DEBUG 01-13 08:46:32.823974.823974 lmp.py:1622]   Expert 17 |    160 | CPU
DEBUG 01-13 08:46:32.824571.824571 lmp.py:1622]   Expert 42 |    167 | CPU
DEBUG 01-13 08:46:32.824644.824644 lmp.py:1622]   Expert 44 |    171 | CPU
DEBUG 01-13 08:46:32.824002.824002 lmp.py:1622]   Expert 29 |    172 | CPU
DEBUG 01-13 08:46:32.824599.824599 lmp.py:1622]   Expert  9 |    175 | CPU
DEBUG 01-13 08:46:32.824957.824957 lmp.py:1622]   Expert 27 |    176 | CPU
DEBUG 01-13 08:46:32.824839.824839 lmp.py:1622]   Expert  7 |    179 | CPU
DEBUG 01-13 08:46:32.824958.824958 lmp.py:1622]   Expert 48 |    183 | GPU
DEBUG 01-13 08:46:32.824078.824078 lmp.py:1622]   Expert  2 |    185 | GPU
DEBUG 01-13 08:46:32.824436.824436 lmp.py:1622]   Expert 41 |    185 | GPU
DEBUG 01-13 08:46:32.824556.824556 lmp.py:1622]   Expert  3 |    189 | GPU
DEBUG 01-13 08:46:32.824676.824676 lmp.py:1622]   Expert  0 |    190 | GPU
DEBUG 01-13 08:46:32.824034.824034 lmp.py:1622]   Expert 56 |    190 | GPU
DEBUG 01-13 08:46:32.824631.824631 lmp.py:1622]   Expert 24 |    193 | GPU
DEBUG 01-13 08:46:32.824751.824751 lmp.py:1622]   Expert 15 |    195 | GPU
DEBUG 01-13 08:46:32.824824.824824 lmp.py:1622]   Expert 18 |    203 | GPU
DEBUG 01-13 08:46:32.824421.824421 lmp.py:1622]   Expert 55 |    205 | GPU
DEBUG 01-13 08:46:32.824839.824839 lmp.py:1622]   Expert 40 |    212 | GPU
DEBUG 01-13 08:46:32.824813.824813 lmp.py:1622]   Expert 23 |    213 | GPU
DEBUG 01-13 08:46:32.824787.824787 lmp.py:1622]   Expert 38 |    214 | GPU
DEBUG 01-13 08:46:32.824284.824284 lmp.py:1622]   Expert 22 |    216 | GPU
DEBUG 01-13 08:46:32.824841.824841 lmp.py:1622]   Expert  6 |    219 | GPU
DEBUG 01-13 08:46:32.824968.824968 lmp.py:1622]   Expert 37 |    226 | GPU
DEBUG 01-13 08:46:32.824902.824902 lmp.py:1622]   Expert 46 |    235 | GPU
DEBUG 01-13 08:46:32.824638.824638 lmp.py:1622]   Expert 19 |    236 | GPU
DEBUG 01-13 08:46:32.824135.824135 lmp.py:1622]   Expert 39 |    249 | GPU
DEBUG 01-13 08:46:32.824348.824348 lmp.py:1622]   Expert 12 |    254 | GPU
DEBUG 01-13 08:46:32.824560.824560 lmp.py:1622]   Expert 25 |    256 | GPU
DEBUG 01-13 08:46:32.824819.824819 lmp.py:1622]   Expert 50 |    264 | GPU
DEBUG 01-13 08:46:32.824555.824555 lmp.py:1622]   Expert 21 |    277 | GPU
DEBUG 01-13 08:46:32.824052.824052 lmp.py:1622]   Expert 62 |    278 | GPU
DEBUG 01-13 08:46:32.824788.824788 lmp.py:1622]   Expert 35 |    289 | GPU
DEBUG 01-13 08:46:32.824285.824285 lmp.py:1622]   Expert 52 |    294 | GPU
DEBUG 01-13 08:46:32.824020.824020 lmp.py:1622]   Expert 49 |    296 | GPU
DEBUG 01-13 08:46:32.824756.824756 lmp.py:1622]   Expert 33 |    300 | GPU
DEBUG 01-13 08:46:32.824730.824730 lmp.py:1622]   Expert  1 |    348 | GPU
DEBUG 01-13 08:46:32.824466.824466 lmp.py:1622]   Expert  5 |    377 | GPU
DEBUG 01-13 08:46:32.824201.824201 lmp.py:1622]   Expert 43 |    439 | GPU
DEBUG 01-13 08:46:32.824652.824652 lmp.py:1622]   Expert 59 |    579 | GPU
DEBUG 01-13 08:46:32.824057.824057 lmp.py:1623] 
DEBUG 01-13 08:46:32.824057.824057 lmp.py:1623]   CPU total tokens: 4099 (33.4%)
DEBUG 01-13 08:46:32.824461.824461 lmp.py:1624]   GPU total tokens: 8189 (66.6%)
DEBUG 01-13 08:46:32.824873.824873 cuda_h.py:19] end experts_map_get cost 0.001741647720336914 seconds
DEBUG 01-13 08:46:32.824676.824676 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-13 08:46:32.824478.824478 lmp.py:1632] 
DEBUG 01-13 08:46:32.824478.824478 lmp.py:1632]   Computing 32 experts on CPU MP...
DEBUG 01-13 08:46:32.824507.824507 cuda_h.py:19] end cpu_experts_submit cost 5.5789947509765625e-05 seconds
DEBUG 01-13 08:46:32.824296.824296 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-13 08:46:32.824039.824039 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-13 08:46:32.825867.825867 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-13 08:46:32.833409.833409 cuda_h.py:19] end allocate_cuda_memory cost 0.00804758071899414 seconds
DEBUG 01-13 08:46:32.833108.833108 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-13 08:46:32.833023.833023 sllm_store_c.py:27] get device uuid map
INFO 01-13 08:46:32.833565.833565 client.py:127] Model loaded
DEBUG 01-13 08:46:32.833835.833835 sllm_store_c.py:29] call client load into gpu
DEBUG 01-13 08:46:32.833874.833874 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, d5055183-eb55-4d34-a645-e53060fd5b71
DEBUG 01-13 08:46:32.834988.834988 client.py:106] call stub.LoadModelAsync
DEBUG 01-13 08:46:32.833918.833918 cuda_h.py:10] start restore2model
DEBUG 01-13 08:46:32.834965.834965 cuda_h.py:10] start experts_func_gpu_einsum_mp
DEBUG 01-13 08:46:32.835078.835078 cuda_h.py:19] end restore2model cost 0.0008559226989746094 seconds
DEBUG 01-13 08:46:32.835048.835048 cuda_h.py:19] end sllm_worker_task cost 0.020157575607299805 seconds
INFO 01-13 08:46:32.836439.836439 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, d5055183-eb55-4d34-a645-e53060fd5b71
DEBUG 01-13 08:46:32.836892.836892 cuda_h.py:19] end load_into_gpu_async cost 0.0032014846801757812 seconds
DEBUG 01-13 08:46:32.836409.836409 cuda_h.py:10] start restore_tensors2
DEBUG 01-13 08:46:32.837660.837660 cuda_h.py:19] end restore_tensors2 cost 0.0005431175231933594 seconds
DEBUG 01-13 08:46:32.837709.837709 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.012266159057617188 seconds
DEBUG 01-13 08:46:32.837485.837485 cuda_h.py:10] start restore2model
DEBUG 01-13 08:46:32.840515.840515 cuda_h.py:19] end restore2model cost 0.0028336048126220703 seconds
DEBUG 01-13 08:46:32.840531.840531 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.01532125473022461 seconds
DEBUG 01-13 08:46:32.840088.840088 cuda_h.py:10] start gpu_sexperts
DEBUG 01-13 08:46:32.840028.840028 cuda_h.py:19] end gpu_sexperts cost 0.00034236907958984375 seconds
DEBUG 01-13 08:46:32.840864.840864 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-13 08:46:32.840263.840263 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 1.9550323486328125e-05 seconds
DEBUG 01-13 08:46:32.840151.840151 cuda_h.py:10] start wait_experts
INFO 01-13 08:46:32.840139.840139 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, d5055183-eb55-4d34-a645-e53060fd5b71
DEBUG 01-13 08:46:32.842361.842361 mlpmodule.py:1006] group tensors cost 0.0067598819732666016 s
DEBUG 01-13 08:46:32.845545.845545 mlpmodule.py:1044] pad cost 0.0029938220977783203 s
DEBUG 01-13 08:46:32.845629.845629 mlpmodule.py:1050] create cpu tensor cost 7.152557373046875e-05 s
DEBUG 01-13 08:46:32.846115.846115 mlpmodule.py:1055] move to cpu cost 4.0531158447265625e-05 s
DEBUG 01-13 08:46:32.859232.859232 mlpmodule.py:1069] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-13 08:46:32.859092.859092 mlpmodule.py:1070] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-13 08:46:32.859804.859804 mlpmodule.py:1075] group_w3 first element: 0.0086669921875
WARNING 01-13 08:46:32.859782.859782 mlpmodule.py:1085] start einsum2
DEBUG 01-13 08:46:32.874704.874704 mlpmodule.py:1095] group einsum cost 0.028579235076904297 s
DEBUG 01-13 08:46:32.875219.875219 mlpmodule.py:1103] cpy2cputensor cost 0.0006976127624511719 s
INFO 01-13 08:46:32.887357.887357 client.py:127] Model loaded
DEBUG 01-13 08:46:32.887120.887120 cuda_h.py:19] end wait_experts cost 0.0470733642578125 seconds
DEBUG 01-13 08:46:32.888965.888965 cuda_h.py:10] start gpu_experts
DEBUG 01-13 08:46:32.889078.889078 mlpmodule.py:559] gpu group tensors cost 0.001596689224243164 s
DEBUG 01-13 08:46:32.894757.894757 mlpmodule.py:592] gpu pad cost 0.004708766937255859 s
DEBUG 01-13 08:46:32.894061.894061 mlpmodule.py:598] start_w1
DEBUG 01-13 08:46:32.895950.895950 mlpmodule.py:602] start_w3
DEBUG 01-13 08:46:32.896030.896030 mlpmodule.py:608] start_w2
DEBUG 01-13 08:46:32.896853.896853 mlpmodule.py:611] gpu group einsum cost 0.0018794536590576172 s
DEBUG 01-13 08:46:32.901479.901479 mlpmodule.py:683] gpu experts func einsum cost 0.013381719589233398 s
DEBUG 01-13 08:46:32.901704.901704 cuda_h.py:19] end gpu_experts cost 0.013706207275390625 seconds
DEBUG 01-13 08:46:32.901177.901177 cuda_h.py:10] start cpu_thread_manager_mp_wait
DEBUG 01-13 08:46:32.901615.901615 mlpmodule.py:785]  experts func einsum cost 0.06660151481628418 s
DEBUG 01-13 08:46:32.901261.901261 cuda_h.py:19] end cpu_thread_manager_mp_wait cost 6.628036499023438e-05 seconds
DEBUG 01-13 08:46:32.902012.902012 cuda_h.py:19] end experts_func_gpu_einsum_mp cost 0.06756758689880371 seconds
DEBUG 01-13 08:46:32.902617.902617 cuda_h.py:19] end layer_moe_generate_mp_l_5 cost 0.08024883270263672 seconds
DEBUG 01-13 08:46:32.902268.902268 lmp.py:1550] -------------------------------- end prefill layer 4 --------------------------------
DEBUG 01-13 08:46:32.902337.902337 lmp.py:1493] -------------------------------- start prefill layer 5 --------------------------------
DEBUG 01-13 08:46:32.902696.902696 cuda_h.py:10] start start_load_qkvogn_s_weight_l_6
DEBUG 01-13 08:46:32.902923.902923 cuda_h.py:10] start start_load_qkvogn_s_weight_l_6
DEBUG 01-13 08:46:32.902119.902119 cuda_h.py:19] end start_load_qkvogn_s_weight_l_6 cost 5.53131103515625e-05 seconds
DEBUG 01-13 08:46:32.902147.902147 cuda_h.py:19] end start_load_qkvogn_s_weight_l_6 cost 0.00011801719665527344 seconds
DEBUG 01-13 08:46:32.902401.902401 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-13 08:46:32.903994.903994 cuda_h.py:10] start sllm_worker_task
DEBUG 01-13 08:46:32.903783.903783 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-13 08:46:32.903130.903130 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-13 08:46:32.903568.903568 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-13 08:46:32.903407.903407 cuda_h.py:19] end allocate_cuda_memory cost 0.00029087066650390625 seconds
DEBUG 01-13 08:46:32.904502.904502 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-13 08:46:32.904119.904119 sllm_store_c.py:27] get device uuid map
DEBUG 01-13 08:46:32.904280.904280 sllm_store_c.py:29] call client load into gpu
DEBUG 01-13 08:46:32.904460.904460 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, f1b46bc4-9d90-4a36-9e51-1146d8ad5fea
DEBUG 01-13 08:46:32.904589.904589 client.py:106] call stub.LoadModelAsync
DEBUG 01-13 08:46:32.904045.904045 cuda_h.py:10] start self_attn
INFO 01-13 08:46:32.905405.905405 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, f1b46bc4-9d90-4a36-9e51-1146d8ad5fea
DEBUG 01-13 08:46:32.905521.905521 cuda_h.py:19] end load_into_gpu_async cost 0.0013115406036376953 seconds
DEBUG 01-13 08:46:32.905469.905469 cuda_h.py:10] start restore_tensors2
DEBUG 01-13 08:46:32.905003.905003 cuda_h.py:19] end restore_tensors2 cost 8.392333984375e-05 seconds
DEBUG 01-13 08:46:32.905235.905235 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.001965761184692383 seconds
INFO 01-13 08:46:32.905781.905781 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, f1b46bc4-9d90-4a36-9e51-1146d8ad5fea
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-13 08:46:32.908855.908855 cuda_h.py:19] end self_attn cost 0.003952741622924805 seconds
DEBUG 01-13 08:46:32.909542.909542 cuda_h.py:19] end iln_self_attn_paln cost 0.005950927734375 seconds
DEBUG 01-13 08:46:32.909915.909915 cuda_h.py:10] start layer_moe_generate_mp_l_6
DEBUG 01-13 08:46:32.909439.909439 cuda_h.py:10] start gate
DEBUG 01-13 08:46:32.909259.909259 cuda_h.py:19] end gate cost 0.00070953369140625 seconds
DEBUG 01-13 08:46:32.909903.909903 cuda_h.py:10] start experts_map_get
DEBUG 01-13 08:46:32.910835.910835 lmp.py:1611] 
DEBUG 01-13 08:46:32.910835.910835 lmp.py:1611] Expert Token Distribution & Device Allocation:
DEBUG 01-13 08:46:32.910929.910929 lmp.py:1612]   Total experts: 64
DEBUG 01-13 08:46:32.910393.910393 lmp.py:1613]   CPU experts: 32 (50%)
DEBUG 01-13 08:46:32.910566.910566 lmp.py:1614]   GPU experts: 32 (50%)
DEBUG 01-13 08:46:32.910309.910309 lmp.py:1615] 
DEBUG 01-13 08:46:32.910309.910309 lmp.py:1615]   Expert ID | Tokens | Device
DEBUG 01-13 08:46:32.910289.910289 lmp.py:1616]   -----------------------------------
DEBUG 01-13 08:46:32.910277.910277 lmp.py:1622]   Expert 34 |     24 | CPU
DEBUG 01-13 08:46:32.910066.910066 lmp.py:1622]   Expert 45 |     60 | CPU
DEBUG 01-13 08:46:32.910378.910378 lmp.py:1622]   Expert 22 |     73 | CPU
DEBUG 01-13 08:46:32.910498.910498 lmp.py:1622]   Expert 57 |     77 | CPU
DEBUG 01-13 08:46:32.910094.910094 lmp.py:1622]   Expert 17 |     92 | CPU
DEBUG 01-13 08:46:32.910214.910214 lmp.py:1622]   Expert 15 |    102 | CPU
DEBUG 01-13 08:46:32.910572.910572 lmp.py:1622]   Expert  4 |    103 | CPU
DEBUG 01-13 08:46:32.910884.910884 lmp.py:1622]   Expert 28 |    108 | CPU
DEBUG 01-13 08:46:32.910958.910958 lmp.py:1622]   Expert 32 |    109 | CPU
DEBUG 01-13 08:46:32.910508.910508 lmp.py:1622]   Expert 60 |    115 | CPU
DEBUG 01-13 08:46:32.910820.910820 lmp.py:1622]   Expert 36 |    124 | CPU
DEBUG 01-13 08:46:32.910178.910178 lmp.py:1622]   Expert 16 |    126 | CPU
DEBUG 01-13 08:46:32.910059.910059 lmp.py:1622]   Expert 52 |    126 | CPU
DEBUG 01-13 08:46:32.910179.910179 lmp.py:1622]   Expert 12 |    128 | CPU
DEBUG 01-13 08:46:32.910538.910538 lmp.py:1622]   Expert 14 |    128 | CPU
DEBUG 01-13 08:46:32.910657.910657 lmp.py:1622]   Expert  2 |    132 | CPU
DEBUG 01-13 08:46:32.910016.910016 lmp.py:1622]   Expert 25 |    132 | CPU
DEBUG 01-13 08:46:32.910135.910135 lmp.py:1622]   Expert  8 |    135 | CPU
DEBUG 01-13 08:46:32.910970.910970 lmp.py:1622]   Expert  5 |    144 | CPU
DEBUG 01-13 08:46:32.910521.910521 lmp.py:1622]   Expert 35 |    146 | CPU
DEBUG 01-13 08:46:32.910641.910641 lmp.py:1622]   Expert 61 |    153 | CPU
DEBUG 01-13 08:46:32.910953.910953 lmp.py:1622]   Expert 23 |    155 | CPU
DEBUG 01-13 08:46:32.910311.910311 lmp.py:1622]   Expert  0 |    156 | CPU
DEBUG 01-13 08:46:32.910431.910431 lmp.py:1622]   Expert 30 |    156 | CPU
DEBUG 01-13 08:46:32.910789.910789 lmp.py:1622]   Expert 39 |    156 | CPU
DEBUG 01-13 08:46:32.910147.910147 lmp.py:1622]   Expert 42 |    165 | CPU
DEBUG 01-13 08:46:32.910028.910028 lmp.py:1622]   Expert  9 |    172 | CPU
DEBUG 01-13 08:46:32.910671.910671 lmp.py:1622]   Expert 46 |    174 | CPU
DEBUG 01-13 08:46:32.910506.910506 lmp.py:1622]   Expert  3 |    176 | CPU
DEBUG 01-13 08:46:32.910149.910149 lmp.py:1622]   Expert 44 |    177 | CPU
DEBUG 01-13 08:46:32.910031.910031 lmp.py:1622]   Expert 41 |    178 | CPU
DEBUG 01-13 08:46:32.910151.910151 lmp.py:1622]   Expert 13 |    181 | CPU
DEBUG 01-13 08:46:32.910747.910747 lmp.py:1622]   Expert 31 |    185 | GPU
DEBUG 01-13 08:46:32.911165.911165 lmp.py:1622]   Expert 51 |    186 | GPU
DEBUG 01-13 08:46:32.911716.911716 lmp.py:1622]   Expert 43 |    187 | GPU
DEBUG 01-13 08:46:32.911074.911074 lmp.py:1622]   Expert 18 |    189 | GPU
DEBUG 01-13 08:46:32.911194.911194 lmp.py:1622]   Expert 26 |    190 | GPU
DEBUG 01-13 08:46:32.911790.911790 lmp.py:1622]   Expert 62 |    191 | GPU
DEBUG 01-13 08:46:32.911910.911910 lmp.py:1622]   Expert 50 |    195 | GPU
DEBUG 01-13 08:46:32.911268.911268 lmp.py:1622]   Expert 49 |    197 | GPU
DEBUG 01-13 08:46:32.911104.911104 lmp.py:1622]   Expert 47 |    199 | GPU
DEBUG 01-13 08:46:32.911939.911939 lmp.py:1622]   Expert 11 |    201 | GPU
DEBUG 01-13 08:46:32.911727.911727 lmp.py:1622]   Expert 27 |    201 | GPU
DEBUG 01-13 08:46:32.911562.911562 lmp.py:1622]   Expert 55 |    202 | GPU
DEBUG 01-13 08:46:32.911159.911159 lmp.py:1622]   Expert 20 |    203 | GPU
DEBUG 01-13 08:46:32.911517.911517 lmp.py:1622]   Expert 63 |    205 | GPU
DEBUG 01-13 08:46:32.911399.911399 lmp.py:1622]   Expert 19 |    210 | GPU
DEBUG 01-13 08:46:32.911280.911280 lmp.py:1622]   Expert 56 |    213 | GPU
DEBUG 01-13 08:46:32.911400.911400 lmp.py:1622]   Expert 38 |    218 | GPU
DEBUG 01-13 08:46:32.911758.911758 lmp.py:1622]   Expert 48 |    225 | GPU
DEBUG 01-13 08:46:32.911640.911640 lmp.py:1622]   Expert  1 |    237 | GPU
DEBUG 01-13 08:46:32.911521.911521 lmp.py:1622]   Expert 10 |    239 | GPU
DEBUG 01-13 08:46:32.911879.911879 lmp.py:1622]   Expert 54 |    240 | GPU
DEBUG 01-13 08:46:32.911714.911714 lmp.py:1622]   Expert  7 |    247 | GPU
DEBUG 01-13 08:46:32.911788.911788 lmp.py:1622]   Expert 21 |    255 | GPU
DEBUG 01-13 08:46:32.911100.911100 lmp.py:1622]   Expert 33 |    258 | GPU
DEBUG 01-13 08:46:32.911219.911219 lmp.py:1622]   Expert 29 |    262 | GPU
DEBUG 01-13 08:46:32.911101.911101 lmp.py:1622]   Expert 40 |    263 | GPU
DEBUG 01-13 08:46:32.911744.911744 lmp.py:1622]   Expert 24 |    268 | GPU
DEBUG 01-13 08:46:32.911864.911864 lmp.py:1622]   Expert 59 |    296 | GPU
DEBUG 01-13 08:46:32.911222.911222 lmp.py:1622]   Expert 37 |    330 | GPU
DEBUG 01-13 08:46:32.911580.911580 lmp.py:1622]   Expert 58 |    371 | GPU
DEBUG 01-13 08:46:32.911461.911461 lmp.py:1622]   Expert  6 |    384 | GPU
DEBUG 01-13 08:46:32.911343.911343 lmp.py:1622]   Expert 53 |    858 | GPU
DEBUG 01-13 08:46:32.911893.911893 lmp.py:1623] 
DEBUG 01-13 08:46:32.911893.911893 lmp.py:1623]   CPU total tokens: 4183 (34.0%)
DEBUG 01-13 08:46:32.911874.911874 lmp.py:1624]   GPU total tokens: 8105 (66.0%)
DEBUG 01-13 08:46:32.911670.911670 cuda_h.py:19] end experts_map_get cost 0.001695394515991211 seconds
DEBUG 01-13 08:46:32.911765.911765 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-13 08:46:32.911997.911997 lmp.py:1632] 
DEBUG 01-13 08:46:32.911997.911997 lmp.py:1632]   Computing 32 experts on CPU MP...
DEBUG 01-13 08:46:32.911072.911072 cuda_h.py:19] end cpu_experts_submit cost 5.7220458984375e-05 seconds
DEBUG 01-13 08:46:32.911768.911768 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-13 08:46:32.911327.911327 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-13 08:46:32.912770.912770 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-13 08:46:32.912158.912158 cuda_h.py:19] end allocate_cuda_memory cost 0.00028395652770996094 seconds
DEBUG 01-13 08:46:32.912426.912426 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-13 08:46:32.912050.912050 sllm_store_c.py:27] get device uuid map
DEBUG 01-13 08:46:32.912449.912449 sllm_store_c.py:29] call client load into gpu
DEBUG 01-13 08:46:32.912344.912344 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 6799514d-6f10-459b-ae66-c2b7cef54340
DEBUG 01-13 08:46:32.912709.912709 client.py:106] call stub.LoadModelAsync
INFO 01-13 08:46:32.913463.913463 client.py:127] Model loaded
DEBUG 01-13 08:46:32.913208.913208 cuda_h.py:10] start restore2model
DEBUG 01-13 08:46:32.913499.913499 cuda_h.py:10] start experts_func_gpu_einsum_mp
DEBUG 01-13 08:46:32.914838.914838 cuda_h.py:19] end restore2model cost 0.0005583763122558594 seconds
DEBUG 01-13 08:46:32.914912.914912 cuda_h.py:19] end sllm_worker_task cost 0.010922908782958984 seconds
INFO 01-13 08:46:32.914976.914976 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 6799514d-6f10-459b-ae66-c2b7cef54340
DEBUG 01-13 08:46:32.914138.914138 cuda_h.py:19] end load_into_gpu_async cost 0.0020291805267333984 seconds
DEBUG 01-13 08:46:32.914132.914132 cuda_h.py:10] start restore_tensors2
DEBUG 01-13 08:46:32.915998.915998 cuda_h.py:19] end restore_tensors2 cost 0.0005042552947998047 seconds
DEBUG 01-13 08:46:32.915954.915954 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0032806396484375 seconds
DEBUG 01-13 08:46:32.915545.915545 cuda_h.py:10] start restore2model
DEBUG 01-13 08:46:32.918795.918795 cuda_h.py:19] end restore2model cost 0.002884387969970703 seconds
DEBUG 01-13 08:46:32.918904.918904 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.0063970088958740234 seconds
DEBUG 01-13 08:46:32.918435.918435 cuda_h.py:10] start gpu_sexperts
DEBUG 01-13 08:46:32.918293.918293 cuda_h.py:19] end gpu_sexperts cost 0.0002834796905517578 seconds
DEBUG 01-13 08:46:32.918944.918944 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-13 08:46:32.918151.918151 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 1.9311904907226562e-05 seconds
DEBUG 01-13 08:46:32.918801.918801 cuda_h.py:10] start wait_experts
INFO 01-13 08:46:32.918358.918358 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 6799514d-6f10-459b-ae66-c2b7cef54340
DEBUG 01-13 08:46:32.924055.924055 mlpmodule.py:1006] group tensors cost 0.01006627082824707 s
DEBUG 01-13 08:46:32.927037.927037 mlpmodule.py:1044] pad cost 0.002439260482788086 s
DEBUG 01-13 08:46:32.927206.927206 mlpmodule.py:1050] create cpu tensor cost 6.818771362304688e-05 s
DEBUG 01-13 08:46:32.927269.927269 mlpmodule.py:1055] move to cpu cost 4.4345855712890625e-05 s
DEBUG 01-13 08:46:32.937588.937588 mlpmodule.py:1069] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-13 08:46:32.937078.937078 mlpmodule.py:1070] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-13 08:46:32.937850.937850 mlpmodule.py:1075] group_w3 first element: 0.03369140625
WARNING 01-13 08:46:32.937623.937623 mlpmodule.py:1085] start einsum2
DEBUG 01-13 08:46:32.952371.952371 mlpmodule.py:1095] group einsum cost 0.024925947189331055 s
DEBUG 01-13 08:46:32.953924.953924 mlpmodule.py:1103] cpy2cputensor cost 0.0006818771362304688 s
INFO 01-13 08:46:32.964707.964707 client.py:127] Model loaded
DEBUG 01-13 08:46:32.964877.964877 cuda_h.py:19] end wait_experts cost 0.04555916786193848 seconds
DEBUG 01-13 08:46:32.964005.964005 cuda_h.py:10] start gpu_experts
DEBUG 01-13 08:46:32.965499.965499 mlpmodule.py:559] gpu group tensors cost 0.001268148422241211 s
DEBUG 01-13 08:46:32.970856.970856 mlpmodule.py:592] gpu pad cost 0.004798173904418945 s
DEBUG 01-13 08:46:32.971307.971307 mlpmodule.py:598] start_w1
DEBUG 01-13 08:46:32.971682.971682 mlpmodule.py:602] start_w3
DEBUG 01-13 08:46:32.972344.972344 mlpmodule.py:608] start_w2
DEBUG 01-13 08:46:32.973449.973449 mlpmodule.py:611] gpu group einsum cost 0.0020656585693359375 s
DEBUG 01-13 08:46:32.977584.977584 mlpmodule.py:683] gpu experts func einsum cost 0.01254415512084961 s
DEBUG 01-13 08:46:32.977881.977881 cuda_h.py:19] end gpu_experts cost 0.012762069702148438 seconds
DEBUG 01-13 08:46:32.977836.977836 cuda_h.py:10] start cpu_thread_manager_mp_wait
DEBUG 01-13 08:46:32.977275.977275 cuda_h.py:19] end cpu_thread_manager_mp_wait cost 4.315376281738281e-05 seconds
DEBUG 01-13 08:46:32.977828.977828 cuda_h.py:19] end layer_moe_generate_mp_l_6 cost 0.06837177276611328 seconds
DEBUG 01-13 08:46:32.977644.977644 lmp.py:1550] -------------------------------- end prefill layer 5 --------------------------------
DEBUG 01-13 08:46:32.977520.977520 lmp.py:1493] -------------------------------- start prefill layer 6 --------------------------------
DEBUG 01-13 08:46:32.977753.977753 cuda_h.py:10] start start_load_qkvogn_s_weight_l_7
DEBUG 01-13 08:46:32.977562.977562 cuda_h.py:10] start start_load_qkvogn_s_weight_l_7
DEBUG 01-13 08:46:32.977750.977750 cuda_h.py:19] end start_load_qkvogn_s_weight_l_7 cost 3.743171691894531e-05 seconds
DEBUG 01-13 08:46:32.977221.977221 cuda_h.py:19] end start_load_qkvogn_s_weight_l_7 cost 7.2479248046875e-05 seconds
DEBUG 01-13 08:46:32.977301.977301 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-13 08:46:32.978185.978185 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-13 08:46:32.978501.978501 cuda_h.py:10] start sllm_worker_task
DEBUG 01-13 08:46:32.978759.978759 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-13 08:46:32.978956.978956 mlpmodule.py:785]  experts func einsum cost 0.06391024589538574 s
DEBUG 01-13 08:46:32.978927.978927 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-13 08:46:32.978243.978243 cuda_h.py:19] end experts_func_gpu_einsum_mp cost 0.06487441062927246 seconds
DEBUG 01-13 08:46:32.978423.978423 cuda_h.py:19] end allocate_cuda_memory cost 0.0003097057342529297 seconds
DEBUG 01-13 08:46:32.978214.978214 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-13 08:46:32.978467.978467 sllm_store_c.py:27] get device uuid map
DEBUG 01-13 08:46:32.979264.979264 sllm_store_c.py:29] call client load into gpu
DEBUG 01-13 08:46:32.979457.979457 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, aa4e17b3-506d-4b8e-b4be-747b99931b11
DEBUG 01-13 08:46:32.979382.979382 client.py:106] call stub.LoadModelAsync
DEBUG 01-13 08:46:32.979717.979717 cuda_h.py:10] start self_attn
INFO 01-13 08:46:32.980331.980331 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, aa4e17b3-506d-4b8e-b4be-747b99931b11
DEBUG 01-13 08:46:32.980659.980659 cuda_h.py:19] end load_into_gpu_async cost 0.0015783309936523438 seconds
DEBUG 01-13 08:46:32.980714.980714 cuda_h.py:10] start restore_tensors2
DEBUG 01-13 08:46:32.980612.980612 cuda_h.py:19] end restore_tensors2 cost 0.00010085105895996094 seconds
DEBUG 01-13 08:46:32.980620.980620 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0023360252380371094 seconds
INFO 01-13 08:46:32.980655.980655 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, aa4e17b3-506d-4b8e-b4be-747b99931b11
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-13 08:46:32.983692.983692 cuda_h.py:19] end self_attn cost 0.004306793212890625 seconds
DEBUG 01-13 08:46:32.984752.984752 cuda_h.py:19] end iln_self_attn_paln cost 0.006296634674072266 seconds
DEBUG 01-13 08:46:32.984384.984384 cuda_h.py:10] start layer_moe_generate_mp_l_7
DEBUG 01-13 08:46:32.984750.984750 cuda_h.py:10] start gate
DEBUG 01-13 08:46:32.985994.985994 cuda_h.py:19] end gate cost 0.0007333755493164062 seconds
DEBUG 01-13 08:46:32.985030.985030 cuda_h.py:10] start experts_map_get
DEBUG 01-13 08:46:32.985517.985517 lmp.py:1611] 
DEBUG 01-13 08:46:32.985517.985517 lmp.py:1611] Expert Token Distribution & Device Allocation:
DEBUG 01-13 08:46:32.985181.985181 lmp.py:1612]   Total experts: 64
DEBUG 01-13 08:46:32.985738.985738 lmp.py:1613]   CPU experts: 32 (50%)
DEBUG 01-13 08:46:32.985911.985911 lmp.py:1614]   GPU experts: 32 (50%)
DEBUG 01-13 08:46:32.985984.985984 lmp.py:1615] 
DEBUG 01-13 08:46:32.985984.985984 lmp.py:1615]   Expert ID | Tokens | Device
DEBUG 01-13 08:46:32.985011.985011 lmp.py:1616]   -----------------------------------
DEBUG 01-13 08:46:32.985522.985522 lmp.py:1622]   Expert  1 |     42 | CPU
DEBUG 01-13 08:46:32.985311.985311 lmp.py:1622]   Expert  7 |     57 | CPU
DEBUG 01-13 08:46:32.985669.985669 lmp.py:1622]   Expert 37 |     74 | CPU
DEBUG 01-13 08:46:32.985266.985266 lmp.py:1622]   Expert 18 |     78 | CPU
DEBUG 01-13 08:46:32.985147.985147 lmp.py:1622]   Expert 54 |     78 | CPU
DEBUG 01-13 08:46:32.985029.985029 lmp.py:1622]   Expert 17 |     80 | CPU
DEBUG 01-13 08:46:32.985387.985387 lmp.py:1622]   Expert  9 |     86 | CPU
DEBUG 01-13 08:46:32.985222.985222 lmp.py:1622]   Expert 13 |     90 | CPU
DEBUG 01-13 08:46:32.985580.985580 lmp.py:1622]   Expert 22 |     97 | CPU
DEBUG 01-13 08:46:32.985177.985177 lmp.py:1622]   Expert 58 |    105 | CPU
DEBUG 01-13 08:46:32.985250.985250 lmp.py:1622]   Expert  0 |    111 | CPU
DEBUG 01-13 08:46:32.985608.985608 lmp.py:1622]   Expert 16 |    117 | CPU
DEBUG 01-13 08:46:32.985444.985444 lmp.py:1622]   Expert 26 |    121 | CPU
DEBUG 01-13 08:46:32.985563.985563 lmp.py:1622]   Expert 10 |    125 | CPU
DEBUG 01-13 08:46:32.986445.986445 lmp.py:1622]   Expert 63 |    126 | CPU
DEBUG 01-13 08:46:32.986565.986565 lmp.py:1622]   Expert 33 |    139 | CPU
DEBUG 01-13 08:46:32.986684.986684 lmp.py:1622]   Expert 59 |    141 | CPU
DEBUG 01-13 08:46:32.986043.986043 lmp.py:1622]   Expert 28 |    145 | CPU
DEBUG 01-13 08:46:32.986354.986354 lmp.py:1622]   Expert 43 |    148 | CPU
DEBUG 01-13 08:46:32.986190.986190 lmp.py:1622]   Expert 62 |    148 | CPU
DEBUG 01-13 08:46:32.986786.986786 lmp.py:1622]   Expert 29 |    151 | CPU
DEBUG 01-13 08:46:32.986621.986621 lmp.py:1622]   Expert  2 |    157 | CPU
DEBUG 01-13 08:46:32.986503.986503 lmp.py:1622]   Expert 51 |    162 | CPU
DEBUG 01-13 08:46:32.986384.986384 lmp.py:1622]   Expert  3 |    163 | CPU
DEBUG 01-13 08:46:32.986027.986027 lmp.py:1622]   Expert 55 |    163 | CPU
DEBUG 01-13 08:46:32.986908.986908 lmp.py:1622]   Expert 11 |    165 | CPU
DEBUG 01-13 08:46:32.986551.986551 lmp.py:1622]   Expert 23 |    167 | CPU
DEBUG 01-13 08:46:32.986194.986194 lmp.py:1622]   Expert 32 |    167 | CPU
DEBUG 01-13 08:46:32.986076.986076 lmp.py:1622]   Expert 45 |    167 | CPU
DEBUG 01-13 08:46:32.986957.986957 lmp.py:1622]   Expert 40 |    170 | CPU
DEBUG 01-13 08:46:32.986792.986792 lmp.py:1622]   Expert 34 |    171 | CPU
DEBUG 01-13 08:46:32.986150.986150 lmp.py:1622]   Expert 53 |    172 | CPU
DEBUG 01-13 08:46:32.986509.986509 lmp.py:1622]   Expert 14 |    175 | GPU
DEBUG 01-13 08:46:32.986344.986344 lmp.py:1622]   Expert 52 |    177 | GPU
DEBUG 01-13 08:46:32.986225.986225 lmp.py:1622]   Expert 42 |    180 | GPU
DEBUG 01-13 08:46:32.986107.986107 lmp.py:1622]   Expert 41 |    182 | GPU
DEBUG 01-13 08:46:32.986750.986750 lmp.py:1622]   Expert 21 |    188 | GPU
DEBUG 01-13 08:46:32.986631.986631 lmp.py:1622]   Expert 57 |    195 | GPU
DEBUG 01-13 08:46:32.986751.986751 lmp.py:1622]   Expert 30 |    199 | GPU
DEBUG 01-13 08:46:32.986394.986394 lmp.py:1622]   Expert 15 |    204 | GPU
DEBUG 01-13 08:46:32.986275.986275 lmp.py:1622]   Expert 35 |    207 | GPU
DEBUG 01-13 08:46:32.986587.986587 lmp.py:1622]   Expert 12 |    213 | GPU
DEBUG 01-13 08:46:32.986422.986422 lmp.py:1622]   Expert  4 |    219 | GPU
DEBUG 01-13 08:46:32.986019.986019 lmp.py:1622]   Expert 49 |    228 | GPU
DEBUG 01-13 08:46:32.986092.986092 lmp.py:1622]   Expert 24 |    229 | GPU
DEBUG 01-13 08:46:32.986212.986212 lmp.py:1622]   Expert 46 |    229 | GPU
DEBUG 01-13 08:46:32.986332.986332 lmp.py:1622]   Expert 44 |    231 | GPU
DEBUG 01-13 08:46:32.986975.986975 lmp.py:1622]   Expert 50 |    232 | GPU
DEBUG 01-13 08:46:32.986856.986856 lmp.py:1622]   Expert 19 |    233 | GPU
DEBUG 01-13 08:46:32.986499.986499 lmp.py:1622]   Expert  8 |    236 | GPU
DEBUG 01-13 08:46:32.986381.986381 lmp.py:1622]   Expert 38 |    238 | GPU
DEBUG 01-13 08:46:32.986262.986262 lmp.py:1622]   Expert  6 |    246 | GPU
DEBUG 01-13 08:46:32.986143.986143 lmp.py:1622]   Expert 47 |    249 | GPU
DEBUG 01-13 08:46:32.986502.986502 lmp.py:1622]   Expert 61 |    258 | GPU
DEBUG 01-13 08:46:32.986098.986098 lmp.py:1622]   Expert 31 |    260 | GPU
DEBUG 01-13 08:46:32.986172.986172 lmp.py:1622]   Expert 39 |    281 | GPU
DEBUG 01-13 08:46:32.986484.986484 lmp.py:1622]   Expert  5 |    303 | GPU
DEBUG 01-13 08:46:32.986603.986603 lmp.py:1622]   Expert 36 |    304 | GPU
DEBUG 01-13 08:46:32.986246.986246 lmp.py:1622]   Expert 27 |    312 | GPU
DEBUG 01-13 08:46:32.986605.986605 lmp.py:1622]   Expert 60 |    331 | GPU
DEBUG 01-13 08:46:32.986486.986486 lmp.py:1622]   Expert 20 |    340 | GPU
DEBUG 01-13 08:46:32.986606.986606 lmp.py:1622]   Expert 48 |    376 | GPU
DEBUG 01-13 08:46:32.986487.986487 lmp.py:1622]   Expert 25 |    393 | GPU
DEBUG 01-13 08:46:32.986369.986369 lmp.py:1622]   Expert 56 |    557 | GPU
DEBUG 01-13 08:46:32.986442.986442 lmp.py:1623] 
DEBUG 01-13 08:46:32.986442.986442 lmp.py:1623]   CPU total tokens: 4083 (33.2%)
DEBUG 01-13 08:46:32.986708.986708 lmp.py:1624]   GPU total tokens: 8205 (66.8%)
DEBUG 01-13 08:46:32.986311.986311 cuda_h.py:19] end experts_map_get cost 0.0016512870788574219 seconds
DEBUG 01-13 08:46:32.987307.987307 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-13 08:46:32.987215.987215 lmp.py:1632] 
DEBUG 01-13 08:46:32.987215.987215 lmp.py:1632]   Computing 32 experts on CPU MP...
DEBUG 01-13 08:46:32.987482.987482 cuda_h.py:19] end cpu_experts_submit cost 6.318092346191406e-05 seconds
DEBUG 01-13 08:46:32.987986.987986 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-13 08:46:32.987538.987538 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-13 08:46:32.987636.987636 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-13 08:46:32.987566.987566 cuda_h.py:19] end allocate_cuda_memory cost 0.00022292137145996094 seconds
DEBUG 01-13 08:46:32.987707.987707 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-13 08:46:32.987370.987370 sllm_store_c.py:27] get device uuid map
DEBUG 01-13 08:46:32.987432.987432 sllm_store_c.py:29] call client load into gpu
DEBUG 01-13 08:46:32.987088.987088 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 9b0fdfd3-5657-424f-8243-709ef5b58a5a
DEBUG 01-13 08:46:32.988764.988764 client.py:106] call stub.LoadModelAsync
INFO 01-13 08:46:32.988730.988730 client.py:127] Model loaded
DEBUG 01-13 08:46:32.988018.988018 cuda_h.py:10] start restore2model
DEBUG 01-13 08:46:32.989297.989297 cuda_h.py:10] start experts_func_gpu_einsum_mp
DEBUG 01-13 08:46:32.989689.989689 cuda_h.py:19] end restore2model cost 0.0006105899810791016 seconds
DEBUG 01-13 08:46:32.989831.989831 cuda_h.py:19] end sllm_worker_task cost 0.01128077507019043 seconds
INFO 01-13 08:46:32.989146.989146 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 9b0fdfd3-5657-424f-8243-709ef5b58a5a
DEBUG 01-13 08:46:32.990638.990638 cuda_h.py:19] end load_into_gpu_async cost 0.002265453338623047 seconds
DEBUG 01-13 08:46:32.990679.990679 cuda_h.py:10] start restore_tensors2
DEBUG 01-13 08:46:32.990942.990942 cuda_h.py:19] end restore_tensors2 cost 0.0005171298980712891 seconds
DEBUG 01-13 08:46:32.990190.990190 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.003439664840698242 seconds
DEBUG 01-13 08:46:32.990788.990788 cuda_h.py:10] start restore2model
DEBUG 01-13 08:46:32.993028.993028 cuda_h.py:19] end restore2model cost 0.002779722213745117 seconds
DEBUG 01-13 08:46:32.993109.993109 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.006424427032470703 seconds
DEBUG 01-13 08:46:32.993428.993428 cuda_h.py:10] start gpu_sexperts
DEBUG 01-13 08:46:32.993433.993433 cuda_h.py:19] end gpu_sexperts cost 0.00030803680419921875 seconds
DEBUG 01-13 08:46:32.994031.994031 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-13 08:46:32.994999.994999 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 1.8596649169921875e-05 seconds
DEBUG 01-13 08:46:32.994980.994980 cuda_h.py:10] start wait_experts
INFO 01-13 08:46:32.994869.994869 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 9b0fdfd3-5657-424f-8243-709ef5b58a5a
DEBUG 01-13 08:46:33.000758.000758 mlpmodule.py:1006] group tensors cost 0.01047825813293457 s
DEBUG 01-13 08:46:33.003909.003909 mlpmodule.py:1044] pad cost 0.0019922256469726562 s
DEBUG 01-13 08:46:33.003151.003151 mlpmodule.py:1050] create cpu tensor cost 5.125999450683594e-05 s
DEBUG 01-13 08:46:33.003346.003346 mlpmodule.py:1055] move to cpu cost 3.910064697265625e-05 s
DEBUG 01-13 08:46:33.011458.011458 mlpmodule.py:1069] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-13 08:46:33.011139.011139 mlpmodule.py:1070] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-13 08:46:33.011249.011249 mlpmodule.py:1075] group_w3 first element: -0.003631591796875
WARNING 01-13 08:46:33.011592.011592 mlpmodule.py:1085] start einsum2
DEBUG 01-13 08:46:33.025760.025760 mlpmodule.py:1095] group einsum cost 0.022000551223754883 s
DEBUG 01-13 08:46:33.026810.026810 mlpmodule.py:1103] cpy2cputensor cost 0.0006561279296875 s
INFO 01-13 08:46:33.040993.040993 client.py:127] Model loaded
DEBUG 01-13 08:46:33.040827.040827 cuda_h.py:19] end wait_experts cost 0.04678916931152344 seconds
DEBUG 01-13 08:46:33.041618.041618 cuda_h.py:10] start gpu_experts
DEBUG 01-13 08:46:33.042927.042927 mlpmodule.py:559] gpu group tensors cost 0.0013666152954101562 s
DEBUG 01-13 08:46:33.046967.046967 mlpmodule.py:592] gpu pad cost 0.004221439361572266 s
DEBUG 01-13 08:46:33.047496.047496 mlpmodule.py:598] start_w1
DEBUG 01-13 08:46:33.047076.047076 mlpmodule.py:602] start_w3
DEBUG 01-13 08:46:33.047075.047075 mlpmodule.py:608] start_w2
DEBUG 01-13 08:46:33.048570.048570 mlpmodule.py:611] gpu group einsum cost 0.0012121200561523438 s
DEBUG 01-13 08:46:33.049594.049594 mlpmodule.py:785]  experts func einsum cost 0.059598684310913086 s
DEBUG 01-13 08:46:33.049157.049157 cuda_h.py:19] end experts_func_gpu_einsum_mp cost 0.06042599678039551 seconds
DEBUG 01-13 08:46:33.054919.054919 mlpmodule.py:683] gpu experts func einsum cost 0.013192176818847656 s
DEBUG 01-13 08:46:33.054946.054946 cuda_h.py:19] end gpu_experts cost 0.013470172882080078 seconds
DEBUG 01-13 08:46:33.054438.054438 cuda_h.py:10] start cpu_thread_manager_mp_wait
DEBUG 01-13 08:46:33.054397.054397 cuda_h.py:19] end cpu_thread_manager_mp_wait cost 6.890296936035156e-05 seconds
DEBUG 01-13 08:46:33.054648.054648 cuda_h.py:19] end layer_moe_generate_mp_l_7 cost 0.07052874565124512 seconds
DEBUG 01-13 08:46:33.055518.055518 lmp.py:1550] -------------------------------- end prefill layer 6 --------------------------------
DEBUG 01-13 08:46:33.055515.055515 lmp.py:1493] -------------------------------- start prefill layer 7 --------------------------------
DEBUG 01-13 08:46:33.055895.055895 cuda_h.py:10] start start_load_qkvogn_s_weight_l_8
DEBUG 01-13 08:46:33.055578.055578 cuda_h.py:10] start start_load_qkvogn_s_weight_l_8
DEBUG 01-13 08:46:33.055375.055375 cuda_h.py:19] end start_load_qkvogn_s_weight_l_8 cost 3.1948089599609375e-05 seconds
DEBUG 01-13 08:46:33.055701.055701 cuda_h.py:19] end start_load_qkvogn_s_weight_l_8 cost 6.508827209472656e-05 seconds
DEBUG 01-13 08:46:33.055920.055920 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-13 08:46:33.055770.055770 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-13 08:46:33.055775.055775 cuda_h.py:10] start sllm_worker_task
DEBUG 01-13 08:46:33.056412.056412 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-13 08:46:33.056882.056882 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-13 08:46:33.056742.056742 cuda_h.py:19] end allocate_cuda_memory cost 0.00030732154846191406 seconds
DEBUG 01-13 08:46:33.056361.056361 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-13 08:46:33.056647.056647 sllm_store_c.py:27] get device uuid map
DEBUG 01-13 08:46:33.056603.056603 sllm_store_c.py:29] call client load into gpu
DEBUG 01-13 08:46:33.057789.057789 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, f88855c8-f7fe-496b-8d9b-ec805e458ee2
DEBUG 01-13 08:46:33.057640.057640 client.py:106] call stub.LoadModelAsync
DEBUG 01-13 08:46:33.057583.057583 cuda_h.py:10] start self_attn
INFO 01-13 08:46:33.058683.058683 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, f88855c8-f7fe-496b-8d9b-ec805e458ee2
DEBUG 01-13 08:46:33.058365.058365 cuda_h.py:19] end load_into_gpu_async cost 0.0018451213836669922 seconds
DEBUG 01-13 08:46:33.058077.058077 cuda_h.py:10] start restore_tensors2
DEBUG 01-13 08:46:33.059270.059270 cuda_h.py:19] end restore_tensors2 cost 0.00016546249389648438 seconds
DEBUG 01-13 08:46:33.059380.059380 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.002892017364501953 seconds
INFO 01-13 08:46:33.059889.059889 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, f88855c8-f7fe-496b-8d9b-ec805e458ee2
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-13 08:46:33.061084.061084 cuda_h.py:19] end self_attn cost 0.00417327880859375 seconds
DEBUG 01-13 08:46:33.062526.062526 cuda_h.py:19] end iln_self_attn_paln cost 0.006206035614013672 seconds
DEBUG 01-13 08:46:33.062059.062059 cuda_h.py:10] start layer_moe_generate_mp_l_8
DEBUG 01-13 08:46:33.062265.062265 cuda_h.py:10] start gate
DEBUG 01-13 08:46:33.062375.062375 cuda_h.py:19] end gate cost 0.0006706714630126953 seconds
DEBUG 01-13 08:46:33.062563.062563 cuda_h.py:10] start experts_map_get
DEBUG 01-13 08:46:33.063237.063237 lmp.py:1611] 
DEBUG 01-13 08:46:33.063237.063237 lmp.py:1611] Expert Token Distribution & Device Allocation:
DEBUG 01-13 08:46:33.063292.063292 lmp.py:1612]   Total experts: 64
DEBUG 01-13 08:46:33.063048.063048 lmp.py:1613]   CPU experts: 32 (50%)
DEBUG 01-13 08:46:33.063274.063274 lmp.py:1614]   GPU experts: 32 (50%)
DEBUG 01-13 08:46:33.063143.063143 lmp.py:1615] 
DEBUG 01-13 08:46:33.063143.063143 lmp.py:1615]   Expert ID | Tokens | Device
DEBUG 01-13 08:46:33.063269.063269 lmp.py:1616]   -----------------------------------
DEBUG 01-13 08:46:33.063972.063972 lmp.py:1622]   Expert 50 |     47 | CPU
DEBUG 01-13 08:46:33.063715.063715 lmp.py:1622]   Expert  3 |     57 | CPU
DEBUG 01-13 08:46:33.063503.063503 lmp.py:1622]   Expert 46 |     57 | CPU
DEBUG 01-13 08:46:33.063054.063054 lmp.py:1622]   Expert  1 |     82 | CPU
DEBUG 01-13 08:46:33.063081.063081 lmp.py:1622]   Expert 29 |     87 | CPU
DEBUG 01-13 08:46:33.063870.063870 lmp.py:1622]   Expert  4 |     88 | CPU
DEBUG 01-13 08:46:33.063089.063089 lmp.py:1622]   Expert 40 |     95 | CPU
DEBUG 01-13 08:46:33.063308.063308 lmp.py:1622]   Expert 15 |     96 | CPU
DEBUG 01-13 08:46:33.063527.063527 lmp.py:1622]   Expert  8 |    109 | CPU
DEBUG 01-13 08:46:33.063839.063839 lmp.py:1622]   Expert 41 |    112 | CPU
DEBUG 01-13 08:46:33.063151.063151 lmp.py:1622]   Expert 28 |    121 | CPU
DEBUG 01-13 08:46:33.063463.063463 lmp.py:1622]   Expert 48 |    129 | CPU
DEBUG 01-13 08:46:33.063298.063298 lmp.py:1622]   Expert 13 |    130 | CPU
DEBUG 01-13 08:46:33.063133.063133 lmp.py:1622]   Expert 16 |    131 | CPU
DEBUG 01-13 08:46:33.063207.063207 lmp.py:1622]   Expert  6 |    132 | CPU
DEBUG 01-13 08:46:33.063042.063042 lmp.py:1622]   Expert 27 |    136 | CPU
DEBUG 01-13 08:46:33.063354.063354 lmp.py:1622]   Expert 51 |    136 | CPU
DEBUG 01-13 08:46:33.063189.063189 lmp.py:1622]   Expert 54 |    136 | CPU
DEBUG 01-13 08:46:33.063501.063501 lmp.py:1622]   Expert  7 |    137 | CPU
DEBUG 01-13 08:46:33.063243.063243 lmp.py:1622]   Expert 60 |    138 | CPU
DEBUG 01-13 08:46:33.063078.063078 lmp.py:1622]   Expert 56 |    141 | CPU
DEBUG 01-13 08:46:33.063152.063152 lmp.py:1622]   Expert 18 |    142 | CPU
DEBUG 01-13 08:46:33.063510.063510 lmp.py:1622]   Expert 14 |    143 | CPU
DEBUG 01-13 08:46:33.063583.063583 lmp.py:1622]   Expert 20 |    143 | CPU
DEBUG 01-13 08:46:33.063180.063180 lmp.py:1622]   Expert 39 |    144 | CPU
DEBUG 01-13 08:46:33.063777.063777 lmp.py:1622]   Expert 52 |    147 | CPU
DEBUG 01-13 08:46:33.063612.063612 lmp.py:1622]   Expert 36 |    148 | CPU
DEBUG 01-13 08:46:33.063208.063208 lmp.py:1622]   Expert 55 |    149 | CPU
DEBUG 01-13 08:46:33.064805.064805 lmp.py:1622]   Expert 43 |    153 | CPU
DEBUG 01-13 08:46:33.064640.064640 lmp.py:1622]   Expert 10 |    156 | CPU
DEBUG 01-13 08:46:33.064051.064051 lmp.py:1622]   Expert 45 |    156 | CPU
DEBUG 01-13 08:46:33.064555.064555 lmp.py:1622]   Expert 11 |    158 | CPU
DEBUG 01-13 08:46:33.064298.064298 lmp.py:1622]   Expert 33 |    159 | GPU
DEBUG 01-13 08:46:33.064371.064371 lmp.py:1622]   Expert  5 |    160 | GPU
DEBUG 01-13 08:46:33.064206.064206 lmp.py:1622]   Expert 62 |    161 | GPU
DEBUG 01-13 08:46:33.064803.064803 lmp.py:1622]   Expert 44 |    171 | GPU
DEBUG 01-13 08:46:33.064876.064876 lmp.py:1622]   Expert 57 |    172 | GPU
DEBUG 01-13 08:46:33.064235.064235 lmp.py:1622]   Expert 58 |    182 | GPU
DEBUG 01-13 08:46:33.064070.064070 lmp.py:1622]   Expert 25 |    183 | GPU
DEBUG 01-13 08:46:33.064481.064481 lmp.py:1622]   Expert 53 |    183 | GPU
DEBUG 01-13 08:46:33.064747.064747 lmp.py:1622]   Expert 32 |    190 | GPU
DEBUG 01-13 08:46:33.064489.064489 lmp.py:1622]   Expert  2 |    194 | GPU
DEBUG 01-13 08:46:33.064563.064563 lmp.py:1622]   Expert 31 |    198 | GPU
DEBUG 01-13 08:46:33.064636.064636 lmp.py:1622]   Expert 49 |    199 | GPU
DEBUG 01-13 08:46:33.064233.064233 lmp.py:1622]   Expert 63 |    201 | GPU
DEBUG 01-13 08:46:33.064068.064068 lmp.py:1622]   Expert 17 |    204 | GPU
DEBUG 01-13 08:46:33.064664.064664 lmp.py:1622]   Expert 35 |    207 | GPU
DEBUG 01-13 08:46:33.064738.064738 lmp.py:1622]   Expert 21 |    208 | GPU
DEBUG 01-13 08:46:33.064363.064363 lmp.py:1622]   Expert 42 |    214 | GPU
DEBUG 01-13 08:46:33.064867.064867 lmp.py:1622]   Expert 34 |    218 | GPU
DEBUG 01-13 08:46:33.064491.064491 lmp.py:1622]   Expert 37 |    220 | GPU
DEBUG 01-13 08:46:33.064617.064617 lmp.py:1622]   Expert 22 |    231 | GPU
DEBUG 01-13 08:46:33.064552.064552 lmp.py:1622]   Expert 59 |    235 | GPU
DEBUG 01-13 08:46:33.064486.064486 lmp.py:1622]   Expert  0 |    245 | GPU
DEBUG 01-13 08:46:33.064898.064898 lmp.py:1622]   Expert 19 |    252 | GPU
DEBUG 01-13 08:46:33.064594.064594 lmp.py:1622]   Expert 24 |    280 | GPU
DEBUG 01-13 08:46:33.064051.064051 lmp.py:1622]   Expert 61 |    283 | GPU
DEBUG 01-13 08:46:33.064701.064701 lmp.py:1622]   Expert 30 |    300 | GPU
DEBUG 01-13 08:46:33.064113.064113 lmp.py:1622]   Expert 47 |    320 | GPU
DEBUG 01-13 08:46:33.064001.064001 lmp.py:1622]   Expert 38 |    365 | GPU
DEBUG 01-13 08:46:33.064174.064174 lmp.py:1622]   Expert 26 |    376 | GPU
DEBUG 01-13 08:46:33.064108.064108 lmp.py:1622]   Expert 12 |    429 | GPU
DEBUG 01-13 08:46:33.064904.064904 lmp.py:1622]   Expert  9 |    689 | GPU
DEBUG 01-13 08:46:33.064123.064123 lmp.py:1622]   Expert 23 |    723 | GPU
DEBUG 01-13 08:46:33.064965.064965 lmp.py:1623] 
DEBUG 01-13 08:46:33.064965.064965 lmp.py:1623]   CPU total tokens: 3936 (32.0%)
DEBUG 01-13 08:46:33.064045.064045 lmp.py:1624]   GPU total tokens: 8352 (68.0%)
DEBUG 01-13 08:46:33.064132.064132 cuda_h.py:19] end experts_map_get cost 0.0019295215606689453 seconds
DEBUG 01-13 08:46:33.064585.064585 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-13 08:46:33.065925.065925 lmp.py:1632] 
DEBUG 01-13 08:46:33.065925.065925 lmp.py:1632]   Computing 32 experts on CPU MP...
DEBUG 01-13 08:46:33.065814.065814 cuda_h.py:19] end cpu_experts_submit cost 5.8650970458984375e-05 seconds
DEBUG 01-13 08:46:33.065656.065656 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-13 08:46:33.065552.065552 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-13 08:46:33.065134.065134 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-13 08:46:33.065002.065002 cuda_h.py:19] end allocate_cuda_memory cost 0.0003523826599121094 seconds
DEBUG 01-13 08:46:33.066615.066615 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-13 08:46:33.066697.066697 sllm_store_c.py:27] get device uuid map
DEBUG 01-13 08:46:33.066871.066871 sllm_store_c.py:29] call client load into gpu
DEBUG 01-13 08:46:33.066264.066264 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 1dce847e-3af4-4208-af3a-ca47551e0d9d
DEBUG 01-13 08:46:33.066947.066947 client.py:106] call stub.LoadModelAsync
INFO 01-13 08:46:33.066505.066505 client.py:127] Model loaded
DEBUG 01-13 08:46:33.067232.067232 cuda_h.py:10] start restore2model
DEBUG 01-13 08:46:33.067503.067503 cuda_h.py:10] start experts_func_gpu_einsum_mp
DEBUG 01-13 08:46:33.068686.068686 cuda_h.py:19] end restore2model cost 0.0010044574737548828 seconds
DEBUG 01-13 08:46:33.068048.068048 cuda_h.py:19] end sllm_worker_task cost 0.01207733154296875 seconds
INFO 01-13 08:46:33.068296.068296 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 1dce847e-3af4-4208-af3a-ca47551e0d9d
DEBUG 01-13 08:46:33.068486.068486 cuda_h.py:19] end load_into_gpu_async cost 0.0024073123931884766 seconds
DEBUG 01-13 08:46:33.068149.068149 cuda_h.py:10] start restore_tensors2
DEBUG 01-13 08:46:33.069477.069477 cuda_h.py:19] end restore_tensors2 cost 0.0004601478576660156 seconds
DEBUG 01-13 08:46:33.069810.069810 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.004128932952880859 seconds
DEBUG 01-13 08:46:33.069957.069957 cuda_h.py:10] start restore2model
DEBUG 01-13 08:46:33.072329.072329 cuda_h.py:19] end restore2model cost 0.002773761749267578 seconds
DEBUG 01-13 08:46:33.072570.072570 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.007109642028808594 seconds
DEBUG 01-13 08:46:33.072935.072935 cuda_h.py:10] start gpu_sexperts
DEBUG 01-13 08:46:33.072808.072808 cuda_h.py:19] end gpu_sexperts cost 0.00033211708068847656 seconds
DEBUG 01-13 08:46:33.072022.072022 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-13 08:46:33.072567.072567 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 1.6927719116210938e-05 seconds
DEBUG 01-13 08:46:33.072740.072740 cuda_h.py:10] start wait_experts
INFO 01-13 08:46:33.072581.072581 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 1dce847e-3af4-4208-af3a-ca47551e0d9d
DEBUG 01-13 08:46:33.080318.080318 mlpmodule.py:1006] group tensors cost 0.010945320129394531 s
DEBUG 01-13 08:46:33.083837.083837 mlpmodule.py:1044] pad cost 0.0027773380279541016 s
DEBUG 01-13 08:46:33.083888.083888 mlpmodule.py:1050] create cpu tensor cost 6.580352783203125e-05 s
DEBUG 01-13 08:46:33.083401.083401 mlpmodule.py:1055] move to cpu cost 4.792213439941406e-05 s
DEBUG 01-13 08:46:33.097222.097222 mlpmodule.py:1069] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-13 08:46:33.097851.097851 mlpmodule.py:1070] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-13 08:46:33.097317.097317 mlpmodule.py:1075] group_w3 first element: 0.01263427734375
WARNING 01-13 08:46:33.097341.097341 mlpmodule.py:1085] start einsum2
DEBUG 01-13 08:46:33.111893.111893 mlpmodule.py:1095] group einsum cost 0.02805042266845703 s
DEBUG 01-13 08:46:33.112697.112697 mlpmodule.py:1103] cpy2cputensor cost 0.0006644725799560547 s
INFO 01-13 08:46:33.118831.118831 client.py:127] Model loaded
DEBUG 01-13 08:46:33.118234.118234 cuda_h.py:19] end wait_experts cost 0.04595661163330078 seconds
DEBUG 01-13 08:46:33.118773.118773 cuda_h.py:10] start gpu_experts
DEBUG 01-13 08:46:33.120277.120277 mlpmodule.py:559] gpu group tensors cost 0.0013964176177978516 s
DEBUG 01-13 08:46:33.125252.125252 mlpmodule.py:592] gpu pad cost 0.004845380783081055 s
DEBUG 01-13 08:46:33.125047.125047 mlpmodule.py:598] start_w1
DEBUG 01-13 08:46:33.126187.126187 mlpmodule.py:602] start_w3
DEBUG 01-13 08:46:33.126082.126082 mlpmodule.py:608] start_w2
DEBUG 01-13 08:46:33.127246.127246 mlpmodule.py:611] gpu group einsum cost 0.0013859272003173828 s
DEBUG 01-13 08:46:33.130637.130637 mlpmodule.py:683] gpu experts func einsum cost 0.011621236801147461 s
DEBUG 01-13 08:46:33.130575.130575 cuda_h.py:19] end gpu_experts cost 0.011831045150756836 seconds
DEBUG 01-13 08:46:33.130398.130398 cuda_h.py:10] start cpu_thread_manager_mp_wait
DEBUG 01-13 08:46:33.130236.130236 cuda_h.py:19] end cpu_thread_manager_mp_wait cost 4.220008850097656e-05 seconds
DEBUG 01-13 08:46:33.130491.130491 cuda_h.py:19] end layer_moe_generate_mp_l_8 cost 0.06885170936584473 seconds
DEBUG 01-13 08:46:33.131534.131534 lmp.py:1550] -------------------------------- end prefill layer 7 --------------------------------
DEBUG 01-13 08:46:33.131807.131807 lmp.py:1493] -------------------------------- start prefill layer 8 --------------------------------
DEBUG 01-13 08:46:33.131716.131716 cuda_h.py:10] start start_load_qkvogn_s_weight_l_9
DEBUG 01-13 08:46:33.131916.131916 cuda_h.py:10] start start_load_qkvogn_s_weight_l_9
DEBUG 01-13 08:46:33.131309.131309 cuda_h.py:19] end start_load_qkvogn_s_weight_l_9 cost 3.838539123535156e-05 seconds
DEBUG 01-13 08:46:33.131147.131147 cuda_h.py:10] start sllm_worker_task
DEBUG 01-13 08:46:33.131070.131070 cuda_h.py:19] end start_load_qkvogn_s_weight_l_9 cost 0.00021314620971679688 seconds
DEBUG 01-13 08:46:33.131737.131737 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-13 08:46:33.131415.131415 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-13 08:46:33.132811.132811 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-13 08:46:33.132425.132425 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-13 08:46:33.132170.132170 cuda_h.py:19] end allocate_cuda_memory cost 0.00040221214294433594 seconds
DEBUG 01-13 08:46:33.132755.132755 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-13 08:46:33.133791.133791 sllm_store_c.py:27] get device uuid map
DEBUG 01-13 08:46:33.133153.133153 sllm_store_c.py:29] call client load into gpu
DEBUG 01-13 08:46:33.133355.133355 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 9aa537af-69f6-4a52-8246-a8dd081b93d8
DEBUG 01-13 08:46:33.133607.133607 client.py:106] call stub.LoadModelAsync
DEBUG 01-13 08:46:33.133882.133882 cuda_h.py:10] start self_attn
INFO 01-13 08:46:33.135508.135508 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 9aa537af-69f6-4a52-8246-a8dd081b93d8
DEBUG 01-13 08:46:33.135691.135691 cuda_h.py:19] end load_into_gpu_async cost 0.0021347999572753906 seconds
DEBUG 01-13 08:46:33.135554.135554 cuda_h.py:10] start restore_tensors2
DEBUG 01-13 08:46:33.135760.135760 cuda_h.py:19] end restore_tensors2 cost 0.0001461505889892578 seconds
DEBUG 01-13 08:46:33.135817.135817 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0035963058471679688 seconds
INFO 01-13 08:46:33.135477.135477 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 9aa537af-69f6-4a52-8246-a8dd081b93d8
DEBUG 01-13 08:46:33.137502.137502 mlpmodule.py:785]  experts func einsum cost 0.06789398193359375 s
DEBUG 01-13 08:46:33.137238.137238 cuda_h.py:19] end experts_func_gpu_einsum_mp cost 0.06966948509216309 seconds
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-13 08:46:33.138801.138801 cuda_h.py:19] end self_attn cost 0.004597902297973633 seconds
DEBUG 01-13 08:46:33.138890.138890 cuda_h.py:19] end iln_self_attn_paln cost 0.00664830207824707 seconds
DEBUG 01-13 08:46:33.138065.138065 cuda_h.py:10] start layer_moe_generate_mp_l_9
DEBUG 01-13 08:46:33.138351.138351 cuda_h.py:10] start gate
DEBUG 01-13 08:46:33.139718.139718 cuda_h.py:19] end gate cost 0.0006582736968994141 seconds
DEBUG 01-13 08:46:33.139455.139455 cuda_h.py:10] start experts_map_get
DEBUG 01-13 08:46:33.139432.139432 lmp.py:1611] 
DEBUG 01-13 08:46:33.139432.139432 lmp.py:1611] Expert Token Distribution & Device Allocation:
DEBUG 01-13 08:46:33.139711.139711 lmp.py:1612]   Total experts: 64
DEBUG 01-13 08:46:33.139606.139606 lmp.py:1613]   CPU experts: 32 (50%)
DEBUG 01-13 08:46:33.139348.139348 lmp.py:1614]   GPU experts: 32 (50%)
DEBUG 01-13 08:46:33.139230.139230 lmp.py:1615] 
DEBUG 01-13 08:46:33.139230.139230 lmp.py:1615]   Expert ID | Tokens | Device
DEBUG 01-13 08:46:33.140588.140588 lmp.py:1616]   -----------------------------------
DEBUG 01-13 08:46:33.140715.140715 lmp.py:1622]   Expert 38 |     10 | CPU
DEBUG 01-13 08:46:33.140642.140642 lmp.py:1622]   Expert 39 |     67 | CPU
DEBUG 01-13 08:46:33.140855.140855 lmp.py:1622]   Expert  7 |     70 | CPU
DEBUG 01-13 08:46:33.140829.140829 lmp.py:1622]   Expert 30 |     78 | CPU
DEBUG 01-13 08:46:33.140803.140803 lmp.py:1622]   Expert 24 |     85 | CPU
DEBUG 01-13 08:46:33.140777.140777 lmp.py:1622]   Expert 14 |     94 | CPU
DEBUG 01-13 08:46:33.140989.140989 lmp.py:1622]   Expert 27 |     95 | CPU
DEBUG 01-13 08:46:33.140963.140963 lmp.py:1622]   Expert 17 |     97 | CPU
DEBUG 01-13 08:46:33.140938.140938 lmp.py:1622]   Expert 16 |     98 | CPU
DEBUG 01-13 08:46:33.140388.140388 lmp.py:1622]   Expert 32 |     98 | CPU
DEBUG 01-13 08:46:33.140793.140793 lmp.py:1622]   Expert 36 |    100 | CPU
DEBUG 01-13 08:46:33.140436.140436 lmp.py:1622]   Expert 40 |    100 | CPU
DEBUG 01-13 08:46:33.140079.140079 lmp.py:1622]   Expert 18 |    109 | CPU
DEBUG 01-13 08:46:33.140768.140768 lmp.py:1622]   Expert 48 |    115 | CPU
DEBUG 01-13 08:46:33.140265.140265 lmp.py:1622]   Expert 12 |    117 | CPU
DEBUG 01-13 08:46:33.140001.140001 lmp.py:1622]   Expert  1 |    123 | CPU
DEBUG 01-13 08:46:33.140737.140737 lmp.py:1622]   Expert  6 |    128 | CPU
DEBUG 01-13 08:46:33.140333.140333 lmp.py:1622]   Expert 59 |    131 | CPU
DEBUG 01-13 08:46:33.140976.140976 lmp.py:1622]   Expert 42 |    136 | CPU
DEBUG 01-13 08:46:33.140381.140381 lmp.py:1622]   Expert  0 |    141 | CPU
DEBUG 01-13 08:46:33.140309.140309 lmp.py:1622]   Expert 53 |    145 | CPU
DEBUG 01-13 08:46:33.140713.140713 lmp.py:1622]   Expert 22 |    146 | CPU
DEBUG 01-13 08:46:33.140092.140092 lmp.py:1622]   Expert 51 |    146 | CPU
DEBUG 01-13 08:46:33.140808.140808 lmp.py:1622]   Expert 60 |    165 | CPU
DEBUG 01-13 08:46:33.140557.140557 lmp.py:1622]   Expert  8 |    166 | CPU
DEBUG 01-13 08:46:33.140644.140644 lmp.py:1622]   Expert 29 |    169 | CPU
DEBUG 01-13 08:46:33.140440.140440 lmp.py:1622]   Expert 15 |    170 | CPU
DEBUG 01-13 08:46:33.140997.140997 lmp.py:1622]   Expert 35 |    171 | CPU
DEBUG 01-13 08:46:33.140793.140793 lmp.py:1622]   Expert 54 |    171 | CPU
DEBUG 01-13 08:46:33.140350.140350 lmp.py:1622]   Expert 44 |    173 | CPU
DEBUG 01-13 08:46:33.140907.140907 lmp.py:1622]   Expert 33 |    179 | CPU
DEBUG 01-13 08:46:33.140226.140226 lmp.py:1622]   Expert 34 |    180 | CPU
DEBUG 01-13 08:46:33.140935.140935 lmp.py:1622]   Expert 19 |    184 | GPU
DEBUG 01-13 08:46:33.140300.140300 lmp.py:1622]   Expert 20 |    189 | GPU
DEBUG 01-13 08:46:33.140188.140188 lmp.py:1622]   Expert  9 |    190 | GPU
DEBUG 01-13 08:46:33.140838.140838 lmp.py:1622]   Expert 47 |    191 | GPU
DEBUG 01-13 08:46:33.140488.140488 lmp.py:1622]   Expert  3 |    194 | GPU
DEBUG 01-13 08:46:33.140899.140899 lmp.py:1622]   Expert 56 |    194 | GPU
DEBUG 01-13 08:46:33.140311.140311 lmp.py:1622]   Expert 21 |    197 | GPU
DEBUG 01-13 08:46:33.140768.140768 lmp.py:1622]   Expert 46 |    201 | GPU
DEBUG 01-13 08:46:33.140365.140365 lmp.py:1622]   Expert 45 |    204 | GPU
DEBUG 01-13 08:46:33.140531.140531 lmp.py:1622]   Expert 28 |    208 | GPU
DEBUG 01-13 08:46:33.140412.140412 lmp.py:1622]   Expert 49 |    209 | GPU
DEBUG 01-13 08:46:33.140340.140340 lmp.py:1622]   Expert 57 |    219 | GPU
DEBUG 01-13 08:46:33.140745.140745 lmp.py:1622]   Expert  2 |    225 | GPU
DEBUG 01-13 08:46:33.140149.140149 lmp.py:1622]   Expert  4 |    225 | GPU
DEBUG 01-13 08:46:33.140031.140031 lmp.py:1622]   Expert 43 |    229 | GPU
DEBUG 01-13 08:46:33.140197.140197 lmp.py:1622]   Expert 13 |    232 | GPU
DEBUG 01-13 08:46:33.140601.140601 lmp.py:1622]   Expert 10 |    240 | GPU
DEBUG 01-13 08:46:33.141529.141529 lmp.py:1622]   Expert 50 |    240 | GPU
DEBUG 01-13 08:46:33.141172.141172 lmp.py:1622]   Expert 41 |    246 | GPU
DEBUG 01-13 08:46:33.141054.141054 lmp.py:1622]   Expert 26 |    256 | GPU
DEBUG 01-13 08:46:33.141664.141664 lmp.py:1622]   Expert 37 |    258 | GPU
DEBUG 01-13 08:46:33.141737.141737 lmp.py:1622]   Expert 63 |    261 | GPU
DEBUG 01-13 08:46:33.141142.141142 lmp.py:1622]   Expert 31 |    268 | GPU
DEBUG 01-13 08:46:33.141308.141308 lmp.py:1622]   Expert 61 |    277 | GPU
DEBUG 01-13 08:46:33.141666.141666 lmp.py:1622]   Expert 52 |    306 | GPU
DEBUG 01-13 08:46:33.141832.141832 lmp.py:1622]   Expert 58 |    322 | GPU
DEBUG 01-13 08:46:33.141191.141191 lmp.py:1622]   Expert 62 |    325 | GPU
DEBUG 01-13 08:46:33.141595.141595 lmp.py:1622]   Expert 55 |    344 | GPU
DEBUG 01-13 08:46:33.141238.141238 lmp.py:1622]   Expert 23 |    382 | GPU
DEBUG 01-13 08:46:33.141173.141173 lmp.py:1622]   Expert 11 |    383 | GPU
DEBUG 01-13 08:46:33.141008.141008 lmp.py:1622]   Expert 25 |    403 | GPU
DEBUG 01-13 08:46:33.141081.141081 lmp.py:1622]   Expert  5 |    513 | GPU
DEBUG 01-13 08:46:33.141347.141347 lmp.py:1623] 
DEBUG 01-13 08:46:33.141347.141347 lmp.py:1623]   CPU total tokens: 3973 (32.3%)
DEBUG 01-13 08:46:33.141420.141420 lmp.py:1624]   GPU total tokens: 8315 (67.7%)
DEBUG 01-13 08:46:33.141785.141785 cuda_h.py:19] end experts_map_get cost 0.0017237663269042969 seconds
DEBUG 01-13 08:46:33.141258.141258 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-13 08:46:33.141298.141298 lmp.py:1632] 
DEBUG 01-13 08:46:33.141298.141298 lmp.py:1632]   Computing 32 experts on CPU MP...
DEBUG 01-13 08:46:33.141750.141750 cuda_h.py:19] end cpu_experts_submit cost 5.245208740234375e-05 seconds
DEBUG 01-13 08:46:33.141970.141970 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-13 08:46:33.141892.141892 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-13 08:46:33.142904.142904 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-13 08:46:33.142935.142935 cuda_h.py:19] end allocate_cuda_memory cost 0.0002903938293457031 seconds
DEBUG 01-13 08:46:33.142639.142639 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-13 08:46:33.142164.142164 sllm_store_c.py:27] get device uuid map
DEBUG 01-13 08:46:33.143947.143947 sllm_store_c.py:29] call client load into gpu
DEBUG 01-13 08:46:33.143888.143888 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 8aa33479-b228-4e16-9948-cce32fb85b80
DEBUG 01-13 08:46:33.143249.143249 cuda_h.py:10] start experts_func_gpu_einsum_mp
DEBUG 01-13 08:46:33.143352.143352 client.py:106] call stub.LoadModelAsync
INFO 01-13 08:46:33.143621.143621 client.py:127] Model loaded
DEBUG 01-13 08:46:33.143093.143093 cuda_h.py:10] start restore2model
DEBUG 01-13 08:46:33.144527.144527 cuda_h.py:19] end restore2model cost 0.0009922981262207031 seconds
DEBUG 01-13 08:46:33.144782.144782 cuda_h.py:19] end sllm_worker_task cost 0.013036489486694336 seconds
INFO 01-13 08:46:33.145284.145284 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 8aa33479-b228-4e16-9948-cce32fb85b80
DEBUG 01-13 08:46:33.145518.145518 cuda_h.py:19] end load_into_gpu_async cost 0.002263307571411133 seconds
DEBUG 01-13 08:46:33.145459.145459 cuda_h.py:10] start restore_tensors2
DEBUG 01-13 08:46:33.145217.145217 cuda_h.py:19] end restore_tensors2 cost 0.0004627704620361328 seconds
DEBUG 01-13 08:46:33.145113.145113 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.003432750701904297 seconds
DEBUG 01-13 08:46:33.145737.145737 cuda_h.py:10] start restore2model
DEBUG 01-13 08:46:33.148732.148732 cuda_h.py:19] end restore2model cost 0.002774953842163086 seconds
DEBUG 01-13 08:46:33.148026.148026 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.00718235969543457 seconds
DEBUG 01-13 08:46:33.148106.148106 cuda_h.py:10] start gpu_sexperts
DEBUG 01-13 08:46:33.149626.149626 cuda_h.py:19] end gpu_sexperts cost 0.0002834796905517578 seconds
DEBUG 01-13 08:46:33.149694.149694 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-13 08:46:33.149994.149994 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 1.6450881958007812e-05 seconds
DEBUG 01-13 08:46:33.149451.149451 cuda_h.py:10] start wait_experts
INFO 01-13 08:46:33.149962.149962 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 8aa33479-b228-4e16-9948-cce32fb85b80
DEBUG 01-13 08:46:33.152534.152534 mlpmodule.py:1006] group tensors cost 0.008941173553466797 s
DEBUG 01-13 08:46:33.155263.155263 mlpmodule.py:1044] pad cost 0.002009153366088867 s
DEBUG 01-13 08:46:33.155743.155743 mlpmodule.py:1050] create cpu tensor cost 5.0067901611328125e-05 s
DEBUG 01-13 08:46:33.155176.155176 mlpmodule.py:1055] move to cpu cost 3.886222839355469e-05 s
DEBUG 01-13 08:46:33.163195.163195 mlpmodule.py:1069] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-13 08:46:33.163307.163307 mlpmodule.py:1070] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-13 08:46:33.163602.163602 mlpmodule.py:1075] group_w3 first element: 0.0859375
WARNING 01-13 08:46:33.163382.163382 mlpmodule.py:1085] start einsum2
DEBUG 01-13 08:46:33.175077.175077 mlpmodule.py:1095] group einsum cost 0.01990222930908203 s
DEBUG 01-13 08:46:33.176450.176450 mlpmodule.py:1103] cpy2cputensor cost 0.000667572021484375 s
INFO 01-13 08:46:33.195978.195978 client.py:127] Model loaded
DEBUG 01-13 08:46:33.195455.195455 cuda_h.py:19] end wait_experts cost 0.046712398529052734 seconds
DEBUG 01-13 08:46:33.196669.196669 cuda_h.py:10] start gpu_experts
DEBUG 01-13 08:46:33.196673.196673 mlpmodule.py:785]  experts func einsum cost 0.052451133728027344 s
DEBUG 01-13 08:46:33.196306.196306 cuda_h.py:19] end experts_func_gpu_einsum_mp cost 0.053446292877197266 seconds
DEBUG 01-13 08:46:33.197152.197152 mlpmodule.py:559] gpu group tensors cost 0.0013885498046875 s
DEBUG 01-13 08:46:33.202144.202144 mlpmodule.py:592] gpu pad cost 0.004395008087158203 s
DEBUG 01-13 08:46:33.202318.202318 mlpmodule.py:598] start_w1
DEBUG 01-13 08:46:33.202108.202108 mlpmodule.py:602] start_w3
DEBUG 01-13 08:46:33.203752.203752 mlpmodule.py:608] start_w2
DEBUG 01-13 08:46:33.203315.203315 mlpmodule.py:611] gpu group einsum cost 0.0015187263488769531 s
DEBUG 01-13 08:46:33.209991.209991 mlpmodule.py:683] gpu experts func einsum cost 0.013008356094360352 s
DEBUG 01-13 08:46:33.209385.209385 cuda_h.py:19] end gpu_experts cost 0.01320791244506836 seconds
DEBUG 01-13 08:46:33.209863.209863 cuda_h.py:10] start cpu_thread_manager_mp_wait
DEBUG 01-13 08:46:33.209065.209065 cuda_h.py:19] end cpu_thread_manager_mp_wait cost 4.4345855712890625e-05 seconds
DEBUG 01-13 08:46:33.209478.209478 cuda_h.py:19] end layer_moe_generate_mp_l_9 cost 0.07067179679870605 seconds
DEBUG 01-13 08:46:33.209778.209778 lmp.py:1550] -------------------------------- end prefill layer 8 --------------------------------
DEBUG 01-13 08:46:33.209515.209515 lmp.py:1493] -------------------------------- start prefill layer 9 --------------------------------
DEBUG 01-13 08:46:33.209510.209510 cuda_h.py:10] start start_load_qkvogn_s_weight_l_10
DEBUG 01-13 08:46:33.209557.209557 cuda_h.py:10] start start_load_qkvogn_s_weight_l_10
DEBUG 01-13 08:46:33.209930.209930 cuda_h.py:19] end start_load_qkvogn_s_weight_l_10 cost 3.2901763916015625e-05 seconds
DEBUG 01-13 08:46:33.209262.209262 cuda_h.py:19] end start_load_qkvogn_s_weight_l_10 cost 7.104873657226562e-05 seconds
DEBUG 01-13 08:46:33.210535.210535 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-13 08:46:33.210590.210590 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-13 08:46:33.210640.210640 cuda_h.py:10] start sllm_worker_task
DEBUG 01-13 08:46:33.210540.210540 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-13 08:46:33.210121.210121 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-13 08:46:33.211060.211060 cuda_h.py:19] end allocate_cuda_memory cost 0.000423431396484375 seconds
DEBUG 01-13 08:46:33.211569.211569 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-13 08:46:33.211195.211195 sllm_store_c.py:27] get device uuid map
DEBUG 01-13 08:46:33.211187.211187 sllm_store_c.py:29] call client load into gpu
DEBUG 01-13 08:46:33.211693.211693 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, ad1f33cd-b911-4747-925a-a60bba9c331a
DEBUG 01-13 08:46:33.211527.211527 client.py:106] call stub.LoadModelAsync
DEBUG 01-13 08:46:33.211749.211749 cuda_h.py:10] start self_attn
INFO 01-13 08:46:33.213775.213775 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, ad1f33cd-b911-4747-925a-a60bba9c331a
DEBUG 01-13 08:46:33.213363.213363 cuda_h.py:19] end load_into_gpu_async cost 0.002225637435913086 seconds
DEBUG 01-13 08:46:33.213061.213061 cuda_h.py:10] start restore_tensors2
DEBUG 01-13 08:46:33.213433.213433 cuda_h.py:19] end restore_tensors2 cost 0.00014328956604003906 seconds
DEBUG 01-13 08:46:33.214775.214775 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0035419464111328125 seconds
INFO 01-13 08:46:33.214423.214423 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, ad1f33cd-b911-4747-925a-a60bba9c331a
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-13 08:46:33.215858.215858 cuda_h.py:19] end self_attn cost 0.00385284423828125 seconds
DEBUG 01-13 08:46:33.216414.216414 cuda_h.py:19] end iln_self_attn_paln cost 0.00622868537902832 seconds
DEBUG 01-13 08:46:33.216509.216509 cuda_h.py:10] start layer_moe_generate_mp_l_10
DEBUG 01-13 08:46:33.216299.216299 cuda_h.py:10] start gate
DEBUG 01-13 08:46:33.217119.217119 cuda_h.py:19] end gate cost 0.0007252693176269531 seconds
DEBUG 01-13 08:46:33.217347.217347 cuda_h.py:10] start experts_map_get
DEBUG 01-13 08:46:33.217094.217094 lmp.py:1611] 
DEBUG 01-13 08:46:33.217094.217094 lmp.py:1611] Expert Token Distribution & Device Allocation:
DEBUG 01-13 08:46:33.217480.217480 lmp.py:1612]   Total experts: 64
DEBUG 01-13 08:46:33.217044.217044 lmp.py:1613]   CPU experts: 32 (50%)
DEBUG 01-13 08:46:33.217700.217700 lmp.py:1614]   GPU experts: 32 (50%)
DEBUG 01-13 08:46:33.217734.217734 lmp.py:1615] 
DEBUG 01-13 08:46:33.217734.217734 lmp.py:1615]   Expert ID | Tokens | Device
DEBUG 01-13 08:46:33.217576.217576 lmp.py:1616]   -----------------------------------
DEBUG 01-13 08:46:33.217570.217570 lmp.py:1622]   Expert 24 |     40 | CPU
DEBUG 01-13 08:46:33.217174.217174 lmp.py:1622]   Expert  2 |     48 | CPU
DEBUG 01-13 08:46:33.217062.217062 lmp.py:1622]   Expert 32 |     64 | CPU
DEBUG 01-13 08:46:33.217427.217427 lmp.py:1622]   Expert 26 |     69 | CPU
DEBUG 01-13 08:46:33.217077.217077 lmp.py:1622]   Expert 19 |     73 | CPU
DEBUG 01-13 08:46:33.217025.217025 lmp.py:1622]   Expert 15 |     77 | CPU
DEBUG 01-13 08:46:33.217820.217820 lmp.py:1622]   Expert 50 |     79 | CPU
DEBUG 01-13 08:46:33.217424.217424 lmp.py:1622]   Expert  7 |     82 | CPU
DEBUG 01-13 08:46:33.217027.217027 lmp.py:1622]   Expert 28 |     82 | CPU
DEBUG 01-13 08:46:33.218154.218154 lmp.py:1622]   Expert  4 |     83 | CPU
DEBUG 01-13 08:46:33.218565.218565 lmp.py:1622]   Expert 59 |     83 | CPU
DEBUG 01-13 08:46:33.218930.218930 lmp.py:1622]   Expert 60 |     90 | CPU
DEBUG 01-13 08:46:33.218580.218580 lmp.py:1622]   Expert 23 |     96 | CPU
DEBUG 01-13 08:46:33.218991.218991 lmp.py:1622]   Expert 49 |    102 | CPU
DEBUG 01-13 08:46:33.218164.218164 lmp.py:1622]   Expert  5 |    104 | CPU
DEBUG 01-13 08:46:33.218814.218814 lmp.py:1622]   Expert 12 |    104 | CPU
DEBUG 01-13 08:46:33.218140.218140 lmp.py:1622]   Expert 27 |    109 | CPU
DEBUG 01-13 08:46:33.218451.218451 lmp.py:1622]   Expert 10 |    111 | CPU
DEBUG 01-13 08:46:33.218479.218479 lmp.py:1622]   Expert 41 |    116 | CPU
DEBUG 01-13 08:46:33.218883.218883 lmp.py:1622]   Expert 16 |    120 | CPU
DEBUG 01-13 08:46:33.218288.218288 lmp.py:1622]   Expert  3 |    123 | CPU
DEBUG 01-13 08:46:33.218454.218454 lmp.py:1622]   Expert 20 |    124 | CPU
DEBUG 01-13 08:46:33.218620.218620 lmp.py:1622]   Expert 25 |    128 | CPU
DEBUG 01-13 08:46:33.218309.218309 lmp.py:1622]   Expert 13 |    129 | CPU
DEBUG 01-13 08:46:33.218475.218475 lmp.py:1622]   Expert 40 |    129 | CPU
DEBUG 01-13 08:46:33.218642.218642 lmp.py:1622]   Expert 37 |    142 | CPU
DEBUG 01-13 08:46:33.218046.218046 lmp.py:1622]   Expert 17 |    146 | CPU
DEBUG 01-13 08:46:33.218212.218212 lmp.py:1622]   Expert 35 |    148 | CPU
DEBUG 01-13 08:46:33.218855.218855 lmp.py:1622]   Expert 22 |    160 | CPU
DEBUG 01-13 08:46:33.218167.218167 lmp.py:1622]   Expert 47 |    162 | CPU
DEBUG 01-13 08:46:33.218764.218764 lmp.py:1622]   Expert 53 |    163 | CPU
DEBUG 01-13 08:46:33.218076.218076 lmp.py:1622]   Expert 38 |    172 | CPU
DEBUG 01-13 08:46:33.218957.218957 lmp.py:1622]   Expert 39 |    173 | GPU
DEBUG 01-13 08:46:33.218600.218600 lmp.py:1622]   Expert 36 |    181 | GPU
DEBUG 01-13 08:46:33.218243.218243 lmp.py:1622]   Expert 44 |    182 | GPU
DEBUG 01-13 08:46:33.218409.218409 lmp.py:1622]   Expert 52 |    186 | GPU
DEBUG 01-13 08:46:33.218337.218337 lmp.py:1622]   Expert 18 |    187 | GPU
DEBUG 01-13 08:46:33.218126.218126 lmp.py:1622]   Expert 58 |    193 | GPU
DEBUG 01-13 08:46:33.218530.218530 lmp.py:1622]   Expert 62 |    198 | GPU
DEBUG 01-13 08:46:33.218935.218935 lmp.py:1622]   Expert 11 |    204 | GPU
DEBUG 01-13 08:46:33.218339.218339 lmp.py:1622]   Expert 48 |    205 | GPU
DEBUG 01-13 08:46:33.218698.218698 lmp.py:1622]   Expert 14 |    215 | GPU
DEBUG 01-13 08:46:33.218917.218917 lmp.py:1622]   Expert 30 |    218 | GPU
DEBUG 01-13 08:46:33.218990.218990 lmp.py:1622]   Expert  1 |    224 | GPU
DEBUG 01-13 08:46:33.218872.218872 lmp.py:1622]   Expert 42 |    228 | GPU
DEBUG 01-13 08:46:33.218276.218276 lmp.py:1622]   Expert 31 |    234 | GPU
DEBUG 01-13 08:46:33.218919.218919 lmp.py:1622]   Expert  6 |    235 | GPU
DEBUG 01-13 08:46:33.218324.218324 lmp.py:1622]   Expert 51 |    238 | GPU
DEBUG 01-13 08:46:33.218967.218967 lmp.py:1622]   Expert 45 |    243 | GPU
DEBUG 01-13 08:46:33.218610.218610 lmp.py:1622]   Expert 34 |    262 | GPU
DEBUG 01-13 08:46:33.218014.218014 lmp.py:1622]   Expert 29 |    268 | GPU
DEBUG 01-13 08:46:33.218041.218041 lmp.py:1622]   Expert 33 |    281 | GPU
DEBUG 01-13 08:46:33.218161.218161 lmp.py:1622]   Expert 57 |    292 | GPU
DEBUG 01-13 08:46:33.218519.218519 lmp.py:1622]   Expert 61 |    305 | GPU
DEBUG 01-13 08:46:33.218262.218262 lmp.py:1622]   Expert 43 |    312 | GPU
DEBUG 01-13 08:46:33.218859.218859 lmp.py:1622]   Expert  0 |    315 | GPU
DEBUG 01-13 08:46:33.218263.218263 lmp.py:1622]   Expert 46 |    358 | GPU
DEBUG 01-13 08:46:33.218429.218429 lmp.py:1622]   Expert  8 |    381 | GPU
DEBUG 01-13 08:46:33.218595.218595 lmp.py:1622]   Expert  9 |    390 | GPU
DEBUG 01-13 08:46:33.218523.218523 lmp.py:1622]   Expert 54 |    400 | GPU
DEBUG 01-13 08:46:33.218451.218451 lmp.py:1622]   Expert 56 |    405 | GPU
DEBUG 01-13 08:46:33.218617.218617 lmp.py:1622]   Expert 63 |    409 | GPU
DEBUG 01-13 08:46:33.219783.219783 lmp.py:1622]   Expert 55 |    423 | GPU
DEBUG 01-13 08:46:33.219949.219949 lmp.py:1622]   Expert 21 |    485 | GPU
DEBUG 01-13 08:46:33.219069.219069 lmp.py:1623] 
DEBUG 01-13 08:46:33.219069.219069 lmp.py:1623]   CPU total tokens: 3458 (28.1%)
DEBUG 01-13 08:46:33.219096.219096 lmp.py:1624]   GPU total tokens: 8830 (71.9%)
DEBUG 01-13 08:46:33.219461.219461 cuda_h.py:19] end experts_map_get cost 0.0018055438995361328 seconds
DEBUG 01-13 08:46:33.219934.219934 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-13 08:46:33.219312.219312 lmp.py:1632] 
DEBUG 01-13 08:46:33.219312.219312 lmp.py:1632]   Computing 32 experts on CPU MP...
DEBUG 01-13 08:46:33.219334.219334 cuda_h.py:19] end cpu_experts_submit cost 5.412101745605469e-05 seconds
DEBUG 01-13 08:46:33.219884.219884 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-13 08:46:33.219806.219806 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-13 08:46:33.219845.219845 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-13 08:46:33.220123.220123 cuda_h.py:19] end allocate_cuda_memory cost 0.00115203857421875 seconds
DEBUG 01-13 08:46:33.220019.220019 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-13 08:46:33.220206.220206 sllm_store_c.py:27] get device uuid map
DEBUG 01-13 08:46:33.221367.221367 sllm_store_c.py:29] call client load into gpu
DEBUG 01-13 08:46:33.221467.221467 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, c7a4f34b-e075-4656-89c4-f4cf9bae33bb
DEBUG 01-13 08:46:33.221965.221965 client.py:106] call stub.LoadModelAsync
INFO 01-13 08:46:33.221328.221328 client.py:127] Model loaded
DEBUG 01-13 08:46:33.222759.222759 cuda_h.py:10] start restore2model
DEBUG 01-13 08:46:33.222044.222044 cuda_h.py:10] start experts_func_gpu_einsum_mp
DEBUG 01-13 08:46:33.223509.223509 cuda_h.py:19] end restore2model cost 0.0009481906890869141 seconds
DEBUG 01-13 08:46:33.223911.223911 cuda_h.py:19] end sllm_worker_task cost 0.012850761413574219 seconds
INFO 01-13 08:46:33.223133.223133 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, c7a4f34b-e075-4656-89c4-f4cf9bae33bb
DEBUG 01-13 08:46:33.223129.223129 cuda_h.py:19] end load_into_gpu_async cost 0.00302886962890625 seconds
DEBUG 01-13 08:46:33.223785.223785 cuda_h.py:10] start restore_tensors2
DEBUG 01-13 08:46:33.224120.224120 cuda_h.py:19] end restore_tensors2 cost 0.00046372413635253906 seconds
DEBUG 01-13 08:46:33.224950.224950 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.005063772201538086 seconds
DEBUG 01-13 08:46:33.224356.224356 cuda_h.py:10] start restore2model
DEBUG 01-13 08:46:33.227115.227115 cuda_h.py:19] end restore2model cost 0.0028464794158935547 seconds
DEBUG 01-13 08:46:33.227673.227673 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.00810861587524414 seconds
DEBUG 01-13 08:46:33.227515.227515 cuda_h.py:10] start gpu_sexperts
DEBUG 01-13 08:46:33.227135.227135 cuda_h.py:19] end gpu_sexperts cost 0.00028586387634277344 seconds
DEBUG 01-13 08:46:33.227679.227679 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-13 08:46:33.227118.227118 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 1.430511474609375e-05 seconds
DEBUG 01-13 08:46:33.227059.227059 cuda_h.py:10] start wait_experts
INFO 01-13 08:46:33.227855.227855 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, c7a4f34b-e075-4656-89c4-f4cf9bae33bb
DEBUG 01-13 08:46:33.234381.234381 mlpmodule.py:1006] group tensors cost 0.009749650955200195 s
DEBUG 01-13 08:46:33.237921.237921 mlpmodule.py:1044] pad cost 0.0032172203063964844 s
DEBUG 01-13 08:46:33.238039.238039 mlpmodule.py:1050] create cpu tensor cost 7.271766662597656e-05 s
DEBUG 01-13 08:46:33.238519.238519 mlpmodule.py:1055] move to cpu cost 5.0067901611328125e-05 s
DEBUG 01-13 08:46:33.246930.246930 mlpmodule.py:1069] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-13 08:46:33.246367.246367 mlpmodule.py:1070] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-13 08:46:33.246284.246284 mlpmodule.py:1075] group_w3 first element: 0.0157470703125
WARNING 01-13 08:46:33.246972.246972 mlpmodule.py:1085] start einsum2
DEBUG 01-13 08:46:33.259236.259236 mlpmodule.py:1095] group einsum cost 0.02150273323059082 s
DEBUG 01-13 08:46:33.260259.260259 mlpmodule.py:1103] cpy2cputensor cost 0.0006797313690185547 s
INFO 01-13 08:46:33.273985.273985 client.py:127] Model loaded
DEBUG 01-13 08:46:33.274871.274871 cuda_h.py:19] end wait_experts cost 0.046163082122802734 seconds
DEBUG 01-13 08:46:33.274186.274186 cuda_h.py:10] start gpu_experts
DEBUG 01-13 08:46:33.275025.275025 mlpmodule.py:559] gpu group tensors cost 0.0013720989227294922 s
DEBUG 01-13 08:46:33.280495.280495 mlpmodule.py:592] gpu pad cost 0.0042192935943603516 s
DEBUG 01-13 08:46:33.280984.280984 mlpmodule.py:598] start_w1
DEBUG 01-13 08:46:33.280662.280662 mlpmodule.py:602] start_w3
DEBUG 01-13 08:46:33.281144.281144 mlpmodule.py:608] start_w2
DEBUG 01-13 08:46:33.281345.281345 mlpmodule.py:611] gpu group einsum cost 0.0011081695556640625 s
DEBUG 01-13 08:46:33.285665.285665 mlpmodule.py:785]  experts func einsum cost 0.06080269813537598 s
DEBUG 01-13 08:46:33.285420.285420 cuda_h.py:19] end experts_func_gpu_einsum_mp cost 0.06252622604370117 seconds
DEBUG 01-13 08:46:33.286462.286462 mlpmodule.py:683] gpu experts func einsum cost 0.012651205062866211 s
DEBUG 01-13 08:46:33.287151.287151 cuda_h.py:19] end gpu_experts cost 0.012924671173095703 seconds
DEBUG 01-13 08:46:33.287114.287114 cuda_h.py:10] start cpu_thread_manager_mp_wait
DEBUG 01-13 08:46:33.287529.287529 cuda_h.py:19] end cpu_thread_manager_mp_wait cost 5.91278076171875e-05 seconds
DEBUG 01-13 08:46:33.287952.287952 cuda_h.py:19] end layer_moe_generate_mp_l_10 cost 0.07113528251647949 seconds
DEBUG 01-13 08:46:33.287894.287894 lmp.py:1550] -------------------------------- end prefill layer 9 --------------------------------
DEBUG 01-13 08:46:33.288440.288440 lmp.py:1493] -------------------------------- start prefill layer 10 --------------------------------
DEBUG 01-13 08:46:33.288396.288396 cuda_h.py:10] start start_load_qkvogn_s_weight_l_11
DEBUG 01-13 08:46:33.288114.288114 cuda_h.py:10] start start_load_qkvogn_s_weight_l_11
DEBUG 01-13 08:46:33.288753.288753 cuda_h.py:19] end start_load_qkvogn_s_weight_l_11 cost 5.364418029785156e-05 seconds
DEBUG 01-13 08:46:33.288624.288624 cuda_h.py:19] end start_load_qkvogn_s_weight_l_11 cost 0.0001418590545654297 seconds
DEBUG 01-13 08:46:33.288076.288076 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-13 08:46:33.288014.288014 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-13 08:46:33.289495.289495 cuda_h.py:10] start self_attn
DEBUG 01-13 08:46:33.290613.290613 cuda_h.py:10] start sllm_worker_task
DEBUG 01-13 08:46:33.291876.291876 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-13 08:46:33.291557.291557 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-13 08:46:33.292626.292626 cuda_h.py:19] end allocate_cuda_memory cost 0.0006909370422363281 seconds
DEBUG 01-13 08:46:33.292252.292252 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-13 08:46:33.292634.292634 sllm_store_c.py:27] get device uuid map
DEBUG 01-13 08:46:33.292075.292075 sllm_store_c.py:29] call client load into gpu
DEBUG 01-13 08:46:33.292959.292959 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, d28f2a90-d8b3-44d4-bae3-292c9ffb38df
DEBUG 01-13 08:46:33.292682.292682 client.py:106] call stub.LoadModelAsync
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-13 08:46:33.294686.294686 cuda_h.py:19] end self_attn cost 0.005232572555541992 seconds
INFO 01-13 08:46:33.294497.294497 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, d28f2a90-d8b3-44d4-bae3-292c9ffb38df
DEBUG 01-13 08:46:33.294543.294543 cuda_h.py:19] end load_into_gpu_async cost 0.002422332763671875 seconds
DEBUG 01-13 08:46:33.295262.295262 cuda_h.py:10] start restore_tensors2
DEBUG 01-13 08:46:33.295651.295651 cuda_h.py:19] end restore_tensors2 cost 0.00017690658569335938 seconds
DEBUG 01-13 08:46:33.295104.295104 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.004309177398681641 seconds
INFO 01-13 08:46:33.295772.295772 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, d28f2a90-d8b3-44d4-bae3-292c9ffb38df
DEBUG 01-13 08:46:33.295213.295213 cuda_h.py:19] end iln_self_attn_paln cost 0.007399082183837891 seconds
DEBUG 01-13 08:46:33.296866.296866 cuda_h.py:10] start layer_moe_generate_mp_l_11
DEBUG 01-13 08:46:33.296165.296165 cuda_h.py:10] start gate
DEBUG 01-13 08:46:33.296426.296426 cuda_h.py:19] end gate cost 0.0008172988891601562 seconds
DEBUG 01-13 08:46:33.297303.297303 cuda_h.py:10] start experts_map_get
DEBUG 01-13 08:46:33.297262.297262 lmp.py:1611] 
DEBUG 01-13 08:46:33.297262.297262 lmp.py:1611] Expert Token Distribution & Device Allocation:
DEBUG 01-13 08:46:33.297024.297024 lmp.py:1612]   Total experts: 64
DEBUG 01-13 08:46:33.297250.297250 lmp.py:1613]   CPU experts: 32 (50%)
DEBUG 01-13 08:46:33.297423.297423 lmp.py:1614]   GPU experts: 32 (50%)
DEBUG 01-13 08:46:33.297258.297258 lmp.py:1615] 
DEBUG 01-13 08:46:33.297258.297258 lmp.py:1615]   Expert ID | Tokens | Device
DEBUG 01-13 08:46:33.297809.297809 lmp.py:1616]   -----------------------------------
DEBUG 01-13 08:46:33.297558.297558 lmp.py:1622]   Expert 43 |     17 | CPU
DEBUG 01-13 08:46:33.297870.297870 lmp.py:1622]   Expert 27 |     34 | CPU
DEBUG 01-13 08:46:33.297990.297990 lmp.py:1622]   Expert 34 |     49 | CPU
DEBUG 01-13 08:46:33.297109.297109 lmp.py:1622]   Expert 26 |     51 | CPU
DEBUG 01-13 08:46:33.297945.297945 lmp.py:1622]   Expert 56 |     53 | CPU
DEBUG 01-13 08:46:33.297064.297064 lmp.py:1622]   Expert  3 |     59 | CPU
DEBUG 01-13 08:46:33.297191.297191 lmp.py:1622]   Expert  4 |     70 | CPU
DEBUG 01-13 08:46:33.297457.297457 lmp.py:1622]   Expert 61 |     80 | CPU
DEBUG 01-13 08:46:33.297245.297245 lmp.py:1622]   Expert 38 |     98 | CPU
DEBUG 01-13 08:46:33.297604.297604 lmp.py:1622]   Expert 14 |     99 | CPU
DEBUG 01-13 08:46:33.297485.297485 lmp.py:1622]   Expert  2 |    113 | CPU
DEBUG 01-13 08:46:33.297128.297128 lmp.py:1622]   Expert 17 |    119 | CPU
DEBUG 01-13 08:46:33.297771.297771 lmp.py:1622]   Expert 22 |    119 | CPU
DEBUG 01-13 08:46:33.297175.297175 lmp.py:1622]   Expert 47 |    127 | CPU
DEBUG 01-13 08:46:33.297580.297580 lmp.py:1622]   Expert 37 |    128 | CPU
DEBUG 01-13 08:46:33.297985.297985 lmp.py:1622]   Expert 54 |    130 | CPU
DEBUG 01-13 08:46:33.297866.297866 lmp.py:1622]   Expert 55 |    131 | CPU
DEBUG 01-13 08:46:33.297509.297509 lmp.py:1622]   Expert 28 |    137 | CPU
DEBUG 01-13 08:46:33.297152.297152 lmp.py:1622]   Expert 45 |    142 | CPU
DEBUG 01-13 08:46:33.297225.297225 lmp.py:1622]   Expert 48 |    145 | CPU
DEBUG 01-13 08:46:33.297299.297299 lmp.py:1622]   Expert 60 |    145 | CPU
DEBUG 01-13 08:46:33.297611.297611 lmp.py:1622]   Expert  7 |    147 | CPU
DEBUG 01-13 08:46:33.297254.297254 lmp.py:1622]   Expert 12 |    147 | CPU
DEBUG 01-13 08:46:33.297135.297135 lmp.py:1622]   Expert 51 |    148 | CPU
DEBUG 01-13 08:46:33.297540.297540 lmp.py:1622]   Expert  5 |    149 | CPU
DEBUG 01-13 08:46:33.297183.297183 lmp.py:1622]   Expert 15 |    151 | CPU
DEBUG 01-13 08:46:33.298826.298826 lmp.py:1622]   Expert  6 |    154 | CPU
DEBUG 01-13 08:46:33.298469.298469 lmp.py:1622]   Expert 63 |    155 | CPU
DEBUG 01-13 08:46:33.298873.298873 lmp.py:1622]   Expert 19 |    164 | CPU
DEBUG 01-13 08:46:33.298755.298755 lmp.py:1622]   Expert 52 |    166 | CPU
DEBUG 01-13 08:46:33.298782.298782 lmp.py:1622]   Expert 31 |    173 | CPU
DEBUG 01-13 08:46:33.298783.298783 lmp.py:1622]   Expert 57 |    177 | CPU
DEBUG 01-13 08:46:33.298810.298810 lmp.py:1622]   Expert 50 |    180 | GPU
DEBUG 01-13 08:46:33.298930.298930 lmp.py:1622]   Expert 44 |    182 | GPU
DEBUG 01-13 08:46:33.298334.298334 lmp.py:1622]   Expert 30 |    186 | GPU
DEBUG 01-13 08:46:33.298977.298977 lmp.py:1622]   Expert 13 |    188 | GPU
DEBUG 01-13 08:46:33.298382.298382 lmp.py:1622]   Expert 18 |    188 | GPU
DEBUG 01-13 08:46:33.298025.298025 lmp.py:1622]   Expert 59 |    191 | GPU
DEBUG 01-13 08:46:33.298906.298906 lmp.py:1622]   Expert 53 |    195 | GPU
DEBUG 01-13 08:46:33.298311.298311 lmp.py:1622]   Expert 23 |    197 | GPU
DEBUG 01-13 08:46:33.298954.298954 lmp.py:1622]   Expert 20 |    198 | GPU
DEBUG 01-13 08:46:33.298597.298597 lmp.py:1622]   Expert 39 |    202 | GPU
DEBUG 01-13 08:46:33.298717.298717 lmp.py:1622]   Expert 21 |    203 | GPU
DEBUG 01-13 08:46:33.298102.298102 lmp.py:1622]   Expert 29 |    203 | GPU
DEBUG 01-13 08:46:33.298652.298652 lmp.py:1622]   Expert 36 |    210 | GPU
DEBUG 01-13 08:46:33.298534.298534 lmp.py:1622]   Expert 16 |    211 | GPU
DEBUG 01-13 08:46:33.298177.298177 lmp.py:1622]   Expert 25 |    212 | GPU
DEBUG 01-13 08:46:33.298058.298058 lmp.py:1622]   Expert 41 |    214 | GPU
DEBUG 01-13 08:46:33.298940.298940 lmp.py:1622]   Expert 49 |    215 | GPU
DEBUG 01-13 08:46:33.298582.298582 lmp.py:1622]   Expert 32 |    218 | GPU
DEBUG 01-13 08:46:33.298987.298987 lmp.py:1622]   Expert 46 |    221 | GPU
DEBUG 01-13 08:46:33.298630.298630 lmp.py:1622]   Expert 42 |    248 | GPU
DEBUG 01-13 08:46:33.298796.298796 lmp.py:1622]   Expert 10 |    250 | GPU
DEBUG 01-13 08:46:33.298201.298201 lmp.py:1622]   Expert  8 |    258 | GPU
DEBUG 01-13 08:46:33.298844.298844 lmp.py:1622]   Expert 62 |    262 | GPU
DEBUG 01-13 08:46:33.298679.298679 lmp.py:1622]   Expert 35 |    274 | GPU
DEBUG 01-13 08:46:33.298421.298421 lmp.py:1622]   Expert  9 |    279 | GPU
DEBUG 01-13 08:46:33.298733.298733 lmp.py:1622]   Expert 33 |    302 | GPU
DEBUG 01-13 08:46:33.298376.298376 lmp.py:1622]   Expert 58 |    306 | GPU
DEBUG 01-13 08:46:33.298781.298781 lmp.py:1622]   Expert 40 |    391 | GPU
DEBUG 01-13 08:46:33.298424.298424 lmp.py:1622]   Expert  0 |    430 | GPU
DEBUG 01-13 08:46:33.298828.298828 lmp.py:1622]   Expert 11 |    465 | GPU
DEBUG 01-13 08:46:33.298233.298233 lmp.py:1622]   Expert 24 |    563 | GPU
DEBUG 01-13 08:46:33.298114.298114 lmp.py:1622]   Expert  1 |    669 | GPU
DEBUG 01-13 08:46:33.298711.298711 lmp.py:1623] 
DEBUG 01-13 08:46:33.298711.298711 lmp.py:1623]   CPU total tokens: 3777 (30.7%)
DEBUG 01-13 08:46:33.298784.298784 lmp.py:1624]   GPU total tokens: 8511 (69.3%)
DEBUG 01-13 08:46:33.298818.298818 cuda_h.py:19] end experts_map_get cost 0.0017125606536865234 seconds
DEBUG 01-13 08:46:33.298019.298019 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-13 08:46:33.298782.298782 lmp.py:1632] 
DEBUG 01-13 08:46:33.298782.298782 lmp.py:1632]   Computing 32 experts on CPU MP...
DEBUG 01-13 08:46:33.298347.298347 cuda_h.py:19] end cpu_experts_submit cost 6.628036499023438e-05 seconds
DEBUG 01-13 08:46:33.298851.298851 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-13 08:46:33.299118.299118 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-13 08:46:33.299131.299131 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-13 08:46:33.300565.300565 cuda_h.py:19] end allocate_cuda_memory cost 0.0014374256134033203 seconds
DEBUG 01-13 08:46:33.300474.300474 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-13 08:46:33.300529.300529 sllm_store_c.py:27] get device uuid map
DEBUG 01-13 08:46:33.300464.300464 sllm_store_c.py:29] call client load into gpu
DEBUG 01-13 08:46:33.300075.300075 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, dd21c27d-7902-428e-95fb-54e14c38e182
DEBUG 01-13 08:46:33.301943.301943 client.py:106] call stub.LoadModelAsync
INFO 01-13 08:46:33.302236.302236 client.py:127] Model loaded
DEBUG 01-13 08:46:33.302876.302876 cuda_h.py:10] start restore2model
DEBUG 01-13 08:46:33.302827.302827 cuda_h.py:10] start experts_func_gpu_einsum_mp
DEBUG 01-13 08:46:33.303230.303230 cuda_h.py:19] end restore2model cost 0.0006182193756103516 seconds
DEBUG 01-13 08:46:33.303941.303941 cuda_h.py:19] end sllm_worker_task cost 0.012424468994140625 seconds
INFO 01-13 08:46:33.304116.304116 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, dd21c27d-7902-428e-95fb-54e14c38e182
DEBUG 01-13 08:46:33.304192.304192 cuda_h.py:19] end load_into_gpu_async cost 0.0037903785705566406 seconds
DEBUG 01-13 08:46:33.304670.304670 cuda_h.py:10] start restore_tensors2
DEBUG 01-13 08:46:33.305012.305012 cuda_h.py:19] end restore_tensors2 cost 0.0005033016204833984 seconds
DEBUG 01-13 08:46:33.305883.305883 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.006184101104736328 seconds
DEBUG 01-13 08:46:33.305089.305089 cuda_h.py:10] start restore2model
DEBUG 01-13 08:46:33.308768.308768 cuda_h.py:19] end restore2model cost 0.0028204917907714844 seconds
DEBUG 01-13 08:46:33.308823.308823 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.00922536849975586 seconds
DEBUG 01-13 08:46:33.308096.308096 cuda_h.py:10] start gpu_sexperts
DEBUG 01-13 08:46:33.308027.308027 cuda_h.py:19] end gpu_sexperts cost 0.0003027915954589844 seconds
DEBUG 01-13 08:46:33.308433.308433 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-13 08:46:33.308932.308932 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 1.7881393432617188e-05 seconds
DEBUG 01-13 08:46:33.308343.308343 cuda_h.py:10] start wait_experts
INFO 01-13 08:46:33.308000.308000 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, dd21c27d-7902-428e-95fb-54e14c38e182
DEBUG 01-13 08:46:33.317440.317440 mlpmodule.py:1006] group tensors cost 0.013269186019897461 s
DEBUG 01-13 08:46:33.320423.320423 mlpmodule.py:1044] pad cost 0.0023467540740966797 s
DEBUG 01-13 08:46:33.320970.320970 mlpmodule.py:1050] create cpu tensor cost 5.650520324707031e-05 s
DEBUG 01-13 08:46:33.320324.320324 mlpmodule.py:1055] move to cpu cost 4.3392181396484375e-05 s
DEBUG 01-13 08:46:33.330816.330816 mlpmodule.py:1069] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-13 08:46:33.330014.330014 mlpmodule.py:1070] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-13 08:46:33.330032.330032 mlpmodule.py:1075] group_w3 first element: -0.0213623046875
WARNING 01-13 08:46:33.330844.330844 mlpmodule.py:1085] start einsum2
DEBUG 01-13 08:46:33.343055.343055 mlpmodule.py:1095] group einsum cost 0.022523880004882812 s
DEBUG 01-13 08:46:33.344789.344789 mlpmodule.py:1103] cpy2cputensor cost 0.00069427490234375 s
INFO 01-13 08:46:33.355130.355130 client.py:127] Model loaded
DEBUG 01-13 08:46:33.355731.355731 cuda_h.py:19] end wait_experts cost 0.04655170440673828 seconds
DEBUG 01-13 08:46:33.355184.355184 cuda_h.py:10] start gpu_experts
DEBUG 01-13 08:46:33.357477.357477 mlpmodule.py:559] gpu group tensors cost 0.0014503002166748047 s
DEBUG 01-13 08:46:33.361946.361946 mlpmodule.py:592] gpu pad cost 0.0043904781341552734 s
DEBUG 01-13 08:46:33.361760.361760 mlpmodule.py:598] start_w1
DEBUG 01-13 08:46:33.362318.362318 mlpmodule.py:602] start_w3
DEBUG 01-13 08:46:33.362821.362821 mlpmodule.py:608] start_w2
DEBUG 01-13 08:46:33.363007.363007 mlpmodule.py:611] gpu group einsum cost 0.0014438629150390625 s
DEBUG 01-13 08:46:33.368636.368636 mlpmodule.py:785]  experts func einsum cost 0.06408286094665527 s
DEBUG 01-13 08:46:33.369815.369815 cuda_h.py:19] end experts_func_gpu_einsum_mp cost 0.0659780502319336 seconds
DEBUG 01-13 08:46:33.369784.369784 mlpmodule.py:683] gpu experts func einsum cost 0.013964653015136719 s
DEBUG 01-13 08:46:33.369089.369089 cuda_h.py:19] end gpu_experts cost 0.014280080795288086 seconds
DEBUG 01-13 08:46:33.369834.369834 cuda_h.py:10] start cpu_thread_manager_mp_wait
DEBUG 01-13 08:46:33.369355.369355 cuda_h.py:19] end cpu_thread_manager_mp_wait cost 6.127357482910156e-05 seconds
DEBUG 01-13 08:46:33.370798.370798 cuda_h.py:19] end layer_moe_generate_mp_l_11 cost 0.07409358024597168 seconds
DEBUG 01-13 08:46:33.370969.370969 lmp.py:1550] -------------------------------- end prefill layer 10 --------------------------------
DEBUG 01-13 08:46:33.370407.370407 lmp.py:1493] -------------------------------- start prefill layer 11 --------------------------------
DEBUG 01-13 08:46:33.370925.370925 cuda_h.py:10] start start_load_qkvogn_s_weight_l_12
DEBUG 01-13 08:46:33.370780.370780 cuda_h.py:10] start start_load_qkvogn_s_weight_l_12
DEBUG 01-13 08:46:33.370736.370736 cuda_h.py:19] end start_load_qkvogn_s_weight_l_12 cost 4.1961669921875e-05 seconds
DEBUG 01-13 08:46:33.370015.370015 cuda_h.py:19] end start_load_qkvogn_s_weight_l_12 cost 7.62939453125e-05 seconds
DEBUG 01-13 08:46:33.370904.370904 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-13 08:46:33.370230.370230 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-13 08:46:33.370784.370784 cuda_h.py:10] start sllm_worker_task
DEBUG 01-13 08:46:33.371108.371108 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-13 08:46:33.371872.371872 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-13 08:46:33.371464.371464 cuda_h.py:19] end allocate_cuda_memory cost 0.0002551078796386719 seconds
DEBUG 01-13 08:46:33.371944.371944 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-13 08:46:33.371276.371276 sllm_store_c.py:27] get device uuid map
DEBUG 01-13 08:46:33.371198.371198 sllm_store_c.py:29] call client load into gpu
DEBUG 01-13 08:46:33.371431.371431 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 9bbc4005-ba1c-4d78-b0b4-59cffb9d45ff
DEBUG 01-13 08:46:33.371328.371328 client.py:106] call stub.LoadModelAsync
DEBUG 01-13 08:46:33.372928.372928 cuda_h.py:10] start self_attn
INFO 01-13 08:46:33.373719.373719 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 9bbc4005-ba1c-4d78-b0b4-59cffb9d45ff
DEBUG 01-13 08:46:33.373931.373931 cuda_h.py:19] end load_into_gpu_async cost 0.0019390583038330078 seconds
DEBUG 01-13 08:46:33.373669.373669 cuda_h.py:10] start restore_tensors2
DEBUG 01-13 08:46:33.373890.373890 cuda_h.py:19] end restore_tensors2 cost 0.00016808509826660156 seconds
DEBUG 01-13 08:46:33.374947.374947 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0028481483459472656 seconds
INFO 01-13 08:46:33.374984.374984 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 9bbc4005-ba1c-4d78-b0b4-59cffb9d45ff
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-13 08:46:33.376164.376164 cuda_h.py:19] end self_attn cost 0.004179239273071289 seconds
DEBUG 01-13 08:46:33.376402.376402 cuda_h.py:19] end iln_self_attn_paln cost 0.005951642990112305 seconds
DEBUG 01-13 08:46:33.376166.376166 cuda_h.py:10] start layer_moe_generate_mp_l_12
DEBUG 01-13 08:46:33.376896.376896 cuda_h.py:10] start gate
DEBUG 01-13 08:46:33.377093.377093 cuda_h.py:19] end gate cost 0.0006990432739257812 seconds
DEBUG 01-13 08:46:33.377843.377843 cuda_h.py:10] start experts_map_get
DEBUG 01-13 08:46:33.378200.378200 lmp.py:1611] 
DEBUG 01-13 08:46:33.378200.378200 lmp.py:1611] Expert Token Distribution & Device Allocation:
DEBUG 01-13 08:46:33.378255.378255 lmp.py:1612]   Total experts: 64
DEBUG 01-13 08:46:33.378322.378322 lmp.py:1613]   CPU experts: 32 (50%)
DEBUG 01-13 08:46:33.378502.378502 lmp.py:1614]   GPU experts: 32 (50%)
DEBUG 01-13 08:46:33.378059.378059 lmp.py:1615] 
DEBUG 01-13 08:46:33.378059.378059 lmp.py:1615]   Expert ID | Tokens | Device
DEBUG 01-13 08:46:33.378994.378994 lmp.py:1616]   -----------------------------------
DEBUG 01-13 08:46:33.378173.378173 lmp.py:1622]   Expert 13 |     18 | CPU
DEBUG 01-13 08:46:33.378154.378154 lmp.py:1622]   Expert 39 |     18 | CPU
DEBUG 01-13 08:46:33.378181.378181 lmp.py:1622]   Expert 49 |     36 | CPU
DEBUG 01-13 08:46:33.378732.378732 lmp.py:1622]   Expert 35 |     49 | CPU
DEBUG 01-13 08:46:33.378044.378044 lmp.py:1622]   Expert 19 |     63 | CPU
DEBUG 01-13 08:46:33.378356.378356 lmp.py:1622]   Expert 32 |     68 | CPU
DEBUG 01-13 08:46:33.378906.378906 lmp.py:1622]   Expert 41 |     72 | CPU
DEBUG 01-13 08:46:33.378748.378748 lmp.py:1622]   Expert  9 |     76 | CPU
DEBUG 01-13 08:46:33.378967.378967 lmp.py:1622]   Expert 26 |     80 | CPU
DEBUG 01-13 08:46:33.378994.378994 lmp.py:1622]   Expert 33 |     84 | CPU
DEBUG 01-13 08:46:33.378783.378783 lmp.py:1622]   Expert 46 |     84 | CPU
DEBUG 01-13 08:46:33.378856.378856 lmp.py:1622]   Expert 31 |     86 | CPU
DEBUG 01-13 08:46:33.378168.378168 lmp.py:1622]   Expert 23 |     87 | CPU
DEBUG 01-13 08:46:33.378195.378195 lmp.py:1622]   Expert 18 |     89 | CPU
DEBUG 01-13 08:46:33.378031.378031 lmp.py:1622]   Expert 38 |     95 | CPU
DEBUG 01-13 08:46:33.378104.378104 lmp.py:1622]   Expert  6 |     97 | CPU
DEBUG 01-13 08:46:33.378178.378178 lmp.py:1622]   Expert  3 |    108 | CPU
DEBUG 01-13 08:46:33.378443.378443 lmp.py:1622]   Expert 17 |    110 | CPU
DEBUG 01-13 08:46:33.378186.378186 lmp.py:1622]   Expert 20 |    114 | CPU
DEBUG 01-13 08:46:33.378928.378928 lmp.py:1622]   Expert 59 |    124 | CPU
DEBUG 01-13 08:46:33.378001.378001 lmp.py:1622]   Expert 40 |    130 | CPU
DEBUG 01-13 08:46:33.378313.378313 lmp.py:1622]   Expert 62 |    131 | CPU
DEBUG 01-13 08:46:33.378148.378148 lmp.py:1622]   Expert 16 |    132 | CPU
DEBUG 01-13 08:46:33.378222.378222 lmp.py:1622]   Expert 43 |    135 | CPU
DEBUG 01-13 08:46:33.378819.378819 lmp.py:1622]   Expert 61 |    136 | CPU
DEBUG 01-13 08:46:33.378892.378892 lmp.py:1622]   Expert 50 |    137 | CPU
DEBUG 01-13 08:46:33.378158.378158 lmp.py:1622]   Expert 15 |    138 | CPU
DEBUG 01-13 08:46:33.378185.378185 lmp.py:1622]   Expert 63 |    144 | CPU
DEBUG 01-13 08:46:33.378689.378689 lmp.py:1622]   Expert  2 |    147 | CPU
DEBUG 01-13 08:46:33.378001.378001 lmp.py:1622]   Expert 44 |    147 | CPU
DEBUG 01-13 08:46:33.378836.378836 lmp.py:1622]   Expert 36 |    148 | CPU
DEBUG 01-13 08:46:33.378909.378909 lmp.py:1622]   Expert 42 |    148 | CPU
DEBUG 01-13 08:46:33.378744.378744 lmp.py:1622]   Expert 10 |    159 | GPU
DEBUG 01-13 08:46:33.378818.378818 lmp.py:1622]   Expert  5 |    181 | GPU
DEBUG 01-13 08:46:33.378891.378891 lmp.py:1622]   Expert 34 |    184 | GPU
DEBUG 01-13 08:46:33.378726.378726 lmp.py:1622]   Expert 45 |    186 | GPU
DEBUG 01-13 08:46:33.378800.378800 lmp.py:1622]   Expert 52 |    190 | GPU
DEBUG 01-13 08:46:33.378542.378542 lmp.py:1622]   Expert 27 |    191 | GPU
DEBUG 01-13 08:46:33.378285.378285 lmp.py:1622]   Expert 60 |    198 | GPU
DEBUG 01-13 08:46:33.378265.378265 lmp.py:1622]   Expert 48 |    206 | GPU
DEBUG 01-13 08:46:33.379577.379577 lmp.py:1622]   Expert 51 |    210 | GPU
DEBUG 01-13 08:46:33.379889.379889 lmp.py:1622]   Expert 56 |    215 | GPU
DEBUG 01-13 08:46:33.379963.379963 lmp.py:1622]   Expert 24 |    223 | GPU
DEBUG 01-13 08:46:33.379798.379798 lmp.py:1622]   Expert  7 |    227 | GPU
DEBUG 01-13 08:46:33.379110.379110 lmp.py:1622]   Expert 53 |    227 | GPU
DEBUG 01-13 08:46:33.379945.379945 lmp.py:1622]   Expert  8 |    231 | GPU
DEBUG 01-13 08:46:33.379257.379257 lmp.py:1622]   Expert 57 |    248 | GPU
DEBUG 01-13 08:46:33.379999.379999 lmp.py:1622]   Expert 47 |    255 | GPU
DEBUG 01-13 08:46:33.379742.379742 lmp.py:1622]   Expert 29 |    258 | GPU
DEBUG 01-13 08:46:33.379107.379107 lmp.py:1622]   Expert 21 |    268 | GPU
DEBUG 01-13 08:46:33.379710.379710 lmp.py:1622]   Expert  0 |    280 | GPU
DEBUG 01-13 08:46:33.379168.379168 lmp.py:1622]   Expert  4 |    284 | GPU
DEBUG 01-13 08:46:33.379864.379864 lmp.py:1622]   Expert 14 |    290 | GPU
DEBUG 01-13 08:46:33.379321.379321 lmp.py:1622]   Expert 22 |    316 | GPU
DEBUG 01-13 08:46:33.379256.379256 lmp.py:1622]   Expert 55 |    319 | GPU
DEBUG 01-13 08:46:33.379952.379952 lmp.py:1622]   Expert 37 |    323 | GPU
DEBUG 01-13 08:46:33.379933.379933 lmp.py:1622]   Expert  1 |    330 | GPU
DEBUG 01-13 08:46:33.379629.379629 lmp.py:1622]   Expert 54 |    331 | GPU
DEBUG 01-13 08:46:33.379802.379802 lmp.py:1622]   Expert 58 |    333 | GPU
DEBUG 01-13 08:46:33.379452.379452 lmp.py:1622]   Expert 28 |    364 | GPU
DEBUG 01-13 08:46:33.379578.379578 lmp.py:1622]   Expert 12 |    365 | GPU
DEBUG 01-13 08:46:33.379274.379274 lmp.py:1622]   Expert 25 |    401 | GPU
DEBUG 01-13 08:46:33.379209.379209 lmp.py:1622]   Expert 11 |    407 | GPU
DEBUG 01-13 08:46:33.379143.379143 lmp.py:1622]   Expert 30 |    857 | GPU
DEBUG 01-13 08:46:33.379793.379793 lmp.py:1623] 
DEBUG 01-13 08:46:33.379793.379793 lmp.py:1623]   CPU total tokens: 3231 (26.3%)
DEBUG 01-13 08:46:33.379920.379920 lmp.py:1624]   GPU total tokens: 9057 (73.7%)
DEBUG 01-13 08:46:33.379053.379053 cuda_h.py:19] end experts_map_get cost 0.0018749237060546875 seconds
DEBUG 01-13 08:46:33.379513.379513 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-13 08:46:33.379852.379852 lmp.py:1632] 
DEBUG 01-13 08:46:33.379852.379852 lmp.py:1632]   Computing 32 experts on CPU MP...
DEBUG 01-13 08:46:33.379510.379510 cuda_h.py:19] end cpu_experts_submit cost 6.341934204101562e-05 seconds
DEBUG 01-13 08:46:33.379511.379511 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-13 08:46:33.379600.379600 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-13 08:46:33.380420.380420 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-13 08:46:33.381413.381413 cuda_h.py:19] end allocate_cuda_memory cost 0.00024437904357910156 seconds
DEBUG 01-13 08:46:33.381555.381555 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-13 08:46:33.381172.381172 sllm_store_c.py:27] get device uuid map
DEBUG 01-13 08:46:33.381994.381994 sllm_store_c.py:29] call client load into gpu
DEBUG 01-13 08:46:33.381174.381174 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, f51171db-264c-4898-85ae-7404fe0fe942
DEBUG 01-13 08:46:33.381612.381612 client.py:106] call stub.LoadModelAsync
INFO 01-13 08:46:33.381106.381106 client.py:127] Model loaded
DEBUG 01-13 08:46:33.381404.381404 cuda_h.py:10] start restore2model
DEBUG 01-13 08:46:33.382249.382249 cuda_h.py:10] start experts_func_gpu_einsum_mp
DEBUG 01-13 08:46:33.382321.382321 cuda_h.py:19] end restore2model cost 0.0007829666137695312 seconds
DEBUG 01-13 08:46:33.382853.382853 cuda_h.py:19] end sllm_worker_task cost 0.011798620223999023 seconds
INFO 01-13 08:46:33.383663.383663 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, f51171db-264c-4898-85ae-7404fe0fe942
DEBUG 01-13 08:46:33.383209.383209 cuda_h.py:19] end load_into_gpu_async cost 0.0023069381713867188 seconds
DEBUG 01-13 08:46:33.383634.383634 cuda_h.py:10] start restore_tensors2
DEBUG 01-13 08:46:33.384249.384249 cuda_h.py:19] end restore_tensors2 cost 0.000499725341796875 seconds
DEBUG 01-13 08:46:33.384198.384198 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.004204511642456055 seconds
DEBUG 01-13 08:46:33.384829.384829 cuda_h.py:10] start restore2model
DEBUG 01-13 08:46:33.386028.386028 cuda_h.py:19] end restore2model cost 0.002748250961303711 seconds
DEBUG 01-13 08:46:33.386885.386885 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.007165193557739258 seconds
DEBUG 01-13 08:46:33.387680.387680 cuda_h.py:10] start gpu_sexperts
DEBUG 01-13 08:46:33.387068.387068 cuda_h.py:19] end gpu_sexperts cost 0.0002875328063964844 seconds
DEBUG 01-13 08:46:33.387574.387574 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-13 08:46:33.387780.387780 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 1.6927719116210938e-05 seconds
DEBUG 01-13 08:46:33.387430.387430 cuda_h.py:10] start wait_experts
INFO 01-13 08:46:33.387232.387232 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, f51171db-264c-4898-85ae-7404fe0fe942
DEBUG 01-13 08:46:33.396544.396544 mlpmodule.py:1006] group tensors cost 0.013010740280151367 s
DEBUG 01-13 08:46:33.399886.399886 mlpmodule.py:1044] pad cost 0.002117156982421875 s
DEBUG 01-13 08:46:33.399910.399910 mlpmodule.py:1050] create cpu tensor cost 6.127357482910156e-05 s
DEBUG 01-13 08:46:33.399556.399556 mlpmodule.py:1055] move to cpu cost 5.269050598144531e-05 s
DEBUG 01-13 08:46:33.411697.411697 mlpmodule.py:1069] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-13 08:46:33.412690.412690 mlpmodule.py:1070] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-13 08:46:33.412508.412508 mlpmodule.py:1075] group_w3 first element: -0.006134033203125
WARNING 01-13 08:46:33.412758.412758 mlpmodule.py:1085] start einsum2
DEBUG 01-13 08:46:33.427791.427791 mlpmodule.py:1095] group einsum cost 0.028110504150390625 s
DEBUG 01-13 08:46:33.428176.428176 mlpmodule.py:1103] cpy2cputensor cost 0.0005934238433837891 s
INFO 01-13 08:46:33.433004.433004 client.py:127] Model loaded
DEBUG 01-13 08:46:33.434427.434427 cuda_h.py:19] end wait_experts cost 0.04654550552368164 seconds
DEBUG 01-13 08:46:33.434596.434596 cuda_h.py:10] start gpu_experts
DEBUG 01-13 08:46:33.435217.435217 mlpmodule.py:559] gpu group tensors cost 0.001382589340209961 s
DEBUG 01-13 08:46:33.440212.440212 mlpmodule.py:592] gpu pad cost 0.004460811614990234 s
DEBUG 01-13 08:46:33.440185.440185 mlpmodule.py:598] start_w1
DEBUG 01-13 08:46:33.441670.441670 mlpmodule.py:602] start_w3
DEBUG 01-13 08:46:33.441757.441757 mlpmodule.py:608] start_w2
DEBUG 01-13 08:46:33.441694.441694 mlpmodule.py:611] gpu group einsum cost 0.0013654232025146484 s
DEBUG 01-13 08:46:33.446650.446650 mlpmodule.py:683] gpu experts func einsum cost 0.011751174926757812 s
DEBUG 01-13 08:46:33.446185.446185 cuda_h.py:19] end gpu_experts cost 0.011982917785644531 seconds
DEBUG 01-13 08:46:33.446167.446167 cuda_h.py:10] start cpu_thread_manager_mp_wait
DEBUG 01-13 08:46:33.446588.446588 cuda_h.py:19] end cpu_thread_manager_mp_wait cost 4.649162292480469e-05 seconds
DEBUG 01-13 08:46:33.446910.446910 cuda_h.py:19] end layer_moe_generate_mp_l_12 cost 0.06963992118835449 seconds
DEBUG 01-13 08:46:33.446855.446855 lmp.py:1550] -------------------------------- end prefill layer 11 --------------------------------
DEBUG 01-13 08:46:33.446182.446182 lmp.py:1493] -------------------------------- start prefill layer 12 --------------------------------
DEBUG 01-13 08:46:33.446011.446011 cuda_h.py:10] start start_load_qkvogn_s_weight_l_13
DEBUG 01-13 08:46:33.447517.447517 cuda_h.py:10] start start_load_qkvogn_s_weight_l_13
DEBUG 01-13 08:46:33.447599.447599 cuda_h.py:19] end start_load_qkvogn_s_weight_l_13 cost 4.5299530029296875e-05 seconds
DEBUG 01-13 08:46:33.447190.447190 cuda_h.py:19] end start_load_qkvogn_s_weight_l_13 cost 0.00010156631469726562 seconds
DEBUG 01-13 08:46:33.447437.447437 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-13 08:46:33.447468.447468 cuda_h.py:10] start sllm_worker_task
DEBUG 01-13 08:46:33.447567.447567 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-13 08:46:33.447643.447643 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-13 08:46:33.447373.447373 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-13 08:46:33.448346.448346 cuda_h.py:19] end allocate_cuda_memory cost 0.0003466606140136719 seconds
DEBUG 01-13 08:46:33.448501.448501 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-13 08:46:33.448887.448887 sllm_store_c.py:27] get device uuid map
DEBUG 01-13 08:46:33.448711.448711 sllm_store_c.py:29] call client load into gpu
DEBUG 01-13 08:46:33.448659.448659 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 6a50fa7c-bab2-4322-8107-107182ff73ab
DEBUG 01-13 08:46:33.448901.448901 client.py:106] call stub.LoadModelAsync
DEBUG 01-13 08:46:33.449624.449624 cuda_h.py:10] start self_attn
DEBUG 01-13 08:46:33.449351.449351 mlpmodule.py:785]  experts func einsum cost 0.06625080108642578 s
DEBUG 01-13 08:46:33.450600.450600 cuda_h.py:19] end experts_func_gpu_einsum_mp cost 0.06769633293151855 seconds
INFO 01-13 08:46:33.450199.450199 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 6a50fa7c-bab2-4322-8107-107182ff73ab
DEBUG 01-13 08:46:33.450540.450540 cuda_h.py:19] end load_into_gpu_async cost 0.001903533935546875 seconds
DEBUG 01-13 08:46:33.450449.450449 cuda_h.py:10] start restore_tensors2
DEBUG 01-13 08:46:33.450181.450181 cuda_h.py:19] end restore_tensors2 cost 8.749961853027344e-05 seconds
DEBUG 01-13 08:46:33.450798.450798 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.002670764923095703 seconds
INFO 01-13 08:46:33.450053.450053 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 6a50fa7c-bab2-4322-8107-107182ff73ab
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-13 08:46:33.453982.453982 cuda_h.py:19] end self_attn cost 0.004050016403198242 seconds
DEBUG 01-13 08:46:33.453469.453469 cuda_h.py:19] end iln_self_attn_paln cost 0.006259441375732422 seconds
DEBUG 01-13 08:46:33.453995.453995 cuda_h.py:10] start layer_moe_generate_mp_l_13
DEBUG 01-13 08:46:33.453427.453427 cuda_h.py:10] start gate
DEBUG 01-13 08:46:33.454810.454810 cuda_h.py:19] end gate cost 0.0007386207580566406 seconds
DEBUG 01-13 08:46:33.454600.454600 cuda_h.py:10] start experts_map_get
DEBUG 01-13 08:46:33.454776.454776 lmp.py:1611] 
DEBUG 01-13 08:46:33.454776.454776 lmp.py:1611] Expert Token Distribution & Device Allocation:
DEBUG 01-13 08:46:33.454817.454817 lmp.py:1612]   Total experts: 64
DEBUG 01-13 08:46:33.454182.454182 lmp.py:1613]   CPU experts: 32 (50%)
DEBUG 01-13 08:46:33.454447.454447 lmp.py:1614]   GPU experts: 32 (50%)
DEBUG 01-13 08:46:33.454044.454044 lmp.py:1615] 
DEBUG 01-13 08:46:33.454044.454044 lmp.py:1615]   Expert ID | Tokens | Device
DEBUG 01-13 08:46:33.454356.454356 lmp.py:1616]   -----------------------------------
DEBUG 01-13 08:46:33.454767.454767 lmp.py:1622]   Expert 12 |     18 | CPU
DEBUG 01-13 08:46:33.454933.454933 lmp.py:1622]   Expert 47 |     20 | CPU
DEBUG 01-13 08:46:33.454622.454622 lmp.py:1622]   Expert 38 |     27 | CPU
DEBUG 01-13 08:46:33.454835.454835 lmp.py:1622]   Expert 27 |     29 | CPU
DEBUG 01-13 08:46:33.454809.454809 lmp.py:1622]   Expert 52 |     33 | CPU
DEBUG 01-13 08:46:33.454021.454021 lmp.py:1622]   Expert 16 |     35 | CPU
DEBUG 01-13 08:46:33.454472.454472 lmp.py:1622]   Expert 63 |     46 | CPU
DEBUG 01-13 08:46:33.455023.455023 lmp.py:1622]   Expert  4 |     55 | CPU
DEBUG 01-13 08:46:33.455096.455096 lmp.py:1622]   Expert 43 |     62 | CPU
DEBUG 01-13 08:46:33.455646.455646 lmp.py:1622]   Expert 44 |     65 | CPU
DEBUG 01-13 08:46:33.455627.455627 lmp.py:1622]   Expert 34 |     71 | CPU
DEBUG 01-13 08:46:33.455847.455847 lmp.py:1622]   Expert 61 |     71 | CPU
DEBUG 01-13 08:46:33.455635.455635 lmp.py:1622]   Expert 53 |     80 | CPU
DEBUG 01-13 08:46:33.455947.455947 lmp.py:1622]   Expert  0 |     85 | CPU
DEBUG 01-13 08:46:33.455305.455305 lmp.py:1622]   Expert 32 |     87 | CPU
DEBUG 01-13 08:46:33.455379.455379 lmp.py:1622]   Expert 37 |     92 | CPU
DEBUG 01-13 08:46:33.455214.455214 lmp.py:1622]   Expert 13 |    100 | CPU
DEBUG 01-13 08:46:33.455287.455287 lmp.py:1622]   Expert 39 |    110 | CPU
DEBUG 01-13 08:46:33.455646.455646 lmp.py:1622]   Expert 21 |    115 | CPU
DEBUG 01-13 08:46:33.455766.455766 lmp.py:1622]   Expert 11 |    121 | CPU
DEBUG 01-13 08:46:33.455362.455362 lmp.py:1622]   Expert 20 |    126 | CPU
DEBUG 01-13 08:46:33.455912.455912 lmp.py:1622]   Expert 60 |    128 | CPU
DEBUG 01-13 08:46:33.455701.455701 lmp.py:1622]   Expert  8 |    136 | CPU
DEBUG 01-13 08:46:33.455874.455874 lmp.py:1622]   Expert 14 |    137 | CPU
DEBUG 01-13 08:46:33.455186.455186 lmp.py:1622]   Expert 57 |    137 | CPU
DEBUG 01-13 08:46:33.455618.455618 lmp.py:1622]   Expert 17 |    149 | CPU
DEBUG 01-13 08:46:33.455883.455883 lmp.py:1622]   Expert  2 |    153 | CPU
DEBUG 01-13 08:46:33.455480.455480 lmp.py:1622]   Expert 22 |    153 | CPU
DEBUG 01-13 08:46:33.455315.455315 lmp.py:1622]   Expert 45 |    155 | CPU
DEBUG 01-13 08:46:33.455150.455150 lmp.py:1622]   Expert  7 |    159 | CPU
DEBUG 01-13 08:46:33.455747.455747 lmp.py:1622]   Expert 18 |    160 | CPU
DEBUG 01-13 08:46:33.455343.455343 lmp.py:1622]   Expert 58 |    162 | CPU
DEBUG 01-13 08:46:33.455417.455417 lmp.py:1622]   Expert 30 |    163 | GPU
DEBUG 01-13 08:46:33.455729.455729 lmp.py:1622]   Expert 23 |    166 | GPU
DEBUG 01-13 08:46:33.455802.455802 lmp.py:1622]   Expert 42 |    169 | GPU
DEBUG 01-13 08:46:33.455399.455399 lmp.py:1622]   Expert 49 |    177 | GPU
DEBUG 01-13 08:46:33.455996.455996 lmp.py:1622]   Expert 29 |    178 | GPU
DEBUG 01-13 08:46:33.455354.455354 lmp.py:1622]   Expert 51 |    180 | GPU
DEBUG 01-13 08:46:33.455712.455712 lmp.py:1622]   Expert 35 |    181 | GPU
DEBUG 01-13 08:46:33.455309.455309 lmp.py:1622]   Expert 55 |    181 | GPU
DEBUG 01-13 08:46:33.455905.455905 lmp.py:1622]   Expert 62 |    185 | GPU
DEBUG 01-13 08:46:33.455787.455787 lmp.py:1622]   Expert 48 |    186 | GPU
DEBUG 01-13 08:46:33.455145.455145 lmp.py:1622]   Expert  6 |    191 | GPU
DEBUG 01-13 08:46:33.455742.455742 lmp.py:1622]   Expert  1 |    195 | GPU
DEBUG 01-13 08:46:33.455199.455199 lmp.py:1622]   Expert 36 |    196 | GPU
DEBUG 01-13 08:46:33.455988.455988 lmp.py:1622]   Expert 31 |    200 | GPU
DEBUG 01-13 08:46:33.455638.455638 lmp.py:1622]   Expert 25 |    203 | GPU
DEBUG 01-13 08:46:33.455996.455996 lmp.py:1622]   Expert 28 |    221 | GPU
DEBUG 01-13 08:46:33.455354.455354 lmp.py:1622]   Expert 41 |    224 | GPU
DEBUG 01-13 08:46:33.455474.455474 lmp.py:1622]   Expert 54 |    226 | GPU
DEBUG 01-13 08:46:33.455594.455594 lmp.py:1622]   Expert 24 |    229 | GPU
DEBUG 01-13 08:46:33.455714.455714 lmp.py:1622]   Expert  5 |    235 | GPU
DEBUG 01-13 08:46:33.455072.455072 lmp.py:1622]   Expert 19 |    237 | GPU
DEBUG 01-13 08:46:33.455669.455669 lmp.py:1622]   Expert  9 |    245 | GPU
DEBUG 01-13 08:46:33.455219.455219 lmp.py:1622]   Expert 50 |    284 | GPU
DEBUG 01-13 08:46:33.455008.455008 lmp.py:1622]   Expert 46 |    301 | GPU
DEBUG 01-13 08:46:33.455796.455796 lmp.py:1622]   Expert 59 |    312 | GPU
DEBUG 01-13 08:46:33.455393.455393 lmp.py:1622]   Expert 56 |    382 | GPU
DEBUG 01-13 08:46:33.455990.455990 lmp.py:1622]   Expert 26 |    391 | GPU
DEBUG 01-13 08:46:33.456110.456110 lmp.py:1622]   Expert 33 |    434 | GPU
DEBUG 01-13 08:46:33.456468.456468 lmp.py:1622]   Expert  3 |    588 | GPU
DEBUG 01-13 08:46:33.456303.456303 lmp.py:1622]   Expert 15 |    676 | GPU
DEBUG 01-13 08:46:33.456899.456899 lmp.py:1622]   Expert 10 |    702 | GPU
DEBUG 01-13 08:46:33.456019.456019 lmp.py:1622]   Expert 40 |    773 | GPU
DEBUG 01-13 08:46:33.456570.456570 lmp.py:1623] 
DEBUG 01-13 08:46:33.456570.456570 lmp.py:1623]   CPU total tokens: 3077 (25.0%)
DEBUG 01-13 08:46:33.456550.456550 lmp.py:1624]   GPU total tokens: 9211 (75.0%)
DEBUG 01-13 08:46:33.456061.456061 cuda_h.py:19] end experts_map_get cost 0.0016808509826660156 seconds
DEBUG 01-13 08:46:33.456263.456263 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-13 08:46:33.456641.456641 lmp.py:1632] 
DEBUG 01-13 08:46:33.456641.456641 lmp.py:1632]   Computing 32 experts on CPU MP...
DEBUG 01-13 08:46:33.456524.456524 cuda_h.py:19] end cpu_experts_submit cost 5.412101745605469e-05 seconds
DEBUG 01-13 08:46:33.456505.456505 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-13 08:46:33.456222.456222 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-13 08:46:33.456063.456063 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-13 08:46:33.457602.457602 cuda_h.py:19] end allocate_cuda_memory cost 0.00042724609375 seconds
DEBUG 01-13 08:46:33.457982.457982 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-13 08:46:33.457029.457029 sllm_store_c.py:27] get device uuid map
DEBUG 01-13 08:46:33.457589.457589 sllm_store_c.py:29] call client load into gpu
DEBUG 01-13 08:46:33.457113.457113 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, dc2caee9-4f93-4679-bde8-10a844f41288
DEBUG 01-13 08:46:33.458513.458513 client.py:106] call stub.LoadModelAsync
INFO 01-13 08:46:33.458279.458279 client.py:127] Model loaded
DEBUG 01-13 08:46:33.458086.458086 cuda_h.py:10] start restore2model
DEBUG 01-13 08:46:33.458283.458283 cuda_h.py:10] start experts_func_gpu_einsum_mp
DEBUG 01-13 08:46:33.459947.459947 cuda_h.py:19] end restore2model cost 0.0010874271392822266 seconds
DEBUG 01-13 08:46:33.459117.459117 cuda_h.py:19] end sllm_worker_task cost 0.012377500534057617 seconds
INFO 01-13 08:46:33.460963.460963 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, dc2caee9-4f93-4679-bde8-10a844f41288
DEBUG 01-13 08:46:33.460940.460940 cuda_h.py:19] end load_into_gpu_async cost 0.003055095672607422 seconds
DEBUG 01-13 08:46:33.460696.460696 cuda_h.py:10] start restore_tensors2
DEBUG 01-13 08:46:33.460720.460720 cuda_h.py:19] end restore_tensors2 cost 0.0004813671112060547 seconds
DEBUG 01-13 08:46:33.460384.460384 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0043849945068359375 seconds
DEBUG 01-13 08:46:33.460299.460299 cuda_h.py:10] start restore2model
DEBUG 01-13 08:46:33.463757.463757 cuda_h.py:19] end restore2model cost 0.0027642250061035156 seconds
DEBUG 01-13 08:46:33.463369.463369 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.0073888301849365234 seconds
DEBUG 01-13 08:46:33.463972.463972 cuda_h.py:10] start gpu_sexperts
DEBUG 01-13 08:46:33.464738.464738 cuda_h.py:19] end gpu_sexperts cost 0.0002853870391845703 seconds
DEBUG 01-13 08:46:33.464011.464011 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-13 08:46:33.464602.464602 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 1.8835067749023438e-05 seconds
DEBUG 01-13 08:46:33.464491.464491 cuda_h.py:10] start wait_experts
INFO 01-13 08:46:33.464094.464094 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, dc2caee9-4f93-4679-bde8-10a844f41288
DEBUG 01-13 08:46:33.476795.476795 mlpmodule.py:1006] group tensors cost 0.01645827293395996 s
DEBUG 01-13 08:46:33.478638.478638 mlpmodule.py:1044] pad cost 0.0017070770263671875 s
DEBUG 01-13 08:46:33.479410.479410 mlpmodule.py:1050] create cpu tensor cost 4.982948303222656e-05 s
DEBUG 01-13 08:46:33.479697.479697 mlpmodule.py:1055] move to cpu cost 3.5762786865234375e-05 s
DEBUG 01-13 08:46:33.487938.487938 mlpmodule.py:1069] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-13 08:46:33.487368.487368 mlpmodule.py:1070] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-13 08:46:33.487034.487034 mlpmodule.py:1075] group_w3 first element: -0.0162353515625
WARNING 01-13 08:46:33.487594.487594 mlpmodule.py:1085] start einsum2
DEBUG 01-13 08:46:33.501317.501317 mlpmodule.py:1095] group einsum cost 0.02201366424560547 s
DEBUG 01-13 08:46:33.502835.502835 mlpmodule.py:1103] cpy2cputensor cost 0.0006258487701416016 s
INFO 01-13 08:46:33.511761.511761 client.py:127] Model loaded
DEBUG 01-13 08:46:33.511521.511521 cuda_h.py:19] end wait_experts cost 0.047136545181274414 seconds
DEBUG 01-13 08:46:33.511894.511894 cuda_h.py:10] start gpu_experts
DEBUG 01-13 08:46:33.513244.513244 mlpmodule.py:559] gpu group tensors cost 0.0014111995697021484 s
DEBUG 01-13 08:46:33.517121.517121 mlpmodule.py:592] gpu pad cost 0.004304409027099609 s
DEBUG 01-13 08:46:33.517609.517609 mlpmodule.py:598] start_w1
DEBUG 01-13 08:46:33.518403.518403 mlpmodule.py:602] start_w3
DEBUG 01-13 08:46:33.519814.519814 mlpmodule.py:608] start_w2
DEBUG 01-13 08:46:33.520707.520707 mlpmodule.py:611] gpu group einsum cost 0.0028095245361328125 s
DEBUG 01-13 08:46:33.522516.522516 mlpmodule.py:785]  experts func einsum cost 0.06254816055297852 s
DEBUG 01-13 08:46:33.522048.522048 cuda_h.py:19] end experts_func_gpu_einsum_mp cost 0.06397867202758789 seconds
DEBUG 01-13 08:46:33.524027.524027 mlpmodule.py:683] gpu experts func einsum cost 0.013132572174072266 s
DEBUG 01-13 08:46:33.524752.524752 cuda_h.py:19] end gpu_experts cost 0.013323307037353516 seconds
DEBUG 01-13 08:46:33.524661.524661 cuda_h.py:10] start cpu_thread_manager_mp_wait
DEBUG 01-13 08:46:33.524538.524538 cuda_h.py:19] end cpu_thread_manager_mp_wait cost 4.9591064453125e-05 seconds
DEBUG 01-13 08:46:33.525389.525389 cuda_h.py:19] end layer_moe_generate_mp_l_13 cost 0.07146263122558594 seconds
DEBUG 01-13 08:46:33.525566.525566 lmp.py:1550] -------------------------------- end prefill layer 12 --------------------------------
DEBUG 01-13 08:46:33.525104.525104 lmp.py:1493] -------------------------------- start prefill layer 13 --------------------------------
DEBUG 01-13 08:46:33.525674.525674 cuda_h.py:10] start start_load_qkvogn_s_weight_l_14
DEBUG 01-13 08:46:33.525821.525821 cuda_h.py:10] start start_load_qkvogn_s_weight_l_14
DEBUG 01-13 08:46:33.525738.525738 cuda_h.py:19] end start_load_qkvogn_s_weight_l_14 cost 4.7206878662109375e-05 seconds
DEBUG 01-13 08:46:33.525746.525746 cuda_h.py:19] end start_load_qkvogn_s_weight_l_14 cost 8.416175842285156e-05 seconds
DEBUG 01-13 08:46:33.525826.525826 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-13 08:46:33.525797.525797 cuda_h.py:10] start sllm_worker_task
DEBUG 01-13 08:46:33.526423.526423 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-13 08:46:33.526658.526658 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-13 08:46:33.526878.526878 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-13 08:46:33.526924.526924 cuda_h.py:19] end allocate_cuda_memory cost 0.00032448768615722656 seconds
DEBUG 01-13 08:46:33.526430.526430 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-13 08:46:33.526544.526544 sllm_store_c.py:27] get device uuid map
DEBUG 01-13 08:46:33.527063.527063 sllm_store_c.py:29] call client load into gpu
DEBUG 01-13 08:46:33.527978.527978 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 3498f8d3-3806-43d7-aa90-7169e3741be7
DEBUG 01-13 08:46:33.527201.527201 client.py:106] call stub.LoadModelAsync
DEBUG 01-13 08:46:33.527533.527533 cuda_h.py:10] start self_attn
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-13 08:46:33.530768.530768 cuda_h.py:19] end self_attn cost 0.003165721893310547 seconds
DEBUG 01-13 08:46:33.531715.531715 cuda_h.py:19] end iln_self_attn_paln cost 0.005332231521606445 seconds
DEBUG 01-13 08:46:33.531717.531717 cuda_h.py:10] start layer_moe_generate_mp_l_14
DEBUG 01-13 08:46:33.531540.531540 cuda_h.py:10] start gate
DEBUG 01-13 08:46:33.532805.532805 cuda_h.py:19] end gate cost 0.0007483959197998047 seconds
DEBUG 01-13 08:46:33.532840.532840 cuda_h.py:10] start experts_map_get
DEBUG 01-13 08:46:33.532833.532833 lmp.py:1611] 
DEBUG 01-13 08:46:33.532833.532833 lmp.py:1611] Expert Token Distribution & Device Allocation:
DEBUG 01-13 08:46:33.532735.532735 lmp.py:1612]   Total experts: 64
DEBUG 01-13 08:46:33.532437.532437 lmp.py:1613]   CPU experts: 32 (50%)
DEBUG 01-13 08:46:33.532703.532703 lmp.py:1614]   GPU experts: 32 (50%)
DEBUG 01-13 08:46:33.532445.532445 lmp.py:1615] 
DEBUG 01-13 08:46:33.532445.532445 lmp.py:1615]   Expert ID | Tokens | Device
DEBUG 01-13 08:46:33.532996.532996 lmp.py:1616]   -----------------------------------
DEBUG 01-13 08:46:33.532315.532315 lmp.py:1622]   Expert 19 |     24 | CPU
DEBUG 01-13 08:46:33.532719.532719 lmp.py:1622]   Expert 30 |     24 | CPU
DEBUG 01-13 08:46:33.532647.532647 lmp.py:1622]   Expert 42 |     27 | CPU
DEBUG 01-13 08:46:33.532098.532098 lmp.py:1622]   Expert 32 |     38 | CPU
DEBUG 01-13 08:46:33.532502.532502 lmp.py:1622]   Expert  6 |     56 | CPU
DEBUG 01-13 08:46:33.532430.532430 lmp.py:1622]   Expert 53 |     69 | CPU
DEBUG 01-13 08:46:33.532119.532119 lmp.py:1622]   Expert  5 |     77 | CPU
DEBUG 01-13 08:46:33.532570.532570 lmp.py:1622]   Expert  1 |     78 | CPU
DEBUG 01-13 08:46:33.532259.532259 lmp.py:1622]   Expert  9 |    110 | CPU
DEBUG 01-13 08:46:33.532902.532902 lmp.py:1622]   Expert 13 |    112 | CPU
DEBUG 01-13 08:46:33.532353.532353 lmp.py:1622]   Expert 34 |    127 | CPU
DEBUG 01-13 08:46:33.532804.532804 lmp.py:1622]   Expert 26 |    128 | CPU
DEBUG 01-13 08:46:33.532255.532255 lmp.py:1622]   Expert 50 |    131 | CPU
DEBUG 01-13 08:46:33.532468.532468 lmp.py:1622]   Expert 63 |    132 | CPU
DEBUG 01-13 08:46:33.532203.532203 lmp.py:1622]   Expert 56 |    133 | CPU
DEBUG 01-13 08:46:33.532416.532416 lmp.py:1622]   Expert 59 |    133 | CPU
DEBUG 01-13 08:46:33.533913.533913 lmp.py:1622]   Expert 58 |    135 | CPU
DEBUG 01-13 08:46:33.533648.533648 lmp.py:1622]   Expert 31 |    138 | CPU
DEBUG 01-13 08:46:33.533146.533146 lmp.py:1622]   Expert 18 |    144 | CPU
DEBUG 01-13 08:46:33.533120.533120 lmp.py:1622]   Expert 11 |    145 | CPU
DEBUG 01-13 08:46:33.533094.533094 lmp.py:1622]   Expert 40 |    145 | CPU
DEBUG 01-13 08:46:33.533545.533545 lmp.py:1622]   Expert  2 |    147 | CPU
DEBUG 01-13 08:46:33.533949.533949 lmp.py:1622]   Expert 12 |    149 | CPU
DEBUG 01-13 08:46:33.533215.533215 lmp.py:1622]   Expert  4 |    150 | CPU
DEBUG 01-13 08:46:33.533096.533096 lmp.py:1622]   Expert 46 |    150 | CPU
DEBUG 01-13 08:46:33.533309.533309 lmp.py:1622]   Expert 20 |    151 | CPU
DEBUG 01-13 08:46:33.533283.533283 lmp.py:1622]   Expert 48 |    155 | CPU
DEBUG 01-13 08:46:33.533495.533495 lmp.py:1622]   Expert 33 |    159 | CPU
DEBUG 01-13 08:46:33.533708.533708 lmp.py:1622]   Expert 61 |    161 | CPU
DEBUG 01-13 08:46:33.533443.533443 lmp.py:1622]   Expert 10 |    167 | CPU
DEBUG 01-13 08:46:33.533417.533417 lmp.py:1622]   Expert 55 |    167 | CPU
DEBUG 01-13 08:46:33.533345.533345 lmp.py:1622]   Expert 35 |    175 | CPU
DEBUG 01-13 08:46:33.533273.533273 lmp.py:1622]   Expert 36 |    176 | GPU
DEBUG 01-13 08:46:33.533677.533677 lmp.py:1622]   Expert 51 |    181 | GPU
DEBUG 01-13 08:46:33.533890.533890 lmp.py:1622]   Expert  8 |    184 | GPU
DEBUG 01-13 08:46:33.533864.533864 lmp.py:1622]   Expert 52 |    190 | GPU
DEBUG 01-13 08:46:33.533076.533076 lmp.py:1622]   Expert 37 |    193 | GPU
DEBUG 01-13 08:46:33.533050.533050 lmp.py:1622]   Expert  0 |    199 | GPU
DEBUG 01-13 08:46:33.533024.533024 lmp.py:1622]   Expert 57 |    201 | GPU
DEBUG 01-13 08:46:33.533998.533998 lmp.py:1622]   Expert 39 |    219 | GPU
DEBUG 01-13 08:46:33.533972.533972 lmp.py:1622]   Expert 62 |    230 | GPU
DEBUG 01-13 08:46:33.533946.533946 lmp.py:1622]   Expert 25 |    235 | GPU
DEBUG 01-13 08:46:33.533682.533682 lmp.py:1622]   Expert 38 |    239 | GPU
DEBUG 01-13 08:46:33.533133.533133 lmp.py:1622]   Expert  7 |    250 | GPU
DEBUG 01-13 08:46:33.533299.533299 lmp.py:1622]   Expert 28 |    252 | GPU
DEBUG 01-13 08:46:33.533849.533849 lmp.py:1622]   Expert 49 |    253 | GPU
DEBUG 01-13 08:46:33.533492.533492 lmp.py:1622]   Expert 27 |    255 | GPU
DEBUG 01-13 08:46:33.533466.533466 lmp.py:1622]   Expert  3 |    256 | GPU
DEBUG 01-13 08:46:33.533679.533679 lmp.py:1622]   Expert 24 |    257 | GPU
DEBUG 01-13 08:46:33.533176.533176 lmp.py:1622]   Expert 16 |    258 | GPU
DEBUG 01-13 08:46:33.533150.533150 lmp.py:1622]   Expert 60 |    259 | GPU
DEBUG 01-13 08:46:33.533363.533363 lmp.py:1622]   Expert 21 |    260 | GPU
DEBUG 01-13 08:46:33.533337.533337 lmp.py:1622]   Expert 43 |    270 | GPU
DEBUG 01-13 08:46:33.533311.533311 lmp.py:1622]   Expert 23 |    282 | GPU
DEBUG 01-13 08:46:33.533046.533046 lmp.py:1622]   Expert 29 |    285 | GPU
DEBUG 01-13 08:46:33.533020.533020 lmp.py:1622]   Expert 15 |    290 | GPU
DEBUG 01-13 08:46:33.533710.533710 lmp.py:1622]   Expert 47 |    291 | GPU
DEBUG 01-13 08:46:33.533022.533022 lmp.py:1622]   Expert 41 |    294 | GPU
DEBUG 01-13 08:46:33.533665.533665 lmp.py:1622]   Expert 44 |    294 | GPU
DEBUG 01-13 08:46:33.533831.533831 lmp.py:1622]   Expert 22 |    295 | GPU
DEBUG 01-13 08:46:33.533805.533805 lmp.py:1622]   Expert 54 |    360 | GPU
DEBUG 01-13 08:46:33.533302.533302 lmp.py:1622]   Expert 14 |    374 | GPU
DEBUG 01-13 08:46:33.533276.533276 lmp.py:1622]   Expert 17 |    408 | GPU
DEBUG 01-13 08:46:33.533773.533773 lmp.py:1622]   Expert 45 |    461 | GPU
DEBUG 01-13 08:46:33.533462.533462 lmp.py:1623] 
DEBUG 01-13 08:46:33.533462.533462 lmp.py:1623]   CPU total tokens: 3837 (31.2%)
DEBUG 01-13 08:46:33.533867.533867 lmp.py:1624]   GPU total tokens: 8451 (68.8%)
DEBUG 01-13 08:46:33.533848.533848 cuda_h.py:19] end experts_map_get cost 0.0015871524810791016 seconds
DEBUG 01-13 08:46:33.533890.533890 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-13 08:46:33.533599.533599 lmp.py:1632] 
DEBUG 01-13 08:46:33.533599.533599 lmp.py:1632]   Computing 32 experts on CPU MP...
DEBUG 01-13 08:46:33.533204.533204 cuda_h.py:19] end cpu_experts_submit cost 6.008148193359375e-05 seconds
DEBUG 01-13 08:46:33.534231.534231 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-13 08:46:33.534465.534465 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-13 08:46:33.534591.534591 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-13 08:46:33.534126.534126 cuda_h.py:19] end allocate_cuda_memory cost 0.0003218650817871094 seconds
DEBUG 01-13 08:46:33.534221.534221 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-13 08:46:33.534077.534077 sllm_store_c.py:27] get device uuid map
DEBUG 01-13 08:46:33.534404.534404 sllm_store_c.py:29] call client load into gpu
DEBUG 01-13 08:46:33.534683.534683 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 628297ba-a148-4d1f-806c-2b3db37584fd
DEBUG 01-13 08:46:33.535738.535738 client.py:106] call stub.LoadModelAsync
DEBUG 01-13 08:46:33.537564.537564 cuda_h.py:10] start experts_func_gpu_einsum_mp
INFO 01-13 08:46:33.538836.538836 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 3498f8d3-3806-43d7-aa90-7169e3741be7
DEBUG 01-13 08:46:33.538986.538986 cuda_h.py:19] end load_into_gpu_async cost 0.003604412078857422 seconds
DEBUG 01-13 08:46:33.538942.538942 cuda_h.py:10] start restore_tensors2
DEBUG 01-13 08:46:33.538843.538843 cuda_h.py:19] end restore_tensors2 cost 0.00013971328735351562 seconds
DEBUG 01-13 08:46:33.538806.538806 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.004606962203979492 seconds
INFO 01-13 08:46:33.538604.538604 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 3498f8d3-3806-43d7-aa90-7169e3741be7
INFO 01-13 08:46:33.545981.545981 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 628297ba-a148-4d1f-806c-2b3db37584fd
DEBUG 01-13 08:46:33.545069.545069 cuda_h.py:19] end load_into_gpu_async cost 0.010843992233276367 seconds
DEBUG 01-13 08:46:33.545726.545726 cuda_h.py:10] start restore_tensors2
DEBUG 01-13 08:46:33.546204.546204 cuda_h.py:19] end restore_tensors2 cost 0.0006046295166015625 seconds
DEBUG 01-13 08:46:33.546299.546299 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.01221156120300293 seconds
DEBUG 01-13 08:46:33.546188.546188 cuda_h.py:10] start restore2model
INFO 01-13 08:46:33.546223.546223 client.py:127] Model loaded
DEBUG 01-13 08:46:33.546439.546439 cuda_h.py:10] start restore2model
DEBUG 01-13 08:46:33.549920.549920 cuda_h.py:19] end restore2model cost 0.0016837120056152344 seconds
DEBUG 01-13 08:46:33.549367.549367 cuda_h.py:19] end sllm_worker_task cost 0.023198843002319336 seconds
DEBUG 01-13 08:46:33.551965.551965 cuda_h.py:19] end restore2model cost 0.004011631011962891 seconds
DEBUG 01-13 08:46:33.551127.551127 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.017416715621948242 seconds
DEBUG 01-13 08:46:33.551161.551161 cuda_h.py:10] start gpu_sexperts
DEBUG 01-13 08:46:33.551636.551636 cuda_h.py:19] end gpu_sexperts cost 0.0003190040588378906 seconds
DEBUG 01-13 08:46:33.551995.551995 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-13 08:46:33.551540.551540 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.0265579223632812e-05 seconds
DEBUG 01-13 08:46:33.551190.551190 cuda_h.py:10] start wait_experts
INFO 01-13 08:46:33.551608.551608 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 628297ba-a148-4d1f-806c-2b3db37584fd
DEBUG 01-13 08:46:33.554561.554561 mlpmodule.py:1006] group tensors cost 0.016148805618286133 s
DEBUG 01-13 08:46:33.558962.558962 mlpmodule.py:1044] pad cost 0.0031473636627197266 s
DEBUG 01-13 08:46:33.558872.558872 mlpmodule.py:1050] create cpu tensor cost 0.00010037422180175781 s
DEBUG 01-13 08:46:33.558486.558486 mlpmodule.py:1055] move to cpu cost 5.91278076171875e-05 s
DEBUG 01-13 08:46:33.568420.568420 mlpmodule.py:1069] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-13 08:46:33.568260.568260 mlpmodule.py:1070] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-13 08:46:33.568701.568701 mlpmodule.py:1075] group_w3 first element: -0.0211181640625
WARNING 01-13 08:46:33.568917.568917 mlpmodule.py:1085] start einsum2
DEBUG 01-13 08:46:33.585997.585997 mlpmodule.py:1095] group einsum cost 0.02660346031188965 s
DEBUG 01-13 08:46:33.586767.586767 mlpmodule.py:1103] cpy2cputensor cost 0.0006549358367919922 s
INFO 01-13 08:46:33.596306.596306 client.py:127] Model loaded
DEBUG 01-13 08:46:33.596046.596046 cuda_h.py:19] end wait_experts cost 0.04471945762634277 seconds
DEBUG 01-13 08:46:33.596632.596632 cuda_h.py:10] start gpu_experts
DEBUG 01-13 08:46:33.598652.598652 mlpmodule.py:559] gpu group tensors cost 0.0014166831970214844 s
DEBUG 01-13 08:46:33.602265.602265 mlpmodule.py:592] gpu pad cost 0.004325389862060547 s
DEBUG 01-13 08:46:33.602872.602872 mlpmodule.py:598] start_w1
DEBUG 01-13 08:46:33.603225.603225 mlpmodule.py:602] start_w3
DEBUG 01-13 08:46:33.603108.603108 mlpmodule.py:785]  experts func einsum cost 0.06575560569763184 s
DEBUG 01-13 08:46:33.603804.603804 mlpmodule.py:608] start_w2
DEBUG 01-13 08:46:33.604043.604043 cuda_h.py:19] end experts_func_gpu_einsum_mp cost 0.06692266464233398 seconds
DEBUG 01-13 08:46:33.604431.604431 mlpmodule.py:611] gpu group einsum cost 0.0012576580047607422 s
DEBUG 01-13 08:46:33.608258.608258 mlpmodule.py:683] gpu experts func einsum cost 0.011806726455688477 s
DEBUG 01-13 08:46:33.608568.608568 cuda_h.py:19] end gpu_experts cost 0.01206064224243164 seconds
DEBUG 01-13 08:46:33.609888.609888 cuda_h.py:10] start cpu_thread_manager_mp_wait
DEBUG 01-13 08:46:33.609343.609343 cuda_h.py:19] end cpu_thread_manager_mp_wait cost 6.794929504394531e-05 seconds
DEBUG 01-13 08:46:33.609824.609824 cuda_h.py:19] end layer_moe_generate_mp_l_14 cost 0.0779118537902832 seconds
DEBUG 01-13 08:46:33.609694.609694 lmp.py:1550] -------------------------------- end prefill layer 13 --------------------------------
DEBUG 01-13 08:46:33.609643.609643 lmp.py:1493] -------------------------------- start prefill layer 14 --------------------------------
DEBUG 01-13 08:46:33.609903.609903 cuda_h.py:10] start start_load_qkvogn_s_weight_l_15
DEBUG 01-13 08:46:33.609124.609124 cuda_h.py:10] start start_load_qkvogn_s_weight_l_15
DEBUG 01-13 08:46:33.610458.610458 cuda_h.py:19] end start_load_qkvogn_s_weight_l_15 cost 5.340576171875e-05 seconds
DEBUG 01-13 08:46:33.610864.610864 cuda_h.py:19] end start_load_qkvogn_s_weight_l_15 cost 0.00011324882507324219 seconds
DEBUG 01-13 08:46:33.610349.610349 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-13 08:46:33.610697.610697 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-13 08:46:33.610371.610371 cuda_h.py:10] start sllm_worker_task
DEBUG 01-13 08:46:33.610503.610503 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-13 08:46:33.610785.610785 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-13 08:46:33.611621.611621 cuda_h.py:19] end allocate_cuda_memory cost 0.0005156993865966797 seconds
DEBUG 01-13 08:46:33.611971.611971 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-13 08:46:33.611008.611008 sllm_store_c.py:27] get device uuid map
DEBUG 01-13 08:46:33.611548.611548 sllm_store_c.py:29] call client load into gpu
DEBUG 01-13 08:46:33.611922.611922 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 6caf3df0-b802-43d8-83c0-ea5436b4f645
DEBUG 01-13 08:46:33.612538.612538 client.py:106] call stub.LoadModelAsync
DEBUG 01-13 08:46:33.612820.612820 cuda_h.py:10] start self_attn
INFO 01-13 08:46:33.613478.613478 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 6caf3df0-b802-43d8-83c0-ea5436b4f645
DEBUG 01-13 08:46:33.614026.614026 cuda_h.py:19] end load_into_gpu_async cost 0.0025386810302734375 seconds
DEBUG 01-13 08:46:33.614096.614096 cuda_h.py:10] start restore_tensors2
DEBUG 01-13 08:46:33.614932.614932 cuda_h.py:19] end restore_tensors2 cost 0.00017213821411132812 seconds
DEBUG 01-13 08:46:33.614135.614135 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0039556026458740234 seconds
INFO 01-13 08:46:33.614961.614961 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 6caf3df0-b802-43d8-83c0-ea5436b4f645
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-13 08:46:33.616686.616686 cuda_h.py:19] end self_attn cost 0.004017829895019531 seconds
DEBUG 01-13 08:46:33.616232.616232 cuda_h.py:19] end iln_self_attn_paln cost 0.006746053695678711 seconds
DEBUG 01-13 08:46:33.616460.616460 cuda_h.py:10] start layer_moe_generate_mp_l_15
DEBUG 01-13 08:46:33.617507.617507 cuda_h.py:10] start gate
DEBUG 01-13 08:46:33.617141.617141 cuda_h.py:19] end gate cost 0.0007131099700927734 seconds
DEBUG 01-13 08:46:33.617355.617355 cuda_h.py:10] start experts_map_get
DEBUG 01-13 08:46:33.618479.618479 lmp.py:1611] 
DEBUG 01-13 08:46:33.618479.618479 lmp.py:1611] Expert Token Distribution & Device Allocation:
DEBUG 01-13 08:46:33.618235.618235 lmp.py:1612]   Total experts: 64
DEBUG 01-13 08:46:33.618315.618315 lmp.py:1613]   CPU experts: 32 (50%)
DEBUG 01-13 08:46:33.618058.618058 lmp.py:1614]   GPU experts: 32 (50%)
DEBUG 01-13 08:46:33.618608.618608 lmp.py:1615] 
DEBUG 01-13 08:46:33.618608.618608 lmp.py:1615]   Expert ID | Tokens | Device
DEBUG 01-13 08:46:33.618158.618158 lmp.py:1616]   -----------------------------------
DEBUG 01-13 08:46:33.618100.618100 lmp.py:1622]   Expert 34 |     26 | CPU
DEBUG 01-13 08:46:33.618888.618888 lmp.py:1622]   Expert  7 |     29 | CPU
DEBUG 01-13 08:46:33.618008.618008 lmp.py:1622]   Expert 13 |     42 | CPU
DEBUG 01-13 08:46:33.618605.618605 lmp.py:1622]   Expert 18 |     77 | CPU
DEBUG 01-13 08:46:33.618201.618201 lmp.py:1622]   Expert 54 |     79 | CPU
DEBUG 01-13 08:46:33.618083.618083 lmp.py:1622]   Expert 39 |     89 | CPU
DEBUG 01-13 08:46:33.618964.618964 lmp.py:1622]   Expert 49 |     89 | CPU
DEBUG 01-13 08:46:33.618846.618846 lmp.py:1622]   Expert 21 |    100 | CPU
DEBUG 01-13 08:46:33.618396.618396 lmp.py:1622]   Expert 59 |    101 | CPU
DEBUG 01-13 08:46:33.618231.618231 lmp.py:1622]   Expert 16 |    104 | CPU
DEBUG 01-13 08:46:33.618543.618543 lmp.py:1622]   Expert  0 |    107 | CPU
DEBUG 01-13 08:46:33.618663.618663 lmp.py:1622]   Expert 15 |    114 | CPU
DEBUG 01-13 08:46:33.618306.618306 lmp.py:1622]   Expert 45 |    118 | CPU
DEBUG 01-13 08:46:33.618187.618187 lmp.py:1622]   Expert 41 |    119 | CPU
DEBUG 01-13 08:46:33.618830.618830 lmp.py:1622]   Expert 22 |    120 | CPU
DEBUG 01-13 08:46:33.618473.618473 lmp.py:1622]   Expert 17 |    130 | CPU
DEBUG 01-13 08:46:33.618878.618878 lmp.py:1622]   Expert 61 |    132 | CPU
DEBUG 01-13 08:46:33.618282.618282 lmp.py:1622]   Expert  8 |    134 | CPU
DEBUG 01-13 08:46:33.618448.618448 lmp.py:1622]   Expert 52 |    136 | CPU
DEBUG 01-13 08:46:33.618330.618330 lmp.py:1622]   Expert 12 |    141 | CPU
DEBUG 01-13 08:46:33.618642.618642 lmp.py:1622]   Expert 48 |    144 | CPU
DEBUG 01-13 08:46:33.618298.618298 lmp.py:1622]   Expert 38 |    148 | CPU
DEBUG 01-13 08:46:33.618656.618656 lmp.py:1622]   Expert 35 |    150 | CPU
DEBUG 01-13 08:46:33.618822.618822 lmp.py:1622]   Expert 50 |    152 | CPU
DEBUG 01-13 08:46:33.618181.618181 lmp.py:1622]   Expert 53 |    154 | CPU
DEBUG 01-13 08:46:33.618539.618539 lmp.py:1622]   Expert 36 |    158 | CPU
DEBUG 01-13 08:46:33.618420.618420 lmp.py:1622]   Expert 60 |    159 | CPU
DEBUG 01-13 08:46:33.618302.618302 lmp.py:1622]   Expert 40 |    160 | CPU
DEBUG 01-13 08:46:33.618183.618183 lmp.py:1622]   Expert 31 |    163 | CPU
DEBUG 01-13 08:46:33.618303.618303 lmp.py:1622]   Expert 27 |    173 | CPU
DEBUG 01-13 08:46:33.618423.618423 lmp.py:1622]   Expert 19 |    193 | CPU
DEBUG 01-13 08:46:33.618543.618543 lmp.py:1622]   Expert  4 |    198 | CPU
DEBUG 01-13 08:46:33.618424.618424 lmp.py:1622]   Expert 30 |    204 | GPU
DEBUG 01-13 08:46:33.618021.618021 lmp.py:1622]   Expert 29 |    208 | GPU
DEBUG 01-13 08:46:33.618048.618048 lmp.py:1622]   Expert 20 |    220 | GPU
DEBUG 01-13 08:46:33.618168.618168 lmp.py:1622]   Expert 11 |    221 | GPU
DEBUG 01-13 08:46:33.618003.618003 lmp.py:1622]   Expert  6 |    225 | GPU
DEBUG 01-13 08:46:33.618884.618884 lmp.py:1622]   Expert 26 |    225 | GPU
DEBUG 01-13 08:46:33.618527.618527 lmp.py:1622]   Expert 46 |    226 | GPU
DEBUG 01-13 08:46:33.619408.619408 lmp.py:1622]   Expert 57 |    228 | GPU
DEBUG 01-13 08:46:33.619051.619051 lmp.py:1622]   Expert 33 |    231 | GPU
DEBUG 01-13 08:46:33.619171.619171 lmp.py:1622]   Expert 43 |    231 | GPU
DEBUG 01-13 08:46:33.619245.619245 lmp.py:1622]   Expert  2 |    237 | GPU
DEBUG 01-13 08:46:33.619126.619126 lmp.py:1622]   Expert 42 |    243 | GPU
DEBUG 01-13 08:46:33.619769.619769 lmp.py:1622]   Expert 23 |    247 | GPU
DEBUG 01-13 08:46:33.619319.619319 lmp.py:1622]   Expert 55 |    251 | GPU
DEBUG 01-13 08:46:33.619870.619870 lmp.py:1622]   Expert 32 |    257 | GPU
DEBUG 01-13 08:46:33.619658.619658 lmp.py:1622]   Expert 56 |    257 | GPU
DEBUG 01-13 08:46:33.619017.619017 lmp.py:1622]   Expert  9 |    261 | GPU
DEBUG 01-13 08:46:33.619136.619136 lmp.py:1622]   Expert 28 |    262 | GPU
DEBUG 01-13 08:46:33.619256.619256 lmp.py:1622]   Expert 44 |    266 | GPU
DEBUG 01-13 08:46:33.619661.619661 lmp.py:1622]   Expert 51 |    268 | GPU
DEBUG 01-13 08:46:33.619019.619019 lmp.py:1622]   Expert  3 |    270 | GPU
DEBUG 01-13 08:46:33.619139.619139 lmp.py:1622]   Expert 14 |    275 | GPU
DEBUG 01-13 08:46:33.619497.619497 lmp.py:1622]   Expert  1 |    278 | GPU
DEBUG 01-13 08:46:33.619617.619617 lmp.py:1622]   Expert 58 |    278 | GPU
DEBUG 01-13 08:46:33.619498.619498 lmp.py:1622]   Expert 47 |    283 | GPU
DEBUG 01-13 08:46:33.619141.619141 lmp.py:1622]   Expert 63 |    291 | GPU
DEBUG 01-13 08:46:33.619453.619453 lmp.py:1622]   Expert 37 |    295 | GPU
DEBUG 01-13 08:46:33.619573.619573 lmp.py:1622]   Expert 62 |    297 | GPU
DEBUG 01-13 08:46:33.619123.619123 lmp.py:1622]   Expert 10 |    315 | GPU
DEBUG 01-13 08:46:33.619482.619482 lmp.py:1622]   Expert 24 |    315 | GPU
DEBUG 01-13 08:46:33.619125.619125 lmp.py:1622]   Expert 25 |    316 | GPU
DEBUG 01-13 08:46:33.619006.619006 lmp.py:1622]   Expert  5 |    368 | GPU
DEBUG 01-13 08:46:33.619318.619318 lmp.py:1623] 
DEBUG 01-13 08:46:33.619318.619318 lmp.py:1623]   CPU total tokens: 3939 (32.1%)
DEBUG 01-13 08:46:33.619630.619630 lmp.py:1624]   GPU total tokens: 8349 (67.9%)
DEBUG 01-13 08:46:33.619472.619472 cuda_h.py:19] end experts_map_get cost 0.0016720294952392578 seconds
DEBUG 01-13 08:46:33.619851.619851 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-13 08:46:33.619800.619800 lmp.py:1632] 
DEBUG 01-13 08:46:33.619800.619800 lmp.py:1632]   Computing 32 experts on CPU MP...
DEBUG 01-13 08:46:33.619166.619166 cuda_h.py:19] end cpu_experts_submit cost 5.936622619628906e-05 seconds
DEBUG 01-13 08:46:33.619431.619431 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-13 08:46:33.619466.619466 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-13 08:46:33.619354.619354 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-13 08:46:33.621807.621807 cuda_h.py:19] end allocate_cuda_memory cost 0.0014202594757080078 seconds
DEBUG 01-13 08:46:33.621822.621822 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-13 08:46:33.621631.621631 sllm_store_c.py:27] get device uuid map
DEBUG 01-13 08:46:33.621560.621560 sllm_store_c.py:29] call client load into gpu
DEBUG 01-13 08:46:33.622217.622217 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 55ca9f16-e2ff-4918-81ae-7d6e4c3a29d9
DEBUG 01-13 08:46:33.622636.622636 client.py:106] call stub.LoadModelAsync
INFO 01-13 08:46:33.623230.623230 client.py:127] Model loaded
DEBUG 01-13 08:46:33.623221.623221 cuda_h.py:10] start restore2model
DEBUG 01-13 08:46:33.624179.624179 cuda_h.py:19] end restore2model cost 0.0010027885437011719 seconds
DEBUG 01-13 08:46:33.624760.624760 cuda_h.py:19] end sllm_worker_task cost 0.014035463333129883 seconds
INFO 01-13 08:46:33.624217.624217 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 55ca9f16-e2ff-4918-81ae-7d6e4c3a29d9
DEBUG 01-13 08:46:33.624329.624329 cuda_h.py:19] end load_into_gpu_async cost 0.0030357837677001953 seconds
DEBUG 01-13 08:46:33.625337.625337 cuda_h.py:10] start restore_tensors2
DEBUG 01-13 08:46:33.625108.625108 cuda_h.py:10] start experts_func_gpu_einsum_mp
DEBUG 01-13 08:46:33.627314.627314 cuda_h.py:19] end restore_tensors2 cost 0.002756834030151367 seconds
DEBUG 01-13 08:46:33.628083.628083 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.008286714553833008 seconds
DEBUG 01-13 08:46:33.628258.628258 cuda_h.py:10] start restore2model
DEBUG 01-13 08:46:33.631497.631497 cuda_h.py:19] end restore2model cost 0.0029435157775878906 seconds
DEBUG 01-13 08:46:33.631115.631115 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.01150822639465332 seconds
DEBUG 01-13 08:46:33.631149.631149 cuda_h.py:10] start gpu_sexperts
DEBUG 01-13 08:46:33.631903.631903 cuda_h.py:19] end gpu_sexperts cost 0.0003142356872558594 seconds
DEBUG 01-13 08:46:33.631401.631401 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-13 08:46:33.631231.631231 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 1.9311904907226562e-05 seconds
DEBUG 01-13 08:46:33.631119.631119 cuda_h.py:10] start wait_experts
INFO 01-13 08:46:33.631822.631822 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 55ca9f16-e2ff-4918-81ae-7d6e4c3a29d9
DEBUG 01-13 08:46:33.640105.640105 mlpmodule.py:1006] group tensors cost 0.012035369873046875 s
DEBUG 01-13 08:46:33.646288.646288 mlpmodule.py:1044] pad cost 0.0043697357177734375 s
DEBUG 01-13 08:46:33.646381.646381 mlpmodule.py:1050] create cpu tensor cost 9.751319885253906e-05 s
DEBUG 01-13 08:46:33.646902.646902 mlpmodule.py:1055] move to cpu cost 6.389617919921875e-05 s
DEBUG 01-13 08:46:33.661477.661477 mlpmodule.py:1069] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-13 08:46:33.661311.661311 mlpmodule.py:1070] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-13 08:46:33.661162.661162 mlpmodule.py:1075] group_w3 first element: 0.000789642333984375
WARNING 01-13 08:46:33.661239.661239 mlpmodule.py:1085] start einsum2
INFO 01-13 08:46:33.673388.673388 client.py:127] Model loaded
DEBUG 01-13 08:46:33.673890.673890 cuda_h.py:19] end wait_experts cost 0.04139137268066406 seconds
DEBUG 01-13 08:46:33.673316.673316 cuda_h.py:10] start gpu_experts
DEBUG 01-13 08:46:33.674760.674760 mlpmodule.py:559] gpu group tensors cost 0.0012180805206298828 s
DEBUG 01-13 08:46:33.678559.678559 mlpmodule.py:1095] group einsum cost 0.03158450126647949 s
DEBUG 01-13 08:46:33.679253.679253 mlpmodule.py:1103] cpy2cputensor cost 0.0007264614105224609 s
DEBUG 01-13 08:46:33.684526.684526 mlpmodule.py:592] gpu pad cost 0.009607315063476562 s
DEBUG 01-13 08:46:33.684517.684517 mlpmodule.py:598] start_w1
DEBUG 01-13 08:46:33.685185.685185 mlpmodule.py:602] start_w3
DEBUG 01-13 08:46:33.685361.685361 mlpmodule.py:608] start_w2
DEBUG 01-13 08:46:33.686282.686282 mlpmodule.py:611] gpu group einsum cost 0.0013117790222167969 s
DEBUG 01-13 08:46:33.689073.689073 mlpmodule.py:683] gpu experts func einsum cost 0.01631641387939453 s
DEBUG 01-13 08:46:33.689561.689561 cuda_h.py:19] end gpu_experts cost 0.0165555477142334 seconds
DEBUG 01-13 08:46:33.689708.689708 cuda_h.py:10] start cpu_thread_manager_mp_wait
DEBUG 01-13 08:46:33.690540.690540 cuda_h.py:19] end cpu_thread_manager_mp_wait cost 8.463859558105469e-05 seconds
DEBUG 01-13 08:46:33.690113.690113 cuda_h.py:19] end layer_moe_generate_mp_l_15 cost 0.07309460639953613 seconds
DEBUG 01-13 08:46:33.690061.690061 lmp.py:1550] -------------------------------- end prefill layer 14 --------------------------------
DEBUG 01-13 08:46:33.690705.690705 lmp.py:1493] -------------------------------- start prefill layer 15 --------------------------------
DEBUG 01-13 08:46:33.690230.690230 cuda_h.py:10] start start_load_qkvogn_s_weight_l_16
DEBUG 01-13 08:46:33.690907.690907 cuda_h.py:10] start start_load_qkvogn_s_weight_l_16
DEBUG 01-13 08:46:33.690188.690188 cuda_h.py:19] end start_load_qkvogn_s_weight_l_16 cost 6.890296936035156e-05 seconds
DEBUG 01-13 08:46:33.690328.690328 cuda_h.py:19] end start_load_qkvogn_s_weight_l_16 cost 0.0001068115234375 seconds
DEBUG 01-13 08:46:33.690647.690647 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-13 08:46:33.690578.690578 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-13 08:46:33.691142.691142 cuda_h.py:10] start sllm_worker_task
DEBUG 01-13 08:46:33.691186.691186 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-13 08:46:33.691996.691996 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-13 08:46:33.691567.691567 cuda_h.py:19] end allocate_cuda_memory cost 0.00037789344787597656 seconds
DEBUG 01-13 08:46:33.691411.691411 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-13 08:46:33.691234.691234 sllm_store_c.py:27] get device uuid map
DEBUG 01-13 08:46:33.692011.692011 sllm_store_c.py:29] call client load into gpu
DEBUG 01-13 08:46:33.692867.692867 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 05505434-45b2-4e10-81c4-854ae3cad4a3
DEBUG 01-13 08:46:33.692838.692838 client.py:106] call stub.LoadModelAsync
DEBUG 01-13 08:46:33.692784.692784 cuda_h.py:10] start self_attn
INFO 01-13 08:46:33.694139.694139 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 05505434-45b2-4e10-81c4-854ae3cad4a3
DEBUG 01-13 08:46:33.694935.694935 cuda_h.py:19] end load_into_gpu_async cost 0.002172708511352539 seconds
DEBUG 01-13 08:46:33.694115.694115 cuda_h.py:10] start restore_tensors2
DEBUG 01-13 08:46:33.694112.694112 cuda_h.py:19] end restore_tensors2 cost 7.510185241699219e-05 seconds
DEBUG 01-13 08:46:33.694345.694345 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.002924680709838867 seconds
INFO 01-13 08:46:33.694963.694963 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 05505434-45b2-4e10-81c4-854ae3cad4a3
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-13 08:46:33.696108.696108 cuda_h.py:19] end self_attn cost 0.004267454147338867 seconds
DEBUG 01-13 08:46:33.697949.697949 cuda_h.py:19] end iln_self_attn_paln cost 0.006398916244506836 seconds
DEBUG 01-13 08:46:33.697183.697183 cuda_h.py:10] start layer_moe_generate_mp_l_16
DEBUG 01-13 08:46:33.697615.697615 cuda_h.py:10] start gate
DEBUG 01-13 08:46:33.698395.698395 cuda_h.py:19] end gate cost 0.0009241104125976562 seconds
DEBUG 01-13 08:46:33.698370.698370 cuda_h.py:10] start experts_map_get
DEBUG 01-13 08:46:33.698540.698540 lmp.py:1611] 
DEBUG 01-13 08:46:33.698540.698540 lmp.py:1611] Expert Token Distribution & Device Allocation:
DEBUG 01-13 08:46:33.698362.698362 lmp.py:1612]   Total experts: 64
DEBUG 01-13 08:46:33.698350.698350 lmp.py:1613]   CPU experts: 32 (50%)
DEBUG 01-13 08:46:33.698569.698569 lmp.py:1614]   GPU experts: 32 (50%)
DEBUG 01-13 08:46:33.698404.698404 lmp.py:1615] 
DEBUG 01-13 08:46:33.698404.698404 lmp.py:1615]   Expert ID | Tokens | Device
DEBUG 01-13 08:46:33.699432.699432 lmp.py:1616]   -----------------------------------
DEBUG 01-13 08:46:33.699134.699134 lmp.py:1622]   Expert 15 |     60 | CPU
DEBUG 01-13 08:46:33.699446.699446 lmp.py:1622]   Expert 41 |     71 | CPU
DEBUG 01-13 08:46:33.699328.699328 lmp.py:1622]   Expert 63 |     75 | CPU
DEBUG 01-13 08:46:33.699209.699209 lmp.py:1622]   Expert  0 |     77 | CPU
DEBUG 01-13 08:46:33.699852.699852 lmp.py:1622]   Expert 20 |     80 | CPU
DEBUG 01-13 08:46:33.699495.699495 lmp.py:1622]   Expert 45 |     88 | CPU
DEBUG 01-13 08:46:33.699900.699900 lmp.py:1622]   Expert 28 |     91 | CPU
DEBUG 01-13 08:46:33.699543.699543 lmp.py:1622]   Expert  7 |     92 | CPU
DEBUG 01-13 08:46:33.699616.699616 lmp.py:1622]   Expert 54 |    101 | CPU
DEBUG 01-13 08:46:33.699498.699498 lmp.py:1622]   Expert 12 |    106 | CPU
DEBUG 01-13 08:46:33.699856.699856 lmp.py:1622]   Expert  5 |    122 | CPU
DEBUG 01-13 08:46:33.699737.699737 lmp.py:1622]   Expert 40 |    123 | CPU
DEBUG 01-13 08:46:33.699142.699142 lmp.py:1622]   Expert 52 |    123 | CPU
DEBUG 01-13 08:46:33.699785.699785 lmp.py:1622]   Expert  4 |    124 | CPU
DEBUG 01-13 08:46:33.699189.699189 lmp.py:1622]   Expert 59 |    125 | CPU
DEBUG 01-13 08:46:33.699355.699355 lmp.py:1622]   Expert 34 |    127 | CPU
DEBUG 01-13 08:46:33.699760.699760 lmp.py:1622]   Expert 62 |    134 | CPU
DEBUG 01-13 08:46:33.699688.699688 lmp.py:1622]   Expert 61 |    136 | CPU
DEBUG 01-13 08:46:33.699854.699854 lmp.py:1622]   Expert 13 |    137 | CPU
DEBUG 01-13 08:46:33.699781.699781 lmp.py:1622]   Expert 21 |    138 | CPU
DEBUG 01-13 08:46:33.699948.699948 lmp.py:1622]   Expert 55 |    138 | CPU
DEBUG 01-13 08:46:33.699114.699114 lmp.py:1622]   Expert 10 |    142 | CPU
DEBUG 01-13 08:46:33.699995.699995 lmp.py:1622]   Expert 42 |    142 | CPU
DEBUG 01-13 08:46:33.699638.699638 lmp.py:1622]   Expert 22 |    145 | CPU
DEBUG 01-13 08:46:33.699520.699520 lmp.py:1622]   Expert 14 |    146 | CPU
DEBUG 01-13 08:46:33.699162.699162 lmp.py:1622]   Expert 51 |    151 | CPU
DEBUG 01-13 08:46:33.699567.699567 lmp.py:1622]   Expert 32 |    158 | CPU
DEBUG 01-13 08:46:33.699495.699495 lmp.py:1622]   Expert 25 |    166 | CPU
DEBUG 01-13 08:46:33.699661.699661 lmp.py:1622]   Expert 53 |    171 | CPU
DEBUG 01-13 08:46:33.699827.699827 lmp.py:1622]   Expert 19 |    175 | CPU
DEBUG 01-13 08:46:33.699232.699232 lmp.py:1622]   Expert  1 |    179 | CPU
DEBUG 01-13 08:46:33.699398.699398 lmp.py:1622]   Expert 47 |    180 | CPU
DEBUG 01-13 08:46:33.699802.699802 lmp.py:1622]   Expert  6 |    181 | GPU
DEBUG 01-13 08:46:33.699968.699968 lmp.py:1622]   Expert 50 |    181 | GPU
DEBUG 01-13 08:46:33.699611.699611 lmp.py:1622]   Expert 26 |    182 | GPU
DEBUG 01-13 08:46:33.699731.699731 lmp.py:1622]   Expert  2 |    183 | GPU
DEBUG 01-13 08:46:33.699851.699851 lmp.py:1622]   Expert 30 |    184 | GPU
DEBUG 01-13 08:46:33.699494.699494 lmp.py:1622]   Expert 35 |    187 | GPU
DEBUG 01-13 08:46:33.699852.699852 lmp.py:1622]   Expert 57 |    187 | GPU
DEBUG 01-13 08:46:33.699018.699018 lmp.py:1622]   Expert 11 |    189 | GPU
DEBUG 01-13 08:46:33.699661.699661 lmp.py:1622]   Expert 56 |    192 | GPU
DEBUG 01-13 08:46:33.699827.699827 lmp.py:1622]   Expert 44 |    203 | GPU
DEBUG 01-13 08:46:33.699755.699755 lmp.py:1622]   Expert 48 |    204 | GPU
DEBUG 01-13 08:46:33.699921.699921 lmp.py:1622]   Expert 24 |    209 | GPU
DEBUG 01-13 08:46:33.699849.699849 lmp.py:1622]   Expert 46 |    213 | GPU
DEBUG 01-13 08:46:33.699538.699538 lmp.py:1622]   Expert 18 |    219 | GPU
DEBUG 01-13 08:46:33.699705.699705 lmp.py:1622]   Expert 39 |    224 | GPU
DEBUG 01-13 08:46:33.699347.699347 lmp.py:1622]   Expert 16 |    225 | GPU
DEBUG 01-13 08:46:33.699136.699136 lmp.py:1622]   Expert 37 |    232 | GPU
DEBUG 01-13 08:46:33.699256.699256 lmp.py:1622]   Expert 29 |    234 | GPU
DEBUG 01-13 08:46:33.699853.699853 lmp.py:1622]   Expert 31 |    247 | GPU
DEBUG 01-13 08:46:33.699257.699257 lmp.py:1622]   Expert  3 |    261 | GPU
DEBUG 01-13 08:46:33.699185.699185 lmp.py:1622]   Expert 17 |    261 | GPU
DEBUG 01-13 08:46:33.699874.699874 lmp.py:1622]   Expert 36 |    261 | GPU
DEBUG 01-13 08:46:33.699709.699709 lmp.py:1622]   Expert 60 |    262 | GPU
DEBUG 01-13 08:46:33.700591.700591 lmp.py:1622]   Expert 38 |    263 | GPU
DEBUG 01-13 08:46:33.700472.700472 lmp.py:1622]   Expert  9 |    264 | GPU
DEBUG 01-13 08:46:33.700354.700354 lmp.py:1622]   Expert 23 |    268 | GPU
DEBUG 01-13 08:46:33.700712.700712 lmp.py:1622]   Expert 27 |    360 | GPU
DEBUG 01-13 08:46:33.700070.700070 lmp.py:1622]   Expert 43 |    366 | GPU
DEBUG 01-13 08:46:33.700667.700667 lmp.py:1622]   Expert 33 |    400 | GPU
DEBUG 01-13 08:46:33.700502.700502 lmp.py:1622]   Expert  8 |    441 | GPU
DEBUG 01-13 08:46:33.700860.700860 lmp.py:1622]   Expert 58 |    444 | GPU
DEBUG 01-13 08:46:33.700980.700980 lmp.py:1622]   Expert 49 |    538 | GPU
DEBUG 01-13 08:46:33.700292.700292 lmp.py:1623] 
DEBUG 01-13 08:46:33.700292.700292 lmp.py:1623]   CPU total tokens: 4023 (32.7%)
DEBUG 01-13 08:46:33.700127.700127 lmp.py:1624]   GPU total tokens: 8265 (67.3%)
DEBUG 01-13 08:46:33.700684.700684 cuda_h.py:19] end experts_map_get cost 0.0018155574798583984 seconds
DEBUG 01-13 08:46:33.700600.700600 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-13 08:46:33.700264.700264 lmp.py:1632] 
DEBUG 01-13 08:46:33.700264.700264 lmp.py:1632]   Computing 32 experts on CPU MP...
DEBUG 01-13 08:46:33.700935.700935 cuda_h.py:19] end cpu_experts_submit cost 6.699562072753906e-05 seconds
DEBUG 01-13 08:46:33.700300.700300 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-13 08:46:33.700421.700421 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-13 08:46:33.700479.700479 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-13 08:46:33.700225.700225 cuda_h.py:19] end allocate_cuda_memory cost 0.00030159950256347656 seconds
DEBUG 01-13 08:46:33.701890.701890 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-13 08:46:33.701269.701269 sllm_store_c.py:27] get device uuid map
DEBUG 01-13 08:46:33.701575.701575 sllm_store_c.py:29] call client load into gpu
DEBUG 01-13 08:46:33.701755.701755 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 1f37580c-6ece-49f3-901a-748d09f3607e
DEBUG 01-13 08:46:33.701901.701901 client.py:106] call stub.LoadModelAsync
INFO 01-13 08:46:33.702864.702864 client.py:127] Model loaded
DEBUG 01-13 08:46:33.702846.702846 cuda_h.py:10] start restore2model
DEBUG 01-13 08:46:33.702216.702216 cuda_h.py:19] end restore2model cost 0.0003440380096435547 seconds
DEBUG 01-13 08:46:33.702463.702463 cuda_h.py:19] end sllm_worker_task cost 0.011240005493164062 seconds
INFO 01-13 08:46:33.703277.703277 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 1f37580c-6ece-49f3-901a-748d09f3607e
DEBUG 01-13 08:46:33.703034.703034 cuda_h.py:19] end load_into_gpu_async cost 0.0022821426391601562 seconds
DEBUG 01-13 08:46:33.703359.703359 cuda_h.py:10] start restore_tensors2
DEBUG 01-13 08:46:33.703859.703859 cuda_h.py:19] end restore_tensors2 cost 0.0004401206970214844 seconds
DEBUG 01-13 08:46:33.703556.703556 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0034110546112060547 seconds
DEBUG 01-13 08:46:33.703041.703041 cuda_h.py:10] start restore2model
DEBUG 01-13 08:46:33.704943.704943 mlpmodule.py:785]  experts func einsum cost 0.07610821723937988 s
DEBUG 01-13 08:46:33.705587.705587 cuda_h.py:19] end experts_func_gpu_einsum_mp cost 0.07956457138061523 seconds
DEBUG 01-13 08:46:33.706413.706413 cuda_h.py:10] start experts_func_gpu_einsum_mp
DEBUG 01-13 08:46:33.707781.707781 cuda_h.py:19] end restore2model cost 0.0030765533447265625 seconds
DEBUG 01-13 08:46:33.707624.707624 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.006676197052001953 seconds
DEBUG 01-13 08:46:33.707704.707704 cuda_h.py:10] start gpu_sexperts
DEBUG 01-13 08:46:33.707954.707954 cuda_h.py:19] end gpu_sexperts cost 0.0003294944763183594 seconds
DEBUG 01-13 08:46:33.707168.707168 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-13 08:46:33.707474.707474 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 1.6927719116210938e-05 seconds
DEBUG 01-13 08:46:33.707839.707839 cuda_h.py:10] start wait_experts
INFO 01-13 08:46:33.707350.707350 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 1f37580c-6ece-49f3-901a-748d09f3607e
DEBUG 01-13 08:46:33.711684.711684 mlpmodule.py:1006] group tensors cost 0.004439592361450195 s
DEBUG 01-13 08:46:33.713592.713592 mlpmodule.py:1044] pad cost 0.0015354156494140625 s
DEBUG 01-13 08:46:33.713536.713536 mlpmodule.py:1050] create cpu tensor cost 4.38690185546875e-05 s
DEBUG 01-13 08:46:33.713684.713684 mlpmodule.py:1055] move to cpu cost 3.0517578125e-05 s
DEBUG 01-13 08:46:33.727881.727881 mlpmodule.py:1069] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-13 08:46:33.727052.727052 mlpmodule.py:1070] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-13 08:46:33.727168.727168 mlpmodule.py:1075] group_w3 first element: -0.0595703125
WARNING 01-13 08:46:33.727370.727370 mlpmodule.py:1085] start einsum2
DEBUG 01-13 08:46:33.741258.741258 mlpmodule.py:1095] group einsum cost 0.027349233627319336 s
DEBUG 01-13 08:46:33.741326.741326 mlpmodule.py:1103] cpy2cputensor cost 0.00066375732421875 s
INFO 01-13 08:46:33.754650.754650 client.py:127] Model loaded
DEBUG 01-13 08:46:33.754179.754179 cuda_h.py:19] end wait_experts cost 0.04707813262939453 seconds
DEBUG 01-13 08:46:33.754803.754803 cuda_h.py:10] start gpu_experts
DEBUG 01-13 08:46:33.755847.755847 mlpmodule.py:559] gpu group tensors cost 0.0007846355438232422 s
DEBUG 01-13 08:46:33.757637.757637 mlpmodule.py:592] gpu pad cost 0.0021550655364990234 s
DEBUG 01-13 08:46:33.758083.758083 mlpmodule.py:598] start_w1
DEBUG 01-13 08:46:33.758534.758534 mlpmodule.py:602] start_w3
DEBUG 01-13 08:46:33.758375.758375 mlpmodule.py:608] start_w2
DEBUG 01-13 08:46:33.758427.758427 mlpmodule.py:611] gpu group einsum cost 0.0007798671722412109 s
DEBUG 01-13 08:46:33.761770.761770 mlpmodule.py:683] gpu experts func einsum cost 0.006807088851928711 s
DEBUG 01-13 08:46:33.761912.761912 cuda_h.py:19] end gpu_experts cost 0.00700068473815918 seconds
DEBUG 01-13 08:46:33.761807.761807 cuda_h.py:10] start cpu_thread_manager_mp_wait
DEBUG 01-13 08:46:33.761625.761625 cuda_h.py:19] end cpu_thread_manager_mp_wait cost 4.649162292480469e-05 seconds
DEBUG 01-13 08:46:33.762747.762747 cuda_h.py:19] end layer_moe_generate_mp_l_16 cost 0.06467294692993164 seconds
DEBUG 01-13 08:46:33.762842.762842 lmp.py:1550] -------------------------------- end prefill layer 15 --------------------------------
DEBUG 01-13 08:46:33.762082.762082 lmp.py:1493] -------------------------------- start prefill layer 16 --------------------------------
DEBUG 01-13 08:46:33.762454.762454 cuda_h.py:10] start start_load_qkvogn_s_weight_l_17
DEBUG 01-13 08:46:33.762494.762494 cuda_h.py:10] start start_load_qkvogn_s_weight_l_17
DEBUG 01-13 08:46:33.762006.762006 cuda_h.py:19] end start_load_qkvogn_s_weight_l_17 cost 3.528594970703125e-05 seconds
DEBUG 01-13 08:46:33.762731.762731 cuda_h.py:10] start sllm_worker_task
DEBUG 01-13 08:46:33.762806.762806 cuda_h.py:19] end start_load_qkvogn_s_weight_l_17 cost 0.00016808509826660156 seconds
DEBUG 01-13 08:46:33.762484.762484 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-13 08:46:33.762823.762823 mlpmodule.py:785]  experts func einsum cost 0.0556793212890625 s
DEBUG 01-13 08:46:33.762975.762975 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-13 08:46:33.762209.762209 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-13 08:46:33.762326.762326 cuda_h.py:19] end experts_func_gpu_einsum_mp cost 0.05668449401855469 seconds
DEBUG 01-13 08:46:33.763157.763157 cuda_h.py:19] end allocate_cuda_memory cost 0.0003311634063720703 seconds
DEBUG 01-13 08:46:33.763339.763339 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-13 08:46:33.763838.763838 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-13 08:46:33.763543.763543 sllm_store_c.py:27] get device uuid map
DEBUG 01-13 08:46:33.763558.763558 sllm_store_c.py:29] call client load into gpu
DEBUG 01-13 08:46:33.763784.763784 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 09ec616a-1937-4d12-9c6d-daccf86121ea
DEBUG 01-13 08:46:33.763091.763091 client.py:106] call stub.LoadModelAsync
DEBUG 01-13 08:46:33.763646.763646 cuda_h.py:10] start self_attn
INFO 01-13 08:46:33.765756.765756 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 09ec616a-1937-4d12-9c6d-daccf86121ea
DEBUG 01-13 08:46:33.765493.765493 cuda_h.py:19] end load_into_gpu_async cost 0.0018603801727294922 seconds
DEBUG 01-13 08:46:33.765070.765070 cuda_h.py:10] start restore_tensors2
DEBUG 01-13 08:46:33.765292.765292 cuda_h.py:19] end restore_tensors2 cost 6.699562072753906e-05 seconds
DEBUG 01-13 08:46:33.765094.765094 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0027132034301757812 seconds
INFO 01-13 08:46:33.765083.765083 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 09ec616a-1937-4d12-9c6d-daccf86121ea
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-13 08:46:33.767575.767575 cuda_h.py:19] end self_attn cost 0.0033597946166992188 seconds
DEBUG 01-13 08:46:33.767534.767534 cuda_h.py:19] end iln_self_attn_paln cost 0.004891872406005859 seconds
DEBUG 01-13 08:46:33.767423.767423 cuda_h.py:10] start layer_moe_generate_mp_l_17
DEBUG 01-13 08:46:33.767862.767862 cuda_h.py:10] start gate
DEBUG 01-13 08:46:33.768451.768451 cuda_h.py:19] end gate cost 0.0007457733154296875 seconds
DEBUG 01-13 08:46:33.768711.768711 cuda_h.py:10] start experts_map_get
DEBUG 01-13 08:46:33.769481.769481 lmp.py:1611] 
DEBUG 01-13 08:46:33.769481.769481 lmp.py:1611] Expert Token Distribution & Device Allocation:
DEBUG 01-13 08:46:33.769953.769953 lmp.py:1612]   Total experts: 64
DEBUG 01-13 08:46:33.769748.769748 lmp.py:1613]   CPU experts: 32 (50%)
DEBUG 01-13 08:46:33.769729.769729 lmp.py:1614]   GPU experts: 32 (50%)
DEBUG 01-13 08:46:33.769803.769803 lmp.py:1615] 
DEBUG 01-13 08:46:33.769803.769803 lmp.py:1615]   Expert ID | Tokens | Device
DEBUG 01-13 08:46:33.769114.769114 lmp.py:1616]   -----------------------------------
DEBUG 01-13 08:46:33.769910.769910 lmp.py:1622]   Expert 58 |     38 | CPU
DEBUG 01-13 08:46:33.769222.769222 lmp.py:1622]   Expert 47 |     59 | CPU
DEBUG 01-13 08:46:33.769057.769057 lmp.py:1622]   Expert 31 |     60 | CPU
DEBUG 01-13 08:46:33.769654.769654 lmp.py:1622]   Expert 49 |     63 | CPU
DEBUG 01-13 08:46:33.769012.769012 lmp.py:1622]   Expert  4 |     68 | CPU
DEBUG 01-13 08:46:33.769132.769132 lmp.py:1622]   Expert 45 |     69 | CPU
DEBUG 01-13 08:46:33.769490.769490 lmp.py:1622]   Expert 38 |     72 | CPU
DEBUG 01-13 08:46:33.769610.769610 lmp.py:1622]   Expert 43 |     74 | CPU
DEBUG 01-13 08:46:33.769730.769730 lmp.py:1622]   Expert 41 |     90 | CPU
DEBUG 01-13 08:46:33.769849.769849 lmp.py:1622]   Expert 33 |     99 | CPU
DEBUG 01-13 08:46:33.769638.769638 lmp.py:1622]   Expert 57 |    102 | CPU
DEBUG 01-13 08:46:33.769712.769712 lmp.py:1622]   Expert 11 |    105 | CPU
DEBUG 01-13 08:46:33.769547.769547 lmp.py:1622]   Expert 50 |    109 | CPU
DEBUG 01-13 08:46:33.769620.769620 lmp.py:1622]   Expert  2 |    111 | CPU
DEBUG 01-13 08:46:33.769217.769217 lmp.py:1622]   Expert 51 |    116 | CPU
DEBUG 01-13 08:46:33.769575.769575 lmp.py:1622]   Expert  0 |    121 | CPU
DEBUG 01-13 08:46:33.769695.769695 lmp.py:1622]   Expert 54 |    125 | CPU
DEBUG 01-13 08:46:33.769815.769815 lmp.py:1622]   Expert 14 |    127 | CPU
DEBUG 01-13 08:46:33.769173.769173 lmp.py:1622]   Expert 56 |    135 | CPU
DEBUG 01-13 08:46:33.769054.769054 lmp.py:1622]   Expert 34 |    141 | CPU
DEBUG 01-13 08:46:33.769174.769174 lmp.py:1622]   Expert 26 |    143 | CPU
DEBUG 01-13 08:46:33.769294.769294 lmp.py:1622]   Expert 27 |    146 | CPU
DEBUG 01-13 08:46:33.769652.769652 lmp.py:1622]   Expert 28 |    160 | CPU
DEBUG 01-13 08:46:33.769202.769202 lmp.py:1622]   Expert 25 |    166 | CPU
DEBUG 01-13 08:46:33.769037.769037 lmp.py:1622]   Expert 55 |    167 | CPU
DEBUG 01-13 08:46:33.769873.769873 lmp.py:1622]   Expert 10 |    172 | CPU
DEBUG 01-13 08:46:33.769946.769946 lmp.py:1622]   Expert 13 |    180 | CPU
DEBUG 01-13 08:46:33.769066.769066 lmp.py:1622]   Expert  9 |    184 | CPU
DEBUG 01-13 08:46:33.769947.769947 lmp.py:1622]   Expert 48 |    185 | CPU
DEBUG 01-13 08:46:33.769829.769829 lmp.py:1622]   Expert  7 |    188 | CPU
DEBUG 01-13 08:46:33.769710.769710 lmp.py:1622]   Expert 61 |    191 | CPU
DEBUG 01-13 08:46:33.769068.769068 lmp.py:1622]   Expert 24 |    192 | CPU
DEBUG 01-13 08:46:33.769188.769188 lmp.py:1622]   Expert  6 |    193 | GPU
DEBUG 01-13 08:46:33.769308.769308 lmp.py:1622]   Expert 46 |    195 | GPU
DEBUG 01-13 08:46:33.769428.769428 lmp.py:1622]   Expert 42 |    201 | GPU
DEBUG 01-13 08:46:33.769309.769309 lmp.py:1622]   Expert 18 |    206 | GPU
DEBUG 01-13 08:46:33.769429.769429 lmp.py:1622]   Expert 40 |    209 | GPU
DEBUG 01-13 08:46:33.769549.769549 lmp.py:1622]   Expert 22 |    215 | GPU
DEBUG 01-13 08:46:33.769145.769145 lmp.py:1622]   Expert 12 |    216 | GPU
DEBUG 01-13 08:46:33.769980.769980 lmp.py:1622]   Expert 21 |    216 | GPU
DEBUG 01-13 08:46:33.770577.770577 lmp.py:1622]   Expert 59 |    218 | GPU
DEBUG 01-13 08:46:33.770988.770988 lmp.py:1622]   Expert 63 |    219 | GPU
DEBUG 01-13 08:46:33.770870.770870 lmp.py:1622]   Expert 29 |    220 | GPU
DEBUG 01-13 08:46:33.770274.770274 lmp.py:1622]   Expert 32 |    223 | GPU
DEBUG 01-13 08:46:33.770964.770964 lmp.py:1622]   Expert 19 |    224 | GPU
DEBUG 01-13 08:46:33.770130.770130 lmp.py:1622]   Expert 36 |    235 | GPU
DEBUG 01-13 08:46:33.770296.770296 lmp.py:1622]   Expert  3 |    247 | GPU
DEBUG 01-13 08:46:33.770224.770224 lmp.py:1622]   Expert 16 |    249 | GPU
DEBUG 01-13 08:46:33.770390.770390 lmp.py:1622]   Expert 37 |    249 | GPU
DEBUG 01-13 08:46:33.770318.770318 lmp.py:1622]   Expert  1 |    253 | GPU
DEBUG 01-13 08:46:33.770245.770245 lmp.py:1622]   Expert  8 |    264 | GPU
DEBUG 01-13 08:46:33.770173.770173 lmp.py:1622]   Expert 20 |    265 | GPU
DEBUG 01-13 08:46:33.770054.770054 lmp.py:1622]   Expert  5 |    268 | GPU
DEBUG 01-13 08:46:33.770697.770697 lmp.py:1622]   Expert 15 |    270 | GPU
DEBUG 01-13 08:46:33.770340.770340 lmp.py:1622]   Expert 30 |    271 | GPU
DEBUG 01-13 08:46:33.770460.770460 lmp.py:1622]   Expert 62 |    271 | GPU
DEBUG 01-13 08:46:33.770388.770388 lmp.py:1622]   Expert 35 |    291 | GPU
DEBUG 01-13 08:46:33.770554.770554 lmp.py:1622]   Expert 39 |    295 | GPU
DEBUG 01-13 08:46:33.770720.770720 lmp.py:1622]   Expert 17 |    297 | GPU
DEBUG 01-13 08:46:33.770648.770648 lmp.py:1622]   Expert 60 |    307 | GPU
DEBUG 01-13 08:46:33.770337.770337 lmp.py:1622]   Expert 52 |    354 | GPU
DEBUG 01-13 08:46:33.770265.770265 lmp.py:1622]   Expert 23 |    374 | GPU
DEBUG 01-13 08:46:33.770954.770954 lmp.py:1622]   Expert 44 |    377 | GPU
DEBUG 01-13 08:46:33.770643.770643 lmp.py:1622]   Expert 53 |    438 | GPU
DEBUG 01-13 08:46:33.770002.770002 lmp.py:1623] 
DEBUG 01-13 08:46:33.770002.770002 lmp.py:1623]   CPU total tokens: 3958 (32.2%)
DEBUG 01-13 08:46:33.770314.770314 lmp.py:1624]   GPU total tokens: 8330 (67.8%)
DEBUG 01-13 08:46:33.770917.770917 cuda_h.py:19] end experts_map_get cost 0.0017724037170410156 seconds
DEBUG 01-13 08:46:33.770251.770251 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-13 08:46:33.770960.770960 lmp.py:1632] 
DEBUG 01-13 08:46:33.770960.770960 lmp.py:1632]   Computing 32 experts on CPU MP...
DEBUG 01-13 08:46:33.770220.770220 cuda_h.py:19] end cpu_experts_submit cost 5.078315734863281e-05 seconds
DEBUG 01-13 08:46:33.770678.770678 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-13 08:46:33.770176.770176 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-13 08:46:33.770366.770366 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-13 08:46:33.772916.772916 cuda_h.py:19] end allocate_cuda_memory cost 0.0017387866973876953 seconds
DEBUG 01-13 08:46:33.772243.772243 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-13 08:46:33.772191.772191 sllm_store_c.py:27] get device uuid map
DEBUG 01-13 08:46:33.772715.772715 sllm_store_c.py:29] call client load into gpu
DEBUG 01-13 08:46:33.772795.772795 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, e00f3a66-48b5-4bcb-a695-c20c8df9deda
DEBUG 01-13 08:46:33.772431.772431 client.py:106] call stub.LoadModelAsync
INFO 01-13 08:46:33.773356.773356 client.py:127] Model loaded
DEBUG 01-13 08:46:33.773830.773830 cuda_h.py:10] start restore2model
DEBUG 01-13 08:46:33.774540.774540 cuda_h.py:19] end restore2model cost 0.00040841102600097656 seconds
DEBUG 01-13 08:46:33.774324.774324 cuda_h.py:19] end sllm_worker_task cost 0.011444330215454102 seconds
DEBUG 01-13 08:46:33.774435.774435 cuda_h.py:10] start experts_func_gpu_einsum_mp
INFO 01-13 08:46:33.774303.774303 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, e00f3a66-48b5-4bcb-a695-c20c8df9deda
DEBUG 01-13 08:46:33.774868.774868 cuda_h.py:19] end load_into_gpu_async cost 0.0022165775299072266 seconds
DEBUG 01-13 08:46:33.774716.774716 cuda_h.py:10] start restore_tensors2
DEBUG 01-13 08:46:33.775843.775843 cuda_h.py:19] end restore_tensors2 cost 0.0003802776336669922 seconds
DEBUG 01-13 08:46:33.775010.775010 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.00469660758972168 seconds
DEBUG 01-13 08:46:33.775495.775495 cuda_h.py:10] start restore2model
DEBUG 01-13 08:46:33.778526.778526 cuda_h.py:19] end restore2model cost 0.0030815601348876953 seconds
DEBUG 01-13 08:46:33.778601.778601 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.007957220077514648 seconds
DEBUG 01-13 08:46:33.778966.778966 cuda_h.py:10] start gpu_sexperts
DEBUG 01-13 08:46:33.778368.778368 cuda_h.py:19] end gpu_sexperts cost 0.0003018379211425781 seconds
DEBUG 01-13 08:46:33.779912.779912 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-13 08:46:33.779066.779066 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 1.52587890625e-05 seconds
DEBUG 01-13 08:46:33.779477.779477 cuda_h.py:10] start wait_experts
INFO 01-13 08:46:33.779604.779604 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, e00f3a66-48b5-4bcb-a695-c20c8df9deda
DEBUG 01-13 08:46:33.787269.787269 mlpmodule.py:1006] group tensors cost 0.012453317642211914 s
DEBUG 01-13 08:46:33.790307.790307 mlpmodule.py:1044] pad cost 0.0023207664489746094 s
DEBUG 01-13 08:46:33.790179.790179 mlpmodule.py:1050] create cpu tensor cost 5.14984130859375e-05 s
DEBUG 01-13 08:46:33.790711.790711 mlpmodule.py:1055] move to cpu cost 4.029273986816406e-05 s
DEBUG 01-13 08:46:33.801413.801413 mlpmodule.py:1069] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-13 08:46:33.802678.802678 mlpmodule.py:1070] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-13 08:46:33.802874.802874 mlpmodule.py:1075] group_w3 first element: -0.02490234375
WARNING 01-13 08:46:33.802872.802872 mlpmodule.py:1085] start einsum2
DEBUG 01-13 08:46:33.818529.818529 mlpmodule.py:1095] group einsum cost 0.027093172073364258 s
DEBUG 01-13 08:46:33.819635.819635 mlpmodule.py:1103] cpy2cputensor cost 0.0007407665252685547 s
INFO 01-13 08:46:33.826181.826181 client.py:127] Model loaded
DEBUG 01-13 08:46:33.826817.826817 cuda_h.py:19] end wait_experts cost 0.04746127128601074 seconds
DEBUG 01-13 08:46:33.826302.826302 cuda_h.py:10] start gpu_experts
DEBUG 01-13 08:46:33.827001.827001 mlpmodule.py:559] gpu group tensors cost 0.0007839202880859375 s
DEBUG 01-13 08:46:33.830176.830176 mlpmodule.py:592] gpu pad cost 0.002408266067504883 s
DEBUG 01-13 08:46:33.830882.830882 mlpmodule.py:598] start_w1
DEBUG 01-13 08:46:33.830358.830358 mlpmodule.py:602] start_w3
DEBUG 01-13 08:46:33.830942.830942 mlpmodule.py:608] start_w2
DEBUG 01-13 08:46:33.830921.830921 mlpmodule.py:611] gpu group einsum cost 0.0007724761962890625 s
DEBUG 01-13 08:46:33.834922.834922 mlpmodule.py:683] gpu experts func einsum cost 0.0075397491455078125 s
DEBUG 01-13 08:46:33.834389.834389 cuda_h.py:19] end gpu_experts cost 0.007720470428466797 seconds
DEBUG 01-13 08:46:33.834860.834860 cuda_h.py:10] start cpu_thread_manager_mp_wait
DEBUG 01-13 08:46:33.834293.834293 cuda_h.py:19] end cpu_thread_manager_mp_wait cost 4.172325134277344e-05 seconds
DEBUG 01-13 08:46:33.834515.834515 cuda_h.py:19] end layer_moe_generate_mp_l_17 cost 0.06678032875061035 seconds
DEBUG 01-13 08:46:33.834565.834565 lmp.py:1550] -------------------------------- end prefill layer 16 --------------------------------
DEBUG 01-13 08:46:33.834342.834342 lmp.py:1493] -------------------------------- start prefill layer 17 --------------------------------
DEBUG 01-13 08:46:33.835713.835713 cuda_h.py:10] start start_load_qkvogn_s_weight_l_18
DEBUG 01-13 08:46:33.835993.835993 cuda_h.py:10] start start_load_qkvogn_s_weight_l_18
DEBUG 01-13 08:46:33.835074.835074 cuda_h.py:19] end start_load_qkvogn_s_weight_l_18 cost 3.2901763916015625e-05 seconds
DEBUG 01-13 08:46:33.835207.835207 cuda_h.py:19] end start_load_qkvogn_s_weight_l_18 cost 6.4849853515625e-05 seconds
DEBUG 01-13 08:46:33.835401.835401 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-13 08:46:33.835635.835635 cuda_h.py:10] start sllm_worker_task
DEBUG 01-13 08:46:33.835519.835519 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-13 08:46:33.835070.835070 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-13 08:46:33.835805.835805 cuda_h.py:19] end allocate_cuda_memory cost 0.00035858154296875 seconds
DEBUG 01-13 08:46:33.835895.835895 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-13 08:46:33.835923.835923 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-13 08:46:33.836781.836781 sllm_store_c.py:27] get device uuid map
DEBUG 01-13 08:46:33.836472.836472 sllm_store_c.py:29] call client load into gpu
DEBUG 01-13 08:46:33.836181.836181 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, d1e09253-f103-4daf-b27d-c8bce3ec2fd5
DEBUG 01-13 08:46:33.836310.836310 client.py:106] call stub.LoadModelAsync
DEBUG 01-13 08:46:33.836251.836251 cuda_h.py:10] start self_attn
INFO 01-13 08:46:33.837373.837373 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, d1e09253-f103-4daf-b27d-c8bce3ec2fd5
DEBUG 01-13 08:46:33.837408.837408 cuda_h.py:19] end load_into_gpu_async cost 0.0017261505126953125 seconds
DEBUG 01-13 08:46:33.837310.837310 cuda_h.py:10] start restore_tensors2
DEBUG 01-13 08:46:33.837751.837751 cuda_h.py:19] end restore_tensors2 cost 8.273124694824219e-05 seconds
DEBUG 01-13 08:46:33.837527.837527 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0026047229766845703 seconds
INFO 01-13 08:46:33.838887.838887 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, d1e09253-f103-4daf-b27d-c8bce3ec2fd5
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-13 08:46:33.840563.840563 cuda_h.py:19] end self_attn cost 0.0033266544342041016 seconds
DEBUG 01-13 08:46:33.840674.840674 cuda_h.py:19] end iln_self_attn_paln cost 0.005155086517333984 seconds
DEBUG 01-13 08:46:33.840769.840769 cuda_h.py:10] start layer_moe_generate_mp_l_18
DEBUG 01-13 08:46:33.840247.840247 cuda_h.py:10] start gate
DEBUG 01-13 08:46:33.841789.841789 cuda_h.py:19] end gate cost 0.0007152557373046875 seconds
DEBUG 01-13 08:46:33.841863.841863 cuda_h.py:10] start experts_map_get
DEBUG 01-13 08:46:33.841474.841474 lmp.py:1611] 
DEBUG 01-13 08:46:33.841474.841474 lmp.py:1611] Expert Token Distribution & Device Allocation:
DEBUG 01-13 08:46:33.841946.841946 lmp.py:1612]   Total experts: 64
DEBUG 01-13 08:46:33.841980.841980 lmp.py:1613]   CPU experts: 32 (50%)
DEBUG 01-13 08:46:33.841768.841768 lmp.py:1614]   GPU experts: 32 (50%)
DEBUG 01-13 08:46:33.841650.841650 lmp.py:1615] 
DEBUG 01-13 08:46:33.841650.841650 lmp.py:1615]   Expert ID | Tokens | Device
DEBUG 01-13 08:46:33.841246.841246 lmp.py:1616]   -----------------------------------
DEBUG 01-13 08:46:33.841042.841042 lmp.py:1622]   Expert  4 |     11 | CPU
DEBUG 01-13 08:46:33.841877.841877 lmp.py:1622]   Expert 28 |     27 | CPU
DEBUG 01-13 08:46:33.841520.841520 lmp.py:1622]   Expert  7 |     37 | CPU
DEBUG 01-13 08:46:33.841924.841924 lmp.py:1622]   Expert 53 |     56 | CPU
DEBUG 01-13 08:46:33.841091.841091 lmp.py:1622]   Expert 52 |     66 | CPU
DEBUG 01-13 08:46:33.841495.841495 lmp.py:1622]   Expert 43 |     72 | CPU
DEBUG 01-13 08:46:33.841661.841661 lmp.py:1622]   Expert 49 |     89 | CPU
DEBUG 01-13 08:46:33.841827.841827 lmp.py:1622]   Expert 12 |     91 | CPU
DEBUG 01-13 08:46:33.841517.841517 lmp.py:1622]   Expert 24 |     99 | CPU
DEBUG 01-13 08:46:33.842444.842444 lmp.py:1622]   Expert 47 |     99 | CPU
DEBUG 01-13 08:46:33.842849.842849 lmp.py:1622]   Expert 33 |    108 | CPU
DEBUG 01-13 08:46:33.842684.842684 lmp.py:1622]   Expert 50 |    108 | CPU
DEBUG 01-13 08:46:33.842804.842804 lmp.py:1622]   Expert  2 |    112 | CPU
DEBUG 01-13 08:46:33.842685.842685 lmp.py:1622]   Expert 36 |    113 | CPU
DEBUG 01-13 08:46:33.842090.842090 lmp.py:1622]   Expert 15 |    117 | CPU
DEBUG 01-13 08:46:33.842733.842733 lmp.py:1622]   Expert  6 |    118 | CPU
DEBUG 01-13 08:46:33.842899.842899 lmp.py:1622]   Expert 39 |    118 | CPU
DEBUG 01-13 08:46:33.842065.842065 lmp.py:1622]   Expert 60 |    119 | CPU
DEBUG 01-13 08:46:33.842470.842470 lmp.py:1622]   Expert 61 |    122 | CPU
DEBUG 01-13 08:46:33.842397.842397 lmp.py:1622]   Expert 25 |    128 | CPU
DEBUG 01-13 08:46:33.842325.842325 lmp.py:1622]   Expert  3 |    145 | CPU
DEBUG 01-13 08:46:33.842253.842253 lmp.py:1622]   Expert 59 |    145 | CPU
DEBUG 01-13 08:46:33.842657.842657 lmp.py:1622]   Expert 30 |    150 | CPU
DEBUG 01-13 08:46:33.842300.842300 lmp.py:1622]   Expert  8 |    152 | CPU
DEBUG 01-13 08:46:33.842182.842182 lmp.py:1622]   Expert 31 |    153 | CPU
DEBUG 01-13 08:46:33.842063.842063 lmp.py:1622]   Expert 58 |    153 | CPU
DEBUG 01-13 08:46:33.842706.842706 lmp.py:1622]   Expert 27 |    154 | CPU
DEBUG 01-13 08:46:33.842111.842111 lmp.py:1622]   Expert 40 |    156 | CPU
DEBUG 01-13 08:46:33.842754.842754 lmp.py:1622]   Expert 10 |    158 | CPU
DEBUG 01-13 08:46:33.842920.842920 lmp.py:1622]   Expert 57 |    161 | CPU
DEBUG 01-13 08:46:33.842086.842086 lmp.py:1622]   Expert 32 |    163 | CPU
DEBUG 01-13 08:46:33.842252.842252 lmp.py:1622]   Expert 37 |    164 | CPU
DEBUG 01-13 08:46:33.842657.842657 lmp.py:1622]   Expert 14 |    165 | GPU
DEBUG 01-13 08:46:33.842823.842823 lmp.py:1622]   Expert 54 |    165 | GPU
DEBUG 01-13 08:46:33.842750.842750 lmp.py:1622]   Expert 38 |    166 | GPU
DEBUG 01-13 08:46:33.842155.842155 lmp.py:1622]   Expert 41 |    166 | GPU
DEBUG 01-13 08:46:33.842798.842798 lmp.py:1622]   Expert 46 |    169 | GPU
DEBUG 01-13 08:46:33.842441.842441 lmp.py:1622]   Expert 19 |    170 | GPU
DEBUG 01-13 08:46:33.842322.842322 lmp.py:1622]   Expert 42 |    170 | GPU
DEBUG 01-13 08:46:33.842965.842965 lmp.py:1622]   Expert 11 |    178 | GPU
DEBUG 01-13 08:46:33.842370.842370 lmp.py:1622]   Expert 34 |    183 | GPU
DEBUG 01-13 08:46:33.842774.842774 lmp.py:1622]   Expert  0 |    192 | GPU
DEBUG 01-13 08:46:33.842941.842941 lmp.py:1622]   Expert 22 |    193 | GPU
DEBUG 01-13 08:46:33.842107.842107 lmp.py:1622]   Expert 18 |    197 | GPU
DEBUG 01-13 08:46:33.842273.842273 lmp.py:1622]   Expert 26 |    198 | GPU
DEBUG 01-13 08:46:33.842439.842439 lmp.py:1622]   Expert 44 |    200 | GPU
DEBUG 01-13 08:46:33.842605.842605 lmp.py:1622]   Expert  1 |    201 | GPU
DEBUG 01-13 08:46:33.842771.842771 lmp.py:1622]   Expert 51 |    207 | GPU
DEBUG 01-13 08:46:33.842176.842176 lmp.py:1622]   Expert 56 |    209 | GPU
DEBUG 01-13 08:46:33.842580.842580 lmp.py:1622]   Expert 20 |    224 | GPU
DEBUG 01-13 08:46:33.842462.842462 lmp.py:1622]   Expert 29 |    224 | GPU
DEBUG 01-13 08:46:33.842105.842105 lmp.py:1622]   Expert 48 |    233 | GPU
DEBUG 01-13 08:46:33.842225.842225 lmp.py:1622]   Expert 45 |    242 | GPU
DEBUG 01-13 08:46:33.842106.842106 lmp.py:1622]   Expert 21 |    245 | GPU
DEBUG 01-13 08:46:33.842272.842272 lmp.py:1622]   Expert 16 |    252 | GPU
DEBUG 01-13 08:46:33.842438.842438 lmp.py:1622]   Expert 35 |    254 | GPU
DEBUG 01-13 08:46:33.842843.842843 lmp.py:1622]   Expert 55 |    258 | GPU
DEBUG 01-13 08:46:33.842009.842009 lmp.py:1622]   Expert  5 |    292 | GPU
DEBUG 01-13 08:46:33.842413.842413 lmp.py:1622]   Expert 23 |    376 | GPU
DEBUG 01-13 08:46:33.842580.842580 lmp.py:1622]   Expert 13 |    379 | GPU
DEBUG 01-13 08:46:33.842269.842269 lmp.py:1622]   Expert 17 |    437 | GPU
DEBUG 01-13 08:46:33.842435.842435 lmp.py:1622]   Expert  9 |    445 | GPU
DEBUG 01-13 08:46:33.842078.842078 lmp.py:1622]   Expert 63 |    456 | GPU
DEBUG 01-13 08:46:33.842483.842483 lmp.py:1622]   Expert 62 |   1178 | GPU
DEBUG 01-13 08:46:33.842848.842848 lmp.py:1623] 
DEBUG 01-13 08:46:33.842848.842848 lmp.py:1623]   CPU total tokens: 3664 (29.8%)
DEBUG 01-13 08:46:33.842683.842683 lmp.py:1624]   GPU total tokens: 8624 (70.2%)
DEBUG 01-13 08:46:33.843856.843856 cuda_h.py:19] end experts_map_get cost 0.0017211437225341797 seconds
DEBUG 01-13 08:46:33.843043.843043 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-13 08:46:33.843369.843369 lmp.py:1632] 
DEBUG 01-13 08:46:33.843369.843369 lmp.py:1632]   Computing 32 experts on CPU MP...
DEBUG 01-13 08:46:33.843291.843291 cuda_h.py:19] end cpu_experts_submit cost 4.76837158203125e-05 seconds
DEBUG 01-13 08:46:33.843795.843795 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-13 08:46:33.843013.843013 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-13 08:46:33.843740.843740 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-13 08:46:33.844577.844577 cuda_h.py:19] end allocate_cuda_memory cost 0.0012483596801757812 seconds
DEBUG 01-13 08:46:33.845110.845110 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-13 08:46:33.845488.845488 sllm_store_c.py:27] get device uuid map
DEBUG 01-13 08:46:33.845820.845820 sllm_store_c.py:29] call client load into gpu
DEBUG 01-13 08:46:33.845947.845947 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 64fc5071-eebc-4aec-963d-222b1a565fcc
DEBUG 01-13 08:46:33.845411.845411 client.py:106] call stub.LoadModelAsync
INFO 01-13 08:46:33.845636.845636 client.py:127] Model loaded
DEBUG 01-13 08:46:33.845857.845857 cuda_h.py:10] start restore2model
DEBUG 01-13 08:46:33.846121.846121 cuda_h.py:19] end restore2model cost 0.00032973289489746094 seconds
DEBUG 01-13 08:46:33.846613.846613 cuda_h.py:19] end sllm_worker_task cost 0.010929107666015625 seconds
INFO 01-13 08:46:33.847999.847999 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 64fc5071-eebc-4aec-963d-222b1a565fcc
DEBUG 01-13 08:46:33.847657.847657 cuda_h.py:19] end load_into_gpu_async cost 0.0022630691528320312 seconds
DEBUG 01-13 08:46:33.847552.847552 cuda_h.py:10] start restore_tensors2
DEBUG 01-13 08:46:33.847579.847579 cuda_h.py:19] end restore_tensors2 cost 0.0003781318664550781 seconds
DEBUG 01-13 08:46:33.847144.847144 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.004278898239135742 seconds
DEBUG 01-13 08:46:33.847960.847960 cuda_h.py:10] start restore2model
DEBUG 01-13 08:46:33.849584.849584 mlpmodule.py:785]  experts func einsum cost 0.07468986511230469 s
DEBUG 01-13 08:46:33.850329.850329 cuda_h.py:19] end experts_func_gpu_einsum_mp cost 0.07624077796936035 seconds
DEBUG 01-13 08:46:33.851430.851430 cuda_h.py:19] end restore2model cost 0.003124713897705078 seconds
DEBUG 01-13 08:46:33.851219.851219 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.007593393325805664 seconds
DEBUG 01-13 08:46:33.851346.851346 cuda_h.py:10] start gpu_sexperts
DEBUG 01-13 08:46:33.851609.851609 cuda_h.py:19] end gpu_sexperts cost 0.0003032684326171875 seconds
DEBUG 01-13 08:46:33.851392.851392 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-13 08:46:33.851460.851460 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 1.52587890625e-05 seconds
DEBUG 01-13 08:46:33.851871.851871 cuda_h.py:10] start wait_experts
INFO 01-13 08:46:33.851475.851475 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 64fc5071-eebc-4aec-963d-222b1a565fcc
DEBUG 01-13 08:46:33.851271.851271 cuda_h.py:10] start experts_func_gpu_einsum_mp
DEBUG 01-13 08:46:33.860543.860543 mlpmodule.py:1006] group tensors cost 0.007840633392333984 s
DEBUG 01-13 08:46:33.863934.863934 mlpmodule.py:1044] pad cost 0.002028226852416992 s
DEBUG 01-13 08:46:33.863084.863084 mlpmodule.py:1050] create cpu tensor cost 5.245208740234375e-05 s
DEBUG 01-13 08:46:33.863517.863517 mlpmodule.py:1055] move to cpu cost 3.838539123535156e-05 s
DEBUG 01-13 08:46:33.872660.872660 mlpmodule.py:1069] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-13 08:46:33.872707.872707 mlpmodule.py:1070] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-13 08:46:33.872280.872280 mlpmodule.py:1075] group_w3 first element: 0.00457763671875
WARNING 01-13 08:46:33.873324.873324 mlpmodule.py:1085] start einsum2
DEBUG 01-13 08:46:33.886662.886662 mlpmodule.py:1095] group einsum cost 0.02245473861694336 s
DEBUG 01-13 08:46:33.886368.886368 mlpmodule.py:1103] cpy2cputensor cost 0.0006461143493652344 s
INFO 01-13 08:46:33.898670.898670 client.py:127] Model loaded
DEBUG 01-13 08:46:33.898371.898371 cuda_h.py:19] end wait_experts cost 0.046532392501831055 seconds
DEBUG 01-13 08:46:33.898995.898995 cuda_h.py:10] start gpu_experts
DEBUG 01-13 08:46:33.899461.899461 mlpmodule.py:559] gpu group tensors cost 0.0007576942443847656 s
DEBUG 01-13 08:46:33.901496.901496 mlpmodule.py:592] gpu pad cost 0.002342700958251953 s
DEBUG 01-13 08:46:33.901095.901095 mlpmodule.py:598] start_w1
DEBUG 01-13 08:46:33.901988.901988 mlpmodule.py:602] start_w3
DEBUG 01-13 08:46:33.902319.902319 mlpmodule.py:608] start_w2
DEBUG 01-13 08:46:33.902320.902320 mlpmodule.py:611] gpu group einsum cost 0.0011811256408691406 s
DEBUG 01-13 08:46:33.904585.904585 mlpmodule.py:683] gpu experts func einsum cost 0.006646156311035156 s
DEBUG 01-13 08:46:33.905516.905516 cuda_h.py:19] end gpu_experts cost 0.006814002990722656 seconds
DEBUG 01-13 08:46:33.905795.905795 cuda_h.py:10] start cpu_thread_manager_mp_wait
DEBUG 01-13 08:46:33.905645.905645 cuda_h.py:19] end cpu_thread_manager_mp_wait cost 3.600120544433594e-05 seconds
DEBUG 01-13 08:46:33.905561.905561 cuda_h.py:19] end layer_moe_generate_mp_l_18 cost 0.0647726058959961 seconds
DEBUG 01-13 08:46:33.905628.905628 lmp.py:1550] -------------------------------- end prefill layer 17 --------------------------------
DEBUG 01-13 08:46:33.905961.905961 lmp.py:1493] -------------------------------- start prefill layer 18 --------------------------------
DEBUG 01-13 08:46:33.905471.905471 cuda_h.py:10] start start_load_qkvogn_s_weight_l_19
DEBUG 01-13 08:46:33.905366.905366 cuda_h.py:10] start start_load_qkvogn_s_weight_l_19
DEBUG 01-13 08:46:33.905878.905878 cuda_h.py:19] end start_load_qkvogn_s_weight_l_19 cost 3.2901763916015625e-05 seconds
DEBUG 01-13 08:46:33.905655.905655 cuda_h.py:10] start sllm_worker_task
DEBUG 01-13 08:46:33.905934.905934 cuda_h.py:19] end start_load_qkvogn_s_weight_l_19 cost 0.00011348724365234375 seconds
DEBUG 01-13 08:46:33.905273.905273 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-13 08:46:33.905983.905983 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-13 08:46:33.905865.905865 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-13 08:46:33.906469.906469 cuda_h.py:19] end allocate_cuda_memory cost 0.0001666545867919922 seconds
DEBUG 01-13 08:46:33.906418.906418 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-13 08:46:33.906704.906704 sllm_store_c.py:27] get device uuid map
DEBUG 01-13 08:46:33.906150.906150 sllm_store_c.py:29] call client load into gpu
DEBUG 01-13 08:46:33.906045.906045 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 9d024ca4-0fde-4336-92e3-b312ca9ece4c
DEBUG 01-13 08:46:33.906213.906213 client.py:106] call stub.LoadModelAsync
DEBUG 01-13 08:46:33.906901.906901 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-13 08:46:33.906766.906766 cuda_h.py:10] start self_attn
INFO 01-13 08:46:33.907545.907545 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 9d024ca4-0fde-4336-92e3-b312ca9ece4c
DEBUG 01-13 08:46:33.907203.907203 cuda_h.py:19] end load_into_gpu_async cost 0.0018415451049804688 seconds
DEBUG 01-13 08:46:33.908628.908628 cuda_h.py:10] start restore_tensors2
DEBUG 01-13 08:46:33.908194.908194 cuda_h.py:19] end restore_tensors2 cost 7.176399230957031e-05 seconds
DEBUG 01-13 08:46:33.908573.908573 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.002368450164794922 seconds
INFO 01-13 08:46:33.908131.908131 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 9d024ca4-0fde-4336-92e3-b312ca9ece4c
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-13 08:46:33.909699.909699 cuda_h.py:19] end self_attn cost 0.003090381622314453 seconds
DEBUG 01-13 08:46:33.910450.910450 cuda_h.py:19] end iln_self_attn_paln cost 0.0043582916259765625 seconds
DEBUG 01-13 08:46:33.910763.910763 cuda_h.py:10] start layer_moe_generate_mp_l_19
DEBUG 01-13 08:46:33.910234.910234 cuda_h.py:10] start gate
DEBUG 01-13 08:46:33.910562.910562 cuda_h.py:19] end gate cost 0.0006487369537353516 seconds
DEBUG 01-13 08:46:33.911345.911345 cuda_h.py:10] start experts_map_get
DEBUG 01-13 08:46:33.911693.911693 lmp.py:1611] 
DEBUG 01-13 08:46:33.911693.911693 lmp.py:1611] Expert Token Distribution & Device Allocation:
DEBUG 01-13 08:46:33.911210.911210 lmp.py:1612]   Total experts: 64
DEBUG 01-13 08:46:33.911622.911622 lmp.py:1613]   CPU experts: 32 (50%)
DEBUG 01-13 08:46:33.911695.911695 lmp.py:1614]   GPU experts: 32 (50%)
DEBUG 01-13 08:46:33.911861.911861 lmp.py:1615] 
DEBUG 01-13 08:46:33.911861.911861 lmp.py:1615]   Expert ID | Tokens | Device
DEBUG 01-13 08:46:33.911027.911027 lmp.py:1616]   -----------------------------------
DEBUG 01-13 08:46:33.911916.911916 lmp.py:1622]   Expert 32 |     33 | CPU
DEBUG 01-13 08:46:33.911320.911320 lmp.py:1622]   Expert  5 |     51 | CPU
DEBUG 01-13 08:46:33.911771.911771 lmp.py:1622]   Expert 30 |     53 | CPU
DEBUG 01-13 08:46:33.911268.911268 lmp.py:1622]   Expert 46 |     68 | CPU
DEBUG 01-13 08:46:33.911242.911242 lmp.py:1622]   Expert  8 |     85 | CPU
DEBUG 01-13 08:46:33.911216.911216 lmp.py:1622]   Expert 40 |     88 | CPU
DEBUG 01-13 08:46:33.911767.911767 lmp.py:1622]   Expert 12 |    103 | CPU
DEBUG 01-13 08:46:33.911516.911516 lmp.py:1622]   Expert 27 |    108 | CPU
DEBUG 01-13 08:46:33.911881.911881 lmp.py:1622]   Expert 17 |    110 | CPU
DEBUG 01-13 08:46:33.911160.911160 lmp.py:1622]   Expert  3 |    112 | CPU
DEBUG 01-13 08:46:33.911995.911995 lmp.py:1622]   Expert 60 |    113 | CPU
DEBUG 01-13 08:46:33.911784.911784 lmp.py:1622]   Expert 21 |    115 | CPU
DEBUG 01-13 08:46:33.911195.911195 lmp.py:1622]   Expert 28 |    117 | CPU
DEBUG 01-13 08:46:33.911600.911600 lmp.py:1622]   Expert 58 |    117 | CPU
DEBUG 01-13 08:46:33.911574.911574 lmp.py:1622]   Expert 29 |    124 | CPU
DEBUG 01-13 08:46:33.911832.911832 lmp.py:1622]   Expert 25 |    130 | CPU
DEBUG 01-13 08:46:33.911376.911376 lmp.py:1622]   Expert 35 |    131 | CPU
DEBUG 01-13 08:46:33.911158.911158 lmp.py:1622]   Expert 19 |    134 | CPU
DEBUG 01-13 08:46:33.911940.911940 lmp.py:1622]   Expert 41 |    134 | CPU
DEBUG 01-13 08:46:33.911960.911960 lmp.py:1622]   Expert 52 |    140 | CPU
DEBUG 01-13 08:46:33.911742.911742 lmp.py:1622]   Expert 54 |    144 | CPU
DEBUG 01-13 08:46:33.911524.911524 lmp.py:1622]   Expert 37 |    145 | CPU
DEBUG 01-13 08:46:33.911783.911783 lmp.py:1622]   Expert  0 |    146 | CPU
DEBUG 01-13 08:46:33.911327.911327 lmp.py:1622]   Expert  6 |    151 | CPU
DEBUG 01-13 08:46:33.911108.911108 lmp.py:1622]   Expert 56 |    151 | CPU
DEBUG 01-13 08:46:33.911652.911652 lmp.py:1622]   Expert 48 |    156 | CPU
DEBUG 01-13 08:46:33.911672.911672 lmp.py:1622]   Expert 63 |    158 | CPU
DEBUG 01-13 08:46:33.911693.911693 lmp.py:1622]   Expert 53 |    161 | CPU
DEBUG 01-13 08:46:33.911713.911713 lmp.py:1622]   Expert 36 |    162 | CPU
DEBUG 01-13 08:46:33.911449.911449 lmp.py:1622]   Expert 59 |    168 | CPU
DEBUG 01-13 08:46:33.911946.911946 lmp.py:1622]   Expert  9 |    180 | CPU
DEBUG 01-13 08:46:33.911443.911443 lmp.py:1622]   Expert 39 |    184 | CPU
DEBUG 01-13 08:46:33.912179.912179 lmp.py:1622]   Expert  1 |    187 | GPU
DEBUG 01-13 08:46:33.912199.912199 lmp.py:1622]   Expert 20 |    193 | GPU
DEBUG 01-13 08:46:33.912220.912220 lmp.py:1622]   Expert 11 |    199 | GPU
DEBUG 01-13 08:46:33.912001.912001 lmp.py:1622]   Expert 42 |    201 | GPU
DEBUG 01-13 08:46:33.912022.912022 lmp.py:1622]   Expert 43 |    201 | GPU
DEBUG 01-13 08:46:33.912804.912804 lmp.py:1622]   Expert 61 |    201 | GPU
DEBUG 01-13 08:46:33.912586.912586 lmp.py:1622]   Expert  7 |    202 | GPU
DEBUG 01-13 08:46:33.912129.912129 lmp.py:1622]   Expert 47 |    209 | GPU
DEBUG 01-13 08:46:33.912673.912673 lmp.py:1622]   Expert 34 |    211 | GPU
DEBUG 01-13 08:46:33.912455.912455 lmp.py:1622]   Expert 57 |    218 | GPU
DEBUG 01-13 08:46:33.912760.912760 lmp.py:1622]   Expert 13 |    219 | GPU
DEBUG 01-13 08:46:33.912303.912303 lmp.py:1622]   Expert 55 |    219 | GPU
DEBUG 01-13 08:46:33.912085.912085 lmp.py:1622]   Expert 16 |    220 | GPU
DEBUG 01-13 08:46:33.912106.912106 lmp.py:1622]   Expert 18 |    233 | GPU
DEBUG 01-13 08:46:33.912888.912888 lmp.py:1622]   Expert 15 |    236 | GPU
DEBUG 01-13 08:46:33.912385.912385 lmp.py:1622]   Expert  4 |    238 | GPU
DEBUG 01-13 08:46:33.912882.912882 lmp.py:1622]   Expert 22 |    241 | GPU
DEBUG 01-13 08:46:33.912902.912902 lmp.py:1622]   Expert 45 |    244 | GPU
DEBUG 01-13 08:46:33.912923.912923 lmp.py:1622]   Expert 31 |    248 | GPU
DEBUG 01-13 08:46:33.912943.912943 lmp.py:1622]   Expert 33 |    248 | GPU
DEBUG 01-13 08:46:33.912487.912487 lmp.py:1622]   Expert 50 |    249 | GPU
DEBUG 01-13 08:46:33.912792.912792 lmp.py:1622]   Expert 51 |    251 | GPU
DEBUG 01-13 08:46:33.912335.912335 lmp.py:1622]   Expert 49 |    267 | GPU
DEBUG 01-13 08:46:33.912641.912641 lmp.py:1622]   Expert 38 |    274 | GPU
DEBUG 01-13 08:46:33.912184.912184 lmp.py:1622]   Expert 44 |    281 | GPU
DEBUG 01-13 08:46:33.912489.912489 lmp.py:1622]   Expert 26 |    284 | GPU
DEBUG 01-13 08:46:33.912768.912768 lmp.py:1622]   Expert 10 |    286 | GPU
DEBUG 01-13 08:46:33.912981.912981 lmp.py:1622]   Expert 24 |    303 | GPU
DEBUG 01-13 08:46:33.912524.912524 lmp.py:1622]   Expert  2 |    321 | GPU
DEBUG 01-13 08:46:33.912737.912737 lmp.py:1622]   Expert 14 |    322 | GPU
DEBUG 01-13 08:46:33.912665.912665 lmp.py:1622]   Expert 23 |    429 | GPU
DEBUG 01-13 08:46:33.912923.912923 lmp.py:1622]   Expert 62 |    681 | GPU
DEBUG 01-13 08:46:33.912613.912613 lmp.py:1623] 
DEBUG 01-13 08:46:33.912613.912613 lmp.py:1623]   CPU total tokens: 3972 (32.3%)
DEBUG 01-13 08:46:33.912302.912302 lmp.py:1624]   GPU total tokens: 8316 (67.7%)
DEBUG 01-13 08:46:33.912044.912044 cuda_h.py:19] end experts_map_get cost 0.001470327377319336 seconds
DEBUG 01-13 08:46:33.912225.912225 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-13 08:46:33.912120.912120 lmp.py:1632] 
DEBUG 01-13 08:46:33.912120.912120 lmp.py:1632]   Computing 32 experts on CPU MP...
DEBUG 01-13 08:46:33.912811.912811 cuda_h.py:19] end cpu_experts_submit cost 4.9591064453125e-05 seconds
DEBUG 01-13 08:46:33.912726.912726 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-13 08:46:33.912808.912808 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-13 08:46:33.912620.912620 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-13 08:46:33.913766.913766 cuda_h.py:19] end allocate_cuda_memory cost 0.0003368854522705078 seconds
DEBUG 01-13 08:46:33.913278.913278 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-13 08:46:33.913318.913318 sllm_store_c.py:27] get device uuid map
DEBUG 01-13 08:46:33.913412.913412 sllm_store_c.py:29] call client load into gpu
DEBUG 01-13 08:46:33.913300.913300 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 03604b39-e414-4fec-acc1-ef4579e88d75
DEBUG 01-13 08:46:33.913410.913410 mlpmodule.py:785]  experts func einsum cost 0.06067466735839844 s
DEBUG 01-13 08:46:33.913783.913783 client.py:106] call stub.LoadModelAsync
DEBUG 01-13 08:46:33.914839.914839 cuda_h.py:19] end experts_func_gpu_einsum_mp cost 0.06258916854858398 seconds
DEBUG 01-13 08:46:33.915626.915626 cuda_h.py:10] start experts_func_gpu_einsum_mp
INFO 01-13 08:46:33.915783.915783 client.py:127] Model loaded
DEBUG 01-13 08:46:33.916566.916566 cuda_h.py:10] start restore2model
DEBUG 01-13 08:46:33.916804.916804 cuda_h.py:19] end restore2model cost 0.0003387928009033203 seconds
DEBUG 01-13 08:46:33.916958.916958 cuda_h.py:19] end sllm_worker_task cost 0.01076054573059082 seconds
INFO 01-13 08:46:33.917708.917708 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 03604b39-e414-4fec-acc1-ef4579e88d75
DEBUG 01-13 08:46:33.917253.917253 cuda_h.py:19] end load_into_gpu_async cost 0.0041637420654296875 seconds
DEBUG 01-13 08:46:33.917094.917094 cuda_h.py:10] start restore_tensors2
DEBUG 01-13 08:46:33.917132.917132 cuda_h.py:19] end restore_tensors2 cost 0.00031828880310058594 seconds
DEBUG 01-13 08:46:33.917147.917147 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.005176544189453125 seconds
DEBUG 01-13 08:46:33.918056.918056 cuda_h.py:10] start restore2model
DEBUG 01-13 08:46:33.920641.920641 mlpmodule.py:1006] group tensors cost 0.003948211669921875 s
DEBUG 01-13 08:46:33.920587.920587 cuda_h.py:19] end restore2model cost 0.0025746822357177734 seconds
DEBUG 01-13 08:46:33.920430.920430 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.007937908172607422 seconds
DEBUG 01-13 08:46:33.920941.920941 cuda_h.py:10] start gpu_sexperts
DEBUG 01-13 08:46:33.921341.921341 cuda_h.py:19] end gpu_sexperts cost 0.0002651214599609375 seconds
DEBUG 01-13 08:46:33.921217.921217 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-13 08:46:33.921510.921510 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 1.3828277587890625e-05 seconds
DEBUG 01-13 08:46:33.921014.921014 cuda_h.py:10] start wait_experts
INFO 01-13 08:46:33.921902.921902 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 03604b39-e414-4fec-acc1-ef4579e88d75
DEBUG 01-13 08:46:33.922612.922612 mlpmodule.py:1044] pad cost 0.001987934112548828 s
DEBUG 01-13 08:46:33.922451.922451 mlpmodule.py:1050] create cpu tensor cost 6.628036499023438e-05 s
DEBUG 01-13 08:46:33.922599.922599 mlpmodule.py:1055] move to cpu cost 3.62396240234375e-05 s
DEBUG 01-13 08:46:33.931729.931729 mlpmodule.py:1069] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-13 08:46:33.931538.931538 mlpmodule.py:1070] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-13 08:46:33.931608.931608 mlpmodule.py:1075] group_w3 first element: 0.0024871826171875
WARNING 01-13 08:46:33.931739.931739 mlpmodule.py:1085] start einsum2
DEBUG 01-13 08:46:33.945622.945622 mlpmodule.py:1095] group einsum cost 0.02215266227722168 s
DEBUG 01-13 08:46:33.945276.945276 mlpmodule.py:1103] cpy2cputensor cost 0.0006921291351318359 s
INFO 01-13 08:46:33.968918.968918 client.py:127] Model loaded
DEBUG 01-13 08:46:33.968178.968178 cuda_h.py:19] end wait_experts cost 0.04755806922912598 seconds
DEBUG 01-13 08:46:33.968452.968452 cuda_h.py:10] start gpu_experts
DEBUG 01-13 08:46:33.969379.969379 mlpmodule.py:559] gpu group tensors cost 0.0008642673492431641 s
DEBUG 01-13 08:46:33.970858.970858 mlpmodule.py:785]  experts func einsum cost 0.05454254150390625 s
DEBUG 01-13 08:46:33.970851.970851 cuda_h.py:19] end experts_func_gpu_einsum_mp cost 0.05533647537231445 seconds
DEBUG 01-13 08:46:33.972682.972682 mlpmodule.py:592] gpu pad cost 0.0030128955841064453 s
DEBUG 01-13 08:46:33.973599.973599 mlpmodule.py:598] start_w1
DEBUG 01-13 08:46:33.973086.973086 mlpmodule.py:602] start_w3
DEBUG 01-13 08:46:33.973367.973367 mlpmodule.py:608] start_w2
DEBUG 01-13 08:46:33.974833.974833 mlpmodule.py:611] gpu group einsum cost 0.0010502338409423828 s
DEBUG 01-13 08:46:33.978343.978343 mlpmodule.py:683] gpu experts func einsum cost 0.00969076156616211 s
DEBUG 01-13 08:46:33.978818.978818 cuda_h.py:19] end gpu_experts cost 0.009917259216308594 seconds
DEBUG 01-13 08:46:33.978356.978356 cuda_h.py:10] start cpu_thread_manager_mp_wait
DEBUG 01-13 08:46:33.978823.978823 cuda_h.py:19] end cpu_thread_manager_mp_wait cost 4.839897155761719e-05 seconds
DEBUG 01-13 08:46:33.979139.979139 cuda_h.py:19] end layer_moe_generate_mp_l_19 cost 0.06874752044677734 seconds
DEBUG 01-13 08:46:33.979933.979933 lmp.py:1550] -------------------------------- end prefill layer 18 --------------------------------
DEBUG 01-13 08:46:33.979146.979146 lmp.py:1493] -------------------------------- start prefill layer 19 --------------------------------
DEBUG 01-13 08:46:33.979677.979677 cuda_h.py:10] start start_load_qkvogn_s_weight_l_20
DEBUG 01-13 08:46:33.979977.979977 cuda_h.py:10] start start_load_qkvogn_s_weight_l_20
DEBUG 01-13 08:46:33.979655.979655 cuda_h.py:19] end start_load_qkvogn_s_weight_l_20 cost 3.886222839355469e-05 seconds
DEBUG 01-13 08:46:33.979901.979901 cuda_h.py:19] end start_load_qkvogn_s_weight_l_20 cost 8.463859558105469e-05 seconds
DEBUG 01-13 08:46:33.979017.979017 cuda_h.py:10] start sllm_worker_task
DEBUG 01-13 08:46:33.979251.979251 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-13 08:46:33.979368.979368 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-13 08:46:33.980439.980439 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-13 08:46:33.980555.980555 cuda_h.py:19] end allocate_cuda_memory cost 0.00043654441833496094 seconds
DEBUG 01-13 08:46:33.980746.980746 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-13 08:46:33.980993.980993 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-13 08:46:33.980151.980151 sllm_store_c.py:27] get device uuid map
DEBUG 01-13 08:46:33.981213.981213 sllm_store_c.py:29] call client load into gpu
DEBUG 01-13 08:46:33.981519.981519 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, fb6f57e8-ccff-42fd-b844-0f51e66da9ce
DEBUG 01-13 08:46:33.981279.981279 client.py:106] call stub.LoadModelAsync
DEBUG 01-13 08:46:33.981262.981262 cuda_h.py:10] start self_attn
INFO 01-13 08:46:33.982574.982574 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, fb6f57e8-ccff-42fd-b844-0f51e66da9ce
DEBUG 01-13 08:46:33.983981.983981 cuda_h.py:19] end load_into_gpu_async cost 0.002051830291748047 seconds
DEBUG 01-13 08:46:33.983665.983665 cuda_h.py:10] start restore_tensors2
DEBUG 01-13 08:46:33.983969.983969 cuda_h.py:19] end restore_tensors2 cost 0.00013566017150878906 seconds
DEBUG 01-13 08:46:33.983336.983336 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0032875537872314453 seconds
INFO 01-13 08:46:33.983446.983446 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, fb6f57e8-ccff-42fd-b844-0f51e66da9ce
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-13 08:46:33.985439.985439 cuda_h.py:19] end self_attn cost 0.004017829895019531 seconds
DEBUG 01-13 08:46:33.986185.986185 cuda_h.py:19] end iln_self_attn_paln cost 0.006147146224975586 seconds
DEBUG 01-13 08:46:33.986551.986551 cuda_h.py:10] start layer_moe_generate_mp_l_20
DEBUG 01-13 08:46:33.986029.986029 cuda_h.py:10] start gate
DEBUG 01-13 08:46:33.987485.987485 cuda_h.py:19] end gate cost 0.0007214546203613281 seconds
DEBUG 01-13 08:46:33.987984.987984 cuda_h.py:10] start experts_map_get
DEBUG 01-13 08:46:33.987476.987476 lmp.py:1611] 
DEBUG 01-13 08:46:33.987476.987476 lmp.py:1611] Expert Token Distribution & Device Allocation:
DEBUG 01-13 08:46:33.987570.987570 lmp.py:1612]   Total experts: 64
DEBUG 01-13 08:46:33.987127.987127 lmp.py:1613]   CPU experts: 32 (50%)
DEBUG 01-13 08:46:33.987823.987823 lmp.py:1614]   GPU experts: 32 (50%)
DEBUG 01-13 08:46:33.987897.987897 lmp.py:1615] 
DEBUG 01-13 08:46:33.987897.987897 lmp.py:1615]   Expert ID | Tokens | Device
DEBUG 01-13 08:46:33.987685.987685 lmp.py:1616]   -----------------------------------
DEBUG 01-13 08:46:33.987766.987766 lmp.py:1622]   Expert 44 |     35 | CPU
DEBUG 01-13 08:46:33.987601.987601 lmp.py:1622]   Expert  1 |     49 | CPU
DEBUG 01-13 08:46:33.987244.987244 lmp.py:1622]   Expert 28 |     54 | CPU
DEBUG 01-13 08:46:33.987887.987887 lmp.py:1622]   Expert 60 |     68 | CPU
DEBUG 01-13 08:46:33.987768.987768 lmp.py:1622]   Expert 48 |     79 | CPU
DEBUG 01-13 08:46:33.987173.987173 lmp.py:1622]   Expert 27 |     81 | CPU
DEBUG 01-13 08:46:33.987816.987816 lmp.py:1622]   Expert  0 |    106 | CPU
DEBUG 01-13 08:46:33.987982.987982 lmp.py:1622]   Expert 42 |    111 | CPU
DEBUG 01-13 08:46:33.987386.987386 lmp.py:1622]   Expert 30 |    113 | CPU
DEBUG 01-13 08:46:33.987983.987983 lmp.py:1622]   Expert 62 |    114 | CPU
DEBUG 01-13 08:46:33.987487.987487 lmp.py:1622]   Expert 22 |    115 | CPU
DEBUG 01-13 08:46:33.987322.987322 lmp.py:1622]   Expert 59 |    117 | CPU
DEBUG 01-13 08:46:33.987965.987965 lmp.py:1622]   Expert 58 |    122 | CPU
DEBUG 01-13 08:46:33.987131.987131 lmp.py:1622]   Expert 12 |    126 | CPU
DEBUG 01-13 08:46:33.987297.987297 lmp.py:1622]   Expert 16 |    126 | CPU
DEBUG 01-13 08:46:33.987463.987463 lmp.py:1622]   Expert  8 |    127 | CPU
DEBUG 01-13 08:46:33.987391.987391 lmp.py:1622]   Expert  5 |    143 | CPU
DEBUG 01-13 08:46:33.987557.987557 lmp.py:1622]   Expert 56 |    143 | CPU
DEBUG 01-13 08:46:33.987247.987247 lmp.py:1622]   Expert 50 |    145 | CPU
DEBUG 01-13 08:46:33.988413.988413 lmp.py:1622]   Expert 55 |    148 | CPU
DEBUG 01-13 08:46:33.988579.988579 lmp.py:1622]   Expert 57 |    148 | CPU
DEBUG 01-13 08:46:33.988937.988937 lmp.py:1622]   Expert 15 |    154 | CPU
DEBUG 01-13 08:46:33.988441.988441 lmp.py:1622]   Expert 26 |    154 | CPU
DEBUG 01-13 08:46:33.988991.988991 lmp.py:1622]   Expert 47 |    157 | CPU
DEBUG 01-13 08:46:33.988111.988111 lmp.py:1622]   Expert 32 |    161 | CPU
DEBUG 01-13 08:46:33.988708.988708 lmp.py:1622]   Expert 41 |    161 | CPU
DEBUG 01-13 08:46:33.988828.988828 lmp.py:1622]   Expert 54 |    164 | CPU
DEBUG 01-13 08:46:33.988186.988186 lmp.py:1622]   Expert  2 |    166 | CPU
DEBUG 01-13 08:46:33.988306.988306 lmp.py:1622]   Expert 13 |    166 | CPU
DEBUG 01-13 08:46:33.988426.988426 lmp.py:1622]   Expert 24 |    166 | CPU
DEBUG 01-13 08:46:33.988367.988367 lmp.py:1622]   Expert 34 |    166 | CPU
DEBUG 01-13 08:46:33.988202.988202 lmp.py:1622]   Expert 52 |    166 | CPU
DEBUG 01-13 08:46:33.988514.988514 lmp.py:1622]   Expert  6 |    168 | GPU
DEBUG 01-13 08:46:33.988826.988826 lmp.py:1622]   Expert 18 |    170 | GPU
DEBUG 01-13 08:46:33.988760.988760 lmp.py:1622]   Expert 40 |    171 | GPU
DEBUG 01-13 08:46:33.988026.988026 lmp.py:1622]   Expert  3 |    178 | GPU
DEBUG 01-13 08:46:33.988338.988338 lmp.py:1622]   Expert 20 |    182 | GPU
DEBUG 01-13 08:46:33.988173.988173 lmp.py:1622]   Expert 37 |    185 | GPU
DEBUG 01-13 08:46:33.988545.988545 lmp.py:1622]   Expert 46 |    186 | GPU
DEBUG 01-13 08:46:33.988380.988380 lmp.py:1622]   Expert 51 |    192 | GPU
DEBUG 01-13 08:46:33.988261.988261 lmp.py:1622]   Expert 25 |    198 | GPU
DEBUG 01-13 08:46:33.988858.988858 lmp.py:1622]   Expert 31 |    199 | GPU
DEBUG 01-13 08:46:33.988693.988693 lmp.py:1622]   Expert 43 |    201 | GPU
DEBUG 01-13 08:46:33.988051.988051 lmp.py:1622]   Expert 19 |    206 | GPU
DEBUG 01-13 08:46:33.988648.988648 lmp.py:1622]   Expert 23 |    209 | GPU
DEBUG 01-13 08:46:33.988960.988960 lmp.py:1622]   Expert 11 |    210 | GPU
DEBUG 01-13 08:46:33.988894.988894 lmp.py:1622]   Expert 35 |    211 | GPU
DEBUG 01-13 08:46:33.988252.988252 lmp.py:1622]   Expert 17 |    213 | GPU
DEBUG 01-13 08:46:33.988849.988849 lmp.py:1622]   Expert 49 |    214 | GPU
DEBUG 01-13 08:46:33.988353.988353 lmp.py:1622]   Expert 39 |    221 | GPU
DEBUG 01-13 08:46:33.988188.988188 lmp.py:1622]   Expert 10 |    230 | GPU
DEBUG 01-13 08:46:33.988785.988785 lmp.py:1622]   Expert 53 |    232 | GPU
DEBUG 01-13 08:46:33.988143.988143 lmp.py:1622]   Expert 33 |    248 | GPU
DEBUG 01-13 08:46:33.988024.988024 lmp.py:1622]   Expert 36 |    269 | GPU
DEBUG 01-13 08:46:33.988098.988098 lmp.py:1622]   Expert 38 |    270 | GPU
DEBUG 01-13 08:46:33.988794.988794 lmp.py:1622]   Expert  4 |    301 | GPU
DEBUG 01-13 08:46:33.988583.988583 lmp.py:1622]   Expert 21 |    331 | GPU
DEBUG 01-13 08:46:33.988610.988610 lmp.py:1622]   Expert 14 |    335 | GPU
DEBUG 01-13 08:46:33.988968.988968 lmp.py:1622]   Expert 63 |    360 | GPU
DEBUG 01-13 08:46:33.988088.988088 lmp.py:1622]   Expert 45 |    363 | GPU
DEBUG 01-13 08:46:33.988685.988685 lmp.py:1622]   Expert 61 |    388 | GPU
DEBUG 01-13 08:46:33.988520.988520 lmp.py:1622]   Expert  9 |    395 | GPU
DEBUG 01-13 08:46:33.988116.988116 lmp.py:1622]   Expert 29 |    487 | GPU
DEBUG 01-13 08:46:33.988951.988951 lmp.py:1622]   Expert  7 |    514 | GPU
DEBUG 01-13 08:46:33.988502.988502 lmp.py:1623] 
DEBUG 01-13 08:46:33.988502.988502 lmp.py:1623]   CPU total tokens: 4051 (33.0%)
DEBUG 01-13 08:46:33.988482.988482 lmp.py:1624]   GPU total tokens: 8237 (67.0%)
DEBUG 01-13 08:46:33.988232.988232 cuda_h.py:19] end experts_map_get cost 0.001836538314819336 seconds
DEBUG 01-13 08:46:33.989618.989618 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-13 08:46:33.989374.989374 lmp.py:1632] 
DEBUG 01-13 08:46:33.989374.989374 lmp.py:1632]   Computing 32 experts on CPU MP...
DEBUG 01-13 08:46:33.989065.989065 cuda_h.py:19] end cpu_experts_submit cost 5.078315734863281e-05 seconds
DEBUG 01-13 08:46:33.989529.989529 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-13 08:46:33.989697.989697 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-13 08:46:33.989536.989536 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-13 08:46:33.990667.990667 cuda_h.py:19] end allocate_cuda_memory cost 0.0009009838104248047 seconds
DEBUG 01-13 08:46:33.990517.990517 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-13 08:46:33.990896.990896 sllm_store_c.py:27] get device uuid map
DEBUG 01-13 08:46:33.991191.991191 sllm_store_c.py:29] call client load into gpu
DEBUG 01-13 08:46:33.991570.991570 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 33ab0b41-b9a5-44f4-9eb0-36a2201aa184
DEBUG 01-13 08:46:33.991795.991795 client.py:106] call stub.LoadModelAsync
INFO 01-13 08:46:33.991981.991981 client.py:127] Model loaded
DEBUG 01-13 08:46:33.991600.991600 cuda_h.py:10] start restore2model
DEBUG 01-13 08:46:33.992787.992787 cuda_h.py:10] start experts_func_gpu_einsum_mp
DEBUG 01-13 08:46:33.992359.992359 cuda_h.py:19] end restore2model cost 0.0008306503295898438 seconds
DEBUG 01-13 08:46:33.992112.992112 cuda_h.py:19] end sllm_worker_task cost 0.012742280960083008 seconds
INFO 01-13 08:46:33.993939.993939 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 33ab0b41-b9a5-44f4-9eb0-36a2201aa184
DEBUG 01-13 08:46:33.993510.993510 cuda_h.py:19] end load_into_gpu_async cost 0.0027322769165039062 seconds
DEBUG 01-13 08:46:33.993790.993790 cuda_h.py:10] start restore_tensors2
DEBUG 01-13 08:46:33.993425.993425 cuda_h.py:19] end restore_tensors2 cost 0.00036978721618652344 seconds
DEBUG 01-13 08:46:33.993109.993109 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.004386425018310547 seconds
DEBUG 01-13 08:46:33.993256.993256 cuda_h.py:10] start restore2model
DEBUG 01-13 08:46:33.996257.996257 cuda_h.py:19] end restore2model cost 0.0031609535217285156 seconds
DEBUG 01-13 08:46:33.996239.996239 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.007731914520263672 seconds
DEBUG 01-13 08:46:33.996465.996465 cuda_h.py:10] start gpu_sexperts
DEBUG 01-13 08:46:33.997172.997172 cuda_h.py:19] end gpu_sexperts cost 0.0003123283386230469 seconds
DEBUG 01-13 08:46:33.997671.997671 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-13 08:46:33.997361.997361 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 1.8358230590820312e-05 seconds
DEBUG 01-13 08:46:33.997488.997488 cuda_h.py:10] start wait_experts
INFO 01-13 08:46:33.997522.997522 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 33ab0b41-b9a5-44f4-9eb0-36a2201aa184
DEBUG 01-13 08:46:34.004077.004077 mlpmodule.py:1006] group tensors cost 0.010967731475830078 s
DEBUG 01-13 08:46:34.011737.011737 mlpmodule.py:1044] pad cost 0.00513768196105957 s
DEBUG 01-13 08:46:34.011255.011255 mlpmodule.py:1050] create cpu tensor cost 0.00011730194091796875 s
DEBUG 01-13 08:46:34.011201.011201 mlpmodule.py:1055] move to cpu cost 7.843971252441406e-05 s
DEBUG 01-13 08:46:34.022267.022267 mlpmodule.py:1069] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-13 08:46:34.022081.022081 mlpmodule.py:1070] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-13 08:46:34.022774.022774 mlpmodule.py:1075] group_w3 first element: -0.0034942626953125
WARNING 01-13 08:46:34.022679.022679 mlpmodule.py:1085] start einsum2
DEBUG 01-13 08:46:34.037720.037720 mlpmodule.py:1095] group einsum cost 0.025638103485107422 s
DEBUG 01-13 08:46:34.038119.038119 mlpmodule.py:1103] cpy2cputensor cost 0.0006456375122070312 s
INFO 01-13 08:46:34.043070.043070 client.py:127] Model loaded
DEBUG 01-13 08:46:34.044229.044229 cuda_h.py:19] end wait_experts cost 0.0466008186340332 seconds
DEBUG 01-13 08:46:34.044998.044998 cuda_h.py:10] start gpu_experts
DEBUG 01-13 08:46:34.045467.045467 mlpmodule.py:559] gpu group tensors cost 0.0008227825164794922 s
DEBUG 01-13 08:46:34.047998.047998 mlpmodule.py:592] gpu pad cost 0.002335071563720703 s
DEBUG 01-13 08:46:34.047968.047968 mlpmodule.py:598] start_w1
DEBUG 01-13 08:46:34.047241.047241 mlpmodule.py:602] start_w3
DEBUG 01-13 08:46:34.048375.048375 mlpmodule.py:608] start_w2
DEBUG 01-13 08:46:34.048025.048025 mlpmodule.py:611] gpu group einsum cost 0.0009160041809082031 s
DEBUG 01-13 08:46:34.052353.052353 mlpmodule.py:683] gpu experts func einsum cost 0.007905721664428711 s
DEBUG 01-13 08:46:34.052840.052840 cuda_h.py:19] end gpu_experts cost 0.008099794387817383 seconds
DEBUG 01-13 08:46:34.052318.052318 cuda_h.py:10] start cpu_thread_manager_mp_wait
DEBUG 01-13 08:46:34.052665.052665 cuda_h.py:19] end cpu_thread_manager_mp_wait cost 4.267692565917969e-05 seconds
DEBUG 01-13 08:46:34.052312.052312 cuda_h.py:19] end layer_moe_generate_mp_l_20 cost 0.06618690490722656 seconds
DEBUG 01-13 08:46:34.052899.052899 lmp.py:1550] -------------------------------- end prefill layer 19 --------------------------------
DEBUG 01-13 08:46:34.052622.052622 lmp.py:1493] -------------------------------- start prefill layer 20 --------------------------------
DEBUG 01-13 08:46:34.052332.052332 cuda_h.py:10] start start_load_qkvogn_s_weight_l_21
DEBUG 01-13 08:46:34.052810.052810 cuda_h.py:10] start start_load_qkvogn_s_weight_l_21
DEBUG 01-13 08:46:34.052236.052236 cuda_h.py:19] end start_load_qkvogn_s_weight_l_21 cost 3.409385681152344e-05 seconds
DEBUG 01-13 08:46:34.052992.052992 cuda_h.py:19] end start_load_qkvogn_s_weight_l_21 cost 6.818771362304688e-05 seconds
DEBUG 01-13 08:46:34.053403.053403 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-13 08:46:34.053677.053677 cuda_h.py:10] start sllm_worker_task
DEBUG 01-13 08:46:34.053700.053700 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-13 08:46:34.053675.053675 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-13 08:46:34.053032.053032 cuda_h.py:19] end allocate_cuda_memory cost 0.000331878662109375 seconds
DEBUG 01-13 08:46:34.053830.053830 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-13 08:46:34.053043.053043 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-13 08:46:34.053086.053086 sllm_store_c.py:27] get device uuid map
DEBUG 01-13 08:46:34.053055.053055 sllm_store_c.py:29] call client load into gpu
DEBUG 01-13 08:46:34.053473.053473 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, d4a64c08-1935-4299-8847-251f4e01e438
DEBUG 01-13 08:46:34.054457.054457 client.py:106] call stub.LoadModelAsync
DEBUG 01-13 08:46:34.054894.054894 cuda_h.py:10] start self_attn
INFO 01-13 08:46:34.055880.055880 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, d4a64c08-1935-4299-8847-251f4e01e438
DEBUG 01-13 08:46:34.055385.055385 cuda_h.py:19] end load_into_gpu_async cost 0.0017993450164794922 seconds
DEBUG 01-13 08:46:34.055419.055419 cuda_h.py:10] start restore_tensors2
DEBUG 01-13 08:46:34.055171.055171 cuda_h.py:19] end restore_tensors2 cost 7.152557373046875e-05 seconds
DEBUG 01-13 08:46:34.055496.055496 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0025932788848876953 seconds
INFO 01-13 08:46:34.055909.055909 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, d4a64c08-1935-4299-8847-251f4e01e438
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-13 08:46:34.058027.058027 cuda_h.py:19] end self_attn cost 0.0036809444427490234 seconds
DEBUG 01-13 08:46:34.058488.058488 cuda_h.py:19] end iln_self_attn_paln cost 0.005473613739013672 seconds
DEBUG 01-13 08:46:34.058331.058331 cuda_h.py:10] start layer_moe_generate_mp_l_21
DEBUG 01-13 08:46:34.058094.058094 cuda_h.py:10] start gate
DEBUG 01-13 08:46:34.059459.059459 cuda_h.py:19] end gate cost 0.000759124755859375 seconds
DEBUG 01-13 08:46:34.059195.059195 cuda_h.py:10] start experts_map_get
DEBUG 01-13 08:46:34.059549.059549 lmp.py:1611] 
DEBUG 01-13 08:46:34.059549.059549 lmp.py:1611] Expert Token Distribution & Device Allocation:
DEBUG 01-13 08:46:34.059305.059305 lmp.py:1612]   Total experts: 64
DEBUG 01-13 08:46:34.059339.059339 lmp.py:1613]   CPU experts: 32 (50%)
DEBUG 01-13 08:46:34.059081.059081 lmp.py:1614]   GPU experts: 32 (50%)
DEBUG 01-13 08:46:34.060916.060916 lmp.py:1615] 
DEBUG 01-13 08:46:34.060916.060916 lmp.py:1615]   Expert ID | Tokens | Device
DEBUG 01-13 08:46:34.060990.060990 lmp.py:1616]   -----------------------------------
DEBUG 01-13 08:46:34.060070.060070 lmp.py:1622]   Expert 54 |     24 | CPU
DEBUG 01-13 08:46:34.060144.060144 lmp.py:1622]   Expert  3 |     34 | CPU
DEBUG 01-13 08:46:34.060025.060025 lmp.py:1622]   Expert  8 |     42 | CPU
DEBUG 01-13 08:46:34.060906.060906 lmp.py:1622]   Expert 28 |     44 | CPU
DEBUG 01-13 08:46:34.060549.060549 lmp.py:1622]   Expert 43 |     50 | CPU
DEBUG 01-13 08:46:34.060954.060954 lmp.py:1622]   Expert 63 |     52 | CPU
DEBUG 01-13 08:46:34.060120.060120 lmp.py:1622]   Expert 36 |     68 | CPU
DEBUG 01-13 08:46:34.060525.060525 lmp.py:1622]   Expert  6 |     77 | CPU
DEBUG 01-13 08:46:34.060313.060313 lmp.py:1622]   Expert 38 |     80 | CPU
DEBUG 01-13 08:46:34.060433.060433 lmp.py:1622]   Expert 39 |     88 | CPU
DEBUG 01-13 08:46:34.060553.060553 lmp.py:1622]   Expert 57 |     99 | CPU
DEBUG 01-13 08:46:34.060779.060779 lmp.py:1622]   Expert 52 |    104 | CPU
DEBUG 01-13 08:46:34.060137.060137 lmp.py:1622]   Expert 12 |    107 | CPU
DEBUG 01-13 08:46:34.060019.060019 lmp.py:1622]   Expert 41 |    111 | CPU
DEBUG 01-13 08:46:34.060900.060900 lmp.py:1622]   Expert 19 |    124 | CPU
DEBUG 01-13 08:46:34.060066.060066 lmp.py:1622]   Expert 13 |    128 | CPU
DEBUG 01-13 08:46:34.060232.060232 lmp.py:1622]   Expert 22 |    128 | CPU
DEBUG 01-13 08:46:34.060637.060637 lmp.py:1622]   Expert 47 |    129 | CPU
DEBUG 01-13 08:46:34.060432.060432 lmp.py:1622]   Expert 50 |    148 | CPU
DEBUG 01-13 08:46:34.060599.060599 lmp.py:1622]   Expert 46 |    150 | CPU
DEBUG 01-13 08:46:34.060003.060003 lmp.py:1622]   Expert  2 |    165 | CPU
DEBUG 01-13 08:46:34.060169.060169 lmp.py:1622]   Expert 20 |    169 | CPU
DEBUG 01-13 08:46:34.060574.060574 lmp.py:1622]   Expert 40 |    169 | CPU
DEBUG 01-13 08:46:34.060740.060740 lmp.py:1622]   Expert 37 |    171 | CPU
DEBUG 01-13 08:46:34.060621.060621 lmp.py:1622]   Expert 24 |    172 | CPU
DEBUG 01-13 08:46:34.060503.060503 lmp.py:1622]   Expert 49 |    174 | CPU
DEBUG 01-13 08:46:34.060146.060146 lmp.py:1622]   Expert 55 |    174 | CPU
DEBUG 01-13 08:46:34.060955.060955 lmp.py:1622]   Expert 21 |    176 | CPU
DEBUG 01-13 08:46:34.060359.060359 lmp.py:1622]   Expert 61 |    177 | CPU
DEBUG 01-13 08:46:34.060525.060525 lmp.py:1622]   Expert 53 |    179 | CPU
DEBUG 01-13 08:46:34.060930.060930 lmp.py:1622]   Expert 33 |    180 | CPU
DEBUG 01-13 08:46:34.060335.060335 lmp.py:1622]   Expert 42 |    181 | CPU
DEBUG 01-13 08:46:34.060501.060501 lmp.py:1622]   Expert 23 |    185 | GPU
DEBUG 01-13 08:46:34.060667.060667 lmp.py:1622]   Expert 18 |    187 | GPU
DEBUG 01-13 08:46:34.060071.060071 lmp.py:1622]   Expert  0 |    191 | GPU
DEBUG 01-13 08:46:34.060476.060476 lmp.py:1622]   Expert 16 |    196 | GPU
DEBUG 01-13 08:46:34.060881.060881 lmp.py:1622]   Expert 32 |    200 | GPU
DEBUG 01-13 08:46:34.060047.060047 lmp.py:1622]   Expert 14 |    204 | GPU
DEBUG 01-13 08:46:34.060643.060643 lmp.py:1622]   Expert 30 |    206 | GPU
DEBUG 01-13 08:46:34.060763.060763 lmp.py:1622]   Expert 31 |    207 | GPU
DEBUG 01-13 08:46:34.060883.060883 lmp.py:1622]   Expert  5 |    211 | GPU
DEBUG 01-13 08:46:34.060241.060241 lmp.py:1622]   Expert  7 |    212 | GPU
DEBUG 01-13 08:46:34.060646.060646 lmp.py:1622]   Expert 60 |    215 | GPU
DEBUG 01-13 08:46:34.060812.060812 lmp.py:1622]   Expert  9 |    216 | GPU
DEBUG 01-13 08:46:34.060216.060216 lmp.py:1622]   Expert 17 |    218 | GPU
DEBUG 01-13 08:46:34.060383.060383 lmp.py:1622]   Expert 62 |    218 | GPU
DEBUG 01-13 08:46:34.060310.060310 lmp.py:1622]   Expert 34 |    220 | GPU
DEBUG 01-13 08:46:34.060476.060476 lmp.py:1622]   Expert 59 |    224 | GPU
DEBUG 01-13 08:46:34.060643.060643 lmp.py:1622]   Expert 29 |    229 | GPU
DEBUG 01-13 08:46:34.060570.060570 lmp.py:1622]   Expert 10 |    232 | GPU
DEBUG 01-13 08:46:34.060736.060736 lmp.py:1622]   Expert 15 |    234 | GPU
DEBUG 01-13 08:46:34.060618.060618 lmp.py:1622]   Expert 58 |    236 | GPU
DEBUG 01-13 08:46:34.061976.061976 lmp.py:1622]   Expert  4 |    243 | GPU
DEBUG 01-13 08:46:34.061096.061096 lmp.py:1622]   Expert 11 |    243 | GPU
DEBUG 01-13 08:46:34.061216.061216 lmp.py:1622]   Expert 26 |    248 | GPU
DEBUG 01-13 08:46:34.061620.061620 lmp.py:1622]   Expert 51 |    250 | GPU
DEBUG 01-13 08:46:34.061025.061025 lmp.py:1622]   Expert 44 |    275 | GPU
DEBUG 01-13 08:46:34.061668.061668 lmp.py:1622]   Expert 27 |    283 | GPU
DEBUG 01-13 08:46:34.061072.061072 lmp.py:1622]   Expert 56 |    291 | GPU
DEBUG 01-13 08:46:34.061715.061715 lmp.py:1622]   Expert  1 |    335 | GPU
DEBUG 01-13 08:46:34.061120.061120 lmp.py:1622]   Expert 45 |    368 | GPU
DEBUG 01-13 08:46:34.061524.061524 lmp.py:1622]   Expert 25 |    472 | GPU
DEBUG 01-13 08:46:34.061929.061929 lmp.py:1622]   Expert 35 |    523 | GPU
DEBUG 01-13 08:46:34.061002.061002 lmp.py:1622]   Expert 48 |    642 | GPU
DEBUG 01-13 08:46:34.061076.061076 lmp.py:1623] 
DEBUG 01-13 08:46:34.061076.061076 lmp.py:1623]   CPU total tokens: 3874 (31.5%)
DEBUG 01-13 08:46:34.061865.061865 lmp.py:1624]   GPU total tokens: 8414 (68.5%)
DEBUG 01-13 08:46:34.061660.061660 cuda_h.py:19] end experts_map_get cost 0.001787424087524414 seconds
DEBUG 01-13 08:46:34.061855.061855 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-13 08:46:34.061326.061326 lmp.py:1632] 
DEBUG 01-13 08:46:34.061326.061326 lmp.py:1632]   Computing 32 experts on CPU MP...
DEBUG 01-13 08:46:34.061685.061685 cuda_h.py:19] end cpu_experts_submit cost 5.435943603515625e-05 seconds
DEBUG 01-13 08:46:34.061335.061335 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-13 08:46:34.061456.061456 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-13 08:46:34.061560.061560 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-13 08:46:34.062376.062376 cuda_h.py:19] end allocate_cuda_memory cost 0.0002799034118652344 seconds
DEBUG 01-13 08:46:34.062134.062134 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-13 08:46:34.062605.062605 sllm_store_c.py:27] get device uuid map
DEBUG 01-13 08:46:34.062421.062421 sllm_store_c.py:29] call client load into gpu
DEBUG 01-13 08:46:34.062216.062216 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 26916a49-8c6d-4903-aee5-731aed873c60
DEBUG 01-13 08:46:34.062587.062587 client.py:106] call stub.LoadModelAsync
INFO 01-13 08:46:34.062622.062622 client.py:127] Model loaded
DEBUG 01-13 08:46:34.062213.062213 cuda_h.py:10] start restore2model
DEBUG 01-13 08:46:34.063019.063019 cuda_h.py:19] end restore2model cost 0.0003197193145751953 seconds
DEBUG 01-13 08:46:34.063497.063497 cuda_h.py:19] end sllm_worker_task cost 0.010184049606323242 seconds
DEBUG 01-13 08:46:34.064758.064758 mlpmodule.py:785]  experts func einsum cost 0.07090401649475098 s
INFO 01-13 08:46:34.064952.064952 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 26916a49-8c6d-4903-aee5-731aed873c60
DEBUG 01-13 08:46:34.064619.064619 cuda_h.py:19] end experts_func_gpu_einsum_mp cost 0.07232284545898438 seconds
DEBUG 01-13 08:46:34.064308.064308 cuda_h.py:19] end load_into_gpu_async cost 0.0023932456970214844 seconds
DEBUG 01-13 08:46:34.064901.064901 cuda_h.py:10] start restore_tensors2
DEBUG 01-13 08:46:34.065506.065506 cuda_h.py:19] end restore_tensors2 cost 0.0004134178161621094 seconds
DEBUG 01-13 08:46:34.065296.065296 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0038933753967285156 seconds
DEBUG 01-13 08:46:34.065112.065112 cuda_h.py:10] start restore2model
DEBUG 01-13 08:46:34.065097.065097 cuda_h.py:10] start experts_func_gpu_einsum_mp
DEBUG 01-13 08:46:34.068465.068465 cuda_h.py:19] end restore2model cost 0.0030031204223632812 seconds
DEBUG 01-13 08:46:34.068162.068162 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.007078647613525391 seconds
DEBUG 01-13 08:46:34.068958.068958 cuda_h.py:10] start gpu_sexperts
DEBUG 01-13 08:46:34.068711.068711 cuda_h.py:19] end gpu_sexperts cost 0.00031113624572753906 seconds
DEBUG 01-13 08:46:34.068925.068925 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-13 08:46:34.069701.069701 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 1.5020370483398438e-05 seconds
DEBUG 01-13 08:46:34.069066.069066 cuda_h.py:10] start wait_experts
INFO 01-13 08:46:34.069623.069623 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 26916a49-8c6d-4903-aee5-731aed873c60
DEBUG 01-13 08:46:34.075776.075776 mlpmodule.py:1006] group tensors cost 0.009116411209106445 s
DEBUG 01-13 08:46:34.078951.078951 mlpmodule.py:1044] pad cost 0.0020759105682373047 s
DEBUG 01-13 08:46:34.078915.078915 mlpmodule.py:1050] create cpu tensor cost 5.4836273193359375e-05 s
DEBUG 01-13 08:46:34.078494.078494 mlpmodule.py:1055] move to cpu cost 3.9577484130859375e-05 s
DEBUG 01-13 08:46:34.088573.088573 mlpmodule.py:1069] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-13 08:46:34.088639.088639 mlpmodule.py:1070] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-13 08:46:34.088114.088114 mlpmodule.py:1075] group_w3 first element: 0.039306640625
WARNING 01-13 08:46:34.088589.088589 mlpmodule.py:1085] start einsum2
DEBUG 01-13 08:46:34.101209.101209 mlpmodule.py:1095] group einsum cost 0.022457599639892578 s
DEBUG 01-13 08:46:34.102453.102453 mlpmodule.py:1103] cpy2cputensor cost 0.0007333755493164062 s
INFO 01-13 08:46:34.115513.115513 client.py:127] Model loaded
DEBUG 01-13 08:46:34.115301.115301 cuda_h.py:19] end wait_experts cost 0.046120643615722656 seconds
DEBUG 01-13 08:46:34.115309.115309 cuda_h.py:10] start gpu_experts
DEBUG 01-13 08:46:34.116876.116876 mlpmodule.py:559] gpu group tensors cost 0.0007905960083007812 s
DEBUG 01-13 08:46:34.118344.118344 mlpmodule.py:592] gpu pad cost 0.0022335052490234375 s
DEBUG 01-13 08:46:34.118699.118699 mlpmodule.py:598] start_w1
DEBUG 01-13 08:46:34.118023.118023 mlpmodule.py:602] start_w3
DEBUG 01-13 08:46:34.119202.119202 mlpmodule.py:608] start_w2
DEBUG 01-13 08:46:34.119347.119347 mlpmodule.py:611] gpu group einsum cost 0.0007650852203369141 s
DEBUG 01-13 08:46:34.122943.122943 mlpmodule.py:683] gpu experts func einsum cost 0.006953716278076172 s
DEBUG 01-13 08:46:34.122787.122787 cuda_h.py:19] end gpu_experts cost 0.007132053375244141 seconds
DEBUG 01-13 08:46:34.122921.122921 cuda_h.py:10] start cpu_thread_manager_mp_wait
DEBUG 01-13 08:46:34.122208.122208 cuda_h.py:19] end cpu_thread_manager_mp_wait cost 3.814697265625e-05 seconds
DEBUG 01-13 08:46:34.122330.122330 cuda_h.py:19] end layer_moe_generate_mp_l_21 cost 0.06401228904724121 seconds
DEBUG 01-13 08:46:34.122438.122438 lmp.py:1550] -------------------------------- end prefill layer 20 --------------------------------
DEBUG 01-13 08:46:34.122962.122962 lmp.py:1493] -------------------------------- start prefill layer 21 --------------------------------
DEBUG 01-13 08:46:34.122758.122758 cuda_h.py:10] start start_load_qkvogn_s_weight_l_22
DEBUG 01-13 08:46:34.122130.122130 cuda_h.py:10] start start_load_qkvogn_s_weight_l_22
DEBUG 01-13 08:46:34.123926.123926 cuda_h.py:19] end start_load_qkvogn_s_weight_l_22 cost 3.504753112792969e-05 seconds
DEBUG 01-13 08:46:34.123080.123080 cuda_h.py:19] end start_load_qkvogn_s_weight_l_22 cost 8.106231689453125e-05 seconds
DEBUG 01-13 08:46:34.123346.123346 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-13 08:46:34.123381.123381 cuda_h.py:10] start sllm_worker_task
DEBUG 01-13 08:46:34.123372.123372 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-13 08:46:34.123287.123287 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-13 08:46:34.123073.123073 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-13 08:46:34.123152.123152 cuda_h.py:19] end allocate_cuda_memory cost 0.0003349781036376953 seconds
DEBUG 01-13 08:46:34.123221.123221 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-13 08:46:34.123268.123268 sllm_store_c.py:27] get device uuid map
DEBUG 01-13 08:46:34.123853.123853 sllm_store_c.py:29] call client load into gpu
DEBUG 01-13 08:46:34.124887.124887 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, f25dafc0-e9fd-4c28-b219-8070eea0b908
DEBUG 01-13 08:46:34.124386.124386 client.py:106] call stub.LoadModelAsync
DEBUG 01-13 08:46:34.124821.124821 cuda_h.py:10] start self_attn
DEBUG 01-13 08:46:34.125082.125082 mlpmodule.py:785]  experts func einsum cost 0.05823516845703125 s
DEBUG 01-13 08:46:34.125103.125103 cuda_h.py:19] end experts_func_gpu_einsum_mp cost 0.05965089797973633 seconds
INFO 01-13 08:46:34.125347.125347 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, f25dafc0-e9fd-4c28-b219-8070eea0b908
DEBUG 01-13 08:46:34.125945.125945 cuda_h.py:19] end load_into_gpu_async cost 0.0017971992492675781 seconds
DEBUG 01-13 08:46:34.125310.125310 cuda_h.py:10] start restore_tensors2
DEBUG 01-13 08:46:34.125200.125200 cuda_h.py:19] end restore_tensors2 cost 6.985664367675781e-05 seconds
DEBUG 01-13 08:46:34.125447.125447 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.002474546432495117 seconds
INFO 01-13 08:46:34.125806.125806 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, f25dafc0-e9fd-4c28-b219-8070eea0b908
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-13 08:46:34.127569.127569 cuda_h.py:19] end self_attn cost 0.0032949447631835938 seconds
DEBUG 01-13 08:46:34.128667.128667 cuda_h.py:19] end iln_self_attn_paln cost 0.005016803741455078 seconds
DEBUG 01-13 08:46:34.128464.128464 cuda_h.py:10] start layer_moe_generate_mp_l_22
DEBUG 01-13 08:46:34.128187.128187 cuda_h.py:10] start gate
DEBUG 01-13 08:46:34.129730.129730 cuda_h.py:19] end gate cost 0.0007488727569580078 seconds
DEBUG 01-13 08:46:34.129467.129467 cuda_h.py:10] start experts_map_get
DEBUG 01-13 08:46:34.129721.129721 lmp.py:1611] 
DEBUG 01-13 08:46:34.129721.129721 lmp.py:1611] Expert Token Distribution & Device Allocation:
DEBUG 01-13 08:46:34.129861.129861 lmp.py:1612]   Total experts: 64
DEBUG 01-13 08:46:34.129657.129657 lmp.py:1613]   CPU experts: 32 (50%)
DEBUG 01-13 08:46:34.129637.129637 lmp.py:1614]   GPU experts: 32 (50%)
DEBUG 01-13 08:46:34.129711.129711 lmp.py:1615] 
DEBUG 01-13 08:46:34.129711.129711 lmp.py:1615]   Expert ID | Tokens | Device
DEBUG 01-13 08:46:34.129738.129738 lmp.py:1616]   -----------------------------------
DEBUG 01-13 08:46:34.129534.129534 lmp.py:1622]   Expert 44 |     26 | CPU
DEBUG 01-13 08:46:34.129322.129322 lmp.py:1622]   Expert  9 |     31 | CPU
DEBUG 01-13 08:46:34.129919.129919 lmp.py:1622]   Expert 11 |     31 | CPU
DEBUG 01-13 08:46:34.129039.129039 lmp.py:1622]   Expert 56 |     55 | CPU
DEBUG 01-13 08:46:34.129874.129874 lmp.py:1622]   Expert 54 |     77 | CPU
DEBUG 01-13 08:46:34.129994.129994 lmp.py:1622]   Expert  7 |     82 | CPU
DEBUG 01-13 08:46:34.129875.129875 lmp.py:1622]   Expert 47 |     84 | CPU
DEBUG 01-13 08:46:34.129756.129756 lmp.py:1622]   Expert 62 |     93 | CPU
DEBUG 01-13 08:46:34.129353.129353 lmp.py:1622]   Expert 60 |    102 | CPU
DEBUG 01-13 08:46:34.129473.129473 lmp.py:1622]   Expert 53 |    103 | CPU
DEBUG 01-13 08:46:34.129023.129023 lmp.py:1622]   Expert 51 |    105 | CPU
DEBUG 01-13 08:46:34.129858.129858 lmp.py:1622]   Expert 41 |    108 | CPU
DEBUG 01-13 08:46:34.129170.129170 lmp.py:1622]   Expert 52 |    110 | CPU
DEBUG 01-13 08:46:34.129528.129528 lmp.py:1622]   Expert 22 |    117 | CPU
DEBUG 01-13 08:46:34.129410.129410 lmp.py:1622]   Expert  1 |    119 | CPU
DEBUG 01-13 08:46:34.129291.129291 lmp.py:1622]   Expert  6 |    126 | CPU
DEBUG 01-13 08:46:34.129173.129173 lmp.py:1622]   Expert 32 |    127 | CPU
DEBUG 01-13 08:46:34.129816.129816 lmp.py:1622]   Expert  8 |    129 | CPU
DEBUG 01-13 08:46:34.130459.130459 lmp.py:1622]   Expert 48 |    133 | CPU
DEBUG 01-13 08:46:34.130340.130340 lmp.py:1622]   Expert  2 |    135 | CPU
DEBUG 01-13 08:46:34.130983.130983 lmp.py:1622]   Expert 27 |    136 | CPU
DEBUG 01-13 08:46:34.130626.130626 lmp.py:1622]   Expert 35 |    137 | CPU
DEBUG 01-13 08:46:34.130699.130699 lmp.py:1622]   Expert 26 |    140 | CPU
DEBUG 01-13 08:46:34.130011.130011 lmp.py:1622]   Expert 39 |    140 | CPU
DEBUG 01-13 08:46:34.130608.130608 lmp.py:1622]   Expert 23 |    144 | CPU
DEBUG 01-13 08:46:34.130158.130158 lmp.py:1622]   Expert 59 |    146 | CPU
DEBUG 01-13 08:46:34.130278.130278 lmp.py:1622]   Expert 50 |    155 | CPU
DEBUG 01-13 08:46:34.130160.130160 lmp.py:1622]   Expert 14 |    160 | CPU
DEBUG 01-13 08:46:34.130041.130041 lmp.py:1622]   Expert 38 |    166 | CPU
DEBUG 01-13 08:46:34.130161.130161 lmp.py:1622]   Expert 24 |    168 | CPU
DEBUG 01-13 08:46:34.130042.130042 lmp.py:1622]   Expert 49 |    171 | CPU
DEBUG 01-13 08:46:34.130923.130923 lmp.py:1622]   Expert  4 |    173 | CPU
DEBUG 01-13 08:46:34.130805.130805 lmp.py:1622]   Expert 34 |    175 | GPU
DEBUG 01-13 08:46:34.130448.130448 lmp.py:1622]   Expert 46 |    175 | GPU
DEBUG 01-13 08:46:34.130806.130806 lmp.py:1622]   Expert  5 |    180 | GPU
DEBUG 01-13 08:46:34.130880.130880 lmp.py:1622]   Expert  0 |    184 | GPU
DEBUG 01-13 08:46:34.130476.130476 lmp.py:1622]   Expert 40 |    184 | GPU
DEBUG 01-13 08:46:34.130550.130550 lmp.py:1622]   Expert 63 |    186 | GPU
DEBUG 01-13 08:46:34.130146.130146 lmp.py:1622]   Expert 19 |    191 | GPU
DEBUG 01-13 08:46:34.130266.130266 lmp.py:1622]   Expert 13 |    202 | GPU
DEBUG 01-13 08:46:34.130909.130909 lmp.py:1622]   Expert 29 |    204 | GPU
DEBUG 01-13 08:46:34.130029.130029 lmp.py:1622]   Expert 57 |    210 | GPU
DEBUG 01-13 08:46:34.130149.130149 lmp.py:1622]   Expert 43 |    211 | GPU
DEBUG 01-13 08:46:34.130792.130792 lmp.py:1622]   Expert 61 |    221 | GPU
DEBUG 01-13 08:46:34.130912.130912 lmp.py:1622]   Expert 33 |    223 | GPU
DEBUG 01-13 08:46:34.130555.130555 lmp.py:1622]   Expert 31 |    241 | GPU
DEBUG 01-13 08:46:34.130436.130436 lmp.py:1622]   Expert 15 |    246 | GPU
DEBUG 01-13 08:46:34.130039.130039 lmp.py:1622]   Expert  3 |    249 | GPU
DEBUG 01-13 08:46:34.130398.130398 lmp.py:1622]   Expert 20 |    254 | GPU
DEBUG 01-13 08:46:34.130279.130279 lmp.py:1622]   Expert 16 |    257 | GPU
DEBUG 01-13 08:46:34.130922.130922 lmp.py:1622]   Expert 12 |    261 | GPU
DEBUG 01-13 08:46:34.130327.130327 lmp.py:1622]   Expert 37 |    261 | GPU
DEBUG 01-13 08:46:34.130254.130254 lmp.py:1622]   Expert 36 |    275 | GPU
DEBUG 01-13 08:46:34.130182.130182 lmp.py:1622]   Expert 18 |    280 | GPU
DEBUG 01-13 08:46:34.130348.130348 lmp.py:1622]   Expert 28 |    297 | GPU
DEBUG 01-13 08:46:34.130514.130514 lmp.py:1622]   Expert 17 |    299 | GPU
DEBUG 01-13 08:46:34.130680.130680 lmp.py:1622]   Expert 25 |    310 | GPU
DEBUG 01-13 08:46:34.130085.130085 lmp.py:1622]   Expert 55 |    313 | GPU
DEBUG 01-13 08:46:34.130966.130966 lmp.py:1622]   Expert 30 |    328 | GPU
DEBUG 01-13 08:46:34.130371.130371 lmp.py:1622]   Expert 58 |    344 | GPU
DEBUG 01-13 08:46:34.130491.130491 lmp.py:1622]   Expert 10 |    368 | GPU
DEBUG 01-13 08:46:34.130849.130849 lmp.py:1622]   Expert 45 |    380 | GPU
DEBUG 01-13 08:46:34.130015.130015 lmp.py:1622]   Expert 21 |    385 | GPU
DEBUG 01-13 08:46:34.130943.130943 lmp.py:1622]   Expert 42 |    665 | GPU
DEBUG 01-13 08:46:34.130063.130063 lmp.py:1623] 
DEBUG 01-13 08:46:34.130063.130063 lmp.py:1623]   CPU total tokens: 3729 (30.3%)
DEBUG 01-13 08:46:34.130944.130944 lmp.py:1624]   GPU total tokens: 8559 (69.7%)
DEBUG 01-13 08:46:34.130071.130071 cuda_h.py:19] end experts_map_get cost 0.0017848014831542969 seconds
DEBUG 01-13 08:46:34.130689.130689 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-13 08:46:34.130445.130445 lmp.py:1632] 
DEBUG 01-13 08:46:34.130445.130445 lmp.py:1632]   Computing 32 experts on CPU MP...
DEBUG 01-13 08:46:34.131513.131513 cuda_h.py:19] end cpu_experts_submit cost 5.0067901611328125e-05 seconds
DEBUG 01-13 08:46:34.131017.131017 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-13 08:46:34.131515.131515 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-13 08:46:34.131309.131309 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-13 08:46:34.132058.132058 cuda_h.py:19] end allocate_cuda_memory cost 0.0015676021575927734 seconds
DEBUG 01-13 08:46:34.132292.132292 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-13 08:46:34.132670.132670 sllm_store_c.py:27] get device uuid map
DEBUG 01-13 08:46:34.133387.133387 sllm_store_c.py:29] call client load into gpu
DEBUG 01-13 08:46:34.133659.133659 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 668e96a5-8d2a-4f72-b72b-66956319178e
DEBUG 01-13 08:46:34.133593.133593 client.py:106] call stub.LoadModelAsync
INFO 01-13 08:46:34.133297.133297 client.py:127] Model loaded
DEBUG 01-13 08:46:34.133179.133179 cuda_h.py:10] start restore2model
DEBUG 01-13 08:46:34.134172.134172 cuda_h.py:19] end restore2model cost 0.0003275871276855469 seconds
DEBUG 01-13 08:46:34.134227.134227 cuda_h.py:19] end sllm_worker_task cost 0.01085352897644043 seconds
DEBUG 01-13 08:46:34.134059.134059 cuda_h.py:10] start experts_func_gpu_einsum_mp
INFO 01-13 08:46:34.135645.135645 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 668e96a5-8d2a-4f72-b72b-66956319178e
DEBUG 01-13 08:46:34.135925.135925 cuda_h.py:19] end load_into_gpu_async cost 0.0022554397583007812 seconds
DEBUG 01-13 08:46:34.135774.135774 cuda_h.py:10] start restore_tensors2
DEBUG 01-13 08:46:34.135840.135840 cuda_h.py:19] end restore_tensors2 cost 0.00037169456481933594 seconds
DEBUG 01-13 08:46:34.135570.135570 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.00458073616027832 seconds
DEBUG 01-13 08:46:34.135101.135101 cuda_h.py:10] start restore2model
DEBUG 01-13 08:46:34.138766.138766 cuda_h.py:19] end restore2model cost 0.0031960010528564453 seconds
DEBUG 01-13 08:46:34.139324.139324 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.007959604263305664 seconds
DEBUG 01-13 08:46:34.139166.139166 cuda_h.py:10] start gpu_sexperts
DEBUG 01-13 08:46:34.139415.139415 cuda_h.py:19] end gpu_sexperts cost 0.000293731689453125 seconds
DEBUG 01-13 08:46:34.139768.139768 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-13 08:46:34.139206.139206 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 1.430511474609375e-05 seconds
DEBUG 01-13 08:46:34.139617.139617 cuda_h.py:10] start wait_experts
INFO 01-13 08:46:34.139983.139983 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 668e96a5-8d2a-4f72-b72b-66956319178e
DEBUG 01-13 08:46:34.176380.176380 mlpmodule.py:1006] group tensors cost 0.010843515396118164 s
DEBUG 01-13 08:46:34.179393.179393 mlpmodule.py:1044] pad cost 0.002221345901489258 s
DEBUG 01-13 08:46:34.179266.179266 mlpmodule.py:1050] create cpu tensor cost 7.843971252441406e-05 s
DEBUG 01-13 08:46:34.179182.179182 mlpmodule.py:1055] move to cpu cost 4.124641418457031e-05 s
INFO 01-13 08:46:34.182932.182932 client.py:127] Model loaded
DEBUG 01-13 08:46:34.183781.183781 cuda_h.py:19] end wait_experts cost 0.04374408721923828 seconds
DEBUG 01-13 08:46:34.183932.183932 cuda_h.py:10] start gpu_experts
DEBUG 01-13 08:46:34.186826.186826 mlpmodule.py:559] gpu group tensors cost 0.0022063255310058594 s
DEBUG 01-13 08:46:34.187466.187466 mlpmodule.py:1069] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-13 08:46:34.187651.187651 mlpmodule.py:1070] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-13 08:46:34.188722.188722 mlpmodule.py:1075] group_w3 first element: 0.00066375732421875
WARNING 01-13 08:46:34.188032.188032 mlpmodule.py:1085] start einsum2
DEBUG 01-13 08:46:34.194456.194456 mlpmodule.py:592] gpu pad cost 0.007733583450317383 s
DEBUG 01-13 08:46:34.194571.194571 mlpmodule.py:598] start_w1
DEBUG 01-13 08:46:34.195025.195025 mlpmodule.py:602] start_w3
DEBUG 01-13 08:46:34.195492.195492 mlpmodule.py:608] start_w2
DEBUG 01-13 08:46:34.196804.196804 mlpmodule.py:611] gpu group einsum cost 0.002034902572631836 s
DEBUG 01-13 08:46:34.200037.200037 mlpmodule.py:1095] group einsum cost 0.020693540573120117 s
DEBUG 01-13 08:46:34.201884.201884 mlpmodule.py:1103] cpy2cputensor cost 0.0008876323699951172 s
DEBUG 01-13 08:46:34.201047.201047 mlpmodule.py:683] gpu experts func einsum cost 0.0180966854095459 s
DEBUG 01-13 08:46:34.202957.202957 cuda_h.py:19] end gpu_experts cost 0.01860189437866211 seconds
DEBUG 01-13 08:46:34.202449.202449 cuda_h.py:10] start cpu_thread_manager_mp_wait
DEBUG 01-13 08:46:34.207091.207091 cuda_h.py:19] end cpu_thread_manager_mp_wait cost 0.004720926284790039 seconds
DEBUG 01-13 08:46:34.207143.207143 cuda_h.py:19] end layer_moe_generate_mp_l_22 cost 0.07896924018859863 seconds
DEBUG 01-13 08:46:34.207949.207949 lmp.py:1550] -------------------------------- end prefill layer 21 --------------------------------
DEBUG 01-13 08:46:34.207917.207917 lmp.py:1493] -------------------------------- start prefill layer 22 --------------------------------
DEBUG 01-13 08:46:34.207064.207064 cuda_h.py:10] start start_load_qkvogn_s_weight_l_23
DEBUG 01-13 08:46:34.207218.207218 cuda_h.py:10] start start_load_qkvogn_s_weight_l_23
DEBUG 01-13 08:46:34.207757.207757 cuda_h.py:19] end start_load_qkvogn_s_weight_l_23 cost 4.1484832763671875e-05 seconds
DEBUG 01-13 08:46:34.207566.207566 cuda_h.py:19] end start_load_qkvogn_s_weight_l_23 cost 8.58306884765625e-05 seconds
DEBUG 01-13 08:46:34.207554.207554 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-13 08:46:34.207026.207026 cuda_h.py:10] start sllm_worker_task
DEBUG 01-13 08:46:34.207447.207447 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-13 08:46:34.208528.208528 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-13 08:46:34.208909.208909 cuda_h.py:19] end allocate_cuda_memory cost 0.00044798851013183594 seconds
DEBUG 01-13 08:46:34.208840.208840 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-13 08:46:34.208114.208114 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-13 08:46:34.208430.208430 sllm_store_c.py:27] get device uuid map
DEBUG 01-13 08:46:34.208888.208888 sllm_store_c.py:29] call client load into gpu
DEBUG 01-13 08:46:34.208221.208221 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, d9d62b43-576e-47e4-8070-c72bcc29cfd1
DEBUG 01-13 08:46:34.209331.209331 client.py:106] call stub.LoadModelAsync
DEBUG 01-13 08:46:34.209669.209669 cuda_h.py:10] start self_attn
INFO 01-13 08:46:34.210386.210386 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, d9d62b43-576e-47e4-8070-c72bcc29cfd1
DEBUG 01-13 08:46:34.210044.210044 cuda_h.py:19] end load_into_gpu_async cost 0.002140045166015625 seconds
DEBUG 01-13 08:46:34.211323.211323 cuda_h.py:10] start restore_tensors2
DEBUG 01-13 08:46:34.211625.211625 cuda_h.py:19] end restore_tensors2 cost 8.535385131835938e-05 seconds
DEBUG 01-13 08:46:34.211150.211150 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.003153562545776367 seconds
INFO 01-13 08:46:34.211185.211185 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, d9d62b43-576e-47e4-8070-c72bcc29cfd1
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-13 08:46:34.213917.213917 cuda_h.py:19] end self_attn cost 0.0039675235748291016 seconds
DEBUG 01-13 08:46:34.213785.213785 cuda_h.py:19] end iln_self_attn_paln cost 0.006067991256713867 seconds
DEBUG 01-13 08:46:34.213734.213734 cuda_h.py:10] start layer_moe_generate_mp_l_23
DEBUG 01-13 08:46:34.214696.214696 cuda_h.py:10] start gate
DEBUG 01-13 08:46:34.214395.214395 cuda_h.py:19] end gate cost 0.0008597373962402344 seconds
DEBUG 01-13 08:46:34.214523.214523 cuda_h.py:10] start experts_map_get
DEBUG 01-13 08:46:34.215079.215079 lmp.py:1611] 
DEBUG 01-13 08:46:34.215079.215079 lmp.py:1611] Expert Token Distribution & Device Allocation:
DEBUG 01-13 08:46:34.215034.215034 lmp.py:1612]   Total experts: 64
DEBUG 01-13 08:46:34.215074.215074 lmp.py:1613]   CPU experts: 32 (50%)
DEBUG 01-13 08:46:34.215777.215777 lmp.py:1614]   GPU experts: 32 (50%)
DEBUG 01-13 08:46:34.215096.215096 lmp.py:1615] 
DEBUG 01-13 08:46:34.215096.215096 lmp.py:1615]   Expert ID | Tokens | Device
DEBUG 01-13 08:46:34.215514.215514 lmp.py:1616]   -----------------------------------
DEBUG 01-13 08:46:34.215462.215462 lmp.py:1622]   Expert 25 |     16 | CPU
DEBUG 01-13 08:46:34.215781.215781 lmp.py:1622]   Expert 48 |     34 | CPU
DEBUG 01-13 08:46:34.215623.215623 lmp.py:1622]   Expert 45 |     38 | CPU
DEBUG 01-13 08:46:34.215465.215465 lmp.py:1622]   Expert  9 |     62 | CPU
DEBUG 01-13 08:46:34.215545.215545 lmp.py:1622]   Expert  0 |     84 | CPU
DEBUG 01-13 08:46:34.215102.215102 lmp.py:1622]   Expert 54 |     84 | CPU
DEBUG 01-13 08:46:34.215421.215421 lmp.py:1622]   Expert 57 |     84 | CPU
DEBUG 01-13 08:46:34.215739.215739 lmp.py:1622]   Expert 20 |     85 | CPU
DEBUG 01-13 08:46:34.215296.215296 lmp.py:1622]   Expert  6 |     86 | CPU
DEBUG 01-13 08:46:34.215900.215900 lmp.py:1622]   Expert 43 |     86 | CPU
DEBUG 01-13 08:46:34.215788.215788 lmp.py:1622]   Expert 47 |     87 | CPU
DEBUG 01-13 08:46:34.216153.216153 lmp.py:1622]   Expert 62 |     98 | CPU
DEBUG 01-13 08:46:34.216187.216187 lmp.py:1622]   Expert 36 |     99 | CPU
DEBUG 01-13 08:46:34.216261.216261 lmp.py:1622]   Expert 13 |    103 | CPU
DEBUG 01-13 08:46:34.216857.216857 lmp.py:1622]   Expert 46 |    106 | CPU
DEBUG 01-13 08:46:34.216408.216408 lmp.py:1622]   Expert 61 |    106 | CPU
DEBUG 01-13 08:46:34.216243.216243 lmp.py:1622]   Expert 50 |    108 | CPU
DEBUG 01-13 08:46:34.216316.216316 lmp.py:1622]   Expert 38 |    109 | CPU
DEBUG 01-13 08:46:34.216151.216151 lmp.py:1622]   Expert  1 |    110 | CPU
DEBUG 01-13 08:46:34.216748.216748 lmp.py:1622]   Expert 15 |    110 | CPU
DEBUG 01-13 08:46:34.216868.216868 lmp.py:1622]   Expert 37 |    111 | CPU
DEBUG 01-13 08:46:34.216749.216749 lmp.py:1622]   Expert 14 |    114 | CPU
DEBUG 01-13 08:46:34.216107.216107 lmp.py:1622]   Expert 21 |    133 | CPU
DEBUG 01-13 08:46:34.216227.216227 lmp.py:1622]   Expert 28 |    137 | CPU
DEBUG 01-13 08:46:34.216347.216347 lmp.py:1622]   Expert 44 |    141 | CPU
DEBUG 01-13 08:46:34.216467.216467 lmp.py:1622]   Expert 52 |    142 | CPU
DEBUG 01-13 08:46:34.216586.216586 lmp.py:1622]   Expert  7 |    145 | CPU
DEBUG 01-13 08:46:34.216706.216706 lmp.py:1622]   Expert 10 |    148 | CPU
DEBUG 01-13 08:46:34.216210.216210 lmp.py:1622]   Expert 24 |    154 | CPU
DEBUG 01-13 08:46:34.216045.216045 lmp.py:1622]   Expert 26 |    162 | CPU
DEBUG 01-13 08:46:34.216119.216119 lmp.py:1622]   Expert 11 |    164 | CPU
DEBUG 01-13 08:46:34.216194.216194 lmp.py:1622]   Expert 42 |    165 | CPU
DEBUG 01-13 08:46:34.216552.216552 lmp.py:1622]   Expert  2 |    166 | GPU
DEBUG 01-13 08:46:34.216910.216910 lmp.py:1622]   Expert 31 |    172 | GPU
DEBUG 01-13 08:46:34.216791.216791 lmp.py:1622]   Expert 35 |    172 | GPU
DEBUG 01-13 08:46:34.216911.216911 lmp.py:1622]   Expert 32 |    178 | GPU
DEBUG 01-13 08:46:34.216031.216031 lmp.py:1622]   Expert 19 |    182 | GPU
DEBUG 01-13 08:46:34.216151.216151 lmp.py:1622]   Expert  3 |    186 | GPU
DEBUG 01-13 08:46:34.216509.216509 lmp.py:1622]   Expert 12 |    193 | GPU
DEBUG 01-13 08:46:34.216344.216344 lmp.py:1622]   Expert 60 |    207 | GPU
DEBUG 01-13 08:46:34.216179.216179 lmp.py:1622]   Expert 56 |    211 | GPU
DEBUG 01-13 08:46:34.216253.216253 lmp.py:1622]   Expert 40 |    214 | GPU
DEBUG 01-13 08:46:34.216611.216611 lmp.py:1622]   Expert 41 |    218 | GPU
DEBUG 01-13 08:46:34.216969.216969 lmp.py:1622]   Expert 23 |    233 | GPU
DEBUG 01-13 08:46:34.216851.216851 lmp.py:1622]   Expert 58 |    233 | GPU
DEBUG 01-13 08:46:34.216732.216732 lmp.py:1622]   Expert 16 |    234 | GPU
DEBUG 01-13 08:46:34.216613.216613 lmp.py:1622]   Expert  8 |    237 | GPU
DEBUG 01-13 08:46:34.216256.216256 lmp.py:1622]   Expert 51 |    237 | GPU
DEBUG 01-13 08:46:34.216138.216138 lmp.py:1622]   Expert 53 |    238 | GPU
DEBUG 01-13 08:46:34.216781.216781 lmp.py:1622]   Expert 59 |    241 | GPU
DEBUG 01-13 08:46:34.216900.216900 lmp.py:1622]   Expert  4 |    248 | GPU
DEBUG 01-13 08:46:34.216451.216451 lmp.py:1622]   Expert 49 |    272 | GPU
DEBUG 01-13 08:46:34.216955.216955 lmp.py:1622]   Expert 55 |    277 | GPU
DEBUG 01-13 08:46:34.216505.216505 lmp.py:1622]   Expert 29 |    282 | GPU
DEBUG 01-13 08:46:34.216055.216055 lmp.py:1622]   Expert 18 |    290 | GPU
DEBUG 01-13 08:46:34.216559.216559 lmp.py:1622]   Expert 63 |    290 | GPU
DEBUG 01-13 08:46:34.216871.216871 lmp.py:1622]   Expert 34 |    294 | GPU
DEBUG 01-13 08:46:34.216706.216706 lmp.py:1622]   Expert 27 |    356 | GPU
DEBUG 01-13 08:46:34.216210.216210 lmp.py:1622]   Expert 39 |    376 | GPU
DEBUG 01-13 08:46:34.216953.216953 lmp.py:1622]   Expert 17 |    389 | GPU
DEBUG 01-13 08:46:34.216695.216695 lmp.py:1622]   Expert 22 |    433 | GPU
DEBUG 01-13 08:46:34.217213.217213 lmp.py:1622]   Expert 30 |    447 | GPU
DEBUG 01-13 08:46:34.217809.217809 lmp.py:1622]   Expert 33 |    460 | GPU
DEBUG 01-13 08:46:34.217645.217645 lmp.py:1622]   Expert  5 |    711 | GPU
DEBUG 01-13 08:46:34.217433.217433 lmp.py:1623] 
DEBUG 01-13 08:46:34.217433.217433 lmp.py:1623]   CPU total tokens: 3411 (27.8%)
DEBUG 01-13 08:46:34.217937.217937 lmp.py:1624]   GPU total tokens: 8877 (72.2%)
DEBUG 01-13 08:46:34.217448.217448 cuda_h.py:19] end experts_map_get cost 0.002086639404296875 seconds
DEBUG 01-13 08:46:34.217418.217418 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-13 08:46:34.217174.217174 lmp.py:1632] 
DEBUG 01-13 08:46:34.217174.217174 lmp.py:1632]   Computing 32 experts on CPU MP...
DEBUG 01-13 08:46:34.217626.217626 cuda_h.py:19] end cpu_experts_submit cost 5.1975250244140625e-05 seconds
DEBUG 01-13 08:46:34.217944.217944 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-13 08:46:34.217304.217304 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-13 08:46:34.217700.217700 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-13 08:46:34.218612.218612 cuda_h.py:19] end allocate_cuda_memory cost 0.0009164810180664062 seconds
DEBUG 01-13 08:46:34.218965.218965 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-13 08:46:34.218973.218973 sllm_store_c.py:27] get device uuid map
DEBUG 01-13 08:46:34.218981.218981 sllm_store_c.py:29] call client load into gpu
DEBUG 01-13 08:46:34.219015.219015 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 3c565dba-e1e5-4c1a-9afc-741fad401987
DEBUG 01-13 08:46:34.222301.222301 mlpmodule.py:785]  experts func einsum cost 0.0572047233581543 s
DEBUG 01-13 08:46:34.222051.222051 cuda_h.py:19] end experts_func_gpu_einsum_mp cost 0.08846402168273926 seconds
DEBUG 01-13 08:46:34.223217.223217 cuda_h.py:10] start experts_func_gpu_einsum_mp
INFO 01-13 08:46:34.231651.231651 client.py:127] Model loaded
DEBUG 01-13 08:46:34.232497.232497 cuda_h.py:10] start restore2model
DEBUG 01-13 08:46:34.231006.231006 client.py:106] call stub.LoadModelAsync
DEBUG 01-13 08:46:34.232100.232100 cuda_h.py:19] end restore2model cost 0.0005335807800292969 seconds
DEBUG 01-13 08:46:34.232128.232128 cuda_h.py:19] end sllm_worker_task cost 0.0247042179107666 seconds
DEBUG 01-13 08:46:34.232299.232299 mlpmodule.py:1006] group tensors cost 0.008071660995483398 s
INFO 01-13 08:46:34.234701.234701 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 3c565dba-e1e5-4c1a-9afc-741fad401987
DEBUG 01-13 08:46:34.234167.234167 cuda_h.py:19] end load_into_gpu_async cost 0.015480756759643555 seconds
DEBUG 01-13 08:46:34.234108.234108 cuda_h.py:10] start restore_tensors2
DEBUG 01-13 08:46:34.234581.234581 mlpmodule.py:1044] pad cost 0.001956462860107422 s
DEBUG 01-13 08:46:34.234777.234777 mlpmodule.py:1050] create cpu tensor cost 5.054473876953125e-05 s
DEBUG 01-13 08:46:34.234545.234545 cuda_h.py:19] end restore_tensors2 cost 0.00036597251892089844 seconds
DEBUG 01-13 08:46:34.234083.234083 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.01750802993774414 seconds
DEBUG 01-13 08:46:34.234879.234879 mlpmodule.py:1055] move to cpu cost 4.00543212890625e-05 s
DEBUG 01-13 08:46:34.234853.234853 cuda_h.py:10] start restore2model
DEBUG 01-13 08:46:34.242284.242284 cuda_h.py:19] end restore2model cost 0.007470846176147461 seconds
DEBUG 01-13 08:46:34.242681.242681 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.025334596633911133 seconds
DEBUG 01-13 08:46:34.242060.242060 cuda_h.py:10] start gpu_sexperts
DEBUG 01-13 08:46:34.243070.243070 mlpmodule.py:1069] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-13 08:46:34.243281.243281 cuda_h.py:19] end gpu_sexperts cost 0.0008161067962646484 seconds
DEBUG 01-13 08:46:34.243170.243170 mlpmodule.py:1070] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-13 08:46:34.243827.243827 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-13 08:46:34.243028.243028 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 3.0517578125e-05 seconds
DEBUG 01-13 08:46:34.243294.243294 mlpmodule.py:1075] group_w3 first element: -0.018798828125
DEBUG 01-13 08:46:34.243930.243930 cuda_h.py:10] start wait_experts
INFO 01-13 08:46:34.243315.243315 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 3c565dba-e1e5-4c1a-9afc-741fad401987
WARNING 01-13 08:46:34.243624.243624 mlpmodule.py:1085] start einsum2
DEBUG 01-13 08:46:34.258934.258934 mlpmodule.py:1095] group einsum cost 0.023717403411865234 s
DEBUG 01-13 08:46:34.259381.259381 mlpmodule.py:1103] cpy2cputensor cost 0.0006461143493652344 s
DEBUG 01-13 08:46:34.273835.273835 mlpmodule.py:785]  experts func einsum cost 0.04921436309814453 s
DEBUG 01-13 08:46:34.274618.274618 cuda_h.py:19] end experts_func_gpu_einsum_mp cost 0.050295352935791016 seconds
INFO 01-13 08:46:34.287995.287995 client.py:127] Model loaded
DEBUG 01-13 08:46:34.287109.287109 cuda_h.py:19] end wait_experts cost 0.04405379295349121 seconds
DEBUG 01-13 08:46:34.288159.288159 cuda_h.py:10] start gpu_experts
DEBUG 01-13 08:46:34.289411.289411 mlpmodule.py:559] gpu group tensors cost 0.0015530586242675781 s
DEBUG 01-13 08:46:34.295795.295795 mlpmodule.py:592] gpu pad cost 0.0057811737060546875 s
DEBUG 01-13 08:46:34.295144.295144 mlpmodule.py:598] start_w1
DEBUG 01-13 08:46:34.296853.296853 mlpmodule.py:602] start_w3
DEBUG 01-13 08:46:34.297177.297177 mlpmodule.py:608] start_w2
DEBUG 01-13 08:46:34.297688.297688 mlpmodule.py:611] gpu group einsum cost 0.0014300346374511719 s
DEBUG 01-13 08:46:34.301278.301278 mlpmodule.py:683] gpu experts func einsum cost 0.013618946075439453 s
DEBUG 01-13 08:46:34.301640.301640 cuda_h.py:19] end gpu_experts cost 0.013866424560546875 seconds
DEBUG 01-13 08:46:34.301654.301654 cuda_h.py:10] start cpu_thread_manager_mp_wait
DEBUG 01-13 08:46:34.302075.302075 cuda_h.py:19] end cpu_thread_manager_mp_wait cost 4.673004150390625e-05 seconds
DEBUG 01-13 08:46:34.302364.302364 cuda_h.py:19] end layer_moe_generate_mp_l_23 cost 0.08820533752441406 seconds
DEBUG 01-13 08:46:34.302900.302900 lmp.py:1550] -------------------------------- end prefill layer 22 --------------------------------
DEBUG 01-13 08:46:34.302935.302935 lmp.py:1493] -------------------------------- start prefill layer 23 --------------------------------
DEBUG 01-13 08:46:34.302989.302989 cuda_h.py:10] start start_load_qkvogn_s_weight_l_24
DEBUG 01-13 08:46:34.302050.302050 cuda_h.py:10] start start_load_qkvogn_s_weight_l_24
DEBUG 01-13 08:46:34.302589.302589 cuda_h.py:19] end start_load_qkvogn_s_weight_l_24 cost 4.0531158447265625e-05 seconds
DEBUG 01-13 08:46:34.302505.302505 cuda_h.py:19] end start_load_qkvogn_s_weight_l_24 cost 8.749961853027344e-05 seconds
DEBUG 01-13 08:46:34.302819.302819 cuda_h.py:10] start sllm_worker_task
DEBUG 01-13 08:46:34.303365.303365 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-13 08:46:34.303966.303966 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-13 08:46:34.303490.303490 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-13 08:46:34.303341.303341 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-13 08:46:34.304775.304775 cuda_h.py:19] end allocate_cuda_memory cost 0.0005116462707519531 seconds
DEBUG 01-13 08:46:34.304862.304862 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-13 08:46:34.304879.304879 sllm_store_c.py:27] get device uuid map
DEBUG 01-13 08:46:34.304182.304182 sllm_store_c.py:29] call client load into gpu
DEBUG 01-13 08:46:34.304165.304165 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, eeaf0c73-1afc-47cf-a448-83900c2f9a32
DEBUG 01-13 08:46:34.305504.305504 client.py:106] call stub.LoadModelAsync
DEBUG 01-13 08:46:34.305938.305938 cuda_h.py:10] start self_attn
INFO 01-13 08:46:34.306514.306514 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, eeaf0c73-1afc-47cf-a448-83900c2f9a32
DEBUG 01-13 08:46:34.307102.307102 cuda_h.py:19] end load_into_gpu_async cost 0.0025136470794677734 seconds
DEBUG 01-13 08:46:34.307542.307542 cuda_h.py:10] start restore_tensors2
DEBUG 01-13 08:46:34.307206.307206 cuda_h.py:19] end restore_tensors2 cost 0.00015044212341308594 seconds
DEBUG 01-13 08:46:34.307163.307163 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.004023075103759766 seconds
INFO 01-13 08:46:34.307214.307214 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, eeaf0c73-1afc-47cf-a448-83900c2f9a32
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-13 08:46:34.309194.309194 cuda_h.py:19] end self_attn cost 0.00438690185546875 seconds
DEBUG 01-13 08:46:34.310993.310993 cuda_h.py:19] end iln_self_attn_paln cost 0.006849765777587891 seconds
DEBUG 01-13 08:46:34.310313.310313 cuda_h.py:10] start layer_moe_generate_mp_l_24
DEBUG 01-13 08:46:34.310791.310791 cuda_h.py:10] start gate
DEBUG 01-13 08:46:34.311075.311075 cuda_h.py:19] end gate cost 0.0007350444793701172 seconds
DEBUG 01-13 08:46:34.311051.311051 cuda_h.py:10] start experts_map_get
DEBUG 01-13 08:46:34.311258.311258 lmp.py:1611] 
DEBUG 01-13 08:46:34.311258.311258 lmp.py:1611] Expert Token Distribution & Device Allocation:
DEBUG 01-13 08:46:34.311352.311352 lmp.py:1612]   Total experts: 64
DEBUG 01-13 08:46:34.311486.311486 lmp.py:1613]   CPU experts: 32 (50%)
DEBUG 01-13 08:46:34.311374.311374 lmp.py:1614]   GPU experts: 32 (50%)
DEBUG 01-13 08:46:34.311878.311878 lmp.py:1615] 
DEBUG 01-13 08:46:34.311878.311878 lmp.py:1615]   Expert ID | Tokens | Device
DEBUG 01-13 08:46:34.311336.311336 lmp.py:1616]   -----------------------------------
DEBUG 01-13 08:46:34.311085.311085 lmp.py:1622]   Expert  5 |     12 | CPU
DEBUG 01-13 08:46:34.311304.311304 lmp.py:1622]   Expert 56 |     36 | CPU
DEBUG 01-13 08:46:34.311331.311331 lmp.py:1622]   Expert 27 |     71 | CPU
DEBUG 01-13 08:46:34.311882.311882 lmp.py:1622]   Expert 16 |     87 | CPU
DEBUG 01-13 08:46:34.311478.311478 lmp.py:1622]   Expert 40 |     90 | CPU
DEBUG 01-13 08:46:34.311313.311313 lmp.py:1622]   Expert 17 |     92 | CPU
DEBUG 01-13 08:46:34.311625.311625 lmp.py:1622]   Expert 53 |     94 | CPU
DEBUG 01-13 08:46:34.311937.311937 lmp.py:1622]   Expert 51 |     97 | CPU
DEBUG 01-13 08:46:34.311772.311772 lmp.py:1622]   Expert 63 |    100 | CPU
DEBUG 01-13 08:46:34.311084.311084 lmp.py:1622]   Expert 49 |    102 | CPU
DEBUG 01-13 08:46:34.311588.311588 lmp.py:1622]   Expert 28 |    104 | CPU
DEBUG 01-13 08:46:34.311615.311615 lmp.py:1622]   Expert  7 |    107 | CPU
DEBUG 01-13 08:46:34.311642.311642 lmp.py:1622]   Expert 37 |    120 | CPU
DEBUG 01-13 08:46:34.311954.311954 lmp.py:1622]   Expert 58 |    123 | CPU
DEBUG 01-13 08:46:34.311789.311789 lmp.py:1622]   Expert 47 |    124 | CPU
DEBUG 01-13 08:46:34.311101.311101 lmp.py:1622]   Expert 11 |    125 | CPU
DEBUG 01-13 08:46:34.311413.311413 lmp.py:1622]   Expert 38 |    125 | CPU
DEBUG 01-13 08:46:34.312725.312725 lmp.py:1622]   Expert 62 |    134 | CPU
DEBUG 01-13 08:46:34.312799.312799 lmp.py:1622]   Expert 57 |    137 | CPU
DEBUG 01-13 08:46:34.312110.312110 lmp.py:1622]   Expert 14 |    144 | CPU
DEBUG 01-13 08:46:34.312184.312184 lmp.py:1622]   Expert 39 |    145 | CPU
DEBUG 01-13 08:46:34.312496.312496 lmp.py:1622]   Expert  1 |    149 | CPU
DEBUG 01-13 08:46:34.312569.312569 lmp.py:1622]   Expert 52 |    150 | CPU
DEBUG 01-13 08:46:34.312835.312835 lmp.py:1622]   Expert 25 |    152 | CPU
DEBUG 01-13 08:46:34.312100.312100 lmp.py:1622]   Expert 23 |    163 | CPU
DEBUG 01-13 08:46:34.312604.312604 lmp.py:1622]   Expert 60 |    165 | CPU
DEBUG 01-13 08:46:34.312678.312678 lmp.py:1622]   Expert 33 |    166 | CPU
DEBUG 01-13 08:46:34.312751.312751 lmp.py:1622]   Expert  6 |    169 | CPU
DEBUG 01-13 08:46:34.312587.312587 lmp.py:1622]   Expert 21 |    173 | CPU
DEBUG 01-13 08:46:34.312898.312898 lmp.py:1622]   Expert 45 |    177 | CPU
DEBUG 01-13 08:46:34.312733.312733 lmp.py:1622]   Expert 19 |    181 | CPU
DEBUG 01-13 08:46:34.312045.312045 lmp.py:1622]   Expert  4 |    183 | CPU
DEBUG 01-13 08:46:34.312119.312119 lmp.py:1622]   Expert 30 |    183 | GPU
DEBUG 01-13 08:46:34.312192.312192 lmp.py:1622]   Expert  3 |    188 | GPU
DEBUG 01-13 08:46:34.312027.312027 lmp.py:1622]   Expert 31 |    191 | GPU
DEBUG 01-13 08:46:34.312339.312339 lmp.py:1622]   Expert 12 |    192 | GPU
DEBUG 01-13 08:46:34.312281.312281 lmp.py:1622]   Expert 44 |    193 | GPU
DEBUG 01-13 08:46:34.312069.312069 lmp.py:1622]   Expert 55 |    199 | GPU
DEBUG 01-13 08:46:34.312143.312143 lmp.py:1622]   Expert 36 |    200 | GPU
DEBUG 01-13 08:46:34.312216.312216 lmp.py:1622]   Expert  9 |    216 | GPU
DEBUG 01-13 08:46:34.312290.312290 lmp.py:1622]   Expert 41 |    221 | GPU
DEBUG 01-13 08:46:34.312363.312363 lmp.py:1622]   Expert 34 |    227 | GPU
DEBUG 01-13 08:46:34.312914.312914 lmp.py:1622]   Expert 22 |    228 | GPU
DEBUG 01-13 08:46:34.312510.312510 lmp.py:1622]   Expert  0 |    230 | GPU
DEBUG 01-13 08:46:34.312107.312107 lmp.py:1622]   Expert 43 |    236 | GPU
DEBUG 01-13 08:46:34.312942.312942 lmp.py:1622]   Expert 26 |    239 | GPU
DEBUG 01-13 08:46:34.312446.312446 lmp.py:1622]   Expert 54 |    242 | GPU
DEBUG 01-13 08:46:34.312950.312950 lmp.py:1622]   Expert 18 |    253 | GPU
DEBUG 01-13 08:46:34.312838.312838 lmp.py:1622]   Expert 15 |    255 | GPU
DEBUG 01-13 08:46:34.312150.312150 lmp.py:1622]   Expert 50 |    255 | GPU
DEBUG 01-13 08:46:34.312985.312985 lmp.py:1622]   Expert 59 |    256 | GPU
DEBUG 01-13 08:46:34.312059.312059 lmp.py:1622]   Expert 13 |    258 | GPU
DEBUG 01-13 08:46:34.312894.312894 lmp.py:1622]   Expert 20 |    262 | GPU
DEBUG 01-13 08:46:34.312729.312729 lmp.py:1622]   Expert 24 |    267 | GPU
DEBUG 01-13 08:46:34.312325.312325 lmp.py:1622]   Expert 61 |    268 | GPU
DEBUG 01-13 08:46:34.312922.312922 lmp.py:1622]   Expert 42 |    269 | GPU
DEBUG 01-13 08:46:34.312949.312949 lmp.py:1622]   Expert 35 |    277 | GPU
DEBUG 01-13 08:46:34.312976.312976 lmp.py:1622]   Expert 29 |    278 | GPU
DEBUG 01-13 08:46:34.312911.312911 lmp.py:1622]   Expert 32 |    290 | GPU
DEBUG 01-13 08:46:34.312984.312984 lmp.py:1622]   Expert  2 |    331 | GPU
DEBUG 01-13 08:46:34.312819.312819 lmp.py:1622]   Expert  8 |    348 | GPU
DEBUG 01-13 08:46:34.312893.312893 lmp.py:1622]   Expert 10 |    359 | GPU
DEBUG 01-13 08:46:34.312728.312728 lmp.py:1622]   Expert 46 |    434 | GPU
DEBUG 01-13 08:46:34.312040.312040 lmp.py:1622]   Expert 48 |    446 | GPU
DEBUG 01-13 08:46:34.312305.312305 lmp.py:1623] 
DEBUG 01-13 08:46:34.312305.312305 lmp.py:1623]   CPU total tokens: 3997 (32.5%)
DEBUG 01-13 08:46:34.312856.312856 lmp.py:1624]   GPU total tokens: 8291 (67.5%)
DEBUG 01-13 08:46:34.312651.312651 cuda_h.py:19] end experts_map_get cost 0.0018875598907470703 seconds
DEBUG 01-13 08:46:34.313899.313899 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-13 08:46:34.313085.313085 lmp.py:1632] 
DEBUG 01-13 08:46:34.313085.313085 lmp.py:1632]   Computing 32 experts on CPU MP...
DEBUG 01-13 08:46:34.313107.313107 cuda_h.py:19] end cpu_experts_submit cost 5.078315734863281e-05 seconds
DEBUG 01-13 08:46:34.313611.313611 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-13 08:46:34.313441.313441 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-13 08:46:34.313711.313711 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-13 08:46:34.314241.314241 cuda_h.py:19] end allocate_cuda_memory cost 0.0007739067077636719 seconds
DEBUG 01-13 08:46:34.314383.314383 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-13 08:46:34.314477.314477 sllm_store_c.py:27] get device uuid map
DEBUG 01-13 08:46:34.314306.314306 sllm_store_c.py:29] call client load into gpu
DEBUG 01-13 08:46:34.314963.314963 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, ac7ad4d8-646c-4523-ac07-f1eb69cad434
DEBUG 01-13 08:46:34.314380.314380 client.py:106] call stub.LoadModelAsync
INFO 01-13 08:46:34.315064.315064 client.py:127] Model loaded
DEBUG 01-13 08:46:34.315817.315817 cuda_h.py:10] start restore2model
DEBUG 01-13 08:46:34.316861.316861 cuda_h.py:10] start experts_func_gpu_einsum_mp
DEBUG 01-13 08:46:34.316300.316300 cuda_h.py:19] end restore2model cost 0.001054525375366211 seconds
DEBUG 01-13 08:46:34.316125.316125 cuda_h.py:19] end sllm_worker_task cost 0.013653039932250977 seconds
INFO 01-13 08:46:34.316911.316911 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, ac7ad4d8-646c-4523-ac07-f1eb69cad434
DEBUG 01-13 08:46:34.317082.317082 cuda_h.py:19] end load_into_gpu_async cost 0.0028285980224609375 seconds
DEBUG 01-13 08:46:34.317222.317222 cuda_h.py:10] start restore_tensors2
DEBUG 01-13 08:46:34.317851.317851 cuda_h.py:19] end restore_tensors2 cost 0.00036406517028808594 seconds
DEBUG 01-13 08:46:34.317442.317442 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.004363536834716797 seconds
DEBUG 01-13 08:46:34.317450.317450 cuda_h.py:10] start restore2model
DEBUG 01-13 08:46:34.320373.320373 cuda_h.py:19] end restore2model cost 0.003210783004760742 seconds
DEBUG 01-13 08:46:34.320925.320925 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.007757425308227539 seconds
DEBUG 01-13 08:46:34.320151.320151 cuda_h.py:10] start gpu_sexperts
DEBUG 01-13 08:46:34.321182.321182 cuda_h.py:19] end gpu_sexperts cost 0.00030612945556640625 seconds
DEBUG 01-13 08:46:34.321634.321634 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-13 08:46:34.321271.321271 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 1.7642974853515625e-05 seconds
DEBUG 01-13 08:46:34.321921.321921 cuda_h.py:10] start wait_experts
INFO 01-13 08:46:34.321193.321193 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, ac7ad4d8-646c-4523-ac07-f1eb69cad434
DEBUG 01-13 08:46:34.328430.328430 mlpmodule.py:1006] group tensors cost 0.01038050651550293 s
DEBUG 01-13 08:46:34.330800.330800 mlpmodule.py:1044] pad cost 0.0017066001892089844 s
DEBUG 01-13 08:46:34.330029.330029 mlpmodule.py:1050] create cpu tensor cost 6.747245788574219e-05 s
DEBUG 01-13 08:46:34.331939.331939 mlpmodule.py:1055] move to cpu cost 3.600120544433594e-05 s
DEBUG 01-13 08:46:34.341598.341598 mlpmodule.py:1069] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-13 08:46:34.341484.341484 mlpmodule.py:1070] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-13 08:46:34.341150.341150 mlpmodule.py:1075] group_w3 first element: 0.08447265625
WARNING 01-13 08:46:34.341975.341975 mlpmodule.py:1085] start einsum2
DEBUG 01-13 08:46:34.356332.356332 mlpmodule.py:1095] group einsum cost 0.025311946868896484 s
DEBUG 01-13 08:46:34.357668.357668 mlpmodule.py:1103] cpy2cputensor cost 0.0007014274597167969 s
DEBUG 01-13 08:46:34.368695.368695 mlpmodule.py:785]  experts func einsum cost 0.04999232292175293 s
DEBUG 01-13 08:46:34.368762.368762 cuda_h.py:19] end experts_func_gpu_einsum_mp cost 0.051850080490112305 seconds
INFO 01-13 08:46:34.368702.368702 client.py:127] Model loaded
DEBUG 01-13 08:46:34.369609.369609 cuda_h.py:19] end wait_experts cost 0.04757976531982422 seconds
DEBUG 01-13 08:46:34.369186.369186 cuda_h.py:10] start gpu_experts
DEBUG 01-13 08:46:34.370561.370561 mlpmodule.py:559] gpu group tensors cost 0.0007894039154052734 s
DEBUG 01-13 08:46:34.372830.372830 mlpmodule.py:592] gpu pad cost 0.002232789993286133 s
DEBUG 01-13 08:46:34.372177.372177 mlpmodule.py:598] start_w1
DEBUG 01-13 08:46:34.372092.372092 mlpmodule.py:602] start_w3
DEBUG 01-13 08:46:34.373775.373775 mlpmodule.py:608] start_w2
DEBUG 01-13 08:46:34.373047.373047 mlpmodule.py:611] gpu group einsum cost 0.0008585453033447266 s
DEBUG 01-13 08:46:34.376197.376197 mlpmodule.py:683] gpu experts func einsum cost 0.006949663162231445 s
DEBUG 01-13 08:46:34.376896.376896 cuda_h.py:19] end gpu_experts cost 0.0071277618408203125 seconds
DEBUG 01-13 08:46:34.376745.376745 cuda_h.py:10] start cpu_thread_manager_mp_wait
DEBUG 01-13 08:46:34.376455.376455 cuda_h.py:19] end cpu_thread_manager_mp_wait cost 3.790855407714844e-05 seconds
DEBUG 01-13 08:46:34.376399.376399 cuda_h.py:19] end layer_moe_generate_mp_l_24 cost 0.06621646881103516 seconds
DEBUG 01-13 08:46:34.376416.376416 lmp.py:1550] -------------------------------- end prefill layer 23 --------------------------------
DEBUG 01-13 08:46:34.376609.376609 lmp.py:1493] -------------------------------- start prefill layer 24 --------------------------------
DEBUG 01-13 08:46:34.376120.376120 cuda_h.py:10] start start_load_qkvogn_s_weight_l_25
DEBUG 01-13 08:46:34.376591.376591 cuda_h.py:10] start start_load_qkvogn_s_weight_l_25
DEBUG 01-13 08:46:34.376003.376003 cuda_h.py:19] end start_load_qkvogn_s_weight_l_25 cost 3.24249267578125e-05 seconds
DEBUG 01-13 08:46:34.376230.376230 cuda_h.py:19] end start_load_qkvogn_s_weight_l_25 cost 6.198883056640625e-05 seconds
DEBUG 01-13 08:46:34.376231.376231 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-13 08:46:34.377835.377835 cuda_h.py:10] start sllm_worker_task
DEBUG 01-13 08:46:34.377335.377335 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-13 08:46:34.377164.377164 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-13 08:46:34.377303.377303 cuda_h.py:19] end allocate_cuda_memory cost 0.0003457069396972656 seconds
DEBUG 01-13 08:46:34.377439.377439 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-13 08:46:34.377414.377414 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-13 08:46:34.377173.377173 sllm_store_c.py:27] get device uuid map
DEBUG 01-13 08:46:34.377187.377187 sllm_store_c.py:29] call client load into gpu
DEBUG 01-13 08:46:34.377698.377698 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 7455e031-68ff-4222-ab8c-6dc5b190213a
DEBUG 01-13 08:46:34.377675.377675 client.py:106] call stub.LoadModelAsync
DEBUG 01-13 08:46:34.378296.378296 cuda_h.py:10] start self_attn
INFO 01-13 08:46:34.379311.379311 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 7455e031-68ff-4222-ab8c-6dc5b190213a
DEBUG 01-13 08:46:34.379353.379353 cuda_h.py:19] end load_into_gpu_async cost 0.001817464828491211 seconds
DEBUG 01-13 08:46:34.379791.379791 cuda_h.py:10] start restore_tensors2
DEBUG 01-13 08:46:34.379848.379848 cuda_h.py:19] end restore_tensors2 cost 7.963180541992188e-05 seconds
DEBUG 01-13 08:46:34.379485.379485 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.002678394317626953 seconds
INFO 01-13 08:46:34.379097.379097 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 7455e031-68ff-4222-ab8c-6dc5b190213a
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-13 08:46:34.381451.381451 cuda_h.py:19] end self_attn cost 0.0033860206604003906 seconds
DEBUG 01-13 08:46:34.382933.382933 cuda_h.py:19] end iln_self_attn_paln cost 0.005120754241943359 seconds
DEBUG 01-13 08:46:34.382876.382876 cuda_h.py:10] start layer_moe_generate_mp_l_25
DEBUG 01-13 08:46:34.382638.382638 cuda_h.py:10] start gate
DEBUG 01-13 08:46:34.382485.382485 cuda_h.py:19] end gate cost 0.000728607177734375 seconds
DEBUG 01-13 08:46:34.383745.383745 cuda_h.py:10] start experts_map_get
DEBUG 01-13 08:46:34.383689.383689 lmp.py:1611] 
DEBUG 01-13 08:46:34.383689.383689 lmp.py:1611] Expert Token Distribution & Device Allocation:
DEBUG 01-13 08:46:34.383829.383829 lmp.py:1612]   Total experts: 64
DEBUG 01-13 08:46:34.383578.383578 lmp.py:1613]   CPU experts: 32 (50%)
DEBUG 01-13 08:46:34.383320.383320 lmp.py:1614]   GPU experts: 32 (50%)
DEBUG 01-13 08:46:34.383632.383632 lmp.py:1615] 
DEBUG 01-13 08:46:34.383632.383632 lmp.py:1615]   Expert ID | Tokens | Device
DEBUG 01-13 08:46:34.383421.383421 lmp.py:1616]   -----------------------------------
DEBUG 01-13 08:46:34.383693.383693 lmp.py:1622]   Expert 36 |     26 | CPU
DEBUG 01-13 08:46:34.383482.383482 lmp.py:1622]   Expert 35 |     37 | CPU
DEBUG 01-13 08:46:34.383556.383556 lmp.py:1622]   Expert 46 |     40 | CPU
DEBUG 01-13 08:46:34.383391.383391 lmp.py:1622]   Expert 25 |     47 | CPU
DEBUG 01-13 08:46:34.383749.383749 lmp.py:1622]   Expert 51 |     50 | CPU
DEBUG 01-13 08:46:34.383107.383107 lmp.py:1622]   Expert 42 |     60 | CPU
DEBUG 01-13 08:46:34.383181.383181 lmp.py:1622]   Expert 16 |     61 | CPU
DEBUG 01-13 08:46:34.383539.383539 lmp.py:1622]   Expert  0 |     67 | CPU
DEBUG 01-13 08:46:34.383612.383612 lmp.py:1622]   Expert 43 |     67 | CPU
DEBUG 01-13 08:46:34.383163.383163 lmp.py:1622]   Expert 30 |     68 | CPU
DEBUG 01-13 08:46:34.383475.383475 lmp.py:1622]   Expert 44 |     68 | CPU
DEBUG 01-13 08:46:34.383310.383310 lmp.py:1622]   Expert 47 |     70 | CPU
DEBUG 01-13 08:46:34.383145.383145 lmp.py:1622]   Expert 39 |     73 | CPU
DEBUG 01-13 08:46:34.383503.383503 lmp.py:1622]   Expert 55 |     75 | CPU
DEBUG 01-13 08:46:34.383623.383623 lmp.py:1622]   Expert  2 |     80 | CPU
DEBUG 01-13 08:46:34.383743.383743 lmp.py:1622]   Expert  4 |    107 | CPU
DEBUG 01-13 08:46:34.383339.383339 lmp.py:1622]   Expert 48 |    108 | CPU
DEBUG 01-13 08:46:34.383459.383459 lmp.py:1622]   Expert  6 |    111 | CPU
DEBUG 01-13 08:46:34.383579.383579 lmp.py:1622]   Expert 33 |    125 | CPU
DEBUG 01-13 08:46:34.384937.384937 lmp.py:1622]   Expert 61 |    125 | CPU
DEBUG 01-13 08:46:34.384534.384534 lmp.py:1622]   Expert 24 |    127 | CPU
DEBUG 01-13 08:46:34.384892.384892 lmp.py:1622]   Expert  9 |    128 | CPU
DEBUG 01-13 08:46:34.384250.384250 lmp.py:1622]   Expert 54 |    131 | CPU
DEBUG 01-13 08:46:34.384039.384039 lmp.py:1622]   Expert 13 |    132 | CPU
DEBUG 01-13 08:46:34.384589.384589 lmp.py:1622]   Expert 38 |    134 | CPU
DEBUG 01-13 08:46:34.384663.384663 lmp.py:1622]   Expert 20 |    135 | CPU
DEBUG 01-13 08:46:34.384736.384736 lmp.py:1622]   Expert 56 |    136 | CPU
DEBUG 01-13 08:46:34.384094.384094 lmp.py:1622]   Expert 15 |    139 | CPU
DEBUG 01-13 08:46:34.384214.384214 lmp.py:1622]   Expert 29 |    145 | CPU
DEBUG 01-13 08:46:34.384811.384811 lmp.py:1622]   Expert  7 |    150 | CPU
DEBUG 01-13 08:46:34.384408.384408 lmp.py:1622]   Expert 59 |    151 | CPU
DEBUG 01-13 08:46:34.384527.384527 lmp.py:1622]   Expert 45 |    154 | CPU
DEBUG 01-13 08:46:34.384601.384601 lmp.py:1622]   Expert 62 |    160 | GPU
DEBUG 01-13 08:46:34.384721.384721 lmp.py:1622]   Expert 19 |    164 | GPU
DEBUG 01-13 08:46:34.384317.384317 lmp.py:1622]   Expert 34 |    182 | GPU
DEBUG 01-13 08:46:34.384391.384391 lmp.py:1622]   Expert 57 |    188 | GPU
DEBUG 01-13 08:46:34.384226.384226 lmp.py:1622]   Expert 10 |    196 | GPU
DEBUG 01-13 08:46:34.384061.384061 lmp.py:1622]   Expert 50 |    196 | GPU
DEBUG 01-13 08:46:34.384850.384850 lmp.py:1622]   Expert 53 |    206 | GPU
DEBUG 01-13 08:46:34.384029.384029 lmp.py:1622]   Expert 23 |    213 | GPU
DEBUG 01-13 08:46:34.384103.384103 lmp.py:1622]   Expert 22 |    217 | GPU
DEBUG 01-13 08:46:34.384461.384461 lmp.py:1622]   Expert  8 |    218 | GPU
DEBUG 01-13 08:46:34.384581.384581 lmp.py:1622]   Expert 31 |    222 | GPU
DEBUG 01-13 08:46:34.384178.384178 lmp.py:1622]   Expert 18 |    225 | GPU
DEBUG 01-13 08:46:34.384536.384536 lmp.py:1622]   Expert 52 |    225 | GPU
DEBUG 01-13 08:46:34.384132.384132 lmp.py:1622]   Expert 60 |    226 | GPU
DEBUG 01-13 08:46:34.384206.384206 lmp.py:1622]   Expert 37 |    230 | GPU
DEBUG 01-13 08:46:34.384803.384803 lmp.py:1622]   Expert 17 |    245 | GPU
DEBUG 01-13 08:46:34.384638.384638 lmp.py:1622]   Expert  5 |    248 | GPU
DEBUG 01-13 08:46:34.384426.384426 lmp.py:1622]   Expert 11 |    261 | GPU
DEBUG 01-13 08:46:34.384023.384023 lmp.py:1622]   Expert  1 |    275 | GPU
DEBUG 01-13 08:46:34.384620.384620 lmp.py:1622]   Expert 41 |    278 | GPU
DEBUG 01-13 08:46:34.384978.384978 lmp.py:1622]   Expert 49 |    279 | GPU
DEBUG 01-13 08:46:34.384098.384098 lmp.py:1622]   Expert 26 |    282 | GPU
DEBUG 01-13 08:46:34.384694.384694 lmp.py:1622]   Expert 28 |    288 | GPU
DEBUG 01-13 08:46:34.384053.384053 lmp.py:1622]   Expert 58 |    290 | GPU
DEBUG 01-13 08:46:34.384411.384411 lmp.py:1622]   Expert 40 |    298 | GPU
DEBUG 01-13 08:46:34.384736.384736 lmp.py:1622]   Expert 32 |    313 | GPU
DEBUG 01-13 08:46:34.384333.384333 lmp.py:1622]   Expert 14 |    319 | GPU
DEBUG 01-13 08:46:34.384691.384691 lmp.py:1622]   Expert 12 |    320 | GPU
DEBUG 01-13 08:46:34.384288.384288 lmp.py:1622]   Expert 63 |    332 | GPU
DEBUG 01-13 08:46:34.384408.384408 lmp.py:1622]   Expert 21 |    373 | GPU
DEBUG 01-13 08:46:34.384527.384527 lmp.py:1622]   Expert 27 |    676 | GPU
DEBUG 01-13 08:46:34.384170.384170 lmp.py:1622]   Expert  3 |   1016 | GPU
DEBUG 01-13 08:46:34.384767.384767 lmp.py:1623] 
DEBUG 01-13 08:46:34.384767.384767 lmp.py:1623]   CPU total tokens: 3127 (25.4%)
DEBUG 01-13 08:46:34.384602.384602 lmp.py:1624]   GPU total tokens: 9161 (74.6%)
DEBUG 01-13 08:46:34.384444.384444 cuda_h.py:19] end experts_map_get cost 0.0018548965454101562 seconds
DEBUG 01-13 08:46:34.384685.384685 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-13 08:46:34.385156.385156 lmp.py:1632] 
DEBUG 01-13 08:46:34.385156.385156 lmp.py:1632]   Computing 32 experts on CPU MP...
DEBUG 01-13 08:46:34.385893.385893 cuda_h.py:19] end cpu_experts_submit cost 5.173683166503906e-05 seconds
DEBUG 01-13 08:46:34.385397.385397 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-13 08:46:34.385703.385703 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-13 08:46:34.385974.385974 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-13 08:46:34.386893.386893 cuda_h.py:19] end allocate_cuda_memory cost 0.0015187263488769531 seconds
DEBUG 01-13 08:46:34.387383.387383 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-13 08:46:34.387915.387915 sllm_store_c.py:27] get device uuid map
DEBUG 01-13 08:46:34.387823.387823 sllm_store_c.py:29] call client load into gpu
DEBUG 01-13 08:46:34.387811.387811 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 90a552a5-03d1-4040-8bb1-ac8bae58957e
DEBUG 01-13 08:46:34.387552.387552 client.py:106] call stub.LoadModelAsync
INFO 01-13 08:46:34.387684.387684 client.py:127] Model loaded
DEBUG 01-13 08:46:34.387434.387434 cuda_h.py:10] start restore2model
DEBUG 01-13 08:46:34.388132.388132 cuda_h.py:19] end restore2model cost 0.0004374980926513672 seconds
DEBUG 01-13 08:46:34.388505.388505 cuda_h.py:19] end sllm_worker_task cost 0.011227130889892578 seconds
DEBUG 01-13 08:46:34.389739.389739 cuda_h.py:10] start experts_func_gpu_einsum_mp
INFO 01-13 08:46:34.389241.389241 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 90a552a5-03d1-4040-8bb1-ac8bae58957e
DEBUG 01-13 08:46:34.389614.389614 cuda_h.py:19] end load_into_gpu_async cost 0.002093791961669922 seconds
DEBUG 01-13 08:46:34.389317.389317 cuda_h.py:10] start restore_tensors2
DEBUG 01-13 08:46:34.389462.389462 cuda_h.py:19] end restore_tensors2 cost 0.0003616809844970703 seconds
DEBUG 01-13 08:46:34.389338.389338 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.004675388336181641 seconds
DEBUG 01-13 08:46:34.389624.389624 cuda_h.py:10] start restore2model
DEBUG 01-13 08:46:34.392492.392492 cuda_h.py:19] end restore2model cost 0.002964019775390625 seconds
DEBUG 01-13 08:46:34.392706.392706 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.007825136184692383 seconds
DEBUG 01-13 08:46:34.392309.392309 cuda_h.py:10] start gpu_sexperts
DEBUG 01-13 08:46:34.393056.393056 cuda_h.py:19] end gpu_sexperts cost 0.00030803680419921875 seconds
DEBUG 01-13 08:46:34.393793.393793 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-13 08:46:34.393854.393854 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 1.4781951904296875e-05 seconds
DEBUG 01-13 08:46:34.393550.393550 cuda_h.py:10] start wait_experts
INFO 01-13 08:46:34.393153.393153 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 90a552a5-03d1-4040-8bb1-ac8bae58957e
DEBUG 01-13 08:46:34.405134.405134 mlpmodule.py:1006] group tensors cost 0.014597892761230469 s
DEBUG 01-13 08:46:34.408147.408147 mlpmodule.py:1044] pad cost 0.0026688575744628906 s
DEBUG 01-13 08:46:34.408264.408264 mlpmodule.py:1050] create cpu tensor cost 5.817413330078125e-05 s
DEBUG 01-13 08:46:34.408604.408604 mlpmodule.py:1055] move to cpu cost 4.029273986816406e-05 s
DEBUG 01-13 08:46:34.419077.419077 mlpmodule.py:1069] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-13 08:46:34.419647.419647 mlpmodule.py:1070] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-13 08:46:34.419247.419247 mlpmodule.py:1075] group_w3 first element: 0.00653076171875
WARNING 01-13 08:46:34.419624.419624 mlpmodule.py:1085] start einsum2
DEBUG 01-13 08:46:34.434666.434666 mlpmodule.py:1095] group einsum cost 0.025902271270751953 s
DEBUG 01-13 08:46:34.435015.435015 mlpmodule.py:1103] cpy2cputensor cost 0.0006690025329589844 s
INFO 01-13 08:46:34.442907.442907 client.py:127] Model loaded
DEBUG 01-13 08:46:34.442926.442926 cuda_h.py:19] end wait_experts cost 0.04896664619445801 seconds
DEBUG 01-13 08:46:34.442457.442457 cuda_h.py:10] start gpu_experts
DEBUG 01-13 08:46:34.443422.443422 mlpmodule.py:559] gpu group tensors cost 0.00080108642578125 s
DEBUG 01-13 08:46:34.445595.445595 mlpmodule.py:592] gpu pad cost 0.0023355484008789062 s
DEBUG 01-13 08:46:34.445797.445797 mlpmodule.py:598] start_w1
DEBUG 01-13 08:46:34.446189.446189 mlpmodule.py:602] start_w3
DEBUG 01-13 08:46:34.446501.446501 mlpmodule.py:608] start_w2
DEBUG 01-13 08:46:34.446203.446203 mlpmodule.py:611] gpu group einsum cost 0.0008594989776611328 s
DEBUG 01-13 08:46:34.449523.449523 mlpmodule.py:785]  experts func einsum cost 0.05868959426879883 s
DEBUG 01-13 08:46:34.449322.449322 cuda_h.py:19] end experts_func_gpu_einsum_mp cost 0.06048083305358887 seconds
DEBUG 01-13 08:46:34.450285.450285 mlpmodule.py:683] gpu experts func einsum cost 0.007794857025146484 s
DEBUG 01-13 08:46:34.450435.450435 cuda_h.py:19] end gpu_experts cost 0.00798940658569336 seconds
DEBUG 01-13 08:46:34.450529.450529 cuda_h.py:10] start cpu_thread_manager_mp_wait
DEBUG 01-13 08:46:34.450147.450147 cuda_h.py:19] end cpu_thread_manager_mp_wait cost 3.7670135498046875e-05 seconds
DEBUG 01-13 08:46:34.450607.450607 cuda_h.py:19] end layer_moe_generate_mp_l_25 cost 0.06848406791687012 seconds
DEBUG 01-13 08:46:34.450954.450954 lmp.py:1550] -------------------------------- end prefill layer 24 --------------------------------
DEBUG 01-13 08:46:34.451386.451386 lmp.py:1493] -------------------------------- start prefill layer 25 --------------------------------
DEBUG 01-13 08:46:34.451043.451043 cuda_h.py:10] start start_load_qkvogn_s_weight_l_26
DEBUG 01-13 08:46:34.451991.451991 cuda_h.py:10] start start_load_qkvogn_s_weight_l_26
DEBUG 01-13 08:46:34.451503.451503 cuda_h.py:19] end start_load_qkvogn_s_weight_l_26 cost 3.361701965332031e-05 seconds
DEBUG 01-13 08:46:34.451723.451723 cuda_h.py:10] start sllm_worker_task
DEBUG 01-13 08:46:34.451175.451175 cuda_h.py:19] end start_load_qkvogn_s_weight_l_26 cost 0.0001437664031982422 seconds
DEBUG 01-13 08:46:34.451238.451238 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-13 08:46:34.451491.451491 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-13 08:46:34.451202.451202 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-13 08:46:34.451403.451403 cuda_h.py:19] end allocate_cuda_memory cost 0.00035309791564941406 seconds
DEBUG 01-13 08:46:34.452651.452651 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-13 08:46:34.452011.452011 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-13 08:46:34.452577.452577 sllm_store_c.py:27] get device uuid map
DEBUG 01-13 08:46:34.452221.452221 sllm_store_c.py:29] call client load into gpu
DEBUG 01-13 08:46:34.452832.452832 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, c634f011-ef4f-4074-a617-b3bb44a81f69
DEBUG 01-13 08:46:34.452378.452378 client.py:106] call stub.LoadModelAsync
DEBUG 01-13 08:46:34.452316.452316 cuda_h.py:10] start self_attn
INFO 01-13 08:46:34.453898.453898 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, c634f011-ef4f-4074-a617-b3bb44a81f69
DEBUG 01-13 08:46:34.453450.453450 cuda_h.py:19] end load_into_gpu_async cost 0.0017323493957519531 seconds
DEBUG 01-13 08:46:34.453768.453768 cuda_h.py:10] start restore_tensors2
DEBUG 01-13 08:46:34.454944.454944 cuda_h.py:19] end restore_tensors2 cost 6.890296936035156e-05 seconds
DEBUG 01-13 08:46:34.454269.454269 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.002638101577758789 seconds
INFO 01-13 08:46:34.454159.454159 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, c634f011-ef4f-4074-a617-b3bb44a81f69
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-13 08:46:34.456258.456258 cuda_h.py:19] end self_attn cost 0.0033321380615234375 seconds
DEBUG 01-13 08:46:34.456072.456072 cuda_h.py:19] end iln_self_attn_paln cost 0.004968404769897461 seconds
DEBUG 01-13 08:46:34.456776.456776 cuda_h.py:10] start layer_moe_generate_mp_l_26
DEBUG 01-13 08:46:34.456446.456446 cuda_h.py:10] start gate
DEBUG 01-13 08:46:34.457459.457459 cuda_h.py:19] end gate cost 0.0007448196411132812 seconds
DEBUG 01-13 08:46:34.457196.457196 cuda_h.py:10] start experts_map_get
DEBUG 01-13 08:46:34.457424.457424 lmp.py:1611] 
DEBUG 01-13 08:46:34.457424.457424 lmp.py:1611] Expert Token Distribution & Device Allocation:
DEBUG 01-13 08:46:34.457340.457340 lmp.py:1612]   Total experts: 64
DEBUG 01-13 08:46:34.457612.457612 lmp.py:1613]   CPU experts: 32 (50%)
DEBUG 01-13 08:46:34.457116.457116 lmp.py:1614]   GPU experts: 32 (50%)
DEBUG 01-13 08:46:34.458951.458951 lmp.py:1615] 
DEBUG 01-13 08:46:34.458951.458951 lmp.py:1615]   Expert ID | Tokens | Device
DEBUG 01-13 08:46:34.458786.458786 lmp.py:1616]   -----------------------------------
DEBUG 01-13 08:46:34.458105.458105 lmp.py:1622]   Expert 13 |     34 | CPU
DEBUG 01-13 08:46:34.458701.458701 lmp.py:1622]   Expert 44 |     41 | CPU
DEBUG 01-13 08:46:34.458344.458344 lmp.py:1622]   Expert 25 |     44 | CPU
DEBUG 01-13 08:46:34.458749.458749 lmp.py:1622]   Expert 38 |     44 | CPU
DEBUG 01-13 08:46:34.458392.458392 lmp.py:1622]   Expert  9 |     45 | CPU
DEBUG 01-13 08:46:34.458320.458320 lmp.py:1622]   Expert 22 |     47 | CPU
DEBUG 01-13 08:46:34.458486.458486 lmp.py:1622]   Expert 33 |     47 | CPU
DEBUG 01-13 08:46:34.458652.458652 lmp.py:1622]   Expert 16 |     52 | CPU
DEBUG 01-13 08:46:34.458580.458580 lmp.py:1622]   Expert  2 |     57 | CPU
DEBUG 01-13 08:46:34.458269.458269 lmp.py:1622]   Expert 42 |     62 | CPU
DEBUG 01-13 08:46:34.458627.458627 lmp.py:1622]   Expert 23 |     65 | CPU
DEBUG 01-13 08:46:34.458270.458270 lmp.py:1622]   Expert  5 |     67 | CPU
DEBUG 01-13 08:46:34.458675.458675 lmp.py:1622]   Expert 24 |     78 | CPU
DEBUG 01-13 08:46:34.458318.458318 lmp.py:1622]   Expert 10 |     81 | CPU
DEBUG 01-13 08:46:34.458722.458722 lmp.py:1622]   Expert 59 |     92 | CPU
DEBUG 01-13 08:46:34.458650.458650 lmp.py:1622]   Expert 55 |     99 | CPU
DEBUG 01-13 08:46:34.458578.458578 lmp.py:1622]   Expert 21 |    104 | CPU
DEBUG 01-13 08:46:34.458267.458267 lmp.py:1622]   Expert 46 |    112 | CPU
DEBUG 01-13 08:46:34.458956.458956 lmp.py:1622]   Expert 61 |    120 | CPU
DEBUG 01-13 08:46:34.458884.458884 lmp.py:1622]   Expert 31 |    124 | CPU
DEBUG 01-13 08:46:34.458573.458573 lmp.py:1622]   Expert 45 |    127 | CPU
DEBUG 01-13 08:46:34.458263.458263 lmp.py:1622]   Expert  6 |    141 | CPU
DEBUG 01-13 08:46:34.458190.458190 lmp.py:1622]   Expert  8 |    142 | CPU
DEBUG 01-13 08:46:34.458072.458072 lmp.py:1622]   Expert 36 |    142 | CPU
DEBUG 01-13 08:46:34.458191.458191 lmp.py:1622]   Expert 51 |    143 | CPU
DEBUG 01-13 08:46:34.458834.458834 lmp.py:1622]   Expert  0 |    152 | CPU
DEBUG 01-13 08:46:34.458239.458239 lmp.py:1622]   Expert 43 |    153 | CPU
DEBUG 01-13 08:46:34.458644.458644 lmp.py:1622]   Expert 26 |    157 | CPU
DEBUG 01-13 08:46:34.458810.458810 lmp.py:1622]   Expert  3 |    162 | CPU
DEBUG 01-13 08:46:34.458737.458737 lmp.py:1622]   Expert 18 |    164 | CPU
DEBUG 01-13 08:46:34.458904.458904 lmp.py:1622]   Expert 48 |    167 | CPU
DEBUG 01-13 08:46:34.458831.458831 lmp.py:1622]   Expert 41 |    172 | CPU
DEBUG 01-13 08:46:34.458521.458521 lmp.py:1622]   Expert  7 |    177 | GPU
DEBUG 01-13 08:46:34.458971.458971 lmp.py:1622]   Expert 12 |    179 | GPU
DEBUG 01-13 08:46:34.458899.458899 lmp.py:1622]   Expert 34 |    180 | GPU
DEBUG 01-13 08:46:34.458350.458350 lmp.py:1622]   Expert 20 |    182 | GPU
DEBUG 01-13 08:46:34.458755.458755 lmp.py:1622]   Expert 56 |    185 | GPU
DEBUG 01-13 08:46:34.458159.458159 lmp.py:1622]   Expert 27 |    192 | GPU
DEBUG 01-13 08:46:34.458325.458325 lmp.py:1622]   Expert 28 |    195 | GPU
DEBUG 01-13 08:46:34.458491.458491 lmp.py:1622]   Expert 47 |    197 | GPU
DEBUG 01-13 08:46:34.458658.458658 lmp.py:1622]   Expert  1 |    198 | GPU
DEBUG 01-13 08:46:34.458585.458585 lmp.py:1622]   Expert 11 |    218 | GPU
DEBUG 01-13 08:46:34.458751.458751 lmp.py:1622]   Expert 32 |    220 | GPU
DEBUG 01-13 08:46:34.458441.458441 lmp.py:1622]   Expert 53 |    230 | GPU
DEBUG 01-13 08:46:34.458759.458759 lmp.py:1622]   Expert 49 |    233 | GPU
DEBUG 01-13 08:46:34.458449.458449 lmp.py:1622]   Expert 63 |    233 | GPU
DEBUG 01-13 08:46:34.458376.458376 lmp.py:1622]   Expert 40 |    236 | GPU
DEBUG 01-13 08:46:34.458304.458304 lmp.py:1622]   Expert  4 |    242 | GPU
DEBUG 01-13 08:46:34.458232.458232 lmp.py:1622]   Expert 29 |    245 | GPU
DEBUG 01-13 08:46:34.458160.458160 lmp.py:1622]   Expert 15 |    246 | GPU
DEBUG 01-13 08:46:34.458564.458564 lmp.py:1622]   Expert 50 |    248 | GPU
DEBUG 01-13 08:46:34.458969.458969 lmp.py:1622]   Expert 30 |    249 | GPU
DEBUG 01-13 08:46:34.458373.458373 lmp.py:1622]   Expert 35 |    268 | GPU
DEBUG 01-13 08:46:34.458778.458778 lmp.py:1622]   Expert 14 |    272 | GPU
DEBUG 01-13 08:46:34.458659.458659 lmp.py:1622]   Expert 37 |    299 | GPU
DEBUG 01-13 08:46:34.459733.459733 lmp.py:1622]   Expert 52 |    332 | GPU
DEBUG 01-13 08:46:34.459614.459614 lmp.py:1622]   Expert 17 |    364 | GPU
DEBUG 01-13 08:46:34.459019.459019 lmp.py:1622]   Expert 54 |    376 | GPU
DEBUG 01-13 08:46:34.459900.459900 lmp.py:1622]   Expert 39 |    399 | GPU
DEBUG 01-13 08:46:34.459781.459781 lmp.py:1622]   Expert 57 |    410 | GPU
DEBUG 01-13 08:46:34.459424.459424 lmp.py:1622]   Expert 60 |    462 | GPU
DEBUG 01-13 08:46:34.459067.459067 lmp.py:1622]   Expert 62 |    466 | GPU
DEBUG 01-13 08:46:34.459949.459949 lmp.py:1622]   Expert 19 |    552 | GPU
DEBUG 01-13 08:46:34.459307.459307 lmp.py:1622]   Expert 58 |    566 | GPU
DEBUG 01-13 08:46:34.459619.459619 lmp.py:1623] 
DEBUG 01-13 08:46:34.459619.459619 lmp.py:1623]   CPU total tokens: 3237 (26.3%)
DEBUG 01-13 08:46:34.459408.459408 lmp.py:1624]   GPU total tokens: 9051 (73.7%)
DEBUG 01-13 08:46:34.459726.459726 cuda_h.py:19] end experts_map_get cost 0.0017638206481933594 seconds
DEBUG 01-13 08:46:34.459490.459490 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-13 08:46:34.459293.459293 lmp.py:1632] 
DEBUG 01-13 08:46:34.459293.459293 lmp.py:1632]   Computing 32 experts on CPU MP...
DEBUG 01-13 08:46:34.459169.459169 cuda_h.py:19] end cpu_experts_submit cost 4.887580871582031e-05 seconds
DEBUG 01-13 08:46:34.459341.459341 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-13 08:46:34.459509.459509 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-13 08:46:34.459733.459733 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-13 08:46:34.461696.461696 cuda_h.py:19] end allocate_cuda_memory cost 0.0014450550079345703 seconds
DEBUG 01-13 08:46:34.461692.461692 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-13 08:46:34.461309.461309 sllm_store_c.py:27] get device uuid map
DEBUG 01-13 08:46:34.461171.461171 sllm_store_c.py:29] call client load into gpu
DEBUG 01-13 08:46:34.461920.461920 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 4abd6d8d-803a-49c2-a664-827639560c22
DEBUG 01-13 08:46:34.461053.461053 client.py:106] call stub.LoadModelAsync
INFO 01-13 08:46:34.461322.461322 client.py:127] Model loaded
DEBUG 01-13 08:46:34.462357.462357 cuda_h.py:10] start restore2model
DEBUG 01-13 08:46:34.462373.462373 cuda_h.py:19] end restore2model cost 0.0004298686981201172 seconds
DEBUG 01-13 08:46:34.462918.462918 cuda_h.py:19] end sllm_worker_task cost 0.011221647262573242 seconds
DEBUG 01-13 08:46:34.462058.462058 cuda_h.py:10] start experts_func_gpu_einsum_mp
INFO 01-13 08:46:34.463669.463669 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 4abd6d8d-803a-49c2-a664-827639560c22
DEBUG 01-13 08:46:34.463472.463472 cuda_h.py:19] end load_into_gpu_async cost 0.002294301986694336 seconds
DEBUG 01-13 08:46:34.463036.463036 cuda_h.py:10] start restore_tensors2
DEBUG 01-13 08:46:34.463665.463665 cuda_h.py:19] end restore_tensors2 cost 0.0003650188446044922 seconds
DEBUG 01-13 08:46:34.463064.463064 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.00447535514831543 seconds
DEBUG 01-13 08:46:34.463118.463118 cuda_h.py:10] start restore2model
DEBUG 01-13 08:46:34.467090.467090 cuda_h.py:19] end restore2model cost 0.003072023391723633 seconds
DEBUG 01-13 08:46:34.467019.467019 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.007744550704956055 seconds
DEBUG 01-13 08:46:34.467550.467550 cuda_h.py:10] start gpu_sexperts
DEBUG 01-13 08:46:34.467296.467296 cuda_h.py:19] end gpu_sexperts cost 0.0003075599670410156 seconds
DEBUG 01-13 08:46:34.467033.467033 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-13 08:46:34.467286.467286 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 1.5020370483398438e-05 seconds
DEBUG 01-13 08:46:34.467698.467698 cuda_h.py:10] start wait_experts
INFO 01-13 08:46:34.467255.467255 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 4abd6d8d-803a-49c2-a664-827639560c22
DEBUG 01-13 08:46:34.481630.481630 mlpmodule.py:1006] group tensors cost 0.017676830291748047 s
DEBUG 01-13 08:46:34.484485.484485 mlpmodule.py:1044] pad cost 0.002771139144897461 s
DEBUG 01-13 08:46:34.484656.484656 mlpmodule.py:1050] create cpu tensor cost 6.532669067382812e-05 s
DEBUG 01-13 08:46:34.484328.484328 mlpmodule.py:1055] move to cpu cost 4.7206878662109375e-05 s
DEBUG 01-13 08:46:34.494494.494494 mlpmodule.py:1069] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-13 08:46:34.494045.494045 mlpmodule.py:1070] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-13 08:46:34.494997.494997 mlpmodule.py:1075] group_w3 first element: 0.007110595703125
WARNING 01-13 08:46:34.494194.494194 mlpmodule.py:1085] start einsum2
DEBUG 01-13 08:46:34.508064.508064 mlpmodule.py:1095] group einsum cost 0.023407697677612305 s
DEBUG 01-13 08:46:34.509698.509698 mlpmodule.py:1103] cpy2cputensor cost 0.0006995201110839844 s
INFO 01-13 08:46:34.515982.515982 client.py:127] Model loaded
DEBUG 01-13 08:46:34.515325.515325 cuda_h.py:19] end wait_experts cost 0.04816746711730957 seconds
DEBUG 01-13 08:46:34.515664.515664 cuda_h.py:10] start gpu_experts
DEBUG 01-13 08:46:34.516603.516603 mlpmodule.py:559] gpu group tensors cost 0.0008177757263183594 s
DEBUG 01-13 08:46:34.519914.519914 mlpmodule.py:592] gpu pad cost 0.002300262451171875 s
DEBUG 01-13 08:46:34.519109.519109 mlpmodule.py:598] start_w1
DEBUG 01-13 08:46:34.519978.519978 mlpmodule.py:602] start_w3
DEBUG 01-13 08:46:34.519442.519442 mlpmodule.py:608] start_w2
DEBUG 01-13 08:46:34.520297.520297 mlpmodule.py:611] gpu group einsum cost 0.000873565673828125 s
DEBUG 01-13 08:46:34.522855.522855 mlpmodule.py:785]  experts func einsum cost 0.059449195861816406 s
DEBUG 01-13 08:46:34.523648.523648 cuda_h.py:19] end experts_func_gpu_einsum_mp cost 0.060637474060058594 seconds
DEBUG 01-13 08:46:34.523571.523571 mlpmodule.py:683] gpu experts func einsum cost 0.007785320281982422 s
DEBUG 01-13 08:46:34.523158.523158 cuda_h.py:19] end gpu_experts cost 0.007985115051269531 seconds
DEBUG 01-13 08:46:34.523113.523113 cuda_h.py:10] start cpu_thread_manager_mp_wait
DEBUG 01-13 08:46:34.524321.524321 cuda_h.py:19] end cpu_thread_manager_mp_wait cost 4.5299530029296875e-05 seconds
DEBUG 01-13 08:46:34.524265.524265 cuda_h.py:19] end layer_moe_generate_mp_l_26 cost 0.0675668716430664 seconds
DEBUG 01-13 08:46:34.524904.524904 lmp.py:1550] -------------------------------- end prefill layer 25 --------------------------------
DEBUG 01-13 08:46:34.524766.524766 lmp.py:1493] -------------------------------- start prefill layer 26 --------------------------------
DEBUG 01-13 08:46:34.524423.524423 cuda_h.py:10] start start_load_qkvogn_s_weight_l_27
DEBUG 01-13 08:46:34.524848.524848 cuda_h.py:10] start start_load_qkvogn_s_weight_l_27
DEBUG 01-13 08:46:34.524167.524167 cuda_h.py:19] end start_load_qkvogn_s_weight_l_27 cost 3.266334533691406e-05 seconds
DEBUG 01-13 08:46:34.524818.524818 cuda_h.py:10] start sllm_worker_task
DEBUG 01-13 08:46:34.524363.524363 cuda_h.py:19] end start_load_qkvogn_s_weight_l_27 cost 0.00014162063598632812 seconds
DEBUG 01-13 08:46:34.524849.524849 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-13 08:46:34.524818.524818 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-13 08:46:34.524813.524813 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-13 08:46:34.525326.525326 cuda_h.py:19] end allocate_cuda_memory cost 0.00039267539978027344 seconds
DEBUG 01-13 08:46:34.525019.525019 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-13 08:46:34.525524.525524 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-13 08:46:34.525667.525667 sllm_store_c.py:27] get device uuid map
DEBUG 01-13 08:46:34.525265.525265 sllm_store_c.py:29] call client load into gpu
DEBUG 01-13 08:46:34.525683.525683 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 764585aa-668b-4dda-b360-59e91147fb05
DEBUG 01-13 08:46:34.525851.525851 client.py:106] call stub.LoadModelAsync
DEBUG 01-13 08:46:34.526451.526451 cuda_h.py:10] start self_attn
INFO 01-13 08:46:34.527455.527455 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 764585aa-668b-4dda-b360-59e91147fb05
DEBUG 01-13 08:46:34.527145.527145 cuda_h.py:19] end load_into_gpu_async cost 0.0018296241760253906 seconds
DEBUG 01-13 08:46:34.527961.527961 cuda_h.py:10] start restore_tensors2
DEBUG 01-13 08:46:34.527382.527382 cuda_h.py:19] end restore_tensors2 cost 7.295608520507812e-05 seconds
DEBUG 01-13 08:46:34.527707.527707 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.002789020538330078 seconds
INFO 01-13 08:46:34.527351.527351 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 764585aa-668b-4dda-b360-59e91147fb05
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-13 08:46:34.529189.529189 cuda_h.py:19] end self_attn cost 0.0033936500549316406 seconds
DEBUG 01-13 08:46:34.529148.529148 cuda_h.py:19] end iln_self_attn_paln cost 0.0050051212310791016 seconds
DEBUG 01-13 08:46:34.530945.530945 cuda_h.py:10] start layer_moe_generate_mp_l_27
DEBUG 01-13 08:46:34.530423.530423 cuda_h.py:10] start gate
DEBUG 01-13 08:46:34.530316.530316 cuda_h.py:19] end gate cost 0.0007278919219970703 seconds
DEBUG 01-13 08:46:34.530861.530861 cuda_h.py:10] start experts_map_get
DEBUG 01-13 08:46:34.531307.531307 lmp.py:1611] 
DEBUG 01-13 08:46:34.531307.531307 lmp.py:1611] Expert Token Distribution & Device Allocation:
DEBUG 01-13 08:46:34.531732.531732 lmp.py:1612]   Total experts: 64
DEBUG 01-13 08:46:34.531481.531481 lmp.py:1613]   CPU experts: 32 (50%)
DEBUG 01-13 08:46:34.531700.531700 lmp.py:1614]   GPU experts: 32 (50%)
DEBUG 01-13 08:46:34.531012.531012 lmp.py:1615] 
DEBUG 01-13 08:46:34.531012.531012 lmp.py:1615]   Expert ID | Tokens | Device
DEBUG 01-13 08:46:34.531516.531516 lmp.py:1616]   -----------------------------------
DEBUG 01-13 08:46:34.531550.531550 lmp.py:1622]   Expert 20 |     10 | CPU
DEBUG 01-13 08:46:34.531339.531339 lmp.py:1622]   Expert 61 |     10 | CPU
DEBUG 01-13 08:46:34.531697.531697 lmp.py:1622]   Expert 11 |     31 | CPU
DEBUG 01-13 08:46:34.531817.531817 lmp.py:1622]   Expert  3 |     32 | CPU
DEBUG 01-13 08:46:34.531414.531414 lmp.py:1622]   Expert  7 |     32 | CPU
DEBUG 01-13 08:46:34.531295.531295 lmp.py:1622]   Expert 51 |     40 | CPU
DEBUG 01-13 08:46:34.531415.531415 lmp.py:1622]   Expert 62 |     42 | CPU
DEBUG 01-13 08:46:34.531535.531535 lmp.py:1622]   Expert 30 |     46 | CPU
DEBUG 01-13 08:46:34.531416.531416 lmp.py:1622]   Expert 17 |     56 | CPU
DEBUG 01-13 08:46:34.531536.531536 lmp.py:1622]   Expert  6 |     61 | CPU
DEBUG 01-13 08:46:34.531417.531417 lmp.py:1622]   Expert 29 |     64 | CPU
DEBUG 01-13 08:46:34.531921.531921 lmp.py:1622]   Expert  9 |     67 | CPU
DEBUG 01-13 08:46:34.531564.531564 lmp.py:1622]   Expert 38 |     73 | CPU
DEBUG 01-13 08:46:34.531207.531207 lmp.py:1622]   Expert 63 |     74 | CPU
DEBUG 01-13 08:46:34.531612.531612 lmp.py:1622]   Expert 59 |     80 | CPU
DEBUG 01-13 08:46:34.531540.531540 lmp.py:1622]   Expert 55 |     82 | CPU
DEBUG 01-13 08:46:34.531467.531467 lmp.py:1622]   Expert 19 |     85 | CPU
DEBUG 01-13 08:46:34.531157.531157 lmp.py:1622]   Expert  8 |     96 | CPU
DEBUG 01-13 08:46:34.531323.531323 lmp.py:1622]   Expert 49 |    104 | CPU
DEBUG 01-13 08:46:34.531250.531250 lmp.py:1622]   Expert 34 |    108 | CPU
DEBUG 01-13 08:46:34.531178.531178 lmp.py:1622]   Expert 22 |    112 | CPU
DEBUG 01-13 08:46:34.531106.531106 lmp.py:1622]   Expert 48 |    112 | CPU
DEBUG 01-13 08:46:34.531795.531795 lmp.py:1622]   Expert 50 |    113 | CPU
DEBUG 01-13 08:46:34.531723.531723 lmp.py:1622]   Expert 42 |    117 | CPU
DEBUG 01-13 08:46:34.531651.531651 lmp.py:1622]   Expert 24 |    118 | CPU
DEBUG 01-13 08:46:34.531340.531340 lmp.py:1622]   Expert 36 |    119 | CPU
DEBUG 01-13 08:46:34.531268.531268 lmp.py:1622]   Expert  4 |    127 | CPU
DEBUG 01-13 08:46:34.531195.531195 lmp.py:1622]   Expert 39 |    128 | CPU
DEBUG 01-13 08:46:34.531361.531361 lmp.py:1622]   Expert 37 |    140 | CPU
DEBUG 01-13 08:46:34.531481.531481 lmp.py:1622]   Expert 15 |    143 | CPU
DEBUG 01-13 08:46:34.532886.532886 lmp.py:1622]   Expert 41 |    148 | CPU
DEBUG 01-13 08:46:34.532529.532529 lmp.py:1622]   Expert 23 |    155 | CPU
DEBUG 01-13 08:46:34.532695.532695 lmp.py:1622]   Expert 56 |    165 | GPU
DEBUG 01-13 08:46:34.532623.532623 lmp.py:1622]   Expert 16 |    168 | GPU
DEBUG 01-13 08:46:34.532550.532550 lmp.py:1622]   Expert  1 |    177 | GPU
DEBUG 01-13 08:46:34.532717.532717 lmp.py:1622]   Expert 43 |    179 | GPU
DEBUG 01-13 08:46:34.532644.532644 lmp.py:1622]   Expert 21 |    180 | GPU
DEBUG 01-13 08:46:34.532334.532334 lmp.py:1622]   Expert 44 |    181 | GPU
DEBUG 01-13 08:46:34.532261.532261 lmp.py:1622]   Expert 60 |    181 | GPU
DEBUG 01-13 08:46:34.532951.532951 lmp.py:1622]   Expert 53 |    187 | GPU
DEBUG 01-13 08:46:34.532878.532878 lmp.py:1622]   Expert 47 |    191 | GPU
DEBUG 01-13 08:46:34.532521.532521 lmp.py:1622]   Expert 12 |    194 | GPU
DEBUG 01-13 08:46:34.532164.532164 lmp.py:1622]   Expert 33 |    202 | GPU
DEBUG 01-13 08:46:34.532046.532046 lmp.py:1622]   Expert 13 |    213 | GPU
DEBUG 01-13 08:46:34.532165.532165 lmp.py:1622]   Expert 32 |    219 | GPU
DEBUG 01-13 08:46:34.532808.532808 lmp.py:1622]   Expert 28 |    229 | GPU
DEBUG 01-13 08:46:34.532975.532975 lmp.py:1622]   Expert  0 |    251 | GPU
DEBUG 01-13 08:46:34.532664.532664 lmp.py:1622]   Expert 31 |    258 | GPU
DEBUG 01-13 08:46:34.532353.532353 lmp.py:1622]   Expert 10 |    261 | GPU
DEBUG 01-13 08:46:34.532281.532281 lmp.py:1622]   Expert 54 |    261 | GPU
DEBUG 01-13 08:46:34.532970.532970 lmp.py:1622]   Expert 26 |    265 | GPU
DEBUG 01-13 08:46:34.532898.532898 lmp.py:1622]   Expert 18 |    269 | GPU
DEBUG 01-13 08:46:34.532079.532079 lmp.py:1622]   Expert 57 |    269 | GPU
DEBUG 01-13 08:46:34.532391.532391 lmp.py:1622]   Expert  2 |    288 | GPU
DEBUG 01-13 08:46:34.532034.532034 lmp.py:1622]   Expert 58 |    296 | GPU
DEBUG 01-13 08:46:34.532677.532677 lmp.py:1622]   Expert 40 |    339 | GPU
DEBUG 01-13 08:46:34.532843.532843 lmp.py:1622]   Expert 45 |    360 | GPU
DEBUG 01-13 08:46:34.532771.532771 lmp.py:1622]   Expert 25 |    371 | GPU
DEBUG 01-13 08:46:34.532937.532937 lmp.py:1622]   Expert  5 |    435 | GPU
DEBUG 01-13 08:46:34.532864.532864 lmp.py:1622]   Expert 35 |    459 | GPU
DEBUG 01-13 08:46:34.532315.532315 lmp.py:1622]   Expert 27 |    485 | GPU
DEBUG 01-13 08:46:34.532481.532481 lmp.py:1622]   Expert 46 |    540 | GPU
DEBUG 01-13 08:46:34.532409.532409 lmp.py:1622]   Expert 52 |    600 | GPU
DEBUG 01-13 08:46:34.532337.532337 lmp.py:1622]   Expert 14 |    890 | GPU
DEBUG 01-13 08:46:34.532887.532887 lmp.py:1623] 
DEBUG 01-13 08:46:34.532887.532887 lmp.py:1623]   CPU total tokens: 2725 (22.2%)
DEBUG 01-13 08:46:34.532722.532722 lmp.py:1624]   GPU total tokens: 9563 (77.8%)
DEBUG 01-13 08:46:34.532803.532803 cuda_h.py:19] end experts_map_get cost 0.0017871856689453125 seconds
DEBUG 01-13 08:46:34.532613.532613 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-13 08:46:34.532607.532607 lmp.py:1632] 
DEBUG 01-13 08:46:34.532607.532607 lmp.py:1632]   Computing 32 experts on CPU MP...
DEBUG 01-13 08:46:34.532536.532536 cuda_h.py:19] end cpu_experts_submit cost 5.2928924560546875e-05 seconds
DEBUG 01-13 08:46:34.532398.532398 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-13 08:46:34.533431.533431 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-13 08:46:34.533516.533516 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-13 08:46:34.534058.534058 cuda_h.py:19] end allocate_cuda_memory cost 0.0013098716735839844 seconds
DEBUG 01-13 08:46:34.534815.534815 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-13 08:46:34.534432.534432 sllm_store_c.py:27] get device uuid map
DEBUG 01-13 08:46:34.534102.534102 sllm_store_c.py:29] call client load into gpu
DEBUG 01-13 08:46:34.534851.534851 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 4abfd4e7-d12a-4bb2-8d85-b50faaa65e1d
DEBUG 01-13 08:46:34.535454.535454 client.py:106] call stub.LoadModelAsync
INFO 01-13 08:46:34.535946.535946 client.py:127] Model loaded
DEBUG 01-13 08:46:34.535014.535014 cuda_h.py:10] start restore2model
DEBUG 01-13 08:46:34.535262.535262 cuda_h.py:10] start experts_func_gpu_einsum_mp
DEBUG 01-13 08:46:34.535774.535774 cuda_h.py:19] end restore2model cost 0.00031948089599609375 seconds
DEBUG 01-13 08:46:34.536498.536498 cuda_h.py:19] end sllm_worker_task cost 0.011270523071289062 seconds
INFO 01-13 08:46:34.537070.537070 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 4abfd4e7-d12a-4bb2-8d85-b50faaa65e1d
DEBUG 01-13 08:46:34.537903.537903 cuda_h.py:19] end load_into_gpu_async cost 0.0025730133056640625 seconds
DEBUG 01-13 08:46:34.537926.537926 cuda_h.py:10] start restore_tensors2
DEBUG 01-13 08:46:34.538473.538473 cuda_h.py:19] end restore_tensors2 cost 0.0004391670227050781 seconds
DEBUG 01-13 08:46:34.538348.538348 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0048143863677978516 seconds
DEBUG 01-13 08:46:34.538734.538734 cuda_h.py:10] start restore2model
DEBUG 01-13 08:46:34.541075.541075 cuda_h.py:19] end restore2model cost 0.0030260086059570312 seconds
DEBUG 01-13 08:46:34.541527.541527 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.008039236068725586 seconds
DEBUG 01-13 08:46:34.541845.541845 cuda_h.py:10] start gpu_sexperts
DEBUG 01-13 08:46:34.541168.541168 cuda_h.py:19] end gpu_sexperts cost 0.0003120899200439453 seconds
DEBUG 01-13 08:46:34.541236.541236 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-13 08:46:34.541582.541582 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 1.5497207641601562e-05 seconds
DEBUG 01-13 08:46:34.541278.541278 cuda_h.py:10] start wait_experts
INFO 01-13 08:46:34.541266.541266 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 4abfd4e7-d12a-4bb2-8d85-b50faaa65e1d
DEBUG 01-13 08:46:34.550824.550824 mlpmodule.py:1006] group tensors cost 0.013666391372680664 s
DEBUG 01-13 08:46:34.553399.553399 mlpmodule.py:1044] pad cost 0.0021300315856933594 s
DEBUG 01-13 08:46:34.553562.553562 mlpmodule.py:1050] create cpu tensor cost 5.984306335449219e-05 s
DEBUG 01-13 08:46:34.553194.553194 mlpmodule.py:1055] move to cpu cost 4.291534423828125e-05 s
DEBUG 01-13 08:46:34.562409.562409 mlpmodule.py:1069] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-13 08:46:34.562202.562202 mlpmodule.py:1070] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-13 08:46:34.562100.562100 mlpmodule.py:1075] group_w3 first element: -0.0024261474609375
WARNING 01-13 08:46:34.563813.563813 mlpmodule.py:1085] start einsum2
DEBUG 01-13 08:46:34.578894.578894 mlpmodule.py:1095] group einsum cost 0.024763107299804688 s
DEBUG 01-13 08:46:34.579399.579399 mlpmodule.py:1103] cpy2cputensor cost 0.0006468296051025391 s
INFO 01-13 08:46:34.589277.589277 client.py:127] Model loaded
DEBUG 01-13 08:46:34.589674.589674 cuda_h.py:19] end wait_experts cost 0.04796099662780762 seconds
DEBUG 01-13 08:46:34.589126.589126 cuda_h.py:10] start gpu_experts
DEBUG 01-13 08:46:34.590269.590269 mlpmodule.py:559] gpu group tensors cost 0.0007925033569335938 s
DEBUG 01-13 08:46:34.591042.591042 mlpmodule.py:785]  experts func einsum cost 0.05425000190734863 s
DEBUG 01-13 08:46:34.591428.591428 cuda_h.py:19] end experts_func_gpu_einsum_mp cost 0.055748939514160156 seconds
DEBUG 01-13 08:46:34.593690.593690 mlpmodule.py:592] gpu pad cost 0.002412557601928711 s
DEBUG 01-13 08:46:34.593719.593719 mlpmodule.py:598] start_w1
DEBUG 01-13 08:46:34.593158.593158 mlpmodule.py:602] start_w3
DEBUG 01-13 08:46:34.593688.593688 mlpmodule.py:608] start_w2
DEBUG 01-13 08:46:34.594092.594092 mlpmodule.py:611] gpu group einsum cost 0.0008351802825927734 s
DEBUG 01-13 08:46:34.597651.597651 mlpmodule.py:683] gpu experts func einsum cost 0.007257699966430664 s
DEBUG 01-13 08:46:34.597965.597965 cuda_h.py:19] end gpu_experts cost 0.007433176040649414 seconds
DEBUG 01-13 08:46:34.597529.597529 cuda_h.py:10] start cpu_thread_manager_mp_wait
DEBUG 01-13 08:46:34.597525.597525 cuda_h.py:19] end cpu_thread_manager_mp_wait cost 3.719329833984375e-05 seconds
DEBUG 01-13 08:46:34.597024.597024 cuda_h.py:19] end layer_moe_generate_mp_l_27 cost 0.06740689277648926 seconds
DEBUG 01-13 08:46:34.597484.597484 lmp.py:1550] -------------------------------- end prefill layer 26 --------------------------------
DEBUG 01-13 08:46:34.597160.597160 lmp.py:1493] -------------------------------- start prefill layer 27 --------------------------------
DEBUG 01-13 08:46:34.597671.597671 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-13 08:46:34.597535.597535 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-13 08:46:34.598453.598453 cuda_h.py:10] start self_attn
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-13 08:46:34.601200.601200 cuda_h.py:19] end self_attn cost 0.002885580062866211 seconds
DEBUG 01-13 08:46:34.601304.601304 cuda_h.py:19] end iln_self_attn_paln cost 0.003630399703979492 seconds
DEBUG 01-13 08:46:34.601001.601001 cuda_h.py:10] start layer_moe_generate_mp_l_28
DEBUG 01-13 08:46:34.601287.601287 cuda_h.py:10] start gate
DEBUG 01-13 08:46:34.602920.602920 cuda_h.py:19] end gate cost 0.0006773471832275391 seconds
DEBUG 01-13 08:46:34.602750.602750 cuda_h.py:10] start experts_map_get
DEBUG 01-13 08:46:34.602930.602930 lmp.py:1611] 
DEBUG 01-13 08:46:34.602930.602930 lmp.py:1611] Expert Token Distribution & Device Allocation:
DEBUG 01-13 08:46:34.602494.602494 lmp.py:1612]   Total experts: 64
DEBUG 01-13 08:46:34.602382.602382 lmp.py:1613]   CPU experts: 32 (50%)
DEBUG 01-13 08:46:34.602456.602456 lmp.py:1614]   GPU experts: 32 (50%)
DEBUG 01-13 08:46:34.602337.602337 lmp.py:1615] 
DEBUG 01-13 08:46:34.602337.602337 lmp.py:1615]   Expert ID | Tokens | Device
DEBUG 01-13 08:46:34.602695.602695 lmp.py:1616]   -----------------------------------
DEBUG 01-13 08:46:34.602299.602299 lmp.py:1622]   Expert 18 |     64 | CPU
DEBUG 01-13 08:46:34.602180.602180 lmp.py:1622]   Expert 54 |     65 | CPU
DEBUG 01-13 08:46:34.602346.602346 lmp.py:1622]   Expert 47 |     68 | CPU
DEBUG 01-13 08:46:34.602274.602274 lmp.py:1622]   Expert 48 |     76 | CPU
DEBUG 01-13 08:46:34.602725.602725 lmp.py:1622]   Expert 23 |     80 | CPU
DEBUG 01-13 08:46:34.602414.602414 lmp.py:1622]   Expert 44 |     83 | CPU
DEBUG 01-13 08:46:34.602342.602342 lmp.py:1622]   Expert 45 |     83 | CPU
DEBUG 01-13 08:46:34.603031.603031 lmp.py:1622]   Expert 20 |     91 | CPU
DEBUG 01-13 08:46:34.603959.603959 lmp.py:1622]   Expert 31 |    105 | CPU
DEBUG 01-13 08:46:34.603648.603648 lmp.py:1622]   Expert 36 |    106 | CPU
DEBUG 01-13 08:46:34.603861.603861 lmp.py:1622]   Expert 61 |    111 | CPU
DEBUG 01-13 08:46:34.603312.603312 lmp.py:1622]   Expert 42 |    114 | CPU
DEBUG 01-13 08:46:34.603763.603763 lmp.py:1622]   Expert 33 |    120 | CPU
DEBUG 01-13 08:46:34.603929.603929 lmp.py:1622]   Expert 10 |    121 | CPU
DEBUG 01-13 08:46:34.603618.603618 lmp.py:1622]   Expert 11 |    126 | CPU
DEBUG 01-13 08:46:34.603784.603784 lmp.py:1622]   Expert 24 |    126 | CPU
DEBUG 01-13 08:46:34.603712.603712 lmp.py:1622]   Expert 43 |    127 | CPU
DEBUG 01-13 08:46:34.603163.603163 lmp.py:1622]   Expert 49 |    130 | CPU
DEBUG 01-13 08:46:34.603852.603852 lmp.py:1622]   Expert 56 |    130 | CPU
DEBUG 01-13 08:46:34.603303.603303 lmp.py:1622]   Expert  0 |    145 | CPU
DEBUG 01-13 08:46:34.603754.603754 lmp.py:1622]   Expert  6 |    145 | CPU
DEBUG 01-13 08:46:34.603205.603205 lmp.py:1622]   Expert 51 |    145 | CPU
DEBUG 01-13 08:46:34.603656.603656 lmp.py:1622]   Expert 17 |    150 | CPU
DEBUG 01-13 08:46:34.603868.603868 lmp.py:1622]   Expert  5 |    152 | CPU
DEBUG 01-13 08:46:34.603557.603557 lmp.py:1622]   Expert 40 |    155 | CPU
DEBUG 01-13 08:46:34.603770.603770 lmp.py:1622]   Expert 57 |    157 | CPU
DEBUG 01-13 08:46:34.603936.603936 lmp.py:1622]   Expert 12 |    158 | CPU
DEBUG 01-13 08:46:34.603864.603864 lmp.py:1622]   Expert 59 |    160 | CPU
DEBUG 01-13 08:46:34.603791.603791 lmp.py:1622]   Expert 55 |    162 | CPU
DEBUG 01-13 08:46:34.603481.603481 lmp.py:1622]   Expert 26 |    163 | CPU
DEBUG 01-13 08:46:34.603408.603408 lmp.py:1622]   Expert 13 |    167 | CPU
DEBUG 01-13 08:46:34.603859.603859 lmp.py:1622]   Expert 38 |    169 | CPU
DEBUG 01-13 08:46:34.603310.603310 lmp.py:1622]   Expert 35 |    172 | GPU
DEBUG 01-13 08:46:34.603284.603284 lmp.py:1622]   Expert 30 |    175 | GPU
DEBUG 01-13 08:46:34.603735.603735 lmp.py:1622]   Expert  7 |    177 | GPU
DEBUG 01-13 08:46:34.603186.603186 lmp.py:1622]   Expert 46 |    177 | GPU
DEBUG 01-13 08:46:34.603637.603637 lmp.py:1622]   Expert 58 |    177 | GPU
DEBUG 01-13 08:46:34.603611.603611 lmp.py:1622]   Expert 50 |    179 | GPU
DEBUG 01-13 08:46:34.603823.603823 lmp.py:1622]   Expert 16 |    186 | GPU
DEBUG 01-13 08:46:34.603751.603751 lmp.py:1622]   Expert 32 |    202 | GPU
DEBUG 01-13 08:46:34.603679.603679 lmp.py:1622]   Expert 15 |    204 | GPU
DEBUG 01-13 08:46:34.603083.603083 lmp.py:1622]   Expert 14 |    206 | GPU
DEBUG 01-13 08:46:34.603250.603250 lmp.py:1622]   Expert  3 |    209 | GPU
DEBUG 01-13 08:46:34.603369.603369 lmp.py:1622]   Expert  1 |    216 | GPU
DEBUG 01-13 08:46:34.603820.603820 lmp.py:1622]   Expert  4 |    223 | GPU
DEBUG 01-13 08:46:34.603794.603794 lmp.py:1622]   Expert 39 |    234 | GPU
DEBUG 01-13 08:46:34.603007.603007 lmp.py:1622]   Expert 52 |    239 | GPU
DEBUG 01-13 08:46:34.603458.603458 lmp.py:1622]   Expert 28 |    246 | GPU
DEBUG 01-13 08:46:34.603670.603670 lmp.py:1622]   Expert 34 |    246 | GPU
DEBUG 01-13 08:46:34.603121.603121 lmp.py:1622]   Expert 25 |    252 | GPU
DEBUG 01-13 08:46:34.603333.603333 lmp.py:1622]   Expert 22 |    255 | GPU
DEBUG 01-13 08:46:34.603069.603069 lmp.py:1622]   Expert 21 |    271 | GPU
DEBUG 01-13 08:46:34.603712.603712 lmp.py:1622]   Expert  2 |    274 | GPU
DEBUG 01-13 08:46:34.603640.603640 lmp.py:1622]   Expert 41 |    279 | GPU
DEBUG 01-13 08:46:34.603567.603567 lmp.py:1622]   Expert 29 |    284 | GPU
DEBUG 01-13 08:46:34.603734.603734 lmp.py:1622]   Expert 60 |    286 | GPU
DEBUG 01-13 08:46:34.603138.603138 lmp.py:1622]   Expert 63 |    288 | GPU
DEBUG 01-13 08:46:34.603589.603589 lmp.py:1622]   Expert 62 |    296 | GPU
DEBUG 01-13 08:46:34.603563.603563 lmp.py:1622]   Expert 27 |    312 | GPU
DEBUG 01-13 08:46:34.603537.603537 lmp.py:1622]   Expert  8 |    330 | GPU
DEBUG 01-13 08:46:34.603273.603273 lmp.py:1622]   Expert 53 |    331 | GPU
DEBUG 01-13 08:46:34.603247.603247 lmp.py:1622]   Expert 37 |    341 | GPU
DEBUG 01-13 08:46:34.603459.603459 lmp.py:1622]   Expert 19 |    433 | GPU
DEBUG 01-13 08:46:34.603195.603195 lmp.py:1622]   Expert  9 |    634 | GPU
DEBUG 01-13 08:46:34.603123.603123 lmp.py:1623] 
DEBUG 01-13 08:46:34.603123.603123 lmp.py:1623]   CPU total tokens: 3954 (32.2%)
DEBUG 01-13 08:46:34.603527.603527 lmp.py:1624]   GPU total tokens: 8334 (67.8%)
DEBUG 01-13 08:46:34.603938.603938 cuda_h.py:19] end experts_map_get cost 0.0016553401947021484 seconds
DEBUG 01-13 08:46:34.604265.604265 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-13 08:46:34.604783.604783 lmp.py:1632] 
DEBUG 01-13 08:46:34.604783.604783 lmp.py:1632]   Computing 32 experts on CPU MP...
DEBUG 01-13 08:46:34.604758.604758 cuda_h.py:19] end cpu_experts_submit cost 5.173683166503906e-05 seconds
DEBUG 01-13 08:46:34.604428.604428 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-13 08:46:34.604880.604880 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-13 08:46:34.604223.604223 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-13 08:46:34.604457.604457 cuda_h.py:19] end allocate_cuda_memory cost 0.0004057884216308594 seconds
DEBUG 01-13 08:46:34.605894.605894 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-13 08:46:34.605008.605008 sllm_store_c.py:27] get device uuid map
DEBUG 01-13 08:46:34.605215.605215 sllm_store_c.py:29] call client load into gpu
DEBUG 01-13 08:46:34.605394.605394 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, f66e70c3-8e50-4b91-bf20-551abec658e5
DEBUG 01-13 08:46:34.605925.605925 client.py:106] call stub.LoadModelAsync
DEBUG 01-13 08:46:34.605788.605788 cuda_h.py:10] start experts_func_gpu_einsum_mp
INFO 01-13 08:46:34.606187.606187 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, f66e70c3-8e50-4b91-bf20-551abec658e5
DEBUG 01-13 08:46:34.606501.606501 cuda_h.py:19] end load_into_gpu_async cost 0.0016624927520751953 seconds
DEBUG 01-13 08:46:34.606727.606727 cuda_h.py:10] start restore_tensors2
DEBUG 01-13 08:46:34.607144.607144 cuda_h.py:19] end restore_tensors2 cost 0.00038623809814453125 seconds
DEBUG 01-13 08:46:34.607206.607206 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0031647682189941406 seconds
DEBUG 01-13 08:46:34.607160.607160 cuda_h.py:10] start restore2model
DEBUG 01-13 08:46:34.610208.610208 cuda_h.py:19] end restore2model cost 0.003160238265991211 seconds
DEBUG 01-13 08:46:34.610051.610051 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.006505727767944336 seconds
DEBUG 01-13 08:46:34.610323.610323 cuda_h.py:10] start gpu_sexperts
DEBUG 01-13 08:46:34.611884.611884 cuda_h.py:19] end gpu_sexperts cost 0.0003108978271484375 seconds
DEBUG 01-13 08:46:34.611429.611429 cuda_h.py:10] start wait_experts
INFO 01-13 08:46:34.611854.611854 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, f66e70c3-8e50-4b91-bf20-551abec658e5
DEBUG 01-13 08:46:34.611619.611619 mlpmodule.py:1006] group tensors cost 0.004731655120849609 s
DEBUG 01-13 08:46:34.613728.613728 mlpmodule.py:1044] pad cost 0.0015361309051513672 s
DEBUG 01-13 08:46:34.613333.613333 mlpmodule.py:1050] create cpu tensor cost 4.410743713378906e-05 s
DEBUG 01-13 08:46:34.613236.613236 mlpmodule.py:1055] move to cpu cost 3.528594970703125e-05 s
DEBUG 01-13 08:46:34.623357.623357 mlpmodule.py:1069] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-13 08:46:34.623511.623511 mlpmodule.py:1070] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-13 08:46:34.623265.623265 mlpmodule.py:1075] group_w3 first element: -0.006439208984375
WARNING 01-13 08:46:34.623180.623180 mlpmodule.py:1085] start einsum2
DEBUG 01-13 08:46:34.638934.638934 mlpmodule.py:1095] group einsum cost 0.025110721588134766 s
DEBUG 01-13 08:46:34.639118.639118 mlpmodule.py:1103] cpy2cputensor cost 0.000698089599609375 s
DEBUG 01-13 08:46:34.656481.656481 mlpmodule.py:785]  experts func einsum cost 0.04986715316772461 s
DEBUG 01-13 08:46:34.657420.657420 cuda_h.py:19] end experts_func_gpu_einsum_mp cost 0.05140113830566406 seconds
INFO 01-13 08:46:34.659418.659418 client.py:127] Model loaded
DEBUG 01-13 08:46:34.659168.659168 cuda_h.py:19] end wait_experts cost 0.04868936538696289 seconds
DEBUG 01-13 08:46:34.659667.659667 cuda_h.py:10] start gpu_experts
DEBUG 01-13 08:46:34.660217.660217 mlpmodule.py:559] gpu group tensors cost 0.0006706714630126953 s
DEBUG 01-13 08:46:34.662182.662182 mlpmodule.py:592] gpu pad cost 0.0020439624786376953 s
DEBUG 01-13 08:46:34.662383.662383 mlpmodule.py:598] start_w1
DEBUG 01-13 08:46:34.663375.663375 mlpmodule.py:602] start_w3
DEBUG 01-13 08:46:34.663607.663607 mlpmodule.py:608] start_w2
DEBUG 01-13 08:46:34.663063.663063 mlpmodule.py:611] gpu group einsum cost 0.0007121562957763672 s
DEBUG 01-13 08:46:34.666803.666803 mlpmodule.py:683] gpu experts func einsum cost 0.006900787353515625 s
DEBUG 01-13 08:46:34.667886.667886 cuda_h.py:19] end gpu_experts cost 0.007066965103149414 seconds
DEBUG 01-13 08:46:34.667026.667026 cuda_h.py:10] start cpu_thread_manager_mp_wait
DEBUG 01-13 08:46:34.667843.667843 cuda_h.py:19] end cpu_thread_manager_mp_wait cost 4.00543212890625e-05 seconds
DEBUG 01-13 08:46:34.667164.667164 cuda_h.py:19] end layer_moe_generate_mp_l_28 cost 0.06574749946594238 seconds
DEBUG 01-13 08:46:34.667451.667451 lmp.py:1550] -------------------------------- end prefill layer 27 --------------------------------
DEBUG 01-13 08:46:34.667943.667943 cuda_h.py:19] end prefill_layer cost 2.1026203632354736 seconds
DEBUG 01-13 08:46:36.834888.834888 cuda_h.py:10] start generate_input_ids
generate input ids cost 0.09651327133178711 s
DEBUG 01-13 08:46:37.218053.218053 cuda_h.py:19] end generate_input_ids cost 0.38252854347229004 seconds
DEBUG 01-13 08:46:37.218165.218165 cuda_h.py:10] start init_cache
DEBUG 01-13 08:46:37.219606.219606 cuda_h.py:19] end init_cache cost 7.176399230957031e-05 seconds
DEBUG 01-13 08:46:39.885838.885838 cuda_h.py:10] start init_meta_layer
DEBUG 01-13 08:46:39.887929.887929 cuda_h.py:19] end init_meta_layer cost 1.4066696166992188e-05 seconds
DEBUG 01-13 08:46:39.887391.887391 cuda_h.py:10] start init_weights
DEBUG 01-13 08:46:39.887061.887061 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-13 08:46:39.887539.887539 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-13 08:46:39.889622.889622 cuda_h.py:19] end allocate_cuda_memory cost 0.0020656585693359375 seconds
DEBUG 01-13 08:46:39.889148.889148 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-13 08:46:39.889811.889811 sllm_store_c.py:27] get device uuid map
DEBUG 01-13 08:46:39.889687.889687 sllm_store_c.py:29] call client load into gpu
DEBUG 01-13 08:46:39.889151.889151 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 80f34df0-a025-43e4-9060-c2eeaabcf8c0
DEBUG 01-13 08:46:39.889320.889320 client.py:106] call stub.LoadModelAsync
INFO 01-13 08:46:39.892170.892170 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 80f34df0-a025-43e4-9060-c2eeaabcf8c0
DEBUG 01-13 08:46:39.892570.892570 cuda_h.py:19] end load_into_gpu_async cost 0.002487659454345703 seconds
DEBUG 01-13 08:46:39.892002.892002 cuda_h.py:10] start restore_tensors2
DEBUG 01-13 08:46:39.892462.892462 cuda_h.py:19] end restore_tensors2 cost 5.817413330078125e-05 seconds
DEBUG 01-13 08:46:39.892437.892437 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.004886150360107422 seconds
DEBUG 01-13 08:46:39.892432.892432 cuda_h.py:10] start restore2model
DEBUG 01-13 08:46:39.892691.892691 cuda_h.py:19] end restore2model cost 0.00019431114196777344 seconds
INFO 01-13 08:46:39.892699.892699 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 80f34df0-a025-43e4-9060-c2eeaabcf8c0
INFO 01-13 08:46:39.971735.971735 client.py:127] Model loaded
DEBUG 01-13 08:46:39.971707.971707 cuda_h.py:10] start load_qkvogns_weight_l_0
DEBUG 01-13 08:46:39.971929.971929 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-13 08:46:39.972192.972192 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-13 08:46:39.972707.972707 cuda_h.py:19] end allocate_cuda_memory cost 0.00046253204345703125 seconds
DEBUG 01-13 08:46:39.972865.972865 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-13 08:46:39.972404.972404 sllm_store_c.py:27] get device uuid map
DEBUG 01-13 08:46:39.973771.973771 sllm_store_c.py:29] call client load into gpu
DEBUG 01-13 08:46:39.973720.973720 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 6e21edad-e4a2-469f-bdd1-7b25986d8a3d
DEBUG 01-13 08:46:39.973521.973521 client.py:106] call stub.LoadModelAsync
INFO 01-13 08:46:39.974328.974328 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 6e21edad-e4a2-469f-bdd1-7b25986d8a3d
DEBUG 01-13 08:46:39.975306.975306 cuda_h.py:19] end load_into_gpu_async cost 0.002205371856689453 seconds
DEBUG 01-13 08:46:39.975970.975970 cuda_h.py:10] start restore_tensors2
DEBUG 01-13 08:46:39.975818.975818 cuda_h.py:19] end restore_tensors2 cost 0.00013446807861328125 seconds
DEBUG 01-13 08:46:39.975264.975264 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0034008026123046875 seconds
INFO 01-13 08:46:39.975929.975929 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 6e21edad-e4a2-469f-bdd1-7b25986d8a3d
INFO 01-13 08:46:39.990312.990312 client.py:127] Model loaded
DEBUG 01-13 08:46:39.990039.990039 cuda_h.py:10] start restore2model
DEBUG 01-13 08:46:39.991065.991065 cuda_h.py:19] end restore2model cost 0.0008656978607177734 seconds
DEBUG 01-13 08:46:39.991195.991195 cuda_h.py:19] end load_qkvogns_weight_l_0 cost 0.020035982131958008 seconds
DEBUG 01-13 08:46:39.992225.992225 cuda_h.py:19] end init_weights cost 0.10457801818847656 seconds
DEBUG 01-13 08:46:39.992220.992220 cuda_h.py:10] start copy_emodel
DEBUG 01-13 08:46:40.732815.732815 cuda_h.py:19] end copy_emodel cost 0.7399866580963135 seconds
DEBUG 01-13 08:46:40.733319.733319 cuda_h.py:10] start init_inputs_tokens
DEBUG 01-13 08:46:40.733242.733242 cuda_h.py:19] end init_inputs_tokens cost 0.0002524852752685547 seconds
DEBUG 01-13 08:46:40.733919.733919 cuda_h.py:10] start prefill_layer
DEBUG 01-13 08:46:40.733821.733821 lmp.py:1493] -------------------------------- start prefill layer 0 --------------------------------
DEBUG 01-13 08:46:40.733994.733994 cuda_h.py:10] start start_load_qkvogn_s_weight_l_1
DEBUG 01-13 08:46:40.733313.733313 cuda_h.py:10] start start_load_qkvogn_s_weight_l_1
DEBUG 01-13 08:46:40.733202.733202 cuda_h.py:19] end start_load_qkvogn_s_weight_l_1 cost 3.24249267578125e-05 seconds
DEBUG 01-13 08:46:40.733495.733495 cuda_h.py:19] end start_load_qkvogn_s_weight_l_1 cost 7.867813110351562e-05 seconds
DEBUG 01-13 08:46:40.733899.733899 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-13 08:46:40.733597.733597 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-13 08:46:40.733374.733374 cuda_h.py:10] start sllm_worker_task
DEBUG 01-13 08:46:40.733233.733233 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-13 08:46:40.733421.733421 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-13 08:46:40.734444.734444 cuda_h.py:19] end allocate_cuda_memory cost 0.0002529621124267578 seconds
DEBUG 01-13 08:46:40.734719.734719 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-13 08:46:40.734489.734489 sllm_store_c.py:27] get device uuid map
DEBUG 01-13 08:46:40.734464.734464 sllm_store_c.py:29] call client load into gpu
DEBUG 01-13 08:46:40.734081.734081 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, ab387499-0cb8-41b8-91fa-30da0640b40f
DEBUG 01-13 08:46:40.734376.734376 client.py:106] call stub.LoadModelAsync
DEBUG 01-13 08:46:40.734189.734189 cuda_h.py:10] start self_attn
INFO 01-13 08:46:40.736777.736777 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, ab387499-0cb8-41b8-91fa-30da0640b40f
DEBUG 01-13 08:46:40.736250.736250 cuda_h.py:19] end load_into_gpu_async cost 0.002350330352783203 seconds
DEBUG 01-13 08:46:40.736959.736959 cuda_h.py:10] start restore_tensors2
DEBUG 01-13 08:46:40.736639.736639 cuda_h.py:19] end restore_tensors2 cost 8.106231689453125e-05 seconds
DEBUG 01-13 08:46:40.736501.736501 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.002997875213623047 seconds
INFO 01-13 08:46:40.736596.736596 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, ab387499-0cb8-41b8-91fa-30da0640b40f
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-13 08:46:40.738615.738615 cuda_h.py:19] end self_attn cost 0.003934144973754883 seconds
DEBUG 01-13 08:46:40.739603.739603 cuda_h.py:19] end iln_self_attn_paln cost 0.006142377853393555 seconds
DEBUG 01-13 08:46:40.739002.739002 cuda_h.py:10] start dense_mlp
INFO 01-13 08:46:40.743053.743053 client.py:127] Model loaded
DEBUG 01-13 08:46:40.743195.743195 cuda_h.py:10] start restore2model
DEBUG 01-13 08:46:40.744368.744368 cuda_h.py:19] end restore2model cost 0.0005688667297363281 seconds
DEBUG 01-13 08:46:40.744840.744840 cuda_h.py:19] end sllm_worker_task cost 0.010811567306518555 seconds
DEBUG 01-13 08:46:40.744870.744870 cuda_h.py:19] end dense_mlp cost 0.004917621612548828 seconds
DEBUG 01-13 08:46:40.744244.744244 lmp.py:1550] -------------------------------- end prefill layer 0 --------------------------------
DEBUG 01-13 08:46:40.744623.744623 lmp.py:1493] -------------------------------- start prefill layer 1 --------------------------------
DEBUG 01-13 08:46:40.744180.744180 cuda_h.py:10] start start_load_qkvogn_s_weight_l_2
DEBUG 01-13 08:46:40.744075.744075 cuda_h.py:10] start start_load_qkvogn_s_weight_l_2
DEBUG 01-13 08:46:40.744805.744805 cuda_h.py:19] end start_load_qkvogn_s_weight_l_2 cost 2.0742416381835938e-05 seconds
DEBUG 01-13 08:46:40.745223.745223 cuda_h.py:19] end start_load_qkvogn_s_weight_l_2 cost 5.1021575927734375e-05 seconds
DEBUG 01-13 08:46:40.745727.745727 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-13 08:46:40.745086.745086 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-13 08:46:40.745068.745068 cuda_h.py:10] start sllm_worker_task
DEBUG 01-13 08:46:40.745911.745911 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-13 08:46:40.745060.745060 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-13 08:46:40.745936.745936 cuda_h.py:19] end allocate_cuda_memory cost 0.00020647048950195312 seconds
DEBUG 01-13 08:46:40.745132.745132 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-13 08:46:40.745419.745419 sllm_store_c.py:27] get device uuid map
DEBUG 01-13 08:46:40.745130.745130 sllm_store_c.py:29] call client load into gpu
DEBUG 01-13 08:46:40.745091.745091 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, f0bead30-88fc-4aaa-99eb-1d70b39a60b2
DEBUG 01-13 08:46:40.745664.745664 client.py:106] call stub.LoadModelAsync
DEBUG 01-13 08:46:40.746995.746995 cuda_h.py:10] start self_attn
INFO 01-13 08:46:40.747398.747398 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, f0bead30-88fc-4aaa-99eb-1d70b39a60b2
DEBUG 01-13 08:46:40.747553.747553 cuda_h.py:19] end load_into_gpu_async cost 0.001430511474609375 seconds
DEBUG 01-13 08:46:40.747468.747468 cuda_h.py:10] start restore_tensors2
DEBUG 01-13 08:46:40.747830.747830 cuda_h.py:19] end restore_tensors2 cost 7.987022399902344e-05 seconds
DEBUG 01-13 08:46:40.747613.747613 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0021157264709472656 seconds
INFO 01-13 08:46:40.747828.747828 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, f0bead30-88fc-4aaa-99eb-1d70b39a60b2
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-13 08:46:40.749275.749275 cuda_h.py:19] end self_attn cost 0.003164052963256836 seconds
DEBUG 01-13 08:46:40.749384.749384 cuda_h.py:19] end iln_self_attn_paln cost 0.004563570022583008 seconds
DEBUG 01-13 08:46:40.749558.749558 cuda_h.py:10] start layer_moe_generate_mp_l_2
DEBUG 01-13 08:46:40.749698.749698 cuda_h.py:10] start gate
DEBUG 01-13 08:46:40.750180.750180 cuda_h.py:19] end gate cost 0.0007081031799316406 seconds
DEBUG 01-13 08:46:40.750917.750917 cuda_h.py:10] start experts_map_get
DEBUG 01-13 08:46:40.750185.750185 lmp.py:1611] 
DEBUG 01-13 08:46:40.750185.750185 lmp.py:1611] Expert Token Distribution & Device Allocation:
DEBUG 01-13 08:46:40.750802.750802 lmp.py:1612]   Total experts: 64
DEBUG 01-13 08:46:40.750167.750167 lmp.py:1613]   CPU experts: 32 (50%)
DEBUG 01-13 08:46:40.750241.750241 lmp.py:1614]   GPU experts: 32 (50%)
DEBUG 01-13 08:46:40.750407.750407 lmp.py:1615] 
DEBUG 01-13 08:46:40.750407.750407 lmp.py:1615]   Expert ID | Tokens | Device
DEBUG 01-13 08:46:40.750335.750335 lmp.py:1616]   -----------------------------------
DEBUG 01-13 08:46:40.750461.750461 lmp.py:1622]   Expert 25 |     64 | CPU
DEBUG 01-13 08:46:40.750389.750389 lmp.py:1622]   Expert 54 |     67 | CPU
DEBUG 01-13 08:46:40.750840.750840 lmp.py:1622]   Expert  3 |     68 | CPU
DEBUG 01-13 08:46:40.750814.750814 lmp.py:1622]   Expert 31 |     72 | CPU
DEBUG 01-13 08:46:40.751026.751026 lmp.py:1622]   Expert 55 |     72 | CPU
DEBUG 01-13 08:46:40.751908.751908 lmp.py:1622]   Expert 62 |     87 | CPU
DEBUG 01-13 08:46:40.751836.751836 lmp.py:1622]   Expert 18 |     88 | CPU
DEBUG 01-13 08:46:40.751002.751002 lmp.py:1622]   Expert 52 |     98 | CPU
DEBUG 01-13 08:46:40.751122.751122 lmp.py:1622]   Expert 22 |    100 | CPU
DEBUG 01-13 08:46:40.751334.751334 lmp.py:1622]   Expert 47 |    104 | CPU
DEBUG 01-13 08:46:40.751023.751023 lmp.py:1622]   Expert  0 |    113 | CPU
DEBUG 01-13 08:46:40.751474.751474 lmp.py:1622]   Expert 37 |    117 | CPU
DEBUG 01-13 08:46:40.751448.751448 lmp.py:1622]   Expert 27 |    121 | CPU
DEBUG 01-13 08:46:40.751661.751661 lmp.py:1622]   Expert 32 |    123 | CPU
DEBUG 01-13 08:46:40.751873.751873 lmp.py:1622]   Expert 41 |    130 | CPU
DEBUG 01-13 08:46:40.751609.751609 lmp.py:1622]   Expert 44 |    131 | CPU
DEBUG 01-13 08:46:40.751821.751821 lmp.py:1622]   Expert 28 |    136 | CPU
DEBUG 01-13 08:46:40.751272.751272 lmp.py:1622]   Expert 13 |    138 | CPU
DEBUG 01-13 08:46:40.751438.751438 lmp.py:1622]   Expert 58 |    140 | CPU
DEBUG 01-13 08:46:40.751604.751604 lmp.py:1622]   Expert 60 |    144 | CPU
DEBUG 01-13 08:46:40.751009.751009 lmp.py:1622]   Expert 43 |    147 | CPU
DEBUG 01-13 08:46:40.751890.751890 lmp.py:1622]   Expert  1 |    150 | CPU
DEBUG 01-13 08:46:40.751103.751103 lmp.py:1622]   Expert 38 |    153 | CPU
DEBUG 01-13 08:46:40.751315.751315 lmp.py:1622]   Expert 49 |    154 | CPU
DEBUG 01-13 08:46:40.751528.751528 lmp.py:1622]   Expert 51 |    155 | CPU
DEBUG 01-13 08:46:40.751502.751502 lmp.py:1622]   Expert 34 |    161 | CPU
DEBUG 01-13 08:46:40.751714.751714 lmp.py:1622]   Expert 35 |    164 | CPU
DEBUG 01-13 08:46:40.751927.751927 lmp.py:1622]   Expert 36 |    168 | CPU
DEBUG 01-13 08:46:40.751662.751662 lmp.py:1622]   Expert 11 |    170 | CPU
DEBUG 01-13 08:46:40.751875.751875 lmp.py:1622]   Expert 17 |    170 | CPU
DEBUG 01-13 08:46:40.751087.751087 lmp.py:1622]   Expert 59 |    174 | CPU
DEBUG 01-13 08:46:40.751061.751061 lmp.py:1622]   Expert 10 |    180 | CPU
DEBUG 01-13 08:46:40.751989.751989 lmp.py:1622]   Expert 20 |    182 | GPU
DEBUG 01-13 08:46:40.751917.751917 lmp.py:1622]   Expert  2 |    186 | GPU
DEBUG 01-13 08:46:40.751844.751844 lmp.py:1622]   Expert 39 |    189 | GPU
DEBUG 01-13 08:46:40.751819.751819 lmp.py:1622]   Expert 33 |    197 | GPU
DEBUG 01-13 08:46:40.751793.751793 lmp.py:1622]   Expert 12 |    198 | GPU
DEBUG 01-13 08:46:40.751767.751767 lmp.py:1622]   Expert 21 |    198 | GPU
DEBUG 01-13 08:46:40.751502.751502 lmp.py:1622]   Expert 48 |    198 | GPU
DEBUG 01-13 08:46:40.751715.751715 lmp.py:1622]   Expert 15 |    199 | GPU
DEBUG 01-13 08:46:40.751450.751450 lmp.py:1622]   Expert 53 |    204 | GPU
DEBUG 01-13 08:46:40.751424.751424 lmp.py:1622]   Expert 19 |    220 | GPU
DEBUG 01-13 08:46:40.751637.751637 lmp.py:1622]   Expert 26 |    221 | GPU
DEBUG 01-13 08:46:40.751611.751611 lmp.py:1622]   Expert 30 |    221 | GPU
DEBUG 01-13 08:46:40.751585.751585 lmp.py:1622]   Expert 45 |    221 | GPU
DEBUG 01-13 08:46:40.751559.751559 lmp.py:1622]   Expert  5 |    227 | GPU
DEBUG 01-13 08:46:40.751533.751533 lmp.py:1622]   Expert  4 |    229 | GPU
DEBUG 01-13 08:46:40.751984.751984 lmp.py:1622]   Expert 24 |    229 | GPU
DEBUG 01-13 08:46:40.751912.751912 lmp.py:1622]   Expert 42 |    242 | GPU
DEBUG 01-13 08:46:40.751316.751316 lmp.py:1622]   Expert 50 |    245 | GPU
DEBUG 01-13 08:46:40.751482.751482 lmp.py:1622]   Expert 29 |    254 | GPU
DEBUG 01-13 08:46:40.751841.751841 lmp.py:1622]   Expert 56 |    262 | GPU
DEBUG 01-13 08:46:40.751530.751530 lmp.py:1622]   Expert 61 |    270 | GPU
DEBUG 01-13 08:46:40.751265.751265 lmp.py:1622]   Expert  8 |    283 | GPU
DEBUG 01-13 08:46:40.751478.751478 lmp.py:1622]   Expert 63 |    285 | GPU
DEBUG 01-13 08:46:40.751214.751214 lmp.py:1622]   Expert 46 |    294 | GPU
DEBUG 01-13 08:46:40.751426.751426 lmp.py:1622]   Expert  9 |    300 | GPU
DEBUG 01-13 08:46:40.751638.751638 lmp.py:1622]   Expert  6 |    316 | GPU
DEBUG 01-13 08:46:40.751374.751374 lmp.py:1622]   Expert 16 |    316 | GPU
DEBUG 01-13 08:46:40.751732.751732 lmp.py:1622]   Expert 40 |    319 | GPU
DEBUG 01-13 08:46:40.751329.751329 lmp.py:1622]   Expert  7 |    322 | GPU
DEBUG 01-13 08:46:40.751210.751210 lmp.py:1622]   Expert 23 |    325 | GPU
DEBUG 01-13 08:46:40.751330.751330 lmp.py:1622]   Expert 14 |    413 | GPU
DEBUG 01-13 08:46:40.751688.751688 lmp.py:1622]   Expert 57 |    464 | GPU
DEBUG 01-13 08:46:40.752808.752808 lmp.py:1623] 
DEBUG 01-13 08:46:40.752808.752808 lmp.py:1623]   CPU total tokens: 4059 (33.0%)
DEBUG 01-13 08:46:40.752928.752928 lmp.py:1624]   GPU total tokens: 8229 (67.0%)
DEBUG 01-13 08:46:40.752578.752578 cuda_h.py:19] end experts_map_get cost 0.0015118122100830078 seconds
DEBUG 01-13 08:46:40.752196.752196 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-13 08:46:40.752522.752522 lmp.py:1632] 
DEBUG 01-13 08:46:40.752522.752522 lmp.py:1632]   Computing 32 experts on CPU MP...
DEBUG 01-13 08:46:40.752643.752643 cuda_h.py:19] end cpu_experts_submit cost 5.3882598876953125e-05 seconds
DEBUG 01-13 08:46:40.752385.752385 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-13 08:46:40.752791.752791 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-13 08:46:40.752557.752557 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-13 08:46:40.753681.753681 cuda_h.py:19] end allocate_cuda_memory cost 0.0012819766998291016 seconds
DEBUG 01-13 08:46:40.753544.753544 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-13 08:46:40.753969.753969 sllm_store_c.py:27] get device uuid map
DEBUG 01-13 08:46:40.753586.753586 sllm_store_c.py:29] call client load into gpu
DEBUG 01-13 08:46:40.753713.753713 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 673cb073-d692-4d53-a86a-e6ff39cb28aa
DEBUG 01-13 08:46:40.754172.754172 client.py:106] call stub.LoadModelAsync
INFO 01-13 08:46:40.754926.754926 client.py:127] Model loaded
DEBUG 01-13 08:46:40.755724.755724 cuda_h.py:10] start restore2model
DEBUG 01-13 08:46:40.755297.755297 cuda_h.py:10] start experts_func_gpu_einsum_mp
DEBUG 01-13 08:46:40.756770.756770 cuda_h.py:19] end restore2model cost 0.0009093284606933594 seconds
DEBUG 01-13 08:46:40.756304.756304 cuda_h.py:19] end sllm_worker_task cost 0.010923385620117188 seconds
INFO 01-13 08:46:40.756532.756532 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 673cb073-d692-4d53-a86a-e6ff39cb28aa
DEBUG 01-13 08:46:40.756927.756927 cuda_h.py:19] end load_into_gpu_async cost 0.0024950504302978516 seconds
DEBUG 01-13 08:46:40.756921.756921 cuda_h.py:10] start restore_tensors2
DEBUG 01-13 08:46:40.756530.756530 cuda_h.py:19] end restore_tensors2 cost 0.00034332275390625 seconds
DEBUG 01-13 08:46:40.756512.756512 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.00451207160949707 seconds
DEBUG 01-13 08:46:40.756229.756229 cuda_h.py:10] start restore2model
DEBUG 01-13 08:46:40.759803.759803 cuda_h.py:19] end restore2model cost 0.002675771713256836 seconds
DEBUG 01-13 08:46:40.759122.759122 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.007364511489868164 seconds
DEBUG 01-13 08:46:40.759441.759441 cuda_h.py:10] start gpu_sexperts
DEBUG 01-13 08:46:40.759564.759564 cuda_h.py:19] end gpu_sexperts cost 0.00027108192443847656 seconds
DEBUG 01-13 08:46:40.759393.759393 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-13 08:46:40.760878.760878 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 1.4066696166992188e-05 seconds
DEBUG 01-13 08:46:40.760621.760621 cuda_h.py:10] start wait_experts
INFO 01-13 08:46:40.760078.760078 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 673cb073-d692-4d53-a86a-e6ff39cb28aa
DEBUG 01-13 08:46:40.763708.763708 mlpmodule.py:1006] group tensors cost 0.007227182388305664 s
DEBUG 01-13 08:46:40.766036.766036 mlpmodule.py:1044] pad cost 0.002395153045654297 s
DEBUG 01-13 08:46:40.767763.767763 mlpmodule.py:1050] create cpu tensor cost 7.033348083496094e-05 s
DEBUG 01-13 08:46:40.767674.767674 mlpmodule.py:1055] move to cpu cost 5.030632019042969e-05 s
DEBUG 01-13 08:46:40.775805.775805 mlpmodule.py:1069] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-13 08:46:40.776189.776189 mlpmodule.py:1070] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-13 08:46:40.776278.776278 mlpmodule.py:1075] group_w3 first element: -0.0107421875
WARNING 01-13 08:46:40.776316.776316 mlpmodule.py:1085] start einsum2
DEBUG 01-13 08:46:40.787157.787157 mlpmodule.py:1095] group einsum cost 0.02065873146057129 s
DEBUG 01-13 08:46:40.788049.788049 mlpmodule.py:1103] cpy2cputensor cost 0.0007224082946777344 s
INFO 01-13 08:46:40.806044.806044 client.py:127] Model loaded
DEBUG 01-13 08:46:40.806438.806438 cuda_h.py:19] end wait_experts cost 0.04614377021789551 seconds
DEBUG 01-13 08:46:40.806301.806301 cuda_h.py:10] start gpu_experts
DEBUG 01-13 08:46:40.807516.807516 mlpmodule.py:559] gpu group tensors cost 0.0011827945709228516 s
DEBUG 01-13 08:46:40.809813.809813 mlpmodule.py:592] gpu pad cost 0.001684427261352539 s
DEBUG 01-13 08:46:40.809862.809862 mlpmodule.py:598] start_w1
DEBUG 01-13 08:46:40.809276.809276 mlpmodule.py:602] start_w3
DEBUG 01-13 08:46:40.809169.809169 mlpmodule.py:608] start_w2
DEBUG 01-13 08:46:40.810232.810232 mlpmodule.py:611] gpu group einsum cost 0.0007612705230712891 s
DEBUG 01-13 08:46:40.812342.812342 mlpmodule.py:683] gpu experts func einsum cost 0.006083011627197266 s
DEBUG 01-13 08:46:40.812096.812096 cuda_h.py:19] end gpu_experts cost 0.0063173770904541016 seconds
DEBUG 01-13 08:46:40.812998.812998 cuda_h.py:10] start cpu_thread_manager_mp_wait
DEBUG 01-13 08:46:40.812708.812708 cuda_h.py:19] end cpu_thread_manager_mp_wait cost 3.933906555175781e-05 seconds
DEBUG 01-13 08:46:40.812579.812579 cuda_h.py:19] end layer_moe_generate_mp_l_2 cost 0.06308197975158691 seconds
DEBUG 01-13 08:46:40.812669.812669 mlpmodule.py:785]  experts func einsum cost 0.05635237693786621 s
DEBUG 01-13 08:46:40.812817.812817 lmp.py:1550] -------------------------------- end prefill layer 1 --------------------------------
DEBUG 01-13 08:46:40.813064.813064 lmp.py:1493] -------------------------------- start prefill layer 2 --------------------------------
DEBUG 01-13 08:46:40.813052.813052 cuda_h.py:10] start start_load_qkvogn_s_weight_l_3
DEBUG 01-13 08:46:40.813185.813185 cuda_h.py:10] start start_load_qkvogn_s_weight_l_3
DEBUG 01-13 08:46:40.813028.813028 cuda_h.py:19] end start_load_qkvogn_s_weight_l_3 cost 3.0994415283203125e-05 seconds
DEBUG 01-13 08:46:40.813798.813798 cuda_h.py:19] end start_load_qkvogn_s_weight_l_3 cost 7.963180541992188e-05 seconds
DEBUG 01-13 08:46:40.813348.813348 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-13 08:46:40.813853.813853 cuda_h.py:19] end experts_func_gpu_einsum_mp cost 0.057410240173339844 seconds
DEBUG 01-13 08:46:40.813092.813092 cuda_h.py:10] start sllm_worker_task
DEBUG 01-13 08:46:40.813824.813824 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-13 08:46:40.813594.813594 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-13 08:46:40.813763.813763 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-13 08:46:40.813360.813360 cuda_h.py:19] end allocate_cuda_memory cost 0.00019240379333496094 seconds
DEBUG 01-13 08:46:40.813807.813807 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-13 08:46:40.813901.813901 sllm_store_c.py:27] get device uuid map
DEBUG 01-13 08:46:40.813055.813055 sllm_store_c.py:29] call client load into gpu
DEBUG 01-13 08:46:40.813327.813327 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 93e0d1fb-60ed-4cca-9759-336f177bd586
DEBUG 01-13 08:46:40.814343.814343 client.py:106] call stub.LoadModelAsync
DEBUG 01-13 08:46:40.814775.814775 cuda_h.py:10] start self_attn
INFO 01-13 08:46:40.815101.815101 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 93e0d1fb-60ed-4cca-9759-336f177bd586
DEBUG 01-13 08:46:40.815461.815461 cuda_h.py:19] end load_into_gpu_async cost 0.0012903213500976562 seconds
DEBUG 01-13 08:46:40.815256.815256 cuda_h.py:10] start restore_tensors2
DEBUG 01-13 08:46:40.815617.815617 cuda_h.py:19] end restore_tensors2 cost 6.389617919921875e-05 seconds
DEBUG 01-13 08:46:40.815465.815465 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0018131732940673828 seconds
INFO 01-13 08:46:40.815746.815746 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 93e0d1fb-60ed-4cca-9759-336f177bd586
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-13 08:46:40.817735.817735 cuda_h.py:19] end self_attn cost 0.003281116485595703 seconds
DEBUG 01-13 08:46:40.817758.817758 cuda_h.py:19] end iln_self_attn_paln cost 0.00469660758972168 seconds
DEBUG 01-13 08:46:40.817025.817025 cuda_h.py:10] start layer_moe_generate_mp_l_3
DEBUG 01-13 08:46:40.818026.818026 cuda_h.py:10] start gate
DEBUG 01-13 08:46:40.818843.818843 cuda_h.py:19] end gate cost 0.0006396770477294922 seconds
DEBUG 01-13 08:46:40.818242.818242 cuda_h.py:10] start experts_map_get
DEBUG 01-13 08:46:40.819543.819543 lmp.py:1611] 
DEBUG 01-13 08:46:40.819543.819543 lmp.py:1611] Expert Token Distribution & Device Allocation:
DEBUG 01-13 08:46:40.819299.819299 lmp.py:1612]   Total experts: 64
DEBUG 01-13 08:46:40.819664.819664 lmp.py:1613]   CPU experts: 32 (50%)
DEBUG 01-13 08:46:40.819453.819453 lmp.py:1614]   GPU experts: 32 (50%)
DEBUG 01-13 08:46:40.819857.819857 lmp.py:1615] 
DEBUG 01-13 08:46:40.819857.819857 lmp.py:1615]   Expert ID | Tokens | Device
DEBUG 01-13 08:46:40.819739.819739 lmp.py:1616]   -----------------------------------
DEBUG 01-13 08:46:40.819865.819865 lmp.py:1622]   Expert 58 |     51 | CPU
DEBUG 01-13 08:46:40.819224.819224 lmp.py:1622]   Expert 27 |     60 | CPU
DEBUG 01-13 08:46:40.819867.819867 lmp.py:1622]   Expert  3 |     69 | CPU
DEBUG 01-13 08:46:40.819794.819794 lmp.py:1622]   Expert 17 |     82 | CPU
DEBUG 01-13 08:46:40.819722.819722 lmp.py:1622]   Expert  0 |     86 | CPU
DEBUG 01-13 08:46:40.819411.819411 lmp.py:1622]   Expert 24 |     88 | CPU
DEBUG 01-13 08:46:40.819101.819101 lmp.py:1622]   Expert 28 |    105 | CPU
DEBUG 01-13 08:46:40.819028.819028 lmp.py:1622]   Expert 34 |    111 | CPU
DEBUG 01-13 08:46:40.819195.819195 lmp.py:1622]   Expert 51 |    114 | CPU
DEBUG 01-13 08:46:40.819122.819122 lmp.py:1622]   Expert 32 |    121 | CPU
DEBUG 01-13 08:46:40.819957.819957 lmp.py:1622]   Expert  9 |    127 | CPU
DEBUG 01-13 08:46:40.819362.819362 lmp.py:1622]   Expert 26 |    132 | CPU
DEBUG 01-13 08:46:40.819528.819528 lmp.py:1622]   Expert  7 |    133 | CPU
DEBUG 01-13 08:46:40.819694.819694 lmp.py:1622]   Expert 15 |    136 | CPU
DEBUG 01-13 08:46:40.819860.819860 lmp.py:1622]   Expert 23 |    137 | CPU
DEBUG 01-13 08:46:40.819841.819841 lmp.py:1622]   Expert 30 |    146 | CPU
DEBUG 01-13 08:46:40.819530.819530 lmp.py:1622]   Expert 45 |    146 | CPU
DEBUG 01-13 08:46:40.819909.819909 lmp.py:1622]   Expert 62 |    148 | CPU
DEBUG 01-13 08:46:40.819075.819075 lmp.py:1622]   Expert 57 |    149 | CPU
DEBUG 01-13 08:46:40.819003.819003 lmp.py:1622]   Expert  1 |    154 | CPU
DEBUG 01-13 08:46:40.819646.819646 lmp.py:1622]   Expert 36 |    157 | CPU
DEBUG 01-13 08:46:40.819574.819574 lmp.py:1622]   Expert 29 |    160 | CPU
DEBUG 01-13 08:46:40.819932.819932 lmp.py:1622]   Expert  8 |    161 | CPU
DEBUG 01-13 08:46:40.819813.819813 lmp.py:1622]   Expert 25 |    161 | CPU
DEBUG 01-13 08:46:40.819456.819456 lmp.py:1622]   Expert 35 |    167 | CPU
DEBUG 01-13 08:46:40.819099.819099 lmp.py:1622]   Expert  6 |    171 | CPU
DEBUG 01-13 08:46:40.819742.819742 lmp.py:1622]   Expert 37 |    172 | CPU
DEBUG 01-13 08:46:40.819908.819908 lmp.py:1622]   Expert 54 |    172 | CPU
DEBUG 01-13 08:46:40.819836.819836 lmp.py:1622]   Expert 48 |    174 | CPU
DEBUG 01-13 08:46:40.819764.819764 lmp.py:1622]   Expert 12 |    177 | CPU
DEBUG 01-13 08:46:40.819930.819930 lmp.py:1622]   Expert 49 |    178 | CPU
DEBUG 01-13 08:46:40.819858.819858 lmp.py:1622]   Expert 13 |    186 | CPU
DEBUG 01-13 08:46:40.819024.819024 lmp.py:1622]   Expert 33 |    188 | GPU
DEBUG 01-13 08:46:40.819713.819713 lmp.py:1622]   Expert 60 |    188 | GPU
DEBUG 01-13 08:46:40.819641.819641 lmp.py:1622]   Expert 10 |    190 | GPU
DEBUG 01-13 08:46:40.819807.819807 lmp.py:1622]   Expert 21 |    193 | GPU
DEBUG 01-13 08:46:40.819688.819688 lmp.py:1622]   Expert 53 |    194 | GPU
DEBUG 01-13 08:46:40.819331.819331 lmp.py:1622]   Expert 16 |    199 | GPU
DEBUG 01-13 08:46:40.819213.819213 lmp.py:1622]   Expert 40 |    201 | GPU
DEBUG 01-13 08:46:40.819617.819617 lmp.py:1622]   Expert 38 |    204 | GPU
DEBUG 01-13 08:46:40.819307.819307 lmp.py:1622]   Expert 43 |    204 | GPU
DEBUG 01-13 08:46:40.819996.819996 lmp.py:1622]   Expert  5 |    209 | GPU
DEBUG 01-13 08:46:40.819924.819924 lmp.py:1622]   Expert 44 |    214 | GPU
DEBUG 01-13 08:46:40.819090.819090 lmp.py:1622]   Expert  4 |    215 | GPU
DEBUG 01-13 08:46:40.819256.819256 lmp.py:1622]   Expert 52 |    215 | GPU
DEBUG 01-13 08:46:40.819184.819184 lmp.py:1622]   Expert 50 |    217 | GPU
DEBUG 01-13 08:46:40.819873.819873 lmp.py:1622]   Expert 19 |    218 | GPU
DEBUG 01-13 08:46:40.820562.820562 lmp.py:1622]   Expert 41 |    222 | GPU
DEBUG 01-13 08:46:40.820728.820728 lmp.py:1622]   Expert 59 |    224 | GPU
DEBUG 01-13 08:46:40.820610.820610 lmp.py:1622]   Expert 55 |    233 | GPU
DEBUG 01-13 08:46:40.820537.820537 lmp.py:1622]   Expert 31 |    242 | GPU
DEBUG 01-13 08:46:40.820942.820942 lmp.py:1622]   Expert 56 |    248 | GPU
DEBUG 01-13 08:46:40.820870.820870 lmp.py:1622]   Expert 39 |    250 | GPU
DEBUG 01-13 08:46:40.820559.820559 lmp.py:1622]   Expert  2 |    261 | GPU
DEBUG 01-13 08:46:40.820487.820487 lmp.py:1622]   Expert 20 |    261 | GPU
DEBUG 01-13 08:46:40.820414.820414 lmp.py:1622]   Expert 22 |    262 | GPU
DEBUG 01-13 08:46:40.820104.820104 lmp.py:1622]   Expert 47 |    276 | GPU
DEBUG 01-13 08:46:40.820031.820031 lmp.py:1622]   Expert 63 |    276 | GPU
DEBUG 01-13 08:46:40.820721.820721 lmp.py:1622]   Expert 42 |    302 | GPU
DEBUG 01-13 08:46:40.820648.820648 lmp.py:1622]   Expert 18 |    312 | GPU
DEBUG 01-13 08:46:40.820576.820576 lmp.py:1622]   Expert 14 |    315 | GPU
DEBUG 01-13 08:46:40.820458.820458 lmp.py:1622]   Expert 46 |    367 | GPU
DEBUG 01-13 08:46:40.820862.820862 lmp.py:1622]   Expert 11 |    385 | GPU
DEBUG 01-13 08:46:40.820505.820505 lmp.py:1622]   Expert 61 |    472 | GPU
DEBUG 01-13 08:46:40.820863.820863 lmp.py:1623] 
DEBUG 01-13 08:46:40.820863.820863 lmp.py:1623]   CPU total tokens: 4331 (35.2%)
DEBUG 01-13 08:46:40.820222.820222 lmp.py:1624]   GPU total tokens: 7957 (64.8%)
DEBUG 01-13 08:46:40.820633.820633 cuda_h.py:19] end experts_map_get cost 0.001558065414428711 seconds
DEBUG 01-13 08:46:40.820205.820205 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-13 08:46:40.820299.820299 lmp.py:1632] 
DEBUG 01-13 08:46:40.820299.820299 lmp.py:1632]   Computing 32 experts on CPU MP...
DEBUG 01-13 08:46:40.820843.820843 cuda_h.py:19] end cpu_experts_submit cost 5.3882598876953125e-05 seconds
DEBUG 01-13 08:46:40.820301.820301 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-13 08:46:40.820369.820369 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-13 08:46:40.820837.820837 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-13 08:46:40.821443.821443 cuda_h.py:19] end allocate_cuda_memory cost 0.0010445117950439453 seconds
DEBUG 01-13 08:46:40.821908.821908 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-13 08:46:40.821095.821095 sllm_store_c.py:27] get device uuid map
DEBUG 01-13 08:46:40.821640.821640 sllm_store_c.py:29] call client load into gpu
DEBUG 01-13 08:46:40.821197.821197 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, eb551a15-2b45-4070-8039-db1ad385e05c
DEBUG 01-13 08:46:40.822017.822017 client.py:106] call stub.LoadModelAsync
INFO 01-13 08:46:40.822909.822909 client.py:127] Model loaded
DEBUG 01-13 08:46:40.822328.822328 cuda_h.py:10] start restore2model
DEBUG 01-13 08:46:40.823713.823713 cuda_h.py:10] start experts_func_gpu_einsum_mp
DEBUG 01-13 08:46:40.823596.823596 cuda_h.py:19] end restore2model cost 0.0004374980926513672 seconds
INFO 01-13 08:46:40.823804.823804 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, eb551a15-2b45-4070-8039-db1ad385e05c
DEBUG 01-13 08:46:40.823945.823945 cuda_h.py:19] end sllm_worker_task cost 0.009920835494995117 seconds
DEBUG 01-13 08:46:40.823464.823464 cuda_h.py:19] end load_into_gpu_async cost 0.0015304088592529297 seconds
DEBUG 01-13 08:46:40.823844.823844 cuda_h.py:10] start restore_tensors2
DEBUG 01-13 08:46:40.823368.823368 cuda_h.py:19] end restore_tensors2 cost 0.0003921985626220703 seconds
DEBUG 01-13 08:46:40.823026.823026 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0033745765686035156 seconds
DEBUG 01-13 08:46:40.824842.824842 cuda_h.py:10] start restore2model
DEBUG 01-13 08:46:40.826770.826770 cuda_h.py:19] end restore2model cost 0.002760648727416992 seconds
DEBUG 01-13 08:46:40.826997.826997 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.0063190460205078125 seconds
DEBUG 01-13 08:46:40.826461.826461 cuda_h.py:10] start gpu_sexperts
DEBUG 01-13 08:46:40.827266.827266 cuda_h.py:19] end gpu_sexperts cost 0.0002815723419189453 seconds
DEBUG 01-13 08:46:40.827381.827381 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-13 08:46:40.827773.827773 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 1.5974044799804688e-05 seconds
DEBUG 01-13 08:46:40.827707.827707 cuda_h.py:10] start wait_experts
INFO 01-13 08:46:40.827880.827880 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, eb551a15-2b45-4070-8039-db1ad385e05c
DEBUG 01-13 08:46:40.828768.828768 mlpmodule.py:1006] group tensors cost 0.004815816879272461 s
DEBUG 01-13 08:46:40.831981.831981 mlpmodule.py:1044] pad cost 0.0016121864318847656 s
DEBUG 01-13 08:46:40.831024.831024 mlpmodule.py:1050] create cpu tensor cost 4.9114227294921875e-05 s
DEBUG 01-13 08:46:40.831364.831364 mlpmodule.py:1055] move to cpu cost 3.62396240234375e-05 s
DEBUG 01-13 08:46:40.842328.842328 mlpmodule.py:1069] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-13 08:46:40.842482.842482 mlpmodule.py:1070] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-13 08:46:40.842635.842635 mlpmodule.py:1075] group_w3 first element: -0.0380859375
WARNING 01-13 08:46:40.842655.842655 mlpmodule.py:1085] start einsum2
DEBUG 01-13 08:46:40.859451.859451 mlpmodule.py:1095] group einsum cost 0.02760481834411621 s
DEBUG 01-13 08:46:40.859958.859958 mlpmodule.py:1103] cpy2cputensor cost 0.0006844997406005859 s
INFO 01-13 08:46:40.874509.874509 client.py:127] Model loaded
DEBUG 01-13 08:46:40.874487.874487 cuda_h.py:19] end wait_experts cost 0.04716300964355469 seconds
DEBUG 01-13 08:46:40.874342.874342 cuda_h.py:10] start gpu_experts
DEBUG 01-13 08:46:40.875194.875194 mlpmodule.py:559] gpu group tensors cost 0.0006289482116699219 s
DEBUG 01-13 08:46:40.877789.877789 mlpmodule.py:592] gpu pad cost 0.0018737316131591797 s
DEBUG 01-13 08:46:40.877375.877375 mlpmodule.py:598] start_w1
DEBUG 01-13 08:46:40.877010.877010 mlpmodule.py:602] start_w3
DEBUG 01-13 08:46:40.877108.877108 mlpmodule.py:608] start_w2
DEBUG 01-13 08:46:40.878618.878618 mlpmodule.py:611] gpu group einsum cost 0.0009160041809082031 s
DEBUG 01-13 08:46:40.880408.880408 mlpmodule.py:683] gpu experts func einsum cost 0.005808591842651367 s
DEBUG 01-13 08:46:40.880545.880545 cuda_h.py:19] end gpu_experts cost 0.006017923355102539 seconds
DEBUG 01-13 08:46:40.880731.880731 cuda_h.py:10] start cpu_thread_manager_mp_wait
DEBUG 01-13 08:46:40.880250.880250 cuda_h.py:19] end cpu_thread_manager_mp_wait cost 3.814697265625e-05 seconds
DEBUG 01-13 08:46:40.880643.880643 cuda_h.py:19] end layer_moe_generate_mp_l_3 cost 0.06274986267089844 seconds
DEBUG 01-13 08:46:40.881280.881280 lmp.py:1550] -------------------------------- end prefill layer 2 --------------------------------
DEBUG 01-13 08:46:40.881765.881765 lmp.py:1493] -------------------------------- start prefill layer 3 --------------------------------
DEBUG 01-13 08:46:40.881560.881560 cuda_h.py:10] start start_load_qkvogn_s_weight_l_4
DEBUG 01-13 08:46:40.881455.881455 cuda_h.py:10] start start_load_qkvogn_s_weight_l_4
DEBUG 01-13 08:46:40.881722.881722 cuda_h.py:19] end start_load_qkvogn_s_weight_l_4 cost 3.2901763916015625e-05 seconds
DEBUG 01-13 08:46:40.881730.881730 cuda_h.py:19] end start_load_qkvogn_s_weight_l_4 cost 7.677078247070312e-05 seconds
DEBUG 01-13 08:46:40.881088.881088 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-13 08:46:40.881144.881144 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-13 08:46:40.881961.881961 cuda_h.py:10] start sllm_worker_task
DEBUG 01-13 08:46:40.881421.881421 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-13 08:46:40.881780.881780 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-13 08:46:40.881331.881331 cuda_h.py:19] end allocate_cuda_memory cost 0.00019598007202148438 seconds
DEBUG 01-13 08:46:40.881208.881208 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-13 08:46:40.881779.881779 sllm_store_c.py:27] get device uuid map
DEBUG 01-13 08:46:40.881324.881324 sllm_store_c.py:29] call client load into gpu
DEBUG 01-13 08:46:40.881358.881358 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 6081b6e0-d91f-4270-8665-4bbb02b1bbb4
DEBUG 01-13 08:46:40.882665.882665 client.py:106] call stub.LoadModelAsync
DEBUG 01-13 08:46:40.882110.882110 cuda_h.py:10] start self_attn
INFO 01-13 08:46:40.883303.883303 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 6081b6e0-d91f-4270-8665-4bbb02b1bbb4
DEBUG 01-13 08:46:40.883570.883570 cuda_h.py:19] end load_into_gpu_async cost 0.0012850761413574219 seconds
DEBUG 01-13 08:46:40.883843.883843 cuda_h.py:10] start restore_tensors2
DEBUG 01-13 08:46:40.883826.883826 cuda_h.py:19] end restore_tensors2 cost 6.67572021484375e-05 seconds
DEBUG 01-13 08:46:40.883913.883913 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.001804351806640625 seconds
INFO 01-13 08:46:40.883941.883941 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 6081b6e0-d91f-4270-8665-4bbb02b1bbb4
DEBUG 01-13 08:46:40.885466.885466 mlpmodule.py:785]  experts func einsum cost 0.06105494499206543 s
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-13 08:46:40.885314.885314 cuda_h.py:19] end self_attn cost 0.0032846927642822266 seconds
DEBUG 01-13 08:46:40.885205.885205 cuda_h.py:19] end iln_self_attn_paln cost 0.004653215408325195 seconds
DEBUG 01-13 08:46:40.885949.885949 cuda_h.py:10] start layer_moe_generate_mp_l_4
DEBUG 01-13 08:46:40.885997.885997 cuda_h.py:10] start gate
DEBUG 01-13 08:46:40.886719.886719 cuda_h.py:19] end experts_func_gpu_einsum_mp cost 0.06299471855163574 seconds
DEBUG 01-13 08:46:40.886291.886291 cuda_h.py:19] end gate cost 0.0006396770477294922 seconds
DEBUG 01-13 08:46:40.886458.886458 cuda_h.py:10] start experts_map_get
DEBUG 01-13 08:46:40.887666.887666 lmp.py:1611] 
DEBUG 01-13 08:46:40.887666.887666 lmp.py:1611] Expert Token Distribution & Device Allocation:
DEBUG 01-13 08:46:40.887436.887436 lmp.py:1612]   Total experts: 64
DEBUG 01-13 08:46:40.887801.887801 lmp.py:1613]   CPU experts: 32 (50%)
DEBUG 01-13 08:46:40.887921.887921 lmp.py:1614]   GPU experts: 32 (50%)
DEBUG 01-13 08:46:40.887133.887133 lmp.py:1615] 
DEBUG 01-13 08:46:40.887133.887133 lmp.py:1615]   Expert ID | Tokens | Device
DEBUG 01-13 08:46:40.887823.887823 lmp.py:1616]   -----------------------------------
DEBUG 01-13 08:46:40.887996.887996 lmp.py:1622]   Expert  1 |     48 | CPU
DEBUG 01-13 08:46:40.887685.887685 lmp.py:1622]   Expert 27 |     62 | CPU
DEBUG 01-13 08:46:40.887421.887421 lmp.py:1622]   Expert  7 |     76 | CPU
DEBUG 01-13 08:46:40.887918.887918 lmp.py:1622]   Expert 48 |     79 | CPU
DEBUG 01-13 08:46:40.887415.887415 lmp.py:1622]   Expert 15 |    102 | CPU
DEBUG 01-13 08:46:40.887912.887912 lmp.py:1622]   Expert 30 |    109 | CPU
DEBUG 01-13 08:46:40.887125.887125 lmp.py:1622]   Expert 18 |    115 | CPU
DEBUG 01-13 08:46:40.887575.887575 lmp.py:1622]   Expert 45 |    117 | CPU
DEBUG 01-13 08:46:40.887788.887788 lmp.py:1622]   Expert 61 |    117 | CPU
DEBUG 01-13 08:46:40.887524.887524 lmp.py:1622]   Expert 32 |    120 | CPU
DEBUG 01-13 08:46:40.887498.887498 lmp.py:1622]   Expert  5 |    130 | CPU
DEBUG 01-13 08:46:40.887756.887756 lmp.py:1622]   Expert 34 |    132 | CPU
DEBUG 01-13 08:46:40.887254.887254 lmp.py:1622]   Expert 26 |    135 | CPU
DEBUG 01-13 08:46:40.887274.887274 lmp.py:1622]   Expert 11 |    140 | CPU
DEBUG 01-13 08:46:40.887771.887771 lmp.py:1622]   Expert  6 |    141 | CPU
DEBUG 01-13 08:46:40.887030.887030 lmp.py:1622]   Expert 39 |    141 | CPU
DEBUG 01-13 08:46:40.887527.887527 lmp.py:1622]   Expert 59 |    141 | CPU
DEBUG 01-13 08:46:40.887263.887263 lmp.py:1622]   Expert 36 |    143 | CPU
DEBUG 01-13 08:46:40.887522.887522 lmp.py:1622]   Expert 51 |    149 | CPU
DEBUG 01-13 08:46:40.887019.887019 lmp.py:1622]   Expert 23 |    152 | CPU
DEBUG 01-13 08:46:40.887754.887754 lmp.py:1622]   Expert 49 |    156 | CPU
DEBUG 01-13 08:46:40.887967.887967 lmp.py:1622]   Expert  2 |    162 | CPU
DEBUG 01-13 08:46:40.887941.887941 lmp.py:1622]   Expert  9 |    163 | CPU
DEBUG 01-13 08:46:40.887392.887392 lmp.py:1622]   Expert 40 |    163 | CPU
DEBUG 01-13 08:46:40.887366.887366 lmp.py:1622]   Expert 52 |    167 | CPU
DEBUG 01-13 08:46:40.887863.887863 lmp.py:1622]   Expert 56 |    167 | CPU
DEBUG 01-13 08:46:40.887122.887122 lmp.py:1622]   Expert 35 |    168 | CPU
DEBUG 01-13 08:46:40.887381.887381 lmp.py:1622]   Expert 50 |    168 | CPU
DEBUG 01-13 08:46:40.887878.887878 lmp.py:1622]   Expert 16 |    173 | CPU
DEBUG 01-13 08:46:40.887898.887898 lmp.py:1622]   Expert  4 |    181 | CPU
DEBUG 01-13 08:46:40.887919.887919 lmp.py:1622]   Expert 13 |    189 | CPU
DEBUG 01-13 08:46:40.887416.887416 lmp.py:1622]   Expert 37 |    189 | CPU
DEBUG 01-13 08:46:40.887436.887436 lmp.py:1622]   Expert 42 |    189 | GPU
DEBUG 01-13 08:46:40.887933.887933 lmp.py:1622]   Expert 17 |    195 | GPU
DEBUG 01-13 08:46:40.887431.887431 lmp.py:1622]   Expert 38 |    200 | GPU
DEBUG 01-13 08:46:40.887405.887405 lmp.py:1622]   Expert 62 |    200 | GPU
DEBUG 01-13 08:46:40.887140.887140 lmp.py:1622]   Expert 21 |    201 | GPU
DEBUG 01-13 08:46:40.887830.887830 lmp.py:1622]   Expert 44 |    204 | GPU
DEBUG 01-13 08:46:40.887280.887280 lmp.py:1622]   Expert 28 |    206 | GPU
DEBUG 01-13 08:46:40.887778.887778 lmp.py:1622]   Expert 60 |    209 | GPU
DEBUG 01-13 08:46:40.887036.887036 lmp.py:1622]   Expert  3 |    211 | GPU
DEBUG 01-13 08:46:40.887295.887295 lmp.py:1622]   Expert 58 |    214 | GPU
DEBUG 01-13 08:46:40.887554.887554 lmp.py:1622]   Expert 10 |    215 | GPU
DEBUG 01-13 08:46:40.887051.887051 lmp.py:1622]   Expert 47 |    218 | GPU
DEBUG 01-13 08:46:40.887548.887548 lmp.py:1622]   Expert 55 |    220 | GPU
DEBUG 01-13 08:46:40.887046.887046 lmp.py:1622]   Expert 53 |    221 | GPU
DEBUG 01-13 08:46:40.887543.887543 lmp.py:1622]   Expert 20 |    223 | GPU
DEBUG 01-13 08:46:40.887802.887802 lmp.py:1622]   Expert 57 |    225 | GPU
DEBUG 01-13 08:46:40.887822.887822 lmp.py:1622]   Expert 33 |    233 | GPU
DEBUG 01-13 08:46:40.887319.887319 lmp.py:1622]   Expert 46 |    236 | GPU
DEBUG 01-13 08:46:40.887532.887532 lmp.py:1622]   Expert  8 |    239 | GPU
DEBUG 01-13 08:46:40.887506.887506 lmp.py:1622]   Expert 31 |    241 | GPU
DEBUG 01-13 08:46:40.887241.887241 lmp.py:1622]   Expert 24 |    244 | GPU
DEBUG 01-13 08:46:40.887454.887454 lmp.py:1622]   Expert 19 |    246 | GPU
DEBUG 01-13 08:46:40.887474.887474 lmp.py:1622]   Expert 63 |    264 | GPU
DEBUG 01-13 08:46:40.888733.888733 lmp.py:1622]   Expert 14 |    270 | GPU
DEBUG 01-13 08:46:40.888753.888753 lmp.py:1622]   Expert 29 |    272 | GPU
DEBUG 01-13 08:46:40.888012.888012 lmp.py:1622]   Expert 12 |    278 | GPU
DEBUG 01-13 08:46:40.888271.888271 lmp.py:1622]   Expert 22 |    278 | GPU
DEBUG 01-13 08:46:40.888530.888530 lmp.py:1622]   Expert  0 |    287 | GPU
DEBUG 01-13 08:46:40.888027.888027 lmp.py:1622]   Expert 43 |    315 | GPU
DEBUG 01-13 08:46:40.888286.888286 lmp.py:1622]   Expert 54 |    343 | GPU
DEBUG 01-13 08:46:40.888498.888498 lmp.py:1622]   Expert 41 |    382 | GPU
DEBUG 01-13 08:46:40.888711.888711 lmp.py:1622]   Expert 25 |    414 | GPU
DEBUG 01-13 08:46:40.888354.888354 lmp.py:1623] 
DEBUG 01-13 08:46:40.888354.888354 lmp.py:1623]   CPU total tokens: 4395 (35.8%)
DEBUG 01-13 08:46:40.888712.888712 lmp.py:1624]   GPU total tokens: 7893 (64.2%)
DEBUG 01-13 08:46:40.888885.888885 cuda_h.py:19] end experts_map_get cost 0.001444101333618164 seconds
DEBUG 01-13 08:46:40.888350.888350 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-13 08:46:40.888822.888822 lmp.py:1632] 
DEBUG 01-13 08:46:40.888822.888822 lmp.py:1632]   Computing 32 experts on CPU MP...
DEBUG 01-13 08:46:40.888221.888221 cuda_h.py:19] end cpu_experts_submit cost 5.1021575927734375e-05 seconds
DEBUG 01-13 08:46:40.888414.888414 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-13 08:46:40.888171.888171 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-13 08:46:40.888924.888924 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-13 08:46:40.889976.889976 cuda_h.py:19] end allocate_cuda_memory cost 0.001125335693359375 seconds
DEBUG 01-13 08:46:40.889203.889203 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-13 08:46:40.889344.889344 sllm_store_c.py:27] get device uuid map
DEBUG 01-13 08:46:40.889273.889273 sllm_store_c.py:29] call client load into gpu
DEBUG 01-13 08:46:40.889783.889783 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 0c1349cf-887d-4c40-a448-1be09b5a81af
DEBUG 01-13 08:46:40.890558.890558 client.py:106] call stub.LoadModelAsync
INFO 01-13 08:46:40.890851.890851 client.py:127] Model loaded
DEBUG 01-13 08:46:40.890138.890138 cuda_h.py:10] start restore2model
INFO 01-13 08:46:40.891476.891476 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 0c1349cf-887d-4c40-a448-1be09b5a81af
DEBUG 01-13 08:46:40.891379.891379 cuda_h.py:19] end load_into_gpu_async cost 0.0012526512145996094 seconds
DEBUG 01-13 08:46:40.891466.891466 cuda_h.py:10] start restore_tensors2
DEBUG 01-13 08:46:40.891166.891166 cuda_h.py:10] start experts_func_gpu_einsum_mp
DEBUG 01-13 08:46:40.891513.891513 cuda_h.py:19] end restore_tensors2 cost 0.0003898143768310547 seconds
DEBUG 01-13 08:46:40.891185.891185 cuda_h.py:19] end restore2model cost 0.0009431838989257812 seconds
DEBUG 01-13 08:46:40.891669.891669 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.003175497055053711 seconds
DEBUG 01-13 08:46:40.891936.891936 cuda_h.py:19] end sllm_worker_task cost 0.010251998901367188 seconds
DEBUG 01-13 08:46:40.891448.891448 cuda_h.py:10] start restore2model
DEBUG 01-13 08:46:40.894615.894615 cuda_h.py:19] end restore2model cost 0.0027081966400146484 seconds
DEBUG 01-13 08:46:40.894358.894358 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.0062062740325927734 seconds
DEBUG 01-13 08:46:40.894174.894174 cuda_h.py:10] start gpu_sexperts
DEBUG 01-13 08:46:40.894105.894105 cuda_h.py:19] end gpu_sexperts cost 0.0002703666687011719 seconds
DEBUG 01-13 08:46:40.894980.894980 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-13 08:46:40.895426.895426 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 1.621246337890625e-05 seconds
DEBUG 01-13 08:46:40.895552.895552 cuda_h.py:10] start wait_experts
INFO 01-13 08:46:40.895871.895871 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 0c1349cf-887d-4c40-a448-1be09b5a81af
DEBUG 01-13 08:46:40.896336.896336 mlpmodule.py:1006] group tensors cost 0.004525184631347656 s
DEBUG 01-13 08:46:40.898451.898451 mlpmodule.py:1044] pad cost 0.0015180110931396484 s
DEBUG 01-13 08:46:40.899441.899441 mlpmodule.py:1050] create cpu tensor cost 4.363059997558594e-05 s
DEBUG 01-13 08:46:40.899052.899052 mlpmodule.py:1055] move to cpu cost 3.147125244140625e-05 s
DEBUG 01-13 08:46:40.908261.908261 mlpmodule.py:1069] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-13 08:46:40.909483.909483 mlpmodule.py:1070] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-13 08:46:40.909717.909717 mlpmodule.py:1075] group_w3 first element: -0.054931640625
WARNING 01-13 08:46:40.909852.909852 mlpmodule.py:1085] start einsum2
DEBUG 01-13 08:46:40.923972.923972 mlpmodule.py:1095] group einsum cost 0.024595975875854492 s
DEBUG 01-13 08:46:40.924647.924647 mlpmodule.py:1103] cpy2cputensor cost 0.0007371902465820312 s
INFO 01-13 08:46:40.941330.941330 client.py:127] Model loaded
DEBUG 01-13 08:46:40.941831.941831 cuda_h.py:19] end wait_experts cost 0.046441078186035156 seconds
DEBUG 01-13 08:46:40.941871.941871 cuda_h.py:10] start gpu_experts
DEBUG 01-13 08:46:40.942518.942518 mlpmodule.py:559] gpu group tensors cost 0.0006237030029296875 s
DEBUG 01-13 08:46:40.943021.943021 mlpmodule.py:592] gpu pad cost 0.0014951229095458984 s
DEBUG 01-13 08:46:40.943692.943692 mlpmodule.py:598] start_w1
DEBUG 01-13 08:46:40.944729.944729 mlpmodule.py:602] start_w3
DEBUG 01-13 08:46:40.944850.944850 mlpmodule.py:608] start_w2
DEBUG 01-13 08:46:40.944709.944709 mlpmodule.py:611] gpu group einsum cost 0.0007147789001464844 s
DEBUG 01-13 08:46:40.946864.946864 mlpmodule.py:683] gpu experts func einsum cost 0.005236625671386719 s
DEBUG 01-13 08:46:40.947267.947267 cuda_h.py:19] end gpu_experts cost 0.005463123321533203 seconds
DEBUG 01-13 08:46:40.947639.947639 cuda_h.py:10] start cpu_thread_manager_mp_wait
DEBUG 01-13 08:46:40.947297.947297 cuda_h.py:19] end cpu_thread_manager_mp_wait cost 3.790855407714844e-05 seconds
DEBUG 01-13 08:46:40.947405.947405 cuda_h.py:19] end layer_moe_generate_mp_l_4 cost 0.061260223388671875 seconds
DEBUG 01-13 08:46:40.947095.947095 lmp.py:1550] -------------------------------- end prefill layer 3 --------------------------------
DEBUG 01-13 08:46:40.947202.947202 lmp.py:1493] -------------------------------- start prefill layer 4 --------------------------------
DEBUG 01-13 08:46:40.947521.947521 cuda_h.py:10] start start_load_qkvogn_s_weight_l_5
DEBUG 01-13 08:46:40.947462.947462 cuda_h.py:10] start start_load_qkvogn_s_weight_l_5
DEBUG 01-13 08:46:40.947491.947491 cuda_h.py:19] end start_load_qkvogn_s_weight_l_5 cost 2.9802322387695312e-05 seconds
DEBUG 01-13 08:46:40.947591.947591 cuda_h.py:19] end start_load_qkvogn_s_weight_l_5 cost 7.462501525878906e-05 seconds
DEBUG 01-13 08:46:40.947234.947234 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-13 08:46:40.947992.947992 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-13 08:46:40.947425.947425 cuda_h.py:10] start sllm_worker_task
DEBUG 01-13 08:46:40.947885.947885 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-13 08:46:40.947814.947814 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-13 08:46:40.948240.948240 cuda_h.py:19] end allocate_cuda_memory cost 0.0002455711364746094 seconds
DEBUG 01-13 08:46:40.948541.948541 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-13 08:46:40.948158.948158 sllm_store_c.py:27] get device uuid map
DEBUG 01-13 08:46:40.948392.948392 sllm_store_c.py:29] call client load into gpu
DEBUG 01-13 08:46:40.948856.948856 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 790f1fdb-4f76-4e2f-bcd4-ac8d6b737ca5
DEBUG 01-13 08:46:40.948303.948303 client.py:106] call stub.LoadModelAsync
DEBUG 01-13 08:46:40.948132.948132 cuda_h.py:10] start self_attn
INFO 01-13 08:46:40.949966.949966 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 790f1fdb-4f76-4e2f-bcd4-ac8d6b737ca5
DEBUG 01-13 08:46:40.949518.949518 cuda_h.py:19] end load_into_gpu_async cost 0.0012469291687011719 seconds
DEBUG 01-13 08:46:40.949313.949313 cuda_h.py:10] start restore_tensors2
DEBUG 01-13 08:46:40.949488.949488 cuda_h.py:19] end restore_tensors2 cost 6.842613220214844e-05 seconds
DEBUG 01-13 08:46:40.949052.949052 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.001810312271118164 seconds
INFO 01-13 08:46:40.949611.949611 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 790f1fdb-4f76-4e2f-bcd4-ac8d6b737ca5
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-13 08:46:40.952099.952099 cuda_h.py:19] end self_attn cost 0.0033202171325683594 seconds
DEBUG 01-13 08:46:40.952402.952402 cuda_h.py:19] end iln_self_attn_paln cost 0.004762411117553711 seconds
DEBUG 01-13 08:46:40.952529.952529 cuda_h.py:10] start layer_moe_generate_mp_l_5
DEBUG 01-13 08:46:40.952862.952862 cuda_h.py:10] start gate
DEBUG 01-13 08:46:40.952617.952617 mlpmodule.py:785]  experts func einsum cost 0.06061434745788574 s
DEBUG 01-13 08:46:40.953915.953915 cuda_h.py:19] end gate cost 0.0007781982421875 seconds
DEBUG 01-13 08:46:40.953282.953282 cuda_h.py:10] start experts_map_get
DEBUG 01-13 08:46:40.953318.953318 lmp.py:1611] 
DEBUG 01-13 08:46:40.953318.953318 lmp.py:1611] Expert Token Distribution & Device Allocation:
DEBUG 01-13 08:46:40.953882.953882 lmp.py:1612]   Total experts: 64
DEBUG 01-13 08:46:40.953817.953817 lmp.py:1613]   CPU experts: 32 (50%)
DEBUG 01-13 08:46:40.953652.953652 lmp.py:1614]   GPU experts: 32 (50%)
DEBUG 01-13 08:46:40.953626.953626 lmp.py:1615] 
DEBUG 01-13 08:46:40.953626.953626 lmp.py:1615]   Expert ID | Tokens | Device
DEBUG 01-13 08:46:40.953315.953315 lmp.py:1616]   -----------------------------------
DEBUG 01-13 08:46:40.953726.953726 lmp.py:1622]   Expert 14 |     58 | CPU
DEBUG 01-13 08:46:40.953654.953654 lmp.py:1622]   Expert 57 |     71 | CPU
DEBUG 01-13 08:46:40.953867.953867 lmp.py:1622]   Expert 13 |     78 | CPU
DEBUG 01-13 08:46:40.953841.953841 lmp.py:1622]   Expert 26 |     84 | CPU
DEBUG 01-13 08:46:40.953338.953338 lmp.py:1622]   Expert 31 |     86 | CPU
DEBUG 01-13 08:46:40.953312.953312 lmp.py:1622]   Expert 54 |     90 | CPU
DEBUG 01-13 08:46:40.953240.953240 lmp.py:1622]   Expert 45 |     99 | CPU
DEBUG 01-13 08:46:40.953691.953691 lmp.py:1622]   Expert 11 |    100 | CPU
DEBUG 01-13 08:46:40.954141.954141 lmp.py:1622]   Expert 30 |    102 | CPU
DEBUG 01-13 08:46:40.954831.954831 lmp.py:1622]   Expert 58 |    105 | CPU
DEBUG 01-13 08:46:40.954282.954282 lmp.py:1622]   Expert 10 |    109 | CPU
DEBUG 01-13 08:46:40.954017.954017 lmp.py:1622]   Expert 51 |    109 | CPU
DEBUG 01-13 08:46:40.954230.954230 lmp.py:1622]   Expert 32 |    117 | CPU
DEBUG 01-13 08:46:40.954965.954965 lmp.py:1622]   Expert 36 |    119 | CPU
DEBUG 01-13 08:46:40.954939.954939 lmp.py:1622]   Expert  8 |    131 | CPU
DEBUG 01-13 08:46:40.954675.954675 lmp.py:1622]   Expert 20 |    131 | CPU
DEBUG 01-13 08:46:40.954172.954172 lmp.py:1622]   Expert 53 |    136 | CPU
DEBUG 01-13 08:46:40.954908.954908 lmp.py:1622]   Expert 63 |    139 | CPU
DEBUG 01-13 08:46:40.954405.954405 lmp.py:1622]   Expert 34 |    144 | CPU
DEBUG 01-13 08:46:40.954810.954810 lmp.py:1622]   Expert 61 |    144 | CPU
DEBUG 01-13 08:46:40.954214.954214 lmp.py:1622]   Expert 16 |    147 | CPU
DEBUG 01-13 08:46:40.954142.954142 lmp.py:1622]   Expert  4 |    148 | CPU
DEBUG 01-13 08:46:40.954546.954546 lmp.py:1622]   Expert 47 |    149 | CPU
DEBUG 01-13 08:46:40.954951.954951 lmp.py:1622]   Expert 60 |    156 | CPU
DEBUG 01-13 08:46:40.954402.954402 lmp.py:1622]   Expert 28 |    160 | CPU
DEBUG 01-13 08:46:40.954614.954614 lmp.py:1622]   Expert 42 |    162 | CPU
DEBUG 01-13 08:46:40.954065.954065 lmp.py:1622]   Expert 17 |    165 | CPU
DEBUG 01-13 08:46:40.954516.954516 lmp.py:1622]   Expert 27 |    171 | CPU
DEBUG 01-13 08:46:40.954205.954205 lmp.py:1622]   Expert 29 |    171 | CPU
DEBUG 01-13 08:46:40.954418.954418 lmp.py:1622]   Expert 44 |    178 | CPU
DEBUG 01-13 08:46:40.954107.954107 lmp.py:1622]   Expert  7 |    179 | CPU
DEBUG 01-13 08:46:40.954796.954796 lmp.py:1622]   Expert  2 |    180 | CPU
DEBUG 01-13 08:46:40.954247.954247 lmp.py:1622]   Expert 41 |    181 | GPU
DEBUG 01-13 08:46:40.954751.954751 lmp.py:1622]   Expert  9 |    182 | GPU
DEBUG 01-13 08:46:40.954202.954202 lmp.py:1622]   Expert 48 |    182 | GPU
DEBUG 01-13 08:46:40.954254.954254 cuda_h.py:19] end experts_func_gpu_einsum_mp cost 0.0630347728729248 seconds
DEBUG 01-13 08:46:40.954415.954415 lmp.py:1622]   Expert  3 |    184 | GPU
DEBUG 01-13 08:46:40.954342.954342 lmp.py:1622]   Expert 56 |    189 | GPU
DEBUG 01-13 08:46:40.954840.954840 lmp.py:1622]   Expert 15 |    190 | GPU
DEBUG 01-13 08:46:40.954814.954814 lmp.py:1622]   Expert  0 |    194 | GPU
DEBUG 01-13 08:46:40.954072.954072 lmp.py:1622]   Expert 24 |    199 | GPU
DEBUG 01-13 08:46:40.954808.954808 lmp.py:1622]   Expert 18 |    201 | GPU
DEBUG 01-13 08:46:40.954305.954305 lmp.py:1622]   Expert 22 |    209 | GPU
DEBUG 01-13 08:46:40.954803.954803 lmp.py:1622]   Expert 55 |    209 | GPU
DEBUG 01-13 08:46:40.954823.954823 lmp.py:1622]   Expert 40 |    212 | GPU
DEBUG 01-13 08:46:40.954559.954559 lmp.py:1622]   Expert 38 |    217 | GPU
DEBUG 01-13 08:46:40.954817.954817 lmp.py:1622]   Expert 23 |    219 | GPU
DEBUG 01-13 08:46:40.954553.954553 lmp.py:1622]   Expert  6 |    220 | GPU
DEBUG 01-13 08:46:40.954289.954289 lmp.py:1622]   Expert 37 |    222 | GPU
DEBUG 01-13 08:46:40.954501.954501 lmp.py:1622]   Expert 46 |    233 | GPU
DEBUG 01-13 08:46:40.954190.954190 lmp.py:1622]   Expert 19 |    248 | GPU
DEBUG 01-13 08:46:40.954164.954164 lmp.py:1622]   Expert 39 |    249 | GPU
DEBUG 01-13 08:46:40.954900.954900 lmp.py:1622]   Expert 25 |    250 | GPU
DEBUG 01-13 08:46:40.954159.954159 lmp.py:1622]   Expert 12 |    261 | GPU
DEBUG 01-13 08:46:40.954656.954656 lmp.py:1622]   Expert 62 |    266 | GPU
DEBUG 01-13 08:46:40.954915.954915 lmp.py:1622]   Expert 50 |    268 | GPU
DEBUG 01-13 08:46:40.954935.954935 lmp.py:1622]   Expert 35 |    276 | GPU
DEBUG 01-13 08:46:40.954956.954956 lmp.py:1622]   Expert 21 |    278 | GPU
DEBUG 01-13 08:46:40.954214.954214 lmp.py:1622]   Expert 49 |    288 | GPU
DEBUG 01-13 08:46:40.954235.954235 lmp.py:1622]   Expert 33 |    299 | GPU
DEBUG 01-13 08:46:40.954732.954732 lmp.py:1622]   Expert 52 |    304 | GPU
DEBUG 01-13 08:46:40.954229.954229 lmp.py:1622]   Expert  1 |    346 | GPU
DEBUG 01-13 08:46:40.954488.954488 lmp.py:1622]   Expert  5 |    380 | GPU
DEBUG 01-13 08:46:40.954747.954747 lmp.py:1622]   Expert 43 |    445 | GPU
DEBUG 01-13 08:46:40.954482.954482 lmp.py:1622]   Expert 59 |    569 | GPU
DEBUG 01-13 08:46:40.954887.954887 lmp.py:1623] 
DEBUG 01-13 08:46:40.954887.954887 lmp.py:1623]   CPU total tokens: 4118 (33.5%)
DEBUG 01-13 08:46:40.954768.954768 lmp.py:1624]   GPU total tokens: 8170 (66.5%)
DEBUG 01-13 08:46:40.954941.954941 cuda_h.py:19] end experts_map_get cost 0.0014755725860595703 seconds
DEBUG 01-13 08:46:40.955215.955215 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-13 08:46:40.955540.955540 lmp.py:1632] 
DEBUG 01-13 08:46:40.955540.955540 lmp.py:1632]   Computing 32 experts on CPU MP...
DEBUG 01-13 08:46:40.955509.955509 cuda_h.py:19] end cpu_experts_submit cost 4.792213439941406e-05 seconds
DEBUG 01-13 08:46:40.955271.955271 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-13 08:46:40.955863.955863 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-13 08:46:40.955569.955569 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-13 08:46:40.956449.956449 cuda_h.py:19] end allocate_cuda_memory cost 0.0007195472717285156 seconds
DEBUG 01-13 08:46:40.956530.956530 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-13 08:46:40.956809.956809 sllm_store_c.py:27] get device uuid map
DEBUG 01-13 08:46:40.956618.956618 sllm_store_c.py:29] call client load into gpu
DEBUG 01-13 08:46:40.956652.956652 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, d2c99ffc-b56c-4960-ad3d-728b1df64dd5
DEBUG 01-13 08:46:40.956454.956454 client.py:106] call stub.LoadModelAsync
INFO 01-13 08:46:40.956796.956796 client.py:127] Model loaded
DEBUG 01-13 08:46:40.957355.957355 cuda_h.py:10] start restore2model
DEBUG 01-13 08:46:40.957297.957297 cuda_h.py:19] end restore2model cost 0.0004105567932128906 seconds
DEBUG 01-13 08:46:40.957457.957457 cuda_h.py:19] end sllm_worker_task cost 0.009592533111572266 seconds
DEBUG 01-13 08:46:40.957359.957359 cuda_h.py:10] start experts_func_gpu_einsum_mp
INFO 01-13 08:46:40.957099.957099 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, d2c99ffc-b56c-4960-ad3d-728b1df64dd5
DEBUG 01-13 08:46:40.957942.957942 cuda_h.py:19] end load_into_gpu_async cost 0.001779794692993164 seconds
DEBUG 01-13 08:46:40.957691.957691 cuda_h.py:10] start restore_tensors2
DEBUG 01-13 08:46:40.958910.958910 cuda_h.py:19] end restore_tensors2 cost 0.0003800392150878906 seconds
DEBUG 01-13 08:46:40.958177.958177 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0032262802124023438 seconds
DEBUG 01-13 08:46:40.958847.958847 cuda_h.py:10] start restore2model
DEBUG 01-13 08:46:40.961310.961310 cuda_h.py:19] end restore2model cost 0.002728700637817383 seconds
DEBUG 01-13 08:46:40.961345.961345 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.006142377853393555 seconds
DEBUG 01-13 08:46:40.961903.961903 cuda_h.py:10] start gpu_sexperts
DEBUG 01-13 08:46:40.961131.961131 cuda_h.py:19] end gpu_sexperts cost 0.0002677440643310547 seconds
DEBUG 01-13 08:46:40.961769.961769 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-13 08:46:40.961730.961730 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 1.4781951904296875e-05 seconds
DEBUG 01-13 08:46:40.961996.961996 cuda_h.py:10] start wait_experts
INFO 01-13 08:46:40.961738.961738 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, d2c99ffc-b56c-4960-ad3d-728b1df64dd5
DEBUG 01-13 08:46:40.963530.963530 mlpmodule.py:1006] group tensors cost 0.00556635856628418 s
DEBUG 01-13 08:46:40.966416.966416 mlpmodule.py:1044] pad cost 0.0017349720001220703 s
DEBUG 01-13 08:46:40.966750.966750 mlpmodule.py:1050] create cpu tensor cost 4.6253204345703125e-05 s
DEBUG 01-13 08:46:40.966229.966229 mlpmodule.py:1055] move to cpu cost 3.457069396972656e-05 s
DEBUG 01-13 08:46:40.975678.975678 mlpmodule.py:1069] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-13 08:46:40.975214.975214 mlpmodule.py:1070] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-13 08:46:40.975979.975979 mlpmodule.py:1075] group_w3 first element: -0.039794921875
WARNING 01-13 08:46:40.975056.975056 mlpmodule.py:1085] start einsum2
DEBUG 01-13 08:46:40.988962.988962 mlpmodule.py:1095] group einsum cost 0.022402524948120117 s
DEBUG 01-13 08:46:40.989025.989025 mlpmodule.py:1103] cpy2cputensor cost 0.0006718635559082031 s
INFO 01-13 08:46:41.008145.008145 client.py:127] Model loaded
DEBUG 01-13 08:46:41.008871.008871 cuda_h.py:19] end wait_experts cost 0.04706382751464844 seconds
DEBUG 01-13 08:46:41.008488.008488 cuda_h.py:10] start gpu_experts
DEBUG 01-13 08:46:41.009240.009240 mlpmodule.py:559] gpu group tensors cost 0.0006017684936523438 s
DEBUG 01-13 08:46:41.011541.011541 mlpmodule.py:592] gpu pad cost 0.0018084049224853516 s
DEBUG 01-13 08:46:41.011823.011823 mlpmodule.py:598] start_w1
DEBUG 01-13 08:46:41.011617.011617 mlpmodule.py:602] start_w3
DEBUG 01-13 08:46:41.012808.012808 mlpmodule.py:608] start_w2
DEBUG 01-13 08:46:41.012595.012595 mlpmodule.py:611] gpu group einsum cost 0.0009169578552246094 s
DEBUG 01-13 08:46:41.014682.014682 mlpmodule.py:683] gpu experts func einsum cost 0.0057065486907958984 s
DEBUG 01-13 08:46:41.014427.014427 cuda_h.py:19] end gpu_experts cost 0.0058634281158447266 seconds
DEBUG 01-13 08:46:41.014799.014799 cuda_h.py:10] start cpu_thread_manager_mp_wait
DEBUG 01-13 08:46:41.014510.014510 cuda_h.py:19] end cpu_thread_manager_mp_wait cost 3.719329833984375e-05 seconds
DEBUG 01-13 08:46:41.014334.014334 cuda_h.py:19] end layer_moe_generate_mp_l_5 cost 0.06236004829406738 seconds
DEBUG 01-13 08:46:41.015725.015725 lmp.py:1550] -------------------------------- end prefill layer 4 --------------------------------
DEBUG 01-13 08:46:41.015448.015448 lmp.py:1493] -------------------------------- start prefill layer 5 --------------------------------
DEBUG 01-13 08:46:41.015767.015767 cuda_h.py:10] start start_load_qkvogn_s_weight_l_6
DEBUG 01-13 08:46:41.015900.015900 cuda_h.py:10] start start_load_qkvogn_s_weight_l_6
DEBUG 01-13 08:46:41.015591.015591 cuda_h.py:19] end start_load_qkvogn_s_weight_l_6 cost 2.8848648071289062e-05 seconds
DEBUG 01-13 08:46:41.015863.015863 cuda_h.py:19] end start_load_qkvogn_s_weight_l_6 cost 5.745887756347656e-05 seconds
DEBUG 01-13 08:46:41.015937.015937 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-13 08:46:41.015078.015078 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-13 08:46:41.015617.015617 mlpmodule.py:785]  experts func einsum cost 0.05723404884338379 s
DEBUG 01-13 08:46:41.015995.015995 cuda_h.py:10] start sllm_worker_task
DEBUG 01-13 08:46:41.015376.015376 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-13 08:46:41.015385.015385 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-13 08:46:41.015476.015476 cuda_h.py:19] end experts_func_gpu_einsum_mp cost 0.0581507682800293 seconds
DEBUG 01-13 08:46:41.015466.015466 cuda_h.py:19] end allocate_cuda_memory cost 0.00018930435180664062 seconds
DEBUG 01-13 08:46:41.016131.016131 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-13 08:46:41.016285.016285 sllm_store_c.py:27] get device uuid map
DEBUG 01-13 08:46:41.016929.016929 sllm_store_c.py:29] call client load into gpu
DEBUG 01-13 08:46:41.016069.016069 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, a5d9c0ca-ed56-42d8-82c7-b5c7d28d4a62
DEBUG 01-13 08:46:41.016629.016629 client.py:106] call stub.LoadModelAsync
DEBUG 01-13 08:46:41.016213.016213 cuda_h.py:10] start self_attn
INFO 01-13 08:46:41.017306.017306 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, a5d9c0ca-ed56-42d8-82c7-b5c7d28d4a62
DEBUG 01-13 08:46:41.017183.017183 cuda_h.py:19] end load_into_gpu_async cost 0.001291513442993164 seconds
DEBUG 01-13 08:46:41.017038.017038 cuda_h.py:10] start restore_tensors2
DEBUG 01-13 08:46:41.017525.017525 cuda_h.py:19] end restore_tensors2 cost 7.867813110351562e-05 seconds
DEBUG 01-13 08:46:41.017580.017580 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0018870830535888672 seconds
INFO 01-13 08:46:41.017827.017827 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, a5d9c0ca-ed56-42d8-82c7-b5c7d28d4a62
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-13 08:46:41.019072.019072 cuda_h.py:19] end self_attn cost 0.0028488636016845703 seconds
DEBUG 01-13 08:46:41.019088.019088 cuda_h.py:19] end iln_self_attn_paln cost 0.004294633865356445 seconds
DEBUG 01-13 08:46:41.019355.019355 cuda_h.py:10] start layer_moe_generate_mp_l_6
DEBUG 01-13 08:46:41.019449.019449 cuda_h.py:10] start gate
DEBUG 01-13 08:46:41.020836.020836 cuda_h.py:19] end gate cost 0.0006380081176757812 seconds
DEBUG 01-13 08:46:41.020380.020380 cuda_h.py:10] start experts_map_get
DEBUG 01-13 08:46:41.020205.020205 lmp.py:1611] 
DEBUG 01-13 08:46:41.020205.020205 lmp.py:1611] Expert Token Distribution & Device Allocation:
DEBUG 01-13 08:46:41.020769.020769 lmp.py:1612]   Total experts: 64
DEBUG 01-13 08:46:41.020895.020895 lmp.py:1613]   CPU experts: 32 (50%)
DEBUG 01-13 08:46:41.020445.020445 lmp.py:1614]   GPU experts: 32 (50%)
DEBUG 01-13 08:46:41.020327.020327 lmp.py:1615] 
DEBUG 01-13 08:46:41.020327.020327 lmp.py:1615]   Expert ID | Tokens | Device
DEBUG 01-13 08:46:41.020731.020731 lmp.py:1616]   -----------------------------------
DEBUG 01-13 08:46:41.020143.020143 lmp.py:1622]   Expert 34 |     22 | CPU
DEBUG 01-13 08:46:41.020024.020024 lmp.py:1622]   Expert 45 |     61 | CPU
DEBUG 01-13 08:46:41.020190.020190 lmp.py:1622]   Expert 22 |     74 | CPU
DEBUG 01-13 08:46:41.020549.020549 lmp.py:1622]   Expert 57 |     80 | CPU
DEBUG 01-13 08:46:41.020430.020430 lmp.py:1622]   Expert 17 |     91 | CPU
DEBUG 01-13 08:46:41.020834.020834 lmp.py:1622]   Expert  4 |     99 | CPU
DEBUG 01-13 08:46:41.020001.020001 lmp.py:1622]   Expert 15 |    103 | CPU
DEBUG 01-13 08:46:41.021405.021405 lmp.py:1622]   Expert 28 |    104 | CPU
DEBUG 01-13 08:46:41.021333.021333 lmp.py:1622]   Expert 32 |    117 | CPU
DEBUG 01-13 08:46:41.021691.021691 lmp.py:1622]   Expert 60 |    117 | CPU
DEBUG 01-13 08:46:41.021572.021572 lmp.py:1622]   Expert 52 |    122 | CPU
DEBUG 01-13 08:46:41.021454.021454 lmp.py:1622]   Expert 36 |    127 | CPU
DEBUG 01-13 08:46:41.021574.021574 lmp.py:1622]   Expert 14 |    129 | CPU
DEBUG 01-13 08:46:41.021740.021740 lmp.py:1622]   Expert 16 |    131 | CPU
DEBUG 01-13 08:46:41.021668.021668 lmp.py:1622]   Expert 25 |    132 | CPU
DEBUG 01-13 08:46:41.021834.021834 lmp.py:1622]   Expert  2 |    134 | CPU
DEBUG 01-13 08:46:41.021761.021761 lmp.py:1622]   Expert 12 |    135 | CPU
DEBUG 01-13 08:46:41.021928.021928 lmp.py:1622]   Expert  8 |    137 | CPU
DEBUG 01-13 08:46:41.021855.021855 lmp.py:1622]   Expert  5 |    139 | CPU
DEBUG 01-13 08:46:41.021021.021021 lmp.py:1622]   Expert 35 |    142 | CPU
DEBUG 01-13 08:46:41.021188.021188 lmp.py:1622]   Expert 23 |    155 | CPU
DEBUG 01-13 08:46:41.021354.021354 lmp.py:1622]   Expert 61 |    155 | CPU
DEBUG 01-13 08:46:41.021235.021235 lmp.py:1622]   Expert 30 |    158 | CPU
DEBUG 01-13 08:46:41.021593.021593 lmp.py:1622]   Expert  0 |    159 | CPU
DEBUG 01-13 08:46:41.021475.021475 lmp.py:1622]   Expert 39 |    163 | CPU
DEBUG 01-13 08:46:41.021833.021833 lmp.py:1622]   Expert 42 |    163 | CPU
DEBUG 01-13 08:46:41.021999.021999 lmp.py:1622]   Expert 13 |    168 | CPU
DEBUG 01-13 08:46:41.021165.021165 lmp.py:1622]   Expert 44 |    173 | CPU
DEBUG 01-13 08:46:41.021331.021331 lmp.py:1622]   Expert 46 |    174 | CPU
DEBUG 01-13 08:46:41.021497.021497 lmp.py:1622]   Expert  3 |    176 | CPU
DEBUG 01-13 08:46:41.021425.021425 lmp.py:1622]   Expert 41 |    178 | CPU
DEBUG 01-13 08:46:41.021591.021591 lmp.py:1622]   Expert  9 |    179 | CPU
DEBUG 01-13 08:46:41.021757.021757 lmp.py:1622]   Expert 31 |    179 | GPU
DEBUG 01-13 08:46:41.021924.021924 lmp.py:1622]   Expert 43 |    184 | GPU
DEBUG 01-13 08:46:41.021090.021090 lmp.py:1622]   Expert 27 |    186 | GPU
DEBUG 01-13 08:46:41.021256.021256 lmp.py:1622]   Expert 62 |    190 | GPU
DEBUG 01-13 08:46:41.021376.021376 lmp.py:1622]   Expert 18 |    191 | GPU
DEBUG 01-13 08:46:41.021734.021734 lmp.py:1622]   Expert 26 |    191 | GPU
DEBUG 01-13 08:46:41.021092.021092 lmp.py:1622]   Expert 49 |    193 | GPU
DEBUG 01-13 08:46:41.021450.021450 lmp.py:1622]   Expert 51 |    194 | GPU
DEBUG 01-13 08:46:41.021332.021332 lmp.py:1622]   Expert 50 |    196 | GPU
DEBUG 01-13 08:46:41.021928.021928 lmp.py:1622]   Expert 11 |    199 | GPU
DEBUG 01-13 08:46:41.021823.021823 lmp.py:1622]   Expert 47 |    201 | GPU
DEBUG 01-13 08:46:41.021513.021513 lmp.py:1622]   Expert 19 |    203 | GPU
DEBUG 01-13 08:46:41.021202.021202 lmp.py:1622]   Expert 20 |    205 | GPU
DEBUG 01-13 08:46:41.021130.021130 lmp.py:1622]   Expert 63 |    205 | GPU
DEBUG 01-13 08:46:41.021581.021581 lmp.py:1622]   Expert 55 |    206 | GPU
DEBUG 01-13 08:46:41.021031.021031 lmp.py:1622]   Expert 56 |    207 | GPU
DEBUG 01-13 08:46:41.021721.021721 lmp.py:1622]   Expert 38 |    216 | GPU
DEBUG 01-13 08:46:41.021172.021172 lmp.py:1622]   Expert 48 |    227 | GPU
DEBUG 01-13 08:46:41.021861.021861 lmp.py:1622]   Expert  1 |    233 | GPU
DEBUG 01-13 08:46:41.021504.021504 lmp.py:1622]   Expert 10 |    238 | GPU
DEBUG 01-13 08:46:41.021147.021147 lmp.py:1622]   Expert  7 |    242 | GPU
DEBUG 01-13 08:46:41.021028.021028 lmp.py:1622]   Expert 54 |    244 | GPU
DEBUG 01-13 08:46:41.021671.021671 lmp.py:1622]   Expert 21 |    256 | GPU
DEBUG 01-13 08:46:41.021076.021076 lmp.py:1622]   Expert 29 |    260 | GPU
DEBUG 01-13 08:46:41.021719.021719 lmp.py:1622]   Expert 33 |    263 | GPU
DEBUG 01-13 08:46:41.021077.021077 lmp.py:1622]   Expert 40 |    263 | GPU
DEBUG 01-13 08:46:41.021766.021766 lmp.py:1622]   Expert 24 |    272 | GPU
DEBUG 01-13 08:46:41.021694.021694 lmp.py:1622]   Expert 59 |    291 | GPU
DEBUG 01-13 08:46:41.021383.021383 lmp.py:1622]   Expert 37 |    342 | GPU
DEBUG 01-13 08:46:41.021834.021834 lmp.py:1622]   Expert 58 |    367 | GPU
DEBUG 01-13 08:46:41.021808.021808 lmp.py:1622]   Expert  6 |    381 | GPU
DEBUG 01-13 08:46:41.021259.021259 lmp.py:1622]   Expert 53 |    866 | GPU
DEBUG 01-13 08:46:41.022664.022664 lmp.py:1623] 
DEBUG 01-13 08:46:41.022664.022664 lmp.py:1623]   CPU total tokens: 4197 (34.2%)
DEBUG 01-13 08:46:41.022068.022068 lmp.py:1624]   GPU total tokens: 8091 (65.8%)
DEBUG 01-13 08:46:41.022003.022003 cuda_h.py:19] end experts_map_get cost 0.001554250717163086 seconds
DEBUG 01-13 08:46:41.022230.022230 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-13 08:46:41.022986.022986 lmp.py:1632] 
DEBUG 01-13 08:46:41.022986.022986 lmp.py:1632]   Computing 32 experts on CPU MP...
DEBUG 01-13 08:46:41.022292.022292 cuda_h.py:19] end cpu_experts_submit cost 5.030632019042969e-05 seconds
DEBUG 01-13 08:46:41.022009.022009 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-13 08:46:41.022792.022792 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-13 08:46:41.022313.022313 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-13 08:46:41.023908.023908 cuda_h.py:19] end allocate_cuda_memory cost 0.0011065006256103516 seconds
DEBUG 01-13 08:46:41.023692.023692 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-13 08:46:41.023117.023117 sllm_store_c.py:27] get device uuid map
DEBUG 01-13 08:46:41.023026.023026 sllm_store_c.py:29] call client load into gpu
DEBUG 01-13 08:46:41.023344.023344 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 9918ba4f-c548-41e4-b60c-a9799e4a7f19
DEBUG 01-13 08:46:41.023450.023450 client.py:106] call stub.LoadModelAsync
DEBUG 01-13 08:46:41.024556.024556 cuda_h.py:10] start experts_func_gpu_einsum_mp
INFO 01-13 08:46:41.025788.025788 client.py:127] Model loaded
DEBUG 01-13 08:46:41.025512.025512 cuda_h.py:10] start restore2model
DEBUG 01-13 08:46:41.025188.025188 cuda_h.py:19] end restore2model cost 0.0005495548248291016 seconds
DEBUG 01-13 08:46:41.025800.025800 cuda_h.py:19] end sllm_worker_task cost 0.010290384292602539 seconds
INFO 01-13 08:46:41.026528.026528 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 9918ba4f-c548-41e4-b60c-a9799e4a7f19
DEBUG 01-13 08:46:41.026993.026993 cuda_h.py:19] end load_into_gpu_async cost 0.0024335384368896484 seconds
DEBUG 01-13 08:46:41.026696.026696 cuda_h.py:10] start restore_tensors2
DEBUG 01-13 08:46:41.026464.026464 cuda_h.py:19] end restore_tensors2 cost 0.0003638267517089844 seconds
DEBUG 01-13 08:46:41.026976.026976 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.004288911819458008 seconds
DEBUG 01-13 08:46:41.026362.026362 cuda_h.py:10] start restore2model
DEBUG 01-13 08:46:41.029472.029472 cuda_h.py:19] end restore2model cost 0.002680063247680664 seconds
DEBUG 01-13 08:46:41.029600.029600 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.007154703140258789 seconds
DEBUG 01-13 08:46:41.029442.029442 cuda_h.py:10] start gpu_sexperts
DEBUG 01-13 08:46:41.029671.029671 cuda_h.py:19] end gpu_sexperts cost 0.00027680397033691406 seconds
DEBUG 01-13 08:46:41.029070.029070 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-13 08:46:41.029078.029078 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 1.3828277587890625e-05 seconds
DEBUG 01-13 08:46:41.029536.029536 cuda_h.py:10] start wait_experts
INFO 01-13 08:46:41.029947.029947 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 9918ba4f-c548-41e4-b60c-a9799e4a7f19
DEBUG 01-13 08:46:41.035581.035581 mlpmodule.py:1006] group tensors cost 0.009828805923461914 s
DEBUG 01-13 08:46:41.037331.037331 mlpmodule.py:1044] pad cost 0.0015614032745361328 s
DEBUG 01-13 08:46:41.037574.037574 mlpmodule.py:1050] create cpu tensor cost 4.38690185546875e-05 s
DEBUG 01-13 08:46:41.037231.037231 mlpmodule.py:1055] move to cpu cost 3.0994415283203125e-05 s
DEBUG 01-13 08:46:41.047282.047282 mlpmodule.py:1069] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-13 08:46:41.047804.047804 mlpmodule.py:1070] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-13 08:46:41.047590.047590 mlpmodule.py:1075] group_w3 first element: 0.03369140625
WARNING 01-13 08:46:41.047576.047576 mlpmodule.py:1085] start einsum2
DEBUG 01-13 08:46:41.061456.061456 mlpmodule.py:1095] group einsum cost 0.023434877395629883 s
DEBUG 01-13 08:46:41.062162.062162 mlpmodule.py:1103] cpy2cputensor cost 0.0006868839263916016 s
INFO 01-13 08:46:41.077189.077189 client.py:127] Model loaded
DEBUG 01-13 08:46:41.077233.077233 cuda_h.py:19] end wait_experts cost 0.0476992130279541 seconds
DEBUG 01-13 08:46:41.077658.077658 cuda_h.py:10] start gpu_experts
DEBUG 01-13 08:46:41.078140.078140 mlpmodule.py:559] gpu group tensors cost 0.0006396770477294922 s
DEBUG 01-13 08:46:41.080858.080858 mlpmodule.py:592] gpu pad cost 0.0017921924591064453 s
DEBUG 01-13 08:46:41.080331.080331 mlpmodule.py:598] start_w1
DEBUG 01-13 08:46:41.081706.081706 mlpmodule.py:602] start_w3
DEBUG 01-13 08:46:41.081459.081459 mlpmodule.py:608] start_w2
DEBUG 01-13 08:46:41.081517.081517 mlpmodule.py:611] gpu group einsum cost 0.0013985633850097656 s
DEBUG 01-13 08:46:41.083771.083771 mlpmodule.py:683] gpu experts func einsum cost 0.0060253143310546875 s
DEBUG 01-13 08:46:41.083210.083210 cuda_h.py:19] end gpu_experts cost 0.006175041198730469 seconds
DEBUG 01-13 08:46:41.083867.083867 cuda_h.py:10] start cpu_thread_manager_mp_wait
DEBUG 01-13 08:46:41.083194.083194 cuda_h.py:19] end cpu_thread_manager_mp_wait cost 3.8623809814453125e-05 seconds
DEBUG 01-13 08:46:41.083726.083726 cuda_h.py:19] end layer_moe_generate_mp_l_6 cost 0.06425261497497559 seconds
DEBUG 01-13 08:46:41.084395.084395 lmp.py:1550] -------------------------------- end prefill layer 5 --------------------------------
DEBUG 01-13 08:46:41.084119.084119 lmp.py:1493] -------------------------------- start prefill layer 6 --------------------------------
DEBUG 01-13 08:46:41.084484.084484 cuda_h.py:10] start start_load_qkvogn_s_weight_l_7
DEBUG 01-13 08:46:41.084425.084425 cuda_h.py:10] start start_load_qkvogn_s_weight_l_7
DEBUG 01-13 08:46:41.084546.084546 cuda_h.py:19] end start_load_qkvogn_s_weight_l_7 cost 3.147125244140625e-05 seconds
DEBUG 01-13 08:46:41.084434.084434 cuda_h.py:19] end start_load_qkvogn_s_weight_l_7 cost 5.745887756347656e-05 seconds
DEBUG 01-13 08:46:41.084899.084899 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-13 08:46:41.084915.084915 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-13 08:46:41.084593.084593 cuda_h.py:10] start sllm_worker_task
DEBUG 01-13 08:46:41.084788.084788 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-13 08:46:41.084101.084101 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-13 08:46:41.085665.085665 mlpmodule.py:785]  experts func einsum cost 0.06021690368652344 s
DEBUG 01-13 08:46:41.085249.085249 cuda_h.py:19] end experts_func_gpu_einsum_mp cost 0.06097698211669922 seconds
DEBUG 01-13 08:46:41.108636.108636 cuda_h.py:19] end allocate_cuda_memory cost 0.02361297607421875 seconds
DEBUG 01-13 08:46:41.108627.108627 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-13 08:46:41.108868.108868 sllm_store_c.py:27] get device uuid map
DEBUG 01-13 08:46:41.108930.108930 sllm_store_c.py:29] call client load into gpu
DEBUG 01-13 08:46:41.108859.108859 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 475989f8-6367-435d-9df2-c4cd331afd68
DEBUG 01-13 08:46:41.108626.108626 client.py:106] call stub.LoadModelAsync
DEBUG 01-13 08:46:41.109239.109239 cuda_h.py:10] start self_attn
INFO 01-13 08:46:41.110683.110683 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 475989f8-6367-435d-9df2-c4cd331afd68
DEBUG 01-13 08:46:41.110050.110050 cuda_h.py:19] end load_into_gpu_async cost 0.001889944076538086 seconds
DEBUG 01-13 08:46:41.110549.110549 cuda_h.py:10] start restore_tensors2
DEBUG 01-13 08:46:41.110727.110727 cuda_h.py:19] end restore_tensors2 cost 0.00011444091796875 seconds
DEBUG 01-13 08:46:41.110378.110378 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.026061296463012695 seconds
INFO 01-13 08:46:41.110348.110348 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 475989f8-6367-435d-9df2-c4cd331afd68
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-13 08:46:41.116223.116223 cuda_h.py:19] end self_attn cost 0.006891012191772461 seconds
DEBUG 01-13 08:46:41.117991.117991 cuda_h.py:19] end iln_self_attn_paln cost 0.03257894515991211 seconds
DEBUG 01-13 08:46:41.117186.117186 cuda_h.py:10] start layer_moe_generate_mp_l_7
DEBUG 01-13 08:46:41.117573.117573 cuda_h.py:10] start gate
DEBUG 01-13 08:46:41.118709.118709 cuda_h.py:19] end gate cost 0.0010128021240234375 seconds
DEBUG 01-13 08:46:41.118599.118599 cuda_h.py:10] start experts_map_get
DEBUG 01-13 08:46:41.119017.119017 lmp.py:1611] 
DEBUG 01-13 08:46:41.119017.119017 lmp.py:1611] Expert Token Distribution & Device Allocation:
DEBUG 01-13 08:46:41.119358.119358 lmp.py:1612]   Total experts: 64
DEBUG 01-13 08:46:41.119724.119724 lmp.py:1613]   CPU experts: 32 (50%)
DEBUG 01-13 08:46:41.119500.119500 lmp.py:1614]   GPU experts: 32 (50%)
DEBUG 01-13 08:46:41.119508.119508 lmp.py:1615] 
DEBUG 01-13 08:46:41.119508.119508 lmp.py:1615]   Expert ID | Tokens | Device
DEBUG 01-13 08:46:41.119232.119232 lmp.py:1616]   -----------------------------------
DEBUG 01-13 08:46:41.119922.119922 lmp.py:1622]   Expert  1 |     44 | CPU
DEBUG 01-13 08:46:41.119122.119122 lmp.py:1622]   Expert  7 |     55 | CPU
DEBUG 01-13 08:46:41.119607.119607 lmp.py:1622]   Expert 37 |     75 | CPU
DEBUG 01-13 08:46:41.119377.119377 lmp.py:1622]   Expert 17 |     79 | CPU
DEBUG 01-13 08:46:41.119385.119385 lmp.py:1622]   Expert 54 |     79 | CPU
DEBUG 01-13 08:46:41.119962.119962 lmp.py:1622]   Expert 18 |     82 | CPU
DEBUG 01-13 08:46:41.119301.119301 lmp.py:1622]   Expert  9 |     90 | CPU
DEBUG 01-13 08:46:41.119640.119640 lmp.py:1622]   Expert 13 |     97 | CPU
DEBUG 01-13 08:46:41.119887.119887 lmp.py:1622]   Expert 58 |    101 | CPU
DEBUG 01-13 08:46:41.119941.119941 lmp.py:1622]   Expert 22 |    104 | CPU
DEBUG 01-13 08:46:41.119518.119518 lmp.py:1622]   Expert  0 |    106 | CPU
DEBUG 01-13 08:46:41.119096.119096 lmp.py:1622]   Expert 16 |    115 | CPU
DEBUG 01-13 08:46:41.119912.119912 lmp.py:1622]   Expert 26 |    121 | CPU
DEBUG 01-13 08:46:41.119489.119489 lmp.py:1622]   Expert 63 |    125 | CPU
DEBUG 01-13 08:46:41.119782.119782 lmp.py:1622]   Expert 10 |    128 | CPU
DEBUG 01-13 08:46:41.119836.119836 lmp.py:1622]   Expert 59 |    136 | CPU
DEBUG 01-13 08:46:41.119699.119699 lmp.py:1622]   Expert 33 |    139 | CPU
DEBUG 01-13 08:46:41.120322.120322 lmp.py:1622]   Expert 28 |    147 | CPU
DEBUG 01-13 08:46:41.120661.120661 lmp.py:1622]   Expert 43 |    147 | CPU
DEBUG 01-13 08:46:41.120524.120524 lmp.py:1622]   Expert 62 |    147 | CPU
DEBUG 01-13 08:46:41.120578.120578 lmp.py:1622]   Expert  2 |    155 | CPU
DEBUG 01-13 08:46:41.120155.120155 lmp.py:1622]   Expert 29 |    155 | CPU
DEBUG 01-13 08:46:41.120495.120495 lmp.py:1622]   Expert  3 |    159 | CPU
DEBUG 01-13 08:46:41.120880.120880 lmp.py:1622]   Expert 55 |    164 | CPU
DEBUG 01-13 08:46:41.120696.120696 lmp.py:1622]   Expert 45 |    165 | CPU
DEBUG 01-13 08:46:41.120512.120512 lmp.py:1622]   Expert 51 |    166 | CPU
DEBUG 01-13 08:46:41.120851.120851 lmp.py:1622]   Expert 53 |    166 | CPU
DEBUG 01-13 08:46:41.120588.120588 lmp.py:1622]   Expert 23 |    168 | CPU
DEBUG 01-13 08:46:41.120165.120165 lmp.py:1622]   Expert 14 |    169 | CPU
DEBUG 01-13 08:46:41.120027.120027 lmp.py:1622]   Expert 32 |    169 | CPU
DEBUG 01-13 08:46:41.120890.120890 lmp.py:1622]   Expert 11 |    170 | CPU
DEBUG 01-13 08:46:41.120182.120182 lmp.py:1622]   Expert 40 |    171 | CPU
DEBUG 01-13 08:46:41.120237.120237 lmp.py:1622]   Expert 34 |    173 | GPU
DEBUG 01-13 08:46:41.120622.120622 lmp.py:1622]   Expert 41 |    179 | GPU
DEBUG 01-13 08:46:41.120246.120246 lmp.py:1622]   Expert 52 |    179 | GPU
DEBUG 01-13 08:46:41.120870.120870 lmp.py:1622]   Expert 57 |    186 | GPU
DEBUG 01-13 08:46:41.120209.120209 lmp.py:1622]   Expert 42 |    189 | GPU
DEBUG 01-13 08:46:41.120548.120548 lmp.py:1622]   Expert 21 |    193 | GPU
DEBUG 01-13 08:46:41.120364.120364 lmp.py:1622]   Expert 35 |    204 | GPU
DEBUG 01-13 08:46:41.120464.120464 lmp.py:1622]   Expert 15 |    205 | GPU
DEBUG 01-13 08:46:41.120565.120565 lmp.py:1622]   Expert 30 |    205 | GPU
DEBUG 01-13 08:46:41.120712.120712 lmp.py:1622]   Expert 12 |    213 | GPU
DEBUG 01-13 08:46:41.120336.120336 lmp.py:1622]   Expert  4 |    221 | GPU
DEBUG 01-13 08:46:41.121152.121152 lmp.py:1622]   Expert 46 |    225 | GPU
DEBUG 01-13 08:46:41.121491.121491 lmp.py:1622]   Expert 50 |    228 | GPU
DEBUG 01-13 08:46:41.121353.121353 lmp.py:1622]   Expert 24 |    230 | GPU
DEBUG 01-13 08:46:41.121977.121977 lmp.py:1622]   Expert  8 |    233 | GPU
DEBUG 01-13 08:46:41.121601.121601 lmp.py:1622]   Expert 44 |    234 | GPU
DEBUG 01-13 08:46:41.121986.121986 lmp.py:1622]   Expert 49 |    235 | GPU
DEBUG 01-13 08:46:41.121895.121895 lmp.py:1622]   Expert 38 |    241 | GPU
DEBUG 01-13 08:46:41.121995.121995 lmp.py:1622]   Expert 19 |    246 | GPU
DEBUG 01-13 08:46:41.121871.121871 lmp.py:1622]   Expert 61 |    247 | GPU
DEBUG 01-13 08:46:41.121972.121972 lmp.py:1622]   Expert 31 |    248 | GPU
DEBUG 01-13 08:46:41.121595.121595 lmp.py:1622]   Expert  6 |    249 | GPU
DEBUG 01-13 08:46:41.121504.121504 lmp.py:1622]   Expert 47 |    251 | GPU
DEBUG 01-13 08:46:41.121320.121320 lmp.py:1622]   Expert 39 |    278 | GPU
DEBUG 01-13 08:46:41.121136.121136 lmp.py:1622]   Expert 36 |    291 | GPU
DEBUG 01-13 08:46:41.121760.121760 lmp.py:1622]   Expert  5 |    299 | GPU
DEBUG 01-13 08:46:41.121860.121860 lmp.py:1622]   Expert 27 |    319 | GPU
DEBUG 01-13 08:46:41.121292.121292 lmp.py:1622]   Expert 60 |    335 | GPU
DEBUG 01-13 08:46:41.121631.121631 lmp.py:1622]   Expert 20 |    340 | GPU
DEBUG 01-13 08:46:41.121970.121970 lmp.py:1622]   Expert 48 |    366 | GPU
DEBUG 01-13 08:46:41.121355.121355 lmp.py:1622]   Expert 25 |    390 | GPU
DEBUG 01-13 08:46:41.121979.121979 lmp.py:1622]   Expert 56 |    562 | GPU
DEBUG 01-13 08:46:41.121749.121749 lmp.py:1623] 
DEBUG 01-13 08:46:41.121749.121749 lmp.py:1623]   CPU total tokens: 4094 (33.3%)
DEBUG 01-13 08:46:41.121711.121711 lmp.py:1624]   GPU total tokens: 8194 (66.7%)
DEBUG 01-13 08:46:41.121971.121971 cuda_h.py:19] end experts_map_get cost 0.003513813018798828 seconds
INFO 01-13 08:46:41.122334.122334 client.py:127] Model loaded
DEBUG 01-13 08:46:41.122901.122901 cuda_h.py:10] start restore2model
DEBUG 01-13 08:46:41.123480.123480 cuda_h.py:19] end restore2model cost 0.0009624958038330078 seconds
DEBUG 01-13 08:46:41.123536.123536 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-13 08:46:41.123678.123678 cuda_h.py:19] end sllm_worker_task cost 0.03881692886352539 seconds
DEBUG 01-13 08:46:41.123105.123105 lmp.py:1632] 
DEBUG 01-13 08:46:41.123105.123105 lmp.py:1632]   Computing 32 experts on CPU MP...
DEBUG 01-13 08:46:41.123529.123529 cuda_h.py:19] end cpu_experts_submit cost 0.00021076202392578125 seconds
DEBUG 01-13 08:46:41.123643.123643 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-13 08:46:41.123501.123501 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-13 08:46:41.124628.124628 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-13 08:46:41.124946.124946 cuda_h.py:19] end allocate_cuda_memory cost 0.0003256797790527344 seconds
DEBUG 01-13 08:46:41.125428.125428 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-13 08:46:41.125947.125947 sllm_store_c.py:27] get device uuid map
DEBUG 01-13 08:46:41.125188.125188 sllm_store_c.py:29] call client load into gpu
DEBUG 01-13 08:46:41.125732.125732 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, a9fb00dc-e409-40ab-8581-6b1455937df0
DEBUG 01-13 08:46:41.125234.125234 client.py:106] call stub.LoadModelAsync
DEBUG 01-13 08:46:41.125906.125906 cuda_h.py:10] start experts_func_gpu_einsum_mp
INFO 01-13 08:46:41.127972.127972 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, a9fb00dc-e409-40ab-8581-6b1455937df0
DEBUG 01-13 08:46:41.127285.127285 cuda_h.py:19] end load_into_gpu_async cost 0.002396106719970703 seconds
DEBUG 01-13 08:46:41.127988.127988 cuda_h.py:10] start restore_tensors2
DEBUG 01-13 08:46:41.128042.128042 cuda_h.py:19] end restore_tensors2 cost 0.0003974437713623047 seconds
DEBUG 01-13 08:46:41.128885.128885 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0040967464447021484 seconds
DEBUG 01-13 08:46:41.128271.128271 cuda_h.py:10] start restore2model
DEBUG 01-13 08:46:41.131203.131203 cuda_h.py:19] end restore2model cost 0.002902984619140625 seconds
DEBUG 01-13 08:46:41.131762.131762 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.007239818572998047 seconds
DEBUG 01-13 08:46:41.131511.131511 cuda_h.py:10] start gpu_sexperts
DEBUG 01-13 08:46:41.131124.131124 cuda_h.py:19] end gpu_sexperts cost 0.0002799034118652344 seconds
DEBUG 01-13 08:46:41.131576.131576 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-13 08:46:41.131459.131459 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.3365020751953125e-05 seconds
DEBUG 01-13 08:46:41.131300.131300 cuda_h.py:10] start wait_experts
INFO 01-13 08:46:41.131050.131050 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, a9fb00dc-e409-40ab-8581-6b1455937df0
DEBUG 01-13 08:46:41.142793.142793 mlpmodule.py:1006] group tensors cost 0.015650510787963867 s
DEBUG 01-13 08:46:41.145517.145517 mlpmodule.py:1044] pad cost 0.0020956993103027344 s
DEBUG 01-13 08:46:41.145541.145541 mlpmodule.py:1050] create cpu tensor cost 5.53131103515625e-05 s
DEBUG 01-13 08:46:41.145656.145656 mlpmodule.py:1055] move to cpu cost 3.9577484130859375e-05 s
DEBUG 01-13 08:46:41.154365.154365 mlpmodule.py:1069] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-13 08:46:41.154312.154312 mlpmodule.py:1070] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-13 08:46:41.155660.155660 mlpmodule.py:1075] group_w3 first element: -0.003631591796875
WARNING 01-13 08:46:41.155764.155764 mlpmodule.py:1085] start einsum2
DEBUG 01-13 08:46:41.168914.168914 mlpmodule.py:1095] group einsum cost 0.023237228393554688 s
DEBUG 01-13 08:46:41.169469.169469 mlpmodule.py:1103] cpy2cputensor cost 0.0006911754608154297 s
INFO 01-13 08:46:41.179836.179836 client.py:127] Model loaded
DEBUG 01-13 08:46:41.179491.179491 cuda_h.py:19] end wait_experts cost 0.04756641387939453 seconds
DEBUG 01-13 08:46:41.179730.179730 cuda_h.py:10] start gpu_experts
DEBUG 01-13 08:46:41.180898.180898 mlpmodule.py:559] gpu group tensors cost 0.0007522106170654297 s
DEBUG 01-13 08:46:41.182733.182733 mlpmodule.py:592] gpu pad cost 0.0019125938415527344 s
DEBUG 01-13 08:46:41.182411.182411 mlpmodule.py:598] start_w1
DEBUG 01-13 08:46:41.182186.182186 mlpmodule.py:602] start_w3
DEBUG 01-13 08:46:41.182087.182087 mlpmodule.py:608] start_w2
DEBUG 01-13 08:46:41.182418.182418 mlpmodule.py:611] gpu group einsum cost 0.0008111000061035156 s
DEBUG 01-13 08:46:41.185295.185295 mlpmodule.py:683] gpu experts func einsum cost 0.0062749385833740234 s
DEBUG 01-13 08:46:41.185379.185379 cuda_h.py:19] end gpu_experts cost 0.00648808479309082 seconds
DEBUG 01-13 08:46:41.185704.185704 cuda_h.py:10] start cpu_thread_manager_mp_wait
DEBUG 01-13 08:46:41.185892.185892 cuda_h.py:19] end cpu_thread_manager_mp_wait cost 4.00543212890625e-05 seconds
DEBUG 01-13 08:46:41.185670.185670 cuda_h.py:19] end layer_moe_generate_mp_l_7 cost 0.06876564025878906 seconds
DEBUG 01-13 08:46:41.186850.186850 lmp.py:1550] -------------------------------- end prefill layer 6 --------------------------------
DEBUG 01-13 08:46:41.186527.186527 lmp.py:1493] -------------------------------- start prefill layer 7 --------------------------------
DEBUG 01-13 08:46:41.186561.186561 cuda_h.py:10] start start_load_qkvogn_s_weight_l_8
DEBUG 01-13 08:46:41.186456.186456 cuda_h.py:10] start start_load_qkvogn_s_weight_l_8
DEBUG 01-13 08:46:41.186484.186484 cuda_h.py:19] end start_load_qkvogn_s_weight_l_8 cost 3.24249267578125e-05 seconds
DEBUG 01-13 08:46:41.186950.186950 cuda_h.py:10] start sllm_worker_task
DEBUG 01-13 08:46:41.186726.186726 cuda_h.py:19] end start_load_qkvogn_s_weight_l_8 cost 0.00014090538024902344 seconds
DEBUG 01-13 08:46:41.186358.186358 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-13 08:46:41.186366.186366 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-13 08:46:41.186977.186977 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-13 08:46:41.187116.187116 cuda_h.py:19] end allocate_cuda_memory cost 0.0003001689910888672 seconds
DEBUG 01-13 08:46:41.187967.187967 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-13 08:46:41.187658.187658 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-13 08:46:41.187740.187740 sllm_store_c.py:27] get device uuid map
DEBUG 01-13 08:46:41.187186.187186 sllm_store_c.py:29] call client load into gpu
DEBUG 01-13 08:46:41.187888.187888 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 88e9e0e6-6c60-4893-a9bb-e522aad060cf
DEBUG 01-13 08:46:41.187481.187481 client.py:106] call stub.LoadModelAsync
DEBUG 01-13 08:46:41.187854.187854 cuda_h.py:10] start self_attn
INFO 01-13 08:46:41.188646.188646 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 88e9e0e6-6c60-4893-a9bb-e522aad060cf
DEBUG 01-13 08:46:41.188675.188675 cuda_h.py:19] end load_into_gpu_async cost 0.0016026496887207031 seconds
DEBUG 01-13 08:46:41.188007.188007 cuda_h.py:10] start restore_tensors2
DEBUG 01-13 08:46:41.189573.189573 cuda_h.py:19] end restore_tensors2 cost 7.200241088867188e-05 seconds
DEBUG 01-13 08:46:41.189852.189852 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.002424001693725586 seconds
INFO 01-13 08:46:41.189013.189013 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 88e9e0e6-6c60-4893-a9bb-e522aad060cf
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-13 08:46:41.190125.190125 cuda_h.py:19] end self_attn cost 0.0028781890869140625 seconds
DEBUG 01-13 08:46:41.190261.190261 cuda_h.py:19] end iln_self_attn_paln cost 0.00426936149597168 seconds
DEBUG 01-13 08:46:41.191150.191150 cuda_h.py:10] start layer_moe_generate_mp_l_8
DEBUG 01-13 08:46:41.191959.191959 cuda_h.py:10] start gate
DEBUG 01-13 08:46:41.191393.191393 cuda_h.py:19] end gate cost 0.000637054443359375 seconds
DEBUG 01-13 08:46:41.191984.191984 cuda_h.py:10] start experts_map_get
DEBUG 01-13 08:46:41.192616.192616 lmp.py:1611] 
DEBUG 01-13 08:46:41.192616.192616 lmp.py:1611] Expert Token Distribution & Device Allocation:
DEBUG 01-13 08:46:41.192180.192180 lmp.py:1612]   Total experts: 64
DEBUG 01-13 08:46:41.192876.192876 lmp.py:1613]   CPU experts: 32 (50%)
DEBUG 01-13 08:46:41.192817.192817 lmp.py:1614]   GPU experts: 32 (50%)
DEBUG 01-13 08:46:41.192937.192937 lmp.py:1615] 
DEBUG 01-13 08:46:41.192937.192937 lmp.py:1615]   Expert ID | Tokens | Device
DEBUG 01-13 08:46:41.192818.192818 lmp.py:1616]   -----------------------------------
DEBUG 01-13 08:46:41.192468.192468 lmp.py:1622]   Expert 50 |     45 | CPU
DEBUG 01-13 08:46:41.192634.192634 lmp.py:1622]   Expert  3 |     54 | CPU
DEBUG 01-13 08:46:41.192847.192847 lmp.py:1622]   Expert 46 |     55 | CPU
DEBUG 01-13 08:46:41.192059.192059 lmp.py:1622]   Expert  1 |     72 | CPU
DEBUG 01-13 08:46:41.192510.192510 lmp.py:1622]   Expert 29 |     85 | CPU
DEBUG 01-13 08:46:41.192246.192246 lmp.py:1622]   Expert  4 |     88 | CPU
DEBUG 01-13 08:46:41.192743.192743 lmp.py:1622]   Expert 15 |     94 | CPU
DEBUG 01-13 08:46:41.192479.192479 lmp.py:1622]   Expert 40 |     94 | CPU
DEBUG 01-13 08:46:41.192453.192453 lmp.py:1622]   Expert  8 |    106 | CPU
DEBUG 01-13 08:46:41.192950.192950 lmp.py:1622]   Expert 41 |    115 | CPU
DEBUG 01-13 08:46:41.192639.192639 lmp.py:1622]   Expert 28 |    117 | CPU
DEBUG 01-13 08:46:41.192328.192328 lmp.py:1622]   Expert 54 |    126 | CPU
DEBUG 01-13 08:46:41.192747.192747 lmp.py:1622]   Expert 16 |    128 | CPU
DEBUG 01-13 08:46:41.192125.192125 lmp.py:1622]   Expert  6 |    130 | CPU
DEBUG 01-13 08:46:41.192814.192814 lmp.py:1622]   Expert 13 |    131 | CPU
DEBUG 01-13 08:46:41.192981.192981 lmp.py:1622]   Expert 48 |    131 | CPU
DEBUG 01-13 08:46:41.192670.192670 lmp.py:1622]   Expert  7 |    133 | CPU
DEBUG 01-13 08:46:41.192359.192359 lmp.py:1622]   Expert 27 |    135 | CPU
DEBUG 01-13 08:46:41.192810.192810 lmp.py:1622]   Expert 14 |    139 | CPU
DEBUG 01-13 08:46:41.192022.192022 lmp.py:1622]   Expert 18 |    139 | CPU
DEBUG 01-13 08:46:41.192950.192950 lmp.py:1622]   Expert 51 |    139 | CPU
DEBUG 01-13 08:46:41.192401.192401 lmp.py:1622]   Expert 56 |    140 | CPU
DEBUG 01-13 08:46:41.192329.192329 lmp.py:1622]   Expert 60 |    140 | CPU
DEBUG 01-13 08:46:41.192018.192018 lmp.py:1622]   Expert 20 |    144 | CPU
DEBUG 01-13 08:46:41.192138.192138 lmp.py:1622]   Expert 39 |    146 | CPU
DEBUG 01-13 08:46:41.192258.192258 lmp.py:1622]   Expert 36 |    147 | CPU
DEBUG 01-13 08:46:41.192662.192662 lmp.py:1622]   Expert 52 |    148 | CPU
DEBUG 01-13 08:46:41.192828.192828 lmp.py:1622]   Expert 55 |    149 | CPU
DEBUG 01-13 08:46:41.192518.192518 lmp.py:1622]   Expert 43 |    152 | CPU
DEBUG 01-13 08:46:41.192445.192445 lmp.py:1622]   Expert 10 |    156 | CPU
DEBUG 01-13 08:46:41.192896.192896 lmp.py:1622]   Expert 45 |    158 | CPU
DEBUG 01-13 08:46:41.192062.192062 lmp.py:1622]   Expert  5 |    159 | CPU
DEBUG 01-13 08:46:41.192229.192229 lmp.py:1622]   Expert 11 |    160 | GPU
DEBUG 01-13 08:46:41.192918.192918 lmp.py:1622]   Expert 62 |    167 | GPU
DEBUG 01-13 08:46:41.192846.192846 lmp.py:1622]   Expert 33 |    176 | GPU
DEBUG 01-13 08:46:41.192535.192535 lmp.py:1622]   Expert 57 |    176 | GPU
DEBUG 01-13 08:46:41.192463.192463 lmp.py:1622]   Expert 44 |    177 | GPU
DEBUG 01-13 08:46:41.192914.192914 lmp.py:1622]   Expert 25 |    181 | GPU
DEBUG 01-13 08:46:41.192603.192603 lmp.py:1622]   Expert 58 |    181 | GPU
DEBUG 01-13 08:46:41.192442.192442 mlpmodule.py:785]  experts func einsum cost 0.06592226028442383 s
DEBUG 01-13 08:46:41.192531.192531 lmp.py:1622]   Expert 53 |    186 | GPU
DEBUG 01-13 08:46:41.192988.192988 lmp.py:1622]   Expert 32 |    191 | GPU
DEBUG 01-13 08:46:41.192393.192393 lmp.py:1622]   Expert 31 |    193 | GPU
DEBUG 01-13 08:46:41.192797.192797 lmp.py:1622]   Expert  2 |    197 | GPU
DEBUG 01-13 08:46:41.192010.192010 lmp.py:1622]   Expert 35 |    197 | GPU
DEBUG 01-13 08:46:41.192984.192984 lmp.py:1622]   Expert 49 |    201 | GPU
DEBUG 01-13 08:46:41.192481.192481 lmp.py:1622]   Expert 21 |    210 | GPU
DEBUG 01-13 08:46:41.192455.192455 lmp.py:1622]   Expert 63 |    210 | GPU
DEBUG 01-13 08:46:41.193191.193191 lmp.py:1622]   Expert 17 |    212 | GPU
DEBUG 01-13 08:46:41.193165.193165 lmp.py:1622]   Expert 34 |    216 | GPU
DEBUG 01-13 08:46:41.193139.193139 lmp.py:1622]   Expert 42 |    219 | GPU
DEBUG 01-13 08:46:41.193113.193113 lmp.py:1622]   Expert 37 |    226 | GPU
DEBUG 01-13 08:46:41.193087.193087 lmp.py:1622]   Expert 59 |    235 | GPU
DEBUG 01-13 08:46:41.193061.193061 lmp.py:1622]   Expert 22 |    243 | GPU
DEBUG 01-13 08:46:41.193373.193373 lmp.py:1622]   Expert  0 |    249 | GPU
DEBUG 01-13 08:46:41.193539.193539 lmp.py:1622]   Expert 19 |    261 | GPU
DEBUG 01-13 08:46:41.193851.193851 lmp.py:1622]   Expert 61 |    279 | GPU
DEBUG 01-13 08:46:41.193063.193063 lmp.py:1622]   Expert 24 |    283 | GPU
DEBUG 01-13 08:46:41.193561.193561 lmp.py:1622]   Expert 30 |    296 | GPU
DEBUG 01-13 08:46:41.193535.193535 lmp.py:1622]   Expert 47 |    323 | GPU
DEBUG 01-13 08:46:41.193509.193509 lmp.py:1622]   Expert 38 |    364 | GPU
DEBUG 01-13 08:46:41.193006.193006 lmp.py:1622]   Expert 26 |    370 | GPU
DEBUG 01-13 08:46:41.193980.193980 lmp.py:1622]   Expert 12 |    432 | GPU
DEBUG 01-13 08:46:41.193716.193716 lmp.py:1622]   Expert  9 |    667 | GPU
DEBUG 01-13 08:46:41.193690.193690 lmp.py:1622]   Expert 23 |    715 | GPU
DEBUG 01-13 08:46:41.193617.193617 lmp.py:1623] 
DEBUG 01-13 08:46:41.193617.193617 lmp.py:1623]   CPU total tokens: 3895 (31.7%)
DEBUG 01-13 08:46:41.193022.193022 lmp.py:1624]   GPU total tokens: 8393 (68.3%)
DEBUG 01-13 08:46:41.193718.193718 cuda_h.py:19] end experts_map_get cost 0.0015323162078857422 seconds
DEBUG 01-13 08:46:41.193507.193507 cuda_h.py:19] end experts_func_gpu_einsum_mp cost 0.06739306449890137 seconds
DEBUG 01-13 08:46:41.193329.193329 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-13 08:46:41.193801.193801 lmp.py:1632] 
DEBUG 01-13 08:46:41.193801.193801 lmp.py:1632]   Computing 32 experts on CPU MP...
DEBUG 01-13 08:46:41.193584.193584 cuda_h.py:19] end cpu_experts_submit cost 5.1021575927734375e-05 seconds
DEBUG 01-13 08:46:41.193088.193088 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-13 08:46:41.193964.193964 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-13 08:46:41.193299.193299 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-13 08:46:41.195390.195390 cuda_h.py:10] start experts_func_gpu_einsum_mp
DEBUG 01-13 08:46:41.196976.196976 cuda_h.py:19] end allocate_cuda_memory cost 0.002069234848022461 seconds
DEBUG 01-13 08:46:41.196110.196110 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-13 08:46:41.196734.196734 sllm_store_c.py:27] get device uuid map
DEBUG 01-13 08:46:41.196689.196689 sllm_store_c.py:29] call client load into gpu
DEBUG 01-13 08:46:41.196485.196485 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 0c298721-b1ed-42e9-9f72-9fd161a80dfa
DEBUG 01-13 08:46:41.196094.196094 client.py:106] call stub.LoadModelAsync
INFO 01-13 08:46:41.196269.196269 client.py:127] Model loaded
DEBUG 01-13 08:46:41.196350.196350 cuda_h.py:10] start restore2model
DEBUG 01-13 08:46:41.197452.197452 cuda_h.py:19] end restore2model cost 0.0004215240478515625 seconds
DEBUG 01-13 08:46:41.197805.197805 cuda_h.py:19] end sllm_worker_task cost 0.010978460311889648 seconds
INFO 01-13 08:46:41.198115.198115 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 0c298721-b1ed-42e9-9f72-9fd161a80dfa
DEBUG 01-13 08:46:41.198104.198104 cuda_h.py:19] end load_into_gpu_async cost 0.0023415088653564453 seconds
DEBUG 01-13 08:46:41.198522.198522 cuda_h.py:10] start restore_tensors2
DEBUG 01-13 08:46:41.198324.198324 cuda_h.py:19] end restore_tensors2 cost 0.00038743019104003906 seconds
DEBUG 01-13 08:46:41.199306.199306 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0054607391357421875 seconds
DEBUG 01-13 08:46:41.199692.199692 cuda_h.py:10] start restore2model
DEBUG 01-13 08:46:41.201279.201279 cuda_h.py:19] end restore2model cost 0.002682924270629883 seconds
DEBUG 01-13 08:46:41.201784.201784 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.008322000503540039 seconds
DEBUG 01-13 08:46:41.201818.201818 cuda_h.py:10] start gpu_sexperts
DEBUG 01-13 08:46:41.201747.201747 mlpmodule.py:1006] group tensors cost 0.005592823028564453 s
DEBUG 01-13 08:46:41.202557.202557 cuda_h.py:19] end gpu_sexperts cost 0.0002682209014892578 seconds
DEBUG 01-13 08:46:41.202479.202479 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-13 08:46:41.202772.202772 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 1.430511474609375e-05 seconds
DEBUG 01-13 08:46:41.202276.202276 cuda_h.py:10] start wait_experts
INFO 01-13 08:46:41.202733.202733 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 0c298721-b1ed-42e9-9f72-9fd161a80dfa
DEBUG 01-13 08:46:41.203703.203703 mlpmodule.py:1044] pad cost 0.0020155906677246094 s
DEBUG 01-13 08:46:41.204435.204435 mlpmodule.py:1050] create cpu tensor cost 5.221366882324219e-05 s
DEBUG 01-13 08:46:41.204544.204544 mlpmodule.py:1055] move to cpu cost 3.743171691894531e-05 s
DEBUG 01-13 08:46:41.211955.211955 mlpmodule.py:1069] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-13 08:46:41.211401.211401 mlpmodule.py:1070] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-13 08:46:41.212931.212931 mlpmodule.py:1075] group_w3 first element: 0.01263427734375
WARNING 01-13 08:46:41.212775.212775 mlpmodule.py:1085] start einsum2
DEBUG 01-13 08:46:41.225189.225189 mlpmodule.py:1095] group einsum cost 0.021348953247070312 s
DEBUG 01-13 08:46:41.226364.226364 mlpmodule.py:1103] cpy2cputensor cost 0.0006577968597412109 s
DEBUG 01-13 08:46:41.249724.249724 mlpmodule.py:785]  experts func einsum cost 0.05397653579711914 s
INFO 01-13 08:46:41.249347.249347 client.py:127] Model loaded
DEBUG 01-13 08:46:41.249047.249047 cuda_h.py:19] end wait_experts cost 0.047510623931884766 seconds
DEBUG 01-13 08:46:41.249233.249233 cuda_h.py:10] start gpu_experts
DEBUG 01-13 08:46:41.250277.250277 cuda_h.py:19] end experts_func_gpu_einsum_mp cost 0.05486273765563965 seconds
DEBUG 01-13 08:46:41.250355.250355 mlpmodule.py:559] gpu group tensors cost 0.0005922317504882812 s
DEBUG 01-13 08:46:41.252166.252166 mlpmodule.py:592] gpu pad cost 0.001789093017578125 s
DEBUG 01-13 08:46:41.252122.252122 mlpmodule.py:598] start_w1
DEBUG 01-13 08:46:41.252874.252874 mlpmodule.py:602] start_w3
DEBUG 01-13 08:46:41.252774.252774 mlpmodule.py:608] start_w2
DEBUG 01-13 08:46:41.253520.253520 mlpmodule.py:611] gpu group einsum cost 0.0006103515625 s
DEBUG 01-13 08:46:41.255940.255940 mlpmodule.py:683] gpu experts func einsum cost 0.005204677581787109 s
DEBUG 01-13 08:46:41.255810.255810 cuda_h.py:19] end gpu_experts cost 0.0053517818450927734 seconds
DEBUG 01-13 08:46:41.255752.255752 cuda_h.py:10] start cpu_thread_manager_mp_wait
DEBUG 01-13 08:46:41.255741.255741 cuda_h.py:19] end cpu_thread_manager_mp_wait cost 3.6716461181640625e-05 seconds
DEBUG 01-13 08:46:41.255227.255227 cuda_h.py:19] end layer_moe_generate_mp_l_8 cost 0.06435179710388184 seconds
DEBUG 01-13 08:46:41.255141.255141 lmp.py:1550] -------------------------------- end prefill layer 7 --------------------------------
DEBUG 01-13 08:46:41.255103.255103 lmp.py:1493] -------------------------------- start prefill layer 8 --------------------------------
DEBUG 01-13 08:46:41.255706.255706 cuda_h.py:10] start start_load_qkvogn_s_weight_l_9
DEBUG 01-13 08:46:41.255648.255648 cuda_h.py:10] start start_load_qkvogn_s_weight_l_9
DEBUG 01-13 08:46:41.255100.255100 cuda_h.py:19] end start_load_qkvogn_s_weight_l_9 cost 2.9802322387695312e-05 seconds
DEBUG 01-13 08:46:41.255200.255200 cuda_h.py:19] end start_load_qkvogn_s_weight_l_9 cost 7.176399230957031e-05 seconds
DEBUG 01-13 08:46:41.255605.255605 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-13 08:46:41.255362.255362 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-13 08:46:41.255802.255802 cuda_h.py:10] start sllm_worker_task
DEBUG 01-13 08:46:41.256553.256553 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-13 08:46:41.256105.256105 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-13 08:46:41.256763.256763 cuda_h.py:19] end allocate_cuda_memory cost 0.00022530555725097656 seconds
DEBUG 01-13 08:46:41.256872.256872 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-13 08:46:41.256681.256681 sllm_store_c.py:27] get device uuid map
DEBUG 01-13 08:46:41.256358.256358 sllm_store_c.py:29] call client load into gpu
DEBUG 01-13 08:46:41.256153.256153 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 9b492496-090d-4661-993e-a5f8c3a81bac
DEBUG 01-13 08:46:41.256097.256097 client.py:106] call stub.LoadModelAsync
DEBUG 01-13 08:46:41.256582.256582 cuda_h.py:10] start self_attn
INFO 01-13 08:46:41.257219.257219 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 9b492496-090d-4661-993e-a5f8c3a81bac
DEBUG 01-13 08:46:41.257288.257288 cuda_h.py:19] end load_into_gpu_async cost 0.0013229846954345703 seconds
DEBUG 01-13 08:46:41.257144.257144 cuda_h.py:10] start restore_tensors2
DEBUG 01-13 08:46:41.257207.257207 cuda_h.py:19] end restore_tensors2 cost 8.249282836914062e-05 seconds
DEBUG 01-13 08:46:41.258162.258162 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0019228458404541016 seconds
INFO 01-13 08:46:41.258535.258535 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 9b492496-090d-4661-993e-a5f8c3a81bac
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-13 08:46:41.259519.259519 cuda_h.py:19] end self_attn cost 0.002805471420288086 seconds
DEBUG 01-13 08:46:41.260642.260642 cuda_h.py:19] end iln_self_attn_paln cost 0.00424504280090332 seconds
DEBUG 01-13 08:46:41.260863.260863 cuda_h.py:10] start layer_moe_generate_mp_l_9
DEBUG 01-13 08:46:41.260764.260764 cuda_h.py:10] start gate
DEBUG 01-13 08:46:41.260463.260463 cuda_h.py:19] end gate cost 0.0006568431854248047 seconds
DEBUG 01-13 08:46:41.260008.260008 cuda_h.py:10] start experts_map_get
DEBUG 01-13 08:46:41.261376.261376 lmp.py:1611] 
DEBUG 01-13 08:46:41.261376.261376 lmp.py:1611] Expert Token Distribution & Device Allocation:
DEBUG 01-13 08:46:41.261178.261178 lmp.py:1612]   Total experts: 64
DEBUG 01-13 08:46:41.261112.261112 lmp.py:1613]   CPU experts: 32 (50%)
DEBUG 01-13 08:46:41.261186.261186 lmp.py:1614]   GPU experts: 32 (50%)
DEBUG 01-13 08:46:41.261306.261306 lmp.py:1615] 
DEBUG 01-13 08:46:41.261306.261306 lmp.py:1615]   Expert ID | Tokens | Device
DEBUG 01-13 08:46:41.261949.261949 lmp.py:1616]   -----------------------------------
DEBUG 01-13 08:46:41.261791.261791 lmp.py:1622]   Expert 38 |      8 | CPU
DEBUG 01-13 08:46:41.261434.261434 lmp.py:1622]   Expert 39 |     69 | CPU
DEBUG 01-13 08:46:41.261646.261646 lmp.py:1622]   Expert  7 |     70 | CPU
DEBUG 01-13 08:46:41.261766.261766 lmp.py:1622]   Expert 30 |     74 | CPU
DEBUG 01-13 08:46:41.261217.261217 lmp.py:1622]   Expert 24 |     86 | CPU
DEBUG 01-13 08:46:41.261906.261906 lmp.py:1622]   Expert 27 |     91 | CPU
DEBUG 01-13 08:46:41.261595.261595 lmp.py:1622]   Expert 14 |     93 | CPU
DEBUG 01-13 08:46:41.261523.261523 lmp.py:1622]   Expert 36 |     97 | CPU
DEBUG 01-13 08:46:41.261212.261212 lmp.py:1622]   Expert 17 |     99 | CPU
DEBUG 01-13 08:46:41.261902.261902 lmp.py:1622]   Expert 32 |     99 | CPU
DEBUG 01-13 08:46:41.261829.261829 lmp.py:1622]   Expert 16 |    100 | CPU
DEBUG 01-13 08:46:41.261711.261711 lmp.py:1622]   Expert 40 |    109 | CPU
DEBUG 01-13 08:46:41.261069.261069 lmp.py:1622]   Expert 18 |    113 | CPU
DEBUG 01-13 08:46:41.261427.261427 lmp.py:1622]   Expert 12 |    114 | CPU
DEBUG 01-13 08:46:41.261593.261593 lmp.py:1622]   Expert 48 |    114 | CPU
DEBUG 01-13 08:46:41.261759.261759 lmp.py:1622]   Expert  1 |    119 | CPU
DEBUG 01-13 08:46:41.261210.261210 lmp.py:1622]   Expert  6 |    131 | CPU
DEBUG 01-13 08:46:41.261900.261900 lmp.py:1622]   Expert 42 |    133 | CPU
DEBUG 01-13 08:46:41.261589.261589 lmp.py:1622]   Expert 59 |    139 | CPU
DEBUG 01-13 08:46:41.261517.261517 lmp.py:1622]   Expert  0 |    142 | CPU
DEBUG 01-13 08:46:41.261968.261968 lmp.py:1622]   Expert 53 |    142 | CPU
DEBUG 01-13 08:46:41.261418.261418 lmp.py:1622]   Expert 22 |    148 | CPU
DEBUG 01-13 08:46:41.261869.261869 lmp.py:1622]   Expert 51 |    149 | CPU
DEBUG 01-13 08:46:41.261989.261989 lmp.py:1622]   Expert 60 |    160 | CPU
DEBUG 01-13 08:46:41.261871.261871 lmp.py:1622]   Expert  8 |    161 | CPU
DEBUG 01-13 08:46:41.261752.261752 lmp.py:1622]   Expert 15 |    166 | CPU
DEBUG 01-13 08:46:41.261733.261733 lmp.py:1622]   Expert 44 |    166 | CPU
DEBUG 01-13 08:46:41.261945.261945 lmp.py:1622]   Expert 29 |    171 | CPU
DEBUG 01-13 08:46:41.261442.261442 lmp.py:1622]   Expert 54 |    174 | CPU
DEBUG 01-13 08:46:41.261178.261178 lmp.py:1622]   Expert 33 |    176 | CPU
DEBUG 01-13 08:46:41.261675.261675 lmp.py:1622]   Expert 35 |    180 | CPU
DEBUG 01-13 08:46:41.261411.261411 lmp.py:1622]   Expert 34 |    182 | CPU
DEBUG 01-13 08:46:41.261147.261147 lmp.py:1622]   Expert 19 |    188 | GPU
DEBUG 01-13 08:46:41.261644.261644 lmp.py:1622]   Expert 47 |    193 | GPU
DEBUG 01-13 08:46:41.261141.261141 lmp.py:1622]   Expert 21 |    195 | GPU
DEBUG 01-13 08:46:41.261115.261115 lmp.py:1622]   Expert 49 |    195 | GPU
DEBUG 01-13 08:46:41.261851.261851 lmp.py:1622]   Expert 56 |    195 | GPU
DEBUG 01-13 08:46:41.261825.261825 lmp.py:1622]   Expert  3 |    196 | GPU
DEBUG 01-13 08:46:41.262421.262421 lmp.py:1622]   Expert  9 |    197 | GPU
DEBUG 01-13 08:46:41.262349.262349 lmp.py:1622]   Expert 46 |    197 | GPU
DEBUG 01-13 08:46:41.262561.262561 lmp.py:1622]   Expert 20 |    198 | GPU
DEBUG 01-13 08:46:41.262059.262059 lmp.py:1622]   Expert 45 |    203 | GPU
DEBUG 01-13 08:46:41.262794.262794 lmp.py:1622]   Expert 28 |    204 | GPU
DEBUG 01-13 08:46:41.262292.262292 lmp.py:1622]   Expert 57 |    221 | GPU
DEBUG 01-13 08:46:41.262266.262266 lmp.py:1622]   Expert  2 |    223 | GPU
DEBUG 01-13 08:46:41.262524.262524 lmp.py:1622]   Expert  4 |    225 | GPU
DEBUG 01-13 08:46:41.262260.262260 lmp.py:1622]   Expert 13 |    227 | GPU
DEBUG 01-13 08:46:41.262519.262519 lmp.py:1622]   Expert 43 |    234 | GPU
DEBUG 01-13 08:46:41.262778.262778 lmp.py:1622]   Expert 10 |    240 | GPU
DEBUG 01-13 08:46:41.262275.262275 lmp.py:1622]   Expert 50 |    242 | GPU
DEBUG 01-13 08:46:41.262772.262772 lmp.py:1622]   Expert 41 |    243 | GPU
DEBUG 01-13 08:46:41.262700.262700 lmp.py:1622]   Expert 26 |    256 | GPU
DEBUG 01-13 08:46:41.262389.262389 lmp.py:1622]   Expert 37 |    257 | GPU
DEBUG 01-13 08:46:41.262078.262078 lmp.py:1622]   Expert 63 |    264 | GPU
DEBUG 01-13 08:46:41.262291.262291 lmp.py:1622]   Expert 31 |    268 | GPU
DEBUG 01-13 08:46:41.262550.262550 lmp.py:1622]   Expert 61 |    271 | GPU
DEBUG 01-13 08:46:41.262047.262047 lmp.py:1622]   Expert 52 |    304 | GPU
DEBUG 01-13 08:46:41.262544.262544 lmp.py:1622]   Expert 58 |    324 | GPU
DEBUG 01-13 08:46:41.262564.262564 lmp.py:1622]   Expert 62 |    328 | GPU
DEBUG 01-13 08:46:41.262062.262062 lmp.py:1622]   Expert 55 |    342 | GPU
DEBUG 01-13 08:46:41.262320.262320 lmp.py:1622]   Expert 11 |    374 | GPU
DEBUG 01-13 08:46:41.262102.262102 lmp.py:1622]   Expert 23 |    392 | GPU
DEBUG 01-13 08:46:41.262599.262599 lmp.py:1622]   Expert 25 |    402 | GPU
DEBUG 01-13 08:46:41.262858.262858 lmp.py:1622]   Expert  5 |    515 | GPU
DEBUG 01-13 08:46:41.262501.262501 lmp.py:1623] 
DEBUG 01-13 08:46:41.262501.262501 lmp.py:1623]   CPU total tokens: 3975 (32.3%)
DEBUG 01-13 08:46:41.262383.262383 lmp.py:1624]   GPU total tokens: 8313 (67.7%)
DEBUG 01-13 08:46:41.262317.262317 cuda_h.py:19] end experts_map_get cost 0.0014986991882324219 seconds
DEBUG 01-13 08:46:41.262968.262968 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-13 08:46:41.262817.262817 lmp.py:1632] 
DEBUG 01-13 08:46:41.262817.262817 lmp.py:1632]   Computing 32 experts on CPU MP...
DEBUG 01-13 08:46:41.262547.262547 cuda_h.py:19] end cpu_experts_submit cost 4.744529724121094e-05 seconds
DEBUG 01-13 08:46:41.262574.262574 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-13 08:46:41.262642.262642 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-13 08:46:41.262964.262964 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-13 08:46:41.264151.264151 cuda_h.py:19] end allocate_cuda_memory cost 0.0011935234069824219 seconds
DEBUG 01-13 08:46:41.264663.264663 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-13 08:46:41.264055.264055 sllm_store_c.py:27] get device uuid map
DEBUG 01-13 08:46:41.264487.264487 sllm_store_c.py:29] call client load into gpu
DEBUG 01-13 08:46:41.264998.264998 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 17f65aea-0565-4083-8439-c82e3eaaa9e8
DEBUG 01-13 08:46:41.264395.264395 client.py:106] call stub.LoadModelAsync
DEBUG 01-13 08:46:41.265737.265737 cuda_h.py:10] start experts_func_gpu_einsum_mp
INFO 01-13 08:46:41.265683.265683 client.py:127] Model loaded
DEBUG 01-13 08:46:41.265811.265811 cuda_h.py:10] start restore2model
DEBUG 01-13 08:46:41.266124.266124 cuda_h.py:19] end restore2model cost 0.0004024505615234375 seconds
DEBUG 01-13 08:46:41.266867.266867 cuda_h.py:19] end sllm_worker_task cost 0.010175704956054688 seconds
INFO 01-13 08:46:41.266822.266822 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 17f65aea-0565-4083-8439-c82e3eaaa9e8
DEBUG 01-13 08:46:41.266957.266957 cuda_h.py:19] end load_into_gpu_async cost 0.0025925636291503906 seconds
DEBUG 01-13 08:46:41.266328.266328 cuda_h.py:10] start restore_tensors2
DEBUG 01-13 08:46:41.267342.267342 cuda_h.py:19] end restore_tensors2 cost 0.0003657341003417969 seconds
DEBUG 01-13 08:46:41.267178.267178 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.004513978958129883 seconds
DEBUG 01-13 08:46:41.267086.267086 cuda_h.py:10] start restore2model
DEBUG 01-13 08:46:41.269124.269124 cuda_h.py:19] end restore2model cost 0.00266265869140625 seconds
DEBUG 01-13 08:46:41.269821.269821 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.0073549747467041016 seconds
DEBUG 01-13 08:46:41.270332.270332 cuda_h.py:10] start gpu_sexperts
DEBUG 01-13 08:46:41.270679.270679 cuda_h.py:19] end gpu_sexperts cost 0.00025963783264160156 seconds
DEBUG 01-13 08:46:41.270555.270555 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-13 08:46:41.270709.270709 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 1.430511474609375e-05 seconds
DEBUG 01-13 08:46:41.270167.270167 cuda_h.py:10] start wait_experts
INFO 01-13 08:46:41.270055.270055 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 17f65aea-0565-4083-8439-c82e3eaaa9e8
DEBUG 01-13 08:46:41.278681.278681 mlpmodule.py:1006] group tensors cost 0.01233673095703125 s
DEBUG 01-13 08:46:41.280004.280004 mlpmodule.py:1044] pad cost 0.001544952392578125 s
DEBUG 01-13 08:46:41.280617.280617 mlpmodule.py:1050] create cpu tensor cost 4.5299530029296875e-05 s
DEBUG 01-13 08:46:41.280467.280467 mlpmodule.py:1055] move to cpu cost 3.218650817871094e-05 s
DEBUG 01-13 08:46:41.290817.290817 mlpmodule.py:1069] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-13 08:46:41.290627.290627 mlpmodule.py:1070] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-13 08:46:41.290599.290599 mlpmodule.py:1075] group_w3 first element: 0.0859375
WARNING 01-13 08:46:41.290394.290394 mlpmodule.py:1085] start einsum2
DEBUG 01-13 08:46:41.302011.302011 mlpmodule.py:1095] group einsum cost 0.021908283233642578 s
DEBUG 01-13 08:46:41.303818.303818 mlpmodule.py:1103] cpy2cputensor cost 0.0006992816925048828 s
INFO 01-13 08:46:41.317621.317621 client.py:127] Model loaded
DEBUG 01-13 08:46:41.317745.317745 cuda_h.py:19] end wait_experts cost 0.046905517578125 seconds
DEBUG 01-13 08:46:41.317985.317985 cuda_h.py:10] start gpu_experts
DEBUG 01-13 08:46:41.318431.318431 mlpmodule.py:559] gpu group tensors cost 0.0007467269897460938 s
DEBUG 01-13 08:46:41.319241.319241 mlpmodule.py:592] gpu pad cost 0.00157928466796875 s
DEBUG 01-13 08:46:41.319581.319581 mlpmodule.py:598] start_w1
DEBUG 01-13 08:46:41.320355.320355 mlpmodule.py:602] start_w3
DEBUG 01-13 08:46:41.320508.320508 mlpmodule.py:608] start_w2
DEBUG 01-13 08:46:41.320984.320984 mlpmodule.py:611] gpu group einsum cost 0.0007517337799072266 s
DEBUG 01-13 08:46:41.322434.322434 mlpmodule.py:683] gpu experts func einsum cost 0.005387306213378906 s
DEBUG 01-13 08:46:41.322410.322410 cuda_h.py:19] end gpu_experts cost 0.005552053451538086 seconds
DEBUG 01-13 08:46:41.323544.323544 cuda_h.py:10] start cpu_thread_manager_mp_wait
DEBUG 01-13 08:46:41.323393.323393 cuda_h.py:19] end cpu_thread_manager_mp_wait cost 3.814697265625e-05 seconds
DEBUG 01-13 08:46:41.323926.323926 cuda_h.py:19] end layer_moe_generate_mp_l_9 cost 0.0629737377166748 seconds
DEBUG 01-13 08:46:41.323900.323900 lmp.py:1550] -------------------------------- end prefill layer 8 --------------------------------
DEBUG 01-13 08:46:41.323862.323862 lmp.py:1493] -------------------------------- start prefill layer 9 --------------------------------
DEBUG 01-13 08:46:41.323227.323227 cuda_h.py:10] start start_load_qkvogn_s_weight_l_10
DEBUG 01-13 08:46:41.323930.323930 cuda_h.py:10] start start_load_qkvogn_s_weight_l_10
DEBUG 01-13 08:46:41.323958.323958 cuda_h.py:19] end start_load_qkvogn_s_weight_l_10 cost 3.1948089599609375e-05 seconds
DEBUG 01-13 08:46:41.323728.323728 cuda_h.py:19] end start_load_qkvogn_s_weight_l_10 cost 7.605552673339844e-05 seconds
DEBUG 01-13 08:46:41.323609.323609 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-13 08:46:41.323232.323232 mlpmodule.py:785]  experts func einsum cost 0.057286977767944336 s
DEBUG 01-13 08:46:41.323783.323783 cuda_h.py:10] start sllm_worker_task
DEBUG 01-13 08:46:41.323112.323112 cuda_h.py:19] end experts_func_gpu_einsum_mp cost 0.058162689208984375 seconds
DEBUG 01-13 08:46:41.323589.323589 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-13 08:46:41.323597.323597 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-13 08:46:41.323707.323707 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-13 08:46:41.324738.324738 cuda_h.py:19] end allocate_cuda_memory cost 0.0003018379211425781 seconds
DEBUG 01-13 08:46:41.324715.324715 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-13 08:46:41.324160.324160 sllm_store_c.py:27] get device uuid map
DEBUG 01-13 08:46:41.324228.324228 sllm_store_c.py:29] call client load into gpu
DEBUG 01-13 08:46:41.324977.324977 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 3796bbb2-70a2-46c2-8380-9d6b93af4e59
DEBUG 01-13 08:46:41.324616.324616 client.py:106] call stub.LoadModelAsync
DEBUG 01-13 08:46:41.324108.324108 cuda_h.py:10] start self_attn
INFO 01-13 08:46:41.326852.326852 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 3796bbb2-70a2-46c2-8380-9d6b93af4e59
DEBUG 01-13 08:46:41.326403.326403 cuda_h.py:19] end load_into_gpu_async cost 0.0017251968383789062 seconds
DEBUG 01-13 08:46:41.326981.326981 cuda_h.py:10] start restore_tensors2
DEBUG 01-13 08:46:41.326779.326779 cuda_h.py:19] end restore_tensors2 cost 7.128715515136719e-05 seconds
DEBUG 01-13 08:46:41.326866.326866 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.002387523651123047 seconds
INFO 01-13 08:46:41.326457.326457 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 3796bbb2-70a2-46c2-8380-9d6b93af4e59
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-13 08:46:41.327175.327175 cuda_h.py:19] end self_attn cost 0.002927541732788086 seconds
DEBUG 01-13 08:46:41.328219.328219 cuda_h.py:19] end iln_self_attn_paln cost 0.00444793701171875 seconds
DEBUG 01-13 08:46:41.328962.328962 cuda_h.py:10] start layer_moe_generate_mp_l_10
DEBUG 01-13 08:46:41.328686.328686 cuda_h.py:10] start gate
DEBUG 01-13 08:46:41.330940.330940 cuda_h.py:19] end gate cost 0.002014636993408203 seconds
DEBUG 01-13 08:46:41.330292.330292 cuda_h.py:10] start experts_map_get
DEBUG 01-13 08:46:41.330077.330077 lmp.py:1611] 
DEBUG 01-13 08:46:41.330077.330077 lmp.py:1611] Expert Token Distribution & Device Allocation:
DEBUG 01-13 08:46:41.330025.330025 lmp.py:1612]   Total experts: 64
DEBUG 01-13 08:46:41.330675.330675 lmp.py:1613]   CPU experts: 32 (50%)
DEBUG 01-13 08:46:41.330510.330510 lmp.py:1614]   GPU experts: 32 (50%)
DEBUG 01-13 08:46:41.330961.330961 lmp.py:1615] 
DEBUG 01-13 08:46:41.330961.330961 lmp.py:1615]   Expert ID | Tokens | Device
DEBUG 01-13 08:46:41.330650.330650 lmp.py:1616]   -----------------------------------
DEBUG 01-13 08:46:41.330585.330585 lmp.py:1622]   Expert 24 |     42 | CPU
DEBUG 01-13 08:46:41.330658.330658 lmp.py:1622]   Expert  2 |     43 | CPU
DEBUG 01-13 08:46:41.330824.330824 lmp.py:1622]   Expert 32 |     63 | CPU
DEBUG 01-13 08:46:41.330275.330275 lmp.py:1622]   Expert 19 |     69 | CPU
DEBUG 01-13 08:46:41.330488.330488 lmp.py:1622]   Expert 26 |     69 | CPU
DEBUG 01-13 08:46:41.330700.330700 lmp.py:1622]   Expert 50 |     76 | CPU
DEBUG 01-13 08:46:41.330913.330913 lmp.py:1622]   Expert  4 |     77 | CPU
DEBUG 01-13 08:46:41.330363.330363 lmp.py:1622]   Expert  7 |     79 | CPU
DEBUG 01-13 08:46:41.330814.330814 lmp.py:1622]   Expert 15 |     83 | CPU
DEBUG 01-13 08:46:41.330504.330504 lmp.py:1622]   Expert 28 |     84 | CPU
DEBUG 01-13 08:46:41.330716.330716 lmp.py:1622]   Expert 59 |     88 | CPU
DEBUG 01-13 08:46:41.330690.330690 lmp.py:1622]   Expert 60 |     89 | CPU
DEBUG 01-13 08:46:41.330141.330141 lmp.py:1622]   Expert 49 |    100 | CPU
DEBUG 01-13 08:46:41.330546.330546 lmp.py:1622]   Expert 23 |    101 | CPU
DEBUG 01-13 08:46:41.331996.331996 lmp.py:1622]   Expert  5 |    103 | CPU
DEBUG 01-13 08:46:41.331686.331686 lmp.py:1622]   Expert 10 |    104 | CPU
DEBUG 01-13 08:46:41.331898.331898 lmp.py:1622]   Expert 12 |    105 | CPU
DEBUG 01-13 08:46:41.331111.331111 lmp.py:1622]   Expert 27 |    113 | CPU
DEBUG 01-13 08:46:41.331323.331323 lmp.py:1622]   Expert 41 |    114 | CPU
DEBUG 01-13 08:46:41.331536.331536 lmp.py:1622]   Expert  3 |    121 | CPU
DEBUG 01-13 08:46:41.331748.331748 lmp.py:1622]   Expert 13 |    125 | CPU
DEBUG 01-13 08:46:41.331722.331722 lmp.py:1622]   Expert 20 |    127 | CPU
DEBUG 01-13 08:46:41.331696.331696 lmp.py:1622]   Expert 25 |    127 | CPU
DEBUG 01-13 08:46:41.331147.331147 lmp.py:1622]   Expert 16 |    131 | CPU
DEBUG 01-13 08:46:41.331121.331121 lmp.py:1622]   Expert 40 |    133 | CPU
DEBUG 01-13 08:46:41.331334.331334 lmp.py:1622]   Expert 37 |    134 | CPU
DEBUG 01-13 08:46:41.331308.331308 lmp.py:1622]   Expert 35 |    141 | CPU
DEBUG 01-13 08:46:41.331282.331282 lmp.py:1622]   Expert 17 |    152 | CPU
DEBUG 01-13 08:46:41.331494.331494 lmp.py:1622]   Expert 47 |    155 | CPU
DEBUG 01-13 08:46:41.331707.331707 lmp.py:1622]   Expert 22 |    158 | CPU
DEBUG 01-13 08:46:41.331111.331111 lmp.py:1622]   Expert 53 |    167 | CPU
DEBUG 01-13 08:46:41.331800.331800 lmp.py:1622]   Expert 39 |    177 | CPU
DEBUG 01-13 08:46:41.331205.331205 lmp.py:1622]   Expert 36 |    178 | GPU
DEBUG 01-13 08:46:41.331656.331656 lmp.py:1622]   Expert 38 |    180 | GPU
DEBUG 01-13 08:46:41.331107.331107 lmp.py:1622]   Expert 44 |    183 | GPU
DEBUG 01-13 08:46:41.331081.331081 lmp.py:1622]   Expert 52 |    186 | GPU
DEBUG 01-13 08:46:41.331293.331293 lmp.py:1622]   Expert 58 |    188 | GPU
DEBUG 01-13 08:46:41.331744.331744 lmp.py:1622]   Expert 18 |    189 | GPU
DEBUG 01-13 08:46:41.331957.331957 lmp.py:1622]   Expert 62 |    197 | GPU
DEBUG 01-13 08:46:41.331408.331408 lmp.py:1622]   Expert 48 |    207 | GPU
DEBUG 01-13 08:46:41.331858.331858 lmp.py:1622]   Expert 11 |    219 | GPU
DEBUG 01-13 08:46:41.331832.331832 lmp.py:1622]   Expert 30 |    219 | GPU
DEBUG 01-13 08:46:41.331522.331522 lmp.py:1622]   Expert 14 |    220 | GPU
DEBUG 01-13 08:46:41.331211.331211 lmp.py:1622]   Expert  1 |    226 | GPU
DEBUG 01-13 08:46:41.331616.331616 lmp.py:1622]   Expert  6 |    235 | GPU
DEBUG 01-13 08:46:41.331881.331881 lmp.py:1622]   Expert 42 |    236 | GPU
DEBUG 01-13 08:46:41.331955.331955 lmp.py:1622]   Expert 31 |    238 | GPU
DEBUG 01-13 08:46:41.331452.331452 lmp.py:1622]   Expert 45 |    238 | GPU
DEBUG 01-13 08:46:41.331711.331711 lmp.py:1622]   Expert 51 |    239 | GPU
DEBUG 01-13 08:46:41.331969.331969 lmp.py:1622]   Expert 34 |    262 | GPU
DEBUG 01-13 08:46:41.331990.331990 lmp.py:1622]   Expert 29 |    265 | GPU
DEBUG 01-13 08:46:41.331010.331010 lmp.py:1622]   Expert 33 |    278 | GPU
DEBUG 01-13 08:46:41.331507.331507 lmp.py:1622]   Expert 57 |    291 | GPU
DEBUG 01-13 08:46:41.331528.331528 lmp.py:1622]   Expert  0 |    301 | GPU
DEBUG 01-13 08:46:41.331548.331548 lmp.py:1622]   Expert 61 |    307 | GPU
DEBUG 01-13 08:46:41.331807.331807 lmp.py:1622]   Expert 43 |    309 | GPU
DEBUG 01-13 08:46:41.331066.331066 lmp.py:1622]   Expert 46 |    349 | GPU
DEBUG 01-13 08:46:41.331325.331325 lmp.py:1622]   Expert  8 |    374 | GPU
DEBUG 01-13 08:46:41.331775.331775 lmp.py:1622]   Expert  9 |    386 | GPU
DEBUG 01-13 08:46:41.331326.331326 lmp.py:1622]   Expert 54 |    400 | GPU
DEBUG 01-13 08:46:41.331684.331684 lmp.py:1622]   Expert 56 |    408 | GPU
DEBUG 01-13 08:46:41.331420.331420 lmp.py:1622]   Expert 63 |    416 | GPU
DEBUG 01-13 08:46:41.331917.331917 lmp.py:1622]   Expert 55 |    428 | GPU
DEBUG 01-13 08:46:41.331414.331414 lmp.py:1622]   Expert 21 |    486 | GPU
DEBUG 01-13 08:46:41.331150.331150 lmp.py:1623] 
DEBUG 01-13 08:46:41.331150.331150 lmp.py:1623]   CPU total tokens: 3450 (28.1%)
DEBUG 01-13 08:46:41.331839.331839 lmp.py:1624]   GPU total tokens: 8838 (71.9%)
DEBUG 01-13 08:46:41.331343.331343 cuda_h.py:19] end experts_map_get cost 0.001485586166381836 seconds
DEBUG 01-13 08:46:41.331862.331862 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-13 08:46:41.331710.331710 lmp.py:1632] 
DEBUG 01-13 08:46:41.331710.331710 lmp.py:1632]   Computing 32 experts on CPU MP...
DEBUG 01-13 08:46:41.332494.332494 cuda_h.py:19] end cpu_experts_submit cost 5.054473876953125e-05 seconds
DEBUG 01-13 08:46:41.332998.332998 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-13 08:46:41.332443.332443 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-13 08:46:41.332163.332163 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-13 08:46:41.332751.332751 cuda_h.py:19] end allocate_cuda_memory cost 0.0003273487091064453 seconds
DEBUG 01-13 08:46:41.332455.332455 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-13 08:46:41.332403.332403 sllm_store_c.py:27] get device uuid map
DEBUG 01-13 08:46:41.332120.332120 sllm_store_c.py:29] call client load into gpu
DEBUG 01-13 08:46:41.332677.332677 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 1fbe0fe6-bf1c-42ee-8ba7-4068180e66d0
DEBUG 01-13 08:46:41.332710.332710 client.py:106] call stub.LoadModelAsync
INFO 01-13 08:46:41.333820.333820 client.py:127] Model loaded
DEBUG 01-13 08:46:41.333140.333140 cuda_h.py:10] start restore2model
DEBUG 01-13 08:46:41.333525.333525 cuda_h.py:19] end restore2model cost 0.0003886222839355469 seconds
DEBUG 01-13 08:46:41.333016.333016 cuda_h.py:19] end sllm_worker_task cost 0.01015329360961914 seconds
DEBUG 01-13 08:46:41.334653.334653 cuda_h.py:10] start experts_func_gpu_einsum_mp
INFO 01-13 08:46:41.334133.334133 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 1fbe0fe6-bf1c-42ee-8ba7-4068180e66d0
DEBUG 01-13 08:46:41.334553.334553 cuda_h.py:19] end load_into_gpu_async cost 0.0022842884063720703 seconds
DEBUG 01-13 08:46:41.334448.334448 cuda_h.py:10] start restore_tensors2
DEBUG 01-13 08:46:41.335072.335072 cuda_h.py:19] end restore_tensors2 cost 0.00043201446533203125 seconds
DEBUG 01-13 08:46:41.335777.335777 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.003418445587158203 seconds
DEBUG 01-13 08:46:41.335308.335308 cuda_h.py:10] start restore2model
DEBUG 01-13 08:46:41.338861.338861 cuda_h.py:19] end restore2model cost 0.0026569366455078125 seconds
DEBUG 01-13 08:46:41.338282.338282 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.00629734992980957 seconds
DEBUG 01-13 08:46:41.338005.338005 cuda_h.py:10] start gpu_sexperts
DEBUG 01-13 08:46:41.338949.338949 cuda_h.py:19] end gpu_sexperts cost 0.0002789497375488281 seconds
DEBUG 01-13 08:46:41.338064.338064 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-13 08:46:41.338694.338694 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 1.5974044799804688e-05 seconds
DEBUG 01-13 08:46:41.338675.338675 cuda_h.py:10] start wait_experts
INFO 01-13 08:46:41.338848.338848 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 1fbe0fe6-bf1c-42ee-8ba7-4068180e66d0
DEBUG 01-13 08:46:41.340170.340170 mlpmodule.py:1006] group tensors cost 0.005591630935668945 s
DEBUG 01-13 08:46:41.343950.343950 mlpmodule.py:1044] pad cost 0.00208282470703125 s
DEBUG 01-13 08:46:41.343497.343497 mlpmodule.py:1050] create cpu tensor cost 5.364418029785156e-05 s
DEBUG 01-13 08:46:41.343798.343798 mlpmodule.py:1055] move to cpu cost 3.743171691894531e-05 s
DEBUG 01-13 08:46:41.352020.352020 mlpmodule.py:1069] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-13 08:46:41.352414.352414 mlpmodule.py:1070] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-13 08:46:41.353409.353409 mlpmodule.py:1075] group_w3 first element: 0.0157470703125
WARNING 01-13 08:46:41.353259.353259 mlpmodule.py:1085] start einsum2
DEBUG 01-13 08:46:41.366237.366237 mlpmodule.py:1095] group einsum cost 0.022696256637573242 s
DEBUG 01-13 08:46:41.367892.367892 mlpmodule.py:1103] cpy2cputensor cost 0.0007007122039794922 s
INFO 01-13 08:46:41.385333.385333 client.py:127] Model loaded
DEBUG 01-13 08:46:41.385990.385990 cuda_h.py:19] end wait_experts cost 0.0471193790435791 seconds
DEBUG 01-13 08:46:41.386404.386404 cuda_h.py:10] start gpu_experts
DEBUG 01-13 08:46:41.387473.387473 mlpmodule.py:559] gpu group tensors cost 0.0014672279357910156 s
DEBUG 01-13 08:46:41.391893.391893 mlpmodule.py:785]  experts func einsum cost 0.056673288345336914 s
DEBUG 01-13 08:46:41.392835.392835 cuda_h.py:19] end experts_func_gpu_einsum_mp cost 0.05774092674255371 seconds
DEBUG 01-13 08:46:41.392234.392234 mlpmodule.py:592] gpu pad cost 0.004590272903442383 s
DEBUG 01-13 08:46:41.392605.392605 mlpmodule.py:598] start_w1
DEBUG 01-13 08:46:41.393926.393926 mlpmodule.py:602] start_w3
DEBUG 01-13 08:46:41.393915.393915 mlpmodule.py:608] start_w2
DEBUG 01-13 08:46:41.394751.394751 mlpmodule.py:611] gpu group einsum cost 0.0015799999237060547 s
DEBUG 01-13 08:46:41.400473.400473 mlpmodule.py:683] gpu experts func einsum cost 0.014159440994262695 s
DEBUG 01-13 08:46:41.400609.400609 cuda_h.py:19] end gpu_experts cost 0.014373540878295898 seconds
DEBUG 01-13 08:46:41.400041.400041 cuda_h.py:10] start cpu_thread_manager_mp_wait
DEBUG 01-13 08:46:41.400626.400626 cuda_h.py:19] end cpu_thread_manager_mp_wait cost 4.363059997558594e-05 seconds
DEBUG 01-13 08:46:41.400285.400285 cuda_h.py:19] end layer_moe_generate_mp_l_10 cost 0.07250189781188965 seconds
DEBUG 01-13 08:46:41.401580.401580 lmp.py:1550] -------------------------------- end prefill layer 9 --------------------------------
DEBUG 01-13 08:46:41.401402.401402 lmp.py:1493] -------------------------------- start prefill layer 10 --------------------------------
DEBUG 01-13 08:46:41.401873.401873 cuda_h.py:10] start start_load_qkvogn_s_weight_l_11
DEBUG 01-13 08:46:41.401444.401444 cuda_h.py:10] start start_load_qkvogn_s_weight_l_11
DEBUG 01-13 08:46:41.401056.401056 cuda_h.py:19] end start_load_qkvogn_s_weight_l_11 cost 3.3855438232421875e-05 seconds
DEBUG 01-13 08:46:41.401957.401957 cuda_h.py:19] end start_load_qkvogn_s_weight_l_11 cost 7.081031799316406e-05 seconds
DEBUG 01-13 08:46:41.401945.401945 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-13 08:46:41.401908.401908 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-13 08:46:41.401606.401606 cuda_h.py:10] start sllm_worker_task
DEBUG 01-13 08:46:41.401649.401649 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-13 08:46:41.401453.401453 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-13 08:46:41.402023.402023 cuda_h.py:19] end allocate_cuda_memory cost 0.0003762245178222656 seconds
DEBUG 01-13 08:46:41.402636.402636 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-13 08:46:41.402028.402028 sllm_store_c.py:27] get device uuid map
DEBUG 01-13 08:46:41.402672.402672 sllm_store_c.py:29] call client load into gpu
DEBUG 01-13 08:46:41.402289.402289 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, c0011eb5-cefb-4689-b3c7-a8a75731a880
DEBUG 01-13 08:46:41.402001.402001 client.py:106] call stub.LoadModelAsync
DEBUG 01-13 08:46:41.402608.402608 cuda_h.py:10] start self_attn
INFO 01-13 08:46:41.403556.403556 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, c0011eb5-cefb-4689-b3c7-a8a75731a880
DEBUG 01-13 08:46:41.403029.403029 cuda_h.py:19] end load_into_gpu_async cost 0.0017900466918945312 seconds
DEBUG 01-13 08:46:41.403930.403930 cuda_h.py:10] start restore_tensors2
DEBUG 01-13 08:46:41.404656.404656 cuda_h.py:19] end restore_tensors2 cost 7.987022399902344e-05 seconds
DEBUG 01-13 08:46:41.404472.404472 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0025663375854492188 seconds
INFO 01-13 08:46:41.404368.404368 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, c0011eb5-cefb-4689-b3c7-a8a75731a880
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-13 08:46:41.406206.406206 cuda_h.py:19] end self_attn cost 0.003345012664794922 seconds
DEBUG 01-13 08:46:41.406093.406093 cuda_h.py:19] end iln_self_attn_paln cost 0.005162239074707031 seconds
DEBUG 01-13 08:46:41.406115.406115 cuda_h.py:10] start layer_moe_generate_mp_l_11
DEBUG 01-13 08:46:41.406892.406892 cuda_h.py:10] start gate
DEBUG 01-13 08:46:41.407474.407474 cuda_h.py:19] end gate cost 0.0007383823394775391 seconds
DEBUG 01-13 08:46:41.407271.407271 cuda_h.py:10] start experts_map_get
DEBUG 01-13 08:46:41.407396.407396 lmp.py:1611] 
DEBUG 01-13 08:46:41.407396.407396 lmp.py:1611] Expert Token Distribution & Device Allocation:
DEBUG 01-13 08:46:41.407689.407689 lmp.py:1612]   Total experts: 64
DEBUG 01-13 08:46:41.407968.407968 lmp.py:1613]   CPU experts: 32 (50%)
DEBUG 01-13 08:46:41.407194.407194 lmp.py:1614]   GPU experts: 32 (50%)
DEBUG 01-13 08:46:41.407036.407036 lmp.py:1615] 
DEBUG 01-13 08:46:41.407036.407036 lmp.py:1615]   Expert ID | Tokens | Device
DEBUG 01-13 08:46:41.407354.407354 lmp.py:1616]   -----------------------------------
DEBUG 01-13 08:46:41.407110.407110 lmp.py:1622]   Expert 43 |     19 | CPU
DEBUG 01-13 08:46:41.408714.408714 lmp.py:1622]   Expert 27 |     36 | CPU
DEBUG 01-13 08:46:41.408602.408602 lmp.py:1622]   Expert 34 |     51 | CPU
DEBUG 01-13 08:46:41.408775.408775 lmp.py:1622]   Expert 56 |     51 | CPU
DEBUG 01-13 08:46:41.408186.408186 lmp.py:1622]   Expert 26 |     55 | CPU
DEBUG 01-13 08:46:41.408836.408836 lmp.py:1622]   Expert  3 |     58 | CPU
DEBUG 01-13 08:46:41.408963.408963 lmp.py:1622]   Expert  4 |     74 | CPU
DEBUG 01-13 08:46:41.408328.408328 lmp.py:1622]   Expert 61 |     74 | CPU
DEBUG 01-13 08:46:41.408216.408216 lmp.py:1622]   Expert 14 |     93 | CPU
DEBUG 01-13 08:46:41.408866.408866 lmp.py:1622]   Expert 38 |    101 | CPU
DEBUG 01-13 08:46:41.408277.408277 lmp.py:1622]   Expert 17 |    110 | CPU
DEBUG 01-13 08:46:41.408450.408450 lmp.py:1622]   Expert  2 |    113 | CPU
DEBUG 01-13 08:46:41.408146.408146 lmp.py:1622]   Expert 22 |    118 | CPU
DEBUG 01-13 08:46:41.408081.408081 lmp.py:1622]   Expert 37 |    128 | CPU
DEBUG 01-13 08:46:41.408254.408254 lmp.py:1622]   Expert 54 |    129 | CPU
DEBUG 01-13 08:46:41.408950.408950 lmp.py:1622]   Expert 55 |    131 | CPU
DEBUG 01-13 08:46:41.408838.408838 lmp.py:1622]   Expert 47 |    133 | CPU
DEBUG 01-13 08:46:41.408488.408488 lmp.py:1622]   Expert 60 |    137 | CPU
DEBUG 01-13 08:46:41.408053.408053 lmp.py:1622]   Expert 28 |    139 | CPU
DEBUG 01-13 08:46:41.408895.408895 lmp.py:1622]   Expert 45 |    139 | CPU
DEBUG 01-13 08:46:41.408591.408591 lmp.py:1622]   Expert 15 |    143 | CPU
DEBUG 01-13 08:46:41.408525.408525 lmp.py:1622]   Expert  5 |    144 | CPU
DEBUG 01-13 08:46:41.408744.408744 lmp.py:1622]   Expert 51 |    144 | CPU
DEBUG 01-13 08:46:41.408202.408202 lmp.py:1622]   Expert 48 |    145 | CPU
DEBUG 01-13 08:46:41.408898.408898 lmp.py:1622]   Expert  7 |    148 | CPU
DEBUG 01-13 08:46:41.408263.408263 lmp.py:1622]   Expert 12 |    149 | CPU
DEBUG 01-13 08:46:41.408675.408675 lmp.py:1622]   Expert 63 |    150 | CPU
DEBUG 01-13 08:46:41.408324.408324 lmp.py:1622]   Expert 19 |    152 | CPU
DEBUG 01-13 08:46:41.408736.408736 lmp.py:1622]   Expert  6 |    159 | CPU
DEBUG 01-13 08:46:41.408624.408624 lmp.py:1622]   Expert 52 |    176 | CPU
DEBUG 01-13 08:46:41.408081.408081 lmp.py:1622]   Expert 57 |    176 | CPU
DEBUG 01-13 08:46:41.408016.408016 lmp.py:1622]   Expert 44 |    182 | CPU
DEBUG 01-13 08:46:41.408950.408950 lmp.py:1622]   Expert 30 |    185 | GPU
DEBUG 01-13 08:46:41.408647.408647 lmp.py:1622]   Expert 18 |    186 | GPU
DEBUG 01-13 08:46:41.408343.408343 lmp.py:1622]   Expert 50 |    187 | GPU
DEBUG 01-13 08:46:41.408277.408277 lmp.py:1622]   Expert 31 |    188 | GPU
DEBUG 01-13 08:46:41.408689.408689 lmp.py:1622]   Expert 13 |    191 | GPU
DEBUG 01-13 08:46:41.408861.408861 lmp.py:1622]   Expert 59 |    192 | GPU
DEBUG 01-13 08:46:41.408273.408273 lmp.py:1622]   Expert 23 |    195 | GPU
DEBUG 01-13 08:46:41.408923.408923 lmp.py:1622]   Expert 20 |    198 | GPU
DEBUG 01-13 08:46:41.408857.408857 lmp.py:1622]   Expert 53 |    201 | GPU
DEBUG 01-13 08:46:41.408553.408553 lmp.py:1622]   Expert 29 |    202 | GPU
DEBUG 01-13 08:46:41.408740.408740 lmp.py:1622]   Expert 39 |    204 | GPU
DEBUG 01-13 08:46:41.408667.408667 lmp.py:1622]   Expert 16 |    205 | GPU
DEBUG 01-13 08:46:41.409118.409118 lmp.py:1622]   Expert 21 |    206 | GPU
DEBUG 01-13 08:46:41.409569.409569 lmp.py:1622]   Expert 36 |    210 | GPU
DEBUG 01-13 08:46:41.409543.409543 lmp.py:1622]   Expert 41 |    212 | GPU
DEBUG 01-13 08:46:41.409994.409994 lmp.py:1622]   Expert 25 |    215 | GPU
DEBUG 01-13 08:46:41.409445.409445 lmp.py:1622]   Expert 49 |    217 | GPU
DEBUG 01-13 08:46:41.409611.409611 lmp.py:1622]   Expert 32 |    220 | GPU
DEBUG 01-13 08:46:41.409492.409492 lmp.py:1622]   Expert 46 |    227 | GPU
DEBUG 01-13 08:46:41.409659.409659 lmp.py:1622]   Expert  8 |    243 | GPU
DEBUG 01-13 08:46:41.409063.409063 lmp.py:1622]   Expert 42 |    253 | GPU
DEBUG 01-13 08:46:41.409991.409991 lmp.py:1622]   Expert 10 |    258 | GPU
DEBUG 01-13 08:46:41.409203.409203 lmp.py:1622]   Expert 62 |    259 | GPU
DEBUG 01-13 08:46:41.409654.409654 lmp.py:1622]   Expert 35 |    283 | GPU
DEBUG 01-13 08:46:41.409344.409344 lmp.py:1622]   Expert  9 |    289 | GPU
DEBUG 01-13 08:46:41.409794.409794 lmp.py:1622]   Expert 33 |    295 | GPU
DEBUG 01-13 08:46:41.409768.409768 lmp.py:1622]   Expert 58 |    298 | GPU
DEBUG 01-13 08:46:41.409981.409981 lmp.py:1622]   Expert 40 |    394 | GPU
DEBUG 01-13 08:46:41.409670.409670 lmp.py:1622]   Expert  0 |    433 | GPU
DEBUG 01-13 08:46:41.409644.409644 lmp.py:1622]   Expert 11 |    454 | GPU
DEBUG 01-13 08:46:41.409287.409287 lmp.py:1622]   Expert 24 |    559 | GPU
DEBUG 01-13 08:46:41.409692.409692 lmp.py:1622]   Expert  1 |    672 | GPU
DEBUG 01-13 08:46:41.409288.409288 lmp.py:1623] 
DEBUG 01-13 08:46:41.409288.409288 lmp.py:1623]   CPU total tokens: 3757 (30.6%)
DEBUG 01-13 08:46:41.409885.409885 lmp.py:1624]   GPU total tokens: 8531 (69.4%)
DEBUG 01-13 08:46:41.409535.409535 cuda_h.py:19] end experts_map_get cost 0.0019156932830810547 seconds
DEBUG 01-13 08:46:41.409385.409385 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-13 08:46:41.409472.409472 lmp.py:1632] 
DEBUG 01-13 08:46:41.409472.409472 lmp.py:1632]   Computing 32 experts on CPU MP...
DEBUG 01-13 08:46:41.409109.409109 cuda_h.py:19] end cpu_experts_submit cost 4.863739013671875e-05 seconds
DEBUG 01-13 08:46:41.409826.409826 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-13 08:46:41.409960.409960 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-13 08:46:41.409574.409574 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-13 08:46:41.411063.411063 cuda_h.py:19] end allocate_cuda_memory cost 0.0013089179992675781 seconds
DEBUG 01-13 08:46:41.411436.411436 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-13 08:46:41.411000.411000 sllm_store_c.py:27] get device uuid map
DEBUG 01-13 08:46:41.411001.411001 sllm_store_c.py:29] call client load into gpu
DEBUG 01-13 08:46:41.411796.411796 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, d243a40c-2878-4b7d-9b80-2e39f29fc4da
DEBUG 01-13 08:46:41.411969.411969 client.py:106] call stub.LoadModelAsync
INFO 01-13 08:46:41.411642.411642 client.py:127] Model loaded
DEBUG 01-13 08:46:41.412128.412128 cuda_h.py:10] start restore2model
DEBUG 01-13 08:46:41.412176.412176 cuda_h.py:19] end restore2model cost 0.0005769729614257812 seconds
DEBUG 01-13 08:46:41.412794.412794 cuda_h.py:19] end sllm_worker_task cost 0.011243343353271484 seconds
DEBUG 01-13 08:46:41.413809.413809 cuda_h.py:10] start experts_func_gpu_einsum_mp
INFO 01-13 08:46:41.413741.413741 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, d243a40c-2878-4b7d-9b80-2e39f29fc4da
DEBUG 01-13 08:46:41.413591.413591 cuda_h.py:19] end load_into_gpu_async cost 0.002433300018310547 seconds
DEBUG 01-13 08:46:41.413009.413009 cuda_h.py:10] start restore_tensors2
DEBUG 01-13 08:46:41.414781.414781 cuda_h.py:19] end restore_tensors2 cost 0.0004706382751464844 seconds
DEBUG 01-13 08:46:41.414816.414816 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0045757293701171875 seconds
DEBUG 01-13 08:46:41.414586.414586 cuda_h.py:10] start restore2model
DEBUG 01-13 08:46:41.416338.416338 cuda_h.py:19] end restore2model cost 0.0026624202728271484 seconds
DEBUG 01-13 08:46:41.417380.417380 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.007444620132446289 seconds
DEBUG 01-13 08:46:41.417222.417222 cuda_h.py:10] start gpu_sexperts
DEBUG 01-13 08:46:41.417053.417053 cuda_h.py:19] end gpu_sexperts cost 0.0002663135528564453 seconds
DEBUG 01-13 08:46:41.417121.417121 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-13 08:46:41.417560.417560 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 1.5735626220703125e-05 seconds
DEBUG 01-13 08:46:41.417302.417302 cuda_h.py:10] start wait_experts
INFO 01-13 08:46:41.417760.417760 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, d243a40c-2878-4b7d-9b80-2e39f29fc4da
DEBUG 01-13 08:46:41.429118.429118 mlpmodule.py:1006] group tensors cost 0.015531301498413086 s
DEBUG 01-13 08:46:41.432556.432556 mlpmodule.py:1044] pad cost 0.0015206336975097656 s
DEBUG 01-13 08:46:41.432135.432135 mlpmodule.py:1050] create cpu tensor cost 5.8650970458984375e-05 s
DEBUG 01-13 08:46:41.432224.432224 mlpmodule.py:1055] move to cpu cost 3.123283386230469e-05 s
DEBUG 01-13 08:46:41.441844.441844 mlpmodule.py:1069] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-13 08:46:41.441665.441665 mlpmodule.py:1070] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-13 08:46:41.441907.441907 mlpmodule.py:1075] group_w3 first element: -0.0213623046875
WARNING 01-13 08:46:41.441329.441329 mlpmodule.py:1085] start einsum2
DEBUG 01-13 08:46:41.455220.455220 mlpmodule.py:1095] group einsum cost 0.022953510284423828 s
DEBUG 01-13 08:46:41.456344.456344 mlpmodule.py:1103] cpy2cputensor cost 0.0006940364837646484 s
INFO 01-13 08:46:41.464386.464386 client.py:127] Model loaded
DEBUG 01-13 08:46:41.464721.464721 cuda_h.py:19] end wait_experts cost 0.046888113021850586 seconds
DEBUG 01-13 08:46:41.464345.464345 cuda_h.py:10] start gpu_experts
DEBUG 01-13 08:46:41.465915.465915 mlpmodule.py:559] gpu group tensors cost 0.0007030963897705078 s
DEBUG 01-13 08:46:41.467655.467655 mlpmodule.py:592] gpu pad cost 0.00183868408203125 s
DEBUG 01-13 08:46:41.467268.467268 mlpmodule.py:598] start_w1
DEBUG 01-13 08:46:41.467729.467729 mlpmodule.py:602] start_w3
DEBUG 01-13 08:46:41.467848.467848 mlpmodule.py:608] start_w2
DEBUG 01-13 08:46:41.467661.467661 mlpmodule.py:611] gpu group einsum cost 0.0006775856018066406 s
DEBUG 01-13 08:46:41.470835.470835 mlpmodule.py:683] gpu experts func einsum cost 0.006017923355102539 s
DEBUG 01-13 08:46:41.470686.470686 cuda_h.py:19] end gpu_experts cost 0.006189584732055664 seconds
DEBUG 01-13 08:46:41.470303.470303 cuda_h.py:10] start cpu_thread_manager_mp_wait
DEBUG 01-13 08:46:41.470835.470835 cuda_h.py:19] end cpu_thread_manager_mp_wait cost 4.291534423828125e-05 seconds
DEBUG 01-13 08:46:41.470050.470050 cuda_h.py:19] end layer_moe_generate_mp_l_11 cost 0.06427240371704102 seconds
DEBUG 01-13 08:46:41.471707.471707 lmp.py:1550] -------------------------------- end prefill layer 10 --------------------------------
DEBUG 01-13 08:46:41.471755.471755 lmp.py:1493] -------------------------------- start prefill layer 11 --------------------------------
DEBUG 01-13 08:46:41.471550.471550 cuda_h.py:10] start start_load_qkvogn_s_weight_l_12
DEBUG 01-13 08:46:41.471545.471545 cuda_h.py:10] start start_load_qkvogn_s_weight_l_12
DEBUG 01-13 08:46:41.471434.471434 cuda_h.py:19] end start_load_qkvogn_s_weight_l_12 cost 3.218650817871094e-05 seconds
DEBUG 01-13 08:46:41.471091.471091 cuda_h.py:19] end start_load_qkvogn_s_weight_l_12 cost 6.341934204101562e-05 seconds
DEBUG 01-13 08:46:41.471595.471595 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-13 08:46:41.471405.471405 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-13 08:46:41.471176.471176 cuda_h.py:10] start sllm_worker_task
DEBUG 01-13 08:46:41.471185.471185 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-13 08:46:41.471730.471730 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-13 08:46:41.471191.471191 cuda_h.py:19] end allocate_cuda_memory cost 0.00030517578125 seconds
DEBUG 01-13 08:46:41.471406.471406 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-13 08:46:41.472693.472693 sllm_store_c.py:27] get device uuid map
DEBUG 01-13 08:46:41.472755.472755 sllm_store_c.py:29] call client load into gpu
DEBUG 01-13 08:46:41.472981.472981 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 846eac20-2761-4357-8e94-aefdadeeaa5c
DEBUG 01-13 08:46:41.472341.472341 client.py:106] call stub.LoadModelAsync
DEBUG 01-13 08:46:41.472152.472152 cuda_h.py:10] start self_attn
INFO 01-13 08:46:41.473651.473651 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 846eac20-2761-4357-8e94-aefdadeeaa5c
DEBUG 01-13 08:46:41.473064.473064 cuda_h.py:19] end load_into_gpu_async cost 0.0013632774353027344 seconds
DEBUG 01-13 08:46:41.473290.473290 cuda_h.py:10] start restore_tensors2
DEBUG 01-13 08:46:41.473849.473849 cuda_h.py:19] end restore_tensors2 cost 7.05718994140625e-05 seconds
DEBUG 01-13 08:46:41.473903.473903 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0020461082458496094 seconds
INFO 01-13 08:46:41.473469.473469 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 846eac20-2761-4357-8e94-aefdadeeaa5c
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-13 08:46:41.475950.475950 cuda_h.py:19] end self_attn cost 0.0028066635131835938 seconds
DEBUG 01-13 08:46:41.475417.475417 cuda_h.py:19] end iln_self_attn_paln cost 0.004369497299194336 seconds
DEBUG 01-13 08:46:41.475592.475592 cuda_h.py:10] start layer_moe_generate_mp_l_12
DEBUG 01-13 08:46:41.475732.475732 cuda_h.py:10] start gate
DEBUG 01-13 08:46:41.476576.476576 cuda_h.py:19] end gate cost 0.000659942626953125 seconds
DEBUG 01-13 08:46:41.476167.476167 cuda_h.py:10] start experts_map_get
DEBUG 01-13 08:46:41.476945.476945 lmp.py:1611] 
DEBUG 01-13 08:46:41.476945.476945 lmp.py:1611] Expert Token Distribution & Device Allocation:
DEBUG 01-13 08:46:41.476224.476224 lmp.py:1612]   Total experts: 64
DEBUG 01-13 08:46:41.476159.476159 lmp.py:1613]   CPU experts: 32 (50%)
DEBUG 01-13 08:46:41.476994.476994 lmp.py:1614]   GPU experts: 32 (50%)
DEBUG 01-13 08:46:41.476445.476445 lmp.py:1615] 
DEBUG 01-13 08:46:41.476445.476445 lmp.py:1615]   Expert ID | Tokens | Device
DEBUG 01-13 08:46:41.476657.476657 lmp.py:1616]   -----------------------------------
DEBUG 01-13 08:46:41.476307.476307 lmp.py:1622]   Expert 39 |     19 | CPU
DEBUG 01-13 08:46:41.476758.476758 lmp.py:1622]   Expert 13 |     22 | CPU
DEBUG 01-13 08:46:41.476732.476732 lmp.py:1622]   Expert 49 |     36 | CPU
DEBUG 01-13 08:46:41.476375.476375 lmp.py:1622]   Expert 35 |     47 | CPU
DEBUG 01-13 08:46:41.477303.477303 lmp.py:1622]   Expert 19 |     61 | CPU
DEBUG 01-13 08:46:41.477754.477754 lmp.py:1622]   Expert 32 |     74 | CPU
DEBUG 01-13 08:46:41.477204.477204 lmp.py:1622]   Expert 41 |     75 | CPU
DEBUG 01-13 08:46:41.477655.477655 lmp.py:1622]   Expert 26 |     77 | CPU
DEBUG 01-13 08:46:41.477298.477298 lmp.py:1622]   Expert 33 |     78 | CPU
DEBUG 01-13 08:46:41.477941.477941 lmp.py:1622]   Expert  9 |     81 | CPU
DEBUG 01-13 08:46:41.477346.477346 lmp.py:1622]   Expert 46 |     83 | CPU
DEBUG 01-13 08:46:41.477512.477512 lmp.py:1622]   Expert 23 |     85 | CPU
DEBUG 01-13 08:46:41.477678.477678 lmp.py:1622]   Expert 31 |     86 | CPU
DEBUG 01-13 08:46:41.477367.477367 lmp.py:1622]   Expert 18 |     94 | CPU
DEBUG 01-13 08:46:41.477057.477057 lmp.py:1622]   Expert 38 |     97 | CPU
DEBUG 01-13 08:46:41.477984.477984 lmp.py:1622]   Expert  6 |     99 | CPU
DEBUG 01-13 08:46:41.477674.477674 lmp.py:1622]   Expert  3 |    104 | CPU
DEBUG 01-13 08:46:41.477363.477363 lmp.py:1622]   Expert 17 |    106 | CPU
DEBUG 01-13 08:46:41.477814.477814 lmp.py:1622]   Expert 20 |    118 | CPU
DEBUG 01-13 08:46:41.477503.477503 lmp.py:1622]   Expert 40 |    129 | CPU
DEBUG 01-13 08:46:41.477193.477193 lmp.py:1622]   Expert 59 |    133 | CPU
DEBUG 01-13 08:46:41.477405.477405 lmp.py:1622]   Expert 61 |    134 | CPU
DEBUG 01-13 08:46:41.477094.477094 lmp.py:1622]   Expert 62 |    134 | CPU
DEBUG 01-13 08:46:41.477737.477737 lmp.py:1622]   Expert 43 |    135 | CPU
DEBUG 01-13 08:46:41.477903.477903 lmp.py:1622]   Expert 15 |    137 | CPU
DEBUG 01-13 08:46:41.477831.477831 lmp.py:1622]   Expert  2 |    138 | CPU
DEBUG 01-13 08:46:41.477997.477997 lmp.py:1622]   Expert 16 |    138 | CPU
DEBUG 01-13 08:46:41.477640.477640 lmp.py:1622]   Expert 42 |    139 | CPU
DEBUG 01-13 08:46:41.477330.477330 lmp.py:1622]   Expert 50 |    141 | CPU
DEBUG 01-13 08:46:41.477780.477780 lmp.py:1622]   Expert 63 |    145 | CPU
DEBUG 01-13 08:46:41.477993.477993 lmp.py:1622]   Expert 44 |    148 | CPU
DEBUG 01-13 08:46:41.477444.477444 lmp.py:1622]   Expert 36 |    152 | CPU
DEBUG 01-13 08:46:41.477895.477895 lmp.py:1622]   Expert 10 |    157 | GPU
DEBUG 01-13 08:46:41.477107.477107 lmp.py:1622]   Expert  5 |    170 | GPU
DEBUG 01-13 08:46:41.477558.477558 lmp.py:1622]   Expert 34 |    177 | GPU
DEBUG 01-13 08:46:41.477247.477247 lmp.py:1622]   Expert 45 |    186 | GPU
DEBUG 01-13 08:46:41.477413.477413 lmp.py:1622]   Expert 27 |    187 | GPU
DEBUG 01-13 08:46:41.477580.477580 lmp.py:1622]   Expert 52 |    192 | GPU
DEBUG 01-13 08:46:41.477507.477507 lmp.py:1622]   Expert 60 |    199 | GPU
DEBUG 01-13 08:46:41.477673.477673 lmp.py:1622]   Expert 48 |    205 | GPU
DEBUG 01-13 08:46:41.477363.477363 lmp.py:1622]   Expert 51 |    212 | GPU
DEBUG 01-13 08:46:41.477575.477575 lmp.py:1622]   Expert 56 |    216 | GPU
DEBUG 01-13 08:46:41.477026.477026 lmp.py:1622]   Expert 24 |    223 | GPU
DEBUG 01-13 08:46:41.477477.477477 lmp.py:1622]   Expert  7 |    224 | GPU
DEBUG 01-13 08:46:41.477689.477689 lmp.py:1622]   Expert  8 |    232 | GPU
DEBUG 01-13 08:46:41.477140.477140 lmp.py:1622]   Expert 53 |    239 | GPU
DEBUG 01-13 08:46:41.477591.477591 lmp.py:1622]   Expert 57 |    244 | GPU
DEBUG 01-13 08:46:41.477804.477804 lmp.py:1622]   Expert 29 |    256 | GPU
DEBUG 01-13 08:46:41.477255.477255 lmp.py:1622]   Expert 47 |    256 | GPU
DEBUG 01-13 08:46:41.477944.477944 lmp.py:1622]   Expert 21 |    268 | GPU
DEBUG 01-13 08:46:41.477395.477395 lmp.py:1622]   Expert  0 |    279 | GPU
DEBUG 01-13 08:46:41.477607.477607 lmp.py:1622]   Expert  4 |    285 | GPU
DEBUG 01-13 08:46:41.477058.477058 lmp.py:1622]   Expert 14 |    289 | GPU
DEBUG 01-13 08:46:41.477986.477986 lmp.py:1622]   Expert 55 |    316 | GPU
DEBUG 01-13 08:46:41.477914.477914 lmp.py:1622]   Expert 22 |    319 | GPU
DEBUG 01-13 08:46:41.477603.477603 lmp.py:1622]   Expert 37 |    320 | GPU
DEBUG 01-13 08:46:41.477531.477531 lmp.py:1622]   Expert 58 |    324 | GPU
DEBUG 01-13 08:46:41.477935.477935 lmp.py:1622]   Expert  1 |    335 | GPU
DEBUG 01-13 08:46:41.477148.477148 lmp.py:1622]   Expert 54 |    336 | GPU
DEBUG 01-13 08:46:41.477598.477598 lmp.py:1622]   Expert 28 |    349 | GPU
DEBUG 01-13 08:46:41.477572.477572 lmp.py:1622]   Expert 12 |    373 | GPU
DEBUG 01-13 08:46:41.477785.477785 lmp.py:1622]   Expert 25 |    394 | GPU
DEBUG 01-13 08:46:41.477997.477997 lmp.py:1622]   Expert 11 |    418 | GPU
DEBUG 01-13 08:46:41.477210.477210 lmp.py:1622]   Expert 30 |    863 | GPU
DEBUG 01-13 08:46:41.478899.478899 lmp.py:1623] 
DEBUG 01-13 08:46:41.478899.478899 lmp.py:1623]   CPU total tokens: 3245 (26.4%)
DEBUG 01-13 08:46:41.478781.478781 lmp.py:1624]   GPU total tokens: 9043 (73.6%)
DEBUG 01-13 08:46:41.478953.478953 cuda_h.py:19] end experts_map_get cost 0.0014998912811279297 seconds
DEBUG 01-13 08:46:41.478373.478373 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-13 08:46:41.478175.478175 lmp.py:1632] 
DEBUG 01-13 08:46:41.478175.478175 lmp.py:1632]   Computing 32 experts on CPU MP...
DEBUG 01-13 08:46:41.478720.478720 cuda_h.py:19] end cpu_experts_submit cost 5.030632019042969e-05 seconds
DEBUG 01-13 08:46:41.478509.478509 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-13 08:46:41.478623.478623 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-13 08:46:41.478561.478561 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-13 08:46:41.478305.478305 mlpmodule.py:785]  experts func einsum cost 0.06403732299804688 s
DEBUG 01-13 08:46:41.479419.479419 cuda_h.py:19] end allocate_cuda_memory cost 0.0012662410736083984 seconds
DEBUG 01-13 08:46:41.479541.479541 cuda_h.py:19] end experts_func_gpu_einsum_mp cost 0.06675338745117188 seconds
DEBUG 01-13 08:46:41.480353.480353 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-13 08:46:41.480335.480335 sllm_store_c.py:27] get device uuid map
DEBUG 01-13 08:46:41.480529.480529 sllm_store_c.py:29] call client load into gpu
DEBUG 01-13 08:46:41.480370.480370 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, c3643517-765f-45b1-a098-bbbe5abadf9f
DEBUG 01-13 08:46:41.480086.480086 client.py:106] call stub.LoadModelAsync
DEBUG 01-13 08:46:41.481480.481480 cuda_h.py:10] start experts_func_gpu_einsum_mp
INFO 01-13 08:46:41.481882.481882 client.py:127] Model loaded
DEBUG 01-13 08:46:41.481679.481679 cuda_h.py:10] start restore2model
DEBUG 01-13 08:46:41.481725.481725 cuda_h.py:19] end restore2model cost 0.00035500526428222656 seconds
DEBUG 01-13 08:46:41.481826.481826 cuda_h.py:19] end sllm_worker_task cost 0.010241031646728516 seconds
INFO 01-13 08:46:41.482616.482616 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, c3643517-765f-45b1-a098-bbbe5abadf9f
DEBUG 01-13 08:46:41.482559.482559 cuda_h.py:19] end load_into_gpu_async cost 0.00212860107421875 seconds
DEBUG 01-13 08:46:41.482454.482454 cuda_h.py:10] start restore_tensors2
DEBUG 01-13 08:46:41.482383.482383 cuda_h.py:19] end restore_tensors2 cost 0.00041174888610839844 seconds
DEBUG 01-13 08:46:41.482610.482610 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0045320987701416016 seconds
DEBUG 01-13 08:46:41.482280.482280 cuda_h.py:10] start restore2model
DEBUG 01-13 08:46:41.485679.485679 cuda_h.py:19] end restore2model cost 0.0025827884674072266 seconds
DEBUG 01-13 08:46:41.485800.485800 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.00728607177734375 seconds
DEBUG 01-13 08:46:41.485165.485165 cuda_h.py:10] start gpu_sexperts
DEBUG 01-13 08:46:41.485764.485764 cuda_h.py:19] end gpu_sexperts cost 0.00027179718017578125 seconds
DEBUG 01-13 08:46:41.485971.485971 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-13 08:46:41.485264.485264 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 1.430511474609375e-05 seconds
DEBUG 01-13 08:46:41.485245.485245 cuda_h.py:10] start wait_experts
INFO 01-13 08:46:41.485225.485225 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, c3643517-765f-45b1-a098-bbbe5abadf9f
DEBUG 01-13 08:46:41.490800.490800 mlpmodule.py:1006] group tensors cost 0.00834965705871582 s
DEBUG 01-13 08:46:41.492349.492349 mlpmodule.py:1044] pad cost 0.002004861831665039 s
DEBUG 01-13 08:46:41.492049.492049 mlpmodule.py:1050] create cpu tensor cost 7.081031799316406e-05 s
DEBUG 01-13 08:46:41.492343.492343 mlpmodule.py:1055] move to cpu cost 3.9577484130859375e-05 s
DEBUG 01-13 08:46:41.503238.503238 mlpmodule.py:1069] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-13 08:46:41.503086.503086 mlpmodule.py:1070] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-13 08:46:41.503659.503659 mlpmodule.py:1075] group_w3 first element: -0.006134033203125
WARNING 01-13 08:46:41.503610.503610 mlpmodule.py:1085] start einsum2
DEBUG 01-13 08:46:41.516659.516659 mlpmodule.py:1095] group einsum cost 0.02380990982055664 s
DEBUG 01-13 08:46:41.517266.517266 mlpmodule.py:1103] cpy2cputensor cost 0.0006620883941650391 s
INFO 01-13 08:46:41.532630.532630 client.py:127] Model loaded
DEBUG 01-13 08:46:41.533549.533549 cuda_h.py:19] end wait_experts cost 0.04702305793762207 seconds
DEBUG 01-13 08:46:41.533974.533974 cuda_h.py:10] start gpu_experts
DEBUG 01-13 08:46:41.533178.533178 mlpmodule.py:559] gpu group tensors cost 0.0006494522094726562 s
DEBUG 01-13 08:46:41.535549.535549 mlpmodule.py:592] gpu pad cost 0.0015377998352050781 s
DEBUG 01-13 08:46:41.535334.535334 mlpmodule.py:598] start_w1
DEBUG 01-13 08:46:41.535466.535466 mlpmodule.py:602] start_w3
DEBUG 01-13 08:46:41.536942.536942 mlpmodule.py:608] start_w2
DEBUG 01-13 08:46:41.536649.536649 mlpmodule.py:611] gpu group einsum cost 0.0007231235504150391 s
DEBUG 01-13 08:46:41.538756.538756 mlpmodule.py:683] gpu experts func einsum cost 0.005257606506347656 s
DEBUG 01-13 08:46:41.538394.538394 cuda_h.py:19] end gpu_experts cost 0.005411624908447266 seconds
DEBUG 01-13 08:46:41.538620.538620 cuda_h.py:10] start cpu_thread_manager_mp_wait
DEBUG 01-13 08:46:41.538947.538947 cuda_h.py:19] end cpu_thread_manager_mp_wait cost 3.838539123535156e-05 seconds
DEBUG 01-13 08:46:41.538387.538387 cuda_h.py:19] end layer_moe_generate_mp_l_12 cost 0.0628812313079834 seconds
DEBUG 01-13 08:46:41.538329.538329 lmp.py:1550] -------------------------------- end prefill layer 11 --------------------------------
DEBUG 01-13 08:46:41.538614.538614 lmp.py:1493] -------------------------------- start prefill layer 12 --------------------------------
DEBUG 01-13 08:46:41.538218.538218 cuda_h.py:10] start start_load_qkvogn_s_weight_l_13
DEBUG 01-13 08:46:41.538828.538828 cuda_h.py:10] start start_load_qkvogn_s_weight_l_13
DEBUG 01-13 08:46:41.539380.539380 cuda_h.py:19] end start_load_qkvogn_s_weight_l_13 cost 3.1948089599609375e-05 seconds
DEBUG 01-13 08:46:41.539388.539388 cuda_h.py:19] end start_load_qkvogn_s_weight_l_13 cost 7.62939453125e-05 seconds
DEBUG 01-13 08:46:41.539845.539845 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-13 08:46:41.539841.539841 cuda_h.py:10] start sllm_worker_task
DEBUG 01-13 08:46:41.539011.539011 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-13 08:46:41.539840.539840 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-13 08:46:41.539857.539857 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-13 08:46:41.539270.539270 cuda_h.py:19] end allocate_cuda_memory cost 0.00040531158447265625 seconds
DEBUG 01-13 08:46:41.540584.540584 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-13 08:46:41.540393.540393 sllm_store_c.py:27] get device uuid map
DEBUG 01-13 08:46:41.540945.540945 sllm_store_c.py:29] call client load into gpu
DEBUG 01-13 08:46:41.540601.540601 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 08f80238-d915-4f55-a5da-20a844b77c17
DEBUG 01-13 08:46:41.540339.540339 client.py:106] call stub.LoadModelAsync
DEBUG 01-13 08:46:41.540957.540957 cuda_h.py:10] start self_attn
DEBUG 01-13 08:46:41.541368.541368 mlpmodule.py:785]  experts func einsum cost 0.05973386764526367 s
INFO 01-13 08:46:41.541311.541311 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 08f80238-d915-4f55-a5da-20a844b77c17
DEBUG 01-13 08:46:41.541181.541181 cuda_h.py:19] end load_into_gpu_async cost 0.0017642974853515625 seconds
DEBUG 01-13 08:46:41.541229.541229 cuda_h.py:10] start restore_tensors2
DEBUG 01-13 08:46:41.541277.541277 cuda_h.py:19] end experts_func_gpu_einsum_mp cost 0.06072735786437988 seconds
DEBUG 01-13 08:46:41.541887.541887 cuda_h.py:19] end restore_tensors2 cost 7.081031799316406e-05 seconds
DEBUG 01-13 08:46:41.541286.541286 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0025491714477539062 seconds
INFO 01-13 08:46:41.542454.542454 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 08f80238-d915-4f55-a5da-20a844b77c17
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-13 08:46:41.543823.543823 cuda_h.py:19] end self_attn cost 0.0028612613677978516 seconds
DEBUG 01-13 08:46:41.543038.543038 cuda_h.py:19] end iln_self_attn_paln cost 0.004537105560302734 seconds
DEBUG 01-13 08:46:41.543258.543258 cuda_h.py:10] start layer_moe_generate_mp_l_13
DEBUG 01-13 08:46:41.543683.543683 cuda_h.py:10] start gate
DEBUG 01-13 08:46:41.544832.544832 cuda_h.py:19] end gate cost 0.0006389617919921875 seconds
DEBUG 01-13 08:46:41.544469.544469 cuda_h.py:10] start experts_map_get
DEBUG 01-13 08:46:41.544333.544333 lmp.py:1611] 
DEBUG 01-13 08:46:41.544333.544333 lmp.py:1611] Expert Token Distribution & Device Allocation:
DEBUG 01-13 08:46:41.544420.544420 lmp.py:1612]   Total experts: 64
DEBUG 01-13 08:46:41.544593.544593 lmp.py:1613]   CPU experts: 32 (50%)
DEBUG 01-13 08:46:41.544428.544428 lmp.py:1614]   GPU experts: 32 (50%)
DEBUG 01-13 08:46:41.544879.544879 lmp.py:1615] 
DEBUG 01-13 08:46:41.544879.544879 lmp.py:1615]   Expert ID | Tokens | Device
DEBUG 01-13 08:46:41.544045.544045 lmp.py:1616]   -----------------------------------
DEBUG 01-13 08:46:41.544456.544456 lmp.py:1622]   Expert 12 |     18 | CPU
DEBUG 01-13 08:46:41.544861.544861 lmp.py:1622]   Expert 47 |     19 | CPU
DEBUG 01-13 08:46:41.544312.544312 lmp.py:1622]   Expert 38 |     30 | CPU
DEBUG 01-13 08:46:41.544047.544047 lmp.py:1622]   Expert 16 |     35 | CPU
DEBUG 01-13 08:46:41.544260.544260 lmp.py:1622]   Expert 27 |     35 | CPU
DEBUG 01-13 08:46:41.544426.544426 lmp.py:1622]   Expert 52 |     37 | CPU
DEBUG 01-13 08:46:41.544115.544115 lmp.py:1622]   Expert 63 |     45 | CPU
DEBUG 01-13 08:46:41.545043.545043 lmp.py:1622]   Expert  4 |     56 | CPU
DEBUG 01-13 08:46:41.545494.545494 lmp.py:1622]   Expert 43 |     56 | CPU
DEBUG 01-13 08:46:41.545422.545422 lmp.py:1622]   Expert 44 |     56 | CPU
DEBUG 01-13 08:46:41.545396.545396 lmp.py:1622]   Expert 61 |     64 | CPU
DEBUG 01-13 08:46:41.545893.545893 lmp.py:1622]   Expert 34 |     69 | CPU
DEBUG 01-13 08:46:41.545105.545105 lmp.py:1622]   Expert 53 |     78 | CPU
DEBUG 01-13 08:46:41.545079.545079 lmp.py:1622]   Expert  0 |     82 | CPU
DEBUG 01-13 08:46:41.545815.545815 lmp.py:1622]   Expert 32 |     86 | CPU
DEBUG 01-13 08:46:41.545789.545789 lmp.py:1622]   Expert 37 |     92 | CPU
DEBUG 01-13 08:46:41.545525.545525 lmp.py:1622]   Expert 13 |    101 | CPU
DEBUG 01-13 08:46:41.545260.545260 lmp.py:1622]   Expert 39 |    111 | CPU
DEBUG 01-13 08:46:41.545996.545996 lmp.py:1622]   Expert 21 |    116 | CPU
DEBUG 01-13 08:46:41.545970.545970 lmp.py:1622]   Expert 11 |    118 | CPU
DEBUG 01-13 08:46:41.545467.545467 lmp.py:1622]   Expert 60 |    130 | CPU
DEBUG 01-13 08:46:41.545203.545203 lmp.py:1622]   Expert 20 |    132 | CPU
DEBUG 01-13 08:46:41.545415.545415 lmp.py:1622]   Expert  8 |    135 | CPU
DEBUG 01-13 08:46:41.545628.545628 lmp.py:1622]   Expert 14 |    138 | CPU
DEBUG 01-13 08:46:41.545555.545555 lmp.py:1622]   Expert 57 |    139 | CPU
DEBUG 01-13 08:46:41.545006.545006 lmp.py:1622]   Expert 22 |    142 | CPU
DEBUG 01-13 08:46:41.545173.545173 lmp.py:1622]   Expert  2 |    156 | CPU
DEBUG 01-13 08:46:41.545147.545147 lmp.py:1622]   Expert 45 |    159 | CPU
DEBUG 01-13 08:46:41.545121.545121 lmp.py:1622]   Expert 17 |    160 | CPU
DEBUG 01-13 08:46:41.545287.545287 lmp.py:1622]   Expert 18 |    164 | CPU
DEBUG 01-13 08:46:41.545453.545453 lmp.py:1622]   Expert 30 |    164 | CPU
DEBUG 01-13 08:46:41.545142.545142 lmp.py:1622]   Expert 58 |    164 | CPU
DEBUG 01-13 08:46:41.545593.545593 lmp.py:1622]   Expert  7 |    165 | GPU
DEBUG 01-13 08:46:41.545282.545282 lmp.py:1622]   Expert 23 |    166 | GPU
DEBUG 01-13 08:46:41.545210.545210 lmp.py:1622]   Expert 55 |    170 | GPU
DEBUG 01-13 08:46:41.545899.545899 lmp.py:1622]   Expert 42 |    173 | GPU
DEBUG 01-13 08:46:41.545304.545304 lmp.py:1622]   Expert 49 |    176 | GPU
DEBUG 01-13 08:46:41.545947.545947 lmp.py:1622]   Expert 51 |    176 | GPU
DEBUG 01-13 08:46:41.545590.545590 lmp.py:1622]   Expert 48 |    177 | GPU
DEBUG 01-13 08:46:41.545233.545233 lmp.py:1622]   Expert 62 |    178 | GPU
DEBUG 01-13 08:46:41.545161.545161 lmp.py:1622]   Expert 35 |    184 | GPU
DEBUG 01-13 08:46:41.545327.545327 lmp.py:1622]   Expert 29 |    187 | GPU
DEBUG 01-13 08:46:41.545254.545254 lmp.py:1622]   Expert 36 |    195 | GPU
DEBUG 01-13 08:46:41.545182.545182 lmp.py:1622]   Expert 25 |    197 | GPU
DEBUG 01-13 08:46:41.545395.545395 lmp.py:1622]   Expert  1 |    199 | GPU
DEBUG 01-13 08:46:41.545084.545084 lmp.py:1622]   Expert  6 |    199 | GPU
DEBUG 01-13 08:46:41.545773.545773 lmp.py:1622]   Expert 31 |    200 | GPU
DEBUG 01-13 08:46:41.545986.545986 lmp.py:1622]   Expert 28 |    219 | GPU
DEBUG 01-13 08:46:41.545198.545198 lmp.py:1622]   Expert 41 |    219 | GPU
DEBUG 01-13 08:46:41.545411.545411 lmp.py:1622]   Expert 54 |    229 | GPU
DEBUG 01-13 08:46:41.545623.545623 lmp.py:1622]   Expert  5 |    234 | GPU
DEBUG 01-13 08:46:41.545836.545836 lmp.py:1622]   Expert 19 |    234 | GPU
DEBUG 01-13 08:46:41.545002.545002 lmp.py:1622]   Expert  9 |    241 | GPU
DEBUG 01-13 08:46:41.545406.545406 lmp.py:1622]   Expert 24 |    244 | GPU
DEBUG 01-13 08:46:41.545572.545572 lmp.py:1622]   Expert 50 |    286 | GPU
DEBUG 01-13 08:46:41.545215.545215 lmp.py:1622]   Expert 59 |    303 | GPU
DEBUG 01-13 08:46:41.545620.545620 lmp.py:1622]   Expert 46 |    307 | GPU
DEBUG 01-13 08:46:41.545071.545071 lmp.py:1622]   Expert 56 |    373 | GPU
DEBUG 01-13 08:46:41.545760.545760 lmp.py:1622]   Expert 26 |    393 | GPU
DEBUG 01-13 08:46:41.545211.545211 lmp.py:1622]   Expert 33 |    429 | GPU
DEBUG 01-13 08:46:41.545423.545423 lmp.py:1622]   Expert  3 |    581 | GPU
DEBUG 01-13 08:46:41.545113.545113 lmp.py:1622]   Expert 15 |    668 | GPU
DEBUG 01-13 08:46:41.545802.545802 lmp.py:1622]   Expert 10 |    721 | GPU
DEBUG 01-13 08:46:41.545253.545253 lmp.py:1622]   Expert 40 |    778 | GPU
DEBUG 01-13 08:46:41.545657.545657 lmp.py:1623] 
DEBUG 01-13 08:46:41.545657.545657 lmp.py:1623]   CPU total tokens: 3087 (25.1%)
DEBUG 01-13 08:46:41.545777.545777 lmp.py:1624]   GPU total tokens: 9201 (74.9%)
DEBUG 01-13 08:46:41.545235.545235 cuda_h.py:19] end experts_map_get cost 0.0014858245849609375 seconds
DEBUG 01-13 08:46:41.546985.546985 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-13 08:46:41.546311.546311 lmp.py:1632] 
DEBUG 01-13 08:46:41.546311.546311 lmp.py:1632]   Computing 32 experts on CPU MP...
DEBUG 01-13 08:46:41.546187.546187 cuda_h.py:19] end cpu_experts_submit cost 4.863739013671875e-05 seconds
DEBUG 01-13 08:46:41.546188.546188 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-13 08:46:41.546739.546739 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-13 08:46:41.546923.546923 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-13 08:46:41.548795.548795 cuda_h.py:19] end allocate_cuda_memory cost 0.0016965866088867188 seconds
DEBUG 01-13 08:46:41.548577.548577 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-13 08:46:41.548082.548082 sllm_store_c.py:27] get device uuid map
DEBUG 01-13 08:46:41.548845.548845 sllm_store_c.py:29] call client load into gpu
DEBUG 01-13 08:46:41.548210.548210 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 85b216d9-f0ef-416d-8f46-58c3181d2efa
DEBUG 01-13 08:46:41.548468.548468 client.py:106] call stub.LoadModelAsync
DEBUG 01-13 08:46:41.549088.549088 cuda_h.py:10] start experts_func_gpu_einsum_mp
INFO 01-13 08:46:41.549554.549554 client.py:127] Model loaded
DEBUG 01-13 08:46:41.550247.550247 cuda_h.py:10] start restore2model
DEBUG 01-13 08:46:41.550486.550486 cuda_h.py:19] end restore2model cost 0.0005252361297607422 seconds
DEBUG 01-13 08:46:41.550540.550540 cuda_h.py:19] end sllm_worker_task cost 0.011420488357543945 seconds
INFO 01-13 08:46:41.551854.551854 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 85b216d9-f0ef-416d-8f46-58c3181d2efa
DEBUG 01-13 08:46:41.551580.551580 cuda_h.py:19] end load_into_gpu_async cost 0.003193378448486328 seconds
DEBUG 01-13 08:46:41.551451.551451 cuda_h.py:10] start restore_tensors2
DEBUG 01-13 08:46:41.552911.552911 cuda_h.py:19] end restore_tensors2 cost 0.0006203651428222656 seconds
DEBUG 01-13 08:46:41.552688.552688 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.006360530853271484 seconds
DEBUG 01-13 08:46:41.552233.552233 cuda_h.py:10] start restore2model
DEBUG 01-13 08:46:41.556582.556582 cuda_h.py:19] end restore2model cost 0.004042148590087891 seconds
DEBUG 01-13 08:46:41.556883.556883 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.010635614395141602 seconds
DEBUG 01-13 08:46:41.556645.556645 cuda_h.py:10] start gpu_sexperts
DEBUG 01-13 08:46:41.557348.557348 cuda_h.py:19] end gpu_sexperts cost 0.0003695487976074219 seconds
DEBUG 01-13 08:46:41.557913.557913 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-13 08:46:41.557233.557233 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 1.9073486328125e-05 seconds
DEBUG 01-13 08:46:41.557519.557519 cuda_h.py:10] start wait_experts
INFO 01-13 08:46:41.557566.557566 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 85b216d9-f0ef-416d-8f46-58c3181d2efa
DEBUG 01-13 08:46:41.561085.561085 mlpmodule.py:1006] group tensors cost 0.011099815368652344 s
DEBUG 01-13 08:46:41.565808.565808 mlpmodule.py:1044] pad cost 0.002527475357055664 s
DEBUG 01-13 08:46:41.565786.565786 mlpmodule.py:1050] create cpu tensor cost 6.318092346191406e-05 s
DEBUG 01-13 08:46:41.565703.565703 mlpmodule.py:1055] move to cpu cost 4.220008850097656e-05 s
DEBUG 01-13 08:46:41.574938.574938 mlpmodule.py:1069] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-13 08:46:41.574395.574395 mlpmodule.py:1070] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-13 08:46:41.574128.574128 mlpmodule.py:1075] group_w3 first element: -0.0162353515625
WARNING 01-13 08:46:41.574875.574875 mlpmodule.py:1085] start einsum2
DEBUG 01-13 08:46:41.588191.588191 mlpmodule.py:1095] group einsum cost 0.022810697555541992 s
DEBUG 01-13 08:46:41.589945.589945 mlpmodule.py:1103] cpy2cputensor cost 0.0006718635559082031 s
INFO 01-13 08:46:41.602537.602537 client.py:127] Model loaded
DEBUG 01-13 08:46:41.602483.602483 cuda_h.py:19] end wait_experts cost 0.04496932029724121 seconds
DEBUG 01-13 08:46:41.602485.602485 cuda_h.py:10] start gpu_experts
DEBUG 01-13 08:46:41.603242.603242 mlpmodule.py:559] gpu group tensors cost 0.0007603168487548828 s
DEBUG 01-13 08:46:41.605533.605533 mlpmodule.py:592] gpu pad cost 0.001684427261352539 s
DEBUG 01-13 08:46:41.605259.605259 mlpmodule.py:598] start_w1
DEBUG 01-13 08:46:41.605874.605874 mlpmodule.py:602] start_w3
DEBUG 01-13 08:46:41.605781.605781 mlpmodule.py:608] start_w2
DEBUG 01-13 08:46:41.605091.605091 mlpmodule.py:611] gpu group einsum cost 0.0007185935974121094 s
DEBUG 01-13 08:46:41.608089.608089 mlpmodule.py:683] gpu experts func einsum cost 0.005497455596923828 s
DEBUG 01-13 08:46:41.608040.608040 cuda_h.py:19] end gpu_experts cost 0.005681514739990234 seconds
DEBUG 01-13 08:46:41.608981.608981 cuda_h.py:10] start cpu_thread_manager_mp_wait
DEBUG 01-13 08:46:41.608070.608070 cuda_h.py:19] end cpu_thread_manager_mp_wait cost 3.814697265625e-05 seconds
DEBUG 01-13 08:46:41.608079.608079 cuda_h.py:19] end layer_moe_generate_mp_l_13 cost 0.0646207332611084 seconds
DEBUG 01-13 08:46:41.608326.608326 lmp.py:1550] -------------------------------- end prefill layer 12 --------------------------------
DEBUG 01-13 08:46:41.608943.608943 lmp.py:1493] -------------------------------- start prefill layer 13 --------------------------------
DEBUG 01-13 08:46:41.608023.608023 cuda_h.py:10] start start_load_qkvogn_s_weight_l_14
DEBUG 01-13 08:46:41.608726.608726 cuda_h.py:10] start start_load_qkvogn_s_weight_l_14
DEBUG 01-13 08:46:41.608085.608085 cuda_h.py:19] end start_load_qkvogn_s_weight_l_14 cost 3.0994415283203125e-05 seconds
DEBUG 01-13 08:46:41.608808.608808 cuda_h.py:19] end start_load_qkvogn_s_weight_l_14 cost 7.557868957519531e-05 seconds
DEBUG 01-13 08:46:41.608697.608697 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-13 08:46:41.608540.608540 cuda_h.py:10] start sllm_worker_task
DEBUG 01-13 08:46:41.609246.609246 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-13 08:46:41.609254.609254 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-13 08:46:41.609464.609464 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-13 08:46:41.609920.609920 cuda_h.py:19] end allocate_cuda_memory cost 0.0003323554992675781 seconds
DEBUG 01-13 08:46:41.609896.609896 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-13 08:46:41.609580.609580 sllm_store_c.py:27] get device uuid map
DEBUG 01-13 08:46:41.609595.609595 sllm_store_c.py:29] call client load into gpu
DEBUG 01-13 08:46:41.609867.609867 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 4ed13535-bc99-47c3-9f60-7fb79a91db5c
DEBUG 01-13 08:46:41.609936.609936 client.py:106] call stub.LoadModelAsync
DEBUG 01-13 08:46:41.610871.610871 cuda_h.py:10] start self_attn
DEBUG 01-13 08:46:41.611598.611598 mlpmodule.py:785]  experts func einsum cost 0.06029176712036133 s
INFO 01-13 08:46:41.611180.611180 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 4ed13535-bc99-47c3-9f60-7fb79a91db5c
DEBUG 01-13 08:46:41.611587.611587 cuda_h.py:19] end load_into_gpu_async cost 0.001795053482055664 seconds
DEBUG 01-13 08:46:41.611050.611050 cuda_h.py:19] end experts_func_gpu_einsum_mp cost 0.06160569190979004 seconds
DEBUG 01-13 08:46:41.611575.611575 cuda_h.py:10] start restore_tensors2
DEBUG 01-13 08:46:41.611373.611373 cuda_h.py:19] end restore_tensors2 cost 7.05718994140625e-05 seconds
DEBUG 01-13 08:46:41.611573.611573 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0024917125701904297 seconds
INFO 01-13 08:46:41.611786.611786 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 4ed13535-bc99-47c3-9f60-7fb79a91db5c
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-13 08:46:41.613454.613454 cuda_h.py:19] end self_attn cost 0.002897500991821289 seconds
DEBUG 01-13 08:46:41.613152.613152 cuda_h.py:19] end iln_self_attn_paln cost 0.004486083984375 seconds
DEBUG 01-13 08:46:41.613373.613373 cuda_h.py:10] start layer_moe_generate_mp_l_14
DEBUG 01-13 08:46:41.613275.613275 cuda_h.py:10] start gate
DEBUG 01-13 08:46:41.614025.614025 cuda_h.py:19] end gate cost 0.0006263256072998047 seconds
DEBUG 01-13 08:46:41.614663.614663 cuda_h.py:10] start experts_map_get
DEBUG 01-13 08:46:41.614202.614202 lmp.py:1611] 
DEBUG 01-13 08:46:41.614202.614202 lmp.py:1611] Expert Token Distribution & Device Allocation:
DEBUG 01-13 08:46:41.614289.614289 lmp.py:1612]   Total experts: 64
DEBUG 01-13 08:46:41.614939.614939 lmp.py:1613]   CPU experts: 32 (50%)
DEBUG 01-13 08:46:41.614013.614013 lmp.py:1614]   GPU experts: 32 (50%)
DEBUG 01-13 08:46:41.614940.614940 lmp.py:1615] 
DEBUG 01-13 08:46:41.614940.614940 lmp.py:1615]   Expert ID | Tokens | Device
DEBUG 01-13 08:46:41.614259.614259 lmp.py:1616]   -----------------------------------
DEBUG 01-13 08:46:41.614624.614624 lmp.py:1622]   Expert 19 |     19 | CPU
DEBUG 01-13 08:46:41.614313.614313 lmp.py:1622]   Expert 30 |     22 | CPU
DEBUG 01-13 08:46:41.614049.614049 lmp.py:1622]   Expert 42 |     23 | CPU
DEBUG 01-13 08:46:41.614785.614785 lmp.py:1622]   Expert 32 |     36 | CPU
DEBUG 01-13 08:46:41.614282.614282 lmp.py:1622]   Expert  6 |     51 | CPU
DEBUG 01-13 08:46:41.614017.614017 lmp.py:1622]   Expert 53 |     74 | CPU
DEBUG 01-13 08:46:41.614276.614276 lmp.py:1622]   Expert  5 |     80 | CPU
DEBUG 01-13 08:46:41.614012.614012 lmp.py:1622]   Expert  1 |     84 | CPU
DEBUG 01-13 08:46:41.614747.614747 lmp.py:1622]   Expert  9 |    113 | CPU
DEBUG 01-13 08:46:41.614437.614437 lmp.py:1622]   Expert 13 |    113 | CPU
DEBUG 01-13 08:46:41.614649.614649 lmp.py:1622]   Expert 63 |    122 | CPU
DEBUG 01-13 08:46:41.614862.614862 lmp.py:1622]   Expert 34 |    127 | CPU
DEBUG 01-13 08:46:41.614313.614313 lmp.py:1622]   Expert 26 |    130 | CPU
DEBUG 01-13 08:46:41.614763.614763 lmp.py:1622]   Expert 50 |    131 | CPU
DEBUG 01-13 08:46:41.614499.614499 lmp.py:1622]   Expert 59 |    131 | CPU
DEBUG 01-13 08:46:41.614473.614473 lmp.py:1622]   Expert 58 |    132 | CPU
DEBUG 01-13 08:46:41.614732.614732 lmp.py:1622]   Expert 31 |    137 | CPU
DEBUG 01-13 08:46:41.614229.614229 lmp.py:1622]   Expert 40 |    143 | CPU
DEBUG 01-13 08:46:41.614965.614965 lmp.py:1622]   Expert 18 |    145 | CPU
DEBUG 01-13 08:46:41.614462.614462 lmp.py:1622]   Expert 12 |    146 | CPU
DEBUG 01-13 08:46:41.614198.614198 lmp.py:1622]   Expert 46 |    147 | CPU
DEBUG 01-13 08:46:41.614887.614887 lmp.py:1622]   Expert  2 |    149 | CPU
DEBUG 01-13 08:46:41.614576.614576 lmp.py:1622]   Expert 56 |    151 | CPU
DEBUG 01-13 08:46:41.614789.614789 lmp.py:1622]   Expert 11 |    152 | CPU
DEBUG 01-13 08:46:41.614001.614001 lmp.py:1622]   Expert 61 |    152 | CPU
DEBUG 01-13 08:46:41.614498.614498 lmp.py:1622]   Expert  4 |    154 | CPU
DEBUG 01-13 08:46:41.614995.614995 lmp.py:1622]   Expert 48 |    154 | CPU
DEBUG 01-13 08:46:41.615493.615493 lmp.py:1622]   Expert 20 |    155 | CPU
DEBUG 01-13 08:46:41.615659.615659 lmp.py:1622]   Expert 33 |    160 | CPU
DEBUG 01-13 08:46:41.615871.615871 lmp.py:1622]   Expert 10 |    162 | CPU
DEBUG 01-13 08:46:41.615084.615084 lmp.py:1622]   Expert 35 |    164 | CPU
DEBUG 01-13 08:46:41.615773.615773 lmp.py:1622]   Expert 55 |    166 | CPU
DEBUG 01-13 08:46:41.615224.615224 lmp.py:1622]   Expert 36 |    177 | GPU
DEBUG 01-13 08:46:41.615436.615436 lmp.py:1622]   Expert 51 |    180 | GPU
DEBUG 01-13 08:46:41.615079.615079 lmp.py:1622]   Expert  8 |    182 | GPU
DEBUG 01-13 08:46:41.615722.615722 lmp.py:1622]   Expert 52 |    188 | GPU
DEBUG 01-13 08:46:41.615650.615650 lmp.py:1622]   Expert 37 |    195 | GPU
DEBUG 01-13 08:46:41.615055.615055 lmp.py:1622]   Expert 57 |    200 | GPU
DEBUG 01-13 08:46:41.615744.615744 lmp.py:1622]   Expert  0 |    203 | GPU
DEBUG 01-13 08:46:41.615433.615433 lmp.py:1622]   Expert 39 |    219 | GPU
DEBUG 01-13 08:46:41.615123.615123 lmp.py:1622]   Expert 62 |    231 | GPU
DEBUG 01-13 08:46:41.615097.615097 lmp.py:1622]   Expert 25 |    232 | GPU
DEBUG 01-13 08:46:41.615786.615786 lmp.py:1622]   Expert 38 |    242 | GPU
DEBUG 01-13 08:46:41.615998.615998 lmp.py:1622]   Expert 27 |    247 | GPU
DEBUG 01-13 08:46:41.615688.615688 lmp.py:1622]   Expert 16 |    248 | GPU
DEBUG 01-13 08:46:41.615900.615900 lmp.py:1622]   Expert  7 |    251 | GPU
DEBUG 01-13 08:46:41.615351.615351 lmp.py:1622]   Expert 28 |    253 | GPU
DEBUG 01-13 08:46:41.615994.615994 lmp.py:1622]   Expert  3 |    255 | GPU
DEBUG 01-13 08:46:41.615160.615160 lmp.py:1622]   Expert 60 |    261 | GPU
DEBUG 01-13 08:46:41.615565.615565 lmp.py:1622]   Expert 21 |    263 | GPU
DEBUG 01-13 08:46:41.615969.615969 lmp.py:1622]   Expert 49 |    263 | GPU
DEBUG 01-13 08:46:41.615420.615420 lmp.py:1622]   Expert 24 |    266 | GPU
DEBUG 01-13 08:46:41.615394.615394 lmp.py:1622]   Expert 43 |    266 | GPU
DEBUG 01-13 08:46:41.615607.615607 lmp.py:1622]   Expert 29 |    279 | GPU
DEBUG 01-13 08:46:41.615581.615581 lmp.py:1622]   Expert 22 |    280 | GPU
DEBUG 01-13 08:46:41.615555.615555 lmp.py:1622]   Expert 23 |    283 | GPU
DEBUG 01-13 08:46:41.615529.615529 lmp.py:1622]   Expert 47 |    288 | GPU
DEBUG 01-13 08:46:41.615980.615980 lmp.py:1622]   Expert 15 |    297 | GPU
DEBUG 01-13 08:46:41.615954.615954 lmp.py:1622]   Expert 44 |    302 | GPU
DEBUG 01-13 08:46:41.615928.615928 lmp.py:1622]   Expert 41 |    316 | GPU
DEBUG 01-13 08:46:41.615617.615617 lmp.py:1622]   Expert 14 |    372 | GPU
DEBUG 01-13 08:46:41.615068.615068 lmp.py:1622]   Expert 54 |    376 | GPU
DEBUG 01-13 08:46:41.615996.615996 lmp.py:1622]   Expert 17 |    402 | GPU
DEBUG 01-13 08:46:41.615923.615923 lmp.py:1622]   Expert 45 |    446 | GPU
DEBUG 01-13 08:46:41.615805.615805 lmp.py:1623] 
DEBUG 01-13 08:46:41.615805.615805 lmp.py:1623]   CPU total tokens: 3825 (31.1%)
DEBUG 01-13 08:46:41.615925.615925 lmp.py:1624]   GPU total tokens: 8463 (68.9%)
DEBUG 01-13 08:46:41.615144.615144 cuda_h.py:19] end experts_map_get cost 0.0014865398406982422 seconds
DEBUG 01-13 08:46:41.615802.615802 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-13 08:46:41.615935.615935 lmp.py:1632] 
DEBUG 01-13 08:46:41.615935.615935 lmp.py:1632]   Computing 32 experts on CPU MP...
DEBUG 01-13 08:46:41.615857.615857 cuda_h.py:19] end cpu_experts_submit cost 4.792213439941406e-05 seconds
DEBUG 01-13 08:46:41.615169.615169 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-13 08:46:41.615522.615522 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-13 08:46:41.616520.616520 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-13 08:46:41.617251.617251 cuda_h.py:19] end allocate_cuda_memory cost 0.0018401145935058594 seconds
DEBUG 01-13 08:46:41.617499.617499 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-13 08:46:41.617255.617255 sllm_store_c.py:27] get device uuid map
DEBUG 01-13 08:46:41.618541.618541 sllm_store_c.py:29] call client load into gpu
DEBUG 01-13 08:46:41.618906.618906 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 700ebf7d-e884-4f9f-9c77-37603f803a3e
DEBUG 01-13 08:46:41.618018.618018 client.py:106] call stub.LoadModelAsync
INFO 01-13 08:46:41.618102.618102 client.py:127] Model loaded
DEBUG 01-13 08:46:41.618600.618600 cuda_h.py:10] start restore2model
DEBUG 01-13 08:46:41.619258.619258 cuda_h.py:10] start experts_func_gpu_einsum_mp
DEBUG 01-13 08:46:41.619466.619466 cuda_h.py:19] end restore2model cost 0.0003261566162109375 seconds
DEBUG 01-13 08:46:41.619044.619044 cuda_h.py:19] end sllm_worker_task cost 0.010145425796508789 seconds
INFO 01-13 08:46:41.620344.620344 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 700ebf7d-e884-4f9f-9c77-37603f803a3e
DEBUG 01-13 08:46:41.620810.620810 cuda_h.py:19] end load_into_gpu_async cost 0.0023376941680908203 seconds
DEBUG 01-13 08:46:41.620990.620990 cuda_h.py:10] start restore_tensors2
DEBUG 01-13 08:46:41.620348.620348 cuda_h.py:19] end restore_tensors2 cost 0.00037670135498046875 seconds
DEBUG 01-13 08:46:41.620853.620853 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.004925966262817383 seconds
DEBUG 01-13 08:46:41.620954.620954 cuda_h.py:10] start restore2model
DEBUG 01-13 08:46:41.623604.623604 cuda_h.py:19] end restore2model cost 0.0025932788848876953 seconds
DEBUG 01-13 08:46:41.623639.623639 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.007699489593505859 seconds
DEBUG 01-13 08:46:41.623720.623720 cuda_h.py:10] start gpu_sexperts
DEBUG 01-13 08:46:41.623975.623975 cuda_h.py:19] end gpu_sexperts cost 0.0002627372741699219 seconds
DEBUG 01-13 08:46:41.623466.623466 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-13 08:46:41.623236.623236 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 1.3828277587890625e-05 seconds
DEBUG 01-13 08:46:41.623932.623932 cuda_h.py:10] start wait_experts
INFO 01-13 08:46:41.623389.623389 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 700ebf7d-e884-4f9f-9c77-37603f803a3e
DEBUG 01-13 08:46:41.630958.630958 mlpmodule.py:1006] group tensors cost 0.010433435440063477 s
DEBUG 01-13 08:46:41.632576.632576 mlpmodule.py:1044] pad cost 0.0017139911651611328 s
DEBUG 01-13 08:46:41.632712.632712 mlpmodule.py:1050] create cpu tensor cost 4.506111145019531e-05 s
DEBUG 01-13 08:46:41.632661.632661 mlpmodule.py:1055] move to cpu cost 3.504753112792969e-05 s
DEBUG 01-13 08:46:41.640859.640859 mlpmodule.py:1069] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-13 08:46:41.641242.641242 mlpmodule.py:1070] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-13 08:46:41.641478.641478 mlpmodule.py:1075] group_w3 first element: -0.0211181640625
WARNING 01-13 08:46:41.641131.641131 mlpmodule.py:1085] start einsum2
DEBUG 01-13 08:46:41.654435.654435 mlpmodule.py:1095] group einsum cost 0.021457910537719727 s
DEBUG 01-13 08:46:41.655861.655861 mlpmodule.py:1103] cpy2cputensor cost 0.0006647109985351562 s
INFO 01-13 08:46:41.670557.670557 client.py:127] Model loaded
DEBUG 01-13 08:46:41.671323.671323 cuda_h.py:19] end wait_experts cost 0.047041893005371094 seconds
DEBUG 01-13 08:46:41.671132.671132 cuda_h.py:10] start gpu_experts
DEBUG 01-13 08:46:41.671234.671234 mlpmodule.py:559] gpu group tensors cost 0.0005705356597900391 s
DEBUG 01-13 08:46:41.673832.673832 mlpmodule.py:592] gpu pad cost 0.0015697479248046875 s
DEBUG 01-13 08:46:41.673246.673246 mlpmodule.py:598] start_w1
DEBUG 01-13 08:46:41.673402.673402 mlpmodule.py:602] start_w3
DEBUG 01-13 08:46:41.673355.673355 mlpmodule.py:608] start_w2
DEBUG 01-13 08:46:41.673388.673388 mlpmodule.py:785]  experts func einsum cost 0.0543520450592041 s
DEBUG 01-13 08:46:41.674870.674870 mlpmodule.py:611] gpu group einsum cost 0.0006358623504638672 s
DEBUG 01-13 08:46:41.674321.674321 cuda_h.py:19] end experts_func_gpu_einsum_mp cost 0.05495572090148926 seconds
DEBUG 01-13 08:46:41.676305.676305 mlpmodule.py:683] gpu experts func einsum cost 0.005049943923950195 s
DEBUG 01-13 08:46:41.676917.676917 cuda_h.py:19] end gpu_experts cost 0.00522303581237793 seconds
DEBUG 01-13 08:46:41.676528.676528 cuda_h.py:10] start cpu_thread_manager_mp_wait
DEBUG 01-13 08:46:41.676789.676789 cuda_h.py:19] end cpu_thread_manager_mp_wait cost 5.269050598144531e-05 seconds
DEBUG 01-13 08:46:41.676189.676189 cuda_h.py:19] end layer_moe_generate_mp_l_14 cost 0.06310677528381348 seconds
DEBUG 01-13 08:46:41.676714.676714 lmp.py:1550] -------------------------------- end prefill layer 13 --------------------------------
DEBUG 01-13 08:46:41.676284.676284 lmp.py:1493] -------------------------------- start prefill layer 14 --------------------------------
DEBUG 01-13 08:46:41.676272.676272 cuda_h.py:10] start start_load_qkvogn_s_weight_l_15
DEBUG 01-13 08:46:41.676651.676651 cuda_h.py:10] start start_load_qkvogn_s_weight_l_15
DEBUG 01-13 08:46:41.676871.676871 cuda_h.py:19] end start_load_qkvogn_s_weight_l_15 cost 3.075599670410156e-05 seconds
DEBUG 01-13 08:46:41.676905.676905 cuda_h.py:19] end start_load_qkvogn_s_weight_l_15 cost 5.888938903808594e-05 seconds
DEBUG 01-13 08:46:41.676786.676786 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-13 08:46:41.677146.677146 cuda_h.py:10] start sllm_worker_task
DEBUG 01-13 08:46:41.677978.677978 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-13 08:46:41.677271.677271 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-13 08:46:41.677811.677811 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-13 08:46:41.677631.677631 cuda_h.py:19] end allocate_cuda_memory cost 0.0003218650817871094 seconds
DEBUG 01-13 08:46:41.677812.677812 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-13 08:46:41.677806.677806 sllm_store_c.py:27] get device uuid map
DEBUG 01-13 08:46:41.677960.677960 sllm_store_c.py:29] call client load into gpu
DEBUG 01-13 08:46:41.677040.677040 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 1415fbe5-7c1a-4fae-a632-04d981a1cc53
DEBUG 01-13 08:46:41.677772.677772 client.py:106] call stub.LoadModelAsync
DEBUG 01-13 08:46:41.678913.678913 cuda_h.py:10] start self_attn
INFO 01-13 08:46:41.679192.679192 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 1415fbe5-7c1a-4fae-a632-04d981a1cc53
DEBUG 01-13 08:46:41.679789.679789 cuda_h.py:19] end load_into_gpu_async cost 0.0016717910766601562 seconds
DEBUG 01-13 08:46:41.679393.679393 cuda_h.py:10] start restore_tensors2
DEBUG 01-13 08:46:41.679707.679707 cuda_h.py:19] end restore_tensors2 cost 6.628036499023438e-05 seconds
DEBUG 01-13 08:46:41.679854.679854 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.002299785614013672 seconds
INFO 01-13 08:46:41.679829.679829 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 1415fbe5-7c1a-4fae-a632-04d981a1cc53
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-13 08:46:41.681454.681454 cuda_h.py:19] end self_attn cost 0.0028307437896728516 seconds
DEBUG 01-13 08:46:41.681086.681086 cuda_h.py:19] end iln_self_attn_paln cost 0.0043718814849853516 seconds
DEBUG 01-13 08:46:41.681545.681545 cuda_h.py:10] start layer_moe_generate_mp_l_15
DEBUG 01-13 08:46:41.681924.681924 cuda_h.py:10] start gate
DEBUG 01-13 08:46:41.682820.682820 cuda_h.py:19] end gate cost 0.0006287097930908203 seconds
DEBUG 01-13 08:46:41.682696.682696 cuda_h.py:10] start experts_map_get
DEBUG 01-13 08:46:41.682421.682421 lmp.py:1611] 
DEBUG 01-13 08:46:41.682421.682421 lmp.py:1611] Expert Token Distribution & Device Allocation:
DEBUG 01-13 08:46:41.682223.682223 lmp.py:1612]   Total experts: 64
DEBUG 01-13 08:46:41.682634.682634 lmp.py:1613]   CPU experts: 32 (50%)
DEBUG 01-13 08:46:41.682231.682231 lmp.py:1614]   GPU experts: 32 (50%)
DEBUG 01-13 08:46:41.682443.682443 lmp.py:1615] 
DEBUG 01-13 08:46:41.682443.682443 lmp.py:1615]   Expert ID | Tokens | Device
DEBUG 01-13 08:46:41.682371.682371 lmp.py:1616]   -----------------------------------
DEBUG 01-13 08:46:41.682021.682021 lmp.py:1622]   Expert  7 |     29 | CPU
DEBUG 01-13 08:46:41.682425.682425 lmp.py:1622]   Expert 34 |     33 | CPU
DEBUG 01-13 08:46:41.682638.682638 lmp.py:1622]   Expert 13 |     42 | CPU
DEBUG 01-13 08:46:41.682850.682850 lmp.py:1622]   Expert 54 |     77 | CPU
DEBUG 01-13 08:46:41.682063.682063 lmp.py:1622]   Expert 18 |     81 | CPU
DEBUG 01-13 08:46:41.682037.682037 lmp.py:1622]   Expert 49 |     85 | CPU
DEBUG 01-13 08:46:41.682011.682011 lmp.py:1622]   Expert 39 |     92 | CPU
DEBUG 01-13 08:46:41.682508.682508 lmp.py:1622]   Expert 21 |     96 | CPU
DEBUG 01-13 08:46:41.682721.682721 lmp.py:1622]   Expert  0 |     99 | CPU
DEBUG 01-13 08:46:41.682695.682695 lmp.py:1622]   Expert 16 |    103 | CPU
DEBUG 01-13 08:46:41.682384.682384 lmp.py:1622]   Expert 59 |    109 | CPU
DEBUG 01-13 08:46:41.682312.682312 lmp.py:1622]   Expert 45 |    116 | CPU
DEBUG 01-13 08:46:41.682239.682239 lmp.py:1622]   Expert 41 |    119 | CPU
DEBUG 01-13 08:46:41.682929.682929 lmp.py:1622]   Expert 15 |    120 | CPU
DEBUG 01-13 08:46:41.682141.682141 lmp.py:1622]   Expert 61 |    122 | CPU
DEBUG 01-13 08:46:41.682638.682638 lmp.py:1622]   Expert 22 |    123 | CPU
DEBUG 01-13 08:46:41.682612.682612 lmp.py:1622]   Expert 17 |    127 | CPU
DEBUG 01-13 08:46:41.682110.682110 lmp.py:1622]   Expert 52 |    132 | CPU
DEBUG 01-13 08:46:41.682845.682845 lmp.py:1622]   Expert  8 |    142 | CPU
DEBUG 01-13 08:46:41.682581.682581 lmp.py:1622]   Expert 38 |    143 | CPU
DEBUG 01-13 08:46:41.682316.682316 lmp.py:1622]   Expert 35 |    144 | CPU
DEBUG 01-13 08:46:41.682052.682052 lmp.py:1622]   Expert 12 |    146 | CPU
DEBUG 01-13 08:46:41.682695.682695 lmp.py:1622]   Expert 48 |    147 | CPU
DEBUG 01-13 08:46:41.682384.682384 lmp.py:1622]   Expert 31 |    154 | CPU
DEBUG 01-13 08:46:41.682074.682074 lmp.py:1622]   Expert 36 |    154 | CPU
DEBUG 01-13 08:46:41.683763.683763 lmp.py:1622]   Expert 40 |    156 | CPU
DEBUG 01-13 08:46:41.683406.683406 lmp.py:1622]   Expert 50 |    157 | CPU
DEBUG 01-13 08:46:41.683095.683095 lmp.py:1622]   Expert 53 |    160 | CPU
DEBUG 01-13 08:46:41.683261.683261 lmp.py:1622]   Expert 60 |    169 | CPU
DEBUG 01-13 08:46:41.683428.683428 lmp.py:1622]   Expert 27 |    173 | CPU
DEBUG 01-13 08:46:41.683594.683594 lmp.py:1622]   Expert 19 |    195 | CPU
DEBUG 01-13 08:46:41.683045.683045 lmp.py:1622]   Expert  4 |    197 | CPU
DEBUG 01-13 08:46:41.683734.683734 lmp.py:1622]   Expert 29 |    202 | GPU
DEBUG 01-13 08:46:41.683662.683662 lmp.py:1622]   Expert 30 |    204 | GPU
DEBUG 01-13 08:46:41.683112.683112 lmp.py:1622]   Expert 20 |    220 | GPU
DEBUG 01-13 08:46:41.683563.683563 lmp.py:1622]   Expert 26 |    220 | GPU
DEBUG 01-13 08:46:41.683491.683491 lmp.py:1622]   Expert  6 |    223 | GPU
DEBUG 01-13 08:46:41.683180.683180 lmp.py:1622]   Expert 11 |    223 | GPU
DEBUG 01-13 08:46:41.683870.683870 lmp.py:1622]   Expert 57 |    224 | GPU
DEBUG 01-13 08:46:41.683559.683559 lmp.py:1622]   Expert 46 |    225 | GPU
DEBUG 01-13 08:46:41.683771.683771 lmp.py:1622]   Expert 33 |    235 | GPU
DEBUG 01-13 08:46:41.683699.683699 lmp.py:1622]   Expert 43 |    235 | GPU
DEBUG 01-13 08:46:41.683150.683150 lmp.py:1622]   Expert 23 |    242 | GPU
DEBUG 01-13 08:46:41.683078.683078 lmp.py:1622]   Expert 42 |    246 | GPU
DEBUG 01-13 08:46:41.683721.683721 lmp.py:1622]   Expert 55 |    247 | GPU
DEBUG 01-13 08:46:41.683602.683602 lmp.py:1622]   Expert  2 |    253 | GPU
DEBUG 01-13 08:46:41.683768.683768 lmp.py:1622]   Expert 28 |    253 | GPU
DEBUG 01-13 08:46:41.683411.683411 lmp.py:1622]   Expert 56 |    257 | GPU
DEBUG 01-13 08:46:41.683339.683339 lmp.py:1622]   Expert  9 |    259 | GPU
DEBUG 01-13 08:46:41.683790.683790 lmp.py:1622]   Expert 32 |    263 | GPU
DEBUG 01-13 08:46:41.683002.683002 lmp.py:1622]   Expert  3 |    265 | GPU
DEBUG 01-13 08:46:41.683930.683930 lmp.py:1622]   Expert 44 |    271 | GPU
DEBUG 01-13 08:46:41.683619.683619 lmp.py:1622]   Expert 51 |    273 | GPU
DEBUG 01-13 08:46:41.683070.683070 lmp.py:1622]   Expert 58 |    275 | GPU
DEBUG 01-13 08:46:41.683759.683759 lmp.py:1622]   Expert 14 |    278 | GPU
DEBUG 01-13 08:46:41.683210.683210 lmp.py:1622]   Expert  1 |    280 | GPU
DEBUG 01-13 08:46:41.683661.683661 lmp.py:1622]   Expert 47 |    287 | GPU
DEBUG 01-13 08:46:41.683351.683351 lmp.py:1622]   Expert 63 |    290 | GPU
DEBUG 01-13 08:46:41.683040.683040 lmp.py:1622]   Expert 62 |    291 | GPU
DEBUG 01-13 08:46:41.683683.683683 lmp.py:1622]   Expert 37 |    298 | GPU
DEBUG 01-13 08:46:41.683564.683564 lmp.py:1622]   Expert 10 |    308 | GPU
DEBUG 01-13 08:46:41.683207.683207 lmp.py:1622]   Expert 25 |    319 | GPU
DEBUG 01-13 08:46:41.683612.683612 lmp.py:1622]   Expert 24 |    320 | GPU
DEBUG 01-13 08:46:41.683539.683539 lmp.py:1622]   Expert  5 |    360 | GPU
DEBUG 01-13 08:46:41.683706.683706 lmp.py:1623] 
DEBUG 01-13 08:46:41.683706.683706 lmp.py:1623]   CPU total tokens: 3942 (32.1%)
DEBUG 01-13 08:46:41.683587.683587 lmp.py:1624]   GPU total tokens: 8346 (67.9%)
DEBUG 01-13 08:46:41.683283.683283 cuda_h.py:19] end experts_map_get cost 0.001493692398071289 seconds
DEBUG 01-13 08:46:41.683795.683795 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-13 08:46:41.683167.683167 lmp.py:1632] 
DEBUG 01-13 08:46:41.683167.683167 lmp.py:1632]   Computing 32 experts on CPU MP...
DEBUG 01-13 08:46:41.683566.683566 cuda_h.py:19] end cpu_experts_submit cost 4.839897155761719e-05 seconds
DEBUG 01-13 08:46:41.683831.683831 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-13 08:46:41.683946.683946 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-13 08:46:41.684129.684129 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-13 08:46:41.686990.686990 cuda_h.py:19] end allocate_cuda_memory cost 0.0019347667694091797 seconds
DEBUG 01-13 08:46:41.686522.686522 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-13 08:46:41.686278.686278 sllm_store_c.py:27] get device uuid map
DEBUG 01-13 08:46:41.686087.686087 sllm_store_c.py:29] call client load into gpu
DEBUG 01-13 08:46:41.686929.686929 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 9e721007-e4fc-4d54-838f-a49cb4d611db
DEBUG 01-13 08:46:41.686611.686611 client.py:106] call stub.LoadModelAsync
INFO 01-13 08:46:41.686376.686376 client.py:127] Model loaded
DEBUG 01-13 08:46:41.686776.686776 cuda_h.py:10] start restore2model
DEBUG 01-13 08:46:41.687426.687426 cuda_h.py:10] start experts_func_gpu_einsum_mp
DEBUG 01-13 08:46:41.687639.687639 cuda_h.py:19] end restore2model cost 0.00041866302490234375 seconds
DEBUG 01-13 08:46:41.687468.687468 cuda_h.py:19] end sllm_worker_task cost 0.010267257690429688 seconds
INFO 01-13 08:46:41.688904.688904 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 9e721007-e4fc-4d54-838f-a49cb4d611db
DEBUG 01-13 08:46:41.688416.688416 cuda_h.py:19] end load_into_gpu_async cost 0.0021359920501708984 seconds
DEBUG 01-13 08:46:41.688549.688549 cuda_h.py:10] start restore_tensors2
DEBUG 01-13 08:46:41.688377.688377 cuda_h.py:19] end restore_tensors2 cost 0.00037217140197753906 seconds
DEBUG 01-13 08:46:41.688790.688790 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.004813194274902344 seconds
DEBUG 01-13 08:46:41.688745.688745 cuda_h.py:10] start restore2model
DEBUG 01-13 08:46:41.691289.691289 cuda_h.py:19] end restore2model cost 0.0025844573974609375 seconds
DEBUG 01-13 08:46:41.691125.691125 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.007569551467895508 seconds
DEBUG 01-13 08:46:41.691775.691775 cuda_h.py:10] start gpu_sexperts
DEBUG 01-13 08:46:41.691745.691745 cuda_h.py:19] end gpu_sexperts cost 0.0002644062042236328 seconds
DEBUG 01-13 08:46:41.691383.691383 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-13 08:46:41.691059.691059 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 1.5497207641601562e-05 seconds
DEBUG 01-13 08:46:41.691279.691279 cuda_h.py:10] start wait_experts
INFO 01-13 08:46:41.691975.691975 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 9e721007-e4fc-4d54-838f-a49cb4d611db
DEBUG 01-13 08:46:41.692620.692620 mlpmodule.py:1006] group tensors cost 0.004934072494506836 s
DEBUG 01-13 08:46:41.694181.694181 mlpmodule.py:1044] pad cost 0.0015075206756591797 s
DEBUG 01-13 08:46:41.694707.694707 mlpmodule.py:1050] create cpu tensor cost 5.5789947509765625e-05 s
DEBUG 01-13 08:46:41.694650.694650 mlpmodule.py:1055] move to cpu cost 3.0994415283203125e-05 s
DEBUG 01-13 08:46:41.702430.702430 mlpmodule.py:1069] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-13 08:46:41.703279.703279 mlpmodule.py:1070] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-13 08:46:41.703641.703641 mlpmodule.py:1075] group_w3 first element: 0.000789642333984375
WARNING 01-13 08:46:41.703825.703825 mlpmodule.py:1085] start einsum2
DEBUG 01-13 08:46:41.716279.716279 mlpmodule.py:1095] group einsum cost 0.0216522216796875 s
DEBUG 01-13 08:46:41.717340.717340 mlpmodule.py:1103] cpy2cputensor cost 0.0007882118225097656 s
INFO 01-13 08:46:41.739388.739388 client.py:127] Model loaded
DEBUG 01-13 08:46:41.739753.739753 cuda_h.py:19] end wait_experts cost 0.0477299690246582 seconds
DEBUG 01-13 08:46:41.739630.739630 cuda_h.py:10] start gpu_experts
DEBUG 01-13 08:46:41.740793.740793 mlpmodule.py:559] gpu group tensors cost 0.0006213188171386719 s
DEBUG 01-13 08:46:41.741034.741034 mlpmodule.py:785]  experts func einsum cost 0.05409097671508789 s
DEBUG 01-13 08:46:41.741757.741757 cuda_h.py:19] end experts_func_gpu_einsum_mp cost 0.05471086502075195 seconds
DEBUG 01-13 08:46:41.742354.742354 mlpmodule.py:592] gpu pad cost 0.0014710426330566406 s
DEBUG 01-13 08:46:41.742324.742324 mlpmodule.py:598] start_w1
DEBUG 01-13 08:46:41.742071.742071 mlpmodule.py:602] start_w3
DEBUG 01-13 08:46:41.742885.742885 mlpmodule.py:608] start_w2
DEBUG 01-13 08:46:41.742261.742261 mlpmodule.py:611] gpu group einsum cost 0.0006890296936035156 s
DEBUG 01-13 08:46:41.745135.745135 mlpmodule.py:683] gpu experts func einsum cost 0.005299568176269531 s
DEBUG 01-13 08:46:41.745304.745304 cuda_h.py:19] end gpu_experts cost 0.005455732345581055 seconds
DEBUG 01-13 08:46:41.745060.745060 cuda_h.py:10] start cpu_thread_manager_mp_wait
DEBUG 01-13 08:46:41.745870.745870 cuda_h.py:19] end cpu_thread_manager_mp_wait cost 3.838539123535156e-05 seconds
DEBUG 01-13 08:46:41.745224.745224 cuda_h.py:19] end layer_moe_generate_mp_l_15 cost 0.06395244598388672 seconds
DEBUG 01-13 08:46:41.745941.745941 lmp.py:1550] -------------------------------- end prefill layer 14 --------------------------------
DEBUG 01-13 08:46:41.745611.745611 lmp.py:1493] -------------------------------- start prefill layer 15 --------------------------------
DEBUG 01-13 08:46:41.745598.745598 cuda_h.py:10] start start_load_qkvogn_s_weight_l_16
DEBUG 01-13 08:46:41.745354.745354 cuda_h.py:10] start start_load_qkvogn_s_weight_l_16
DEBUG 01-13 08:46:41.745290.745290 cuda_h.py:19] end start_load_qkvogn_s_weight_l_16 cost 3.170967102050781e-05 seconds
DEBUG 01-13 08:46:41.745947.745947 cuda_h.py:19] end start_load_qkvogn_s_weight_l_16 cost 6.270408630371094e-05 seconds
DEBUG 01-13 08:46:41.745212.745212 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-13 08:46:41.745499.745499 cuda_h.py:10] start sllm_worker_task
DEBUG 01-13 08:46:41.746259.746259 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-13 08:46:41.746797.746797 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-13 08:46:41.746404.746404 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-13 08:46:41.746357.746357 cuda_h.py:19] end allocate_cuda_memory cost 0.0003402233123779297 seconds
DEBUG 01-13 08:46:41.746149.746149 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-13 08:46:41.746369.746369 sllm_store_c.py:27] get device uuid map
DEBUG 01-13 08:46:41.746921.746921 sllm_store_c.py:29] call client load into gpu
DEBUG 01-13 08:46:41.746392.746392 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 54d8a0c3-6395-4f2d-b55b-e853e44b09ce
DEBUG 01-13 08:46:41.746574.746574 client.py:106] call stub.LoadModelAsync
DEBUG 01-13 08:46:41.747159.747159 cuda_h.py:10] start self_attn
INFO 01-13 08:46:41.748392.748392 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 54d8a0c3-6395-4f2d-b55b-e853e44b09ce
DEBUG 01-13 08:46:41.748195.748195 cuda_h.py:19] end load_into_gpu_async cost 0.0017325878143310547 seconds
DEBUG 01-13 08:46:41.748905.748905 cuda_h.py:10] start restore_tensors2
DEBUG 01-13 08:46:41.748823.748823 cuda_h.py:19] end restore_tensors2 cost 8.20159912109375e-05 seconds
DEBUG 01-13 08:46:41.748222.748222 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.002488374710083008 seconds
INFO 01-13 08:46:41.748131.748131 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 54d8a0c3-6395-4f2d-b55b-e853e44b09ce
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-13 08:46:41.750916.750916 cuda_h.py:19] end self_attn cost 0.002986907958984375 seconds
DEBUG 01-13 08:46:41.750556.750556 cuda_h.py:19] end iln_self_attn_paln cost 0.004681825637817383 seconds
DEBUG 01-13 08:46:41.750114.750114 cuda_h.py:10] start layer_moe_generate_mp_l_16
DEBUG 01-13 08:46:41.750400.750400 cuda_h.py:10] start gate
DEBUG 01-13 08:46:41.751701.751701 cuda_h.py:19] end gate cost 0.0006430149078369141 seconds
DEBUG 01-13 08:46:41.751292.751292 cuda_h.py:10] start experts_map_get
DEBUG 01-13 08:46:41.751481.751481 lmp.py:1611] 
DEBUG 01-13 08:46:41.751481.751481 lmp.py:1611] Expert Token Distribution & Device Allocation:
DEBUG 01-13 08:46:41.751429.751429 lmp.py:1612]   Total experts: 64
DEBUG 01-13 08:46:41.751748.751748 lmp.py:1613]   CPU experts: 32 (50%)
DEBUG 01-13 08:46:41.751490.751490 lmp.py:1614]   GPU experts: 32 (50%)
DEBUG 01-13 08:46:41.751041.751041 lmp.py:1615] 
DEBUG 01-13 08:46:41.751041.751041 lmp.py:1615]   Expert ID | Tokens | Device
DEBUG 01-13 08:46:41.751306.751306 lmp.py:1616]   -----------------------------------
DEBUG 01-13 08:46:41.751863.751863 lmp.py:1622]   Expert 15 |     60 | CPU
DEBUG 01-13 08:46:41.751937.751937 lmp.py:1622]   Expert  0 |     72 | CPU
DEBUG 01-13 08:46:41.751057.751057 lmp.py:1622]   Expert 41 |     73 | CPU
DEBUG 01-13 08:46:41.751938.751938 lmp.py:1622]   Expert 63 |     73 | CPU
DEBUG 01-13 08:46:41.751343.751343 lmp.py:1622]   Expert 20 |     85 | CPU
DEBUG 01-13 08:46:41.751509.751509 lmp.py:1622]   Expert 28 |     95 | CPU
DEBUG 01-13 08:46:41.751913.751913 lmp.py:1622]   Expert 45 |     95 | CPU
DEBUG 01-13 08:46:41.751841.751841 lmp.py:1622]   Expert 54 |     98 | CPU
DEBUG 01-13 08:46:41.752007.752007 lmp.py:1622]   Expert  7 |    101 | CPU
DEBUG 01-13 08:46:41.752127.752127 lmp.py:1622]   Expert 12 |    110 | CPU
DEBUG 01-13 08:46:41.752485.752485 lmp.py:1622]   Expert  5 |    115 | CPU
DEBUG 01-13 08:46:41.752128.752128 lmp.py:1622]   Expert 52 |    116 | CPU
DEBUG 01-13 08:46:41.752010.752010 lmp.py:1622]   Expert 40 |    123 | CPU
DEBUG 01-13 08:46:41.752414.752414 lmp.py:1622]   Expert  4 |    124 | CPU
DEBUG 01-13 08:46:41.752580.752580 lmp.py:1622]   Expert 34 |    126 | CPU
DEBUG 01-13 08:46:41.752177.752177 lmp.py:1622]   Expert 59 |    128 | CPU
DEBUG 01-13 08:46:41.752535.752535 lmp.py:1622]   Expert 55 |    134 | CPU
DEBUG 01-13 08:46:41.752416.752416 lmp.py:1622]   Expert 13 |    135 | CPU
DEBUG 01-13 08:46:41.752298.752298 lmp.py:1622]   Expert 62 |    135 | CPU
DEBUG 01-13 08:46:41.752179.752179 lmp.py:1622]   Expert 61 |    136 | CPU
DEBUG 01-13 08:46:41.752537.752537 lmp.py:1622]   Expert 21 |    141 | CPU
DEBUG 01-13 08:46:41.752180.752180 lmp.py:1622]   Expert 42 |    141 | CPU
DEBUG 01-13 08:46:41.752300.752300 lmp.py:1622]   Expert 10 |    142 | CPU
DEBUG 01-13 08:46:41.752897.752897 lmp.py:1622]   Expert 14 |    147 | CPU
DEBUG 01-13 08:46:41.752970.752970 lmp.py:1622]   Expert 22 |    147 | CPU
DEBUG 01-13 08:46:41.752044.752044 lmp.py:1622]   Expert 32 |    155 | CPU
DEBUG 01-13 08:46:41.752356.752356 lmp.py:1622]   Expert 51 |    156 | CPU
DEBUG 01-13 08:46:41.752237.752237 lmp.py:1622]   Expert 25 |    166 | CPU
DEBUG 01-13 08:46:41.752357.752357 lmp.py:1622]   Expert 50 |    169 | CPU
DEBUG 01-13 08:46:41.752729.752729 lmp.py:1622]   Expert 53 |    171 | CPU
DEBUG 01-13 08:46:41.752325.752325 lmp.py:1622]   Expert 26 |    173 | CPU
DEBUG 01-13 08:46:41.752445.752445 lmp.py:1622]   Expert 47 |    173 | CPU
DEBUG 01-13 08:46:41.752565.752565 lmp.py:1622]   Expert 19 |    179 | GPU
DEBUG 01-13 08:46:41.752923.752923 lmp.py:1622]   Expert 30 |    179 | GPU
DEBUG 01-13 08:46:41.752805.752805 lmp.py:1622]   Expert 35 |    180 | GPU
DEBUG 01-13 08:46:41.752401.752401 lmp.py:1622]   Expert  1 |    184 | GPU
DEBUG 01-13 08:46:41.752998.752998 lmp.py:1622]   Expert 11 |    184 | GPU
DEBUG 01-13 08:46:41.752072.752072 lmp.py:1622]   Expert  6 |    187 | GPU
DEBUG 01-13 08:46:41.752668.752668 lmp.py:1622]   Expert  2 |    188 | GPU
DEBUG 01-13 08:46:41.752503.752503 lmp.py:1622]   Expert 57 |    189 | GPU
DEBUG 01-13 08:46:41.752861.752861 lmp.py:1622]   Expert 56 |    193 | GPU
DEBUG 01-13 08:46:41.752981.752981 lmp.py:1622]   Expert 48 |    203 | GPU
DEBUG 01-13 08:46:41.752101.752101 lmp.py:1622]   Expert 24 |    205 | GPU
DEBUG 01-13 08:46:41.752459.752459 lmp.py:1622]   Expert 44 |    211 | GPU
DEBUG 01-13 08:46:41.752341.752341 lmp.py:1622]   Expert 46 |    213 | GPU
DEBUG 01-13 08:46:41.752222.752222 lmp.py:1622]   Expert 16 |    222 | GPU
DEBUG 01-13 08:46:41.752342.752342 lmp.py:1622]   Expert 39 |    222 | GPU
DEBUG 01-13 08:46:41.752985.752985 lmp.py:1622]   Expert 18 |    229 | GPU
DEBUG 01-13 08:46:41.752866.752866 lmp.py:1622]   Expert 29 |    233 | GPU
DEBUG 01-13 08:46:41.752417.752417 lmp.py:1622]   Expert 37 |    241 | GPU
DEBUG 01-13 08:46:41.752013.752013 lmp.py:1622]   Expert  3 |    254 | GPU
DEBUG 01-13 08:46:41.752848.752848 lmp.py:1622]   Expert 31 |    258 | GPU
DEBUG 01-13 08:46:41.752445.752445 lmp.py:1622]   Expert 38 |    259 | GPU
DEBUG 01-13 08:46:41.752565.752565 lmp.py:1622]   Expert 36 |    260 | GPU
DEBUG 01-13 08:46:41.752161.752161 lmp.py:1622]   Expert 60 |    261 | GPU
DEBUG 01-13 08:46:41.752520.752520 lmp.py:1622]   Expert  9 |    265 | GPU
DEBUG 01-13 08:46:41.752401.752401 lmp.py:1622]   Expert 17 |    265 | GPU
DEBUG 01-13 08:46:41.752521.752521 lmp.py:1622]   Expert 23 |    272 | GPU
DEBUG 01-13 08:46:41.752879.752879 lmp.py:1622]   Expert 27 |    353 | GPU
DEBUG 01-13 08:46:41.752999.752999 lmp.py:1622]   Expert 43 |    361 | GPU
DEBUG 01-13 08:46:41.752880.752880 lmp.py:1622]   Expert 33 |    395 | GPU
DEBUG 01-13 08:46:41.752000.752000 lmp.py:1622]   Expert  8 |    435 | GPU
DEBUG 01-13 08:46:41.753597.753597 lmp.py:1622]   Expert 58 |    437 | GPU
DEBUG 01-13 08:46:41.753478.753478 lmp.py:1622]   Expert 49 |    556 | GPU
DEBUG 01-13 08:46:41.753313.753313 lmp.py:1623] 
DEBUG 01-13 08:46:41.753313.753313 lmp.py:1623]   CPU total tokens: 4015 (32.7%)
DEBUG 01-13 08:46:41.753817.753817 lmp.py:1624]   GPU total tokens: 8273 (67.3%)
DEBUG 01-13 08:46:41.753374.753374 cuda_h.py:19] end experts_map_get cost 0.0016469955444335938 seconds
DEBUG 01-13 08:46:41.753655.753655 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-13 08:46:41.753332.753332 lmp.py:1632] 
DEBUG 01-13 08:46:41.753332.753332 lmp.py:1632]   Computing 32 experts on CPU MP...
DEBUG 01-13 08:46:41.753353.753353 cuda_h.py:19] end cpu_experts_submit cost 6.151199340820312e-05 seconds
DEBUG 01-13 08:46:41.753572.753572 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-13 08:46:41.753263.753263 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-13 08:46:41.753215.753215 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-13 08:46:41.754983.754983 cuda_h.py:19] end allocate_cuda_memory cost 0.0013380050659179688 seconds
DEBUG 01-13 08:46:41.754302.754302 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-13 08:46:41.754820.754820 sllm_store_c.py:27] get device uuid map
DEBUG 01-13 08:46:41.755824.755824 sllm_store_c.py:29] call client load into gpu
DEBUG 01-13 08:46:41.755964.755964 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, f00a763f-4d27-4b18-afaa-5eea5e5daa94
DEBUG 01-13 08:46:41.755990.755990 client.py:106] call stub.LoadModelAsync
DEBUG 01-13 08:46:41.756969.756969 cuda_h.py:10] start experts_func_gpu_einsum_mp
INFO 01-13 08:46:41.756129.756129 client.py:127] Model loaded
DEBUG 01-13 08:46:41.756515.756515 cuda_h.py:10] start restore2model
DEBUG 01-13 08:46:41.757780.757780 cuda_h.py:19] end restore2model cost 0.0005307197570800781 seconds
DEBUG 01-13 08:46:41.757961.757961 cuda_h.py:19] end sllm_worker_task cost 0.011226654052734375 seconds
INFO 01-13 08:46:41.758405.758405 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, f00a763f-4d27-4b18-afaa-5eea5e5daa94
DEBUG 01-13 08:46:41.758964.758964 cuda_h.py:19] end load_into_gpu_async cost 0.0032978057861328125 seconds
DEBUG 01-13 08:46:41.758667.758667 cuda_h.py:10] start restore_tensors2
DEBUG 01-13 08:46:41.758335.758335 cuda_h.py:19] end restore_tensors2 cost 0.0003612041473388672 seconds
DEBUG 01-13 08:46:41.758549.758549 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0053462982177734375 seconds
DEBUG 01-13 08:46:41.758265.758265 cuda_h.py:10] start restore2model
DEBUG 01-13 08:46:41.761329.761329 cuda_h.py:19] end restore2model cost 0.002650737762451172 seconds
DEBUG 01-13 08:46:41.761926.761926 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.00817418098449707 seconds
DEBUG 01-13 08:46:41.761530.761530 cuda_h.py:10] start gpu_sexperts
DEBUG 01-13 08:46:41.761778.761778 cuda_h.py:19] end gpu_sexperts cost 0.0002586841583251953 seconds
DEBUG 01-13 08:46:41.761462.761462 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-13 08:46:41.761470.761470 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 1.430511474609375e-05 seconds
DEBUG 01-13 08:46:41.761974.761974 cuda_h.py:10] start wait_experts
INFO 01-13 08:46:41.761431.761431 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, f00a763f-4d27-4b18-afaa-5eea5e5daa94
DEBUG 01-13 08:46:41.767685.767685 mlpmodule.py:1006] group tensors cost 0.009959220886230469 s
DEBUG 01-13 08:46:41.771162.771162 mlpmodule.py:1044] pad cost 0.002820253372192383 s
DEBUG 01-13 08:46:41.771426.771426 mlpmodule.py:1050] create cpu tensor cost 6.866455078125e-05 s
DEBUG 01-13 08:46:41.771383.771383 mlpmodule.py:1055] move to cpu cost 4.673004150390625e-05 s
DEBUG 01-13 08:46:41.780899.780899 mlpmodule.py:1069] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-13 08:46:41.781620.781620 mlpmodule.py:1070] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-13 08:46:41.781862.781862 mlpmodule.py:1075] group_w3 first element: -0.0595703125
WARNING 01-13 08:46:41.781344.781344 mlpmodule.py:1085] start einsum2
DEBUG 01-13 08:46:41.795913.795913 mlpmodule.py:1095] group einsum cost 0.023586750030517578 s
DEBUG 01-13 08:46:41.796441.796441 mlpmodule.py:1103] cpy2cputensor cost 0.0007188320159912109 s
INFO 01-13 08:46:41.808331.808331 client.py:127] Model loaded
DEBUG 01-13 08:46:41.808654.808654 cuda_h.py:19] end wait_experts cost 0.0469813346862793 seconds
DEBUG 01-13 08:46:41.808132.808132 cuda_h.py:10] start gpu_experts
DEBUG 01-13 08:46:41.809624.809624 mlpmodule.py:559] gpu group tensors cost 0.0007441043853759766 s
DEBUG 01-13 08:46:41.811193.811193 mlpmodule.py:592] gpu pad cost 0.0016732215881347656 s
DEBUG 01-13 08:46:41.811097.811097 mlpmodule.py:598] start_w1
DEBUG 01-13 08:46:41.812264.812264 mlpmodule.py:602] start_w3
DEBUG 01-13 08:46:41.812701.812701 mlpmodule.py:608] start_w2
DEBUG 01-13 08:46:41.812045.812045 mlpmodule.py:611] gpu group einsum cost 0.0008022785186767578 s
DEBUG 01-13 08:46:41.814306.814306 mlpmodule.py:683] gpu experts func einsum cost 0.005673885345458984 s
DEBUG 01-13 08:46:41.814740.814740 cuda_h.py:19] end gpu_experts cost 0.005860567092895508 seconds
DEBUG 01-13 08:46:41.814019.814019 cuda_h.py:10] start cpu_thread_manager_mp_wait
DEBUG 01-13 08:46:41.814207.814207 cuda_h.py:19] end cpu_thread_manager_mp_wait cost 3.886222839355469e-05 seconds
DEBUG 01-13 08:46:41.815396.815396 cuda_h.py:19] end layer_moe_generate_mp_l_16 cost 0.06435179710388184 seconds
DEBUG 01-13 08:46:41.815576.815576 lmp.py:1550] -------------------------------- end prefill layer 15 --------------------------------
DEBUG 01-13 08:46:41.815875.815875 lmp.py:1493] -------------------------------- start prefill layer 16 --------------------------------
DEBUG 01-13 08:46:41.815631.815631 cuda_h.py:10] start start_load_qkvogn_s_weight_l_17
DEBUG 01-13 08:46:41.815626.815626 cuda_h.py:10] start start_load_qkvogn_s_weight_l_17
DEBUG 01-13 08:46:41.815177.815177 cuda_h.py:19] end start_load_qkvogn_s_weight_l_17 cost 3.0517578125e-05 seconds
DEBUG 01-13 08:46:41.815019.815019 cuda_h.py:19] end start_load_qkvogn_s_weight_l_17 cost 5.793571472167969e-05 seconds
DEBUG 01-13 08:46:41.815662.815662 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-13 08:46:41.815612.815612 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-13 08:46:41.815905.815905 cuda_h.py:10] start sllm_worker_task
DEBUG 01-13 08:46:41.815690.815690 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-13 08:46:41.815241.815241 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-13 08:46:41.816672.816672 cuda_h.py:19] end allocate_cuda_memory cost 0.0003521442413330078 seconds
DEBUG 01-13 08:46:41.816833.816833 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-13 08:46:41.816358.816358 sllm_store_c.py:27] get device uuid map
DEBUG 01-13 08:46:41.816419.816419 sllm_store_c.py:29] call client load into gpu
DEBUG 01-13 08:46:41.816976.816976 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 80d843a8-9260-4b80-87a8-7865e60faa9b
DEBUG 01-13 08:46:41.816450.816450 client.py:106] call stub.LoadModelAsync
DEBUG 01-13 08:46:41.816803.816803 cuda_h.py:10] start self_attn
INFO 01-13 08:46:41.818084.818084 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 80d843a8-9260-4b80-87a8-7865e60faa9b
DEBUG 01-13 08:46:41.818716.818716 cuda_h.py:19] end load_into_gpu_async cost 0.0017931461334228516 seconds
DEBUG 01-13 08:46:41.818227.818227 cuda_h.py:10] start restore_tensors2
DEBUG 01-13 08:46:41.818263.818263 cuda_h.py:19] end restore_tensors2 cost 7.033348083496094e-05 seconds
DEBUG 01-13 08:46:41.818351.818351 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0024912357330322266 seconds
INFO 01-13 08:46:41.818041.818041 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 80d843a8-9260-4b80-87a8-7865e60faa9b
DEBUG 01-13 08:46:41.819163.819163 mlpmodule.py:785]  experts func einsum cost 0.061859846115112305 s
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-13 08:46:41.819031.819031 cuda_h.py:19] end self_attn cost 0.0028107166290283203 seconds
DEBUG 01-13 08:46:41.819417.819417 cuda_h.py:19] end experts_func_gpu_einsum_mp cost 0.06304526329040527 seconds
DEBUG 01-13 08:46:41.819598.819598 cuda_h.py:19] end iln_self_attn_paln cost 0.004384756088256836 seconds
DEBUG 01-13 08:46:41.819342.819342 cuda_h.py:10] start layer_moe_generate_mp_l_17
DEBUG 01-13 08:46:41.819436.819436 cuda_h.py:10] start gate
DEBUG 01-13 08:46:41.820478.820478 cuda_h.py:19] end gate cost 0.000629425048828125 seconds
DEBUG 01-13 08:46:41.820353.820353 cuda_h.py:10] start experts_map_get
DEBUG 01-13 08:46:41.820794.820794 lmp.py:1611] 
DEBUG 01-13 08:46:41.820794.820794 lmp.py:1611] Expert Token Distribution & Device Allocation:
DEBUG 01-13 08:46:41.821642.821642 lmp.py:1612]   Total experts: 64
DEBUG 01-13 08:46:41.821338.821338 lmp.py:1613]   CPU experts: 32 (50%)
DEBUG 01-13 08:46:41.821697.821697 lmp.py:1614]   GPU experts: 32 (50%)
DEBUG 01-13 08:46:41.821386.821386 lmp.py:1615] 
DEBUG 01-13 08:46:41.821386.821386 lmp.py:1615]   Expert ID | Tokens | Device
DEBUG 01-13 08:46:41.821790.821790 lmp.py:1616]   -----------------------------------
DEBUG 01-13 08:46:41.821202.821202 lmp.py:1622]   Expert 58 |     33 | CPU
DEBUG 01-13 08:46:41.821606.821606 lmp.py:1622]   Expert 47 |     54 | CPU
DEBUG 01-13 08:46:41.821819.821819 lmp.py:1622]   Expert 31 |     61 | CPU
DEBUG 01-13 08:46:41.821793.821793 lmp.py:1622]   Expert 49 |     65 | CPU
DEBUG 01-13 08:46:41.821052.821052 lmp.py:1622]   Expert 38 |     66 | CPU
DEBUG 01-13 08:46:41.821264.821264 lmp.py:1622]   Expert 45 |     66 | CPU
DEBUG 01-13 08:46:41.821523.821523 lmp.py:1622]   Expert  4 |     73 | CPU
DEBUG 01-13 08:46:41.821020.821020 lmp.py:1622]   Expert 43 |     80 | CPU
DEBUG 01-13 08:46:41.821517.821517 lmp.py:1622]   Expert 41 |     83 | CPU
DEBUG 01-13 08:46:41.821253.821253 lmp.py:1622]   Expert 33 |    100 | CPU
DEBUG 01-13 08:46:41.821512.821512 lmp.py:1622]   Expert 50 |    101 | CPU
DEBUG 01-13 08:46:41.821009.821009 lmp.py:1622]   Expert 57 |    105 | CPU
DEBUG 01-13 08:46:41.821506.821506 lmp.py:1622]   Expert  2 |    113 | CPU
DEBUG 01-13 08:46:41.821765.821765 lmp.py:1622]   Expert 11 |    114 | CPU
DEBUG 01-13 08:46:41.821262.821262 lmp.py:1622]   Expert 51 |    116 | CPU
DEBUG 01-13 08:46:41.821759.821759 lmp.py:1622]   Expert 54 |    121 | CPU
DEBUG 01-13 08:46:41.821210.821210 lmp.py:1622]   Expert 14 |    122 | CPU
DEBUG 01-13 08:46:41.821184.821184 lmp.py:1622]   Expert  0 |    124 | CPU
DEBUG 01-13 08:46:41.821158.821158 lmp.py:1622]   Expert 56 |    125 | CPU
DEBUG 01-13 08:46:41.821609.821609 lmp.py:1622]   Expert 34 |    141 | CPU
DEBUG 01-13 08:46:41.821345.821345 lmp.py:1622]   Expert 26 |    148 | CPU
DEBUG 01-13 08:46:41.821604.821604 lmp.py:1622]   Expert 27 |    159 | CPU
DEBUG 01-13 08:46:41.821101.821101 lmp.py:1622]   Expert 25 |    164 | CPU
DEBUG 01-13 08:46:41.821836.821836 lmp.py:1622]   Expert 28 |    168 | CPU
DEBUG 01-13 08:46:41.821095.821095 lmp.py:1622]   Expert 55 |    168 | CPU
DEBUG 01-13 08:46:41.821831.821831 lmp.py:1622]   Expert 10 |    169 | CPU
DEBUG 01-13 08:46:41.821090.821090 lmp.py:1622]   Expert  9 |    179 | CPU
DEBUG 01-13 08:46:41.821825.821825 lmp.py:1622]   Expert 13 |    180 | CPU
DEBUG 01-13 08:46:41.821084.821084 lmp.py:1622]   Expert 46 |    189 | CPU
DEBUG 01-13 08:46:41.821820.821820 lmp.py:1622]   Expert 61 |    191 | CPU
DEBUG 01-13 08:46:41.821078.821078 lmp.py:1622]   Expert  6 |    192 | CPU
DEBUG 01-13 08:46:41.821721.821721 lmp.py:1622]   Expert  7 |    193 | CPU
DEBUG 01-13 08:46:41.821411.821411 lmp.py:1622]   Expert 24 |    195 | GPU
DEBUG 01-13 08:46:41.821054.821054 lmp.py:1622]   Expert 48 |    197 | GPU
DEBUG 01-13 08:46:41.821697.821697 lmp.py:1622]   Expert 18 |    203 | GPU
DEBUG 01-13 08:46:41.821863.821863 lmp.py:1622]   Expert 42 |    206 | GPU
DEBUG 01-13 08:46:41.821267.821267 lmp.py:1622]   Expert 22 |    211 | GPU
DEBUG 01-13 08:46:41.821957.821957 lmp.py:1622]   Expert 40 |    211 | GPU
DEBUG 01-13 08:46:41.821408.821408 lmp.py:1622]   Expert 21 |    214 | GPU
DEBUG 01-13 08:46:41.821620.821620 lmp.py:1622]   Expert 29 |    215 | GPU
DEBUG 01-13 08:46:41.821071.821071 lmp.py:1622]   Expert 12 |    216 | GPU
DEBUG 01-13 08:46:41.821522.821522 lmp.py:1622]   Expert 59 |    216 | GPU
DEBUG 01-13 08:46:41.821734.821734 lmp.py:1622]   Expert 63 |    219 | GPU
DEBUG 01-13 08:46:41.821947.821947 lmp.py:1622]   Expert 32 |    221 | GPU
DEBUG 01-13 08:46:41.821398.821398 lmp.py:1622]   Expert 19 |    225 | GPU
DEBUG 01-13 08:46:41.821041.821041 lmp.py:1622]   Expert 36 |    237 | GPU
DEBUG 01-13 08:46:41.821684.821684 lmp.py:1622]   Expert  3 |    242 | GPU
DEBUG 01-13 08:46:41.821850.821850 lmp.py:1622]   Expert 37 |    249 | GPU
DEBUG 01-13 08:46:41.821777.821777 lmp.py:1622]   Expert  1 |    251 | GPU
DEBUG 01-13 08:46:41.821944.821944 lmp.py:1622]   Expert 16 |    254 | GPU
DEBUG 01-13 08:46:41.821394.821394 lmp.py:1622]   Expert  8 |    263 | GPU
DEBUG 01-13 08:46:41.821607.821607 lmp.py:1622]   Expert 20 |    264 | GPU
DEBUG 01-13 08:46:41.821058.821058 lmp.py:1622]   Expert 30 |    269 | GPU
DEBUG 01-13 08:46:41.821509.821509 lmp.py:1622]   Expert  5 |    270 | GPU
DEBUG 01-13 08:46:41.821721.821721 lmp.py:1622]   Expert 15 |    271 | GPU
DEBUG 01-13 08:46:41.822934.822934 lmp.py:1622]   Expert 62 |    278 | GPU
DEBUG 01-13 08:46:41.822623.822623 lmp.py:1622]   Expert 35 |    289 | GPU
DEBUG 01-13 08:46:41.822835.822835 lmp.py:1622]   Expert 39 |    295 | GPU
DEBUG 01-13 08:46:41.822240.822240 lmp.py:1622]   Expert 17 |    297 | GPU
DEBUG 01-13 08:46:41.822168.822168 lmp.py:1622]   Expert 60 |    307 | GPU
DEBUG 01-13 08:46:41.822572.822572 lmp.py:1622]   Expert 52 |    353 | GPU
DEBUG 01-13 08:46:41.822977.822977 lmp.py:1622]   Expert 23 |    374 | GPU
DEBUG 01-13 08:46:41.822666.822666 lmp.py:1622]   Expert 44 |    376 | GPU
DEBUG 01-13 08:46:41.822117.822117 lmp.py:1622]   Expert 53 |    437 | GPU
DEBUG 01-13 08:46:41.822521.822521 lmp.py:1623] 
DEBUG 01-13 08:46:41.822521.822521 lmp.py:1623]   CPU total tokens: 3963 (32.3%)
DEBUG 01-13 08:46:41.822926.822926 lmp.py:1624]   GPU total tokens: 8325 (67.7%)
DEBUG 01-13 08:46:41.822622.822622 cuda_h.py:19] end experts_map_get cost 0.0014698505401611328 seconds
DEBUG 01-13 08:46:41.822849.822849 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-13 08:46:41.822413.822413 lmp.py:1632] 
DEBUG 01-13 08:46:41.822413.822413 lmp.py:1632]   Computing 32 experts on CPU MP...
DEBUG 01-13 08:46:41.822004.822004 cuda_h.py:19] end cpu_experts_submit cost 4.863739013671875e-05 seconds
DEBUG 01-13 08:46:41.822224.822224 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-13 08:46:41.822484.822484 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-13 08:46:41.822905.822905 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-13 08:46:41.823743.823743 cuda_h.py:19] end allocate_cuda_memory cost 0.0008652210235595703 seconds
DEBUG 01-13 08:46:41.823875.823875 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-13 08:46:41.823804.823804 sllm_store_c.py:27] get device uuid map
DEBUG 01-13 08:46:41.823805.823805 sllm_store_c.py:29] call client load into gpu
DEBUG 01-13 08:46:41.823362.823362 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 39e0c9fb-807a-4d70-ab03-59a88fdb44c0
DEBUG 01-13 08:46:41.824872.824872 client.py:106] call stub.LoadModelAsync
DEBUG 01-13 08:46:41.825960.825960 cuda_h.py:10] start experts_func_gpu_einsum_mp
INFO 01-13 08:46:41.826964.826964 client.py:127] Model loaded
DEBUG 01-13 08:46:41.826191.826191 cuda_h.py:10] start restore2model
DEBUG 01-13 08:46:41.826762.826762 cuda_h.py:19] end restore2model cost 0.0004048347473144531 seconds
DEBUG 01-13 08:46:41.826684.826684 cuda_h.py:19] end sllm_worker_task cost 0.01092386245727539 seconds
INFO 01-13 08:46:41.827522.827522 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 39e0c9fb-807a-4d70-ab03-59a88fdb44c0
DEBUG 01-13 08:46:41.827935.827935 cuda_h.py:19] end load_into_gpu_async cost 0.00409698486328125 seconds
DEBUG 01-13 08:46:41.828466.828466 cuda_h.py:10] start restore_tensors2
DEBUG 01-13 08:46:41.828731.828731 cuda_h.py:19] end restore_tensors2 cost 0.0003809928894042969 seconds
DEBUG 01-13 08:46:41.828998.828998 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0060443878173828125 seconds
DEBUG 01-13 08:46:41.828860.828860 cuda_h.py:10] start restore2model
DEBUG 01-13 08:46:41.831461.831461 cuda_h.py:19] end restore2model cost 0.002485990524291992 seconds
DEBUG 01-13 08:46:41.831767.831767 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.008701324462890625 seconds
DEBUG 01-13 08:46:41.831437.831437 cuda_h.py:10] start gpu_sexperts
DEBUG 01-13 08:46:41.831222.831222 cuda_h.py:19] end gpu_sexperts cost 0.0002694129943847656 seconds
DEBUG 01-13 08:46:41.831191.831191 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-13 08:46:41.831483.831483 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 1.4066696166992188e-05 seconds
DEBUG 01-13 08:46:41.831795.831795 cuda_h.py:10] start wait_experts
INFO 01-13 08:46:41.831922.831922 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 39e0c9fb-807a-4d70-ab03-59a88fdb44c0
DEBUG 01-13 08:46:41.836612.836612 mlpmodule.py:1006] group tensors cost 0.009829998016357422 s
DEBUG 01-13 08:46:41.839499.839499 mlpmodule.py:1044] pad cost 0.002106904983520508 s
DEBUG 01-13 08:46:41.839570.839570 mlpmodule.py:1050] create cpu tensor cost 6.079673767089844e-05 s
DEBUG 01-13 08:46:41.839255.839255 mlpmodule.py:1055] move to cpu cost 4.863739013671875e-05 s
DEBUG 01-13 08:46:41.849510.849510 mlpmodule.py:1069] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-13 08:46:41.849134.849134 mlpmodule.py:1070] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-13 08:46:41.849271.849271 mlpmodule.py:1075] group_w3 first element: -0.02490234375
WARNING 01-13 08:46:41.849708.849708 mlpmodule.py:1085] start einsum2
DEBUG 01-13 08:46:41.863000.863000 mlpmodule.py:1095] group einsum cost 0.02394890785217285 s
DEBUG 01-13 08:46:41.864511.864511 mlpmodule.py:1103] cpy2cputensor cost 0.0007691383361816406 s
INFO 01-13 08:46:41.878143.878143 client.py:127] Model loaded
DEBUG 01-13 08:46:41.879486.879486 cuda_h.py:19] end wait_experts cost 0.047484636306762695 seconds
DEBUG 01-13 08:46:41.879388.879388 cuda_h.py:10] start gpu_experts
DEBUG 01-13 08:46:41.879372.879372 mlpmodule.py:559] gpu group tensors cost 0.0006253719329833984 s
DEBUG 01-13 08:46:41.881103.881103 mlpmodule.py:592] gpu pad cost 0.0015897750854492188 s
DEBUG 01-13 08:46:41.881768.881768 mlpmodule.py:598] start_w1
DEBUG 01-13 08:46:41.881324.881324 mlpmodule.py:602] start_w3
DEBUG 01-13 08:46:41.882913.882913 mlpmodule.py:608] start_w2
DEBUG 01-13 08:46:41.882322.882322 mlpmodule.py:611] gpu group einsum cost 0.0007233619689941406 s
DEBUG 01-13 08:46:41.884354.884354 mlpmodule.py:683] gpu experts func einsum cost 0.005205631256103516 s
DEBUG 01-13 08:46:41.884284.884284 cuda_h.py:19] end gpu_experts cost 0.00537419319152832 seconds
DEBUG 01-13 08:46:41.884186.884186 cuda_h.py:10] start cpu_thread_manager_mp_wait
DEBUG 01-13 08:46:41.884420.884420 cuda_h.py:19] end cpu_thread_manager_mp_wait cost 3.7670135498046875e-05 seconds
DEBUG 01-13 08:46:41.884144.884144 cuda_h.py:19] end layer_moe_generate_mp_l_17 cost 0.06467604637145996 seconds
DEBUG 01-13 08:46:41.884755.884755 lmp.py:1550] -------------------------------- end prefill layer 16 --------------------------------
DEBUG 01-13 08:46:41.884670.884670 lmp.py:1493] -------------------------------- start prefill layer 17 --------------------------------
DEBUG 01-13 08:46:41.884274.884274 cuda_h.py:10] start start_load_qkvogn_s_weight_l_18
DEBUG 01-13 08:46:41.884976.884976 cuda_h.py:10] start start_load_qkvogn_s_weight_l_18
DEBUG 01-13 08:46:41.885667.885667 cuda_h.py:19] end start_load_qkvogn_s_weight_l_18 cost 3.0040740966796875e-05 seconds
DEBUG 01-13 08:46:41.885198.885198 cuda_h.py:19] end start_load_qkvogn_s_weight_l_18 cost 7.319450378417969e-05 seconds
DEBUG 01-13 08:46:41.885795.885795 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-13 08:46:41.885346.885346 cuda_h.py:10] start sllm_worker_task
DEBUG 01-13 08:46:41.885761.885761 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-13 08:46:41.885246.885246 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-13 08:46:41.885641.885641 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-13 08:46:41.885037.885037 cuda_h.py:19] end allocate_cuda_memory cost 0.00032401084899902344 seconds
DEBUG 01-13 08:46:41.885477.885477 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-13 08:46:41.885524.885524 sllm_store_c.py:27] get device uuid map
DEBUG 01-13 08:46:41.885585.885585 sllm_store_c.py:29] call client load into gpu
DEBUG 01-13 08:46:41.885858.885858 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 26eeba7a-725e-42b1-852d-ccb82d362147
DEBUG 01-13 08:46:41.886496.886496 client.py:106] call stub.LoadModelAsync
DEBUG 01-13 08:46:41.886134.886134 cuda_h.py:10] start self_attn
INFO 01-13 08:46:41.887556.887556 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 26eeba7a-725e-42b1-852d-ccb82d362147
DEBUG 01-13 08:46:41.887426.887426 cuda_h.py:19] end load_into_gpu_async cost 0.00180816650390625 seconds
DEBUG 01-13 08:46:41.887937.887937 cuda_h.py:10] start restore_tensors2
DEBUG 01-13 08:46:41.887397.887397 cuda_h.py:19] end restore_tensors2 cost 6.747245788574219e-05 seconds
DEBUG 01-13 08:46:41.887723.887723 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0024700164794921875 seconds
INFO 01-13 08:46:41.887969.887969 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 26eeba7a-725e-42b1-852d-ccb82d362147
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-13 08:46:41.889807.889807 cuda_h.py:19] end self_attn cost 0.0028235912322998047 seconds
DEBUG 01-13 08:46:41.889141.889141 cuda_h.py:19] end iln_self_attn_paln cost 0.004369497299194336 seconds
DEBUG 01-13 08:46:41.889646.889646 cuda_h.py:10] start layer_moe_generate_mp_l_18
DEBUG 01-13 08:46:41.889786.889786 cuda_h.py:10] start gate
DEBUG 01-13 08:46:41.890185.890185 cuda_h.py:19] end gate cost 0.0006132125854492188 seconds
DEBUG 01-13 08:46:41.890346.890346 cuda_h.py:10] start experts_map_get
DEBUG 01-13 08:46:41.890885.890885 lmp.py:1611] 
DEBUG 01-13 08:46:41.890885.890885 lmp.py:1611] Expert Token Distribution & Device Allocation:
DEBUG 01-13 08:46:41.890449.890449 lmp.py:1612]   Total experts: 64
DEBUG 01-13 08:46:41.890622.890622 lmp.py:1613]   CPU experts: 32 (50%)
DEBUG 01-13 08:46:41.890219.890219 lmp.py:1614]   GPU experts: 32 (50%)
DEBUG 01-13 08:46:41.890623.890623 lmp.py:1615] 
DEBUG 01-13 08:46:41.890623.890623 lmp.py:1615]   Expert ID | Tokens | Device
DEBUG 01-13 08:46:41.890028.890028 lmp.py:1616]   -----------------------------------
DEBUG 01-13 08:46:41.890108.890108 lmp.py:1622]   Expert  4 |     11 | CPU
DEBUG 01-13 08:46:41.890036.890036 lmp.py:1622]   Expert 28 |     26 | CPU
DEBUG 01-13 08:46:41.890248.890248 lmp.py:1622]   Expert  7 |     43 | CPU
DEBUG 01-13 08:46:41.890984.890984 lmp.py:1622]   Expert 53 |     55 | CPU
DEBUG 01-13 08:46:41.890720.890720 lmp.py:1622]   Expert 52 |     65 | CPU
DEBUG 01-13 08:46:41.890217.890217 lmp.py:1622]   Expert 43 |     79 | CPU
DEBUG 01-13 08:46:41.890952.890952 lmp.py:1622]   Expert 49 |     92 | CPU
DEBUG 01-13 08:46:41.890211.890211 lmp.py:1622]   Expert 12 |     93 | CPU
DEBUG 01-13 08:46:41.890947.890947 lmp.py:1622]   Expert 24 |    102 | CPU
DEBUG 01-13 08:46:41.890398.890398 lmp.py:1622]   Expert 33 |    102 | CPU
DEBUG 01-13 08:46:41.890610.890610 lmp.py:1622]   Expert 47 |    102 | CPU
DEBUG 01-13 08:46:41.890299.890299 lmp.py:1622]   Expert  2 |    106 | CPU
DEBUG 01-13 08:46:41.890989.890989 lmp.py:1622]   Expert 50 |    109 | CPU
DEBUG 01-13 08:46:41.890248.890248 lmp.py:1622]   Expert 15 |    110 | CPU
DEBUG 01-13 08:46:41.890983.890983 lmp.py:1622]   Expert 39 |    111 | CPU
DEBUG 01-13 08:46:41.890004.890004 lmp.py:1622]   Expert 36 |    118 | CPU
DEBUG 01-13 08:46:41.890501.890501 lmp.py:1622]   Expert 60 |    118 | CPU
DEBUG 01-13 08:46:41.890998.890998 lmp.py:1622]   Expert 61 |    124 | CPU
DEBUG 01-13 08:46:41.890257.890257 lmp.py:1622]   Expert  6 |    128 | CPU
DEBUG 01-13 08:46:41.891516.891516 lmp.py:1622]   Expert 25 |    128 | CPU
DEBUG 01-13 08:46:41.891774.891774 lmp.py:1622]   Expert 59 |    139 | CPU
DEBUG 01-13 08:46:41.891795.891795 lmp.py:1622]   Expert  3 |    145 | CPU
DEBUG 01-13 08:46:41.891292.891292 lmp.py:1622]   Expert 58 |    147 | CPU
DEBUG 01-13 08:46:41.891743.891743 lmp.py:1622]   Expert 27 |    148 | CPU
DEBUG 01-13 08:46:41.891478.891478 lmp.py:1622]   Expert 31 |    154 | CPU
DEBUG 01-13 08:46:41.891929.891929 lmp.py:1622]   Expert  8 |    155 | CPU
DEBUG 01-13 08:46:41.891619.891619 lmp.py:1622]   Expert 10 |    156 | CPU
DEBUG 01-13 08:46:41.891639.891639 lmp.py:1622]   Expert 30 |    158 | CPU
DEBUG 01-13 08:46:41.891898.891898 lmp.py:1622]   Expert 57 |    159 | CPU
DEBUG 01-13 08:46:41.891157.891157 lmp.py:1622]   Expert 14 |    160 | CPU
DEBUG 01-13 08:46:41.891177.891177 lmp.py:1622]   Expert 37 |    160 | CPU
DEBUG 01-13 08:46:41.891436.891436 lmp.py:1622]   Expert 40 |    161 | CPU
DEBUG 01-13 08:46:41.891695.891695 lmp.py:1622]   Expert 41 |    162 | GPU
DEBUG 01-13 08:46:41.891715.891715 lmp.py:1622]   Expert 32 |    163 | GPU
DEBUG 01-13 08:46:41.891735.891735 lmp.py:1622]   Expert 38 |    163 | GPU
DEBUG 01-13 08:46:41.891948.891948 lmp.py:1622]   Expert 46 |    163 | GPU
DEBUG 01-13 08:46:41.891352.891352 lmp.py:1622]   Expert 11 |    167 | GPU
DEBUG 01-13 08:46:41.891518.891518 lmp.py:1622]   Expert 54 |    168 | GPU
DEBUG 01-13 08:46:41.891446.891446 lmp.py:1622]   Expert 19 |    172 | GPU
DEBUG 01-13 08:46:41.891612.891612 lmp.py:1622]   Expert 42 |    176 | GPU
DEBUG 01-13 08:46:41.891778.891778 lmp.py:1622]   Expert 34 |    188 | GPU
DEBUG 01-13 08:46:41.891229.891229 lmp.py:1622]   Expert 22 |    194 | GPU
DEBUG 01-13 08:46:41.891203.891203 lmp.py:1622]   Expert 26 |    198 | GPU
DEBUG 01-13 08:46:41.891654.891654 lmp.py:1622]   Expert  0 |    199 | GPU
DEBUG 01-13 08:46:41.891628.891628 lmp.py:1622]   Expert  1 |    201 | GPU
DEBUG 01-13 08:46:41.891602.891602 lmp.py:1622]   Expert 18 |    202 | GPU
DEBUG 01-13 08:46:41.891815.891815 lmp.py:1622]   Expert 44 |    206 | GPU
DEBUG 01-13 08:46:41.891789.891789 lmp.py:1622]   Expert 51 |    208 | GPU
DEBUG 01-13 08:46:41.891920.891920 mlpmodule.py:785]  experts func einsum cost 0.0649409294128418 s
DEBUG 01-13 08:46:41.891524.891524 lmp.py:1622]   Expert 56 |    209 | GPU
DEBUG 01-13 08:46:41.891267.891267 lmp.py:1622]   Expert 29 |    223 | GPU
DEBUG 01-13 08:46:41.891956.891956 lmp.py:1622]   Expert 20 |    229 | GPU
DEBUG 01-13 08:46:41.891930.891930 lmp.py:1622]   Expert 48 |    230 | GPU
DEBUG 01-13 08:46:41.891381.891381 lmp.py:1622]   Expert 45 |    242 | GPU
DEBUG 01-13 08:46:41.891355.891355 lmp.py:1622]   Expert 16 |    249 | GPU
DEBUG 01-13 08:46:41.891614.891614 lmp.py:1622]   Expert 21 |    253 | GPU
DEBUG 01-13 08:46:41.891873.891873 lmp.py:1622]   Expert 35 |    257 | GPU
DEBUG 01-13 08:46:41.891131.891131 lmp.py:1622]   Expert 55 |    257 | GPU
DEBUG 01-13 08:46:41.891152.891152 lmp.py:1622]   Expert  5 |    291 | GPU
DEBUG 01-13 08:46:41.891411.891411 lmp.py:1622]   Expert 23 |    373 | GPU
DEBUG 01-13 08:46:41.891669.891669 lmp.py:1622]   Expert 13 |    387 | GPU
DEBUG 01-13 08:46:41.891167.891167 lmp.py:1622]   Expert 17 |    435 | GPU
DEBUG 01-13 08:46:41.891187.891187 lmp.py:1622]   Expert 63 |    445 | GPU
DEBUG 01-13 08:46:41.891207.891207 lmp.py:1622]   Expert  9 |    446 | GPU
DEBUG 01-13 08:46:41.891466.891466 lmp.py:1622]   Expert 62 |   1168 | GPU
DEBUG 01-13 08:46:41.891679.891679 lmp.py:1623] 
DEBUG 01-13 08:46:41.891679.891679 lmp.py:1623]   CPU total tokens: 3664 (29.8%)
DEBUG 01-13 08:46:41.891845.891845 lmp.py:1624]   GPU total tokens: 8624 (70.2%)
DEBUG 01-13 08:46:41.891587.891587 cuda_h.py:19] end experts_map_get cost 0.0014505386352539062 seconds
DEBUG 01-13 08:46:41.891146.891146 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-13 08:46:41.891385.891385 lmp.py:1632] 
DEBUG 01-13 08:46:41.891385.891385 lmp.py:1632]   Computing 32 experts on CPU MP...
DEBUG 01-13 08:46:41.891307.891307 cuda_h.py:19] end cpu_experts_submit cost 5.4836273193359375e-05 seconds
DEBUG 01-13 08:46:41.891381.891381 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-13 08:46:41.891210.891210 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-13 08:46:41.892301.892301 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-13 08:46:41.892999.892999 cuda_h.py:19] end experts_func_gpu_einsum_mp cost 0.06664085388183594 seconds
DEBUG 01-13 08:46:41.894301.894301 cuda_h.py:19] end allocate_cuda_memory cost 0.0019314289093017578 seconds
DEBUG 01-13 08:46:41.894455.894455 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-13 08:46:41.894563.894563 sllm_store_c.py:27] get device uuid map
DEBUG 01-13 08:46:41.894564.894564 sllm_store_c.py:29] call client load into gpu
DEBUG 01-13 08:46:41.894168.894168 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, e5e7561f-177f-498d-82c2-d9229705853b
DEBUG 01-13 08:46:41.894141.894141 client.py:106] call stub.LoadModelAsync
DEBUG 01-13 08:46:41.895689.895689 cuda_h.py:10] start experts_func_gpu_einsum_mp
INFO 01-13 08:46:41.895241.895241 client.py:127] Model loaded
DEBUG 01-13 08:46:41.895985.895985 cuda_h.py:10] start restore2model
DEBUG 01-13 08:46:41.896489.896489 cuda_h.py:19] end restore2model cost 0.00040531158447265625 seconds
DEBUG 01-13 08:46:41.896140.896140 cuda_h.py:19] end sllm_worker_task cost 0.01109766960144043 seconds
INFO 01-13 08:46:41.897261.897261 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, e5e7561f-177f-498d-82c2-d9229705853b
DEBUG 01-13 08:46:41.897820.897820 cuda_h.py:19] end load_into_gpu_async cost 0.0033118724822998047 seconds
DEBUG 01-13 08:46:41.897284.897284 cuda_h.py:10] start restore_tensors2
DEBUG 01-13 08:46:41.897330.897330 cuda_h.py:19] end restore_tensors2 cost 0.00035881996154785156 seconds
DEBUG 01-13 08:46:41.897021.897021 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.005980730056762695 seconds
DEBUG 01-13 08:46:41.898883.898883 cuda_h.py:10] start restore2model
DEBUG 01-13 08:46:41.900121.900121 cuda_h.py:19] end restore2model cost 0.002534627914428711 seconds
DEBUG 01-13 08:46:41.900434.900434 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.008691549301147461 seconds
DEBUG 01-13 08:46:41.900561.900561 cuda_h.py:10] start gpu_sexperts
DEBUG 01-13 08:46:41.900716.900716 cuda_h.py:19] end gpu_sexperts cost 0.00026035308837890625 seconds
DEBUG 01-13 08:46:41.900877.900877 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-13 08:46:41.901600.901600 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 1.4781951904296875e-05 seconds
DEBUG 01-13 08:46:41.901865.901865 cuda_h.py:10] start wait_experts
INFO 01-13 08:46:41.901085.901085 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, e5e7561f-177f-498d-82c2-d9229705853b
DEBUG 01-13 08:46:41.906357.906357 mlpmodule.py:1006] group tensors cost 0.010437726974487305 s
DEBUG 01-13 08:46:41.911228.911228 mlpmodule.py:1044] pad cost 0.0036656856536865234 s
DEBUG 01-13 08:46:41.911695.911695 mlpmodule.py:1050] create cpu tensor cost 0.00012135505676269531 s
DEBUG 01-13 08:46:41.911926.911926 mlpmodule.py:1055] move to cpu cost 7.176399230957031e-05 s
DEBUG 01-13 08:46:41.921745.921745 mlpmodule.py:1069] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-13 08:46:41.921567.921567 mlpmodule.py:1070] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-13 08:46:41.921684.921684 mlpmodule.py:1075] group_w3 first element: 0.00457763671875
WARNING 01-13 08:46:41.921716.921716 mlpmodule.py:1085] start einsum2
DEBUG 01-13 08:46:41.936765.936765 mlpmodule.py:1095] group einsum cost 0.024325132369995117 s
DEBUG 01-13 08:46:41.936148.936148 mlpmodule.py:1103] cpy2cputensor cost 0.0006976127624511719 s
INFO 01-13 08:46:41.948676.948676 client.py:127] Model loaded
DEBUG 01-13 08:46:41.948040.948040 cuda_h.py:19] end wait_experts cost 0.04728245735168457 seconds
DEBUG 01-13 08:46:41.948095.948095 cuda_h.py:10] start gpu_experts
DEBUG 01-13 08:46:41.949077.949077 mlpmodule.py:559] gpu group tensors cost 0.0007507801055908203 s
DEBUG 01-13 08:46:41.951173.951173 mlpmodule.py:592] gpu pad cost 0.002173900604248047 s
DEBUG 01-13 08:46:41.951765.951765 mlpmodule.py:598] start_w1
DEBUG 01-13 08:46:41.952353.952353 mlpmodule.py:602] start_w3
DEBUG 01-13 08:46:41.952419.952419 mlpmodule.py:608] start_w2
DEBUG 01-13 08:46:41.952136.952136 mlpmodule.py:611] gpu group einsum cost 0.0011835098266601562 s
DEBUG 01-13 08:46:41.954002.954002 mlpmodule.py:683] gpu experts func einsum cost 0.006423234939575195 s
DEBUG 01-13 08:46:41.955515.955515 cuda_h.py:19] end gpu_experts cost 0.006602287292480469 seconds
DEBUG 01-13 08:46:41.955841.955841 cuda_h.py:10] start cpu_thread_manager_mp_wait
DEBUG 01-13 08:46:41.955506.955506 cuda_h.py:19] end cpu_thread_manager_mp_wait cost 4.0531158447265625e-05 seconds
DEBUG 01-13 08:46:41.955422.955422 cuda_h.py:19] end layer_moe_generate_mp_l_18 cost 0.06567573547363281 seconds
DEBUG 01-13 08:46:41.955337.955337 lmp.py:1550] -------------------------------- end prefill layer 17 --------------------------------
DEBUG 01-13 08:46:41.955345.955345 lmp.py:1493] -------------------------------- start prefill layer 18 --------------------------------
DEBUG 01-13 08:46:41.955379.955379 cuda_h.py:10] start start_load_qkvogn_s_weight_l_19
DEBUG 01-13 08:46:41.955512.955512 cuda_h.py:10] start start_load_qkvogn_s_weight_l_19
DEBUG 01-13 08:46:41.955971.955971 cuda_h.py:19] end start_load_qkvogn_s_weight_l_19 cost 3.24249267578125e-05 seconds
DEBUG 01-13 08:46:41.955290.955290 cuda_h.py:19] end start_load_qkvogn_s_weight_l_19 cost 6.031990051269531e-05 seconds
DEBUG 01-13 08:46:41.955648.955648 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-13 08:46:41.955722.955722 cuda_h.py:10] start sllm_worker_task
DEBUG 01-13 08:46:41.955515.955515 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-13 08:46:41.955238.955238 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-13 08:46:41.956110.956110 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-13 08:46:41.956892.956892 cuda_h.py:19] end allocate_cuda_memory cost 0.0001888275146484375 seconds
DEBUG 01-13 08:46:41.956471.956471 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-13 08:46:41.956326.956326 sllm_store_c.py:27] get device uuid map
DEBUG 01-13 08:46:41.956063.956063 sllm_store_c.py:29] call client load into gpu
DEBUG 01-13 08:46:41.956786.956786 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 0be84d7b-95fa-4dad-b768-0b04e3cc88f4
DEBUG 01-13 08:46:41.956286.956286 client.py:106] call stub.LoadModelAsync
DEBUG 01-13 08:46:41.956930.956930 cuda_h.py:10] start self_attn
INFO 01-13 08:46:41.958656.958656 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 0be84d7b-95fa-4dad-b768-0b04e3cc88f4
DEBUG 01-13 08:46:41.958062.958062 cuda_h.py:19] end load_into_gpu_async cost 0.001806497573852539 seconds
DEBUG 01-13 08:46:41.958308.958308 cuda_h.py:10] start restore_tensors2
DEBUG 01-13 08:46:41.958484.958484 cuda_h.py:19] end restore_tensors2 cost 6.866455078125e-05 seconds
DEBUG 01-13 08:46:41.958571.958571 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0023298263549804688 seconds
INFO 01-13 08:46:41.958030.958030 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 0be84d7b-95fa-4dad-b768-0b04e3cc88f4
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-13 08:46:41.960574.960574 cuda_h.py:19] end self_attn cost 0.0031523704528808594 seconds
DEBUG 01-13 08:46:41.960651.960651 cuda_h.py:19] end iln_self_attn_paln cost 0.0046100616455078125 seconds
DEBUG 01-13 08:46:41.960110.960110 cuda_h.py:10] start layer_moe_generate_mp_l_19
DEBUG 01-13 08:46:41.960310.960310 cuda_h.py:10] start gate
DEBUG 01-13 08:46:41.961690.961690 cuda_h.py:19] end gate cost 0.0006337165832519531 seconds
DEBUG 01-13 08:46:41.961089.961089 cuda_h.py:10] start experts_map_get
DEBUG 01-13 08:46:41.961429.961429 lmp.py:1611] 
DEBUG 01-13 08:46:41.961429.961429 lmp.py:1611] Expert Token Distribution & Device Allocation:
DEBUG 01-13 08:46:41.961755.961755 lmp.py:1612]   Total experts: 64
DEBUG 01-13 08:46:41.961212.961212 lmp.py:1613]   CPU experts: 32 (50%)
DEBUG 01-13 08:46:41.961809.961809 lmp.py:1614]   GPU experts: 32 (50%)
DEBUG 01-13 08:46:41.961022.961022 lmp.py:1615] 
DEBUG 01-13 08:46:41.961022.961022 lmp.py:1615]   Expert ID | Tokens | Device
DEBUG 01-13 08:46:41.961188.961188 lmp.py:1616]   -----------------------------------
DEBUG 01-13 08:46:41.961837.961837 lmp.py:1622]   Expert 32 |     40 | CPU
DEBUG 01-13 08:46:41.961004.961004 lmp.py:1622]   Expert 30 |     46 | CPU
DEBUG 01-13 08:46:41.961885.961885 lmp.py:1622]   Expert  5 |     48 | CPU
DEBUG 01-13 08:46:41.961051.961051 lmp.py:1622]   Expert 46 |     67 | CPU
DEBUG 01-13 08:46:41.961740.961740 lmp.py:1622]   Expert  8 |     79 | CPU
DEBUG 01-13 08:46:41.961907.961907 lmp.py:1622]   Expert 40 |     90 | CPU
DEBUG 01-13 08:46:41.961596.961596 lmp.py:1622]   Expert 12 |     96 | CPU
DEBUG 01-13 08:46:41.961047.961047 lmp.py:1622]   Expert 27 |    105 | CPU
DEBUG 01-13 08:46:41.961213.961213 lmp.py:1622]   Expert  3 |    109 | CPU
DEBUG 01-13 08:46:41.961333.961333 lmp.py:1622]   Expert 60 |    112 | CPU
DEBUG 01-13 08:46:41.961260.961260 lmp.py:1622]   Expert 58 |    115 | CPU
DEBUG 01-13 08:46:41.961950.961950 lmp.py:1622]   Expert 28 |    120 | CPU
DEBUG 01-13 08:46:41.961639.961639 lmp.py:1622]   Expert 17 |    121 | CPU
DEBUG 01-13 08:46:41.961567.961567 lmp.py:1622]   Expert 29 |    121 | CPU
DEBUG 01-13 08:46:41.961494.961494 lmp.py:1622]   Expert 19 |    128 | CPU
DEBUG 01-13 08:46:41.961707.961707 lmp.py:1622]   Expert 35 |    129 | CPU
DEBUG 01-13 08:46:41.961396.961396 lmp.py:1622]   Expert 21 |    130 | CPU
DEBUG 01-13 08:46:41.961847.961847 lmp.py:1622]   Expert 25 |    131 | CPU
DEBUG 01-13 08:46:41.961536.961536 lmp.py:1622]   Expert 41 |    133 | CPU
DEBUG 01-13 08:46:41.961987.961987 lmp.py:1622]   Expert 52 |    138 | CPU
DEBUG 01-13 08:46:41.961915.961915 lmp.py:1622]   Expert  0 |    140 | CPU
DEBUG 01-13 08:46:41.961604.961604 lmp.py:1622]   Expert 54 |    147 | CPU
DEBUG 01-13 08:46:41.961247.961247 lmp.py:1622]   Expert 56 |    148 | CPU
DEBUG 01-13 08:46:41.961652.961652 lmp.py:1622]   Expert 37 |    150 | CPU
DEBUG 01-13 08:46:41.961056.961056 lmp.py:1622]   Expert 48 |    151 | CPU
DEBUG 01-13 08:46:41.961461.961461 lmp.py:1622]   Expert  6 |    152 | CPU
DEBUG 01-13 08:46:41.961389.961389 lmp.py:1622]   Expert 53 |    158 | CPU
DEBUG 01-13 08:46:41.961078.961078 lmp.py:1622]   Expert 36 |    161 | CPU
DEBUG 01-13 08:46:41.962006.962006 lmp.py:1622]   Expert 63 |    162 | CPU
DEBUG 01-13 08:46:41.962457.962457 lmp.py:1622]   Expert 59 |    168 | CPU
DEBUG 01-13 08:46:41.962146.962146 lmp.py:1622]   Expert  9 |    184 | CPU
DEBUG 01-13 08:46:41.962597.962597 lmp.py:1622]   Expert  1 |    185 | CPU
DEBUG 01-13 08:46:41.962286.962286 lmp.py:1622]   Expert 39 |    191 | GPU
DEBUG 01-13 08:46:41.962499.962499 lmp.py:1622]   Expert 20 |    195 | GPU
DEBUG 01-13 08:46:41.962188.962188 lmp.py:1622]   Expert 43 |    196 | GPU
DEBUG 01-13 08:46:41.962877.962877 lmp.py:1622]   Expert 61 |    201 | GPU
DEBUG 01-13 08:46:41.962328.962328 lmp.py:1622]   Expert 42 |    202 | GPU
DEBUG 01-13 08:46:41.962209.962209 lmp.py:1622]   Expert  7 |    203 | GPU
DEBUG 01-13 08:46:41.962614.962614 lmp.py:1622]   Expert 11 |    203 | GPU
DEBUG 01-13 08:46:41.962780.962780 lmp.py:1622]   Expert 34 |    206 | GPU
DEBUG 01-13 08:46:41.962423.962423 lmp.py:1622]   Expert 47 |    210 | GPU
DEBUG 01-13 08:46:41.962351.962351 lmp.py:1622]   Expert 57 |    216 | GPU
DEBUG 01-13 08:46:41.962802.962802 lmp.py:1622]   Expert 55 |    217 | GPU
DEBUG 01-13 08:46:41.962253.962253 lmp.py:1622]   Expert 13 |    219 | GPU
DEBUG 01-13 08:46:41.962942.962942 lmp.py:1622]   Expert 16 |    221 | GPU
DEBUG 01-13 08:46:41.962870.962870 lmp.py:1622]   Expert 18 |    234 | GPU
DEBUG 01-13 08:46:41.962559.962559 lmp.py:1622]   Expert  4 |    236 | GPU
DEBUG 01-13 08:46:41.962010.962010 lmp.py:1622]   Expert 15 |    237 | GPU
DEBUG 01-13 08:46:41.962699.962699 lmp.py:1622]   Expert 22 |    244 | GPU
DEBUG 01-13 08:46:41.962388.962388 lmp.py:1622]   Expert 50 |    244 | GPU
DEBUG 01-13 08:46:41.962555.962555 lmp.py:1622]   Expert 45 |    246 | GPU
DEBUG 01-13 08:46:41.962390.962390 lmp.py:1622]   Expert 31 |    248 | GPU
DEBUG 01-13 08:46:41.962509.962509 lmp.py:1622]   Expert 33 |    248 | GPU
DEBUG 01-13 08:46:41.962106.962106 lmp.py:1622]   Expert 51 |    254 | GPU
DEBUG 01-13 08:46:41.962272.962272 lmp.py:1622]   Expert 49 |    263 | GPU
DEBUG 01-13 08:46:41.962961.962961 lmp.py:1622]   Expert 38 |    277 | GPU
DEBUG 01-13 08:46:41.962651.962651 lmp.py:1622]   Expert 26 |    284 | GPU
DEBUG 01-13 08:46:41.962102.962102 lmp.py:1622]   Expert 10 |    288 | GPU
DEBUG 01-13 08:46:41.962791.962791 lmp.py:1622]   Expert 44 |    293 | GPU
DEBUG 01-13 08:46:41.962480.962480 lmp.py:1622]   Expert 24 |    300 | GPU
DEBUG 01-13 08:46:41.962170.962170 lmp.py:1622]   Expert 14 |    315 | GPU
DEBUG 01-13 08:46:41.962097.962097 lmp.py:1622]   Expert  2 |    317 | GPU
DEBUG 01-13 08:46:41.962025.962025 lmp.py:1622]   Expert 23 |    434 | GPU
DEBUG 01-13 08:46:41.962476.962476 lmp.py:1622]   Expert 62 |    682 | GPU
DEBUG 01-13 08:46:41.962073.962073 lmp.py:1623] 
DEBUG 01-13 08:46:41.962073.962073 lmp.py:1623]   CPU total tokens: 3964 (32.3%)
DEBUG 01-13 08:46:41.962431.962431 lmp.py:1624]   GPU total tokens: 8324 (67.7%)
DEBUG 01-13 08:46:41.962763.962763 cuda_h.py:19] end experts_map_get cost 0.001522064208984375 seconds
DEBUG 01-13 08:46:41.962182.962182 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-13 08:46:41.962793.962793 lmp.py:1632] 
DEBUG 01-13 08:46:41.962793.962793 lmp.py:1632]   Computing 32 experts on CPU MP...
DEBUG 01-13 08:46:41.962715.962715 cuda_h.py:19] end cpu_experts_submit cost 4.792213439941406e-05 seconds
DEBUG 01-13 08:46:41.962265.962265 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-13 08:46:41.962763.962763 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-13 08:46:41.963424.963424 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-13 08:46:41.963095.963095 mlpmodule.py:785]  experts func einsum cost 0.06711292266845703 s
DEBUG 01-13 08:46:41.963532.963532 cuda_h.py:19] end experts_func_gpu_einsum_mp cost 0.06799435615539551 seconds
DEBUG 01-13 08:46:41.964965.964965 cuda_h.py:19] end allocate_cuda_memory cost 0.001489877700805664 seconds
DEBUG 01-13 08:46:41.964143.964143 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-13 08:46:41.964912.964912 sllm_store_c.py:27] get device uuid map
DEBUG 01-13 08:46:41.964960.964960 sllm_store_c.py:29] call client load into gpu
DEBUG 01-13 08:46:41.965279.965279 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 74b7059b-1ab7-48f4-ba22-616ab218856c
DEBUG 01-13 08:46:41.965159.965159 client.py:106] call stub.LoadModelAsync
INFO 01-13 08:46:41.965370.965370 client.py:127] Model loaded
DEBUG 01-13 08:46:41.965676.965676 cuda_h.py:10] start restore2model
DEBUG 01-13 08:46:41.965414.965414 cuda_h.py:10] start experts_func_gpu_einsum_mp
DEBUG 01-13 08:46:41.965158.965158 cuda_h.py:19] end restore2model cost 0.00032520294189453125 seconds
DEBUG 01-13 08:46:41.965782.965782 cuda_h.py:19] end sllm_worker_task cost 0.009929895401000977 seconds
INFO 01-13 08:46:41.966449.966449 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 74b7059b-1ab7-48f4-ba22-616ab218856c
DEBUG 01-13 08:46:41.966146.966146 cuda_h.py:19] end load_into_gpu_async cost 0.0020318031311035156 seconds
DEBUG 01-13 08:46:41.967180.967180 cuda_h.py:10] start restore_tensors2
DEBUG 01-13 08:46:41.967988.967988 cuda_h.py:19] end restore_tensors2 cost 0.0003592967987060547 seconds
DEBUG 01-13 08:46:41.967486.967486 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0045468807220458984 seconds
DEBUG 01-13 08:46:41.967441.967441 cuda_h.py:10] start restore2model
DEBUG 01-13 08:46:41.970037.970037 cuda_h.py:19] end restore2model cost 0.0025534629821777344 seconds
DEBUG 01-13 08:46:41.970966.970966 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.007272481918334961 seconds
DEBUG 01-13 08:46:41.970113.970113 cuda_h.py:10] start gpu_sexperts
DEBUG 01-13 08:46:41.970984.970984 cuda_h.py:19] end gpu_sexperts cost 0.00026106834411621094 seconds
DEBUG 01-13 08:46:41.970429.970429 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-13 08:46:41.970437.970437 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 1.430511474609375e-05 seconds
DEBUG 01-13 08:46:41.970941.970941 cuda_h.py:10] start wait_experts
INFO 01-13 08:46:41.970922.970922 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 74b7059b-1ab7-48f4-ba22-616ab218856c
DEBUG 01-13 08:46:41.971122.971122 mlpmodule.py:1006] group tensors cost 0.005667686462402344 s
DEBUG 01-13 08:46:41.975261.975261 mlpmodule.py:1044] pad cost 0.0032308101654052734 s
DEBUG 01-13 08:46:41.976936.976936 mlpmodule.py:1050] create cpu tensor cost 0.00014781951904296875 s
DEBUG 01-13 08:46:41.976360.976360 mlpmodule.py:1055] move to cpu cost 8.344650268554688e-05 s
DEBUG 01-13 08:46:41.985799.985799 mlpmodule.py:1069] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-13 08:46:41.986767.986767 mlpmodule.py:1070] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-13 08:46:41.986573.986573 mlpmodule.py:1075] group_w3 first element: 0.0024871826171875
WARNING 01-13 08:46:41.986373.986373 mlpmodule.py:1085] start einsum2
DEBUG 01-13 08:46:41.999156.999156 mlpmodule.py:1095] group einsum cost 0.02341294288635254 s
DEBUG 01-13 08:46:42.000600.000600 mlpmodule.py:1103] cpy2cputensor cost 0.00074005126953125 s
INFO 01-13 08:46:42.017657.017657 client.py:127] Model loaded
DEBUG 01-13 08:46:42.018331.018331 cuda_h.py:19] end wait_experts cost 0.047403812408447266 seconds
DEBUG 01-13 08:46:42.018610.018610 cuda_h.py:10] start gpu_experts
DEBUG 01-13 08:46:42.018012.018012 mlpmodule.py:559] gpu group tensors cost 0.0006194114685058594 s
DEBUG 01-13 08:46:42.020707.020707 mlpmodule.py:592] gpu pad cost 0.0014984607696533203 s
DEBUG 01-13 08:46:42.020273.020273 mlpmodule.py:598] start_w1
DEBUG 01-13 08:46:42.020841.020841 mlpmodule.py:602] start_w3
DEBUG 01-13 08:46:42.020833.020833 mlpmodule.py:608] start_w2
DEBUG 01-13 08:46:42.021303.021303 mlpmodule.py:611] gpu group einsum cost 0.0006895065307617188 s
DEBUG 01-13 08:46:42.023752.023752 mlpmodule.py:683] gpu experts func einsum cost 0.005136251449584961 s
DEBUG 01-13 08:46:42.023789.023789 cuda_h.py:19] end gpu_experts cost 0.0053021907806396484 seconds
DEBUG 01-13 08:46:42.023160.023160 cuda_h.py:10] start cpu_thread_manager_mp_wait
DEBUG 01-13 08:46:42.023348.023348 cuda_h.py:19] end cpu_thread_manager_mp_wait cost 3.933906555175781e-05 seconds
DEBUG 01-13 08:46:42.023549.023549 cuda_h.py:19] end layer_moe_generate_mp_l_19 cost 0.06313633918762207 seconds
DEBUG 01-13 08:46:42.023385.023385 lmp.py:1550] -------------------------------- end prefill layer 18 --------------------------------
DEBUG 01-13 08:46:42.023108.023108 lmp.py:1493] -------------------------------- start prefill layer 19 --------------------------------
DEBUG 01-13 08:46:42.023665.023665 cuda_h.py:10] start start_load_qkvogn_s_weight_l_20
DEBUG 01-13 08:46:42.023560.023560 cuda_h.py:10] start start_load_qkvogn_s_weight_l_20
DEBUG 01-13 08:46:42.023873.023873 cuda_h.py:19] end start_load_qkvogn_s_weight_l_20 cost 3.147125244140625e-05 seconds
DEBUG 01-13 08:46:42.023477.023477 cuda_h.py:19] end start_load_qkvogn_s_weight_l_20 cost 5.841255187988281e-05 seconds
DEBUG 01-13 08:46:42.023881.023881 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-13 08:46:42.024970.024970 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-13 08:46:42.024363.024363 cuda_h.py:10] start sllm_worker_task
DEBUG 01-13 08:46:42.024499.024499 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-13 08:46:42.024812.024812 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-13 08:46:42.024725.024725 cuda_h.py:19] end allocate_cuda_memory cost 0.00032258033752441406 seconds
DEBUG 01-13 08:46:42.024602.024602 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-13 08:46:42.024723.024723 sllm_store_c.py:27] get device uuid map
DEBUG 01-13 08:46:42.024214.024214 sllm_store_c.py:29] call client load into gpu
DEBUG 01-13 08:46:42.024248.024248 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 0fea61dc-4d3d-4ce4-8000-8471a94414bf
DEBUG 01-13 08:46:42.024264.024264 client.py:106] call stub.LoadModelAsync
DEBUG 01-13 08:46:42.025357.025357 cuda_h.py:10] start self_attn
DEBUG 01-13 08:46:42.025923.025923 mlpmodule.py:785]  experts func einsum cost 0.05926918983459473 s
DEBUG 01-13 08:46:42.025859.025859 cuda_h.py:19] end experts_func_gpu_einsum_mp cost 0.060247182846069336 seconds
INFO 01-13 08:46:42.026228.026228 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 0fea61dc-4d3d-4ce4-8000-8471a94414bf
DEBUG 01-13 08:46:42.026443.026443 cuda_h.py:19] end load_into_gpu_async cost 0.0017077922821044922 seconds
DEBUG 01-13 08:46:42.026483.026483 cuda_h.py:10] start restore_tensors2
DEBUG 01-13 08:46:42.026612.026612 cuda_h.py:19] end restore_tensors2 cost 6.842613220214844e-05 seconds
DEBUG 01-13 08:46:42.026336.026336 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0024073123931884766 seconds
INFO 01-13 08:46:42.026973.026973 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 0fea61dc-4d3d-4ce4-8000-8471a94414bf
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-13 08:46:42.028184.028184 cuda_h.py:19] end self_attn cost 0.0028650760650634766 seconds
DEBUG 01-13 08:46:42.028108.028108 cuda_h.py:19] end iln_self_attn_paln cost 0.00435185432434082 seconds
DEBUG 01-13 08:46:42.031493.031493 cuda_h.py:10] start layer_moe_generate_mp_l_20
DEBUG 01-13 08:46:42.031185.031185 cuda_h.py:10] start gate
DEBUG 01-13 08:46:42.032688.032688 cuda_h.py:19] end gate cost 0.0007562637329101562 seconds
DEBUG 01-13 08:46:42.032425.032425 cuda_h.py:10] start experts_map_get
DEBUG 01-13 08:46:42.032879.032879 lmp.py:1611] 
DEBUG 01-13 08:46:42.032879.032879 lmp.py:1611] Expert Token Distribution & Device Allocation:
DEBUG 01-13 08:46:42.032257.032257 lmp.py:1612]   Total experts: 64
DEBUG 01-13 08:46:42.032622.032622 lmp.py:1613]   CPU experts: 32 (50%)
DEBUG 01-13 08:46:42.032888.032888 lmp.py:1614]   GPU experts: 32 (50%)
DEBUG 01-13 08:46:42.032769.032769 lmp.py:1615] 
DEBUG 01-13 08:46:42.032769.032769 lmp.py:1615]   Expert ID | Tokens | Device
DEBUG 01-13 08:46:42.032366.032366 lmp.py:1616]   -----------------------------------
DEBUG 01-13 08:46:42.032354.032354 lmp.py:1622]   Expert 44 |     35 | CPU
DEBUG 01-13 08:46:42.032950.032950 lmp.py:1622]   Expert  1 |     51 | CPU
DEBUG 01-13 08:46:42.032355.032355 lmp.py:1622]   Expert 28 |     55 | CPU
DEBUG 01-13 08:46:42.032283.032283 lmp.py:1622]   Expert 60 |     64 | CPU
DEBUG 01-13 08:46:42.032972.032972 lmp.py:1622]   Expert 48 |     74 | CPU
DEBUG 01-13 08:46:42.032661.032661 lmp.py:1622]   Expert 27 |     93 | CPU
DEBUG 01-13 08:46:42.032781.032781 lmp.py:1622]   Expert  0 |    108 | CPU
DEBUG 01-13 08:46:42.032662.032662 lmp.py:1622]   Expert 62 |    109 | CPU
DEBUG 01-13 08:46:42.032067.032067 lmp.py:1622]   Expert 22 |    113 | CPU
DEBUG 01-13 08:46:42.032187.032187 lmp.py:1622]   Expert 30 |    115 | CPU
DEBUG 01-13 08:46:42.032353.032353 lmp.py:1622]   Expert 42 |    116 | CPU
DEBUG 01-13 08:46:42.032565.032565 lmp.py:1622]   Expert 59 |    117 | CPU
DEBUG 01-13 08:46:42.032016.032016 lmp.py:1622]   Expert 58 |    118 | CPU
DEBUG 01-13 08:46:42.032944.032944 lmp.py:1622]   Expert 16 |    123 | CPU
DEBUG 01-13 08:46:42.032633.032633 lmp.py:1622]   Expert  8 |    132 | CPU
DEBUG 01-13 08:46:42.032561.032561 lmp.py:1622]   Expert 12 |    133 | CPU
DEBUG 01-13 08:46:42.032773.032773 lmp.py:1622]   Expert 50 |    136 | CPU
DEBUG 01-13 08:46:42.032224.032224 lmp.py:1622]   Expert 56 |    140 | CPU
DEBUG 01-13 08:46:42.032867.032867 lmp.py:1622]   Expert  5 |    146 | CPU
DEBUG 01-13 08:46:42.032272.032272 lmp.py:1622]   Expert 57 |    147 | CPU
DEBUG 01-13 08:46:42.032200.032200 lmp.py:1622]   Expert 15 |    148 | CPU
DEBUG 01-13 08:46:42.032604.032604 lmp.py:1622]   Expert 55 |    153 | CPU
DEBUG 01-13 08:46:42.032009.032009 lmp.py:1622]   Expert 26 |    154 | CPU
DEBUG 01-13 08:46:42.032698.032698 lmp.py:1622]   Expert 32 |    159 | CPU
DEBUG 01-13 08:46:42.032387.032387 lmp.py:1622]   Expert 52 |    159 | CPU
DEBUG 01-13 08:46:42.032838.032838 lmp.py:1622]   Expert 47 |    161 | CPU
DEBUG 01-13 08:46:42.032527.032527 lmp.py:1622]   Expert 13 |    162 | CPU
DEBUG 01-13 08:46:42.032217.032217 lmp.py:1622]   Expert 40 |    163 | CPU
DEBUG 01-13 08:46:42.033668.033668 lmp.py:1622]   Expert 24 |    165 | CPU
DEBUG 01-13 08:46:42.033880.033880 lmp.py:1622]   Expert 54 |    165 | CPU
DEBUG 01-13 08:46:42.033569.033569 lmp.py:1622]   Expert  6 |    167 | CPU
DEBUG 01-13 08:46:42.033259.033259 lmp.py:1622]   Expert 41 |    167 | CPU
DEBUG 01-13 08:46:42.033684.033684 lmp.py:1622]   Expert 18 |    168 | GPU
DEBUG 01-13 08:46:42.033611.033611 lmp.py:1622]   Expert 34 |    170 | GPU
DEBUG 01-13 08:46:42.033539.033539 lmp.py:1622]   Expert  2 |    171 | GPU
DEBUG 01-13 08:46:42.033228.033228 lmp.py:1622]   Expert  3 |    180 | GPU
DEBUG 01-13 08:46:42.033156.033156 lmp.py:1622]   Expert 37 |    181 | GPU
DEBUG 01-13 08:46:42.033322.033322 lmp.py:1622]   Expert 46 |    183 | GPU
DEBUG 01-13 08:46:42.033488.033488 lmp.py:1622]   Expert 20 |    184 | GPU
DEBUG 01-13 08:46:42.033178.033178 lmp.py:1622]   Expert 51 |    194 | GPU
DEBUG 01-13 08:46:42.033105.033105 lmp.py:1622]   Expert 17 |    199 | GPU
DEBUG 01-13 08:46:42.033033.033033 lmp.py:1622]   Expert 19 |    200 | GPU
DEBUG 01-13 08:46:42.033961.033961 lmp.py:1622]   Expert 25 |    201 | GPU
DEBUG 01-13 08:46:42.033888.033888 lmp.py:1622]   Expert 31 |    202 | GPU
DEBUG 01-13 08:46:42.033293.033293 lmp.py:1622]   Expert 43 |    202 | GPU
DEBUG 01-13 08:46:42.033797.033797 lmp.py:1622]   Expert 23 |    203 | GPU
DEBUG 01-13 08:46:42.033202.033202 lmp.py:1622]   Expert 11 |    207 | GPU
DEBUG 01-13 08:46:42.033891.033891 lmp.py:1622]   Expert 35 |    208 | GPU
DEBUG 01-13 08:46:42.033342.033342 lmp.py:1622]   Expert 49 |    217 | GPU
DEBUG 01-13 08:46:42.033316.033316 lmp.py:1622]   Expert 53 |    229 | GPU
DEBUG 01-13 08:46:42.033290.033290 lmp.py:1622]   Expert 10 |    231 | GPU
DEBUG 01-13 08:46:42.033026.033026 lmp.py:1622]   Expert 39 |    234 | GPU
DEBUG 01-13 08:46:42.033000.033000 lmp.py:1622]   Expert 33 |    249 | GPU
DEBUG 01-13 08:46:42.033974.033974 lmp.py:1622]   Expert 38 |    265 | GPU
DEBUG 01-13 08:46:42.033948.033948 lmp.py:1622]   Expert 36 |    270 | GPU
DEBUG 01-13 08:46:42.033922.033922 lmp.py:1622]   Expert  4 |    304 | GPU
DEBUG 01-13 08:46:42.033896.033896 lmp.py:1622]   Expert 21 |    324 | GPU
DEBUG 01-13 08:46:42.033631.033631 lmp.py:1622]   Expert 14 |    345 | GPU
DEBUG 01-13 08:46:42.033367.033367 lmp.py:1622]   Expert 45 |    364 | GPU
DEBUG 01-13 08:46:42.033341.033341 lmp.py:1622]   Expert 63 |    364 | GPU
DEBUG 01-13 08:46:42.033507.033507 lmp.py:1622]   Expert 61 |    383 | GPU
DEBUG 01-13 08:46:42.033196.033196 lmp.py:1622]   Expert  9 |    407 | GPU
DEBUG 01-13 08:46:42.033376.033376 lmp.py:1622]   Expert 29 |    484 | GPU
DEBUG 01-13 08:46:42.033827.033827 lmp.py:1622]   Expert  7 |    517 | GPU
DEBUG 01-13 08:46:42.033444.033444 lmp.py:1623] 
DEBUG 01-13 08:46:42.033444.033444 lmp.py:1623]   CPU total tokens: 4048 (32.9%)
DEBUG 01-13 08:46:42.033325.033325 lmp.py:1624]   GPU total tokens: 8240 (67.1%)
DEBUG 01-13 08:46:42.033260.033260 cuda_h.py:19] end experts_map_get cost 0.0015709400177001953 seconds
INFO 01-13 08:46:42.033276.033276 client.py:127] Model loaded
DEBUG 01-13 08:46:42.033841.033841 cuda_h.py:10] start restore2model
DEBUG 01-13 08:46:42.034283.034283 cuda_h.py:19] end restore2model cost 0.0004940032958984375 seconds
DEBUG 01-13 08:46:42.034589.034589 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-13 08:46:42.034451.034451 cuda_h.py:19] end sllm_worker_task cost 0.010258674621582031 seconds
DEBUG 01-13 08:46:42.034387.034387 lmp.py:1632] 
DEBUG 01-13 08:46:42.034387.034387 lmp.py:1632]   Computing 32 experts on CPU MP...
DEBUG 01-13 08:46:42.034895.034895 cuda_h.py:19] end cpu_experts_submit cost 0.00013184547424316406 seconds
DEBUG 01-13 08:46:42.034975.034975 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-13 08:46:42.034666.034666 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-13 08:46:42.034862.034862 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-13 08:46:42.035831.035831 cuda_h.py:19] end allocate_cuda_memory cost 0.00022172927856445312 seconds
DEBUG 01-13 08:46:42.035504.035504 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-13 08:46:42.035889.035889 sllm_store_c.py:27] get device uuid map
DEBUG 01-13 08:46:42.035725.035725 sllm_store_c.py:29] call client load into gpu
DEBUG 01-13 08:46:42.035521.035521 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 859aa132-35aa-4513-9d7d-d5326c42a882
DEBUG 01-13 08:46:42.035262.035262 client.py:106] call stub.LoadModelAsync
DEBUG 01-13 08:46:42.036509.036509 cuda_h.py:10] start experts_func_gpu_einsum_mp
INFO 01-13 08:46:42.037433.037433 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 859aa132-35aa-4513-9d7d-d5326c42a882
DEBUG 01-13 08:46:42.037554.037554 cuda_h.py:19] end load_into_gpu_async cost 0.002246379852294922 seconds
DEBUG 01-13 08:46:42.037800.037800 cuda_h.py:10] start restore_tensors2
DEBUG 01-13 08:46:42.038992.038992 cuda_h.py:19] end restore_tensors2 cost 0.0003612041473388672 seconds
DEBUG 01-13 08:46:42.038967.038967 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0036382675170898438 seconds
DEBUG 01-13 08:46:42.038922.038922 cuda_h.py:10] start restore2model
DEBUG 01-13 08:46:42.041601.041601 cuda_h.py:19] end restore2model cost 0.0026481151580810547 seconds
DEBUG 01-13 08:46:42.041060.041060 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.0064656734466552734 seconds
DEBUG 01-13 08:46:42.041140.041140 cuda_h.py:10] start gpu_sexperts
DEBUG 01-13 08:46:42.041190.041190 cuda_h.py:19] end gpu_sexperts cost 0.0002868175506591797 seconds
DEBUG 01-13 08:46:42.041305.041305 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-13 08:46:42.041843.041843 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 1.6689300537109375e-05 seconds
DEBUG 01-13 08:46:42.041016.041016 cuda_h.py:10] start wait_experts
INFO 01-13 08:46:42.041427.041427 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 859aa132-35aa-4513-9d7d-d5326c42a882
DEBUG 01-13 08:46:42.043849.043849 mlpmodule.py:1006] group tensors cost 0.006091594696044922 s
DEBUG 01-13 08:46:42.047057.047057 mlpmodule.py:1044] pad cost 0.003139495849609375 s
DEBUG 01-13 08:46:42.047089.047089 mlpmodule.py:1050] create cpu tensor cost 7.82012939453125e-05 s
DEBUG 01-13 08:46:42.047185.047185 mlpmodule.py:1055] move to cpu cost 5.173683166503906e-05 s
DEBUG 01-13 08:46:42.056098.056098 mlpmodule.py:1069] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-13 08:46:42.056363.056363 mlpmodule.py:1070] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-13 08:46:42.057533.057533 mlpmodule.py:1075] group_w3 first element: -0.0034942626953125
WARNING 01-13 08:46:42.057280.057280 mlpmodule.py:1085] start einsum2
DEBUG 01-13 08:46:42.069806.069806 mlpmodule.py:1095] group einsum cost 0.022193193435668945 s
DEBUG 01-13 08:46:42.070587.070587 mlpmodule.py:1103] cpy2cputensor cost 0.0007014274597167969 s
INFO 01-13 08:46:42.088293.088293 client.py:127] Model loaded
DEBUG 01-13 08:46:42.088191.088191 cuda_h.py:19] end wait_experts cost 0.047139644622802734 seconds
DEBUG 01-13 08:46:42.088994.088994 cuda_h.py:10] start gpu_experts
DEBUG 01-13 08:46:42.089646.089646 mlpmodule.py:559] gpu group tensors cost 0.0005934238433837891 s
DEBUG 01-13 08:46:42.091259.091259 mlpmodule.py:592] gpu pad cost 0.001439809799194336 s
DEBUG 01-13 08:46:42.091301.091301 mlpmodule.py:598] start_w1
DEBUG 01-13 08:46:42.091479.091479 mlpmodule.py:602] start_w3
DEBUG 01-13 08:46:42.091426.091426 mlpmodule.py:608] start_w2
DEBUG 01-13 08:46:42.091133.091133 mlpmodule.py:611] gpu group einsum cost 0.0007176399230957031 s
DEBUG 01-13 08:46:42.093707.093707 mlpmodule.py:683] gpu experts func einsum cost 0.004996299743652344 s
DEBUG 01-13 08:46:42.094054.094054 cuda_h.py:19] end gpu_experts cost 0.005147695541381836 seconds
DEBUG 01-13 08:46:42.094803.094803 cuda_h.py:10] start cpu_thread_manager_mp_wait
DEBUG 01-13 08:46:42.094614.094614 cuda_h.py:19] end cpu_thread_manager_mp_wait cost 4.458427429199219e-05 seconds
DEBUG 01-13 08:46:42.094146.094146 cuda_h.py:19] end layer_moe_generate_mp_l_20 cost 0.06296014785766602 seconds
DEBUG 01-13 08:46:42.094565.094565 lmp.py:1550] -------------------------------- end prefill layer 19 --------------------------------
DEBUG 01-13 08:46:42.094705.094705 lmp.py:1493] -------------------------------- start prefill layer 20 --------------------------------
DEBUG 01-13 08:46:42.094832.094832 cuda_h.py:10] start start_load_qkvogn_s_weight_l_21
DEBUG 01-13 08:46:42.094058.094058 cuda_h.py:10] start start_load_qkvogn_s_weight_l_21
DEBUG 01-13 08:46:42.094702.094702 cuda_h.py:19] end start_load_qkvogn_s_weight_l_21 cost 3.0994415283203125e-05 seconds
DEBUG 01-13 08:46:42.094352.094352 cuda_h.py:19] end start_load_qkvogn_s_weight_l_21 cost 5.698204040527344e-05 seconds
DEBUG 01-13 08:46:42.094564.094564 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-13 08:46:42.094242.094242 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-13 08:46:42.094682.094682 cuda_h.py:10] start sllm_worker_task
DEBUG 01-13 08:46:42.094586.094586 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-13 08:46:42.094091.094091 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-13 08:46:42.095865.095865 cuda_h.py:19] end allocate_cuda_memory cost 0.0003247261047363281 seconds
DEBUG 01-13 08:46:42.095046.095046 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-13 08:46:42.095517.095517 sllm_store_c.py:27] get device uuid map
DEBUG 01-13 08:46:42.095194.095194 sllm_store_c.py:29] call client load into gpu
DEBUG 01-13 08:46:42.095989.095989 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 1a990a4f-f760-4792-98d6-75a4c685ade5
DEBUG 01-13 08:46:42.095913.095913 client.py:106] call stub.LoadModelAsync
DEBUG 01-13 08:46:42.095525.095525 cuda_h.py:10] start self_attn
INFO 01-13 08:46:42.097811.097811 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 1a990a4f-f760-4792-98d6-75a4c685ade5
DEBUG 01-13 08:46:42.097601.097601 cuda_h.py:19] end load_into_gpu_async cost 0.0017113685607910156 seconds
DEBUG 01-13 08:46:42.097681.097681 cuda_h.py:10] start restore_tensors2
DEBUG 01-13 08:46:42.097479.097479 cuda_h.py:19] end restore_tensors2 cost 7.081031799316406e-05 seconds
DEBUG 01-13 08:46:42.097374.097374 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.002336263656616211 seconds
INFO 01-13 08:46:42.097919.097919 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 1a990a4f-f760-4792-98d6-75a4c685ade5
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-13 08:46:42.098985.098985 cuda_h.py:19] end self_attn cost 0.003017425537109375 seconds
DEBUG 01-13 08:46:42.098804.098804 mlpmodule.py:785]  experts func einsum cost 0.06153702735900879 s
DEBUG 01-13 08:46:42.099710.099710 cuda_h.py:19] end iln_self_attn_paln cost 0.004540920257568359 seconds
DEBUG 01-13 08:46:42.099353.099353 cuda_h.py:19] end experts_func_gpu_einsum_mp cost 0.06264448165893555 seconds
DEBUG 01-13 08:46:42.099262.099262 cuda_h.py:10] start layer_moe_generate_mp_l_21
DEBUG 01-13 08:46:42.099594.099594 cuda_h.py:10] start gate
DEBUG 01-13 08:46:42.099113.099113 cuda_h.py:19] end gate cost 0.0006308555603027344 seconds
DEBUG 01-13 08:46:42.099174.099174 cuda_h.py:10] start experts_map_get
DEBUG 01-13 08:46:42.100078.100078 lmp.py:1611] 
DEBUG 01-13 08:46:42.100078.100078 lmp.py:1611] Expert Token Distribution & Device Allocation:
DEBUG 01-13 08:46:42.100780.100780 lmp.py:1612]   Total experts: 64
DEBUG 01-13 08:46:42.100808.100808 lmp.py:1613]   CPU experts: 32 (50%)
DEBUG 01-13 08:46:42.100974.100974 lmp.py:1614]   GPU experts: 32 (50%)
DEBUG 01-13 08:46:42.100232.100232 lmp.py:1615] 
DEBUG 01-13 08:46:42.100232.100232 lmp.py:1615]   Expert ID | Tokens | Device
DEBUG 01-13 08:46:42.100968.100968 lmp.py:1616]   -----------------------------------
DEBUG 01-13 08:46:42.100711.100711 lmp.py:1622]   Expert 54 |     25 | CPU
DEBUG 01-13 08:46:42.100446.100446 lmp.py:1622]   Expert  3 |     30 | CPU
DEBUG 01-13 08:46:42.100943.100943 lmp.py:1622]   Expert  8 |     40 | CPU
DEBUG 01-13 08:46:42.100951.100951 lmp.py:1622]   Expert 28 |     44 | CPU
DEBUG 01-13 08:46:42.100402.100402 lmp.py:1622]   Expert 43 |     44 | CPU
DEBUG 01-13 08:46:42.100138.100138 lmp.py:1622]   Expert 63 |     55 | CPU
DEBUG 01-13 08:46:42.100635.100635 lmp.py:1622]   Expert 36 |     71 | CPU
DEBUG 01-13 08:46:42.100609.100609 lmp.py:1622]   Expert 38 |     72 | CPU
DEBUG 01-13 08:46:42.100106.100106 lmp.py:1622]   Expert  6 |     81 | CPU
DEBUG 01-13 08:46:42.100842.100842 lmp.py:1622]   Expert 39 |     98 | CPU
DEBUG 01-13 08:46:42.100339.100339 lmp.py:1622]   Expert 41 |    103 | CPU
DEBUG 01-13 08:46:42.100075.100075 lmp.py:1622]   Expert 52 |    104 | CPU
DEBUG 01-13 08:46:42.100572.100572 lmp.py:1622]   Expert 57 |    104 | CPU
DEBUG 01-13 08:46:42.100930.100930 lmp.py:1622]   Expert 12 |    112 | CPU
DEBUG 01-13 08:46:42.100143.100143 lmp.py:1622]   Expert 19 |    127 | CPU
DEBUG 01-13 08:46:42.100594.100594 lmp.py:1622]   Expert 47 |    127 | CPU
DEBUG 01-13 08:46:42.100283.100283 lmp.py:1622]   Expert 13 |    128 | CPU
DEBUG 01-13 08:46:42.100972.100972 lmp.py:1622]   Expert 22 |    136 | CPU
DEBUG 01-13 08:46:42.100185.100185 lmp.py:1622]   Expert 46 |    151 | CPU
DEBUG 01-13 08:46:42.100636.100636 lmp.py:1622]   Expert 21 |    156 | CPU
DEBUG 01-13 08:46:42.100848.100848 lmp.py:1622]   Expert 50 |    157 | CPU
DEBUG 01-13 08:46:42.100584.100584 lmp.py:1622]   Expert 40 |    168 | CPU
DEBUG 01-13 08:46:42.100034.100034 lmp.py:1622]   Expert 24 |    172 | CPU
DEBUG 01-13 08:46:42.100485.100485 lmp.py:1622]   Expert 55 |    172 | CPU
DEBUG 01-13 08:46:42.100936.100936 lmp.py:1622]   Expert 20 |    173 | CPU
DEBUG 01-13 08:46:42.100387.100387 lmp.py:1622]   Expert 37 |    173 | CPU
DEBUG 01-13 08:46:42.100600.100600 lmp.py:1622]   Expert 53 |    173 | CPU
DEBUG 01-13 08:46:42.100050.100050 lmp.py:1622]   Expert 61 |    175 | CPU
DEBUG 01-13 08:46:42.100740.100740 lmp.py:1622]   Expert 33 |    177 | CPU
DEBUG 01-13 08:46:42.100952.100952 lmp.py:1622]   Expert 49 |    177 | CPU
DEBUG 01-13 08:46:42.100165.100165 lmp.py:1622]   Expert 23 |    178 | CPU
DEBUG 01-13 08:46:42.100583.100583 lmp.py:1622]   Expert 42 |    181 | CPU
DEBUG 01-13 08:46:42.100272.100272 lmp.py:1622]   Expert  2 |    182 | GPU
DEBUG 01-13 08:46:42.100769.100769 lmp.py:1622]   Expert 18 |    190 | GPU
DEBUG 01-13 08:46:42.100028.100028 lmp.py:1622]   Expert 16 |    195 | GPU
DEBUG 01-13 08:46:42.100764.100764 lmp.py:1622]   Expert 30 |    198 | GPU
DEBUG 01-13 08:46:42.100261.100261 lmp.py:1622]   Expert  0 |    199 | GPU
DEBUG 01-13 08:46:42.100997.100997 lmp.py:1622]   Expert 32 |    204 | GPU
DEBUG 01-13 08:46:42.100255.100255 lmp.py:1622]   Expert  5 |    207 | GPU
DEBUG 01-13 08:46:42.101991.101991 lmp.py:1622]   Expert  7 |    209 | GPU
DEBUG 01-13 08:46:42.101250.101250 lmp.py:1622]   Expert 14 |    212 | GPU
DEBUG 01-13 08:46:42.101985.101985 lmp.py:1622]   Expert 34 |    213 | GPU
DEBUG 01-13 08:46:42.101483.101483 lmp.py:1622]   Expert 31 |    214 | GPU
DEBUG 01-13 08:46:42.101980.101980 lmp.py:1622]   Expert  9 |    216 | GPU
DEBUG 01-13 08:46:42.101239.101239 lmp.py:1622]   Expert 59 |    219 | GPU
DEBUG 01-13 08:46:42.101974.101974 lmp.py:1622]   Expert 17 |    221 | GPU
DEBUG 01-13 08:46:42.101471.101471 lmp.py:1622]   Expert 62 |    221 | GPU
DEBUG 01-13 08:46:42.101207.101207 lmp.py:1622]   Expert 60 |    224 | GPU
DEBUG 01-13 08:46:42.101466.101466 lmp.py:1622]   Expert 29 |    226 | GPU
DEBUG 01-13 08:46:42.101201.101201 lmp.py:1622]   Expert 15 |    231 | GPU
DEBUG 01-13 08:46:42.101460.101460 lmp.py:1622]   Expert 10 |    232 | GPU
DEBUG 01-13 08:46:42.101719.101719 lmp.py:1622]   Expert 58 |    242 | GPU
DEBUG 01-13 08:46:42.101216.101216 lmp.py:1622]   Expert  4 |    243 | GPU
DEBUG 01-13 08:46:42.101713.101713 lmp.py:1622]   Expert 26 |    247 | GPU
DEBUG 01-13 08:46:42.101211.101211 lmp.py:1622]   Expert 51 |    248 | GPU
DEBUG 01-13 08:46:42.101469.101469 lmp.py:1622]   Expert 11 |    249 | GPU
DEBUG 01-13 08:46:42.101967.101967 lmp.py:1622]   Expert 44 |    268 | GPU
DEBUG 01-13 08:46:42.101225.101225 lmp.py:1622]   Expert 27 |    280 | GPU
DEBUG 01-13 08:46:42.101961.101961 lmp.py:1622]   Expert 56 |    285 | GPU
DEBUG 01-13 08:46:42.101220.101220 lmp.py:1622]   Expert  1 |    333 | GPU
DEBUG 01-13 08:46:42.101479.101479 lmp.py:1622]   Expert 45 |    362 | GPU
DEBUG 01-13 08:46:42.101976.101976 lmp.py:1622]   Expert 25 |    484 | GPU
DEBUG 01-13 08:46:42.101996.101996 lmp.py:1622]   Expert 35 |    514 | GPU
DEBUG 01-13 08:46:42.101493.101493 lmp.py:1622]   Expert 48 |    636 | GPU
DEBUG 01-13 08:46:42.101468.101468 lmp.py:1623] 
DEBUG 01-13 08:46:42.101468.101468 lmp.py:1623]   CPU total tokens: 3884 (31.6%)
DEBUG 01-13 08:46:42.101157.101157 lmp.py:1624]   GPU total tokens: 8404 (68.4%)
DEBUG 01-13 08:46:42.101138.101138 cuda_h.py:19] end experts_map_get cost 0.0014574527740478516 seconds
DEBUG 01-13 08:46:42.101934.101934 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-13 08:46:42.101829.101829 lmp.py:1632] 
DEBUG 01-13 08:46:42.101829.101829 lmp.py:1632]   Computing 32 experts on CPU MP...
DEBUG 01-13 08:46:42.101275.101275 cuda_h.py:19] end cpu_experts_submit cost 4.792213439941406e-05 seconds
DEBUG 01-13 08:46:42.101825.101825 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-13 08:46:42.101416.101416 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-13 08:46:42.101514.101514 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-13 08:46:42.103405.103405 cuda_h.py:19] end allocate_cuda_memory cost 0.0014677047729492188 seconds
DEBUG 01-13 08:46:42.103056.103056 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-13 08:46:42.103381.103381 sllm_store_c.py:27] get device uuid map
DEBUG 01-13 08:46:42.103475.103475 sllm_store_c.py:29] call client load into gpu
DEBUG 01-13 08:46:42.103125.103125 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 1b795ea0-b7cd-4203-aee5-d8f667aaca1a
DEBUG 01-13 08:46:42.103436.103436 client.py:106] call stub.LoadModelAsync
DEBUG 01-13 08:46:42.104381.104381 cuda_h.py:10] start experts_func_gpu_einsum_mp
INFO 01-13 08:46:42.105497.105497 client.py:127] Model loaded
DEBUG 01-13 08:46:42.105194.105194 cuda_h.py:10] start restore2model
DEBUG 01-13 08:46:42.105295.105295 cuda_h.py:19] end restore2model cost 0.00042247772216796875 seconds
DEBUG 01-13 08:46:42.105887.105887 cuda_h.py:19] end sllm_worker_task cost 0.010764598846435547 seconds
INFO 01-13 08:46:42.106110.106110 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 1b795ea0-b7cd-4203-aee5-d8f667aaca1a
DEBUG 01-13 08:46:42.106291.106291 cuda_h.py:19] end load_into_gpu_async cost 0.0032308101654052734 seconds
DEBUG 01-13 08:46:42.106947.106947 cuda_h.py:10] start restore_tensors2
DEBUG 01-13 08:46:42.107132.107132 cuda_h.py:19] end restore_tensors2 cost 0.00035452842712402344 seconds
DEBUG 01-13 08:46:42.107869.107869 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.005402326583862305 seconds
DEBUG 01-13 08:46:42.107301.107301 cuda_h.py:10] start restore2model
DEBUG 01-13 08:46:42.109630.109630 cuda_h.py:19] end restore2model cost 0.0026710033416748047 seconds
DEBUG 01-13 08:46:42.109367.109367 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.00824427604675293 seconds
DEBUG 01-13 08:46:42.109467.109467 cuda_h.py:10] start gpu_sexperts
DEBUG 01-13 08:46:42.110530.110530 cuda_h.py:19] end gpu_sexperts cost 0.0002617835998535156 seconds
DEBUG 01-13 08:46:42.110167.110167 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-13 08:46:42.110367.110367 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 1.430511474609375e-05 seconds
DEBUG 01-13 08:46:42.110110.110110 cuda_h.py:10] start wait_experts
INFO 01-13 08:46:42.110329.110329 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 1b795ea0-b7cd-4203-aee5-d8f667aaca1a
DEBUG 01-13 08:46:42.118502.118502 mlpmodule.py:1006] group tensors cost 0.012628316879272461 s
DEBUG 01-13 08:46:42.121878.121878 mlpmodule.py:1044] pad cost 0.003117084503173828 s
DEBUG 01-13 08:46:42.122588.122588 mlpmodule.py:1050] create cpu tensor cost 8.20159912109375e-05 s
DEBUG 01-13 08:46:42.122201.122201 mlpmodule.py:1055] move to cpu cost 4.696846008300781e-05 s
DEBUG 01-13 08:46:42.131126.131126 mlpmodule.py:1069] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-13 08:46:42.131379.131379 mlpmodule.py:1070] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-13 08:46:42.131933.131933 mlpmodule.py:1075] group_w3 first element: 0.0205078125
WARNING 01-13 08:46:42.132157.132157 mlpmodule.py:1085] start einsum2
DEBUG 01-13 08:46:42.145778.145778 mlpmodule.py:1095] group einsum cost 0.02286672592163086 s
DEBUG 01-13 08:46:42.146539.146539 mlpmodule.py:1103] cpy2cputensor cost 0.0007269382476806641 s
INFO 01-13 08:46:42.157051.157051 client.py:127] Model loaded
DEBUG 01-13 08:46:42.157368.157368 cuda_h.py:19] end wait_experts cost 0.047022104263305664 seconds
DEBUG 01-13 08:46:42.157369.157369 cuda_h.py:10] start gpu_experts
DEBUG 01-13 08:46:42.158530.158530 mlpmodule.py:559] gpu group tensors cost 0.0007467269897460938 s
DEBUG 01-13 08:46:42.160797.160797 mlpmodule.py:592] gpu pad cost 0.0017800331115722656 s
DEBUG 01-13 08:46:42.160892.160892 mlpmodule.py:598] start_w1
DEBUG 01-13 08:46:42.160994.160994 mlpmodule.py:602] start_w3
DEBUG 01-13 08:46:42.160259.160259 mlpmodule.py:608] start_w2
DEBUG 01-13 08:46:42.161443.161443 mlpmodule.py:611] gpu group einsum cost 0.0008261203765869141 s
DEBUG 01-13 08:46:42.163593.163593 mlpmodule.py:683] gpu experts func einsum cost 0.0057811737060546875 s
DEBUG 01-13 08:46:42.163569.163569 cuda_h.py:19] end gpu_experts cost 0.0059468746185302734 seconds
DEBUG 01-13 08:46:42.163703.163703 cuda_h.py:10] start cpu_thread_manager_mp_wait
DEBUG 01-13 08:46:42.163036.163036 cuda_h.py:19] end cpu_thread_manager_mp_wait cost 3.981590270996094e-05 seconds
DEBUG 01-13 08:46:42.163145.163145 cuda_h.py:19] end layer_moe_generate_mp_l_21 cost 0.06431365013122559 seconds
DEBUG 01-13 08:46:42.163848.163848 lmp.py:1550] -------------------------------- end prefill layer 20 --------------------------------
DEBUG 01-13 08:46:42.163372.163372 lmp.py:1493] -------------------------------- start prefill layer 21 --------------------------------
DEBUG 01-13 08:46:42.163453.163453 cuda_h.py:10] start start_load_qkvogn_s_weight_l_22
DEBUG 01-13 08:46:42.163109.163109 cuda_h.py:10] start start_load_qkvogn_s_weight_l_22
DEBUG 01-13 08:46:42.163138.163138 cuda_h.py:19] end start_load_qkvogn_s_weight_l_22 cost 3.0040740966796875e-05 seconds
DEBUG 01-13 08:46:42.163576.163576 cuda_h.py:19] end start_load_qkvogn_s_weight_l_22 cost 7.557868957519531e-05 seconds
DEBUG 01-13 08:46:42.163696.163696 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-13 08:46:42.164009.164009 cuda_h.py:10] start sllm_worker_task
DEBUG 01-13 08:46:42.164840.164840 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-13 08:46:42.164199.164199 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-13 08:46:42.164345.164345 cuda_h.py:19] end allocate_cuda_memory cost 0.0003495216369628906 seconds
DEBUG 01-13 08:46:42.164911.164911 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-13 08:46:42.164886.164886 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-13 08:46:42.164446.164446 sllm_store_c.py:27] get device uuid map
DEBUG 01-13 08:46:42.164699.164699 sllm_store_c.py:29] call client load into gpu
DEBUG 01-13 08:46:42.164594.164594 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 075f37ae-fd92-446e-a06a-3d25f610e389
DEBUG 01-13 08:46:42.164570.164570 client.py:106] call stub.LoadModelAsync
DEBUG 01-13 08:46:42.165515.165515 cuda_h.py:10] start self_attn
INFO 01-13 08:46:42.166050.166050 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 075f37ae-fd92-446e-a06a-3d25f610e389
DEBUG 01-13 08:46:42.166887.166887 cuda_h.py:19] end load_into_gpu_async cost 0.0016951560974121094 seconds
DEBUG 01-13 08:46:42.166728.166728 cuda_h.py:10] start restore_tensors2
DEBUG 01-13 08:46:42.166811.166811 cuda_h.py:19] end restore_tensors2 cost 7.081031799316406e-05 seconds
DEBUG 01-13 08:46:42.166375.166375 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0025043487548828125 seconds
INFO 01-13 08:46:42.166112.166112 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 075f37ae-fd92-446e-a06a-3d25f610e389
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-13 08:46:42.168479.168479 cuda_h.py:19] end self_attn cost 0.0028281211853027344 seconds
DEBUG 01-13 08:46:42.168390.168390 cuda_h.py:19] end iln_self_attn_paln cost 0.004486083984375 seconds
DEBUG 01-13 08:46:42.168564.168564 cuda_h.py:10] start layer_moe_generate_mp_l_22
DEBUG 01-13 08:46:42.168705.168705 cuda_h.py:10] start gate
DEBUG 01-13 08:46:42.169747.169747 cuda_h.py:19] end gate cost 0.0006301403045654297 seconds
DEBUG 01-13 08:46:42.169192.169192 cuda_h.py:10] start experts_map_get
DEBUG 01-13 08:46:42.169169.169169 lmp.py:1611] 
DEBUG 01-13 08:46:42.169169.169169 lmp.py:1611] Expert Token Distribution & Device Allocation:
DEBUG 01-13 08:46:42.169733.169733 lmp.py:1612]   Total experts: 64
DEBUG 01-13 08:46:42.169396.169396 lmp.py:1613]   CPU experts: 32 (50%)
DEBUG 01-13 08:46:42.169470.169470 lmp.py:1614]   GPU experts: 32 (50%)
DEBUG 01-13 08:46:42.169920.169920 lmp.py:1615] 
DEBUG 01-13 08:46:42.169920.169920 lmp.py:1615]   Expert ID | Tokens | Device
DEBUG 01-13 08:46:42.169610.169610 lmp.py:1616]   -----------------------------------
DEBUG 01-13 08:46:42.169259.169259 lmp.py:1622]   Expert  9 |     30 | CPU
DEBUG 01-13 08:46:42.169949.169949 lmp.py:1622]   Expert 44 |     30 | CPU
DEBUG 01-13 08:46:42.169923.169923 lmp.py:1622]   Expert 11 |     36 | CPU
DEBUG 01-13 08:46:42.169897.169897 lmp.py:1622]   Expert 56 |     51 | CPU
DEBUG 01-13 08:46:42.169871.169871 lmp.py:1622]   Expert 54 |     76 | CPU
DEBUG 01-13 08:46:42.169130.169130 lmp.py:1622]   Expert  7 |     81 | CPU
DEBUG 01-13 08:46:42.169104.169104 lmp.py:1622]   Expert 62 |     92 | CPU
DEBUG 01-13 08:46:42.169078.169078 lmp.py:1622]   Expert 47 |     98 | CPU
DEBUG 01-13 08:46:42.169529.169529 lmp.py:1622]   Expert 60 |     98 | CPU
DEBUG 01-13 08:46:42.169980.169980 lmp.py:1622]   Expert 51 |    106 | CPU
DEBUG 01-13 08:46:42.169192.169192 lmp.py:1622]   Expert 52 |    109 | CPU
DEBUG 01-13 08:46:42.169166.169166 lmp.py:1622]   Expert 41 |    110 | CPU
DEBUG 01-13 08:46:42.169902.169902 lmp.py:1622]   Expert 53 |    116 | CPU
DEBUG 01-13 08:46:42.169160.169160 lmp.py:1622]   Expert 22 |    119 | CPU
DEBUG 01-13 08:46:42.169181.169181 lmp.py:1622]   Expert 32 |    122 | CPU
DEBUG 01-13 08:46:42.169678.169678 lmp.py:1622]   Expert  6 |    123 | CPU
DEBUG 01-13 08:46:42.170698.170698 lmp.py:1622]   Expert  8 |    124 | CPU
DEBUG 01-13 08:46:42.170957.170957 lmp.py:1622]   Expert 48 |    126 | CPU
DEBUG 01-13 08:46:42.170885.170885 lmp.py:1622]   Expert  1 |    133 | CPU
DEBUG 01-13 08:46:42.170574.170574 lmp.py:1622]   Expert 27 |    136 | CPU
DEBUG 01-13 08:46:42.170787.170787 lmp.py:1622]   Expert  2 |    138 | CPU
DEBUG 01-13 08:46:42.170238.170238 lmp.py:1622]   Expert 59 |    139 | CPU
DEBUG 01-13 08:46:42.170404.170404 lmp.py:1622]   Expert 23 |    141 | CPU
DEBUG 01-13 08:46:42.170331.170331 lmp.py:1622]   Expert 39 |    143 | CPU
DEBUG 01-13 08:46:42.170259.170259 lmp.py:1622]   Expert 26 |    145 | CPU
DEBUG 01-13 08:46:42.170187.170187 lmp.py:1622]   Expert 35 |    145 | CPU
DEBUG 01-13 08:46:42.170638.170638 lmp.py:1622]   Expert 50 |    150 | CPU
DEBUG 01-13 08:46:42.170373.170373 lmp.py:1622]   Expert 14 |    156 | CPU
DEBUG 01-13 08:46:42.170586.170586 lmp.py:1622]   Expert 24 |    165 | CPU
DEBUG 01-13 08:46:42.170560.170560 lmp.py:1622]   Expert 38 |    169 | CPU
DEBUG 01-13 08:46:42.170772.170772 lmp.py:1622]   Expert 46 |    171 | CPU
DEBUG 01-13 08:46:42.170985.170985 lmp.py:1622]   Expert 49 |    171 | CPU
DEBUG 01-13 08:46:42.170436.170436 lmp.py:1622]   Expert 34 |    172 | GPU
DEBUG 01-13 08:46:42.170648.170648 lmp.py:1622]   Expert  0 |    173 | GPU
DEBUG 01-13 08:46:42.170337.170337 lmp.py:1622]   Expert  4 |    176 | GPU
DEBUG 01-13 08:46:42.170265.170265 lmp.py:1622]   Expert 63 |    185 | GPU
DEBUG 01-13 08:46:42.170193.170193 lmp.py:1622]   Expert  5 |    186 | GPU
DEBUG 01-13 08:46:42.170121.170121 lmp.py:1622]   Expert 40 |    189 | GPU
DEBUG 01-13 08:46:42.170048.170048 lmp.py:1622]   Expert 19 |    192 | GPU
DEBUG 01-13 08:46:42.170499.170499 lmp.py:1622]   Expert 29 |    197 | GPU
DEBUG 01-13 08:46:42.170950.170950 lmp.py:1622]   Expert 13 |    206 | GPU
DEBUG 01-13 08:46:42.170163.170163 lmp.py:1622]   Expert 57 |    207 | GPU
DEBUG 01-13 08:46:42.170375.170375 lmp.py:1622]   Expert 43 |    211 | GPU
DEBUG 01-13 08:46:42.170587.170587 lmp.py:1622]   Expert 33 |    225 | GPU
DEBUG 01-13 08:46:42.170562.170562 lmp.py:1622]   Expert 61 |    227 | GPU
DEBUG 01-13 08:46:42.170536.170536 lmp.py:1622]   Expert 31 |    242 | GPU
DEBUG 01-13 08:46:42.170986.170986 lmp.py:1622]   Expert 37 |    246 | GPU
DEBUG 01-13 08:46:42.170960.170960 lmp.py:1622]   Expert 16 |    249 | GPU
DEBUG 01-13 08:46:42.170696.170696 lmp.py:1622]   Expert 15 |    252 | GPU
DEBUG 01-13 08:46:42.170385.170385 lmp.py:1622]   Expert 20 |    256 | GPU
DEBUG 01-13 08:46:42.170552.170552 lmp.py:1622]   Expert  3 |    258 | GPU
DEBUG 01-13 08:46:42.170241.170241 lmp.py:1622]   Expert 36 |    269 | GPU
DEBUG 01-13 08:46:42.170169.170169 lmp.py:1622]   Expert 12 |    274 | GPU
DEBUG 01-13 08:46:42.170858.170858 lmp.py:1622]   Expert 18 |    278 | GPU
DEBUG 01-13 08:46:42.170309.170309 lmp.py:1622]   Expert 28 |    298 | GPU
DEBUG 01-13 08:46:42.170521.170521 lmp.py:1622]   Expert 17 |    299 | GPU
DEBUG 01-13 08:46:42.170972.170972 lmp.py:1622]   Expert 55 |    304 | GPU
DEBUG 01-13 08:46:42.170946.170946 lmp.py:1622]   Expert 25 |    311 | GPU
DEBUG 01-13 08:46:42.170159.170159 lmp.py:1622]   Expert 30 |    329 | GPU
DEBUG 01-13 08:46:42.170133.170133 lmp.py:1622]   Expert 58 |    341 | GPU
DEBUG 01-13 08:46:42.170584.170584 lmp.py:1622]   Expert 10 |    365 | GPU
DEBUG 01-13 08:46:42.170558.170558 lmp.py:1622]   Expert 45 |    383 | GPU
DEBUG 01-13 08:46:42.170770.170770 lmp.py:1622]   Expert 21 |    389 | GPU
DEBUG 01-13 08:46:42.170221.170221 lmp.py:1622]   Expert 42 |    650 | GPU
DEBUG 01-13 08:46:42.170864.170864 lmp.py:1623] 
DEBUG 01-13 08:46:42.170864.170864 lmp.py:1623]   CPU total tokens: 3749 (30.5%)
DEBUG 01-13 08:46:42.170222.170222 lmp.py:1624]   GPU total tokens: 8539 (69.5%)
DEBUG 01-13 08:46:42.170395.170395 cuda_h.py:19] end experts_map_get cost 0.0014913082122802734 seconds
DEBUG 01-13 08:46:42.170384.170384 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-13 08:46:42.170756.170756 lmp.py:1632] 
DEBUG 01-13 08:46:42.170756.170756 lmp.py:1632]   Computing 32 experts on CPU MP...
DEBUG 01-13 08:46:42.170916.170916 cuda_h.py:19] end cpu_experts_submit cost 4.839897155761719e-05 seconds
DEBUG 01-13 08:46:42.170136.170136 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-13 08:46:42.171203.171203 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-13 08:46:42.171560.171560 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-13 08:46:42.171474.171474 mlpmodule.py:785]  experts func einsum cost 0.0656132698059082 s
DEBUG 01-13 08:46:42.172286.172286 cuda_h.py:19] end experts_func_gpu_einsum_mp cost 0.06703925132751465 seconds
DEBUG 01-13 08:46:42.172348.172348 cuda_h.py:19] end allocate_cuda_memory cost 0.0012578964233398438 seconds
DEBUG 01-13 08:46:42.172954.172954 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-13 08:46:42.172571.172571 sllm_store_c.py:27] get device uuid map
DEBUG 01-13 08:46:42.172096.172096 sllm_store_c.py:29] call client load into gpu
DEBUG 01-13 08:46:42.172461.172461 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 757af879-a5fa-43fa-b1cb-aabf38162a0f
DEBUG 01-13 08:46:42.173112.173112 cuda_h.py:10] start experts_func_gpu_einsum_mp
DEBUG 01-13 08:46:42.173964.173964 client.py:106] call stub.LoadModelAsync
INFO 01-13 08:46:42.174204.174204 client.py:127] Model loaded
DEBUG 01-13 08:46:42.174981.174981 cuda_h.py:10] start restore2model
DEBUG 01-13 08:46:42.175641.175641 cuda_h.py:19] end restore2model cost 0.0003173351287841797 seconds
DEBUG 01-13 08:46:42.175596.175596 cuda_h.py:19] end sllm_worker_task cost 0.010926008224487305 seconds
INFO 01-13 08:46:42.176206.176206 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 757af879-a5fa-43fa-b1cb-aabf38162a0f
DEBUG 01-13 08:46:42.176334.176334 cuda_h.py:19] end load_into_gpu_async cost 0.003194093704223633 seconds
DEBUG 01-13 08:46:42.176752.176752 cuda_h.py:10] start restore_tensors2
DEBUG 01-13 08:46:42.176857.176857 cuda_h.py:19] end restore_tensors2 cost 0.0003311634063720703 seconds
DEBUG 01-13 08:46:42.176640.176640 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0054950714111328125 seconds
DEBUG 01-13 08:46:42.176403.176403 cuda_h.py:10] start restore2model
DEBUG 01-13 08:46:42.179084.179084 cuda_h.py:19] end restore2model cost 0.0025107860565185547 seconds
DEBUG 01-13 08:46:42.179682.179682 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.008176803588867188 seconds
DEBUG 01-13 08:46:42.179093.179093 cuda_h.py:10] start gpu_sexperts
DEBUG 01-13 08:46:42.179619.179619 cuda_h.py:19] end gpu_sexperts cost 0.00025463104248046875 seconds
DEBUG 01-13 08:46:42.179157.179157 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-13 08:46:42.179211.179211 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 1.3828277587890625e-05 seconds
DEBUG 01-13 08:46:42.179238.179238 cuda_h.py:10] start wait_experts
INFO 01-13 08:46:42.179504.179504 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 757af879-a5fa-43fa-b1cb-aabf38162a0f
DEBUG 01-13 08:46:42.181583.181583 mlpmodule.py:1006] group tensors cost 0.008122682571411133 s
DEBUG 01-13 08:46:42.184226.184226 mlpmodule.py:1044] pad cost 0.0020751953125 s
DEBUG 01-13 08:46:42.184475.184475 mlpmodule.py:1050] create cpu tensor cost 5.3882598876953125e-05 s
DEBUG 01-13 08:46:42.184908.184908 mlpmodule.py:1055] move to cpu cost 3.6716461181640625e-05 s
DEBUG 01-13 08:46:42.193800.193800 mlpmodule.py:1069] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-13 08:46:42.193013.193013 mlpmodule.py:1070] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-13 08:46:42.193329.193329 mlpmodule.py:1075] group_w3 first element: 0.00066375732421875
WARNING 01-13 08:46:42.193083.193083 mlpmodule.py:1085] start einsum2
DEBUG 01-13 08:46:42.205162.205162 mlpmodule.py:1095] group einsum cost 0.02095508575439453 s
DEBUG 01-13 08:46:42.206406.206406 mlpmodule.py:1103] cpy2cputensor cost 0.0007121562957763672 s
INFO 01-13 08:46:42.226177.226177 client.py:127] Model loaded
DEBUG 01-13 08:46:42.226082.226082 cuda_h.py:19] end wait_experts cost 0.046720266342163086 seconds
DEBUG 01-13 08:46:42.226600.226600 cuda_h.py:10] start gpu_experts
DEBUG 01-13 08:46:42.227616.227616 mlpmodule.py:559] gpu group tensors cost 0.0005841255187988281 s
DEBUG 01-13 08:46:42.228356.228356 mlpmodule.py:785]  experts func einsum cost 0.05414223670959473 s
DEBUG 01-13 08:46:42.228353.228353 cuda_h.py:19] end experts_func_gpu_einsum_mp cost 0.05541086196899414 seconds
DEBUG 01-13 08:46:42.228150.228150 mlpmodule.py:592] gpu pad cost 0.0014510154724121094 s
DEBUG 01-13 08:46:42.228099.228099 mlpmodule.py:598] start_w1
DEBUG 01-13 08:46:42.228846.228846 mlpmodule.py:602] start_w3
DEBUG 01-13 08:46:42.229030.229030 mlpmodule.py:608] start_w2
DEBUG 01-13 08:46:42.229857.229857 mlpmodule.py:611] gpu group einsum cost 0.0006630420684814453 s
DEBUG 01-13 08:46:42.231931.231931 mlpmodule.py:683] gpu experts func einsum cost 0.005068540573120117 s
DEBUG 01-13 08:46:42.231616.231616 cuda_h.py:19] end gpu_experts cost 0.005219936370849609 seconds
DEBUG 01-13 08:46:42.231896.231896 cuda_h.py:10] start cpu_thread_manager_mp_wait
DEBUG 01-13 08:46:42.231083.231083 cuda_h.py:19] end cpu_thread_manager_mp_wait cost 3.8623809814453125e-05 seconds
DEBUG 01-13 08:46:42.231053.231053 cuda_h.py:19] end layer_moe_generate_mp_l_22 cost 0.06321573257446289 seconds
DEBUG 01-13 08:46:42.232909.232909 lmp.py:1550] -------------------------------- end prefill layer 21 --------------------------------
DEBUG 01-13 08:46:42.232347.232347 lmp.py:1493] -------------------------------- start prefill layer 22 --------------------------------
DEBUG 01-13 08:46:42.232858.232858 cuda_h.py:10] start start_load_qkvogn_s_weight_l_23
DEBUG 01-13 08:46:42.232945.232945 cuda_h.py:10] start start_load_qkvogn_s_weight_l_23
DEBUG 01-13 08:46:42.232404.232404 cuda_h.py:19] end start_load_qkvogn_s_weight_l_23 cost 3.147125244140625e-05 seconds
DEBUG 01-13 08:46:42.232213.232213 cuda_h.py:19] end start_load_qkvogn_s_weight_l_23 cost 5.984306335449219e-05 seconds
DEBUG 01-13 08:46:42.232525.232525 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-13 08:46:42.232124.232124 cuda_h.py:10] start sllm_worker_task
DEBUG 01-13 08:46:42.232085.232085 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-13 08:46:42.232617.232617 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-13 08:46:42.232645.232645 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-13 08:46:42.233586.233586 cuda_h.py:19] end allocate_cuda_memory cost 0.0005068778991699219 seconds
DEBUG 01-13 08:46:42.233043.233043 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-13 08:46:42.233338.233338 sllm_store_c.py:27] get device uuid map
DEBUG 01-13 08:46:42.233131.233131 sllm_store_c.py:29] call client load into gpu
DEBUG 01-13 08:46:42.234862.234862 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, ecefeafd-6005-4254-9664-49b06a3ab7db
DEBUG 01-13 08:46:42.234988.234988 client.py:106] call stub.LoadModelAsync
DEBUG 01-13 08:46:42.234254.234254 cuda_h.py:10] start self_attn
INFO 01-13 08:46:42.235080.235080 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, ecefeafd-6005-4254-9664-49b06a3ab7db
DEBUG 01-13 08:46:42.236760.236760 cuda_h.py:19] end load_into_gpu_async cost 0.002309560775756836 seconds
DEBUG 01-13 08:46:42.236836.236836 cuda_h.py:10] start restore_tensors2
DEBUG 01-13 08:46:42.236898.236898 cuda_h.py:19] end restore_tensors2 cost 0.00016117095947265625 seconds
DEBUG 01-13 08:46:42.236001.236001 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0037469863891601562 seconds
INFO 01-13 08:46:42.236065.236065 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, ecefeafd-6005-4254-9664-49b06a3ab7db
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-13 08:46:42.237775.237775 cuda_h.py:19] end self_attn cost 0.0034389495849609375 seconds
DEBUG 01-13 08:46:42.238130.238130 cuda_h.py:19] end iln_self_attn_paln cost 0.0059659481048583984 seconds
DEBUG 01-13 08:46:42.238304.238304 cuda_h.py:10] start layer_moe_generate_mp_l_23
DEBUG 01-13 08:46:42.238113.238113 cuda_h.py:10] start gate
DEBUG 01-13 08:46:42.239784.239784 cuda_h.py:19] end gate cost 0.0006368160247802734 seconds
DEBUG 01-13 08:46:42.239660.239660 cuda_h.py:10] start experts_map_get
DEBUG 01-13 08:46:42.239829.239829 lmp.py:1611] 
DEBUG 01-13 08:46:42.239829.239829 lmp.py:1611] Expert Token Distribution & Device Allocation:
DEBUG 01-13 08:46:42.239731.239731 lmp.py:1612]   Total experts: 64
DEBUG 01-13 08:46:42.239871.239871 lmp.py:1613]   CPU experts: 32 (50%)
DEBUG 01-13 08:46:42.239614.239614 lmp.py:1614]   GPU experts: 32 (50%)
DEBUG 01-13 08:46:42.239257.239257 lmp.py:1615] 
DEBUG 01-13 08:46:42.239257.239257 lmp.py:1615]   Expert ID | Tokens | Device
DEBUG 01-13 08:46:42.239138.239138 lmp.py:1616]   -----------------------------------
DEBUG 01-13 08:46:42.239503.239503 lmp.py:1622]   Expert 25 |     14 | CPU
DEBUG 01-13 08:46:42.239384.239384 lmp.py:1622]   Expert 48 |     35 | CPU
DEBUG 01-13 08:46:42.239789.239789 lmp.py:1622]   Expert 45 |     38 | CPU
DEBUG 01-13 08:46:42.239432.239432 lmp.py:1622]   Expert  9 |     55 | CPU
DEBUG 01-13 08:46:42.239360.239360 lmp.py:1622]   Expert 43 |     76 | CPU
DEBUG 01-13 08:46:42.239764.239764 lmp.py:1622]   Expert 20 |     77 | CPU
DEBUG 01-13 08:46:42.239169.239169 lmp.py:1622]   Expert 54 |     81 | CPU
DEBUG 01-13 08:46:42.239573.239573 lmp.py:1622]   Expert  0 |     82 | CPU
DEBUG 01-13 08:46:42.239297.239297 lmp.py:1622]   Expert 47 |     82 | CPU
DEBUG 01-13 08:46:42.239893.239893 lmp.py:1622]   Expert 57 |     84 | CPU
DEBUG 01-13 08:46:42.239629.239629 lmp.py:1622]   Expert  6 |     93 | CPU
DEBUG 01-13 08:46:42.239364.239364 lmp.py:1622]   Expert 36 |    102 | CPU
DEBUG 01-13 08:46:42.239623.239623 lmp.py:1622]   Expert 46 |    103 | CPU
DEBUG 01-13 08:46:42.239597.239597 lmp.py:1622]   Expert 61 |    103 | CPU
DEBUG 01-13 08:46:42.239094.239094 lmp.py:1622]   Expert 13 |    104 | CPU
DEBUG 01-13 08:46:42.239069.239069 lmp.py:1622]   Expert 62 |    105 | CPU
DEBUG 01-13 08:46:42.239566.239566 lmp.py:1622]   Expert 38 |    110 | CPU
DEBUG 01-13 08:46:42.239063.239063 lmp.py:1622]   Expert 15 |    111 | CPU
DEBUG 01-13 08:46:42.239322.239322 lmp.py:1622]   Expert 50 |    111 | CPU
DEBUG 01-13 08:46:42.239057.239057 lmp.py:1622]   Expert  1 |    112 | CPU
DEBUG 01-13 08:46:42.239555.239555 lmp.py:1622]   Expert 37 |    113 | CPU
DEBUG 01-13 08:46:42.239290.239290 lmp.py:1622]   Expert 14 |    116 | CPU
DEBUG 01-13 08:46:42.239549.239549 lmp.py:1622]   Expert 21 |    139 | CPU
DEBUG 01-13 08:46:42.239285.239285 lmp.py:1622]   Expert  7 |    140 | CPU
DEBUG 01-13 08:46:42.239782.239782 lmp.py:1622]   Expert 28 |    141 | CPU
DEBUG 01-13 08:46:42.239710.239710 lmp.py:1622]   Expert 52 |    143 | CPU
DEBUG 01-13 08:46:42.239445.239445 lmp.py:1622]   Expert 44 |    151 | CPU
DEBUG 01-13 08:46:42.239134.239134 lmp.py:1622]   Expert 42 |    152 | CPU
DEBUG 01-13 08:46:42.240108.240108 lmp.py:1622]   Expert 24 |    156 | CPU
DEBUG 01-13 08:46:42.240367.240367 lmp.py:1622]   Expert 10 |    157 | CPU
DEBUG 01-13 08:46:42.240864.240864 lmp.py:1622]   Expert 11 |    158 | CPU
DEBUG 01-13 08:46:42.240123.240123 lmp.py:1622]   Expert 26 |    162 | CPU
DEBUG 01-13 08:46:42.240859.240859 lmp.py:1622]   Expert 35 |    167 | GPU
DEBUG 01-13 08:46:42.240356.240356 lmp.py:1622]   Expert  2 |    172 | GPU
DEBUG 01-13 08:46:42.240376.240376 lmp.py:1622]   Expert 31 |    176 | GPU
DEBUG 01-13 08:46:42.240112.240112 lmp.py:1622]   Expert  3 |    179 | GPU
DEBUG 01-13 08:46:42.240132.240132 lmp.py:1622]   Expert 32 |    181 | GPU
DEBUG 01-13 08:46:42.240868.240868 lmp.py:1622]   Expert 19 |    189 | GPU
DEBUG 01-13 08:46:42.240557.240557 lmp.py:1622]   Expert 12 |    196 | GPU
DEBUG 01-13 08:46:42.240247.240247 lmp.py:1622]   Expert 60 |    206 | GPU
DEBUG 01-13 08:46:42.240320.240320 lmp.py:1622]   Expert 40 |    208 | GPU
DEBUG 01-13 08:46:42.240579.240579 lmp.py:1622]   Expert 56 |    213 | GPU
DEBUG 01-13 08:46:42.240315.240315 lmp.py:1622]   Expert 41 |    215 | GPU
DEBUG 01-13 08:46:42.240812.240812 lmp.py:1622]   Expert 53 |    225 | GPU
DEBUG 01-13 08:46:42.240547.240547 lmp.py:1622]   Expert 58 |    231 | GPU
DEBUG 01-13 08:46:42.240568.240568 lmp.py:1622]   Expert 16 |    232 | GPU
DEBUG 01-13 08:46:42.240065.240065 lmp.py:1622]   Expert 51 |    232 | GPU
DEBUG 01-13 08:46:42.240324.240324 lmp.py:1622]   Expert 23 |    237 | GPU
DEBUG 01-13 08:46:42.240344.240344 lmp.py:1622]   Expert  8 |    241 | GPU
DEBUG 01-13 08:46:42.240603.240603 lmp.py:1622]   Expert 59 |    248 | GPU
DEBUG 01-13 08:46:42.240100.240100 lmp.py:1622]   Expert  4 |    250 | GPU
DEBUG 01-13 08:46:42.240836.240836 lmp.py:1622]   Expert 55 |    268 | GPU
DEBUG 01-13 08:46:42.240764.240764 lmp.py:1622]   Expert 49 |    275 | GPU
DEBUG 01-13 08:46:42.240367.240367 lmp.py:1622]   Expert 18 |    282 | GPU
DEBUG 01-13 08:46:42.240864.240864 lmp.py:1622]   Expert 29 |    282 | GPU
DEBUG 01-13 08:46:42.240123.240123 lmp.py:1622]   Expert 34 |    286 | GPU
DEBUG 01-13 08:46:42.240859.240859 lmp.py:1622]   Expert 63 |    293 | GPU
DEBUG 01-13 08:46:42.240117.240117 lmp.py:1622]   Expert 27 |    358 | GPU
DEBUG 01-13 08:46:42.240376.240376 lmp.py:1622]   Expert 39 |    369 | GPU
DEBUG 01-13 08:46:42.240635.240635 lmp.py:1622]   Expert 17 |    399 | GPU
DEBUG 01-13 08:46:42.240655.240655 lmp.py:1622]   Expert 22 |    433 | GPU
DEBUG 01-13 08:46:42.240153.240153 lmp.py:1622]   Expert 30 |    448 | GPU
DEBUG 01-13 08:46:42.240173.240173 lmp.py:1622]   Expert 33 |    474 | GPU
DEBUG 01-13 08:46:42.240670.240670 lmp.py:1622]   Expert  5 |    717 | GPU
DEBUG 01-13 08:46:42.240883.240883 lmp.py:1623] 
DEBUG 01-13 08:46:42.240883.240883 lmp.py:1623]   CPU total tokens: 3406 (27.7%)
DEBUG 01-13 08:46:42.240572.240572 lmp.py:1624]   GPU total tokens: 8882 (72.3%)
DEBUG 01-13 08:46:42.240553.240553 cuda_h.py:19] end experts_map_get cost 0.0015070438385009766 seconds
DEBUG 01-13 08:46:42.240157.240157 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-13 08:46:42.240675.240675 lmp.py:1632] 
DEBUG 01-13 08:46:42.240675.240675 lmp.py:1632]   Computing 32 experts on CPU MP...
DEBUG 01-13 08:46:42.240266.240266 cuda_h.py:19] end cpu_experts_submit cost 5.0067901611328125e-05 seconds
DEBUG 01-13 08:46:42.240936.240936 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-13 08:46:42.240196.240196 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-13 08:46:42.240187.240187 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-13 08:46:42.242390.242390 cuda_h.py:19] end allocate_cuda_memory cost 0.0012743473052978516 seconds
DEBUG 01-13 08:46:42.242472.242472 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-13 08:46:42.242320.242320 sllm_store_c.py:27] get device uuid map
DEBUG 01-13 08:46:42.243670.243670 sllm_store_c.py:29] call client load into gpu
DEBUG 01-13 08:46:42.243949.243949 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, e2926e02-e635-41a9-af31-d365475d597e
DEBUG 01-13 08:46:42.243697.243697 client.py:106] call stub.LoadModelAsync
DEBUG 01-13 08:46:42.243297.243297 cuda_h.py:10] start experts_func_gpu_einsum_mp
INFO 01-13 08:46:42.244704.244704 client.py:127] Model loaded
DEBUG 01-13 08:46:42.244429.244429 cuda_h.py:10] start restore2model
DEBUG 01-13 08:46:42.245941.245941 cuda_h.py:19] end restore2model cost 0.0009553432464599609 seconds
DEBUG 01-13 08:46:42.245667.245667 cuda_h.py:19] end sllm_worker_task cost 0.012765645980834961 seconds
INFO 01-13 08:46:42.245073.245073 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, e2926e02-e635-41a9-af31-d365475d597e
DEBUG 01-13 08:46:42.245161.245161 cuda_h.py:19] end load_into_gpu_async cost 0.0033550262451171875 seconds
DEBUG 01-13 08:46:42.245102.245102 cuda_h.py:10] start restore_tensors2
DEBUG 01-13 08:46:42.246823.246823 cuda_h.py:19] end restore_tensors2 cost 0.0003306865692138672 seconds
DEBUG 01-13 08:46:42.246659.246659 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.00529789924621582 seconds
DEBUG 01-13 08:46:42.246091.246091 cuda_h.py:10] start restore2model
DEBUG 01-13 08:46:42.248731.248731 cuda_h.py:19] end restore2model cost 0.0026543140411376953 seconds
DEBUG 01-13 08:46:42.248798.248798 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.008126974105834961 seconds
DEBUG 01-13 08:46:42.248640.248640 cuda_h.py:10] start gpu_sexperts
DEBUG 01-13 08:46:42.249749.249749 cuda_h.py:19] end gpu_sexperts cost 0.00026154518127441406 seconds
DEBUG 01-13 08:46:42.249195.249195 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-13 08:46:42.249156.249156 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 1.4066696166992188e-05 seconds
DEBUG 01-13 08:46:42.249137.249137 cuda_h.py:10] start wait_experts
INFO 01-13 08:46:42.249787.249787 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, e2926e02-e635-41a9-af31-d365475d597e
DEBUG 01-13 08:46:42.254787.254787 mlpmodule.py:1006] group tensors cost 0.009836196899414062 s
DEBUG 01-13 08:46:42.256212.256212 mlpmodule.py:1044] pad cost 0.0016372203826904297 s
DEBUG 01-13 08:46:42.256494.256494 mlpmodule.py:1050] create cpu tensor cost 4.57763671875e-05 s
DEBUG 01-13 08:46:42.256589.256589 mlpmodule.py:1055] move to cpu cost 3.4809112548828125e-05 s
DEBUG 01-13 08:46:42.266832.266832 mlpmodule.py:1069] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-13 08:46:42.266450.266450 mlpmodule.py:1070] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-13 08:46:42.266965.266965 mlpmodule.py:1075] group_w3 first element: -0.018798828125
WARNING 01-13 08:46:42.266595.266595 mlpmodule.py:1085] start einsum2
DEBUG 01-13 08:46:42.280059.280059 mlpmodule.py:1095] group einsum cost 0.023844003677368164 s
DEBUG 01-13 08:46:42.281051.281051 mlpmodule.py:1103] cpy2cputensor cost 0.0006780624389648438 s
DEBUG 01-13 08:46:42.295952.295952 mlpmodule.py:785]  experts func einsum cost 0.0507814884185791 s
DEBUG 01-13 08:46:42.295477.295477 cuda_h.py:19] end experts_func_gpu_einsum_mp cost 0.05152583122253418 seconds
INFO 01-13 08:46:42.297871.297871 client.py:127] Model loaded
DEBUG 01-13 08:46:42.298015.298015 cuda_h.py:19] end wait_experts cost 0.04870915412902832 seconds
DEBUG 01-13 08:46:42.298969.298969 cuda_h.py:10] start gpu_experts
DEBUG 01-13 08:46:42.298767.298767 mlpmodule.py:559] gpu group tensors cost 0.0005984306335449219 s
DEBUG 01-13 08:46:42.300675.300675 mlpmodule.py:592] gpu pad cost 0.0015118122100830078 s
DEBUG 01-13 08:46:42.300174.300174 mlpmodule.py:598] start_w1
DEBUG 01-13 08:46:42.300603.300603 mlpmodule.py:602] start_w3
DEBUG 01-13 08:46:42.301450.301450 mlpmodule.py:608] start_w2
DEBUG 01-13 08:46:42.301800.301800 mlpmodule.py:611] gpu group einsum cost 0.0006706714630126953 s
DEBUG 01-13 08:46:42.303599.303599 mlpmodule.py:683] gpu experts func einsum cost 0.005077838897705078 s
DEBUG 01-13 08:46:42.303430.303430 cuda_h.py:19] end gpu_experts cost 0.005231618881225586 seconds
DEBUG 01-13 08:46:42.303901.303901 cuda_h.py:10] start cpu_thread_manager_mp_wait
DEBUG 01-13 08:46:42.303990.303990 cuda_h.py:19] end cpu_thread_manager_mp_wait cost 3.814697265625e-05 seconds
DEBUG 01-13 08:46:42.303522.303522 cuda_h.py:19] end layer_moe_generate_mp_l_23 cost 0.06522798538208008 seconds
DEBUG 01-13 08:46:42.303967.303967 lmp.py:1550] -------------------------------- end prefill layer 22 --------------------------------
DEBUG 01-13 08:46:42.303928.303928 lmp.py:1493] -------------------------------- start prefill layer 23 --------------------------------
DEBUG 01-13 08:46:42.303532.303532 cuda_h.py:10] start start_load_qkvogn_s_weight_l_24
DEBUG 01-13 08:46:42.303996.303996 cuda_h.py:10] start start_load_qkvogn_s_weight_l_24
DEBUG 01-13 08:46:42.303925.303925 cuda_h.py:19] end start_load_qkvogn_s_weight_l_24 cost 3.0040740966796875e-05 seconds
DEBUG 01-13 08:46:42.303456.303456 cuda_h.py:19] end start_load_qkvogn_s_weight_l_24 cost 7.390975952148438e-05 seconds
DEBUG 01-13 08:46:42.304338.304338 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-13 08:46:42.304194.304194 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-13 08:46:42.304727.304727 cuda_h.py:10] start sllm_worker_task
DEBUG 01-13 08:46:42.304432.304432 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-13 08:46:42.304388.304388 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-13 08:46:42.304388.304388 cuda_h.py:19] end allocate_cuda_memory cost 0.00034809112548828125 seconds
DEBUG 01-13 08:46:42.304397.304397 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-13 08:46:42.304444.304444 sllm_store_c.py:27] get device uuid map
DEBUG 01-13 08:46:42.304267.304267 sllm_store_c.py:29] call client load into gpu
DEBUG 01-13 08:46:42.304778.304778 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, f1b152fc-86c2-4cc1-92de-500b649f0a98
DEBUG 01-13 08:46:42.304893.304893 client.py:106] call stub.LoadModelAsync
DEBUG 01-13 08:46:42.305192.305192 cuda_h.py:10] start self_attn
INFO 01-13 08:46:42.306134.306134 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, f1b152fc-86c2-4cc1-92de-500b649f0a98
DEBUG 01-13 08:46:42.306924.306924 cuda_h.py:19] end load_into_gpu_async cost 0.001651763916015625 seconds
DEBUG 01-13 08:46:42.306256.306256 cuda_h.py:10] start restore_tensors2
DEBUG 01-13 08:46:42.306644.306644 cuda_h.py:19] end restore_tensors2 cost 6.866455078125e-05 seconds
DEBUG 01-13 08:46:42.306161.306161 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.002347230911254883 seconds
INFO 01-13 08:46:42.306421.306421 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, f1b152fc-86c2-4cc1-92de-500b649f0a98
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-13 08:46:42.308787.308787 cuda_h.py:19] end self_attn cost 0.002869129180908203 seconds
DEBUG 01-13 08:46:42.308837.308837 cuda_h.py:19] end iln_self_attn_paln cost 0.004410266876220703 seconds
DEBUG 01-13 08:46:42.308104.308104 cuda_h.py:10] start layer_moe_generate_mp_l_24
DEBUG 01-13 08:46:42.308483.308483 cuda_h.py:10] start gate
DEBUG 01-13 08:46:42.309969.309969 cuda_h.py:19] end gate cost 0.0006406307220458984 seconds
DEBUG 01-13 08:46:42.309083.309083 cuda_h.py:10] start experts_map_get
DEBUG 01-13 08:46:42.309007.309007 lmp.py:1611] 
DEBUG 01-13 08:46:42.309007.309007 lmp.py:1611] Expert Token Distribution & Device Allocation:
DEBUG 01-13 08:46:42.309286.309286 lmp.py:1612]   Total experts: 64
DEBUG 01-13 08:46:42.309380.309380 lmp.py:1613]   CPU experts: 32 (50%)
DEBUG 01-13 08:46:42.309453.309453 lmp.py:1614]   GPU experts: 32 (50%)
DEBUG 01-13 08:46:42.309620.309620 lmp.py:1615] 
DEBUG 01-13 08:46:42.309620.309620 lmp.py:1615]   Expert ID | Tokens | Device
DEBUG 01-13 08:46:42.309263.309263 lmp.py:1616]   -----------------------------------
DEBUG 01-13 08:46:42.309866.309866 lmp.py:1622]   Expert  5 |     13 | CPU
DEBUG 01-13 08:46:42.309794.309794 lmp.py:1622]   Expert 56 |     35 | CPU
DEBUG 01-13 08:46:42.309529.309529 lmp.py:1622]   Expert 27 |     75 | CPU
DEBUG 01-13 08:46:42.309980.309980 lmp.py:1622]   Expert 16 |     86 | CPU
DEBUG 01-13 08:46:42.309716.309716 lmp.py:1622]   Expert 17 |     87 | CPU
DEBUG 01-13 08:46:42.309451.309451 lmp.py:1622]   Expert 40 |     89 | CPU
DEBUG 01-13 08:46:42.309710.309710 lmp.py:1622]   Expert 51 |     97 | CPU
DEBUG 01-13 08:46:42.309207.309207 lmp.py:1622]   Expert  7 |    100 | CPU
DEBUG 01-13 08:46:42.309181.309181 lmp.py:1622]   Expert 53 |    100 | CPU
DEBUG 01-13 08:46:42.309679.309679 lmp.py:1622]   Expert 49 |    102 | CPU
DEBUG 01-13 08:46:42.309414.309414 lmp.py:1622]   Expert 28 |    110 | CPU
DEBUG 01-13 08:46:42.309912.309912 lmp.py:1622]   Expert 63 |    110 | CPU
DEBUG 01-13 08:46:42.309409.309409 lmp.py:1622]   Expert 58 |    118 | CPU
DEBUG 01-13 08:46:42.309906.309906 lmp.py:1622]   Expert 37 |    120 | CPU
DEBUG 01-13 08:46:42.309165.309165 lmp.py:1622]   Expert 11 |    121 | CPU
DEBUG 01-13 08:46:42.309616.309616 lmp.py:1622]   Expert 38 |    125 | CPU
DEBUG 01-13 08:46:42.309828.309828 lmp.py:1622]   Expert 47 |    126 | CPU
DEBUG 01-13 08:46:42.309802.309802 lmp.py:1622]   Expert 57 |    139 | CPU
DEBUG 01-13 08:46:42.309015.309015 lmp.py:1622]   Expert 62 |    142 | CPU
DEBUG 01-13 08:46:42.309465.309465 lmp.py:1622]   Expert 39 |    144 | CPU
DEBUG 01-13 08:46:42.310870.310870 lmp.py:1622]   Expert 14 |    145 | CPU
DEBUG 01-13 08:46:42.310321.310321 lmp.py:1622]   Expert  1 |    146 | CPU
DEBUG 01-13 08:46:42.310249.310249 lmp.py:1622]   Expert 25 |    152 | CPU
DEBUG 01-13 08:46:42.310699.310699 lmp.py:1622]   Expert 33 |    158 | CPU
DEBUG 01-13 08:46:42.310150.310150 lmp.py:1622]   Expert 52 |    161 | CPU
DEBUG 01-13 08:46:42.310601.310601 lmp.py:1622]   Expert 23 |    163 | CPU
DEBUG 01-13 08:46:42.310814.310814 lmp.py:1622]   Expert  6 |    167 | CPU
DEBUG 01-13 08:46:42.310503.310503 lmp.py:1622]   Expert 60 |    174 | CPU
DEBUG 01-13 08:46:42.310954.310954 lmp.py:1622]   Expert 21 |    175 | CPU
DEBUG 01-13 08:46:42.310928.310928 lmp.py:1622]   Expert 45 |    177 | CPU
DEBUG 01-13 08:46:42.310856.310856 lmp.py:1622]   Expert 30 |    179 | CPU
DEBUG 01-13 08:46:42.310022.310022 lmp.py:1622]   Expert 44 |    179 | CPU
DEBUG 01-13 08:46:42.310950.310950 lmp.py:1622]   Expert  4 |    185 | GPU
DEBUG 01-13 08:46:42.310877.310877 lmp.py:1622]   Expert 19 |    186 | GPU
DEBUG 01-13 08:46:42.310805.310805 lmp.py:1622]   Expert  3 |    189 | GPU
DEBUG 01-13 08:46:42.310256.310256 lmp.py:1622]   Expert 31 |    199 | GPU
DEBUG 01-13 08:46:42.310707.310707 lmp.py:1622]   Expert 36 |    203 | GPU
DEBUG 01-13 08:46:42.310919.310919 lmp.py:1622]   Expert 55 |    204 | GPU
DEBUG 01-13 08:46:42.310370.310370 lmp.py:1622]   Expert 12 |    209 | GPU
DEBUG 01-13 08:46:42.310583.310583 lmp.py:1622]   Expert 41 |    214 | GPU
DEBUG 01-13 08:46:42.310033.310033 lmp.py:1622]   Expert  9 |    218 | GPU
DEBUG 01-13 08:46:42.310723.310723 lmp.py:1622]   Expert  0 |    223 | GPU
DEBUG 01-13 08:46:42.310697.310697 lmp.py:1622]   Expert 22 |    223 | GPU
DEBUG 01-13 08:46:42.310909.310909 lmp.py:1622]   Expert 34 |    223 | GPU
DEBUG 01-13 08:46:42.310122.310122 lmp.py:1622]   Expert 43 |    236 | GPU
DEBUG 01-13 08:46:42.310334.310334 lmp.py:1622]   Expert 26 |    240 | GPU
DEBUG 01-13 08:46:42.310547.310547 lmp.py:1622]   Expert 54 |    243 | GPU
DEBUG 01-13 08:46:42.310521.310521 lmp.py:1622]   Expert 59 |    252 | GPU
DEBUG 01-13 08:46:42.310972.310972 lmp.py:1622]   Expert 20 |    255 | GPU
DEBUG 01-13 08:46:42.310899.310899 lmp.py:1622]   Expert 61 |    257 | GPU
DEBUG 01-13 08:46:42.310827.310827 lmp.py:1622]   Expert 15 |    258 | GPU
DEBUG 01-13 08:46:42.310755.310755 lmp.py:1622]   Expert 50 |    258 | GPU
DEBUG 01-13 08:46:42.310444.310444 lmp.py:1622]   Expert 18 |    259 | GPU
DEBUG 01-13 08:46:42.310133.310133 lmp.py:1622]   Expert 13 |    262 | GPU
DEBUG 01-13 08:46:42.310346.310346 lmp.py:1622]   Expert 35 |    266 | GPU
DEBUG 01-13 08:46:42.310558.310558 lmp.py:1622]   Expert 24 |    268 | GPU
DEBUG 01-13 08:46:42.310771.310771 lmp.py:1622]   Expert 42 |    268 | GPU
DEBUG 01-13 08:46:42.310983.310983 lmp.py:1622]   Expert 29 |    269 | GPU
DEBUG 01-13 08:46:42.310957.310957 lmp.py:1622]   Expert 32 |    285 | GPU
DEBUG 01-13 08:46:42.310170.310170 lmp.py:1622]   Expert  2 |    336 | GPU
DEBUG 01-13 08:46:42.310382.310382 lmp.py:1622]   Expert  8 |    342 | GPU
DEBUG 01-13 08:46:42.310595.310595 lmp.py:1622]   Expert 10 |    376 | GPU
DEBUG 01-13 08:46:42.310284.310284 lmp.py:1622]   Expert 46 |    429 | GPU
DEBUG 01-13 08:46:42.310450.310450 lmp.py:1622]   Expert 48 |    438 | GPU
DEBUG 01-13 08:46:42.310093.310093 lmp.py:1623] 
DEBUG 01-13 08:46:42.310093.310093 lmp.py:1623]   CPU total tokens: 4015 (32.7%)
DEBUG 01-13 08:46:42.310690.310690 lmp.py:1624]   GPU total tokens: 8273 (67.3%)
DEBUG 01-13 08:46:42.310386.310386 cuda_h.py:19] end experts_map_get cost 0.0014944076538085938 seconds
DEBUG 01-13 08:46:42.310467.310467 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-13 08:46:42.310362.310362 lmp.py:1632] 
DEBUG 01-13 08:46:42.310362.310362 lmp.py:1632]   Computing 32 experts on CPU MP...
DEBUG 01-13 08:46:42.310000.310000 cuda_h.py:19] end cpu_experts_submit cost 4.839897155761719e-05 seconds
DEBUG 01-13 08:46:42.310504.310504 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-13 08:46:42.310187.310187 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-13 08:46:42.311782.311782 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-13 08:46:42.312778.312778 cuda_h.py:19] end allocate_cuda_memory cost 0.0016133785247802734 seconds
DEBUG 01-13 08:46:42.312574.312574 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-13 08:46:42.312853.312853 sllm_store_c.py:27] get device uuid map
DEBUG 01-13 08:46:42.312378.312378 sllm_store_c.py:29] call client load into gpu
DEBUG 01-13 08:46:42.312220.312220 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 0cc9d9ab-e49d-4500-ad8d-e7abaadd94d9
DEBUG 01-13 08:46:42.313524.313524 client.py:106] call stub.LoadModelAsync
DEBUG 01-13 08:46:42.314389.314389 cuda_h.py:10] start experts_func_gpu_einsum_mp
INFO 01-13 08:46:42.314266.314266 client.py:127] Model loaded
DEBUG 01-13 08:46:42.314248.314248 cuda_h.py:10] start restore2model
DEBUG 01-13 08:46:42.315183.315183 cuda_h.py:19] end restore2model cost 0.00040650367736816406 seconds
DEBUG 01-13 08:46:42.315821.315821 cuda_h.py:19] end sllm_worker_task cost 0.010827779769897461 seconds
INFO 01-13 08:46:42.316980.316980 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 0cc9d9ab-e49d-4500-ad8d-e7abaadd94d9
DEBUG 01-13 08:46:42.316876.316876 cuda_h.py:19] end load_into_gpu_async cost 0.0032432079315185547 seconds
DEBUG 01-13 08:46:42.316056.316056 cuda_h.py:10] start restore_tensors2
DEBUG 01-13 08:46:42.316121.316121 cuda_h.py:19] end restore_tensors2 cost 0.0003371238708496094 seconds
DEBUG 01-13 08:46:42.316235.316235 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.005559206008911133 seconds
DEBUG 01-13 08:46:42.316097.316097 cuda_h.py:10] start restore2model
DEBUG 01-13 08:46:42.319945.319945 cuda_h.py:19] end restore2model cost 0.0025272369384765625 seconds
DEBUG 01-13 08:46:42.319258.319258 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.008259773254394531 seconds
DEBUG 01-13 08:46:42.319881.319881 cuda_h.py:10] start gpu_sexperts
DEBUG 01-13 08:46:42.319076.319076 cuda_h.py:19] end gpu_sexperts cost 0.0002551078796386719 seconds
DEBUG 01-13 08:46:42.319237.319237 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-13 08:46:42.319722.319722 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 1.4781951904296875e-05 seconds
DEBUG 01-13 08:46:42.319703.319703 cuda_h.py:10] start wait_experts
INFO 01-13 08:46:42.319399.319399 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 0cc9d9ab-e49d-4500-ad8d-e7abaadd94d9
DEBUG 01-13 08:46:42.324468.324468 mlpmodule.py:1006] group tensors cost 0.00978541374206543 s
DEBUG 01-13 08:46:42.326988.326988 mlpmodule.py:1044] pad cost 0.0015194416046142578 s
DEBUG 01-13 08:46:42.326568.326568 mlpmodule.py:1050] create cpu tensor cost 5.936622619628906e-05 s
DEBUG 01-13 08:46:42.326610.326610 mlpmodule.py:1055] move to cpu cost 3.266334533691406e-05 s
DEBUG 01-13 08:46:42.335716.335716 mlpmodule.py:1069] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-13 08:46:42.335525.335525 mlpmodule.py:1070] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-13 08:46:42.335803.335803 mlpmodule.py:1075] group_w3 first element: 0.08447265625
WARNING 01-13 08:46:42.335584.335584 mlpmodule.py:1085] start einsum2
DEBUG 01-13 08:46:42.349897.349897 mlpmodule.py:1095] group einsum cost 0.022912263870239258 s
DEBUG 01-13 08:46:42.350320.350320 mlpmodule.py:1103] cpy2cputensor cost 0.0007338523864746094 s
DEBUG 01-13 08:46:42.364747.364747 mlpmodule.py:785]  experts func einsum cost 0.049414873123168945 s
DEBUG 01-13 08:46:42.364917.364917 cuda_h.py:19] end experts_func_gpu_einsum_mp cost 0.05064749717712402 seconds
INFO 01-13 08:46:42.368380.368380 client.py:127] Model loaded
DEBUG 01-13 08:46:42.368955.368955 cuda_h.py:19] end wait_experts cost 0.04902243614196777 seconds
DEBUG 01-13 08:46:42.368095.368095 cuda_h.py:10] start gpu_experts
DEBUG 01-13 08:46:42.369244.369244 mlpmodule.py:559] gpu group tensors cost 0.0006082057952880859 s
DEBUG 01-13 08:46:42.370924.370924 mlpmodule.py:592] gpu pad cost 0.0014493465423583984 s
DEBUG 01-13 08:46:42.371443.371443 mlpmodule.py:598] start_w1
DEBUG 01-13 08:46:42.371751.371751 mlpmodule.py:602] start_w3
DEBUG 01-13 08:46:42.371393.371393 mlpmodule.py:608] start_w2
DEBUG 01-13 08:46:42.371292.371292 mlpmodule.py:611] gpu group einsum cost 0.0006258487701416016 s
DEBUG 01-13 08:46:42.373803.373803 mlpmodule.py:683] gpu experts func einsum cost 0.005025148391723633 s
DEBUG 01-13 08:46:42.373554.373554 cuda_h.py:19] end gpu_experts cost 0.005183219909667969 seconds
DEBUG 01-13 08:46:42.373641.373641 cuda_h.py:10] start cpu_thread_manager_mp_wait
DEBUG 01-13 08:46:42.374776.374776 cuda_h.py:19] end cpu_thread_manager_mp_wait cost 3.695487976074219e-05 seconds
DEBUG 01-13 08:46:42.374501.374501 cuda_h.py:19] end layer_moe_generate_mp_l_24 cost 0.06560611724853516 seconds
DEBUG 01-13 08:46:42.374296.374296 lmp.py:1550] -------------------------------- end prefill layer 23 --------------------------------
DEBUG 01-13 08:46:42.374106.374106 lmp.py:1493] -------------------------------- start prefill layer 24 --------------------------------
DEBUG 01-13 08:46:42.374709.374709 cuda_h.py:10] start start_load_qkvogn_s_weight_l_25
DEBUG 01-13 08:46:42.374889.374889 cuda_h.py:10] start start_load_qkvogn_s_weight_l_25
DEBUG 01-13 08:46:42.374533.374533 cuda_h.py:19] end start_load_qkvogn_s_weight_l_25 cost 3.075599670410156e-05 seconds
DEBUG 01-13 08:46:42.374826.374826 cuda_h.py:19] end start_load_qkvogn_s_weight_l_25 cost 7.43865966796875e-05 seconds
DEBUG 01-13 08:46:42.374376.374376 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-13 08:46:42.374922.374922 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-13 08:46:42.374435.374435 cuda_h.py:10] start sllm_worker_task
DEBUG 01-13 08:46:42.374706.374706 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-13 08:46:42.375537.375537 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-13 08:46:42.375205.375205 cuda_h.py:19] end allocate_cuda_memory cost 0.00045871734619140625 seconds
DEBUG 01-13 08:46:42.375594.375594 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-13 08:46:42.375187.375187 sllm_store_c.py:27] get device uuid map
DEBUG 01-13 08:46:42.375237.375237 sllm_store_c.py:29] call client load into gpu
DEBUG 01-13 08:46:42.376093.376093 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 1a2ebc91-0783-4e80-a88e-f95b96c93e0a
DEBUG 01-13 08:46:42.376658.376658 cuda_h.py:10] start self_attn
DEBUG 01-13 08:46:42.376711.376711 client.py:106] call stub.LoadModelAsync
INFO 01-13 08:46:42.377364.377364 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 1a2ebc91-0783-4e80-a88e-f95b96c93e0a
DEBUG 01-13 08:46:42.378302.378302 cuda_h.py:19] end load_into_gpu_async cost 0.0022475719451904297 seconds
DEBUG 01-13 08:46:42.378728.378728 cuda_h.py:10] start restore_tensors2
DEBUG 01-13 08:46:42.378271.378271 cuda_h.py:19] end restore_tensors2 cost 0.00012040138244628906 seconds
DEBUG 01-13 08:46:42.378479.378479 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.003432035446166992 seconds
INFO 01-13 08:46:42.378515.378515 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 1a2ebc91-0783-4e80-a88e-f95b96c93e0a
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-13 08:46:42.379658.379658 cuda_h.py:19] end self_attn cost 0.003284454345703125 seconds
DEBUG 01-13 08:46:42.379489.379489 cuda_h.py:19] end iln_self_attn_paln cost 0.005316019058227539 seconds
DEBUG 01-13 08:46:42.379802.379802 cuda_h.py:10] start layer_moe_generate_mp_l_25
DEBUG 01-13 08:46:42.380942.380942 cuda_h.py:10] start gate
DEBUG 01-13 08:46:42.380283.380283 cuda_h.py:19] end gate cost 0.0006396770477294922 seconds
DEBUG 01-13 08:46:42.380158.380158 cuda_h.py:10] start experts_map_get
DEBUG 01-13 08:46:42.381228.381228 lmp.py:1611] 
DEBUG 01-13 08:46:42.381228.381228 lmp.py:1611] Expert Token Distribution & Device Allocation:
DEBUG 01-13 08:46:42.381222.381222 lmp.py:1612]   Total experts: 64
DEBUG 01-13 08:46:42.381779.381779 lmp.py:1613]   CPU experts: 32 (50%)
DEBUG 01-13 08:46:42.381760.381760 lmp.py:1614]   GPU experts: 32 (50%)
DEBUG 01-13 08:46:42.381119.381119 lmp.py:1615] 
DEBUG 01-13 08:46:42.381119.381119 lmp.py:1615]   Expert ID | Tokens | Device
DEBUG 01-13 08:46:42.381954.381954 lmp.py:1616]   -----------------------------------
DEBUG 01-13 08:46:42.381272.381272 lmp.py:1622]   Expert 36 |     24 | CPU
DEBUG 01-13 08:46:42.381392.381392 lmp.py:1622]   Expert 35 |     35 | CPU
DEBUG 01-13 08:46:42.381797.381797 lmp.py:1622]   Expert 46 |     45 | CPU
DEBUG 01-13 08:46:42.381201.381201 lmp.py:1622]   Expert 25 |     48 | CPU
DEBUG 01-13 08:46:42.381367.381367 lmp.py:1622]   Expert 51 |     52 | CPU
DEBUG 01-13 08:46:42.381295.381295 lmp.py:1622]   Expert 16 |     54 | CPU
DEBUG 01-13 08:46:42.381700.381700 lmp.py:1622]   Expert 42 |     63 | CPU
DEBUG 01-13 08:46:42.381627.381627 lmp.py:1622]   Expert 30 |     64 | CPU
DEBUG 01-13 08:46:42.381032.381032 lmp.py:1622]   Expert  0 |     65 | CPU
DEBUG 01-13 08:46:42.381675.381675 lmp.py:1622]   Expert 43 |     66 | CPU
DEBUG 01-13 08:46:42.381841.381841 lmp.py:1622]   Expert 44 |     68 | CPU
DEBUG 01-13 08:46:42.381007.381007 lmp.py:1622]   Expert 39 |     69 | CPU
DEBUG 01-13 08:46:42.381412.381412 lmp.py:1622]   Expert 47 |     74 | CPU
DEBUG 01-13 08:46:42.381101.381101 lmp.py:1622]   Expert 55 |     77 | CPU
DEBUG 01-13 08:46:42.381698.381698 lmp.py:1622]   Expert  2 |     88 | CPU
DEBUG 01-13 08:46:42.381579.381579 lmp.py:1622]   Expert  4 |    113 | CPU
DEBUG 01-13 08:46:42.381460.381460 lmp.py:1622]   Expert 33 |    116 | CPU
DEBUG 01-13 08:46:42.381865.381865 lmp.py:1622]   Expert 48 |    116 | CPU
DEBUG 01-13 08:46:42.381985.381985 lmp.py:1622]   Expert 61 |    119 | CPU
DEBUG 01-13 08:46:42.381913.381913 lmp.py:1622]   Expert  6 |    123 | CPU
DEBUG 01-13 08:46:42.381840.381840 lmp.py:1622]   Expert 13 |    126 | CPU
DEBUG 01-13 08:46:42.381768.381768 lmp.py:1622]   Expert 24 |    126 | CPU
DEBUG 01-13 08:46:42.381696.381696 lmp.py:1622]   Expert 38 |    131 | CPU
DEBUG 01-13 08:46:42.381862.381862 lmp.py:1622]   Expert 56 |    132 | CPU
DEBUG 01-13 08:46:42.381757.381757 lmp.py:1622]   Expert  9 |    133 | CPU
DEBUG 01-13 08:46:42.381446.381446 lmp.py:1622]   Expert 15 |    136 | CPU
DEBUG 01-13 08:46:42.381566.381566 lmp.py:1622]   Expert 20 |    137 | CPU
DEBUG 01-13 08:46:42.381494.381494 lmp.py:1622]   Expert  7 |    141 | CPU
DEBUG 01-13 08:46:42.381898.381898 lmp.py:1622]   Expert 54 |    144 | CPU
DEBUG 01-13 08:46:42.381064.381064 lmp.py:1622]   Expert 29 |    147 | CPU
DEBUG 01-13 08:46:42.381469.381469 lmp.py:1622]   Expert 59 |    153 | CPU
DEBUG 01-13 08:46:42.381635.381635 lmp.py:1622]   Expert 45 |    160 | CPU
DEBUG 01-13 08:46:42.381324.381324 lmp.py:1622]   Expert 62 |    160 | GPU
DEBUG 01-13 08:46:42.381775.381775 lmp.py:1622]   Expert 19 |    164 | GPU
DEBUG 01-13 08:46:42.381226.381226 lmp.py:1622]   Expert 57 |    189 | GPU
DEBUG 01-13 08:46:42.381915.381915 lmp.py:1622]   Expert 34 |    194 | GPU
DEBUG 01-13 08:46:42.381366.381366 lmp.py:1622]   Expert 10 |    202 | GPU
DEBUG 01-13 08:46:42.381817.381817 lmp.py:1622]   Expert 50 |    204 | GPU
DEBUG 01-13 08:46:42.381506.381506 lmp.py:1622]   Expert 53 |    205 | GPU
DEBUG 01-13 08:46:42.381719.381719 lmp.py:1622]   Expert 23 |    208 | GPU
DEBUG 01-13 08:46:42.381931.381931 lmp.py:1622]   Expert  8 |    210 | GPU
DEBUG 01-13 08:46:42.381098.381098 lmp.py:1622]   Expert 31 |    211 | GPU
DEBUG 01-13 08:46:42.381264.381264 lmp.py:1622]   Expert 22 |    212 | GPU
DEBUG 01-13 08:46:42.381430.381430 lmp.py:1622]   Expert 18 |    218 | GPU
DEBUG 01-13 08:46:42.381358.381358 lmp.py:1622]   Expert 37 |    218 | GPU
DEBUG 01-13 08:46:42.381285.381285 lmp.py:1622]   Expert 52 |    225 | GPU
DEBUG 01-13 08:46:42.381975.381975 lmp.py:1622]   Expert 60 |    226 | GPU
DEBUG 01-13 08:46:42.381187.381187 lmp.py:1622]   Expert  5 |    239 | GPU
DEBUG 01-13 08:46:42.382923.382923 lmp.py:1622]   Expert 17 |    248 | GPU
DEBUG 01-13 08:46:42.382612.382612 lmp.py:1622]   Expert 11 |    264 | GPU
DEBUG 01-13 08:46:42.382824.382824 lmp.py:1622]   Expert 41 |    275 | GPU
DEBUG 01-13 08:46:42.382514.382514 lmp.py:1622]   Expert  1 |    276 | GPU
DEBUG 01-13 08:46:42.382965.382965 lmp.py:1622]   Expert 49 |    282 | GPU
DEBUG 01-13 08:46:42.382177.382177 lmp.py:1622]   Expert 26 |    287 | GPU
DEBUG 01-13 08:46:42.382866.382866 lmp.py:1622]   Expert 28 |    287 | GPU
DEBUG 01-13 08:46:42.382271.382271 lmp.py:1622]   Expert 58 |    290 | GPU
DEBUG 01-13 08:46:42.382437.382437 lmp.py:1622]   Expert 32 |    296 | GPU
DEBUG 01-13 08:46:42.382842.382842 lmp.py:1622]   Expert 40 |    304 | GPU
DEBUG 01-13 08:46:42.382008.382008 lmp.py:1622]   Expert 14 |    322 | GPU
DEBUG 01-13 08:46:42.382174.382174 lmp.py:1622]   Expert 12 |    323 | GPU
DEBUG 01-13 08:46:42.382863.382863 lmp.py:1622]   Expert 63 |    333 | GPU
DEBUG 01-13 08:46:42.382791.382791 lmp.py:1622]   Expert 21 |    368 | GPU
DEBUG 01-13 08:46:42.382480.382480 lmp.py:1622]   Expert 27 |    673 | GPU
DEBUG 01-13 08:46:42.382170.382170 lmp.py:1622]   Expert  3 |   1030 | GPU
DEBUG 01-13 08:46:42.382051.382051 lmp.py:1623] 
DEBUG 01-13 08:46:42.382051.382051 lmp.py:1623]   CPU total tokens: 3145 (25.6%)
DEBUG 01-13 08:46:42.382694.382694 lmp.py:1624]   GPU total tokens: 9143 (74.4%)
DEBUG 01-13 08:46:42.382152.382152 cuda_h.py:19] end experts_map_get cost 0.0015473365783691406 seconds
DEBUG 01-13 08:46:42.382187.382187 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-13 08:46:42.382512.382512 lmp.py:1632] 
DEBUG 01-13 08:46:42.382512.382512 lmp.py:1632]   Computing 32 experts on CPU MP...
DEBUG 01-13 08:46:42.382911.382911 cuda_h.py:19] end cpu_experts_submit cost 4.792213439941406e-05 seconds
DEBUG 01-13 08:46:42.382461.382461 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-13 08:46:42.382622.382622 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-13 08:46:42.382839.382839 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-13 08:46:42.384859.384859 cuda_h.py:19] end allocate_cuda_memory cost 0.0017352104187011719 seconds
DEBUG 01-13 08:46:42.384947.384947 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-13 08:46:42.384418.384418 sllm_store_c.py:27] get device uuid map
DEBUG 01-13 08:46:42.385701.385701 sllm_store_c.py:29] call client load into gpu
DEBUG 01-13 08:46:42.385603.385603 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 965f6f05-5de4-4499-8e0f-825b1ab1807d
DEBUG 01-13 08:46:42.385729.385729 client.py:106] call stub.LoadModelAsync
INFO 01-13 08:46:42.385524.385524 client.py:127] Model loaded
DEBUG 01-13 08:46:42.385342.385342 cuda_h.py:10] start restore2model
DEBUG 01-13 08:46:42.385911.385911 cuda_h.py:10] start experts_func_gpu_einsum_mp
DEBUG 01-13 08:46:42.386407.386407 cuda_h.py:19] end restore2model cost 0.0008790493011474609 seconds
DEBUG 01-13 08:46:42.386166.386166 cuda_h.py:19] end sllm_worker_task cost 0.011969804763793945 seconds
INFO 01-13 08:46:42.387235.387235 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 965f6f05-5de4-4499-8e0f-825b1ab1807d
DEBUG 01-13 08:46:42.387416.387416 cuda_h.py:19] end load_into_gpu_async cost 0.002698183059692383 seconds
DEBUG 01-13 08:46:42.387357.387357 cuda_h.py:10] start restore_tensors2
DEBUG 01-13 08:46:42.387721.387721 cuda_h.py:19] end restore_tensors2 cost 0.0003478527069091797 seconds
DEBUG 01-13 08:46:42.387597.387597 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.005151510238647461 seconds
DEBUG 01-13 08:46:42.387267.387267 cuda_h.py:10] start restore2model
DEBUG 01-13 08:46:42.390111.390111 cuda_h.py:19] end restore2model cost 0.002623319625854492 seconds
DEBUG 01-13 08:46:42.390424.390424 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.007957696914672852 seconds
DEBUG 01-13 08:46:42.390525.390525 cuda_h.py:10] start gpu_sexperts
DEBUG 01-13 08:46:42.390078.390078 cuda_h.py:19] end gpu_sexperts cost 0.0002658367156982422 seconds
DEBUG 01-13 08:46:42.390907.390907 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-13 08:46:42.390392.390392 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 1.3828277587890625e-05 seconds
DEBUG 01-13 08:46:42.390896.390896 cuda_h.py:10] start wait_experts
INFO 01-13 08:46:42.390023.390023 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 965f6f05-5de4-4499-8e0f-825b1ab1807d
DEBUG 01-13 08:46:42.396903.396903 mlpmodule.py:1006] group tensors cost 0.009837627410888672 s
DEBUG 01-13 08:46:42.398352.398352 mlpmodule.py:1044] pad cost 0.001560211181640625 s
DEBUG 01-13 08:46:42.398488.398488 mlpmodule.py:1050] create cpu tensor cost 4.553794860839844e-05 s
DEBUG 01-13 08:46:42.398384.398384 mlpmodule.py:1055] move to cpu cost 3.123283386230469e-05 s
DEBUG 01-13 08:46:42.408618.408618 mlpmodule.py:1069] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-13 08:46:42.408242.408242 mlpmodule.py:1070] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-13 08:46:42.408177.408177 mlpmodule.py:1075] group_w3 first element: 0.00653076171875
WARNING 01-13 08:46:42.408979.408979 mlpmodule.py:1085] start einsum2
DEBUG 01-13 08:46:42.422677.422677 mlpmodule.py:1095] group einsum cost 0.023895978927612305 s
DEBUG 01-13 08:46:42.423404.423404 mlpmodule.py:1103] cpy2cputensor cost 0.0007038116455078125 s
DEBUG 01-13 08:46:42.437443.437443 mlpmodule.py:785]  experts func einsum cost 0.05049729347229004 s
DEBUG 01-13 08:46:42.437173.437173 cuda_h.py:19] end experts_func_gpu_einsum_mp cost 0.05161619186401367 seconds
INFO 01-13 08:46:42.439661.439661 client.py:127] Model loaded
DEBUG 01-13 08:46:42.439772.439772 cuda_h.py:19] end wait_experts cost 0.048673152923583984 seconds
DEBUG 01-13 08:46:42.439098.439098 cuda_h.py:10] start gpu_experts
DEBUG 01-13 08:46:42.440764.440764 mlpmodule.py:559] gpu group tensors cost 0.0006048679351806641 s
DEBUG 01-13 08:46:42.441299.441299 mlpmodule.py:592] gpu pad cost 0.0014414787292480469 s
DEBUG 01-13 08:46:42.441142.441142 mlpmodule.py:598] start_w1
DEBUG 01-13 08:46:42.442465.442465 mlpmodule.py:602] start_w3
DEBUG 01-13 08:46:42.442696.442696 mlpmodule.py:608] start_w2
DEBUG 01-13 08:46:42.442721.442721 mlpmodule.py:611] gpu group einsum cost 0.0006709098815917969 s
DEBUG 01-13 08:46:42.444276.444276 mlpmodule.py:683] gpu experts func einsum cost 0.005023002624511719 s
DEBUG 01-13 08:46:42.444769.444769 cuda_h.py:19] end gpu_experts cost 0.005175113677978516 seconds
DEBUG 01-13 08:46:42.444763.444763 cuda_h.py:10] start cpu_thread_manager_mp_wait
DEBUG 01-13 08:46:42.444997.444997 cuda_h.py:19] end cpu_thread_manager_mp_wait cost 3.886222839355469e-05 seconds
DEBUG 01-13 08:46:42.445814.445814 cuda_h.py:19] end layer_moe_generate_mp_l_25 cost 0.06500792503356934 seconds
DEBUG 01-13 08:46:42.445133.445133 lmp.py:1550] -------------------------------- end prefill layer 24 --------------------------------
DEBUG 01-13 08:46:42.445750.445750 lmp.py:1493] -------------------------------- start prefill layer 25 --------------------------------
DEBUG 01-13 08:46:42.445400.445400 cuda_h.py:10] start start_load_qkvogn_s_weight_l_26
DEBUG 01-13 08:46:42.445818.445818 cuda_h.py:10] start start_load_qkvogn_s_weight_l_26
DEBUG 01-13 08:46:42.445178.445178 cuda_h.py:19] end start_load_qkvogn_s_weight_l_26 cost 3.0517578125e-05 seconds
DEBUG 01-13 08:46:42.445424.445424 cuda_h.py:19] end start_load_qkvogn_s_weight_l_26 cost 7.534027099609375e-05 seconds
DEBUG 01-13 08:46:42.445120.445120 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-13 08:46:42.445771.445771 cuda_h.py:10] start sllm_worker_task
DEBUG 01-13 08:46:42.445046.445046 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-13 08:46:42.445121.445121 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-13 08:46:42.446386.446386 cuda_h.py:19] end allocate_cuda_memory cost 0.00036716461181640625 seconds
DEBUG 01-13 08:46:42.446905.446905 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-13 08:46:42.446283.446283 sllm_store_c.py:27] get device uuid map
DEBUG 01-13 08:46:42.446199.446199 sllm_store_c.py:29] call client load into gpu
DEBUG 01-13 08:46:42.446663.446663 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 01e76131-cab3-4f77-a176-b8188dbbfa69
DEBUG 01-13 08:46:42.446494.446494 client.py:106] call stub.LoadModelAsync
DEBUG 01-13 08:46:42.446247.446247 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-13 08:46:42.446151.446151 cuda_h.py:10] start self_attn
INFO 01-13 08:46:42.447754.447754 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 01e76131-cab3-4f77-a176-b8188dbbfa69
DEBUG 01-13 08:46:42.447068.447068 cuda_h.py:19] end load_into_gpu_async cost 0.0016658306121826172 seconds
DEBUG 01-13 08:46:42.447386.447386 cuda_h.py:10] start restore_tensors2
DEBUG 01-13 08:46:42.447184.447184 cuda_h.py:19] end restore_tensors2 cost 7.104873657226562e-05 seconds
DEBUG 01-13 08:46:42.447702.447702 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0023467540740966797 seconds
INFO 01-13 08:46:42.448214.448214 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 01e76131-cab3-4f77-a176-b8188dbbfa69
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-13 08:46:42.449872.449872 cuda_h.py:19] end self_attn cost 0.003075122833251953 seconds
DEBUG 01-13 08:46:42.450935.450935 cuda_h.py:19] end iln_self_attn_paln cost 0.004715681076049805 seconds
DEBUG 01-13 08:46:42.450440.450440 cuda_h.py:10] start layer_moe_generate_mp_l_26
DEBUG 01-13 08:46:42.450580.450580 cuda_h.py:10] start gate
DEBUG 01-13 08:46:42.450324.450324 cuda_h.py:19] end gate cost 0.0006198883056640625 seconds
DEBUG 01-13 08:46:42.450292.450292 cuda_h.py:10] start experts_map_get
DEBUG 01-13 08:46:42.451117.451117 lmp.py:1611] 
DEBUG 01-13 08:46:42.451117.451117 lmp.py:1611] Expert Token Distribution & Device Allocation:
DEBUG 01-13 08:46:42.451157.451157 lmp.py:1612]   Total experts: 64
DEBUG 01-13 08:46:42.451853.451853 lmp.py:1613]   CPU experts: 32 (50%)
DEBUG 01-13 08:46:42.451450.451450 lmp.py:1614]   GPU experts: 32 (50%)
DEBUG 01-13 08:46:42.451901.451901 lmp.py:1615] 
DEBUG 01-13 08:46:42.451901.451901 lmp.py:1615]   Expert ID | Tokens | Device
DEBUG 01-13 08:46:42.451590.451590 lmp.py:1616]   -----------------------------------
DEBUG 01-13 08:46:42.451432.451432 lmp.py:1622]   Expert 13 |     36 | CPU
DEBUG 01-13 08:46:42.451313.451313 lmp.py:1622]   Expert 44 |     39 | CPU
DEBUG 01-13 08:46:42.451480.451480 lmp.py:1622]   Expert  9 |     44 | CPU
DEBUG 01-13 08:46:42.451169.451169 lmp.py:1622]   Expert 22 |     45 | CPU
DEBUG 01-13 08:46:42.451858.451858 lmp.py:1622]   Expert 25 |     45 | CPU
DEBUG 01-13 08:46:42.451740.451740 lmp.py:1622]   Expert 38 |     46 | CPU
DEBUG 01-13 08:46:42.451429.451429 lmp.py:1622]   Expert 33 |     47 | CPU
DEBUG 01-13 08:46:42.451357.451357 lmp.py:1622]   Expert  2 |     49 | CPU
DEBUG 01-13 08:46:42.451867.451867 lmp.py:1622]   Expert 16 |     54 | CPU
DEBUG 01-13 08:46:42.451080.451080 lmp.py:1622]   Expert 42 |     54 | CPU
DEBUG 01-13 08:46:42.451292.451292 lmp.py:1622]   Expert  5 |     69 | CPU
DEBUG 01-13 08:46:42.451551.451551 lmp.py:1622]   Expert 23 |     74 | CPU
DEBUG 01-13 08:46:42.451287.451287 lmp.py:1622]   Expert 24 |     81 | CPU
DEBUG 01-13 08:46:42.451546.451546 lmp.py:1622]   Expert 10 |     83 | CPU
DEBUG 01-13 08:46:42.451281.451281 lmp.py:1622]   Expert 59 |     96 | CPU
DEBUG 01-13 08:46:42.451778.451778 lmp.py:1622]   Expert 21 |    101 | CPU
DEBUG 01-13 08:46:42.451037.451037 lmp.py:1622]   Expert 46 |    105 | CPU
DEBUG 01-13 08:46:42.451534.451534 lmp.py:1622]   Expert 61 |    107 | CPU
DEBUG 01-13 08:46:42.451985.451985 lmp.py:1622]   Expert 55 |    108 | CPU
DEBUG 01-13 08:46:42.451198.451198 lmp.py:1622]   Expert 45 |    116 | CPU
DEBUG 01-13 08:46:42.451933.451933 lmp.py:1622]   Expert 31 |    129 | CPU
DEBUG 01-13 08:46:42.451146.451146 lmp.py:1622]   Expert 36 |    136 | CPU
DEBUG 01-13 08:46:42.451358.451358 lmp.py:1622]   Expert  6 |    140 | CPU
DEBUG 01-13 08:46:42.451855.451855 lmp.py:1622]   Expert 51 |    145 | CPU
DEBUG 01-13 08:46:42.451114.451114 lmp.py:1622]   Expert  8 |    149 | CPU
DEBUG 01-13 08:46:42.451611.451611 lmp.py:1622]   Expert  0 |    152 | CPU
DEBUG 01-13 08:46:42.451109.451109 lmp.py:1622]   Expert 43 |    153 | CPU
DEBUG 01-13 08:46:42.451844.451844 lmp.py:1622]   Expert 26 |    154 | CPU
DEBUG 01-13 08:46:42.451103.451103 lmp.py:1622]   Expert 18 |    157 | CPU
DEBUG 01-13 08:46:42.451839.451839 lmp.py:1622]   Expert  3 |    164 | CPU
DEBUG 01-13 08:46:42.451097.451097 lmp.py:1622]   Expert 41 |    168 | CPU
DEBUG 01-13 08:46:42.451356.451356 lmp.py:1622]   Expert 48 |    168 | CPU
DEBUG 01-13 08:46:42.451092.451092 lmp.py:1622]   Expert 12 |    175 | GPU
DEBUG 01-13 08:46:42.451589.451589 lmp.py:1622]   Expert  7 |    179 | GPU
DEBUG 01-13 08:46:42.451802.451802 lmp.py:1622]   Expert 20 |    179 | GPU
DEBUG 01-13 08:46:42.451252.451252 lmp.py:1622]   Expert 56 |    182 | GPU
DEBUG 01-13 08:46:42.451227.451227 lmp.py:1622]   Expert 28 |    193 | GPU
DEBUG 01-13 08:46:42.452201.452201 lmp.py:1622]   Expert 34 |    194 | GPU
DEBUG 01-13 08:46:42.452936.452936 lmp.py:1622]   Expert 27 |    196 | GPU
DEBUG 01-13 08:46:42.452433.452433 lmp.py:1622]   Expert 47 |    200 | GPU
DEBUG 01-13 08:46:42.452454.452454 lmp.py:1622]   Expert  1 |    206 | GPU
DEBUG 01-13 08:46:42.452951.452951 lmp.py:1622]   Expert 11 |    206 | GPU
DEBUG 01-13 08:46:42.452210.452210 lmp.py:1622]   Expert 32 |    224 | GPU
DEBUG 01-13 08:46:42.452707.452707 lmp.py:1622]   Expert 49 |    224 | GPU
DEBUG 01-13 08:46:42.452966.452966 lmp.py:1622]   Expert 53 |    228 | GPU
DEBUG 01-13 08:46:42.452463.452463 lmp.py:1622]   Expert 40 |    233 | GPU
DEBUG 01-13 08:46:42.452722.452722 lmp.py:1622]   Expert 63 |    238 | GPU
DEBUG 01-13 08:46:42.452981.452981 lmp.py:1622]   Expert 15 |    246 | GPU
DEBUG 01-13 08:46:42.452239.452239 lmp.py:1622]   Expert 50 |    246 | GPU
DEBUG 01-13 08:46:42.452498.452498 lmp.py:1622]   Expert 29 |    248 | GPU
DEBUG 01-13 08:46:42.452234.452234 lmp.py:1622]   Expert  4 |    250 | GPU
DEBUG 01-13 08:46:42.452493.452493 lmp.py:1622]   Expert 30 |    250 | GPU
DEBUG 01-13 08:46:42.452943.452943 lmp.py:1622]   Expert 14 |    264 | GPU
DEBUG 01-13 08:46:42.452394.452394 lmp.py:1622]   Expert 35 |    272 | GPU
DEBUG 01-13 08:46:42.452368.452368 lmp.py:1622]   Expert 37 |    306 | GPU
DEBUG 01-13 08:46:42.452581.452581 lmp.py:1622]   Expert 52 |    340 | GPU
DEBUG 01-13 08:46:42.452840.452840 lmp.py:1622]   Expert 17 |    361 | GPU
DEBUG 01-13 08:46:42.452098.452098 lmp.py:1622]   Expert 54 |    377 | GPU
DEBUG 01-13 08:46:42.452357.452357 lmp.py:1622]   Expert 39 |    402 | GPU
DEBUG 01-13 08:46:42.452378.452378 lmp.py:1622]   Expert 57 |    413 | GPU
DEBUG 01-13 08:46:42.452875.452875 lmp.py:1622]   Expert 60 |    461 | GPU
DEBUG 01-13 08:46:42.452432.452432 lmp.py:1622]   Expert 62 |    466 | GPU
DEBUG 01-13 08:46:42.452883.452883 lmp.py:1622]   Expert 19 |    545 | GPU
DEBUG 01-13 08:46:42.452142.452142 lmp.py:1622]   Expert 58 |    570 | GPU
DEBUG 01-13 08:46:42.452354.452354 lmp.py:1623] 
DEBUG 01-13 08:46:42.452354.452354 lmp.py:1623]   CPU total tokens: 3214 (26.2%)
DEBUG 01-13 08:46:42.452282.452282 lmp.py:1624]   GPU total tokens: 9074 (73.8%)
DEBUG 01-13 08:46:42.452978.452978 cuda_h.py:19] end experts_map_get cost 0.001461029052734375 seconds
DEBUG 01-13 08:46:42.452728.452728 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-13 08:46:42.452577.452577 lmp.py:1632] 
DEBUG 01-13 08:46:42.452577.452577 lmp.py:1632]   Computing 32 experts on CPU MP...
DEBUG 01-13 08:46:42.452261.452261 cuda_h.py:19] end cpu_experts_submit cost 4.7206878662109375e-05 seconds
DEBUG 01-13 08:46:42.452049.452049 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-13 08:46:42.452402.452402 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-13 08:46:42.452089.452089 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-13 08:46:42.454822.454822 cuda_h.py:19] end allocate_cuda_memory cost 0.0014891624450683594 seconds
DEBUG 01-13 08:46:42.454334.454334 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-13 08:46:42.454090.454090 sllm_store_c.py:27] get device uuid map
DEBUG 01-13 08:46:42.454153.454153 sllm_store_c.py:29] call client load into gpu
DEBUG 01-13 08:46:42.454664.454664 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, f1d08a3c-24c7-4313-a333-6f0de6267dec
DEBUG 01-13 08:46:42.454213.454213 client.py:106] call stub.LoadModelAsync
INFO 01-13 08:46:42.455706.455706 client.py:127] Model loaded
DEBUG 01-13 08:46:42.455549.455549 cuda_h.py:10] start restore2model
DEBUG 01-13 08:46:42.455671.455671 cuda_h.py:19] end restore2model cost 0.0004374980926513672 seconds
DEBUG 01-13 08:46:42.455546.455546 cuda_h.py:19] end sllm_worker_task cost 0.010210275650024414 seconds
DEBUG 01-13 08:46:42.456912.456912 cuda_h.py:10] start experts_func_gpu_einsum_mp
INFO 01-13 08:46:42.456465.456465 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, f1d08a3c-24c7-4313-a333-6f0de6267dec
DEBUG 01-13 08:46:42.456116.456116 cuda_h.py:19] end load_into_gpu_async cost 0.002333402633666992 seconds
DEBUG 01-13 08:46:42.456388.456388 cuda_h.py:10] start restore_tensors2
DEBUG 01-13 08:46:42.457606.457606 cuda_h.py:19] end restore_tensors2 cost 0.00034546852111816406 seconds
DEBUG 01-13 08:46:42.457197.457197 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.004530668258666992 seconds
DEBUG 01-13 08:46:42.457582.457582 cuda_h.py:10] start restore2model
DEBUG 01-13 08:46:42.459869.459869 cuda_h.py:19] end restore2model cost 0.002599954605102539 seconds
DEBUG 01-13 08:46:42.459083.459083 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.007306098937988281 seconds
DEBUG 01-13 08:46:42.460899.460899 cuda_h.py:10] start gpu_sexperts
DEBUG 01-13 08:46:42.460160.460160 cuda_h.py:19] end gpu_sexperts cost 0.00026869773864746094 seconds
DEBUG 01-13 08:46:42.460751.460751 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-13 08:46:42.460588.460588 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.6464462280273438e-05 seconds
DEBUG 01-13 08:46:42.460237.460237 cuda_h.py:10] start wait_experts
INFO 01-13 08:46:42.460033.460033 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, f1d08a3c-24c7-4313-a333-6f0de6267dec
DEBUG 01-13 08:46:42.472758.472758 mlpmodule.py:1006] group tensors cost 0.01538395881652832 s
DEBUG 01-13 08:46:42.475954.475954 mlpmodule.py:1044] pad cost 0.001529693603515625 s
DEBUG 01-13 08:46:42.475990.475990 mlpmodule.py:1050] create cpu tensor cost 4.410743713378906e-05 s
DEBUG 01-13 08:46:42.475602.475602 mlpmodule.py:1055] move to cpu cost 3.218650817871094e-05 s
DEBUG 01-13 08:46:42.484630.484630 mlpmodule.py:1069] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-13 08:46:42.485604.485604 mlpmodule.py:1070] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-13 08:46:42.485403.485403 mlpmodule.py:1075] group_w3 first element: 0.007110595703125
WARNING 01-13 08:46:42.485343.485343 mlpmodule.py:1085] start einsum2
DEBUG 01-13 08:46:42.499819.499819 mlpmodule.py:1095] group einsum cost 0.023805618286132812 s
DEBUG 01-13 08:46:42.500851.500851 mlpmodule.py:1103] cpy2cputensor cost 0.0006844997406005859 s
INFO 01-13 08:46:42.509212.509212 client.py:127] Model loaded
DEBUG 01-13 08:46:42.509101.509101 cuda_h.py:19] end wait_experts cost 0.04926872253417969 seconds
DEBUG 01-13 08:46:42.509959.509959 cuda_h.py:10] start gpu_experts
DEBUG 01-13 08:46:42.511349.511349 mlpmodule.py:559] gpu group tensors cost 0.0015420913696289062 s
DEBUG 01-13 08:46:42.513864.513864 mlpmodule.py:785]  experts func einsum cost 0.05600166320800781 s
DEBUG 01-13 08:46:42.514292.514292 cuda_h.py:19] end experts_func_gpu_einsum_mp cost 0.057466745376586914 seconds
DEBUG 01-13 08:46:42.515333.515333 mlpmodule.py:592] gpu pad cost 0.003453969955444336 s
DEBUG 01-13 08:46:42.515144.515144 mlpmodule.py:598] start_w1
DEBUG 01-13 08:46:42.516849.516849 mlpmodule.py:602] start_w3
DEBUG 01-13 08:46:42.516074.516074 mlpmodule.py:608] start_w2
DEBUG 01-13 08:46:42.516783.516783 mlpmodule.py:611] gpu group einsum cost 0.0008990764617919922 s
DEBUG 01-13 08:46:42.518930.518930 mlpmodule.py:683] gpu experts func einsum cost 0.008631467819213867 s
DEBUG 01-13 08:46:42.518060.518060 cuda_h.py:19] end gpu_experts cost 0.008882522583007812 seconds
DEBUG 01-13 08:46:42.518962.518962 cuda_h.py:10] start cpu_thread_manager_mp_wait
DEBUG 01-13 08:46:42.518131.518131 cuda_h.py:19] end cpu_thread_manager_mp_wait cost 6.008148193359375e-05 seconds
DEBUG 01-13 08:46:42.519061.519061 cuda_h.py:19] end layer_moe_generate_mp_l_26 cost 0.068756103515625 seconds
DEBUG 01-13 08:46:42.519765.519765 lmp.py:1550] -------------------------------- end prefill layer 25 --------------------------------
DEBUG 01-13 08:46:42.519912.519912 lmp.py:1493] -------------------------------- start prefill layer 26 --------------------------------
DEBUG 01-13 08:46:42.519377.519377 cuda_h.py:10] start start_load_qkvogn_s_weight_l_27
DEBUG 01-13 08:46:42.519755.519755 cuda_h.py:10] start start_load_qkvogn_s_weight_l_27
DEBUG 01-13 08:46:42.519857.519857 cuda_h.py:19] end start_load_qkvogn_s_weight_l_27 cost 4.935264587402344e-05 seconds
DEBUG 01-13 08:46:42.519414.519414 cuda_h.py:19] end start_load_qkvogn_s_weight_l_27 cost 7.867813110351562e-05 seconds
DEBUG 01-13 08:46:42.519819.519819 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-13 08:46:42.519404.519404 cuda_h.py:10] start sllm_worker_task
DEBUG 01-13 08:46:42.519357.519357 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-13 08:46:42.519604.519604 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-13 08:46:42.519019.519019 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-13 08:46:42.520151.520151 cuda_h.py:19] end allocate_cuda_memory cost 0.0003380775451660156 seconds
DEBUG 01-13 08:46:42.520988.520988 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-13 08:46:42.520612.520612 sllm_store_c.py:27] get device uuid map
DEBUG 01-13 08:46:42.520772.520772 sllm_store_c.py:29] call client load into gpu
DEBUG 01-13 08:46:42.520714.520714 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 984b8515-e35e-4509-ae0a-21e0b112ed67
DEBUG 01-13 08:46:42.520697.520697 client.py:106] call stub.LoadModelAsync
DEBUG 01-13 08:46:42.520746.520746 cuda_h.py:10] start self_attn
INFO 01-13 08:46:42.522294.522294 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 984b8515-e35e-4509-ae0a-21e0b112ed67
DEBUG 01-13 08:46:42.522130.522130 cuda_h.py:19] end load_into_gpu_async cost 0.0018239021301269531 seconds
DEBUG 01-13 08:46:42.522972.522972 cuda_h.py:10] start restore_tensors2
DEBUG 01-13 08:46:42.522385.522385 cuda_h.py:19] end restore_tensors2 cost 6.961822509765625e-05 seconds
DEBUG 01-13 08:46:42.522234.522234 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.002505064010620117 seconds
INFO 01-13 08:46:42.522647.522647 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 984b8515-e35e-4509-ae0a-21e0b112ed67
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-13 08:46:42.523153.523153 cuda_h.py:19] end self_attn cost 0.0029778480529785156 seconds
DEBUG 01-13 08:46:42.524685.524685 cuda_h.py:19] end iln_self_attn_paln cost 0.0046842098236083984 seconds
DEBUG 01-13 08:46:42.524575.524575 cuda_h.py:10] start layer_moe_generate_mp_l_27
DEBUG 01-13 08:46:42.524430.524430 cuda_h.py:10] start gate
DEBUG 01-13 08:46:42.525607.525607 cuda_h.py:19] end gate cost 0.0006945133209228516 seconds
DEBUG 01-13 08:46:42.525483.525483 cuda_h.py:10] start experts_map_get
DEBUG 01-13 08:46:42.525082.525082 lmp.py:1611] 
DEBUG 01-13 08:46:42.525082.525082 lmp.py:1611] Expert Token Distribution & Device Allocation:
DEBUG 01-13 08:46:42.525838.525838 lmp.py:1612]   Total experts: 64
DEBUG 01-13 08:46:42.525773.525773 lmp.py:1613]   CPU experts: 32 (50%)
DEBUG 01-13 08:46:42.525846.525846 lmp.py:1614]   GPU experts: 32 (50%)
DEBUG 01-13 08:46:42.525774.525774 lmp.py:1615] 
DEBUG 01-13 08:46:42.525774.525774 lmp.py:1615]   Expert ID | Tokens | Device
DEBUG 01-13 08:46:42.525463.525463 lmp.py:1616]   -----------------------------------
DEBUG 01-13 08:46:42.525113.525113 lmp.py:1622]   Expert 20 |      7 | CPU
DEBUG 01-13 08:46:42.525518.525518 lmp.py:1622]   Expert 61 |     11 | CPU
DEBUG 01-13 08:46:42.525730.525730 lmp.py:1622]   Expert 11 |     27 | CPU
DEBUG 01-13 08:46:42.525704.525704 lmp.py:1622]   Expert  7 |     34 | CPU
DEBUG 01-13 08:46:42.525440.525440 lmp.py:1622]   Expert  3 |     38 | CPU
DEBUG 01-13 08:46:42.525698.525698 lmp.py:1622]   Expert 62 |     38 | CPU
DEBUG 01-13 08:46:42.525434.525434 lmp.py:1622]   Expert 51 |     42 | CPU
DEBUG 01-13 08:46:42.525931.525931 lmp.py:1622]   Expert 30 |     52 | CPU
DEBUG 01-13 08:46:42.525667.525667 lmp.py:1622]   Expert 17 |     57 | CPU
DEBUG 01-13 08:46:42.525926.525926 lmp.py:1622]   Expert  6 |     59 | CPU
DEBUG 01-13 08:46:42.525900.525900 lmp.py:1622]   Expert 29 |     59 | CPU
DEBUG 01-13 08:46:42.525112.525112 lmp.py:1622]   Expert  9 |     70 | CPU
DEBUG 01-13 08:46:42.525801.525801 lmp.py:1622]   Expert 63 |     77 | CPU
DEBUG 01-13 08:46:42.525014.525014 lmp.py:1622]   Expert 38 |     80 | CPU
DEBUG 01-13 08:46:42.525465.525465 lmp.py:1622]   Expert 59 |     83 | CPU
DEBUG 01-13 08:46:42.525962.525962 lmp.py:1622]   Expert 19 |     84 | CPU
DEBUG 01-13 08:46:42.525128.525128 lmp.py:1622]   Expert 55 |     84 | CPU
DEBUG 01-13 08:46:42.525579.525579 lmp.py:1622]   Expert 22 |     95 | CPU
DEBUG 01-13 08:46:42.525792.525792 lmp.py:1622]   Expert  8 |     99 | CPU
DEBUG 01-13 08:46:42.525242.525242 lmp.py:1622]   Expert 49 |    103 | CPU
DEBUG 01-13 08:46:42.525693.525693 lmp.py:1622]   Expert 48 |    105 | CPU
DEBUG 01-13 08:46:42.525144.525144 lmp.py:1622]   Expert 50 |    112 | CPU
DEBUG 01-13 08:46:42.525357.525357 lmp.py:1622]   Expert 24 |    113 | CPU
DEBUG 01-13 08:46:42.525808.525808 lmp.py:1622]   Expert 34 |    115 | CPU
DEBUG 01-13 08:46:42.525020.525020 lmp.py:1622]   Expert 36 |    116 | CPU
DEBUG 01-13 08:46:42.525186.525186 lmp.py:1622]   Expert 42 |    118 | CPU
DEBUG 01-13 08:46:42.525352.525352 lmp.py:1622]   Expert 39 |    120 | CPU
DEBUG 01-13 08:46:42.525042.525042 lmp.py:1622]   Expert  4 |    127 | CPU
DEBUG 01-13 08:46:42.525208.525208 lmp.py:1622]   Expert 37 |    141 | CPU
DEBUG 01-13 08:46:42.526374.526374 lmp.py:1622]   Expert 15 |    145 | CPU
DEBUG 01-13 08:46:42.526825.526825 lmp.py:1622]   Expert 23 |    154 | CPU
DEBUG 01-13 08:46:42.526037.526037 lmp.py:1622]   Expert 41 |    155 | CPU
DEBUG 01-13 08:46:42.526011.526011 lmp.py:1622]   Expert 16 |    165 | GPU
DEBUG 01-13 08:46:42.526462.526462 lmp.py:1622]   Expert 56 |    165 | GPU
DEBUG 01-13 08:46:42.526913.526913 lmp.py:1622]   Expert 44 |    172 | GPU
DEBUG 01-13 08:46:42.526125.526125 lmp.py:1622]   Expert  1 |    175 | GPU
DEBUG 01-13 08:46:42.526815.526815 lmp.py:1622]   Expert 60 |    176 | GPU
DEBUG 01-13 08:46:42.526266.526266 lmp.py:1622]   Expert 43 |    178 | GPU
DEBUG 01-13 08:46:42.526246.526246 lmp.py:1622]   Expert 21 |    182 | GPU
DEBUG 01-13 08:46:42.526697.526697 lmp.py:1622]   Expert 53 |    190 | GPU
DEBUG 01-13 08:46:42.526910.526910 lmp.py:1622]   Expert 47 |    200 | GPU
DEBUG 01-13 08:46:42.526122.526122 lmp.py:1622]   Expert 12 |    201 | GPU
DEBUG 01-13 08:46:42.526812.526812 lmp.py:1622]   Expert 33 |    201 | GPU
DEBUG 01-13 08:46:42.526547.526547 lmp.py:1622]   Expert 13 |    217 | GPU
DEBUG 01-13 08:46:42.526044.526044 lmp.py:1622]   Expert 32 |    219 | GPU
DEBUG 01-13 08:46:42.526065.526065 lmp.py:1622]   Expert 28 |    227 | GPU
DEBUG 01-13 08:46:42.526800.526800 lmp.py:1622]   Expert  0 |    247 | GPU
DEBUG 01-13 08:46:42.526059.526059 lmp.py:1622]   Expert 31 |    257 | GPU
DEBUG 01-13 08:46:42.526556.526556 lmp.py:1622]   Expert 54 |    257 | GPU
DEBUG 01-13 08:46:42.526815.526815 lmp.py:1622]   Expert 10 |    258 | GPU
DEBUG 01-13 08:46:42.526836.526836 lmp.py:1622]   Expert 26 |    263 | GPU
DEBUG 01-13 08:46:42.526094.526094 lmp.py:1622]   Expert 18 |    267 | GPU
DEBUG 01-13 08:46:42.526353.526353 lmp.py:1622]   Expert 57 |    274 | GPU
DEBUG 01-13 08:46:42.526327.526327 lmp.py:1622]   Expert  2 |    287 | GPU
DEBUG 01-13 08:46:42.526063.526063 lmp.py:1622]   Expert 58 |    302 | GPU
DEBUG 01-13 08:46:42.526037.526037 lmp.py:1622]   Expert 40 |    344 | GPU
DEBUG 01-13 08:46:42.526772.526772 lmp.py:1622]   Expert 45 |    360 | GPU
DEBUG 01-13 08:46:42.526508.526508 lmp.py:1622]   Expert 25 |    393 | GPU
DEBUG 01-13 08:46:42.526528.526528 lmp.py:1622]   Expert  5 |    432 | GPU
DEBUG 01-13 08:46:42.526026.526026 lmp.py:1622]   Expert 35 |    458 | GPU
DEBUG 01-13 08:46:42.526284.526284 lmp.py:1622]   Expert 27 |    476 | GPU
DEBUG 01-13 08:46:42.526305.526305 lmp.py:1622]   Expert 46 |    533 | GPU
DEBUG 01-13 08:46:42.526040.526040 lmp.py:1622]   Expert 52 |    617 | GPU
DEBUG 01-13 08:46:42.526299.526299 lmp.py:1622]   Expert 14 |    875 | GPU
DEBUG 01-13 08:46:42.526273.526273 lmp.py:1623] 
DEBUG 01-13 08:46:42.526273.526273 lmp.py:1623]   CPU total tokens: 2720 (22.1%)
DEBUG 01-13 08:46:42.526724.526724 lmp.py:1624]   GPU total tokens: 9568 (77.9%)
DEBUG 01-13 08:46:42.526467.526467 cuda_h.py:19] end experts_map_get cost 0.0014700889587402344 seconds
DEBUG 01-13 08:46:42.526177.526177 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-13 08:46:42.526126.526126 lmp.py:1632] 
DEBUG 01-13 08:46:42.526126.526126 lmp.py:1632]   Computing 32 experts on CPU MP...
DEBUG 01-13 08:46:42.526531.526531 cuda_h.py:19] end cpu_experts_submit cost 5.459785461425781e-05 seconds
DEBUG 01-13 08:46:42.526797.526797 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-13 08:46:42.526342.526342 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-13 08:46:42.526175.526175 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-13 08:46:42.528810.528810 cuda_h.py:19] end allocate_cuda_memory cost 0.0017154216766357422 seconds
DEBUG 01-13 08:46:42.528090.528090 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-13 08:46:42.528800.528800 sllm_store_c.py:27] get device uuid map
DEBUG 01-13 08:46:42.528517.528517 sllm_store_c.py:29] call client load into gpu
DEBUG 01-13 08:46:42.528882.528882 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 0b286e13-31d8-41a1-861d-844ff045a3f2
DEBUG 01-13 08:46:42.529153.529153 client.py:106] call stub.LoadModelAsync
INFO 01-13 08:46:42.529733.529733 client.py:127] Model loaded
DEBUG 01-13 08:46:42.529708.529708 cuda_h.py:10] start restore2model
DEBUG 01-13 08:46:42.530913.530913 cuda_h.py:19] end restore2model cost 0.0003643035888671875 seconds
DEBUG 01-13 08:46:42.530113.530113 cuda_h.py:19] end sllm_worker_task cost 0.010289192199707031 seconds
DEBUG 01-13 08:46:42.530304.530304 cuda_h.py:10] start experts_func_gpu_einsum_mp
INFO 01-13 08:46:42.531662.531662 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 0b286e13-31d8-41a1-861d-844ff045a3f2
DEBUG 01-13 08:46:42.531890.531890 cuda_h.py:19] end load_into_gpu_async cost 0.0022754669189453125 seconds
DEBUG 01-13 08:46:42.531261.531261 cuda_h.py:10] start restore_tensors2
DEBUG 01-13 08:46:42.531810.531810 cuda_h.py:19] end restore_tensors2 cost 0.00034356117248535156 seconds
DEBUG 01-13 08:46:42.531686.531686 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0047228336334228516 seconds
DEBUG 01-13 08:46:42.531456.531456 cuda_h.py:10] start restore2model
DEBUG 01-13 08:46:42.534644.534644 cuda_h.py:19] end restore2model cost 0.002638101577758789 seconds
DEBUG 01-13 08:46:42.534620.534620 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.007536888122558594 seconds
DEBUG 01-13 08:46:42.534746.534746 cuda_h.py:10] start gpu_sexperts
DEBUG 01-13 08:46:42.534107.534107 cuda_h.py:19] end gpu_sexperts cost 0.00027108192443847656 seconds
DEBUG 01-13 08:46:42.534957.534957 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-13 08:46:42.534164.534164 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 1.7404556274414062e-05 seconds
DEBUG 01-13 08:46:42.534098.534098 cuda_h.py:10] start wait_experts
INFO 01-13 08:46:42.534463.534463 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 0b286e13-31d8-41a1-861d-844ff045a3f2
DEBUG 01-13 08:46:42.542467.542467 mlpmodule.py:1006] group tensors cost 0.01101994514465332 s
DEBUG 01-13 08:46:42.544482.544482 mlpmodule.py:1044] pad cost 0.0019011497497558594 s
DEBUG 01-13 08:46:42.544876.544876 mlpmodule.py:1050] create cpu tensor cost 5.936622619628906e-05 s
DEBUG 01-13 08:46:42.544640.544640 mlpmodule.py:1055] move to cpu cost 3.1948089599609375e-05 s
DEBUG 01-13 08:46:42.552424.552424 mlpmodule.py:1069] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-13 08:46:42.552356.552356 mlpmodule.py:1070] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-13 08:46:42.552392.552392 mlpmodule.py:1075] group_w3 first element: -0.0024261474609375
WARNING 01-13 08:46:42.552748.552748 mlpmodule.py:1085] start einsum2
DEBUG 01-13 08:46:42.566725.566725 mlpmodule.py:1095] group einsum cost 0.021233081817626953 s
DEBUG 01-13 08:46:42.567647.567647 mlpmodule.py:1103] cpy2cputensor cost 0.0006597042083740234 s
DEBUG 01-13 08:46:42.579506.579506 mlpmodule.py:785]  experts func einsum cost 0.04801654815673828 s
DEBUG 01-13 08:46:42.579130.579130 cuda_h.py:19] end experts_func_gpu_einsum_mp cost 0.048886775970458984 seconds
INFO 01-13 08:46:42.583894.583894 client.py:127] Model loaded
DEBUG 01-13 08:46:42.583573.583573 cuda_h.py:19] end wait_experts cost 0.04915809631347656 seconds
DEBUG 01-13 08:46:42.584945.584945 cuda_h.py:10] start gpu_experts
DEBUG 01-13 08:46:42.584412.584412 mlpmodule.py:559] gpu group tensors cost 0.0006017684936523438 s
DEBUG 01-13 08:46:42.586371.586371 mlpmodule.py:592] gpu pad cost 0.0014801025390625 s
DEBUG 01-13 08:46:42.586573.586573 mlpmodule.py:598] start_w1
DEBUG 01-13 08:46:42.586697.586697 mlpmodule.py:602] start_w3
DEBUG 01-13 08:46:42.586397.586397 mlpmodule.py:608] start_w2
DEBUG 01-13 08:46:42.587661.587661 mlpmodule.py:611] gpu group einsum cost 0.0006606578826904297 s
DEBUG 01-13 08:46:42.589840.589840 mlpmodule.py:683] gpu experts func einsum cost 0.005064725875854492 s
DEBUG 01-13 08:46:42.589670.589670 cuda_h.py:19] end gpu_experts cost 0.005217075347900391 seconds
DEBUG 01-13 08:46:42.589234.589234 cuda_h.py:10] start cpu_thread_manager_mp_wait
DEBUG 01-13 08:46:42.589753.589753 cuda_h.py:19] end cpu_thread_manager_mp_wait cost 3.790855407714844e-05 seconds
DEBUG 01-13 08:46:42.589670.589670 cuda_h.py:19] end layer_moe_generate_mp_l_27 cost 0.06510281562805176 seconds
DEBUG 01-13 08:46:42.589949.589949 lmp.py:1550] -------------------------------- end prefill layer 26 --------------------------------
DEBUG 01-13 08:46:42.589328.589328 lmp.py:1493] -------------------------------- start prefill layer 27 --------------------------------
DEBUG 01-13 08:46:42.589739.589739 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-13 08:46:42.589112.589112 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-13 08:46:42.590419.590419 cuda_h.py:10] start self_attn
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-13 08:46:42.592786.592786 cuda_h.py:19] end self_attn cost 0.0026018619537353516 seconds
DEBUG 01-13 08:46:42.592736.592736 cuda_h.py:19] end iln_self_attn_paln cost 0.0032346248626708984 seconds
DEBUG 01-13 08:46:42.593764.593764 cuda_h.py:10] start layer_moe_generate_mp_l_28
DEBUG 01-13 08:46:42.593666.593666 cuda_h.py:10] start gate
DEBUG 01-13 08:46:42.593686.593686 cuda_h.py:19] end gate cost 0.0005800724029541016 seconds
DEBUG 01-13 08:46:42.593132.593132 cuda_h.py:10] start experts_map_get
DEBUG 01-13 08:46:42.594459.594459 lmp.py:1611] 
DEBUG 01-13 08:46:42.594459.594459 lmp.py:1611] Expert Token Distribution & Device Allocation:
DEBUG 01-13 08:46:42.594307.594307 lmp.py:1612]   Total experts: 64
DEBUG 01-13 08:46:42.594288.594288 lmp.py:1613]   CPU experts: 32 (50%)
DEBUG 01-13 08:46:42.594170.594170 lmp.py:1614]   GPU experts: 32 (50%)
DEBUG 01-13 08:46:42.594621.594621 lmp.py:1615] 
DEBUG 01-13 08:46:42.594621.594621 lmp.py:1615]   Expert ID | Tokens | Device
DEBUG 01-13 08:46:42.594310.594310 lmp.py:1616]   -----------------------------------
DEBUG 01-13 08:46:42.594244.594244 lmp.py:1622]   Expert 18 |     63 | CPU
DEBUG 01-13 08:46:42.594934.594934 lmp.py:1622]   Expert 54 |     65 | CPU
DEBUG 01-13 08:46:42.594431.594431 lmp.py:1622]   Expert 47 |     71 | CPU
DEBUG 01-13 08:46:42.594690.594690 lmp.py:1622]   Expert 23 |     74 | CPU
DEBUG 01-13 08:46:42.594187.594187 lmp.py:1622]   Expert 44 |     77 | CPU
DEBUG 01-13 08:46:42.594446.594446 lmp.py:1622]   Expert 45 |     80 | CPU
DEBUG 01-13 08:46:42.594943.594943 lmp.py:1622]   Expert 48 |     81 | CPU
DEBUG 01-13 08:46:42.594963.594963 lmp.py:1622]   Expert 20 |     87 | CPU
DEBUG 01-13 08:46:42.594984.594984 lmp.py:1622]   Expert 36 |     99 | CPU
DEBUG 01-13 08:46:42.594242.594242 lmp.py:1622]   Expert 31 |    101 | CPU
DEBUG 01-13 08:46:42.594501.594501 lmp.py:1622]   Expert 61 |    110 | CPU
DEBUG 01-13 08:46:42.594813.594813 lmp.py:1622]   Expert 42 |    114 | CPU
DEBUG 01-13 08:46:42.594787.594787 lmp.py:1622]   Expert 33 |    117 | CPU
DEBUG 01-13 08:46:42.594761.594761 lmp.py:1622]   Expert 43 |    121 | CPU
DEBUG 01-13 08:46:42.594974.594974 lmp.py:1622]   Expert 11 |    123 | CPU
DEBUG 01-13 08:46:42.594994.594994 lmp.py:1622]   Expert 24 |    125 | CPU
DEBUG 01-13 08:46:42.594538.594538 lmp.py:1622]   Expert 10 |    127 | CPU
DEBUG 01-13 08:46:42.594081.594081 lmp.py:1622]   Expert 56 |    131 | CPU
DEBUG 01-13 08:46:42.594340.594340 lmp.py:1622]   Expert 49 |    133 | CPU
DEBUG 01-13 08:46:42.594122.594122 lmp.py:1622]   Expert  6 |    135 | CPU
DEBUG 01-13 08:46:42.594904.594904 lmp.py:1622]   Expert  0 |    143 | CPU
DEBUG 01-13 08:46:42.594447.594447 lmp.py:1622]   Expert 51 |    144 | CPU
DEBUG 01-13 08:46:42.594229.594229 lmp.py:1622]   Expert  5 |    152 | CPU
DEBUG 01-13 08:46:42.594011.594011 lmp.py:1622]   Expert 40 |    154 | CPU
DEBUG 01-13 08:46:42.594032.594032 lmp.py:1622]   Expert 17 |    155 | CPU
DEBUG 01-13 08:46:42.594529.594529 lmp.py:1622]   Expert 12 |    159 | CPU
DEBUG 01-13 08:46:42.594026.594026 lmp.py:1622]   Expert 55 |    162 | CPU
DEBUG 01-13 08:46:42.594000.594000 lmp.py:1622]   Expert 59 |    162 | CPU
DEBUG 01-13 08:46:42.594736.594736 lmp.py:1622]   Expert 57 |    165 | CPU
DEBUG 01-13 08:46:42.594187.594187 lmp.py:1622]   Expert 26 |    167 | CPU
DEBUG 01-13 08:46:42.594969.594969 lmp.py:1622]   Expert 13 |    170 | CPU
DEBUG 01-13 08:46:42.594750.594750 lmp.py:1622]   Expert 38 |    171 | CPU
DEBUG 01-13 08:46:42.594532.594532 lmp.py:1622]   Expert 30 |    174 | GPU
DEBUG 01-13 08:46:42.594076.594076 lmp.py:1622]   Expert  7 |    176 | GPU
DEBUG 01-13 08:46:42.594858.594858 lmp.py:1622]   Expert 46 |    178 | GPU
DEBUG 01-13 08:46:42.594117.594117 lmp.py:1622]   Expert 58 |    178 | GPU
DEBUG 01-13 08:46:42.594137.594137 lmp.py:1622]   Expert 35 |    179 | GPU
DEBUG 01-13 08:46:42.594919.594919 lmp.py:1622]   Expert 16 |    188 | GPU
DEBUG 01-13 08:46:42.594939.594939 lmp.py:1622]   Expert 50 |    192 | GPU
DEBUG 01-13 08:46:42.594437.594437 lmp.py:1622]   Expert 15 |    202 | GPU
DEBUG 01-13 08:46:42.594172.594172 lmp.py:1622]   Expert 32 |    203 | GPU
DEBUG 01-13 08:46:42.594146.594146 lmp.py:1622]   Expert 14 |    204 | GPU
DEBUG 01-13 08:46:42.594643.594643 lmp.py:1622]   Expert  3 |    214 | GPU
DEBUG 01-13 08:46:42.594141.594141 lmp.py:1622]   Expert  1 |    216 | GPU
DEBUG 01-13 08:46:42.594923.594923 lmp.py:1622]   Expert  4 |    222 | GPU
DEBUG 01-13 08:46:42.594181.594181 lmp.py:1622]   Expert 39 |    235 | GPU
DEBUG 01-13 08:46:42.594725.594725 lmp.py:1622]   Expert 52 |    237 | GPU
DEBUG 01-13 08:46:42.594745.594745 lmp.py:1622]   Expert 34 |    246 | GPU
DEBUG 01-13 08:46:42.594004.594004 lmp.py:1622]   Expert 28 |    248 | GPU
DEBUG 01-13 08:46:42.594786.594786 lmp.py:1622]   Expert 25 |    250 | GPU
DEBUG 01-13 08:46:42.594568.594568 lmp.py:1622]   Expert 22 |    262 | GPU
DEBUG 01-13 08:46:42.594588.594588 lmp.py:1622]   Expert 41 |    273 | GPU
DEBUG 01-13 08:46:42.594370.594370 lmp.py:1622]   Expert 21 |    276 | GPU
DEBUG 01-13 08:46:42.594152.594152 lmp.py:1622]   Expert  2 |    283 | GPU
DEBUG 01-13 08:46:42.594888.594888 lmp.py:1622]   Expert 29 |    284 | GPU
DEBUG 01-13 08:46:42.594147.594147 lmp.py:1622]   Expert 63 |    288 | GPU
DEBUG 01-13 08:46:42.594359.594359 lmp.py:1622]   Expert 60 |    290 | GPU
DEBUG 01-13 08:46:42.595095.595095 lmp.py:1622]   Expert 62 |    300 | GPU
DEBUG 01-13 08:46:42.595830.595830 lmp.py:1622]   Expert 27 |    305 | GPU
DEBUG 01-13 08:46:42.595851.595851 lmp.py:1622]   Expert  8 |    329 | GPU
DEBUG 01-13 08:46:42.595394.595394 lmp.py:1622]   Expert 53 |    329 | GPU
DEBUG 01-13 08:46:42.595938.595938 lmp.py:1622]   Expert 37 |    337 | GPU
DEBUG 01-13 08:46:42.595720.595720 lmp.py:1622]   Expert 19 |    437 | GPU
DEBUG 01-13 08:46:42.595263.595263 lmp.py:1622]   Expert  9 |    615 | GPU
DEBUG 01-13 08:46:42.595999.595999 lmp.py:1623] 
DEBUG 01-13 08:46:42.595999.595999 lmp.py:1623]   CPU total tokens: 3938 (32.0%)
DEBUG 01-13 08:46:42.595450.595450 lmp.py:1624]   GPU total tokens: 8350 (68.0%)
DEBUG 01-13 08:46:42.595477.595477 cuda_h.py:19] end experts_map_get cost 0.0013871192932128906 seconds
DEBUG 01-13 08:46:42.595056.595056 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-13 08:46:42.595858.595858 lmp.py:1632] 
DEBUG 01-13 08:46:42.595858.595858 lmp.py:1632]   Computing 32 experts on CPU MP...
DEBUG 01-13 08:46:42.595549.595549 cuda_h.py:19] end cpu_experts_submit cost 5.269050598144531e-05 seconds
DEBUG 01-13 08:46:42.595099.595099 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-13 08:46:42.595458.595458 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-13 08:46:42.595537.595537 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-13 08:46:42.595252.595252 cuda_h.py:19] end allocate_cuda_memory cost 0.0003521442413330078 seconds
DEBUG 01-13 08:46:42.596570.596570 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-13 08:46:42.596638.596638 sllm_store_c.py:27] get device uuid map
DEBUG 01-13 08:46:42.596129.596129 sllm_store_c.py:29] call client load into gpu
DEBUG 01-13 08:46:42.596832.596832 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 3d28e6a7-20d0-41d2-9409-ed14830cfffa
DEBUG 01-13 08:46:42.596740.596740 client.py:106] call stub.LoadModelAsync
DEBUG 01-13 08:46:42.597315.597315 cuda_h.py:10] start experts_func_gpu_einsum_mp
INFO 01-13 08:46:42.598680.598680 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 3d28e6a7-20d0-41d2-9409-ed14830cfffa
DEBUG 01-13 08:46:42.598278.598278 cuda_h.py:19] end load_into_gpu_async cost 0.0025200843811035156 seconds
DEBUG 01-13 08:46:42.598312.598312 cuda_h.py:10] start restore_tensors2
DEBUG 01-13 08:46:42.599238.599238 cuda_h.py:19] end restore_tensors2 cost 0.00034165382385253906 seconds
DEBUG 01-13 08:46:42.599260.599260 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.003922700881958008 seconds
DEBUG 01-13 08:46:42.599645.599645 cuda_h.py:10] start restore2model
DEBUG 01-13 08:46:42.602184.602184 cuda_h.py:19] end restore2model cost 0.0026161670684814453 seconds
DEBUG 01-13 08:46:42.602159.602159 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.006730318069458008 seconds
DEBUG 01-13 08:46:42.602306.602306 cuda_h.py:10] start gpu_sexperts
DEBUG 01-13 08:46:42.602985.602985 cuda_h.py:19] end gpu_sexperts cost 0.0002605915069580078 seconds
DEBUG 01-13 08:46:42.602145.602145 cuda_h.py:10] start wait_experts
INFO 01-13 08:46:42.602054.602054 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 3d28e6a7-20d0-41d2-9409-ed14830cfffa
DEBUG 01-13 08:46:42.603985.603985 mlpmodule.py:1006] group tensors cost 0.00559687614440918 s
DEBUG 01-13 08:46:42.606757.606757 mlpmodule.py:1044] pad cost 0.0028409957885742188 s
DEBUG 01-13 08:46:42.607438.607438 mlpmodule.py:1050] create cpu tensor cost 7.104873657226562e-05 s
DEBUG 01-13 08:46:42.607050.607050 mlpmodule.py:1055] move to cpu cost 5.078315734863281e-05 s
DEBUG 01-13 08:46:42.615666.615666 mlpmodule.py:1069] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-13 08:46:42.615030.615030 mlpmodule.py:1070] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-13 08:46:42.615763.615763 mlpmodule.py:1075] group_w3 first element: -0.006439208984375
WARNING 01-13 08:46:42.615093.615093 mlpmodule.py:1085] start einsum2
DEBUG 01-13 08:46:42.629319.629319 mlpmodule.py:1095] group einsum cost 0.02218341827392578 s
DEBUG 01-13 08:46:42.630251.630251 mlpmodule.py:1103] cpy2cputensor cost 0.0006892681121826172 s
DEBUG 01-13 08:46:42.648001.648001 mlpmodule.py:785]  experts func einsum cost 0.051216840744018555 s
DEBUG 01-13 08:46:42.649961.649961 cuda_h.py:19] end experts_func_gpu_einsum_mp cost 0.0523838996887207 seconds
INFO 01-13 08:46:42.651504.651504 client.py:127] Model loaded
DEBUG 01-13 08:46:42.651787.651787 cuda_h.py:19] end wait_experts cost 0.04898977279663086 seconds
DEBUG 01-13 08:46:42.651397.651397 cuda_h.py:10] start gpu_experts
DEBUG 01-13 08:46:42.652108.652108 mlpmodule.py:559] gpu group tensors cost 0.0005731582641601562 s
DEBUG 01-13 08:46:42.653964.653964 mlpmodule.py:592] gpu pad cost 0.001552581787109375 s
DEBUG 01-13 08:46:42.653556.653556 mlpmodule.py:598] start_w1
DEBUG 01-13 08:46:42.654004.654004 mlpmodule.py:602] start_w3
DEBUG 01-13 08:46:42.654083.654083 mlpmodule.py:608] start_w2
DEBUG 01-13 08:46:42.654916.654916 mlpmodule.py:611] gpu group einsum cost 0.0006544589996337891 s
DEBUG 01-13 08:46:42.656086.656086 mlpmodule.py:683] gpu experts func einsum cost 0.005052804946899414 s
DEBUG 01-13 08:46:42.656500.656500 cuda_h.py:19] end gpu_experts cost 0.005213737487792969 seconds
DEBUG 01-13 08:46:42.656395.656395 cuda_h.py:10] start cpu_thread_manager_mp_wait
DEBUG 01-13 08:46:42.656921.656921 cuda_h.py:19] end cpu_thread_manager_mp_wait cost 4.0531158447265625e-05 seconds
DEBUG 01-13 08:46:42.656221.656221 cuda_h.py:19] end layer_moe_generate_mp_l_28 cost 0.06386041641235352 seconds
DEBUG 01-13 08:46:42.657957.657957 lmp.py:1550] -------------------------------- end prefill layer 27 --------------------------------
DEBUG 01-13 08:46:42.657972.657972 cuda_h.py:19] end prefill_layer cost 1.9238200187683105 seconds
DEBUG 01-13 08:46:44.828946.828946 cuda_h.py:10] start generate_input_ids
generate input ids cost 0.08942794799804688 s
DEBUG 01-13 08:46:45.196874.196874 cuda_h.py:19] end generate_input_ids cost 0.3589131832122803 seconds
DEBUG 01-13 08:46:45.196112.196112 cuda_h.py:10] start init_cache
DEBUG 01-13 08:46:45.197023.197023 cuda_h.py:19] end init_cache cost 6.771087646484375e-05 seconds
DEBUG 01-13 08:46:47.547245.547245 cuda_h.py:10] start init_meta_layer
DEBUG 01-13 08:46:47.549094.549094 cuda_h.py:19] end init_meta_layer cost 1.239776611328125e-05 seconds
DEBUG 01-13 08:46:47.549894.549894 cuda_h.py:10] start init_weights
DEBUG 01-13 08:46:47.549326.549326 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-13 08:46:47.549280.549280 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-13 08:46:47.551740.551740 cuda_h.py:19] end allocate_cuda_memory cost 0.0020296573638916016 seconds
DEBUG 01-13 08:46:47.552113.552113 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-13 08:46:47.552392.552392 sllm_store_c.py:27] get device uuid map
DEBUG 01-13 08:46:47.552785.552785 sllm_store_c.py:29] call client load into gpu
DEBUG 01-13 08:46:47.552865.552865 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, b5e64490-d679-4413-b9b2-4054212f5e16
DEBUG 01-13 08:46:47.552033.552033 client.py:106] call stub.LoadModelAsync
INFO 01-13 08:46:47.554998.554998 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, b5e64490-d679-4413-b9b2-4054212f5e16
DEBUG 01-13 08:46:47.554834.554834 cuda_h.py:19] end load_into_gpu_async cost 0.0021169185638427734 seconds
DEBUG 01-13 08:46:47.554935.554935 cuda_h.py:10] start restore_tensors2
DEBUG 01-13 08:46:47.554176.554176 cuda_h.py:19] end restore_tensors2 cost 4.887580871582031e-05 seconds
DEBUG 01-13 08:46:47.554402.554402 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0044231414794921875 seconds
DEBUG 01-13 08:46:47.554859.554859 cuda_h.py:10] start restore2model
DEBUG 01-13 08:46:47.554349.554349 cuda_h.py:19] end restore2model cost 0.00016236305236816406 seconds
INFO 01-13 08:46:47.554582.554582 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, b5e64490-d679-4413-b9b2-4054212f5e16
INFO 01-13 08:46:47.633893.633893 client.py:127] Model loaded
DEBUG 01-13 08:46:47.633355.633355 cuda_h.py:10] start load_qkvogns_weight_l_0
DEBUG 01-13 08:46:47.633717.633717 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-13 08:46:47.633794.633794 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-13 08:46:47.634447.634447 cuda_h.py:19] end allocate_cuda_memory cost 0.0004229545593261719 seconds
DEBUG 01-13 08:46:47.634412.634412 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-13 08:46:47.634859.634859 sllm_store_c.py:27] get device uuid map
DEBUG 01-13 08:46:47.634279.634279 sllm_store_c.py:29] call client load into gpu
DEBUG 01-13 08:46:47.634706.634706 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, effe337d-c4ae-4f41-8d95-71f6975976bc
DEBUG 01-13 08:46:47.634036.634036 client.py:106] call stub.LoadModelAsync
INFO 01-13 08:46:47.636672.636672 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, effe337d-c4ae-4f41-8d95-71f6975976bc
DEBUG 01-13 08:46:47.636493.636493 cuda_h.py:19] end load_into_gpu_async cost 0.002112150192260742 seconds
DEBUG 01-13 08:46:47.636680.636680 cuda_h.py:10] start restore_tensors2
DEBUG 01-13 08:46:47.636211.636211 cuda_h.py:19] end restore_tensors2 cost 0.0001456737518310547 seconds
DEBUG 01-13 08:46:47.636326.636326 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.003283977508544922 seconds
INFO 01-13 08:46:47.637183.637183 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, effe337d-c4ae-4f41-8d95-71f6975976bc
INFO 01-13 08:46:47.651920.651920 client.py:127] Model loaded
DEBUG 01-13 08:46:47.652269.652269 cuda_h.py:10] start restore2model
DEBUG 01-13 08:46:47.653548.653548 cuda_h.py:19] end restore2model cost 0.0009248256683349609 seconds
DEBUG 01-13 08:46:47.653916.653916 cuda_h.py:19] end load_qkvogns_weight_l_0 cost 0.019634723663330078 seconds
DEBUG 01-13 08:46:47.653032.653032 cuda_h.py:19] end init_weights cost 0.10336160659790039 seconds
DEBUG 01-13 08:46:47.653835.653835 cuda_h.py:10] start copy_emodel
DEBUG 01-13 08:46:48.384773.384773 cuda_h.py:19] end copy_emodel cost 0.7306575775146484 seconds
DEBUG 01-13 08:46:48.384045.384045 cuda_h.py:10] start init_inputs_tokens
DEBUG 01-13 08:46:48.385514.385514 cuda_h.py:19] end init_inputs_tokens cost 0.000286102294921875 seconds
DEBUG 01-13 08:46:48.385290.385290 cuda_h.py:10] start prefill_layer
DEBUG 01-13 08:46:48.385861.385861 lmp.py:1493] -------------------------------- start prefill layer 0 --------------------------------
DEBUG 01-13 08:46:48.385987.385987 cuda_h.py:10] start start_load_qkvogn_s_weight_l_1
DEBUG 01-13 08:46:48.385783.385783 cuda_h.py:10] start start_load_qkvogn_s_weight_l_1
DEBUG 01-13 08:46:48.385295.385295 cuda_h.py:19] end start_load_qkvogn_s_weight_l_1 cost 3.457069396972656e-05 seconds
DEBUG 01-13 08:46:48.385375.385375 cuda_h.py:19] end start_load_qkvogn_s_weight_l_1 cost 6.508827209472656e-05 seconds
DEBUG 01-13 08:46:48.385780.385780 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-13 08:46:48.385523.385523 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-13 08:46:48.385970.385970 cuda_h.py:10] start sllm_worker_task
DEBUG 01-13 08:46:48.385829.385829 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-13 08:46:48.385348.385348 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-13 08:46:48.386284.386284 cuda_h.py:19] end allocate_cuda_memory cost 0.00022363662719726562 seconds
DEBUG 01-13 08:46:48.386622.386622 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-13 08:46:48.386551.386551 sllm_store_c.py:27] get device uuid map
DEBUG 01-13 08:46:48.386023.386023 sllm_store_c.py:29] call client load into gpu
DEBUG 01-13 08:46:48.386548.386548 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, ebedd259-cffd-4d77-b4c3-24a11bcfcc35
DEBUG 01-13 08:46:48.386797.386797 client.py:106] call stub.LoadModelAsync
DEBUG 01-13 08:46:48.386515.386515 cuda_h.py:10] start self_attn
INFO 01-13 08:46:48.388739.388739 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, ebedd259-cffd-4d77-b4c3-24a11bcfcc35
DEBUG 01-13 08:46:48.388127.388127 cuda_h.py:19] end load_into_gpu_async cost 0.0021851062774658203 seconds
DEBUG 01-13 08:46:48.388619.388619 cuda_h.py:10] start restore_tensors2
DEBUG 01-13 08:46:48.388386.388386 cuda_h.py:19] end restore_tensors2 cost 9.703636169433594e-05 seconds
DEBUG 01-13 08:46:48.388502.388502 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0030481815338134766 seconds
INFO 01-13 08:46:48.388307.388307 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, ebedd259-cffd-4d77-b4c3-24a11bcfcc35
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-13 08:46:48.390488.390488 cuda_h.py:19] end self_attn cost 0.0034942626953125 seconds
DEBUG 01-13 08:46:48.390698.390698 cuda_h.py:19] end iln_self_attn_paln cost 0.005458354949951172 seconds
DEBUG 01-13 08:46:48.390574.390574 cuda_h.py:10] start dense_mlp
INFO 01-13 08:46:48.397129.397129 client.py:127] Model loaded
DEBUG 01-13 08:46:48.397224.397224 cuda_h.py:10] start restore2model
DEBUG 01-13 08:46:48.398776.398776 cuda_h.py:19] end restore2model cost 0.0005898475646972656 seconds
DEBUG 01-13 08:46:48.398018.398018 cuda_h.py:19] end sllm_worker_task cost 0.012567758560180664 seconds
DEBUG 01-13 08:46:48.398686.398686 cuda_h.py:19] end dense_mlp cost 0.0074405670166015625 seconds
DEBUG 01-13 08:46:48.398903.398903 lmp.py:1550] -------------------------------- end prefill layer 0 --------------------------------
DEBUG 01-13 08:46:48.398700.398700 lmp.py:1493] -------------------------------- start prefill layer 1 --------------------------------
DEBUG 01-13 08:46:48.398099.398099 cuda_h.py:10] start start_load_qkvogn_s_weight_l_2
DEBUG 01-13 08:46:48.398843.398843 cuda_h.py:10] start start_load_qkvogn_s_weight_l_2
DEBUG 01-13 08:46:48.398150.398150 cuda_h.py:19] end start_load_qkvogn_s_weight_l_2 cost 3.504753112792969e-05 seconds
DEBUG 01-13 08:46:48.398841.398841 cuda_h.py:19] end start_load_qkvogn_s_weight_l_2 cost 9.274482727050781e-05 seconds
DEBUG 01-13 08:46:48.398941.398941 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-13 08:46:48.399593.399593 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-13 08:46:48.399113.399113 cuda_h.py:10] start sllm_worker_task
DEBUG 01-13 08:46:48.399349.399349 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-13 08:46:48.399021.399021 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-13 08:46:48.399679.399679 cuda_h.py:19] end allocate_cuda_memory cost 0.00034499168395996094 seconds
DEBUG 01-13 08:46:48.400956.400956 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-13 08:46:48.400880.400880 sllm_store_c.py:27] get device uuid map
DEBUG 01-13 08:46:48.400924.400924 sllm_store_c.py:29] call client load into gpu
DEBUG 01-13 08:46:48.400470.400470 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, a875db12-6060-43ca-a55e-c61320cca8fa
DEBUG 01-13 08:46:48.400211.400211 client.py:106] call stub.LoadModelAsync
DEBUG 01-13 08:46:48.400605.400605 cuda_h.py:10] start self_attn
INFO 01-13 08:46:48.401055.401055 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, a875db12-6060-43ca-a55e-c61320cca8fa
DEBUG 01-13 08:46:48.402417.402417 cuda_h.py:19] end load_into_gpu_async cost 0.001971721649169922 seconds
DEBUG 01-13 08:46:48.402181.402181 cuda_h.py:10] start restore_tensors2
DEBUG 01-13 08:46:48.402698.402698 cuda_h.py:19] end restore_tensors2 cost 0.00013136863708496094 seconds
DEBUG 01-13 08:46:48.402005.402005 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0031120777130126953 seconds
INFO 01-13 08:46:48.402891.402891 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, a875db12-6060-43ca-a55e-c61320cca8fa
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-13 08:46:48.406435.406435 cuda_h.py:19] end self_attn cost 0.005108833312988281 seconds
DEBUG 01-13 08:46:48.406591.406591 cuda_h.py:19] end iln_self_attn_paln cost 0.007483720779418945 seconds
DEBUG 01-13 08:46:48.406012.406012 cuda_h.py:10] start layer_moe_generate_mp_l_2
DEBUG 01-13 08:46:48.406100.406100 cuda_h.py:10] start gate
DEBUG 01-13 08:46:48.407158.407158 cuda_h.py:19] end gate cost 0.0010623931884765625 seconds
DEBUG 01-13 08:46:48.407273.407273 cuda_h.py:10] start experts_map_get
DEBUG 01-13 08:46:48.408625.408625 lmp.py:1611] 
DEBUG 01-13 08:46:48.408625.408625 lmp.py:1611] Expert Token Distribution & Device Allocation:
DEBUG 01-13 08:46:48.408680.408680 lmp.py:1612]   Total experts: 64
DEBUG 01-13 08:46:48.408111.408111 lmp.py:1613]   CPU experts: 32 (50%)
DEBUG 01-13 08:46:48.408430.408430 lmp.py:1614]   GPU experts: 32 (50%)
DEBUG 01-13 08:46:48.408888.408888 lmp.py:1615] 
DEBUG 01-13 08:46:48.408888.408888 lmp.py:1615]   Expert ID | Tokens | Device
DEBUG 01-13 08:46:48.408345.408345 lmp.py:1616]   -----------------------------------
DEBUG 01-13 08:46:48.408717.408717 lmp.py:1622]   Expert 25 |     64 | CPU
DEBUG 01-13 08:46:48.408890.408890 lmp.py:1622]   Expert 54 |     67 | CPU
DEBUG 01-13 08:46:48.408348.408348 lmp.py:1622]   Expert  3 |     68 | CPU
DEBUG 01-13 08:46:48.408805.408805 lmp.py:1622]   Expert 31 |     72 | CPU
DEBUG 01-13 08:46:48.408786.408786 lmp.py:1622]   Expert 55 |     72 | CPU
DEBUG 01-13 08:46:48.408767.408767 lmp.py:1622]   Expert 62 |     87 | CPU
DEBUG 01-13 08:46:48.408986.408986 lmp.py:1622]   Expert 18 |     88 | CPU
DEBUG 01-13 08:46:48.408206.408206 lmp.py:1622]   Expert 52 |     98 | CPU
DEBUG 01-13 08:46:48.408140.408140 lmp.py:1622]   Expert 22 |    100 | CPU
DEBUG 01-13 08:46:48.408598.408598 lmp.py:1622]   Expert 47 |    104 | CPU
DEBUG 01-13 08:46:48.408771.408771 lmp.py:1622]   Expert  0 |    113 | CPU
DEBUG 01-13 08:46:48.408990.408990 lmp.py:1622]   Expert 37 |    117 | CPU
DEBUG 01-13 08:46:48.408786.408786 lmp.py:1622]   Expert 27 |    121 | CPU
DEBUG 01-13 08:46:48.408528.408528 lmp.py:1622]   Expert 32 |    123 | CPU
DEBUG 01-13 08:46:48.408032.408032 lmp.py:1622]   Expert 41 |    130 | CPU
DEBUG 01-13 08:46:48.408490.408490 lmp.py:1622]   Expert 44 |    131 | CPU
DEBUG 01-13 08:46:48.408470.408470 lmp.py:1622]   Expert 28 |    136 | CPU
DEBUG 01-13 08:46:48.408974.408974 lmp.py:1622]   Expert 13 |    138 | CPU
DEBUG 01-13 08:46:48.408717.408717 lmp.py:1622]   Expert 58 |    140 | CPU
DEBUG 01-13 08:46:48.408459.408459 lmp.py:1622]   Expert 60 |    144 | CPU
DEBUG 01-13 08:46:48.408977.408977 lmp.py:1622]   Expert 43 |    147 | CPU
DEBUG 01-13 08:46:48.408004.408004 lmp.py:1622]   Expert  1 |    150 | CPU
DEBUG 01-13 08:46:48.408985.408985 lmp.py:1622]   Expert 38 |    153 | CPU
DEBUG 01-13 08:46:48.408535.408535 lmp.py:1622]   Expert 49 |    154 | CPU
DEBUG 01-13 08:46:48.409086.409086 lmp.py:1622]   Expert 51 |    155 | CPU
DEBUG 01-13 08:46:48.409874.409874 lmp.py:1622]   Expert 34 |    161 | CPU
DEBUG 01-13 08:46:48.409186.409186 lmp.py:1622]   Expert 35 |    164 | CPU
DEBUG 01-13 08:46:48.409975.409975 lmp.py:1622]   Expert 36 |    168 | CPU
DEBUG 01-13 08:46:48.409048.409048 lmp.py:1622]   Expert 11 |    170 | CPU
DEBUG 01-13 08:46:48.409599.409599 lmp.py:1622]   Expert 17 |    170 | CPU
DEBUG 01-13 08:46:48.409626.409626 lmp.py:1622]   Expert 59 |    174 | CPU
DEBUG 01-13 08:46:48.409938.409938 lmp.py:1622]   Expert 10 |    180 | CPU
DEBUG 01-13 08:46:48.409680.409680 lmp.py:1622]   Expert 20 |    182 | GPU
DEBUG 01-13 08:46:48.409946.409946 lmp.py:1622]   Expert  2 |    186 | GPU
DEBUG 01-13 08:46:48.409973.409973 lmp.py:1622]   Expert 39 |    189 | GPU
DEBUG 01-13 08:46:48.409523.409523 lmp.py:1622]   Expert 33 |    197 | GPU
DEBUG 01-13 08:46:48.409074.409074 lmp.py:1622]   Expert 12 |    198 | GPU
DEBUG 01-13 08:46:48.409624.409624 lmp.py:1622]   Expert 21 |    198 | GPU
DEBUG 01-13 08:46:48.409697.409697 lmp.py:1622]   Expert 48 |    198 | GPU
DEBUG 01-13 08:46:48.409771.409771 lmp.py:1622]   Expert 15 |    199 | GPU
DEBUG 01-13 08:46:48.409036.409036 lmp.py:1622]   Expert 53 |    204 | GPU
DEBUG 01-13 08:46:48.409540.409540 lmp.py:1622]   Expert 19 |    220 | GPU
DEBUG 01-13 08:46:48.409283.409283 lmp.py:1622]   Expert 26 |    221 | GPU
DEBUG 01-13 08:46:48.409502.409502 lmp.py:1622]   Expert 30 |    221 | GPU
DEBUG 01-13 08:46:48.409814.409814 lmp.py:1622]   Expert 45 |    221 | GPU
DEBUG 01-13 08:46:48.409126.409126 lmp.py:1622]   Expert  5 |    227 | GPU
DEBUG 01-13 08:46:48.409438.409438 lmp.py:1622]   Expert  4 |    229 | GPU
DEBUG 01-13 08:46:48.409750.409750 lmp.py:1622]   Expert 24 |    229 | GPU
DEBUG 01-13 08:46:48.409585.409585 lmp.py:1622]   Expert 42 |    242 | GPU
DEBUG 01-13 08:46:48.409658.409658 lmp.py:1622]   Expert 50 |    245 | GPU
DEBUG 01-13 08:46:48.409732.409732 lmp.py:1622]   Expert 29 |    254 | GPU
DEBUG 01-13 08:46:48.409805.409805 lmp.py:1622]   Expert 56 |    262 | GPU
DEBUG 01-13 08:46:48.409832.409832 lmp.py:1622]   Expert 61 |    270 | GPU
DEBUG 01-13 08:46:48.409860.409860 lmp.py:1622]   Expert  8 |    283 | GPU
DEBUG 01-13 08:46:48.409125.409125 lmp.py:1622]   Expert 63 |    285 | GPU
DEBUG 01-13 08:46:48.409676.409676 lmp.py:1622]   Expert 46 |    294 | GPU
DEBUG 01-13 08:46:48.409987.409987 lmp.py:1622]   Expert  9 |    300 | GPU
DEBUG 01-13 08:46:48.409299.409299 lmp.py:1622]   Expert  6 |    316 | GPU
DEBUG 01-13 08:46:48.409896.409896 lmp.py:1622]   Expert 16 |    316 | GPU
DEBUG 01-13 08:46:48.409969.409969 lmp.py:1622]   Expert 40 |    319 | GPU
DEBUG 01-13 08:46:48.409281.409281 lmp.py:1622]   Expert  7 |    322 | GPU
DEBUG 01-13 08:46:48.409355.409355 lmp.py:1622]   Expert 23 |    325 | GPU
DEBUG 01-13 08:46:48.409428.409428 lmp.py:1622]   Expert 14 |    413 | GPU
DEBUG 01-13 08:46:48.409932.409932 lmp.py:1622]   Expert 57 |    464 | GPU
DEBUG 01-13 08:46:48.409489.409489 lmp.py:1623] 
DEBUG 01-13 08:46:48.409489.409489 lmp.py:1623]   CPU total tokens: 4059 (33.0%)
DEBUG 01-13 08:46:48.409331.409331 lmp.py:1624]   GPU total tokens: 8229 (67.0%)
DEBUG 01-13 08:46:48.409749.409749 cuda_h.py:19] end experts_map_get cost 0.001917123794555664 seconds
INFO 01-13 08:46:48.409132.409132 client.py:127] Model loaded
DEBUG 01-13 08:46:48.410242.410242 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-13 08:46:48.410105.410105 cuda_h.py:10] start restore2model
DEBUG 01-13 08:46:48.410133.410133 lmp.py:1632] 
DEBUG 01-13 08:46:48.410133.410133 lmp.py:1632]   Computing 32 experts on CPU MP...
DEBUG 01-13 08:46:48.410917.410917 cuda_h.py:19] end cpu_experts_submit cost 0.0002658367156982422 seconds
DEBUG 01-13 08:46:48.410242.410242 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-13 08:46:48.410039.410039 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-13 08:46:48.410998.410998 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-13 08:46:48.410913.410913 cuda_h.py:19] end allocate_cuda_memory cost 0.00021409988403320312 seconds
DEBUG 01-13 08:46:48.411955.411955 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-13 08:46:48.411764.411764 sllm_store_c.py:27] get device uuid map
DEBUG 01-13 08:46:48.411296.411296 sllm_store_c.py:29] call client load into gpu
DEBUG 01-13 08:46:48.411999.411999 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 473c9a17-f38c-487c-9b89-cccb1c627755
DEBUG 01-13 08:46:48.411496.411496 client.py:106] call stub.LoadModelAsync
DEBUG 01-13 08:46:48.412703.412703 cuda_h.py:19] end restore2model cost 0.0020568370819091797 seconds
DEBUG 01-13 08:46:48.412078.412078 cuda_h.py:19] end sllm_worker_task cost 0.013670206069946289 seconds
INFO 01-13 08:46:48.413972.413972 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 473c9a17-f38c-487c-9b89-cccb1c627755
DEBUG 01-13 08:46:48.413497.413497 cuda_h.py:19] end load_into_gpu_async cost 0.00250244140625 seconds
DEBUG 01-13 08:46:48.413399.413399 cuda_h.py:10] start restore_tensors2
DEBUG 01-13 08:46:48.414220.414220 cuda_h.py:10] start experts_func_gpu_einsum_mp
DEBUG 01-13 08:46:48.414109.414109 cuda_h.py:19] end restore_tensors2 cost 0.00041484832763671875 seconds
DEBUG 01-13 08:46:48.414193.414193 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.003976583480834961 seconds
DEBUG 01-13 08:46:48.414678.414678 cuda_h.py:10] start restore2model
DEBUG 01-13 08:46:48.417291.417291 cuda_h.py:19] end restore2model cost 0.003224611282348633 seconds
DEBUG 01-13 08:46:48.417525.417525 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.007414102554321289 seconds
DEBUG 01-13 08:46:48.418373.418373 cuda_h.py:10] start gpu_sexperts
DEBUG 01-13 08:46:48.418358.418358 cuda_h.py:19] end gpu_sexperts cost 0.00030732154846191406 seconds
DEBUG 01-13 08:46:48.418088.418088 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-13 08:46:48.418619.418619 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 1.4543533325195312e-05 seconds
DEBUG 01-13 08:46:48.418885.418885 cuda_h.py:10] start wait_experts
INFO 01-13 08:46:48.418912.418912 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 473c9a17-f38c-487c-9b89-cccb1c627755
DEBUG 01-13 08:46:48.427692.427692 mlpmodule.py:1006] group tensors cost 0.011664867401123047 s
DEBUG 01-13 08:46:48.430290.430290 mlpmodule.py:1044] pad cost 0.002155303955078125 s
DEBUG 01-13 08:46:48.430050.430050 mlpmodule.py:1050] create cpu tensor cost 6.365776062011719e-05 s
DEBUG 01-13 08:46:48.430232.430232 mlpmodule.py:1055] move to cpu cost 4.887580871582031e-05 s
DEBUG 01-13 08:46:48.444227.444227 mlpmodule.py:1069] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-13 08:46:48.444276.444276 mlpmodule.py:1070] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-13 08:46:48.445003.445003 mlpmodule.py:1075] group_w3 first element: -0.0107421875
WARNING 01-13 08:46:48.445042.445042 mlpmodule.py:1085] start einsum2
DEBUG 01-13 08:46:48.457983.457983 mlpmodule.py:1095] group einsum cost 0.027283906936645508 s
DEBUG 01-13 08:46:48.458582.458582 mlpmodule.py:1103] cpy2cputensor cost 0.0006630420684814453 s
INFO 01-13 08:46:48.464179.464179 client.py:127] Model loaded
DEBUG 01-13 08:46:48.464980.464980 cuda_h.py:19] end wait_experts cost 0.04570913314819336 seconds
DEBUG 01-13 08:46:48.464173.464173 cuda_h.py:10] start gpu_experts
DEBUG 01-13 08:46:48.465779.465779 mlpmodule.py:559] gpu group tensors cost 0.0015518665313720703 s
DEBUG 01-13 08:46:48.467841.467841 mlpmodule.py:592] gpu pad cost 0.001949310302734375 s
DEBUG 01-13 08:46:48.468128.468128 mlpmodule.py:598] start_w1
DEBUG 01-13 08:46:48.468067.468067 mlpmodule.py:602] start_w3
DEBUG 01-13 08:46:48.468914.468914 mlpmodule.py:608] start_w2
DEBUG 01-13 08:46:48.468687.468687 mlpmodule.py:611] gpu group einsum cost 0.0008645057678222656 s
DEBUG 01-13 08:46:48.471722.471722 mlpmodule.py:683] gpu experts func einsum cost 0.007174253463745117 s
DEBUG 01-13 08:46:48.471851.471851 cuda_h.py:19] end gpu_experts cost 0.007349729537963867 seconds
DEBUG 01-13 08:46:48.471375.471375 cuda_h.py:10] start cpu_thread_manager_mp_wait
DEBUG 01-13 08:46:48.471245.471245 cuda_h.py:19] end cpu_thread_manager_mp_wait cost 4.553794860839844e-05 seconds
DEBUG 01-13 08:46:48.471645.471645 cuda_h.py:19] end layer_moe_generate_mp_l_2 cost 0.06516075134277344 seconds
DEBUG 01-13 08:46:48.472038.472038 lmp.py:1550] -------------------------------- end prefill layer 1 --------------------------------
DEBUG 01-13 08:46:48.472192.472192 lmp.py:1493] -------------------------------- start prefill layer 2 --------------------------------
DEBUG 01-13 08:46:48.472041.472041 cuda_h.py:10] start start_load_qkvogn_s_weight_l_3
DEBUG 01-13 08:46:48.472373.472373 cuda_h.py:10] start start_load_qkvogn_s_weight_l_3
DEBUG 01-13 08:46:48.472283.472283 cuda_h.py:19] end start_load_qkvogn_s_weight_l_3 cost 4.267692565917969e-05 seconds
DEBUG 01-13 08:46:48.472277.472277 cuda_h.py:19] end start_load_qkvogn_s_weight_l_3 cost 7.677078247070312e-05 seconds
DEBUG 01-13 08:46:48.472880.472880 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-13 08:46:48.472777.472777 cuda_h.py:10] start sllm_worker_task
DEBUG 01-13 08:46:48.472356.472356 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-13 08:46:48.472531.472531 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-13 08:46:48.472929.472929 cuda_h.py:19] end allocate_cuda_memory cost 0.0001842975616455078 seconds
DEBUG 01-13 08:46:48.472495.472495 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-13 08:46:48.472385.472385 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-13 08:46:48.473381.473381 sllm_store_c.py:27] get device uuid map
DEBUG 01-13 08:46:48.473396.473396 sllm_store_c.py:29] call client load into gpu
DEBUG 01-13 08:46:48.473159.473159 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 116577b8-8e37-42ae-aff4-f47ba6218ab5
DEBUG 01-13 08:46:48.473420.473420 client.py:106] call stub.LoadModelAsync
DEBUG 01-13 08:46:48.473078.473078 cuda_h.py:10] start self_attn
INFO 01-13 08:46:48.474673.474673 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 116577b8-8e37-42ae-aff4-f47ba6218ab5
DEBUG 01-13 08:46:48.474562.474562 cuda_h.py:19] end load_into_gpu_async cost 0.0016427040100097656 seconds
DEBUG 01-13 08:46:48.474642.474642 cuda_h.py:10] start restore_tensors2
DEBUG 01-13 08:46:48.474248.474248 cuda_h.py:19] end restore_tensors2 cost 7.05718994140625e-05 seconds
DEBUG 01-13 08:46:48.474527.474527 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.002305746078491211 seconds
INFO 01-13 08:46:48.474463.474463 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 116577b8-8e37-42ae-aff4-f47ba6218ab5
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-13 08:46:48.476096.476096 cuda_h.py:19] end self_attn cost 0.003041505813598633 seconds
DEBUG 01-13 08:46:48.476901.476901 cuda_h.py:19] end iln_self_attn_paln cost 0.004547834396362305 seconds
DEBUG 01-13 08:46:48.476268.476268 cuda_h.py:10] start layer_moe_generate_mp_l_3
DEBUG 01-13 08:46:48.476408.476408 cuda_h.py:10] start gate
DEBUG 01-13 08:46:48.477093.477093 cuda_h.py:19] end gate cost 0.0006477832794189453 seconds
DEBUG 01-13 08:46:48.477161.477161 cuda_h.py:10] start experts_map_get
DEBUG 01-13 08:46:48.478674.478674 lmp.py:1611] 
DEBUG 01-13 08:46:48.478674.478674 lmp.py:1611] Expert Token Distribution & Device Allocation:
DEBUG 01-13 08:46:48.478953.478953 lmp.py:1612]   Total experts: 64
DEBUG 01-13 08:46:48.478603.478603 lmp.py:1613]   CPU experts: 32 (50%)
DEBUG 01-13 08:46:48.478630.478630 lmp.py:1614]   GPU experts: 32 (50%)
DEBUG 01-13 08:46:48.478797.478797 lmp.py:1615] 
DEBUG 01-13 08:46:48.478797.478797 lmp.py:1615]   Expert ID | Tokens | Device
DEBUG 01-13 08:46:48.478976.478976 lmp.py:1616]   -----------------------------------
DEBUG 01-13 08:46:48.478911.478911 lmp.py:1622]   Expert 58 |     54 | CPU
DEBUG 01-13 08:46:48.478077.478077 lmp.py:1622]   Expert 27 |     58 | CPU
DEBUG 01-13 08:46:48.478766.478766 lmp.py:1622]   Expert  3 |     68 | CPU
DEBUG 01-13 08:46:48.478409.478409 lmp.py:1622]   Expert 17 |     84 | CPU
DEBUG 01-13 08:46:48.478337.478337 lmp.py:1622]   Expert  0 |     87 | CPU
DEBUG 01-13 08:46:48.478026.478026 lmp.py:1622]   Expert 24 |     87 | CPU
DEBUG 01-13 08:46:48.478146.478146 lmp.py:1622]   Expert 28 |    101 | CPU
DEBUG 01-13 08:46:48.478312.478312 lmp.py:1622]   Expert 34 |    113 | CPU
DEBUG 01-13 08:46:48.478478.478478 lmp.py:1622]   Expert 51 |    114 | CPU
DEBUG 01-13 08:46:48.478929.478929 lmp.py:1622]   Expert 32 |    119 | CPU
DEBUG 01-13 08:46:48.478380.478380 lmp.py:1622]   Expert  9 |    122 | CPU
DEBUG 01-13 08:46:48.478069.478069 lmp.py:1622]   Expert 15 |    135 | CPU
DEBUG 01-13 08:46:48.478759.478759 lmp.py:1622]   Expert  7 |    136 | CPU
DEBUG 01-13 08:46:48.478210.478210 lmp.py:1622]   Expert 23 |    136 | CPU
DEBUG 01-13 08:46:48.478422.478422 lmp.py:1622]   Expert 26 |    136 | CPU
DEBUG 01-13 08:46:48.478111.478111 lmp.py:1622]   Expert 30 |    145 | CPU
DEBUG 01-13 08:46:48.478324.478324 lmp.py:1622]   Expert 45 |    146 | CPU
DEBUG 01-13 08:46:48.478536.478536 lmp.py:1622]   Expert 57 |    147 | CPU
DEBUG 01-13 08:46:48.478987.478987 lmp.py:1622]   Expert 62 |    150 | CPU
DEBUG 01-13 08:46:48.478915.478915 lmp.py:1622]   Expert  1 |    153 | CPU
DEBUG 01-13 08:46:48.478558.478558 lmp.py:1622]   Expert 36 |    157 | CPU
DEBUG 01-13 08:46:48.478962.478962 lmp.py:1622]   Expert 29 |    160 | CPU
DEBUG 01-13 08:46:48.478367.478367 lmp.py:1622]   Expert  8 |    162 | CPU
DEBUG 01-13 08:46:48.478056.478056 lmp.py:1622]   Expert 25 |    164 | CPU
DEBUG 01-13 08:46:48.478746.478746 lmp.py:1622]   Expert 35 |    171 | CPU
DEBUG 01-13 08:46:48.478196.478196 lmp.py:1622]   Expert  6 |    172 | CPU
DEBUG 01-13 08:46:48.478409.478409 lmp.py:1622]   Expert 49 |    173 | CPU
DEBUG 01-13 08:46:48.478098.478098 lmp.py:1622]   Expert 54 |    173 | CPU
DEBUG 01-13 08:46:48.478549.478549 lmp.py:1622]   Expert 48 |    174 | CPU
DEBUG 01-13 08:46:48.478762.478762 lmp.py:1622]   Expert 37 |    177 | CPU
DEBUG 01-13 08:46:48.478736.478736 lmp.py:1622]   Expert 12 |    178 | CPU
DEBUG 01-13 08:46:48.478186.478186 lmp.py:1622]   Expert 13 |    186 | CPU
DEBUG 01-13 08:46:48.478876.478876 lmp.py:1622]   Expert 53 |    189 | GPU
DEBUG 01-13 08:46:48.478803.478803 lmp.py:1622]   Expert 60 |    189 | GPU
DEBUG 01-13 08:46:48.478208.478208 lmp.py:1622]   Expert 10 |    190 | GPU
DEBUG 01-13 08:46:48.478897.478897 lmp.py:1622]   Expert 33 |    190 | GPU
DEBUG 01-13 08:46:48.478302.478302 lmp.py:1622]   Expert 21 |    192 | GPU
DEBUG 01-13 08:46:48.478991.478991 lmp.py:1622]   Expert 16 |    201 | GPU
DEBUG 01-13 08:46:48.478204.478204 lmp.py:1622]   Expert 40 |    201 | GPU
DEBUG 01-13 08:46:48.478655.478655 lmp.py:1622]   Expert 38 |    203 | GPU
DEBUG 01-13 08:46:48.478867.478867 lmp.py:1622]   Expert 43 |    205 | GPU
DEBUG 01-13 08:46:48.478556.478556 lmp.py:1622]   Expert  5 |    208 | GPU
DEBUG 01-13 08:46:48.478769.478769 lmp.py:1622]   Expert 44 |    213 | GPU
DEBUG 01-13 08:46:48.478981.478981 lmp.py:1622]   Expert 52 |    216 | GPU
DEBUG 01-13 08:46:48.478432.478432 lmp.py:1622]   Expert  4 |    219 | GPU
DEBUG 01-13 08:46:48.478645.478645 lmp.py:1622]   Expert 19 |    219 | GPU
DEBUG 01-13 08:46:48.478811.478811 lmp.py:1622]   Expert 50 |    219 | GPU
DEBUG 01-13 08:46:48.478215.478215 lmp.py:1622]   Expert 59 |    220 | GPU
DEBUG 01-13 08:46:48.478620.478620 lmp.py:1622]   Expert 41 |    222 | GPU
DEBUG 01-13 08:46:48.478071.478071 lmp.py:1622]   Expert 55 |    231 | GPU
DEBUG 01-13 08:46:48.479522.479522 lmp.py:1622]   Expert 31 |    240 | GPU
DEBUG 01-13 08:46:48.479972.479972 lmp.py:1622]   Expert 56 |    245 | GPU
DEBUG 01-13 08:46:48.479423.479423 lmp.py:1622]   Expert 20 |    254 | GPU
DEBUG 01-13 08:46:48.479397.479397 lmp.py:1622]   Expert 39 |    254 | GPU
DEBUG 01-13 08:46:48.479087.479087 lmp.py:1622]   Expert  2 |    262 | GPU
DEBUG 01-13 08:46:48.479776.479776 lmp.py:1622]   Expert 22 |    265 | GPU
DEBUG 01-13 08:46:48.479465.479465 lmp.py:1622]   Expert 63 |    276 | GPU
DEBUG 01-13 08:46:48.479439.479439 lmp.py:1622]   Expert 47 |    278 | GPU
DEBUG 01-13 08:46:48.479844.479844 lmp.py:1622]   Expert 42 |    302 | GPU
DEBUG 01-13 08:46:48.479248.479248 lmp.py:1622]   Expert 18 |    315 | GPU
DEBUG 01-13 08:46:48.479653.479653 lmp.py:1622]   Expert 14 |    318 | GPU
DEBUG 01-13 08:46:48.479819.479819 lmp.py:1622]   Expert 46 |    366 | GPU
DEBUG 01-13 08:46:48.479508.479508 lmp.py:1622]   Expert 11 |    384 | GPU
DEBUG 01-13 08:46:48.479959.479959 lmp.py:1622]   Expert 61 |    464 | GPU
DEBUG 01-13 08:46:48.479364.479364 lmp.py:1623] 
DEBUG 01-13 08:46:48.479364.479364 lmp.py:1623]   CPU total tokens: 4338 (35.3%)
DEBUG 01-13 08:46:48.479007.479007 lmp.py:1624]   GPU total tokens: 7950 (64.7%)
DEBUG 01-13 08:46:48.479703.479703 cuda_h.py:19] end experts_map_get cost 0.0015306472778320312 seconds
DEBUG 01-13 08:46:48.479692.479692 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-13 08:46:48.479971.479971 lmp.py:1632] 
DEBUG 01-13 08:46:48.479971.479971 lmp.py:1632]   Computing 32 experts on CPU MP...
DEBUG 01-13 08:46:48.479277.479277 cuda_h.py:19] end cpu_experts_submit cost 5.030632019042969e-05 seconds
DEBUG 01-13 08:46:48.479066.479066 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-13 08:46:48.479571.479571 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-13 08:46:48.479113.479113 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-13 08:46:48.480029.480029 mlpmodule.py:785]  experts func einsum cost 0.06509971618652344 s
DEBUG 01-13 08:46:48.480022.480022 cuda_h.py:19] end experts_func_gpu_einsum_mp cost 0.06630468368530273 seconds
DEBUG 01-13 08:46:48.481438.481438 cuda_h.py:19] end allocate_cuda_memory cost 0.0013644695281982422 seconds
DEBUG 01-13 08:46:48.481537.481537 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-13 08:46:48.481015.481015 sllm_store_c.py:27] get device uuid map
DEBUG 01-13 08:46:48.481023.481023 sllm_store_c.py:29] call client load into gpu
DEBUG 01-13 08:46:48.481865.481865 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 99561484-7e35-4757-870b-f882d25dfd28
DEBUG 01-13 08:46:48.481606.481606 client.py:106] call stub.LoadModelAsync
DEBUG 01-13 08:46:48.482210.482210 cuda_h.py:10] start experts_func_gpu_einsum_mp
INFO 01-13 08:46:48.482047.482047 client.py:127] Model loaded
DEBUG 01-13 08:46:48.482731.482731 cuda_h.py:10] start restore2model
DEBUG 01-13 08:46:48.483836.483836 cuda_h.py:19] end restore2model cost 0.0003273487091064453 seconds
DEBUG 01-13 08:46:48.483698.483698 cuda_h.py:19] end sllm_worker_task cost 0.010797262191772461 seconds
INFO 01-13 08:46:48.484497.484497 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 99561484-7e35-4757-870b-f882d25dfd28
DEBUG 01-13 08:46:48.484247.484247 cuda_h.py:19] end load_into_gpu_async cost 0.0029783248901367188 seconds
DEBUG 01-13 08:46:48.484665.484665 cuda_h.py:10] start restore_tensors2
DEBUG 01-13 08:46:48.484064.484064 cuda_h.py:19] end restore_tensors2 cost 0.0004074573516845703 seconds
DEBUG 01-13 08:46:48.484569.484569 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.005435466766357422 seconds
DEBUG 01-13 08:46:48.485047.485047 cuda_h.py:10] start restore2model
DEBUG 01-13 08:46:48.487375.487375 cuda_h.py:19] end restore2model cost 0.002635478973388672 seconds
DEBUG 01-13 08:46:48.487357.487357 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.008269309997558594 seconds
DEBUG 01-13 08:46:48.487437.487437 cuda_h.py:10] start gpu_sexperts
DEBUG 01-13 08:46:48.488129.488129 cuda_h.py:19] end gpu_sexperts cost 0.0002703666687011719 seconds
DEBUG 01-13 08:46:48.488959.488959 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-13 08:46:48.488066.488066 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 1.52587890625e-05 seconds
DEBUG 01-13 08:46:48.488762.488762 cuda_h.py:10] start wait_experts
INFO 01-13 08:46:48.488889.488889 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 99561484-7e35-4757-870b-f882d25dfd28
DEBUG 01-13 08:46:48.488024.488024 mlpmodule.py:1006] group tensors cost 0.00539708137512207 s
DEBUG 01-13 08:46:48.490127.490127 mlpmodule.py:1044] pad cost 0.0015382766723632812 s
DEBUG 01-13 08:46:48.490183.490183 mlpmodule.py:1050] create cpu tensor cost 5.984306335449219e-05 s
DEBUG 01-13 08:46:48.490795.490795 mlpmodule.py:1055] move to cpu cost 3.0994415283203125e-05 s
DEBUG 01-13 08:46:48.500309.500309 mlpmodule.py:1069] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-13 08:46:48.501094.501094 mlpmodule.py:1070] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-13 08:46:48.501360.501360 mlpmodule.py:1075] group_w3 first element: -0.0380859375
WARNING 01-13 08:46:48.501548.501548 mlpmodule.py:1085] start einsum2
DEBUG 01-13 08:46:48.515221.515221 mlpmodule.py:1095] group einsum cost 0.02469801902770996 s
DEBUG 01-13 08:46:48.516757.516757 mlpmodule.py:1103] cpy2cputensor cost 0.0007529258728027344 s
INFO 01-13 08:46:48.535417.535417 client.py:127] Model loaded
DEBUG 01-13 08:46:48.535276.535276 cuda_h.py:19] end wait_experts cost 0.04735398292541504 seconds
DEBUG 01-13 08:46:48.535946.535946 cuda_h.py:10] start gpu_experts
DEBUG 01-13 08:46:48.536950.536950 mlpmodule.py:559] gpu group tensors cost 0.0006108283996582031 s
DEBUG 01-13 08:46:48.537877.537877 mlpmodule.py:592] gpu pad cost 0.0014948844909667969 s
DEBUG 01-13 08:46:48.537528.537528 mlpmodule.py:598] start_w1
DEBUG 01-13 08:46:48.538762.538762 mlpmodule.py:602] start_w3
DEBUG 01-13 08:46:48.538642.538642 mlpmodule.py:608] start_w2
DEBUG 01-13 08:46:48.538465.538465 mlpmodule.py:611] gpu group einsum cost 0.0008966922760009766 s
DEBUG 01-13 08:46:48.539500.539500 mlpmodule.py:785]  experts func einsum cost 0.05681610107421875 s
DEBUG 01-13 08:46:48.540076.540076 cuda_h.py:19] end experts_func_gpu_einsum_mp cost 0.0579981803894043 seconds
DEBUG 01-13 08:46:48.540283.540283 mlpmodule.py:683] gpu experts func einsum cost 0.005213260650634766 s
DEBUG 01-13 08:46:48.540875.540875 cuda_h.py:19] end gpu_experts cost 0.0053653717041015625 seconds
DEBUG 01-13 08:46:48.541770.541770 cuda_h.py:10] start cpu_thread_manager_mp_wait
DEBUG 01-13 08:46:48.541210.541210 cuda_h.py:19] end cpu_thread_manager_mp_wait cost 5.14984130859375e-05 seconds
DEBUG 01-13 08:46:48.541603.541603 cuda_h.py:19] end layer_moe_generate_mp_l_3 cost 0.0641927719116211 seconds
DEBUG 01-13 08:46:48.541571.541571 lmp.py:1550] -------------------------------- end prefill layer 2 --------------------------------
DEBUG 01-13 08:46:48.541533.541533 lmp.py:1493] -------------------------------- start prefill layer 3 --------------------------------
DEBUG 01-13 08:46:48.541375.541375 cuda_h.py:10] start start_load_qkvogn_s_weight_l_4
DEBUG 01-13 08:46:48.541885.541885 cuda_h.py:10] start start_load_qkvogn_s_weight_l_4
DEBUG 01-13 08:46:48.541953.541953 cuda_h.py:19] end start_load_qkvogn_s_weight_l_4 cost 2.765655517578125e-05 seconds
DEBUG 01-13 08:46:48.541816.541816 cuda_h.py:19] end start_load_qkvogn_s_weight_l_4 cost 6.937980651855469e-05 seconds
DEBUG 01-13 08:46:48.541220.541220 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-13 08:46:48.541401.541401 cuda_h.py:10] start sllm_worker_task
DEBUG 01-13 08:46:48.541246.541246 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-13 08:46:48.541784.541784 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-13 08:46:48.541829.541829 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-13 08:46:48.542036.542036 cuda_h.py:19] end allocate_cuda_memory cost 0.00020956993103027344 seconds
DEBUG 01-13 08:46:48.542735.542735 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-13 08:46:48.542127.542127 sllm_store_c.py:27] get device uuid map
DEBUG 01-13 08:46:48.542500.542500 sllm_store_c.py:29] call client load into gpu
DEBUG 01-13 08:46:48.542813.542813 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 94bd8a4d-ae7f-4c1d-b5a6-6abbb6e3b656
DEBUG 01-13 08:46:48.542955.542955 client.py:106] call stub.LoadModelAsync
DEBUG 01-13 08:46:48.542836.542836 cuda_h.py:10] start self_attn
INFO 01-13 08:46:48.543984.543984 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 94bd8a4d-ae7f-4c1d-b5a6-6abbb6e3b656
DEBUG 01-13 08:46:48.543457.543457 cuda_h.py:19] end load_into_gpu_async cost 0.0015408992767333984 seconds
DEBUG 01-13 08:46:48.543120.543120 cuda_h.py:10] start restore_tensors2
DEBUG 01-13 08:46:48.544899.544899 cuda_h.py:19] end restore_tensors2 cost 8.225440979003906e-05 seconds
DEBUG 01-13 08:46:48.544967.544967 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0021657943725585938 seconds
INFO 01-13 08:46:48.544048.544048 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 94bd8a4d-ae7f-4c1d-b5a6-6abbb6e3b656
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-13 08:46:48.545492.545492 cuda_h.py:19] end self_attn cost 0.0029151439666748047 seconds
DEBUG 01-13 08:46:48.546761.546761 cuda_h.py:19] end iln_self_attn_paln cost 0.0044422149658203125 seconds
DEBUG 01-13 08:46:48.546219.546219 cuda_h.py:10] start layer_moe_generate_mp_l_4
DEBUG 01-13 08:46:48.546883.546883 cuda_h.py:10] start gate
DEBUG 01-13 08:46:48.546203.546203 cuda_h.py:19] end gate cost 0.0006246566772460938 seconds
DEBUG 01-13 08:46:48.546555.546555 cuda_h.py:10] start experts_map_get
DEBUG 01-13 08:46:48.547194.547194 lmp.py:1611] 
DEBUG 01-13 08:46:48.547194.547194 lmp.py:1611] Expert Token Distribution & Device Allocation:
DEBUG 01-13 08:46:48.547235.547235 lmp.py:1612]   Total experts: 64
DEBUG 01-13 08:46:48.547885.547885 lmp.py:1613]   CPU experts: 32 (50%)
DEBUG 01-13 08:46:48.547720.547720 lmp.py:1614]   GPU experts: 32 (50%)
DEBUG 01-13 08:46:48.547125.547125 lmp.py:1615] 
DEBUG 01-13 08:46:48.547125.547125 lmp.py:1615]   Expert ID | Tokens | Device
DEBUG 01-13 08:46:48.547768.547768 lmp.py:1616]   -----------------------------------
DEBUG 01-13 08:46:48.547133.547133 lmp.py:1622]   Expert  1 |     44 | CPU
DEBUG 01-13 08:46:48.547299.547299 lmp.py:1622]   Expert 27 |     60 | CPU
DEBUG 01-13 08:46:48.547511.547511 lmp.py:1622]   Expert  7 |     80 | CPU
DEBUG 01-13 08:46:48.547247.547247 lmp.py:1622]   Expert 48 |     81 | CPU
DEBUG 01-13 08:46:48.547221.547221 lmp.py:1622]   Expert 15 |     97 | CPU
DEBUG 01-13 08:46:48.547956.547956 lmp.py:1622]   Expert 30 |    112 | CPU
DEBUG 01-13 08:46:48.547692.547692 lmp.py:1622]   Expert 32 |    116 | CPU
DEBUG 01-13 08:46:48.547189.547189 lmp.py:1622]   Expert 45 |    116 | CPU
DEBUG 01-13 08:46:48.547925.547925 lmp.py:1622]   Expert 61 |    116 | CPU
DEBUG 01-13 08:46:48.547422.547422 lmp.py:1622]   Expert 18 |    120 | CPU
DEBUG 01-13 08:46:48.547396.547396 lmp.py:1622]   Expert 34 |    133 | CPU
DEBUG 01-13 08:46:48.547847.547847 lmp.py:1622]   Expert 39 |    135 | CPU
DEBUG 01-13 08:46:48.547298.547298 lmp.py:1622]   Expert  5 |    137 | CPU
DEBUG 01-13 08:46:48.547510.547510 lmp.py:1622]   Expert 11 |    139 | CPU
DEBUG 01-13 08:46:48.547630.547630 lmp.py:1622]   Expert 26 |    139 | CPU
DEBUG 01-13 08:46:48.547320.547320 lmp.py:1622]   Expert 36 |    140 | CPU
DEBUG 01-13 08:46:48.547770.547770 lmp.py:1622]   Expert 59 |    141 | CPU
DEBUG 01-13 08:46:48.547983.547983 lmp.py:1622]   Expert  6 |    142 | CPU
DEBUG 01-13 08:46:48.547195.547195 lmp.py:1622]   Expert 51 |    149 | CPU
DEBUG 01-13 08:46:48.547646.547646 lmp.py:1622]   Expert 49 |    155 | CPU
DEBUG 01-13 08:46:48.547097.547097 lmp.py:1622]   Expert 23 |    157 | CPU
DEBUG 01-13 08:46:48.547786.547786 lmp.py:1622]   Expert  2 |    158 | CPU
DEBUG 01-13 08:46:48.547476.547476 lmp.py:1622]   Expert  9 |    161 | CPU
DEBUG 01-13 08:46:48.547688.547688 lmp.py:1622]   Expert 50 |    164 | CPU
DEBUG 01-13 08:46:48.547901.547901 lmp.py:1622]   Expert 52 |    165 | CPU
DEBUG 01-13 08:46:48.547113.547113 lmp.py:1622]   Expert 56 |    167 | CPU
DEBUG 01-13 08:46:48.547564.547564 lmp.py:1622]   Expert 35 |    171 | CPU
DEBUG 01-13 08:46:48.547253.547253 lmp.py:1622]   Expert 40 |    171 | CPU
DEBUG 01-13 08:46:48.547135.547135 lmp.py:1622]   Expert 16 |    173 | CPU
DEBUG 01-13 08:46:48.547539.547539 lmp.py:1622]   Expert 37 |    186 | CPU
DEBUG 01-13 08:46:48.547705.547705 lmp.py:1622]   Expert 42 |    187 | CPU
DEBUG 01-13 08:46:48.547110.547110 lmp.py:1622]   Expert  4 |    188 | CPU
DEBUG 01-13 08:46:48.547038.547038 lmp.py:1622]   Expert 13 |    191 | GPU
DEBUG 01-13 08:46:48.547250.547250 lmp.py:1622]   Expert 17 |    194 | GPU
DEBUG 01-13 08:46:48.547463.547463 lmp.py:1622]   Expert 62 |    195 | GPU
DEBUG 01-13 08:46:48.547913.547913 lmp.py:1622]   Expert 38 |    196 | GPU
DEBUG 01-13 08:46:48.547126.547126 lmp.py:1622]   Expert 21 |    204 | GPU
DEBUG 01-13 08:46:48.547577.547577 lmp.py:1622]   Expert 28 |    208 | GPU
DEBUG 01-13 08:46:48.547028.547028 lmp.py:1622]   Expert 44 |    210 | GPU
DEBUG 01-13 08:46:48.547002.547002 lmp.py:1622]   Expert 58 |    210 | GPU
DEBUG 01-13 08:46:48.547453.547453 lmp.py:1622]   Expert  3 |    211 | GPU
DEBUG 01-13 08:46:48.547903.547903 lmp.py:1622]   Expert 10 |    211 | GPU
DEBUG 01-13 08:46:48.547593.547593 lmp.py:1622]   Expert 53 |    214 | GPU
DEBUG 01-13 08:46:48.547520.547520 lmp.py:1622]   Expert 60 |    215 | GPU
DEBUG 01-13 08:46:48.548971.548971 lmp.py:1622]   Expert 47 |    217 | GPU
DEBUG 01-13 08:46:48.548376.548376 lmp.py:1622]   Expert 55 |    220 | GPU
DEBUG 01-13 08:46:48.548542.548542 lmp.py:1622]   Expert 20 |    223 | GPU
DEBUG 01-13 08:46:48.548993.548993 lmp.py:1622]   Expert 57 |    226 | GPU
DEBUG 01-13 08:46:48.548682.548682 lmp.py:1622]   Expert 33 |    235 | GPU
DEBUG 01-13 08:46:48.548656.548656 lmp.py:1622]   Expert 46 |    235 | GPU
DEBUG 01-13 08:46:48.548107.548107 lmp.py:1622]   Expert 31 |    238 | GPU
DEBUG 01-13 08:46:48.548320.548320 lmp.py:1622]   Expert  8 |    240 | GPU
DEBUG 01-13 08:46:48.548294.548294 lmp.py:1622]   Expert 24 |    243 | GPU
DEBUG 01-13 08:46:48.548506.548506 lmp.py:1622]   Expert 19 |    245 | GPU
DEBUG 01-13 08:46:48.548719.548719 lmp.py:1622]   Expert 63 |    264 | GPU
DEBUG 01-13 08:46:48.548693.548693 lmp.py:1622]   Expert 14 |    270 | GPU
DEBUG 01-13 08:46:48.548620.548620 lmp.py:1622]   Expert 29 |    275 | GPU
DEBUG 01-13 08:46:48.548310.548310 lmp.py:1622]   Expert 12 |    277 | GPU
DEBUG 01-13 08:46:48.548999.548999 lmp.py:1622]   Expert 22 |    277 | GPU
DEBUG 01-13 08:46:48.548404.548404 lmp.py:1622]   Expert  0 |    289 | GPU
DEBUG 01-13 08:46:48.548093.548093 lmp.py:1622]   Expert 43 |    314 | GPU
DEBUG 01-13 08:46:48.548305.548305 lmp.py:1622]   Expert 54 |    346 | GPU
DEBUG 01-13 08:46:48.548518.548518 lmp.py:1622]   Expert 41 |    382 | GPU
DEBUG 01-13 08:46:48.548730.548730 lmp.py:1622]   Expert 25 |    413 | GPU
DEBUG 01-13 08:46:48.548135.548135 lmp.py:1623] 
DEBUG 01-13 08:46:48.548135.548135 lmp.py:1623]   CPU total tokens: 4400 (35.8%)
DEBUG 01-13 08:46:48.548539.548539 lmp.py:1624]   GPU total tokens: 7888 (64.2%)
DEBUG 01-13 08:46:48.548534.548534 cuda_h.py:19] end experts_map_get cost 0.001491546630859375 seconds
DEBUG 01-13 08:46:48.548238.548238 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-13 08:46:48.548848.548848 lmp.py:1632] 
DEBUG 01-13 08:46:48.548848.548848 lmp.py:1632]   Computing 32 experts on CPU MP...
DEBUG 01-13 08:46:48.548962.548962 cuda_h.py:19] end cpu_experts_submit cost 4.982948303222656e-05 seconds
DEBUG 01-13 08:46:48.548156.548156 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-13 08:46:48.548555.548555 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-13 08:46:48.548870.548870 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-13 08:46:48.550410.550410 cuda_h.py:19] end allocate_cuda_memory cost 0.0014536380767822266 seconds
DEBUG 01-13 08:46:48.550128.550128 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-13 08:46:48.550930.550930 sllm_store_c.py:27] get device uuid map
DEBUG 01-13 08:46:48.550468.550468 sllm_store_c.py:29] call client load into gpu
DEBUG 01-13 08:46:48.550740.550740 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 81632679-d1b9-4f5a-8427-97857592a4d3
DEBUG 01-13 08:46:48.550177.550177 client.py:106] call stub.LoadModelAsync
INFO 01-13 08:46:48.551380.551380 client.py:127] Model loaded
DEBUG 01-13 08:46:48.551812.551812 cuda_h.py:10] start restore2model
DEBUG 01-13 08:46:48.551043.551043 cuda_h.py:10] start experts_func_gpu_einsum_mp
DEBUG 01-13 08:46:48.552370.552370 cuda_h.py:19] end restore2model cost 0.0005688667297363281 seconds
DEBUG 01-13 08:46:48.552319.552319 cuda_h.py:19] end sllm_worker_task cost 0.010832071304321289 seconds
INFO 01-13 08:46:48.552508.552508 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 81632679-d1b9-4f5a-8427-97857592a4d3
DEBUG 01-13 08:46:48.552927.552927 cuda_h.py:19] end load_into_gpu_async cost 0.0024869441986083984 seconds
DEBUG 01-13 08:46:48.552392.552392 cuda_h.py:10] start restore_tensors2
DEBUG 01-13 08:46:48.553062.553062 cuda_h.py:19] end restore_tensors2 cost 0.0003979206085205078 seconds
DEBUG 01-13 08:46:48.553851.553851 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.004690647125244141 seconds
DEBUG 01-13 08:46:48.553475.553475 cuda_h.py:10] start restore2model
DEBUG 01-13 08:46:48.556770.556770 cuda_h.py:19] end restore2model cost 0.002646923065185547 seconds
DEBUG 01-13 08:46:48.556805.556805 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.007515668869018555 seconds
DEBUG 01-13 08:46:48.556429.556429 cuda_h.py:10] start gpu_sexperts
DEBUG 01-13 08:46:48.556195.556195 cuda_h.py:19] end gpu_sexperts cost 0.0002887248992919922 seconds
DEBUG 01-13 08:46:48.556793.556793 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-13 08:46:48.556807.556807 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 1.52587890625e-05 seconds
DEBUG 01-13 08:46:48.556219.556219 cuda_h.py:10] start wait_experts
INFO 01-13 08:46:48.556061.556061 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 81632679-d1b9-4f5a-8427-97857592a4d3
DEBUG 01-13 08:46:48.560387.560387 mlpmodule.py:1006] group tensors cost 0.008069992065429688 s
DEBUG 01-13 08:46:48.566197.566197 mlpmodule.py:1044] pad cost 0.004856586456298828 s
DEBUG 01-13 08:46:48.567461.567461 mlpmodule.py:1050] create cpu tensor cost 9.107589721679688e-05 s
DEBUG 01-13 08:46:48.567307.567307 mlpmodule.py:1055] move to cpu cost 6.151199340820312e-05 s
DEBUG 01-13 08:46:48.575945.575945 mlpmodule.py:1069] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-13 08:46:48.576376.576376 mlpmodule.py:1070] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-13 08:46:48.576831.576831 mlpmodule.py:1075] group_w3 first element: -0.054931640625
WARNING 01-13 08:46:48.576056.576056 mlpmodule.py:1085] start einsum2
DEBUG 01-13 08:46:48.589811.589811 mlpmodule.py:1095] group einsum cost 0.022059202194213867 s
DEBUG 01-13 08:46:48.590753.590753 mlpmodule.py:1103] cpy2cputensor cost 0.0007739067077636719 s
INFO 01-13 08:46:48.603936.603936 client.py:127] Model loaded
DEBUG 01-13 08:46:48.603305.603305 cuda_h.py:19] end wait_experts cost 0.04724478721618652 seconds
DEBUG 01-13 08:46:48.603499.603499 cuda_h.py:10] start gpu_experts
DEBUG 01-13 08:46:48.604632.604632 mlpmodule.py:559] gpu group tensors cost 0.0008907318115234375 s
DEBUG 01-13 08:46:48.606880.606880 mlpmodule.py:592] gpu pad cost 0.0015807151794433594 s
DEBUG 01-13 08:46:48.606928.606928 mlpmodule.py:598] start_w1
DEBUG 01-13 08:46:48.607477.607477 mlpmodule.py:602] start_w3
DEBUG 01-13 08:46:48.607722.607722 mlpmodule.py:608] start_w2
DEBUG 01-13 08:46:48.607270.607270 mlpmodule.py:611] gpu group einsum cost 0.0007061958312988281 s
DEBUG 01-13 08:46:48.609942.609942 mlpmodule.py:683] gpu experts func einsum cost 0.005618572235107422 s
DEBUG 01-13 08:46:48.609674.609674 cuda_h.py:19] end gpu_experts cost 0.0057888031005859375 seconds
DEBUG 01-13 08:46:48.609761.609761 cuda_h.py:10] start cpu_thread_manager_mp_wait
DEBUG 01-13 08:46:48.609087.609087 cuda_h.py:19] end cpu_thread_manager_mp_wait cost 3.743171691894531e-05 seconds
DEBUG 01-13 08:46:48.609481.609481 cuda_h.py:19] end layer_moe_generate_mp_l_4 cost 0.063751220703125 seconds
DEBUG 01-13 08:46:48.610436.610436 lmp.py:1550] -------------------------------- end prefill layer 3 --------------------------------
DEBUG 01-13 08:46:48.610497.610497 lmp.py:1493] -------------------------------- start prefill layer 4 --------------------------------
DEBUG 01-13 08:46:48.610246.610246 cuda_h.py:10] start start_load_qkvogn_s_weight_l_5
DEBUG 01-13 08:46:48.610618.610618 cuda_h.py:10] start start_load_qkvogn_s_weight_l_5
DEBUG 01-13 08:46:48.610362.610362 cuda_h.py:19] end start_load_qkvogn_s_weight_l_5 cost 3.314018249511719e-05 seconds
DEBUG 01-13 08:46:48.610157.610157 cuda_h.py:19] end start_load_qkvogn_s_weight_l_5 cost 6.151199340820312e-05 seconds
DEBUG 01-13 08:46:48.610205.610205 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-13 08:46:48.610618.610618 cuda_h.py:10] start sllm_worker_task
DEBUG 01-13 08:46:48.610171.610171 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-13 08:46:48.610703.610703 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-13 08:46:48.610521.610521 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-13 08:46:48.611680.611680 cuda_h.py:19] end allocate_cuda_memory cost 0.0003597736358642578 seconds
DEBUG 01-13 08:46:48.611432.611432 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-13 08:46:48.611122.611122 sllm_store_c.py:27] get device uuid map
DEBUG 01-13 08:46:48.611627.611627 sllm_store_c.py:29] call client load into gpu
DEBUG 01-13 08:46:48.611483.611483 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 8df6abc5-72bc-4674-8ced-119127efbb01
DEBUG 01-13 08:46:48.611718.611718 client.py:106] call stub.LoadModelAsync
DEBUG 01-13 08:46:48.611019.611019 cuda_h.py:10] start self_attn
INFO 01-13 08:46:48.612828.612828 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 8df6abc5-72bc-4674-8ced-119127efbb01
DEBUG 01-13 08:46:48.612016.612016 cuda_h.py:19] end load_into_gpu_async cost 0.00157928466796875 seconds
DEBUG 01-13 08:46:48.612679.612679 cuda_h.py:10] start restore_tensors2
DEBUG 01-13 08:46:48.612835.612835 cuda_h.py:19] end restore_tensors2 cost 8.130073547363281e-05 seconds
DEBUG 01-13 08:46:48.613281.613281 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0023353099822998047 seconds
INFO 01-13 08:46:48.613952.613952 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 8df6abc5-72bc-4674-8ced-119127efbb01
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-13 08:46:48.614299.614299 cuda_h.py:19] end self_attn cost 0.0029516220092773438 seconds
DEBUG 01-13 08:46:48.615620.615620 cuda_h.py:19] end iln_self_attn_paln cost 0.00466609001159668 seconds
DEBUG 01-13 08:46:48.615795.615795 cuda_h.py:10] start layer_moe_generate_mp_l_5
DEBUG 01-13 08:46:48.615412.615412 cuda_h.py:10] start gate
DEBUG 01-13 08:46:48.615202.615202 cuda_h.py:19] end gate cost 0.0006196498870849609 seconds
DEBUG 01-13 08:46:48.615601.615601 cuda_h.py:10] start experts_map_get
DEBUG 01-13 08:46:48.616955.616955 lmp.py:1611] 
DEBUG 01-13 08:46:48.616955.616955 lmp.py:1611] Expert Token Distribution & Device Allocation:
DEBUG 01-13 08:46:48.616903.616903 lmp.py:1612]   Total experts: 64
DEBUG 01-13 08:46:48.616791.616791 lmp.py:1613]   CPU experts: 32 (50%)
DEBUG 01-13 08:46:48.616103.616103 lmp.py:1614]   GPU experts: 32 (50%)
DEBUG 01-13 08:46:48.616508.616508 lmp.py:1615] 
DEBUG 01-13 08:46:48.616508.616508 lmp.py:1615]   Expert ID | Tokens | Device
DEBUG 01-13 08:46:48.616389.616389 lmp.py:1616]   -----------------------------------
DEBUG 01-13 08:46:48.616516.616516 lmp.py:1622]   Expert 14 |     60 | CPU
DEBUG 01-13 08:46:48.616920.616920 lmp.py:1622]   Expert 57 |     68 | CPU
DEBUG 01-13 08:46:48.616610.616610 lmp.py:1622]   Expert 13 |     74 | CPU
DEBUG 01-13 08:46:48.616345.616345 lmp.py:1622]   Expert 26 |     87 | CPU
DEBUG 01-13 08:46:48.616319.616319 lmp.py:1622]   Expert 31 |     91 | CPU
DEBUG 01-13 08:46:48.616055.616055 lmp.py:1622]   Expert 54 |     94 | CPU
DEBUG 01-13 08:46:48.616711.616711 lmp.py:1622]   Expert 11 |     95 | CPU
DEBUG 01-13 08:46:48.616546.616546 lmp.py:1622]   Expert 45 |     99 | CPU
DEBUG 01-13 08:46:48.616905.616905 lmp.py:1622]   Expert 30 |    101 | CPU
DEBUG 01-13 08:46:48.616071.616071 lmp.py:1622]   Expert 58 |    102 | CPU
DEBUG 01-13 08:46:48.616714.616714 lmp.py:1622]   Expert 51 |    112 | CPU
DEBUG 01-13 08:46:48.616118.616118 lmp.py:1622]   Expert 10 |    113 | CPU
DEBUG 01-13 08:46:48.616285.616285 lmp.py:1622]   Expert 32 |    113 | CPU
DEBUG 01-13 08:46:48.616735.616735 lmp.py:1622]   Expert 36 |    117 | CPU
DEBUG 01-13 08:46:48.616186.616186 lmp.py:1622]   Expert  8 |    126 | CPU
DEBUG 01-13 08:46:48.616876.616876 lmp.py:1622]   Expert 20 |    128 | CPU
DEBUG 01-13 08:46:48.616565.616565 lmp.py:1622]   Expert 63 |    138 | CPU
DEBUG 01-13 08:46:48.616254.616254 lmp.py:1622]   Expert 47 |    139 | CPU
DEBUG 01-13 08:46:48.616943.616943 lmp.py:1622]   Expert 53 |    140 | CPU
DEBUG 01-13 08:46:48.616394.616394 lmp.py:1622]   Expert 34 |    141 | CPU
DEBUG 01-13 08:46:48.616084.616084 lmp.py:1622]   Expert  4 |    143 | CPU
DEBUG 01-13 08:46:48.616773.616773 lmp.py:1622]   Expert 61 |    144 | CPU
DEBUG 01-13 08:46:48.616416.616416 lmp.py:1622]   Expert 16 |    150 | CPU
DEBUG 01-13 08:46:48.616297.616297 lmp.py:1622]   Expert 60 |    158 | CPU
DEBUG 01-13 08:46:48.616463.616463 lmp.py:1622]   Expert 42 |    160 | CPU
DEBUG 01-13 08:46:48.616630.616630 lmp.py:1622]   Expert 28 |    162 | CPU
DEBUG 01-13 08:46:48.616796.616796 lmp.py:1622]   Expert 17 |    165 | CPU
DEBUG 01-13 08:46:48.616485.616485 lmp.py:1622]   Expert 29 |    170 | CPU
DEBUG 01-13 08:46:48.616174.616174 lmp.py:1622]   Expert 27 |    171 | CPU
DEBUG 01-13 08:46:48.616625.616625 lmp.py:1622]   Expert 44 |    175 | CPU
DEBUG 01-13 08:46:48.616315.616315 lmp.py:1622]   Expert  9 |    177 | CPU
DEBUG 01-13 08:46:48.616765.616765 lmp.py:1622]   Expert  7 |    180 | CPU
DEBUG 01-13 08:46:48.616455.616455 lmp.py:1622]   Expert 41 |    182 | GPU
DEBUG 01-13 08:46:48.616144.616144 lmp.py:1622]   Expert 48 |    183 | GPU
DEBUG 01-13 08:46:48.616595.616595 lmp.py:1622]   Expert  2 |    184 | GPU
DEBUG 01-13 08:46:48.616761.616761 lmp.py:1622]   Expert 56 |    184 | GPU
DEBUG 01-13 08:46:48.616166.616166 lmp.py:1622]   Expert  3 |    189 | GPU
DEBUG 01-13 08:46:48.616332.616332 lmp.py:1622]   Expert 15 |    195 | GPU
DEBUG 01-13 08:46:48.616736.616736 lmp.py:1622]   Expert 24 |    197 | GPU
DEBUG 01-13 08:46:48.616141.616141 lmp.py:1622]   Expert  0 |    199 | GPU
DEBUG 01-13 08:46:48.616830.616830 lmp.py:1622]   Expert 18 |    203 | GPU
DEBUG 01-13 08:46:48.616043.616043 lmp.py:1622]   Expert 40 |    206 | GPU
DEBUG 01-13 08:46:48.617732.617732 lmp.py:1622]   Expert 55 |    206 | GPU
DEBUG 01-13 08:46:48.617944.617944 lmp.py:1622]   Expert 38 |    215 | GPU
DEBUG 01-13 08:46:48.617395.617395 lmp.py:1622]   Expert 22 |    216 | GPU
DEBUG 01-13 08:46:48.617846.617846 lmp.py:1622]   Expert 23 |    217 | GPU
DEBUG 01-13 08:46:48.617059.617059 lmp.py:1622]   Expert  6 |    226 | GPU
DEBUG 01-13 08:46:48.617748.617748 lmp.py:1622]   Expert 37 |    226 | GPU
DEBUG 01-13 08:46:48.617914.617914 lmp.py:1622]   Expert 46 |    236 | GPU
DEBUG 01-13 08:46:48.617080.617080 lmp.py:1622]   Expert 39 |    250 | GPU
DEBUG 01-13 08:46:48.617246.617246 lmp.py:1622]   Expert 19 |    251 | GPU
DEBUG 01-13 08:46:48.617651.617651 lmp.py:1622]   Expert 25 |    258 | GPU
DEBUG 01-13 08:46:48.617817.617817 lmp.py:1622]   Expert 12 |    260 | GPU
DEBUG 01-13 08:46:48.617268.617268 lmp.py:1622]   Expert 50 |    263 | GPU
DEBUG 01-13 08:46:48.617480.617480 lmp.py:1622]   Expert 62 |    266 | GPU
DEBUG 01-13 08:46:48.617931.617931 lmp.py:1622]   Expert 21 |    271 | GPU
DEBUG 01-13 08:46:48.617382.617382 lmp.py:1622]   Expert 35 |    278 | GPU
DEBUG 01-13 08:46:48.617071.617071 lmp.py:1622]   Expert 49 |    288 | GPU
DEBUG 01-13 08:46:48.617522.617522 lmp.py:1622]   Expert 33 |    300 | GPU
DEBUG 01-13 08:46:48.617735.617735 lmp.py:1622]   Expert 52 |    304 | GPU
DEBUG 01-13 08:46:48.617186.617186 lmp.py:1622]   Expert  1 |    349 | GPU
DEBUG 01-13 08:46:48.617637.617637 lmp.py:1622]   Expert  5 |    373 | GPU
DEBUG 01-13 08:46:48.617087.617087 lmp.py:1622]   Expert 43 |    439 | GPU
DEBUG 01-13 08:46:48.617300.617300 lmp.py:1622]   Expert 59 |    581 | GPU
DEBUG 01-13 08:46:48.617704.617704 lmp.py:1623] 
DEBUG 01-13 08:46:48.617704.617704 lmp.py:1623]   CPU total tokens: 4093 (33.3%)
DEBUG 01-13 08:46:48.617301.617301 lmp.py:1624]   GPU total tokens: 8195 (66.7%)
DEBUG 01-13 08:46:48.617951.617951 cuda_h.py:19] end experts_map_get cost 0.0015299320220947266 seconds
DEBUG 01-13 08:46:48.617609.617609 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-13 08:46:48.617742.617742 lmp.py:1632] 
DEBUG 01-13 08:46:48.617742.617742 lmp.py:1632]   Computing 32 experts on CPU MP...
DEBUG 01-13 08:46:48.617479.617479 cuda_h.py:19] end cpu_experts_submit cost 4.863739013671875e-05 seconds
DEBUG 01-13 08:46:48.617221.617221 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-13 08:46:48.617289.617289 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-13 08:46:48.617393.617393 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-13 08:46:48.618126.618126 mlpmodule.py:785]  experts func einsum cost 0.06539297103881836 s
DEBUG 01-13 08:46:48.618739.618739 cuda_h.py:19] end allocate_cuda_memory cost 0.00039649009704589844 seconds
DEBUG 01-13 08:46:48.618586.618586 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-13 08:46:48.618594.618594 sllm_store_c.py:27] get device uuid map
DEBUG 01-13 08:46:48.618118.618118 sllm_store_c.py:29] call client load into gpu
DEBUG 01-13 08:46:48.618676.618676 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, d0482408-691f-4eaf-ace8-18833f529444
DEBUG 01-13 08:46:48.618073.618073 client.py:106] call stub.LoadModelAsync
DEBUG 01-13 08:46:48.619296.619296 cuda_h.py:19] end experts_func_gpu_einsum_mp cost 0.06737971305847168 seconds
DEBUG 01-13 08:46:48.620130.620130 cuda_h.py:10] start experts_func_gpu_einsum_mp
INFO 01-13 08:46:48.620077.620077 client.py:127] Model loaded
DEBUG 01-13 08:46:48.621929.621929 cuda_h.py:10] start restore2model
DEBUG 01-13 08:46:48.622503.622503 cuda_h.py:19] end restore2model cost 0.0010037422180175781 seconds
DEBUG 01-13 08:46:48.622064.622064 cuda_h.py:19] end sllm_worker_task cost 0.011774063110351562 seconds
INFO 01-13 08:46:48.622698.622698 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, d0482408-691f-4eaf-ace8-18833f529444
DEBUG 01-13 08:46:48.622975.622975 cuda_h.py:19] end load_into_gpu_async cost 0.004065275192260742 seconds
DEBUG 01-13 08:46:48.622805.622805 cuda_h.py:10] start restore_tensors2
DEBUG 01-13 08:46:48.623362.623362 cuda_h.py:19] end restore_tensors2 cost 0.0005764961242675781 seconds
DEBUG 01-13 08:46:48.623815.623815 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.00580286979675293 seconds
DEBUG 01-13 08:46:48.623036.623036 cuda_h.py:10] start restore2model
DEBUG 01-13 08:46:48.625620.625620 mlpmodule.py:1006] group tensors cost 0.004214048385620117 s
DEBUG 01-13 08:46:48.628155.628155 mlpmodule.py:1044] pad cost 0.002032041549682617 s
DEBUG 01-13 08:46:48.628235.628235 cuda_h.py:19] end restore2model cost 0.004521608352661133 seconds
DEBUG 01-13 08:46:48.628066.628066 mlpmodule.py:1050] create cpu tensor cost 5.269050598144531e-05 s
DEBUG 01-13 08:46:48.628941.628941 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.010575294494628906 seconds
DEBUG 01-13 08:46:48.628909.628909 cuda_h.py:10] start gpu_sexperts
DEBUG 01-13 08:46:48.628830.628830 mlpmodule.py:1055] move to cpu cost 3.6716461181640625e-05 s
DEBUG 01-13 08:46:48.628717.628717 cuda_h.py:19] end gpu_sexperts cost 0.0005121231079101562 seconds
DEBUG 01-13 08:46:48.629601.629601 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-13 08:46:48.629667.629667 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 5.841255187988281e-05 seconds
DEBUG 01-13 08:46:48.629087.629087 cuda_h.py:10] start wait_experts
INFO 01-13 08:46:48.629487.629487 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, d0482408-691f-4eaf-ace8-18833f529444
DEBUG 01-13 08:46:48.635172.635172 mlpmodule.py:1069] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-13 08:46:48.635610.635610 mlpmodule.py:1070] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-13 08:46:48.636303.636303 mlpmodule.py:1075] group_w3 first element: 0.0086669921875
WARNING 01-13 08:46:48.636573.636573 mlpmodule.py:1085] start einsum2
DEBUG 01-13 08:46:48.648166.648166 mlpmodule.py:1095] group einsum cost 0.020627260208129883 s
DEBUG 01-13 08:46:48.649609.649609 mlpmodule.py:1103] cpy2cputensor cost 0.0007002353668212891 s
INFO 01-13 08:46:48.672362.672362 client.py:127] Model loaded
DEBUG 01-13 08:46:48.673999.673999 cuda_h.py:19] end wait_experts cost 0.04333996772766113 seconds
DEBUG 01-13 08:46:48.673346.673346 cuda_h.py:10] start gpu_experts
DEBUG 01-13 08:46:48.674937.674937 mlpmodule.py:559] gpu group tensors cost 0.0014374256134033203 s
DEBUG 01-13 08:46:48.675388.675388 mlpmodule.py:785]  experts func einsum cost 0.054656028747558594 s
DEBUG 01-13 08:46:48.676450.676450 cuda_h.py:19] end experts_func_gpu_einsum_mp cost 0.05574750900268555 seconds
DEBUG 01-13 08:46:48.679966.679966 mlpmodule.py:592] gpu pad cost 0.004899263381958008 s
DEBUG 01-13 08:46:48.679177.679177 mlpmodule.py:598] start_w1
DEBUG 01-13 08:46:48.680449.680449 mlpmodule.py:602] start_w3
DEBUG 01-13 08:46:48.680172.680172 mlpmodule.py:608] start_w2
DEBUG 01-13 08:46:48.681409.681409 mlpmodule.py:611] gpu group einsum cost 0.0017805099487304688 s
DEBUG 01-13 08:46:48.685237.685237 mlpmodule.py:683] gpu experts func einsum cost 0.011996030807495117 s
DEBUG 01-13 08:46:48.685082.685082 cuda_h.py:19] end gpu_experts cost 0.012237548828125 seconds
DEBUG 01-13 08:46:48.685620.685620 cuda_h.py:10] start cpu_thread_manager_mp_wait
DEBUG 01-13 08:46:48.685881.685881 cuda_h.py:19] end cpu_thread_manager_mp_wait cost 4.458427429199219e-05 seconds
DEBUG 01-13 08:46:48.685799.685799 cuda_h.py:19] end layer_moe_generate_mp_l_5 cost 0.07050943374633789 seconds
DEBUG 01-13 08:46:48.685239.685239 lmp.py:1550] -------------------------------- end prefill layer 4 --------------------------------
DEBUG 01-13 08:46:48.686559.686559 lmp.py:1493] -------------------------------- start prefill layer 5 --------------------------------
DEBUG 01-13 08:46:48.686183.686183 cuda_h.py:10] start start_load_qkvogn_s_weight_l_6
DEBUG 01-13 08:46:48.686621.686621 cuda_h.py:10] start start_load_qkvogn_s_weight_l_6
DEBUG 01-13 08:46:48.686439.686439 cuda_h.py:19] end start_load_qkvogn_s_weight_l_6 cost 3.838539123535156e-05 seconds
DEBUG 01-13 08:46:48.686731.686731 cuda_h.py:19] end start_load_qkvogn_s_weight_l_6 cost 8.273124694824219e-05 seconds
DEBUG 01-13 08:46:48.686772.686772 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-13 08:46:48.686232.686232 cuda_h.py:10] start sllm_worker_task
DEBUG 01-13 08:46:48.686421.686421 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-13 08:46:48.686225.686225 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-13 08:46:48.686075.686075 cuda_h.py:19] end allocate_cuda_memory cost 0.00022840499877929688 seconds
DEBUG 01-13 08:46:48.686986.686986 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-13 08:46:48.686975.686975 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-13 08:46:48.687091.687091 sllm_store_c.py:27] get device uuid map
DEBUG 01-13 08:46:48.687981.687981 sllm_store_c.py:29] call client load into gpu
DEBUG 01-13 08:46:48.687267.687267 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 5c5e46e0-e1da-4a26-8f5f-e97158bfeb2f
DEBUG 01-13 08:46:48.687310.687310 client.py:106] call stub.LoadModelAsync
DEBUG 01-13 08:46:48.687533.687533 cuda_h.py:10] start self_attn
INFO 01-13 08:46:48.688491.688491 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 5c5e46e0-e1da-4a26-8f5f-e97158bfeb2f
DEBUG 01-13 08:46:48.688870.688870 cuda_h.py:19] end load_into_gpu_async cost 0.0019085407257080078 seconds
DEBUG 01-13 08:46:48.689011.689011 cuda_h.py:10] start restore_tensors2
DEBUG 01-13 08:46:48.689266.689266 cuda_h.py:19] end restore_tensors2 cost 8.153915405273438e-05 seconds
DEBUG 01-13 08:46:48.689797.689797 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0026938915252685547 seconds
INFO 01-13 08:46:48.689409.689409 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 5c5e46e0-e1da-4a26-8f5f-e97158bfeb2f
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-13 08:46:48.691994.691994 cuda_h.py:19] end self_attn cost 0.0039823055267333984 seconds
DEBUG 01-13 08:46:48.692074.692074 cuda_h.py:19] end iln_self_attn_paln cost 0.0057981014251708984 seconds
DEBUG 01-13 08:46:48.692228.692228 cuda_h.py:10] start layer_moe_generate_mp_l_6
DEBUG 01-13 08:46:48.692296.692296 cuda_h.py:10] start gate
DEBUG 01-13 08:46:48.693005.693005 cuda_h.py:19] end gate cost 0.0007598400115966797 seconds
DEBUG 01-13 08:46:48.693835.693835 cuda_h.py:10] start experts_map_get
DEBUG 01-13 08:46:48.693242.693242 lmp.py:1611] 
DEBUG 01-13 08:46:48.693242.693242 lmp.py:1611] Expert Token Distribution & Device Allocation:
DEBUG 01-13 08:46:48.693283.693283 lmp.py:1612]   Total experts: 64
DEBUG 01-13 08:46:48.693933.693933 lmp.py:1613]   CPU experts: 32 (50%)
DEBUG 01-13 08:46:48.693768.693768 lmp.py:1614]   GPU experts: 32 (50%)
DEBUG 01-13 08:46:48.693742.693742 lmp.py:1615] 
DEBUG 01-13 08:46:48.693742.693742 lmp.py:1615]   Expert ID | Tokens | Device
DEBUG 01-13 08:46:48.693193.693193 lmp.py:1616]   -----------------------------------
DEBUG 01-13 08:46:48.693604.693604 lmp.py:1622]   Expert 34 |     26 | CPU
DEBUG 01-13 08:46:48.693770.693770 lmp.py:1622]   Expert 45 |     60 | CPU
DEBUG 01-13 08:46:48.693744.693744 lmp.py:1622]   Expert 22 |     74 | CPU
DEBUG 01-13 08:46:48.693480.693480 lmp.py:1622]   Expert 57 |     77 | CPU
DEBUG 01-13 08:46:48.693216.693216 lmp.py:1622]   Expert 17 |     87 | CPU
DEBUG 01-13 08:46:48.693951.693951 lmp.py:1622]   Expert  4 |     98 | CPU
DEBUG 01-13 08:46:48.693687.693687 lmp.py:1622]   Expert 15 |    102 | CPU
DEBUG 01-13 08:46:48.693661.693661 lmp.py:1622]   Expert 28 |    102 | CPU
DEBUG 01-13 08:46:48.693589.693589 lmp.py:1622]   Expert 32 |    117 | CPU
DEBUG 01-13 08:46:48.693324.693324 lmp.py:1622]   Expert 60 |    117 | CPU
DEBUG 01-13 08:46:48.693060.693060 lmp.py:1622]   Expert 36 |    121 | CPU
DEBUG 01-13 08:46:48.693941.693941 lmp.py:1622]   Expert 14 |    122 | CPU
DEBUG 01-13 08:46:48.693631.693631 lmp.py:1622]   Expert 52 |    123 | CPU
DEBUG 01-13 08:46:48.693320.693320 lmp.py:1622]   Expert 25 |    124 | CPU
DEBUG 01-13 08:46:48.693532.693532 lmp.py:1622]   Expert  2 |    134 | CPU
DEBUG 01-13 08:46:48.693983.693983 lmp.py:1622]   Expert 16 |    134 | CPU
DEBUG 01-13 08:46:48.693673.693673 lmp.py:1622]   Expert  8 |    135 | CPU
DEBUG 01-13 08:46:48.693123.693123 lmp.py:1622]   Expert 12 |    136 | CPU
DEBUG 01-13 08:46:48.693813.693813 lmp.py:1622]   Expert  5 |    141 | CPU
DEBUG 01-13 08:46:48.693025.693025 lmp.py:1622]   Expert 35 |    145 | CPU
DEBUG 01-13 08:46:48.693476.693476 lmp.py:1622]   Expert 30 |    153 | CPU
DEBUG 01-13 08:46:48.693165.693165 lmp.py:1622]   Expert 61 |    155 | CPU
DEBUG 01-13 08:46:48.693378.693378 lmp.py:1622]   Expert  0 |    159 | CPU
DEBUG 01-13 08:46:48.693067.693067 lmp.py:1622]   Expert 23 |    159 | CPU
DEBUG 01-13 08:46:48.693756.693756 lmp.py:1622]   Expert 39 |    159 | CPU
DEBUG 01-13 08:46:48.693446.693446 lmp.py:1622]   Expert 42 |    164 | CPU
DEBUG 01-13 08:46:48.693658.693658 lmp.py:1622]   Expert 13 |    166 | CPU
DEBUG 01-13 08:46:48.693109.693109 lmp.py:1622]   Expert  9 |    169 | CPU
DEBUG 01-13 08:46:48.693322.693322 lmp.py:1622]   Expert 46 |    171 | CPU
DEBUG 01-13 08:46:48.693534.693534 lmp.py:1622]   Expert 44 |    173 | CPU
DEBUG 01-13 08:46:48.693746.693746 lmp.py:1622]   Expert  3 |    175 | CPU
DEBUG 01-13 08:46:48.694197.694197 lmp.py:1622]   Expert 31 |    175 | CPU
DEBUG 01-13 08:46:48.694125.694125 lmp.py:1622]   Expert 41 |    179 | GPU
DEBUG 01-13 08:46:48.694530.694530 lmp.py:1622]   Expert 43 |    185 | GPU
DEBUG 01-13 08:46:48.694980.694980 lmp.py:1622]   Expert 26 |    189 | GPU
DEBUG 01-13 08:46:48.694670.694670 lmp.py:1622]   Expert 18 |    191 | GPU
DEBUG 01-13 08:46:48.694121.694121 lmp.py:1622]   Expert 51 |    191 | GPU
DEBUG 01-13 08:46:48.694572.694572 lmp.py:1622]   Expert 27 |    194 | GPU
DEBUG 01-13 08:46:48.694784.694784 lmp.py:1622]   Expert 49 |    194 | GPU
DEBUG 01-13 08:46:48.694235.694235 lmp.py:1622]   Expert 62 |    194 | GPU
DEBUG 01-13 08:46:48.694686.694686 lmp.py:1622]   Expert 50 |    195 | GPU
DEBUG 01-13 08:46:48.694898.694898 lmp.py:1622]   Expert 47 |    198 | GPU
DEBUG 01-13 08:46:48.694111.694111 lmp.py:1622]   Expert 11 |    201 | GPU
DEBUG 01-13 08:46:48.694562.694562 lmp.py:1622]   Expert 19 |    202 | GPU
DEBUG 01-13 08:46:48.694012.694012 lmp.py:1622]   Expert 20 |    203 | GPU
DEBUG 01-13 08:46:48.694417.694417 lmp.py:1622]   Expert 55 |    206 | GPU
DEBUG 01-13 08:46:48.694868.694868 lmp.py:1622]   Expert 56 |    211 | GPU
DEBUG 01-13 08:46:48.694319.694319 lmp.py:1622]   Expert 63 |    213 | GPU
DEBUG 01-13 08:46:48.694770.694770 lmp.py:1622]   Expert 38 |    220 | GPU
DEBUG 01-13 08:46:48.694221.694221 lmp.py:1622]   Expert 48 |    236 | GPU
DEBUG 01-13 08:46:48.694433.694433 lmp.py:1622]   Expert  1 |    239 | GPU
DEBUG 01-13 08:46:48.694645.694645 lmp.py:1622]   Expert 10 |    241 | GPU
DEBUG 01-13 08:46:48.694096.694096 lmp.py:1622]   Expert  7 |    245 | GPU
DEBUG 01-13 08:46:48.694786.694786 lmp.py:1622]   Expert 54 |    248 | GPU
DEBUG 01-13 08:46:48.694237.694237 lmp.py:1622]   Expert 21 |    254 | GPU
DEBUG 01-13 08:46:48.694641.694641 lmp.py:1622]   Expert 33 |    258 | GPU
DEBUG 01-13 08:46:48.694330.694330 lmp.py:1622]   Expert 29 |    260 | GPU
DEBUG 01-13 08:46:48.694543.694543 lmp.py:1622]   Expert 40 |    267 | GPU
DEBUG 01-13 08:46:48.694517.694517 lmp.py:1622]   Expert 24 |    277 | GPU
DEBUG 01-13 08:46:48.694206.694206 lmp.py:1622]   Expert 59 |    288 | GPU
DEBUG 01-13 08:46:48.694419.694419 lmp.py:1622]   Expert 37 |    337 | GPU
DEBUG 01-13 08:46:48.694870.694870 lmp.py:1622]   Expert 58 |    366 | GPU
DEBUG 01-13 08:46:48.694082.694082 lmp.py:1622]   Expert  6 |    386 | GPU
DEBUG 01-13 08:46:48.694533.694533 lmp.py:1622]   Expert 53 |    867 | GPU
DEBUG 01-13 08:46:48.694937.694937 lmp.py:1623] 
DEBUG 01-13 08:46:48.694937.694937 lmp.py:1623]   CPU total tokens: 4153 (33.8%)
DEBUG 01-13 08:46:48.694534.694534 lmp.py:1624]   GPU total tokens: 8135 (66.2%)
DEBUG 01-13 08:46:48.694992.694992 cuda_h.py:19] end experts_map_get cost 0.001493692398071289 seconds
DEBUG 01-13 08:46:48.694742.694742 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-13 08:46:48.694399.694399 lmp.py:1632] 
DEBUG 01-13 08:46:48.694399.694399 lmp.py:1632]   Computing 32 experts on CPU MP...
DEBUG 01-13 08:46:48.694559.694559 cuda_h.py:19] end cpu_experts_submit cost 4.792213439941406e-05 seconds
DEBUG 01-13 08:46:48.694878.694878 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-13 08:46:48.694323.694323 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-13 08:46:48.694666.694666 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-13 08:46:48.695649.695649 cuda_h.py:19] end allocate_cuda_memory cost 0.0006566047668457031 seconds
DEBUG 01-13 08:46:48.696312.696312 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-13 08:46:48.696744.696744 sllm_store_c.py:27] get device uuid map
DEBUG 01-13 08:46:48.696461.696461 sllm_store_c.py:29] call client load into gpu
DEBUG 01-13 08:46:48.696779.696779 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 7ecd2e91-8818-4f5c-ba46-57720465071a
DEBUG 01-13 08:46:48.696461.696461 client.py:106] call stub.LoadModelAsync
INFO 01-13 08:46:48.696652.696652 client.py:127] Model loaded
DEBUG 01-13 08:46:48.696662.696662 cuda_h.py:10] start restore2model
DEBUG 01-13 08:46:48.697390.697390 cuda_h.py:19] end restore2model cost 0.0005552768707275391 seconds
DEBUG 01-13 08:46:48.697148.697148 cuda_h.py:19] end sllm_worker_task cost 0.010832786560058594 seconds
DEBUG 01-13 08:46:48.697186.697186 cuda_h.py:10] start experts_func_gpu_einsum_mp
INFO 01-13 08:46:48.698032.698032 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 7ecd2e91-8818-4f5c-ba46-57720465071a
DEBUG 01-13 08:46:48.698114.698114 cuda_h.py:19] end load_into_gpu_async cost 0.0021309852600097656 seconds
DEBUG 01-13 08:46:48.698532.698532 cuda_h.py:10] start restore_tensors2
DEBUG 01-13 08:46:48.698738.698738 cuda_h.py:19] end restore_tensors2 cost 0.0004029273986816406 seconds
DEBUG 01-13 08:46:48.698912.698912 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.003923177719116211 seconds
DEBUG 01-13 08:46:48.698106.698106 cuda_h.py:10] start restore2model
DEBUG 01-13 08:46:48.701560.701560 cuda_h.py:19] end restore2model cost 0.002658367156982422 seconds
DEBUG 01-13 08:46:48.701787.701787 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.006758689880371094 seconds
DEBUG 01-13 08:46:48.701152.701152 cuda_h.py:10] start gpu_sexperts
DEBUG 01-13 08:46:48.701208.701208 cuda_h.py:19] end gpu_sexperts cost 0.0002574920654296875 seconds
DEBUG 01-13 08:46:48.701845.701845 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-13 08:46:48.701907.701907 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 1.4066696166992188e-05 seconds
DEBUG 01-13 08:46:48.701887.701887 cuda_h.py:10] start wait_experts
INFO 01-13 08:46:48.701590.701590 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 7ecd2e91-8818-4f5c-ba46-57720465071a
DEBUG 01-13 08:46:48.715440.715440 mlpmodule.py:1006] group tensors cost 0.016663074493408203 s
DEBUG 01-13 08:46:48.718604.718604 mlpmodule.py:1044] pad cost 0.0017211437225341797 s
DEBUG 01-13 08:46:48.718084.718084 mlpmodule.py:1050] create cpu tensor cost 4.8160552978515625e-05 s
DEBUG 01-13 08:46:48.718987.718987 mlpmodule.py:1055] move to cpu cost 3.409385681152344e-05 s
DEBUG 01-13 08:46:48.727224.727224 mlpmodule.py:1069] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-13 08:46:48.727456.727456 mlpmodule.py:1070] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-13 08:46:48.727373.727373 mlpmodule.py:1075] group_w3 first element: 0.03369140625
WARNING 01-13 08:46:48.727683.727683 mlpmodule.py:1085] start einsum2
DEBUG 01-13 08:46:48.740328.740328 mlpmodule.py:1095] group einsum cost 0.022356748580932617 s
DEBUG 01-13 08:46:48.741313.741313 mlpmodule.py:1103] cpy2cputensor cost 0.0007026195526123047 s
INFO 01-13 08:46:48.749125.749125 client.py:127] Model loaded
DEBUG 01-13 08:46:48.749886.749886 cuda_h.py:19] end wait_experts cost 0.04718160629272461 seconds
DEBUG 01-13 08:46:48.749318.749318 cuda_h.py:10] start gpu_experts
DEBUG 01-13 08:46:48.750228.750228 mlpmodule.py:559] gpu group tensors cost 0.00077056884765625 s
DEBUG 01-13 08:46:48.752536.752536 mlpmodule.py:592] gpu pad cost 0.002193927764892578 s
DEBUG 01-13 08:46:48.752875.752875 mlpmodule.py:598] start_w1
DEBUG 01-13 08:46:48.753331.753331 mlpmodule.py:602] start_w3
DEBUG 01-13 08:46:48.753192.753192 mlpmodule.py:608] start_w2
DEBUG 01-13 08:46:48.754603.754603 mlpmodule.py:611] gpu group einsum cost 0.0015537738800048828 s
DEBUG 01-13 08:46:48.756915.756915 mlpmodule.py:683] gpu experts func einsum cost 0.007459402084350586 s
DEBUG 01-13 08:46:48.756223.756223 cuda_h.py:19] end gpu_experts cost 0.007624387741088867 seconds
DEBUG 01-13 08:46:48.756456.756456 cuda_h.py:10] start cpu_thread_manager_mp_wait
DEBUG 01-13 08:46:48.756981.756981 cuda_h.py:19] end cpu_thread_manager_mp_wait cost 3.838539123535156e-05 seconds
DEBUG 01-13 08:46:48.757759.757759 cuda_h.py:19] end layer_moe_generate_mp_l_6 cost 0.0648500919342041 seconds
DEBUG 01-13 08:46:48.757310.757310 lmp.py:1550] -------------------------------- end prefill layer 5 --------------------------------
DEBUG 01-13 08:46:48.757179.757179 lmp.py:1493] -------------------------------- start prefill layer 6 --------------------------------
DEBUG 01-13 08:46:48.757835.757835 cuda_h.py:10] start start_load_qkvogn_s_weight_l_7
DEBUG 01-13 08:46:48.757353.757353 cuda_h.py:10] start start_load_qkvogn_s_weight_l_7
DEBUG 01-13 08:46:48.757481.757481 cuda_h.py:19] end start_load_qkvogn_s_weight_l_7 cost 3.218650817871094e-05 seconds
DEBUG 01-13 08:46:48.757945.757945 cuda_h.py:19] end start_load_qkvogn_s_weight_l_7 cost 6.246566772460938e-05 seconds
DEBUG 01-13 08:46:48.757211.757211 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-13 08:46:48.757156.757156 cuda_h.py:10] start sllm_worker_task
DEBUG 01-13 08:46:48.757477.757477 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-13 08:46:48.757584.757584 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-13 08:46:48.757807.757807 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-13 08:46:48.758046.758046 cuda_h.py:19] end allocate_cuda_memory cost 0.0001747608184814453 seconds
DEBUG 01-13 08:46:48.758009.758009 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-13 08:46:48.758341.758341 sllm_store_c.py:27] get device uuid map
DEBUG 01-13 08:46:48.758164.758164 sllm_store_c.py:29] call client load into gpu
DEBUG 01-13 08:46:48.758343.758343 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 42d1261a-9050-482f-946c-656be0e47b36
DEBUG 01-13 08:46:48.758889.758889 client.py:106] call stub.LoadModelAsync
DEBUG 01-13 08:46:48.758018.758018 cuda_h.py:10] start self_attn
INFO 01-13 08:46:48.759967.759967 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 42d1261a-9050-482f-946c-656be0e47b36
DEBUG 01-13 08:46:48.759803.759803 cuda_h.py:19] end load_into_gpu_async cost 0.001744985580444336 seconds
DEBUG 01-13 08:46:48.759361.759361 cuda_h.py:10] start restore_tensors2
DEBUG 01-13 08:46:48.760966.760966 cuda_h.py:19] end restore_tensors2 cost 6.961822509765625e-05 seconds
DEBUG 01-13 08:46:48.760577.760577 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0022385120391845703 seconds
INFO 01-13 08:46:48.760036.760036 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 42d1261a-9050-482f-946c-656be0e47b36
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-13 08:46:48.761216.761216 cuda_h.py:19] end self_attn cost 0.0028944015502929688 seconds
DEBUG 01-13 08:46:48.761200.761200 cuda_h.py:19] end iln_self_attn_paln cost 0.004341602325439453 seconds
DEBUG 01-13 08:46:48.761520.761520 cuda_h.py:10] start layer_moe_generate_mp_l_7
DEBUG 01-13 08:46:48.762375.762375 cuda_h.py:10] start gate
DEBUG 01-13 08:46:48.762912.762912 cuda_h.py:19] end gate cost 0.0005726814270019531 seconds
DEBUG 01-13 08:46:48.762503.762503 cuda_h.py:10] start experts_map_get
DEBUG 01-13 08:46:48.762626.762626 lmp.py:1611] 
DEBUG 01-13 08:46:48.762626.762626 lmp.py:1611] Expert Token Distribution & Device Allocation:
DEBUG 01-13 08:46:48.762428.762428 lmp.py:1612]   Total experts: 64
DEBUG 01-13 08:46:48.763316.763316 lmp.py:1613]   CPU experts: 32 (50%)
DEBUG 01-13 08:46:48.763343.763343 lmp.py:1614]   GPU experts: 32 (50%)
DEBUG 01-13 08:46:48.763986.763986 lmp.py:1615] 
DEBUG 01-13 08:46:48.763986.763986 lmp.py:1615]   Expert ID | Tokens | Device
DEBUG 01-13 08:46:48.763868.763868 lmp.py:1616]   -----------------------------------
DEBUG 01-13 08:46:48.763233.763233 lmp.py:1622]   Expert  1 |     48 | CPU
DEBUG 01-13 08:46:48.763114.763114 lmp.py:1622]   Expert  7 |     57 | CPU
DEBUG 01-13 08:46:48.763042.763042 lmp.py:1622]   Expert 37 |     71 | CPU
DEBUG 01-13 08:46:48.763731.763731 lmp.py:1622]   Expert 18 |     79 | CPU
DEBUG 01-13 08:46:48.763943.763943 lmp.py:1622]   Expert 54 |     79 | CPU
DEBUG 01-13 08:46:48.763918.763918 lmp.py:1622]   Expert 17 |     84 | CPU
DEBUG 01-13 08:46:48.763130.763130 lmp.py:1622]   Expert  9 |     88 | CPU
DEBUG 01-13 08:46:48.763866.763866 lmp.py:1622]   Expert 13 |     94 | CPU
DEBUG 01-13 08:46:48.763078.763078 lmp.py:1622]   Expert  0 |    105 | CPU
DEBUG 01-13 08:46:48.763244.763244 lmp.py:1622]   Expert 22 |    105 | CPU
DEBUG 01-13 08:46:48.763410.763410 lmp.py:1622]   Expert 58 |    105 | CPU
DEBUG 01-13 08:46:48.763100.763100 lmp.py:1622]   Expert 16 |    114 | CPU
DEBUG 01-13 08:46:48.763087.763087 lmp.py:1622]   Expert 26 |    118 | CPU
DEBUG 01-13 08:46:48.763538.763538 lmp.py:1622]   Expert 10 |    128 | CPU
DEBUG 01-13 08:46:48.763512.763512 lmp.py:1622]   Expert 63 |    131 | CPU
DEBUG 01-13 08:46:48.763248.763248 lmp.py:1622]   Expert 59 |    138 | CPU
DEBUG 01-13 08:46:48.763983.763983 lmp.py:1622]   Expert 33 |    141 | CPU
DEBUG 01-13 08:46:48.763719.763719 lmp.py:1622]   Expert 28 |    145 | CPU
DEBUG 01-13 08:46:48.763455.763455 lmp.py:1622]   Expert 62 |    149 | CPU
DEBUG 01-13 08:46:48.763952.763952 lmp.py:1622]   Expert 29 |    150 | CPU
DEBUG 01-13 08:46:48.763926.763926 lmp.py:1622]   Expert 43 |    151 | CPU
DEBUG 01-13 08:46:48.763185.763185 lmp.py:1622]   Expert  2 |    159 | CPU
DEBUG 01-13 08:46:48.763920.763920 lmp.py:1622]   Expert 55 |    159 | CPU
DEBUG 01-13 08:46:48.763563.763563 lmp.py:1622]   Expert 51 |    161 | CPU
DEBUG 01-13 08:46:48.763445.763445 lmp.py:1622]   Expert 23 |    163 | CPU
DEBUG 01-13 08:46:48.763088.763088 lmp.py:1622]   Expert  3 |    167 | CPU
DEBUG 01-13 08:46:48.763969.763969 lmp.py:1622]   Expert 40 |    167 | CPU
DEBUG 01-13 08:46:48.763612.763612 lmp.py:1622]   Expert 11 |    169 | CPU
DEBUG 01-13 08:46:48.763255.763255 lmp.py:1622]   Expert 32 |    169 | CPU
DEBUG 01-13 08:46:48.763660.763660 lmp.py:1622]   Expert 45 |    169 | CPU
DEBUG 01-13 08:46:48.763587.763587 lmp.py:1622]   Expert 53 |    170 | CPU
DEBUG 01-13 08:46:48.763277.763277 lmp.py:1622]   Expert 34 |    171 | CPU
DEBUG 01-13 08:46:48.763966.763966 lmp.py:1622]   Expert 14 |    175 | GPU
DEBUG 01-13 08:46:48.763655.763655 lmp.py:1622]   Expert 52 |    175 | GPU
DEBUG 01-13 08:46:48.763345.763345 lmp.py:1622]   Expert 41 |    178 | GPU
DEBUG 01-13 08:46:48.763795.763795 lmp.py:1622]   Expert 42 |    183 | GPU
DEBUG 01-13 08:46:48.763485.763485 lmp.py:1622]   Expert 57 |    192 | GPU
DEBUG 01-13 08:46:48.763889.763889 lmp.py:1622]   Expert 21 |    193 | GPU
DEBUG 01-13 08:46:48.763294.763294 lmp.py:1622]   Expert 15 |    196 | GPU
DEBUG 01-13 08:46:48.763937.763937 lmp.py:1622]   Expert 30 |    196 | GPU
DEBUG 01-13 08:46:48.763341.763341 lmp.py:1622]   Expert 35 |    208 | GPU
DEBUG 01-13 08:46:48.763508.763508 lmp.py:1622]   Expert 12 |    215 | GPU
DEBUG 01-13 08:46:48.763435.763435 lmp.py:1622]   Expert  4 |    217 | GPU
DEBUG 01-13 08:46:48.763125.763125 lmp.py:1622]   Expert 46 |    226 | GPU
DEBUG 01-13 08:46:48.763814.763814 lmp.py:1622]   Expert 24 |    229 | GPU
DEBUG 01-13 08:46:48.763265.763265 lmp.py:1622]   Expert 49 |    230 | GPU
DEBUG 01-13 08:46:48.763192.763192 lmp.py:1622]   Expert  8 |    231 | GPU
DEBUG 01-13 08:46:48.763882.763882 lmp.py:1622]   Expert 50 |    232 | GPU
DEBUG 01-13 08:46:48.763571.763571 lmp.py:1622]   Expert 44 |    233 | GPU
DEBUG 01-13 08:46:48.763499.763499 lmp.py:1622]   Expert 19 |    244 | GPU
DEBUG 01-13 08:46:48.763711.763711 lmp.py:1622]   Expert 38 |    245 | GPU
DEBUG 01-13 08:46:48.763116.763116 lmp.py:1622]   Expert  6 |    246 | GPU
DEBUG 01-13 08:46:48.763759.763759 lmp.py:1622]   Expert 47 |    246 | GPU
DEBUG 01-13 08:46:48.763640.763640 lmp.py:1622]   Expert 31 |    252 | GPU
DEBUG 01-13 08:46:48.764045.764045 lmp.py:1622]   Expert 61 |    259 | GPU
DEBUG 01-13 08:46:48.764734.764734 lmp.py:1622]   Expert 39 |    276 | GPU
DEBUG 01-13 08:46:48.764423.764423 lmp.py:1622]   Expert 36 |    299 | GPU
DEBUG 01-13 08:46:48.764636.764636 lmp.py:1622]   Expert  5 |    305 | GPU
DEBUG 01-13 08:46:48.764087.764087 lmp.py:1622]   Expert 27 |    310 | GPU
DEBUG 01-13 08:46:48.764299.764299 lmp.py:1622]   Expert 60 |    334 | GPU
DEBUG 01-13 08:46:48.764988.764988 lmp.py:1622]   Expert 20 |    340 | GPU
DEBUG 01-13 08:46:48.764678.764678 lmp.py:1622]   Expert 48 |    373 | GPU
DEBUG 01-13 08:46:48.764990.764990 lmp.py:1622]   Expert 25 |    396 | GPU
DEBUG 01-13 08:46:48.764871.764871 lmp.py:1622]   Expert 56 |    550 | GPU
DEBUG 01-13 08:46:48.764991.764991 lmp.py:1623] 
DEBUG 01-13 08:46:48.764991.764991 lmp.py:1623]   CPU total tokens: 4104 (33.4%)
DEBUG 01-13 08:46:48.764826.764826 lmp.py:1624]   GPU total tokens: 8184 (66.6%)
DEBUG 01-13 08:46:48.764284.764284 cuda_h.py:19] end experts_map_get cost 0.001531362533569336 seconds
DEBUG 01-13 08:46:48.764511.764511 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-13 08:46:48.764598.764598 lmp.py:1632] 
DEBUG 01-13 08:46:48.764598.764598 lmp.py:1632]   Computing 32 experts on CPU MP...
DEBUG 01-13 08:46:48.764474.764474 cuda_h.py:19] end cpu_experts_submit cost 4.9114227294921875e-05 seconds
DEBUG 01-13 08:46:48.764978.764978 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-13 08:46:48.764887.764887 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-13 08:46:48.764071.764071 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-13 08:46:48.765480.765480 mlpmodule.py:785]  experts func einsum cost 0.06657528877258301 s
DEBUG 01-13 08:46:48.765242.765242 cuda_h.py:19] end allocate_cuda_memory cost 0.0009353160858154297 seconds
DEBUG 01-13 08:46:48.765838.765838 cuda_h.py:19] end experts_func_gpu_einsum_mp cost 0.0681459903717041 seconds
DEBUG 01-13 08:46:48.766994.766994 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-13 08:46:48.766135.766135 sllm_store_c.py:27] get device uuid map
DEBUG 01-13 08:46:48.766766.766766 sllm_store_c.py:29] call client load into gpu
DEBUG 01-13 08:46:48.766753.766753 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 6aad2c61-8549-48b0-80cf-ed06ba71af5b
DEBUG 01-13 08:46:48.766581.766581 client.py:106] call stub.LoadModelAsync
DEBUG 01-13 08:46:48.766608.766608 cuda_h.py:10] start experts_func_gpu_einsum_mp
INFO 01-13 08:46:48.771403.771403 client.py:127] Model loaded
DEBUG 01-13 08:46:48.771193.771193 cuda_h.py:10] start restore2model
DEBUG 01-13 08:46:48.772665.772665 cuda_h.py:19] end restore2model cost 0.0004036426544189453 seconds
DEBUG 01-13 08:46:48.772110.772110 cuda_h.py:19] end sllm_worker_task cost 0.01433873176574707 seconds
INFO 01-13 08:46:48.773781.773781 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 6aad2c61-8549-48b0-80cf-ed06ba71af5b
DEBUG 01-13 08:46:48.774095.774095 cuda_h.py:19] end load_into_gpu_async cost 0.007907629013061523 seconds
DEBUG 01-13 08:46:48.774798.774798 cuda_h.py:10] start restore_tensors2
DEBUG 01-13 08:46:48.774163.774163 cuda_h.py:19] end restore_tensors2 cost 0.0003826618194580078 seconds
DEBUG 01-13 08:46:48.774953.774953 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.010030508041381836 seconds
DEBUG 01-13 08:46:48.774623.774623 cuda_h.py:10] start restore2model
DEBUG 01-13 08:46:48.777463.777463 cuda_h.py:19] end restore2model cost 0.0025186538696289062 seconds
DEBUG 01-13 08:46:48.777352.777352 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.012746810913085938 seconds
DEBUG 01-13 08:46:48.777168.777168 cuda_h.py:10] start gpu_sexperts
DEBUG 01-13 08:46:48.777490.777490 cuda_h.py:19] end gpu_sexperts cost 0.00027680397033691406 seconds
DEBUG 01-13 08:46:48.777558.777558 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-13 08:46:48.777964.777964 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 1.3828277587890625e-05 seconds
DEBUG 01-13 08:46:48.777137.777137 cuda_h.py:10] start wait_experts
INFO 01-13 08:46:48.777502.777502 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 6aad2c61-8549-48b0-80cf-ed06ba71af5b
DEBUG 01-13 08:46:48.778021.778021 mlpmodule.py:1006] group tensors cost 0.010365724563598633 s
DEBUG 01-13 08:46:48.781638.781638 mlpmodule.py:1044] pad cost 0.0025691986083984375 s
DEBUG 01-13 08:46:48.782106.782106 mlpmodule.py:1050] create cpu tensor cost 6.413459777832031e-05 s
DEBUG 01-13 08:46:48.782997.782997 mlpmodule.py:1055] move to cpu cost 4.7206878662109375e-05 s
DEBUG 01-13 08:46:48.789515.789515 mlpmodule.py:1069] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-13 08:46:48.790064.790064 mlpmodule.py:1070] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-13 08:46:48.790227.790227 mlpmodule.py:1075] group_w3 first element: -0.003631591796875
WARNING 01-13 08:46:48.790306.790306 mlpmodule.py:1085] start einsum2
DEBUG 01-13 08:46:48.803780.803780 mlpmodule.py:1095] group einsum cost 0.021519899368286133 s
DEBUG 01-13 08:46:48.804355.804355 mlpmodule.py:1103] cpy2cputensor cost 0.0007145404815673828 s
INFO 01-13 08:46:48.824616.824616 client.py:127] Model loaded
DEBUG 01-13 08:46:48.824648.824648 cuda_h.py:19] end wait_experts cost 0.04705095291137695 seconds
DEBUG 01-13 08:46:48.824278.824278 cuda_h.py:10] start gpu_experts
DEBUG 01-13 08:46:48.825383.825383 mlpmodule.py:559] gpu group tensors cost 0.0006418228149414062 s
DEBUG 01-13 08:46:48.827214.827214 mlpmodule.py:592] gpu pad cost 0.0014226436614990234 s
DEBUG 01-13 08:46:48.827733.827733 mlpmodule.py:598] start_w1
DEBUG 01-13 08:46:48.827049.827049 mlpmodule.py:602] start_w3
DEBUG 01-13 08:46:48.827115.827115 mlpmodule.py:608] start_w2
DEBUG 01-13 08:46:48.827610.827610 mlpmodule.py:611] gpu group einsum cost 0.0006802082061767578 s
DEBUG 01-13 08:46:48.828279.828279 mlpmodule.py:785]  experts func einsum cost 0.06001877784729004 s
DEBUG 01-13 08:46:48.828136.828136 cuda_h.py:19] end experts_func_gpu_einsum_mp cost 0.06154966354370117 seconds
DEBUG 01-13 08:46:48.830845.830845 mlpmodule.py:683] gpu experts func einsum cost 0.005339384078979492 s
DEBUG 01-13 08:46:48.830967.830967 cuda_h.py:19] end gpu_experts cost 0.005502462387084961 seconds
DEBUG 01-13 08:46:48.830815.830815 cuda_h.py:10] start cpu_thread_manager_mp_wait
DEBUG 01-13 08:46:48.830672.830672 cuda_h.py:19] end cpu_thread_manager_mp_wait cost 3.743171691894531e-05 seconds
DEBUG 01-13 08:46:48.830119.830119 cuda_h.py:19] end layer_moe_generate_mp_l_7 cost 0.06849312782287598 seconds
DEBUG 01-13 08:46:48.830074.830074 lmp.py:1550] -------------------------------- end prefill layer 6 --------------------------------
DEBUG 01-13 08:46:48.830089.830089 lmp.py:1493] -------------------------------- start prefill layer 7 --------------------------------
DEBUG 01-13 08:46:48.830884.830884 cuda_h.py:10] start start_load_qkvogn_s_weight_l_8
DEBUG 01-13 08:46:48.830018.830018 cuda_h.py:10] start start_load_qkvogn_s_weight_l_8
DEBUG 01-13 08:46:48.830092.830092 cuda_h.py:19] end start_load_qkvogn_s_weight_l_8 cost 3.0517578125e-05 seconds
DEBUG 01-13 08:46:48.830054.830054 cuda_h.py:19] end start_load_qkvogn_s_weight_l_8 cost 7.605552673339844e-05 seconds
DEBUG 01-13 08:46:48.831758.831758 cuda_h.py:10] start sllm_worker_task
DEBUG 01-13 08:46:48.831356.831356 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-13 08:46:48.831511.831511 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-13 08:46:48.831985.831985 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-13 08:46:48.831784.831784 cuda_h.py:19] end allocate_cuda_memory cost 0.0003044605255126953 seconds
DEBUG 01-13 08:46:48.831291.831291 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-13 08:46:48.831835.831835 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-13 08:46:48.831772.831772 sllm_store_c.py:27] get device uuid map
DEBUG 01-13 08:46:48.831125.831125 sllm_store_c.py:29] call client load into gpu
DEBUG 01-13 08:46:48.831589.831589 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, de1a4199-8bfc-42cf-96f7-c93ca4236f64
DEBUG 01-13 08:46:48.831228.831228 client.py:106] call stub.LoadModelAsync
DEBUG 01-13 08:46:48.832323.832323 cuda_h.py:10] start self_attn
INFO 01-13 08:46:48.833139.833139 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, de1a4199-8bfc-42cf-96f7-c93ca4236f64
DEBUG 01-13 08:46:48.833213.833213 cuda_h.py:19] end load_into_gpu_async cost 0.0013086795806884766 seconds
DEBUG 01-13 08:46:48.833009.833009 cuda_h.py:10] start restore_tensors2
DEBUG 01-13 08:46:48.833184.833184 cuda_h.py:19] end restore_tensors2 cost 6.794929504394531e-05 seconds
DEBUG 01-13 08:46:48.833794.833794 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0020596981048583984 seconds
INFO 01-13 08:46:48.833399.833399 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, de1a4199-8bfc-42cf-96f7-c93ca4236f64
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-13 08:46:48.835850.835850 cuda_h.py:19] end self_attn cost 0.002820730209350586 seconds
DEBUG 01-13 08:46:48.835980.835980 cuda_h.py:19] end iln_self_attn_paln cost 0.004258632659912109 seconds
DEBUG 01-13 08:46:48.835916.835916 cuda_h.py:10] start layer_moe_generate_mp_l_8
DEBUG 01-13 08:46:48.835056.835056 cuda_h.py:10] start gate
DEBUG 01-13 08:46:48.836575.836575 cuda_h.py:19] end gate cost 0.000629425048828125 seconds
DEBUG 01-13 08:46:48.836027.836027 cuda_h.py:10] start experts_map_get
DEBUG 01-13 08:46:48.836064.836064 lmp.py:1611] 
DEBUG 01-13 08:46:48.836064.836064 lmp.py:1611] Expert Token Distribution & Device Allocation:
DEBUG 01-13 08:46:48.836488.836488 lmp.py:1612]   Total experts: 64
DEBUG 01-13 08:46:48.836615.836615 lmp.py:1613]   CPU experts: 32 (50%)
DEBUG 01-13 08:46:48.836165.836165 lmp.py:1614]   GPU experts: 32 (50%)
DEBUG 01-13 08:46:48.836762.836762 lmp.py:1615] 
DEBUG 01-13 08:46:48.836762.836762 lmp.py:1615]   Expert ID | Tokens | Device
DEBUG 01-13 08:46:48.836882.836882 lmp.py:1616]   -----------------------------------
DEBUG 01-13 08:46:48.836201.836201 lmp.py:1622]   Expert 50 |     49 | CPU
DEBUG 01-13 08:46:48.836320.836320 lmp.py:1622]   Expert  3 |     56 | CPU
DEBUG 01-13 08:46:48.836963.836963 lmp.py:1622]   Expert 46 |     60 | CPU
DEBUG 01-13 08:46:48.836891.836891 lmp.py:1622]   Expert  1 |     78 | CPU
DEBUG 01-13 08:46:48.836057.836057 lmp.py:1622]   Expert  4 |     86 | CPU
DEBUG 01-13 08:46:48.836462.836462 lmp.py:1622]   Expert 29 |     92 | CPU
DEBUG 01-13 08:46:48.836389.836389 lmp.py:1622]   Expert 15 |     94 | CPU
DEBUG 01-13 08:46:48.836556.836556 lmp.py:1622]   Expert 40 |     96 | CPU
DEBUG 01-13 08:46:48.836722.836722 lmp.py:1622]   Expert  8 |    110 | CPU
DEBUG 01-13 08:46:48.836888.836888 lmp.py:1622]   Expert 28 |    110 | CPU
DEBUG 01-13 08:46:48.836292.836292 lmp.py:1622]   Expert 41 |    112 | CPU
DEBUG 01-13 08:46:48.836174.836174 lmp.py:1622]   Expert 48 |    120 | CPU
DEBUG 01-13 08:46:48.836055.836055 lmp.py:1622]   Expert 16 |    124 | CPU
DEBUG 01-13 08:46:48.836175.836175 lmp.py:1622]   Expert  6 |    125 | CPU
DEBUG 01-13 08:46:48.836580.836580 lmp.py:1622]   Expert 54 |    132 | CPU
DEBUG 01-13 08:46:48.836746.836746 lmp.py:1622]   Expert  7 |    134 | CPU
DEBUG 01-13 08:46:48.836389.836389 lmp.py:1622]   Expert 13 |    134 | CPU
DEBUG 01-13 08:46:48.836793.836793 lmp.py:1622]   Expert 27 |    135 | CPU
DEBUG 01-13 08:46:48.837198.837198 lmp.py:1622]   Expert 39 |    138 | CPU
DEBUG 01-13 08:46:48.837364.837364 lmp.py:1622]   Expert 51 |    141 | CPU
DEBUG 01-13 08:46:48.837530.837530 lmp.py:1622]   Expert 56 |    142 | CPU
DEBUG 01-13 08:46:48.837458.837458 lmp.py:1622]   Expert 60 |    142 | CPU
DEBUG 01-13 08:46:48.837624.837624 lmp.py:1622]   Expert 55 |    143 | CPU
DEBUG 01-13 08:46:48.837790.837790 lmp.py:1622]   Expert 14 |    144 | CPU
DEBUG 01-13 08:46:48.837956.837956 lmp.py:1622]   Expert 18 |    146 | CPU
DEBUG 01-13 08:46:48.837314.837314 lmp.py:1622]   Expert 20 |    147 | CPU
DEBUG 01-13 08:46:48.837196.837196 lmp.py:1622]   Expert 36 |    149 | CPU
DEBUG 01-13 08:46:48.837316.837316 lmp.py:1622]   Expert 52 |    149 | CPU
DEBUG 01-13 08:46:48.837197.837197 lmp.py:1622]   Expert 43 |    151 | CPU
DEBUG 01-13 08:46:48.837363.837363 lmp.py:1622]   Expert 10 |    155 | CPU
DEBUG 01-13 08:46:48.837052.837052 lmp.py:1622]   Expert 45 |    156 | CPU
DEBUG 01-13 08:46:48.837980.837980 lmp.py:1622]   Expert  5 |    157 | CPU
DEBUG 01-13 08:46:48.837908.837908 lmp.py:1622]   Expert 11 |    158 | GPU
DEBUG 01-13 08:46:48.837074.837074 lmp.py:1622]   Expert 33 |    166 | GPU
DEBUG 01-13 08:46:48.837479.837479 lmp.py:1622]   Expert 62 |    166 | GPU
DEBUG 01-13 08:46:48.837645.837645 lmp.py:1622]   Expert 44 |    175 | GPU
DEBUG 01-13 08:46:48.837811.837811 lmp.py:1622]   Expert 57 |    175 | GPU
DEBUG 01-13 08:46:48.837692.837692 lmp.py:1622]   Expert 58 |    182 | GPU
DEBUG 01-13 08:46:48.837335.837335 lmp.py:1622]   Expert 53 |    184 | GPU
DEBUG 01-13 08:46:48.837932.837932 lmp.py:1622]   Expert 25 |    185 | GPU
DEBUG 01-13 08:46:48.837813.837813 lmp.py:1622]   Expert 32 |    186 | GPU
DEBUG 01-13 08:46:48.837741.837741 lmp.py:1622]   Expert 31 |    190 | GPU
DEBUG 01-13 08:46:48.837907.837907 lmp.py:1622]   Expert  2 |    193 | GPU
DEBUG 01-13 08:46:48.837596.837596 lmp.py:1622]   Expert 63 |    196 | GPU
DEBUG 01-13 08:46:48.837763.837763 lmp.py:1622]   Expert 49 |    197 | GPU
DEBUG 01-13 08:46:48.837690.837690 lmp.py:1622]   Expert 35 |    206 | GPU
DEBUG 01-13 08:46:48.837618.837618 lmp.py:1622]   Expert 21 |    210 | GPU
DEBUG 01-13 08:46:48.837546.837546 lmp.py:1622]   Expert 17 |    214 | GPU
DEBUG 01-13 08:46:48.837473.837473 lmp.py:1622]   Expert 34 |    215 | GPU
DEBUG 01-13 08:46:48.837640.837640 lmp.py:1622]   Expert 42 |    216 | GPU
DEBUG 01-13 08:46:48.837044.837044 lmp.py:1622]   Expert 37 |    224 | GPU
DEBUG 01-13 08:46:48.837926.837926 lmp.py:1622]   Expert 59 |    230 | GPU
DEBUG 01-13 08:46:48.837045.837045 lmp.py:1622]   Expert  0 |    237 | GPU
DEBUG 01-13 08:46:48.837642.837642 lmp.py:1622]   Expert 22 |    239 | GPU
DEBUG 01-13 08:46:48.837908.837908 lmp.py:1622]   Expert 19 |    258 | GPU
DEBUG 01-13 08:46:48.837835.837835 lmp.py:1622]   Expert 24 |    280 | GPU
DEBUG 01-13 08:46:48.837048.837048 lmp.py:1622]   Expert 61 |    287 | GPU
DEBUG 01-13 08:46:48.837260.837260 lmp.py:1622]   Expert 30 |    302 | GPU
DEBUG 01-13 08:46:48.837473.837473 lmp.py:1622]   Expert 47 |    325 | GPU
DEBUG 01-13 08:46:48.837685.837685 lmp.py:1622]   Expert 38 |    367 | GPU
DEBUG 01-13 08:46:48.837898.837898 lmp.py:1622]   Expert 26 |    368 | GPU
DEBUG 01-13 08:46:48.837395.837395 lmp.py:1622]   Expert 12 |    435 | GPU
DEBUG 01-13 08:46:48.837607.837607 lmp.py:1622]   Expert  9 |    693 | GPU
DEBUG 01-13 08:46:48.837105.837105 lmp.py:1622]   Expert 23 |    722 | GPU
DEBUG 01-13 08:46:48.837271.837271 lmp.py:1623] 
DEBUG 01-13 08:46:48.837271.837271 lmp.py:1623]   CPU total tokens: 3907 (31.8%)
DEBUG 01-13 08:46:48.837390.837390 lmp.py:1624]   GPU total tokens: 8381 (68.2%)
DEBUG 01-13 08:46:48.837802.837802 cuda_h.py:19] end experts_map_get cost 0.0015609264373779297 seconds
DEBUG 01-13 08:46:48.837506.837506 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-13 08:46:48.837116.837116 lmp.py:1632] 
DEBUG 01-13 08:46:48.837116.837116 lmp.py:1632]   Computing 32 experts on CPU MP...
DEBUG 01-13 08:46:48.837230.837230 cuda_h.py:19] end cpu_experts_submit cost 4.863739013671875e-05 seconds
DEBUG 01-13 08:46:48.838258.838258 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-13 08:46:48.838372.838372 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-13 08:46:48.838071.838071 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-13 08:46:48.839065.839065 cuda_h.py:19] end allocate_cuda_memory cost 0.0011546611785888672 seconds
DEBUG 01-13 08:46:48.839316.839316 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-13 08:46:48.840857.840857 sllm_store_c.py:27] get device uuid map
DEBUG 01-13 08:46:48.840967.840967 sllm_store_c.py:29] call client load into gpu
DEBUG 01-13 08:46:48.840453.840453 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 22000702-90f0-4c39-b062-d5bdcca8d9b1
DEBUG 01-13 08:46:48.840608.840608 cuda_h.py:10] start experts_func_gpu_einsum_mp
DEBUG 01-13 08:46:48.840093.840093 client.py:106] call stub.LoadModelAsync
INFO 01-13 08:46:48.841038.841038 client.py:127] Model loaded
DEBUG 01-13 08:46:48.841219.841219 cuda_h.py:10] start restore2model
DEBUG 01-13 08:46:48.841221.841221 cuda_h.py:19] end restore2model cost 0.0004177093505859375 seconds
DEBUG 01-13 08:46:48.841574.841574 cuda_h.py:19] end sllm_worker_task cost 0.010589599609375 seconds
INFO 01-13 08:46:48.841232.841232 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 22000702-90f0-4c39-b062-d5bdcca8d9b1
DEBUG 01-13 08:46:48.842038.842038 cuda_h.py:19] end load_into_gpu_async cost 0.0020296573638916016 seconds
DEBUG 01-13 08:46:48.842716.842716 cuda_h.py:10] start restore_tensors2
DEBUG 01-13 08:46:48.843972.843972 cuda_h.py:19] end restore_tensors2 cost 0.0008456707000732422 seconds
DEBUG 01-13 08:46:48.843361.843361 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.005188465118408203 seconds
DEBUG 01-13 08:46:48.843252.843252 cuda_h.py:10] start restore2model
DEBUG 01-13 08:46:48.847057.847057 mlpmodule.py:1006] group tensors cost 0.006011247634887695 s
DEBUG 01-13 08:46:48.851216.851216 cuda_h.py:19] end restore2model cost 0.008128643035888672 seconds
DEBUG 01-13 08:46:48.851466.851466 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.013707637786865234 seconds
DEBUG 01-13 08:46:48.851051.851051 cuda_h.py:10] start gpu_sexperts
DEBUG 01-13 08:46:48.851411.851411 mlpmodule.py:1044] pad cost 0.0034027099609375 s
DEBUG 01-13 08:46:48.852973.852973 mlpmodule.py:1050] create cpu tensor cost 7.915496826171875e-05 s
DEBUG 01-13 08:46:48.852460.852460 mlpmodule.py:1055] move to cpu cost 5.4836273193359375e-05 s
DEBUG 01-13 08:46:48.852034.852034 cuda_h.py:19] end gpu_sexperts cost 0.0007734298706054688 seconds
DEBUG 01-13 08:46:48.852694.852694 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-13 08:46:48.852771.852771 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 3.695487976074219e-05 seconds
DEBUG 01-13 08:46:48.853012.853012 cuda_h.py:10] start wait_experts
INFO 01-13 08:46:48.853929.853929 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 22000702-90f0-4c39-b062-d5bdcca8d9b1
DEBUG 01-13 08:46:48.861678.861678 mlpmodule.py:1069] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-13 08:46:48.861831.861831 mlpmodule.py:1070] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-13 08:46:48.861424.861424 mlpmodule.py:1075] group_w3 first element: 0.01263427734375
WARNING 01-13 08:46:48.861363.861363 mlpmodule.py:1085] start einsum2
DEBUG 01-13 08:46:48.880920.880920 mlpmodule.py:1095] group einsum cost 0.028077125549316406 s
DEBUG 01-13 08:46:48.881973.881973 mlpmodule.py:1103] cpy2cputensor cost 0.0007121562957763672 s
INFO 01-13 08:46:48.892830.892830 client.py:127] Model loaded
DEBUG 01-13 08:46:48.892730.892730 cuda_h.py:19] end wait_experts cost 0.03973674774169922 seconds
DEBUG 01-13 08:46:48.892208.892208 cuda_h.py:10] start gpu_experts
DEBUG 01-13 08:46:48.893164.893164 mlpmodule.py:559] gpu group tensors cost 0.0007698535919189453 s
DEBUG 01-13 08:46:48.895475.895475 mlpmodule.py:592] gpu pad cost 0.0020873546600341797 s
DEBUG 01-13 08:46:48.895477.895477 mlpmodule.py:598] start_w1
DEBUG 01-13 08:46:48.896878.896878 mlpmodule.py:602] start_w3
DEBUG 01-13 08:46:48.896930.896930 mlpmodule.py:608] start_w2
DEBUG 01-13 08:46:48.896829.896829 mlpmodule.py:611] gpu group einsum cost 0.0006113052368164062 s
DEBUG 01-13 08:46:48.898498.898498 mlpmodule.py:683] gpu experts func einsum cost 0.005794048309326172 s
DEBUG 01-13 08:46:48.898137.898137 cuda_h.py:19] end gpu_experts cost 0.005956888198852539 seconds
DEBUG 01-13 08:46:48.898939.898939 cuda_h.py:10] start cpu_thread_manager_mp_wait
DEBUG 01-13 08:46:48.898504.898504 cuda_h.py:19] end cpu_thread_manager_mp_wait cost 3.528594970703125e-05 seconds
DEBUG 01-13 08:46:48.899566.899566 cuda_h.py:19] end layer_moe_generate_mp_l_8 cost 0.06351089477539062 seconds
DEBUG 01-13 08:46:48.899687.899687 lmp.py:1550] -------------------------------- end prefill layer 7 --------------------------------
DEBUG 01-13 08:46:48.899271.899271 lmp.py:1493] -------------------------------- start prefill layer 8 --------------------------------
DEBUG 01-13 08:46:48.899258.899258 cuda_h.py:10] start start_load_qkvogn_s_weight_l_9
DEBUG 01-13 08:46:48.899153.899153 cuda_h.py:10] start start_load_qkvogn_s_weight_l_9
DEBUG 01-13 08:46:48.899520.899520 cuda_h.py:19] end start_load_qkvogn_s_weight_l_9 cost 3.075599670410156e-05 seconds
DEBUG 01-13 08:46:48.899077.899077 cuda_h.py:19] end start_load_qkvogn_s_weight_l_9 cost 5.888938903808594e-05 seconds
DEBUG 01-13 08:46:48.899197.899197 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-13 08:46:48.899602.899602 cuda_h.py:10] start sllm_worker_task
DEBUG 01-13 08:46:48.899486.899486 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-13 08:46:48.899038.899038 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-13 08:46:48.899709.899709 cuda_h.py:19] end allocate_cuda_memory cost 0.00024819374084472656 seconds
DEBUG 01-13 08:46:48.900501.900501 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-13 08:46:48.900013.900013 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-13 08:46:48.900294.900294 sllm_store_c.py:27] get device uuid map
DEBUG 01-13 08:46:48.900369.900369 sllm_store_c.py:29] call client load into gpu
DEBUG 01-13 08:46:48.900264.900264 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 1f44bcf9-8628-426c-ba3d-7d73d4a3643d
DEBUG 01-13 08:46:48.900585.900585 client.py:106] call stub.LoadModelAsync
DEBUG 01-13 08:46:48.900873.900873 cuda_h.py:10] start self_attn
INFO 01-13 08:46:48.901173.901173 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 1f44bcf9-8628-426c-ba3d-7d73d4a3643d
DEBUG 01-13 08:46:48.901579.901579 cuda_h.py:19] end load_into_gpu_async cost 0.0015799999237060547 seconds
DEBUG 01-13 08:46:48.901659.901659 cuda_h.py:10] start restore_tensors2
DEBUG 01-13 08:46:48.901457.901457 cuda_h.py:19] end restore_tensors2 cost 7.128715515136719e-05 seconds
DEBUG 01-13 08:46:48.901067.901067 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.002292156219482422 seconds
INFO 01-13 08:46:48.901473.901473 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 1f44bcf9-8628-426c-ba3d-7d73d4a3643d
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-13 08:46:48.903162.903162 cuda_h.py:19] end self_attn cost 0.0032393932342529297 seconds
DEBUG 01-13 08:46:48.904755.904755 cuda_h.py:19] end iln_self_attn_paln cost 0.004770517349243164 seconds
DEBUG 01-13 08:46:48.904975.904975 cuda_h.py:10] start layer_moe_generate_mp_l_9
DEBUG 01-13 08:46:48.904069.904069 cuda_h.py:10] start gate
DEBUG 01-13 08:46:48.905695.905695 cuda_h.py:19] end gate cost 0.0006604194641113281 seconds
DEBUG 01-13 08:46:48.905763.905763 cuda_h.py:10] start experts_map_get
DEBUG 01-13 08:46:48.905316.905316 lmp.py:1611] 
DEBUG 01-13 08:46:48.905316.905316 lmp.py:1611] Expert Token Distribution & Device Allocation:
DEBUG 01-13 08:46:48.905609.905609 lmp.py:1612]   Total experts: 64
DEBUG 01-13 08:46:48.905928.905928 lmp.py:1613]   CPU experts: 32 (50%)
DEBUG 01-13 08:46:48.905432.905432 lmp.py:1614]   GPU experts: 32 (50%)
DEBUG 01-13 08:46:48.905281.905281 lmp.py:1615] 
DEBUG 01-13 08:46:48.905281.905281 lmp.py:1615]   Expert ID | Tokens | Device
DEBUG 01-13 08:46:48.905400.905400 lmp.py:1616]   -----------------------------------
DEBUG 01-13 08:46:48.905240.905240 mlpmodule.py:785]  experts func einsum cost 0.06410861015319824 s
DEBUG 01-13 08:46:48.905765.905765 lmp.py:1622]   Expert 38 |     12 | CPU
DEBUG 01-13 08:46:48.905839.905839 lmp.py:1622]   Expert 39 |     67 | CPU
DEBUG 01-13 08:46:48.905005.905005 lmp.py:1622]   Expert  7 |     72 | CPU
DEBUG 01-13 08:46:48.905648.905648 lmp.py:1622]   Expert 30 |     75 | CPU
DEBUG 01-13 08:46:48.905337.905337 lmp.py:1622]   Expert 24 |     89 | CPU
DEBUG 01-13 08:46:48.905027.905027 lmp.py:1622]   Expert 27 |     92 | CPU
DEBUG 01-13 08:46:48.905716.905716 lmp.py:1622]   Expert 14 |     96 | CPU
DEBUG 01-13 08:46:48.905167.905167 lmp.py:1622]   Expert 36 |     98 | CPU
DEBUG 01-13 08:46:48.905856.905856 lmp.py:1622]   Expert 32 |    100 | CPU
DEBUG 01-13 08:46:48.905068.905068 lmp.py:1622]   Expert 17 |    102 | CPU
DEBUG 01-13 08:46:48.905996.905996 lmp.py:1622]   Expert 40 |    103 | CPU
DEBUG 01-13 08:46:48.905977.905977 lmp.py:1622]   Expert 16 |    105 | CPU
DEBUG 01-13 08:46:48.905428.905428 lmp.py:1622]   Expert 18 |    111 | CPU
DEBUG 01-13 08:46:48.905879.905879 lmp.py:1622]   Expert 48 |    113 | CPU
DEBUG 01-13 08:46:48.905568.905568 lmp.py:1622]   Expert 12 |    118 | CPU
DEBUG 01-13 08:46:48.905542.905542 lmp.py:1622]   Expert  1 |    119 | CPU
DEBUG 01-13 08:46:48.905801.905801 lmp.py:1622]   Expert  6 |    130 | CPU
DEBUG 01-13 08:46:48.905060.905060 lmp.py:1622]   Expert 42 |    132 | CPU
DEBUG 01-13 08:46:48.905557.905557 lmp.py:1622]   Expert 59 |    139 | CPU
DEBUG 01-13 08:46:48.905054.905054 lmp.py:1622]   Expert  0 |    145 | CPU
DEBUG 01-13 08:46:48.905790.905790 lmp.py:1622]   Expert 22 |    145 | CPU
DEBUG 01-13 08:46:48.905049.905049 lmp.py:1622]   Expert 51 |    145 | CPU
DEBUG 01-13 08:46:48.905784.905784 lmp.py:1622]   Expert 53 |    147 | CPU
DEBUG 01-13 08:46:48.905520.905520 lmp.py:1622]   Expert  8 |    154 | CPU
DEBUG 01-13 08:46:48.905209.905209 lmp.py:1622]   Expert 60 |    158 | CPU
DEBUG 01-13 08:46:48.905660.905660 lmp.py:1622]   Expert 15 |    168 | CPU
DEBUG 01-13 08:46:48.906349.906349 lmp.py:1622]   Expert 29 |    170 | CPU
DEBUG 01-13 08:46:48.906562.906562 lmp.py:1622]   Expert 44 |    172 | CPU
DEBUG 01-13 08:46:48.906059.906059 lmp.py:1622]   Expert 54 |    172 | CPU
DEBUG 01-13 08:46:48.906318.906318 lmp.py:1622]   Expert 33 |    175 | CPU
DEBUG 01-13 08:46:48.906577.906577 lmp.py:1622]   Expert 34 |    179 | CPU
DEBUG 01-13 08:46:48.906597.906597 lmp.py:1622]   Expert 35 |    179 | CPU
DEBUG 01-13 08:46:48.906856.906856 lmp.py:1622]   Expert 19 |    185 | GPU
DEBUG 01-13 08:46:48.906353.906353 lmp.py:1622]   Expert 47 |    193 | GPU
DEBUG 01-13 08:46:48.906612.906612 lmp.py:1622]   Expert 56 |    193 | GPU
DEBUG 01-13 08:46:48.906347.906347 lmp.py:1622]   Expert  9 |    197 | GPU
DEBUG 01-13 08:46:48.906368.906368 lmp.py:1622]   Expert 20 |    197 | GPU
DEBUG 01-13 08:46:48.906865.906865 lmp.py:1622]   Expert 21 |    197 | GPU
DEBUG 01-13 08:46:48.906077.906077 lmp.py:1622]   Expert 49 |    200 | GPU
DEBUG 01-13 08:46:48.906290.906290 lmp.py:1622]   Expert 45 |    201 | GPU
DEBUG 01-13 08:46:48.906264.906264 lmp.py:1622]   Expert 46 |    201 | GPU
DEBUG 01-13 08:46:48.906476.906476 lmp.py:1622]   Expert 28 |    203 | GPU
DEBUG 01-13 08:46:48.906212.906212 lmp.py:1622]   Expert  3 |    204 | GPU
DEBUG 01-13 08:46:48.906471.906471 lmp.py:1622]   Expert  2 |    218 | GPU
DEBUG 01-13 08:46:48.906491.906491 lmp.py:1622]   Expert 57 |    220 | GPU
DEBUG 01-13 08:46:48.906750.906750 lmp.py:1622]   Expert 13 |    222 | GPU
DEBUG 01-13 08:46:48.906770.906770 lmp.py:1622]   Expert 43 |    227 | GPU
DEBUG 01-13 08:46:48.906791.906791 lmp.py:1622]   Expert  4 |    229 | GPU
DEBUG 01-13 08:46:48.906049.906049 lmp.py:1622]   Expert 50 |    236 | GPU
DEBUG 01-13 08:46:48.906070.906070 lmp.py:1622]   Expert 10 |    237 | GPU
DEBUG 01-13 08:46:48.906567.906567 lmp.py:1622]   Expert 41 |    241 | GPU
DEBUG 01-13 08:46:48.906587.906587 lmp.py:1622]   Expert 26 |    257 | GPU
DEBUG 01-13 08:46:48.906846.906846 lmp.py:1622]   Expert 63 |    261 | GPU
DEBUG 01-13 08:46:48.906582.906582 lmp.py:1622]   Expert 37 |    264 | GPU
DEBUG 01-13 08:46:48.906079.906079 lmp.py:1622]   Expert 31 |    267 | GPU
DEBUG 01-13 08:46:48.906576.906576 lmp.py:1622]   Expert 61 |    267 | GPU
DEBUG 01-13 08:46:48.906312.906312 lmp.py:1622]   Expert 52 |    308 | GPU
DEBUG 01-13 08:46:48.906763.906763 lmp.py:1622]   Expert 62 |    329 | GPU
DEBUG 01-13 08:46:48.906537.906537 cuda_h.py:19] end experts_func_gpu_einsum_mp cost 0.06560516357421875 seconds
DEBUG 01-13 08:46:48.906214.906214 lmp.py:1622]   Expert 58 |    335 | GPU
DEBUG 01-13 08:46:48.906903.906903 lmp.py:1622]   Expert 55 |    339 | GPU
DEBUG 01-13 08:46:48.906162.906162 lmp.py:1622]   Expert 11 |    377 | GPU
DEBUG 01-13 08:46:48.906659.906659 lmp.py:1622]   Expert 23 |    380 | GPU
DEBUG 01-13 08:46:48.906156.906156 lmp.py:1622]   Expert 25 |    399 | GPU
DEBUG 01-13 08:46:48.906415.906415 lmp.py:1622]   Expert  5 |    522 | GPU
DEBUG 01-13 08:46:48.906389.906389 lmp.py:1623] 
DEBUG 01-13 08:46:48.906389.906389 lmp.py:1623]   CPU total tokens: 3982 (32.4%)
DEBUG 01-13 08:46:48.906078.906078 lmp.py:1624]   GPU total tokens: 8306 (67.6%)
DEBUG 01-13 08:46:48.906821.906821 cuda_h.py:19] end experts_map_get cost 0.0014891624450683594 seconds
DEBUG 01-13 08:46:48.906856.906856 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-13 08:46:48.906327.906327 lmp.py:1632] 
DEBUG 01-13 08:46:48.906327.906327 lmp.py:1632]   Computing 32 experts on CPU MP...
DEBUG 01-13 08:46:48.906441.906441 cuda_h.py:19] end cpu_experts_submit cost 4.935264587402344e-05 seconds
DEBUG 01-13 08:46:48.906204.906204 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-13 08:46:48.906941.906941 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-13 08:46:48.907838.907838 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-13 08:46:48.908533.908533 cuda_h.py:19] end allocate_cuda_memory cost 0.0007512569427490234 seconds
DEBUG 01-13 08:46:48.908714.908714 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-13 08:46:48.908901.908901 sllm_store_c.py:27] get device uuid map
DEBUG 01-13 08:46:48.908617.908617 sllm_store_c.py:29] call client load into gpu
DEBUG 01-13 08:46:48.908459.908459 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, c9b20127-78ee-4c23-9385-5bfc9128750b
DEBUG 01-13 08:46:48.908578.908578 client.py:106] call stub.LoadModelAsync
DEBUG 01-13 08:46:48.908410.908410 cuda_h.py:10] start experts_func_gpu_einsum_mp
INFO 01-13 08:46:48.908424.908424 client.py:127] Model loaded
DEBUG 01-13 08:46:48.908075.908075 cuda_h.py:10] start restore2model
DEBUG 01-13 08:46:48.909216.909216 cuda_h.py:19] end restore2model cost 0.0004162788391113281 seconds
DEBUG 01-13 08:46:48.909377.909377 cuda_h.py:19] end sllm_worker_task cost 0.009794950485229492 seconds
INFO 01-13 08:46:48.910670.910670 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, c9b20127-78ee-4c23-9385-5bfc9128750b
DEBUG 01-13 08:46:48.910706.910706 cuda_h.py:19] end load_into_gpu_async cost 0.0022764205932617188 seconds
DEBUG 01-13 08:46:48.910647.910647 cuda_h.py:10] start restore_tensors2
DEBUG 01-13 08:46:48.910058.910058 cuda_h.py:19] end restore_tensors2 cost 0.0003821849822998047 seconds
DEBUG 01-13 08:46:48.911232.911232 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0037729740142822266 seconds
DEBUG 01-13 08:46:48.911472.911472 cuda_h.py:10] start restore2model
DEBUG 01-13 08:46:48.913699.913699 cuda_h.py:19] end restore2model cost 0.002597332000732422 seconds
DEBUG 01-13 08:46:48.913634.913634 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.006894588470458984 seconds
DEBUG 01-13 08:46:48.913497.913497 cuda_h.py:10] start gpu_sexperts
DEBUG 01-13 08:46:48.914089.914089 cuda_h.py:19] end gpu_sexperts cost 0.0002665519714355469 seconds
DEBUG 01-13 08:46:48.914157.914157 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-13 08:46:48.914549.914549 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 1.5020370483398438e-05 seconds
DEBUG 01-13 08:46:48.914530.914530 cuda_h.py:10] start wait_experts
INFO 01-13 08:46:48.914465.914465 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, c9b20127-78ee-4c23-9385-5bfc9128750b
DEBUG 01-13 08:46:48.919675.919675 mlpmodule.py:1006] group tensors cost 0.009928703308105469 s
DEBUG 01-13 08:46:48.921921.921921 mlpmodule.py:1044] pad cost 0.0015611648559570312 s
DEBUG 01-13 08:46:48.921567.921567 mlpmodule.py:1050] create cpu tensor cost 6.890296936035156e-05 s
DEBUG 01-13 08:46:48.921517.921517 mlpmodule.py:1055] move to cpu cost 3.2901763916015625e-05 s
DEBUG 01-13 08:46:48.928582.928582 mlpmodule.py:1069] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-13 08:46:48.929643.929643 mlpmodule.py:1070] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-13 08:46:48.929819.929819 mlpmodule.py:1075] group_w3 first element: 0.0859375
WARNING 01-13 08:46:48.929877.929877 mlpmodule.py:1085] start einsum2
DEBUG 01-13 08:46:48.941231.941231 mlpmodule.py:1095] group einsum cost 0.02006220817565918 s
DEBUG 01-13 08:46:48.942523.942523 mlpmodule.py:1103] cpy2cputensor cost 0.0007405281066894531 s
INFO 01-13 08:46:48.960474.960474 client.py:127] Model loaded
DEBUG 01-13 08:46:48.960016.960016 cuda_h.py:19] end wait_experts cost 0.046686410903930664 seconds
DEBUG 01-13 08:46:48.960640.960640 cuda_h.py:10] start gpu_experts
DEBUG 01-13 08:46:48.961233.961233 mlpmodule.py:559] gpu group tensors cost 0.000621795654296875 s
DEBUG 01-13 08:46:48.962445.962445 mlpmodule.py:785]  experts func einsum cost 0.05289483070373535 s
DEBUG 01-13 08:46:48.962176.962176 cuda_h.py:19] end experts_func_gpu_einsum_mp cost 0.05399370193481445 seconds
DEBUG 01-13 08:46:48.963066.963066 mlpmodule.py:592] gpu pad cost 0.0014548301696777344 s
DEBUG 01-13 08:46:48.963061.963061 mlpmodule.py:598] start_w1
DEBUG 01-13 08:46:48.963391.963391 mlpmodule.py:602] start_w3
DEBUG 01-13 08:46:48.963198.963198 mlpmodule.py:608] start_w2
DEBUG 01-13 08:46:48.963767.963767 mlpmodule.py:611] gpu group einsum cost 0.0006945133209228516 s
DEBUG 01-13 08:46:48.966425.966425 mlpmodule.py:683] gpu experts func einsum cost 0.005156278610229492 s
DEBUG 01-13 08:46:48.966044.966044 cuda_h.py:19] end gpu_experts cost 0.00532984733581543 seconds
DEBUG 01-13 08:46:48.966701.966701 cuda_h.py:10] start cpu_thread_manager_mp_wait
DEBUG 01-13 08:46:48.966412.966412 cuda_h.py:19] end cpu_thread_manager_mp_wait cost 3.910064697265625e-05 seconds
DEBUG 01-13 08:46:48.966666.966666 cuda_h.py:19] end layer_moe_generate_mp_l_9 cost 0.062135934829711914 seconds
DEBUG 01-13 08:46:48.966647.966647 lmp.py:1550] -------------------------------- end prefill layer 8 --------------------------------
DEBUG 01-13 08:46:48.966655.966655 lmp.py:1493] -------------------------------- start prefill layer 9 --------------------------------
DEBUG 01-13 08:46:48.966497.966497 cuda_h.py:10] start start_load_qkvogn_s_weight_l_10
DEBUG 01-13 08:46:48.966107.966107 cuda_h.py:10] start start_load_qkvogn_s_weight_l_10
DEBUG 01-13 08:46:48.966513.966513 cuda_h.py:19] end start_load_qkvogn_s_weight_l_10 cost 2.956390380859375e-05 seconds
DEBUG 01-13 08:46:48.966567.966567 cuda_h.py:19] end start_load_qkvogn_s_weight_l_10 cost 7.200241088867188e-05 seconds
DEBUG 01-13 08:46:48.966210.966210 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-13 08:46:48.967583.967583 cuda_h.py:10] start sllm_worker_task
DEBUG 01-13 08:46:48.967528.967528 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-13 08:46:48.967828.967828 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-13 08:46:48.967905.967905 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-13 08:46:48.967448.967448 cuda_h.py:19] end allocate_cuda_memory cost 0.0003514289855957031 seconds
DEBUG 01-13 08:46:48.967008.967008 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-13 08:46:48.967321.967321 sllm_store_c.py:27] get device uuid map
DEBUG 01-13 08:46:48.967780.967780 sllm_store_c.py:29] call client load into gpu
DEBUG 01-13 08:46:48.967827.967827 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 0e1b6a27-8469-4feb-931f-5411352ab52a
DEBUG 01-13 08:46:48.968963.968963 client.py:106] call stub.LoadModelAsync
DEBUG 01-13 08:46:48.968977.968977 cuda_h.py:10] start self_attn
INFO 01-13 08:46:48.969812.969812 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 0e1b6a27-8469-4feb-931f-5411352ab52a
DEBUG 01-13 08:46:48.969345.969345 cuda_h.py:19] end load_into_gpu_async cost 0.0017015933990478516 seconds
DEBUG 01-13 08:46:48.969392.969392 cuda_h.py:10] start restore_tensors2
DEBUG 01-13 08:46:48.969409.969409 cuda_h.py:19] end restore_tensors2 cost 8.177757263183594e-05 seconds
DEBUG 01-13 08:46:48.969616.969616 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0024793148040771484 seconds
INFO 01-13 08:46:48.969605.969605 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 0e1b6a27-8469-4feb-931f-5411352ab52a
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-13 08:46:48.971301.971301 cuda_h.py:19] end self_attn cost 0.0028820037841796875 seconds
DEBUG 01-13 08:46:48.971264.971264 cuda_h.py:19] end iln_self_attn_paln cost 0.004540205001831055 seconds
DEBUG 01-13 08:46:48.971008.971008 cuda_h.py:10] start layer_moe_generate_mp_l_10
DEBUG 01-13 08:46:48.971625.971625 cuda_h.py:10] start gate
DEBUG 01-13 08:46:48.972892.972892 cuda_h.py:19] end gate cost 0.0006206035614013672 seconds
DEBUG 01-13 08:46:48.972529.972529 cuda_h.py:10] start experts_map_get
DEBUG 01-13 08:46:48.972413.972413 lmp.py:1611] 
DEBUG 01-13 08:46:48.972413.972413 lmp.py:1611] Expert Token Distribution & Device Allocation:
DEBUG 01-13 08:46:48.972030.972030 lmp.py:1612]   Total experts: 64
DEBUG 01-13 08:46:48.972872.972872 lmp.py:1613]   CPU experts: 32 (50%)
DEBUG 01-13 08:46:48.972422.972422 lmp.py:1614]   GPU experts: 32 (50%)
DEBUG 01-13 08:46:48.972112.972112 lmp.py:1615] 
DEBUG 01-13 08:46:48.972112.972112 lmp.py:1615]   Expert ID | Tokens | Device
DEBUG 01-13 08:46:48.972516.972516 lmp.py:1616]   -----------------------------------
DEBUG 01-13 08:46:48.972166.972166 lmp.py:1622]   Expert 24 |     40 | CPU
DEBUG 01-13 08:46:48.972332.972332 lmp.py:1622]   Expert  2 |     46 | CPU
DEBUG 01-13 08:46:48.972306.972306 lmp.py:1622]   Expert 32 |     64 | CPU
DEBUG 01-13 08:46:48.972042.972042 lmp.py:1622]   Expert 26 |     66 | CPU
DEBUG 01-13 08:46:48.972016.972016 lmp.py:1622]   Expert 19 |     68 | CPU
DEBUG 01-13 08:46:48.972990.972990 lmp.py:1622]   Expert 50 |     78 | CPU
DEBUG 01-13 08:46:48.972964.972964 lmp.py:1622]   Expert  7 |     80 | CPU
DEBUG 01-13 08:46:48.972700.972700 lmp.py:1622]   Expert 15 |     80 | CPU
DEBUG 01-13 08:46:48.972197.972197 lmp.py:1622]   Expert  4 |     83 | CPU
DEBUG 01-13 08:46:48.972932.972932 lmp.py:1622]   Expert 28 |     83 | CPU
DEBUG 01-13 08:46:48.972430.972430 lmp.py:1622]   Expert 59 |     86 | CPU
DEBUG 01-13 08:46:48.972119.972119 lmp.py:1622]   Expert 60 |     88 | CPU
DEBUG 01-13 08:46:48.972808.972808 lmp.py:1622]   Expert 23 |     97 | CPU
DEBUG 01-13 08:46:48.972021.972021 lmp.py:1622]   Expert  5 |    101 | CPU
DEBUG 01-13 08:46:48.972710.972710 lmp.py:1622]   Expert 49 |    102 | CPU
DEBUG 01-13 08:46:48.972684.972684 lmp.py:1622]   Expert 12 |    107 | CPU
DEBUG 01-13 08:46:48.972181.972181 lmp.py:1622]   Expert 10 |    108 | CPU
DEBUG 01-13 08:46:48.973394.973394 lmp.py:1622]   Expert 27 |    109 | CPU
DEBUG 01-13 08:46:48.973891.973891 lmp.py:1622]   Expert 41 |    123 | CPU
DEBUG 01-13 08:46:48.973865.973865 lmp.py:1622]   Expert  3 |    124 | CPU
DEBUG 01-13 08:46:48.973601.973601 lmp.py:1622]   Expert 13 |    126 | CPU
DEBUG 01-13 08:46:48.973098.973098 lmp.py:1622]   Expert 20 |    127 | CPU
DEBUG 01-13 08:46:48.973833.973833 lmp.py:1622]   Expert 25 |    127 | CPU
DEBUG 01-13 08:46:48.973331.973331 lmp.py:1622]   Expert 40 |    127 | CPU
DEBUG 01-13 08:46:48.973066.973066 lmp.py:1622]   Expert 16 |    130 | CPU
DEBUG 01-13 08:46:48.973802.973802 lmp.py:1622]   Expert 37 |    137 | CPU
DEBUG 01-13 08:46:48.973730.973730 lmp.py:1622]   Expert 17 |    144 | CPU
DEBUG 01-13 08:46:48.973611.973611 lmp.py:1622]   Expert 35 |    147 | CPU
DEBUG 01-13 08:46:48.973016.973016 lmp.py:1622]   Expert 22 |    152 | CPU
DEBUG 01-13 08:46:48.973420.973420 lmp.py:1622]   Expert 47 |    158 | CPU
DEBUG 01-13 08:46:48.973825.973825 lmp.py:1622]   Expert 53 |    166 | CPU
DEBUG 01-13 08:46:48.973752.973752 lmp.py:1622]   Expert 39 |    172 | CPU
DEBUG 01-13 08:46:48.973680.973680 lmp.py:1622]   Expert 38 |    178 | GPU
DEBUG 01-13 08:46:48.973369.973369 lmp.py:1622]   Expert 44 |    179 | GPU
DEBUG 01-13 08:46:48.973582.973582 lmp.py:1622]   Expert 36 |    181 | GPU
DEBUG 01-13 08:46:48.973033.973033 lmp.py:1622]   Expert 52 |    184 | GPU
DEBUG 01-13 08:46:48.973722.973722 lmp.py:1622]   Expert 18 |    185 | GPU
DEBUG 01-13 08:46:48.973173.973173 lmp.py:1622]   Expert 58 |    186 | GPU
DEBUG 01-13 08:46:48.973624.973624 lmp.py:1622]   Expert 62 |    198 | GPU
DEBUG 01-13 08:46:48.973313.973313 lmp.py:1622]   Expert 48 |    203 | GPU
DEBUG 01-13 08:46:48.973764.973764 lmp.py:1622]   Expert 14 |    212 | GPU
DEBUG 01-13 08:46:48.973930.973930 lmp.py:1622]   Expert 11 |    213 | GPU
DEBUG 01-13 08:46:48.973096.973096 lmp.py:1622]   Expert 30 |    220 | GPU
DEBUG 01-13 08:46:48.973262.973262 lmp.py:1622]   Expert  1 |    233 | GPU
DEBUG 01-13 08:46:48.973667.973667 lmp.py:1622]   Expert 31 |    233 | GPU
DEBUG 01-13 08:46:48.973595.973595 lmp.py:1622]   Expert 42 |    234 | GPU
DEBUG 01-13 08:46:48.973569.973569 lmp.py:1622]   Expert  6 |    235 | GPU
DEBUG 01-13 08:46:48.973258.973258 lmp.py:1622]   Expert 45 |    239 | GPU
DEBUG 01-13 08:46:48.973709.973709 lmp.py:1622]   Expert 51 |    244 | GPU
DEBUG 01-13 08:46:48.973160.973160 lmp.py:1622]   Expert 29 |    260 | GPU
DEBUG 01-13 08:46:48.973372.973372 lmp.py:1622]   Expert 34 |    260 | GPU
DEBUG 01-13 08:46:48.973823.973823 lmp.py:1622]   Expert 33 |    279 | GPU
DEBUG 01-13 08:46:48.973274.973274 lmp.py:1622]   Expert 57 |    294 | GPU
DEBUG 01-13 08:46:48.973487.973487 lmp.py:1622]   Expert 61 |    308 | GPU
DEBUG 01-13 08:46:48.973937.973937 lmp.py:1622]   Expert  0 |    314 | GPU
DEBUG 01-13 08:46:48.973865.973865 lmp.py:1622]   Expert 43 |    317 | GPU
DEBUG 01-13 08:46:48.973270.973270 lmp.py:1622]   Expert 46 |    354 | GPU
DEBUG 01-13 08:46:48.973674.973674 lmp.py:1622]   Expert  8 |    379 | GPU
DEBUG 01-13 08:46:48.973602.973602 lmp.py:1622]   Expert  9 |    386 | GPU
DEBUG 01-13 08:46:48.973245.973245 lmp.py:1622]   Expert 54 |    400 | GPU
DEBUG 01-13 08:46:48.973934.973934 lmp.py:1622]   Expert 56 |    412 | GPU
DEBUG 01-13 08:46:48.973624.973624 lmp.py:1622]   Expert 63 |    417 | GPU
DEBUG 01-13 08:46:48.973836.973836 lmp.py:1622]   Expert 55 |    423 | GPU
DEBUG 01-13 08:46:48.973525.973525 lmp.py:1622]   Expert 21 |    482 | GPU
DEBUG 01-13 08:46:48.973930.973930 lmp.py:1623] 
DEBUG 01-13 08:46:48.973930.973930 lmp.py:1623]   CPU total tokens: 3446 (28.0%)
DEBUG 01-13 08:46:48.973573.973573 lmp.py:1624]   GPU total tokens: 8842 (72.0%)
DEBUG 01-13 08:46:48.973746.973746 cuda_h.py:19] end experts_map_get cost 0.001500844955444336 seconds
DEBUG 01-13 08:46:48.973542.973542 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-13 08:46:48.973345.973345 lmp.py:1632] 
DEBUG 01-13 08:46:48.973345.973345 lmp.py:1632]   Computing 32 experts on CPU MP...
DEBUG 01-13 08:46:48.973221.973221 cuda_h.py:19] end cpu_experts_submit cost 4.887580871582031e-05 seconds
DEBUG 01-13 08:46:48.973725.973725 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-13 08:46:48.974455.974455 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-13 08:46:48.974466.974466 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-13 08:46:48.975349.975349 cuda_h.py:19] end allocate_cuda_memory cost 0.0015997886657714844 seconds
DEBUG 01-13 08:46:48.975192.975192 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-13 08:46:48.975041.975041 sllm_store_c.py:27] get device uuid map
DEBUG 01-13 08:46:48.975373.975373 sllm_store_c.py:29] call client load into gpu
DEBUG 01-13 08:46:48.975976.975976 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 0c20f723-348a-41dc-852e-95a3314ae0f9
DEBUG 01-13 08:46:48.976809.976809 client.py:106] call stub.LoadModelAsync
DEBUG 01-13 08:46:48.977251.977251 cuda_h.py:10] start experts_func_gpu_einsum_mp
INFO 01-13 08:46:48.977630.977630 client.py:127] Model loaded
DEBUG 01-13 08:46:48.977871.977871 cuda_h.py:10] start restore2model
DEBUG 01-13 08:46:48.978739.978739 cuda_h.py:19] end restore2model cost 0.0005536079406738281 seconds
DEBUG 01-13 08:46:48.978397.978397 cuda_h.py:19] end sllm_worker_task cost 0.01106882095336914 seconds
INFO 01-13 08:46:48.979671.979671 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 0c20f723-348a-41dc-852e-95a3314ae0f9
DEBUG 01-13 08:46:48.979967.979967 cuda_h.py:19] end load_into_gpu_async cost 0.0033311843872070312 seconds
DEBUG 01-13 08:46:48.979838.979838 cuda_h.py:10] start restore_tensors2
DEBUG 01-13 08:46:48.979589.979589 cuda_h.py:19] end restore_tensors2 cost 0.0004096031188964844 seconds
DEBUG 01-13 08:46:48.979525.979525 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.005822181701660156 seconds
DEBUG 01-13 08:46:48.979956.979956 cuda_h.py:10] start restore2model
DEBUG 01-13 08:46:48.982573.982573 cuda_h.py:19] end restore2model cost 0.0025682449340820312 seconds
DEBUG 01-13 08:46:48.982409.982409 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.0085601806640625 seconds
DEBUG 01-13 08:46:48.982059.982059 cuda_h.py:10] start gpu_sexperts
DEBUG 01-13 08:46:48.982247.982247 cuda_h.py:19] end gpu_sexperts cost 0.0002512931823730469 seconds
DEBUG 01-13 08:46:48.982216.982216 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-13 08:46:48.982316.982316 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 1.33514404296875e-05 seconds
DEBUG 01-13 08:46:48.982867.982867 cuda_h.py:10] start wait_experts
INFO 01-13 08:46:48.983993.983993 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 0c20f723-348a-41dc-852e-95a3314ae0f9
DEBUG 01-13 08:46:48.989627.989627 mlpmodule.py:1006] group tensors cost 0.011444091796875 s
DEBUG 01-13 08:46:48.993897.993897 mlpmodule.py:1044] pad cost 0.0029129981994628906 s
DEBUG 01-13 08:46:48.993399.993399 mlpmodule.py:1050] create cpu tensor cost 6.937980651855469e-05 s
DEBUG 01-13 08:46:48.993151.993151 mlpmodule.py:1055] move to cpu cost 4.863739013671875e-05 s
DEBUG 01-13 08:46:49.001740.001740 mlpmodule.py:1069] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-13 08:46:49.001078.001078 mlpmodule.py:1070] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-13 08:46:49.002924.002924 mlpmodule.py:1075] group_w3 first element: 0.0157470703125
WARNING 01-13 08:46:49.002625.002625 mlpmodule.py:1085] start einsum2
DEBUG 01-13 08:46:49.014822.014822 mlpmodule.py:1095] group einsum cost 0.021142959594726562 s
DEBUG 01-13 08:46:49.015657.015657 mlpmodule.py:1103] cpy2cputensor cost 0.000743865966796875 s
INFO 01-13 08:46:49.029747.029747 client.py:127] Model loaded
DEBUG 01-13 08:46:49.029495.029495 cuda_h.py:19] end wait_experts cost 0.04620718955993652 seconds
DEBUG 01-13 08:46:49.029165.029165 cuda_h.py:10] start gpu_experts
DEBUG 01-13 08:46:49.030751.030751 mlpmodule.py:559] gpu group tensors cost 0.0007722377777099609 s
DEBUG 01-13 08:46:49.031145.031145 mlpmodule.py:592] gpu pad cost 0.0016217231750488281 s
DEBUG 01-13 08:46:49.031777.031777 mlpmodule.py:598] start_w1
DEBUG 01-13 08:46:49.032199.032199 mlpmodule.py:602] start_w3
DEBUG 01-13 08:46:49.032267.032267 mlpmodule.py:608] start_w2
DEBUG 01-13 08:46:49.032267.032267 mlpmodule.py:611] gpu group einsum cost 0.0007808208465576172 s
DEBUG 01-13 08:46:49.034082.034082 mlpmodule.py:683] gpu experts func einsum cost 0.005517721176147461 s
DEBUG 01-13 08:46:49.035152.035152 cuda_h.py:19] end gpu_experts cost 0.005718231201171875 seconds
DEBUG 01-13 08:46:49.035239.035239 cuda_h.py:10] start cpu_thread_manager_mp_wait
DEBUG 01-13 08:46:49.035281.035281 cuda_h.py:19] end cpu_thread_manager_mp_wait cost 3.790855407714844e-05 seconds
DEBUG 01-13 08:46:49.035913.035913 cuda_h.py:19] end layer_moe_generate_mp_l_10 cost 0.06359386444091797 seconds
DEBUG 01-13 08:46:49.035695.035695 lmp.py:1550] -------------------------------- end prefill layer 9 --------------------------------
DEBUG 01-13 08:46:49.035849.035849 lmp.py:1493] -------------------------------- start prefill layer 10 --------------------------------
DEBUG 01-13 08:46:49.035929.035929 cuda_h.py:10] start start_load_qkvogn_s_weight_l_11
DEBUG 01-13 08:46:49.035917.035917 cuda_h.py:10] start start_load_qkvogn_s_weight_l_11
DEBUG 01-13 08:46:49.035614.035614 cuda_h.py:19] end start_load_qkvogn_s_weight_l_11 cost 3.123283386230469e-05 seconds
DEBUG 01-13 08:46:49.035171.035171 cuda_h.py:19] end start_load_qkvogn_s_weight_l_11 cost 6.246566772460938e-05 seconds
DEBUG 01-13 08:46:49.035126.035126 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-13 08:46:49.035314.035314 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-13 08:46:49.035350.035350 cuda_h.py:10] start sllm_worker_task
DEBUG 01-13 08:46:49.035625.035625 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-13 08:46:49.035700.035700 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-13 08:46:49.036076.036076 cuda_h.py:19] end allocate_cuda_memory cost 0.0003120899200439453 seconds
DEBUG 01-13 08:46:49.036423.036423 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-13 08:46:49.036882.036882 sllm_store_c.py:27] get device uuid map
DEBUG 01-13 08:46:49.036227.036227 sllm_store_c.py:29] call client load into gpu
DEBUG 01-13 08:46:49.036453.036453 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 13109b0c-5985-4a31-91dd-faa23fcb1cfe
DEBUG 01-13 08:46:49.036761.036761 client.py:106] call stub.LoadModelAsync
DEBUG 01-13 08:46:49.036001.036001 cuda_h.py:10] start self_attn
INFO 01-13 08:46:49.037876.037876 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 13109b0c-5985-4a31-91dd-faa23fcb1cfe
DEBUG 01-13 08:46:49.037984.037984 cuda_h.py:19] end load_into_gpu_async cost 0.0010933876037597656 seconds
DEBUG 01-13 08:46:49.037926.037926 cuda_h.py:10] start restore_tensors2
DEBUG 01-13 08:46:49.037624.037624 cuda_h.py:19] end restore_tensors2 cost 6.842613220214844e-05 seconds
DEBUG 01-13 08:46:49.037950.037950 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0017504692077636719 seconds
INFO 01-13 08:46:49.037826.037826 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 13109b0c-5985-4a31-91dd-faa23fcb1cfe
DEBUG 01-13 08:46:49.039268.039268 mlpmodule.py:785]  experts func einsum cost 0.06129050254821777 s
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-13 08:46:49.039941.039941 cuda_h.py:19] end self_attn cost 0.0028731822967529297 seconds
DEBUG 01-13 08:46:49.040249.040249 cuda_h.py:19] end experts_func_gpu_einsum_mp cost 0.06269645690917969 seconds
DEBUG 01-13 08:46:49.040931.040931 cuda_h.py:19] end iln_self_attn_paln cost 0.004426479339599609 seconds
DEBUG 01-13 08:46:49.040443.040443 cuda_h.py:10] start layer_moe_generate_mp_l_11
DEBUG 01-13 08:46:49.040683.040683 cuda_h.py:10] start gate
DEBUG 01-13 08:46:49.040898.040898 cuda_h.py:19] end gate cost 0.0006430149078369141 seconds
DEBUG 01-13 08:46:49.040966.040966 cuda_h.py:10] start experts_map_get
DEBUG 01-13 08:46:49.041366.041366 lmp.py:1611] 
DEBUG 01-13 08:46:49.041366.041366 lmp.py:1611] Expert Token Distribution & Device Allocation:
DEBUG 01-13 08:46:49.041175.041175 lmp.py:1612]   Total experts: 64
DEBUG 01-13 08:46:49.041779.041779 lmp.py:1613]   CPU experts: 32 (50%)
DEBUG 01-13 08:46:49.041852.041852 lmp.py:1614]   GPU experts: 32 (50%)
DEBUG 01-13 08:46:49.041018.041018 lmp.py:1615] 
DEBUG 01-13 08:46:49.041018.041018 lmp.py:1615]   Expert ID | Tokens | Device
DEBUG 01-13 08:46:49.041661.041661 lmp.py:1616]   -----------------------------------
DEBUG 01-13 08:46:49.041549.041549 lmp.py:1622]   Expert 43 |     19 | CPU
DEBUG 01-13 08:46:49.041477.041477 lmp.py:1622]   Expert 27 |     33 | CPU
DEBUG 01-13 08:46:49.041690.041690 lmp.py:1622]   Expert 34 |     51 | CPU
DEBUG 01-13 08:46:49.041948.041948 lmp.py:1622]   Expert 26 |     53 | CPU
DEBUG 01-13 08:46:49.041207.041207 lmp.py:1622]   Expert  3 |     55 | CPU
DEBUG 01-13 08:46:49.041704.041704 lmp.py:1622]   Expert 56 |     55 | CPU
DEBUG 01-13 08:46:49.041202.041202 lmp.py:1622]   Expert  4 |     73 | CPU
DEBUG 01-13 08:46:49.041699.041699 lmp.py:1622]   Expert 61 |     76 | CPU
DEBUG 01-13 08:46:49.041958.041958 lmp.py:1622]   Expert 14 |     89 | CPU
DEBUG 01-13 08:46:49.041693.041693 lmp.py:1622]   Expert 38 |     95 | CPU
DEBUG 01-13 08:46:49.041621.041621 lmp.py:1622]   Expert  2 |    115 | CPU
DEBUG 01-13 08:46:49.041595.041595 lmp.py:1622]   Expert 17 |    118 | CPU
DEBUG 01-13 08:46:49.041046.041046 lmp.py:1622]   Expert 37 |    124 | CPU
DEBUG 01-13 08:46:49.041497.041497 lmp.py:1622]   Expert 22 |    125 | CPU
DEBUG 01-13 08:46:49.041948.041948 lmp.py:1622]   Expert 47 |    127 | CPU
DEBUG 01-13 08:46:49.041683.041683 lmp.py:1622]   Expert 54 |    129 | CPU
DEBUG 01-13 08:46:49.041181.041181 lmp.py:1622]   Expert 55 |    131 | CPU
DEBUG 01-13 08:46:49.041678.041678 lmp.py:1622]   Expert 28 |    136 | CPU
DEBUG 01-13 08:46:49.041413.041413 lmp.py:1622]   Expert 15 |    143 | CPU
DEBUG 01-13 08:46:49.041149.041149 lmp.py:1622]   Expert 45 |    143 | CPU
DEBUG 01-13 08:46:49.041646.041646 lmp.py:1622]   Expert 12 |    146 | CPU
DEBUG 01-13 08:46:49.041382.041382 lmp.py:1622]   Expert 48 |    146 | CPU
DEBUG 01-13 08:46:49.041117.041117 lmp.py:1622]   Expert 60 |    147 | CPU
DEBUG 01-13 08:46:49.041853.041853 lmp.py:1622]   Expert 51 |    148 | CPU
DEBUG 01-13 08:46:49.041304.041304 lmp.py:1622]   Expert 63 |    149 | CPU
DEBUG 01-13 08:46:49.041278.041278 lmp.py:1622]   Expert  7 |    151 | CPU
DEBUG 01-13 08:46:49.041490.041490 lmp.py:1622]   Expert 19 |    151 | CPU
DEBUG 01-13 08:46:49.041988.041988 lmp.py:1622]   Expert  5 |    155 | CPU
DEBUG 01-13 08:46:49.041962.041962 lmp.py:1622]   Expert  6 |    160 | CPU
DEBUG 01-13 08:46:49.041697.041697 lmp.py:1622]   Expert 52 |    167 | CPU
DEBUG 01-13 08:46:49.041956.041956 lmp.py:1622]   Expert 57 |    175 | CPU
DEBUG 01-13 08:46:49.041215.041215 lmp.py:1622]   Expert 31 |    177 | CPU
DEBUG 01-13 08:46:49.041712.041712 lmp.py:1622]   Expert 18 |    180 | GPU
DEBUG 01-13 08:46:49.041209.041209 lmp.py:1622]   Expert 44 |    181 | GPU
DEBUG 01-13 08:46:49.041945.041945 lmp.py:1622]   Expert 13 |    182 | GPU
DEBUG 01-13 08:46:49.041204.041204 lmp.py:1622]   Expert 50 |    186 | GPU
DEBUG 01-13 08:46:49.041939.041939 lmp.py:1622]   Expert 30 |    187 | GPU
DEBUG 01-13 08:46:49.041437.041437 lmp.py:1622]   Expert 59 |    188 | GPU
DEBUG 01-13 08:46:49.041887.041887 lmp.py:1622]   Expert 53 |    192 | GPU
DEBUG 01-13 08:46:49.041100.041100 lmp.py:1622]   Expert 23 |    198 | GPU
DEBUG 01-13 08:46:49.041074.041074 lmp.py:1622]   Expert 29 |    198 | GPU
DEBUG 01-13 08:46:49.041048.041048 lmp.py:1622]   Expert 20 |    200 | GPU
DEBUG 01-13 08:46:49.042737.042737 lmp.py:1622]   Expert 39 |    200 | GPU
DEBUG 01-13 08:46:49.042235.042235 lmp.py:1622]   Expert 21 |    205 | GPU
DEBUG 01-13 08:46:49.042732.042732 lmp.py:1622]   Expert 36 |    205 | GPU
DEBUG 01-13 08:46:49.042752.042752 lmp.py:1622]   Expert 16 |    211 | GPU
DEBUG 01-13 08:46:49.042011.042011 lmp.py:1622]   Expert 41 |    213 | GPU
DEBUG 01-13 08:46:49.042508.042508 lmp.py:1622]   Expert 25 |    217 | GPU
DEBUG 01-13 08:46:49.042005.042005 lmp.py:1622]   Expert 32 |    218 | GPU
DEBUG 01-13 08:46:49.042979.042979 lmp.py:1622]   Expert 49 |    230 | GPU
DEBUG 01-13 08:46:49.042669.042669 lmp.py:1622]   Expert 46 |    231 | GPU
DEBUG 01-13 08:46:49.042881.042881 lmp.py:1622]   Expert  8 |    253 | GPU
DEBUG 01-13 08:46:49.042094.042094 lmp.py:1622]   Expert 10 |    253 | GPU
DEBUG 01-13 08:46:49.042783.042783 lmp.py:1622]   Expert 62 |    253 | GPU
DEBUG 01-13 08:46:49.042280.042280 lmp.py:1622]   Expert 42 |    255 | GPU
DEBUG 01-13 08:46:49.042777.042777 lmp.py:1622]   Expert 35 |    274 | GPU
DEBUG 01-13 08:46:49.042036.042036 lmp.py:1622]   Expert  9 |    288 | GPU
DEBUG 01-13 08:46:49.042533.042533 lmp.py:1622]   Expert 33 |    305 | GPU
DEBUG 01-13 08:46:49.042031.042031 lmp.py:1622]   Expert 58 |    313 | GPU
DEBUG 01-13 08:46:49.042766.042766 lmp.py:1622]   Expert 40 |    386 | GPU
DEBUG 01-13 08:46:49.042263.042263 lmp.py:1622]   Expert  0 |    430 | GPU
DEBUG 01-13 08:46:49.042714.042714 lmp.py:1622]   Expert 11 |    466 | GPU
DEBUG 01-13 08:46:49.042688.042688 lmp.py:1622]   Expert 24 |    559 | GPU
DEBUG 01-13 08:46:49.042378.042378 lmp.py:1622]   Expert  1 |    669 | GPU
DEBUG 01-13 08:46:49.042544.042544 lmp.py:1623] 
DEBUG 01-13 08:46:49.042544.042544 lmp.py:1623]   CPU total tokens: 3762 (30.6%)
DEBUG 01-13 08:46:49.042902.042902 lmp.py:1624]   GPU total tokens: 8526 (69.4%)
DEBUG 01-13 08:46:49.042313.042313 cuda_h.py:19] end experts_map_get cost 0.0014574527740478516 seconds
DEBUG 01-13 08:46:49.042971.042971 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-13 08:46:49.042012.042012 lmp.py:1632] 
DEBUG 01-13 08:46:49.042012.042012 lmp.py:1632]   Computing 32 experts on CPU MP...
DEBUG 01-13 08:46:49.042172.042172 cuda_h.py:19] end cpu_experts_submit cost 4.8160552978515625e-05 seconds
DEBUG 01-13 08:46:49.042961.042961 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-13 08:46:49.042314.042314 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-13 08:46:49.043481.043481 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-13 08:46:49.044834.044834 cuda_h.py:10] start experts_func_gpu_einsum_mp
DEBUG 01-13 08:46:49.044925.044925 cuda_h.py:19] end allocate_cuda_memory cost 0.0017621517181396484 seconds
DEBUG 01-13 08:46:49.044775.044775 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-13 08:46:49.044107.044107 sllm_store_c.py:27] get device uuid map
DEBUG 01-13 08:46:49.044777.044777 sllm_store_c.py:29] call client load into gpu
DEBUG 01-13 08:46:49.045573.045573 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, c07ebc2b-511c-4704-9ef8-ed67a9cab0df
DEBUG 01-13 08:46:49.045109.045109 client.py:106] call stub.LoadModelAsync
INFO 01-13 08:46:49.045420.045420 client.py:127] Model loaded
DEBUG 01-13 08:46:49.045726.045726 cuda_h.py:10] start restore2model
DEBUG 01-13 08:46:49.045738.045738 cuda_h.py:19] end restore2model cost 0.0003299713134765625 seconds
DEBUG 01-13 08:46:49.045601.045601 cuda_h.py:19] end sllm_worker_task cost 0.009964227676391602 seconds
INFO 01-13 08:46:49.046293.046293 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, c07ebc2b-511c-4704-9ef8-ed67a9cab0df
DEBUG 01-13 08:46:49.046759.046759 cuda_h.py:19] end load_into_gpu_async cost 0.0012519359588623047 seconds
DEBUG 01-13 08:46:49.046415.046415 cuda_h.py:10] start restore_tensors2
DEBUG 01-13 08:46:49.046483.046483 cuda_h.py:19] end restore_tensors2 cost 0.0004088878631591797 seconds
DEBUG 01-13 08:46:49.046465.046465 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.003793001174926758 seconds
DEBUG 01-13 08:46:49.046473.046473 cuda_h.py:10] start restore2model
DEBUG 01-13 08:46:49.049739.049739 cuda_h.py:19] end restore2model cost 0.0025887489318847656 seconds
DEBUG 01-13 08:46:49.049682.049682 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.0068645477294921875 seconds
DEBUG 01-13 08:46:49.049762.049762 cuda_h.py:10] start gpu_sexperts
DEBUG 01-13 08:46:49.049686.049686 cuda_h.py:19] end gpu_sexperts cost 0.0002639293670654297 seconds
DEBUG 01-13 08:46:49.049515.049515 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-13 08:46:49.049954.049954 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 1.4781951904296875e-05 seconds
DEBUG 01-13 08:46:49.049935.049935 cuda_h.py:10] start wait_experts
INFO 01-13 08:46:49.049869.049869 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, c07ebc2b-511c-4704-9ef8-ed67a9cab0df
DEBUG 01-13 08:46:49.053999.053999 mlpmodule.py:1006] group tensors cost 0.008961200714111328 s
DEBUG 01-13 08:46:49.056684.056684 mlpmodule.py:1044] pad cost 0.0016744136810302734 s
DEBUG 01-13 08:46:49.056680.056680 mlpmodule.py:1050] create cpu tensor cost 4.673004150390625e-05 s
DEBUG 01-13 08:46:49.056405.056405 mlpmodule.py:1055] move to cpu cost 4.076957702636719e-05 s
DEBUG 01-13 08:46:49.065439.065439 mlpmodule.py:1069] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-13 08:46:49.065986.065986 mlpmodule.py:1070] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-13 08:46:49.065073.065073 mlpmodule.py:1075] group_w3 first element: -0.0213623046875
WARNING 01-13 08:46:49.066924.066924 mlpmodule.py:1085] start einsum2
DEBUG 01-13 08:46:49.079223.079223 mlpmodule.py:1095] group einsum cost 0.02255725860595703 s
DEBUG 01-13 08:46:49.080720.080720 mlpmodule.py:1103] cpy2cputensor cost 0.0007302761077880859 s
INFO 01-13 08:46:49.097695.097695 client.py:127] Model loaded
DEBUG 01-13 08:46:49.097077.097077 cuda_h.py:19] end wait_experts cost 0.04732561111450195 seconds
DEBUG 01-13 08:46:49.097787.097787 cuda_h.py:10] start gpu_experts
DEBUG 01-13 08:46:49.097473.097473 mlpmodule.py:559] gpu group tensors cost 0.0006165504455566406 s
DEBUG 01-13 08:46:49.099791.099791 mlpmodule.py:592] gpu pad cost 0.0015366077423095703 s
DEBUG 01-13 08:46:49.099384.099384 mlpmodule.py:598] start_w1
DEBUG 01-13 08:46:49.100626.100626 mlpmodule.py:602] start_w3
DEBUG 01-13 08:46:49.100480.100480 mlpmodule.py:608] start_w2
DEBUG 01-13 08:46:49.100140.100140 mlpmodule.py:611] gpu group einsum cost 0.0006282329559326172 s
DEBUG 01-13 08:46:49.102111.102111 mlpmodule.py:683] gpu experts func einsum cost 0.00505828857421875 s
DEBUG 01-13 08:46:49.102810.102810 cuda_h.py:19] end gpu_experts cost 0.005223274230957031 seconds
DEBUG 01-13 08:46:49.102990.102990 cuda_h.py:10] start cpu_thread_manager_mp_wait
DEBUG 01-13 08:46:49.102124.102124 cuda_h.py:19] end cpu_thread_manager_mp_wait cost 3.743171691894531e-05 seconds
DEBUG 01-13 08:46:49.102041.102041 cuda_h.py:19] end layer_moe_generate_mp_l_11 cost 0.06252169609069824 seconds
DEBUG 01-13 08:46:49.102837.102837 lmp.py:1550] -------------------------------- end prefill layer 10 --------------------------------
DEBUG 01-13 08:46:49.102898.102898 lmp.py:1493] -------------------------------- start prefill layer 11 --------------------------------
DEBUG 01-13 08:46:49.103025.103025 cuda_h.py:10] start start_load_qkvogn_s_weight_l_12
DEBUG 01-13 08:46:49.103681.103681 cuda_h.py:10] start start_load_qkvogn_s_weight_l_12
DEBUG 01-13 08:46:49.103895.103895 cuda_h.py:19] end start_load_qkvogn_s_weight_l_12 cost 2.8848648071289062e-05 seconds
DEBUG 01-13 08:46:49.103664.103664 cuda_h.py:19] end start_load_qkvogn_s_weight_l_12 cost 7.271766662597656e-05 seconds
DEBUG 01-13 08:46:49.103698.103698 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-13 08:46:49.103495.103495 cuda_h.py:10] start sllm_worker_task
DEBUG 01-13 08:46:49.103770.103770 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-13 08:46:49.103414.103414 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-13 08:46:49.103505.103505 mlpmodule.py:785]  experts func einsum cost 0.058333635330200195 s
DEBUG 01-13 08:46:49.103853.103853 cuda_h.py:19] end allocate_cuda_memory cost 0.0004258155822753906 seconds
DEBUG 01-13 08:46:49.103325.103325 cuda_h.py:19] end experts_func_gpu_einsum_mp cost 0.059629201889038086 seconds
DEBUG 01-13 08:46:49.103307.103307 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-13 08:46:49.103851.103851 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-13 08:46:49.104173.104173 sllm_store_c.py:27] get device uuid map
DEBUG 01-13 08:46:49.104995.104995 sllm_store_c.py:29] call client load into gpu
DEBUG 01-13 08:46:49.104791.104791 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 6128edf0-2f4e-4aeb-8975-0d3603b738f9
DEBUG 01-13 08:46:49.104383.104383 client.py:106] call stub.LoadModelAsync
DEBUG 01-13 08:46:49.104254.104254 cuda_h.py:10] start self_attn
INFO 01-13 08:46:49.105197.105197 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 6128edf0-2f4e-4aeb-8975-0d3603b738f9
DEBUG 01-13 08:46:49.105749.105749 cuda_h.py:19] end load_into_gpu_async cost 0.0015840530395507812 seconds
DEBUG 01-13 08:46:49.105021.105021 cuda_h.py:10] start restore_tensors2
DEBUG 01-13 08:46:49.105435.105435 cuda_h.py:19] end restore_tensors2 cost 6.842613220214844e-05 seconds
DEBUG 01-13 08:46:49.105973.105973 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.002469301223754883 seconds
INFO 01-13 08:46:49.105233.105233 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 6128edf0-2f4e-4aeb-8975-0d3603b738f9
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-13 08:46:49.107119.107119 cuda_h.py:19] end self_attn cost 0.0028238296508789062 seconds
DEBUG 01-13 08:46:49.107512.107512 cuda_h.py:19] end iln_self_attn_paln cost 0.00450444221496582 seconds
DEBUG 01-13 08:46:49.107355.107355 cuda_h.py:10] start layer_moe_generate_mp_l_12
DEBUG 01-13 08:46:49.107688.107688 cuda_h.py:10] start gate
DEBUG 01-13 08:46:49.108412.108412 cuda_h.py:19] end gate cost 0.0006394386291503906 seconds
DEBUG 01-13 08:46:49.108242.108242 cuda_h.py:10] start experts_map_get
DEBUG 01-13 08:46:49.108927.108927 lmp.py:1611] 
DEBUG 01-13 08:46:49.108927.108927 lmp.py:1611] Expert Token Distribution & Device Allocation:
DEBUG 01-13 08:46:49.108491.108491 lmp.py:1612]   Total experts: 64
DEBUG 01-13 08:46:49.108141.108141 lmp.py:1613]   CPU experts: 32 (50%)
DEBUG 01-13 08:46:49.108168.108168 lmp.py:1614]   GPU experts: 32 (50%)
DEBUG 01-13 08:46:49.108811.108811 lmp.py:1615] 
DEBUG 01-13 08:46:49.108811.108811 lmp.py:1615]   Expert ID | Tokens | Device
DEBUG 01-13 08:46:49.108692.108692 lmp.py:1616]   -----------------------------------
DEBUG 01-13 08:46:49.108342.108342 lmp.py:1622]   Expert 39 |     15 | CPU
DEBUG 01-13 08:46:49.108985.108985 lmp.py:1622]   Expert 13 |     21 | CPU
DEBUG 01-13 08:46:49.108436.108436 lmp.py:1622]   Expert 49 |     33 | CPU
DEBUG 01-13 08:46:49.108887.108887 lmp.py:1622]   Expert 35 |     46 | CPU
DEBUG 01-13 08:46:49.108099.108099 lmp.py:1622]   Expert 19 |     58 | CPU
DEBUG 01-13 08:46:49.109073.109073 lmp.py:1622]   Expert 32 |     70 | CPU
DEBUG 01-13 08:46:49.109286.109286 lmp.py:1622]   Expert 41 |     77 | CPU
DEBUG 01-13 08:46:49.109021.109021 lmp.py:1622]   Expert 26 |     78 | CPU
DEBUG 01-13 08:46:49.109234.109234 lmp.py:1622]   Expert  9 |     82 | CPU
DEBUG 01-13 08:46:49.109400.109400 lmp.py:1622]   Expert 23 |     84 | CPU
DEBUG 01-13 08:46:49.109328.109328 lmp.py:1622]   Expert 46 |     84 | CPU
DEBUG 01-13 08:46:49.109255.109255 lmp.py:1622]   Expert 31 |     85 | CPU
DEBUG 01-13 08:46:49.109945.109945 lmp.py:1622]   Expert 33 |     85 | CPU
DEBUG 01-13 08:46:49.109396.109396 lmp.py:1622]   Expert 18 |     95 | CPU
DEBUG 01-13 08:46:49.109714.109714 lmp.py:1622]   Expert  3 |    101 | CPU
DEBUG 01-13 08:46:49.109834.109834 lmp.py:1622]   Expert  6 |    101 | CPU
DEBUG 01-13 08:46:49.109285.109285 lmp.py:1622]   Expert 38 |    105 | CPU
DEBUG 01-13 08:46:49.109213.109213 lmp.py:1622]   Expert 17 |    111 | CPU
DEBUG 01-13 08:46:49.109902.109902 lmp.py:1622]   Expert 20 |    112 | CPU
DEBUG 01-13 08:46:49.109591.109591 lmp.py:1622]   Expert 59 |    122 | CPU
DEBUG 01-13 08:46:49.109519.109519 lmp.py:1622]   Expert 40 |    127 | CPU
DEBUG 01-13 08:46:49.109400.109400 lmp.py:1622]   Expert 16 |    129 | CPU
DEBUG 01-13 08:46:49.109381.109381 lmp.py:1622]   Expert 61 |    132 | CPU
DEBUG 01-13 08:46:49.109309.109309 lmp.py:1622]   Expert 62 |    133 | CPU
DEBUG 01-13 08:46:49.109521.109521 lmp.py:1622]   Expert 43 |    134 | CPU
DEBUG 01-13 08:46:49.109972.109972 lmp.py:1622]   Expert 50 |    137 | CPU
DEBUG 01-13 08:46:49.109185.109185 lmp.py:1622]   Expert 63 |    142 | CPU
DEBUG 01-13 08:46:49.109920.109920 lmp.py:1622]   Expert 15 |    143 | CPU
DEBUG 01-13 08:46:49.109656.109656 lmp.py:1622]   Expert 36 |    144 | CPU
DEBUG 01-13 08:46:49.109392.109392 lmp.py:1622]   Expert  2 |    145 | CPU
DEBUG 01-13 08:46:49.109366.109366 lmp.py:1622]   Expert 42 |    146 | CPU
DEBUG 01-13 08:46:49.109101.109101 lmp.py:1622]   Expert 44 |    149 | CPU
DEBUG 01-13 08:46:49.109837.109837 lmp.py:1622]   Expert 10 |    157 | GPU
DEBUG 01-13 08:46:49.109811.109811 lmp.py:1622]   Expert 34 |    176 | GPU
DEBUG 01-13 08:46:49.109547.109547 lmp.py:1622]   Expert  5 |    177 | GPU
DEBUG 01-13 08:46:49.109282.109282 lmp.py:1622]   Expert 45 |    186 | GPU
DEBUG 01-13 08:46:49.109210.109210 lmp.py:1622]   Expert 27 |    191 | GPU
DEBUG 01-13 08:46:49.109661.109661 lmp.py:1622]   Expert 52 |    191 | GPU
DEBUG 01-13 08:46:49.109589.109589 lmp.py:1622]   Expert 48 |    197 | GPU
DEBUG 01-13 08:46:49.109278.109278 lmp.py:1622]   Expert 60 |    197 | GPU
DEBUG 01-13 08:46:49.109967.109967 lmp.py:1622]   Expert 51 |    213 | GPU
DEBUG 01-13 08:46:49.109941.109941 lmp.py:1622]   Expert  7 |    222 | GPU
DEBUG 01-13 08:46:49.109915.109915 lmp.py:1622]   Expert 56 |    223 | GPU
DEBUG 01-13 08:46:49.109889.109889 lmp.py:1622]   Expert 24 |    225 | GPU
DEBUG 01-13 08:46:49.109387.109387 lmp.py:1622]   Expert  8 |    226 | GPU
DEBUG 01-13 08:46:49.109122.109122 lmp.py:1622]   Expert 53 |    233 | GPU
DEBUG 01-13 08:46:49.109858.109858 lmp.py:1622]   Expert 57 |    245 | GPU
DEBUG 01-13 08:46:49.109832.109832 lmp.py:1622]   Expert 47 |    250 | GPU
DEBUG 01-13 08:46:49.109819.109819 lmp.py:1622]   Expert 29 |    258 | GPU
DEBUG 01-13 08:46:49.109270.109270 lmp.py:1622]   Expert 21 |    271 | GPU
DEBUG 01-13 08:46:49.109960.109960 lmp.py:1622]   Expert  4 |    274 | GPU
DEBUG 01-13 08:46:49.109934.109934 lmp.py:1622]   Expert  0 |    285 | GPU
DEBUG 01-13 08:46:49.109385.109385 lmp.py:1622]   Expert 14 |    290 | GPU
DEBUG 01-13 08:46:49.109074.109074 lmp.py:1622]   Expert 22 |    318 | GPU
DEBUG 01-13 08:46:49.109571.109571 lmp.py:1622]   Expert 55 |    321 | GPU
DEBUG 01-13 08:46:49.109068.109068 lmp.py:1622]   Expert 37 |    323 | GPU
DEBUG 01-13 08:46:49.109327.109327 lmp.py:1622]   Expert 58 |    325 | GPU
DEBUG 01-13 08:46:49.109063.109063 lmp.py:1622]   Expert  1 |    329 | GPU
DEBUG 01-13 08:46:49.109560.109560 lmp.py:1622]   Expert 54 |    337 | GPU
DEBUG 01-13 08:46:49.109057.109057 lmp.py:1622]   Expert 28 |    366 | GPU
DEBUG 01-13 08:46:49.109316.109316 lmp.py:1622]   Expert 12 |    369 | GPU
DEBUG 01-13 08:46:49.109813.109813 lmp.py:1622]   Expert 25 |    402 | GPU
DEBUG 01-13 08:46:49.109833.109833 lmp.py:1622]   Expert 11 |    414 | GPU
DEBUG 01-13 08:46:49.109092.109092 lmp.py:1622]   Expert 30 |    871 | GPU
DEBUG 01-13 08:46:49.109305.109305 lmp.py:1623] 
DEBUG 01-13 08:46:49.109305.109305 lmp.py:1623]   CPU total tokens: 3226 (26.3%)
DEBUG 01-13 08:46:49.110756.110756 lmp.py:1624]   GPU total tokens: 9062 (73.7%)
DEBUG 01-13 08:46:49.110260.110260 cuda_h.py:19] end experts_map_get cost 0.0014946460723876953 seconds
DEBUG 01-13 08:46:49.110864.110864 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-13 08:46:49.110190.110190 lmp.py:1632] 
DEBUG 01-13 08:46:49.110190.110190 lmp.py:1632]   Computing 32 experts on CPU MP...
DEBUG 01-13 08:46:49.110873.110873 cuda_h.py:19] end cpu_experts_submit cost 4.7206878662109375e-05 seconds
DEBUG 01-13 08:46:49.110185.110185 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-13 08:46:49.110154.110154 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-13 08:46:49.110311.110311 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-13 08:46:49.111030.111030 cuda_h.py:19] end allocate_cuda_memory cost 0.0014433860778808594 seconds
DEBUG 01-13 08:46:49.111396.111396 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-13 08:46:49.111913.111913 sllm_store_c.py:27] get device uuid map
DEBUG 01-13 08:46:49.111961.111961 sllm_store_c.py:29] call client load into gpu
DEBUG 01-13 08:46:49.112617.112617 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 138c7356-8a5b-4e0e-a707-b8d785feeac6
DEBUG 01-13 08:46:49.112524.112524 client.py:106] call stub.LoadModelAsync
DEBUG 01-13 08:46:49.113777.113777 cuda_h.py:10] start experts_func_gpu_einsum_mp
INFO 01-13 08:46:49.113107.113107 client.py:127] Model loaded
DEBUG 01-13 08:46:49.113373.113373 cuda_h.py:10] start restore2model
DEBUG 01-13 08:46:49.114912.114912 cuda_h.py:19] end restore2model cost 0.0004286766052246094 seconds
DEBUG 01-13 08:46:49.114503.114503 cuda_h.py:19] end sllm_worker_task cost 0.010837793350219727 seconds
INFO 01-13 08:46:49.115767.115767 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 138c7356-8a5b-4e0e-a707-b8d785feeac6
DEBUG 01-13 08:46:49.115995.115995 cuda_h.py:19] end load_into_gpu_async cost 0.0032165050506591797 seconds
DEBUG 01-13 08:46:49.115982.115982 cuda_h.py:10] start restore_tensors2
DEBUG 01-13 08:46:49.115837.115837 cuda_h.py:19] end restore_tensors2 cost 0.0003933906555175781 seconds
DEBUG 01-13 08:46:49.115965.115965 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0054171085357666016 seconds
DEBUG 01-13 08:46:49.115920.115920 cuda_h.py:10] start restore2model
DEBUG 01-13 08:46:49.118625.118625 cuda_h.py:19] end restore2model cost 0.0026335716247558594 seconds
DEBUG 01-13 08:46:49.118508.118508 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.008222103118896484 seconds
DEBUG 01-13 08:46:49.118542.118542 cuda_h.py:10] start gpu_sexperts
DEBUG 01-13 08:46:49.118486.118486 cuda_h.py:19] end gpu_sexperts cost 0.0002791881561279297 seconds
DEBUG 01-13 08:46:49.118892.118892 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-13 08:46:49.118330.118330 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 1.4781951904296875e-05 seconds
DEBUG 01-13 08:46:49.118788.118788 cuda_h.py:10] start wait_experts
INFO 01-13 08:46:49.118722.118722 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 138c7356-8a5b-4e0e-a707-b8d785feeac6
DEBUG 01-13 08:46:49.124169.124169 mlpmodule.py:1006] group tensors cost 0.010865926742553711 s
DEBUG 01-13 08:46:49.128077.128077 mlpmodule.py:1044] pad cost 0.002306222915649414 s
DEBUG 01-13 08:46:49.128432.128432 mlpmodule.py:1050] create cpu tensor cost 5.8650970458984375e-05 s
DEBUG 01-13 08:46:49.128826.128826 mlpmodule.py:1055] move to cpu cost 4.076957702636719e-05 s
DEBUG 01-13 08:46:49.142443.142443 mlpmodule.py:1069] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-13 08:46:49.142742.142742 mlpmodule.py:1070] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-13 08:46:49.142964.142964 mlpmodule.py:1075] group_w3 first element: -0.006134033203125
WARNING 01-13 08:46:49.142784.142784 mlpmodule.py:1085] start einsum2
DEBUG 01-13 08:46:49.157893.157893 mlpmodule.py:1095] group einsum cost 0.029201745986938477 s
DEBUG 01-13 08:46:49.158381.158381 mlpmodule.py:1103] cpy2cputensor cost 0.0006704330444335938 s
INFO 01-13 08:46:49.165166.165166 client.py:127] Model loaded
DEBUG 01-13 08:46:49.165734.165734 cuda_h.py:19] end wait_experts cost 0.04661726951599121 seconds
DEBUG 01-13 08:46:49.165735.165735 cuda_h.py:10] start gpu_experts
DEBUG 01-13 08:46:49.166540.166540 mlpmodule.py:559] gpu group tensors cost 0.0007550716400146484 s
DEBUG 01-13 08:46:49.168582.168582 mlpmodule.py:592] gpu pad cost 0.0017867088317871094 s
DEBUG 01-13 08:46:49.168438.168438 mlpmodule.py:598] start_w1
DEBUG 01-13 08:46:49.168382.168382 mlpmodule.py:602] start_w3
DEBUG 01-13 08:46:49.169216.169216 mlpmodule.py:608] start_w2
DEBUG 01-13 08:46:49.169620.169620 mlpmodule.py:611] gpu group einsum cost 0.0008690357208251953 s
DEBUG 01-13 08:46:49.171739.171739 mlpmodule.py:683] gpu experts func einsum cost 0.006311893463134766 s
DEBUG 01-13 08:46:49.172014.172014 cuda_h.py:19] end gpu_experts cost 0.0064945220947265625 seconds
DEBUG 01-13 08:46:49.172107.172107 cuda_h.py:10] start cpu_thread_manager_mp_wait
DEBUG 01-13 08:46:49.172779.172779 cuda_h.py:19] end cpu_thread_manager_mp_wait cost 4.0531158447265625e-05 seconds
DEBUG 01-13 08:46:49.172371.172371 cuda_h.py:19] end layer_moe_generate_mp_l_12 cost 0.06451725959777832 seconds
DEBUG 01-13 08:46:49.172123.172123 lmp.py:1550] -------------------------------- end prefill layer 11 --------------------------------
DEBUG 01-13 08:46:49.172899.172899 lmp.py:1493] -------------------------------- start prefill layer 12 --------------------------------
DEBUG 01-13 08:46:49.172655.172655 cuda_h.py:10] start start_load_qkvogn_s_weight_l_13
DEBUG 01-13 08:46:49.172703.172703 cuda_h.py:10] start start_load_qkvogn_s_weight_l_13
DEBUG 01-13 08:46:49.172844.172844 cuda_h.py:19] end start_load_qkvogn_s_weight_l_13 cost 3.814697265625e-05 seconds
DEBUG 01-13 08:46:49.172310.172310 cuda_h.py:10] start sllm_worker_task
DEBUG 01-13 08:46:49.172093.172093 cuda_h.py:19] end start_load_qkvogn_s_weight_l_13 cost 0.00015163421630859375 seconds
DEBUG 01-13 08:46:49.172963.172963 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-13 08:46:49.173270.173270 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-13 08:46:49.173934.173934 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-13 08:46:49.173981.173981 cuda_h.py:19] end allocate_cuda_memory cost 0.0003314018249511719 seconds
DEBUG 01-13 08:46:49.173541.173541 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-13 08:46:49.173516.173516 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-13 08:46:49.173837.173837 sllm_store_c.py:27] get device uuid map
DEBUG 01-13 08:46:49.173044.173044 sllm_store_c.py:29] call client load into gpu
DEBUG 01-13 08:46:49.173654.173654 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, b648de7f-38ae-47a7-b77f-124520ac65c5
DEBUG 01-13 08:46:49.173538.173538 client.py:106] call stub.LoadModelAsync
DEBUG 01-13 08:46:49.174198.174198 cuda_h.py:10] start self_attn
INFO 01-13 08:46:49.175979.175979 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, b648de7f-38ae-47a7-b77f-124520ac65c5
DEBUG 01-13 08:46:49.175391.175391 cuda_h.py:19] end load_into_gpu_async cost 0.0017066001892089844 seconds
DEBUG 01-13 08:46:49.175710.175710 cuda_h.py:10] start restore_tensors2
DEBUG 01-13 08:46:49.175654.175654 cuda_h.py:19] end restore_tensors2 cost 7.295608520507812e-05 seconds
DEBUG 01-13 08:46:49.175456.175456 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0025501251220703125 seconds
INFO 01-13 08:46:49.175014.175014 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, b648de7f-38ae-47a7-b77f-124520ac65c5
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-13 08:46:49.177364.177364 cuda_h.py:19] end self_attn cost 0.002903461456298828 seconds
DEBUG 01-13 08:46:49.177091.177091 cuda_h.py:19] end iln_self_attn_paln cost 0.004401445388793945 seconds
DEBUG 01-13 08:46:49.177503.177503 cuda_h.py:10] start layer_moe_generate_mp_l_13
DEBUG 01-13 08:46:49.177166.177166 cuda_h.py:10] start gate
DEBUG 01-13 08:46:49.178500.178500 cuda_h.py:19] end gate cost 0.0006346702575683594 seconds
DEBUG 01-13 08:46:49.178330.178330 cuda_h.py:10] start experts_map_get
DEBUG 01-13 08:46:49.178445.178445 lmp.py:1611] 
DEBUG 01-13 08:46:49.178445.178445 lmp.py:1611] Expert Token Distribution & Device Allocation:
DEBUG 01-13 08:46:49.178109.178109 lmp.py:1612]   Total experts: 64
DEBUG 01-13 08:46:49.178474.178474 lmp.py:1613]   CPU experts: 32 (50%)
DEBUG 01-13 08:46:49.178547.178547 lmp.py:1614]   GPU experts: 32 (50%)
DEBUG 01-13 08:46:49.178237.178237 lmp.py:1615] 
DEBUG 01-13 08:46:49.178237.178237 lmp.py:1615]   Expert ID | Tokens | Device
DEBUG 01-13 08:46:49.178403.178403 lmp.py:1616]   -----------------------------------
DEBUG 01-13 08:46:49.178814.178814 lmp.py:1622]   Expert 12 |     18 | CPU
DEBUG 01-13 08:46:49.178742.178742 lmp.py:1622]   Expert 47 |     20 | CPU
DEBUG 01-13 08:46:49.178477.178477 lmp.py:1622]   Expert 38 |     26 | CPU
DEBUG 01-13 08:46:49.178451.178451 lmp.py:1622]   Expert 27 |     28 | CPU
DEBUG 01-13 08:46:49.178949.178949 lmp.py:1622]   Expert 16 |     36 | CPU
DEBUG 01-13 08:46:49.178923.178923 lmp.py:1622]   Expert 52 |     40 | CPU
DEBUG 01-13 08:46:49.178420.178420 lmp.py:1622]   Expert 63 |     49 | CPU
DEBUG 01-13 08:46:49.178155.178155 lmp.py:1622]   Expert  4 |     55 | CPU
DEBUG 01-13 08:46:49.178891.178891 lmp.py:1622]   Expert 43 |     58 | CPU
DEBUG 01-13 08:46:49.178819.178819 lmp.py:1622]   Expert 61 |     66 | CPU
DEBUG 01-13 08:46:49.178270.178270 lmp.py:1622]   Expert 34 |     73 | CPU
DEBUG 01-13 08:46:49.178721.178721 lmp.py:1622]   Expert 44 |     73 | CPU
DEBUG 01-13 08:46:49.178602.178602 lmp.py:1622]   Expert 53 |     80 | CPU
DEBUG 01-13 08:46:49.179245.179245 lmp.py:1622]   Expert  0 |     81 | CPU
DEBUG 01-13 08:46:49.179934.179934 lmp.py:1622]   Expert 32 |     90 | CPU
DEBUG 01-13 08:46:49.179862.179862 lmp.py:1622]   Expert 37 |     92 | CPU
DEBUG 01-13 08:46:49.179074.179074 lmp.py:1622]   Expert 13 |     98 | CPU
DEBUG 01-13 08:46:49.179002.179002 lmp.py:1622]   Expert 39 |    114 | CPU
DEBUG 01-13 08:46:49.179930.179930 lmp.py:1622]   Expert 21 |    116 | CPU
DEBUG 01-13 08:46:49.179619.179619 lmp.py:1622]   Expert 11 |    121 | CPU
DEBUG 01-13 08:46:49.179832.179832 lmp.py:1622]   Expert 20 |    127 | CPU
DEBUG 01-13 08:46:49.179044.179044 lmp.py:1622]   Expert  8 |    132 | CPU
DEBUG 01-13 08:46:49.179210.179210 lmp.py:1622]   Expert 14 |    134 | CPU
DEBUG 01-13 08:46:49.179138.179138 lmp.py:1622]   Expert 60 |    137 | CPU
DEBUG 01-13 08:46:49.179781.179781 lmp.py:1622]   Expert 22 |    140 | CPU
DEBUG 01-13 08:46:49.179709.179709 lmp.py:1622]   Expert 57 |    141 | CPU
DEBUG 01-13 08:46:49.179636.179636 lmp.py:1622]   Expert  2 |    149 | CPU
DEBUG 01-13 08:46:49.179087.179087 lmp.py:1622]   Expert 45 |    154 | CPU
DEBUG 01-13 08:46:49.179300.179300 lmp.py:1622]   Expert 18 |    155 | CPU
DEBUG 01-13 08:46:49.179512.179512 lmp.py:1622]   Expert 17 |    159 | CPU
DEBUG 01-13 08:46:49.179201.179201 lmp.py:1622]   Expert  7 |    161 | CPU
DEBUG 01-13 08:46:49.179652.179652 lmp.py:1622]   Expert 58 |    163 | CPU
DEBUG 01-13 08:46:49.179865.179865 lmp.py:1622]   Expert 23 |    165 | GPU
DEBUG 01-13 08:46:49.179316.179316 lmp.py:1622]   Expert 30 |    165 | GPU
DEBUG 01-13 08:46:49.179767.179767 lmp.py:1622]   Expert 42 |    168 | GPU
DEBUG 01-13 08:46:49.179979.179979 lmp.py:1622]   Expert 51 |    173 | GPU
DEBUG 01-13 08:46:49.179430.179430 lmp.py:1622]   Expert 35 |    175 | GPU
DEBUG 01-13 08:46:49.179835.179835 lmp.py:1622]   Expert 48 |    177 | GPU
DEBUG 01-13 08:46:49.179762.179762 lmp.py:1622]   Expert 55 |    178 | GPU
DEBUG 01-13 08:46:49.179690.179690 lmp.py:1622]   Expert 62 |    178 | GPU
DEBUG 01-13 08:46:49.179532.179532 lmp.py:1622]   Expert 49 |    179 | GPU
DEBUG 01-13 08:46:49.179744.179744 lmp.py:1622]   Expert 29 |    182 | GPU
DEBUG 01-13 08:46:49.179241.179241 lmp.py:1622]   Expert  6 |    191 | GPU
DEBUG 01-13 08:46:49.179500.179500 lmp.py:1622]   Expert  1 |    196 | GPU
DEBUG 01-13 08:46:49.179997.179997 lmp.py:1622]   Expert 36 |    198 | GPU
DEBUG 01-13 08:46:49.179018.179018 lmp.py:1622]   Expert 25 |    203 | GPU
DEBUG 01-13 08:46:49.179753.179753 lmp.py:1622]   Expert 31 |    203 | GPU
DEBUG 01-13 08:46:49.179251.179251 lmp.py:1622]   Expert 28 |    217 | GPU
DEBUG 01-13 08:46:49.179940.179940 lmp.py:1622]   Expert 54 |    225 | GPU
DEBUG 01-13 08:46:49.179152.179152 lmp.py:1622]   Expert 41 |    226 | GPU
DEBUG 01-13 08:46:49.179126.179126 lmp.py:1622]   Expert  5 |    231 | GPU
DEBUG 01-13 08:46:49.179339.179339 lmp.py:1622]   Expert 19 |    238 | GPU
DEBUG 01-13 08:46:49.179313.179313 lmp.py:1622]   Expert  9 |    244 | GPU
DEBUG 01-13 08:46:49.179810.179810 lmp.py:1622]   Expert 24 |    244 | GPU
DEBUG 01-13 08:46:49.179307.179307 lmp.py:1622]   Expert 50 |    292 | GPU
DEBUG 01-13 08:46:49.179043.179043 lmp.py:1622]   Expert 46 |    308 | GPU
DEBUG 01-13 08:46:49.179302.179302 lmp.py:1622]   Expert 59 |    308 | GPU
DEBUG 01-13 08:46:49.179561.179561 lmp.py:1622]   Expert 56 |    387 | GPU
DEBUG 01-13 08:46:49.179058.179058 lmp.py:1622]   Expert 26 |    396 | GPU
DEBUG 01-13 08:46:49.179793.179793 lmp.py:1622]   Expert 33 |    427 | GPU
DEBUG 01-13 08:46:49.179052.179052 lmp.py:1622]   Expert  3 |    580 | GPU
DEBUG 01-13 08:46:49.179788.179788 lmp.py:1622]   Expert 15 |    656 | GPU
DEBUG 01-13 08:46:49.179047.179047 lmp.py:1622]   Expert 10 |    710 | GPU
DEBUG 01-13 08:46:49.179305.179305 lmp.py:1622]   Expert 40 |    782 | GPU
DEBUG 01-13 08:46:49.179233.179233 lmp.py:1623] 
DEBUG 01-13 08:46:49.179233.179233 lmp.py:1623]   CPU total tokens: 3086 (25.1%)
DEBUG 01-13 08:46:49.179638.179638 lmp.py:1624]   GPU total tokens: 9202 (74.9%)
DEBUG 01-13 08:46:49.179857.179857 cuda_h.py:19] end experts_map_get cost 0.0014851093292236328 seconds
DEBUG 01-13 08:46:49.179846.179846 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-13 08:46:49.179933.179933 lmp.py:1632] 
DEBUG 01-13 08:46:49.179933.179933 lmp.py:1632]   Computing 32 experts on CPU MP...
DEBUG 01-13 08:46:49.180054.180054 cuda_h.py:19] end cpu_experts_submit cost 5.173683166503906e-05 seconds
DEBUG 01-13 08:46:49.180532.180532 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-13 08:46:49.180554.180554 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-13 08:46:49.180121.180121 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-13 08:46:49.181301.181301 mlpmodule.py:785]  experts func einsum cost 0.06783103942871094 s
DEBUG 01-13 08:46:49.182342.182342 cuda_h.py:19] end allocate_cuda_memory cost 0.0018150806427001953 seconds
DEBUG 01-13 08:46:49.182140.182140 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-13 08:46:49.182134.182134 sllm_store_c.py:27] get device uuid map
DEBUG 01-13 08:46:49.182281.182281 sllm_store_c.py:29] call client load into gpu
DEBUG 01-13 08:46:49.182169.182169 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 44491836-23f3-4f1b-bc8d-c25340d1956e
DEBUG 01-13 08:46:49.182894.182894 cuda_h.py:19] end experts_func_gpu_einsum_mp cost 0.06882166862487793 seconds
DEBUG 01-13 08:46:49.182566.182566 client.py:106] call stub.LoadModelAsync
INFO 01-13 08:46:49.182973.182973 client.py:127] Model loaded
DEBUG 01-13 08:46:49.183802.183802 cuda_h.py:10] start restore2model
DEBUG 01-13 08:46:49.183715.183715 cuda_h.py:19] end restore2model cost 0.00032520294189453125 seconds
DEBUG 01-13 08:46:49.183624.183624 cuda_h.py:19] end sllm_worker_task cost 0.010435342788696289 seconds
DEBUG 01-13 08:46:49.183465.183465 cuda_h.py:10] start experts_func_gpu_einsum_mp
INFO 01-13 08:46:49.184767.184767 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 44491836-23f3-4f1b-bc8d-c25340d1956e
DEBUG 01-13 08:46:49.184564.184564 cuda_h.py:19] end load_into_gpu_async cost 0.0023508071899414062 seconds
DEBUG 01-13 08:46:49.184459.184459 cuda_h.py:10] start restore_tensors2
DEBUG 01-13 08:46:49.185533.185533 cuda_h.py:19] end restore_tensors2 cost 0.00041294097900390625 seconds
DEBUG 01-13 08:46:49.185562.185562 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.004968166351318359 seconds
DEBUG 01-13 08:46:49.185854.185854 cuda_h.py:10] start restore2model
DEBUG 01-13 08:46:49.187842.187842 cuda_h.py:19] end restore2model cost 0.0025603771209716797 seconds
DEBUG 01-13 08:46:49.187771.187771 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.007703304290771484 seconds
DEBUG 01-13 08:46:49.187136.187136 cuda_h.py:10] start gpu_sexperts
DEBUG 01-13 08:46:49.188636.188636 cuda_h.py:19] end gpu_sexperts cost 0.00026988983154296875 seconds
DEBUG 01-13 08:46:49.188704.188704 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-13 08:46:49.188811.188811 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 1.5735626220703125e-05 seconds
DEBUG 01-13 08:46:49.188507.188507 cuda_h.py:10] start wait_experts
INFO 01-13 08:46:49.188395.188395 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 44491836-23f3-4f1b-bc8d-c25340d1956e
DEBUG 01-13 08:46:49.193093.193093 mlpmodule.py:1006] group tensors cost 0.009589195251464844 s
DEBUG 01-13 08:46:49.196322.196322 mlpmodule.py:1044] pad cost 0.002084970474243164 s
DEBUG 01-13 08:46:49.196908.196908 mlpmodule.py:1050] create cpu tensor cost 5.5789947509765625e-05 s
DEBUG 01-13 08:46:49.196249.196249 mlpmodule.py:1055] move to cpu cost 3.838539123535156e-05 s
DEBUG 01-13 08:46:49.205567.205567 mlpmodule.py:1069] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-13 08:46:49.205627.205627 mlpmodule.py:1070] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-13 08:46:49.205035.205035 mlpmodule.py:1075] group_w3 first element: -0.0162353515625
WARNING 01-13 08:46:49.205597.205597 mlpmodule.py:1085] start einsum2
DEBUG 01-13 08:46:49.218968.218968 mlpmodule.py:1095] group einsum cost 0.02118825912475586 s
DEBUG 01-13 08:46:49.219881.219881 mlpmodule.py:1103] cpy2cputensor cost 0.00069427490234375 s
INFO 01-13 08:46:49.235127.235127 client.py:127] Model loaded
DEBUG 01-13 08:46:49.235014.235014 cuda_h.py:19] end wait_experts cost 0.046912193298339844 seconds
DEBUG 01-13 08:46:49.235200.235200 cuda_h.py:10] start gpu_experts
DEBUG 01-13 08:46:49.235396.235396 mlpmodule.py:559] gpu group tensors cost 0.0006103515625 s
DEBUG 01-13 08:46:49.237424.237424 mlpmodule.py:592] gpu pad cost 0.0015659332275390625 s
DEBUG 01-13 08:46:49.237123.237123 mlpmodule.py:598] start_w1
DEBUG 01-13 08:46:49.238253.238253 mlpmodule.py:602] start_w3
DEBUG 01-13 08:46:49.238591.238591 mlpmodule.py:608] start_w2
DEBUG 01-13 08:46:49.238643.238643 mlpmodule.py:611] gpu group einsum cost 0.0006976127624511719 s
DEBUG 01-13 08:46:49.240550.240550 mlpmodule.py:785]  experts func einsum cost 0.056468963623046875 s
DEBUG 01-13 08:46:49.241963.241963 cuda_h.py:19] end experts_func_gpu_einsum_mp cost 0.05749034881591797 seconds
DEBUG 01-13 08:46:49.241688.241688 mlpmodule.py:683] gpu experts func einsum cost 0.00577855110168457 s
DEBUG 01-13 08:46:49.242853.242853 cuda_h.py:19] end gpu_experts cost 0.006808757781982422 seconds
DEBUG 01-13 08:46:49.243118.243118 cuda_h.py:10] start cpu_thread_manager_mp_wait
DEBUG 01-13 08:46:49.244133.244133 cuda_h.py:19] end cpu_thread_manager_mp_wait cost 3.933906555175781e-05 seconds
DEBUG 01-13 08:46:49.245249.245249 cuda_h.py:19] end layer_moe_generate_mp_l_13 cost 0.0677194595336914 seconds
DEBUG 01-13 08:46:49.248140.248140 lmp.py:1550] -------------------------------- end prefill layer 12 --------------------------------
DEBUG 01-13 08:46:49.249829.249829 lmp.py:1493] -------------------------------- start prefill layer 13 --------------------------------
DEBUG 01-13 08:46:49.249999.249999 cuda_h.py:10] start start_load_qkvogn_s_weight_l_14
DEBUG 01-13 08:46:49.249245.249245 cuda_h.py:10] start start_load_qkvogn_s_weight_l_14
DEBUG 01-13 08:46:49.249989.249989 cuda_h.py:19] end start_load_qkvogn_s_weight_l_14 cost 3.0994415283203125e-05 seconds
DEBUG 01-13 08:46:49.249785.249785 cuda_h.py:19] end start_load_qkvogn_s_weight_l_14 cost 6.008148193359375e-05 seconds
DEBUG 01-13 08:46:49.249904.249904 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-13 08:46:49.249191.249191 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-13 08:46:49.249916.249916 cuda_h.py:10] start sllm_worker_task
DEBUG 01-13 08:46:49.249700.249700 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-13 08:46:49.249245.249245 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-13 08:46:49.249012.249012 cuda_h.py:19] end allocate_cuda_memory cost 0.00031948089599609375 seconds
DEBUG 01-13 08:46:49.250597.250597 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-13 08:46:49.250406.250406 sllm_store_c.py:27] get device uuid map
DEBUG 01-13 08:46:49.250275.250275 sllm_store_c.py:29] call client load into gpu
DEBUG 01-13 08:46:49.250071.250071 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, a5ce7deb-26af-4f81-97bc-ac9898f31667
DEBUG 01-13 08:46:49.250994.250994 client.py:106] call stub.LoadModelAsync
DEBUG 01-13 08:46:49.250003.250003 cuda_h.py:10] start self_attn
INFO 01-13 08:46:49.251918.251918 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, a5ce7deb-26af-4f81-97bc-ac9898f31667
DEBUG 01-13 08:46:49.251291.251291 cuda_h.py:19] end load_into_gpu_async cost 0.0017032623291015625 seconds
DEBUG 01-13 08:46:49.251332.251332 cuda_h.py:10] start restore_tensors2
DEBUG 01-13 08:46:49.251813.251813 cuda_h.py:19] end restore_tensors2 cost 7.605552673339844e-05 seconds
DEBUG 01-13 08:46:49.251781.251781 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.002379179000854492 seconds
INFO 01-13 08:46:49.252578.252578 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, a5ce7deb-26af-4f81-97bc-ac9898f31667
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-13 08:46:49.253354.253354 cuda_h.py:19] end self_attn cost 0.002900838851928711 seconds
DEBUG 01-13 08:46:49.253833.253833 cuda_h.py:19] end iln_self_attn_paln cost 0.0043792724609375 seconds
DEBUG 01-13 08:46:49.253292.253292 cuda_h.py:10] start layer_moe_generate_mp_l_14
DEBUG 01-13 08:46:49.253194.253194 cuda_h.py:10] start gate
DEBUG 01-13 08:46:49.254176.254176 cuda_h.py:19] end gate cost 0.0006220340728759766 seconds
DEBUG 01-13 08:46:49.254145.254145 cuda_h.py:10] start experts_map_get
DEBUG 01-13 08:46:49.254247.254247 lmp.py:1611] 
DEBUG 01-13 08:46:49.254247.254247 lmp.py:1611] Expert Token Distribution & Device Allocation:
DEBUG 01-13 08:46:49.254857.254857 lmp.py:1612]   Total experts: 64
DEBUG 01-13 08:46:49.254553.254553 lmp.py:1613]   CPU experts: 32 (50%)
DEBUG 01-13 08:46:49.254388.254388 lmp.py:1614]   GPU experts: 32 (50%)
DEBUG 01-13 08:46:49.254031.254031 lmp.py:1615] 
DEBUG 01-13 08:46:49.254031.254031 lmp.py:1615]   Expert ID | Tokens | Device
DEBUG 01-13 08:46:49.254913.254913 lmp.py:1616]   -----------------------------------
DEBUG 01-13 08:46:49.254516.254516 lmp.py:1622]   Expert 19 |     21 | CPU
DEBUG 01-13 08:46:49.254397.254397 lmp.py:1622]   Expert 42 |     24 | CPU
DEBUG 01-13 08:46:49.254087.254087 lmp.py:1622]   Expert 30 |     25 | CPU
DEBUG 01-13 08:46:49.254061.254061 lmp.py:1622]   Expert 32 |     38 | CPU
DEBUG 01-13 08:46:49.255035.255035 lmp.py:1622]   Expert  6 |     52 | CPU
DEBUG 01-13 08:46:49.255009.255009 lmp.py:1622]   Expert 53 |     71 | CPU
DEBUG 01-13 08:46:49.255745.255745 lmp.py:1622]   Expert  5 |     75 | CPU
DEBUG 01-13 08:46:49.255719.255719 lmp.py:1622]   Expert  1 |     77 | CPU
DEBUG 01-13 08:46:49.255693.255693 lmp.py:1622]   Expert  9 |    111 | CPU
DEBUG 01-13 08:46:49.255428.255428 lmp.py:1622]   Expert 13 |    111 | CPU
DEBUG 01-13 08:46:49.255594.255594 lmp.py:1622]   Expert 58 |    128 | CPU
DEBUG 01-13 08:46:49.255284.255284 lmp.py:1622]   Expert 63 |    129 | CPU
DEBUG 01-13 08:46:49.255211.255211 lmp.py:1622]   Expert 31 |    130 | CPU
DEBUG 01-13 08:46:49.255139.255139 lmp.py:1622]   Expert 50 |    132 | CPU
DEBUG 01-13 08:46:49.255590.255590 lmp.py:1622]   Expert 59 |    133 | CPU
DEBUG 01-13 08:46:49.255326.255326 lmp.py:1622]   Expert 34 |    134 | CPU
DEBUG 01-13 08:46:49.255823.255823 lmp.py:1622]   Expert 26 |    136 | CPU
DEBUG 01-13 08:46:49.255320.255320 lmp.py:1622]   Expert 40 |    142 | CPU
DEBUG 01-13 08:46:49.255817.255817 lmp.py:1622]   Expert  2 |    146 | CPU
DEBUG 01-13 08:46:49.255314.255314 lmp.py:1622]   Expert 11 |    146 | CPU
DEBUG 01-13 08:46:49.255050.255050 lmp.py:1622]   Expert 56 |    146 | CPU
DEBUG 01-13 08:46:49.255024.255024 lmp.py:1622]   Expert 48 |    149 | CPU
DEBUG 01-13 08:46:49.255521.255521 lmp.py:1622]   Expert 12 |    151 | CPU
DEBUG 01-13 08:46:49.255495.255495 lmp.py:1622]   Expert 18 |    151 | CPU
DEBUG 01-13 08:46:49.255754.255754 lmp.py:1622]   Expert 20 |    152 | CPU
DEBUG 01-13 08:46:49.255490.255490 lmp.py:1622]   Expert  4 |    157 | CPU
DEBUG 01-13 08:46:49.255610.255610 lmp.py:1622]   Expert 33 |    160 | CPU
DEBUG 01-13 08:46:49.255776.255776 lmp.py:1622]   Expert 10 |    162 | CPU
DEBUG 01-13 08:46:49.255180.255180 lmp.py:1622]   Expert 61 |    162 | CPU
DEBUG 01-13 08:46:49.255062.255062 lmp.py:1622]   Expert 46 |    164 | CPU
DEBUG 01-13 08:46:49.255989.255989 lmp.py:1622]   Expert 35 |    166 | CPU
DEBUG 01-13 08:46:49.255917.255917 lmp.py:1622]   Expert 55 |    166 | CPU
DEBUG 01-13 08:46:49.255606.255606 lmp.py:1622]   Expert 36 |    175 | GPU
DEBUG 01-13 08:46:49.255296.255296 lmp.py:1622]   Expert  8 |    179 | GPU
DEBUG 01-13 08:46:49.255747.255747 lmp.py:1622]   Expert 51 |    182 | GPU
DEBUG 01-13 08:46:49.255198.255198 lmp.py:1622]   Expert 52 |    187 | GPU
DEBUG 01-13 08:46:49.255648.255648 lmp.py:1622]   Expert 37 |    191 | GPU
DEBUG 01-13 08:46:49.255338.255338 lmp.py:1622]   Expert 57 |    200 | GPU
DEBUG 01-13 08:46:49.255027.255027 lmp.py:1622]   Expert  0 |    203 | GPU
DEBUG 01-13 08:46:49.255147.255147 lmp.py:1622]   Expert 39 |    217 | GPU
DEBUG 01-13 08:46:49.255790.255790 lmp.py:1622]   Expert 25 |    228 | GPU
DEBUG 01-13 08:46:49.255718.255718 lmp.py:1622]   Expert 62 |    228 | GPU
DEBUG 01-13 08:46:49.255407.255407 lmp.py:1622]   Expert 27 |    245 | GPU
DEBUG 01-13 08:46:49.255096.255096 lmp.py:1622]   Expert 28 |    247 | GPU
DEBUG 01-13 08:46:49.255024.255024 lmp.py:1622]   Expert  7 |    251 | GPU
DEBUG 01-13 08:46:49.255475.255475 lmp.py:1622]   Expert 38 |    255 | GPU
DEBUG 01-13 08:46:49.255926.255926 lmp.py:1622]   Expert 21 |    256 | GPU
DEBUG 01-13 08:46:49.255376.255376 lmp.py:1622]   Expert 60 |    256 | GPU
DEBUG 01-13 08:46:49.255827.255827 lmp.py:1622]   Expert 16 |    257 | GPU
DEBUG 01-13 08:46:49.255278.255278 lmp.py:1622]   Expert 49 |    257 | GPU
DEBUG 01-13 08:46:49.255491.255491 lmp.py:1622]   Expert  3 |    258 | GPU
DEBUG 01-13 08:46:49.255942.255942 lmp.py:1622]   Expert 24 |    264 | GPU
DEBUG 01-13 08:46:49.255631.255631 lmp.py:1622]   Expert 43 |    267 | GPU
DEBUG 01-13 08:46:49.255797.255797 lmp.py:1622]   Expert 29 |    276 | GPU
DEBUG 01-13 08:46:49.255202.255202 lmp.py:1622]   Expert 23 |    280 | GPU
DEBUG 01-13 08:46:49.255368.255368 lmp.py:1622]   Expert 22 |    286 | GPU
DEBUG 01-13 08:46:49.255534.255534 lmp.py:1622]   Expert 15 |    290 | GPU
DEBUG 01-13 08:46:49.255985.255985 lmp.py:1622]   Expert 47 |    296 | GPU
DEBUG 01-13 08:46:49.255436.255436 lmp.py:1622]   Expert 44 |    305 | GPU
DEBUG 01-13 08:46:49.255886.255886 lmp.py:1622]   Expert 41 |    307 | GPU
DEBUG 01-13 08:46:49.255099.255099 lmp.py:1622]   Expert 14 |    372 | GPU
DEBUG 01-13 08:46:49.255550.255550 lmp.py:1622]   Expert 54 |    374 | GPU
DEBUG 01-13 08:46:49.255001.255001 lmp.py:1622]   Expert 17 |    407 | GPU
DEBUG 01-13 08:46:49.255452.255452 lmp.py:1622]   Expert 45 |    445 | GPU
DEBUG 01-13 08:46:49.256856.256856 lmp.py:1623] 
DEBUG 01-13 08:46:49.256856.256856 lmp.py:1623]   CPU total tokens: 3847 (31.3%)
DEBUG 01-13 08:46:49.256261.256261 lmp.py:1624]   GPU total tokens: 8441 (68.7%)
DEBUG 01-13 08:46:49.256957.256957 cuda_h.py:19] end experts_map_get cost 0.0014843940734863281 seconds
DEBUG 01-13 08:46:49.256707.256707 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-13 08:46:49.256794.256794 lmp.py:1632] 
DEBUG 01-13 08:46:49.256794.256794 lmp.py:1632]   Computing 32 experts on CPU MP...
DEBUG 01-13 08:46:49.256524.256524 cuda_h.py:19] end cpu_experts_submit cost 4.649162292480469e-05 seconds
DEBUG 01-13 08:46:49.256359.256359 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-13 08:46:49.256282.256282 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-13 08:46:49.256923.256923 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-13 08:46:49.258713.258713 cuda_h.py:19] end allocate_cuda_memory cost 0.0017952919006347656 seconds
DEBUG 01-13 08:46:49.258510.258510 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-13 08:46:49.258478.258478 sllm_store_c.py:27] get device uuid map
DEBUG 01-13 08:46:49.258718.258718 sllm_store_c.py:29] call client load into gpu
DEBUG 01-13 08:46:49.258036.258036 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 7c626e80-1f37-4b44-b3b5-81ac9a8f96bf
DEBUG 01-13 08:46:49.258897.258897 client.py:106] call stub.LoadModelAsync
INFO 01-13 08:46:49.259350.259350 client.py:127] Model loaded
DEBUG 01-13 08:46:49.259438.259438 cuda_h.py:10] start restore2model
DEBUG 01-13 08:46:49.259698.259698 cuda_h.py:19] end restore2model cost 0.0003974437713623047 seconds
DEBUG 01-13 08:46:49.259143.259143 cuda_h.py:19] end sllm_worker_task cost 0.010060548782348633 seconds
DEBUG 01-13 08:46:49.259302.259302 cuda_h.py:10] start experts_func_gpu_einsum_mp
INFO 01-13 08:46:49.260797.260797 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 7c626e80-1f37-4b44-b3b5-81ac9a8f96bf
DEBUG 01-13 08:46:49.260262.260262 cuda_h.py:19] end load_into_gpu_async cost 0.0022602081298828125 seconds
DEBUG 01-13 08:46:49.260442.260442 cuda_h.py:10] start restore_tensors2
DEBUG 01-13 08:46:49.260341.260341 cuda_h.py:19] end restore_tensors2 cost 0.0003199577331542969 seconds
DEBUG 01-13 08:46:49.261509.261509 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0047795772552490234 seconds
DEBUG 01-13 08:46:49.261324.261324 cuda_h.py:10] start restore2model
DEBUG 01-13 08:46:49.263495.263495 cuda_h.py:19] end restore2model cost 0.002485036849975586 seconds
DEBUG 01-13 08:46:49.263569.263569 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.007437467575073242 seconds
DEBUG 01-13 08:46:49.263001.263001 cuda_h.py:10] start gpu_sexperts
DEBUG 01-13 08:46:49.263541.263541 cuda_h.py:19] end gpu_sexperts cost 0.0002624988555908203 seconds
DEBUG 01-13 08:46:49.264655.264655 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-13 08:46:49.264617.264617 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 1.430511474609375e-05 seconds
DEBUG 01-13 08:46:49.264074.264074 cuda_h.py:10] start wait_experts
INFO 01-13 08:46:49.264724.264724 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 7c626e80-1f37-4b44-b3b5-81ac9a8f96bf
DEBUG 01-13 08:46:49.272253.272253 mlpmodule.py:1006] group tensors cost 0.01232600212097168 s
DEBUG 01-13 08:46:49.274130.274130 mlpmodule.py:1044] pad cost 0.0015149116516113281 s
DEBUG 01-13 08:46:49.274710.274710 mlpmodule.py:1050] create cpu tensor cost 4.38690185546875e-05 s
DEBUG 01-13 08:46:49.274275.274275 mlpmodule.py:1055] move to cpu cost 3.123283386230469e-05 s
DEBUG 01-13 08:46:49.284253.284253 mlpmodule.py:1069] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-13 08:46:49.284903.284903 mlpmodule.py:1070] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-13 08:46:49.284710.284710 mlpmodule.py:1075] group_w3 first element: -0.0211181640625
WARNING 01-13 08:46:49.284797.284797 mlpmodule.py:1085] start einsum2
DEBUG 01-13 08:46:49.297667.297667 mlpmodule.py:1095] group einsum cost 0.022495269775390625 s
DEBUG 01-13 08:46:49.298899.298899 mlpmodule.py:1103] cpy2cputensor cost 0.0007152557373046875 s
INFO 01-13 08:46:49.311300.311300 client.py:127] Model loaded
DEBUG 01-13 08:46:49.311822.311822 cuda_h.py:19] end wait_experts cost 0.04741811752319336 seconds
DEBUG 01-13 08:46:49.311824.311824 cuda_h.py:10] start gpu_experts
DEBUG 01-13 08:46:49.312490.312490 mlpmodule.py:559] gpu group tensors cost 0.0008015632629394531 s
DEBUG 01-13 08:46:49.314712.314712 mlpmodule.py:592] gpu pad cost 0.0015621185302734375 s
DEBUG 01-13 08:46:49.314695.314695 mlpmodule.py:598] start_w1
DEBUG 01-13 08:46:49.314010.314010 mlpmodule.py:602] start_w3
DEBUG 01-13 08:46:49.314062.314062 mlpmodule.py:608] start_w2
DEBUG 01-13 08:46:49.314245.314245 mlpmodule.py:611] gpu group einsum cost 0.0006170272827148438 s
DEBUG 01-13 08:46:49.317865.317865 mlpmodule.py:683] gpu experts func einsum cost 0.005295991897583008 s
DEBUG 01-13 08:46:49.317557.317557 cuda_h.py:19] end gpu_experts cost 0.005462646484375 seconds
DEBUG 01-13 08:46:49.317452.317452 cuda_h.py:10] start cpu_thread_manager_mp_wait
DEBUG 01-13 08:46:49.317679.317679 cuda_h.py:19] end cpu_thread_manager_mp_wait cost 3.4332275390625e-05 seconds
DEBUG 01-13 08:46:49.317828.317828 cuda_h.py:19] end layer_moe_generate_mp_l_14 cost 0.06342720985412598 seconds
DEBUG 01-13 08:46:49.317617.317617 lmp.py:1550] -------------------------------- end prefill layer 13 --------------------------------
DEBUG 01-13 08:46:49.317486.317486 lmp.py:1493] -------------------------------- start prefill layer 14 --------------------------------
DEBUG 01-13 08:46:49.317043.317043 cuda_h.py:10] start start_load_qkvogn_s_weight_l_15
DEBUG 01-13 08:46:49.317984.317984 cuda_h.py:10] start start_load_qkvogn_s_weight_l_15
DEBUG 01-13 08:46:49.317105.317105 cuda_h.py:19] end start_load_qkvogn_s_weight_l_15 cost 3.0517578125e-05 seconds
DEBUG 01-13 08:46:49.317113.317113 cuda_h.py:19] end start_load_qkvogn_s_weight_l_15 cost 7.486343383789062e-05 seconds
DEBUG 01-13 08:46:49.317571.317571 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-13 08:46:49.317527.317527 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-13 08:46:49.317581.317581 mlpmodule.py:785]  experts func einsum cost 0.05756521224975586 s
DEBUG 01-13 08:46:49.317629.317629 cuda_h.py:10] start sllm_worker_task
DEBUG 01-13 08:46:49.317857.317857 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-13 08:46:49.317501.317501 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-13 08:46:49.318480.318480 cuda_h.py:19] end experts_func_gpu_einsum_mp cost 0.0585784912109375 seconds
DEBUG 01-13 08:46:49.318759.318759 cuda_h.py:19] end allocate_cuda_memory cost 0.0003304481506347656 seconds
DEBUG 01-13 08:46:49.318437.318437 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-13 08:46:49.318292.318292 sllm_store_c.py:27] get device uuid map
DEBUG 01-13 08:46:49.318684.318684 sllm_store_c.py:29] call client load into gpu
DEBUG 01-13 08:46:49.318195.318195 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 2e25aa83-e577-4f1c-b9f5-3c24bcc64463
DEBUG 01-13 08:46:49.318218.318218 client.py:106] call stub.LoadModelAsync
DEBUG 01-13 08:46:49.318657.318657 cuda_h.py:10] start self_attn
INFO 01-13 08:46:49.320238.320238 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 2e25aa83-e577-4f1c-b9f5-3c24bcc64463
DEBUG 01-13 08:46:49.320167.320167 cuda_h.py:19] end load_into_gpu_async cost 0.001592874526977539 seconds
DEBUG 01-13 08:46:49.320532.320532 cuda_h.py:10] start restore_tensors2
DEBUG 01-13 08:46:49.320277.320277 cuda_h.py:19] end restore_tensors2 cost 6.747245788574219e-05 seconds
DEBUG 01-13 08:46:49.320125.320125 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0022356510162353516 seconds
INFO 01-13 08:46:49.320160.320160 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 2e25aa83-e577-4f1c-b9f5-3c24bcc64463
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-13 08:46:49.321082.321082 cuda_h.py:19] end self_attn cost 0.0029556751251220703 seconds
DEBUG 01-13 08:46:49.322113.322113 cuda_h.py:19] end iln_self_attn_paln cost 0.0044786930084228516 seconds
DEBUG 01-13 08:46:49.322240.322240 cuda_h.py:10] start layer_moe_generate_mp_l_15
DEBUG 01-13 08:46:49.322142.322142 cuda_h.py:10] start gate
DEBUG 01-13 08:46:49.322277.322277 cuda_h.py:19] end gate cost 0.0006284713745117188 seconds
DEBUG 01-13 08:46:49.323199.323199 cuda_h.py:10] start experts_map_get
DEBUG 01-13 08:46:49.323414.323414 lmp.py:1611] 
DEBUG 01-13 08:46:49.323414.323414 lmp.py:1611] Expert Token Distribution & Device Allocation:
DEBUG 01-13 08:46:49.323455.323455 lmp.py:1612]   Total experts: 64
DEBUG 01-13 08:46:49.323105.323105 lmp.py:1613]   CPU experts: 32 (50%)
DEBUG 01-13 08:46:49.323178.323178 lmp.py:1614]   GPU experts: 32 (50%)
DEBUG 01-13 08:46:49.323106.323106 lmp.py:1615] 
DEBUG 01-13 08:46:49.323106.323106 lmp.py:1615]   Expert ID | Tokens | Device
DEBUG 01-13 08:46:49.323511.323511 lmp.py:1616]   -----------------------------------
DEBUG 01-13 08:46:49.323399.323399 lmp.py:1622]   Expert  7 |     30 | CPU
DEBUG 01-13 08:46:49.323088.323088 lmp.py:1622]   Expert 34 |     32 | CPU
DEBUG 01-13 08:46:49.323539.323539 lmp.py:1622]   Expert 13 |     43 | CPU
DEBUG 01-13 08:46:49.323275.323275 lmp.py:1622]   Expert 54 |     78 | CPU
DEBUG 01-13 08:46:49.323010.323010 lmp.py:1622]   Expert 39 |     81 | CPU
DEBUG 01-13 08:46:49.323223.323223 lmp.py:1622]   Expert 18 |     82 | CPU
DEBUG 01-13 08:46:49.323958.323958 lmp.py:1622]   Expert 49 |     87 | CPU
DEBUG 01-13 08:46:49.323694.323694 lmp.py:1622]   Expert 21 |     99 | CPU
DEBUG 01-13 08:46:49.323429.323429 lmp.py:1622]   Expert  0 |    103 | CPU
DEBUG 01-13 08:46:49.323072.323072 lmp.py:1622]   Expert 59 |    104 | CPU
DEBUG 01-13 08:46:49.323715.323715 lmp.py:1622]   Expert 16 |    105 | CPU
DEBUG 01-13 08:46:49.323882.323882 lmp.py:1622]   Expert 41 |    118 | CPU
DEBUG 01-13 08:46:49.323048.323048 lmp.py:1622]   Expert 45 |    119 | CPU
DEBUG 01-13 08:46:49.323452.323452 lmp.py:1622]   Expert 15 |    120 | CPU
DEBUG 01-13 08:46:49.323903.323903 lmp.py:1622]   Expert 17 |    123 | CPU
DEBUG 01-13 08:46:49.323592.323592 lmp.py:1622]   Expert 22 |    124 | CPU
DEBUG 01-13 08:46:49.323282.323282 lmp.py:1622]   Expert 61 |    130 | CPU
DEBUG 01-13 08:46:49.323494.323494 lmp.py:1622]   Expert 52 |    135 | CPU
DEBUG 01-13 08:46:49.323945.323945 lmp.py:1622]   Expert 35 |    138 | CPU
DEBUG 01-13 08:46:49.323396.323396 lmp.py:1622]   Expert  8 |    139 | CPU
DEBUG 01-13 08:46:49.323085.323085 lmp.py:1622]   Expert 38 |    140 | CPU
DEBUG 01-13 08:46:49.323298.323298 lmp.py:1622]   Expert 48 |    141 | CPU
DEBUG 01-13 08:46:49.323987.323987 lmp.py:1622]   Expert 12 |    145 | CPU
DEBUG 01-13 08:46:49.323438.323438 lmp.py:1622]   Expert 36 |    155 | CPU
DEBUG 01-13 08:46:49.323604.323604 lmp.py:1622]   Expert 31 |    157 | CPU
DEBUG 01-13 08:46:49.323532.323532 lmp.py:1622]   Expert 50 |    157 | CPU
DEBUG 01-13 08:46:49.323459.323459 lmp.py:1622]   Expert 53 |    160 | CPU
DEBUG 01-13 08:46:49.323626.323626 lmp.py:1622]   Expert 40 |    163 | CPU
DEBUG 01-13 08:46:49.323553.323553 lmp.py:1622]   Expert 60 |    164 | CPU
DEBUG 01-13 08:46:49.323004.323004 lmp.py:1622]   Expert 27 |    174 | CPU
DEBUG 01-13 08:46:49.323694.323694 lmp.py:1622]   Expert  4 |    200 | CPU
DEBUG 01-13 08:46:49.323383.323383 lmp.py:1622]   Expert 19 |    200 | CPU
DEBUG 01-13 08:46:49.323834.323834 lmp.py:1622]   Expert 29 |    200 | GPU
DEBUG 01-13 08:46:49.323285.323285 lmp.py:1622]   Expert 30 |    204 | GPU
DEBUG 01-13 08:46:49.323974.323974 lmp.py:1622]   Expert 11 |    218 | GPU
DEBUG 01-13 08:46:49.324425.324425 lmp.py:1622]   Expert 20 |    219 | GPU
DEBUG 01-13 08:46:49.324637.324637 lmp.py:1622]   Expert 26 |    226 | GPU
DEBUG 01-13 08:46:49.324088.324088 lmp.py:1622]   Expert 57 |    226 | GPU
DEBUG 01-13 08:46:49.324016.324016 lmp.py:1622]   Expert 46 |    228 | GPU
DEBUG 01-13 08:46:49.324182.324182 lmp.py:1622]   Expert  6 |    229 | GPU
DEBUG 01-13 08:46:49.324871.324871 lmp.py:1622]   Expert 43 |    230 | GPU
DEBUG 01-13 08:46:49.324799.324799 lmp.py:1622]   Expert 33 |    231 | GPU
DEBUG 01-13 08:46:49.324011.324011 lmp.py:1622]   Expert 23 |    238 | GPU
DEBUG 01-13 08:46:49.324462.324462 lmp.py:1622]   Expert 42 |    240 | GPU
DEBUG 01-13 08:46:49.324675.324675 lmp.py:1622]   Expert  2 |    245 | GPU
DEBUG 01-13 08:46:49.324887.324887 lmp.py:1622]   Expert 55 |    250 | GPU
DEBUG 01-13 08:46:49.324100.324100 lmp.py:1622]   Expert 28 |    259 | GPU
DEBUG 01-13 08:46:49.324551.324551 lmp.py:1622]   Expert 56 |    260 | GPU
DEBUG 01-13 08:46:49.324525.324525 lmp.py:1622]   Expert  9 |    262 | GPU
DEBUG 01-13 08:46:49.324976.324976 lmp.py:1622]   Expert  3 |    265 | GPU
DEBUG 01-13 08:46:49.324188.324188 lmp.py:1622]   Expert 32 |    265 | GPU
DEBUG 01-13 08:46:49.324831.324831 lmp.py:1622]   Expert 44 |    267 | GPU
DEBUG 01-13 08:46:49.324759.324759 lmp.py:1622]   Expert 51 |    272 | GPU
DEBUG 01-13 08:46:49.324686.324686 lmp.py:1622]   Expert 58 |    273 | GPU
DEBUG 01-13 08:46:49.324137.324137 lmp.py:1622]   Expert 14 |    276 | GPU
DEBUG 01-13 08:46:49.324303.324303 lmp.py:1622]   Expert  1 |    280 | GPU
DEBUG 01-13 08:46:49.324754.324754 lmp.py:1622]   Expert 63 |    288 | GPU
DEBUG 01-13 08:46:49.324205.324205 lmp.py:1622]   Expert 47 |    291 | GPU
DEBUG 01-13 08:46:49.324285.324285 lmp.py:1622]   Expert 62 |    293 | GPU
DEBUG 01-13 08:46:49.324498.324498 lmp.py:1622]   Expert 37 |    302 | GPU
DEBUG 01-13 08:46:49.324949.324949 lmp.py:1622]   Expert 24 |    313 | GPU
DEBUG 01-13 08:46:49.324877.324877 lmp.py:1622]   Expert 10 |    314 | GPU
DEBUG 01-13 08:46:49.324327.324327 lmp.py:1622]   Expert 25 |    318 | GPU
DEBUG 01-13 08:46:49.324255.324255 lmp.py:1622]   Expert  5 |    360 | GPU
DEBUG 01-13 08:46:49.324090.324090 lmp.py:1623] 
DEBUG 01-13 08:46:49.324090.324090 lmp.py:1623]   CPU total tokens: 3946 (32.1%)
DEBUG 01-13 08:46:49.324448.324448 lmp.py:1624]   GPU total tokens: 8342 (67.9%)
DEBUG 01-13 08:46:49.324098.324098 cuda_h.py:19] end experts_map_get cost 0.0015130043029785156 seconds
DEBUG 01-13 08:46:49.324802.324802 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-13 08:46:49.324174.324174 lmp.py:1632] 
DEBUG 01-13 08:46:49.324174.324174 lmp.py:1632]   Computing 32 experts on CPU MP...
DEBUG 01-13 08:46:49.324858.324858 cuda_h.py:19] end cpu_experts_submit cost 4.696846008300781e-05 seconds
DEBUG 01-13 08:46:49.324123.324123 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-13 08:46:49.324522.324522 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-13 08:46:49.325931.325931 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-13 08:46:49.325896.325896 cuda_h.py:10] start experts_func_gpu_einsum_mp
DEBUG 01-13 08:46:49.326637.326637 cuda_h.py:19] end allocate_cuda_memory cost 0.0011823177337646484 seconds
DEBUG 01-13 08:46:49.326759.326759 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-13 08:46:49.326959.326959 sllm_store_c.py:27] get device uuid map
DEBUG 01-13 08:46:49.326842.326842 sllm_store_c.py:29] call client load into gpu
DEBUG 01-13 08:46:49.326313.326313 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 3c8eaf61-e4f5-4276-9591-6880ac24e1e9
DEBUG 01-13 08:46:49.327394.327394 client.py:106] call stub.LoadModelAsync
INFO 01-13 08:46:49.327619.327619 client.py:127] Model loaded
DEBUG 01-13 08:46:49.327754.327754 cuda_h.py:10] start restore2model
DEBUG 01-13 08:46:49.327325.327325 cuda_h.py:19] end restore2model cost 0.0004069805145263672 seconds
DEBUG 01-13 08:46:49.327638.327638 cuda_h.py:19] end sllm_worker_task cost 0.009886026382446289 seconds
INFO 01-13 08:46:49.328873.328873 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 3c8eaf61-e4f5-4276-9591-6880ac24e1e9
DEBUG 01-13 08:46:49.328068.328068 cuda_h.py:19] end load_into_gpu_async cost 0.0022547245025634766 seconds
DEBUG 01-13 08:46:49.329162.329162 cuda_h.py:10] start restore_tensors2
DEBUG 01-13 08:46:49.329152.329152 cuda_h.py:19] end restore_tensors2 cost 0.00045013427734375 seconds
DEBUG 01-13 08:46:49.329055.329055 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0044231414794921875 seconds
DEBUG 01-13 08:46:49.329592.329592 cuda_h.py:10] start restore2model
DEBUG 01-13 08:46:49.332586.332586 cuda_h.py:19] end restore2model cost 0.0031189918518066406 seconds
DEBUG 01-13 08:46:49.332873.332873 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.00811457633972168 seconds
DEBUG 01-13 08:46:49.332860.332860 cuda_h.py:10] start gpu_sexperts
DEBUG 01-13 08:46:49.333388.333388 cuda_h.py:19] end gpu_sexperts cost 0.0002868175506591797 seconds
DEBUG 01-13 08:46:49.333171.333171 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-13 08:46:49.333709.333709 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 1.4543533325195312e-05 seconds
DEBUG 01-13 08:46:49.333597.333597 cuda_h.py:10] start wait_experts
INFO 01-13 08:46:49.333154.333154 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 3c8eaf61-e4f5-4276-9591-6880ac24e1e9
DEBUG 01-13 08:46:49.334961.334961 mlpmodule.py:1006] group tensors cost 0.007314920425415039 s
DEBUG 01-13 08:46:49.340514.340514 mlpmodule.py:1044] pad cost 0.005418539047241211 s
DEBUG 01-13 08:46:49.340747.340747 mlpmodule.py:1050] create cpu tensor cost 0.00011563301086425781 s
DEBUG 01-13 08:46:49.341594.341594 mlpmodule.py:1055] move to cpu cost 7.390975952148438e-05 s
DEBUG 01-13 08:46:49.353686.353686 mlpmodule.py:1069] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-13 08:46:49.353772.353772 mlpmodule.py:1070] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-13 08:46:49.353736.353736 mlpmodule.py:1075] group_w3 first element: 0.000789642333984375
WARNING 01-13 08:46:49.353602.353602 mlpmodule.py:1085] start einsum2
DEBUG 01-13 08:46:49.370837.370837 mlpmodule.py:1095] group einsum cost 0.029079675674438477 s
DEBUG 01-13 08:46:49.371672.371672 mlpmodule.py:1103] cpy2cputensor cost 0.0007460117340087891 s
INFO 01-13 08:46:49.379656.379656 client.py:127] Model loaded
DEBUG 01-13 08:46:49.380510.380510 cuda_h.py:19] end wait_experts cost 0.046799659729003906 seconds
DEBUG 01-13 08:46:49.380226.380226 cuda_h.py:10] start gpu_experts
DEBUG 01-13 08:46:49.381733.381733 mlpmodule.py:559] gpu group tensors cost 0.0007853507995605469 s
DEBUG 01-13 08:46:49.382557.382557 mlpmodule.py:592] gpu pad cost 0.0017955303192138672 s
DEBUG 01-13 08:46:49.383514.383514 mlpmodule.py:598] start_w1
DEBUG 01-13 08:46:49.383922.383922 mlpmodule.py:602] start_w3
DEBUG 01-13 08:46:49.383551.383551 mlpmodule.py:608] start_w2
DEBUG 01-13 08:46:49.383218.383218 mlpmodule.py:611] gpu group einsum cost 0.0006601810455322266 s
DEBUG 01-13 08:46:49.386362.386362 mlpmodule.py:683] gpu experts func einsum cost 0.005923032760620117 s
DEBUG 01-13 08:46:49.386670.386670 cuda_h.py:19] end gpu_experts cost 0.006089925765991211 seconds
DEBUG 01-13 08:46:49.386710.386710 cuda_h.py:10] start cpu_thread_manager_mp_wait
DEBUG 01-13 08:46:49.386660.386660 cuda_h.py:19] end cpu_thread_manager_mp_wait cost 3.743171691894531e-05 seconds
DEBUG 01-13 08:46:49.386914.386914 cuda_h.py:19] end layer_moe_generate_mp_l_15 cost 0.06419539451599121 seconds
DEBUG 01-13 08:46:49.386969.386969 lmp.py:1550] -------------------------------- end prefill layer 14 --------------------------------
DEBUG 01-13 08:46:49.386474.386474 lmp.py:1493] -------------------------------- start prefill layer 15 --------------------------------
DEBUG 01-13 08:46:49.386700.386700 cuda_h.py:10] start start_load_qkvogn_s_weight_l_16
DEBUG 01-13 08:46:49.386025.386025 cuda_h.py:10] start start_load_qkvogn_s_weight_l_16
DEBUG 01-13 08:46:49.386676.386676 cuda_h.py:19] end start_load_qkvogn_s_weight_l_16 cost 3.24249267578125e-05 seconds
DEBUG 01-13 08:46:49.386379.386379 cuda_h.py:19] end start_load_qkvogn_s_weight_l_16 cost 6.246566772460938e-05 seconds
DEBUG 01-13 08:46:49.386168.386168 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-13 08:46:49.387985.387985 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-13 08:46:49.387188.387188 cuda_h.py:10] start sllm_worker_task
DEBUG 01-13 08:46:49.387363.387363 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-13 08:46:49.387498.387498 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-13 08:46:49.387522.387522 cuda_h.py:19] end allocate_cuda_memory cost 0.00029778480529785156 seconds
DEBUG 01-13 08:46:49.387061.387061 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-13 08:46:49.387155.387155 sllm_store_c.py:27] get device uuid map
DEBUG 01-13 08:46:49.387912.387912 sllm_store_c.py:29] call client load into gpu
DEBUG 01-13 08:46:49.387377.387377 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, a7cf1f42-d521-44dc-ae97-98033b3ad008
DEBUG 01-13 08:46:49.387353.387353 client.py:106] call stub.LoadModelAsync
DEBUG 01-13 08:46:49.388301.388301 cuda_h.py:10] start self_attn
INFO 01-13 08:46:49.389656.389656 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, a7cf1f42-d521-44dc-ae97-98033b3ad008
DEBUG 01-13 08:46:49.389969.389969 cuda_h.py:19] end load_into_gpu_async cost 0.001758575439453125 seconds
DEBUG 01-13 08:46:49.389764.389764 cuda_h.py:10] start restore_tensors2
DEBUG 01-13 08:46:49.389768.389768 cuda_h.py:19] end restore_tensors2 cost 8.177757263183594e-05 seconds
DEBUG 01-13 08:46:49.389663.389663 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.002393007278442383 seconds
INFO 01-13 08:46:49.389724.389724 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, a7cf1f42-d521-44dc-ae97-98033b3ad008
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-13 08:46:49.391353.391353 cuda_h.py:19] end self_attn cost 0.002878427505493164 seconds
DEBUG 01-13 08:46:49.391946.391946 cuda_h.py:19] end iln_self_attn_paln cost 0.004398822784423828 seconds
DEBUG 01-13 08:46:49.391358.391358 cuda_h.py:10] start layer_moe_generate_mp_l_16
DEBUG 01-13 08:46:49.391498.391498 cuda_h.py:10] start gate
DEBUG 01-13 08:46:49.392733.392733 cuda_h.py:19] end gate cost 0.0006313323974609375 seconds
DEBUG 01-13 08:46:49.392178.392178 cuda_h.py:10] start experts_map_get
DEBUG 01-13 08:46:49.392653.392653 lmp.py:1611] 
DEBUG 01-13 08:46:49.392653.392653 lmp.py:1611] Expert Token Distribution & Device Allocation:
DEBUG 01-13 08:46:49.392078.392078 lmp.py:1612]   Total experts: 64
DEBUG 01-13 08:46:49.392966.392966 lmp.py:1613]   CPU experts: 32 (50%)
DEBUG 01-13 08:46:49.392801.392801 lmp.py:1614]   GPU experts: 32 (50%)
DEBUG 01-13 08:46:49.392491.392491 lmp.py:1615] 
DEBUG 01-13 08:46:49.392491.392491 lmp.py:1615]   Expert ID | Tokens | Device
DEBUG 01-13 08:46:49.392895.392895 lmp.py:1616]   -----------------------------------
DEBUG 01-13 08:46:49.392783.392783 lmp.py:1622]   Expert 15 |     58 | CPU
DEBUG 01-13 08:46:49.392188.392188 lmp.py:1622]   Expert 41 |     68 | CPU
DEBUG 01-13 08:46:49.392162.392162 lmp.py:1622]   Expert 63 |     72 | CPU
DEBUG 01-13 08:46:49.392136.392136 lmp.py:1622]   Expert 20 |     80 | CPU
DEBUG 01-13 08:46:49.392872.392872 lmp.py:1622]   Expert  0 |     82 | CPU
DEBUG 01-13 08:46:49.392846.392846 lmp.py:1622]   Expert 45 |     84 | CPU
DEBUG 01-13 08:46:49.392581.392581 lmp.py:1622]   Expert  7 |     94 | CPU
DEBUG 01-13 08:46:49.392555.392555 lmp.py:1622]   Expert 28 |     98 | CPU
DEBUG 01-13 08:46:49.392483.392483 lmp.py:1622]   Expert 54 |    103 | CPU
DEBUG 01-13 08:46:49.392457.392457 lmp.py:1622]   Expert 12 |    107 | CPU
DEBUG 01-13 08:46:49.392670.392670 lmp.py:1622]   Expert 52 |    113 | CPU
DEBUG 01-13 08:46:49.392121.392121 lmp.py:1622]   Expert 40 |    118 | CPU
DEBUG 01-13 08:46:49.392095.392095 lmp.py:1622]   Expert  4 |    122 | CPU
DEBUG 01-13 08:46:49.392307.392307 lmp.py:1622]   Expert  5 |    126 | CPU
DEBUG 01-13 08:46:49.392281.392281 lmp.py:1622]   Expert 59 |    127 | CPU
DEBUG 01-13 08:46:49.392540.392540 lmp.py:1622]   Expert 62 |    129 | CPU
DEBUG 01-13 08:46:49.392276.392276 lmp.py:1622]   Expert 34 |    130 | CPU
DEBUG 01-13 08:46:49.392773.392773 lmp.py:1622]   Expert 61 |    134 | CPU
DEBUG 01-13 08:46:49.392508.392508 lmp.py:1622]   Expert 13 |    136 | CPU
DEBUG 01-13 08:46:49.392767.392767 lmp.py:1622]   Expert 21 |    141 | CPU
DEBUG 01-13 08:46:49.392788.392788 lmp.py:1622]   Expert 55 |    142 | CPU
DEBUG 01-13 08:46:49.393285.393285 lmp.py:1622]   Expert 22 |    143 | CPU
DEBUG 01-13 08:46:49.393020.393020 lmp.py:1622]   Expert 42 |    143 | CPU
DEBUG 01-13 08:46:49.393379.393379 lmp.py:1622]   Expert 10 |    146 | CPU
DEBUG 01-13 08:46:49.393022.393022 lmp.py:1622]   Expert 14 |    147 | CPU
DEBUG 01-13 08:46:49.393426.393426 lmp.py:1622]   Expert 51 |    155 | CPU
DEBUG 01-13 08:46:49.393831.393831 lmp.py:1622]   Expert 32 |    160 | CPU
DEBUG 01-13 08:46:49.393282.393282 lmp.py:1622]   Expert 25 |    165 | CPU
DEBUG 01-13 08:46:49.393732.393732 lmp.py:1622]   Expert 50 |    168 | CPU
DEBUG 01-13 08:46:49.393183.393183 lmp.py:1622]   Expert 53 |    171 | CPU
DEBUG 01-13 08:46:49.393634.393634 lmp.py:1622]   Expert 30 |    176 | CPU
DEBUG 01-13 08:46:49.393608.393608 lmp.py:1622]   Expert 26 |    178 | CPU
DEBUG 01-13 08:46:49.393298.393298 lmp.py:1622]   Expert  2 |    179 | GPU
DEBUG 01-13 08:46:49.393987.393987 lmp.py:1622]   Expert  6 |    179 | GPU
DEBUG 01-13 08:46:49.393438.393438 lmp.py:1622]   Expert 19 |    179 | GPU
DEBUG 01-13 08:46:49.393650.393650 lmp.py:1622]   Expert 47 |    180 | GPU
DEBUG 01-13 08:46:49.393624.393624 lmp.py:1622]   Expert  1 |    183 | GPU
DEBUG 01-13 08:46:49.393314.393314 lmp.py:1622]   Expert 35 |    185 | GPU
DEBUG 01-13 08:46:49.393480.393480 lmp.py:1622]   Expert 11 |    189 | GPU
DEBUG 01-13 08:46:49.393884.393884 lmp.py:1622]   Expert 57 |    189 | GPU
DEBUG 01-13 08:46:49.393574.393574 lmp.py:1622]   Expert 56 |    190 | GPU
DEBUG 01-13 08:46:49.393978.393978 lmp.py:1622]   Expert 48 |    204 | GPU
DEBUG 01-13 08:46:49.393621.393621 lmp.py:1622]   Expert 46 |    208 | GPU
DEBUG 01-13 08:46:49.393072.393072 lmp.py:1622]   Expert 24 |    209 | GPU
DEBUG 01-13 08:46:49.393000.393000 lmp.py:1622]   Expert 44 |    217 | GPU
DEBUG 01-13 08:46:49.393451.393451 lmp.py:1622]   Expert 16 |    218 | GPU
DEBUG 01-13 08:46:49.393378.393378 lmp.py:1622]   Expert 39 |    222 | GPU
DEBUG 01-13 08:46:49.393352.393352 lmp.py:1622]   Expert 18 |    229 | GPU
DEBUG 01-13 08:46:49.393803.393803 lmp.py:1622]   Expert 29 |    234 | GPU
DEBUG 01-13 08:46:49.393016.393016 lmp.py:1622]   Expert 37 |    241 | GPU
DEBUG 01-13 08:46:49.393228.393228 lmp.py:1622]   Expert  3 |    254 | GPU
DEBUG 01-13 08:46:49.393679.393679 lmp.py:1622]   Expert 31 |    255 | GPU
DEBUG 01-13 08:46:49.393607.393607 lmp.py:1622]   Expert 17 |    258 | GPU
DEBUG 01-13 08:46:49.393534.393534 lmp.py:1622]   Expert 60 |    258 | GPU
DEBUG 01-13 08:46:49.393462.393462 lmp.py:1622]   Expert 36 |    260 | GPU
DEBUG 01-13 08:46:49.393628.393628 lmp.py:1622]   Expert 38 |    262 | GPU
DEBUG 01-13 08:46:49.393602.393602 lmp.py:1622]   Expert 23 |    267 | GPU
DEBUG 01-13 08:46:49.393053.393053 lmp.py:1622]   Expert  9 |    271 | GPU
DEBUG 01-13 08:46:49.393504.393504 lmp.py:1622]   Expert 43 |    361 | GPU
DEBUG 01-13 08:46:49.393478.393478 lmp.py:1622]   Expert 27 |    365 | GPU
DEBUG 01-13 08:46:49.393691.393691 lmp.py:1622]   Expert 33 |    404 | GPU
DEBUG 01-13 08:46:49.393903.393903 lmp.py:1622]   Expert  8 |    438 | GPU
DEBUG 01-13 08:46:49.393116.393116 lmp.py:1622]   Expert 58 |    447 | GPU
DEBUG 01-13 08:46:49.393090.393090 lmp.py:1622]   Expert 49 |    537 | GPU
DEBUG 01-13 08:46:49.393494.393494 lmp.py:1623] 
DEBUG 01-13 08:46:49.393494.393494 lmp.py:1623]   CPU total tokens: 4016 (32.7%)
DEBUG 01-13 08:46:49.393137.393137 lmp.py:1624]   GPU total tokens: 8272 (67.3%)
DEBUG 01-13 08:46:49.393310.393310 cuda_h.py:19] end experts_map_get cost 0.0015437602996826172 seconds
DEBUG 01-13 08:46:49.393683.393683 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-13 08:46:49.393532.393532 lmp.py:1632] 
DEBUG 01-13 08:46:49.393532.393532 lmp.py:1632]   Computing 32 experts on CPU MP...
DEBUG 01-13 08:46:49.393600.393600 cuda_h.py:19] end cpu_experts_submit cost 4.982948303222656e-05 seconds
DEBUG 01-13 08:46:49.393150.393150 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-13 08:46:49.393503.393503 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-13 08:46:49.394971.394971 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-13 08:46:49.395290.395290 cuda_h.py:19] end allocate_cuda_memory cost 0.0017817020416259766 seconds
DEBUG 01-13 08:46:49.396727.396727 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-13 08:46:49.396966.396966 sllm_store_c.py:27] get device uuid map
DEBUG 01-13 08:46:49.396882.396882 sllm_store_c.py:29] call client load into gpu
DEBUG 01-13 08:46:49.396677.396677 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, f0d94fd6-3d40-4368-acba-f5fb04a8d2e2
DEBUG 01-13 08:46:49.396976.396976 client.py:106] call stub.LoadModelAsync
DEBUG 01-13 08:46:49.396635.396635 mlpmodule.py:785]  experts func einsum cost 0.06999516487121582 s
DEBUG 01-13 08:46:49.396853.396853 cuda_h.py:19] end experts_func_gpu_einsum_mp cost 0.07120513916015625 seconds
INFO 01-13 08:46:49.397713.397713 client.py:127] Model loaded
DEBUG 01-13 08:46:49.397112.397112 cuda_h.py:10] start restore2model
DEBUG 01-13 08:46:49.397111.397111 cuda_h.py:10] start experts_func_gpu_einsum_mp
DEBUG 01-13 08:46:49.398726.398726 cuda_h.py:19] end restore2model cost 0.00031685829162597656 seconds
DEBUG 01-13 08:46:49.398542.398542 cuda_h.py:19] end sllm_worker_task cost 0.010885238647460938 seconds
INFO 01-13 08:46:49.399881.399881 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, f0d94fd6-3d40-4368-acba-f5fb04a8d2e2
DEBUG 01-13 08:46:49.399846.399846 cuda_h.py:19] end load_into_gpu_async cost 0.003122568130493164 seconds
DEBUG 01-13 08:46:49.399193.399193 cuda_h.py:10] start restore_tensors2
DEBUG 01-13 08:46:49.400793.400793 cuda_h.py:19] end restore_tensors2 cost 0.0004489421844482422 seconds
DEBUG 01-13 08:46:49.400537.400537 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.006147623062133789 seconds
DEBUG 01-13 08:46:49.400446.400446 cuda_h.py:10] start restore2model
DEBUG 01-13 08:46:49.402180.402180 cuda_h.py:19] end restore2model cost 0.002515554428100586 seconds
DEBUG 01-13 08:46:49.402182.402182 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.00885009765625 seconds
DEBUG 01-13 08:46:49.402070.402070 cuda_h.py:10] start gpu_sexperts
DEBUG 01-13 08:46:49.402150.402150 mlpmodule.py:1006] group tensors cost 0.004207611083984375 s
DEBUG 01-13 08:46:49.403272.403272 cuda_h.py:19] end gpu_sexperts cost 0.00026035308837890625 seconds
DEBUG 01-13 08:46:49.403671.403671 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-13 08:46:49.403679.403679 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 1.3589859008789062e-05 seconds
DEBUG 01-13 08:46:49.403567.403567 cuda_h.py:10] start wait_experts
INFO 01-13 08:46:49.403310.403310 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, f0d94fd6-3d40-4368-acba-f5fb04a8d2e2
DEBUG 01-13 08:46:49.405386.405386 mlpmodule.py:1044] pad cost 0.002003908157348633 s
DEBUG 01-13 08:46:49.405827.405827 mlpmodule.py:1050] create cpu tensor cost 5.412101745605469e-05 s
DEBUG 01-13 08:46:49.405167.405167 mlpmodule.py:1055] move to cpu cost 3.910064697265625e-05 s
DEBUG 01-13 08:46:49.412979.412979 mlpmodule.py:1069] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-13 08:46:49.412940.412940 mlpmodule.py:1070] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-13 08:46:49.412732.412732 mlpmodule.py:1075] group_w3 first element: -0.0595703125
WARNING 01-13 08:46:49.413671.413671 mlpmodule.py:1085] start einsum2
DEBUG 01-13 08:46:49.425586.425586 mlpmodule.py:1095] group einsum cost 0.020336627960205078 s
DEBUG 01-13 08:46:49.426163.426163 mlpmodule.py:1103] cpy2cputensor cost 0.0007643699645996094 s
INFO 01-13 08:46:49.449264.449264 client.py:127] Model loaded
DEBUG 01-13 08:46:49.450405.450405 cuda_h.py:19] end wait_experts cost 0.04690861701965332 seconds
DEBUG 01-13 08:46:49.450779.450779 cuda_h.py:10] start gpu_experts
DEBUG 01-13 08:46:49.450641.450641 mlpmodule.py:785]  experts func einsum cost 0.05251193046569824 s
DEBUG 01-13 08:46:49.451393.451393 cuda_h.py:19] end experts_func_gpu_einsum_mp cost 0.05343747138977051 seconds
DEBUG 01-13 08:46:49.451195.451195 mlpmodule.py:559] gpu group tensors cost 0.0009615421295166016 s
DEBUG 01-13 08:46:49.453262.453262 mlpmodule.py:592] gpu pad cost 0.0023107528686523438 s
DEBUG 01-13 08:46:49.453384.453384 mlpmodule.py:598] start_w1
DEBUG 01-13 08:46:49.454598.454598 mlpmodule.py:602] start_w3
DEBUG 01-13 08:46:49.454567.454567 mlpmodule.py:608] start_w2
DEBUG 01-13 08:46:49.454886.454886 mlpmodule.py:611] gpu group einsum cost 0.0009300708770751953 s
DEBUG 01-13 08:46:49.458050.458050 mlpmodule.py:683] gpu experts func einsum cost 0.007914543151855469 s
DEBUG 01-13 08:46:49.458120.458120 cuda_h.py:19] end gpu_experts cost 0.00815129280090332 seconds
DEBUG 01-13 08:46:49.458473.458473 cuda_h.py:10] start cpu_thread_manager_mp_wait
DEBUG 01-13 08:46:49.458172.458172 cuda_h.py:19] end cpu_thread_manager_mp_wait cost 4.744529724121094e-05 seconds
DEBUG 01-13 08:46:49.458473.458473 cuda_h.py:19] end layer_moe_generate_mp_l_16 cost 0.0672905445098877 seconds
DEBUG 01-13 08:46:49.459067.459067 lmp.py:1550] -------------------------------- end prefill layer 15 --------------------------------
DEBUG 01-13 08:46:49.459586.459586 lmp.py:1493] -------------------------------- start prefill layer 16 --------------------------------
DEBUG 01-13 08:46:49.459879.459879 cuda_h.py:10] start start_load_qkvogn_s_weight_l_17
DEBUG 01-13 08:46:49.459986.459986 cuda_h.py:10] start start_load_qkvogn_s_weight_l_17
DEBUG 01-13 08:46:49.459426.459426 cuda_h.py:19] end start_load_qkvogn_s_weight_l_17 cost 3.886222839355469e-05 seconds
DEBUG 01-13 08:46:49.459434.459434 cuda_h.py:19] end start_load_qkvogn_s_weight_l_17 cost 8.463859558105469e-05 seconds
DEBUG 01-13 08:46:49.459475.459475 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-13 08:46:49.459585.459585 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-13 08:46:49.459530.459530 cuda_h.py:10] start sllm_worker_task
DEBUG 01-13 08:46:49.459192.459192 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-13 08:46:49.460880.460880 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-13 08:46:49.460817.460817 cuda_h.py:19] end allocate_cuda_memory cost 0.0005562305450439453 seconds
DEBUG 01-13 08:46:49.460068.460068 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-13 08:46:49.461217.461217 sllm_store_c.py:27] get device uuid map
DEBUG 01-13 08:46:49.461176.461176 sllm_store_c.py:29] call client load into gpu
DEBUG 01-13 08:46:49.461920.461920 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 836c8909-9e4d-4ef9-b576-bcfceaa41e68
DEBUG 01-13 08:46:49.461851.461851 cuda_h.py:10] start self_attn
DEBUG 01-13 08:46:49.461726.461726 client.py:106] call stub.LoadModelAsync
INFO 01-13 08:46:49.463278.463278 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 836c8909-9e4d-4ef9-b576-bcfceaa41e68
DEBUG 01-13 08:46:49.463203.463203 cuda_h.py:19] end load_into_gpu_async cost 0.0025489330291748047 seconds
DEBUG 01-13 08:46:49.463710.463710 cuda_h.py:10] start restore_tensors2
DEBUG 01-13 08:46:49.463684.463684 cuda_h.py:19] end restore_tensors2 cost 0.000148773193359375 seconds
DEBUG 01-13 08:46:49.463396.463396 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.004004240036010742 seconds
INFO 01-13 08:46:49.464799.464799 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 836c8909-9e4d-4ef9-b576-bcfceaa41e68
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-13 08:46:49.465756.465756 cuda_h.py:19] end self_attn cost 0.00395512580871582 seconds
DEBUG 01-13 08:46:49.465342.465342 cuda_h.py:19] end iln_self_attn_paln cost 0.006463050842285156 seconds
DEBUG 01-13 08:46:49.465562.465562 cuda_h.py:10] start layer_moe_generate_mp_l_17
DEBUG 01-13 08:46:49.466179.466179 cuda_h.py:10] start gate
DEBUG 01-13 08:46:49.466844.466844 cuda_h.py:19] end gate cost 0.0006337165832519531 seconds
DEBUG 01-13 08:46:49.466766.466766 cuda_h.py:10] start experts_map_get
DEBUG 01-13 08:46:49.467928.467928 lmp.py:1611] 
DEBUG 01-13 08:46:49.467928.467928 lmp.py:1611] Expert Token Distribution & Device Allocation:
DEBUG 01-13 08:46:49.467730.467730 lmp.py:1612]   Total experts: 64
DEBUG 01-13 08:46:49.467142.467142 lmp.py:1613]   CPU experts: 32 (50%)
DEBUG 01-13 08:46:49.467454.467454 lmp.py:1614]   GPU experts: 32 (50%)
DEBUG 01-13 08:46:49.467097.467097 lmp.py:1615] 
DEBUG 01-13 08:46:49.467097.467097 lmp.py:1615]   Expert ID | Tokens | Device
DEBUG 01-13 08:46:49.467455.467455 lmp.py:1616]   -----------------------------------
DEBUG 01-13 08:46:49.467820.467820 lmp.py:1622]   Expert 58 |     33 | CPU
DEBUG 01-13 08:46:49.467224.467224 lmp.py:1622]   Expert 47 |     55 | CPU
DEBUG 01-13 08:46:49.467914.467914 lmp.py:1622]   Expert 49 |     59 | CPU
DEBUG 01-13 08:46:49.467888.467888 lmp.py:1622]   Expert 31 |     61 | CPU
DEBUG 01-13 08:46:49.467862.467862 lmp.py:1622]   Expert  4 |     69 | CPU
DEBUG 01-13 08:46:49.467836.467836 lmp.py:1622]   Expert 38 |     70 | CPU
DEBUG 01-13 08:46:49.467333.467333 lmp.py:1622]   Expert 45 |     71 | CPU
DEBUG 01-13 08:46:49.467830.467830 lmp.py:1622]   Expert 43 |     72 | CPU
DEBUG 01-13 08:46:49.467327.467327 lmp.py:1622]   Expert 41 |     84 | CPU
DEBUG 01-13 08:46:49.467825.467825 lmp.py:1622]   Expert 33 |    102 | CPU
DEBUG 01-13 08:46:49.467322.467322 lmp.py:1622]   Expert 50 |    106 | CPU
DEBUG 01-13 08:46:49.467011.467011 lmp.py:1622]   Expert 57 |    107 | CPU
DEBUG 01-13 08:46:49.467416.467416 lmp.py:1622]   Expert  2 |    111 | CPU
DEBUG 01-13 08:46:49.467151.467151 lmp.py:1622]   Expert 11 |    111 | CPU
DEBUG 01-13 08:46:49.467410.467410 lmp.py:1622]   Expert 51 |    112 | CPU
DEBUG 01-13 08:46:49.467146.467146 lmp.py:1622]   Expert 54 |    125 | CPU
DEBUG 01-13 08:46:49.467643.467643 lmp.py:1622]   Expert  0 |    126 | CPU
DEBUG 01-13 08:46:49.467663.467663 lmp.py:1622]   Expert 14 |    127 | CPU
DEBUG 01-13 08:46:49.467922.467922 lmp.py:1622]   Expert 56 |    128 | CPU
DEBUG 01-13 08:46:49.467181.467181 lmp.py:1622]   Expert 34 |    136 | CPU
DEBUG 01-13 08:46:49.467678.467678 lmp.py:1622]   Expert 26 |    149 | CPU
DEBUG 01-13 08:46:49.467699.467699 lmp.py:1622]   Expert 27 |    158 | CPU
DEBUG 01-13 08:46:49.467719.467719 lmp.py:1622]   Expert 28 |    159 | CPU
DEBUG 01-13 08:46:49.467978.467978 lmp.py:1622]   Expert 25 |    164 | CPU
DEBUG 01-13 08:46:49.467236.467236 lmp.py:1622]   Expert 10 |    168 | CPU
DEBUG 01-13 08:46:49.467734.467734 lmp.py:1622]   Expert 55 |    172 | CPU
DEBUG 01-13 08:46:49.467185.467185 lmp.py:1622]   Expert  9 |    182 | CPU
DEBUG 01-13 08:46:49.467874.467874 lmp.py:1622]   Expert 13 |    187 | CPU
DEBUG 01-13 08:46:49.467848.467848 lmp.py:1622]   Expert 48 |    189 | CPU
DEBUG 01-13 08:46:49.467299.467299 lmp.py:1622]   Expert  6 |    191 | CPU
DEBUG 01-13 08:46:49.467034.467034 lmp.py:1622]   Expert 61 |    192 | CPU
DEBUG 01-13 08:46:49.467532.467532 lmp.py:1622]   Expert 24 |    193 | CPU
DEBUG 01-13 08:46:49.467267.467267 lmp.py:1622]   Expert 46 |    195 | GPU
DEBUG 01-13 08:46:49.467526.467526 lmp.py:1622]   Expert  7 |    196 | GPU
DEBUG 01-13 08:46:49.467023.467023 lmp.py:1622]   Expert 42 |    199 | GPU
DEBUG 01-13 08:46:49.467520.467520 lmp.py:1622]   Expert 18 |    207 | GPU
DEBUG 01-13 08:46:49.467071.467071 lmp.py:1622]   Expert 40 |    208 | GPU
DEBUG 01-13 08:46:49.467714.467714 lmp.py:1622]   Expert 63 |    213 | GPU
DEBUG 01-13 08:46:49.467834.467834 lmp.py:1622]   Expert 59 |    214 | GPU
DEBUG 01-13 08:46:49.467669.467669 lmp.py:1622]   Expert 12 |    215 | GPU
DEBUG 01-13 08:46:49.467265.467265 lmp.py:1622]   Expert 21 |    217 | GPU
DEBUG 01-13 08:46:49.467670.467670 lmp.py:1622]   Expert 29 |    222 | GPU
DEBUG 01-13 08:46:49.467598.467598 lmp.py:1622]   Expert 22 |    223 | GPU
DEBUG 01-13 08:46:49.467002.467002 lmp.py:1622]   Expert 32 |    223 | GPU
DEBUG 01-13 08:46:49.467407.467407 lmp.py:1622]   Expert 19 |    230 | GPU
DEBUG 01-13 08:46:49.467573.467573 lmp.py:1622]   Expert 36 |    233 | GPU
DEBUG 01-13 08:46:49.467501.467501 lmp.py:1622]   Expert  3 |    247 | GPU
DEBUG 01-13 08:46:49.467667.467667 lmp.py:1622]   Expert  1 |    248 | GPU
DEBUG 01-13 08:46:49.467594.467594 lmp.py:1622]   Expert 37 |    249 | GPU
DEBUG 01-13 08:46:49.467834.467834 lmp.py:1622]   Expert  8 |    259 | GPU
DEBUG 01-13 08:46:49.467954.467954 lmp.py:1622]   Expert 16 |    259 | GPU
DEBUG 01-13 08:46:49.467550.467550 lmp.py:1622]   Expert 30 |    262 | GPU
DEBUG 01-13 08:46:49.468001.468001 lmp.py:1622]   Expert 15 |    267 | GPU
DEBUG 01-13 08:46:49.468214.468214 lmp.py:1622]   Expert 20 |    269 | GPU
DEBUG 01-13 08:46:49.468188.468188 lmp.py:1622]   Expert  5 |    270 | GPU
DEBUG 01-13 08:46:49.468685.468685 lmp.py:1622]   Expert 62 |    272 | GPU
DEBUG 01-13 08:46:49.468421.468421 lmp.py:1622]   Expert 35 |    290 | GPU
DEBUG 01-13 08:46:49.468918.468918 lmp.py:1622]   Expert 17 |    293 | GPU
DEBUG 01-13 08:46:49.468938.468938 lmp.py:1622]   Expert 39 |    303 | GPU
DEBUG 01-13 08:46:49.468674.468674 lmp.py:1622]   Expert 60 |    306 | GPU
DEBUG 01-13 08:46:49.468933.468933 lmp.py:1622]   Expert 52 |    354 | GPU
DEBUG 01-13 08:46:49.468668.468668 lmp.py:1622]   Expert 23 |    358 | GPU
DEBUG 01-13 08:46:49.468404.468404 lmp.py:1622]   Expert 44 |    376 | GPU
DEBUG 01-13 08:46:49.468332.468332 lmp.py:1622]   Expert 53 |    442 | GPU
DEBUG 01-13 08:46:49.468451.468451 lmp.py:1623] 
DEBUG 01-13 08:46:49.468451.468451 lmp.py:1623]   CPU total tokens: 3969 (32.3%)
DEBUG 01-13 08:46:49.468048.468048 lmp.py:1624]   GPU total tokens: 8319 (67.7%)
DEBUG 01-13 08:46:49.468506.468506 cuda_h.py:19] end experts_map_get cost 0.0015010833740234375 seconds
DEBUG 01-13 08:46:49.468779.468779 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-13 08:46:49.468105.468105 lmp.py:1632] 
DEBUG 01-13 08:46:49.468105.468105 lmp.py:1632]   Computing 32 experts on CPU MP...
DEBUG 01-13 08:46:49.468860.468860 cuda_h.py:19] end cpu_experts_submit cost 4.8160552978515625e-05 seconds
DEBUG 01-13 08:46:49.468669.468669 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-13 08:46:49.468267.468267 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-13 08:46:49.468596.468596 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-13 08:46:49.470141.470141 cuda_h.py:19] end allocate_cuda_memory cost 0.0018079280853271484 seconds
DEBUG 01-13 08:46:49.470700.470700 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-13 08:46:49.470740.470740 sllm_store_c.py:27] get device uuid map
DEBUG 01-13 08:46:49.470549.470549 sllm_store_c.py:29] call client load into gpu
DEBUG 01-13 08:46:49.470438.470438 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 8cddcd44-e728-46d9-ba86-495ad4226de0
DEBUG 01-13 08:46:49.470524.470524 client.py:106] call stub.LoadModelAsync
INFO 01-13 08:46:49.471262.471262 client.py:127] Model loaded
DEBUG 01-13 08:46:49.471524.471524 cuda_h.py:10] start restore2model
DEBUG 01-13 08:46:49.472475.472475 cuda_h.py:10] start experts_func_gpu_einsum_mp
DEBUG 01-13 08:46:49.472257.472257 cuda_h.py:19] end restore2model cost 0.0009992122650146484 seconds
DEBUG 01-13 08:46:49.472797.472797 cuda_h.py:19] end sllm_worker_task cost 0.013134956359863281 seconds
INFO 01-13 08:46:49.473847.473847 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 8cddcd44-e728-46d9-ba86-495ad4226de0
DEBUG 01-13 08:46:49.473302.473302 cuda_h.py:19] end load_into_gpu_async cost 0.0025162696838378906 seconds
DEBUG 01-13 08:46:49.473011.473011 cuda_h.py:10] start restore_tensors2
DEBUG 01-13 08:46:49.473489.473489 cuda_h.py:19] end restore_tensors2 cost 0.0003933906555175781 seconds
DEBUG 01-13 08:46:49.473994.473994 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.005075693130493164 seconds
DEBUG 01-13 08:46:49.473095.473095 cuda_h.py:10] start restore2model
DEBUG 01-13 08:46:49.476146.476146 cuda_h.py:19] end restore2model cost 0.002502918243408203 seconds
DEBUG 01-13 08:46:49.476983.476983 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.0077571868896484375 seconds
DEBUG 01-13 08:46:49.476335.476335 cuda_h.py:10] start gpu_sexperts
DEBUG 01-13 08:46:49.476459.476459 cuda_h.py:19] end gpu_sexperts cost 0.0002913475036621094 seconds
DEBUG 01-13 08:46:49.476812.476812 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-13 08:46:49.476542.476542 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 1.4543533325195312e-05 seconds
DEBUG 01-13 08:46:49.476000.476000 cuda_h.py:10] start wait_experts
INFO 01-13 08:46:49.476126.476126 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 8cddcd44-e728-46d9-ba86-495ad4226de0
DEBUG 01-13 08:46:49.488143.488143 mlpmodule.py:1006] group tensors cost 0.01615142822265625 s
DEBUG 01-13 08:46:49.493000.493000 mlpmodule.py:1044] pad cost 0.003448486328125 s
DEBUG 01-13 08:46:49.493946.493946 mlpmodule.py:1050] create cpu tensor cost 7.963180541992188e-05 s
DEBUG 01-13 08:46:49.493910.493910 mlpmodule.py:1055] move to cpu cost 5.4836273193359375e-05 s
DEBUG 01-13 08:46:49.503512.503512 mlpmodule.py:1069] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-13 08:46:49.503605.503605 mlpmodule.py:1070] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-13 08:46:49.503537.503537 mlpmodule.py:1075] group_w3 first element: -0.02490234375
WARNING 01-13 08:46:49.503807.503807 mlpmodule.py:1085] start einsum2
DEBUG 01-13 08:46:49.516907.516907 mlpmodule.py:1095] group einsum cost 0.02291727066040039 s
DEBUG 01-13 08:46:49.517782.517782 mlpmodule.py:1103] cpy2cputensor cost 0.0007781982421875 s
INFO 01-13 08:46:49.524006.524006 client.py:127] Model loaded
DEBUG 01-13 08:46:49.524250.524250 cuda_h.py:19] end wait_experts cost 0.04738783836364746 seconds
DEBUG 01-13 08:46:49.524874.524874 cuda_h.py:10] start gpu_experts
DEBUG 01-13 08:46:49.525381.525381 mlpmodule.py:559] gpu group tensors cost 0.0007596015930175781 s
DEBUG 01-13 08:46:49.527126.527126 mlpmodule.py:592] gpu pad cost 0.0018045902252197266 s
DEBUG 01-13 08:46:49.527513.527513 mlpmodule.py:598] start_w1
DEBUG 01-13 08:46:49.527149.527149 mlpmodule.py:602] start_w3
DEBUG 01-13 08:46:49.527050.527050 mlpmodule.py:608] start_w2
DEBUG 01-13 08:46:49.528507.528507 mlpmodule.py:611] gpu group einsum cost 0.0007994174957275391 s
DEBUG 01-13 08:46:49.530823.530823 mlpmodule.py:683] gpu experts func einsum cost 0.006251335144042969 s
DEBUG 01-13 08:46:49.530668.530668 cuda_h.py:19] end gpu_experts cost 0.006452798843383789 seconds
DEBUG 01-13 08:46:49.530238.530238 cuda_h.py:10] start cpu_thread_manager_mp_wait
DEBUG 01-13 08:46:49.530102.530102 cuda_h.py:19] end cpu_thread_manager_mp_wait cost 4.076957702636719e-05 seconds
DEBUG 01-13 08:46:49.531509.531509 cuda_h.py:19] end layer_moe_generate_mp_l_17 cost 0.06502771377563477 seconds
DEBUG 01-13 08:46:49.531717.531717 lmp.py:1550] -------------------------------- end prefill layer 16 --------------------------------
DEBUG 01-13 08:46:49.531970.531970 lmp.py:1493] -------------------------------- start prefill layer 17 --------------------------------
DEBUG 01-13 08:46:49.531726.531726 cuda_h.py:10] start start_load_qkvogn_s_weight_l_18
DEBUG 01-13 08:46:49.531211.531211 cuda_h.py:10] start start_load_qkvogn_s_weight_l_18
DEBUG 01-13 08:46:49.531207.531207 cuda_h.py:19] end start_load_qkvogn_s_weight_l_18 cost 3.552436828613281e-05 seconds
DEBUG 01-13 08:46:49.531963.531963 cuda_h.py:19] end start_load_qkvogn_s_weight_l_18 cost 6.961822509765625e-05 seconds
DEBUG 01-13 08:46:49.531282.531282 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-13 08:46:49.531728.531728 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-13 08:46:49.531804.531804 cuda_h.py:10] start sllm_worker_task
DEBUG 01-13 08:46:49.531615.531615 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-13 08:46:49.531544.531544 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-13 08:46:49.532577.532577 cuda_h.py:19] end allocate_cuda_memory cost 0.0003383159637451172 seconds
DEBUG 01-13 08:46:49.532838.532838 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-13 08:46:49.532475.532475 sllm_store_c.py:27] get device uuid map
DEBUG 01-13 08:46:49.532921.532921 sllm_store_c.py:29] call client load into gpu
DEBUG 01-13 08:46:49.532816.532816 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 04dcde05-f3e2-4c54-baa0-dc32fb436f58
DEBUG 01-13 08:46:49.532077.532077 client.py:106] call stub.LoadModelAsync
DEBUG 01-13 08:46:49.532464.532464 cuda_h.py:10] start self_attn
INFO 01-13 08:46:49.533217.533217 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 04dcde05-f3e2-4c54-baa0-dc32fb436f58
DEBUG 01-13 08:46:49.534722.534722 cuda_h.py:19] end load_into_gpu_async cost 0.0016202926635742188 seconds
DEBUG 01-13 08:46:49.534802.534802 cuda_h.py:10] start restore_tensors2
DEBUG 01-13 08:46:49.534646.534646 cuda_h.py:19] end restore_tensors2 cost 7.033348083496094e-05 seconds
DEBUG 01-13 08:46:49.534780.534780 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.002302408218383789 seconds
INFO 01-13 08:46:49.534907.534907 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 04dcde05-f3e2-4c54-baa0-dc32fb436f58
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-13 08:46:49.535605.535605 cuda_h.py:19] end self_attn cost 0.002950906753540039 seconds
DEBUG 01-13 08:46:49.536324.536324 cuda_h.py:19] end iln_self_attn_paln cost 0.004599094390869141 seconds
DEBUG 01-13 08:46:49.536975.536975 cuda_h.py:10] start layer_moe_generate_mp_l_18
DEBUG 01-13 08:46:49.536877.536877 cuda_h.py:10] start gate
DEBUG 01-13 08:46:49.536258.536258 cuda_h.py:19] end gate cost 0.0006699562072753906 seconds
DEBUG 01-13 08:46:49.537611.537611 cuda_h.py:10] start experts_map_get
DEBUG 01-13 08:46:49.537210.537210 lmp.py:1611] 
DEBUG 01-13 08:46:49.537210.537210 lmp.py:1611] Expert Token Distribution & Device Allocation:
DEBUG 01-13 08:46:49.537774.537774 lmp.py:1612]   Total experts: 64
DEBUG 01-13 08:46:49.537185.537185 lmp.py:1613]   CPU experts: 32 (50%)
DEBUG 01-13 08:46:49.537020.537020 lmp.py:1614]   GPU experts: 32 (50%)
DEBUG 01-13 08:46:49.537425.537425 lmp.py:1615] 
DEBUG 01-13 08:46:49.537425.537425 lmp.py:1615]   Expert ID | Tokens | Device
DEBUG 01-13 08:46:49.537591.537591 lmp.py:1616]   -----------------------------------
DEBUG 01-13 08:46:49.537479.537479 lmp.py:1622]   Expert  4 |     11 | CPU
DEBUG 01-13 08:46:49.537645.537645 lmp.py:1622]   Expert 28 |     28 | CPU
DEBUG 01-13 08:46:49.537619.537619 lmp.py:1622]   Expert  7 |     44 | CPU
DEBUG 01-13 08:46:49.537355.537355 lmp.py:1622]   Expert 52 |     60 | CPU
DEBUG 01-13 08:46:49.537852.537852 lmp.py:1622]   Expert 53 |     61 | CPU
DEBUG 01-13 08:46:49.537495.537495 lmp.py:1622]   Expert 43 |     72 | CPU
DEBUG 01-13 08:46:49.537184.537184 lmp.py:1622]   Expert 49 |     88 | CPU
DEBUG 01-13 08:46:49.537635.537635 lmp.py:1622]   Expert 12 |     90 | CPU
DEBUG 01-13 08:46:49.537086.537086 lmp.py:1622]   Expert 24 |     97 | CPU
DEBUG 01-13 08:46:49.537537.537537 lmp.py:1622]   Expert 50 |     97 | CPU
DEBUG 01-13 08:46:49.537419.537419 lmp.py:1622]   Expert 47 |    101 | CPU
DEBUG 01-13 08:46:49.537585.537585 lmp.py:1622]   Expert 33 |    103 | CPU
DEBUG 01-13 08:46:49.537751.537751 lmp.py:1622]   Expert 15 |    109 | CPU
DEBUG 01-13 08:46:49.537440.537440 lmp.py:1622]   Expert  2 |    111 | CPU
DEBUG 01-13 08:46:49.537414.537414 lmp.py:1622]   Expert 39 |    116 | CPU
DEBUG 01-13 08:46:49.537627.537627 lmp.py:1622]   Expert 60 |    117 | CPU
DEBUG 01-13 08:46:49.537078.537078 lmp.py:1622]   Expert 36 |    122 | CPU
DEBUG 01-13 08:46:49.537767.537767 lmp.py:1622]   Expert  6 |    123 | CPU
DEBUG 01-13 08:46:49.537979.537979 lmp.py:1622]   Expert 61 |    124 | CPU
DEBUG 01-13 08:46:49.537430.537430 lmp.py:1622]   Expert 25 |    126 | CPU
DEBUG 01-13 08:46:49.537643.537643 lmp.py:1622]   Expert  3 |    147 | CPU
DEBUG 01-13 08:46:49.537855.537855 lmp.py:1622]   Expert 27 |    149 | CPU
DEBUG 01-13 08:46:49.537021.537021 lmp.py:1622]   Expert 59 |    152 | CPU
DEBUG 01-13 08:46:49.537949.537949 lmp.py:1622]   Expert 31 |    154 | CPU
DEBUG 01-13 08:46:49.537877.537877 lmp.py:1622]   Expert 40 |    155 | CPU
DEBUG 01-13 08:46:49.537566.537566 lmp.py:1622]   Expert  8 |    156 | CPU
DEBUG 01-13 08:46:49.537017.537017 lmp.py:1622]   Expert 30 |    157 | CPU
DEBUG 01-13 08:46:49.537468.537468 lmp.py:1622]   Expert 58 |    157 | CPU
DEBUG 01-13 08:46:49.537442.537442 lmp.py:1622]   Expert 57 |    160 | CPU
DEBUG 01-13 08:46:49.537654.537654 lmp.py:1622]   Expert 10 |    161 | CPU
DEBUG 01-13 08:46:49.537867.537867 lmp.py:1622]   Expert 32 |    162 | CPU
DEBUG 01-13 08:46:49.537602.537602 lmp.py:1622]   Expert 41 |    162 | CPU
DEBUG 01-13 08:46:49.537053.537053 lmp.py:1622]   Expert 38 |    163 | GPU
DEBUG 01-13 08:46:49.538266.538266 lmp.py:1622]   Expert 14 |    164 | GPU
DEBUG 01-13 08:46:49.538193.538193 lmp.py:1622]   Expert 46 |    165 | GPU
DEBUG 01-13 08:46:49.538121.538121 lmp.py:1622]   Expert 37 |    167 | GPU
DEBUG 01-13 08:46:49.538810.538810 lmp.py:1622]   Expert 54 |    171 | GPU
DEBUG 01-13 08:46:49.538261.538261 lmp.py:1622]   Expert 11 |    172 | GPU
DEBUG 01-13 08:46:49.538474.538474 lmp.py:1622]   Expert 42 |    173 | GPU
DEBUG 01-13 08:46:49.538448.538448 lmp.py:1622]   Expert 19 |    175 | GPU
DEBUG 01-13 08:46:49.538422.538422 lmp.py:1622]   Expert 34 |    182 | GPU
DEBUG 01-13 08:46:49.538634.538634 lmp.py:1622]   Expert  0 |    190 | GPU
DEBUG 01-13 08:46:49.538608.538608 lmp.py:1622]   Expert 22 |    195 | GPU
DEBUG 01-13 08:46:49.538821.538821 lmp.py:1622]   Expert 18 |    198 | GPU
DEBUG 01-13 08:46:49.538556.538556 lmp.py:1622]   Expert  1 |    199 | GPU
DEBUG 01-13 08:46:49.538007.538007 lmp.py:1622]   Expert 44 |    204 | GPU
DEBUG 01-13 08:46:49.538935.538935 lmp.py:1622]   Expert 26 |    207 | GPU
DEBUG 01-13 08:46:49.538101.538101 lmp.py:1622]   Expert 51 |    207 | GPU
DEBUG 01-13 08:46:49.538267.538267 lmp.py:1622]   Expert 56 |    207 | GPU
DEBUG 01-13 08:46:49.538241.538241 lmp.py:1622]   Expert 20 |    220 | GPU
DEBUG 01-13 08:46:49.538454.538454 lmp.py:1622]   Expert 29 |    223 | GPU
DEBUG 01-13 08:46:49.538666.538666 lmp.py:1622]   Expert 48 |    235 | GPU
DEBUG 01-13 08:46:49.538402.538402 lmp.py:1622]   Expert 45 |    241 | GPU
DEBUG 01-13 08:46:49.538614.538614 lmp.py:1622]   Expert 21 |    245 | GPU
DEBUG 01-13 08:46:49.538350.538350 lmp.py:1622]   Expert 16 |    252 | GPU
DEBUG 01-13 08:46:49.538324.538324 lmp.py:1622]   Expert 35 |    252 | GPU
DEBUG 01-13 08:46:49.538298.538298 lmp.py:1622]   Expert 55 |    262 | GPU
DEBUG 01-13 08:46:49.538034.538034 lmp.py:1622]   Expert  5 |    293 | GPU
DEBUG 01-13 08:46:49.538246.538246 lmp.py:1622]   Expert 23 |    377 | GPU
DEBUG 01-13 08:46:49.538982.538982 lmp.py:1622]   Expert 13 |    390 | GPU
DEBUG 01-13 08:46:49.538956.538956 lmp.py:1622]   Expert 17 |    438 | GPU
DEBUG 01-13 08:46:49.538645.538645 lmp.py:1622]   Expert 63 |    441 | GPU
DEBUG 01-13 08:46:49.538573.538573 lmp.py:1622]   Expert  9 |    442 | GPU
DEBUG 01-13 08:46:49.538024.538024 lmp.py:1622]   Expert 62 |   1166 | GPU
DEBUG 01-13 08:46:49.538667.538667 lmp.py:1623] 
DEBUG 01-13 08:46:49.538667.538667 lmp.py:1623]   CPU total tokens: 3672 (29.9%)
DEBUG 01-13 08:46:49.538310.538310 lmp.py:1624]   GPU total tokens: 8616 (70.1%)
DEBUG 01-13 08:46:49.538767.538767 cuda_h.py:19] end experts_map_get cost 0.0014925003051757812 seconds
DEBUG 01-13 08:46:49.538041.538041 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-13 08:46:49.538413.538413 lmp.py:1632] 
DEBUG 01-13 08:46:49.538413.538413 lmp.py:1632]   Computing 32 experts on CPU MP...
DEBUG 01-13 08:46:49.538719.538719 cuda_h.py:19] end cpu_experts_submit cost 5.0067901611328125e-05 seconds
DEBUG 01-13 08:46:49.538985.538985 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-13 08:46:49.538483.538483 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-13 08:46:49.538164.538164 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-13 08:46:49.540993.540993 cuda_h.py:19] end allocate_cuda_memory cost 0.001384735107421875 seconds
DEBUG 01-13 08:46:49.540710.540710 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-13 08:46:49.540420.540420 sllm_store_c.py:27] get device uuid map
DEBUG 01-13 08:46:49.540382.540382 sllm_store_c.py:29] call client load into gpu
DEBUG 01-13 08:46:49.540416.540416 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 3c74dda2-704a-4af2-af26-a5df45f23823
DEBUG 01-13 08:46:49.540157.540157 client.py:106] call stub.LoadModelAsync
INFO 01-13 08:46:49.542550.542550 client.py:127] Model loaded
DEBUG 01-13 08:46:49.542375.542375 cuda_h.py:10] start restore2model
DEBUG 01-13 08:46:49.543106.543106 cuda_h.py:19] end restore2model cost 0.0007836818695068359 seconds
DEBUG 01-13 08:46:49.543505.543505 cuda_h.py:19] end sllm_worker_task cost 0.011347532272338867 seconds
INFO 01-13 08:46:49.543665.543665 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 3c74dda2-704a-4af2-af26-a5df45f23823
DEBUG 01-13 08:46:49.543607.543607 cuda_h.py:19] end load_into_gpu_async cost 0.0032248497009277344 seconds
DEBUG 01-13 08:46:49.543787.543787 cuda_h.py:10] start restore_tensors2
DEBUG 01-13 08:46:49.544656.544656 cuda_h.py:19] end restore_tensors2 cost 0.00040340423583984375 seconds
DEBUG 01-13 08:46:49.544492.544492 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.005391597747802734 seconds
DEBUG 01-13 08:46:49.544354.544354 cuda_h.py:10] start restore2model
DEBUG 01-13 08:46:49.544871.544871 mlpmodule.py:785]  experts func einsum cost 0.07173442840576172 s
DEBUG 01-13 08:46:49.545742.545742 cuda_h.py:19] end experts_func_gpu_einsum_mp cost 0.07311153411865234 seconds
DEBUG 01-13 08:46:49.545897.545897 cuda_h.py:10] start experts_func_gpu_einsum_mp
DEBUG 01-13 08:46:49.546977.546977 cuda_h.py:19] end restore2model cost 0.0025382041931152344 seconds
DEBUG 01-13 08:46:49.546012.546012 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.008109569549560547 seconds
DEBUG 01-13 08:46:49.546615.546615 cuda_h.py:10] start gpu_sexperts
DEBUG 01-13 08:46:49.547817.547817 cuda_h.py:19] end gpu_sexperts cost 0.0002608299255371094 seconds
DEBUG 01-13 08:46:49.547700.547700 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-13 08:46:49.547900.547900 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 1.3828277587890625e-05 seconds
DEBUG 01-13 08:46:49.547119.547119 cuda_h.py:10] start wait_experts
INFO 01-13 08:46:49.547292.547292 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 3c74dda2-704a-4af2-af26-a5df45f23823
DEBUG 01-13 08:46:49.555317.555317 mlpmodule.py:1006] group tensors cost 0.008726119995117188 s
DEBUG 01-13 08:46:49.558534.558534 mlpmodule.py:1044] pad cost 0.0021271705627441406 s
DEBUG 01-13 08:46:49.558942.558942 mlpmodule.py:1050] create cpu tensor cost 6.961822509765625e-05 s
DEBUG 01-13 08:46:49.558944.558944 mlpmodule.py:1055] move to cpu cost 3.743171691894531e-05 s
DEBUG 01-13 08:46:49.566182.566182 mlpmodule.py:1069] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-13 08:46:49.566361.566361 mlpmodule.py:1070] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-13 08:46:49.566385.566385 mlpmodule.py:1075] group_w3 first element: 0.00457763671875
WARNING 01-13 08:46:49.566555.566555 mlpmodule.py:1085] start einsum2
DEBUG 01-13 08:46:49.578143.578143 mlpmodule.py:1095] group einsum cost 0.020281553268432617 s
DEBUG 01-13 08:46:49.579618.579618 mlpmodule.py:1103] cpy2cputensor cost 0.0007054805755615234 s
INFO 01-13 08:46:49.594062.594062 client.py:127] Model loaded
DEBUG 01-13 08:46:49.594829.594829 cuda_h.py:19] end wait_experts cost 0.046866416931152344 seconds
DEBUG 01-13 08:46:49.594399.594399 cuda_h.py:10] start gpu_experts
DEBUG 01-13 08:46:49.594821.594821 mlpmodule.py:559] gpu group tensors cost 0.0006334781646728516 s
DEBUG 01-13 08:46:49.596246.596246 mlpmodule.py:592] gpu pad cost 0.001924753189086914 s
DEBUG 01-13 08:46:49.597248.597248 mlpmodule.py:598] start_w1
DEBUG 01-13 08:46:49.597572.597572 mlpmodule.py:602] start_w3
DEBUG 01-13 08:46:49.597406.597406 mlpmodule.py:608] start_w2
DEBUG 01-13 08:46:49.598829.598829 mlpmodule.py:611] gpu group einsum cost 0.001127481460571289 s
DEBUG 01-13 08:46:49.600171.600171 mlpmodule.py:683] gpu experts func einsum cost 0.005952358245849609 s
DEBUG 01-13 08:46:49.600652.600652 cuda_h.py:19] end gpu_experts cost 0.0061283111572265625 seconds
DEBUG 01-13 08:46:49.600084.600084 cuda_h.py:10] start cpu_thread_manager_mp_wait
DEBUG 01-13 08:46:49.600702.600702 cuda_h.py:19] end cpu_thread_manager_mp_wait cost 3.910064697265625e-05 seconds
DEBUG 01-13 08:46:49.600764.600764 cuda_h.py:19] end layer_moe_generate_mp_l_18 cost 0.06428027153015137 seconds
DEBUG 01-13 08:46:49.600215.600215 lmp.py:1550] -------------------------------- end prefill layer 17 --------------------------------
DEBUG 01-13 08:46:49.600323.600323 lmp.py:1493] -------------------------------- start prefill layer 18 --------------------------------
DEBUG 01-13 08:46:49.600549.600549 cuda_h.py:10] start start_load_qkvogn_s_weight_l_19
DEBUG 01-13 08:46:49.600636.600636 cuda_h.py:10] start start_load_qkvogn_s_weight_l_19
DEBUG 01-13 08:46:49.600711.600711 cuda_h.py:19] end start_load_qkvogn_s_weight_l_19 cost 3.0994415283203125e-05 seconds
DEBUG 01-13 08:46:49.600745.600745 cuda_h.py:19] end start_load_qkvogn_s_weight_l_19 cost 5.984306335449219e-05 seconds
DEBUG 01-13 08:46:49.600103.600103 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-13 08:46:49.601767.601767 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-13 08:46:49.601605.601605 cuda_h.py:10] start sllm_worker_task
DEBUG 01-13 08:46:49.601416.601416 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-13 08:46:49.601472.601472 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-13 08:46:49.601144.601144 cuda_h.py:19] end allocate_cuda_memory cost 0.0002224445343017578 seconds
DEBUG 01-13 08:46:49.601578.601578 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-13 08:46:49.601030.601030 sllm_store_c.py:27] get device uuid map
DEBUG 01-13 08:46:49.601681.601681 sllm_store_c.py:29] call client load into gpu
DEBUG 01-13 08:46:49.601497.601497 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, bc3daabf-422c-4a8d-b8b4-199d9b2cf663
DEBUG 01-13 08:46:49.602051.602051 client.py:106] call stub.LoadModelAsync
DEBUG 01-13 08:46:49.602077.602077 cuda_h.py:10] start self_attn
INFO 01-13 08:46:49.603295.603295 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, bc3daabf-422c-4a8d-b8b4-199d9b2cf663
DEBUG 01-13 08:46:49.603695.603695 cuda_h.py:19] end load_into_gpu_async cost 0.0018563270568847656 seconds
DEBUG 01-13 08:46:49.603703.603703 cuda_h.py:10] start restore_tensors2
DEBUG 01-13 08:46:49.603317.603317 cuda_h.py:19] end restore_tensors2 cost 8.225440979003906e-05 seconds
DEBUG 01-13 08:46:49.603994.603994 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.002560138702392578 seconds
INFO 01-13 08:46:49.603313.603313 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, bc3daabf-422c-4a8d-b8b4-199d9b2cf663
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-13 08:46:49.605871.605871 cuda_h.py:19] end self_attn cost 0.0030717849731445312 seconds
DEBUG 01-13 08:46:49.605531.605531 cuda_h.py:19] end iln_self_attn_paln cost 0.00464177131652832 seconds
DEBUG 01-13 08:46:49.605100.605100 mlpmodule.py:785]  experts func einsum cost 0.05903792381286621 s
DEBUG 01-13 08:46:49.605228.605228 cuda_h.py:10] start layer_moe_generate_mp_l_19
DEBUG 01-13 08:46:49.605130.605130 cuda_h.py:10] start gate
DEBUG 01-13 08:46:49.605173.605173 cuda_h.py:19] end experts_func_gpu_einsum_mp cost 0.06001639366149902 seconds
DEBUG 01-13 08:46:49.606867.606867 cuda_h.py:19] end gate cost 0.0006165504455566406 seconds
DEBUG 01-13 08:46:49.606789.606789 cuda_h.py:10] start experts_map_get
DEBUG 01-13 08:46:49.606461.606461 lmp.py:1611] 
DEBUG 01-13 08:46:49.606461.606461 lmp.py:1611] Expert Token Distribution & Device Allocation:
DEBUG 01-13 08:46:49.606309.606309 lmp.py:1612]   Total experts: 64
DEBUG 01-13 08:46:49.606767.606767 lmp.py:1613]   CPU experts: 32 (50%)
DEBUG 01-13 08:46:49.606410.606410 lmp.py:1614]   GPU experts: 32 (50%)
DEBUG 01-13 08:46:49.606907.606907 lmp.py:1615] 
DEBUG 01-13 08:46:49.606907.606907 lmp.py:1615]   Expert ID | Tokens | Device
DEBUG 01-13 08:46:49.606120.606120 lmp.py:1616]   -----------------------------------
DEBUG 01-13 08:46:49.606339.606339 lmp.py:1622]   Expert 32 |     36 | CPU
DEBUG 01-13 08:46:49.606551.606551 lmp.py:1622]   Expert 30 |     49 | CPU
DEBUG 01-13 08:46:49.606287.606287 lmp.py:1622]   Expert  5 |     50 | CPU
DEBUG 01-13 08:46:49.606069.606069 lmp.py:1622]   Expert 46 |     69 | CPU
DEBUG 01-13 08:46:49.606805.606805 lmp.py:1622]   Expert  8 |     83 | CPU
DEBUG 01-13 08:46:49.606586.606586 lmp.py:1622]   Expert 40 |     83 | CPU
DEBUG 01-13 08:46:49.606845.606845 lmp.py:1622]   Expert 12 |     97 | CPU
DEBUG 01-13 08:46:49.606581.606581 lmp.py:1622]   Expert 27 |    103 | CPU
DEBUG 01-13 08:46:49.606363.606363 lmp.py:1622]   Expert 60 |    108 | CPU
DEBUG 01-13 08:46:49.606337.606337 lmp.py:1622]   Expert 17 |    111 | CPU
DEBUG 01-13 08:46:49.607549.607549 lmp.py:1622]   Expert 58 |    111 | CPU
DEBUG 01-13 08:46:49.607715.607715 lmp.py:1622]   Expert  3 |    113 | CPU
DEBUG 01-13 08:46:49.607974.607974 lmp.py:1622]   Expert 21 |    119 | CPU
DEBUG 01-13 08:46:49.607756.607756 lmp.py:1622]   Expert 28 |    120 | CPU
DEBUG 01-13 08:46:49.607300.607300 lmp.py:1622]   Expert 29 |    125 | CPU
DEBUG 01-13 08:46:49.607082.607082 lmp.py:1622]   Expert 25 |    126 | CPU
DEBUG 01-13 08:46:49.607864.607864 lmp.py:1622]   Expert 35 |    134 | CPU
DEBUG 01-13 08:46:49.607407.607407 lmp.py:1622]   Expert 41 |    135 | CPU
DEBUG 01-13 08:46:49.607189.607189 lmp.py:1622]   Expert 19 |    136 | CPU
DEBUG 01-13 08:46:49.607210.607210 lmp.py:1622]   Expert 54 |    136 | CPU
DEBUG 01-13 08:46:49.607991.607991 lmp.py:1622]   Expert  0 |    140 | CPU
DEBUG 01-13 08:46:49.607773.607773 lmp.py:1622]   Expert 52 |    140 | CPU
DEBUG 01-13 08:46:49.607032.607032 lmp.py:1622]   Expert 37 |    146 | CPU
DEBUG 01-13 08:46:49.607006.607006 lmp.py:1622]   Expert 48 |    149 | CPU
DEBUG 01-13 08:46:49.607219.607219 lmp.py:1622]   Expert  6 |    150 | CPU
DEBUG 01-13 08:46:49.607954.607954 lmp.py:1622]   Expert 56 |    153 | CPU
DEBUG 01-13 08:46:49.607690.607690 lmp.py:1622]   Expert 53 |    159 | CPU
DEBUG 01-13 08:46:49.607618.607618 lmp.py:1622]   Expert 63 |    162 | CPU
DEBUG 01-13 08:46:49.607115.607115 lmp.py:1622]   Expert 36 |    165 | CPU
DEBUG 01-13 08:46:49.607851.607851 lmp.py:1622]   Expert 59 |    169 | CPU
DEBUG 01-13 08:46:49.607586.607586 lmp.py:1622]   Expert  9 |    179 | CPU
DEBUG 01-13 08:46:49.607322.607322 lmp.py:1622]   Expert  1 |    189 | CPU
DEBUG 01-13 08:46:49.607534.607534 lmp.py:1622]   Expert 39 |    192 | GPU
DEBUG 01-13 08:46:49.607031.607031 lmp.py:1622]   Expert 43 |    197 | GPU
DEBUG 01-13 08:46:49.607244.607244 lmp.py:1622]   Expert 20 |    198 | GPU
DEBUG 01-13 08:46:49.607741.607741 lmp.py:1622]   Expert 42 |    201 | GPU
DEBUG 01-13 08:46:49.607715.607715 lmp.py:1622]   Expert 61 |    201 | GPU
DEBUG 01-13 08:46:49.607881.607881 lmp.py:1622]   Expert 11 |    202 | GPU
DEBUG 01-13 08:46:49.607571.607571 lmp.py:1622]   Expert 34 |    205 | GPU
DEBUG 01-13 08:46:49.607260.607260 lmp.py:1622]   Expert  7 |    208 | GPU
DEBUG 01-13 08:46:49.607426.607426 lmp.py:1622]   Expert 47 |    210 | GPU
DEBUG 01-13 08:46:49.607638.607638 lmp.py:1622]   Expert 55 |    214 | GPU
DEBUG 01-13 08:46:49.607851.607851 lmp.py:1622]   Expert 13 |    219 | GPU
DEBUG 01-13 08:46:49.607587.607587 lmp.py:1622]   Expert 16 |    221 | GPU
DEBUG 01-13 08:46:49.607322.607322 lmp.py:1622]   Expert 57 |    222 | GPU
DEBUG 01-13 08:46:49.607058.607058 lmp.py:1622]   Expert  4 |    229 | GPU
DEBUG 01-13 08:46:49.607032.607032 lmp.py:1622]   Expert 18 |    235 | GPU
DEBUG 01-13 08:46:49.607768.607768 lmp.py:1622]   Expert 15 |    236 | GPU
DEBUG 01-13 08:46:49.607980.607980 lmp.py:1622]   Expert 45 |    237 | GPU
DEBUG 01-13 08:46:49.607192.607192 lmp.py:1622]   Expert 50 |    243 | GPU
DEBUG 01-13 08:46:49.607928.607928 lmp.py:1622]   Expert 22 |    248 | GPU
DEBUG 01-13 08:46:49.607617.607617 lmp.py:1622]   Expert 33 |    249 | GPU
DEBUG 01-13 08:46:49.607545.607545 lmp.py:1622]   Expert 51 |    256 | GPU
DEBUG 01-13 08:46:49.607234.607234 lmp.py:1622]   Expert 31 |    257 | GPU
DEBUG 01-13 08:46:49.607162.607162 lmp.py:1622]   Expert 49 |    268 | GPU
DEBUG 01-13 08:46:49.607136.607136 lmp.py:1622]   Expert 38 |    273 | GPU
DEBUG 01-13 08:46:49.607872.607872 lmp.py:1622]   Expert 26 |    276 | GPU
DEBUG 01-13 08:46:49.607369.607369 lmp.py:1622]   Expert 10 |    284 | GPU
DEBUG 01-13 08:46:49.607105.607105 lmp.py:1622]   Expert 44 |    298 | GPU
DEBUG 01-13 08:46:49.607363.607363 lmp.py:1622]   Expert 24 |    301 | GPU
DEBUG 01-13 08:46:49.607337.607337 lmp.py:1622]   Expert  2 |    312 | GPU
DEBUG 01-13 08:46:49.607835.607835 lmp.py:1622]   Expert 14 |    317 | GPU
DEBUG 01-13 08:46:49.607570.607570 lmp.py:1622]   Expert 23 |    456 | GPU
DEBUG 01-13 08:46:49.607067.607067 lmp.py:1622]   Expert 62 |    678 | GPU
DEBUG 01-13 08:46:49.607995.607995 lmp.py:1623] 
DEBUG 01-13 08:46:49.607995.607995 lmp.py:1623]   CPU total tokens: 3945 (32.1%)
DEBUG 01-13 08:46:49.607400.607400 lmp.py:1624]   GPU total tokens: 8343 (67.9%)
DEBUG 01-13 08:46:49.607857.607857 cuda_h.py:19] end experts_map_get cost 0.0014286041259765625 seconds
DEBUG 01-13 08:46:49.607416.607416 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-13 08:46:49.607741.607741 lmp.py:1632] 
DEBUG 01-13 08:46:49.607741.607741 lmp.py:1632]   Computing 32 experts on CPU MP...
DEBUG 01-13 08:46:49.608710.608710 cuda_h.py:19] end cpu_experts_submit cost 4.744529724121094e-05 seconds
DEBUG 01-13 08:46:49.608519.608519 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-13 08:46:49.608633.608633 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-13 08:46:49.608816.608816 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-13 08:46:49.610961.610961 cuda_h.py:19] end allocate_cuda_memory cost 0.0017235279083251953 seconds
DEBUG 01-13 08:46:49.610063.610063 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-13 08:46:49.610296.610296 sllm_store_c.py:27] get device uuid map
DEBUG 01-13 08:46:49.610820.610820 sllm_store_c.py:29] call client load into gpu
DEBUG 01-13 08:46:49.610139.610139 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 59a3d5ee-623a-403d-8ae9-c4c24762970a
DEBUG 01-13 08:46:49.610774.610774 client.py:106] call stub.LoadModelAsync
DEBUG 01-13 08:46:49.611613.611613 cuda_h.py:10] start experts_func_gpu_einsum_mp
INFO 01-13 08:46:49.611744.611744 client.py:127] Model loaded
DEBUG 01-13 08:46:49.611336.611336 cuda_h.py:10] start restore2model
DEBUG 01-13 08:46:49.612304.612304 cuda_h.py:19] end restore2model cost 0.0005807876586914062 seconds
DEBUG 01-13 08:46:49.612029.612029 cuda_h.py:19] end sllm_worker_task cost 0.01137399673461914 seconds
INFO 01-13 08:46:49.613417.613417 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 59a3d5ee-623a-403d-8ae9-c4c24762970a
DEBUG 01-13 08:46:49.613028.613028 cuda_h.py:19] end load_into_gpu_async cost 0.0032758712768554688 seconds
DEBUG 01-13 08:46:49.613923.613923 cuda_h.py:10] start restore_tensors2
DEBUG 01-13 08:46:49.613248.613248 cuda_h.py:19] end restore_tensors2 cost 0.00038886070251464844 seconds
DEBUG 01-13 08:46:49.613800.613800 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.005751848220825195 seconds
DEBUG 01-13 08:46:49.613708.613708 cuda_h.py:10] start restore2model
DEBUG 01-13 08:46:49.616591.616591 cuda_h.py:19] end restore2model cost 0.0025870800018310547 seconds
DEBUG 01-13 08:46:49.616341.616341 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.008520841598510742 seconds
DEBUG 01-13 08:46:49.616183.616183 cuda_h.py:10] start gpu_sexperts
DEBUG 01-13 08:46:49.616577.616577 cuda_h.py:19] end gpu_sexperts cost 0.00026035308837890625 seconds
DEBUG 01-13 08:46:49.616453.616453 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-13 08:46:49.617368.617368 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 1.430511474609375e-05 seconds
DEBUG 01-13 08:46:49.617826.617826 cuda_h.py:10] start wait_experts
INFO 01-13 08:46:49.617999.617999 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 59a3d5ee-623a-403d-8ae9-c4c24762970a
DEBUG 01-13 08:46:49.618783.618783 mlpmodule.py:1006] group tensors cost 0.005823850631713867 s
DEBUG 01-13 08:46:49.621947.621947 mlpmodule.py:1044] pad cost 0.002693653106689453 s
DEBUG 01-13 08:46:49.621084.621084 mlpmodule.py:1050] create cpu tensor cost 6.413459777832031e-05 s
DEBUG 01-13 08:46:49.621399.621399 mlpmodule.py:1055] move to cpu cost 4.410743713378906e-05 s
DEBUG 01-13 08:46:49.629066.629066 mlpmodule.py:1069] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-13 08:46:49.629226.629226 mlpmodule.py:1070] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-13 08:46:49.630257.630257 mlpmodule.py:1075] group_w3 first element: 0.0024871826171875
WARNING 01-13 08:46:49.630203.630203 mlpmodule.py:1085] start einsum2
DEBUG 01-13 08:46:49.643727.643727 mlpmodule.py:1095] group einsum cost 0.021384239196777344 s
DEBUG 01-13 08:46:49.644363.644363 mlpmodule.py:1103] cpy2cputensor cost 0.0007381439208984375 s
INFO 01-13 08:46:49.664439.664439 client.py:127] Model loaded
DEBUG 01-13 08:46:49.664378.664378 cuda_h.py:19] end wait_experts cost 0.0472874641418457 seconds
DEBUG 01-13 08:46:49.664326.664326 cuda_h.py:10] start gpu_experts
DEBUG 01-13 08:46:49.665920.665920 mlpmodule.py:559] gpu group tensors cost 0.0006208419799804688 s
DEBUG 01-13 08:46:49.666973.666973 mlpmodule.py:592] gpu pad cost 0.0015170574188232422 s
DEBUG 01-13 08:46:49.666584.666584 mlpmodule.py:598] start_w1
DEBUG 01-13 08:46:49.667457.667457 mlpmodule.py:602] start_w3
DEBUG 01-13 08:46:49.667801.667801 mlpmodule.py:608] start_w2
DEBUG 01-13 08:46:49.667442.667442 mlpmodule.py:611] gpu group einsum cost 0.0007014274597167969 s
DEBUG 01-13 08:46:49.668317.668317 mlpmodule.py:785]  experts func einsum cost 0.05620718002319336 s
DEBUG 01-13 08:46:49.668267.668267 cuda_h.py:19] end experts_func_gpu_einsum_mp cost 0.05717325210571289 seconds
DEBUG 01-13 08:46:49.669321.669321 mlpmodule.py:683] gpu experts func einsum cost 0.0052721500396728516 s
DEBUG 01-13 08:46:49.669119.669119 cuda_h.py:19] end gpu_experts cost 0.0054395198822021484 seconds
DEBUG 01-13 08:46:49.669682.669682 cuda_h.py:10] start cpu_thread_manager_mp_wait
DEBUG 01-13 08:46:49.669963.669963 cuda_h.py:19] end cpu_thread_manager_mp_wait cost 3.6716461181640625e-05 seconds
DEBUG 01-13 08:46:49.670502.670502 cuda_h.py:19] end layer_moe_generate_mp_l_19 cost 0.06432199478149414 seconds
DEBUG 01-13 08:46:49.670649.670649 lmp.py:1550] -------------------------------- end prefill layer 18 --------------------------------
DEBUG 01-13 08:46:49.670518.670518 lmp.py:1493] -------------------------------- start prefill layer 19 --------------------------------
DEBUG 01-13 08:46:49.670983.670983 cuda_h.py:10] start start_load_qkvogn_s_weight_l_20
DEBUG 01-13 08:46:49.670831.670831 cuda_h.py:10] start start_load_qkvogn_s_weight_l_20
DEBUG 01-13 08:46:49.670429.670429 cuda_h.py:19] end start_load_qkvogn_s_weight_l_20 cost 2.9325485229492188e-05 seconds
DEBUG 01-13 08:46:49.670086.670086 cuda_h.py:19] end start_load_qkvogn_s_weight_l_20 cost 6.008148193359375e-05 seconds
DEBUG 01-13 08:46:49.670067.670067 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-13 08:46:49.670877.670877 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-13 08:46:49.670463.670463 cuda_h.py:10] start sllm_worker_task
DEBUG 01-13 08:46:49.670314.670314 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-13 08:46:49.670104.670104 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-13 08:46:49.671082.671082 cuda_h.py:19] end allocate_cuda_memory cost 0.0002999305725097656 seconds
DEBUG 01-13 08:46:49.671628.671628 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-13 08:46:49.671490.671490 sllm_store_c.py:27] get device uuid map
DEBUG 01-13 08:46:49.671312.671312 sllm_store_c.py:29] call client load into gpu
DEBUG 01-13 08:46:49.671823.671823 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 4e67588a-d481-406a-9ce6-97c9f9bf9508
DEBUG 01-13 08:46:49.671469.671469 client.py:106] call stub.LoadModelAsync
DEBUG 01-13 08:46:49.671834.671834 cuda_h.py:10] start self_attn
INFO 01-13 08:46:49.672709.672709 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 4e67588a-d481-406a-9ce6-97c9f9bf9508
DEBUG 01-13 08:46:49.672122.672122 cuda_h.py:19] end load_into_gpu_async cost 0.0016582012176513672 seconds
DEBUG 01-13 08:46:49.672262.672262 cuda_h.py:10] start restore_tensors2
DEBUG 01-13 08:46:49.673735.673735 cuda_h.py:19] end restore_tensors2 cost 7.104873657226562e-05 seconds
DEBUG 01-13 08:46:49.673544.673544 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0023102760314941406 seconds
INFO 01-13 08:46:49.673758.673758 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 4e67588a-d481-406a-9ce6-97c9f9bf9508
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-13 08:46:49.674385.674385 cuda_h.py:19] end self_attn cost 0.002942800521850586 seconds
DEBUG 01-13 08:46:49.674568.674568 cuda_h.py:19] end iln_self_attn_paln cost 0.004446506500244141 seconds
DEBUG 01-13 08:46:49.675457.675457 cuda_h.py:10] start layer_moe_generate_mp_l_20
DEBUG 01-13 08:46:49.675650.675650 cuda_h.py:10] start gate
DEBUG 01-13 08:46:49.675852.675852 cuda_h.py:19] end gate cost 0.0006394386291503906 seconds
DEBUG 01-13 08:46:49.675920.675920 cuda_h.py:10] start experts_map_get
DEBUG 01-13 08:46:49.676778.676778 lmp.py:1611] 
DEBUG 01-13 08:46:49.676778.676778 lmp.py:1611] Expert Token Distribution & Device Allocation:
DEBUG 01-13 08:46:49.676772.676772 lmp.py:1612]   Total experts: 64
DEBUG 01-13 08:46:49.676614.676614 lmp.py:1613]   CPU experts: 32 (50%)
DEBUG 01-13 08:46:49.676880.676880 lmp.py:1614]   GPU experts: 32 (50%)
DEBUG 01-13 08:46:49.676761.676761 lmp.py:1615] 
DEBUG 01-13 08:46:49.676761.676761 lmp.py:1615]   Expert ID | Tokens | Device
DEBUG 01-13 08:46:49.676119.676119 lmp.py:1616]   -----------------------------------
DEBUG 01-13 08:46:49.676200.676200 lmp.py:1622]   Expert 44 |     33 | CPU
DEBUG 01-13 08:46:49.676035.676035 lmp.py:1622]   Expert  1 |     53 | CPU
DEBUG 01-13 08:46:49.676439.676439 lmp.py:1622]   Expert 28 |     62 | CPU
DEBUG 01-13 08:46:49.676844.676844 lmp.py:1622]   Expert 60 |     71 | CPU
DEBUG 01-13 08:46:49.676010.676010 lmp.py:1622]   Expert 48 |     74 | CPU
DEBUG 01-13 08:46:49.676176.676176 lmp.py:1622]   Expert 27 |     86 | CPU
DEBUG 01-13 08:46:49.676342.676342 lmp.py:1622]   Expert  0 |    104 | CPU
DEBUG 01-13 08:46:49.676999.676999 lmp.py:1622]   Expert 42 |    105 | CPU
DEBUG 01-13 08:46:49.676695.676695 lmp.py:1622]   Expert 30 |    111 | CPU
DEBUG 01-13 08:46:49.676861.676861 lmp.py:1622]   Expert 22 |    114 | CPU
DEBUG 01-13 08:46:49.676742.676742 lmp.py:1622]   Expert 59 |    116 | CPU
DEBUG 01-13 08:46:49.676816.676816 lmp.py:1622]   Expert 62 |    116 | CPU
DEBUG 01-13 08:46:49.676174.676174 lmp.py:1622]   Expert 58 |    117 | CPU
DEBUG 01-13 08:46:49.676294.676294 lmp.py:1622]   Expert 16 |    122 | CPU
DEBUG 01-13 08:46:49.676175.676175 lmp.py:1622]   Expert 12 |    129 | CPU
DEBUG 01-13 08:46:49.676534.676534 lmp.py:1622]   Expert  8 |    130 | CPU
DEBUG 01-13 08:46:49.676938.676938 lmp.py:1622]   Expert 50 |    139 | CPU
DEBUG 01-13 08:46:49.676820.676820 lmp.py:1622]   Expert 56 |    141 | CPU
DEBUG 01-13 08:46:49.676463.676463 lmp.py:1622]   Expert  5 |    143 | CPU
DEBUG 01-13 08:46:49.676344.676344 lmp.py:1622]   Expert 57 |    147 | CPU
DEBUG 01-13 08:46:49.676748.676748 lmp.py:1622]   Expert 15 |    152 | CPU
DEBUG 01-13 08:46:49.676153.676153 lmp.py:1622]   Expert 26 |    155 | CPU
DEBUG 01-13 08:46:49.676227.676227 lmp.py:1622]   Expert 55 |    156 | CPU
DEBUG 01-13 08:46:49.676346.676346 lmp.py:1622]   Expert 47 |    157 | CPU
DEBUG 01-13 08:46:49.676943.676943 lmp.py:1622]   Expert 32 |    160 | CPU
DEBUG 01-13 08:46:49.676301.676301 lmp.py:1622]   Expert 24 |    161 | CPU
DEBUG 01-13 08:46:49.676375.676375 lmp.py:1622]   Expert 52 |    165 | CPU
DEBUG 01-13 08:46:49.676508.676508 lmp.py:1622]   Expert 13 |    166 | CPU
DEBUG 01-13 08:46:49.676959.676959 lmp.py:1622]   Expert 34 |    166 | CPU
DEBUG 01-13 08:46:49.676648.676648 lmp.py:1622]   Expert  2 |    168 | CPU
DEBUG 01-13 08:46:49.676861.676861 lmp.py:1622]   Expert 18 |    170 | CPU
DEBUG 01-13 08:46:49.676073.676073 lmp.py:1622]   Expert  6 |    171 | CPU
DEBUG 01-13 08:46:49.676001.676001 lmp.py:1622]   Expert 41 |    171 | GPU
DEBUG 01-13 08:46:49.676690.676690 lmp.py:1622]   Expert 40 |    172 | GPU
DEBUG 01-13 08:46:49.676664.676664 lmp.py:1622]   Expert 54 |    173 | GPU
DEBUG 01-13 08:46:49.676976.676976 lmp.py:1622]   Expert  3 |    176 | GPU
DEBUG 01-13 08:46:49.676904.676904 lmp.py:1622]   Expert 20 |    181 | GPU
DEBUG 01-13 08:46:49.676070.676070 lmp.py:1622]   Expert 46 |    184 | GPU
DEBUG 01-13 08:46:49.676521.676521 lmp.py:1622]   Expert 19 |    186 | GPU
DEBUG 01-13 08:46:49.676210.676210 lmp.py:1622]   Expert 37 |    191 | GPU
DEBUG 01-13 08:46:49.676423.676423 lmp.py:1622]   Expert 25 |    195 | GPU
DEBUG 01-13 08:46:49.677158.677158 lmp.py:1622]   Expert 31 |    199 | GPU
DEBUG 01-13 08:46:49.677609.677609 lmp.py:1622]   Expert 51 |    199 | GPU
DEBUG 01-13 08:46:49.677060.677060 lmp.py:1622]   Expert 43 |    200 | GPU
DEBUG 01-13 08:46:49.677511.677511 lmp.py:1622]   Expert 11 |    202 | GPU
DEBUG 01-13 08:46:49.677723.677723 lmp.py:1622]   Expert 17 |    203 | GPU
DEBUG 01-13 08:46:49.677936.677936 lmp.py:1622]   Expert 23 |    203 | GPU
DEBUG 01-13 08:46:49.677387.677387 lmp.py:1622]   Expert 35 |    212 | GPU
DEBUG 01-13 08:46:49.677361.677361 lmp.py:1622]   Expert 49 |    213 | GPU
DEBUG 01-13 08:46:49.677573.677573 lmp.py:1622]   Expert 39 |    222 | GPU
DEBUG 01-13 08:46:49.677263.677263 lmp.py:1622]   Expert 53 |    228 | GPU
DEBUG 01-13 08:46:49.677429.677429 lmp.py:1622]   Expert 10 |    236 | GPU
DEBUG 01-13 08:46:49.677356.677356 lmp.py:1622]   Expert 33 |    247 | GPU
DEBUG 01-13 08:46:49.677046.677046 lmp.py:1622]   Expert 38 |    268 | GPU
DEBUG 01-13 08:46:49.677689.677689 lmp.py:1622]   Expert 36 |    273 | GPU
DEBUG 01-13 08:46:49.677378.677378 lmp.py:1622]   Expert  4 |    303 | GPU
DEBUG 01-13 08:46:49.677829.677829 lmp.py:1622]   Expert 21 |    323 | GPU
DEBUG 01-13 08:46:49.677280.677280 lmp.py:1622]   Expert 14 |    342 | GPU
DEBUG 01-13 08:46:49.677492.677492 lmp.py:1622]   Expert 63 |    355 | GPU
DEBUG 01-13 08:46:49.677943.677943 lmp.py:1622]   Expert 45 |    370 | GPU
DEBUG 01-13 08:46:49.677394.677394 lmp.py:1622]   Expert 61 |    395 | GPU
DEBUG 01-13 08:46:49.677606.677606 lmp.py:1622]   Expert  9 |    397 | GPU
DEBUG 01-13 08:46:49.677580.677580 lmp.py:1622]   Expert 29 |    497 | GPU
DEBUG 01-13 08:46:49.677793.677793 lmp.py:1622]   Expert  7 |    512 | GPU
DEBUG 01-13 08:46:49.677959.677959 lmp.py:1623] 
DEBUG 01-13 08:46:49.677959.677959 lmp.py:1623]   CPU total tokens: 4060 (33.0%)
DEBUG 01-13 08:46:49.677079.677079 lmp.py:1624]   GPU total tokens: 8228 (67.0%)
DEBUG 01-13 08:46:49.677967.677967 cuda_h.py:19] end experts_map_get cost 0.0015857219696044922 seconds
DEBUG 01-13 08:46:49.677479.677479 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-13 08:46:49.677851.677851 lmp.py:1632] 
DEBUG 01-13 08:46:49.677851.677851 lmp.py:1632]   Computing 32 experts on CPU MP...
DEBUG 01-13 08:46:49.677548.677548 cuda_h.py:19] end cpu_experts_submit cost 4.7206878662109375e-05 seconds
DEBUG 01-13 08:46:49.677357.677357 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-13 08:46:49.677233.677233 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-13 08:46:49.677801.677801 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-13 08:46:49.679499.679499 cuda_h.py:19] end allocate_cuda_memory cost 0.0012531280517578125 seconds
DEBUG 01-13 08:46:49.679535.679535 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-13 08:46:49.679575.679575 sllm_store_c.py:27] get device uuid map
DEBUG 01-13 08:46:49.679908.679908 sllm_store_c.py:29] call client load into gpu
DEBUG 01-13 08:46:49.679557.679557 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 00ecae40-33e5-403e-9f46-9af7eee90301
DEBUG 01-13 08:46:49.679285.679285 client.py:106] call stub.LoadModelAsync
DEBUG 01-13 08:46:49.680122.680122 cuda_h.py:10] start experts_func_gpu_einsum_mp
INFO 01-13 08:46:49.680739.680739 client.py:127] Model loaded
DEBUG 01-13 08:46:49.680874.680874 cuda_h.py:10] start restore2model
DEBUG 01-13 08:46:49.681313.681313 cuda_h.py:19] end restore2model cost 0.00042057037353515625 seconds
DEBUG 01-13 08:46:49.681011.681011 cuda_h.py:19] end sllm_worker_task cost 0.010736465454101562 seconds
INFO 01-13 08:46:49.682586.682586 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 00ecae40-33e5-403e-9f46-9af7eee90301
DEBUG 01-13 08:46:49.682766.682766 cuda_h.py:19] end load_into_gpu_async cost 0.003332853317260742 seconds
DEBUG 01-13 08:46:49.682423.682423 cuda_h.py:10] start restore_tensors2
DEBUG 01-13 08:46:49.682570.682570 cuda_h.py:19] end restore_tensors2 cost 0.00039696693420410156 seconds
DEBUG 01-13 08:46:49.683744.683744 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.005337953567504883 seconds
DEBUG 01-13 08:46:49.683937.683937 cuda_h.py:10] start restore2model
DEBUG 01-13 08:46:49.685563.685563 cuda_h.py:19] end restore2model cost 0.0026383399963378906 seconds
DEBUG 01-13 08:46:49.685452.685452 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.008159637451171875 seconds
DEBUG 01-13 08:46:49.685791.685791 cuda_h.py:10] start gpu_sexperts
DEBUG 01-13 08:46:49.686722.686722 cuda_h.py:19] end gpu_sexperts cost 0.00027060508728027344 seconds
DEBUG 01-13 08:46:49.686883.686883 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-13 08:46:49.686891.686891 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 1.4066696166992188e-05 seconds
DEBUG 01-13 08:46:49.686156.686156 cuda_h.py:10] start wait_experts
INFO 01-13 08:46:49.686614.686614 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 00ecae40-33e5-403e-9f46-9af7eee90301
DEBUG 01-13 08:46:49.687042.687042 mlpmodule.py:1006] group tensors cost 0.0060770511627197266 s
DEBUG 01-13 08:46:49.691633.691633 mlpmodule.py:1044] pad cost 0.003724336624145508 s
DEBUG 01-13 08:46:49.692870.692870 mlpmodule.py:1050] create cpu tensor cost 8.249282836914062e-05 s
DEBUG 01-13 08:46:49.692080.692080 mlpmodule.py:1055] move to cpu cost 5.650520324707031e-05 s
DEBUG 01-13 08:46:49.700718.700718 mlpmodule.py:1069] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-13 08:46:49.701440.701440 mlpmodule.py:1070] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-13 08:46:49.701425.701425 mlpmodule.py:1075] group_w3 first element: -0.0034942626953125
WARNING 01-13 08:46:49.701424.701424 mlpmodule.py:1085] start einsum2
DEBUG 01-13 08:46:49.714459.714459 mlpmodule.py:1095] group einsum cost 0.022283554077148438 s
DEBUG 01-13 08:46:49.715506.715506 mlpmodule.py:1103] cpy2cputensor cost 0.0007376670837402344 s
INFO 01-13 08:46:49.733586.733586 client.py:127] Model loaded
DEBUG 01-13 08:46:49.733778.733778 cuda_h.py:19] end wait_experts cost 0.04738187789916992 seconds
DEBUG 01-13 08:46:49.733302.733302 cuda_h.py:10] start gpu_experts
DEBUG 01-13 08:46:49.734875.734875 mlpmodule.py:559] gpu group tensors cost 0.0006072521209716797 s
DEBUG 01-13 08:46:49.735688.735688 mlpmodule.py:592] gpu pad cost 0.001443624496459961 s
DEBUG 01-13 08:46:49.735868.735868 mlpmodule.py:598] start_w1
DEBUG 01-13 08:46:49.736249.736249 mlpmodule.py:602] start_w3
DEBUG 01-13 08:46:49.736817.736817 mlpmodule.py:608] start_w2
DEBUG 01-13 08:46:49.736795.736795 mlpmodule.py:611] gpu group einsum cost 0.0005776882171630859 s
DEBUG 01-13 08:46:49.738598.738598 mlpmodule.py:683] gpu experts func einsum cost 0.004795551300048828 s
DEBUG 01-13 08:46:49.738496.738496 cuda_h.py:19] end gpu_experts cost 0.004963874816894531 seconds
DEBUG 01-13 08:46:49.738391.738391 cuda_h.py:10] start cpu_thread_manager_mp_wait
DEBUG 01-13 08:46:49.738287.738287 cuda_h.py:19] end cpu_thread_manager_mp_wait cost 3.552436828613281e-05 seconds
DEBUG 01-13 08:46:49.738011.738011 cuda_h.py:19] end layer_moe_generate_mp_l_20 cost 0.06378912925720215 seconds
DEBUG 01-13 08:46:49.739946.739946 lmp.py:1550] -------------------------------- end prefill layer 19 --------------------------------
DEBUG 01-13 08:46:49.739623.739623 lmp.py:1493] -------------------------------- start prefill layer 20 --------------------------------
DEBUG 01-13 08:46:49.739657.739657 cuda_h.py:10] start start_load_qkvogn_s_weight_l_21
DEBUG 01-13 08:46:49.739552.739552 cuda_h.py:10] start start_load_qkvogn_s_weight_l_21
DEBUG 01-13 08:46:49.739958.739958 cuda_h.py:19] end start_load_qkvogn_s_weight_l_21 cost 2.9325485229492188e-05 seconds
DEBUG 01-13 08:46:49.739137.739137 cuda_h.py:19] end start_load_qkvogn_s_weight_l_21 cost 5.984306335449219e-05 seconds
DEBUG 01-13 08:46:49.739496.739496 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-13 08:46:49.739776.739776 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-13 08:46:49.739024.739024 cuda_h.py:10] start sllm_worker_task
DEBUG 01-13 08:46:49.739993.739993 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-13 08:46:49.739221.739221 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-13 08:46:49.739174.739174 cuda_h.py:19] end allocate_cuda_memory cost 0.0003483295440673828 seconds
DEBUG 01-13 08:46:49.740389.740389 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-13 08:46:49.740682.740682 sllm_store_c.py:27] get device uuid map
DEBUG 01-13 08:46:49.740478.740478 sllm_store_c.py:29] call client load into gpu
DEBUG 01-13 08:46:49.740135.740135 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 5d367233-7314-4c9a-89f9-406c003370f2
DEBUG 01-13 08:46:49.740880.740880 client.py:106] call stub.LoadModelAsync
DEBUG 01-13 08:46:49.740001.740001 cuda_h.py:10] start self_attn
INFO 01-13 08:46:49.741479.741479 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 5d367233-7314-4c9a-89f9-406c003370f2
DEBUG 01-13 08:46:49.741607.741607 cuda_h.py:19] end load_into_gpu_async cost 0.0017364025115966797 seconds
DEBUG 01-13 08:46:49.741125.741125 cuda_h.py:10] start restore_tensors2
DEBUG 01-13 08:46:49.741983.741983 cuda_h.py:19] end restore_tensors2 cost 7.343292236328125e-05 seconds
DEBUG 01-13 08:46:49.742507.742507 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.002444744110107422 seconds
INFO 01-13 08:46:49.742582.742582 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 5d367233-7314-4c9a-89f9-406c003370f2
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-13 08:46:49.743939.743939 cuda_h.py:19] end self_attn cost 0.0028455257415771484 seconds
DEBUG 01-13 08:46:49.743870.743870 mlpmodule.py:785]  experts func einsum cost 0.062255859375 s
DEBUG 01-13 08:46:49.743731.743731 cuda_h.py:19] end iln_self_attn_paln cost 0.004427909851074219 seconds
DEBUG 01-13 08:46:49.743044.743044 cuda_h.py:10] start layer_moe_generate_mp_l_21
DEBUG 01-13 08:46:49.743992.743992 cuda_h.py:10] start gate
DEBUG 01-13 08:46:49.744419.744419 cuda_h.py:19] end gate cost 0.0006337165832519531 seconds
DEBUG 01-13 08:46:49.744056.744056 cuda_h.py:10] start experts_map_get
DEBUG 01-13 08:46:49.744817.744817 cuda_h.py:19] end experts_func_gpu_einsum_mp cost 0.06394267082214355 seconds
DEBUG 01-13 08:46:49.744158.744158 lmp.py:1611] 
DEBUG 01-13 08:46:49.744158.744158 lmp.py:1611] Expert Token Distribution & Device Allocation:
DEBUG 01-13 08:46:49.744252.744252 lmp.py:1612]   Total experts: 64
DEBUG 01-13 08:46:49.744855.744855 lmp.py:1613]   CPU experts: 32 (50%)
DEBUG 01-13 08:46:49.744737.744737 lmp.py:1614]   GPU experts: 32 (50%)
DEBUG 01-13 08:46:49.744711.744711 lmp.py:1615] 
DEBUG 01-13 08:46:49.744711.744711 lmp.py:1615]   Expert ID | Tokens | Device
DEBUG 01-13 08:46:49.744400.744400 lmp.py:1616]   -----------------------------------
DEBUG 01-13 08:46:49.744858.744858 lmp.py:1622]   Expert 54 |     25 | CPU
DEBUG 01-13 08:46:49.744309.744309 lmp.py:1622]   Expert  3 |     33 | CPU
DEBUG 01-13 08:46:49.745044.745044 lmp.py:1622]   Expert  8 |     43 | CPU
DEBUG 01-13 08:46:49.745542.745542 lmp.py:1622]   Expert 28 |     43 | CPU
DEBUG 01-13 08:46:49.745800.745800 lmp.py:1622]   Expert 43 |     53 | CPU
DEBUG 01-13 08:46:49.745582.745582 lmp.py:1622]   Expert 63 |     53 | CPU
DEBUG 01-13 08:46:49.745126.745126 lmp.py:1622]   Expert 36 |     65 | CPU
DEBUG 01-13 08:46:49.745908.745908 lmp.py:1622]   Expert 38 |     75 | CPU
DEBUG 01-13 08:46:49.745167.745167 lmp.py:1622]   Expert  6 |     77 | CPU
DEBUG 01-13 08:46:49.745141.745141 lmp.py:1622]   Expert 39 |     93 | CPU
DEBUG 01-13 08:46:49.745876.745876 lmp.py:1622]   Expert 41 |    101 | CPU
DEBUG 01-13 08:46:49.745612.745612 lmp.py:1622]   Expert 57 |    104 | CPU
DEBUG 01-13 08:46:49.745109.745109 lmp.py:1622]   Expert 12 |    105 | CPU
DEBUG 01-13 08:46:49.745083.745083 lmp.py:1622]   Expert 52 |    107 | CPU
DEBUG 01-13 08:46:49.745342.745342 lmp.py:1622]   Expert 47 |    125 | CPU
DEBUG 01-13 08:46:49.745601.745601 lmp.py:1622]   Expert 19 |    126 | CPU
DEBUG 01-13 08:46:49.745860.745860 lmp.py:1622]   Expert 13 |    131 | CPU
DEBUG 01-13 08:46:49.745641.745641 lmp.py:1622]   Expert 22 |    132 | CPU
DEBUG 01-13 08:46:49.745423.745423 lmp.py:1622]   Expert 46 |    139 | CPU
DEBUG 01-13 08:46:49.745967.745967 lmp.py:1622]   Expert 50 |    147 | CPU
DEBUG 01-13 08:46:49.745987.745987 lmp.py:1622]   Expert 24 |    157 | CPU
DEBUG 01-13 08:46:49.745531.745531 lmp.py:1622]   Expert 55 |    165 | CPU
DEBUG 01-13 08:46:49.745313.745313 lmp.py:1622]   Expert 40 |    170 | CPU
DEBUG 01-13 08:46:49.745095.745095 lmp.py:1622]   Expert 21 |    171 | CPU
DEBUG 01-13 08:46:49.745354.745354 lmp.py:1622]   Expert 37 |    171 | CPU
DEBUG 01-13 08:46:49.745612.745612 lmp.py:1622]   Expert  2 |    172 | CPU
DEBUG 01-13 08:46:49.745633.745633 lmp.py:1622]   Expert 33 |    174 | CPU
DEBUG 01-13 08:46:49.745560.745560 lmp.py:1622]   Expert 61 |    176 | CPU
DEBUG 01-13 08:46:49.745773.745773 lmp.py:1622]   Expert 53 |    177 | CPU
DEBUG 01-13 08:46:49.745985.745985 lmp.py:1622]   Expert 20 |    178 | CPU
DEBUG 01-13 08:46:49.745721.745721 lmp.py:1622]   Expert 49 |    181 | CPU
DEBUG 01-13 08:46:49.745457.745457 lmp.py:1622]   Expert 42 |    182 | CPU
DEBUG 01-13 08:46:49.745954.745954 lmp.py:1622]   Expert 18 |    184 | GPU
DEBUG 01-13 08:46:49.745689.745689 lmp.py:1622]   Expert 23 |    189 | GPU
DEBUG 01-13 08:46:49.745187.745187 lmp.py:1622]   Expert 16 |    195 | GPU
DEBUG 01-13 08:46:49.745922.745922 lmp.py:1622]   Expert 30 |    201 | GPU
DEBUG 01-13 08:46:49.745181.745181 lmp.py:1622]   Expert  0 |    203 | GPU
DEBUG 01-13 08:46:49.745917.745917 lmp.py:1622]   Expert  5 |    203 | GPU
DEBUG 01-13 08:46:49.745414.745414 lmp.py:1622]   Expert  7 |    206 | GPU
DEBUG 01-13 08:46:49.745626.745626 lmp.py:1622]   Expert 14 |    207 | GPU
DEBUG 01-13 08:46:49.745600.745600 lmp.py:1622]   Expert 32 |    208 | GPU
DEBUG 01-13 08:46:49.745813.745813 lmp.py:1622]   Expert 34 |    212 | GPU
DEBUG 01-13 08:46:49.745787.745787 lmp.py:1622]   Expert 62 |    212 | GPU
DEBUG 01-13 08:46:49.745761.745761 lmp.py:1622]   Expert 60 |    213 | GPU
DEBUG 01-13 08:46:49.745258.745258 lmp.py:1622]   Expert 17 |    217 | GPU
DEBUG 01-13 08:46:49.745517.745517 lmp.py:1622]   Expert 59 |    220 | GPU
DEBUG 01-13 08:46:49.745491.745491 lmp.py:1622]   Expert  9 |    222 | GPU
DEBUG 01-13 08:46:49.745511.745511 lmp.py:1622]   Expert 31 |    226 | GPU
DEBUG 01-13 08:46:49.745770.745770 lmp.py:1622]   Expert 29 |    230 | GPU
DEBUG 01-13 08:46:49.745506.745506 lmp.py:1622]   Expert 10 |    232 | GPU
DEBUG 01-13 08:46:49.745765.745765 lmp.py:1622]   Expert 15 |    238 | GPU
DEBUG 01-13 08:46:49.745023.745023 lmp.py:1622]   Expert  4 |    240 | GPU
DEBUG 01-13 08:46:49.745282.745282 lmp.py:1622]   Expert 58 |    245 | GPU
DEBUG 01-13 08:46:49.745779.745779 lmp.py:1622]   Expert 26 |    250 | GPU
DEBUG 01-13 08:46:49.745277.745277 lmp.py:1622]   Expert 11 |    251 | GPU
DEBUG 01-13 08:46:49.745489.745489 lmp.py:1622]   Expert 51 |    254 | GPU
DEBUG 01-13 08:46:49.745225.745225 lmp.py:1622]   Expert 44 |    266 | GPU
DEBUG 01-13 08:46:49.745437.745437 lmp.py:1622]   Expert 27 |    287 | GPU
DEBUG 01-13 08:46:49.745696.745696 lmp.py:1622]   Expert 56 |    290 | GPU
DEBUG 01-13 08:46:49.745908.745908 lmp.py:1622]   Expert  1 |    333 | GPU
DEBUG 01-13 08:46:49.745121.745121 lmp.py:1622]   Expert 45 |    356 | GPU
DEBUG 01-13 08:46:49.745618.745618 lmp.py:1622]   Expert 25 |    477 | GPU
DEBUG 01-13 08:46:49.745831.745831 lmp.py:1622]   Expert 35 |    531 | GPU
DEBUG 01-13 08:46:49.745566.745566 lmp.py:1622]   Expert 48 |    639 | GPU
DEBUG 01-13 08:46:49.745971.745971 lmp.py:1623] 
DEBUG 01-13 08:46:49.745971.745971 lmp.py:1623]   CPU total tokens: 3851 (31.3%)
DEBUG 01-13 08:46:49.745137.745137 lmp.py:1624]   GPU total tokens: 8437 (68.7%)
DEBUG 01-13 08:46:49.746118.746118 cuda_h.py:19] end experts_map_get cost 0.0014231204986572266 seconds
DEBUG 01-13 08:46:49.746676.746676 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-13 08:46:49.746809.746809 lmp.py:1632] 
DEBUG 01-13 08:46:49.746809.746809 lmp.py:1632]   Computing 32 experts on CPU MP...
DEBUG 01-13 08:46:49.746824.746824 cuda_h.py:19] end cpu_experts_submit cost 4.5299530029296875e-05 seconds
DEBUG 01-13 08:46:49.746872.746872 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-13 08:46:49.746840.746840 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-13 08:46:49.746792.746792 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-13 08:46:49.747371.747371 cuda_h.py:19] end allocate_cuda_memory cost 0.0014472007751464844 seconds
DEBUG 01-13 08:46:49.747950.747950 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-13 08:46:49.747428.747428 sllm_store_c.py:27] get device uuid map
DEBUG 01-13 08:46:49.747999.747999 sllm_store_c.py:29] call client load into gpu
DEBUG 01-13 08:46:49.748324.748324 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 6492433d-ce41-4950-bd21-d7340c01f401
DEBUG 01-13 08:46:49.748390.748390 client.py:106] call stub.LoadModelAsync
DEBUG 01-13 08:46:49.749894.749894 cuda_h.py:10] start experts_func_gpu_einsum_mp
INFO 01-13 08:46:49.749826.749826 client.py:127] Model loaded
DEBUG 01-13 08:46:49.749960.749960 cuda_h.py:10] start restore2model
DEBUG 01-13 08:46:49.750770.750770 cuda_h.py:19] end restore2model cost 0.00041103363037109375 seconds
DEBUG 01-13 08:46:49.750560.750560 cuda_h.py:19] end sllm_worker_task cost 0.010605573654174805 seconds
INFO 01-13 08:46:49.751181.751181 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 6492433d-ce41-4950-bd21-d7340c01f401
DEBUG 01-13 08:46:49.751362.751362 cuda_h.py:19] end load_into_gpu_async cost 0.0031783580780029297 seconds
DEBUG 01-13 08:46:49.751973.751973 cuda_h.py:10] start restore_tensors2
DEBUG 01-13 08:46:49.751444.751444 cuda_h.py:19] end restore_tensors2 cost 0.0003902912139892578 seconds
DEBUG 01-13 08:46:49.751280.751280 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.005392313003540039 seconds
DEBUG 01-13 08:46:49.751235.751235 cuda_h.py:10] start restore2model
DEBUG 01-13 08:46:49.754399.754399 cuda_h.py:19] end restore2model cost 0.002516508102416992 seconds
DEBUG 01-13 08:46:49.754666.754666 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.008079290390014648 seconds
DEBUG 01-13 08:46:49.754767.754767 cuda_h.py:10] start gpu_sexperts
DEBUG 01-13 08:46:49.754399.754399 cuda_h.py:19] end gpu_sexperts cost 0.0002613067626953125 seconds
DEBUG 01-13 08:46:49.754798.754798 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-13 08:46:49.754283.754283 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 1.430511474609375e-05 seconds
DEBUG 01-13 08:46:49.754787.754787 cuda_h.py:10] start wait_experts
INFO 01-13 08:46:49.754483.754483 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 6492433d-ce41-4950-bd21-d7340c01f401
DEBUG 01-13 08:46:49.762054.762054 mlpmodule.py:1006] group tensors cost 0.012667655944824219 s
DEBUG 01-13 08:46:49.767901.767901 mlpmodule.py:1044] pad cost 0.003180980682373047 s
DEBUG 01-13 08:46:49.767972.767972 mlpmodule.py:1050] create cpu tensor cost 7.462501525878906e-05 s
DEBUG 01-13 08:46:49.767876.767876 mlpmodule.py:1055] move to cpu cost 5.316734313964844e-05 s
DEBUG 01-13 08:46:49.776545.776545 mlpmodule.py:1069] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-13 08:46:49.776711.776711 mlpmodule.py:1070] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-13 08:46:49.776073.776073 mlpmodule.py:1075] group_w3 first element: 0.039306640625
WARNING 01-13 08:46:49.776827.776827 mlpmodule.py:1085] start einsum2
DEBUG 01-13 08:46:49.788555.788555 mlpmodule.py:1095] group einsum cost 0.021352052688598633 s
DEBUG 01-13 08:46:49.789907.789907 mlpmodule.py:1103] cpy2cputensor cost 0.0007359981536865234 s
INFO 01-13 08:46:49.801322.801322 client.py:127] Model loaded
DEBUG 01-13 08:46:49.801282.801282 cuda_h.py:19] end wait_experts cost 0.04677462577819824 seconds
DEBUG 01-13 08:46:49.801190.801190 cuda_h.py:10] start gpu_experts
DEBUG 01-13 08:46:49.802656.802656 mlpmodule.py:559] gpu group tensors cost 0.0007572174072265625 s
DEBUG 01-13 08:46:49.804565.804565 mlpmodule.py:592] gpu pad cost 0.001756429672241211 s
DEBUG 01-13 08:46:49.804753.804753 mlpmodule.py:598] start_w1
DEBUG 01-13 08:46:49.804528.804528 mlpmodule.py:602] start_w3
DEBUG 01-13 08:46:49.804329.804329 mlpmodule.py:608] start_w2
DEBUG 01-13 08:46:49.805131.805131 mlpmodule.py:611] gpu group einsum cost 0.0008013248443603516 s
DEBUG 01-13 08:46:49.807437.807437 mlpmodule.py:683] gpu experts func einsum cost 0.005690336227416992 s
DEBUG 01-13 08:46:49.807441.807441 cuda_h.py:19] end gpu_experts cost 0.00587773323059082 seconds
DEBUG 01-13 08:46:49.807482.807482 cuda_h.py:10] start cpu_thread_manager_mp_wait
DEBUG 01-13 08:46:49.807391.807391 cuda_h.py:19] end cpu_thread_manager_mp_wait cost 3.600120544433594e-05 seconds
DEBUG 01-13 08:46:49.807600.807600 cuda_h.py:19] end layer_moe_generate_mp_l_21 cost 0.06382870674133301 seconds
DEBUG 01-13 08:46:49.807509.807509 lmp.py:1550] -------------------------------- end prefill layer 20 --------------------------------
DEBUG 01-13 08:46:49.807570.807570 lmp.py:1493] -------------------------------- start prefill layer 21 --------------------------------
DEBUG 01-13 08:46:49.807080.807080 cuda_h.py:10] start start_load_qkvogn_s_weight_l_22
DEBUG 01-13 08:46:49.808691.808691 cuda_h.py:10] start start_load_qkvogn_s_weight_l_22
DEBUG 01-13 08:46:49.808242.808242 cuda_h.py:19] end start_load_qkvogn_s_weight_l_22 cost 3.147125244140625e-05 seconds
DEBUG 01-13 08:46:49.808084.808084 cuda_h.py:19] end start_load_qkvogn_s_weight_l_22 cost 5.888938903808594e-05 seconds
DEBUG 01-13 08:46:49.808442.808442 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-13 08:46:49.808199.808199 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-13 08:46:49.808745.808745 cuda_h.py:10] start sllm_worker_task
DEBUG 01-13 08:46:49.808451.808451 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-13 08:46:49.808414.808414 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-13 08:46:49.808930.808930 cuda_h.py:19] end allocate_cuda_memory cost 0.00034356117248535156 seconds
DEBUG 01-13 08:46:49.808800.808800 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-13 08:46:49.808371.808371 sllm_store_c.py:27] get device uuid map
DEBUG 01-13 08:46:49.808432.808432 sllm_store_c.py:29] call client load into gpu
DEBUG 01-13 08:46:49.809942.809942 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, b1e4b99e-0e8e-4de5-962f-87b0a939eaa0
DEBUG 01-13 08:46:49.809681.809681 client.py:106] call stub.LoadModelAsync
DEBUG 01-13 08:46:49.809948.809948 cuda_h.py:10] start self_attn
INFO 01-13 08:46:49.810803.810803 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, b1e4b99e-0e8e-4de5-962f-87b0a939eaa0
DEBUG 01-13 08:46:49.810877.810877 cuda_h.py:19] end load_into_gpu_async cost 0.0012860298156738281 seconds
DEBUG 01-13 08:46:49.810673.810673 cuda_h.py:10] start restore_tensors2
DEBUG 01-13 08:46:49.810040.810040 cuda_h.py:19] end restore_tensors2 cost 6.937980651855469e-05 seconds
DEBUG 01-13 08:46:49.810604.810604 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0019528865814208984 seconds
INFO 01-13 08:46:49.810825.810825 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, b1e4b99e-0e8e-4de5-962f-87b0a939eaa0
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-13 08:46:49.812664.812664 cuda_h.py:19] end self_attn cost 0.002749204635620117 seconds
DEBUG 01-13 08:46:49.812641.812641 cuda_h.py:19] end iln_self_attn_paln cost 0.004332304000854492 seconds
DEBUG 01-13 08:46:49.812769.812769 cuda_h.py:10] start layer_moe_generate_mp_l_22
DEBUG 01-13 08:46:49.812148.812148 cuda_h.py:10] start gate
DEBUG 01-13 08:46:49.813812.813812 cuda_h.py:19] end gate cost 0.00063323974609375 seconds
DEBUG 01-13 08:46:49.813258.813258 cuda_h.py:10] start experts_map_get
DEBUG 01-13 08:46:49.813096.813096 lmp.py:1611] 
DEBUG 01-13 08:46:49.813096.813096 lmp.py:1611] Expert Token Distribution & Device Allocation:
DEBUG 01-13 08:46:49.813659.813659 lmp.py:1612]   Total experts: 64
DEBUG 01-13 08:46:49.813356.813356 lmp.py:1613]   CPU experts: 32 (50%)
DEBUG 01-13 08:46:49.813714.813714 lmp.py:1614]   GPU experts: 32 (50%)
DEBUG 01-13 08:46:49.813926.813926 lmp.py:1615] 
DEBUG 01-13 08:46:49.813926.813926 lmp.py:1615]   Expert ID | Tokens | Device
DEBUG 01-13 08:46:49.813092.813092 lmp.py:1616]   -----------------------------------
DEBUG 01-13 08:46:49.813742.813742 lmp.py:1622]   Expert 44 |     27 | CPU
DEBUG 01-13 08:46:49.813246.813246 lmp.py:1622]   Expert  9 |     35 | CPU
DEBUG 01-13 08:46:49.813604.813604 lmp.py:1622]   Expert 11 |     35 | CPU
DEBUG 01-13 08:46:49.813963.813963 lmp.py:1622]   Expert 56 |     54 | CPU
DEBUG 01-13 08:46:49.813321.813321 lmp.py:1622]   Expert 54 |     72 | CPU
DEBUG 01-13 08:46:49.813249.813249 lmp.py:1622]   Expert  7 |     82 | CPU
DEBUG 01-13 08:46:49.813415.813415 lmp.py:1622]   Expert 47 |     88 | CPU
DEBUG 01-13 08:46:49.813342.813342 lmp.py:1622]   Expert 62 |     94 | CPU
DEBUG 01-13 08:46:49.813032.813032 lmp.py:1622]   Expert 60 |     99 | CPU
DEBUG 01-13 08:46:49.813198.813198 lmp.py:1622]   Expert 41 |    106 | CPU
DEBUG 01-13 08:46:49.813126.813126 lmp.py:1622]   Expert 51 |    110 | CPU
DEBUG 01-13 08:46:49.813053.813053 lmp.py:1622]   Expert 52 |    111 | CPU
DEBUG 01-13 08:46:49.813219.813219 lmp.py:1622]   Expert 22 |    117 | CPU
DEBUG 01-13 08:46:49.813147.813147 lmp.py:1622]   Expert 53 |    117 | CPU
DEBUG 01-13 08:46:49.813029.813029 lmp.py:1622]   Expert  8 |    118 | CPU
DEBUG 01-13 08:46:49.813433.813433 lmp.py:1622]   Expert  6 |    119 | CPU
DEBUG 01-13 08:46:49.813076.813076 lmp.py:1622]   Expert 48 |    130 | CPU
DEBUG 01-13 08:46:49.814481.814481 lmp.py:1622]   Expert 32 |    131 | CPU
DEBUG 01-13 08:46:49.814408.814408 lmp.py:1622]   Expert  1 |    134 | CPU
DEBUG 01-13 08:46:49.814574.814574 lmp.py:1622]   Expert  2 |    136 | CPU
DEBUG 01-13 08:46:49.814025.814025 lmp.py:1622]   Expert 35 |    140 | CPU
DEBUG 01-13 08:46:49.814476.814476 lmp.py:1622]   Expert 23 |    141 | CPU
DEBUG 01-13 08:46:49.814166.814166 lmp.py:1622]   Expert 26 |    141 | CPU
DEBUG 01-13 08:46:49.814855.814855 lmp.py:1622]   Expert 59 |    141 | CPU
DEBUG 01-13 08:46:49.814544.814544 lmp.py:1622]   Expert 39 |    144 | CPU
DEBUG 01-13 08:46:49.814757.814757 lmp.py:1622]   Expert 27 |    146 | CPU
DEBUG 01-13 08:46:49.814446.814446 lmp.py:1622]   Expert 50 |    151 | CPU
DEBUG 01-13 08:46:49.814089.814089 lmp.py:1622]   Expert 14 |    165 | CPU
DEBUG 01-13 08:46:49.814732.814732 lmp.py:1622]   Expert 24 |    167 | CPU
DEBUG 01-13 08:46:49.814136.814136 lmp.py:1622]   Expert 46 |    169 | CPU
DEBUG 01-13 08:46:49.814779.814779 lmp.py:1622]   Expert 49 |    170 | CPU
DEBUG 01-13 08:46:49.814230.814230 lmp.py:1622]   Expert 38 |    172 | CPU
DEBUG 01-13 08:46:49.814920.814920 lmp.py:1622]   Expert 34 |    173 | GPU
DEBUG 01-13 08:46:49.814609.814609 lmp.py:1622]   Expert  4 |    174 | GPU
DEBUG 01-13 08:46:49.814060.814060 lmp.py:1622]   Expert 40 |    179 | GPU
DEBUG 01-13 08:46:49.814749.814749 lmp.py:1622]   Expert  0 |    183 | GPU
DEBUG 01-13 08:46:49.814438.814438 lmp.py:1622]   Expert  5 |    186 | GPU
DEBUG 01-13 08:46:49.814651.814651 lmp.py:1622]   Expert 19 |    190 | GPU
DEBUG 01-13 08:46:49.814625.814625 lmp.py:1622]   Expert 63 |    191 | GPU
DEBUG 01-13 08:46:49.814837.814837 lmp.py:1622]   Expert 13 |    195 | GPU
DEBUG 01-13 08:46:49.814527.814527 lmp.py:1622]   Expert 29 |    204 | GPU
DEBUG 01-13 08:46:49.814501.814501 lmp.py:1622]   Expert 43 |    212 | GPU
DEBUG 01-13 08:46:49.814713.814713 lmp.py:1622]   Expert 57 |    212 | GPU
DEBUG 01-13 08:46:49.814118.814118 lmp.py:1622]   Expert 61 |    223 | GPU
DEBUG 01-13 08:46:49.814284.814284 lmp.py:1622]   Expert 33 |    226 | GPU
DEBUG 01-13 08:46:49.814688.814688 lmp.py:1622]   Expert 31 |    235 | GPU
DEBUG 01-13 08:46:49.814331.814331 lmp.py:1622]   Expert 16 |    240 | GPU
DEBUG 01-13 08:46:49.814021.814021 lmp.py:1622]   Expert 15 |    246 | GPU
DEBUG 01-13 08:46:49.814472.814472 lmp.py:1622]   Expert 20 |    248 | GPU
DEBUG 01-13 08:46:49.814922.814922 lmp.py:1622]   Expert 37 |    255 | GPU
DEBUG 01-13 08:46:49.814373.814373 lmp.py:1622]   Expert  3 |    257 | GPU
DEBUG 01-13 08:46:49.814586.814586 lmp.py:1622]   Expert 12 |    261 | GPU
DEBUG 01-13 08:46:49.814798.814798 lmp.py:1622]   Expert 36 |    273 | GPU
DEBUG 01-13 08:46:49.814011.814011 lmp.py:1622]   Expert 18 |    280 | GPU
DEBUG 01-13 08:46:49.814700.814700 lmp.py:1622]   Expert 28 |    298 | GPU
DEBUG 01-13 08:46:49.814389.814389 lmp.py:1622]   Expert 17 |    307 | GPU
DEBUG 01-13 08:46:49.814602.814602 lmp.py:1622]   Expert 25 |    311 | GPU
DEBUG 01-13 08:46:49.814053.814053 lmp.py:1622]   Expert 30 |    315 | GPU
DEBUG 01-13 08:46:49.814742.814742 lmp.py:1622]   Expert 55 |    317 | GPU
DEBUG 01-13 08:46:49.814431.814431 lmp.py:1622]   Expert 58 |    340 | GPU
DEBUG 01-13 08:46:49.814121.814121 lmp.py:1622]   Expert 10 |    362 | GPU
DEBUG 01-13 08:46:49.814525.814525 lmp.py:1622]   Expert 45 |    384 | GPU
DEBUG 01-13 08:46:49.814930.814930 lmp.py:1622]   Expert 21 |    387 | GPU
DEBUG 01-13 08:46:49.814857.814857 lmp.py:1622]   Expert 42 |    662 | GPU
DEBUG 01-13 08:46:49.814739.814739 lmp.py:1623] 
DEBUG 01-13 08:46:49.814739.814739 lmp.py:1623]   CPU total tokens: 3762 (30.6%)
DEBUG 01-13 08:46:49.814620.814620 lmp.py:1624]   GPU total tokens: 8526 (69.4%)
DEBUG 01-13 08:46:49.814579.814579 mlpmodule.py:785]  experts func einsum cost 0.06459331512451172 s
DEBUG 01-13 08:46:49.814316.814316 cuda_h.py:19] end experts_map_get cost 0.0015261173248291016 seconds
DEBUG 01-13 08:46:49.814597.814597 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-13 08:46:49.814730.814730 lmp.py:1632] 
DEBUG 01-13 08:46:49.814730.814730 lmp.py:1632]   Computing 32 experts on CPU MP...
DEBUG 01-13 08:46:49.814414.814414 cuda_h.py:19] end cpu_experts_submit cost 4.696846008300781e-05 seconds
DEBUG 01-13 08:46:49.815679.815679 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-13 08:46:49.814798.814798 cuda_h.py:19] end experts_func_gpu_einsum_mp cost 0.06544089317321777 seconds
DEBUG 01-13 08:46:49.815317.815317 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-13 08:46:49.815150.815150 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-13 08:46:49.816990.816990 cuda_h.py:19] end allocate_cuda_memory cost 0.001321554183959961 seconds
DEBUG 01-13 08:46:49.816409.816409 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-13 08:46:49.816404.816404 sllm_store_c.py:27] get device uuid map
DEBUG 01-13 08:46:49.816405.816405 sllm_store_c.py:29] call client load into gpu
DEBUG 01-13 08:46:49.816008.816008 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 859fa2bc-a67c-49ee-905b-36f4fcf4ea3c
DEBUG 01-13 08:46:49.816227.816227 client.py:106] call stub.LoadModelAsync
DEBUG 01-13 08:46:49.817450.817450 cuda_h.py:10] start experts_func_gpu_einsum_mp
INFO 01-13 08:46:49.818214.818214 client.py:127] Model loaded
DEBUG 01-13 08:46:49.818182.818182 cuda_h.py:10] start restore2model
DEBUG 01-13 08:46:49.818103.818103 cuda_h.py:19] end restore2model cost 0.00036597251892089844 seconds
DEBUG 01-13 08:46:49.818740.818740 cuda_h.py:19] end sllm_worker_task cost 0.010228872299194336 seconds
INFO 01-13 08:46:49.818154.818154 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 859fa2bc-a67c-49ee-905b-36f4fcf4ea3c
DEBUG 01-13 08:46:49.818528.818528 cuda_h.py:19] end load_into_gpu_async cost 0.002329587936401367 seconds
DEBUG 01-13 08:46:49.819312.819312 cuda_h.py:10] start restore_tensors2
DEBUG 01-13 08:46:49.819419.819419 cuda_h.py:19] end restore_tensors2 cost 0.0005927085876464844 seconds
DEBUG 01-13 08:46:49.819541.819541 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0047016143798828125 seconds
DEBUG 01-13 08:46:49.819623.819623 cuda_h.py:10] start restore2model
DEBUG 01-13 08:46:49.824663.824663 cuda_h.py:19] end restore2model cost 0.004503726959228516 seconds
DEBUG 01-13 08:46:49.824686.824686 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.009459495544433594 seconds
DEBUG 01-13 08:46:49.824363.824363 cuda_h.py:10] start gpu_sexperts
DEBUG 01-13 08:46:49.825100.825100 cuda_h.py:19] end gpu_sexperts cost 0.0004229545593261719 seconds
DEBUG 01-13 08:46:49.825487.825487 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-13 08:46:49.825628.825628 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.0265579223632812e-05 seconds
DEBUG 01-13 08:46:49.825491.825491 cuda_h.py:10] start wait_experts
INFO 01-13 08:46:49.825353.825353 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 859fa2bc-a67c-49ee-905b-36f4fcf4ea3c
DEBUG 01-13 08:46:49.827713.827713 mlpmodule.py:1006] group tensors cost 0.008960962295532227 s
DEBUG 01-13 08:46:49.830371.830371 mlpmodule.py:1044] pad cost 0.002129077911376953 s
DEBUG 01-13 08:46:49.830527.830527 mlpmodule.py:1050] create cpu tensor cost 5.412101745605469e-05 s
DEBUG 01-13 08:46:49.830867.830867 mlpmodule.py:1055] move to cpu cost 3.9577484130859375e-05 s
DEBUG 01-13 08:46:49.838823.838823 mlpmodule.py:1069] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-13 08:46:49.839539.839539 mlpmodule.py:1070] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-13 08:46:49.839755.839755 mlpmodule.py:1075] group_w3 first element: 0.00066375732421875
WARNING 01-13 08:46:49.839356.839356 mlpmodule.py:1085] start einsum2
DEBUG 01-13 08:46:49.849621.849621 mlpmodule.py:1095] group einsum cost 0.01886296272277832 s
DEBUG 01-13 08:46:49.850648.850648 mlpmodule.py:1103] cpy2cputensor cost 0.0007486343383789062 s
INFO 01-13 08:46:49.868639.868639 client.py:127] Model loaded
DEBUG 01-13 08:46:49.869663.869663 cuda_h.py:19] end wait_experts cost 0.043857574462890625 seconds
DEBUG 01-13 08:46:49.869088.869088 cuda_h.py:10] start gpu_experts
DEBUG 01-13 08:46:49.869350.869350 mlpmodule.py:559] gpu group tensors cost 0.0006206035614013672 s
DEBUG 01-13 08:46:49.871164.871164 mlpmodule.py:592] gpu pad cost 0.0014791488647460938 s
DEBUG 01-13 08:46:49.871199.871199 mlpmodule.py:598] start_w1
DEBUG 01-13 08:46:49.871707.871707 mlpmodule.py:602] start_w3
DEBUG 01-13 08:46:49.871333.871333 mlpmodule.py:785]  experts func einsum cost 0.05339932441711426 s
DEBUG 01-13 08:46:49.871806.871806 mlpmodule.py:608] start_w2
DEBUG 01-13 08:46:49.872944.872944 mlpmodule.py:611] gpu group einsum cost 0.0006873607635498047 s
DEBUG 01-13 08:46:49.872621.872621 cuda_h.py:19] end experts_func_gpu_einsum_mp cost 0.054436445236206055 seconds
DEBUG 01-13 08:46:49.874779.874779 mlpmodule.py:683] gpu experts func einsum cost 0.0051190853118896484 s
DEBUG 01-13 08:46:49.874749.874749 cuda_h.py:19] end gpu_experts cost 0.005271196365356445 seconds
DEBUG 01-13 08:46:49.874690.874690 cuda_h.py:10] start cpu_thread_manager_mp_wait
DEBUG 01-13 08:46:49.874824.874824 cuda_h.py:19] end cpu_thread_manager_mp_wait cost 3.743171691894531e-05 seconds
DEBUG 01-13 08:46:49.874549.874549 cuda_h.py:19] end layer_moe_generate_mp_l_22 cost 0.0620267391204834 seconds
DEBUG 01-13 08:46:49.874444.874444 lmp.py:1550] -------------------------------- end prefill layer 21 --------------------------------
DEBUG 01-13 08:46:49.874644.874644 lmp.py:1493] -------------------------------- start prefill layer 22 --------------------------------
DEBUG 01-13 08:46:49.874725.874725 cuda_h.py:10] start start_load_qkvogn_s_weight_l_23
DEBUG 01-13 08:46:49.874666.874666 cuda_h.py:10] start start_load_qkvogn_s_weight_l_23
DEBUG 01-13 08:46:49.874164.874164 cuda_h.py:19] end start_load_qkvogn_s_weight_l_23 cost 2.8371810913085938e-05 seconds
DEBUG 01-13 08:46:49.875483.875483 cuda_h.py:19] end start_load_qkvogn_s_weight_l_23 cost 5.5789947509765625e-05 seconds
DEBUG 01-13 08:46:49.875365.875365 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-13 08:46:49.875712.875712 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-13 08:46:49.875390.875390 cuda_h.py:10] start sllm_worker_task
DEBUG 01-13 08:46:49.875942.875942 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-13 08:46:49.875667.875667 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-13 08:46:49.875615.875615 cuda_h.py:19] end allocate_cuda_memory cost 0.0003676414489746094 seconds
DEBUG 01-13 08:46:49.875274.875274 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-13 08:46:49.875322.875322 sllm_store_c.py:27] get device uuid map
DEBUG 01-13 08:46:49.876941.876941 sllm_store_c.py:29] call client load into gpu
DEBUG 01-13 08:46:49.876942.876942 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 180174f3-f545-4e92-b55b-105192337663
DEBUG 01-13 08:46:49.876800.876800 client.py:106] call stub.LoadModelAsync
DEBUG 01-13 08:46:49.876357.876357 cuda_h.py:10] start self_attn
INFO 01-13 08:46:49.877059.877059 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 180174f3-f545-4e92-b55b-105192337663
DEBUG 01-13 08:46:49.877400.877400 cuda_h.py:19] end load_into_gpu_async cost 0.001318216323852539 seconds
DEBUG 01-13 08:46:49.877792.877792 cuda_h.py:10] start restore_tensors2
DEBUG 01-13 08:46:49.877869.877869 cuda_h.py:19] end restore_tensors2 cost 8.273124694824219e-05 seconds
DEBUG 01-13 08:46:49.877050.877050 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0021674633026123047 seconds
INFO 01-13 08:46:49.877370.877370 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 180174f3-f545-4e92-b55b-105192337663
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-13 08:46:49.879224.879224 cuda_h.py:19] end self_attn cost 0.003283262252807617 seconds
DEBUG 01-13 08:46:49.880551.880551 cuda_h.py:19] end iln_self_attn_paln cost 0.004939556121826172 seconds
DEBUG 01-13 08:46:49.880149.880149 cuda_h.py:10] start layer_moe_generate_mp_l_23
DEBUG 01-13 08:46:49.880382.880382 cuda_h.py:10] start gate
DEBUG 01-13 08:46:49.880623.880623 cuda_h.py:19] end gate cost 0.0006372928619384766 seconds
DEBUG 01-13 08:46:49.880883.880883 cuda_h.py:10] start experts_map_get
DEBUG 01-13 08:46:49.881145.881145 lmp.py:1611] 
DEBUG 01-13 08:46:49.881145.881145 lmp.py:1611] Expert Token Distribution & Device Allocation:
DEBUG 01-13 08:46:49.881854.881854 lmp.py:1612]   Total experts: 64
DEBUG 01-13 08:46:49.881696.881696 lmp.py:1613]   CPU experts: 32 (50%)
DEBUG 01-13 08:46:49.881246.881246 lmp.py:1614]   GPU experts: 32 (50%)
DEBUG 01-13 08:46:49.881651.881651 lmp.py:1615] 
DEBUG 01-13 08:46:49.881651.881651 lmp.py:1615]   Expert ID | Tokens | Device
DEBUG 01-13 08:46:49.881532.881532 lmp.py:1616]   -----------------------------------
DEBUG 01-13 08:46:49.881897.881897 lmp.py:1622]   Expert 25 |     16 | CPU
DEBUG 01-13 08:46:49.881732.881732 lmp.py:1622]   Expert 48 |     32 | CPU
DEBUG 01-13 08:46:49.881375.881375 lmp.py:1622]   Expert 45 |     37 | CPU
DEBUG 01-13 08:46:49.881780.881780 lmp.py:1622]   Expert  9 |     58 | CPU
DEBUG 01-13 08:46:49.881469.881469 lmp.py:1622]   Expert 54 |     77 | CPU
DEBUG 01-13 08:46:49.881635.881635 lmp.py:1622]   Expert 20 |     83 | CPU
DEBUG 01-13 08:46:49.881040.881040 lmp.py:1622]   Expert 43 |     83 | CPU
DEBUG 01-13 08:46:49.881875.881875 lmp.py:1622]   Expert  0 |     87 | CPU
DEBUG 01-13 08:46:49.881617.881617 lmp.py:1622]   Expert 47 |     88 | CPU
DEBUG 01-13 08:46:49.881022.881022 lmp.py:1622]   Expert 57 |     90 | CPU
DEBUG 01-13 08:46:49.881188.881188 lmp.py:1622]   Expert  6 |     92 | CPU
DEBUG 01-13 08:46:49.881593.881593 lmp.py:1622]   Expert 13 |     98 | CPU
DEBUG 01-13 08:46:49.881759.881759 lmp.py:1622]   Expert 36 |    101 | CPU
DEBUG 01-13 08:46:49.881687.881687 lmp.py:1622]   Expert  1 |    103 | CPU
DEBUG 01-13 08:46:49.881853.881853 lmp.py:1622]   Expert 46 |    105 | CPU
DEBUG 01-13 08:46:49.881780.881780 lmp.py:1622]   Expert 61 |    105 | CPU
DEBUG 01-13 08:46:49.881708.881708 lmp.py:1622]   Expert 15 |    109 | CPU
DEBUG 01-13 08:46:49.881636.881636 lmp.py:1622]   Expert 62 |    110 | CPU
DEBUG 01-13 08:46:49.881325.881325 lmp.py:1622]   Expert 50 |    111 | CPU
DEBUG 01-13 08:46:49.881028.881028 lmp.py:1622]   Expert 14 |    112 | CPU
DEBUG 01-13 08:46:49.881492.881492 lmp.py:1622]   Expert 38 |    114 | CPU
DEBUG 01-13 08:46:49.881182.881182 lmp.py:1622]   Expert 37 |    115 | CPU
DEBUG 01-13 08:46:49.881109.881109 lmp.py:1622]   Expert 21 |    126 | CPU
DEBUG 01-13 08:46:49.881037.881037 lmp.py:1622]   Expert 28 |    140 | CPU
DEBUG 01-13 08:46:49.881965.881965 lmp.py:1622]   Expert  7 |    143 | CPU
DEBUG 01-13 08:46:49.881701.881701 lmp.py:1622]   Expert 44 |    147 | CPU
DEBUG 01-13 08:46:49.881198.881198 lmp.py:1622]   Expert 10 |    148 | CPU
DEBUG 01-13 08:46:49.881695.881695 lmp.py:1622]   Expert 24 |    151 | CPU
DEBUG 01-13 08:46:49.881669.881669 lmp.py:1622]   Expert 52 |    152 | CPU
DEBUG 01-13 08:46:49.881166.881166 lmp.py:1622]   Expert 42 |    156 | CPU
DEBUG 01-13 08:46:49.881663.881663 lmp.py:1622]   Expert 11 |    162 | CPU
DEBUG 01-13 08:46:49.881161.881161 lmp.py:1622]   Expert  2 |    167 | CPU
DEBUG 01-13 08:46:49.881896.881896 lmp.py:1622]   Expert 26 |    169 | GPU
DEBUG 01-13 08:46:49.881155.881155 lmp.py:1622]   Expert 31 |    172 | GPU
DEBUG 01-13 08:46:49.881891.881891 lmp.py:1622]   Expert 35 |    175 | GPU
DEBUG 01-13 08:46:49.881342.881342 lmp.py:1622]   Expert 32 |    177 | GPU
DEBUG 01-13 08:46:49.881508.881508 lmp.py:1622]   Expert  3 |    186 | GPU
DEBUG 01-13 08:46:49.881197.881197 lmp.py:1622]   Expert 19 |    187 | GPU
DEBUG 01-13 08:46:49.881171.881171 lmp.py:1622]   Expert 12 |    194 | GPU
DEBUG 01-13 08:46:49.881907.881907 lmp.py:1622]   Expert 60 |    196 | GPU
DEBUG 01-13 08:46:49.881642.881642 lmp.py:1622]   Expert 40 |    210 | GPU
DEBUG 01-13 08:46:49.881378.881378 lmp.py:1622]   Expert 56 |    211 | GPU
DEBUG 01-13 08:46:49.881114.881114 lmp.py:1622]   Expert 41 |    214 | GPU
DEBUG 01-13 08:46:49.881611.881611 lmp.py:1622]   Expert 16 |    228 | GPU
DEBUG 01-13 08:46:49.881346.881346 lmp.py:1622]   Expert 53 |    229 | GPU
DEBUG 01-13 08:46:49.882082.882082 lmp.py:1622]   Expert 58 |    229 | GPU
DEBUG 01-13 08:46:49.882579.882579 lmp.py:1622]   Expert 23 |    234 | GPU
DEBUG 01-13 08:46:49.882076.882076 lmp.py:1622]   Expert 51 |    235 | GPU
DEBUG 01-13 08:46:49.882050.882050 lmp.py:1622]   Expert  8 |    241 | GPU
DEBUG 01-13 08:46:49.882740.882740 lmp.py:1622]   Expert 59 |    249 | GPU
DEBUG 01-13 08:46:49.882667.882667 lmp.py:1622]   Expert  4 |    260 | GPU
DEBUG 01-13 08:46:49.882357.882357 lmp.py:1622]   Expert 49 |    265 | GPU
DEBUG 01-13 08:46:49.882331.882331 lmp.py:1622]   Expert 55 |    281 | GPU
DEBUG 01-13 08:46:49.882066.882066 lmp.py:1622]   Expert 29 |    283 | GPU
DEBUG 01-13 08:46:49.882325.882325 lmp.py:1622]   Expert 18 |    286 | GPU
DEBUG 01-13 08:46:49.882822.882822 lmp.py:1622]   Expert 34 |    286 | GPU
DEBUG 01-13 08:46:49.882558.882558 lmp.py:1622]   Expert 63 |    295 | GPU
DEBUG 01-13 08:46:49.882055.882055 lmp.py:1622]   Expert 27 |    351 | GPU
DEBUG 01-13 08:46:49.882552.882552 lmp.py:1622]   Expert 39 |    376 | GPU
DEBUG 01-13 08:46:49.882050.882050 lmp.py:1622]   Expert 17 |    391 | GPU
DEBUG 01-13 08:46:49.882547.882547 lmp.py:1622]   Expert 22 |    428 | GPU
DEBUG 01-13 08:46:49.882806.882806 lmp.py:1622]   Expert 30 |    446 | GPU
DEBUG 01-13 08:46:49.882541.882541 lmp.py:1622]   Expert 33 |    467 | GPU
DEBUG 01-13 08:46:49.882039.882039 lmp.py:1622]   Expert  5 |    719 | GPU
DEBUG 01-13 08:46:49.882443.882443 lmp.py:1623] 
DEBUG 01-13 08:46:49.882443.882443 lmp.py:1623]   CPU total tokens: 3418 (27.8%)
DEBUG 01-13 08:46:49.882040.882040 lmp.py:1624]   GPU total tokens: 8870 (72.2%)
DEBUG 01-13 08:46:49.882259.882259 cuda_h.py:19] end experts_map_get cost 0.0015130043029785156 seconds
DEBUG 01-13 08:46:49.882625.882625 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-13 08:46:49.882282.882282 lmp.py:1632] 
DEBUG 01-13 08:46:49.882282.882282 lmp.py:1632]   Computing 32 experts on CPU MP...
DEBUG 01-13 08:46:49.882535.882535 cuda_h.py:19] end cpu_experts_submit cost 4.6253204345703125e-05 seconds
DEBUG 01-13 08:46:49.882821.882821 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-13 08:46:49.882174.882174 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-13 08:46:49.882741.882741 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-13 08:46:49.883383.883383 cuda_h.py:19] end allocate_cuda_memory cost 0.0011420249938964844 seconds
DEBUG 01-13 08:46:49.884071.884071 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-13 08:46:49.884509.884509 sllm_store_c.py:27] get device uuid map
DEBUG 01-13 08:46:49.884809.884809 sllm_store_c.py:29] call client load into gpu
DEBUG 01-13 08:46:49.884558.884558 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 90861840-cab0-470e-8379-747b94b1704b
DEBUG 01-13 08:46:49.884968.884968 client.py:106] call stub.LoadModelAsync
INFO 01-13 08:46:49.885094.885094 client.py:127] Model loaded
DEBUG 01-13 08:46:49.885508.885508 cuda_h.py:10] start restore2model
DEBUG 01-13 08:46:49.885124.885124 cuda_h.py:10] start experts_func_gpu_einsum_mp
DEBUG 01-13 08:46:49.885212.885212 cuda_h.py:19] end restore2model cost 0.0005903244018554688 seconds
DEBUG 01-13 08:46:49.885129.885129 cuda_h.py:19] end sllm_worker_task cost 0.010709524154663086 seconds
INFO 01-13 08:46:49.886347.886347 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 90861840-cab0-470e-8379-747b94b1704b
DEBUG 01-13 08:46:49.886190.886190 cuda_h.py:19] end load_into_gpu_async cost 0.0019397735595703125 seconds
DEBUG 01-13 08:46:49.886608.886608 cuda_h.py:10] start restore_tensors2
DEBUG 01-13 08:46:49.887736.887736 cuda_h.py:19] end restore_tensors2 cost 0.0004177093505859375 seconds
DEBUG 01-13 08:46:49.887148.887148 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.004556179046630859 seconds
DEBUG 01-13 08:46:49.887341.887341 cuda_h.py:10] start restore2model
DEBUG 01-13 08:46:49.889074.889074 cuda_h.py:19] end restore2model cost 0.002653837203979492 seconds
DEBUG 01-13 08:46:49.889294.889294 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.0073833465576171875 seconds
DEBUG 01-13 08:46:49.889395.889395 cuda_h.py:10] start gpu_sexperts
DEBUG 01-13 08:46:49.890365.890365 cuda_h.py:19] end gpu_sexperts cost 0.0002636909484863281 seconds
DEBUG 01-13 08:46:49.890479.890479 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-13 08:46:49.890633.890633 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 1.52587890625e-05 seconds
DEBUG 01-13 08:46:49.890375.890375 cuda_h.py:10] start wait_experts
INFO 01-13 08:46:49.890071.890071 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 90861840-cab0-470e-8379-747b94b1704b
DEBUG 01-13 08:46:49.897099.897099 mlpmodule.py:1006] group tensors cost 0.011663436889648438 s
DEBUG 01-13 08:46:49.901264.901264 mlpmodule.py:1044] pad cost 0.0033516883850097656 s
DEBUG 01-13 08:46:49.901612.901612 mlpmodule.py:1050] create cpu tensor cost 5.435943603515625e-05 s
DEBUG 01-13 08:46:49.902807.902807 mlpmodule.py:1055] move to cpu cost 3.910064697265625e-05 s
DEBUG 01-13 08:46:49.910500.910500 mlpmodule.py:1069] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-13 08:46:49.911739.911739 mlpmodule.py:1070] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-13 08:46:49.911431.911431 mlpmodule.py:1075] group_w3 first element: -0.018798828125
WARNING 01-13 08:46:49.911153.911153 mlpmodule.py:1085] start einsum2
DEBUG 01-13 08:46:49.924731.924731 mlpmodule.py:1095] group einsum cost 0.02257370948791504 s
DEBUG 01-13 08:46:49.925287.925287 mlpmodule.py:1103] cpy2cputensor cost 0.0007257461547851562 s
INFO 01-13 08:46:49.938562.938562 client.py:127] Model loaded
DEBUG 01-13 08:46:49.938084.938084 cuda_h.py:19] end wait_experts cost 0.0482327938079834 seconds
DEBUG 01-13 08:46:49.938755.938755 cuda_h.py:10] start gpu_experts
DEBUG 01-13 08:46:49.939086.939086 mlpmodule.py:785]  experts func einsum cost 0.053433895111083984 s
DEBUG 01-13 08:46:49.939843.939843 mlpmodule.py:559] gpu group tensors cost 0.0007598400115966797 s
DEBUG 01-13 08:46:49.939289.939289 cuda_h.py:19] end experts_func_gpu_einsum_mp cost 0.054460763931274414 seconds
DEBUG 01-13 08:46:49.941007.941007 mlpmodule.py:592] gpu pad cost 0.0016570091247558594 s
DEBUG 01-13 08:46:49.941130.941130 mlpmodule.py:598] start_w1
DEBUG 01-13 08:46:49.941906.941906 mlpmodule.py:602] start_w3
DEBUG 01-13 08:46:49.941574.941574 mlpmodule.py:608] start_w2
DEBUG 01-13 08:46:49.942122.942122 mlpmodule.py:611] gpu group einsum cost 0.0007662773132324219 s
DEBUG 01-13 08:46:49.944965.944965 mlpmodule.py:683] gpu experts func einsum cost 0.00558781623840332 s
DEBUG 01-13 08:46:49.944011.944011 cuda_h.py:19] end gpu_experts cost 0.0058460235595703125 seconds
DEBUG 01-13 08:46:49.944813.944813 cuda_h.py:10] start cpu_thread_manager_mp_wait
DEBUG 01-13 08:46:49.944147.944147 cuda_h.py:19] end cpu_thread_manager_mp_wait cost 4.100799560546875e-05 seconds
DEBUG 01-13 08:46:49.944832.944832 cuda_h.py:19] end layer_moe_generate_mp_l_23 cost 0.06465935707092285 seconds
DEBUG 01-13 08:46:49.944912.944912 lmp.py:1550] -------------------------------- end prefill layer 22 --------------------------------
DEBUG 01-13 08:46:49.945404.945404 lmp.py:1493] -------------------------------- start prefill layer 23 --------------------------------
DEBUG 01-13 08:46:49.945961.945961 cuda_h.py:10] start start_load_qkvogn_s_weight_l_24
DEBUG 01-13 08:46:49.945571.945571 cuda_h.py:10] start start_load_qkvogn_s_weight_l_24
DEBUG 01-13 08:46:49.945077.945077 cuda_h.py:19] end start_load_qkvogn_s_weight_l_24 cost 3.218650817871094e-05 seconds
DEBUG 01-13 08:46:49.945761.945761 cuda_h.py:10] start sllm_worker_task
DEBUG 01-13 08:46:49.945313.945313 cuda_h.py:19] end start_load_qkvogn_s_weight_l_24 cost 0.00017118453979492188 seconds
DEBUG 01-13 08:46:49.945845.945845 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-13 08:46:49.945522.945522 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-13 08:46:49.945710.945710 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-13 08:46:49.945075.945075 cuda_h.py:19] end allocate_cuda_memory cost 0.0003299713134765625 seconds
DEBUG 01-13 08:46:49.945070.945070 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-13 08:46:49.945972.945972 sllm_store_c.py:27] get device uuid map
DEBUG 01-13 08:46:49.946887.946887 sllm_store_c.py:29] call client load into gpu
DEBUG 01-13 08:46:49.946875.946875 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 9a12518e-e0bf-4151-b50a-a35365f346c8
DEBUG 01-13 08:46:49.946322.946322 client.py:106] call stub.LoadModelAsync
DEBUG 01-13 08:46:49.946889.946889 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-13 08:46:49.946489.946489 cuda_h.py:10] start self_attn
INFO 01-13 08:46:49.947594.947594 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 9a12518e-e0bf-4151-b50a-a35365f346c8
DEBUG 01-13 08:46:49.947569.947569 cuda_h.py:19] end load_into_gpu_async cost 0.0012123584747314453 seconds
DEBUG 01-13 08:46:49.947888.947888 cuda_h.py:10] start restore_tensors2
DEBUG 01-13 08:46:49.947394.947394 cuda_h.py:19] end restore_tensors2 cost 6.723403930664062e-05 seconds
DEBUG 01-13 08:46:49.947243.947243 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0018930435180664062 seconds
INFO 01-13 08:46:49.947549.947549 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 9a12518e-e0bf-4151-b50a-a35365f346c8
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-13 08:46:49.949936.949936 cuda_h.py:19] end self_attn cost 0.0028395652770996094 seconds
DEBUG 01-13 08:46:49.949390.949390 cuda_h.py:19] end iln_self_attn_paln cost 0.0042459964752197266 seconds
DEBUG 01-13 08:46:49.949611.949611 cuda_h.py:10] start layer_moe_generate_mp_l_24
DEBUG 01-13 08:46:49.949036.949036 cuda_h.py:10] start gate
DEBUG 01-13 08:46:49.950448.950448 cuda_h.py:19] end gate cost 0.0006225109100341797 seconds
DEBUG 01-13 08:46:49.950801.950801 cuda_h.py:10] start experts_map_get
DEBUG 01-13 08:46:49.950632.950632 lmp.py:1611] 
DEBUG 01-13 08:46:49.950632.950632 lmp.py:1611] Expert Token Distribution & Device Allocation:
DEBUG 01-13 08:46:49.950103.950103 lmp.py:1612]   Total experts: 64
DEBUG 01-13 08:46:49.950468.950468 lmp.py:1613]   CPU experts: 32 (50%)
DEBUG 01-13 08:46:49.950780.950780 lmp.py:1614]   GPU experts: 32 (50%)
DEBUG 01-13 08:46:49.950423.950423 lmp.py:1615] 
DEBUG 01-13 08:46:49.950423.950423 lmp.py:1615]   Expert ID | Tokens | Device
DEBUG 01-13 08:46:49.950543.950543 lmp.py:1616]   -----------------------------------
DEBUG 01-13 08:46:49.950193.950193 lmp.py:1622]   Expert  5 |      8 | CPU
DEBUG 01-13 08:46:49.951313.951313 lmp.py:1622]   Expert 56 |     28 | CPU
DEBUG 01-13 08:46:49.951479.951479 lmp.py:1622]   Expert 27 |     76 | CPU
DEBUG 01-13 08:46:49.951406.951406 lmp.py:1622]   Expert 16 |     84 | CPU
DEBUG 01-13 08:46:49.951096.951096 lmp.py:1622]   Expert 40 |     87 | CPU
DEBUG 01-13 08:46:49.951262.951262 lmp.py:1622]   Expert 17 |     89 | CPU
DEBUG 01-13 08:46:49.951666.951666 lmp.py:1622]   Expert 53 |     89 | CPU
DEBUG 01-13 08:46:49.951833.951833 lmp.py:1622]   Expert 49 |    102 | CPU
DEBUG 01-13 08:46:49.951237.951237 lmp.py:1622]   Expert  7 |    103 | CPU
DEBUG 01-13 08:46:49.951165.951165 lmp.py:1622]   Expert 28 |    105 | CPU
DEBUG 01-13 08:46:49.951377.951377 lmp.py:1622]   Expert 51 |    105 | CPU
DEBUG 01-13 08:46:49.951067.951067 lmp.py:1622]   Expert 63 |    107 | CPU
DEBUG 01-13 08:46:49.951517.951517 lmp.py:1622]   Expert 58 |    118 | CPU
DEBUG 01-13 08:46:49.951968.951968 lmp.py:1622]   Expert 11 |    121 | CPU
DEBUG 01-13 08:46:49.951181.951181 lmp.py:1622]   Expert 38 |    125 | CPU
DEBUG 01-13 08:46:49.951393.951393 lmp.py:1622]   Expert 47 |    127 | CPU
DEBUG 01-13 08:46:49.951844.951844 lmp.py:1622]   Expert 37 |    132 | CPU
DEBUG 01-13 08:46:49.951533.951533 lmp.py:1622]   Expert 62 |    141 | CPU
DEBUG 01-13 08:46:49.951984.951984 lmp.py:1622]   Expert 57 |    142 | CPU
DEBUG 01-13 08:46:49.951627.951627 lmp.py:1622]   Expert 39 |    144 | CPU
DEBUG 01-13 08:46:49.951793.951793 lmp.py:1622]   Expert 14 |    146 | CPU
DEBUG 01-13 08:46:49.951436.951436 lmp.py:1622]   Expert  1 |    147 | CPU
DEBUG 01-13 08:46:49.951841.951841 lmp.py:1622]   Expert 25 |    150 | CPU
DEBUG 01-13 08:46:49.951530.951530 lmp.py:1622]   Expert 52 |    156 | CPU
DEBUG 01-13 08:46:49.951220.951220 lmp.py:1622]   Expert 23 |    162 | CPU
DEBUG 01-13 08:46:49.951670.951670 lmp.py:1622]   Expert 33 |    163 | CPU
DEBUG 01-13 08:46:49.951360.951360 lmp.py:1622]   Expert  6 |    172 | CPU
DEBUG 01-13 08:46:49.951811.951811 lmp.py:1622]   Expert 21 |    172 | CPU
DEBUG 01-13 08:46:49.951023.951023 lmp.py:1622]   Expert 45 |    173 | CPU
DEBUG 01-13 08:46:49.951474.951474 lmp.py:1622]   Expert 60 |    174 | CPU
DEBUG 01-13 08:46:49.951686.951686 lmp.py:1622]   Expert 30 |    175 | CPU
DEBUG 01-13 08:46:49.951137.951137 lmp.py:1622]   Expert 19 |    183 | CPU
DEBUG 01-13 08:46:49.951827.951827 lmp.py:1622]   Expert 44 |    183 | GPU
DEBUG 01-13 08:46:49.951470.951470 lmp.py:1622]   Expert  4 |    184 | GPU
DEBUG 01-13 08:46:49.951636.951636 lmp.py:1622]   Expert  3 |    190 | GPU
DEBUG 01-13 08:46:49.951279.951279 lmp.py:1622]   Expert 12 |    196 | GPU
DEBUG 01-13 08:46:49.951683.951683 lmp.py:1622]   Expert 31 |    197 | GPU
DEBUG 01-13 08:46:49.951373.951373 lmp.py:1622]   Expert 36 |    203 | GPU
DEBUG 01-13 08:46:49.951062.951062 lmp.py:1622]   Expert 55 |    203 | GPU
DEBUG 01-13 08:46:49.951990.951990 lmp.py:1622]   Expert  9 |    216 | GPU
DEBUG 01-13 08:46:49.951202.951202 lmp.py:1622]   Expert 41 |    216 | GPU
DEBUG 01-13 08:46:49.951130.951130 lmp.py:1622]   Expert  0 |    220 | GPU
DEBUG 01-13 08:46:49.951581.951581 lmp.py:1622]   Expert 22 |    221 | GPU
DEBUG 01-13 08:46:49.951270.951270 lmp.py:1622]   Expert 34 |    226 | GPU
DEBUG 01-13 08:46:49.951482.951482 lmp.py:1622]   Expert 43 |    237 | GPU
DEBUG 01-13 08:46:49.951410.951410 lmp.py:1622]   Expert 26 |    238 | GPU
DEBUG 01-13 08:46:49.951861.951861 lmp.py:1622]   Expert 54 |    238 | GPU
DEBUG 01-13 08:46:49.951550.951550 lmp.py:1622]   Expert 18 |    249 | GPU
DEBUG 01-13 08:46:49.951716.951716 lmp.py:1622]   Expert 59 |    252 | GPU
DEBUG 01-13 08:46:49.951883.951883 lmp.py:1622]   Expert 13 |    253 | GPU
DEBUG 01-13 08:46:49.951526.951526 lmp.py:1622]   Expert 50 |    260 | GPU
DEBUG 01-13 08:46:49.951930.951930 lmp.py:1622]   Expert 15 |    263 | GPU
DEBUG 01-13 08:46:49.951858.951858 lmp.py:1622]   Expert 29 |    266 | GPU
DEBUG 01-13 08:46:49.951070.951070 lmp.py:1622]   Expert 61 |    267 | GPU
DEBUG 01-13 08:46:49.951760.951760 lmp.py:1622]   Expert 20 |    268 | GPU
DEBUG 01-13 08:46:49.951211.951211 lmp.py:1622]   Expert 24 |    270 | GPU
DEBUG 01-13 08:46:49.951138.951138 lmp.py:1622]   Expert 42 |    270 | GPU
DEBUG 01-13 08:46:49.951589.951589 lmp.py:1622]   Expert 35 |    276 | GPU
DEBUG 01-13 08:46:49.951278.951278 lmp.py:1622]   Expert 32 |    299 | GPU
DEBUG 01-13 08:46:49.951968.951968 lmp.py:1622]   Expert  2 |    331 | GPU
DEBUG 01-13 08:46:49.951657.951657 lmp.py:1622]   Expert  8 |    346 | GPU
DEBUG 01-13 08:46:49.952300.952300 lmp.py:1622]   Expert 10 |    369 | GPU
DEBUG 01-13 08:46:49.952943.952943 lmp.py:1622]   Expert 46 |    430 | GPU
DEBUG 01-13 08:46:49.952586.952586 lmp.py:1622]   Expert 48 |    445 | GPU
DEBUG 01-13 08:46:49.952706.952706 lmp.py:1623] 
DEBUG 01-13 08:46:49.952706.952706 lmp.py:1623]   CPU total tokens: 4006 (32.6%)
DEBUG 01-13 08:46:49.952064.952064 lmp.py:1624]   GPU total tokens: 8282 (67.4%)
DEBUG 01-13 08:46:49.952760.952760 cuda_h.py:19] end experts_map_get cost 0.0015225410461425781 seconds
DEBUG 01-13 08:46:49.952510.952510 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-13 08:46:49.952644.952644 lmp.py:1632] 
DEBUG 01-13 08:46:49.952644.952644 lmp.py:1632]   Computing 32 experts on CPU MP...
DEBUG 01-13 08:46:49.952851.952851 cuda_h.py:19] end cpu_experts_submit cost 4.744529724121094e-05 seconds
DEBUG 01-13 08:46:49.952116.952116 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-13 08:46:49.952946.952946 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-13 08:46:49.952547.952547 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-13 08:46:49.953026.953026 cuda_h.py:19] end allocate_cuda_memory cost 0.0011937618255615234 seconds
DEBUG 01-13 08:46:49.953584.953584 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-13 08:46:49.954028.954028 sllm_store_c.py:27] get device uuid map
DEBUG 01-13 08:46:49.954374.954374 sllm_store_c.py:29] call client load into gpu
DEBUG 01-13 08:46:49.954646.954646 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, eacb904b-28e1-4b1b-b80f-c5e960279b8c
DEBUG 01-13 08:46:49.954911.954911 client.py:106] call stub.LoadModelAsync
DEBUG 01-13 08:46:49.954463.954463 cuda_h.py:10] start experts_func_gpu_einsum_mp
INFO 01-13 08:46:49.955569.955569 client.py:127] Model loaded
DEBUG 01-13 08:46:49.955041.955041 cuda_h.py:10] start restore2model
DEBUG 01-13 08:46:49.955322.955322 cuda_h.py:19] end restore2model cost 0.0004012584686279297 seconds
DEBUG 01-13 08:46:49.955820.955820 cuda_h.py:19] end sllm_worker_task cost 0.010524272918701172 seconds
INFO 01-13 08:46:49.956248.956248 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, eacb904b-28e1-4b1b-b80f-c5e960279b8c
DEBUG 01-13 08:46:49.956330.956330 cuda_h.py:19] end load_into_gpu_async cost 0.0019073486328125 seconds
DEBUG 01-13 08:46:49.956841.956841 cuda_h.py:10] start restore_tensors2
DEBUG 01-13 08:46:49.956267.956267 cuda_h.py:19] end restore_tensors2 cost 0.0004267692565917969 seconds
DEBUG 01-13 08:46:49.956302.956302 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.004277706146240234 seconds
DEBUG 01-13 08:46:49.956687.956687 cuda_h.py:10] start restore2model
DEBUG 01-13 08:46:49.959204.959204 cuda_h.py:19] end restore2model cost 0.002565622329711914 seconds
DEBUG 01-13 08:46:49.959716.959716 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.007021427154541016 seconds
DEBUG 01-13 08:46:49.959320.959320 cuda_h.py:10] start gpu_sexperts
DEBUG 01-13 08:46:49.959283.959283 cuda_h.py:19] end gpu_sexperts cost 0.0002589225769042969 seconds
DEBUG 01-13 08:46:49.959159.959159 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-13 08:46:49.959028.959028 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 1.5497207641601562e-05 seconds
DEBUG 01-13 08:46:49.959155.959155 cuda_h.py:10] start wait_experts
INFO 01-13 08:46:49.959804.959804 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, eacb904b-28e1-4b1b-b80f-c5e960279b8c
DEBUG 01-13 08:46:49.972978.972978 mlpmodule.py:1006] group tensors cost 0.01651597023010254 s
DEBUG 01-13 08:46:49.976090.976090 mlpmodule.py:1044] pad cost 0.002844095230102539 s
DEBUG 01-13 08:46:49.976672.976672 mlpmodule.py:1050] create cpu tensor cost 6.985664367675781e-05 s
DEBUG 01-13 08:46:49.976946.976946 mlpmodule.py:1055] move to cpu cost 4.7206878662109375e-05 s
DEBUG 01-13 08:46:49.985169.985169 mlpmodule.py:1069] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-13 08:46:49.985653.985653 mlpmodule.py:1070] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-13 08:46:49.985108.985108 mlpmodule.py:1075] group_w3 first element: 0.08447265625
WARNING 01-13 08:46:49.985371.985371 mlpmodule.py:1085] start einsum2
DEBUG 01-13 08:46:50.000784.000784 mlpmodule.py:1095] group einsum cost 0.02372908592224121 s
DEBUG 01-13 08:46:50.001342.001342 mlpmodule.py:1103] cpy2cputensor cost 0.0007846355438232422 s
INFO 01-13 08:46:50.008231.008231 client.py:127] Model loaded
DEBUG 01-13 08:46:50.008654.008654 cuda_h.py:19] end wait_experts cost 0.04849815368652344 seconds
DEBUG 01-13 08:46:50.008609.008609 cuda_h.py:10] start gpu_experts
DEBUG 01-13 08:46:50.009248.009248 mlpmodule.py:559] gpu group tensors cost 0.0007636547088623047 s
DEBUG 01-13 08:46:50.011014.011014 mlpmodule.py:592] gpu pad cost 0.0018258094787597656 s
DEBUG 01-13 08:46:50.011222.011222 mlpmodule.py:598] start_w1
DEBUG 01-13 08:46:50.011637.011637 mlpmodule.py:602] start_w3
DEBUG 01-13 08:46:50.011041.011041 mlpmodule.py:608] start_w2
DEBUG 01-13 08:46:50.011039.011039 mlpmodule.py:611] gpu group einsum cost 0.0006742477416992188 s
DEBUG 01-13 08:46:50.014180.014180 mlpmodule.py:785]  experts func einsum cost 0.05898237228393555 s
DEBUG 01-13 08:46:50.014451.014451 mlpmodule.py:683] gpu experts func einsum cost 0.006215333938598633 s
DEBUG 01-13 08:46:50.014615.014615 cuda_h.py:19] end gpu_experts cost 0.006468296051025391 seconds
DEBUG 01-13 08:46:50.014139.014139 cuda_h.py:10] start cpu_thread_manager_mp_wait
DEBUG 01-13 08:46:50.014049.014049 cuda_h.py:19] end cpu_thread_manager_mp_wait cost 4.029273986816406e-05 seconds
DEBUG 01-13 08:46:50.015264.015264 cuda_h.py:19] end layer_moe_generate_mp_l_24 cost 0.06516313552856445 seconds
DEBUG 01-13 08:46:50.015118.015118 cuda_h.py:19] end experts_func_gpu_einsum_mp cost 0.05998373031616211 seconds
DEBUG 01-13 08:46:50.015426.015426 lmp.py:1550] -------------------------------- end prefill layer 23 --------------------------------
DEBUG 01-13 08:46:50.015918.015918 lmp.py:1493] -------------------------------- start prefill layer 24 --------------------------------
DEBUG 01-13 08:46:50.015243.015243 cuda_h.py:10] start start_load_qkvogn_s_weight_l_25
DEBUG 01-13 08:46:50.015098.015098 cuda_h.py:10] start start_load_qkvogn_s_weight_l_25
DEBUG 01-13 08:46:50.015379.015379 cuda_h.py:19] end start_load_qkvogn_s_weight_l_25 cost 3.719329833984375e-05 seconds
DEBUG 01-13 08:46:50.015845.015845 cuda_h.py:10] start sllm_worker_task
DEBUG 01-13 08:46:50.015912.015912 cuda_h.py:19] end start_load_qkvogn_s_weight_l_25 cost 0.00014925003051757812 seconds
DEBUG 01-13 08:46:50.015259.015259 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-13 08:46:50.015566.015566 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-13 08:46:50.015661.015661 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-13 08:46:50.016034.016034 cuda_h.py:19] end allocate_cuda_memory cost 0.0003688335418701172 seconds
DEBUG 01-13 08:46:50.016693.016693 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-13 08:46:50.016009.016009 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-13 08:46:50.016529.016529 sllm_store_c.py:27] get device uuid map
DEBUG 01-13 08:46:50.016597.016597 sllm_store_c.py:29] call client load into gpu
DEBUG 01-13 08:46:50.016254.016254 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 48e9dc81-fd69-42d0-b9c2-f40fcbbb0f6b
DEBUG 01-13 08:46:50.016276.016276 client.py:106] call stub.LoadModelAsync
DEBUG 01-13 08:46:50.017899.017899 cuda_h.py:10] start self_attn
INFO 01-13 08:46:50.018222.018222 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 48e9dc81-fd69-42d0-b9c2-f40fcbbb0f6b
DEBUG 01-13 08:46:50.018350.018350 cuda_h.py:19] end load_into_gpu_async cost 0.0017628669738769531 seconds
DEBUG 01-13 08:46:50.018622.018622 cuda_h.py:10] start restore_tensors2
DEBUG 01-13 08:46:50.018705.018705 cuda_h.py:19] end restore_tensors2 cost 7.05718994140625e-05 seconds
DEBUG 01-13 08:46:50.018507.018507 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.002755880355834961 seconds
INFO 01-13 08:46:50.018814.018814 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 48e9dc81-fd69-42d0-b9c2-f40fcbbb0f6b
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-13 08:46:50.020625.020625 cuda_h.py:19] end self_attn cost 0.0030341148376464844 seconds
DEBUG 01-13 08:46:50.020629.020629 cuda_h.py:19] end iln_self_attn_paln cost 0.004737377166748047 seconds
DEBUG 01-13 08:46:50.020995.020995 cuda_h.py:10] start layer_moe_generate_mp_l_25
DEBUG 01-13 08:46:50.020566.020566 cuda_h.py:10] start gate
DEBUG 01-13 08:46:50.021622.021622 cuda_h.py:19] end gate cost 0.0006387233734130859 seconds
DEBUG 01-13 08:46:50.021166.021166 cuda_h.py:10] start experts_map_get
DEBUG 01-13 08:46:50.021243.021243 lmp.py:1611] 
DEBUG 01-13 08:46:50.021243.021243 lmp.py:1611] Expert Token Distribution & Device Allocation:
DEBUG 01-13 08:46:50.021807.021807 lmp.py:1612]   Total experts: 64
DEBUG 01-13 08:46:50.021172.021172 lmp.py:1613]   CPU experts: 32 (50%)
DEBUG 01-13 08:46:50.021768.021768 lmp.py:1614]   GPU experts: 32 (50%)
DEBUG 01-13 08:46:50.021934.021934 lmp.py:1615] 
DEBUG 01-13 08:46:50.021934.021934 lmp.py:1615]   Expert ID | Tokens | Device
DEBUG 01-13 08:46:50.021101.021101 lmp.py:1616]   -----------------------------------
DEBUG 01-13 08:46:50.021227.021227 lmp.py:1622]   Expert 36 |     28 | CPU
DEBUG 01-13 08:46:50.021155.021155 lmp.py:1622]   Expert 35 |     29 | CPU
DEBUG 01-13 08:46:50.021129.021129 lmp.py:1622]   Expert 46 |     39 | CPU
DEBUG 01-13 08:46:50.021772.021772 lmp.py:1622]   Expert 25 |     44 | CPU
DEBUG 01-13 08:46:50.021938.021938 lmp.py:1622]   Expert 51 |     48 | CPU
DEBUG 01-13 08:46:50.021866.021866 lmp.py:1622]   Expert 16 |     58 | CPU
DEBUG 01-13 08:46:50.021794.021794 lmp.py:1622]   Expert  0 |     65 | CPU
DEBUG 01-13 08:46:50.021483.021483 lmp.py:1622]   Expert 30 |     65 | CPU
DEBUG 01-13 08:46:50.021364.021364 lmp.py:1622]   Expert 43 |     66 | CPU
DEBUG 01-13 08:46:50.021769.021769 lmp.py:1622]   Expert 42 |     67 | CPU
DEBUG 01-13 08:46:50.022935.022935 lmp.py:1622]   Expert 47 |     73 | CPU
DEBUG 01-13 08:46:50.022339.022339 lmp.py:1622]   Expert 44 |     74 | CPU
DEBUG 01-13 08:46:50.022744.022744 lmp.py:1622]   Expert 55 |     74 | CPU
DEBUG 01-13 08:46:50.022672.022672 lmp.py:1622]   Expert 39 |     75 | CPU
DEBUG 01-13 08:46:50.022361.022361 lmp.py:1622]   Expert  2 |     90 | CPU
DEBUG 01-13 08:46:50.022289.022289 lmp.py:1622]   Expert  4 |    107 | CPU
DEBUG 01-13 08:46:50.022978.022978 lmp.py:1622]   Expert 48 |    111 | CPU
DEBUG 01-13 08:46:50.022906.022906 lmp.py:1622]   Expert  6 |    117 | CPU
DEBUG 01-13 08:46:50.022595.022595 lmp.py:1622]   Expert 33 |    117 | CPU
DEBUG 01-13 08:46:50.022284.022284 lmp.py:1622]   Expert 61 |    121 | CPU
DEBUG 01-13 08:46:50.022451.022451 lmp.py:1622]   Expert 13 |    125 | CPU
DEBUG 01-13 08:46:50.022378.022378 lmp.py:1622]   Expert 24 |    127 | CPU
DEBUG 01-13 08:46:50.022260.022260 lmp.py:1622]   Expert 56 |    130 | CPU
DEBUG 01-13 08:46:50.022664.022664 lmp.py:1622]   Expert 15 |    134 | CPU
DEBUG 01-13 08:46:50.022069.022069 lmp.py:1622]   Expert 20 |    134 | CPU
DEBUG 01-13 08:46:50.022996.022996 lmp.py:1622]   Expert 54 |    137 | CPU
DEBUG 01-13 08:46:50.022924.022924 lmp.py:1622]   Expert  9 |    138 | CPU
DEBUG 01-13 08:46:50.022375.022375 lmp.py:1622]   Expert  7 |    143 | CPU
DEBUG 01-13 08:46:50.022303.022303 lmp.py:1622]   Expert 29 |    143 | CPU
DEBUG 01-13 08:46:50.022754.022754 lmp.py:1622]   Expert 38 |    144 | CPU
DEBUG 01-13 08:46:50.022443.022443 lmp.py:1622]   Expert 59 |    149 | CPU
DEBUG 01-13 08:46:50.022894.022894 lmp.py:1622]   Expert 45 |    154 | CPU
DEBUG 01-13 08:46:50.022345.022345 lmp.py:1622]   Expert 19 |    161 | GPU
DEBUG 01-13 08:46:50.022511.022511 lmp.py:1622]   Expert 62 |    163 | GPU
DEBUG 01-13 08:46:50.022677.022677 lmp.py:1622]   Expert 34 |    182 | GPU
DEBUG 01-13 08:46:50.022082.022082 lmp.py:1622]   Expert 57 |    191 | GPU
DEBUG 01-13 08:46:50.022486.022486 lmp.py:1622]   Expert 50 |    197 | GPU
DEBUG 01-13 08:46:50.022891.022891 lmp.py:1622]   Expert 23 |    210 | GPU
DEBUG 01-13 08:46:50.022818.022818 lmp.py:1622]   Expert 10 |    212 | GPU
DEBUG 01-13 08:46:50.022508.022508 lmp.py:1622]   Expert 31 |    213 | GPU
DEBUG 01-13 08:46:50.022435.022435 lmp.py:1622]   Expert  8 |    214 | GPU
DEBUG 01-13 08:46:50.022886.022886 lmp.py:1622]   Expert 18 |    219 | GPU
DEBUG 01-13 08:46:50.022337.022337 lmp.py:1622]   Expert 53 |    220 | GPU
DEBUG 01-13 08:46:50.022788.022788 lmp.py:1622]   Expert 22 |    223 | GPU
DEBUG 01-13 08:46:50.022477.022477 lmp.py:1622]   Expert 60 |    224 | GPU
DEBUG 01-13 08:46:50.022643.022643 lmp.py:1622]   Expert 37 |    227 | GPU
DEBUG 01-13 08:46:50.022048.022048 lmp.py:1622]   Expert 52 |    228 | GPU
DEBUG 01-13 08:46:50.022214.022214 lmp.py:1622]   Expert  5 |    237 | GPU
DEBUG 01-13 08:46:50.022619.022619 lmp.py:1622]   Expert 17 |    246 | GPU
DEBUG 01-13 08:46:50.022262.022262 lmp.py:1622]   Expert 11 |    259 | GPU
DEBUG 01-13 08:46:50.022428.022428 lmp.py:1622]   Expert  1 |    279 | GPU
DEBUG 01-13 08:46:50.022640.022640 lmp.py:1622]   Expert 49 |    280 | GPU
DEBUG 01-13 08:46:50.022330.022330 lmp.py:1622]   Expert 28 |    281 | GPU
DEBUG 01-13 08:46:50.022781.022781 lmp.py:1622]   Expert 41 |    281 | GPU
DEBUG 01-13 08:46:50.022231.022231 lmp.py:1622]   Expert 26 |    285 | GPU
DEBUG 01-13 08:46:50.022682.022682 lmp.py:1622]   Expert 32 |    285 | GPU
DEBUG 01-13 08:46:50.022133.022133 lmp.py:1622]   Expert 58 |    298 | GPU
DEBUG 01-13 08:46:50.022584.022584 lmp.py:1622]   Expert 40 |    303 | GPU
DEBUG 01-13 08:46:50.022273.022273 lmp.py:1622]   Expert 14 |    320 | GPU
DEBUG 01-13 08:46:50.022486.022486 lmp.py:1622]   Expert 12 |    323 | GPU
DEBUG 01-13 08:46:50.022414.022414 lmp.py:1622]   Expert 63 |    327 | GPU
DEBUG 01-13 08:46:50.022580.022580 lmp.py:1622]   Expert 21 |    361 | GPU
DEBUG 01-13 08:46:50.022746.022746 lmp.py:1622]   Expert 27 |    685 | GPU
DEBUG 01-13 08:46:50.022389.022389 lmp.py:1622]   Expert  3 |   1028 | GPU
DEBUG 01-13 08:46:50.022032.022032 lmp.py:1623] 
DEBUG 01-13 08:46:50.022032.022032 lmp.py:1623]   CPU total tokens: 3126 (25.4%)
DEBUG 01-13 08:46:50.022152.022152 lmp.py:1624]   GPU total tokens: 9162 (74.6%)
DEBUG 01-13 08:46:50.022609.022609 cuda_h.py:19] end experts_map_get cost 0.0015273094177246094 seconds
DEBUG 01-13 08:46:50.023075.023075 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-13 08:46:50.023354.023354 lmp.py:1632] 
DEBUG 01-13 08:46:50.023354.023354 lmp.py:1632]   Computing 32 experts on CPU MP...
DEBUG 01-13 08:46:50.023091.023091 cuda_h.py:19] end cpu_experts_submit cost 5.221366882324219e-05 seconds
DEBUG 01-13 08:46:50.023595.023595 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-13 08:46:50.023140.023140 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-13 08:46:50.023311.023311 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-13 08:46:50.024274.024274 cuda_h.py:19] end allocate_cuda_memory cost 0.001447916030883789 seconds
DEBUG 01-13 08:46:50.024614.024614 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-13 08:46:50.024775.024775 sllm_store_c.py:27] get device uuid map
DEBUG 01-13 08:46:50.024160.024160 sllm_store_c.py:29] call client load into gpu
DEBUG 01-13 08:46:50.025479.025479 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 692de48a-f838-4053-abab-41692ba6b524
DEBUG 01-13 08:46:50.025751.025751 client.py:106] call stub.LoadModelAsync
INFO 01-13 08:46:50.025810.025810 client.py:127] Model loaded
DEBUG 01-13 08:46:50.025179.025179 cuda_h.py:10] start restore2model
DEBUG 01-13 08:46:50.026933.026933 cuda_h.py:19] end restore2model cost 0.00034689903259277344 seconds
DEBUG 01-13 08:46:50.026465.026465 cuda_h.py:19] end sllm_worker_task cost 0.010486125946044922 seconds
DEBUG 01-13 08:46:50.026485.026485 cuda_h.py:10] start experts_func_gpu_einsum_mp
INFO 01-13 08:46:50.027065.027065 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 692de48a-f838-4053-abab-41692ba6b524
DEBUG 01-13 08:46:50.027861.027861 cuda_h.py:19] end load_into_gpu_async cost 0.002378702163696289 seconds
DEBUG 01-13 08:46:50.027518.027518 cuda_h.py:10] start restore_tensors2
DEBUG 01-13 08:46:50.027136.027136 cuda_h.py:19] end restore_tensors2 cost 0.0004279613494873047 seconds
DEBUG 01-13 08:46:50.027502.027502 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.004668235778808594 seconds
DEBUG 01-13 08:46:50.027987.027987 cuda_h.py:10] start restore2model
DEBUG 01-13 08:46:50.030512.030512 cuda_h.py:19] end restore2model cost 0.002606630325317383 seconds
DEBUG 01-13 08:46:50.030302.030302 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.0074520111083984375 seconds
DEBUG 01-13 08:46:50.030641.030641 cuda_h.py:10] start gpu_sexperts
DEBUG 01-13 08:46:50.030678.030678 cuda_h.py:19] end gpu_sexperts cost 0.0002739429473876953 seconds
DEBUG 01-13 08:46:50.030077.030077 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-13 08:46:50.031608.031608 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 1.3589859008789062e-05 seconds
DEBUG 01-13 08:46:50.031112.031112 cuda_h.py:10] start wait_experts
INFO 01-13 08:46:50.031570.031570 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 692de48a-f838-4053-abab-41692ba6b524
DEBUG 01-13 08:46:50.042156.042156 mlpmodule.py:1006] group tensors cost 0.015537261962890625 s
DEBUG 01-13 08:46:50.046041.046041 mlpmodule.py:1044] pad cost 0.0029096603393554688 s
DEBUG 01-13 08:46:50.046953.046953 mlpmodule.py:1050] create cpu tensor cost 6.914138793945312e-05 s
DEBUG 01-13 08:46:50.046513.046513 mlpmodule.py:1055] move to cpu cost 4.7206878662109375e-05 s
DEBUG 01-13 08:46:50.055645.055645 mlpmodule.py:1069] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-13 08:46:50.055314.055314 mlpmodule.py:1070] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-13 08:46:50.056100.056100 mlpmodule.py:1075] group_w3 first element: 0.00653076171875
WARNING 01-13 08:46:50.056986.056986 mlpmodule.py:1085] start einsum2
DEBUG 01-13 08:46:50.069339.069339 mlpmodule.py:1095] group einsum cost 0.023192405700683594 s
DEBUG 01-13 08:46:50.070099.070099 mlpmodule.py:1103] cpy2cputensor cost 0.0007047653198242188 s
INFO 01-13 08:46:50.080253.080253 client.py:127] Model loaded
DEBUG 01-13 08:46:50.080332.080332 cuda_h.py:19] end wait_experts cost 0.04945111274719238 seconds
DEBUG 01-13 08:46:50.080479.080479 cuda_h.py:10] start gpu_experts
DEBUG 01-13 08:46:50.081323.081323 mlpmodule.py:559] gpu group tensors cost 0.0007538795471191406 s
DEBUG 01-13 08:46:50.083718.083718 mlpmodule.py:592] gpu pad cost 0.0018308162689208984 s
DEBUG 01-13 08:46:50.083025.083025 mlpmodule.py:598] start_w1
DEBUG 01-13 08:46:50.083767.083767 mlpmodule.py:602] start_w3
DEBUG 01-13 08:46:50.084543.084543 mlpmodule.py:608] start_w2
DEBUG 01-13 08:46:50.084907.084907 mlpmodule.py:611] gpu group einsum cost 0.0008232593536376953 s
DEBUG 01-13 08:46:50.084357.084357 mlpmodule.py:785]  experts func einsum cost 0.057579755783081055 s
DEBUG 01-13 08:46:50.084889.084889 cuda_h.py:19] end experts_func_gpu_einsum_mp cost 0.05823540687561035 seconds
DEBUG 01-13 08:46:50.086687.086687 mlpmodule.py:683] gpu experts func einsum cost 0.006290912628173828 s
DEBUG 01-13 08:46:50.087587.087587 cuda_h.py:19] end gpu_experts cost 0.006545066833496094 seconds
DEBUG 01-13 08:46:50.087435.087435 cuda_h.py:10] start cpu_thread_manager_mp_wait
DEBUG 01-13 08:46:50.087332.087332 cuda_h.py:19] end cpu_thread_manager_mp_wait cost 3.62396240234375e-05 seconds
DEBUG 01-13 08:46:50.087917.087917 cuda_h.py:19] end layer_moe_generate_mp_l_25 cost 0.06666040420532227 seconds
DEBUG 01-13 08:46:50.087468.087468 lmp.py:1550] -------------------------------- end prefill layer 24 --------------------------------
DEBUG 01-13 08:46:50.087145.087145 lmp.py:1493] -------------------------------- start prefill layer 25 --------------------------------
DEBUG 01-13 08:46:50.087940.087940 cuda_h.py:10] start start_load_qkvogn_s_weight_l_26
DEBUG 01-13 08:46:50.087405.087405 cuda_h.py:10] start start_load_qkvogn_s_weight_l_26
DEBUG 01-13 08:46:50.087811.087811 cuda_h.py:19] end start_load_qkvogn_s_weight_l_26 cost 3.0279159545898438e-05 seconds
DEBUG 01-13 08:46:50.087606.087606 cuda_h.py:19] end start_load_qkvogn_s_weight_l_26 cost 5.841255187988281e-05 seconds
DEBUG 01-13 08:46:50.087846.087846 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-13 08:46:50.087676.087676 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-13 08:46:50.087884.087884 cuda_h.py:10] start sllm_worker_task
DEBUG 01-13 08:46:50.088305.088305 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-13 08:46:50.088618.088618 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-13 08:46:50.088830.088830 cuda_h.py:19] end allocate_cuda_memory cost 0.00036716461181640625 seconds
DEBUG 01-13 08:46:50.088800.088800 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-13 08:46:50.088847.088847 sllm_store_c.py:27] get device uuid map
DEBUG 01-13 08:46:50.088909.088909 sllm_store_c.py:29] call client load into gpu
DEBUG 01-13 08:46:50.088658.088658 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, ed58e292-0d5e-4051-808c-28d8b15606cd
DEBUG 01-13 08:46:50.088111.088111 client.py:106] call stub.LoadModelAsync
DEBUG 01-13 08:46:50.089086.089086 cuda_h.py:10] start self_attn
INFO 01-13 08:46:50.090765.090765 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, ed58e292-0d5e-4051-808c-28d8b15606cd
DEBUG 01-13 08:46:50.090794.090794 cuda_h.py:19] end load_into_gpu_async cost 0.0017502307891845703 seconds
DEBUG 01-13 08:46:50.090112.090112 cuda_h.py:10] start restore_tensors2
DEBUG 01-13 08:46:50.090665.090665 cuda_h.py:19] end restore_tensors2 cost 6.699562072753906e-05 seconds
DEBUG 01-13 08:46:50.090229.090229 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.002437591552734375 seconds
INFO 01-13 08:46:50.090588.090588 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, ed58e292-0d5e-4051-808c-28d8b15606cd
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-13 08:46:50.091918.091918 cuda_h.py:19] end self_attn cost 0.0028333663940429688 seconds
DEBUG 01-13 08:46:50.092457.092457 cuda_h.py:19] end iln_self_attn_paln cost 0.00439000129699707 seconds
DEBUG 01-13 08:46:50.092155.092155 cuda_h.py:10] start layer_moe_generate_mp_l_26
DEBUG 01-13 08:46:50.092056.092056 cuda_h.py:10] start gate
DEBUG 01-13 08:46:50.092973.092973 cuda_h.py:19] end gate cost 0.0006432533264160156 seconds
DEBUG 01-13 08:46:50.093802.093802 cuda_h.py:10] start experts_map_get
DEBUG 01-13 08:46:50.093442.093442 lmp.py:1611] 
DEBUG 01-13 08:46:50.093442.093442 lmp.py:1611] Expert Token Distribution & Device Allocation:
DEBUG 01-13 08:46:50.093244.093244 lmp.py:1612]   Total experts: 64
DEBUG 01-13 08:46:50.093132.093132 lmp.py:1613]   CPU experts: 32 (50%)
DEBUG 01-13 08:46:50.093205.093205 lmp.py:1614]   GPU experts: 32 (50%)
DEBUG 01-13 08:46:50.093372.093372 lmp.py:1615] 
DEBUG 01-13 08:46:50.093372.093372 lmp.py:1615]   Expert ID | Tokens | Device
DEBUG 01-13 08:46:50.093491.093491 lmp.py:1616]   -----------------------------------
DEBUG 01-13 08:46:50.093618.093618 lmp.py:1622]   Expert 13 |     31 | CPU
DEBUG 01-13 08:46:50.093784.093784 lmp.py:1622]   Expert 44 |     38 | CPU
DEBUG 01-13 08:46:50.093473.093473 lmp.py:1622]   Expert  9 |     43 | CPU
DEBUG 01-13 08:46:50.093209.093209 lmp.py:1622]   Expert 38 |     44 | CPU
DEBUG 01-13 08:46:50.093183.093183 lmp.py:1622]   Expert 25 |     46 | CPU
DEBUG 01-13 08:46:50.093919.093919 lmp.py:1622]   Expert 16 |     49 | CPU
DEBUG 01-13 08:46:50.093893.093893 lmp.py:1622]   Expert 22 |     51 | CPU
DEBUG 01-13 08:46:50.093152.093152 lmp.py:1622]   Expert 33 |     54 | CPU
DEBUG 01-13 08:46:50.093126.093126 lmp.py:1622]   Expert  2 |     57 | CPU
DEBUG 01-13 08:46:50.093623.093623 lmp.py:1622]   Expert 42 |     62 | CPU
DEBUG 01-13 08:46:50.093358.093358 lmp.py:1622]   Expert 23 |     69 | CPU
DEBUG 01-13 08:46:50.093617.093617 lmp.py:1622]   Expert  5 |     75 | CPU
DEBUG 01-13 08:46:50.093114.093114 lmp.py:1622]   Expert 10 |     78 | CPU
DEBUG 01-13 08:46:50.093373.093373 lmp.py:1622]   Expert 24 |     80 | CPU
DEBUG 01-13 08:46:50.093632.093632 lmp.py:1622]   Expert 59 |     91 | CPU
DEBUG 01-13 08:46:50.093652.093652 lmp.py:1622]   Expert 55 |     98 | CPU
DEBUG 01-13 08:46:50.093911.093911 lmp.py:1622]   Expert 21 |    101 | CPU
DEBUG 01-13 08:46:50.093124.093124 lmp.py:1622]   Expert 46 |    107 | CPU
DEBUG 01-13 08:46:50.093621.093621 lmp.py:1622]   Expert 45 |    118 | CPU
DEBUG 01-13 08:46:50.093072.093072 lmp.py:1622]   Expert 31 |    121 | CPU
DEBUG 01-13 08:46:50.093284.093284 lmp.py:1622]   Expert 61 |    124 | CPU
DEBUG 01-13 08:46:50.093258.093258 lmp.py:1622]   Expert 36 |    135 | CPU
DEBUG 01-13 08:46:50.093994.093994 lmp.py:1622]   Expert 51 |    138 | CPU
DEBUG 01-13 08:46:50.093491.093491 lmp.py:1622]   Expert  6 |    139 | CPU
DEBUG 01-13 08:46:50.093465.093465 lmp.py:1622]   Expert  8 |    143 | CPU
DEBUG 01-13 08:46:50.093201.093201 lmp.py:1622]   Expert  0 |    149 | CPU
DEBUG 01-13 08:46:50.093936.093936 lmp.py:1622]   Expert 26 |    155 | CPU
DEBUG 01-13 08:46:50.093434.093434 lmp.py:1622]   Expert 43 |    158 | CPU
DEBUG 01-13 08:46:50.093361.093361 lmp.py:1622]   Expert 18 |    159 | CPU
DEBUG 01-13 08:46:50.093051.093051 lmp.py:1622]   Expert  3 |    163 | CPU
DEBUG 01-13 08:46:50.093740.093740 lmp.py:1622]   Expert 48 |    166 | CPU
DEBUG 01-13 08:46:50.093952.093952 lmp.py:1622]   Expert 20 |    167 | CPU
DEBUG 01-13 08:46:50.093642.093642 lmp.py:1622]   Expert 41 |    168 | GPU
DEBUG 01-13 08:46:50.093854.093854 lmp.py:1622]   Expert 12 |    179 | GPU
DEBUG 01-13 08:46:50.093543.093543 lmp.py:1622]   Expert  7 |    186 | GPU
DEBUG 01-13 08:46:50.093233.093233 lmp.py:1622]   Expert 56 |    187 | GPU
DEBUG 01-13 08:46:50.094399.094399 lmp.py:1622]   Expert 34 |    189 | GPU
DEBUG 01-13 08:46:50.094803.094803 lmp.py:1622]   Expert 28 |    191 | GPU
DEBUG 01-13 08:46:50.094446.094446 lmp.py:1622]   Expert 27 |    200 | GPU
DEBUG 01-13 08:46:50.094089.094089 lmp.py:1622]   Expert  1 |    201 | GPU
DEBUG 01-13 08:46:50.094256.094256 lmp.py:1622]   Expert 47 |    201 | GPU
DEBUG 01-13 08:46:50.094945.094945 lmp.py:1622]   Expert 11 |    212 | GPU
DEBUG 01-13 08:46:50.094873.094873 lmp.py:1622]   Expert 32 |    218 | GPU
DEBUG 01-13 08:46:50.094085.094085 lmp.py:1622]   Expert 49 |    229 | GPU
DEBUG 01-13 08:46:50.094774.094774 lmp.py:1622]   Expert 53 |    230 | GPU
DEBUG 01-13 08:46:50.094225.094225 lmp.py:1622]   Expert 40 |    231 | GPU
DEBUG 01-13 08:46:50.094676.094676 lmp.py:1622]   Expert 63 |    233 | GPU
DEBUG 01-13 08:46:50.094650.094650 lmp.py:1622]   Expert 29 |    244 | GPU
DEBUG 01-13 08:46:50.094339.094339 lmp.py:1622]   Expert 50 |    245 | GPU
DEBUG 01-13 08:46:50.094744.094744 lmp.py:1622]   Expert  4 |    250 | GPU
DEBUG 01-13 08:46:50.094910.094910 lmp.py:1622]   Expert 15 |    251 | GPU
DEBUG 01-13 08:46:50.094076.094076 lmp.py:1622]   Expert 30 |    251 | GPU
DEBUG 01-13 08:46:50.094481.094481 lmp.py:1622]   Expert 14 |    271 | GPU
DEBUG 01-13 08:46:50.094170.094170 lmp.py:1622]   Expert 35 |    273 | GPU
DEBUG 01-13 08:46:50.094383.094383 lmp.py:1622]   Expert 37 |    304 | GPU
DEBUG 01-13 08:46:50.094833.094833 lmp.py:1622]   Expert 52 |    338 | GPU
DEBUG 01-13 08:46:50.094284.094284 lmp.py:1622]   Expert 17 |    371 | GPU
DEBUG 01-13 08:46:50.094974.094974 lmp.py:1622]   Expert 54 |    377 | GPU
DEBUG 01-13 08:46:50.094186.094186 lmp.py:1622]   Expert 39 |    399 | GPU
DEBUG 01-13 08:46:50.094637.094637 lmp.py:1622]   Expert 57 |    409 | GPU
DEBUG 01-13 08:46:50.094326.094326 lmp.py:1622]   Expert 60 |    453 | GPU
DEBUG 01-13 08:46:50.094777.094777 lmp.py:1622]   Expert 62 |    468 | GPU
DEBUG 01-13 08:46:50.094705.094705 lmp.py:1622]   Expert 19 |    553 | GPU
DEBUG 01-13 08:46:50.094348.094348 lmp.py:1622]   Expert 58 |    567 | GPU
DEBUG 01-13 08:46:50.094468.094468 lmp.py:1623] 
DEBUG 01-13 08:46:50.094468.094468 lmp.py:1623]   CPU total tokens: 3209 (26.1%)
DEBUG 01-13 08:46:50.094303.094303 lmp.py:1624]   GPU total tokens: 9079 (73.9%)
DEBUG 01-13 08:46:50.094760.094760 cuda_h.py:19] end experts_map_get cost 0.0014863014221191406 seconds
DEBUG 01-13 08:46:50.094941.094941 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-13 08:46:50.094313.094313 lmp.py:1632] 
DEBUG 01-13 08:46:50.094313.094313 lmp.py:1632]   Computing 32 experts on CPU MP...
DEBUG 01-13 08:46:50.094043.094043 cuda_h.py:19] end cpu_experts_submit cost 4.6253204345703125e-05 seconds
DEBUG 01-13 08:46:50.094547.094547 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-13 08:46:50.094423.094423 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-13 08:46:50.094210.094210 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-13 08:46:50.096441.096441 cuda_h.py:19] end allocate_cuda_memory cost 0.001926422119140625 seconds
DEBUG 01-13 08:46:50.096384.096384 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-13 08:46:50.096829.096829 sllm_store_c.py:27] get device uuid map
DEBUG 01-13 08:46:50.097791.097791 sllm_store_c.py:29] call client load into gpu
DEBUG 01-13 08:46:50.097586.097586 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 07431f89-c074-414d-aa9d-5074af5a2444
DEBUG 01-13 08:46:50.097374.097374 client.py:106] call stub.LoadModelAsync
INFO 01-13 08:46:50.097607.097607 client.py:127] Model loaded
DEBUG 01-13 08:46:50.097251.097251 cuda_h.py:10] start restore2model
DEBUG 01-13 08:46:50.097519.097519 cuda_h.py:10] start experts_func_gpu_einsum_mp
DEBUG 01-13 08:46:50.098840.098840 cuda_h.py:19] end restore2model cost 0.00036716461181640625 seconds
DEBUG 01-13 08:46:50.098040.098040 cuda_h.py:19] end sllm_worker_task cost 0.010102272033691406 seconds
INFO 01-13 08:46:50.099362.099362 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 07431f89-c074-414d-aa9d-5074af5a2444
DEBUG 01-13 08:46:50.099920.099920 cuda_h.py:19] end load_into_gpu_async cost 0.002136707305908203 seconds
DEBUG 01-13 08:46:50.099862.099862 cuda_h.py:10] start restore_tensors2
DEBUG 01-13 08:46:50.099857.099857 cuda_h.py:19] end restore_tensors2 cost 0.00042557716369628906 seconds
DEBUG 01-13 08:46:50.099885.099885 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.004881858825683594 seconds
DEBUG 01-13 08:46:50.099416.099416 cuda_h.py:10] start restore2model
DEBUG 01-13 08:46:50.102028.102028 cuda_h.py:19] end restore2model cost 0.0025992393493652344 seconds
DEBUG 01-13 08:46:50.102155.102155 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.007660388946533203 seconds
DEBUG 01-13 08:46:50.102474.102474 cuda_h.py:10] start gpu_sexperts
DEBUG 01-13 08:46:50.102067.102067 cuda_h.py:19] end gpu_sexperts cost 0.00026607513427734375 seconds
DEBUG 01-13 08:46:50.102704.102704 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-13 08:46:50.102427.102427 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 1.430511474609375e-05 seconds
DEBUG 01-13 08:46:50.102170.102170 cuda_h.py:10] start wait_experts
INFO 01-13 08:46:50.102296.102296 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 07431f89-c074-414d-aa9d-5074af5a2444
DEBUG 01-13 08:46:50.114781.114781 mlpmodule.py:1006] group tensors cost 0.01613783836364746 s
DEBUG 01-13 08:46:50.118809.118809 mlpmodule.py:1044] pad cost 0.002881288528442383 s
DEBUG 01-13 08:46:50.118052.118052 mlpmodule.py:1050] create cpu tensor cost 6.842613220214844e-05 s
DEBUG 01-13 08:46:50.118950.118950 mlpmodule.py:1055] move to cpu cost 4.9114227294921875e-05 s
DEBUG 01-13 08:46:50.127750.127750 mlpmodule.py:1069] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-13 08:46:50.127380.127380 mlpmodule.py:1070] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-13 08:46:50.127974.127974 mlpmodule.py:1075] group_w3 first element: 0.007110595703125
WARNING 01-13 08:46:50.127158.127158 mlpmodule.py:1085] start einsum2
DEBUG 01-13 08:46:50.141658.141658 mlpmodule.py:1095] group einsum cost 0.02264237403869629 s
DEBUG 01-13 08:46:50.142101.142101 mlpmodule.py:1103] cpy2cputensor cost 0.0007138252258300781 s
INFO 01-13 08:46:50.151243.151243 client.py:127] Model loaded
DEBUG 01-13 08:46:50.152944.152944 cuda_h.py:19] end wait_experts cost 0.04919123649597168 seconds
DEBUG 01-13 08:46:50.152277.152277 cuda_h.py:10] start gpu_experts
DEBUG 01-13 08:46:50.153011.153011 mlpmodule.py:559] gpu group tensors cost 0.0008499622344970703 s
DEBUG 01-13 08:46:50.154716.154716 mlpmodule.py:592] gpu pad cost 0.001814126968383789 s
DEBUG 01-13 08:46:50.154057.154057 mlpmodule.py:598] start_w1
DEBUG 01-13 08:46:50.155611.155611 mlpmodule.py:602] start_w3
DEBUG 01-13 08:46:50.155677.155677 mlpmodule.py:608] start_w2
DEBUG 01-13 08:46:50.155920.155920 mlpmodule.py:611] gpu group einsum cost 0.0006716251373291016 s
DEBUG 01-13 08:46:50.156213.156213 mlpmodule.py:785]  experts func einsum cost 0.05735921859741211 s
DEBUG 01-13 08:46:50.156738.156738 cuda_h.py:19] end experts_func_gpu_einsum_mp cost 0.05823397636413574 seconds
DEBUG 01-13 08:46:50.158007.158007 mlpmodule.py:683] gpu experts func einsum cost 0.006081104278564453 s
DEBUG 01-13 08:46:50.158311.158311 cuda_h.py:19] end gpu_experts cost 0.006349325180053711 seconds
DEBUG 01-13 08:46:50.158690.158690 cuda_h.py:10] start cpu_thread_manager_mp_wait
DEBUG 01-13 08:46:50.158415.158415 cuda_h.py:19] end cpu_thread_manager_mp_wait cost 3.743171691894531e-05 seconds
DEBUG 01-13 08:46:50.158384.158384 cuda_h.py:19] end layer_moe_generate_mp_l_26 cost 0.0663611888885498 seconds
DEBUG 01-13 08:46:50.158631.158631 lmp.py:1550] -------------------------------- end prefill layer 25 --------------------------------
DEBUG 01-13 08:46:50.158155.158155 lmp.py:1493] -------------------------------- start prefill layer 26 --------------------------------
DEBUG 01-13 08:46:50.158236.158236 cuda_h.py:10] start start_load_qkvogn_s_weight_l_27
DEBUG 01-13 08:46:50.158415.158415 cuda_h.py:10] start start_load_qkvogn_s_weight_l_27
DEBUG 01-13 08:46:50.159298.159298 cuda_h.py:19] end start_load_qkvogn_s_weight_l_27 cost 3.0994415283203125e-05 seconds
DEBUG 01-13 08:46:50.159399.159399 cuda_h.py:19] end start_load_qkvogn_s_weight_l_27 cost 7.319450378417969e-05 seconds
DEBUG 01-13 08:46:50.159803.159803 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-13 08:46:50.159428.159428 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-13 08:46:50.159444.159444 cuda_h.py:10] start sllm_worker_task
DEBUG 01-13 08:46:50.159494.159494 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-13 08:46:50.159569.159569 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-13 08:46:50.159051.159051 cuda_h.py:19] end allocate_cuda_memory cost 0.00031948089599609375 seconds
DEBUG 01-13 08:46:50.159597.159597 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-13 08:46:50.159406.159406 sllm_store_c.py:27] get device uuid map
DEBUG 01-13 08:46:50.159513.159513 sllm_store_c.py:29] call client load into gpu
DEBUG 01-13 08:46:50.159024.159024 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, ceff9cf0-bf04-4d23-b09c-e1fb4cb6671e
DEBUG 01-13 08:46:50.160378.160378 client.py:106] call stub.LoadModelAsync
DEBUG 01-13 08:46:50.160968.160968 cuda_h.py:10] start self_attn
INFO 01-13 08:46:50.161074.161074 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, ceff9cf0-bf04-4d23-b09c-e1fb4cb6671e
DEBUG 01-13 08:46:50.161056.161056 cuda_h.py:19] end load_into_gpu_async cost 0.0018131732940673828 seconds
DEBUG 01-13 08:46:50.161613.161613 cuda_h.py:10] start restore_tensors2
DEBUG 01-13 08:46:50.161008.161008 cuda_h.py:19] end restore_tensors2 cost 8.988380432128906e-05 seconds
DEBUG 01-13 08:46:50.161810.161810 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.00247955322265625 seconds
INFO 01-13 08:46:50.161329.161329 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, ceff9cf0-bf04-4d23-b09c-e1fb4cb6671e
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-13 08:46:50.163266.163266 cuda_h.py:19] end self_attn cost 0.0028967857360839844 seconds
DEBUG 01-13 08:46:50.163198.163198 cuda_h.py:19] end iln_self_attn_paln cost 0.0044362545013427734 seconds
DEBUG 01-13 08:46:50.163087.163087 cuda_h.py:10] start layer_moe_generate_mp_l_27
DEBUG 01-13 08:46:50.163420.163420 cuda_h.py:10] start gate
DEBUG 01-13 08:46:50.164383.164383 cuda_h.py:19] end gate cost 0.0006415843963623047 seconds
DEBUG 01-13 08:46:50.165683.165683 cuda_h.py:10] start experts_map_get
DEBUG 01-13 08:46:50.165092.165092 lmp.py:1611] 
DEBUG 01-13 08:46:50.165092.165092 lmp.py:1611] Expert Token Distribution & Device Allocation:
DEBUG 01-13 08:46:50.165709.165709 lmp.py:1612]   Total experts: 64
DEBUG 01-13 08:46:50.165120.165120 lmp.py:1613]   CPU experts: 32 (50%)
DEBUG 01-13 08:46:50.165478.165478 lmp.py:1614]   GPU experts: 32 (50%)
DEBUG 01-13 08:46:50.165929.165929 lmp.py:1615] 
DEBUG 01-13 08:46:50.165929.165929 lmp.py:1615]   Expert ID | Tokens | Device
DEBUG 01-13 08:46:50.165380.165380 lmp.py:1616]   -----------------------------------
DEBUG 01-13 08:46:50.165791.165791 lmp.py:1622]   Expert 20 |      7 | CPU
DEBUG 01-13 08:46:50.165958.165958 lmp.py:1622]   Expert 61 |     10 | CPU
DEBUG 01-13 08:46:50.165647.165647 lmp.py:1622]   Expert 11 |     29 | CPU
DEBUG 01-13 08:46:50.165621.165621 lmp.py:1622]   Expert  7 |     36 | CPU
DEBUG 01-13 08:46:50.165025.165025 lmp.py:1622]   Expert  3 |     37 | CPU
DEBUG 01-13 08:46:50.165430.165430 lmp.py:1622]   Expert 51 |     42 | CPU
DEBUG 01-13 08:46:50.165596.165596 lmp.py:1622]   Expert 62 |     42 | CPU
DEBUG 01-13 08:46:50.165524.165524 lmp.py:1622]   Expert 30 |     48 | CPU
DEBUG 01-13 08:46:50.165975.165975 lmp.py:1622]   Expert 17 |     56 | CPU
DEBUG 01-13 08:46:50.166949.166949 lmp.py:1622]   Expert  6 |     58 | CPU
DEBUG 01-13 08:46:50.166446.166446 lmp.py:1622]   Expert 29 |     59 | CPU
DEBUG 01-13 08:46:50.166705.166705 lmp.py:1622]   Expert  9 |     70 | CPU
DEBUG 01-13 08:46:50.166440.166440 lmp.py:1622]   Expert 63 |     74 | CPU
DEBUG 01-13 08:46:50.166699.166699 lmp.py:1622]   Expert 19 |     76 | CPU
DEBUG 01-13 08:46:50.166196.166196 lmp.py:1622]   Expert 38 |     79 | CPU
DEBUG 01-13 08:46:50.166932.166932 lmp.py:1622]   Expert 59 |     83 | CPU
DEBUG 01-13 08:46:50.166906.166906 lmp.py:1622]   Expert 55 |     84 | CPU
DEBUG 01-13 08:46:50.166403.166403 lmp.py:1622]   Expert  8 |     99 | CPU
DEBUG 01-13 08:46:50.166139.166139 lmp.py:1622]   Expert 22 |     99 | CPU
DEBUG 01-13 08:46:50.166875.166875 lmp.py:1622]   Expert 49 |    102 | CPU
DEBUG 01-13 08:46:50.166610.166610 lmp.py:1622]   Expert 48 |    105 | CPU
DEBUG 01-13 08:46:50.166823.166823 lmp.py:1622]   Expert 34 |    111 | CPU
DEBUG 01-13 08:46:50.166797.166797 lmp.py:1622]   Expert 50 |    115 | CPU
DEBUG 01-13 08:46:50.166724.166724 lmp.py:1622]   Expert 36 |    116 | CPU
DEBUG 01-13 08:46:50.166652.166652 lmp.py:1622]   Expert 42 |    116 | CPU
DEBUG 01-13 08:46:50.166103.166103 lmp.py:1622]   Expert 24 |    117 | CPU
DEBUG 01-13 08:46:50.166839.166839 lmp.py:1622]   Expert 39 |    125 | CPU
DEBUG 01-13 08:46:50.166336.166336 lmp.py:1622]   Expert  4 |    127 | CPU
DEBUG 01-13 08:46:50.166979.166979 lmp.py:1622]   Expert 37 |    137 | CPU
DEBUG 01-13 08:46:50.166430.166430 lmp.py:1622]   Expert 15 |    144 | CPU
DEBUG 01-13 08:46:50.166881.166881 lmp.py:1622]   Expert 41 |    144 | CPU
DEBUG 01-13 08:46:50.166808.166808 lmp.py:1622]   Expert 23 |    151 | CPU
DEBUG 01-13 08:46:50.166498.166498 lmp.py:1622]   Expert 56 |    160 | GPU
DEBUG 01-13 08:46:50.166948.166948 lmp.py:1622]   Expert 60 |    165 | GPU
DEBUG 01-13 08:46:50.166638.166638 lmp.py:1622]   Expert 16 |    171 | GPU
DEBUG 01-13 08:46:50.166089.166089 lmp.py:1622]   Expert  1 |    173 | GPU
DEBUG 01-13 08:46:50.166016.166016 lmp.py:1622]   Expert 43 |    177 | GPU
DEBUG 01-13 08:46:50.166182.166182 lmp.py:1622]   Expert 21 |    181 | GPU
DEBUG 01-13 08:46:50.166825.166825 lmp.py:1622]   Expert 44 |    185 | GPU
DEBUG 01-13 08:46:50.166468.166468 lmp.py:1622]   Expert 53 |    189 | GPU
DEBUG 01-13 08:46:50.166873.166873 lmp.py:1622]   Expert 47 |    197 | GPU
DEBUG 01-13 08:46:50.166039.166039 lmp.py:1622]   Expert 33 |    204 | GPU
DEBUG 01-13 08:46:50.166728.166728 lmp.py:1622]   Expert 12 |    205 | GPU
DEBUG 01-13 08:46:50.166418.166418 lmp.py:1622]   Expert 13 |    212 | GPU
DEBUG 01-13 08:46:50.166869.166869 lmp.py:1622]   Expert 32 |    225 | GPU
DEBUG 01-13 08:46:50.166320.166320 lmp.py:1622]   Expert 28 |    231 | GPU
DEBUG 01-13 08:46:50.166009.166009 lmp.py:1622]   Expert  0 |    252 | GPU
DEBUG 01-13 08:46:50.166937.166937 lmp.py:1622]   Expert 31 |    257 | GPU
DEBUG 01-13 08:46:50.166387.166387 lmp.py:1622]   Expert 54 |    258 | GPU
DEBUG 01-13 08:46:50.166600.166600 lmp.py:1622]   Expert 26 |    259 | GPU
DEBUG 01-13 08:46:50.166289.166289 lmp.py:1622]   Expert 10 |    262 | GPU
DEBUG 01-13 08:46:50.166217.166217 lmp.py:1622]   Expert 57 |    263 | GPU
DEBUG 01-13 08:46:50.166145.166145 lmp.py:1622]   Expert 18 |    267 | GPU
DEBUG 01-13 08:46:50.166549.166549 lmp.py:1622]   Expert  2 |    289 | GPU
DEBUG 01-13 08:46:50.166192.166192 lmp.py:1622]   Expert 58 |    308 | GPU
DEBUG 01-13 08:46:50.166881.166881 lmp.py:1622]   Expert 40 |    339 | GPU
DEBUG 01-13 08:46:50.166094.166094 lmp.py:1622]   Expert 45 |    357 | GPU
DEBUG 01-13 08:46:50.166306.166306 lmp.py:1622]   Expert 25 |    383 | GPU
DEBUG 01-13 08:46:50.166996.166996 lmp.py:1622]   Expert  5 |    420 | GPU
DEBUG 01-13 08:46:50.166685.166685 lmp.py:1622]   Expert 35 |    458 | GPU
DEBUG 01-13 08:46:50.166374.166374 lmp.py:1622]   Expert 27 |    486 | GPU
DEBUG 01-13 08:46:50.166587.166587 lmp.py:1622]   Expert 46 |    543 | GPU
DEBUG 01-13 08:46:50.166799.166799 lmp.py:1622]   Expert 52 |    616 | GPU
DEBUG 01-13 08:46:50.166250.166250 lmp.py:1622]   Expert 14 |    898 | GPU
DEBUG 01-13 08:46:50.166416.166416 lmp.py:1623] 
DEBUG 01-13 08:46:50.166416.166416 lmp.py:1623]   CPU total tokens: 2698 (22.0%)
DEBUG 01-13 08:46:50.166059.166059 lmp.py:1624]   GPU total tokens: 9590 (78.0%)
DEBUG 01-13 08:46:50.166709.166709 cuda_h.py:19] end experts_map_get cost 0.00151824951171875 seconds
DEBUG 01-13 08:46:50.167764.167764 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-13 08:46:50.167520.167520 lmp.py:1632] 
DEBUG 01-13 08:46:50.167520.167520 lmp.py:1632]   Computing 32 experts on CPU MP...
DEBUG 01-13 08:46:50.167542.167542 cuda_h.py:19] end cpu_experts_submit cost 5.054473876953125e-05 seconds
DEBUG 01-13 08:46:50.167854.167854 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-13 08:46:50.167683.167683 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-13 08:46:50.167053.167053 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-13 08:46:50.168888.168888 cuda_h.py:19] end allocate_cuda_memory cost 0.0015630722045898438 seconds
DEBUG 01-13 08:46:50.169069.169069 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-13 08:46:50.169779.169779 sllm_store_c.py:27] get device uuid map
DEBUG 01-13 08:46:50.169972.169972 sllm_store_c.py:29] call client load into gpu
DEBUG 01-13 08:46:50.169291.169291 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 95351223-058e-4dd8-9625-4e940171e77a
DEBUG 01-13 08:46:50.169523.169523 client.py:106] call stub.LoadModelAsync
INFO 01-13 08:46:50.169525.169525 client.py:127] Model loaded
DEBUG 01-13 08:46:50.169500.169500 cuda_h.py:10] start restore2model
DEBUG 01-13 08:46:50.170221.170221 cuda_h.py:19] end restore2model cost 0.0003249645233154297 seconds
DEBUG 01-13 08:46:50.170845.170845 cuda_h.py:19] end sllm_worker_task cost 0.010880231857299805 seconds
DEBUG 01-13 08:46:50.170609.170609 cuda_h.py:10] start experts_func_gpu_einsum_mp
INFO 01-13 08:46:50.171177.171177 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 95351223-058e-4dd8-9625-4e940171e77a
DEBUG 01-13 08:46:50.171358.171358 cuda_h.py:19] end load_into_gpu_async cost 0.0022499561309814453 seconds
DEBUG 01-13 08:46:50.171968.171968 cuda_h.py:10] start restore_tensors2
DEBUG 01-13 08:46:50.171117.171117 cuda_h.py:19] end restore_tensors2 cost 0.00046825408935546875 seconds
DEBUG 01-13 08:46:50.171483.171483 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.00467371940612793 seconds
DEBUG 01-13 08:46:50.171783.171783 cuda_h.py:10] start restore2model
DEBUG 01-13 08:46:50.174327.174327 cuda_h.py:19] end restore2model cost 0.002584218978881836 seconds
DEBUG 01-13 08:46:50.174177.174177 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.007450103759765625 seconds
DEBUG 01-13 08:46:50.174754.174754 cuda_h.py:10] start gpu_sexperts
DEBUG 01-13 08:46:50.174361.174361 cuda_h.py:19] end gpu_sexperts cost 0.0002779960632324219 seconds
DEBUG 01-13 08:46:50.174521.174521 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-13 08:46:50.175814.175814 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 1.33514404296875e-05 seconds
DEBUG 01-13 08:46:50.175795.175795 cuda_h.py:10] start wait_experts
INFO 01-13 08:46:50.175253.175253 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 95351223-058e-4dd8-9625-4e940171e77a
DEBUG 01-13 08:46:50.186244.186244 mlpmodule.py:1006] group tensors cost 0.01563715934753418 s
DEBUG 01-13 08:46:50.190346.190346 mlpmodule.py:1044] pad cost 0.0029108524322509766 s
DEBUG 01-13 08:46:50.190549.190549 mlpmodule.py:1050] create cpu tensor cost 7.009506225585938e-05 s
DEBUG 01-13 08:46:50.190062.190062 mlpmodule.py:1055] move to cpu cost 4.76837158203125e-05 s
DEBUG 01-13 08:46:50.199994.199994 mlpmodule.py:1069] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-13 08:46:50.199663.199663 mlpmodule.py:1070] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-13 08:46:50.200071.200071 mlpmodule.py:1075] group_w3 first element: -0.0024261474609375
WARNING 01-13 08:46:50.200957.200957 mlpmodule.py:1085] start einsum2
DEBUG 01-13 08:46:50.216826.216826 mlpmodule.py:1095] group einsum cost 0.025459766387939453 s
DEBUG 01-13 08:46:50.217262.217262 mlpmodule.py:1103] cpy2cputensor cost 0.0007097721099853516 s
INFO 01-13 08:46:50.223969.223969 client.py:127] Model loaded
DEBUG 01-13 08:46:50.223909.223909 cuda_h.py:19] end wait_experts cost 0.04884767532348633 seconds
DEBUG 01-13 08:46:50.223102.223102 cuda_h.py:10] start gpu_experts
DEBUG 01-13 08:46:50.224662.224662 mlpmodule.py:559] gpu group tensors cost 0.0007922649383544922 s
DEBUG 01-13 08:46:50.226224.226224 mlpmodule.py:592] gpu pad cost 0.0018825531005859375 s
DEBUG 01-13 08:46:50.226923.226923 mlpmodule.py:598] start_w1
DEBUG 01-13 08:46:50.227149.227149 mlpmodule.py:602] start_w3
DEBUG 01-13 08:46:50.227732.227732 mlpmodule.py:608] start_w2
DEBUG 01-13 08:46:50.227050.227050 mlpmodule.py:611] gpu group einsum cost 0.0008289813995361328 s
DEBUG 01-13 08:46:50.230161.230161 mlpmodule.py:683] gpu experts func einsum cost 0.006603240966796875 s
DEBUG 01-13 08:46:50.230199.230199 mlpmodule.py:785]  experts func einsum cost 0.06001853942871094 s
DEBUG 01-13 08:46:50.230068.230068 cuda_h.py:19] end gpu_experts cost 0.006860256195068359 seconds
DEBUG 01-13 08:46:50.230215.230215 cuda_h.py:10] start cpu_thread_manager_mp_wait
DEBUG 01-13 08:46:50.230800.230800 cuda_h.py:19] end cpu_thread_manager_mp_wait cost 4.2438507080078125e-05 seconds
DEBUG 01-13 08:46:50.231446.231446 cuda_h.py:19] end layer_moe_generate_mp_l_27 cost 0.06743788719177246 seconds
DEBUG 01-13 08:46:50.231810.231810 cuda_h.py:19] end experts_func_gpu_einsum_mp cost 0.0606837272644043 seconds
DEBUG 01-13 08:46:50.231953.231953 lmp.py:1550] -------------------------------- end prefill layer 26 --------------------------------
DEBUG 01-13 08:46:50.231676.231676 lmp.py:1493] -------------------------------- start prefill layer 27 --------------------------------
DEBUG 01-13 08:46:50.231955.231955 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-13 08:46:50.231017.231017 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-13 08:46:50.231683.231683 cuda_h.py:10] start self_attn
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-13 08:46:50.234765.234765 cuda_h.py:19] end self_attn cost 0.0025644302368164062 seconds
DEBUG 01-13 08:46:50.234908.234908 cuda_h.py:19] end iln_self_attn_paln cost 0.0033016204833984375 seconds
DEBUG 01-13 08:46:50.234320.234320 cuda_h.py:10] start layer_moe_generate_mp_l_28
DEBUG 01-13 08:46:50.234792.234792 cuda_h.py:10] start gate
DEBUG 01-13 08:46:50.235026.235026 cuda_h.py:19] end gate cost 0.0006310939788818359 seconds
DEBUG 01-13 08:46:50.235524.235524 cuda_h.py:10] start experts_map_get
DEBUG 01-13 08:46:50.235925.235925 lmp.py:1611] 
DEBUG 01-13 08:46:50.235925.235925 lmp.py:1611] Expert Token Distribution & Device Allocation:
DEBUG 01-13 08:46:50.235297.235297 lmp.py:1612]   Total experts: 64
DEBUG 01-13 08:46:50.235039.235039 lmp.py:1613]   CPU experts: 32 (50%)
DEBUG 01-13 08:46:50.235920.235920 lmp.py:1614]   GPU experts: 32 (50%)
DEBUG 01-13 08:46:50.235610.235610 lmp.py:1615] 
DEBUG 01-13 08:46:50.235610.235610 lmp.py:1615]   Expert ID | Tokens | Device
DEBUG 01-13 08:46:50.235584.235584 lmp.py:1616]   -----------------------------------
DEBUG 01-13 08:46:50.236565.236565 lmp.py:1622]   Expert 18 |     63 | CPU
DEBUG 01-13 08:46:50.236539.236539 lmp.py:1622]   Expert 54 |     68 | CPU
DEBUG 01-13 08:46:50.236274.236274 lmp.py:1622]   Expert 47 |     76 | CPU
DEBUG 01-13 08:46:50.236295.236295 lmp.py:1622]   Expert 23 |     78 | CPU
DEBUG 01-13 08:46:50.236077.236077 lmp.py:1622]   Expert 44 |     78 | CPU
DEBUG 01-13 08:46:50.236527.236527 lmp.py:1622]   Expert 45 |     78 | CPU
DEBUG 01-13 08:46:50.236740.236740 lmp.py:1622]   Expert 48 |     81 | CPU
DEBUG 01-13 08:46:50.236237.236237 lmp.py:1622]   Expert 20 |     98 | CPU
DEBUG 01-13 08:46:50.236973.236973 lmp.py:1622]   Expert 31 |    105 | CPU
DEBUG 01-13 08:46:50.236947.236947 lmp.py:1622]   Expert 36 |    106 | CPU
DEBUG 01-13 08:46:50.236206.236206 lmp.py:1622]   Expert 61 |    106 | CPU
DEBUG 01-13 08:46:50.236987.236987 lmp.py:1622]   Expert 42 |    112 | CPU
DEBUG 01-13 08:46:50.236008.236008 lmp.py:1622]   Expert 33 |    118 | CPU
DEBUG 01-13 08:46:50.236267.236267 lmp.py:1622]   Expert 10 |    122 | CPU
DEBUG 01-13 08:46:50.236049.236049 lmp.py:1622]   Expert 11 |    123 | CPU
DEBUG 01-13 08:46:50.236069.236069 lmp.py:1622]   Expert 24 |    123 | CPU
DEBUG 01-13 08:46:50.236089.236089 lmp.py:1622]   Expert 43 |    124 | CPU
DEBUG 01-13 08:46:50.236871.236871 lmp.py:1622]   Expert 49 |    125 | CPU
DEBUG 01-13 08:46:50.236653.236653 lmp.py:1622]   Expert 56 |    127 | CPU
DEBUG 01-13 08:46:50.236435.236435 lmp.py:1622]   Expert  6 |    140 | CPU
DEBUG 01-13 08:46:50.236171.236171 lmp.py:1622]   Expert 51 |    140 | CPU
DEBUG 01-13 08:46:50.236145.236145 lmp.py:1622]   Expert 17 |    143 | CPU
DEBUG 01-13 08:46:50.236404.236404 lmp.py:1622]   Expert  0 |    147 | CPU
DEBUG 01-13 08:46:50.236662.236662 lmp.py:1622]   Expert 40 |    154 | CPU
DEBUG 01-13 08:46:50.236696.236696 lmp.py:1622]   Expert  5 |    159 | CPU
DEBUG 01-13 08:46:50.236644.236644 lmp.py:1622]   Expert 55 |    159 | CPU
DEBUG 01-13 08:46:50.236903.236903 lmp.py:1622]   Expert 59 |    160 | CPU
DEBUG 01-13 08:46:50.236116.236116 lmp.py:1622]   Expert 12 |    162 | CPU
DEBUG 01-13 08:46:50.236613.236613 lmp.py:1622]   Expert 26 |    163 | CPU
DEBUG 01-13 08:46:50.236349.236349 lmp.py:1622]   Expert 38 |    165 | CPU
DEBUG 01-13 08:46:50.236607.236607 lmp.py:1622]   Expert 57 |    167 | CPU
DEBUG 01-13 08:46:50.236105.236105 lmp.py:1622]   Expert 46 |    172 | CPU
DEBUG 01-13 08:46:50.236602.236602 lmp.py:1622]   Expert 13 |    176 | GPU
DEBUG 01-13 08:46:50.236576.236576 lmp.py:1622]   Expert 30 |    176 | GPU
DEBUG 01-13 08:46:50.236504.236504 lmp.py:1622]   Expert 35 |    176 | GPU
DEBUG 01-13 08:46:50.236716.236716 lmp.py:1622]   Expert  7 |    177 | GPU
DEBUG 01-13 08:46:50.236167.236167 lmp.py:1622]   Expert 58 |    177 | GPU
DEBUG 01-13 08:46:50.236095.236095 lmp.py:1622]   Expert 16 |    184 | GPU
DEBUG 01-13 08:46:50.236784.236784 lmp.py:1622]   Expert 50 |    188 | GPU
DEBUG 01-13 08:46:50.236520.236520 lmp.py:1622]   Expert 14 |    200 | GPU
DEBUG 01-13 08:46:50.236255.236255 lmp.py:1622]   Expert 32 |    202 | GPU
DEBUG 01-13 08:46:50.236752.236752 lmp.py:1622]   Expert 15 |    204 | GPU
DEBUG 01-13 08:46:50.236726.236726 lmp.py:1622]   Expert  1 |    215 | GPU
DEBUG 01-13 08:46:50.236224.236224 lmp.py:1622]   Expert  3 |    216 | GPU
DEBUG 01-13 08:46:50.236198.236198 lmp.py:1622]   Expert  4 |    228 | GPU
DEBUG 01-13 08:46:50.236695.236695 lmp.py:1622]   Expert 39 |    233 | GPU
DEBUG 01-13 08:46:50.236669.236669 lmp.py:1622]   Expert 52 |    237 | GPU
DEBUG 01-13 08:46:50.236881.236881 lmp.py:1622]   Expert 28 |    239 | GPU
DEBUG 01-13 08:46:50.236809.236809 lmp.py:1622]   Expert 34 |    239 | GPU
DEBUG 01-13 08:46:50.236260.236260 lmp.py:1622]   Expert 25 |    243 | GPU
DEBUG 01-13 08:46:50.236711.236711 lmp.py:1622]   Expert 22 |    257 | GPU
DEBUG 01-13 08:46:50.236162.236162 lmp.py:1622]   Expert 21 |    273 | GPU
DEBUG 01-13 08:46:50.236851.236851 lmp.py:1622]   Expert 41 |    275 | GPU
DEBUG 01-13 08:46:50.236348.236348 lmp.py:1622]   Expert  2 |    280 | GPU
DEBUG 01-13 08:46:50.236084.236084 lmp.py:1622]   Expert 60 |    288 | GPU
DEBUG 01-13 08:46:50.236581.236581 lmp.py:1622]   Expert 29 |    289 | GPU
DEBUG 01-13 08:46:50.236317.236317 lmp.py:1622]   Expert 63 |    293 | GPU
DEBUG 01-13 08:46:50.236814.236814 lmp.py:1622]   Expert 62 |    302 | GPU
DEBUG 01-13 08:46:50.236550.236550 lmp.py:1622]   Expert 27 |    308 | GPU
DEBUG 01-13 08:46:50.236047.236047 lmp.py:1622]   Expert  8 |    333 | GPU
DEBUG 01-13 08:46:50.236782.236782 lmp.py:1622]   Expert 53 |    333 | GPU
DEBUG 01-13 08:46:50.237280.237280 lmp.py:1622]   Expert 37 |    339 | GPU
DEBUG 01-13 08:46:50.237538.237538 lmp.py:1622]   Expert 19 |    439 | GPU
DEBUG 01-13 08:46:50.237036.237036 lmp.py:1622]   Expert  9 |    627 | GPU
DEBUG 01-13 08:46:50.237679.237679 lmp.py:1623] 
DEBUG 01-13 08:46:50.237679.237679 lmp.py:1623]   CPU total tokens: 3942 (32.1%)
DEBUG 01-13 08:46:50.237560.237560 lmp.py:1624]   GPU total tokens: 8346 (67.9%)
DEBUG 01-13 08:46:50.237256.237256 cuda_h.py:19] end experts_map_get cost 0.0014605522155761719 seconds
DEBUG 01-13 08:46:50.237483.237483 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-13 08:46:50.237570.237570 lmp.py:1632] 
DEBUG 01-13 08:46:50.237570.237570 lmp.py:1632]   Computing 32 experts on CPU MP...
DEBUG 01-13 08:46:50.237453.237453 cuda_h.py:19] end cpu_experts_submit cost 5.3882598876953125e-05 seconds
DEBUG 01-13 08:46:50.237911.237911 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-13 08:46:50.237316.237316 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-13 08:46:50.237096.237096 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-13 08:46:50.238948.238948 cuda_h.py:19] end allocate_cuda_memory cost 0.0003383159637451172 seconds
DEBUG 01-13 08:46:50.238519.238519 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-13 08:46:50.238613.238613 sllm_store_c.py:27] get device uuid map
DEBUG 01-13 08:46:50.238913.238913 sllm_store_c.py:29] call client load into gpu
DEBUG 01-13 08:46:50.238660.238660 cuda_h.py:10] start experts_func_gpu_einsum_mp
DEBUG 01-13 08:46:50.238854.238854 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, d1b4084a-5013-43f3-8132-b4e995c64b6c
DEBUG 01-13 08:46:50.238961.238961 client.py:106] call stub.LoadModelAsync
INFO 01-13 08:46:50.240438.240438 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, d1b4084a-5013-43f3-8132-b4e995c64b6c
DEBUG 01-13 08:46:50.240181.240181 cuda_h.py:19] end load_into_gpu_async cost 0.002525806427001953 seconds
DEBUG 01-13 08:46:50.240692.240692 cuda_h.py:10] start restore_tensors2
DEBUG 01-13 08:46:50.241550.241550 cuda_h.py:19] end restore_tensors2 cost 0.0004642009735107422 seconds
DEBUG 01-13 08:46:50.241346.241346 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.004035234451293945 seconds
DEBUG 01-13 08:46:50.241070.241070 cuda_h.py:10] start restore2model
DEBUG 01-13 08:46:50.243891.243891 cuda_h.py:19] end restore2model cost 0.0025429725646972656 seconds
DEBUG 01-13 08:46:50.244773.244773 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.006758928298950195 seconds
DEBUG 01-13 08:46:50.244397.244397 cuda_h.py:10] start gpu_sexperts
DEBUG 01-13 08:46:50.244971.244971 cuda_h.py:19] end gpu_sexperts cost 0.0002734661102294922 seconds
DEBUG 01-13 08:46:50.244543.244543 cuda_h.py:10] start wait_experts
INFO 01-13 08:46:50.244583.244583 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, d1b4084a-5013-43f3-8132-b4e995c64b6c
DEBUG 01-13 08:46:50.245816.245816 mlpmodule.py:1006] group tensors cost 0.006512880325317383 s
DEBUG 01-13 08:46:50.250282.250282 mlpmodule.py:1044] pad cost 0.0037376880645751953 s
DEBUG 01-13 08:46:50.250427.250427 mlpmodule.py:1050] create cpu tensor cost 8.344650268554688e-05 s
DEBUG 01-13 08:46:50.250927.250927 mlpmodule.py:1055] move to cpu cost 5.53131103515625e-05 s
DEBUG 01-13 08:46:50.258235.258235 mlpmodule.py:1069] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-13 08:46:50.258798.258798 mlpmodule.py:1070] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-13 08:46:50.258677.258677 mlpmodule.py:1075] group_w3 first element: -0.006439208984375
WARNING 01-13 08:46:50.258954.258954 mlpmodule.py:1085] start einsum2
DEBUG 01-13 08:46:50.272068.272068 mlpmodule.py:1095] group einsum cost 0.02147984504699707 s
DEBUG 01-13 08:46:50.273180.273180 mlpmodule.py:1103] cpy2cputensor cost 0.0007331371307373047 s
DEBUG 01-13 08:46:50.290229.290229 mlpmodule.py:785]  experts func einsum cost 0.05129694938659668 s
DEBUG 01-13 08:46:50.290831.290831 cuda_h.py:19] end experts_func_gpu_einsum_mp cost 0.052097320556640625 seconds
INFO 01-13 08:46:50.293399.293399 client.py:127] Model loaded
DEBUG 01-13 08:46:50.293391.293391 cuda_h.py:19] end wait_experts cost 0.049211740493774414 seconds
DEBUG 01-13 08:46:50.293478.293478 cuda_h.py:10] start gpu_experts
DEBUG 01-13 08:46:50.294926.294926 mlpmodule.py:559] gpu group tensors cost 0.0006160736083984375 s
DEBUG 01-13 08:46:50.296602.296602 mlpmodule.py:592] gpu pad cost 0.001550436019897461 s
DEBUG 01-13 08:46:50.296368.296368 mlpmodule.py:598] start_w1
DEBUG 01-13 08:46:50.296276.296276 mlpmodule.py:602] start_w3
DEBUG 01-13 08:46:50.296077.296077 mlpmodule.py:608] start_w2
DEBUG 01-13 08:46:50.297037.297037 mlpmodule.py:611] gpu group einsum cost 0.0008082389831542969 s
DEBUG 01-13 08:46:50.299109.299109 mlpmodule.py:683] gpu experts func einsum cost 0.005702495574951172 s
DEBUG 01-13 08:46:50.299084.299084 cuda_h.py:19] end gpu_experts cost 0.0060007572174072266 seconds
DEBUG 01-13 08:46:50.299628.299628 cuda_h.py:10] start cpu_thread_manager_mp_wait
DEBUG 01-13 08:46:50.299843.299843 cuda_h.py:19] end cpu_thread_manager_mp_wait cost 4.315376281738281e-05 seconds
DEBUG 01-13 08:46:50.300264.300264 cuda_h.py:19] end layer_moe_generate_mp_l_28 cost 0.06513071060180664 seconds
DEBUG 01-13 08:46:50.300756.300756 lmp.py:1550] -------------------------------- end prefill layer 27 --------------------------------
DEBUG 01-13 08:46:50.300817.300817 cuda_h.py:19] end prefill_layer cost 1.9150378704071045 seconds
Collecting data...
Generating '/tmp/nsys-report-8035.qdstrm'
[1/1] [0%                          ] report1.nsys-rep[1/1] [0%                          ] report1.nsys-rep[1/1] [0%                          ] report1.nsys-rep[1/1] [7%                          ] report1.nsys-rep[1/1] [10%                         ] report1.nsys-rep[1/1] [13%                         ] report1.nsys-rep[1/1] [=16%                        ] report1.nsys-rep[1/1] [==19%                       ] report1.nsys-rep[1/1] [==21%                       ] report1.nsys-rep[1/1] [===24%                      ] report1.nsys-rep[1/1] [====27%                     ] report1.nsys-rep[1/1] [=====31%                    ] report1.nsys-rep[1/1] [======35%                   ] report1.nsys-rep[1/1] [=======39%                  ] report1.nsys-rep[1/1] [=========43%                ] report1.nsys-rep[1/1] [==========47%               ] report1.nsys-rep[1/1] [===========50%              ] report1.nsys-rep[1/1] [========================100%] report1.nsys-rep[1/1] [========================100%] report1.nsys-rep
Generated:
	/mnt/zhengcf3/lmp/examples/report1.nsys-rep
