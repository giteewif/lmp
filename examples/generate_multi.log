here pin
INFO 01-14 20:42:07.354755.354755 pinpool.py:28] Initializing PinnedMemoryPool with 2GB total, allocating in 1024MB chunks...
DEBUG 01-14 20:42:08.226657.226657 pinpool.py:40] Allocated chunk 1: 536870912 elements (1024.0 MB)
DEBUG 01-14 20:42:08.703669.703669 pinpool.py:40] Allocated chunk 2: 536870912 elements (1024.0 MB)
INFO 01-14 20:42:08.703212.703212 pinpool.py:52] Successfully allocated 2 chunks, total 1073741824 elements (2048.0 MB) in 1.350s
DEBUG 01-14 20:42:08.819310.819310 cuda_memory_view.py:613] 
DEBUG 01-14 20:42:08.819310.819310 cuda_memory_view.py:613] restore_tensors_from_shared_memory_names time: 0.014397859573364258
DEBUG 01-14 20:42:08.836787.836787 cuda_h.py:10] start init_mp_process
DEBUG 01-14 20:42:08.868622.868622 cuda_h.py:19] end init_mp_process cost 0.03155350685119629 seconds
DEBUG 01-14 20:42:10.870538.870538 cuda_h.py:10] start generate_input_ids
generate input ids cost 0.11499333381652832 s
DEBUG 01-14 20:42:11.410499.410499 cuda_h.py:19] end generate_input_ids cost 0.5389394760131836 seconds
DEBUG 01-14 20:42:11.410796.410796 cuda_h.py:10] start init_cache
DEBUG 01-14 20:42:11.410046.410046 cuda_h.py:19] end init_cache cost 0.00010800361633300781 seconds
here pin
INFO 01-14 20:42:12.630245.630245 pinpool.py:28] Initializing PinnedMemoryPool with 2GB total, allocating in 1024MB chunks...
DEBUG 01-14 20:42:13.460162.460162 pinpool.py:40] Allocated chunk 1: 536870912 elements (1024.0 MB)
DEBUG 01-14 20:42:13.912467.912467 pinpool.py:40] Allocated chunk 2: 536870912 elements (1024.0 MB)
INFO 01-14 20:42:13.913259.913259 pinpool.py:52] Successfully allocated 2 chunks, total 1073741824 elements (2048.0 MB) in 1.282s
DEBUG 01-14 20:42:13.922219.922219 cpu_thread_manager_mp.py:80] 初始化
DEBUG 01-14 20:42:14.036607.036607 cuda_memory_view.py:613] 
DEBUG 01-14 20:42:14.036607.036607 cuda_memory_view.py:613] restore_tensors_from_shared_memory_names time: 0.020862579345703125
DEBUG 01-14 20:42:14.041481.041481 cuda_h.py:10] start init_meta_layer
DEBUG 01-14 20:42:14.041919.041919 cuda_h.py:19] end init_meta_layer cost 1.0967254638671875e-05 seconds
DEBUG 01-14 20:42:14.041543.041543 cuda_h.py:10] start init_weights
DEBUG 01-14 20:42:14.041259.041259 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-14 20:42:14.042122.042122 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-14 20:42:14.042588.042588 cuda_h.py:19] end allocate_cuda_memory cost 0.0004410743713378906 seconds
DEBUG 01-14 20:42:14.042909.042909 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-14 20:42:14.042116.042116 sllm_store_c.py:27] get device uuid map
DEBUG 01-14 20:42:14.042390.042390 sllm_store_c.py:29] call client load into gpu
DEBUG 01-14 20:42:14.042384.042384 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 6bf8afa5-4f7e-4150-b317-0fcb25a1b27b
DEBUG 01-14 20:42:14.042931.042931 client.py:106] call stub.LoadModelAsync
INFO 01-14 20:42:14.044588.044588 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 6bf8afa5-4f7e-4150-b317-0fcb25a1b27b
DEBUG 01-14 20:42:14.044306.044306 cuda_h.py:19] end load_into_gpu_async cost 0.0017287731170654297 seconds
DEBUG 01-14 20:42:14.044751.044751 cuda_h.py:10] start restore_tensors2
DEBUG 01-14 20:42:14.044894.044894 cuda_h.py:19] end restore_tensors2 cost 7.581710815429688e-05 seconds
DEBUG 01-14 20:42:14.044842.044842 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0025458335876464844 seconds
DEBUG 01-14 20:42:14.044737.044737 cuda_h.py:10] start restore2model
DEBUG 01-14 20:42:14.044043.044043 cuda_h.py:19] end restore2model cost 0.0001976490020751953 seconds
INFO 01-14 20:42:14.044382.044382 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 6bf8afa5-4f7e-4150-b317-0fcb25a1b27b
INFO 01-14 20:42:14.126876.126876 client.py:127] Model loaded
DEBUG 01-14 20:42:14.126146.126146 cuda_h.py:10] start load_qkvogns_weight_l_0
DEBUG 01-14 20:42:14.126720.126720 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-14 20:42:14.126811.126811 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-14 20:42:14.127675.127675 cuda_h.py:19] end allocate_cuda_memory cost 0.0003941059112548828 seconds
DEBUG 01-14 20:42:14.127038.127038 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-14 20:42:14.127128.127128 sllm_store_c.py:27] get device uuid map
DEBUG 01-14 20:42:14.127608.127608 sllm_store_c.py:29] call client load into gpu
DEBUG 01-14 20:42:14.127518.127518 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 10d0a64e-98f3-4706-bf2e-1c3e90c10260
DEBUG 01-14 20:42:14.127730.127730 client.py:106] call stub.LoadModelAsync
INFO 01-14 20:42:14.129576.129576 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 10d0a64e-98f3-4706-bf2e-1c3e90c10260
DEBUG 01-14 20:42:14.129898.129898 cuda_h.py:19] end load_into_gpu_async cost 0.002037525177001953 seconds
DEBUG 01-14 20:42:14.129238.129238 cuda_h.py:10] start restore_tensors2
DEBUG 01-14 20:42:14.129088.129088 cuda_h.py:19] end restore_tensors2 cost 0.0001595020294189453 seconds
DEBUG 01-14 20:42:14.129362.129362 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0032656192779541016 seconds
INFO 01-14 20:42:14.129279.129279 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 10d0a64e-98f3-4706-bf2e-1c3e90c10260
INFO 01-14 20:42:14.146053.146053 client.py:127] Model loaded
DEBUG 01-14 20:42:14.146726.146726 cuda_h.py:10] start restore2model
DEBUG 01-14 20:42:14.147409.147409 cuda_h.py:19] end restore2model cost 0.0008914470672607422 seconds
DEBUG 01-14 20:42:14.147976.147976 cuda_h.py:19] end load_qkvogns_weight_l_0 cost 0.021325111389160156 seconds
DEBUG 01-14 20:42:14.147820.147820 cuda_h.py:19] end init_weights cost 0.10595917701721191 seconds
DEBUG 01-14 20:42:14.148929.148929 cuda_h.py:10] start copy_emodel
DEBUG 01-14 20:42:14.828821.828821 cuda_h.py:19] end copy_emodel cost 0.6802120208740234 seconds
DEBUG 01-14 20:42:14.829458.829458 cuda_h.py:10] start init_inputs_tokens
DEBUG 01-14 20:42:14.905687.905687 cuda_h.py:19] end init_inputs_tokens cost 0.07618236541748047 seconds
DEBUG 01-14 20:42:14.905665.905665 cuda_h.py:10] start prefill
DEBUG 01-14 20:42:14.905203.905203 cuda_h.py:10] start prefill_layer
DEBUG 01-14 20:42:14.905581.905581 lmp.py:1494] -------------------------------- start prefill layer 0 --------------------------------
DEBUG 01-14 20:42:14.905185.905185 cuda_h.py:10] start start_load_qkvogn_s_weight_l_1
DEBUG 01-14 20:42:14.905364.905364 cuda_h.py:10] start start_load_qkvogn_s_weight_l_1
DEBUG 01-14 20:42:14.905513.905513 cuda_h.py:19] end start_load_qkvogn_s_weight_l_1 cost 4.673004150390625e-05 seconds
DEBUG 01-14 20:42:14.905143.905143 cuda_h.py:19] end start_load_qkvogn_s_weight_l_1 cost 9.512901306152344e-05 seconds
DEBUG 01-14 20:42:14.905409.905409 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-14 20:42:14.905054.905054 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-14 20:42:14.905561.905561 cuda_h.py:10] start sllm_worker_task
DEBUG 01-14 20:42:14.906406.906406 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-14 20:42:14.906408.906408 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-14 20:42:14.906682.906682 cuda_h.py:19] end allocate_cuda_memory cost 0.0002262592315673828 seconds
DEBUG 01-14 20:42:14.906566.906566 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-14 20:42:14.906528.906528 sllm_store_c.py:27] get device uuid map
DEBUG 01-14 20:42:14.906079.906079 sllm_store_c.py:29] call client load into gpu
DEBUG 01-14 20:42:14.906935.906935 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, a9c3784d-6017-421c-b170-ad6577b0b8c8
DEBUG 01-14 20:42:14.906455.906455 client.py:106] call stub.LoadModelAsync
INFO 01-14 20:42:14.908999.908999 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, a9c3784d-6017-421c-b170-ad6577b0b8c8
DEBUG 01-14 20:42:14.908975.908975 cuda_h.py:19] end load_into_gpu_async cost 0.0020804405212402344 seconds
DEBUG 01-14 20:42:14.908275.908275 cuda_h.py:10] start restore_tensors2
DEBUG 01-14 20:42:14.908631.908631 cuda_h.py:19] end restore_tensors2 cost 0.00011420249938964844 seconds
DEBUG 01-14 20:42:14.908560.908560 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.002771139144897461 seconds
INFO 01-14 20:42:14.908774.908774 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, a9c3784d-6017-421c-b170-ad6577b0b8c8
INFO 01-14 20:42:14.916644.916644 client.py:127] Model loaded
DEBUG 01-14 20:42:14.916978.916978 cuda_h.py:10] start restore2model
DEBUG 01-14 20:42:14.917299.917299 cuda_h.py:19] end restore2model cost 0.0006399154663085938 seconds
DEBUG 01-14 20:42:14.917215.917215 cuda_h.py:19] end sllm_worker_task cost 0.011528253555297852 seconds
DEBUG 01-14 20:42:14.997886.997886 cuda_h.py:10] start self_attn
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-14 20:42:15.252168.252168 cuda_h.py:19] end self_attn cost 0.25488901138305664 seconds
DEBUG 01-14 20:42:15.253879.253879 cuda_h.py:19] end iln_self_attn_paln cost 0.347461462020874 seconds
DEBUG 01-14 20:42:15.253451.253451 cuda_h.py:10] start dense_mlp
DEBUG 01-14 20:42:15.260131.260131 cuda_h.py:19] end dense_mlp cost 0.0067996978759765625 seconds
DEBUG 01-14 20:42:15.260347.260347 cuda_h.py:19] end prefill_layer cost 0.35474538803100586 seconds
DEBUG 01-14 20:42:15.260322.260322 lmp.py:1551] -------------------------------- end prefill layer 0 --------------------------------
DEBUG 01-14 20:42:15.260117.260117 cuda_h.py:10] start prefill_layer
DEBUG 01-14 20:42:15.260343.260343 lmp.py:1494] -------------------------------- start prefill layer 1 --------------------------------
DEBUG 01-14 20:42:15.260709.260709 cuda_h.py:10] start start_load_qkvogn_s_weight_l_2
DEBUG 01-14 20:42:15.260935.260935 cuda_h.py:10] start start_load_qkvogn_s_weight_l_2
DEBUG 01-14 20:42:15.260824.260824 cuda_h.py:19] end start_load_qkvogn_s_weight_l_2 cost 3.075599670410156e-05 seconds
DEBUG 01-14 20:42:15.260408.260408 cuda_h.py:19] end start_load_qkvogn_s_weight_l_2 cost 8.058547973632812e-05 seconds
DEBUG 01-14 20:42:15.260435.260435 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-14 20:42:15.260650.260650 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-14 20:42:15.260621.260621 cuda_h.py:10] start sllm_worker_task
DEBUG 01-14 20:42:15.261575.261575 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-14 20:42:15.261885.261885 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-14 20:42:15.261728.261728 cuda_h.py:19] end allocate_cuda_memory cost 0.0003161430358886719 seconds
DEBUG 01-14 20:42:15.261998.261998 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-14 20:42:15.261134.261134 sllm_store_c.py:27] get device uuid map
DEBUG 01-14 20:42:15.262198.262198 sllm_store_c.py:29] call client load into gpu
DEBUG 01-14 20:42:15.262194.262194 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, bf0a1ba1-e58d-4881-9ec7-df47470cf850
DEBUG 01-14 20:42:15.262447.262447 client.py:106] call stub.LoadModelAsync
DEBUG 01-14 20:42:15.262669.262669 cuda_h.py:10] start self_attn
INFO 01-14 20:42:15.264470.264470 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, bf0a1ba1-e58d-4881-9ec7-df47470cf850
DEBUG 01-14 20:42:15.264377.264377 cuda_h.py:19] end load_into_gpu_async cost 0.0024912357330322266 seconds
DEBUG 01-14 20:42:15.264228.264228 cuda_h.py:10] start restore_tensors2
DEBUG 01-14 20:42:15.264137.264137 cuda_h.py:19] end restore_tensors2 cost 0.00014710426330566406 seconds
DEBUG 01-14 20:42:15.264339.264339 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.003711223602294922 seconds
INFO 01-14 20:42:15.265796.265796 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, bf0a1ba1-e58d-4881-9ec7-df47470cf850
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-14 20:42:15.266047.266047 cuda_h.py:19] end self_attn cost 0.003559112548828125 seconds
DEBUG 01-14 20:42:15.266719.266719 cuda_h.py:19] end iln_self_attn_paln cost 0.00584721565246582 seconds
DEBUG 01-14 20:42:15.266052.266052 cuda_h.py:10] start layer_moe_generate_mp_l_2
DEBUG 01-14 20:42:15.266868.266868 cuda_h.py:10] start gate
INFO 01-14 20:42:15.272852.272852 client.py:127] Model loaded
DEBUG 01-14 20:42:15.272605.272605 cuda_h.py:10] start restore2model
DEBUG 01-14 20:42:15.273238.273238 cuda_h.py:19] end restore2model cost 0.0010042190551757812 seconds
DEBUG 01-14 20:42:15.273011.273011 cuda_h.py:19] end sllm_worker_task cost 0.012624502182006836 seconds
DEBUG 01-14 20:42:15.366059.366059 cuda_h.py:19] end gate cost 0.10016989707946777 seconds
DEBUG 01-14 20:42:15.367845.367845 cuda_h.py:10] start experts_map_get
DEBUG 01-14 20:42:15.367658.367658 lmp.py:1615] 
DEBUG 01-14 20:42:15.367658.367658 lmp.py:1615] Expert Token Distribution & Device Allocation:
DEBUG 01-14 20:42:15.367567.367567 lmp.py:1616]   Total experts: 64
DEBUG 01-14 20:42:15.367885.367885 lmp.py:1617]   CPU experts: 32 (50%)
DEBUG 01-14 20:42:15.367436.367436 lmp.py:1618]   GPU experts: 32 (50%)
DEBUG 01-14 20:42:15.367317.367317 lmp.py:1619] 
DEBUG 01-14 20:42:15.367317.367317 lmp.py:1619]   Expert ID | Tokens | Device
DEBUG 01-14 20:42:15.367914.367914 lmp.py:1620]   -----------------------------------
DEBUG 01-14 20:42:15.367630.367630 lmp.py:1625]   Expert 25 |     64 | CPU
DEBUG 01-14 20:42:15.367465.367465 lmp.py:1625]   Expert 54 |     67 | CPU
DEBUG 01-14 20:42:15.367870.367870 lmp.py:1625]   Expert  3 |     68 | CPU
DEBUG 01-14 20:42:15.367274.367274 lmp.py:1625]   Expert 31 |     72 | CPU
DEBUG 01-14 20:42:15.367679.367679 lmp.py:1625]   Expert 55 |     72 | CPU
DEBUG 01-14 20:42:15.367845.367845 lmp.py:1625]   Expert 62 |     87 | CPU
DEBUG 01-14 20:42:15.367011.367011 lmp.py:1625]   Expert 18 |     88 | CPU
DEBUG 01-14 20:42:15.367654.367654 lmp.py:1625]   Expert 52 |     98 | CPU
DEBUG 01-14 20:42:15.367059.367059 lmp.py:1625]   Expert 22 |    100 | CPU
DEBUG 01-14 20:42:15.367463.367463 lmp.py:1625]   Expert 47 |    104 | CPU
DEBUG 01-14 20:42:15.367060.367060 lmp.py:1625]   Expert  0 |    113 | CPU
DEBUG 01-14 20:42:15.367802.367802 lmp.py:1625]   Expert 37 |    117 | CPU
DEBUG 01-14 20:42:15.367637.367637 lmp.py:1625]   Expert 27 |    121 | CPU
DEBUG 01-14 20:42:15.367903.367903 lmp.py:1625]   Expert 32 |    123 | CPU
DEBUG 01-14 20:42:15.367308.367308 lmp.py:1625]   Expert 41 |    130 | CPU
DEBUG 01-14 20:42:15.367474.367474 lmp.py:1625]   Expert 44 |    131 | CPU
DEBUG 01-14 20:42:15.367401.367401 lmp.py:1625]   Expert 28 |    136 | CPU
DEBUG 01-14 20:42:15.367329.367329 lmp.py:1625]   Expert 13 |    138 | CPU
DEBUG 01-14 20:42:15.367495.367495 lmp.py:1625]   Expert 58 |    140 | CPU
DEBUG 01-14 20:42:15.367185.367185 lmp.py:1625]   Expert 60 |    144 | CPU
DEBUG 01-14 20:42:15.367351.367351 lmp.py:1625]   Expert 43 |    147 | CPU
DEBUG 01-14 20:42:15.367278.367278 lmp.py:1625]   Expert  1 |    150 | CPU
DEBUG 01-14 20:42:15.367729.367729 lmp.py:1625]   Expert 38 |    153 | CPU
DEBUG 01-14 20:42:15.367657.367657 lmp.py:1625]   Expert 49 |    154 | CPU
DEBUG 01-14 20:42:15.367062.367062 lmp.py:1625]   Expert 51 |    155 | CPU
DEBUG 01-14 20:42:15.367658.367658 lmp.py:1625]   Expert 34 |    161 | CPU
DEBUG 01-14 20:42:15.367401.367401 lmp.py:1625]   Expert 35 |    164 | CPU
DEBUG 01-14 20:42:15.368381.368381 lmp.py:1625]   Expert 36 |    168 | CPU
DEBUG 01-14 20:42:15.368024.368024 lmp.py:1625]   Expert 11 |    170 | CPU
DEBUG 01-14 20:42:15.368191.368191 lmp.py:1625]   Expert 17 |    170 | CPU
DEBUG 01-14 20:42:15.368118.368118 lmp.py:1625]   Expert 59 |    174 | CPU
DEBUG 01-14 20:42:15.368808.368808 lmp.py:1625]   Expert 10 |    180 | CPU
DEBUG 01-14 20:42:15.368735.368735 lmp.py:1625]   Expert 20 |    182 | GPU
DEBUG 01-14 20:42:15.368663.368663 lmp.py:1625]   Expert  2 |    186 | GPU
DEBUG 01-14 20:42:15.368591.368591 lmp.py:1625]   Expert 39 |    189 | GPU
DEBUG 01-14 20:42:15.368280.368280 lmp.py:1625]   Expert 33 |    197 | GPU
DEBUG 01-14 20:42:15.368969.368969 lmp.py:1625]   Expert 12 |    198 | GPU
DEBUG 01-14 20:42:15.368420.368420 lmp.py:1625]   Expert 21 |    198 | GPU
DEBUG 01-14 20:42:15.368110.368110 lmp.py:1625]   Expert 48 |    198 | GPU
DEBUG 01-14 20:42:15.368037.368037 lmp.py:1625]   Expert 15 |    199 | GPU
DEBUG 01-14 20:42:15.368965.368965 lmp.py:1625]   Expert 53 |    204 | GPU
DEBUG 01-14 20:42:15.368893.368893 lmp.py:1625]   Expert 19 |    220 | GPU
DEBUG 01-14 20:42:15.368820.368820 lmp.py:1625]   Expert 26 |    221 | GPU
DEBUG 01-14 20:42:15.368702.368702 lmp.py:1625]   Expert 30 |    221 | GPU
DEBUG 01-14 20:42:15.368868.368868 lmp.py:1625]   Expert 45 |    221 | GPU
DEBUG 01-14 20:42:15.368034.368034 lmp.py:1625]   Expert  5 |    227 | GPU
DEBUG 01-14 20:42:15.368962.368962 lmp.py:1625]   Expert  4 |    229 | GPU
DEBUG 01-14 20:42:15.368651.368651 lmp.py:1625]   Expert 24 |    229 | GPU
DEBUG 01-14 20:42:15.368579.368579 lmp.py:1625]   Expert 42 |    242 | GPU
DEBUG 01-14 20:42:15.368904.368904 lmp.py:1625]   Expert 50 |    245 | GPU
DEBUG 01-14 20:42:15.368508.368508 lmp.py:1625]   Expert 29 |    254 | GPU
DEBUG 01-14 20:42:15.368396.368396 lmp.py:1625]   Expert 56 |    262 | GPU
DEBUG 01-14 20:42:15.368191.368191 lmp.py:1625]   Expert 61 |    270 | GPU
DEBUG 01-14 20:42:15.368179.368179 lmp.py:1625]   Expert  8 |    283 | GPU
DEBUG 01-14 20:42:15.368014.368014 lmp.py:1625]   Expert 63 |    285 | GPU
DEBUG 01-14 20:42:15.368518.368518 lmp.py:1625]   Expert 46 |    294 | GPU
DEBUG 01-14 20:42:15.368353.368353 lmp.py:1625]   Expert  9 |    300 | GPU
DEBUG 01-14 20:42:15.368758.368758 lmp.py:1625]   Expert  6 |    316 | GPU
DEBUG 01-14 20:42:15.368447.368447 lmp.py:1625]   Expert 16 |    316 | GPU
DEBUG 01-14 20:42:15.368136.368136 lmp.py:1625]   Expert 40 |    319 | GPU
DEBUG 01-14 20:42:15.368064.368064 lmp.py:1625]   Expert  7 |    322 | GPU
DEBUG 01-14 20:42:15.368992.368992 lmp.py:1625]   Expert 23 |    325 | GPU
DEBUG 01-14 20:42:15.368920.368920 lmp.py:1625]   Expert 14 |    413 | GPU
DEBUG 01-14 20:42:15.368609.368609 lmp.py:1625]   Expert 57 |    464 | GPU
DEBUG 01-14 20:42:15.368490.368490 lmp.py:1626] 
DEBUG 01-14 20:42:15.368490.368490 lmp.py:1626]   CPU total tokens: 4059 (33.0%)
DEBUG 01-14 20:42:15.368087.368087 lmp.py:1627]   GPU total tokens: 8229 (67.0%)
DEBUG 01-14 20:42:15.368459.368459 cuda_h.py:19] end experts_map_get cost 0.0016696453094482422 seconds
DEBUG 01-14 20:42:15.368325.368325 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-14 20:42:15.368579.368579 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-14 20:42:15.369527.369527 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-14 20:42:15.369095.369095 cuda_h.py:19] end allocate_cuda_memory cost 0.0003018379211425781 seconds
DEBUG 01-14 20:42:15.369442.369442 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-14 20:42:15.369775.369775 sllm_store_c.py:27] get device uuid map
DEBUG 01-14 20:42:15.369836.369836 sllm_store_c.py:29] call client load into gpu
DEBUG 01-14 20:42:15.369777.369777 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 19b015cc-c4aa-47e9-934b-2bac4a391dc6
DEBUG 01-14 20:42:15.369539.369539 client.py:106] call stub.LoadModelAsync
INFO 01-14 20:42:15.372714.372714 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 19b015cc-c4aa-47e9-934b-2bac4a391dc6
DEBUG 01-14 20:42:15.372571.372571 cuda_h.py:19] end load_into_gpu_async cost 0.002410888671875 seconds
DEBUG 01-14 20:42:15.372393.372393 cuda_h.py:10] start restore_tensors2
DEBUG 01-14 20:42:15.372080.372080 cuda_h.py:19] end restore_tensors2 cost 0.0003027915954589844 seconds
DEBUG 01-14 20:42:15.372141.372141 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0035126209259033203 seconds
DEBUG 01-14 20:42:15.372858.372858 cuda_h.py:10] start restore2model
DEBUG 01-14 20:42:15.375071.375071 cuda_h.py:19] end restore2model cost 0.0025835037231445312 seconds
DEBUG 01-14 20:42:15.375828.375828 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.006288766860961914 seconds
DEBUG 01-14 20:42:15.375790.375790 cuda_h.py:10] start gpu_sexperts
DEBUG 01-14 20:42:15.375205.375205 cuda_h.py:19] end gpu_sexperts cost 0.0004818439483642578 seconds
DEBUG 01-14 20:42:15.375332.375332 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-14 20:42:15.375141.375141 lmp.py:1683] 
DEBUG 01-14 20:42:15.375141.375141 lmp.py:1683]   Computing 32 experts on CPU...
DEBUG 01-14 20:42:15.375382.375382 cuda_h.py:19] end cpu_experts_submit cost 7.224082946777344e-05 seconds
DEBUG 01-14 20:42:15.375854.375854 cuda_h.py:10] start experts_func_mgpu_group_pad
DEBUG 01-14 20:42:15.388734.388734 mlpmodule.py:1460] group tensors cost 0.011820793151855469 s
DEBUG 01-14 20:42:15.388613.388613 cuda_h.py:10] start move_flat_hidden2cpu
DEBUG 01-14 20:42:15.390065.390065 cuda_h.py:19] end experts_func_mgpu_group_pad cost 0.014969348907470703 seconds
DEBUG 01-14 20:42:15.391095.391095 cuda_h.py:10] start gpu_group_list
DEBUG 01-14 20:42:15.392931.392931 cuda_h.py:19] end gpu_group_list cost 0.00037789344787597656 seconds
DEBUG 01-14 20:42:15.392112.392112 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-14 20:42:15.392493.392493 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.86102294921875e-05 seconds
DEBUG 01-14 20:42:15.392038.392038 cuda_h.py:10] start wait_experts
INFO 01-14 20:42:15.392159.392159 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 19b015cc-c4aa-47e9-934b-2bac4a391dc6
DEBUG 01-14 20:42:15.410113.410113 cuda_h.py:19] end move_flat_hidden2cpu cost 0.021944046020507812 seconds
DEBUG 01-14 20:42:15.415922.415922 mlpmodule.py:1533] pad cost 0.0039212703704833984 s
DEBUG 01-14 20:42:15.415697.415697 mlpmodule.py:1539] create cpu tensor cost 8.249282836914062e-05 s
DEBUG 01-14 20:42:15.417943.417943 mlpmodule.py:1544] move to cpu cost 0.0021390914916992188 s
INFO 01-14 20:42:15.419617.419617 client.py:127] Model loaded
DEBUG 01-14 20:42:15.419827.419827 cuda_h.py:19] end wait_experts cost 0.02685689926147461 seconds
DEBUG 01-14 20:42:15.419973.419973 cuda_h.py:10] start gpu_experts
DEBUG 01-14 20:42:15.419644.419644 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-14 20:42:15.427076.427076 mlpmodule.py:1558] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-14 20:42:15.427254.427254 mlpmodule.py:1559] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-14 20:42:15.427575.427575 mlpmodule.py:1564] group_w3 first element: -0.0107421875
WARNING 01-14 20:42:15.428298.428298 mlpmodule.py:1574] start einsum2
DEBUG 01-14 20:42:15.442545.442545 mlpmodule.py:1584] group einsum cost 0.025212764739990234 s
DEBUG 01-14 20:42:15.443774.443774 mlpmodule.py:1593] cpy2cputensor cost 0.0007052421569824219 s
DEBUG 01-14 20:42:15.443742.443742 cuda_h.py:10] start move_outputs
DEBUG 01-14 20:42:15.445377.445377 cuda_h.py:19] end move_outputs cost 0.002111196517944336 seconds
DEBUG 01-14 20:42:15.452041.452041 cuda_h.py:19] end wait_cetm_experts cost 0.0329437255859375 seconds
DEBUG 01-14 20:42:15.452173.452173 cuda_h.py:10] start gpu_group_einsum_mp_multi_list
DEBUG 01-14 20:42:15.453996.453996 cuda_h.py:10] start gpu_group_tensor
DEBUG 01-14 20:42:15.468107.468107 cuda_h.py:19] end gpu_group_tensor cost 0.015700578689575195 seconds
DEBUG 01-14 20:42:15.469598.469598 cuda_h.py:10] start gpu_group_einsum
DEBUG 01-14 20:42:15.470138.470138 mlpmodule.py:1367]  experts func einsum cost 0.09418368339538574 s
DEBUG 01-14 20:42:15.471520.471520 cuda_h.py:19] end gpu_group_einsum cost 0.002156496047973633 seconds
DEBUG 01-14 20:42:15.471532.471532 cuda_h.py:10] start gpu_final_hidden_states_scatter
DEBUG 01-14 20:42:15.471481.471481 cuda_h.py:10] start all_expert_outputs_slices
DEBUG 01-14 20:42:15.471842.471842 cuda_h.py:19] end all_expert_outputs_slices cost 0.00026297569274902344 seconds
DEBUG 01-14 20:42:15.471896.471896 cuda_h.py:10] start concat_expert_out
DEBUG 01-14 20:42:15.471238.471238 cuda_h.py:19] end concat_expert_out cost 7.367134094238281e-05 seconds
DEBUG 01-14 20:42:15.471009.471009 cuda_h.py:10] start index_scatter
DEBUG 01-14 20:42:15.472033.472033 cuda_h.py:19] end index_scatter cost 8.130073547363281e-05 seconds
DEBUG 01-14 20:42:15.472239.472239 cuda_h.py:19] end gpu_final_hidden_states_scatter cost 0.000713348388671875 seconds
DEBUG 01-14 20:42:15.472487.472487 cuda_h.py:19] end gpu_experts cost 0.052490234375 seconds
DEBUG 01-14 20:42:15.472720.472720 cuda_h.py:10] start all_expert_weight_slices
DEBUG 01-14 20:42:15.473190.473190 cuda_h.py:19] end all_expert_weight_slices cost 0.0009417533874511719 seconds
DEBUG 01-14 20:42:15.473357.473357 cuda_h.py:10] start cpuoutputsdeal
DEBUG 01-14 20:42:15.473749.473749 cuda_h.py:10] start index_scatter
DEBUG 01-14 20:42:15.473203.473203 cuda_h.py:19] end index_scatter cost 6.079673767089844e-05 seconds
DEBUG 01-14 20:42:15.473033.473033 cuda_h.py:19] end cpuoutputsdeal cost 0.0005700588226318359 seconds
DEBUG 01-14 20:42:15.473533.473533 cuda_h.py:19] end layer_moe_generate_mp_l_2 cost 0.20733904838562012 seconds
DEBUG 01-14 20:42:15.474118.474118 cuda_h.py:19] end prefill_layer cost 0.2138047218322754 seconds
DEBUG 01-14 20:42:15.474908.474908 lmp.py:1551] -------------------------------- end prefill layer 1 --------------------------------
DEBUG 01-14 20:42:15.474949.474949 cuda_h.py:10] start prefill_layer
DEBUG 01-14 20:42:15.474420.474420 lmp.py:1494] -------------------------------- start prefill layer 2 --------------------------------
DEBUG 01-14 20:42:15.474415.474415 cuda_h.py:10] start start_load_qkvogn_s_weight_l_3
DEBUG 01-14 20:42:15.474840.474840 cuda_h.py:10] start start_load_qkvogn_s_weight_l_3
DEBUG 01-14 20:42:15.474597.474597 cuda_h.py:19] end start_load_qkvogn_s_weight_l_3 cost 3.457069396972656e-05 seconds
DEBUG 01-14 20:42:15.474837.474837 cuda_h.py:19] end start_load_qkvogn_s_weight_l_3 cost 7.033348083496094e-05 seconds
DEBUG 01-14 20:42:15.474016.474016 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-14 20:42:15.474105.474105 cuda_h.py:10] start sllm_worker_task
DEBUG 01-14 20:42:15.474552.474552 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-14 20:42:15.474752.474752 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-14 20:42:15.474253.474253 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-14 20:42:15.475208.475208 cuda_h.py:19] end allocate_cuda_memory cost 0.00021123886108398438 seconds
DEBUG 01-14 20:42:15.475681.475681 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-14 20:42:15.475821.475821 sllm_store_c.py:27] get device uuid map
DEBUG 01-14 20:42:15.475597.475597 sllm_store_c.py:29] call client load into gpu
DEBUG 01-14 20:42:15.475585.475585 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 5b71c7c6-c309-4d91-9f80-f53bcb4b8869
DEBUG 01-14 20:42:15.475462.475462 client.py:106] call stub.LoadModelAsync
DEBUG 01-14 20:42:15.475699.475699 cuda_h.py:10] start self_attn
INFO 01-14 20:42:15.477625.477625 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 5b71c7c6-c309-4d91-9f80-f53bcb4b8869
DEBUG 01-14 20:42:15.477197.477197 cuda_h.py:19] end load_into_gpu_async cost 0.0021352767944335938 seconds
DEBUG 01-14 20:42:15.477768.477768 cuda_h.py:10] start restore_tensors2
DEBUG 01-14 20:42:15.477063.477063 cuda_h.py:19] end restore_tensors2 cost 7.557868957519531e-05 seconds
DEBUG 01-14 20:42:15.477356.477356 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.002694368362426758 seconds
INFO 01-14 20:42:15.477298.477298 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 5b71c7c6-c309-4d91-9f80-f53bcb4b8869
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-14 20:42:15.478213.478213 cuda_h.py:19] end self_attn cost 0.003013134002685547 seconds
DEBUG 01-14 20:42:15.479965.479965 cuda_h.py:19] end iln_self_attn_paln cost 0.004560232162475586 seconds
DEBUG 01-14 20:42:15.479007.479007 cuda_h.py:10] start layer_moe_generate_mp_l_3
DEBUG 01-14 20:42:15.479962.479962 cuda_h.py:10] start gate
DEBUG 01-14 20:42:15.479541.479541 cuda_h.py:19] end gate cost 0.0006368160247802734 seconds
DEBUG 01-14 20:42:15.480900.480900 cuda_h.py:10] start experts_map_get
DEBUG 01-14 20:42:15.480976.480976 lmp.py:1615] 
DEBUG 01-14 20:42:15.480976.480976 lmp.py:1615] Expert Token Distribution & Device Allocation:
DEBUG 01-14 20:42:15.480924.480924 lmp.py:1616]   Total experts: 64
DEBUG 01-14 20:42:15.480482.480482 lmp.py:1617]   CPU experts: 32 (50%)
DEBUG 01-14 20:42:15.480874.480874 lmp.py:1618]   GPU experts: 32 (50%)
DEBUG 01-14 20:42:15.480954.480954 lmp.py:1619] 
DEBUG 01-14 20:42:15.480954.480954 lmp.py:1619]   Expert ID | Tokens | Device
DEBUG 01-14 20:42:15.480842.480842 lmp.py:1620]   -----------------------------------
DEBUG 01-14 20:42:15.480691.480691 lmp.py:1625]   Expert 58 |     57 | CPU
DEBUG 01-14 20:42:15.480056.480056 lmp.py:1625]   Expert 27 |     81 | CPU
DEBUG 01-14 20:42:15.480798.480798 lmp.py:1625]   Expert  3 |     85 | CPU
DEBUG 01-14 20:42:15.480203.480203 lmp.py:1625]   Expert 24 |     86 | CPU
DEBUG 01-14 20:42:15.480084.480084 lmp.py:1625]   Expert 17 |     87 | CPU
DEBUG 01-14 20:42:15.480681.480681 lmp.py:1625]   Expert  0 |     88 | CPU
DEBUG 01-14 20:42:15.480277.480277 lmp.py:1625]   Expert 28 |    106 | CPU
DEBUG 01-14 20:42:15.480159.480159 lmp.py:1625]   Expert 34 |    108 | CPU
DEBUG 01-14 20:42:15.480756.480756 lmp.py:1625]   Expert 51 |    112 | CPU
DEBUG 01-14 20:42:15.480160.480160 lmp.py:1625]   Expert 32 |    117 | CPU
DEBUG 01-14 20:42:15.480141.480141 lmp.py:1625]   Expert 23 |    122 | CPU
DEBUG 01-14 20:42:15.480069.480069 lmp.py:1625]   Expert 15 |    128 | CPU
DEBUG 01-14 20:42:15.480712.480712 lmp.py:1625]   Expert  7 |    133 | CPU
DEBUG 01-14 20:42:15.480878.480878 lmp.py:1625]   Expert 26 |    135 | CPU
DEBUG 01-14 20:42:15.480044.480044 lmp.py:1625]   Expert  9 |    139 | CPU
DEBUG 01-14 20:42:15.480548.480548 lmp.py:1625]   Expert 30 |    140 | CPU
DEBUG 01-14 20:42:15.480668.480668 lmp.py:1625]   Expert 57 |    142 | CPU
DEBUG 01-14 20:42:15.480311.480311 lmp.py:1625]   Expert 62 |    145 | CPU
DEBUG 01-14 20:42:15.480192.480192 lmp.py:1625]   Expert 45 |    146 | CPU
DEBUG 01-14 20:42:15.480835.480835 lmp.py:1625]   Expert  1 |    150 | CPU
DEBUG 01-14 20:42:15.480955.480955 lmp.py:1625]   Expert  6 |    153 | CPU
DEBUG 01-14 20:42:15.480121.480121 lmp.py:1625]   Expert 48 |    156 | CPU
DEBUG 01-14 20:42:15.480387.480387 lmp.py:1625]   Expert  8 |    162 | CPU
DEBUG 01-14 20:42:15.480314.480314 lmp.py:1625]   Expert 54 |    163 | CPU
DEBUG 01-14 20:42:15.480480.480480 lmp.py:1625]   Expert 25 |    166 | CPU
DEBUG 01-14 20:42:15.480408.480408 lmp.py:1625]   Expert 49 |    168 | CPU
DEBUG 01-14 20:42:15.480097.480097 lmp.py:1625]   Expert 29 |    172 | CPU
DEBUG 01-14 20:42:15.480409.480409 lmp.py:1625]   Expert 36 |    173 | CPU
DEBUG 01-14 20:42:15.481529.481529 lmp.py:1625]   Expert 35 |    174 | CPU
DEBUG 01-14 20:42:15.481887.481887 lmp.py:1625]   Expert 12 |    176 | CPU
DEBUG 01-14 20:42:15.481769.481769 lmp.py:1625]   Expert 37 |    186 | CPU
DEBUG 01-14 20:42:15.481650.481650 lmp.py:1625]   Expert 13 |    187 | CPU
DEBUG 01-14 20:42:15.481439.481439 lmp.py:1625]   Expert 53 |    187 | GPU
DEBUG 01-14 20:42:15.481373.481373 lmp.py:1625]   Expert 33 |    190 | GPU
DEBUG 01-14 20:42:15.481493.481493 lmp.py:1625]   Expert 60 |    190 | GPU
DEBUG 01-14 20:42:15.481375.481375 lmp.py:1625]   Expert 16 |    195 | GPU
DEBUG 01-14 20:42:15.481494.481494 lmp.py:1625]   Expert 40 |    200 | GPU
DEBUG 01-14 20:42:15.481376.481376 lmp.py:1625]   Expert 21 |    201 | GPU
DEBUG 01-14 20:42:15.481496.481496 lmp.py:1625]   Expert 38 |    202 | GPU
DEBUG 01-14 20:42:15.481000.481000 lmp.py:1625]   Expert 19 |    208 | GPU
DEBUG 01-14 20:42:15.481788.481788 lmp.py:1625]   Expert  5 |    209 | GPU
DEBUG 01-14 20:42:15.481623.481623 lmp.py:1625]   Expert 41 |    213 | GPU
DEBUG 01-14 20:42:15.481982.481982 lmp.py:1625]   Expert 43 |    213 | GPU
DEBUG 01-14 20:42:15.481817.481817 lmp.py:1625]   Expert 10 |    215 | GPU
DEBUG 01-14 20:42:15.481175.481175 lmp.py:1625]   Expert 52 |    217 | GPU
DEBUG 01-14 20:42:15.481917.481917 lmp.py:1625]   Expert 50 |    219 | GPU
DEBUG 01-14 20:42:15.481276.481276 lmp.py:1625]   Expert 44 |    220 | GPU
DEBUG 01-14 20:42:15.481157.481157 lmp.py:1625]   Expert  4 |    221 | GPU
DEBUG 01-14 20:42:15.481277.481277 lmp.py:1625]   Expert 56 |    228 | GPU
DEBUG 01-14 20:42:15.481397.481397 lmp.py:1625]   Expert 59 |    231 | GPU
DEBUG 01-14 20:42:15.481662.481662 lmp.py:1625]   Expert 55 |    234 | GPU
DEBUG 01-14 20:42:15.481782.481782 lmp.py:1625]   Expert 31 |    245 | GPU
DEBUG 01-14 20:42:15.481902.481902 lmp.py:1625]   Expert 39 |    246 | GPU
DEBUG 01-14 20:42:15.481545.481545 lmp.py:1625]   Expert 22 |    255 | GPU
DEBUG 01-14 20:42:15.481426.481426 lmp.py:1625]   Expert 20 |    260 | GPU
DEBUG 01-14 20:42:15.481546.481546 lmp.py:1625]   Expert  2 |    267 | GPU
DEBUG 01-14 20:42:15.481381.481381 lmp.py:1625]   Expert 63 |    279 | GPU
DEBUG 01-14 20:42:15.481693.481693 lmp.py:1625]   Expert 47 |    284 | GPU
DEBUG 01-14 20:42:15.481290.481290 lmp.py:1625]   Expert 18 |    304 | GPU
DEBUG 01-14 20:42:15.481893.481893 lmp.py:1625]   Expert 14 |    310 | GPU
DEBUG 01-14 20:42:15.481298.481298 lmp.py:1625]   Expert 42 |    320 | GPU
DEBUG 01-14 20:42:15.481325.481325 lmp.py:1625]   Expert 46 |    373 | GPU
DEBUG 01-14 20:42:15.481014.481014 lmp.py:1625]   Expert 11 |    374 | GPU
DEBUG 01-14 20:42:15.481180.481180 lmp.py:1625]   Expert 61 |    435 | GPU
DEBUG 01-14 20:42:15.481538.481538 lmp.py:1626] 
DEBUG 01-14 20:42:15.481538.481538 lmp.py:1626]   CPU total tokens: 4343 (35.3%)
DEBUG 01-14 20:42:15.481135.481135 lmp.py:1627]   GPU total tokens: 7945 (64.7%)
DEBUG 01-14 20:42:15.481646.481646 cuda_h.py:19] end experts_map_get cost 0.001674652099609375 seconds
DEBUG 01-14 20:42:15.481595.481595 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-14 20:42:15.481015.481015 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-14 20:42:15.481430.481430 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-14 20:42:15.482834.482834 cuda_h.py:19] end allocate_cuda_memory cost 0.0005767345428466797 seconds
DEBUG 01-14 20:42:15.482061.482061 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-14 20:42:15.482440.482440 sllm_store_c.py:27] get device uuid map
DEBUG 01-14 20:42:15.482157.482157 sllm_store_c.py:29] call client load into gpu
DEBUG 01-14 20:42:15.482667.482667 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 4853b818-a4c2-42d7-b043-c4a658a9d085
DEBUG 01-14 20:42:15.482958.482958 client.py:106] call stub.LoadModelAsync
INFO 01-14 20:42:15.488506.488506 client.py:127] Model loaded
DEBUG 01-14 20:42:15.488615.488615 cuda_h.py:10] start restore2model
DEBUG 01-14 20:42:15.488702.488702 cuda_h.py:19] end restore2model cost 0.0005705356597900391 seconds
DEBUG 01-14 20:42:15.489274.489274 cuda_h.py:19] end sllm_worker_task cost 0.014188289642333984 seconds
INFO 01-14 20:42:15.490935.490935 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 4853b818-a4c2-42d7-b043-c4a658a9d085
DEBUG 01-14 20:42:15.490016.490016 cuda_h.py:19] end load_into_gpu_async cost 0.008112430572509766 seconds
DEBUG 01-14 20:42:15.490150.490150 cuda_h.py:10] start restore_tensors2
DEBUG 01-14 20:42:15.491326.491326 cuda_h.py:19] end restore_tensors2 cost 0.00027680397033691406 seconds
DEBUG 01-14 20:42:15.491201.491201 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.009311676025390625 seconds
DEBUG 01-14 20:42:15.491679.491679 cuda_h.py:10] start restore2model
DEBUG 01-14 20:42:15.493754.493754 cuda_h.py:19] end restore2model cost 0.002586841583251953 seconds
DEBUG 01-14 20:42:15.493266.493266 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.012085676193237305 seconds
DEBUG 01-14 20:42:15.493446.493446 cuda_h.py:10] start gpu_sexperts
DEBUG 01-14 20:42:15.494926.494926 cuda_h.py:19] end gpu_sexperts cost 0.00028705596923828125 seconds
DEBUG 01-14 20:42:15.494186.494186 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-14 20:42:15.494750.494750 lmp.py:1683] 
DEBUG 01-14 20:42:15.494750.494750 lmp.py:1683]   Computing 32 experts on CPU...
DEBUG 01-14 20:42:15.494686.494686 cuda_h.py:19] end cpu_experts_submit cost 5.53131103515625e-05 seconds
DEBUG 01-14 20:42:15.494687.494687 cuda_h.py:10] start experts_func_mgpu_group_pad
DEBUG 01-14 20:42:15.498945.498945 mlpmodule.py:1460] group tensors cost 0.0038018226623535156 s
DEBUG 01-14 20:42:15.499472.499472 cuda_h.py:10] start move_flat_hidden2cpu
DEBUG 01-14 20:42:15.506033.506033 cuda_h.py:19] end move_flat_hidden2cpu cost 0.006949663162231445 seconds
DEBUG 01-14 20:42:15.508980.508980 cuda_h.py:19] end experts_func_mgpu_group_pad cost 0.01365971565246582 seconds
DEBUG 01-14 20:42:15.509633.509633 mlpmodule.py:1533] pad cost 0.0027451515197753906 s
DEBUG 01-14 20:42:15.509891.509891 mlpmodule.py:1539] create cpu tensor cost 7.43865966796875e-05 s
DEBUG 01-14 20:42:15.509981.509981 cuda_h.py:10] start gpu_group_list
DEBUG 01-14 20:42:15.510986.510986 cuda_h.py:19] end gpu_group_list cost 0.0004258155822753906 seconds
DEBUG 01-14 20:42:15.510098.510098 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-14 20:42:15.510213.510213 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.2172927856445312e-05 seconds
DEBUG 01-14 20:42:15.510446.510446 cuda_h.py:10] start wait_experts
INFO 01-14 20:42:15.510156.510156 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 4853b818-a4c2-42d7-b043-c4a658a9d085
DEBUG 01-14 20:42:15.511795.511795 mlpmodule.py:1544] move to cpu cost 0.0022125244140625 s
DEBUG 01-14 20:42:15.520001.520001 mlpmodule.py:1558] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-14 20:42:15.521822.521822 mlpmodule.py:1559] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-14 20:42:15.521110.521110 mlpmodule.py:1564] group_w3 first element: -0.0380859375
WARNING 01-14 20:42:15.521148.521148 mlpmodule.py:1574] start einsum2
DEBUG 01-14 20:42:15.536094.536094 mlpmodule.py:1584] group einsum cost 0.025218725204467773 s
DEBUG 01-14 20:42:15.537901.537901 mlpmodule.py:1593] cpy2cputensor cost 0.0007560253143310547 s
DEBUG 01-14 20:42:15.537480.537480 cuda_h.py:10] start move_outputs
DEBUG 01-14 20:42:15.540666.540666 cuda_h.py:19] end move_outputs cost 0.0027360916137695312 seconds
INFO 01-14 20:42:15.550267.550267 client.py:127] Model loaded
DEBUG 01-14 20:42:15.550667.550667 cuda_h.py:19] end wait_experts cost 0.03997993469238281 seconds
DEBUG 01-14 20:42:15.550615.550615 cuda_h.py:10] start gpu_experts
DEBUG 01-14 20:42:15.550709.550709 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-14 20:42:15.550541.550541 cuda_h.py:19] end wait_cetm_experts cost 8.511543273925781e-05 seconds
DEBUG 01-14 20:42:15.550390.550390 cuda_h.py:10] start gpu_group_einsum_mp_multi_list
DEBUG 01-14 20:42:15.550339.550339 cuda_h.py:10] start gpu_group_tensor
DEBUG 01-14 20:42:15.550644.550644 cuda_h.py:19] end gpu_group_tensor cost 0.0001952648162841797 seconds
DEBUG 01-14 20:42:15.551310.551310 cuda_h.py:10] start gpu_group_einsum
DEBUG 01-14 20:42:15.557080.557080 cuda_h.py:19] end gpu_group_einsum cost 0.006947994232177734 seconds
DEBUG 01-14 20:42:15.558303.558303 cuda_h.py:10] start gpu_final_hidden_states_scatter
DEBUG 01-14 20:42:15.558418.558418 cuda_h.py:10] start all_expert_outputs_slices
DEBUG 01-14 20:42:15.558359.558359 cuda_h.py:19] end all_expert_outputs_slices cost 0.00020956993103027344 seconds
DEBUG 01-14 20:42:15.558347.558347 cuda_h.py:10] start concat_expert_out
DEBUG 01-14 20:42:15.558893.558893 cuda_h.py:19] end concat_expert_out cost 5.698204040527344e-05 seconds
DEBUG 01-14 20:42:15.558875.558875 cuda_h.py:10] start index_scatter
DEBUG 01-14 20:42:15.558819.558819 cuda_h.py:19] end index_scatter cost 5.984306335449219e-05 seconds
DEBUG 01-14 20:42:15.558906.558906 cuda_h.py:19] end gpu_final_hidden_states_scatter cost 0.0005462169647216797 seconds
DEBUG 01-14 20:42:15.558809.558809 cuda_h.py:19] end gpu_experts cost 0.008330106735229492 seconds
DEBUG 01-14 20:42:15.558935.558935 cuda_h.py:10] start all_expert_weight_slices
DEBUG 01-14 20:42:15.559385.559385 cuda_h.py:19] end all_expert_weight_slices cost 0.0007593631744384766 seconds
DEBUG 01-14 20:42:15.559731.559731 cuda_h.py:10] start cpuoutputsdeal
DEBUG 01-14 20:42:15.559855.559855 cuda_h.py:10] start index_scatter
DEBUG 01-14 20:42:15.560037.560037 cuda_h.py:19] end index_scatter cost 4.744529724121094e-05 seconds
DEBUG 01-14 20:42:15.560277.560277 cuda_h.py:19] end cpuoutputsdeal cost 0.00044798851013183594 seconds
DEBUG 01-14 20:42:15.560134.560134 cuda_h.py:19] end layer_moe_generate_mp_l_3 cost 0.08088946342468262 seconds
DEBUG 01-14 20:42:15.560447.560447 cuda_h.py:19] end prefill_layer cost 0.08604216575622559 seconds
DEBUG 01-14 20:42:15.560561.560561 lmp.py:1551] -------------------------------- end prefill layer 2 --------------------------------
DEBUG 01-14 20:42:15.560211.560211 cuda_h.py:10] start prefill_layer
DEBUG 01-14 20:42:15.560861.560861 lmp.py:1494] -------------------------------- start prefill layer 3 --------------------------------
DEBUG 01-14 20:42:15.560464.560464 cuda_h.py:10] start start_load_qkvogn_s_weight_l_4
DEBUG 01-14 20:42:15.560498.560498 cuda_h.py:10] start start_load_qkvogn_s_weight_l_4
DEBUG 01-14 20:42:15.560865.560865 cuda_h.py:19] end start_load_qkvogn_s_weight_l_4 cost 2.9325485229492188e-05 seconds
DEBUG 01-14 20:42:15.560356.560356 cuda_h.py:19] end start_load_qkvogn_s_weight_l_4 cost 8.296966552734375e-05 seconds
DEBUG 01-14 20:42:15.560430.560430 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-14 20:42:15.560631.560631 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-14 20:42:15.560302.560302 cuda_h.py:10] start sllm_worker_task
DEBUG 01-14 20:42:15.560974.560974 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-14 20:42:15.561492.561492 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-14 20:42:15.562164.562164 cuda_h.py:19] end allocate_cuda_memory cost 0.0016124248504638672 seconds
DEBUG 01-14 20:42:15.562795.562795 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-14 20:42:15.562750.562750 sllm_store_c.py:27] get device uuid map
DEBUG 01-14 20:42:15.562957.562957 sllm_store_c.py:29] call client load into gpu
DEBUG 01-14 20:42:15.562899.562899 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 4f587d08-75ef-4705-9dc1-2c8b0502e5ce
DEBUG 01-14 20:42:15.562391.562391 client.py:106] call stub.LoadModelAsync
DEBUG 01-14 20:42:15.563341.563341 cuda_h.py:10] start self_attn
INFO 01-14 20:42:15.563019.563019 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 4f587d08-75ef-4705-9dc1-2c8b0502e5ce
DEBUG 01-14 20:42:15.563001.563001 cuda_h.py:19] end load_into_gpu_async cost 0.001168966293334961 seconds
DEBUG 01-14 20:42:15.563512.563512 cuda_h.py:10] start restore_tensors2
DEBUG 01-14 20:42:15.564495.564495 cuda_h.py:19] end restore_tensors2 cost 6.628036499023438e-05 seconds
DEBUG 01-14 20:42:15.564821.564821 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0031061172485351562 seconds
INFO 01-14 20:42:15.564842.564842 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 4f587d08-75ef-4705-9dc1-2c8b0502e5ce
DEBUG 01-14 20:42:15.564486.564486 mlpmodule.py:1367]  experts func einsum cost 0.07018733024597168 s
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-14 20:42:15.566095.566095 cuda_h.py:19] end self_attn cost 0.0030548572540283203 seconds
DEBUG 01-14 20:42:15.566773.566773 cuda_h.py:19] end iln_self_attn_paln cost 0.005876064300537109 seconds
DEBUG 01-14 20:42:15.566285.566285 cuda_h.py:10] start layer_moe_generate_mp_l_4
DEBUG 01-14 20:42:15.566286.566286 cuda_h.py:10] start gate
DEBUG 01-14 20:42:15.567951.567951 cuda_h.py:19] end gate cost 0.0006306171417236328 seconds
DEBUG 01-14 20:42:15.567065.567065 cuda_h.py:10] start experts_map_get
DEBUG 01-14 20:42:15.567718.567718 lmp.py:1615] 
DEBUG 01-14 20:42:15.567718.567718 lmp.py:1615] Expert Token Distribution & Device Allocation:
DEBUG 01-14 20:42:15.567017.567017 lmp.py:1616]   Total experts: 64
DEBUG 01-14 20:42:15.567336.567336 lmp.py:1617]   CPU experts: 32 (50%)
DEBUG 01-14 20:42:15.567125.567125 lmp.py:1618]   GPU experts: 32 (50%)
DEBUG 01-14 20:42:15.567768.567768 lmp.py:1619] 
DEBUG 01-14 20:42:15.567768.567768 lmp.py:1619]   Expert ID | Tokens | Device
DEBUG 01-14 20:42:15.567411.567411 lmp.py:1620]   -----------------------------------
DEBUG 01-14 20:42:15.567915.567915 lmp.py:1625]   Expert  1 |     54 | CPU
DEBUG 01-14 20:42:15.567558.567558 lmp.py:1625]   Expert 27 |     59 | CPU
DEBUG 01-14 20:42:15.567962.567962 lmp.py:1625]   Expert 48 |     79 | CPU
DEBUG 01-14 20:42:15.567367.567367 lmp.py:1625]   Expert  7 |     82 | CPU
DEBUG 01-14 20:42:15.567533.567533 lmp.py:1625]   Expert 30 |    101 | CPU
DEBUG 01-14 20:42:15.567699.567699 lmp.py:1625]   Expert 15 |    102 | CPU
DEBUG 01-14 20:42:15.567865.567865 lmp.py:1625]   Expert 39 |    114 | CPU
DEBUG 01-14 20:42:15.568555.568555 lmp.py:1625]   Expert 32 |    115 | CPU
DEBUG 01-14 20:42:15.568721.568721 lmp.py:1625]   Expert 61 |    116 | CPU
DEBUG 01-14 20:42:15.568410.568410 lmp.py:1625]   Expert 18 |    118 | CPU
DEBUG 01-14 20:42:15.568099.568099 lmp.py:1625]   Expert 45 |    130 | CPU
DEBUG 01-14 20:42:15.568027.568027 lmp.py:1625]   Expert 34 |    138 | CPU
DEBUG 01-14 20:42:15.568054.568054 lmp.py:1625]   Expert 59 |    139 | CPU
DEBUG 01-14 20:42:15.568982.568982 lmp.py:1625]   Expert 36 |    144 | CPU
DEBUG 01-14 20:42:15.568671.568671 lmp.py:1625]   Expert 11 |    145 | CPU
DEBUG 01-14 20:42:15.568122.568122 lmp.py:1625]   Expert 26 |    146 | CPU
DEBUG 01-14 20:42:15.568050.568050 lmp.py:1625]   Expert  9 |    147 | CPU
DEBUG 01-14 20:42:15.568739.568739 lmp.py:1625]   Expert 49 |    152 | CPU
DEBUG 01-14 20:42:15.568428.568428 lmp.py:1625]   Expert  5 |    153 | CPU
DEBUG 01-14 20:42:15.568879.568879 lmp.py:1625]   Expert 51 |    153 | CPU
DEBUG 01-14 20:42:15.568807.568807 lmp.py:1625]   Expert  6 |    154 | CPU
DEBUG 01-14 20:42:15.568019.568019 lmp.py:1625]   Expert 23 |    155 | CPU
DEBUG 01-14 20:42:15.568709.568709 lmp.py:1625]   Expert  2 |    165 | CPU
DEBUG 01-14 20:42:15.568160.568160 lmp.py:1625]   Expert 40 |    167 | CPU
DEBUG 01-14 20:42:15.568849.568849 lmp.py:1625]   Expert 50 |    167 | CPU
DEBUG 01-14 20:42:15.568253.568253 lmp.py:1625]   Expert 16 |    168 | CPU
DEBUG 01-14 20:42:15.568943.568943 lmp.py:1625]   Expert 56 |    170 | CPU
DEBUG 01-14 20:42:15.568632.568632 lmp.py:1625]   Expert  4 |    171 | CPU
DEBUG 01-14 20:42:15.568321.568321 lmp.py:1625]   Expert 52 |    174 | CPU
DEBUG 01-14 20:42:15.568011.568011 lmp.py:1625]   Expert 44 |    185 | CPU
DEBUG 01-14 20:42:15.568336.568336 lmp.py:1625]   Expert 37 |    186 | CPU
DEBUG 01-14 20:42:15.568430.568430 lmp.py:1625]   Expert 35 |    188 | CPU
DEBUG 01-14 20:42:15.568596.568596 lmp.py:1625]   Expert 42 |    188 | GPU
DEBUG 01-14 20:42:15.568762.568762 lmp.py:1625]   Expert 17 |    189 | GPU
DEBUG 01-14 20:42:15.568452.568452 lmp.py:1625]   Expert 38 |    193 | GPU
DEBUG 01-14 20:42:15.568379.568379 lmp.py:1625]   Expert 13 |    199 | GPU
DEBUG 01-14 20:42:15.568545.568545 lmp.py:1625]   Expert 21 |    206 | GPU
DEBUG 01-14 20:42:15.568950.568950 lmp.py:1625]   Expert 10 |    208 | GPU
DEBUG 01-14 20:42:15.568116.568116 lmp.py:1625]   Expert  3 |    209 | GPU
DEBUG 01-14 20:42:15.568805.568805 lmp.py:1625]   Expert 28 |    209 | GPU
DEBUG 01-14 20:42:15.568972.568972 lmp.py:1625]   Expert 53 |    211 | GPU
DEBUG 01-14 20:42:15.568138.568138 lmp.py:1625]   Expert 20 |    215 | GPU
DEBUG 01-14 20:42:15.568065.568065 lmp.py:1625]   Expert 58 |    215 | GPU
DEBUG 01-14 20:42:15.568232.568232 lmp.py:1625]   Expert 47 |    216 | GPU
DEBUG 01-14 20:42:15.568921.568921 lmp.py:1625]   Expert 19 |    219 | GPU
DEBUG 01-14 20:42:15.568849.568849 lmp.py:1625]   Expert 33 |    223 | GPU
DEBUG 01-14 20:42:15.568776.568776 lmp.py:1625]   Expert  8 |    224 | GPU
DEBUG 01-14 20:42:15.568466.568466 lmp.py:1625]   Expert 55 |    226 | GPU
DEBUG 01-14 20:42:15.568155.568155 lmp.py:1625]   Expert 60 |    229 | GPU
DEBUG 01-14 20:42:15.568844.568844 lmp.py:1625]   Expert 31 |    231 | GPU
DEBUG 01-14 20:42:15.568010.568010 lmp.py:1625]   Expert 57 |    234 | GPU
DEBUG 01-14 20:42:15.568415.568415 lmp.py:1625]   Expert 46 |    236 | GPU
DEBUG 01-14 20:42:15.568343.568343 lmp.py:1625]   Expert 24 |    243 | GPU
DEBUG 01-14 20:42:15.568509.568509 lmp.py:1625]   Expert 62 |    246 | GPU
DEBUG 01-14 20:42:15.568436.568436 lmp.py:1625]   Expert 63 |    254 | GPU
DEBUG 01-14 20:42:15.568795.568795 lmp.py:1625]   Expert 14 |    257 | GPU
DEBUG 01-14 20:42:15.568676.568676 lmp.py:1625]   Expert 12 |    258 | GPU
DEBUG 01-14 20:42:15.568319.568319 lmp.py:1625]   Expert 22 |    273 | GPU
DEBUG 01-14 20:42:15.568200.568200 lmp.py:1625]   Expert 43 |    289 | GPU
DEBUG 01-14 20:42:15.568320.568320 lmp.py:1625]   Expert 29 |    297 | GPU
DEBUG 01-14 20:42:15.568202.568202 lmp.py:1625]   Expert  0 |    309 | GPU
DEBUG 01-14 20:42:15.568845.568845 lmp.py:1625]   Expert 54 |    341 | GPU
DEBUG 01-14 20:42:15.568726.568726 lmp.py:1625]   Expert 41 |    388 | GPU
DEBUG 01-14 20:42:15.568607.568607 lmp.py:1625]   Expert 25 |    416 | GPU
DEBUG 01-14 20:42:15.569966.569966 lmp.py:1626] 
DEBUG 01-14 20:42:15.569966.569966 lmp.py:1626]   CPU total tokens: 4437 (36.1%)
DEBUG 01-14 20:42:15.569708.569708 lmp.py:1627]   GPU total tokens: 7851 (63.9%)
DEBUG 01-14 20:42:15.569027.569027 cuda_h.py:19] end experts_map_get cost 0.0015931129455566406 seconds
DEBUG 01-14 20:42:15.569215.569215 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-14 20:42:15.569912.569912 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-14 20:42:15.569850.569850 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-14 20:42:15.570154.570154 cuda_h.py:19] end allocate_cuda_memory cost 0.001138925552368164 seconds
DEBUG 01-14 20:42:15.570958.570958 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-14 20:42:15.570190.570190 sllm_store_c.py:27] get device uuid map
DEBUG 01-14 20:42:15.570715.570715 sllm_store_c.py:29] call client load into gpu
DEBUG 01-14 20:42:15.570034.570034 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 93e3c6be-b67d-4c44-8f09-2a5a27e77414
DEBUG 01-14 20:42:15.570264.570264 client.py:106] call stub.LoadModelAsync
INFO 01-14 20:42:15.572457.572457 client.py:127] Model loaded
DEBUG 01-14 20:42:15.572666.572666 cuda_h.py:10] start restore2model
DEBUG 01-14 20:42:15.572615.572615 cuda_h.py:19] end restore2model cost 0.000537872314453125 seconds
INFO 01-14 20:42:15.573207.573207 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 93e3c6be-b67d-4c44-8f09-2a5a27e77414
DEBUG 01-14 20:42:15.573355.573355 cuda_h.py:19] end sllm_worker_task cost 0.012186288833618164 seconds
DEBUG 01-14 20:42:15.573582.573582 cuda_h.py:19] end load_into_gpu_async cost 0.0026009082794189453 seconds
DEBUG 01-14 20:42:15.573201.573201 cuda_h.py:10] start restore_tensors2
DEBUG 01-14 20:42:15.573277.573277 cuda_h.py:19] end restore_tensors2 cost 0.0002727508544921875 seconds
DEBUG 01-14 20:42:15.573146.573146 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.004397392272949219 seconds
DEBUG 01-14 20:42:15.573432.573432 cuda_h.py:10] start restore2model
DEBUG 01-14 20:42:15.576230.576230 cuda_h.py:19] end restore2model cost 0.002627849578857422 seconds
DEBUG 01-14 20:42:15.576973.576973 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.007200956344604492 seconds
DEBUG 01-14 20:42:15.576769.576769 cuda_h.py:10] start gpu_sexperts
DEBUG 01-14 20:42:15.576939.576939 cuda_h.py:19] end gpu_sexperts cost 0.0002951622009277344 seconds
DEBUG 01-14 20:42:15.576192.576192 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-14 20:42:15.576326.576326 lmp.py:1683] 
DEBUG 01-14 20:42:15.576326.576326 lmp.py:1683]   Computing 32 experts on CPU...
DEBUG 01-14 20:42:15.576493.576493 cuda_h.py:19] end cpu_experts_submit cost 5.269050598144531e-05 seconds
DEBUG 01-14 20:42:15.576242.576242 cuda_h.py:10] start experts_func_mgpu_group_pad
DEBUG 01-14 20:42:15.582154.582154 mlpmodule.py:1460] group tensors cost 0.005212545394897461 s
DEBUG 01-14 20:42:15.583945.583945 cuda_h.py:10] start move_flat_hidden2cpu
DEBUG 01-14 20:42:15.585090.585090 cuda_h.py:19] end experts_func_mgpu_group_pad cost 0.00882267951965332 seconds
DEBUG 01-14 20:42:15.587943.587943 cuda_h.py:10] start gpu_group_list
DEBUG 01-14 20:42:15.587702.587702 cuda_h.py:19] end gpu_group_list cost 0.00042891502380371094 seconds
DEBUG 01-14 20:42:15.588139.588139 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-14 20:42:15.588201.588201 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 1.8596649169921875e-05 seconds
DEBUG 01-14 20:42:15.588719.588719 cuda_h.py:10] start wait_experts
INFO 01-14 20:42:15.588521.588521 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 93e3c6be-b67d-4c44-8f09-2a5a27e77414
DEBUG 01-14 20:42:15.591287.591287 cuda_h.py:19] end move_flat_hidden2cpu cost 0.008159875869750977 seconds
DEBUG 01-14 20:42:15.593410.593410 mlpmodule.py:1533] pad cost 0.0017895698547363281 s
DEBUG 01-14 20:42:15.593930.593930 mlpmodule.py:1539] create cpu tensor cost 3.743171691894531e-05 s
DEBUG 01-14 20:42:15.595508.595508 mlpmodule.py:1544] move to cpu cost 0.0022149085998535156 s
DEBUG 01-14 20:42:15.603102.603102 mlpmodule.py:1558] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-14 20:42:15.603578.603578 mlpmodule.py:1559] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-14 20:42:15.603966.603966 mlpmodule.py:1564] group_w3 first element: -0.054931640625
WARNING 01-14 20:42:15.603672.603672 mlpmodule.py:1574] start einsum2
DEBUG 01-14 20:42:15.618652.618652 mlpmodule.py:1584] group einsum cost 0.02340531349182129 s
DEBUG 01-14 20:42:15.619786.619786 mlpmodule.py:1593] cpy2cputensor cost 0.0007841587066650391 s
DEBUG 01-14 20:42:15.620983.620983 cuda_h.py:10] start move_outputs
DEBUG 01-14 20:42:15.623412.623412 cuda_h.py:19] end move_outputs cost 0.003072977066040039 seconds
INFO 01-14 20:42:15.628965.628965 client.py:127] Model loaded
DEBUG 01-14 20:42:15.628976.628976 cuda_h.py:19] end wait_experts cost 0.04007601737976074 seconds
DEBUG 01-14 20:42:15.628189.628189 cuda_h.py:10] start gpu_experts
DEBUG 01-14 20:42:15.628873.628873 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-14 20:42:15.628686.628686 cuda_h.py:19] end wait_cetm_experts cost 0.00010061264038085938 seconds
DEBUG 01-14 20:42:15.628450.628450 cuda_h.py:10] start gpu_group_einsum_mp_multi_list
DEBUG 01-14 20:42:15.628636.628636 cuda_h.py:10] start gpu_group_tensor
DEBUG 01-14 20:42:15.628077.628077 cuda_h.py:19] end gpu_group_tensor cost 0.00024819374084472656 seconds
DEBUG 01-14 20:42:15.629395.629395 cuda_h.py:10] start gpu_group_einsum
DEBUG 01-14 20:42:15.629309.629309 cuda_h.py:19] end gpu_group_einsum cost 0.0007445812225341797 seconds
DEBUG 01-14 20:42:15.630620.630620 cuda_h.py:10] start gpu_final_hidden_states_scatter
DEBUG 01-14 20:42:15.630974.630974 cuda_h.py:10] start all_expert_outputs_slices
DEBUG 01-14 20:42:15.630897.630897 cuda_h.py:19] end all_expert_outputs_slices cost 0.0003542900085449219 seconds
DEBUG 01-14 20:42:15.630721.630721 cuda_h.py:10] start concat_expert_out
DEBUG 01-14 20:42:15.638672.638672 cuda_h.py:19] end concat_expert_out cost 0.007769584655761719 seconds
DEBUG 01-14 20:42:15.638477.638477 cuda_h.py:10] start index_scatter
DEBUG 01-14 20:42:15.638779.638779 cuda_h.py:19] end index_scatter cost 6.937980651855469e-05 seconds
DEBUG 01-14 20:42:15.638264.638264 cuda_h.py:19] end gpu_final_hidden_states_scatter cost 0.008655309677124023 seconds
DEBUG 01-14 20:42:15.638995.638995 cuda_h.py:19] end gpu_experts cost 0.010558366775512695 seconds
DEBUG 01-14 20:42:15.638420.638420 cuda_h.py:10] start all_expert_weight_slices
DEBUG 01-14 20:42:15.639528.639528 cuda_h.py:19] end all_expert_weight_slices cost 0.0008192062377929688 seconds
DEBUG 01-14 20:42:15.639834.639834 cuda_h.py:10] start cpuoutputsdeal
DEBUG 01-14 20:42:15.640787.640787 cuda_h.py:10] start index_scatter
DEBUG 01-14 20:42:15.640692.640692 cuda_h.py:19] end index_scatter cost 5.054473876953125e-05 seconds
DEBUG 01-14 20:42:15.640507.640507 cuda_h.py:19] end cpuoutputsdeal cost 0.0005030632019042969 seconds
DEBUG 01-14 20:42:15.640000.640000 cuda_h.py:19] end layer_moe_generate_mp_l_4 cost 0.07373881340026855 seconds
DEBUG 01-14 20:42:15.640555.640555 cuda_h.py:19] end prefill_layer cost 0.0802452564239502 seconds
DEBUG 01-14 20:42:15.640954.640954 lmp.py:1551] -------------------------------- end prefill layer 3 --------------------------------
DEBUG 01-14 20:42:15.640941.640941 cuda_h.py:10] start prefill_layer
DEBUG 01-14 20:42:15.640406.640406 lmp.py:1494] -------------------------------- start prefill layer 4 --------------------------------
DEBUG 01-14 20:42:15.640916.640916 cuda_h.py:10] start start_load_qkvogn_s_weight_l_5
DEBUG 01-14 20:42:15.640335.640335 cuda_h.py:10] start start_load_qkvogn_s_weight_l_5
DEBUG 01-14 20:42:15.640078.640078 cuda_h.py:19] end start_load_qkvogn_s_weight_l_5 cost 3.0517578125e-05 seconds
DEBUG 01-14 20:42:15.641596.641596 cuda_h.py:19] end start_load_qkvogn_s_weight_l_5 cost 6.365776062011719e-05 seconds
DEBUG 01-14 20:42:15.641948.641948 cuda_h.py:10] start sllm_worker_task
DEBUG 01-14 20:42:15.641433.641433 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-14 20:42:15.641304.641304 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-14 20:42:15.641678.641678 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-14 20:42:15.645437.645437 cuda_h.py:19] end allocate_cuda_memory cost 0.004627704620361328 seconds
DEBUG 01-14 20:42:15.646983.646983 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-14 20:42:15.646315.646315 sllm_store_c.py:27] get device uuid map
DEBUG 01-14 20:42:15.646191.646191 sllm_store_c.py:29] call client load into gpu
DEBUG 01-14 20:42:15.646039.646039 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 44640c74-8dc2-441e-ba6e-a2bd0a6b6723
DEBUG 01-14 20:42:15.646122.646122 client.py:106] call stub.LoadModelAsync
DEBUG 01-14 20:42:15.646406.646406 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-14 20:42:15.646868.646868 cuda_h.py:10] start self_attn
INFO 01-14 20:42:15.647755.647755 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 44640c74-8dc2-441e-ba6e-a2bd0a6b6723
DEBUG 01-14 20:42:15.647697.647697 cuda_h.py:19] end load_into_gpu_async cost 0.00133514404296875 seconds
DEBUG 01-14 20:42:15.647784.647784 cuda_h.py:10] start restore_tensors2
DEBUG 01-14 20:42:15.647198.647198 cuda_h.py:19] end restore_tensors2 cost 6.67572021484375e-05 seconds
DEBUG 01-14 20:42:15.647669.647669 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.006299734115600586 seconds
INFO 01-14 20:42:15.647598.647598 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 44640c74-8dc2-441e-ba6e-a2bd0a6b6723
DEBUG 01-14 20:42:15.648916.648916 mlpmodule.py:1367]  experts func einsum cost 0.07109880447387695 s
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-14 20:42:15.650897.650897 cuda_h.py:19] end self_attn cost 0.0031909942626953125 seconds
DEBUG 01-14 20:42:15.650457.650457 cuda_h.py:19] end iln_self_attn_paln cost 0.009083271026611328 seconds
DEBUG 01-14 20:42:15.650499.650499 cuda_h.py:10] start layer_moe_generate_mp_l_5
DEBUG 01-14 20:42:15.650838.650838 cuda_h.py:10] start gate
DEBUG 01-14 20:42:15.651385.651385 cuda_h.py:19] end gate cost 0.0006814002990722656 seconds
DEBUG 01-14 20:42:15.651268.651268 cuda_h.py:10] start experts_map_get
DEBUG 01-14 20:42:15.651140.651140 lmp.py:1615] 
DEBUG 01-14 20:42:15.651140.651140 lmp.py:1615] Expert Token Distribution & Device Allocation:
DEBUG 01-14 20:42:15.651187.651187 lmp.py:1616]   Total experts: 64
DEBUG 01-14 20:42:15.651890.651890 lmp.py:1617]   CPU experts: 32 (50%)
DEBUG 01-14 20:42:15.651494.651494 lmp.py:1618]   GPU experts: 32 (50%)
DEBUG 01-14 20:42:15.651759.651759 lmp.py:1619] 
DEBUG 01-14 20:42:15.651759.651759 lmp.py:1619]   Expert ID | Tokens | Device
DEBUG 01-14 20:42:15.651263.651263 lmp.py:1620]   -----------------------------------
DEBUG 01-14 20:42:15.651483.651483 lmp.py:1625]   Expert 14 |     70 | CPU
DEBUG 01-14 20:42:15.651748.651748 lmp.py:1625]   Expert 13 |     74 | CPU
DEBUG 01-14 20:42:15.651491.651491 lmp.py:1625]   Expert 57 |     80 | CPU
DEBUG 01-14 20:42:15.651995.651995 lmp.py:1625]   Expert 11 |     83 | CPU
DEBUG 01-14 20:42:15.651306.651306 lmp.py:1625]   Expert 54 |     88 | CPU
DEBUG 01-14 20:42:15.651857.651857 lmp.py:1625]   Expert 26 |     89 | CPU
DEBUG 01-14 20:42:15.651930.651930 lmp.py:1625]   Expert 31 |     91 | CPU
DEBUG 01-14 20:42:15.651242.651242 lmp.py:1625]   Expert 45 |     93 | CPU
DEBUG 01-14 20:42:15.651793.651793 lmp.py:1625]   Expert 10 |     96 | CPU
DEBUG 01-14 20:42:15.651628.651628 lmp.py:1625]   Expert 58 |    107 | CPU
DEBUG 01-14 20:42:15.651416.651416 lmp.py:1625]   Expert 51 |    108 | CPU
DEBUG 01-14 20:42:15.651444.651444 lmp.py:1625]   Expert 30 |    109 | CPU
DEBUG 01-14 20:42:15.651517.651517 lmp.py:1625]   Expert 36 |    115 | CPU
DEBUG 01-14 20:42:15.651114.651114 lmp.py:1625]   Expert 32 |    126 | CPU
DEBUG 01-14 20:42:15.651949.651949 lmp.py:1625]   Expert 20 |    130 | CPU
DEBUG 01-14 20:42:15.651545.651545 lmp.py:1625]   Expert 63 |    139 | CPU
DEBUG 01-14 20:42:15.652619.652619 lmp.py:1625]   Expert  4 |    142 | CPU
DEBUG 01-14 20:42:15.652361.652361 lmp.py:1625]   Expert 61 |    144 | CPU
DEBUG 01-14 20:42:15.652865.652865 lmp.py:1625]   Expert 16 |    145 | CPU
DEBUG 01-14 20:42:15.652654.652654 lmp.py:1625]   Expert 34 |    148 | CPU
DEBUG 01-14 20:42:15.652681.652681 lmp.py:1625]   Expert 53 |    149 | CPU
DEBUG 01-14 20:42:15.652947.652947 lmp.py:1625]   Expert 42 |    151 | CPU
DEBUG 01-14 20:42:15.652974.652974 lmp.py:1625]   Expert  8 |    153 | CPU
DEBUG 01-14 20:42:15.652001.652001 lmp.py:1625]   Expert 47 |    153 | CPU
DEBUG 01-14 20:42:15.652505.652505 lmp.py:1625]   Expert 60 |    154 | CPU
DEBUG 01-14 20:42:15.652532.652532 lmp.py:1625]   Expert 28 |    158 | CPU
DEBUG 01-14 20:42:15.652321.652321 lmp.py:1625]   Expert 17 |    163 | CPU
DEBUG 01-14 20:42:15.652348.652348 lmp.py:1625]   Expert 27 |    171 | CPU
DEBUG 01-14 20:42:15.652614.652614 lmp.py:1625]   Expert 44 |    178 | CPU
DEBUG 01-14 20:42:15.652641.652641 lmp.py:1625]   Expert 56 |    178 | CPU
DEBUG 01-14 20:42:15.652191.652191 lmp.py:1625]   Expert 29 |    179 | CPU
DEBUG 01-14 20:42:15.652218.652218 lmp.py:1625]   Expert  0 |    181 | CPU
DEBUG 01-14 20:42:15.652769.652769 lmp.py:1625]   Expert  3 |    181 | GPU
DEBUG 01-14 20:42:15.652557.652557 lmp.py:1625]   Expert 41 |    182 | GPU
DEBUG 01-14 20:42:15.652869.652869 lmp.py:1625]   Expert 24 |    183 | GPU
DEBUG 01-14 20:42:15.652241.652241 lmp.py:1625]   Expert 48 |    185 | GPU
DEBUG 01-14 20:42:15.652222.652222 lmp.py:1625]   Expert  7 |    187 | GPU
DEBUG 01-14 20:42:15.652011.652011 lmp.py:1625]   Expert  9 |    187 | GPU
DEBUG 01-14 20:42:15.652038.652038 lmp.py:1625]   Expert  2 |    188 | GPU
DEBUG 01-14 20:42:15.652303.652303 lmp.py:1625]   Expert 15 |    191 | GPU
DEBUG 01-14 20:42:15.652854.652854 lmp.py:1625]   Expert 18 |    196 | GPU
DEBUG 01-14 20:42:15.652643.652643 lmp.py:1625]   Expert 55 |    199 | GPU
DEBUG 01-14 20:42:15.652431.652431 lmp.py:1625]   Expert 40 |    201 | GPU
DEBUG 01-14 20:42:15.652174.652174 lmp.py:1625]   Expert  6 |    214 | GPU
DEBUG 01-14 20:42:15.652201.652201 lmp.py:1625]   Expert 38 |    215 | GPU
DEBUG 01-14 20:42:15.652990.652990 lmp.py:1625]   Expert 22 |    217 | GPU
DEBUG 01-14 20:42:15.652017.652017 lmp.py:1625]   Expert 37 |    221 | GPU
DEBUG 01-14 20:42:15.652805.652805 lmp.py:1625]   Expert 23 |    229 | GPU
DEBUG 01-14 20:42:15.652594.652594 lmp.py:1625]   Expert 25 |    236 | GPU
DEBUG 01-14 20:42:15.652906.652906 lmp.py:1625]   Expert 46 |    240 | GPU
DEBUG 01-14 20:42:15.652695.652695 lmp.py:1625]   Expert 50 |    247 | GPU
DEBUG 01-14 20:42:15.652722.652722 lmp.py:1625]   Expert 39 |    254 | GPU
DEBUG 01-14 20:42:15.652226.652226 lmp.py:1625]   Expert 12 |    256 | GPU
DEBUG 01-14 20:42:15.652730.652730 lmp.py:1625]   Expert 62 |    260 | GPU
DEBUG 01-14 20:42:15.652519.652519 lmp.py:1625]   Expert 19 |    265 | GPU
DEBUG 01-14 20:42:15.652738.652738 lmp.py:1625]   Expert 21 |    267 | GPU
DEBUG 01-14 20:42:15.652765.652765 lmp.py:1625]   Expert 35 |    283 | GPU
DEBUG 01-14 20:42:15.652746.652746 lmp.py:1625]   Expert 49 |    295 | GPU
DEBUG 01-14 20:42:15.652488.652488 lmp.py:1625]   Expert 52 |    305 | GPU
DEBUG 01-14 20:42:15.652754.652754 lmp.py:1625]   Expert 33 |    315 | GPU
DEBUG 01-14 20:42:15.652781.652781 lmp.py:1625]   Expert  1 |    343 | GPU
DEBUG 01-14 20:42:15.652570.652570 lmp.py:1625]   Expert  5 |    376 | GPU
DEBUG 01-14 20:42:15.652597.652597 lmp.py:1625]   Expert 43 |    432 | GPU
DEBUG 01-14 20:42:15.652585.652585 lmp.py:1625]   Expert 59 |    593 | GPU
DEBUG 01-14 20:42:15.652327.652327 lmp.py:1626] 
DEBUG 01-14 20:42:15.652327.652327 lmp.py:1626]   CPU total tokens: 4145 (33.7%)
DEBUG 01-14 20:42:15.653977.653977 lmp.py:1627]   GPU total tokens: 8143 (66.3%)
DEBUG 01-14 20:42:15.653726.653726 cuda_h.py:19] end experts_map_get cost 0.001775979995727539 seconds
DEBUG 01-14 20:42:15.653152.653152 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-14 20:42:15.653949.653949 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-14 20:42:15.653655.653655 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-14 20:42:15.654714.654714 cuda_h.py:19] end allocate_cuda_memory cost 0.0015168190002441406 seconds
DEBUG 01-14 20:42:15.654107.654107 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-14 20:42:15.654585.654585 sllm_store_c.py:27] get device uuid map
DEBUG 01-14 20:42:15.654494.654494 sllm_store_c.py:29] call client load into gpu
DEBUG 01-14 20:42:15.655674.655674 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 330842b6-f6e8-4e36-82cc-f5254a707cad
DEBUG 01-14 20:42:15.655210.655210 client.py:106] call stub.LoadModelAsync
INFO 01-14 20:42:15.655655.655655 client.py:127] Model loaded
DEBUG 01-14 20:42:15.655120.655120 cuda_h.py:10] start restore2model
DEBUG 01-14 20:42:15.656493.656493 cuda_h.py:19] end restore2model cost 0.00040793418884277344 seconds
DEBUG 01-14 20:42:15.656853.656853 cuda_h.py:19] end sllm_worker_task cost 0.015019416809082031 seconds
INFO 01-14 20:42:15.656743.656743 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 330842b6-f6e8-4e36-82cc-f5254a707cad
DEBUG 01-14 20:42:15.656600.656600 cuda_h.py:19] end load_into_gpu_async cost 0.0014088153839111328 seconds
DEBUG 01-14 20:42:15.656277.656277 cuda_h.py:10] start restore_tensors2
DEBUG 01-14 20:42:15.656725.656725 cuda_h.py:19] end restore_tensors2 cost 0.0003001689910888672 seconds
DEBUG 01-14 20:42:15.656077.656077 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.003615140914916992 seconds
DEBUG 01-14 20:42:15.656940.656940 cuda_h.py:10] start restore2model
DEBUG 01-14 20:42:15.659828.659828 cuda_h.py:19] end restore2model cost 0.0027642250061035156 seconds
DEBUG 01-14 20:42:15.659671.659671 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.006564140319824219 seconds
DEBUG 01-14 20:42:15.659420.659420 cuda_h.py:10] start gpu_sexperts
DEBUG 01-14 20:42:15.660193.660193 cuda_h.py:19] end gpu_sexperts cost 0.0002925395965576172 seconds
DEBUG 01-14 20:42:15.660830.660830 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-14 20:42:15.660586.660586 lmp.py:1683] 
DEBUG 01-14 20:42:15.660586.660586 lmp.py:1683]   Computing 32 experts on CPU...
DEBUG 01-14 20:42:15.660800.660800 cuda_h.py:19] end cpu_experts_submit cost 5.269050598144531e-05 seconds
DEBUG 01-14 20:42:15.660026.660026 cuda_h.py:10] start experts_func_mgpu_group_pad
DEBUG 01-14 20:42:15.666288.666288 mlpmodule.py:1460] group tensors cost 0.0057446956634521484 s
DEBUG 01-14 20:42:15.667632.667632 cuda_h.py:10] start move_flat_hidden2cpu
DEBUG 01-14 20:42:15.668003.668003 cuda_h.py:19] end experts_func_mgpu_group_pad cost 0.00858449935913086 seconds
DEBUG 01-14 20:42:15.670234.670234 cuda_h.py:10] start gpu_group_list
DEBUG 01-14 20:42:15.670609.670609 cuda_h.py:19] end gpu_group_list cost 0.0004181861877441406 seconds
DEBUG 01-14 20:42:15.670321.670321 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-14 20:42:15.671305.671305 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.7179718017578125e-05 seconds
DEBUG 01-14 20:42:15.671479.671479 cuda_h.py:10] start wait_experts
INFO 01-14 20:42:15.671675.671675 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 330842b6-f6e8-4e36-82cc-f5254a707cad
DEBUG 01-14 20:42:15.674991.674991 cuda_h.py:19] end move_flat_hidden2cpu cost 0.007073163986206055 seconds
DEBUG 01-14 20:42:15.676623.676623 mlpmodule.py:1533] pad cost 0.0017418861389160156 s
DEBUG 01-14 20:42:15.676428.676428 mlpmodule.py:1539] create cpu tensor cost 3.743171691894531e-05 s
DEBUG 01-14 20:42:15.678150.678150 mlpmodule.py:1544] move to cpu cost 0.0021429061889648438 s
DEBUG 01-14 20:42:15.686482.686482 mlpmodule.py:1558] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-14 20:42:15.686104.686104 mlpmodule.py:1559] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-14 20:42:15.686346.686346 mlpmodule.py:1564] group_w3 first element: 0.0111083984375
WARNING 01-14 20:42:15.686953.686953 mlpmodule.py:1574] start einsum2
DEBUG 01-14 20:42:15.702623.702623 mlpmodule.py:1584] group einsum cost 0.02452254295349121 s
DEBUG 01-14 20:42:15.704422.704422 mlpmodule.py:1593] cpy2cputensor cost 0.0008044242858886719 s
DEBUG 01-14 20:42:15.704048.704048 cuda_h.py:10] start move_outputs
DEBUG 01-14 20:42:15.707474.707474 cuda_h.py:19] end move_outputs cost 0.002804279327392578 seconds
INFO 01-14 20:42:15.711356.711356 client.py:127] Model loaded
DEBUG 01-14 20:42:15.711512.711512 cuda_h.py:19] end wait_experts cost 0.04027581214904785 seconds
DEBUG 01-14 20:42:15.711448.711448 cuda_h.py:10] start gpu_experts
DEBUG 01-14 20:42:15.711085.711085 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-14 20:42:15.711937.711937 cuda_h.py:19] end wait_cetm_experts cost 8.749961853027344e-05 seconds
DEBUG 01-14 20:42:15.711417.711417 cuda_h.py:10] start gpu_group_einsum_mp_multi_list
DEBUG 01-14 20:42:15.711603.711603 cuda_h.py:10] start gpu_group_tensor
DEBUG 01-14 20:42:15.722098.722098 cuda_h.py:19] end gpu_group_tensor cost 0.010778188705444336 seconds
DEBUG 01-14 20:42:15.722475.722475 cuda_h.py:10] start gpu_group_einsum
DEBUG 01-14 20:42:15.723013.723013 cuda_h.py:19] end gpu_group_einsum cost 0.0005848407745361328 seconds
DEBUG 01-14 20:42:15.723229.723229 cuda_h.py:10] start gpu_final_hidden_states_scatter
DEBUG 01-14 20:42:15.723072.723072 cuda_h.py:10] start all_expert_outputs_slices
DEBUG 01-14 20:42:15.723578.723578 cuda_h.py:19] end all_expert_outputs_slices cost 0.00023293495178222656 seconds
DEBUG 01-14 20:42:15.723810.723810 cuda_h.py:10] start concat_expert_out
DEBUG 01-14 20:42:15.724854.724854 cuda_h.py:19] end concat_expert_out cost 6.580352783203125e-05 seconds
DEBUG 01-14 20:42:15.724810.724810 cuda_h.py:10] start index_scatter
DEBUG 01-14 20:42:15.724084.724084 cuda_h.py:19] end index_scatter cost 6.4849853515625e-05 seconds
DEBUG 01-14 20:42:15.724509.724509 cuda_h.py:19] end gpu_final_hidden_states_scatter cost 0.0006172657012939453 seconds
DEBUG 01-14 20:42:15.724386.724386 cuda_h.py:19] end gpu_experts cost 0.01276540756225586 seconds
DEBUG 01-14 20:42:15.724150.724150 cuda_h.py:10] start all_expert_weight_slices
DEBUG 01-14 20:42:15.725415.725415 cuda_h.py:19] end all_expert_weight_slices cost 0.0007598400115966797 seconds
DEBUG 01-14 20:42:15.725046.725046 cuda_h.py:10] start cpuoutputsdeal
DEBUG 01-14 20:42:15.725806.725806 cuda_h.py:10] start index_scatter
DEBUG 01-14 20:42:15.725220.725220 cuda_h.py:19] end index_scatter cost 4.649162292480469e-05 seconds
DEBUG 01-14 20:42:15.725221.725221 cuda_h.py:19] end cpuoutputsdeal cost 0.00045037269592285156 seconds
DEBUG 01-14 20:42:15.725177.725177 cuda_h.py:19] end layer_moe_generate_mp_l_5 cost 0.0753941535949707 seconds
DEBUG 01-14 20:42:15.726226.726226 cuda_h.py:19] end prefill_layer cost 0.08522367477416992 seconds
DEBUG 01-14 20:42:15.726142.726142 lmp.py:1551] -------------------------------- end prefill layer 4 --------------------------------
DEBUG 01-14 20:42:15.726791.726791 cuda_h.py:10] start prefill_layer
DEBUG 01-14 20:42:15.726872.726872 lmp.py:1494] -------------------------------- start prefill layer 5 --------------------------------
DEBUG 01-14 20:42:15.726475.726475 cuda_h.py:10] start start_load_qkvogn_s_weight_l_6
DEBUG 01-14 20:42:15.726324.726324 cuda_h.py:10] start start_load_qkvogn_s_weight_l_6
DEBUG 01-14 20:42:15.726683.726683 cuda_h.py:19] end start_load_qkvogn_s_weight_l_6 cost 2.956390380859375e-05 seconds
DEBUG 01-14 20:42:15.726432.726432 cuda_h.py:19] end start_load_qkvogn_s_weight_l_6 cost 5.817413330078125e-05 seconds
DEBUG 01-14 20:42:15.726744.726744 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-14 20:42:15.726694.726694 cuda_h.py:10] start sllm_worker_task
DEBUG 01-14 20:42:15.726440.726440 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-14 20:42:15.726302.726302 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-14 20:42:15.726597.726597 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-14 20:42:15.727256.727256 cuda_h.py:19] end allocate_cuda_memory cost 0.0012540817260742188 seconds
DEBUG 01-14 20:42:15.728259.728259 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-14 20:42:15.728273.728273 sllm_store_c.py:27] get device uuid map
DEBUG 01-14 20:42:15.728149.728149 sllm_store_c.py:29] call client load into gpu
DEBUG 01-14 20:42:15.728806.728806 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 412975eb-909f-4e38-9ee7-d00ccaa2670a
DEBUG 01-14 20:42:15.728113.728113 client.py:106] call stub.LoadModelAsync
DEBUG 01-14 20:42:15.728715.728715 mlpmodule.py:1367]  experts func einsum cost 0.0679469108581543 s
DEBUG 01-14 20:42:15.728346.728346 cuda_h.py:10] start self_attn
INFO 01-14 20:42:15.729297.729297 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 412975eb-909f-4e38-9ee7-d00ccaa2670a
DEBUG 01-14 20:42:15.729168.729168 cuda_h.py:19] end load_into_gpu_async cost 0.0017862319946289062 seconds
DEBUG 01-14 20:42:15.729407.729407 cuda_h.py:10] start restore_tensors2
DEBUG 01-14 20:42:15.730471.730471 cuda_h.py:19] end restore_tensors2 cost 8.0108642578125e-05 seconds
DEBUG 01-14 20:42:15.730346.730346 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0034148693084716797 seconds
INFO 01-14 20:42:15.730078.730078 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 412975eb-909f-4e38-9ee7-d00ccaa2670a
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-14 20:42:15.731387.731387 cuda_h.py:19] end self_attn cost 0.002943754196166992 seconds
DEBUG 01-14 20:42:15.732350.732350 cuda_h.py:19] end iln_self_attn_paln cost 0.005614280700683594 seconds
DEBUG 01-14 20:42:15.732770.732770 cuda_h.py:10] start layer_moe_generate_mp_l_6
DEBUG 01-14 20:42:15.732725.732725 cuda_h.py:10] start gate
DEBUG 01-14 20:42:15.732013.732013 cuda_h.py:19] end gate cost 0.0006687641143798828 seconds
DEBUG 01-14 20:42:15.732273.732273 cuda_h.py:10] start experts_map_get
DEBUG 01-14 20:42:15.733065.733065 lmp.py:1615] 
DEBUG 01-14 20:42:15.733065.733065 lmp.py:1615] Expert Token Distribution & Device Allocation:
DEBUG 01-14 20:42:15.733013.733013 lmp.py:1616]   Total experts: 64
DEBUG 01-14 20:42:15.733139.733139 lmp.py:1617]   CPU experts: 32 (50%)
DEBUG 01-14 20:42:15.733928.733928 lmp.py:1618]   GPU experts: 32 (50%)
DEBUG 01-14 20:42:15.733048.733048 lmp.py:1619] 
DEBUG 01-14 20:42:15.733048.733048 lmp.py:1619]   Expert ID | Tokens | Device
DEBUG 01-14 20:42:15.733168.733168 lmp.py:1620]   -----------------------------------
DEBUG 01-14 20:42:15.733480.733480 lmp.py:1625]   Expert 34 |     34 | CPU
DEBUG 01-14 20:42:15.733838.733838 lmp.py:1625]   Expert 45 |     71 | CPU
DEBUG 01-14 20:42:15.733481.733481 lmp.py:1625]   Expert 22 |     78 | CPU
DEBUG 01-14 20:42:15.733124.733124 lmp.py:1625]   Expert 57 |     92 | CPU
DEBUG 01-14 20:42:15.733482.733482 lmp.py:1625]   Expert 17 |     96 | CPU
DEBUG 01-14 20:42:15.733602.733602 lmp.py:1625]   Expert 15 |    104 | CPU
DEBUG 01-14 20:42:15.733960.733960 lmp.py:1625]   Expert  4 |    108 | CPU
DEBUG 01-14 20:42:15.733080.733080 lmp.py:1625]   Expert 28 |    111 | CPU
DEBUG 01-14 20:42:15.733961.733961 lmp.py:1625]   Expert 16 |    119 | CPU
DEBUG 01-14 20:42:15.733604.733604 lmp.py:1625]   Expert 60 |    120 | CPU
DEBUG 01-14 20:42:15.733770.733770 lmp.py:1625]   Expert 12 |    121 | CPU
DEBUG 01-14 20:42:15.733937.733937 lmp.py:1625]   Expert  8 |    124 | CPU
DEBUG 01-14 20:42:15.733864.733864 lmp.py:1625]   Expert 14 |    124 | CPU
DEBUG 01-14 20:42:15.733176.733176 lmp.py:1625]   Expert 36 |    126 | CPU
DEBUG 01-14 20:42:15.733534.733534 lmp.py:1625]   Expert 25 |    127 | CPU
DEBUG 01-14 20:42:15.733893.733893 lmp.py:1625]   Expert 32 |    130 | CPU
DEBUG 01-14 20:42:15.733774.733774 lmp.py:1625]   Expert 52 |    131 | CPU
DEBUG 01-14 20:42:15.733132.733132 lmp.py:1625]   Expert  2 |    138 | CPU
DEBUG 01-14 20:42:15.733014.733014 lmp.py:1625]   Expert 35 |    142 | CPU
DEBUG 01-14 20:42:15.733564.733564 lmp.py:1625]   Expert  5 |    143 | CPU
DEBUG 01-14 20:42:15.733638.733638 lmp.py:1625]   Expert  0 |    145 | CPU
DEBUG 01-14 20:42:15.733949.733949 lmp.py:1625]   Expert 41 |    150 | CPU
DEBUG 01-14 20:42:15.733261.733261 lmp.py:1625]   Expert 23 |    156 | CPU
DEBUG 01-14 20:42:15.733858.733858 lmp.py:1625]   Expert 39 |    159 | CPU
DEBUG 01-14 20:42:15.733978.733978 lmp.py:1625]   Expert 61 |    160 | CPU
DEBUG 01-14 20:42:15.733098.733098 lmp.py:1625]   Expert 30 |    162 | CPU
DEBUG 01-14 20:42:15.733217.733217 lmp.py:1625]   Expert 44 |    170 | CPU
DEBUG 01-14 20:42:15.733576.733576 lmp.py:1625]   Expert  3 |    174 | CPU
DEBUG 01-14 20:42:15.733695.733695 lmp.py:1625]   Expert  9 |    174 | CPU
DEBUG 01-14 20:42:15.733577.733577 lmp.py:1625]   Expert 13 |    175 | CPU
DEBUG 01-14 20:42:15.733697.733697 lmp.py:1625]   Expert 43 |    177 | CPU
DEBUG 01-14 20:42:15.733532.733532 lmp.py:1625]   Expert 31 |    179 | CPU
DEBUG 01-14 20:42:15.733367.733367 lmp.py:1625]   Expert 46 |    183 | GPU
DEBUG 01-14 20:42:15.733679.733679 lmp.py:1625]   Expert 62 |    186 | GPU
DEBUG 01-14 20:42:15.733514.733514 lmp.py:1625]   Expert 42 |    188 | GPU
DEBUG 01-14 20:42:15.733164.733164 lmp.py:1625]   Expert 50 |    188 | GPU
DEBUG 01-14 20:42:15.733568.733568 lmp.py:1625]   Expert 11 |    193 | GPU
DEBUG 01-14 20:42:15.733734.733734 lmp.py:1625]   Expert 20 |    194 | GPU
DEBUG 01-14 20:42:15.733185.733185 lmp.py:1625]   Expert 26 |    194 | GPU
DEBUG 01-14 20:42:15.734113.734113 lmp.py:1625]   Expert 47 |    196 | GPU
DEBUG 01-14 20:42:15.734802.734802 lmp.py:1625]   Expert 51 |    199 | GPU
DEBUG 01-14 20:42:15.734730.734730 lmp.py:1625]   Expert 19 |    200 | GPU
DEBUG 01-14 20:42:15.734658.734658 lmp.py:1625]   Expert 63 |    201 | GPU
DEBUG 01-14 20:42:15.734824.734824 lmp.py:1625]   Expert 18 |    203 | GPU
DEBUG 01-14 20:42:15.734228.734228 lmp.py:1625]   Expert 27 |    205 | GPU
DEBUG 01-14 20:42:15.734871.734871 lmp.py:1625]   Expert 55 |    211 | GPU
DEBUG 01-14 20:42:15.734753.734753 lmp.py:1625]   Expert 56 |    211 | GPU
DEBUG 01-14 20:42:15.734396.734396 lmp.py:1625]   Expert 38 |    213 | GPU
DEBUG 01-14 20:42:15.734562.734562 lmp.py:1625]   Expert 49 |    216 | GPU
DEBUG 01-14 20:42:15.734489.734489 lmp.py:1625]   Expert 48 |    228 | GPU
DEBUG 01-14 20:42:15.734417.734417 lmp.py:1625]   Expert  1 |    235 | GPU
DEBUG 01-14 20:42:15.734345.734345 lmp.py:1625]   Expert  7 |    236 | GPU
DEBUG 01-14 20:42:15.734796.734796 lmp.py:1625]   Expert 10 |    242 | GPU
DEBUG 01-14 20:42:15.734962.734962 lmp.py:1625]   Expert 54 |    245 | GPU
DEBUG 01-14 20:42:15.734651.734651 lmp.py:1625]   Expert 21 |    246 | GPU
DEBUG 01-14 20:42:15.734817.734817 lmp.py:1625]   Expert 24 |    252 | GPU
DEBUG 01-14 20:42:15.734507.734507 lmp.py:1625]   Expert 33 |    255 | GPU
DEBUG 01-14 20:42:15.734673.734673 lmp.py:1625]   Expert 29 |    261 | GPU
DEBUG 01-14 20:42:15.734362.734362 lmp.py:1625]   Expert 40 |    271 | GPU
DEBUG 01-14 20:42:15.734813.734813 lmp.py:1625]   Expert 59 |    288 | GPU
DEBUG 01-14 20:42:15.734979.734979 lmp.py:1625]   Expert 37 |    336 | GPU
DEBUG 01-14 20:42:15.734384.734384 lmp.py:1625]   Expert 58 |    356 | GPU
DEBUG 01-14 20:42:15.734027.734027 lmp.py:1625]   Expert  6 |    385 | GPU
DEBUG 01-14 20:42:15.734146.734146 lmp.py:1625]   Expert 53 |    851 | GPU
DEBUG 01-14 20:42:15.734220.734220 lmp.py:1626] 
DEBUG 01-14 20:42:15.734220.734220 lmp.py:1626]   CPU total tokens: 4220 (34.3%)
DEBUG 01-14 20:42:15.734293.734293 lmp.py:1627]   GPU total tokens: 8068 (65.7%)
DEBUG 01-14 20:42:15.734466.734466 cuda_h.py:19] end experts_map_get cost 0.0015873908996582031 seconds
DEBUG 01-14 20:42:15.734170.734170 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-14 20:42:15.734914.734914 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-14 20:42:15.734236.734236 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-14 20:42:15.736907.736907 cuda_h.py:19] end allocate_cuda_memory cost 0.0014095306396484375 seconds
DEBUG 01-14 20:42:15.736042.736042 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-14 20:42:15.736990.736990 sllm_store_c.py:27] get device uuid map
DEBUG 01-14 20:42:15.736706.736706 sllm_store_c.py:29] call client load into gpu
DEBUG 01-14 20:42:15.736648.736648 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 898a9e45-b326-4044-845a-7a350aa47a77
DEBUG 01-14 20:42:15.736031.736031 client.py:106] call stub.LoadModelAsync
INFO 01-14 20:42:15.737350.737350 client.py:127] Model loaded
DEBUG 01-14 20:42:15.737525.737525 cuda_h.py:10] start restore2model
DEBUG 01-14 20:42:15.738897.738897 cuda_h.py:19] end restore2model cost 0.0004100799560546875 seconds
DEBUG 01-14 20:42:15.738442.738442 cuda_h.py:19] end sllm_worker_task cost 0.011908531188964844 seconds
INFO 01-14 20:42:15.739604.739604 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 898a9e45-b326-4044-845a-7a350aa47a77
DEBUG 01-14 20:42:15.739885.739885 cuda_h.py:19] end load_into_gpu_async cost 0.003182649612426758 seconds
DEBUG 01-14 20:42:15.739733.739733 cuda_h.py:10] start restore_tensors2
DEBUG 01-14 20:42:15.739432.739432 cuda_h.py:19] end restore_tensors2 cost 0.0002765655517578125 seconds
DEBUG 01-14 20:42:15.739063.739063 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0052106380462646484 seconds
DEBUG 01-14 20:42:15.739303.739303 cuda_h.py:10] start restore2model
DEBUG 01-14 20:42:15.742077.742077 cuda_h.py:19] end restore2model cost 0.002542734146118164 seconds
DEBUG 01-14 20:42:15.742258.742258 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.007930517196655273 seconds
DEBUG 01-14 20:42:15.742889.742889 cuda_h.py:10] start gpu_sexperts
DEBUG 01-14 20:42:15.742721.742721 cuda_h.py:19] end gpu_sexperts cost 0.00029754638671875 seconds
DEBUG 01-14 20:42:15.742882.742882 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-14 20:42:15.742730.742730 lmp.py:1683] 
DEBUG 01-14 20:42:15.742730.742730 lmp.py:1683]   Computing 32 experts on CPU...
DEBUG 01-14 20:42:15.743752.743752 cuda_h.py:19] end cpu_experts_submit cost 5.1021575927734375e-05 seconds
DEBUG 01-14 20:42:15.743217.743217 cuda_h.py:10] start experts_func_mgpu_group_pad
DEBUG 01-14 20:42:15.753717.753717 mlpmodule.py:1460] group tensors cost 0.009906768798828125 s
DEBUG 01-14 20:42:15.753857.753857 cuda_h.py:10] start move_flat_hidden2cpu
DEBUG 01-14 20:42:15.755819.755819 cuda_h.py:19] end experts_func_mgpu_group_pad cost 0.012626409530639648 seconds
DEBUG 01-14 20:42:15.764143.764143 cuda_h.py:19] end move_flat_hidden2cpu cost 0.010852336883544922 seconds
DEBUG 01-14 20:42:15.766728.766728 mlpmodule.py:1533] pad cost 0.001737356185913086 s
DEBUG 01-14 20:42:15.766433.766433 mlpmodule.py:1539] create cpu tensor cost 3.6716461181640625e-05 s
DEBUG 01-14 20:42:15.768327.768327 mlpmodule.py:1544] move to cpu cost 0.002129077911376953 s
DEBUG 01-14 20:42:15.770675.770675 cuda_h.py:10] start gpu_group_list
DEBUG 01-14 20:42:15.771390.771390 cuda_h.py:19] end gpu_group_list cost 0.0008871555328369141 seconds
DEBUG 01-14 20:42:15.772056.772056 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-14 20:42:15.773897.773897 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 7.724761962890625e-05 seconds
DEBUG 01-14 20:42:15.773949.773949 cuda_h.py:10] start wait_experts
INFO 01-14 20:42:15.773112.773112 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 898a9e45-b326-4044-845a-7a350aa47a77
DEBUG 01-14 20:42:15.777719.777719 mlpmodule.py:1558] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-14 20:42:15.777721.777721 mlpmodule.py:1559] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-14 20:42:15.777944.777944 mlpmodule.py:1564] group_w3 first element: 0.03369140625
WARNING 01-14 20:42:15.777478.777478 mlpmodule.py:1574] start einsum2
DEBUG 01-14 20:42:15.792187.792187 mlpmodule.py:1584] group einsum cost 0.023225069046020508 s
DEBUG 01-14 20:42:15.793449.793449 mlpmodule.py:1593] cpy2cputensor cost 0.0010263919830322266 s
DEBUG 01-14 20:42:15.793465.793465 cuda_h.py:10] start move_outputs
INFO 01-14 20:42:15.793119.793119 client.py:127] Model loaded
DEBUG 01-14 20:42:15.793799.793799 cuda_h.py:19] end wait_experts cost 0.020331621170043945 seconds
DEBUG 01-14 20:42:15.793284.793284 cuda_h.py:10] start gpu_experts
DEBUG 01-14 20:42:15.793146.793146 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-14 20:42:15.795330.795330 cuda_h.py:19] end move_outputs cost 0.002069711685180664 seconds
DEBUG 01-14 20:42:15.799939.799939 cuda_h.py:19] end wait_cetm_experts cost 0.00584721565246582 seconds
DEBUG 01-14 20:42:15.799154.799154 cuda_h.py:10] start gpu_group_einsum_mp_multi_list
DEBUG 01-14 20:42:15.799354.799354 cuda_h.py:10] start gpu_group_tensor
DEBUG 01-14 20:42:15.800865.800865 cuda_h.py:19] end gpu_group_tensor cost 0.00020194053649902344 seconds
DEBUG 01-14 20:42:15.800346.800346 cuda_h.py:10] start gpu_group_einsum
DEBUG 01-14 20:42:15.816165.816165 mlpmodule.py:1367]  experts func einsum cost 0.07334423065185547 s
DEBUG 01-14 20:42:15.817348.817348 cuda_h.py:19] end gpu_group_einsum cost 0.017016172409057617 seconds
DEBUG 01-14 20:42:15.817114.817114 cuda_h.py:10] start gpu_final_hidden_states_scatter
DEBUG 01-14 20:42:15.817765.817765 cuda_h.py:10] start all_expert_outputs_slices
DEBUG 01-14 20:42:15.817091.817091 cuda_h.py:19] end all_expert_outputs_slices cost 0.0001995563507080078 seconds
DEBUG 01-14 20:42:15.817939.817939 cuda_h.py:10] start concat_expert_out
DEBUG 01-14 20:42:15.817830.817830 cuda_h.py:19] end concat_expert_out cost 6.175041198730469e-05 seconds
DEBUG 01-14 20:42:15.817210.817210 cuda_h.py:10] start index_scatter
DEBUG 01-14 20:42:15.818332.818332 cuda_h.py:19] end index_scatter cost 5.841255187988281e-05 seconds
DEBUG 01-14 20:42:15.818565.818565 cuda_h.py:19] end gpu_final_hidden_states_scatter cost 0.000568389892578125 seconds
DEBUG 01-14 20:42:15.818329.818329 cuda_h.py:19] end gpu_experts cost 0.024262428283691406 seconds
DEBUG 01-14 20:42:15.818515.818515 cuda_h.py:10] start all_expert_weight_slices
DEBUG 01-14 20:42:15.819734.819734 cuda_h.py:19] end all_expert_weight_slices cost 0.0007650852203369141 seconds
DEBUG 01-14 20:42:15.819696.819696 cuda_h.py:10] start cpuoutputsdeal
DEBUG 01-14 20:42:15.819104.819104 cuda_h.py:10] start index_scatter
DEBUG 01-14 20:42:15.819333.819333 cuda_h.py:19] end index_scatter cost 4.9114227294921875e-05 seconds
DEBUG 01-14 20:42:15.819910.819910 cuda_h.py:19] end cpuoutputsdeal cost 0.0004456043243408203 seconds
DEBUG 01-14 20:42:15.819721.819721 cuda_h.py:19] end layer_moe_generate_mp_l_6 cost 0.08750057220458984 seconds
DEBUG 01-14 20:42:15.819015.819015 cuda_h.py:19] end prefill_layer cost 0.09367632865905762 seconds
DEBUG 01-14 20:42:15.819222.819222 lmp.py:1551] -------------------------------- end prefill layer 5 --------------------------------
DEBUG 01-14 20:42:15.819348.819348 cuda_h.py:10] start prefill_layer
DEBUG 01-14 20:42:15.819713.819713 lmp.py:1494] -------------------------------- start prefill layer 6 --------------------------------
DEBUG 01-14 20:42:15.820079.820079 cuda_h.py:10] start start_load_qkvogn_s_weight_l_7
DEBUG 01-14 20:42:15.820450.820450 cuda_h.py:10] start start_load_qkvogn_s_weight_l_7
DEBUG 01-14 20:42:15.820949.820949 cuda_h.py:19] end start_load_qkvogn_s_weight_l_7 cost 2.7179718017578125e-05 seconds
DEBUG 01-14 20:42:15.820957.820957 cuda_h.py:19] end start_load_qkvogn_s_weight_l_7 cost 7.081031799316406e-05 seconds
DEBUG 01-14 20:42:15.820792.820792 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-14 20:42:15.820781.820781 cuda_h.py:10] start sllm_worker_task
DEBUG 01-14 20:42:15.820745.820745 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-14 20:42:15.820845.820845 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-14 20:42:15.820922.820922 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-14 20:42:15.820645.820645 cuda_h.py:19] end allocate_cuda_memory cost 0.0001785755157470703 seconds
DEBUG 01-14 20:42:15.820402.820402 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-14 20:42:15.820781.820781 sllm_store_c.py:27] get device uuid map
DEBUG 01-14 20:42:15.820432.820432 sllm_store_c.py:29] call client load into gpu
DEBUG 01-14 20:42:15.820479.820479 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 16aa7a0e-75a6-45a2-85ae-2ad9d65eef46
DEBUG 01-14 20:42:15.820853.820853 client.py:106] call stub.LoadModelAsync
DEBUG 01-14 20:42:15.821063.821063 cuda_h.py:10] start self_attn
INFO 01-14 20:42:15.822130.822130 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 16aa7a0e-75a6-45a2-85ae-2ad9d65eef46
DEBUG 01-14 20:42:15.822748.822748 cuda_h.py:19] end load_into_gpu_async cost 0.0017993450164794922 seconds
DEBUG 01-14 20:42:15.822842.822842 cuda_h.py:10] start restore_tensors2
DEBUG 01-14 20:42:15.822429.822429 cuda_h.py:19] end restore_tensors2 cost 8.0108642578125e-05 seconds
DEBUG 01-14 20:42:15.822404.822404 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0023398399353027344 seconds
INFO 01-14 20:42:15.822824.822824 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 16aa7a0e-75a6-45a2-85ae-2ad9d65eef46
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-14 20:42:15.824124.824124 cuda_h.py:19] end self_attn cost 0.0029268264770507812 seconds
DEBUG 01-14 20:42:15.824260.824260 cuda_h.py:19] end iln_self_attn_paln cost 0.004456758499145508 seconds
DEBUG 01-14 20:42:15.824487.824487 cuda_h.py:10] start layer_moe_generate_mp_l_7
DEBUG 01-14 20:42:15.824488.824488 cuda_h.py:10] start gate
DEBUG 01-14 20:42:15.825789.825789 cuda_h.py:19] end gate cost 0.0006418228149414062 seconds
DEBUG 01-14 20:42:15.825718.825718 cuda_h.py:10] start experts_map_get
DEBUG 01-14 20:42:15.825834.825834 lmp.py:1615] 
DEBUG 01-14 20:42:15.825834.825834 lmp.py:1615] Expert Token Distribution & Device Allocation:
DEBUG 01-14 20:42:15.825974.825974 lmp.py:1616]   Total experts: 64
DEBUG 01-14 20:42:15.825439.825439 lmp.py:1617]   CPU experts: 32 (50%)
DEBUG 01-14 20:42:15.825095.825095 lmp.py:1618]   GPU experts: 32 (50%)
DEBUG 01-14 20:42:15.825599.825599 lmp.py:1619] 
DEBUG 01-14 20:42:15.825599.825599 lmp.py:1619]   Expert ID | Tokens | Device
DEBUG 01-14 20:42:15.825434.825434 lmp.py:1620]   -----------------------------------
DEBUG 01-14 20:42:15.825746.825746 lmp.py:1625]   Expert  1 |     48 | CPU
DEBUG 01-14 20:42:15.825151.825151 lmp.py:1625]   Expert 37 |     65 | CPU
DEBUG 01-14 20:42:15.825509.825509 lmp.py:1625]   Expert 17 |     72 | CPU
DEBUG 01-14 20:42:15.825390.825390 lmp.py:1625]   Expert  7 |     79 | CPU
DEBUG 01-14 20:42:15.825557.825557 lmp.py:1625]   Expert 13 |     82 | CPU
DEBUG 01-14 20:42:15.825723.825723 lmp.py:1625]   Expert 18 |     83 | CPU
DEBUG 01-14 20:42:15.826366.826366 lmp.py:1625]   Expert  9 |     93 | CPU
DEBUG 01-14 20:42:15.826817.826817 lmp.py:1625]   Expert 54 |     95 | CPU
DEBUG 01-14 20:42:15.826029.826029 lmp.py:1625]   Expert 58 |     97 | CPU
DEBUG 01-14 20:42:15.826480.826480 lmp.py:1625]   Expert 22 |    104 | CPU
DEBUG 01-14 20:42:15.826169.826169 lmp.py:1625]   Expert  0 |    107 | CPU
DEBUG 01-14 20:42:15.826620.826620 lmp.py:1625]   Expert 26 |    109 | CPU
DEBUG 01-14 20:42:15.826071.826071 lmp.py:1625]   Expert 59 |    111 | CPU
DEBUG 01-14 20:42:15.826760.826760 lmp.py:1625]   Expert 10 |    116 | CPU
DEBUG 01-14 20:42:15.826211.826211 lmp.py:1625]   Expert 16 |    119 | CPU
DEBUG 01-14 20:42:15.826616.826616 lmp.py:1625]   Expert 43 |    125 | CPU
DEBUG 01-14 20:42:15.826543.826543 lmp.py:1625]   Expert 63 |    132 | CPU
DEBUG 01-14 20:42:15.826710.826710 lmp.py:1625]   Expert 28 |    138 | CPU
DEBUG 01-14 20:42:15.826353.826353 lmp.py:1625]   Expert 33 |    138 | CPU
DEBUG 01-14 20:42:15.826426.826426 lmp.py:1625]   Expert 29 |    142 | CPU
DEBUG 01-14 20:42:15.826307.826307 lmp.py:1625]   Expert  2 |    147 | CPU
DEBUG 01-14 20:42:15.826950.826950 lmp.py:1625]   Expert 51 |    148 | CPU
DEBUG 01-14 20:42:15.826117.826117 lmp.py:1625]   Expert 45 |    157 | CPU
DEBUG 01-14 20:42:15.826521.826521 lmp.py:1625]   Expert 23 |    161 | CPU
DEBUG 01-14 20:42:15.826926.826926 lmp.py:1625]   Expert 62 |    161 | CPU
DEBUG 01-14 20:42:15.826330.826330 lmp.py:1625]   Expert 40 |    166 | CPU
DEBUG 01-14 20:42:15.826496.826496 lmp.py:1625]   Expert 55 |    167 | CPU
DEBUG 01-14 20:42:15.826662.826662 lmp.py:1625]   Expert 34 |    168 | CPU
DEBUG 01-14 20:42:15.826067.826067 lmp.py:1625]   Expert 32 |    169 | CPU
DEBUG 01-14 20:42:15.826710.826710 lmp.py:1625]   Expert 52 |    172 | CPU
DEBUG 01-14 20:42:15.826638.826638 lmp.py:1625]   Expert 11 |    173 | CPU
DEBUG 01-14 20:42:15.826758.826758 lmp.py:1625]   Expert 41 |    174 | CPU
DEBUG 01-14 20:42:15.826877.826877 lmp.py:1625]   Expert 14 |    175 | GPU
DEBUG 01-14 20:42:15.826997.826997 lmp.py:1625]   Expert 53 |    180 | GPU
DEBUG 01-14 20:42:15.826117.826117 lmp.py:1625]   Expert  3 |    184 | GPU
DEBUG 01-14 20:42:15.826998.826998 lmp.py:1625]   Expert 42 |    189 | GPU
DEBUG 01-14 20:42:15.826641.826641 lmp.py:1625]   Expert 57 |    191 | GPU
DEBUG 01-14 20:42:15.826807.826807 lmp.py:1625]   Expert 15 |    205 | GPU
DEBUG 01-14 20:42:15.826735.826735 lmp.py:1625]   Expert 35 |    206 | GPU
DEBUG 01-14 20:42:15.826901.826901 lmp.py:1625]   Expert 30 |    210 | GPU
DEBUG 01-14 20:42:15.826067.826067 lmp.py:1625]   Expert 24 |    219 | GPU
DEBUG 01-14 20:42:15.826472.826472 lmp.py:1625]   Expert  4 |    220 | GPU
DEBUG 01-14 20:42:15.826638.826638 lmp.py:1625]   Expert 21 |    222 | GPU
DEBUG 01-14 20:42:15.826804.826804 lmp.py:1625]   Expert 44 |    224 | GPU
DEBUG 01-14 20:42:15.826970.826970 lmp.py:1625]   Expert 12 |    226 | GPU
DEBUG 01-14 20:42:15.826375.826375 lmp.py:1625]   Expert 19 |    231 | GPU
DEBUG 01-14 20:42:15.826018.826018 lmp.py:1625]   Expert 49 |    234 | GPU
DEBUG 01-14 20:42:15.826091.826091 lmp.py:1625]   Expert 38 |    236 | GPU
DEBUG 01-14 20:42:15.826927.826927 lmp.py:1625]   Expert 47 |    240 | GPU
DEBUG 01-14 20:42:15.826808.826808 lmp.py:1625]   Expert 50 |    245 | GPU
DEBUG 01-14 20:42:15.826212.826212 lmp.py:1625]   Expert 61 |    245 | GPU
DEBUG 01-14 20:42:15.826855.826855 lmp.py:1625]   Expert 46 |    247 | GPU
DEBUG 01-14 20:42:15.826783.826783 lmp.py:1625]   Expert 31 |    248 | GPU
DEBUG 01-14 20:42:15.826188.826188 lmp.py:1625]   Expert  8 |    249 | GPU
DEBUG 01-14 20:42:15.826592.826592 lmp.py:1625]   Expert  6 |    254 | GPU
DEBUG 01-14 20:42:15.826758.826758 lmp.py:1625]   Expert 39 |    261 | GPU
DEBUG 01-14 20:42:15.826925.826925 lmp.py:1625]   Expert  5 |    299 | GPU
DEBUG 01-14 20:42:15.826091.826091 lmp.py:1625]   Expert 27 |    302 | GPU
DEBUG 01-14 20:42:15.826495.826495 lmp.py:1625]   Expert 48 |    304 | GPU
DEBUG 01-14 20:42:15.826423.826423 lmp.py:1625]   Expert 20 |    342 | GPU
DEBUG 01-14 20:42:15.826781.826781 lmp.py:1625]   Expert 60 |    361 | GPU
DEBUG 01-14 20:42:15.826424.826424 lmp.py:1625]   Expert 36 |    362 | GPU
DEBUG 01-14 20:42:15.826067.826067 lmp.py:1625]   Expert 25 |    392 | GPU
DEBUG 01-14 20:42:15.827479.827479 lmp.py:1625]   Expert 56 |    567 | GPU
DEBUG 01-14 20:42:15.827121.827121 lmp.py:1626] 
DEBUG 01-14 20:42:15.827121.827121 lmp.py:1626]   CPU total tokens: 4018 (32.7%)
DEBUG 01-14 20:42:15.827526.827526 lmp.py:1627]   GPU total tokens: 8270 (67.3%)
DEBUG 01-14 20:42:15.827461.827461 cuda_h.py:19] end experts_map_get cost 0.0015711784362792969 seconds
DEBUG 01-14 20:42:15.827787.827787 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-14 20:42:15.827531.827531 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-14 20:42:15.827323.827323 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-14 20:42:15.828555.828555 cuda_h.py:19] end allocate_cuda_memory cost 0.001542806625366211 seconds
DEBUG 01-14 20:42:15.828458.828458 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-14 20:42:15.828929.828929 sllm_store_c.py:27] get device uuid map
DEBUG 01-14 20:42:15.829546.829546 sllm_store_c.py:29] call client load into gpu
DEBUG 01-14 20:42:15.829673.829673 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 2940a63f-b889-4808-bade-3dcf512e80f3
DEBUG 01-14 20:42:15.829950.829950 client.py:106] call stub.LoadModelAsync
INFO 01-14 20:42:15.830640.830640 client.py:127] Model loaded
DEBUG 01-14 20:42:15.830198.830198 cuda_h.py:10] start restore2model
DEBUG 01-14 20:42:15.831302.831302 cuda_h.py:19] end restore2model cost 0.0004878044128417969 seconds
DEBUG 01-14 20:42:15.831775.831775 cuda_h.py:19] end sllm_worker_task cost 0.010941743850708008 seconds
INFO 01-14 20:42:15.832777.832777 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 2940a63f-b889-4808-bade-3dcf512e80f3
DEBUG 01-14 20:42:15.832028.832028 cuda_h.py:19] end load_into_gpu_async cost 0.0033197402954101562 seconds
DEBUG 01-14 20:42:15.832979.832979 cuda_h.py:10] start restore_tensors2
DEBUG 01-14 20:42:15.833778.833778 cuda_h.py:19] end restore_tensors2 cost 0.0006525516510009766 seconds
DEBUG 01-14 20:42:15.833316.833316 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.006033182144165039 seconds
DEBUG 01-14 20:42:15.833794.833794 cuda_h.py:10] start restore2model
DEBUG 01-14 20:42:15.835978.835978 cuda_h.py:19] end restore2model cost 0.002492666244506836 seconds
DEBUG 01-14 20:42:15.835954.835954 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.008695840835571289 seconds
DEBUG 01-14 20:42:15.835749.835749 cuda_h.py:10] start gpu_sexperts
DEBUG 01-14 20:42:15.836719.836719 cuda_h.py:19] end gpu_sexperts cost 0.0002620220184326172 seconds
DEBUG 01-14 20:42:15.836688.836688 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-14 20:42:15.836080.836080 lmp.py:1683] 
DEBUG 01-14 20:42:15.836080.836080 lmp.py:1683]   Computing 32 experts on CPU...
DEBUG 01-14 20:42:15.836386.836386 cuda_h.py:19] end cpu_experts_submit cost 4.9591064453125e-05 seconds
DEBUG 01-14 20:42:15.836897.836897 cuda_h.py:10] start experts_func_mgpu_group_pad
DEBUG 01-14 20:42:15.847980.847980 mlpmodule.py:1460] group tensors cost 0.010888338088989258 s
DEBUG 01-14 20:42:15.848024.848024 cuda_h.py:10] start move_flat_hidden2cpu
DEBUG 01-14 20:42:15.850262.850262 cuda_h.py:19] end experts_func_mgpu_group_pad cost 0.01364588737487793 seconds
DEBUG 01-14 20:42:15.851052.851052 cuda_h.py:10] start gpu_group_list
DEBUG 01-14 20:42:15.852876.852876 cuda_h.py:19] end gpu_group_list cost 0.0005736351013183594 seconds
DEBUG 01-14 20:42:15.852691.852691 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-14 20:42:15.852754.852754 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.2411346435546875e-05 seconds
DEBUG 01-14 20:42:15.852385.852385 cuda_h.py:10] start wait_experts
INFO 01-14 20:42:15.852247.852247 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 2940a63f-b889-4808-bade-3dcf512e80f3
DEBUG 01-14 20:42:15.856111.856111 cuda_h.py:19] end move_flat_hidden2cpu cost 0.008015632629394531 seconds
DEBUG 01-14 20:42:15.861361.861361 mlpmodule.py:1533] pad cost 0.004640817642211914 s
DEBUG 01-14 20:42:15.861266.861266 mlpmodule.py:1539] create cpu tensor cost 6.651878356933594e-05 s
DEBUG 01-14 20:42:15.863654.863654 mlpmodule.py:1544] move to cpu cost 0.002063274383544922 s
DEBUG 01-14 20:42:15.871880.871880 mlpmodule.py:1558] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-14 20:42:15.871641.871641 mlpmodule.py:1559] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-14 20:42:15.871830.871830 mlpmodule.py:1564] group_w3 first element: -0.003631591796875
WARNING 01-14 20:42:15.871676.871676 mlpmodule.py:1574] start einsum2
DEBUG 01-14 20:42:15.885653.885653 mlpmodule.py:1584] group einsum cost 0.021607637405395508 s
INFO 01-14 20:42:15.886865.886865 client.py:127] Model loaded
DEBUG 01-14 20:42:15.886776.886776 mlpmodule.py:1593] cpy2cputensor cost 0.0010995864868164062 s
DEBUG 01-14 20:42:15.886813.886813 cuda_h.py:19] end wait_experts cost 0.034078359603881836 seconds
DEBUG 01-14 20:42:15.886390.886390 cuda_h.py:10] start move_outputs
DEBUG 01-14 20:42:15.886849.886849 cuda_h.py:10] start gpu_experts
DEBUG 01-14 20:42:15.886475.886475 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-14 20:42:15.888442.888442 cuda_h.py:19] end move_outputs cost 0.002026796340942383 seconds
DEBUG 01-14 20:42:15.892222.892222 cuda_h.py:19] end wait_cetm_experts cost 0.0058498382568359375 seconds
DEBUG 01-14 20:42:15.892953.892953 cuda_h.py:10] start gpu_group_einsum_mp_multi_list
DEBUG 01-14 20:42:15.892809.892809 cuda_h.py:10] start gpu_group_tensor
DEBUG 01-14 20:42:15.893611.893611 cuda_h.py:19] end gpu_group_tensor cost 0.00020813941955566406 seconds
DEBUG 01-14 20:42:15.893277.893277 cuda_h.py:10] start gpu_group_einsum
DEBUG 01-14 20:42:15.893955.893955 cuda_h.py:19] end gpu_group_einsum cost 0.0006272792816162109 seconds
DEBUG 01-14 20:42:15.893801.893801 cuda_h.py:10] start gpu_final_hidden_states_scatter
DEBUG 01-14 20:42:15.894220.894220 cuda_h.py:10] start all_expert_outputs_slices
DEBUG 01-14 20:42:15.894531.894531 cuda_h.py:19] end all_expert_outputs_slices cost 0.0003292560577392578 seconds
DEBUG 01-14 20:42:15.894631.894631 cuda_h.py:10] start concat_expert_out
DEBUG 01-14 20:42:15.894456.894456 cuda_h.py:19] end concat_expert_out cost 5.91278076171875e-05 seconds
DEBUG 01-14 20:42:15.894730.894730 cuda_h.py:10] start index_scatter
DEBUG 01-14 20:42:15.894574.894574 cuda_h.py:19] end index_scatter cost 6.127357482910156e-05 seconds
DEBUG 01-14 20:42:15.894622.894622 cuda_h.py:19] end gpu_final_hidden_states_scatter cost 0.0007338523864746094 seconds
DEBUG 01-14 20:42:15.894591.894591 cuda_h.py:19] end gpu_experts cost 0.008030891418457031 seconds
DEBUG 01-14 20:42:15.894817.894817 cuda_h.py:10] start all_expert_weight_slices
DEBUG 01-14 20:42:15.895465.895465 cuda_h.py:19] end all_expert_weight_slices cost 0.000904083251953125 seconds
DEBUG 01-14 20:42:15.895903.895903 cuda_h.py:10] start cpuoutputsdeal
DEBUG 01-14 20:42:15.896837.896837 cuda_h.py:10] start index_scatter
DEBUG 01-14 20:42:15.896682.896682 cuda_h.py:19] end index_scatter cost 4.76837158203125e-05 seconds
DEBUG 01-14 20:42:15.896717.896717 cuda_h.py:19] end cpuoutputsdeal cost 0.0005342960357666016 seconds
DEBUG 01-14 20:42:15.896302.896302 cuda_h.py:19] end layer_moe_generate_mp_l_7 cost 0.07177567481994629 seconds
DEBUG 01-14 20:42:15.896915.896915 cuda_h.py:19] end prefill_layer cost 0.07682967185974121 seconds
DEBUG 01-14 20:42:15.896599.896599 lmp.py:1551] -------------------------------- end prefill layer 6 --------------------------------
DEBUG 01-14 20:42:15.896779.896779 cuda_h.py:10] start prefill_layer
DEBUG 01-14 20:42:15.896912.896912 lmp.py:1494] -------------------------------- start prefill layer 7 --------------------------------
DEBUG 01-14 20:42:15.896807.896807 cuda_h.py:10] start start_load_qkvogn_s_weight_l_8
DEBUG 01-14 20:42:15.896325.896325 cuda_h.py:10] start start_load_qkvogn_s_weight_l_8
DEBUG 01-14 20:42:15.897837.897837 cuda_h.py:19] end start_load_qkvogn_s_weight_l_8 cost 3.266334533691406e-05 seconds
DEBUG 01-14 20:42:15.897831.897831 cuda_h.py:19] end start_load_qkvogn_s_weight_l_8 cost 6.604194641113281e-05 seconds
DEBUG 01-14 20:42:15.897110.897110 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-14 20:42:15.897384.897384 cuda_h.py:10] start sllm_worker_task
DEBUG 01-14 20:42:15.897713.897713 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-14 20:42:15.897966.897966 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-14 20:42:15.897435.897435 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-14 20:42:15.898781.898781 cuda_h.py:19] end allocate_cuda_memory cost 0.0013687610626220703 seconds
DEBUG 01-14 20:42:15.899566.899566 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-14 20:42:15.899125.899125 sllm_store_c.py:27] get device uuid map
DEBUG 01-14 20:42:15.899915.899915 sllm_store_c.py:29] call client load into gpu
DEBUG 01-14 20:42:15.899863.899863 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, aaa320c9-3ec9-46c0-aec4-df7231467ea8
DEBUG 01-14 20:42:15.899973.899973 client.py:106] call stub.LoadModelAsync
DEBUG 01-14 20:42:15.904213.904213 cuda_h.py:10] start self_attn
INFO 01-14 20:42:15.905594.905594 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, aaa320c9-3ec9-46c0-aec4-df7231467ea8
DEBUG 01-14 20:42:15.905802.905802 cuda_h.py:19] end load_into_gpu_async cost 0.006574153900146484 seconds
DEBUG 01-14 20:42:15.905743.905743 cuda_h.py:10] start restore_tensors2
DEBUG 01-14 20:42:15.905548.905548 cuda_h.py:19] end restore_tensors2 cost 7.510185241699219e-05 seconds
DEBUG 01-14 20:42:15.905065.905065 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.008356332778930664 seconds
INFO 01-14 20:42:15.905100.905100 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, aaa320c9-3ec9-46c0-aec4-df7231467ea8
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-14 20:42:15.907699.907699 cuda_h.py:19] end self_attn cost 0.002959012985229492 seconds
DEBUG 01-14 20:42:15.908902.908902 cuda_h.py:19] end iln_self_attn_paln cost 0.010937929153442383 seconds
DEBUG 01-14 20:42:15.908698.908698 cuda_h.py:10] start layer_moe_generate_mp_l_8
DEBUG 01-14 20:42:15.908938.908938 cuda_h.py:10] start gate
DEBUG 01-14 20:42:15.908180.908180 cuda_h.py:19] end gate cost 0.0006690025329589844 seconds
DEBUG 01-14 20:42:15.908533.908533 cuda_h.py:10] start experts_map_get
DEBUG 01-14 20:42:15.909510.909510 lmp.py:1615] 
DEBUG 01-14 20:42:15.909510.909510 lmp.py:1615] Expert Token Distribution & Device Allocation:
DEBUG 01-14 20:42:15.909981.909981 lmp.py:1616]   Total experts: 64
DEBUG 01-14 20:42:15.909584.909584 lmp.py:1617]   CPU experts: 32 (50%)
DEBUG 01-14 20:42:15.909042.909042 lmp.py:1618]   GPU experts: 32 (50%)
DEBUG 01-14 20:42:15.909592.909592 lmp.py:1619] 
DEBUG 01-14 20:42:15.909592.909592 lmp.py:1619]   Expert ID | Tokens | Device
DEBUG 01-14 20:42:15.909381.909381 lmp.py:1620]   -----------------------------------
DEBUG 01-14 20:42:15.909746.909746 lmp.py:1625]   Expert 46 |     39 | CPU
DEBUG 01-14 20:42:15.909919.909919 lmp.py:1625]   Expert 50 |     49 | CPU
DEBUG 01-14 20:42:15.909562.909562 lmp.py:1625]   Expert  3 |     59 | CPU
DEBUG 01-14 20:42:15.909205.909205 lmp.py:1625]   Expert  1 |     83 | CPU
DEBUG 01-14 20:42:15.909610.909610 lmp.py:1625]   Expert 15 |     95 | CPU
DEBUG 01-14 20:42:15.909206.909206 lmp.py:1625]   Expert 29 |     96 | CPU
DEBUG 01-14 20:42:15.909803.909803 lmp.py:1625]   Expert  4 |     97 | CPU
DEBUG 01-14 20:42:15.909923.909923 lmp.py:1625]   Expert 40 |    104 | CPU
DEBUG 01-14 20:42:15.909758.909758 lmp.py:1625]   Expert 28 |    106 | CPU
DEBUG 01-14 20:42:15.909401.909401 lmp.py:1625]   Expert 54 |    114 | CPU
DEBUG 01-14 20:42:15.909905.909905 lmp.py:1625]   Expert  8 |    117 | CPU
DEBUG 01-14 20:42:15.909548.909548 lmp.py:1625]   Expert 41 |    120 | CPU
DEBUG 01-14 20:42:15.909429.909429 lmp.py:1625]   Expert 13 |    129 | CPU
DEBUG 01-14 20:42:15.909834.909834 lmp.py:1625]   Expert 16 |    129 | CPU
DEBUG 01-14 20:42:15.909000.909000 lmp.py:1625]   Expert 18 |    130 | CPU
DEBUG 01-14 20:42:15.909596.909596 lmp.py:1625]   Expert 51 |    133 | CPU
DEBUG 01-14 20:42:15.909147.909147 lmp.py:1625]   Expert 48 |    134 | CPU
DEBUG 01-14 20:42:15.909505.909505 lmp.py:1625]   Expert  6 |    135 | CPU
DEBUG 01-14 20:42:15.909386.909386 lmp.py:1625]   Expert  7 |    135 | CPU
DEBUG 01-14 20:42:15.909506.909506 lmp.py:1625]   Expert 60 |    138 | CPU
DEBUG 01-14 20:42:15.909864.909864 lmp.py:1625]   Expert 20 |    140 | CPU
DEBUG 01-14 20:42:15.909176.909176 lmp.py:1625]   Expert 27 |    141 | CPU
DEBUG 01-14 20:42:15.909773.909773 lmp.py:1625]   Expert 36 |    141 | CPU
DEBUG 01-14 20:42:15.909701.909701 lmp.py:1625]   Expert 52 |    141 | CPU
DEBUG 01-14 20:42:15.909867.909867 lmp.py:1625]   Expert 39 |    143 | CPU
DEBUG 01-14 20:42:15.909033.909033 lmp.py:1625]   Expert 11 |    144 | CPU
DEBUG 01-14 20:42:15.909961.909961 lmp.py:1625]   Expert 43 |    144 | CPU
DEBUG 01-14 20:42:15.909273.909273 lmp.py:1625]   Expert 62 |    154 | CPU
DEBUG 01-14 20:42:15.909154.909154 lmp.py:1625]   Expert 35 |    155 | CPU
DEBUG 01-14 20:42:15.909035.909035 lmp.py:1625]   Expert 14 |    157 | CPU
DEBUG 01-14 20:42:15.909394.909394 lmp.py:1625]   Expert 56 |    159 | CPU
DEBUG 01-14 20:42:15.909037.909037 lmp.py:1625]   Expert 45 |    163 | CPU
DEBUG 01-14 20:42:15.909441.909441 lmp.py:1625]   Expert  5 |    168 | GPU
DEBUG 01-14 20:42:15.909515.909515 lmp.py:1625]   Expert 55 |    169 | GPU
DEBUG 01-14 20:42:15.909204.909204 lmp.py:1625]   Expert 10 |    173 | GPU
DEBUG 01-14 20:42:15.909370.909370 lmp.py:1625]   Expert 44 |    180 | GPU
DEBUG 01-14 20:42:15.910298.910298 lmp.py:1625]   Expert 25 |    182 | GPU
DEBUG 01-14 20:42:15.910987.910987 lmp.py:1625]   Expert 31 |    183 | GPU
DEBUG 01-14 20:42:15.910107.910107 lmp.py:1625]   Expert 57 |    183 | GPU
DEBUG 01-14 20:42:15.910704.910704 lmp.py:1625]   Expert 58 |    185 | GPU
DEBUG 01-14 20:42:15.910823.910823 lmp.py:1625]   Expert 33 |    189 | GPU
DEBUG 01-14 20:42:15.910182.910182 lmp.py:1625]   Expert 32 |    190 | GPU
DEBUG 01-14 20:42:15.910301.910301 lmp.py:1625]   Expert  2 |    194 | GPU
DEBUG 01-14 20:42:15.910944.910944 lmp.py:1625]   Expert 53 |    198 | GPU
DEBUG 01-14 20:42:15.910349.910349 lmp.py:1625]   Expert 21 |    200 | GPU
DEBUG 01-14 20:42:15.910422.910422 lmp.py:1625]   Expert 17 |    201 | GPU
DEBUG 01-14 20:42:15.910065.910065 lmp.py:1625]   Expert 49 |    210 | GPU
DEBUG 01-14 20:42:15.910232.910232 lmp.py:1625]   Expert 59 |    215 | GPU
DEBUG 01-14 20:42:15.910875.910875 lmp.py:1625]   Expert 63 |    220 | GPU
DEBUG 01-14 20:42:15.910279.910279 lmp.py:1625]   Expert  0 |    224 | GPU
DEBUG 01-14 20:42:15.910353.910353 lmp.py:1625]   Expert 37 |    242 | GPU
DEBUG 01-14 20:42:15.910757.910757 lmp.py:1625]   Expert 34 |    244 | GPU
DEBUG 01-14 20:42:15.910115.910115 lmp.py:1625]   Expert 42 |    246 | GPU
DEBUG 01-14 20:42:15.910474.910474 lmp.py:1625]   Expert 22 |    255 | GPU
DEBUG 01-14 20:42:15.910355.910355 lmp.py:1625]   Expert 19 |    256 | GPU
DEBUG 01-14 20:42:15.910760.910760 lmp.py:1625]   Expert 24 |    275 | GPU
DEBUG 01-14 20:42:15.910641.910641 lmp.py:1625]   Expert 61 |    280 | GPU
DEBUG 01-14 20:42:15.910999.910999 lmp.py:1625]   Expert 30 |    316 | GPU
DEBUG 01-14 20:42:15.910119.910119 lmp.py:1625]   Expert 47 |    325 | GPU
DEBUG 01-14 20:42:15.910808.910808 lmp.py:1625]   Expert 38 |    378 | GPU
DEBUG 01-14 20:42:15.910974.910974 lmp.py:1625]   Expert 26 |    394 | GPU
DEBUG 01-14 20:42:15.910141.910141 lmp.py:1625]   Expert 12 |    402 | GPU
DEBUG 01-14 20:42:15.910545.910545 lmp.py:1625]   Expert 23 |    592 | GPU
DEBUG 01-14 20:42:15.910234.910234 lmp.py:1625]   Expert  9 |    695 | GPU
DEBUG 01-14 20:42:15.910546.910546 lmp.py:1626] 
DEBUG 01-14 20:42:15.910546.910546 lmp.py:1626]   CPU total tokens: 3924 (31.9%)
DEBUG 01-14 20:42:15.910381.910381 lmp.py:1627]   GPU total tokens: 8364 (68.1%)
DEBUG 01-14 20:42:15.910746.910746 cuda_h.py:19] end experts_map_get cost 0.0016036033630371094 seconds
DEBUG 01-14 20:42:15.910080.910080 mlpmodule.py:1367]  experts func einsum cost 0.07400679588317871 s
DEBUG 01-14 20:42:15.910202.910202 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-14 20:42:15.910589.910589 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-14 20:42:15.910209.910209 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-14 20:42:15.912134.912134 cuda_h.py:19] end allocate_cuda_memory cost 0.0018756389617919922 seconds
DEBUG 01-14 20:42:15.912243.912243 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-14 20:42:15.912383.912383 sllm_store_c.py:27] get device uuid map
DEBUG 01-14 20:42:15.912437.912437 sllm_store_c.py:29] call client load into gpu
DEBUG 01-14 20:42:15.913187.913187 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 41fe6593-0516-4022-b70a-80972f239d03
DEBUG 01-14 20:42:15.913882.913882 client.py:106] call stub.LoadModelAsync
INFO 01-14 20:42:15.913048.913048 client.py:127] Model loaded
DEBUG 01-14 20:42:15.913183.913183 cuda_h.py:10] start restore2model
DEBUG 01-14 20:42:15.913609.913609 cuda_h.py:19] end restore2model cost 0.0004143714904785156 seconds
DEBUG 01-14 20:42:15.914723.914723 cuda_h.py:19] end sllm_worker_task cost 0.016684532165527344 seconds
INFO 01-14 20:42:15.914173.914173 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 41fe6593-0516-4022-b70a-80972f239d03
DEBUG 01-14 20:42:15.914262.914262 cuda_h.py:19] end load_into_gpu_async cost 0.0013127326965332031 seconds
DEBUG 01-14 20:42:15.914256.914256 cuda_h.py:10] start restore_tensors2
DEBUG 01-14 20:42:15.914943.914943 cuda_h.py:19] end restore_tensors2 cost 0.00030350685119628906 seconds
DEBUG 01-14 20:42:15.914865.914865 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0038640499114990234 seconds
DEBUG 01-14 20:42:15.914820.914820 cuda_h.py:10] start restore2model
DEBUG 01-14 20:42:15.917229.917229 cuda_h.py:19] end restore2model cost 0.0025191307067871094 seconds
DEBUG 01-14 20:42:15.917112.917112 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.006560802459716797 seconds
DEBUG 01-14 20:42:15.917861.917861 cuda_h.py:10] start gpu_sexperts
DEBUG 01-14 20:42:15.917958.917958 cuda_h.py:19] end gpu_sexperts cost 0.0002865791320800781 seconds
DEBUG 01-14 20:42:15.917734.917734 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-14 20:42:15.917629.917629 lmp.py:1683] 
DEBUG 01-14 20:42:15.917629.917629 lmp.py:1683]   Computing 32 experts on CPU...
DEBUG 01-14 20:42:15.917750.917750 cuda_h.py:19] end cpu_experts_submit cost 5.4836273193359375e-05 seconds
DEBUG 01-14 20:42:15.917307.917307 cuda_h.py:10] start experts_func_mgpu_group_pad
DEBUG 01-14 20:42:15.922936.922936 mlpmodule.py:1460] group tensors cost 0.00429534912109375 s
DEBUG 01-14 20:42:15.922030.922030 cuda_h.py:10] start move_flat_hidden2cpu
DEBUG 01-14 20:42:15.925550.925550 cuda_h.py:19] end experts_func_mgpu_group_pad cost 0.007122039794921875 seconds
DEBUG 01-14 20:42:15.926099.926099 cuda_h.py:10] start gpu_group_list
DEBUG 01-14 20:42:15.926341.926341 cuda_h.py:19] end gpu_group_list cost 0.00042700767517089844 seconds
DEBUG 01-14 20:42:15.926611.926611 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-14 20:42:15.926706.926706 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 1.71661376953125e-05 seconds
DEBUG 01-14 20:42:15.926793.926793 cuda_h.py:10] start wait_experts
INFO 01-14 20:42:15.927311.927311 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 41fe6593-0516-4022-b70a-80972f239d03
DEBUG 01-14 20:42:15.930225.930225 cuda_h.py:19] end move_flat_hidden2cpu cost 0.007102489471435547 seconds
DEBUG 01-14 20:42:15.934990.934990 mlpmodule.py:1533] pad cost 0.004183292388916016 s
DEBUG 01-14 20:42:15.934732.934732 mlpmodule.py:1539] create cpu tensor cost 7.414817810058594e-05 s
DEBUG 01-14 20:42:15.936382.936382 mlpmodule.py:1544] move to cpu cost 0.001954793930053711 s
DEBUG 01-14 20:42:15.944918.944918 mlpmodule.py:1558] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-14 20:42:15.944101.944101 mlpmodule.py:1559] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-14 20:42:15.944177.944177 mlpmodule.py:1564] group_w3 first element: 0.01263427734375
WARNING 01-14 20:42:15.945101.945101 mlpmodule.py:1574] start einsum2
DEBUG 01-14 20:42:15.958964.958964 mlpmodule.py:1584] group einsum cost 0.022020816802978516 s
DEBUG 01-14 20:42:15.959085.959085 mlpmodule.py:1593] cpy2cputensor cost 0.0006330013275146484 s
DEBUG 01-14 20:42:15.959431.959431 cuda_h.py:10] start move_outputs
DEBUG 01-14 20:42:15.962511.962511 cuda_h.py:19] end move_outputs cost 0.0025565624237060547 seconds
INFO 01-14 20:42:15.970803.970803 client.py:127] Model loaded
DEBUG 01-14 20:42:15.970943.970943 cuda_h.py:19] end wait_experts cost 0.043383121490478516 seconds
DEBUG 01-14 20:42:15.970448.970448 cuda_h.py:10] start gpu_experts
DEBUG 01-14 20:42:15.970602.970602 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-14 20:42:15.970973.970973 cuda_h.py:19] end wait_cetm_experts cost 0.00017309188842773438 seconds
DEBUG 01-14 20:42:15.970976.970976 cuda_h.py:10] start gpu_group_einsum_mp_multi_list
DEBUG 01-14 20:42:15.970685.970685 cuda_h.py:10] start gpu_group_tensor
DEBUG 01-14 20:42:15.971860.971860 cuda_h.py:19] end gpu_group_tensor cost 0.00023794174194335938 seconds
DEBUG 01-14 20:42:15.971692.971692 cuda_h.py:10] start gpu_group_einsum
DEBUG 01-14 20:42:15.971669.971669 cuda_h.py:19] end gpu_group_einsum cost 0.0006651878356933594 seconds
DEBUG 01-14 20:42:15.972019.972019 cuda_h.py:10] start gpu_final_hidden_states_scatter
DEBUG 01-14 20:42:15.972419.972419 cuda_h.py:10] start all_expert_outputs_slices
DEBUG 01-14 20:42:15.972195.972195 cuda_h.py:19] end all_expert_outputs_slices cost 0.00038743019104003906 seconds
DEBUG 01-14 20:42:15.972097.972097 cuda_h.py:10] start concat_expert_out
DEBUG 01-14 20:42:15.972140.972140 cuda_h.py:19] end concat_expert_out cost 6.437301635742188e-05 seconds
DEBUG 01-14 20:42:15.972851.972851 cuda_h.py:10] start index_scatter
DEBUG 01-14 20:42:15.972331.972331 cuda_h.py:19] end index_scatter cost 7.486343383789062e-05 seconds
DEBUG 01-14 20:42:15.972902.972902 cuda_h.py:19] end gpu_final_hidden_states_scatter cost 0.0007987022399902344 seconds
DEBUG 01-14 20:42:15.973971.973971 cuda_h.py:19] end gpu_experts cost 0.002532958984375 seconds
DEBUG 01-14 20:42:15.973581.973581 cuda_h.py:10] start all_expert_weight_slices
DEBUG 01-14 20:42:15.974640.974640 cuda_h.py:19] end all_expert_weight_slices cost 0.0009243488311767578 seconds
DEBUG 01-14 20:42:15.974648.974648 cuda_h.py:10] start cpuoutputsdeal
DEBUG 01-14 20:42:15.974855.974855 cuda_h.py:10] start index_scatter
DEBUG 01-14 20:42:15.974467.974467 cuda_h.py:19] end index_scatter cost 4.982948303222656e-05 seconds
DEBUG 01-14 20:42:15.974899.974899 cuda_h.py:19] end cpuoutputsdeal cost 0.0005428791046142578 seconds
DEBUG 01-14 20:42:15.974093.974093 cuda_h.py:19] end layer_moe_generate_mp_l_8 cost 0.06655192375183105 seconds
DEBUG 01-14 20:42:15.975753.975753 cuda_h.py:19] end prefill_layer cost 0.0781095027923584 seconds
DEBUG 01-14 20:42:15.975152.975152 lmp.py:1551] -------------------------------- end prefill layer 7 --------------------------------
DEBUG 01-14 20:42:15.975994.975994 cuda_h.py:10] start prefill_layer
DEBUG 01-14 20:42:15.975597.975597 lmp.py:1494] -------------------------------- start prefill layer 8 --------------------------------
DEBUG 01-14 20:42:15.975585.975585 cuda_h.py:10] start start_load_qkvogn_s_weight_l_9
DEBUG 01-14 20:42:15.975619.975619 cuda_h.py:10] start start_load_qkvogn_s_weight_l_9
DEBUG 01-14 20:42:15.975131.975131 cuda_h.py:19] end start_load_qkvogn_s_weight_l_9 cost 3.337860107421875e-05 seconds
DEBUG 01-14 20:42:15.975072.975072 cuda_h.py:19] end start_load_qkvogn_s_weight_l_9 cost 6.389617919921875e-05 seconds
DEBUG 01-14 20:42:15.975576.975576 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-14 20:42:15.975757.975757 cuda_h.py:10] start sllm_worker_task
DEBUG 01-14 20:42:15.975449.975449 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-14 20:42:15.975755.975755 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-14 20:42:15.976982.976982 cuda_h.py:19] end allocate_cuda_memory cost 0.0010042190551757812 seconds
DEBUG 01-14 20:42:15.976814.976814 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-14 20:42:15.976180.976180 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-14 20:42:15.976523.976523 sllm_store_c.py:27] get device uuid map
DEBUG 01-14 20:42:15.976067.976067 sllm_store_c.py:29] call client load into gpu
DEBUG 01-14 20:42:15.976678.976678 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 30266ee4-d603-4914-996a-5ed888dcad67
DEBUG 01-14 20:42:15.977177.977177 client.py:106] call stub.LoadModelAsync
DEBUG 01-14 20:42:15.977620.977620 cuda_h.py:10] start self_attn
INFO 01-14 20:42:15.977725.977725 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 30266ee4-d603-4914-996a-5ed888dcad67
DEBUG 01-14 20:42:15.978992.978992 cuda_h.py:19] end load_into_gpu_async cost 0.0011544227600097656 seconds
DEBUG 01-14 20:42:15.978741.978741 cuda_h.py:10] start restore_tensors2
DEBUG 01-14 20:42:15.978830.978830 cuda_h.py:19] end restore_tensors2 cost 7.367134094238281e-05 seconds
DEBUG 01-14 20:42:15.978348.978348 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0027053356170654297 seconds
INFO 01-14 20:42:15.978105.978105 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 30266ee4-d603-4914-996a-5ed888dcad67
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-14 20:42:15.980124.980124 cuda_h.py:19] end self_attn cost 0.002925872802734375 seconds
DEBUG 01-14 20:42:15.980195.980195 cuda_h.py:19] end iln_self_attn_paln cost 0.005411624908447266 seconds
DEBUG 01-14 20:42:15.980038.980038 cuda_h.py:10] start layer_moe_generate_mp_l_9
DEBUG 01-14 20:42:15.980278.980278 cuda_h.py:10] start gate
DEBUG 01-14 20:42:15.981201.981201 cuda_h.py:19] end gate cost 0.0006449222564697266 seconds
DEBUG 01-14 20:42:15.981839.981839 cuda_h.py:10] start experts_map_get
DEBUG 01-14 20:42:15.981538.981538 lmp.py:1615] 
DEBUG 01-14 20:42:15.981538.981538 lmp.py:1615] Expert Token Distribution & Device Allocation:
DEBUG 01-14 20:42:15.981678.981678 lmp.py:1616]   Total experts: 64
DEBUG 01-14 20:42:15.981043.981043 lmp.py:1617]   CPU experts: 32 (50%)
DEBUG 01-14 20:42:15.981315.981315 lmp.py:1618]   GPU experts: 32 (50%)
DEBUG 01-14 20:42:15.981296.981296 lmp.py:1619] 
DEBUG 01-14 20:42:15.981296.981296 lmp.py:1619]   Expert ID | Tokens | Device
DEBUG 01-14 20:42:15.981462.981462 lmp.py:1620]   -----------------------------------
DEBUG 01-14 20:42:15.981820.981820 lmp.py:1625]   Expert 38 |     19 | CPU
DEBUG 01-14 20:42:15.982987.982987 lmp.py:1625]   Expert 39 |     61 | CPU
DEBUG 01-14 20:42:15.982153.982153 lmp.py:1625]   Expert 30 |     69 | CPU
DEBUG 01-14 20:42:15.982657.982657 lmp.py:1625]   Expert 59 |     73 | CPU
DEBUG 01-14 20:42:15.982399.982399 lmp.py:1625]   Expert  7 |     77 | CPU
DEBUG 01-14 20:42:15.982473.982473 lmp.py:1625]   Expert 36 |     93 | CPU
DEBUG 01-14 20:42:15.982069.982069 lmp.py:1625]   Expert 40 |     94 | CPU
DEBUG 01-14 20:42:15.982381.982381 lmp.py:1625]   Expert 24 |     96 | CPU
DEBUG 01-14 20:42:15.982932.982932 lmp.py:1625]   Expert 27 |     97 | CPU
DEBUG 01-14 20:42:15.982243.982243 lmp.py:1625]   Expert 17 |    100 | CPU
DEBUG 01-14 20:42:15.982940.982940 lmp.py:1625]   Expert 14 |    101 | CPU
DEBUG 01-14 20:42:15.982490.982490 lmp.py:1625]   Expert 12 |    105 | CPU
DEBUG 01-14 20:42:15.982802.982802 lmp.py:1625]   Expert  6 |    109 | CPU
DEBUG 01-14 20:42:15.982637.982637 lmp.py:1625]   Expert 18 |    109 | CPU
DEBUG 01-14 20:42:15.982710.982710 lmp.py:1625]   Expert  1 |    116 | CPU
DEBUG 01-14 20:42:15.982168.982168 lmp.py:1625]   Expert 16 |    117 | CPU
DEBUG 01-14 20:42:15.982480.982480 lmp.py:1625]   Expert 48 |    120 | CPU
DEBUG 01-14 20:42:15.982792.982792 lmp.py:1625]   Expert 32 |    125 | CPU
DEBUG 01-14 20:42:15.982388.982388 lmp.py:1625]   Expert 51 |    141 | CPU
DEBUG 01-14 20:42:15.982462.982462 lmp.py:1625]   Expert  0 |    146 | CPU
DEBUG 01-14 20:42:15.982443.982443 lmp.py:1625]   Expert 44 |    147 | CPU
DEBUG 01-14 20:42:15.982516.982516 lmp.py:1625]   Expert  8 |    160 | CPU
DEBUG 01-14 20:42:15.982113.982113 lmp.py:1625]   Expert 53 |    161 | CPU
DEBUG 01-14 20:42:15.982710.982710 lmp.py:1625]   Expert 35 |    166 | CPU
DEBUG 01-14 20:42:15.982306.982306 lmp.py:1625]   Expert 42 |    169 | CPU
DEBUG 01-14 20:42:15.982380.982380 lmp.py:1625]   Expert 22 |    170 | CPU
DEBUG 01-14 20:42:15.982407.982407 lmp.py:1625]   Expert 60 |    173 | CPU
DEBUG 01-14 20:42:15.982242.982242 lmp.py:1625]   Expert 34 |    174 | CPU
DEBUG 01-14 20:42:15.982362.982362 lmp.py:1625]   Expert 33 |    186 | CPU
DEBUG 01-14 20:42:15.982197.982197 lmp.py:1625]   Expert 29 |    188 | CPU
DEBUG 01-14 20:42:15.982555.982555 lmp.py:1625]   Expert 45 |    188 | CPU
DEBUG 01-14 20:42:15.982059.982059 lmp.py:1625]   Expert 19 |    189 | CPU
DEBUG 01-14 20:42:15.982431.982431 lmp.py:1625]   Expert 49 |    190 | GPU
DEBUG 01-14 20:42:15.982266.982266 lmp.py:1625]   Expert 15 |    194 | GPU
DEBUG 01-14 20:42:15.982863.982863 lmp.py:1625]   Expert 54 |    194 | GPU
DEBUG 01-14 20:42:15.982698.982698 lmp.py:1625]   Expert 47 |    197 | GPU
DEBUG 01-14 20:42:15.982632.982632 lmp.py:1625]   Expert  9 |    203 | GPU
DEBUG 01-14 20:42:15.982229.982229 lmp.py:1625]   Expert 28 |    203 | GPU
DEBUG 01-14 20:42:15.982587.982587 lmp.py:1625]   Expert 56 |    203 | GPU
DEBUG 01-14 20:42:15.982137.982137 lmp.py:1625]   Expert 21 |    206 | GPU
DEBUG 01-14 20:42:15.982257.982257 lmp.py:1625]   Expert  3 |    209 | GPU
DEBUG 01-14 20:42:15.982615.982615 lmp.py:1625]   Expert 20 |    211 | GPU
DEBUG 01-14 20:42:15.982927.982927 lmp.py:1625]   Expert 13 |    213 | GPU
DEBUG 01-14 20:42:15.982286.982286 lmp.py:1625]   Expert 57 |    215 | GPU
DEBUG 01-14 20:42:15.982790.982790 lmp.py:1625]   Expert 10 |    217 | GPU
DEBUG 01-14 20:42:15.982148.982148 lmp.py:1625]   Expert 46 |    217 | GPU
DEBUG 01-14 20:42:15.982506.982506 lmp.py:1625]   Expert 41 |    218 | GPU
DEBUG 01-14 20:42:15.982864.982864 lmp.py:1625]   Expert  4 |    221 | GPU
DEBUG 01-14 20:42:15.982222.982222 lmp.py:1625]   Expert 43 |    223 | GPU
DEBUG 01-14 20:42:15.982726.982726 lmp.py:1625]   Expert 63 |    228 | GPU
DEBUG 01-14 20:42:15.982277.982277 lmp.py:1625]   Expert 37 |    232 | GPU
DEBUG 01-14 20:42:15.982589.982589 lmp.py:1625]   Expert  2 |    233 | GPU
DEBUG 01-14 20:42:15.983947.983947 lmp.py:1625]   Expert 50 |    250 | GPU
DEBUG 01-14 20:42:15.983113.983113 lmp.py:1625]   Expert 61 |    263 | GPU
DEBUG 01-14 20:42:15.983902.983902 lmp.py:1625]   Expert 26 |    264 | GPU
DEBUG 01-14 20:42:15.983306.983306 lmp.py:1625]   Expert 31 |    276 | GPU
DEBUG 01-14 20:42:15.983380.983380 lmp.py:1625]   Expert 58 |    279 | GPU
DEBUG 01-14 20:42:15.983784.983784 lmp.py:1625]   Expert 62 |    305 | GPU
DEBUG 01-14 20:42:15.983381.983381 lmp.py:1625]   Expert 52 |    306 | GPU
DEBUG 01-14 20:42:15.983309.983309 lmp.py:1625]   Expert 55 |    341 | GPU
DEBUG 01-14 20:42:15.983813.983813 lmp.py:1625]   Expert 11 |    373 | GPU
DEBUG 01-14 20:42:15.983740.983740 lmp.py:1625]   Expert 23 |    414 | GPU
DEBUG 01-14 20:42:15.983337.983337 lmp.py:1625]   Expert 25 |    434 | GPU
DEBUG 01-14 20:42:15.983742.983742 lmp.py:1625]   Expert  5 |    517 | GPU
DEBUG 01-14 20:42:15.983292.983292 lmp.py:1626] 
DEBUG 01-14 20:42:15.983292.983292 lmp.py:1626]   CPU total tokens: 4039 (32.9%)
DEBUG 01-14 20:42:15.983796.983796 lmp.py:1627]   GPU total tokens: 8249 (67.1%)
DEBUG 01-14 20:42:15.983353.983353 cuda_h.py:19] end experts_map_get cost 0.0016825199127197266 seconds
DEBUG 01-14 20:42:15.983197.983197 mlpmodule.py:1367]  experts func einsum cost 0.06530475616455078 s
DEBUG 01-14 20:42:15.983009.983009 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-14 20:42:15.983691.983691 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-14 20:42:15.983080.983080 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-14 20:42:15.984075.984075 cuda_h.py:19] end allocate_cuda_memory cost 0.0006260871887207031 seconds
DEBUG 01-14 20:42:15.984561.984561 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-14 20:42:15.984178.984178 sllm_store_c.py:27] get device uuid map
DEBUG 01-14 20:42:15.984372.984372 sllm_store_c.py:29] call client load into gpu
DEBUG 01-14 20:42:15.984214.984214 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, d4af715d-d296-4db7-8737-0a36287bb705
DEBUG 01-14 20:42:15.984326.984326 client.py:106] call stub.LoadModelAsync
INFO 01-14 20:42:15.986061.986061 client.py:127] Model loaded
DEBUG 01-14 20:42:15.986840.986840 cuda_h.py:10] start restore2model
INFO 01-14 20:42:15.986607.986607 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, d4af715d-d296-4db7-8737-0a36287bb705
DEBUG 01-14 20:42:15.986119.986119 cuda_h.py:19] end load_into_gpu_async cost 0.0023767948150634766 seconds
DEBUG 01-14 20:42:15.986252.986252 cuda_h.py:10] start restore_tensors2
DEBUG 01-14 20:42:15.987052.987052 cuda_h.py:19] end restore_tensors2 cost 0.0003159046173095703 seconds
DEBUG 01-14 20:42:15.987974.987974 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0036919116973876953 seconds
DEBUG 01-14 20:42:15.987790.987790 cuda_h.py:10] start restore2model
DEBUG 01-14 20:42:15.988156.988156 cuda_h.py:19] end restore2model cost 0.0006246566772460938 seconds
DEBUG 01-14 20:42:15.988610.988610 cuda_h.py:19] end sllm_worker_task cost 0.012734413146972656 seconds
DEBUG 01-14 20:42:15.990938.990938 cuda_h.py:19] end restore2model cost 0.002989530563354492 seconds
DEBUG 01-14 20:42:15.990119.990119 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.006881237030029297 seconds
DEBUG 01-14 20:42:15.990365.990365 cuda_h.py:10] start gpu_sexperts
DEBUG 01-14 20:42:15.990276.990276 cuda_h.py:19] end gpu_sexperts cost 0.00028777122497558594 seconds
DEBUG 01-14 20:42:15.990483.990483 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-14 20:42:15.990617.990617 lmp.py:1683] 
DEBUG 01-14 20:42:15.990617.990617 lmp.py:1683]   Computing 32 experts on CPU...
DEBUG 01-14 20:42:15.990506.990506 cuda_h.py:19] end cpu_experts_submit cost 5.888938903808594e-05 seconds
DEBUG 01-14 20:42:15.991878.991878 cuda_h.py:10] start experts_func_mgpu_group_pad
DEBUG 01-14 20:42:16.000065.000065 mlpmodule.py:1460] group tensors cost 0.00916433334350586 s
DEBUG 01-14 20:42:16.001856.001856 cuda_h.py:10] start move_flat_hidden2cpu
DEBUG 01-14 20:42:16.005155.005155 cuda_h.py:19] end experts_func_mgpu_group_pad cost 0.01415705680847168 seconds
DEBUG 01-14 20:42:16.007056.007056 cuda_h.py:10] start gpu_group_list
DEBUG 01-14 20:42:16.007501.007501 cuda_h.py:19] end gpu_group_list cost 0.00055694580078125 seconds
DEBUG 01-14 20:42:16.007086.007086 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-14 20:42:16.008673.008673 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 3.409385681152344e-05 seconds
DEBUG 01-14 20:42:16.008257.008257 cuda_h.py:10] start wait_experts
INFO 01-14 20:42:16.008696.008696 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, d4af715d-d296-4db7-8737-0a36287bb705
DEBUG 01-14 20:42:16.009278.009278 cuda_h.py:19] end move_flat_hidden2cpu cost 0.007970809936523438 seconds
DEBUG 01-14 20:42:16.010133.010133 mlpmodule.py:1533] pad cost 0.0015037059783935547 s
DEBUG 01-14 20:42:16.011931.011931 mlpmodule.py:1539] create cpu tensor cost 3.528594970703125e-05 s
DEBUG 01-14 20:42:16.013775.013775 mlpmodule.py:1544] move to cpu cost 0.0022363662719726562 s
DEBUG 01-14 20:42:16.021732.021732 mlpmodule.py:1558] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-14 20:42:16.021915.021915 mlpmodule.py:1559] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-14 20:42:16.021984.021984 mlpmodule.py:1564] group_w3 first element: 0.0859375
WARNING 01-14 20:42:16.021730.021730 mlpmodule.py:1574] start einsum2
DEBUG 01-14 20:42:16.037940.037940 mlpmodule.py:1584] group einsum cost 0.02381157875061035 s
DEBUG 01-14 20:42:16.038798.038798 mlpmodule.py:1593] cpy2cputensor cost 0.0007190704345703125 s
DEBUG 01-14 20:42:16.038429.038429 cuda_h.py:10] start move_outputs
DEBUG 01-14 20:42:16.041149.041149 cuda_h.py:19] end move_outputs cost 0.0028867721557617188 seconds
INFO 01-14 20:42:16.042150.042150 client.py:127] Model loaded
DEBUG 01-14 20:42:16.042144.042144 cuda_h.py:19] end wait_experts cost 0.03472089767456055 seconds
DEBUG 01-14 20:42:16.042682.042682 cuda_h.py:10] start gpu_experts
DEBUG 01-14 20:42:16.042412.042412 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-14 20:42:16.045590.045590 cuda_h.py:19] end wait_cetm_experts cost 0.002128124237060547 seconds
DEBUG 01-14 20:42:16.045851.045851 cuda_h.py:10] start gpu_group_einsum_mp_multi_list
DEBUG 01-14 20:42:16.045945.045945 cuda_h.py:10] start gpu_group_tensor
DEBUG 01-14 20:42:16.045173.045173 cuda_h.py:19] end gpu_group_tensor cost 0.00024127960205078125 seconds
DEBUG 01-14 20:42:16.045005.045005 cuda_h.py:10] start gpu_group_einsum
DEBUG 01-14 20:42:16.046128.046128 cuda_h.py:19] end gpu_group_einsum cost 0.0006711483001708984 seconds
DEBUG 01-14 20:42:16.046133.046133 cuda_h.py:10] start gpu_final_hidden_states_scatter
DEBUG 01-14 20:42:16.046420.046420 cuda_h.py:10] start all_expert_outputs_slices
DEBUG 01-14 20:42:16.046540.046540 cuda_h.py:19] end all_expert_outputs_slices cost 0.0003552436828613281 seconds
DEBUG 01-14 20:42:16.047342.047342 cuda_h.py:10] start concat_expert_out
DEBUG 01-14 20:42:16.047518.047518 cuda_h.py:19] end concat_expert_out cost 5.745887756347656e-05 seconds
DEBUG 01-14 20:42:16.047083.047083 cuda_h.py:10] start index_scatter
DEBUG 01-14 20:42:16.047133.047133 cuda_h.py:19] end index_scatter cost 7.271766662597656e-05 seconds
DEBUG 01-14 20:42:16.047585.047585 cuda_h.py:19] end gpu_final_hidden_states_scatter cost 0.0007722377777099609 seconds
DEBUG 01-14 20:42:16.047077.047077 cuda_h.py:19] end gpu_experts cost 0.0044727325439453125 seconds
DEBUG 01-14 20:42:16.047403.047403 cuda_h.py:10] start all_expert_weight_slices
DEBUG 01-14 20:42:16.048284.048284 cuda_h.py:19] end all_expert_weight_slices cost 0.0009684562683105469 seconds
DEBUG 01-14 20:42:16.048776.048776 cuda_h.py:10] start cpuoutputsdeal
DEBUG 01-14 20:42:16.048976.048976 cuda_h.py:10] start index_scatter
DEBUG 01-14 20:42:16.049774.049774 cuda_h.py:19] end index_scatter cost 4.792213439941406e-05 seconds
DEBUG 01-14 20:42:16.049113.049113 cuda_h.py:19] end cpuoutputsdeal cost 0.0005347728729248047 seconds
DEBUG 01-14 20:42:16.049738.049738 cuda_h.py:19] end layer_moe_generate_mp_l_9 cost 0.06831955909729004 seconds
DEBUG 01-14 20:42:16.049365.049365 cuda_h.py:19] end prefill_layer cost 0.07436847686767578 seconds
DEBUG 01-14 20:42:16.049241.049241 lmp.py:1551] -------------------------------- end prefill layer 8 --------------------------------
DEBUG 01-14 20:42:16.049659.049659 cuda_h.py:10] start prefill_layer
DEBUG 01-14 20:42:16.049554.049554 lmp.py:1494] -------------------------------- start prefill layer 9 --------------------------------
DEBUG 01-14 20:42:16.049926.049926 cuda_h.py:10] start start_load_qkvogn_s_weight_l_10
DEBUG 01-14 20:42:16.049490.049490 cuda_h.py:10] start start_load_qkvogn_s_weight_l_10
DEBUG 01-14 20:42:16.049102.049102 cuda_h.py:19] end start_load_qkvogn_s_weight_l_10 cost 3.719329833984375e-05 seconds
DEBUG 01-14 20:42:16.049010.049010 cuda_h.py:19] end start_load_qkvogn_s_weight_l_10 cost 7.700920104980469e-05 seconds
DEBUG 01-14 20:42:16.049806.049806 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-14 20:42:16.049239.049239 cuda_h.py:10] start sllm_worker_task
DEBUG 01-14 20:42:16.049263.049263 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-14 20:42:16.050856.050856 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-14 20:42:16.050905.050905 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-14 20:42:16.051927.051927 cuda_h.py:19] end allocate_cuda_memory cost 0.0007176399230957031 seconds
DEBUG 01-14 20:42:16.051698.051698 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-14 20:42:16.051845.051845 sllm_store_c.py:27] get device uuid map
DEBUG 01-14 20:42:16.051827.051827 sllm_store_c.py:29] call client load into gpu
DEBUG 01-14 20:42:16.051536.051536 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 4800530d-6ced-49fa-9a65-412525bd4125
DEBUG 01-14 20:42:16.051149.051149 client.py:106] call stub.LoadModelAsync
DEBUG 01-14 20:42:16.051605.051605 cuda_h.py:10] start self_attn
INFO 01-14 20:42:16.052263.052263 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 4800530d-6ced-49fa-9a65-412525bd4125
DEBUG 01-14 20:42:16.052351.052351 cuda_h.py:19] end load_into_gpu_async cost 0.001074075698852539 seconds
DEBUG 01-14 20:42:16.052153.052153 cuda_h.py:10] start restore_tensors2
DEBUG 01-14 20:42:16.052071.052071 cuda_h.py:19] end restore_tensors2 cost 8.368492126464844e-05 seconds
DEBUG 01-14 20:42:16.052702.052702 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0022666454315185547 seconds
INFO 01-14 20:42:16.052771.052771 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 4800530d-6ced-49fa-9a65-412525bd4125
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-14 20:42:16.054668.054668 cuda_h.py:19] end self_attn cost 0.0029876232147216797 seconds
DEBUG 01-14 20:42:16.055374.055374 cuda_h.py:19] end iln_self_attn_paln cost 0.005264759063720703 seconds
DEBUG 01-14 20:42:16.055502.055502 cuda_h.py:10] start layer_moe_generate_mp_l_10
DEBUG 01-14 20:42:16.055563.055563 cuda_h.py:10] start gate
DEBUG 01-14 20:42:16.055507.055507 cuda_h.py:19] end gate cost 0.0006575584411621094 seconds
DEBUG 01-14 20:42:16.055290.055290 cuda_h.py:10] start experts_map_get
DEBUG 01-14 20:42:16.056519.056519 lmp.py:1615] 
DEBUG 01-14 20:42:16.056519.056519 lmp.py:1615] Expert Token Distribution & Device Allocation:
DEBUG 01-14 20:42:16.056897.056897 lmp.py:1616]   Total experts: 64
DEBUG 01-14 20:42:16.056262.056262 lmp.py:1617]   CPU experts: 32 (50%)
DEBUG 01-14 20:42:16.056528.056528 lmp.py:1618]   GPU experts: 32 (50%)
DEBUG 01-14 20:42:16.056932.056932 lmp.py:1619] 
DEBUG 01-14 20:42:16.056932.056932 lmp.py:1619]   Expert ID | Tokens | Device
DEBUG 01-14 20:42:16.056860.056860 lmp.py:1620]   -----------------------------------
DEBUG 01-14 20:42:16.056980.056980 lmp.py:1625]   Expert 24 |     42 | CPU
DEBUG 01-14 20:42:16.056518.056518 lmp.py:1625]   Expert  2 |     43 | CPU
DEBUG 01-14 20:42:16.056757.056757 lmp.py:1625]   Expert 26 |     68 | CPU
DEBUG 01-14 20:42:16.056930.056930 lmp.py:1625]   Expert 23 |     71 | CPU
DEBUG 01-14 20:42:16.056865.056865 lmp.py:1625]   Expert 32 |     71 | CPU
DEBUG 01-14 20:42:16.056077.056077 lmp.py:1625]   Expert 19 |     74 | CPU
DEBUG 01-14 20:42:16.056528.056528 lmp.py:1625]   Expert  4 |     75 | CPU
DEBUG 01-14 20:42:16.056502.056502 lmp.py:1625]   Expert 50 |     77 | CPU
DEBUG 01-14 20:42:16.056715.056715 lmp.py:1625]   Expert 59 |     81 | CPU
DEBUG 01-14 20:42:16.056100.056100 lmp.py:1625]   Expert 60 |     89 | CPU
DEBUG 01-14 20:42:16.056174.056174 lmp.py:1625]   Expert 28 |     90 | CPU
DEBUG 01-14 20:42:16.056625.056625 lmp.py:1625]   Expert  7 |    101 | CPU
DEBUG 01-14 20:42:16.056599.056599 lmp.py:1625]   Expert 15 |    102 | CPU
DEBUG 01-14 20:42:16.056811.056811 lmp.py:1625]   Expert 49 |    108 | CPU
DEBUG 01-14 20:42:16.056785.056785 lmp.py:1625]   Expert 27 |    109 | CPU
DEBUG 01-14 20:42:16.056759.056759 lmp.py:1625]   Expert 10 |    110 | CPU
DEBUG 01-14 20:42:16.056733.056733 lmp.py:1625]   Expert 12 |    113 | CPU
DEBUG 01-14 20:42:16.056707.056707 lmp.py:1625]   Expert  5 |    124 | CPU
DEBUG 01-14 20:42:16.056681.056681 lmp.py:1625]   Expert  3 |    126 | CPU
DEBUG 01-14 20:42:16.056417.056417 lmp.py:1625]   Expert 20 |    130 | CPU
DEBUG 01-14 20:42:16.056391.056391 lmp.py:1625]   Expert 25 |    131 | CPU
DEBUG 01-14 20:42:16.056365.056365 lmp.py:1625]   Expert 41 |    131 | CPU
DEBUG 01-14 20:42:16.056101.056101 lmp.py:1625]   Expert 13 |    132 | CPU
DEBUG 01-14 20:42:16.056075.056075 lmp.py:1625]   Expert 35 |    142 | CPU
DEBUG 01-14 20:42:16.056810.056810 lmp.py:1625]   Expert 40 |    145 | CPU
DEBUG 01-14 20:42:16.056023.056023 lmp.py:1625]   Expert 37 |    146 | CPU
DEBUG 01-14 20:42:16.056758.056758 lmp.py:1625]   Expert 17 |    156 | CPU
DEBUG 01-14 20:42:16.056494.056494 lmp.py:1625]   Expert 22 |    159 | CPU
DEBUG 01-14 20:42:16.056706.056706 lmp.py:1625]   Expert 36 |    162 | CPU
DEBUG 01-14 20:42:16.056442.056442 lmp.py:1625]   Expert 47 |    167 | CPU
DEBUG 01-14 20:42:16.056131.056131 lmp.py:1625]   Expert 53 |    171 | CPU
DEBUG 01-14 20:42:16.056821.056821 lmp.py:1625]   Expert 16 |    174 | CPU
DEBUG 01-14 20:42:16.056795.056795 lmp.py:1625]   Expert 44 |    178 | GPU
DEBUG 01-14 20:42:16.056769.056769 lmp.py:1625]   Expert 58 |    178 | GPU
DEBUG 01-14 20:42:16.057266.057266 lmp.py:1625]   Expert 52 |    181 | GPU
DEBUG 01-14 20:42:16.057002.057002 lmp.py:1625]   Expert 18 |    187 | GPU
DEBUG 01-14 20:42:16.057452.057452 lmp.py:1625]   Expert 39 |    191 | GPU
DEBUG 01-14 20:42:16.057188.057188 lmp.py:1625]   Expert 48 |    195 | GPU
DEBUG 01-14 20:42:16.057162.057162 lmp.py:1625]   Expert 30 |    198 | GPU
DEBUG 01-14 20:42:16.057898.057898 lmp.py:1625]   Expert 38 |    202 | GPU
DEBUG 01-14 20:42:16.057633.057633 lmp.py:1625]   Expert 11 |    203 | GPU
DEBUG 01-14 20:42:16.057084.057084 lmp.py:1625]   Expert 45 |    206 | GPU
DEBUG 01-14 20:42:16.057012.057012 lmp.py:1625]   Expert 62 |    211 | GPU
DEBUG 01-14 20:42:16.057224.057224 lmp.py:1625]   Expert  1 |    217 | GPU
DEBUG 01-14 20:42:16.057437.057437 lmp.py:1625]   Expert 29 |    219 | GPU
DEBUG 01-14 20:42:16.057173.057173 lmp.py:1625]   Expert 51 |    220 | GPU
DEBUG 01-14 20:42:16.057385.057385 lmp.py:1625]   Expert 14 |    233 | GPU
DEBUG 01-14 20:42:16.057597.057597 lmp.py:1625]   Expert 31 |    245 | GPU
DEBUG 01-14 20:42:16.057572.057572 lmp.py:1625]   Expert 34 |    255 | GPU
DEBUG 01-14 20:42:16.057784.057784 lmp.py:1625]   Expert  6 |    263 | GPU
DEBUG 01-14 20:42:16.057996.057996 lmp.py:1625]   Expert 43 |    273 | GPU
DEBUG 01-14 20:42:16.057593.057593 lmp.py:1625]   Expert 61 |    275 | GPU
DEBUG 01-14 20:42:16.057713.057713 lmp.py:1625]   Expert 42 |    293 | GPU
DEBUG 01-14 20:42:16.057687.057687 lmp.py:1625]   Expert 33 |    295 | GPU
DEBUG 01-14 20:42:16.057423.057423 lmp.py:1625]   Expert  0 |    299 | GPU
DEBUG 01-14 20:42:16.057397.057397 lmp.py:1625]   Expert 56 |    305 | GPU
DEBUG 01-14 20:42:16.057609.057609 lmp.py:1625]   Expert 57 |    313 | GPU
DEBUG 01-14 20:42:16.057345.057345 lmp.py:1625]   Expert 46 |    327 | GPU
DEBUG 01-14 20:42:16.057657.057657 lmp.py:1625]   Expert 54 |    363 | GPU
DEBUG 01-14 20:42:16.057492.057492 lmp.py:1625]   Expert  9 |    396 | GPU
DEBUG 01-14 20:42:16.057804.057804 lmp.py:1625]   Expert 63 |    406 | GPU
DEBUG 01-14 20:42:16.057115.057115 lmp.py:1625]   Expert  8 |    416 | GPU
DEBUG 01-14 20:42:16.057235.057235 lmp.py:1625]   Expert 55 |    457 | GPU
DEBUG 01-14 20:42:16.057355.057355 lmp.py:1625]   Expert 21 |    468 | GPU
DEBUG 01-14 20:42:16.057713.057713 lmp.py:1626] 
DEBUG 01-14 20:42:16.057713.057713 lmp.py:1626]   CPU total tokens: 3620 (29.5%)
DEBUG 01-14 20:42:16.057502.057502 lmp.py:1627]   GPU total tokens: 8668 (70.5%)
DEBUG 01-14 20:42:16.057629.057629 cuda_h.py:19] end experts_map_get cost 0.0015888214111328125 seconds
DEBUG 01-14 20:42:16.057015.057015 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-14 20:42:16.057004.057004 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-14 20:42:16.057645.057645 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-14 20:42:16.059292.059292 cuda_h.py:19] end allocate_cuda_memory cost 0.001882791519165039 seconds
DEBUG 01-14 20:42:16.059665.059665 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-14 20:42:16.059090.059090 sllm_store_c.py:27] get device uuid map
DEBUG 01-14 20:42:16.059383.059383 sllm_store_c.py:29] call client load into gpu
DEBUG 01-14 20:42:16.059178.059178 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, a13f3947-a996-4cdf-b44a-196c5df16f19
DEBUG 01-14 20:42:16.060841.060841 client.py:106] call stub.LoadModelAsync
INFO 01-14 20:42:16.060854.060854 client.py:127] Model loaded
DEBUG 01-14 20:42:16.060770.060770 cuda_h.py:10] start restore2model
DEBUG 01-14 20:42:16.060876.060876 cuda_h.py:19] end restore2model cost 0.00035071372985839844 seconds
DEBUG 01-14 20:42:16.060182.060182 cuda_h.py:19] end sllm_worker_task cost 0.010871410369873047 seconds
INFO 01-14 20:42:16.060689.060689 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, a13f3947-a996-4cdf-b44a-196c5df16f19
DEBUG 01-14 20:42:16.060532.060532 cuda_h.py:19] end load_into_gpu_async cost 0.0011317729949951172 seconds
DEBUG 01-14 20:42:16.061473.061473 cuda_h.py:10] start restore_tensors2
DEBUG 01-14 20:42:16.061763.061763 cuda_h.py:19] end restore_tensors2 cost 0.0003268718719482422 seconds
DEBUG 01-14 20:42:16.061824.061824 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.003706216812133789 seconds
DEBUG 01-14 20:42:16.061256.061256 cuda_h.py:10] start restore2model
DEBUG 01-14 20:42:16.064494.064494 cuda_h.py:19] end restore2model cost 0.002532958984375 seconds
DEBUG 01-14 20:42:16.064377.064377 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.0064160823822021484 seconds
DEBUG 01-14 20:42:16.064457.064457 cuda_h.py:10] start gpu_sexperts
DEBUG 01-14 20:42:16.064773.064773 cuda_h.py:19] end gpu_sexperts cost 0.0003075599670410156 seconds
DEBUG 01-14 20:42:16.064894.064894 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-14 20:42:16.064696.064696 lmp.py:1683] 
DEBUG 01-14 20:42:16.064696.064696 lmp.py:1683]   Computing 32 experts on CPU...
DEBUG 01-14 20:42:16.064341.064341 cuda_h.py:19] end cpu_experts_submit cost 5.340576171875e-05 seconds
DEBUG 01-14 20:42:16.064182.064182 cuda_h.py:10] start experts_func_mgpu_group_pad
DEBUG 01-14 20:42:16.066831.066831 cuda_h.py:19] end experts_func_mgpu_group_pad cost 0.001535654067993164 seconds
DEBUG 01-14 20:42:16.066525.066525 cuda_h.py:10] start gpu_group_list
DEBUG 01-14 20:42:16.067146.067146 cuda_h.py:19] end gpu_group_list cost 0.0003044605255126953 seconds
DEBUG 01-14 20:42:16.067925.067925 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-14 20:42:16.067808.067808 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 1.5020370483398438e-05 seconds
DEBUG 01-14 20:42:16.067365.067365 cuda_h.py:10] start wait_experts
INFO 01-14 20:42:16.067776.067776 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, a13f3947-a996-4cdf-b44a-196c5df16f19
DEBUG 01-14 20:42:16.067661.067661 mlpmodule.py:1367]  experts func einsum cost 0.0762331485748291 s
DEBUG 01-14 20:42:16.072234.072234 mlpmodule.py:1460] group tensors cost 0.004572629928588867 s
DEBUG 01-14 20:42:16.073988.073988 cuda_h.py:10] start move_flat_hidden2cpu
DEBUG 01-14 20:42:16.077441.077441 cuda_h.py:19] end move_flat_hidden2cpu cost 0.004772663116455078 seconds
DEBUG 01-14 20:42:16.079374.079374 mlpmodule.py:1533] pad cost 0.0014812946319580078 s
DEBUG 01-14 20:42:16.079980.079980 mlpmodule.py:1539] create cpu tensor cost 3.719329833984375e-05 s
DEBUG 01-14 20:42:16.081195.081195 mlpmodule.py:1544] move to cpu cost 0.002055644989013672 s
DEBUG 01-14 20:42:16.088779.088779 mlpmodule.py:1558] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-14 20:42:16.088168.088168 mlpmodule.py:1559] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-14 20:42:16.088290.088290 mlpmodule.py:1564] group_w3 first element: 0.0157470703125
WARNING 01-14 20:42:16.089738.089738 mlpmodule.py:1574] start einsum2
DEBUG 01-14 20:42:16.102946.102946 mlpmodule.py:1584] group einsum cost 0.020347118377685547 s
DEBUG 01-14 20:42:16.103549.103549 mlpmodule.py:1593] cpy2cputensor cost 0.0007913112640380859 s
DEBUG 01-14 20:42:16.103749.103749 cuda_h.py:10] start move_outputs
DEBUG 01-14 20:42:16.105008.105008 cuda_h.py:19] end move_outputs cost 0.0027594566345214844 seconds
INFO 01-14 20:42:16.117236.117236 client.py:127] Model loaded
DEBUG 01-14 20:42:16.117198.117198 cuda_h.py:19] end wait_experts cost 0.04975748062133789 seconds
DEBUG 01-14 20:42:16.117147.117147 cuda_h.py:10] start gpu_experts
DEBUG 01-14 20:42:16.117970.117970 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-14 20:42:16.117844.117844 cuda_h.py:19] end wait_cetm_experts cost 0.0001544952392578125 seconds
DEBUG 01-14 20:42:16.117601.117601 cuda_h.py:10] start gpu_group_einsum_mp_multi_list
DEBUG 01-14 20:42:16.117357.117357 cuda_h.py:10] start gpu_group_tensor
DEBUG 01-14 20:42:16.117107.117107 cuda_h.py:19] end gpu_group_tensor cost 0.0002071857452392578 seconds
DEBUG 01-14 20:42:16.118316.118316 cuda_h.py:10] start gpu_group_einsum
DEBUG 01-14 20:42:16.118451.118451 cuda_h.py:19] end gpu_group_einsum cost 0.0006084442138671875 seconds
DEBUG 01-14 20:42:16.118191.118191 cuda_h.py:10] start gpu_final_hidden_states_scatter
DEBUG 01-14 20:42:16.118849.118849 cuda_h.py:10] start all_expert_outputs_slices
DEBUG 01-14 20:42:16.119766.119766 cuda_h.py:19] end all_expert_outputs_slices cost 0.0002579689025878906 seconds
DEBUG 01-14 20:42:16.119906.119906 cuda_h.py:10] start concat_expert_out
DEBUG 01-14 20:42:16.119625.119625 cuda_h.py:19] end concat_expert_out cost 7.2479248046875e-05 seconds
DEBUG 01-14 20:42:16.119475.119475 cuda_h.py:10] start index_scatter
DEBUG 01-14 20:42:16.119233.119233 cuda_h.py:19] end index_scatter cost 7.009506225585938e-05 seconds
DEBUG 01-14 20:42:16.119042.119042 cuda_h.py:19] end gpu_final_hidden_states_scatter cost 0.0006508827209472656 seconds
DEBUG 01-14 20:42:16.119767.119767 cuda_h.py:19] end gpu_experts cost 0.0022509098052978516 seconds
DEBUG 01-14 20:42:16.119370.119370 cuda_h.py:10] start all_expert_weight_slices
DEBUG 01-14 20:42:16.120967.120967 cuda_h.py:19] end all_expert_weight_slices cost 0.0007944107055664062 seconds
DEBUG 01-14 20:42:16.120558.120558 cuda_h.py:10] start cpuoutputsdeal
DEBUG 01-14 20:42:16.120963.120963 cuda_h.py:10] start index_scatter
DEBUG 01-14 20:42:16.121105.121105 cuda_h.py:19] end index_scatter cost 4.8160552978515625e-05 seconds
DEBUG 01-14 20:42:16.121822.121822 cuda_h.py:19] end cpuoutputsdeal cost 0.0005195140838623047 seconds
DEBUG 01-14 20:42:16.121924.121924 cuda_h.py:19] end layer_moe_generate_mp_l_10 cost 0.06596565246582031 seconds
DEBUG 01-14 20:42:16.121080.121080 cuda_h.py:19] end prefill_layer cost 0.07187318801879883 seconds
DEBUG 01-14 20:42:16.121718.121718 lmp.py:1551] -------------------------------- end prefill layer 9 --------------------------------
DEBUG 01-14 20:42:16.121321.121321 cuda_h.py:10] start prefill_layer
DEBUG 01-14 20:42:16.121925.121925 lmp.py:1494] -------------------------------- start prefill layer 10 --------------------------------
DEBUG 01-14 20:42:16.121734.121734 cuda_h.py:10] start start_load_qkvogn_s_weight_l_11
DEBUG 01-14 20:42:16.121814.121814 cuda_h.py:10] start start_load_qkvogn_s_weight_l_11
DEBUG 01-14 20:42:16.121842.121842 cuda_h.py:19] end start_load_qkvogn_s_weight_l_11 cost 2.956390380859375e-05 seconds
DEBUG 01-14 20:42:16.121651.121651 cuda_h.py:19] end start_load_qkvogn_s_weight_l_11 cost 5.6743621826171875e-05 seconds
DEBUG 01-14 20:42:16.121632.121632 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-14 20:42:16.121158.121158 cuda_h.py:10] start sllm_worker_task
DEBUG 01-14 20:42:16.121487.121487 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-14 20:42:16.121071.121071 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-14 20:42:16.122910.122910 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-14 20:42:16.126565.126565 cuda_h.py:19] end allocate_cuda_memory cost 0.004692554473876953 seconds
DEBUG 01-14 20:42:16.126005.126005 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-14 20:42:16.126874.126874 sllm_store_c.py:27] get device uuid map
DEBUG 01-14 20:42:16.127518.127518 sllm_store_c.py:29] call client load into gpu
DEBUG 01-14 20:42:16.127466.127466 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 76d16873-1275-4107-ba90-aa8bd4adfbd9
DEBUG 01-14 20:42:16.127204.127204 client.py:106] call stub.LoadModelAsync
DEBUG 01-14 20:42:16.127833.127833 mlpmodule.py:1367]  experts func einsum cost 0.05945849418640137 s
DEBUG 01-14 20:42:16.127228.127228 cuda_h.py:10] start self_attn
INFO 01-14 20:42:16.128604.128604 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 76d16873-1275-4107-ba90-aa8bd4adfbd9
DEBUG 01-14 20:42:16.128534.128534 cuda_h.py:19] end load_into_gpu_async cost 0.001714944839477539 seconds
DEBUG 01-14 20:42:16.128959.128959 cuda_h.py:10] start restore_tensors2
DEBUG 01-14 20:42:16.128797.128797 cuda_h.py:19] end restore_tensors2 cost 7.653236389160156e-05 seconds
DEBUG 01-14 20:42:16.128699.128699 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.006783723831176758 seconds
INFO 01-14 20:42:16.128059.128059 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 76d16873-1275-4107-ba90-aa8bd4adfbd9
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-14 20:42:16.130694.130694 cuda_h.py:19] end self_attn cost 0.0029447078704833984 seconds
DEBUG 01-14 20:42:16.130213.130213 cuda_h.py:19] end iln_self_attn_paln cost 0.00921320915222168 seconds
DEBUG 01-14 20:42:16.131818.131818 cuda_h.py:10] start layer_moe_generate_mp_l_11
DEBUG 01-14 20:42:16.131104.131104 cuda_h.py:10] start gate
DEBUG 01-14 20:42:16.131061.131061 cuda_h.py:19] end gate cost 0.0006730556488037109 seconds
DEBUG 01-14 20:42:16.131937.131937 cuda_h.py:10] start experts_map_get
DEBUG 01-14 20:42:16.132854.132854 lmp.py:1615] 
DEBUG 01-14 20:42:16.132854.132854 lmp.py:1615] Expert Token Distribution & Device Allocation:
DEBUG 01-14 20:42:16.132848.132848 lmp.py:1616]   Total experts: 64
DEBUG 01-14 20:42:16.132213.132213 lmp.py:1617]   CPU experts: 32 (50%)
DEBUG 01-14 20:42:16.132525.132525 lmp.py:1618]   GPU experts: 32 (50%)
DEBUG 01-14 20:42:16.132168.132168 lmp.py:1619] 
DEBUG 01-14 20:42:16.132168.132168 lmp.py:1619]   Expert ID | Tokens | Device
DEBUG 01-14 20:42:16.132811.132811 lmp.py:1620]   -----------------------------------
DEBUG 01-14 20:42:16.132885.132885 lmp.py:1625]   Expert 43 |     19 | CPU
DEBUG 01-14 20:42:16.132150.132150 lmp.py:1625]   Expert 27 |     35 | CPU
DEBUG 01-14 20:42:16.132555.132555 lmp.py:1625]   Expert 26 |     46 | CPU
DEBUG 01-14 20:42:16.132721.132721 lmp.py:1625]   Expert  3 |     55 | CPU
DEBUG 01-14 20:42:16.132649.132649 lmp.py:1625]   Expert 34 |     61 | CPU
DEBUG 01-14 20:42:16.132338.132338 lmp.py:1625]   Expert 56 |     82 | CPU
DEBUG 01-14 20:42:16.132027.132027 lmp.py:1625]   Expert 61 |     85 | CPU
DEBUG 01-14 20:42:16.132909.132909 lmp.py:1625]   Expert  4 |     97 | CPU
DEBUG 01-14 20:42:16.132467.132467 lmp.py:1625]   Expert 38 |    104 | CPU
DEBUG 01-14 20:42:16.132348.132348 lmp.py:1625]   Expert 14 |    108 | CPU
DEBUG 01-14 20:42:16.132753.132753 lmp.py:1625]   Expert  7 |    110 | CPU
DEBUG 01-14 20:42:16.132158.132158 lmp.py:1625]   Expert  2 |    122 | CPU
DEBUG 01-14 20:42:16.132324.132324 lmp.py:1625]   Expert 22 |    122 | CPU
DEBUG 01-14 20:42:16.132205.132205 lmp.py:1625]   Expert 47 |    124 | CPU
DEBUG 01-14 20:42:16.132802.132802 lmp.py:1625]   Expert  5 |    126 | CPU
DEBUG 01-14 20:42:16.132491.132491 lmp.py:1625]   Expert 17 |    133 | CPU
DEBUG 01-14 20:42:16.132704.132704 lmp.py:1625]   Expert 54 |    134 | CPU
DEBUG 01-14 20:42:16.132916.132916 lmp.py:1625]   Expert 45 |    135 | CPU
DEBUG 01-14 20:42:16.132605.132605 lmp.py:1625]   Expert 48 |    135 | CPU
DEBUG 01-14 20:42:16.132202.132202 lmp.py:1625]   Expert 51 |    136 | CPU
DEBUG 01-14 20:42:16.132130.132130 lmp.py:1625]   Expert 19 |    139 | CPU
DEBUG 01-14 20:42:16.132057.132057 lmp.py:1625]   Expert 55 |    148 | CPU
DEBUG 01-14 20:42:16.132985.132985 lmp.py:1625]   Expert 57 |    150 | CPU
DEBUG 01-14 20:42:16.132151.132151 lmp.py:1625]   Expert 63 |    150 | CPU
DEBUG 01-14 20:42:16.132841.132841 lmp.py:1625]   Expert 15 |    151 | CPU
DEBUG 01-14 20:42:16.132768.132768 lmp.py:1625]   Expert 28 |    157 | CPU
DEBUG 01-14 20:42:16.132219.132219 lmp.py:1625]   Expert 37 |    162 | CPU
DEBUG 01-14 20:42:16.132293.132293 lmp.py:1625]   Expert 12 |    163 | CPU
DEBUG 01-14 20:42:16.132744.132744 lmp.py:1625]   Expert 60 |    167 | CPU
DEBUG 01-14 20:42:16.132194.132194 lmp.py:1625]   Expert 18 |    168 | CPU
DEBUG 01-14 20:42:16.132407.132407 lmp.py:1625]   Expert 50 |    171 | CPU
DEBUG 01-14 20:42:16.132619.132619 lmp.py:1625]   Expert 44 |    186 | CPU
DEBUG 01-14 20:42:16.132832.132832 lmp.py:1625]   Expert  6 |    188 | GPU
DEBUG 01-14 20:42:16.132190.132190 lmp.py:1625]   Expert 52 |    189 | GPU
DEBUG 01-14 20:42:16.132879.132879 lmp.py:1625]   Expert 31 |    193 | GPU
DEBUG 01-14 20:42:16.132522.132522 lmp.py:1625]   Expert 23 |    194 | GPU
DEBUG 01-14 20:42:16.132688.132688 lmp.py:1625]   Expert 39 |    195 | GPU
DEBUG 01-14 20:42:16.132855.132855 lmp.py:1625]   Expert 53 |    196 | GPU
DEBUG 01-14 20:42:16.132021.132021 lmp.py:1625]   Expert 30 |    198 | GPU
DEBUG 01-14 20:42:16.132425.132425 lmp.py:1625]   Expert 29 |    203 | GPU
DEBUG 01-14 20:42:16.132499.132499 lmp.py:1625]   Expert 21 |    205 | GPU
DEBUG 01-14 20:42:16.133188.133188 lmp.py:1625]   Expert 13 |    210 | GPU
DEBUG 01-14 20:42:16.133877.133877 lmp.py:1625]   Expert 20 |    210 | GPU
DEBUG 01-14 20:42:16.133567.133567 lmp.py:1625]   Expert 42 |    213 | GPU
DEBUG 01-14 20:42:16.133018.133018 lmp.py:1625]   Expert 16 |    214 | GPU
DEBUG 01-14 20:42:16.133230.133230 lmp.py:1625]   Expert 36 |    216 | GPU
DEBUG 01-14 20:42:16.133065.133065 lmp.py:1625]   Expert 59 |    223 | GPU
DEBUG 01-14 20:42:16.133470.133470 lmp.py:1625]   Expert 49 |    224 | GPU
DEBUG 01-14 20:42:16.133874.133874 lmp.py:1625]   Expert 41 |    225 | GPU
DEBUG 01-14 20:42:16.133279.133279 lmp.py:1625]   Expert  8 |    232 | GPU
DEBUG 01-14 20:42:16.133445.133445 lmp.py:1625]   Expert 25 |    234 | GPU
DEBUG 01-14 20:42:16.133373.133373 lmp.py:1625]   Expert 11 |    235 | GPU
DEBUG 01-14 20:42:16.133446.133446 lmp.py:1625]   Expert 10 |    248 | GPU
DEBUG 01-14 20:42:16.133374.133374 lmp.py:1625]   Expert 33 |    250 | GPU
DEBUG 01-14 20:42:16.133063.133063 lmp.py:1625]   Expert 32 |    258 | GPU
DEBUG 01-14 20:42:16.133752.133752 lmp.py:1625]   Expert 46 |    268 | GPU
DEBUG 01-14 20:42:16.133203.133203 lmp.py:1625]   Expert 58 |    273 | GPU
DEBUG 01-14 20:42:16.133131.133131 lmp.py:1625]   Expert 35 |    301 | GPU
DEBUG 01-14 20:42:16.133489.133489 lmp.py:1625]   Expert 62 |    310 | GPU
DEBUG 01-14 20:42:16.133940.133940 lmp.py:1625]   Expert  9 |    321 | GPU
DEBUG 01-14 20:42:16.133629.133629 lmp.py:1625]   Expert  0 |    395 | GPU
DEBUG 01-14 20:42:16.133080.133080 lmp.py:1625]   Expert 40 |    414 | GPU
DEBUG 01-14 20:42:16.133008.133008 lmp.py:1625]   Expert 24 |    543 | GPU
DEBUG 01-14 20:42:16.133651.133651 lmp.py:1625]   Expert  1 |    629 | GPU
DEBUG 01-14 20:42:16.133009.133009 lmp.py:1626] 
DEBUG 01-14 20:42:16.133009.133009 lmp.py:1626]   CPU total tokens: 3881 (31.6%)
DEBUG 01-14 20:42:16.133083.133083 lmp.py:1627]   GPU total tokens: 8407 (68.4%)
DEBUG 01-14 20:42:16.133448.133448 cuda_h.py:19] end experts_map_get cost 0.0015766620635986328 seconds
DEBUG 01-14 20:42:16.133635.133635 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-14 20:42:16.133478.133478 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-14 20:42:16.133900.133900 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-14 20:42:16.135153.135153 cuda_h.py:19] end allocate_cuda_memory cost 0.001979351043701172 seconds
DEBUG 01-14 20:42:16.135632.135632 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-14 20:42:16.135296.135296 sllm_store_c.py:27] get device uuid map
DEBUG 01-14 20:42:16.135197.135197 sllm_store_c.py:29] call client load into gpu
DEBUG 01-14 20:42:16.135470.135470 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 48f6e8f7-a750-43ea-8251-b1cc9db68f17
DEBUG 01-14 20:42:16.136145.136145 client.py:106] call stub.LoadModelAsync
INFO 01-14 20:42:16.136842.136842 client.py:127] Model loaded
DEBUG 01-14 20:42:16.136168.136168 cuda_h.py:10] start restore2model
DEBUG 01-14 20:42:16.137409.137409 cuda_h.py:19] end restore2model cost 0.0004057884216308594 seconds
DEBUG 01-14 20:42:16.137345.137345 cuda_h.py:19] end sllm_worker_task cost 0.015097618103027344 seconds
INFO 01-14 20:42:16.138058.138058 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 48f6e8f7-a750-43ea-8251-b1cc9db68f17
DEBUG 01-14 20:42:16.138170.138170 cuda_h.py:19] end load_into_gpu_async cost 0.002346515655517578 seconds
DEBUG 01-14 20:42:16.138245.138245 cuda_h.py:10] start restore_tensors2
DEBUG 01-14 20:42:16.139674.139674 cuda_h.py:19] end restore_tensors2 cost 0.0006654262542724609 seconds
DEBUG 01-14 20:42:16.139040.139040 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0054781436920166016 seconds
DEBUG 01-14 20:42:16.139486.139486 cuda_h.py:10] start restore2model
DEBUG 01-14 20:42:16.141267.141267 cuda_h.py:19] end restore2model cost 0.002541780471801758 seconds
DEBUG 01-14 20:42:16.141050.141050 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.008213520050048828 seconds
DEBUG 01-14 20:42:16.141369.141369 cuda_h.py:10] start gpu_sexperts
DEBUG 01-14 20:42:16.142770.142770 cuda_h.py:19] end gpu_sexperts cost 0.0002651214599609375 seconds
DEBUG 01-14 20:42:16.142354.142354 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-14 20:42:16.142203.142203 lmp.py:1683] 
DEBUG 01-14 20:42:16.142203.142203 lmp.py:1683]   Computing 32 experts on CPU...
DEBUG 01-14 20:42:16.142251.142251 cuda_h.py:19] end cpu_experts_submit cost 7.104873657226562e-05 seconds
DEBUG 01-14 20:42:16.142378.142378 cuda_h.py:10] start experts_func_mgpu_group_pad
DEBUG 01-14 20:42:16.153674.153674 mlpmodule.py:1460] group tensors cost 0.011147499084472656 s
DEBUG 01-14 20:42:16.154619.154619 cuda_h.py:10] start move_flat_hidden2cpu
DEBUG 01-14 20:42:16.160156.160156 cuda_h.py:19] end experts_func_mgpu_group_pad cost 0.018013954162597656 seconds
DEBUG 01-14 20:42:16.160937.160937 cuda_h.py:19] end move_flat_hidden2cpu cost 0.006245613098144531 seconds
DEBUG 01-14 20:42:16.164402.164402 cuda_h.py:10] start gpu_group_list
DEBUG 01-14 20:42:16.165046.165046 cuda_h.py:19] end gpu_group_list cost 0.0010259151458740234 seconds
DEBUG 01-14 20:42:16.165768.165768 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-14 20:42:16.165434.165434 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.6226043701171875e-05 seconds
DEBUG 01-14 20:42:16.165919.165919 cuda_h.py:10] start wait_experts
INFO 01-14 20:42:16.165543.165543 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 48f6e8f7-a750-43ea-8251-b1cc9db68f17
DEBUG 01-14 20:42:16.165812.165812 mlpmodule.py:1533] pad cost 0.004847288131713867 s
DEBUG 01-14 20:42:16.166486.166486 mlpmodule.py:1539] create cpu tensor cost 3.933906555175781e-05 s
DEBUG 01-14 20:42:16.168898.168898 mlpmodule.py:1544] move to cpu cost 0.002196073532104492 s
DEBUG 01-14 20:42:16.175215.175215 mlpmodule.py:1558] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-14 20:42:16.176882.176882 mlpmodule.py:1559] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-14 20:42:16.176851.176851 mlpmodule.py:1564] group_w3 first element: -0.0213623046875
WARNING 01-14 20:42:16.176762.176762 mlpmodule.py:1574] start einsum2
DEBUG 01-14 20:42:16.190608.190608 mlpmodule.py:1584] group einsum cost 0.022492170333862305 s
DEBUG 01-14 20:42:16.191234.191234 mlpmodule.py:1593] cpy2cputensor cost 0.0007207393646240234 s
DEBUG 01-14 20:42:16.191534.191534 cuda_h.py:10] start move_outputs
INFO 01-14 20:42:16.192947.192947 client.py:127] Model loaded
DEBUG 01-14 20:42:16.192072.192072 cuda_h.py:19] end wait_experts cost 0.026877403259277344 seconds
DEBUG 01-14 20:42:16.192034.192034 cuda_h.py:10] start gpu_experts
DEBUG 01-14 20:42:16.192426.192426 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-14 20:42:16.193038.193038 cuda_h.py:19] end move_outputs cost 0.002157926559448242 seconds
DEBUG 01-14 20:42:16.197675.197675 cuda_h.py:19] end wait_cetm_experts cost 0.0051882266998291016 seconds
DEBUG 01-14 20:42:16.198904.198904 cuda_h.py:10] start gpu_group_einsum_mp_multi_list
DEBUG 01-14 20:42:16.198144.198144 cuda_h.py:10] start gpu_group_tensor
DEBUG 01-14 20:42:16.198511.198511 cuda_h.py:19] end gpu_group_tensor cost 0.0002377033233642578 seconds
DEBUG 01-14 20:42:16.198627.198627 cuda_h.py:10] start gpu_group_einsum
DEBUG 01-14 20:42:16.199142.199142 cuda_h.py:19] end gpu_group_einsum cost 0.000675201416015625 seconds
DEBUG 01-14 20:42:16.199697.199697 cuda_h.py:10] start gpu_final_hidden_states_scatter
DEBUG 01-14 20:42:16.199117.199117 cuda_h.py:10] start all_expert_outputs_slices
DEBUG 01-14 20:42:16.199607.199607 cuda_h.py:19] end all_expert_outputs_slices cost 0.0003552436828613281 seconds
DEBUG 01-14 20:42:16.199423.199423 cuda_h.py:10] start concat_expert_out
DEBUG 01-14 20:42:16.200698.200698 cuda_h.py:19] end concat_expert_out cost 6.103515625e-05 seconds
DEBUG 01-14 20:42:16.200455.200455 cuda_h.py:10] start index_scatter
DEBUG 01-14 20:42:16.200949.200949 cuda_h.py:19] end index_scatter cost 7.2479248046875e-05 seconds
DEBUG 01-14 20:42:16.200666.200666 cuda_h.py:19] end gpu_final_hidden_states_scatter cost 0.0007865428924560547 seconds
DEBUG 01-14 20:42:16.200874.200874 cuda_h.py:19] end gpu_experts cost 0.007648944854736328 seconds
DEBUG 01-14 20:42:16.200657.200657 cuda_h.py:10] start all_expert_weight_slices
DEBUG 01-14 20:42:16.201412.201412 cuda_h.py:19] end all_expert_weight_slices cost 0.0009427070617675781 seconds
DEBUG 01-14 20:42:16.201725.201725 cuda_h.py:10] start cpuoutputsdeal
DEBUG 01-14 20:42:16.201818.201818 cuda_h.py:10] start index_scatter
DEBUG 01-14 20:42:16.201060.201060 cuda_h.py:19] end index_scatter cost 4.887580871582031e-05 seconds
DEBUG 01-14 20:42:16.202492.202492 cuda_h.py:19] end cpuoutputsdeal cost 0.0005371570587158203 seconds
DEBUG 01-14 20:42:16.202925.202925 cuda_h.py:19] end layer_moe_generate_mp_l_11 cost 0.07100963592529297 seconds
DEBUG 01-14 20:42:16.202038.202038 cuda_h.py:19] end prefill_layer cost 0.08090639114379883 seconds
DEBUG 01-14 20:42:16.202934.202934 lmp.py:1551] -------------------------------- end prefill layer 10 --------------------------------
DEBUG 01-14 20:42:16.202590.202590 cuda_h.py:10] start prefill_layer
DEBUG 01-14 20:42:16.202009.202009 lmp.py:1494] -------------------------------- start prefill layer 11 --------------------------------
DEBUG 01-14 20:42:16.202427.202427 cuda_h.py:10] start start_load_qkvogn_s_weight_l_12
DEBUG 01-14 20:42:16.202514.202514 cuda_h.py:10] start start_load_qkvogn_s_weight_l_12
DEBUG 01-14 20:42:16.202086.202086 cuda_h.py:19] end start_load_qkvogn_s_weight_l_12 cost 4.1961669921875e-05 seconds
DEBUG 01-14 20:42:16.202094.202094 cuda_h.py:19] end start_load_qkvogn_s_weight_l_12 cost 8.559226989746094e-05 seconds
DEBUG 01-14 20:42:16.202558.202558 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-14 20:42:16.202780.202780 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-14 20:42:16.203850.203850 cuda_h.py:10] start sllm_worker_task
DEBUG 01-14 20:42:16.203890.203890 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-14 20:42:16.203982.203982 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-14 20:42:16.204934.204934 cuda_h.py:19] end allocate_cuda_memory cost 0.00140380859375 seconds
DEBUG 01-14 20:42:16.205081.205081 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-14 20:42:16.205316.205316 sllm_store_c.py:27] get device uuid map
DEBUG 01-14 20:42:16.205751.205751 sllm_store_c.py:29] call client load into gpu
DEBUG 01-14 20:42:16.205244.205244 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 8278c9d8-c22f-4e81-a288-a9bfd15cab33
DEBUG 01-14 20:42:16.205882.205882 client.py:106] call stub.LoadModelAsync
DEBUG 01-14 20:42:16.210369.210369 cuda_h.py:10] start self_attn
INFO 01-14 20:42:16.211090.211090 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 8278c9d8-c22f-4e81-a288-a9bfd15cab33
DEBUG 01-14 20:42:16.212432.212432 cuda_h.py:19] end load_into_gpu_async cost 0.006837368011474609 seconds
DEBUG 01-14 20:42:16.212956.212956 cuda_h.py:10] start restore_tensors2
DEBUG 01-14 20:42:16.212411.212411 cuda_h.py:19] end restore_tensors2 cost 9.107589721679688e-05 seconds
DEBUG 01-14 20:42:16.212882.212882 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.008941173553466797 seconds
INFO 01-14 20:42:16.212507.212507 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 8278c9d8-c22f-4e81-a288-a9bfd15cab33
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-14 20:42:16.214249.214249 cuda_h.py:19] end self_attn cost 0.003201723098754883 seconds
DEBUG 01-14 20:42:16.214445.214445 cuda_h.py:19] end iln_self_attn_paln cost 0.011608123779296875 seconds
DEBUG 01-14 20:42:16.214387.214387 cuda_h.py:10] start layer_moe_generate_mp_l_12
DEBUG 01-14 20:42:16.214627.214627 cuda_h.py:10] start gate
DEBUG 01-14 20:42:16.215073.215073 cuda_h.py:19] end gate cost 0.0006456375122070312 seconds
DEBUG 01-14 20:42:16.215949.215949 cuda_h.py:10] start experts_map_get
DEBUG 01-14 20:42:16.215006.215006 lmp.py:1615] 
DEBUG 01-14 20:42:16.215006.215006 lmp.py:1615] Expert Token Distribution & Device Allocation:
DEBUG 01-14 20:42:16.215239.215239 lmp.py:1616]   Total experts: 64
DEBUG 01-14 20:42:16.215750.215750 lmp.py:1617]   CPU experts: 32 (50%)
DEBUG 01-14 20:42:16.215638.215638 lmp.py:1618]   GPU experts: 32 (50%)
DEBUG 01-14 20:42:16.215804.215804 lmp.py:1619] 
DEBUG 01-14 20:42:16.215804.215804 lmp.py:1619]   Expert ID | Tokens | Device
DEBUG 01-14 20:42:16.215209.215209 lmp.py:1620]   -----------------------------------
DEBUG 01-14 20:42:16.215713.215713 lmp.py:1625]   Expert 39 |     15 | CPU
DEBUG 01-14 20:42:16.215641.215641 lmp.py:1625]   Expert 13 |     22 | CPU
DEBUG 01-14 20:42:16.215615.215615 lmp.py:1625]   Expert 49 |     36 | CPU
DEBUG 01-14 20:42:16.215589.215589 lmp.py:1625]   Expert  9 |     58 | CPU
DEBUG 01-14 20:42:16.215086.215086 lmp.py:1625]   Expert 19 |     63 | CPU
DEBUG 01-14 20:42:16.215060.215060 lmp.py:1625]   Expert 26 |     63 | CPU
DEBUG 01-14 20:42:16.215034.215034 lmp.py:1625]   Expert 33 |     68 | CPU
DEBUG 01-14 20:42:16.215485.215485 lmp.py:1625]   Expert 35 |     70 | CPU
DEBUG 01-14 20:42:16.215413.215413 lmp.py:1625]   Expert 46 |     74 | CPU
DEBUG 01-14 20:42:16.215864.215864 lmp.py:1625]   Expert 32 |     81 | CPU
DEBUG 01-14 20:42:16.215553.215553 lmp.py:1625]   Expert 41 |     87 | CPU
DEBUG 01-14 20:42:16.215719.215719 lmp.py:1625]   Expert 23 |     90 | CPU
DEBUG 01-14 20:42:16.215931.215931 lmp.py:1625]   Expert 31 |    100 | CPU
DEBUG 01-14 20:42:16.215429.215429 lmp.py:1625]   Expert 17 |    101 | CPU
DEBUG 01-14 20:42:16.215687.215687 lmp.py:1625]   Expert 18 |    104 | CPU
DEBUG 01-14 20:42:16.215185.215185 lmp.py:1625]   Expert  6 |    108 | CPU
DEBUG 01-14 20:42:16.215920.215920 lmp.py:1625]   Expert  3 |    111 | CPU
DEBUG 01-14 20:42:16.216848.216848 lmp.py:1625]   Expert 50 |    118 | CPU
DEBUG 01-14 20:42:16.216822.216822 lmp.py:1625]   Expert 38 |    122 | CPU
DEBUG 01-14 20:42:16.216034.216034 lmp.py:1625]   Expert 40 |    125 | CPU
DEBUG 01-14 20:42:16.216485.216485 lmp.py:1625]   Expert 15 |    129 | CPU
DEBUG 01-14 20:42:16.216698.216698 lmp.py:1625]   Expert 63 |    130 | CPU
DEBUG 01-14 20:42:16.216910.216910 lmp.py:1625]   Expert 20 |    132 | CPU
DEBUG 01-14 20:42:16.216361.216361 lmp.py:1625]   Expert 61 |    143 | CPU
DEBUG 01-14 20:42:16.216858.216858 lmp.py:1625]   Expert 62 |    143 | CPU
DEBUG 01-14 20:42:16.216740.216740 lmp.py:1625]   Expert 43 |    144 | CPU
DEBUG 01-14 20:42:16.216760.216760 lmp.py:1625]   Expert 36 |    146 | CPU
DEBUG 01-14 20:42:16.216257.216257 lmp.py:1625]   Expert  2 |    149 | CPU
DEBUG 01-14 20:42:16.216516.216516 lmp.py:1625]   Expert 42 |    151 | CPU
DEBUG 01-14 20:42:16.216013.216013 lmp.py:1625]   Expert 10 |    157 | CPU
DEBUG 01-14 20:42:16.216749.216749 lmp.py:1625]   Expert 44 |    158 | CPU
DEBUG 01-14 20:42:16.216154.216154 lmp.py:1625]   Expert 16 |    163 | CPU
DEBUG 01-14 20:42:16.216843.216843 lmp.py:1625]   Expert  5 |    170 | GPU
DEBUG 01-14 20:42:16.216817.216817 lmp.py:1625]   Expert 56 |    173 | GPU
DEBUG 01-14 20:42:16.216029.216029 lmp.py:1625]   Expert 59 |    181 | GPU
DEBUG 01-14 20:42:16.216719.216719 lmp.py:1625]   Expert 52 |    192 | GPU
DEBUG 01-14 20:42:16.216693.216693 lmp.py:1625]   Expert 45 |    194 | GPU
DEBUG 01-14 20:42:16.216813.216813 lmp.py:1625]   Expert 34 |    198 | GPU
DEBUG 01-14 20:42:16.216310.216310 lmp.py:1625]   Expert 60 |    203 | GPU
DEBUG 01-14 20:42:16.216807.216807 lmp.py:1625]   Expert 27 |    209 | GPU
DEBUG 01-14 20:42:16.216066.216066 lmp.py:1625]   Expert 51 |    210 | GPU
DEBUG 01-14 20:42:16.216100.216100 lmp.py:1625]   Expert 24 |    217 | GPU
DEBUG 01-14 20:42:16.216300.216300 lmp.py:1625]   Expert 53 |    223 | GPU
DEBUG 01-14 20:42:16.216704.216704 lmp.py:1625]   Expert 48 |    226 | GPU
DEBUG 01-14 20:42:16.216394.216394 lmp.py:1625]   Expert 47 |    248 | GPU
DEBUG 01-14 20:42:16.216083.216083 lmp.py:1625]   Expert  7 |    251 | GPU
DEBUG 01-14 20:42:16.216633.216633 lmp.py:1625]   Expert  8 |    253 | GPU
DEBUG 01-14 20:42:16.216707.216707 lmp.py:1625]   Expert 29 |    260 | GPU
DEBUG 01-14 20:42:16.216681.216681 lmp.py:1625]   Expert 21 |    267 | GPU
DEBUG 01-14 20:42:16.216178.216178 lmp.py:1625]   Expert 58 |    277 | GPU
DEBUG 01-14 20:42:16.216152.216152 lmp.py:1625]   Expert 57 |    280 | GPU
DEBUG 01-14 20:42:16.216649.216649 lmp.py:1625]   Expert  1 |    292 | GPU
DEBUG 01-14 20:42:16.216385.216385 lmp.py:1625]   Expert 14 |    292 | GPU
DEBUG 01-14 20:42:16.216604.216604 lmp.py:1625]   Expert 37 |    295 | GPU
DEBUG 01-14 20:42:16.216916.216916 lmp.py:1625]   Expert 11 |    296 | GPU
DEBUG 01-14 20:42:16.216228.216228 lmp.py:1625]   Expert  0 |    305 | GPU
DEBUG 01-14 20:42:16.216063.216063 lmp.py:1625]   Expert  4 |    306 | GPU
DEBUG 01-14 20:42:16.216421.216421 lmp.py:1625]   Expert 22 |    308 | GPU
DEBUG 01-14 20:42:16.216779.216779 lmp.py:1625]   Expert 55 |    324 | GPU
DEBUG 01-14 20:42:16.216184.216184 lmp.py:1625]   Expert 54 |    331 | GPU
DEBUG 01-14 20:42:16.216542.216542 lmp.py:1625]   Expert 25 |    371 | GPU
DEBUG 01-14 20:42:16.216708.216708 lmp.py:1625]   Expert 28 |    411 | GPU
DEBUG 01-14 20:42:16.216590.216590 lmp.py:1625]   Expert 12 |    415 | GPU
DEBUG 01-14 20:42:16.216279.216279 lmp.py:1625]   Expert 30 |    749 | GPU
DEBUG 01-14 20:42:16.216737.216737 lmp.py:1626] 
DEBUG 01-14 20:42:16.216737.216737 lmp.py:1626]   CPU total tokens: 3361 (27.4%)
DEBUG 01-14 20:42:16.216810.216810 lmp.py:1627]   GPU total tokens: 8927 (72.6%)
DEBUG 01-14 20:42:16.216652.216652 cuda_h.py:19] end experts_map_get cost 0.0015773773193359375 seconds
DEBUG 01-14 20:42:16.216793.216793 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-14 20:42:16.217312.217312 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-14 20:42:16.217178.217178 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-14 20:42:16.218335.218335 cuda_h.py:19] end allocate_cuda_memory cost 0.0012722015380859375 seconds
DEBUG 01-14 20:42:16.218522.218522 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-14 20:42:16.218636.218636 sllm_store_c.py:27] get device uuid map
DEBUG 01-14 20:42:16.218082.218082 sllm_store_c.py:29] call client load into gpu
DEBUG 01-14 20:42:16.218261.218261 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 25bcee93-289f-4275-a89f-842028901ccc
DEBUG 01-14 20:42:16.218408.218408 client.py:106] call stub.LoadModelAsync
DEBUG 01-14 20:42:16.219054.219054 mlpmodule.py:1367]  experts func einsum cost 0.07634592056274414 s
INFO 01-14 20:42:16.220113.220113 client.py:127] Model loaded
DEBUG 01-14 20:42:16.220721.220721 cuda_h.py:10] start restore2model
INFO 01-14 20:42:16.221007.221007 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 25bcee93-289f-4275-a89f-842028901ccc
DEBUG 01-14 20:42:16.221852.221852 cuda_h.py:19] end load_into_gpu_async cost 0.002701282501220703 seconds
DEBUG 01-14 20:42:16.221178.221178 cuda_h.py:10] start restore_tensors2
DEBUG 01-14 20:42:16.221713.221713 cuda_h.py:19] end restore_tensors2 cost 0.0003311634063720703 seconds
DEBUG 01-14 20:42:16.221219.221219 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.004712820053100586 seconds
DEBUG 01-14 20:42:16.221466.221466 cuda_h.py:10] start restore2model
DEBUG 01-14 20:42:16.222748.222748 cuda_h.py:19] end restore2model cost 0.0004913806915283203 seconds
DEBUG 01-14 20:42:16.222065.222065 cuda_h.py:19] end sllm_worker_task cost 0.019292354583740234 seconds
DEBUG 01-14 20:42:16.224731.224731 cuda_h.py:19] end restore2model cost 0.002934694290161133 seconds
DEBUG 01-14 20:42:16.224534.224534 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.007849693298339844 seconds
DEBUG 01-14 20:42:16.224568.224568 cuda_h.py:10] start gpu_sexperts
DEBUG 01-14 20:42:16.225341.225341 cuda_h.py:19] end gpu_sexperts cost 0.00029015541076660156 seconds
DEBUG 01-14 20:42:16.225071.225071 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-14 20:42:16.225827.225827 lmp.py:1683] 
DEBUG 01-14 20:42:16.225827.225827 lmp.py:1683]   Computing 32 experts on CPU...
DEBUG 01-14 20:42:16.225623.225623 cuda_h.py:19] end cpu_experts_submit cost 6.127357482910156e-05 seconds
DEBUG 01-14 20:42:16.225280.225280 cuda_h.py:10] start experts_func_mgpu_group_pad
DEBUG 01-14 20:42:16.236802.236802 mlpmodule.py:1460] group tensors cost 0.010405778884887695 s
DEBUG 01-14 20:42:16.237029.237029 cuda_h.py:10] start move_flat_hidden2cpu
DEBUG 01-14 20:42:16.242205.242205 cuda_h.py:19] end experts_func_mgpu_group_pad cost 0.01707148551940918 seconds
DEBUG 01-14 20:42:16.245612.245612 cuda_h.py:10] start gpu_group_list
DEBUG 01-14 20:42:16.246672.246672 cuda_h.py:19] end gpu_group_list cost 0.0006630420684814453 seconds
DEBUG 01-14 20:42:16.246252.246252 cuda_h.py:19] end move_flat_hidden2cpu cost 0.009695768356323242 seconds
DEBUG 01-14 20:42:16.247471.247471 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-14 20:42:16.247882.247882 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 3.361701965332031e-05 seconds
DEBUG 01-14 20:42:16.247718.247718 cuda_h.py:10] start wait_experts
INFO 01-14 20:42:16.247309.247309 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 25bcee93-289f-4275-a89f-842028901ccc
DEBUG 01-14 20:42:16.249120.249120 mlpmodule.py:1533] pad cost 0.0022306442260742188 s
DEBUG 01-14 20:42:16.249833.249833 mlpmodule.py:1539] create cpu tensor cost 4.2438507080078125e-05 s
DEBUG 01-14 20:42:16.251138.251138 mlpmodule.py:1544] move to cpu cost 0.0019402503967285156 s
DEBUG 01-14 20:42:16.259162.259162 mlpmodule.py:1558] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-14 20:42:16.259804.259804 mlpmodule.py:1559] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-14 20:42:16.259039.259039 mlpmodule.py:1564] group_w3 first element: -0.006134033203125
WARNING 01-14 20:42:16.259368.259368 mlpmodule.py:1574] start einsum2
DEBUG 01-14 20:42:16.272861.272861 mlpmodule.py:1584] group einsum cost 0.02129817008972168 s
DEBUG 01-14 20:42:16.273575.273575 mlpmodule.py:1593] cpy2cputensor cost 0.0006999969482421875 s
DEBUG 01-14 20:42:16.273895.273895 cuda_h.py:10] start move_outputs
DEBUG 01-14 20:42:16.275577.275577 cuda_h.py:19] end move_outputs cost 0.0019450187683105469 seconds
INFO 01-14 20:42:16.276122.276122 client.py:127] Model loaded
DEBUG 01-14 20:42:16.276937.276937 cuda_h.py:19] end wait_experts cost 0.029410600662231445 seconds
DEBUG 01-14 20:42:16.276713.276713 cuda_h.py:10] start gpu_experts
DEBUG 01-14 20:42:16.276636.276636 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-14 20:42:16.280167.280167 cuda_h.py:19] end wait_cetm_experts cost 0.0035812854766845703 seconds
DEBUG 01-14 20:42:16.280667.280667 cuda_h.py:10] start gpu_group_einsum_mp_multi_list
DEBUG 01-14 20:42:16.280668.280668 cuda_h.py:10] start gpu_group_tensor
DEBUG 01-14 20:42:16.280757.280757 cuda_h.py:19] end gpu_group_tensor cost 0.00024271011352539062 seconds
DEBUG 01-14 20:42:16.281635.281635 cuda_h.py:10] start gpu_group_einsum
DEBUG 01-14 20:42:16.281082.281082 cuda_h.py:19] end gpu_group_einsum cost 0.0006282329559326172 seconds
DEBUG 01-14 20:42:16.281179.281179 cuda_h.py:10] start gpu_final_hidden_states_scatter
DEBUG 01-14 20:42:16.281698.281698 cuda_h.py:10] start all_expert_outputs_slices
DEBUG 01-14 20:42:16.282850.282850 cuda_h.py:19] end all_expert_outputs_slices cost 0.0003535747528076172 seconds
DEBUG 01-14 20:42:16.282858.282858 cuda_h.py:10] start concat_expert_out
DEBUG 01-14 20:42:16.282650.282650 cuda_h.py:19] end concat_expert_out cost 5.4836273193359375e-05 seconds
DEBUG 01-14 20:42:16.282261.282261 cuda_h.py:10] start index_scatter
DEBUG 01-14 20:42:16.282019.282019 cuda_h.py:19] end index_scatter cost 6.961822509765625e-05 seconds
DEBUG 01-14 20:42:16.282828.282828 cuda_h.py:19] end gpu_final_hidden_states_scatter cost 0.0007462501525878906 seconds
DEBUG 01-14 20:42:16.282076.282076 cuda_h.py:19] end gpu_experts cost 0.005853176116943359 seconds
DEBUG 01-14 20:42:16.282256.282256 cuda_h.py:10] start all_expert_weight_slices
DEBUG 01-14 20:42:16.283639.283639 cuda_h.py:19] end all_expert_weight_slices cost 0.0009174346923828125 seconds
DEBUG 01-14 20:42:16.283647.283647 cuda_h.py:10] start cpuoutputsdeal
DEBUG 01-14 20:42:16.284866.284866 cuda_h.py:10] start index_scatter
DEBUG 01-14 20:42:16.284915.284915 cuda_h.py:19] end index_scatter cost 5.936622619628906e-05 seconds
DEBUG 01-14 20:42:16.284586.284586 cuda_h.py:19] end cpuoutputsdeal cost 0.0005228519439697266 seconds
DEBUG 01-14 20:42:16.284761.284761 cuda_h.py:19] end layer_moe_generate_mp_l_12 cost 0.06984877586364746 seconds
DEBUG 01-14 20:42:16.284078.284078 cuda_h.py:19] end prefill_layer cost 0.08217501640319824 seconds
DEBUG 01-14 20:42:16.284431.284431 lmp.py:1551] -------------------------------- end prefill layer 11 --------------------------------
DEBUG 01-14 20:42:16.284326.284326 cuda_h.py:10] start prefill_layer
DEBUG 01-14 20:42:16.284698.284698 lmp.py:1494] -------------------------------- start prefill layer 12 --------------------------------
DEBUG 01-14 20:42:16.284308.284308 cuda_h.py:10] start start_load_qkvogn_s_weight_l_13
DEBUG 01-14 20:42:16.284872.284872 cuda_h.py:10] start start_load_qkvogn_s_weight_l_13
DEBUG 01-14 20:42:16.285245.285245 cuda_h.py:19] end start_load_qkvogn_s_weight_l_13 cost 3.600120544433594e-05 seconds
DEBUG 01-14 20:42:16.285193.285193 cuda_h.py:19] end start_load_qkvogn_s_weight_l_13 cost 7.033348083496094e-05 seconds
DEBUG 01-14 20:42:16.285988.285988 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-14 20:42:16.285442.285442 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-14 20:42:16.285768.285768 cuda_h.py:10] start sllm_worker_task
DEBUG 01-14 20:42:16.285469.285469 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-14 20:42:16.285220.285220 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-14 20:42:16.287538.287538 cuda_h.py:19] end allocate_cuda_memory cost 0.0021615028381347656 seconds
DEBUG 01-14 20:42:16.287355.287355 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-14 20:42:16.287410.287410 sllm_store_c.py:27] get device uuid map
DEBUG 01-14 20:42:16.287822.287822 sllm_store_c.py:29] call client load into gpu
DEBUG 01-14 20:42:16.287009.287009 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, a5d23d4c-86bb-45c6-b383-405267a6785a
DEBUG 01-14 20:42:16.287211.287211 client.py:106] call stub.LoadModelAsync
DEBUG 01-14 20:42:16.288891.288891 cuda_h.py:10] start self_attn
INFO 01-14 20:42:16.288232.288232 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, a5d23d4c-86bb-45c6-b383-405267a6785a
DEBUG 01-14 20:42:16.288168.288168 cuda_h.py:19] end load_into_gpu_async cost 0.0010874271392822266 seconds
DEBUG 01-14 20:42:16.288871.288871 cuda_h.py:10] start restore_tensors2
DEBUG 01-14 20:42:16.288682.288682 cuda_h.py:19] end restore_tensors2 cost 7.414817810058594e-05 seconds
DEBUG 01-14 20:42:16.289677.289677 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0035943984985351562 seconds
INFO 01-14 20:42:16.289937.289937 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, a5d23d4c-86bb-45c6-b383-405267a6785a
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-14 20:42:16.291726.291726 cuda_h.py:19] end self_attn cost 0.0028955936431884766 seconds
DEBUG 01-14 20:42:16.291193.291193 cuda_h.py:19] end iln_self_attn_paln cost 0.006468534469604492 seconds
DEBUG 01-14 20:42:16.291274.291274 cuda_h.py:10] start layer_moe_generate_mp_l_13
DEBUG 01-14 20:42:16.291845.291845 cuda_h.py:10] start gate
DEBUG 01-14 20:42:16.292232.292232 cuda_h.py:19] end gate cost 0.0006380081176757812 seconds
DEBUG 01-14 20:42:16.292075.292075 cuda_h.py:10] start experts_map_get
DEBUG 01-14 20:42:16.292681.292681 lmp.py:1615] 
DEBUG 01-14 20:42:16.292681.292681 lmp.py:1615] Expert Token Distribution & Device Allocation:
DEBUG 01-14 20:42:16.292629.292629 lmp.py:1616]   Total experts: 64
DEBUG 01-14 20:42:16.292994.292994 lmp.py:1617]   CPU experts: 32 (50%)
DEBUG 01-14 20:42:16.292598.292598 lmp.py:1618]   GPU experts: 32 (50%)
DEBUG 01-14 20:42:16.292148.292148 lmp.py:1619] 
DEBUG 01-14 20:42:16.292148.292148 lmp.py:1619]   Expert ID | Tokens | Device
DEBUG 01-14 20:42:16.292506.292506 lmp.py:1620]   -----------------------------------
DEBUG 01-14 20:42:16.292341.292341 lmp.py:1625]   Expert 12 |     26 | CPU
DEBUG 01-14 20:42:16.292746.292746 lmp.py:1625]   Expert 38 |     29 | CPU
DEBUG 01-14 20:42:16.292674.292674 lmp.py:1625]   Expert 16 |     31 | CPU
DEBUG 01-14 20:42:16.292124.292124 lmp.py:1625]   Expert 52 |     32 | CPU
DEBUG 01-14 20:42:16.292814.292814 lmp.py:1625]   Expert 47 |     41 | CPU
DEBUG 01-14 20:42:16.292026.292026 lmp.py:1625]   Expert 63 |     44 | CPU
DEBUG 01-14 20:42:16.292716.292716 lmp.py:1625]   Expert 27 |     56 | CPU
DEBUG 01-14 20:42:16.292928.292928 lmp.py:1625]   Expert  4 |     69 | CPU
DEBUG 01-14 20:42:16.292617.292617 lmp.py:1625]   Expert 53 |     77 | CPU
DEBUG 01-14 20:42:16.292260.292260 lmp.py:1625]   Expert 43 |     79 | CPU
DEBUG 01-14 20:42:16.293426.293426 lmp.py:1625]   Expert 44 |     81 | CPU
DEBUG 01-14 20:42:16.293354.293354 lmp.py:1625]   Expert 61 |     81 | CPU
DEBUG 01-14 20:42:16.293282.293282 lmp.py:1625]   Expert 34 |     82 | CPU
DEBUG 01-14 20:42:16.293686.293686 lmp.py:1625]   Expert 13 |     98 | CPU
DEBUG 01-14 20:42:16.293376.293376 lmp.py:1625]   Expert 32 |    104 | CPU
DEBUG 01-14 20:42:16.293588.293588 lmp.py:1625]   Expert 37 |    105 | CPU
DEBUG 01-14 20:42:16.293801.293801 lmp.py:1625]   Expert 39 |    106 | CPU
DEBUG 01-14 20:42:16.293013.293013 lmp.py:1625]   Expert  0 |    112 | CPU
DEBUG 01-14 20:42:16.293226.293226 lmp.py:1625]   Expert 20 |    118 | CPU
DEBUG 01-14 20:42:16.293438.293438 lmp.py:1625]   Expert 14 |    123 | CPU
DEBUG 01-14 20:42:16.293889.293889 lmp.py:1625]   Expert 21 |    123 | CPU
DEBUG 01-14 20:42:16.293817.293817 lmp.py:1625]   Expert 30 |    128 | CPU
DEBUG 01-14 20:42:16.293506.293506 lmp.py:1625]   Expert 45 |    135 | CPU
DEBUG 01-14 20:42:16.293195.293195 lmp.py:1625]   Expert  8 |    136 | CPU
DEBUG 01-14 20:42:16.293123.293123 lmp.py:1625]   Expert 18 |    139 | CPU
DEBUG 01-14 20:42:16.293574.293574 lmp.py:1625]   Expert 60 |    140 | CPU
DEBUG 01-14 20:42:16.293025.293025 lmp.py:1625]   Expert 11 |    143 | CPU
DEBUG 01-14 20:42:16.293999.293999 lmp.py:1625]   Expert 57 |    152 | CPU
DEBUG 01-14 20:42:16.293973.293973 lmp.py:1625]   Expert 17 |    157 | CPU
DEBUG 01-14 20:42:16.293947.293947 lmp.py:1625]   Expert 22 |    159 | CPU
DEBUG 01-14 20:42:16.293159.293159 lmp.py:1625]   Expert 36 |    160 | CPU
DEBUG 01-14 20:42:16.293610.293610 lmp.py:1625]   Expert 42 |    161 | CPU
DEBUG 01-14 20:42:16.293584.293584 lmp.py:1625]   Expert  2 |    163 | GPU
DEBUG 01-14 20:42:16.293750.293750 lmp.py:1625]   Expert  7 |    167 | GPU
DEBUG 01-14 20:42:16.293440.293440 lmp.py:1625]   Expert 23 |    170 | GPU
DEBUG 01-14 20:42:16.293367.293367 lmp.py:1625]   Expert 25 |    175 | GPU
DEBUG 01-14 20:42:16.293295.293295 lmp.py:1625]   Expert 58 |    178 | GPU
DEBUG 01-14 20:42:16.293700.293700 lmp.py:1625]   Expert 62 |    178 | GPU
DEBUG 01-14 20:42:16.293151.293151 lmp.py:1625]   Expert 49 |    180 | GPU
DEBUG 01-14 20:42:16.293363.293363 lmp.py:1625]   Expert 35 |    181 | GPU
DEBUG 01-14 20:42:16.293814.293814 lmp.py:1625]   Expert 48 |    192 | GPU
DEBUG 01-14 20:42:16.293788.293788 lmp.py:1625]   Expert 29 |    193 | GPU
DEBUG 01-14 20:42:16.293239.293239 lmp.py:1625]   Expert 55 |    194 | GPU
DEBUG 01-14 20:42:16.293690.293690 lmp.py:1625]   Expert  6 |    196 | GPU
DEBUG 01-14 20:42:16.293664.293664 lmp.py:1625]   Expert  1 |    202 | GPU
DEBUG 01-14 20:42:16.293876.293876 lmp.py:1625]   Expert 31 |    203 | GPU
DEBUG 01-14 20:42:16.293566.293566 lmp.py:1625]   Expert 51 |    215 | GPU
DEBUG 01-14 20:42:16.293255.293255 lmp.py:1625]   Expert 28 |    217 | GPU
DEBUG 01-14 20:42:16.293189.293189 lmp.py:1625]   Expert  5 |    223 | GPU
DEBUG 01-14 20:42:16.293117.293117 lmp.py:1625]   Expert 19 |    227 | GPU
DEBUG 01-14 20:42:16.293330.293330 lmp.py:1625]   Expert 54 |    228 | GPU
DEBUG 01-14 20:42:16.293542.293542 lmp.py:1625]   Expert  9 |    242 | GPU
DEBUG 01-14 20:42:16.293754.293754 lmp.py:1625]   Expert 41 |    255 | GPU
DEBUG 01-14 20:42:16.293967.293967 lmp.py:1625]   Expert 24 |    265 | GPU
DEBUG 01-14 20:42:16.293994.293994 lmp.py:1625]   Expert 50 |    270 | GPU
DEBUG 01-14 20:42:16.293591.293591 lmp.py:1625]   Expert 46 |    289 | GPU
DEBUG 01-14 20:42:16.293949.293949 lmp.py:1625]   Expert 59 |    323 | GPU
DEBUG 01-14 20:42:16.293546.293546 lmp.py:1625]   Expert 33 |    396 | GPU
DEBUG 01-14 20:42:16.293619.293619 lmp.py:1625]   Expert 56 |    421 | GPU
DEBUG 01-14 20:42:16.293931.293931 lmp.py:1625]   Expert 10 |    432 | GPU
DEBUG 01-14 20:42:16.293243.293243 lmp.py:1625]   Expert 26 |    433 | GPU
DEBUG 01-14 20:42:16.293270.293270 lmp.py:1625]   Expert 15 |    593 | GPU
DEBUG 01-14 20:42:16.293582.293582 lmp.py:1625]   Expert  3 |    602 | GPU
DEBUG 01-14 20:42:16.293940.293940 lmp.py:1625]   Expert 40 |    858 | GPU
DEBUG 01-14 20:42:16.293729.293729 lmp.py:1626] 
DEBUG 01-14 20:42:16.293729.293729 lmp.py:1626]   CPU total tokens: 3227 (26.3%)
DEBUG 01-14 20:42:16.293279.293279 lmp.py:1627]   GPU total tokens: 9061 (73.7%)
DEBUG 01-14 20:42:16.293598.293598 cuda_h.py:19] end experts_map_get cost 0.0015492439270019531 seconds
DEBUG 01-14 20:42:16.294051.294051 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-14 20:42:16.294332.294332 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-14 20:42:16.294184.294184 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-14 20:42:16.299834.299834 cuda_h.py:19] end allocate_cuda_memory cost 0.005536556243896484 seconds
DEBUG 01-14 20:42:16.299505.299505 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-14 20:42:16.299692.299692 sllm_store_c.py:27] get device uuid map
DEBUG 01-14 20:42:16.299508.299508 sllm_store_c.py:29] call client load into gpu
DEBUG 01-14 20:42:16.300873.300873 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 1c70ea2e-4a63-4f66-bd52-286277029034
DEBUG 01-14 20:42:16.300740.300740 client.py:106] call stub.LoadModelAsync
INFO 01-14 20:42:16.300018.300018 client.py:127] Model loaded
DEBUG 01-14 20:42:16.300128.300128 mlpmodule.py:1367]  experts func einsum cost 0.07474684715270996 s
DEBUG 01-14 20:42:16.300437.300437 cuda_h.py:10] start restore2model
INFO 01-14 20:42:16.301990.301990 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 1c70ea2e-4a63-4f66-bd52-286277029034
DEBUG 01-14 20:42:16.301800.301800 cuda_h.py:19] end restore2model cost 0.0006225109100341797 seconds
DEBUG 01-14 20:42:16.301850.301850 cuda_h.py:19] end load_into_gpu_async cost 0.0015499591827392578 seconds
DEBUG 01-14 20:42:16.301096.301096 cuda_h.py:19] end sllm_worker_task cost 0.01616358757019043 seconds
DEBUG 01-14 20:42:16.301257.301257 cuda_h.py:10] start restore_tensors2
DEBUG 01-14 20:42:16.302961.302961 cuda_h.py:19] end restore_tensors2 cost 0.0003466606140136719 seconds
DEBUG 01-14 20:42:16.302505.302505 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.007934331893920898 seconds
DEBUG 01-14 20:42:16.302652.302652 cuda_h.py:10] start restore2model
DEBUG 01-14 20:42:16.304831.304831 cuda_h.py:19] end restore2model cost 0.0025246143341064453 seconds
DEBUG 01-14 20:42:16.304475.304475 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.010634422302246094 seconds
DEBUG 01-14 20:42:16.304270.304270 cuda_h.py:10] start gpu_sexperts
DEBUG 01-14 20:42:16.305129.305129 cuda_h.py:19] end gpu_sexperts cost 0.0002853870391845703 seconds
DEBUG 01-14 20:42:16.305905.305905 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-14 20:42:16.305515.305515 lmp.py:1683] 
DEBUG 01-14 20:42:16.305515.305515 lmp.py:1683]   Computing 32 experts on CPU...
DEBUG 01-14 20:42:16.305597.305597 cuda_h.py:19] end cpu_experts_submit cost 6.008148193359375e-05 seconds
DEBUG 01-14 20:42:16.305730.305730 cuda_h.py:10] start experts_func_mgpu_group_pad
DEBUG 01-14 20:42:16.314576.314576 mlpmodule.py:1460] group tensors cost 0.009253978729248047 s
DEBUG 01-14 20:42:16.315301.315301 cuda_h.py:10] start move_flat_hidden2cpu
DEBUG 01-14 20:42:16.320033.320033 cuda_h.py:19] end experts_func_mgpu_group_pad cost 0.015446186065673828 seconds
DEBUG 01-14 20:42:16.322495.322495 cuda_h.py:19] end move_flat_hidden2cpu cost 0.006913661956787109 seconds
DEBUG 01-14 20:42:16.324348.324348 cuda_h.py:10] start gpu_group_list
DEBUG 01-14 20:42:16.326940.326940 cuda_h.py:19] end gpu_group_list cost 0.0012316703796386719 seconds
DEBUG 01-14 20:42:16.326069.326069 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-14 20:42:16.326817.326817 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 4.220008850097656e-05 seconds
DEBUG 01-14 20:42:16.326471.326471 cuda_h.py:10] start wait_experts
INFO 01-14 20:42:16.327268.327268 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 1c70ea2e-4a63-4f66-bd52-286277029034
DEBUG 01-14 20:42:16.327760.327760 mlpmodule.py:1533] pad cost 0.004953861236572266 s
DEBUG 01-14 20:42:16.327957.327957 mlpmodule.py:1539] create cpu tensor cost 4.0531158447265625e-05 s
DEBUG 01-14 20:42:16.329049.329049 mlpmodule.py:1544] move to cpu cost 0.0019245147705078125 s
DEBUG 01-14 20:42:16.338223.338223 mlpmodule.py:1558] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-14 20:42:16.338620.338620 mlpmodule.py:1559] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-14 20:42:16.338047.338047 mlpmodule.py:1564] group_w3 first element: -0.0162353515625
WARNING 01-14 20:42:16.338707.338707 mlpmodule.py:1574] start einsum2
DEBUG 01-14 20:42:16.354531.354531 mlpmodule.py:1584] group einsum cost 0.024171113967895508 s
DEBUG 01-14 20:42:16.355946.355946 mlpmodule.py:1593] cpy2cputensor cost 0.0006952285766601562 s
DEBUG 01-14 20:42:16.355551.355551 cuda_h.py:10] start move_outputs
INFO 01-14 20:42:16.355246.355246 client.py:127] Model loaded
DEBUG 01-14 20:42:16.355279.355279 cuda_h.py:19] end wait_experts cost 0.028790950775146484 seconds
DEBUG 01-14 20:42:16.355433.355433 cuda_h.py:10] start gpu_experts
DEBUG 01-14 20:42:16.355063.355063 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-14 20:42:16.357993.357993 cuda_h.py:19] end move_outputs cost 0.0018925666809082031 seconds
DEBUG 01-14 20:42:16.361999.361999 cuda_h.py:19] end wait_cetm_experts cost 0.005135536193847656 seconds
DEBUG 01-14 20:42:16.361678.361678 cuda_h.py:10] start gpu_group_einsum_mp_multi_list
DEBUG 01-14 20:42:16.361533.361533 cuda_h.py:10] start gpu_group_tensor
DEBUG 01-14 20:42:16.361900.361900 cuda_h.py:19] end gpu_group_tensor cost 0.0002307891845703125 seconds
DEBUG 01-14 20:42:16.361633.361633 cuda_h.py:10] start gpu_group_einsum
DEBUG 01-14 20:42:16.362126.362126 cuda_h.py:19] end gpu_group_einsum cost 0.0006270408630371094 seconds
DEBUG 01-14 20:42:16.362130.362130 cuda_h.py:10] start gpu_final_hidden_states_scatter
DEBUG 01-14 20:42:16.362318.362318 cuda_h.py:10] start all_expert_outputs_slices
DEBUG 01-14 20:42:16.362848.362848 cuda_h.py:19] end all_expert_outputs_slices cost 0.0003466606140136719 seconds
DEBUG 01-14 20:42:16.362140.362140 cuda_h.py:10] start concat_expert_out
DEBUG 01-14 20:42:16.363932.363932 cuda_h.py:19] end concat_expert_out cost 5.5789947509765625e-05 seconds
DEBUG 01-14 20:42:16.363457.363457 cuda_h.py:10] start index_scatter
DEBUG 01-14 20:42:16.363977.363977 cuda_h.py:19] end index_scatter cost 6.937980651855469e-05 seconds
DEBUG 01-14 20:42:16.363786.363786 cuda_h.py:19] end gpu_final_hidden_states_scatter cost 0.0007493495941162109 seconds
DEBUG 01-14 20:42:16.363173.363173 cuda_h.py:19] end gpu_experts cost 0.007434368133544922 seconds
DEBUG 01-14 20:42:16.363160.363160 cuda_h.py:10] start all_expert_weight_slices
DEBUG 01-14 20:42:16.364775.364775 cuda_h.py:19] end all_expert_weight_slices cost 0.00091552734375 seconds
DEBUG 01-14 20:42:16.364690.364690 cuda_h.py:10] start cpuoutputsdeal
DEBUG 01-14 20:42:16.364341.364341 cuda_h.py:10] start index_scatter
DEBUG 01-14 20:42:16.364947.364947 cuda_h.py:19] end index_scatter cost 4.863739013671875e-05 seconds
DEBUG 01-14 20:42:16.364902.364902 cuda_h.py:19] end cpuoutputsdeal cost 0.0005245208740234375 seconds
DEBUG 01-14 20:42:16.365997.365997 cuda_h.py:19] end layer_moe_generate_mp_l_13 cost 0.07335948944091797 seconds
DEBUG 01-14 20:42:16.365890.365890 cuda_h.py:19] end prefill_layer cost 0.08051180839538574 seconds
DEBUG 01-14 20:42:16.365812.365812 lmp.py:1551] -------------------------------- end prefill layer 12 --------------------------------
DEBUG 01-14 20:42:16.365760.365760 cuda_h.py:10] start prefill_layer
DEBUG 01-14 20:42:16.365232.365232 lmp.py:1494] -------------------------------- start prefill layer 13 --------------------------------
DEBUG 01-14 20:42:16.365603.365603 cuda_h.py:10] start start_load_qkvogn_s_weight_l_14
DEBUG 01-14 20:42:16.365929.365929 cuda_h.py:10] start start_load_qkvogn_s_weight_l_14
DEBUG 01-14 20:42:16.365156.365156 cuda_h.py:19] end start_load_qkvogn_s_weight_l_14 cost 3.457069396972656e-05 seconds
DEBUG 01-14 20:42:16.365720.365720 cuda_h.py:19] end start_load_qkvogn_s_weight_l_14 cost 6.67572021484375e-05 seconds
DEBUG 01-14 20:42:16.365708.365708 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-14 20:42:16.365856.365856 cuda_h.py:10] start sllm_worker_task
DEBUG 01-14 20:42:16.365682.365682 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-14 20:42:16.365081.365081 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-14 20:42:16.366841.366841 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-14 20:42:16.369051.369051 cuda_h.py:19] end allocate_cuda_memory cost 0.003658294677734375 seconds
DEBUG 01-14 20:42:16.369722.369722 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-14 20:42:16.369962.369962 sllm_store_c.py:27] get device uuid map
DEBUG 01-14 20:42:16.369268.369268 sllm_store_c.py:29] call client load into gpu
DEBUG 01-14 20:42:16.369640.369640 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, dd140a37-f7e2-4aa1-843e-284f7ac863ec
DEBUG 01-14 20:42:16.370848.370848 client.py:106] call stub.LoadModelAsync
DEBUG 01-14 20:42:16.370409.370409 cuda_h.py:10] start self_attn
INFO 01-14 20:42:16.371166.371166 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, dd140a37-f7e2-4aa1-843e-284f7ac863ec
DEBUG 01-14 20:42:16.371578.371578 cuda_h.py:19] end load_into_gpu_async cost 0.001402139663696289 seconds
DEBUG 01-14 20:42:16.371804.371804 cuda_h.py:10] start restore_tensors2
DEBUG 01-14 20:42:16.371708.371708 cuda_h.py:19] end restore_tensors2 cost 7.772445678710938e-05 seconds
DEBUG 01-14 20:42:16.371464.371464 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.005403041839599609 seconds
INFO 01-14 20:42:16.371076.371076 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, dd140a37-f7e2-4aa1-843e-284f7ac863ec
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-14 20:42:16.373211.373211 cuda_h.py:19] end self_attn cost 0.003110170364379883 seconds
DEBUG 01-14 20:42:16.373798.373798 cuda_h.py:19] end iln_self_attn_paln cost 0.008214473724365234 seconds
DEBUG 01-14 20:42:16.373496.373496 cuda_h.py:10] start layer_moe_generate_mp_l_14
DEBUG 01-14 20:42:16.374874.374874 cuda_h.py:10] start gate
DEBUG 01-14 20:42:16.374580.374580 cuda_h.py:19] end gate cost 0.0006618499755859375 seconds
DEBUG 01-14 20:42:16.374217.374217 cuda_h.py:10] start experts_map_get
DEBUG 01-14 20:42:16.375453.375453 lmp.py:1615] 
DEBUG 01-14 20:42:16.375453.375453 lmp.py:1615] Expert Token Distribution & Device Allocation:
DEBUG 01-14 20:42:16.375355.375355 lmp.py:1616]   Total experts: 64
DEBUG 01-14 20:42:16.375912.375912 lmp.py:1617]   CPU experts: 32 (50%)
DEBUG 01-14 20:42:16.375893.375893 lmp.py:1618]   GPU experts: 32 (50%)
DEBUG 01-14 20:42:16.375251.375251 lmp.py:1619] 
DEBUG 01-14 20:42:16.375251.375251 lmp.py:1619]   Expert ID | Tokens | Device
DEBUG 01-14 20:42:16.375324.375324 lmp.py:1620]   -----------------------------------
DEBUG 01-14 20:42:16.375875.375875 lmp.py:1625]   Expert 42 |     20 | CPU
DEBUG 01-14 20:42:16.375756.375756 lmp.py:1625]   Expert 30 |     23 | CPU
DEBUG 01-14 20:42:16.375160.375160 lmp.py:1625]   Expert 19 |     24 | CPU
DEBUG 01-14 20:42:16.375565.375565 lmp.py:1625]   Expert  6 |     57 | CPU
DEBUG 01-14 20:42:16.375446.375446 lmp.py:1625]   Expert 32 |     64 | CPU
DEBUG 01-14 20:42:16.375851.375851 lmp.py:1625]   Expert  5 |     66 | CPU
DEBUG 01-14 20:42:16.375256.375256 lmp.py:1625]   Expert  1 |     73 | CPU
DEBUG 01-14 20:42:16.375899.375899 lmp.py:1625]   Expert 53 |     97 | CPU
DEBUG 01-14 20:42:16.375018.375018 lmp.py:1625]   Expert 18 |    108 | CPU
DEBUG 01-14 20:42:16.375377.375377 lmp.py:1625]   Expert 11 |    111 | CPU
DEBUG 01-14 20:42:16.375496.375496 lmp.py:1625]   Expert 63 |    125 | CPU
DEBUG 01-14 20:42:16.375139.375139 lmp.py:1625]   Expert 13 |    131 | CPU
DEBUG 01-14 20:42:16.375021.375021 lmp.py:1625]   Expert 59 |    134 | CPU
DEBUG 01-14 20:42:16.375425.375425 lmp.py:1625]   Expert 58 |    135 | CPU
DEBUG 01-14 20:42:16.375830.375830 lmp.py:1625]   Expert 31 |    143 | CPU
DEBUG 01-14 20:42:16.375234.375234 lmp.py:1625]   Expert 34 |    143 | CPU
DEBUG 01-14 20:42:16.375401.375401 lmp.py:1625]   Expert 40 |    143 | CPU
DEBUG 01-14 20:42:16.375567.375567 lmp.py:1625]   Expert 51 |    144 | CPU
DEBUG 01-14 20:42:16.375971.375971 lmp.py:1625]   Expert  4 |    147 | CPU
DEBUG 01-14 20:42:16.375899.375899 lmp.py:1625]   Expert 26 |    149 | CPU
DEBUG 01-14 20:42:16.375542.375542 lmp.py:1625]   Expert 61 |    151 | CPU
DEBUG 01-14 20:42:16.375185.375185 lmp.py:1625]   Expert 48 |    152 | CPU
DEBUG 01-14 20:42:16.375828.375828 lmp.py:1625]   Expert 50 |    152 | CPU
DEBUG 01-14 20:42:16.375047.375047 lmp.py:1625]   Expert 56 |    152 | CPU
DEBUG 01-14 20:42:16.375736.375736 lmp.py:1625]   Expert 20 |    153 | CPU
DEBUG 01-14 20:42:16.375949.375949 lmp.py:1625]   Expert  9 |    164 | CPU
DEBUG 01-14 20:42:16.375685.375685 lmp.py:1625]   Expert 12 |    165 | CPU
DEBUG 01-14 20:42:16.375659.375659 lmp.py:1625]   Expert 33 |    165 | CPU
DEBUG 01-14 20:42:16.375871.375871 lmp.py:1625]   Expert 35 |    166 | CPU
DEBUG 01-14 20:42:16.375607.375607 lmp.py:1625]   Expert 37 |    167 | CPU
DEBUG 01-14 20:42:16.375581.375581 lmp.py:1625]   Expert 55 |    167 | CPU
DEBUG 01-14 20:42:16.375316.375316 lmp.py:1625]   Expert 46 |    172 | CPU
DEBUG 01-14 20:42:16.375290.375290 lmp.py:1625]   Expert 10 |    174 | GPU
DEBUG 01-14 20:42:16.375980.375980 lmp.py:1625]   Expert  2 |    175 | GPU
DEBUG 01-14 20:42:16.375431.375431 lmp.py:1625]   Expert 52 |    180 | GPU
DEBUG 01-14 20:42:16.375881.375881 lmp.py:1625]   Expert 36 |    181 | GPU
DEBUG 01-14 20:42:16.375571.375571 lmp.py:1625]   Expert  8 |    191 | GPU
DEBUG 01-14 20:42:16.375022.375022 lmp.py:1625]   Expert 25 |    198 | GPU
DEBUG 01-14 20:42:16.375234.375234 lmp.py:1625]   Expert 39 |    201 | GPU
DEBUG 01-14 20:42:16.375208.375208 lmp.py:1625]   Expert 57 |    212 | GPU
DEBUG 01-14 20:42:16.375421.375421 lmp.py:1625]   Expert  0 |    215 | GPU
DEBUG 01-14 20:42:16.375918.375918 lmp.py:1625]   Expert  3 |    215 | GPU
DEBUG 01-14 20:42:16.375653.375653 lmp.py:1625]   Expert 24 |    224 | GPU
DEBUG 01-14 20:42:16.375389.375389 lmp.py:1625]   Expert 27 |    234 | GPU
DEBUG 01-14 20:42:16.375125.375125 lmp.py:1625]   Expert 21 |    238 | GPU
DEBUG 01-14 20:42:16.375099.375099 lmp.py:1625]   Expert 38 |    241 | GPU
DEBUG 01-14 20:42:16.376311.376311 lmp.py:1625]   Expert 62 |    241 | GPU
DEBUG 01-14 20:42:16.376477.376477 lmp.py:1625]   Expert  7 |    242 | GPU
DEBUG 01-14 20:42:16.376405.376405 lmp.py:1625]   Expert 23 |    242 | GPU
DEBUG 01-14 20:42:16.376618.376618 lmp.py:1625]   Expert 28 |    264 | GPU
DEBUG 01-14 20:42:16.376068.376068 lmp.py:1625]   Expert 60 |    270 | GPU
DEBUG 01-14 20:42:16.376758.376758 lmp.py:1625]   Expert 29 |    272 | GPU
DEBUG 01-14 20:42:16.376732.376732 lmp.py:1625]   Expert 43 |    275 | GPU
DEBUG 01-14 20:42:16.376229.376229 lmp.py:1625]   Expert 54 |    286 | GPU
DEBUG 01-14 20:42:16.376965.376965 lmp.py:1625]   Expert 15 |    287 | GPU
DEBUG 01-14 20:42:16.376462.376462 lmp.py:1625]   Expert 49 |    287 | GPU
DEBUG 01-14 20:42:16.376197.376197 lmp.py:1625]   Expert 16 |    290 | GPU
DEBUG 01-14 20:42:16.376695.376695 lmp.py:1625]   Expert 41 |    290 | GPU
DEBUG 01-14 20:42:16.376960.376960 lmp.py:1625]   Expert 22 |    291 | GPU
DEBUG 01-14 20:42:16.376696.376696 lmp.py:1625]   Expert 47 |    312 | GPU
DEBUG 01-14 20:42:16.376431.376431 lmp.py:1625]   Expert 44 |    319 | GPU
DEBUG 01-14 20:42:16.376406.376406 lmp.py:1625]   Expert 14 |    374 | GPU
DEBUG 01-14 20:42:16.376903.376903 lmp.py:1625]   Expert 17 |    379 | GPU
DEBUG 01-14 20:42:16.376354.376354 lmp.py:1625]   Expert 45 |    525 | GPU
DEBUG 01-14 20:42:16.376997.376997 lmp.py:1626] 
DEBUG 01-14 20:42:16.376997.376997 lmp.py:1626]   CPU total tokens: 3963 (32.3%)
DEBUG 01-14 20:42:16.376878.376878 lmp.py:1627]   GPU total tokens: 8325 (67.7%)
DEBUG 01-14 20:42:16.376289.376289 cuda_h.py:19] end experts_map_get cost 0.0015344619750976562 seconds
DEBUG 01-14 20:42:16.376053.376053 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-14 20:42:16.376943.376943 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-14 20:42:16.376186.376186 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-14 20:42:16.377304.377304 cuda_h.py:19] end allocate_cuda_memory cost 0.0013148784637451172 seconds
DEBUG 01-14 20:42:16.378836.378836 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-14 20:42:16.378308.378308 sllm_store_c.py:27] get device uuid map
DEBUG 01-14 20:42:16.378839.378839 sllm_store_c.py:29] call client load into gpu
DEBUG 01-14 20:42:16.378634.378634 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 00d3fd6a-9e73-4d4c-81e1-003dab1a1569
DEBUG 01-14 20:42:16.378886.378886 client.py:106] call stub.LoadModelAsync
INFO 01-14 20:42:16.378720.378720 client.py:127] Model loaded
DEBUG 01-14 20:42:16.378194.378194 cuda_h.py:10] start restore2model
DEBUG 01-14 20:42:16.379498.379498 cuda_h.py:19] end restore2model cost 0.00036144256591796875 seconds
DEBUG 01-14 20:42:16.379474.379474 cuda_h.py:19] end sllm_worker_task cost 0.013118505477905273 seconds
INFO 01-14 20:42:16.379688.379688 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 00d3fd6a-9e73-4d4c-81e1-003dab1a1569
DEBUG 01-14 20:42:16.379962.379962 cuda_h.py:19] end load_into_gpu_async cost 0.0011467933654785156 seconds
DEBUG 01-14 20:42:16.379188.379188 cuda_h.py:10] start restore_tensors2
DEBUG 01-14 20:42:16.379922.379922 cuda_h.py:19] end restore_tensors2 cost 0.000339508056640625 seconds
DEBUG 01-14 20:42:16.379937.379937 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0031669139862060547 seconds
DEBUG 01-14 20:42:16.379130.379130 cuda_h.py:10] start restore2model
DEBUG 01-14 20:42:16.382269.382269 cuda_h.py:19] end restore2model cost 0.0025262832641601562 seconds
DEBUG 01-14 20:42:16.382105.382105 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.0058727264404296875 seconds
DEBUG 01-14 20:42:16.382424.382424 cuda_h.py:10] start gpu_sexperts
DEBUG 01-14 20:42:16.382593.382593 cuda_h.py:19] end gpu_sexperts cost 0.0002655982971191406 seconds
DEBUG 01-14 20:42:16.382892.382892 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-14 20:42:16.382072.382072 lmp.py:1683] 
DEBUG 01-14 20:42:16.382072.382072 lmp.py:1683]   Computing 32 experts on CPU...
DEBUG 01-14 20:42:16.382021.382021 cuda_h.py:19] end cpu_experts_submit cost 6.794929504394531e-05 seconds
DEBUG 01-14 20:42:16.382863.382863 cuda_h.py:10] start experts_func_mgpu_group_pad
DEBUG 01-14 20:42:16.384625.384625 cuda_h.py:19] end experts_func_mgpu_group_pad cost 0.0015451908111572266 seconds
DEBUG 01-14 20:42:16.385075.385075 cuda_h.py:10] start gpu_group_list
DEBUG 01-14 20:42:16.385849.385849 cuda_h.py:19] end gpu_group_list cost 0.00030875205993652344 seconds
DEBUG 01-14 20:42:16.385734.385734 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-14 20:42:16.385332.385332 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 1.4781951904296875e-05 seconds
DEBUG 01-14 20:42:16.385227.385227 cuda_h.py:10] start wait_experts
INFO 01-14 20:42:16.385360.385360 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 00d3fd6a-9e73-4d4c-81e1-003dab1a1569
DEBUG 01-14 20:42:16.385073.385073 mlpmodule.py:1367]  experts func einsum cost 0.08028650283813477 s
DEBUG 01-14 20:42:16.395567.395567 mlpmodule.py:1460] group tensors cost 0.009531497955322266 s
DEBUG 01-14 20:42:16.396545.396545 cuda_h.py:10] start move_flat_hidden2cpu
DEBUG 01-14 20:42:16.402246.402246 cuda_h.py:19] end move_flat_hidden2cpu cost 0.005837678909301758 seconds
DEBUG 01-14 20:42:16.404142.404142 mlpmodule.py:1533] pad cost 0.00176239013671875 s
DEBUG 01-14 20:42:16.404371.404371 mlpmodule.py:1539] create cpu tensor cost 3.647804260253906e-05 s
DEBUG 01-14 20:42:16.406705.406705 mlpmodule.py:1544] move to cpu cost 0.0020341873168945312 s
DEBUG 01-14 20:42:16.414815.414815 mlpmodule.py:1558] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-14 20:42:16.414914.414914 mlpmodule.py:1559] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-14 20:42:16.415387.415387 mlpmodule.py:1564] group_w3 first element: -0.0211181640625
WARNING 01-14 20:42:16.415048.415048 mlpmodule.py:1574] start einsum2
DEBUG 01-14 20:42:16.432019.432019 mlpmodule.py:1584] group einsum cost 0.02650761604309082 s
INFO 01-14 20:42:16.433395.433395 client.py:127] Model loaded
DEBUG 01-14 20:42:16.433195.433195 cuda_h.py:19] end wait_experts cost 0.04781675338745117 seconds
DEBUG 01-14 20:42:16.433583.433583 cuda_h.py:10] start gpu_experts
DEBUG 01-14 20:42:16.434265.434265 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-14 20:42:16.434433.434433 mlpmodule.py:1593] cpy2cputensor cost 0.0007021427154541016 s
DEBUG 01-14 20:42:16.434032.434032 cuda_h.py:10] start move_outputs
DEBUG 01-14 20:42:16.436564.436564 cuda_h.py:19] end move_outputs cost 0.002009153366088867 seconds
DEBUG 01-14 20:42:16.440399.440399 cuda_h.py:19] end wait_cetm_experts cost 0.006329536437988281 seconds
DEBUG 01-14 20:42:16.440946.440946 cuda_h.py:10] start gpu_group_einsum_mp_multi_list
DEBUG 01-14 20:42:16.440663.440663 cuda_h.py:10] start gpu_group_tensor
DEBUG 01-14 20:42:16.440367.440367 cuda_h.py:19] end gpu_group_tensor cost 0.00023865699768066406 seconds
DEBUG 01-14 20:42:16.441669.441669 cuda_h.py:10] start gpu_group_einsum
DEBUG 01-14 20:42:16.441892.441892 cuda_h.py:19] end gpu_group_einsum cost 0.0006730556488037109 seconds
DEBUG 01-14 20:42:16.441242.441242 cuda_h.py:10] start gpu_final_hidden_states_scatter
DEBUG 01-14 20:42:16.442383.442383 cuda_h.py:10] start all_expert_outputs_slices
DEBUG 01-14 20:42:16.442225.442225 cuda_h.py:19] end all_expert_outputs_slices cost 0.0003695487976074219 seconds
DEBUG 01-14 20:42:16.442411.442411 cuda_h.py:10] start concat_expert_out
DEBUG 01-14 20:42:16.442401.442401 cuda_h.py:19] end concat_expert_out cost 6.246566772460938e-05 seconds
DEBUG 01-14 20:42:16.442059.442059 cuda_h.py:10] start index_scatter
DEBUG 01-14 20:42:16.442294.442294 cuda_h.py:19] end index_scatter cost 7.009506225585938e-05 seconds
DEBUG 01-14 20:42:16.442388.442388 cuda_h.py:19] end gpu_final_hidden_states_scatter cost 0.0007622241973876953 seconds
DEBUG 01-14 20:42:16.442934.442934 cuda_h.py:19] end gpu_experts cost 0.008770942687988281 seconds
DEBUG 01-14 20:42:16.442590.442590 cuda_h.py:10] start all_expert_weight_slices
DEBUG 01-14 20:42:16.443855.443855 cuda_h.py:19] end all_expert_weight_slices cost 0.0009372234344482422 seconds
DEBUG 01-14 20:42:16.443247.443247 cuda_h.py:10] start cpuoutputsdeal
DEBUG 01-14 20:42:16.444532.444532 cuda_h.py:10] start index_scatter
DEBUG 01-14 20:42:16.444603.444603 cuda_h.py:19] end index_scatter cost 7.319450378417969e-05 seconds
DEBUG 01-14 20:42:16.444180.444180 cuda_h.py:19] end cpuoutputsdeal cost 0.0005533695220947266 seconds
DEBUG 01-14 20:42:16.444328.444328 cuda_h.py:19] end layer_moe_generate_mp_l_14 cost 0.0705265998840332 seconds
DEBUG 01-14 20:42:16.444930.444930 cuda_h.py:19] end prefill_layer cost 0.07941174507141113 seconds
DEBUG 01-14 20:42:16.444098.444098 lmp.py:1551] -------------------------------- end prefill layer 13 --------------------------------
DEBUG 01-14 20:42:16.445039.445039 cuda_h.py:10] start prefill_layer
DEBUG 01-14 20:42:16.445696.445696 lmp.py:1494] -------------------------------- start prefill layer 14 --------------------------------
DEBUG 01-14 20:42:16.445306.445306 cuda_h.py:10] start start_load_qkvogn_s_weight_l_15
DEBUG 01-14 20:42:16.445154.445154 cuda_h.py:10] start start_load_qkvogn_s_weight_l_15
DEBUG 01-14 20:42:16.445382.445382 cuda_h.py:19] end start_load_qkvogn_s_weight_l_15 cost 3.4809112548828125e-05 seconds
DEBUG 01-14 20:42:16.445184.445184 cuda_h.py:19] end start_load_qkvogn_s_weight_l_15 cost 6.747245788574219e-05 seconds
DEBUG 01-14 20:42:16.445218.445218 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-14 20:42:16.445433.445433 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-14 20:42:16.445363.445363 cuda_h.py:10] start sllm_worker_task
DEBUG 01-14 20:42:16.445950.445950 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-14 20:42:16.445077.445077 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-14 20:42:16.450507.450507 cuda_h.py:19] end allocate_cuda_memory cost 0.0046536922454833984 seconds
DEBUG 01-14 20:42:16.450351.450351 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-14 20:42:16.450590.450590 sllm_store_c.py:27] get device uuid map
DEBUG 01-14 20:42:16.450943.450943 sllm_store_c.py:29] call client load into gpu
DEBUG 01-14 20:42:16.450123.450123 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 3497df62-a7c2-4fbf-ba71-3e58d4502d7c
DEBUG 01-14 20:42:16.450146.450146 client.py:106] call stub.LoadModelAsync
DEBUG 01-14 20:42:16.450712.450712 cuda_h.py:10] start self_attn
INFO 01-14 20:42:16.451350.451350 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 3497df62-a7c2-4fbf-ba71-3e58d4502d7c
DEBUG 01-14 20:42:16.451094.451094 cuda_h.py:19] end load_into_gpu_async cost 0.0013890266418457031 seconds
DEBUG 01-14 20:42:16.451843.451843 cuda_h.py:10] start restore_tensors2
DEBUG 01-14 20:42:16.451986.451986 cuda_h.py:19] end restore_tensors2 cost 7.772445678710938e-05 seconds
DEBUG 01-14 20:42:16.451026.451026 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0064127445220947266 seconds
INFO 01-14 20:42:16.452969.452969 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 3497df62-a7c2-4fbf-ba71-3e58d4502d7c
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-14 20:42:16.454243.454243 cuda_h.py:19] end self_attn cost 0.0033080577850341797 seconds
DEBUG 01-14 20:42:16.454537.454537 cuda_h.py:19] end iln_self_attn_paln cost 0.00929570198059082 seconds
DEBUG 01-14 20:42:16.454042.454042 cuda_h.py:10] start layer_moe_generate_mp_l_15
DEBUG 01-14 20:42:16.454898.454898 cuda_h.py:10] start gate
DEBUG 01-14 20:42:16.455119.455119 cuda_h.py:19] end gate cost 0.0006570816040039062 seconds
DEBUG 01-14 20:42:16.455280.455280 cuda_h.py:10] start experts_map_get
DEBUG 01-14 20:42:16.455979.455979 lmp.py:1615] 
DEBUG 01-14 20:42:16.455979.455979 lmp.py:1615] Expert Token Distribution & Device Allocation:
DEBUG 01-14 20:42:16.455927.455927 lmp.py:1616]   Total experts: 64
DEBUG 01-14 20:42:16.455530.455530 lmp.py:1617]   CPU experts: 32 (50%)
DEBUG 01-14 20:42:16.455796.455796 lmp.py:1618]   GPU experts: 32 (50%)
DEBUG 01-14 20:42:16.455154.455154 lmp.py:1619] 
DEBUG 01-14 20:42:16.455154.455154 lmp.py:1619]   Expert ID | Tokens | Device
DEBUG 01-14 20:42:16.455751.455751 lmp.py:1620]   -----------------------------------
DEBUG 01-14 20:42:16.455540.455540 lmp.py:1625]   Expert 34 |     18 | CPU
DEBUG 01-14 20:42:16.455183.455183 lmp.py:1625]   Expert 13 |     41 | CPU
DEBUG 01-14 20:42:16.455826.455826 lmp.py:1625]   Expert  7 |     44 | CPU
DEBUG 01-14 20:42:16.455230.455230 lmp.py:1625]   Expert 39 |     85 | CPU
DEBUG 01-14 20:42:16.455396.455396 lmp.py:1625]   Expert 54 |     88 | CPU
DEBUG 01-14 20:42:16.455801.455801 lmp.py:1625]   Expert 18 |     92 | CPU
DEBUG 01-14 20:42:16.455967.455967 lmp.py:1625]   Expert 49 |     94 | CPU
DEBUG 01-14 20:42:16.455133.455133 lmp.py:1625]   Expert 59 |     96 | CPU
DEBUG 01-14 20:42:16.455538.455538 lmp.py:1625]   Expert 16 |    106 | CPU
DEBUG 01-14 20:42:16.455472.455472 lmp.py:1625]   Expert 41 |    111 | CPU
DEBUG 01-14 20:42:16.455592.455592 lmp.py:1625]   Expert  0 |    112 | CPU
DEBUG 01-14 20:42:16.456473.456473 lmp.py:1625]   Expert 45 |    112 | CPU
DEBUG 01-14 20:42:16.456116.456116 lmp.py:1625]   Expert 22 |    118 | CPU
DEBUG 01-14 20:42:16.456236.456236 lmp.py:1625]   Expert 21 |    121 | CPU
DEBUG 01-14 20:42:16.456356.456356 lmp.py:1625]   Expert 52 |    132 | CPU
DEBUG 01-14 20:42:16.456522.456522 lmp.py:1625]   Expert  8 |    140 | CPU
DEBUG 01-14 20:42:16.456688.456688 lmp.py:1625]   Expert 12 |    141 | CPU
DEBUG 01-14 20:42:16.456616.456616 lmp.py:1625]   Expert 35 |    143 | CPU
DEBUG 01-14 20:42:16.456067.456067 lmp.py:1625]   Expert 38 |    143 | CPU
DEBUG 01-14 20:42:16.456471.456471 lmp.py:1625]   Expert 15 |    144 | CPU
DEBUG 01-14 20:42:16.456399.456399 lmp.py:1625]   Expert 36 |    144 | CPU
DEBUG 01-14 20:42:16.456327.456327 lmp.py:1625]   Expert 61 |    144 | CPU
DEBUG 01-14 20:42:16.456208.456208 lmp.py:1625]   Expert 17 |    146 | CPU
DEBUG 01-14 20:42:16.456613.456613 lmp.py:1625]   Expert 60 |    153 | CPU
DEBUG 01-14 20:42:16.456494.456494 lmp.py:1625]   Expert 48 |    158 | CPU
DEBUG 01-14 20:42:16.456614.456614 lmp.py:1625]   Expert 27 |    171 | CPU
DEBUG 01-14 20:42:16.456019.456019 lmp.py:1625]   Expert 31 |    171 | CPU
DEBUG 01-14 20:42:16.456185.456185 lmp.py:1625]   Expert 53 |    177 | CPU
DEBUG 01-14 20:42:16.456874.456874 lmp.py:1625]   Expert 19 |    184 | CPU
DEBUG 01-14 20:42:16.456802.456802 lmp.py:1625]   Expert 40 |    186 | CPU
DEBUG 01-14 20:42:16.456729.456729 lmp.py:1625]   Expert 50 |    189 | CPU
DEBUG 01-14 20:42:16.456419.456419 lmp.py:1625]   Expert  4 |    190 | CPU
DEBUG 01-14 20:42:16.456585.456585 lmp.py:1625]   Expert 20 |    190 | GPU
DEBUG 01-14 20:42:16.456380.456380 lmp.py:1625]   Expert 46 |    191 | GPU
DEBUG 01-14 20:42:16.456262.456262 lmp.py:1625]   Expert 11 |    202 | GPU
DEBUG 01-14 20:42:16.456905.456905 lmp.py:1625]   Expert 30 |    205 | GPU
DEBUG 01-14 20:42:16.456309.456309 lmp.py:1625]   Expert 43 |    209 | GPU
DEBUG 01-14 20:42:16.456714.456714 lmp.py:1625]   Expert 29 |    214 | GPU
DEBUG 01-14 20:42:16.456357.456357 lmp.py:1625]   Expert 26 |    215 | GPU
DEBUG 01-14 20:42:16.456523.456523 lmp.py:1625]   Expert 14 |    220 | GPU
DEBUG 01-14 20:42:16.456689.456689 lmp.py:1625]   Expert 57 |    227 | GPU
DEBUG 01-14 20:42:16.456855.456855 lmp.py:1625]   Expert  6 |    229 | GPU
DEBUG 01-14 20:42:16.456783.456783 lmp.py:1625]   Expert 33 |    236 | GPU
DEBUG 01-14 20:42:16.456711.456711 lmp.py:1625]   Expert  2 |    241 | GPU
DEBUG 01-14 20:42:16.456877.456877 lmp.py:1625]   Expert 23 |    241 | GPU
DEBUG 01-14 20:42:16.456043.456043 lmp.py:1625]   Expert  3 |    245 | GPU
DEBUG 01-14 20:42:16.456401.456401 lmp.py:1625]   Expert 37 |    255 | GPU
DEBUG 01-14 20:42:16.456044.456044 lmp.py:1625]   Expert 42 |    255 | GPU
DEBUG 01-14 20:42:16.456926.456926 lmp.py:1625]   Expert 56 |    255 | GPU
DEBUG 01-14 20:42:16.456807.456807 lmp.py:1625]   Expert  9 |    263 | GPU
DEBUG 01-14 20:42:16.456211.456211 lmp.py:1625]   Expert 44 |    265 | GPU
DEBUG 01-14 20:42:16.456139.456139 lmp.py:1625]   Expert 32 |    268 | GPU
DEBUG 01-14 20:42:16.456305.456305 lmp.py:1625]   Expert 55 |    271 | GPU
DEBUG 01-14 20:42:16.456471.456471 lmp.py:1625]   Expert 51 |    275 | GPU
DEBUG 01-14 20:42:16.456638.456638 lmp.py:1625]   Expert 10 |    280 | GPU
DEBUG 01-14 20:42:16.456804.456804 lmp.py:1625]   Expert 28 |    281 | GPU
DEBUG 01-14 20:42:16.456970.456970 lmp.py:1625]   Expert 58 |    284 | GPU
DEBUG 01-14 20:42:16.456136.456136 lmp.py:1625]   Expert  1 |    285 | GPU
DEBUG 01-14 20:42:16.456302.456302 lmp.py:1625]   Expert 24 |    285 | GPU
DEBUG 01-14 20:42:16.456184.456184 lmp.py:1625]   Expert 63 |    293 | GPU
DEBUG 01-14 20:42:16.456065.456065 lmp.py:1625]   Expert 25 |    312 | GPU
DEBUG 01-14 20:42:16.456470.456470 lmp.py:1625]   Expert 47 |    324 | GPU
DEBUG 01-14 20:42:16.456112.456112 lmp.py:1625]   Expert 62 |    328 | GPU
DEBUG 01-14 20:42:16.456279.456279 lmp.py:1625]   Expert  5 |    350 | GPU
DEBUG 01-14 20:42:16.456637.456637 lmp.py:1626] 
DEBUG 01-14 20:42:16.456637.456637 lmp.py:1626]   CPU total tokens: 4094 (33.3%)
DEBUG 01-14 20:42:16.456518.456518 lmp.py:1627]   GPU total tokens: 8194 (66.7%)
DEBUG 01-14 20:42:16.456406.456406 cuda_h.py:19] end experts_map_get cost 0.0015723705291748047 seconds
DEBUG 01-14 20:42:16.457448.457448 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-14 20:42:16.457245.457245 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-14 20:42:16.457382.457382 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-14 20:42:16.459886.459886 cuda_h.py:19] end allocate_cuda_memory cost 0.0019521713256835938 seconds
DEBUG 01-14 20:42:16.459444.459444 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-14 20:42:16.459631.459631 sllm_store_c.py:27] get device uuid map
DEBUG 01-14 20:42:16.459539.459539 sllm_store_c.py:29] call client load into gpu
DEBUG 01-14 20:42:16.459619.459619 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 22ce91b3-b1fc-4cb2-abdc-5a441d1c9ed0
DEBUG 01-14 20:42:16.459056.459056 client.py:106] call stub.LoadModelAsync
INFO 01-14 20:42:16.459082.459082 client.py:127] Model loaded
DEBUG 01-14 20:42:16.459886.459886 cuda_h.py:10] start restore2model
DEBUG 01-14 20:42:16.460795.460795 cuda_h.py:19] end restore2model cost 0.0004184246063232422 seconds
DEBUG 01-14 20:42:16.460771.460771 cuda_h.py:19] end sllm_worker_task cost 0.014834165573120117 seconds
INFO 01-14 20:42:16.460397.460397 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 22ce91b3-b1fc-4cb2-abdc-5a441d1c9ed0
DEBUG 01-14 20:42:16.460631.460631 cuda_h.py:19] end load_into_gpu_async cost 0.0011909008026123047 seconds
DEBUG 01-14 20:42:16.460049.460049 cuda_h.py:10] start restore_tensors2
DEBUG 01-14 20:42:16.460121.460121 cuda_h.py:19] end restore_tensors2 cost 0.0003426074981689453 seconds
DEBUG 01-14 20:42:16.460659.460659 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0038290023803710938 seconds
DEBUG 01-14 20:42:16.460852.460852 cuda_h.py:10] start restore2model
DEBUG 01-14 20:42:16.463686.463686 cuda_h.py:19] end restore2model cost 0.0025169849395751953 seconds
DEBUG 01-14 20:42:16.463707.463707 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.006517648696899414 seconds
DEBUG 01-14 20:42:16.463026.463026 cuda_h.py:10] start gpu_sexperts
DEBUG 01-14 20:42:16.463433.463433 cuda_h.py:19] end gpu_sexperts cost 0.0002696514129638672 seconds
DEBUG 01-14 20:42:16.463779.463779 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-14 20:42:16.463482.463482 lmp.py:1683] 
DEBUG 01-14 20:42:16.463482.463482 lmp.py:1683]   Computing 32 experts on CPU...
DEBUG 01-14 20:42:16.464239.464239 cuda_h.py:19] end cpu_experts_submit cost 6.651878356933594e-05 seconds
DEBUG 01-14 20:42:16.464320.464320 cuda_h.py:10] start experts_func_mgpu_group_pad
DEBUG 01-14 20:42:16.465862.465862 cuda_h.py:19] end experts_func_mgpu_group_pad cost 0.0015273094177246094 seconds
DEBUG 01-14 20:42:16.466431.466431 cuda_h.py:10] start gpu_group_list
DEBUG 01-14 20:42:16.466774.466774 cuda_h.py:19] end gpu_group_list cost 0.0003120899200439453 seconds
DEBUG 01-14 20:42:16.466414.466414 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-14 20:42:16.466627.466627 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 1.430511474609375e-05 seconds
DEBUG 01-14 20:42:16.466231.466231 cuda_h.py:10] start wait_experts
INFO 01-14 20:42:16.466881.466881 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 22ce91b3-b1fc-4cb2-abdc-5a441d1c9ed0
DEBUG 01-14 20:42:16.467702.467702 mlpmodule.py:1367]  experts func einsum cost 0.08180356025695801 s
DEBUG 01-14 20:42:16.472958.472958 mlpmodule.py:1460] group tensors cost 0.004634857177734375 s
DEBUG 01-14 20:42:16.473739.473739 cuda_h.py:10] start move_flat_hidden2cpu
DEBUG 01-14 20:42:16.481596.481596 cuda_h.py:19] end move_flat_hidden2cpu cost 0.007732868194580078 seconds
DEBUG 01-14 20:42:16.483367.483367 mlpmodule.py:1533] pad cost 0.001767873764038086 s
DEBUG 01-14 20:42:16.483026.483026 mlpmodule.py:1539] create cpu tensor cost 3.62396240234375e-05 s
DEBUG 01-14 20:42:16.485123.485123 mlpmodule.py:1544] move to cpu cost 0.002240419387817383 s
DEBUG 01-14 20:42:16.493118.493118 mlpmodule.py:1558] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-14 20:42:16.494925.494925 mlpmodule.py:1559] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-14 20:42:16.494014.494014 mlpmodule.py:1564] group_w3 first element: 0.000789642333984375
WARNING 01-14 20:42:16.494860.494860 mlpmodule.py:1574] start einsum2
DEBUG 01-14 20:42:16.510812.510812 mlpmodule.py:1584] group einsum cost 0.025022268295288086 s
DEBUG 01-14 20:42:16.511315.511315 mlpmodule.py:1593] cpy2cputensor cost 0.000762939453125 s
DEBUG 01-14 20:42:16.511158.511158 cuda_h.py:10] start move_outputs
DEBUG 01-14 20:42:16.514757.514757 cuda_h.py:19] end move_outputs cost 0.0030045509338378906 seconds
INFO 01-14 20:42:16.516354.516354 client.py:127] Model loaded
DEBUG 01-14 20:42:16.516699.516699 cuda_h.py:19] end wait_experts cost 0.049349069595336914 seconds
DEBUG 01-14 20:42:16.516377.516377 cuda_h.py:10] start gpu_experts
DEBUG 01-14 20:42:16.516154.516154 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-14 20:42:16.519508.519508 cuda_h.py:19] end wait_cetm_experts cost 0.002819061279296875 seconds
DEBUG 01-14 20:42:16.519716.519716 cuda_h.py:10] start gpu_group_einsum_mp_multi_list
DEBUG 01-14 20:42:16.519856.519856 cuda_h.py:10] start gpu_group_tensor
DEBUG 01-14 20:42:16.519508.519508 cuda_h.py:19] end gpu_group_tensor cost 0.00023746490478515625 seconds
DEBUG 01-14 20:42:16.519147.519147 cuda_h.py:10] start gpu_group_einsum
DEBUG 01-14 20:42:16.520399.520399 cuda_h.py:19] end gpu_group_einsum cost 0.0007288455963134766 seconds
DEBUG 01-14 20:42:16.520417.520417 cuda_h.py:10] start gpu_final_hidden_states_scatter
DEBUG 01-14 20:42:16.520082.520082 cuda_h.py:10] start all_expert_outputs_slices
DEBUG 01-14 20:42:16.521155.521155 cuda_h.py:19] end all_expert_outputs_slices cost 0.0003674030303955078 seconds
DEBUG 01-14 20:42:16.521957.521957 cuda_h.py:10] start concat_expert_out
DEBUG 01-14 20:42:16.521179.521179 cuda_h.py:19] end concat_expert_out cost 5.7220458984375e-05 seconds
DEBUG 01-14 20:42:16.521552.521552 cuda_h.py:10] start index_scatter
DEBUG 01-14 20:42:16.521264.521264 cuda_h.py:19] end index_scatter cost 7.033348083496094e-05 seconds
DEBUG 01-14 20:42:16.521119.521119 cuda_h.py:19] end gpu_final_hidden_states_scatter cost 0.0007503032684326172 seconds
DEBUG 01-14 20:42:16.521950.521950 cuda_h.py:19] end gpu_experts cost 0.00520014762878418 seconds
DEBUG 01-14 20:42:16.521991.521991 cuda_h.py:10] start all_expert_weight_slices
DEBUG 01-14 20:42:16.522348.522348 cuda_h.py:19] end all_expert_weight_slices cost 0.0009348392486572266 seconds
DEBUG 01-14 20:42:16.522594.522594 cuda_h.py:10] start cpuoutputsdeal
DEBUG 01-14 20:42:16.523794.523794 cuda_h.py:10] start index_scatter
DEBUG 01-14 20:42:16.523228.523228 cuda_h.py:19] end index_scatter cost 4.744529724121094e-05 seconds
DEBUG 01-14 20:42:16.523090.523090 cuda_h.py:19] end cpuoutputsdeal cost 0.0005474090576171875 seconds
DEBUG 01-14 20:42:16.523238.523238 cuda_h.py:19] end layer_moe_generate_mp_l_15 cost 0.06872320175170898 seconds
DEBUG 01-14 20:42:16.523092.523092 cuda_h.py:19] end prefill_layer cost 0.07869553565979004 seconds
DEBUG 01-14 20:42:16.523922.523922 lmp.py:1551] -------------------------------- end prefill layer 14 --------------------------------
DEBUG 01-14 20:42:16.523817.523817 cuda_h.py:10] start prefill_layer
DEBUG 01-14 20:42:16.523712.523712 lmp.py:1494] -------------------------------- start prefill layer 15 --------------------------------
DEBUG 01-14 20:42:16.523845.523845 cuda_h.py:10] start start_load_qkvogn_s_weight_l_16
DEBUG 01-14 20:42:16.523363.523363 cuda_h.py:10] start start_load_qkvogn_s_weight_l_16
DEBUG 01-14 20:42:16.523782.523782 cuda_h.py:19] end start_load_qkvogn_s_weight_l_16 cost 3.528594970703125e-05 seconds
DEBUG 01-14 20:42:16.523783.523783 cuda_h.py:19] end start_load_qkvogn_s_weight_l_16 cost 7.2479248046875e-05 seconds
DEBUG 01-14 20:42:16.524579.524579 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-14 20:42:16.524687.524687 cuda_h.py:10] start sllm_worker_task
DEBUG 01-14 20:42:16.524567.524567 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-14 20:42:16.524158.524158 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-14 20:42:16.524067.524067 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-14 20:42:16.525718.525718 cuda_h.py:19] end allocate_cuda_memory cost 0.0005822181701660156 seconds
DEBUG 01-14 20:42:16.525636.525636 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-14 20:42:16.525439.525439 sllm_store_c.py:27] get device uuid map
DEBUG 01-14 20:42:16.525991.525991 sllm_store_c.py:29] call client load into gpu
DEBUG 01-14 20:42:16.525508.525508 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, fad43148-fbc4-485c-9bb2-a2bdd0dcc80b
DEBUG 01-14 20:42:16.525313.525313 client.py:106] call stub.LoadModelAsync
DEBUG 01-14 20:42:16.530644.530644 cuda_h.py:10] start self_attn
INFO 01-14 20:42:16.531092.531092 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, fad43148-fbc4-485c-9bb2-a2bdd0dcc80b
DEBUG 01-14 20:42:16.531931.531931 cuda_h.py:19] end load_into_gpu_async cost 0.0059740543365478516 seconds
DEBUG 01-14 20:42:16.531383.531383 cuda_h.py:10] start restore_tensors2
DEBUG 01-14 20:42:16.531341.531341 cuda_h.py:19] end restore_tensors2 cost 0.00010132789611816406 seconds
DEBUG 01-14 20:42:16.531694.531694 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.007098674774169922 seconds
INFO 01-14 20:42:16.531202.531202 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, fad43148-fbc4-485c-9bb2-a2bdd0dcc80b
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-14 20:42:16.535187.535187 cuda_h.py:19] end self_attn cost 0.0048313140869140625 seconds
DEBUG 01-14 20:42:16.535757.535757 cuda_h.py:19] end iln_self_attn_paln cost 0.011818170547485352 seconds
DEBUG 01-14 20:42:16.535018.535018 cuda_h.py:10] start layer_moe_generate_mp_l_16
DEBUG 01-14 20:42:16.536855.536855 cuda_h.py:10] start gate
DEBUG 01-14 20:42:16.536521.536521 cuda_h.py:19] end gate cost 0.0008616447448730469 seconds
DEBUG 01-14 20:42:16.537093.537093 cuda_h.py:10] start experts_map_get
DEBUG 01-14 20:42:16.537030.537030 lmp.py:1615] 
DEBUG 01-14 20:42:16.537030.537030 lmp.py:1615] Expert Token Distribution & Device Allocation:
DEBUG 01-14 20:42:16.537581.537581 lmp.py:1616]   Total experts: 64
DEBUG 01-14 20:42:16.537205.537205 lmp.py:1617]   CPU experts: 32 (50%)
DEBUG 01-14 20:42:16.537537.537537 lmp.py:1618]   GPU experts: 32 (50%)
DEBUG 01-14 20:42:16.537008.537008 lmp.py:1619] 
DEBUG 01-14 20:42:16.537008.537008 lmp.py:1619]   Expert ID | Tokens | Device
DEBUG 01-14 20:42:16.537102.537102 lmp.py:1620]   -----------------------------------
DEBUG 01-14 20:42:16.537858.537858 lmp.py:1625]   Expert 20 |     67 | CPU
DEBUG 01-14 20:42:16.537806.537806 lmp.py:1625]   Expert  0 |     74 | CPU
DEBUG 01-14 20:42:16.537370.537370 lmp.py:1625]   Expert 63 |     80 | CPU
DEBUG 01-14 20:42:16.537411.537411 lmp.py:1625]   Expert  7 |     83 | CPU
DEBUG 01-14 20:42:16.537405.537405 lmp.py:1625]   Expert 52 |     85 | CPU
DEBUG 01-14 20:42:16.537161.537161 lmp.py:1625]   Expert 15 |     86 | CPU
DEBUG 01-14 20:42:16.537772.537772 lmp.py:1625]   Expert 41 |     86 | CPU
DEBUG 01-14 20:42:16.537336.537336 lmp.py:1625]   Expert 28 |     89 | CPU
DEBUG 01-14 20:42:16.537184.537184 lmp.py:1625]   Expert 45 |     91 | CPU
DEBUG 01-14 20:42:16.537463.537463 lmp.py:1625]   Expert 54 |    109 | CPU
DEBUG 01-14 20:42:16.538696.538696 lmp.py:1625]   Expert 12 |    115 | CPU
DEBUG 01-14 20:42:16.538975.538975 lmp.py:1625]   Expert 62 |    116 | CPU
DEBUG 01-14 20:42:16.538870.538870 lmp.py:1625]   Expert 21 |    119 | CPU
DEBUG 01-14 20:42:16.538434.538434 lmp.py:1625]   Expert 59 |    121 | CPU
DEBUG 01-14 20:42:16.538144.538144 lmp.py:1625]   Expert  5 |    130 | CPU
DEBUG 01-14 20:42:16.538185.538185 lmp.py:1625]   Expert 55 |    130 | CPU
DEBUG 01-14 20:42:16.538795.538795 lmp.py:1625]   Expert 14 |    136 | CPU
DEBUG 01-14 20:42:16.538458.538458 lmp.py:1625]   Expert 34 |    140 | CPU
DEBUG 01-14 20:42:16.538353.538353 lmp.py:1625]   Expert 51 |    149 | CPU
DEBUG 01-14 20:42:16.538440.538440 lmp.py:1625]   Expert  4 |    152 | CPU
DEBUG 01-14 20:42:16.538958.538958 lmp.py:1625]   Expert 61 |    152 | CPU
DEBUG 01-14 20:42:16.538005.538005 lmp.py:1625]   Expert  1 |    155 | CPU
DEBUG 01-14 20:42:16.538808.538808 lmp.py:1625]   Expert 13 |    157 | CPU
DEBUG 01-14 20:42:16.538471.538471 lmp.py:1625]   Expert 40 |    158 | CPU
DEBUG 01-14 20:42:16.538843.538843 lmp.py:1625]   Expert 10 |    164 | CPU
DEBUG 01-14 20:42:16.538453.538453 lmp.py:1625]   Expert 32 |    167 | CPU
DEBUG 01-14 20:42:16.538110.538110 lmp.py:1625]   Expert 44 |    170 | CPU
DEBUG 01-14 20:42:16.538058.538058 lmp.py:1625]   Expert 16 |    171 | CPU
DEBUG 01-14 20:42:16.538145.538145 lmp.py:1625]   Expert 22 |    171 | CPU
DEBUG 01-14 20:42:16.538530.538530 lmp.py:1625]   Expert 42 |    171 | CPU
DEBUG 01-14 20:42:16.538525.538525 lmp.py:1625]   Expert 11 |    172 | CPU
DEBUG 01-14 20:42:16.538850.538850 lmp.py:1625]   Expert  2 |    175 | CPU
DEBUG 01-14 20:42:16.538745.538745 lmp.py:1625]   Expert  6 |    176 | GPU
DEBUG 01-14 20:42:16.538501.538501 lmp.py:1625]   Expert 30 |    179 | GPU
DEBUG 01-14 20:42:16.538780.538780 lmp.py:1625]   Expert 19 |    181 | GPU
DEBUG 01-14 20:42:16.538205.538205 lmp.py:1625]   Expert 47 |    181 | GPU
DEBUG 01-14 20:42:16.538007.538007 lmp.py:1625]   Expert 53 |    183 | GPU
DEBUG 01-14 20:42:16.538432.538432 lmp.py:1625]   Expert 56 |    186 | GPU
DEBUG 01-14 20:42:16.538850.538850 lmp.py:1625]   Expert 35 |    187 | GPU
DEBUG 01-14 20:42:16.538461.538461 lmp.py:1625]   Expert 25 |    189 | GPU
DEBUG 01-14 20:42:16.538694.538694 lmp.py:1625]   Expert 26 |    195 | GPU
DEBUG 01-14 20:42:16.538496.538496 lmp.py:1625]   Expert 24 |    200 | GPU
DEBUG 01-14 20:42:16.538868.538868 lmp.py:1625]   Expert 57 |    207 | GPU
DEBUG 01-14 20:42:16.539054.539054 lmp.py:1625]   Expert 50 |    213 | GPU
DEBUG 01-14 20:42:16.539664.539664 lmp.py:1625]   Expert 48 |    223 | GPU
DEBUG 01-14 20:42:16.539427.539427 lmp.py:1625]   Expert 46 |    228 | GPU
DEBUG 01-14 20:42:16.539355.539355 lmp.py:1625]   Expert 39 |    229 | GPU
DEBUG 01-14 20:42:16.539621.539621 lmp.py:1625]   Expert 18 |    234 | GPU
DEBUG 01-14 20:42:16.539502.539502 lmp.py:1625]   Expert 37 |    236 | GPU
DEBUG 01-14 20:42:16.539112.539112 lmp.py:1625]   Expert  3 |    241 | GPU
DEBUG 01-14 20:42:16.539470.539470 lmp.py:1625]   Expert 29 |    249 | GPU
DEBUG 01-14 20:42:16.539021.539021 lmp.py:1625]   Expert 60 |    255 | GPU
DEBUG 01-14 20:42:16.539333.539333 lmp.py:1625]   Expert 31 |    258 | GPU
DEBUG 01-14 20:42:16.539168.539168 lmp.py:1625]   Expert 36 |    260 | GPU
DEBUG 01-14 20:42:16.539334.539334 lmp.py:1625]   Expert 23 |    262 | GPU
DEBUG 01-14 20:42:16.539692.539692 lmp.py:1625]   Expert 38 |    262 | GPU
DEBUG 01-14 20:42:16.539858.539858 lmp.py:1625]   Expert 17 |    267 | GPU
DEBUG 01-14 20:42:16.539740.539740 lmp.py:1625]   Expert  9 |    272 | GPU
DEBUG 01-14 20:42:16.539575.539575 lmp.py:1625]   Expert  8 |    285 | GPU
DEBUG 01-14 20:42:16.539694.539694 lmp.py:1625]   Expert 27 |    324 | GPU
DEBUG 01-14 20:42:16.539622.539622 lmp.py:1625]   Expert 43 |    371 | GPU
DEBUG 01-14 20:42:16.539742.539742 lmp.py:1625]   Expert 33 |    416 | GPU
DEBUG 01-14 20:42:16.539670.539670 lmp.py:1625]   Expert 58 |    474 | GPU
DEBUG 01-14 20:42:16.539220.539220 lmp.py:1625]   Expert 49 |    524 | GPU
DEBUG 01-14 20:42:16.539532.539532 lmp.py:1626] 
DEBUG 01-14 20:42:16.539532.539532 lmp.py:1626]   CPU total tokens: 4141 (33.7%)
DEBUG 01-14 20:42:16.539798.539798 lmp.py:1627]   GPU total tokens: 8147 (66.3%)
DEBUG 01-14 20:42:16.539593.539593 cuda_h.py:19] end experts_map_get cost 0.0024340152740478516 seconds
DEBUG 01-14 20:42:16.539880.539880 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-14 20:42:16.539776.539776 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-14 20:42:16.539589.539589 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-14 20:42:16.541877.541877 cuda_h.py:19] end allocate_cuda_memory cost 0.0018262863159179688 seconds
DEBUG 01-14 20:42:16.541488.541488 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-14 20:42:16.541198.541198 sllm_store_c.py:27] get device uuid map
DEBUG 01-14 20:42:16.541775.541775 sllm_store_c.py:29] call client load into gpu
DEBUG 01-14 20:42:16.541332.541332 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 64f7503c-9db5-4f64-9e04-ef8472a28659
DEBUG 01-14 20:42:16.541729.541729 client.py:106] call stub.LoadModelAsync
INFO 01-14 20:42:16.542663.542663 client.py:127] Model loaded
DEBUG 01-14 20:42:16.542483.542483 mlpmodule.py:1367]  experts func einsum cost 0.07410359382629395 s
DEBUG 01-14 20:42:16.542699.542699 cuda_h.py:10] start restore2model
DEBUG 01-14 20:42:16.543211.543211 cuda_h.py:19] end restore2model cost 0.0006952285766601562 seconds
DEBUG 01-14 20:42:16.543076.543076 cuda_h.py:19] end sllm_worker_task cost 0.01911759376525879 seconds
INFO 01-14 20:42:16.543212.543212 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 64f7503c-9db5-4f64-9e04-ef8472a28659
DEBUG 01-14 20:42:16.543699.543699 cuda_h.py:19] end load_into_gpu_async cost 0.0019102096557617188 seconds
DEBUG 01-14 20:42:16.543508.543508 cuda_h.py:10] start restore_tensors2
DEBUG 01-14 20:42:16.544594.544594 cuda_h.py:19] end restore_tensors2 cost 0.0003502368927001953 seconds
DEBUG 01-14 20:42:16.544807.544807 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.004455089569091797 seconds
DEBUG 01-14 20:42:16.544239.544239 cuda_h.py:10] start restore2model
DEBUG 01-14 20:42:16.546564.546564 cuda_h.py:19] end restore2model cost 0.0025610923767089844 seconds
DEBUG 01-14 20:42:16.546308.546308 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.007201194763183594 seconds
DEBUG 01-14 20:42:16.546342.546342 cuda_h.py:10] start gpu_sexperts
DEBUG 01-14 20:42:16.547399.547399 cuda_h.py:19] end gpu_sexperts cost 0.0002913475036621094 seconds
DEBUG 01-14 20:42:16.547388.547388 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-14 20:42:16.547806.547806 lmp.py:1683] 
DEBUG 01-14 20:42:16.547806.547806 lmp.py:1683]   Computing 32 experts on CPU...
DEBUG 01-14 20:42:16.547695.547695 cuda_h.py:19] end cpu_experts_submit cost 5.817413330078125e-05 seconds
DEBUG 01-14 20:42:16.547590.547590 cuda_h.py:10] start experts_func_mgpu_group_pad
DEBUG 01-14 20:42:16.552547.552547 mlpmodule.py:1460] group tensors cost 0.0044651031494140625 s
DEBUG 01-14 20:42:16.552347.552347 cuda_h.py:10] start move_flat_hidden2cpu
DEBUG 01-14 20:42:16.555114.555114 cuda_h.py:19] end experts_func_mgpu_group_pad cost 0.008266925811767578 seconds
DEBUG 01-14 20:42:16.557974.557974 cuda_h.py:10] start gpu_group_list
DEBUG 01-14 20:42:16.557382.557382 cuda_h.py:19] end gpu_group_list cost 0.00042128562927246094 seconds
DEBUG 01-14 20:42:16.557758.557758 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-14 20:42:16.557383.557383 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.0742416381835938e-05 seconds
DEBUG 01-14 20:42:16.557616.557616 cuda_h.py:10] start wait_experts
INFO 01-14 20:42:16.557610.557610 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 64f7503c-9db5-4f64-9e04-ef8472a28659
DEBUG 01-14 20:42:16.560119.560119 cuda_h.py:19] end move_flat_hidden2cpu cost 0.0075550079345703125 seconds
DEBUG 01-14 20:42:16.562917.562917 mlpmodule.py:1533] pad cost 0.0017635822296142578 s
DEBUG 01-14 20:42:16.562862.562862 mlpmodule.py:1539] create cpu tensor cost 5.7220458984375e-05 s
DEBUG 01-14 20:42:16.564926.564926 mlpmodule.py:1544] move to cpu cost 0.0020716190338134766 s
DEBUG 01-14 20:42:16.573856.573856 mlpmodule.py:1558] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-14 20:42:16.573352.573352 mlpmodule.py:1559] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-14 20:42:16.573342.573342 mlpmodule.py:1564] group_w3 first element: -0.0595703125
WARNING 01-14 20:42:16.573764.573764 mlpmodule.py:1574] start einsum2
DEBUG 01-14 20:42:16.589053.589053 mlpmodule.py:1584] group einsum cost 0.024468660354614258 s
DEBUG 01-14 20:42:16.590198.590198 mlpmodule.py:1593] cpy2cputensor cost 0.0007076263427734375 s
DEBUG 01-14 20:42:16.590710.590710 cuda_h.py:10] start move_outputs
DEBUG 01-14 20:42:16.592398.592398 cuda_h.py:19] end move_outputs cost 0.002720355987548828 seconds
INFO 01-14 20:42:16.599105.599105 client.py:127] Model loaded
DEBUG 01-14 20:42:16.600449.600449 cuda_h.py:19] end wait_experts cost 0.042028188705444336 seconds
DEBUG 01-14 20:42:16.600218.600218 cuda_h.py:10] start gpu_experts
DEBUG 01-14 20:42:16.600419.600419 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-14 20:42:16.600035.600035 cuda_h.py:19] end wait_cetm_experts cost 0.00017642974853515625 seconds
DEBUG 01-14 20:42:16.600462.600462 cuda_h.py:10] start gpu_group_einsum_mp_multi_list
DEBUG 01-14 20:42:16.600887.600887 cuda_h.py:10] start gpu_group_tensor
DEBUG 01-14 20:42:16.600115.600115 cuda_h.py:19] end gpu_group_tensor cost 0.00024080276489257812 seconds
DEBUG 01-14 20:42:16.600185.600185 cuda_h.py:10] start gpu_group_einsum
DEBUG 01-14 20:42:16.601427.601427 cuda_h.py:19] end gpu_group_einsum cost 0.000652313232421875 seconds
DEBUG 01-14 20:42:16.601002.601002 cuda_h.py:10] start gpu_final_hidden_states_scatter
DEBUG 01-14 20:42:16.601335.601335 cuda_h.py:10] start all_expert_outputs_slices
DEBUG 01-14 20:42:16.602031.602031 cuda_h.py:19] end all_expert_outputs_slices cost 0.0003552436828613281 seconds
DEBUG 01-14 20:42:16.602933.602933 cuda_h.py:10] start concat_expert_out
DEBUG 01-14 20:42:16.602254.602254 cuda_h.py:19] end concat_expert_out cost 6.079673767089844e-05 seconds
DEBUG 01-14 20:42:16.602296.602296 cuda_h.py:10] start index_scatter
DEBUG 01-14 20:42:16.602677.602677 cuda_h.py:19] end index_scatter cost 7.176399230957031e-05 seconds
DEBUG 01-14 20:42:16.602201.602201 cuda_h.py:19] end gpu_final_hidden_states_scatter cost 0.0007643699645996094 seconds
DEBUG 01-14 20:42:16.602270.602270 cuda_h.py:19] end gpu_experts cost 0.0025017261505126953 seconds
DEBUG 01-14 20:42:16.602927.602927 cuda_h.py:10] start all_expert_weight_slices
DEBUG 01-14 20:42:16.603661.603661 cuda_h.py:19] end all_expert_weight_slices cost 0.0009319782257080078 seconds
DEBUG 01-14 20:42:16.603907.603907 cuda_h.py:10] start cpuoutputsdeal
DEBUG 01-14 20:42:16.604677.604677 cuda_h.py:10] start index_scatter
DEBUG 01-14 20:42:16.604428.604428 cuda_h.py:19] end index_scatter cost 4.9591064453125e-05 seconds
DEBUG 01-14 20:42:16.604383.604383 cuda_h.py:19] end cpuoutputsdeal cost 0.0005326271057128906 seconds
DEBUG 01-14 20:42:16.604293.604293 cuda_h.py:19] end layer_moe_generate_mp_l_16 cost 0.06827425956726074 seconds
DEBUG 01-14 20:42:16.604098.604098 cuda_h.py:19] end prefill_layer cost 0.08096742630004883 seconds
DEBUG 01-14 20:42:16.604127.604127 lmp.py:1551] -------------------------------- end prefill layer 15 --------------------------------
DEBUG 01-14 20:42:16.604638.604638 cuda_h.py:10] start prefill_layer
DEBUG 01-14 20:42:16.604956.604956 lmp.py:1494] -------------------------------- start prefill layer 16 --------------------------------
DEBUG 01-14 20:42:16.604275.604275 cuda_h.py:10] start start_load_qkvogn_s_weight_l_17
DEBUG 01-14 20:42:16.604978.604978 cuda_h.py:10] start start_load_qkvogn_s_weight_l_17
DEBUG 01-14 20:42:16.605205.605205 cuda_h.py:19] end start_load_qkvogn_s_weight_l_17 cost 3.0279159545898438e-05 seconds
DEBUG 01-14 20:42:16.605193.605193 cuda_h.py:19] end start_load_qkvogn_s_weight_l_17 cost 6.008148193359375e-05 seconds
DEBUG 01-14 20:42:16.605220.605220 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-14 20:42:16.605017.605017 cuda_h.py:10] start sllm_worker_task
DEBUG 01-14 20:42:16.605430.605430 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-14 20:42:16.605306.605306 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-14 20:42:16.608385.608385 cuda_h.py:19] end allocate_cuda_memory cost 0.002716541290283203 seconds
DEBUG 01-14 20:42:16.608938.608938 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-14 20:42:16.608516.608516 sllm_store_c.py:27] get device uuid map
DEBUG 01-14 20:42:16.608406.608406 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-14 20:42:16.608726.608726 sllm_store_c.py:29] call client load into gpu
DEBUG 01-14 20:42:16.608062.608062 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, aaaaab70-de5b-480a-a261-abace78d7d8a
DEBUG 01-14 20:42:16.608423.608423 client.py:106] call stub.LoadModelAsync
DEBUG 01-14 20:42:16.608308.608308 cuda_h.py:10] start self_attn
INFO 01-14 20:42:16.609065.609065 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, aaaaab70-de5b-480a-a261-abace78d7d8a
DEBUG 01-14 20:42:16.609207.609207 cuda_h.py:19] end load_into_gpu_async cost 0.00145721435546875 seconds
DEBUG 01-14 20:42:16.609148.609148 cuda_h.py:10] start restore_tensors2
DEBUG 01-14 20:42:16.609999.609999 cuda_h.py:19] end restore_tensors2 cost 7.390975952148438e-05 seconds
DEBUG 01-14 20:42:16.609040.609040 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.004527568817138672 seconds
INFO 01-14 20:42:16.609360.609360 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, aaaaab70-de5b-480a-a261-abace78d7d8a
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-14 20:42:16.611901.611901 cuda_h.py:19] end self_attn cost 0.003002643585205078 seconds
DEBUG 01-14 20:42:16.612778.612778 cuda_h.py:19] end iln_self_attn_paln cost 0.007158517837524414 seconds
DEBUG 01-14 20:42:16.612721.612721 cuda_h.py:10] start layer_moe_generate_mp_l_17
DEBUG 01-14 20:42:16.612768.612768 cuda_h.py:10] start gate
DEBUG 01-14 20:42:16.613805.613805 cuda_h.py:19] end gate cost 0.0006480216979980469 seconds
DEBUG 01-14 20:42:16.613919.613919 cuda_h.py:10] start experts_map_get
DEBUG 01-14 20:42:16.613639.613639 lmp.py:1615] 
DEBUG 01-14 20:42:16.613639.613639 lmp.py:1615] Expert Token Distribution & Device Allocation:
DEBUG 01-14 20:42:16.613401.613401 lmp.py:1616]   Total experts: 64
DEBUG 01-14 20:42:16.613005.613005 lmp.py:1617]   CPU experts: 32 (50%)
DEBUG 01-14 20:42:16.613701.613701 lmp.py:1618]   GPU experts: 32 (50%)
DEBUG 01-14 20:42:16.613490.613490 lmp.py:1619] 
DEBUG 01-14 20:42:16.613490.613490 lmp.py:1619]   Expert ID | Tokens | Device
DEBUG 01-14 20:42:16.613801.613801 lmp.py:1620]   -----------------------------------
DEBUG 01-14 20:42:16.613637.613637 lmp.py:1625]   Expert 58 |     49 | CPU
DEBUG 01-14 20:42:16.613710.613710 lmp.py:1625]   Expert 45 |     50 | CPU
DEBUG 01-14 20:42:16.613830.613830 lmp.py:1625]   Expert 49 |     64 | CPU
DEBUG 01-14 20:42:16.613380.613380 lmp.py:1625]   Expert  4 |     67 | CPU
DEBUG 01-14 20:42:16.613785.613785 lmp.py:1625]   Expert 31 |     68 | CPU
DEBUG 01-14 20:42:16.613097.613097 lmp.py:1625]   Expert 38 |     70 | CPU
DEBUG 01-14 20:42:16.613693.613693 lmp.py:1625]   Expert 43 |     73 | CPU
DEBUG 01-14 20:42:16.613482.613482 lmp.py:1625]   Expert 47 |     76 | CPU
DEBUG 01-14 20:42:16.613887.613887 lmp.py:1625]   Expert 41 |     79 | CPU
DEBUG 01-14 20:42:16.613245.613245 lmp.py:1625]   Expert 14 |     98 | CPU
DEBUG 01-14 20:42:16.613649.613649 lmp.py:1625]   Expert  0 |     99 | CPU
DEBUG 01-14 20:42:16.613484.613484 lmp.py:1625]   Expert 57 |    100 | CPU
DEBUG 01-14 20:42:16.613366.613366 lmp.py:1625]   Expert 51 |    101 | CPU
DEBUG 01-14 20:42:16.613962.613962 lmp.py:1625]   Expert 26 |    110 | CPU
DEBUG 01-14 20:42:16.613321.613321 lmp.py:1625]   Expert  2 |    111 | CPU
DEBUG 01-14 20:42:16.613348.613348 lmp.py:1625]   Expert 11 |    114 | CPU
DEBUG 01-14 20:42:16.613752.613752 lmp.py:1625]   Expert 33 |    114 | CPU
DEBUG 01-14 20:42:16.613786.613786 lmp.py:1625]   Expert 50 |    115 | CPU
DEBUG 01-14 20:42:16.613714.613714 lmp.py:1625]   Expert 27 |    129 | CPU
DEBUG 01-14 20:42:16.613311.613311 lmp.py:1625]   Expert 55 |    134 | CPU
DEBUG 01-14 20:42:16.613907.613907 lmp.py:1625]   Expert 34 |    148 | CPU
DEBUG 01-14 20:42:16.613458.613458 lmp.py:1625]   Expert 28 |    149 | CPU
DEBUG 01-14 20:42:16.613862.613862 lmp.py:1625]   Expert  9 |    166 | CPU
DEBUG 01-14 20:42:16.613174.613174 lmp.py:1625]   Expert 25 |    168 | CPU
DEBUG 01-14 20:42:16.614765.614765 lmp.py:1625]   Expert 54 |    171 | CPU
DEBUG 01-14 20:42:16.614130.614130 lmp.py:1625]   Expert 13 |    176 | CPU
DEBUG 01-14 20:42:16.614681.614681 lmp.py:1625]   Expert 10 |    180 | CPU
DEBUG 01-14 20:42:16.614754.614754 lmp.py:1625]   Expert 48 |    184 | CPU
DEBUG 01-14 20:42:16.614589.614589 lmp.py:1625]   Expert  6 |    185 | CPU
DEBUG 01-14 20:42:16.614332.614332 lmp.py:1625]   Expert 56 |    185 | CPU
DEBUG 01-14 20:42:16.614882.614882 lmp.py:1625]   Expert  7 |    186 | CPU
DEBUG 01-14 20:42:16.614717.614717 lmp.py:1625]   Expert 46 |    198 | CPU
DEBUG 01-14 20:42:16.614267.614267 lmp.py:1625]   Expert 61 |    201 | GPU
DEBUG 01-14 20:42:16.614056.614056 lmp.py:1625]   Expert 24 |    202 | GPU
DEBUG 01-14 20:42:16.614083.614083 lmp.py:1625]   Expert 29 |    203 | GPU
DEBUG 01-14 20:42:16.614872.614872 lmp.py:1625]   Expert 40 |    204 | GPU
DEBUG 01-14 20:42:16.614330.614330 lmp.py:1625]   Expert 63 |    211 | GPU
DEBUG 01-14 20:42:16.614926.614926 lmp.py:1625]   Expert 42 |    214 | GPU
DEBUG 01-14 20:42:16.614000.614000 lmp.py:1625]   Expert 18 |    216 | GPU
DEBUG 01-14 20:42:16.614358.614358 lmp.py:1625]   Expert 21 |    218 | GPU
DEBUG 01-14 20:42:16.614147.614147 lmp.py:1625]   Expert  1 |    225 | GPU
DEBUG 01-14 20:42:16.614889.614889 lmp.py:1625]   Expert 12 |    225 | GPU
DEBUG 01-14 20:42:16.614486.614486 lmp.py:1625]   Expert 16 |    226 | GPU
DEBUG 01-14 20:42:16.614321.614321 lmp.py:1625]   Expert 22 |    227 | GPU
DEBUG 01-14 20:42:16.614633.614633 lmp.py:1625]   Expert 19 |    230 | GPU
DEBUG 01-14 20:42:16.614706.614706 lmp.py:1625]   Expert  3 |    234 | GPU
DEBUG 01-14 20:42:16.614303.614303 lmp.py:1625]   Expert 32 |    234 | GPU
DEBUG 01-14 20:42:16.614900.614900 lmp.py:1625]   Expert 36 |    235 | GPU
DEBUG 01-14 20:42:16.614688.614688 lmp.py:1625]   Expert 39 |    243 | GPU
DEBUG 01-14 20:42:16.614954.614954 lmp.py:1625]   Expert 59 |    246 | GPU
DEBUG 01-14 20:42:16.614027.614027 lmp.py:1625]   Expert 37 |    252 | GPU
DEBUG 01-14 20:42:16.614624.614624 lmp.py:1625]   Expert  8 |    253 | GPU
DEBUG 01-14 20:42:16.614697.614697 lmp.py:1625]   Expert  5 |    258 | GPU
DEBUG 01-14 20:42:16.614725.614725 lmp.py:1625]   Expert 20 |    262 | GPU
DEBUG 01-14 20:42:16.614990.614990 lmp.py:1625]   Expert 30 |    276 | GPU
DEBUG 01-14 20:42:16.614064.614064 lmp.py:1625]   Expert 62 |    279 | GPU
DEBUG 01-14 20:42:16.614614.614614 lmp.py:1625]   Expert 15 |    295 | GPU
DEBUG 01-14 20:42:16.614164.614164 lmp.py:1625]   Expert 35 |    300 | GPU
DEBUG 01-14 20:42:16.614476.614476 lmp.py:1625]   Expert 17 |    312 | GPU
DEBUG 01-14 20:42:16.614550.614550 lmp.py:1625]   Expert 60 |    333 | GPU
DEBUG 01-14 20:42:16.614815.614815 lmp.py:1625]   Expert 23 |    356 | GPU
DEBUG 01-14 20:42:16.614650.614650 lmp.py:1625]   Expert 52 |    366 | GPU
DEBUG 01-14 20:42:16.614770.614770 lmp.py:1625]   Expert 44 |    397 | GPU
DEBUG 01-14 20:42:16.614890.614890 lmp.py:1625]   Expert 53 |    438 | GPU
DEBUG 01-14 20:42:16.614202.614202 lmp.py:1626] 
DEBUG 01-14 20:42:16.614202.614202 lmp.py:1626]   CPU total tokens: 3917 (31.9%)
DEBUG 01-14 20:42:16.614991.614991 lmp.py:1627]   GPU total tokens: 8371 (68.1%)
DEBUG 01-14 20:42:16.614309.614309 cuda_h.py:19] end experts_map_get cost 0.0017333030700683594 seconds
DEBUG 01-14 20:42:16.614955.614955 mlpmodule.py:1367]  experts func einsum cost 0.06728219985961914 s
DEBUG 01-14 20:42:16.615819.615819 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-14 20:42:16.615674.615674 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-14 20:42:16.615202.615202 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-14 20:42:16.616769.616769 cuda_h.py:19] end allocate_cuda_memory cost 0.0014696121215820312 seconds
DEBUG 01-14 20:42:16.616288.616288 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-14 20:42:16.617713.617713 sllm_store_c.py:27] get device uuid map
DEBUG 01-14 20:42:16.617496.617496 sllm_store_c.py:29] call client load into gpu
DEBUG 01-14 20:42:16.617676.617676 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 4aae1a95-1c3b-4c12-9d46-cdec65e3b05f
DEBUG 01-14 20:42:16.617695.617695 client.py:106] call stub.LoadModelAsync
INFO 01-14 20:42:16.617943.617943 client.py:127] Model loaded
DEBUG 01-14 20:42:16.617587.617587 cuda_h.py:10] start restore2model
DEBUG 01-14 20:42:16.618460.618460 cuda_h.py:19] end restore2model cost 0.00033092498779296875 seconds
DEBUG 01-14 20:42:16.618322.618322 cuda_h.py:19] end sllm_worker_task cost 0.012993812561035156 seconds
INFO 01-14 20:42:16.618773.618773 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 4aae1a95-1c3b-4c12-9d46-cdec65e3b05f
DEBUG 01-14 20:42:16.618338.618338 cuda_h.py:19] end load_into_gpu_async cost 0.0014767646789550781 seconds
DEBUG 01-14 20:42:16.618233.618233 cuda_h.py:10] start restore_tensors2
DEBUG 01-14 20:42:16.618213.618213 cuda_h.py:19] end restore_tensors2 cost 0.0003437995910644531 seconds
DEBUG 01-14 20:42:16.618612.618612 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0036454200744628906 seconds
DEBUG 01-14 20:42:16.618613.618613 cuda_h.py:10] start restore2model
DEBUG 01-14 20:42:16.621077.621077 cuda_h.py:19] end restore2model cost 0.002555370330810547 seconds
DEBUG 01-14 20:42:16.621814.621814 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.0063936710357666016 seconds
DEBUG 01-14 20:42:16.621656.621656 cuda_h.py:10] start gpu_sexperts
DEBUG 01-14 20:42:16.621248.621248 cuda_h.py:19] end gpu_sexperts cost 0.0002663135528564453 seconds
DEBUG 01-14 20:42:16.621594.621594 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-14 20:42:16.622728.622728 lmp.py:1683] 
DEBUG 01-14 20:42:16.622728.622728 lmp.py:1683]   Computing 32 experts on CPU...
DEBUG 01-14 20:42:16.622346.622346 cuda_h.py:19] end cpu_experts_submit cost 5.340576171875e-05 seconds
DEBUG 01-14 20:42:16.622949.622949 cuda_h.py:10] start experts_func_mgpu_group_pad
DEBUG 01-14 20:42:16.638583.638583 mlpmodule.py:1460] group tensors cost 0.01599574089050293 s
DEBUG 01-14 20:42:16.639721.639721 cuda_h.py:10] start move_flat_hidden2cpu
DEBUG 01-14 20:42:16.643775.643775 cuda_h.py:19] end experts_func_mgpu_group_pad cost 0.02143406867980957 seconds
DEBUG 01-14 20:42:16.645797.645797 cuda_h.py:10] start gpu_group_list
DEBUG 01-14 20:42:16.646235.646235 cuda_h.py:19] end gpu_group_list cost 0.0006926059722900391 seconds
DEBUG 01-14 20:42:16.646157.646157 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-14 20:42:16.647579.647579 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 3.4809112548828125e-05 seconds
DEBUG 01-14 20:42:16.647654.647654 cuda_h.py:10] start wait_experts
INFO 01-14 20:42:16.647152.647152 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 4aae1a95-1c3b-4c12-9d46-cdec65e3b05f
DEBUG 01-14 20:42:16.648061.648061 cuda_h.py:19] end move_flat_hidden2cpu cost 0.009275674819946289 seconds
DEBUG 01-14 20:42:16.650165.650165 mlpmodule.py:1533] pad cost 0.0018107891082763672 s
DEBUG 01-14 20:42:16.650930.650930 mlpmodule.py:1539] create cpu tensor cost 3.838539123535156e-05 s
DEBUG 01-14 20:42:16.653593.653593 mlpmodule.py:1544] move to cpu cost 0.0023458003997802734 s
DEBUG 01-14 20:42:16.661673.661673 mlpmodule.py:1558] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-14 20:42:16.661619.661619 mlpmodule.py:1559] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-14 20:42:16.661370.661370 mlpmodule.py:1564] group_w3 first element: -0.02490234375
WARNING 01-14 20:42:16.661170.661170 mlpmodule.py:1574] start einsum2
INFO 01-14 20:42:16.670370.670370 client.py:127] Model loaded
DEBUG 01-14 20:42:16.670429.670429 cuda_h.py:19] end wait_experts cost 0.02329230308532715 seconds
DEBUG 01-14 20:42:16.670722.670722 cuda_h.py:10] start gpu_experts
DEBUG 01-14 20:42:16.670399.670399 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-14 20:42:16.677017.677017 mlpmodule.py:1584] group einsum cost 0.024623632431030273 s
DEBUG 01-14 20:42:16.678892.678892 mlpmodule.py:1593] cpy2cputensor cost 0.0007715225219726562 s
DEBUG 01-14 20:42:16.679921.679921 cuda_h.py:10] start move_outputs
DEBUG 01-14 20:42:16.681853.681853 cuda_h.py:19] end move_outputs cost 0.0023047924041748047 seconds
DEBUG 01-14 20:42:16.685800.685800 cuda_h.py:19] end wait_cetm_experts cost 0.014855623245239258 seconds
DEBUG 01-14 20:42:16.685747.685747 cuda_h.py:10] start gpu_group_einsum_mp_multi_list
DEBUG 01-14 20:42:16.685855.685855 cuda_h.py:10] start gpu_group_tensor
DEBUG 01-14 20:42:16.686890.686890 cuda_h.py:19] end gpu_group_tensor cost 0.00023818016052246094 seconds
DEBUG 01-14 20:42:16.686530.686530 cuda_h.py:10] start gpu_group_einsum
DEBUG 01-14 20:42:16.686369.686369 cuda_h.py:19] end gpu_group_einsum cost 0.0006709098815917969 seconds
DEBUG 01-14 20:42:16.686128.686128 cuda_h.py:10] start gpu_final_hidden_states_scatter
DEBUG 01-14 20:42:16.687747.687747 cuda_h.py:10] start all_expert_outputs_slices
DEBUG 01-14 20:42:16.687992.687992 cuda_h.py:19] end all_expert_outputs_slices cost 0.00035071372985839844 seconds
DEBUG 01-14 20:42:16.687053.687053 cuda_h.py:10] start concat_expert_out
DEBUG 01-14 20:42:16.687612.687612 cuda_h.py:19] end concat_expert_out cost 5.936622619628906e-05 seconds
DEBUG 01-14 20:42:16.687376.687376 cuda_h.py:10] start index_scatter
DEBUG 01-14 20:42:16.687141.687141 cuda_h.py:19] end index_scatter cost 7.224082946777344e-05 seconds
DEBUG 01-14 20:42:16.687143.687143 cuda_h.py:19] end gpu_final_hidden_states_scatter cost 0.0007681846618652344 seconds
DEBUG 01-14 20:42:16.687682.687682 cuda_h.py:19] end gpu_experts cost 0.01735711097717285 seconds
DEBUG 01-14 20:42:16.687192.687192 cuda_h.py:10] start all_expert_weight_slices
DEBUG 01-14 20:42:16.688108.688108 cuda_h.py:19] end all_expert_weight_slices cost 0.0009932518005371094 seconds
DEBUG 01-14 20:42:16.688930.688930 cuda_h.py:10] start cpuoutputsdeal
DEBUG 01-14 20:42:16.689746.689746 cuda_h.py:10] start index_scatter
DEBUG 01-14 20:42:16.689835.689835 cuda_h.py:19] end index_scatter cost 4.9114227294921875e-05 seconds
DEBUG 01-14 20:42:16.689267.689267 cuda_h.py:19] end cpuoutputsdeal cost 0.0005352497100830078 seconds
DEBUG 01-14 20:42:16.689607.689607 cuda_h.py:19] end layer_moe_generate_mp_l_17 cost 0.0772712230682373 seconds
DEBUG 01-14 20:42:16.690449.690449 cuda_h.py:19] end prefill_layer cost 0.08511877059936523 seconds
DEBUG 01-14 20:42:16.690278.690278 lmp.py:1551] -------------------------------- end prefill layer 16 --------------------------------
DEBUG 01-14 20:42:16.690458.690458 cuda_h.py:10] start prefill_layer
DEBUG 01-14 20:42:16.690638.690638 lmp.py:1494] -------------------------------- start prefill layer 17 --------------------------------
DEBUG 01-14 20:42:16.690771.690771 cuda_h.py:10] start start_load_qkvogn_s_weight_l_18
DEBUG 01-14 20:42:16.690812.690812 cuda_h.py:10] start start_load_qkvogn_s_weight_l_18
DEBUG 01-14 20:42:16.690470.690470 cuda_h.py:19] end start_load_qkvogn_s_weight_l_18 cost 3.528594970703125e-05 seconds
DEBUG 01-14 20:42:16.690703.690703 cuda_h.py:19] end start_load_qkvogn_s_weight_l_18 cost 6.914138793945312e-05 seconds
DEBUG 01-14 20:42:16.690983.690983 cuda_h.py:10] start sllm_worker_task
DEBUG 01-14 20:42:16.690011.690011 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-14 20:42:16.690379.690379 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-14 20:42:16.690437.690437 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-14 20:42:16.691242.691242 cuda_h.py:19] end allocate_cuda_memory cost 0.00048089027404785156 seconds
DEBUG 01-14 20:42:16.691319.691319 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-14 20:42:16.691414.691414 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-14 20:42:16.691731.691731 sllm_store_c.py:27] get device uuid map
DEBUG 01-14 20:42:16.691952.691952 sllm_store_c.py:29] call client load into gpu
DEBUG 01-14 20:42:16.691661.691661 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, ebd9c162-900c-4972-bb73-f011eac30b58
DEBUG 01-14 20:42:16.691181.691181 client.py:106] call stub.LoadModelAsync
DEBUG 01-14 20:42:16.696788.696788 cuda_h.py:10] start self_attn
INFO 01-14 20:42:16.697546.697546 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, ebd9c162-900c-4972-bb73-f011eac30b58
DEBUG 01-14 20:42:16.697953.697953 cuda_h.py:19] end load_into_gpu_async cost 0.0060269832611083984 seconds
DEBUG 01-14 20:42:16.697663.697663 cuda_h.py:10] start restore_tensors2
DEBUG 01-14 20:42:16.697090.697090 cuda_h.py:19] end restore_tensors2 cost 7.510185241699219e-05 seconds
DEBUG 01-14 20:42:16.697323.697323 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.007105588912963867 seconds
INFO 01-14 20:42:16.697907.697907 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, ebd9c162-900c-4972-bb73-f011eac30b58
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-14 20:42:16.699829.699829 cuda_h.py:19] end self_attn cost 0.0031197071075439453 seconds
DEBUG 01-14 20:42:16.700740.700740 cuda_h.py:19] end iln_self_attn_paln cost 0.009521722793579102 seconds
DEBUG 01-14 20:42:16.700868.700868 cuda_h.py:10] start layer_moe_generate_mp_l_18
DEBUG 01-14 20:42:16.700770.700770 cuda_h.py:10] start gate
DEBUG 01-14 20:42:16.700190.700190 cuda_h.py:19] end gate cost 0.0006623268127441406 seconds
DEBUG 01-14 20:42:16.700543.700543 cuda_h.py:10] start experts_map_get
DEBUG 01-14 20:42:16.701441.701441 lmp.py:1615] 
DEBUG 01-14 20:42:16.701441.701441 lmp.py:1615] Expert Token Distribution & Device Allocation:
DEBUG 01-14 20:42:16.701150.701150 lmp.py:1616]   Total experts: 64
DEBUG 01-14 20:42:16.701814.701814 lmp.py:1617]   CPU experts: 32 (50%)
DEBUG 01-14 20:42:16.701556.701556 lmp.py:1618]   GPU experts: 32 (50%)
DEBUG 01-14 20:42:16.701961.701961 lmp.py:1619] 
DEBUG 01-14 20:42:16.701961.701961 lmp.py:1619]   Expert ID | Tokens | Device
DEBUG 01-14 20:42:16.701604.701604 lmp.py:1620]   -----------------------------------
DEBUG 01-14 20:42:16.701200.701200 lmp.py:1625]   Expert  4 |     13 | CPU
DEBUG 01-14 20:42:16.701367.701367 lmp.py:1625]   Expert 28 |     37 | CPU
DEBUG 01-14 20:42:16.701817.701817 lmp.py:1625]   Expert  7 |     48 | CPU
DEBUG 01-14 20:42:16.701507.701507 lmp.py:1625]   Expert 53 |     58 | CPU
DEBUG 01-14 20:42:16.701958.701958 lmp.py:1625]   Expert 52 |     67 | CPU
DEBUG 01-14 20:42:16.701885.701885 lmp.py:1625]   Expert 43 |     69 | CPU
DEBUG 01-14 20:42:16.701813.701813 lmp.py:1625]   Expert 49 |     87 | CPU
DEBUG 01-14 20:42:16.701456.701456 lmp.py:1625]   Expert 12 |     93 | CPU
DEBUG 01-14 20:42:16.701145.701145 lmp.py:1625]   Expert 15 |     94 | CPU
DEBUG 01-14 20:42:16.701596.701596 lmp.py:1625]   Expert 60 |    100 | CPU
DEBUG 01-14 20:42:16.701809.701809 lmp.py:1625]   Expert 33 |    104 | CPU
DEBUG 01-14 20:42:16.701929.701929 lmp.py:1625]   Expert  2 |    105 | CPU
DEBUG 01-14 20:42:16.701479.701479 lmp.py:1625]   Expert 47 |    106 | CPU
DEBUG 01-14 20:42:16.701930.701930 lmp.py:1625]   Expert 36 |    110 | CPU
DEBUG 01-14 20:42:16.701573.701573 lmp.py:1625]   Expert  6 |    114 | CPU
DEBUG 01-14 20:42:16.701024.701024 lmp.py:1625]   Expert 25 |    122 | CPU
DEBUG 01-14 20:42:16.701667.701667 lmp.py:1625]   Expert 50 |    124 | CPU
DEBUG 01-14 20:42:16.701071.701071 lmp.py:1625]   Expert 59 |    126 | CPU
DEBUG 01-14 20:42:16.701476.701476 lmp.py:1625]   Expert 30 |    127 | CPU
DEBUG 01-14 20:42:16.701927.701927 lmp.py:1625]   Expert 39 |    129 | CPU
DEBUG 01-14 20:42:16.701901.701901 lmp.py:1625]   Expert 24 |    130 | CPU
DEBUG 01-14 20:42:16.701875.701875 lmp.py:1625]   Expert  8 |    136 | CPU
DEBUG 01-14 20:42:16.701087.701087 lmp.py:1625]   Expert 27 |    138 | CPU
DEBUG 01-14 20:42:16.701300.701300 lmp.py:1625]   Expert  3 |    140 | CPU
DEBUG 01-14 20:42:16.701035.701035 lmp.py:1625]   Expert 14 |    149 | CPU
DEBUG 01-14 20:42:16.701248.701248 lmp.py:1625]   Expert 37 |    149 | CPU
DEBUG 01-14 20:42:16.701460.701460 lmp.py:1625]   Expert 10 |    150 | CPU
DEBUG 01-14 20:42:16.701434.701434 lmp.py:1625]   Expert 32 |    153 | CPU
DEBUG 01-14 20:42:16.701362.701362 lmp.py:1625]   Expert 11 |    154 | CPU
DEBUG 01-14 20:42:16.701290.701290 lmp.py:1625]   Expert 38 |    156 | CPU
DEBUG 01-14 20:42:16.701217.701217 lmp.py:1625]   Expert 58 |    158 | CPU
DEBUG 01-14 20:42:16.701383.701383 lmp.py:1625]   Expert 40 |    160 | CPU
DEBUG 01-14 20:42:16.701311.701311 lmp.py:1625]   Expert 31 |    162 | GPU
DEBUG 01-14 20:42:16.701285.701285 lmp.py:1625]   Expert 19 |    165 | GPU
DEBUG 01-14 20:42:16.701259.701259 lmp.py:1625]   Expert 41 |    165 | GPU
DEBUG 01-14 20:42:16.701233.701233 lmp.py:1625]   Expert 54 |    168 | GPU
DEBUG 01-14 20:42:16.702207.702207 lmp.py:1625]   Expert 61 |    169 | GPU
DEBUG 01-14 20:42:16.702181.702181 lmp.py:1625]   Expert 46 |    171 | GPU
DEBUG 01-14 20:42:16.702155.702155 lmp.py:1625]   Expert 18 |    175 | GPU
DEBUG 01-14 20:42:16.702129.702129 lmp.py:1625]   Expert 22 |    177 | GPU
DEBUG 01-14 20:42:16.702057.702057 lmp.py:1625]   Expert 57 |    177 | GPU
DEBUG 01-14 20:42:16.702985.702985 lmp.py:1625]   Expert 42 |    179 | GPU
DEBUG 01-14 20:42:16.702436.702436 lmp.py:1625]   Expert 56 |    186 | GPU
DEBUG 01-14 20:42:16.702125.702125 lmp.py:1625]   Expert 34 |    190 | GPU
DEBUG 01-14 20:42:16.702053.702053 lmp.py:1625]   Expert 26 |    191 | GPU
DEBUG 01-14 20:42:16.702504.702504 lmp.py:1625]   Expert 44 |    194 | GPU
DEBUG 01-14 20:42:16.702478.702478 lmp.py:1625]   Expert  0 |    209 | GPU
DEBUG 01-14 20:42:16.702452.702452 lmp.py:1625]   Expert  1 |    209 | GPU
DEBUG 01-14 20:42:16.702187.702187 lmp.py:1625]   Expert 20 |    224 | GPU
DEBUG 01-14 20:42:16.702400.702400 lmp.py:1625]   Expert 51 |    225 | GPU
DEBUG 01-14 20:42:16.702612.702612 lmp.py:1625]   Expert 48 |    231 | GPU
DEBUG 01-14 20:42:16.702110.702110 lmp.py:1625]   Expert 45 |    234 | GPU
DEBUG 01-14 20:42:16.702322.702322 lmp.py:1625]   Expert 29 |    236 | GPU
DEBUG 01-14 20:42:16.702011.702011 lmp.py:1625]   Expert 55 |    240 | GPU
DEBUG 01-14 20:42:16.702177.702177 lmp.py:1625]   Expert 35 |    241 | GPU
DEBUG 01-14 20:42:16.702628.702628 lmp.py:1625]   Expert 21 |    242 | GPU
DEBUG 01-14 20:42:16.702318.702318 lmp.py:1625]   Expert 16 |    256 | GPU
DEBUG 01-14 20:42:16.702292.702292 lmp.py:1625]   Expert  5 |    296 | GPU
DEBUG 01-14 20:42:16.702027.702027 lmp.py:1625]   Expert 13 |    369 | GPU
DEBUG 01-14 20:42:16.702763.702763 lmp.py:1625]   Expert 23 |    377 | GPU
DEBUG 01-14 20:42:16.702691.702691 lmp.py:1625]   Expert 17 |    418 | GPU
DEBUG 01-14 20:42:16.702380.702380 lmp.py:1625]   Expert 63 |    472 | GPU
DEBUG 01-14 20:42:16.702069.702069 lmp.py:1625]   Expert  9 |    514 | GPU
DEBUG 01-14 20:42:16.702235.702235 lmp.py:1625]   Expert 62 |   1220 | GPU
DEBUG 01-14 20:42:16.702355.702355 lmp.py:1626] 
DEBUG 01-14 20:42:16.702355.702355 lmp.py:1626]   CPU total tokens: 3606 (29.3%)
DEBUG 01-14 20:42:16.702237.702237 lmp.py:1627]   GPU total tokens: 8682 (70.7%)
DEBUG 01-14 20:42:16.702886.702886 cuda_h.py:19] end experts_map_get cost 0.001523733139038086 seconds
DEBUG 01-14 20:42:16.702736.702736 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-14 20:42:16.702487.702487 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-14 20:42:16.702392.702392 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-14 20:42:16.704115.704115 cuda_h.py:19] end allocate_cuda_memory cost 0.0015881061553955078 seconds
DEBUG 01-14 20:42:16.704872.704872 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-14 20:42:16.704059.704059 sllm_store_c.py:27] get device uuid map
DEBUG 01-14 20:42:16.704974.704974 sllm_store_c.py:29] call client load into gpu
DEBUG 01-14 20:42:16.704200.704200 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, a9963f66-f2e6-4ea4-ae20-47713bc319cd
DEBUG 01-14 20:42:16.704875.704875 client.py:106] call stub.LoadModelAsync
INFO 01-14 20:42:16.704956.704956 client.py:127] Model loaded
DEBUG 01-14 20:42:16.705898.705898 cuda_h.py:10] start restore2model
DEBUG 01-14 20:42:16.705278.705278 cuda_h.py:19] end restore2model cost 0.00041413307189941406 seconds
DEBUG 01-14 20:42:16.705631.705631 cuda_h.py:19] end sllm_worker_task cost 0.015050649642944336 seconds
INFO 01-14 20:42:16.705137.705137 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, a9963f66-f2e6-4ea4-ae20-47713bc319cd
DEBUG 01-14 20:42:16.705848.705848 cuda_h.py:19] end load_into_gpu_async cost 0.0012094974517822266 seconds
DEBUG 01-14 20:42:16.705789.705789 cuda_h.py:10] start restore_tensors2
DEBUG 01-14 20:42:16.706755.706755 cuda_h.py:19] end restore_tensors2 cost 0.0003361701965332031 seconds
DEBUG 01-14 20:42:16.706247.706247 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.003484487533569336 seconds
DEBUG 01-14 20:42:16.706440.706440 cuda_h.py:10] start restore2model
DEBUG 01-14 20:42:16.706465.706465 mlpmodule.py:1367]  experts func einsum cost 0.08432412147521973 s
DEBUG 01-14 20:42:16.709009.709009 cuda_h.py:19] end restore2model cost 0.002905607223510742 seconds
DEBUG 01-14 20:42:16.709899.709899 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.006622791290283203 seconds
DEBUG 01-14 20:42:16.709125.709125 cuda_h.py:10] start gpu_sexperts
DEBUG 01-14 20:42:16.709262.709262 cuda_h.py:19] end gpu_sexperts cost 0.0002791881561279297 seconds
DEBUG 01-14 20:42:16.709468.709468 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-14 20:42:16.709602.709602 lmp.py:1683] 
DEBUG 01-14 20:42:16.709602.709602 lmp.py:1683]   Computing 32 experts on CPU...
DEBUG 01-14 20:42:16.709207.709207 cuda_h.py:19] end cpu_experts_submit cost 6.008148193359375e-05 seconds
DEBUG 01-14 20:42:16.709101.709101 cuda_h.py:10] start experts_func_mgpu_group_pad
DEBUG 01-14 20:42:16.718234.718234 mlpmodule.py:1460] group tensors cost 0.008506298065185547 s
DEBUG 01-14 20:42:16.719455.719455 cuda_h.py:10] start move_flat_hidden2cpu
DEBUG 01-14 20:42:16.723599.723599 cuda_h.py:19] end experts_func_mgpu_group_pad cost 0.013402462005615234 seconds
DEBUG 01-14 20:42:16.724583.724583 cuda_h.py:10] start gpu_group_list
DEBUG 01-14 20:42:16.725671.725671 cuda_h.py:19] end gpu_group_list cost 0.0005533695220947266 seconds
DEBUG 01-14 20:42:16.725255.725255 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-14 20:42:16.725338.725338 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.3603439331054688e-05 seconds
DEBUG 01-14 20:42:16.725584.725584 cuda_h.py:10] start wait_experts
INFO 01-14 20:42:16.725830.725830 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, a9963f66-f2e6-4ea4-ae20-47713bc319cd
DEBUG 01-14 20:42:16.728168.728168 cuda_h.py:19] end move_flat_hidden2cpu cost 0.008745431900024414 seconds
DEBUG 01-14 20:42:16.730445.730445 mlpmodule.py:1533] pad cost 0.0018019676208496094 s
DEBUG 01-14 20:42:16.730117.730117 mlpmodule.py:1539] create cpu tensor cost 3.814697265625e-05 s
DEBUG 01-14 20:42:16.732215.732215 mlpmodule.py:1544] move to cpu cost 0.0018963813781738281 s
DEBUG 01-14 20:42:16.740880.740880 mlpmodule.py:1558] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-14 20:42:16.740834.740834 mlpmodule.py:1559] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-14 20:42:16.740877.740877 mlpmodule.py:1564] group_w3 first element: 0.00457763671875
WARNING 01-14 20:42:16.740246.740246 mlpmodule.py:1574] start einsum2
DEBUG 01-14 20:42:16.756278.756278 mlpmodule.py:1584] group einsum cost 0.02432417869567871 s
DEBUG 01-14 20:42:16.757069.757069 mlpmodule.py:1593] cpy2cputensor cost 0.0006561279296875 s
DEBUG 01-14 20:42:16.757681.757681 cuda_h.py:10] start move_outputs
DEBUG 01-14 20:42:16.760246.760246 cuda_h.py:19] end move_outputs cost 0.0028045177459716797 seconds
INFO 01-14 20:42:16.761564.761564 client.py:127] Model loaded
DEBUG 01-14 20:42:16.761936.761936 cuda_h.py:19] end wait_experts cost 0.035378456115722656 seconds
DEBUG 01-14 20:42:16.761620.761620 cuda_h.py:10] start gpu_experts
DEBUG 01-14 20:42:16.761920.761920 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-14 20:42:16.765296.765296 cuda_h.py:19] end wait_cetm_experts cost 0.0035047531127929688 seconds
DEBUG 01-14 20:42:16.765312.765312 cuda_h.py:10] start gpu_group_einsum_mp_multi_list
DEBUG 01-14 20:42:16.765453.765453 cuda_h.py:10] start gpu_group_tensor
DEBUG 01-14 20:42:16.765005.765005 cuda_h.py:19] end gpu_group_tensor cost 0.00023484230041503906 seconds
DEBUG 01-14 20:42:16.765214.765214 cuda_h.py:10] start gpu_group_einsum
DEBUG 01-14 20:42:16.781256.781256 mlpmodule.py:1367]  experts func einsum cost 0.07128524780273438 s
DEBUG 01-14 20:42:16.781530.781530 cuda_h.py:19] end gpu_group_einsum cost 0.01628422737121582 seconds
DEBUG 01-14 20:42:16.782232.782232 cuda_h.py:10] start gpu_final_hidden_states_scatter
DEBUG 01-14 20:42:16.782214.782214 cuda_h.py:10] start all_expert_outputs_slices
DEBUG 01-14 20:42:16.782210.782210 cuda_h.py:19] end all_expert_outputs_slices cost 0.0002422332763671875 seconds
DEBUG 01-14 20:42:16.782866.782866 cuda_h.py:10] start concat_expert_out
DEBUG 01-14 20:42:16.782386.782386 cuda_h.py:19] end concat_expert_out cost 7.009506225585938e-05 seconds
DEBUG 01-14 20:42:16.782567.782567 cuda_h.py:10] start index_scatter
DEBUG 01-14 20:42:16.782412.782412 cuda_h.py:19] end index_scatter cost 6.556510925292969e-05 seconds
DEBUG 01-14 20:42:16.782406.782406 cuda_h.py:19] end gpu_final_hidden_states_scatter cost 0.0006148815155029297 seconds
DEBUG 01-14 20:42:16.782746.782746 cuda_h.py:19] end gpu_experts cost 0.02134108543395996 seconds
DEBUG 01-14 20:42:16.782158.782158 cuda_h.py:10] start all_expert_weight_slices
DEBUG 01-14 20:42:16.783609.783609 cuda_h.py:19] end all_expert_weight_slices cost 0.0007946491241455078 seconds
DEBUG 01-14 20:42:16.783962.783962 cuda_h.py:10] start cpuoutputsdeal
DEBUG 01-14 20:42:16.784439.784439 cuda_h.py:10] start index_scatter
DEBUG 01-14 20:42:16.784927.784927 cuda_h.py:19] end index_scatter cost 5.53131103515625e-05 seconds
DEBUG 01-14 20:42:16.784034.784034 cuda_h.py:19] end cpuoutputsdeal cost 0.0005481243133544922 seconds
DEBUG 01-14 20:42:16.784050.784050 cuda_h.py:19] end layer_moe_generate_mp_l_18 cost 0.08412671089172363 seconds
DEBUG 01-14 20:42:16.784660.784660 cuda_h.py:19] end prefill_layer cost 0.09460186958312988 seconds
DEBUG 01-14 20:42:16.784404.784404 lmp.py:1551] -------------------------------- end prefill layer 17 --------------------------------
DEBUG 01-14 20:42:16.784729.784729 cuda_h.py:10] start prefill_layer
DEBUG 01-14 20:42:16.784293.784293 lmp.py:1494] -------------------------------- start prefill layer 18 --------------------------------
DEBUG 01-14 20:42:16.784334.784334 cuda_h.py:10] start start_load_qkvogn_s_weight_l_19
DEBUG 01-14 20:42:16.784805.784805 cuda_h.py:10] start start_load_qkvogn_s_weight_l_19
DEBUG 01-14 20:42:16.784463.784463 cuda_h.py:19] end start_load_qkvogn_s_weight_l_19 cost 3.457069396972656e-05 seconds
DEBUG 01-14 20:42:16.785603.785603 cuda_h.py:19] end start_load_qkvogn_s_weight_l_19 cost 7.009506225585938e-05 seconds
DEBUG 01-14 20:42:16.785398.785398 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-14 20:42:16.785308.785308 cuda_h.py:10] start sllm_worker_task
DEBUG 01-14 20:42:16.785459.785459 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-14 20:42:16.785858.785858 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-14 20:42:16.785611.785611 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-14 20:42:16.785931.785931 cuda_h.py:19] end allocate_cuda_memory cost 0.00022530555725097656 seconds
DEBUG 01-14 20:42:16.785358.785358 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-14 20:42:16.785611.785611 sllm_store_c.py:27] get device uuid map
DEBUG 01-14 20:42:16.785256.785256 sllm_store_c.py:29] call client load into gpu
DEBUG 01-14 20:42:16.785919.785919 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 5b868442-a4a0-4947-8e71-c4ae6f5d66da
DEBUG 01-14 20:42:16.786962.786962 client.py:106] call stub.LoadModelAsync
DEBUG 01-14 20:42:16.786311.786311 cuda_h.py:10] start self_attn
INFO 01-14 20:42:16.787710.787710 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 5b868442-a4a0-4947-8e71-c4ae6f5d66da
DEBUG 01-14 20:42:16.787467.787467 cuda_h.py:19] end load_into_gpu_async cost 0.0018239021301269531 seconds
DEBUG 01-14 20:42:16.787654.787654 cuda_h.py:10] start restore_tensors2
DEBUG 01-14 20:42:16.787386.787386 cuda_h.py:19] end restore_tensors2 cost 8.368492126464844e-05 seconds
DEBUG 01-14 20:42:16.787533.787533 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.002459287643432617 seconds
INFO 01-14 20:42:16.787906.787906 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 5b868442-a4a0-4947-8e71-c4ae6f5d66da
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-14 20:42:16.789530.789530 cuda_h.py:19] end self_attn cost 0.003319978713989258 seconds
DEBUG 01-14 20:42:16.790814.790814 cuda_h.py:19] end iln_self_attn_paln cost 0.005046367645263672 seconds
DEBUG 01-14 20:42:16.790240.790240 cuda_h.py:10] start layer_moe_generate_mp_l_19
DEBUG 01-14 20:42:16.790592.790592 cuda_h.py:10] start gate
DEBUG 01-14 20:42:16.791386.791386 cuda_h.py:19] end gate cost 0.0007159709930419922 seconds
DEBUG 01-14 20:42:16.791514.791514 cuda_h.py:10] start experts_map_get
DEBUG 01-14 20:42:16.791785.791785 lmp.py:1615] 
DEBUG 01-14 20:42:16.791785.791785 lmp.py:1615] Expert Token Distribution & Device Allocation:
DEBUG 01-14 20:42:16.791362.791362 lmp.py:1616]   Total experts: 64
DEBUG 01-14 20:42:16.791118.791118 lmp.py:1617]   CPU experts: 32 (50%)
DEBUG 01-14 20:42:16.791583.791583 lmp.py:1618]   GPU experts: 32 (50%)
DEBUG 01-14 20:42:16.791663.791663 lmp.py:1619] 
DEBUG 01-14 20:42:16.791663.791663 lmp.py:1619]   Expert ID | Tokens | Device
DEBUG 01-14 20:42:16.791505.791505 lmp.py:1620]   -----------------------------------
DEBUG 01-14 20:42:16.791062.791062 lmp.py:1625]   Expert 32 |     49 | CPU
DEBUG 01-14 20:42:16.791427.791427 lmp.py:1625]   Expert 30 |     54 | CPU
DEBUG 01-14 20:42:16.791077.791077 lmp.py:1625]   Expert  5 |     56 | CPU
DEBUG 01-14 20:42:16.791203.791203 lmp.py:1625]   Expert 46 |     59 | CPU
DEBUG 01-14 20:42:16.791615.791615 lmp.py:1625]   Expert 12 |     91 | CPU
DEBUG 01-14 20:42:16.791218.791218 lmp.py:1625]   Expert 60 |     99 | CPU
DEBUG 01-14 20:42:16.791583.791583 lmp.py:1625]   Expert 40 |    103 | CPU
DEBUG 01-14 20:42:16.791710.791710 lmp.py:1625]   Expert  8 |    105 | CPU
DEBUG 01-14 20:42:16.791883.791883 lmp.py:1625]   Expert 27 |    107 | CPU
DEBUG 01-14 20:42:16.791817.791817 lmp.py:1625]   Expert 28 |    113 | CPU
DEBUG 01-14 20:42:16.791752.791752 lmp.py:1625]   Expert 17 |    115 | CPU
DEBUG 01-14 20:42:16.791686.791686 lmp.py:1625]   Expert 29 |    115 | CPU
DEBUG 01-14 20:42:16.791813.791813 lmp.py:1625]   Expert 41 |    115 | CPU
DEBUG 01-14 20:42:16.791939.791939 lmp.py:1625]   Expert  3 |    118 | CPU
DEBUG 01-14 20:42:16.791828.791828 lmp.py:1625]   Expert 25 |    120 | CPU
DEBUG 01-14 20:42:16.791193.791193 lmp.py:1625]   Expert 21 |    123 | CPU
DEBUG 01-14 20:42:16.791604.791604 lmp.py:1625]   Expert 35 |    129 | CPU
DEBUG 01-14 20:42:16.792300.792300 lmp.py:1625]   Expert 54 |    130 | CPU
DEBUG 01-14 20:42:16.792711.792711 lmp.py:1625]   Expert  6 |    132 | CPU
DEBUG 01-14 20:42:16.792407.792407 lmp.py:1625]   Expert 58 |    136 | CPU
DEBUG 01-14 20:42:16.792104.792104 lmp.py:1625]   Expert  0 |    142 | CPU
DEBUG 01-14 20:42:16.792515.792515 lmp.py:1625]   Expert 19 |    143 | CPU
DEBUG 01-14 20:42:16.792926.792926 lmp.py:1625]   Expert 37 |    144 | CPU
DEBUG 01-14 20:42:16.792814.792814 lmp.py:1625]   Expert 52 |    152 | CPU
DEBUG 01-14 20:42:16.792464.792464 lmp.py:1625]   Expert 63 |    154 | CPU
DEBUG 01-14 20:42:16.792637.792637 lmp.py:1625]   Expert 53 |    157 | CPU
DEBUG 01-14 20:42:16.792333.792333 lmp.py:1625]   Expert  9 |    158 | CPU
DEBUG 01-14 20:42:16.792268.792268 lmp.py:1625]   Expert 56 |    165 | CPU
DEBUG 01-14 20:42:16.792725.792725 lmp.py:1625]   Expert 48 |    169 | CPU
DEBUG 01-14 20:42:16.792898.792898 lmp.py:1625]   Expert 36 |    170 | CPU
DEBUG 01-14 20:42:16.792594.792594 lmp.py:1625]   Expert  1 |    173 | CPU
DEBUG 01-14 20:42:16.792721.792721 lmp.py:1625]   Expert 59 |    175 | CPU
DEBUG 01-14 20:42:16.792609.792609 lmp.py:1625]   Expert 47 |    189 | GPU
DEBUG 01-14 20:42:16.792736.792736 lmp.py:1625]   Expert 20 |    198 | GPU
DEBUG 01-14 20:42:16.792625.792625 lmp.py:1625]   Expert 39 |    201 | GPU
DEBUG 01-14 20:42:16.792090.792090 lmp.py:1625]   Expert 42 |    205 | GPU
DEBUG 01-14 20:42:16.792978.792978 lmp.py:1625]   Expert 61 |    205 | GPU
DEBUG 01-14 20:42:16.792628.792628 lmp.py:1625]   Expert 34 |    212 | GPU
DEBUG 01-14 20:42:16.792562.792562 lmp.py:1625]   Expert  7 |    217 | GPU
DEBUG 01-14 20:42:16.792973.792973 lmp.py:1625]   Expert 13 |    221 | GPU
DEBUG 01-14 20:42:16.792100.792100 lmp.py:1625]   Expert 11 |    222 | GPU
DEBUG 01-14 20:42:16.792703.792703 lmp.py:1625]   Expert 16 |    222 | GPU
DEBUG 01-14 20:42:16.792307.792307 lmp.py:1625]   Expert 57 |    222 | GPU
DEBUG 01-14 20:42:16.792672.792672 lmp.py:1625]   Expert 18 |    223 | GPU
DEBUG 01-14 20:42:16.792560.792560 lmp.py:1625]   Expert 55 |    233 | GPU
DEBUG 01-14 20:42:16.792495.792495 lmp.py:1625]   Expert  2 |    247 | GPU
DEBUG 01-14 20:42:16.792429.792429 lmp.py:1625]   Expert 49 |    249 | GPU
DEBUG 01-14 20:42:16.792602.792602 lmp.py:1625]   Expert 50 |    249 | GPU
DEBUG 01-14 20:42:16.792775.792775 lmp.py:1625]   Expert 15 |    251 | GPU
DEBUG 01-14 20:42:16.792948.792948 lmp.py:1625]   Expert  4 |    253 | GPU
DEBUG 01-14 20:42:16.792644.792644 lmp.py:1625]   Expert 43 |    253 | GPU
DEBUG 01-14 20:42:16.792340.792340 lmp.py:1625]   Expert 31 |    255 | GPU
DEBUG 01-14 20:42:16.792275.792275 lmp.py:1625]   Expert 51 |    255 | GPU
DEBUG 01-14 20:42:16.792640.792640 lmp.py:1625]   Expert 22 |    257 | GPU
DEBUG 01-14 20:42:16.792243.792243 lmp.py:1625]   Expert 45 |    258 | GPU
DEBUG 01-14 20:42:16.792847.792847 lmp.py:1625]   Expert 33 |    260 | GPU
DEBUG 01-14 20:42:16.792212.792212 lmp.py:1625]   Expert 38 |    277 | GPU
DEBUG 01-14 20:42:16.792384.792384 lmp.py:1625]   Expert 26 |    286 | GPU
DEBUG 01-14 20:42:16.792319.792319 lmp.py:1625]   Expert 44 |    286 | GPU
DEBUG 01-14 20:42:16.792253.792253 lmp.py:1625]   Expert 23 |    290 | GPU
DEBUG 01-14 20:42:16.793426.793426 lmp.py:1625]   Expert 24 |    305 | GPU
DEBUG 01-14 20:42:16.793838.793838 lmp.py:1625]   Expert 14 |    308 | GPU
DEBUG 01-14 20:42:16.793011.793011 lmp.py:1625]   Expert 10 |    310 | GPU
DEBUG 01-14 20:42:16.793184.793184 lmp.py:1625]   Expert 62 |    698 | GPU
DEBUG 01-14 20:42:16.793502.793502 lmp.py:1626] 
DEBUG 01-14 20:42:16.793502.793502 lmp.py:1626]   CPU total tokens: 3971 (32.3%)
DEBUG 01-14 20:42:16.793775.793775 lmp.py:1627]   GPU total tokens: 8317 (67.7%)
DEBUG 01-14 20:42:16.793292.793292 cuda_h.py:19] end experts_map_get cost 0.002046823501586914 seconds
DEBUG 01-14 20:42:16.793732.793732 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-14 20:42:16.793019.793019 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-14 20:42:16.793038.793038 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-14 20:42:16.794459.794459 cuda_h.py:19] end allocate_cuda_memory cost 0.0014667510986328125 seconds
DEBUG 01-14 20:42:16.795063.795063 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-14 20:42:16.795012.795012 sllm_store_c.py:27] get device uuid map
DEBUG 01-14 20:42:16.795013.795013 sllm_store_c.py:29] call client load into gpu
DEBUG 01-14 20:42:16.795047.795047 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, eecbf7cd-583c-4c40-a69f-0547160eb663
DEBUG 01-14 20:42:16.795132.795132 client.py:106] call stub.LoadModelAsync
INFO 01-14 20:42:16.795228.795228 client.py:127] Model loaded
DEBUG 01-14 20:42:16.795091.795091 cuda_h.py:10] start restore2model
DEBUG 01-14 20:42:16.796654.796654 cuda_h.py:19] end restore2model cost 0.0005369186401367188 seconds
DEBUG 01-14 20:42:16.796696.796696 cuda_h.py:19] end sllm_worker_task cost 0.01119852066040039 seconds
INFO 01-14 20:42:16.797394.797394 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, eecbf7cd-583c-4c40-a69f-0547160eb663
DEBUG 01-14 20:42:16.797859.797859 cuda_h.py:19] end load_into_gpu_async cost 0.0023775100708007812 seconds
DEBUG 01-14 20:42:16.797516.797516 cuda_h.py:10] start restore_tensors2
DEBUG 01-14 20:42:16.797945.797945 cuda_h.py:19] end restore_tensors2 cost 0.00032401084899902344 seconds
DEBUG 01-14 20:42:16.797675.797675 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.004529714584350586 seconds
DEBUG 01-14 20:42:16.797915.797915 cuda_h.py:10] start restore2model
DEBUG 01-14 20:42:16.800973.800973 cuda_h.py:19] end restore2model cost 0.0025060176849365234 seconds
DEBUG 01-14 20:42:16.800094.800094 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.007220268249511719 seconds
DEBUG 01-14 20:42:16.800413.800413 cuda_h.py:10] start gpu_sexperts
DEBUG 01-14 20:42:16.800615.800615 cuda_h.py:19] end gpu_sexperts cost 0.0002582073211669922 seconds
DEBUG 01-14 20:42:16.800437.800437 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-14 20:42:16.800663.800663 lmp.py:1683] 
DEBUG 01-14 20:42:16.800663.800663 lmp.py:1683]   Computing 32 experts on CPU...
DEBUG 01-14 20:42:16.800784.800784 cuda_h.py:19] end cpu_experts_submit cost 5.316734313964844e-05 seconds
DEBUG 01-14 20:42:16.800149.800149 cuda_h.py:10] start experts_func_mgpu_group_pad
DEBUG 01-14 20:42:16.809239.809239 mlpmodule.py:1460] group tensors cost 0.007820606231689453 s
DEBUG 01-14 20:42:16.810479.810479 cuda_h.py:10] start move_flat_hidden2cpu
DEBUG 01-14 20:42:16.812617.812617 cuda_h.py:19] end experts_func_mgpu_group_pad cost 0.011804342269897461 seconds
DEBUG 01-14 20:42:16.815445.815445 cuda_h.py:10] start gpu_group_list
DEBUG 01-14 20:42:16.816852.816852 cuda_h.py:19] end gpu_group_list cost 0.0005612373352050781 seconds
DEBUG 01-14 20:42:16.816727.816727 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-14 20:42:16.816691.816691 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.9087066650390625e-05 seconds
DEBUG 01-14 20:42:16.816402.816402 cuda_h.py:10] start wait_experts
INFO 01-14 20:42:16.816841.816841 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, eecbf7cd-583c-4c40-a69f-0547160eb663
DEBUG 01-14 20:42:16.819135.819135 cuda_h.py:19] end move_flat_hidden2cpu cost 0.009411334991455078 seconds
DEBUG 01-14 20:42:16.821961.821961 mlpmodule.py:1533] pad cost 0.0018134117126464844 s
DEBUG 01-14 20:42:16.821687.821687 mlpmodule.py:1539] create cpu tensor cost 4.267692565917969e-05 s
DEBUG 01-14 20:42:16.824168.824168 mlpmodule.py:1544] move to cpu cost 0.0020685195922851562 s
DEBUG 01-14 20:42:16.831283.831283 mlpmodule.py:1558] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-14 20:42:16.831587.831587 mlpmodule.py:1559] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-14 20:42:16.831922.831922 mlpmodule.py:1564] group_w3 first element: 0.0024871826171875
WARNING 01-14 20:42:16.832098.832098 mlpmodule.py:1574] start einsum2
DEBUG 01-14 20:42:16.846585.846585 mlpmodule.py:1584] group einsum cost 0.02223372459411621 s
DEBUG 01-14 20:42:16.847471.847471 mlpmodule.py:1593] cpy2cputensor cost 0.0007066726684570312 s
DEBUG 01-14 20:42:16.847838.847838 cuda_h.py:10] start move_outputs
DEBUG 01-14 20:42:16.850172.850172 cuda_h.py:19] end move_outputs cost 0.0026350021362304688 seconds
INFO 01-14 20:42:16.853194.853194 client.py:127] Model loaded
DEBUG 01-14 20:42:16.853857.853857 cuda_h.py:19] end wait_experts cost 0.03686046600341797 seconds
DEBUG 01-14 20:42:16.853541.853541 cuda_h.py:10] start gpu_experts
DEBUG 01-14 20:42:16.853701.853701 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-14 20:42:16.854704.854704 cuda_h.py:19] end wait_cetm_experts cost 0.0012240409851074219 seconds
DEBUG 01-14 20:42:16.854203.854203 cuda_h.py:10] start gpu_group_einsum_mp_multi_list
DEBUG 01-14 20:42:16.854820.854820 cuda_h.py:10] start gpu_group_tensor
DEBUG 01-14 20:42:16.855287.855287 cuda_h.py:19] end gpu_group_tensor cost 0.00024056434631347656 seconds
DEBUG 01-14 20:42:16.855688.855688 cuda_h.py:10] start gpu_group_einsum
DEBUG 01-14 20:42:16.855196.855196 cuda_h.py:19] end gpu_group_einsum cost 0.0006723403930664062 seconds
DEBUG 01-14 20:42:16.856823.856823 cuda_h.py:10] start gpu_final_hidden_states_scatter
DEBUG 01-14 20:42:16.856918.856918 cuda_h.py:10] start all_expert_outputs_slices
DEBUG 01-14 20:42:16.856310.856310 cuda_h.py:19] end all_expert_outputs_slices cost 0.00038933753967285156 seconds
DEBUG 01-14 20:42:16.856450.856450 cuda_h.py:10] start concat_expert_out
DEBUG 01-14 20:42:16.856248.856248 cuda_h.py:19] end concat_expert_out cost 6.079673767089844e-05 seconds
DEBUG 01-14 20:42:16.856767.856767 cuda_h.py:10] start index_scatter
DEBUG 01-14 20:42:16.856340.856340 cuda_h.py:19] end index_scatter cost 7.271766662597656e-05 seconds
DEBUG 01-14 20:42:16.856911.856911 cuda_h.py:19] end gpu_final_hidden_states_scatter cost 0.0007870197296142578 seconds
DEBUG 01-14 20:42:16.856966.856966 cuda_h.py:19] end gpu_experts cost 0.0035827159881591797 seconds
DEBUG 01-14 20:42:16.857477.857477 cuda_h.py:10] start all_expert_weight_slices
DEBUG 01-14 20:42:16.857350.857350 cuda_h.py:19] end all_expert_weight_slices cost 0.0009224414825439453 seconds
DEBUG 01-14 20:42:16.858027.858027 cuda_h.py:10] start cpuoutputsdeal
DEBUG 01-14 20:42:16.858889.858889 cuda_h.py:10] start index_scatter
DEBUG 01-14 20:42:16.858594.858594 cuda_h.py:19] end index_scatter cost 4.8160552978515625e-05 seconds
DEBUG 01-14 20:42:16.858834.858834 cuda_h.py:19] end cpuoutputsdeal cost 0.0005319118499755859 seconds
DEBUG 01-14 20:42:16.858790.858790 cuda_h.py:19] end layer_moe_generate_mp_l_19 cost 0.06840920448303223 seconds
DEBUG 01-14 20:42:16.859181.859181 cuda_h.py:19] end prefill_layer cost 0.07417702674865723 seconds
DEBUG 01-14 20:42:16.859156.859156 lmp.py:1551] -------------------------------- end prefill layer 18 --------------------------------
DEBUG 01-14 20:42:16.859819.859819 cuda_h.py:10] start prefill_layer
DEBUG 01-14 20:42:16.859668.859668 lmp.py:1494] -------------------------------- start prefill layer 19 --------------------------------
DEBUG 01-14 20:42:16.859801.859801 cuda_h.py:10] start start_load_qkvogn_s_weight_l_20
DEBUG 01-14 20:42:16.859081.859081 cuda_h.py:10] start start_load_qkvogn_s_weight_l_20
DEBUG 01-14 20:42:16.859069.859069 cuda_h.py:19] end start_load_qkvogn_s_weight_l_20 cost 3.3855438232421875e-05 seconds
DEBUG 01-14 20:42:16.859064.859064 cuda_h.py:19] end start_load_qkvogn_s_weight_l_20 cost 6.747245788574219e-05 seconds
DEBUG 01-14 20:42:16.859952.859952 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-14 20:42:16.859908.859908 cuda_h.py:10] start sllm_worker_task
DEBUG 01-14 20:42:16.859736.859736 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-14 20:42:16.859373.859373 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-14 20:42:16.859371.859371 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-14 20:42:16.860398.860398 cuda_h.py:19] end allocate_cuda_memory cost 0.000362396240234375 seconds
DEBUG 01-14 20:42:16.860308.860308 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-14 20:42:16.860978.860978 sllm_store_c.py:27] get device uuid map
DEBUG 01-14 20:42:16.860576.860576 sllm_store_c.py:29] call client load into gpu
DEBUG 01-14 20:42:16.860181.860181 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, f635f8bb-d0f1-40e1-80ff-0dfa5895b66f
DEBUG 01-14 20:42:16.860370.860370 client.py:106] call stub.LoadModelAsync
DEBUG 01-14 20:42:16.860429.860429 cuda_h.py:10] start self_attn
INFO 01-14 20:42:16.861868.861868 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, f635f8bb-d0f1-40e1-80ff-0dfa5895b66f
DEBUG 01-14 20:42:16.861956.861956 cuda_h.py:19] end load_into_gpu_async cost 0.0011415481567382812 seconds
DEBUG 01-14 20:42:16.861712.861712 cuda_h.py:10] start restore_tensors2
DEBUG 01-14 20:42:16.861491.861491 cuda_h.py:19] end restore_tensors2 cost 8.654594421386719e-05 seconds
DEBUG 01-14 20:42:16.861539.861539 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0018687248229980469 seconds
INFO 01-14 20:42:16.861349.861349 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, f635f8bb-d0f1-40e1-80ff-0dfa5895b66f
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-14 20:42:16.864968.864968 cuda_h.py:19] end self_attn cost 0.003765106201171875 seconds
DEBUG 01-14 20:42:16.865965.865965 cuda_h.py:19] end iln_self_attn_paln cost 0.005583524703979492 seconds
DEBUG 01-14 20:42:16.865882.865882 cuda_h.py:10] start layer_moe_generate_mp_l_20
DEBUG 01-14 20:42:16.865075.865075 cuda_h.py:10] start gate
DEBUG 01-14 20:42:16.865569.865569 cuda_h.py:19] end gate cost 0.0006761550903320312 seconds
DEBUG 01-14 20:42:16.865068.865068 cuda_h.py:10] start experts_map_get
DEBUG 01-14 20:42:16.866370.866370 lmp.py:1615] 
DEBUG 01-14 20:42:16.866370.866370 lmp.py:1615] Expert Token Distribution & Device Allocation:
DEBUG 01-14 20:42:16.866848.866848 lmp.py:1616]   Total experts: 64
DEBUG 01-14 20:42:16.866690.866690 lmp.py:1617]   CPU experts: 32 (50%)
DEBUG 01-14 20:42:16.866340.866340 lmp.py:1618]   GPU experts: 32 (50%)
DEBUG 01-14 20:42:16.866698.866698 lmp.py:1619] 
DEBUG 01-14 20:42:16.866698.866698 lmp.py:1619]   Expert ID | Tokens | Device
DEBUG 01-14 20:42:16.866818.866818 lmp.py:1620]   -----------------------------------
DEBUG 01-14 20:42:16.866368.866368 lmp.py:1625]   Expert  1 |     35 | CPU
DEBUG 01-14 20:42:16.866488.866488 lmp.py:1625]   Expert 44 |     50 | CPU
DEBUG 01-14 20:42:16.866084.866084 lmp.py:1625]   Expert 60 |     68 | CPU
DEBUG 01-14 20:42:16.866443.866443 lmp.py:1625]   Expert 28 |     73 | CPU
DEBUG 01-14 20:42:16.866370.866370 lmp.py:1625]   Expert 27 |     90 | CPU
DEBUG 01-14 20:42:16.866881.866881 lmp.py:1625]   Expert 48 |     90 | CPU
DEBUG 01-14 20:42:16.866286.866286 lmp.py:1625]   Expert 62 |     93 | CPU
DEBUG 01-14 20:42:16.866213.866213 lmp.py:1625]   Expert  0 |    102 | CPU
DEBUG 01-14 20:42:16.866618.866618 lmp.py:1625]   Expert 30 |    102 | CPU
DEBUG 01-14 20:42:16.866546.866546 lmp.py:1625]   Expert 22 |    108 | CPU
DEBUG 01-14 20:42:16.866904.866904 lmp.py:1625]   Expert 42 |    115 | CPU
DEBUG 01-14 20:42:16.866116.866116 lmp.py:1625]   Expert 50 |    124 | CPU
DEBUG 01-14 20:42:16.866329.866329 lmp.py:1625]   Expert  8 |    125 | CPU
DEBUG 01-14 20:42:16.866018.866018 lmp.py:1625]   Expert 58 |    125 | CPU
DEBUG 01-14 20:42:16.866661.866661 lmp.py:1625]   Expert 59 |    125 | CPU
DEBUG 01-14 20:42:16.866589.866589 lmp.py:1625]   Expert 12 |    129 | CPU
DEBUG 01-14 20:42:16.866517.866517 lmp.py:1625]   Expert 56 |    141 | CPU
DEBUG 01-14 20:42:16.866444.866444 lmp.py:1625]   Expert 32 |    144 | CPU
DEBUG 01-14 20:42:16.866372.866372 lmp.py:1625]   Expert  5 |    146 | CPU
DEBUG 01-14 20:42:16.866492.866492 lmp.py:1625]   Expert 26 |    149 | CPU
DEBUG 01-14 20:42:16.866420.866420 lmp.py:1625]   Expert 16 |    153 | CPU
DEBUG 01-14 20:42:16.866155.866155 lmp.py:1625]   Expert 34 |    153 | CPU
DEBUG 01-14 20:42:16.866606.866606 lmp.py:1625]   Expert 55 |    153 | CPU
DEBUG 01-14 20:42:16.866580.866580 lmp.py:1625]   Expert  2 |    154 | CPU
DEBUG 01-14 20:42:16.866316.866316 lmp.py:1625]   Expert 19 |    157 | CPU
DEBUG 01-14 20:42:16.866436.866436 lmp.py:1625]   Expert 47 |    159 | CPU
DEBUG 01-14 20:42:16.866840.866840 lmp.py:1625]   Expert 15 |    161 | CPU
DEBUG 01-14 20:42:16.866768.866768 lmp.py:1625]   Expert 13 |    162 | CPU
DEBUG 01-14 20:42:16.866934.866934 lmp.py:1625]   Expert 41 |    167 | CPU
DEBUG 01-14 20:42:16.866862.866862 lmp.py:1625]   Expert 52 |    169 | CPU
DEBUG 01-14 20:42:16.866789.866789 lmp.py:1625]   Expert 25 |    175 | CPU
DEBUG 01-14 20:42:16.866148.866148 lmp.py:1625]   Expert  6 |    176 | CPU
DEBUG 01-14 20:42:16.866075.866075 lmp.py:1625]   Expert 40 |    177 | GPU
DEBUG 01-14 20:42:16.866526.866526 lmp.py:1625]   Expert 18 |    178 | GPU
DEBUG 01-14 20:42:16.867500.867500 lmp.py:1625]   Expert 24 |    178 | GPU
DEBUG 01-14 20:42:16.867951.867951 lmp.py:1625]   Expert 51 |    178 | GPU
DEBUG 01-14 20:42:16.867925.867925 lmp.py:1625]   Expert 20 |    183 | GPU
DEBUG 01-14 20:42:16.867807.867807 lmp.py:1625]   Expert 17 |    185 | GPU
DEBUG 01-14 20:42:16.867211.867211 lmp.py:1625]   Expert 37 |    185 | GPU
DEBUG 01-14 20:42:16.867139.867139 lmp.py:1625]   Expert 54 |    188 | GPU
DEBUG 01-14 20:42:16.867305.867305 lmp.py:1625]   Expert  3 |    189 | GPU
DEBUG 01-14 20:42:16.867994.867994 lmp.py:1625]   Expert 46 |    192 | GPU
DEBUG 01-14 20:42:16.867922.867922 lmp.py:1625]   Expert 11 |    195 | GPU
DEBUG 01-14 20:42:16.867141.867141 lmp.py:1625]   Expert 57 |    197 | GPU
DEBUG 01-14 20:42:16.867453.867453 lmp.py:1625]   Expert 23 |    205 | GPU
DEBUG 01-14 20:42:16.867381.867381 lmp.py:1625]   Expert 43 |    210 | GPU
DEBUG 01-14 20:42:16.867309.867309 lmp.py:1625]   Expert 31 |    219 | GPU
DEBUG 01-14 20:42:16.867283.867283 lmp.py:1625]   Expert 49 |    219 | GPU
DEBUG 01-14 20:42:16.867164.867164 lmp.py:1625]   Expert 35 |    228 | GPU
DEBUG 01-14 20:42:16.867853.867853 lmp.py:1625]   Expert 10 |    229 | GPU
DEBUG 01-14 20:42:16.867304.867304 lmp.py:1625]   Expert 53 |    237 | GPU
DEBUG 01-14 20:42:16.867755.867755 lmp.py:1625]   Expert 36 |    249 | GPU
DEBUG 01-14 20:42:16.867206.867206 lmp.py:1625]   Expert 33 |    252 | GPU
DEBUG 01-14 20:42:16.867418.867418 lmp.py:1625]   Expert 39 |    262 | GPU
DEBUG 01-14 20:42:16.867346.867346 lmp.py:1625]   Expert 38 |    267 | GPU
DEBUG 01-14 20:42:16.867035.867035 lmp.py:1625]   Expert  4 |    303 | GPU
DEBUG 01-14 20:42:16.867963.867963 lmp.py:1625]   Expert 21 |    324 | GPU
DEBUG 01-14 20:42:16.867891.867891 lmp.py:1625]   Expert  9 |    334 | GPU
DEBUG 01-14 20:42:16.867103.867103 lmp.py:1625]   Expert 14 |    346 | GPU
DEBUG 01-14 20:42:16.867223.867223 lmp.py:1625]   Expert 63 |    358 | GPU
DEBUG 01-14 20:42:16.867674.867674 lmp.py:1625]   Expert 45 |    364 | GPU
DEBUG 01-14 20:42:16.867887.867887 lmp.py:1625]   Expert 61 |    390 | GPU
DEBUG 01-14 20:42:16.867861.867861 lmp.py:1625]   Expert 29 |    478 | GPU
DEBUG 01-14 20:42:16.867835.867835 lmp.py:1625]   Expert  7 |    516 | GPU
DEBUG 01-14 20:42:16.867001.867001 lmp.py:1626] 
DEBUG 01-14 20:42:16.867001.867001 lmp.py:1626]   CPU total tokens: 4073 (33.1%)
DEBUG 01-14 20:42:16.867551.867551 lmp.py:1627]   GPU total tokens: 8215 (66.9%)
DEBUG 01-14 20:42:16.867962.867962 cuda_h.py:19] end experts_map_get cost 0.001577615737915039 seconds
DEBUG 01-14 20:42:16.867627.867627 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-14 20:42:16.867331.867331 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-14 20:42:16.867713.867713 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-14 20:42:16.869000.869000 cuda_h.py:19] end allocate_cuda_memory cost 0.0020012855529785156 seconds
DEBUG 01-14 20:42:16.869308.869308 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-14 20:42:16.869686.869686 sllm_store_c.py:27] get device uuid map
DEBUG 01-14 20:42:16.870949.870949 sllm_store_c.py:29] call client load into gpu
DEBUG 01-14 20:42:16.870996.870996 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 8d0471d6-6246-4347-a9e5-f11d3bb1e0aa
DEBUG 01-14 20:42:16.870824.870824 client.py:106] call stub.LoadModelAsync
INFO 01-14 20:42:16.870286.870286 client.py:127] Model loaded
DEBUG 01-14 20:42:16.870117.870117 cuda_h.py:10] start restore2model
DEBUG 01-14 20:42:16.870618.870618 mlpmodule.py:1367]  experts func einsum cost 0.06940627098083496 s
INFO 01-14 20:42:16.871153.871153 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 8d0471d6-6246-4347-a9e5-f11d3bb1e0aa
DEBUG 01-14 20:42:16.871666.871666 cuda_h.py:19] end restore2model cost 0.0007445812225341797 seconds
DEBUG 01-14 20:42:16.871616.871616 cuda_h.py:19] end load_into_gpu_async cost 0.0014526844024658203 seconds
DEBUG 01-14 20:42:16.871809.871809 cuda_h.py:19] end sllm_worker_task cost 0.011848926544189453 seconds
DEBUG 01-14 20:42:16.871976.871976 cuda_h.py:10] start restore_tensors2
DEBUG 01-14 20:42:16.871428.871428 cuda_h.py:19] end restore_tensors2 cost 0.0003495216369628906 seconds
DEBUG 01-14 20:42:16.872503.872503 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0043163299560546875 seconds
DEBUG 01-14 20:42:16.872650.872650 cuda_h.py:10] start restore2model
DEBUG 01-14 20:42:16.874737.874737 cuda_h.py:19] end restore2model cost 0.0025610923767089844 seconds
DEBUG 01-14 20:42:16.874288.874288 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.0070574283599853516 seconds
DEBUG 01-14 20:42:16.874945.874945 cuda_h.py:10] start gpu_sexperts
DEBUG 01-14 20:42:16.875650.875650 cuda_h.py:19] end gpu_sexperts cost 0.0002751350402832031 seconds
DEBUG 01-14 20:42:16.875070.875070 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-14 20:42:16.875918.875918 lmp.py:1683] 
DEBUG 01-14 20:42:16.875918.875918 lmp.py:1683]   Computing 32 experts on CPU...
DEBUG 01-14 20:42:16.875662.875662 cuda_h.py:19] end cpu_experts_submit cost 5.7220458984375e-05 seconds
DEBUG 01-14 20:42:16.875795.875795 cuda_h.py:10] start experts_func_mgpu_group_pad
DEBUG 01-14 20:42:16.880933.880933 mlpmodule.py:1460] group tensors cost 0.004525423049926758 s
DEBUG 01-14 20:42:16.880260.880260 cuda_h.py:10] start move_flat_hidden2cpu
DEBUG 01-14 20:42:16.883699.883699 cuda_h.py:19] end experts_func_mgpu_group_pad cost 0.007740974426269531 seconds
DEBUG 01-14 20:42:16.884958.884958 cuda_h.py:10] start gpu_group_list
DEBUG 01-14 20:42:16.884015.884015 cuda_h.py:19] end gpu_group_list cost 0.0004086494445800781 seconds
DEBUG 01-14 20:42:16.885928.885928 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-14 20:42:16.885276.885276 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.4318695068359375e-05 seconds
DEBUG 01-14 20:42:16.885337.885337 cuda_h.py:10] start wait_experts
INFO 01-14 20:42:16.885623.885623 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 8d0471d6-6246-4347-a9e5-f11d3bb1e0aa
DEBUG 01-14 20:42:16.887438.887438 cuda_h.py:19] end move_flat_hidden2cpu cost 0.006617069244384766 seconds
DEBUG 01-14 20:42:16.889893.889893 mlpmodule.py:1533] pad cost 0.0017867088317871094 s
DEBUG 01-14 20:42:16.889996.889996 mlpmodule.py:1539] create cpu tensor cost 3.8623809814453125e-05 s
DEBUG 01-14 20:42:16.891259.891259 mlpmodule.py:1544] move to cpu cost 0.002081155776977539 s
DEBUG 01-14 20:42:16.899384.899384 mlpmodule.py:1558] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-14 20:42:16.900476.900476 mlpmodule.py:1559] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-14 20:42:16.900063.900063 mlpmodule.py:1564] group_w3 first element: -0.0034942626953125
WARNING 01-14 20:42:16.900478.900478 mlpmodule.py:1574] start einsum2
DEBUG 01-14 20:42:16.924361.924361 mlpmodule.py:1584] group einsum cost 0.03281545639038086 s
INFO 01-14 20:42:16.925240.925240 client.py:127] Model loaded
DEBUG 01-14 20:42:16.925869.925869 mlpmodule.py:1593] cpy2cputensor cost 0.0010745525360107422 s
DEBUG 01-14 20:42:16.926702.926702 cuda_h.py:19] end wait_experts cost 0.04068636894226074 seconds
DEBUG 01-14 20:42:16.926380.926380 cuda_h.py:10] start move_outputs
DEBUG 01-14 20:42:16.926715.926715 cuda_h.py:10] start gpu_experts
DEBUG 01-14 20:42:16.926489.926489 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-14 20:42:16.928852.928852 cuda_h.py:19] end move_outputs cost 0.0025358200073242188 seconds
DEBUG 01-14 20:42:16.939987.939987 cuda_h.py:19] end wait_cetm_experts cost 0.012850284576416016 seconds
DEBUG 01-14 20:42:16.939289.939289 cuda_h.py:10] start gpu_group_einsum_mp_multi_list
DEBUG 01-14 20:42:16.939052.939052 cuda_h.py:10] start gpu_group_tensor
DEBUG 01-14 20:42:16.939273.939273 cuda_h.py:19] end gpu_group_tensor cost 0.0002338886260986328 seconds
DEBUG 01-14 20:42:16.939337.939337 cuda_h.py:10] start gpu_group_einsum
DEBUG 01-14 20:42:16.940975.940975 cuda_h.py:19] end gpu_group_einsum cost 0.0006282329559326172 seconds
DEBUG 01-14 20:42:16.940874.940874 cuda_h.py:10] start gpu_final_hidden_states_scatter
DEBUG 01-14 20:42:16.940962.940962 cuda_h.py:10] start all_expert_outputs_slices
DEBUG 01-14 20:42:16.941383.941383 cuda_h.py:19] end all_expert_outputs_slices cost 0.00027489662170410156 seconds
DEBUG 01-14 20:42:16.941192.941192 cuda_h.py:10] start concat_expert_out
DEBUG 01-14 20:42:16.941395.941395 cuda_h.py:19] end concat_expert_out cost 7.62939453125e-05 seconds
DEBUG 01-14 20:42:16.941337.941337 cuda_h.py:10] start index_scatter
DEBUG 01-14 20:42:16.941758.941758 cuda_h.py:19] end index_scatter cost 6.937980651855469e-05 seconds
DEBUG 01-14 20:42:16.941613.941613 cuda_h.py:19] end gpu_final_hidden_states_scatter cost 0.0006749629974365234 seconds
DEBUG 01-14 20:42:16.941828.941828 cuda_h.py:19] end gpu_experts cost 0.015088796615600586 seconds
DEBUG 01-14 20:42:16.941286.941286 cuda_h.py:10] start all_expert_weight_slices
DEBUG 01-14 20:42:16.942028.942028 cuda_h.py:19] end all_expert_weight_slices cost 0.0007650852203369141 seconds
DEBUG 01-14 20:42:16.942228.942228 cuda_h.py:10] start cpuoutputsdeal
DEBUG 01-14 20:42:16.942352.942352 cuda_h.py:10] start index_scatter
DEBUG 01-14 20:42:16.942050.942050 cuda_h.py:19] end index_scatter cost 4.673004150390625e-05 seconds
DEBUG 01-14 20:42:16.942290.942290 cuda_h.py:19] end cpuoutputsdeal cost 0.0004413127899169922 seconds
DEBUG 01-14 20:42:16.942001.942001 cuda_h.py:19] end layer_moe_generate_mp_l_20 cost 0.07768750190734863 seconds
DEBUG 01-14 20:42:16.943740.943740 cuda_h.py:19] end prefill_layer cost 0.08403873443603516 seconds
DEBUG 01-14 20:42:16.943378.943378 lmp.py:1551] -------------------------------- end prefill layer 19 --------------------------------
DEBUG 01-14 20:42:16.943551.943551 cuda_h.py:10] start prefill_layer
DEBUG 01-14 20:42:16.943962.943962 lmp.py:1494] -------------------------------- start prefill layer 20 --------------------------------
DEBUG 01-14 20:42:16.943850.943850 cuda_h.py:10] start start_load_qkvogn_s_weight_l_21
DEBUG 01-14 20:42:16.943361.943361 cuda_h.py:10] start start_load_qkvogn_s_weight_l_21
DEBUG 01-14 20:42:16.943051.943051 cuda_h.py:19] end start_load_qkvogn_s_weight_l_21 cost 2.956390380859375e-05 seconds
DEBUG 01-14 20:42:16.943708.943708 cuda_h.py:19] end start_load_qkvogn_s_weight_l_21 cost 5.9604644775390625e-05 seconds
DEBUG 01-14 20:42:16.943020.943020 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-14 20:42:16.943360.943360 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-14 20:42:16.943899.943899 cuda_h.py:10] start sllm_worker_task
DEBUG 01-14 20:42:16.943135.943135 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-14 20:42:16.943031.943031 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-14 20:42:16.944195.944195 cuda_h.py:19] end allocate_cuda_memory cost 0.0005016326904296875 seconds
DEBUG 01-14 20:42:16.944489.944489 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-14 20:42:16.944205.944205 sllm_store_c.py:27] get device uuid map
DEBUG 01-14 20:42:16.944558.944558 sllm_store_c.py:29] call client load into gpu
DEBUG 01-14 20:42:16.944453.944453 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 03d66325-1784-4898-9443-13921bf5d4b1
DEBUG 01-14 20:42:16.944661.944661 client.py:106] call stub.LoadModelAsync
DEBUG 01-14 20:42:16.944009.944009 cuda_h.py:10] start self_attn
INFO 01-14 20:42:16.945554.945554 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 03d66325-1784-4898-9443-13921bf5d4b1
DEBUG 01-14 20:42:16.945867.945867 cuda_h.py:19] end load_into_gpu_async cost 0.001190185546875 seconds
DEBUG 01-14 20:42:16.945617.945617 cuda_h.py:10] start restore_tensors2
DEBUG 01-14 20:42:16.945229.945229 cuda_h.py:19] end restore_tensors2 cost 7.390975952148438e-05 seconds
DEBUG 01-14 20:42:16.945032.945032 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.002026081085205078 seconds
INFO 01-14 20:42:16.945484.945484 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 03d66325-1784-4898-9443-13921bf5d4b1
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-14 20:42:16.947138.947138 cuda_h.py:19] end self_attn cost 0.0029811859130859375 seconds
DEBUG 01-14 20:42:16.948710.948710 cuda_h.py:19] end iln_self_attn_paln cost 0.0047643184661865234 seconds
DEBUG 01-14 20:42:16.948454.948454 cuda_h.py:10] start layer_moe_generate_mp_l_21
DEBUG 01-14 20:42:16.948548.948548 cuda_h.py:10] start gate
DEBUG 01-14 20:42:16.949724.949724 cuda_h.py:19] end gate cost 0.0006940364837646484 seconds
DEBUG 01-14 20:42:16.949839.949839 cuda_h.py:10] start experts_map_get
DEBUG 01-14 20:42:16.949982.949982 lmp.py:1615] 
DEBUG 01-14 20:42:16.949982.949982 lmp.py:1615] Expert Token Distribution & Device Allocation:
DEBUG 01-14 20:42:16.949360.949360 lmp.py:1616]   Total experts: 64
DEBUG 01-14 20:42:16.949725.949725 lmp.py:1617]   CPU experts: 32 (50%)
DEBUG 01-14 20:42:16.949468.949468 lmp.py:1618]   GPU experts: 32 (50%)
DEBUG 01-14 20:42:16.949587.949587 lmp.py:1619] 
DEBUG 01-14 20:42:16.949587.949587 lmp.py:1619]   Expert ID | Tokens | Device
DEBUG 01-14 20:42:16.949422.949422 lmp.py:1620]   -----------------------------------
DEBUG 01-14 20:42:16.949019.949019 lmp.py:1625]   Expert 54 |     25 | CPU
DEBUG 01-14 20:42:16.949616.949616 lmp.py:1625]   Expert 28 |     38 | CPU
DEBUG 01-14 20:42:16.949259.949259 lmp.py:1625]   Expert  3 |     40 | CPU
DEBUG 01-14 20:42:16.949140.949140 lmp.py:1625]   Expert  8 |     43 | CPU
DEBUG 01-14 20:42:16.949545.949545 lmp.py:1625]   Expert 43 |     53 | CPU
DEBUG 01-14 20:42:16.949472.949472 lmp.py:1625]   Expert 63 |     62 | CPU
DEBUG 01-14 20:42:16.949162.949162 lmp.py:1625]   Expert 38 |     79 | CPU
DEBUG 01-14 20:42:16.949328.949328 lmp.py:1625]   Expert  6 |     80 | CPU
DEBUG 01-14 20:42:16.949494.949494 lmp.py:1625]   Expert 57 |     84 | CPU
DEBUG 01-14 20:42:16.949422.949422 lmp.py:1625]   Expert 39 |     87 | CPU
DEBUG 01-14 20:42:16.949588.949588 lmp.py:1625]   Expert 36 |     93 | CPU
DEBUG 01-14 20:42:16.949516.949516 lmp.py:1625]   Expert 41 |     98 | CPU
DEBUG 01-14 20:42:16.949682.949682 lmp.py:1625]   Expert 12 |    101 | CPU
DEBUG 01-14 20:42:16.949609.949609 lmp.py:1625]   Expert 47 |    108 | CPU
DEBUG 01-14 20:42:16.949060.949060 lmp.py:1625]   Expert 19 |    112 | CPU
DEBUG 01-14 20:42:16.949465.949465 lmp.py:1625]   Expert 52 |    112 | CPU
DEBUG 01-14 20:42:16.949393.949393 lmp.py:1625]   Expert 13 |    127 | CPU
DEBUG 01-14 20:42:16.949036.949036 lmp.py:1625]   Expert 46 |    137 | CPU
DEBUG 01-14 20:42:16.949440.949440 lmp.py:1625]   Expert 22 |    141 | CPU
DEBUG 01-14 20:42:16.949136.949136 lmp.py:1625]   Expert 40 |    144 | CPU
DEBUG 01-14 20:42:16.949779.949779 lmp.py:1625]   Expert 50 |    149 | CPU
DEBUG 01-14 20:42:16.949707.949707 lmp.py:1625]   Expert  2 |    150 | CPU
DEBUG 01-14 20:42:16.949396.949396 lmp.py:1625]   Expert 20 |    162 | CPU
DEBUG 01-14 20:42:16.949324.949324 lmp.py:1625]   Expert 37 |    164 | CPU
DEBUG 01-14 20:42:16.949013.949013 lmp.py:1625]   Expert 53 |    165 | CPU
DEBUG 01-14 20:42:16.949941.949941 lmp.py:1625]   Expert 23 |    168 | CPU
DEBUG 01-14 20:42:16.950630.950630 lmp.py:1625]   Expert 55 |    170 | CPU
DEBUG 01-14 20:42:16.950558.950558 lmp.py:1625]   Expert 14 |    172 | CPU
DEBUG 01-14 20:42:16.950009.950009 lmp.py:1625]   Expert 24 |    174 | CPU
DEBUG 01-14 20:42:16.950413.950413 lmp.py:1625]   Expert 21 |    176 | CPU
DEBUG 01-14 20:42:16.950580.950580 lmp.py:1625]   Expert 61 |    176 | CPU
DEBUG 01-14 20:42:16.950507.950507 lmp.py:1625]   Expert 42 |    184 | CPU
DEBUG 01-14 20:42:16.950627.950627 lmp.py:1625]   Expert  5 |    187 | GPU
DEBUG 01-14 20:42:16.950508.950508 lmp.py:1625]   Expert  0 |    188 | GPU
DEBUG 01-14 20:42:16.950151.950151 lmp.py:1625]   Expert 49 |    195 | GPU
DEBUG 01-14 20:42:16.950794.950794 lmp.py:1625]   Expert 18 |    197 | GPU
DEBUG 01-14 20:42:16.950437.950437 lmp.py:1625]   Expert 32 |    198 | GPU
DEBUG 01-14 20:42:16.950365.950365 lmp.py:1625]   Expert 16 |    201 | GPU
DEBUG 01-14 20:42:16.950293.950293 lmp.py:1625]   Expert 33 |    201 | GPU
DEBUG 01-14 20:42:16.950459.950459 lmp.py:1625]   Expert 34 |    201 | GPU
DEBUG 01-14 20:42:16.950910.950910 lmp.py:1625]   Expert 30 |    206 | GPU
DEBUG 01-14 20:42:16.950076.950076 lmp.py:1625]   Expert  7 |    207 | GPU
DEBUG 01-14 20:42:16.950242.950242 lmp.py:1625]   Expert 31 |    214 | GPU
DEBUG 01-14 20:42:16.950408.950408 lmp.py:1625]   Expert 59 |    215 | GPU
DEBUG 01-14 20:42:16.950336.950336 lmp.py:1625]   Expert 62 |    216 | GPU
DEBUG 01-14 20:42:16.950979.950979 lmp.py:1625]   Expert  9 |    219 | GPU
DEBUG 01-14 20:42:16.950622.950622 lmp.py:1625]   Expert 10 |    223 | GPU
DEBUG 01-14 20:42:16.950503.950503 lmp.py:1625]   Expert 60 |    226 | GPU
DEBUG 01-14 20:42:16.950146.950146 lmp.py:1625]   Expert 15 |    228 | GPU
DEBUG 01-14 20:42:16.950551.950551 lmp.py:1625]   Expert  4 |    231 | GPU
DEBUG 01-14 20:42:16.950240.950240 lmp.py:1625]   Expert 58 |    235 | GPU
DEBUG 01-14 20:42:16.950168.950168 lmp.py:1625]   Expert 17 |    238 | GPU
DEBUG 01-14 20:42:16.950096.950096 lmp.py:1625]   Expert 29 |    240 | GPU
DEBUG 01-14 20:42:16.950262.950262 lmp.py:1625]   Expert 26 |    250 | GPU
DEBUG 01-14 20:42:16.950951.950951 lmp.py:1625]   Expert 51 |    270 | GPU
DEBUG 01-14 20:42:16.950879.950879 lmp.py:1625]   Expert 44 |    272 | GPU
DEBUG 01-14 20:42:16.950429.950429 lmp.py:1625]   Expert 11 |    279 | GPU
DEBUG 01-14 20:42:16.950549.950549 lmp.py:1625]   Expert 56 |    284 | GPU
DEBUG 01-14 20:42:16.950430.950430 lmp.py:1625]   Expert 27 |    297 | GPU
DEBUG 01-14 20:42:16.950596.950596 lmp.py:1625]   Expert  1 |    342 | GPU
DEBUG 01-14 20:42:16.950478.950478 lmp.py:1625]   Expert 45 |    371 | GPU
DEBUG 01-14 20:42:16.950882.950882 lmp.py:1625]   Expert 25 |    450 | GPU
DEBUG 01-14 20:42:16.950810.950810 lmp.py:1625]   Expert 35 |    518 | GPU
DEBUG 01-14 20:42:16.950261.950261 lmp.py:1625]   Expert 48 |    715 | GPU
DEBUG 01-14 20:42:16.950381.950381 lmp.py:1626] 
DEBUG 01-14 20:42:16.950381.950381 lmp.py:1626]   CPU total tokens: 3774 (30.7%)
DEBUG 01-14 20:42:16.950501.950501 lmp.py:1627]   GPU total tokens: 8514 (69.3%)
DEBUG 01-14 20:42:16.950197.950197 cuda_h.py:19] end experts_map_get cost 0.001569986343383789 seconds
DEBUG 01-14 20:42:16.950616.950616 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-14 20:42:16.950029.950029 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-14 20:42:16.950589.950589 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-14 20:42:16.953313.953313 cuda_h.py:19] end allocate_cuda_memory cost 0.0020096302032470703 seconds
DEBUG 01-14 20:42:16.953971.953971 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-14 20:42:16.953204.953204 sllm_store_c.py:27] get device uuid map
DEBUG 01-14 20:42:16.953920.953920 sllm_store_c.py:29] call client load into gpu
DEBUG 01-14 20:42:16.953716.953716 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 8536a964-7aeb-4fd8-9d85-a9ee316b09ee
DEBUG 01-14 20:42:16.953132.953132 client.py:106] call stub.LoadModelAsync
DEBUG 01-14 20:42:16.953800.953800 mlpmodule.py:1367]  experts func einsum cost 0.0778968334197998 s
INFO 01-14 20:42:16.953309.953309 client.py:127] Model loaded
DEBUG 01-14 20:42:16.953103.953103 cuda_h.py:10] start restore2model
DEBUG 01-14 20:42:16.954289.954289 cuda_h.py:19] end restore2model cost 0.0003597736358642578 seconds
INFO 01-14 20:42:16.954325.954325 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 8536a964-7aeb-4fd8-9d85-a9ee316b09ee
DEBUG 01-14 20:42:16.954798.954798 cuda_h.py:19] end sllm_worker_task cost 0.010711431503295898 seconds
DEBUG 01-14 20:42:16.954787.954787 cuda_h.py:19] end load_into_gpu_async cost 0.0013720989227294922 seconds
DEBUG 01-14 20:42:16.954557.954557 cuda_h.py:10] start restore_tensors2
DEBUG 01-14 20:42:16.954583.954583 cuda_h.py:19] end restore_tensors2 cost 0.0003407001495361328 seconds
DEBUG 01-14 20:42:16.954843.954843 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.004123210906982422 seconds
DEBUG 01-14 20:42:16.955321.955321 cuda_h.py:10] start restore2model
DEBUG 01-14 20:42:16.957957.957957 cuda_h.py:19] end restore2model cost 0.0025463104248046875 seconds
DEBUG 01-14 20:42:16.957469.957469 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.0068399906158447266 seconds
DEBUG 01-14 20:42:16.957046.957046 cuda_h.py:10] start gpu_sexperts
DEBUG 01-14 20:42:16.957785.957785 cuda_h.py:19] end gpu_sexperts cost 0.0002689361572265625 seconds
DEBUG 01-14 20:42:16.958343.958343 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-14 20:42:16.958477.958477 lmp.py:1683] 
DEBUG 01-14 20:42:16.958477.958477 lmp.py:1683]   Computing 32 experts on CPU...
DEBUG 01-14 20:42:16.958266.958266 cuda_h.py:19] end cpu_experts_submit cost 5.602836608886719e-05 seconds
DEBUG 01-14 20:42:16.958300.958300 cuda_h.py:10] start experts_func_mgpu_group_pad
DEBUG 01-14 20:42:16.967524.967524 mlpmodule.py:1460] group tensors cost 0.009053230285644531 s
DEBUG 01-14 20:42:16.968921.968921 cuda_h.py:10] start move_flat_hidden2cpu
DEBUG 01-14 20:42:16.973042.973042 cuda_h.py:19] end experts_func_mgpu_group_pad cost 0.015746593475341797 seconds
DEBUG 01-14 20:42:16.975766.975766 cuda_h.py:19] end move_flat_hidden2cpu cost 0.006752729415893555 seconds
DEBUG 01-14 20:42:16.977088.977088 cuda_h.py:10] start gpu_group_list
DEBUG 01-14 20:42:16.978547.978547 cuda_h.py:19] end gpu_group_list cost 0.0007026195526123047 seconds
DEBUG 01-14 20:42:16.978583.978583 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-14 20:42:16.978865.978865 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 3.552436828613281e-05 seconds
DEBUG 01-14 20:42:16.978324.978324 cuda_h.py:10] start wait_experts
INFO 01-14 20:42:16.978538.978538 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 8536a964-7aeb-4fd8-9d85-a9ee316b09ee
DEBUG 01-14 20:42:16.979303.979303 mlpmodule.py:1533] pad cost 0.003854036331176758 s
DEBUG 01-14 20:42:16.979957.979957 mlpmodule.py:1539] create cpu tensor cost 4.5299530029296875e-05 s
DEBUG 01-14 20:42:16.981249.981249 mlpmodule.py:1544] move to cpu cost 0.0021784305572509766 s
DEBUG 01-14 20:42:16.989622.989622 mlpmodule.py:1558] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-14 20:42:16.989124.989124 mlpmodule.py:1559] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-14 20:42:16.989737.989737 mlpmodule.py:1564] group_w3 first element: 0.039306640625
WARNING 01-14 20:42:16.989397.989397 mlpmodule.py:1574] start einsum2
DEBUG 01-14 20:42:17.005463.005463 mlpmodule.py:1584] group einsum cost 0.02331376075744629 s
DEBUG 01-14 20:42:17.006846.006846 mlpmodule.py:1593] cpy2cputensor cost 0.0007262229919433594 s
DEBUG 01-14 20:42:17.006053.006053 cuda_h.py:10] start move_outputs
DEBUG 01-14 20:42:17.008845.008845 cuda_h.py:19] end move_outputs cost 0.002657651901245117 seconds
INFO 01-14 20:42:17.010970.010970 client.py:127] Model loaded
DEBUG 01-14 20:42:17.010143.010143 cuda_h.py:19] end wait_experts cost 0.03188824653625488 seconds
DEBUG 01-14 20:42:17.010681.010681 cuda_h.py:10] start gpu_experts
DEBUG 01-14 20:42:17.010742.010742 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-14 20:42:17.013162.013162 cuda_h.py:19] end wait_cetm_experts cost 0.0032203197479248047 seconds
DEBUG 01-14 20:42:17.014847.014847 cuda_h.py:10] start gpu_group_einsum_mp_multi_list
DEBUG 01-14 20:42:17.014179.014179 cuda_h.py:10] start gpu_group_tensor
DEBUG 01-14 20:42:17.014115.014115 cuda_h.py:19] end gpu_group_tensor cost 0.00023746490478515625 seconds
DEBUG 01-14 20:42:17.014755.014755 cuda_h.py:10] start gpu_group_einsum
DEBUG 01-14 20:42:17.015553.015553 cuda_h.py:19] end gpu_group_einsum cost 0.000640869140625 seconds
DEBUG 01-14 20:42:17.015936.015936 cuda_h.py:10] start gpu_final_hidden_states_scatter
DEBUG 01-14 20:42:17.015739.015739 cuda_h.py:10] start all_expert_outputs_slices
DEBUG 01-14 20:42:17.015255.015255 cuda_h.py:19] end all_expert_outputs_slices cost 0.0003414154052734375 seconds
DEBUG 01-14 20:42:17.015224.015224 cuda_h.py:10] start concat_expert_out
DEBUG 01-14 20:42:17.015876.015876 cuda_h.py:19] end concat_expert_out cost 5.793571472167969e-05 seconds
DEBUG 01-14 20:42:17.015679.015679 cuda_h.py:10] start index_scatter
DEBUG 01-14 20:42:17.016199.016199 cuda_h.py:19] end index_scatter cost 6.937980651855469e-05 seconds
DEBUG 01-14 20:42:17.016532.016532 cuda_h.py:19] end gpu_final_hidden_states_scatter cost 0.0007424354553222656 seconds
DEBUG 01-14 20:42:17.016011.016011 cuda_h.py:19] end gpu_experts cost 0.005479097366333008 seconds
DEBUG 01-14 20:42:17.016952.016952 cuda_h.py:10] start all_expert_weight_slices
DEBUG 01-14 20:42:17.017880.017880 cuda_h.py:19] end all_expert_weight_slices cost 0.0009686946868896484 seconds
DEBUG 01-14 20:42:17.017848.017848 cuda_h.py:10] start cpuoutputsdeal
DEBUG 01-14 20:42:17.017372.017372 cuda_h.py:10] start index_scatter
DEBUG 01-14 20:42:17.017501.017501 cuda_h.py:19] end index_scatter cost 4.76837158203125e-05 seconds
DEBUG 01-14 20:42:17.017933.017933 cuda_h.py:19] end cpuoutputsdeal cost 0.0005211830139160156 seconds
DEBUG 01-14 20:42:17.017379.017379 cuda_h.py:19] end layer_moe_generate_mp_l_21 cost 0.06954193115234375 seconds
DEBUG 01-14 20:42:17.018750.018750 cuda_h.py:19] end prefill_layer cost 0.07494401931762695 seconds
DEBUG 01-14 20:42:17.018672.018672 lmp.py:1551] -------------------------------- end prefill layer 20 --------------------------------
DEBUG 01-14 20:42:17.018851.018851 cuda_h.py:10] start prefill_layer
DEBUG 01-14 20:42:17.018270.018270 lmp.py:1494] -------------------------------- start prefill layer 21 --------------------------------
DEBUG 01-14 20:42:17.018403.018403 cuda_h.py:10] start start_load_qkvogn_s_weight_l_22
DEBUG 01-14 20:42:17.018967.018967 cuda_h.py:10] start start_load_qkvogn_s_weight_l_22
DEBUG 01-14 20:42:17.018911.018911 cuda_h.py:19] end start_load_qkvogn_s_weight_l_22 cost 7.033348083496094e-05 seconds
DEBUG 01-14 20:42:17.018866.018866 cuda_h.py:19] end start_load_qkvogn_s_weight_l_22 cost 0.000110626220703125 seconds
DEBUG 01-14 20:42:17.018092.018092 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-14 20:42:17.018670.018670 cuda_h.py:10] start sllm_worker_task
DEBUG 01-14 20:42:17.018503.018503 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-14 20:42:17.018525.018525 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-14 20:42:17.019358.019358 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-14 20:42:17.032717.032717 cuda_h.py:19] end allocate_cuda_memory cost 0.013605833053588867 seconds
DEBUG 01-14 20:42:17.032002.032002 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-14 20:42:17.032078.032078 sllm_store_c.py:27] get device uuid map
DEBUG 01-14 20:42:17.033359.033359 sllm_store_c.py:29] call client load into gpu
DEBUG 01-14 20:42:17.033547.033547 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 8fb1f6c7-53a6-47a0-83d9-2c0d128fe19f
DEBUG 01-14 20:42:17.033533.033533 client.py:106] call stub.LoadModelAsync
DEBUG 01-14 20:42:17.033078.033078 cuda_h.py:10] start self_attn
INFO 01-14 20:42:17.034575.034575 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 8fb1f6c7-53a6-47a0-83d9-2c0d128fe19f
DEBUG 01-14 20:42:17.034500.034500 cuda_h.py:19] end load_into_gpu_async cost 0.0019261837005615234 seconds
DEBUG 01-14 20:42:17.034489.034489 cuda_h.py:10] start restore_tensors2
DEBUG 01-14 20:42:17.035323.035323 cuda_h.py:19] end restore_tensors2 cost 0.00013136863708496094 seconds
DEBUG 01-14 20:42:17.035849.035849 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.016252756118774414 seconds
INFO 01-14 20:42:17.035893.035893 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 8fb1f6c7-53a6-47a0-83d9-2c0d128fe19f
DEBUG 01-14 20:42:17.038469.038469 mlpmodule.py:1367]  experts func einsum cost 0.07981538772583008 s
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-14 20:42:17.041961.041961 cuda_h.py:19] end self_attn cost 0.0074388980865478516 seconds
DEBUG 01-14 20:42:17.042597.042597 cuda_h.py:19] end iln_self_attn_paln cost 0.023737668991088867 seconds
DEBUG 01-14 20:42:17.042284.042284 cuda_h.py:10] start layer_moe_generate_mp_l_22
DEBUG 01-14 20:42:17.042427.042427 cuda_h.py:10] start gate
INFO 01-14 20:42:17.042567.042567 client.py:127] Model loaded
DEBUG 01-14 20:42:17.042168.042168 cuda_h.py:10] start restore2model
DEBUG 01-14 20:42:17.044526.044526 cuda_h.py:19] end restore2model cost 0.0011174678802490234 seconds
DEBUG 01-14 20:42:17.044021.044021 cuda_h.py:19] end sllm_worker_task cost 0.025507211685180664 seconds
DEBUG 01-14 20:42:17.045860.045860 cuda_h.py:19] end gate cost 0.002957582473754883 seconds
DEBUG 01-14 20:42:17.045136.045136 cuda_h.py:10] start experts_map_get
DEBUG 01-14 20:42:17.046245.046245 lmp.py:1615] 
DEBUG 01-14 20:42:17.046245.046245 lmp.py:1615] Expert Token Distribution & Device Allocation:
DEBUG 01-14 20:42:17.046513.046513 lmp.py:1616]   Total experts: 64
DEBUG 01-14 20:42:17.046516.046516 lmp.py:1617]   CPU experts: 32 (50%)
DEBUG 01-14 20:42:17.046174.046174 lmp.py:1618]   GPU experts: 32 (50%)
DEBUG 01-14 20:42:17.046917.046917 lmp.py:1619] 
DEBUG 01-14 20:42:17.046917.046917 lmp.py:1619]   Expert ID | Tokens | Device
DEBUG 01-14 20:42:17.047138.047138 lmp.py:1620]   -----------------------------------
DEBUG 01-14 20:42:17.047312.047312 lmp.py:1625]   Expert 44 |     38 | CPU
DEBUG 01-14 20:42:17.047579.047579 lmp.py:1625]   Expert 11 |     41 | CPU
DEBUG 01-14 20:42:17.047892.047892 lmp.py:1625]   Expert  9 |     47 | CPU
DEBUG 01-14 20:42:17.047251.047251 lmp.py:1625]   Expert 54 |     64 | CPU
DEBUG 01-14 20:42:17.047895.047895 lmp.py:1625]   Expert 56 |     66 | CPU
DEBUG 01-14 20:42:17.047347.047347 lmp.py:1625]   Expert 51 |     92 | CPU
DEBUG 01-14 20:42:17.047561.047561 lmp.py:1625]   Expert 62 |     98 | CPU
DEBUG 01-14 20:42:17.047775.047775 lmp.py:1625]   Expert 47 |     99 | CPU
DEBUG 01-14 20:42:17.047320.047320 lmp.py:1625]   Expert 22 |    101 | CPU
DEBUG 01-14 20:42:17.047353.047353 lmp.py:1625]   Expert 60 |    103 | CPU
DEBUG 01-14 20:42:17.047387.047387 lmp.py:1625]   Expert 52 |    105 | CPU
DEBUG 01-14 20:42:17.047183.047183 lmp.py:1625]   Expert 41 |    107 | CPU
DEBUG 01-14 20:42:17.047932.047932 lmp.py:1625]   Expert  7 |    109 | CPU
DEBUG 01-14 20:42:17.047728.047728 lmp.py:1625]   Expert 35 |    109 | CPU
DEBUG 01-14 20:42:17.047523.047523 lmp.py:1625]   Expert  8 |    114 | CPU
DEBUG 01-14 20:42:17.047557.047557 lmp.py:1625]   Expert 48 |    122 | CPU
DEBUG 01-14 20:42:17.047830.047830 lmp.py:1625]   Expert 53 |    124 | CPU
DEBUG 01-14 20:42:17.047863.047863 lmp.py:1625]   Expert  6 |    125 | CPU
DEBUG 01-14 20:42:17.047897.047897 lmp.py:1625]   Expert  1 |    126 | CPU
DEBUG 01-14 20:42:17.047931.047931 lmp.py:1625]   Expert  2 |    129 | CPU
DEBUG 01-14 20:42:17.047204.047204 lmp.py:1625]   Expert 32 |    136 | CPU
DEBUG 01-14 20:42:17.047238.047238 lmp.py:1625]   Expert 59 |    137 | CPU
DEBUG 01-14 20:42:17.047272.047272 lmp.py:1625]   Expert 23 |    138 | CPU
DEBUG 01-14 20:42:17.047067.047067 lmp.py:1625]   Expert 27 |    138 | CPU
DEBUG 01-14 20:42:17.047863.047863 lmp.py:1625]   Expert 14 |    143 | CPU
DEBUG 01-14 20:42:17.047897.047897 lmp.py:1625]   Expert 26 |    145 | CPU
DEBUG 01-14 20:42:17.047699.047699 lmp.py:1625]   Expert 39 |    149 | CPU
DEBUG 01-14 20:42:17.048879.048879 lmp.py:1625]   Expert 50 |    149 | CPU
DEBUG 01-14 20:42:17.048820.048820 lmp.py:1625]   Expert 49 |    154 | CPU
DEBUG 01-14 20:42:17.048092.048092 lmp.py:1625]   Expert 34 |    161 | CPU
DEBUG 01-14 20:42:17.048365.048365 lmp.py:1625]   Expert 38 |    165 | CPU
DEBUG 01-14 20:42:17.048876.048876 lmp.py:1625]   Expert 24 |    171 | CPU
DEBUG 01-14 20:42:17.048386.048386 lmp.py:1625]   Expert  4 |    176 | GPU
DEBUG 01-14 20:42:17.048659.048659 lmp.py:1625]   Expert 57 |    180 | GPU
DEBUG 01-14 20:42:17.048931.048931 lmp.py:1625]   Expert 40 |    182 | GPU
DEBUG 01-14 20:42:17.048349.048349 lmp.py:1625]   Expert  0 |    190 | GPU
DEBUG 01-14 20:42:17.048529.048529 lmp.py:1625]   Expert 46 |    191 | GPU
DEBUG 01-14 20:42:17.048947.048947 lmp.py:1625]   Expert 43 |    192 | GPU
DEBUG 01-14 20:42:17.048219.048219 lmp.py:1625]   Expert 61 |    193 | GPU
DEBUG 01-14 20:42:17.048730.048730 lmp.py:1625]   Expert 13 |    195 | GPU
DEBUG 01-14 20:42:17.048526.048526 lmp.py:1625]   Expert 19 |    196 | GPU
DEBUG 01-14 20:42:17.048560.048560 lmp.py:1625]   Expert 63 |    197 | GPU
DEBUG 01-14 20:42:17.048369.048369 lmp.py:1625]   Expert 29 |    207 | GPU
DEBUG 01-14 20:42:17.048641.048641 lmp.py:1625]   Expert  5 |    208 | GPU
DEBUG 01-14 20:42:17.048914.048914 lmp.py:1625]   Expert 31 |    213 | GPU
DEBUG 01-14 20:42:17.048948.048948 lmp.py:1625]   Expert 33 |    221 | GPU
DEBUG 01-14 20:42:17.048041.048041 lmp.py:1625]   Expert 16 |    241 | GPU
DEBUG 01-14 20:42:17.048936.048936 lmp.py:1625]   Expert 37 |    242 | GPU
DEBUG 01-14 20:42:17.048401.048401 lmp.py:1625]   Expert 20 |    250 | GPU
DEBUG 01-14 20:42:17.048912.048912 lmp.py:1625]   Expert  3 |    259 | GPU
DEBUG 01-14 20:42:17.048707.048707 lmp.py:1625]   Expert 36 |    266 | GPU
DEBUG 01-14 20:42:17.048741.048741 lmp.py:1625]   Expert 15 |    279 | GPU
DEBUG 01-14 20:42:17.048537.048537 lmp.py:1625]   Expert 18 |    283 | GPU
DEBUG 01-14 20:42:17.048332.048332 lmp.py:1625]   Expert 17 |    306 | GPU
DEBUG 01-14 20:42:17.048366.048366 lmp.py:1625]   Expert 12 |    310 | GPU
DEBUG 01-14 20:42:17.048162.048162 lmp.py:1625]   Expert 30 |    315 | GPU
DEBUG 01-14 20:42:17.048434.048434 lmp.py:1625]   Expert 28 |    321 | GPU
DEBUG 01-14 20:42:17.048991.048991 lmp.py:1625]   Expert 55 |    326 | GPU
DEBUG 01-14 20:42:17.048025.048025 lmp.py:1625]   Expert 58 |    334 | GPU
DEBUG 01-14 20:42:17.048728.048728 lmp.py:1625]   Expert 25 |    372 | GPU
DEBUG 01-14 20:42:17.048669.048669 lmp.py:1625]   Expert 10 |    375 | GPU
DEBUG 01-14 20:42:17.048895.048895 lmp.py:1625]   Expert 45 |    380 | GPU
DEBUG 01-14 20:42:17.048644.048644 lmp.py:1625]   Expert 21 |    387 | GPU
DEBUG 01-14 20:42:17.048678.048678 lmp.py:1625]   Expert 42 |    596 | GPU
DEBUG 01-14 20:42:17.048381.048381 lmp.py:1626] 
DEBUG 01-14 20:42:17.048381.048381 lmp.py:1626]   CPU total tokens: 3705 (30.2%)
DEBUG 01-14 20:42:17.049084.049084 lmp.py:1627]   GPU total tokens: 8583 (69.8%)
DEBUG 01-14 20:42:17.049178.049178 cuda_h.py:19] end experts_map_get cost 0.003147602081298828 seconds
DEBUG 01-14 20:42:17.049870.049870 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-14 20:42:17.049654.049654 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-14 20:42:17.049091.049091 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-14 20:42:17.049108.049108 cuda_h.py:19] end allocate_cuda_memory cost 0.00028133392333984375 seconds
DEBUG 01-14 20:42:17.049594.049594 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-14 20:42:17.049079.049079 sllm_store_c.py:27] get device uuid map
DEBUG 01-14 20:42:17.049240.049240 sllm_store_c.py:29] call client load into gpu
DEBUG 01-14 20:42:17.049618.049618 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 4c02fb98-4a36-4efe-8c14-f96e05f5dde9
DEBUG 01-14 20:42:17.050328.050328 client.py:106] call stub.LoadModelAsync
INFO 01-14 20:42:17.052137.052137 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 4c02fb98-4a36-4efe-8c14-f96e05f5dde9
DEBUG 01-14 20:42:17.052563.052563 cuda_h.py:19] end load_into_gpu_async cost 0.0023903846740722656 seconds
DEBUG 01-14 20:42:17.052280.052280 cuda_h.py:10] start restore_tensors2
DEBUG 01-14 20:42:17.052350.052350 cuda_h.py:19] end restore_tensors2 cost 0.0004696846008300781 seconds
DEBUG 01-14 20:42:17.052683.052683 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0035991668701171875 seconds
DEBUG 01-14 20:42:17.052797.052797 cuda_h.py:10] start restore2model
DEBUG 01-14 20:42:17.056238.056238 cuda_h.py:19] end restore2model cost 0.0038297176361083984 seconds
DEBUG 01-14 20:42:17.056718.056718 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.007674455642700195 seconds
DEBUG 01-14 20:42:17.056626.056626 cuda_h.py:10] start gpu_sexperts
DEBUG 01-14 20:42:17.057754.057754 cuda_h.py:19] end gpu_sexperts cost 0.000400543212890625 seconds
DEBUG 01-14 20:42:17.057173.057173 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-14 20:42:17.057611.057611 lmp.py:1683] 
DEBUG 01-14 20:42:17.057611.057611 lmp.py:1683]   Computing 32 experts on CPU...
DEBUG 01-14 20:42:17.057780.057780 cuda_h.py:19] end cpu_experts_submit cost 8.96453857421875e-05 seconds
DEBUG 01-14 20:42:17.057450.057450 cuda_h.py:10] start experts_func_mgpu_group_pad
DEBUG 01-14 20:42:17.075699.075699 mlpmodule.py:1460] group tensors cost 0.016828298568725586 s
DEBUG 01-14 20:42:17.076426.076426 cuda_h.py:10] start move_flat_hidden2cpu
DEBUG 01-14 20:42:17.081763.081763 cuda_h.py:19] end experts_func_mgpu_group_pad cost 0.02428269386291504 seconds
DEBUG 01-14 20:42:17.082407.082407 cuda_h.py:19] end move_flat_hidden2cpu cost 0.006886720657348633 seconds
DEBUG 01-14 20:42:17.085211.085211 cuda_h.py:10] start gpu_group_list
DEBUG 01-14 20:42:17.087908.087908 cuda_h.py:19] end gpu_group_list cost 0.0011966228485107422 seconds
DEBUG 01-14 20:42:17.087884.087884 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-14 20:42:17.087526.087526 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.5033950805664062e-05 seconds
DEBUG 01-14 20:42:17.087965.087965 cuda_h.py:10] start wait_experts
INFO 01-14 20:42:17.088350.088350 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 4c02fb98-4a36-4efe-8c14-f96e05f5dde9
DEBUG 01-14 20:42:17.088990.088990 mlpmodule.py:1533] pad cost 0.00516510009765625 s
DEBUG 01-14 20:42:17.088042.088042 mlpmodule.py:1539] create cpu tensor cost 4.863739013671875e-05 s
DEBUG 01-14 20:42:17.090204.090204 mlpmodule.py:1544] move to cpu cost 0.0020308494567871094 s
DEBUG 01-14 20:42:17.098557.098557 mlpmodule.py:1558] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-14 20:42:17.098026.098026 mlpmodule.py:1559] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-14 20:42:17.098592.098592 mlpmodule.py:1564] group_w3 first element: 0.00066375732421875
WARNING 01-14 20:42:17.098206.098206 mlpmodule.py:1574] start einsum2
INFO 01-14 20:42:17.104824.104824 client.py:127] Model loaded
DEBUG 01-14 20:42:17.104089.104089 cuda_h.py:19] end wait_experts cost 0.01650071144104004 seconds
DEBUG 01-14 20:42:17.104997.104997 cuda_h.py:10] start gpu_experts
DEBUG 01-14 20:42:17.104727.104727 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-14 20:42:17.112703.112703 mlpmodule.py:1584] group einsum cost 0.02152395248413086 s
DEBUG 01-14 20:42:17.113648.113648 mlpmodule.py:1593] cpy2cputensor cost 0.0007314682006835938 s
DEBUG 01-14 20:42:17.113862.113862 cuda_h.py:10] start move_outputs
DEBUG 01-14 20:42:17.115023.115023 cuda_h.py:19] end move_outputs cost 0.002016305923461914 seconds
DEBUG 01-14 20:42:17.123254.123254 cuda_h.py:19] end wait_cetm_experts cost 0.01901531219482422 seconds
DEBUG 01-14 20:42:17.123824.123824 cuda_h.py:10] start gpu_group_einsum_mp_multi_list
DEBUG 01-14 20:42:17.123985.123985 cuda_h.py:10] start gpu_group_tensor
DEBUG 01-14 20:42:17.124027.124027 cuda_h.py:19] end gpu_group_tensor cost 0.0002422332763671875 seconds
DEBUG 01-14 20:42:17.124528.124528 cuda_h.py:10] start gpu_group_einsum
DEBUG 01-14 20:42:17.125065.125065 cuda_h.py:19] end gpu_group_einsum cost 0.0007188320159912109 seconds
DEBUG 01-14 20:42:17.125514.125514 cuda_h.py:10] start gpu_final_hidden_states_scatter
DEBUG 01-14 20:42:17.125086.125086 cuda_h.py:10] start all_expert_outputs_slices
DEBUG 01-14 20:42:17.125861.125861 cuda_h.py:19] end all_expert_outputs_slices cost 0.00035691261291503906 seconds
DEBUG 01-14 20:42:17.125140.125140 cuda_h.py:10] start concat_expert_out
DEBUG 01-14 20:42:17.125554.125554 cuda_h.py:19] end concat_expert_out cost 5.793571472167969e-05 seconds
DEBUG 01-14 20:42:17.126596.126596 cuda_h.py:10] start index_scatter
DEBUG 01-14 20:42:17.126785.126785 cuda_h.py:19] end index_scatter cost 7.05718994140625e-05 seconds
DEBUG 01-14 20:42:17.126879.126879 cuda_h.py:19] end gpu_final_hidden_states_scatter cost 0.0007433891296386719 seconds
DEBUG 01-14 20:42:17.126272.126272 cuda_h.py:19] end gpu_experts cost 0.021626949310302734 seconds
DEBUG 01-14 20:42:17.126313.126313 cuda_h.py:10] start all_expert_weight_slices
DEBUG 01-14 20:42:17.127353.127353 cuda_h.py:19] end all_expert_weight_slices cost 0.000978708267211914 seconds
DEBUG 01-14 20:42:17.127276.127276 cuda_h.py:10] start cpuoutputsdeal
DEBUG 01-14 20:42:17.127992.127992 cuda_h.py:10] start index_scatter
DEBUG 01-14 20:42:17.127220.127220 cuda_h.py:19] end index_scatter cost 4.839897155761719e-05 seconds
DEBUG 01-14 20:42:17.127606.127606 cuda_h.py:19] end cpuoutputsdeal cost 0.0005292892456054688 seconds
DEBUG 01-14 20:42:17.127138.127138 cuda_h.py:19] end layer_moe_generate_mp_l_22 cost 0.0853424072265625 seconds
DEBUG 01-14 20:42:17.128540.128540 cuda_h.py:19] end prefill_layer cost 0.10992097854614258 seconds
DEBUG 01-14 20:42:17.128416.128416 lmp.py:1551] -------------------------------- end prefill layer 21 --------------------------------
DEBUG 01-14 20:42:17.128019.128019 cuda_h.py:10] start prefill_layer
DEBUG 01-14 20:42:17.128861.128861 lmp.py:1494] -------------------------------- start prefill layer 22 --------------------------------
DEBUG 01-14 20:42:17.128154.128154 cuda_h.py:10] start start_load_qkvogn_s_weight_l_23
DEBUG 01-14 20:42:17.128525.128525 cuda_h.py:10] start start_load_qkvogn_s_weight_l_23
DEBUG 01-14 20:42:17.128422.128422 cuda_h.py:19] end start_load_qkvogn_s_weight_l_23 cost 3.8623809814453125e-05 seconds
DEBUG 01-14 20:42:17.128648.128648 cuda_h.py:19] end start_load_qkvogn_s_weight_l_23 cost 6.794929504394531e-05 seconds
DEBUG 01-14 20:42:17.128536.128536 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-14 20:42:17.128955.128955 cuda_h.py:10] start sllm_worker_task
DEBUG 01-14 20:42:17.128999.128999 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-14 20:42:17.128730.128730 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-14 20:42:17.128900.128900 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-14 20:42:17.130650.130650 cuda_h.py:19] end allocate_cuda_memory cost 0.0011789798736572266 seconds
DEBUG 01-14 20:42:17.130844.130844 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-14 20:42:17.130654.130654 sllm_store_c.py:27] get device uuid map
DEBUG 01-14 20:42:17.130642.130642 sllm_store_c.py:29] call client load into gpu
DEBUG 01-14 20:42:17.130822.130822 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 277bb464-0a1e-457b-816d-b4063a0f4cb9
DEBUG 01-14 20:42:17.130322.130322 client.py:106] call stub.LoadModelAsync
DEBUG 01-14 20:42:17.130018.130018 mlpmodule.py:1367]  experts func einsum cost 0.07248401641845703 s
DEBUG 01-14 20:42:17.131573.131573 cuda_h.py:10] start self_attn
INFO 01-14 20:42:17.132122.132122 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 277bb464-0a1e-457b-816d-b4063a0f4cb9
DEBUG 01-14 20:42:17.132680.132680 cuda_h.py:19] end load_into_gpu_async cost 0.0017728805541992188 seconds
DEBUG 01-14 20:42:17.132144.132144 cuda_h.py:10] start restore_tensors2
DEBUG 01-14 20:42:17.132611.132611 cuda_h.py:19] end restore_tensors2 cost 7.152557373046875e-05 seconds
DEBUG 01-14 20:42:17.132513.132513 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0032842159271240234 seconds
INFO 01-14 20:42:17.132052.132052 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 277bb464-0a1e-457b-816d-b4063a0f4cb9
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-14 20:42:17.134874.134874 cuda_h.py:19] end self_attn cost 0.0029561519622802734 seconds
DEBUG 01-14 20:42:17.134837.134837 cuda_h.py:19] end iln_self_attn_paln cost 0.0058100223541259766 seconds
DEBUG 01-14 20:42:17.134178.134178 cuda_h.py:10] start layer_moe_generate_mp_l_23
DEBUG 01-14 20:42:17.134563.134563 cuda_h.py:10] start gate
DEBUG 01-14 20:42:17.135526.135526 cuda_h.py:19] end gate cost 0.0006399154663085938 seconds
DEBUG 01-14 20:42:17.135355.135355 cuda_h.py:10] start experts_map_get
DEBUG 01-14 20:42:17.135300.135300 lmp.py:1615] 
DEBUG 01-14 20:42:17.135300.135300 lmp.py:1615] Expert Token Distribution & Device Allocation:
DEBUG 01-14 20:42:17.135248.135248 lmp.py:1616]   Total experts: 64
DEBUG 01-14 20:42:17.135613.135613 lmp.py:1617]   CPU experts: 32 (50%)
DEBUG 01-14 20:42:17.135878.135878 lmp.py:1618]   GPU experts: 32 (50%)
DEBUG 01-14 20:42:17.135998.135998 lmp.py:1619] 
DEBUG 01-14 20:42:17.135998.135998 lmp.py:1619]   Expert ID | Tokens | Device
DEBUG 01-14 20:42:17.135879.135879 lmp.py:1620]   -----------------------------------
DEBUG 01-14 20:42:17.135298.135298 lmp.py:1625]   Expert 25 |     15 | CPU
DEBUG 01-14 20:42:17.135848.135848 lmp.py:1625]   Expert 45 |     31 | CPU
DEBUG 01-14 20:42:17.135014.135014 lmp.py:1625]   Expert 48 |     37 | CPU
DEBUG 01-14 20:42:17.135134.135134 lmp.py:1625]   Expert  9 |     64 | CPU
DEBUG 01-14 20:42:17.135777.135777 lmp.py:1625]   Expert 43 |     71 | CPU
DEBUG 01-14 20:42:17.135374.135374 lmp.py:1625]   Expert 54 |     73 | CPU
DEBUG 01-14 20:42:17.135493.135493 lmp.py:1625]   Expert 50 |     86 | CPU
DEBUG 01-14 20:42:17.135421.135421 lmp.py:1625]   Expert 47 |     88 | CPU
DEBUG 01-14 20:42:17.135587.135587 lmp.py:1625]   Expert  6 |     90 | CPU
DEBUG 01-14 20:42:17.135992.135992 lmp.py:1625]   Expert  0 |     92 | CPU
DEBUG 01-14 20:42:17.135873.135873 lmp.py:1625]   Expert  1 |     99 | CPU
DEBUG 01-14 20:42:17.135231.135231 lmp.py:1625]   Expert 15 |     99 | CPU
DEBUG 01-14 20:42:17.135828.135828 lmp.py:1625]   Expert 62 |     99 | CPU
DEBUG 01-14 20:42:17.135948.135948 lmp.py:1625]   Expert 20 |    102 | CPU
DEBUG 01-14 20:42:17.135737.135737 lmp.py:1625]   Expert 13 |    103 | CPU
DEBUG 01-14 20:42:17.135141.135141 lmp.py:1625]   Expert 61 |    106 | CPU
DEBUG 01-14 20:42:17.135069.135069 lmp.py:1625]   Expert 36 |    110 | CPU
DEBUG 01-14 20:42:17.135473.135473 lmp.py:1625]   Expert 57 |    115 | CPU
DEBUG 01-14 20:42:17.136401.136401 lmp.py:1625]   Expert 46 |    120 | CPU
DEBUG 01-14 20:42:17.136998.136998 lmp.py:1625]   Expert 21 |    121 | CPU
DEBUG 01-14 20:42:17.136641.136641 lmp.py:1625]   Expert 37 |    121 | CPU
DEBUG 01-14 20:42:17.136999.136999 lmp.py:1625]   Expert 38 |    124 | CPU
DEBUG 01-14 20:42:17.136404.136404 lmp.py:1625]   Expert  7 |    130 | CPU
DEBUG 01-14 20:42:17.136808.136808 lmp.py:1625]   Expert 24 |    141 | CPU
DEBUG 01-14 20:42:17.136689.136689 lmp.py:1625]   Expert 42 |    145 | CPU
DEBUG 01-14 20:42:17.136240.136240 lmp.py:1625]   Expert 31 |    147 | CPU
DEBUG 01-14 20:42:17.136168.136168 lmp.py:1625]   Expert 14 |    152 | CPU
DEBUG 01-14 20:42:17.136095.136095 lmp.py:1625]   Expert  2 |    156 | CPU
DEBUG 01-14 20:42:17.136023.136023 lmp.py:1625]   Expert 44 |    159 | CPU
DEBUG 01-14 20:42:17.136712.136712 lmp.py:1625]   Expert 11 |    160 | CPU
DEBUG 01-14 20:42:17.136878.136878 lmp.py:1625]   Expert 26 |    160 | CPU
DEBUG 01-14 20:42:17.136998.136998 lmp.py:1625]   Expert 10 |    161 | CPU
DEBUG 01-14 20:42:17.136118.136118 lmp.py:1625]   Expert 35 |    175 | GPU
DEBUG 01-14 20:42:17.136999.136999 lmp.py:1625]   Expert 52 |    175 | GPU
DEBUG 01-14 20:42:17.136119.136119 lmp.py:1625]   Expert  3 |    177 | GPU
DEBUG 01-14 20:42:17.136001.136001 lmp.py:1625]   Expert 28 |    177 | GPU
DEBUG 01-14 20:42:17.136551.136551 lmp.py:1625]   Expert 32 |    179 | GPU
DEBUG 01-14 20:42:17.136955.136955 lmp.py:1625]   Expert 19 |    188 | GPU
DEBUG 01-14 20:42:17.136883.136883 lmp.py:1625]   Expert 12 |    196 | GPU
DEBUG 01-14 20:42:17.136049.136049 lmp.py:1625]   Expert  8 |    207 | GPU
DEBUG 01-14 20:42:17.136052.136052 lmp.py:1625]   Expert 56 |    208 | GPU
DEBUG 01-14 20:42:17.136364.136364 lmp.py:1625]   Expert 60 |    208 | GPU
DEBUG 01-14 20:42:17.136013.136013 lmp.py:1625]   Expert 41 |    216 | GPU
DEBUG 01-14 20:42:17.136133.136133 lmp.py:1625]   Expert 59 |    221 | GPU
DEBUG 01-14 20:42:17.136207.136207 lmp.py:1625]   Expert  4 |    228 | GPU
DEBUG 01-14 20:42:17.136373.136373 lmp.py:1625]   Expert 16 |    233 | GPU
DEBUG 01-14 20:42:17.136777.136777 lmp.py:1625]   Expert 40 |    237 | GPU
DEBUG 01-14 20:42:17.136182.136182 lmp.py:1625]   Expert 23 |    238 | GPU
DEBUG 01-14 20:42:17.136348.136348 lmp.py:1625]   Expert 55 |    238 | GPU
DEBUG 01-14 20:42:17.136614.136614 lmp.py:1625]   Expert 51 |    248 | GPU
DEBUG 01-14 20:42:17.136257.136257 lmp.py:1625]   Expert 53 |    249 | GPU
DEBUG 01-14 20:42:17.136946.136946 lmp.py:1625]   Expert 49 |    256 | GPU
DEBUG 01-14 20:42:17.136351.136351 lmp.py:1625]   Expert 58 |    258 | GPU
DEBUG 01-14 20:42:17.136755.136755 lmp.py:1625]   Expert 34 |    273 | GPU
DEBUG 01-14 20:42:17.136444.136444 lmp.py:1625]   Expert 18 |    279 | GPU
DEBUG 01-14 20:42:17.136756.136756 lmp.py:1625]   Expert 29 |    286 | GPU
DEBUG 01-14 20:42:17.136446.136446 lmp.py:1625]   Expert 63 |    296 | GPU
DEBUG 01-14 20:42:17.136896.136896 lmp.py:1625]   Expert 27 |    368 | GPU
DEBUG 01-14 20:42:17.136586.136586 lmp.py:1625]   Expert 39 |    382 | GPU
DEBUG 01-14 20:42:17.136752.136752 lmp.py:1625]   Expert 33 |    404 | GPU
DEBUG 01-14 20:42:17.136156.136156 lmp.py:1625]   Expert 22 |    415 | GPU
DEBUG 01-14 20:42:17.136561.136561 lmp.py:1625]   Expert 17 |    421 | GPU
DEBUG 01-14 20:42:17.136489.136489 lmp.py:1625]   Expert 30 |    483 | GPU
DEBUG 01-14 20:42:17.136655.136655 lmp.py:1625]   Expert  5 |    692 | GPU
DEBUG 01-14 20:42:17.136013.136013 lmp.py:1626] 
DEBUG 01-14 20:42:17.136013.136013 lmp.py:1626]   CPU total tokens: 3477 (28.3%)
DEBUG 01-14 20:42:17.136040.136040 lmp.py:1627]   GPU total tokens: 8811 (71.7%)
DEBUG 01-14 20:42:17.136359.136359 cuda_h.py:19] end experts_map_get cost 0.0016584396362304688 seconds
DEBUG 01-14 20:42:17.136216.136216 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-14 20:42:17.137728.137728 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-14 20:42:17.137202.137202 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-14 20:42:17.138589.138589 cuda_h.py:19] end allocate_cuda_memory cost 0.0014073848724365234 seconds
DEBUG 01-14 20:42:17.138829.138829 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-14 20:42:17.138347.138347 sllm_store_c.py:27] get device uuid map
DEBUG 01-14 20:42:17.138964.138964 sllm_store_c.py:29] call client load into gpu
DEBUG 01-14 20:42:17.138567.138567 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 4c272cbc-5ec1-440a-b63d-600587af2094
DEBUG 01-14 20:42:17.138268.138268 client.py:106] call stub.LoadModelAsync
INFO 01-14 20:42:17.140558.140558 client.py:127] Model loaded
DEBUG 01-14 20:42:17.140700.140700 cuda_h.py:10] start restore2model
DEBUG 01-14 20:42:17.140861.140861 cuda_h.py:19] end restore2model cost 0.00041365623474121094 seconds
DEBUG 01-14 20:42:17.140836.140836 cuda_h.py:19] end sllm_worker_task cost 0.012099027633666992 seconds
INFO 01-14 20:42:17.140919.140919 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 4c272cbc-5ec1-440a-b63d-600587af2094
DEBUG 01-14 20:42:17.141868.141868 cuda_h.py:19] end load_into_gpu_async cost 0.002312183380126953 seconds
DEBUG 01-14 20:42:17.141048.141048 cuda_h.py:10] start restore_tensors2
DEBUG 01-14 20:42:17.141292.141292 cuda_h.py:19] end restore_tensors2 cost 0.0003261566162109375 seconds
DEBUG 01-14 20:42:17.141452.141452 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.004407644271850586 seconds
DEBUG 01-14 20:42:17.141884.141884 cuda_h.py:10] start restore2model
DEBUG 01-14 20:42:17.144213.144213 cuda_h.py:19] end restore2model cost 0.002496004104614258 seconds
DEBUG 01-14 20:42:17.144666.144666 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.007079124450683594 seconds
DEBUG 01-14 20:42:17.144223.144223 cuda_h.py:10] start gpu_sexperts
DEBUG 01-14 20:42:17.144439.144439 cuda_h.py:19] end gpu_sexperts cost 0.00030350685119628906 seconds
DEBUG 01-14 20:42:17.144931.144931 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-14 20:42:17.144779.144779 lmp.py:1683] 
DEBUG 01-14 20:42:17.144779.144779 lmp.py:1683]   Computing 32 experts on CPU...
DEBUG 01-14 20:42:17.144139.144139 cuda_h.py:19] end cpu_experts_submit cost 5.507469177246094e-05 seconds
DEBUG 01-14 20:42:17.144127.144127 cuda_h.py:10] start experts_func_mgpu_group_pad
DEBUG 01-14 20:42:17.162655.162655 mlpmodule.py:1460] group tensors cost 0.017120838165283203 s
DEBUG 01-14 20:42:17.163797.163797 cuda_h.py:10] start move_flat_hidden2cpu
DEBUG 01-14 20:42:17.165144.165144 cuda_h.py:19] end experts_func_mgpu_group_pad cost 0.021021604537963867 seconds
DEBUG 01-14 20:42:17.167668.167668 cuda_h.py:10] start gpu_group_list
DEBUG 01-14 20:42:17.168489.168489 cuda_h.py:19] end gpu_group_list cost 0.0004918575286865234 seconds
DEBUG 01-14 20:42:17.168515.168515 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-14 20:42:17.168937.168937 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.4557113647460938e-05 seconds
DEBUG 01-14 20:42:17.168845.168845 cuda_h.py:10] start wait_experts
INFO 01-14 20:42:17.168469.168469 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 4c272cbc-5ec1-440a-b63d-600587af2094
DEBUG 01-14 20:42:17.170747.170747 cuda_h.py:19] end move_flat_hidden2cpu cost 0.006733894348144531 seconds
DEBUG 01-14 20:42:17.172651.172651 mlpmodule.py:1533] pad cost 0.0019571781158447266 s
DEBUG 01-14 20:42:17.172377.172377 mlpmodule.py:1539] create cpu tensor cost 4.482269287109375e-05 s
DEBUG 01-14 20:42:17.174594.174594 mlpmodule.py:1544] move to cpu cost 0.0019145011901855469 s
DEBUG 01-14 20:42:17.181750.181750 mlpmodule.py:1558] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-14 20:42:17.181444.181444 mlpmodule.py:1559] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-14 20:42:17.181189.181189 mlpmodule.py:1564] group_w3 first element: -0.018798828125
WARNING 01-14 20:42:17.181365.181365 mlpmodule.py:1574] start einsum2
DEBUG 01-14 20:42:17.193735.193735 mlpmodule.py:1584] group einsum cost 0.019537925720214844 s
DEBUG 01-14 20:42:17.194136.194136 mlpmodule.py:1593] cpy2cputensor cost 0.0006742477416992188 s
DEBUG 01-14 20:42:17.194680.194680 cuda_h.py:10] start move_outputs
INFO 01-14 20:42:17.195936.195936 client.py:127] Model loaded
DEBUG 01-14 20:42:17.195201.195201 cuda_h.py:19] end wait_experts cost 0.026781797409057617 seconds
DEBUG 01-14 20:42:17.195878.195878 cuda_h.py:10] start gpu_experts
DEBUG 01-14 20:42:17.195701.195701 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-14 20:42:17.196958.196958 cuda_h.py:19] end move_outputs cost 0.0019130706787109375 seconds
DEBUG 01-14 20:42:17.201517.201517 cuda_h.py:19] end wait_cetm_experts cost 0.0059278011322021484 seconds
DEBUG 01-14 20:42:17.201395.201395 cuda_h.py:10] start gpu_group_einsum_mp_multi_list
DEBUG 01-14 20:42:17.201966.201966 cuda_h.py:10] start gpu_group_tensor
DEBUG 01-14 20:42:17.201094.201094 cuda_h.py:19] end gpu_group_tensor cost 0.00023698806762695312 seconds
DEBUG 01-14 20:42:17.201456.201456 cuda_h.py:10] start gpu_group_einsum
DEBUG 01-14 20:42:17.202474.202474 cuda_h.py:19] end gpu_group_einsum cost 0.0006949901580810547 seconds
DEBUG 01-14 20:42:17.202479.202479 cuda_h.py:10] start gpu_final_hidden_states_scatter
DEBUG 01-14 20:42:17.202620.202620 cuda_h.py:10] start all_expert_outputs_slices
DEBUG 01-14 20:42:17.203170.203170 cuda_h.py:19] end all_expert_outputs_slices cost 0.0003616809844970703 seconds
DEBUG 01-14 20:42:17.203834.203834 cuda_h.py:10] start concat_expert_out
DEBUG 01-14 20:42:17.203678.203678 cuda_h.py:19] end concat_expert_out cost 5.936622619628906e-05 seconds
DEBUG 01-14 20:42:17.203104.203104 cuda_h.py:10] start index_scatter
DEBUG 01-14 20:42:17.203724.203724 cuda_h.py:19] end index_scatter cost 7.200241088867188e-05 seconds
DEBUG 01-14 20:42:17.203056.203056 cuda_h.py:19] end gpu_final_hidden_states_scatter cost 0.0007617473602294922 seconds
DEBUG 01-14 20:42:17.203919.203919 cuda_h.py:19] end gpu_experts cost 0.008322000503540039 seconds
DEBUG 01-14 20:42:17.203384.203384 cuda_h.py:10] start all_expert_weight_slices
DEBUG 01-14 20:42:17.204503.204503 cuda_h.py:19] end all_expert_weight_slices cost 0.0009682178497314453 seconds
DEBUG 01-14 20:42:17.204240.204240 cuda_h.py:10] start cpuoutputsdeal
DEBUG 01-14 20:42:17.205579.205579 cuda_h.py:10] start index_scatter
DEBUG 01-14 20:42:17.205854.205854 cuda_h.py:19] end index_scatter cost 4.792213439941406e-05 seconds
DEBUG 01-14 20:42:17.205570.205570 cuda_h.py:19] end cpuoutputsdeal cost 0.0005257129669189453 seconds
DEBUG 01-14 20:42:17.205387.205387 cuda_h.py:19] end layer_moe_generate_mp_l_23 cost 0.0709075927734375 seconds
DEBUG 01-14 20:42:17.205711.205711 cuda_h.py:19] end prefill_layer cost 0.07741308212280273 seconds
DEBUG 01-14 20:42:17.205978.205978 lmp.py:1551] -------------------------------- end prefill layer 22 --------------------------------
DEBUG 01-14 20:42:17.205635.205635 cuda_h.py:10] start prefill_layer
DEBUG 01-14 20:42:17.205291.205291 lmp.py:1494] -------------------------------- start prefill layer 23 --------------------------------
DEBUG 01-14 20:42:17.205186.205186 cuda_h.py:10] start start_load_qkvogn_s_weight_l_24
DEBUG 01-14 20:42:17.205419.205419 cuda_h.py:10] start start_load_qkvogn_s_weight_l_24
DEBUG 01-14 20:42:17.206077.206077 cuda_h.py:19] end start_load_qkvogn_s_weight_l_24 cost 3.528594970703125e-05 seconds
DEBUG 01-14 20:42:17.206356.206356 cuda_h.py:19] end start_load_qkvogn_s_weight_l_24 cost 6.866455078125e-05 seconds
DEBUG 01-14 20:42:17.206483.206483 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-14 20:42:17.206631.206631 cuda_h.py:10] start sllm_worker_task
DEBUG 01-14 20:42:17.206901.206901 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-14 20:42:17.206830.206830 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-14 20:42:17.206113.206113 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-14 20:42:17.208413.208413 cuda_h.py:19] end allocate_cuda_memory cost 0.002390623092651367 seconds
DEBUG 01-14 20:42:17.209714.209714 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-14 20:42:17.209622.209622 sllm_store_c.py:27] get device uuid map
DEBUG 01-14 20:42:17.209783.209783 sllm_store_c.py:29] call client load into gpu
DEBUG 01-14 20:42:17.209631.209631 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, dd4722a0-3402-4283-a20e-0ac83a3ce733
DEBUG 01-14 20:42:17.209939.209939 client.py:106] call stub.LoadModelAsync
DEBUG 01-14 20:42:17.209951.209951 cuda_h.py:10] start self_attn
INFO 01-14 20:42:17.209653.209653 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, dd4722a0-3402-4283-a20e-0ac83a3ce733
DEBUG 01-14 20:42:17.210258.210258 cuda_h.py:19] end load_into_gpu_async cost 0.0009953975677490234 seconds
DEBUG 01-14 20:42:17.210723.210723 cuda_h.py:10] start restore_tensors2
DEBUG 01-14 20:42:17.210812.210812 cuda_h.py:19] end restore_tensors2 cost 7.343292236328125e-05 seconds
DEBUG 01-14 20:42:17.210091.210091 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0037322044372558594 seconds
INFO 01-14 20:42:17.210365.210365 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, dd4722a0-3402-4283-a20e-0ac83a3ce733
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-14 20:42:17.212946.212946 mlpmodule.py:1367]  experts func einsum cost 0.06737422943115234 s
DEBUG 01-14 20:42:17.212668.212668 cuda_h.py:19] end self_attn cost 0.0031518936157226562 seconds
DEBUG 01-14 20:42:17.213919.213919 cuda_h.py:19] end iln_self_attn_paln cost 0.007063388824462891 seconds
DEBUG 01-14 20:42:17.213961.213961 cuda_h.py:10] start layer_moe_generate_mp_l_24
DEBUG 01-14 20:42:17.213247.213247 cuda_h.py:10] start gate
DEBUG 01-14 20:42:17.213680.213680 cuda_h.py:19] end gate cost 0.0006339550018310547 seconds
DEBUG 01-14 20:42:17.214893.214893 cuda_h.py:10] start experts_map_get
DEBUG 01-14 20:42:17.214507.214507 lmp.py:1615] 
DEBUG 01-14 20:42:17.214507.214507 lmp.py:1615] Expert Token Distribution & Device Allocation:
DEBUG 01-14 20:42:17.214846.214846 lmp.py:1616]   Total experts: 64
DEBUG 01-14 20:42:17.214449.214449 lmp.py:1617]   CPU experts: 32 (50%)
DEBUG 01-14 20:42:17.214715.214715 lmp.py:1618]   GPU experts: 32 (50%)
DEBUG 01-14 20:42:17.214596.214596 lmp.py:1619] 
DEBUG 01-14 20:42:17.214596.214596 lmp.py:1619]   Expert ID | Tokens | Device
DEBUG 01-14 20:42:17.214954.214954 lmp.py:1620]   -----------------------------------
DEBUG 01-14 20:42:17.214505.214505 lmp.py:1625]   Expert  5 |     11 | CPU
DEBUG 01-14 20:42:17.214386.214386 lmp.py:1625]   Expert 56 |     42 | CPU
DEBUG 01-14 20:42:17.214459.214459 lmp.py:1625]   Expert 16 |     95 | CPU
DEBUG 01-14 20:42:17.214672.214672 lmp.py:1625]   Expert 40 |     95 | CPU
DEBUG 01-14 20:42:17.214123.214123 lmp.py:1625]   Expert 53 |     96 | CPU
DEBUG 01-14 20:42:17.214574.214574 lmp.py:1625]   Expert 17 |     97 | CPU
DEBUG 01-14 20:42:17.214025.214025 lmp.py:1625]   Expert 27 |     98 | CPU
DEBUG 01-14 20:42:17.214621.214621 lmp.py:1625]   Expert 47 |     98 | CPU
DEBUG 01-14 20:42:17.214503.214503 lmp.py:1625]   Expert 51 |    104 | CPU
DEBUG 01-14 20:42:17.214669.214669 lmp.py:1625]   Expert 37 |    108 | CPU
DEBUG 01-14 20:42:17.214597.214597 lmp.py:1625]   Expert  7 |    111 | CPU
DEBUG 01-14 20:42:17.214955.214955 lmp.py:1625]   Expert 28 |    111 | CPU
DEBUG 01-14 20:42:17.214313.214313 lmp.py:1625]   Expert 49 |    116 | CPU
DEBUG 01-14 20:42:17.214718.214718 lmp.py:1625]   Expert 63 |    121 | CPU
DEBUG 01-14 20:42:17.214029.214029 lmp.py:1625]   Expert 58 |    126 | CPU
DEBUG 01-14 20:42:17.214434.214434 lmp.py:1625]   Expert 38 |    135 | CPU
DEBUG 01-14 20:42:17.214600.214600 lmp.py:1625]   Expert 14 |    136 | CPU
DEBUG 01-14 20:42:17.214528.214528 lmp.py:1625]   Expert 57 |    138 | CPU
DEBUG 01-14 20:42:17.214694.214694 lmp.py:1625]   Expert 11 |    150 | CPU
DEBUG 01-14 20:42:17.214860.214860 lmp.py:1625]   Expert 39 |    150 | CPU
DEBUG 01-14 20:42:17.214265.214265 lmp.py:1625]   Expert  1 |    153 | CPU
DEBUG 01-14 20:42:17.214908.214908 lmp.py:1625]   Expert 62 |    154 | CPU
DEBUG 01-14 20:42:17.214312.214312 lmp.py:1625]   Expert 12 |    158 | CPU
DEBUG 01-14 20:42:17.214955.214955 lmp.py:1625]   Expert 25 |    160 | CPU
DEBUG 01-14 20:42:17.214837.214837 lmp.py:1625]   Expert 21 |    162 | CPU
DEBUG 01-14 20:42:17.214480.214480 lmp.py:1625]   Expert 52 |    162 | CPU
DEBUG 01-14 20:42:17.214030.214030 lmp.py:1625]   Expert 23 |    164 | CPU
DEBUG 01-14 20:42:17.214196.214196 lmp.py:1625]   Expert 45 |    165 | CPU
DEBUG 01-14 20:42:17.214601.214601 lmp.py:1625]   Expert 33 |    166 | CPU
DEBUG 01-14 20:42:17.214767.214767 lmp.py:1625]   Expert 30 |    170 | CPU
DEBUG 01-14 20:42:17.214933.214933 lmp.py:1625]   Expert  6 |    176 | CPU
DEBUG 01-14 20:42:17.214006.214006 lmp.py:1625]   Expert 55 |    177 | CPU
DEBUG 01-14 20:42:17.215365.215365 lmp.py:1625]   Expert 36 |    182 | GPU
DEBUG 01-14 20:42:17.215484.215484 lmp.py:1625]   Expert 31 |    185 | GPU
DEBUG 01-14 20:42:17.215843.215843 lmp.py:1625]   Expert  9 |    190 | GPU
DEBUG 01-14 20:42:17.215486.215486 lmp.py:1625]   Expert 60 |    196 | GPU
DEBUG 01-14 20:42:17.215321.215321 lmp.py:1625]   Expert  4 |    197 | GPU
DEBUG 01-14 20:42:17.215440.215440 lmp.py:1625]   Expert 19 |    200 | GPU
DEBUG 01-14 20:42:17.215368.215368 lmp.py:1625]   Expert  3 |    203 | GPU
DEBUG 01-14 20:42:17.215534.215534 lmp.py:1625]   Expert 44 |    204 | GPU
DEBUG 01-14 20:42:17.215700.215700 lmp.py:1625]   Expert 34 |    207 | GPU
DEBUG 01-14 20:42:17.215867.215867 lmp.py:1625]   Expert 50 |    222 | GPU
DEBUG 01-14 20:42:17.215940.215940 lmp.py:1625]   Expert 22 |    224 | GPU
DEBUG 01-14 20:42:17.215345.215345 lmp.py:1625]   Expert  0 |    228 | GPU
DEBUG 01-14 20:42:17.215511.215511 lmp.py:1625]   Expert 43 |    228 | GPU
DEBUG 01-14 20:42:17.215869.215869 lmp.py:1625]   Expert 26 |    230 | GPU
DEBUG 01-14 20:42:17.215512.215512 lmp.py:1625]   Expert 41 |    234 | GPU
DEBUG 01-14 20:42:17.215155.215155 lmp.py:1625]   Expert 59 |    238 | GPU
DEBUG 01-14 20:42:17.215275.215275 lmp.py:1625]   Expert 13 |    241 | GPU
DEBUG 01-14 20:42:17.215441.215441 lmp.py:1625]   Expert 18 |    248 | GPU
DEBUG 01-14 20:42:17.215230.215230 lmp.py:1625]   Expert 20 |    254 | GPU
DEBUG 01-14 20:42:17.215396.215396 lmp.py:1625]   Expert 42 |    258 | GPU
DEBUG 01-14 20:42:17.215323.215323 lmp.py:1625]   Expert 24 |    259 | GPU
DEBUG 01-14 20:42:17.215251.215251 lmp.py:1625]   Expert 15 |    260 | GPU
DEBUG 01-14 20:42:17.215417.215417 lmp.py:1625]   Expert 61 |    261 | GPU
DEBUG 01-14 20:42:17.215014.215014 lmp.py:1625]   Expert 54 |    262 | GPU
DEBUG 01-14 20:42:17.215372.215372 lmp.py:1625]   Expert 35 |    272 | GPU
DEBUG 01-14 20:42:17.215015.215015 lmp.py:1625]   Expert 32 |    279 | GPU
DEBUG 01-14 20:42:17.215420.215420 lmp.py:1625]   Expert 29 |    285 | GPU
DEBUG 01-14 20:42:17.215824.215824 lmp.py:1625]   Expert 10 |    294 | GPU
DEBUG 01-14 20:42:17.215706.215706 lmp.py:1625]   Expert  8 |    344 | GPU
DEBUG 01-14 20:42:17.215302.215302 lmp.py:1625]   Expert  2 |    352 | GPU
DEBUG 01-14 20:42:17.215945.215945 lmp.py:1625]   Expert 46 |    465 | GPU
DEBUG 01-14 20:42:17.215873.215873 lmp.py:1625]   Expert 48 |    481 | GPU
DEBUG 01-14 20:42:17.215516.215516 lmp.py:1626] 
DEBUG 01-14 20:42:17.215516.215516 lmp.py:1626]   CPU total tokens: 4105 (33.4%)
DEBUG 01-14 20:42:17.215397.215397 lmp.py:1627]   GPU total tokens: 8183 (66.6%)
DEBUG 01-14 20:42:17.215239.215239 cuda_h.py:19] end experts_map_get cost 0.0015950202941894531 seconds
DEBUG 01-14 20:42:17.215281.215281 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-14 20:42:17.215601.215601 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-14 20:42:17.215891.215891 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-14 20:42:17.217703.217703 cuda_h.py:19] end allocate_cuda_memory cost 0.0014755725860595703 seconds
DEBUG 01-14 20:42:17.217288.217288 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-14 20:42:17.217905.217905 sllm_store_c.py:27] get device uuid map
DEBUG 01-14 20:42:17.217881.217881 sllm_store_c.py:29] call client load into gpu
DEBUG 01-14 20:42:17.217199.217199 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 97f5038f-8d96-431b-b12b-3fc2f1ad3a58
DEBUG 01-14 20:42:17.217087.217087 client.py:106] call stub.LoadModelAsync
INFO 01-14 20:42:17.218941.218941 client.py:127] Model loaded
DEBUG 01-14 20:42:17.218632.218632 cuda_h.py:10] start restore2model
DEBUG 01-14 20:42:17.218545.218545 cuda_h.py:19] end restore2model cost 0.0003254413604736328 seconds
DEBUG 01-14 20:42:17.218599.218599 cuda_h.py:19] end sllm_worker_task cost 0.012099027633666992 seconds
INFO 01-14 20:42:17.218245.218245 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 97f5038f-8d96-431b-b12b-3fc2f1ad3a58
DEBUG 01-14 20:42:17.218956.218956 cuda_h.py:19] end load_into_gpu_async cost 0.0012981891632080078 seconds
DEBUG 01-14 20:42:17.218089.218089 cuda_h.py:10] start restore_tensors2
DEBUG 01-14 20:42:17.219916.219916 cuda_h.py:19] end restore_tensors2 cost 0.0003361701965332031 seconds
DEBUG 01-14 20:42:17.219030.219030 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0034875869750976562 seconds
DEBUG 01-14 20:42:17.219270.219270 cuda_h.py:10] start restore2model
DEBUG 01-14 20:42:17.221396.221396 cuda_h.py:19] end restore2model cost 0.0025560855865478516 seconds
DEBUG 01-14 20:42:17.221086.221086 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.006217479705810547 seconds
DEBUG 01-14 20:42:17.221902.221902 cuda_h.py:10] start gpu_sexperts
DEBUG 01-14 20:42:17.222224.222224 cuda_h.py:19] end gpu_sexperts cost 0.0002772808074951172 seconds
DEBUG 01-14 20:42:17.222954.222954 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-14 20:42:17.222471.222471 lmp.py:1683] 
DEBUG 01-14 20:42:17.222471.222471 lmp.py:1683]   Computing 32 experts on CPU...
DEBUG 01-14 20:42:17.222400.222400 cuda_h.py:19] end cpu_experts_submit cost 5.412101745605469e-05 seconds
DEBUG 01-14 20:42:17.222242.222242 cuda_h.py:10] start experts_func_mgpu_group_pad
DEBUG 01-14 20:42:17.232821.232821 mlpmodule.py:1460] group tensors cost 0.009291410446166992 s
DEBUG 01-14 20:42:17.233525.233525 cuda_h.py:10] start move_flat_hidden2cpu
DEBUG 01-14 20:42:17.239228.239228 cuda_h.py:19] end experts_func_mgpu_group_pad cost 0.016523122787475586 seconds
DEBUG 01-14 20:42:17.239679.239679 cuda_h.py:19] end move_flat_hidden2cpu cost 0.006468057632446289 seconds
DEBUG 01-14 20:42:17.242339.242339 cuda_h.py:10] start gpu_group_list
DEBUG 01-14 20:42:17.243382.243382 cuda_h.py:19] end gpu_group_list cost 0.0007503032684326172 seconds
DEBUG 01-14 20:42:17.243558.243558 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-14 20:42:17.243529.243529 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.9802322387695312e-05 seconds
DEBUG 01-14 20:42:17.243796.243796 cuda_h.py:10] start wait_experts
INFO 01-14 20:42:17.244448.244448 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 97f5038f-8d96-431b-b12b-3fc2f1ad3a58
DEBUG 01-14 20:42:17.244099.244099 mlpmodule.py:1533] pad cost 0.004328489303588867 s
DEBUG 01-14 20:42:17.244819.244819 mlpmodule.py:1539] create cpu tensor cost 5.7220458984375e-05 s
DEBUG 01-14 20:42:17.246242.246242 mlpmodule.py:1544] move to cpu cost 0.002097606658935547 s
DEBUG 01-14 20:42:17.253380.253380 mlpmodule.py:1558] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-14 20:42:17.254081.254081 mlpmodule.py:1559] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-14 20:42:17.254800.254800 mlpmodule.py:1564] group_w3 first element: 0.08447265625
WARNING 01-14 20:42:17.254268.254268 mlpmodule.py:1574] start einsum2
DEBUG 01-14 20:42:17.267029.267029 mlpmodule.py:1584] group einsum cost 0.021246910095214844 s
DEBUG 01-14 20:42:17.268484.268484 mlpmodule.py:1593] cpy2cputensor cost 0.0007188320159912109 s
DEBUG 01-14 20:42:17.268598.268598 cuda_h.py:10] start move_outputs
DEBUG 01-14 20:42:17.271922.271922 cuda_h.py:19] end move_outputs cost 0.002906322479248047 seconds
INFO 01-14 20:42:17.274480.274480 client.py:127] Model loaded
DEBUG 01-14 20:42:17.275918.275918 cuda_h.py:19] end wait_experts cost 0.031009197235107422 seconds
DEBUG 01-14 20:42:17.275694.275694 cuda_h.py:10] start gpu_experts
DEBUG 01-14 20:42:17.275901.275901 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-14 20:42:17.277813.277813 cuda_h.py:19] end wait_cetm_experts cost 0.0020716190338134766 seconds
DEBUG 01-14 20:42:17.277451.277451 cuda_h.py:10] start gpu_group_einsum_mp_multi_list
DEBUG 01-14 20:42:17.277638.277638 cuda_h.py:10] start gpu_group_tensor
DEBUG 01-14 20:42:17.277998.277998 cuda_h.py:19] end gpu_group_tensor cost 0.0002346038818359375 seconds
DEBUG 01-14 20:42:17.277637.277637 cuda_h.py:10] start gpu_group_einsum
DEBUG 01-14 20:42:17.278820.278820 cuda_h.py:19] end gpu_group_einsum cost 0.0006439685821533203 seconds
DEBUG 01-14 20:42:17.278739.278739 cuda_h.py:10] start gpu_final_hidden_states_scatter
DEBUG 01-14 20:42:17.278781.278781 cuda_h.py:10] start all_expert_outputs_slices
DEBUG 01-14 20:42:17.279747.279747 cuda_h.py:19] end all_expert_outputs_slices cost 0.00034928321838378906 seconds
DEBUG 01-14 20:42:17.279788.279788 cuda_h.py:10] start concat_expert_out
DEBUG 01-14 20:42:17.279632.279632 cuda_h.py:19] end concat_expert_out cost 5.9604644775390625e-05 seconds
DEBUG 01-14 20:42:17.279343.279343 cuda_h.py:10] start index_scatter
DEBUG 01-14 20:42:17.279817.279817 cuda_h.py:19] end index_scatter cost 7.033348083496094e-05 seconds
DEBUG 01-14 20:42:17.279672.279672 cuda_h.py:19] end gpu_final_hidden_states_scatter cost 0.0007452964782714844 seconds
DEBUG 01-14 20:42:17.279768.279768 cuda_h.py:19] end gpu_experts cost 0.0043408870697021484 seconds
DEBUG 01-14 20:42:17.279470.279470 cuda_h.py:10] start all_expert_weight_slices
DEBUG 01-14 20:42:17.280669.280669 cuda_h.py:19] end all_expert_weight_slices cost 0.0009548664093017578 seconds
DEBUG 01-14 20:42:17.280737.280737 cuda_h.py:10] start cpuoutputsdeal
DEBUG 01-14 20:42:17.280553.280553 cuda_h.py:10] start index_scatter
DEBUG 01-14 20:42:17.281682.281682 cuda_h.py:19] end index_scatter cost 4.839897155761719e-05 seconds
DEBUG 01-14 20:42:17.281590.281590 cuda_h.py:19] end cpuoutputsdeal cost 0.0005266666412353516 seconds
DEBUG 01-14 20:42:17.281546.281546 cuda_h.py:19] end layer_moe_generate_mp_l_24 cost 0.06788516044616699 seconds
DEBUG 01-14 20:42:17.281996.281996 cuda_h.py:19] end prefill_layer cost 0.07562017440795898 seconds
DEBUG 01-14 20:42:17.281395.281395 lmp.py:1551] -------------------------------- end prefill layer 23 --------------------------------
DEBUG 01-14 20:42:17.281336.281336 cuda_h.py:10] start prefill_layer
DEBUG 01-14 20:42:17.281231.281231 lmp.py:1494] -------------------------------- start prefill layer 24 --------------------------------
DEBUG 01-14 20:42:17.281126.281126 cuda_h.py:10] start start_load_qkvogn_s_weight_l_25
DEBUG 01-14 20:42:17.281928.281928 cuda_h.py:10] start start_load_qkvogn_s_weight_l_25
DEBUG 01-14 20:42:17.281155.281155 cuda_h.py:19] end start_load_qkvogn_s_weight_l_25 cost 3.4809112548828125e-05 seconds
DEBUG 01-14 20:42:17.281865.281865 cuda_h.py:19] end start_load_qkvogn_s_weight_l_25 cost 6.866455078125e-05 seconds
DEBUG 01-14 20:42:17.281945.281945 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-14 20:42:17.281345.281345 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-14 20:42:17.281229.281229 cuda_h.py:10] start sllm_worker_task
DEBUG 01-14 20:42:17.282849.282849 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-14 20:42:17.282592.282592 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-14 20:42:17.284173.284173 cuda_h.py:19] end allocate_cuda_memory cost 0.0022835731506347656 seconds
DEBUG 01-14 20:42:17.284151.284151 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-14 20:42:17.284961.284961 sllm_store_c.py:27] get device uuid map
DEBUG 01-14 20:42:17.284360.284360 sllm_store_c.py:29] call client load into gpu
DEBUG 01-14 20:42:17.284063.284063 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 6ee3e0fc-eabe-41d4-9785-50d1c157c682
DEBUG 01-14 20:42:17.284609.284609 client.py:106] call stub.LoadModelAsync
DEBUG 01-14 20:42:17.285661.285661 cuda_h.py:10] start self_attn
INFO 01-14 20:42:17.286749.286749 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 6ee3e0fc-eabe-41d4-9785-50d1c157c682
DEBUG 01-14 20:42:17.286499.286499 cuda_h.py:19] end load_into_gpu_async cost 0.0016527175903320312 seconds
DEBUG 01-14 20:42:17.286487.286487 cuda_h.py:10] start restore_tensors2
DEBUG 01-14 20:42:17.286576.286576 cuda_h.py:19] end restore_tensors2 cost 7.414817810058594e-05 seconds
DEBUG 01-14 20:42:17.286286.286286 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.004327297210693359 seconds
INFO 01-14 20:42:17.286030.286030 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 6ee3e0fc-eabe-41d4-9785-50d1c157c682
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-14 20:42:17.288510.288510 mlpmodule.py:1367]  experts func einsum cost 0.06510210037231445 s
DEBUG 01-14 20:42:17.288322.288322 cuda_h.py:19] end self_attn cost 0.0032515525817871094 seconds
DEBUG 01-14 20:42:17.288817.288817 cuda_h.py:19] end iln_self_attn_paln cost 0.0069997310638427734 seconds
DEBUG 01-14 20:42:17.288375.288375 cuda_h.py:10] start layer_moe_generate_mp_l_25
DEBUG 01-14 20:42:17.288853.288853 cuda_h.py:10] start gate
DEBUG 01-14 20:42:17.289962.289962 cuda_h.py:19] end gate cost 0.0006413459777832031 seconds
DEBUG 01-14 20:42:17.289076.289076 cuda_h.py:10] start experts_map_get
DEBUG 01-14 20:42:17.289113.289113 lmp.py:1615] 
DEBUG 01-14 20:42:17.289113.289113 lmp.py:1615] Expert Token Distribution & Device Allocation:
DEBUG 01-14 20:42:17.290538.290538 lmp.py:1616]   Total experts: 64
DEBUG 01-14 20:42:17.290618.290618 lmp.py:1617]   CPU experts: 32 (50%)
DEBUG 01-14 20:42:17.290883.290883 lmp.py:1618]   GPU experts: 32 (50%)
DEBUG 01-14 20:42:17.290480.290480 lmp.py:1619] 
DEBUG 01-14 20:42:17.290480.290480 lmp.py:1619]   Expert ID | Tokens | Device
DEBUG 01-14 20:42:17.290838.290838 lmp.py:1620]   -----------------------------------
DEBUG 01-14 20:42:17.290150.290150 lmp.py:1625]   Expert 36 |     24 | CPU
DEBUG 01-14 20:42:17.290747.290747 lmp.py:1625]   Expert 35 |     43 | CPU
DEBUG 01-14 20:42:17.290628.290628 lmp.py:1625]   Expert 30 |     50 | CPU
DEBUG 01-14 20:42:17.290794.290794 lmp.py:1625]   Expert 51 |     52 | CPU
DEBUG 01-14 20:42:17.290961.290961 lmp.py:1625]   Expert 25 |     55 | CPU
DEBUG 01-14 20:42:17.290365.290365 lmp.py:1625]   Expert 46 |     58 | CPU
DEBUG 01-14 20:42:17.290531.290531 lmp.py:1625]   Expert 43 |     59 | CPU
DEBUG 01-14 20:42:17.290890.290890 lmp.py:1625]   Expert 55 |     59 | CPU
DEBUG 01-14 20:42:17.290532.290532 lmp.py:1625]   Expert 47 |     73 | CPU
DEBUG 01-14 20:42:17.290414.290414 lmp.py:1625]   Expert 44 |     75 | CPU
DEBUG 01-14 20:42:17.290011.290011 lmp.py:1625]   Expert  0 |     80 | CPU
DEBUG 01-14 20:42:17.290654.290654 lmp.py:1625]   Expert 16 |     82 | CPU
DEBUG 01-14 20:42:17.290820.290820 lmp.py:1625]   Expert 42 |     88 | CPU
DEBUG 01-14 20:42:17.290986.290986 lmp.py:1625]   Expert  2 |     89 | CPU
DEBUG 01-14 20:42:17.290914.290914 lmp.py:1625]   Expert 39 |     90 | CPU
DEBUG 01-14 20:42:17.290841.290841 lmp.py:1625]   Expert  4 |    103 | CPU
DEBUG 01-14 20:42:17.290531.290531 lmp.py:1625]   Expert 33 |    123 | CPU
DEBUG 01-14 20:42:17.290935.290935 lmp.py:1625]   Expert 48 |    123 | CPU
DEBUG 01-14 20:42:17.290055.290055 lmp.py:1625]   Expert 61 |    124 | CPU
DEBUG 01-14 20:42:17.290698.290698 lmp.py:1625]   Expert 54 |    126 | CPU
DEBUG 01-14 20:42:17.290579.290579 lmp.py:1625]   Expert 24 |    129 | CPU
DEBUG 01-14 20:42:17.290984.290984 lmp.py:1625]   Expert 15 |    136 | CPU
DEBUG 01-14 20:42:17.290912.290912 lmp.py:1625]   Expert 29 |    136 | CPU
DEBUG 01-14 20:42:17.290839.290839 lmp.py:1625]   Expert  6 |    137 | CPU
DEBUG 01-14 20:42:17.290529.290529 lmp.py:1625]   Expert 38 |    139 | CPU
DEBUG 01-14 20:42:17.290456.290456 lmp.py:1625]   Expert 56 |    144 | CPU
DEBUG 01-14 20:42:17.290384.290384 lmp.py:1625]   Expert  7 |    152 | CPU
DEBUG 01-14 20:42:17.290312.290312 lmp.py:1625]   Expert 62 |    153 | CPU
DEBUG 01-14 20:42:17.290239.290239 lmp.py:1625]   Expert 19 |    154 | CPU
DEBUG 01-14 20:42:17.290644.290644 lmp.py:1625]   Expert 20 |    157 | CPU
DEBUG 01-14 20:42:17.290049.290049 lmp.py:1625]   Expert 13 |    158 | CPU
DEBUG 01-14 20:42:17.290930.290930 lmp.py:1625]   Expert  9 |    159 | CPU
DEBUG 01-14 20:42:17.290573.290573 lmp.py:1625]   Expert 59 |    159 | GPU
DEBUG 01-14 20:42:17.290501.290501 lmp.py:1625]   Expert 34 |    174 | GPU
DEBUG 01-14 20:42:17.290667.290667 lmp.py:1625]   Expert 45 |    178 | GPU
DEBUG 01-14 20:42:17.290594.290594 lmp.py:1625]   Expert 18 |    182 | GPU
DEBUG 01-14 20:42:17.290522.290522 lmp.py:1625]   Expert 50 |    186 | GPU
DEBUG 01-14 20:42:17.290688.290688 lmp.py:1625]   Expert  8 |    187 | GPU
DEBUG 01-14 20:42:17.290616.290616 lmp.py:1625]   Expert 23 |    198 | GPU
DEBUG 01-14 20:42:17.290305.290305 lmp.py:1625]   Expert 57 |    198 | GPU
DEBUG 01-14 20:42:17.290233.290233 lmp.py:1625]   Expert 31 |    200 | GPU
DEBUG 01-14 20:42:17.290591.290591 lmp.py:1625]   Expert 60 |    201 | GPU
DEBUG 01-14 20:42:17.290473.290473 lmp.py:1625]   Expert 22 |    209 | GPU
DEBUG 01-14 20:42:17.290116.290116 lmp.py:1625]   Expert 10 |    221 | GPU
DEBUG 01-14 20:42:17.290759.290759 lmp.py:1625]   Expert 17 |    225 | GPU
DEBUG 01-14 20:42:17.290925.290925 lmp.py:1625]   Expert  5 |    234 | GPU
DEBUG 01-14 20:42:17.290853.290853 lmp.py:1625]   Expert 37 |    236 | GPU
DEBUG 01-14 20:42:17.290780.290780 lmp.py:1625]   Expert 52 |    237 | GPU
DEBUG 01-14 20:42:17.290470.290470 lmp.py:1625]   Expert 11 |    238 | GPU
DEBUG 01-14 20:42:17.290397.290397 lmp.py:1625]   Expert 53 |    253 | GPU
DEBUG 01-14 20:42:17.290325.290325 lmp.py:1625]   Expert  1 |    266 | GPU
DEBUG 01-14 20:42:17.290014.290014 lmp.py:1625]   Expert 49 |    271 | GPU
DEBUG 01-14 20:42:17.291942.291942 lmp.py:1625]   Expert 26 |    278 | GPU
DEBUG 01-14 20:42:17.291347.291347 lmp.py:1625]   Expert 14 |    281 | GPU
DEBUG 01-14 20:42:17.291751.291751 lmp.py:1625]   Expert 41 |    283 | GPU
DEBUG 01-14 20:42:17.291917.291917 lmp.py:1625]   Expert 58 |    284 | GPU
DEBUG 01-14 20:42:17.291083.291083 lmp.py:1625]   Expert 40 |    298 | GPU
DEBUG 01-14 20:42:17.291726.291726 lmp.py:1625]   Expert 28 |    305 | GPU
DEBUG 01-14 20:42:17.291892.291892 lmp.py:1625]   Expert 12 |    319 | GPU
DEBUG 01-14 20:42:17.291582.291582 lmp.py:1625]   Expert 32 |    324 | GPU
DEBUG 01-14 20:42:17.291794.291794 lmp.py:1625]   Expert 21 |    351 | GPU
DEBUG 01-14 20:42:17.291484.291484 lmp.py:1625]   Expert 63 |    351 | GPU
DEBUG 01-14 20:42:17.291173.291173 lmp.py:1625]   Expert 27 |    604 | GPU
DEBUG 01-14 20:42:17.291101.291101 lmp.py:1625]   Expert  3 |   1027 | GPU
DEBUG 01-14 20:42:17.291982.291982 lmp.py:1626] 
DEBUG 01-14 20:42:17.291982.291982 lmp.py:1626]   CPU total tokens: 3330 (27.1%)
DEBUG 01-14 20:42:17.291340.291340 lmp.py:1627]   GPU total tokens: 8958 (72.9%)
DEBUG 01-14 20:42:17.291752.291752 cuda_h.py:19] end experts_map_get cost 0.001558065414428711 seconds
DEBUG 01-14 20:42:17.291932.291932 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-14 20:42:17.291107.291107 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-14 20:42:17.291250.291250 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-14 20:42:17.293732.293732 cuda_h.py:19] end allocate_cuda_memory cost 0.0020775794982910156 seconds
DEBUG 01-14 20:42:17.293959.293959 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-14 20:42:17.293715.293715 sllm_store_c.py:27] get device uuid map
DEBUG 01-14 20:42:17.293047.293047 sllm_store_c.py:29] call client load into gpu
DEBUG 01-14 20:42:17.293127.293127 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, c51497b6-c16f-46ff-9277-750eee6f26a5
DEBUG 01-14 20:42:17.293856.293856 client.py:106] call stub.LoadModelAsync
INFO 01-14 20:42:17.294919.294919 client.py:127] Model loaded
DEBUG 01-14 20:42:17.294663.294663 cuda_h.py:10] start restore2model
DEBUG 01-14 20:42:17.294114.294114 cuda_h.py:19] end restore2model cost 0.0003674030303955078 seconds
DEBUG 01-14 20:42:17.294744.294744 cuda_h.py:19] end sllm_worker_task cost 0.012714385986328125 seconds
INFO 01-14 20:42:17.294910.294910 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, c51497b6-c16f-46ff-9277-750eee6f26a5
DEBUG 01-14 20:42:17.295806.295806 cuda_h.py:19] end load_into_gpu_async cost 0.0013282299041748047 seconds
DEBUG 01-14 20:42:17.295224.295224 cuda_h.py:10] start restore_tensors2
DEBUG 01-14 20:42:17.295607.295607 cuda_h.py:19] end restore_tensors2 cost 0.00032591819763183594 seconds
DEBUG 01-14 20:42:17.295621.295621 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.004078388214111328 seconds
DEBUG 01-14 20:42:17.295815.295815 cuda_h.py:10] start restore2model
DEBUG 01-14 20:42:17.298549.298549 cuda_h.py:19] end restore2model cost 0.0025141239166259766 seconds
DEBUG 01-14 20:42:17.298378.298378 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.006761312484741211 seconds
DEBUG 01-14 20:42:17.298267.298267 cuda_h.py:10] start gpu_sexperts
DEBUG 01-14 20:42:17.298892.298892 cuda_h.py:19] end gpu_sexperts cost 0.0002570152282714844 seconds
DEBUG 01-14 20:42:17.298973.298973 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-14 20:42:17.298200.298200 lmp.py:1683] 
DEBUG 01-14 20:42:17.298200.298200 lmp.py:1683]   Computing 32 experts on CPU...
DEBUG 01-14 20:42:17.298797.298797 cuda_h.py:19] end cpu_experts_submit cost 5.4836273193359375e-05 seconds
DEBUG 01-14 20:42:17.298023.298023 cuda_h.py:10] start experts_func_mgpu_group_pad
DEBUG 01-14 20:42:17.309217.309217 mlpmodule.py:1460] group tensors cost 0.010122299194335938 s
DEBUG 01-14 20:42:17.309161.309161 cuda_h.py:10] start move_flat_hidden2cpu
DEBUG 01-14 20:42:17.312206.312206 cuda_h.py:19] end experts_func_mgpu_group_pad cost 0.014088630676269531 seconds
DEBUG 01-14 20:42:17.314773.314773 cuda_h.py:10] start gpu_group_list
DEBUG 01-14 20:42:17.315548.315548 cuda_h.py:19] end gpu_group_list cost 0.0005145072937011719 seconds
DEBUG 01-14 20:42:17.315343.315343 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-14 20:42:17.315161.315161 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.8371810913085938e-05 seconds
DEBUG 01-14 20:42:17.315693.315693 cuda_h.py:10] start wait_experts
INFO 01-14 20:42:17.315316.315316 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, c51497b6-c16f-46ff-9277-750eee6f26a5
DEBUG 01-14 20:42:17.316553.316553 cuda_h.py:19] end move_flat_hidden2cpu cost 0.006688117980957031 seconds
DEBUG 01-14 20:42:17.318583.318583 mlpmodule.py:1533] pad cost 0.0019788742065429688 s
DEBUG 01-14 20:42:17.318878.318878 mlpmodule.py:1539] create cpu tensor cost 4.363059997558594e-05 s
DEBUG 01-14 20:42:17.320546.320546 mlpmodule.py:1544] move to cpu cost 0.0018887519836425781 s
DEBUG 01-14 20:42:17.327119.327119 mlpmodule.py:1558] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-14 20:42:17.328396.328396 mlpmodule.py:1559] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-14 20:42:17.328486.328486 mlpmodule.py:1564] group_w3 first element: 0.00653076171875
WARNING 01-14 20:42:17.328477.328477 mlpmodule.py:1574] start einsum2
DEBUG 01-14 20:42:17.341084.341084 mlpmodule.py:1584] group einsum cost 0.021126508712768555 s
DEBUG 01-14 20:42:17.342192.342192 mlpmodule.py:1593] cpy2cputensor cost 0.000640869140625 s
DEBUG 01-14 20:42:17.342014.342014 cuda_h.py:10] start move_outputs
DEBUG 01-14 20:42:17.345852.345852 cuda_h.py:19] end move_outputs cost 0.002444744110107422 seconds
INFO 01-14 20:42:17.351400.351400 client.py:127] Model loaded
DEBUG 01-14 20:42:17.351698.351698 cuda_h.py:19] end wait_experts cost 0.03589987754821777 seconds
DEBUG 01-14 20:42:17.351375.351375 cuda_h.py:10] start gpu_experts
DEBUG 01-14 20:42:17.351244.351244 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-14 20:42:17.351913.351913 cuda_h.py:19] end wait_cetm_experts cost 0.0001823902130126953 seconds
DEBUG 01-14 20:42:17.351816.351816 cuda_h.py:10] start gpu_group_einsum_mp_multi_list
DEBUG 01-14 20:42:17.351526.351526 cuda_h.py:10] start gpu_group_tensor
DEBUG 01-14 20:42:17.352932.352932 cuda_h.py:19] end gpu_group_tensor cost 0.00023317337036132812 seconds
DEBUG 01-14 20:42:17.352141.352141 cuda_h.py:10] start gpu_group_einsum
DEBUG 01-14 20:42:17.352194.352194 cuda_h.py:19] end gpu_group_einsum cost 0.00072479248046875 seconds
DEBUG 01-14 20:42:17.353669.353669 cuda_h.py:10] start gpu_final_hidden_states_scatter
DEBUG 01-14 20:42:17.353664.353664 cuda_h.py:10] start all_expert_outputs_slices
DEBUG 01-14 20:42:17.353645.353645 cuda_h.py:19] end all_expert_outputs_slices cost 0.0003581047058105469 seconds
DEBUG 01-14 20:42:17.353931.353931 cuda_h.py:10] start concat_expert_out
DEBUG 01-14 20:42:17.353067.353067 cuda_h.py:19] end concat_expert_out cost 6.127357482910156e-05 seconds
DEBUG 01-14 20:42:17.353585.353585 cuda_h.py:10] start index_scatter
DEBUG 01-14 20:42:17.353536.353536 cuda_h.py:19] end index_scatter cost 7.05718994140625e-05 seconds
DEBUG 01-14 20:42:17.353868.353868 cuda_h.py:19] end gpu_final_hidden_states_scatter cost 0.0007658004760742188 seconds
DEBUG 01-14 20:42:17.353016.353016 cuda_h.py:19] end gpu_experts cost 0.002515077590942383 seconds
DEBUG 01-14 20:42:17.353481.353481 cuda_h.py:10] start all_expert_weight_slices
DEBUG 01-14 20:42:17.354208.354208 cuda_h.py:19] end all_expert_weight_slices cost 0.0009260177612304688 seconds
DEBUG 01-14 20:42:17.354170.354170 cuda_h.py:10] start cpuoutputsdeal
DEBUG 01-14 20:42:17.355157.355157 cuda_h.py:10] start index_scatter
DEBUG 01-14 20:42:17.355379.355379 cuda_h.py:19] end index_scatter cost 4.6253204345703125e-05 seconds
DEBUG 01-14 20:42:17.355811.355811 cuda_h.py:19] end cpuoutputsdeal cost 0.0005128383636474609 seconds
DEBUG 01-14 20:42:17.355158.355158 cuda_h.py:19] end layer_moe_generate_mp_l_25 cost 0.06665921211242676 seconds
DEBUG 01-14 20:42:17.355899.355899 cuda_h.py:19] end prefill_layer cost 0.07433056831359863 seconds
DEBUG 01-14 20:42:17.356291.356291 lmp.py:1551] -------------------------------- end prefill layer 24 --------------------------------
DEBUG 01-14 20:42:17.356994.356994 cuda_h.py:10] start prefill_layer
DEBUG 01-14 20:42:17.356650.356650 lmp.py:1494] -------------------------------- start prefill layer 25 --------------------------------
DEBUG 01-14 20:42:17.356830.356830 cuda_h.py:10] start start_load_qkvogn_s_weight_l_26
DEBUG 01-14 20:42:17.356155.356155 cuda_h.py:10] start start_load_qkvogn_s_weight_l_26
DEBUG 01-14 20:42:17.356098.356098 cuda_h.py:19] end start_load_qkvogn_s_weight_l_26 cost 3.457069396972656e-05 seconds
DEBUG 01-14 20:42:17.356478.356478 cuda_h.py:10] start sllm_worker_task
DEBUG 01-14 20:42:17.356328.356328 cuda_h.py:19] end start_load_qkvogn_s_weight_l_26 cost 0.00016760826110839844 seconds
DEBUG 01-14 20:42:17.356497.356497 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-14 20:42:17.356156.356156 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-14 20:42:17.356954.356954 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-14 20:42:17.357959.357959 cuda_h.py:19] end allocate_cuda_memory cost 0.0006287097930908203 seconds
DEBUG 01-14 20:42:17.357122.357122 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-14 20:42:17.357204.357204 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-14 20:42:17.357877.357877 sllm_store_c.py:27] get device uuid map
DEBUG 01-14 20:42:17.357614.357614 sllm_store_c.py:29] call client load into gpu
DEBUG 01-14 20:42:17.357655.357655 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, fb0da5df-a2cd-4e41-a6d3-00a6482118b3
DEBUG 01-14 20:42:17.357863.357863 client.py:106] call stub.LoadModelAsync
DEBUG 01-14 20:42:17.358179.358179 cuda_h.py:10] start self_attn
INFO 01-14 20:42:17.359267.359267 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, fb0da5df-a2cd-4e41-a6d3-00a6482118b3
DEBUG 01-14 20:42:17.359448.359448 cuda_h.py:19] end load_into_gpu_async cost 0.0018239021301269531 seconds
DEBUG 01-14 20:42:17.359913.359913 cuda_h.py:10] start restore_tensors2
DEBUG 01-14 20:42:17.359618.359618 cuda_h.py:19] end restore_tensors2 cost 7.200241088867188e-05 seconds
DEBUG 01-14 20:42:17.359897.359897 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0030786991119384766 seconds
INFO 01-14 20:42:17.359409.359409 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, fb0da5df-a2cd-4e41-a6d3-00a6482118b3
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
DEBUG 01-14 20:42:17.361417.361417 mlpmodule.py:1367]  experts func einsum cost 0.062395572662353516 s
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-14 20:42:17.362475.362475 cuda_h.py:19] end self_attn cost 0.004000425338745117 seconds
DEBUG 01-14 20:42:17.362320.362320 cuda_h.py:19] end iln_self_attn_paln cost 0.0059261322021484375 seconds
DEBUG 01-14 20:42:17.362647.362647 cuda_h.py:10] start layer_moe_generate_mp_l_26
DEBUG 01-14 20:42:17.362708.362708 cuda_h.py:10] start gate
DEBUG 01-14 20:42:17.363632.363632 cuda_h.py:19] end gate cost 0.0006458759307861328 seconds
DEBUG 01-14 20:42:17.363223.363223 cuda_h.py:10] start experts_map_get
DEBUG 01-14 20:42:17.363551.363551 lmp.py:1615] 
DEBUG 01-14 20:42:17.363551.363551 lmp.py:1615] Expert Token Distribution & Device Allocation:
DEBUG 01-14 20:42:17.363022.363022 lmp.py:1616]   Total experts: 64
DEBUG 01-14 20:42:17.363149.363149 lmp.py:1617]   CPU experts: 32 (50%)
DEBUG 01-14 20:42:17.363699.363699 lmp.py:1618]   GPU experts: 32 (50%)
DEBUG 01-14 20:42:17.363865.363865 lmp.py:1619] 
DEBUG 01-14 20:42:17.363865.363865 lmp.py:1619]   Expert ID | Tokens | Device
DEBUG 01-14 20:42:17.363654.363654 lmp.py:1620]   -----------------------------------
DEBUG 01-14 20:42:17.363012.363012 lmp.py:1625]   Expert 13 |     24 | CPU
DEBUG 01-14 20:42:17.363417.363417 lmp.py:1625]   Expert 44 |     40 | CPU
DEBUG 01-14 20:42:17.363345.363345 lmp.py:1625]   Expert  9 |     41 | CPU
DEBUG 01-14 20:42:17.363557.363557 lmp.py:1625]   Expert 16 |     42 | CPU
DEBUG 01-14 20:42:17.363677.363677 lmp.py:1625]   Expert 33 |     44 | CPU
DEBUG 01-14 20:42:17.363605.363605 lmp.py:1625]   Expert  2 |     46 | CPU
DEBUG 01-14 20:42:17.364817.364817 lmp.py:1625]   Expert 38 |     49 | CPU
DEBUG 01-14 20:42:17.364745.364745 lmp.py:1625]   Expert 22 |     58 | CPU
DEBUG 01-14 20:42:17.364673.364673 lmp.py:1625]   Expert 25 |     60 | CPU
DEBUG 01-14 20:42:17.364839.364839 lmp.py:1625]   Expert  5 |     63 | CPU
DEBUG 01-14 20:42:17.364528.364528 lmp.py:1625]   Expert 24 |     63 | CPU
DEBUG 01-14 20:42:17.364740.364740 lmp.py:1625]   Expert 42 |     73 | CPU
DEBUG 01-14 20:42:17.364099.364099 lmp.py:1625]   Expert 23 |     74 | CPU
DEBUG 01-14 20:42:17.364550.364550 lmp.py:1625]   Expert 10 |     87 | CPU
DEBUG 01-14 20:42:17.364908.364908 lmp.py:1625]   Expert 46 |    102 | CPU
DEBUG 01-14 20:42:17.364074.364074 lmp.py:1625]   Expert 61 |    102 | CPU
DEBUG 01-14 20:42:17.364240.364240 lmp.py:1625]   Expert 59 |    104 | CPU
DEBUG 01-14 20:42:17.364406.364406 lmp.py:1625]   Expert 55 |    106 | CPU
DEBUG 01-14 20:42:17.364096.364096 lmp.py:1625]   Expert 21 |    116 | CPU
DEBUG 01-14 20:42:17.364739.364739 lmp.py:1625]   Expert 45 |    132 | CPU
DEBUG 01-14 20:42:17.364858.364858 lmp.py:1625]   Expert  6 |    134 | CPU
DEBUG 01-14 20:42:17.364501.364501 lmp.py:1625]   Expert  3 |    137 | CPU
DEBUG 01-14 20:42:17.364383.364383 lmp.py:1625]   Expert 31 |    141 | CPU
DEBUG 01-14 20:42:17.364026.364026 lmp.py:1625]   Expert 36 |    149 | CPU
DEBUG 01-14 20:42:17.364192.364192 lmp.py:1625]   Expert 43 |    153 | CPU
DEBUG 01-14 20:42:17.364981.364981 lmp.py:1625]   Expert 48 |    154 | CPU
DEBUG 01-14 20:42:17.364385.364385 lmp.py:1625]   Expert 51 |    159 | CPU
DEBUG 01-14 20:42:17.364850.364850 lmp.py:1625]   Expert 26 |    160 | CPU
DEBUG 01-14 20:42:17.364923.364923 lmp.py:1625]   Expert 41 |    160 | CPU
DEBUG 01-14 20:42:17.364050.364050 lmp.py:1625]   Expert 20 |    161 | CPU
DEBUG 01-14 20:42:17.364123.364123 lmp.py:1625]   Expert 28 |    162 | CPU
DEBUG 01-14 20:42:17.364766.364766 lmp.py:1625]   Expert 18 |    166 | CPU
DEBUG 01-14 20:42:17.364648.364648 lmp.py:1625]   Expert 56 |    168 | GPU
DEBUG 01-14 20:42:17.364052.364052 lmp.py:1625]   Expert  8 |    173 | GPU
DEBUG 01-14 20:42:17.364172.364172 lmp.py:1625]   Expert 12 |    176 | GPU
DEBUG 01-14 20:42:17.364815.364815 lmp.py:1625]   Expert  0 |    180 | GPU
DEBUG 01-14 20:42:17.364365.364365 lmp.py:1625]   Expert  7 |    184 | GPU
DEBUG 01-14 20:42:17.364531.364531 lmp.py:1625]   Expert 27 |    185 | GPU
DEBUG 01-14 20:42:17.364459.364459 lmp.py:1625]   Expert 47 |    195 | GPU
DEBUG 01-14 20:42:17.364387.364387 lmp.py:1625]   Expert  1 |    202 | GPU
DEBUG 01-14 20:42:17.364553.364553 lmp.py:1625]   Expert 15 |    216 | GPU
DEBUG 01-14 20:42:17.364150.364150 lmp.py:1625]   Expert 34 |    218 | GPU
DEBUG 01-14 20:42:17.364793.364793 lmp.py:1625]   Expert 40 |    223 | GPU
DEBUG 01-14 20:42:17.364435.364435 lmp.py:1625]   Expert 11 |    226 | GPU
DEBUG 01-14 20:42:17.364555.364555 lmp.py:1625]   Expert 32 |    231 | GPU
DEBUG 01-14 20:42:17.364198.364198 lmp.py:1625]   Expert 49 |    235 | GPU
DEBUG 01-14 20:42:17.364841.364841 lmp.py:1625]   Expert 50 |    236 | GPU
DEBUG 01-14 20:42:17.364007.364007 lmp.py:1625]   Expert 53 |    246 | GPU
DEBUG 01-14 20:42:17.364081.364081 lmp.py:1625]   Expert 63 |    247 | GPU
DEBUG 01-14 20:42:17.364485.364485 lmp.py:1625]   Expert  4 |    256 | GPU
DEBUG 01-14 20:42:17.364652.364652 lmp.py:1625]   Expert 30 |    257 | GPU
DEBUG 01-14 20:42:17.364341.364341 lmp.py:1625]   Expert 29 |    262 | GPU
DEBUG 01-14 20:42:17.364269.364269 lmp.py:1625]   Expert 35 |    274 | GPU
DEBUG 01-14 20:42:17.364435.364435 lmp.py:1625]   Expert 14 |    277 | GPU
DEBUG 01-14 20:42:17.364031.364031 lmp.py:1625]   Expert 37 |    300 | GPU
DEBUG 01-14 20:42:17.364436.364436 lmp.py:1625]   Expert 52 |    355 | GPU
DEBUG 01-14 20:42:17.364364.364364 lmp.py:1625]   Expert 17 |    361 | GPU
DEBUG 01-14 20:42:17.364053.364053 lmp.py:1625]   Expert 54 |    372 | GPU
DEBUG 01-14 20:42:17.364458.364458 lmp.py:1625]   Expert 39 |    383 | GPU
DEBUG 01-14 20:42:17.364862.364862 lmp.py:1625]   Expert 57 |    410 | GPU
DEBUG 01-14 20:42:17.364743.364743 lmp.py:1625]   Expert 60 |    445 | GPU
DEBUG 01-14 20:42:17.364386.364386 lmp.py:1625]   Expert 62 |    461 | GPU
DEBUG 01-14 20:42:17.365029.365029 lmp.py:1625]   Expert 19 |    504 | GPU
DEBUG 01-14 20:42:17.365434.365434 lmp.py:1625]   Expert 58 |    568 | GPU
DEBUG 01-14 20:42:17.365938.365938 lmp.py:1626] 
DEBUG 01-14 20:42:17.365938.365938 lmp.py:1626]   CPU total tokens: 3262 (26.5%)
DEBUG 01-14 20:42:17.365296.365296 lmp.py:1627]   GPU total tokens: 9026 (73.5%)
DEBUG 01-14 20:42:17.365946.365946 cuda_h.py:19] end experts_map_get cost 0.001592874526977539 seconds
DEBUG 01-14 20:42:17.365180.365180 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-14 20:42:17.365454.365454 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-14 20:42:17.365121.365121 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-14 20:42:17.366497.366497 cuda_h.py:19] end allocate_cuda_memory cost 0.0015065670013427734 seconds
DEBUG 01-14 20:42:17.366360.366360 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-14 20:42:17.367692.367692 sllm_store_c.py:27] get device uuid map
DEBUG 01-14 20:42:17.367647.367647 sllm_store_c.py:29] call client load into gpu
DEBUG 01-14 20:42:17.367251.367251 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 34ced3ab-82a3-479a-aff7-6226c381c800
DEBUG 01-14 20:42:17.367740.367740 client.py:106] call stub.LoadModelAsync
INFO 01-14 20:42:17.367331.367331 client.py:127] Model loaded
DEBUG 01-14 20:42:17.367306.367306 cuda_h.py:10] start restore2model
DEBUG 01-14 20:42:17.368504.368504 cuda_h.py:19] end restore2model cost 0.0003249645233154297 seconds
DEBUG 01-14 20:42:17.368889.368889 cuda_h.py:19] end sllm_worker_task cost 0.011726617813110352 seconds
INFO 01-14 20:42:17.369932.369932 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 34ced3ab-82a3-479a-aff7-6226c381c800
DEBUG 01-14 20:42:17.369497.369497 cuda_h.py:19] end load_into_gpu_async cost 0.0022771358489990234 seconds
DEBUG 01-14 20:42:17.369776.369776 cuda_h.py:10] start restore_tensors2
DEBUG 01-14 20:42:17.369769.369769 cuda_h.py:19] end restore_tensors2 cost 0.00035381317138671875 seconds
DEBUG 01-14 20:42:17.369334.369334 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.004523277282714844 seconds
DEBUG 01-14 20:42:17.369574.369574 cuda_h.py:10] start restore2model
DEBUG 01-14 20:42:17.372009.372009 cuda_h.py:19] end restore2model cost 0.002463817596435547 seconds
DEBUG 01-14 20:42:17.372745.372745 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.007163524627685547 seconds
DEBUG 01-14 20:42:17.372349.372349 cuda_h.py:10] start gpu_sexperts
DEBUG 01-14 20:42:17.372241.372241 cuda_h.py:19] end gpu_sexperts cost 0.00029087066650390625 seconds
DEBUG 01-14 20:42:17.372355.372355 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-14 20:42:17.372158.372158 lmp.py:1683] 
DEBUG 01-14 20:42:17.372158.372158 lmp.py:1683]   Computing 32 experts on CPU...
DEBUG 01-14 20:42:17.372663.372663 cuda_h.py:19] end cpu_experts_submit cost 5.6743621826171875e-05 seconds
DEBUG 01-14 20:42:17.372511.372511 cuda_h.py:10] start experts_func_mgpu_group_pad
DEBUG 01-14 20:42:17.383807.383807 mlpmodule.py:1460] group tensors cost 0.009942293167114258 s
DEBUG 01-14 20:42:17.384407.384407 cuda_h.py:10] start move_flat_hidden2cpu
DEBUG 01-14 20:42:17.390289.390289 cuda_h.py:19] end experts_func_mgpu_group_pad cost 0.017207622528076172 seconds
DEBUG 01-14 20:42:17.390717.390717 cuda_h.py:19] end move_flat_hidden2cpu cost 0.006624460220336914 seconds
DEBUG 01-14 20:42:17.393817.393817 cuda_h.py:10] start gpu_group_list
DEBUG 01-14 20:42:17.394799.394799 cuda_h.py:19] end gpu_group_list cost 0.0006742477416992188 seconds
DEBUG 01-14 20:42:17.394735.394735 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-14 20:42:17.394567.394567 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.6226043701171875e-05 seconds
DEBUG 01-14 20:42:17.394211.394211 cuda_h.py:10] start wait_experts
INFO 01-14 20:42:17.395663.395663 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 34ced3ab-82a3-479a-aff7-6226c381c800
DEBUG 01-14 20:42:17.395059.395059 mlpmodule.py:1533] pad cost 0.004339933395385742 s
DEBUG 01-14 20:42:17.395707.395707 mlpmodule.py:1539] create cpu tensor cost 4.76837158203125e-05 s
DEBUG 01-14 20:42:17.397820.397820 mlpmodule.py:1544] move to cpu cost 0.001972198486328125 s
DEBUG 01-14 20:42:17.404552.404552 mlpmodule.py:1558] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-14 20:42:17.405160.405160 mlpmodule.py:1559] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-14 20:42:17.405196.405196 mlpmodule.py:1564] group_w3 first element: -0.02734375
WARNING 01-14 20:42:17.405671.405671 mlpmodule.py:1574] start einsum2
DEBUG 01-14 20:42:17.419825.419825 mlpmodule.py:1584] group einsum cost 0.022000551223754883 s
DEBUG 01-14 20:42:17.420258.420258 mlpmodule.py:1593] cpy2cputensor cost 0.000667572021484375 s
DEBUG 01-14 20:42:17.420512.420512 cuda_h.py:10] start move_outputs
DEBUG 01-14 20:42:17.423436.423436 cuda_h.py:19] end move_outputs cost 0.0026509761810302734 seconds
INFO 01-14 20:42:17.425293.425293 client.py:127] Model loaded
DEBUG 01-14 20:42:17.425731.425731 cuda_h.py:19] end wait_experts cost 0.030300617218017578 seconds
DEBUG 01-14 20:42:17.425792.425792 cuda_h.py:10] start gpu_experts
DEBUG 01-14 20:42:17.425376.425376 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-14 20:42:17.428746.428746 cuda_h.py:19] end wait_cetm_experts cost 0.002689361572265625 seconds
DEBUG 01-14 20:42:17.428669.428669 cuda_h.py:10] start gpu_group_einsum_mp_multi_list
DEBUG 01-14 20:42:17.428240.428240 cuda_h.py:10] start gpu_group_tensor
DEBUG 01-14 20:42:17.428462.428462 cuda_h.py:19] end gpu_group_tensor cost 0.000270843505859375 seconds
DEBUG 01-14 20:42:17.428884.428884 cuda_h.py:10] start gpu_group_einsum
DEBUG 01-14 20:42:17.429062.429062 cuda_h.py:19] end gpu_group_einsum cost 0.0007073879241943359 seconds
DEBUG 01-14 20:42:17.429497.429497 cuda_h.py:10] start gpu_final_hidden_states_scatter
DEBUG 01-14 20:42:17.429923.429923 cuda_h.py:10] start all_expert_outputs_slices
DEBUG 01-14 20:42:17.430725.430725 cuda_h.py:19] end all_expert_outputs_slices cost 0.0003654956817626953 seconds
DEBUG 01-14 20:42:17.430342.430342 cuda_h.py:10] start concat_expert_out
DEBUG 01-14 20:42:17.430663.430663 cuda_h.py:19] end concat_expert_out cost 5.9604644775390625e-05 seconds
DEBUG 01-14 20:42:17.430705.430705 cuda_h.py:10] start index_scatter
DEBUG 01-14 20:42:17.430994.430994 cuda_h.py:19] end index_scatter cost 7.343292236328125e-05 seconds
DEBUG 01-14 20:42:17.430756.430756 cuda_h.py:19] end gpu_final_hidden_states_scatter cost 0.0007722377777099609 seconds
DEBUG 01-14 20:42:17.430097.430097 cuda_h.py:19] end gpu_experts cost 0.005107879638671875 seconds
DEBUG 01-14 20:42:17.430707.430707 cuda_h.py:10] start all_expert_weight_slices
DEBUG 01-14 20:42:17.431594.431594 cuda_h.py:19] end all_expert_weight_slices cost 0.0009369850158691406 seconds
DEBUG 01-14 20:42:17.431847.431847 cuda_h.py:10] start cpuoutputsdeal
DEBUG 01-14 20:42:17.431040.431040 cuda_h.py:10] start index_scatter
DEBUG 01-14 20:42:17.432990.432990 cuda_h.py:19] end index_scatter cost 5.078315734863281e-05 seconds
DEBUG 01-14 20:42:17.432329.432329 cuda_h.py:19] end cpuoutputsdeal cost 0.0005371570587158203 seconds
DEBUG 01-14 20:42:17.432908.432908 cuda_h.py:19] end layer_moe_generate_mp_l_26 cost 0.06947040557861328 seconds
DEBUG 01-14 20:42:17.432511.432511 cuda_h.py:19] end prefill_layer cost 0.07654070854187012 seconds
DEBUG 01-14 20:42:17.432348.432348 lmp.py:1551] -------------------------------- end prefill layer 25 --------------------------------
DEBUG 01-14 20:42:17.432050.432050 cuda_h.py:10] start prefill_layer
DEBUG 01-14 20:42:17.432184.432184 lmp.py:1494] -------------------------------- start prefill layer 26 --------------------------------
DEBUG 01-14 20:42:17.432602.432602 cuda_h.py:10] start start_load_qkvogn_s_weight_l_27
DEBUG 01-14 20:42:17.432451.432451 cuda_h.py:10] start start_load_qkvogn_s_weight_l_27
DEBUG 01-14 20:42:17.432300.432300 cuda_h.py:19] end start_load_qkvogn_s_weight_l_27 cost 3.6716461181640625e-05 seconds
DEBUG 01-14 20:42:17.432295.432295 cuda_h.py:19] end start_load_qkvogn_s_weight_l_27 cost 7.081031799316406e-05 seconds
DEBUG 01-14 20:42:17.432567.432567 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-14 20:42:17.432908.432908 cuda_h.py:10] start sllm_worker_task
DEBUG 01-14 20:42:17.433078.433078 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-14 20:42:17.433292.433292 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-14 20:42:17.433436.433436 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-14 20:42:17.434581.434581 cuda_h.py:19] end allocate_cuda_memory cost 0.0013279914855957031 seconds
DEBUG 01-14 20:42:17.434060.434060 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-14 20:42:17.434062.434062 sllm_store_c.py:27] get device uuid map
DEBUG 01-14 20:42:17.434414.434414 sllm_store_c.py:29] call client load into gpu
DEBUG 01-14 20:42:17.434071.434071 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, df821004-bb3a-4339-998e-43216cb4bbcf
DEBUG 01-14 20:42:17.434186.434186 client.py:106] call stub.LoadModelAsync
DEBUG 01-14 20:42:17.435192.435192 cuda_h.py:10] start self_attn
INFO 01-14 20:42:17.435670.435670 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, df821004-bb3a-4339-998e-43216cb4bbcf
DEBUG 01-14 20:42:17.435103.435103 cuda_h.py:19] end load_into_gpu_async cost 0.0010488033294677734 seconds
DEBUG 01-14 20:42:17.435998.435998 cuda_h.py:10] start restore_tensors2
DEBUG 01-14 20:42:17.435995.435995 cuda_h.py:19] end restore_tensors2 cost 7.534027099609375e-05 seconds
DEBUG 01-14 20:42:17.436990.436990 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.002716064453125 seconds
INFO 01-14 20:42:17.436793.436793 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, df821004-bb3a-4339-998e-43216cb4bbcf
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
DEBUG 01-14 20:42:17.437113.437113 mlpmodule.py:1367]  experts func einsum cost 0.06461286544799805 s
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-14 20:42:17.438391.438391 cuda_h.py:19] end self_attn cost 0.0032994747161865234 seconds
DEBUG 01-14 20:42:17.439952.439952 cuda_h.py:19] end iln_self_attn_paln cost 0.006110191345214844 seconds
DEBUG 01-14 20:42:17.439140.439140 cuda_h.py:10] start layer_moe_generate_mp_l_27
DEBUG 01-14 20:42:17.439618.439618 cuda_h.py:10] start gate
DEBUG 01-14 20:42:17.439342.439342 cuda_h.py:19] end gate cost 0.0006330013275146484 seconds
DEBUG 01-14 20:42:17.439841.439841 cuda_h.py:10] start experts_map_get
DEBUG 01-14 20:42:17.440752.440752 lmp.py:1615] 
DEBUG 01-14 20:42:17.440752.440752 lmp.py:1615] Expert Token Distribution & Device Allocation:
DEBUG 01-14 20:42:17.440177.440177 lmp.py:1616]   Total experts: 64
DEBUG 01-14 20:42:17.440019.440019 lmp.py:1617]   CPU experts: 32 (50%)
DEBUG 01-14 20:42:17.440000.440000 lmp.py:1618]   GPU experts: 32 (50%)
DEBUG 01-14 20:42:17.440358.440358 lmp.py:1619] 
DEBUG 01-14 20:42:17.440358.440358 lmp.py:1619]   Expert ID | Tokens | Device
DEBUG 01-14 20:42:17.440955.440955 lmp.py:1620]   -----------------------------------
DEBUG 01-14 20:42:17.440266.440266 lmp.py:1625]   Expert 20 |     14 | CPU
DEBUG 01-14 20:42:17.440294.440294 lmp.py:1625]   Expert 61 |     22 | CPU
DEBUG 01-14 20:42:17.440460.440460 lmp.py:1625]   Expert 51 |     40 | CPU
DEBUG 01-14 20:42:17.440593.440593 lmp.py:1625]   Expert 62 |     40 | CPU
DEBUG 01-14 20:42:17.440190.440190 lmp.py:1625]   Expert  7 |     47 | CPU
DEBUG 01-14 20:42:17.440786.440786 lmp.py:1625]   Expert 11 |     50 | CPU
DEBUG 01-14 20:42:17.440668.440668 lmp.py:1625]   Expert 29 |     51 | CPU
DEBUG 01-14 20:42:17.440357.440357 lmp.py:1625]   Expert 30 |     53 | CPU
DEBUG 01-14 20:42:17.440907.440907 lmp.py:1625]   Expert  3 |     58 | CPU
DEBUG 01-14 20:42:17.440504.440504 lmp.py:1625]   Expert  9 |     62 | CPU
DEBUG 01-14 20:42:17.440578.440578 lmp.py:1625]   Expert 17 |     63 | CPU
DEBUG 01-14 20:42:17.440174.440174 lmp.py:1625]   Expert  8 |     72 | CPU
DEBUG 01-14 20:42:17.440056.440056 lmp.py:1625]   Expert  6 |     75 | CPU
DEBUG 01-14 20:42:17.440083.440083 lmp.py:1625]   Expert 59 |     75 | CPU
DEBUG 01-14 20:42:17.440726.440726 lmp.py:1625]   Expert 63 |     82 | CPU
DEBUG 01-14 20:42:17.440130.440130 lmp.py:1625]   Expert 48 |     91 | CPU
DEBUG 01-14 20:42:17.440773.440773 lmp.py:1625]   Expert 55 |     95 | CPU
DEBUG 01-14 20:42:17.440939.440939 lmp.py:1625]   Expert 38 |     96 | CPU
DEBUG 01-14 20:42:17.440106.440106 lmp.py:1625]   Expert 24 |    110 | CPU
DEBUG 01-14 20:42:17.440749.440749 lmp.py:1625]   Expert 36 |    112 | CPU
DEBUG 01-14 20:42:17.440153.440153 lmp.py:1625]   Expert 49 |    112 | CPU
DEBUG 01-14 20:42:17.440558.440558 lmp.py:1625]   Expert 19 |    119 | CPU
DEBUG 01-14 20:42:17.440724.440724 lmp.py:1625]   Expert 39 |    121 | CPU
DEBUG 01-14 20:42:17.440128.440128 lmp.py:1625]   Expert 50 |    122 | CPU
DEBUG 01-14 20:42:17.440963.440963 lmp.py:1625]   Expert  4 |    123 | CPU
DEBUG 01-14 20:42:17.440083.440083 lmp.py:1625]   Expert 42 |    129 | CPU
DEBUG 01-14 20:42:17.440680.440680 lmp.py:1625]   Expert 34 |    134 | CPU
DEBUG 01-14 20:42:17.440277.440277 lmp.py:1625]   Expert 41 |    134 | CPU
DEBUG 01-14 20:42:17.440350.440350 lmp.py:1625]   Expert 22 |    140 | CPU
DEBUG 01-14 20:42:17.440231.440231 lmp.py:1625]   Expert 15 |    156 | CPU
DEBUG 01-14 20:42:17.440636.440636 lmp.py:1625]   Expert 37 |    158 | CPU
DEBUG 01-14 20:42:17.440994.440994 lmp.py:1625]   Expert 60 |    158 | CPU
DEBUG 01-14 20:42:17.440399.440399 lmp.py:1625]   Expert 56 |    161 | GPU
DEBUG 01-14 20:42:17.440803.440803 lmp.py:1625]   Expert 21 |    167 | GPU
DEBUG 01-14 20:42:17.440115.440115 lmp.py:1625]   Expert 23 |    172 | GPU
DEBUG 01-14 20:42:17.440520.440520 lmp.py:1625]   Expert 44 |    174 | GPU
DEBUG 01-14 20:42:17.440355.440355 lmp.py:1625]   Expert 33 |    181 | GPU
DEBUG 01-14 20:42:17.441475.441475 lmp.py:1625]   Expert 47 |    181 | GPU
DEBUG 01-14 20:42:17.441594.441594 lmp.py:1625]   Expert 16 |    185 | GPU
DEBUG 01-14 20:42:17.441714.441714 lmp.py:1625]   Expert  1 |    186 | GPU
DEBUG 01-14 20:42:17.441265.441265 lmp.py:1625]   Expert 43 |    187 | GPU
DEBUG 01-14 20:42:17.441908.441908 lmp.py:1625]   Expert 13 |    204 | GPU
DEBUG 01-14 20:42:17.441312.441312 lmp.py:1625]   Expert 53 |    206 | GPU
DEBUG 01-14 20:42:17.441478.441478 lmp.py:1625]   Expert 32 |    226 | GPU
DEBUG 01-14 20:42:17.441644.441644 lmp.py:1625]   Expert 12 |    228 | GPU
DEBUG 01-14 20:42:17.441811.441811 lmp.py:1625]   Expert 28 |    228 | GPU
DEBUG 01-14 20:42:17.441122.441122 lmp.py:1625]   Expert  2 |    233 | GPU
DEBUG 01-14 20:42:17.441719.441719 lmp.py:1625]   Expert 31 |    246 | GPU
DEBUG 01-14 20:42:17.441839.441839 lmp.py:1625]   Expert 25 |    250 | GPU
DEBUG 01-14 20:42:17.441720.441720 lmp.py:1625]   Expert 26 |    262 | GPU
DEBUG 01-14 20:42:17.441794.441794 lmp.py:1625]   Expert  0 |    263 | GPU
DEBUG 01-14 20:42:17.441390.441390 lmp.py:1625]   Expert 18 |    267 | GPU
DEBUG 01-14 20:42:17.441033.441033 lmp.py:1625]   Expert 54 |    276 | GPU
DEBUG 01-14 20:42:17.441961.441961 lmp.py:1625]   Expert 57 |    277 | GPU
DEBUG 01-14 20:42:17.441127.441127 lmp.py:1625]   Expert 10 |    278 | GPU
DEBUG 01-14 20:42:17.441817.441817 lmp.py:1625]   Expert 58 |    280 | GPU
DEBUG 01-14 20:42:17.441744.441744 lmp.py:1625]   Expert 40 |    333 | GPU
DEBUG 01-14 20:42:17.441341.441341 lmp.py:1625]   Expert 45 |    375 | GPU
DEBUG 01-14 20:42:17.441222.441222 lmp.py:1625]   Expert 35 |    440 | GPU
DEBUG 01-14 20:42:17.441865.441865 lmp.py:1625]   Expert  5 |    478 | GPU
DEBUG 01-14 20:42:17.441747.441747 lmp.py:1625]   Expert 46 |    499 | GPU
DEBUG 01-14 20:42:17.441390.441390 lmp.py:1625]   Expert 27 |    512 | GPU
DEBUG 01-14 20:42:17.441509.441509 lmp.py:1625]   Expert 52 |    563 | GPU
DEBUG 01-14 20:42:17.441821.441821 lmp.py:1625]   Expert 14 |    856 | GPU
DEBUG 01-14 20:42:17.441703.441703 lmp.py:1626] 
DEBUG 01-14 20:42:17.441703.441703 lmp.py:1626]   CPU total tokens: 2914 (23.7%)
DEBUG 01-14 20:42:17.441061.441061 lmp.py:1627]   GPU total tokens: 9374 (76.3%)
DEBUG 01-14 20:42:17.441188.441188 cuda_h.py:19] end experts_map_get cost 0.0016314983367919922 seconds
DEBUG 01-14 20:42:17.441091.441091 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-14 20:42:17.441033.441033 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-14 20:42:17.441806.441806 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-14 20:42:17.443057.443057 cuda_h.py:19] end allocate_cuda_memory cost 0.0013082027435302734 seconds
DEBUG 01-14 20:42:17.443728.443728 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-14 20:42:17.443438.443438 sllm_store_c.py:27] get device uuid map
DEBUG 01-14 20:42:17.443154.443154 sllm_store_c.py:29] call client load into gpu
DEBUG 01-14 20:42:17.443188.443188 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, a776b08c-0786-498c-a667-c9f107e05efa
DEBUG 01-14 20:42:17.443539.443539 client.py:106] call stub.LoadModelAsync
INFO 01-14 20:42:17.443066.443066 client.py:127] Model loaded
DEBUG 01-14 20:42:17.443200.443200 cuda_h.py:10] start restore2model
DEBUG 01-14 20:42:17.444897.444897 cuda_h.py:19] end restore2model cost 0.00040435791015625 seconds
DEBUG 01-14 20:42:17.444125.444125 cuda_h.py:19] end sllm_worker_task cost 0.011230945587158203 seconds
INFO 01-14 20:42:17.444307.444307 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, a776b08c-0786-498c-a667-c9f107e05efa
DEBUG 01-14 20:42:17.444018.444018 cuda_h.py:19] end load_into_gpu_async cost 0.0013022422790527344 seconds
DEBUG 01-14 20:42:17.444674.444674 cuda_h.py:10] start restore_tensors2
DEBUG 01-14 20:42:17.444581.444581 cuda_h.py:19] end restore_tensors2 cost 0.0003619194030761719 seconds
DEBUG 01-14 20:42:17.445980.445980 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.003343343734741211 seconds
DEBUG 01-14 20:42:17.445319.445319 cuda_h.py:10] start restore2model
DEBUG 01-14 20:42:17.447040.447040 cuda_h.py:19] end restore2model cost 0.002503633499145508 seconds
DEBUG 01-14 20:42:17.447254.447254 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.0060231685638427734 seconds
DEBUG 01-14 20:42:17.447049.447049 cuda_h.py:10] start gpu_sexperts
DEBUG 01-14 20:42:17.447086.447086 cuda_h.py:19] end gpu_sexperts cost 0.0002770423889160156 seconds
DEBUG 01-14 20:42:17.448054.448054 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-14 20:42:17.448639.448639 lmp.py:1683] 
DEBUG 01-14 20:42:17.448639.448639 lmp.py:1683]   Computing 32 experts on CPU...
DEBUG 01-14 20:42:17.448429.448429 cuda_h.py:19] end cpu_experts_submit cost 5.650520324707031e-05 seconds
DEBUG 01-14 20:42:17.448701.448701 cuda_h.py:10] start experts_func_mgpu_group_pad
DEBUG 01-14 20:42:17.463475.463475 mlpmodule.py:1460] group tensors cost 0.014486551284790039 s
DEBUG 01-14 20:42:17.464784.464784 cuda_h.py:10] start move_flat_hidden2cpu
DEBUG 01-14 20:42:17.469947.469947 cuda_h.py:19] end experts_func_mgpu_group_pad cost 0.02093219757080078 seconds
DEBUG 01-14 20:42:17.470325.470325 cuda_h.py:19] end move_flat_hidden2cpu cost 0.006582736968994141 seconds
DEBUG 01-14 20:42:17.472893.472893 cuda_h.py:10] start gpu_group_list
DEBUG 01-14 20:42:17.473073.473073 cuda_h.py:19] end gpu_group_list cost 0.0006239414215087891 seconds
DEBUG 01-14 20:42:17.473711.473711 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-14 20:42:17.474867.474867 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.765655517578125e-05 seconds
DEBUG 01-14 20:42:17.474789.474789 cuda_h.py:10] start wait_experts
INFO 01-14 20:42:17.474043.474043 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, a776b08c-0786-498c-a667-c9f107e05efa
DEBUG 01-14 20:42:17.474782.474782 mlpmodule.py:1533] pad cost 0.004038810729980469 s
DEBUG 01-14 20:42:17.475965.475965 mlpmodule.py:1539] create cpu tensor cost 4.7206878662109375e-05 s
DEBUG 01-14 20:42:17.476758.476758 mlpmodule.py:1544] move to cpu cost 0.0018811225891113281 s
DEBUG 01-14 20:42:17.484662.484662 mlpmodule.py:1558] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-14 20:42:17.484085.484085 mlpmodule.py:1559] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-14 20:42:17.484128.484128 mlpmodule.py:1564] group_w3 first element: -0.0024261474609375
WARNING 01-14 20:42:17.484318.484318 mlpmodule.py:1574] start einsum2
INFO 01-14 20:42:17.498879.498879 client.py:127] Model loaded
DEBUG 01-14 20:42:17.498575.498575 cuda_h.py:19] end wait_experts cost 0.02418208122253418 seconds
DEBUG 01-14 20:42:17.498053.498053 cuda_h.py:10] start gpu_experts
DEBUG 01-14 20:42:17.498114.498114 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-14 20:42:17.498810.498810 mlpmodule.py:1584] group einsum cost 0.02182769775390625 s
DEBUG 01-14 20:42:17.499851.499851 mlpmodule.py:1593] cpy2cputensor cost 0.0006351470947265625 s
DEBUG 01-14 20:42:17.499435.499435 cuda_h.py:10] start move_outputs
DEBUG 01-14 20:42:17.501055.501055 cuda_h.py:19] end move_outputs cost 0.0018644332885742188 seconds
DEBUG 01-14 20:42:17.506932.506932 cuda_h.py:19] end wait_cetm_experts cost 0.007771968841552734 seconds
DEBUG 01-14 20:42:17.506236.506236 cuda_h.py:10] start gpu_group_einsum_mp_multi_list
DEBUG 01-14 20:42:17.506005.506005 cuda_h.py:10] start gpu_group_tensor
DEBUG 01-14 20:42:17.506425.506425 cuda_h.py:19] end gpu_group_tensor cost 0.00023794174194335938 seconds
DEBUG 01-14 20:42:17.506164.506164 cuda_h.py:10] start gpu_group_einsum
DEBUG 01-14 20:42:17.507825.507825 cuda_h.py:19] end gpu_group_einsum cost 0.0006735324859619141 seconds
DEBUG 01-14 20:42:17.507121.507121 cuda_h.py:10] start gpu_final_hidden_states_scatter
DEBUG 01-14 20:42:17.507653.507653 cuda_h.py:10] start all_expert_outputs_slices
DEBUG 01-14 20:42:17.508805.508805 cuda_h.py:19] end all_expert_outputs_slices cost 0.00035381317138671875 seconds
DEBUG 01-14 20:42:17.508800.508800 cuda_h.py:10] start concat_expert_out
DEBUG 01-14 20:42:17.508068.508068 cuda_h.py:19] end concat_expert_out cost 5.7697296142578125e-05 seconds
DEBUG 01-14 20:42:17.508111.508111 cuda_h.py:10] start index_scatter
DEBUG 01-14 20:42:17.508784.508784 cuda_h.py:19] end index_scatter cost 7.2479248046875e-05 seconds
DEBUG 01-14 20:42:17.508593.508593 cuda_h.py:19] end gpu_final_hidden_states_scatter cost 0.0007863044738769531 seconds
DEBUG 01-14 20:42:17.508231.508231 cuda_h.py:19] end gpu_experts cost 0.010247468948364258 seconds
DEBUG 01-14 20:42:17.508272.508272 cuda_h.py:10] start all_expert_weight_slices
DEBUG 01-14 20:42:17.509172.509172 cuda_h.py:19] end all_expert_weight_slices cost 0.0009489059448242188 seconds
DEBUG 01-14 20:42:17.509849.509849 cuda_h.py:10] start cpuoutputsdeal
DEBUG 01-14 20:42:17.510029.510029 cuda_h.py:10] start index_scatter
DEBUG 01-14 20:42:17.510549.510549 cuda_h.py:19] end index_scatter cost 5.0067901611328125e-05 seconds
DEBUG 01-14 20:42:17.510934.510934 cuda_h.py:19] end cpuoutputsdeal cost 0.0005247592926025391 seconds
DEBUG 01-14 20:42:17.510036.510036 cuda_h.py:19] end layer_moe_generate_mp_l_27 cost 0.07123851776123047 seconds
DEBUG 01-14 20:42:17.510764.510764 cuda_h.py:19] end prefill_layer cost 0.07805728912353516 seconds
DEBUG 01-14 20:42:17.510263.510263 lmp.py:1551] -------------------------------- end prefill layer 26 --------------------------------
DEBUG 01-14 20:42:17.510204.510204 cuda_h.py:10] start prefill_layer
DEBUG 01-14 20:42:17.510338.510338 lmp.py:1494] -------------------------------- start prefill layer 27 --------------------------------
DEBUG 01-14 20:42:17.510948.510948 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-14 20:42:17.511779.511779 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-14 20:42:17.511445.511445 cuda_h.py:10] start self_attn
DEBUG 01-14 20:42:17.514864.514864 mlpmodule.py:1367]  experts func einsum cost 0.06568789482116699 s
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-14 20:42:17.515954.515954 cuda_h.py:19] end self_attn cost 0.00445246696472168 seconds
DEBUG 01-14 20:42:17.516827.516827 cuda_h.py:19] end iln_self_attn_paln cost 0.005246162414550781 seconds
DEBUG 01-14 20:42:17.516551.516551 cuda_h.py:10] start layer_moe_generate_mp_l_28
DEBUG 01-14 20:42:17.516837.516837 cuda_h.py:10] start gate
DEBUG 01-14 20:42:17.516356.516356 cuda_h.py:19] end gate cost 0.000629425048828125 seconds
DEBUG 01-14 20:42:17.517908.517908 cuda_h.py:10] start experts_map_get
DEBUG 01-14 20:42:17.517395.517395 lmp.py:1615] 
DEBUG 01-14 20:42:17.517395.517395 lmp.py:1615] Expert Token Distribution & Device Allocation:
DEBUG 01-14 20:42:17.517820.517820 lmp.py:1616]   Total experts: 64
DEBUG 01-14 20:42:17.517662.517662 lmp.py:1617]   CPU experts: 32 (50%)
DEBUG 01-14 20:42:17.517166.517166 lmp.py:1618]   GPU experts: 32 (50%)
DEBUG 01-14 20:42:17.517286.517286 lmp.py:1619] 
DEBUG 01-14 20:42:17.517286.517286 lmp.py:1619]   Expert ID | Tokens | Device
DEBUG 01-14 20:42:17.517167.517167 lmp.py:1620]   -----------------------------------
DEBUG 01-14 20:42:17.517525.517525 lmp.py:1625]   Expert 48 |     65 | CPU
DEBUG 01-14 20:42:17.517553.517553 lmp.py:1625]   Expert 47 |     69 | CPU
DEBUG 01-14 20:42:17.517719.517719 lmp.py:1625]   Expert 54 |     73 | CPU
DEBUG 01-14 20:42:17.517170.517170 lmp.py:1625]   Expert 18 |     74 | CPU
DEBUG 01-14 20:42:17.517859.517859 lmp.py:1625]   Expert 44 |     83 | CPU
DEBUG 01-14 20:42:17.517071.517071 lmp.py:1625]   Expert 23 |     88 | CPU
DEBUG 01-14 20:42:17.517430.517430 lmp.py:1625]   Expert 45 |     89 | CPU
DEBUG 01-14 20:42:17.517119.517119 lmp.py:1625]   Expert 20 |     92 | CPU
DEBUG 01-14 20:42:17.517523.517523 lmp.py:1625]   Expert 11 |     98 | CPU
DEBUG 01-14 20:42:17.517928.517928 lmp.py:1625]   Expert 61 |    106 | CPU
DEBUG 01-14 20:42:17.517333.517333 lmp.py:1625]   Expert 36 |    110 | CPU
DEBUG 01-14 20:42:17.517737.517737 lmp.py:1625]   Expert 31 |    113 | CPU
DEBUG 01-14 20:42:17.517903.517903 lmp.py:1625]   Expert 24 |    118 | CPU
DEBUG 01-14 20:42:17.517738.517738 lmp.py:1625]   Expert 10 |    119 | CPU
DEBUG 01-14 20:42:17.517189.517189 lmp.py:1625]   Expert  5 |    121 | CPU
DEBUG 01-14 20:42:17.517402.517402 lmp.py:1625]   Expert 42 |    126 | CPU
DEBUG 01-14 20:42:17.517614.517614 lmp.py:1625]   Expert 33 |    131 | CPU
DEBUG 01-14 20:42:17.517350.517350 lmp.py:1625]   Expert  6 |    133 | CPU
DEBUG 01-14 20:42:17.517801.517801 lmp.py:1625]   Expert 43 |    133 | CPU
DEBUG 01-14 20:42:17.517159.517159 lmp.py:1625]   Expert 49 |    133 | CPU
DEBUG 01-14 20:42:17.517087.517087 lmp.py:1625]   Expert 17 |    136 | CPU
DEBUG 01-14 20:42:17.517491.517491 lmp.py:1625]   Expert 56 |    136 | CPU
DEBUG 01-14 20:42:17.517896.517896 lmp.py:1625]   Expert 57 |    143 | CPU
DEBUG 01-14 20:42:17.517300.517300 lmp.py:1625]   Expert 12 |    148 | CPU
DEBUG 01-14 20:42:17.517228.517228 lmp.py:1625]   Expert  0 |    160 | CPU
DEBUG 01-14 20:42:17.517394.517394 lmp.py:1625]   Expert 51 |    162 | CPU
DEBUG 01-14 20:42:17.517752.517752 lmp.py:1625]   Expert 38 |    163 | CPU
DEBUG 01-14 20:42:17.517203.517203 lmp.py:1625]   Expert 26 |    164 | CPU
DEBUG 01-14 20:42:17.517654.517654 lmp.py:1625]   Expert 46 |    164 | CPU
DEBUG 01-14 20:42:17.517628.517628 lmp.py:1625]   Expert 35 |    169 | CPU
DEBUG 01-14 20:42:17.518364.518364 lmp.py:1625]   Expert 59 |    169 | CPU
DEBUG 01-14 20:42:17.518338.518338 lmp.py:1625]   Expert 50 |    171 | CPU
DEBUG 01-14 20:42:17.518696.518696 lmp.py:1625]   Expert 13 |    172 | GPU
DEBUG 01-14 20:42:17.518909.518909 lmp.py:1625]   Expert 55 |    175 | GPU
DEBUG 01-14 20:42:17.518883.518883 lmp.py:1625]   Expert 40 |    176 | GPU
DEBUG 01-14 20:42:17.518095.518095 lmp.py:1625]   Expert  7 |    179 | GPU
DEBUG 01-14 20:42:17.518546.518546 lmp.py:1625]   Expert 16 |    179 | GPU
DEBUG 01-14 20:42:17.518282.518282 lmp.py:1625]   Expert 58 |    180 | GPU
DEBUG 01-14 20:42:17.518209.518209 lmp.py:1625]   Expert 30 |    188 | GPU
DEBUG 01-14 20:42:17.518375.518375 lmp.py:1625]   Expert 15 |    196 | GPU
DEBUG 01-14 20:42:17.518542.518542 lmp.py:1625]   Expert 14 |    208 | GPU
DEBUG 01-14 20:42:17.518469.518469 lmp.py:1625]   Expert  1 |    209 | GPU
DEBUG 01-14 20:42:17.518159.518159 lmp.py:1625]   Expert  4 |    217 | GPU
DEBUG 01-14 20:42:17.518755.518755 lmp.py:1625]   Expert 32 |    217 | GPU
DEBUG 01-14 20:42:17.518206.518206 lmp.py:1625]   Expert  3 |    225 | GPU
DEBUG 01-14 20:42:17.518942.518942 lmp.py:1625]   Expert 28 |    231 | GPU
DEBUG 01-14 20:42:17.518154.518154 lmp.py:1625]   Expert 34 |    239 | GPU
DEBUG 01-14 20:42:17.518367.518367 lmp.py:1625]   Expert 25 |    240 | GPU
DEBUG 01-14 20:42:17.518579.518579 lmp.py:1625]   Expert 39 |    247 | GPU
DEBUG 01-14 20:42:17.518222.518222 lmp.py:1625]   Expert 22 |    250 | GPU
DEBUG 01-14 20:42:17.518865.518865 lmp.py:1625]   Expert 52 |    257 | GPU
DEBUG 01-14 20:42:17.518031.518031 lmp.py:1625]   Expert 60 |    257 | GPU
DEBUG 01-14 20:42:17.518674.518674 lmp.py:1625]   Expert  2 |    268 | GPU
DEBUG 01-14 20:42:17.518317.518317 lmp.py:1625]   Expert 41 |    285 | GPU
DEBUG 01-14 20:42:17.518291.518291 lmp.py:1625]   Expert 27 |    289 | GPU
DEBUG 01-14 20:42:17.518649.518649 lmp.py:1625]   Expert 62 |    297 | GPU
DEBUG 01-14 20:42:17.518862.518862 lmp.py:1625]   Expert 21 |    298 | GPU
DEBUG 01-14 20:42:17.518598.518598 lmp.py:1625]   Expert 63 |    298 | GPU
DEBUG 01-14 20:42:17.518095.518095 lmp.py:1625]   Expert 29 |    300 | GPU
DEBUG 01-14 20:42:17.518069.518069 lmp.py:1625]   Expert 37 |    338 | GPU
DEBUG 01-14 20:42:17.518804.518804 lmp.py:1625]   Expert  8 |    339 | GPU
DEBUG 01-14 20:42:17.518116.518116 lmp.py:1625]   Expert 53 |    344 | GPU
DEBUG 01-14 20:42:17.518759.518759 lmp.py:1625]   Expert 19 |    453 | GPU
DEBUG 01-14 20:42:17.518925.518925 lmp.py:1625]   Expert  9 |    578 | GPU
DEBUG 01-14 20:42:17.518807.518807 lmp.py:1626] 
DEBUG 01-14 20:42:17.518807.518807 lmp.py:1626]   CPU total tokens: 3959 (32.2%)
DEBUG 01-14 20:42:17.518165.518165 lmp.py:1627]   GPU total tokens: 8329 (67.8%)
DEBUG 01-14 20:42:17.518815.518815 cuda_h.py:19] end experts_map_get cost 0.001552581787109375 seconds
DEBUG 01-14 20:42:17.518188.518188 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-14 20:42:17.518653.518653 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-14 20:42:17.518188.518188 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-14 20:42:17.519751.519751 cuda_h.py:19] end allocate_cuda_memory cost 0.0003445148468017578 seconds
DEBUG 01-14 20:42:17.519938.519938 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-14 20:42:17.519410.519410 sllm_store_c.py:27] get device uuid map
DEBUG 01-14 20:42:17.519563.519563 sllm_store_c.py:29] call client load into gpu
DEBUG 01-14 20:42:17.519458.519458 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 875eaf20-0a13-4811-b7ee-0fd22eb746b0
DEBUG 01-14 20:42:17.519716.519716 client.py:106] call stub.LoadModelAsync
INFO 01-14 20:42:17.521391.521391 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 875eaf20-0a13-4811-b7ee-0fd22eb746b0
DEBUG 01-14 20:42:17.521466.521466 cuda_h.py:19] end load_into_gpu_async cost 0.0018668174743652344 seconds
DEBUG 01-14 20:42:17.521168.521168 cuda_h.py:10] start restore_tensors2
DEBUG 01-14 20:42:17.521513.521513 cuda_h.py:19] end restore_tensors2 cost 0.00036716461181640625 seconds
DEBUG 01-14 20:42:17.521435.521435 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.002939462661743164 seconds
DEBUG 01-14 20:42:17.521681.521681 cuda_h.py:10] start restore2model
DEBUG 01-14 20:42:17.524582.524582 cuda_h.py:19] end restore2model cost 0.002529144287109375 seconds
DEBUG 01-14 20:42:17.524941.524941 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.005652427673339844 seconds
DEBUG 01-14 20:42:17.524750.524750 cuda_h.py:10] start gpu_sexperts
DEBUG 01-14 20:42:17.524833.524833 cuda_h.py:19] end gpu_sexperts cost 0.0002760887145996094 seconds
DEBUG 01-14 20:42:17.524616.524616 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-14 20:42:17.524273.524273 lmp.py:1683] 
DEBUG 01-14 20:42:17.524273.524273 lmp.py:1683]   Computing 32 experts on CPU...
DEBUG 01-14 20:42:17.524447.524447 cuda_h.py:19] end cpu_experts_submit cost 5.793571472167969e-05 seconds
DEBUG 01-14 20:42:17.524886.524886 cuda_h.py:10] start experts_func_mgpu_group_pad
DEBUG 01-14 20:42:17.529772.529772 mlpmodule.py:1460] group tensors cost 0.004683494567871094 s
DEBUG 01-14 20:42:17.530132.530132 cuda_h.py:10] start move_flat_hidden2cpu
DEBUG 01-14 20:42:17.533577.533577 cuda_h.py:19] end experts_func_mgpu_group_pad cost 0.008318901062011719 seconds
DEBUG 01-14 20:42:17.534736.534736 cuda_h.py:10] start gpu_group_list
DEBUG 01-14 20:42:17.535833.535833 cuda_h.py:19] end gpu_group_list cost 0.00041937828063964844 seconds
DEBUG 01-14 20:42:17.535462.535462 cuda_h.py:10] start wait_experts
INFO 01-14 20:42:17.535756.535756 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 875eaf20-0a13-4811-b7ee-0fd22eb746b0
DEBUG 01-14 20:42:17.537993.537993 cuda_h.py:19] end move_flat_hidden2cpu cost 0.006463527679443359 seconds
DEBUG 01-14 20:42:17.539850.539850 mlpmodule.py:1533] pad cost 0.00196075439453125 s
DEBUG 01-14 20:42:17.539483.539483 mlpmodule.py:1539] create cpu tensor cost 4.363059997558594e-05 s
DEBUG 01-14 20:42:17.541950.541950 mlpmodule.py:1544] move to cpu cost 0.0020270347595214844 s
DEBUG 01-14 20:42:17.548354.548354 mlpmodule.py:1558] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-14 20:42:17.548910.548910 mlpmodule.py:1559] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-14 20:42:17.548105.548105 mlpmodule.py:1564] group_w3 first element: -0.006439208984375
WARNING 01-14 20:42:17.548958.548958 mlpmodule.py:1574] start einsum2
DEBUG 01-14 20:42:17.561861.561861 mlpmodule.py:1584] group einsum cost 0.019999980926513672 s
DEBUG 01-14 20:42:17.562216.562216 mlpmodule.py:1593] cpy2cputensor cost 0.0006964206695556641 s
DEBUG 01-14 20:42:17.562423.562423 cuda_h.py:10] start move_outputs
DEBUG 01-14 20:42:17.565423.565423 cuda_h.py:19] end move_outputs cost 0.0027387142181396484 seconds
INFO 01-14 20:42:17.577753.577753 client.py:127] Model loaded
DEBUG 01-14 20:42:17.577241.577241 cuda_h.py:19] end wait_experts cost 0.04178261756896973 seconds
DEBUG 01-14 20:42:17.577388.577388 cuda_h.py:10] start gpu_experts
DEBUG 01-14 20:42:17.577104.577104 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-14 20:42:17.577561.577561 cuda_h.py:19] end wait_cetm_experts cost 0.0001647472381591797 seconds
DEBUG 01-14 20:42:17.577372.577372 cuda_h.py:10] start gpu_group_einsum_mp_multi_list
DEBUG 01-14 20:42:17.577128.577128 cuda_h.py:10] start gpu_group_tensor
DEBUG 01-14 20:42:17.577880.577880 mlpmodule.py:1367]  experts func einsum cost 0.052643775939941406 s
DEBUG 01-14 20:42:17.578716.578716 cuda_h.py:19] end gpu_group_tensor cost 0.0003180503845214844 seconds
DEBUG 01-14 20:42:17.578550.578550 cuda_h.py:10] start gpu_group_einsum
DEBUG 01-14 20:42:17.579102.579102 cuda_h.py:19] end gpu_group_einsum cost 0.0005970001220703125 seconds
DEBUG 01-14 20:42:17.579550.579550 cuda_h.py:10] start gpu_final_hidden_states_scatter
DEBUG 01-14 20:42:17.579393.579393 cuda_h.py:10] start all_expert_outputs_slices
DEBUG 01-14 20:42:17.579819.579819 cuda_h.py:19] end all_expert_outputs_slices cost 0.0002474784851074219 seconds
DEBUG 01-14 20:42:17.579052.579052 cuda_h.py:10] start concat_expert_out
DEBUG 01-14 20:42:17.579658.579658 cuda_h.py:19] end concat_expert_out cost 6.008148193359375e-05 seconds
DEBUG 01-14 20:42:17.579045.579045 cuda_h.py:10] start index_scatter
DEBUG 01-14 20:42:17.579326.579326 cuda_h.py:19] end index_scatter cost 6.961822509765625e-05 seconds
DEBUG 01-14 20:42:17.579943.579943 cuda_h.py:19] end gpu_final_hidden_states_scatter cost 0.00063323974609375 seconds
DEBUG 01-14 20:42:17.579283.579283 cuda_h.py:19] end gpu_experts cost 0.0023903846740722656 seconds
DEBUG 01-14 20:42:17.579648.579648 cuda_h.py:10] start all_expert_weight_slices
DEBUG 01-14 20:42:17.580702.580702 cuda_h.py:19] end all_expert_weight_slices cost 0.0007803440093994141 seconds
DEBUG 01-14 20:42:17.580048.580048 cuda_h.py:10] start cpuoutputsdeal
DEBUG 01-14 20:42:17.581570.581570 cuda_h.py:10] start index_scatter
DEBUG 01-14 20:42:17.581222.581222 cuda_h.py:19] end index_scatter cost 4.6253204345703125e-05 seconds
DEBUG 01-14 20:42:17.581746.581746 cuda_h.py:19] end cpuoutputsdeal cost 0.000453948974609375 seconds
DEBUG 01-14 20:42:17.581272.581272 cuda_h.py:19] end layer_moe_generate_mp_l_28 cost 0.0650014877319336 seconds
DEBUG 01-14 20:42:17.581065.581065 cuda_h.py:19] end prefill_layer cost 0.07075691223144531 seconds
DEBUG 01-14 20:42:17.581417.581417 lmp.py:1551] -------------------------------- end prefill layer 27 --------------------------------
DEBUG 01-14 20:42:17.581703.581703 cuda_h.py:19] end prefill cost 2.6761584281921387 seconds
DEBUG 01-14 20:42:19.748315.748315 cuda_h.py:10] start generate_input_ids
generate input ids cost 0.0994575023651123 s
DEBUG 01-14 20:42:20.091082.091082 cuda_h.py:19] end generate_input_ids cost 0.3428535461425781 seconds
DEBUG 01-14 20:42:20.091915.091915 cuda_h.py:10] start init_cache
DEBUG 01-14 20:42:20.091648.091648 cuda_h.py:19] end init_cache cost 5.340576171875e-05 seconds
DEBUG 01-14 20:42:22.544891.544891 cuda_h.py:10] start init_meta_layer
DEBUG 01-14 20:42:22.545085.545085 cuda_h.py:19] end init_meta_layer cost 3.0517578125e-05 seconds
DEBUG 01-14 20:42:22.545855.545855 cuda_h.py:10] start init_weights
DEBUG 01-14 20:42:22.545909.545909 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-14 20:42:22.545725.545725 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-14 20:42:22.547647.547647 cuda_h.py:19] end allocate_cuda_memory cost 0.0021920204162597656 seconds
DEBUG 01-14 20:42:22.547749.547749 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-14 20:42:22.547274.547274 sllm_store_c.py:27] get device uuid map
DEBUG 01-14 20:42:22.547846.547846 sllm_store_c.py:29] call client load into gpu
DEBUG 01-14 20:42:22.547356.547356 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 433302ba-b1b7-4020-b7dc-c6ce15209599
DEBUG 01-14 20:42:22.547684.547684 client.py:106] call stub.LoadModelAsync
INFO 01-14 20:42:22.549079.549079 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 433302ba-b1b7-4020-b7dc-c6ce15209599
DEBUG 01-14 20:42:22.549898.549898 cuda_h.py:19] end load_into_gpu_async cost 0.002028942108154297 seconds
DEBUG 01-14 20:42:22.549715.549715 cuda_h.py:10] start restore_tensors2
DEBUG 01-14 20:42:22.550569.550569 cuda_h.py:19] end restore_tensors2 cost 0.00011110305786132812 seconds
DEBUG 01-14 20:42:22.550556.550556 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.004666566848754883 seconds
DEBUG 01-14 20:42:22.550259.550259 cuda_h.py:10] start restore2model
DEBUG 01-14 20:42:22.550472.550472 cuda_h.py:19] end restore2model cost 0.00020360946655273438 seconds
INFO 01-14 20:42:22.550328.550328 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 433302ba-b1b7-4020-b7dc-c6ce15209599
INFO 01-14 20:42:22.629970.629970 client.py:127] Model loaded
DEBUG 01-14 20:42:22.629386.629386 cuda_h.py:10] start load_qkvogns_weight_l_0
DEBUG 01-14 20:42:22.629861.629861 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-14 20:42:22.629693.629693 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-14 20:42:22.630537.630537 cuda_h.py:19] end allocate_cuda_memory cost 0.0003898143768310547 seconds
DEBUG 01-14 20:42:22.630211.630211 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-14 20:42:22.630657.630657 sllm_store_c.py:27] get device uuid map
DEBUG 01-14 20:42:22.630309.630309 sllm_store_c.py:29] call client load into gpu
DEBUG 01-14 20:42:22.630643.630643 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, f1c30883-c692-4571-8138-d80ddac03b4f
DEBUG 01-14 20:42:22.630728.630728 client.py:106] call stub.LoadModelAsync
INFO 01-14 20:42:22.632781.632781 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, f1c30883-c692-4571-8138-d80ddac03b4f
DEBUG 01-14 20:42:22.632641.632641 cuda_h.py:19] end load_into_gpu_async cost 0.0020859241485595703 seconds
DEBUG 01-14 20:42:22.632041.632041 cuda_h.py:10] start restore_tensors2
DEBUG 01-14 20:42:22.632513.632513 cuda_h.py:19] end restore_tensors2 cost 0.00015926361083984375 seconds
DEBUG 01-14 20:42:22.632503.632503 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.003271341323852539 seconds
INFO 01-14 20:42:22.632035.632035 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, f1c30883-c692-4571-8138-d80ddac03b4f
INFO 01-14 20:42:22.647992.647992 client.py:127] Model loaded
DEBUG 01-14 20:42:22.648560.648560 cuda_h.py:10] start restore2model
DEBUG 01-14 20:42:22.649918.649918 cuda_h.py:19] end restore2model cost 0.0008904933929443359 seconds
DEBUG 01-14 20:42:22.649684.649684 cuda_h.py:19] end load_qkvogns_weight_l_0 cost 0.019679546356201172 seconds
DEBUG 01-14 20:42:22.649330.649330 cuda_h.py:19] end init_weights cost 0.10392999649047852 seconds
DEBUG 01-14 20:42:22.649325.649325 cuda_h.py:10] start copy_emodel
DEBUG 01-14 20:42:23.440873.440873 cuda_h.py:19] end copy_emodel cost 0.790579080581665 seconds
DEBUG 01-14 20:42:23.440172.440172 cuda_h.py:10] start init_inputs_tokens
DEBUG 01-14 20:42:23.441295.441295 cuda_h.py:19] end init_inputs_tokens cost 0.0002913475036621094 seconds
DEBUG 01-14 20:42:23.441595.441595 cuda_h.py:10] start prefill
DEBUG 01-14 20:42:23.441404.441404 cuda_h.py:10] start prefill_layer
DEBUG 01-14 20:42:23.441007.441007 lmp.py:1494] -------------------------------- start prefill layer 0 --------------------------------
DEBUG 01-14 20:42:23.441180.441180 cuda_h.py:10] start start_load_qkvogn_s_weight_l_1
DEBUG 01-14 20:42:23.441976.441976 cuda_h.py:10] start start_load_qkvogn_s_weight_l_1
DEBUG 01-14 20:42:23.441157.441157 cuda_h.py:19] end start_load_qkvogn_s_weight_l_1 cost 3.4809112548828125e-05 seconds
DEBUG 01-14 20:42:23.441767.441767 cuda_h.py:19] end start_load_qkvogn_s_weight_l_1 cost 7.05718994140625e-05 seconds
DEBUG 01-14 20:42:23.441079.441079 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-14 20:42:23.441823.441823 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-14 20:42:23.441362.441362 cuda_h.py:10] start sllm_worker_task
DEBUG 01-14 20:42:23.441360.441360 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-14 20:42:23.441216.441216 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-14 20:42:23.442076.442076 cuda_h.py:19] end allocate_cuda_memory cost 0.0003066062927246094 seconds
DEBUG 01-14 20:42:23.442212.442212 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-14 20:42:23.442365.442365 sllm_store_c.py:27] get device uuid map
DEBUG 01-14 20:42:23.442818.442818 sllm_store_c.py:29] call client load into gpu
DEBUG 01-14 20:42:23.442289.442289 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 8a26e9aa-9611-4cbe-a47a-ef550eec0b1b
DEBUG 01-14 20:42:23.442908.442908 client.py:106] call stub.LoadModelAsync
DEBUG 01-14 20:42:23.442344.442344 cuda_h.py:10] start self_attn
INFO 01-14 20:42:23.444427.444427 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 8a26e9aa-9611-4cbe-a47a-ef550eec0b1b
DEBUG 01-14 20:42:23.444621.444621 cuda_h.py:19] end load_into_gpu_async cost 0.0019087791442871094 seconds
DEBUG 01-14 20:42:23.444570.444570 cuda_h.py:10] start restore_tensors2
DEBUG 01-14 20:42:23.444772.444772 cuda_h.py:19] end restore_tensors2 cost 8.058547973632812e-05 seconds
DEBUG 01-14 20:42:23.444224.444224 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0026297569274902344 seconds
INFO 01-14 20:42:23.444074.444074 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 8a26e9aa-9611-4cbe-a47a-ef550eec0b1b
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-14 20:42:23.447200.447200 cuda_h.py:19] end self_attn cost 0.004147768020629883 seconds
DEBUG 01-14 20:42:23.447913.447913 cuda_h.py:19] end iln_self_attn_paln cost 0.0058879852294921875 seconds
DEBUG 01-14 20:42:23.447425.447425 cuda_h.py:10] start dense_mlp
INFO 01-14 20:42:23.453434.453434 client.py:127] Model loaded
DEBUG 01-14 20:42:23.453862.453862 cuda_h.py:10] start restore2model
DEBUG 01-14 20:42:23.453520.453520 cuda_h.py:19] end restore2model cost 0.0005786418914794922 seconds
DEBUG 01-14 20:42:23.453767.453767 cuda_h.py:19] end sllm_worker_task cost 0.012174606323242188 seconds
DEBUG 01-14 20:42:23.454546.454546 cuda_h.py:19] end dense_mlp cost 0.006546735763549805 seconds
DEBUG 01-14 20:42:23.454543.454543 cuda_h.py:19] end prefill_layer cost 0.012821435928344727 seconds
DEBUG 01-14 20:42:23.454683.454683 lmp.py:1551] -------------------------------- end prefill layer 0 --------------------------------
DEBUG 01-14 20:42:23.454094.454094 cuda_h.py:10] start prefill_layer
DEBUG 01-14 20:42:23.454651.454651 lmp.py:1494] -------------------------------- start prefill layer 1 --------------------------------
DEBUG 01-14 20:42:23.454778.454778 cuda_h.py:10] start start_load_qkvogn_s_weight_l_2
DEBUG 01-14 20:42:23.454620.454620 cuda_h.py:10] start start_load_qkvogn_s_weight_l_2
DEBUG 01-14 20:42:23.454443.454443 cuda_h.py:19] end start_load_qkvogn_s_weight_l_2 cost 2.0742416381835938e-05 seconds
DEBUG 01-14 20:42:23.454477.454477 cuda_h.py:19] end start_load_qkvogn_s_weight_l_2 cost 4.792213439941406e-05 seconds
DEBUG 01-14 20:42:23.454550.454550 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-14 20:42:23.454128.454128 cuda_h.py:10] start sllm_worker_task
DEBUG 01-14 20:42:23.454600.454600 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-14 20:42:23.454404.454404 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-14 20:42:23.454810.454810 cuda_h.py:19] end allocate_cuda_memory cost 0.0002129077911376953 seconds
DEBUG 01-14 20:42:23.454270.454270 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-14 20:42:23.454239.454239 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-14 20:42:23.455628.455628 sllm_store_c.py:27] get device uuid map
DEBUG 01-14 20:42:23.455334.455334 sllm_store_c.py:29] call client load into gpu
DEBUG 01-14 20:42:23.455515.455515 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 32c5a19b-415c-4b8e-a439-8ef0c9c612a5
DEBUG 01-14 20:42:23.455024.455024 client.py:106] call stub.LoadModelAsync
DEBUG 01-14 20:42:23.455766.455766 cuda_h.py:10] start self_attn
INFO 01-14 20:42:23.456055.456055 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 32c5a19b-415c-4b8e-a439-8ef0c9c612a5
DEBUG 01-14 20:42:23.457993.457993 cuda_h.py:19] end load_into_gpu_async cost 0.0019812583923339844 seconds
DEBUG 01-14 20:42:23.457380.457380 cuda_h.py:10] start restore_tensors2
DEBUG 01-14 20:42:23.457136.457136 cuda_h.py:19] end restore_tensors2 cost 0.00014972686767578125 seconds
DEBUG 01-14 20:42:23.457742.457742 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0030024051666259766 seconds
INFO 01-14 20:42:23.458412.458412 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 32c5a19b-415c-4b8e-a439-8ef0c9c612a5
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-14 20:42:23.461895.461895 cuda_h.py:19] end self_attn cost 0.006131410598754883 seconds
DEBUG 01-14 20:42:23.462422.462422 cuda_h.py:19] end iln_self_attn_paln cost 0.007806301116943359 seconds
DEBUG 01-14 20:42:23.462312.462312 cuda_h.py:10] start layer_moe_generate_mp_l_2
DEBUG 01-14 20:42:23.462459.462459 cuda_h.py:10] start gate
DEBUG 01-14 20:42:23.463388.463388 cuda_h.py:19] end gate cost 0.0007905960083007812 seconds
DEBUG 01-14 20:42:23.463456.463456 cuda_h.py:10] start experts_map_get
DEBUG 01-14 20:42:23.463883.463883 lmp.py:1615] 
DEBUG 01-14 20:42:23.463883.463883 lmp.py:1615] Expert Token Distribution & Device Allocation:
DEBUG 01-14 20:42:23.463070.463070 lmp.py:1616]   Total experts: 64
DEBUG 01-14 20:42:23.463389.463389 lmp.py:1617]   CPU experts: 32 (50%)
DEBUG 01-14 20:42:23.463800.463800 lmp.py:1618]   GPU experts: 32 (50%)
DEBUG 01-14 20:42:23.463112.463112 lmp.py:1619] 
DEBUG 01-14 20:42:23.463112.463112 lmp.py:1619]   Expert ID | Tokens | Device
DEBUG 01-14 20:42:23.463901.463901 lmp.py:1620]   -----------------------------------
DEBUG 01-14 20:42:23.463789.463789 lmp.py:1625]   Expert 25 |     64 | CPU
DEBUG 01-14 20:42:23.463385.463385 lmp.py:1625]   Expert 54 |     67 | CPU
DEBUG 01-14 20:42:23.463267.463267 lmp.py:1625]   Expert  3 |     68 | CPU
DEBUG 01-14 20:42:23.463910.463910 lmp.py:1625]   Expert 31 |     72 | CPU
DEBUG 01-14 20:42:23.463553.463553 lmp.py:1625]   Expert 55 |     72 | CPU
DEBUG 01-14 20:42:23.463434.463434 lmp.py:1625]   Expert 62 |     87 | CPU
DEBUG 01-14 20:42:23.463316.463316 lmp.py:1625]   Expert 18 |     88 | CPU
DEBUG 01-14 20:42:23.463151.463151 lmp.py:1625]   Expert 52 |     98 | CPU
DEBUG 01-14 20:42:23.463747.463747 lmp.py:1625]   Expert 22 |    100 | CPU
DEBUG 01-14 20:42:23.463582.463582 lmp.py:1625]   Expert 47 |    104 | CPU
DEBUG 01-14 20:42:23.463464.463464 lmp.py:1625]   Expert  0 |    113 | CPU
DEBUG 01-14 20:42:23.463868.463868 lmp.py:1625]   Expert 37 |    117 | CPU
DEBUG 01-14 20:42:23.463273.463273 lmp.py:1625]   Expert 27 |    121 | CPU
DEBUG 01-14 20:42:23.463677.463677 lmp.py:1625]   Expert 32 |    123 | CPU
DEBUG 01-14 20:42:23.463844.463844 lmp.py:1625]   Expert 41 |    130 | CPU
DEBUG 01-14 20:42:23.463487.463487 lmp.py:1625]   Expert 44 |    131 | CPU
DEBUG 01-14 20:42:23.463891.463891 lmp.py:1625]   Expert 28 |    136 | CPU
DEBUG 01-14 20:42:23.463772.463772 lmp.py:1625]   Expert 13 |    138 | CPU
DEBUG 01-14 20:42:23.463415.463415 lmp.py:1625]   Expert 58 |    140 | CPU
DEBUG 01-14 20:42:23.463396.463396 lmp.py:1625]   Expert 60 |    144 | CPU
DEBUG 01-14 20:42:23.464231.464231 lmp.py:1625]   Expert 43 |    147 | CPU
DEBUG 01-14 20:42:23.464451.464451 lmp.py:1625]   Expert  1 |    150 | CPU
DEBUG 01-14 20:42:23.464094.464094 lmp.py:1625]   Expert 38 |    153 | CPU
DEBUG 01-14 20:42:23.464975.464975 lmp.py:1625]   Expert 49 |    154 | CPU
DEBUG 01-14 20:42:23.464141.464141 lmp.py:1625]   Expert 51 |    155 | CPU
DEBUG 01-14 20:42:23.464784.464784 lmp.py:1625]   Expert 34 |    161 | CPU
DEBUG 01-14 20:42:23.464950.464950 lmp.py:1625]   Expert 35 |    164 | CPU
DEBUG 01-14 20:42:23.464832.464832 lmp.py:1625]   Expert 36 |    168 | CPU
DEBUG 01-14 20:42:23.464236.464236 lmp.py:1625]   Expert 11 |    170 | CPU
DEBUG 01-14 20:42:23.464641.464641 lmp.py:1625]   Expert 17 |    170 | CPU
DEBUG 01-14 20:42:23.464807.464807 lmp.py:1625]   Expert 59 |    174 | CPU
DEBUG 01-14 20:42:23.464688.464688 lmp.py:1625]   Expert 10 |    180 | CPU
DEBUG 01-14 20:42:23.464523.464523 lmp.py:1625]   Expert 20 |    182 | GPU
DEBUG 01-14 20:42:23.464597.464597 lmp.py:1625]   Expert  2 |    186 | GPU
DEBUG 01-14 20:42:23.464240.464240 lmp.py:1625]   Expert 39 |    189 | GPU
DEBUG 01-14 20:42:23.464360.464360 lmp.py:1625]   Expert 33 |    197 | GPU
DEBUG 01-14 20:42:23.464764.464764 lmp.py:1625]   Expert 12 |    198 | GPU
DEBUG 01-14 20:42:23.464884.464884 lmp.py:1625]   Expert 21 |    198 | GPU
DEBUG 01-14 20:42:23.464527.464527 lmp.py:1625]   Expert 48 |    198 | GPU
DEBUG 01-14 20:42:23.464170.464170 lmp.py:1625]   Expert 15 |    199 | GPU
DEBUG 01-14 20:42:23.464574.464574 lmp.py:1625]   Expert 53 |    204 | GPU
DEBUG 01-14 20:42:23.464801.464801 lmp.py:1625]   Expert 19 |    220 | GPU
DEBUG 01-14 20:42:23.464159.464159 lmp.py:1625]   Expert 26 |    221 | GPU
DEBUG 01-14 20:42:23.464279.464279 lmp.py:1625]   Expert 30 |    221 | GPU
DEBUG 01-14 20:42:23.464445.464445 lmp.py:1625]   Expert 45 |    221 | GPU
DEBUG 01-14 20:42:23.464041.464041 lmp.py:1625]   Expert  5 |    227 | GPU
DEBUG 01-14 20:42:23.464307.464307 lmp.py:1625]   Expert  4 |    229 | GPU
DEBUG 01-14 20:42:23.464142.464142 lmp.py:1625]   Expert 24 |    229 | GPU
DEBUG 01-14 20:42:23.464500.464500 lmp.py:1625]   Expert 42 |    242 | GPU
DEBUG 01-14 20:42:23.464143.464143 lmp.py:1625]   Expert 50 |    245 | GPU
DEBUG 01-14 20:42:23.464071.464071 lmp.py:1625]   Expert 29 |    254 | GPU
DEBUG 01-14 20:42:23.464475.464475 lmp.py:1625]   Expert 56 |    262 | GPU
DEBUG 01-14 20:42:23.464118.464118 lmp.py:1625]   Expert 61 |    270 | GPU
DEBUG 01-14 20:42:23.464761.464761 lmp.py:1625]   Expert  8 |    283 | GPU
DEBUG 01-14 20:42:23.464166.464166 lmp.py:1625]   Expert 63 |    285 | GPU
DEBUG 01-14 20:42:23.464809.464809 lmp.py:1625]   Expert 46 |    294 | GPU
DEBUG 01-14 20:42:23.464214.464214 lmp.py:1625]   Expert  9 |    300 | GPU
DEBUG 01-14 20:42:23.464856.464856 lmp.py:1625]   Expert  6 |    316 | GPU
DEBUG 01-14 20:42:23.464023.464023 lmp.py:1625]   Expert 16 |    316 | GPU
DEBUG 01-14 20:42:23.464381.464381 lmp.py:1625]   Expert 40 |    319 | GPU
DEBUG 01-14 20:42:23.464739.464739 lmp.py:1625]   Expert  7 |    322 | GPU
DEBUG 01-14 20:42:23.464574.464574 lmp.py:1625]   Expert 23 |    325 | GPU
DEBUG 01-14 20:42:23.464740.464740 lmp.py:1625]   Expert 14 |    413 | GPU
DEBUG 01-14 20:42:23.464906.464906 lmp.py:1625]   Expert 57 |    464 | GPU
DEBUG 01-14 20:42:23.464265.464265 lmp.py:1626] 
DEBUG 01-14 20:42:23.464265.464265 lmp.py:1626]   CPU total tokens: 4059 (33.0%)
DEBUG 01-14 20:42:23.464338.464338 lmp.py:1627]   GPU total tokens: 8229 (67.0%)
DEBUG 01-14 20:42:23.464465.464465 cuda_h.py:19] end experts_map_get cost 0.0016281604766845703 seconds
DEBUG 01-14 20:42:23.464481.464481 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-14 20:42:23.464946.464946 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-14 20:42:23.465137.465137 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-14 20:42:23.465343.465343 cuda_h.py:19] end allocate_cuda_memory cost 0.00018930435180664062 seconds
DEBUG 01-14 20:42:23.465040.465040 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-14 20:42:23.465226.465226 sllm_store_c.py:27] get device uuid map
DEBUG 01-14 20:42:23.465771.465771 sllm_store_c.py:29] call client load into gpu
DEBUG 01-14 20:42:23.465183.465183 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 45a40ee7-d92c-4dc0-bf81-ae018247502a
DEBUG 01-14 20:42:23.465913.465913 client.py:106] call stub.LoadModelAsync
INFO 01-14 20:42:23.466702.466702 client.py:127] Model loaded
DEBUG 01-14 20:42:23.466932.466932 cuda_h.py:10] start restore2model
DEBUG 01-14 20:42:23.467795.467795 cuda_h.py:19] end restore2model cost 0.0009648799896240234 seconds
DEBUG 01-14 20:42:23.467667.467667 cuda_h.py:19] end sllm_worker_task cost 0.012859344482421875 seconds
INFO 01-14 20:42:23.467580.467580 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 45a40ee7-d92c-4dc0-bf81-ae018247502a
DEBUG 01-14 20:42:23.467099.467099 cuda_h.py:19] end load_into_gpu_async cost 0.002324342727661133 seconds
DEBUG 01-14 20:42:23.467994.467994 cuda_h.py:10] start restore_tensors2
DEBUG 01-14 20:42:23.468702.468702 cuda_h.py:19] end restore_tensors2 cost 0.0003516674041748047 seconds
DEBUG 01-14 20:42:23.468161.468161 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0032224655151367188 seconds
DEBUG 01-14 20:42:23.468540.468540 cuda_h.py:10] start restore2model
DEBUG 01-14 20:42:23.470735.470735 cuda_h.py:19] end restore2model cost 0.002641916275024414 seconds
DEBUG 01-14 20:42:23.471923.471923 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.006052255630493164 seconds
DEBUG 01-14 20:42:23.471387.471387 cuda_h.py:10] start gpu_sexperts
DEBUG 01-14 20:42:23.471722.471722 cuda_h.py:19] end gpu_sexperts cost 0.000286102294921875 seconds
DEBUG 01-14 20:42:23.471784.471784 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-14 20:42:23.471440.471440 lmp.py:1683] 
DEBUG 01-14 20:42:23.471440.471440 lmp.py:1683]   Computing 32 experts on CPU...
DEBUG 01-14 20:42:23.471283.471283 cuda_h.py:19] end cpu_experts_submit cost 5.984306335449219e-05 seconds
DEBUG 01-14 20:42:23.471032.471032 cuda_h.py:10] start experts_func_mgpu_group_pad
DEBUG 01-14 20:42:23.483720.483720 mlpmodule.py:1460] group tensors cost 0.010868072509765625 s
DEBUG 01-14 20:42:23.484679.484679 cuda_h.py:10] start move_flat_hidden2cpu
DEBUG 01-14 20:42:23.487265.487265 cuda_h.py:19] end experts_func_mgpu_group_pad cost 0.015860557556152344 seconds
DEBUG 01-14 20:42:23.489765.489765 cuda_h.py:10] start gpu_group_list
DEBUG 01-14 20:42:23.490344.490344 cuda_h.py:19] end gpu_group_list cost 0.0005428791046142578 seconds
DEBUG 01-14 20:42:23.490493.490493 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-14 20:42:23.490901.490901 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 3.5762786865234375e-05 seconds
DEBUG 01-14 20:42:23.490386.490386 cuda_h.py:10] start wait_experts
INFO 01-14 20:42:23.490541.490541 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 45a40ee7-d92c-4dc0-bf81-ae018247502a
DEBUG 01-14 20:42:23.494104.494104 cuda_h.py:19] end move_flat_hidden2cpu cost 0.0102081298828125 seconds
DEBUG 01-14 20:42:23.497614.497614 mlpmodule.py:1533] pad cost 0.0022373199462890625 s
DEBUG 01-14 20:42:23.497015.497015 mlpmodule.py:1539] create cpu tensor cost 4.506111145019531e-05 s
DEBUG 01-14 20:42:23.499684.499684 mlpmodule.py:1544] move to cpu cost 0.0021409988403320312 s
DEBUG 01-14 20:42:23.511283.511283 mlpmodule.py:1558] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-14 20:42:23.511136.511136 mlpmodule.py:1559] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-14 20:42:23.511311.511311 mlpmodule.py:1564] group_w3 first element: -0.0107421875
WARNING 01-14 20:42:23.511357.511357 mlpmodule.py:1574] start einsum2
INFO 01-14 20:42:23.519746.519746 client.py:127] Model loaded
DEBUG 01-14 20:42:23.519277.519277 cuda_h.py:19] end wait_experts cost 0.028508901596069336 seconds
DEBUG 01-14 20:42:23.519829.519829 cuda_h.py:10] start gpu_experts
DEBUG 01-14 20:42:23.519811.519811 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-14 20:42:23.528199.528199 mlpmodule.py:1584] group einsum cost 0.029117822647094727 s
DEBUG 01-14 20:42:23.529588.529588 mlpmodule.py:1593] cpy2cputensor cost 0.0007398128509521484 s
DEBUG 01-14 20:42:23.529941.529941 cuda_h.py:10] start move_outputs
DEBUG 01-14 20:42:23.531643.531643 cuda_h.py:19] end move_outputs cost 0.002131938934326172 seconds
DEBUG 01-14 20:42:23.536145.536145 cuda_h.py:19] end wait_cetm_experts cost 0.017396211624145508 seconds
DEBUG 01-14 20:42:23.537738.537738 cuda_h.py:10] start gpu_group_einsum_mp_multi_list
DEBUG 01-14 20:42:23.537925.537925 cuda_h.py:10] start gpu_group_tensor
DEBUG 01-14 20:42:23.550737.550737 mlpmodule.py:1367]  experts func einsum cost 0.07770013809204102 s
DEBUG 01-14 20:42:23.550058.550058 cuda_h.py:19] end gpu_group_tensor cost 0.01356196403503418 seconds
DEBUG 01-14 20:42:23.551437.551437 cuda_h.py:10] start gpu_group_einsum
DEBUG 01-14 20:42:23.552239.552239 cuda_h.py:19] end gpu_group_einsum cost 0.0011546611785888672 seconds
DEBUG 01-14 20:42:23.552622.552622 cuda_h.py:10] start gpu_final_hidden_states_scatter
DEBUG 01-14 20:42:23.552902.552902 cuda_h.py:10] start all_expert_outputs_slices
DEBUG 01-14 20:42:23.553410.553410 cuda_h.py:19] end all_expert_outputs_slices cost 0.00030040740966796875 seconds
DEBUG 01-14 20:42:23.553603.553603 cuda_h.py:10] start concat_expert_out
DEBUG 01-14 20:42:23.553421.553421 cuda_h.py:19] end concat_expert_out cost 0.00024390220642089844 seconds
DEBUG 01-14 20:42:23.553318.553318 cuda_h.py:10] start index_scatter
DEBUG 01-14 20:42:23.553846.553846 cuda_h.py:19] end index_scatter cost 9.179115295410156e-05 seconds
DEBUG 01-14 20:42:23.553954.553954 cuda_h.py:19] end gpu_final_hidden_states_scatter cost 0.0009660720825195312 seconds
DEBUG 01-14 20:42:23.553520.553520 cuda_h.py:19] end gpu_experts cost 0.03424549102783203 seconds
DEBUG 01-14 20:42:23.553614.553614 cuda_h.py:10] start all_expert_weight_slices
DEBUG 01-14 20:42:23.554748.554748 cuda_h.py:19] end all_expert_weight_slices cost 0.0010111331939697266 seconds
DEBUG 01-14 20:42:23.554101.554101 cuda_h.py:10] start cpuoutputsdeal
DEBUG 01-14 20:42:23.555381.555381 cuda_h.py:10] start index_scatter
DEBUG 01-14 20:42:23.555656.555656 cuda_h.py:19] end index_scatter cost 4.863739013671875e-05 seconds
DEBUG 01-14 20:42:23.555134.555134 cuda_h.py:19] end cpuoutputsdeal cost 0.0005538463592529297 seconds
DEBUG 01-14 20:42:23.555514.555514 cuda_h.py:19] end layer_moe_generate_mp_l_2 cost 0.09319949150085449 seconds
DEBUG 01-14 20:42:23.555736.555736 cuda_h.py:19] end prefill_layer cost 0.10160374641418457 seconds
DEBUG 01-14 20:42:23.555400.555400 lmp.py:1551] -------------------------------- end prefill layer 1 --------------------------------
DEBUG 01-14 20:42:23.555957.555957 cuda_h.py:10] start prefill_layer
DEBUG 01-14 20:42:23.555183.555183 lmp.py:1494] -------------------------------- start prefill layer 2 --------------------------------
DEBUG 01-14 20:42:23.555979.555979 cuda_h.py:10] start start_load_qkvogn_s_weight_l_3
DEBUG 01-14 20:42:23.555874.555874 cuda_h.py:10] start start_load_qkvogn_s_weight_l_3
DEBUG 01-14 20:42:23.556379.556379 cuda_h.py:19] end start_load_qkvogn_s_weight_l_3 cost 3.218650817871094e-05 seconds
DEBUG 01-14 20:42:23.556890.556890 cuda_h.py:19] end start_load_qkvogn_s_weight_l_3 cost 6.079673767089844e-05 seconds
DEBUG 01-14 20:42:23.556725.556725 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-14 20:42:23.556569.556569 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-14 20:42:23.556221.556221 cuda_h.py:10] start sllm_worker_task
DEBUG 01-14 20:42:23.556849.556849 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-14 20:42:23.556415.556415 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-14 20:42:23.556644.556644 cuda_h.py:19] end allocate_cuda_memory cost 0.00023937225341796875 seconds
DEBUG 01-14 20:42:23.556999.556999 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-14 20:42:23.557803.557803 sllm_store_c.py:27] get device uuid map
DEBUG 01-14 20:42:23.557349.557349 sllm_store_c.py:29] call client load into gpu
DEBUG 01-14 20:42:23.557185.557185 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 532b561a-1e9c-4ebb-a6b4-0ab59b842b18
DEBUG 01-14 20:42:23.557713.557713 client.py:106] call stub.LoadModelAsync
DEBUG 01-14 20:42:23.557692.557692 cuda_h.py:10] start self_attn
INFO 01-14 20:42:23.559634.559634 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 532b561a-1e9c-4ebb-a6b4-0ab59b842b18
DEBUG 01-14 20:42:23.559671.559671 cuda_h.py:19] end load_into_gpu_async cost 0.0021829605102539062 seconds
DEBUG 01-14 20:42:23.559030.559030 cuda_h.py:10] start restore_tensors2
DEBUG 01-14 20:42:23.559221.559221 cuda_h.py:19] end restore_tensors2 cost 0.00012159347534179688 seconds
DEBUG 01-14 20:42:23.559980.559980 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.003036975860595703 seconds
INFO 01-14 20:42:23.559838.559838 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 532b561a-1e9c-4ebb-a6b4-0ab59b842b18
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-14 20:42:23.560448.560448 cuda_h.py:19] end self_attn cost 0.003326416015625 seconds
DEBUG 01-14 20:42:23.561114.561114 cuda_h.py:19] end iln_self_attn_paln cost 0.0050563812255859375 seconds
DEBUG 01-14 20:42:23.561434.561434 cuda_h.py:10] start layer_moe_generate_mp_l_3
DEBUG 01-14 20:42:23.561197.561197 cuda_h.py:10] start gate
DEBUG 01-14 20:42:23.561035.561035 cuda_h.py:19] end gate cost 0.0006508827209472656 seconds
DEBUG 01-14 20:42:23.562838.562838 cuda_h.py:10] start experts_map_get
DEBUG 01-14 20:42:23.562664.562664 lmp.py:1615] 
DEBUG 01-14 20:42:23.562664.562664 lmp.py:1615] Expert Token Distribution & Device Allocation:
DEBUG 01-14 20:42:23.562757.562757 lmp.py:1616]   Total experts: 64
DEBUG 01-14 20:42:23.562315.562315 lmp.py:1617]   CPU experts: 32 (50%)
DEBUG 01-14 20:42:23.562534.562534 lmp.py:1618]   GPU experts: 32 (50%)
DEBUG 01-14 20:42:23.562084.562084 lmp.py:1619] 
DEBUG 01-14 20:42:23.562084.562084 lmp.py:1619]   Expert ID | Tokens | Device
DEBUG 01-14 20:42:23.562873.562873 lmp.py:1620]   -----------------------------------
DEBUG 01-14 20:42:23.562662.562662 lmp.py:1625]   Expert 58 |     57 | CPU
DEBUG 01-14 20:42:23.562781.562781 lmp.py:1625]   Expert 27 |     80 | CPU
DEBUG 01-14 20:42:23.562186.562186 lmp.py:1625]   Expert  3 |     85 | CPU
DEBUG 01-14 20:42:23.562352.562352 lmp.py:1625]   Expert 24 |     86 | CPU
DEBUG 01-14 20:42:23.562518.562518 lmp.py:1625]   Expert 17 |     87 | CPU
DEBUG 01-14 20:42:23.562446.562446 lmp.py:1625]   Expert  0 |     88 | CPU
DEBUG 01-14 20:42:23.562851.562851 lmp.py:1625]   Expert 28 |    106 | CPU
DEBUG 01-14 20:42:23.562017.562017 lmp.py:1625]   Expert 34 |    108 | CPU
DEBUG 01-14 20:42:23.562183.562183 lmp.py:1625]   Expert 51 |    112 | CPU
DEBUG 01-14 20:42:23.562587.562587 lmp.py:1625]   Expert 32 |    117 | CPU
DEBUG 01-14 20:42:23.562946.562946 lmp.py:1625]   Expert 23 |    122 | CPU
DEBUG 01-14 20:42:23.562304.562304 lmp.py:1625]   Expert 15 |    128 | CPU
DEBUG 01-14 20:42:23.562662.562662 lmp.py:1625]   Expert  7 |    133 | CPU
DEBUG 01-14 20:42:23.562259.562259 lmp.py:1625]   Expert 26 |    135 | CPU
DEBUG 01-14 20:42:23.562902.562902 lmp.py:1625]   Expert  9 |    138 | CPU
DEBUG 01-14 20:42:23.562068.562068 lmp.py:1625]   Expert 30 |    141 | CPU
DEBUG 01-14 20:42:23.562472.562472 lmp.py:1625]   Expert 57 |    142 | CPU
DEBUG 01-14 20:42:23.562639.562639 lmp.py:1625]   Expert 62 |    145 | CPU
DEBUG 01-14 20:42:23.562566.562566 lmp.py:1625]   Expert 45 |    146 | CPU
DEBUG 01-14 20:42:23.562494.562494 lmp.py:1625]   Expert  1 |    150 | CPU
DEBUG 01-14 20:42:23.562660.562660 lmp.py:1625]   Expert  6 |    152 | CPU
DEBUG 01-14 20:42:23.562349.562349 lmp.py:1625]   Expert 48 |    157 | CPU
DEBUG 01-14 20:42:23.562516.562516 lmp.py:1625]   Expert  8 |    162 | CPU
DEBUG 01-14 20:42:23.562682.562682 lmp.py:1625]   Expert 54 |    165 | CPU
DEBUG 01-14 20:42:23.562563.562563 lmp.py:1625]   Expert 25 |    166 | CPU
DEBUG 01-14 20:42:23.562921.562921 lmp.py:1625]   Expert 49 |    168 | CPU
DEBUG 01-14 20:42:23.562280.562280 lmp.py:1625]   Expert 29 |    172 | CPU
DEBUG 01-14 20:42:23.562638.562638 lmp.py:1625]   Expert 35 |    173 | CPU
DEBUG 01-14 20:42:23.562804.562804 lmp.py:1625]   Expert 36 |    173 | CPU
DEBUG 01-14 20:42:23.563970.563970 lmp.py:1625]   Expert 12 |    176 | CPU
DEBUG 01-14 20:42:23.563898.563898 lmp.py:1625]   Expert 37 |    186 | CPU
DEBUG 01-14 20:42:23.563825.563825 lmp.py:1625]   Expert 53 |    187 | CPU
DEBUG 01-14 20:42:23.563515.563515 lmp.py:1625]   Expert 13 |    188 | GPU
DEBUG 01-14 20:42:23.563204.563204 lmp.py:1625]   Expert 33 |    190 | GPU
DEBUG 01-14 20:42:23.563132.563132 lmp.py:1625]   Expert 60 |    190 | GPU
DEBUG 01-14 20:42:23.563444.563444 lmp.py:1625]   Expert 16 |    195 | GPU
DEBUG 01-14 20:42:23.563040.563040 lmp.py:1625]   Expert 40 |    200 | GPU
DEBUG 01-14 20:42:23.563836.563836 lmp.py:1625]   Expert 21 |    201 | GPU
DEBUG 01-14 20:42:23.563671.563671 lmp.py:1625]   Expert 38 |    202 | GPU
DEBUG 01-14 20:42:23.563552.563552 lmp.py:1625]   Expert 19 |    208 | GPU
DEBUG 01-14 20:42:23.563911.563911 lmp.py:1625]   Expert  5 |    209 | GPU
DEBUG 01-14 20:42:23.563838.563838 lmp.py:1625]   Expert 41 |    213 | GPU
DEBUG 01-14 20:42:23.563766.563766 lmp.py:1625]   Expert 43 |    214 | GPU
DEBUG 01-14 20:42:23.563455.563455 lmp.py:1625]   Expert 10 |    215 | GPU
DEBUG 01-14 20:42:23.563906.563906 lmp.py:1625]   Expert 52 |    217 | GPU
DEBUG 01-14 20:42:23.563834.563834 lmp.py:1625]   Expert 50 |    219 | GPU
DEBUG 01-14 20:42:23.563762.563762 lmp.py:1625]   Expert 44 |    220 | GPU
DEBUG 01-14 20:42:23.563689.563689 lmp.py:1625]   Expert  4 |    221 | GPU
DEBUG 01-14 20:42:23.563856.563856 lmp.py:1625]   Expert 56 |    227 | GPU
DEBUG 01-14 20:42:23.563545.563545 lmp.py:1625]   Expert 59 |    230 | GPU
DEBUG 01-14 20:42:23.563996.563996 lmp.py:1625]   Expert 55 |    234 | GPU
DEBUG 01-14 20:42:23.563115.563115 lmp.py:1625]   Expert 31 |    245 | GPU
DEBUG 01-14 20:42:23.563758.563758 lmp.py:1625]   Expert 39 |    246 | GPU
DEBUG 01-14 20:42:23.563640.563640 lmp.py:1625]   Expert 22 |    255 | GPU
DEBUG 01-14 20:42:23.563521.563521 lmp.py:1625]   Expert 20 |    260 | GPU
DEBUG 01-14 20:42:23.563449.563449 lmp.py:1625]   Expert  2 |    269 | GPU
DEBUG 01-14 20:42:23.563138.563138 lmp.py:1625]   Expert 63 |    279 | GPU
DEBUG 01-14 20:42:23.563589.563589 lmp.py:1625]   Expert 47 |    284 | GPU
DEBUG 01-14 20:42:23.563517.563517 lmp.py:1625]   Expert 18 |    301 | GPU
DEBUG 01-14 20:42:23.563968.563968 lmp.py:1625]   Expert 14 |    310 | GPU
DEBUG 01-14 20:42:23.563657.563657 lmp.py:1625]   Expert 42 |    320 | GPU
DEBUG 01-14 20:42:23.563346.563346 lmp.py:1625]   Expert 46 |    373 | GPU
DEBUG 01-14 20:42:23.563797.563797 lmp.py:1625]   Expert 11 |    376 | GPU
DEBUG 01-14 20:42:23.563679.563679 lmp.py:1625]   Expert 61 |    434 | GPU
DEBUG 01-14 20:42:23.563752.563752 lmp.py:1626] 
DEBUG 01-14 20:42:23.563752.563752 lmp.py:1626]   CPU total tokens: 4343 (35.3%)
DEBUG 01-14 20:42:23.563302.563302 lmp.py:1627]   GPU total tokens: 7945 (64.7%)
DEBUG 01-14 20:42:23.563144.563144 cuda_h.py:19] end experts_map_get cost 0.0015971660614013672 seconds
DEBUG 01-14 20:42:23.563564.563564 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-14 20:42:23.563645.563645 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-14 20:42:23.563299.563299 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-14 20:42:23.565375.565375 cuda_h.py:19] end allocate_cuda_memory cost 0.0012497901916503906 seconds
DEBUG 01-14 20:42:23.565794.565794 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-14 20:42:23.565788.565788 sllm_store_c.py:27] get device uuid map
DEBUG 01-14 20:42:23.565697.565697 sllm_store_c.py:29] call client load into gpu
DEBUG 01-14 20:42:23.565016.565016 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, ed4692e7-89d3-43e0-8689-3a77ae478204
DEBUG 01-14 20:42:23.565565.565565 client.py:106] call stub.LoadModelAsync
INFO 01-14 20:42:23.566720.566720 client.py:127] Model loaded
DEBUG 01-14 20:42:23.567744.567744 cuda_h.py:10] start restore2model
DEBUG 01-14 20:42:23.568900.568900 cuda_h.py:19] end restore2model cost 0.0008156299591064453 seconds
DEBUG 01-14 20:42:23.568839.568839 cuda_h.py:19] end sllm_worker_task cost 0.011760234832763672 seconds
INFO 01-14 20:42:23.568507.568507 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, ed4692e7-89d3-43e0-8689-3a77ae478204
DEBUG 01-14 20:42:23.568662.568662 cuda_h.py:19] end load_into_gpu_async cost 0.003133058547973633 seconds
DEBUG 01-14 20:42:23.568418.568418 cuda_h.py:10] start restore_tensors2
DEBUG 01-14 20:42:23.568756.568756 cuda_h.py:19] end restore_tensors2 cost 0.00039768218994140625 seconds
DEBUG 01-14 20:42:23.568500.568500 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.005135297775268555 seconds
DEBUG 01-14 20:42:23.568263.568263 cuda_h.py:10] start restore2model
DEBUG 01-14 20:42:23.571710.571710 cuda_h.py:19] end restore2model cost 0.0026471614837646484 seconds
DEBUG 01-14 20:42:23.571560.571560 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.007974386215209961 seconds
DEBUG 01-14 20:42:23.571879.571879 cuda_h.py:10] start gpu_sexperts
DEBUG 01-14 20:42:23.572518.572518 cuda_h.py:19] end gpu_sexperts cost 0.00026535987854003906 seconds
DEBUG 01-14 20:42:23.572599.572599 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-14 20:42:23.572733.572733 lmp.py:1683] 
DEBUG 01-14 20:42:23.572733.572733 lmp.py:1683]   Computing 32 experts on CPU...
DEBUG 01-14 20:42:23.572006.572006 cuda_h.py:19] end cpu_experts_submit cost 6.0558319091796875e-05 seconds
DEBUG 01-14 20:42:23.572385.572385 cuda_h.py:10] start experts_func_mgpu_group_pad
DEBUG 01-14 20:42:23.579874.579874 mlpmodule.py:1460] group tensors cost 0.006972312927246094 s
DEBUG 01-14 20:42:23.580133.580133 cuda_h.py:10] start move_flat_hidden2cpu
DEBUG 01-14 20:42:23.582609.582609 cuda_h.py:19] end experts_func_mgpu_group_pad cost 0.010194063186645508 seconds
DEBUG 01-14 20:42:23.583619.583619 cuda_h.py:10] start gpu_group_list
DEBUG 01-14 20:42:23.584771.584771 cuda_h.py:19] end gpu_group_list cost 0.0004858970642089844 seconds
DEBUG 01-14 20:42:23.584315.584315 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-14 20:42:23.584710.584710 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.4557113647460938e-05 seconds
DEBUG 01-14 20:42:23.585908.585908 cuda_h.py:10] start wait_experts
INFO 01-14 20:42:23.585003.585003 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, ed4692e7-89d3-43e0-8689-3a77ae478204
DEBUG 01-14 20:42:23.588345.588345 cuda_h.py:19] end move_flat_hidden2cpu cost 0.0076181888580322266 seconds
DEBUG 01-14 20:42:23.590642.590642 mlpmodule.py:1533] pad cost 0.002033233642578125 s
DEBUG 01-14 20:42:23.590858.590858 mlpmodule.py:1539] create cpu tensor cost 4.8160552978515625e-05 s
DEBUG 01-14 20:42:23.592391.592391 mlpmodule.py:1544] move to cpu cost 0.0022139549255371094 s
DEBUG 01-14 20:42:23.602496.602496 mlpmodule.py:1558] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-14 20:42:23.602423.602423 mlpmodule.py:1559] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-14 20:42:23.602082.602082 mlpmodule.py:1564] group_w3 first element: -0.0380859375
WARNING 01-14 20:42:23.602351.602351 mlpmodule.py:1574] start einsum2
DEBUG 01-14 20:42:23.619617.619617 mlpmodule.py:1584] group einsum cost 0.026834964752197266 s
DEBUG 01-14 20:42:23.620254.620254 mlpmodule.py:1593] cpy2cputensor cost 0.0007989406585693359 s
DEBUG 01-14 20:42:23.620275.620275 cuda_h.py:10] start move_outputs
INFO 01-14 20:42:23.621680.621680 client.py:127] Model loaded
DEBUG 01-14 20:42:23.622056.622056 cuda_h.py:19] end wait_experts cost 0.036956071853637695 seconds
DEBUG 01-14 20:42:23.622511.622511 cuda_h.py:10] start gpu_experts
DEBUG 01-14 20:42:23.622984.622984 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-14 20:42:23.623894.623894 cuda_h.py:19] end move_outputs cost 0.002192974090576172 seconds
DEBUG 01-14 20:42:23.627504.627504 cuda_h.py:19] end wait_cetm_experts cost 0.005292654037475586 seconds
DEBUG 01-14 20:42:23.628406.628406 cuda_h.py:10] start gpu_group_einsum_mp_multi_list
DEBUG 01-14 20:42:23.628783.628783 cuda_h.py:10] start gpu_group_tensor
DEBUG 01-14 20:42:23.628150.628150 cuda_h.py:19] end gpu_group_tensor cost 0.0004162788391113281 seconds
DEBUG 01-14 20:42:23.628212.628212 cuda_h.py:10] start gpu_group_einsum
DEBUG 01-14 20:42:23.637513.637513 cuda_h.py:19] end gpu_group_einsum cost 0.008809089660644531 seconds
DEBUG 01-14 20:42:23.638047.638047 cuda_h.py:10] start gpu_final_hidden_states_scatter
DEBUG 01-14 20:42:23.638314.638314 cuda_h.py:10] start all_expert_outputs_slices
DEBUG 01-14 20:42:23.638628.638628 cuda_h.py:19] end all_expert_outputs_slices cost 0.00023221969604492188 seconds
DEBUG 01-14 20:42:23.638569.638569 cuda_h.py:10] start concat_expert_out
DEBUG 01-14 20:42:23.638943.638943 cuda_h.py:19] end concat_expert_out cost 5.936622619628906e-05 seconds
DEBUG 01-14 20:42:23.638839.638839 cuda_h.py:10] start index_scatter
DEBUG 01-14 20:42:23.638882.638882 cuda_h.py:19] end index_scatter cost 6.890296936035156e-05 seconds
DEBUG 01-14 20:42:23.638023.638023 cuda_h.py:19] end gpu_final_hidden_states_scatter cost 0.0006079673767089844 seconds
DEBUG 01-14 20:42:23.638178.638178 cuda_h.py:19] end gpu_experts cost 0.016487598419189453 seconds
DEBUG 01-14 20:42:23.638066.638066 cuda_h.py:10] start all_expert_weight_slices
DEBUG 01-14 20:42:23.639550.639550 cuda_h.py:19] end all_expert_weight_slices cost 0.0007755756378173828 seconds
DEBUG 01-14 20:42:23.639903.639903 cuda_h.py:10] start cpuoutputsdeal
DEBUG 01-14 20:42:23.640908.640908 cuda_h.py:10] start index_scatter
DEBUG 01-14 20:42:23.640699.640699 cuda_h.py:19] end index_scatter cost 4.57763671875e-05 seconds
DEBUG 01-14 20:42:23.640462.640462 cuda_h.py:19] end cpuoutputsdeal cost 0.00045800209045410156 seconds
DEBUG 01-14 20:42:23.640934.640934 cuda_h.py:19] end layer_moe_generate_mp_l_3 cost 0.07898879051208496 seconds
DEBUG 01-14 20:42:23.640297.640297 cuda_h.py:19] end prefill_layer cost 0.08466577529907227 seconds
DEBUG 01-14 20:42:23.640484.640484 lmp.py:1551] -------------------------------- end prefill layer 2 --------------------------------
DEBUG 01-14 20:42:23.640849.640849 cuda_h.py:10] start prefill_layer
DEBUG 01-14 20:42:23.640214.640214 lmp.py:1494] -------------------------------- start prefill layer 3 --------------------------------
DEBUG 01-14 20:42:23.640818.640818 cuda_h.py:10] start start_load_qkvogn_s_weight_l_4
DEBUG 01-14 20:42:23.640613.640613 cuda_h.py:10] start start_load_qkvogn_s_weight_l_4
DEBUG 01-14 20:42:23.640304.640304 cuda_h.py:19] end start_load_qkvogn_s_weight_l_4 cost 3.0279159545898438e-05 seconds
DEBUG 01-14 20:42:23.640338.640338 cuda_h.py:19] end start_load_qkvogn_s_weight_l_4 cost 5.7697296142578125e-05 seconds
DEBUG 01-14 20:42:23.640696.640696 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-14 20:42:23.640844.640844 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-14 20:42:23.641860.641860 cuda_h.py:10] start sllm_worker_task
DEBUG 01-14 20:42:23.641427.641427 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-14 20:42:23.641216.641216 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-14 20:42:23.642962.642962 cuda_h.py:19] end allocate_cuda_memory cost 0.00164794921875 seconds
DEBUG 01-14 20:42:23.643651.643651 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-14 20:42:23.643125.643125 sllm_store_c.py:27] get device uuid map
DEBUG 01-14 20:42:23.643974.643974 sllm_store_c.py:29] call client load into gpu
DEBUG 01-14 20:42:23.643631.643631 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 348e1cec-a4e7-4c5a-8213-f1abcc2d0d66
DEBUG 01-14 20:42:23.643508.643508 client.py:106] call stub.LoadModelAsync
DEBUG 01-14 20:42:23.643572.643572 mlpmodule.py:1367]  experts func einsum cost 0.07095623016357422 s
DEBUG 01-14 20:42:23.644603.644603 cuda_h.py:10] start self_attn
INFO 01-14 20:42:23.644620.644620 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 348e1cec-a4e7-4c5a-8213-f1abcc2d0d66
DEBUG 01-14 20:42:23.644032.644032 cuda_h.py:19] end load_into_gpu_async cost 0.0018048286437988281 seconds
DEBUG 01-14 20:42:23.644735.644735 cuda_h.py:10] start restore_tensors2
DEBUG 01-14 20:42:23.645871.645871 cuda_h.py:19] end restore_tensors2 cost 7.05718994140625e-05 seconds
DEBUG 01-14 20:42:23.645688.645688 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.004013538360595703 seconds
INFO 01-14 20:42:23.645359.645359 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 348e1cec-a4e7-4c5a-8213-f1abcc2d0d66
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-14 20:42:23.647115.647115 cuda_h.py:19] end self_attn cost 0.002901315689086914 seconds
DEBUG 01-14 20:42:23.647131.647131 cuda_h.py:19] end iln_self_attn_paln cost 0.006437778472900391 seconds
DEBUG 01-14 20:42:23.647305.647305 cuda_h.py:10] start layer_moe_generate_mp_l_4
DEBUG 01-14 20:42:23.647306.647306 cuda_h.py:10] start gate
DEBUG 01-14 20:42:23.648633.648633 cuda_h.py:19] end gate cost 0.0006282329559326172 seconds
DEBUG 01-14 20:42:23.648271.648271 cuda_h.py:10] start experts_map_get
DEBUG 01-14 20:42:23.648275.648275 lmp.py:1615] 
DEBUG 01-14 20:42:23.648275.648275 lmp.py:1615] Expert Token Distribution & Device Allocation:
DEBUG 01-14 20:42:23.648415.648415 lmp.py:1616]   Total experts: 64
DEBUG 01-14 20:42:23.648018.648018 lmp.py:1617]   CPU experts: 32 (50%)
DEBUG 01-14 20:42:23.648284.648284 lmp.py:1618]   GPU experts: 32 (50%)
DEBUG 01-14 20:42:23.648688.648688 lmp.py:1619] 
DEBUG 01-14 20:42:23.648688.648688 lmp.py:1619]   Expert ID | Tokens | Device
DEBUG 01-14 20:42:23.648000.648000 lmp.py:1620]   -----------------------------------
DEBUG 01-14 20:42:23.648027.648027 lmp.py:1625]   Expert  1 |     55 | CPU
DEBUG 01-14 20:42:23.648624.648624 lmp.py:1625]   Expert 27 |     59 | CPU
DEBUG 01-14 20:42:23.648506.648506 lmp.py:1625]   Expert 48 |     79 | CPU
DEBUG 01-14 20:42:23.648387.648387 lmp.py:1625]   Expert  7 |     84 | CPU
DEBUG 01-14 20:42:23.648507.648507 lmp.py:1625]   Expert 30 |    100 | CPU
DEBUG 01-14 20:42:23.648342.648342 lmp.py:1625]   Expert 15 |    102 | CPU
DEBUG 01-14 20:42:23.648985.648985 lmp.py:1625]   Expert 32 |    114 | CPU
DEBUG 01-14 20:42:23.648866.648866 lmp.py:1625]   Expert 61 |    115 | CPU
DEBUG 01-14 20:42:23.648032.648032 lmp.py:1625]   Expert 39 |    116 | CPU
DEBUG 01-14 20:42:23.648675.648675 lmp.py:1625]   Expert 18 |    117 | CPU
DEBUG 01-14 20:42:23.648841.648841 lmp.py:1625]   Expert 45 |    134 | CPU
DEBUG 01-14 20:42:23.648246.648246 lmp.py:1625]   Expert 34 |    136 | CPU
DEBUG 01-14 20:42:23.648889.648889 lmp.py:1625]   Expert 59 |    138 | CPU
DEBUG 01-14 20:42:23.648770.648770 lmp.py:1625]   Expert 11 |    144 | CPU
DEBUG 01-14 20:42:23.648890.648890 lmp.py:1625]   Expert 36 |    145 | CPU
DEBUG 01-14 20:42:23.648056.648056 lmp.py:1625]   Expert 26 |    148 | CPU
DEBUG 01-14 20:42:23.648461.648461 lmp.py:1625]   Expert  9 |    150 | CPU
DEBUG 01-14 20:42:23.648389.648389 lmp.py:1625]   Expert 23 |    151 | CPU
DEBUG 01-14 20:42:23.648555.648555 lmp.py:1625]   Expert 49 |    151 | CPU
DEBUG 01-14 20:42:23.648721.648721 lmp.py:1625]   Expert  5 |    152 | CPU
DEBUG 01-14 20:42:23.648649.648649 lmp.py:1625]   Expert  6 |    153 | CPU
DEBUG 01-14 20:42:23.648053.648053 lmp.py:1625]   Expert 51 |    153 | CPU
DEBUG 01-14 20:42:23.648935.648935 lmp.py:1625]   Expert  2 |    162 | CPU
DEBUG 01-14 20:42:23.648101.648101 lmp.py:1625]   Expert 50 |    165 | CPU
DEBUG 01-14 20:42:23.649028.649028 lmp.py:1625]   Expert 16 |    166 | CPU
DEBUG 01-14 20:42:23.649195.649195 lmp.py:1625]   Expert 40 |    166 | CPU
DEBUG 01-14 20:42:23.649361.649361 lmp.py:1625]   Expert 56 |    169 | CPU
DEBUG 01-14 20:42:23.649050.649050 lmp.py:1625]   Expert  4 |    171 | CPU
DEBUG 01-14 20:42:23.649739.649739 lmp.py:1625]   Expert 52 |    178 | CPU
DEBUG 01-14 20:42:23.649905.649905 lmp.py:1625]   Expert 17 |    184 | CPU
DEBUG 01-14 20:42:23.649310.649310 lmp.py:1625]   Expert 35 |    186 | CPU
DEBUG 01-14 20:42:23.649238.649238 lmp.py:1625]   Expert 44 |    186 | CPU
DEBUG 01-14 20:42:23.649404.649404 lmp.py:1625]   Expert 37 |    188 | GPU
DEBUG 01-14 20:42:23.649093.649093 lmp.py:1625]   Expert 38 |    193 | GPU
DEBUG 01-14 20:42:23.649021.649021 lmp.py:1625]   Expert 42 |    194 | GPU
DEBUG 01-14 20:42:23.649187.649187 lmp.py:1625]   Expert 13 |    202 | GPU
DEBUG 01-14 20:42:23.649353.649353 lmp.py:1625]   Expert 21 |    206 | GPU
DEBUG 01-14 20:42:23.649281.649281 lmp.py:1625]   Expert  3 |    209 | GPU
DEBUG 01-14 20:42:23.649162.649162 lmp.py:1625]   Expert 28 |    210 | GPU
DEBUG 01-14 20:42:23.649044.649044 lmp.py:1625]   Expert 53 |    211 | GPU
DEBUG 01-14 20:42:23.649210.649210 lmp.py:1625]   Expert 10 |    212 | GPU
DEBUG 01-14 20:42:23.649137.649137 lmp.py:1625]   Expert 20 |    215 | GPU
DEBUG 01-14 20:42:23.649065.649065 lmp.py:1625]   Expert 47 |    216 | GPU
DEBUG 01-14 20:42:23.649231.649231 lmp.py:1625]   Expert 58 |    217 | GPU
DEBUG 01-14 20:42:23.649397.649397 lmp.py:1625]   Expert 19 |    222 | GPU
DEBUG 01-14 20:42:23.649087.649087 lmp.py:1625]   Expert 33 |    224 | GPU
DEBUG 01-14 20:42:23.649014.649014 lmp.py:1625]   Expert  8 |    225 | GPU
DEBUG 01-14 20:42:23.649181.649181 lmp.py:1625]   Expert 55 |    226 | GPU
DEBUG 01-14 20:42:23.649824.649824 lmp.py:1625]   Expert 60 |    229 | GPU
DEBUG 01-14 20:42:23.649467.649467 lmp.py:1625]   Expert 31 |    230 | GPU
DEBUG 01-14 20:42:23.649633.649633 lmp.py:1625]   Expert 57 |    233 | GPU
DEBUG 01-14 20:42:23.649322.649322 lmp.py:1625]   Expert 46 |    236 | GPU
DEBUG 01-14 20:42:23.649011.649011 lmp.py:1625]   Expert 62 |    240 | GPU
DEBUG 01-14 20:42:23.649939.649939 lmp.py:1625]   Expert 24 |    242 | GPU
DEBUG 01-14 20:42:23.649628.649628 lmp.py:1625]   Expert 63 |    253 | GPU
DEBUG 01-14 20:42:23.649079.649079 lmp.py:1625]   Expert 14 |    257 | GPU
DEBUG 01-14 20:42:23.649768.649768 lmp.py:1625]   Expert 12 |    260 | GPU
DEBUG 01-14 20:42:23.649458.649458 lmp.py:1625]   Expert 22 |    273 | GPU
DEBUG 01-14 20:42:23.649386.649386 lmp.py:1625]   Expert 43 |    289 | GPU
DEBUG 01-14 20:42:23.649028.649028 lmp.py:1625]   Expert 29 |    297 | GPU
DEBUG 01-14 20:42:23.649195.649195 lmp.py:1625]   Expert  0 |    308 | GPU
DEBUG 01-14 20:42:23.649884.649884 lmp.py:1625]   Expert 54 |    340 | GPU
DEBUG 01-14 20:42:23.649335.649335 lmp.py:1625]   Expert 41 |    387 | GPU
DEBUG 01-14 20:42:23.649263.649263 lmp.py:1625]   Expert 25 |    415 | GPU
DEBUG 01-14 20:42:23.649667.649667 lmp.py:1626] 
DEBUG 01-14 20:42:23.649667.649667 lmp.py:1626]   CPU total tokens: 4429 (36.0%)
DEBUG 01-14 20:42:23.649548.649548 lmp.py:1627]   GPU total tokens: 7859 (64.0%)
DEBUG 01-14 20:42:23.649960.649960 cuda_h.py:19] end experts_map_get cost 0.0015690326690673828 seconds
DEBUG 01-14 20:42:23.649333.649333 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-14 20:42:23.649461.649461 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-14 20:42:23.649737.649737 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-14 20:42:23.652872.652872 cuda_h.py:19] end allocate_cuda_memory cost 0.0020341873168945312 seconds
DEBUG 01-14 20:42:23.652067.652067 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-14 20:42:23.652684.652684 sllm_store_c.py:27] get device uuid map
DEBUG 01-14 20:42:23.652824.652824 sllm_store_c.py:29] call client load into gpu
DEBUG 01-14 20:42:23.652235.652235 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 0e527ea1-1e9e-4336-ad15-0825c49dd85d
DEBUG 01-14 20:42:23.652493.652493 client.py:106] call stub.LoadModelAsync
INFO 01-14 20:42:23.653032.653032 client.py:127] Model loaded
DEBUG 01-14 20:42:23.653988.653988 cuda_h.py:10] start restore2model
DEBUG 01-14 20:42:23.654508.654508 cuda_h.py:19] end restore2model cost 0.0004432201385498047 seconds
DEBUG 01-14 20:42:23.654966.654966 cuda_h.py:19] end sllm_worker_task cost 0.01336216926574707 seconds
INFO 01-14 20:42:23.655591.655591 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 0e527ea1-1e9e-4336-ad15-0825c49dd85d
DEBUG 01-14 20:42:23.655626.655626 cuda_h.py:19] end load_into_gpu_async cost 0.0034317970275878906 seconds
DEBUG 01-14 20:42:23.655044.655044 cuda_h.py:10] start restore_tensors2
DEBUG 01-14 20:42:23.656404.656404 cuda_h.py:19] end restore_tensors2 cost 0.0004124641418457031 seconds
DEBUG 01-14 20:42:23.656909.656909 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0062410831451416016 seconds
DEBUG 01-14 20:42:23.656718.656718 cuda_h.py:10] start restore2model
DEBUG 01-14 20:42:23.658758.658758 cuda_h.py:19] end restore2model cost 0.002565145492553711 seconds
DEBUG 01-14 20:42:23.658747.658747 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.008984088897705078 seconds
DEBUG 01-14 20:42:23.658589.658589 cuda_h.py:10] start gpu_sexperts
DEBUG 01-14 20:42:23.659560.659560 cuda_h.py:19] end gpu_sexperts cost 0.00030040740966796875 seconds
DEBUG 01-14 20:42:23.659622.659622 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-14 20:42:23.659324.659324 lmp.py:1683] 
DEBUG 01-14 20:42:23.659324.659324 lmp.py:1683]   Computing 32 experts on CPU...
DEBUG 01-14 20:42:23.659830.659830 cuda_h.py:19] end cpu_experts_submit cost 5.650520324707031e-05 seconds
DEBUG 01-14 20:42:23.659387.659387 cuda_h.py:10] start experts_func_mgpu_group_pad
DEBUG 01-14 20:42:23.677949.677949 mlpmodule.py:1460] group tensors cost 0.017048358917236328 s
DEBUG 01-14 20:42:23.678307.678307 cuda_h.py:10] start move_flat_hidden2cpu
DEBUG 01-14 20:42:23.684082.684082 cuda_h.py:19] end experts_func_mgpu_group_pad cost 0.02522587776184082 seconds
DEBUG 01-14 20:42:23.685190.685190 cuda_h.py:19] end move_flat_hidden2cpu cost 0.007286787033081055 seconds
DEBUG 01-14 20:42:23.688056.688056 cuda_h.py:10] start gpu_group_list
DEBUG 01-14 20:42:23.689360.689360 cuda_h.py:19] end gpu_group_list cost 0.0008711814880371094 seconds
DEBUG 01-14 20:42:23.690128.690128 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-14 20:42:23.690994.690994 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 3.5762786865234375e-05 seconds
DEBUG 01-14 20:42:23.690473.690473 cuda_h.py:10] start wait_experts
INFO 01-14 20:42:23.690126.690126 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 0e527ea1-1e9e-4336-ad15-0825c49dd85d
DEBUG 01-14 20:42:23.691271.691271 mlpmodule.py:1533] pad cost 0.0061931610107421875 s
DEBUG 01-14 20:42:23.691116.691116 mlpmodule.py:1539] create cpu tensor cost 5.6743621826171875e-05 s
DEBUG 01-14 20:42:23.694510.694510 mlpmodule.py:1544] move to cpu cost 0.002210378646850586 s
DEBUG 01-14 20:42:23.703635.703635 mlpmodule.py:1558] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-14 20:42:23.703125.703125 mlpmodule.py:1559] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-14 20:42:23.703871.703871 mlpmodule.py:1564] group_w3 first element: -0.054931640625
WARNING 01-14 20:42:23.703558.703558 mlpmodule.py:1574] start einsum2
INFO 01-14 20:42:23.706095.706095 client.py:127] Model loaded
DEBUG 01-14 20:42:23.706555.706555 cuda_h.py:19] end wait_experts cost 0.016363859176635742 seconds
DEBUG 01-14 20:42:23.707255.707255 cuda_h.py:10] start gpu_experts
DEBUG 01-14 20:42:23.707477.707477 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-14 20:42:23.721608.721608 mlpmodule.py:1584] group einsum cost 0.027355194091796875 s
DEBUG 01-14 20:42:23.722199.722199 mlpmodule.py:1593] cpy2cputensor cost 0.0007941722869873047 s
DEBUG 01-14 20:42:23.722287.722287 cuda_h.py:10] start move_outputs
DEBUG 01-14 20:42:23.725337.725337 cuda_h.py:19] end move_outputs cost 0.0024566650390625 seconds
DEBUG 01-14 20:42:23.730568.730568 cuda_h.py:19] end wait_cetm_experts cost 0.02337956428527832 seconds
DEBUG 01-14 20:42:23.730886.730886 cuda_h.py:10] start gpu_group_einsum_mp_multi_list
DEBUG 01-14 20:42:23.730947.730947 cuda_h.py:10] start gpu_group_tensor
DEBUG 01-14 20:42:23.731864.731864 cuda_h.py:19] end gpu_group_tensor cost 0.0002541542053222656 seconds
DEBUG 01-14 20:42:23.731226.731226 cuda_h.py:10] start gpu_group_einsum
DEBUG 01-14 20:42:23.732927.732927 cuda_h.py:19] end gpu_group_einsum cost 0.0007071495056152344 seconds
DEBUG 01-14 20:42:23.732654.732654 cuda_h.py:10] start gpu_final_hidden_states_scatter
DEBUG 01-14 20:42:23.732325.732325 cuda_h.py:10] start all_expert_outputs_slices
DEBUG 01-14 20:42:23.732425.732425 cuda_h.py:19] end all_expert_outputs_slices cost 0.0003867149353027344 seconds
DEBUG 01-14 20:42:23.732612.732612 cuda_h.py:10] start concat_expert_out
DEBUG 01-14 20:42:23.742358.742358 cuda_h.py:19] end concat_expert_out cost 0.009381771087646484 seconds
DEBUG 01-14 20:42:23.742535.742535 cuda_h.py:10] start index_scatter
DEBUG 01-14 20:42:23.742035.742035 cuda_h.py:19] end index_scatter cost 8.0108642578125e-05 seconds
DEBUG 01-14 20:42:23.742275.742275 cuda_h.py:19] end gpu_final_hidden_states_scatter cost 0.010204315185546875 seconds
DEBUG 01-14 20:42:23.742418.742418 cuda_h.py:19] end gpu_experts cost 0.035444021224975586 seconds
DEBUG 01-14 20:42:23.742736.742736 cuda_h.py:10] start all_expert_weight_slices
DEBUG 01-14 20:42:23.743148.743148 cuda_h.py:19] end all_expert_weight_slices cost 0.0008018016815185547 seconds
DEBUG 01-14 20:42:23.743263.743263 cuda_h.py:10] start cpuoutputsdeal
DEBUG 01-14 20:42:23.743228.743228 cuda_h.py:10] start index_scatter
DEBUG 01-14 20:42:23.743702.743702 cuda_h.py:19] end index_scatter cost 5.221366882324219e-05 seconds
DEBUG 01-14 20:42:23.743803.743803 cuda_h.py:19] end cpuoutputsdeal cost 0.0004773139953613281 seconds
DEBUG 01-14 20:42:23.743421.743421 cuda_h.py:19] end layer_moe_generate_mp_l_4 cost 0.09657716751098633 seconds
DEBUG 01-14 20:42:23.744658.744658 cuda_h.py:19] end prefill_layer cost 0.1036233901977539 seconds
DEBUG 01-14 20:42:23.744190.744190 lmp.py:1551] -------------------------------- end prefill layer 3 --------------------------------
DEBUG 01-14 20:42:23.744462.744462 cuda_h.py:10] start prefill_layer
DEBUG 01-14 20:42:23.744351.744351 lmp.py:1494] -------------------------------- start prefill layer 4 --------------------------------
DEBUG 01-14 20:42:23.744954.744954 cuda_h.py:10] start start_load_qkvogn_s_weight_l_5
DEBUG 01-14 20:42:23.744226.744226 cuda_h.py:10] start start_load_qkvogn_s_weight_l_5
DEBUG 01-14 20:42:23.744685.744685 cuda_h.py:19] end start_load_qkvogn_s_weight_l_5 cost 3.337860107421875e-05 seconds
DEBUG 01-14 20:42:23.744527.744527 cuda_h.py:19] end start_load_qkvogn_s_weight_l_5 cost 6.008148193359375e-05 seconds
DEBUG 01-14 20:42:23.744170.744170 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-14 20:42:23.744193.744193 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-14 20:42:23.744500.744500 cuda_h.py:10] start sllm_worker_task
DEBUG 01-14 20:42:23.744715.744715 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-14 20:42:23.744836.744836 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-14 20:42:23.747044.747044 cuda_h.py:19] end allocate_cuda_memory cost 0.002222299575805664 seconds
DEBUG 01-14 20:42:23.747405.747405 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-14 20:42:23.747082.747082 sllm_store_c.py:27] get device uuid map
DEBUG 01-14 20:42:23.747150.747150 sllm_store_c.py:29] call client load into gpu
DEBUG 01-14 20:42:23.747522.747522 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, b76edf4e-cf60-4518-844e-693da2273b3a
DEBUG 01-14 20:42:23.747352.747352 client.py:106] call stub.LoadModelAsync
DEBUG 01-14 20:42:23.747812.747812 mlpmodule.py:1367]  experts func einsum cost 0.08774375915527344 s
DEBUG 01-14 20:42:23.748483.748483 cuda_h.py:10] start self_attn
INFO 01-14 20:42:23.751859.751859 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, b76edf4e-cf60-4518-844e-693da2273b3a
DEBUG 01-14 20:42:23.751854.751854 cuda_h.py:19] end load_into_gpu_async cost 0.004078388214111328 seconds
DEBUG 01-14 20:42:23.751233.751233 cuda_h.py:10] start restore_tensors2
DEBUG 01-14 20:42:23.751489.751489 cuda_h.py:19] end restore_tensors2 cost 8.392333984375e-05 seconds
DEBUG 01-14 20:42:23.751874.751874 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0066831111907958984 seconds
INFO 01-14 20:42:23.751585.751585 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, b76edf4e-cf60-4518-844e-693da2273b3a
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-14 20:42:23.754733.754733 cuda_h.py:19] end self_attn cost 0.006272792816162109 seconds
DEBUG 01-14 20:42:23.755811.755811 cuda_h.py:19] end iln_self_attn_paln cost 0.010993719100952148 seconds
DEBUG 01-14 20:42:23.755922.755922 cuda_h.py:10] start layer_moe_generate_mp_l_5
DEBUG 01-14 20:42:23.755158.755158 cuda_h.py:10] start gate
DEBUG 01-14 20:42:23.757797.757797 cuda_h.py:19] end gate cost 0.0013930797576904297 seconds
DEBUG 01-14 20:42:23.757543.757543 cuda_h.py:10] start experts_map_get
DEBUG 01-14 20:42:23.758095.758095 lmp.py:1615] 
DEBUG 01-14 20:42:23.758095.758095 lmp.py:1615] Expert Token Distribution & Device Allocation:
DEBUG 01-14 20:42:23.758633.758633 lmp.py:1616]   Total experts: 64
DEBUG 01-14 20:42:23.758535.758535 lmp.py:1617]   CPU experts: 32 (50%)
DEBUG 01-14 20:42:23.758668.758668 lmp.py:1618]   GPU experts: 32 (50%)
DEBUG 01-14 20:42:23.758895.758895 lmp.py:1619] 
DEBUG 01-14 20:42:23.758895.758895 lmp.py:1619]   Expert ID | Tokens | Device
DEBUG 01-14 20:42:23.758597.758597 lmp.py:1620]   -----------------------------------
DEBUG 01-14 20:42:23.758208.758208 lmp.py:1625]   Expert 14 |     70 | CPU
DEBUG 01-14 20:42:23.758718.758718 lmp.py:1625]   Expert 13 |     71 | CPU
DEBUG 01-14 20:42:23.758037.758037 lmp.py:1625]   Expert 57 |     78 | CPU
DEBUG 01-14 20:42:23.758594.758594 lmp.py:1625]   Expert 11 |     84 | CPU
DEBUG 01-14 20:42:23.758913.758913 lmp.py:1625]   Expert 26 |     87 | CPU
DEBUG 01-14 20:42:23.758993.758993 lmp.py:1625]   Expert 31 |     87 | CPU
DEBUG 01-14 20:42:23.758935.758935 lmp.py:1625]   Expert 54 |     88 | CPU
DEBUG 01-14 20:42:23.758161.758161 lmp.py:1625]   Expert 45 |     90 | CPU
DEBUG 01-14 20:42:23.758671.758671 lmp.py:1625]   Expert 10 |     96 | CPU
DEBUG 01-14 20:42:23.758944.758944 lmp.py:1625]   Expert 58 |    106 | CPU
DEBUG 01-14 20:42:23.758693.758693 lmp.py:1625]   Expert 51 |    109 | CPU
DEBUG 01-14 20:42:23.758442.758442 lmp.py:1625]   Expert 30 |    110 | CPU
DEBUG 01-14 20:42:23.758907.758907 lmp.py:1625]   Expert 36 |    115 | CPU
DEBUG 01-14 20:42:23.758133.758133 lmp.py:1625]   Expert 20 |    126 | CPU
DEBUG 01-14 20:42:23.758120.758120 lmp.py:1625]   Expert 32 |    126 | CPU
DEBUG 01-14 20:42:23.758869.758869 lmp.py:1625]   Expert  4 |    138 | CPU
DEBUG 01-14 20:42:23.758142.758142 lmp.py:1625]   Expert 61 |    138 | CPU
DEBUG 01-14 20:42:23.758891.758891 lmp.py:1625]   Expert 63 |    141 | CPU
DEBUG 01-14 20:42:23.758163.758163 lmp.py:1625]   Expert 16 |    144 | CPU
DEBUG 01-14 20:42:23.758436.758436 lmp.py:1625]   Expert 42 |    149 | CPU
DEBUG 01-14 20:42:23.758708.758708 lmp.py:1625]   Expert 47 |    150 | CPU
DEBUG 01-14 20:42:23.758742.758742 lmp.py:1625]   Expert 34 |    151 | CPU
DEBUG 01-14 20:42:23.758730.758730 lmp.py:1625]   Expert 53 |    151 | CPU
DEBUG 01-14 20:42:23.758194.758194 lmp.py:1625]   Expert  8 |    152 | CPU
DEBUG 01-14 20:42:23.758897.758897 lmp.py:1625]   Expert 60 |    154 | CPU
DEBUG 01-14 20:42:23.758169.758169 lmp.py:1625]   Expert 28 |    159 | CPU
DEBUG 01-14 20:42:23.758680.758680 lmp.py:1625]   Expert 17 |    166 | CPU
DEBUG 01-14 20:42:23.758953.758953 lmp.py:1625]   Expert 27 |    170 | CPU
DEBUG 01-14 20:42:23.758225.758225 lmp.py:1625]   Expert 44 |    178 | CPU
DEBUG 01-14 20:42:23.758259.758259 lmp.py:1625]   Expert 56 |    178 | CPU
DEBUG 01-14 20:42:23.758293.758293 lmp.py:1625]   Expert 29 |    179 | CPU
DEBUG 01-14 20:42:23.758565.758565 lmp.py:1625]   Expert 24 |    180 | CPU
DEBUG 01-14 20:42:23.759030.759030 lmp.py:1625]   Expert  0 |    181 | GPU
DEBUG 01-14 20:42:23.759971.759971 lmp.py:1625]   Expert 41 |    182 | GPU
DEBUG 01-14 20:42:23.759720.759720 lmp.py:1625]   Expert 48 |    183 | GPU
DEBUG 01-14 20:42:23.759993.759993 lmp.py:1625]   Expert  9 |    186 | GPU
DEBUG 01-14 20:42:23.759027.759027 lmp.py:1625]   Expert  2 |    187 | GPU
DEBUG 01-14 20:42:23.759299.759299 lmp.py:1625]   Expert  7 |    187 | GPU
DEBUG 01-14 20:42:23.759571.759571 lmp.py:1625]   Expert 15 |    189 | GPU
DEBUG 01-14 20:42:23.759605.759605 lmp.py:1625]   Expert  3 |    190 | GPU
DEBUG 01-14 20:42:23.759878.759878 lmp.py:1625]   Expert 18 |    196 | GPU
DEBUG 01-14 20:42:23.759865.759865 lmp.py:1625]   Expert 55 |    197 | GPU
DEBUG 01-14 20:42:23.759568.759568 lmp.py:1625]   Expert 40 |    199 | GPU
DEBUG 01-14 20:42:23.759794.759794 lmp.py:1625]   Expert  6 |    215 | GPU
DEBUG 01-14 20:42:23.759782.759782 lmp.py:1625]   Expert 38 |    215 | GPU
DEBUG 01-14 20:42:23.759816.759816 lmp.py:1625]   Expert 22 |    216 | GPU
DEBUG 01-14 20:42:23.759611.759611 lmp.py:1625]   Expert 23 |    227 | GPU
DEBUG 01-14 20:42:23.759407.759407 lmp.py:1625]   Expert 37 |    227 | GPU
DEBUG 01-14 20:42:23.759494.759494 lmp.py:1625]   Expert 25 |    237 | GPU
DEBUG 01-14 20:42:23.759005.759005 lmp.py:1625]   Expert 46 |    241 | GPU
DEBUG 01-14 20:42:23.759708.759708 lmp.py:1625]   Expert 50 |    252 | GPU
DEBUG 01-14 20:42:23.759980.759980 lmp.py:1625]   Expert 39 |    259 | GPU
DEBUG 01-14 20:42:23.759252.759252 lmp.py:1625]   Expert 12 |    261 | GPU
DEBUG 01-14 20:42:23.759001.759001 lmp.py:1625]   Expert 62 |    262 | GPU
DEBUG 01-14 20:42:23.759035.759035 lmp.py:1625]   Expert 19 |    267 | GPU
DEBUG 01-14 20:42:23.759546.759546 lmp.py:1625]   Expert 21 |    267 | GPU
DEBUG 01-14 20:42:23.759819.759819 lmp.py:1625]   Expert 35 |    292 | GPU
DEBUG 01-14 20:42:23.759283.759283 lmp.py:1625]   Expert 49 |    293 | GPU
DEBUG 01-14 20:42:23.759224.759224 lmp.py:1625]   Expert 52 |    301 | GPU
DEBUG 01-14 20:42:23.759166.759166 lmp.py:1625]   Expert 33 |    305 | GPU
DEBUG 01-14 20:42:23.759438.759438 lmp.py:1625]   Expert  1 |    344 | GPU
DEBUG 01-14 20:42:23.759426.759426 lmp.py:1625]   Expert  5 |    380 | GPU
DEBUG 01-14 20:42:23.759983.759983 lmp.py:1625]   Expert 43 |    434 | GPU
DEBUG 01-14 20:42:23.759017.759017 lmp.py:1625]   Expert 59 |    595 | GPU
DEBUG 01-14 20:42:23.759720.759720 lmp.py:1626] 
DEBUG 01-14 20:42:23.759720.759720 lmp.py:1626]   CPU total tokens: 4121 (33.5%)
DEBUG 01-14 20:42:23.759422.759422 lmp.py:1627]   GPU total tokens: 8167 (66.5%)
DEBUG 01-14 20:42:23.759609.759609 cuda_h.py:19] end experts_map_get cost 0.0022923946380615234 seconds
INFO 01-14 20:42:23.759175.759175 client.py:127] Model loaded
DEBUG 01-14 20:42:23.760377.760377 cuda_h.py:10] start restore2model
DEBUG 01-14 20:42:23.760964.760964 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-14 20:42:23.760292.760292 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-14 20:42:23.760854.760854 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-14 20:42:23.761215.761215 cuda_h.py:19] end allocate_cuda_memory cost 0.0002446174621582031 seconds
DEBUG 01-14 20:42:23.761334.761334 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-14 20:42:23.761640.761640 sllm_store_c.py:27] get device uuid map
DEBUG 01-14 20:42:23.761424.761424 sllm_store_c.py:29] call client load into gpu
DEBUG 01-14 20:42:23.761471.761471 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, c028bd96-cdc1-4dff-ad86-b408b133e2fc
DEBUG 01-14 20:42:23.761188.761188 client.py:106] call stub.LoadModelAsync
DEBUG 01-14 20:42:23.761636.761636 cuda_h.py:19] end restore2model cost 0.0017502307891845703 seconds
DEBUG 01-14 20:42:23.761691.761691 cuda_h.py:19] end sllm_worker_task cost 0.017086505889892578 seconds
INFO 01-14 20:42:23.763860.763860 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, c028bd96-cdc1-4dff-ad86-b408b133e2fc
DEBUG 01-14 20:42:23.763922.763922 cuda_h.py:19] end load_into_gpu_async cost 0.001889944076538086 seconds
DEBUG 01-14 20:42:23.763785.763785 cuda_h.py:10] start restore_tensors2
DEBUG 01-14 20:42:23.763837.763837 cuda_h.py:19] end restore_tensors2 cost 0.000518798828125 seconds
DEBUG 01-14 20:42:23.764283.764283 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0032548904418945312 seconds
DEBUG 01-14 20:42:23.764682.764682 cuda_h.py:10] start restore2model
DEBUG 01-14 20:42:23.767109.767109 cuda_h.py:19] end restore2model cost 0.003817319869995117 seconds
DEBUG 01-14 20:42:23.767887.767887 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.0073261260986328125 seconds
DEBUG 01-14 20:42:23.768319.768319 cuda_h.py:10] start gpu_sexperts
DEBUG 01-14 20:42:23.768002.768002 cuda_h.py:19] end gpu_sexperts cost 0.00038814544677734375 seconds
DEBUG 01-14 20:42:23.768706.768706 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-14 20:42:23.768760.768760 lmp.py:1683] 
DEBUG 01-14 20:42:23.768760.768760 lmp.py:1683]   Computing 32 experts on CPU...
DEBUG 01-14 20:42:23.768054.768054 cuda_h.py:19] end cpu_experts_submit cost 7.62939453125e-05 seconds
DEBUG 01-14 20:42:23.768111.768111 cuda_h.py:10] start experts_func_mgpu_group_pad
DEBUG 01-14 20:42:23.780086.780086 mlpmodule.py:1460] group tensors cost 0.010942697525024414 s
DEBUG 01-14 20:42:23.781744.781744 cuda_h.py:10] start move_flat_hidden2cpu
DEBUG 01-14 20:42:23.787761.787761 cuda_h.py:19] end experts_func_mgpu_group_pad cost 0.01832747459411621 seconds
DEBUG 01-14 20:42:23.789501.789501 cuda_h.py:19] end move_flat_hidden2cpu cost 0.008237123489379883 seconds
DEBUG 01-14 20:42:23.790516.790516 cuda_h.py:10] start gpu_group_list
DEBUG 01-14 20:42:23.791292.791292 cuda_h.py:19] end gpu_group_list cost 0.0008378028869628906 seconds
DEBUG 01-14 20:42:23.791938.791938 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-14 20:42:23.792188.792188 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 3.504753112792969e-05 seconds
DEBUG 01-14 20:42:23.792753.792753 cuda_h.py:10] start wait_experts
INFO 01-14 20:42:23.792219.792219 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, c028bd96-cdc1-4dff-ad86-b408b133e2fc
DEBUG 01-14 20:42:23.794244.794244 mlpmodule.py:1533] pad cost 0.0044023990631103516 s
DEBUG 01-14 20:42:23.794229.794229 mlpmodule.py:1539] create cpu tensor cost 5.602836608886719e-05 s
DEBUG 01-14 20:42:23.796475.796475 mlpmodule.py:1544] move to cpu cost 0.0021359920501708984 s
DEBUG 01-14 20:42:23.803503.803503 mlpmodule.py:1558] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-14 20:42:23.803070.803070 mlpmodule.py:1559] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-14 20:42:23.803271.803271 mlpmodule.py:1564] group_w3 first element: 0.0086669921875
WARNING 01-14 20:42:23.804388.804388 mlpmodule.py:1574] start einsum2
INFO 01-14 20:42:23.813882.813882 client.py:127] Model loaded
DEBUG 01-14 20:42:23.813752.813752 cuda_h.py:19] end wait_experts cost 0.02122020721435547 seconds
DEBUG 01-14 20:42:23.813039.813039 cuda_h.py:10] start gpu_experts
DEBUG 01-14 20:42:23.813187.813187 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-14 20:42:23.816255.816255 mlpmodule.py:1584] group einsum cost 0.019681930541992188 s
DEBUG 01-14 20:42:23.817450.817450 mlpmodule.py:1593] cpy2cputensor cost 0.0007078647613525391 s
DEBUG 01-14 20:42:23.817624.817624 cuda_h.py:10] start move_outputs
DEBUG 01-14 20:42:23.819006.819006 cuda_h.py:19] end move_outputs cost 0.0020678043365478516 seconds
DEBUG 01-14 20:42:23.824652.824652 cuda_h.py:19] end wait_cetm_experts cost 0.011025428771972656 seconds
DEBUG 01-14 20:42:23.824401.824401 cuda_h.py:10] start gpu_group_einsum_mp_multi_list
DEBUG 01-14 20:42:23.824316.824316 cuda_h.py:10] start gpu_group_tensor
DEBUG 01-14 20:42:23.836147.836147 cuda_h.py:19] end gpu_group_tensor cost 0.011509895324707031 seconds
DEBUG 01-14 20:42:23.836697.836697 cuda_h.py:10] start gpu_group_einsum
DEBUG 01-14 20:42:23.837944.837944 cuda_h.py:19] end gpu_group_einsum cost 0.0006227493286132812 seconds
DEBUG 01-14 20:42:23.837392.837392 cuda_h.py:10] start gpu_final_hidden_states_scatter
DEBUG 01-14 20:42:23.837712.837712 cuda_h.py:10] start all_expert_outputs_slices
DEBUG 01-14 20:42:23.837523.837523 cuda_h.py:19] end all_expert_outputs_slices cost 0.0002498626708984375 seconds
DEBUG 01-14 20:42:23.837517.837517 cuda_h.py:10] start concat_expert_out
DEBUG 01-14 20:42:23.837838.837838 cuda_h.py:19] end concat_expert_out cost 6.103515625e-05 seconds
DEBUG 01-14 20:42:23.838271.838271 cuda_h.py:10] start index_scatter
DEBUG 01-14 20:42:23.838168.838168 cuda_h.py:19] end index_scatter cost 6.937980651855469e-05 seconds
DEBUG 01-14 20:42:23.838593.838593 cuda_h.py:19] end gpu_final_hidden_states_scatter cost 0.0006318092346191406 seconds
DEBUG 01-14 20:42:23.838404.838404 cuda_h.py:19] end gpu_experts cost 0.024694204330444336 seconds
DEBUG 01-14 20:42:23.838007.838007 cuda_h.py:10] start all_expert_weight_slices
DEBUG 01-14 20:42:23.839663.839663 cuda_h.py:19] end all_expert_weight_slices cost 0.0007703304290771484 seconds
DEBUG 01-14 20:42:23.839817.839817 cuda_h.py:10] start cpuoutputsdeal
DEBUG 01-14 20:42:23.839988.839988 cuda_h.py:10] start index_scatter
DEBUG 01-14 20:42:23.839025.839025 cuda_h.py:19] end index_scatter cost 4.839897155761719e-05 seconds
DEBUG 01-14 20:42:23.839695.839695 cuda_h.py:19] end cpuoutputsdeal cost 0.00047135353088378906 seconds
DEBUG 01-14 20:42:23.839982.839982 cuda_h.py:19] end layer_moe_generate_mp_l_5 cost 0.08377504348754883 seconds
DEBUG 01-14 20:42:23.839502.839502 cuda_h.py:19] end prefill_layer cost 0.09550762176513672 seconds
DEBUG 01-14 20:42:23.840730.840730 lmp.py:1551] -------------------------------- end prefill layer 4 --------------------------------
DEBUG 01-14 20:42:23.840571.840571 cuda_h.py:10] start prefill_layer
DEBUG 01-14 20:42:23.840413.840413 lmp.py:1494] -------------------------------- start prefill layer 5 --------------------------------
DEBUG 01-14 20:42:23.840017.840017 cuda_h.py:10] start start_load_qkvogn_s_weight_l_6
DEBUG 01-14 20:42:23.840481.840481 cuda_h.py:10] start start_load_qkvogn_s_weight_l_6
DEBUG 01-14 20:42:23.840986.840986 cuda_h.py:19] end start_load_qkvogn_s_weight_l_6 cost 3.266334533691406e-05 seconds
DEBUG 01-14 20:42:23.840782.840782 cuda_h.py:19] end start_load_qkvogn_s_weight_l_6 cost 6.008148193359375e-05 seconds
DEBUG 01-14 20:42:23.840140.840140 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-14 20:42:23.840434.840434 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-14 20:42:23.840318.840318 cuda_h.py:10] start sllm_worker_task
DEBUG 01-14 20:42:23.840653.840653 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-14 20:42:23.840966.840966 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-14 20:42:23.841014.841014 cuda_h.py:19] end allocate_cuda_memory cost 0.0008080005645751953 seconds
DEBUG 01-14 20:42:23.841817.841817 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-14 20:42:23.841958.841958 sllm_store_c.py:27] get device uuid map
DEBUG 01-14 20:42:23.841641.841641 sllm_store_c.py:29] call client load into gpu
DEBUG 01-14 20:42:23.841642.841642 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 6ba6e820-cab1-4aff-b0ce-5ab8c656c89c
DEBUG 01-14 20:42:23.841374.841374 client.py:106] call stub.LoadModelAsync
DEBUG 01-14 20:42:23.841307.841307 mlpmodule.py:1367]  experts func einsum cost 0.07260775566101074 s
DEBUG 01-14 20:42:23.842828.842828 cuda_h.py:10] start self_attn
INFO 01-14 20:42:23.843847.843847 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 6ba6e820-cab1-4aff-b0ce-5ab8c656c89c
DEBUG 01-14 20:42:23.843975.843975 cuda_h.py:19] end load_into_gpu_async cost 0.001905202865600586 seconds
DEBUG 01-14 20:42:23.843108.843108 cuda_h.py:10] start restore_tensors2
DEBUG 01-14 20:42:23.843198.843198 cuda_h.py:19] end restore_tensors2 cost 7.2479248046875e-05 seconds
DEBUG 01-14 20:42:23.843431.843431 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0030312538146972656 seconds
INFO 01-14 20:42:23.843459.843459 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 6ba6e820-cab1-4aff-b0ce-5ab8c656c89c
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-14 20:42:23.845759.845759 cuda_h.py:19] end self_attn cost 0.0029687881469726562 seconds
DEBUG 01-14 20:42:23.845557.845557 cuda_h.py:19] end iln_self_attn_paln cost 0.00529932975769043 seconds
DEBUG 01-14 20:42:23.845831.845831 cuda_h.py:10] start layer_moe_generate_mp_l_6
DEBUG 01-14 20:42:23.845547.845547 cuda_h.py:10] start gate
DEBUG 01-14 20:42:23.846272.846272 cuda_h.py:19] end gate cost 0.0006389617919921875 seconds
DEBUG 01-14 20:42:23.846724.846724 cuda_h.py:10] start experts_map_get
DEBUG 01-14 20:42:23.846714.846714 lmp.py:1615] 
DEBUG 01-14 20:42:23.846714.846714 lmp.py:1615] Expert Token Distribution & Device Allocation:
DEBUG 01-14 20:42:23.846139.846139 lmp.py:1616]   Total experts: 64
DEBUG 01-14 20:42:23.846981.846981 lmp.py:1617]   CPU experts: 32 (50%)
DEBUG 01-14 20:42:23.846008.846008 lmp.py:1618]   GPU experts: 32 (50%)
DEBUG 01-14 20:42:23.846889.846889 lmp.py:1619] 
DEBUG 01-14 20:42:23.846889.846889 lmp.py:1619]   Expert ID | Tokens | Device
DEBUG 01-14 20:42:23.846725.846725 lmp.py:1620]   -----------------------------------
DEBUG 01-14 20:42:23.846321.846321 lmp.py:1625]   Expert 34 |     36 | CPU
DEBUG 01-14 20:42:23.846964.846964 lmp.py:1625]   Expert 45 |     70 | CPU
DEBUG 01-14 20:42:23.846130.846130 lmp.py:1625]   Expert 22 |     76 | CPU
DEBUG 01-14 20:42:23.846296.846296 lmp.py:1625]   Expert 57 |     96 | CPU
DEBUG 01-14 20:42:23.846224.846224 lmp.py:1625]   Expert 17 |     97 | CPU
DEBUG 01-14 20:42:23.846390.846390 lmp.py:1625]   Expert 15 |    101 | CPU
DEBUG 01-14 20:42:23.846318.846318 lmp.py:1625]   Expert  4 |    105 | CPU
DEBUG 01-14 20:42:23.846153.846153 lmp.py:1625]   Expert 28 |    108 | CPU
DEBUG 01-14 20:42:23.846227.846227 lmp.py:1625]   Expert 16 |    116 | CPU
DEBUG 01-14 20:42:23.846062.846062 lmp.py:1625]   Expert 12 |    121 | CPU
DEBUG 01-14 20:42:23.847135.847135 lmp.py:1625]   Expert 60 |    121 | CPU
DEBUG 01-14 20:42:23.847970.847970 lmp.py:1625]   Expert 14 |    125 | CPU
DEBUG 01-14 20:42:23.847852.847852 lmp.py:1625]   Expert 32 |    125 | CPU
DEBUG 01-14 20:42:23.847495.847495 lmp.py:1625]   Expert 25 |    128 | CPU
DEBUG 01-14 20:42:23.847614.847614 lmp.py:1625]   Expert 36 |    128 | CPU
DEBUG 01-14 20:42:23.847496.847496 lmp.py:1625]   Expert  8 |    129 | CPU
DEBUG 01-14 20:42:23.847377.847377 lmp.py:1625]   Expert 52 |    130 | CPU
DEBUG 01-14 20:42:23.847782.847782 lmp.py:1625]   Expert  2 |    135 | CPU
DEBUG 01-14 20:42:23.847663.847663 lmp.py:1625]   Expert  0 |    140 | CPU
DEBUG 01-14 20:42:23.847068.847068 lmp.py:1625]   Expert  5 |    142 | CPU
DEBUG 01-14 20:42:23.847711.847711 lmp.py:1625]   Expert 35 |    143 | CPU
DEBUG 01-14 20:42:23.847069.847069 lmp.py:1625]   Expert 23 |    153 | CPU
DEBUG 01-14 20:42:23.847666.847666 lmp.py:1625]   Expert 41 |    153 | CPU
DEBUG 01-14 20:42:23.847547.847547 lmp.py:1625]   Expert 39 |    160 | CPU
DEBUG 01-14 20:42:23.847905.847905 lmp.py:1625]   Expert 61 |    162 | CPU
DEBUG 01-14 20:42:23.847548.847548 lmp.py:1625]   Expert 30 |    163 | CPU
DEBUG 01-14 20:42:23.847953.847953 lmp.py:1625]   Expert 43 |    169 | CPU
DEBUG 01-14 20:42:23.847357.847357 lmp.py:1625]   Expert 44 |    169 | CPU
DEBUG 01-14 20:42:23.847762.847762 lmp.py:1625]   Expert  9 |    175 | CPU
DEBUG 01-14 20:42:23.847166.847166 lmp.py:1625]   Expert 13 |    175 | CPU
DEBUG 01-14 20:42:23.847809.847809 lmp.py:1625]   Expert  3 |    177 | CPU
DEBUG 01-14 20:42:23.847975.847975 lmp.py:1625]   Expert 31 |    177 | CPU
DEBUG 01-14 20:42:23.847142.847142 lmp.py:1625]   Expert 46 |    187 | GPU
DEBUG 01-14 20:42:23.847785.847785 lmp.py:1625]   Expert 42 |    188 | GPU
DEBUG 01-14 20:42:23.847428.847428 lmp.py:1625]   Expert 50 |    188 | GPU
DEBUG 01-14 20:42:23.847547.847547 lmp.py:1625]   Expert 62 |    188 | GPU
DEBUG 01-14 20:42:23.847190.847190 lmp.py:1625]   Expert 11 |    194 | GPU
DEBUG 01-14 20:42:23.847310.847310 lmp.py:1625]   Expert 47 |    194 | GPU
DEBUG 01-14 20:42:23.847953.847953 lmp.py:1625]   Expert 20 |    195 | GPU
DEBUG 01-14 20:42:23.847358.847358 lmp.py:1625]   Expert 26 |    196 | GPU
DEBUG 01-14 20:42:23.847524.847524 lmp.py:1625]   Expert 51 |    198 | GPU
DEBUG 01-14 20:42:23.847928.847928 lmp.py:1625]   Expert 19 |    201 | GPU
DEBUG 01-14 20:42:23.847095.847095 lmp.py:1625]   Expert 63 |    201 | GPU
DEBUG 01-14 20:42:23.847976.847976 lmp.py:1625]   Expert 27 |    203 | GPU
DEBUG 01-14 20:42:23.847142.847142 lmp.py:1625]   Expert 18 |    205 | GPU
DEBUG 01-14 20:42:23.847308.847308 lmp.py:1625]   Expert 56 |    210 | GPU
DEBUG 01-14 20:42:23.847713.847713 lmp.py:1625]   Expert 55 |    211 | GPU
DEBUG 01-14 20:42:23.847117.847117 lmp.py:1625]   Expert 38 |    216 | GPU
DEBUG 01-14 20:42:23.847522.847522 lmp.py:1625]   Expert 49 |    220 | GPU
DEBUG 01-14 20:42:23.847688.847688 lmp.py:1625]   Expert 48 |    225 | GPU
DEBUG 01-14 20:42:23.847569.847569 lmp.py:1625]   Expert  1 |    234 | GPU
DEBUG 01-14 20:42:23.847212.847212 lmp.py:1625]   Expert 54 |    240 | GPU
DEBUG 01-14 20:42:23.847047.847047 lmp.py:1625]   Expert  7 |    241 | GPU
DEBUG 01-14 20:42:23.847406.847406 lmp.py:1625]   Expert 10 |    242 | GPU
DEBUG 01-14 20:42:23.847049.847049 lmp.py:1625]   Expert 21 |    247 | GPU
DEBUG 01-14 20:42:23.847453.847453 lmp.py:1625]   Expert 24 |    252 | GPU
DEBUG 01-14 20:42:23.847619.847619 lmp.py:1625]   Expert 33 |    252 | GPU
DEBUG 01-14 20:42:23.847024.847024 lmp.py:1625]   Expert 29 |    260 | GPU
DEBUG 01-14 20:42:23.847428.847428 lmp.py:1625]   Expert 40 |    269 | GPU
DEBUG 01-14 20:42:23.847833.847833 lmp.py:1625]   Expert 59 |    295 | GPU
DEBUG 01-14 20:42:23.847953.847953 lmp.py:1625]   Expert 37 |    337 | GPU
DEBUG 01-14 20:42:23.847549.847549 lmp.py:1625]   Expert 58 |    355 | GPU
DEBUG 01-14 20:42:23.847431.847431 lmp.py:1625]   Expert  6 |    388 | GPU
DEBUG 01-14 20:42:23.847789.847789 lmp.py:1625]   Expert 53 |    851 | GPU
DEBUG 01-14 20:42:23.847909.847909 lmp.py:1626] 
DEBUG 01-14 20:42:23.847909.847909 lmp.py:1626]   CPU total tokens: 4205 (34.2%)
DEBUG 01-14 20:42:23.847506.847506 lmp.py:1627]   GPU total tokens: 8083 (65.8%)
DEBUG 01-14 20:42:23.848917.848917 cuda_h.py:19] end experts_map_get cost 0.0015878677368164062 seconds
DEBUG 01-14 20:42:23.848959.848959 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-14 20:42:23.848756.848756 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-14 20:42:23.848270.848270 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-14 20:42:23.850429.850429 cuda_h.py:19] end allocate_cuda_memory cost 0.0019452571868896484 seconds
DEBUG 01-14 20:42:23.850769.850769 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-14 20:42:23.850479.850479 sllm_store_c.py:27] get device uuid map
DEBUG 01-14 20:42:23.850096.850096 sllm_store_c.py:29] call client load into gpu
DEBUG 01-14 20:42:23.850984.850984 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, c674a125-e01a-4ccd-8460-aa7fb16b717c
DEBUG 01-14 20:42:23.850374.850374 client.py:106] call stub.LoadModelAsync
INFO 01-14 20:42:23.851853.851853 client.py:127] Model loaded
DEBUG 01-14 20:42:23.851465.851465 cuda_h.py:10] start restore2model
DEBUG 01-14 20:42:23.851734.851734 cuda_h.py:19] end restore2model cost 0.00046944618225097656 seconds
DEBUG 01-14 20:42:23.851007.851007 cuda_h.py:19] end sllm_worker_task cost 0.011188268661499023 seconds
INFO 01-14 20:42:23.852454.852454 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, c674a125-e01a-4ccd-8460-aa7fb16b717c
DEBUG 01-14 20:42:23.852158.852158 cuda_h.py:19] end load_into_gpu_async cost 0.0022885799407958984 seconds
DEBUG 01-14 20:42:23.852053.852053 cuda_h.py:10] start restore_tensors2
DEBUG 01-14 20:42:23.853193.853193 cuda_h.py:19] end restore_tensors2 cost 0.0003914833068847656 seconds
DEBUG 01-14 20:42:23.853321.853321 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.004992008209228516 seconds
DEBUG 01-14 20:42:23.853799.853799 cuda_h.py:10] start restore2model
DEBUG 01-14 20:42:23.855522.855522 cuda_h.py:19] end restore2model cost 0.0025751590728759766 seconds
DEBUG 01-14 20:42:23.855365.855365 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.00774836540222168 seconds
DEBUG 01-14 20:42:23.855637.855637 cuda_h.py:10] start gpu_sexperts
DEBUG 01-14 20:42:23.856144.856144 cuda_h.py:19] end gpu_sexperts cost 0.0002715587615966797 seconds
DEBUG 01-14 20:42:23.856113.856113 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-14 20:42:23.856008.856008 lmp.py:1683] 
DEBUG 01-14 20:42:23.856008.856008 lmp.py:1683]   Computing 32 experts on CPU...
DEBUG 01-14 20:42:23.856751.856751 cuda_h.py:19] end cpu_experts_submit cost 5.6743621826171875e-05 seconds
DEBUG 01-14 20:42:23.856308.856308 cuda_h.py:10] start experts_func_mgpu_group_pad
DEBUG 01-14 20:42:23.867158.867158 mlpmodule.py:1460] group tensors cost 0.010406255722045898 s
DEBUG 01-14 20:42:23.868423.868423 cuda_h.py:10] start move_flat_hidden2cpu
DEBUG 01-14 20:42:23.870337.870337 cuda_h.py:19] end experts_func_mgpu_group_pad cost 0.014045000076293945 seconds
DEBUG 01-14 20:42:23.872098.872098 cuda_h.py:10] start gpu_group_list
DEBUG 01-14 20:42:23.872645.872645 cuda_h.py:19] end gpu_group_list cost 0.0005850791931152344 seconds
DEBUG 01-14 20:42:23.873409.873409 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-14 20:42:23.873884.873884 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 3.1948089599609375e-05 seconds
DEBUG 01-14 20:42:23.873475.873475 cuda_h.py:10] start wait_experts
INFO 01-14 20:42:23.873722.873722 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, c674a125-e01a-4ccd-8460-aa7fb16b717c
DEBUG 01-14 20:42:23.875665.875665 cuda_h.py:19] end move_flat_hidden2cpu cost 0.007532596588134766 seconds
DEBUG 01-14 20:42:23.878629.878629 mlpmodule.py:1533] pad cost 0.0023162364959716797 s
DEBUG 01-14 20:42:23.878375.878375 mlpmodule.py:1539] create cpu tensor cost 4.57763671875e-05 s
DEBUG 01-14 20:42:23.880904.880904 mlpmodule.py:1544] move to cpu cost 0.0021049976348876953 s
DEBUG 01-14 20:42:23.887406.887406 mlpmodule.py:1558] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-14 20:42:23.887005.887005 mlpmodule.py:1559] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-14 20:42:23.887352.887352 mlpmodule.py:1564] group_w3 first element: 0.03369140625
WARNING 01-14 20:42:23.887992.887992 mlpmodule.py:1574] start einsum2
DEBUG 01-14 20:42:23.900447.900447 mlpmodule.py:1584] group einsum cost 0.019725799560546875 s
DEBUG 01-14 20:42:23.901965.901965 mlpmodule.py:1593] cpy2cputensor cost 0.0007376670837402344 s
DEBUG 01-14 20:42:23.901093.901093 cuda_h.py:10] start move_outputs
INFO 01-14 20:42:23.902425.902425 client.py:127] Model loaded
DEBUG 01-14 20:42:23.902312.902312 cuda_h.py:19] end wait_experts cost 0.028890132904052734 seconds
DEBUG 01-14 20:42:23.902943.902943 cuda_h.py:10] start gpu_experts
DEBUG 01-14 20:42:23.902812.902812 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-14 20:42:23.903612.903612 cuda_h.py:19] end move_outputs cost 0.0020194053649902344 seconds
DEBUG 01-14 20:42:23.908727.908727 cuda_h.py:19] end wait_cetm_experts cost 0.0059130191802978516 seconds
DEBUG 01-14 20:42:23.908434.908434 cuda_h.py:10] start gpu_group_einsum_mp_multi_list
DEBUG 01-14 20:42:23.908673.908673 cuda_h.py:10] start gpu_group_tensor
DEBUG 01-14 20:42:23.908054.908054 cuda_h.py:19] end gpu_group_tensor cost 0.0002467632293701172 seconds
DEBUG 01-14 20:42:23.909272.909272 cuda_h.py:10] start gpu_group_einsum
DEBUG 01-14 20:42:23.925529.925529 mlpmodule.py:1367]  experts func einsum cost 0.06897115707397461 s
DEBUG 01-14 20:42:23.927722.927722 cuda_h.py:19] end gpu_group_einsum cost 0.017912626266479492 seconds
DEBUG 01-14 20:42:23.927340.927340 cuda_h.py:10] start gpu_final_hidden_states_scatter
DEBUG 01-14 20:42:23.927721.927721 cuda_h.py:10] start all_expert_outputs_slices
DEBUG 01-14 20:42:23.927617.927617 cuda_h.py:19] end all_expert_outputs_slices cost 0.00039267539978027344 seconds
DEBUG 01-14 20:42:23.927830.927830 cuda_h.py:10] start concat_expert_out
DEBUG 01-14 20:42:23.928895.928895 cuda_h.py:19] end concat_expert_out cost 9.751319885253906e-05 seconds
DEBUG 01-14 20:42:23.928038.928038 cuda_h.py:10] start index_scatter
DEBUG 01-14 20:42:23.928155.928155 cuda_h.py:19] end index_scatter cost 0.00010132789611816406 seconds
DEBUG 01-14 20:42:23.928091.928091 cuda_h.py:19] end gpu_final_hidden_states_scatter cost 0.0010082721710205078 seconds
DEBUG 01-14 20:42:23.928228.928228 cuda_h.py:19] end gpu_experts cost 0.026088953018188477 seconds
DEBUG 01-14 20:42:23.928481.928481 cuda_h.py:10] start all_expert_weight_slices
DEBUG 01-14 20:42:23.929470.929470 cuda_h.py:19] end all_expert_weight_slices cost 0.0013811588287353516 seconds
DEBUG 01-14 20:42:23.930942.930942 cuda_h.py:10] start cpuoutputsdeal
DEBUG 01-14 20:42:23.930346.930346 cuda_h.py:10] start index_scatter
DEBUG 01-14 20:42:23.930013.930013 cuda_h.py:19] end index_scatter cost 6.890296936035156e-05 seconds
DEBUG 01-14 20:42:23.930471.930471 cuda_h.py:19] end cpuoutputsdeal cost 0.0007305145263671875 seconds
DEBUG 01-14 20:42:23.930515.930515 cuda_h.py:19] end layer_moe_generate_mp_l_6 cost 0.08526396751403809 seconds
DEBUG 01-14 20:42:23.931231.931231 cuda_h.py:19] end prefill_layer cost 0.09125304222106934 seconds
DEBUG 01-14 20:42:23.931022.931022 lmp.py:1551] -------------------------------- end prefill layer 5 --------------------------------
DEBUG 01-14 20:42:23.931454.931454 cuda_h.py:10] start prefill_layer
DEBUG 01-14 20:42:23.931124.931124 lmp.py:1494] -------------------------------- start prefill layer 6 --------------------------------
DEBUG 01-14 20:42:23.931794.931794 cuda_h.py:10] start start_load_qkvogn_s_weight_l_7
DEBUG 01-14 20:42:23.931848.931848 cuda_h.py:10] start start_load_qkvogn_s_weight_l_7
DEBUG 01-14 20:42:23.931096.931096 cuda_h.py:19] end start_load_qkvogn_s_weight_l_7 cost 3.933906555175781e-05 seconds
DEBUG 01-14 20:42:23.931865.931865 cuda_h.py:19] end start_load_qkvogn_s_weight_l_7 cost 8.344650268554688e-05 seconds
DEBUG 01-14 20:42:23.931052.931052 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-14 20:42:23.931168.931168 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-14 20:42:23.932160.932160 cuda_h.py:10] start sllm_worker_task
DEBUG 01-14 20:42:23.932431.932431 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-14 20:42:23.932788.932788 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-14 20:42:23.932691.932691 cuda_h.py:19] end allocate_cuda_memory cost 0.000370025634765625 seconds
DEBUG 01-14 20:42:23.933500.933500 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-14 20:42:23.933987.933987 sllm_store_c.py:27] get device uuid map
DEBUG 01-14 20:42:23.933666.933666 sllm_store_c.py:29] call client load into gpu
DEBUG 01-14 20:42:23.933597.933597 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 06b2f95d-e5d7-4d02-a51d-4f40e5082397
DEBUG 01-14 20:42:23.933921.933921 client.py:106] call stub.LoadModelAsync
DEBUG 01-14 20:42:23.933142.933142 cuda_h.py:10] start self_attn
INFO 01-14 20:42:23.935765.935765 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 06b2f95d-e5d7-4d02-a51d-4f40e5082397
DEBUG 01-14 20:42:23.935684.935684 cuda_h.py:19] end load_into_gpu_async cost 0.0024046897888183594 seconds
DEBUG 01-14 20:42:23.935787.935787 cuda_h.py:10] start restore_tensors2
DEBUG 01-14 20:42:23.935439.935439 cuda_h.py:19] end restore_tensors2 cost 0.00017499923706054688 seconds
DEBUG 01-14 20:42:23.936662.936662 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0038022994995117188 seconds
INFO 01-14 20:42:23.936251.936251 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 06b2f95d-e5d7-4d02-a51d-4f40e5082397
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-14 20:42:23.938852.938852 cuda_h.py:19] end self_attn cost 0.004678487777709961 seconds
DEBUG 01-14 20:42:23.939979.939979 cuda_h.py:19] end iln_self_attn_paln cost 0.007272481918334961 seconds
DEBUG 01-14 20:42:23.939956.939956 cuda_h.py:10] start layer_moe_generate_mp_l_7
DEBUG 01-14 20:42:23.939461.939461 cuda_h.py:10] start gate
DEBUG 01-14 20:42:23.940262.940262 cuda_h.py:19] end gate cost 0.0009236335754394531 seconds
DEBUG 01-14 20:42:23.940350.940350 cuda_h.py:10] start experts_map_get
DEBUG 01-14 20:42:23.940261.940261 lmp.py:1615] 
DEBUG 01-14 20:42:23.940261.940261 lmp.py:1615] Expert Token Distribution & Device Allocation:
DEBUG 01-14 20:42:23.940070.940070 lmp.py:1616]   Total experts: 64
DEBUG 01-14 20:42:23.940720.940720 lmp.py:1617]   CPU experts: 32 (50%)
DEBUG 01-14 20:42:23.940032.940032 lmp.py:1618]   GPU experts: 32 (50%)
DEBUG 01-14 20:42:23.940198.940198 lmp.py:1619] 
DEBUG 01-14 20:42:23.940198.940198 lmp.py:1619]   Expert ID | Tokens | Device
DEBUG 01-14 20:42:23.940364.940364 lmp.py:1620]   -----------------------------------
DEBUG 01-14 20:42:23.940199.940199 lmp.py:1625]   Expert  1 |     51 | CPU
DEBUG 01-14 20:42:23.940558.940558 lmp.py:1625]   Expert 37 |     65 | CPU
DEBUG 01-14 20:42:23.940916.940916 lmp.py:1625]   Expert 17 |     74 | CPU
DEBUG 01-14 20:42:23.940559.940559 lmp.py:1625]   Expert  7 |     76 | CPU
DEBUG 01-14 20:42:23.940202.940202 lmp.py:1625]   Expert 18 |     80 | CPU
DEBUG 01-14 20:42:23.940891.940891 lmp.py:1625]   Expert 13 |     83 | CPU
DEBUG 01-14 20:42:23.940342.940342 lmp.py:1625]   Expert  9 |     91 | CPU
DEBUG 01-14 20:42:23.940316.940316 lmp.py:1625]   Expert 54 |     96 | CPU
DEBUG 01-14 20:42:23.940529.940529 lmp.py:1625]   Expert 58 |     97 | CPU
DEBUG 01-14 20:42:23.940741.940741 lmp.py:1625]   Expert 22 |    106 | CPU
DEBUG 01-14 20:42:23.940192.940192 lmp.py:1625]   Expert  0 |    109 | CPU
DEBUG 01-14 20:42:23.940404.940404 lmp.py:1625]   Expert 59 |    110 | CPU
DEBUG 01-14 20:42:23.940617.940617 lmp.py:1625]   Expert 26 |    112 | CPU
DEBUG 01-14 20:42:23.940829.940829 lmp.py:1625]   Expert 10 |    116 | CPU
DEBUG 01-14 20:42:23.940803.940803 lmp.py:1625]   Expert 16 |    122 | CPU
DEBUG 01-14 20:42:23.940208.940208 lmp.py:1625]   Expert 43 |    128 | CPU
DEBUG 01-14 20:42:23.940281.940281 lmp.py:1625]   Expert 63 |    130 | CPU
DEBUG 01-14 20:42:23.940116.940116 lmp.py:1625]   Expert 28 |    137 | CPU
DEBUG 01-14 20:42:23.941713.941713 lmp.py:1625]   Expert 29 |    139 | CPU
DEBUG 01-14 20:42:23.941118.941118 lmp.py:1625]   Expert 33 |    141 | CPU
DEBUG 01-14 20:42:23.941999.941999 lmp.py:1625]   Expert  2 |    149 | CPU
DEBUG 01-14 20:42:23.941165.941165 lmp.py:1625]   Expert 51 |    152 | CPU
DEBUG 01-14 20:42:23.941808.941808 lmp.py:1625]   Expert 45 |    156 | CPU
DEBUG 01-14 20:42:23.941213.941213 lmp.py:1625]   Expert 40 |    160 | CPU
DEBUG 01-14 20:42:23.941333.941333 lmp.py:1625]   Expert 62 |    162 | CPU
DEBUG 01-14 20:42:23.941975.941975 lmp.py:1625]   Expert 23 |    163 | CPU
DEBUG 01-14 20:42:23.941857.941857 lmp.py:1625]   Expert 32 |    166 | CPU
DEBUG 01-14 20:42:23.941738.941738 lmp.py:1625]   Expert 11 |    169 | CPU
DEBUG 01-14 20:42:23.941381.941381 lmp.py:1625]   Expert 55 |    169 | CPU
DEBUG 01-14 20:42:23.941547.941547 lmp.py:1625]   Expert 34 |    170 | CPU
DEBUG 01-14 20:42:23.941190.941190 lmp.py:1625]   Expert 41 |    172 | CPU
DEBUG 01-14 20:42:23.941833.941833 lmp.py:1625]   Expert 52 |    173 | CPU
DEBUG 01-14 20:42:23.941238.941238 lmp.py:1625]   Expert  3 |    179 | GPU
DEBUG 01-14 20:42:23.941642.941642 lmp.py:1625]   Expert 14 |    179 | GPU
DEBUG 01-14 20:42:23.941908.941908 lmp.py:1625]   Expert 53 |    185 | GPU
DEBUG 01-14 20:42:23.941028.941028 lmp.py:1625]   Expert 42 |    188 | GPU
DEBUG 01-14 20:42:23.941863.941863 lmp.py:1625]   Expert 57 |    193 | GPU
DEBUG 01-14 20:42:23.941029.941029 lmp.py:1625]   Expert 15 |    201 | GPU
DEBUG 01-14 20:42:23.941149.941149 lmp.py:1625]   Expert 35 |    203 | GPU
DEBUG 01-14 20:42:23.941030.941030 lmp.py:1625]   Expert 30 |    212 | GPU
DEBUG 01-14 20:42:23.941673.941673 lmp.py:1625]   Expert 21 |    214 | GPU
DEBUG 01-14 20:42:23.941555.941555 lmp.py:1625]   Expert 24 |    217 | GPU
DEBUG 01-14 20:42:23.941198.941198 lmp.py:1625]   Expert  4 |    221 | GPU
DEBUG 01-14 20:42:23.941602.941602 lmp.py:1625]   Expert 12 |    224 | GPU
DEBUG 01-14 20:42:23.941173.941173 lmp.py:1625]   Expert 44 |    226 | GPU
DEBUG 01-14 20:42:23.941816.941816 lmp.py:1625]   Expert 19 |    232 | GPU
DEBUG 01-14 20:42:23.941790.941790 lmp.py:1625]   Expert 49 |    232 | GPU
DEBUG 01-14 20:42:23.941002.941002 lmp.py:1625]   Expert 47 |    235 | GPU
DEBUG 01-14 20:42:23.941692.941692 lmp.py:1625]   Expert 38 |    236 | GPU
DEBUG 01-14 20:42:23.941619.941619 lmp.py:1625]   Expert 50 |    245 | GPU
DEBUG 01-14 20:42:23.941885.941885 lmp.py:1625]   Expert 31 |    248 | GPU
DEBUG 01-14 20:42:23.941336.941336 lmp.py:1625]   Expert 61 |    248 | GPU
DEBUG 01-14 20:42:23.941071.941071 lmp.py:1625]   Expert  8 |    249 | GPU
DEBUG 01-14 20:42:23.941284.941284 lmp.py:1625]   Expert 46 |    249 | GPU
DEBUG 01-14 20:42:23.941781.941781 lmp.py:1625]   Expert  6 |    253 | GPU
DEBUG 01-14 20:42:23.941755.941755 lmp.py:1625]   Expert 39 |    262 | GPU
DEBUG 01-14 20:42:23.941252.941252 lmp.py:1625]   Expert  5 |    303 | GPU
DEBUG 01-14 20:42:23.941226.941226 lmp.py:1625]   Expert 27 |    303 | GPU
DEBUG 01-14 20:42:23.941439.941439 lmp.py:1625]   Expert 48 |    303 | GPU
DEBUG 01-14 20:42:23.941936.941936 lmp.py:1625]   Expert 20 |    341 | GPU
DEBUG 01-14 20:42:23.941625.941625 lmp.py:1625]   Expert 36 |    361 | GPU
DEBUG 01-14 20:42:23.941030.941030 lmp.py:1625]   Expert 60 |    363 | GPU
DEBUG 01-14 20:42:23.941911.941911 lmp.py:1625]   Expert 25 |    391 | GPU
DEBUG 01-14 20:42:23.941839.941839 lmp.py:1625]   Expert 56 |    568 | GPU
DEBUG 01-14 20:42:23.941244.941244 lmp.py:1626] 
DEBUG 01-14 20:42:23.941244.941244 lmp.py:1626]   CPU total tokens: 4024 (32.7%)
DEBUG 01-14 20:42:23.941410.941410 lmp.py:1627]   GPU total tokens: 8264 (67.3%)
DEBUG 01-14 20:42:23.941059.941059 cuda_h.py:19] end experts_map_get cost 0.0015811920166015625 seconds
DEBUG 01-14 20:42:23.941055.941055 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-14 20:42:23.941752.941752 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-14 20:42:23.942028.942028 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-14 20:42:23.942662.942662 cuda_h.py:19] end allocate_cuda_memory cost 0.0006792545318603516 seconds
DEBUG 01-14 20:42:23.942366.942366 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-14 20:42:23.942360.942360 sllm_store_c.py:27] get device uuid map
DEBUG 01-14 20:42:23.942183.942183 sllm_store_c.py:29] call client load into gpu
DEBUG 01-14 20:42:23.942501.942501 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 2d820b75-41cf-484c-ba98-47c3506bae36
DEBUG 01-14 20:42:23.943322.943322 client.py:106] call stub.LoadModelAsync
INFO 01-14 20:42:23.943194.943194 client.py:127] Model loaded
DEBUG 01-14 20:42:23.943464.943464 cuda_h.py:10] start restore2model
DEBUG 01-14 20:42:23.945253.945253 cuda_h.py:19] end restore2model cost 0.0010874271392822266 seconds
DEBUG 01-14 20:42:23.945436.945436 cuda_h.py:19] end sllm_worker_task cost 0.013003110885620117 seconds
INFO 01-14 20:42:23.945394.945394 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 2d820b75-41cf-484c-ba98-47c3506bae36
DEBUG 01-14 20:42:23.945478.945478 cuda_h.py:19] end load_into_gpu_async cost 0.002541065216064453 seconds
DEBUG 01-14 20:42:23.945473.945473 cuda_h.py:10] start restore_tensors2
DEBUG 01-14 20:42:23.945129.945129 cuda_h.py:19] end restore_tensors2 cost 0.00038623809814453125 seconds
DEBUG 01-14 20:42:23.945257.945257 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.003963947296142578 seconds
DEBUG 01-14 20:42:23.946112.946112 cuda_h.py:10] start restore2model
DEBUG 01-14 20:42:23.948989.948989 cuda_h.py:19] end restore2model cost 0.0026171207427978516 seconds
DEBUG 01-14 20:42:23.948753.948753 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.0067713260650634766 seconds
DEBUG 01-14 20:42:23.948502.948502 cuda_h.py:10] start gpu_sexperts
DEBUG 01-14 20:42:23.949108.949108 cuda_h.py:19] end gpu_sexperts cost 0.0002741813659667969 seconds
DEBUG 01-14 20:42:23.949362.949362 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-14 20:42:23.949734.949734 lmp.py:1683] 
DEBUG 01-14 20:42:23.949734.949734 lmp.py:1683]   Computing 32 experts on CPU...
DEBUG 01-14 20:42:23.949861.949861 cuda_h.py:19] end cpu_experts_submit cost 5.91278076171875e-05 seconds
DEBUG 01-14 20:42:23.949942.949942 cuda_h.py:10] start experts_func_mgpu_group_pad
DEBUG 01-14 20:42:23.966838.966838 mlpmodule.py:1460] group tensors cost 0.016534805297851562 s
DEBUG 01-14 20:42:23.967746.967746 cuda_h.py:10] start move_flat_hidden2cpu
DEBUG 01-14 20:42:23.969070.969070 cuda_h.py:19] end experts_func_mgpu_group_pad cost 0.02035236358642578 seconds
DEBUG 01-14 20:42:23.971531.971531 cuda_h.py:10] start gpu_group_list
DEBUG 01-14 20:42:23.972509.972509 cuda_h.py:19] end gpu_group_list cost 0.0007634162902832031 seconds
DEBUG 01-14 20:42:23.973373.973373 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-14 20:42:23.973384.973384 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 3.218650817871094e-05 seconds
DEBUG 01-14 20:42:23.973532.973532 cuda_h.py:10] start wait_experts
INFO 01-14 20:42:23.973415.973415 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 2d820b75-41cf-484c-ba98-47c3506bae36
DEBUG 01-14 20:42:23.979728.979728 cuda_h.py:19] end move_flat_hidden2cpu cost 0.011815786361694336 seconds
DEBUG 01-14 20:42:23.981187.981187 mlpmodule.py:1533] pad cost 0.0023109912872314453 s
DEBUG 01-14 20:42:23.981926.981926 mlpmodule.py:1539] create cpu tensor cost 4.57763671875e-05 s
DEBUG 01-14 20:42:23.983149.983149 mlpmodule.py:1544] move to cpu cost 0.0020551681518554688 s
DEBUG 01-14 20:42:23.993079.993079 mlpmodule.py:1558] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-14 20:42:23.993906.993906 mlpmodule.py:1559] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-14 20:42:23.993618.993618 mlpmodule.py:1564] group_w3 first element: -0.003631591796875
WARNING 01-14 20:42:23.994100.994100 mlpmodule.py:1574] start einsum2
INFO 01-14 20:42:23.994330.994330 client.py:127] Model loaded
DEBUG 01-14 20:42:23.995593.995593 cuda_h.py:19] end wait_experts cost 0.0216829776763916 seconds
DEBUG 01-14 20:42:23.995259.995259 cuda_h.py:10] start gpu_experts
DEBUG 01-14 20:42:23.995262.995262 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-14 20:42:24.013764.013764 mlpmodule.py:1584] group einsum cost 0.029149293899536133 s
DEBUG 01-14 20:42:24.014969.014969 mlpmodule.py:1593] cpy2cputensor cost 0.0007557868957519531 s
DEBUG 01-14 20:42:24.014488.014488 cuda_h.py:10] start move_outputs
DEBUG 01-14 20:42:24.016824.016824 cuda_h.py:19] end move_outputs cost 0.0020711421966552734 seconds
DEBUG 01-14 20:42:24.021479.021479 cuda_h.py:19] end wait_cetm_experts cost 0.026334285736083984 seconds
DEBUG 01-14 20:42:24.022171.022171 cuda_h.py:10] start gpu_group_einsum_mp_multi_list
DEBUG 01-14 20:42:24.022134.022134 cuda_h.py:10] start gpu_group_tensor
DEBUG 01-14 20:42:24.022867.022867 cuda_h.py:19] end gpu_group_tensor cost 0.0002779960632324219 seconds
DEBUG 01-14 20:42:24.022316.022316 cuda_h.py:10] start gpu_group_einsum
DEBUG 01-14 20:42:24.023696.023696 cuda_h.py:19] end gpu_group_einsum cost 0.0006110668182373047 seconds
DEBUG 01-14 20:42:24.023351.023351 cuda_h.py:10] start gpu_final_hidden_states_scatter
DEBUG 01-14 20:42:24.023168.023168 cuda_h.py:10] start all_expert_outputs_slices
DEBUG 01-14 20:42:24.023219.023219 cuda_h.py:19] end all_expert_outputs_slices cost 0.0003180503845214844 seconds
DEBUG 01-14 20:42:24.024863.024863 cuda_h.py:10] start concat_expert_out
DEBUG 01-14 20:42:24.024488.024488 cuda_h.py:19] end concat_expert_out cost 0.00022745132446289062 seconds
DEBUG 01-14 20:42:24.024025.024025 cuda_h.py:10] start index_scatter
DEBUG 01-14 20:42:24.024080.024080 cuda_h.py:19] end index_scatter cost 0.00011801719665527344 seconds
DEBUG 01-14 20:42:24.025708.025708 cuda_h.py:19] end gpu_final_hidden_states_scatter cost 0.0014986991882324219 seconds
DEBUG 01-14 20:42:24.025079.025079 cuda_h.py:19] end gpu_experts cost 0.029955148696899414 seconds
DEBUG 01-14 20:42:24.025176.025176 cuda_h.py:10] start all_expert_weight_slices
DEBUG 01-14 20:42:24.026964.026964 cuda_h.py:19] end all_expert_weight_slices cost 0.0011224746704101562 seconds
DEBUG 01-14 20:42:24.026142.026142 cuda_h.py:10] start cpuoutputsdeal
DEBUG 01-14 20:42:24.027056.027056 cuda_h.py:10] start index_scatter
DEBUG 01-14 20:42:24.027375.027375 cuda_h.py:19] end index_scatter cost 6.508827209472656e-05 seconds
DEBUG 01-14 20:42:24.027268.027268 cuda_h.py:19] end cpuoutputsdeal cost 0.0009510517120361328 seconds
DEBUG 01-14 20:42:24.027709.027709 cuda_h.py:19] end layer_moe_generate_mp_l_7 cost 0.08870840072631836 seconds
DEBUG 01-14 20:42:24.028772.028772 cuda_h.py:19] end prefill_layer cost 0.09685111045837402 seconds
DEBUG 01-14 20:42:24.028378.028378 lmp.py:1551] -------------------------------- end prefill layer 6 --------------------------------
DEBUG 01-14 20:42:24.028532.028532 cuda_h.py:10] start prefill_layer
DEBUG 01-14 20:42:24.028334.028334 lmp.py:1494] -------------------------------- start prefill layer 7 --------------------------------
DEBUG 01-14 20:42:24.028991.028991 cuda_h.py:10] start start_load_qkvogn_s_weight_l_8
DEBUG 01-14 20:42:24.028031.028031 cuda_h.py:10] start start_load_qkvogn_s_weight_l_8
DEBUG 01-14 20:42:24.028404.028404 cuda_h.py:19] end start_load_qkvogn_s_weight_l_8 cost 3.552436828613281e-05 seconds
DEBUG 01-14 20:42:24.028306.028306 cuda_h.py:19] end start_load_qkvogn_s_weight_l_8 cost 7.176399230957031e-05 seconds
DEBUG 01-14 20:42:24.028810.028810 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-14 20:42:24.028415.028415 cuda_h.py:10] start sllm_worker_task
DEBUG 01-14 20:42:24.028060.028060 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-14 20:42:24.028936.028936 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-14 20:42:24.033081.033081 cuda_h.py:19] end allocate_cuda_memory cost 0.004075050354003906 seconds
DEBUG 01-14 20:42:24.033426.033426 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-14 20:42:24.033561.033561 sllm_store_c.py:27] get device uuid map
DEBUG 01-14 20:42:24.033198.033198 sllm_store_c.py:29] call client load into gpu
DEBUG 01-14 20:42:24.033809.033809 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, addc76ff-e173-4485-aa32-5cbe83e22638
DEBUG 01-14 20:42:24.033163.033163 client.py:106] call stub.LoadModelAsync
DEBUG 01-14 20:42:24.033905.033905 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-14 20:42:24.034943.034943 cuda_h.py:10] start self_attn
INFO 01-14 20:42:24.035617.035617 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, addc76ff-e173-4485-aa32-5cbe83e22638
DEBUG 01-14 20:42:24.035168.035168 cuda_h.py:19] end load_into_gpu_async cost 0.0019223690032958984 seconds
DEBUG 01-14 20:42:24.035653.035653 cuda_h.py:10] start restore_tensors2
DEBUG 01-14 20:42:24.035643.035643 cuda_h.py:19] end restore_tensors2 cost 7.05718994140625e-05 seconds
DEBUG 01-14 20:42:24.035207.035207 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.006539821624755859 seconds
INFO 01-14 20:42:24.035182.035182 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, addc76ff-e173-4485-aa32-5cbe83e22638
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-14 20:42:24.037720.037720 cuda_h.py:19] end self_attn cost 0.0029702186584472656 seconds
DEBUG 01-14 20:42:24.037413.037413 cuda_h.py:19] end iln_self_attn_paln cost 0.008666753768920898 seconds
DEBUG 01-14 20:42:24.037679.037679 cuda_h.py:10] start layer_moe_generate_mp_l_8
DEBUG 01-14 20:42:24.037773.037773 cuda_h.py:10] start gate
DEBUG 01-14 20:42:24.038993.038993 cuda_h.py:19] end gate cost 0.0005853176116943359 seconds
DEBUG 01-14 20:42:24.038199.038199 cuda_h.py:10] start experts_map_get
DEBUG 01-14 20:42:24.038368.038368 lmp.py:1615] 
DEBUG 01-14 20:42:24.038368.038368 lmp.py:1615] Expert Token Distribution & Device Allocation:
DEBUG 01-14 20:42:24.038979.038979 lmp.py:1616]   Total experts: 64
DEBUG 01-14 20:42:24.038675.038675 lmp.py:1617]   CPU experts: 32 (50%)
DEBUG 01-14 20:42:24.038510.038510 lmp.py:1618]   GPU experts: 32 (50%)
DEBUG 01-14 20:42:24.038722.038722 lmp.py:1619] 
DEBUG 01-14 20:42:24.038722.038722 lmp.py:1619]   Expert ID | Tokens | Device
DEBUG 01-14 20:42:24.038127.038127 lmp.py:1620]   -----------------------------------
DEBUG 01-14 20:42:24.038584.038584 lmp.py:1625]   Expert 46 |     38 | CPU
DEBUG 01-14 20:42:24.038181.038181 lmp.py:1625]   Expert 50 |     48 | CPU
DEBUG 01-14 20:42:24.038632.038632 lmp.py:1625]   Expert  3 |     59 | CPU
DEBUG 01-14 20:42:24.038368.038368 lmp.py:1625]   Expert  1 |     86 | CPU
DEBUG 01-14 20:42:24.038342.038342 lmp.py:1625]   Expert 15 |     96 | CPU
DEBUG 01-14 20:42:24.038077.038077 lmp.py:1625]   Expert 29 |     96 | CPU
DEBUG 01-14 20:42:24.038741.038741 lmp.py:1625]   Expert  4 |     99 | CPU
DEBUG 01-14 20:42:24.038245.038245 lmp.py:1625]   Expert 40 |    101 | CPU
DEBUG 01-14 20:42:24.038318.038318 lmp.py:1625]   Expert 28 |    105 | CPU
DEBUG 01-14 20:42:24.038392.038392 lmp.py:1625]   Expert 54 |    115 | CPU
DEBUG 01-14 20:42:24.038227.038227 lmp.py:1625]   Expert  8 |    116 | CPU
DEBUG 01-14 20:42:24.038823.038823 lmp.py:1625]   Expert 41 |    118 | CPU
DEBUG 01-14 20:42:24.038705.038705 lmp.py:1625]   Expert 13 |    128 | CPU
DEBUG 01-14 20:42:24.038063.038063 lmp.py:1625]   Expert 18 |    132 | CPU
DEBUG 01-14 20:42:24.038229.038229 lmp.py:1625]   Expert  7 |    133 | CPU
DEBUG 01-14 20:42:24.038826.038826 lmp.py:1625]   Expert 16 |    133 | CPU
DEBUG 01-14 20:42:24.038469.038469 lmp.py:1625]   Expert  6 |    135 | CPU
DEBUG 01-14 20:42:24.038688.038688 lmp.py:1625]   Expert 48 |    136 | CPU
DEBUG 01-14 20:42:24.038093.038093 lmp.py:1625]   Expert 51 |    136 | CPU
DEBUG 01-14 20:42:24.038689.038689 lmp.py:1625]   Expert 36 |    137 | CPU
DEBUG 01-14 20:42:24.039855.039855 lmp.py:1625]   Expert 27 |    139 | CPU
DEBUG 01-14 20:42:24.039737.039737 lmp.py:1625]   Expert 60 |    139 | CPU
DEBUG 01-14 20:42:24.039903.039903 lmp.py:1625]   Expert 52 |    140 | CPU
DEBUG 01-14 20:42:24.039500.039500 lmp.py:1625]   Expert 20 |    141 | CPU
DEBUG 01-14 20:42:24.039904.039904 lmp.py:1625]   Expert 39 |    141 | CPU
DEBUG 01-14 20:42:24.039262.039262 lmp.py:1625]   Expert 43 |    141 | CPU
DEBUG 01-14 20:42:24.039428.039428 lmp.py:1625]   Expert 11 |    144 | CPU
DEBUG 01-14 20:42:24.039787.039787 lmp.py:1625]   Expert 35 |    151 | CPU
DEBUG 01-14 20:42:24.039191.039191 lmp.py:1625]   Expert 62 |    154 | CPU
DEBUG 01-14 20:42:24.039549.039549 lmp.py:1625]   Expert 56 |    159 | CPU
DEBUG 01-14 20:42:24.039954.039954 lmp.py:1625]   Expert 14 |    160 | CPU
DEBUG 01-14 20:42:24.039312.039312 lmp.py:1625]   Expert 45 |    160 | CPU
DEBUG 01-14 20:42:24.039478.039478 lmp.py:1625]   Expert  5 |    166 | GPU
DEBUG 01-14 20:42:24.039598.039598 lmp.py:1625]   Expert 10 |    172 | GPU
DEBUG 01-14 20:42:24.039764.039764 lmp.py:1625]   Expert 44 |    176 | GPU
DEBUG 01-14 20:42:24.039361.039361 lmp.py:1625]   Expert 55 |    176 | GPU
DEBUG 01-14 20:42:24.039766.039766 lmp.py:1625]   Expert 25 |    183 | GPU
DEBUG 01-14 20:42:24.039647.039647 lmp.py:1625]   Expert 57 |    183 | GPU
DEBUG 01-14 20:42:24.039575.039575 lmp.py:1625]   Expert 58 |    183 | GPU
DEBUG 01-14 20:42:24.039694.039694 lmp.py:1625]   Expert 31 |    187 | GPU
DEBUG 01-14 20:42:24.039861.039861 lmp.py:1625]   Expert 33 |    188 | GPU
DEBUG 01-14 20:42:24.039563.039563 lmp.py:1625]   Expert 32 |    190 | GPU
DEBUG 01-14 20:42:24.039730.039730 lmp.py:1625]   Expert  2 |    195 | GPU
DEBUG 01-14 20:42:24.039849.039849 lmp.py:1625]   Expert 53 |    197 | GPU
DEBUG 01-14 20:42:24.039016.039016 lmp.py:1625]   Expert 21 |    201 | GPU
DEBUG 01-14 20:42:24.039135.039135 lmp.py:1625]   Expert 17 |    203 | GPU
DEBUG 01-14 20:42:24.039302.039302 lmp.py:1625]   Expert 49 |    209 | GPU
DEBUG 01-14 20:42:24.039660.039660 lmp.py:1625]   Expert 59 |    218 | GPU
DEBUG 01-14 20:42:24.039826.039826 lmp.py:1625]   Expert 63 |    222 | GPU
DEBUG 01-14 20:42:24.039707.039707 lmp.py:1625]   Expert  0 |    226 | GPU
DEBUG 01-14 20:42:24.039635.039635 lmp.py:1625]   Expert 34 |    237 | GPU
DEBUG 01-14 20:42:24.039516.039516 lmp.py:1625]   Expert 37 |    244 | GPU
DEBUG 01-14 20:42:24.039444.039444 lmp.py:1625]   Expert 42 |    246 | GPU
DEBUG 01-14 20:42:24.039087.039087 lmp.py:1625]   Expert 22 |    255 | GPU
DEBUG 01-14 20:42:24.039015.039015 lmp.py:1625]   Expert 19 |    257 | GPU
DEBUG 01-14 20:42:24.039896.039896 lmp.py:1625]   Expert 24 |    275 | GPU
DEBUG 01-14 20:42:24.039824.039824 lmp.py:1625]   Expert 61 |    282 | GPU
DEBUG 01-14 20:42:24.039467.039467 lmp.py:1625]   Expert 30 |    317 | GPU
DEBUG 01-14 20:42:24.039156.039156 lmp.py:1625]   Expert 47 |    323 | GPU
DEBUG 01-14 20:42:24.039276.039276 lmp.py:1625]   Expert 38 |    378 | GPU
DEBUG 01-14 20:42:24.039204.039204 lmp.py:1625]   Expert 26 |    395 | GPU
DEBUG 01-14 20:42:24.039847.039847 lmp.py:1625]   Expert 12 |    407 | GPU
DEBUG 01-14 20:42:24.039774.039774 lmp.py:1625]   Expert 23 |    590 | GPU
DEBUG 01-14 20:42:24.039417.039417 lmp.py:1625]   Expert  9 |    691 | GPU
DEBUG 01-14 20:42:24.039060.039060 lmp.py:1626] 
DEBUG 01-14 20:42:24.039060.039060 lmp.py:1626]   CPU total tokens: 3916 (31.9%)
DEBUG 01-14 20:42:24.039134.039134 lmp.py:1627]   GPU total tokens: 8372 (68.1%)
DEBUG 01-14 20:42:24.039260.039260 cuda_h.py:19] end experts_map_get cost 0.0015976428985595703 seconds
DEBUG 01-14 20:42:24.039078.039078 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-14 20:42:24.039974.039974 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-14 20:42:24.040588.040588 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-14 20:42:24.040608.040608 cuda_h.py:19] end allocate_cuda_memory cost 0.0001933574676513672 seconds
DEBUG 01-14 20:42:24.040631.040631 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-14 20:42:24.040963.040963 sllm_store_c.py:27] get device uuid map
DEBUG 01-14 20:42:24.040011.040011 sllm_store_c.py:29] call client load into gpu
DEBUG 01-14 20:42:24.040999.040999 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 57653dde-b480-4b79-93d0-a7f8ba8767bb
DEBUG 01-14 20:42:24.040164.040164 client.py:106] call stub.LoadModelAsync
DEBUG 01-14 20:42:24.040718.040718 mlpmodule.py:1367]  experts func einsum cost 0.09093475341796875 s
INFO 01-14 20:42:24.051477.051477 client.py:127] Model loaded
DEBUG 01-14 20:42:24.051017.051017 cuda_h.py:10] start restore2model
DEBUG 01-14 20:42:24.053057.053057 cuda_h.py:19] end restore2model cost 0.0010476112365722656 seconds
DEBUG 01-14 20:42:24.053094.053094 cuda_h.py:19] end sllm_worker_task cost 0.02435302734375 seconds
INFO 01-14 20:42:24.053639.053639 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 57653dde-b480-4b79-93d0-a7f8ba8767bb
DEBUG 01-14 20:42:24.053804.053804 cuda_h.py:19] end load_into_gpu_async cost 0.013206005096435547 seconds
DEBUG 01-14 20:42:24.053058.053058 cuda_h.py:10] start restore_tensors2
DEBUG 01-14 20:42:24.054852.054852 cuda_h.py:19] end restore_tensors2 cost 0.0008876323699951172 seconds
DEBUG 01-14 20:42:24.054593.054593 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.014882802963256836 seconds
DEBUG 01-14 20:42:24.054344.054344 cuda_h.py:10] start restore2model
DEBUG 01-14 20:42:24.062029.062029 cuda_h.py:19] end restore2model cost 0.007522106170654297 seconds
DEBUG 01-14 20:42:24.062980.062980 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.022747039794921875 seconds
DEBUG 01-14 20:42:24.062564.062564 cuda_h.py:10] start gpu_sexperts
DEBUG 01-14 20:42:24.063924.063924 cuda_h.py:19] end gpu_sexperts cost 0.0004253387451171875 seconds
DEBUG 01-14 20:42:24.063827.063827 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-14 20:42:24.063557.063557 lmp.py:1683] 
DEBUG 01-14 20:42:24.063557.063557 lmp.py:1683]   Computing 32 experts on CPU...
DEBUG 01-14 20:42:24.063342.063342 cuda_h.py:19] end cpu_experts_submit cost 8.654594421386719e-05 seconds
DEBUG 01-14 20:42:24.063257.063257 cuda_h.py:10] start experts_func_mgpu_group_pad
DEBUG 01-14 20:42:24.076592.076592 mlpmodule.py:1460] group tensors cost 0.011827468872070312 s
DEBUG 01-14 20:42:24.077029.077029 cuda_h.py:10] start move_flat_hidden2cpu
DEBUG 01-14 20:42:24.080365.080365 cuda_h.py:19] end experts_func_mgpu_group_pad cost 0.016610383987426758 seconds
DEBUG 01-14 20:42:24.082796.082796 cuda_h.py:10] start gpu_group_list
DEBUG 01-14 20:42:24.083662.083662 cuda_h.py:19] end gpu_group_list cost 0.0006155967712402344 seconds
DEBUG 01-14 20:42:24.083703.083703 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-14 20:42:24.083077.083077 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.6226043701171875e-05 seconds
DEBUG 01-14 20:42:24.083807.083807 cuda_h.py:10] start wait_experts
INFO 01-14 20:42:24.083775.083775 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 57653dde-b480-4b79-93d0-a7f8ba8767bb
DEBUG 01-14 20:42:24.086825.086825 cuda_h.py:19] end move_flat_hidden2cpu cost 0.00897526741027832 seconds
DEBUG 01-14 20:42:24.090091.090091 mlpmodule.py:1533] pad cost 0.0037641525268554688 s
DEBUG 01-14 20:42:24.090580.090580 mlpmodule.py:1539] create cpu tensor cost 6.794929504394531e-05 s
DEBUG 01-14 20:42:24.092091.092091 mlpmodule.py:1544] move to cpu cost 0.001916646957397461 s
DEBUG 01-14 20:42:24.101722.101722 mlpmodule.py:1558] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-14 20:42:24.102330.102330 mlpmodule.py:1559] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-14 20:42:24.102989.102989 mlpmodule.py:1564] group_w3 first element: 0.01263427734375
WARNING 01-14 20:42:24.102193.102193 mlpmodule.py:1574] start einsum2
INFO 01-14 20:42:24.103689.103689 client.py:127] Model loaded
DEBUG 01-14 20:42:24.103577.103577 cuda_h.py:19] end wait_experts cost 0.019949913024902344 seconds
DEBUG 01-14 20:42:24.103718.103718 cuda_h.py:10] start gpu_experts
DEBUG 01-14 20:42:24.104099.104099 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-14 20:42:24.119724.119724 mlpmodule.py:1584] group einsum cost 0.026900529861450195 s
DEBUG 01-14 20:42:24.120841.120841 mlpmodule.py:1593] cpy2cputensor cost 0.00072479248046875 s
DEBUG 01-14 20:42:24.120816.120816 cuda_h.py:10] start move_outputs
DEBUG 01-14 20:42:24.122635.122635 cuda_h.py:19] end move_outputs cost 0.0018720626831054688 seconds
DEBUG 01-14 20:42:24.126717.126717 cuda_h.py:19] end wait_cetm_experts cost 0.021917343139648438 seconds
DEBUG 01-14 20:42:24.126081.126081 cuda_h.py:10] start gpu_group_einsum_mp_multi_list
DEBUG 01-14 20:42:24.126904.126904 cuda_h.py:10] start gpu_group_tensor
DEBUG 01-14 20:42:24.126192.126192 cuda_h.py:19] end gpu_group_tensor cost 0.0002493858337402344 seconds
DEBUG 01-14 20:42:24.126354.126354 cuda_h.py:10] start gpu_group_einsum
DEBUG 01-14 20:42:24.127385.127385 cuda_h.py:19] end gpu_group_einsum cost 0.0006692409515380859 seconds
DEBUG 01-14 20:42:24.127066.127066 cuda_h.py:10] start gpu_final_hidden_states_scatter
DEBUG 01-14 20:42:24.127207.127207 cuda_h.py:10] start all_expert_outputs_slices
DEBUG 01-14 20:42:24.128956.128956 cuda_h.py:19] end all_expert_outputs_slices cost 0.00037217140197753906 seconds
DEBUG 01-14 20:42:24.128143.128143 cuda_h.py:10] start concat_expert_out
DEBUG 01-14 20:42:24.128033.128033 cuda_h.py:19] end concat_expert_out cost 5.817413330078125e-05 seconds
DEBUG 01-14 20:42:24.128598.128598 cuda_h.py:10] start index_scatter
DEBUG 01-14 20:42:24.128549.128549 cuda_h.py:19] end index_scatter cost 7.081031799316406e-05 seconds
DEBUG 01-14 20:42:24.128677.128677 cuda_h.py:19] end gpu_final_hidden_states_scatter cost 0.0007860660552978516 seconds
DEBUG 01-14 20:42:24.128792.128792 cuda_h.py:19] end gpu_experts cost 0.024505615234375 seconds
DEBUG 01-14 20:42:24.128164.128164 cuda_h.py:10] start all_expert_weight_slices
DEBUG 01-14 20:42:24.129310.129310 cuda_h.py:19] end all_expert_weight_slices cost 0.00095367431640625 seconds
DEBUG 01-14 20:42:24.129516.129516 cuda_h.py:10] start cpuoutputsdeal
DEBUG 01-14 20:42:24.129332.129332 cuda_h.py:10] start index_scatter
DEBUG 01-14 20:42:24.130090.130090 cuda_h.py:19] end index_scatter cost 5.030632019042969e-05 seconds
DEBUG 01-14 20:42:24.130284.130284 cuda_h.py:19] end cpuoutputsdeal cost 0.0005362033843994141 seconds
DEBUG 01-14 20:42:24.130955.130955 cuda_h.py:19] end layer_moe_generate_mp_l_8 cost 0.09265875816345215 seconds
DEBUG 01-14 20:42:24.130802.130802 cuda_h.py:19] end prefill_layer cost 0.10199284553527832 seconds
DEBUG 01-14 20:42:24.130606.130606 lmp.py:1551] -------------------------------- end prefill layer 7 --------------------------------
DEBUG 01-14 20:42:24.130024.130024 cuda_h.py:10] start prefill_layer
DEBUG 01-14 20:42:24.130217.130217 lmp.py:1494] -------------------------------- start prefill layer 8 --------------------------------
DEBUG 01-14 20:42:24.130351.130351 cuda_h.py:10] start start_load_qkvogn_s_weight_l_9
DEBUG 01-14 20:42:24.130683.130683 cuda_h.py:10] start start_load_qkvogn_s_weight_l_9
DEBUG 01-14 20:42:24.130009.130009 cuda_h.py:19] end start_load_qkvogn_s_weight_l_9 cost 3.743171691894531e-05 seconds
DEBUG 01-14 20:42:24.130488.130488 cuda_h.py:19] end start_load_qkvogn_s_weight_l_9 cost 7.605552673339844e-05 seconds
DEBUG 01-14 20:42:24.130667.130667 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-14 20:42:24.130174.130174 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-14 20:42:24.131726.131726 cuda_h.py:10] start sllm_worker_task
DEBUG 01-14 20:42:24.131328.131328 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-14 20:42:24.131092.131092 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-14 20:42:24.136418.136418 cuda_h.py:19] end allocate_cuda_memory cost 0.005353689193725586 seconds
DEBUG 01-14 20:42:24.136541.136541 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-14 20:42:24.136542.136542 sllm_store_c.py:27] get device uuid map
DEBUG 01-14 20:42:24.136140.136140 sllm_store_c.py:29] call client load into gpu
DEBUG 01-14 20:42:24.136134.136134 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 1cccadb9-2525-4741-8507-e6ec22c0b0aa
DEBUG 01-14 20:42:24.137918.137918 client.py:106] call stub.LoadModelAsync
DEBUG 01-14 20:42:24.137113.137113 cuda_h.py:10] start self_attn
INFO 01-14 20:42:24.138554.138554 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 1cccadb9-2525-4741-8507-e6ec22c0b0aa
DEBUG 01-14 20:42:24.138205.138205 cuda_h.py:19] end load_into_gpu_async cost 0.0019981861114501953 seconds
DEBUG 01-14 20:42:24.138451.138451 cuda_h.py:10] start restore_tensors2
DEBUG 01-14 20:42:24.138872.138872 cuda_h.py:19] end restore_tensors2 cost 7.2479248046875e-05 seconds
DEBUG 01-14 20:42:24.139436.139436 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.00772404670715332 seconds
INFO 01-14 20:42:24.139411.139411 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 1cccadb9-2525-4741-8507-e6ec22c0b0aa
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-14 20:42:24.140877.140877 cuda_h.py:19] end self_attn cost 0.0029456615447998047 seconds
DEBUG 01-14 20:42:24.140636.140636 cuda_h.py:19] end iln_self_attn_paln cost 0.009705066680908203 seconds
DEBUG 01-14 20:42:24.140333.140333 cuda_h.py:10] start layer_moe_generate_mp_l_9
DEBUG 01-14 20:42:24.140904.140904 cuda_h.py:10] start gate
DEBUG 01-14 20:42:24.141536.141536 cuda_h.py:19] end gate cost 0.0006403923034667969 seconds
DEBUG 01-14 20:42:24.141888.141888 cuda_h.py:10] start experts_map_get
DEBUG 01-14 20:42:24.141687.141687 lmp.py:1615] 
DEBUG 01-14 20:42:24.141687.141687 lmp.py:1615] Expert Token Distribution & Device Allocation:
DEBUG 01-14 20:42:24.141443.141443 lmp.py:1616]   Total experts: 64
DEBUG 01-14 20:42:24.141616.141616 lmp.py:1617]   CPU experts: 32 (50%)
DEBUG 01-14 20:42:24.141689.141689 lmp.py:1618]   GPU experts: 32 (50%)
DEBUG 01-14 20:42:24.141855.141855 lmp.py:1619] 
DEBUG 01-14 20:42:24.141855.141855 lmp.py:1619]   Expert ID | Tokens | Device
DEBUG 01-14 20:42:24.141783.141783 lmp.py:1620]   -----------------------------------
DEBUG 01-14 20:42:24.141426.141426 lmp.py:1625]   Expert 38 |     20 | CPU
DEBUG 01-14 20:42:24.141354.141354 lmp.py:1625]   Expert 39 |     60 | CPU
DEBUG 01-14 20:42:24.141566.141566 lmp.py:1625]   Expert 30 |     68 | CPU
DEBUG 01-14 20:42:24.141779.141779 lmp.py:1625]   Expert 59 |     75 | CPU
DEBUG 01-14 20:42:24.141991.141991 lmp.py:1625]   Expert  7 |     79 | CPU
DEBUG 01-14 20:42:24.141965.141965 lmp.py:1625]   Expert 36 |     92 | CPU
DEBUG 01-14 20:42:24.141939.141939 lmp.py:1625]   Expert 24 |     94 | CPU
DEBUG 01-14 20:42:24.142913.142913 lmp.py:1625]   Expert 40 |     97 | CPU
DEBUG 01-14 20:42:24.142364.142364 lmp.py:1625]   Expert 17 |     99 | CPU
DEBUG 01-14 20:42:24.142815.142815 lmp.py:1625]   Expert 27 |     99 | CPU
DEBUG 01-14 20:42:24.142027.142027 lmp.py:1625]   Expert 14 |    102 | CPU
DEBUG 01-14 20:42:24.142478.142478 lmp.py:1625]   Expert 12 |    105 | CPU
DEBUG 01-14 20:42:24.142452.142452 lmp.py:1625]   Expert  1 |    107 | CPU
DEBUG 01-14 20:42:24.142426.142426 lmp.py:1625]   Expert 18 |    111 | CPU
DEBUG 01-14 20:42:24.142162.142162 lmp.py:1625]   Expert  6 |    112 | CPU
DEBUG 01-14 20:42:24.142898.142898 lmp.py:1625]   Expert 16 |    118 | CPU
DEBUG 01-14 20:42:24.142872.142872 lmp.py:1625]   Expert 48 |    122 | CPU
DEBUG 01-14 20:42:24.142945.142945 lmp.py:1625]   Expert 32 |    127 | CPU
DEBUG 01-14 20:42:24.142826.142826 lmp.py:1625]   Expert 51 |    145 | CPU
DEBUG 01-14 20:42:24.142039.142039 lmp.py:1625]   Expert 44 |    146 | CPU
DEBUG 01-14 20:42:24.142490.142490 lmp.py:1625]   Expert  0 |    147 | CPU
DEBUG 01-14 20:42:24.142987.142987 lmp.py:1625]   Expert 53 |    155 | CPU
DEBUG 01-14 20:42:24.142961.142961 lmp.py:1625]   Expert  8 |    162 | CPU
DEBUG 01-14 20:42:24.142458.142458 lmp.py:1625]   Expert 35 |    162 | CPU
DEBUG 01-14 20:42:24.142432.142432 lmp.py:1625]   Expert 22 |    164 | CPU
DEBUG 01-14 20:42:24.142744.142744 lmp.py:1625]   Expert 42 |    167 | CPU
DEBUG 01-14 20:42:24.142102.142102 lmp.py:1625]   Expert 60 |    171 | CPU
DEBUG 01-14 20:42:24.142414.142414 lmp.py:1625]   Expert 34 |    179 | CPU
DEBUG 01-14 20:42:24.142296.142296 lmp.py:1625]   Expert 33 |    186 | CPU
DEBUG 01-14 20:42:24.142131.142131 lmp.py:1625]   Expert 29 |    187 | CPU
DEBUG 01-14 20:42:24.142489.142489 lmp.py:1625]   Expert 45 |    188 | CPU
DEBUG 01-14 20:42:24.142324.142324 lmp.py:1625]   Expert 19 |    192 | CPU
DEBUG 01-14 20:42:24.142444.142444 lmp.py:1625]   Expert 54 |    192 | GPU
DEBUG 01-14 20:42:24.142325.142325 lmp.py:1625]   Expert 47 |    194 | GPU
DEBUG 01-14 20:42:24.142968.142968 lmp.py:1625]   Expert 15 |    195 | GPU
DEBUG 01-14 20:42:24.142611.142611 lmp.py:1625]   Expert 49 |    195 | GPU
DEBUG 01-14 20:42:24.142493.142493 lmp.py:1625]   Expert 28 |    202 | GPU
DEBUG 01-14 20:42:24.142897.142897 lmp.py:1625]   Expert 56 |    202 | GPU
DEBUG 01-14 20:42:24.142063.142063 lmp.py:1625]   Expert  9 |    205 | GPU
DEBUG 01-14 20:42:24.142706.142706 lmp.py:1625]   Expert 21 |    205 | GPU
DEBUG 01-14 20:42:24.142349.142349 lmp.py:1625]   Expert 13 |    208 | GPU
DEBUG 01-14 20:42:24.142992.142992 lmp.py:1625]   Expert  3 |    209 | GPU
DEBUG 01-14 20:42:24.142351.142351 lmp.py:1625]   Expert 10 |    210 | GPU
DEBUG 01-14 20:42:24.142994.142994 lmp.py:1625]   Expert 20 |    212 | GPU
DEBUG 01-14 20:42:24.142636.142636 lmp.py:1625]   Expert 46 |    216 | GPU
DEBUG 01-14 20:42:24.142279.142279 lmp.py:1625]   Expert  4 |    218 | GPU
DEBUG 01-14 20:42:24.142684.142684 lmp.py:1625]   Expert 57 |    218 | GPU
DEBUG 01-14 20:42:24.142042.142042 lmp.py:1625]   Expert 41 |    219 | GPU
DEBUG 01-14 20:42:24.142877.142877 lmp.py:1625]   Expert 43 |    220 | GPU
DEBUG 01-14 20:42:24.142759.142759 lmp.py:1625]   Expert 63 |    228 | GPU
DEBUG 01-14 20:42:24.142402.142402 lmp.py:1625]   Expert  2 |    231 | GPU
DEBUG 01-14 20:42:24.142806.142806 lmp.py:1625]   Expert 37 |    237 | GPU
DEBUG 01-14 20:42:24.142926.142926 lmp.py:1625]   Expert 50 |    251 | GPU
DEBUG 01-14 20:42:24.142807.142807 lmp.py:1625]   Expert 26 |    262 | GPU
DEBUG 01-14 20:42:24.142450.142450 lmp.py:1625]   Expert 61 |    268 | GPU
DEBUG 01-14 20:42:24.142332.142332 lmp.py:1625]   Expert 31 |    277 | GPU
DEBUG 01-14 20:42:24.142975.142975 lmp.py:1625]   Expert 58 |    282 | GPU
DEBUG 01-14 20:42:24.142856.142856 lmp.py:1625]   Expert 52 |    305 | GPU
DEBUG 01-14 20:42:24.142499.142499 lmp.py:1625]   Expert 62 |    310 | GPU
DEBUG 01-14 20:42:24.142381.142381 lmp.py:1625]   Expert 55 |    341 | GPU
DEBUG 01-14 20:42:24.142262.142262 lmp.py:1625]   Expert 11 |    377 | GPU
DEBUG 01-14 20:42:24.142905.142905 lmp.py:1625]   Expert 23 |    411 | GPU
DEBUG 01-14 20:42:24.142309.142309 lmp.py:1625]   Expert 25 |    432 | GPU
DEBUG 01-14 20:42:24.142714.142714 lmp.py:1625]   Expert  5 |    518 | GPU
DEBUG 01-14 20:42:24.142311.142311 lmp.py:1626] 
DEBUG 01-14 20:42:24.142311.142311 lmp.py:1626]   CPU total tokens: 4038 (32.9%)
DEBUG 01-14 20:42:24.143907.143907 lmp.py:1627]   GPU total tokens: 8250 (67.1%)
DEBUG 01-14 20:42:24.143796.143796 cuda_h.py:19] end experts_map_get cost 0.0015532970428466797 seconds
DEBUG 01-14 20:42:24.143984.143984 mlpmodule.py:1367]  experts func einsum cost 0.0789937973022461 s
DEBUG 01-14 20:42:24.143412.143412 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-14 20:42:24.143133.143133 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-14 20:42:24.143899.143899 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-14 20:42:24.144165.144165 cuda_h.py:19] end allocate_cuda_memory cost 0.0011782646179199219 seconds
DEBUG 01-14 20:42:24.144605.144605 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-14 20:42:24.144792.144792 sllm_store_c.py:27] get device uuid map
DEBUG 01-14 20:42:24.144170.144170 sllm_store_c.py:29] call client load into gpu
DEBUG 01-14 20:42:24.144058.144058 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, ec3057f1-9917-41e1-851b-dc6386e0c88b
DEBUG 01-14 20:42:24.145071.145071 client.py:106] call stub.LoadModelAsync
INFO 01-14 20:42:24.146520.146520 client.py:127] Model loaded
DEBUG 01-14 20:42:24.146120.146120 cuda_h.py:10] start restore2model
DEBUG 01-14 20:42:24.147570.147570 cuda_h.py:19] end restore2model cost 0.0007121562957763672 seconds
DEBUG 01-14 20:42:24.147207.147207 cuda_h.py:19] end sllm_worker_task cost 0.016388654708862305 seconds
INFO 01-14 20:42:24.148666.148666 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, ec3057f1-9917-41e1-851b-dc6386e0c88b
DEBUG 01-14 20:42:24.148324.148324 cuda_h.py:19] end load_into_gpu_async cost 0.0032334327697753906 seconds
DEBUG 01-14 20:42:24.148742.148742 cuda_h.py:10] start restore_tensors2
DEBUG 01-14 20:42:24.148412.148412 cuda_h.py:19] end restore_tensors2 cost 0.00039505958557128906 seconds
DEBUG 01-14 20:42:24.148586.148586 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.005186319351196289 seconds
DEBUG 01-14 20:42:24.148494.148494 cuda_h.py:10] start restore2model
DEBUG 01-14 20:42:24.151138.151138 cuda_h.py:19] end restore2model cost 0.002588510513305664 seconds
DEBUG 01-14 20:42:24.151167.151167 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.007965564727783203 seconds
DEBUG 01-14 20:42:24.151459.151459 cuda_h.py:10] start gpu_sexperts
DEBUG 01-14 20:42:24.151033.151033 cuda_h.py:19] end gpu_sexperts cost 0.00028324127197265625 seconds
DEBUG 01-14 20:42:24.151670.151670 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-14 20:42:24.151996.151996 lmp.py:1683] 
DEBUG 01-14 20:42:24.151996.151996 lmp.py:1683]   Computing 32 experts on CPU...
DEBUG 01-14 20:42:24.151932.151932 cuda_h.py:19] end cpu_experts_submit cost 5.817413330078125e-05 seconds
DEBUG 01-14 20:42:24.151303.151303 cuda_h.py:10] start experts_func_mgpu_group_pad
DEBUG 01-14 20:42:24.161878.161878 mlpmodule.py:1460] group tensors cost 0.009081363677978516 s
DEBUG 01-14 20:42:24.162848.162848 cuda_h.py:10] start move_flat_hidden2cpu
DEBUG 01-14 20:42:24.164966.164966 cuda_h.py:19] end experts_func_mgpu_group_pad cost 0.012612581253051758 seconds
DEBUG 01-14 20:42:24.166055.166055 cuda_h.py:10] start gpu_group_list
DEBUG 01-14 20:42:24.167078.167078 cuda_h.py:19] end gpu_group_list cost 0.0005524158477783203 seconds
DEBUG 01-14 20:42:24.167688.167688 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-14 20:42:24.167003.167003 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.2649765014648438e-05 seconds
DEBUG 01-14 20:42:24.167441.167441 cuda_h.py:10] start wait_experts
INFO 01-14 20:42:24.167734.167734 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, ec3057f1-9917-41e1-851b-dc6386e0c88b
DEBUG 01-14 20:42:24.168733.168733 cuda_h.py:19] end move_flat_hidden2cpu cost 0.006582021713256836 seconds
DEBUG 01-14 20:42:24.170854.170854 mlpmodule.py:1533] pad cost 0.0015316009521484375 s
DEBUG 01-14 20:42:24.170348.170348 mlpmodule.py:1539] create cpu tensor cost 5.245208740234375e-05 s
DEBUG 01-14 20:42:24.172332.172332 mlpmodule.py:1544] move to cpu cost 0.0022706985473632812 s
DEBUG 01-14 20:42:24.183028.183028 mlpmodule.py:1558] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-14 20:42:24.183901.183901 mlpmodule.py:1559] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-14 20:42:24.183155.183155 mlpmodule.py:1564] group_w3 first element: 0.0859375
WARNING 01-14 20:42:24.183689.183689 mlpmodule.py:1574] start einsum2
INFO 01-14 20:42:24.201363.201363 client.py:127] Model loaded
DEBUG 01-14 20:42:24.202125.202125 mlpmodule.py:1584] group einsum cost 0.029337644577026367 s
DEBUG 01-14 20:42:24.202284.202284 cuda_h.py:19] end wait_experts cost 0.03478646278381348 seconds
DEBUG 01-14 20:42:24.202845.202845 cuda_h.py:10] start gpu_experts
DEBUG 01-14 20:42:24.203361.203361 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-14 20:42:24.203331.203331 mlpmodule.py:1593] cpy2cputensor cost 0.0009081363677978516 s
DEBUG 01-14 20:42:24.203942.203942 cuda_h.py:10] start move_outputs
DEBUG 01-14 20:42:24.205700.205700 cuda_h.py:19] end move_outputs cost 0.0022079944610595703 seconds
DEBUG 01-14 20:42:24.209146.209146 cuda_h.py:19] end wait_cetm_experts cost 0.005957603454589844 seconds
DEBUG 01-14 20:42:24.209721.209721 cuda_h.py:10] start gpu_group_einsum_mp_multi_list
DEBUG 01-14 20:42:24.209743.209743 cuda_h.py:10] start gpu_group_tensor
DEBUG 01-14 20:42:24.209590.209590 cuda_h.py:19] end gpu_group_tensor cost 0.00031256675720214844 seconds
DEBUG 01-14 20:42:24.210636.210636 cuda_h.py:10] start gpu_group_einsum
DEBUG 01-14 20:42:24.210471.210471 cuda_h.py:19] end gpu_group_einsum cost 0.0007176399230957031 seconds
DEBUG 01-14 20:42:24.211319.211319 cuda_h.py:10] start gpu_final_hidden_states_scatter
DEBUG 01-14 20:42:24.211156.211156 cuda_h.py:10] start all_expert_outputs_slices
DEBUG 01-14 20:42:24.211364.211364 cuda_h.py:19] end all_expert_outputs_slices cost 0.0003662109375 seconds
DEBUG 01-14 20:42:24.211254.211254 cuda_h.py:10] start concat_expert_out
DEBUG 01-14 20:42:24.211171.211171 cuda_h.py:19] end concat_expert_out cost 6.651878356933594e-05 seconds
DEBUG 01-14 20:42:24.211911.211911 cuda_h.py:10] start index_scatter
DEBUG 01-14 20:42:24.212380.212380 cuda_h.py:19] end index_scatter cost 0.00011920928955078125 seconds
DEBUG 01-14 20:42:24.212402.212402 cuda_h.py:19] end gpu_final_hidden_states_scatter cost 0.001008749008178711 seconds
DEBUG 01-14 20:42:24.212955.212955 cuda_h.py:19] end gpu_experts cost 0.009061813354492188 seconds
DEBUG 01-14 20:42:24.212202.212202 cuda_h.py:10] start all_expert_weight_slices
DEBUG 01-14 20:42:24.213696.213696 cuda_h.py:19] end all_expert_weight_slices cost 0.0010056495666503906 seconds
DEBUG 01-14 20:42:24.213857.213857 cuda_h.py:10] start cpuoutputsdeal
DEBUG 01-14 20:42:24.214862.214862 cuda_h.py:10] start index_scatter
DEBUG 01-14 20:42:24.214860.214860 cuda_h.py:19] end index_scatter cost 5.7220458984375e-05 seconds
DEBUG 01-14 20:42:24.214935.214935 cuda_h.py:19] end cpuoutputsdeal cost 0.0006814002990722656 seconds
DEBUG 01-14 20:42:24.214886.214886 cuda_h.py:19] end layer_moe_generate_mp_l_9 cost 0.0736541748046875 seconds
DEBUG 01-14 20:42:24.214948.214948 cuda_h.py:19] end prefill_layer cost 0.08413529396057129 seconds
DEBUG 01-14 20:42:24.214839.214839 lmp.py:1551] -------------------------------- end prefill layer 8 --------------------------------
DEBUG 01-14 20:42:24.214032.214032 cuda_h.py:10] start prefill_layer
DEBUG 01-14 20:42:24.215596.215596 lmp.py:1494] -------------------------------- start prefill layer 9 --------------------------------
DEBUG 01-14 20:42:24.215014.215014 cuda_h.py:10] start start_load_qkvogn_s_weight_l_10
DEBUG 01-14 20:42:24.215009.215009 cuda_h.py:10] start start_load_qkvogn_s_weight_l_10
DEBUG 01-14 20:42:24.215331.215331 cuda_h.py:19] end start_load_qkvogn_s_weight_l_10 cost 0.00010371208190917969 seconds
DEBUG 01-14 20:42:24.215869.215869 cuda_h.py:10] start sllm_worker_task
DEBUG 01-14 20:42:24.215601.215601 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-14 20:42:24.215762.215762 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-14 20:42:24.215302.215302 cuda_h.py:19] end start_load_qkvogn_s_weight_l_10 cost 0.00022459030151367188 seconds
DEBUG 01-14 20:42:24.221204.221204 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-14 20:42:24.221320.221320 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-14 20:42:24.221528.221528 cuda_h.py:19] end allocate_cuda_memory cost 0.006033897399902344 seconds
DEBUG 01-14 20:42:24.221995.221995 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-14 20:42:24.221950.221950 sllm_store_c.py:27] get device uuid map
DEBUG 01-14 20:42:24.221826.221826 sllm_store_c.py:29] call client load into gpu
DEBUG 01-14 20:42:24.221436.221436 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 4c5d43d4-d010-404f-867a-bc0b3dd46db8
DEBUG 01-14 20:42:24.221883.221883 client.py:106] call stub.LoadModelAsync
DEBUG 01-14 20:42:24.222854.222854 cuda_h.py:10] start self_attn
INFO 01-14 20:42:24.223019.223019 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 4c5d43d4-d010-404f-867a-bc0b3dd46db8
DEBUG 01-14 20:42:24.223346.223346 cuda_h.py:19] end load_into_gpu_async cost 0.0017316341400146484 seconds
DEBUG 01-14 20:42:24.223877.223877 cuda_h.py:10] start restore_tensors2
DEBUG 01-14 20:42:24.223576.223576 cuda_h.py:19] end restore_tensors2 cost 6.747245788574219e-05 seconds
DEBUG 01-14 20:42:24.223616.223616 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.008130788803100586 seconds
INFO 01-14 20:42:24.223784.223784 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 4c5d43d4-d010-404f-867a-bc0b3dd46db8
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-14 20:42:24.225417.225417 cuda_h.py:19] end self_attn cost 0.0029137134552001953 seconds
DEBUG 01-14 20:42:24.225593.225593 cuda_h.py:19] end iln_self_attn_paln cost 0.004065990447998047 seconds
DEBUG 01-14 20:42:24.225621.225621 cuda_h.py:10] start layer_moe_generate_mp_l_10
DEBUG 01-14 20:42:24.225954.225954 cuda_h.py:10] start gate
DEBUG 01-14 20:42:24.226963.226963 cuda_h.py:19] end gate cost 0.0006356239318847656 seconds
DEBUG 01-14 20:42:24.226124.226124 cuda_h.py:10] start experts_map_get
DEBUG 01-14 20:42:24.226968.226968 lmp.py:1615] 
DEBUG 01-14 20:42:24.226968.226968 lmp.py:1615] Expert Token Distribution & Device Allocation:
DEBUG 01-14 20:42:24.226546.226546 lmp.py:1616]   Total experts: 64
DEBUG 01-14 20:42:24.226957.226957 lmp.py:1617]   CPU experts: 32 (50%)
DEBUG 01-14 20:42:24.226792.226792 lmp.py:1618]   GPU experts: 32 (50%)
DEBUG 01-14 20:42:24.226720.226720 lmp.py:1619] 
DEBUG 01-14 20:42:24.226720.226720 lmp.py:1619]   Expert ID | Tokens | Device
DEBUG 01-14 20:42:24.226648.226648 lmp.py:1620]   -----------------------------------
DEBUG 01-14 20:42:24.226960.226960 lmp.py:1625]   Expert 24 |     41 | CPU
DEBUG 01-14 20:42:24.226603.226603 lmp.py:1625]   Expert  2 |     42 | CPU
DEBUG 01-14 20:42:24.226530.226530 lmp.py:1625]   Expert 26 |     68 | CPU
DEBUG 01-14 20:42:24.226696.226696 lmp.py:1625]   Expert 19 |     69 | CPU
DEBUG 01-14 20:42:24.226624.226624 lmp.py:1625]   Expert 32 |     71 | CPU
DEBUG 01-14 20:42:24.226075.226075 lmp.py:1625]   Expert  4 |     75 | CPU
DEBUG 01-14 20:42:24.226287.226287 lmp.py:1625]   Expert 50 |     78 | CPU
DEBUG 01-14 20:42:24.226262.226262 lmp.py:1625]   Expert 23 |     80 | CPU
DEBUG 01-14 20:42:24.226236.226236 lmp.py:1625]   Expert 59 |     81 | CPU
DEBUG 01-14 20:42:24.226263.226263 lmp.py:1625]   Expert 60 |     84 | CPU
DEBUG 01-14 20:42:24.226667.226667 lmp.py:1625]   Expert 28 |     89 | CPU
DEBUG 01-14 20:42:24.226880.226880 lmp.py:1625]   Expert  7 |    100 | CPU
DEBUG 01-14 20:42:24.226092.226092 lmp.py:1625]   Expert 15 |    103 | CPU
DEBUG 01-14 20:42:24.226020.226020 lmp.py:1625]   Expert 49 |    103 | CPU
DEBUG 01-14 20:42:24.226617.226617 lmp.py:1625]   Expert 27 |    105 | CPU
DEBUG 01-14 20:42:24.226260.226260 lmp.py:1625]   Expert 10 |    113 | CPU
DEBUG 01-14 20:42:24.226903.226903 lmp.py:1625]   Expert 12 |    114 | CPU
DEBUG 01-14 20:42:24.226069.226069 lmp.py:1625]   Expert  3 |    126 | CPU
DEBUG 01-14 20:42:24.226235.226235 lmp.py:1625]   Expert  5 |    128 | CPU
DEBUG 01-14 20:42:24.226163.226163 lmp.py:1625]   Expert 20 |    130 | CPU
DEBUG 01-14 20:42:24.226090.226090 lmp.py:1625]   Expert 13 |    132 | CPU
DEBUG 01-14 20:42:24.227018.227018 lmp.py:1625]   Expert 41 |    134 | CPU
DEBUG 01-14 20:42:24.227707.227707 lmp.py:1625]   Expert 25 |    135 | CPU
DEBUG 01-14 20:42:24.227112.227112 lmp.py:1625]   Expert 35 |    142 | CPU
DEBUG 01-14 20:42:24.227040.227040 lmp.py:1625]   Expert 37 |    143 | CPU
DEBUG 01-14 20:42:24.227729.227729 lmp.py:1625]   Expert 40 |    144 | CPU
DEBUG 01-14 20:42:24.227895.227895 lmp.py:1625]   Expert 22 |    159 | CPU
DEBUG 01-14 20:42:24.227538.227538 lmp.py:1625]   Expert 17 |    160 | CPU
DEBUG 01-14 20:42:24.227181.227181 lmp.py:1625]   Expert 47 |    162 | CPU
DEBUG 01-14 20:42:24.227585.227585 lmp.py:1625]   Expert 36 |    166 | CPU
DEBUG 01-14 20:42:24.227990.227990 lmp.py:1625]   Expert 53 |    168 | CPU
DEBUG 01-14 20:42:24.227918.227918 lmp.py:1625]   Expert 16 |    173 | CPU
DEBUG 01-14 20:42:24.227845.227845 lmp.py:1625]   Expert 58 |    178 | GPU
DEBUG 01-14 20:42:24.227012.227012 lmp.py:1625]   Expert 44 |    179 | GPU
DEBUG 01-14 20:42:24.227178.227178 lmp.py:1625]   Expert 52 |    180 | GPU
DEBUG 01-14 20:42:24.227105.227105 lmp.py:1625]   Expert 39 |    186 | GPU
DEBUG 01-14 20:42:24.227033.227033 lmp.py:1625]   Expert 18 |    187 | GPU
DEBUG 01-14 20:42:24.227199.227199 lmp.py:1625]   Expert 48 |    196 | GPU
DEBUG 01-14 20:42:24.227889.227889 lmp.py:1625]   Expert 30 |    199 | GPU
DEBUG 01-14 20:42:24.227055.227055 lmp.py:1625]   Expert 38 |    201 | GPU
DEBUG 01-14 20:42:24.227698.227698 lmp.py:1625]   Expert 45 |    207 | GPU
DEBUG 01-14 20:42:24.227102.227102 lmp.py:1625]   Expert 11 |    208 | GPU
DEBUG 01-14 20:42:24.227507.227507 lmp.py:1625]   Expert 62 |    213 | GPU
DEBUG 01-14 20:42:24.227388.227388 lmp.py:1625]   Expert  1 |    217 | GPU
DEBUG 01-14 20:42:24.227078.227078 lmp.py:1625]   Expert 29 |    218 | GPU
DEBUG 01-14 20:42:24.227244.227244 lmp.py:1625]   Expert 51 |    223 | GPU
DEBUG 01-14 20:42:24.227171.227171 lmp.py:1625]   Expert 14 |    238 | GPU
DEBUG 01-14 20:42:24.227861.227861 lmp.py:1625]   Expert 31 |    246 | GPU
DEBUG 01-14 20:42:24.227788.227788 lmp.py:1625]   Expert 34 |    256 | GPU
DEBUG 01-14 20:42:24.227716.227716 lmp.py:1625]   Expert  6 |    266 | GPU
DEBUG 01-14 20:42:24.227644.227644 lmp.py:1625]   Expert 43 |    271 | GPU
DEBUG 01-14 20:42:24.227095.227095 lmp.py:1625]   Expert 61 |    275 | GPU
DEBUG 01-14 20:42:24.227022.227022 lmp.py:1625]   Expert 42 |    289 | GPU
DEBUG 01-14 20:42:24.227904.227904 lmp.py:1625]   Expert 33 |    293 | GPU
DEBUG 01-14 20:42:24.227308.227308 lmp.py:1625]   Expert  0 |    295 | GPU
DEBUG 01-14 20:42:24.227289.227289 lmp.py:1625]   Expert 56 |    300 | GPU
DEBUG 01-14 20:42:24.227409.227409 lmp.py:1625]   Expert 57 |    310 | GPU
DEBUG 01-14 20:42:24.227814.227814 lmp.py:1625]   Expert 46 |    319 | GPU
DEBUG 01-14 20:42:24.227741.227741 lmp.py:1625]   Expert 54 |    366 | GPU
DEBUG 01-14 20:42:24.227431.227431 lmp.py:1625]   Expert  9 |    397 | GPU
DEBUG 01-14 20:42:24.227120.227120 lmp.py:1625]   Expert 63 |    409 | GPU
DEBUG 01-14 20:42:24.227048.227048 lmp.py:1625]   Expert  8 |    423 | GPU
DEBUG 01-14 20:42:24.227975.227975 lmp.py:1625]   Expert 55 |    460 | GPU
DEBUG 01-14 20:42:24.227903.227903 lmp.py:1625]   Expert 21 |    465 | GPU
DEBUG 01-14 20:42:24.227546.227546 lmp.py:1626] 
DEBUG 01-14 20:42:24.227546.227546 lmp.py:1626]   CPU total tokens: 3618 (29.4%)
DEBUG 01-14 20:42:24.227666.227666 lmp.py:1627]   GPU total tokens: 8670 (70.6%)
DEBUG 01-14 20:42:24.227792.227792 cuda_h.py:19] end experts_map_get cost 0.0015523433685302734 seconds
DEBUG 01-14 20:42:24.227266.227266 mlpmodule.py:1367]  experts func einsum cost 0.07567954063415527 s
DEBUG 01-14 20:42:24.228138.228138 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-14 20:42:24.228660.228660 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-14 20:42:24.228711.228711 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-14 20:42:24.229953.229953 cuda_h.py:19] end allocate_cuda_memory cost 0.0012667179107666016 seconds
DEBUG 01-14 20:42:24.229771.229771 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-14 20:42:24.229149.229149 sllm_store_c.py:27] get device uuid map
DEBUG 01-14 20:42:24.229449.229449 sllm_store_c.py:29] call client load into gpu
DEBUG 01-14 20:42:24.229575.229575 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, f29d3be6-585c-422c-b4d2-f664bf4acbad
DEBUG 01-14 20:42:24.230370.230370 client.py:106] call stub.LoadModelAsync
INFO 01-14 20:42:24.231865.231865 client.py:127] Model loaded
DEBUG 01-14 20:42:24.231218.231218 cuda_h.py:10] start restore2model
DEBUG 01-14 20:42:24.231038.231038 cuda_h.py:19] end restore2model cost 0.0003275871276855469 seconds
DEBUG 01-14 20:42:24.231662.231662 cuda_h.py:19] end sllm_worker_task cost 0.01644420623779297 seconds
INFO 01-14 20:42:24.232217.232217 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, f29d3be6-585c-422c-b4d2-f664bf4acbad
DEBUG 01-14 20:42:24.233043.233043 cuda_h.py:19] end load_into_gpu_async cost 0.0033445358276367188 seconds
DEBUG 01-14 20:42:24.233443.233443 cuda_h.py:10] start restore_tensors2
DEBUG 01-14 20:42:24.233846.233846 cuda_h.py:19] end restore_tensors2 cost 0.0004756450653076172 seconds
DEBUG 01-14 20:42:24.233066.233066 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.005571842193603516 seconds
DEBUG 01-14 20:42:24.233259.233259 cuda_h.py:10] start restore2model
DEBUG 01-14 20:42:24.236755.236755 cuda_h.py:19] end restore2model cost 0.0025146007537841797 seconds
DEBUG 01-14 20:42:24.236989.236989 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.008284330368041992 seconds
DEBUG 01-14 20:42:24.236043.236043 cuda_h.py:10] start gpu_sexperts
DEBUG 01-14 20:42:24.236603.236603 cuda_h.py:19] end gpu_sexperts cost 0.0002770423889160156 seconds
DEBUG 01-14 20:42:24.236996.236996 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-14 20:42:24.236414.236414 lmp.py:1683] 
DEBUG 01-14 20:42:24.236414.236414 lmp.py:1683]   Computing 32 experts on CPU...
DEBUG 01-14 20:42:24.236396.236396 cuda_h.py:19] end cpu_experts_submit cost 5.745887756347656e-05 seconds
DEBUG 01-14 20:42:24.236006.236006 cuda_h.py:10] start experts_func_mgpu_group_pad
DEBUG 01-14 20:42:24.245867.245867 mlpmodule.py:1460] group tensors cost 0.008034467697143555 s
DEBUG 01-14 20:42:24.246661.246661 cuda_h.py:10] start move_flat_hidden2cpu
DEBUG 01-14 20:42:24.252639.252639 cuda_h.py:19] end experts_func_mgpu_group_pad cost 0.015453100204467773 seconds
DEBUG 01-14 20:42:24.253332.253332 cuda_h.py:19] end move_flat_hidden2cpu cost 0.00668787956237793 seconds
DEBUG 01-14 20:42:24.255260.255260 cuda_h.py:10] start gpu_group_list
DEBUG 01-14 20:42:24.256309.256309 cuda_h.py:19] end gpu_group_list cost 0.0006866455078125 seconds
DEBUG 01-14 20:42:24.256935.256935 mlpmodule.py:1533] pad cost 0.003622293472290039 s
DEBUG 01-14 20:42:24.257531.257531 mlpmodule.py:1539] create cpu tensor cost 6.198883056640625e-05 s
DEBUG 01-14 20:42:24.257918.257918 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-14 20:42:24.257215.257215 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 3.314018249511719e-05 seconds
DEBUG 01-14 20:42:24.257521.257521 cuda_h.py:10] start wait_experts
INFO 01-14 20:42:24.257967.257967 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, f29d3be6-585c-422c-b4d2-f664bf4acbad
DEBUG 01-14 20:42:24.259184.259184 mlpmodule.py:1544] move to cpu cost 0.002046346664428711 s
DEBUG 01-14 20:42:24.268966.268966 mlpmodule.py:1558] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-14 20:42:24.268408.268408 mlpmodule.py:1559] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-14 20:42:24.268398.268398 mlpmodule.py:1564] group_w3 first element: 0.0157470703125
WARNING 01-14 20:42:24.268568.268568 mlpmodule.py:1574] start einsum2
INFO 01-14 20:42:24.286989.286989 client.py:127] Model loaded
DEBUG 01-14 20:42:24.286895.286895 cuda_h.py:19] end wait_experts cost 0.0288999080657959 seconds
DEBUG 01-14 20:42:24.286373.286373 cuda_h.py:10] start gpu_experts
DEBUG 01-14 20:42:24.286481.286481 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-14 20:42:24.286382.286382 mlpmodule.py:1584] group einsum cost 0.02756810188293457 s
DEBUG 01-14 20:42:24.287909.287909 mlpmodule.py:1593] cpy2cputensor cost 0.0007295608520507812 s
DEBUG 01-14 20:42:24.287686.287686 cuda_h.py:10] start move_outputs
DEBUG 01-14 20:42:24.290465.290465 cuda_h.py:19] end move_outputs cost 0.002089262008666992 seconds
DEBUG 01-14 20:42:24.293474.293474 cuda_h.py:19] end wait_cetm_experts cost 0.007063627243041992 seconds
DEBUG 01-14 20:42:24.293393.293393 cuda_h.py:10] start gpu_group_einsum_mp_multi_list
DEBUG 01-14 20:42:24.293971.293971 cuda_h.py:10] start gpu_group_tensor
DEBUG 01-14 20:42:24.294013.294013 cuda_h.py:19] end gpu_group_tensor cost 0.00024390220642089844 seconds
DEBUG 01-14 20:42:24.294553.294553 cuda_h.py:10] start gpu_group_einsum
DEBUG 01-14 20:42:24.294459.294459 cuda_h.py:19] end gpu_group_einsum cost 0.0006873607635498047 seconds
DEBUG 01-14 20:42:24.295225.295225 cuda_h.py:10] start gpu_final_hidden_states_scatter
DEBUG 01-14 20:42:24.295221.295221 cuda_h.py:10] start all_expert_outputs_slices
DEBUG 01-14 20:42:24.295056.295056 cuda_h.py:19] end all_expert_outputs_slices cost 0.0003674030303955078 seconds
DEBUG 01-14 20:42:24.295573.295573 cuda_h.py:10] start concat_expert_out
DEBUG 01-14 20:42:24.295556.295556 cuda_h.py:19] end concat_expert_out cost 5.602836608886719e-05 seconds
DEBUG 01-14 20:42:24.295168.295168 cuda_h.py:10] start index_scatter
DEBUG 01-14 20:42:24.295648.295648 cuda_h.py:19] end index_scatter cost 7.390975952148438e-05 seconds
DEBUG 01-14 20:42:24.295411.295411 cuda_h.py:19] end gpu_final_hidden_states_scatter cost 0.0007548332214355469 seconds
DEBUG 01-14 20:42:24.295513.295513 cuda_h.py:19] end gpu_experts cost 0.00948476791381836 seconds
DEBUG 01-14 20:42:24.296408.296408 cuda_h.py:10] start all_expert_weight_slices
DEBUG 01-14 20:42:24.297290.297290 cuda_h.py:19] end all_expert_weight_slices cost 0.0009963512420654297 seconds
DEBUG 01-14 20:42:24.297411.297411 cuda_h.py:10] start cpuoutputsdeal
DEBUG 01-14 20:42:24.297035.297035 cuda_h.py:10] start index_scatter
DEBUG 01-14 20:42:24.297117.297117 cuda_h.py:19] end index_scatter cost 4.887580871582031e-05 seconds
DEBUG 01-14 20:42:24.297834.297834 cuda_h.py:19] end cpuoutputsdeal cost 0.0005271434783935547 seconds
DEBUG 01-14 20:42:24.297075.297075 cuda_h.py:19] end layer_moe_generate_mp_l_10 cost 0.07224845886230469 seconds
DEBUG 01-14 20:42:24.298452.298452 cuda_h.py:19] end prefill_layer cost 0.08310675621032715 seconds
DEBUG 01-14 20:42:24.298334.298334 lmp.py:1551] -------------------------------- end prefill layer 9 --------------------------------
DEBUG 01-14 20:42:24.298382.298382 cuda_h.py:10] start prefill_layer
DEBUG 01-14 20:42:24.298615.298615 lmp.py:1494] -------------------------------- start prefill layer 10 --------------------------------
DEBUG 01-14 20:42:24.298510.298510 cuda_h.py:10] start start_load_qkvogn_s_weight_l_11
DEBUG 01-14 20:42:24.298312.298312 cuda_h.py:10] start start_load_qkvogn_s_weight_l_11
DEBUG 01-14 20:42:24.298063.298063 cuda_h.py:19] end start_load_qkvogn_s_weight_l_11 cost 3.409385681152344e-05 seconds
DEBUG 01-14 20:42:24.298534.298534 cuda_h.py:19] end start_load_qkvogn_s_weight_l_11 cost 6.747245788574219e-05 seconds
DEBUG 01-14 20:42:24.298137.298137 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-14 20:42:24.298610.298610 cuda_h.py:10] start sllm_worker_task
DEBUG 01-14 20:42:24.298997.298997 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-14 20:42:24.298794.298794 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-14 20:42:24.299534.299534 cuda_h.py:19] end allocate_cuda_memory cost 0.0008900165557861328 seconds
DEBUG 01-14 20:42:24.299518.299518 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-14 20:42:24.299084.299084 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-14 20:42:24.299651.299651 sllm_store_c.py:27] get device uuid map
DEBUG 01-14 20:42:24.299024.299024 sllm_store_c.py:29] call client load into gpu
DEBUG 01-14 20:42:24.300257.300257 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, bee5f59b-552e-409d-b360-2de8b0dbb6fc
DEBUG 01-14 20:42:24.300293.300293 client.py:106] call stub.LoadModelAsync
DEBUG 01-14 20:42:24.300822.300822 cuda_h.py:10] start self_attn
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-14 20:42:24.303280.303280 cuda_h.py:19] end self_attn cost 0.0027251243591308594 seconds
DEBUG 01-14 20:42:24.303263.303263 cuda_h.py:19] end iln_self_attn_paln cost 0.00511622428894043 seconds
DEBUG 01-14 20:42:24.303763.303763 cuda_h.py:10] start layer_moe_generate_mp_l_11
DEBUG 01-14 20:42:24.303002.303002 cuda_h.py:10] start gate
DEBUG 01-14 20:42:24.304076.304076 cuda_h.py:19] end gate cost 0.0005819797515869141 seconds
DEBUG 01-14 20:42:24.304667.304667 cuda_h.py:10] start experts_map_get
DEBUG 01-14 20:42:24.304254.304254 lmp.py:1615] 
DEBUG 01-14 20:42:24.304254.304254 lmp.py:1615] Expert Token Distribution & Device Allocation:
DEBUG 01-14 20:42:24.304494.304494 lmp.py:1616]   Total experts: 64
DEBUG 01-14 20:42:24.304766.304766 lmp.py:1617]   CPU experts: 32 (50%)
DEBUG 01-14 20:42:24.304224.304224 lmp.py:1618]   GPU experts: 32 (50%)
DEBUG 01-14 20:42:24.304297.304297 lmp.py:1619] 
DEBUG 01-14 20:42:24.304297.304297 lmp.py:1619]   Expert ID | Tokens | Device
DEBUG 01-14 20:42:24.304371.304371 lmp.py:1620]   -----------------------------------
DEBUG 01-14 20:42:24.304398.304398 lmp.py:1625]   Expert 43 |     20 | CPU
DEBUG 01-14 20:42:24.304756.304756 lmp.py:1625]   Expert 27 |     33 | CPU
DEBUG 01-14 20:42:24.304399.304399 lmp.py:1625]   Expert 26 |     48 | CPU
DEBUG 01-14 20:42:24.304804.304804 lmp.py:1625]   Expert  3 |     57 | CPU
DEBUG 01-14 20:42:24.304162.304162 lmp.py:1625]   Expert 34 |     61 | CPU
DEBUG 01-14 20:42:24.304805.304805 lmp.py:1625]   Expert 56 |     79 | CPU
DEBUG 01-14 20:42:24.304925.304925 lmp.py:1625]   Expert 61 |     87 | CPU
DEBUG 01-14 20:42:24.304806.304806 lmp.py:1625]   Expert  4 |     92 | CPU
DEBUG 01-14 20:42:24.304926.304926 lmp.py:1625]   Expert 38 |    106 | CPU
DEBUG 01-14 20:42:24.304046.304046 lmp.py:1625]   Expert  7 |    107 | CPU
DEBUG 01-14 20:42:24.305689.305689 lmp.py:1625]   Expert 14 |    110 | CPU
DEBUG 01-14 20:42:24.305093.305093 lmp.py:1625]   Expert  5 |    119 | CPU
DEBUG 01-14 20:42:24.305498.305498 lmp.py:1625]   Expert 22 |    120 | CPU
DEBUG 01-14 20:42:24.305141.305141 lmp.py:1625]   Expert 47 |    122 | CPU
DEBUG 01-14 20:42:24.305546.305546 lmp.py:1625]   Expert  2 |    123 | CPU
DEBUG 01-14 20:42:24.305712.305712 lmp.py:1625]   Expert 45 |    129 | CPU
DEBUG 01-14 20:42:24.305116.305116 lmp.py:1625]   Expert 17 |    133 | CPU
DEBUG 01-14 20:42:24.305474.305474 lmp.py:1625]   Expert 54 |    134 | CPU
DEBUG 01-14 20:42:24.305356.305356 lmp.py:1625]   Expert 48 |    135 | CPU
DEBUG 01-14 20:42:24.305237.305237 lmp.py:1625]   Expert 19 |    138 | CPU
DEBUG 01-14 20:42:24.305119.305119 lmp.py:1625]   Expert 51 |    138 | CPU
DEBUG 01-14 20:42:24.305523.305523 lmp.py:1625]   Expert 15 |    150 | CPU
DEBUG 01-14 20:42:24.305689.305689 lmp.py:1625]   Expert 55 |    151 | CPU
DEBUG 01-14 20:42:24.305617.305617 lmp.py:1625]   Expert 57 |    151 | CPU
DEBUG 01-14 20:42:24.305783.305783 lmp.py:1625]   Expert 28 |    152 | CPU
DEBUG 01-14 20:42:24.305949.305949 lmp.py:1625]   Expert 63 |    153 | CPU
DEBUG 01-14 20:42:24.305877.305877 lmp.py:1625]   Expert 37 |    161 | CPU
DEBUG 01-14 20:42:24.305043.305043 lmp.py:1625]   Expert 12 |    163 | CPU
DEBUG 01-14 20:42:24.305448.305448 lmp.py:1625]   Expert 18 |    168 | CPU
DEBUG 01-14 20:42:24.305137.305137 lmp.py:1625]   Expert 60 |    170 | CPU
DEBUG 01-14 20:42:24.305495.305495 lmp.py:1625]   Expert 50 |    176 | CPU
DEBUG 01-14 20:42:24.305138.305138 lmp.py:1625]   Expert  6 |    183 | CPU
DEBUG 01-14 20:42:24.305496.305496 lmp.py:1625]   Expert 44 |    188 | GPU
DEBUG 01-14 20:42:24.305093.305093 lmp.py:1625]   Expert 52 |    192 | GPU
DEBUG 01-14 20:42:24.305213.305213 lmp.py:1625]   Expert 53 |    194 | GPU
DEBUG 01-14 20:42:24.305617.305617 lmp.py:1625]   Expert 31 |    195 | GPU
DEBUG 01-14 20:42:24.305784.305784 lmp.py:1625]   Expert 39 |    196 | GPU
DEBUG 01-14 20:42:24.305764.305764 lmp.py:1625]   Expert 23 |    197 | GPU
DEBUG 01-14 20:42:24.305646.305646 lmp.py:1625]   Expert 30 |    200 | GPU
DEBUG 01-14 20:42:24.305527.305527 lmp.py:1625]   Expert 21 |    204 | GPU
DEBUG 01-14 20:42:24.305693.305693 lmp.py:1625]   Expert 29 |    205 | GPU
DEBUG 01-14 20:42:24.305621.305621 lmp.py:1625]   Expert 42 |    211 | GPU
DEBUG 01-14 20:42:24.305787.305787 lmp.py:1625]   Expert 13 |    212 | GPU
DEBUG 01-14 20:42:24.305861.305861 lmp.py:1625]   Expert 16 |    214 | GPU
DEBUG 01-14 20:42:24.305457.305457 lmp.py:1625]   Expert 20 |    217 | GPU
DEBUG 01-14 20:42:24.305054.305054 lmp.py:1625]   Expert 36 |    217 | GPU
DEBUG 01-14 20:42:24.305651.305651 lmp.py:1625]   Expert 41 |    225 | GPU
DEBUG 01-14 20:42:24.305486.305486 lmp.py:1625]   Expert 49 |    226 | GPU
DEBUG 01-14 20:42:24.305606.305606 lmp.py:1625]   Expert 59 |    228 | GPU
DEBUG 01-14 20:42:24.305725.305725 lmp.py:1625]   Expert  8 |    230 | GPU
DEBUG 01-14 20:42:24.305084.305084 lmp.py:1625]   Expert 25 |    231 | GPU
DEBUG 01-14 20:42:24.305203.305203 lmp.py:1625]   Expert 11 |    236 | GPU
DEBUG 01-14 20:42:24.305323.305323 lmp.py:1625]   Expert 10 |    246 | GPU
DEBUG 01-14 20:42:24.305681.305681 lmp.py:1625]   Expert 33 |    251 | GPU
DEBUG 01-14 20:42:24.305278.305278 lmp.py:1625]   Expert 32 |    254 | GPU
DEBUG 01-14 20:42:24.305875.305875 lmp.py:1625]   Expert 46 |    270 | GPU
DEBUG 01-14 20:42:24.305471.305471 lmp.py:1625]   Expert 58 |    279 | GPU
DEBUG 01-14 20:42:24.305306.305306 lmp.py:1625]   Expert 35 |    301 | GPU
DEBUG 01-14 20:42:24.305142.305142 lmp.py:1625]   Expert 62 |    305 | GPU
DEBUG 01-14 20:42:24.305261.305261 lmp.py:1625]   Expert  9 |    323 | GPU
DEBUG 01-14 20:42:24.305858.305858 lmp.py:1625]   Expert  0 |    392 | GPU
DEBUG 01-14 20:42:24.305501.305501 lmp.py:1625]   Expert 40 |    417 | GPU
DEBUG 01-14 20:42:24.305621.305621 lmp.py:1625]   Expert 24 |    546 | GPU
DEBUG 01-14 20:42:24.305217.305217 lmp.py:1625]   Expert  1 |    617 | GPU
DEBUG 01-14 20:42:24.305768.305768 lmp.py:1626] 
DEBUG 01-14 20:42:24.305768.305768 lmp.py:1626]   CPU total tokens: 3869 (31.5%)
DEBUG 01-14 20:42:24.305795.305795 lmp.py:1627]   GPU total tokens: 8419 (68.5%)
DEBUG 01-14 20:42:24.306352.306352 cuda_h.py:19] end experts_map_get cost 0.0016345977783203125 seconds
INFO 01-14 20:42:24.306025.306025 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, bee5f59b-552e-409d-b360-2de8b0dbb6fc
DEBUG 01-14 20:42:24.306351.306351 cuda_h.py:19] end load_into_gpu_async cost 0.006276607513427734 seconds
DEBUG 01-14 20:42:24.306438.306438 cuda_h.py:10] start restore_tensors2
DEBUG 01-14 20:42:24.306382.306382 cuda_h.py:19] end restore_tensors2 cost 7.033348083496094e-05 seconds
DEBUG 01-14 20:42:24.306946.306946 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.007722616195678711 seconds
INFO 01-14 20:42:24.306273.306273 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, bee5f59b-552e-409d-b360-2de8b0dbb6fc
DEBUG 01-14 20:42:24.306103.306103 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-14 20:42:24.306351.306351 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-14 20:42:24.306448.306448 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-14 20:42:24.307367.307367 cuda_h.py:19] end allocate_cuda_memory cost 0.0010983943939208984 seconds
DEBUG 01-14 20:42:24.307455.307455 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-14 20:42:24.307119.307119 sllm_store_c.py:27] get device uuid map
DEBUG 01-14 20:42:24.308035.308035 sllm_store_c.py:29] call client load into gpu
DEBUG 01-14 20:42:24.308692.308692 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 29182521-79af-40c1-b001-21ec5e4a5c4f
DEBUG 01-14 20:42:24.308626.308626 client.py:106] call stub.LoadModelAsync
INFO 01-14 20:42:24.312240.312240 client.py:127] Model loaded
DEBUG 01-14 20:42:24.312946.312946 cuda_h.py:10] start restore2model
DEBUG 01-14 20:42:24.313129.313129 cuda_h.py:19] end restore2model cost 0.0004494190216064453 seconds
DEBUG 01-14 20:42:24.313468.313468 cuda_h.py:19] end sllm_worker_task cost 0.014473676681518555 seconds
INFO 01-14 20:42:24.314549.314549 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 29182521-79af-40c1-b001-21ec5e4a5c4f
DEBUG 01-14 20:42:24.314548.314548 cuda_h.py:19] end load_into_gpu_async cost 0.006266117095947266 seconds
DEBUG 01-14 20:42:24.314306.314306 cuda_h.py:10] start restore_tensors2
DEBUG 01-14 20:42:24.314886.314886 mlpmodule.py:1367]  experts func einsum cost 0.07707476615905762 s
DEBUG 01-14 20:42:24.314783.314783 cuda_h.py:19] end restore_tensors2 cost 0.0004031658172607422 seconds
DEBUG 01-14 20:42:24.315307.315307 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.008538246154785156 seconds
DEBUG 01-14 20:42:24.315601.315601 cuda_h.py:10] start restore2model
DEBUG 01-14 20:42:24.317107.317107 cuda_h.py:19] end restore2model cost 0.0026226043701171875 seconds
DEBUG 01-14 20:42:24.317679.317679 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.011404275894165039 seconds
DEBUG 01-14 20:42:24.317925.317925 cuda_h.py:10] start gpu_sexperts
DEBUG 01-14 20:42:24.318154.318154 cuda_h.py:19] end gpu_sexperts cost 0.0002789497375488281 seconds
DEBUG 01-14 20:42:24.318977.318977 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-14 20:42:24.318395.318395 lmp.py:1683] 
DEBUG 01-14 20:42:24.318395.318395 lmp.py:1683]   Computing 32 experts on CPU...
DEBUG 01-14 20:42:24.318046.318046 cuda_h.py:19] end cpu_experts_submit cost 5.8650970458984375e-05 seconds
DEBUG 01-14 20:42:24.318365.318365 cuda_h.py:10] start experts_func_mgpu_group_pad
DEBUG 01-14 20:42:24.328874.328874 mlpmodule.py:1460] group tensors cost 0.009436607360839844 s
DEBUG 01-14 20:42:24.329257.329257 cuda_h.py:10] start move_flat_hidden2cpu
DEBUG 01-14 20:42:24.334290.334290 cuda_h.py:19] end experts_func_mgpu_group_pad cost 0.016298532485961914 seconds
DEBUG 01-14 20:42:24.335668.335668 cuda_h.py:19] end move_flat_hidden2cpu cost 0.006249666213989258 seconds
DEBUG 01-14 20:42:24.338616.338616 cuda_h.py:10] start gpu_group_list
DEBUG 01-14 20:42:24.338568.338568 cuda_h.py:19] end gpu_group_list cost 0.0007760524749755859 seconds
DEBUG 01-14 20:42:24.339571.339571 mlpmodule.py:1533] pad cost 0.0037136077880859375 s
DEBUG 01-14 20:42:24.339025.339025 mlpmodule.py:1539] create cpu tensor cost 4.363059997558594e-05 s
DEBUG 01-14 20:42:24.339650.339650 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-14 20:42:24.339034.339034 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 3.528594970703125e-05 seconds
DEBUG 01-14 20:42:24.339354.339354 cuda_h.py:10] start wait_experts
INFO 01-14 20:42:24.339859.339859 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 29182521-79af-40c1-b001-21ec5e4a5c4f
DEBUG 01-14 20:42:24.341596.341596 mlpmodule.py:1544] move to cpu cost 0.002165079116821289 s
DEBUG 01-14 20:42:24.351544.351544 mlpmodule.py:1558] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-14 20:42:24.351808.351808 mlpmodule.py:1559] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-14 20:42:24.351698.351698 mlpmodule.py:1564] group_w3 first element: -0.0213623046875
WARNING 01-14 20:42:24.351007.351007 mlpmodule.py:1574] start einsum2
INFO 01-14 20:42:24.369773.369773 client.py:127] Model loaded
DEBUG 01-14 20:42:24.369342.369342 cuda_h.py:19] end wait_experts cost 0.029449939727783203 seconds
DEBUG 01-14 20:42:24.369251.369251 cuda_h.py:10] start gpu_experts
DEBUG 01-14 20:42:24.369597.369597 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-14 20:42:24.369510.369510 mlpmodule.py:1584] group einsum cost 0.027988195419311523 s
DEBUG 01-14 20:42:24.370912.370912 mlpmodule.py:1593] cpy2cputensor cost 0.0007512569427490234 s
DEBUG 01-14 20:42:24.370027.370027 cuda_h.py:10] start move_outputs
DEBUG 01-14 20:42:24.372761.372761 cuda_h.py:19] end move_outputs cost 0.0021245479583740234 seconds
DEBUG 01-14 20:42:24.376537.376537 cuda_h.py:19] end wait_cetm_experts cost 0.007046699523925781 seconds
DEBUG 01-14 20:42:24.376251.376251 cuda_h.py:10] start gpu_group_einsum_mp_multi_list
DEBUG 01-14 20:42:24.376498.376498 cuda_h.py:10] start gpu_group_tensor
DEBUG 01-14 20:42:24.376732.376732 cuda_h.py:19] end gpu_group_tensor cost 0.0002446174621582031 seconds
DEBUG 01-14 20:42:24.377970.377970 cuda_h.py:10] start gpu_group_einsum
DEBUG 01-14 20:42:24.377096.377096 cuda_h.py:19] end gpu_group_einsum cost 0.0007162094116210938 seconds
DEBUG 01-14 20:42:24.378076.378076 cuda_h.py:10] start gpu_final_hidden_states_scatter
DEBUG 01-14 20:42:24.378629.378629 cuda_h.py:10] start all_expert_outputs_slices
DEBUG 01-14 20:42:24.378536.378536 cuda_h.py:19] end all_expert_outputs_slices cost 0.0003483295440673828 seconds
DEBUG 01-14 20:42:24.378530.378530 cuda_h.py:10] start concat_expert_out
DEBUG 01-14 20:42:24.378229.378229 cuda_h.py:19] end concat_expert_out cost 5.6743621826171875e-05 seconds
DEBUG 01-14 20:42:24.378032.378032 cuda_h.py:10] start index_scatter
DEBUG 01-14 20:42:24.378182.378182 cuda_h.py:19] end index_scatter cost 7.510185241699219e-05 seconds
DEBUG 01-14 20:42:24.378183.378183 cuda_h.py:19] end gpu_final_hidden_states_scatter cost 0.0007443428039550781 seconds
DEBUG 01-14 20:42:24.378099.378099 cuda_h.py:19] end gpu_experts cost 0.009690999984741211 seconds
DEBUG 01-14 20:42:24.378710.378710 cuda_h.py:10] start all_expert_weight_slices
DEBUG 01-14 20:42:24.379835.379835 cuda_h.py:19] end all_expert_weight_slices cost 0.0009400844573974609 seconds
DEBUG 01-14 20:42:24.380472.380472 cuda_h.py:10] start cpuoutputsdeal
DEBUG 01-14 20:42:24.380176.380176 cuda_h.py:10] start index_scatter
DEBUG 01-14 20:42:24.380458.380458 cuda_h.py:19] end index_scatter cost 4.935264587402344e-05 seconds
DEBUG 01-14 20:42:24.380843.380843 cuda_h.py:19] end cpuoutputsdeal cost 0.0005602836608886719 seconds
DEBUG 01-14 20:42:24.380607.380607 cuda_h.py:19] end layer_moe_generate_mp_l_11 cost 0.07699465751647949 seconds
DEBUG 01-14 20:42:24.381547.381547 cuda_h.py:19] end prefill_layer cost 0.08281254768371582 seconds
DEBUG 01-14 20:42:24.381232.381232 lmp.py:1551] -------------------------------- end prefill layer 10 --------------------------------
DEBUG 01-14 20:42:24.381464.381464 cuda_h.py:10] start prefill_layer
DEBUG 01-14 20:42:24.381406.381406 lmp.py:1494] -------------------------------- start prefill layer 11 --------------------------------
DEBUG 01-14 20:42:24.381109.381109 cuda_h.py:10] start start_load_qkvogn_s_weight_l_12
DEBUG 01-14 20:42:24.381441.381441 cuda_h.py:10] start start_load_qkvogn_s_weight_l_12
DEBUG 01-14 20:42:24.381483.381483 cuda_h.py:19] end start_load_qkvogn_s_weight_l_12 cost 3.838539123535156e-05 seconds
DEBUG 01-14 20:42:24.381240.381240 cuda_h.py:10] start sllm_worker_task
DEBUG 01-14 20:42:24.381368.381368 cuda_h.py:19] end start_load_qkvogn_s_weight_l_12 cost 0.00016307830810546875 seconds
DEBUG 01-14 20:42:24.381994.381994 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-14 20:42:24.381851.381851 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-14 20:42:24.381913.381913 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-14 20:42:24.381506.381506 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-14 20:42:24.382386.382386 cuda_h.py:19] end allocate_cuda_memory cost 0.0006825923919677734 seconds
DEBUG 01-14 20:42:24.382313.382313 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-14 20:42:24.382540.382540 sllm_store_c.py:27] get device uuid map
DEBUG 01-14 20:42:24.382761.382761 sllm_store_c.py:29] call client load into gpu
DEBUG 01-14 20:42:24.382393.382393 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, fbd99e11-a573-4ce5-a4bd-c63883bc1c0a
DEBUG 01-14 20:42:24.383986.383986 client.py:106] call stub.LoadModelAsync
DEBUG 01-14 20:42:24.383809.383809 cuda_h.py:10] start self_attn
INFO 01-14 20:42:24.384890.384890 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, fbd99e11-a573-4ce5-a4bd-c63883bc1c0a
DEBUG 01-14 20:42:24.384827.384827 cuda_h.py:19] end load_into_gpu_async cost 0.001825571060180664 seconds
DEBUG 01-14 20:42:24.384239.384239 cuda_h.py:10] start restore_tensors2
DEBUG 01-14 20:42:24.384985.384985 cuda_h.py:19] end restore_tensors2 cost 8.535385131835938e-05 seconds
DEBUG 01-14 20:42:24.384888.384888 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.003239154815673828 seconds
INFO 01-14 20:42:24.384698.384698 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, fbd99e11-a573-4ce5-a4bd-c63883bc1c0a
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-14 20:42:24.387962.387962 cuda_h.py:19] end self_attn cost 0.003667593002319336 seconds
DEBUG 01-14 20:42:24.387980.387980 cuda_h.py:19] end iln_self_attn_paln cost 0.005712270736694336 seconds
DEBUG 01-14 20:42:24.387307.387307 cuda_h.py:10] start layer_moe_generate_mp_l_12
DEBUG 01-14 20:42:24.387898.387898 cuda_h.py:10] start gate
DEBUG 01-14 20:42:24.388620.388620 cuda_h.py:19] end gate cost 0.0007390975952148438 seconds
DEBUG 01-14 20:42:24.388967.388967 cuda_h.py:10] start experts_map_get
DEBUG 01-14 20:42:24.388547.388547 lmp.py:1615] 
DEBUG 01-14 20:42:24.388547.388547 lmp.py:1615] Expert Token Distribution & Device Allocation:
DEBUG 01-14 20:42:24.388217.388217 lmp.py:1616]   Total experts: 64
DEBUG 01-14 20:42:24.388397.388397 lmp.py:1617]   CPU experts: 32 (50%)
DEBUG 01-14 20:42:24.388524.388524 lmp.py:1618]   GPU experts: 32 (50%)
DEBUG 01-14 20:42:24.388789.388789 lmp.py:1619] 
DEBUG 01-14 20:42:24.388789.388789 lmp.py:1619]   Expert ID | Tokens | Device
DEBUG 01-14 20:42:24.388293.388293 lmp.py:1620]   -----------------------------------
DEBUG 01-14 20:42:24.388512.388512 lmp.py:1625]   Expert 39 |     15 | CPU
DEBUG 01-14 20:42:24.388301.388301 lmp.py:1625]   Expert 13 |     22 | CPU
DEBUG 01-14 20:42:24.388613.388613 lmp.py:1625]   Expert 49 |     35 | CPU
DEBUG 01-14 20:42:24.388448.388448 lmp.py:1625]   Expert  9 |     62 | CPU
DEBUG 01-14 20:42:24.389522.389522 lmp.py:1625]   Expert 19 |     62 | CPU
DEBUG 01-14 20:42:24.389357.389357 lmp.py:1625]   Expert 26 |     63 | CPU
DEBUG 01-14 20:42:24.389715.389715 lmp.py:1625]   Expert 33 |     70 | CPU
DEBUG 01-14 20:42:24.389073.389073 lmp.py:1625]   Expert 35 |     73 | CPU
DEBUG 01-14 20:42:24.389147.389147 lmp.py:1625]   Expert 46 |     74 | CPU
DEBUG 01-14 20:42:24.389982.389982 lmp.py:1625]   Expert 32 |     82 | CPU
DEBUG 01-14 20:42:24.389294.389294 lmp.py:1625]   Expert 41 |     86 | CPU
DEBUG 01-14 20:42:24.389082.389082 lmp.py:1625]   Expert 23 |     89 | CPU
DEBUG 01-14 20:42:24.389394.389394 lmp.py:1625]   Expert 31 |    100 | CPU
DEBUG 01-14 20:42:24.389229.389229 lmp.py:1625]   Expert 17 |    101 | CPU
DEBUG 01-14 20:42:24.389064.389064 lmp.py:1625]   Expert 18 |    107 | CPU
DEBUG 01-14 20:42:24.389423.389423 lmp.py:1625]   Expert  6 |    109 | CPU
DEBUG 01-14 20:42:24.389019.389019 lmp.py:1625]   Expert  3 |    115 | CPU
DEBUG 01-14 20:42:24.389616.389616 lmp.py:1625]   Expert 50 |    118 | CPU
DEBUG 01-14 20:42:24.389974.389974 lmp.py:1625]   Expert 38 |    120 | CPU
DEBUG 01-14 20:42:24.389332.389332 lmp.py:1625]   Expert 40 |    125 | CPU
DEBUG 01-14 20:42:24.389406.389406 lmp.py:1625]   Expert 15 |    130 | CPU
DEBUG 01-14 20:42:24.389479.389479 lmp.py:1625]   Expert 20 |    131 | CPU
DEBUG 01-14 20:42:24.389314.389314 lmp.py:1625]   Expert 63 |    132 | CPU
DEBUG 01-14 20:42:24.389388.389388 lmp.py:1625]   Expert 62 |    137 | CPU
DEBUG 01-14 20:42:24.389984.389984 lmp.py:1625]   Expert 61 |    141 | CPU
DEBUG 01-14 20:42:24.389343.389343 lmp.py:1625]   Expert 36 |    143 | CPU
DEBUG 01-14 20:42:24.389178.389178 lmp.py:1625]   Expert 43 |    145 | CPU
DEBUG 01-14 20:42:24.389774.389774 lmp.py:1625]   Expert 42 |    147 | CPU
DEBUG 01-14 20:42:24.389894.389894 lmp.py:1625]   Expert  2 |    149 | CPU
DEBUG 01-14 20:42:24.389491.389491 lmp.py:1625]   Expert 44 |    156 | CPU
DEBUG 01-14 20:42:24.389849.389849 lmp.py:1625]   Expert 10 |    157 | CPU
DEBUG 01-14 20:42:24.389698.389698 lmp.py:1625]   Expert 16 |    160 | CPU
DEBUG 01-14 20:42:24.389109.389109 lmp.py:1625]   Expert  5 |    173 | GPU
DEBUG 01-14 20:42:24.389659.389659 lmp.py:1625]   Expert 56 |    174 | GPU
DEBUG 01-14 20:42:24.389256.389256 lmp.py:1625]   Expert 59 |    176 | GPU
DEBUG 01-14 20:42:24.389853.389853 lmp.py:1625]   Expert 45 |    194 | GPU
DEBUG 01-14 20:42:24.389449.389449 lmp.py:1625]   Expert 52 |    194 | GPU
DEBUG 01-14 20:42:24.389284.389284 lmp.py:1625]   Expert 34 |    196 | GPU
DEBUG 01-14 20:42:24.389643.389643 lmp.py:1625]   Expert 60 |    199 | GPU
DEBUG 01-14 20:42:24.389001.389001 lmp.py:1625]   Expert 27 |    204 | GPU
DEBUG 01-14 20:42:24.389074.389074 lmp.py:1625]   Expert 51 |    213 | GPU
DEBUG 01-14 20:42:24.389148.389148 lmp.py:1625]   Expert 24 |    219 | GPU
DEBUG 01-14 20:42:24.389460.389460 lmp.py:1625]   Expert 48 |    224 | GPU
DEBUG 01-14 20:42:24.389295.389295 lmp.py:1625]   Expert 53 |    225 | GPU
DEBUG 01-14 20:42:24.389607.389607 lmp.py:1625]   Expert 47 |    243 | GPU
DEBUG 01-14 20:42:24.389965.389965 lmp.py:1625]   Expert  7 |    251 | GPU
DEBUG 01-14 20:42:24.389800.389800 lmp.py:1625]   Expert  8 |    251 | GPU
DEBUG 01-14 20:42:24.389920.389920 lmp.py:1625]   Expert 29 |    263 | GPU
DEBUG 01-14 20:42:24.389755.389755 lmp.py:1625]   Expert 21 |    268 | GPU
DEBUG 01-14 20:42:24.389352.389352 lmp.py:1625]   Expert 58 |    277 | GPU
DEBUG 01-14 20:42:24.389233.389233 lmp.py:1625]   Expert 57 |    283 | GPU
DEBUG 01-14 20:42:24.389353.389353 lmp.py:1625]   Expert 14 |    290 | GPU
DEBUG 01-14 20:42:24.389949.389949 lmp.py:1625]   Expert 37 |    294 | GPU
DEBUG 01-14 20:42:24.389308.389308 lmp.py:1625]   Expert  1 |    297 | GPU
DEBUG 01-14 20:42:24.389427.389427 lmp.py:1625]   Expert 11 |    302 | GPU
DEBUG 01-14 20:42:24.389501.389501 lmp.py:1625]   Expert  0 |    308 | GPU
DEBUG 01-14 20:42:24.389813.389813 lmp.py:1625]   Expert 22 |    309 | GPU
DEBUG 01-14 20:42:24.390648.390648 lmp.py:1625]   Expert  4 |    310 | GPU
DEBUG 01-14 20:42:24.390721.390721 lmp.py:1625]   Expert 55 |    324 | GPU
DEBUG 01-14 20:42:24.390318.390318 lmp.py:1625]   Expert 54 |    335 | GPU
DEBUG 01-14 20:42:24.390676.390676 lmp.py:1625]   Expert 25 |    366 | GPU
DEBUG 01-14 20:42:24.390035.390035 lmp.py:1625]   Expert 28 |    410 | GPU
DEBUG 01-14 20:42:24.390393.390393 lmp.py:1625]   Expert 12 |    415 | GPU
DEBUG 01-14 20:42:24.390513.390513 lmp.py:1625]   Expert 30 |    745 | GPU
DEBUG 01-14 20:42:24.390824.390824 lmp.py:1626] 
DEBUG 01-14 20:42:24.390824.390824 lmp.py:1626]   CPU total tokens: 3356 (27.3%)
DEBUG 01-14 20:42:24.390852.390852 lmp.py:1627]   GPU total tokens: 8932 (72.7%)
DEBUG 01-14 20:42:24.390886.390886 cuda_h.py:19] end experts_map_get cost 0.0016987323760986328 seconds
DEBUG 01-14 20:42:24.390272.390272 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-14 20:42:24.390553.390553 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-14 20:42:24.390213.390213 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-14 20:42:24.396882.396882 cuda_h.py:19] end allocate_cuda_memory cost 0.0057222843170166016 seconds
DEBUG 01-14 20:42:24.396343.396343 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-14 20:42:24.396397.396397 sllm_store_c.py:27] get device uuid map
DEBUG 01-14 20:42:24.396783.396783 sllm_store_c.py:29] call client load into gpu
DEBUG 01-14 20:42:24.396255.396255 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 0d8b7da0-7b79-4d74-8ac9-00636fd1fba0
DEBUG 01-14 20:42:24.396957.396957 client.py:106] call stub.LoadModelAsync
INFO 01-14 20:42:24.396076.396076 client.py:127] Model loaded
DEBUG 01-14 20:42:24.396190.396190 cuda_h.py:10] start restore2model
DEBUG 01-14 20:42:24.397286.397286 mlpmodule.py:1367]  experts func einsum cost 0.07814192771911621 s
DEBUG 01-14 20:42:24.397697.397697 cuda_h.py:19] end restore2model cost 0.0006411075592041016 seconds
DEBUG 01-14 20:42:24.397342.397342 cuda_h.py:19] end sllm_worker_task cost 0.016140222549438477 seconds
INFO 01-14 20:42:24.398238.398238 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 0d8b7da0-7b79-4d74-8ac9-00636fd1fba0
DEBUG 01-14 20:42:24.398981.398981 cuda_h.py:19] end load_into_gpu_async cost 0.002215862274169922 seconds
DEBUG 01-14 20:42:24.398922.398922 cuda_h.py:10] start restore_tensors2
DEBUG 01-14 20:42:24.399790.399790 cuda_h.py:19] end restore_tensors2 cost 0.0003662109375 seconds
DEBUG 01-14 20:42:24.399772.399772 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.008706092834472656 seconds
DEBUG 01-14 20:42:24.399012.399012 cuda_h.py:10] start restore2model
DEBUG 01-14 20:42:24.401040.401040 cuda_h.py:19] end restore2model cost 0.0025894641876220703 seconds
DEBUG 01-14 20:42:24.401214.401214 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.011473894119262695 seconds
DEBUG 01-14 20:42:24.401579.401579 cuda_h.py:10] start gpu_sexperts
DEBUG 01-14 20:42:24.402370.402370 cuda_h.py:19] end gpu_sexperts cost 0.00027251243591308594 seconds
DEBUG 01-14 20:42:24.402737.402737 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-14 20:42:24.402201.402201 lmp.py:1683] 
DEBUG 01-14 20:42:24.402201.402201 lmp.py:1683]   Computing 32 experts on CPU...
DEBUG 01-14 20:42:24.402230.402230 cuda_h.py:19] end cpu_experts_submit cost 5.5789947509765625e-05 seconds
DEBUG 01-14 20:42:24.402979.402979 cuda_h.py:10] start experts_func_mgpu_group_pad
DEBUG 01-14 20:42:24.411682.411682 mlpmodule.py:1460] group tensors cost 0.008946418762207031 s
DEBUG 01-14 20:42:24.412431.412431 cuda_h.py:10] start move_flat_hidden2cpu
DEBUG 01-14 20:42:24.414480.414480 cuda_h.py:19] end experts_func_mgpu_group_pad cost 0.01253509521484375 seconds
DEBUG 01-14 20:42:24.416348.416348 cuda_h.py:10] start gpu_group_list
DEBUG 01-14 20:42:24.416605.416605 cuda_h.py:19] end gpu_group_list cost 0.0004527568817138672 seconds
DEBUG 01-14 20:42:24.417605.417605 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-14 20:42:24.417992.417992 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 1.9311904907226562e-05 seconds
DEBUG 01-14 20:42:24.417225.417225 cuda_h.py:10] start wait_experts
INFO 01-14 20:42:24.417173.417173 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 0d8b7da0-7b79-4d74-8ac9-00636fd1fba0
DEBUG 01-14 20:42:24.418817.418817 cuda_h.py:19] end move_flat_hidden2cpu cost 0.006121397018432617 seconds
DEBUG 01-14 20:42:24.420607.420607 mlpmodule.py:1533] pad cost 0.0015282630920410156 s
DEBUG 01-14 20:42:24.420312.420312 mlpmodule.py:1539] create cpu tensor cost 3.4332275390625e-05 s
DEBUG 01-14 20:42:24.422119.422119 mlpmodule.py:1544] move to cpu cost 0.0018944740295410156 s
DEBUG 01-14 20:42:24.431835.431835 mlpmodule.py:1558] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-14 20:42:24.431973.431973 mlpmodule.py:1559] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-14 20:42:24.431712.431712 mlpmodule.py:1564] group_w3 first element: -0.006134033203125
WARNING 01-14 20:42:24.431273.431273 mlpmodule.py:1574] start einsum2
DEBUG 01-14 20:42:24.448613.448613 mlpmodule.py:1584] group einsum cost 0.02616405487060547 s
DEBUG 01-14 20:42:24.449837.449837 mlpmodule.py:1593] cpy2cputensor cost 0.0006837844848632812 s
DEBUG 01-14 20:42:24.449659.449659 cuda_h.py:10] start move_outputs
DEBUG 01-14 20:42:24.451445.451445 cuda_h.py:19] end move_outputs cost 0.0024802684783935547 seconds
INFO 01-14 20:42:24.454362.454362 client.py:127] Model loaded
DEBUG 01-14 20:42:24.455011.455011 cuda_h.py:19] end wait_experts cost 0.0378875732421875 seconds
DEBUG 01-14 20:42:24.455218.455218 cuda_h.py:10] start gpu_experts
DEBUG 01-14 20:42:24.455710.455710 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-14 20:42:24.455708.455708 cuda_h.py:19] end wait_cetm_experts cost 0.0006959438323974609 seconds
DEBUG 01-14 20:42:24.455386.455386 cuda_h.py:10] start gpu_group_einsum_mp_multi_list
DEBUG 01-14 20:42:24.456003.456003 cuda_h.py:10] start gpu_group_tensor
DEBUG 01-14 20:42:24.456469.456469 cuda_h.py:19] end gpu_group_tensor cost 0.00024080276489257812 seconds
DEBUG 01-14 20:42:24.456514.456514 cuda_h.py:10] start gpu_group_einsum
DEBUG 01-14 20:42:24.457631.457631 cuda_h.py:19] end gpu_group_einsum cost 0.0006616115570068359 seconds
DEBUG 01-14 20:42:24.457205.457205 cuda_h.py:10] start gpu_final_hidden_states_scatter
DEBUG 01-14 20:42:24.457631.457631 cuda_h.py:10] start all_expert_outputs_slices
DEBUG 01-14 20:42:24.457274.457274 cuda_h.py:19] end all_expert_outputs_slices cost 0.0003657341003417969 seconds
DEBUG 01-14 20:42:24.457791.457791 cuda_h.py:10] start concat_expert_out
DEBUG 01-14 20:42:24.457066.457066 cuda_h.py:19] end concat_expert_out cost 6.151199340820312e-05 seconds
DEBUG 01-14 20:42:24.457207.457207 cuda_h.py:10] start index_scatter
DEBUG 01-14 20:42:24.458827.458827 cuda_h.py:19] end index_scatter cost 7.200241088867188e-05 seconds
DEBUG 01-14 20:42:24.458967.458967 cuda_h.py:19] end gpu_final_hidden_states_scatter cost 0.0007576942443847656 seconds
DEBUG 01-14 20:42:24.458937.458937 cuda_h.py:19] end gpu_experts cost 0.003025054931640625 seconds
DEBUG 01-14 20:42:24.458308.458308 cuda_h.py:10] start all_expert_weight_slices
DEBUG 01-14 20:42:24.459242.459242 cuda_h.py:19] end all_expert_weight_slices cost 0.0009393692016601562 seconds
DEBUG 01-14 20:42:24.459826.459826 cuda_h.py:10] start cpuoutputsdeal
DEBUG 01-14 20:42:24.459403.459403 cuda_h.py:10] start index_scatter
DEBUG 01-14 20:42:24.459863.459863 cuda_h.py:19] end index_scatter cost 4.601478576660156e-05 seconds
DEBUG 01-14 20:42:24.459341.459341 cuda_h.py:19] end cpuoutputsdeal cost 0.0005254745483398438 seconds
DEBUG 01-14 20:42:24.459536.459536 cuda_h.py:19] end layer_moe_generate_mp_l_12 cost 0.07224774360656738 seconds
DEBUG 01-14 20:42:24.460568.460568 cuda_h.py:19] end prefill_layer cost 0.07901358604431152 seconds
DEBUG 01-14 20:42:24.460987.460987 lmp.py:1551] -------------------------------- end prefill layer 11 --------------------------------
DEBUG 01-14 20:42:24.460406.460406 cuda_h.py:10] start prefill_layer
DEBUG 01-14 20:42:24.460062.460062 lmp.py:1494] -------------------------------- start prefill layer 12 --------------------------------
DEBUG 01-14 20:42:24.460672.460672 cuda_h.py:10] start start_load_qkvogn_s_weight_l_13
DEBUG 01-14 20:42:24.460071.460071 cuda_h.py:10] start start_load_qkvogn_s_weight_l_13
DEBUG 01-14 20:42:24.460875.460875 cuda_h.py:19] end start_load_qkvogn_s_weight_l_13 cost 3.695487976074219e-05 seconds
DEBUG 01-14 20:42:24.460108.460108 cuda_h.py:19] end start_load_qkvogn_s_weight_l_13 cost 7.05718994140625e-05 seconds
DEBUG 01-14 20:42:24.460996.460996 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-14 20:42:24.460403.460403 cuda_h.py:10] start sllm_worker_task
DEBUG 01-14 20:42:24.460446.460446 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-14 20:42:24.460190.460190 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-14 20:42:24.461174.461174 cuda_h.py:19] end allocate_cuda_memory cost 0.0010709762573242188 seconds
DEBUG 01-14 20:42:24.462542.462542 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-14 20:42:24.462154.462154 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-14 20:42:24.462908.462908 sllm_store_c.py:27] get device uuid map
DEBUG 01-14 20:42:24.462844.462844 sllm_store_c.py:29] call client load into gpu
DEBUG 01-14 20:42:24.462037.462037 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, bfdef8d0-1be1-4d9b-9491-e1f029ea48a6
DEBUG 01-14 20:42:24.462073.462073 client.py:106] call stub.LoadModelAsync
DEBUG 01-14 20:42:24.462688.462688 cuda_h.py:10] start self_attn
INFO 01-14 20:42:24.463183.463183 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, bfdef8d0-1be1-4d9b-9491-e1f029ea48a6
DEBUG 01-14 20:42:24.463357.463357 cuda_h.py:19] end load_into_gpu_async cost 0.001737356185913086 seconds
DEBUG 01-14 20:42:24.464298.464298 cuda_h.py:10] start restore_tensors2
DEBUG 01-14 20:42:24.464434.464434 cuda_h.py:19] end restore_tensors2 cost 7.2479248046875e-05 seconds
DEBUG 01-14 20:42:24.464951.464951 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.003396272659301758 seconds
INFO 01-14 20:42:24.464311.464311 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, bfdef8d0-1be1-4d9b-9491-e1f029ea48a6
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-14 20:42:24.465122.465122 cuda_h.py:19] end self_attn cost 0.003021717071533203 seconds
DEBUG 01-14 20:42:24.466226.466226 cuda_h.py:19] end iln_self_attn_paln cost 0.005649089813232422 seconds
DEBUG 01-14 20:42:24.466685.466685 cuda_h.py:10] start layer_moe_generate_mp_l_13
DEBUG 01-14 20:42:24.466540.466540 cuda_h.py:10] start gate
DEBUG 01-14 20:42:24.466020.466020 cuda_h.py:19] end gate cost 0.0006358623504638672 seconds
DEBUG 01-14 20:42:24.467226.467226 cuda_h.py:10] start experts_map_get
DEBUG 01-14 20:42:24.467548.467548 lmp.py:1615] 
DEBUG 01-14 20:42:24.467548.467548 lmp.py:1615] Expert Token Distribution & Device Allocation:
DEBUG 01-14 20:42:24.467258.467258 lmp.py:1616]   Total experts: 64
DEBUG 01-14 20:42:24.467623.467623 lmp.py:1617]   CPU experts: 32 (50%)
DEBUG 01-14 20:42:24.467935.467935 lmp.py:1618]   GPU experts: 32 (50%)
DEBUG 01-14 20:42:24.467101.467101 lmp.py:1619] 
DEBUG 01-14 20:42:24.467101.467101 lmp.py:1619]   Expert ID | Tokens | Device
DEBUG 01-14 20:42:24.467744.467744 lmp.py:1620]   -----------------------------------
DEBUG 01-14 20:42:24.467579.467579 lmp.py:1625]   Expert 12 |     27 | CPU
DEBUG 01-14 20:42:24.467983.467983 lmp.py:1625]   Expert 16 |     31 | CPU
DEBUG 01-14 20:42:24.467673.467673 lmp.py:1625]   Expert 38 |     31 | CPU
DEBUG 01-14 20:42:24.467647.467647 lmp.py:1625]   Expert 52 |     32 | CPU
DEBUG 01-14 20:42:24.467482.467482 lmp.py:1625]   Expert 47 |     39 | CPU
DEBUG 01-14 20:42:24.467886.467886 lmp.py:1625]   Expert 63 |     44 | CPU
DEBUG 01-14 20:42:24.467052.467052 lmp.py:1625]   Expert 27 |     56 | CPU
DEBUG 01-14 20:42:24.467980.467980 lmp.py:1625]   Expert  4 |     69 | CPU
DEBUG 01-14 20:42:24.467385.467385 lmp.py:1625]   Expert 43 |     76 | CPU
DEBUG 01-14 20:42:24.467551.467551 lmp.py:1625]   Expert 61 |     77 | CPU
DEBUG 01-14 20:42:24.467479.467479 lmp.py:1625]   Expert 53 |     79 | CPU
DEBUG 01-14 20:42:24.467406.467406 lmp.py:1625]   Expert 34 |     81 | CPU
DEBUG 01-14 20:42:24.467334.467334 lmp.py:1625]   Expert 44 |     84 | CPU
DEBUG 01-14 20:42:24.467262.467262 lmp.py:1625]   Expert 13 |     96 | CPU
DEBUG 01-14 20:42:24.467435.467435 lmp.py:1625]   Expert 37 |    103 | CPU
DEBUG 01-14 20:42:24.467601.467601 lmp.py:1625]   Expert 39 |    106 | CPU
DEBUG 01-14 20:42:24.467244.467244 lmp.py:1625]   Expert 32 |    110 | CPU
DEBUG 01-14 20:42:24.467840.467840 lmp.py:1625]   Expert  0 |    113 | CPU
DEBUG 01-14 20:42:24.467245.467245 lmp.py:1625]   Expert 20 |    124 | CPU
DEBUG 01-14 20:42:24.467888.467888 lmp.py:1625]   Expert 14 |    126 | CPU
DEBUG 01-14 20:42:24.467292.467292 lmp.py:1625]   Expert 21 |    129 | CPU
DEBUG 01-14 20:42:24.467651.467651 lmp.py:1625]   Expert 30 |    129 | CPU
DEBUG 01-14 20:42:24.467009.467009 lmp.py:1625]   Expert  8 |    138 | CPU
DEBUG 01-14 20:42:24.467606.467606 lmp.py:1625]   Expert 60 |    138 | CPU
DEBUG 01-14 20:42:24.467964.467964 lmp.py:1625]   Expert 18 |    140 | CPU
DEBUG 01-14 20:42:24.467322.467322 lmp.py:1625]   Expert 45 |    142 | CPU
DEBUG 01-14 20:42:24.467157.467157 lmp.py:1625]   Expert 11 |    147 | CPU
DEBUG 01-14 20:42:24.467277.467277 lmp.py:1625]   Expert 57 |    155 | CPU
DEBUG 01-14 20:42:24.467397.467397 lmp.py:1625]   Expert 17 |    157 | CPU
DEBUG 01-14 20:42:24.467755.467755 lmp.py:1625]   Expert 36 |    157 | CPU
DEBUG 01-14 20:42:24.467113.467113 lmp.py:1625]   Expert 22 |    158 | CPU
DEBUG 01-14 20:42:24.468471.468471 lmp.py:1625]   Expert 42 |    162 | CPU
DEBUG 01-14 20:42:24.468591.468591 lmp.py:1625]   Expert  2 |    163 | GPU
DEBUG 01-14 20:42:24.468188.468188 lmp.py:1625]   Expert  7 |    167 | GPU
DEBUG 01-14 20:42:24.468308.468308 lmp.py:1625]   Expert 23 |    170 | GPU
DEBUG 01-14 20:42:24.468865.468865 lmp.py:1625]   Expert 58 |    170 | GPU
DEBUG 01-14 20:42:24.468985.468985 lmp.py:1625]   Expert 25 |    176 | GPU
DEBUG 01-14 20:42:24.468866.468866 lmp.py:1625]   Expert 49 |    177 | GPU
DEBUG 01-14 20:42:24.468747.468747 lmp.py:1625]   Expert 35 |    181 | GPU
DEBUG 01-14 20:42:24.468867.468867 lmp.py:1625]   Expert 62 |    181 | GPU
DEBUG 01-14 20:42:24.468510.468510 lmp.py:1625]   Expert 48 |    191 | GPU
DEBUG 01-14 20:42:24.468630.468630 lmp.py:1625]   Expert  6 |    192 | GPU
DEBUG 01-14 20:42:24.468227.468227 lmp.py:1625]   Expert 55 |    192 | GPU
DEBUG 01-14 20:42:24.468062.468062 lmp.py:1625]   Expert 29 |    200 | GPU
DEBUG 01-14 20:42:24.468897.468897 lmp.py:1625]   Expert  1 |    201 | GPU
DEBUG 01-14 20:42:24.468255.468255 lmp.py:1625]   Expert 31 |    207 | GPU
DEBUG 01-14 20:42:24.468852.468852 lmp.py:1625]   Expert 51 |    214 | GPU
DEBUG 01-14 20:42:24.468971.468971 lmp.py:1625]   Expert 28 |    219 | GPU
DEBUG 01-14 20:42:24.468853.468853 lmp.py:1625]   Expert  5 |    220 | GPU
DEBUG 01-14 20:42:24.468496.468496 lmp.py:1625]   Expert 19 |    226 | GPU
DEBUG 01-14 20:42:24.468139.468139 lmp.py:1625]   Expert 54 |    230 | GPU
DEBUG 01-14 20:42:24.468543.468543 lmp.py:1625]   Expert  9 |    242 | GPU
DEBUG 01-14 20:42:24.468339.468339 lmp.py:1625]   Expert 41 |    250 | GPU
DEBUG 01-14 20:42:24.468465.468465 lmp.py:1625]   Expert 24 |    262 | GPU
DEBUG 01-14 20:42:24.468685.468685 lmp.py:1625]   Expert 50 |    267 | GPU
DEBUG 01-14 20:42:24.468050.468050 lmp.py:1625]   Expert 46 |    281 | GPU
DEBUG 01-14 20:42:24.468408.468408 lmp.py:1625]   Expert 59 |    325 | GPU
DEBUG 01-14 20:42:24.468005.468005 lmp.py:1625]   Expert 33 |    396 | GPU
DEBUG 01-14 20:42:24.468124.468124 lmp.py:1625]   Expert 56 |    411 | GPU
DEBUG 01-14 20:42:24.468006.468006 lmp.py:1625]   Expert 10 |    429 | GPU
DEBUG 01-14 20:42:24.468649.468649 lmp.py:1625]   Expert 26 |    433 | GPU
DEBUG 01-14 20:42:24.468292.468292 lmp.py:1625]   Expert  3 |    599 | GPU
DEBUG 01-14 20:42:24.468935.468935 lmp.py:1625]   Expert 15 |    602 | GPU
DEBUG 01-14 20:42:24.468578.468578 lmp.py:1625]   Expert 40 |    858 | GPU
DEBUG 01-14 20:42:24.468366.468366 lmp.py:1626] 
DEBUG 01-14 20:42:24.468366.468366 lmp.py:1626]   CPU total tokens: 3256 (26.5%)
DEBUG 01-14 20:42:24.468394.468394 lmp.py:1627]   GPU total tokens: 9032 (73.5%)
DEBUG 01-14 20:42:24.468951.468951 cuda_h.py:19] end experts_map_get cost 0.0016283988952636719 seconds
DEBUG 01-14 20:42:24.468000.468000 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-14 20:42:24.468995.468995 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-14 20:42:24.468139.468139 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-14 20:42:24.470967.470967 cuda_h.py:19] end allocate_cuda_memory cost 0.0013463497161865234 seconds
DEBUG 01-14 20:42:24.470770.470770 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-14 20:42:24.470970.470970 sllm_store_c.py:27] get device uuid map
DEBUG 01-14 20:42:24.470362.470362 sllm_store_c.py:29] call client load into gpu
DEBUG 01-14 20:42:24.470396.470396 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 2dfffe03-9eb5-4456-8d21-ae3d0c4d6112
DEBUG 01-14 20:42:24.470112.470112 client.py:106] call stub.LoadModelAsync
INFO 01-14 20:42:24.472079.472079 client.py:127] Model loaded
DEBUG 01-14 20:42:24.472485.472485 cuda_h.py:10] start restore2model
DEBUG 01-14 20:42:24.472596.472596 cuda_h.py:19] end restore2model cost 0.0003311634063720703 seconds
DEBUG 01-14 20:42:24.472935.472935 cuda_h.py:19] end sllm_worker_task cost 0.011854171752929688 seconds
INFO 01-14 20:42:24.473648.473648 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 2dfffe03-9eb5-4456-8d21-ae3d0c4d6112
DEBUG 01-14 20:42:24.473183.473183 cuda_h.py:19] end load_into_gpu_async cost 0.0033702850341796875 seconds
DEBUG 01-14 20:42:24.473961.473961 cuda_h.py:10] start restore_tensors2
DEBUG 01-14 20:42:24.474262.474262 cuda_h.py:19] end restore_tensors2 cost 0.00043463706970214844 seconds
DEBUG 01-14 20:42:24.474099.474099 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.005633831024169922 seconds
DEBUG 01-14 20:42:24.474338.474338 cuda_h.py:10] start restore2model
DEBUG 01-14 20:42:24.476950.476950 mlpmodule.py:1367]  experts func einsum cost 0.07432770729064941 s
DEBUG 01-14 20:42:24.477121.477121 cuda_h.py:19] end restore2model cost 0.003170013427734375 seconds
DEBUG 01-14 20:42:24.477880.477880 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.009039878845214844 seconds
DEBUG 01-14 20:42:24.477675.477675 cuda_h.py:10] start gpu_sexperts
DEBUG 01-14 20:42:24.478281.478281 cuda_h.py:19] end gpu_sexperts cost 0.0002751350402832031 seconds
DEBUG 01-14 20:42:24.478581.478581 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-14 20:42:24.478476.478476 lmp.py:1683] 
DEBUG 01-14 20:42:24.478476.478476 lmp.py:1683]   Computing 32 experts on CPU...
DEBUG 01-14 20:42:24.478412.478412 cuda_h.py:19] end cpu_experts_submit cost 5.793571472167969e-05 seconds
DEBUG 01-14 20:42:24.478307.478307 cuda_h.py:10] start experts_func_mgpu_group_pad
DEBUG 01-14 20:42:24.487036.487036 mlpmodule.py:1460] group tensors cost 0.008747339248657227 s
DEBUG 01-14 20:42:24.488063.488063 cuda_h.py:10] start move_flat_hidden2cpu
DEBUG 01-14 20:42:24.493891.493891 cuda_h.py:19] end move_flat_hidden2cpu cost 0.005874156951904297 seconds
DEBUG 01-14 20:42:24.494375.494375 cuda_h.py:19] end experts_func_mgpu_group_pad cost 0.0160219669342041 seconds
DEBUG 01-14 20:42:24.497992.497992 mlpmodule.py:1533] pad cost 0.003526449203491211 s
DEBUG 01-14 20:42:24.497400.497400 mlpmodule.py:1539] create cpu tensor cost 4.2438507080078125e-05 s
DEBUG 01-14 20:42:24.498166.498166 cuda_h.py:10] start gpu_group_list
DEBUG 01-14 20:42:24.499594.499594 cuda_h.py:19] end gpu_group_list cost 0.0005981922149658203 seconds
DEBUG 01-14 20:42:24.499674.499674 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-14 20:42:24.499511.499511 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.5033950805664062e-05 seconds
DEBUG 01-14 20:42:24.499043.499043 cuda_h.py:10] start wait_experts
INFO 01-14 20:42:24.499481.499481 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 2dfffe03-9eb5-4456-8d21-ae3d0c4d6112
DEBUG 01-14 20:42:24.499115.499115 mlpmodule.py:1544] move to cpu cost 0.0019207000732421875 s
DEBUG 01-14 20:42:24.509617.509617 mlpmodule.py:1558] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-14 20:42:24.509980.509980 mlpmodule.py:1559] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-14 20:42:24.509009.509009 mlpmodule.py:1564] group_w3 first element: -0.0162353515625
WARNING 01-14 20:42:24.509934.509934 mlpmodule.py:1574] start einsum2
DEBUG 01-14 20:42:24.526500.526500 mlpmodule.py:1584] group einsum cost 0.02699732780456543 s
DEBUG 01-14 20:42:24.527576.527576 mlpmodule.py:1593] cpy2cputensor cost 0.0006997585296630859 s
DEBUG 01-14 20:42:24.527637.527637 cuda_h.py:10] start move_outputs
INFO 01-14 20:42:24.528166.528166 client.py:127] Model loaded
DEBUG 01-14 20:42:24.528623.528623 cuda_h.py:19] end wait_experts cost 0.029332399368286133 seconds
DEBUG 01-14 20:42:24.528300.528300 cuda_h.py:10] start gpu_experts
DEBUG 01-14 20:42:24.528930.528930 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-14 20:42:24.529258.529258 cuda_h.py:19] end move_outputs cost 0.0018887519836425781 seconds
DEBUG 01-14 20:42:24.533155.533155 cuda_h.py:19] end wait_cetm_experts cost 0.004294872283935547 seconds
DEBUG 01-14 20:42:24.533649.533649 cuda_h.py:10] start gpu_group_einsum_mp_multi_list
DEBUG 01-14 20:42:24.533697.533697 cuda_h.py:10] start gpu_group_tensor
DEBUG 01-14 20:42:24.533547.533547 cuda_h.py:19] end gpu_group_tensor cost 0.0002429485321044922 seconds
DEBUG 01-14 20:42:24.533441.533441 cuda_h.py:10] start gpu_group_einsum
DEBUG 01-14 20:42:24.534562.534562 cuda_h.py:19] end gpu_group_einsum cost 0.0005962848663330078 seconds
DEBUG 01-14 20:42:24.534144.534144 cuda_h.py:10] start gpu_final_hidden_states_scatter
DEBUG 01-14 20:42:24.534053.534053 cuda_h.py:10] start all_expert_outputs_slices
DEBUG 01-14 20:42:24.535061.535061 cuda_h.py:19] end all_expert_outputs_slices cost 0.0003898143768310547 seconds
DEBUG 01-14 20:42:24.535712.535712 cuda_h.py:10] start concat_expert_out
DEBUG 01-14 20:42:24.535021.535021 cuda_h.py:19] end concat_expert_out cost 6.985664367675781e-05 seconds
DEBUG 01-14 20:42:24.535229.535229 cuda_h.py:10] start index_scatter
DEBUG 01-14 20:42:24.535168.535168 cuda_h.py:19] end index_scatter cost 0.00012969970703125 seconds
DEBUG 01-14 20:42:24.535667.535667 cuda_h.py:19] end gpu_final_hidden_states_scatter cost 0.0009248256683349609 seconds
DEBUG 01-14 20:42:24.535406.535406 cuda_h.py:19] end gpu_experts cost 0.006894826889038086 seconds
DEBUG 01-14 20:42:24.535652.535652 cuda_h.py:10] start all_expert_weight_slices
DEBUG 01-14 20:42:24.536251.536251 cuda_h.py:19] end all_expert_weight_slices cost 0.0010380744934082031 seconds
DEBUG 01-14 20:42:24.537512.537512 cuda_h.py:10] start cpuoutputsdeal
DEBUG 01-14 20:42:24.537223.537223 cuda_h.py:10] start index_scatter
DEBUG 01-14 20:42:24.537452.537452 cuda_h.py:19] end index_scatter cost 5.435943603515625e-05 seconds
DEBUG 01-14 20:42:24.537381.537381 cuda_h.py:19] end cpuoutputsdeal cost 0.0005967617034912109 seconds
DEBUG 01-14 20:42:24.537040.537040 cuda_h.py:19] end layer_moe_generate_mp_l_13 cost 0.07149195671081543 seconds
DEBUG 01-14 20:42:24.538159.538159 cuda_h.py:19] end prefill_layer cost 0.07784199714660645 seconds
DEBUG 01-14 20:42:24.538002.538002 lmp.py:1551] -------------------------------- end prefill layer 12 --------------------------------
DEBUG 01-14 20:42:24.538658.538658 cuda_h.py:10] start prefill_layer
DEBUG 01-14 20:42:24.538076.538076 lmp.py:1494] -------------------------------- start prefill layer 13 --------------------------------
DEBUG 01-14 20:42:24.538971.538971 cuda_h.py:10] start start_load_qkvogn_s_weight_l_14
DEBUG 01-14 20:42:24.538774.538774 cuda_h.py:10] start start_load_qkvogn_s_weight_l_14
DEBUG 01-14 20:42:24.538942.538942 cuda_h.py:19] end start_load_qkvogn_s_weight_l_14 cost 5.984306335449219e-05 seconds
DEBUG 01-14 20:42:24.538811.538811 cuda_h.py:10] start sllm_worker_task
DEBUG 01-14 20:42:24.538953.538953 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-14 20:42:24.538921.538921 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-14 20:42:24.538375.538375 cuda_h.py:19] end start_load_qkvogn_s_weight_l_14 cost 0.00013637542724609375 seconds
DEBUG 01-14 20:42:24.540277.540277 cuda_h.py:19] end allocate_cuda_memory cost 0.0018770694732666016 seconds
DEBUG 01-14 20:42:24.540042.540042 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-14 20:42:24.540589.540589 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-14 20:42:24.540263.540263 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-14 20:42:24.540730.540730 sllm_store_c.py:27] get device uuid map
DEBUG 01-14 20:42:24.541529.541529 sllm_store_c.py:29] call client load into gpu
DEBUG 01-14 20:42:24.541914.541914 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, c1f5aca4-4577-412a-a090-a3cccc8668cf
DEBUG 01-14 20:42:24.541904.541904 client.py:106] call stub.LoadModelAsync
DEBUG 01-14 20:42:24.541028.541028 cuda_h.py:10] start self_attn
INFO 01-14 20:42:24.542845.542845 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, c1f5aca4-4577-412a-a090-a3cccc8668cf
DEBUG 01-14 20:42:24.542748.542748 cuda_h.py:19] end load_into_gpu_async cost 0.0017390251159667969 seconds
DEBUG 01-14 20:42:24.542120.542120 cuda_h.py:10] start restore_tensors2
DEBUG 01-14 20:42:24.542202.542202 cuda_h.py:19] end restore_tensors2 cost 6.818771362304688e-05 seconds
DEBUG 01-14 20:42:24.542435.542435 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.004298686981201172 seconds
INFO 01-14 20:42:24.542603.542603 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, c1f5aca4-4577-412a-a090-a3cccc8668cf
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-14 20:42:24.544225.544225 cuda_h.py:19] end self_attn cost 0.003233671188354492 seconds
DEBUG 01-14 20:42:24.545275.545275 cuda_h.py:19] end iln_self_attn_paln cost 0.004399776458740234 seconds
DEBUG 01-14 20:42:24.545211.545211 cuda_h.py:10] start layer_moe_generate_mp_l_14
DEBUG 01-14 20:42:24.545828.545828 cuda_h.py:10] start gate
DEBUG 01-14 20:42:24.545016.545016 cuda_h.py:19] end gate cost 0.0006322860717773438 seconds
DEBUG 01-14 20:42:24.546653.546653 cuda_h.py:10] start experts_map_get
DEBUG 01-14 20:42:24.546067.546067 lmp.py:1615] 
DEBUG 01-14 20:42:24.546067.546067 lmp.py:1615] Expert Token Distribution & Device Allocation:
DEBUG 01-14 20:42:24.546731.546731 lmp.py:1616]   Total experts: 64
DEBUG 01-14 20:42:24.546526.546526 lmp.py:1617]   CPU experts: 32 (50%)
DEBUG 01-14 20:42:24.546553.546553 lmp.py:1618]   GPU experts: 32 (50%)
DEBUG 01-14 20:42:24.546150.546150 lmp.py:1619] 
DEBUG 01-14 20:42:24.546150.546150 lmp.py:1619]   Expert ID | Tokens | Device
DEBUG 01-14 20:42:24.546985.546985 lmp.py:1620]   -----------------------------------
DEBUG 01-14 20:42:24.546012.546012 lmp.py:1625]   Expert 42 |     18 | CPU
DEBUG 01-14 20:42:24.546370.546370 lmp.py:1625]   Expert 19 |     24 | CPU
DEBUG 01-14 20:42:24.546252.546252 lmp.py:1625]   Expert 30 |     24 | CPU
DEBUG 01-14 20:42:24.546133.546133 lmp.py:1625]   Expert  6 |     59 | CPU
DEBUG 01-14 20:42:24.546253.546253 lmp.py:1625]   Expert 32 |     69 | CPU
DEBUG 01-14 20:42:24.546565.546565 lmp.py:1625]   Expert  1 |     70 | CPU
DEBUG 01-14 20:42:24.546446.546446 lmp.py:1625]   Expert  5 |     73 | CPU
DEBUG 01-14 20:42:24.546805.546805 lmp.py:1625]   Expert 53 |    102 | CPU
DEBUG 01-14 20:42:24.546924.546924 lmp.py:1625]   Expert 11 |    111 | CPU
DEBUG 01-14 20:42:24.546806.546806 lmp.py:1625]   Expert 18 |    112 | CPU
DEBUG 01-14 20:42:24.546687.546687 lmp.py:1625]   Expert 63 |    129 | CPU
DEBUG 01-14 20:42:24.546092.546092 lmp.py:1625]   Expert 13 |    131 | CPU
DEBUG 01-14 20:42:24.546735.546735 lmp.py:1625]   Expert 58 |    136 | CPU
DEBUG 01-14 20:42:24.546901.546901 lmp.py:1625]   Expert 59 |    138 | CPU
DEBUG 01-14 20:42:24.546829.546829 lmp.py:1625]   Expert 31 |    140 | CPU
DEBUG 01-14 20:42:24.546995.546995 lmp.py:1625]   Expert 26 |    142 | CPU
DEBUG 01-14 20:42:24.546161.546161 lmp.py:1625]   Expert 40 |    142 | CPU
DEBUG 01-14 20:42:24.546327.546327 lmp.py:1625]   Expert 51 |    144 | CPU
DEBUG 01-14 20:42:24.546447.546447 lmp.py:1625]   Expert  4 |    147 | CPU
DEBUG 01-14 20:42:24.546090.546090 lmp.py:1625]   Expert 34 |    150 | CPU
DEBUG 01-14 20:42:24.546971.546971 lmp.py:1625]   Expert 61 |    151 | CPU
DEBUG 01-14 20:42:24.546290.546290 lmp.py:1625]   Expert 56 |    152 | CPU
DEBUG 01-14 20:42:24.546886.546886 lmp.py:1625]   Expert 50 |    153 | CPU
DEBUG 01-14 20:42:24.546622.546622 lmp.py:1625]   Expert 20 |    154 | CPU
DEBUG 01-14 20:42:24.546835.546835 lmp.py:1625]   Expert 48 |    156 | CPU
DEBUG 01-14 20:42:24.546047.546047 lmp.py:1625]   Expert  9 |    157 | CPU
DEBUG 01-14 20:42:24.546021.546021 lmp.py:1625]   Expert 12 |    160 | CPU
DEBUG 01-14 20:42:24.546234.546234 lmp.py:1625]   Expert 35 |    162 | CPU
DEBUG 01-14 20:42:24.546969.546969 lmp.py:1625]   Expert 37 |    165 | CPU
DEBUG 01-14 20:42:24.546420.546420 lmp.py:1625]   Expert 55 |    167 | CPU
DEBUG 01-14 20:42:24.546871.546871 lmp.py:1625]   Expert 33 |    168 | CPU
DEBUG 01-14 20:42:24.547322.547322 lmp.py:1625]   Expert 10 |    173 | CPU
DEBUG 01-14 20:42:24.547773.547773 lmp.py:1625]   Expert 36 |    176 | GPU
DEBUG 01-14 20:42:24.547462.547462 lmp.py:1625]   Expert 46 |    176 | GPU
DEBUG 01-14 20:42:24.547674.547674 lmp.py:1625]   Expert 52 |    179 | GPU
DEBUG 01-14 20:42:24.547172.547172 lmp.py:1625]   Expert  2 |    180 | GPU
DEBUG 01-14 20:42:24.547146.547146 lmp.py:1625]   Expert  8 |    188 | GPU
DEBUG 01-14 20:42:24.547881.547881 lmp.py:1625]   Expert 25 |    200 | GPU
DEBUG 01-14 20:42:24.547617.547617 lmp.py:1625]   Expert 39 |    200 | GPU
DEBUG 01-14 20:42:24.547591.547591 lmp.py:1625]   Expert  3 |    207 | GPU
DEBUG 01-14 20:42:24.547327.547327 lmp.py:1625]   Expert 57 |    210 | GPU
DEBUG 01-14 20:42:24.547301.547301 lmp.py:1625]   Expert  0 |    213 | GPU
DEBUG 01-14 20:42:24.547036.547036 lmp.py:1625]   Expert 24 |    213 | GPU
DEBUG 01-14 20:42:24.547249.547249 lmp.py:1625]   Expert  7 |    234 | GPU
DEBUG 01-14 20:42:24.547938.547938 lmp.py:1625]   Expert 27 |    238 | GPU
DEBUG 01-14 20:42:24.547627.547627 lmp.py:1625]   Expert 62 |    238 | GPU
DEBUG 01-14 20:42:24.547078.547078 lmp.py:1625]   Expert 21 |    240 | GPU
DEBUG 01-14 20:42:24.547006.547006 lmp.py:1625]   Expert 23 |    242 | GPU
DEBUG 01-14 20:42:24.547172.547172 lmp.py:1625]   Expert 38 |    245 | GPU
DEBUG 01-14 20:42:24.547623.547623 lmp.py:1625]   Expert 28 |    264 | GPU
DEBUG 01-14 20:42:24.547597.547597 lmp.py:1625]   Expert 43 |    271 | GPU
DEBUG 01-14 20:42:24.547809.547809 lmp.py:1625]   Expert 29 |    273 | GPU
DEBUG 01-14 20:42:24.547784.547784 lmp.py:1625]   Expert 60 |    274 | GPU
DEBUG 01-14 20:42:24.547519.547519 lmp.py:1625]   Expert 49 |    285 | GPU
DEBUG 01-14 20:42:24.547493.547493 lmp.py:1625]   Expert 15 |    287 | GPU
DEBUG 01-14 20:42:24.547229.547229 lmp.py:1625]   Expert 16 |    287 | GPU
DEBUG 01-14 20:42:24.547203.547203 lmp.py:1625]   Expert 41 |    291 | GPU
DEBUG 01-14 20:42:24.547415.547415 lmp.py:1625]   Expert 54 |    292 | GPU
DEBUG 01-14 20:42:24.547628.547628 lmp.py:1625]   Expert 22 |    299 | GPU
DEBUG 01-14 20:42:24.547556.547556 lmp.py:1625]   Expert 44 |    315 | GPU
DEBUG 01-14 20:42:24.547245.547245 lmp.py:1625]   Expert 47 |    316 | GPU
DEBUG 01-14 20:42:24.547173.547173 lmp.py:1625]   Expert 14 |    372 | GPU
DEBUG 01-14 20:42:24.547623.547623 lmp.py:1625]   Expert 17 |    380 | GPU
DEBUG 01-14 20:42:24.547359.547359 lmp.py:1625]   Expert 45 |    524 | GPU
DEBUG 01-14 20:42:24.547525.547525 lmp.py:1626] 
DEBUG 01-14 20:42:24.547525.547525 lmp.py:1626]   CPU total tokens: 3979 (32.4%)
DEBUG 01-14 20:42:24.547168.547168 lmp.py:1627]   GPU total tokens: 8309 (67.6%)
DEBUG 01-14 20:42:24.547626.547626 cuda_h.py:19] end experts_map_get cost 0.0015308856964111328 seconds
DEBUG 01-14 20:42:24.547284.547284 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-14 20:42:24.547365.547365 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-14 20:42:24.547516.547516 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-14 20:42:24.549218.549218 cuda_h.py:19] end allocate_cuda_memory cost 0.0013604164123535156 seconds
DEBUG 01-14 20:42:24.549690.549690 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-14 20:42:24.549546.549546 sllm_store_c.py:27] get device uuid map
DEBUG 01-14 20:42:24.549509.549509 sllm_store_c.py:29] call client load into gpu
DEBUG 01-14 20:42:24.549689.549689 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, b66ef9b1-d528-4ac5-9957-b0f859adbaf6
DEBUG 01-14 20:42:24.549854.549854 client.py:106] call stub.LoadModelAsync
INFO 01-14 20:42:24.549802.549802 client.py:127] Model loaded
DEBUG 01-14 20:42:24.549169.549169 cuda_h.py:10] start restore2model
DEBUG 01-14 20:42:24.550572.550572 cuda_h.py:19] end restore2model cost 0.0003323554992675781 seconds
DEBUG 01-14 20:42:24.550103.550103 cuda_h.py:19] end sllm_worker_task cost 0.011803627014160156 seconds
INFO 01-14 20:42:24.551610.551610 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, b66ef9b1-d528-4ac5-9957-b0f859adbaf6
DEBUG 01-14 20:42:24.551930.551930 cuda_h.py:19] end load_into_gpu_async cost 0.002178668975830078 seconds
DEBUG 01-14 20:42:24.551686.551686 cuda_h.py:10] start restore_tensors2
DEBUG 01-14 20:42:24.551454.551454 cuda_h.py:19] end restore_tensors2 cost 0.00036334991455078125 seconds
DEBUG 01-14 20:42:24.552814.552814 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.004275083541870117 seconds
DEBUG 01-14 20:42:24.552914.552914 cuda_h.py:10] start restore2model
DEBUG 01-14 20:42:24.554054.554054 cuda_h.py:19] end restore2model cost 0.002566814422607422 seconds
DEBUG 01-14 20:42:24.554606.554606 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.0070209503173828125 seconds
DEBUG 01-14 20:42:24.554355.554355 cuda_h.py:10] start gpu_sexperts
DEBUG 01-14 20:42:24.555577.555577 cuda_h.py:19] end gpu_sexperts cost 0.0002734661102294922 seconds
DEBUG 01-14 20:42:24.555684.555684 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-14 20:42:24.555056.555056 lmp.py:1683] 
DEBUG 01-14 20:42:24.555056.555056 lmp.py:1683]   Computing 32 experts on CPU...
DEBUG 01-14 20:42:24.555886.555886 cuda_h.py:19] end cpu_experts_submit cost 4.982948303222656e-05 seconds
DEBUG 01-14 20:42:24.555920.555920 cuda_h.py:10] start experts_func_mgpu_group_pad
DEBUG 01-14 20:42:24.556640.556640 cuda_h.py:19] end experts_func_mgpu_group_pad cost 0.0015194416046142578 seconds
DEBUG 01-14 20:42:24.557953.557953 mlpmodule.py:1367]  experts func einsum cost 0.0786430835723877 s
DEBUG 01-14 20:42:24.566813.566813 mlpmodule.py:1460] group tensors cost 0.009051084518432617 s
DEBUG 01-14 20:42:24.567703.567703 cuda_h.py:10] start move_flat_hidden2cpu
DEBUG 01-14 20:42:24.568160.568160 cuda_h.py:10] start gpu_group_list
DEBUG 01-14 20:42:24.568825.568825 cuda_h.py:19] end gpu_group_list cost 0.0005178451538085938 seconds
DEBUG 01-14 20:42:24.568580.568580 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-14 20:42:24.569600.569600 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 3.147125244140625e-05 seconds
DEBUG 01-14 20:42:24.569774.569774 cuda_h.py:10] start wait_experts
INFO 01-14 20:42:24.569054.569054 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, b66ef9b1-d528-4ac5-9957-b0f859adbaf6
DEBUG 01-14 20:42:24.573107.573107 cuda_h.py:19] end move_flat_hidden2cpu cost 0.0055103302001953125 seconds
DEBUG 01-14 20:42:24.574143.574143 mlpmodule.py:1533] pad cost 0.0015332698822021484 s
DEBUG 01-14 20:42:24.574047.574047 mlpmodule.py:1539] create cpu tensor cost 3.600120544433594e-05 s
DEBUG 01-14 20:42:24.576203.576203 mlpmodule.py:1544] move to cpu cost 0.002043485641479492 s
DEBUG 01-14 20:42:24.586279.586279 mlpmodule.py:1558] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-14 20:42:24.586073.586073 mlpmodule.py:1559] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-14 20:42:24.586056.586056 mlpmodule.py:1564] group_w3 first element: -0.0211181640625
WARNING 01-14 20:42:24.586742.586742 mlpmodule.py:1574] start einsum2
DEBUG 01-14 20:42:24.603999.603999 mlpmodule.py:1584] group einsum cost 0.02628159523010254 s
DEBUG 01-14 20:42:24.604455.604455 mlpmodule.py:1593] cpy2cputensor cost 0.0007719993591308594 s
DEBUG 01-14 20:42:24.604709.604709 cuda_h.py:10] start move_outputs
DEBUG 01-14 20:42:24.607967.607967 cuda_h.py:19] end move_outputs cost 0.002756834030151367 seconds
INFO 01-14 20:42:24.608285.608285 client.py:127] Model loaded
DEBUG 01-14 20:42:24.608119.608119 cuda_h.py:19] end wait_experts cost 0.03891777992248535 seconds
DEBUG 01-14 20:42:24.608657.608657 cuda_h.py:10] start gpu_experts
DEBUG 01-14 20:42:24.608957.608957 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-14 20:42:24.611937.611937 cuda_h.py:19] end wait_cetm_experts cost 0.0029296875 seconds
DEBUG 01-14 20:42:24.611244.611244 cuda_h.py:10] start gpu_group_einsum_mp_multi_list
DEBUG 01-14 20:42:24.611338.611338 cuda_h.py:10] start gpu_group_tensor
DEBUG 01-14 20:42:24.611612.611612 cuda_h.py:19] end gpu_group_tensor cost 0.00023937225341796875 seconds
DEBUG 01-14 20:42:24.611775.611775 cuda_h.py:10] start gpu_group_einsum
DEBUG 01-14 20:42:24.612213.612213 cuda_h.py:19] end gpu_group_einsum cost 0.0005552768707275391 seconds
DEBUG 01-14 20:42:24.612006.612006 cuda_h.py:10] start gpu_final_hidden_states_scatter
DEBUG 01-14 20:42:24.612273.612273 cuda_h.py:10] start all_expert_outputs_slices
DEBUG 01-14 20:42:24.612291.612291 cuda_h.py:19] end all_expert_outputs_slices cost 0.00029659271240234375 seconds
DEBUG 01-14 20:42:24.612431.612431 cuda_h.py:10] start concat_expert_out
DEBUG 01-14 20:42:24.613699.613699 cuda_h.py:19] end concat_expert_out cost 5.7220458984375e-05 seconds
DEBUG 01-14 20:42:24.613502.613502 cuda_h.py:10] start index_scatter
DEBUG 01-14 20:42:24.613214.613214 cuda_h.py:19] end index_scatter cost 7.104873657226562e-05 seconds
DEBUG 01-14 20:42:24.613262.613262 cuda_h.py:19] end gpu_final_hidden_states_scatter cost 0.0006740093231201172 seconds
DEBUG 01-14 20:42:24.613324.613324 cuda_h.py:19] end gpu_experts cost 0.005059242248535156 seconds
DEBUG 01-14 20:42:24.613219.613219 cuda_h.py:10] start all_expert_weight_slices
DEBUG 01-14 20:42:24.614775.614775 cuda_h.py:19] end all_expert_weight_slices cost 0.0009405612945556641 seconds
DEBUG 01-14 20:42:24.614313.614313 cuda_h.py:10] start cpuoutputsdeal
DEBUG 01-14 20:42:24.614036.614036 cuda_h.py:10] start index_scatter
DEBUG 01-14 20:42:24.614311.614311 cuda_h.py:19] end index_scatter cost 4.673004150390625e-05 seconds
DEBUG 01-14 20:42:24.614265.614265 cuda_h.py:19] end cpuoutputsdeal cost 0.0005335807800292969 seconds
DEBUG 01-14 20:42:24.615553.615553 cuda_h.py:19] end layer_moe_generate_mp_l_14 cost 0.06970882415771484 seconds
DEBUG 01-14 20:42:24.615148.615148 cuda_h.py:19] end prefill_layer cost 0.07708525657653809 seconds
DEBUG 01-14 20:42:24.615137.615137 lmp.py:1551] -------------------------------- end prefill layer 13 --------------------------------
DEBUG 01-14 20:42:24.615316.615316 cuda_h.py:10] start prefill_layer
DEBUG 01-14 20:42:24.615973.615973 lmp.py:1494] -------------------------------- start prefill layer 14 --------------------------------
DEBUG 01-14 20:42:24.615868.615868 cuda_h.py:10] start start_load_qkvogn_s_weight_l_15
DEBUG 01-14 20:42:24.615114.615114 cuda_h.py:10] start start_load_qkvogn_s_weight_l_15
DEBUG 01-14 20:42:24.615964.615964 cuda_h.py:19] end start_load_qkvogn_s_weight_l_15 cost 3.62396240234375e-05 seconds
DEBUG 01-14 20:42:24.615958.615958 cuda_h.py:19] end start_load_qkvogn_s_weight_l_15 cost 6.961822509765625e-05 seconds
DEBUG 01-14 20:42:24.615999.615999 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-14 20:42:24.615564.615564 cuda_h.py:10] start sllm_worker_task
DEBUG 01-14 20:42:24.615047.615047 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-14 20:42:24.615115.615115 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-14 20:42:24.616413.616413 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-14 20:42:24.619516.619516 cuda_h.py:19] end allocate_cuda_memory cost 0.003225564956665039 seconds
DEBUG 01-14 20:42:24.619948.619948 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-14 20:42:24.619142.619142 sllm_store_c.py:27] get device uuid map
DEBUG 01-14 20:42:24.619640.619640 sllm_store_c.py:29] call client load into gpu
DEBUG 01-14 20:42:24.619774.619774 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 0472e6c9-0026-4562-aeee-34fe1863cd17
DEBUG 01-14 20:42:24.619220.619220 client.py:106] call stub.LoadModelAsync
DEBUG 01-14 20:42:24.620191.620191 cuda_h.py:10] start self_attn
INFO 01-14 20:42:24.621109.621109 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 0472e6c9-0026-4562-aeee-34fe1863cd17
DEBUG 01-14 20:42:24.621899.621899 cuda_h.py:19] end load_into_gpu_async cost 0.0016467571258544922 seconds
DEBUG 01-14 20:42:24.621648.621648 cuda_h.py:10] start restore_tensors2
DEBUG 01-14 20:42:24.621830.621830 cuda_h.py:19] end restore_tensors2 cost 7.271766662597656e-05 seconds
DEBUG 01-14 20:42:24.621109.621109 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.005211591720581055 seconds
INFO 01-14 20:42:24.621846.621846 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 0472e6c9-0026-4562-aeee-34fe1863cd17
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-14 20:42:24.623820.623820 cuda_h.py:19] end self_attn cost 0.0028913021087646484 seconds
DEBUG 01-14 20:42:24.623313.623313 cuda_h.py:19] end iln_self_attn_paln cost 0.007480144500732422 seconds
DEBUG 01-14 20:42:24.623819.623819 cuda_h.py:10] start layer_moe_generate_mp_l_15
DEBUG 01-14 20:42:24.623151.623151 cuda_h.py:10] start gate
DEBUG 01-14 20:42:24.624498.624498 cuda_h.py:19] end gate cost 0.0006387233734130859 seconds
DEBUG 01-14 20:42:24.624705.624705 cuda_h.py:10] start experts_map_get
DEBUG 01-14 20:42:24.624616.624616 lmp.py:1615] 
DEBUG 01-14 20:42:24.624616.624616 lmp.py:1615] Expert Token Distribution & Device Allocation:
DEBUG 01-14 20:42:24.624995.624995 lmp.py:1616]   Total experts: 64
DEBUG 01-14 20:42:24.624360.624360 lmp.py:1617]   CPU experts: 32 (50%)
DEBUG 01-14 20:42:24.624434.624434 lmp.py:1618]   GPU experts: 32 (50%)
DEBUG 01-14 20:42:24.624600.624600 lmp.py:1619] 
DEBUG 01-14 20:42:24.624600.624600 lmp.py:1619]   Expert ID | Tokens | Device
DEBUG 01-14 20:42:24.624004.624004 lmp.py:1620]   -----------------------------------
DEBUG 01-14 20:42:24.624839.624839 lmp.py:1625]   Expert 34 |     18 | CPU
DEBUG 01-14 20:42:24.624244.624244 lmp.py:1625]   Expert 13 |     42 | CPU
DEBUG 01-14 20:42:24.624364.624364 lmp.py:1625]   Expert  7 |     43 | CPU
DEBUG 01-14 20:42:24.624291.624291 lmp.py:1625]   Expert 39 |     79 | CPU
DEBUG 01-14 20:42:24.624696.624696 lmp.py:1625]   Expert 54 |     88 | CPU
DEBUG 01-14 20:42:24.624862.624862 lmp.py:1625]   Expert 49 |     93 | CPU
DEBUG 01-14 20:42:24.624505.624505 lmp.py:1625]   Expert 18 |     94 | CPU
DEBUG 01-14 20:42:24.624956.624956 lmp.py:1625]   Expert 59 |     95 | CPU
DEBUG 01-14 20:42:24.624930.624930 lmp.py:1625]   Expert 16 |    101 | CPU
DEBUG 01-14 20:42:24.624142.624142 lmp.py:1625]   Expert 41 |    108 | CPU
DEBUG 01-14 20:42:24.624262.624262 lmp.py:1625]   Expert 45 |    110 | CPU
DEBUG 01-14 20:42:24.624428.624428 lmp.py:1625]   Expert  0 |    112 | CPU
DEBUG 01-14 20:42:24.624356.624356 lmp.py:1625]   Expert 21 |    115 | CPU
DEBUG 01-14 20:42:24.624284.624284 lmp.py:1625]   Expert 22 |    115 | CPU
DEBUG 01-14 20:42:24.624973.624973 lmp.py:1625]   Expert 52 |    130 | CPU
DEBUG 01-14 20:42:24.624662.624662 lmp.py:1625]   Expert 12 |    141 | CPU
DEBUG 01-14 20:42:24.624021.624021 lmp.py:1625]   Expert  8 |    142 | CPU
DEBUG 01-14 20:42:24.624902.624902 lmp.py:1625]   Expert 35 |    144 | CPU
DEBUG 01-14 20:42:24.624545.624545 lmp.py:1625]   Expert 38 |    144 | CPU
DEBUG 01-14 20:42:24.624188.624188 lmp.py:1625]   Expert 61 |    145 | CPU
DEBUG 01-14 20:42:24.624831.624831 lmp.py:1625]   Expert 17 |    146 | CPU
DEBUG 01-14 20:42:24.624236.624236 lmp.py:1625]   Expert 15 |    152 | CPU
DEBUG 01-14 20:42:24.624163.624163 lmp.py:1625]   Expert 36 |    154 | CPU
DEBUG 01-14 20:42:24.624329.624329 lmp.py:1625]   Expert 60 |    156 | CPU
DEBUG 01-14 20:42:24.624257.624257 lmp.py:1625]   Expert 48 |    158 | CPU
DEBUG 01-14 20:42:24.624185.624185 lmp.py:1625]   Expert 27 |    166 | CPU
DEBUG 01-14 20:42:24.625351.625351 lmp.py:1625]   Expert 31 |    170 | CPU
DEBUG 01-14 20:42:24.625802.625802 lmp.py:1625]   Expert 53 |    178 | CPU
DEBUG 01-14 20:42:24.625922.625922 lmp.py:1625]   Expert 19 |    182 | CPU
DEBUG 01-14 20:42:24.625326.625326 lmp.py:1625]   Expert 40 |    186 | CPU
DEBUG 01-14 20:42:24.625731.625731 lmp.py:1625]   Expert  4 |    187 | CPU
DEBUG 01-14 20:42:24.625135.625135 lmp.py:1625]   Expert 50 |    188 | CPU
DEBUG 01-14 20:42:24.625778.625778 lmp.py:1625]   Expert 20 |    189 | GPU
DEBUG 01-14 20:42:24.625944.625944 lmp.py:1625]   Expert 46 |    191 | GPU
DEBUG 01-14 20:42:24.625111.625111 lmp.py:1625]   Expert 11 |    201 | GPU
DEBUG 01-14 20:42:24.625800.625800 lmp.py:1625]   Expert 43 |    208 | GPU
DEBUG 01-14 20:42:24.625966.625966 lmp.py:1625]   Expert 30 |    209 | GPU
DEBUG 01-14 20:42:24.625132.625132 lmp.py:1625]   Expert 26 |    212 | GPU
DEBUG 01-14 20:42:24.625298.625298 lmp.py:1625]   Expert 29 |    214 | GPU
DEBUG 01-14 20:42:24.625464.625464 lmp.py:1625]   Expert 14 |    223 | GPU
DEBUG 01-14 20:42:24.625684.625684 lmp.py:1625]   Expert  6 |    229 | GPU
DEBUG 01-14 20:42:24.625664.625664 lmp.py:1625]   Expert 57 |    229 | GPU
DEBUG 01-14 20:42:24.625023.625023 lmp.py:1625]   Expert 23 |    241 | GPU
DEBUG 01-14 20:42:24.625381.625381 lmp.py:1625]   Expert  3 |    242 | GPU
DEBUG 01-14 20:42:24.625786.625786 lmp.py:1625]   Expert  2 |    245 | GPU
DEBUG 01-14 20:42:24.625952.625952 lmp.py:1625]   Expert 33 |    245 | GPU
DEBUG 01-14 20:42:24.625356.625356 lmp.py:1625]   Expert 56 |    249 | GPU
DEBUG 01-14 20:42:24.625761.625761 lmp.py:1625]   Expert 37 |    254 | GPU
DEBUG 01-14 20:42:24.625927.625927 lmp.py:1625]   Expert 42 |    256 | GPU
DEBUG 01-14 20:42:24.625093.625093 lmp.py:1625]   Expert  9 |    259 | GPU
DEBUG 01-14 20:42:24.625498.625498 lmp.py:1625]   Expert 44 |    265 | GPU
DEBUG 01-14 20:42:24.625425.625425 lmp.py:1625]   Expert 32 |    267 | GPU
DEBUG 01-14 20:42:24.625591.625591 lmp.py:1625]   Expert 55 |    272 | GPU
DEBUG 01-14 20:42:24.625996.625996 lmp.py:1625]   Expert 51 |    274 | GPU
DEBUG 01-14 20:42:24.625401.625401 lmp.py:1625]   Expert 28 |    279 | GPU
DEBUG 01-14 20:42:24.625805.625805 lmp.py:1625]   Expert 58 |    285 | GPU
DEBUG 01-14 20:42:24.625971.625971 lmp.py:1625]   Expert  1 |    286 | GPU
DEBUG 01-14 20:42:24.625614.625614 lmp.py:1625]   Expert 63 |    288 | GPU
DEBUG 01-14 20:42:24.625780.625780 lmp.py:1625]   Expert 24 |    291 | GPU
DEBUG 01-14 20:42:24.625470.625470 lmp.py:1625]   Expert 10 |    292 | GPU
DEBUG 01-14 20:42:24.625397.625397 lmp.py:1625]   Expert 25 |    308 | GPU
DEBUG 01-14 20:42:24.625325.625325 lmp.py:1625]   Expert 47 |    323 | GPU
DEBUG 01-14 20:42:24.625491.625491 lmp.py:1625]   Expert 62 |    328 | GPU
DEBUG 01-14 20:42:24.625419.625419 lmp.py:1625]   Expert  5 |    352 | GPU
DEBUG 01-14 20:42:24.625777.625777 lmp.py:1626] 
DEBUG 01-14 20:42:24.625777.625777 lmp.py:1626]   CPU total tokens: 4082 (33.2%)
DEBUG 01-14 20:42:24.625089.625089 lmp.py:1627]   GPU total tokens: 8206 (66.8%)
DEBUG 01-14 20:42:24.625169.625169 cuda_h.py:19] end experts_map_get cost 0.001577615737915039 seconds
DEBUG 01-14 20:42:24.625211.625211 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-14 20:42:24.625485.625485 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-14 20:42:24.625390.625390 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-14 20:42:24.628710.628710 cuda_h.py:19] end allocate_cuda_memory cost 0.0025887489318847656 seconds
DEBUG 01-14 20:42:24.628467.628467 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-14 20:42:24.628892.628892 sllm_store_c.py:27] get device uuid map
DEBUG 01-14 20:42:24.628900.628900 sllm_store_c.py:29] call client load into gpu
DEBUG 01-14 20:42:24.628934.628934 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 78a224cd-9185-4b82-a0ab-81ce1a4d80d1
DEBUG 01-14 20:42:24.628245.628245 client.py:106] call stub.LoadModelAsync
INFO 01-14 20:42:24.629086.629086 client.py:127] Model loaded
DEBUG 01-14 20:42:24.629300.629300 cuda_h.py:10] start restore2model
DEBUG 01-14 20:42:24.629381.629381 cuda_h.py:19] end restore2model cost 0.0004105567932128906 seconds
DEBUG 01-14 20:42:24.629058.629058 cuda_h.py:19] end sllm_worker_task cost 0.013737916946411133 seconds
INFO 01-14 20:42:24.630650.630650 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 78a224cd-9185-4b82-a0ab-81ce1a4d80d1
DEBUG 01-14 20:42:24.630877.630877 cuda_h.py:19] end load_into_gpu_async cost 0.00212860107421875 seconds
DEBUG 01-14 20:42:24.630011.630011 cuda_h.py:10] start restore_tensors2
DEBUG 01-14 20:42:24.631805.631805 cuda_h.py:19] end restore_tensors2 cost 0.00034618377685546875 seconds
DEBUG 01-14 20:42:24.631734.631734 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0054264068603515625 seconds
DEBUG 01-14 20:42:24.631404.631404 cuda_h.py:10] start restore2model
DEBUG 01-14 20:42:24.633327.633327 cuda_h.py:19] end restore2model cost 0.002611875534057617 seconds
DEBUG 01-14 20:42:24.634355.634355 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.00822305679321289 seconds
DEBUG 01-14 20:42:24.634674.634674 cuda_h.py:10] start gpu_sexperts
DEBUG 01-14 20:42:24.634817.634817 cuda_h.py:19] end gpu_sexperts cost 0.00026917457580566406 seconds
DEBUG 01-14 20:42:24.634832.634832 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-14 20:42:24.634965.634965 lmp.py:1683] 
DEBUG 01-14 20:42:24.634965.634965 lmp.py:1683]   Computing 32 experts on CPU...
DEBUG 01-14 20:42:24.634609.634609 cuda_h.py:19] end cpu_experts_submit cost 5.340576171875e-05 seconds
DEBUG 01-14 20:42:24.634643.634643 cuda_h.py:10] start experts_func_mgpu_group_pad
DEBUG 01-14 20:42:24.636536.636536 cuda_h.py:19] end experts_func_mgpu_group_pad cost 0.001504659652709961 seconds
DEBUG 01-14 20:42:24.636529.636529 cuda_h.py:10] start gpu_group_list
DEBUG 01-14 20:42:24.637555.637555 cuda_h.py:19] end gpu_group_list cost 0.00031447410583496094 seconds
DEBUG 01-14 20:42:24.637188.637188 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-14 20:42:24.637879.637879 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 1.4066696166992188e-05 seconds
DEBUG 01-14 20:42:24.637720.637720 cuda_h.py:10] start wait_experts
INFO 01-14 20:42:24.637086.637086 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 78a224cd-9185-4b82-a0ab-81ce1a4d80d1
DEBUG 01-14 20:42:24.637699.637699 mlpmodule.py:1367]  experts func einsum cost 0.08022379875183105 s
DEBUG 01-14 20:42:24.642113.642113 mlpmodule.py:1460] group tensors cost 0.004571676254272461 s
DEBUG 01-14 20:42:24.643798.643798 cuda_h.py:10] start move_flat_hidden2cpu
DEBUG 01-14 20:42:24.648609.648609 cuda_h.py:19] end move_flat_hidden2cpu cost 0.004975080490112305 seconds
DEBUG 01-14 20:42:24.649689.649689 mlpmodule.py:1533] pad cost 0.0015075206756591797 s
DEBUG 01-14 20:42:24.650918.650918 mlpmodule.py:1539] create cpu tensor cost 3.528594970703125e-05 s
DEBUG 01-14 20:42:24.652490.652490 mlpmodule.py:1544] move to cpu cost 0.0022125244140625 s
DEBUG 01-14 20:42:24.661896.661896 mlpmodule.py:1558] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-14 20:42:24.661881.661881 mlpmodule.py:1559] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-14 20:42:24.661242.661242 mlpmodule.py:1564] group_w3 first element: 0.000789642333984375
WARNING 01-14 20:42:24.662405.662405 mlpmodule.py:1574] start einsum2
DEBUG 01-14 20:42:24.679365.679365 mlpmodule.py:1584] group einsum cost 0.027463674545288086 s
DEBUG 01-14 20:42:24.680741.680741 mlpmodule.py:1593] cpy2cputensor cost 0.0007407665252685547 s
DEBUG 01-14 20:42:24.680902.680902 cuda_h.py:10] start move_outputs
DEBUG 01-14 20:42:24.683167.683167 cuda_h.py:19] end move_outputs cost 0.0029366016387939453 seconds
INFO 01-14 20:42:24.687592.687592 client.py:127] Model loaded
DEBUG 01-14 20:42:24.687061.687061 cuda_h.py:19] end wait_experts cost 0.05005955696105957 seconds
DEBUG 01-14 20:42:24.687970.687970 cuda_h.py:10] start gpu_experts
DEBUG 01-14 20:42:24.687462.687462 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-14 20:42:24.687372.687372 cuda_h.py:19] end wait_cetm_experts cost 0.0002505779266357422 seconds
DEBUG 01-14 20:42:24.688972.688972 cuda_h.py:10] start gpu_group_einsum_mp_multi_list
DEBUG 01-14 20:42:24.688524.688524 cuda_h.py:10] start gpu_group_tensor
DEBUG 01-14 20:42:24.688868.688868 cuda_h.py:19] end gpu_group_tensor cost 0.0003466606140136719 seconds
DEBUG 01-14 20:42:24.688960.688960 cuda_h.py:10] start gpu_group_einsum
DEBUG 01-14 20:42:24.689589.689589 cuda_h.py:19] end gpu_group_einsum cost 0.0007121562957763672 seconds
DEBUG 01-14 20:42:24.689024.689024 cuda_h.py:10] start gpu_final_hidden_states_scatter
DEBUG 01-14 20:42:24.689596.689596 cuda_h.py:10] start all_expert_outputs_slices
DEBUG 01-14 20:42:24.690285.690285 cuda_h.py:19] end all_expert_outputs_slices cost 0.0003643035888671875 seconds
DEBUG 01-14 20:42:24.690394.690394 cuda_h.py:10] start concat_expert_out
DEBUG 01-14 20:42:24.690397.690397 cuda_h.py:19] end concat_expert_out cost 6.604194641113281e-05 seconds
DEBUG 01-14 20:42:24.690347.690347 cuda_h.py:10] start index_scatter
DEBUG 01-14 20:42:24.690827.690827 cuda_h.py:19] end index_scatter cost 7.343292236328125e-05 seconds
DEBUG 01-14 20:42:24.690921.690921 cuda_h.py:19] end gpu_final_hidden_states_scatter cost 0.0008208751678466797 seconds
DEBUG 01-14 20:42:24.690897.690897 cuda_h.py:19] end gpu_experts cost 0.002935171127319336 seconds
DEBUG 01-14 20:42:24.690746.690746 cuda_h.py:10] start all_expert_weight_slices
DEBUG 01-14 20:42:24.691766.691766 cuda_h.py:19] end all_expert_weight_slices cost 0.0009665489196777344 seconds
DEBUG 01-14 20:42:24.691119.691119 cuda_h.py:10] start cpuoutputsdeal
DEBUG 01-14 20:42:24.692219.692219 cuda_h.py:10] start index_scatter
DEBUG 01-14 20:42:24.692348.692348 cuda_h.py:19] end index_scatter cost 4.792213439941406e-05 seconds
DEBUG 01-14 20:42:24.692879.692879 cuda_h.py:19] end cpuoutputsdeal cost 0.0005304813385009766 seconds
DEBUG 01-14 20:42:24.692935.692935 cuda_h.py:19] end layer_moe_generate_mp_l_15 cost 0.06891012191772461 seconds
DEBUG 01-14 20:42:24.692300.692300 cuda_h.py:19] end prefill_layer cost 0.07720208168029785 seconds
DEBUG 01-14 20:42:24.692712.692712 lmp.py:1551] -------------------------------- end prefill layer 14 --------------------------------
DEBUG 01-14 20:42:24.692846.692846 cuda_h.py:10] start prefill_layer
DEBUG 01-14 20:42:24.692264.692264 lmp.py:1494] -------------------------------- start prefill layer 15 --------------------------------
DEBUG 01-14 20:42:24.692874.692874 cuda_h.py:10] start start_load_qkvogn_s_weight_l_16
DEBUG 01-14 20:42:24.692438.692438 cuda_h.py:10] start start_load_qkvogn_s_weight_l_16
DEBUG 01-14 20:42:24.692414.692414 cuda_h.py:19] end start_load_qkvogn_s_weight_l_16 cost 5.936622619628906e-05 seconds
DEBUG 01-14 20:42:24.693376.693376 cuda_h.py:10] start sllm_worker_task
DEBUG 01-14 20:42:24.693564.693564 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-14 20:42:24.693963.693963 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-14 20:42:24.693178.693178 cuda_h.py:19] end start_load_qkvogn_s_weight_l_16 cost 0.0001347064971923828 seconds
DEBUG 01-14 20:42:24.697457.697457 cuda_h.py:19] end allocate_cuda_memory cost 0.004427433013916016 seconds
DEBUG 01-14 20:42:24.697085.697085 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-14 20:42:24.697804.697804 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-14 20:42:24.698082.698082 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-14 20:42:24.698421.698421 sllm_store_c.py:27] get device uuid map
DEBUG 01-14 20:42:24.698598.698598 sllm_store_c.py:29] call client load into gpu
DEBUG 01-14 20:42:24.698209.698209 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 4dd3e6a9-4547-4ad1-899a-7b507913967e
DEBUG 01-14 20:42:24.698417.698417 client.py:106] call stub.LoadModelAsync
DEBUG 01-14 20:42:24.698016.698016 cuda_h.py:10] start self_attn
INFO 01-14 20:42:24.699766.699766 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 4dd3e6a9-4547-4ad1-899a-7b507913967e
DEBUG 01-14 20:42:24.699649.699649 cuda_h.py:19] end load_into_gpu_async cost 0.0014698505401611328 seconds
DEBUG 01-14 20:42:24.699921.699921 cuda_h.py:10] start restore_tensors2
DEBUG 01-14 20:42:24.699712.699712 cuda_h.py:19] end restore_tensors2 cost 6.651878356933594e-05 seconds
DEBUG 01-14 20:42:24.699038.699038 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.006609678268432617 seconds
INFO 01-14 20:42:24.699304.699304 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 4dd3e6a9-4547-4ad1-899a-7b507913967e
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-14 20:42:24.701806.701806 cuda_h.py:19] end self_attn cost 0.0029363632202148438 seconds
DEBUG 01-14 20:42:24.702147.702147 cuda_h.py:19] end iln_self_attn_paln cost 0.004046201705932617 seconds
DEBUG 01-14 20:42:24.702627.702627 cuda_h.py:10] start layer_moe_generate_mp_l_16
DEBUG 01-14 20:42:24.702443.702443 cuda_h.py:10] start gate
DEBUG 01-14 20:42:24.702904.702904 cuda_h.py:19] end gate cost 0.0006890296936035156 seconds
DEBUG 01-14 20:42:24.702570.702570 mlpmodule.py:1367]  experts func einsum cost 0.06472373008728027 s
DEBUG 01-14 20:42:24.703605.703605 cuda_h.py:10] start experts_map_get
DEBUG 01-14 20:42:24.703330.703330 lmp.py:1615] 
DEBUG 01-14 20:42:24.703330.703330 lmp.py:1615] Expert Token Distribution & Device Allocation:
DEBUG 01-14 20:42:24.703405.703405 lmp.py:1616]   Total experts: 64
DEBUG 01-14 20:42:24.703830.703830 lmp.py:1617]   CPU experts: 32 (50%)
DEBUG 01-14 20:42:24.703010.703010 lmp.py:1618]   GPU experts: 32 (50%)
DEBUG 01-14 20:42:24.703805.703805 lmp.py:1619] 
DEBUG 01-14 20:42:24.703805.703805 lmp.py:1619]   Expert ID | Tokens | Device
DEBUG 01-14 20:42:24.703170.703170 lmp.py:1620]   -----------------------------------
DEBUG 01-14 20:42:24.703919.703919 lmp.py:1625]   Expert 20 |     71 | CPU
DEBUG 01-14 20:42:24.703523.703523 lmp.py:1625]   Expert  0 |     73 | CPU
DEBUG 01-14 20:42:24.703934.703934 lmp.py:1625]   Expert 15 |     82 | CPU
DEBUG 01-14 20:42:24.703299.703299 lmp.py:1625]   Expert  7 |     83 | CPU
DEBUG 01-14 20:42:24.703903.703903 lmp.py:1625]   Expert 63 |     84 | CPU
DEBUG 01-14 20:42:24.703552.703552 lmp.py:1625]   Expert 28 |     86 | CPU
DEBUG 01-14 20:42:24.703917.703917 lmp.py:1625]   Expert 52 |     87 | CPU
DEBUG 01-14 20:42:24.703567.703567 lmp.py:1625]   Expert 41 |     88 | CPU
DEBUG 01-14 20:42:24.703217.703217 lmp.py:1625]   Expert 45 |     90 | CPU
DEBUG 01-14 20:42:24.703867.703867 lmp.py:1625]   Expert 54 |    106 | CPU
DEBUG 01-14 20:42:24.703516.703516 lmp.py:1625]   Expert 12 |    110 | CPU
DEBUG 01-14 20:42:24.703928.703928 lmp.py:1625]   Expert 21 |    116 | CPU
DEBUG 01-14 20:42:24.703293.703293 lmp.py:1625]   Expert 62 |    117 | CPU
DEBUG 01-14 20:42:24.703181.703181 lmp.py:1625]   Expert 59 |    119 | CPU
DEBUG 01-14 20:42:24.704308.704308 lmp.py:1625]   Expert 55 |    124 | CPU
DEBUG 01-14 20:42:24.704957.704957 lmp.py:1625]   Expert  5 |    129 | CPU
DEBUG 01-14 20:42:24.704369.704369 lmp.py:1625]   Expert 14 |    139 | CPU
DEBUG 01-14 20:42:24.704303.704303 lmp.py:1625]   Expert 34 |    142 | CPU
DEBUG 01-14 20:42:24.704761.704761 lmp.py:1625]   Expert 13 |    150 | CPU
DEBUG 01-14 20:42:24.704457.704457 lmp.py:1625]   Expert  4 |    151 | CPU
DEBUG 01-14 20:42:24.704584.704584 lmp.py:1625]   Expert 51 |    151 | CPU
DEBUG 01-14 20:42:24.704472.704472 lmp.py:1625]   Expert  1 |    154 | CPU
DEBUG 01-14 20:42:24.704122.704122 lmp.py:1625]   Expert 40 |    157 | CPU
DEBUG 01-14 20:42:24.704010.704010 lmp.py:1625]   Expert 61 |    157 | CPU
DEBUG 01-14 20:42:24.704898.704898 lmp.py:1625]   Expert 16 |    166 | CPU
DEBUG 01-14 20:42:24.704309.704309 lmp.py:1625]   Expert 32 |    166 | CPU
DEBUG 01-14 20:42:24.704005.704005 lmp.py:1625]   Expert 10 |    167 | CPU
DEBUG 01-14 20:42:24.704940.704940 lmp.py:1625]   Expert 22 |    168 | CPU
DEBUG 01-14 20:42:24.704113.704113 lmp.py:1625]   Expert  2 |    170 | CPU
DEBUG 01-14 20:42:24.704570.704570 lmp.py:1625]   Expert 42 |    170 | CPU
DEBUG 01-14 20:42:24.704267.704267 lmp.py:1625]   Expert 44 |    170 | CPU
DEBUG 01-14 20:42:24.704976.704976 lmp.py:1625]   Expert  6 |    173 | CPU
DEBUG 01-14 20:42:24.704527.704527 lmp.py:1625]   Expert 11 |    174 | GPU
DEBUG 01-14 20:42:24.704461.704461 lmp.py:1625]   Expert 25 |    181 | GPU
DEBUG 01-14 20:42:24.704872.704872 lmp.py:1625]   Expert 19 |    183 | GPU
DEBUG 01-14 20:42:24.704522.704522 lmp.py:1625]   Expert 30 |    183 | GPU
DEBUG 01-14 20:42:24.704410.704410 lmp.py:1625]   Expert 35 |    185 | GPU
DEBUG 01-14 20:42:24.704106.704106 lmp.py:1625]   Expert 53 |    185 | GPU
DEBUG 01-14 20:42:24.704803.704803 lmp.py:1625]   Expert 56 |    187 | GPU
DEBUG 01-14 20:42:24.704975.704975 lmp.py:1625]   Expert 26 |    188 | GPU
DEBUG 01-14 20:42:24.704433.704433 lmp.py:1625]   Expert 47 |    189 | GPU
DEBUG 01-14 20:42:24.704414.704414 lmp.py:1625]   Expert 24 |    196 | GPU
DEBUG 01-14 20:42:24.704441.704441 lmp.py:1625]   Expert 57 |    205 | GPU
DEBUG 01-14 20:42:24.704660.704660 lmp.py:1625]   Expert 46 |    223 | GPU
DEBUG 01-14 20:42:24.704926.704926 lmp.py:1625]   Expert 48 |    226 | GPU
DEBUG 01-14 20:42:24.704622.704622 lmp.py:1625]   Expert 50 |    226 | GPU
DEBUG 01-14 20:42:24.704603.704603 lmp.py:1625]   Expert 39 |    234 | GPU
DEBUG 01-14 20:42:24.704822.704822 lmp.py:1625]   Expert 37 |    237 | GPU
DEBUG 01-14 20:42:24.704849.704849 lmp.py:1625]   Expert  3 |    240 | GPU
DEBUG 01-14 20:42:24.704830.704830 lmp.py:1625]   Expert 18 |    240 | GPU
DEBUG 01-14 20:42:24.704096.704096 lmp.py:1625]   Expert 29 |    250 | GPU
DEBUG 01-14 20:42:24.704315.704315 lmp.py:1625]   Expert 60 |    255 | GPU
DEBUG 01-14 20:42:24.704865.704865 lmp.py:1625]   Expert 31 |    258 | GPU
DEBUG 01-14 20:42:24.704323.704323 lmp.py:1625]   Expert 23 |    259 | GPU
DEBUG 01-14 20:42:24.704635.704635 lmp.py:1625]   Expert 36 |    259 | GPU
DEBUG 01-14 20:42:24.704616.704616 lmp.py:1625]   Expert 17 |    263 | GPU
DEBUG 01-14 20:42:24.704404.704404 lmp.py:1625]   Expert 38 |    264 | GPU
DEBUG 01-14 20:42:24.704339.704339 lmp.py:1625]   Expert  9 |    274 | GPU
DEBUG 01-14 20:42:24.704081.704081 lmp.py:1625]   Expert  8 |    289 | GPU
DEBUG 01-14 20:42:24.704254.704254 lmp.py:1625]   Expert 27 |    325 | GPU
DEBUG 01-14 20:42:24.705235.705235 lmp.py:1625]   Expert 43 |    373 | GPU
DEBUG 01-14 20:42:24.705693.705693 lmp.py:1625]   Expert 33 |    414 | GPU
DEBUG 01-14 20:42:24.705958.705958 lmp.py:1625]   Expert 58 |    479 | GPU
DEBUG 01-14 20:42:24.705416.705416 lmp.py:1625]   Expert 49 |    528 | GPU
DEBUG 01-14 20:42:24.705397.705397 lmp.py:1626] 
DEBUG 01-14 20:42:24.705397.705397 lmp.py:1626]   CPU total tokens: 4116 (33.5%)
DEBUG 01-14 20:42:24.705047.705047 lmp.py:1627]   GPU total tokens: 8172 (66.5%)
DEBUG 01-14 20:42:24.705372.705372 cuda_h.py:19] end experts_map_get cost 0.0019731521606445312 seconds
DEBUG 01-14 20:42:24.705242.705242 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-14 20:42:24.705053.705053 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-14 20:42:24.705210.705210 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-14 20:42:24.706964.706964 cuda_h.py:19] end allocate_cuda_memory cost 0.0013260841369628906 seconds
DEBUG 01-14 20:42:24.706795.706795 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-14 20:42:24.706055.706055 sllm_store_c.py:27] get device uuid map
DEBUG 01-14 20:42:24.706394.706394 sllm_store_c.py:29] call client load into gpu
DEBUG 01-14 20:42:24.707289.707289 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, e0bdcc14-ef88-430f-b225-6357f6c273fc
DEBUG 01-14 20:42:24.707097.707097 client.py:106] call stub.LoadModelAsync
INFO 01-14 20:42:24.707502.707502 client.py:127] Model loaded
DEBUG 01-14 20:42:24.707855.707855 cuda_h.py:10] start restore2model
DEBUG 01-14 20:42:24.707913.707913 cuda_h.py:19] end restore2model cost 0.00032973289489746094 seconds
DEBUG 01-14 20:42:24.707060.707060 cuda_h.py:19] end sllm_worker_task cost 0.014833688735961914 seconds
INFO 01-14 20:42:24.708489.708489 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, e0bdcc14-ef88-430f-b225-6357f6c273fc
DEBUG 01-14 20:42:24.708485.708485 cuda_h.py:19] end load_into_gpu_async cost 0.0013730525970458984 seconds
DEBUG 01-14 20:42:24.708671.708671 cuda_h.py:10] start restore_tensors2
DEBUG 01-14 20:42:24.708454.708454 cuda_h.py:19] end restore_tensors2 cost 0.0003726482391357422 seconds
DEBUG 01-14 20:42:24.708774.708774 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0035240650177001953 seconds
DEBUG 01-14 20:42:24.708067.708067 cuda_h.py:10] start restore2model
DEBUG 01-14 20:42:24.711696.711696 cuda_h.py:19] end restore2model cost 0.002924203872680664 seconds
DEBUG 01-14 20:42:24.711572.711572 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.006634950637817383 seconds
DEBUG 01-14 20:42:24.711937.711937 cuda_h.py:10] start gpu_sexperts
DEBUG 01-14 20:42:24.712265.712265 cuda_h.py:19] end gpu_sexperts cost 0.00028228759765625 seconds
DEBUG 01-14 20:42:24.712088.712088 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-14 20:42:24.712652.712652 lmp.py:1683] 
DEBUG 01-14 20:42:24.712652.712652 lmp.py:1683]   Computing 32 experts on CPU...
DEBUG 01-14 20:42:24.712680.712680 cuda_h.py:19] end cpu_experts_submit cost 5.5789947509765625e-05 seconds
DEBUG 01-14 20:42:24.712265.712265 cuda_h.py:10] start experts_func_mgpu_group_pad
DEBUG 01-14 20:42:24.717539.717539 mlpmodule.py:1460] group tensors cost 0.004632711410522461 s
DEBUG 01-14 20:42:24.718944.718944 cuda_h.py:10] start move_flat_hidden2cpu
DEBUG 01-14 20:42:24.720051.720051 cuda_h.py:19] end experts_func_mgpu_group_pad cost 0.007575035095214844 seconds
DEBUG 01-14 20:42:24.721461.721461 cuda_h.py:10] start gpu_group_list
DEBUG 01-14 20:42:24.722842.722842 cuda_h.py:19] end gpu_group_list cost 0.00041961669921875 seconds
DEBUG 01-14 20:42:24.722874.722874 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-14 20:42:24.722492.722492 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 1.811981201171875e-05 seconds
DEBUG 01-14 20:42:24.722009.722009 cuda_h.py:10] start wait_experts
INFO 01-14 20:42:24.722004.722004 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, e0bdcc14-ef88-430f-b225-6357f6c273fc
DEBUG 01-14 20:42:24.724869.724869 cuda_h.py:19] end move_flat_hidden2cpu cost 0.0064029693603515625 seconds
DEBUG 01-14 20:42:24.726571.726571 mlpmodule.py:1533] pad cost 0.00167083740234375 s
DEBUG 01-14 20:42:24.726138.726138 mlpmodule.py:1539] create cpu tensor cost 3.528594970703125e-05 s
DEBUG 01-14 20:42:24.728909.728909 mlpmodule.py:1544] move to cpu cost 0.002044200897216797 s
DEBUG 01-14 20:42:24.737700.737700 mlpmodule.py:1558] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-14 20:42:24.737501.737501 mlpmodule.py:1559] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-14 20:42:24.737908.737908 mlpmodule.py:1564] group_w3 first element: -0.0595703125
WARNING 01-14 20:42:24.738402.738402 mlpmodule.py:1574] start einsum2
DEBUG 01-14 20:42:24.754099.754099 mlpmodule.py:1584] group einsum cost 0.026146650314331055 s
DEBUG 01-14 20:42:24.755926.755926 mlpmodule.py:1593] cpy2cputensor cost 0.0007653236389160156 s
DEBUG 01-14 20:42:24.755510.755510 cuda_h.py:10] start move_outputs
DEBUG 01-14 20:42:24.758294.758294 cuda_h.py:19] end move_outputs cost 0.002825021743774414 seconds
INFO 01-14 20:42:24.765718.765718 client.py:127] Model loaded
DEBUG 01-14 20:42:24.765763.765763 cuda_h.py:19] end wait_experts cost 0.04323554039001465 seconds
DEBUG 01-14 20:42:24.765818.765818 cuda_h.py:10] start gpu_experts
DEBUG 01-14 20:42:24.765018.765018 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-14 20:42:24.765787.765787 cuda_h.py:19] end wait_cetm_experts cost 0.0001838207244873047 seconds
DEBUG 01-14 20:42:24.766882.766882 cuda_h.py:10] start gpu_group_einsum_mp_multi_list
DEBUG 01-14 20:42:24.766830.766830 cuda_h.py:10] start gpu_group_tensor
DEBUG 01-14 20:42:24.766567.766567 cuda_h.py:19] end gpu_group_tensor cost 0.0002315044403076172 seconds
DEBUG 01-14 20:42:24.766631.766631 cuda_h.py:10] start gpu_group_einsum
DEBUG 01-14 20:42:24.767305.767305 cuda_h.py:19] end gpu_group_einsum cost 0.0006892681121826172 seconds
DEBUG 01-14 20:42:24.767117.767117 cuda_h.py:10] start gpu_final_hidden_states_scatter
DEBUG 01-14 20:42:24.767590.767590 cuda_h.py:10] start all_expert_outputs_slices
DEBUG 01-14 20:42:24.767623.767623 cuda_h.py:19] end all_expert_outputs_slices cost 0.0003726482391357422 seconds
DEBUG 01-14 20:42:24.767095.767095 cuda_h.py:10] start concat_expert_out
DEBUG 01-14 20:42:24.767270.767270 cuda_h.py:19] end concat_expert_out cost 5.7697296142578125e-05 seconds
DEBUG 01-14 20:42:24.768835.768835 cuda_h.py:10] start index_scatter
DEBUG 01-14 20:42:24.768454.768454 cuda_h.py:19] end index_scatter cost 7.271766662597656e-05 seconds
DEBUG 01-14 20:42:24.768879.768879 cuda_h.py:19] end gpu_final_hidden_states_scatter cost 0.0007588863372802734 seconds
DEBUG 01-14 20:42:24.768895.768895 cuda_h.py:19] end gpu_experts cost 0.0024864673614501953 seconds
DEBUG 01-14 20:42:24.768552.768552 cuda_h.py:10] start all_expert_weight_slices
DEBUG 01-14 20:42:24.769479.769479 cuda_h.py:19] end all_expert_weight_slices cost 0.0009620189666748047 seconds
DEBUG 01-14 20:42:24.769971.769971 cuda_h.py:10] start cpuoutputsdeal
DEBUG 01-14 20:42:24.769979.769979 cuda_h.py:10] start index_scatter
DEBUG 01-14 20:42:24.769300.769300 cuda_h.py:19] end index_scatter cost 4.76837158203125e-05 seconds
DEBUG 01-14 20:42:24.769016.769016 cuda_h.py:19] end cpuoutputsdeal cost 0.0005292892456054688 seconds
DEBUG 01-14 20:42:24.769972.769972 cuda_h.py:19] end layer_moe_generate_mp_l_16 cost 0.06784605979919434 seconds
DEBUG 01-14 20:42:24.770919.770919 cuda_h.py:19] end prefill_layer cost 0.07751607894897461 seconds
DEBUG 01-14 20:42:24.770901.770901 lmp.py:1551] -------------------------------- end prefill layer 15 --------------------------------
DEBUG 01-14 20:42:24.770697.770697 cuda_h.py:10] start prefill_layer
DEBUG 01-14 20:42:24.770777.770777 lmp.py:1494] -------------------------------- start prefill layer 16 --------------------------------
DEBUG 01-14 20:42:24.770142.770142 cuda_h.py:10] start start_load_qkvogn_s_weight_l_17
DEBUG 01-14 20:42:24.770368.770368 cuda_h.py:10] start start_load_qkvogn_s_weight_l_17
DEBUG 01-14 20:42:24.770727.770727 cuda_h.py:19] end start_load_qkvogn_s_weight_l_17 cost 3.075599670410156e-05 seconds
DEBUG 01-14 20:42:24.770430.770430 cuda_h.py:19] end start_load_qkvogn_s_weight_l_17 cost 5.888938903808594e-05 seconds
DEBUG 01-14 20:42:24.770504.770504 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-14 20:42:24.770566.770566 cuda_h.py:10] start sllm_worker_task
DEBUG 01-14 20:42:24.770187.770187 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-14 20:42:24.770817.770817 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-14 20:42:24.771862.771862 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-14 20:42:24.771555.771555 cuda_h.py:19] end allocate_cuda_memory cost 0.0008862018585205078 seconds
DEBUG 01-14 20:42:24.772154.772154 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-14 20:42:24.772917.772917 sllm_store_c.py:27] get device uuid map
DEBUG 01-14 20:42:24.772316.772316 sllm_store_c.py:29] call client load into gpu
DEBUG 01-14 20:42:24.772257.772257 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 2f3e6663-e6f2-4aff-b1af-4834d732a4be
DEBUG 01-14 20:42:24.772134.772134 client.py:106] call stub.LoadModelAsync
DEBUG 01-14 20:42:24.772645.772645 cuda_h.py:10] start self_attn
INFO 01-14 20:42:24.773197.773197 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 2f3e6663-e6f2-4aff-b1af-4834d732a4be
DEBUG 01-14 20:42:24.773756.773756 cuda_h.py:19] end load_into_gpu_async cost 0.001705169677734375 seconds
DEBUG 01-14 20:42:24.773982.773982 cuda_h.py:10] start restore_tensors2
DEBUG 01-14 20:42:24.773210.773210 cuda_h.py:19] end restore_tensors2 cost 7.081031799316406e-05 seconds
DEBUG 01-14 20:42:24.773158.773158 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.002953767776489258 seconds
INFO 01-14 20:42:24.773041.773041 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 2f3e6663-e6f2-4aff-b1af-4834d732a4be
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-14 20:42:24.775083.775083 cuda_h.py:19] end self_attn cost 0.002922534942626953 seconds
DEBUG 01-14 20:42:24.775060.775060 cuda_h.py:19] end iln_self_attn_paln cost 0.005294322967529297 seconds
DEBUG 01-14 20:42:24.775088.775088 cuda_h.py:10] start layer_moe_generate_mp_l_17
DEBUG 01-14 20:42:24.776705.776705 cuda_h.py:10] start gate
DEBUG 01-14 20:42:24.776131.776131 cuda_h.py:19] end gate cost 0.0006322860717773438 seconds
DEBUG 01-14 20:42:24.776245.776245 cuda_h.py:10] start experts_map_get
DEBUG 01-14 20:42:24.777514.777514 lmp.py:1615] 
DEBUG 01-14 20:42:24.777514.777514 lmp.py:1615] Expert Token Distribution & Device Allocation:
DEBUG 01-14 20:42:24.777747.777747 lmp.py:1616]   Total experts: 64
DEBUG 01-14 20:42:24.777118.777118 lmp.py:1617]   CPU experts: 32 (50%)
DEBUG 01-14 20:42:24.777146.777146 lmp.py:1618]   GPU experts: 32 (50%)
DEBUG 01-14 20:42:24.777550.777550 lmp.py:1619] 
DEBUG 01-14 20:42:24.777550.777550 lmp.py:1619]   Expert ID | Tokens | Device
DEBUG 01-14 20:42:24.777670.777670 lmp.py:1620]   -----------------------------------
DEBUG 01-14 20:42:24.777028.777028 lmp.py:1625]   Expert 45 |     49 | CPU
DEBUG 01-14 20:42:24.777453.777453 lmp.py:1625]   Expert 58 |     49 | CPU
DEBUG 01-14 20:42:24.777580.777580 lmp.py:1625]   Expert 49 |     66 | CPU
DEBUG 01-14 20:42:24.777415.777415 lmp.py:1625]   Expert  4 |     68 | CPU
DEBUG 01-14 20:42:24.777488.777488 lmp.py:1625]   Expert 31 |     69 | CPU
DEBUG 01-14 20:42:24.777608.777608 lmp.py:1625]   Expert 43 |     73 | CPU
DEBUG 01-14 20:42:24.777490.777490 lmp.py:1625]   Expert 38 |     74 | CPU
DEBUG 01-14 20:42:24.777325.777325 lmp.py:1625]   Expert 41 |     74 | CPU
DEBUG 01-14 20:42:24.777444.777444 lmp.py:1625]   Expert 47 |     78 | CPU
DEBUG 01-14 20:42:24.777803.777803 lmp.py:1625]   Expert 14 |     98 | CPU
DEBUG 01-14 20:42:24.777876.777876 lmp.py:1625]   Expert  0 |    100 | CPU
DEBUG 01-14 20:42:24.777996.777996 lmp.py:1625]   Expert 57 |    101 | CPU
DEBUG 01-14 20:42:24.777877.777877 lmp.py:1625]   Expert 51 |    102 | CPU
DEBUG 01-14 20:42:24.777295.777295 lmp.py:1625]   Expert 26 |    111 | CPU
DEBUG 01-14 20:42:24.777654.777654 lmp.py:1625]   Expert  2 |    114 | CPU
DEBUG 01-14 20:42:24.777297.777297 lmp.py:1625]   Expert 11 |    114 | CPU
DEBUG 01-14 20:42:24.777178.777178 lmp.py:1625]   Expert 33 |    114 | CPU
DEBUG 01-14 20:42:24.777252.777252 lmp.py:1625]   Expert 50 |    115 | CPU
DEBUG 01-14 20:42:24.777848.777848 lmp.py:1625]   Expert 27 |    130 | CPU
DEBUG 01-14 20:42:24.777922.777922 lmp.py:1625]   Expert 55 |    137 | CPU
DEBUG 01-14 20:42:24.777234.777234 lmp.py:1625]   Expert 34 |    152 | CPU
DEBUG 01-14 20:42:24.777353.777353 lmp.py:1625]   Expert 28 |    155 | CPU
DEBUG 01-14 20:42:24.777712.777712 lmp.py:1625]   Expert 25 |    158 | CPU
DEBUG 01-14 20:42:24.777593.777593 lmp.py:1625]   Expert  9 |    167 | CPU
DEBUG 01-14 20:42:24.777951.777951 lmp.py:1625]   Expert 54 |    174 | CPU
DEBUG 01-14 20:42:24.777594.777594 lmp.py:1625]   Expert 13 |    175 | CPU
DEBUG 01-14 20:42:24.777714.777714 lmp.py:1625]   Expert 56 |    181 | CPU
DEBUG 01-14 20:42:24.777357.777357 lmp.py:1625]   Expert 48 |    182 | CPU
DEBUG 01-14 20:42:24.777715.777715 lmp.py:1625]   Expert  6 |    183 | CPU
DEBUG 01-14 20:42:24.777073.777073 lmp.py:1625]   Expert 10 |    187 | CPU
DEBUG 01-14 20:42:24.777909.777909 lmp.py:1625]   Expert  7 |    188 | CPU
DEBUG 01-14 20:42:24.777505.777505 lmp.py:1625]   Expert 46 |    196 | CPU
DEBUG 01-14 20:42:24.777102.777102 lmp.py:1625]   Expert 61 |    199 | GPU
DEBUG 01-14 20:42:24.777460.777460 lmp.py:1625]   Expert 24 |    200 | GPU
DEBUG 01-14 20:42:24.777818.777818 lmp.py:1625]   Expert 40 |    201 | GPU
DEBUG 01-14 20:42:24.777700.777700 lmp.py:1625]   Expert 29 |    203 | GPU
DEBUG 01-14 20:42:24.777581.777581 lmp.py:1625]   Expert 63 |    210 | GPU
DEBUG 01-14 20:42:24.777462.777462 lmp.py:1625]   Expert 42 |    216 | GPU
DEBUG 01-14 20:42:24.777582.777582 lmp.py:1625]   Expert 21 |    218 | GPU
DEBUG 01-14 20:42:24.777702.777702 lmp.py:1625]   Expert 18 |    221 | GPU
DEBUG 01-14 20:42:24.777822.777822 lmp.py:1625]   Expert  1 |    224 | GPU
DEBUG 01-14 20:42:24.777419.777419 lmp.py:1625]   Expert 22 |    224 | GPU
DEBUG 01-14 20:42:24.777492.777492 lmp.py:1625]   Expert 12 |    226 | GPU
DEBUG 01-14 20:42:24.777850.777850 lmp.py:1625]   Expert 16 |    229 | GPU
DEBUG 01-14 20:42:24.777924.777924 lmp.py:1625]   Expert 32 |    235 | GPU
DEBUG 01-14 20:42:24.778520.778520 lmp.py:1625]   Expert 39 |    235 | GPU
DEBUG 01-14 20:42:24.778117.778117 lmp.py:1625]   Expert  3 |    236 | GPU
DEBUG 01-14 20:42:24.778714.778714 lmp.py:1625]   Expert 19 |    239 | GPU
DEBUG 01-14 20:42:24.778834.778834 lmp.py:1625]   Expert 36 |    243 | GPU
DEBUG 01-14 20:42:24.778953.778953 lmp.py:1625]   Expert 59 |    243 | GPU
DEBUG 01-14 20:42:24.778550.778550 lmp.py:1625]   Expert 37 |    249 | GPU
DEBUG 01-14 20:42:24.778670.778670 lmp.py:1625]   Expert  8 |    253 | GPU
DEBUG 01-14 20:42:24.778790.778790 lmp.py:1625]   Expert  5 |    255 | GPU
DEBUG 01-14 20:42:24.778625.778625 lmp.py:1625]   Expert 20 |    262 | GPU
DEBUG 01-14 20:42:24.778698.778698 lmp.py:1625]   Expert 30 |    275 | GPU
DEBUG 01-14 20:42:24.778295.778295 lmp.py:1625]   Expert 62 |    284 | GPU
DEBUG 01-14 20:42:24.778130.778130 lmp.py:1625]   Expert 35 |    294 | GPU
DEBUG 01-14 20:42:24.778488.778488 lmp.py:1625]   Expert 15 |    295 | GPU
DEBUG 01-14 20:42:24.778846.778846 lmp.py:1625]   Expert 17 |    304 | GPU
DEBUG 01-14 20:42:24.778489.778489 lmp.py:1625]   Expert 60 |    332 | GPU
DEBUG 01-14 20:42:24.778848.778848 lmp.py:1625]   Expert 23 |    352 | GPU
DEBUG 01-14 20:42:24.778206.778206 lmp.py:1625]   Expert 52 |    363 | GPU
DEBUG 01-14 20:42:24.778041.778041 lmp.py:1625]   Expert 44 |    397 | GPU
DEBUG 01-14 20:42:24.778637.778637 lmp.py:1625]   Expert 53 |    437 | GPU
DEBUG 01-14 20:42:24.778188.778188 lmp.py:1626] 
DEBUG 01-14 20:42:24.778188.778188 lmp.py:1626]   CPU total tokens: 3934 (32.0%)
DEBUG 01-14 20:42:24.778453.778453 lmp.py:1627]   GPU total tokens: 8354 (68.0%)
DEBUG 01-14 20:42:24.778772.778772 cuda_h.py:19] end experts_map_get cost 0.0016586780548095703 seconds
DEBUG 01-14 20:42:24.778663.778663 mlpmodule.py:1367]  experts func einsum cost 0.06569671630859375 s
DEBUG 01-14 20:42:24.778004.778004 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-14 20:42:24.778189.778189 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-14 20:42:24.778764.778764 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-14 20:42:24.780612.780612 cuda_h.py:19] end allocate_cuda_memory cost 0.0019545555114746094 seconds
DEBUG 01-14 20:42:24.781893.781893 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-14 20:42:24.781364.781364 sllm_store_c.py:27] get device uuid map
DEBUG 01-14 20:42:24.781888.781888 sllm_store_c.py:29] call client load into gpu
DEBUG 01-14 20:42:24.781969.781969 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 13118163-17fb-49d0-bc83-6d3a65379771
DEBUG 01-14 20:42:24.781035.781035 client.py:106] call stub.LoadModelAsync
INFO 01-14 20:42:24.781268.781268 client.py:127] Model loaded
DEBUG 01-14 20:42:24.781310.781310 cuda_h.py:10] start restore2model
DEBUG 01-14 20:42:24.782081.782081 cuda_h.py:19] end restore2model cost 0.0004215240478515625 seconds
DEBUG 01-14 20:42:24.782149.782149 cuda_h.py:19] end sllm_worker_task cost 0.01149129867553711 seconds
INFO 01-14 20:42:24.783414.783414 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 13118163-17fb-49d0-bc83-6d3a65379771
DEBUG 01-14 20:42:24.783449.783449 cuda_h.py:19] end load_into_gpu_async cost 0.002131223678588867 seconds
DEBUG 01-14 20:42:24.783205.783205 cuda_h.py:10] start restore_tensors2
DEBUG 01-14 20:42:24.783157.783157 cuda_h.py:19] end restore_tensors2 cost 0.0003235340118408203 seconds
DEBUG 01-14 20:42:24.783317.783317 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.004779338836669922 seconds
DEBUG 01-14 20:42:24.783272.783272 cuda_h.py:10] start restore2model
DEBUG 01-14 20:42:24.786314.786314 cuda_h.py:19] end restore2model cost 0.002599000930786133 seconds
DEBUG 01-14 20:42:24.786912.786912 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.0075931549072265625 seconds
DEBUG 01-14 20:42:24.786277.786277 cuda_h.py:10] start gpu_sexperts
DEBUG 01-14 20:42:24.786624.786624 cuda_h.py:19] end gpu_sexperts cost 0.0002624988555908203 seconds
DEBUG 01-14 20:42:24.786799.786799 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-14 20:42:24.786217.786217 lmp.py:1683] 
DEBUG 01-14 20:42:24.786217.786217 lmp.py:1683]   Computing 32 experts on CPU...
DEBUG 01-14 20:42:24.786768.786768 cuda_h.py:19] end cpu_experts_submit cost 5.5789947509765625e-05 seconds
DEBUG 01-14 20:42:24.786061.786061 cuda_h.py:10] start experts_func_mgpu_group_pad
DEBUG 01-14 20:42:24.797027.797027 mlpmodule.py:1460] group tensors cost 0.010180234909057617 s
DEBUG 01-14 20:42:24.798890.798890 cuda_h.py:10] start move_flat_hidden2cpu
DEBUG 01-14 20:42:24.803125.803125 cuda_h.py:19] end experts_func_mgpu_group_pad cost 0.016068220138549805 seconds
DEBUG 01-14 20:42:24.804808.804808 cuda_h.py:19] end move_flat_hidden2cpu cost 0.006543874740600586 seconds
DEBUG 01-14 20:42:24.806109.806109 cuda_h.py:10] start gpu_group_list
DEBUG 01-14 20:42:24.808657.808657 cuda_h.py:19] end gpu_group_list cost 0.0011401176452636719 seconds
DEBUG 01-14 20:42:24.808765.808765 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-14 20:42:24.808236.808236 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 4.029273986816406e-05 seconds
DEBUG 01-14 20:42:24.808955.808955 cuda_h.py:10] start wait_experts
INFO 01-14 20:42:24.809216.809216 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 13118163-17fb-49d0-bc83-6d3a65379771
DEBUG 01-14 20:42:24.809728.809728 mlpmodule.py:1533] pad cost 0.0048105716705322266 s
DEBUG 01-14 20:42:24.809567.809567 mlpmodule.py:1539] create cpu tensor cost 3.814697265625e-05 s
DEBUG 01-14 20:42:24.812083.812083 mlpmodule.py:1544] move to cpu cost 0.0023093223571777344 s
DEBUG 01-14 20:42:24.822132.822132 mlpmodule.py:1558] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-14 20:42:24.822210.822210 mlpmodule.py:1559] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-14 20:42:24.822677.822677 mlpmodule.py:1564] group_w3 first element: -0.02490234375
WARNING 01-14 20:42:24.822264.822264 mlpmodule.py:1574] start einsum2
INFO 01-14 20:42:24.837132.837132 client.py:127] Model loaded
DEBUG 01-14 20:42:24.837517.837517 cuda_h.py:19] end wait_experts cost 0.028357267379760742 seconds
DEBUG 01-14 20:42:24.837918.837918 cuda_h.py:10] start gpu_experts
DEBUG 01-14 20:42:24.837059.837059 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-14 20:42:24.840704.840704 mlpmodule.py:1584] group einsum cost 0.028364896774291992 s
DEBUG 01-14 20:42:24.841917.841917 mlpmodule.py:1593] cpy2cputensor cost 0.0008308887481689453 s
DEBUG 01-14 20:42:24.841886.841886 cuda_h.py:10] start move_outputs
DEBUG 01-14 20:42:24.844075.844075 cuda_h.py:19] end move_outputs cost 0.002250194549560547 seconds
DEBUG 01-14 20:42:24.847531.847531 cuda_h.py:19] end wait_cetm_experts cost 0.010048389434814453 seconds
DEBUG 01-14 20:42:24.847611.847611 cuda_h.py:10] start gpu_group_einsum_mp_multi_list
DEBUG 01-14 20:42:24.848288.848288 cuda_h.py:10] start gpu_group_tensor
DEBUG 01-14 20:42:24.848661.848661 cuda_h.py:19] end gpu_group_tensor cost 0.00024127960205078125 seconds
DEBUG 01-14 20:42:24.848085.848085 cuda_h.py:10] start gpu_group_einsum
DEBUG 01-14 20:42:24.849713.849713 cuda_h.py:19] end gpu_group_einsum cost 0.0006806850433349609 seconds
DEBUG 01-14 20:42:24.849870.849870 cuda_h.py:10] start gpu_final_hidden_states_scatter
DEBUG 01-14 20:42:24.849727.849727 cuda_h.py:10] start all_expert_outputs_slices
DEBUG 01-14 20:42:24.849330.849330 cuda_h.py:19] end all_expert_outputs_slices cost 0.0003681182861328125 seconds
DEBUG 01-14 20:42:24.849655.849655 cuda_h.py:10] start concat_expert_out
DEBUG 01-14 20:42:24.849400.849400 cuda_h.py:19] end concat_expert_out cost 5.698204040527344e-05 seconds
DEBUG 01-14 20:42:24.850012.850012 cuda_h.py:10] start index_scatter
DEBUG 01-14 20:42:24.850677.850677 cuda_h.py:19] end index_scatter cost 7.176399230957031e-05 seconds
DEBUG 01-14 20:42:24.850010.850010 cuda_h.py:19] end gpu_final_hidden_states_scatter cost 0.0007557868957519531 seconds
DEBUG 01-14 20:42:24.850926.850926 cuda_h.py:19] end gpu_experts cost 0.012670516967773438 seconds
DEBUG 01-14 20:42:24.850821.850821 cuda_h.py:10] start all_expert_weight_slices
DEBUG 01-14 20:42:24.851701.851701 cuda_h.py:19] end all_expert_weight_slices cost 0.0009331703186035156 seconds
DEBUG 01-14 20:42:24.851424.851424 cuda_h.py:10] start cpuoutputsdeal
DEBUG 01-14 20:42:24.851101.851101 cuda_h.py:10] start index_scatter
DEBUG 01-14 20:42:24.851230.851230 cuda_h.py:19] end index_scatter cost 4.7206878662109375e-05 seconds
DEBUG 01-14 20:42:24.851900.851900 cuda_h.py:19] end cpuoutputsdeal cost 0.0005321502685546875 seconds
DEBUG 01-14 20:42:24.851379.851379 cuda_h.py:19] end layer_moe_generate_mp_l_17 cost 0.07592153549194336 seconds
DEBUG 01-14 20:42:24.852671.852671 cuda_h.py:19] end prefill_layer cost 0.08186960220336914 seconds
DEBUG 01-14 20:42:24.852215.852215 lmp.py:1551] -------------------------------- end prefill layer 16 --------------------------------
DEBUG 01-14 20:42:24.852741.852741 cuda_h.py:10] start prefill_layer
DEBUG 01-14 20:42:24.852351.852351 lmp.py:1494] -------------------------------- start prefill layer 17 --------------------------------
DEBUG 01-14 20:42:24.852292.852292 cuda_h.py:10] start start_load_qkvogn_s_weight_l_18
DEBUG 01-14 20:42:24.852856.852856 cuda_h.py:10] start start_load_qkvogn_s_weight_l_18
DEBUG 01-14 20:42:24.852660.852660 cuda_h.py:19] end start_load_qkvogn_s_weight_l_18 cost 3.814697265625e-05 seconds
DEBUG 01-14 20:42:24.852853.852853 cuda_h.py:19] end start_load_qkvogn_s_weight_l_18 cost 7.748603820800781e-05 seconds
DEBUG 01-14 20:42:24.852610.852610 cuda_h.py:10] start sllm_worker_task
DEBUG 01-14 20:42:24.852848.852848 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-14 20:42:24.852016.852016 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-14 20:42:24.852804.852804 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-14 20:42:24.853934.853934 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-14 20:42:24.857658.857658 cuda_h.py:19] end allocate_cuda_memory cost 0.004279136657714844 seconds
DEBUG 01-14 20:42:24.857183.857183 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-14 20:42:24.858746.858746 sllm_store_c.py:27] get device uuid map
DEBUG 01-14 20:42:24.858480.858480 sllm_store_c.py:29] call client load into gpu
DEBUG 01-14 20:42:24.858474.858474 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, ae0ea88e-217c-40d6-9fdf-047db3f2d724
DEBUG 01-14 20:42:24.858596.858596 client.py:106] call stub.LoadModelAsync
DEBUG 01-14 20:42:24.858136.858136 cuda_h.py:10] start self_attn
INFO 01-14 20:42:24.860147.860147 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, ae0ea88e-217c-40d6-9fdf-047db3f2d724
DEBUG 01-14 20:42:24.860321.860321 cuda_h.py:19] end load_into_gpu_async cost 0.0019533634185791016 seconds
DEBUG 01-14 20:42:24.860070.860070 cuda_h.py:10] start restore_tensors2
DEBUG 01-14 20:42:24.860544.860544 cuda_h.py:19] end restore_tensors2 cost 6.866455078125e-05 seconds
DEBUG 01-14 20:42:24.860823.860823 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.007308483123779297 seconds
INFO 01-14 20:42:24.860182.860182 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, ae0ea88e-217c-40d6-9fdf-047db3f2d724
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-14 20:42:24.861448.861448 cuda_h.py:19] end self_attn cost 0.0029392242431640625 seconds
DEBUG 01-14 20:42:24.862419.862419 cuda_h.py:19] end iln_self_attn_paln cost 0.00899505615234375 seconds
DEBUG 01-14 20:42:24.862865.862865 cuda_h.py:10] start layer_moe_generate_mp_l_18
DEBUG 01-14 20:42:24.862151.862151 cuda_h.py:10] start gate
DEBUG 01-14 20:42:24.862730.862730 cuda_h.py:19] end gate cost 0.0006392002105712891 seconds
DEBUG 01-14 20:42:24.862367.862367 cuda_h.py:10] start experts_map_get
DEBUG 01-14 20:42:24.863543.863543 lmp.py:1615] 
DEBUG 01-14 20:42:24.863543.863543 lmp.py:1615] Expert Token Distribution & Device Allocation:
DEBUG 01-14 20:42:24.863398.863398 lmp.py:1616]   Total experts: 64
DEBUG 01-14 20:42:24.863717.863717 lmp.py:1617]   CPU experts: 32 (50%)
DEBUG 01-14 20:42:24.863267.863267 lmp.py:1618]   GPU experts: 32 (50%)
DEBUG 01-14 20:42:24.863672.863672 lmp.py:1619] 
DEBUG 01-14 20:42:24.863672.863672 lmp.py:1619]   Expert ID | Tokens | Device
DEBUG 01-14 20:42:24.863792.863792 lmp.py:1620]   -----------------------------------
DEBUG 01-14 20:42:24.863150.863150 lmp.py:1625]   Expert  4 |     14 | CPU
DEBUG 01-14 20:42:24.863078.863078 lmp.py:1625]   Expert 28 |     39 | CPU
DEBUG 01-14 20:42:24.863290.863290 lmp.py:1625]   Expert  7 |     46 | CPU
DEBUG 01-14 20:42:24.863503.863503 lmp.py:1625]   Expert 53 |     61 | CPU
DEBUG 01-14 20:42:24.863954.863954 lmp.py:1625]   Expert 52 |     71 | CPU
DEBUG 01-14 20:42:24.863928.863928 lmp.py:1625]   Expert 43 |     82 | CPU
DEBUG 01-14 20:42:24.863140.863140 lmp.py:1625]   Expert 49 |     84 | CPU
DEBUG 01-14 20:42:24.863353.863353 lmp.py:1625]   Expert 12 |     91 | CPU
DEBUG 01-14 20:42:24.863757.863757 lmp.py:1625]   Expert 47 |     94 | CPU
DEBUG 01-14 20:42:24.863069.863069 lmp.py:1625]   Expert 15 |     97 | CPU
DEBUG 01-14 20:42:24.863335.863335 lmp.py:1625]   Expert 60 |     99 | CPU
DEBUG 01-14 20:42:24.863170.863170 lmp.py:1625]   Expert 33 |    109 | CPU
DEBUG 01-14 20:42:24.863958.863958 lmp.py:1625]   Expert 36 |    111 | CPU
DEBUG 01-14 20:42:24.863032.863032 lmp.py:1625]   Expert  2 |    113 | CPU
DEBUG 01-14 20:42:24.863344.863344 lmp.py:1625]   Expert 59 |    113 | CPU
DEBUG 01-14 20:42:24.863940.863940 lmp.py:1625]   Expert  6 |    118 | CPU
DEBUG 01-14 20:42:24.863776.863776 lmp.py:1625]   Expert 25 |    120 | CPU
DEBUG 01-14 20:42:24.863372.863372 lmp.py:1625]   Expert 30 |    124 | CPU
DEBUG 01-14 20:42:24.863267.863267 lmp.py:1625]   Expert 50 |    124 | CPU
DEBUG 01-14 20:42:24.863864.863864 lmp.py:1625]   Expert 39 |    125 | CPU
DEBUG 01-14 20:42:24.863699.863699 lmp.py:1625]   Expert 24 |    127 | CPU
DEBUG 01-14 20:42:24.863580.863580 lmp.py:1625]   Expert  8 |    133 | CPU
DEBUG 01-14 20:42:24.863415.863415 lmp.py:1625]   Expert 27 |    134 | CPU
DEBUG 01-14 20:42:24.863535.863535 lmp.py:1625]   Expert  3 |    140 | CPU
DEBUG 01-14 20:42:24.863046.863046 lmp.py:1625]   Expert 14 |    145 | CPU
DEBUG 01-14 20:42:24.863450.863450 lmp.py:1625]   Expert 10 |    147 | CPU
DEBUG 01-14 20:42:24.863809.863809 lmp.py:1625]   Expert 37 |    151 | CPU
DEBUG 01-14 20:42:24.863213.863213 lmp.py:1625]   Expert 38 |    151 | CPU
DEBUG 01-14 20:42:24.863810.863810 lmp.py:1625]   Expert 11 |    153 | CPU
DEBUG 01-14 20:42:24.863738.863738 lmp.py:1625]   Expert 32 |    154 | CPU
DEBUG 01-14 20:42:24.863096.863096 lmp.py:1625]   Expert 58 |    155 | CPU
DEBUG 01-14 20:42:24.863977.863977 lmp.py:1625]   Expert 19 |    160 | CPU
DEBUG 01-14 20:42:24.863812.863812 lmp.py:1625]   Expert 40 |    161 | GPU
DEBUG 01-14 20:42:24.863455.863455 lmp.py:1625]   Expert 54 |    162 | GPU
DEBUG 01-14 20:42:24.863052.863052 lmp.py:1625]   Expert 31 |    164 | GPU
DEBUG 01-14 20:42:24.863457.863457 lmp.py:1625]   Expert 41 |    164 | GPU
DEBUG 01-14 20:42:24.863576.863576 lmp.py:1625]   Expert 61 |    165 | GPU
DEBUG 01-14 20:42:24.863981.863981 lmp.py:1625]   Expert 22 |    167 | GPU
DEBUG 01-14 20:42:24.863339.863339 lmp.py:1625]   Expert 46 |    171 | GPU
DEBUG 01-14 20:42:24.863505.863505 lmp.py:1625]   Expert 57 |    177 | GPU
DEBUG 01-14 20:42:24.864387.864387 lmp.py:1625]   Expert 18 |    178 | GPU
DEBUG 01-14 20:42:24.864791.864791 lmp.py:1625]   Expert 42 |    179 | GPU
DEBUG 01-14 20:42:24.864911.864911 lmp.py:1625]   Expert 26 |    185 | GPU
DEBUG 01-14 20:42:24.864792.864792 lmp.py:1625]   Expert 34 |    189 | GPU
DEBUG 01-14 20:42:24.864866.864866 lmp.py:1625]   Expert 56 |    192 | GPU
DEBUG 01-14 20:42:24.864509.864509 lmp.py:1625]   Expert 44 |    194 | GPU
DEBUG 01-14 20:42:24.864582.864582 lmp.py:1625]   Expert  1 |    208 | GPU
DEBUG 01-14 20:42:24.864987.864987 lmp.py:1625]   Expert  0 |    212 | GPU
DEBUG 01-14 20:42:24.864345.864345 lmp.py:1625]   Expert 51 |    230 | GPU
DEBUG 01-14 20:42:24.864034.864034 lmp.py:1625]   Expert 20 |    231 | GPU
DEBUG 01-14 20:42:24.864869.864869 lmp.py:1625]   Expert 48 |    234 | GPU
DEBUG 01-14 20:42:24.864797.864797 lmp.py:1625]   Expert 21 |    236 | GPU
DEBUG 01-14 20:42:24.864679.864679 lmp.py:1625]   Expert 29 |    239 | GPU
DEBUG 01-14 20:42:24.864368.864368 lmp.py:1625]   Expert 55 |    241 | GPU
DEBUG 01-14 20:42:24.864726.864726 lmp.py:1625]   Expert 35 |    244 | GPU
DEBUG 01-14 20:42:24.864084.864084 lmp.py:1625]   Expert 45 |    247 | GPU
DEBUG 01-14 20:42:24.864919.864919 lmp.py:1625]   Expert 16 |    259 | GPU
DEBUG 01-14 20:42:24.864801.864801 lmp.py:1625]   Expert  5 |    295 | GPU
DEBUG 01-14 20:42:24.864636.864636 lmp.py:1625]   Expert 13 |    374 | GPU
DEBUG 01-14 20:42:24.864040.864040 lmp.py:1625]   Expert 23 |    378 | GPU
DEBUG 01-14 20:42:24.864160.864160 lmp.py:1625]   Expert 17 |    421 | GPU
DEBUG 01-14 20:42:24.864002.864002 lmp.py:1625]   Expert 63 |    471 | GPU
DEBUG 01-14 20:42:24.864837.864837 lmp.py:1625]   Expert  9 |    508 | GPU
DEBUG 01-14 20:42:24.864242.864242 lmp.py:1625]   Expert 62 |   1227 | GPU
DEBUG 01-14 20:42:24.864838.864838 lmp.py:1626] 
DEBUG 01-14 20:42:24.864838.864838 lmp.py:1626]   CPU total tokens: 3585 (29.2%)
DEBUG 01-14 20:42:24.864720.864720 lmp.py:1627]   GPU total tokens: 8703 (70.8%)
DEBUG 01-14 20:42:24.864562.864562 cuda_h.py:19] end experts_map_get cost 0.0016248226165771484 seconds
DEBUG 01-14 20:42:24.864512.864512 mlpmodule.py:1367]  experts func einsum cost 0.07730841636657715 s
DEBUG 01-14 20:42:24.864589.864589 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-14 20:42:24.864112.864112 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-14 20:42:24.865454.865454 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-14 20:42:24.866826.866826 cuda_h.py:19] end allocate_cuda_memory cost 0.0015730857849121094 seconds
DEBUG 01-14 20:42:24.866610.866610 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-14 20:42:24.866896.866896 sllm_store_c.py:27] get device uuid map
DEBUG 01-14 20:42:24.866705.866705 sllm_store_c.py:29] call client load into gpu
DEBUG 01-14 20:42:24.866547.866547 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, c6f1b204-f8fe-4cb8-914f-7faed6e6e7c3
DEBUG 01-14 20:42:24.867620.867620 client.py:106] call stub.LoadModelAsync
INFO 01-14 20:42:24.867328.867328 client.py:127] Model loaded
DEBUG 01-14 20:42:24.867780.867780 cuda_h.py:10] start restore2model
DEBUG 01-14 20:42:24.867945.867945 cuda_h.py:19] end restore2model cost 0.0003361701965332031 seconds
DEBUG 01-14 20:42:24.867522.867522 cuda_h.py:19] end sllm_worker_task cost 0.01503610610961914 seconds
INFO 01-14 20:42:24.868087.868087 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, c6f1b204-f8fe-4cb8-914f-7faed6e6e7c3
DEBUG 01-14 20:42:24.869291.869291 cuda_h.py:19] end load_into_gpu_async cost 0.0022745132446289062 seconds
DEBUG 01-14 20:42:24.869731.869731 cuda_h.py:10] start restore_tensors2
DEBUG 01-14 20:42:24.869765.869765 cuda_h.py:19] end restore_tensors2 cost 0.0007703304290771484 seconds
DEBUG 01-14 20:42:24.870972.870972 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.005101680755615234 seconds
DEBUG 01-14 20:42:24.870543.870543 cuda_h.py:10] start restore2model
DEBUG 01-14 20:42:24.872154.872154 cuda_h.py:19] end restore2model cost 0.002594470977783203 seconds
DEBUG 01-14 20:42:24.872520.872520 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.007884502410888672 seconds
DEBUG 01-14 20:42:24.872985.872985 cuda_h.py:10] start gpu_sexperts
DEBUG 01-14 20:42:24.873306.873306 cuda_h.py:19] end gpu_sexperts cost 0.00027561187744140625 seconds
DEBUG 01-14 20:42:24.873414.873414 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-14 20:42:24.873832.873832 lmp.py:1683] 
DEBUG 01-14 20:42:24.873832.873832 lmp.py:1683]   Computing 32 experts on CPU...
DEBUG 01-14 20:42:24.873291.873291 cuda_h.py:19] end cpu_experts_submit cost 5.698204040527344e-05 seconds
DEBUG 01-14 20:42:24.873232.873232 cuda_h.py:10] start experts_func_mgpu_group_pad
DEBUG 01-14 20:42:24.883271.883271 mlpmodule.py:1460] group tensors cost 0.009225130081176758 s
DEBUG 01-14 20:42:24.883470.883470 cuda_h.py:10] start move_flat_hidden2cpu
DEBUG 01-14 20:42:24.886230.886230 cuda_h.py:19] end experts_func_mgpu_group_pad cost 0.012914657592773438 seconds
DEBUG 01-14 20:42:24.887282.887282 cuda_h.py:10] start gpu_group_list
DEBUG 01-14 20:42:24.888371.888371 cuda_h.py:19] end gpu_group_list cost 0.0005764961242675781 seconds
DEBUG 01-14 20:42:24.888477.888477 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-14 20:42:24.889581.889581 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.6702880859375e-05 seconds
DEBUG 01-14 20:42:24.889954.889954 cuda_h.py:10] start wait_experts
INFO 01-14 20:42:24.889724.889724 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, c6f1b204-f8fe-4cb8-914f-7faed6e6e7c3
DEBUG 01-14 20:42:24.890051.890051 cuda_h.py:19] end move_flat_hidden2cpu cost 0.006619453430175781 seconds
DEBUG 01-14 20:42:24.892119.892119 mlpmodule.py:1533] pad cost 0.0015189647674560547 s
DEBUG 01-14 20:42:24.892546.892546 mlpmodule.py:1539] create cpu tensor cost 3.814697265625e-05 s
DEBUG 01-14 20:42:24.894260.894260 mlpmodule.py:1544] move to cpu cost 0.0018949508666992188 s
DEBUG 01-14 20:42:24.903461.903461 mlpmodule.py:1558] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-14 20:42:24.903102.903102 mlpmodule.py:1559] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-14 20:42:24.903694.903694 mlpmodule.py:1564] group_w3 first element: 0.00457763671875
WARNING 01-14 20:42:24.903857.903857 mlpmodule.py:1574] start einsum2
DEBUG 01-14 20:42:24.919668.919668 mlpmodule.py:1584] group einsum cost 0.02556920051574707 s
DEBUG 01-14 20:42:24.920203.920203 mlpmodule.py:1593] cpy2cputensor cost 0.0007104873657226562 s
DEBUG 01-14 20:42:24.920800.920800 cuda_h.py:10] start move_outputs
DEBUG 01-14 20:42:24.923187.923187 cuda_h.py:19] end move_outputs cost 0.002432107925415039 seconds
INFO 01-14 20:42:24.925386.925386 client.py:127] Model loaded
DEBUG 01-14 20:42:24.925804.925804 cuda_h.py:19] end wait_experts cost 0.03638267517089844 seconds
DEBUG 01-14 20:42:24.925772.925772 cuda_h.py:10] start gpu_experts
DEBUG 01-14 20:42:24.925741.925741 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-14 20:42:24.927088.927088 cuda_h.py:19] end wait_cetm_experts cost 0.001621246337890625 seconds
DEBUG 01-14 20:42:24.927057.927057 cuda_h.py:10] start gpu_group_einsum_mp_multi_list
DEBUG 01-14 20:42:24.927628.927628 cuda_h.py:10] start gpu_group_tensor
DEBUG 01-14 20:42:24.927472.927472 cuda_h.py:19] end gpu_group_tensor cost 0.00023794174194335938 seconds
DEBUG 01-14 20:42:24.927436.927436 cuda_h.py:10] start gpu_group_einsum
DEBUG 01-14 20:42:24.942898.942898 mlpmodule.py:1367]  experts func einsum cost 0.06890487670898438 s
DEBUG 01-14 20:42:24.943611.943611 cuda_h.py:19] end gpu_group_einsum cost 0.015443563461303711 seconds
DEBUG 01-14 20:42:24.943339.943339 cuda_h.py:10] start gpu_final_hidden_states_scatter
DEBUG 01-14 20:42:24.943175.943175 cuda_h.py:10] start all_expert_outputs_slices
DEBUG 01-14 20:42:24.943687.943687 cuda_h.py:19] end all_expert_outputs_slices cost 0.0002434253692626953 seconds
DEBUG 01-14 20:42:24.943536.943536 cuda_h.py:10] start concat_expert_out
DEBUG 01-14 20:42:24.943533.943533 cuda_h.py:19] end concat_expert_out cost 7.104873657226562e-05 seconds
DEBUG 01-14 20:42:24.943614.943614 cuda_h.py:10] start index_scatter
DEBUG 01-14 20:42:24.944366.944366 cuda_h.py:19] end index_scatter cost 6.723403930664062e-05 seconds
DEBUG 01-14 20:42:24.944645.944645 cuda_h.py:19] end gpu_final_hidden_states_scatter cost 0.0006062984466552734 seconds
DEBUG 01-14 20:42:24.944840.944840 cuda_h.py:19] end gpu_experts cost 0.018592357635498047 seconds
DEBUG 01-14 20:42:24.944397.944397 cuda_h.py:10] start all_expert_weight_slices
DEBUG 01-14 20:42:24.945601.945601 cuda_h.py:19] end all_expert_weight_slices cost 0.0009253025054931641 seconds
DEBUG 01-14 20:42:24.945821.945821 cuda_h.py:10] start cpuoutputsdeal
DEBUG 01-14 20:42:24.945995.945995 cuda_h.py:10] start index_scatter
DEBUG 01-14 20:42:24.945628.945628 cuda_h.py:19] end index_scatter cost 5.7220458984375e-05 seconds
DEBUG 01-14 20:42:24.945928.945928 cuda_h.py:19] end cpuoutputsdeal cost 0.0005714893341064453 seconds
DEBUG 01-14 20:42:24.945374.945374 cuda_h.py:19] end layer_moe_generate_mp_l_18 cost 0.08380341529846191 seconds
DEBUG 01-14 20:42:24.946374.946374 cuda_h.py:19] end prefill_layer cost 0.09383225440979004 seconds
DEBUG 01-14 20:42:24.946124.946124 lmp.py:1551] -------------------------------- end prefill layer 17 --------------------------------
DEBUG 01-14 20:42:24.946880.946880 cuda_h.py:10] start prefill_layer
DEBUG 01-14 20:42:24.946398.946398 lmp.py:1494] -------------------------------- start prefill layer 18 --------------------------------
DEBUG 01-14 20:42:24.946677.946677 cuda_h.py:10] start start_load_qkvogn_s_weight_l_19
DEBUG 01-14 20:42:24.946864.946864 cuda_h.py:10] start start_load_qkvogn_s_weight_l_19
DEBUG 01-14 20:42:24.946859.946859 cuda_h.py:19] end start_load_qkvogn_s_weight_l_19 cost 3.695487976074219e-05 seconds
DEBUG 01-14 20:42:24.946238.946238 cuda_h.py:19] end start_load_qkvogn_s_weight_l_19 cost 7.319450378417969e-05 seconds
DEBUG 01-14 20:42:24.946749.946749 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-14 20:42:24.946725.946725 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-14 20:42:24.946477.946477 cuda_h.py:10] start sllm_worker_task
DEBUG 01-14 20:42:24.946964.946964 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-14 20:42:24.946960.946960 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-14 20:42:24.947061.947061 cuda_h.py:19] end allocate_cuda_memory cost 0.0002048015594482422 seconds
DEBUG 01-14 20:42:24.947567.947567 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-14 20:42:24.947913.947913 sllm_store_c.py:27] get device uuid map
DEBUG 01-14 20:42:24.947849.947849 sllm_store_c.py:29] call client load into gpu
DEBUG 01-14 20:42:24.947658.947658 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, f89ccfc5-8250-4f64-8378-c1310d58dc31
DEBUG 01-14 20:42:24.947701.947701 client.py:106] call stub.LoadModelAsync
DEBUG 01-14 20:42:24.947776.947776 cuda_h.py:10] start self_attn
INFO 01-14 20:42:24.949412.949412 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, f89ccfc5-8250-4f64-8378-c1310d58dc31
DEBUG 01-14 20:42:24.949123.949123 cuda_h.py:19] end load_into_gpu_async cost 0.0017342567443847656 seconds
DEBUG 01-14 20:42:24.949217.949217 cuda_h.py:10] start restore_tensors2
DEBUG 01-14 20:42:24.949718.949718 cuda_h.py:19] end restore_tensors2 cost 8.726119995117188e-05 seconds
DEBUG 01-14 20:42:24.949534.949534 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.002343893051147461 seconds
INFO 01-14 20:42:24.949384.949384 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, f89ccfc5-8250-4f64-8378-c1310d58dc31
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-14 20:42:24.951825.951825 cuda_h.py:19] end self_attn cost 0.0033686161041259766 seconds
DEBUG 01-14 20:42:24.951254.951254 cuda_h.py:19] end iln_self_attn_paln cost 0.004971742630004883 seconds
DEBUG 01-14 20:42:24.951594.951594 cuda_h.py:10] start layer_moe_generate_mp_l_19
DEBUG 01-14 20:42:24.951702.951702 cuda_h.py:10] start gate
DEBUG 01-14 20:42:24.952337.952337 cuda_h.py:19] end gate cost 0.0007417201995849609 seconds
DEBUG 01-14 20:42:24.952988.952988 cuda_h.py:10] start experts_map_get
DEBUG 01-14 20:42:24.952279.952279 lmp.py:1615] 
DEBUG 01-14 20:42:24.952279.952279 lmp.py:1615] Expert Token Distribution & Device Allocation:
DEBUG 01-14 20:42:24.953241.953241 lmp.py:1616]   Total experts: 64
DEBUG 01-14 20:42:24.953666.953666 lmp.py:1617]   CPU experts: 32 (50%)
DEBUG 01-14 20:42:24.953799.953799 lmp.py:1618]   GPU experts: 32 (50%)
DEBUG 01-14 20:42:24.953595.953595 lmp.py:1619] 
DEBUG 01-14 20:42:24.953595.953595 lmp.py:1619]   Expert ID | Tokens | Device
DEBUG 01-14 20:42:24.953914.953914 lmp.py:1620]   -----------------------------------
DEBUG 01-14 20:42:24.953186.953186 lmp.py:1625]   Expert 30 |     50 | CPU
DEBUG 01-14 20:42:24.953743.953743 lmp.py:1625]   Expert 32 |     54 | CPU
DEBUG 01-14 20:42:24.953347.953347 lmp.py:1625]   Expert  5 |     56 | CPU
DEBUG 01-14 20:42:24.953235.953235 lmp.py:1625]   Expert 46 |     63 | CPU
DEBUG 01-14 20:42:24.953600.953600 lmp.py:1625]   Expert 12 |     94 | CPU
DEBUG 01-14 20:42:24.953965.953965 lmp.py:1625]   Expert  8 |     98 | CPU
DEBUG 01-14 20:42:24.953615.953615 lmp.py:1625]   Expert 40 |    103 | CPU
DEBUG 01-14 20:42:24.953741.953741 lmp.py:1625]   Expert 60 |    103 | CPU
DEBUG 01-14 20:42:24.953821.953821 lmp.py:1625]   Expert 27 |    106 | CPU
DEBUG 01-14 20:42:24.953379.953379 lmp.py:1625]   Expert 41 |    111 | CPU
DEBUG 01-14 20:42:24.953982.953982 lmp.py:1625]   Expert  3 |    114 | CPU
DEBUG 01-14 20:42:24.953632.953632 lmp.py:1625]   Expert 17 |    114 | CPU
DEBUG 01-14 20:42:24.953520.953520 lmp.py:1625]   Expert 28 |    116 | CPU
DEBUG 01-14 20:42:24.953931.953931 lmp.py:1625]   Expert 29 |    117 | CPU
DEBUG 01-14 20:42:24.953058.953058 lmp.py:1625]   Expert 21 |    120 | CPU
DEBUG 01-14 20:42:24.953900.953900 lmp.py:1625]   Expert 54 |    127 | CPU
DEBUG 01-14 20:42:24.953026.953026 lmp.py:1625]   Expert  6 |    130 | CPU
DEBUG 01-14 20:42:24.953299.953299 lmp.py:1625]   Expert 35 |    130 | CPU
DEBUG 01-14 20:42:24.953856.953856 lmp.py:1625]   Expert 58 |    130 | CPU
DEBUG 01-14 20:42:24.953128.953128 lmp.py:1625]   Expert 25 |    132 | CPU
DEBUG 01-14 20:42:24.953493.953493 lmp.py:1625]   Expert 52 |    142 | CPU
DEBUG 01-14 20:42:24.953381.953381 lmp.py:1625]   Expert 19 |    145 | CPU
DEBUG 01-14 20:42:24.953031.953031 lmp.py:1625]   Expert 37 |    146 | CPU
DEBUG 01-14 20:42:24.953635.953635 lmp.py:1625]   Expert  0 |    147 | CPU
DEBUG 01-14 20:42:24.953523.953523 lmp.py:1625]   Expert  9 |    154 | CPU
DEBUG 01-14 20:42:24.953649.953649 lmp.py:1625]   Expert 63 |    157 | CPU
DEBUG 01-14 20:42:24.953538.953538 lmp.py:1625]   Expert 53 |    159 | CPU
DEBUG 01-14 20:42:24.953379.953379 lmp.py:1625]   Expert 48 |    165 | CPU
DEBUG 01-14 20:42:24.953698.953698 lmp.py:1625]   Expert 36 |    167 | CPU
DEBUG 01-14 20:42:24.953494.953494 lmp.py:1625]   Expert 56 |    169 | CPU
DEBUG 01-14 20:42:24.953620.953620 lmp.py:1625]   Expert  1 |    176 | CPU
DEBUG 01-14 20:42:24.953747.953747 lmp.py:1625]   Expert 59 |    176 | CPU
DEBUG 01-14 20:42:24.953873.953873 lmp.py:1625]   Expert 47 |    187 | GPU
DEBUG 01-14 20:42:24.953523.953523 lmp.py:1625]   Expert 20 |    199 | GPU
DEBUG 01-14 20:42:24.953173.953173 lmp.py:1625]   Expert 39 |    199 | GPU
DEBUG 01-14 20:42:24.953061.953061 lmp.py:1625]   Expert 42 |    205 | GPU
DEBUG 01-14 20:42:24.954141.954141 lmp.py:1625]   Expert 61 |    208 | GPU
DEBUG 01-14 20:42:24.954460.954460 lmp.py:1625]   Expert 34 |    216 | GPU
DEBUG 01-14 20:42:24.954540.954540 lmp.py:1625]   Expert 13 |    218 | GPU
DEBUG 01-14 20:42:24.954144.954144 lmp.py:1625]   Expert  7 |    219 | GPU
DEBUG 01-14 20:42:24.954555.954555 lmp.py:1625]   Expert 57 |    220 | GPU
DEBUG 01-14 20:42:24.954920.954920 lmp.py:1625]   Expert 16 |    221 | GPU
DEBUG 01-14 20:42:24.954570.954570 lmp.py:1625]   Expert 18 |    223 | GPU
DEBUG 01-14 20:42:24.954458.954458 lmp.py:1625]   Expert 11 |    224 | GPU
DEBUG 01-14 20:42:24.954346.954346 lmp.py:1625]   Expert 55 |    233 | GPU
DEBUG 01-14 20:42:24.954533.954533 lmp.py:1625]   Expert 50 |    245 | GPU
DEBUG 01-14 20:42:24.954130.954130 lmp.py:1625]   Expert 49 |    246 | GPU
DEBUG 01-14 20:42:24.954203.954203 lmp.py:1625]   Expert 15 |    247 | GPU
DEBUG 01-14 20:42:24.954806.954806 lmp.py:1625]   Expert 43 |    248 | GPU
DEBUG 01-14 20:42:24.954734.954734 lmp.py:1625]   Expert  2 |    251 | GPU
DEBUG 01-14 20:42:24.954947.954947 lmp.py:1625]   Expert 22 |    251 | GPU
DEBUG 01-14 20:42:24.954159.954159 lmp.py:1625]   Expert  4 |    252 | GPU
DEBUG 01-14 20:42:24.954895.954895 lmp.py:1625]   Expert 51 |    253 | GPU
DEBUG 01-14 20:42:24.954869.954869 lmp.py:1625]   Expert 31 |    259 | GPU
DEBUG 01-14 20:42:24.954843.954843 lmp.py:1625]   Expert 45 |    259 | GPU
DEBUG 01-14 20:42:24.954817.954817 lmp.py:1625]   Expert 33 |    262 | GPU
DEBUG 01-14 20:42:24.954791.954791 lmp.py:1625]   Expert 38 |    279 | GPU
DEBUG 01-14 20:42:24.954527.954527 lmp.py:1625]   Expert 44 |    280 | GPU
DEBUG 01-14 20:42:24.954501.954501 lmp.py:1625]   Expert 26 |    292 | GPU
DEBUG 01-14 20:42:24.954475.954475 lmp.py:1625]   Expert 23 |    293 | GPU
DEBUG 01-14 20:42:24.954502.954502 lmp.py:1625]   Expert 10 |    306 | GPU
DEBUG 01-14 20:42:24.954668.954668 lmp.py:1625]   Expert 24 |    308 | GPU
DEBUG 01-14 20:42:24.954834.954834 lmp.py:1625]   Expert 14 |    310 | GPU
DEBUG 01-14 20:42:24.954285.954285 lmp.py:1625]   Expert 62 |    704 | GPU
DEBUG 01-14 20:42:24.954213.954213 lmp.py:1626] 
DEBUG 01-14 20:42:24.954213.954213 lmp.py:1626]   CPU total tokens: 3971 (32.3%)
DEBUG 01-14 20:42:24.954379.954379 lmp.py:1627]   GPU total tokens: 8317 (67.7%)
DEBUG 01-14 20:42:24.954121.954121 cuda_h.py:19] end experts_map_get cost 0.0019600391387939453 seconds
DEBUG 01-14 20:42:24.954680.954680 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-14 20:42:24.954092.954092 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-14 20:42:24.954997.954997 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-14 20:42:24.956788.956788 cuda_h.py:19] end allocate_cuda_memory cost 0.001428842544555664 seconds
DEBUG 01-14 20:42:24.956936.956936 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-14 20:42:24.956514.956514 sllm_store_c.py:27] get device uuid map
DEBUG 01-14 20:42:24.956469.956469 sllm_store_c.py:29] call client load into gpu
DEBUG 01-14 20:42:24.956748.956748 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, ceb8babf-d73e-4b0c-a703-7825ca885512
DEBUG 01-14 20:42:24.956237.956237 client.py:106] call stub.LoadModelAsync
INFO 01-14 20:42:24.957921.957921 client.py:127] Model loaded
DEBUG 01-14 20:42:24.957500.957500 cuda_h.py:10] start restore2model
DEBUG 01-14 20:42:24.957560.957560 cuda_h.py:19] end restore2model cost 0.0005519390106201172 seconds
DEBUG 01-14 20:42:24.957171.957171 cuda_h.py:19] end sllm_worker_task cost 0.0109405517578125 seconds
INFO 01-14 20:42:24.958054.958054 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, ceb8babf-d73e-4b0c-a703-7825ca885512
DEBUG 01-14 20:42:24.958735.958735 cuda_h.py:19] end load_into_gpu_async cost 0.0024261474609375 seconds
DEBUG 01-14 20:42:24.958512.958512 cuda_h.py:10] start restore_tensors2
DEBUG 01-14 20:42:24.959295.959295 cuda_h.py:19] end restore_tensors2 cost 0.00036072731018066406 seconds
DEBUG 01-14 20:42:24.959601.959601 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.004704952239990234 seconds
DEBUG 01-14 20:42:24.959934.959934 cuda_h.py:10] start restore2model
DEBUG 01-14 20:42:24.962106.962106 cuda_h.py:19] end restore2model cost 0.0025556087493896484 seconds
DEBUG 01-14 20:42:24.962373.962373 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.007436513900756836 seconds
DEBUG 01-14 20:42:24.962427.962427 cuda_h.py:10] start gpu_sexperts
DEBUG 01-14 20:42:24.962643.962643 cuda_h.py:19] end gpu_sexperts cost 0.00026917457580566406 seconds
DEBUG 01-14 20:42:24.962227.962227 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-14 20:42:24.962122.962122 lmp.py:1683] 
DEBUG 01-14 20:42:24.962122.962122 lmp.py:1683]   Computing 32 experts on CPU...
DEBUG 01-14 20:42:24.962150.962150 cuda_h.py:19] end cpu_experts_submit cost 5.626678466796875e-05 seconds
DEBUG 01-14 20:42:24.962708.962708 cuda_h.py:10] start experts_func_mgpu_group_pad
DEBUG 01-14 20:42:24.973820.973820 mlpmodule.py:1460] group tensors cost 0.010633468627929688 s
DEBUG 01-14 20:42:24.974364.974364 cuda_h.py:10] start move_flat_hidden2cpu
DEBUG 01-14 20:42:24.978673.978673 cuda_h.py:19] end experts_func_mgpu_group_pad cost 0.01628708839416504 seconds
DEBUG 01-14 20:42:24.981901.981901 cuda_h.py:10] start gpu_group_list
DEBUG 01-14 20:42:24.982598.982598 cuda_h.py:19] end gpu_group_list cost 0.0008785724639892578 seconds
DEBUG 01-14 20:42:24.983320.983320 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-14 20:42:24.983855.983855 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 3.504753112792969e-05 seconds
DEBUG 01-14 20:42:24.983984.983984 cuda_h.py:10] start wait_experts
INFO 01-14 20:42:24.983451.983451 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, ceb8babf-d73e-4b0c-a703-7825ca885512
DEBUG 01-14 20:42:24.984450.984450 cuda_h.py:19] end move_flat_hidden2cpu cost 0.00920248031616211 seconds
DEBUG 01-14 20:42:24.985221.985221 mlpmodule.py:1533] pad cost 0.0015468597412109375 s
DEBUG 01-14 20:42:24.985946.985946 mlpmodule.py:1539] create cpu tensor cost 3.743171691894531e-05 s
DEBUG 01-14 20:42:24.988958.988958 mlpmodule.py:1544] move to cpu cost 0.002078533172607422 s
DEBUG 01-14 20:42:24.997555.997555 mlpmodule.py:1558] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-14 20:42:24.997747.997747 mlpmodule.py:1559] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-14 20:42:24.997598.997598 mlpmodule.py:1564] group_w3 first element: 0.0024871826171875
WARNING 01-14 20:42:24.997913.997913 mlpmodule.py:1574] start einsum2
INFO 01-14 20:42:25.013265.013265 client.py:127] Model loaded
DEBUG 01-14 20:42:25.013033.013033 cuda_h.py:19] end wait_experts cost 0.030443906784057617 seconds
DEBUG 01-14 20:42:25.013942.013942 cuda_h.py:10] start gpu_experts
DEBUG 01-14 20:42:25.013579.013579 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-14 20:42:25.014421.014421 mlpmodule.py:1584] group einsum cost 0.026216745376586914 s
DEBUG 01-14 20:42:25.015205.015205 mlpmodule.py:1593] cpy2cputensor cost 0.0007183551788330078 s
DEBUG 01-14 20:42:25.015598.015598 cuda_h.py:10] start move_outputs
DEBUG 01-14 20:42:25.017978.017978 cuda_h.py:19] end move_outputs cost 0.0020401477813720703 seconds
DEBUG 01-14 20:42:25.021160.021160 cuda_h.py:19] end wait_cetm_experts cost 0.0070056915283203125 seconds
DEBUG 01-14 20:42:25.021847.021847 cuda_h.py:10] start gpu_group_einsum_mp_multi_list
DEBUG 01-14 20:42:25.021902.021902 cuda_h.py:10] start gpu_group_tensor
DEBUG 01-14 20:42:25.021361.021361 cuda_h.py:19] end gpu_group_tensor cost 0.00023436546325683594 seconds
DEBUG 01-14 20:42:25.021100.021100 cuda_h.py:10] start gpu_group_einsum
DEBUG 01-14 20:42:25.022966.022966 cuda_h.py:19] end gpu_group_einsum cost 0.0006880760192871094 seconds
DEBUG 01-14 20:42:25.022401.022401 cuda_h.py:10] start gpu_final_hidden_states_scatter
DEBUG 01-14 20:42:25.022874.022874 cuda_h.py:10] start all_expert_outputs_slices
DEBUG 01-14 20:42:25.022000.022000 cuda_h.py:19] end all_expert_outputs_slices cost 0.0003600120544433594 seconds
DEBUG 01-14 20:42:25.022710.022710 cuda_h.py:10] start concat_expert_out
DEBUG 01-14 20:42:25.023269.023269 cuda_h.py:19] end concat_expert_out cost 5.984306335449219e-05 seconds
DEBUG 01-14 20:42:25.023073.023073 cuda_h.py:10] start index_scatter
DEBUG 01-14 20:42:25.023262.023262 cuda_h.py:19] end index_scatter cost 7.176399230957031e-05 seconds
DEBUG 01-14 20:42:25.023640.023640 cuda_h.py:19] end gpu_final_hidden_states_scatter cost 0.0007596015930175781 seconds
DEBUG 01-14 20:42:25.023650.023650 cuda_h.py:19] end gpu_experts cost 0.009441614151000977 seconds
DEBUG 01-14 20:42:25.023876.023876 cuda_h.py:10] start all_expert_weight_slices
DEBUG 01-14 20:42:25.024339.024339 cuda_h.py:19] end all_expert_weight_slices cost 0.0009427070617675781 seconds
DEBUG 01-14 20:42:25.024169.024169 cuda_h.py:10] start cpuoutputsdeal
DEBUG 01-14 20:42:25.024568.024568 cuda_h.py:10] start index_scatter
DEBUG 01-14 20:42:25.024936.024936 cuda_h.py:19] end index_scatter cost 4.76837158203125e-05 seconds
DEBUG 01-14 20:42:25.025367.025367 cuda_h.py:19] end cpuoutputsdeal cost 0.0005373954772949219 seconds
DEBUG 01-14 20:42:25.025330.025330 cuda_h.py:19] end layer_moe_generate_mp_l_19 cost 0.07336163520812988 seconds
DEBUG 01-14 20:42:25.025311.025311 cuda_h.py:19] end prefill_layer cost 0.07907533645629883 seconds
DEBUG 01-14 20:42:25.025670.025670 lmp.py:1551] -------------------------------- end prefill layer 18 --------------------------------
DEBUG 01-14 20:42:25.025611.025611 cuda_h.py:10] start prefill_layer
DEBUG 01-14 20:42:25.025268.025268 lmp.py:1494] -------------------------------- start prefill layer 19 --------------------------------
DEBUG 01-14 20:42:25.025163.025163 cuda_h.py:10] start start_load_qkvogn_s_weight_l_20
DEBUG 01-14 20:42:25.025919.025919 cuda_h.py:10] start start_load_qkvogn_s_weight_l_20
DEBUG 01-14 20:42:25.025961.025961 cuda_h.py:19] end start_load_qkvogn_s_weight_l_20 cost 3.7670135498046875e-05 seconds
DEBUG 01-14 20:42:25.025671.025671 cuda_h.py:19] end start_load_qkvogn_s_weight_l_20 cost 7.176399230957031e-05 seconds
DEBUG 01-14 20:42:25.025758.025758 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-14 20:42:25.025516.025516 cuda_h.py:10] start sllm_worker_task
DEBUG 01-14 20:42:25.026739.026739 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-14 20:42:25.026734.026734 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-14 20:42:25.029523.029523 cuda_h.py:19] end allocate_cuda_memory cost 0.003734111785888672 seconds
DEBUG 01-14 20:42:25.029064.029064 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-14 20:42:25.030953.030953 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-14 20:42:25.030952.030952 sllm_store_c.py:27] get device uuid map
DEBUG 01-14 20:42:25.030186.030186 sllm_store_c.py:29] call client load into gpu
DEBUG 01-14 20:42:25.030704.030704 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 6a9d2d3d-c7ac-40d4-a805-64dc62444ac0
DEBUG 01-14 20:42:25.030634.030634 client.py:106] call stub.LoadModelAsync
DEBUG 01-14 20:42:25.030823.030823 cuda_h.py:10] start self_attn
INFO 01-14 20:42:25.031027.031027 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 6a9d2d3d-c7ac-40d4-a805-64dc62444ac0
DEBUG 01-14 20:42:25.031631.031631 cuda_h.py:19] end load_into_gpu_async cost 0.0017020702362060547 seconds
DEBUG 01-14 20:42:25.031811.031811 cuda_h.py:10] start restore_tensors2
DEBUG 01-14 20:42:25.032523.032523 cuda_h.py:19] end restore_tensors2 cost 7.62939453125e-05 seconds
DEBUG 01-14 20:42:25.032756.032756 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.006013393402099609 seconds
INFO 01-14 20:42:25.032208.032208 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 6a9d2d3d-c7ac-40d4-a805-64dc62444ac0
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-14 20:42:25.033235.033235 cuda_h.py:19] end self_attn cost 0.0029366016387939453 seconds
DEBUG 01-14 20:42:25.034955.034955 cuda_h.py:19] end iln_self_attn_paln cost 0.008220195770263672 seconds
DEBUG 01-14 20:42:25.034129.034129 cuda_h.py:10] start layer_moe_generate_mp_l_20
DEBUG 01-14 20:42:25.034461.034461 cuda_h.py:10] start gate
DEBUG 01-14 20:42:25.034954.034954 cuda_h.py:19] end gate cost 0.0006465911865234375 seconds
DEBUG 01-14 20:42:25.034353.034353 cuda_h.py:10] start experts_map_get
DEBUG 01-14 20:42:25.035396.035396 lmp.py:1615] 
DEBUG 01-14 20:42:25.035396.035396 lmp.py:1615] Expert Token Distribution & Device Allocation:
DEBUG 01-14 20:42:25.035113.035113 lmp.py:1616]   Total experts: 64
DEBUG 01-14 20:42:25.035121.035121 lmp.py:1617]   CPU experts: 32 (50%)
DEBUG 01-14 20:42:25.035678.035678 lmp.py:1618]   GPU experts: 32 (50%)
DEBUG 01-14 20:42:25.035705.035705 lmp.py:1619] 
DEBUG 01-14 20:42:25.035705.035705 lmp.py:1619]   Expert ID | Tokens | Device
DEBUG 01-14 20:42:25.035209.035209 lmp.py:1620]   -----------------------------------
DEBUG 01-14 20:42:25.035428.035428 lmp.py:1625]   Expert  1 |     38 | CPU
DEBUG 01-14 20:42:25.035932.035932 lmp.py:1625]   Expert 44 |     51 | CPU
DEBUG 01-14 20:42:25.035483.035483 lmp.py:1625]   Expert 60 |     67 | CPU
DEBUG 01-14 20:42:25.035556.035556 lmp.py:1625]   Expert 28 |     79 | CPU
DEBUG 01-14 20:42:25.035299.035299 lmp.py:1625]   Expert 62 |     89 | CPU
DEBUG 01-14 20:42:25.035087.035087 lmp.py:1625]   Expert 48 |     93 | CPU
DEBUG 01-14 20:42:25.035207.035207 lmp.py:1625]   Expert 27 |     94 | CPU
DEBUG 01-14 20:42:25.035519.035519 lmp.py:1625]   Expert 30 |     96 | CPU
DEBUG 01-14 20:42:25.035116.035116 lmp.py:1625]   Expert  0 |    102 | CPU
DEBUG 01-14 20:42:25.035951.035951 lmp.py:1625]   Expert 22 |    108 | CPU
DEBUG 01-14 20:42:25.035355.035355 lmp.py:1625]   Expert 42 |    113 | CPU
DEBUG 01-14 20:42:25.035952.035952 lmp.py:1625]   Expert 58 |    120 | CPU
DEBUG 01-14 20:42:25.035118.035118 lmp.py:1625]   Expert  8 |    127 | CPU
DEBUG 01-14 20:42:25.035476.035476 lmp.py:1625]   Expert 12 |    128 | CPU
DEBUG 01-14 20:42:25.035166.035166 lmp.py:1625]   Expert 50 |    128 | CPU
DEBUG 01-14 20:42:25.035286.035286 lmp.py:1625]   Expert 59 |    129 | CPU
DEBUG 01-14 20:42:25.035452.035452 lmp.py:1625]   Expert 56 |    141 | CPU
DEBUG 01-14 20:42:25.035810.035810 lmp.py:1625]   Expert  5 |    142 | CPU
DEBUG 01-14 20:42:25.035214.035214 lmp.py:1625]   Expert 34 |    146 | CPU
DEBUG 01-14 20:42:25.035526.035526 lmp.py:1625]   Expert 55 |    148 | CPU
DEBUG 01-14 20:42:25.035931.035931 lmp.py:1625]   Expert 16 |    149 | CPU
DEBUG 01-14 20:42:25.035528.035528 lmp.py:1625]   Expert 32 |    149 | CPU
DEBUG 01-14 20:42:25.035694.035694 lmp.py:1625]   Expert 26 |    150 | CPU
DEBUG 01-14 20:42:25.035575.035575 lmp.py:1625]   Expert 19 |    155 | CPU
DEBUG 01-14 20:42:25.035741.035741 lmp.py:1625]   Expert 13 |    159 | CPU
DEBUG 01-14 20:42:25.035623.035623 lmp.py:1625]   Expert 15 |    159 | CPU
DEBUG 01-14 20:42:25.035550.035550 lmp.py:1625]   Expert  2 |    160 | CPU
DEBUG 01-14 20:42:25.035147.035147 lmp.py:1625]   Expert 47 |    161 | CPU
DEBUG 01-14 20:42:25.035836.035836 lmp.py:1625]   Expert 41 |    165 | CPU
DEBUG 01-14 20:42:25.035195.035195 lmp.py:1625]   Expert 52 |    168 | CPU
DEBUG 01-14 20:42:25.035314.035314 lmp.py:1625]   Expert 25 |    174 | CPU
DEBUG 01-14 20:42:25.035673.035673 lmp.py:1625]   Expert 24 |    176 | CPU
DEBUG 01-14 20:42:25.035508.035508 lmp.py:1625]   Expert  6 |    177 | GPU
DEBUG 01-14 20:42:25.035343.035343 lmp.py:1625]   Expert 20 |    179 | GPU
DEBUG 01-14 20:42:25.035509.035509 lmp.py:1625]   Expert 40 |    181 | GPU
DEBUG 01-14 20:42:25.035629.035629 lmp.py:1625]   Expert 18 |    182 | GPU
DEBUG 01-14 20:42:25.036795.036795 lmp.py:1625]   Expert 51 |    182 | GPU
DEBUG 01-14 20:42:25.036630.036630 lmp.py:1625]   Expert 37 |    184 | GPU
DEBUG 01-14 20:42:25.036319.036319 lmp.py:1625]   Expert 54 |    185 | GPU
DEBUG 01-14 20:42:25.036439.036439 lmp.py:1625]   Expert 17 |    188 | GPU
DEBUG 01-14 20:42:25.036605.036605 lmp.py:1625]   Expert  3 |    191 | GPU
DEBUG 01-14 20:42:25.036725.036725 lmp.py:1625]   Expert 57 |    192 | GPU
DEBUG 01-14 20:42:25.036129.036129 lmp.py:1625]   Expert 46 |    194 | GPU
DEBUG 01-14 20:42:25.036726.036726 lmp.py:1625]   Expert 11 |    201 | GPU
DEBUG 01-14 20:42:25.036608.036608 lmp.py:1625]   Expert 23 |    202 | GPU
DEBUG 01-14 20:42:25.036443.036443 lmp.py:1625]   Expert 43 |    207 | GPU
DEBUG 01-14 20:42:25.036847.036847 lmp.py:1625]   Expert 49 |    220 | GPU
DEBUG 01-14 20:42:25.036729.036729 lmp.py:1625]   Expert 31 |    223 | GPU
DEBUG 01-14 20:42:25.036133.036133 lmp.py:1625]   Expert 10 |    229 | GPU
DEBUG 01-14 20:42:25.036253.036253 lmp.py:1625]   Expert 35 |    230 | GPU
DEBUG 01-14 20:42:25.036419.036419 lmp.py:1625]   Expert 53 |    234 | GPU
DEBUG 01-14 20:42:25.036777.036777 lmp.py:1625]   Expert 36 |    244 | GPU
DEBUG 01-14 20:42:25.036705.036705 lmp.py:1625]   Expert 33 |    251 | GPU
DEBUG 01-14 20:42:25.036302.036302 lmp.py:1625]   Expert 38 |    264 | GPU
DEBUG 01-14 20:42:25.036468.036468 lmp.py:1625]   Expert 39 |    264 | GPU
DEBUG 01-14 20:42:25.036064.036064 lmp.py:1625]   Expert  4 |    305 | GPU
DEBUG 01-14 20:42:25.036946.036946 lmp.py:1625]   Expert 21 |    325 | GPU
DEBUG 01-14 20:42:25.036887.036887 lmp.py:1625]   Expert  9 |    328 | GPU
DEBUG 01-14 20:42:25.036007.036007 lmp.py:1625]   Expert 14 |    347 | GPU
DEBUG 01-14 20:42:25.036193.036193 lmp.py:1625]   Expert 63 |    363 | GPU
DEBUG 01-14 20:42:25.036221.036221 lmp.py:1625]   Expert 45 |    366 | GPU
DEBUG 01-14 20:42:25.036387.036387 lmp.py:1625]   Expert 61 |    389 | GPU
DEBUG 01-14 20:42:25.036030.036030 lmp.py:1625]   Expert 29 |    480 | GPU
DEBUG 01-14 20:42:25.036957.036957 lmp.py:1625]   Expert  7 |    517 | GPU
DEBUG 01-14 20:42:25.036793.036793 lmp.py:1626] 
DEBUG 01-14 20:42:25.036793.036793 lmp.py:1626]   CPU total tokens: 4064 (33.1%)
DEBUG 01-14 20:42:25.036628.036628 lmp.py:1627]   GPU total tokens: 8224 (66.9%)
DEBUG 01-14 20:42:25.036423.036423 cuda_h.py:19] end experts_map_get cost 0.0016698837280273438 seconds
DEBUG 01-14 20:42:25.036691.036691 mlpmodule.py:1367]  experts func einsum cost 0.07346987724304199 s
DEBUG 01-14 20:42:25.036629.036629 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-14 20:42:25.036351.036351 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-14 20:42:25.037892.037892 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-14 20:42:25.039781.039781 cuda_h.py:19] end allocate_cuda_memory cost 0.0019884109497070312 seconds
DEBUG 01-14 20:42:25.039075.039075 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-14 20:42:25.039215.039215 sllm_store_c.py:27] get device uuid map
DEBUG 01-14 20:42:25.039839.039839 sllm_store_c.py:29] call client load into gpu
DEBUG 01-14 20:42:25.039681.039681 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, af437e4b-13a6-4198-ad81-789cebe98688
DEBUG 01-14 20:42:25.039899.039899 client.py:106] call stub.LoadModelAsync
INFO 01-14 20:42:25.039271.039271 client.py:127] Model loaded
DEBUG 01-14 20:42:25.039246.039246 cuda_h.py:10] start restore2model
DEBUG 01-14 20:42:25.040742.040742 cuda_h.py:19] end restore2model cost 0.0003337860107421875 seconds
DEBUG 01-14 20:42:25.040048.040048 cuda_h.py:19] end sllm_worker_task cost 0.014415264129638672 seconds
INFO 01-14 20:42:25.041817.041817 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, af437e4b-13a6-4198-ad81-789cebe98688
DEBUG 01-14 20:42:25.041053.041053 cuda_h.py:19] end load_into_gpu_async cost 0.0024619102478027344 seconds
DEBUG 01-14 20:42:25.041731.041731 cuda_h.py:10] start restore_tensors2
DEBUG 01-14 20:42:25.042868.042868 cuda_h.py:19] end restore_tensors2 cost 0.0004582405090332031 seconds
DEBUG 01-14 20:42:25.042836.042836 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.005385875701904297 seconds
DEBUG 01-14 20:42:25.042838.042838 cuda_h.py:10] start restore2model
DEBUG 01-14 20:42:25.045157.045157 cuda_h.py:19] end restore2model cost 0.0025911331176757812 seconds
DEBUG 01-14 20:42:25.045431.045431 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.008172035217285156 seconds
DEBUG 01-14 20:42:25.045942.045942 cuda_h.py:10] start gpu_sexperts
DEBUG 01-14 20:42:25.045747.045747 cuda_h.py:19] end gpu_sexperts cost 0.0002810955047607422 seconds
DEBUG 01-14 20:42:25.045768.045768 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-14 20:42:25.045948.045948 lmp.py:1683] 
DEBUG 01-14 20:42:25.045948.045948 lmp.py:1683]   Computing 32 experts on CPU...
DEBUG 01-14 20:42:25.045599.045599 cuda_h.py:19] end cpu_experts_submit cost 5.8650970458984375e-05 seconds
DEBUG 01-14 20:42:25.045017.045017 cuda_h.py:10] start experts_func_mgpu_group_pad
DEBUG 01-14 20:42:25.054708.054708 mlpmodule.py:1460] group tensors cost 0.008574724197387695 s
DEBUG 01-14 20:42:25.055883.055883 cuda_h.py:10] start move_flat_hidden2cpu
DEBUG 01-14 20:42:25.058388.058388 cuda_h.py:19] end experts_func_mgpu_group_pad cost 0.012599945068359375 seconds
DEBUG 01-14 20:42:25.060543.060543 cuda_h.py:10] start gpu_group_list
DEBUG 01-14 20:42:25.060803.060803 cuda_h.py:19] end gpu_group_list cost 0.000560760498046875 seconds
DEBUG 01-14 20:42:25.061731.061731 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-14 20:42:25.061985.061985 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.1457672119140625e-05 seconds
DEBUG 01-14 20:42:25.061655.061655 cuda_h.py:10] start wait_experts
INFO 01-14 20:42:25.061802.061802 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, af437e4b-13a6-4198-ad81-789cebe98688
DEBUG 01-14 20:42:25.062852.062852 cuda_h.py:19] end move_flat_hidden2cpu cost 0.007085561752319336 seconds
DEBUG 01-14 20:42:25.064166.064166 mlpmodule.py:1533] pad cost 0.0015621185302734375 s
DEBUG 01-14 20:42:25.064714.064714 mlpmodule.py:1539] create cpu tensor cost 5.269050598144531e-05 s
DEBUG 01-14 20:42:25.066440.066440 mlpmodule.py:1544] move to cpu cost 0.0020787715911865234 s
DEBUG 01-14 20:42:25.075023.075023 mlpmodule.py:1558] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-14 20:42:25.076254.076254 mlpmodule.py:1559] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-14 20:42:25.076615.076615 mlpmodule.py:1564] group_w3 first element: -0.0034942626953125
WARNING 01-14 20:42:25.076254.076254 mlpmodule.py:1574] start einsum2
DEBUG 01-14 20:42:25.093458.093458 mlpmodule.py:1584] group einsum cost 0.02637505531311035 s
DEBUG 01-14 20:42:25.094052.094052 mlpmodule.py:1593] cpy2cputensor cost 0.000732421875 s
DEBUG 01-14 20:42:25.094637.094637 cuda_h.py:10] start move_outputs
DEBUG 01-14 20:42:25.096965.096965 cuda_h.py:19] end move_outputs cost 0.002658367156982422 seconds
INFO 01-14 20:42:25.098986.098986 client.py:127] Model loaded
DEBUG 01-14 20:42:25.098960.098960 cuda_h.py:19] end wait_experts cost 0.03752732276916504 seconds
DEBUG 01-14 20:42:25.098498.098498 cuda_h.py:10] start gpu_experts
DEBUG 01-14 20:42:25.098751.098751 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-14 20:42:25.101045.101045 cuda_h.py:19] end wait_cetm_experts cost 0.0022132396697998047 seconds
DEBUG 01-14 20:42:25.101591.101591 cuda_h.py:10] start gpu_group_einsum_mp_multi_list
DEBUG 01-14 20:42:25.101924.101924 cuda_h.py:10] start gpu_group_tensor
DEBUG 01-14 20:42:25.101283.101283 cuda_h.py:19] end gpu_group_tensor cost 0.000232696533203125 seconds
DEBUG 01-14 20:42:25.101824.101824 cuda_h.py:10] start gpu_group_einsum
DEBUG 01-14 20:42:25.102798.102798 cuda_h.py:19] end gpu_group_einsum cost 0.0005609989166259766 seconds
DEBUG 01-14 20:42:25.102306.102306 cuda_h.py:10] start gpu_final_hidden_states_scatter
DEBUG 01-14 20:42:25.102903.102903 cuda_h.py:10] start all_expert_outputs_slices
DEBUG 01-14 20:42:25.102768.102768 cuda_h.py:19] end all_expert_outputs_slices cost 0.0002892017364501953 seconds
DEBUG 01-14 20:42:25.102240.102240 cuda_h.py:10] start concat_expert_out
DEBUG 01-14 20:42:25.102985.102985 cuda_h.py:19] end concat_expert_out cost 5.817413330078125e-05 seconds
DEBUG 01-14 20:42:25.102358.102358 cuda_h.py:10] start index_scatter
DEBUG 01-14 20:42:25.102739.102739 cuda_h.py:19] end index_scatter cost 7.271766662597656e-05 seconds
DEBUG 01-14 20:42:25.103164.103164 cuda_h.py:19] end gpu_final_hidden_states_scatter cost 0.0006628036499023438 seconds
DEBUG 01-14 20:42:25.103041.103041 cuda_h.py:19] end gpu_experts cost 0.00429987907409668 seconds
DEBUG 01-14 20:42:25.103459.103459 cuda_h.py:10] start all_expert_weight_slices
DEBUG 01-14 20:42:25.104220.104220 cuda_h.py:19] end all_expert_weight_slices cost 0.0009527206420898438 seconds
DEBUG 01-14 20:42:25.104043.104043 cuda_h.py:10] start cpuoutputsdeal
DEBUG 01-14 20:42:25.104568.104568 cuda_h.py:10] start index_scatter
DEBUG 01-14 20:42:25.104843.104843 cuda_h.py:19] end index_scatter cost 4.76837158203125e-05 seconds
DEBUG 01-14 20:42:25.104082.104082 cuda_h.py:19] end cpuoutputsdeal cost 0.0005631446838378906 seconds
DEBUG 01-14 20:42:25.104231.104231 cuda_h.py:19] end layer_moe_generate_mp_l_20 cost 0.07065463066101074 seconds
DEBUG 01-14 20:42:25.105256.105256 cuda_h.py:19] end prefill_layer cost 0.07955241203308105 seconds
DEBUG 01-14 20:42:25.105609.105609 lmp.py:1551] -------------------------------- end prefill layer 19 --------------------------------
DEBUG 01-14 20:42:25.105358.105358 cuda_h.py:10] start prefill_layer
DEBUG 01-14 20:42:25.105584.105584 lmp.py:1494] -------------------------------- start prefill layer 20 --------------------------------
DEBUG 01-14 20:42:25.105002.105002 cuda_h.py:10] start start_load_qkvogn_s_weight_l_21
DEBUG 01-14 20:42:25.105520.105520 cuda_h.py:10] start start_load_qkvogn_s_weight_l_21
DEBUG 01-14 20:42:25.105079.105079 cuda_h.py:19] end start_load_qkvogn_s_weight_l_21 cost 6.818771362304688e-05 seconds
DEBUG 01-14 20:42:25.105233.105233 cuda_h.py:10] start sllm_worker_task
DEBUG 01-14 20:42:25.105706.105706 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-14 20:42:25.105197.105197 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-14 20:42:25.105274.105274 cuda_h.py:19] end start_load_qkvogn_s_weight_l_21 cost 0.00014472007751464844 seconds
DEBUG 01-14 20:42:25.107721.107721 cuda_h.py:19] end allocate_cuda_memory cost 0.002351999282836914 seconds
DEBUG 01-14 20:42:25.108130.108130 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-14 20:42:25.108293.108293 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-14 20:42:25.108804.108804 sllm_store_c.py:27] get device uuid map
DEBUG 01-14 20:42:25.108888.108888 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-14 20:42:25.108370.108370 sllm_store_c.py:29] call client load into gpu
DEBUG 01-14 20:42:25.108691.108691 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 6e0ae6c6-bfbf-49b4-953a-328078ce646a
DEBUG 01-14 20:42:25.108998.108998 client.py:106] call stub.LoadModelAsync
DEBUG 01-14 20:42:25.109982.109982 cuda_h.py:10] start self_attn
INFO 01-14 20:42:25.110661.110661 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 6e0ae6c6-bfbf-49b4-953a-328078ce646a
DEBUG 01-14 20:42:25.110835.110835 cuda_h.py:19] end load_into_gpu_async cost 0.001712799072265625 seconds
DEBUG 01-14 20:42:25.110631.110631 cuda_h.py:10] start restore_tensors2
DEBUG 01-14 20:42:25.110429.110429 cuda_h.py:19] end restore_tensors2 cost 7.05718994140625e-05 seconds
DEBUG 01-14 20:42:25.110754.110754 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.00478672981262207 seconds
INFO 01-14 20:42:25.110743.110743 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 6e0ae6c6-bfbf-49b4-953a-328078ce646a
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
DEBUG 01-14 20:42:25.111433.111433 mlpmodule.py:1367]  experts func einsum cost 0.06528973579406738 s
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-14 20:42:25.112636.112636 cuda_h.py:19] end self_attn cost 0.0032470226287841797 seconds
DEBUG 01-14 20:42:25.112662.112662 cuda_h.py:19] end iln_self_attn_paln cost 0.004412651062011719 seconds
DEBUG 01-14 20:42:25.112366.112366 cuda_h.py:10] start layer_moe_generate_mp_l_21
DEBUG 01-14 20:42:25.112652.112652 cuda_h.py:10] start gate
DEBUG 01-14 20:42:25.113025.113025 cuda_h.py:19] end gate cost 0.0006270408630371094 seconds
DEBUG 01-14 20:42:25.113424.113424 cuda_h.py:10] start experts_map_get
DEBUG 01-14 20:42:25.113792.113792 lmp.py:1615] 
DEBUG 01-14 20:42:25.113792.113792 lmp.py:1615] Expert Token Distribution & Device Allocation:
DEBUG 01-14 20:42:25.113124.113124 lmp.py:1616]   Total experts: 64
DEBUG 01-14 20:42:25.113920.113920 lmp.py:1617]   CPU experts: 32 (50%)
DEBUG 01-14 20:42:25.113662.113662 lmp.py:1618]   GPU experts: 32 (50%)
DEBUG 01-14 20:42:25.113259.113259 lmp.py:1619] 
DEBUG 01-14 20:42:25.113259.113259 lmp.py:1619]   Expert ID | Tokens | Device
DEBUG 01-14 20:42:25.113332.113332 lmp.py:1620]   -----------------------------------
DEBUG 01-14 20:42:25.113883.113883 lmp.py:1625]   Expert 54 |     27 | CPU
DEBUG 01-14 20:42:25.114718.114718 lmp.py:1625]   Expert 28 |     37 | CPU
DEBUG 01-14 20:42:25.114122.114122 lmp.py:1625]   Expert  3 |     42 | CPU
DEBUG 01-14 20:42:25.114004.114004 lmp.py:1625]   Expert  8 |     43 | CPU
DEBUG 01-14 20:42:25.114647.114647 lmp.py:1625]   Expert 43 |     59 | CPU
DEBUG 01-14 20:42:25.114051.114051 lmp.py:1625]   Expert 63 |     62 | CPU
DEBUG 01-14 20:42:25.114456.114456 lmp.py:1625]   Expert  6 |     76 | CPU
DEBUG 01-14 20:42:25.114860.114860 lmp.py:1625]   Expert 57 |     83 | CPU
DEBUG 01-14 20:42:25.114265.114265 lmp.py:1625]   Expert 38 |     87 | CPU
DEBUG 01-14 20:42:25.114431.114431 lmp.py:1625]   Expert 39 |     87 | CPU
DEBUG 01-14 20:42:25.114836.114836 lmp.py:1625]   Expert 36 |     90 | CPU
DEBUG 01-14 20:42:25.114002.114002 lmp.py:1625]   Expert 41 |     97 | CPU
DEBUG 01-14 20:42:25.114168.114168 lmp.py:1625]   Expert 47 |    103 | CPU
DEBUG 01-14 20:42:25.114718.114718 lmp.py:1625]   Expert 52 |    103 | CPU
DEBUG 01-14 20:42:25.114931.114931 lmp.py:1625]   Expert 12 |    104 | CPU
DEBUG 01-14 20:42:25.114381.114381 lmp.py:1625]   Expert 19 |    107 | CPU
DEBUG 01-14 20:42:25.114429.114429 lmp.py:1625]   Expert 13 |    128 | CPU
DEBUG 01-14 20:42:25.114834.114834 lmp.py:1625]   Expert 40 |    143 | CPU
DEBUG 01-14 20:42:25.114284.114284 lmp.py:1625]   Expert 46 |    145 | CPU
DEBUG 01-14 20:42:25.114259.114259 lmp.py:1625]   Expert 50 |    145 | CPU
DEBUG 01-14 20:42:25.114471.114471 lmp.py:1625]   Expert 22 |    147 | CPU
DEBUG 01-14 20:42:25.114683.114683 lmp.py:1625]   Expert  2 |    150 | CPU
DEBUG 01-14 20:42:25.114134.114134 lmp.py:1625]   Expert 37 |    162 | CPU
DEBUG 01-14 20:42:25.114870.114870 lmp.py:1625]   Expert 20 |    163 | CPU
DEBUG 01-14 20:42:25.114844.114844 lmp.py:1625]   Expert 53 |    164 | CPU
DEBUG 01-14 20:42:25.114818.114818 lmp.py:1625]   Expert 21 |    166 | CPU
DEBUG 01-14 20:42:25.114792.114792 lmp.py:1625]   Expert 14 |    171 | CPU
DEBUG 01-14 20:42:25.114528.114528 lmp.py:1625]   Expert 55 |    171 | CPU
DEBUG 01-14 20:42:25.114740.114740 lmp.py:1625]   Expert 23 |    174 | CPU
DEBUG 01-14 20:42:25.114714.114714 lmp.py:1625]   Expert 24 |    177 | CPU
DEBUG 01-14 20:42:25.114927.114927 lmp.py:1625]   Expert 61 |    181 | CPU
DEBUG 01-14 20:42:25.114093.114093 lmp.py:1625]   Expert  0 |    188 | CPU
DEBUG 01-14 20:42:25.114259.114259 lmp.py:1625]   Expert 42 |    188 | GPU
DEBUG 01-14 20:42:25.114948.114948 lmp.py:1625]   Expert  5 |    192 | GPU
DEBUG 01-14 20:42:25.114638.114638 lmp.py:1625]   Expert 49 |    198 | GPU
DEBUG 01-14 20:42:25.114327.114327 lmp.py:1625]   Expert 33 |    200 | GPU
DEBUG 01-14 20:42:25.114301.114301 lmp.py:1625]   Expert 34 |    200 | GPU
DEBUG 01-14 20:42:25.114275.114275 lmp.py:1625]   Expert 30 |    202 | GPU
DEBUG 01-14 20:42:25.114011.114011 lmp.py:1625]   Expert 32 |    203 | GPU
DEBUG 01-14 20:42:25.114223.114223 lmp.py:1625]   Expert 16 |    207 | GPU
DEBUG 01-14 20:42:25.114197.114197 lmp.py:1625]   Expert 18 |    210 | GPU
DEBUG 01-14 20:42:25.114933.114933 lmp.py:1625]   Expert  7 |    212 | GPU
DEBUG 01-14 20:42:25.114145.114145 lmp.py:1625]   Expert  9 |    213 | GPU
DEBUG 01-14 20:42:25.114642.114642 lmp.py:1625]   Expert 59 |    213 | GPU
DEBUG 01-14 20:42:25.114570.114570 lmp.py:1625]   Expert 31 |    215 | GPU
DEBUG 01-14 20:42:25.114498.114498 lmp.py:1625]   Expert 62 |    217 | GPU
DEBUG 01-14 20:42:25.114949.114949 lmp.py:1625]   Expert 10 |    222 | GPU
DEBUG 01-14 20:42:25.114638.114638 lmp.py:1625]   Expert 15 |    224 | GPU
DEBUG 01-14 20:42:25.114327.114327 lmp.py:1625]   Expert 60 |    225 | GPU
DEBUG 01-14 20:42:25.114778.114778 lmp.py:1625]   Expert  4 |    234 | GPU
DEBUG 01-14 20:42:25.114752.114752 lmp.py:1625]   Expert 58 |    237 | GPU
DEBUG 01-14 20:42:25.114488.114488 lmp.py:1625]   Expert 29 |    238 | GPU
DEBUG 01-14 20:42:25.114700.114700 lmp.py:1625]   Expert 17 |    240 | GPU
DEBUG 01-14 20:42:25.114198.114198 lmp.py:1625]   Expert 26 |    249 | GPU
DEBUG 01-14 20:42:25.114410.114410 lmp.py:1625]   Expert 11 |    270 | GPU
DEBUG 01-14 20:42:25.114384.114384 lmp.py:1625]   Expert 44 |    271 | GPU
DEBUG 01-14 20:42:25.114358.114358 lmp.py:1625]   Expert 51 |    274 | GPU
DEBUG 01-14 20:42:25.114332.114332 lmp.py:1625]   Expert 56 |    283 | GPU
DEBUG 01-14 20:42:25.114783.114783 lmp.py:1625]   Expert 27 |    295 | GPU
DEBUG 01-14 20:42:25.114995.114995 lmp.py:1625]   Expert  1 |    344 | GPU
DEBUG 01-14 20:42:25.115685.115685 lmp.py:1625]   Expert 45 |    358 | GPU
DEBUG 01-14 20:42:25.115136.115136 lmp.py:1625]   Expert 25 |    448 | GPU
DEBUG 01-14 20:42:25.115063.115063 lmp.py:1625]   Expert 35 |    513 | GPU
DEBUG 01-14 20:42:25.115037.115037 lmp.py:1625]   Expert 48 |    711 | GPU
DEBUG 01-14 20:42:25.115965.115965 lmp.py:1626] 
DEBUG 01-14 20:42:25.115965.115965 lmp.py:1626]   CPU total tokens: 3782 (30.8%)
DEBUG 01-14 20:42:25.115131.115131 lmp.py:1627]   GPU total tokens: 8506 (69.2%)
DEBUG 01-14 20:42:25.115304.115304 cuda_h.py:19] end experts_map_get cost 0.0015330314636230469 seconds
DEBUG 01-14 20:42:25.115485.115485 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-14 20:42:25.115613.115613 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-14 20:42:25.115180.115180 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-14 20:42:25.117299.117299 cuda_h.py:19] end allocate_cuda_memory cost 0.0021257400512695312 seconds
DEBUG 01-14 20:42:25.117401.117401 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-14 20:42:25.117224.117224 sllm_store_c.py:27] get device uuid map
DEBUG 01-14 20:42:25.117894.117894 sllm_store_c.py:29] call client load into gpu
DEBUG 01-14 20:42:25.117451.117451 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 5c9087f1-df9f-4c20-a257-6ea4c3cdf5f0
DEBUG 01-14 20:42:25.117477.117477 client.py:106] call stub.LoadModelAsync
INFO 01-14 20:42:25.118584.118584 client.py:127] Model loaded
DEBUG 01-14 20:42:25.118818.118818 cuda_h.py:10] start restore2model
DEBUG 01-14 20:42:25.118740.118740 cuda_h.py:19] end restore2model cost 0.0003924369812011719 seconds
DEBUG 01-14 20:42:25.118424.118424 cuda_h.py:19] end sllm_worker_task cost 0.01334524154663086 seconds
INFO 01-14 20:42:25.119957.119957 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 5c9087f1-df9f-4c20-a257-6ea4c3cdf5f0
DEBUG 01-14 20:42:25.120538.120538 cuda_h.py:19] end load_into_gpu_async cost 0.0024614334106445312 seconds
DEBUG 01-14 20:42:25.120316.120316 cuda_h.py:10] start restore_tensors2
DEBUG 01-14 20:42:25.120054.120054 cuda_h.py:19] end restore_tensors2 cost 0.0004067420959472656 seconds
DEBUG 01-14 20:42:25.120883.120883 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0054781436920166016 seconds
DEBUG 01-14 20:42:25.120838.120838 cuda_h.py:10] start restore2model
DEBUG 01-14 20:42:25.123061.123061 cuda_h.py:19] end restore2model cost 0.0024900436401367188 seconds
DEBUG 01-14 20:42:25.123514.123514 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.008139610290527344 seconds
DEBUG 01-14 20:42:25.123117.123117 cuda_h.py:10] start gpu_sexperts
DEBUG 01-14 20:42:25.123956.123956 cuda_h.py:19] end gpu_sexperts cost 0.00029730796813964844 seconds
DEBUG 01-14 20:42:25.123302.123302 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-14 20:42:25.123243.123243 lmp.py:1683] 
DEBUG 01-14 20:42:25.123243.123243 lmp.py:1683]   Computing 32 experts on CPU...
DEBUG 01-14 20:42:25.123272.123272 cuda_h.py:19] end cpu_experts_submit cost 5.626678466796875e-05 seconds
DEBUG 01-14 20:42:25.123637.123637 cuda_h.py:10] start experts_func_mgpu_group_pad
DEBUG 01-14 20:42:25.134525.134525 mlpmodule.py:1460] group tensors cost 0.010229110717773438 s
DEBUG 01-14 20:42:25.135569.135569 cuda_h.py:10] start move_flat_hidden2cpu
DEBUG 01-14 20:42:25.137985.137985 cuda_h.py:19] end experts_func_mgpu_group_pad cost 0.013514518737792969 seconds
DEBUG 01-14 20:42:25.139710.139710 cuda_h.py:10] start gpu_group_list
DEBUG 01-14 20:42:25.139296.139296 cuda_h.py:19] end gpu_group_list cost 0.0005800724029541016 seconds
DEBUG 01-14 20:42:25.140622.140622 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-14 20:42:25.140910.140910 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 3.123283386230469e-05 seconds
DEBUG 01-14 20:42:25.140634.140634 cuda_h.py:10] start wait_experts
INFO 01-14 20:42:25.140595.140595 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 5c9087f1-df9f-4c20-a257-6ea4c3cdf5f0
DEBUG 01-14 20:42:25.141064.141064 cuda_h.py:19] end move_flat_hidden2cpu cost 0.006628513336181641 seconds
DEBUG 01-14 20:42:25.143338.143338 mlpmodule.py:1533] pad cost 0.0015277862548828125 s
DEBUG 01-14 20:42:25.143527.143527 mlpmodule.py:1539] create cpu tensor cost 3.62396240234375e-05 s
DEBUG 01-14 20:42:25.145636.145636 mlpmodule.py:1544] move to cpu cost 0.002218008041381836 s
DEBUG 01-14 20:42:25.155252.155252 mlpmodule.py:1558] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-14 20:42:25.155238.155238 mlpmodule.py:1559] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-14 20:42:25.155407.155407 mlpmodule.py:1564] group_w3 first element: -0.046630859375
WARNING 01-14 20:42:25.155470.155470 mlpmodule.py:1574] start einsum2
DEBUG 01-14 20:42:25.172991.172991 mlpmodule.py:1584] group einsum cost 0.026154041290283203 s
DEBUG 01-14 20:42:25.173890.173890 mlpmodule.py:1593] cpy2cputensor cost 0.0007231235504150391 s
DEBUG 01-14 20:42:25.173435.173435 cuda_h.py:10] start move_outputs
INFO 01-14 20:42:25.174301.174301 client.py:127] Model loaded
DEBUG 01-14 20:42:25.174579.174579 cuda_h.py:19] end wait_experts cost 0.03409624099731445 seconds
DEBUG 01-14 20:42:25.174017.174017 cuda_h.py:10] start gpu_experts
DEBUG 01-14 20:42:25.174840.174840 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-14 20:42:25.175959.175959 cuda_h.py:19] end move_outputs cost 0.002171754837036133 seconds
DEBUG 01-14 20:42:25.179489.179489 cuda_h.py:19] end wait_cetm_experts cost 0.004714012145996094 seconds
DEBUG 01-14 20:42:25.179798.179798 cuda_h.py:10] start gpu_group_einsum_mp_multi_list
DEBUG 01-14 20:42:25.179276.179276 cuda_h.py:10] start gpu_group_tensor
DEBUG 01-14 20:42:25.179073.179073 cuda_h.py:19] end gpu_group_tensor cost 0.00023794174194335938 seconds
DEBUG 01-14 20:42:25.179111.179111 cuda_h.py:10] start gpu_group_einsum
DEBUG 01-14 20:42:25.180507.180507 cuda_h.py:19] end gpu_group_einsum cost 0.0006921291351318359 seconds
DEBUG 01-14 20:42:25.180373.180373 cuda_h.py:10] start gpu_final_hidden_states_scatter
DEBUG 01-14 20:42:25.180866.180866 cuda_h.py:10] start all_expert_outputs_slices
DEBUG 01-14 20:42:25.181555.181555 cuda_h.py:19] end all_expert_outputs_slices cost 0.0003628730773925781 seconds
DEBUG 01-14 20:42:25.181311.181311 cuda_h.py:10] start concat_expert_out
DEBUG 01-14 20:42:25.181247.181247 cuda_h.py:19] end concat_expert_out cost 5.793571472167969e-05 seconds
DEBUG 01-14 20:42:25.181336.181336 cuda_h.py:10] start index_scatter
DEBUG 01-14 20:42:25.181571.181571 cuda_h.py:19] end index_scatter cost 7.104873657226562e-05 seconds
DEBUG 01-14 20:42:25.181903.181903 cuda_h.py:19] end gpu_final_hidden_states_scatter cost 0.0007627010345458984 seconds
DEBUG 01-14 20:42:25.181581.181581 cuda_h.py:19] end gpu_experts cost 0.007127523422241211 seconds
DEBUG 01-14 20:42:25.181238.181238 cuda_h.py:10] start all_expert_weight_slices
DEBUG 01-14 20:42:25.182886.182886 cuda_h.py:19] end all_expert_weight_slices cost 0.00093841552734375 seconds
DEBUG 01-14 20:42:25.182371.182371 cuda_h.py:10] start cpuoutputsdeal
DEBUG 01-14 20:42:25.183710.183710 cuda_h.py:10] start index_scatter
DEBUG 01-14 20:42:25.183177.183177 cuda_h.py:19] end index_scatter cost 4.887580871582031e-05 seconds
DEBUG 01-14 20:42:25.183377.183377 cuda_h.py:19] end cpuoutputsdeal cost 0.0005366802215576172 seconds
DEBUG 01-14 20:42:25.183281.183281 cuda_h.py:19] end layer_moe_generate_mp_l_21 cost 0.07040977478027344 seconds
DEBUG 01-14 20:42:25.183619.183619 cuda_h.py:19] end prefill_layer cost 0.07835674285888672 seconds
DEBUG 01-14 20:42:25.183640.183640 lmp.py:1551] -------------------------------- end prefill layer 20 --------------------------------
DEBUG 01-14 20:42:25.183058.183058 cuda_h.py:10] start prefill_layer
DEBUG 01-14 20:42:25.183430.183430 lmp.py:1494] -------------------------------- start prefill layer 21 --------------------------------
DEBUG 01-14 20:42:25.183663.183663 cuda_h.py:10] start start_load_qkvogn_s_weight_l_22
DEBUG 01-14 20:42:25.183803.183803 cuda_h.py:10] start start_load_qkvogn_s_weight_l_22
DEBUG 01-14 20:42:25.183845.183845 cuda_h.py:19] end start_load_qkvogn_s_weight_l_22 cost 3.7670135498046875e-05 seconds
DEBUG 01-14 20:42:25.183932.183932 cuda_h.py:19] end start_load_qkvogn_s_weight_l_22 cost 6.914138793945312e-05 seconds
DEBUG 01-14 20:42:25.183490.183490 cuda_h.py:10] start sllm_worker_task
DEBUG 01-14 20:42:25.184274.184274 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-14 20:42:25.184773.184773 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-14 20:42:25.184274.184274 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-14 20:42:25.187933.187933 cuda_h.py:19] end allocate_cuda_memory cost 0.0028259754180908203 seconds
DEBUG 01-14 20:42:25.187759.187759 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-14 20:42:25.187093.187093 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-14 20:42:25.187205.187205 sllm_store_c.py:27] get device uuid map
DEBUG 01-14 20:42:25.187379.187379 sllm_store_c.py:29] call client load into gpu
DEBUG 01-14 20:42:25.187281.187281 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, db12d304-f246-418e-a78d-78dd8740c909
DEBUG 01-14 20:42:25.187410.187410 client.py:106] call stub.LoadModelAsync
DEBUG 01-14 20:42:25.188699.188699 cuda_h.py:10] start self_attn
INFO 01-14 20:42:25.188461.188461 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, db12d304-f246-418e-a78d-78dd8740c909
DEBUG 01-14 20:42:25.188542.188542 cuda_h.py:19] end load_into_gpu_async cost 0.001161336898803711 seconds
DEBUG 01-14 20:42:25.188828.188828 cuda_h.py:10] start restore_tensors2
DEBUG 01-14 20:42:25.188547.188547 cuda_h.py:19] end restore_tensors2 cost 7.390975952148438e-05 seconds
DEBUG 01-14 20:42:25.188740.188740 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.004653453826904297 seconds
INFO 01-14 20:42:25.188729.188729 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, db12d304-f246-418e-a78d-78dd8740c909
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-14 20:42:25.191684.191684 mlpmodule.py:1367]  experts func einsum cost 0.06703782081604004 s
DEBUG 01-14 20:42:25.191925.191925 cuda_h.py:19] end self_attn cost 0.0037071704864501953 seconds
DEBUG 01-14 20:42:25.192381.192381 cuda_h.py:19] end iln_self_attn_paln cost 0.007997274398803711 seconds
DEBUG 01-14 20:42:25.192469.192469 cuda_h.py:10] start layer_moe_generate_mp_l_22
DEBUG 01-14 20:42:25.192709.192709 cuda_h.py:10] start gate
DEBUG 01-14 20:42:25.193981.193981 cuda_h.py:19] end gate cost 0.0007615089416503906 seconds
DEBUG 01-14 20:42:25.193287.193287 cuda_h.py:10] start experts_map_get
DEBUG 01-14 20:42:25.193384.193384 lmp.py:1615] 
DEBUG 01-14 20:42:25.193384.193384 lmp.py:1615] Expert Token Distribution & Device Allocation:
DEBUG 01-14 20:42:25.193491.193491 lmp.py:1616]   Total experts: 64
DEBUG 01-14 20:42:25.193048.193048 lmp.py:1617]   CPU experts: 32 (50%)
DEBUG 01-14 20:42:25.193552.193552 lmp.py:1618]   GPU experts: 32 (50%)
DEBUG 01-14 20:42:25.193434.193434 lmp.py:1619] 
DEBUG 01-14 20:42:25.193434.193434 lmp.py:1619]   Expert ID | Tokens | Device
DEBUG 01-14 20:42:25.193030.193030 lmp.py:1620]   -----------------------------------
DEBUG 01-14 20:42:25.193627.193627 lmp.py:1625]   Expert 11 |     36 | CPU
DEBUG 01-14 20:42:25.193555.193555 lmp.py:1625]   Expert 44 |     42 | CPU
DEBUG 01-14 20:42:25.193244.193244 lmp.py:1625]   Expert  9 |     46 | CPU
DEBUG 01-14 20:42:25.193456.193456 lmp.py:1625]   Expert 54 |     57 | CPU
DEBUG 01-14 20:42:25.193146.193146 lmp.py:1625]   Expert 56 |     70 | CPU
DEBUG 01-14 20:42:25.193597.193597 lmp.py:1625]   Expert 62 |     89 | CPU
DEBUG 01-14 20:42:25.193571.193571 lmp.py:1625]   Expert 51 |     95 | CPU
DEBUG 01-14 20:42:25.193313.193313 lmp.py:1625]   Expert 47 |    101 | CPU
DEBUG 01-14 20:42:25.193479.193479 lmp.py:1625]   Expert 22 |    102 | CPU
DEBUG 01-14 20:42:25.193645.193645 lmp.py:1625]   Expert 35 |    105 | CPU
DEBUG 01-14 20:42:25.193811.193811 lmp.py:1625]   Expert  7 |    106 | CPU
DEBUG 01-14 20:42:25.193739.193739 lmp.py:1625]   Expert 41 |    108 | CPU
DEBUG 01-14 20:42:25.193905.193905 lmp.py:1625]   Expert 60 |    109 | CPU
DEBUG 01-14 20:42:25.193356.193356 lmp.py:1625]   Expert 52 |    112 | CPU
DEBUG 01-14 20:42:25.193330.193330 lmp.py:1625]   Expert  8 |    116 | CPU
DEBUG 01-14 20:42:25.193304.193304 lmp.py:1625]   Expert  1 |    121 | CPU
DEBUG 01-14 20:42:25.193040.193040 lmp.py:1625]   Expert  6 |    126 | CPU
DEBUG 01-14 20:42:25.193252.193252 lmp.py:1625]   Expert 48 |    126 | CPU
DEBUG 01-14 20:42:25.193465.193465 lmp.py:1625]   Expert  2 |    132 | CPU
DEBUG 01-14 20:42:25.193439.193439 lmp.py:1625]   Expert 53 |    132 | CPU
DEBUG 01-14 20:42:25.193413.193413 lmp.py:1625]   Expert 27 |    133 | CPU
DEBUG 01-14 20:42:25.193486.193486 lmp.py:1625]   Expert 32 |    133 | CPU
DEBUG 01-14 20:42:25.193891.193891 lmp.py:1625]   Expert 59 |    137 | CPU
DEBUG 01-14 20:42:25.193819.193819 lmp.py:1625]   Expert 23 |    140 | CPU
DEBUG 01-14 20:42:25.193746.193746 lmp.py:1625]   Expert 50 |    143 | CPU
DEBUG 01-14 20:42:25.194436.194436 lmp.py:1625]   Expert 14 |    147 | CPU
DEBUG 01-14 20:42:25.194125.194125 lmp.py:1625]   Expert 49 |    151 | CPU
DEBUG 01-14 20:42:25.194337.194337 lmp.py:1625]   Expert 39 |    154 | CPU
DEBUG 01-14 20:42:25.194312.194312 lmp.py:1625]   Expert 26 |    157 | CPU
DEBUG 01-14 20:42:25.194286.194286 lmp.py:1625]   Expert 34 |    158 | CPU
DEBUG 01-14 20:42:25.194260.194260 lmp.py:1625]   Expert 24 |    167 | CPU
DEBUG 01-14 20:42:25.194995.194995 lmp.py:1625]   Expert 38 |    167 | CPU
DEBUG 01-14 20:42:25.194492.194492 lmp.py:1625]   Expert  4 |    174 | GPU
DEBUG 01-14 20:42:25.194467.194467 lmp.py:1625]   Expert 40 |    184 | GPU
DEBUG 01-14 20:42:25.194586.194586 lmp.py:1625]   Expert 43 |    185 | GPU
DEBUG 01-14 20:42:25.194945.194945 lmp.py:1625]   Expert 57 |    188 | GPU
DEBUG 01-14 20:42:25.194872.194872 lmp.py:1625]   Expert  0 |    189 | GPU
DEBUG 01-14 20:42:25.194323.194323 lmp.py:1625]   Expert 46 |    190 | GPU
DEBUG 01-14 20:42:25.194774.194774 lmp.py:1625]   Expert 61 |    195 | GPU
DEBUG 01-14 20:42:25.194986.194986 lmp.py:1625]   Expert 19 |    196 | GPU
DEBUG 01-14 20:42:25.194199.194199 lmp.py:1625]   Expert 63 |    196 | GPU
DEBUG 01-14 20:42:25.194411.194411 lmp.py:1625]   Expert 13 |    202 | GPU
DEBUG 01-14 20:42:25.194147.194147 lmp.py:1625]   Expert  5 |    205 | GPU
DEBUG 01-14 20:42:25.194883.194883 lmp.py:1625]   Expert 29 |    208 | GPU
DEBUG 01-14 20:42:25.194380.194380 lmp.py:1625]   Expert 31 |    216 | GPU
DEBUG 01-14 20:42:25.194116.194116 lmp.py:1625]   Expert 33 |    220 | GPU
DEBUG 01-14 20:42:25.194851.194851 lmp.py:1625]   Expert 16 |    238 | GPU
DEBUG 01-14 20:42:25.194779.194779 lmp.py:1625]   Expert 37 |    242 | GPU
DEBUG 01-14 20:42:25.194137.194137 lmp.py:1625]   Expert  3 |    257 | GPU
DEBUG 01-14 20:42:25.194826.194826 lmp.py:1625]   Expert 20 |    259 | GPU
DEBUG 01-14 20:42:25.194516.194516 lmp.py:1625]   Expert 36 |    270 | GPU
DEBUG 01-14 20:42:25.194967.194967 lmp.py:1625]   Expert 15 |    274 | GPU
DEBUG 01-14 20:42:25.194179.194179 lmp.py:1625]   Expert 18 |    284 | GPU
DEBUG 01-14 20:42:25.194391.194391 lmp.py:1625]   Expert 17 |    312 | GPU
DEBUG 01-14 20:42:25.194127.194127 lmp.py:1625]   Expert 12 |    315 | GPU
DEBUG 01-14 20:42:25.194101.194101 lmp.py:1625]   Expert 30 |    315 | GPU
DEBUG 01-14 20:42:25.194075.194075 lmp.py:1625]   Expert 28 |    317 | GPU
DEBUG 01-14 20:42:25.194049.194049 lmp.py:1625]   Expert 55 |    317 | GPU
DEBUG 01-14 20:42:25.194454.194454 lmp.py:1625]   Expert 58 |    334 | GPU
DEBUG 01-14 20:42:25.194382.194382 lmp.py:1625]   Expert 25 |    351 | GPU
DEBUG 01-14 20:42:25.194309.194309 lmp.py:1625]   Expert 10 |    376 | GPU
DEBUG 01-14 20:42:25.194999.194999 lmp.py:1625]   Expert 45 |    381 | GPU
DEBUG 01-14 20:42:25.194688.194688 lmp.py:1625]   Expert 21 |    384 | GPU
DEBUG 01-14 20:42:25.194377.194377 lmp.py:1625]   Expert 42 |    596 | GPU
DEBUG 01-14 20:42:25.194120.194120 lmp.py:1626] 
DEBUG 01-14 20:42:25.194120.194120 lmp.py:1626]   CPU total tokens: 3718 (30.3%)
DEBUG 01-14 20:42:25.194193.194193 lmp.py:1627]   GPU total tokens: 8570 (69.7%)
DEBUG 01-14 20:42:25.194320.194320 cuda_h.py:19] end experts_map_get cost 0.0015401840209960938 seconds
DEBUG 01-14 20:42:25.194885.194885 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-14 20:42:25.194443.194443 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-14 20:42:25.194017.194017 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-14 20:42:25.195244.195244 cuda_h.py:19] end allocate_cuda_memory cost 0.0005884170532226562 seconds
DEBUG 01-14 20:42:25.195424.195424 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-14 20:42:25.195704.195704 sllm_store_c.py:27] get device uuid map
DEBUG 01-14 20:42:25.195897.195897 sllm_store_c.py:29] call client load into gpu
DEBUG 01-14 20:42:25.195739.195739 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 727b8ce9-af98-43a7-8544-908770f01379
DEBUG 01-14 20:42:25.195395.195395 client.py:106] call stub.LoadModelAsync
INFO 01-14 20:42:25.196514.196514 client.py:127] Model loaded
DEBUG 01-14 20:42:25.196873.196873 cuda_h.py:10] start restore2model
DEBUG 01-14 20:42:25.196655.196655 cuda_h.py:19] end restore2model cost 0.0003657341003417969 seconds
DEBUG 01-14 20:42:25.196531.196531 cuda_h.py:19] end sllm_worker_task cost 0.012542963027954102 seconds
INFO 01-14 20:42:25.197263.197263 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 727b8ce9-af98-43a7-8544-908770f01379
DEBUG 01-14 20:42:25.197967.197967 cuda_h.py:19] end load_into_gpu_async cost 0.0015256404876708984 seconds
DEBUG 01-14 20:42:25.197100.197100 cuda_h.py:10] start restore_tensors2
DEBUG 01-14 20:42:25.197458.197458 cuda_h.py:19] end restore_tensors2 cost 0.00037479400634765625 seconds
DEBUG 01-14 20:42:25.197871.197871 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.002855062484741211 seconds
DEBUG 01-14 20:42:25.197832.197832 cuda_h.py:10] start restore2model
DEBUG 01-14 20:42:25.200814.200814 cuda_h.py:19] end restore2model cost 0.0025811195373535156 seconds
DEBUG 01-14 20:42:25.200506.200506 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.0056591033935546875 seconds
DEBUG 01-14 20:42:25.200970.200970 cuda_h.py:10] start gpu_sexperts
DEBUG 01-14 20:42:25.200094.200094 cuda_h.py:19] end gpu_sexperts cost 0.0003044605255126953 seconds
DEBUG 01-14 20:42:25.200586.200586 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-14 20:42:25.200958.200958 lmp.py:1683] 
DEBUG 01-14 20:42:25.200958.200958 lmp.py:1683]   Computing 32 experts on CPU...
DEBUG 01-14 20:42:25.200099.200099 cuda_h.py:19] end cpu_experts_submit cost 6.866455078125e-05 seconds
DEBUG 01-14 20:42:25.200663.200663 cuda_h.py:10] start experts_func_mgpu_group_pad
DEBUG 01-14 20:42:25.211209.211209 mlpmodule.py:1460] group tensors cost 0.009855031967163086 s
DEBUG 01-14 20:42:25.212532.212532 cuda_h.py:10] start move_flat_hidden2cpu
DEBUG 01-14 20:42:25.217884.217884 cuda_h.py:19] end experts_func_mgpu_group_pad cost 0.016621828079223633 seconds
DEBUG 01-14 20:42:25.218430.218430 cuda_h.py:19] end move_flat_hidden2cpu cost 0.006173372268676758 seconds
DEBUG 01-14 20:42:25.220158.220158 cuda_h.py:10] start gpu_group_list
DEBUG 01-14 20:42:25.221562.221562 cuda_h.py:19] end gpu_group_list cost 0.0007860660552978516 seconds
DEBUG 01-14 20:42:25.221247.221247 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-14 20:42:25.222576.222576 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.9802322387695312e-05 seconds
DEBUG 01-14 20:42:25.222896.222896 cuda_h.py:10] start wait_experts
INFO 01-14 20:42:25.222547.222547 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 727b8ce9-af98-43a7-8544-908770f01379
DEBUG 01-14 20:42:25.222162.222162 mlpmodule.py:1533] pad cost 0.003934144973754883 s
DEBUG 01-14 20:42:25.222908.222908 mlpmodule.py:1539] create cpu tensor cost 4.076957702636719e-05 s
DEBUG 01-14 20:42:25.224876.224876 mlpmodule.py:1544] move to cpu cost 0.001975536346435547 s
DEBUG 01-14 20:42:25.233091.233091 mlpmodule.py:1558] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-14 20:42:25.234732.234732 mlpmodule.py:1559] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-14 20:42:25.234424.234424 mlpmodule.py:1564] group_w3 first element: 0.00066375732421875
WARNING 01-14 20:42:25.234349.234349 mlpmodule.py:1574] start einsum2
DEBUG 01-14 20:42:25.252552.252552 mlpmodule.py:1584] group einsum cost 0.027417659759521484 s
INFO 01-14 20:42:25.253366.253366 client.py:127] Model loaded
DEBUG 01-14 20:42:25.253120.253120 mlpmodule.py:1593] cpy2cputensor cost 0.0009398460388183594 s
DEBUG 01-14 20:42:25.253768.253768 cuda_h.py:19] end wait_experts cost 0.03110647201538086 seconds
DEBUG 01-14 20:42:25.253910.253910 cuda_h.py:10] start move_outputs
DEBUG 01-14 20:42:25.253098.253098 cuda_h.py:10] start gpu_experts
DEBUG 01-14 20:42:25.253760.253760 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-14 20:42:25.255591.255591 cuda_h.py:19] end move_outputs cost 0.0019540786743164062 seconds
DEBUG 01-14 20:42:25.259648.259648 cuda_h.py:19] end wait_cetm_experts cost 0.0055158138275146484 seconds
DEBUG 01-14 20:42:25.259540.259540 cuda_h.py:10] start gpu_group_einsum_mp_multi_list
DEBUG 01-14 20:42:25.259733.259733 cuda_h.py:10] start gpu_group_tensor
DEBUG 01-14 20:42:25.259140.259140 cuda_h.py:19] end gpu_group_tensor cost 0.000232696533203125 seconds
DEBUG 01-14 20:42:25.259561.259561 cuda_h.py:10] start gpu_group_einsum
DEBUG 01-14 20:42:25.260973.260973 cuda_h.py:19] end gpu_group_einsum cost 0.0005691051483154297 seconds
DEBUG 01-14 20:42:25.260911.260911 cuda_h.py:10] start gpu_final_hidden_states_scatter
DEBUG 01-14 20:42:25.260893.260893 cuda_h.py:10] start all_expert_outputs_slices
DEBUG 01-14 20:42:25.260228.260228 cuda_h.py:19] end all_expert_outputs_slices cost 0.00028634071350097656 seconds
DEBUG 01-14 20:42:25.261600.261600 cuda_h.py:10] start concat_expert_out
DEBUG 01-14 20:42:25.261252.261252 cuda_h.py:19] end concat_expert_out cost 5.888938903808594e-05 seconds
DEBUG 01-14 20:42:25.261625.261625 cuda_h.py:10] start index_scatter
DEBUG 01-14 20:42:25.261529.261529 cuda_h.py:19] end index_scatter cost 7.271766662597656e-05 seconds
DEBUG 01-14 20:42:25.261815.261815 cuda_h.py:19] end gpu_final_hidden_states_scatter cost 0.0006592273712158203 seconds
DEBUG 01-14 20:42:25.261255.261255 cuda_h.py:19] end gpu_experts cost 0.00768733024597168 seconds
DEBUG 01-14 20:42:25.261773.261773 cuda_h.py:10] start all_expert_weight_slices
DEBUG 01-14 20:42:25.262097.262097 cuda_h.py:19] end all_expert_weight_slices cost 0.0009438991546630859 seconds
DEBUG 01-14 20:42:25.262264.262264 cuda_h.py:10] start cpuoutputsdeal
DEBUG 01-14 20:42:25.262649.262649 cuda_h.py:10] start index_scatter
DEBUG 01-14 20:42:25.262354.262354 cuda_h.py:19] end index_scatter cost 5.125999450683594e-05 seconds
DEBUG 01-14 20:42:25.263263.263263 cuda_h.py:19] end cpuoutputsdeal cost 0.0005316734313964844 seconds
DEBUG 01-14 20:42:25.263696.263696 cuda_h.py:19] end layer_moe_generate_mp_l_22 cost 0.07081484794616699 seconds
DEBUG 01-14 20:42:25.263053.263053 cuda_h.py:19] end prefill_layer cost 0.07970380783081055 seconds
DEBUG 01-14 20:42:25.263975.263975 lmp.py:1551] -------------------------------- end prefill layer 21 --------------------------------
DEBUG 01-14 20:42:25.263201.263201 cuda_h.py:10] start prefill_layer
DEBUG 01-14 20:42:25.263427.263427 lmp.py:1494] -------------------------------- start prefill layer 22 --------------------------------
DEBUG 01-14 20:42:25.263607.263607 cuda_h.py:10] start start_load_qkvogn_s_weight_l_23
DEBUG 01-14 20:42:25.263892.263892 cuda_h.py:10] start start_load_qkvogn_s_weight_l_23
DEBUG 01-14 20:42:25.263120.263120 cuda_h.py:19] end start_load_qkvogn_s_weight_l_23 cost 3.457069396972656e-05 seconds
DEBUG 01-14 20:42:25.263114.263114 cuda_h.py:19] end start_load_qkvogn_s_weight_l_23 cost 6.723403930664062e-05 seconds
DEBUG 01-14 20:42:25.263632.263632 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-14 20:42:25.263144.263144 cuda_h.py:10] start sllm_worker_task
DEBUG 01-14 20:42:25.263328.263328 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-14 20:42:25.264489.264489 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-14 20:42:25.264984.264984 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-14 20:42:25.266751.266751 cuda_h.py:19] end allocate_cuda_memory cost 0.0018906593322753906 seconds
DEBUG 01-14 20:42:25.266727.266727 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-14 20:42:25.266113.266113 sllm_store_c.py:27] get device uuid map
DEBUG 01-14 20:42:25.266838.266838 sllm_store_c.py:29] call client load into gpu
DEBUG 01-14 20:42:25.266316.266316 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 97fa382d-63d1-4709-a81f-126b6d3dda07
DEBUG 01-14 20:42:25.266505.266505 client.py:106] call stub.LoadModelAsync
DEBUG 01-14 20:42:25.266979.266979 cuda_h.py:10] start self_attn
INFO 01-14 20:42:25.267898.267898 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 97fa382d-63d1-4709-a81f-126b6d3dda07
DEBUG 01-14 20:42:25.268722.268722 cuda_h.py:19] end load_into_gpu_async cost 0.0017826557159423828 seconds
DEBUG 01-14 20:42:25.268147.268147 cuda_h.py:10] start restore_tensors2
DEBUG 01-14 20:42:25.268568.268568 cuda_h.py:19] end restore_tensors2 cost 6.914138793945312e-05 seconds
DEBUG 01-14 20:42:25.268344.268344 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.004048585891723633 seconds
INFO 01-14 20:42:25.268034.268034 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 97fa382d-63d1-4709-a81f-126b6d3dda07
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-14 20:42:25.269260.269260 mlpmodule.py:1367]  experts func einsum cost 0.06836605072021484 s
DEBUG 01-14 20:42:25.270175.270175 cuda_h.py:19] end self_attn cost 0.0032143592834472656 seconds
DEBUG 01-14 20:42:25.270412.270412 cuda_h.py:19] end iln_self_attn_paln cost 0.006773471832275391 seconds
DEBUG 01-14 20:42:25.270262.270262 cuda_h.py:10] start layer_moe_generate_mp_l_23
DEBUG 01-14 20:42:25.270786.270786 cuda_h.py:10] start gate
DEBUG 01-14 20:42:25.271465.271465 cuda_h.py:19] end gate cost 0.0006422996520996094 seconds
DEBUG 01-14 20:42:25.271625.271625 cuda_h.py:10] start experts_map_get
DEBUG 01-14 20:42:25.271616.271616 lmp.py:1615] 
DEBUG 01-14 20:42:25.271616.271616 lmp.py:1615] Expert Token Distribution & Device Allocation:
DEBUG 01-14 20:42:25.271756.271756 lmp.py:1616]   Total experts: 64
DEBUG 01-14 20:42:25.271359.271359 lmp.py:1617]   CPU experts: 32 (50%)
DEBUG 01-14 20:42:25.271863.271863 lmp.py:1618]   GPU experts: 32 (50%)
DEBUG 01-14 20:42:25.271983.271983 lmp.py:1619] 
DEBUG 01-14 20:42:25.271983.271983 lmp.py:1619]   Expert ID | Tokens | Device
DEBUG 01-14 20:42:25.271580.271580 lmp.py:1620]   -----------------------------------
DEBUG 01-14 20:42:25.271322.271322 lmp.py:1625]   Expert 25 |     16 | CPU
DEBUG 01-14 20:42:25.271542.271542 lmp.py:1625]   Expert 45 |     31 | CPU
DEBUG 01-14 20:42:25.271661.271661 lmp.py:1625]   Expert 48 |     38 | CPU
DEBUG 01-14 20:42:25.271020.271020 lmp.py:1625]   Expert  9 |     59 | CPU
DEBUG 01-14 20:42:25.271378.271378 lmp.py:1625]   Expert 43 |     71 | CPU
DEBUG 01-14 20:42:25.271498.271498 lmp.py:1625]   Expert 54 |     77 | CPU
DEBUG 01-14 20:42:25.272141.272141 lmp.py:1625]   Expert  0 |     82 | CPU
DEBUG 01-14 20:42:25.272784.272784 lmp.py:1625]   Expert 47 |     85 | CPU
DEBUG 01-14 20:42:25.272950.272950 lmp.py:1625]   Expert  6 |     92 | CPU
DEBUG 01-14 20:42:25.272354.272354 lmp.py:1625]   Expert 50 |     92 | CPU
DEBUG 01-14 20:42:25.272520.272520 lmp.py:1625]   Expert  1 |     97 | CPU
DEBUG 01-14 20:42:25.272687.272687 lmp.py:1625]   Expert 15 |    100 | CPU
DEBUG 01-14 20:42:25.272191.272191 lmp.py:1625]   Expert 20 |    101 | CPU
DEBUG 01-14 20:42:25.272787.272787 lmp.py:1625]   Expert 13 |    105 | CPU
DEBUG 01-14 20:42:25.272430.272430 lmp.py:1625]   Expert 62 |    106 | CPU
DEBUG 01-14 20:42:25.272073.272073 lmp.py:1625]   Expert 61 |    110 | CPU
DEBUG 01-14 20:42:25.272478.272478 lmp.py:1625]   Expert 21 |    111 | CPU
DEBUG 01-14 20:42:25.272644.272644 lmp.py:1625]   Expert 36 |    111 | CPU
DEBUG 01-14 20:42:25.272810.272810 lmp.py:1625]   Expert 57 |    117 | CPU
DEBUG 01-14 20:42:25.272738.272738 lmp.py:1625]   Expert 37 |    119 | CPU
DEBUG 01-14 20:42:25.272665.272665 lmp.py:1625]   Expert 38 |    126 | CPU
DEBUG 01-14 20:42:25.272355.272355 lmp.py:1625]   Expert 46 |    126 | CPU
DEBUG 01-14 20:42:25.272044.272044 lmp.py:1625]   Expert  7 |    130 | CPU
DEBUG 01-14 20:42:25.272210.272210 lmp.py:1625]   Expert 14 |    145 | CPU
DEBUG 01-14 20:42:25.272138.272138 lmp.py:1625]   Expert 24 |    145 | CPU
DEBUG 01-14 20:42:25.272596.272596 lmp.py:1625]   Expert 42 |    148 | CPU
DEBUG 01-14 20:42:25.272715.272715 lmp.py:1625]   Expert 31 |    150 | CPU
DEBUG 01-14 20:42:25.272802.272802 lmp.py:1625]   Expert  2 |    160 | CPU
DEBUG 01-14 20:42:25.272684.272684 lmp.py:1625]   Expert 10 |    160 | CPU
DEBUG 01-14 20:42:25.272426.272426 lmp.py:1625]   Expert 11 |    161 | CPU
DEBUG 01-14 20:42:25.272639.272639 lmp.py:1625]   Expert 44 |    161 | CPU
DEBUG 01-14 20:42:25.272374.272374 lmp.py:1625]   Expert 26 |    163 | CPU
DEBUG 01-14 20:42:25.272587.272587 lmp.py:1625]   Expert 52 |    168 | GPU
DEBUG 01-14 20:42:25.272084.272084 lmp.py:1625]   Expert 28 |    170 | GPU
DEBUG 01-14 20:42:25.272296.272296 lmp.py:1625]   Expert 32 |    178 | GPU
DEBUG 01-14 20:42:25.272270.272270 lmp.py:1625]   Expert 35 |    178 | GPU
DEBUG 01-14 20:42:25.272006.272006 lmp.py:1625]   Expert  3 |    183 | GPU
DEBUG 01-14 20:42:25.272457.272457 lmp.py:1625]   Expert 19 |    188 | GPU
DEBUG 01-14 20:42:25.272431.272431 lmp.py:1625]   Expert 12 |    195 | GPU
DEBUG 01-14 20:42:25.272266.272266 lmp.py:1625]   Expert 56 |    199 | GPU
DEBUG 01-14 20:42:25.272147.272147 lmp.py:1625]   Expert  8 |    206 | GPU
DEBUG 01-14 20:42:25.272075.272075 lmp.py:1625]   Expert 41 |    212 | GPU
DEBUG 01-14 20:42:25.272765.272765 lmp.py:1625]   Expert 60 |    212 | GPU
DEBUG 01-14 20:42:25.272454.272454 lmp.py:1625]   Expert 59 |    220 | GPU
DEBUG 01-14 20:42:25.272905.272905 lmp.py:1625]   Expert  4 |    222 | GPU
DEBUG 01-14 20:42:25.272117.272117 lmp.py:1625]   Expert 16 |    231 | GPU
DEBUG 01-14 20:42:25.272330.272330 lmp.py:1625]   Expert 40 |    233 | GPU
DEBUG 01-14 20:42:25.272065.272065 lmp.py:1625]   Expert 23 |    241 | GPU
DEBUG 01-14 20:42:25.272278.272278 lmp.py:1625]   Expert 53 |    247 | GPU
DEBUG 01-14 20:42:25.272490.272490 lmp.py:1625]   Expert 55 |    247 | GPU
DEBUG 01-14 20:42:25.272703.272703 lmp.py:1625]   Expert 51 |    251 | GPU
DEBUG 01-14 20:42:25.272392.272392 lmp.py:1625]   Expert 58 |    254 | GPU
DEBUG 01-14 20:42:25.272181.272181 lmp.py:1625]   Expert 49 |    261 | GPU
DEBUG 01-14 20:42:25.272870.272870 lmp.py:1625]   Expert 34 |    273 | GPU
DEBUG 01-14 20:42:25.272321.272321 lmp.py:1625]   Expert 18 |    276 | GPU
DEBUG 01-14 20:42:25.272010.272010 lmp.py:1625]   Expert 29 |    284 | GPU
DEBUG 01-14 20:42:25.272176.272176 lmp.py:1625]   Expert 63 |    303 | GPU
DEBUG 01-14 20:42:25.272627.272627 lmp.py:1625]   Expert 27 |    375 | GPU
DEBUG 01-14 20:42:25.272601.272601 lmp.py:1625]   Expert 39 |    385 | GPU
DEBUG 01-14 20:42:25.272814.272814 lmp.py:1625]   Expert 33 |    396 | GPU
DEBUG 01-14 20:42:25.272026.272026 lmp.py:1625]   Expert 17 |    415 | GPU
DEBUG 01-14 20:42:25.272000.272000 lmp.py:1625]   Expert 22 |    418 | GPU
DEBUG 01-14 20:42:25.272213.272213 lmp.py:1625]   Expert 30 |    481 | GPU
DEBUG 01-14 20:42:25.272902.272902 lmp.py:1625]   Expert  5 |    691 | GPU
DEBUG 01-14 20:42:25.273929.273929 lmp.py:1626] 
DEBUG 01-14 20:42:25.273929.273929 lmp.py:1626]   CPU total tokens: 3495 (28.4%)
DEBUG 01-14 20:42:25.273526.273526 lmp.py:1627]   GPU total tokens: 8793 (71.6%)
DEBUG 01-14 20:42:25.273699.273699 cuda_h.py:19] end experts_map_get cost 0.0015704631805419922 seconds
DEBUG 01-14 20:42:25.273118.273118 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-14 20:42:25.273822.273822 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-14 20:42:25.273496.273496 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-14 20:42:25.275742.275742 cuda_h.py:19] end allocate_cuda_memory cost 0.0019729137420654297 seconds
DEBUG 01-14 20:42:25.275446.275446 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-14 20:42:25.275679.275679 sllm_store_c.py:27] get device uuid map
DEBUG 01-14 20:42:25.275064.275064 sllm_store_c.py:29] call client load into gpu
DEBUG 01-14 20:42:25.275621.275621 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 7346aa18-685f-46f2-a48c-3227a4ca3db4
DEBUG 01-14 20:42:25.275814.275814 client.py:106] call stub.LoadModelAsync
INFO 01-14 20:42:25.276153.276153 client.py:127] Model loaded
DEBUG 01-14 20:42:25.276413.276413 cuda_h.py:10] start restore2model
DEBUG 01-14 20:42:25.276491.276491 cuda_h.py:19] end restore2model cost 0.0003409385681152344 seconds
DEBUG 01-14 20:42:25.276546.276546 cuda_h.py:19] end sllm_worker_task cost 0.01259160041809082 seconds
INFO 01-14 20:42:25.277145.277145 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 7346aa18-685f-46f2-a48c-3227a4ca3db4
DEBUG 01-14 20:42:25.277332.277332 cuda_h.py:19] end load_into_gpu_async cost 0.002305269241333008 seconds
DEBUG 01-14 20:42:25.277989.277989 cuda_h.py:10] start restore_tensors2
DEBUG 01-14 20:42:25.278484.278484 cuda_h.py:19] end restore_tensors2 cost 0.0003390312194824219 seconds
DEBUG 01-14 20:42:25.278413.278413 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.004977226257324219 seconds
DEBUG 01-14 20:42:25.278560.278560 cuda_h.py:10] start restore2model
DEBUG 01-14 20:42:25.280383.280383 cuda_h.py:19] end restore2model cost 0.0025734901428222656 seconds
DEBUG 01-14 20:42:25.280703.280703 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.007740497589111328 seconds
DEBUG 01-14 20:42:25.280783.280783 cuda_h.py:10] start gpu_sexperts
DEBUG 01-14 20:42:25.281767.281767 cuda_h.py:19] end gpu_sexperts cost 0.0002722740173339844 seconds
DEBUG 01-14 20:42:25.281636.281636 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-14 20:42:25.281723.281723 lmp.py:1683] 
DEBUG 01-14 20:42:25.281723.281723 lmp.py:1683]   Computing 32 experts on CPU...
DEBUG 01-14 20:42:25.281374.281374 cuda_h.py:19] end cpu_experts_submit cost 5.936622619628906e-05 seconds
DEBUG 01-14 20:42:25.281030.281030 cuda_h.py:10] start experts_func_mgpu_group_pad
DEBUG 01-14 20:42:25.291003.291003 mlpmodule.py:1460] group tensors cost 0.009854316711425781 s
DEBUG 01-14 20:42:25.292541.292541 cuda_h.py:10] start move_flat_hidden2cpu
DEBUG 01-14 20:42:25.295912.295912 cuda_h.py:19] end experts_func_mgpu_group_pad cost 0.013619422912597656 seconds
DEBUG 01-14 20:42:25.296668.296668 cuda_h.py:10] start gpu_group_list
DEBUG 01-14 20:42:25.297587.297587 cuda_h.py:19] end gpu_group_list cost 0.0004475116729736328 seconds
DEBUG 01-14 20:42:25.297885.297885 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-14 20:42:25.297604.297604 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.8848648071289062e-05 seconds
DEBUG 01-14 20:42:25.297321.297321 cuda_h.py:10] start wait_experts
INFO 01-14 20:42:25.297799.297799 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 7346aa18-685f-46f2-a48c-3227a4ca3db4
DEBUG 01-14 20:42:25.298845.298845 cuda_h.py:19] end move_flat_hidden2cpu cost 0.006446123123168945 seconds
DEBUG 01-14 20:42:25.300225.300225 mlpmodule.py:1533] pad cost 0.0015425682067871094 s
DEBUG 01-14 20:42:25.300599.300599 mlpmodule.py:1539] create cpu tensor cost 3.5762786865234375e-05 s
DEBUG 01-14 20:42:25.302122.302122 mlpmodule.py:1544] move to cpu cost 0.0019283294677734375 s
DEBUG 01-14 20:42:25.311276.311276 mlpmodule.py:1558] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-14 20:42:25.311294.311294 mlpmodule.py:1559] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-14 20:42:25.311271.311271 mlpmodule.py:1564] group_w3 first element: -0.018798828125
WARNING 01-14 20:42:25.311096.311096 mlpmodule.py:1574] start einsum2
DEBUG 01-14 20:42:25.328368.328368 mlpmodule.py:1584] group einsum cost 0.0254518985748291 s
DEBUG 01-14 20:42:25.328445.328445 mlpmodule.py:1593] cpy2cputensor cost 0.0007312297821044922 s
DEBUG 01-14 20:42:25.329367.329367 cuda_h.py:10] start move_outputs
DEBUG 01-14 20:42:25.331301.331301 cuda_h.py:19] end move_outputs cost 0.002517223358154297 seconds
INFO 01-14 20:42:25.334443.334443 client.py:127] Model loaded
DEBUG 01-14 20:42:25.334886.334886 cuda_h.py:19] end wait_experts cost 0.03680872917175293 seconds
DEBUG 01-14 20:42:25.334424.334424 cuda_h.py:10] start gpu_experts
DEBUG 01-14 20:42:25.334200.334200 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-14 20:42:25.335040.335040 cuda_h.py:19] end wait_cetm_experts cost 0.001104116439819336 seconds
DEBUG 01-14 20:42:25.335109.335109 cuda_h.py:10] start gpu_group_einsum_mp_multi_list
DEBUG 01-14 20:42:25.335634.335634 cuda_h.py:10] start gpu_group_tensor
DEBUG 01-14 20:42:25.336061.336061 cuda_h.py:19] end gpu_group_tensor cost 0.0002796649932861328 seconds
DEBUG 01-14 20:42:25.336430.336430 cuda_h.py:10] start gpu_group_einsum
DEBUG 01-14 20:42:25.336397.336397 cuda_h.py:19] end gpu_group_einsum cost 0.0005574226379394531 seconds
DEBUG 01-14 20:42:25.336428.336428 cuda_h.py:10] start gpu_final_hidden_states_scatter
DEBUG 01-14 20:42:25.337410.337410 cuda_h.py:10] start all_expert_outputs_slices
DEBUG 01-14 20:42:25.337692.337692 cuda_h.py:19] end all_expert_outputs_slices cost 0.00028228759765625 seconds
DEBUG 01-14 20:42:25.337733.337733 cuda_h.py:10] start concat_expert_out
DEBUG 01-14 20:42:25.337716.337716 cuda_h.py:19] end concat_expert_out cost 5.650520324707031e-05 seconds
DEBUG 01-14 20:42:25.337858.337858 cuda_h.py:10] start index_scatter
DEBUG 01-14 20:42:25.337623.337623 cuda_h.py:19] end index_scatter cost 7.176399230957031e-05 seconds
DEBUG 01-14 20:42:25.337478.337478 cuda_h.py:19] end gpu_final_hidden_states_scatter cost 0.0006618499755859375 seconds
DEBUG 01-14 20:42:25.337441.337441 cuda_h.py:19] end gpu_experts cost 0.003246784210205078 seconds
DEBUG 01-14 20:42:25.337429.337429 cuda_h.py:10] start all_expert_weight_slices
DEBUG 01-14 20:42:25.338945.338945 cuda_h.py:19] end all_expert_weight_slices cost 0.0009467601776123047 seconds
DEBUG 01-14 20:42:25.338622.338622 cuda_h.py:10] start cpuoutputsdeal
DEBUG 01-14 20:42:25.339252.339252 cuda_h.py:10] start index_scatter
DEBUG 01-14 20:42:25.339904.339904 cuda_h.py:19] end index_scatter cost 4.7206878662109375e-05 seconds
DEBUG 01-14 20:42:25.339621.339621 cuda_h.py:19] end cpuoutputsdeal cost 0.0005319118499755859 seconds
DEBUG 01-14 20:42:25.339338.339338 cuda_h.py:19] end layer_moe_generate_mp_l_23 cost 0.06870412826538086 seconds
DEBUG 01-14 20:42:25.339239.339239 cuda_h.py:19] end prefill_layer cost 0.07626152038574219 seconds
DEBUG 01-14 20:42:25.339691.339691 lmp.py:1551] -------------------------------- end prefill layer 22 --------------------------------
DEBUG 01-14 20:42:25.339109.339109 cuda_h.py:10] start prefill_layer
DEBUG 01-14 20:42:25.339765.339765 lmp.py:1494] -------------------------------- start prefill layer 23 --------------------------------
DEBUG 01-14 20:42:25.339614.339614 cuda_h.py:10] start start_load_qkvogn_s_weight_l_24
DEBUG 01-14 20:42:25.339940.339940 cuda_h.py:10] start start_load_qkvogn_s_weight_l_24
DEBUG 01-14 20:42:25.340982.340982 cuda_h.py:19] end start_load_qkvogn_s_weight_l_24 cost 3.814697265625e-05 seconds
DEBUG 01-14 20:42:25.340784.340784 cuda_h.py:19] end start_load_qkvogn_s_weight_l_24 cost 7.009506225585938e-05 seconds
DEBUG 01-14 20:42:25.340111.340111 cuda_h.py:10] start sllm_worker_task
DEBUG 01-14 20:42:25.340708.340708 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-14 20:42:25.340057.340057 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-14 20:42:25.340890.340890 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-14 20:42:25.340827.340827 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-14 20:42:25.343518.343518 cuda_h.py:19] end allocate_cuda_memory cost 0.002299070358276367 seconds
DEBUG 01-14 20:42:25.343840.343840 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-14 20:42:25.343808.343808 sllm_store_c.py:27] get device uuid map
DEBUG 01-14 20:42:25.343514.343514 sllm_store_c.py:29] call client load into gpu
DEBUG 01-14 20:42:25.343561.343561 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, fa0336a2-e43c-4d53-9a06-c6f5b9bf8a55
DEBUG 01-14 20:42:25.343684.343684 client.py:106] call stub.LoadModelAsync
DEBUG 01-14 20:42:25.343236.343236 cuda_h.py:10] start self_attn
INFO 01-14 20:42:25.344566.344566 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, fa0336a2-e43c-4d53-9a06-c6f5b9bf8a55
DEBUG 01-14 20:42:25.344469.344469 cuda_h.py:19] end load_into_gpu_async cost 0.0017161369323730469 seconds
DEBUG 01-14 20:42:25.344695.344695 cuda_h.py:10] start restore_tensors2
DEBUG 01-14 20:42:25.345446.345446 cuda_h.py:19] end restore_tensors2 cost 7.176399230957031e-05 seconds
DEBUG 01-14 20:42:25.345964.345964 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0045201778411865234 seconds
INFO 01-14 20:42:25.345270.345270 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, fa0336a2-e43c-4d53-9a06-c6f5b9bf8a55
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-14 20:42:25.346568.346568 cuda_h.py:19] end self_attn cost 0.0029516220092773438 seconds
DEBUG 01-14 20:42:25.346640.346640 mlpmodule.py:1367]  experts func einsum cost 0.06508159637451172 s
DEBUG 01-14 20:42:25.347156.347156 cuda_h.py:19] end iln_self_attn_paln cost 0.00683283805847168 seconds
DEBUG 01-14 20:42:25.347829.347829 cuda_h.py:10] start layer_moe_generate_mp_l_24
DEBUG 01-14 20:42:25.347360.347360 cuda_h.py:10] start gate
DEBUG 01-14 20:42:25.348793.348793 cuda_h.py:19] end gate cost 0.0006308555603027344 seconds
DEBUG 01-14 20:42:25.348953.348953 cuda_h.py:10] start experts_map_get
DEBUG 01-14 20:42:25.348156.348156 lmp.py:1615] 
DEBUG 01-14 20:42:25.348156.348156 lmp.py:1615] Expert Token Distribution & Device Allocation:
DEBUG 01-14 20:42:25.348727.348727 lmp.py:1616]   Total experts: 64
DEBUG 01-14 20:42:25.348330.348330 lmp.py:1617]   CPU experts: 32 (50%)
DEBUG 01-14 20:42:25.348788.348788 lmp.py:1618]   GPU experts: 32 (50%)
DEBUG 01-14 20:42:25.348385.348385 lmp.py:1619] 
DEBUG 01-14 20:42:25.348385.348385 lmp.py:1619]   Expert ID | Tokens | Device
DEBUG 01-14 20:42:25.348935.348935 lmp.py:1620]   -----------------------------------
DEBUG 01-14 20:42:25.348485.348485 lmp.py:1625]   Expert  5 |     13 | CPU
DEBUG 01-14 20:42:25.348082.348082 lmp.py:1625]   Expert 56 |     41 | CPU
DEBUG 01-14 20:42:25.348202.348202 lmp.py:1625]   Expert 27 |     85 | CPU
DEBUG 01-14 20:42:25.348606.348606 lmp.py:1625]   Expert 16 |     93 | CPU
DEBUG 01-14 20:42:25.348011.348011 lmp.py:1625]   Expert 40 |     97 | CPU
DEBUG 01-14 20:42:25.348131.348131 lmp.py:1625]   Expert 17 |     98 | CPU
DEBUG 01-14 20:42:25.348012.348012 lmp.py:1625]   Expert 53 |     99 | CPU
DEBUG 01-14 20:42:25.348893.348893 lmp.py:1625]   Expert 47 |    101 | CPU
DEBUG 01-14 20:42:25.348490.348490 lmp.py:1625]   Expert 28 |    106 | CPU
DEBUG 01-14 20:42:25.348087.348087 lmp.py:1625]   Expert  7 |    114 | CPU
DEBUG 01-14 20:42:25.348730.348730 lmp.py:1625]   Expert 37 |    114 | CPU
DEBUG 01-14 20:42:25.348896.348896 lmp.py:1625]   Expert 49 |    116 | CPU
DEBUG 01-14 20:42:25.348300.348300 lmp.py:1625]   Expert 51 |    117 | CPU
DEBUG 01-14 20:42:25.348705.348705 lmp.py:1625]   Expert 63 |    119 | CPU
DEBUG 01-14 20:42:25.348871.348871 lmp.py:1625]   Expert 58 |    127 | CPU
DEBUG 01-14 20:42:25.348037.348037 lmp.py:1625]   Expert 57 |    136 | CPU
DEBUG 01-14 20:42:25.348442.348442 lmp.py:1625]   Expert 38 |    138 | CPU
DEBUG 01-14 20:42:25.348800.348800 lmp.py:1625]   Expert 14 |    147 | CPU
DEBUG 01-14 20:42:25.348443.348443 lmp.py:1625]   Expert 39 |    148 | CPU
DEBUG 01-14 20:42:25.348848.348848 lmp.py:1625]   Expert 12 |    152 | CPU
DEBUG 01-14 20:42:25.348729.348729 lmp.py:1625]   Expert 62 |    152 | CPU
DEBUG 01-14 20:42:25.348372.348372 lmp.py:1625]   Expert  1 |    153 | CPU
DEBUG 01-14 20:42:25.348300.348300 lmp.py:1625]   Expert 33 |    154 | CPU
DEBUG 01-14 20:42:25.348135.348135 lmp.py:1625]   Expert 11 |    155 | CPU
DEBUG 01-14 20:42:25.348493.348493 lmp.py:1625]   Expert 52 |    159 | CPU
DEBUG 01-14 20:42:25.349944.349944 lmp.py:1625]   Expert 23 |    160 | CPU
DEBUG 01-14 20:42:25.349918.349918 lmp.py:1625]   Expert 25 |    162 | CPU
DEBUG 01-14 20:42:25.349952.349952 lmp.py:1625]   Expert 30 |    162 | CPU
DEBUG 01-14 20:42:25.349456.349456 lmp.py:1625]   Expert 21 |    165 | CPU
DEBUG 01-14 20:42:25.349384.349384 lmp.py:1625]   Expert 45 |    178 | CPU
DEBUG 01-14 20:42:25.349834.349834 lmp.py:1625]   Expert 36 |    182 | CPU
DEBUG 01-14 20:42:25.349524.349524 lmp.py:1625]   Expert  6 |    184 | CPU
DEBUG 01-14 20:42:25.349213.349213 lmp.py:1625]   Expert 55 |    184 | GPU
DEBUG 01-14 20:42:25.349664.349664 lmp.py:1625]   Expert 31 |    187 | GPU
DEBUG 01-14 20:42:25.349400.349400 lmp.py:1625]   Expert 60 |    188 | GPU
DEBUG 01-14 20:42:25.349612.349612 lmp.py:1625]   Expert  9 |    190 | GPU
DEBUG 01-14 20:42:25.349348.349348 lmp.py:1625]   Expert 44 |    197 | GPU
DEBUG 01-14 20:42:25.349560.349560 lmp.py:1625]   Expert  4 |    200 | GPU
DEBUG 01-14 20:42:25.349534.349534 lmp.py:1625]   Expert 19 |    203 | GPU
DEBUG 01-14 20:42:25.349508.349508 lmp.py:1625]   Expert  3 |    205 | GPU
DEBUG 01-14 20:42:25.349482.349482 lmp.py:1625]   Expert 34 |    210 | GPU
DEBUG 01-14 20:42:25.349410.349410 lmp.py:1625]   Expert 50 |    224 | GPU
DEBUG 01-14 20:42:25.349384.349384 lmp.py:1625]   Expert 22 |    226 | GPU
DEBUG 01-14 20:42:25.349073.349073 lmp.py:1625]   Expert 26 |    229 | GPU
DEBUG 01-14 20:42:25.349001.349001 lmp.py:1625]   Expert  0 |    232 | GPU
DEBUG 01-14 20:42:25.349690.349690 lmp.py:1625]   Expert 43 |    235 | GPU
DEBUG 01-14 20:42:25.349426.349426 lmp.py:1625]   Expert 59 |    236 | GPU
DEBUG 01-14 20:42:25.349400.349400 lmp.py:1625]   Expert 18 |    237 | GPU
DEBUG 01-14 20:42:25.349374.349374 lmp.py:1625]   Expert 41 |    238 | GPU
DEBUG 01-14 20:42:25.349110.349110 lmp.py:1625]   Expert 13 |    240 | GPU
DEBUG 01-14 20:42:25.349322.349322 lmp.py:1625]   Expert 42 |    250 | GPU
DEBUG 01-14 20:42:25.349819.349819 lmp.py:1625]   Expert 61 |    253 | GPU
DEBUG 01-14 20:42:25.349555.349555 lmp.py:1625]   Expert 54 |    257 | GPU
DEBUG 01-14 20:42:25.349006.349006 lmp.py:1625]   Expert 20 |    260 | GPU
DEBUG 01-14 20:42:25.349695.349695 lmp.py:1625]   Expert 24 |    261 | GPU
DEBUG 01-14 20:42:25.349384.349384 lmp.py:1625]   Expert 15 |    263 | GPU
DEBUG 01-14 20:42:25.349074.349074 lmp.py:1625]   Expert 35 |    272 | GPU
DEBUG 01-14 20:42:25.349001.349001 lmp.py:1625]   Expert 29 |    281 | GPU
DEBUG 01-14 20:42:25.349976.349976 lmp.py:1625]   Expert 32 |    290 | GPU
DEBUG 01-14 20:42:25.349950.349950 lmp.py:1625]   Expert 10 |    301 | GPU
DEBUG 01-14 20:42:25.349924.349924 lmp.py:1625]   Expert  8 |    338 | GPU
DEBUG 01-14 20:42:25.349898.349898 lmp.py:1625]   Expert  2 |    350 | GPU
DEBUG 01-14 20:42:25.349872.349872 lmp.py:1625]   Expert 46 |    449 | GPU
DEBUG 01-14 20:42:25.349276.349276 lmp.py:1625]   Expert 48 |    475 | GPU
DEBUG 01-14 20:42:25.349158.349158 lmp.py:1626] 
DEBUG 01-14 20:42:25.349158.349158 lmp.py:1626]   CPU total tokens: 4127 (33.6%)
DEBUG 01-14 20:42:25.349516.349516 lmp.py:1627]   GPU total tokens: 8161 (66.4%)
DEBUG 01-14 20:42:25.349642.349642 cuda_h.py:19] end experts_map_get cost 0.0015683174133300781 seconds
DEBUG 01-14 20:42:25.349539.349539 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-14 20:42:25.349097.349097 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-14 20:42:25.349956.349956 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-14 20:42:25.351223.351223 cuda_h.py:19] end allocate_cuda_memory cost 0.0012166500091552734 seconds
DEBUG 01-14 20:42:25.351404.351404 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-14 20:42:25.351445.351445 sllm_store_c.py:27] get device uuid map
DEBUG 01-14 20:42:25.351168.351168 sllm_store_c.py:29] call client load into gpu
DEBUG 01-14 20:42:25.351248.351248 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 1757ee94-9b71-4c30-8923-6764a2e94556
DEBUG 01-14 20:42:25.351036.351036 client.py:106] call stub.LoadModelAsync
INFO 01-14 20:42:25.352996.352996 client.py:127] Model loaded
DEBUG 01-14 20:42:25.353217.353217 cuda_h.py:10] start restore2model
DEBUG 01-14 20:42:25.353845.353845 cuda_h.py:19] end restore2model cost 0.0003235340118408203 seconds
DEBUG 01-14 20:42:25.353945.353945 cuda_h.py:19] end sllm_worker_task cost 0.013098001480102539 seconds
INFO 01-14 20:42:25.354007.354007 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 1757ee94-9b71-4c30-8923-6764a2e94556
DEBUG 01-14 20:42:25.354188.354188 cuda_h.py:19] end load_into_gpu_async cost 0.0032143592834472656 seconds
DEBUG 01-14 20:42:25.354606.354606 cuda_h.py:10] start restore_tensors2
DEBUG 01-14 20:42:25.354294.354294 cuda_h.py:19] end restore_tensors2 cost 0.00033974647521972656 seconds
DEBUG 01-14 20:42:25.354170.354170 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.005122184753417969 seconds
DEBUG 01-14 20:42:25.355886.355886 cuda_h.py:10] start restore2model
DEBUG 01-14 20:42:25.357383.357383 cuda_h.py:19] end restore2model cost 0.0025491714477539062 seconds
DEBUG 01-14 20:42:25.357571.357571 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.007861137390136719 seconds
DEBUG 01-14 20:42:25.357625.357625 cuda_h.py:10] start gpu_sexperts
DEBUG 01-14 20:42:25.358470.358470 cuda_h.py:19] end gpu_sexperts cost 0.0002715587615966797 seconds
DEBUG 01-14 20:42:25.358101.358101 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-14 20:42:25.358042.358042 lmp.py:1683] 
DEBUG 01-14 20:42:25.358042.358042 lmp.py:1683]   Computing 32 experts on CPU...
DEBUG 01-14 20:42:25.358806.358806 cuda_h.py:19] end cpu_experts_submit cost 5.626678466796875e-05 seconds
DEBUG 01-14 20:42:25.358648.358648 cuda_h.py:10] start experts_func_mgpu_group_pad
DEBUG 01-14 20:42:25.375367.375367 mlpmodule.py:1460] group tensors cost 0.01694178581237793 s
DEBUG 01-14 20:42:25.376358.376358 cuda_h.py:10] start move_flat_hidden2cpu
DEBUG 01-14 20:42:25.382480.382480 cuda_h.py:19] end experts_func_mgpu_group_pad cost 0.023986339569091797 seconds
DEBUG 01-14 20:42:25.383931.383931 cuda_h.py:19] end move_flat_hidden2cpu cost 0.006747722625732422 seconds
DEBUG 01-14 20:42:25.386406.386406 cuda_h.py:10] start gpu_group_list
DEBUG 01-14 20:42:25.387864.387864 cuda_h.py:19] end gpu_group_list cost 0.0012259483337402344 seconds
DEBUG 01-14 20:42:25.388899.388899 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-14 20:42:25.388284.388284 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 4.38690185546875e-05 seconds
DEBUG 01-14 20:42:25.388109.388109 cuda_h.py:10] start wait_experts
INFO 01-14 20:42:25.388254.388254 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 1757ee94-9b71-4c30-8923-6764a2e94556
DEBUG 01-14 20:42:25.388600.388600 mlpmodule.py:1533] pad cost 0.005380153656005859 s
DEBUG 01-14 20:42:25.388008.388008 mlpmodule.py:1539] create cpu tensor cost 3.9577484130859375e-05 s
DEBUG 01-14 20:42:25.391685.391685 mlpmodule.py:1544] move to cpu cost 0.0021817684173583984 s
DEBUG 01-14 20:42:25.400545.400545 mlpmodule.py:1558] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-14 20:42:25.400683.400683 mlpmodule.py:1559] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-14 20:42:25.400270.400270 mlpmodule.py:1564] group_w3 first element: 0.08447265625
WARNING 01-14 20:42:25.400129.400129 mlpmodule.py:1574] start einsum2
INFO 01-14 20:42:25.407679.407679 client.py:127] Model loaded
DEBUG 01-14 20:42:25.407011.407011 cuda_h.py:19] end wait_experts cost 0.019049882888793945 seconds
DEBUG 01-14 20:42:25.407973.407973 cuda_h.py:10] start gpu_experts
DEBUG 01-14 20:42:25.407948.407948 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-14 20:42:25.417240.417240 mlpmodule.py:1584] group einsum cost 0.026767492294311523 s
DEBUG 01-14 20:42:25.418743.418743 mlpmodule.py:1593] cpy2cputensor cost 0.0007686614990234375 s
DEBUG 01-14 20:42:25.418612.418612 cuda_h.py:10] start move_outputs
DEBUG 01-14 20:42:25.421823.421823 cuda_h.py:19] end move_outputs cost 0.002126455307006836 seconds
DEBUG 01-14 20:42:25.424034.424034 cuda_h.py:19] end wait_cetm_experts cost 0.017116546630859375 seconds
DEBUG 01-14 20:42:25.425882.425882 cuda_h.py:10] start gpu_group_einsum_mp_multi_list
DEBUG 01-14 20:42:25.425294.425294 cuda_h.py:10] start gpu_group_tensor
DEBUG 01-14 20:42:25.425728.425728 cuda_h.py:19] end gpu_group_tensor cost 0.00024890899658203125 seconds
DEBUG 01-14 20:42:25.425513.425513 cuda_h.py:10] start gpu_group_einsum
DEBUG 01-14 20:42:25.426366.426366 cuda_h.py:19] end gpu_group_einsum cost 0.0006842613220214844 seconds
DEBUG 01-14 20:42:25.426033.426033 cuda_h.py:10] start gpu_final_hidden_states_scatter
DEBUG 01-14 20:42:25.426459.426459 cuda_h.py:10] start all_expert_outputs_slices
DEBUG 01-14 20:42:25.426016.426016 cuda_h.py:19] end all_expert_outputs_slices cost 0.0003705024719238281 seconds
DEBUG 01-14 20:42:25.426441.426441 cuda_h.py:10] start concat_expert_out
DEBUG 01-14 20:42:25.427901.427901 cuda_h.py:19] end concat_expert_out cost 5.6743621826171875e-05 seconds
DEBUG 01-14 20:42:25.427943.427943 cuda_h.py:10] start index_scatter
DEBUG 01-14 20:42:25.427662.427662 cuda_h.py:19] end index_scatter cost 7.557868957519531e-05 seconds
DEBUG 01-14 20:42:25.427709.427709 cuda_h.py:19] end gpu_final_hidden_states_scatter cost 0.0007643699645996094 seconds
DEBUG 01-14 20:42:25.427910.427910 cuda_h.py:19] end gpu_experts cost 0.019657135009765625 seconds
DEBUG 01-14 20:42:25.427328.427328 cuda_h.py:10] start all_expert_weight_slices
DEBUG 01-14 20:42:25.428546.428546 cuda_h.py:19] end all_expert_weight_slices cost 0.0009374618530273438 seconds
DEBUG 01-14 20:42:25.428270.428270 cuda_h.py:10] start cpuoutputsdeal
DEBUG 01-14 20:42:25.428412.428412 cuda_h.py:10] start index_scatter
DEBUG 01-14 20:42:25.428640.428640 cuda_h.py:19] end index_scatter cost 4.649162292480469e-05 seconds
DEBUG 01-14 20:42:25.428595.428595 cuda_h.py:19] end cpuoutputsdeal cost 0.000537872314453125 seconds
DEBUG 01-14 20:42:25.429551.429551 cuda_h.py:19] end layer_moe_generate_mp_l_24 cost 0.08167552947998047 seconds
DEBUG 01-14 20:42:25.429922.429922 cuda_h.py:19] end prefill_layer cost 0.08950686454772949 seconds
DEBUG 01-14 20:42:25.429135.429135 lmp.py:1551] -------------------------------- end prefill layer 23 --------------------------------
DEBUG 01-14 20:42:25.429077.429077 cuda_h.py:10] start prefill_layer
DEBUG 01-14 20:42:25.429972.429972 lmp.py:1494] -------------------------------- start prefill layer 24 --------------------------------
DEBUG 01-14 20:42:25.429105.429105 cuda_h.py:10] start start_load_qkvogn_s_weight_l_25
DEBUG 01-14 20:42:25.429192.429192 cuda_h.py:10] start start_load_qkvogn_s_weight_l_25
DEBUG 01-14 20:42:25.429042.429042 cuda_h.py:19] end start_load_qkvogn_s_weight_l_25 cost 3.695487976074219e-05 seconds
DEBUG 01-14 20:42:25.429036.429036 cuda_h.py:19] end start_load_qkvogn_s_weight_l_25 cost 7.009506225585938e-05 seconds
DEBUG 01-14 20:42:25.429839.429839 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-14 20:42:25.429597.429597 cuda_h.py:10] start sllm_worker_task
DEBUG 01-14 20:42:25.429389.429389 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-14 20:42:25.430709.430709 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-14 20:42:25.431406.431406 cuda_h.py:19] end allocate_cuda_memory cost 0.0015959739685058594 seconds
DEBUG 01-14 20:42:25.431815.431815 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-14 20:42:25.431618.431618 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-14 20:42:25.431769.431769 sllm_store_c.py:27] get device uuid map
DEBUG 01-14 20:42:25.432181.432181 sllm_store_c.py:29] call client load into gpu
DEBUG 01-14 20:42:25.432321.432321 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, fc641c13-5b30-4207-9be4-1359e36afba9
DEBUG 01-14 20:42:25.432987.432987 client.py:106] call stub.LoadModelAsync
DEBUG 01-14 20:42:25.432960.432960 cuda_h.py:10] start self_attn
INFO 01-14 20:42:25.434146.434146 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, fc641c13-5b30-4207-9be4-1359e36afba9
DEBUG 01-14 20:42:25.434660.434660 cuda_h.py:19] end load_into_gpu_async cost 0.0024535655975341797 seconds
DEBUG 01-14 20:42:25.434094.434094 cuda_h.py:10] start restore_tensors2
DEBUG 01-14 20:42:25.434395.434395 cuda_h.py:19] end restore_tensors2 cost 0.00020074844360351562 seconds
DEBUG 01-14 20:42:25.434982.434982 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.004988908767700195 seconds
INFO 01-14 20:42:25.435670.435670 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, fc641c13-5b30-4207-9be4-1359e36afba9
DEBUG 01-14 20:42:25.435469.435469 mlpmodule.py:1367]  experts func einsum cost 0.07698464393615723 s
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-14 20:42:25.437148.437148 cuda_h.py:19] end self_attn cost 0.004544734954833984 seconds
DEBUG 01-14 20:42:25.437589.437589 cuda_h.py:19] end iln_self_attn_paln cost 0.007746696472167969 seconds
DEBUG 01-14 20:42:25.437539.437539 cuda_h.py:10] start layer_moe_generate_mp_l_25
DEBUG 01-14 20:42:25.437778.437778 cuda_h.py:10] start gate
DEBUG 01-14 20:42:25.438880.438880 cuda_h.py:19] end gate cost 0.0006375312805175781 seconds
DEBUG 01-14 20:42:25.438578.438578 cuda_h.py:10] start experts_map_get
DEBUG 01-14 20:42:25.438290.438290 lmp.py:1615] 
DEBUG 01-14 20:42:25.438290.438290 lmp.py:1615] Expert Token Distribution & Device Allocation:
DEBUG 01-14 20:42:25.438808.438808 lmp.py:1616]   Total experts: 64
DEBUG 01-14 20:42:25.438696.438696 lmp.py:1617]   CPU experts: 32 (50%)
DEBUG 01-14 20:42:25.438008.438008 lmp.py:1618]   GPU experts: 32 (50%)
DEBUG 01-14 20:42:25.438366.438366 lmp.py:1619] 
DEBUG 01-14 20:42:25.438366.438366 lmp.py:1619]   Expert ID | Tokens | Device
DEBUG 01-14 20:42:25.438486.438486 lmp.py:1620]   -----------------------------------
DEBUG 01-14 20:42:25.438798.438798 lmp.py:1625]   Expert 36 |     23 | CPU
DEBUG 01-14 20:42:25.438540.438540 lmp.py:1625]   Expert 35 |     42 | CPU
DEBUG 01-14 20:42:25.438567.438567 lmp.py:1625]   Expert 25 |     49 | CPU
DEBUG 01-14 20:42:25.438118.438118 lmp.py:1625]   Expert 30 |     54 | CPU
DEBUG 01-14 20:42:25.438668.438668 lmp.py:1625]   Expert 51 |     54 | CPU
DEBUG 01-14 20:42:25.438457.438457 lmp.py:1625]   Expert 46 |     60 | CPU
DEBUG 01-14 20:42:25.438437.438437 lmp.py:1625]   Expert 55 |     63 | CPU
DEBUG 01-14 20:42:25.438226.438226 lmp.py:1625]   Expert 43 |     64 | CPU
DEBUG 01-14 20:42:25.438492.438492 lmp.py:1625]   Expert 47 |     66 | CPU
DEBUG 01-14 20:42:25.438088.438088 lmp.py:1625]   Expert 44 |     75 | CPU
DEBUG 01-14 20:42:25.438639.438639 lmp.py:1625]   Expert 16 |     80 | CPU
DEBUG 01-14 20:42:25.439474.439474 lmp.py:1625]   Expert  0 |     81 | CPU
DEBUG 01-14 20:42:25.439024.439024 lmp.py:1625]   Expert  2 |     82 | CPU
DEBUG 01-14 20:42:25.439859.439859 lmp.py:1625]   Expert 39 |     88 | CPU
DEBUG 01-14 20:42:25.439410.439410 lmp.py:1625]   Expert 42 |     97 | CPU
DEBUG 01-14 20:42:25.439006.439006 lmp.py:1625]   Expert  4 |     99 | CPU
DEBUG 01-14 20:42:25.439795.439795 lmp.py:1625]   Expert 54 |    122 | CPU
DEBUG 01-14 20:42:25.439392.439392 lmp.py:1625]   Expert 33 |    124 | CPU
DEBUG 01-14 20:42:25.439704.439704 lmp.py:1625]   Expert 48 |    124 | CPU
DEBUG 01-14 20:42:25.439015.439015 lmp.py:1625]   Expert 61 |    128 | CPU
DEBUG 01-14 20:42:25.439281.439281 lmp.py:1625]   Expert 24 |    131 | CPU
DEBUG 01-14 20:42:25.439070.439070 lmp.py:1625]   Expert 29 |    133 | CPU
DEBUG 01-14 20:42:25.439097.439097 lmp.py:1625]   Expert 15 |    137 | CPU
DEBUG 01-14 20:42:25.439170.439170 lmp.py:1625]   Expert  6 |    139 | CPU
DEBUG 01-14 20:42:25.439721.439721 lmp.py:1625]   Expert 38 |    147 | CPU
DEBUG 01-14 20:42:25.439317.439317 lmp.py:1625]   Expert 56 |    148 | CPU
DEBUG 01-14 20:42:25.439868.439868 lmp.py:1625]   Expert  7 |    150 | CPU
DEBUG 01-14 20:42:25.439464.439464 lmp.py:1625]   Expert 19 |    153 | CPU
DEBUG 01-14 20:42:25.439267.439267 lmp.py:1625]   Expert 59 |    153 | CPU
DEBUG 01-14 20:42:25.439340.439340 lmp.py:1625]   Expert 62 |    153 | CPU
DEBUG 01-14 20:42:25.439057.439057 lmp.py:1625]   Expert  9 |    156 | CPU
DEBUG 01-14 20:42:25.439561.439561 lmp.py:1625]   Expert 13 |    158 | CPU
DEBUG 01-14 20:42:25.439111.439111 lmp.py:1625]   Expert 20 |    164 | GPU
DEBUG 01-14 20:42:25.439423.439423 lmp.py:1625]   Expert 45 |    173 | GPU
DEBUG 01-14 20:42:25.439496.439496 lmp.py:1625]   Expert 34 |    174 | GPU
DEBUG 01-14 20:42:25.439331.439331 lmp.py:1625]   Expert 18 |    186 | GPU
DEBUG 01-14 20:42:25.439405.439405 lmp.py:1625]   Expert  8 |    187 | GPU
DEBUG 01-14 20:42:25.439240.439240 lmp.py:1625]   Expert 50 |    190 | GPU
DEBUG 01-14 20:42:25.439313.439313 lmp.py:1625]   Expert 57 |    193 | GPU
DEBUG 01-14 20:42:25.439148.439148 lmp.py:1625]   Expert 23 |    196 | GPU
DEBUG 01-14 20:42:25.439699.439699 lmp.py:1625]   Expert 60 |    201 | GPU
DEBUG 01-14 20:42:25.439249.439249 lmp.py:1625]   Expert 31 |    204 | GPU
DEBUG 01-14 20:42:25.439799.439799 lmp.py:1625]   Expert 22 |    209 | GPU
DEBUG 01-14 20:42:25.439111.439111 lmp.py:1625]   Expert 10 |    216 | GPU
DEBUG 01-14 20:42:25.439662.439662 lmp.py:1625]   Expert 37 |    230 | GPU
DEBUG 01-14 20:42:25.439258.439258 lmp.py:1625]   Expert  5 |    234 | GPU
DEBUG 01-14 20:42:25.439093.439093 lmp.py:1625]   Expert 17 |    234 | GPU
DEBUG 01-14 20:42:25.439690.439690 lmp.py:1625]   Expert 11 |    239 | GPU
DEBUG 01-14 20:42:25.439287.439287 lmp.py:1625]   Expert 52 |    242 | GPU
DEBUG 01-14 20:42:25.439883.439883 lmp.py:1625]   Expert 53 |    254 | GPU
DEBUG 01-14 20:42:25.439718.439718 lmp.py:1625]   Expert  1 |    265 | GPU
DEBUG 01-14 20:42:25.439077.439077 lmp.py:1625]   Expert 49 |    268 | GPU
DEBUG 01-14 20:42:25.439627.439627 lmp.py:1625]   Expert 26 |    275 | GPU
DEBUG 01-14 20:42:25.439700.439700 lmp.py:1625]   Expert 14 |    282 | GPU
DEBUG 01-14 20:42:25.439489.439489 lmp.py:1625]   Expert 41 |    285 | GPU
DEBUG 01-14 20:42:25.439801.439801 lmp.py:1625]   Expert 58 |    285 | GPU
DEBUG 01-14 20:42:25.439351.439351 lmp.py:1625]   Expert 40 |    295 | GPU
DEBUG 01-14 20:42:25.439948.439948 lmp.py:1625]   Expert 28 |    303 | GPU
DEBUG 01-14 20:42:25.439022.439022 lmp.py:1625]   Expert 32 |    323 | GPU
DEBUG 01-14 20:42:25.439095.439095 lmp.py:1625]   Expert 12 |    328 | GPU
DEBUG 01-14 20:42:25.439169.439169 lmp.py:1625]   Expert 21 |    344 | GPU
DEBUG 01-14 20:42:25.439719.439719 lmp.py:1625]   Expert 63 |    354 | GPU
DEBUG 01-14 20:42:25.440269.440269 lmp.py:1625]   Expert 27 |    599 | GPU
DEBUG 01-14 20:42:25.440296.440296 lmp.py:1625]   Expert  3 |   1023 | GPU
DEBUG 01-14 20:42:25.440039.440039 lmp.py:1626] 
DEBUG 01-14 20:42:25.440039.440039 lmp.py:1626]   CPU total tokens: 3333 (27.1%)
DEBUG 01-14 20:42:25.440781.440781 lmp.py:1627]   GPU total tokens: 8955 (72.9%)
DEBUG 01-14 20:42:25.440815.440815 cuda_h.py:19] end experts_map_get cost 0.0017254352569580078 seconds
DEBUG 01-14 20:42:25.440380.440380 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-14 20:42:25.440515.440515 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-14 20:42:25.440017.440017 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-14 20:42:25.441029.441029 cuda_h.py:19] end allocate_cuda_memory cost 0.0009217262268066406 seconds
DEBUG 01-14 20:42:25.441031.441031 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-14 20:42:25.441556.441556 sllm_store_c.py:27] get device uuid map
DEBUG 01-14 20:42:25.441869.441869 sllm_store_c.py:29] call client load into gpu
DEBUG 01-14 20:42:25.441194.441194 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 1198d774-808b-4f0f-a054-c1de762c8adb
DEBUG 01-14 20:42:25.441871.441871 client.py:106] call stub.LoadModelAsync
INFO 01-14 20:42:25.442377.442377 client.py:127] Model loaded
DEBUG 01-14 20:42:25.442050.442050 cuda_h.py:10] start restore2model
DEBUG 01-14 20:42:25.443646.443646 cuda_h.py:19] end restore2model cost 0.0010797977447509766 seconds
DEBUG 01-14 20:42:25.443903.443903 cuda_h.py:19] end sllm_worker_task cost 0.013776779174804688 seconds
INFO 01-14 20:42:25.443704.443704 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 1198d774-808b-4f0f-a054-c1de762c8adb
DEBUG 01-14 20:42:25.444509.444509 cuda_h.py:19] end load_into_gpu_async cost 0.002557992935180664 seconds
DEBUG 01-14 20:42:25.444219.444219 cuda_h.py:10] start restore_tensors2
DEBUG 01-14 20:42:25.444524.444524 cuda_h.py:19] end restore_tensors2 cost 0.00037360191345214844 seconds
DEBUG 01-14 20:42:25.444499.444499 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.004248142242431641 seconds
DEBUG 01-14 20:42:25.444315.444315 cuda_h.py:10] start restore2model
DEBUG 01-14 20:42:25.447632.447632 cuda_h.py:19] end restore2model cost 0.0025222301483154297 seconds
DEBUG 01-14 20:42:25.447230.447230 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.00695347785949707 seconds
DEBUG 01-14 20:42:25.447331.447331 cuda_h.py:10] start gpu_sexperts
DEBUG 01-14 20:42:25.447930.447930 cuda_h.py:19] end gpu_sexperts cost 0.0002713203430175781 seconds
DEBUG 01-14 20:42:25.447422.447422 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-14 20:42:25.447363.447363 lmp.py:1683] 
DEBUG 01-14 20:42:25.447363.447363 lmp.py:1683]   Computing 32 experts on CPU...
DEBUG 01-14 20:42:25.447557.447557 cuda_h.py:19] end cpu_experts_submit cost 7.319450378417969e-05 seconds
DEBUG 01-14 20:42:25.447353.447353 cuda_h.py:10] start experts_func_mgpu_group_pad
DEBUG 01-14 20:42:25.464772.464772 mlpmodule.py:1460] group tensors cost 0.016071319580078125 s
DEBUG 01-14 20:42:25.465282.465282 cuda_h.py:10] start move_flat_hidden2cpu
DEBUG 01-14 20:42:25.471739.471739 cuda_h.py:19] end experts_func_mgpu_group_pad cost 0.023302078247070312 seconds
DEBUG 01-14 20:42:25.472110.472110 cuda_h.py:19] end move_flat_hidden2cpu cost 0.006849050521850586 seconds
DEBUG 01-14 20:42:25.474429.474429 cuda_h.py:10] start gpu_group_list
DEBUG 01-14 20:42:25.475879.475879 cuda_h.py:19] end gpu_group_list cost 0.0008289813995361328 seconds
DEBUG 01-14 20:42:25.475909.475909 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-14 20:42:25.475470.475470 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 3.409385681152344e-05 seconds
DEBUG 01-14 20:42:25.475082.475082 cuda_h.py:10] start wait_experts
INFO 01-14 20:42:25.475231.475231 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 1198d774-808b-4f0f-a054-c1de762c8adb
DEBUG 01-14 20:42:25.476696.476696 mlpmodule.py:1533] pad cost 0.0039010047912597656 s
DEBUG 01-14 20:42:25.476005.476005 mlpmodule.py:1539] create cpu tensor cost 3.838539123535156e-05 s
DEBUG 01-14 20:42:25.478884.478884 mlpmodule.py:1544] move to cpu cost 0.0018744468688964844 s
DEBUG 01-14 20:42:25.490403.490403 mlpmodule.py:1558] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-14 20:42:25.490532.490532 mlpmodule.py:1559] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-14 20:42:25.490827.490827 mlpmodule.py:1564] group_w3 first element: 0.00653076171875
WARNING 01-14 20:42:25.491322.491322 mlpmodule.py:1574] start einsum2
INFO 01-14 20:42:25.496785.496785 client.py:127] Model loaded
DEBUG 01-14 20:42:25.497559.497559 cuda_h.py:19] end wait_experts cost 0.02161860466003418 seconds
DEBUG 01-14 20:42:25.497973.497973 cuda_h.py:10] start gpu_experts
DEBUG 01-14 20:42:25.497915.497915 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-14 20:42:25.507120.507120 mlpmodule.py:1584] group einsum cost 0.0293424129486084 s
DEBUG 01-14 20:42:25.508742.508742 mlpmodule.py:1593] cpy2cputensor cost 0.0007405281066894531 s
DEBUG 01-14 20:42:25.508671.508671 cuda_h.py:10] start move_outputs
DEBUG 01-14 20:42:25.510580.510580 cuda_h.py:19] end move_outputs cost 0.0022132396697998047 seconds
DEBUG 01-14 20:42:25.515642.515642 cuda_h.py:19] end wait_cetm_experts cost 0.01824951171875 seconds
DEBUG 01-14 20:42:25.516894.516894 cuda_h.py:10] start gpu_group_einsum_mp_multi_list
DEBUG 01-14 20:42:25.516492.516492 cuda_h.py:10] start gpu_group_tensor
DEBUG 01-14 20:42:25.516396.516396 cuda_h.py:19] end gpu_group_tensor cost 0.0004532337188720703 seconds
DEBUG 01-14 20:42:25.516493.516493 cuda_h.py:10] start gpu_group_einsum
DEBUG 01-14 20:42:25.517136.517136 cuda_h.py:19] end gpu_group_einsum cost 0.000736236572265625 seconds
DEBUG 01-14 20:42:25.517717.517717 cuda_h.py:10] start gpu_final_hidden_states_scatter
DEBUG 01-14 20:42:25.517666.517666 cuda_h.py:10] start all_expert_outputs_slices
DEBUG 01-14 20:42:25.518973.518973 cuda_h.py:19] end all_expert_outputs_slices cost 0.0004329681396484375 seconds
DEBUG 01-14 20:42:25.518921.518921 cuda_h.py:10] start concat_expert_out
DEBUG 01-14 20:42:25.518196.518196 cuda_h.py:19] end concat_expert_out cost 6.127357482910156e-05 seconds
DEBUG 01-14 20:42:25.518675.518675 cuda_h.py:10] start index_scatter
DEBUG 01-14 20:42:25.518593.518593 cuda_h.py:19] end index_scatter cost 8.177757263183594e-05 seconds
DEBUG 01-14 20:42:25.518687.518687 cuda_h.py:19] end gpu_final_hidden_states_scatter cost 0.0008404254913330078 seconds
DEBUG 01-14 20:42:25.518140.518140 cuda_h.py:19] end gpu_experts cost 0.021189451217651367 seconds
DEBUG 01-14 20:42:25.518280.518280 cuda_h.py:10] start all_expert_weight_slices
DEBUG 01-14 20:42:25.519819.519819 cuda_h.py:19] end all_expert_weight_slices cost 0.0010313987731933594 seconds
DEBUG 01-14 20:42:25.519735.519735 cuda_h.py:10] start cpuoutputsdeal
DEBUG 01-14 20:42:25.520102.520102 cuda_h.py:10] start index_scatter
DEBUG 01-14 20:42:25.520476.520476 cuda_h.py:19] end index_scatter cost 5.173683166503906e-05 seconds
DEBUG 01-14 20:42:25.520770.520770 cuda_h.py:19] end cpuoutputsdeal cost 0.0006291866302490234 seconds
DEBUG 01-14 20:42:25.520614.520614 cuda_h.py:19] end layer_moe_generate_mp_l_25 cost 0.08292436599731445 seconds
DEBUG 01-14 20:42:25.521714.521714 cuda_h.py:19] end prefill_layer cost 0.09158873558044434 seconds
DEBUG 01-14 20:42:25.521855.521855 lmp.py:1551] -------------------------------- end prefill layer 24 --------------------------------
DEBUG 01-14 20:42:25.521989.521989 cuda_h.py:10] start prefill_layer
DEBUG 01-14 20:42:25.521884.521884 lmp.py:1494] -------------------------------- start prefill layer 25 --------------------------------
DEBUG 01-14 20:42:25.521494.521494 cuda_h.py:10] start start_load_qkvogn_s_weight_l_26
DEBUG 01-14 20:42:25.521680.521680 cuda_h.py:10] start start_load_qkvogn_s_weight_l_26
DEBUG 01-14 20:42:25.521875.521875 cuda_h.py:19] end start_load_qkvogn_s_weight_l_26 cost 4.506111145019531e-05 seconds
DEBUG 01-14 20:42:25.521724.521724 cuda_h.py:19] end start_load_qkvogn_s_weight_l_26 cost 7.62939453125e-05 seconds
DEBUG 01-14 20:42:25.521658.521658 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-14 20:42:25.521397.521397 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-14 20:42:25.521725.521725 cuda_h.py:10] start sllm_worker_task
DEBUG 01-14 20:42:25.521610.521610 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-14 20:42:25.521454.521454 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-14 20:42:25.522884.522884 cuda_h.py:19] end allocate_cuda_memory cost 0.0007293224334716797 seconds
DEBUG 01-14 20:42:25.522313.522313 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-14 20:42:25.522281.522281 sllm_store_c.py:27] get device uuid map
DEBUG 01-14 20:42:25.522932.522932 sllm_store_c.py:29] call client load into gpu
DEBUG 01-14 20:42:25.522642.522642 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 990b084f-a782-4a69-a81a-a4a3c41d08c8
DEBUG 01-14 20:42:25.523057.523057 client.py:106] call stub.LoadModelAsync
DEBUG 01-14 20:42:25.523844.523844 cuda_h.py:10] start self_attn
INFO 01-14 20:42:25.524638.524638 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 990b084f-a782-4a69-a81a-a4a3c41d08c8
DEBUG 01-14 20:42:25.524627.524627 cuda_h.py:19] end load_into_gpu_async cost 0.0020105838775634766 seconds
DEBUG 01-14 20:42:25.524614.524614 cuda_h.py:10] start restore_tensors2
DEBUG 01-14 20:42:25.525771.525771 cuda_h.py:19] end restore_tensors2 cost 8.7738037109375e-05 seconds
DEBUG 01-14 20:42:25.525196.525196 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.003183126449584961 seconds
INFO 01-14 20:42:25.525085.525085 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 990b084f-a782-4a69-a81a-a4a3c41d08c8
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-14 20:42:25.526553.526553 cuda_h.py:19] end self_attn cost 0.003300905227661133 seconds
DEBUG 01-14 20:42:25.527737.527737 cuda_h.py:19] end iln_self_attn_paln cost 0.005677461624145508 seconds
DEBUG 01-14 20:42:25.527063.527063 cuda_h.py:10] start layer_moe_generate_mp_l_26
DEBUG 01-14 20:42:25.527231.527231 cuda_h.py:10] start gate
DEBUG 01-14 20:42:25.527150.527150 mlpmodule.py:1367]  experts func einsum cost 0.07921004295349121 s
DEBUG 01-14 20:42:25.528661.528661 cuda_h.py:19] end gate cost 0.0009360313415527344 seconds
DEBUG 01-14 20:42:25.528538.528538 cuda_h.py:10] start experts_map_get
DEBUG 01-14 20:42:25.528231.528231 lmp.py:1615] 
DEBUG 01-14 20:42:25.528231.528231 lmp.py:1615] Expert Token Distribution & Device Allocation:
DEBUG 01-14 20:42:25.528756.528756 lmp.py:1616]   Total experts: 64
DEBUG 01-14 20:42:25.528074.528074 lmp.py:1617]   CPU experts: 32 (50%)
DEBUG 01-14 20:42:25.528817.528817 lmp.py:1618]   GPU experts: 32 (50%)
DEBUG 01-14 20:42:25.528414.528414 lmp.py:1619] 
DEBUG 01-14 20:42:25.528414.528414 lmp.py:1619]   Expert ID | Tokens | Device
DEBUG 01-14 20:42:25.528010.528010 lmp.py:1620]   -----------------------------------
DEBUG 01-14 20:42:25.528561.528561 lmp.py:1625]   Expert 13 |     25 | CPU
DEBUG 01-14 20:42:25.528442.528442 lmp.py:1625]   Expert 33 |     39 | CPU
DEBUG 01-14 20:42:25.528085.528085 lmp.py:1625]   Expert 44 |     39 | CPU
DEBUG 01-14 20:42:25.528489.528489 lmp.py:1625]   Expert 16 |     43 | CPU
DEBUG 01-14 20:42:25.528132.528132 lmp.py:1625]   Expert  9 |     45 | CPU
DEBUG 01-14 20:42:25.528537.528537 lmp.py:1625]   Expert 38 |     50 | CPU
DEBUG 01-14 20:42:25.528942.528942 lmp.py:1625]   Expert  2 |     51 | CPU
DEBUG 01-14 20:42:25.528300.528300 lmp.py:1625]   Expert 22 |     54 | CPU
DEBUG 01-14 20:42:25.528181.528181 lmp.py:1625]   Expert 25 |     54 | CPU
DEBUG 01-14 20:42:25.528063.528063 lmp.py:1625]   Expert  5 |     65 | CPU
DEBUG 01-14 20:42:25.528944.528944 lmp.py:1625]   Expert 24 |     65 | CPU
DEBUG 01-14 20:42:25.529587.529587 lmp.py:1625]   Expert 42 |     69 | CPU
DEBUG 01-14 20:42:25.529753.529753 lmp.py:1625]   Expert 23 |     72 | CPU
DEBUG 01-14 20:42:25.529681.529681 lmp.py:1625]   Expert 10 |     89 | CPU
DEBUG 01-14 20:42:25.529370.529370 lmp.py:1625]   Expert 46 |     97 | CPU
DEBUG 01-14 20:42:25.529536.529536 lmp.py:1625]   Expert 55 |    105 | CPU
DEBUG 01-14 20:42:25.529464.529464 lmp.py:1625]   Expert 59 |    105 | CPU
DEBUG 01-14 20:42:25.529153.529153 lmp.py:1625]   Expert 61 |    108 | CPU
DEBUG 01-14 20:42:25.529558.529558 lmp.py:1625]   Expert 21 |    115 | CPU
DEBUG 01-14 20:42:25.529485.529485 lmp.py:1625]   Expert  6 |    129 | CPU
DEBUG 01-14 20:42:25.529367.529367 lmp.py:1625]   Expert 31 |    135 | CPU
DEBUG 01-14 20:42:25.529533.529533 lmp.py:1625]   Expert 45 |    136 | CPU
DEBUG 01-14 20:42:25.529938.529938 lmp.py:1625]   Expert  3 |    138 | CPU
DEBUG 01-14 20:42:25.529342.529342 lmp.py:1625]   Expert 36 |    150 | CPU
DEBUG 01-14 20:42:25.529747.529747 lmp.py:1625]   Expert 48 |    152 | CPU
DEBUG 01-14 20:42:25.529674.529674 lmp.py:1625]   Expert 26 |    155 | CPU
DEBUG 01-14 20:42:25.529364.529364 lmp.py:1625]   Expert 43 |    155 | CPU
DEBUG 01-14 20:42:25.529291.529291 lmp.py:1625]   Expert 41 |    162 | CPU
DEBUG 01-14 20:42:25.529981.529981 lmp.py:1625]   Expert 51 |    164 | CPU
DEBUG 01-14 20:42:25.529432.529432 lmp.py:1625]   Expert  8 |    165 | CPU
DEBUG 01-14 20:42:25.529359.529359 lmp.py:1625]   Expert 18 |    165 | CPU
DEBUG 01-14 20:42:25.529049.529049 lmp.py:1625]   Expert 20 |    168 | CPU
DEBUG 01-14 20:42:25.529645.529645 lmp.py:1625]   Expert 28 |    169 | GPU
DEBUG 01-14 20:42:25.529288.529288 lmp.py:1625]   Expert 56 |    170 | GPU
DEBUG 01-14 20:42:25.529931.529931 lmp.py:1625]   Expert 12 |    177 | GPU
DEBUG 01-14 20:42:25.529336.529336 lmp.py:1625]   Expert  7 |    182 | GPU
DEBUG 01-14 20:42:25.529264.529264 lmp.py:1625]   Expert 27 |    184 | GPU
DEBUG 01-14 20:42:25.529430.529430 lmp.py:1625]   Expert  0 |    195 | GPU
DEBUG 01-14 20:42:25.529357.529357 lmp.py:1625]   Expert 47 |    196 | GPU
DEBUG 01-14 20:42:25.529047.529047 lmp.py:1625]   Expert  1 |    207 | GPU
DEBUG 01-14 20:42:25.529974.529974 lmp.py:1625]   Expert 15 |    214 | GPU
DEBUG 01-14 20:42:25.529902.529902 lmp.py:1625]   Expert 34 |    217 | GPU
DEBUG 01-14 20:42:25.529068.529068 lmp.py:1625]   Expert 40 |    225 | GPU
DEBUG 01-14 20:42:25.529758.529758 lmp.py:1625]   Expert 11 |    228 | GPU
DEBUG 01-14 20:42:25.529447.529447 lmp.py:1625]   Expert 32 |    230 | GPU
DEBUG 01-14 20:42:25.529375.529375 lmp.py:1625]   Expert 49 |    236 | GPU
DEBUG 01-14 20:42:25.529494.529494 lmp.py:1625]   Expert 50 |    238 | GPU
DEBUG 01-14 20:42:25.529899.529899 lmp.py:1625]   Expert 63 |    244 | GPU
DEBUG 01-14 20:42:25.529303.529303 lmp.py:1625]   Expert 53 |    245 | GPU
DEBUG 01-14 20:42:25.529946.529946 lmp.py:1625]   Expert 30 |    254 | GPU
DEBUG 01-14 20:42:25.529828.529828 lmp.py:1625]   Expert  4 |    255 | GPU
DEBUG 01-14 20:42:25.529756.529756 lmp.py:1625]   Expert 29 |    260 | GPU
DEBUG 01-14 20:42:25.529683.529683 lmp.py:1625]   Expert 35 |    268 | GPU
DEBUG 01-14 20:42:25.529373.529373 lmp.py:1625]   Expert 14 |    277 | GPU
DEBUG 01-14 20:42:25.529539.529539 lmp.py:1625]   Expert 37 |    299 | GPU
DEBUG 01-14 20:42:25.529228.529228 lmp.py:1625]   Expert 17 |    358 | GPU
DEBUG 01-14 20:42:25.529156.529156 lmp.py:1625]   Expert 52 |    364 | GPU
DEBUG 01-14 20:42:25.529083.529083 lmp.py:1625]   Expert 54 |    370 | GPU
DEBUG 01-14 20:42:25.529250.529250 lmp.py:1625]   Expert 39 |    380 | GPU
DEBUG 01-14 20:42:25.529177.529177 lmp.py:1625]   Expert 57 |    406 | GPU
DEBUG 01-14 20:42:25.529582.529582 lmp.py:1625]   Expert 60 |    443 | GPU
DEBUG 01-14 20:42:25.529986.529986 lmp.py:1625]   Expert 62 |    458 | GPU
DEBUG 01-14 20:42:25.529868.529868 lmp.py:1625]   Expert 19 |    505 | GPU
DEBUG 01-14 20:42:25.529511.529511 lmp.py:1625]   Expert 58 |    570 | GPU
DEBUG 01-14 20:42:25.529392.529392 lmp.py:1626] 
DEBUG 01-14 20:42:25.529392.529392 lmp.py:1626]   CPU total tokens: 3264 (26.6%)
DEBUG 01-14 20:42:25.529274.529274 lmp.py:1627]   GPU total tokens: 9024 (73.4%)
DEBUG 01-14 20:42:25.529447.529447 cuda_h.py:19] end experts_map_get cost 0.001589059829711914 seconds
DEBUG 01-14 20:42:25.530926.530926 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-14 20:42:25.530398.530398 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-14 20:42:25.530543.530543 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-14 20:42:25.531604.531604 cuda_h.py:19] end allocate_cuda_memory cost 0.0013790130615234375 seconds
DEBUG 01-14 20:42:25.531805.531805 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-14 20:42:25.531184.531184 sllm_store_c.py:27] get device uuid map
DEBUG 01-14 20:42:25.531569.531569 sllm_store_c.py:29] call client load into gpu
DEBUG 01-14 20:42:25.531219.531219 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, b64e937a-15cb-4c38-b59e-9c77f1effef0
DEBUG 01-14 20:42:25.532925.532925 client.py:106] call stub.LoadModelAsync
INFO 01-14 20:42:25.532384.532384 client.py:127] Model loaded
DEBUG 01-14 20:42:25.532095.532095 cuda_h.py:10] start restore2model
DEBUG 01-14 20:42:25.532992.532992 cuda_h.py:19] end restore2model cost 0.0004508495330810547 seconds
DEBUG 01-14 20:42:25.533775.533775 cuda_h.py:19] end sllm_worker_task cost 0.011261701583862305 seconds
INFO 01-14 20:42:25.534265.534265 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, b64e937a-15cb-4c38-b59e-9c77f1effef0
DEBUG 01-14 20:42:25.534539.534539 cuda_h.py:19] end load_into_gpu_async cost 0.0022962093353271484 seconds
DEBUG 01-14 20:42:25.534434.534434 cuda_h.py:10] start restore_tensors2
DEBUG 01-14 20:42:25.534829.534829 cuda_h.py:19] end restore_tensors2 cost 0.0005102157592773438 seconds
DEBUG 01-14 20:42:25.534672.534672 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.004601955413818359 seconds
DEBUG 01-14 20:42:25.534866.534866 cuda_h.py:10] start restore2model
DEBUG 01-14 20:42:25.537566.537566 cuda_h.py:19] end restore2model cost 0.002699613571166992 seconds
DEBUG 01-14 20:42:25.537205.537205 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.007514238357543945 seconds
DEBUG 01-14 20:42:25.537000.537000 cuda_h.py:10] start gpu_sexperts
DEBUG 01-14 20:42:25.537090.537090 cuda_h.py:19] end gpu_sexperts cost 0.00028252601623535156 seconds
DEBUG 01-14 20:42:25.537675.537675 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-14 20:42:25.538544.538544 lmp.py:1683] 
DEBUG 01-14 20:42:25.538544.538544 lmp.py:1683]   Computing 32 experts on CPU...
DEBUG 01-14 20:42:25.538771.538771 cuda_h.py:19] end cpu_experts_submit cost 6.103515625e-05 seconds
DEBUG 01-14 20:42:25.538328.538328 cuda_h.py:10] start experts_func_mgpu_group_pad
DEBUG 01-14 20:42:25.549978.549978 mlpmodule.py:1460] group tensors cost 0.010794878005981445 s
DEBUG 01-14 20:42:25.550681.550681 cuda_h.py:10] start move_flat_hidden2cpu
DEBUG 01-14 20:42:25.556936.556936 cuda_h.py:19] end experts_func_mgpu_group_pad cost 0.01849675178527832 seconds
DEBUG 01-14 20:42:25.557466.557466 cuda_h.py:19] end move_flat_hidden2cpu cost 0.006600141525268555 seconds
DEBUG 01-14 20:42:25.560044.560044 cuda_h.py:10] start gpu_group_list
DEBUG 01-14 20:42:25.561542.561542 cuda_h.py:19] end gpu_group_list cost 0.0012221336364746094 seconds
DEBUG 01-14 20:42:25.562541.562541 mlpmodule.py:1533] pad cost 0.004832744598388672 s
DEBUG 01-14 20:42:25.562341.562341 mlpmodule.py:1539] create cpu tensor cost 4.267692565917969e-05 s
DEBUG 01-14 20:42:25.562933.562933 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-14 20:42:25.562252.562252 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 5.078315734863281e-05 seconds
DEBUG 01-14 20:42:25.562043.562043 cuda_h.py:10] start wait_experts
INFO 01-14 20:42:25.562874.562874 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, b64e937a-15cb-4c38-b59e-9c77f1effef0
DEBUG 01-14 20:42:25.564536.564536 mlpmodule.py:1544] move to cpu cost 0.0020287036895751953 s
DEBUG 01-14 20:42:25.574738.574738 mlpmodule.py:1558] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-14 20:42:25.574472.574472 mlpmodule.py:1559] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-14 20:42:25.574064.574064 mlpmodule.py:1564] group_w3 first element: -0.02734375
WARNING 01-14 20:42:25.574988.574988 mlpmodule.py:1574] start einsum2
INFO 01-14 20:42:25.589720.589720 client.py:127] Model loaded
DEBUG 01-14 20:42:25.589259.589259 cuda_h.py:19] end wait_experts cost 0.026517152786254883 seconds
DEBUG 01-14 20:42:25.589136.589136 cuda_h.py:10] start gpu_experts
DEBUG 01-14 20:42:25.589768.589768 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-14 20:42:25.591092.591092 mlpmodule.py:1584] group einsum cost 0.027364730834960938 s
DEBUG 01-14 20:42:25.592626.592626 mlpmodule.py:1593] cpy2cputensor cost 0.0007417201995849609 s
DEBUG 01-14 20:42:25.592588.592588 cuda_h.py:10] start move_outputs
DEBUG 01-14 20:42:25.594919.594919 cuda_h.py:19] end move_outputs cost 0.001970052719116211 seconds
DEBUG 01-14 20:42:25.598586.598586 cuda_h.py:19] end wait_cetm_experts cost 0.009113311767578125 seconds
DEBUG 01-14 20:42:25.598592.598592 cuda_h.py:10] start gpu_group_einsum_mp_multi_list
DEBUG 01-14 20:42:25.599561.599561 cuda_h.py:10] start gpu_group_tensor
DEBUG 01-14 20:42:25.599670.599670 cuda_h.py:19] end gpu_group_tensor cost 0.0002551078796386719 seconds
DEBUG 01-14 20:42:25.599053.599053 cuda_h.py:10] start gpu_group_einsum
DEBUG 01-14 20:42:25.600471.600471 cuda_h.py:19] end gpu_group_einsum cost 0.0007374286651611328 seconds
DEBUG 01-14 20:42:25.600285.600285 cuda_h.py:10] start gpu_final_hidden_states_scatter
DEBUG 01-14 20:42:25.600625.600625 cuda_h.py:10] start all_expert_outputs_slices
DEBUG 01-14 20:42:25.600381.600381 cuda_h.py:19] end all_expert_outputs_slices cost 0.0003781318664550781 seconds
DEBUG 01-14 20:42:25.601375.601375 cuda_h.py:10] start concat_expert_out
DEBUG 01-14 20:42:25.601080.601080 cuda_h.py:19] end concat_expert_out cost 6.341934204101562e-05 seconds
DEBUG 01-14 20:42:25.601699.601699 cuda_h.py:10] start index_scatter
DEBUG 01-14 20:42:25.601093.601093 cuda_h.py:19] end index_scatter cost 8.082389831542969e-05 seconds
DEBUG 01-14 20:42:25.601525.601525 cuda_h.py:19] end gpu_final_hidden_states_scatter cost 0.0007882118225097656 seconds
DEBUG 01-14 20:42:25.601833.601833 cuda_h.py:19] end gpu_experts cost 0.011838197708129883 seconds
DEBUG 01-14 20:42:25.601464.601464 cuda_h.py:10] start all_expert_weight_slices
DEBUG 01-14 20:42:25.602717.602717 cuda_h.py:19] end all_expert_weight_slices cost 0.0009953975677490234 seconds
DEBUG 01-14 20:42:25.602401.602401 cuda_h.py:10] start cpuoutputsdeal
DEBUG 01-14 20:42:25.603165.603165 cuda_h.py:10] start index_scatter
DEBUG 01-14 20:42:25.603453.603453 cuda_h.py:19] end index_scatter cost 5.4836273193359375e-05 seconds
DEBUG 01-14 20:42:25.603554.603554 cuda_h.py:19] end cpuoutputsdeal cost 0.0005741119384765625 seconds
DEBUG 01-14 20:42:25.603940.603940 cuda_h.py:19] end layer_moe_generate_mp_l_26 cost 0.07599878311157227 seconds
DEBUG 01-14 20:42:25.603166.603166 cuda_h.py:19] end prefill_layer cost 0.08240222930908203 seconds
DEBUG 01-14 20:42:25.603055.603055 lmp.py:1551] -------------------------------- end prefill layer 25 --------------------------------
DEBUG 01-14 20:42:25.603474.603474 cuda_h.py:10] start prefill_layer
DEBUG 01-14 20:42:25.603369.603369 lmp.py:1494] -------------------------------- start prefill layer 26 --------------------------------
DEBUG 01-14 20:42:25.603979.603979 cuda_h.py:10] start start_load_qkvogn_s_weight_l_27
DEBUG 01-14 20:42:25.603735.603735 cuda_h.py:10] start start_load_qkvogn_s_weight_l_27
DEBUG 01-14 20:42:25.603188.603188 cuda_h.py:19] end start_load_qkvogn_s_weight_l_27 cost 5.936622619628906e-05 seconds
DEBUG 01-14 20:42:25.603772.603772 cuda_h.py:10] start sllm_worker_task
DEBUG 01-14 20:42:25.604397.604397 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-14 20:42:25.604273.604273 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-14 20:42:25.604151.604151 cuda_h.py:19] end start_load_qkvogn_s_weight_l_27 cost 0.00014066696166992188 seconds
DEBUG 01-14 20:42:25.605134.605134 cuda_h.py:19] end allocate_cuda_memory cost 0.0009493827819824219 seconds
DEBUG 01-14 20:42:25.605065.605065 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-14 20:42:25.605619.605619 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-14 20:42:25.605511.605511 sllm_store_c.py:27] get device uuid map
DEBUG 01-14 20:42:25.605984.605984 sllm_store_c.py:29] call client load into gpu
DEBUG 01-14 20:42:25.605177.605177 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 81c45a51-eae4-4bf7-ac83-d2dcc4c63e74
DEBUG 01-14 20:42:25.605035.605035 client.py:106] call stub.LoadModelAsync
DEBUG 01-14 20:42:25.605787.605787 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-14 20:42:25.606785.606785 cuda_h.py:10] start self_attn
INFO 01-14 20:42:25.607687.607687 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 81c45a51-eae4-4bf7-ac83-d2dcc4c63e74
DEBUG 01-14 20:42:25.607110.607110 cuda_h.py:19] end load_into_gpu_async cost 0.0020437240600585938 seconds
DEBUG 01-14 20:42:25.607456.607456 cuda_h.py:10] start restore_tensors2
DEBUG 01-14 20:42:25.607375.607375 cuda_h.py:19] end restore_tensors2 cost 0.00012111663818359375 seconds
DEBUG 01-14 20:42:25.607707.607707 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0036773681640625 seconds
INFO 01-14 20:42:25.607313.607313 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 81c45a51-eae4-4bf7-ac83-d2dcc4c63e74
DEBUG 01-14 20:42:25.608069.608069 mlpmodule.py:1367]  experts func einsum cost 0.07013273239135742 s
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-14 20:42:25.610429.610429 cuda_h.py:19] end self_attn cost 0.004340648651123047 seconds
DEBUG 01-14 20:42:25.611083.611083 cuda_h.py:19] end iln_self_attn_paln cost 0.005670309066772461 seconds
DEBUG 01-14 20:42:25.611125.611125 cuda_h.py:10] start layer_moe_generate_mp_l_27
DEBUG 01-14 20:42:25.611173.611173 cuda_h.py:10] start gate
DEBUG 01-14 20:42:25.611494.611494 cuda_h.py:19] end gate cost 0.0006580352783203125 seconds
DEBUG 01-14 20:42:25.611853.611853 cuda_h.py:10] start experts_map_get
DEBUG 01-14 20:42:25.612507.612507 lmp.py:1615] 
DEBUG 01-14 20:42:25.612507.612507 lmp.py:1615] Expert Token Distribution & Device Allocation:
DEBUG 01-14 20:42:25.612793.612793 lmp.py:1616]   Total experts: 64
DEBUG 01-14 20:42:25.612781.612781 lmp.py:1617]   CPU experts: 32 (50%)
DEBUG 01-14 20:42:25.612954.612954 lmp.py:1618]   GPU experts: 32 (50%)
DEBUG 01-14 20:42:25.612981.612981 lmp.py:1619] 
DEBUG 01-14 20:42:25.612981.612981 lmp.py:1619]   Expert ID | Tokens | Device
DEBUG 01-14 20:42:25.612737.612737 lmp.py:1620]   -----------------------------------
DEBUG 01-14 20:42:25.612334.612334 lmp.py:1625]   Expert 20 |     15 | CPU
DEBUG 01-14 20:42:25.612884.612884 lmp.py:1625]   Expert 61 |     21 | CPU
DEBUG 01-14 20:42:25.612719.612719 lmp.py:1625]   Expert 51 |     34 | CPU
DEBUG 01-14 20:42:25.612746.612746 lmp.py:1625]   Expert 62 |     40 | CPU
DEBUG 01-14 20:42:25.612773.612773 lmp.py:1625]   Expert 11 |     46 | CPU
DEBUG 01-14 20:42:25.612085.612085 lmp.py:1625]   Expert  7 |     50 | CPU
DEBUG 01-14 20:42:25.612874.612874 lmp.py:1625]   Expert 30 |     53 | CPU
DEBUG 01-14 20:42:25.612663.612663 lmp.py:1625]   Expert  3 |     58 | CPU
DEBUG 01-14 20:42:25.612259.612259 lmp.py:1625]   Expert 29 |     60 | CPU
DEBUG 01-14 20:42:25.612856.612856 lmp.py:1625]   Expert  9 |     63 | CPU
DEBUG 01-14 20:42:25.612691.612691 lmp.py:1625]   Expert  6 |     64 | CPU
DEBUG 01-14 20:42:25.612526.612526 lmp.py:1625]   Expert 17 |     67 | CPU
DEBUG 01-14 20:42:25.612361.612361 lmp.py:1625]   Expert  8 |     70 | CPU
DEBUG 01-14 20:42:25.612958.612958 lmp.py:1625]   Expert 59 |     74 | CPU
DEBUG 01-14 20:42:25.612508.612508 lmp.py:1625]   Expert 63 |     80 | CPU
DEBUG 01-14 20:42:25.612820.612820 lmp.py:1625]   Expert 48 |     95 | CPU
DEBUG 01-14 20:42:25.612894.612894 lmp.py:1625]   Expert 38 |     97 | CPU
DEBUG 01-14 20:42:25.612205.612205 lmp.py:1625]   Expert 55 |    101 | CPU
DEBUG 01-14 20:42:25.612517.612517 lmp.py:1625]   Expert 24 |    109 | CPU
DEBUG 01-14 20:42:25.612114.612114 lmp.py:1625]   Expert 49 |    112 | CPU
DEBUG 01-14 20:42:25.612188.612188 lmp.py:1625]   Expert 19 |    113 | CPU
DEBUG 01-14 20:42:25.612784.612784 lmp.py:1625]   Expert 36 |    113 | CPU
DEBUG 01-14 20:42:25.612858.612858 lmp.py:1625]   Expert 39 |    114 | CPU
DEBUG 01-14 20:42:25.612931.612931 lmp.py:1625]   Expert 50 |    117 | CPU
DEBUG 01-14 20:42:25.612528.612528 lmp.py:1625]   Expert 42 |    126 | CPU
DEBUG 01-14 20:42:25.612317.612317 lmp.py:1625]   Expert  4 |    129 | CPU
DEBUG 01-14 20:42:25.612628.612628 lmp.py:1625]   Expert 41 |    133 | CPU
DEBUG 01-14 20:42:25.612702.612702 lmp.py:1625]   Expert 22 |    136 | CPU
DEBUG 01-14 20:42:25.612014.612014 lmp.py:1625]   Expert 34 |    136 | CPU
DEBUG 01-14 20:42:25.612326.612326 lmp.py:1625]   Expert 37 |    155 | CPU
DEBUG 01-14 20:42:25.613161.613161 lmp.py:1625]   Expert 15 |    159 | CPU
DEBUG 01-14 20:42:25.613519.613519 lmp.py:1625]   Expert 60 |    161 | CPU
DEBUG 01-14 20:42:25.613116.613116 lmp.py:1625]   Expert 56 |    162 | GPU
DEBUG 01-14 20:42:25.613951.613951 lmp.py:1625]   Expert 23 |    166 | GPU
DEBUG 01-14 20:42:25.613786.613786 lmp.py:1625]   Expert 21 |    168 | GPU
DEBUG 01-14 20:42:25.613051.613051 lmp.py:1625]   Expert 44 |    177 | GPU
DEBUG 01-14 20:42:25.613079.613079 lmp.py:1625]   Expert 47 |    180 | GPU
DEBUG 01-14 20:42:25.613152.613152 lmp.py:1625]   Expert 16 |    183 | GPU
DEBUG 01-14 20:42:25.613702.613702 lmp.py:1625]   Expert  1 |    184 | GPU
DEBUG 01-14 20:42:25.613014.613014 lmp.py:1625]   Expert 33 |    185 | GPU
DEBUG 01-14 20:42:25.613803.613803 lmp.py:1625]   Expert 43 |    187 | GPU
DEBUG 01-14 20:42:25.613876.613876 lmp.py:1625]   Expert 13 |    204 | GPU
DEBUG 01-14 20:42:25.613235.613235 lmp.py:1625]   Expert 53 |    205 | GPU
DEBUG 01-14 20:42:25.613070.613070 lmp.py:1625]   Expert 32 |    226 | GPU
DEBUG 01-14 20:42:25.613905.613905 lmp.py:1625]   Expert 28 |    228 | GPU
DEBUG 01-14 20:42:25.613501.613501 lmp.py:1625]   Expert 12 |    237 | GPU
DEBUG 01-14 20:42:25.613575.613575 lmp.py:1625]   Expert  2 |    245 | GPU
DEBUG 01-14 20:42:25.613172.613172 lmp.py:1625]   Expert 31 |    247 | GPU
DEBUG 01-14 20:42:25.613722.613722 lmp.py:1625]   Expert 25 |    251 | GPU
DEBUG 01-14 20:42:25.613795.613795 lmp.py:1625]   Expert  0 |    260 | GPU
DEBUG 01-14 20:42:25.613869.613869 lmp.py:1625]   Expert 26 |    261 | GPU
DEBUG 01-14 20:42:25.613227.613227 lmp.py:1625]   Expert 18 |    266 | GPU
DEBUG 01-14 20:42:25.613585.613585 lmp.py:1625]   Expert 54 |    275 | GPU
DEBUG 01-14 20:42:25.613659.613659 lmp.py:1625]   Expert 57 |    275 | GPU
DEBUG 01-14 20:42:25.613971.613971 lmp.py:1625]   Expert 10 |    276 | GPU
DEBUG 01-14 20:42:25.613044.613044 lmp.py:1625]   Expert 58 |    280 | GPU
DEBUG 01-14 20:42:25.613641.613641 lmp.py:1625]   Expert 40 |    329 | GPU
DEBUG 01-14 20:42:25.613238.613238 lmp.py:1625]   Expert 45 |    378 | GPU
DEBUG 01-14 20:42:25.613549.613549 lmp.py:1625]   Expert 35 |    438 | GPU
DEBUG 01-14 20:42:25.613623.613623 lmp.py:1625]   Expert  5 |    478 | GPU
DEBUG 01-14 20:42:25.613173.613173 lmp.py:1625]   Expert 46 |    493 | GPU
DEBUG 01-14 20:42:25.613532.613532 lmp.py:1625]   Expert 27 |    514 | GPU
DEBUG 01-14 20:42:25.613651.613651 lmp.py:1625]   Expert 52 |    569 | GPU
DEBUG 01-14 20:42:25.613771.613771 lmp.py:1625]   Expert 14 |    860 | GPU
DEBUG 01-14 20:42:25.613375.613375 lmp.py:1626] 
DEBUG 01-14 20:42:25.613375.613375 lmp.py:1626]   CPU total tokens: 2901 (23.6%)
DEBUG 01-14 20:42:25.613594.613594 lmp.py:1627]   GPU total tokens: 9387 (76.4%)
DEBUG 01-14 20:42:25.613913.613913 cuda_h.py:19] end experts_map_get cost 0.0017349720001220703 seconds
DEBUG 01-14 20:42:25.613815.613815 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-14 20:42:25.613189.613189 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-14 20:42:25.613161.613161 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-14 20:42:25.614477.614477 cuda_h.py:19] end allocate_cuda_memory cost 0.0003008842468261719 seconds
DEBUG 01-14 20:42:25.614181.614181 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-14 20:42:25.614175.614175 sllm_store_c.py:27] get device uuid map
DEBUG 01-14 20:42:25.614322.614322 sllm_store_c.py:29] call client load into gpu
DEBUG 01-14 20:42:25.614879.614879 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 1597df84-4460-48c5-9031-0a046d7938da
DEBUG 01-14 20:42:25.614896.614896 client.py:106] call stub.LoadModelAsync
INFO 01-14 20:42:25.614386.614386 client.py:127] Model loaded
DEBUG 01-14 20:42:25.615157.615157 cuda_h.py:10] start restore2model
DEBUG 01-14 20:42:25.615111.615111 cuda_h.py:19] end restore2model cost 0.0005447864532470703 seconds
DEBUG 01-14 20:42:25.615240.615240 cuda_h.py:19] end sllm_worker_task cost 0.011716365814208984 seconds
INFO 01-14 20:42:25.616302.616302 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 1597df84-4460-48c5-9031-0a046d7938da
DEBUG 01-14 20:42:25.616298.616298 cuda_h.py:19] end load_into_gpu_async cost 0.0020911693572998047 seconds
DEBUG 01-14 20:42:25.616670.616670 cuda_h.py:10] start restore_tensors2
DEBUG 01-14 20:42:25.616796.616796 cuda_h.py:19] end restore_tensors2 cost 0.0003821849822998047 seconds
DEBUG 01-14 20:42:25.617056.617056 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0031440258026123047 seconds
DEBUG 01-14 20:42:25.617872.617872 cuda_h.py:10] start restore2model
DEBUG 01-14 20:42:25.619141.619141 cuda_h.py:19] end restore2model cost 0.002657175064086914 seconds
DEBUG 01-14 20:42:25.619931.619931 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.005989789962768555 seconds
DEBUG 01-14 20:42:25.619965.619965 cuda_h.py:10] start gpu_sexperts
DEBUG 01-14 20:42:25.620161.620161 cuda_h.py:19] end gpu_sexperts cost 0.00028967857360839844 seconds
DEBUG 01-14 20:42:25.620268.620268 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-14 20:42:25.620687.620687 lmp.py:1683] 
DEBUG 01-14 20:42:25.620687.620687 lmp.py:1683]   Computing 32 experts on CPU...
DEBUG 01-14 20:42:25.620000.620000 cuda_h.py:19] end cpu_experts_submit cost 5.555152893066406e-05 seconds
DEBUG 01-14 20:42:25.620511.620511 cuda_h.py:10] start experts_func_mgpu_group_pad
DEBUG 01-14 20:42:25.631047.631047 mlpmodule.py:1460] group tensors cost 0.010286569595336914 s
DEBUG 01-14 20:42:25.631392.631392 cuda_h.py:10] start move_flat_hidden2cpu
DEBUG 01-14 20:42:25.637422.637422 cuda_h.py:19] end experts_func_mgpu_group_pad cost 0.017449617385864258 seconds
DEBUG 01-14 20:42:25.638412.638412 cuda_h.py:19] end move_flat_hidden2cpu cost 0.006446361541748047 seconds
DEBUG 01-14 20:42:25.641985.641985 mlpmodule.py:1533] pad cost 0.0033063888549804688 s
DEBUG 01-14 20:42:25.641896.641896 mlpmodule.py:1539] create cpu tensor cost 4.410743713378906e-05 s
DEBUG 01-14 20:42:25.641833.641833 cuda_h.py:10] start gpu_group_list
DEBUG 01-14 20:42:25.643729.643729 cuda_h.py:19] end gpu_group_list cost 0.0012288093566894531 seconds
DEBUG 01-14 20:42:25.643284.643284 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-14 20:42:25.643134.643134 mlpmodule.py:1544] move to cpu cost 0.001920461654663086 s
DEBUG 01-14 20:42:25.643554.643554 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.8371810913085938e-05 seconds
DEBUG 01-14 20:42:25.644788.644788 cuda_h.py:10] start wait_experts
INFO 01-14 20:42:25.644320.644320 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 1597df84-4460-48c5-9031-0a046d7938da
DEBUG 01-14 20:42:25.652663.652663 mlpmodule.py:1558] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-14 20:42:25.653695.653695 mlpmodule.py:1559] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-14 20:42:25.653956.653956 mlpmodule.py:1564] group_w3 first element: -0.0024261474609375
WARNING 01-14 20:42:25.653735.653735 mlpmodule.py:1574] start einsum2
DEBUG 01-14 20:42:25.669812.669812 mlpmodule.py:1584] group einsum cost 0.025536537170410156 s
DEBUG 01-14 20:42:25.670272.670272 mlpmodule.py:1593] cpy2cputensor cost 0.0007059574127197266 s
DEBUG 01-14 20:42:25.670493.670493 cuda_h.py:10] start move_outputs
DEBUG 01-14 20:42:25.672273.672273 cuda_h.py:19] end move_outputs cost 0.0019099712371826172 seconds
INFO 01-14 20:42:25.673934.673934 client.py:127] Model loaded
DEBUG 01-14 20:42:25.673861.673861 cuda_h.py:19] end wait_experts cost 0.029390573501586914 seconds
DEBUG 01-14 20:42:25.673491.673491 cuda_h.py:10] start gpu_experts
DEBUG 01-14 20:42:25.673076.673076 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-14 20:42:25.676047.676047 cuda_h.py:19] end wait_cetm_experts cost 0.0028526782989501953 seconds
DEBUG 01-14 20:42:25.676692.676692 cuda_h.py:10] start gpu_group_einsum_mp_multi_list
DEBUG 01-14 20:42:25.676879.676879 cuda_h.py:10] start gpu_group_tensor
DEBUG 01-14 20:42:25.677259.677259 cuda_h.py:19] end gpu_group_tensor cost 0.0002484321594238281 seconds
DEBUG 01-14 20:42:25.677137.677137 cuda_h.py:10] start gpu_group_einsum
DEBUG 01-14 20:42:25.677235.677235 cuda_h.py:19] end gpu_group_einsum cost 0.0006861686706542969 seconds
DEBUG 01-14 20:42:25.678577.678577 cuda_h.py:10] start gpu_final_hidden_states_scatter
DEBUG 01-14 20:42:25.678858.678858 cuda_h.py:10] start all_expert_outputs_slices
DEBUG 01-14 20:42:25.678342.678342 cuda_h.py:19] end all_expert_outputs_slices cost 0.0003871917724609375 seconds
DEBUG 01-14 20:42:25.678145.678145 cuda_h.py:10] start concat_expert_out
DEBUG 01-14 20:42:25.678135.678135 cuda_h.py:19] end concat_expert_out cost 6.246566772460938e-05 seconds
DEBUG 01-14 20:42:25.678461.678461 cuda_h.py:10] start index_scatter
DEBUG 01-14 20:42:25.678465.678465 cuda_h.py:19] end index_scatter cost 7.510185241699219e-05 seconds
DEBUG 01-14 20:42:25.678327.678327 cuda_h.py:19] end gpu_final_hidden_states_scatter cost 0.0007846355438232422 seconds
DEBUG 01-14 20:42:25.678204.678204 cuda_h.py:19] end gpu_experts cost 0.005234718322753906 seconds
DEBUG 01-14 20:42:25.679907.679907 cuda_h.py:10] start all_expert_weight_slices
DEBUG 01-14 20:42:25.680735.680735 cuda_h.py:19] end all_expert_weight_slices cost 0.0009655952453613281 seconds
DEBUG 01-14 20:42:25.680174.680174 cuda_h.py:10] start cpuoutputsdeal
DEBUG 01-14 20:42:25.680244.680244 cuda_h.py:10] start index_scatter
DEBUG 01-14 20:42:25.680294.680294 cuda_h.py:19] end index_scatter cost 5.364418029785156e-05 seconds
DEBUG 01-14 20:42:25.680394.680394 cuda_h.py:19] end cpuoutputsdeal cost 0.0006260871887207031 seconds
DEBUG 01-14 20:42:25.680542.680542 cuda_h.py:19] end layer_moe_generate_mp_l_27 cost 0.06958818435668945 seconds
DEBUG 01-14 20:42:25.681430.681430 cuda_h.py:19] end prefill_layer cost 0.07739400863647461 seconds
DEBUG 01-14 20:42:25.681929.681929 lmp.py:1551] -------------------------------- end prefill layer 26 --------------------------------
DEBUG 01-14 20:42:25.681963.681963 cuda_h.py:10] start prefill_layer
DEBUG 01-14 20:42:25.681189.681189 lmp.py:1494] -------------------------------- start prefill layer 27 --------------------------------
DEBUG 01-14 20:42:25.681892.681892 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-14 20:42:25.681345.681345 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-14 20:42:25.681819.681819 cuda_h.py:10] start self_attn
DEBUG 01-14 20:42:25.684294.684294 mlpmodule.py:1367]  experts func einsum cost 0.06396889686584473 s
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-14 20:42:25.686758.686758 cuda_h.py:19] end self_attn cost 0.004454374313354492 seconds
DEBUG 01-14 20:42:25.686017.686017 cuda_h.py:19] end iln_self_attn_paln cost 0.0052890777587890625 seconds
DEBUG 01-14 20:42:25.686774.686774 cuda_h.py:10] start layer_moe_generate_mp_l_28
DEBUG 01-14 20:42:25.686967.686967 cuda_h.py:10] start gate
DEBUG 01-14 20:42:25.687610.687610 cuda_h.py:19] end gate cost 0.0005793571472167969 seconds
DEBUG 01-14 20:42:25.687732.687732 cuda_h.py:10] start experts_map_get
DEBUG 01-14 20:42:25.687490.687490 lmp.py:1615] 
DEBUG 01-14 20:42:25.687490.687490 lmp.py:1615] Expert Token Distribution & Device Allocation:
DEBUG 01-14 20:42:25.687816.687816 lmp.py:1616]   Total experts: 64
DEBUG 01-14 20:42:25.687797.687797 lmp.py:1617]   CPU experts: 32 (50%)
DEBUG 01-14 20:42:25.687678.687678 lmp.py:1618]   GPU experts: 32 (50%)
DEBUG 01-14 20:42:25.687175.687175 lmp.py:1619] 
DEBUG 01-14 20:42:25.687175.687175 lmp.py:1619]   Expert ID | Tokens | Device
DEBUG 01-14 20:42:25.687149.687149 lmp.py:1620]   -----------------------------------
DEBUG 01-14 20:42:25.687554.687554 lmp.py:1625]   Expert 47 |     62 | CPU
DEBUG 01-14 20:42:25.687502.687502 lmp.py:1625]   Expert 48 |     65 | CPU
DEBUG 01-14 20:42:25.687476.687476 lmp.py:1625]   Expert 18 |     72 | CPU
DEBUG 01-14 20:42:25.687688.687688 lmp.py:1625]   Expert 54 |     78 | CPU
DEBUG 01-14 20:42:25.687663.687663 lmp.py:1625]   Expert 44 |     85 | CPU
DEBUG 01-14 20:42:25.687160.687160 lmp.py:1625]   Expert 45 |     86 | CPU
DEBUG 01-14 20:42:25.687372.687372 lmp.py:1625]   Expert 23 |     90 | CPU
DEBUG 01-14 20:42:25.687346.687346 lmp.py:1625]   Expert 20 |     93 | CPU
DEBUG 01-14 20:42:25.687658.687658 lmp.py:1625]   Expert 11 |    103 | CPU
DEBUG 01-14 20:42:25.688871.688871 lmp.py:1625]   Expert 61 |    105 | CPU
DEBUG 01-14 20:42:25.688057.688057 lmp.py:1625]   Expert 31 |    107 | CPU
DEBUG 01-14 20:42:25.688746.688746 lmp.py:1625]   Expert 36 |    114 | CPU
DEBUG 01-14 20:42:25.688436.688436 lmp.py:1625]   Expert 24 |    116 | CPU
DEBUG 01-14 20:42:25.688887.688887 lmp.py:1625]   Expert  5 |    120 | CPU
DEBUG 01-14 20:42:25.688576.688576 lmp.py:1625]   Expert 10 |    126 | CPU
DEBUG 01-14 20:42:25.688027.688027 lmp.py:1625]   Expert 17 |    128 | CPU
DEBUG 01-14 20:42:25.688008.688008 lmp.py:1625]   Expert 33 |    128 | CPU
DEBUG 01-14 20:42:25.688935.688935 lmp.py:1625]   Expert 42 |    128 | CPU
DEBUG 01-14 20:42:25.688625.688625 lmp.py:1625]   Expert 49 |    131 | CPU
DEBUG 01-14 20:42:25.688983.688983 lmp.py:1625]   Expert  6 |    134 | CPU
DEBUG 01-14 20:42:25.688626.688626 lmp.py:1625]   Expert 43 |    137 | CPU
DEBUG 01-14 20:42:25.688077.688077 lmp.py:1625]   Expert 56 |    138 | CPU
DEBUG 01-14 20:42:25.688289.688289 lmp.py:1625]   Expert 57 |    151 | CPU
DEBUG 01-14 20:42:25.688740.688740 lmp.py:1625]   Expert 12 |    155 | CPU
DEBUG 01-14 20:42:25.688191.688191 lmp.py:1625]   Expert 51 |    156 | CPU
DEBUG 01-14 20:42:25.688880.688880 lmp.py:1625]   Expert  0 |    159 | CPU
DEBUG 01-14 20:42:25.688616.688616 lmp.py:1625]   Expert 26 |    160 | CPU
DEBUG 01-14 20:42:25.688067.688067 lmp.py:1625]   Expert 38 |    162 | CPU
DEBUG 01-14 20:42:25.688518.688518 lmp.py:1625]   Expert 46 |    164 | CPU
DEBUG 01-14 20:42:25.688492.688492 lmp.py:1625]   Expert 59 |    164 | CPU
DEBUG 01-14 20:42:25.688704.688704 lmp.py:1625]   Expert 35 |    170 | CPU
DEBUG 01-14 20:42:25.688645.688645 lmp.py:1625]   Expert 50 |    172 | CPU
DEBUG 01-14 20:42:25.688573.688573 lmp.py:1625]   Expert 55 |    173 | GPU
DEBUG 01-14 20:42:25.688547.688547 lmp.py:1625]   Expert 13 |    174 | GPU
DEBUG 01-14 20:42:25.688521.688521 lmp.py:1625]   Expert 16 |    177 | GPU
DEBUG 01-14 20:42:25.688495.688495 lmp.py:1625]   Expert 40 |    179 | GPU
DEBUG 01-14 20:42:25.688946.688946 lmp.py:1625]   Expert 58 |    179 | GPU
DEBUG 01-14 20:42:25.688397.688397 lmp.py:1625]   Expert  7 |    183 | GPU
DEBUG 01-14 20:42:25.688848.688848 lmp.py:1625]   Expert 30 |    192 | GPU
DEBUG 01-14 20:42:25.688822.688822 lmp.py:1625]   Expert 15 |    197 | GPU
DEBUG 01-14 20:42:25.688227.688227 lmp.py:1625]   Expert  1 |    204 | GPU
DEBUG 01-14 20:42:25.688777.688777 lmp.py:1625]   Expert 14 |    208 | GPU
DEBUG 01-14 20:42:25.688181.688181 lmp.py:1625]   Expert 32 |    216 | GPU
DEBUG 01-14 20:42:25.688255.688255 lmp.py:1625]   Expert  4 |    217 | GPU
DEBUG 01-14 20:42:25.688944.688944 lmp.py:1625]   Expert  3 |    218 | GPU
DEBUG 01-14 20:42:25.688395.688395 lmp.py:1625]   Expert 25 |    227 | GPU
DEBUG 01-14 20:42:25.688608.688608 lmp.py:1625]   Expert 28 |    233 | GPU
DEBUG 01-14 20:42:25.688582.688582 lmp.py:1625]   Expert 34 |    239 | GPU
DEBUG 01-14 20:42:25.688317.688317 lmp.py:1625]   Expert 39 |    245 | GPU
DEBUG 01-14 20:42:25.688053.688053 lmp.py:1625]   Expert 22 |    256 | GPU
DEBUG 01-14 20:42:25.688265.688265 lmp.py:1625]   Expert 60 |    260 | GPU
DEBUG 01-14 20:42:25.688478.688478 lmp.py:1625]   Expert 52 |    262 | GPU
DEBUG 01-14 20:42:25.688213.688213 lmp.py:1625]   Expert  2 |    269 | GPU
DEBUG 01-14 20:42:25.688664.688664 lmp.py:1625]   Expert 41 |    281 | GPU
DEBUG 01-14 20:42:25.688400.688400 lmp.py:1625]   Expert 21 |    293 | GPU
DEBUG 01-14 20:42:25.688566.688566 lmp.py:1625]   Expert 27 |    295 | GPU
DEBUG 01-14 20:42:25.688732.688732 lmp.py:1625]   Expert 63 |    300 | GPU
DEBUG 01-14 20:42:25.688660.688660 lmp.py:1625]   Expert 62 |    304 | GPU
DEBUG 01-14 20:42:25.688111.688111 lmp.py:1625]   Expert 29 |    306 | GPU
DEBUG 01-14 20:42:25.688562.688562 lmp.py:1625]   Expert 37 |    332 | GPU
DEBUG 01-14 20:42:25.688297.688297 lmp.py:1625]   Expert  8 |    335 | GPU
DEBUG 01-14 20:42:25.688271.688271 lmp.py:1625]   Expert 53 |    348 | GPU
DEBUG 01-14 20:42:25.688245.688245 lmp.py:1625]   Expert 19 |    461 | GPU
DEBUG 01-14 20:42:25.688458.688458 lmp.py:1625]   Expert  9 |    566 | GPU
DEBUG 01-14 20:42:25.688624.688624 lmp.py:1626] 
DEBUG 01-14 20:42:25.688624.688624 lmp.py:1626]   CPU total tokens: 3959 (32.2%)
DEBUG 01-14 20:42:25.688744.688744 lmp.py:1627]   GPU total tokens: 8329 (67.8%)
DEBUG 01-14 20:42:25.688394.688394 cuda_h.py:19] end experts_map_get cost 0.0015499591827392578 seconds
DEBUG 01-14 20:42:25.689866.689866 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-14 20:42:25.689047.689047 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-14 20:42:25.689681.689681 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-14 20:42:25.689562.689562 cuda_h.py:19] end allocate_cuda_memory cost 0.0003619194030761719 seconds
DEBUG 01-14 20:42:25.689803.689803 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-14 20:42:25.689036.689036 sllm_store_c.py:27] get device uuid map
DEBUG 01-14 20:42:25.689428.689428 sllm_store_c.py:29] call client load into gpu
DEBUG 01-14 20:42:25.689224.689224 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, b4e13df5-fb9e-41ee-93d5-c1272652e8c8
DEBUG 01-14 20:42:25.690472.690472 client.py:106] call stub.LoadModelAsync
INFO 01-14 20:42:25.692901.692901 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, b4e13df5-fb9e-41ee-93d5-c1272652e8c8
DEBUG 01-14 20:42:25.692645.692645 cuda_h.py:19] end load_into_gpu_async cost 0.002554655075073242 seconds
DEBUG 01-14 20:42:25.692063.692063 cuda_h.py:10] start restore_tensors2
DEBUG 01-14 20:42:25.692866.692866 cuda_h.py:19] end restore_tensors2 cost 0.0004246234893798828 seconds
DEBUG 01-14 20:42:25.692272.692272 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0037229061126708984 seconds
DEBUG 01-14 20:42:25.692326.692326 cuda_h.py:10] start restore2model
DEBUG 01-14 20:42:25.695812.695812 cuda_h.py:19] end restore2model cost 0.0026111602783203125 seconds
DEBUG 01-14 20:42:25.695264.695264 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.006514310836791992 seconds
DEBUG 01-14 20:42:25.695867.695867 cuda_h.py:10] start gpu_sexperts
DEBUG 01-14 20:42:25.695295.695295 cuda_h.py:19] end gpu_sexperts cost 0.00028586387634277344 seconds
DEBUG 01-14 20:42:25.695264.695264 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-14 20:42:25.696179.696179 lmp.py:1683] 
DEBUG 01-14 20:42:25.696179.696179 lmp.py:1683]   Computing 32 experts on CPU...
DEBUG 01-14 20:42:25.696691.696691 cuda_h.py:19] end cpu_experts_submit cost 7.724761962890625e-05 seconds
DEBUG 01-14 20:42:25.696063.696063 cuda_h.py:10] start experts_func_mgpu_group_pad
DEBUG 01-14 20:42:25.701380.701380 mlpmodule.py:1460] group tensors cost 0.004671812057495117 s
DEBUG 01-14 20:42:25.702429.702429 cuda_h.py:10] start move_flat_hidden2cpu
DEBUG 01-14 20:42:25.704426.704426 cuda_h.py:19] end experts_func_mgpu_group_pad cost 0.008816003799438477 seconds
DEBUG 01-14 20:42:25.706128.706128 cuda_h.py:10] start gpu_group_list
DEBUG 01-14 20:42:25.707031.707031 cuda_h.py:19] end gpu_group_list cost 0.0004134178161621094 seconds
DEBUG 01-14 20:42:25.707912.707912 cuda_h.py:10] start wait_experts
INFO 01-14 20:42:25.707934.707934 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, b4e13df5-fb9e-41ee-93d5-c1272652e8c8
DEBUG 01-14 20:42:25.708470.708470 cuda_h.py:19] end move_flat_hidden2cpu cost 0.006698131561279297 seconds
DEBUG 01-14 20:42:25.710272.710272 mlpmodule.py:1533] pad cost 0.0016727447509765625 s
DEBUG 01-14 20:42:25.710454.710454 mlpmodule.py:1539] create cpu tensor cost 3.62396240234375e-05 s
DEBUG 01-14 20:42:25.712020.712020 mlpmodule.py:1544] move to cpu cost 0.002032041549682617 s
DEBUG 01-14 20:42:25.721623.721623 mlpmodule.py:1558] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-14 20:42:25.722741.722741 mlpmodule.py:1559] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-14 20:42:25.722201.722201 mlpmodule.py:1564] group_w3 first element: -0.006439208984375
WARNING 01-14 20:42:25.722232.722232 mlpmodule.py:1574] start einsum2
DEBUG 01-14 20:42:25.738564.738564 mlpmodule.py:1584] group einsum cost 0.02606034278869629 s
DEBUG 01-14 20:42:25.739847.739847 mlpmodule.py:1593] cpy2cputensor cost 0.0007455348968505859 s
DEBUG 01-14 20:42:25.739862.739862 cuda_h.py:10] start move_outputs
DEBUG 01-14 20:42:25.742287.742287 cuda_h.py:19] end move_outputs cost 0.002773284912109375 seconds
INFO 01-14 20:42:25.749154.749154 client.py:127] Model loaded
DEBUG 01-14 20:42:25.749531.749531 cuda_h.py:19] end wait_experts cost 0.04234910011291504 seconds
DEBUG 01-14 20:42:25.749016.749016 cuda_h.py:10] start gpu_experts
DEBUG 01-14 20:42:25.749885.749885 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-14 20:42:25.749415.749415 cuda_h.py:19] end wait_cetm_experts cost 0.00018095970153808594 seconds
DEBUG 01-14 20:42:25.750610.750610 cuda_h.py:10] start gpu_group_einsum_mp_multi_list
DEBUG 01-14 20:42:25.750750.750750 cuda_h.py:10] start gpu_group_tensor
DEBUG 01-14 20:42:25.750024.750024 cuda_h.py:19] end gpu_group_tensor cost 0.00024127960205078125 seconds
DEBUG 01-14 20:42:25.750856.750856 cuda_h.py:10] start gpu_group_einsum
DEBUG 01-14 20:42:25.751617.751617 cuda_h.py:19] end gpu_group_einsum cost 0.0007107257843017578 seconds
DEBUG 01-14 20:42:25.751350.751350 cuda_h.py:10] start gpu_final_hidden_states_scatter
DEBUG 01-14 20:42:25.751929.751929 cuda_h.py:10] start all_expert_outputs_slices
DEBUG 01-14 20:42:25.751261.751261 cuda_h.py:19] end all_expert_outputs_slices cost 0.0003802776336669922 seconds
DEBUG 01-14 20:42:25.751309.751309 cuda_h.py:10] start concat_expert_out
DEBUG 01-14 20:42:25.752888.752888 cuda_h.py:19] end concat_expert_out cost 6.723403930664062e-05 seconds
DEBUG 01-14 20:42:25.752652.752652 cuda_h.py:10] start index_scatter
DEBUG 01-14 20:42:25.752855.752855 cuda_h.py:19] end index_scatter cost 7.915496826171875e-05 seconds
DEBUG 01-14 20:42:25.752571.752571 cuda_h.py:19] end gpu_final_hidden_states_scatter cost 0.0008096694946289062 seconds
DEBUG 01-14 20:42:25.752694.752694 cuda_h.py:19] end gpu_experts cost 0.0026123523712158203 seconds
DEBUG 01-14 20:42:25.752635.752635 cuda_h.py:10] start all_expert_weight_slices
DEBUG 01-14 20:42:25.753286.753286 cuda_h.py:19] end all_expert_weight_slices cost 0.0009579658508300781 seconds
DEBUG 01-14 20:42:25.753393.753393 cuda_h.py:10] start cpuoutputsdeal
DEBUG 01-14 20:42:25.753793.753793 cuda_h.py:10] start index_scatter
DEBUG 01-14 20:42:25.754651.754651 cuda_h.py:19] end index_scatter cost 5.459785461425781e-05 seconds
DEBUG 01-14 20:42:25.754705.754705 cuda_h.py:19] end cpuoutputsdeal cost 0.0005862712860107422 seconds
DEBUG 01-14 20:42:25.754814.754814 cuda_h.py:19] end layer_moe_generate_mp_l_28 cost 0.06740951538085938 seconds
DEBUG 01-14 20:42:25.754437.754437 cuda_h.py:19] end prefill_layer cost 0.07328248023986816 seconds
DEBUG 01-14 20:42:25.754996.754996 lmp.py:1551] -------------------------------- end prefill layer 27 --------------------------------
DEBUG 01-14 20:42:25.754282.754282 cuda_h.py:19] end prefill cost 2.3134026527404785 seconds
DEBUG 01-14 20:42:25.754011.754011 mlpmodule.py:1367]  experts func einsum cost 0.05836820602416992 s
DEBUG 01-14 20:42:27.931914.931914 cuda_h.py:10] start generate_input_ids
generate input ids cost 0.09277105331420898 s
DEBUG 01-14 20:42:28.296156.296156 cuda_h.py:19] end generate_input_ids cost 0.3613128662109375 seconds
DEBUG 01-14 20:42:28.296572.296572 cuda_h.py:10] start init_cache
DEBUG 01-14 20:42:28.296596.296596 cuda_h.py:19] end init_cache cost 6.651878356933594e-05 seconds
DEBUG 01-14 20:42:30.848556.848556 cuda_h.py:10] start init_meta_layer
DEBUG 01-14 20:42:30.850061.850061 cuda_h.py:19] end init_meta_layer cost 1.1444091796875e-05 seconds
DEBUG 01-14 20:42:30.850966.850966 cuda_h.py:10] start init_weights
DEBUG 01-14 20:42:30.850206.850206 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-14 20:42:30.850631.850631 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-14 20:42:30.852526.852526 cuda_h.py:19] end allocate_cuda_memory cost 0.0021758079528808594 seconds
DEBUG 01-14 20:42:30.852336.852336 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-14 20:42:30.852476.852476 sllm_store_c.py:27] get device uuid map
DEBUG 01-14 20:42:30.852206.852206 sllm_store_c.py:29] call client load into gpu
DEBUG 01-14 20:42:30.852479.852479 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, ea75ed1f-5558-4fa5-a4b9-06135f8a7418
DEBUG 01-14 20:42:30.853700.853700 client.py:106] call stub.LoadModelAsync
INFO 01-14 20:42:30.854368.854368 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, ea75ed1f-5558-4fa5-a4b9-06135f8a7418
DEBUG 01-14 20:42:30.855882.855882 cuda_h.py:19] end load_into_gpu_async cost 0.002216815948486328 seconds
DEBUG 01-14 20:42:30.855123.855123 cuda_h.py:10] start restore_tensors2
DEBUG 01-14 20:42:30.855884.855884 cuda_h.py:19] end restore_tensors2 cost 0.00010085105895996094 seconds
DEBUG 01-14 20:42:30.855521.855521 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.004845380783081055 seconds
DEBUG 01-14 20:42:30.855740.855740 cuda_h.py:10] start restore2model
DEBUG 01-14 20:42:30.855919.855919 cuda_h.py:19] end restore2model cost 0.00017976760864257812 seconds
INFO 01-14 20:42:30.855391.855391 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, ea75ed1f-5558-4fa5-a4b9-06135f8a7418
INFO 01-14 20:42:30.934606.934606 client.py:127] Model loaded
DEBUG 01-14 20:42:30.934247.934247 cuda_h.py:10] start load_qkvogns_weight_l_0
DEBUG 01-14 20:42:30.934423.934423 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-14 20:42:30.935003.935003 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-14 20:42:30.935753.935753 cuda_h.py:19] end allocate_cuda_memory cost 0.00035691261291503906 seconds
DEBUG 01-14 20:42:30.935142.935142 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-14 20:42:30.935920.935920 sllm_store_c.py:27] get device uuid map
DEBUG 01-14 20:42:30.935095.935095 sllm_store_c.py:29] call client load into gpu
DEBUG 01-14 20:42:30.935760.935760 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, bdd3df39-7c58-4d03-9ead-7cd231cc9e8f
DEBUG 01-14 20:42:30.936183.936183 client.py:106] call stub.LoadModelAsync
INFO 01-14 20:42:30.937098.937098 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, bdd3df39-7c58-4d03-9ead-7cd231cc9e8f
DEBUG 01-14 20:42:30.937647.937647 cuda_h.py:19] end load_into_gpu_async cost 0.002106189727783203 seconds
DEBUG 01-14 20:42:30.937000.937000 cuda_h.py:10] start restore_tensors2
DEBUG 01-14 20:42:30.938292.938292 cuda_h.py:19] end restore_tensors2 cost 0.00013375282287597656 seconds
DEBUG 01-14 20:42:30.938653.938653 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0032138824462890625 seconds
INFO 01-14 20:42:30.938278.938278 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, bdd3df39-7c58-4d03-9ead-7cd231cc9e8f
INFO 01-14 20:42:30.953045.953045 client.py:127] Model loaded
DEBUG 01-14 20:42:30.953189.953189 cuda_h.py:10] start restore2model
DEBUG 01-14 20:42:30.954935.954935 cuda_h.py:19] end restore2model cost 0.0008387565612792969 seconds
DEBUG 01-14 20:42:30.954397.954397 cuda_h.py:19] end load_qkvogns_weight_l_0 cost 0.01960301399230957 seconds
DEBUG 01-14 20:42:30.954135.954135 cuda_h.py:19] end init_weights cost 0.10408830642700195 seconds
DEBUG 01-14 20:42:30.954223.954223 cuda_h.py:10] start copy_emodel
DEBUG 01-14 20:42:31.715248.715248 cuda_h.py:19] end copy_emodel cost 0.760528564453125 seconds
DEBUG 01-14 20:42:31.716288.716288 cuda_h.py:10] start init_inputs_tokens
DEBUG 01-14 20:42:31.716901.716901 cuda_h.py:19] end init_inputs_tokens cost 0.0002589225769042969 seconds
DEBUG 01-14 20:42:31.716936.716936 cuda_h.py:10] start prefill
DEBUG 01-14 20:42:31.716983.716983 cuda_h.py:10] start prefill_layer
DEBUG 01-14 20:42:31.716348.716348 lmp.py:1494] -------------------------------- start prefill layer 0 --------------------------------
DEBUG 01-14 20:42:31.716045.716045 cuda_h.py:10] start start_load_qkvogn_s_weight_l_1
DEBUG 01-14 20:42:31.716384.716384 cuda_h.py:10] start start_load_qkvogn_s_weight_l_1
DEBUG 01-14 20:42:31.716326.716326 cuda_h.py:19] end start_load_qkvogn_s_weight_l_1 cost 3.528594970703125e-05 seconds
DEBUG 01-14 20:42:31.716552.716552 cuda_h.py:19] end start_load_qkvogn_s_weight_l_1 cost 6.818771362304688e-05 seconds
DEBUG 01-14 20:42:31.716626.716626 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-14 20:42:31.716138.716138 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-14 20:42:31.716948.716948 cuda_h.py:10] start sllm_worker_task
DEBUG 01-14 20:42:31.717729.717729 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-14 20:42:31.717294.717294 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-14 20:42:31.717749.717749 cuda_h.py:19] end allocate_cuda_memory cost 0.0002925395965576172 seconds
DEBUG 01-14 20:42:31.717520.717520 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-14 20:42:31.717621.717621 sllm_store_c.py:27] get device uuid map
DEBUG 01-14 20:42:31.717788.717788 sllm_store_c.py:29] call client load into gpu
DEBUG 01-14 20:42:31.717498.717498 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 37d30df1-941d-4f7b-b606-f9b6173a843e
DEBUG 01-14 20:42:31.717872.717872 client.py:106] call stub.LoadModelAsync
DEBUG 01-14 20:42:31.718843.718843 cuda_h.py:10] start self_attn
INFO 01-14 20:42:31.719130.719130 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 37d30df1-941d-4f7b-b606-f9b6173a843e
DEBUG 01-14 20:42:31.719264.719264 cuda_h.py:19] end load_into_gpu_async cost 0.0020189285278320312 seconds
DEBUG 01-14 20:42:31.719497.719497 cuda_h.py:10] start restore_tensors2
DEBUG 01-14 20:42:31.719468.719468 cuda_h.py:19] end restore_tensors2 cost 7.963180541992188e-05 seconds
DEBUG 01-14 20:42:31.719138.719138 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0026788711547851562 seconds
INFO 01-14 20:42:31.719611.719611 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 37d30df1-941d-4f7b-b606-f9b6173a843e
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-14 20:42:31.721889.721889 cuda_h.py:19] end self_attn cost 0.0034797191619873047 seconds
DEBUG 01-14 20:42:31.721032.721032 cuda_h.py:19] end iln_self_attn_paln cost 0.005185127258300781 seconds
DEBUG 01-14 20:42:31.721477.721477 cuda_h.py:10] start dense_mlp
INFO 01-14 20:42:31.731524.731524 client.py:127] Model loaded
DEBUG 01-14 20:42:31.731098.731098 cuda_h.py:10] start restore2model
DEBUG 01-14 20:42:31.732618.732618 cuda_h.py:19] end restore2model cost 0.0006108283996582031 seconds
DEBUG 01-14 20:42:31.732037.732037 cuda_h.py:19] end sllm_worker_task cost 0.015544652938842773 seconds
DEBUG 01-14 20:42:31.732160.732160 cuda_h.py:19] end dense_mlp cost 0.010645151138305664 seconds
DEBUG 01-14 20:42:31.732707.732707 cuda_h.py:19] end prefill_layer cost 0.016236066818237305 seconds
DEBUG 01-14 20:42:31.732900.732900 lmp.py:1551] -------------------------------- end prefill layer 0 --------------------------------
DEBUG 01-14 20:42:31.732980.732980 cuda_h.py:10] start prefill_layer
DEBUG 01-14 20:42:31.732538.732538 lmp.py:1494] -------------------------------- start prefill layer 1 --------------------------------
DEBUG 01-14 20:42:31.732903.732903 cuda_h.py:10] start start_load_qkvogn_s_weight_l_2
DEBUG 01-14 20:42:31.732029.732029 cuda_h.py:10] start start_load_qkvogn_s_weight_l_2
DEBUG 01-14 20:42:31.732044.732044 cuda_h.py:19] end start_load_qkvogn_s_weight_l_2 cost 2.1696090698242188e-05 seconds
DEBUG 01-14 20:42:31.732747.732747 cuda_h.py:19] end start_load_qkvogn_s_weight_l_2 cost 5.078315734863281e-05 seconds
DEBUG 01-14 20:42:31.732297.732297 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-14 20:42:31.733080.733080 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-14 20:42:31.733539.733539 cuda_h.py:10] start sllm_worker_task
DEBUG 01-14 20:42:31.733144.733144 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-14 20:42:31.733464.733464 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-14 20:42:31.733909.733909 cuda_h.py:19] end allocate_cuda_memory cost 0.0002105236053466797 seconds
DEBUG 01-14 20:42:31.733842.733842 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-14 20:42:31.733625.733625 sllm_store_c.py:27] get device uuid map
DEBUG 01-14 20:42:31.733700.733700 sllm_store_c.py:29] call client load into gpu
DEBUG 01-14 20:42:31.733390.733390 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 061dc121-0df2-4726-802f-5d2eb3467d99
DEBUG 01-14 20:42:31.733288.733288 client.py:106] call stub.LoadModelAsync
DEBUG 01-14 20:42:31.734566.734566 cuda_h.py:10] start self_attn
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
INFO 01-14 20:42:31.736207.736207 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 061dc121-0df2-4726-802f-5d2eb3467d99
DEBUG 01-14 20:42:31.736627.736627 cuda_h.py:19] end load_into_gpu_async cost 0.0026276111602783203 seconds
DEBUG 01-14 20:42:31.736464.736464 cuda_h.py:10] start restore_tensors2
DEBUG 01-14 20:42:31.736569.736569 cuda_h.py:19] end restore_tensors2 cost 9.703636169433594e-05 seconds
DEBUG 01-14 20:42:31.736326.736326 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.003426790237426758 seconds
INFO 01-14 20:42:31.736051.736051 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 061dc121-0df2-4726-802f-5d2eb3467d99
DEBUG 01-14 20:42:31.737821.737821 cuda_h.py:19] end self_attn cost 0.0029973983764648438 seconds
DEBUG 01-14 20:42:31.737098.737098 cuda_h.py:19] end iln_self_attn_paln cost 0.004492044448852539 seconds
DEBUG 01-14 20:42:31.737769.737769 cuda_h.py:10] start layer_moe_generate_mp_l_2
DEBUG 01-14 20:42:31.737830.737830 cuda_h.py:10] start gate
DEBUG 01-14 20:42:31.738958.738958 cuda_h.py:19] end gate cost 0.0008192062377929688 seconds
DEBUG 01-14 20:42:31.738755.738755 cuda_h.py:10] start experts_map_get
DEBUG 01-14 20:42:31.738642.738642 lmp.py:1615] 
DEBUG 01-14 20:42:31.738642.738642 lmp.py:1615] Expert Token Distribution & Device Allocation:
DEBUG 01-14 20:42:31.738550.738550 lmp.py:1616]   Total experts: 64
DEBUG 01-14 20:42:31.738922.738922 lmp.py:1617]   CPU experts: 32 (50%)
DEBUG 01-14 20:42:31.739241.739241 lmp.py:1618]   GPU experts: 32 (50%)
DEBUG 01-14 20:42:31.739321.739321 lmp.py:1619] 
DEBUG 01-14 20:42:31.739321.739321 lmp.py:1619]   Expert ID | Tokens | Device
DEBUG 01-14 20:42:31.739686.739686 lmp.py:1620]   -----------------------------------
DEBUG 01-14 20:42:31.739482.739482 lmp.py:1625]   Expert 25 |     64 | CPU
DEBUG 01-14 20:42:31.739085.739085 lmp.py:1625]   Expert 54 |     67 | CPU
DEBUG 01-14 20:42:31.739020.739020 lmp.py:1625]   Expert  3 |     68 | CPU
DEBUG 01-14 20:42:31.739716.739716 lmp.py:1625]   Expert 31 |     72 | CPU
DEBUG 01-14 20:42:31.739935.739935 lmp.py:1625]   Expert 55 |     72 | CPU
DEBUG 01-14 20:42:31.739916.739916 lmp.py:1625]   Expert 62 |     87 | CPU
DEBUG 01-14 20:42:31.739420.739420 lmp.py:1625]   Expert 18 |     88 | CPU
DEBUG 01-14 20:42:31.739162.739162 lmp.py:1625]   Expert 52 |     98 | CPU
DEBUG 01-14 20:42:31.739143.739143 lmp.py:1625]   Expert 22 |    100 | CPU
DEBUG 01-14 20:42:31.739316.739316 lmp.py:1625]   Expert 47 |    104 | CPU
DEBUG 01-14 20:42:31.739489.739489 lmp.py:1625]   Expert  0 |    113 | CPU
DEBUG 01-14 20:42:31.739423.739423 lmp.py:1625]   Expert 37 |    117 | CPU
DEBUG 01-14 20:42:31.739643.739643 lmp.py:1625]   Expert 27 |    121 | CPU
DEBUG 01-14 20:42:31.739385.739385 lmp.py:1625]   Expert 32 |    123 | CPU
DEBUG 01-14 20:42:31.739889.739889 lmp.py:1625]   Expert 41 |    130 | CPU
DEBUG 01-14 20:42:31.739393.739393 lmp.py:1625]   Expert 44 |    131 | CPU
DEBUG 01-14 20:42:31.739136.739136 lmp.py:1625]   Expert 28 |    136 | CPU
DEBUG 01-14 20:42:31.739878.739878 lmp.py:1625]   Expert 13 |    138 | CPU
DEBUG 01-14 20:42:31.739382.739382 lmp.py:1625]   Expert 58 |    140 | CPU
DEBUG 01-14 20:42:31.739363.739363 lmp.py:1625]   Expert 60 |    144 | CPU
DEBUG 01-14 20:42:31.739105.739105 lmp.py:1625]   Expert 43 |    147 | CPU
DEBUG 01-14 20:42:31.739801.739801 lmp.py:1625]   Expert  1 |    150 | CPU
DEBUG 01-14 20:42:31.739259.739259 lmp.py:1625]   Expert 38 |    153 | CPU
DEBUG 01-14 20:42:31.739478.739478 lmp.py:1625]   Expert 49 |    154 | CPU
DEBUG 01-14 20:42:31.739982.739982 lmp.py:1625]   Expert 51 |    155 | CPU
DEBUG 01-14 20:42:31.739725.739725 lmp.py:1625]   Expert 34 |    161 | CPU
DEBUG 01-14 20:42:31.739467.739467 lmp.py:1625]   Expert 35 |    164 | CPU
DEBUG 01-14 20:42:31.739209.739209 lmp.py:1625]   Expert 36 |    168 | CPU
DEBUG 01-14 20:42:31.739713.739713 lmp.py:1625]   Expert 11 |    170 | CPU
DEBUG 01-14 20:42:31.739217.739217 lmp.py:1625]   Expert 17 |    170 | CPU
DEBUG 01-14 20:42:31.739960.739960 lmp.py:1625]   Expert 59 |    174 | CPU
DEBUG 01-14 20:42:31.739179.739179 lmp.py:1625]   Expert 10 |    180 | CPU
DEBUG 01-14 20:42:31.739875.739875 lmp.py:1625]   Expert 20 |    182 | GPU
DEBUG 01-14 20:42:31.739571.739571 lmp.py:1625]   Expert  2 |    186 | GPU
DEBUG 01-14 20:42:31.739075.739075 lmp.py:1625]   Expert 39 |    189 | GPU
DEBUG 01-14 20:42:31.739579.739579 lmp.py:1625]   Expert 33 |    197 | GPU
DEBUG 01-14 20:42:31.739083.739083 lmp.py:1625]   Expert 12 |    198 | GPU
DEBUG 01-14 20:42:31.739587.739587 lmp.py:1625]   Expert 21 |    198 | GPU
DEBUG 01-14 20:42:31.739091.739091 lmp.py:1625]   Expert 48 |    198 | GPU
DEBUG 01-14 20:42:31.739549.739549 lmp.py:1625]   Expert 15 |    199 | GPU
DEBUG 01-14 20:42:31.739245.739245 lmp.py:1625]   Expert 53 |    204 | GPU
DEBUG 01-14 20:42:31.739180.739180 lmp.py:1625]   Expert 19 |    220 | GPU
DEBUG 01-14 20:42:31.739399.739399 lmp.py:1625]   Expert 26 |    221 | GPU
DEBUG 01-14 20:42:31.739903.739903 lmp.py:1625]   Expert 30 |    221 | GPU
DEBUG 01-14 20:42:31.740930.740930 lmp.py:1625]   Expert 45 |    221 | GPU
DEBUG 01-14 20:42:31.740196.740196 lmp.py:1625]   Expert  5 |    227 | GPU
DEBUG 01-14 20:42:31.740461.740461 lmp.py:1625]   Expert  4 |    229 | GPU
DEBUG 01-14 20:42:31.740727.740727 lmp.py:1625]   Expert 24 |    229 | GPU
DEBUG 01-14 20:42:31.740992.740992 lmp.py:1625]   Expert 42 |    242 | GPU
DEBUG 01-14 20:42:31.740404.740404 lmp.py:1625]   Expert 50 |    245 | GPU
DEBUG 01-14 20:42:31.740530.740530 lmp.py:1625]   Expert 29 |    254 | GPU
DEBUG 01-14 20:42:31.740418.740418 lmp.py:1625]   Expert 56 |    262 | GPU
DEBUG 01-14 20:42:31.740307.740307 lmp.py:1625]   Expert 61 |    270 | GPU
DEBUG 01-14 20:42:31.740480.740480 lmp.py:1625]   Expert  8 |    283 | GPU
DEBUG 01-14 20:42:31.740891.740891 lmp.py:1625]   Expert 63 |    285 | GPU
DEBUG 01-14 20:42:31.740110.740110 lmp.py:1625]   Expert 46 |    294 | GPU
DEBUG 01-14 20:42:31.740806.740806 lmp.py:1625]   Expert  9 |    300 | GPU
DEBUG 01-14 20:42:31.740264.740264 lmp.py:1625]   Expert  6 |    316 | GPU
DEBUG 01-14 20:42:31.740437.740437 lmp.py:1625]   Expert 16 |    316 | GPU
DEBUG 01-14 20:42:31.740610.740610 lmp.py:1625]   Expert 40 |    319 | GPU
DEBUG 01-14 20:42:31.740498.740498 lmp.py:1625]   Expert  7 |    322 | GPU
DEBUG 01-14 20:42:31.740221.740221 lmp.py:1625]   Expert 23 |    325 | GPU
DEBUG 01-14 20:42:31.740109.740109 lmp.py:1625]   Expert 14 |    413 | GPU
DEBUG 01-14 20:42:31.740521.740521 lmp.py:1625]   Expert 57 |    464 | GPU
DEBUG 01-14 20:42:31.740217.740217 lmp.py:1626] 
DEBUG 01-14 20:42:31.740217.740217 lmp.py:1626]   CPU total tokens: 4059 (33.0%)
DEBUG 01-14 20:42:31.740628.740628 lmp.py:1627]   GPU total tokens: 8229 (67.0%)
DEBUG 01-14 20:42:31.740569.740569 cuda_h.py:19] end experts_map_get cost 0.0019342899322509766 seconds
DEBUG 01-14 20:42:31.740016.740016 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-14 20:42:31.740734.740734 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-14 20:42:31.740004.740004 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-14 20:42:31.742420.742420 cuda_h.py:19] end allocate_cuda_memory cost 0.002090930938720703 seconds
DEBUG 01-14 20:42:31.743494.743494 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-14 20:42:31.743356.743356 sllm_store_c.py:27] get device uuid map
DEBUG 01-14 20:42:31.743179.743179 sllm_store_c.py:29] call client load into gpu
DEBUG 01-14 20:42:31.743173.743173 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 6f605fef-6519-44c5-b899-9235dbd94a6f
DEBUG 01-14 20:42:31.743191.743191 client.py:106] call stub.LoadModelAsync
INFO 01-14 20:42:31.744119.744119 client.py:127] Model loaded
DEBUG 01-14 20:42:31.744427.744427 cuda_h.py:10] start restore2model
DEBUG 01-14 20:42:31.745653.745653 cuda_h.py:19] end restore2model cost 0.0007128715515136719 seconds
DEBUG 01-14 20:42:31.745530.745530 cuda_h.py:19] end sllm_worker_task cost 0.012712717056274414 seconds
INFO 01-14 20:42:31.746710.746710 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 6f605fef-6519-44c5-b899-9235dbd94a6f
DEBUG 01-14 20:42:31.746898.746898 cuda_h.py:19] end load_into_gpu_async cost 0.0027132034301757812 seconds
DEBUG 01-14 20:42:31.746985.746985 cuda_h.py:10] start restore_tensors2
DEBUG 01-14 20:42:31.746674.746674 cuda_h.py:19] end restore_tensors2 cost 0.00037407875061035156 seconds
DEBUG 01-14 20:42:31.746086.746086 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.005953788757324219 seconds
DEBUG 01-14 20:42:31.746803.746803 cuda_h.py:10] start restore2model
DEBUG 01-14 20:42:31.749140.749140 cuda_h.py:19] end restore2model cost 0.0027091503143310547 seconds
DEBUG 01-14 20:42:31.749182.749182 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.008865594863891602 seconds
DEBUG 01-14 20:42:31.749215.749215 cuda_h.py:10] start gpu_sexperts
DEBUG 01-14 20:42:31.749245.749245 cuda_h.py:19] end gpu_sexperts cost 0.00027179718017578125 seconds
DEBUG 01-14 20:42:31.749035.749035 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-14 20:42:31.749692.749692 lmp.py:1683] 
DEBUG 01-14 20:42:31.749692.749692 lmp.py:1683]   Computing 32 experts on CPU...
DEBUG 01-14 20:42:31.749098.749098 cuda_h.py:19] end cpu_experts_submit cost 5.364418029785156e-05 seconds
DEBUG 01-14 20:42:31.750867.750867 cuda_h.py:10] start experts_func_mgpu_group_pad
DEBUG 01-14 20:42:31.756787.756787 mlpmodule.py:1460] group tensors cost 0.005898714065551758 s
DEBUG 01-14 20:42:31.757362.757362 cuda_h.py:10] start move_flat_hidden2cpu
DEBUG 01-14 20:42:31.763664.763664 cuda_h.py:19] end experts_func_mgpu_group_pad cost 0.013655662536621094 seconds
DEBUG 01-14 20:42:31.765269.765269 cuda_h.py:10] start gpu_group_list
DEBUG 01-14 20:42:31.766806.766806 cuda_h.py:19] end gpu_group_list cost 0.0005028247833251953 seconds
DEBUG 01-14 20:42:31.766838.766838 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-14 20:42:31.766794.766794 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.1457672119140625e-05 seconds
DEBUG 01-14 20:42:31.766411.766411 cuda_h.py:10] start wait_experts
INFO 01-14 20:42:31.766743.766743 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 6f605fef-6519-44c5-b899-9235dbd94a6f
DEBUG 01-14 20:42:31.790380.790380 cuda_h.py:19] end move_flat_hidden2cpu cost 0.0324704647064209 seconds
DEBUG 01-14 20:42:31.791051.791051 mlpmodule.py:1533] pad cost 0.0015399456024169922 s
DEBUG 01-14 20:42:31.791949.791949 mlpmodule.py:1539] create cpu tensor cost 3.719329833984375e-05 s
INFO 01-14 20:42:31.794453.794453 client.py:127] Model loaded
DEBUG 01-14 20:42:31.794550.794550 mlpmodule.py:1544] move to cpu cost 0.002084970474243164 s
DEBUG 01-14 20:42:31.794447.794447 cuda_h.py:19] end wait_experts cost 0.027327775955200195 seconds
DEBUG 01-14 20:42:31.794326.794326 cuda_h.py:10] start gpu_experts
DEBUG 01-14 20:42:31.794003.794003 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-14 20:42:31.805269.805269 mlpmodule.py:1558] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-14 20:42:31.805678.805678 mlpmodule.py:1559] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-14 20:42:31.805701.805701 mlpmodule.py:1564] group_w3 first element: -0.0107421875
WARNING 01-14 20:42:31.806480.806480 mlpmodule.py:1574] start einsum2
DEBUG 01-14 20:42:31.823470.823470 mlpmodule.py:1584] group einsum cost 0.029654979705810547 s
DEBUG 01-14 20:42:31.824197.824197 mlpmodule.py:1593] cpy2cputensor cost 0.0007579326629638672 s
DEBUG 01-14 20:42:31.824166.824166 cuda_h.py:10] start move_outputs
DEBUG 01-14 20:42:31.827256.827256 cuda_h.py:19] end move_outputs cost 0.002070903778076172 seconds
DEBUG 01-14 20:42:31.830838.830838 cuda_h.py:19] end wait_cetm_experts cost 0.036313533782958984 seconds
DEBUG 01-14 20:42:31.831255.831255 cuda_h.py:10] start gpu_group_einsum_mp_multi_list
DEBUG 01-14 20:42:31.831601.831601 cuda_h.py:10] start gpu_group_tensor
DEBUG 01-14 20:42:31.843234.843234 mlpmodule.py:1367]  experts func einsum cost 0.09286952018737793 s
DEBUG 01-14 20:42:31.844464.844464 cuda_h.py:19] end gpu_group_tensor cost 0.013039588928222656 seconds
DEBUG 01-14 20:42:31.844557.844557 cuda_h.py:10] start gpu_group_einsum
DEBUG 01-14 20:42:31.845414.845414 cuda_h.py:19] end gpu_group_einsum cost 0.0010221004486083984 seconds
DEBUG 01-14 20:42:31.845769.845769 cuda_h.py:10] start gpu_final_hidden_states_scatter
DEBUG 01-14 20:42:31.845698.845698 cuda_h.py:10] start all_expert_outputs_slices
DEBUG 01-14 20:42:31.845952.845952 cuda_h.py:19] end all_expert_outputs_slices cost 0.00022840499877929688 seconds
DEBUG 01-14 20:42:31.845132.845132 cuda_h.py:10] start concat_expert_out
DEBUG 01-14 20:42:31.846486.846486 cuda_h.py:19] end concat_expert_out cost 5.364418029785156e-05 seconds
DEBUG 01-14 20:42:31.846428.846428 cuda_h.py:10] start index_scatter
DEBUG 01-14 20:42:31.846564.846564 cuda_h.py:19] end index_scatter cost 6.818771362304688e-05 seconds
DEBUG 01-14 20:42:31.846181.846181 cuda_h.py:19] end gpu_final_hidden_states_scatter cost 0.0005800724029541016 seconds
DEBUG 01-14 20:42:31.846614.846614 cuda_h.py:19] end gpu_experts cost 0.05186271667480469 seconds
DEBUG 01-14 20:42:31.846456.846456 cuda_h.py:10] start all_expert_weight_slices
DEBUG 01-14 20:42:31.847794.847794 cuda_h.py:19] end all_expert_weight_slices cost 0.0007841587066650391 seconds
DEBUG 01-14 20:42:31.847663.847663 cuda_h.py:10] start cpuoutputsdeal
DEBUG 01-14 20:42:31.847814.847814 cuda_h.py:10] start index_scatter
DEBUG 01-14 20:42:31.847274.847274 cuda_h.py:19] end index_scatter cost 4.673004150390625e-05 seconds
DEBUG 01-14 20:42:31.847752.847752 cuda_h.py:19] end cpuoutputsdeal cost 0.0004611015319824219 seconds
DEBUG 01-14 20:42:31.847463.847463 cuda_h.py:19] end layer_moe_generate_mp_l_2 cost 0.11009383201599121 seconds
DEBUG 01-14 20:42:31.848182.848182 cuda_h.py:19] end prefill_layer cost 0.11518383026123047 seconds
DEBUG 01-14 20:42:31.848748.848748 lmp.py:1551] -------------------------------- end prefill layer 1 --------------------------------
DEBUG 01-14 20:42:31.848305.848305 cuda_h.py:10] start prefill_layer
DEBUG 01-14 20:42:31.848862.848862 lmp.py:1494] -------------------------------- start prefill layer 2 --------------------------------
DEBUG 01-14 20:42:31.848704.848704 cuda_h.py:10] start start_load_qkvogn_s_weight_l_3
DEBUG 01-14 20:42:31.848976.848976 cuda_h.py:10] start start_load_qkvogn_s_weight_l_3
DEBUG 01-14 20:42:31.848912.848912 cuda_h.py:19] end start_load_qkvogn_s_weight_l_3 cost 3.3855438232421875e-05 seconds
DEBUG 01-14 20:42:31.848469.848469 cuda_h.py:19] end start_load_qkvogn_s_weight_l_3 cost 6.151199340820312e-05 seconds
DEBUG 01-14 20:42:31.848304.848304 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-14 20:42:31.848883.848883 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-14 20:42:31.848762.848762 cuda_h.py:10] start sllm_worker_task
DEBUG 01-14 20:42:31.848375.848375 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-14 20:42:31.848787.848787 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-14 20:42:31.848610.848610 cuda_h.py:19] end allocate_cuda_memory cost 0.00021767616271972656 seconds
DEBUG 01-14 20:42:31.849990.849990 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-14 20:42:31.849038.849038 sllm_store_c.py:27] get device uuid map
DEBUG 01-14 20:42:31.849675.849675 sllm_store_c.py:29] call client load into gpu
DEBUG 01-14 20:42:31.849809.849809 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, c770de3e-9940-4f88-94ab-bc5ae8b2d0d3
DEBUG 01-14 20:42:31.849169.849169 client.py:106] call stub.LoadModelAsync
DEBUG 01-14 20:42:31.849402.849402 cuda_h.py:10] start self_attn
INFO 01-14 20:42:31.850388.850388 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, c770de3e-9940-4f88-94ab-bc5ae8b2d0d3
DEBUG 01-14 20:42:31.851515.851515 cuda_h.py:19] end load_into_gpu_async cost 0.0020020008087158203 seconds
DEBUG 01-14 20:42:31.851503.851503 cuda_h.py:10] start restore_tensors2
DEBUG 01-14 20:42:31.851877.851877 cuda_h.py:19] end restore_tensors2 cost 7.176399230957031e-05 seconds
DEBUG 01-14 20:42:31.851064.851064 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.002543210983276367 seconds
INFO 01-14 20:42:31.851377.851377 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, c770de3e-9940-4f88-94ab-bc5ae8b2d0d3
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-14 20:42:31.852444.852444 cuda_h.py:19] end self_attn cost 0.0029506683349609375 seconds
DEBUG 01-14 20:42:31.852944.852944 cuda_h.py:19] end iln_self_attn_paln cost 0.0044460296630859375 seconds
DEBUG 01-14 20:42:31.852787.852787 cuda_h.py:10] start layer_moe_generate_mp_l_3
DEBUG 01-14 20:42:31.852311.852311 cuda_h.py:10] start gate
DEBUG 01-14 20:42:31.853519.853519 cuda_h.py:19] end gate cost 0.0006461143493652344 seconds
DEBUG 01-14 20:42:31.853826.853826 cuda_h.py:10] start experts_map_get
DEBUG 01-14 20:42:31.853055.853055 lmp.py:1615] 
DEBUG 01-14 20:42:31.853055.853055 lmp.py:1615] Expert Token Distribution & Device Allocation:
DEBUG 01-14 20:42:31.853764.853764 lmp.py:1616]   Total experts: 64
DEBUG 01-14 20:42:31.853606.853606 lmp.py:1617]   CPU experts: 32 (50%)
DEBUG 01-14 20:42:31.853395.853395 lmp.py:1618]   GPU experts: 32 (50%)
DEBUG 01-14 20:42:31.853561.853561 lmp.py:1619] 
DEBUG 01-14 20:42:31.853561.853561 lmp.py:1619]   Expert ID | Tokens | Device
DEBUG 01-14 20:42:31.854727.854727 lmp.py:1620]   -----------------------------------
DEBUG 01-14 20:42:31.854562.854562 lmp.py:1625]   Expert 58 |     56 | CPU
DEBUG 01-14 20:42:31.854967.854967 lmp.py:1625]   Expert 27 |     81 | CPU
DEBUG 01-14 20:42:31.854133.854133 lmp.py:1625]   Expert  3 |     85 | CPU
DEBUG 01-14 20:42:31.854822.854822 lmp.py:1625]   Expert 17 |     87 | CPU
DEBUG 01-14 20:42:31.854273.854273 lmp.py:1625]   Expert 24 |     87 | CPU
DEBUG 01-14 20:42:31.854486.854486 lmp.py:1625]   Expert  0 |     88 | CPU
DEBUG 01-14 20:42:31.854890.854890 lmp.py:1625]   Expert 28 |    106 | CPU
DEBUG 01-14 20:42:31.854056.854056 lmp.py:1625]   Expert 34 |    107 | CPU
DEBUG 01-14 20:42:31.854984.854984 lmp.py:1625]   Expert 51 |    112 | CPU
DEBUG 01-14 20:42:31.854197.854197 lmp.py:1625]   Expert 32 |    118 | CPU
DEBUG 01-14 20:42:31.854409.854409 lmp.py:1625]   Expert 23 |    122 | CPU
DEBUG 01-14 20:42:31.854383.854383 lmp.py:1625]   Expert 15 |    128 | CPU
DEBUG 01-14 20:42:31.854595.854595 lmp.py:1625]   Expert  7 |    133 | CPU
DEBUG 01-14 20:42:31.854570.854570 lmp.py:1625]   Expert 26 |    135 | CPU
DEBUG 01-14 20:42:31.854305.854305 lmp.py:1625]   Expert  9 |    138 | CPU
DEBUG 01-14 20:42:31.854756.854756 lmp.py:1625]   Expert 30 |    141 | CPU
DEBUG 01-14 20:42:31.854207.854207 lmp.py:1625]   Expert 57 |    142 | CPU
DEBUG 01-14 20:42:31.854181.854181 lmp.py:1625]   Expert 62 |    145 | CPU
DEBUG 01-14 20:42:31.854632.854632 lmp.py:1625]   Expert 45 |    146 | CPU
DEBUG 01-14 20:42:31.854606.854606 lmp.py:1625]   Expert  1 |    150 | CPU
DEBUG 01-14 20:42:31.854580.854580 lmp.py:1625]   Expert  6 |    154 | CPU
DEBUG 01-14 20:42:31.854077.854077 lmp.py:1625]   Expert 48 |    157 | CPU
DEBUG 01-14 20:42:31.854290.854290 lmp.py:1625]   Expert  8 |    162 | CPU
DEBUG 01-14 20:42:31.854264.854264 lmp.py:1625]   Expert 54 |    163 | CPU
DEBUG 01-14 20:42:31.854999.854999 lmp.py:1625]   Expert 25 |    166 | CPU
DEBUG 01-14 20:42:31.854735.854735 lmp.py:1625]   Expert 49 |    168 | CPU
DEBUG 01-14 20:42:31.854424.854424 lmp.py:1625]   Expert 29 |    172 | CPU
DEBUG 01-14 20:42:31.854114.854114 lmp.py:1625]   Expert 35 |    173 | CPU
DEBUG 01-14 20:42:31.854326.854326 lmp.py:1625]   Expert 36 |    173 | CPU
DEBUG 01-14 20:42:31.854300.854300 lmp.py:1625]   Expert 12 |    176 | CPU
DEBUG 01-14 20:42:31.854036.854036 lmp.py:1625]   Expert 37 |    186 | CPU
DEBUG 01-14 20:42:31.854010.854010 lmp.py:1625]   Expert 53 |    186 | CPU
DEBUG 01-14 20:42:31.854507.854507 lmp.py:1625]   Expert 13 |    188 | GPU
DEBUG 01-14 20:42:31.854388.854388 lmp.py:1625]   Expert 33 |    190 | GPU
DEBUG 01-14 20:42:31.854793.854793 lmp.py:1625]   Expert 60 |    190 | GPU
DEBUG 01-14 20:42:31.854482.854482 lmp.py:1625]   Expert 16 |    195 | GPU
DEBUG 01-14 20:42:31.854410.854410 lmp.py:1625]   Expert 40 |    200 | GPU
DEBUG 01-14 20:42:31.854338.854338 lmp.py:1625]   Expert 21 |    201 | GPU
DEBUG 01-14 20:42:31.854742.854742 lmp.py:1625]   Expert 38 |    202 | GPU
DEBUG 01-14 20:42:31.854908.854908 lmp.py:1625]   Expert 19 |    208 | GPU
DEBUG 01-14 20:42:31.854598.854598 lmp.py:1625]   Expert  5 |    209 | GPU
DEBUG 01-14 20:42:31.854525.854525 lmp.py:1625]   Expert 41 |    213 | GPU
DEBUG 01-14 20:42:31.854976.854976 lmp.py:1625]   Expert 43 |    214 | GPU
DEBUG 01-14 20:42:31.854904.854904 lmp.py:1625]   Expert 10 |    215 | GPU
DEBUG 01-14 20:42:31.854593.854593 lmp.py:1625]   Expert 52 |    217 | GPU
DEBUG 01-14 20:42:31.854283.854283 lmp.py:1625]   Expert 50 |    219 | GPU
DEBUG 01-14 20:42:31.854972.854972 lmp.py:1625]   Expert 44 |    220 | GPU
DEBUG 01-14 20:42:31.854376.854376 lmp.py:1625]   Expert  4 |    221 | GPU
DEBUG 01-14 20:42:31.854781.854781 lmp.py:1625]   Expert 56 |    227 | GPU
DEBUG 01-14 20:42:31.854709.854709 lmp.py:1625]   Expert 59 |    230 | GPU
DEBUG 01-14 20:42:31.854921.854921 lmp.py:1625]   Expert 55 |    234 | GPU
DEBUG 01-14 20:42:31.854610.854610 lmp.py:1625]   Expert 31 |    245 | GPU
DEBUG 01-14 20:42:31.854300.854300 lmp.py:1625]   Expert 39 |    246 | GPU
DEBUG 01-14 20:42:31.854751.854751 lmp.py:1625]   Expert 22 |    255 | GPU
DEBUG 01-14 20:42:31.854963.854963 lmp.py:1625]   Expert 20 |    261 | GPU
DEBUG 01-14 20:42:31.854652.854652 lmp.py:1625]   Expert  2 |    265 | GPU
DEBUG 01-14 20:42:31.854580.854580 lmp.py:1625]   Expert 63 |    279 | GPU
DEBUG 01-14 20:42:31.854031.854031 lmp.py:1625]   Expert 47 |    284 | GPU
DEBUG 01-14 20:42:31.854482.854482 lmp.py:1625]   Expert 18 |    304 | GPU
DEBUG 01-14 20:42:31.855171.855171 lmp.py:1625]   Expert 14 |    311 | GPU
DEBUG 01-14 20:42:31.855576.855576 lmp.py:1625]   Expert 42 |    320 | GPU
DEBUG 01-14 20:42:31.855325.855325 lmp.py:1625]   Expert 46 |    371 | GPU
DEBUG 01-14 20:42:31.855537.855537 lmp.py:1625]   Expert 11 |    376 | GPU
DEBUG 01-14 20:42:31.855273.855273 lmp.py:1625]   Expert 61 |    435 | GPU
DEBUG 01-14 20:42:31.855962.855962 lmp.py:1626] 
DEBUG 01-14 20:42:31.855962.855962 lmp.py:1626]   CPU total tokens: 4343 (35.3%)
DEBUG 01-14 20:42:31.855890.855890 lmp.py:1627]   GPU total tokens: 7945 (64.7%)
DEBUG 01-14 20:42:31.855348.855348 cuda_h.py:19] end experts_map_get cost 0.0015149116516113281 seconds
DEBUG 01-14 20:42:31.855767.855767 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-14 20:42:31.855325.855325 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-14 20:42:31.855039.855039 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-14 20:42:31.856764.856764 cuda_h.py:19] end allocate_cuda_memory cost 0.0010638236999511719 seconds
DEBUG 01-14 20:42:31.856290.856290 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-14 20:42:31.856522.856522 sllm_store_c.py:27] get device uuid map
DEBUG 01-14 20:42:31.856332.856332 sllm_store_c.py:29] call client load into gpu
DEBUG 01-14 20:42:31.856935.856935 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 1da71190-03ad-4823-9df1-e8fd30b06bc2
DEBUG 01-14 20:42:31.856994.856994 client.py:106] call stub.LoadModelAsync
INFO 01-14 20:42:31.859228.859228 client.py:127] Model loaded
DEBUG 01-14 20:42:31.859967.859967 cuda_h.py:10] start restore2model
DEBUG 01-14 20:42:31.860744.860744 cuda_h.py:19] end restore2model cost 0.0006005764007568359 seconds
DEBUG 01-14 20:42:31.860912.860912 cuda_h.py:19] end sllm_worker_task cost 0.011499643325805664 seconds
INFO 01-14 20:42:31.860540.860540 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 1da71190-03ad-4823-9df1-e8fd30b06bc2
DEBUG 01-14 20:42:31.860198.860198 cuda_h.py:19] end load_into_gpu_async cost 0.004146099090576172 seconds
DEBUG 01-14 20:42:31.860570.860570 cuda_h.py:10] start restore_tensors2
DEBUG 01-14 20:42:31.861159.861159 cuda_h.py:19] end restore_tensors2 cost 0.00037217140197753906 seconds
DEBUG 01-14 20:42:31.861618.861618 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.005950450897216797 seconds
DEBUG 01-14 20:42:31.861573.861573 cuda_h.py:10] start restore2model
DEBUG 01-14 20:42:31.863895.863895 cuda_h.py:19] end restore2model cost 0.0026612281799316406 seconds
DEBUG 01-14 20:42:31.864506.864506 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.00880289077758789 seconds
DEBUG 01-14 20:42:31.864064.864064 cuda_h.py:10] start gpu_sexperts
DEBUG 01-14 20:42:31.864464.864464 cuda_h.py:19] end gpu_sexperts cost 0.0002646446228027344 seconds
DEBUG 01-14 20:42:31.864990.864990 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-14 20:42:31.864746.864746 lmp.py:1683] 
DEBUG 01-14 20:42:31.864746.864746 lmp.py:1683]   Computing 32 experts on CPU...
DEBUG 01-14 20:42:31.864635.864635 cuda_h.py:19] end cpu_experts_submit cost 6.031990051269531e-05 seconds
DEBUG 01-14 20:42:31.864338.864338 cuda_h.py:10] start experts_func_mgpu_group_pad
DEBUG 01-14 20:42:31.870561.870561 mlpmodule.py:1460] group tensors cost 0.005830287933349609 s
DEBUG 01-14 20:42:31.871174.871174 cuda_h.py:10] start move_flat_hidden2cpu
DEBUG 01-14 20:42:31.876898.876898 cuda_h.py:19] end experts_func_mgpu_group_pad cost 0.011685371398925781 seconds
DEBUG 01-14 20:42:31.879677.879677 cuda_h.py:19] end move_flat_hidden2cpu cost 0.007428407669067383 seconds
DEBUG 01-14 20:42:31.879817.879817 cuda_h.py:10] start gpu_group_list
DEBUG 01-14 20:42:31.880034.880034 cuda_h.py:19] end gpu_group_list cost 0.0007424354553222656 seconds
DEBUG 01-14 20:42:31.880025.880025 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-14 20:42:31.880254.880254 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 3.0040740966796875e-05 seconds
DEBUG 01-14 20:42:31.880714.880714 cuda_h.py:10] start wait_experts
INFO 01-14 20:42:31.880696.880696 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 1da71190-03ad-4823-9df1-e8fd30b06bc2
DEBUG 01-14 20:42:31.882697.882697 mlpmodule.py:1533] pad cost 0.003003358840942383 s
DEBUG 01-14 20:42:31.882767.882767 mlpmodule.py:1539] create cpu tensor cost 3.695487976074219e-05 s
DEBUG 01-14 20:42:31.884902.884902 mlpmodule.py:1544] move to cpu cost 0.0022034645080566406 s
DEBUG 01-14 20:42:31.894312.894312 mlpmodule.py:1558] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-14 20:42:31.894582.894582 mlpmodule.py:1559] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-14 20:42:31.894837.894837 mlpmodule.py:1564] group_w3 first element: -0.0380859375
WARNING 01-14 20:42:31.894370.894370 mlpmodule.py:1574] start einsum2
DEBUG 01-14 20:42:31.913277.913277 mlpmodule.py:1584] group einsum cost 0.02913355827331543 s
DEBUG 01-14 20:42:31.914370.914370 mlpmodule.py:1593] cpy2cputensor cost 0.0007865428924560547 s
DEBUG 01-14 20:42:31.914769.914769 cuda_h.py:10] start move_outputs
INFO 01-14 20:42:31.917354.917354 client.py:127] Model loaded
DEBUG 01-14 20:42:31.917367.917367 cuda_h.py:19] end move_outputs cost 0.002393960952758789 seconds
DEBUG 01-14 20:42:31.917398.917398 cuda_h.py:19] end wait_experts cost 0.03654956817626953 seconds
DEBUG 01-14 20:42:31.917338.917338 cuda_h.py:10] start gpu_experts
DEBUG 01-14 20:42:31.917360.917360 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-14 20:42:31.921251.921251 cuda_h.py:19] end wait_cetm_experts cost 0.00342559814453125 seconds
DEBUG 01-14 20:42:31.921320.921320 cuda_h.py:10] start gpu_group_einsum_mp_multi_list
DEBUG 01-14 20:42:31.921652.921652 cuda_h.py:10] start gpu_group_tensor
DEBUG 01-14 20:42:31.921324.921324 cuda_h.py:19] end gpu_group_tensor cost 0.0002529621124267578 seconds
DEBUG 01-14 20:42:31.921295.921295 cuda_h.py:10] start gpu_group_einsum
DEBUG 01-14 20:42:31.936744.936744 mlpmodule.py:1367]  experts func einsum cost 0.07105016708374023 s
DEBUG 01-14 20:42:31.936742.936742 cuda_h.py:19] end gpu_group_einsum cost 0.014491558074951172 seconds
DEBUG 01-14 20:42:31.936286.936286 cuda_h.py:10] start gpu_final_hidden_states_scatter
DEBUG 01-14 20:42:31.936906.936906 cuda_h.py:10] start all_expert_outputs_slices
DEBUG 01-14 20:42:31.936736.936736 cuda_h.py:19] end all_expert_outputs_slices cost 0.00022912025451660156 seconds
DEBUG 01-14 20:42:31.936061.936061 cuda_h.py:10] start concat_expert_out
DEBUG 01-14 20:42:31.936852.936852 cuda_h.py:19] end concat_expert_out cost 5.888938903808594e-05 seconds
DEBUG 01-14 20:42:31.936318.936318 cuda_h.py:10] start index_scatter
DEBUG 01-14 20:42:31.937500.937500 cuda_h.py:19] end index_scatter cost 6.699562072753906e-05 seconds
DEBUG 01-14 20:42:31.937971.937971 cuda_h.py:19] end gpu_final_hidden_states_scatter cost 0.0005924701690673828 seconds
DEBUG 01-14 20:42:31.937312.937312 cuda_h.py:19] end gpu_experts cost 0.01953864097595215 seconds
DEBUG 01-14 20:42:31.937915.937915 cuda_h.py:10] start all_expert_weight_slices
DEBUG 01-14 20:42:31.937048.937048 cuda_h.py:19] end all_expert_weight_slices cost 0.0007724761962890625 seconds
DEBUG 01-14 20:42:31.938460.938460 cuda_h.py:10] start cpuoutputsdeal
DEBUG 01-14 20:42:31.938409.938409 cuda_h.py:10] start index_scatter
DEBUG 01-14 20:42:31.938996.938996 cuda_h.py:19] end index_scatter cost 5.745887756347656e-05 seconds
DEBUG 01-14 20:42:31.938819.938819 cuda_h.py:19] end cpuoutputsdeal cost 0.0005815029144287109 seconds
DEBUG 01-14 20:42:31.938279.938279 cuda_h.py:19] end layer_moe_generate_mp_l_3 cost 0.08585286140441895 seconds
DEBUG 01-14 20:42:31.939047.939047 cuda_h.py:19] end prefill_layer cost 0.09096598625183105 seconds
DEBUG 01-14 20:42:31.939341.939341 lmp.py:1551] -------------------------------- end prefill layer 2 --------------------------------
DEBUG 01-14 20:42:31.939574.939574 cuda_h.py:10] start prefill_layer
DEBUG 01-14 20:42:31.939899.939899 lmp.py:1494] -------------------------------- start prefill layer 3 --------------------------------
DEBUG 01-14 20:42:31.939940.939940 cuda_h.py:10] start start_load_qkvogn_s_weight_l_4
DEBUG 01-14 20:42:31.939603.939603 cuda_h.py:10] start start_load_qkvogn_s_weight_l_4
DEBUG 01-14 20:42:31.939745.939745 cuda_h.py:19] end start_load_qkvogn_s_weight_l_4 cost 3.886222839355469e-05 seconds
DEBUG 01-14 20:42:31.939362.939362 cuda_h.py:19] end start_load_qkvogn_s_weight_l_4 cost 7.534027099609375e-05 seconds
DEBUG 01-14 20:42:31.939410.939410 cuda_h.py:10] start sllm_worker_task
DEBUG 01-14 20:42:31.939591.939591 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-14 20:42:31.939105.939105 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-14 20:42:31.939797.939797 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-14 20:42:31.940038.940038 cuda_h.py:19] end allocate_cuda_memory cost 0.00019979476928710938 seconds
DEBUG 01-14 20:42:31.940286.940286 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-14 20:42:31.940606.940606 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-14 20:42:31.940385.940385 sllm_store_c.py:27] get device uuid map
DEBUG 01-14 20:42:31.940321.940321 sllm_store_c.py:29] call client load into gpu
DEBUG 01-14 20:42:31.940442.940442 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, bda912ef-63da-4e2c-b494-e4898bb208f3
DEBUG 01-14 20:42:31.940247.940247 client.py:106] call stub.LoadModelAsync
DEBUG 01-14 20:42:31.940384.940384 cuda_h.py:10] start self_attn
INFO 01-14 20:42:31.941421.941421 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, bda912ef-63da-4e2c-b494-e4898bb208f3
DEBUG 01-14 20:42:31.942655.942655 cuda_h.py:19] end load_into_gpu_async cost 0.001745462417602539 seconds
DEBUG 01-14 20:42:31.942272.942272 cuda_h.py:10] start restore_tensors2
DEBUG 01-14 20:42:31.942005.942005 cuda_h.py:19] end restore_tensors2 cost 8.273124694824219e-05 seconds
DEBUG 01-14 20:42:31.942344.942344 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0025014877319335938 seconds
INFO 01-14 20:42:31.942286.942286 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, bda912ef-63da-4e2c-b494-e4898bb208f3
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-14 20:42:31.944414.944414 cuda_h.py:19] end self_attn cost 0.003385782241821289 seconds
DEBUG 01-14 20:42:31.944268.944268 cuda_h.py:19] end iln_self_attn_paln cost 0.005006074905395508 seconds
DEBUG 01-14 20:42:31.944747.944747 cuda_h.py:10] start layer_moe_generate_mp_l_4
DEBUG 01-14 20:42:31.944047.944047 cuda_h.py:10] start gate
DEBUG 01-14 20:42:31.945701.945701 cuda_h.py:19] end gate cost 0.0007190704345703125 seconds
DEBUG 01-14 20:42:31.945697.945697 cuda_h.py:10] start experts_map_get
DEBUG 01-14 20:42:31.946849.946849 lmp.py:1615] 
DEBUG 01-14 20:42:31.946849.946849 lmp.py:1615] Expert Token Distribution & Device Allocation:
DEBUG 01-14 20:42:31.946380.946380 lmp.py:1616]   Total experts: 64
DEBUG 01-14 20:42:31.946659.946659 lmp.py:1617]   CPU experts: 32 (50%)
DEBUG 01-14 20:42:31.946124.946124 lmp.py:1618]   GPU experts: 32 (50%)
DEBUG 01-14 20:42:31.946204.946204 lmp.py:1619] 
DEBUG 01-14 20:42:31.946204.946204 lmp.py:1619]   Expert ID | Tokens | Device
DEBUG 01-14 20:42:31.946523.946523 lmp.py:1620]   -----------------------------------
DEBUG 01-14 20:42:31.946080.946080 lmp.py:1625]   Expert  1 |     55 | CPU
DEBUG 01-14 20:42:31.946922.946922 lmp.py:1625]   Expert 27 |     59 | CPU
DEBUG 01-14 20:42:31.946572.946572 lmp.py:1625]   Expert 48 |     81 | CPU
DEBUG 01-14 20:42:31.946221.946221 lmp.py:1625]   Expert  7 |     86 | CPU
DEBUG 01-14 20:42:31.946394.946394 lmp.py:1625]   Expert 30 |    100 | CPU
DEBUG 01-14 20:42:31.946329.946329 lmp.py:1625]   Expert 15 |    102 | CPU
DEBUG 01-14 20:42:31.946217.946217 lmp.py:1625]   Expert 32 |    114 | CPU
DEBUG 01-14 20:42:31.946344.946344 lmp.py:1625]   Expert 61 |    115 | CPU
DEBUG 01-14 20:42:31.946709.946709 lmp.py:1625]   Expert 39 |    116 | CPU
DEBUG 01-14 20:42:31.946405.946405 lmp.py:1625]   Expert 18 |    118 | CPU
DEBUG 01-14 20:42:31.946101.946101 lmp.py:1625]   Expert 45 |    135 | CPU
DEBUG 01-14 20:42:31.946797.946797 lmp.py:1625]   Expert 34 |    137 | CPU
DEBUG 01-14 20:42:31.946731.946731 lmp.py:1625]   Expert 59 |    138 | CPU
DEBUG 01-14 20:42:31.946189.946189 lmp.py:1625]   Expert 11 |    144 | CPU
DEBUG 01-14 20:42:31.946362.946362 lmp.py:1625]   Expert 36 |    145 | CPU
DEBUG 01-14 20:42:31.946727.946727 lmp.py:1625]   Expert 26 |    147 | CPU
DEBUG 01-14 20:42:31.946662.946662 lmp.py:1625]   Expert  9 |    150 | CPU
DEBUG 01-14 20:42:31.946119.946119 lmp.py:1625]   Expert 23 |    151 | CPU
DEBUG 01-14 20:42:31.946815.946815 lmp.py:1625]   Expert 49 |    151 | CPU
DEBUG 01-14 20:42:31.946273.946273 lmp.py:1625]   Expert  5 |    153 | CPU
DEBUG 01-14 20:42:31.946969.946969 lmp.py:1625]   Expert  6 |    153 | CPU
DEBUG 01-14 20:42:31.946665.946665 lmp.py:1625]   Expert 51 |    153 | CPU
DEBUG 01-14 20:42:31.946792.946792 lmp.py:1625]   Expert  2 |    161 | CPU
DEBUG 01-14 20:42:31.946634.946634 lmp.py:1625]   Expert 50 |    165 | CPU
DEBUG 01-14 20:42:31.946999.946999 lmp.py:1625]   Expert 16 |    166 | CPU
DEBUG 01-14 20:42:31.946887.946887 lmp.py:1625]   Expert 40 |    166 | CPU
DEBUG 01-14 20:42:31.946537.946537 lmp.py:1625]   Expert 56 |    169 | CPU
DEBUG 01-14 20:42:31.946948.946948 lmp.py:1625]   Expert  4 |    170 | CPU
DEBUG 01-14 20:42:31.946598.946598 lmp.py:1625]   Expert 52 |    177 | CPU
DEBUG 01-14 20:42:31.946771.946771 lmp.py:1625]   Expert 17 |    184 | CPU
DEBUG 01-14 20:42:31.946420.946420 lmp.py:1625]   Expert 44 |    184 | CPU
DEBUG 01-14 20:42:31.946024.946024 lmp.py:1625]   Expert 35 |    187 | CPU
DEBUG 01-14 20:42:31.946342.946342 lmp.py:1625]   Expert 37 |    187 | GPU
DEBUG 01-14 20:42:31.946469.946469 lmp.py:1625]   Expert 38 |    193 | GPU
DEBUG 01-14 20:42:31.946357.946357 lmp.py:1625]   Expert 42 |    195 | GPU
DEBUG 01-14 20:42:31.947769.947769 lmp.py:1625]   Expert 13 |    202 | GPU
DEBUG 01-14 20:42:31.947372.947372 lmp.py:1625]   Expert 21 |    206 | GPU
DEBUG 01-14 20:42:31.947214.947214 lmp.py:1625]   Expert  3 |    207 | GPU
DEBUG 01-14 20:42:31.947864.947864 lmp.py:1625]   Expert 28 |    209 | GPU
DEBUG 01-14 20:42:31.947513.947513 lmp.py:1625]   Expert 53 |    210 | GPU
DEBUG 01-14 20:42:31.947925.947925 lmp.py:1625]   Expert 10 |    213 | GPU
DEBUG 01-14 20:42:31.947767.947767 lmp.py:1625]   Expert 20 |    215 | GPU
DEBUG 01-14 20:42:31.947609.947609 lmp.py:1625]   Expert 47 |    216 | GPU
DEBUG 01-14 20:42:31.947497.947497 lmp.py:1625]   Expert 58 |    216 | GPU
DEBUG 01-14 20:42:31.947623.947623 lmp.py:1625]   Expert 19 |    223 | GPU
DEBUG 01-14 20:42:31.947273.947273 lmp.py:1625]   Expert 33 |    224 | GPU
DEBUG 01-14 20:42:31.947684.947684 lmp.py:1625]   Expert  8 |    226 | GPU
DEBUG 01-14 20:42:31.947334.947334 lmp.py:1625]   Expert 55 |    226 | GPU
DEBUG 01-14 20:42:31.947176.947176 lmp.py:1625]   Expert 60 |    229 | GPU
DEBUG 01-14 20:42:31.947779.947779 lmp.py:1625]   Expert 31 |    230 | GPU
DEBUG 01-14 20:42:31.947668.947668 lmp.py:1625]   Expert 57 |    233 | GPU
DEBUG 01-14 20:42:31.947841.947841 lmp.py:1625]   Expert 46 |    236 | GPU
DEBUG 01-14 20:42:31.947967.947967 lmp.py:1625]   Expert 62 |    240 | GPU
DEBUG 01-14 20:42:31.947855.947855 lmp.py:1625]   Expert 24 |    243 | GPU
DEBUG 01-14 20:42:31.947982.947982 lmp.py:1625]   Expert 63 |    251 | GPU
DEBUG 01-14 20:42:31.947585.947585 lmp.py:1625]   Expert 14 |    256 | GPU
DEBUG 01-14 20:42:31.947666.947666 lmp.py:1625]   Expert 12 |    261 | GPU
DEBUG 01-14 20:42:31.947554.947554 lmp.py:1625]   Expert 22 |    273 | GPU
DEBUG 01-14 20:42:31.947965.947965 lmp.py:1625]   Expert 43 |    289 | GPU
DEBUG 01-14 20:42:31.947377.947377 lmp.py:1625]   Expert 29 |    296 | GPU
DEBUG 01-14 20:42:31.947265.947265 lmp.py:1625]   Expert  0 |    309 | GPU
DEBUG 01-14 20:42:31.947915.947915 lmp.py:1625]   Expert 54 |    340 | GPU
DEBUG 01-14 20:42:31.947756.947756 lmp.py:1625]   Expert 41 |    387 | GPU
DEBUG 01-14 20:42:31.947406.947406 lmp.py:1625]   Expert 25 |    415 | GPU
DEBUG 01-14 20:42:31.947486.947486 lmp.py:1626] 
DEBUG 01-14 20:42:31.947486.947486 lmp.py:1626]   CPU total tokens: 4432 (36.1%)
DEBUG 01-14 20:42:31.947567.947567 lmp.py:1627]   GPU total tokens: 7856 (63.9%)
DEBUG 01-14 20:42:31.947177.947177 cuda_h.py:19] end experts_map_get cost 0.002037525177001953 seconds
DEBUG 01-14 20:42:31.947332.947332 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-14 20:42:31.947718.947718 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-14 20:42:31.948385.948385 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-14 20:42:31.949829.949829 cuda_h.py:19] end allocate_cuda_memory cost 0.0011360645294189453 seconds
DEBUG 01-14 20:42:31.949533.949533 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-14 20:42:31.949103.949103 sllm_store_c.py:27] get device uuid map
DEBUG 01-14 20:42:31.949912.949912 sllm_store_c.py:29] call client load into gpu
DEBUG 01-14 20:42:31.949324.949324 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 40f077de-372c-442b-9443-b938ca489486
DEBUG 01-14 20:42:31.949045.949045 client.py:106] call stub.LoadModelAsync
INFO 01-14 20:42:31.949819.949819 client.py:127] Model loaded
DEBUG 01-14 20:42:31.949397.949397 cuda_h.py:10] start restore2model
DEBUG 01-14 20:42:31.950902.950902 cuda_h.py:19] end restore2model cost 0.0005624294281005859 seconds
DEBUG 01-14 20:42:31.950990.950990 cuda_h.py:19] end sllm_worker_task cost 0.011022567749023438 seconds
INFO 01-14 20:42:31.951274.951274 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 40f077de-372c-442b-9443-b938ca489486
DEBUG 01-14 20:42:31.951948.951948 cuda_h.py:19] end load_into_gpu_async cost 0.002465486526489258 seconds
DEBUG 01-14 20:42:31.951103.951103 cuda_h.py:10] start restore_tensors2
DEBUG 01-14 20:42:31.952729.952729 cuda_h.py:19] end restore_tensors2 cost 0.00043082237243652344 seconds
DEBUG 01-14 20:42:31.952394.952394 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.004511356353759766 seconds
DEBUG 01-14 20:42:31.952017.952017 cuda_h.py:10] start restore2model
DEBUG 01-14 20:42:31.955444.955444 cuda_h.py:19] end restore2model cost 0.002638101577758789 seconds
DEBUG 01-14 20:42:31.955433.955433 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.007334470748901367 seconds
DEBUG 01-14 20:42:31.955990.955990 cuda_h.py:10] start gpu_sexperts
DEBUG 01-14 20:42:31.955206.955206 cuda_h.py:19] end gpu_sexperts cost 0.0002694129943847656 seconds
DEBUG 01-14 20:42:31.955241.955241 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-14 20:42:31.955136.955136 lmp.py:1683] 
DEBUG 01-14 20:42:31.955136.955136 lmp.py:1683]   Computing 32 experts on CPU...
DEBUG 01-14 20:42:31.955257.955257 cuda_h.py:19] end cpu_experts_submit cost 5.3882598876953125e-05 seconds
DEBUG 01-14 20:42:31.955576.955576 cuda_h.py:10] start experts_func_mgpu_group_pad
DEBUG 01-14 20:42:31.966438.966438 mlpmodule.py:1460] group tensors cost 0.010233163833618164 s
DEBUG 01-14 20:42:31.967053.967053 cuda_h.py:10] start move_flat_hidden2cpu
DEBUG 01-14 20:42:31.970585.970585 cuda_h.py:19] end experts_func_mgpu_group_pad cost 0.01487588882446289 seconds
DEBUG 01-14 20:42:31.972552.972552 cuda_h.py:10] start gpu_group_list
DEBUG 01-14 20:42:31.973506.973506 cuda_h.py:19] end gpu_group_list cost 0.0007002353668212891 seconds
DEBUG 01-14 20:42:31.974529.974529 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-14 20:42:31.974124.974124 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 3.838539123535156e-05 seconds
DEBUG 01-14 20:42:31.974821.974821 cuda_h.py:10] start wait_experts
INFO 01-14 20:42:31.974273.974273 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 40f077de-372c-442b-9443-b938ca489486
DEBUG 01-14 20:42:31.975499.975499 cuda_h.py:19] end move_flat_hidden2cpu cost 0.008130311965942383 seconds
DEBUG 01-14 20:42:31.977482.977482 mlpmodule.py:1533] pad cost 0.0015642642974853516 s
DEBUG 01-14 20:42:31.977618.977618 mlpmodule.py:1539] create cpu tensor cost 3.5762786865234375e-05 s
DEBUG 01-14 20:42:31.979230.979230 mlpmodule.py:1544] move to cpu cost 0.0022058486938476562 s
DEBUG 01-14 20:42:31.989965.989965 mlpmodule.py:1558] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-14 20:42:31.989712.989712 mlpmodule.py:1559] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-14 20:42:31.989794.989794 mlpmodule.py:1564] group_w3 first element: -0.054931640625
WARNING 01-14 20:42:31.989779.989779 mlpmodule.py:1574] start einsum2
INFO 01-14 20:42:32.007866.007866 client.py:127] Model loaded
DEBUG 01-14 20:42:32.007031.007031 cuda_h.py:19] end wait_experts cost 0.03330254554748535 seconds
DEBUG 01-14 20:42:32.007894.007894 cuda_h.py:10] start gpu_experts
DEBUG 01-14 20:42:32.007809.007809 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-14 20:42:32.008967.008967 mlpmodule.py:1584] group einsum cost 0.028878211975097656 s
DEBUG 01-14 20:42:32.009443.009443 mlpmodule.py:1593] cpy2cputensor cost 0.0007429122924804688 s
DEBUG 01-14 20:42:32.009358.009358 cuda_h.py:10] start move_outputs
DEBUG 01-14 20:42:32.011550.011550 cuda_h.py:19] end move_outputs cost 0.002147197723388672 seconds
DEBUG 01-14 20:42:32.015130.015130 cuda_h.py:19] end wait_cetm_experts cost 0.007339954376220703 seconds
DEBUG 01-14 20:42:32.015241.015241 cuda_h.py:10] start gpu_group_einsum_mp_multi_list
DEBUG 01-14 20:42:32.015249.015249 cuda_h.py:10] start gpu_group_tensor
DEBUG 01-14 20:42:32.015867.015867 cuda_h.py:19] end gpu_group_tensor cost 0.000247955322265625 seconds
DEBUG 01-14 20:42:32.015553.015553 cuda_h.py:10] start gpu_group_einsum
DEBUG 01-14 20:42:32.016389.016389 cuda_h.py:19] end gpu_group_einsum cost 0.0005650520324707031 seconds
DEBUG 01-14 20:42:32.016077.016077 cuda_h.py:10] start gpu_final_hidden_states_scatter
DEBUG 01-14 20:42:32.016298.016298 cuda_h.py:10] start all_expert_outputs_slices
DEBUG 01-14 20:42:32.016031.016031 cuda_h.py:19] end all_expert_outputs_slices cost 0.00028705596923828125 seconds
DEBUG 01-14 20:42:32.016025.016025 cuda_h.py:10] start concat_expert_out
DEBUG 01-14 20:42:32.025264.025264 cuda_h.py:19] end concat_expert_out cost 0.008282184600830078 seconds
DEBUG 01-14 20:42:32.025361.025361 cuda_h.py:10] start index_scatter
DEBUG 01-14 20:42:32.025160.025160 cuda_h.py:19] end index_scatter cost 8.559226989746094e-05 seconds
DEBUG 01-14 20:42:32.025639.025639 cuda_h.py:19] end gpu_final_hidden_states_scatter cost 0.009009838104248047 seconds
DEBUG 01-14 20:42:32.025555.025555 cuda_h.py:19] end gpu_experts cost 0.01794600486755371 seconds
DEBUG 01-14 20:42:32.025443.025443 cuda_h.py:10] start all_expert_weight_slices
DEBUG 01-14 20:42:32.026908.026908 cuda_h.py:19] end all_expert_weight_slices cost 0.0008070468902587891 seconds
DEBUG 01-14 20:42:32.026592.026592 cuda_h.py:10] start cpuoutputsdeal
DEBUG 01-14 20:42:32.026981.026981 cuda_h.py:10] start index_scatter
DEBUG 01-14 20:42:32.027918.027918 cuda_h.py:19] end index_scatter cost 4.649162292480469e-05 seconds
DEBUG 01-14 20:42:32.027920.027920 cuda_h.py:19] end cpuoutputsdeal cost 0.00046181678771972656 seconds
DEBUG 01-14 20:42:32.027107.027107 cuda_h.py:19] end layer_moe_generate_mp_l_4 cost 0.08231973648071289 seconds
DEBUG 01-14 20:42:32.027363.027363 cuda_h.py:19] end prefill_layer cost 0.0882258415222168 seconds
DEBUG 01-14 20:42:32.027313.027313 lmp.py:1551] -------------------------------- end prefill layer 3 --------------------------------
DEBUG 01-14 20:42:32.027393.027393 cuda_h.py:10] start prefill_layer
DEBUG 01-14 20:42:32.027235.027235 lmp.py:1494] -------------------------------- start prefill layer 4 --------------------------------
DEBUG 01-14 20:42:32.027838.027838 cuda_h.py:10] start start_load_qkvogn_s_weight_l_5
DEBUG 01-14 20:42:32.027349.027349 cuda_h.py:10] start start_load_qkvogn_s_weight_l_5
DEBUG 01-14 20:42:32.027993.027993 cuda_h.py:19] end start_load_qkvogn_s_weight_l_5 cost 3.0040740966796875e-05 seconds
DEBUG 01-14 20:42:32.027312.027312 cuda_h.py:19] end start_load_qkvogn_s_weight_l_5 cost 5.7220458984375e-05 seconds
DEBUG 01-14 20:42:32.027147.027147 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-14 20:42:32.027513.027513 cuda_h.py:10] start sllm_worker_task
DEBUG 01-14 20:42:32.027273.027273 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-14 20:42:32.027950.027950 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-14 20:42:32.028735.028735 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-14 20:42:32.030798.030798 cuda_h.py:19] end allocate_cuda_memory cost 0.002814769744873047 seconds
DEBUG 01-14 20:42:32.031543.031543 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-14 20:42:32.031643.031643 sllm_store_c.py:27] get device uuid map
DEBUG 01-14 20:42:32.031426.031426 sllm_store_c.py:29] call client load into gpu
DEBUG 01-14 20:42:32.031560.031560 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 0e8250cf-69f7-4ad5-9a75-8a390867c035
DEBUG 01-14 20:42:32.031788.031788 client.py:106] call stub.LoadModelAsync
DEBUG 01-14 20:42:32.031384.031384 mlpmodule.py:1367]  experts func einsum cost 0.0753164291381836 s
DEBUG 01-14 20:42:32.031150.031150 cuda_h.py:10] start self_attn
INFO 01-14 20:42:32.032198.032198 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 0e8250cf-69f7-4ad5-9a75-8a390867c035
DEBUG 01-14 20:42:32.032115.032115 cuda_h.py:19] end load_into_gpu_async cost 0.0018208026885986328 seconds
DEBUG 01-14 20:42:32.032540.032540 cuda_h.py:10] start restore_tensors2
DEBUG 01-14 20:42:32.033775.033775 cuda_h.py:19] end restore_tensors2 cost 7.224082946777344e-05 seconds
DEBUG 01-14 20:42:32.033200.033200 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.004999399185180664 seconds
INFO 01-14 20:42:32.033029.033029 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 0e8250cf-69f7-4ad5-9a75-8a390867c035
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-14 20:42:32.034398.034398 cuda_h.py:19] end self_attn cost 0.0029556751251220703 seconds
DEBUG 01-14 20:42:32.035799.035799 cuda_h.py:19] end iln_self_attn_paln cost 0.007368564605712891 seconds
DEBUG 01-14 20:42:32.035403.035403 cuda_h.py:10] start layer_moe_generate_mp_l_5
DEBUG 01-14 20:42:32.035974.035974 cuda_h.py:10] start gate
DEBUG 01-14 20:42:32.035625.035625 cuda_h.py:19] end gate cost 0.0006213188171386719 seconds
DEBUG 01-14 20:42:32.035931.035931 cuda_h.py:10] start experts_map_get
DEBUG 01-14 20:42:32.036677.036677 lmp.py:1615] 
DEBUG 01-14 20:42:32.036677.036677 lmp.py:1615] Expert Token Distribution & Device Allocation:
DEBUG 01-14 20:42:32.036963.036963 lmp.py:1616]   Total experts: 64
DEBUG 01-14 20:42:32.036804.036804 lmp.py:1617]   CPU experts: 32 (50%)
DEBUG 01-14 20:42:32.036832.036832 lmp.py:1618]   GPU experts: 32 (50%)
DEBUG 01-14 20:42:32.036475.036475 lmp.py:1619] 
DEBUG 01-14 20:42:32.036475.036475 lmp.py:1619]   Expert ID | Tokens | Device
DEBUG 01-14 20:42:32.036071.036071 lmp.py:1620]   -----------------------------------
DEBUG 01-14 20:42:32.036145.036145 lmp.py:1625]   Expert 14 |     69 | CPU
DEBUG 01-14 20:42:32.036040.036040 lmp.py:1625]   Expert 13 |     71 | CPU
DEBUG 01-14 20:42:32.036921.036921 lmp.py:1625]   Expert 57 |     77 | CPU
DEBUG 01-14 20:42:32.036326.036326 lmp.py:1625]   Expert 11 |     83 | CPU
DEBUG 01-14 20:42:32.036260.036260 lmp.py:1625]   Expert 26 |     89 | CPU
DEBUG 01-14 20:42:32.036426.036426 lmp.py:1625]   Expert 31 |     89 | CPU
DEBUG 01-14 20:42:32.036592.036592 lmp.py:1625]   Expert 54 |     90 | CPU
DEBUG 01-14 20:42:32.036759.036759 lmp.py:1625]   Expert 45 |     91 | CPU
DEBUG 01-14 20:42:32.036163.036163 lmp.py:1625]   Expert 10 |     96 | CPU
DEBUG 01-14 20:42:32.036568.036568 lmp.py:1625]   Expert 58 |    105 | CPU
DEBUG 01-14 20:42:32.036502.036502 lmp.py:1625]   Expert 30 |    109 | CPU
DEBUG 01-14 20:42:32.036907.036907 lmp.py:1625]   Expert 51 |    109 | CPU
DEBUG 01-14 20:42:32.036834.036834 lmp.py:1625]   Expert 36 |    115 | CPU
DEBUG 01-14 20:42:32.036001.036001 lmp.py:1625]   Expert 32 |    126 | CPU
DEBUG 01-14 20:42:32.036882.036882 lmp.py:1625]   Expert 20 |    127 | CPU
DEBUG 01-14 20:42:32.036094.036094 lmp.py:1625]   Expert 61 |    137 | CPU
DEBUG 01-14 20:42:32.036545.036545 lmp.py:1625]   Expert  4 |    139 | CPU
DEBUG 01-14 20:42:32.036996.036996 lmp.py:1625]   Expert 63 |    140 | CPU
DEBUG 01-14 20:42:32.036732.036732 lmp.py:1625]   Expert 16 |    144 | CPU
DEBUG 01-14 20:42:32.036944.036944 lmp.py:1625]   Expert 42 |    148 | CPU
DEBUG 01-14 20:42:32.036157.036157 lmp.py:1625]   Expert 47 |    149 | CPU
DEBUG 01-14 20:42:32.036131.036131 lmp.py:1625]   Expert 53 |    150 | CPU
DEBUG 01-14 20:42:32.036582.036582 lmp.py:1625]   Expert 34 |    151 | CPU
DEBUG 01-14 20:42:32.036271.036271 lmp.py:1625]   Expert  8 |    153 | CPU
DEBUG 01-14 20:42:32.036437.036437 lmp.py:1625]   Expert 60 |    154 | CPU
DEBUG 01-14 20:42:32.036603.036603 lmp.py:1625]   Expert 28 |    158 | CPU
DEBUG 01-14 20:42:32.036293.036293 lmp.py:1625]   Expert 17 |    168 | CPU
DEBUG 01-14 20:42:32.036505.036505 lmp.py:1625]   Expert 27 |    171 | CPU
DEBUG 01-14 20:42:32.036718.036718 lmp.py:1625]   Expert 56 |    176 | CPU
DEBUG 01-14 20:42:32.036215.036215 lmp.py:1625]   Expert 29 |    178 | CPU
DEBUG 01-14 20:42:32.036427.036427 lmp.py:1625]   Expert 44 |    179 | CPU
DEBUG 01-14 20:42:32.036163.036163 lmp.py:1625]   Expert 24 |    181 | CPU
DEBUG 01-14 20:42:32.036375.036375 lmp.py:1625]   Expert 41 |    181 | GPU
DEBUG 01-14 20:42:32.036588.036588 lmp.py:1625]   Expert  0 |    183 | GPU
DEBUG 01-14 20:42:32.036323.036323 lmp.py:1625]   Expert 48 |    183 | GPU
DEBUG 01-14 20:42:32.036536.036536 lmp.py:1625]   Expert  9 |    186 | GPU
DEBUG 01-14 20:42:32.036748.036748 lmp.py:1625]   Expert  2 |    187 | GPU
DEBUG 01-14 20:42:32.037438.037438 lmp.py:1625]   Expert  7 |    189 | GPU
DEBUG 01-14 20:42:32.037604.037604 lmp.py:1625]   Expert 15 |    189 | GPU
DEBUG 01-14 20:42:32.037770.037770 lmp.py:1625]   Expert  3 |    190 | GPU
DEBUG 01-14 20:42:32.037936.037936 lmp.py:1625]   Expert 18 |    196 | GPU
DEBUG 01-14 20:42:32.037148.037148 lmp.py:1625]   Expert 55 |    198 | GPU
DEBUG 01-14 20:42:32.037361.037361 lmp.py:1625]   Expert 40 |    200 | GPU
DEBUG 01-14 20:42:32.037097.037097 lmp.py:1625]   Expert  6 |    212 | GPU
DEBUG 01-14 20:42:32.037309.037309 lmp.py:1625]   Expert 22 |    214 | GPU
DEBUG 01-14 20:42:32.037045.037045 lmp.py:1625]   Expert 38 |    214 | GPU
DEBUG 01-14 20:42:32.037019.037019 lmp.py:1625]   Expert 37 |    224 | GPU
DEBUG 01-14 20:42:32.037993.037993 lmp.py:1625]   Expert 23 |    229 | GPU
DEBUG 01-14 20:42:32.037728.037728 lmp.py:1625]   Expert 25 |    238 | GPU
DEBUG 01-14 20:42:32.037610.037610 lmp.py:1625]   Expert 46 |    241 | GPU
DEBUG 01-14 20:42:32.037299.037299 lmp.py:1625]   Expert 50 |    251 | GPU
DEBUG 01-14 20:42:32.037227.037227 lmp.py:1625]   Expert 39 |    258 | GPU
DEBUG 01-14 20:42:32.037916.037916 lmp.py:1625]   Expert 62 |    262 | GPU
DEBUG 01-14 20:42:32.037844.037844 lmp.py:1625]   Expert 12 |    264 | GPU
DEBUG 01-14 20:42:32.037818.037818 lmp.py:1625]   Expert 19 |    267 | GPU
DEBUG 01-14 20:42:32.037030.037030 lmp.py:1625]   Expert 21 |    267 | GPU
DEBUG 01-14 20:42:32.037766.037766 lmp.py:1625]   Expert 35 |    290 | GPU
DEBUG 01-14 20:42:32.037740.037740 lmp.py:1625]   Expert 49 |    292 | GPU
DEBUG 01-14 20:42:32.037952.037952 lmp.py:1625]   Expert 52 |    302 | GPU
DEBUG 01-14 20:42:32.037688.037688 lmp.py:1625]   Expert 33 |    308 | GPU
DEBUG 01-14 20:42:32.037662.037662 lmp.py:1625]   Expert  1 |    346 | GPU
DEBUG 01-14 20:42:32.037590.037590 lmp.py:1625]   Expert  5 |    377 | GPU
DEBUG 01-14 20:42:32.037518.037518 lmp.py:1625]   Expert 43 |    432 | GPU
DEBUG 01-14 20:42:32.037445.037445 lmp.py:1625]   Expert 59 |    596 | GPU
DEBUG 01-14 20:42:32.037850.037850 lmp.py:1626] 
DEBUG 01-14 20:42:32.037850.037850 lmp.py:1626]   CPU total tokens: 4122 (33.5%)
DEBUG 01-14 20:42:32.037685.037685 lmp.py:1627]   GPU total tokens: 8166 (66.5%)
DEBUG 01-14 20:42:32.037619.037619 cuda_h.py:19] end experts_map_get cost 0.0015323162078857422 seconds
DEBUG 01-14 20:42:32.037562.037562 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-14 20:42:32.037782.037782 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-14 20:42:32.037972.037972 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-14 20:42:32.039474.039474 cuda_h.py:19] end allocate_cuda_memory cost 0.0012843608856201172 seconds
DEBUG 01-14 20:42:32.039522.039522 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-14 20:42:32.039424.039424 sllm_store_c.py:27] get device uuid map
DEBUG 01-14 20:42:32.039803.039803 sllm_store_c.py:29] call client load into gpu
DEBUG 01-14 20:42:32.039168.039168 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 232f55fa-43f9-4739-8174-8cf1eb6408d3
DEBUG 01-14 20:42:32.039697.039697 client.py:106] call stub.LoadModelAsync
INFO 01-14 20:42:32.040708.040708 client.py:127] Model loaded
DEBUG 01-14 20:42:32.040021.040021 cuda_h.py:10] start restore2model
DEBUG 01-14 20:42:32.041546.041546 cuda_h.py:19] end restore2model cost 0.0004184246063232422 seconds
DEBUG 01-14 20:42:32.041230.041230 cuda_h.py:19] end sllm_worker_task cost 0.013314247131347656 seconds
INFO 01-14 20:42:32.041901.041901 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 232f55fa-43f9-4739-8174-8cf1eb6408d3
DEBUG 01-14 20:42:32.041320.041320 cuda_h.py:19] end load_into_gpu_async cost 0.002624034881591797 seconds
DEBUG 01-14 20:42:32.041407.041407 cuda_h.py:10] start restore_tensors2
DEBUG 01-14 20:42:32.042382.042382 cuda_h.py:19] end restore_tensors2 cost 0.0004088878631591797 seconds
DEBUG 01-14 20:42:32.042940.042940 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.004689931869506836 seconds
DEBUG 01-14 20:42:32.042849.042849 cuda_h.py:10] start restore2model
DEBUG 01-14 20:42:32.045839.045839 cuda_h.py:19] end restore2model cost 0.0026302337646484375 seconds
DEBUG 01-14 20:42:32.045158.045158 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.007504940032958984 seconds
DEBUG 01-14 20:42:32.045954.045954 cuda_h.py:10] start gpu_sexperts
DEBUG 01-14 20:42:32.045752.045752 cuda_h.py:19] end gpu_sexperts cost 0.00027561187744140625 seconds
DEBUG 01-14 20:42:32.045244.045244 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-14 20:42:32.045093.045093 lmp.py:1683] 
DEBUG 01-14 20:42:32.045093.045093 lmp.py:1683]   Computing 32 experts on CPU...
DEBUG 01-14 20:42:32.045121.045121 cuda_h.py:19] end cpu_experts_submit cost 5.602836608886719e-05 seconds
DEBUG 01-14 20:42:32.045917.045917 cuda_h.py:10] start experts_func_mgpu_group_pad
DEBUG 01-14 20:42:32.051179.051179 mlpmodule.py:1460] group tensors cost 0.0052454471588134766 s
DEBUG 01-14 20:42:32.052379.052379 cuda_h.py:10] start move_flat_hidden2cpu
DEBUG 01-14 20:42:32.054533.054533 cuda_h.py:19] end experts_func_mgpu_group_pad cost 0.008445501327514648 seconds
DEBUG 01-14 20:42:32.055443.055443 cuda_h.py:10] start gpu_group_list
DEBUG 01-14 20:42:32.056157.056157 cuda_h.py:19] end gpu_group_list cost 0.0004470348358154297 seconds
DEBUG 01-14 20:42:32.056024.056024 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-14 20:42:32.056749.056749 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 4.7206878662109375e-05 seconds
DEBUG 01-14 20:42:32.056936.056936 cuda_h.py:10] start wait_experts
INFO 01-14 20:42:32.056634.056634 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 232f55fa-43f9-4739-8174-8cf1eb6408d3
DEBUG 01-14 20:42:32.058533.058533 cuda_h.py:19] end move_flat_hidden2cpu cost 0.006501674652099609 seconds
DEBUG 01-14 20:42:32.060906.060906 mlpmodule.py:1533] pad cost 0.0015325546264648438 s
DEBUG 01-14 20:42:32.060221.060221 mlpmodule.py:1539] create cpu tensor cost 5.8650970458984375e-05 s
DEBUG 01-14 20:42:32.062082.062082 mlpmodule.py:1544] move to cpu cost 0.0021355152130126953 s
DEBUG 01-14 20:42:32.072702.072702 mlpmodule.py:1558] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-14 20:42:32.072702.072702 mlpmodule.py:1559] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-14 20:42:32.073805.073805 mlpmodule.py:1564] group_w3 first element: 0.0086669921875
WARNING 01-14 20:42:32.073028.073028 mlpmodule.py:1574] start einsum2
DEBUG 01-14 20:42:32.091987.091987 mlpmodule.py:1584] group einsum cost 0.028538227081298828 s
DEBUG 01-14 20:42:32.092940.092940 mlpmodule.py:1593] cpy2cputensor cost 0.0007555484771728516 s
DEBUG 01-14 20:42:32.092339.092339 cuda_h.py:10] start move_outputs
DEBUG 01-14 20:42:32.094839.094839 cuda_h.py:19] end move_outputs cost 0.002653360366821289 seconds
INFO 01-14 20:42:32.099247.099247 client.py:127] Model loaded
DEBUG 01-14 20:42:32.099015.099015 cuda_h.py:19] end wait_experts cost 0.043378591537475586 seconds
DEBUG 01-14 20:42:32.099307.099307 cuda_h.py:10] start gpu_experts
DEBUG 01-14 20:42:32.100031.100031 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-14 20:42:32.100885.100885 cuda_h.py:19] end wait_cetm_experts cost 0.00017976760864257812 seconds
DEBUG 01-14 20:42:32.100934.100934 cuda_h.py:10] start gpu_group_einsum_mp_multi_list
DEBUG 01-14 20:42:32.100975.100975 cuda_h.py:10] start gpu_group_tensor
DEBUG 01-14 20:42:32.109021.109021 cuda_h.py:19] end gpu_group_tensor cost 0.009022951126098633 seconds
DEBUG 01-14 20:42:32.109702.109702 cuda_h.py:10] start gpu_group_einsum
DEBUG 01-14 20:42:32.110113.110113 cuda_h.py:19] end gpu_group_einsum cost 0.0005536079406738281 seconds
DEBUG 01-14 20:42:32.110123.110123 cuda_h.py:10] start gpu_final_hidden_states_scatter
DEBUG 01-14 20:42:32.110576.110576 cuda_h.py:10] start all_expert_outputs_slices
DEBUG 01-14 20:42:32.110538.110538 cuda_h.py:19] end all_expert_outputs_slices cost 0.00022339820861816406 seconds
DEBUG 01-14 20:42:32.110956.110956 cuda_h.py:10] start concat_expert_out
DEBUG 01-14 20:42:32.110263.110263 cuda_h.py:19] end concat_expert_out cost 5.53131103515625e-05 seconds
DEBUG 01-14 20:42:32.110875.110875 cuda_h.py:10] start index_scatter
DEBUG 01-14 20:42:32.110011.110011 cuda_h.py:19] end index_scatter cost 6.818771362304688e-05 seconds
DEBUG 01-14 20:42:32.110171.110171 cuda_h.py:19] end gpu_final_hidden_states_scatter cost 0.0005908012390136719 seconds
DEBUG 01-14 20:42:32.111055.111055 cuda_h.py:19] end gpu_experts cost 0.011020183563232422 seconds
DEBUG 01-14 20:42:32.111811.111811 cuda_h.py:10] start all_expert_weight_slices
DEBUG 01-14 20:42:32.112031.112031 cuda_h.py:19] end all_expert_weight_slices cost 0.001003265380859375 seconds
DEBUG 01-14 20:42:32.112391.112391 cuda_h.py:10] start cpuoutputsdeal
DEBUG 01-14 20:42:32.112207.112207 cuda_h.py:10] start index_scatter
DEBUG 01-14 20:42:32.112370.112370 cuda_h.py:19] end index_scatter cost 5.817413330078125e-05 seconds
DEBUG 01-14 20:42:32.112147.112147 cuda_h.py:19] end cpuoutputsdeal cost 0.0005941390991210938 seconds
DEBUG 01-14 20:42:32.112739.112739 cuda_h.py:19] end layer_moe_generate_mp_l_5 cost 0.0776371955871582 seconds
DEBUG 01-14 20:42:32.113910.113910 cuda_h.py:19] end prefill_layer cost 0.08563947677612305 seconds
DEBUG 01-14 20:42:32.113343.113343 lmp.py:1551] -------------------------------- end prefill layer 4 --------------------------------
DEBUG 01-14 20:42:32.113576.113576 cuda_h.py:10] start prefill_layer
DEBUG 01-14 20:42:32.113094.113094 lmp.py:1494] -------------------------------- start prefill layer 5 --------------------------------
DEBUG 01-14 20:42:32.113380.113380 cuda_h.py:10] start start_load_qkvogn_s_weight_l_6
DEBUG 01-14 20:42:32.113619.113619 cuda_h.py:10] start start_load_qkvogn_s_weight_l_6
DEBUG 01-14 20:42:32.113708.113708 cuda_h.py:19] end start_load_qkvogn_s_weight_l_6 cost 3.4332275390625e-05 seconds
DEBUG 01-14 20:42:32.113086.113086 cuda_h.py:19] end start_load_qkvogn_s_weight_l_6 cost 7.081031799316406e-05 seconds
DEBUG 01-14 20:42:32.113359.113359 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-14 20:42:32.113262.113262 cuda_h.py:10] start sllm_worker_task
DEBUG 01-14 20:42:32.113059.113059 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-14 20:42:32.113181.113181 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-14 20:42:32.114154.114154 cuda_h.py:19] end allocate_cuda_memory cost 0.0007495880126953125 seconds
DEBUG 01-14 20:42:32.114719.114719 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-14 20:42:32.114336.114336 sllm_store_c.py:27] get device uuid map
DEBUG 01-14 20:42:32.114735.114735 sllm_store_c.py:29] call client load into gpu
DEBUG 01-14 20:42:32.114630.114630 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, a0da15af-c24b-4ae5-8077-bcc18a2ff093
DEBUG 01-14 20:42:32.114692.114692 client.py:106] call stub.LoadModelAsync
DEBUG 01-14 20:42:32.115706.115706 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-14 20:42:32.115128.115128 mlpmodule.py:1367]  experts func einsum cost 0.06903195381164551 s
DEBUG 01-14 20:42:32.115955.115955 cuda_h.py:10] start self_attn
INFO 01-14 20:42:32.116569.116569 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, a0da15af-c24b-4ae5-8077-bcc18a2ff093
DEBUG 01-14 20:42:32.116551.116551 cuda_h.py:19] end load_into_gpu_async cost 0.0018775463104248047 seconds
DEBUG 01-14 20:42:32.116539.116539 cuda_h.py:10] start restore_tensors2
DEBUG 01-14 20:42:32.116483.116483 cuda_h.py:19] end restore_tensors2 cost 6.866455078125e-05 seconds
DEBUG 01-14 20:42:32.116523.116523 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0029413700103759766 seconds
INFO 01-14 20:42:32.116274.116274 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, a0da15af-c24b-4ae5-8077-bcc18a2ff093
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-14 20:42:32.118737.118737 cuda_h.py:19] end self_attn cost 0.0032782554626464844 seconds
DEBUG 01-14 20:42:32.119684.119684 cuda_h.py:19] end iln_self_attn_paln cost 0.005713462829589844 seconds
DEBUG 01-14 20:42:32.119130.119130 cuda_h.py:10] start layer_moe_generate_mp_l_6
DEBUG 01-14 20:42:32.119714.119714 cuda_h.py:10] start gate
DEBUG 01-14 20:42:32.120813.120813 cuda_h.py:19] end gate cost 0.0007302761077880859 seconds
DEBUG 01-14 20:42:32.120040.120040 cuda_h.py:10] start experts_map_get
DEBUG 01-14 20:42:32.120206.120206 lmp.py:1615] 
DEBUG 01-14 20:42:32.120206.120206 lmp.py:1615] Expert Token Distribution & Device Allocation:
DEBUG 01-14 20:42:32.120930.120930 lmp.py:1616]   Total experts: 64
DEBUG 01-14 20:42:32.120401.120401 lmp.py:1617]   CPU experts: 32 (50%)
DEBUG 01-14 20:42:32.120104.120104 lmp.py:1618]   GPU experts: 32 (50%)
DEBUG 01-14 20:42:32.120959.120959 lmp.py:1619] 
DEBUG 01-14 20:42:32.120959.120959 lmp.py:1619]   Expert ID | Tokens | Device
DEBUG 01-14 20:42:32.120801.120801 lmp.py:1620]   -----------------------------------
DEBUG 01-14 20:42:32.120120.120120 lmp.py:1625]   Expert 34 |     36 | CPU
DEBUG 01-14 20:42:32.120737.120737 lmp.py:1625]   Expert 45 |     69 | CPU
DEBUG 01-14 20:42:32.120664.120664 lmp.py:1625]   Expert 22 |     76 | CPU
DEBUG 01-14 20:42:32.120115.120115 lmp.py:1625]   Expert 57 |     94 | CPU
DEBUG 01-14 20:42:32.120805.120805 lmp.py:1625]   Expert 17 |     97 | CPU
DEBUG 01-14 20:42:32.120255.120255 lmp.py:1625]   Expert 15 |    102 | CPU
DEBUG 01-14 20:42:32.120945.120945 lmp.py:1625]   Expert  4 |    105 | CPU
DEBUG 01-14 20:42:32.121349.121349 lmp.py:1625]   Expert 28 |    109 | CPU
DEBUG 01-14 20:42:32.121992.121992 lmp.py:1625]   Expert 16 |    117 | CPU
DEBUG 01-14 20:42:32.121158.121158 lmp.py:1625]   Expert 12 |    121 | CPU
DEBUG 01-14 20:42:32.121563.121563 lmp.py:1625]   Expert 60 |    122 | CPU
DEBUG 01-14 20:42:32.121444.121444 lmp.py:1625]   Expert 32 |    126 | CPU
DEBUG 01-14 20:42:32.121895.121895 lmp.py:1625]   Expert 36 |    127 | CPU
DEBUG 01-14 20:42:32.121346.121346 lmp.py:1625]   Expert 14 |    128 | CPU
DEBUG 01-14 20:42:32.121559.121559 lmp.py:1625]   Expert 25 |    128 | CPU
DEBUG 01-14 20:42:32.121533.121533 lmp.py:1625]   Expert  8 |    129 | CPU
DEBUG 01-14 20:42:32.121414.121414 lmp.py:1625]   Expert 52 |    130 | CPU
DEBUG 01-14 20:42:32.121819.121819 lmp.py:1625]   Expert  2 |    135 | CPU
DEBUG 01-14 20:42:32.121985.121985 lmp.py:1625]   Expert  0 |    140 | CPU
DEBUG 01-14 20:42:32.121343.121343 lmp.py:1625]   Expert  5 |    143 | CPU
DEBUG 01-14 20:42:32.121224.121224 lmp.py:1625]   Expert 35 |    144 | CPU
DEBUG 01-14 20:42:32.121867.121867 lmp.py:1625]   Expert 41 |    150 | CPU
DEBUG 01-14 20:42:32.121510.121510 lmp.py:1625]   Expert 23 |    153 | CPU
DEBUG 01-14 20:42:32.121392.121392 lmp.py:1625]   Expert 39 |    158 | CPU
DEBUG 01-14 20:42:32.121558.121558 lmp.py:1625]   Expert 30 |    163 | CPU
DEBUG 01-14 20:42:32.121486.121486 lmp.py:1625]   Expert 61 |    163 | CPU
DEBUG 01-14 20:42:32.121413.121413 lmp.py:1625]   Expert 44 |    168 | CPU
DEBUG 01-14 20:42:32.121341.121341 lmp.py:1625]   Expert 43 |    169 | CPU
DEBUG 01-14 20:42:32.121030.121030 lmp.py:1625]   Expert  9 |    174 | CPU
DEBUG 01-14 20:42:32.121196.121196 lmp.py:1625]   Expert 13 |    175 | CPU
DEBUG 01-14 20:42:32.121363.121363 lmp.py:1625]   Expert  3 |    178 | CPU
DEBUG 01-14 20:42:32.121959.121959 lmp.py:1625]   Expert 31 |    180 | CPU
DEBUG 01-14 20:42:32.121079.121079 lmp.py:1625]   Expert 46 |    186 | GPU
DEBUG 01-14 20:42:32.121437.121437 lmp.py:1625]   Expert 62 |    187 | GPU
DEBUG 01-14 20:42:32.121557.121557 lmp.py:1625]   Expert 42 |    188 | GPU
DEBUG 01-14 20:42:32.121915.121915 lmp.py:1625]   Expert 50 |    188 | GPU
DEBUG 01-14 20:42:32.121081.121081 lmp.py:1625]   Expert 47 |    194 | GPU
DEBUG 01-14 20:42:32.121248.121248 lmp.py:1625]   Expert 11 |    195 | GPU
DEBUG 01-14 20:42:32.121175.121175 lmp.py:1625]   Expert 26 |    195 | GPU
DEBUG 01-14 20:42:32.121341.121341 lmp.py:1625]   Expert 20 |    196 | GPU
DEBUG 01-14 20:42:32.121269.121269 lmp.py:1625]   Expert 51 |    198 | GPU
DEBUG 01-14 20:42:32.121627.121627 lmp.py:1625]   Expert 19 |    202 | GPU
DEBUG 01-14 20:42:32.121270.121270 lmp.py:1625]   Expert 18 |    203 | GPU
DEBUG 01-14 20:42:32.121152.121152 lmp.py:1625]   Expert 63 |    203 | GPU
DEBUG 01-14 20:42:32.121272.121272 lmp.py:1625]   Expert 27 |    206 | GPU
DEBUG 01-14 20:42:32.121438.121438 lmp.py:1625]   Expert 56 |    208 | GPU
DEBUG 01-14 20:42:32.121365.121365 lmp.py:1625]   Expert 55 |    212 | GPU
DEBUG 01-14 20:42:32.121532.121532 lmp.py:1625]   Expert 38 |    216 | GPU
DEBUG 01-14 20:42:32.121459.121459 lmp.py:1625]   Expert 49 |    220 | GPU
DEBUG 01-14 20:42:32.121149.121149 lmp.py:1625]   Expert 48 |    223 | GPU
DEBUG 01-14 20:42:32.121553.121553 lmp.py:1625]   Expert  1 |    234 | GPU
DEBUG 01-14 20:42:32.121719.121719 lmp.py:1625]   Expert 10 |    242 | GPU
DEBUG 01-14 20:42:32.121647.121647 lmp.py:1625]   Expert 54 |    242 | GPU
DEBUG 01-14 20:42:32.121290.121290 lmp.py:1625]   Expert  7 |    244 | GPU
DEBUG 01-14 20:42:32.121933.121933 lmp.py:1625]   Expert 21 |    248 | GPU
DEBUG 01-14 20:42:32.121053.121053 lmp.py:1625]   Expert 24 |    251 | GPU
DEBUG 01-14 20:42:32.121934.121934 lmp.py:1625]   Expert 33 |    251 | GPU
DEBUG 01-14 20:42:32.121100.121100 lmp.py:1625]   Expert 29 |    261 | GPU
DEBUG 01-14 20:42:32.121266.121266 lmp.py:1625]   Expert 40 |    269 | GPU
DEBUG 01-14 20:42:32.121717.121717 lmp.py:1625]   Expert 59 |    291 | GPU
DEBUG 01-14 20:42:32.121645.121645 lmp.py:1625]   Expert 37 |    337 | GPU
DEBUG 01-14 20:42:32.121334.121334 lmp.py:1625]   Expert 58 |    354 | GPU
DEBUG 01-14 20:42:32.121024.121024 lmp.py:1625]   Expert  6 |    385 | GPU
DEBUG 01-14 20:42:32.121190.121190 lmp.py:1625]   Expert 53 |    850 | GPU
DEBUG 01-14 20:42:32.121071.121071 lmp.py:1626] 
DEBUG 01-14 20:42:32.121071.121071 lmp.py:1626]   CPU total tokens: 4209 (34.3%)
DEBUG 01-14 20:42:32.122383.122383 lmp.py:1627]   GPU total tokens: 8079 (65.7%)
DEBUG 01-14 20:42:32.122748.122748 cuda_h.py:19] end experts_map_get cost 0.0017147064208984375 seconds
DEBUG 01-14 20:42:32.122790.122790 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-14 20:42:32.122348.122348 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-14 20:42:32.122459.122459 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-14 20:42:32.123237.123237 cuda_h.py:19] end allocate_cuda_memory cost 0.0012412071228027344 seconds
DEBUG 01-14 20:42:32.123524.123524 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-14 20:42:32.123519.123519 sllm_store_c.py:27] get device uuid map
DEBUG 01-14 20:42:32.123136.123136 sllm_store_c.py:29] call client load into gpu
DEBUG 01-14 20:42:32.123230.123230 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, b2f4a80a-d641-4771-b26c-9a049cd0211d
DEBUG 01-14 20:42:32.123177.123177 client.py:106] call stub.LoadModelAsync
INFO 01-14 20:42:32.124844.124844 client.py:127] Model loaded
DEBUG 01-14 20:42:32.124125.124125 cuda_h.py:10] start restore2model
DEBUG 01-14 20:42:32.124657.124657 cuda_h.py:19] end restore2model cost 0.00042128562927246094 seconds
DEBUG 01-14 20:42:32.124533.124533 cuda_h.py:19] end sllm_worker_task cost 0.011173248291015625 seconds
INFO 01-14 20:42:32.126631.126631 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, b2f4a80a-d641-4771-b26c-9a049cd0211d
DEBUG 01-14 20:42:32.126742.126742 cuda_h.py:19] end load_into_gpu_async cost 0.002496957778930664 seconds
DEBUG 01-14 20:42:32.126950.126950 cuda_h.py:10] start restore_tensors2
DEBUG 01-14 20:42:32.126782.126782 cuda_h.py:19] end restore_tensors2 cost 0.0004405975341796875 seconds
DEBUG 01-14 20:42:32.126194.126194 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.004673004150390625 seconds
DEBUG 01-14 20:42:32.126672.126672 cuda_h.py:10] start restore2model
DEBUG 01-14 20:42:32.129119.129119 cuda_h.py:19] end restore2model cost 0.0026171207427978516 seconds
DEBUG 01-14 20:42:32.129181.129181 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.0074923038482666016 seconds
DEBUG 01-14 20:42:32.129997.129997 cuda_h.py:10] start gpu_sexperts
DEBUG 01-14 20:42:32.129351.129351 cuda_h.py:19] end gpu_sexperts cost 0.00026607513427734375 seconds
DEBUG 01-14 20:42:32.130889.130889 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-14 20:42:32.130592.130592 lmp.py:1683] 
DEBUG 01-14 20:42:32.130592.130592 lmp.py:1683]   Computing 32 experts on CPU...
DEBUG 01-14 20:42:32.130416.130416 cuda_h.py:19] end cpu_experts_submit cost 8.106231689453125e-05 seconds
DEBUG 01-14 20:42:32.130973.130973 cuda_h.py:10] start experts_func_mgpu_group_pad
DEBUG 01-14 20:42:32.143185.143185 mlpmodule.py:1460] group tensors cost 0.012763738632202148 s
DEBUG 01-14 20:42:32.144220.144220 cuda_h.py:10] start move_flat_hidden2cpu
DEBUG 01-14 20:42:32.150144.150144 cuda_h.py:19] end experts_func_mgpu_group_pad cost 0.020454883575439453 seconds
DEBUG 01-14 20:42:32.151523.151523 cuda_h.py:19] end move_flat_hidden2cpu cost 0.006970643997192383 seconds
DEBUG 01-14 20:42:32.153995.153995 cuda_h.py:10] start gpu_group_list
DEBUG 01-14 20:42:32.154224.154224 cuda_h.py:19] end gpu_group_list cost 0.0008866786956787109 seconds
DEBUG 01-14 20:42:32.155169.155169 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-14 20:42:32.155632.155632 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 3.552436828613281e-05 seconds
DEBUG 01-14 20:42:32.155701.155701 cuda_h.py:10] start wait_experts
INFO 01-14 20:42:32.155365.155365 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, b2f4a80a-d641-4771-b26c-9a049cd0211d
DEBUG 01-14 20:42:32.155108.155108 mlpmodule.py:1533] pad cost 0.0041046142578125 s
DEBUG 01-14 20:42:32.155715.155715 mlpmodule.py:1539] create cpu tensor cost 4.458427429199219e-05 s
DEBUG 01-14 20:42:32.158370.158370 mlpmodule.py:1544] move to cpu cost 0.002127408981323242 s
DEBUG 01-14 20:42:32.167498.167498 mlpmodule.py:1558] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-14 20:42:32.167021.167021 mlpmodule.py:1559] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-14 20:42:32.168203.168203 mlpmodule.py:1564] group_w3 first element: 0.03369140625
WARNING 01-14 20:42:32.168995.168995 mlpmodule.py:1574] start einsum2
INFO 01-14 20:42:32.181311.181311 client.py:127] Model loaded
DEBUG 01-14 20:42:32.182897.182897 cuda_h.py:19] end wait_experts cost 0.026514053344726562 seconds
DEBUG 01-14 20:42:32.182952.182952 cuda_h.py:10] start gpu_experts
DEBUG 01-14 20:42:32.182345.182345 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-14 20:42:32.185473.185473 mlpmodule.py:1584] group einsum cost 0.026932954788208008 s
DEBUG 01-14 20:42:32.185173.185173 mlpmodule.py:1593] cpy2cputensor cost 0.0007326602935791016 s
DEBUG 01-14 20:42:32.185373.185373 cuda_h.py:10] start move_outputs
DEBUG 01-14 20:42:32.188622.188622 cuda_h.py:19] end move_outputs cost 0.002085447311401367 seconds
DEBUG 01-14 20:42:32.191169.191169 cuda_h.py:19] end wait_cetm_experts cost 0.009477376937866211 seconds
DEBUG 01-14 20:42:32.191909.191909 cuda_h.py:10] start gpu_group_einsum_mp_multi_list
DEBUG 01-14 20:42:32.191725.191725 cuda_h.py:10] start gpu_group_tensor
DEBUG 01-14 20:42:32.192668.192668 cuda_h.py:19] end gpu_group_tensor cost 0.00024008750915527344 seconds
DEBUG 01-14 20:42:32.192308.192308 cuda_h.py:10] start gpu_group_einsum
DEBUG 01-14 20:42:32.208964.208964 mlpmodule.py:1367]  experts func einsum cost 0.07780146598815918 s
DEBUG 01-14 20:42:32.209281.209281 cuda_h.py:19] end gpu_group_einsum cost 0.016728639602661133 seconds
DEBUG 01-14 20:42:32.209512.209512 cuda_h.py:10] start gpu_final_hidden_states_scatter
DEBUG 01-14 20:42:32.209401.209401 cuda_h.py:10] start all_expert_outputs_slices
DEBUG 01-14 20:42:32.209132.209132 cuda_h.py:19] end all_expert_outputs_slices cost 0.0002281665802001953 seconds
DEBUG 01-14 20:42:32.209027.209027 cuda_h.py:10] start concat_expert_out
DEBUG 01-14 20:42:32.209672.209672 cuda_h.py:19] end concat_expert_out cost 5.793571472167969e-05 seconds
DEBUG 01-14 20:42:32.209376.209376 cuda_h.py:10] start index_scatter
DEBUG 01-14 20:42:32.209320.209320 cuda_h.py:19] end index_scatter cost 6.794929504394531e-05 seconds
DEBUG 01-14 20:42:32.209506.209506 cuda_h.py:19] end gpu_final_hidden_states_scatter cost 0.000583648681640625 seconds
DEBUG 01-14 20:42:32.210463.210463 cuda_h.py:19] end gpu_experts cost 0.02785491943359375 seconds
DEBUG 01-14 20:42:32.210874.210874 cuda_h.py:10] start all_expert_weight_slices
DEBUG 01-14 20:42:32.210576.210576 cuda_h.py:19] end all_expert_weight_slices cost 0.0007712841033935547 seconds
DEBUG 01-14 20:42:32.210445.210445 cuda_h.py:10] start cpuoutputsdeal
DEBUG 01-14 20:42:32.211728.211728 cuda_h.py:10] start index_scatter
DEBUG 01-14 20:42:32.211195.211195 cuda_h.py:19] end index_scatter cost 4.744529724121094e-05 seconds
DEBUG 01-14 20:42:32.211912.211912 cuda_h.py:19] end cpuoutputsdeal cost 0.0004596710205078125 seconds
DEBUG 01-14 20:42:32.211053.211053 cuda_h.py:19] end layer_moe_generate_mp_l_6 cost 0.09200334548950195 seconds
DEBUG 01-14 20:42:32.211024.211024 cuda_h.py:19] end prefill_layer cost 0.09840083122253418 seconds
DEBUG 01-14 20:42:32.211305.211305 lmp.py:1551] -------------------------------- end prefill layer 5 --------------------------------
DEBUG 01-14 20:42:32.211147.211147 cuda_h.py:10] start prefill_layer
DEBUG 01-14 20:42:32.211796.211796 lmp.py:1494] -------------------------------- start prefill layer 6 --------------------------------
DEBUG 01-14 20:42:32.211161.211161 cuda_h.py:10] start start_load_qkvogn_s_weight_l_7
DEBUG 01-14 20:42:32.211957.211957 cuda_h.py:10] start start_load_qkvogn_s_weight_l_7
DEBUG 01-14 20:42:32.211747.211747 cuda_h.py:19] end start_load_qkvogn_s_weight_l_7 cost 3.266334533691406e-05 seconds
DEBUG 01-14 20:42:32.212589.212589 cuda_h.py:19] end start_load_qkvogn_s_weight_l_7 cost 5.936622619628906e-05 seconds
DEBUG 01-14 20:42:32.212470.212470 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-14 20:42:32.212095.212095 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-14 20:42:32.212158.212158 cuda_h.py:10] start sllm_worker_task
DEBUG 01-14 20:42:32.212870.212870 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-14 20:42:32.212375.212375 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-14 20:42:32.212277.212277 cuda_h.py:19] end allocate_cuda_memory cost 0.0002079010009765625 seconds
DEBUG 01-14 20:42:32.212936.212936 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-14 20:42:32.212567.212567 sllm_store_c.py:27] get device uuid map
DEBUG 01-14 20:42:32.212403.212403 sllm_store_c.py:29] call client load into gpu
DEBUG 01-14 20:42:32.212543.212543 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, a1c9ce20-1072-4f1f-928e-be6333a902d1
DEBUG 01-14 20:42:32.212440.212440 client.py:106] call stub.LoadModelAsync
DEBUG 01-14 20:42:32.213403.213403 cuda_h.py:10] start self_attn
INFO 01-14 20:42:32.214495.214495 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, a1c9ce20-1072-4f1f-928e-be6333a902d1
DEBUG 01-14 20:42:32.214074.214074 cuda_h.py:19] end load_into_gpu_async cost 0.0020933151245117188 seconds
DEBUG 01-14 20:42:32.214121.214121 cuda_h.py:10] start restore_tensors2
DEBUG 01-14 20:42:32.214092.214092 cuda_h.py:19] end restore_tensors2 cost 8.368492126464844e-05 seconds
DEBUG 01-14 20:42:32.215147.215147 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.002695322036743164 seconds
INFO 01-14 20:42:32.215990.215990 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, a1c9ce20-1072-4f1f-928e-be6333a902d1
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-14 20:42:32.216895.216895 cuda_h.py:19] end self_attn cost 0.0029659271240234375 seconds
DEBUG 01-14 20:42:32.216468.216468 cuda_h.py:19] end iln_self_attn_paln cost 0.004462718963623047 seconds
DEBUG 01-14 20:42:32.216742.216742 cuda_h.py:10] start layer_moe_generate_mp_l_7
DEBUG 01-14 20:42:32.216743.216743 cuda_h.py:10] start gate
DEBUG 01-14 20:42:32.217799.217799 cuda_h.py:19] end gate cost 0.0006368160247802734 seconds
DEBUG 01-14 20:42:32.217059.217059 cuda_h.py:10] start experts_map_get
DEBUG 01-14 20:42:32.217195.217195 lmp.py:1615] 
DEBUG 01-14 20:42:32.217195.217195 lmp.py:1615] Expert Token Distribution & Device Allocation:
DEBUG 01-14 20:42:32.217858.217858 lmp.py:1616]   Total experts: 64
DEBUG 01-14 20:42:32.217892.217892 lmp.py:1617]   CPU experts: 32 (50%)
DEBUG 01-14 20:42:32.217873.217873 lmp.py:1618]   GPU experts: 32 (50%)
DEBUG 01-14 20:42:32.217470.217470 lmp.py:1619] 
DEBUG 01-14 20:42:32.217470.217470 lmp.py:1619]   Expert ID | Tokens | Device
DEBUG 01-14 20:42:32.217782.217782 lmp.py:1620]   -----------------------------------
DEBUG 01-14 20:42:32.217809.217809 lmp.py:1625]   Expert  1 |     51 | CPU
DEBUG 01-14 20:42:32.217405.217405 lmp.py:1625]   Expert 37 |     64 | CPU
DEBUG 01-14 20:42:32.217048.217048 lmp.py:1625]   Expert 17 |     75 | CPU
DEBUG 01-14 20:42:32.217930.217930 lmp.py:1625]   Expert  7 |     77 | CPU
DEBUG 01-14 20:42:32.217573.217573 lmp.py:1625]   Expert 13 |     82 | CPU
DEBUG 01-14 20:42:32.217216.217216 lmp.py:1625]   Expert 18 |     82 | CPU
DEBUG 01-14 20:42:32.217097.217097 lmp.py:1625]   Expert  9 |     87 | CPU
DEBUG 01-14 20:42:32.217740.217740 lmp.py:1625]   Expert 54 |     95 | CPU
DEBUG 01-14 20:42:32.217098.217098 lmp.py:1625]   Expert 58 |     98 | CPU
DEBUG 01-14 20:42:32.217457.217457 lmp.py:1625]   Expert  0 |    109 | CPU
DEBUG 01-14 20:42:32.217292.217292 lmp.py:1625]   Expert 22 |    112 | CPU
DEBUG 01-14 20:42:32.218411.218411 lmp.py:1625]   Expert 59 |    112 | CPU
DEBUG 01-14 20:42:32.218247.218247 lmp.py:1625]   Expert 26 |    113 | CPU
DEBUG 01-14 20:42:32.218890.218890 lmp.py:1625]   Expert 10 |    117 | CPU
DEBUG 01-14 20:42:32.218056.218056 lmp.py:1625]   Expert 16 |    120 | CPU
DEBUG 01-14 20:42:32.218460.218460 lmp.py:1625]   Expert 43 |    130 | CPU
DEBUG 01-14 20:42:32.218626.218626 lmp.py:1625]   Expert 63 |    132 | CPU
DEBUG 01-14 20:42:32.218031.218031 lmp.py:1625]   Expert 28 |    138 | CPU
DEBUG 01-14 20:42:32.218674.218674 lmp.py:1625]   Expert 29 |    139 | CPU
DEBUG 01-14 20:42:32.218840.218840 lmp.py:1625]   Expert 33 |    141 | CPU
DEBUG 01-14 20:42:32.218198.218198 lmp.py:1625]   Expert  2 |    147 | CPU
DEBUG 01-14 20:42:32.218795.218795 lmp.py:1625]   Expert 51 |    150 | CPU
DEBUG 01-14 20:42:32.218153.218153 lmp.py:1625]   Expert 45 |    157 | CPU
DEBUG 01-14 20:42:32.218988.218988 lmp.py:1625]   Expert 40 |    161 | CPU
DEBUG 01-14 20:42:32.218346.218346 lmp.py:1625]   Expert 62 |    161 | CPU
DEBUG 01-14 20:42:32.218989.218989 lmp.py:1625]   Expert 23 |    165 | CPU
DEBUG 01-14 20:42:32.218394.218394 lmp.py:1625]   Expert 32 |    166 | CPU
DEBUG 01-14 20:42:32.218799.218799 lmp.py:1625]   Expert 55 |    166 | CPU
DEBUG 01-14 20:42:32.218965.218965 lmp.py:1625]   Expert 34 |    168 | CPU
DEBUG 01-14 20:42:32.218369.218369 lmp.py:1625]   Expert 11 |    171 | CPU
DEBUG 01-14 20:42:32.218535.218535 lmp.py:1625]   Expert 52 |    173 | CPU
DEBUG 01-14 20:42:32.218940.218940 lmp.py:1625]   Expert 41 |    175 | CPU
DEBUG 01-14 20:42:32.218583.218583 lmp.py:1625]   Expert  3 |    179 | GPU
DEBUG 01-14 20:42:32.218987.218987 lmp.py:1625]   Expert 14 |    179 | GPU
DEBUG 01-14 20:42:32.218107.218107 lmp.py:1625]   Expert 53 |    184 | GPU
DEBUG 01-14 20:42:32.218704.218704 lmp.py:1625]   Expert 42 |    189 | GPU
DEBUG 01-14 20:42:32.218585.218585 lmp.py:1625]   Expert 57 |    192 | GPU
DEBUG 01-14 20:42:32.218182.218182 lmp.py:1625]   Expert 15 |    200 | GPU
DEBUG 01-14 20:42:32.218587.218587 lmp.py:1625]   Expert 35 |    204 | GPU
DEBUG 01-14 20:42:32.218991.218991 lmp.py:1625]   Expert 30 |    210 | GPU
DEBUG 01-14 20:42:32.218396.218396 lmp.py:1625]   Expert 21 |    211 | GPU
DEBUG 01-14 20:42:32.218800.218800 lmp.py:1625]   Expert 24 |    217 | GPU
DEBUG 01-14 20:42:32.218205.218205 lmp.py:1625]   Expert  4 |    220 | GPU
DEBUG 01-14 20:42:32.218848.218848 lmp.py:1625]   Expert 12 |    225 | GPU
DEBUG 01-14 20:42:32.218444.218444 lmp.py:1625]   Expert 44 |    225 | GPU
DEBUG 01-14 20:42:32.218041.218041 lmp.py:1625]   Expert 19 |    231 | GPU
DEBUG 01-14 20:42:32.218638.218638 lmp.py:1625]   Expert 49 |    231 | GPU
DEBUG 01-14 20:42:32.218234.218234 lmp.py:1625]   Expert 47 |    235 | GPU
DEBUG 01-14 20:42:32.218877.218877 lmp.py:1625]   Expert 38 |    236 | GPU
DEBUG 01-14 20:42:32.218282.218282 lmp.py:1625]   Expert 61 |    242 | GPU
DEBUG 01-14 20:42:32.218448.218448 lmp.py:1625]   Expert 31 |    245 | GPU
DEBUG 01-14 20:42:32.218853.218853 lmp.py:1625]   Expert 50 |    245 | GPU
DEBUG 01-14 20:42:32.218257.218257 lmp.py:1625]   Expert  8 |    247 | GPU
DEBUG 01-14 20:42:32.218662.218662 lmp.py:1625]   Expert 46 |    251 | GPU
DEBUG 01-14 20:42:32.218066.218066 lmp.py:1625]   Expert  6 |    252 | GPU
DEBUG 01-14 20:42:32.218709.218709 lmp.py:1625]   Expert 39 |    262 | GPU
DEBUG 01-14 20:42:32.218591.218591 lmp.py:1625]   Expert  5 |    302 | GPU
DEBUG 01-14 20:42:32.218949.218949 lmp.py:1625]   Expert 27 |    302 | GPU
DEBUG 01-14 20:42:32.218069.218069 lmp.py:1625]   Expert 48 |    305 | GPU
DEBUG 01-14 20:42:32.218427.218427 lmp.py:1625]   Expert 20 |    342 | GPU
DEBUG 01-14 20:42:32.218831.218831 lmp.py:1625]   Expert 36 |    360 | GPU
DEBUG 01-14 20:42:32.218998.218998 lmp.py:1625]   Expert 60 |    366 | GPU
DEBUG 01-14 20:42:32.218402.218402 lmp.py:1625]   Expert 25 |    395 | GPU
DEBUG 01-14 20:42:32.218568.218568 lmp.py:1625]   Expert 56 |    570 | GPU
DEBUG 01-14 20:42:32.218688.218688 lmp.py:1626] 
DEBUG 01-14 20:42:32.218688.218688 lmp.py:1626]   CPU total tokens: 4034 (32.8%)
DEBUG 01-14 20:42:32.218046.218046 lmp.py:1627]   GPU total tokens: 8254 (67.2%)
DEBUG 01-14 20:42:32.218696.218696 cuda_h.py:19] end experts_map_get cost 0.0015985965728759766 seconds
DEBUG 01-14 20:42:32.219976.219976 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-14 20:42:32.219535.219535 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-14 20:42:32.219248.219248 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-14 20:42:32.221009.221009 cuda_h.py:19] end allocate_cuda_memory cost 0.0019321441650390625 seconds
DEBUG 01-14 20:42:32.221429.221429 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-14 20:42:32.221092.221092 sllm_store_c.py:27] get device uuid map
DEBUG 01-14 20:42:32.221047.221047 sllm_store_c.py:29] call client load into gpu
DEBUG 01-14 20:42:32.221558.221558 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 1eb349d2-45c8-4107-b9db-9a773067ede2
DEBUG 01-14 20:42:32.221623.221623 client.py:106] call stub.LoadModelAsync
INFO 01-14 20:42:32.223778.223778 client.py:127] Model loaded
DEBUG 01-14 20:42:32.223827.223827 cuda_h.py:10] start restore2model
DEBUG 01-14 20:42:32.223310.223310 cuda_h.py:19] end restore2model cost 0.0005512237548828125 seconds
DEBUG 01-14 20:42:32.223922.223922 cuda_h.py:19] end sllm_worker_task cost 0.011455059051513672 seconds
INFO 01-14 20:42:32.224809.224809 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 1eb349d2-45c8-4107-b9db-9a773067ede2
DEBUG 01-14 20:42:32.224904.224904 cuda_h.py:19] end load_into_gpu_async cost 0.003088235855102539 seconds
DEBUG 01-14 20:42:32.224706.224706 cuda_h.py:10] start restore_tensors2
DEBUG 01-14 20:42:32.224071.224071 cuda_h.py:19] end restore_tensors2 cost 0.0003807544708251953 seconds
DEBUG 01-14 20:42:32.224437.224437 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.005767822265625 seconds
DEBUG 01-14 20:42:32.224154.224154 cuda_h.py:10] start restore2model
DEBUG 01-14 20:42:32.227612.227612 cuda_h.py:19] end restore2model cost 0.0025920867919921875 seconds
DEBUG 01-14 20:42:32.227879.227879 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.008537054061889648 seconds
DEBUG 01-14 20:42:32.227483.227483 cuda_h.py:10] start gpu_sexperts
DEBUG 01-14 20:42:32.227353.227353 cuda_h.py:19] end gpu_sexperts cost 0.0002613067626953125 seconds
DEBUG 01-14 20:42:32.227912.227912 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-14 20:42:32.228283.228283 lmp.py:1683] 
DEBUG 01-14 20:42:32.228283.228283 lmp.py:1683]   Computing 32 experts on CPU...
DEBUG 01-14 20:42:32.228404.228404 cuda_h.py:19] end cpu_experts_submit cost 5.4836273193359375e-05 seconds
DEBUG 01-14 20:42:32.228246.228246 cuda_h.py:10] start experts_func_mgpu_group_pad
DEBUG 01-14 20:42:32.239173.239173 mlpmodule.py:1460] group tensors cost 0.010449886322021484 s
DEBUG 01-14 20:42:32.239257.239257 cuda_h.py:10] start move_flat_hidden2cpu
DEBUG 01-14 20:42:32.242527.242527 cuda_h.py:19] end experts_func_mgpu_group_pad cost 0.013886451721191406 seconds
DEBUG 01-14 20:42:32.243967.243967 cuda_h.py:10] start gpu_group_list
DEBUG 01-14 20:42:32.244759.244759 cuda_h.py:19] end gpu_group_list cost 0.0005788803100585938 seconds
DEBUG 01-14 20:42:32.244397.244397 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-14 20:42:32.244241.244241 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.86102294921875e-05 seconds
DEBUG 01-14 20:42:32.244680.244680 cuda_h.py:10] start wait_experts
INFO 01-14 20:42:32.244357.244357 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 1eb349d2-45c8-4107-b9db-9a773067ede2
DEBUG 01-14 20:42:32.248877.248877 cuda_h.py:19] end move_flat_hidden2cpu cost 0.00815129280090332 seconds
DEBUG 01-14 20:42:32.249052.249052 mlpmodule.py:1533] pad cost 0.0015571117401123047 s
DEBUG 01-14 20:42:32.249718.249718 mlpmodule.py:1539] create cpu tensor cost 3.5762786865234375e-05 s
DEBUG 01-14 20:42:32.251378.251378 mlpmodule.py:1544] move to cpu cost 0.002066373825073242 s
DEBUG 01-14 20:42:32.261514.261514 mlpmodule.py:1558] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-14 20:42:32.261308.261308 mlpmodule.py:1559] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-14 20:42:32.261059.261059 mlpmodule.py:1564] group_w3 first element: -0.003631591796875
WARNING 01-14 20:42:32.262634.262634 mlpmodule.py:1574] start einsum2
DEBUG 01-14 20:42:32.279723.279723 mlpmodule.py:1584] group einsum cost 0.02784872055053711 s
DEBUG 01-14 20:42:32.280113.280113 mlpmodule.py:1593] cpy2cputensor cost 0.0007565021514892578 s
DEBUG 01-14 20:42:32.280472.280472 cuda_h.py:10] start move_outputs
INFO 01-14 20:42:32.281066.281066 client.py:127] Model loaded
DEBUG 01-14 20:42:32.281132.281132 cuda_h.py:19] end wait_experts cost 0.0367891788482666 seconds
DEBUG 01-14 20:42:32.281379.281379 cuda_h.py:10] start gpu_experts
DEBUG 01-14 20:42:32.281102.281102 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-14 20:42:32.282985.282985 cuda_h.py:19] end move_outputs cost 0.0020227432250976562 seconds
DEBUG 01-14 20:42:32.286901.286901 cuda_h.py:19] end wait_cetm_experts cost 0.005039691925048828 seconds
DEBUG 01-14 20:42:32.286872.286872 cuda_h.py:10] start gpu_group_einsum_mp_multi_list
DEBUG 01-14 20:42:32.286635.286635 cuda_h.py:10] start gpu_group_tensor
DEBUG 01-14 20:42:32.287969.287969 cuda_h.py:19] end gpu_group_tensor cost 0.00023746490478515625 seconds
DEBUG 01-14 20:42:32.287416.287416 cuda_h.py:10] start gpu_group_einsum
DEBUG 01-14 20:42:32.287643.287643 cuda_h.py:19] end gpu_group_einsum cost 0.00057220458984375 seconds
DEBUG 01-14 20:42:32.287197.287197 cuda_h.py:10] start gpu_final_hidden_states_scatter
DEBUG 01-14 20:42:32.287563.287563 cuda_h.py:10] start all_expert_outputs_slices
DEBUG 01-14 20:42:32.288328.288328 cuda_h.py:19] end all_expert_outputs_slices cost 0.0002875328063964844 seconds
DEBUG 01-14 20:42:32.288369.288369 cuda_h.py:10] start concat_expert_out
DEBUG 01-14 20:42:32.288115.288115 cuda_h.py:19] end concat_expert_out cost 9.274482727050781e-05 seconds
DEBUG 01-14 20:42:32.288257.288257 cuda_h.py:10] start index_scatter
DEBUG 01-14 20:42:32.288068.288068 cuda_h.py:19] end index_scatter cost 7.295608520507812e-05 seconds
DEBUG 01-14 20:42:32.288877.288877 cuda_h.py:19] end gpu_final_hidden_states_scatter cost 0.0007040500640869141 seconds
DEBUG 01-14 20:42:32.288125.288125 cuda_h.py:19] end gpu_experts cost 0.007229328155517578 seconds
DEBUG 01-14 20:42:32.288305.288305 cuda_h.py:10] start all_expert_weight_slices
DEBUG 01-14 20:42:32.289781.289781 cuda_h.py:19] end all_expert_weight_slices cost 0.0009512901306152344 seconds
DEBUG 01-14 20:42:32.289604.289604 cuda_h.py:10] start cpuoutputsdeal
DEBUG 01-14 20:42:32.290241.290241 cuda_h.py:10] start index_scatter
DEBUG 01-14 20:42:32.290946.290946 cuda_h.py:19] end index_scatter cost 4.935264587402344e-05 seconds
DEBUG 01-14 20:42:32.290616.290616 cuda_h.py:19] end cpuoutputsdeal cost 0.0005419254302978516 seconds
DEBUG 01-14 20:42:32.290480.290480 cuda_h.py:19] end layer_moe_generate_mp_l_7 cost 0.07382607460021973 seconds
DEBUG 01-14 20:42:32.290433.290433 cuda_h.py:19] end prefill_layer cost 0.07894086837768555 seconds
DEBUG 01-14 20:42:32.290753.290753 lmp.py:1551] -------------------------------- end prefill layer 6 --------------------------------
DEBUG 01-14 20:42:32.290940.290940 cuda_h.py:10] start prefill_layer
DEBUG 01-14 20:42:32.290742.290742 lmp.py:1494] -------------------------------- start prefill layer 7 --------------------------------
DEBUG 01-14 20:42:32.290591.290591 cuda_h.py:10] start start_load_qkvogn_s_weight_l_8
DEBUG 01-14 20:42:32.291870.291870 cuda_h.py:10] start start_load_qkvogn_s_weight_l_8
DEBUG 01-14 20:42:32.291203.291203 cuda_h.py:19] end start_load_qkvogn_s_weight_l_8 cost 4.1961669921875e-05 seconds
DEBUG 01-14 20:42:32.291390.291390 cuda_h.py:19] end start_load_qkvogn_s_weight_l_8 cost 7.724761962890625e-05 seconds
DEBUG 01-14 20:42:32.291007.291007 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-14 20:42:32.291109.291109 cuda_h.py:10] start sllm_worker_task
DEBUG 01-14 20:42:32.291412.291412 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-14 20:42:32.291049.291049 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-14 20:42:32.291663.291663 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-14 20:42:32.292244.292244 cuda_h.py:19] end allocate_cuda_memory cost 0.0004901885986328125 seconds
DEBUG 01-14 20:42:32.292870.292870 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-14 20:42:32.292163.292163 sllm_store_c.py:27] get device uuid map
DEBUG 01-14 20:42:32.292807.292807 sllm_store_c.py:29] call client load into gpu
DEBUG 01-14 20:42:32.292086.292086 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 0d76be8e-d443-4477-8d0a-2b2059d0be57
DEBUG 01-14 20:42:32.292335.292335 client.py:106] call stub.LoadModelAsync
DEBUG 01-14 20:42:32.292279.292279 cuda_h.py:10] start self_attn
INFO 01-14 20:42:32.293530.293530 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 0d76be8e-d443-4477-8d0a-2b2059d0be57
DEBUG 01-14 20:42:32.293327.293327 cuda_h.py:19] end load_into_gpu_async cost 0.0017344951629638672 seconds
DEBUG 01-14 20:42:32.294414.294414 cuda_h.py:10] start restore_tensors2
DEBUG 01-14 20:42:32.294001.294001 cuda_h.py:19] end restore_tensors2 cost 8.440017700195312e-05 seconds
DEBUG 01-14 20:42:32.294525.294525 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0026280879974365234 seconds
INFO 01-14 20:42:32.294713.294713 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 0d76be8e-d443-4477-8d0a-2b2059d0be57
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-14 20:42:32.296729.296729 cuda_h.py:19] end self_attn cost 0.003276348114013672 seconds
DEBUG 01-14 20:42:32.296131.296131 cuda_h.py:19] end iln_self_attn_paln cost 0.005251884460449219 seconds
DEBUG 01-14 20:42:32.296928.296928 cuda_h.py:10] start layer_moe_generate_mp_l_8
DEBUG 01-14 20:42:32.296644.296644 cuda_h.py:10] start gate
DEBUG 01-14 20:42:32.297680.297680 cuda_h.py:19] end gate cost 0.0006587505340576172 seconds
DEBUG 01-14 20:42:32.297609.297609 cuda_h.py:10] start experts_map_get
DEBUG 01-14 20:42:32.297891.297891 lmp.py:1615] 
DEBUG 01-14 20:42:32.297891.297891 lmp.py:1615] Expert Token Distribution & Device Allocation:
DEBUG 01-14 20:42:32.297462.297462 lmp.py:1616]   Total experts: 64
DEBUG 01-14 20:42:32.297450.297450 lmp.py:1617]   CPU experts: 32 (50%)
DEBUG 01-14 20:42:32.297338.297338 lmp.py:1618]   GPU experts: 32 (50%)
DEBUG 01-14 20:42:32.297888.297888 lmp.py:1619] 
DEBUG 01-14 20:42:32.297888.297888 lmp.py:1619]   Expert ID | Tokens | Device
DEBUG 01-14 20:42:32.297915.297915 lmp.py:1620]   -----------------------------------
DEBUG 01-14 20:42:32.297419.297419 lmp.py:1625]   Expert 46 |     35 | CPU
DEBUG 01-14 20:42:32.297970.297970 lmp.py:1625]   Expert 50 |     48 | CPU
DEBUG 01-14 20:42:32.297520.297520 lmp.py:1625]   Expert  3 |     59 | CPU
DEBUG 01-14 20:42:32.297594.297594 lmp.py:1625]   Expert  1 |     87 | CPU
DEBUG 01-14 20:42:32.297190.297190 lmp.py:1625]   Expert 15 |     97 | CPU
DEBUG 01-14 20:42:32.297456.297456 lmp.py:1625]   Expert 29 |     98 | CPU
DEBUG 01-14 20:42:32.297768.297768 lmp.py:1625]   Expert  4 |    100 | CPU
DEBUG 01-14 20:42:32.297126.297126 lmp.py:1625]   Expert 40 |    100 | CPU
DEBUG 01-14 20:42:32.297961.297961 lmp.py:1625]   Expert 28 |    108 | CPU
DEBUG 01-14 20:42:32.297034.297034 lmp.py:1625]   Expert  8 |    116 | CPU
DEBUG 01-14 20:42:32.297108.297108 lmp.py:1625]   Expert 54 |    118 | CPU
DEBUG 01-14 20:42:32.297705.297705 lmp.py:1625]   Expert 41 |    119 | CPU
DEBUG 01-14 20:42:32.297493.297493 lmp.py:1625]   Expert 13 |    128 | CPU
DEBUG 01-14 20:42:32.297567.297567 lmp.py:1625]   Expert 16 |    130 | CPU
DEBUG 01-14 20:42:32.298925.298925 lmp.py:1625]   Expert 18 |    133 | CPU
DEBUG 01-14 20:42:32.298714.298714 lmp.py:1625]   Expert  7 |    134 | CPU
DEBUG 01-14 20:42:32.298310.298310 lmp.py:1625]   Expert 36 |    134 | CPU
DEBUG 01-14 20:42:32.298430.298430 lmp.py:1625]   Expert 48 |    136 | CPU
DEBUG 01-14 20:42:32.298265.298265 lmp.py:1625]   Expert 51 |    136 | CPU
DEBUG 01-14 20:42:32.298624.298624 lmp.py:1625]   Expert  6 |    137 | CPU
DEBUG 01-14 20:42:32.298220.298220 lmp.py:1625]   Expert 27 |    139 | CPU
DEBUG 01-14 20:42:32.298055.298055 lmp.py:1625]   Expert 43 |    140 | CPU
DEBUG 01-14 20:42:32.298414.298414 lmp.py:1625]   Expert 52 |    140 | CPU
DEBUG 01-14 20:42:32.298772.298772 lmp.py:1625]   Expert 60 |    140 | CPU
DEBUG 01-14 20:42:32.298368.298368 lmp.py:1625]   Expert 20 |    142 | CPU
DEBUG 01-14 20:42:32.298965.298965 lmp.py:1625]   Expert 39 |    142 | CPU
DEBUG 01-14 20:42:32.298323.298323 lmp.py:1625]   Expert 11 |    145 | CPU
DEBUG 01-14 20:42:32.298920.298920 lmp.py:1625]   Expert 35 |    152 | CPU
DEBUG 01-14 20:42:32.298517.298517 lmp.py:1625]   Expert 62 |    155 | CPU
DEBUG 01-14 20:42:32.298352.298352 lmp.py:1625]   Expert 56 |    158 | CPU
DEBUG 01-14 20:42:32.298948.298948 lmp.py:1625]   Expert 45 |    160 | CPU
DEBUG 01-14 20:42:32.298307.298307 lmp.py:1625]   Expert 14 |    161 | CPU
DEBUG 01-14 20:42:32.298771.298771 lmp.py:1625]   Expert  5 |    164 | GPU
DEBUG 01-14 20:42:32.298798.298798 lmp.py:1625]   Expert 10 |    172 | GPU
DEBUG 01-14 20:42:32.298825.298825 lmp.py:1625]   Expert 44 |    176 | GPU
DEBUG 01-14 20:42:32.298899.298899 lmp.py:1625]   Expert 55 |    178 | GPU
DEBUG 01-14 20:42:32.298211.298211 lmp.py:1625]   Expert 25 |    181 | GPU
DEBUG 01-14 20:42:32.298284.298284 lmp.py:1625]   Expert 58 |    184 | GPU
DEBUG 01-14 20:42:32.298119.298119 lmp.py:1625]   Expert 31 |    185 | GPU
DEBUG 01-14 20:42:32.298477.298477 lmp.py:1625]   Expert 33 |    185 | GPU
DEBUG 01-14 20:42:32.298551.298551 lmp.py:1625]   Expert 57 |    185 | GPU
DEBUG 01-14 20:42:32.298624.298624 lmp.py:1625]   Expert 32 |    189 | GPU
DEBUG 01-14 20:42:32.298221.298221 lmp.py:1625]   Expert  2 |    195 | GPU
DEBUG 01-14 20:42:32.298579.298579 lmp.py:1625]   Expert 53 |    195 | GPU
DEBUG 01-14 20:42:32.298414.298414 lmp.py:1625]   Expert 21 |    203 | GPU
DEBUG 01-14 20:42:32.298773.298773 lmp.py:1625]   Expert 17 |    204 | GPU
DEBUG 01-14 20:42:32.298131.298131 lmp.py:1625]   Expert 49 |    210 | GPU
DEBUG 01-14 20:42:32.298204.298204 lmp.py:1625]   Expert 59 |    216 | GPU
DEBUG 01-14 20:42:32.298563.298563 lmp.py:1625]   Expert  0 |    224 | GPU
DEBUG 01-14 20:42:32.298921.298921 lmp.py:1625]   Expert 63 |    224 | GPU
DEBUG 01-14 20:42:32.298517.298517 lmp.py:1625]   Expert 34 |    240 | GPU
DEBUG 01-14 20:42:32.298637.298637 lmp.py:1625]   Expert 37 |    244 | GPU
DEBUG 01-14 20:42:32.298188.298188 lmp.py:1625]   Expert 42 |    246 | GPU
DEBUG 01-14 20:42:32.298115.298115 lmp.py:1625]   Expert 22 |    250 | GPU
DEBUG 01-14 20:42:32.298235.298235 lmp.py:1625]   Expert 19 |    254 | GPU
DEBUG 01-14 20:42:32.298163.298163 lmp.py:1625]   Expert 24 |    272 | GPU
DEBUG 01-14 20:42:32.298044.298044 lmp.py:1625]   Expert 61 |    281 | GPU
DEBUG 01-14 20:42:32.298972.298972 lmp.py:1625]   Expert 30 |    317 | GPU
DEBUG 01-14 20:42:32.298615.298615 lmp.py:1625]   Expert 47 |    323 | GPU
DEBUG 01-14 20:42:32.298019.298019 lmp.py:1625]   Expert 38 |    378 | GPU
DEBUG 01-14 20:42:32.298139.298139 lmp.py:1625]   Expert 26 |    394 | GPU
DEBUG 01-14 20:42:32.298305.298305 lmp.py:1625]   Expert 12 |    409 | GPU
DEBUG 01-14 20:42:32.298187.298187 lmp.py:1625]   Expert 23 |    594 | GPU
DEBUG 01-14 20:42:32.298353.298353 lmp.py:1625]   Expert  9 |    689 | GPU
DEBUG 01-14 20:42:32.298188.298188 lmp.py:1626] 
DEBUG 01-14 20:42:32.298188.298188 lmp.py:1626]   CPU total tokens: 3927 (32.0%)
DEBUG 01-14 20:42:32.298308.298308 lmp.py:1627]   GPU total tokens: 8361 (68.0%)
DEBUG 01-14 20:42:32.298150.298150 cuda_h.py:19] end experts_map_get cost 0.0016684532165527344 seconds
DEBUG 01-14 20:42:32.299457.299457 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-14 20:42:32.299837.299837 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-14 20:42:32.299073.299073 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-14 20:42:32.304104.304104 cuda_h.py:19] end allocate_cuda_memory cost 0.005199432373046875 seconds
DEBUG 01-14 20:42:32.304520.304520 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-14 20:42:32.304879.304879 sllm_store_c.py:27] get device uuid map
DEBUG 01-14 20:42:32.304246.304246 sllm_store_c.py:29] call client load into gpu
DEBUG 01-14 20:42:32.304386.304386 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 56ad77db-bf3b-4a6a-9e88-5b1c15d8cdd2
DEBUG 01-14 20:42:32.305089.305089 client.py:106] call stub.LoadModelAsync
DEBUG 01-14 20:42:32.305740.305740 mlpmodule.py:1367]  experts func einsum cost 0.07666015625 s
INFO 01-14 20:42:32.305982.305982 client.py:127] Model loaded
DEBUG 01-14 20:42:32.305646.305646 cuda_h.py:10] start restore2model
DEBUG 01-14 20:42:32.306822.306822 cuda_h.py:19] end restore2model cost 0.0010042190551757812 seconds
DEBUG 01-14 20:42:32.307355.307355 cuda_h.py:19] end sllm_worker_task cost 0.015677452087402344 seconds
INFO 01-14 20:42:32.307757.307757 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 56ad77db-bf3b-4a6a-9e88-5b1c15d8cdd2
DEBUG 01-14 20:42:32.307093.307093 cuda_h.py:19] end load_into_gpu_async cost 0.0026106834411621094 seconds
DEBUG 01-14 20:42:32.307624.307624 cuda_h.py:10] start restore_tensors2
DEBUG 01-14 20:42:32.307190.307190 cuda_h.py:19] end restore_tensors2 cost 0.0004520416259765625 seconds
DEBUG 01-14 20:42:32.307192.307192 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.008804082870483398 seconds
DEBUG 01-14 20:42:32.308399.308399 cuda_h.py:10] start restore2model
DEBUG 01-14 20:42:32.311962.311962 cuda_h.py:19] end restore2model cost 0.003327608108520508 seconds
DEBUG 01-14 20:42:32.311865.311865 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.012340784072875977 seconds
DEBUG 01-14 20:42:32.311005.311005 cuda_h.py:10] start gpu_sexperts
DEBUG 01-14 20:42:32.311038.311038 cuda_h.py:19] end gpu_sexperts cost 0.00032973289489746094 seconds
DEBUG 01-14 20:42:32.311920.311920 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-14 20:42:32.311968.311968 lmp.py:1683] 
DEBUG 01-14 20:42:32.311968.311968 lmp.py:1683]   Computing 32 experts on CPU...
DEBUG 01-14 20:42:32.312679.312679 cuda_h.py:19] end cpu_experts_submit cost 6.699562072753906e-05 seconds
DEBUG 01-14 20:42:32.312104.312104 cuda_h.py:10] start experts_func_mgpu_group_pad
DEBUG 01-14 20:42:32.317403.317403 mlpmodule.py:1460] group tensors cost 0.004555702209472656 s
DEBUG 01-14 20:42:32.317604.317604 cuda_h.py:10] start move_flat_hidden2cpu
DEBUG 01-14 20:42:32.320361.320361 cuda_h.py:19] end experts_func_mgpu_group_pad cost 0.008037567138671875 seconds
DEBUG 01-14 20:42:32.321610.321610 cuda_h.py:10] start gpu_group_list
DEBUG 01-14 20:42:32.322045.322045 cuda_h.py:19] end gpu_group_list cost 0.00043487548828125 seconds
DEBUG 01-14 20:42:32.322482.322482 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-14 20:42:32.322936.322936 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 1.9311904907226562e-05 seconds
DEBUG 01-14 20:42:32.322288.322288 cuda_h.py:10] start wait_experts
INFO 01-14 20:42:32.322998.322998 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 56ad77db-bf3b-4a6a-9e88-5b1c15d8cdd2
DEBUG 01-14 20:42:32.325676.325676 cuda_h.py:19] end move_flat_hidden2cpu cost 0.007220745086669922 seconds
DEBUG 01-14 20:42:32.326472.326472 mlpmodule.py:1533] pad cost 0.001535654067993164 s
DEBUG 01-14 20:42:32.326655.326655 mlpmodule.py:1539] create cpu tensor cost 3.504753112792969e-05 s
DEBUG 01-14 20:42:32.328634.328634 mlpmodule.py:1544] move to cpu cost 0.0019104480743408203 s
DEBUG 01-14 20:42:32.339657.339657 mlpmodule.py:1558] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-14 20:42:32.339450.339450 mlpmodule.py:1559] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-14 20:42:32.339447.339447 mlpmodule.py:1564] group_w3 first element: 0.01263427734375
WARNING 01-14 20:42:32.339795.339795 mlpmodule.py:1574] start einsum2
DEBUG 01-14 20:42:32.358176.358176 mlpmodule.py:1584] group einsum cost 0.029355525970458984 s
DEBUG 01-14 20:42:32.359546.359546 mlpmodule.py:1593] cpy2cputensor cost 0.0007646083831787109 s
DEBUG 01-14 20:42:32.359462.359462 cuda_h.py:10] start move_outputs
DEBUG 01-14 20:42:32.362193.362193 cuda_h.py:19] end move_outputs cost 0.0028257369995117188 seconds
INFO 01-14 20:42:32.363174.363174 client.py:127] Model loaded
DEBUG 01-14 20:42:32.363054.363054 cuda_h.py:19] end wait_experts cost 0.04141879081726074 seconds
DEBUG 01-14 20:42:32.364400.364400 cuda_h.py:10] start gpu_experts
DEBUG 01-14 20:42:32.364223.364223 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-14 20:42:32.366574.366574 cuda_h.py:19] end wait_cetm_experts cost 0.0021512508392333984 seconds
DEBUG 01-14 20:42:32.366597.366597 cuda_h.py:10] start gpu_group_einsum_mp_multi_list
DEBUG 01-14 20:42:32.366499.366499 cuda_h.py:10] start gpu_group_tensor
DEBUG 01-14 20:42:32.366594.366594 cuda_h.py:19] end gpu_group_tensor cost 0.0002493858337402344 seconds
DEBUG 01-14 20:42:32.366088.366088 cuda_h.py:10] start gpu_group_einsum
DEBUG 01-14 20:42:32.367676.367676 cuda_h.py:19] end gpu_group_einsum cost 0.0006973743438720703 seconds
DEBUG 01-14 20:42:32.367397.367397 cuda_h.py:10] start gpu_final_hidden_states_scatter
DEBUG 01-14 20:42:32.367869.367869 cuda_h.py:10] start all_expert_outputs_slices
DEBUG 01-14 20:42:32.368757.368757 cuda_h.py:19] end all_expert_outputs_slices cost 0.0003707408905029297 seconds
DEBUG 01-14 20:42:32.368513.368513 cuda_h.py:10] start concat_expert_out
DEBUG 01-14 20:42:32.368403.368403 cuda_h.py:19] end concat_expert_out cost 5.793571472167969e-05 seconds
DEBUG 01-14 20:42:32.368128.368128 cuda_h.py:10] start index_scatter
DEBUG 01-14 20:42:32.368590.368590 cuda_h.py:19] end index_scatter cost 0.00013184547424316406 seconds
DEBUG 01-14 20:42:32.368314.368314 cuda_h.py:19] end gpu_final_hidden_states_scatter cost 0.0008349418640136719 seconds
DEBUG 01-14 20:42:32.368184.368184 cuda_h.py:19] end gpu_experts cost 0.0045850276947021484 seconds
DEBUG 01-14 20:42:32.368840.368840 cuda_h.py:10] start all_expert_weight_slices
DEBUG 01-14 20:42:32.369926.369926 cuda_h.py:19] end all_expert_weight_slices cost 0.0009441375732421875 seconds
DEBUG 01-14 20:42:32.369795.369795 cuda_h.py:10] start cpuoutputsdeal
DEBUG 01-14 20:42:32.370717.370717 cuda_h.py:10] start index_scatter
DEBUG 01-14 20:42:32.370230.370230 cuda_h.py:19] end index_scatter cost 4.8160552978515625e-05 seconds
DEBUG 01-14 20:42:32.370423.370423 cuda_h.py:19] end cpuoutputsdeal cost 0.0005393028259277344 seconds
DEBUG 01-14 20:42:32.370095.370095 cuda_h.py:19] end layer_moe_generate_mp_l_8 cost 0.0737905502319336 seconds
DEBUG 01-14 20:42:32.370618.370618 cuda_h.py:19] end prefill_layer cost 0.07975029945373535 seconds
DEBUG 01-14 20:42:32.370799.370799 lmp.py:1551] -------------------------------- end prefill layer 7 --------------------------------
DEBUG 01-14 20:42:32.370978.370978 cuda_h.py:10] start prefill_layer
DEBUG 01-14 20:42:32.370396.370396 lmp.py:1494] -------------------------------- start prefill layer 8 --------------------------------
DEBUG 01-14 20:42:32.370245.370245 cuda_h.py:10] start start_load_qkvogn_s_weight_l_9
DEBUG 01-14 20:42:32.370524.370524 cuda_h.py:10] start start_load_qkvogn_s_weight_l_9
DEBUG 01-14 20:42:32.370228.370228 cuda_h.py:19] end start_load_qkvogn_s_weight_l_9 cost 3.552436828613281e-05 seconds
DEBUG 01-14 20:42:32.370223.370223 cuda_h.py:19] end start_load_qkvogn_s_weight_l_9 cost 6.842613220214844e-05 seconds
DEBUG 01-14 20:42:32.371588.371588 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-14 20:42:32.371914.371914 cuda_h.py:10] start sllm_worker_task
DEBUG 01-14 20:42:32.371953.371953 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-14 20:42:32.371160.371160 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-14 20:42:32.371105.371105 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-14 20:42:32.372395.372395 cuda_h.py:19] end allocate_cuda_memory cost 0.0006959438323974609 seconds
DEBUG 01-14 20:42:32.372544.372544 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-14 20:42:32.372360.372360 sllm_store_c.py:27] get device uuid map
DEBUG 01-14 20:42:32.372004.372004 sllm_store_c.py:29] call client load into gpu
DEBUG 01-14 20:42:32.372324.372324 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 9567424d-ac9d-4663-a268-28d83769b570
DEBUG 01-14 20:42:32.372765.372765 client.py:106] call stub.LoadModelAsync
DEBUG 01-14 20:42:32.372820.372820 cuda_h.py:10] start self_attn
INFO 01-14 20:42:32.373968.373968 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 9567424d-ac9d-4663-a268-28d83769b570
DEBUG 01-14 20:42:32.373811.373811 cuda_h.py:19] end load_into_gpu_async cost 0.0012102127075195312 seconds
DEBUG 01-14 20:42:32.373944.373944 cuda_h.py:10] start restore_tensors2
DEBUG 01-14 20:42:32.373531.373531 cuda_h.py:19] end restore_tensors2 cost 8.606910705566406e-05 seconds
DEBUG 01-14 20:42:32.373572.373572 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.002302408218383789 seconds
INFO 01-14 20:42:32.373070.373070 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 9567424d-ac9d-4663-a268-28d83769b570
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-14 20:42:32.376786.376786 cuda_h.py:19] end self_attn cost 0.003656148910522461 seconds
DEBUG 01-14 20:42:32.376876.376876 cuda_h.py:19] end iln_self_attn_paln cost 0.0057065486907958984 seconds
DEBUG 01-14 20:42:32.376242.376242 cuda_h.py:10] start layer_moe_generate_mp_l_9
DEBUG 01-14 20:42:32.376051.376051 cuda_h.py:10] start gate
DEBUG 01-14 20:42:32.377123.377123 cuda_h.py:19] end gate cost 0.0007188320159912109 seconds
DEBUG 01-14 20:42:32.377859.377859 cuda_h.py:10] start experts_map_get
DEBUG 01-14 20:42:32.378373.378373 lmp.py:1615] 
DEBUG 01-14 20:42:32.378373.378373 lmp.py:1615] Expert Token Distribution & Device Allocation:
DEBUG 01-14 20:42:32.378606.378606 lmp.py:1616]   Total experts: 64
DEBUG 01-14 20:42:32.378256.378256 lmp.py:1617]   CPU experts: 32 (50%)
DEBUG 01-14 20:42:32.378237.378237 lmp.py:1618]   GPU experts: 32 (50%)
DEBUG 01-14 20:42:32.378979.378979 lmp.py:1619] 
DEBUG 01-14 20:42:32.378979.378979 lmp.py:1619]   Expert ID | Tokens | Device
DEBUG 01-14 20:42:32.378245.378245 lmp.py:1620]   -----------------------------------
DEBUG 01-14 20:42:32.378033.378033 lmp.py:1625]   Expert 38 |     20 | CPU
DEBUG 01-14 20:42:32.378392.378392 lmp.py:1625]   Expert 39 |     60 | CPU
DEBUG 01-14 20:42:32.378035.378035 lmp.py:1625]   Expert 30 |     66 | CPU
DEBUG 01-14 20:42:32.378677.378677 lmp.py:1625]   Expert 59 |     74 | CPU
DEBUG 01-14 20:42:32.378082.378082 lmp.py:1625]   Expert  7 |     78 | CPU
DEBUG 01-14 20:42:32.378248.378248 lmp.py:1625]   Expert 36 |     90 | CPU
DEBUG 01-14 20:42:32.378414.378414 lmp.py:1625]   Expert 24 |     94 | CPU
DEBUG 01-14 20:42:32.378580.378580 lmp.py:1625]   Expert 40 |     94 | CPU
DEBUG 01-14 20:42:32.378177.378177 lmp.py:1625]   Expert 27 |     97 | CPU
DEBUG 01-14 20:42:32.378251.378251 lmp.py:1625]   Expert 17 |    100 | CPU
DEBUG 01-14 20:42:32.378655.378655 lmp.py:1625]   Expert 14 |    103 | CPU
DEBUG 01-14 20:42:32.378060.378060 lmp.py:1625]   Expert 12 |    105 | CPU
DEBUG 01-14 20:42:32.378233.378233 lmp.py:1625]   Expert  1 |    107 | CPU
DEBUG 01-14 20:42:32.378114.378114 lmp.py:1625]   Expert 18 |    108 | CPU
DEBUG 01-14 20:42:32.378519.378519 lmp.py:1625]   Expert  6 |    112 | CPU
DEBUG 01-14 20:42:32.378685.378685 lmp.py:1625]   Expert 16 |    118 | CPU
DEBUG 01-14 20:42:32.378851.378851 lmp.py:1625]   Expert 48 |    120 | CPU
DEBUG 01-14 20:42:32.378017.378017 lmp.py:1625]   Expert 32 |    127 | CPU
DEBUG 01-14 20:42:32.378183.378183 lmp.py:1625]   Expert 44 |    144 | CPU
DEBUG 01-14 20:42:32.378826.378826 lmp.py:1625]   Expert 51 |    144 | CPU
DEBUG 01-14 20:42:32.378661.378661 lmp.py:1625]   Expert  0 |    147 | CPU
DEBUG 01-14 20:42:32.378258.378258 lmp.py:1625]   Expert 53 |    154 | CPU
DEBUG 01-14 20:42:32.378901.378901 lmp.py:1625]   Expert  8 |    159 | CPU
DEBUG 01-14 20:42:32.378067.378067 lmp.py:1625]   Expert 35 |    165 | CPU
DEBUG 01-14 20:42:32.378233.378233 lmp.py:1625]   Expert 22 |    167 | CPU
DEBUG 01-14 20:42:32.378399.378399 lmp.py:1625]   Expert 42 |    169 | CPU
DEBUG 01-14 20:42:32.378327.378327 lmp.py:1625]   Expert 60 |    172 | CPU
DEBUG 01-14 20:42:32.378493.378493 lmp.py:1625]   Expert 34 |    179 | CPU
DEBUG 01-14 20:42:32.378659.378659 lmp.py:1625]   Expert 33 |    186 | CPU
DEBUG 01-14 20:42:32.378825.378825 lmp.py:1625]   Expert 29 |    187 | CPU
DEBUG 01-14 20:42:32.378753.378753 lmp.py:1625]   Expert 45 |    188 | CPU
DEBUG 01-14 20:42:32.378681.378681 lmp.py:1625]   Expert 19 |    190 | CPU
DEBUG 01-14 20:42:32.378516.378516 lmp.py:1625]   Expert 54 |    190 | GPU
DEBUG 01-14 20:42:32.378920.378920 lmp.py:1625]   Expert 47 |    192 | GPU
DEBUG 01-14 20:42:32.378848.378848 lmp.py:1625]   Expert 49 |    195 | GPU
DEBUG 01-14 20:42:32.378014.378014 lmp.py:1625]   Expert 15 |    197 | GPU
DEBUG 01-14 20:42:32.378419.378419 lmp.py:1625]   Expert 56 |    201 | GPU
DEBUG 01-14 20:42:32.378585.378585 lmp.py:1625]   Expert 28 |    203 | GPU
DEBUG 01-14 20:42:32.378513.378513 lmp.py:1625]   Expert  9 |    204 | GPU
DEBUG 01-14 20:42:32.378917.378917 lmp.py:1625]   Expert 21 |    205 | GPU
DEBUG 01-14 20:42:32.378845.378845 lmp.py:1625]   Expert  3 |    210 | GPU
DEBUG 01-14 20:42:32.378773.378773 lmp.py:1625]   Expert 13 |    211 | GPU
DEBUG 01-14 20:42:32.378939.378939 lmp.py:1625]   Expert 10 |    212 | GPU
DEBUG 01-14 20:42:32.378582.378582 lmp.py:1625]   Expert 20 |    213 | GPU
DEBUG 01-14 20:42:32.378516.378516 lmp.py:1625]   Expert 41 |    214 | GPU
DEBUG 01-14 20:42:32.378921.378921 lmp.py:1625]   Expert 46 |    217 | GPU
DEBUG 01-14 20:42:32.378895.378895 lmp.py:1625]   Expert 57 |    218 | GPU
DEBUG 01-14 20:42:32.379107.379107 lmp.py:1625]   Expert  4 |    220 | GPU
DEBUG 01-14 20:42:32.379081.379081 lmp.py:1625]   Expert 43 |    228 | GPU
DEBUG 01-14 20:42:32.379294.379294 lmp.py:1625]   Expert  2 |    231 | GPU
DEBUG 01-14 20:42:32.379268.379268 lmp.py:1625]   Expert 63 |    232 | GPU
DEBUG 01-14 20:42:32.379242.379242 lmp.py:1625]   Expert 37 |    235 | GPU
DEBUG 01-14 20:42:32.379454.379454 lmp.py:1625]   Expert 50 |    251 | GPU
DEBUG 01-14 20:42:32.379667.379667 lmp.py:1625]   Expert 61 |    266 | GPU
DEBUG 01-14 20:42:32.379879.379879 lmp.py:1625]   Expert 26 |    267 | GPU
DEBUG 01-14 20:42:32.379761.379761 lmp.py:1625]   Expert 31 |    278 | GPU
DEBUG 01-14 20:42:32.379834.379834 lmp.py:1625]   Expert 58 |    282 | GPU
DEBUG 01-14 20:42:32.379047.379047 lmp.py:1625]   Expert 52 |    305 | GPU
DEBUG 01-14 20:42:32.379021.379021 lmp.py:1625]   Expert 62 |    310 | GPU
DEBUG 01-14 20:42:32.379233.379233 lmp.py:1625]   Expert 55 |    339 | GPU
DEBUG 01-14 20:42:32.379207.379207 lmp.py:1625]   Expert 11 |    375 | GPU
DEBUG 01-14 20:42:32.379943.379943 lmp.py:1625]   Expert 23 |    412 | GPU
DEBUG 01-14 20:42:32.379917.379917 lmp.py:1625]   Expert 25 |    432 | GPU
DEBUG 01-14 20:42:32.379653.379653 lmp.py:1625]   Expert  5 |    519 | GPU
DEBUG 01-14 20:42:32.379342.379342 lmp.py:1626] 
DEBUG 01-14 20:42:32.379342.379342 lmp.py:1626]   CPU total tokens: 4024 (32.7%)
DEBUG 01-14 20:42:32.379746.379746 lmp.py:1627]   GPU total tokens: 8264 (67.3%)
DEBUG 01-14 20:42:32.379111.379111 cuda_h.py:19] end experts_map_get cost 0.0015606880187988281 seconds
DEBUG 01-14 20:42:32.379392.379392 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-14 20:42:32.379288.379288 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-14 20:42:32.379631.379631 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-14 20:42:32.382065.382065 cuda_h.py:19] end allocate_cuda_memory cost 0.0032167434692382812 seconds
DEBUG 01-14 20:42:32.383791.383791 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-14 20:42:32.383978.383978 sllm_store_c.py:27] get device uuid map
DEBUG 01-14 20:42:32.383840.383840 sllm_store_c.py:29] call client load into gpu
DEBUG 01-14 20:42:32.383920.383920 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, c59813ab-3a36-42c5-a365-45dcedeceb13
DEBUG 01-14 20:42:32.383185.383185 client.py:106] call stub.LoadModelAsync
INFO 01-14 20:42:32.383582.383582 client.py:127] Model loaded
DEBUG 01-14 20:42:32.383226.383226 cuda_h.py:10] start restore2model
DEBUG 01-14 20:42:32.383278.383278 mlpmodule.py:1367]  experts func einsum cost 0.07126355171203613 s
DEBUG 01-14 20:42:32.384832.384832 cuda_h.py:19] end restore2model cost 0.0006475448608398438 seconds
DEBUG 01-14 20:42:32.384895.384895 cuda_h.py:19] end sllm_worker_task cost 0.013054609298706055 seconds
INFO 01-14 20:42:32.384381.384381 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, c59813ab-3a36-42c5-a365-45dcedeceb13
DEBUG 01-14 20:42:32.384444.384444 cuda_h.py:19] end load_into_gpu_async cost 0.001463174819946289 seconds
DEBUG 01-14 20:42:32.384392.384392 cuda_h.py:10] start restore_tensors2
DEBUG 01-14 20:42:32.385467.385467 cuda_h.py:19] end restore_tensors2 cost 0.00041174888610839844 seconds
DEBUG 01-14 20:42:32.385025.385025 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.005574464797973633 seconds
DEBUG 01-14 20:42:32.385033.385033 cuda_h.py:10] start restore2model
DEBUG 01-14 20:42:32.387922.387922 cuda_h.py:19] end restore2model cost 0.0025904178619384766 seconds
DEBUG 01-14 20:42:32.387779.387779 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.008367300033569336 seconds
DEBUG 01-14 20:42:32.387528.387528 cuda_h.py:10] start gpu_sexperts
DEBUG 01-14 20:42:32.388757.388757 cuda_h.py:19] end gpu_sexperts cost 0.00027751922607421875 seconds
DEBUG 01-14 20:42:32.388580.388580 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-14 20:42:32.388713.388713 lmp.py:1683] 
DEBUG 01-14 20:42:32.388713.388713 lmp.py:1683]   Computing 32 experts on CPU...
DEBUG 01-14 20:42:32.388841.388841 cuda_h.py:19] end cpu_experts_submit cost 5.9604644775390625e-05 seconds
DEBUG 01-14 20:42:32.388974.388974 cuda_h.py:10] start experts_func_mgpu_group_pad
DEBUG 01-14 20:42:32.397162.397162 mlpmodule.py:1460] group tensors cost 0.00876617431640625 s
DEBUG 01-14 20:42:32.398508.398508 cuda_h.py:10] start move_flat_hidden2cpu
DEBUG 01-14 20:42:32.403676.403676 cuda_h.py:19] end experts_func_mgpu_group_pad cost 0.015547037124633789 seconds
DEBUG 01-14 20:42:32.405129.405129 cuda_h.py:19] end move_flat_hidden2cpu cost 0.007038593292236328 seconds
DEBUG 01-14 20:42:32.406384.406384 cuda_h.py:10] start gpu_group_list
DEBUG 01-14 20:42:32.407234.407234 cuda_h.py:19] end gpu_group_list cost 0.0006995201110839844 seconds
DEBUG 01-14 20:42:32.408052.408052 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-14 20:42:32.408367.408367 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.9325485229492188e-05 seconds
DEBUG 01-14 20:42:32.408821.408821 cuda_h.py:10] start wait_experts
INFO 01-14 20:42:32.408465.408465 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, c59813ab-3a36-42c5-a365-45dcedeceb13
DEBUG 01-14 20:42:32.408431.408431 mlpmodule.py:1533] pad cost 0.0035495758056640625 s
DEBUG 01-14 20:42:32.408932.408932 mlpmodule.py:1539] create cpu tensor cost 3.7670135498046875e-05 s
DEBUG 01-14 20:42:32.411399.411399 mlpmodule.py:1544] move to cpu cost 0.002238750457763672 s
DEBUG 01-14 20:42:32.421543.421543 mlpmodule.py:1558] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-14 20:42:32.421973.421973 mlpmodule.py:1559] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-14 20:42:32.421532.421532 mlpmodule.py:1564] group_w3 first element: 0.0859375
WARNING 01-14 20:42:32.421384.421384 mlpmodule.py:1574] start einsum2
INFO 01-14 20:42:32.440577.440577 client.py:127] Model loaded
DEBUG 01-14 20:42:32.440703.440703 cuda_h.py:19] end wait_experts cost 0.03221535682678223 seconds
DEBUG 01-14 20:42:32.440135.440135 cuda_h.py:10] start gpu_experts
DEBUG 01-14 20:42:32.440004.440004 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-14 20:42:32.440116.440116 mlpmodule.py:1584] group einsum cost 0.02945852279663086 s
DEBUG 01-14 20:42:32.441292.441292 mlpmodule.py:1593] cpy2cputensor cost 0.0007255077362060547 s
DEBUG 01-14 20:42:32.441260.441260 cuda_h.py:10] start move_outputs
DEBUG 01-14 20:42:32.443977.443977 cuda_h.py:19] end move_outputs cost 0.0021810531616210938 seconds
DEBUG 01-14 20:42:32.447144.447144 cuda_h.py:19] end wait_cetm_experts cost 0.006891489028930664 seconds
DEBUG 01-14 20:42:32.447956.447956 cuda_h.py:10] start gpu_group_einsum_mp_multi_list
DEBUG 01-14 20:42:32.447772.447772 cuda_h.py:10] start gpu_group_tensor
DEBUG 01-14 20:42:32.448530.448530 cuda_h.py:19] end gpu_group_tensor cost 0.0002460479736328125 seconds
DEBUG 01-14 20:42:32.448832.448832 cuda_h.py:10] start gpu_group_einsum
DEBUG 01-14 20:42:32.448422.448422 cuda_h.py:19] end gpu_group_einsum cost 0.0007658004760742188 seconds
DEBUG 01-14 20:42:32.449156.449156 cuda_h.py:10] start gpu_final_hidden_states_scatter
DEBUG 01-14 20:42:32.449344.449344 cuda_h.py:10] start all_expert_outputs_slices
DEBUG 01-14 20:42:32.449417.449417 cuda_h.py:19] end all_expert_outputs_slices cost 0.0003666877746582031 seconds
DEBUG 01-14 20:42:32.449458.449458 cuda_h.py:10] start concat_expert_out
DEBUG 01-14 20:42:32.449534.449534 cuda_h.py:19] end concat_expert_out cost 5.507469177246094e-05 seconds
DEBUG 01-14 20:42:32.449291.449291 cuda_h.py:10] start index_scatter
DEBUG 01-14 20:42:32.449433.449433 cuda_h.py:19] end index_scatter cost 7.224082946777344e-05 seconds
DEBUG 01-14 20:42:32.449050.449050 cuda_h.py:19] end gpu_final_hidden_states_scatter cost 0.0007498264312744141 seconds
DEBUG 01-14 20:42:32.449967.449967 cuda_h.py:19] end gpu_experts cost 0.009398698806762695 seconds
DEBUG 01-14 20:42:32.450862.450862 cuda_h.py:10] start all_expert_weight_slices
DEBUG 01-14 20:42:32.451757.451757 cuda_h.py:19] end all_expert_weight_slices cost 0.0009777545928955078 seconds
DEBUG 01-14 20:42:32.451116.451116 cuda_h.py:10] start cpuoutputsdeal
DEBUG 01-14 20:42:32.451137.451137 cuda_h.py:10] start index_scatter
DEBUG 01-14 20:42:32.451750.451750 cuda_h.py:19] end index_scatter cost 4.887580871582031e-05 seconds
DEBUG 01-14 20:42:32.451612.451612 cuda_h.py:19] end cpuoutputsdeal cost 0.0005466938018798828 seconds
DEBUG 01-14 20:42:32.451284.451284 cuda_h.py:19] end layer_moe_generate_mp_l_9 cost 0.07478833198547363 seconds
DEBUG 01-14 20:42:32.452330.452330 cuda_h.py:19] end prefill_layer cost 0.0812675952911377 seconds
DEBUG 01-14 20:42:32.452166.452166 lmp.py:1551] -------------------------------- end prefill layer 8 --------------------------------
DEBUG 01-14 20:42:32.452346.452346 cuda_h.py:10] start prefill_layer
DEBUG 01-14 20:42:32.452002.452002 lmp.py:1494] -------------------------------- start prefill layer 9 --------------------------------
DEBUG 01-14 20:42:32.452851.452851 cuda_h.py:10] start start_load_qkvogn_s_weight_l_10
DEBUG 01-14 20:42:32.452845.452845 cuda_h.py:10] start start_load_qkvogn_s_weight_l_10
DEBUG 01-14 20:42:32.452741.452741 cuda_h.py:19] end start_load_qkvogn_s_weight_l_10 cost 3.600120544433594e-05 seconds
DEBUG 01-14 20:42:32.452689.452689 cuda_h.py:19] end start_load_qkvogn_s_weight_l_10 cost 7.009506225585938e-05 seconds
DEBUG 01-14 20:42:32.452029.452029 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-14 20:42:32.452309.452309 cuda_h.py:10] start sllm_worker_task
DEBUG 01-14 20:42:32.452831.452831 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-14 20:42:32.452515.452515 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-14 20:42:32.452698.452698 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-14 20:42:32.453896.453896 cuda_h.py:19] end allocate_cuda_memory cost 0.0009109973907470703 seconds
DEBUG 01-14 20:42:32.453090.453090 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-14 20:42:32.453668.453668 sllm_store_c.py:27] get device uuid map
DEBUG 01-14 20:42:32.453935.453935 sllm_store_c.py:29] call client load into gpu
DEBUG 01-14 20:42:32.453644.453644 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, b069f63b-537c-4b7a-b59f-2ce15910889c
DEBUG 01-14 20:42:32.454396.454396 client.py:106] call stub.LoadModelAsync
DEBUG 01-14 20:42:32.454249.454249 cuda_h.py:10] start self_attn
INFO 01-14 20:42:32.455445.455445 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, b069f63b-537c-4b7a-b59f-2ce15910889c
DEBUG 01-14 20:42:32.455506.455506 cuda_h.py:19] end load_into_gpu_async cost 0.001674652099609375 seconds
DEBUG 01-14 20:42:32.455609.455609 cuda_h.py:10] start restore_tensors2
DEBUG 01-14 20:42:32.456473.456473 cuda_h.py:19] end restore_tensors2 cost 0.00019550323486328125 seconds
DEBUG 01-14 20:42:32.456600.456600 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0035581588745117188 seconds
INFO 01-14 20:42:32.456510.456510 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, b069f63b-537c-4b7a-b59f-2ce15910889c
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-14 20:42:32.459536.459536 cuda_h.py:19] end self_attn cost 0.0049397945404052734 seconds
DEBUG 01-14 20:42:32.459588.459588 cuda_h.py:19] end iln_self_attn_paln cost 0.007271766662597656 seconds
DEBUG 01-14 20:42:32.459206.459206 cuda_h.py:10] start layer_moe_generate_mp_l_10
DEBUG 01-14 20:42:32.459207.459207 cuda_h.py:10] start gate
DEBUG 01-14 20:42:32.460648.460648 cuda_h.py:19] end gate cost 0.000675201416015625 seconds
DEBUG 01-14 20:42:32.460868.460868 cuda_h.py:10] start experts_map_get
DEBUG 01-14 20:42:32.461634.461634 lmp.py:1615] 
DEBUG 01-14 20:42:32.461634.461634 lmp.py:1615] Expert Token Distribution & Device Allocation:
DEBUG 01-14 20:42:32.461105.461105 lmp.py:1616]   Total experts: 64
DEBUG 01-14 20:42:32.461523.461523 lmp.py:1617]   CPU experts: 32 (50%)
DEBUG 01-14 20:42:32.461312.461312 lmp.py:1618]   GPU experts: 32 (50%)
DEBUG 01-14 20:42:32.461478.461478 lmp.py:1619] 
DEBUG 01-14 20:42:32.461478.461478 lmp.py:1619]   Expert ID | Tokens | Device
DEBUG 01-14 20:42:32.461121.461121 lmp.py:1620]   -----------------------------------
DEBUG 01-14 20:42:32.461195.461195 lmp.py:1625]   Expert  2 |     41 | CPU
DEBUG 01-14 20:42:32.461123.461123 lmp.py:1625]   Expert 24 |     43 | CPU
DEBUG 01-14 20:42:32.461812.461812 lmp.py:1625]   Expert 19 |     69 | CPU
DEBUG 01-14 20:42:32.461501.461501 lmp.py:1625]   Expert 32 |     71 | CPU
DEBUG 01-14 20:42:32.461952.461952 lmp.py:1625]   Expert 26 |     72 | CPU
DEBUG 01-14 20:42:32.461357.461357 lmp.py:1625]   Expert  4 |     77 | CPU
DEBUG 01-14 20:42:32.461476.461476 lmp.py:1625]   Expert 50 |     79 | CPU
DEBUG 01-14 20:42:32.461788.461788 lmp.py:1625]   Expert 23 |     81 | CPU
DEBUG 01-14 20:42:32.461478.461478 lmp.py:1625]   Expert 59 |     82 | CPU
DEBUG 01-14 20:42:32.461458.461458 lmp.py:1625]   Expert 60 |     85 | CPU
DEBUG 01-14 20:42:32.461386.461386 lmp.py:1625]   Expert 28 |     91 | CPU
DEBUG 01-14 20:42:32.461837.461837 lmp.py:1625]   Expert  7 |    100 | CPU
DEBUG 01-14 20:42:32.461811.461811 lmp.py:1625]   Expert 15 |    103 | CPU
DEBUG 01-14 20:42:32.461024.461024 lmp.py:1625]   Expert 49 |    105 | CPU
DEBUG 01-14 20:42:32.461474.461474 lmp.py:1625]   Expert 27 |    107 | CPU
DEBUG 01-14 20:42:32.461448.461448 lmp.py:1625]   Expert 10 |    111 | CPU
DEBUG 01-14 20:42:32.461184.461184 lmp.py:1625]   Expert 12 |    114 | CPU
DEBUG 01-14 20:42:32.461350.461350 lmp.py:1625]   Expert  3 |    126 | CPU
DEBUG 01-14 20:42:32.461563.461563 lmp.py:1625]   Expert 13 |    126 | CPU
DEBUG 01-14 20:42:32.461490.461490 lmp.py:1625]   Expert  5 |    128 | CPU
DEBUG 01-14 20:42:32.461464.461464 lmp.py:1625]   Expert 20 |    130 | CPU
DEBUG 01-14 20:42:32.461439.461439 lmp.py:1625]   Expert 41 |    137 | CPU
DEBUG 01-14 20:42:32.461227.461227 lmp.py:1625]   Expert 25 |    139 | CPU
DEBUG 01-14 20:42:32.461301.461301 lmp.py:1625]   Expert 35 |    143 | CPU
DEBUG 01-14 20:42:32.461374.461374 lmp.py:1625]   Expert 37 |    144 | CPU
DEBUG 01-14 20:42:32.461971.461971 lmp.py:1625]   Expert 40 |    144 | CPU
DEBUG 01-14 20:42:32.461568.461568 lmp.py:1625]   Expert 17 |    159 | CPU
DEBUG 01-14 20:42:32.461403.461403 lmp.py:1625]   Expert 22 |    160 | CPU
DEBUG 01-14 20:42:32.461476.461476 lmp.py:1625]   Expert 47 |    160 | CPU
DEBUG 01-14 20:42:32.461550.461550 lmp.py:1625]   Expert 36 |    168 | CPU
DEBUG 01-14 20:42:32.461100.461100 lmp.py:1625]   Expert 53 |    168 | CPU
DEBUG 01-14 20:42:32.461127.461127 lmp.py:1625]   Expert 16 |    171 | CPU
DEBUG 01-14 20:42:32.461916.461916 lmp.py:1625]   Expert 52 |    178 | GPU
DEBUG 01-14 20:42:32.461751.461751 lmp.py:1625]   Expert 58 |    178 | GPU
DEBUG 01-14 20:42:32.461348.461348 lmp.py:1625]   Expert 44 |    181 | GPU
DEBUG 01-14 20:42:32.461467.461467 lmp.py:1625]   Expert 18 |    186 | GPU
DEBUG 01-14 20:42:32.461779.461779 lmp.py:1625]   Expert 39 |    189 | GPU
DEBUG 01-14 20:42:32.461091.461091 lmp.py:1625]   Expert 48 |    196 | GPU
DEBUG 01-14 20:42:32.461641.461641 lmp.py:1625]   Expert 30 |    200 | GPU
DEBUG 01-14 20:42:32.461715.461715 lmp.py:1625]   Expert 38 |    202 | GPU
DEBUG 01-14 20:42:32.461981.461981 lmp.py:1625]   Expert 45 |    202 | GPU
DEBUG 01-14 20:42:32.461008.461008 lmp.py:1625]   Expert 11 |    207 | GPU
DEBUG 01-14 20:42:32.461512.461512 lmp.py:1625]   Expert 62 |    211 | GPU
DEBUG 01-14 20:42:32.461824.461824 lmp.py:1625]   Expert 29 |    216 | GPU
DEBUG 01-14 20:42:32.461659.461659 lmp.py:1625]   Expert  1 |    217 | GPU
DEBUG 01-14 20:42:32.461255.461255 lmp.py:1625]   Expert 51 |    224 | GPU
DEBUG 01-14 20:42:32.461044.461044 lmp.py:1625]   Expert 14 |    234 | GPU
DEBUG 01-14 20:42:32.461879.461879 lmp.py:1625]   Expert 31 |    245 | GPU
DEBUG 01-14 20:42:32.462483.462483 lmp.py:1625]   Expert 34 |    255 | GPU
DEBUG 01-14 20:42:32.462033.462033 lmp.py:1625]   Expert  6 |    264 | GPU
DEBUG 01-14 20:42:32.462537.462537 lmp.py:1625]   Expert 43 |    273 | GPU
DEBUG 01-14 20:42:32.462849.462849 lmp.py:1625]   Expert 61 |    274 | GPU
DEBUG 01-14 20:42:32.462922.462922 lmp.py:1625]   Expert 33 |    290 | GPU
DEBUG 01-14 20:42:32.462473.462473 lmp.py:1625]   Expert 42 |    290 | GPU
DEBUG 01-14 20:42:32.462023.462023 lmp.py:1625]   Expert  0 |    294 | GPU
DEBUG 01-14 20:42:32.462812.462812 lmp.py:1625]   Expert 56 |    305 | GPU
DEBUG 01-14 20:42:32.462362.462362 lmp.py:1625]   Expert 57 |    315 | GPU
DEBUG 01-14 20:42:32.462674.462674 lmp.py:1625]   Expert 46 |    318 | GPU
DEBUG 01-14 20:42:32.462701.462701 lmp.py:1625]   Expert 54 |    368 | GPU
DEBUG 01-14 20:42:32.462728.462728 lmp.py:1625]   Expert  9 |    397 | GPU
DEBUG 01-14 20:42:32.462994.462994 lmp.py:1625]   Expert 63 |    403 | GPU
DEBUG 01-14 20:42:32.462829.462829 lmp.py:1625]   Expert  8 |    416 | GPU
DEBUG 01-14 20:42:32.462664.462664 lmp.py:1625]   Expert 21 |    463 | GPU
DEBUG 01-14 20:42:32.462499.462499 lmp.py:1625]   Expert 55 |    463 | GPU
DEBUG 01-14 20:42:32.462526.462526 lmp.py:1626] 
DEBUG 01-14 20:42:32.462526.462526 lmp.py:1626]   CPU total tokens: 3634 (29.6%)
DEBUG 01-14 20:42:32.462792.462792 lmp.py:1627]   GPU total tokens: 8654 (70.4%)
DEBUG 01-14 20:42:32.462587.462587 cuda_h.py:19] end experts_map_get cost 0.0016591548919677734 seconds
DEBUG 01-14 20:42:32.462060.462060 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-14 20:42:32.462294.462294 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-14 20:42:32.462729.462729 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-14 20:42:32.466048.466048 cuda_h.py:19] end allocate_cuda_memory cost 0.003356456756591797 seconds
DEBUG 01-14 20:42:32.466939.466939 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-14 20:42:32.466338.466338 sllm_store_c.py:27] get device uuid map
DEBUG 01-14 20:42:32.466922.466922 sllm_store_c.py:29] call client load into gpu
DEBUG 01-14 20:42:32.466532.466532 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 717c441d-85a2-4b50-a912-c79997a02475
DEBUG 01-14 20:42:32.466579.466579 client.py:106] call stub.LoadModelAsync
INFO 01-14 20:42:32.466138.466138 client.py:127] Model loaded
DEBUG 01-14 20:42:32.466766.466766 cuda_h.py:10] start restore2model
DEBUG 01-14 20:42:32.468096.468096 cuda_h.py:19] end restore2model cost 0.0012238025665283203 seconds
INFO 01-14 20:42:32.468277.468277 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 717c441d-85a2-4b50-a912-c79997a02475
DEBUG 01-14 20:42:32.468646.468646 cuda_h.py:19] end sllm_worker_task cost 0.015960216522216797 seconds
DEBUG 01-14 20:42:32.468658.468658 mlpmodule.py:1367]  experts func einsum cost 0.08017206192016602 s
DEBUG 01-14 20:42:32.468311.468311 cuda_h.py:19] end load_into_gpu_async cost 0.00275421142578125 seconds
DEBUG 01-14 20:42:32.469789.469789 cuda_h.py:10] start restore_tensors2
DEBUG 01-14 20:42:32.469506.469506 cuda_h.py:19] end restore_tensors2 cost 0.00041937828063964844 seconds
DEBUG 01-14 20:42:32.469025.469025 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.007182598114013672 seconds
DEBUG 01-14 20:42:32.469649.469649 cuda_h.py:10] start restore2model
DEBUG 01-14 20:42:32.472846.472846 cuda_h.py:19] end restore2model cost 0.002675294876098633 seconds
DEBUG 01-14 20:42:32.472027.472027 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.010058403015136719 seconds
DEBUG 01-14 20:42:32.472299.472299 cuda_h.py:10] start gpu_sexperts
DEBUG 01-14 20:42:32.472641.472641 cuda_h.py:19] end gpu_sexperts cost 0.00029087066650390625 seconds
DEBUG 01-14 20:42:32.472325.472325 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-14 20:42:32.472220.472220 lmp.py:1683] 
DEBUG 01-14 20:42:32.472220.472220 lmp.py:1683]   Computing 32 experts on CPU...
DEBUG 01-14 20:42:32.473401.473401 cuda_h.py:19] end cpu_experts_submit cost 6.246566772460938e-05 seconds
DEBUG 01-14 20:42:32.473342.473342 cuda_h.py:10] start experts_func_mgpu_group_pad
DEBUG 01-14 20:42:32.479257.479257 mlpmodule.py:1460] group tensors cost 0.005544900894165039 s
DEBUG 01-14 20:42:32.479159.479159 cuda_h.py:10] start move_flat_hidden2cpu
DEBUG 01-14 20:42:32.484935.484935 cuda_h.py:19] end experts_func_mgpu_group_pad cost 0.011116266250610352 seconds
DEBUG 01-14 20:42:32.486018.486018 cuda_h.py:19] end move_flat_hidden2cpu cost 0.006604671478271484 seconds
DEBUG 01-14 20:42:32.486094.486094 cuda_h.py:10] start gpu_group_list
DEBUG 01-14 20:42:32.487285.487285 cuda_h.py:19] end gpu_group_list cost 0.0006115436553955078 seconds
DEBUG 01-14 20:42:32.487227.487227 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-14 20:42:32.487145.487145 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.8848648071289062e-05 seconds
DEBUG 01-14 20:42:32.487974.487974 cuda_h.py:10] start wait_experts
INFO 01-14 20:42:32.488135.488135 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 717c441d-85a2-4b50-a912-c79997a02475
DEBUG 01-14 20:42:32.489843.489843 mlpmodule.py:1533] pad cost 0.0029163360595703125 s
DEBUG 01-14 20:42:32.489251.489251 mlpmodule.py:1539] create cpu tensor cost 3.7670135498046875e-05 s
DEBUG 01-14 20:42:32.491234.491234 mlpmodule.py:1544] move to cpu cost 0.00202178955078125 s
DEBUG 01-14 20:42:32.501172.501172 mlpmodule.py:1558] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-14 20:42:32.501250.501250 mlpmodule.py:1559] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-14 20:42:32.501372.501372 mlpmodule.py:1564] group_w3 first element: 0.0157470703125
WARNING 01-14 20:42:32.501158.501158 mlpmodule.py:1574] start einsum2
DEBUG 01-14 20:42:32.519572.519572 mlpmodule.py:1584] group einsum cost 0.028018474578857422 s
DEBUG 01-14 20:42:32.520748.520748 mlpmodule.py:1593] cpy2cputensor cost 0.0007076263427734375 s
DEBUG 01-14 20:42:32.520193.520193 cuda_h.py:10] start move_outputs
DEBUG 01-14 20:42:32.523366.523366 cuda_h.py:19] end move_outputs cost 0.0027611255645751953 seconds
INFO 01-14 20:42:32.525331.525331 client.py:127] Model loaded
DEBUG 01-14 20:42:32.526973.526973 cuda_h.py:19] end wait_experts cost 0.038066864013671875 seconds
DEBUG 01-14 20:42:32.526749.526749 cuda_h.py:10] start gpu_experts
DEBUG 01-14 20:42:32.526334.526334 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-14 20:42:32.527838.527838 cuda_h.py:19] end wait_cetm_experts cost 0.0013871192932128906 seconds
DEBUG 01-14 20:42:32.527854.527854 cuda_h.py:10] start gpu_group_einsum_mp_multi_list
DEBUG 01-14 20:42:32.527425.527425 cuda_h.py:10] start gpu_group_tensor
DEBUG 01-14 20:42:32.528613.528613 cuda_h.py:19] end gpu_group_tensor cost 0.00024700164794921875 seconds
DEBUG 01-14 20:42:32.528776.528776 cuda_h.py:10] start gpu_group_einsum
DEBUG 01-14 20:42:32.528571.528571 cuda_h.py:19] end gpu_group_einsum cost 0.0007436275482177734 seconds
DEBUG 01-14 20:42:32.529258.529258 cuda_h.py:10] start gpu_final_hidden_states_scatter
DEBUG 01-14 20:42:32.529022.529022 cuda_h.py:10] start all_expert_outputs_slices
DEBUG 01-14 20:42:32.529711.529711 cuda_h.py:19] end all_expert_outputs_slices cost 0.0003638267517089844 seconds
DEBUG 01-14 20:42:32.529752.529752 cuda_h.py:10] start concat_expert_out
DEBUG 01-14 20:42:32.529881.529881 cuda_h.py:19] end concat_expert_out cost 5.745887756347656e-05 seconds
DEBUG 01-14 20:42:32.529638.529638 cuda_h.py:10] start index_scatter
DEBUG 01-14 20:42:32.529066.529066 cuda_h.py:19] end index_scatter cost 7.104873657226562e-05 seconds
DEBUG 01-14 20:42:32.529398.529398 cuda_h.py:19] end gpu_final_hidden_states_scatter cost 0.0007536411285400391 seconds
DEBUG 01-14 20:42:32.529606.529606 cuda_h.py:19] end gpu_experts cost 0.003795623779296875 seconds
DEBUG 01-14 20:42:32.530262.530262 cuda_h.py:10] start all_expert_weight_slices
DEBUG 01-14 20:42:32.530084.530084 cuda_h.py:19] end all_expert_weight_slices cost 0.0009598731994628906 seconds
DEBUG 01-14 20:42:32.531344.531344 cuda_h.py:10] start cpuoutputsdeal
DEBUG 01-14 20:42:32.531928.531928 cuda_h.py:10] start index_scatter
DEBUG 01-14 20:42:32.531024.531024 cuda_h.py:19] end index_scatter cost 5.1975250244140625e-05 seconds
DEBUG 01-14 20:42:32.531456.531456 cuda_h.py:19] end cpuoutputsdeal cost 0.0005450248718261719 seconds
DEBUG 01-14 20:42:32.531412.531412 cuda_h.py:19] end layer_moe_generate_mp_l_10 cost 0.07178425788879395 seconds
DEBUG 01-14 20:42:32.532339.532339 cuda_h.py:19] end prefill_layer cost 0.0798788070678711 seconds
DEBUG 01-14 20:42:32.532712.532712 lmp.py:1551] -------------------------------- end prefill layer 9 --------------------------------
DEBUG 01-14 20:42:32.532892.532892 cuda_h.py:10] start prefill_layer
DEBUG 01-14 20:42:32.532072.532072 lmp.py:1494] -------------------------------- start prefill layer 10 --------------------------------
DEBUG 01-14 20:42:32.532920.532920 cuda_h.py:10] start start_load_qkvogn_s_weight_l_11
DEBUG 01-14 20:42:32.532153.532153 cuda_h.py:10] start start_load_qkvogn_s_weight_l_11
DEBUG 01-14 20:42:32.532433.532433 cuda_h.py:19] end start_load_qkvogn_s_weight_l_11 cost 3.814697265625e-05 seconds
DEBUG 01-14 20:42:32.532997.532997 cuda_h.py:19] end start_load_qkvogn_s_weight_l_11 cost 6.937980651855469e-05 seconds
DEBUG 01-14 20:42:32.532482.532482 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-14 20:42:32.532287.532287 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-14 20:42:32.532967.532967 cuda_h.py:10] start sllm_worker_task
DEBUG 01-14 20:42:32.532056.532056 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-14 20:42:32.533009.533009 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-14 20:42:32.534636.534636 cuda_h.py:19] end allocate_cuda_memory cost 0.0010142326354980469 seconds
DEBUG 01-14 20:42:32.534597.534597 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-14 20:42:32.534760.534760 sllm_store_c.py:27] get device uuid map
DEBUG 01-14 20:42:32.534520.534520 sllm_store_c.py:29] call client load into gpu
DEBUG 01-14 20:42:32.534589.534589 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 2de5438e-fbb8-4fa3-9e3b-ab49222c7393
DEBUG 01-14 20:42:32.535510.535510 client.py:106] call stub.LoadModelAsync
DEBUG 01-14 20:42:32.535315.535315 cuda_h.py:10] start self_attn
INFO 01-14 20:42:32.536532.536532 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 2de5438e-fbb8-4fa3-9e3b-ab49222c7393
DEBUG 01-14 20:42:32.536448.536448 cuda_h.py:19] end load_into_gpu_async cost 0.0015721321105957031 seconds
DEBUG 01-14 20:42:32.536443.536443 cuda_h.py:10] start restore_tensors2
DEBUG 01-14 20:42:32.536851.536851 cuda_h.py:19] end restore_tensors2 cost 9.5367431640625e-05 seconds
DEBUG 01-14 20:42:32.536713.536713 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.003281116485595703 seconds
INFO 01-14 20:42:32.536576.536576 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 2de5438e-fbb8-4fa3-9e3b-ab49222c7393
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-14 20:42:32.538778.538778 cuda_h.py:19] end self_attn cost 0.0032165050506591797 seconds
DEBUG 01-14 20:42:32.538643.538643 cuda_h.py:19] end iln_self_attn_paln cost 0.006540536880493164 seconds
DEBUG 01-14 20:42:32.539916.539916 cuda_h.py:10] start layer_moe_generate_mp_l_11
DEBUG 01-14 20:42:32.539487.539487 cuda_h.py:10] start gate
DEBUG 01-14 20:42:32.539987.539987 cuda_h.py:19] end gate cost 0.0006499290466308594 seconds
DEBUG 01-14 20:42:32.539439.539439 cuda_h.py:10] start experts_map_get
DEBUG 01-14 20:42:32.540098.540098 lmp.py:1615] 
DEBUG 01-14 20:42:32.540098.540098 lmp.py:1615] Expert Token Distribution & Device Allocation:
DEBUG 01-14 20:42:32.540530.540530 lmp.py:1616]   Total experts: 64
DEBUG 01-14 20:42:32.540518.540518 lmp.py:1617]   CPU experts: 32 (50%)
DEBUG 01-14 20:42:32.540214.540214 lmp.py:1618]   GPU experts: 32 (50%)
DEBUG 01-14 20:42:32.540049.540049 lmp.py:1619] 
DEBUG 01-14 20:42:32.540049.540049 lmp.py:1619]   Expert ID | Tokens | Device
DEBUG 01-14 20:42:32.540076.540076 lmp.py:1620]   -----------------------------------
DEBUG 01-14 20:42:32.540818.540818 lmp.py:1625]   Expert 43 |     18 | CPU
DEBUG 01-14 20:42:32.540084.540084 lmp.py:1625]   Expert 27 |     35 | CPU
DEBUG 01-14 20:42:32.540483.540483 lmp.py:1625]   Expert 26 |     46 | CPU
DEBUG 01-14 20:42:32.540656.540656 lmp.py:1625]   Expert  3 |     56 | CPU
DEBUG 01-14 20:42:32.540405.540405 lmp.py:1625]   Expert 34 |     59 | CPU
DEBUG 01-14 20:42:32.540698.540698 lmp.py:1625]   Expert 56 |     79 | CPU
DEBUG 01-14 20:42:32.540679.540679 lmp.py:1625]   Expert 61 |     87 | CPU
DEBUG 01-14 20:42:32.540706.540706 lmp.py:1625]   Expert  4 |     96 | CPU
DEBUG 01-14 20:42:32.540256.540256 lmp.py:1625]   Expert  7 |    105 | CPU
DEBUG 01-14 20:42:32.540091.540091 lmp.py:1625]   Expert 38 |    105 | CPU
DEBUG 01-14 20:42:32.540642.540642 lmp.py:1625]   Expert 14 |    108 | CPU
DEBUG 01-14 20:42:32.540715.540715 lmp.py:1625]   Expert 22 |    119 | CPU
DEBUG 01-14 20:42:32.540265.540265 lmp.py:1625]   Expert  5 |    120 | CPU
DEBUG 01-14 20:42:32.540862.540862 lmp.py:1625]   Expert 47 |    122 | CPU
DEBUG 01-14 20:42:32.540174.540174 lmp.py:1625]   Expert  2 |    123 | CPU
DEBUG 01-14 20:42:32.540201.540201 lmp.py:1625]   Expert 45 |    132 | CPU
DEBUG 01-14 20:42:32.540513.540513 lmp.py:1625]   Expert 17 |    134 | CPU
DEBUG 01-14 20:42:32.540063.540063 lmp.py:1625]   Expert 48 |    135 | CPU
DEBUG 01-14 20:42:32.540852.540852 lmp.py:1625]   Expert 54 |    135 | CPU
DEBUG 01-14 20:42:32.540164.540164 lmp.py:1625]   Expert 51 |    136 | CPU
DEBUG 01-14 20:42:32.540476.540476 lmp.py:1625]   Expert 19 |    143 | CPU
DEBUG 01-14 20:42:32.540834.540834 lmp.py:1625]   Expert 55 |    148 | CPU
DEBUG 01-14 20:42:32.540908.540908 lmp.py:1625]   Expert 63 |    151 | CPU
DEBUG 01-14 20:42:32.540981.540981 lmp.py:1625]   Expert 15 |    152 | CPU
DEBUG 01-14 20:42:32.540578.540578 lmp.py:1625]   Expert 57 |    152 | CPU
DEBUG 01-14 20:42:32.540651.540651 lmp.py:1625]   Expert 28 |    153 | CPU
DEBUG 01-14 20:42:32.540725.540725 lmp.py:1625]   Expert 37 |    161 | CPU
DEBUG 01-14 20:42:32.540037.540037 lmp.py:1625]   Expert 12 |    162 | CPU
DEBUG 01-14 20:42:32.540349.540349 lmp.py:1625]   Expert 18 |    168 | CPU
DEBUG 01-14 20:42:32.540184.540184 lmp.py:1625]   Expert 60 |    170 | CPU
DEBUG 01-14 20:42:32.540019.540019 lmp.py:1625]   Expert 50 |    174 | CPU
DEBUG 01-14 20:42:32.540377.540377 lmp.py:1625]   Expert  6 |    182 | CPU
DEBUG 01-14 20:42:32.540974.540974 lmp.py:1625]   Expert 44 |    191 | GPU
DEBUG 01-14 20:42:32.540332.540332 lmp.py:1625]   Expert 52 |    192 | GPU
DEBUG 01-14 20:42:32.540690.540690 lmp.py:1625]   Expert 31 |    194 | GPU
DEBUG 01-14 20:42:32.541525.541525 lmp.py:1625]   Expert 39 |    194 | GPU
DEBUG 01-14 20:42:32.541599.541599 lmp.py:1625]   Expert 23 |    195 | GPU
DEBUG 01-14 20:42:32.541672.541672 lmp.py:1625]   Expert 53 |    195 | GPU
DEBUG 01-14 20:42:32.541984.541984 lmp.py:1625]   Expert 30 |    200 | GPU
DEBUG 01-14 20:42:32.541057.541057 lmp.py:1625]   Expert 29 |    202 | GPU
DEBUG 01-14 20:42:32.541369.541369 lmp.py:1625]   Expert 21 |    207 | GPU
DEBUG 01-14 20:42:32.541966.541966 lmp.py:1625]   Expert 13 |    212 | GPU
DEBUG 01-14 20:42:32.541324.541324 lmp.py:1625]   Expert 42 |    214 | GPU
DEBUG 01-14 20:42:32.541444.541444 lmp.py:1625]   Expert 16 |    215 | GPU
DEBUG 01-14 20:42:32.541041.541041 lmp.py:1625]   Expert 36 |    216 | GPU
DEBUG 01-14 20:42:32.541876.541876 lmp.py:1625]   Expert 20 |    217 | GPU
DEBUG 01-14 20:42:32.541188.541188 lmp.py:1625]   Expert 41 |    225 | GPU
DEBUG 01-14 20:42:32.541261.541261 lmp.py:1625]   Expert 49 |    227 | GPU
DEBUG 01-14 20:42:32.541050.541050 lmp.py:1625]   Expert 25 |    230 | GPU
DEBUG 01-14 20:42:32.541647.541647 lmp.py:1625]   Expert 59 |    230 | GPU
DEBUG 01-14 20:42:32.541720.541720 lmp.py:1625]   Expert 11 |    232 | GPU
DEBUG 01-14 20:42:32.541555.541555 lmp.py:1625]   Expert  8 |    233 | GPU
DEBUG 01-14 20:42:32.541913.541913 lmp.py:1625]   Expert 10 |    248 | GPU
DEBUG 01-14 20:42:32.541272.541272 lmp.py:1625]   Expert 33 |    250 | GPU
DEBUG 01-14 20:42:32.541107.541107 lmp.py:1625]   Expert 32 |    256 | GPU
DEBUG 01-14 20:42:32.541942.541942 lmp.py:1625]   Expert 46 |    265 | GPU
DEBUG 01-14 20:42:32.541015.541015 lmp.py:1625]   Expert 58 |    277 | GPU
DEBUG 01-14 20:42:32.541135.541135 lmp.py:1625]   Expert 35 |    299 | GPU
DEBUG 01-14 20:42:32.541447.541447 lmp.py:1625]   Expert 62 |    306 | GPU
DEBUG 01-14 20:42:32.541851.541851 lmp.py:1625]   Expert  9 |    324 | GPU
DEBUG 01-14 20:42:32.541686.541686 lmp.py:1625]   Expert  0 |    393 | GPU
DEBUG 01-14 20:42:32.541614.541614 lmp.py:1625]   Expert 40 |    414 | GPU
DEBUG 01-14 20:42:32.541496.541496 lmp.py:1625]   Expert 24 |    547 | GPU
DEBUG 01-14 20:42:32.541423.541423 lmp.py:1625]   Expert  1 |    622 | GPU
DEBUG 01-14 20:42:32.541735.541735 lmp.py:1626] 
DEBUG 01-14 20:42:32.541735.541735 lmp.py:1626]   CPU total tokens: 3866 (31.5%)
DEBUG 01-14 20:42:32.541093.541093 lmp.py:1627]   GPU total tokens: 8422 (68.5%)
DEBUG 01-14 20:42:32.541366.541366 cuda_h.py:19] end experts_map_get cost 0.0017421245574951172 seconds
DEBUG 01-14 20:42:32.541083.541083 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-14 20:42:32.541033.541033 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-14 20:42:32.541276.541276 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-14 20:42:32.547835.547835 cuda_h.py:19] end allocate_cuda_memory cost 0.0057828426361083984 seconds
DEBUG 01-14 20:42:32.547083.547083 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-14 20:42:32.547442.547442 sllm_store_c.py:27] get device uuid map
DEBUG 01-14 20:42:32.547272.547272 sllm_store_c.py:29] call client load into gpu
DEBUG 01-14 20:42:32.547643.547643 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 1d999ffd-c070-4921-923a-05d3d8023e9d
DEBUG 01-14 20:42:32.548095.548095 client.py:106] call stub.LoadModelAsync
INFO 01-14 20:42:32.548240.548240 client.py:127] Model loaded
DEBUG 01-14 20:42:32.548932.548932 cuda_h.py:10] start restore2model
DEBUG 01-14 20:42:32.549588.549588 cuda_h.py:19] end restore2model cost 0.0005645751953125 seconds
DEBUG 01-14 20:42:32.549922.549922 cuda_h.py:19] end sllm_worker_task cost 0.01619577407836914 seconds
DEBUG 01-14 20:42:32.549111.549111 mlpmodule.py:1367]  experts func einsum cost 0.07575249671936035 s
INFO 01-14 20:42:32.550372.550372 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 1d999ffd-c070-4921-923a-05d3d8023e9d
DEBUG 01-14 20:42:32.550402.550402 cuda_h.py:19] end load_into_gpu_async cost 0.0023543834686279297 seconds
DEBUG 01-14 20:42:32.550635.550635 cuda_h.py:10] start restore_tensors2
DEBUG 01-14 20:42:32.550284.550284 cuda_h.py:19] end restore_tensors2 cost 0.0003809928894042969 seconds
DEBUG 01-14 20:42:32.550412.550412 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.008928298950195312 seconds
DEBUG 01-14 20:42:32.550791.550791 cuda_h.py:10] start restore2model
DEBUG 01-14 20:42:32.553879.553879 cuda_h.py:19] end restore2model cost 0.002598285675048828 seconds
DEBUG 01-14 20:42:32.553814.553814 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.011704444885253906 seconds
DEBUG 01-14 20:42:32.553371.553371 cuda_h.py:10] start gpu_sexperts
DEBUG 01-14 20:42:32.553429.553429 cuda_h.py:19] end gpu_sexperts cost 0.00029158592224121094 seconds
DEBUG 01-14 20:42:32.553656.553656 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-14 20:42:32.553836.553836 lmp.py:1683] 
DEBUG 01-14 20:42:32.553836.553836 lmp.py:1683]   Computing 32 experts on CPU...
DEBUG 01-14 20:42:32.553725.553725 cuda_h.py:19] end cpu_experts_submit cost 5.8650970458984375e-05 seconds
DEBUG 01-14 20:42:32.553620.553620 cuda_h.py:10] start experts_func_mgpu_group_pad
DEBUG 01-14 20:42:32.563247.563247 mlpmodule.py:1460] group tensors cost 0.008852243423461914 s
DEBUG 01-14 20:42:32.563750.563750 cuda_h.py:10] start move_flat_hidden2cpu
DEBUG 01-14 20:42:32.566525.566525 cuda_h.py:19] end experts_func_mgpu_group_pad cost 0.012339115142822266 seconds
DEBUG 01-14 20:42:32.568397.568397 cuda_h.py:10] start gpu_group_list
DEBUG 01-14 20:42:32.569777.569777 cuda_h.py:19] end gpu_group_list cost 0.0005438327789306641 seconds
DEBUG 01-14 20:42:32.569752.569752 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-14 20:42:32.569385.569385 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 3.337860107421875e-05 seconds
DEBUG 01-14 20:42:32.569254.569254 cuda_h.py:10] start wait_experts
INFO 01-14 20:42:32.569407.569407 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 1d999ffd-c070-4921-923a-05d3d8023e9d
DEBUG 01-14 20:42:32.571837.571837 cuda_h.py:19] end move_flat_hidden2cpu cost 0.007269382476806641 seconds
DEBUG 01-14 20:42:32.572158.572158 mlpmodule.py:1533] pad cost 0.0015652179718017578 s
DEBUG 01-14 20:42:32.572870.572870 mlpmodule.py:1539] create cpu tensor cost 3.743171691894531e-05 s
DEBUG 01-14 20:42:32.575731.575731 mlpmodule.py:1544] move to cpu cost 0.002146005630493164 s
DEBUG 01-14 20:42:32.585085.585085 mlpmodule.py:1558] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-14 20:42:32.585640.585640 mlpmodule.py:1559] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-14 20:42:32.586669.586669 mlpmodule.py:1564] group_w3 first element: -0.0213623046875
WARNING 01-14 20:42:32.586640.586640 mlpmodule.py:1574] start einsum2
DEBUG 01-14 20:42:32.605478.605478 mlpmodule.py:1584] group einsum cost 0.03051614761352539 s
DEBUG 01-14 20:42:32.606232.606232 mlpmodule.py:1593] cpy2cputensor cost 0.0007748603820800781 s
DEBUG 01-14 20:42:32.606267.606267 cuda_h.py:10] start move_outputs
INFO 01-14 20:42:32.606069.606069 client.py:127] Model loaded
DEBUG 01-14 20:42:32.607757.607757 cuda_h.py:19] end wait_experts cost 0.03752899169921875 seconds
DEBUG 01-14 20:42:32.607388.607388 cuda_h.py:10] start gpu_experts
DEBUG 01-14 20:42:32.607495.607495 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-14 20:42:32.608432.608432 cuda_h.py:19] end move_outputs cost 0.002104520797729492 seconds
DEBUG 01-14 20:42:32.612177.612177 cuda_h.py:19] end wait_cetm_experts cost 0.005268096923828125 seconds
DEBUG 01-14 20:42:32.612194.612194 cuda_h.py:10] start gpu_group_einsum_mp_multi_list
DEBUG 01-14 20:42:32.612910.612910 cuda_h.py:10] start gpu_group_tensor
DEBUG 01-14 20:42:32.612675.612675 cuda_h.py:19] end gpu_group_tensor cost 0.0002498626708984375 seconds
DEBUG 01-14 20:42:32.613315.613315 cuda_h.py:10] start gpu_group_einsum
DEBUG 01-14 20:42:32.613645.613645 cuda_h.py:19] end gpu_group_einsum cost 0.0007154941558837891 seconds
DEBUG 01-14 20:42:32.613710.613710 cuda_h.py:10] start gpu_final_hidden_states_scatter
DEBUG 01-14 20:42:32.614182.614182 cuda_h.py:10] start all_expert_outputs_slices
DEBUG 01-14 20:42:32.614249.614249 cuda_h.py:19] end all_expert_outputs_slices cost 0.0003616809844970703 seconds
DEBUG 01-14 20:42:32.614051.614051 cuda_h.py:10] start concat_expert_out
DEBUG 01-14 20:42:32.614465.614465 cuda_h.py:19] end concat_expert_out cost 5.7220458984375e-05 seconds
DEBUG 01-14 20:42:32.614314.614314 cuda_h.py:10] start index_scatter
DEBUG 01-14 20:42:32.614219.614219 cuda_h.py:19] end index_scatter cost 7.2479248046875e-05 seconds
DEBUG 01-14 20:42:32.614789.614789 cuda_h.py:19] end gpu_final_hidden_states_scatter cost 0.0007469654083251953 seconds
DEBUG 01-14 20:42:32.614613.614613 cuda_h.py:19] end gpu_experts cost 0.007686138153076172 seconds
DEBUG 01-14 20:42:32.614508.614508 cuda_h.py:10] start all_expert_weight_slices
DEBUG 01-14 20:42:32.615907.615907 cuda_h.py:19] end all_expert_weight_slices cost 0.0009953975677490234 seconds
DEBUG 01-14 20:42:32.615373.615373 cuda_h.py:10] start cpuoutputsdeal
DEBUG 01-14 20:42:32.616845.616845 cuda_h.py:10] start index_scatter
DEBUG 01-14 20:42:32.616656.616656 cuda_h.py:19] end index_scatter cost 5.173683166503906e-05 seconds
DEBUG 01-14 20:42:32.616757.616757 cuda_h.py:19] end cpuoutputsdeal cost 0.0005700588226318359 seconds
DEBUG 01-14 20:42:32.616773.616773 cuda_h.py:19] end layer_moe_generate_mp_l_11 cost 0.07756590843200684 seconds
DEBUG 01-14 20:42:32.617892.617892 cuda_h.py:19] end prefill_layer cost 0.08483505249023438 seconds
DEBUG 01-14 20:42:32.617444.617444 lmp.py:1551] -------------------------------- end prefill layer 10 --------------------------------
DEBUG 01-14 20:42:32.617385.617385 cuda_h.py:10] start prefill_layer
DEBUG 01-14 20:42:32.617572.617572 lmp.py:1494] -------------------------------- start prefill layer 11 --------------------------------
DEBUG 01-14 20:42:32.617897.617897 cuda_h.py:10] start start_load_qkvogn_s_weight_l_12
DEBUG 01-14 20:42:32.617415.617415 cuda_h.py:10] start start_load_qkvogn_s_weight_l_12
DEBUG 01-14 20:42:32.617218.617218 cuda_h.py:19] end start_load_qkvogn_s_weight_l_12 cost 3.814697265625e-05 seconds
DEBUG 01-14 20:42:32.617166.617166 cuda_h.py:19] end start_load_qkvogn_s_weight_l_12 cost 7.200241088867188e-05 seconds
DEBUG 01-14 20:42:32.617069.617069 cuda_h.py:10] start sllm_worker_task
DEBUG 01-14 20:42:32.617376.617376 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-14 20:42:32.617882.617882 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-14 20:42:32.617515.617515 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-14 20:42:32.619461.619461 cuda_h.py:19] end allocate_cuda_memory cost 0.0014972686767578125 seconds
DEBUG 01-14 20:42:32.619702.619702 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-14 20:42:32.619610.619610 sllm_store_c.py:27] get device uuid map
DEBUG 01-14 20:42:32.619685.619685 sllm_store_c.py:29] call client load into gpu
DEBUG 01-14 20:42:32.619110.619110 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, eacab6dc-6cb8-47f1-8ee4-0dfa0c47e88c
DEBUG 01-14 20:42:32.619961.619961 client.py:106] call stub.LoadModelAsync
DEBUG 01-14 20:42:32.619106.619106 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-14 20:42:32.620283.620283 cuda_h.py:10] start self_attn
INFO 01-14 20:42:32.620802.620802 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, eacab6dc-6cb8-47f1-8ee4-0dfa0c47e88c
DEBUG 01-14 20:42:32.620646.620646 cuda_h.py:19] end load_into_gpu_async cost 0.0012543201446533203 seconds
DEBUG 01-14 20:42:32.620494.620494 cuda_h.py:10] start restore_tensors2
DEBUG 01-14 20:42:32.620419.620419 cuda_h.py:19] end restore_tensors2 cost 8.487701416015625e-05 seconds
DEBUG 01-14 20:42:32.620850.620850 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0031158924102783203 seconds
INFO 01-14 20:42:32.620661.620661 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, eacab6dc-6cb8-47f1-8ee4-0dfa0c47e88c
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-14 20:42:32.623110.623110 cuda_h.py:19] end self_attn cost 0.003077983856201172 seconds
DEBUG 01-14 20:42:32.623399.623399 cuda_h.py:19] end iln_self_attn_paln cost 0.005869150161743164 seconds
DEBUG 01-14 20:42:32.623526.623526 cuda_h.py:10] start layer_moe_generate_mp_l_12
DEBUG 01-14 20:42:32.623335.623335 cuda_h.py:10] start gate
DEBUG 01-14 20:42:32.624014.624014 cuda_h.py:19] end gate cost 0.0006413459777832031 seconds
DEBUG 01-14 20:42:32.624989.624989 cuda_h.py:10] start experts_map_get
DEBUG 01-14 20:42:32.624146.624146 lmp.py:1615] 
DEBUG 01-14 20:42:32.624146.624146 lmp.py:1615] Expert Token Distribution & Device Allocation:
DEBUG 01-14 20:42:32.624286.624286 lmp.py:1616]   Total experts: 64
DEBUG 01-14 20:42:32.624651.624651 lmp.py:1617]   CPU experts: 32 (50%)
DEBUG 01-14 20:42:32.624201.624201 lmp.py:1618]   GPU experts: 32 (50%)
DEBUG 01-14 20:42:32.624844.624844 lmp.py:1619] 
DEBUG 01-14 20:42:32.624844.624844 lmp.py:1619]   Expert ID | Tokens | Device
DEBUG 01-14 20:42:32.624964.624964 lmp.py:1620]   -----------------------------------
DEBUG 01-14 20:42:32.624753.624753 lmp.py:1625]   Expert 39 |     14 | CPU
DEBUG 01-14 20:42:32.624157.624157 lmp.py:1625]   Expert 13 |     23 | CPU
DEBUG 01-14 20:42:32.624085.624085 lmp.py:1625]   Expert 49 |     37 | CPU
DEBUG 01-14 20:42:32.624013.624013 lmp.py:1625]   Expert  9 |     59 | CPU
DEBUG 01-14 20:42:32.624702.624702 lmp.py:1625]   Expert 19 |     62 | CPU
DEBUG 01-14 20:42:32.624914.624914 lmp.py:1625]   Expert 26 |     65 | CPU
DEBUG 01-14 20:42:32.624365.624365 lmp.py:1625]   Expert 35 |     70 | CPU
DEBUG 01-14 20:42:32.624578.624578 lmp.py:1625]   Expert 33 |     72 | CPU
DEBUG 01-14 20:42:32.624790.624790 lmp.py:1625]   Expert 46 |     73 | CPU
DEBUG 01-14 20:42:32.624956.624956 lmp.py:1625]   Expert 32 |     82 | CPU
DEBUG 01-14 20:42:32.624884.624884 lmp.py:1625]   Expert 23 |     86 | CPU
DEBUG 01-14 20:42:32.624050.624050 lmp.py:1625]   Expert 41 |     86 | CPU
DEBUG 01-14 20:42:32.624216.624216 lmp.py:1625]   Expert 31 |     99 | CPU
DEBUG 01-14 20:42:32.624382.624382 lmp.py:1625]   Expert 17 |    101 | CPU
DEBUG 01-14 20:42:32.624072.624072 lmp.py:1625]   Expert 18 |    104 | CPU
DEBUG 01-14 20:42:32.624284.624284 lmp.py:1625]   Expert  6 |    108 | CPU
DEBUG 01-14 20:42:32.625497.625497 lmp.py:1625]   Expert  3 |    114 | CPU
DEBUG 01-14 20:42:32.625709.625709 lmp.py:1625]   Expert 38 |    119 | CPU
DEBUG 01-14 20:42:32.625160.625160 lmp.py:1625]   Expert 50 |    121 | CPU
DEBUG 01-14 20:42:32.625134.625134 lmp.py:1625]   Expert 40 |    124 | CPU
DEBUG 01-14 20:42:32.625347.625347 lmp.py:1625]   Expert 15 |    129 | CPU
DEBUG 01-14 20:42:32.625797.625797 lmp.py:1625]   Expert 20 |    129 | CPU
DEBUG 01-14 20:42:32.625248.625248 lmp.py:1625]   Expert 63 |    131 | CPU
DEBUG 01-14 20:42:32.625176.625176 lmp.py:1625]   Expert 62 |    137 | CPU
DEBUG 01-14 20:42:32.625104.625104 lmp.py:1625]   Expert 61 |    139 | CPU
DEBUG 01-14 20:42:32.625793.625793 lmp.py:1625]   Expert 36 |    146 | CPU
DEBUG 01-14 20:42:32.625721.625721 lmp.py:1625]   Expert  2 |    147 | CPU
DEBUG 01-14 20:42:32.625317.625317 lmp.py:1625]   Expert 43 |    147 | CPU
DEBUG 01-14 20:42:32.625722.625722 lmp.py:1625]   Expert 42 |    151 | CPU
DEBUG 01-14 20:42:32.625888.625888 lmp.py:1625]   Expert 10 |    159 | CPU
DEBUG 01-14 20:42:32.625816.625816 lmp.py:1625]   Expert 44 |    159 | CPU
DEBUG 01-14 20:42:32.625982.625982 lmp.py:1625]   Expert 16 |    162 | CPU
DEBUG 01-14 20:42:32.625148.625148 lmp.py:1625]   Expert  5 |    173 | GPU
DEBUG 01-14 20:42:32.625314.625314 lmp.py:1625]   Expert 56 |    176 | GPU
DEBUG 01-14 20:42:32.625242.625242 lmp.py:1625]   Expert 59 |    176 | GPU
DEBUG 01-14 20:42:32.625123.625123 lmp.py:1625]   Expert 34 |    195 | GPU
DEBUG 01-14 20:42:32.625528.625528 lmp.py:1625]   Expert 45 |    195 | GPU
DEBUG 01-14 20:42:32.625648.625648 lmp.py:1625]   Expert 52 |    197 | GPU
DEBUG 01-14 20:42:32.625529.625529 lmp.py:1625]   Expert 60 |    202 | GPU
DEBUG 01-14 20:42:32.625603.625603 lmp.py:1625]   Expert 27 |    205 | GPU
DEBUG 01-14 20:42:32.625915.625915 lmp.py:1625]   Expert 51 |    213 | GPU
DEBUG 01-14 20:42:32.625842.625842 lmp.py:1625]   Expert 24 |    218 | GPU
DEBUG 01-14 20:42:32.625770.625770 lmp.py:1625]   Expert 48 |    224 | GPU
DEBUG 01-14 20:42:32.625698.625698 lmp.py:1625]   Expert 53 |    225 | GPU
DEBUG 01-14 20:42:32.625387.625387 lmp.py:1625]   Expert 47 |    243 | GPU
DEBUG 01-14 20:42:32.625315.625315 lmp.py:1625]   Expert  7 |    250 | GPU
DEBUG 01-14 20:42:32.625196.625196 lmp.py:1625]   Expert  8 |    251 | GPU
DEBUG 01-14 20:42:32.625554.625554 lmp.py:1625]   Expert 29 |    263 | GPU
DEBUG 01-14 20:42:32.625913.625913 lmp.py:1625]   Expert 21 |    269 | GPU
DEBUG 01-14 20:42:32.625509.625509 lmp.py:1625]   Expert 58 |    273 | GPU
DEBUG 01-14 20:42:32.625867.625867 lmp.py:1625]   Expert 57 |    281 | GPU
DEBUG 01-14 20:42:32.625987.625987 lmp.py:1625]   Expert 14 |    290 | GPU
DEBUG 01-14 20:42:32.625869.625869 lmp.py:1625]   Expert 37 |    295 | GPU
DEBUG 01-14 20:42:32.625273.625273 lmp.py:1625]   Expert  1 |    297 | GPU
DEBUG 01-14 20:42:32.625214.625214 lmp.py:1625]   Expert 11 |    299 | GPU
DEBUG 01-14 20:42:32.625096.625096 lmp.py:1625]   Expert  0 |    308 | GPU
DEBUG 01-14 20:42:32.625454.625454 lmp.py:1625]   Expert  4 |    308 | GPU
DEBUG 01-14 20:42:32.625336.625336 lmp.py:1625]   Expert 22 |    309 | GPU
DEBUG 01-14 20:42:32.625694.625694 lmp.py:1625]   Expert 55 |    327 | GPU
DEBUG 01-14 20:42:32.625290.625290 lmp.py:1625]   Expert 54 |    331 | GPU
DEBUG 01-14 20:42:32.625887.625887 lmp.py:1625]   Expert 25 |    363 | GPU
DEBUG 01-14 20:42:32.625722.625722 lmp.py:1625]   Expert 12 |    412 | GPU
DEBUG 01-14 20:42:32.625365.625365 lmp.py:1625]   Expert 28 |    412 | GPU
DEBUG 01-14 20:42:32.625485.625485 lmp.py:1625]   Expert 30 |    753 | GPU
DEBUG 01-14 20:42:32.625558.625558 lmp.py:1626] 
DEBUG 01-14 20:42:32.625558.625558 lmp.py:1626]   CPU total tokens: 3355 (27.3%)
DEBUG 01-14 20:42:32.625393.625393 lmp.py:1627]   GPU total tokens: 8933 (72.7%)
DEBUG 01-14 20:42:32.625758.625758 cuda_h.py:19] end experts_map_get cost 0.0015909671783447266 seconds
DEBUG 01-14 20:42:32.625092.625092 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-14 20:42:32.626280.626280 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-14 20:42:32.626708.626708 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-14 20:42:32.627163.627163 cuda_h.py:19] end allocate_cuda_memory cost 0.0016682147979736328 seconds
DEBUG 01-14 20:42:32.627966.627966 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-14 20:42:32.627630.627630 sllm_store_c.py:27] get device uuid map
DEBUG 01-14 20:42:32.628300.628300 sllm_store_c.py:29] call client load into gpu
DEBUG 01-14 20:42:32.628049.628049 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 2f34d027-d5c3-46cb-bc01-fdf2e3e0481d
DEBUG 01-14 20:42:32.628698.628698 client.py:106] call stub.LoadModelAsync
INFO 01-14 20:42:32.628667.628667 client.py:127] Model loaded
DEBUG 01-14 20:42:32.628602.628602 cuda_h.py:10] start restore2model
DEBUG 01-14 20:42:32.628237.628237 cuda_h.py:19] end restore2model cost 0.0003299713134765625 seconds
DEBUG 01-14 20:42:32.628099.628099 cuda_h.py:19] end sllm_worker_task cost 0.011445045471191406 seconds
INFO 01-14 20:42:32.629649.629649 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 2f34d027-d5c3-46cb-bc01-fdf2e3e0481d
DEBUG 01-14 20:42:32.629161.629161 cuda_h.py:19] end load_into_gpu_async cost 0.0012328624725341797 seconds
DEBUG 01-14 20:42:32.629579.629579 cuda_h.py:10] start restore_tensors2
DEBUG 01-14 20:42:32.629779.629779 cuda_h.py:19] end restore_tensors2 cost 0.00040078163146972656 seconds
DEBUG 01-14 20:42:32.629622.629622 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0036666393280029297 seconds
DEBUG 01-14 20:42:32.629007.629007 cuda_h.py:10] start restore2model
DEBUG 01-14 20:42:32.632736.632736 cuda_h.py:19] end restore2model cost 0.002543926239013672 seconds
DEBUG 01-14 20:42:32.632865.632865 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.00641942024230957 seconds
DEBUG 01-14 20:42:32.632137.632137 cuda_h.py:10] start gpu_sexperts
DEBUG 01-14 20:42:32.632181.632181 cuda_h.py:19] end gpu_sexperts cost 0.0002808570861816406 seconds
DEBUG 01-14 20:42:32.632672.632672 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-14 20:42:32.632521.632521 lmp.py:1683] 
DEBUG 01-14 20:42:32.632521.632521 lmp.py:1683]   Computing 32 experts on CPU...
DEBUG 01-14 20:42:32.632019.632019 cuda_h.py:19] end cpu_experts_submit cost 5.221366882324219e-05 seconds
DEBUG 01-14 20:42:32.632577.632577 cuda_h.py:10] start experts_func_mgpu_group_pad
DEBUG 01-14 20:42:32.634053.634053 cuda_h.py:19] end experts_func_mgpu_group_pad cost 0.0015494823455810547 seconds
DEBUG 01-14 20:42:32.635702.635702 cuda_h.py:10] start gpu_group_list
DEBUG 01-14 20:42:32.635542.635542 cuda_h.py:19] end gpu_group_list cost 0.00032067298889160156 seconds
DEBUG 01-14 20:42:32.636832.636832 mlpmodule.py:1367]  experts func einsum cost 0.08168506622314453 s
DEBUG 01-14 20:42:32.636436.636436 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-14 20:42:32.636638.636638 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 1.8358230590820312e-05 seconds
DEBUG 01-14 20:42:32.636308.636308 cuda_h.py:10] start wait_experts
INFO 01-14 20:42:32.636826.636826 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 2f34d027-d5c3-46cb-bc01-fdf2e3e0481d
DEBUG 01-14 20:42:32.646560.646560 mlpmodule.py:1460] group tensors cost 0.009816646575927734 s
DEBUG 01-14 20:42:32.646835.646835 cuda_h.py:10] start move_flat_hidden2cpu
DEBUG 01-14 20:42:32.652291.652291 cuda_h.py:19] end move_flat_hidden2cpu cost 0.005815744400024414 seconds
DEBUG 01-14 20:42:32.654265.654265 mlpmodule.py:1533] pad cost 0.001514434814453125 s
DEBUG 01-14 20:42:32.654486.654486 mlpmodule.py:1539] create cpu tensor cost 3.600120544433594e-05 s
DEBUG 01-14 20:42:32.656989.656989 mlpmodule.py:1544] move to cpu cost 0.0019161701202392578 s
DEBUG 01-14 20:42:32.666853.666853 mlpmodule.py:1558] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-14 20:42:32.666879.666879 mlpmodule.py:1559] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-14 20:42:32.666332.666332 mlpmodule.py:1564] group_w3 first element: -0.006134033203125
WARNING 01-14 20:42:32.666395.666395 mlpmodule.py:1574] start einsum2
DEBUG 01-14 20:42:32.683854.683854 mlpmodule.py:1584] group einsum cost 0.027353763580322266 s
DEBUG 01-14 20:42:32.684249.684249 mlpmodule.py:1593] cpy2cputensor cost 0.0007207393646240234 s
DEBUG 01-14 20:42:32.684086.684086 cuda_h.py:10] start move_outputs
INFO 01-14 20:42:32.685617.685617 client.py:127] Model loaded
DEBUG 01-14 20:42:32.686824.686824 cuda_h.py:19] end wait_experts cost 0.04974865913391113 seconds
DEBUG 01-14 20:42:32.686244.686244 cuda_h.py:10] start gpu_experts
DEBUG 01-14 20:42:32.686612.686612 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-14 20:42:32.686866.686866 cuda_h.py:19] end move_outputs cost 0.0019001960754394531 seconds
DEBUG 01-14 20:42:32.690841.690841 cuda_h.py:19] end wait_cetm_experts cost 0.004174947738647461 seconds
DEBUG 01-14 20:42:32.690948.690948 cuda_h.py:10] start gpu_group_einsum_mp_multi_list
DEBUG 01-14 20:42:32.691229.691229 cuda_h.py:10] start gpu_group_tensor
DEBUG 01-14 20:42:32.691107.691107 cuda_h.py:19] end gpu_group_tensor cost 0.0004172325134277344 seconds
DEBUG 01-14 20:42:32.691255.691255 cuda_h.py:10] start gpu_group_einsum
DEBUG 01-14 20:42:32.693281.693281 cuda_h.py:19] end gpu_group_einsum cost 0.0012657642364501953 seconds
DEBUG 01-14 20:42:32.693555.693555 cuda_h.py:10] start gpu_final_hidden_states_scatter
DEBUG 01-14 20:42:32.693825.693825 cuda_h.py:10] start all_expert_outputs_slices
DEBUG 01-14 20:42:32.694776.694776 cuda_h.py:19] end all_expert_outputs_slices cost 0.0006546974182128906 seconds
DEBUG 01-14 20:42:32.694144.694144 cuda_h.py:10] start concat_expert_out
DEBUG 01-14 20:42:32.694489.694489 cuda_h.py:19] end concat_expert_out cost 0.00014066696166992188 seconds
DEBUG 01-14 20:42:32.694507.694507 cuda_h.py:10] start index_scatter
DEBUG 01-14 20:42:32.694681.694681 cuda_h.py:19] end index_scatter cost 0.00014519691467285156 seconds
DEBUG 01-14 20:42:32.695710.695710 cuda_h.py:19] end gpu_final_hidden_states_scatter cost 0.0015556812286376953 seconds
DEBUG 01-14 20:42:32.695948.695948 cuda_h.py:19] end gpu_experts cost 0.00886845588684082 seconds
DEBUG 01-14 20:42:32.695381.695381 cuda_h.py:10] start all_expert_weight_slices
DEBUG 01-14 20:42:32.697004.697004 cuda_h.py:19] end all_expert_weight_slices cost 0.0023069381713867188 seconds
DEBUG 01-14 20:42:32.697280.697280 cuda_h.py:10] start cpuoutputsdeal
DEBUG 01-14 20:42:32.698379.698379 cuda_h.py:10] start index_scatter
DEBUG 01-14 20:42:32.698345.698345 cuda_h.py:19] end index_scatter cost 7.2479248046875e-05 seconds
DEBUG 01-14 20:42:32.699565.699565 cuda_h.py:19] end cpuoutputsdeal cost 0.001123189926147461 seconds
DEBUG 01-14 20:42:32.699045.699045 cuda_h.py:19] end layer_moe_generate_mp_l_12 cost 0.0755918025970459 seconds
DEBUG 01-14 20:42:32.699603.699603 cuda_h.py:19] end prefill_layer cost 0.082427978515625 seconds
DEBUG 01-14 20:42:32.699559.699559 lmp.py:1551] -------------------------------- end prefill layer 11 --------------------------------
DEBUG 01-14 20:42:32.699422.699422 cuda_h.py:10] start prefill_layer
DEBUG 01-14 20:42:32.699807.699807 lmp.py:1494] -------------------------------- start prefill layer 12 --------------------------------
DEBUG 01-14 20:42:32.699431.699431 cuda_h.py:10] start start_load_qkvogn_s_weight_l_13
DEBUG 01-14 20:42:32.699154.699154 cuda_h.py:10] start start_load_qkvogn_s_weight_l_13
DEBUG 01-14 20:42:32.699501.699501 cuda_h.py:19] end start_load_qkvogn_s_weight_l_13 cost 4.029273986816406e-05 seconds
DEBUG 01-14 20:42:32.699742.699742 cuda_h.py:10] start sllm_worker_task
DEBUG 01-14 20:42:32.700393.700393 cuda_h.py:19] end start_load_qkvogn_s_weight_l_13 cost 0.000171661376953125 seconds
DEBUG 01-14 20:42:32.700654.700654 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-14 20:42:32.700967.700967 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-14 20:42:32.700738.700738 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-14 20:42:32.702190.702190 cuda_h.py:19] end allocate_cuda_memory cost 0.0024995803833007812 seconds
DEBUG 01-14 20:42:32.702398.702398 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-14 20:42:32.703744.703744 sllm_store_c.py:27] get device uuid map
DEBUG 01-14 20:42:32.703904.703904 sllm_store_c.py:29] call client load into gpu
DEBUG 01-14 20:42:32.703323.703323 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 9863d122-aeeb-4d99-bfb2-565c1a813fd5
DEBUG 01-14 20:42:32.703200.703200 client.py:106] call stub.LoadModelAsync
DEBUG 01-14 20:42:32.703994.703994 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-14 20:42:32.703818.703818 cuda_h.py:10] start self_attn
INFO 01-14 20:42:32.704423.704423 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 9863d122-aeeb-4d99-bfb2-565c1a813fd5
DEBUG 01-14 20:42:32.704412.704412 cuda_h.py:19] end load_into_gpu_async cost 0.0015461444854736328 seconds
DEBUG 01-14 20:42:32.704638.704638 cuda_h.py:10] start restore_tensors2
DEBUG 01-14 20:42:32.704257.704257 cuda_h.py:19] end restore_tensors2 cost 7.343292236328125e-05 seconds
DEBUG 01-14 20:42:32.704490.704490 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.004477024078369141 seconds
INFO 01-14 20:42:32.704949.704949 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 9863d122-aeeb-4d99-bfb2-565c1a813fd5
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-14 20:42:32.708918.708918 cuda_h.py:19] end self_attn cost 0.004693746566772461 seconds
DEBUG 01-14 20:42:32.709959.709959 cuda_h.py:19] end iln_self_attn_paln cost 0.00869441032409668 seconds
DEBUG 01-14 20:42:32.709563.709563 cuda_h.py:10] start layer_moe_generate_mp_l_13
DEBUG 01-14 20:42:32.709902.709902 cuda_h.py:10] start gate
DEBUG 01-14 20:42:32.709770.709770 mlpmodule.py:1367]  experts func einsum cost 0.07266449928283691 s
DEBUG 01-14 20:42:32.710502.710502 cuda_h.py:19] end gate cost 0.0008485317230224609 seconds
DEBUG 01-14 20:42:32.710101.710101 cuda_h.py:10] start experts_map_get
DEBUG 01-14 20:42:32.710675.710675 lmp.py:1615] 
DEBUG 01-14 20:42:32.710675.710675 lmp.py:1615] Expert Token Distribution & Device Allocation:
DEBUG 01-14 20:42:32.710769.710769 lmp.py:1616]   Total experts: 64
DEBUG 01-14 20:42:32.710518.710518 lmp.py:1617]   CPU experts: 32 (50%)
DEBUG 01-14 20:42:32.710452.710452 lmp.py:1618]   GPU experts: 32 (50%)
DEBUG 01-14 20:42:32.710479.710479 lmp.py:1619] 
DEBUG 01-14 20:42:32.710479.710479 lmp.py:1619]   Expert ID | Tokens | Device
DEBUG 01-14 20:42:32.710745.710745 lmp.py:1620]   -----------------------------------
DEBUG 01-14 20:42:32.710487.710487 lmp.py:1625]   Expert 12 |     25 | CPU
DEBUG 01-14 20:42:32.710799.710799 lmp.py:1625]   Expert 52 |     30 | CPU
DEBUG 01-14 20:42:32.710873.710873 lmp.py:1625]   Expert 38 |     31 | CPU
DEBUG 01-14 20:42:32.710231.710231 lmp.py:1625]   Expert 16 |     32 | CPU
DEBUG 01-14 20:42:32.710828.710828 lmp.py:1625]   Expert 47 |     40 | CPU
DEBUG 01-14 20:42:32.710424.710424 lmp.py:1625]   Expert 63 |     45 | CPU
DEBUG 01-14 20:42:32.710021.710021 lmp.py:1625]   Expert 27 |     55 | CPU
DEBUG 01-14 20:42:32.710287.710287 lmp.py:1625]   Expert  4 |     71 | CPU
DEBUG 01-14 20:42:32.710837.710837 lmp.py:1625]   Expert 43 |     78 | CPU
DEBUG 01-14 20:42:32.710910.710910 lmp.py:1625]   Expert 53 |     80 | CPU
DEBUG 01-14 20:42:32.710222.710222 lmp.py:1625]   Expert 61 |     80 | CPU
DEBUG 01-14 20:42:32.710296.710296 lmp.py:1625]   Expert 44 |     81 | CPU
DEBUG 01-14 20:42:32.710654.710654 lmp.py:1625]   Expert 34 |     83 | CPU
DEBUG 01-14 20:42:32.710774.710774 lmp.py:1625]   Expert 13 |     93 | CPU
DEBUG 01-14 20:42:32.710655.710655 lmp.py:1625]   Expert 37 |    104 | CPU
DEBUG 01-14 20:42:32.710537.710537 lmp.py:1625]   Expert 32 |    107 | CPU
DEBUG 01-14 20:42:32.710418.710418 lmp.py:1625]   Expert 39 |    109 | CPU
DEBUG 01-14 20:42:32.710538.710538 lmp.py:1625]   Expert  0 |    111 | CPU
DEBUG 01-14 20:42:32.710419.710419 lmp.py:1625]   Expert 20 |    122 | CPU
DEBUG 01-14 20:42:32.710493.710493 lmp.py:1625]   Expert 21 |    126 | CPU
DEBUG 01-14 20:42:32.710580.710580 lmp.py:1625]   Expert 14 |    127 | CPU
DEBUG 01-14 20:42:32.710938.710938 lmp.py:1625]   Expert 30 |    128 | CPU
DEBUG 01-14 20:42:32.710104.710104 lmp.py:1625]   Expert 60 |    136 | CPU
DEBUG 01-14 20:42:32.711032.711032 lmp.py:1625]   Expert  8 |    137 | CPU
DEBUG 01-14 20:42:32.711436.711436 lmp.py:1625]   Expert 18 |    141 | CPU
DEBUG 01-14 20:42:32.711603.711603 lmp.py:1625]   Expert 45 |    142 | CPU
DEBUG 01-14 20:42:32.711007.711007 lmp.py:1625]   Expert 11 |    145 | CPU
DEBUG 01-14 20:42:32.711173.711173 lmp.py:1625]   Expert 22 |    154 | CPU
DEBUG 01-14 20:42:32.711339.711339 lmp.py:1625]   Expert 17 |    157 | CPU
DEBUG 01-14 20:42:32.711029.711029 lmp.py:1625]   Expert 57 |    157 | CPU
DEBUG 01-14 20:42:32.711433.711433 lmp.py:1625]   Expert 36 |    159 | CPU
DEBUG 01-14 20:42:32.711076.711076 lmp.py:1625]   Expert 42 |    160 | CPU
DEBUG 01-14 20:42:32.711958.711958 lmp.py:1625]   Expert  2 |    167 | GPU
DEBUG 01-14 20:42:32.711793.711793 lmp.py:1625]   Expert  7 |    167 | GPU
DEBUG 01-14 20:42:32.711912.711912 lmp.py:1625]   Expert 58 |    170 | GPU
DEBUG 01-14 20:42:32.711079.711079 lmp.py:1625]   Expert 23 |    173 | GPU
DEBUG 01-14 20:42:32.711006.711006 lmp.py:1625]   Expert 25 |    176 | GPU
DEBUG 01-14 20:42:32.711934.711934 lmp.py:1625]   Expert 35 |    176 | GPU
DEBUG 01-14 20:42:32.711862.711862 lmp.py:1625]   Expert 49 |    176 | GPU
DEBUG 01-14 20:42:32.711551.711551 lmp.py:1625]   Expert 62 |    179 | GPU
DEBUG 01-14 20:42:32.711479.711479 lmp.py:1625]   Expert 55 |    192 | GPU
DEBUG 01-14 20:42:32.711407.711407 lmp.py:1625]   Expert 48 |    194 | GPU
DEBUG 01-14 20:42:32.711573.711573 lmp.py:1625]   Expert  6 |    195 | GPU
DEBUG 01-14 20:42:32.711262.711262 lmp.py:1625]   Expert 29 |    199 | GPU
DEBUG 01-14 20:42:32.711143.711143 lmp.py:1625]   Expert  1 |    203 | GPU
DEBUG 01-14 20:42:32.711263.711263 lmp.py:1625]   Expert 31 |    205 | GPU
DEBUG 01-14 20:42:32.711906.711906 lmp.py:1625]   Expert 51 |    211 | GPU
DEBUG 01-14 20:42:32.711026.711026 lmp.py:1625]   Expert 28 |    218 | GPU
DEBUG 01-14 20:42:32.711954.711954 lmp.py:1625]   Expert  5 |    222 | GPU
DEBUG 01-14 20:42:32.711643.711643 lmp.py:1625]   Expert 54 |    224 | GPU
DEBUG 01-14 20:42:32.711809.711809 lmp.py:1625]   Expert 19 |    226 | GPU
DEBUG 01-14 20:42:32.711737.711737 lmp.py:1625]   Expert  9 |    243 | GPU
DEBUG 01-14 20:42:32.711426.711426 lmp.py:1625]   Expert 41 |    250 | GPU
DEBUG 01-14 20:42:32.711354.711354 lmp.py:1625]   Expert 24 |    266 | GPU
DEBUG 01-14 20:42:32.711043.711043 lmp.py:1625]   Expert 50 |    267 | GPU
DEBUG 01-14 20:42:32.711494.711494 lmp.py:1625]   Expert 46 |    284 | GPU
DEBUG 01-14 20:42:32.711852.711852 lmp.py:1625]   Expert 59 |    327 | GPU
DEBUG 01-14 20:42:32.711257.711257 lmp.py:1625]   Expert 33 |    395 | GPU
DEBUG 01-14 20:42:32.711138.711138 lmp.py:1625]   Expert 56 |    413 | GPU
DEBUG 01-14 20:42:32.711781.711781 lmp.py:1625]   Expert 26 |    432 | GPU
DEBUG 01-14 20:42:32.711663.711663 lmp.py:1625]   Expert 10 |    435 | GPU
DEBUG 01-14 20:42:32.711829.711829 lmp.py:1625]   Expert  3 |    598 | GPU
DEBUG 01-14 20:42:32.711995.711995 lmp.py:1625]   Expert 15 |    606 | GPU
DEBUG 01-14 20:42:32.711684.711684 lmp.py:1625]   Expert 40 |    853 | GPU
DEBUG 01-14 20:42:32.711804.711804 lmp.py:1626] 
DEBUG 01-14 20:42:32.711804.711804 lmp.py:1626]   CPU total tokens: 3246 (26.4%)
DEBUG 01-14 20:42:32.711924.711924 lmp.py:1627]   GPU total tokens: 9042 (73.6%)
DEBUG 01-14 20:42:32.711574.711574 cuda_h.py:19] end experts_map_get cost 0.0016162395477294922 seconds
DEBUG 01-14 20:42:32.711523.711523 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-14 20:42:32.711465.711465 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-14 20:42:32.712331.712331 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-14 20:42:32.712552.712552 cuda_h.py:19] end allocate_cuda_memory cost 0.0002334117889404297 seconds
INFO 01-14 20:42:32.712681.712681 client.py:127] Model loaded
DEBUG 01-14 20:42:32.712551.712551 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-14 20:42:32.712288.712288 cuda_h.py:10] start restore2model
DEBUG 01-14 20:42:32.712574.712574 sllm_store_c.py:27] get device uuid map
DEBUG 01-14 20:42:32.712390.712390 sllm_store_c.py:29] call client load into gpu
DEBUG 01-14 20:42:32.712093.712093 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 0abec4cf-e7e0-4d04-8eb3-ceacbf7d5dfd
DEBUG 01-14 20:42:32.713828.713828 client.py:106] call stub.LoadModelAsync
DEBUG 01-14 20:42:32.713381.713381 cuda_h.py:19] end restore2model cost 0.0007205009460449219 seconds
DEBUG 01-14 20:42:32.713827.713827 cuda_h.py:19] end sllm_worker_task cost 0.013271808624267578 seconds
INFO 01-14 20:42:32.714529.714529 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 0abec4cf-e7e0-4d04-8eb3-ceacbf7d5dfd
DEBUG 01-14 20:42:32.714611.714611 cuda_h.py:19] end load_into_gpu_async cost 0.0018880367279052734 seconds
DEBUG 01-14 20:42:32.714983.714983 cuda_h.py:10] start restore_tensors2
DEBUG 01-14 20:42:32.714706.714706 cuda_h.py:19] end restore_tensors2 cost 0.00039839744567871094 seconds
DEBUG 01-14 20:42:32.714880.714880 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0030536651611328125 seconds
DEBUG 01-14 20:42:32.715788.715788 cuda_h.py:10] start restore2model
DEBUG 01-14 20:42:32.717377.717377 cuda_h.py:19] end restore2model cost 0.0027201175689697266 seconds
DEBUG 01-14 20:42:32.717737.717737 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.005956411361694336 seconds
DEBUG 01-14 20:42:32.717486.717486 cuda_h.py:10] start gpu_sexperts
DEBUG 01-14 20:42:32.718914.718914 cuda_h.py:19] end gpu_sexperts cost 0.0002799034118652344 seconds
DEBUG 01-14 20:42:32.718405.718405 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-14 20:42:32.718969.718969 lmp.py:1683] 
DEBUG 01-14 20:42:32.718969.718969 lmp.py:1683]   Computing 32 experts on CPU...
DEBUG 01-14 20:42:32.718428.718428 cuda_h.py:19] end cpu_experts_submit cost 5.8650970458984375e-05 seconds
DEBUG 01-14 20:42:32.718177.718177 cuda_h.py:10] start experts_func_mgpu_group_pad
DEBUG 01-14 20:42:32.729906.729906 mlpmodule.py:1460] group tensors cost 0.010393381118774414 s
DEBUG 01-14 20:42:32.729113.729113 cuda_h.py:10] start move_flat_hidden2cpu
DEBUG 01-14 20:42:32.732170.732170 cuda_h.py:19] end experts_func_mgpu_group_pad cost 0.014375686645507812 seconds
DEBUG 01-14 20:42:32.734312.734312 cuda_h.py:10] start gpu_group_list
DEBUG 01-14 20:42:32.734713.734713 cuda_h.py:19] end gpu_group_list cost 0.0004134178161621094 seconds
DEBUG 01-14 20:42:32.734814.734814 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-14 20:42:32.735792.735792 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 3.6716461181640625e-05 seconds
DEBUG 01-14 20:42:32.735608.735608 cuda_h.py:10] start wait_experts
INFO 01-14 20:42:32.735179.735179 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 0abec4cf-e7e0-4d04-8eb3-ceacbf7d5dfd
DEBUG 01-14 20:42:32.736172.736172 cuda_h.py:19] end move_flat_hidden2cpu cost 0.0068264007568359375 seconds
DEBUG 01-14 20:42:32.738776.738776 mlpmodule.py:1533] pad cost 0.0015354156494140625 s
DEBUG 01-14 20:42:32.738104.738104 mlpmodule.py:1539] create cpu tensor cost 3.552436828613281e-05 s
DEBUG 01-14 20:42:32.740672.740672 mlpmodule.py:1544] move to cpu cost 0.0018928050994873047 s
DEBUG 01-14 20:42:32.750950.750950 mlpmodule.py:1558] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-14 20:42:32.750551.750551 mlpmodule.py:1559] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-14 20:42:32.750025.750025 mlpmodule.py:1564] group_w3 first element: -0.0162353515625
WARNING 01-14 20:42:32.750010.750010 mlpmodule.py:1574] start einsum2
DEBUG 01-14 20:42:32.767861.767861 mlpmodule.py:1584] group einsum cost 0.02730703353881836 s
DEBUG 01-14 20:42:32.768362.768362 mlpmodule.py:1593] cpy2cputensor cost 0.0007290840148925781 s
DEBUG 01-14 20:42:32.768052.768052 cuda_h.py:10] start move_outputs
DEBUG 01-14 20:42:32.771661.771661 cuda_h.py:19] end move_outputs cost 0.0025238990783691406 seconds
INFO 01-14 20:42:32.772604.772604 client.py:127] Model loaded
DEBUG 01-14 20:42:32.772030.772030 cuda_h.py:19] end wait_experts cost 0.037256717681884766 seconds
DEBUG 01-14 20:42:32.772854.772854 cuda_h.py:10] start gpu_experts
DEBUG 01-14 20:42:32.772578.772578 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-14 20:42:32.775667.775667 cuda_h.py:19] end wait_cetm_experts cost 0.0029687881469726562 seconds
DEBUG 01-14 20:42:32.775699.775699 cuda_h.py:10] start gpu_group_einsum_mp_multi_list
DEBUG 01-14 20:42:32.775192.775192 cuda_h.py:10] start gpu_group_tensor
DEBUG 01-14 20:42:32.776438.776438 cuda_h.py:19] end gpu_group_tensor cost 0.0003533363342285156 seconds
DEBUG 01-14 20:42:32.776810.776810 cuda_h.py:10] start gpu_group_einsum
DEBUG 01-14 20:42:32.777833.777833 cuda_h.py:19] end gpu_group_einsum cost 0.0009725093841552734 seconds
DEBUG 01-14 20:42:32.777886.777886 cuda_h.py:10] start gpu_final_hidden_states_scatter
DEBUG 01-14 20:42:32.777360.777360 cuda_h.py:10] start all_expert_outputs_slices
DEBUG 01-14 20:42:32.778492.778492 cuda_h.py:19] end all_expert_outputs_slices cost 0.0005221366882324219 seconds
DEBUG 01-14 20:42:32.778342.778342 cuda_h.py:10] start concat_expert_out
DEBUG 01-14 20:42:32.778242.778242 cuda_h.py:19] end concat_expert_out cost 0.000110626220703125 seconds
DEBUG 01-14 20:42:32.778650.778650 cuda_h.py:10] start index_scatter
DEBUG 01-14 20:42:32.779100.779100 cuda_h.py:19] end index_scatter cost 0.00012063980102539062 seconds
DEBUG 01-14 20:42:32.779487.779487 cuda_h.py:19] end gpu_final_hidden_states_scatter cost 0.0012364387512207031 seconds
DEBUG 01-14 20:42:32.779929.779929 cuda_h.py:19] end gpu_experts cost 0.006732463836669922 seconds
DEBUG 01-14 20:42:32.779918.779918 cuda_h.py:10] start all_expert_weight_slices
DEBUG 01-14 20:42:32.781049.781049 cuda_h.py:19] end all_expert_weight_slices cost 0.0016834735870361328 seconds
DEBUG 01-14 20:42:32.781581.781581 cuda_h.py:10] start cpuoutputsdeal
DEBUG 01-14 20:42:32.781419.781419 cuda_h.py:10] start index_scatter
DEBUG 01-14 20:42:32.782988.782988 cuda_h.py:19] end index_scatter cost 8.320808410644531e-05 seconds
DEBUG 01-14 20:42:32.782414.782414 cuda_h.py:19] end cpuoutputsdeal cost 0.0008785724639892578 seconds
DEBUG 01-14 20:42:32.782836.782836 cuda_h.py:19] end layer_moe_generate_mp_l_13 cost 0.07314801216125488 seconds
DEBUG 01-14 20:42:32.782588.782588 cuda_h.py:19] end prefill_layer cost 0.08304476737976074 seconds
DEBUG 01-14 20:42:32.782942.782942 lmp.py:1551] -------------------------------- end prefill layer 12 --------------------------------
DEBUG 01-14 20:42:32.782195.782195 cuda_h.py:10] start prefill_layer
DEBUG 01-14 20:42:32.782402.782402 lmp.py:1494] -------------------------------- start prefill layer 13 --------------------------------
DEBUG 01-14 20:42:32.783847.783847 cuda_h.py:10] start start_load_qkvogn_s_weight_l_14
DEBUG 01-14 20:42:32.783677.783677 cuda_h.py:10] start start_load_qkvogn_s_weight_l_14
DEBUG 01-14 20:42:32.783336.783336 cuda_h.py:19] end start_load_qkvogn_s_weight_l_14 cost 4.5299530029296875e-05 seconds
DEBUG 01-14 20:42:32.783980.783980 cuda_h.py:19] end start_load_qkvogn_s_weight_l_14 cost 0.00010466575622558594 seconds
DEBUG 01-14 20:42:32.783557.783557 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-14 20:42:32.783733.783733 cuda_h.py:10] start sllm_worker_task
DEBUG 01-14 20:42:32.783512.783512 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-14 20:42:32.783772.783772 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-14 20:42:32.791321.791321 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-14 20:42:32.791757.791757 cuda_h.py:19] end allocate_cuda_memory cost 0.008208274841308594 seconds
DEBUG 01-14 20:42:32.792795.792795 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-14 20:42:32.792885.792885 sllm_store_c.py:27] get device uuid map
DEBUG 01-14 20:42:32.792326.792326 sllm_store_c.py:29] call client load into gpu
DEBUG 01-14 20:42:32.792693.792693 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 7b708c32-a75f-44b4-9b8e-e9adb0364aca
DEBUG 01-14 20:42:32.792944.792944 client.py:106] call stub.LoadModelAsync
DEBUG 01-14 20:42:32.793828.793828 cuda_h.py:10] start self_attn
INFO 01-14 20:42:32.793818.793818 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 7b708c32-a75f-44b4-9b8e-e9adb0364aca
DEBUG 01-14 20:42:32.793610.793610 cuda_h.py:19] end load_into_gpu_async cost 0.0016934871673583984 seconds
DEBUG 01-14 20:42:32.794043.794043 cuda_h.py:10] start restore_tensors2
DEBUG 01-14 20:42:32.794865.794865 cuda_h.py:19] end restore_tensors2 cost 0.0001480579376220703 seconds
DEBUG 01-14 20:42:32.794550.794550 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.010802745819091797 seconds
INFO 01-14 20:42:32.794145.794145 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 7b708c32-a75f-44b4-9b8e-e9adb0364aca
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-14 20:42:32.800610.800610 mlpmodule.py:1367]  experts func einsum cost 0.08147549629211426 s
DEBUG 01-14 20:42:32.800366.800366 cuda_h.py:19] end self_attn cost 0.00740504264831543 seconds
DEBUG 01-14 20:42:32.801423.801423 cuda_h.py:19] end iln_self_attn_paln cost 0.018068552017211914 seconds
DEBUG 01-14 20:42:32.801651.801651 cuda_h.py:10] start layer_moe_generate_mp_l_14
DEBUG 01-14 20:42:32.801832.801832 cuda_h.py:10] start gate
INFO 01-14 20:42:32.801245.801245 client.py:127] Model loaded
DEBUG 01-14 20:42:32.801885.801885 cuda_h.py:10] start restore2model
DEBUG 01-14 20:42:32.803494.803494 cuda_h.py:19] end restore2model cost 0.0010941028594970703 seconds
DEBUG 01-14 20:42:32.803307.803307 cuda_h.py:19] end sllm_worker_task cost 0.019790172576904297 seconds
DEBUG 01-14 20:42:32.804658.804658 cuda_h.py:19] end gate cost 0.0024394989013671875 seconds
DEBUG 01-14 20:42:32.804210.804210 cuda_h.py:10] start experts_map_get
DEBUG 01-14 20:42:32.804779.804779 lmp.py:1615] 
DEBUG 01-14 20:42:32.804779.804779 lmp.py:1615] Expert Token Distribution & Device Allocation:
DEBUG 01-14 20:42:32.804953.804953 lmp.py:1616]   Total experts: 64
DEBUG 01-14 20:42:32.804252.804252 lmp.py:1617]   CPU experts: 32 (50%)
DEBUG 01-14 20:42:32.804591.804591 lmp.py:1618]   GPU experts: 32 (50%)
DEBUG 01-14 20:42:32.804116.804116 lmp.py:1619] 
DEBUG 01-14 20:42:32.804116.804116 lmp.py:1619]   Expert ID | Tokens | Device
DEBUG 01-14 20:42:32.804494.804494 lmp.py:1620]   -----------------------------------
DEBUG 01-14 20:42:32.804303.804303 lmp.py:1625]   Expert 42 |     18 | CPU
DEBUG 01-14 20:42:32.804205.804205 lmp.py:1625]   Expert 30 |     24 | CPU
DEBUG 01-14 20:42:32.805153.805153 lmp.py:1625]   Expert 19 |     25 | CPU
DEBUG 01-14 20:42:32.805247.805247 lmp.py:1625]   Expert  6 |     59 | CPU
DEBUG 01-14 20:42:32.805149.805149 lmp.py:1625]   Expert 32 |     63 | CPU
DEBUG 01-14 20:42:32.805097.805097 lmp.py:1625]   Expert  5 |     70 | CPU
DEBUG 01-14 20:42:32.805760.805760 lmp.py:1625]   Expert  1 |     73 | CPU
DEBUG 01-14 20:42:32.805708.805708 lmp.py:1625]   Expert 53 |    101 | CPU
DEBUG 01-14 20:42:32.805657.805657 lmp.py:1625]   Expert 18 |    112 | CPU
DEBUG 01-14 20:42:32.805889.805889 lmp.py:1625]   Expert 11 |    113 | CPU
DEBUG 01-14 20:42:32.805791.805791 lmp.py:1625]   Expert 63 |    132 | CPU
DEBUG 01-14 20:42:32.805455.805455 lmp.py:1625]   Expert 58 |    133 | CPU
DEBUG 01-14 20:42:32.805356.805356 lmp.py:1625]   Expert 13 |    134 | CPU
DEBUG 01-14 20:42:32.805828.805828 lmp.py:1625]   Expert 59 |    136 | CPU
DEBUG 01-14 20:42:32.805060.805060 lmp.py:1625]   Expert 26 |    142 | CPU
DEBUG 01-14 20:42:32.805532.805532 lmp.py:1625]   Expert 31 |    142 | CPU
DEBUG 01-14 20:42:32.805241.805241 lmp.py:1625]   Expert 51 |    143 | CPU
DEBUG 01-14 20:42:32.805143.805143 lmp.py:1625]   Expert 40 |    145 | CPU
DEBUG 01-14 20:42:32.805522.805522 lmp.py:1625]   Expert  4 |    149 | CPU
DEBUG 01-14 20:42:32.805139.805139 lmp.py:1625]   Expert 61 |    149 | CPU
DEBUG 01-14 20:42:32.805087.805087 lmp.py:1625]   Expert 50 |    150 | CPU
DEBUG 01-14 20:42:32.805558.805558 lmp.py:1625]   Expert 34 |    151 | CPU
DEBUG 01-14 20:42:32.805029.805029 lmp.py:1625]   Expert 56 |    152 | CPU
DEBUG 01-14 20:42:32.805501.805501 lmp.py:1625]   Expert 20 |    154 | CPU
DEBUG 01-14 20:42:32.805210.805210 lmp.py:1625]   Expert 48 |    155 | CPU
DEBUG 01-14 20:42:32.805635.805635 lmp.py:1625]   Expert  9 |    160 | CPU
DEBUG 01-14 20:42:32.805298.805298 lmp.py:1625]   Expert 12 |    162 | CPU
DEBUG 01-14 20:42:32.805008.805008 lmp.py:1625]   Expert 35 |    163 | CPU
DEBUG 01-14 20:42:32.805718.805718 lmp.py:1625]   Expert 37 |    166 | CPU
DEBUG 01-14 20:42:32.805712.805712 lmp.py:1625]   Expert 33 |    168 | CPU
DEBUG 01-14 20:42:32.805707.805707 lmp.py:1625]   Expert 55 |    168 | CPU
DEBUG 01-14 20:42:32.805701.805701 lmp.py:1625]   Expert 10 |    172 | CPU
DEBUG 01-14 20:42:32.805126.805126 lmp.py:1625]   Expert 46 |    174 | GPU
DEBUG 01-14 20:42:32.806849.806849 lmp.py:1625]   Expert  2 |    177 | GPU
DEBUG 01-14 20:42:32.806897.806897 lmp.py:1625]   Expert 52 |    177 | GPU
DEBUG 01-14 20:42:32.806083.806083 lmp.py:1625]   Expert 36 |    179 | GPU
DEBUG 01-14 20:42:32.806793.806793 lmp.py:1625]   Expert  8 |    187 | GPU
DEBUG 01-14 20:42:32.806172.806172 lmp.py:1625]   Expert 25 |    200 | GPU
DEBUG 01-14 20:42:32.806312.806312 lmp.py:1625]   Expert 39 |    201 | GPU
DEBUG 01-14 20:42:32.806690.806690 lmp.py:1625]   Expert 57 |    210 | GPU
DEBUG 01-14 20:42:32.806162.806162 lmp.py:1625]   Expert  3 |    211 | GPU
DEBUG 01-14 20:42:32.806633.806633 lmp.py:1625]   Expert  0 |    213 | GPU
DEBUG 01-14 20:42:32.806058.806058 lmp.py:1625]   Expert 24 |    213 | GPU
DEBUG 01-14 20:42:32.806436.806436 lmp.py:1625]   Expert  7 |    235 | GPU
DEBUG 01-14 20:42:32.806338.806338 lmp.py:1625]   Expert 27 |    237 | GPU
DEBUG 01-14 20:42:32.806571.806571 lmp.py:1625]   Expert 21 |    240 | GPU
DEBUG 01-14 20:42:32.806327.806327 lmp.py:1625]   Expert 62 |    241 | GPU
DEBUG 01-14 20:42:32.806083.806083 lmp.py:1625]   Expert 23 |    243 | GPU
DEBUG 01-14 20:42:32.806316.806316 lmp.py:1625]   Expert 38 |    246 | GPU
DEBUG 01-14 20:42:32.806218.806218 lmp.py:1625]   Expert 28 |    261 | GPU
DEBUG 01-14 20:42:32.806119.806119 lmp.py:1625]   Expert 60 |    271 | GPU
DEBUG 01-14 20:42:32.806544.806544 lmp.py:1625]   Expert 43 |    272 | GPU
DEBUG 01-14 20:42:32.806015.806015 lmp.py:1625]   Expert 29 |    273 | GPU
DEBUG 01-14 20:42:32.806248.806248 lmp.py:1625]   Expert 16 |    284 | GPU
DEBUG 01-14 20:42:32.806243.806243 lmp.py:1625]   Expert 54 |    286 | GPU
DEBUG 01-14 20:42:32.806999.806999 lmp.py:1625]   Expert 49 |    287 | GPU
DEBUG 01-14 20:42:32.806377.806377 lmp.py:1625]   Expert 15 |    290 | GPU
DEBUG 01-14 20:42:32.806518.806518 lmp.py:1625]   Expert 41 |    291 | GPU
DEBUG 01-14 20:42:32.806896.806896 lmp.py:1625]   Expert 22 |    293 | GPU
DEBUG 01-14 20:42:32.806606.806606 lmp.py:1625]   Expert 44 |    316 | GPU
DEBUG 01-14 20:42:32.806839.806839 lmp.py:1625]   Expert 47 |    317 | GPU
DEBUG 01-14 20:42:32.806071.806071 lmp.py:1625]   Expert 14 |    372 | GPU
DEBUG 01-14 20:42:32.806781.806781 lmp.py:1625]   Expert 17 |    380 | GPU
DEBUG 01-14 20:42:32.807160.807160 lmp.py:1625]   Expert 45 |    527 | GPU
DEBUG 01-14 20:42:32.807207.807207 lmp.py:1626] 
DEBUG 01-14 20:42:32.807207.807207 lmp.py:1626]   CPU total tokens: 3984 (32.4%)
DEBUG 01-14 20:42:32.807447.807447 lmp.py:1627]   GPU total tokens: 8304 (67.6%)
DEBUG 01-14 20:42:32.807740.807740 cuda_h.py:19] end experts_map_get cost 0.002900362014770508 seconds
DEBUG 01-14 20:42:32.807783.807783 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-14 20:42:32.807541.807541 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-14 20:42:32.807488.807488 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-14 20:42:32.807308.807308 cuda_h.py:19] end allocate_cuda_memory cost 0.0003008842468261719 seconds
DEBUG 01-14 20:42:32.807007.807007 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-14 20:42:32.808982.808982 sllm_store_c.py:27] get device uuid map
DEBUG 01-14 20:42:32.808825.808825 sllm_store_c.py:29] call client load into gpu
DEBUG 01-14 20:42:32.808787.808787 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 6e4ea367-0eaa-4ca0-a785-c90f2b4103a9
DEBUG 01-14 20:42:32.808612.808612 client.py:106] call stub.LoadModelAsync
INFO 01-14 20:42:32.809092.809092 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 6e4ea367-0eaa-4ca0-a785-c90f2b4103a9
DEBUG 01-14 20:42:32.810923.810923 cuda_h.py:19] end load_into_gpu_async cost 0.001988649368286133 seconds
DEBUG 01-14 20:42:32.810653.810653 cuda_h.py:10] start restore_tensors2
DEBUG 01-14 20:42:32.810110.810110 cuda_h.py:19] end restore_tensors2 cost 0.0005393028259277344 seconds
DEBUG 01-14 20:42:32.810284.810284 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0033512115478515625 seconds
DEBUG 01-14 20:42:32.810431.810431 cuda_h.py:10] start restore2model
DEBUG 01-14 20:42:32.813800.813800 cuda_h.py:19] end restore2model cost 0.0027000904083251953 seconds
DEBUG 01-14 20:42:32.813021.813021 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.0062732696533203125 seconds
DEBUG 01-14 20:42:32.813009.813009 cuda_h.py:10] start gpu_sexperts
DEBUG 01-14 20:42:32.813045.813045 cuda_h.py:19] end gpu_sexperts cost 0.00027680397033691406 seconds
DEBUG 01-14 20:42:32.813822.813822 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-14 20:42:32.813432.813432 lmp.py:1683] 
DEBUG 01-14 20:42:32.813432.813432 lmp.py:1683]   Computing 32 experts on CPU...
DEBUG 01-14 20:42:32.813652.813652 cuda_h.py:19] end cpu_experts_submit cost 5.698204040527344e-05 seconds
DEBUG 01-14 20:42:32.814448.814448 cuda_h.py:10] start experts_func_mgpu_group_pad
DEBUG 01-14 20:42:32.825173.825173 mlpmodule.py:1460] group tensors cost 0.010544300079345703 s
DEBUG 01-14 20:42:32.825291.825291 cuda_h.py:10] start move_flat_hidden2cpu
DEBUG 01-14 20:42:32.829745.829745 cuda_h.py:19] end experts_func_mgpu_group_pad cost 0.015530824661254883 seconds
DEBUG 01-14 20:42:32.831585.831585 cuda_h.py:10] start gpu_group_list
DEBUG 01-14 20:42:32.832167.832167 cuda_h.py:19] end gpu_group_list cost 0.0006728172302246094 seconds
DEBUG 01-14 20:42:32.832732.832732 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-14 20:42:32.832598.832598 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.9325485229492188e-05 seconds
DEBUG 01-14 20:42:32.833872.833872 cuda_h.py:10] start wait_experts
INFO 01-14 20:42:32.833324.833324 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 6e4ea367-0eaa-4ca0-a785-c90f2b4103a9
DEBUG 01-14 20:42:32.833052.833052 cuda_h.py:19] end move_flat_hidden2cpu cost 0.0074558258056640625 seconds
DEBUG 01-14 20:42:32.834571.834571 mlpmodule.py:1533] pad cost 0.0015320777893066406 s
DEBUG 01-14 20:42:32.835475.835475 mlpmodule.py:1539] create cpu tensor cost 3.719329833984375e-05 s
DEBUG 01-14 20:42:32.837763.837763 mlpmodule.py:1544] move to cpu cost 0.002033710479736328 s
DEBUG 01-14 20:42:32.846329.846329 mlpmodule.py:1558] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-14 20:42:32.847215.847215 mlpmodule.py:1559] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-14 20:42:32.847636.847636 mlpmodule.py:1564] group_w3 first element: -0.0211181640625
WARNING 01-14 20:42:32.847627.847627 mlpmodule.py:1574] start einsum2
DEBUG 01-14 20:42:32.864583.864583 mlpmodule.py:1584] group einsum cost 0.027764320373535156 s
DEBUG 01-14 20:42:32.865230.865230 mlpmodule.py:1593] cpy2cputensor cost 0.0007333755493164062 s
DEBUG 01-14 20:42:32.865245.865245 cuda_h.py:10] start move_outputs
INFO 01-14 20:42:32.866814.866814 client.py:127] Model loaded
DEBUG 01-14 20:42:32.866538.866538 cuda_h.py:19] end wait_experts cost 0.0336604118347168 seconds
DEBUG 01-14 20:42:32.866899.866899 cuda_h.py:10] start gpu_experts
DEBUG 01-14 20:42:32.866690.866690 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-14 20:42:32.867221.867221 cuda_h.py:19] end move_outputs cost 0.0020003318786621094 seconds
DEBUG 01-14 20:42:32.871753.871753 cuda_h.py:19] end wait_cetm_experts cost 0.0047550201416015625 seconds
DEBUG 01-14 20:42:32.872953.872953 cuda_h.py:10] start gpu_group_einsum_mp_multi_list
DEBUG 01-14 20:42:32.872473.872473 cuda_h.py:10] start gpu_group_tensor
DEBUG 01-14 20:42:32.872484.872484 cuda_h.py:19] end gpu_group_tensor cost 0.00044345855712890625 seconds
DEBUG 01-14 20:42:32.872578.872578 cuda_h.py:10] start gpu_group_einsum
DEBUG 01-14 20:42:32.874529.874529 cuda_h.py:19] end gpu_group_einsum cost 0.0011763572692871094 seconds
DEBUG 01-14 20:42:32.874458.874458 cuda_h.py:10] start gpu_final_hidden_states_scatter
DEBUG 01-14 20:42:32.874827.874827 cuda_h.py:10] start all_expert_outputs_slices
DEBUG 01-14 20:42:32.875513.875513 cuda_h.py:19] end all_expert_outputs_slices cost 0.000629425048828125 seconds
DEBUG 01-14 20:42:32.875827.875827 cuda_h.py:10] start concat_expert_out
DEBUG 01-14 20:42:32.875550.875550 cuda_h.py:19] end concat_expert_out cost 0.0001385211944580078 seconds
DEBUG 01-14 20:42:32.875707.875707 cuda_h.py:10] start index_scatter
DEBUG 01-14 20:42:32.875258.875258 cuda_h.py:19] end index_scatter cost 0.0001423358917236328 seconds
DEBUG 01-14 20:42:32.876334.876334 cuda_h.py:19] end gpu_final_hidden_states_scatter cost 0.0015234947204589844 seconds
DEBUG 01-14 20:42:32.876380.876380 cuda_h.py:19] end gpu_experts cost 0.009338140487670898 seconds
DEBUG 01-14 20:42:32.876097.876097 cuda_h.py:10] start all_expert_weight_slices
DEBUG 01-14 20:42:32.878549.878549 cuda_h.py:19] end all_expert_weight_slices cost 0.00225067138671875 seconds
DEBUG 01-14 20:42:32.878552.878552 cuda_h.py:10] start cpuoutputsdeal
DEBUG 01-14 20:42:32.879420.879420 cuda_h.py:10] start index_scatter
DEBUG 01-14 20:42:32.880282.880282 cuda_h.py:19] end index_scatter cost 0.0001246929168701172 seconds
DEBUG 01-14 20:42:32.880988.880988 cuda_h.py:19] end cpuoutputsdeal cost 0.0012612342834472656 seconds
DEBUG 01-14 20:42:32.880941.880941 cuda_h.py:19] end layer_moe_generate_mp_l_14 cost 0.07879972457885742 seconds
DEBUG 01-14 20:42:32.881885.881885 cuda_h.py:19] end prefill_layer cost 0.09805798530578613 seconds
DEBUG 01-14 20:42:32.881081.881081 lmp.py:1551] -------------------------------- end prefill layer 13 --------------------------------
DEBUG 01-14 20:42:32.881369.881369 cuda_h.py:10] start prefill_layer
DEBUG 01-14 20:42:32.881225.881225 lmp.py:1494] -------------------------------- start prefill layer 14 --------------------------------
DEBUG 01-14 20:42:32.881890.881890 cuda_h.py:10] start start_load_qkvogn_s_weight_l_15
DEBUG 01-14 20:42:32.881654.881654 cuda_h.py:10] start start_load_qkvogn_s_weight_l_15
DEBUG 01-14 20:42:32.881221.881221 cuda_h.py:19] end start_load_qkvogn_s_weight_l_15 cost 5.91278076171875e-05 seconds
DEBUG 01-14 20:42:32.881669.881669 cuda_h.py:10] start sllm_worker_task
DEBUG 01-14 20:42:32.881546.881546 cuda_h.py:19] end start_load_qkvogn_s_weight_l_15 cost 0.00027060508728027344 seconds
DEBUG 01-14 20:42:32.881332.881332 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-14 20:42:32.882506.882506 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-14 20:42:32.882131.882131 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-14 20:42:32.889489.889489 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-14 20:42:32.889360.889360 cuda_h.py:19] end allocate_cuda_memory cost 0.0069506168365478516 seconds
DEBUG 01-14 20:42:32.889714.889714 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-14 20:42:32.889007.889007 sllm_store_c.py:27] get device uuid map
DEBUG 01-14 20:42:32.889095.889095 sllm_store_c.py:29] call client load into gpu
DEBUG 01-14 20:42:32.889421.889421 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 6109a5f3-f675-4ea9-8397-6e58febf4ad2
DEBUG 01-14 20:42:32.889582.889582 client.py:106] call stub.LoadModelAsync
DEBUG 01-14 20:42:32.889808.889808 cuda_h.py:10] start self_attn
INFO 01-14 20:42:32.890263.890263 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 6109a5f3-f675-4ea9-8397-6e58febf4ad2
DEBUG 01-14 20:42:32.890199.890199 cuda_h.py:19] end load_into_gpu_async cost 0.0015802383422851562 seconds
DEBUG 01-14 20:42:32.890816.890816 cuda_h.py:10] start restore_tensors2
DEBUG 01-14 20:42:32.890926.890926 cuda_h.py:19] end restore_tensors2 cost 7.462501525878906e-05 seconds
DEBUG 01-14 20:42:32.891881.891881 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.008965730667114258 seconds
INFO 01-14 20:42:32.891758.891758 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 6109a5f3-f675-4ea9-8397-6e58febf4ad2
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-14 20:42:32.893015.893015 cuda_h.py:19] end self_attn cost 0.0039255619049072266 seconds
DEBUG 01-14 20:42:32.894541.894541 cuda_h.py:19] end iln_self_attn_paln cost 0.012176990509033203 seconds
DEBUG 01-14 20:42:32.894047.894047 cuda_h.py:10] start layer_moe_generate_mp_l_15
DEBUG 01-14 20:42:32.894632.894632 cuda_h.py:10] start gate
DEBUG 01-14 20:42:32.895436.895436 cuda_h.py:19] end gate cost 0.0009884834289550781 seconds
DEBUG 01-14 20:42:32.895829.895829 cuda_h.py:10] start experts_map_get
DEBUG 01-14 20:42:32.896304.896304 lmp.py:1615] 
DEBUG 01-14 20:42:32.896304.896304 lmp.py:1615] Expert Token Distribution & Device Allocation:
DEBUG 01-14 20:42:32.896710.896710 lmp.py:1616]   Total experts: 64
DEBUG 01-14 20:42:32.896718.896718 lmp.py:1617]   CPU experts: 32 (50%)
DEBUG 01-14 20:42:32.896527.896527 lmp.py:1618]   GPU experts: 32 (50%)
DEBUG 01-14 20:42:32.896713.896713 lmp.py:1619] 
DEBUG 01-14 20:42:32.896713.896713 lmp.py:1619]   Expert ID | Tokens | Device
DEBUG 01-14 20:42:32.896708.896708 lmp.py:1620]   -----------------------------------
DEBUG 01-14 20:42:32.896609.896609 lmp.py:1625]   Expert 34 |     19 | CPU
DEBUG 01-14 20:42:32.896386.896386 lmp.py:1625]   Expert 13 |     42 | CPU
DEBUG 01-14 20:42:32.896903.896903 lmp.py:1625]   Expert  7 |     43 | CPU
DEBUG 01-14 20:42:32.896136.896136 lmp.py:1625]   Expert 39 |     83 | CPU
DEBUG 01-14 20:42:32.896084.896084 lmp.py:1625]   Expert 54 |     88 | CPU
DEBUG 01-14 20:42:32.896032.896032 lmp.py:1625]   Expert 49 |     93 | CPU
DEBUG 01-14 20:42:32.896311.896311 lmp.py:1625]   Expert 18 |     95 | CPU
DEBUG 01-14 20:42:32.896829.896829 lmp.py:1625]   Expert 59 |     95 | CPU
DEBUG 01-14 20:42:32.896870.896870 lmp.py:1625]   Expert 16 |    101 | CPU
DEBUG 01-14 20:42:32.896149.896149 lmp.py:1625]   Expert 41 |    104 | CPU
DEBUG 01-14 20:42:32.896766.896766 lmp.py:1625]   Expert  0 |    111 | CPU
DEBUG 01-14 20:42:32.896145.896145 lmp.py:1625]   Expert 45 |    111 | CPU
DEBUG 01-14 20:42:32.896854.896854 lmp.py:1625]   Expert 22 |    115 | CPU
DEBUG 01-14 20:42:32.896802.896802 lmp.py:1625]   Expert 21 |    118 | CPU
DEBUG 01-14 20:42:32.896750.896750 lmp.py:1625]   Expert 52 |    131 | CPU
DEBUG 01-14 20:42:32.896222.896222 lmp.py:1625]   Expert  8 |    140 | CPU
DEBUG 01-14 20:42:32.896408.896408 lmp.py:1625]   Expert 17 |    141 | CPU
DEBUG 01-14 20:42:32.896595.896595 lmp.py:1625]   Expert 61 |    141 | CPU
DEBUG 01-14 20:42:32.896020.896020 lmp.py:1625]   Expert 12 |    144 | CPU
DEBUG 01-14 20:42:32.896729.896729 lmp.py:1625]   Expert 38 |    145 | CPU
DEBUG 01-14 20:42:32.897962.897962 lmp.py:1625]   Expert 35 |    149 | CPU
DEBUG 01-14 20:42:32.897433.897433 lmp.py:1625]   Expert 36 |    153 | CPU
DEBUG 01-14 20:42:32.897381.897381 lmp.py:1625]   Expert 48 |    155 | CPU
DEBUG 01-14 20:42:32.897575.897575 lmp.py:1625]   Expert 60 |    157 | CPU
DEBUG 01-14 20:42:32.897530.897530 lmp.py:1625]   Expert 15 |    160 | CPU
DEBUG 01-14 20:42:32.897478.897478 lmp.py:1625]   Expert 27 |    168 | CPU
DEBUG 01-14 20:42:32.897711.897711 lmp.py:1625]   Expert 31 |    169 | CPU
DEBUG 01-14 20:42:32.897420.897420 lmp.py:1625]   Expert 19 |    181 | CPU
DEBUG 01-14 20:42:32.897653.897653 lmp.py:1625]   Expert 53 |    182 | CPU
DEBUG 01-14 20:42:32.897316.897316 lmp.py:1625]   Expert 20 |    184 | CPU
DEBUG 01-14 20:42:32.897741.897741 lmp.py:1625]   Expert 40 |    184 | CPU
DEBUG 01-14 20:42:32.897405.897405 lmp.py:1625]   Expert 50 |    186 | CPU
DEBUG 01-14 20:42:32.897114.897114 lmp.py:1625]   Expert  4 |    192 | GPU
DEBUG 01-14 20:42:32.897301.897301 lmp.py:1625]   Expert 46 |    192 | GPU
DEBUG 01-14 20:42:32.897057.897057 lmp.py:1625]   Expert 11 |    201 | GPU
DEBUG 01-14 20:42:32.897005.897005 lmp.py:1625]   Expert 30 |    209 | GPU
DEBUG 01-14 20:42:32.897668.897668 lmp.py:1625]   Expert 43 |    211 | GPU
DEBUG 01-14 20:42:32.897332.897332 lmp.py:1625]   Expert 26 |    212 | GPU
DEBUG 01-14 20:42:32.897564.897564 lmp.py:1625]   Expert 29 |    216 | GPU
DEBUG 01-14 20:42:32.897797.897797 lmp.py:1625]   Expert 14 |    221 | GPU
DEBUG 01-14 20:42:32.897507.897507 lmp.py:1625]   Expert 57 |    226 | GPU
DEBUG 01-14 20:42:32.897170.897170 lmp.py:1625]   Expert  6 |    229 | GPU
DEBUG 01-14 20:42:32.897357.897357 lmp.py:1625]   Expert 23 |    239 | GPU
DEBUG 01-14 20:42:32.897020.897020 lmp.py:1625]   Expert 33 |    241 | GPU
DEBUG 01-14 20:42:32.897730.897730 lmp.py:1625]   Expert  2 |    243 | GPU
DEBUG 01-14 20:42:32.897678.897678 lmp.py:1625]   Expert  3 |    243 | GPU
DEBUG 01-14 20:42:32.897626.897626 lmp.py:1625]   Expert 56 |    251 | GPU
DEBUG 01-14 20:42:32.897289.897289 lmp.py:1625]   Expert 37 |    255 | GPU
DEBUG 01-14 20:42:32.897191.897191 lmp.py:1625]   Expert  9 |    261 | GPU
DEBUG 01-14 20:42:32.897378.897378 lmp.py:1625]   Expert 42 |    262 | GPU
DEBUG 01-14 20:42:32.897610.897610 lmp.py:1625]   Expert 44 |    264 | GPU
DEBUG 01-14 20:42:32.898559.898559 lmp.py:1625]   Expert 32 |    267 | GPU
DEBUG 01-14 20:42:32.898507.898507 lmp.py:1625]   Expert 55 |    272 | GPU
DEBUG 01-14 20:42:32.898693.898693 lmp.py:1625]   Expert 51 |    276 | GPU
DEBUG 01-14 20:42:32.898403.898403 lmp.py:1625]   Expert 28 |    279 | GPU
DEBUG 01-14 20:42:32.898112.898112 lmp.py:1625]   Expert 10 |    280 | GPU
DEBUG 01-14 20:42:32.898822.898822 lmp.py:1625]   Expert 58 |    283 | GPU
DEBUG 01-14 20:42:32.898446.898446 lmp.py:1625]   Expert  1 |    286 | GPU
DEBUG 01-14 20:42:32.898586.898586 lmp.py:1625]   Expert 63 |    289 | GPU
DEBUG 01-14 20:42:32.898726.898726 lmp.py:1625]   Expert 24 |    291 | GPU
DEBUG 01-14 20:42:32.898866.898866 lmp.py:1625]   Expert 25 |    308 | GPU
DEBUG 01-14 20:42:32.898768.898768 lmp.py:1625]   Expert 47 |    321 | GPU
DEBUG 01-14 20:42:32.898955.898955 lmp.py:1625]   Expert 62 |    327 | GPU
DEBUG 01-14 20:42:32.898141.898141 lmp.py:1625]   Expert  5 |    353 | GPU
DEBUG 01-14 20:42:32.898235.898235 lmp.py:1626] 
DEBUG 01-14 20:42:32.898235.898235 lmp.py:1626]   CPU total tokens: 4088 (33.3%)
DEBUG 01-14 20:42:32.898521.898521 lmp.py:1627]   GPU total tokens: 8200 (66.7%)
DEBUG 01-14 20:42:32.898483.898483 cuda_h.py:19] end experts_map_get cost 0.0028533935546875 seconds
DEBUG 01-14 20:42:32.898090.898090 mlpmodule.py:1367]  experts func einsum cost 0.08404779434204102 s
DEBUG 01-14 20:42:32.898453.898453 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
INFO 01-14 20:42:32.898842.898842 client.py:127] Model loaded
DEBUG 01-14 20:42:32.899548.899548 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-14 20:42:32.899842.899842 cuda_h.py:10] start restore2model
DEBUG 01-14 20:42:32.899074.899074 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-14 20:42:32.900221.900221 cuda_h.py:19] end allocate_cuda_memory cost 0.0002956390380859375 seconds
DEBUG 01-14 20:42:32.900485.900485 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-14 20:42:32.900659.900659 sllm_store_c.py:27] get device uuid map
DEBUG 01-14 20:42:32.900979.900979 sllm_store_c.py:29] call client load into gpu
DEBUG 01-14 20:42:32.900894.900894 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, f8efedbb-a6b0-4adf-903e-6bb7bfbfde0c
DEBUG 01-14 20:42:32.900676.900676 client.py:106] call stub.LoadModelAsync
DEBUG 01-14 20:42:32.901153.901153 cuda_h.py:19] end restore2model cost 0.0016682147979736328 seconds
DEBUG 01-14 20:42:32.901486.901486 cuda_h.py:19] end sllm_worker_task cost 0.019271135330200195 seconds
INFO 01-14 20:42:32.902546.902546 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, f8efedbb-a6b0-4adf-903e-6bb7bfbfde0c
DEBUG 01-14 20:42:32.902819.902819 cuda_h.py:19] end load_into_gpu_async cost 0.002016305923461914 seconds
DEBUG 01-14 20:42:32.902476.902476 cuda_h.py:10] start restore_tensors2
DEBUG 01-14 20:42:32.902253.902253 cuda_h.py:19] end restore_tensors2 cost 0.0004401206970214844 seconds
DEBUG 01-14 20:42:32.902143.902143 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.003584146499633789 seconds
DEBUG 01-14 20:42:32.902243.902243 cuda_h.py:10] start restore2model
DEBUG 01-14 20:42:32.905522.905522 cuda_h.py:19] end restore2model cost 0.0025641918182373047 seconds
DEBUG 01-14 20:42:32.905405.905405 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.006448984146118164 seconds
DEBUG 01-14 20:42:32.905915.905915 cuda_h.py:10] start gpu_sexperts
DEBUG 01-14 20:42:32.905602.905602 cuda_h.py:19] end gpu_sexperts cost 0.0002994537353515625 seconds
DEBUG 01-14 20:42:32.905094.905094 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-14 20:42:32.905896.905896 lmp.py:1683] 
DEBUG 01-14 20:42:32.905896.905896 lmp.py:1683]   Computing 32 experts on CPU...
DEBUG 01-14 20:42:32.905070.905070 cuda_h.py:19] end cpu_experts_submit cost 5.936622619628906e-05 seconds
DEBUG 01-14 20:42:32.906581.906581 cuda_h.py:10] start experts_func_mgpu_group_pad
DEBUG 01-14 20:42:32.913596.913596 mlpmodule.py:1460] group tensors cost 0.007287502288818359 s
DEBUG 01-14 20:42:32.914977.914977 cuda_h.py:10] start move_flat_hidden2cpu
DEBUG 01-14 20:42:32.916641.916641 cuda_h.py:19] end experts_func_mgpu_group_pad cost 0.010842084884643555 seconds
DEBUG 01-14 20:42:32.918833.918833 cuda_h.py:10] start gpu_group_list
DEBUG 01-14 20:42:32.918829.918829 cuda_h.py:19] end gpu_group_list cost 0.000354766845703125 seconds
DEBUG 01-14 20:42:32.918178.918178 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-14 20:42:32.918201.918201 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 1.7881393432617188e-05 seconds
DEBUG 01-14 20:42:32.918334.918334 cuda_h.py:10] start wait_experts
INFO 01-14 20:42:32.918514.918514 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, f8efedbb-a6b0-4adf-903e-6bb7bfbfde0c
DEBUG 01-14 20:42:32.921804.921804 cuda_h.py:19] end move_flat_hidden2cpu cost 0.006824016571044922 seconds
DEBUG 01-14 20:42:32.923078.923078 mlpmodule.py:1533] pad cost 0.0017397403717041016 s
DEBUG 01-14 20:42:32.923658.923658 mlpmodule.py:1539] create cpu tensor cost 4.506111145019531e-05 s
DEBUG 01-14 20:42:32.925561.925561 mlpmodule.py:1544] move to cpu cost 0.002207517623901367 s
DEBUG 01-14 20:42:32.935592.935592 mlpmodule.py:1558] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-14 20:42:32.935393.935393 mlpmodule.py:1559] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-14 20:42:32.935720.935720 mlpmodule.py:1564] group_w3 first element: 0.000789642333984375
WARNING 01-14 20:42:32.936195.936195 mlpmodule.py:1574] start einsum2
DEBUG 01-14 20:42:32.955005.955005 mlpmodule.py:1584] group einsum cost 0.02960062026977539 s
DEBUG 01-14 20:42:32.956666.956666 mlpmodule.py:1593] cpy2cputensor cost 0.0007538795471191406 s
DEBUG 01-14 20:42:32.956442.956442 cuda_h.py:10] start move_outputs
DEBUG 01-14 20:42:32.959435.959435 cuda_h.py:19] end move_outputs cost 0.0031223297119140625 seconds
INFO 01-14 20:42:32.960267.960267 client.py:127] Model loaded
DEBUG 01-14 20:42:32.960659.960659 cuda_h.py:19] end wait_experts cost 0.04168558120727539 seconds
DEBUG 01-14 20:42:32.960390.960390 cuda_h.py:10] start gpu_experts
DEBUG 01-14 20:42:32.960307.960307 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-14 20:42:32.963404.963404 cuda_h.py:19] end wait_cetm_experts cost 0.003001689910888672 seconds
DEBUG 01-14 20:42:32.964761.964761 cuda_h.py:10] start gpu_group_einsum_mp_multi_list
DEBUG 01-14 20:42:32.964136.964136 cuda_h.py:10] start gpu_group_tensor
DEBUG 01-14 20:42:32.964194.964194 cuda_h.py:19] end gpu_group_tensor cost 0.000476837158203125 seconds
DEBUG 01-14 20:42:32.964573.964573 cuda_h.py:10] start gpu_group_einsum
DEBUG 01-14 20:42:32.966578.966578 cuda_h.py:19] end gpu_group_einsum cost 0.0012180805206298828 seconds
DEBUG 01-14 20:42:32.966779.966779 cuda_h.py:10] start gpu_final_hidden_states_scatter
DEBUG 01-14 20:42:32.966479.966479 cuda_h.py:10] start all_expert_outputs_slices
DEBUG 01-14 20:42:32.967894.967894 cuda_h.py:19] end all_expert_outputs_slices cost 0.0006306171417236328 seconds
DEBUG 01-14 20:42:32.967387.967387 cuda_h.py:10] start concat_expert_out
DEBUG 01-14 20:42:32.967440.967440 cuda_h.py:19] end concat_expert_out cost 0.00013589859008789062 seconds
DEBUG 01-14 20:42:32.967048.967048 cuda_h.py:10] start index_scatter
DEBUG 01-14 20:42:32.968534.968534 cuda_h.py:19] end index_scatter cost 0.00014281272888183594 seconds
DEBUG 01-14 20:42:32.968855.968855 cuda_h.py:19] end gpu_final_hidden_states_scatter cost 0.0015647411346435547 seconds
DEBUG 01-14 20:42:32.968523.968523 cuda_h.py:19] end gpu_experts cost 0.007649660110473633 seconds
DEBUG 01-14 20:42:32.968950.968950 cuda_h.py:10] start all_expert_weight_slices
DEBUG 01-14 20:42:32.970745.970745 cuda_h.py:19] end all_expert_weight_slices cost 0.0022897720336914062 seconds
DEBUG 01-14 20:42:32.970603.970603 cuda_h.py:10] start cpuoutputsdeal
DEBUG 01-14 20:42:32.971968.971968 cuda_h.py:10] start index_scatter
DEBUG 01-14 20:42:32.972108.972108 cuda_h.py:19] end index_scatter cost 0.00012135505676269531 seconds
DEBUG 01-14 20:42:32.972767.972767 cuda_h.py:19] end cpuoutputsdeal cost 0.0012722015380859375 seconds
DEBUG 01-14 20:42:32.972442.972442 cuda_h.py:19] end layer_moe_generate_mp_l_15 cost 0.07799267768859863 seconds
DEBUG 01-14 20:42:32.972637.972637 cuda_h.py:19] end prefill_layer cost 0.09159731864929199 seconds
DEBUG 01-14 20:42:32.973208.973208 lmp.py:1551] -------------------------------- end prefill layer 14 --------------------------------
DEBUG 01-14 20:42:32.973402.973402 cuda_h.py:10] start prefill_layer
DEBUG 01-14 20:42:32.973072.973072 lmp.py:1494] -------------------------------- start prefill layer 15 --------------------------------
DEBUG 01-14 20:42:32.973219.973219 cuda_h.py:10] start start_load_qkvogn_s_weight_l_16
DEBUG 01-14 20:42:32.973273.973273 cuda_h.py:10] start start_load_qkvogn_s_weight_l_16
DEBUG 01-14 20:42:32.973773.973773 cuda_h.py:19] end start_load_qkvogn_s_weight_l_16 cost 4.220008850097656e-05 seconds
DEBUG 01-14 20:42:32.973643.973643 cuda_h.py:10] start sllm_worker_task
DEBUG 01-14 20:42:32.973090.973090 cuda_h.py:19] end start_load_qkvogn_s_weight_l_16 cost 0.00021219253540039062 seconds
DEBUG 01-14 20:42:32.973802.973802 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-14 20:42:32.973236.973236 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-14 20:42:32.973536.973536 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-14 20:42:32.978257.978257 cuda_h.py:19] end allocate_cuda_memory cost 0.004610300064086914 seconds
DEBUG 01-14 20:42:32.978028.978028 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-14 20:42:32.978897.978897 sllm_store_c.py:27] get device uuid map
DEBUG 01-14 20:42:32.978064.978064 sllm_store_c.py:29] call client load into gpu
DEBUG 01-14 20:42:32.978012.978012 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, e8db0a5f-24d2-4c67-b9eb-bec68a9e0ca8
DEBUG 01-14 20:42:32.978280.978280 client.py:106] call stub.LoadModelAsync
DEBUG 01-14 20:42:32.978711.978711 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-14 20:42:32.979201.979201 mlpmodule.py:1367]  experts func einsum cost 0.0726480484008789 s
DEBUG 01-14 20:42:32.979890.979890 cuda_h.py:10] start self_attn
INFO 01-14 20:42:32.979070.979070 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, e8db0a5f-24d2-4c67-b9eb-bec68a9e0ca8
DEBUG 01-14 20:42:32.979536.979536 cuda_h.py:19] end load_into_gpu_async cost 0.0012784004211425781 seconds
DEBUG 01-14 20:42:32.979623.979623 cuda_h.py:10] start restore_tensors2
DEBUG 01-14 20:42:32.979295.979295 cuda_h.py:19] end restore_tensors2 cost 7.891654968261719e-05 seconds
DEBUG 01-14 20:42:32.980257.980257 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.006310224533081055 seconds
INFO 01-14 20:42:32.980915.980915 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, e8db0a5f-24d2-4c67-b9eb-bec68a9e0ca8
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-14 20:42:32.983671.983671 cuda_h.py:19] end self_attn cost 0.004045009613037109 seconds
DEBUG 01-14 20:42:32.984558.984558 cuda_h.py:19] end iln_self_attn_paln cost 0.010276317596435547 seconds
DEBUG 01-14 20:42:32.984991.984991 cuda_h.py:10] start layer_moe_generate_mp_l_16
DEBUG 01-14 20:42:32.984529.984529 cuda_h.py:10] start gate
DEBUG 01-14 20:42:32.984463.984463 cuda_h.py:19] end gate cost 0.0007498264312744141 seconds
DEBUG 01-14 20:42:32.985452.985452 cuda_h.py:10] start experts_map_get
DEBUG 01-14 20:42:32.985949.985949 lmp.py:1615] 
DEBUG 01-14 20:42:32.985949.985949 lmp.py:1615] Expert Token Distribution & Device Allocation:
DEBUG 01-14 20:42:32.985195.985195 lmp.py:1616]   Total experts: 64
DEBUG 01-14 20:42:32.985620.985620 lmp.py:1617]   CPU experts: 32 (50%)
DEBUG 01-14 20:42:32.985899.985899 lmp.py:1618]   GPU experts: 32 (50%)
DEBUG 01-14 20:42:32.985648.985648 lmp.py:1619] 
DEBUG 01-14 20:42:32.985648.985648 lmp.py:1619]   Expert ID | Tokens | Device
DEBUG 01-14 20:42:32.985874.985874 lmp.py:1620]   -----------------------------------
DEBUG 01-14 20:42:32.985816.985816 lmp.py:1625]   Expert 20 |     71 | CPU
DEBUG 01-14 20:42:32.985088.985088 lmp.py:1625]   Expert  0 |     72 | CPU
DEBUG 01-14 20:42:32.985122.985122 lmp.py:1625]   Expert 41 |     81 | CPU
DEBUG 01-14 20:42:32.985202.985202 lmp.py:1625]   Expert  7 |     82 | CPU
DEBUG 01-14 20:42:32.985283.985283 lmp.py:1625]   Expert 63 |     84 | CPU
DEBUG 01-14 20:42:32.985840.985840 lmp.py:1625]   Expert 15 |     85 | CPU
DEBUG 01-14 20:42:32.985635.985635 lmp.py:1625]   Expert 45 |     90 | CPU
DEBUG 01-14 20:42:32.985669.985669 lmp.py:1625]   Expert 52 |     90 | CPU
DEBUG 01-14 20:42:32.985703.985703 lmp.py:1625]   Expert 28 |     91 | CPU
DEBUG 01-14 20:42:32.985545.985545 lmp.py:1625]   Expert 54 |    106 | CPU
DEBUG 01-14 20:42:32.985387.985387 lmp.py:1625]   Expert 12 |    112 | CPU
DEBUG 01-14 20:42:32.985944.985944 lmp.py:1625]   Expert 21 |    116 | CPU
DEBUG 01-14 20:42:32.985547.985547 lmp.py:1625]   Expert 62 |    117 | CPU
DEBUG 01-14 20:42:32.985628.985628 lmp.py:1625]   Expert 59 |    118 | CPU
DEBUG 01-14 20:42:32.985469.985469 lmp.py:1625]   Expert 55 |    121 | CPU
DEBUG 01-14 20:42:32.985311.985311 lmp.py:1625]   Expert  5 |    126 | CPU
DEBUG 01-14 20:42:32.985153.985153 lmp.py:1625]   Expert 14 |    140 | CPU
DEBUG 01-14 20:42:32.986187.986187 lmp.py:1625]   Expert 34 |    144 | CPU
DEBUG 01-14 20:42:32.986983.986983 lmp.py:1625]   Expert  4 |    150 | CPU
DEBUG 01-14 20:42:32.986301.986301 lmp.py:1625]   Expert 51 |    150 | CPU
DEBUG 01-14 20:42:32.986097.986097 lmp.py:1625]   Expert 13 |    151 | CPU
DEBUG 01-14 20:42:32.986177.986177 lmp.py:1625]   Expert  1 |    154 | CPU
DEBUG 01-14 20:42:32.986019.986019 lmp.py:1625]   Expert 40 |    156 | CPU
DEBUG 01-14 20:42:32.986622.986622 lmp.py:1625]   Expert 61 |    157 | CPU
DEBUG 01-14 20:42:32.986226.986226 lmp.py:1625]   Expert 32 |    162 | CPU
DEBUG 01-14 20:42:32.986591.986591 lmp.py:1625]   Expert 16 |    163 | CPU
DEBUG 01-14 20:42:32.986910.986910 lmp.py:1625]   Expert 10 |    169 | CPU
DEBUG 01-14 20:42:32.986467.986467 lmp.py:1625]   Expert 42 |    170 | CPU
DEBUG 01-14 20:42:32.986501.986501 lmp.py:1625]   Expert 22 |    171 | CPU
DEBUG 01-14 20:42:32.986104.986104 lmp.py:1625]   Expert 44 |    171 | CPU
DEBUG 01-14 20:42:32.986708.986708 lmp.py:1625]   Expert 11 |    172 | CPU
DEBUG 01-14 20:42:32.986073.986073 lmp.py:1625]   Expert  2 |    173 | CPU
DEBUG 01-14 20:42:32.986153.986153 lmp.py:1625]   Expert  6 |    177 | GPU
DEBUG 01-14 20:42:32.986756.986756 lmp.py:1625]   Expert 30 |    181 | GPU
DEBUG 01-14 20:42:32.986883.986883 lmp.py:1625]   Expert 25 |    183 | GPU
DEBUG 01-14 20:42:32.986963.986963 lmp.py:1625]   Expert 35 |    184 | GPU
DEBUG 01-14 20:42:32.986520.986520 lmp.py:1625]   Expert 19 |    186 | GPU
DEBUG 01-14 20:42:32.986077.986077 lmp.py:1625]   Expert 56 |    188 | GPU
DEBUG 01-14 20:42:32.986681.986681 lmp.py:1625]   Expert 47 |    189 | GPU
DEBUG 01-14 20:42:32.986284.986284 lmp.py:1625]   Expert 26 |    191 | GPU
DEBUG 01-14 20:42:32.986888.986888 lmp.py:1625]   Expert 53 |    191 | GPU
DEBUG 01-14 20:42:32.986730.986730 lmp.py:1625]   Expert 24 |    200 | GPU
DEBUG 01-14 20:42:32.986095.986095 lmp.py:1625]   Expert 57 |    207 | GPU
DEBUG 01-14 20:42:32.986698.986698 lmp.py:1625]   Expert 50 |    220 | GPU
DEBUG 01-14 20:42:32.986063.986063 lmp.py:1625]   Expert 48 |    221 | GPU
DEBUG 01-14 20:42:32.986620.986620 lmp.py:1625]   Expert 46 |    228 | GPU
DEBUG 01-14 20:42:32.986939.986939 lmp.py:1625]   Expert 18 |    235 | GPU
DEBUG 01-14 20:42:32.986496.986496 lmp.py:1625]   Expert 39 |    235 | GPU
DEBUG 01-14 20:42:32.986099.986099 lmp.py:1625]   Expert 37 |    237 | GPU
DEBUG 01-14 20:42:32.986464.986464 lmp.py:1625]   Expert  3 |    239 | GPU
DEBUG 01-14 20:42:32.986353.986353 lmp.py:1625]   Expert 29 |    251 | GPU
DEBUG 01-14 20:42:32.986956.986956 lmp.py:1625]   Expert 60 |    252 | GPU
DEBUG 01-14 20:42:32.986083.986083 lmp.py:1625]   Expert 31 |    259 | GPU
DEBUG 01-14 20:42:32.986401.986401 lmp.py:1625]   Expert 36 |    260 | GPU
DEBUG 01-14 20:42:32.986482.986482 lmp.py:1625]   Expert 17 |    262 | GPU
DEBUG 01-14 20:42:32.986039.986039 lmp.py:1625]   Expert 38 |    262 | GPU
DEBUG 01-14 20:42:32.986357.986357 lmp.py:1625]   Expert 23 |    263 | GPU
DEBUG 01-14 20:42:32.986722.986722 lmp.py:1625]   Expert  9 |    270 | GPU
DEBUG 01-14 20:42:32.987326.987326 lmp.py:1625]   Expert  8 |    288 | GPU
DEBUG 01-14 20:42:32.987691.987691 lmp.py:1625]   Expert 27 |    328 | GPU
DEBUG 01-14 20:42:32.987294.987294 lmp.py:1625]   Expert 43 |    367 | GPU
DEBUG 01-14 20:42:32.987421.987421 lmp.py:1625]   Expert 33 |    415 | GPU
DEBUG 01-14 20:42:32.987501.987501 lmp.py:1625]   Expert 58 |    478 | GPU
DEBUG 01-14 20:42:32.987058.987058 lmp.py:1625]   Expert 49 |    526 | GPU
DEBUG 01-14 20:42:32.987808.987808 lmp.py:1626] 
DEBUG 01-14 20:42:32.987808.987808 lmp.py:1626]   CPU total tokens: 4115 (33.5%)
DEBUG 01-14 20:42:32.987842.987842 lmp.py:1627]   GPU total tokens: 8173 (66.5%)
DEBUG 01-14 20:42:32.987644.987644 cuda_h.py:19] end experts_map_get cost 0.002140522003173828 seconds
DEBUG 01-14 20:42:32.987991.987991 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-14 20:42:32.987192.987192 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-14 20:42:32.987847.987847 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-14 20:42:32.987287.987287 cuda_h.py:19] end allocate_cuda_memory cost 0.0002472400665283203 seconds
INFO 01-14 20:42:32.987575.987575 client.py:127] Model loaded
DEBUG 01-14 20:42:32.988757.988757 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-14 20:42:32.988084.988084 cuda_h.py:10] start restore2model
DEBUG 01-14 20:42:32.988576.988576 sllm_store_c.py:27] get device uuid map
DEBUG 01-14 20:42:32.988654.988654 sllm_store_c.py:29] call client load into gpu
DEBUG 01-14 20:42:32.988894.988894 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, c89e9b66-a50c-49c1-8e12-30bab478aca6
DEBUG 01-14 20:42:32.988373.988373 client.py:106] call stub.LoadModelAsync
DEBUG 01-14 20:42:32.989086.989086 cuda_h.py:19] end restore2model cost 0.0009441375732421875 seconds
DEBUG 01-14 20:42:32.989320.989320 cuda_h.py:19] end sllm_worker_task cost 0.015701770782470703 seconds
INFO 01-14 20:42:32.989093.989093 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, c89e9b66-a50c-49c1-8e12-30bab478aca6
DEBUG 01-14 20:42:32.989480.989480 cuda_h.py:19] end load_into_gpu_async cost 0.001684427261352539 seconds
DEBUG 01-14 20:42:32.989435.989435 cuda_h.py:10] start restore_tensors2
DEBUG 01-14 20:42:32.990398.990398 cuda_h.py:19] end restore_tensors2 cost 0.0004630088806152344 seconds
DEBUG 01-14 20:42:32.990447.990447 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0030329227447509766 seconds
DEBUG 01-14 20:42:32.990939.990939 cuda_h.py:10] start restore2model
DEBUG 01-14 20:42:32.993785.993785 cuda_h.py:19] end restore2model cost 0.0030715465545654297 seconds
DEBUG 01-14 20:42:32.993966.993966 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.006336212158203125 seconds
DEBUG 01-14 20:42:32.993569.993569 cuda_h.py:10] start gpu_sexperts
DEBUG 01-14 20:42:32.993884.993884 cuda_h.py:19] end gpu_sexperts cost 0.0002739429473876953 seconds
DEBUG 01-14 20:42:32.994468.994468 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-14 20:42:32.994648.994648 lmp.py:1683] 
DEBUG 01-14 20:42:32.994648.994648 lmp.py:1683]   Computing 32 experts on CPU...
DEBUG 01-14 20:42:32.994723.994723 cuda_h.py:19] end cpu_experts_submit cost 5.459785461425781e-05 seconds
DEBUG 01-14 20:42:32.994062.994062 cuda_h.py:10] start experts_func_mgpu_group_pad
DEBUG 01-14 20:42:33.005561.005561 mlpmodule.py:1460] group tensors cost 0.01095724105834961 s
DEBUG 01-14 20:42:33.006196.006196 cuda_h.py:10] start move_flat_hidden2cpu
DEBUG 01-14 20:42:33.011126.011126 cuda_h.py:19] end experts_func_mgpu_group_pad cost 0.017275571823120117 seconds
DEBUG 01-14 20:42:33.013075.013075 cuda_h.py:19] end move_flat_hidden2cpu cost 0.007154226303100586 seconds
DEBUG 01-14 20:42:33.014765.014765 cuda_h.py:10] start gpu_group_list
DEBUG 01-14 20:42:33.015190.015190 cuda_h.py:19] end gpu_group_list cost 0.0006427764892578125 seconds
DEBUG 01-14 20:42:33.015431.015431 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-14 20:42:33.015786.015786 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.9325485229492188e-05 seconds
DEBUG 01-14 20:42:33.015291.015291 cuda_h.py:10] start wait_experts
INFO 01-14 20:42:33.015791.015791 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, c89e9b66-a50c-49c1-8e12-30bab478aca6
DEBUG 01-14 20:42:33.016807.016807 mlpmodule.py:1533] pad cost 0.0031092166900634766 s
DEBUG 01-14 20:42:33.017143.017143 mlpmodule.py:1539] create cpu tensor cost 4.100799560546875e-05 s
DEBUG 01-14 20:42:33.019650.019650 mlpmodule.py:1544] move to cpu cost 0.0020470619201660156 s
DEBUG 01-14 20:42:33.029385.029385 mlpmodule.py:1558] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-14 20:42:33.029317.029317 mlpmodule.py:1559] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-14 20:42:33.029625.029625 mlpmodule.py:1564] group_w3 first element: -0.0595703125
WARNING 01-14 20:42:33.029165.029165 mlpmodule.py:1574] start einsum2
INFO 01-14 20:42:33.046003.046003 client.py:127] Model loaded
DEBUG 01-14 20:42:33.046514.046514 cuda_h.py:19] end wait_experts cost 0.030668973922729492 seconds
DEBUG 01-14 20:42:33.046490.046490 cuda_h.py:10] start gpu_experts
DEBUG 01-14 20:42:33.046089.046089 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-14 20:42:33.047998.047998 mlpmodule.py:1584] group einsum cost 0.02770090103149414 s
DEBUG 01-14 20:42:33.047115.047115 mlpmodule.py:1593] cpy2cputensor cost 0.0007338523864746094 s
DEBUG 01-14 20:42:33.047268.047268 cuda_h.py:10] start move_outputs
DEBUG 01-14 20:42:33.050787.050787 cuda_h.py:19] end move_outputs cost 0.0019981861114501953 seconds
DEBUG 01-14 20:42:33.053052.053052 cuda_h.py:19] end wait_cetm_experts cost 0.007094144821166992 seconds
DEBUG 01-14 20:42:33.054756.054756 cuda_h.py:10] start gpu_group_einsum_mp_multi_list
DEBUG 01-14 20:42:33.054567.054567 cuda_h.py:10] start gpu_group_tensor
DEBUG 01-14 20:42:33.054704.054704 cuda_h.py:19] end gpu_group_tensor cost 0.0004291534423828125 seconds
DEBUG 01-14 20:42:33.054937.054937 cuda_h.py:10] start gpu_group_einsum
DEBUG 01-14 20:42:33.056007.056007 cuda_h.py:19] end gpu_group_einsum cost 0.0011594295501708984 seconds
DEBUG 01-14 20:42:33.056071.056071 cuda_h.py:10] start gpu_final_hidden_states_scatter
DEBUG 01-14 20:42:33.056393.056393 cuda_h.py:10] start all_expert_outputs_slices
DEBUG 01-14 20:42:33.057868.057868 cuda_h.py:19] end all_expert_outputs_slices cost 0.0006399154663085938 seconds
DEBUG 01-14 20:42:33.057453.057453 cuda_h.py:10] start concat_expert_out
DEBUG 01-14 20:42:33.057606.057606 cuda_h.py:19] end concat_expert_out cost 0.0001354217529296875 seconds
DEBUG 01-14 20:42:33.057208.057208 cuda_h.py:10] start index_scatter
DEBUG 01-14 20:42:33.058904.058904 cuda_h.py:19] end index_scatter cost 0.00014328956604003906 seconds
DEBUG 01-14 20:42:33.058364.058364 cuda_h.py:19] end gpu_final_hidden_states_scatter cost 0.001547098159790039 seconds
DEBUG 01-14 20:42:33.058887.058887 cuda_h.py:19] end gpu_experts cost 0.011768579483032227 seconds
DEBUG 01-14 20:42:33.058188.058188 cuda_h.py:10] start all_expert_weight_slices
DEBUG 01-14 20:42:33.060263.060263 cuda_h.py:19] end all_expert_weight_slices cost 0.0023529529571533203 seconds
DEBUG 01-14 20:42:33.060664.060664 cuda_h.py:10] start cpuoutputsdeal
DEBUG 01-14 20:42:33.061367.061367 cuda_h.py:10] start index_scatter
DEBUG 01-14 20:42:33.062507.062507 cuda_h.py:19] end index_scatter cost 0.00012159347534179688 seconds
DEBUG 01-14 20:42:33.062358.062358 cuda_h.py:19] end cpuoutputsdeal cost 0.0012745857238769531 seconds
DEBUG 01-14 20:42:33.062663.062663 cuda_h.py:19] end layer_moe_generate_mp_l_16 cost 0.07835507392883301 seconds
DEBUG 01-14 20:42:33.063415.063415 cuda_h.py:19] end prefill_layer cost 0.09012269973754883 seconds
DEBUG 01-14 20:42:33.063109.063109 lmp.py:1551] -------------------------------- end prefill layer 15 --------------------------------
DEBUG 01-14 20:42:33.063602.063602 cuda_h.py:10] start prefill_layer
DEBUG 01-14 20:42:33.063618.063618 lmp.py:1494] -------------------------------- start prefill layer 16 --------------------------------
DEBUG 01-14 20:42:33.063283.063283 cuda_h.py:10] start start_load_qkvogn_s_weight_l_17
DEBUG 01-14 20:42:33.063956.063956 cuda_h.py:10] start start_load_qkvogn_s_weight_l_17
DEBUG 01-14 20:42:33.063338.063338 cuda_h.py:19] end start_load_qkvogn_s_weight_l_17 cost 5.936622619628906e-05 seconds
DEBUG 01-14 20:42:33.064249.064249 cuda_h.py:10] start sllm_worker_task
DEBUG 01-14 20:42:33.064589.064589 cuda_h.py:19] end start_load_qkvogn_s_weight_l_17 cost 0.0002567768096923828 seconds
DEBUG 01-14 20:42:33.064089.064089 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-14 20:42:33.064203.064203 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-14 20:42:33.064444.064444 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-14 20:42:33.068988.068988 cuda_h.py:19] end allocate_cuda_memory cost 0.0042781829833984375 seconds
DEBUG 01-14 20:42:33.068619.068619 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-14 20:42:33.068905.068905 sllm_store_c.py:27] get device uuid map
DEBUG 01-14 20:42:33.068020.068020 sllm_store_c.py:29] call client load into gpu
DEBUG 01-14 20:42:33.068153.068153 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 105d2795-2bb2-436a-9a6b-6b84ac041f27
DEBUG 01-14 20:42:33.068123.068123 client.py:106] call stub.LoadModelAsync
DEBUG 01-14 20:42:33.069798.069798 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-14 20:42:33.069972.069972 mlpmodule.py:1367]  experts func einsum cost 0.07470226287841797 s
DEBUG 01-14 20:42:33.069781.069781 cuda_h.py:10] start self_attn
INFO 01-14 20:42:33.069441.069441 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 105d2795-2bb2-436a-9a6b-6b84ac041f27
DEBUG 01-14 20:42:33.070506.070506 cuda_h.py:19] end load_into_gpu_async cost 0.001317739486694336 seconds
DEBUG 01-14 20:42:33.070593.070593 cuda_h.py:10] start restore_tensors2
DEBUG 01-14 20:42:33.070537.070537 cuda_h.py:19] end restore_tensors2 cost 7.319450378417969e-05 seconds
DEBUG 01-14 20:42:33.070339.070339 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0059871673583984375 seconds
INFO 01-14 20:42:33.070129.070129 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 105d2795-2bb2-436a-9a6b-6b84ac041f27
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-14 20:42:33.074539.074539 cuda_h.py:19] end self_attn cost 0.004038810729980469 seconds
DEBUG 01-14 20:42:33.074497.074497 cuda_h.py:19] end iln_self_attn_paln cost 0.010024309158325195 seconds
DEBUG 01-14 20:42:33.074962.074962 cuda_h.py:10] start layer_moe_generate_mp_l_17
DEBUG 01-14 20:42:33.074394.074394 cuda_h.py:10] start gate
DEBUG 01-14 20:42:33.075424.075424 cuda_h.py:19] end gate cost 0.0006520748138427734 seconds
DEBUG 01-14 20:42:33.075922.075922 cuda_h.py:10] start experts_map_get
DEBUG 01-14 20:42:33.075516.075516 lmp.py:1615] 
DEBUG 01-14 20:42:33.075516.075516 lmp.py:1615] Expert Token Distribution & Device Allocation:
DEBUG 01-14 20:42:33.075372.075372 lmp.py:1616]   Total experts: 64
DEBUG 01-14 20:42:33.075406.075406 lmp.py:1617]   CPU experts: 32 (50%)
DEBUG 01-14 20:42:33.075578.075578 lmp.py:1618]   GPU experts: 32 (50%)
DEBUG 01-14 20:42:33.075175.075175 lmp.py:1619] 
DEBUG 01-14 20:42:33.075175.075175 lmp.py:1619]   Expert ID | Tokens | Device
DEBUG 01-14 20:42:33.075964.075964 lmp.py:1620]   -----------------------------------
DEBUG 01-14 20:42:33.075753.075753 lmp.py:1625]   Expert 45 |     46 | CPU
DEBUG 01-14 20:42:33.075349.075349 lmp.py:1625]   Expert 58 |     47 | CPU
DEBUG 01-14 20:42:33.075469.075469 lmp.py:1625]   Expert 49 |     65 | CPU
DEBUG 01-14 20:42:33.075735.075735 lmp.py:1625]   Expert 31 |     70 | CPU
DEBUG 01-14 20:42:33.075239.075239 lmp.py:1625]   Expert  4 |     71 | CPU
DEBUG 01-14 20:42:33.075266.075266 lmp.py:1625]   Expert 38 |     72 | CPU
DEBUG 01-14 20:42:33.075293.075293 lmp.py:1625]   Expert 43 |     72 | CPU
DEBUG 01-14 20:42:33.075843.075843 lmp.py:1625]   Expert 41 |     73 | CPU
DEBUG 01-14 20:42:33.075917.075917 lmp.py:1625]   Expert 47 |     77 | CPU
DEBUG 01-14 20:42:33.075990.075990 lmp.py:1625]   Expert  0 |     99 | CPU
DEBUG 01-14 20:42:33.075825.075825 lmp.py:1625]   Expert 14 |     99 | CPU
DEBUG 01-14 20:42:33.075376.075376 lmp.py:1625]   Expert 51 |    100 | CPU
DEBUG 01-14 20:42:33.075403.075403 lmp.py:1625]   Expert 57 |    100 | CPU
DEBUG 01-14 20:42:33.075953.075953 lmp.py:1625]   Expert 26 |    112 | CPU
DEBUG 01-14 20:42:33.075265.075265 lmp.py:1625]   Expert  2 |    115 | CPU
DEBUG 01-14 20:42:33.076313.076313 lmp.py:1625]   Expert 50 |    115 | CPU
DEBUG 01-14 20:42:33.076578.076578 lmp.py:1625]   Expert 33 |    117 | CPU
DEBUG 01-14 20:42:33.076413.076413 lmp.py:1625]   Expert 11 |    118 | CPU
DEBUG 01-14 20:42:33.076487.076487 lmp.py:1625]   Expert 27 |    131 | CPU
DEBUG 01-14 20:42:33.076037.076037 lmp.py:1625]   Expert 55 |    133 | CPU
DEBUG 01-14 20:42:33.076303.076303 lmp.py:1625]   Expert 34 |    151 | CPU
DEBUG 01-14 20:42:33.076376.076376 lmp.py:1625]   Expert 28 |    153 | CPU
DEBUG 01-14 20:42:33.076973.076973 lmp.py:1625]   Expert 25 |    160 | CPU
DEBUG 01-14 20:42:33.076046.076046 lmp.py:1625]   Expert  9 |    163 | CPU
DEBUG 01-14 20:42:33.076358.076358 lmp.py:1625]   Expert 54 |    175 | CPU
DEBUG 01-14 20:42:33.076193.076193 lmp.py:1625]   Expert 13 |    177 | CPU
DEBUG 01-14 20:42:33.076028.076028 lmp.py:1625]   Expert  7 |    184 | CPU
DEBUG 01-14 20:42:33.076055.076055 lmp.py:1625]   Expert  6 |    185 | CPU
DEBUG 01-14 20:42:33.076321.076321 lmp.py:1625]   Expert 48 |    188 | CPU
DEBUG 01-14 20:42:33.076394.076394 lmp.py:1625]   Expert 56 |    189 | CPU
DEBUG 01-14 20:42:33.076706.076706 lmp.py:1625]   Expert 10 |    190 | CPU
DEBUG 01-14 20:42:33.076780.076780 lmp.py:1625]   Expert 46 |    193 | CPU
DEBUG 01-14 20:42:33.076092.076092 lmp.py:1625]   Expert 24 |    200 | GPU
DEBUG 01-14 20:42:33.076165.076165 lmp.py:1625]   Expert 61 |    201 | GPU
DEBUG 01-14 20:42:33.076477.076477 lmp.py:1625]   Expert 40 |    203 | GPU
DEBUG 01-14 20:42:33.076472.076472 lmp.py:1625]   Expert 29 |    204 | GPU
DEBUG 01-14 20:42:33.076976.076976 lmp.py:1625]   Expert 63 |    213 | GPU
DEBUG 01-14 20:42:33.076572.076572 lmp.py:1625]   Expert 42 |    214 | GPU
DEBUG 01-14 20:42:33.076407.076407 lmp.py:1625]   Expert 21 |    218 | GPU
DEBUG 01-14 20:42:33.076481.076481 lmp.py:1625]   Expert  1 |    219 | GPU
DEBUG 01-14 20:42:33.076554.076554 lmp.py:1625]   Expert 18 |    221 | GPU
DEBUG 01-14 20:42:33.076151.076151 lmp.py:1625]   Expert 22 |    227 | GPU
DEBUG 01-14 20:42:33.076986.076986 lmp.py:1625]   Expert 32 |    227 | GPU
DEBUG 01-14 20:42:33.076775.076775 lmp.py:1625]   Expert 12 |    228 | GPU
DEBUG 01-14 20:42:33.076802.076802 lmp.py:1625]   Expert 16 |    228 | GPU
DEBUG 01-14 20:42:33.076875.076875 lmp.py:1625]   Expert  3 |    234 | GPU
DEBUG 01-14 20:42:33.076710.076710 lmp.py:1625]   Expert 19 |    238 | GPU
DEBUG 01-14 20:42:33.076546.076546 lmp.py:1625]   Expert 36 |    239 | GPU
DEBUG 01-14 20:42:33.076904.076904 lmp.py:1625]   Expert 39 |    239 | GPU
DEBUG 01-14 20:42:33.076500.076500 lmp.py:1625]   Expert 59 |    241 | GPU
DEBUG 01-14 20:42:33.076812.076812 lmp.py:1625]   Expert  8 |    244 | GPU
DEBUG 01-14 20:42:33.076363.076363 lmp.py:1625]   Expert 37 |    246 | GPU
DEBUG 01-14 20:42:33.076959.076959 lmp.py:1625]   Expert 20 |    258 | GPU
DEBUG 01-14 20:42:33.076794.076794 lmp.py:1625]   Expert  5 |    259 | GPU
DEBUG 01-14 20:42:33.076153.076153 lmp.py:1625]   Expert 30 |    274 | GPU
DEBUG 01-14 20:42:33.076749.076749 lmp.py:1625]   Expert 62 |    282 | GPU
DEBUG 01-14 20:42:33.076823.076823 lmp.py:1625]   Expert 15 |    294 | GPU
DEBUG 01-14 20:42:33.076181.076181 lmp.py:1625]   Expert 35 |    302 | GPU
DEBUG 01-14 20:42:33.076208.076208 lmp.py:1625]   Expert 17 |    307 | GPU
DEBUG 01-14 20:42:33.076997.076997 lmp.py:1625]   Expert 60 |    331 | GPU
DEBUG 01-14 20:42:33.076832.076832 lmp.py:1625]   Expert 23 |    357 | GPU
DEBUG 01-14 20:42:33.076952.076952 lmp.py:1625]   Expert 52 |    365 | GPU
DEBUG 01-14 20:42:33.076072.076072 lmp.py:1625]   Expert 44 |    396 | GPU
DEBUG 01-14 20:42:33.076907.076907 lmp.py:1625]   Expert 53 |    439 | GPU
DEBUG 01-14 20:42:33.076172.076172 lmp.py:1626] 
DEBUG 01-14 20:42:33.076172.076172 lmp.py:1626]   CPU total tokens: 3940 (32.1%)
DEBUG 01-14 20:42:33.076723.076723 lmp.py:1627]   GPU total tokens: 8348 (67.9%)
DEBUG 01-14 20:42:33.076187.076187 cuda_h.py:19] end experts_map_get cost 0.0017437934875488281 seconds
DEBUG 01-14 20:42:33.077428.077428 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-14 20:42:33.077754.077754 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-14 20:42:33.077097.077097 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-14 20:42:33.077073.077073 cuda_h.py:19] end allocate_cuda_memory cost 0.00022554397583007812 seconds
DEBUG 01-14 20:42:33.077492.077492 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-14 20:42:33.077156.077156 sllm_store_c.py:27] get device uuid map
DEBUG 01-14 20:42:33.077587.077587 sllm_store_c.py:29] call client load into gpu
DEBUG 01-14 20:42:33.077336.077336 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 57702d03-5544-4212-868d-558f263f87db
DEBUG 01-14 20:42:33.077714.077714 client.py:106] call stub.LoadModelAsync
INFO 01-14 20:42:33.078846.078846 client.py:127] Model loaded
DEBUG 01-14 20:42:33.078404.078404 cuda_h.py:10] start restore2model
DEBUG 01-14 20:42:33.078221.078221 cuda_h.py:19] end restore2model cost 0.0004210472106933594 seconds
DEBUG 01-14 20:42:33.078680.078680 cuda_h.py:19] end sllm_worker_task cost 0.014492273330688477 seconds
INFO 01-14 20:42:33.078984.078984 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 57702d03-5544-4212-868d-558f263f87db
DEBUG 01-14 20:42:33.078642.078642 cuda_h.py:19] end load_into_gpu_async cost 0.0012676715850830078 seconds
DEBUG 01-14 20:42:33.078537.078537 cuda_h.py:10] start restore_tensors2
DEBUG 01-14 20:42:33.079220.079220 cuda_h.py:19] end restore_tensors2 cost 0.0004055500030517578 seconds
DEBUG 01-14 20:42:33.079202.079202 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0022690296173095703 seconds
DEBUG 01-14 20:42:33.079925.079925 cuda_h.py:10] start restore2model
DEBUG 01-14 20:42:33.082759.082759 cuda_h.py:19] end restore2model cost 0.002899169921875 seconds
DEBUG 01-14 20:42:33.082463.082463 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.005366086959838867 seconds
DEBUG 01-14 20:42:33.082358.082358 cuda_h.py:10] start gpu_sexperts
DEBUG 01-14 20:42:33.082561.082561 cuda_h.py:19] end gpu_sexperts cost 0.00029158592224121094 seconds
DEBUG 01-14 20:42:33.082483.082483 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-14 20:42:33.082954.082954 lmp.py:1683] 
DEBUG 01-14 20:42:33.082954.082954 lmp.py:1683]   Computing 32 experts on CPU...
DEBUG 01-14 20:42:33.082658.082658 cuda_h.py:19] end cpu_experts_submit cost 6.270408630371094e-05 seconds
DEBUG 01-14 20:42:33.082076.082076 cuda_h.py:10] start experts_func_mgpu_group_pad
DEBUG 01-14 20:42:33.100010.100010 mlpmodule.py:1460] group tensors cost 0.01659989356994629 s
DEBUG 01-14 20:42:33.101237.101237 cuda_h.py:10] start move_flat_hidden2cpu
DEBUG 01-14 20:42:33.105413.105413 cuda_h.py:19] end experts_func_mgpu_group_pad cost 0.022825241088867188 seconds
DEBUG 01-14 20:42:33.108920.108920 cuda_h.py:19] end move_flat_hidden2cpu cost 0.007432460784912109 seconds
DEBUG 01-14 20:42:33.108482.108482 cuda_h.py:10] start gpu_group_list
DEBUG 01-14 20:42:33.110534.110534 cuda_h.py:19] end gpu_group_list cost 0.0009493827819824219 seconds
DEBUG 01-14 20:42:33.110105.110105 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-14 20:42:33.110568.110568 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 4.0531158447265625e-05 seconds
DEBUG 01-14 20:42:33.110718.110718 cuda_h.py:10] start wait_experts
INFO 01-14 20:42:33.110257.110257 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 57702d03-5544-4212-868d-558f263f87db
DEBUG 01-14 20:42:33.112707.112707 mlpmodule.py:1533] pad cost 0.003622770309448242 s
DEBUG 01-14 20:42:33.112661.112661 mlpmodule.py:1539] create cpu tensor cost 4.267692565917969e-05 s
DEBUG 01-14 20:42:33.114435.114435 mlpmodule.py:1544] move to cpu cost 0.002283334732055664 s
DEBUG 01-14 20:42:33.125142.125142 mlpmodule.py:1558] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-14 20:42:33.125287.125287 mlpmodule.py:1559] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-14 20:42:33.125946.125946 mlpmodule.py:1564] group_w3 first element: -0.02490234375
WARNING 01-14 20:42:33.126560.126560 mlpmodule.py:1574] start einsum2
INFO 01-14 20:42:33.132210.132210 client.py:127] Model loaded
DEBUG 01-14 20:42:33.132476.132476 cuda_h.py:19] end wait_experts cost 0.021562576293945312 seconds
DEBUG 01-14 20:42:33.132949.132949 cuda_h.py:10] start gpu_experts
DEBUG 01-14 20:42:33.132329.132329 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-14 20:42:33.143846.143846 mlpmodule.py:1584] group einsum cost 0.028421878814697266 s
DEBUG 01-14 20:42:33.144043.144043 mlpmodule.py:1593] cpy2cputensor cost 0.0007681846618652344 s
DEBUG 01-14 20:42:33.144919.144919 cuda_h.py:10] start move_outputs
DEBUG 01-14 20:42:33.146619.146619 cuda_h.py:19] end move_outputs cost 0.002274036407470703 seconds
DEBUG 01-14 20:42:33.150907.150907 cuda_h.py:19] end wait_cetm_experts cost 0.017761707305908203 seconds
DEBUG 01-14 20:42:33.150095.150095 cuda_h.py:10] start gpu_group_einsum_mp_multi_list
DEBUG 01-14 20:42:33.150490.150490 cuda_h.py:10] start gpu_group_tensor
DEBUG 01-14 20:42:33.151448.151448 cuda_h.py:19] end gpu_group_tensor cost 0.0004360675811767578 seconds
DEBUG 01-14 20:42:33.151774.151774 cuda_h.py:10] start gpu_group_einsum
DEBUG 01-14 20:42:33.153746.153746 cuda_h.py:19] end gpu_group_einsum cost 0.0012280941009521484 seconds
DEBUG 01-14 20:42:33.153914.153914 cuda_h.py:10] start gpu_final_hidden_states_scatter
DEBUG 01-14 20:42:33.153621.153621 cuda_h.py:10] start all_expert_outputs_slices
DEBUG 01-14 20:42:33.154532.154532 cuda_h.py:19] end all_expert_outputs_slices cost 0.0006227493286132812 seconds
DEBUG 01-14 20:42:33.154164.154164 cuda_h.py:10] start concat_expert_out
DEBUG 01-14 20:42:33.154184.154184 cuda_h.py:19] end concat_expert_out cost 0.00014066696166992188 seconds
DEBUG 01-14 20:42:33.154633.154633 cuda_h.py:10] start index_scatter
DEBUG 01-14 20:42:33.154615.154615 cuda_h.py:19] end index_scatter cost 0.0001437664031982422 seconds
DEBUG 01-14 20:42:33.154167.154167 cuda_h.py:19] end gpu_final_hidden_states_scatter cost 0.0015175342559814453 seconds
DEBUG 01-14 20:42:33.155419.155419 cuda_h.py:19] end gpu_experts cost 0.022475242614746094 seconds
DEBUG 01-14 20:42:33.155435.155435 cuda_h.py:10] start all_expert_weight_slices
DEBUG 01-14 20:42:33.157103.157103 cuda_h.py:19] end all_expert_weight_slices cost 0.0022668838500976562 seconds
DEBUG 01-14 20:42:33.157299.157299 cuda_h.py:10] start cpuoutputsdeal
DEBUG 01-14 20:42:33.158240.158240 cuda_h.py:10] start index_scatter
DEBUG 01-14 20:42:33.158380.158380 cuda_h.py:19] end index_scatter cost 0.0001220703125 seconds
DEBUG 01-14 20:42:33.159754.159754 cuda_h.py:19] end cpuoutputsdeal cost 0.0012750625610351562 seconds
DEBUG 01-14 20:42:33.159906.159906 cuda_h.py:19] end layer_moe_generate_mp_l_17 cost 0.0847012996673584 seconds
DEBUG 01-14 20:42:33.159433.159433 cuda_h.py:19] end prefill_layer cost 0.09633851051330566 seconds
DEBUG 01-14 20:42:33.160577.160577 lmp.py:1551] -------------------------------- end prefill layer 16 --------------------------------
DEBUG 01-14 20:42:33.160494.160494 cuda_h.py:10] start prefill_layer
DEBUG 01-14 20:42:33.160602.160602 lmp.py:1494] -------------------------------- start prefill layer 17 --------------------------------
DEBUG 01-14 20:42:33.160659.160659 cuda_h.py:10] start start_load_qkvogn_s_weight_l_18
DEBUG 01-14 20:42:33.160133.160133 cuda_h.py:10] start start_load_qkvogn_s_weight_l_18
DEBUG 01-14 20:42:33.160648.160648 cuda_h.py:19] end start_load_qkvogn_s_weight_l_18 cost 6.127357482910156e-05 seconds
DEBUG 01-14 20:42:33.160851.160851 cuda_h.py:10] start sllm_worker_task
DEBUG 01-14 20:42:33.160681.160681 cuda_h.py:19] end start_load_qkvogn_s_weight_l_18 cost 0.00026988983154296875 seconds
DEBUG 01-14 20:42:33.160169.160169 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-14 20:42:33.160900.160900 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-14 20:42:33.161830.161830 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-14 20:42:33.165268.165268 cuda_h.py:19] end allocate_cuda_memory cost 0.00444793701171875 seconds
DEBUG 01-14 20:42:33.165032.165032 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-14 20:42:33.165325.165325 sllm_store_c.py:27] get device uuid map
DEBUG 01-14 20:42:33.165962.165962 sllm_store_c.py:29] call client load into gpu
DEBUG 01-14 20:42:33.165811.165811 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, d589cfd3-723a-41f7-94e0-89885e62e46f
DEBUG 01-14 20:42:33.165787.165787 client.py:106] call stub.LoadModelAsync
DEBUG 01-14 20:42:33.166549.166549 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-14 20:42:33.166014.166014 mlpmodule.py:1367]  experts func einsum cost 0.0828089714050293 s
DEBUG 01-14 20:42:33.166058.166058 cuda_h.py:10] start self_attn
INFO 01-14 20:42:33.167998.167998 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, d589cfd3-723a-41f7-94e0-89885e62e46f
DEBUG 01-14 20:42:33.167649.167649 cuda_h.py:19] end load_into_gpu_async cost 0.0017833709716796875 seconds
DEBUG 01-14 20:42:33.167398.167398 cuda_h.py:10] start restore_tensors2
DEBUG 01-14 20:42:33.167965.167965 cuda_h.py:19] end restore_tensors2 cost 7.534027099609375e-05 seconds
DEBUG 01-14 20:42:33.167529.167529 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.006650686264038086 seconds
INFO 01-14 20:42:33.167068.167068 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, d589cfd3-723a-41f7-94e0-89885e62e46f
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-14 20:42:33.171444.171444 cuda_h.py:19] end self_attn cost 0.004476785659790039 seconds
DEBUG 01-14 20:42:33.171454.171454 cuda_h.py:19] end iln_self_attn_paln cost 0.010835886001586914 seconds
DEBUG 01-14 20:42:33.172014.172014 cuda_h.py:10] start layer_moe_generate_mp_l_18
DEBUG 01-14 20:42:33.172870.172870 cuda_h.py:10] start gate
DEBUG 01-14 20:42:33.173281.173281 cuda_h.py:19] end gate cost 0.0009436607360839844 seconds
DEBUG 01-14 20:42:33.173443.173443 cuda_h.py:10] start experts_map_get
DEBUG 01-14 20:42:33.173746.173746 lmp.py:1615] 
DEBUG 01-14 20:42:33.173746.173746 lmp.py:1615] Expert Token Distribution & Device Allocation:
DEBUG 01-14 20:42:33.173774.173774 lmp.py:1616]   Total experts: 64
DEBUG 01-14 20:42:33.173359.173359 lmp.py:1617]   CPU experts: 32 (50%)
DEBUG 01-14 20:42:33.173744.173744 lmp.py:1618]   GPU experts: 32 (50%)
DEBUG 01-14 20:42:33.173884.173884 lmp.py:1619] 
DEBUG 01-14 20:42:33.173884.173884 lmp.py:1619]   Expert ID | Tokens | Device
DEBUG 01-14 20:42:33.173786.173786 lmp.py:1620]   -----------------------------------
DEBUG 01-14 20:42:33.174741.174741 lmp.py:1625]   Expert  4 |     14 | CPU
DEBUG 01-14 20:42:33.174119.174119 lmp.py:1625]   Expert 28 |     34 | CPU
DEBUG 01-14 20:42:33.174783.174783 lmp.py:1625]   Expert  7 |     49 | CPU
DEBUG 01-14 20:42:33.174731.174731 lmp.py:1625]   Expert 53 |     63 | CPU
DEBUG 01-14 20:42:33.174109.174109 lmp.py:1625]   Expert 52 |     71 | CPU
DEBUG 01-14 20:42:33.174773.174773 lmp.py:1625]   Expert 43 |     75 | CPU
DEBUG 01-14 20:42:33.174482.174482 lmp.py:1625]   Expert 49 |     83 | CPU
DEBUG 01-14 20:42:33.174430.174430 lmp.py:1625]   Expert 12 |     93 | CPU
DEBUG 01-14 20:42:33.174332.174332 lmp.py:1625]   Expert 15 |     97 | CPU
DEBUG 01-14 20:42:33.174141.174141 lmp.py:1625]   Expert 47 |     97 | CPU
DEBUG 01-14 20:42:33.174950.174950 lmp.py:1625]   Expert 60 |    102 | CPU
DEBUG 01-14 20:42:33.174568.174568 lmp.py:1625]   Expert 36 |    107 | CPU
DEBUG 01-14 20:42:33.174807.174807 lmp.py:1625]   Expert  2 |    109 | CPU
DEBUG 01-14 20:42:33.174755.174755 lmp.py:1625]   Expert 33 |    109 | CPU
DEBUG 01-14 20:42:33.174465.174465 lmp.py:1625]   Expert  6 |    117 | CPU
DEBUG 01-14 20:42:33.174698.174698 lmp.py:1625]   Expert 50 |    117 | CPU
DEBUG 01-14 20:42:33.174361.174361 lmp.py:1625]   Expert 25 |    121 | CPU
DEBUG 01-14 20:42:33.174309.174309 lmp.py:1625]   Expert 30 |    123 | CPU
DEBUG 01-14 20:42:33.174780.174780 lmp.py:1625]   Expert 39 |    126 | CPU
DEBUG 01-14 20:42:33.174013.174013 lmp.py:1625]   Expert 24 |    128 | CPU
DEBUG 01-14 20:42:33.174677.174677 lmp.py:1625]   Expert 59 |    129 | CPU
DEBUG 01-14 20:42:33.174578.174578 lmp.py:1625]   Expert  8 |    131 | CPU
DEBUG 01-14 20:42:33.174811.174811 lmp.py:1625]   Expert 27 |    134 | CPU
DEBUG 01-14 20:42:33.174428.174428 lmp.py:1625]   Expert  3 |    143 | CPU
DEBUG 01-14 20:42:33.174164.174164 lmp.py:1625]   Expert 10 |    146 | CPU
DEBUG 01-14 20:42:33.174376.174376 lmp.py:1625]   Expert 37 |    150 | CPU
DEBUG 01-14 20:42:33.174827.174827 lmp.py:1625]   Expert 14 |    153 | CPU
DEBUG 01-14 20:42:33.174755.174755 lmp.py:1625]   Expert 32 |    153 | CPU
DEBUG 01-14 20:42:33.174967.174967 lmp.py:1625]   Expert 11 |    154 | CPU
DEBUG 01-14 20:42:33.174703.174703 lmp.py:1625]   Expert 38 |    154 | CPU
DEBUG 01-14 20:42:33.174200.174200 lmp.py:1625]   Expert 40 |    156 | CPU
DEBUG 01-14 20:42:33.174413.174413 lmp.py:1625]   Expert 58 |    158 | CPU
DEBUG 01-14 20:42:33.174625.174625 lmp.py:1625]   Expert 61 |    160 | GPU
DEBUG 01-14 20:42:33.174361.174361 lmp.py:1625]   Expert 19 |    163 | GPU
DEBUG 01-14 20:42:33.174573.174573 lmp.py:1625]   Expert 41 |    163 | GPU
DEBUG 01-14 20:42:33.174547.174547 lmp.py:1625]   Expert 31 |    164 | GPU
DEBUG 01-14 20:42:33.174237.174237 lmp.py:1625]   Expert 54 |    164 | GPU
DEBUG 01-14 20:42:33.175687.175687 lmp.py:1625]   Expert 46 |    171 | GPU
DEBUG 01-14 20:42:33.175900.175900 lmp.py:1625]   Expert 22 |    174 | GPU
DEBUG 01-14 20:42:33.175874.175874 lmp.py:1625]   Expert 18 |    175 | GPU
DEBUG 01-14 20:42:33.175848.175848 lmp.py:1625]   Expert 42 |    176 | GPU
DEBUG 01-14 20:42:33.175584.175584 lmp.py:1625]   Expert 57 |    176 | GPU
DEBUG 01-14 20:42:33.175558.175558 lmp.py:1625]   Expert 26 |    187 | GPU
DEBUG 01-14 20:42:33.175770.175770 lmp.py:1625]   Expert 34 |    188 | GPU
DEBUG 01-14 20:42:33.175267.175267 lmp.py:1625]   Expert 56 |    189 | GPU
DEBUG 01-14 20:42:33.175241.175241 lmp.py:1625]   Expert 44 |    193 | GPU
DEBUG 01-14 20:42:33.175169.175169 lmp.py:1625]   Expert  0 |    210 | GPU
DEBUG 01-14 20:42:33.175858.175858 lmp.py:1625]   Expert  1 |    211 | GPU
DEBUG 01-14 20:42:33.175071.175071 lmp.py:1625]   Expert 20 |    223 | GPU
DEBUG 01-14 20:42:33.175045.175045 lmp.py:1625]   Expert 51 |    224 | GPU
DEBUG 01-14 20:42:33.175496.175496 lmp.py:1625]   Expert 48 |    234 | GPU
DEBUG 01-14 20:42:33.175947.175947 lmp.py:1625]   Expert 55 |    240 | GPU
DEBUG 01-14 20:42:33.175636.175636 lmp.py:1625]   Expert 29 |    241 | GPU
DEBUG 01-14 20:42:33.175325.175325 lmp.py:1625]   Expert 35 |    244 | GPU
DEBUG 01-14 20:42:33.175538.175538 lmp.py:1625]   Expert 45 |    244 | GPU
DEBUG 01-14 20:42:33.175750.175750 lmp.py:1625]   Expert 21 |    246 | GPU
DEBUG 01-14 20:42:33.175486.175486 lmp.py:1625]   Expert 16 |    259 | GPU
DEBUG 01-14 20:42:33.175221.175221 lmp.py:1625]   Expert  5 |    293 | GPU
DEBUG 01-14 20:42:33.175195.175195 lmp.py:1625]   Expert 13 |    373 | GPU
DEBUG 01-14 20:42:33.175931.175931 lmp.py:1625]   Expert 23 |    383 | GPU
DEBUG 01-14 20:42:33.175905.175905 lmp.py:1625]   Expert 17 |    416 | GPU
DEBUG 01-14 20:42:33.175356.175356 lmp.py:1625]   Expert 63 |    477 | GPU
DEBUG 01-14 20:42:33.175807.175807 lmp.py:1625]   Expert  9 |    504 | GPU
DEBUG 01-14 20:42:33.175019.175019 lmp.py:1625]   Expert 62 |   1227 | GPU
DEBUG 01-14 20:42:33.175709.175709 lmp.py:1626] 
DEBUG 01-14 20:42:33.175709.175709 lmp.py:1626]   CPU total tokens: 3596 (29.3%)
DEBUG 01-14 20:42:33.175636.175636 lmp.py:1627]   GPU total tokens: 8692 (70.7%)
DEBUG 01-14 20:42:33.175379.175379 cuda_h.py:19] end experts_map_get cost 0.0021872520446777344 seconds
DEBUG 01-14 20:42:33.175513.175513 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-14 20:42:33.175310.175310 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-14 20:42:33.175785.175785 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-14 20:42:33.176310.176310 cuda_h.py:19] end allocate_cuda_memory cost 0.00021314620971679688 seconds
DEBUG 01-14 20:42:33.176246.176246 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-14 20:42:33.176571.176571 sllm_store_c.py:27] get device uuid map
DEBUG 01-14 20:42:33.176426.176426 sllm_store_c.py:29] call client load into gpu
DEBUG 01-14 20:42:33.176076.176076 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, ec487574-b884-40c9-a698-7c9863d9090f
DEBUG 01-14 20:42:33.176526.176526 client.py:106] call stub.LoadModelAsync
INFO 01-14 20:42:33.176274.176274 client.py:127] Model loaded
DEBUG 01-14 20:42:33.176594.176594 cuda_h.py:10] start restore2model
DEBUG 01-14 20:42:33.177927.177927 cuda_h.py:19] end restore2model cost 0.00041556358337402344 seconds
DEBUG 01-14 20:42:33.177326.177326 cuda_h.py:19] end sllm_worker_task cost 0.016178131103515625 seconds
INFO 01-14 20:42:33.177104.177104 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, ec487574-b884-40c9-a698-7c9863d9090f
DEBUG 01-14 20:42:33.177755.177755 cuda_h.py:19] end load_into_gpu_async cost 0.001537322998046875 seconds
DEBUG 01-14 20:42:33.177981.177981 cuda_h.py:10] start restore_tensors2
DEBUG 01-14 20:42:33.178729.178729 cuda_h.py:19] end restore_tensors2 cost 0.00035071372985839844 seconds
DEBUG 01-14 20:42:33.178181.178181 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0024428367614746094 seconds
DEBUG 01-14 20:42:33.178944.178944 cuda_h.py:10] start restore2model
DEBUG 01-14 20:42:33.180872.180872 cuda_h.py:19] end restore2model cost 0.0025854110717773438 seconds
DEBUG 01-14 20:42:33.180808.180808 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.005208730697631836 seconds
DEBUG 01-14 20:42:33.180226.180226 cuda_h.py:10] start gpu_sexperts
DEBUG 01-14 20:42:33.181925.181925 cuda_h.py:19] end gpu_sexperts cost 0.0002734661102294922 seconds
DEBUG 01-14 20:42:33.181794.181794 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-14 20:42:33.181166.181166 lmp.py:1683] 
DEBUG 01-14 20:42:33.181166.181166 lmp.py:1683]   Computing 32 experts on CPU...
DEBUG 01-14 20:42:33.181578.181578 cuda_h.py:19] end cpu_experts_submit cost 5.8650970458984375e-05 seconds
DEBUG 01-14 20:42:33.181328.181328 cuda_h.py:10] start experts_func_mgpu_group_pad
DEBUG 01-14 20:42:33.199722.199722 mlpmodule.py:1460] group tensors cost 0.01808619499206543 s
DEBUG 01-14 20:42:33.200481.200481 cuda_h.py:10] start move_flat_hidden2cpu
DEBUG 01-14 20:42:33.203520.203520 cuda_h.py:19] end experts_func_mgpu_group_pad cost 0.022316932678222656 seconds
DEBUG 01-14 20:42:33.205060.205060 cuda_h.py:10] start gpu_group_list
DEBUG 01-14 20:42:33.205470.205470 cuda_h.py:19] end gpu_group_list cost 0.0004513263702392578 seconds
DEBUG 01-14 20:42:33.205850.205850 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-14 20:42:33.206694.206694 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.3603439331054688e-05 seconds
DEBUG 01-14 20:42:33.206848.206848 cuda_h.py:10] start wait_experts
INFO 01-14 20:42:33.206140.206140 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, ec487574-b884-40c9-a698-7c9863d9090f
DEBUG 01-14 20:42:33.207854.207854 cuda_h.py:19] end move_flat_hidden2cpu cost 0.006909608840942383 seconds
DEBUG 01-14 20:42:33.209902.209902 mlpmodule.py:1533] pad cost 0.001542806625366211 s
DEBUG 01-14 20:42:33.209688.209688 mlpmodule.py:1539] create cpu tensor cost 5.412101745605469e-05 s
DEBUG 01-14 20:42:33.211374.211374 mlpmodule.py:1544] move to cpu cost 0.0018715858459472656 s
DEBUG 01-14 20:42:33.221477.221477 mlpmodule.py:1558] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-14 20:42:33.221171.221171 mlpmodule.py:1559] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-14 20:42:33.221207.221207 mlpmodule.py:1564] group_w3 first element: 0.00457763671875
WARNING 01-14 20:42:33.221384.221384 mlpmodule.py:1574] start einsum2
INFO 01-14 20:42:33.231826.231826 client.py:127] Model loaded
DEBUG 01-14 20:42:33.232544.232544 cuda_h.py:19] end wait_experts cost 0.026046037673950195 seconds
DEBUG 01-14 20:42:33.232653.232653 cuda_h.py:10] start gpu_experts
DEBUG 01-14 20:42:33.232015.232015 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-14 20:42:33.236354.236354 mlpmodule.py:1584] group einsum cost 0.02522444725036621 s
DEBUG 01-14 20:42:33.237795.237795 mlpmodule.py:1593] cpy2cputensor cost 0.0007309913635253906 s
DEBUG 01-14 20:42:33.237863.237863 cuda_h.py:10] start move_outputs
DEBUG 01-14 20:42:33.239549.239549 cuda_h.py:19] end move_outputs cost 0.0018427371978759766 seconds
DEBUG 01-14 20:42:33.243781.243781 cuda_h.py:19] end wait_cetm_experts cost 0.011078596115112305 seconds
DEBUG 01-14 20:42:33.243571.243571 cuda_h.py:10] start gpu_group_einsum_mp_multi_list
DEBUG 01-14 20:42:33.244051.244051 cuda_h.py:10] start gpu_group_tensor
DEBUG 01-14 20:42:33.244462.244462 cuda_h.py:19] end gpu_group_tensor cost 0.00048351287841796875 seconds
DEBUG 01-14 20:42:33.244238.244238 cuda_h.py:10] start gpu_group_einsum
DEBUG 01-14 20:42:33.259076.259076 mlpmodule.py:1367]  experts func einsum cost 0.07716608047485352 s
DEBUG 01-14 20:42:33.259103.259103 cuda_h.py:19] end gpu_group_einsum cost 0.014792203903198242 seconds
DEBUG 01-14 20:42:33.260206.260206 cuda_h.py:10] start gpu_final_hidden_states_scatter
DEBUG 01-14 20:42:33.260489.260489 cuda_h.py:10] start all_expert_outputs_slices
DEBUG 01-14 20:42:33.261885.261885 cuda_h.py:19] end all_expert_outputs_slices cost 0.0006556510925292969 seconds
DEBUG 01-14 20:42:33.261914.261914 cuda_h.py:10] start concat_expert_out
DEBUG 01-14 20:42:33.261074.261074 cuda_h.py:19] end concat_expert_out cost 0.00014519691467285156 seconds
DEBUG 01-14 20:42:33.261477.261477 cuda_h.py:10] start index_scatter
DEBUG 01-14 20:42:33.261312.261312 cuda_h.py:19] end index_scatter cost 0.0001423358917236328 seconds
DEBUG 01-14 20:42:33.261819.261819 cuda_h.py:19] end gpu_final_hidden_states_scatter cost 0.0015673637390136719 seconds
DEBUG 01-14 20:42:33.261772.261772 cuda_h.py:19] end gpu_experts cost 0.029541730880737305 seconds
DEBUG 01-14 20:42:33.262012.262012 cuda_h.py:10] start all_expert_weight_slices
DEBUG 01-14 20:42:33.264997.264997 cuda_h.py:19] end all_expert_weight_slices cost 0.002223968505859375 seconds
DEBUG 01-14 20:42:33.264173.264173 cuda_h.py:10] start cpuoutputsdeal
DEBUG 01-14 20:42:33.265221.265221 cuda_h.py:10] start index_scatter
DEBUG 01-14 20:42:33.265315.265315 cuda_h.py:19] end index_scatter cost 0.00012230873107910156 seconds
DEBUG 01-14 20:42:33.265835.265835 cuda_h.py:19] end cpuoutputsdeal cost 0.001287221908569336 seconds
DEBUG 01-14 20:42:33.266609.266609 cuda_h.py:19] end layer_moe_generate_mp_l_18 cost 0.09386396408081055 seconds
DEBUG 01-14 20:42:33.266666.266666 cuda_h.py:19] end prefill_layer cost 0.10633277893066406 seconds
DEBUG 01-14 20:42:33.266066.266066 lmp.py:1551] -------------------------------- end prefill layer 17 --------------------------------
DEBUG 01-14 20:42:33.266796.266796 cuda_h.py:10] start prefill_layer
DEBUG 01-14 20:42:33.266764.266764 lmp.py:1494] -------------------------------- start prefill layer 18 --------------------------------
DEBUG 01-14 20:42:33.266872.266872 cuda_h.py:10] start start_load_qkvogn_s_weight_l_19
DEBUG 01-14 20:42:33.266271.266271 cuda_h.py:10] start start_load_qkvogn_s_weight_l_19
DEBUG 01-14 20:42:33.266546.266546 cuda_h.py:19] end start_load_qkvogn_s_weight_l_19 cost 4.482269287109375e-05 seconds
DEBUG 01-14 20:42:33.266898.266898 cuda_h.py:19] end start_load_qkvogn_s_weight_l_19 cost 0.00010466575622558594 seconds
DEBUG 01-14 20:42:33.266714.266714 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-14 20:42:33.267731.267731 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-14 20:42:33.267120.267120 cuda_h.py:10] start sllm_worker_task
DEBUG 01-14 20:42:33.267095.267095 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-14 20:42:33.267901.267901 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-14 20:42:33.268110.268110 cuda_h.py:19] end allocate_cuda_memory cost 0.0003745555877685547 seconds
DEBUG 01-14 20:42:33.268044.268044 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-14 20:42:33.268843.268843 sllm_store_c.py:27] get device uuid map
DEBUG 01-14 20:42:33.268429.268429 sllm_store_c.py:29] call client load into gpu
DEBUG 01-14 20:42:33.268008.268008 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, cbe86254-59f9-459c-87fd-054220b565cc
DEBUG 01-14 20:42:33.268657.268657 client.py:106] call stub.LoadModelAsync
DEBUG 01-14 20:42:33.269092.269092 cuda_h.py:10] start self_attn
INFO 01-14 20:42:33.270193.270193 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, cbe86254-59f9-459c-87fd-054220b565cc
DEBUG 01-14 20:42:33.270330.270330 cuda_h.py:19] end load_into_gpu_async cost 0.002500295639038086 seconds
DEBUG 01-14 20:42:33.271029.271029 cuda_h.py:10] start restore_tensors2
DEBUG 01-14 20:42:33.271580.271580 cuda_h.py:19] end restore_tensors2 cost 0.0001480579376220703 seconds
DEBUG 01-14 20:42:33.271225.271225 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.003789663314819336 seconds
INFO 01-14 20:42:33.271654.271654 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, cbe86254-59f9-459c-87fd-054220b565cc
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-14 20:42:33.274144.274144 cuda_h.py:19] end self_attn cost 0.00502467155456543 seconds
DEBUG 01-14 20:42:33.274677.274677 cuda_h.py:19] end iln_self_attn_paln cost 0.00774836540222168 seconds
DEBUG 01-14 20:42:33.274529.274529 cuda_h.py:10] start layer_moe_generate_mp_l_19
DEBUG 01-14 20:42:33.274047.274047 cuda_h.py:10] start gate
DEBUG 01-14 20:42:33.275863.275863 cuda_h.py:19] end gate cost 0.0009593963623046875 seconds
DEBUG 01-14 20:42:33.276316.276316 cuda_h.py:10] start experts_map_get
DEBUG 01-14 20:42:33.276711.276711 lmp.py:1615] 
DEBUG 01-14 20:42:33.276711.276711 lmp.py:1615] Expert Token Distribution & Device Allocation:
DEBUG 01-14 20:42:33.276951.276951 lmp.py:1616]   Total experts: 64
DEBUG 01-14 20:42:33.276939.276939 lmp.py:1617]   CPU experts: 32 (50%)
DEBUG 01-14 20:42:33.276827.276827 lmp.py:1618]   GPU experts: 32 (50%)
DEBUG 01-14 20:42:33.276092.276092 lmp.py:1619] 
DEBUG 01-14 20:42:33.276092.276092 lmp.py:1619]   Expert ID | Tokens | Device
DEBUG 01-14 20:42:33.276312.276312 lmp.py:1620]   -----------------------------------
DEBUG 01-14 20:42:33.276783.276783 lmp.py:1625]   Expert 32 |     49 | CPU
DEBUG 01-14 20:42:33.276572.276572 lmp.py:1625]   Expert  5 |     53 | CPU
DEBUG 01-14 20:42:33.276215.276215 lmp.py:1625]   Expert 30 |     55 | CPU
DEBUG 01-14 20:42:33.276858.276858 lmp.py:1625]   Expert 46 |     60 | CPU
DEBUG 01-14 20:42:33.276262.276262 lmp.py:1625]   Expert 12 |     91 | CPU
DEBUG 01-14 20:42:33.276905.276905 lmp.py:1625]   Expert 60 |    100 | CPU
DEBUG 01-14 20:42:33.276833.276833 lmp.py:1625]   Expert  8 |    104 | CPU
DEBUG 01-14 20:42:33.276237.276237 lmp.py:1625]   Expert 27 |    105 | CPU
DEBUG 01-14 20:42:33.276980.276980 lmp.py:1625]   Expert 40 |    106 | CPU
DEBUG 01-14 20:42:33.276815.276815 lmp.py:1625]   Expert 28 |    110 | CPU
DEBUG 01-14 20:42:33.276219.276219 lmp.py:1625]   Expert 41 |    113 | CPU
DEBUG 01-14 20:42:33.276624.276624 lmp.py:1625]   Expert  3 |    115 | CPU
DEBUG 01-14 20:42:33.276075.276075 lmp.py:1625]   Expert 17 |    115 | CPU
DEBUG 01-14 20:42:33.276764.276764 lmp.py:1625]   Expert 21 |    119 | CPU
DEBUG 01-14 20:42:33.276692.276692 lmp.py:1625]   Expert 29 |    120 | CPU
DEBUG 01-14 20:42:33.276381.276381 lmp.py:1625]   Expert 25 |    128 | CPU
DEBUG 01-14 20:42:33.276070.276070 lmp.py:1625]   Expert 35 |    129 | CPU
DEBUG 01-14 20:42:33.276998.276998 lmp.py:1625]   Expert 54 |    130 | CPU
DEBUG 01-14 20:42:33.276449.276449 lmp.py:1625]   Expert 58 |    132 | CPU
DEBUG 01-14 20:42:33.276377.276377 lmp.py:1625]   Expert  6 |    133 | CPU
DEBUG 01-14 20:42:33.276642.276642 lmp.py:1625]   Expert 19 |    140 | CPU
DEBUG 01-14 20:42:33.276239.276239 lmp.py:1625]   Expert  0 |    144 | CPU
DEBUG 01-14 20:42:33.276644.276644 lmp.py:1625]   Expert 37 |    146 | CPU
DEBUG 01-14 20:42:33.276763.276763 lmp.py:1625]   Expert 52 |    146 | CPU
DEBUG 01-14 20:42:33.276930.276930 lmp.py:1625]   Expert  9 |    153 | CPU
DEBUG 01-14 20:42:33.277380.277380 lmp.py:1625]   Expert 63 |    157 | CPU
DEBUG 01-14 20:42:33.277831.277831 lmp.py:1625]   Expert 53 |    158 | CPU
DEBUG 01-14 20:42:33.277521.277521 lmp.py:1625]   Expert 48 |    160 | CPU
DEBUG 01-14 20:42:33.277971.277971 lmp.py:1625]   Expert 36 |    165 | CPU
DEBUG 01-14 20:42:33.277422.277422 lmp.py:1625]   Expert 56 |    168 | CPU
DEBUG 01-14 20:42:33.277112.277112 lmp.py:1625]   Expert 59 |    174 | CPU
DEBUG 01-14 20:42:33.277039.277039 lmp.py:1625]   Expert  1 |    175 | CPU
DEBUG 01-14 20:42:33.277490.277490 lmp.py:1625]   Expert 47 |    187 | GPU
DEBUG 01-14 20:42:33.277656.277656 lmp.py:1625]   Expert 20 |    197 | GPU
DEBUG 01-14 20:42:33.277346.277346 lmp.py:1625]   Expert 39 |    201 | GPU
DEBUG 01-14 20:42:33.277466.277466 lmp.py:1625]   Expert 42 |    206 | GPU
DEBUG 01-14 20:42:33.277347.277347 lmp.py:1625]   Expert 61 |    211 | GPU
DEBUG 01-14 20:42:33.277275.277275 lmp.py:1625]   Expert 34 |    215 | GPU
DEBUG 01-14 20:42:33.277964.277964 lmp.py:1625]   Expert  7 |    219 | GPU
DEBUG 01-14 20:42:33.277415.277415 lmp.py:1625]   Expert 11 |    221 | GPU
DEBUG 01-14 20:42:33.277343.277343 lmp.py:1625]   Expert 13 |    223 | GPU
DEBUG 01-14 20:42:33.277032.277032 lmp.py:1625]   Expert 16 |    223 | GPU
DEBUG 01-14 20:42:33.277721.277721 lmp.py:1625]   Expert 18 |    223 | GPU
DEBUG 01-14 20:42:33.277410.277410 lmp.py:1625]   Expert 57 |    223 | GPU
DEBUG 01-14 20:42:33.277861.277861 lmp.py:1625]   Expert 55 |    232 | GPU
DEBUG 01-14 20:42:33.277789.277789 lmp.py:1625]   Expert 49 |    245 | GPU
DEBUG 01-14 20:42:33.277717.277717 lmp.py:1625]   Expert  4 |    248 | GPU
DEBUG 01-14 20:42:33.277644.277644 lmp.py:1625]   Expert 15 |    248 | GPU
DEBUG 01-14 20:42:33.277572.277572 lmp.py:1625]   Expert 50 |    248 | GPU
DEBUG 01-14 20:42:33.277454.277454 lmp.py:1625]   Expert  2 |    250 | GPU
DEBUG 01-14 20:42:33.277335.277335 lmp.py:1625]   Expert 51 |    253 | GPU
DEBUG 01-14 20:42:33.277455.277455 lmp.py:1625]   Expert 43 |    255 | GPU
DEBUG 01-14 20:42:33.277621.277621 lmp.py:1625]   Expert 22 |    257 | GPU
DEBUG 01-14 20:42:33.277549.277549 lmp.py:1625]   Expert 45 |    258 | GPU
DEBUG 01-14 20:42:33.277238.277238 lmp.py:1625]   Expert 33 |    260 | GPU
DEBUG 01-14 20:42:33.277404.277404 lmp.py:1625]   Expert 31 |    264 | GPU
DEBUG 01-14 20:42:33.277332.277332 lmp.py:1625]   Expert 38 |    279 | GPU
DEBUG 01-14 20:42:33.277021.277021 lmp.py:1625]   Expert 44 |    283 | GPU
DEBUG 01-14 20:42:33.277949.277949 lmp.py:1625]   Expert 26 |    290 | GPU
DEBUG 01-14 20:42:33.277638.277638 lmp.py:1625]   Expert 23 |    298 | GPU
DEBUG 01-14 20:42:33.277566.277566 lmp.py:1625]   Expert 14 |    306 | GPU
DEBUG 01-14 20:42:33.277209.277209 lmp.py:1625]   Expert 24 |    307 | GPU
DEBUG 01-14 20:42:33.277805.277805 lmp.py:1625]   Expert 10 |    309 | GPU
DEBUG 01-14 20:42:33.277402.277402 lmp.py:1625]   Expert 62 |    696 | GPU
DEBUG 01-14 20:42:33.277383.277383 lmp.py:1626] 
DEBUG 01-14 20:42:33.277383.277383 lmp.py:1626]   CPU total tokens: 3953 (32.2%)
DEBUG 01-14 20:42:33.277410.277410 lmp.py:1627]   GPU total tokens: 8335 (67.8%)
DEBUG 01-14 20:42:33.277729.277729 cuda_h.py:19] end experts_map_get cost 0.0016093254089355469 seconds
DEBUG 01-14 20:42:33.277215.277215 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-14 20:42:33.277588.277588 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-14 20:42:33.278070.278070 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-14 20:42:33.278447.278447 cuda_h.py:19] end allocate_cuda_memory cost 0.0003497600555419922 seconds
DEBUG 01-14 20:42:33.278005.278005 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-14 20:42:33.278999.278999 sllm_store_c.py:27] get device uuid map
DEBUG 01-14 20:42:33.278285.278285 sllm_store_c.py:29] call client load into gpu
DEBUG 01-14 20:42:33.278081.278081 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, dbeac953-d986-4400-bdbd-e69f84acc7bf
DEBUG 01-14 20:42:33.278160.278160 client.py:106] call stub.LoadModelAsync
INFO 01-14 20:42:33.279453.279453 client.py:127] Model loaded
DEBUG 01-14 20:42:33.279947.279947 cuda_h.py:10] start restore2model
DEBUG 01-14 20:42:33.280889.280889 cuda_h.py:19] end restore2model cost 0.0009548664093017578 seconds
DEBUG 01-14 20:42:33.280443.280443 cuda_h.py:19] end sllm_worker_task cost 0.012980461120605469 seconds
INFO 01-14 20:42:33.280407.280407 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, dbeac953-d986-4400-bdbd-e69f84acc7bf
DEBUG 01-14 20:42:33.280484.280484 cuda_h.py:19] end load_into_gpu_async cost 0.002214193344116211 seconds
DEBUG 01-14 20:42:33.280578.280578 cuda_h.py:10] start restore_tensors2
DEBUG 01-14 20:42:33.281643.281643 cuda_h.py:19] end restore_tensors2 cost 0.0003345012664794922 seconds
DEBUG 01-14 20:42:33.281572.281572 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.003263235092163086 seconds
DEBUG 01-14 20:42:33.281481.281481 cuda_h.py:10] start restore2model
DEBUG 01-14 20:42:33.283823.283823 cuda_h.py:19] end restore2model cost 0.002680063247680664 seconds
DEBUG 01-14 20:42:33.283706.283706 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.0061244964599609375 seconds
DEBUG 01-14 20:42:33.283501.283501 cuda_h.py:10] start gpu_sexperts
DEBUG 01-14 20:42:33.284677.284677 cuda_h.py:19] end gpu_sexperts cost 0.00027370452880859375 seconds
DEBUG 01-14 20:42:33.284645.284645 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-14 20:42:33.284733.284733 lmp.py:1683] 
DEBUG 01-14 20:42:33.284733.284733 lmp.py:1683]   Computing 32 experts on CPU...
DEBUG 01-14 20:42:33.284112.284112 cuda_h.py:19] end cpu_experts_submit cost 6.818771362304688e-05 seconds
DEBUG 01-14 20:42:33.284054.284054 cuda_h.py:10] start experts_func_mgpu_group_pad
DEBUG 01-14 20:42:33.296759.296759 mlpmodule.py:1460] group tensors cost 0.011716604232788086 s
DEBUG 01-14 20:42:33.297980.297980 cuda_h.py:10] start move_flat_hidden2cpu
DEBUG 01-14 20:42:33.302712.302712 cuda_h.py:19] end experts_func_mgpu_group_pad cost 0.01821446418762207 seconds
DEBUG 01-14 20:42:33.304129.304129 cuda_h.py:19] end move_flat_hidden2cpu cost 0.00692296028137207 seconds
DEBUG 01-14 20:42:33.306560.306560 cuda_h.py:10] start gpu_group_list
DEBUG 01-14 20:42:33.306531.306531 cuda_h.py:19] end gpu_group_list cost 0.0005388259887695312 seconds
DEBUG 01-14 20:42:33.307665.307665 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-14 20:42:33.307178.307178 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.4557113647460938e-05 seconds
DEBUG 01-14 20:42:33.307100.307100 cuda_h.py:10] start wait_experts
INFO 01-14 20:42:33.307446.307446 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, dbeac953-d986-4400-bdbd-e69f84acc7bf
DEBUG 01-14 20:42:33.308498.308498 mlpmodule.py:1533] pad cost 0.003355741500854492 s
DEBUG 01-14 20:42:33.308860.308860 mlpmodule.py:1539] create cpu tensor cost 4.482269287109375e-05 s
DEBUG 01-14 20:42:33.310176.310176 mlpmodule.py:1544] move to cpu cost 0.0020847320556640625 s
DEBUG 01-14 20:42:33.320968.320968 mlpmodule.py:1558] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-14 20:42:33.320093.320093 mlpmodule.py:1559] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-14 20:42:33.320560.320560 mlpmodule.py:1564] group_w3 first element: 0.0024871826171875
WARNING 01-14 20:42:33.320306.320306 mlpmodule.py:1574] start einsum2
INFO 01-14 20:42:33.336609.336609 client.py:127] Model loaded
DEBUG 01-14 20:42:33.336558.336558 cuda_h.py:19] end wait_experts cost 0.029230356216430664 seconds
DEBUG 01-14 20:42:33.336488.336488 cuda_h.py:10] start gpu_experts
DEBUG 01-14 20:42:33.336472.336472 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-14 20:42:33.337337.337337 mlpmodule.py:1584] group einsum cost 0.026845216751098633 s
DEBUG 01-14 20:42:33.338030.338030 mlpmodule.py:1593] cpy2cputensor cost 0.0007455348968505859 s
DEBUG 01-14 20:42:33.338131.338131 cuda_h.py:10] start move_outputs
DEBUG 01-14 20:42:33.340028.340028 cuda_h.py:19] end move_outputs cost 0.002032756805419922 seconds
DEBUG 01-14 20:42:33.344439.344439 cuda_h.py:19] end wait_cetm_experts cost 0.007603645324707031 seconds
DEBUG 01-14 20:42:33.344758.344758 cuda_h.py:10] start gpu_group_einsum_mp_multi_list
DEBUG 01-14 20:42:33.344901.344901 cuda_h.py:10] start gpu_group_tensor
DEBUG 01-14 20:42:33.345899.345899 cuda_h.py:19] end gpu_group_tensor cost 0.0004334449768066406 seconds
DEBUG 01-14 20:42:33.345847.345847 cuda_h.py:10] start gpu_group_einsum
DEBUG 01-14 20:42:33.347661.347661 cuda_h.py:19] end gpu_group_einsum cost 0.0014269351959228516 seconds
DEBUG 01-14 20:42:33.347756.347756 cuda_h.py:10] start gpu_final_hidden_states_scatter
DEBUG 01-14 20:42:33.347509.347509 cuda_h.py:10] start all_expert_outputs_slices
DEBUG 01-14 20:42:33.348010.348010 cuda_h.py:19] end all_expert_outputs_slices cost 0.0006313323974609375 seconds
DEBUG 01-14 20:42:33.348649.348649 cuda_h.py:10] start concat_expert_out
DEBUG 01-14 20:42:33.348175.348175 cuda_h.py:19] end concat_expert_out cost 0.0002028942108154297 seconds
DEBUG 01-14 20:42:33.348359.348359 cuda_h.py:10] start index_scatter
DEBUG 01-14 20:42:33.349646.349646 cuda_h.py:19] end index_scatter cost 0.00015306472778320312 seconds
DEBUG 01-14 20:42:33.349821.349821 cuda_h.py:19] end gpu_final_hidden_states_scatter cost 0.0016241073608398438 seconds
DEBUG 01-14 20:42:33.349721.349721 cuda_h.py:19] end gpu_experts cost 0.012594938278198242 seconds
DEBUG 01-14 20:42:33.349677.349677 cuda_h.py:10] start all_expert_weight_slices
DEBUG 01-14 20:42:33.351235.351235 cuda_h.py:19] end all_expert_weight_slices cost 0.0025293827056884766 seconds
DEBUG 01-14 20:42:33.352605.352605 cuda_h.py:10] start cpuoutputsdeal
DEBUG 01-14 20:42:33.353504.353504 cuda_h.py:10] start index_scatter
DEBUG 01-14 20:42:33.353726.353726 cuda_h.py:19] end index_scatter cost 0.00015616416931152344 seconds
DEBUG 01-14 20:42:33.353160.353160 cuda_h.py:19] end cpuoutputsdeal cost 0.001462697982788086 seconds
DEBUG 01-14 20:42:33.353511.353511 cuda_h.py:19] end layer_moe_generate_mp_l_19 cost 0.07892036437988281 seconds
DEBUG 01-14 20:42:33.354582.354582 cuda_h.py:19] end prefill_layer cost 0.08787059783935547 seconds
DEBUG 01-14 20:42:33.354501.354501 lmp.py:1551] -------------------------------- end prefill layer 18 --------------------------------
DEBUG 01-14 20:42:33.354338.354338 cuda_h.py:10] start prefill_layer
DEBUG 01-14 20:42:33.354838.354838 lmp.py:1494] -------------------------------- start prefill layer 19 --------------------------------
DEBUG 01-14 20:42:33.355715.355715 cuda_h.py:10] start start_load_qkvogn_s_weight_l_20
DEBUG 01-14 20:42:33.355658.355658 cuda_h.py:10] start start_load_qkvogn_s_weight_l_20
DEBUG 01-14 20:42:33.355591.355591 cuda_h.py:19] end start_load_qkvogn_s_weight_l_20 cost 6.818771362304688e-05 seconds
DEBUG 01-14 20:42:33.355258.355258 cuda_h.py:10] start sllm_worker_task
DEBUG 01-14 20:42:33.355560.355560 cuda_h.py:19] end start_load_qkvogn_s_weight_l_20 cost 0.0003230571746826172 seconds
DEBUG 01-14 20:42:33.355968.355968 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-14 20:42:33.355124.355124 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-14 20:42:33.355776.355776 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-14 20:42:33.358579.358579 cuda_h.py:19] end allocate_cuda_memory cost 0.0020647048950195312 seconds
DEBUG 01-14 20:42:33.358674.358674 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-14 20:42:33.358721.358721 sllm_store_c.py:27] get device uuid map
DEBUG 01-14 20:42:33.358882.358882 sllm_store_c.py:29] call client load into gpu
DEBUG 01-14 20:42:33.358731.358731 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, a4783a7d-bbf8-430b-88f7-42d6bf342c0b
DEBUG 01-14 20:42:33.358892.358892 client.py:106] call stub.LoadModelAsync
DEBUG 01-14 20:42:33.358991.358991 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-14 20:42:33.358560.358560 mlpmodule.py:1367]  experts func einsum cost 0.0736691951751709 s
DEBUG 01-14 20:42:33.359844.359844 cuda_h.py:10] start self_attn
INFO 01-14 20:42:33.359912.359912 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, a4783a7d-bbf8-430b-88f7-42d6bf342c0b
DEBUG 01-14 20:42:33.359225.359225 cuda_h.py:19] end load_into_gpu_async cost 0.0016002655029296875 seconds
DEBUG 01-14 20:42:33.359928.359928 cuda_h.py:10] start restore_tensors2
DEBUG 01-14 20:42:33.359448.359448 cuda_h.py:19] end restore_tensors2 cost 7.677078247070312e-05 seconds
DEBUG 01-14 20:42:33.359727.359727 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0040950775146484375 seconds
INFO 01-14 20:42:33.360531.360531 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, a4783a7d-bbf8-430b-88f7-42d6bf342c0b
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-14 20:42:33.362008.362008 cuda_h.py:19] end self_attn cost 0.0037932395935058594 seconds
DEBUG 01-14 20:42:33.363989.363989 cuda_h.py:19] end iln_self_attn_paln cost 0.007429838180541992 seconds
DEBUG 01-14 20:42:33.363482.363482 cuda_h.py:10] start layer_moe_generate_mp_l_20
DEBUG 01-14 20:42:33.363695.363695 cuda_h.py:10] start gate
DEBUG 01-14 20:42:33.364894.364894 cuda_h.py:19] end gate cost 0.0009372234344482422 seconds
DEBUG 01-14 20:42:33.364181.364181 cuda_h.py:10] start experts_map_get
DEBUG 01-14 20:42:33.365922.365922 lmp.py:1615] 
DEBUG 01-14 20:42:33.365922.365922 lmp.py:1615] Expert Token Distribution & Device Allocation:
DEBUG 01-14 20:42:33.365189.365189 lmp.py:1616]   Total experts: 64
DEBUG 01-14 20:42:33.365621.365621 lmp.py:1617]   CPU experts: 32 (50%)
DEBUG 01-14 20:42:33.365854.365854 lmp.py:1618]   GPU experts: 32 (50%)
DEBUG 01-14 20:42:33.365557.365557 lmp.py:1619] 
DEBUG 01-14 20:42:33.365557.365557 lmp.py:1619]   Expert ID | Tokens | Device
DEBUG 01-14 20:42:33.365021.365021 lmp.py:1620]   -----------------------------------
DEBUG 01-14 20:42:33.365585.365585 lmp.py:1625]   Expert  1 |     37 | CPU
DEBUG 01-14 20:42:33.365480.365480 lmp.py:1625]   Expert 44 |     47 | CPU
DEBUG 01-14 20:42:33.365944.365944 lmp.py:1625]   Expert 60 |     65 | CPU
DEBUG 01-14 20:42:33.365455.365455 lmp.py:1625]   Expert 28 |     77 | CPU
DEBUG 01-14 20:42:33.365204.365204 lmp.py:1625]   Expert 27 |     90 | CPU
DEBUG 01-14 20:42:33.365715.365715 lmp.py:1625]   Expert 62 |     91 | CPU
DEBUG 01-14 20:42:33.365849.365849 lmp.py:1625]   Expert 48 |     93 | CPU
DEBUG 01-14 20:42:33.365028.365028 lmp.py:1625]   Expert 30 |     99 | CPU
DEBUG 01-14 20:42:33.365970.365970 lmp.py:1625]   Expert  0 |    105 | CPU
DEBUG 01-14 20:42:33.365673.365673 lmp.py:1625]   Expert 22 |    109 | CPU
DEBUG 01-14 20:42:33.365137.365137 lmp.py:1625]   Expert 42 |    111 | CPU
DEBUG 01-14 20:42:33.365794.365794 lmp.py:1625]   Expert 58 |    114 | CPU
DEBUG 01-14 20:42:33.365258.365258 lmp.py:1625]   Expert 59 |    123 | CPU
DEBUG 01-14 20:42:33.365722.365722 lmp.py:1625]   Expert  8 |    127 | CPU
DEBUG 01-14 20:42:33.365187.365187 lmp.py:1625]   Expert 50 |    127 | CPU
DEBUG 01-14 20:42:33.365413.365413 lmp.py:1625]   Expert 12 |    132 | CPU
DEBUG 01-14 20:42:33.365354.365354 lmp.py:1625]   Expert 56 |    139 | CPU
DEBUG 01-14 20:42:33.365057.365057 lmp.py:1625]   Expert  5 |    144 | CPU
DEBUG 01-14 20:42:33.365283.365283 lmp.py:1625]   Expert 32 |    144 | CPU
DEBUG 01-14 20:42:33.365748.365748 lmp.py:1625]   Expert 55 |    149 | CPU
DEBUG 01-14 20:42:33.365974.365974 lmp.py:1625]   Expert 16 |    152 | CPU
DEBUG 01-14 20:42:33.365438.365438 lmp.py:1625]   Expert 34 |    152 | CPU
DEBUG 01-14 20:42:33.365618.365618 lmp.py:1625]   Expert 26 |    154 | CPU
DEBUG 01-14 20:42:33.366036.366036 lmp.py:1625]   Expert 19 |    155 | CPU
DEBUG 01-14 20:42:33.366024.366024 lmp.py:1625]   Expert 15 |    159 | CPU
DEBUG 01-14 20:42:33.366250.366250 lmp.py:1625]   Expert 47 |    159 | CPU
DEBUG 01-14 20:42:33.366237.366237 lmp.py:1625]   Expert  2 |    161 | CPU
DEBUG 01-14 20:42:33.366655.366655 lmp.py:1625]   Expert 13 |    163 | CPU
DEBUG 01-14 20:42:33.366358.366358 lmp.py:1625]   Expert 41 |    169 | CPU
DEBUG 01-14 20:42:33.366584.366584 lmp.py:1625]   Expert 52 |    174 | CPU
DEBUG 01-14 20:42:33.366810.366810 lmp.py:1625]   Expert 25 |    175 | CPU
DEBUG 01-14 20:42:33.366798.366798 lmp.py:1625]   Expert 18 |    177 | CPU
DEBUG 01-14 20:42:33.366739.366739 lmp.py:1625]   Expert 24 |    178 | GPU
DEBUG 01-14 20:42:33.366442.366442 lmp.py:1625]   Expert  6 |    179 | GPU
DEBUG 01-14 20:42:33.366191.366191 lmp.py:1625]   Expert 37 |    179 | GPU
DEBUG 01-14 20:42:33.366656.366656 lmp.py:1625]   Expert 20 |    182 | GPU
DEBUG 01-14 20:42:33.366405.366405 lmp.py:1625]   Expert 51 |    182 | GPU
DEBUG 01-14 20:42:33.366062.366062 lmp.py:1625]   Expert 40 |    183 | GPU
DEBUG 01-14 20:42:33.366765.366765 lmp.py:1625]   Expert 54 |    187 | GPU
DEBUG 01-14 20:42:33.366752.366752 lmp.py:1625]   Expert 17 |    188 | GPU
DEBUG 01-14 20:42:33.366932.366932 lmp.py:1625]   Expert 57 |    189 | GPU
DEBUG 01-14 20:42:33.366350.366350 lmp.py:1625]   Expert  3 |    194 | GPU
DEBUG 01-14 20:42:33.366338.366338 lmp.py:1625]   Expert 46 |    194 | GPU
DEBUG 01-14 20:42:33.366087.366087 lmp.py:1625]   Expert 11 |    198 | GPU
DEBUG 01-14 20:42:33.366267.366267 lmp.py:1625]   Expert 23 |    204 | GPU
DEBUG 01-14 20:42:33.366254.366254 lmp.py:1625]   Expert 43 |    207 | GPU
DEBUG 01-14 20:42:33.366480.366480 lmp.py:1625]   Expert 49 |    219 | GPU
DEBUG 01-14 20:42:33.366898.366898 lmp.py:1625]   Expert 31 |    222 | GPU
DEBUG 01-14 20:42:33.366840.366840 lmp.py:1625]   Expert 10 |    228 | GPU
DEBUG 01-14 20:42:33.366066.366066 lmp.py:1625]   Expert 35 |    229 | GPU
DEBUG 01-14 20:42:33.366053.366053 lmp.py:1625]   Expert 53 |    234 | GPU
DEBUG 01-14 20:42:33.366756.366756 lmp.py:1625]   Expert 36 |    246 | GPU
DEBUG 01-14 20:42:33.366221.366221 lmp.py:1625]   Expert 33 |    253 | GPU
DEBUG 01-14 20:42:33.366162.366162 lmp.py:1625]   Expert 38 |    265 | GPU
DEBUG 01-14 20:42:33.366150.366150 lmp.py:1625]   Expert 39 |    265 | GPU
DEBUG 01-14 20:42:33.366376.366376 lmp.py:1625]   Expert  4 |    305 | GPU
DEBUG 01-14 20:42:33.366555.366555 lmp.py:1625]   Expert 21 |    326 | GPU
DEBUG 01-14 20:42:33.366735.366735 lmp.py:1625]   Expert  9 |    328 | GPU
DEBUG 01-14 20:42:33.366200.366200 lmp.py:1625]   Expert 14 |    341 | GPU
DEBUG 01-14 20:42:33.366426.366426 lmp.py:1625]   Expert 63 |    359 | GPU
DEBUG 01-14 20:42:33.366413.366413 lmp.py:1625]   Expert 45 |    363 | GPU
DEBUG 01-14 20:42:33.367639.367639 lmp.py:1625]   Expert 61 |    385 | GPU
DEBUG 01-14 20:42:33.367342.367342 lmp.py:1625]   Expert 29 |    488 | GPU
DEBUG 01-14 20:42:33.367045.367045 lmp.py:1625]   Expert  7 |    515 | GPU
DEBUG 01-14 20:42:33.367225.367225 lmp.py:1626] 
DEBUG 01-14 20:42:33.367225.367225 lmp.py:1626]   CPU total tokens: 4073 (33.1%)
DEBUG 01-14 20:42:33.367358.367358 lmp.py:1627]   GPU total tokens: 8215 (66.9%)
DEBUG 01-14 20:42:33.367214.367214 cuda_h.py:19] end experts_map_get cost 0.0025038719177246094 seconds
DEBUG 01-14 20:42:33.367144.367144 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-14 20:42:33.367213.367213 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-14 20:42:33.367411.367411 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-14 20:42:33.367276.367276 cuda_h.py:19] end allocate_cuda_memory cost 0.0002789497375488281 seconds
DEBUG 01-14 20:42:33.367212.367212 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-14 20:42:33.367107.367107 sllm_store_c.py:27] get device uuid map
DEBUG 01-14 20:42:33.367532.367532 sllm_store_c.py:29] call client load into gpu
DEBUG 01-14 20:42:33.367705.367705 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, f6578bb0-d957-46b9-9127-d01cf932bd10
DEBUG 01-14 20:42:33.368738.368738 client.py:106] call stub.LoadModelAsync
INFO 01-14 20:42:33.368902.368902 client.py:127] Model loaded
DEBUG 01-14 20:42:33.368275.368275 cuda_h.py:10] start restore2model
DEBUG 01-14 20:42:33.368676.368676 cuda_h.py:19] end restore2model cost 0.0004642009735107422 seconds
DEBUG 01-14 20:42:33.368035.368035 cuda_h.py:19] end sllm_worker_task cost 0.013302087783813477 seconds
INFO 01-14 20:42:33.369978.369978 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, f6578bb0-d957-46b9-9127-d01cf932bd10
DEBUG 01-14 20:42:33.369113.369113 cuda_h.py:19] end load_into_gpu_async cost 0.0017554759979248047 seconds
DEBUG 01-14 20:42:33.369961.369961 cuda_h.py:10] start restore_tensors2
DEBUG 01-14 20:42:33.370980.370980 cuda_h.py:19] end restore_tensors2 cost 0.0003383159637451172 seconds
DEBUG 01-14 20:42:33.370379.370379 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0027577877044677734 seconds
DEBUG 01-14 20:42:33.370857.370857 cuda_h.py:10] start restore2model
DEBUG 01-14 20:42:33.372839.372839 cuda_h.py:19] end restore2model cost 0.002801179885864258 seconds
DEBUG 01-14 20:42:33.373682.373682 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.005765199661254883 seconds
DEBUG 01-14 20:42:33.373485.373485 cuda_h.py:10] start gpu_sexperts
DEBUG 01-14 20:42:33.373422.373422 cuda_h.py:19] end gpu_sexperts cost 0.0002741813659667969 seconds
DEBUG 01-14 20:42:33.373530.373530 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-14 20:42:33.373948.373948 lmp.py:1683] 
DEBUG 01-14 20:42:33.373948.373948 lmp.py:1683]   Computing 32 experts on CPU...
DEBUG 01-14 20:42:33.373652.373652 cuda_h.py:19] end cpu_experts_submit cost 5.555152893066406e-05 seconds
DEBUG 01-14 20:42:33.373831.373831 cuda_h.py:10] start experts_func_mgpu_group_pad
DEBUG 01-14 20:42:33.385153.385153 mlpmodule.py:1460] group tensors cost 0.011339664459228516 s
DEBUG 01-14 20:42:33.386360.386360 cuda_h.py:10] start move_flat_hidden2cpu
DEBUG 01-14 20:42:33.390513.390513 cuda_h.py:19] end experts_func_mgpu_group_pad cost 0.017263174057006836 seconds
DEBUG 01-14 20:42:33.393504.393504 cuda_h.py:10] start gpu_group_list
DEBUG 01-14 20:42:33.394618.394618 cuda_h.py:19] end gpu_group_list cost 0.0008637905120849609 seconds
DEBUG 01-14 20:42:33.394821.394821 cuda_h.py:19] end move_flat_hidden2cpu cost 0.007908344268798828 seconds
DEBUG 01-14 20:42:33.395852.395852 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-14 20:42:33.395647.395647 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 3.886222839355469e-05 seconds
DEBUG 01-14 20:42:33.395048.395048 cuda_h.py:10] start wait_experts
INFO 01-14 20:42:33.395772.395772 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, f6578bb0-d957-46b9-9127-d01cf932bd10
DEBUG 01-14 20:42:33.397515.397515 mlpmodule.py:1533] pad cost 0.002370595932006836 s
DEBUG 01-14 20:42:33.397884.397884 mlpmodule.py:1539] create cpu tensor cost 4.1961669921875e-05 s
DEBUG 01-14 20:42:33.399114.399114 mlpmodule.py:1544] move to cpu cost 0.0020933151245117188 s
DEBUG 01-14 20:42:33.409969.409969 mlpmodule.py:1558] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-14 20:42:33.409040.409040 mlpmodule.py:1559] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-14 20:42:33.409924.409924 mlpmodule.py:1564] group_w3 first element: -0.0034942626953125
WARNING 01-14 20:42:33.409279.409279 mlpmodule.py:1574] start einsum2
INFO 01-14 20:42:33.425721.425721 client.py:127] Model loaded
DEBUG 01-14 20:42:33.425934.425934 cuda_h.py:19] end wait_experts cost 0.029732704162597656 seconds
DEBUG 01-14 20:42:33.425805.425805 cuda_h.py:10] start gpu_experts
DEBUG 01-14 20:42:33.425821.425821 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-14 20:42:33.426975.426975 mlpmodule.py:1584] group einsum cost 0.026822328567504883 s
DEBUG 01-14 20:42:33.427245.427245 mlpmodule.py:1593] cpy2cputensor cost 0.0007472038269042969 s
DEBUG 01-14 20:42:33.427253.427253 cuda_h.py:10] start move_outputs
DEBUG 01-14 20:42:33.429594.429594 cuda_h.py:19] end move_outputs cost 0.002045869827270508 seconds
DEBUG 01-14 20:42:33.433841.433841 cuda_h.py:19] end wait_cetm_experts cost 0.007810115814208984 seconds
DEBUG 01-14 20:42:33.433822.433822 cuda_h.py:10] start gpu_group_einsum_mp_multi_list
DEBUG 01-14 20:42:33.433203.433203 cuda_h.py:10] start gpu_group_tensor
DEBUG 01-14 20:42:33.434048.434048 cuda_h.py:19] end gpu_group_tensor cost 0.00041675567626953125 seconds
DEBUG 01-14 20:42:33.434520.434520 cuda_h.py:10] start gpu_group_einsum
DEBUG 01-14 20:42:33.435585.435585 cuda_h.py:19] end gpu_group_einsum cost 0.0012257099151611328 seconds
DEBUG 01-14 20:42:33.436613.436613 cuda_h.py:10] start gpu_final_hidden_states_scatter
DEBUG 01-14 20:42:33.436883.436883 cuda_h.py:10] start all_expert_outputs_slices
DEBUG 01-14 20:42:33.436406.436406 cuda_h.py:19] end all_expert_outputs_slices cost 0.0007185935974121094 seconds
DEBUG 01-14 20:42:33.437331.437331 cuda_h.py:10] start concat_expert_out
DEBUG 01-14 20:42:33.437067.437067 cuda_h.py:19] end concat_expert_out cost 0.00014328956604003906 seconds
DEBUG 01-14 20:42:33.437754.437754 cuda_h.py:10] start index_scatter
DEBUG 01-14 20:42:33.437703.437703 cuda_h.py:19] end index_scatter cost 0.0001513957977294922 seconds
DEBUG 01-14 20:42:33.437786.437786 cuda_h.py:19] end gpu_final_hidden_states_scatter cost 0.0016722679138183594 seconds
DEBUG 01-14 20:42:33.438116.438116 cuda_h.py:19] end gpu_experts cost 0.01258993148803711 seconds
DEBUG 01-14 20:42:33.438595.438595 cuda_h.py:10] start all_expert_weight_slices
DEBUG 01-14 20:42:33.440425.440425 cuda_h.py:19] end all_expert_weight_slices cost 0.0019750595092773438 seconds
DEBUG 01-14 20:42:33.440455.440455 cuda_h.py:10] start cpuoutputsdeal
DEBUG 01-14 20:42:33.441703.441703 cuda_h.py:10] start index_scatter
DEBUG 01-14 20:42:33.441505.441505 cuda_h.py:19] end index_scatter cost 0.00010037422180175781 seconds
DEBUG 01-14 20:42:33.441282.441282 cuda_h.py:19] end cpuoutputsdeal cost 0.0011053085327148438 seconds
DEBUG 01-14 20:42:33.441877.441877 cuda_h.py:19] end layer_moe_generate_mp_l_20 cost 0.07801032066345215 seconds
DEBUG 01-14 20:42:33.442519.442519 cuda_h.py:19] end prefill_layer cost 0.08719348907470703 seconds
DEBUG 01-14 20:42:33.442715.442715 lmp.py:1551] -------------------------------- end prefill layer 19 --------------------------------
DEBUG 01-14 20:42:33.442312.442312 cuda_h.py:10] start prefill_layer
DEBUG 01-14 20:42:33.442579.442579 lmp.py:1494] -------------------------------- start prefill layer 20 --------------------------------
DEBUG 01-14 20:42:33.442561.442561 cuda_h.py:10] start start_load_qkvogn_s_weight_l_21
DEBUG 01-14 20:42:33.442358.442358 cuda_h.py:10] start start_load_qkvogn_s_weight_l_21
DEBUG 01-14 20:42:33.442984.442984 cuda_h.py:19] end start_load_qkvogn_s_weight_l_21 cost 4.8160552978515625e-05 seconds
DEBUG 01-14 20:42:33.442643.442643 cuda_h.py:10] start sllm_worker_task
DEBUG 01-14 20:42:33.442261.442261 cuda_h.py:19] end start_load_qkvogn_s_weight_l_21 cost 0.00022411346435546875 seconds
DEBUG 01-14 20:42:33.442491.442491 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-14 20:42:33.442692.442692 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-14 20:42:33.443563.443563 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-14 20:42:33.444095.444095 cuda_h.py:19] end allocate_cuda_memory cost 0.0011548995971679688 seconds
DEBUG 01-14 20:42:33.444403.444403 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-14 20:42:33.444073.444073 sllm_store_c.py:27] get device uuid map
DEBUG 01-14 20:42:33.444141.444141 sllm_store_c.py:29] call client load into gpu
DEBUG 01-14 20:42:33.444036.444036 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 30cbf3b7-caa1-45ab-afd0-3ece2b5a254c
DEBUG 01-14 20:42:33.444866.444866 client.py:106] call stub.LoadModelAsync
DEBUG 01-14 20:42:33.444371.444371 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-14 20:42:33.445159.445159 mlpmodule.py:1367]  experts func einsum cost 0.07091259956359863 s
DEBUG 01-14 20:42:33.445740.445740 cuda_h.py:10] start self_attn
INFO 01-14 20:42:33.445626.445626 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 30cbf3b7-caa1-45ab-afd0-3ece2b5a254c
DEBUG 01-14 20:42:33.445800.445800 cuda_h.py:19] end load_into_gpu_async cost 0.0015528202056884766 seconds
DEBUG 01-14 20:42:33.446218.446218 cuda_h.py:10] start restore_tensors2
DEBUG 01-14 20:42:33.446692.446692 cuda_h.py:19] end restore_tensors2 cost 7.748603820800781e-05 seconds
DEBUG 01-14 20:42:33.446494.446494 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0031332969665527344 seconds
INFO 01-14 20:42:33.446365.446365 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 30cbf3b7-caa1-45ab-afd0-3ece2b5a254c
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-14 20:42:33.450865.450865 cuda_h.py:19] end self_attn cost 0.004790306091308594 seconds
DEBUG 01-14 20:42:33.450241.450241 cuda_h.py:19] end iln_self_attn_paln cost 0.007729530334472656 seconds
DEBUG 01-14 20:42:33.450859.450859 cuda_h.py:10] start layer_moe_generate_mp_l_21
DEBUG 01-14 20:42:33.450205.450205 cuda_h.py:10] start gate
DEBUG 01-14 20:42:33.451230.451230 cuda_h.py:19] end gate cost 0.0007145404815673828 seconds
DEBUG 01-14 20:42:33.451451.451451 cuda_h.py:10] start experts_map_get
DEBUG 01-14 20:42:33.452921.452921 lmp.py:1615] 
DEBUG 01-14 20:42:33.452921.452921 lmp.py:1615] Expert Token Distribution & Device Allocation:
DEBUG 01-14 20:42:33.452412.452412 lmp.py:1616]   Total experts: 64
DEBUG 01-14 20:42:33.452691.452691 lmp.py:1617]   CPU experts: 32 (50%)
DEBUG 01-14 20:42:33.452249.452249 lmp.py:1618]   GPU experts: 32 (50%)
DEBUG 01-14 20:42:33.452660.452660 lmp.py:1619] 
DEBUG 01-14 20:42:33.452660.452660 lmp.py:1619]   Expert ID | Tokens | Device
DEBUG 01-14 20:42:33.452833.452833 lmp.py:1620]   -----------------------------------
DEBUG 01-14 20:42:33.452959.452959 lmp.py:1625]   Expert 54 |     27 | CPU
DEBUG 01-14 20:42:33.452371.452371 lmp.py:1625]   Expert  3 |     40 | CPU
DEBUG 01-14 20:42:33.452828.452828 lmp.py:1625]   Expert 28 |     40 | CPU
DEBUG 01-14 20:42:33.452631.452631 lmp.py:1625]   Expert  8 |     45 | CPU
DEBUG 01-14 20:42:33.452804.452804 lmp.py:1625]   Expert 43 |     58 | CPU
DEBUG 01-14 20:42:33.452785.452785 lmp.py:1625]   Expert 63 |     61 | CPU
DEBUG 01-14 20:42:33.452004.452004 lmp.py:1625]   Expert 38 |     78 | CPU
DEBUG 01-14 20:42:33.452700.452700 lmp.py:1625]   Expert  6 |     80 | CPU
DEBUG 01-14 20:42:33.452919.452919 lmp.py:1625]   Expert 57 |     83 | CPU
DEBUG 01-14 20:42:33.452092.452092 lmp.py:1625]   Expert 39 |     85 | CPU
DEBUG 01-14 20:42:33.452550.452550 lmp.py:1625]   Expert 36 |     94 | CPU
DEBUG 01-14 20:42:33.452531.452531 lmp.py:1625]   Expert 41 |     99 | CPU
DEBUG 01-14 20:42:33.452511.452511 lmp.py:1625]   Expert 47 |    102 | CPU
DEBUG 01-14 20:42:33.452254.452254 lmp.py:1625]   Expert 12 |    105 | CPU
DEBUG 01-14 20:42:33.452473.452473 lmp.py:1625]   Expert 52 |    108 | CPU
DEBUG 01-14 20:42:33.452454.452454 lmp.py:1625]   Expert 19 |    110 | CPU
DEBUG 01-14 20:42:33.452435.452435 lmp.py:1625]   Expert 13 |    133 | CPU
DEBUG 01-14 20:42:33.452177.452177 lmp.py:1625]   Expert 46 |    137 | CPU
DEBUG 01-14 20:42:33.452112.452112 lmp.py:1625]   Expert 22 |    141 | CPU
DEBUG 01-14 20:42:33.452000.452000 lmp.py:1625]   Expert 50 |    141 | CPU
DEBUG 01-14 20:42:33.452888.452888 lmp.py:1625]   Expert 40 |    146 | CPU
DEBUG 01-14 20:42:33.452061.452061 lmp.py:1625]   Expert  2 |    159 | CPU
DEBUG 01-14 20:42:33.452472.452472 lmp.py:1625]   Expert 20 |    159 | CPU
DEBUG 01-14 20:42:33.452407.452407 lmp.py:1625]   Expert 37 |    160 | CPU
DEBUG 01-14 20:42:33.452533.452533 lmp.py:1625]   Expert 14 |    164 | CPU
DEBUG 01-14 20:42:33.452468.452468 lmp.py:1625]   Expert 53 |    165 | CPU
DEBUG 01-14 20:42:33.452164.452164 lmp.py:1625]   Expert 21 |    169 | CPU
DEBUG 01-14 20:42:33.452098.452098 lmp.py:1625]   Expert 23 |    171 | CPU
DEBUG 01-14 20:42:33.452795.452795 lmp.py:1625]   Expert 55 |    171 | CPU
DEBUG 01-14 20:42:33.452491.452491 lmp.py:1625]   Expert 24 |    180 | CPU
DEBUG 01-14 20:42:33.452140.452140 lmp.py:1625]   Expert 61 |    181 | CPU
DEBUG 01-14 20:42:33.453790.453790 lmp.py:1625]   Expert 42 |    184 | CPU
DEBUG 01-14 20:42:33.453202.453202 lmp.py:1625]   Expert  0 |    185 | GPU
DEBUG 01-14 20:42:33.453613.453613 lmp.py:1625]   Expert  5 |    190 | GPU
DEBUG 01-14 20:42:33.453547.453547 lmp.py:1625]   Expert 34 |    197 | GPU
DEBUG 01-14 20:42:33.453959.453959 lmp.py:1625]   Expert 33 |    199 | GPU
DEBUG 01-14 20:42:33.453655.453655 lmp.py:1625]   Expert 30 |    200 | GPU
DEBUG 01-14 20:42:33.453543.453543 lmp.py:1625]   Expert 18 |    201 | GPU
DEBUG 01-14 20:42:33.453478.453478 lmp.py:1625]   Expert 49 |    201 | GPU
DEBUG 01-14 20:42:33.453174.453174 lmp.py:1625]   Expert 32 |    202 | GPU
DEBUG 01-14 20:42:33.453347.453347 lmp.py:1625]   Expert 16 |    207 | GPU
DEBUG 01-14 20:42:33.453281.453281 lmp.py:1625]   Expert  9 |    212 | GPU
DEBUG 01-14 20:42:33.453454.453454 lmp.py:1625]   Expert 59 |    214 | GPU
DEBUG 01-14 20:42:33.453627.453627 lmp.py:1625]   Expert 62 |    214 | GPU
DEBUG 01-14 20:42:33.453515.453515 lmp.py:1625]   Expert  7 |    217 | GPU
DEBUG 01-14 20:42:33.453450.453450 lmp.py:1625]   Expert 31 |    220 | GPU
DEBUG 01-14 20:42:33.453106.453106 lmp.py:1625]   Expert 10 |    225 | GPU
DEBUG 01-14 20:42:33.453471.453471 lmp.py:1625]   Expert 60 |    226 | GPU
DEBUG 01-14 20:42:33.453598.453598 lmp.py:1625]   Expert 29 |    229 | GPU
DEBUG 01-14 20:42:33.453532.453532 lmp.py:1625]   Expert 15 |    230 | GPU
DEBUG 01-14 20:42:33.453705.453705 lmp.py:1625]   Expert  4 |    234 | GPU
DEBUG 01-14 20:42:33.453640.453640 lmp.py:1625]   Expert 17 |    236 | GPU
DEBUG 01-14 20:42:33.453051.453051 lmp.py:1625]   Expert 58 |    238 | GPU
DEBUG 01-14 20:42:33.453462.453462 lmp.py:1625]   Expert 26 |    250 | GPU
DEBUG 01-14 20:42:33.453159.453159 lmp.py:1625]   Expert 44 |    268 | GPU
DEBUG 01-14 20:42:33.453855.453855 lmp.py:1625]   Expert 51 |    275 | GPU
DEBUG 01-14 20:42:33.453789.453789 lmp.py:1625]   Expert 11 |    284 | GPU
DEBUG 01-14 20:42:33.453008.453008 lmp.py:1625]   Expert 56 |    284 | GPU
DEBUG 01-14 20:42:33.453420.453420 lmp.py:1625]   Expert 27 |    297 | GPU
DEBUG 01-14 20:42:33.453354.453354 lmp.py:1625]   Expert  1 |    342 | GPU
DEBUG 01-14 20:42:33.453050.453050 lmp.py:1625]   Expert 45 |    367 | GPU
DEBUG 01-14 20:42:33.453270.453270 lmp.py:1625]   Expert 25 |    444 | GPU
DEBUG 01-14 20:42:33.453204.453204 lmp.py:1625]   Expert 35 |    514 | GPU
DEBUG 01-14 20:42:33.453900.453900 lmp.py:1625]   Expert 48 |    710 | GPU
DEBUG 01-14 20:42:33.453788.453788 lmp.py:1626] 
DEBUG 01-14 20:42:33.453788.453788 lmp.py:1626]   CPU total tokens: 3776 (30.7%)
DEBUG 01-14 20:42:33.453869.453869 lmp.py:1627]   GPU total tokens: 8512 (69.3%)
DEBUG 01-14 20:42:33.453002.453002 cuda_h.py:19] end experts_map_get cost 0.001985788345336914 seconds
INFO 01-14 20:42:33.453382.453382 client.py:127] Model loaded
DEBUG 01-14 20:42:33.453503.453503 cuda_h.py:10] start restore2model
DEBUG 01-14 20:42:33.454296.454296 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-14 20:42:33.454372.454372 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-14 20:42:33.454411.454411 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-14 20:42:33.454726.454726 cuda_h.py:19] end allocate_cuda_memory cost 0.00026154518127441406 seconds
DEBUG 01-14 20:42:33.454228.454228 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-14 20:42:33.454713.454713 sllm_store_c.py:27] get device uuid map
DEBUG 01-14 20:42:33.454343.454343 sllm_store_c.py:29] call client load into gpu
DEBUG 01-14 20:42:33.454669.454669 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 45c5b3f4-3b48-42c4-b349-28ac232e693d
DEBUG 01-14 20:42:33.455504.455504 client.py:106] call stub.LoadModelAsync
DEBUG 01-14 20:42:33.455514.455514 cuda_h.py:19] end restore2model cost 0.0014824867248535156 seconds
DEBUG 01-14 20:42:33.455675.455675 cuda_h.py:19] end sllm_worker_task cost 0.01263427734375 seconds
INFO 01-14 20:42:33.456025.456025 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 45c5b3f4-3b48-42c4-b349-28ac232e693d
DEBUG 01-14 20:42:33.456882.456882 cuda_h.py:19] end load_into_gpu_async cost 0.0014905929565429688 seconds
DEBUG 01-14 20:42:33.456214.456214 cuda_h.py:10] start restore_tensors2
DEBUG 01-14 20:42:33.456573.456573 cuda_h.py:19] end restore_tensors2 cost 0.00039768218994140625 seconds
DEBUG 01-14 20:42:33.456039.456039 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.002670764923095703 seconds
DEBUG 01-14 20:42:33.456146.456146 cuda_h.py:10] start restore2model
DEBUG 01-14 20:42:33.460804.460804 cuda_h.py:19] end restore2model cost 0.003190279006958008 seconds
DEBUG 01-14 20:42:33.460163.460163 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.006068706512451172 seconds
DEBUG 01-14 20:42:33.460959.460959 cuda_h.py:10] start gpu_sexperts
DEBUG 01-14 20:42:33.460083.460083 cuda_h.py:19] end gpu_sexperts cost 0.00030612945556640625 seconds
DEBUG 01-14 20:42:33.460859.460859 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-14 20:42:33.460423.460423 lmp.py:1683] 
DEBUG 01-14 20:42:33.460423.460423 lmp.py:1683]   Computing 32 experts on CPU...
DEBUG 01-14 20:42:33.460551.460551 cuda_h.py:19] end cpu_experts_submit cost 5.91278076171875e-05 seconds
DEBUG 01-14 20:42:33.460585.460585 cuda_h.py:10] start experts_func_mgpu_group_pad
DEBUG 01-14 20:42:33.477366.477366 mlpmodule.py:1460] group tensors cost 0.01659417152404785 s
DEBUG 01-14 20:42:33.479559.479559 cuda_h.py:10] start move_flat_hidden2cpu
DEBUG 01-14 20:42:33.484001.484001 cuda_h.py:19] end experts_func_mgpu_group_pad cost 0.02323603630065918 seconds
DEBUG 01-14 20:42:33.486585.486585 cuda_h.py:19] end move_flat_hidden2cpu cost 0.00717926025390625 seconds
DEBUG 01-14 20:42:33.486178.486178 cuda_h.py:10] start gpu_group_list
DEBUG 01-14 20:42:33.488958.488958 cuda_h.py:19] end gpu_group_list cost 0.0009388923645019531 seconds
DEBUG 01-14 20:42:33.488978.488978 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-14 20:42:33.488653.488653 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 3.910064697265625e-05 seconds
DEBUG 01-14 20:42:33.488538.488538 cuda_h.py:10] start wait_experts
INFO 01-14 20:42:33.488315.488315 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 45c5b3f4-3b48-42c4-b349-28ac232e693d
DEBUG 01-14 20:42:33.490117.490117 mlpmodule.py:1533] pad cost 0.003669261932373047 s
DEBUG 01-14 20:42:33.490592.490592 mlpmodule.py:1539] create cpu tensor cost 3.9577484130859375e-05 s
DEBUG 01-14 20:42:33.492415.492415 mlpmodule.py:1544] move to cpu cost 0.0021758079528808594 s
DEBUG 01-14 20:42:33.502334.502334 mlpmodule.py:1558] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-14 20:42:33.502466.502466 mlpmodule.py:1559] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-14 20:42:33.502264.502264 mlpmodule.py:1564] group_w3 first element: 0.039306640625
WARNING 01-14 20:42:33.502824.502824 mlpmodule.py:1574] start einsum2
INFO 01-14 20:42:33.509098.509098 client.py:127] Model loaded
DEBUG 01-14 20:42:33.509303.509303 cuda_h.py:19] end wait_experts cost 0.020799636840820312 seconds
DEBUG 01-14 20:42:33.509908.509908 cuda_h.py:10] start gpu_experts
DEBUG 01-14 20:42:33.509374.509374 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-14 20:42:33.518671.518671 mlpmodule.py:1584] group einsum cost 0.026149749755859375 s
DEBUG 01-14 20:42:33.519380.519380 mlpmodule.py:1593] cpy2cputensor cost 0.0008068084716796875 s
DEBUG 01-14 20:42:33.519964.519964 cuda_h.py:10] start move_outputs
DEBUG 01-14 20:42:33.522475.522475 cuda_h.py:19] end move_outputs cost 0.002148866653442383 seconds
DEBUG 01-14 20:42:33.527820.527820 cuda_h.py:19] end wait_cetm_experts cost 0.017565488815307617 seconds
DEBUG 01-14 20:42:33.527716.527716 cuda_h.py:10] start gpu_group_einsum_mp_multi_list
DEBUG 01-14 20:42:33.527919.527919 cuda_h.py:10] start gpu_group_tensor
DEBUG 01-14 20:42:33.528678.528678 cuda_h.py:19] end gpu_group_tensor cost 0.000431060791015625 seconds
DEBUG 01-14 20:42:33.528199.528199 cuda_h.py:10] start gpu_group_einsum
DEBUG 01-14 20:42:33.530564.530564 cuda_h.py:19] end gpu_group_einsum cost 0.0012710094451904297 seconds
DEBUG 01-14 20:42:33.530156.530156 cuda_h.py:10] start gpu_final_hidden_states_scatter
DEBUG 01-14 20:42:33.530445.530445 cuda_h.py:10] start all_expert_outputs_slices
DEBUG 01-14 20:42:33.531662.531662 cuda_h.py:19] end all_expert_outputs_slices cost 0.0006322860717773438 seconds
DEBUG 01-14 20:42:33.531545.531545 cuda_h.py:10] start concat_expert_out
DEBUG 01-14 20:42:33.531944.531944 cuda_h.py:19] end concat_expert_out cost 0.0001430511474609375 seconds
DEBUG 01-14 20:42:33.531154.531154 cuda_h.py:10] start index_scatter
DEBUG 01-14 20:42:33.531818.531818 cuda_h.py:19] end index_scatter cost 0.0001533031463623047 seconds
DEBUG 01-14 20:42:33.532623.532623 cuda_h.py:19] end gpu_final_hidden_states_scatter cost 0.001561880111694336 seconds
DEBUG 01-14 20:42:33.532497.532497 cuda_h.py:19] end gpu_experts cost 0.02246379852294922 seconds
DEBUG 01-14 20:42:33.532406.532406 cuda_h.py:10] start all_expert_weight_slices
DEBUG 01-14 20:42:33.534301.534301 cuda_h.py:19] end all_expert_weight_slices cost 0.002295970916748047 seconds
DEBUG 01-14 20:42:33.534211.534211 cuda_h.py:10] start cpuoutputsdeal
DEBUG 01-14 20:42:33.535061.535061 cuda_h.py:10] start index_scatter
DEBUG 01-14 20:42:33.536493.536493 cuda_h.py:19] end index_scatter cost 0.0001246929168701172 seconds
DEBUG 01-14 20:42:33.536629.536629 cuda_h.py:19] end cpuoutputsdeal cost 0.0013086795806884766 seconds
DEBUG 01-14 20:42:33.536981.536981 cuda_h.py:19] end layer_moe_generate_mp_l_21 cost 0.08543181419372559 seconds
DEBUG 01-14 20:42:33.537475.537475 cuda_h.py:19] end prefill_layer cost 0.09478425979614258 seconds
DEBUG 01-14 20:42:33.537022.537022 lmp.py:1551] -------------------------------- end prefill layer 20 --------------------------------
DEBUG 01-14 20:42:33.537833.537833 cuda_h.py:10] start prefill_layer
DEBUG 01-14 20:42:33.537881.537881 lmp.py:1494] -------------------------------- start prefill layer 21 --------------------------------
DEBUG 01-14 20:42:33.537215.537215 cuda_h.py:10] start start_load_qkvogn_s_weight_l_22
DEBUG 01-14 20:42:33.537032.537032 cuda_h.py:10] start start_load_qkvogn_s_weight_l_22
DEBUG 01-14 20:42:33.537097.537097 cuda_h.py:19] end start_load_qkvogn_s_weight_l_22 cost 6.437301635742188e-05 seconds
DEBUG 01-14 20:42:33.537008.537008 cuda_h.py:10] start sllm_worker_task
DEBUG 01-14 20:42:33.537084.537084 cuda_h.py:19] end start_load_qkvogn_s_weight_l_22 cost 0.0002751350402832031 seconds
DEBUG 01-14 20:42:33.538717.538717 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-14 20:42:33.538309.538309 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-14 20:42:33.538047.538047 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-14 20:42:33.539571.539571 cuda_h.py:19] end allocate_cuda_memory cost 0.0008749961853027344 seconds
DEBUG 01-14 20:42:33.539381.539381 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-14 20:42:33.539859.539859 sllm_store_c.py:27] get device uuid map
DEBUG 01-14 20:42:33.539272.539272 sllm_store_c.py:29] call client load into gpu
DEBUG 01-14 20:42:33.539882.539882 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, a9009ca0-4ae8-4dea-88d1-96a6b492edda
DEBUG 01-14 20:42:33.539335.539335 client.py:106] call stub.LoadModelAsync
DEBUG 01-14 20:42:33.539118.539118 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-14 20:42:33.539504.539504 mlpmodule.py:1367]  experts func einsum cost 0.07871055603027344 s
DEBUG 01-14 20:42:33.540369.540369 cuda_h.py:10] start self_attn
INFO 01-14 20:42:33.541340.541340 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, a9009ca0-4ae8-4dea-88d1-96a6b492edda
DEBUG 01-14 20:42:33.541607.541607 cuda_h.py:19] end load_into_gpu_async cost 0.0019550323486328125 seconds
DEBUG 01-14 20:42:33.541833.541833 cuda_h.py:10] start restore_tensors2
DEBUG 01-14 20:42:33.541492.541492 cuda_h.py:19] end restore_tensors2 cost 7.2479248046875e-05 seconds
DEBUG 01-14 20:42:33.541771.541771 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0032634735107421875 seconds
INFO 01-14 20:42:33.541938.541938 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, a9009ca0-4ae8-4dea-88d1-96a6b492edda
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-14 20:42:33.544418.544418 cuda_h.py:19] end self_attn cost 0.00410151481628418 seconds
DEBUG 01-14 20:42:33.545921.545921 cuda_h.py:19] end iln_self_attn_paln cost 0.006832599639892578 seconds
DEBUG 01-14 20:42:33.545315.545315 cuda_h.py:10] start layer_moe_generate_mp_l_22
DEBUG 01-14 20:42:33.545051.545051 cuda_h.py:10] start gate
DEBUG 01-14 20:42:33.546298.546298 cuda_h.py:19] end gate cost 0.0007984638214111328 seconds
DEBUG 01-14 20:42:33.546056.546056 cuda_h.py:10] start experts_map_get
DEBUG 01-14 20:42:33.546084.546084 lmp.py:1615] 
DEBUG 01-14 20:42:33.546084.546084 lmp.py:1615] Expert Token Distribution & Device Allocation:
DEBUG 01-14 20:42:33.546575.546575 lmp.py:1616]   Total experts: 64
DEBUG 01-14 20:42:33.546861.546861 lmp.py:1617]   CPU experts: 32 (50%)
DEBUG 01-14 20:42:33.546187.546187 lmp.py:1618]   GPU experts: 32 (50%)
DEBUG 01-14 20:42:33.546413.546413 lmp.py:1619] 
DEBUG 01-14 20:42:33.546413.546413 lmp.py:1619]   Expert ID | Tokens | Device
DEBUG 01-14 20:42:33.546400.546400 lmp.py:1620]   -----------------------------------
DEBUG 01-14 20:42:33.546534.546534 lmp.py:1625]   Expert 11 |     34 | CPU
DEBUG 01-14 20:42:33.546714.546714 lmp.py:1625]   Expert 44 |     41 | CPU
DEBUG 01-14 20:42:33.546416.546416 lmp.py:1625]   Expert  9 |     50 | CPU
DEBUG 01-14 20:42:33.546927.546927 lmp.py:1625]   Expert 54 |     58 | CPU
DEBUG 01-14 20:42:33.546200.546200 lmp.py:1625]   Expert 56 |     66 | CPU
DEBUG 01-14 20:42:33.546618.546618 lmp.py:1625]   Expert 62 |     94 | CPU
DEBUG 01-14 20:42:33.546513.546513 lmp.py:1625]   Expert 51 |     98 | CPU
DEBUG 01-14 20:42:33.547169.547169 lmp.py:1625]   Expert 35 |    103 | CPU
DEBUG 01-14 20:42:33.547111.547111 lmp.py:1625]   Expert 22 |    105 | CPU
DEBUG 01-14 20:42:33.547813.547813 lmp.py:1625]   Expert 47 |    105 | CPU
DEBUG 01-14 20:42:33.547755.547755 lmp.py:1625]   Expert 52 |    106 | CPU
DEBUG 01-14 20:42:33.547696.547696 lmp.py:1625]   Expert 41 |    108 | CPU
DEBUG 01-14 20:42:33.547160.547160 lmp.py:1625]   Expert 60 |    109 | CPU
DEBUG 01-14 20:42:33.547102.547102 lmp.py:1625]   Expert  7 |    111 | CPU
DEBUG 01-14 20:42:33.547997.547997 lmp.py:1625]   Expert  1 |    115 | CPU
DEBUG 01-14 20:42:33.547176.547176 lmp.py:1625]   Expert  8 |    118 | CPU
DEBUG 01-14 20:42:33.547118.547118 lmp.py:1625]   Expert 48 |    122 | CPU
DEBUG 01-14 20:42:33.547344.547344 lmp.py:1625]   Expert  6 |    127 | CPU
DEBUG 01-14 20:42:33.547285.547285 lmp.py:1625]   Expert  2 |    133 | CPU
DEBUG 01-14 20:42:33.547180.547180 lmp.py:1625]   Expert 53 |    133 | CPU
DEBUG 01-14 20:42:33.547883.547883 lmp.py:1625]   Expert 32 |    134 | CPU
DEBUG 01-14 20:42:33.547109.547109 lmp.py:1625]   Expert 27 |    136 | CPU
DEBUG 01-14 20:42:33.547335.547335 lmp.py:1625]   Expert 23 |    140 | CPU
DEBUG 01-14 20:42:33.547800.547800 lmp.py:1625]   Expert 59 |    144 | CPU
DEBUG 01-14 20:42:33.547979.547979 lmp.py:1625]   Expert 14 |    146 | CPU
DEBUG 01-14 20:42:33.547682.547682 lmp.py:1625]   Expert 39 |    148 | CPU
DEBUG 01-14 20:42:33.547908.547908 lmp.py:1625]   Expert 26 |    149 | CPU
DEBUG 01-14 20:42:33.547849.547849 lmp.py:1625]   Expert 50 |    152 | CPU
DEBUG 01-14 20:42:33.547552.547552 lmp.py:1625]   Expert 49 |    155 | CPU
DEBUG 01-14 20:42:33.547970.547970 lmp.py:1625]   Expert 34 |    160 | CPU
DEBUG 01-14 20:42:33.547435.547435 lmp.py:1625]   Expert 38 |    164 | CPU
DEBUG 01-14 20:42:33.547376.547376 lmp.py:1625]   Expert 24 |    167 | CPU
DEBUG 01-14 20:42:33.547079.547079 lmp.py:1625]   Expert  4 |    175 | GPU
DEBUG 01-14 20:42:33.547020.547020 lmp.py:1625]   Expert 40 |    183 | GPU
DEBUG 01-14 20:42:33.547677.547677 lmp.py:1625]   Expert 57 |    183 | GPU
DEBUG 01-14 20:42:33.547572.547572 lmp.py:1625]   Expert  0 |    186 | GPU
DEBUG 01-14 20:42:33.547798.547798 lmp.py:1625]   Expert 46 |    188 | GPU
DEBUG 01-14 20:42:33.547501.547501 lmp.py:1625]   Expert 43 |    189 | GPU
DEBUG 01-14 20:42:33.547442.547442 lmp.py:1625]   Expert 13 |    192 | GPU
DEBUG 01-14 20:42:33.547099.547099 lmp.py:1625]   Expert 63 |    192 | GPU
DEBUG 01-14 20:42:33.547471.547471 lmp.py:1625]   Expert 61 |    196 | GPU
DEBUG 01-14 20:42:33.547650.547650 lmp.py:1625]   Expert 19 |    200 | GPU
DEBUG 01-14 20:42:33.547876.547876 lmp.py:1625]   Expert 29 |    206 | GPU
DEBUG 01-14 20:42:33.547533.547533 lmp.py:1625]   Expert  5 |    211 | GPU
DEBUG 01-14 20:42:33.547520.547520 lmp.py:1625]   Expert 31 |    212 | GPU
DEBUG 01-14 20:42:33.548223.548223 lmp.py:1625]   Expert 33 |    223 | GPU
DEBUG 01-14 20:42:33.548449.548449 lmp.py:1625]   Expert 37 |    237 | GPU
DEBUG 01-14 20:42:33.548675.548675 lmp.py:1625]   Expert 16 |    244 | GPU
DEBUG 01-14 20:42:33.548094.548094 lmp.py:1625]   Expert 20 |    250 | GPU
DEBUG 01-14 20:42:33.548750.548750 lmp.py:1625]   Expert  3 |    255 | GPU
DEBUG 01-14 20:42:33.548215.548215 lmp.py:1625]   Expert 36 |    269 | GPU
DEBUG 01-14 20:42:33.548739.548739 lmp.py:1625]   Expert 15 |    280 | GPU
DEBUG 01-14 20:42:33.548157.548157 lmp.py:1625]   Expert 18 |    284 | GPU
DEBUG 01-14 20:42:33.548429.548429 lmp.py:1625]   Expert 17 |    305 | GPU
DEBUG 01-14 20:42:33.548179.548179 lmp.py:1625]   Expert 30 |    313 | GPU
DEBUG 01-14 20:42:33.548213.548213 lmp.py:1625]   Expert 55 |    317 | GPU
DEBUG 01-14 20:42:33.548247.548247 lmp.py:1625]   Expert 12 |    323 | GPU
DEBUG 01-14 20:42:33.548519.548519 lmp.py:1625]   Expert 28 |    323 | GPU
DEBUG 01-14 20:42:33.548222.548222 lmp.py:1625]   Expert 58 |    334 | GPU
DEBUG 01-14 20:42:33.548793.548793 lmp.py:1625]   Expert 25 |    356 | GPU
DEBUG 01-14 20:42:33.548257.548257 lmp.py:1625]   Expert 10 |    372 | GPU
DEBUG 01-14 20:42:33.548529.548529 lmp.py:1625]   Expert 21 |    383 | GPU
DEBUG 01-14 20:42:33.548802.548802 lmp.py:1625]   Expert 45 |    384 | GPU
DEBUG 01-14 20:42:33.548505.548505 lmp.py:1625]   Expert 42 |    592 | GPU
DEBUG 01-14 20:42:33.548446.548446 lmp.py:1626] 
DEBUG 01-14 20:42:33.548446.548446 lmp.py:1626]   CPU total tokens: 3731 (30.4%)
DEBUG 01-14 20:42:33.548149.548149 lmp.py:1627]   GPU total tokens: 8557 (69.6%)
DEBUG 01-14 20:42:33.548051.548051 cuda_h.py:19] end experts_map_get cost 0.0023751258850097656 seconds
DEBUG 01-14 20:42:33.548265.548265 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-14 20:42:33.548480.548480 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-14 20:42:33.548685.548685 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-14 20:42:33.549796.549796 cuda_h.py:19] end allocate_cuda_memory cost 0.00027751922607421875 seconds
INFO 01-14 20:42:33.549024.549024 client.py:127] Model loaded
DEBUG 01-14 20:42:33.549093.549093 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-14 20:42:33.549320.549320 cuda_h.py:10] start restore2model
DEBUG 01-14 20:42:33.549090.549090 sllm_store_c.py:27] get device uuid map
DEBUG 01-14 20:42:33.549488.549488 sllm_store_c.py:29] call client load into gpu
DEBUG 01-14 20:42:33.549397.549397 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 7a268d73-da67-4ceb-8596-6ebf0aa2f64c
DEBUG 01-14 20:42:33.550094.550094 client.py:106] call stub.LoadModelAsync
DEBUG 01-14 20:42:33.550849.550849 cuda_h.py:19] end restore2model cost 0.0008549690246582031 seconds
DEBUG 01-14 20:42:33.550720.550720 cuda_h.py:19] end sllm_worker_task cost 0.0125885009765625 seconds
INFO 01-14 20:42:33.552243.552243 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 7a268d73-da67-4ceb-8596-6ebf0aa2f64c
DEBUG 01-14 20:42:33.552192.552192 cuda_h.py:19] end load_into_gpu_async cost 0.0028514862060546875 seconds
DEBUG 01-14 20:42:33.552610.552610 cuda_h.py:10] start restore_tensors2
DEBUG 01-14 20:42:33.552708.552708 cuda_h.py:19] end restore_tensors2 cost 0.0003261566162109375 seconds
DEBUG 01-14 20:42:33.552584.552584 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.004044771194458008 seconds
DEBUG 01-14 20:42:33.552777.552777 cuda_h.py:10] start restore2model
DEBUG 01-14 20:42:33.555154.555154 cuda_h.py:19] end restore2model cost 0.0025322437286376953 seconds
DEBUG 01-14 20:42:33.555653.555653 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.0067768096923828125 seconds
DEBUG 01-14 20:42:33.555256.555256 cuda_h.py:10] start gpu_sexperts
DEBUG 01-14 20:42:33.555293.555293 cuda_h.py:19] end gpu_sexperts cost 0.0002791881561279297 seconds
DEBUG 01-14 20:42:33.555116.555116 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-14 20:42:33.555249.555249 lmp.py:1683] 
DEBUG 01-14 20:42:33.555249.555249 lmp.py:1683]   Computing 32 experts on CPU...
DEBUG 01-14 20:42:33.555277.555277 cuda_h.py:19] end cpu_experts_submit cost 5.602836608886719e-05 seconds
DEBUG 01-14 20:42:33.555358.555358 cuda_h.py:10] start experts_func_mgpu_group_pad
DEBUG 01-14 20:42:33.567581.567581 mlpmodule.py:1460] group tensors cost 0.010330677032470703 s
DEBUG 01-14 20:42:33.567674.567674 cuda_h.py:10] start move_flat_hidden2cpu
DEBUG 01-14 20:42:33.570209.570209 cuda_h.py:19] end experts_func_mgpu_group_pad cost 0.014097929000854492 seconds
DEBUG 01-14 20:42:33.571305.571305 cuda_h.py:10] start gpu_group_list
DEBUG 01-14 20:42:33.571337.571337 cuda_h.py:19] end gpu_group_list cost 0.0004494190216064453 seconds
DEBUG 01-14 20:42:33.572502.572502 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-14 20:42:33.572419.572419 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.1219253540039062e-05 seconds
DEBUG 01-14 20:42:33.572612.572612 cuda_h.py:10] start wait_experts
INFO 01-14 20:42:33.572898.572898 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 7a268d73-da67-4ceb-8596-6ebf0aa2f64c
DEBUG 01-14 20:42:33.574200.574200 cuda_h.py:19] end move_flat_hidden2cpu cost 0.006533145904541016 seconds
DEBUG 01-14 20:42:33.576692.576692 mlpmodule.py:1533] pad cost 0.0015499591827392578 s
DEBUG 01-14 20:42:33.576835.576835 mlpmodule.py:1539] create cpu tensor cost 3.743171691894531e-05 s
DEBUG 01-14 20:42:33.578287.578287 mlpmodule.py:1544] move to cpu cost 0.0019783973693847656 s
DEBUG 01-14 20:42:33.587100.587100 mlpmodule.py:1558] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-14 20:42:33.587648.587648 mlpmodule.py:1559] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-14 20:42:33.587519.587519 mlpmodule.py:1564] group_w3 first element: 0.00066375732421875
WARNING 01-14 20:42:33.588159.588159 mlpmodule.py:1574] start einsum2
DEBUG 01-14 20:42:33.605267.605267 mlpmodule.py:1584] group einsum cost 0.026827573776245117 s
DEBUG 01-14 20:42:33.606657.606657 mlpmodule.py:1593] cpy2cputensor cost 0.0007531642913818359 s
DEBUG 01-14 20:42:33.606380.606380 cuda_h.py:10] start move_outputs
DEBUG 01-14 20:42:33.608429.608429 cuda_h.py:19] end move_outputs cost 0.002422809600830078 seconds
INFO 01-14 20:42:33.609331.609331 client.py:127] Model loaded
DEBUG 01-14 20:42:33.609698.609698 cuda_h.py:19] end wait_experts cost 0.037492990493774414 seconds
DEBUG 01-14 20:42:33.609053.609053 cuda_h.py:10] start gpu_experts
DEBUG 01-14 20:42:33.610250.610250 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-14 20:42:33.613666.613666 cuda_h.py:19] end wait_cetm_experts cost 0.0028302669525146484 seconds
DEBUG 01-14 20:42:33.613831.613831 cuda_h.py:10] start gpu_group_einsum_mp_multi_list
DEBUG 01-14 20:42:33.613682.613682 cuda_h.py:10] start gpu_group_tensor
DEBUG 01-14 20:42:33.613945.613945 cuda_h.py:19] end gpu_group_tensor cost 0.0004191398620605469 seconds
DEBUG 01-14 20:42:33.614317.614317 cuda_h.py:10] start gpu_group_einsum
DEBUG 01-14 20:42:33.615466.615466 cuda_h.py:19] end gpu_group_einsum cost 0.0011882781982421875 seconds
DEBUG 01-14 20:42:33.615727.615727 cuda_h.py:10] start gpu_final_hidden_states_scatter
DEBUG 01-14 20:42:33.615903.615903 cuda_h.py:10] start all_expert_outputs_slices
DEBUG 01-14 20:42:33.616460.616460 cuda_h.py:19] end all_expert_outputs_slices cost 0.0007078647613525391 seconds
DEBUG 01-14 20:42:33.616205.616205 cuda_h.py:10] start concat_expert_out
DEBUG 01-14 20:42:33.616405.616405 cuda_h.py:19] end concat_expert_out cost 0.0001690387725830078 seconds
DEBUG 01-14 20:42:33.617238.617238 cuda_h.py:10] start index_scatter
DEBUG 01-14 20:42:33.617220.617220 cuda_h.py:19] end index_scatter cost 0.0001430511474609375 seconds
DEBUG 01-14 20:42:33.617316.617316 cuda_h.py:19] end gpu_final_hidden_states_scatter cost 0.0016584396362304688 seconds
DEBUG 01-14 20:42:33.617514.617514 cuda_h.py:19] end gpu_experts cost 0.007517337799072266 seconds
DEBUG 01-14 20:42:33.617662.617662 cuda_h.py:10] start all_expert_weight_slices
DEBUG 01-14 20:42:33.620548.620548 cuda_h.py:19] end all_expert_weight_slices cost 0.0022547245025634766 seconds
DEBUG 01-14 20:42:33.620499.620499 cuda_h.py:10] start cpuoutputsdeal
DEBUG 01-14 20:42:33.621441.621441 cuda_h.py:10] start index_scatter
DEBUG 01-14 20:42:33.621443.621443 cuda_h.py:19] end index_scatter cost 0.00011968612670898438 seconds
DEBUG 01-14 20:42:33.621539.621539 cuda_h.py:19] end cpuoutputsdeal cost 0.0013167858123779297 seconds
DEBUG 01-14 20:42:33.621115.621115 cuda_h.py:19] end layer_moe_generate_mp_l_22 cost 0.07644534111022949 seconds
DEBUG 01-14 20:42:33.622979.622979 cuda_h.py:19] end prefill_layer cost 0.08480072021484375 seconds
DEBUG 01-14 20:42:33.622286.622286 lmp.py:1551] -------------------------------- end prefill layer 21 --------------------------------
DEBUG 01-14 20:42:33.622003.622003 cuda_h.py:10] start prefill_layer
DEBUG 01-14 20:42:33.622673.622673 lmp.py:1494] -------------------------------- start prefill layer 22 --------------------------------
DEBUG 01-14 20:42:33.622390.622390 cuda_h.py:10] start start_load_qkvogn_s_weight_l_23
DEBUG 01-14 20:42:33.622967.622967 cuda_h.py:10] start start_load_qkvogn_s_weight_l_23
DEBUG 01-14 20:42:33.622837.622837 cuda_h.py:19] end start_load_qkvogn_s_weight_l_23 cost 3.719329833984375e-05 seconds
DEBUG 01-14 20:42:33.622322.622322 cuda_h.py:19] end start_load_qkvogn_s_weight_l_23 cost 8.726119995117188e-05 seconds
DEBUG 01-14 20:42:33.622793.622793 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-14 20:42:33.622895.622895 cuda_h.py:10] start sllm_worker_task
DEBUG 01-14 20:42:33.622031.622031 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-14 20:42:33.622490.622490 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-14 20:42:33.625411.625411 cuda_h.py:19] end allocate_cuda_memory cost 0.0027234554290771484 seconds
DEBUG 01-14 20:42:33.625868.625868 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-14 20:42:33.625249.625249 sllm_store_c.py:27] get device uuid map
DEBUG 01-14 20:42:33.626517.626517 sllm_store_c.py:29] call client load into gpu
DEBUG 01-14 20:42:33.626386.626386 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, cb98993a-086d-4959-974d-0520117e6316
DEBUG 01-14 20:42:33.626117.626117 client.py:106] call stub.LoadModelAsync
DEBUG 01-14 20:42:33.626051.626051 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-14 20:42:33.626456.626456 mlpmodule.py:1367]  experts func einsum cost 0.06993222236633301 s
DEBUG 01-14 20:42:33.627471.627471 cuda_h.py:10] start self_attn
INFO 01-14 20:42:33.627716.627716 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, cb98993a-086d-4959-974d-0520117e6316
DEBUG 01-14 20:42:33.627175.627175 cuda_h.py:19] end load_into_gpu_async cost 0.0017473697662353516 seconds
DEBUG 01-14 20:42:33.627354.627354 cuda_h.py:10] start restore_tensors2
DEBUG 01-14 20:42:33.627344.627344 cuda_h.py:19] end restore_tensors2 cost 7.200241088867188e-05 seconds
DEBUG 01-14 20:42:33.627862.627862 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.005002021789550781 seconds
INFO 01-14 20:42:33.627195.627195 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, cb98993a-086d-4959-974d-0520117e6316
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-14 20:42:33.631510.631510 cuda_h.py:19] end self_attn cost 0.004197597503662109 seconds
DEBUG 01-14 20:42:33.631934.631934 cuda_h.py:19] end iln_self_attn_paln cost 0.009297609329223633 seconds
DEBUG 01-14 20:42:33.631777.631777 cuda_h.py:10] start layer_moe_generate_mp_l_23
DEBUG 01-14 20:42:33.632778.632778 cuda_h.py:10] start gate
DEBUG 01-14 20:42:33.632940.632940 cuda_h.py:19] end gate cost 0.0006461143493652344 seconds
DEBUG 01-14 20:42:33.632962.632962 cuda_h.py:10] start experts_map_get
DEBUG 01-14 20:42:33.633813.633813 lmp.py:1615] 
DEBUG 01-14 20:42:33.633813.633813 lmp.py:1615] Expert Token Distribution & Device Allocation:
DEBUG 01-14 20:42:33.633523.633523 lmp.py:1616]   Total experts: 64
DEBUG 01-14 20:42:33.633365.633365 lmp.py:1617]   CPU experts: 32 (50%)
DEBUG 01-14 20:42:33.633345.633345 lmp.py:1618]   GPU experts: 32 (50%)
DEBUG 01-14 20:42:33.633704.633704 lmp.py:1619] 
DEBUG 01-14 20:42:33.633704.633704 lmp.py:1619]   Expert ID | Tokens | Device
DEBUG 01-14 20:42:33.633823.633823 lmp.py:1620]   -----------------------------------
DEBUG 01-14 20:42:33.633135.633135 lmp.py:1625]   Expert 25 |     12 | CPU
DEBUG 01-14 20:42:33.633255.633255 lmp.py:1625]   Expert 45 |     33 | CPU
DEBUG 01-14 20:42:33.633660.633660 lmp.py:1625]   Expert 48 |     38 | CPU
DEBUG 01-14 20:42:33.633541.633541 lmp.py:1625]   Expert  9 |     64 | CPU
DEBUG 01-14 20:42:33.633707.633707 lmp.py:1625]   Expert 43 |     68 | CPU
DEBUG 01-14 20:42:33.633873.633873 lmp.py:1625]   Expert 54 |     77 | CPU
DEBUG 01-14 20:42:33.633662.633662 lmp.py:1625]   Expert 47 |     87 | CPU
DEBUG 01-14 20:42:33.633974.633974 lmp.py:1625]   Expert  6 |     88 | CPU
DEBUG 01-14 20:42:33.633809.633809 lmp.py:1625]   Expert  0 |     91 | CPU
DEBUG 01-14 20:42:33.633167.633167 lmp.py:1625]   Expert 50 |     93 | CPU
DEBUG 01-14 20:42:33.633002.633002 lmp.py:1625]   Expert  1 |     95 | CPU
DEBUG 01-14 20:42:33.633122.633122 lmp.py:1625]   Expert 20 |     97 | CPU
DEBUG 01-14 20:42:33.633242.633242 lmp.py:1625]   Expert 15 |     99 | CPU
DEBUG 01-14 20:42:33.633362.633362 lmp.py:1625]   Expert 13 |    102 | CPU
DEBUG 01-14 20:42:33.633435.633435 lmp.py:1625]   Expert 62 |    104 | CPU
DEBUG 01-14 20:42:33.633509.633509 lmp.py:1625]   Expert 36 |    109 | CPU
DEBUG 01-14 20:42:33.633867.633867 lmp.py:1625]   Expert 61 |    115 | CPU
DEBUG 01-14 20:42:33.633987.633987 lmp.py:1625]   Expert 21 |    116 | CPU
DEBUG 01-14 20:42:33.633107.633107 lmp.py:1625]   Expert 57 |    116 | CPU
DEBUG 01-14 20:42:33.633226.633226 lmp.py:1625]   Expert 37 |    117 | CPU
DEBUG 01-14 20:42:33.633108.633108 lmp.py:1625]   Expert 46 |    118 | CPU
DEBUG 01-14 20:42:33.633989.633989 lmp.py:1625]   Expert 38 |    126 | CPU
DEBUG 01-14 20:42:33.633348.633348 lmp.py:1625]   Expert  7 |    128 | CPU
DEBUG 01-14 20:42:33.633467.633467 lmp.py:1625]   Expert 14 |    143 | CPU
DEBUG 01-14 20:42:33.633349.633349 lmp.py:1625]   Expert 24 |    144 | CPU
DEBUG 01-14 20:42:33.633992.633992 lmp.py:1625]   Expert 42 |    153 | CPU
DEBUG 01-14 20:42:33.633396.633396 lmp.py:1625]   Expert 26 |    154 | CPU
DEBUG 01-14 20:42:33.633516.633516 lmp.py:1625]   Expert 31 |    155 | CPU
DEBUG 01-14 20:42:33.633636.633636 lmp.py:1625]   Expert 10 |    156 | CPU
DEBUG 01-14 20:42:33.633279.633279 lmp.py:1625]   Expert  2 |    159 | CPU
DEBUG 01-14 20:42:33.633399.633399 lmp.py:1625]   Expert 11 |    160 | CPU
DEBUG 01-14 20:42:33.633757.633757 lmp.py:1625]   Expert 44 |    163 | CPU
DEBUG 01-14 20:42:33.633400.633400 lmp.py:1625]   Expert 52 |    172 | GPU
DEBUG 01-14 20:42:33.633281.633281 lmp.py:1625]   Expert 28 |    173 | GPU
DEBUG 01-14 20:42:33.633686.633686 lmp.py:1625]   Expert  3 |    177 | GPU
DEBUG 01-14 20:42:33.633567.633567 lmp.py:1625]   Expert 32 |    180 | GPU
DEBUG 01-14 20:42:33.633210.633210 lmp.py:1625]   Expert 35 |    181 | GPU
DEBUG 01-14 20:42:33.633853.633853 lmp.py:1625]   Expert 12 |    188 | GPU
DEBUG 01-14 20:42:33.633735.633735 lmp.py:1625]   Expert 19 |    191 | GPU
DEBUG 01-14 20:42:33.633093.633093 lmp.py:1625]   Expert 56 |    202 | GPU
DEBUG 01-14 20:42:33.633213.633213 lmp.py:1625]   Expert  8 |    203 | GPU
DEBUG 01-14 20:42:33.633856.633856 lmp.py:1625]   Expert 60 |    211 | GPU
DEBUG 01-14 20:42:33.633499.633499 lmp.py:1625]   Expert 41 |    215 | GPU
DEBUG 01-14 20:42:33.633380.633380 lmp.py:1625]   Expert 59 |    220 | GPU
DEBUG 01-14 20:42:33.634261.634261 lmp.py:1625]   Expert  4 |    223 | GPU
DEBUG 01-14 20:42:33.634904.634904 lmp.py:1625]   Expert 16 |    231 | GPU
DEBUG 01-14 20:42:33.634786.634786 lmp.py:1625]   Expert 40 |    236 | GPU
DEBUG 01-14 20:42:33.634667.634667 lmp.py:1625]   Expert 23 |    242 | GPU
DEBUG 01-14 20:42:33.634264.634264 lmp.py:1625]   Expert 55 |    243 | GPU
DEBUG 01-14 20:42:33.634860.634860 lmp.py:1625]   Expert 51 |    251 | GPU
DEBUG 01-14 20:42:33.634742.634742 lmp.py:1625]   Expert 58 |    254 | GPU
DEBUG 01-14 20:42:33.634385.634385 lmp.py:1625]   Expert 53 |    256 | GPU
DEBUG 01-14 20:42:33.634789.634789 lmp.py:1625]   Expert 49 |    259 | GPU
DEBUG 01-14 20:42:33.634671.634671 lmp.py:1625]   Expert 18 |    273 | GPU
DEBUG 01-14 20:42:33.634552.634552 lmp.py:1625]   Expert 34 |    277 | GPU
DEBUG 01-14 20:42:33.634910.634910 lmp.py:1625]   Expert 29 |    286 | GPU
DEBUG 01-14 20:42:33.634507.634507 lmp.py:1625]   Expert 63 |    298 | GPU
DEBUG 01-14 20:42:33.634627.634627 lmp.py:1625]   Expert 27 |    375 | GPU
DEBUG 01-14 20:42:33.634508.634508 lmp.py:1625]   Expert 39 |    387 | GPU
DEBUG 01-14 20:42:33.634151.634151 lmp.py:1625]   Expert 33 |    392 | GPU
DEBUG 01-14 20:42:33.634271.634271 lmp.py:1625]   Expert 22 |    415 | GPU
DEBUG 01-14 20:42:33.634914.634914 lmp.py:1625]   Expert 17 |    424 | GPU
DEBUG 01-14 20:42:33.634319.634319 lmp.py:1625]   Expert 30 |    482 | GPU
DEBUG 01-14 20:42:33.634200.634200 lmp.py:1625]   Expert  5 |    691 | GPU
DEBUG 01-14 20:42:33.634227.634227 lmp.py:1626] 
DEBUG 01-14 20:42:33.634227.634227 lmp.py:1626]   CPU total tokens: 3480 (28.3%)
DEBUG 01-14 20:42:33.634777.634777 lmp.py:1627]   GPU total tokens: 8808 (71.7%)
DEBUG 01-14 20:42:33.634904.634904 cuda_h.py:19] end experts_map_get cost 0.0016126632690429688 seconds
DEBUG 01-14 20:42:33.634184.634184 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-14 20:42:33.634081.634081 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-14 20:42:33.634900.634900 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-14 20:42:33.634970.634970 cuda_h.py:19] end allocate_cuda_memory cost 0.00026297569274902344 seconds
DEBUG 01-14 20:42:33.635005.635005 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-14 20:42:33.635284.635284 sllm_store_c.py:27] get device uuid map
DEBUG 01-14 20:42:33.635378.635378 sllm_store_c.py:29] call client load into gpu
DEBUG 01-14 20:42:33.635981.635981 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 63216063-1472-476a-999b-193dc229678c
DEBUG 01-14 20:42:33.681542.681542 client.py:106] call stub.LoadModelAsync
INFO 01-14 20:42:33.682784.682784 client.py:127] Model loaded
DEBUG 01-14 20:42:33.682378.682378 cuda_h.py:10] start restore2model
DEBUG 01-14 20:42:33.683507.683507 cuda_h.py:19] end restore2model cost 0.0009763240814208984 seconds
DEBUG 01-14 20:42:33.683332.683332 cuda_h.py:19] end sllm_worker_task cost 0.060614585876464844 seconds
INFO 01-14 20:42:33.683832.683832 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 63216063-1472-476a-999b-193dc229678c
DEBUG 01-14 20:42:33.683742.683742 cuda_h.py:19] end load_into_gpu_async cost 0.04867744445800781 seconds
DEBUG 01-14 20:42:33.683829.683829 cuda_h.py:10] start restore_tensors2
DEBUG 01-14 20:42:33.684299.684299 cuda_h.py:19] end restore_tensors2 cost 0.00035500526428222656 seconds
DEBUG 01-14 20:42:33.684367.684367 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.04965972900390625 seconds
DEBUG 01-14 20:42:33.684421.684421 cuda_h.py:10] start restore2model
DEBUG 01-14 20:42:33.686600.686600 cuda_h.py:19] end restore2model cost 0.0025603771209716797 seconds
DEBUG 01-14 20:42:33.686907.686907 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.0523989200592041 seconds
DEBUG 01-14 20:42:33.686556.686556 cuda_h.py:10] start gpu_sexperts
DEBUG 01-14 20:42:33.687502.687502 cuda_h.py:19] end gpu_sexperts cost 0.00030159950256347656 seconds
DEBUG 01-14 20:42:33.687040.687040 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-14 20:42:33.687650.687650 lmp.py:1683] 
DEBUG 01-14 20:42:33.687650.687650 lmp.py:1683]   Computing 32 experts on CPU...
DEBUG 01-14 20:42:33.687632.687632 cuda_h.py:19] end cpu_experts_submit cost 5.745887756347656e-05 seconds
DEBUG 01-14 20:42:33.687997.687997 cuda_h.py:10] start experts_func_mgpu_group_pad
DEBUG 01-14 20:42:33.706236.706236 mlpmodule.py:1460] group tensors cost 0.018327713012695312 s
DEBUG 01-14 20:42:33.707610.707610 cuda_h.py:10] start move_flat_hidden2cpu
DEBUG 01-14 20:42:33.709937.709937 cuda_h.py:19] end experts_func_mgpu_group_pad cost 0.02225494384765625 seconds
DEBUG 01-14 20:42:33.711611.711611 cuda_h.py:10] start gpu_group_list
DEBUG 01-14 20:42:33.711216.711216 cuda_h.py:19] end gpu_group_list cost 0.0004115104675292969 seconds
DEBUG 01-14 20:42:33.711493.711493 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-14 20:42:33.711456.711456 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.1457672119140625e-05 seconds
DEBUG 01-14 20:42:33.711742.711742 cuda_h.py:10] start wait_experts
INFO 01-14 20:42:33.711598.711598 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 63216063-1472-476a-999b-193dc229678c
DEBUG 01-14 20:42:33.716807.716807 cuda_h.py:19] end move_flat_hidden2cpu cost 0.009140968322753906 seconds
DEBUG 01-14 20:42:33.718419.718419 mlpmodule.py:1533] pad cost 0.0015368461608886719 s
DEBUG 01-14 20:42:33.718840.718840 mlpmodule.py:1539] create cpu tensor cost 3.552436828613281e-05 s
DEBUG 01-14 20:42:33.720840.720840 mlpmodule.py:1544] move to cpu cost 0.0019295215606689453 s
DEBUG 01-14 20:42:33.731425.731425 mlpmodule.py:1558] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-14 20:42:33.732172.732172 mlpmodule.py:1559] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-14 20:42:33.732725.732725 mlpmodule.py:1564] group_w3 first element: -0.018798828125
WARNING 01-14 20:42:33.732696.732696 mlpmodule.py:1574] start einsum2
INFO 01-14 20:42:33.734993.734993 client.py:127] Model loaded
DEBUG 01-14 20:42:33.735468.735468 cuda_h.py:19] end wait_experts cost 0.023372173309326172 seconds
DEBUG 01-14 20:42:33.735285.735285 cuda_h.py:10] start gpu_experts
DEBUG 01-14 20:42:33.735467.735467 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-14 20:42:33.749549.749549 mlpmodule.py:1584] group einsum cost 0.028817415237426758 s
DEBUG 01-14 20:42:33.749472.749472 mlpmodule.py:1593] cpy2cputensor cost 0.0006575584411621094 s
DEBUG 01-14 20:42:33.749817.749817 cuda_h.py:10] start move_outputs
DEBUG 01-14 20:42:33.751809.751809 cuda_h.py:19] end move_outputs cost 0.0018951892852783203 seconds
DEBUG 01-14 20:42:33.755095.755095 cuda_h.py:19] end wait_cetm_experts cost 0.02001047134399414 seconds
DEBUG 01-14 20:42:33.755482.755482 cuda_h.py:10] start gpu_group_einsum_mp_multi_list
DEBUG 01-14 20:42:33.756413.756413 cuda_h.py:10] start gpu_group_tensor
DEBUG 01-14 20:42:33.756352.756352 cuda_h.py:19] end gpu_group_tensor cost 0.00045609474182128906 seconds
DEBUG 01-14 20:42:33.756891.756891 cuda_h.py:10] start gpu_group_einsum
DEBUG 01-14 20:42:33.757439.757439 cuda_h.py:19] end gpu_group_einsum cost 0.0010209083557128906 seconds
DEBUG 01-14 20:42:33.758461.758461 cuda_h.py:10] start gpu_final_hidden_states_scatter
DEBUG 01-14 20:42:33.758300.758300 cuda_h.py:10] start all_expert_outputs_slices
DEBUG 01-14 20:42:33.759893.759893 cuda_h.py:19] end all_expert_outputs_slices cost 0.0006327629089355469 seconds
DEBUG 01-14 20:42:33.759777.759777 cuda_h.py:10] start concat_expert_out
DEBUG 01-14 20:42:33.759698.759698 cuda_h.py:19] end concat_expert_out cost 0.00014066696166992188 seconds
DEBUG 01-14 20:42:33.759048.759048 cuda_h.py:10] start index_scatter
DEBUG 01-14 20:42:33.759691.759691 cuda_h.py:19] end index_scatter cost 0.00013971328735351562 seconds
DEBUG 01-14 20:42:33.759973.759973 cuda_h.py:19] end gpu_final_hidden_states_scatter cost 0.001535654067993164 seconds
DEBUG 01-14 20:42:33.760740.760740 cuda_h.py:19] end gpu_experts cost 0.024602651596069336 seconds
DEBUG 01-14 20:42:33.760981.760981 cuda_h.py:10] start all_expert_weight_slices
DEBUG 01-14 20:42:33.762008.762008 cuda_h.py:19] end all_expert_weight_slices cost 0.0022895336151123047 seconds
DEBUG 01-14 20:42:33.762965.762965 cuda_h.py:10] start cpuoutputsdeal
DEBUG 01-14 20:42:33.763959.763959 cuda_h.py:10] start index_scatter
DEBUG 01-14 20:42:33.763588.763588 cuda_h.py:19] end index_scatter cost 7.724761962890625e-05 seconds
DEBUG 01-14 20:42:33.763100.763100 cuda_h.py:19] end cpuoutputsdeal cost 0.0011875629425048828 seconds
DEBUG 01-14 20:42:33.763885.763885 cuda_h.py:19] end layer_moe_generate_mp_l_23 cost 0.1319577693939209 seconds
DEBUG 01-14 20:42:33.764359.764359 cuda_h.py:19] end prefill_layer cost 0.1421058177947998 seconds
DEBUG 01-14 20:42:33.764110.764110 lmp.py:1551] -------------------------------- end prefill layer 22 --------------------------------
DEBUG 01-14 20:42:33.764463.764463 cuda_h.py:10] start prefill_layer
DEBUG 01-14 20:42:33.764855.764855 lmp.py:1494] -------------------------------- start prefill layer 23 --------------------------------
DEBUG 01-14 20:42:33.764578.764578 cuda_h.py:10] start start_load_qkvogn_s_weight_l_24
DEBUG 01-14 20:42:33.764639.764639 cuda_h.py:10] start start_load_qkvogn_s_weight_l_24
DEBUG 01-14 20:42:33.764848.764848 cuda_h.py:19] end start_load_qkvogn_s_weight_l_24 cost 4.0531158447265625e-05 seconds
DEBUG 01-14 20:42:33.764439.764439 cuda_h.py:19] end start_load_qkvogn_s_weight_l_24 cost 9.369850158691406e-05 seconds
DEBUG 01-14 20:42:33.764109.764109 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-14 20:42:33.765456.765456 cuda_h.py:10] start sllm_worker_task
DEBUG 01-14 20:42:33.765969.765969 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-14 20:42:33.765083.765083 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-14 20:42:33.766272.766272 cuda_h.py:19] end allocate_cuda_memory cost 0.0016429424285888672 seconds
DEBUG 01-14 20:42:33.766473.766473 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-14 20:42:33.766064.766064 sllm_store_c.py:27] get device uuid map
DEBUG 01-14 20:42:33.767102.767102 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-14 20:42:33.767920.767920 sllm_store_c.py:29] call client load into gpu
DEBUG 01-14 20:42:33.767779.767779 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 8fb007db-de9f-4a5d-b37b-8f96c852744f
DEBUG 01-14 20:42:33.767663.767663 client.py:106] call stub.LoadModelAsync
DEBUG 01-14 20:42:33.767630.767630 mlpmodule.py:1367]  experts func einsum cost 0.07958078384399414 s
DEBUG 01-14 20:42:33.768133.768133 cuda_h.py:10] start self_attn
INFO 01-14 20:42:33.769715.769715 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 8fb007db-de9f-4a5d-b37b-8f96c852744f
DEBUG 01-14 20:42:33.769135.769135 cuda_h.py:19] end load_into_gpu_async cost 0.0022978782653808594 seconds
DEBUG 01-14 20:42:33.769122.769122 cuda_h.py:10] start restore_tensors2
DEBUG 01-14 20:42:33.769212.769212 cuda_h.py:19] end restore_tensors2 cost 7.295608520507812e-05 seconds
DEBUG 01-14 20:42:33.769537.769537 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0042874813079833984 seconds
INFO 01-14 20:42:33.769626.769626 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 8fb007db-de9f-4a5d-b37b-8f96c852744f
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-14 20:42:33.772248.772248 cuda_h.py:19] end self_attn cost 0.004096508026123047 seconds
DEBUG 01-14 20:42:33.772941.772941 cuda_h.py:19] end iln_self_attn_paln cost 0.007795095443725586 seconds
DEBUG 01-14 20:42:33.772362.772362 cuda_h.py:10] start layer_moe_generate_mp_l_24
DEBUG 01-14 20:42:33.772688.772688 cuda_h.py:10] start gate
DEBUG 01-14 20:42:33.774128.774128 cuda_h.py:19] end gate cost 0.0010089874267578125 seconds
DEBUG 01-14 20:42:33.774957.774957 cuda_h.py:10] start experts_map_get
DEBUG 01-14 20:42:33.774617.774617 lmp.py:1615] 
DEBUG 01-14 20:42:33.774617.774617 lmp.py:1615] Expert Token Distribution & Device Allocation:
DEBUG 01-14 20:42:33.774850.774850 lmp.py:1616]   Total experts: 64
DEBUG 01-14 20:42:33.774738.774738 lmp.py:1617]   CPU experts: 32 (50%)
DEBUG 01-14 20:42:33.774003.774003 lmp.py:1618]   GPU experts: 32 (50%)
DEBUG 01-14 20:42:33.774885.774885 lmp.py:1619] 
DEBUG 01-14 20:42:33.774885.774885 lmp.py:1619]   Expert ID | Tokens | Device
DEBUG 01-14 20:42:33.774528.774528 lmp.py:1620]   -----------------------------------
DEBUG 01-14 20:42:33.774078.774078 lmp.py:1625]   Expert  5 |     11 | CPU
DEBUG 01-14 20:42:33.774721.774721 lmp.py:1625]   Expert 56 |     44 | CPU
DEBUG 01-14 20:42:33.774649.774649 lmp.py:1625]   Expert 27 |     95 | CPU
DEBUG 01-14 20:42:33.774861.774861 lmp.py:1625]   Expert 40 |     95 | CPU
DEBUG 01-14 20:42:33.774789.774789 lmp.py:1625]   Expert 16 |     96 | CPU
DEBUG 01-14 20:42:33.774955.774955 lmp.py:1625]   Expert 17 |     97 | CPU
DEBUG 01-14 20:42:33.774644.774644 lmp.py:1625]   Expert 53 |     99 | CPU
DEBUG 01-14 20:42:33.774334.774334 lmp.py:1625]   Expert 47 |    101 | CPU
DEBUG 01-14 20:42:33.774023.774023 lmp.py:1625]   Expert  7 |    109 | CPU
DEBUG 01-14 20:42:33.774474.774474 lmp.py:1625]   Expert 51 |    109 | CPU
DEBUG 01-14 20:42:33.774925.774925 lmp.py:1625]   Expert 28 |    110 | CPU
DEBUG 01-14 20:42:33.774614.774614 lmp.py:1625]   Expert 49 |    116 | CPU
DEBUG 01-14 20:42:33.774588.774588 lmp.py:1625]   Expert 37 |    118 | CPU
DEBUG 01-14 20:42:33.774754.774754 lmp.py:1625]   Expert 63 |    121 | CPU
DEBUG 01-14 20:42:33.774159.774159 lmp.py:1625]   Expert 58 |    127 | CPU
DEBUG 01-14 20:42:33.774848.774848 lmp.py:1625]   Expert 38 |    135 | CPU
DEBUG 01-14 20:42:33.774299.774299 lmp.py:1625]   Expert 57 |    136 | CPU
DEBUG 01-14 20:42:33.774750.774750 lmp.py:1625]   Expert 14 |    146 | CPU
DEBUG 01-14 20:42:33.774724.774724 lmp.py:1625]   Expert 39 |    146 | CPU
DEBUG 01-14 20:42:33.774413.774413 lmp.py:1625]   Expert  1 |    152 | CPU
DEBUG 01-14 20:42:33.774626.774626 lmp.py:1625]   Expert 11 |    156 | CPU
DEBUG 01-14 20:42:33.774600.774600 lmp.py:1625]   Expert 62 |    158 | CPU
DEBUG 01-14 20:42:33.774527.774527 lmp.py:1625]   Expert 12 |    159 | CPU
DEBUG 01-14 20:42:33.774693.774693 lmp.py:1625]   Expert 52 |    163 | CPU
DEBUG 01-14 20:42:33.774144.774144 lmp.py:1625]   Expert 21 |    164 | CPU
DEBUG 01-14 20:42:33.774595.774595 lmp.py:1625]   Expert 25 |    164 | CPU
DEBUG 01-14 20:42:33.774331.774331 lmp.py:1625]   Expert 23 |    165 | CPU
DEBUG 01-14 20:42:33.774305.774305 lmp.py:1625]   Expert 33 |    166 | CPU
DEBUG 01-14 20:42:33.774756.774756 lmp.py:1625]   Expert 30 |    169 | CPU
DEBUG 01-14 20:42:33.774637.774637 lmp.py:1625]   Expert 45 |    169 | CPU
DEBUG 01-14 20:42:33.774280.774280 lmp.py:1625]   Expert  6 |    173 | CPU
DEBUG 01-14 20:42:33.775923.775923 lmp.py:1625]   Expert 55 |    179 | CPU
DEBUG 01-14 20:42:33.775328.775328 lmp.py:1625]   Expert 36 |    184 | GPU
DEBUG 01-14 20:42:33.775732.775732 lmp.py:1625]   Expert 31 |    186 | GPU
DEBUG 01-14 20:42:33.775137.775137 lmp.py:1625]   Expert 60 |    186 | GPU
DEBUG 01-14 20:42:33.775541.775541 lmp.py:1625]   Expert  9 |    190 | GPU
DEBUG 01-14 20:42:33.775708.775708 lmp.py:1625]   Expert  3 |    199 | GPU
DEBUG 01-14 20:42:33.775874.775874 lmp.py:1625]   Expert 44 |    199 | GPU
DEBUG 01-14 20:42:33.775040.775040 lmp.py:1625]   Expert 19 |    201 | GPU
DEBUG 01-14 20:42:33.775444.775444 lmp.py:1625]   Expert  4 |    203 | GPU
DEBUG 01-14 20:42:33.775087.775087 lmp.py:1625]   Expert 34 |    214 | GPU
DEBUG 01-14 20:42:33.775492.775492 lmp.py:1625]   Expert 22 |    222 | GPU
DEBUG 01-14 20:42:33.775420.775420 lmp.py:1625]   Expert  0 |    229 | GPU
DEBUG 01-14 20:42:33.775824.775824 lmp.py:1625]   Expert 26 |    229 | GPU
DEBUG 01-14 20:42:33.775990.775990 lmp.py:1625]   Expert 50 |    229 | GPU
DEBUG 01-14 20:42:33.775918.775918 lmp.py:1625]   Expert 43 |    230 | GPU
DEBUG 01-14 20:42:33.775323.775323 lmp.py:1625]   Expert 41 |    231 | GPU
DEBUG 01-14 20:42:33.775012.775012 lmp.py:1625]   Expert 59 |    235 | GPU
DEBUG 01-14 20:42:33.775416.775416 lmp.py:1625]   Expert 13 |    238 | GPU
DEBUG 01-14 20:42:33.775583.775583 lmp.py:1625]   Expert 18 |    245 | GPU
DEBUG 01-14 20:42:33.775749.775749 lmp.py:1625]   Expert 42 |    248 | GPU
DEBUG 01-14 20:42:33.775915.775915 lmp.py:1625]   Expert 54 |    256 | GPU
DEBUG 01-14 20:42:33.775796.775796 lmp.py:1625]   Expert 61 |    256 | GPU
DEBUG 01-14 20:42:33.775201.775201 lmp.py:1625]   Expert 20 |    258 | GPU
DEBUG 01-14 20:42:33.775605.775605 lmp.py:1625]   Expert 24 |    260 | GPU
DEBUG 01-14 20:42:33.775771.775771 lmp.py:1625]   Expert 15 |    261 | GPU
DEBUG 01-14 20:42:33.775938.775938 lmp.py:1625]   Expert 35 |    272 | GPU
DEBUG 01-14 20:42:33.775865.775865 lmp.py:1625]   Expert 29 |    281 | GPU
DEBUG 01-14 20:42:33.775793.775793 lmp.py:1625]   Expert 32 |    289 | GPU
DEBUG 01-14 20:42:33.775198.775198 lmp.py:1625]   Expert 10 |    292 | GPU
DEBUG 01-14 20:42:33.775317.775317 lmp.py:1625]   Expert  8 |    345 | GPU
DEBUG 01-14 20:42:33.775914.775914 lmp.py:1625]   Expert  2 |    351 | GPU
DEBUG 01-14 20:42:33.775557.775557 lmp.py:1625]   Expert 46 |    454 | GPU
DEBUG 01-14 20:42:33.775723.775723 lmp.py:1625]   Expert 48 |    467 | GPU
DEBUG 01-14 20:42:33.775605.775605 lmp.py:1626] 
DEBUG 01-14 20:42:33.775605.775605 lmp.py:1626]   CPU total tokens: 4148 (33.8%)
DEBUG 01-14 20:42:33.775440.775440 lmp.py:1627]   GPU total tokens: 8140 (66.2%)
DEBUG 01-14 20:42:33.775089.775089 cuda_h.py:19] end experts_map_get cost 0.001542806625366211 seconds
DEBUG 01-14 20:42:33.775701.775701 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-14 20:42:33.775451.775451 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-14 20:42:33.775278.775278 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-14 20:42:33.776883.776883 cuda_h.py:19] end allocate_cuda_memory cost 0.0008327960968017578 seconds
DEBUG 01-14 20:42:33.776316.776316 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-14 20:42:33.776410.776410 sllm_store_c.py:27] get device uuid map
DEBUG 01-14 20:42:33.776265.776265 sllm_store_c.py:29] call client load into gpu
DEBUG 01-14 20:42:33.776630.776630 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 56ea1ec3-75f8-4da8-8bc9-eaedee0c04b1
DEBUG 01-14 20:42:33.777617.777617 client.py:106] call stub.LoadModelAsync
INFO 01-14 20:42:33.777569.777569 client.py:127] Model loaded
DEBUG 01-14 20:42:33.777067.777067 cuda_h.py:10] start restore2model
DEBUG 01-14 20:42:33.777750.777750 cuda_h.py:19] end restore2model cost 0.0003631114959716797 seconds
DEBUG 01-14 20:42:33.777996.777996 cuda_h.py:19] end sllm_worker_task cost 0.012881994247436523 seconds
INFO 01-14 20:42:33.779591.779591 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 56ea1ec3-75f8-4da8-8bc9-eaedee0c04b1
DEBUG 01-14 20:42:33.779864.779864 cuda_h.py:19] end load_into_gpu_async cost 0.0022988319396972656 seconds
DEBUG 01-14 20:42:33.779044.779044 cuda_h.py:10] start restore_tensors2
DEBUG 01-14 20:42:33.779188.779188 cuda_h.py:19] end restore_tensors2 cost 0.00032591819763183594 seconds
DEBUG 01-14 20:42:33.779302.779302 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0038347244262695312 seconds
DEBUG 01-14 20:42:33.779403.779403 cuda_h.py:10] start restore2model
DEBUG 01-14 20:42:33.782750.782750 cuda_h.py:19] end restore2model cost 0.0026137828826904297 seconds
DEBUG 01-14 20:42:33.782348.782348 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.006627798080444336 seconds
DEBUG 01-14 20:42:33.782428.782428 cuda_h.py:10] start gpu_sexperts
DEBUG 01-14 20:42:33.782941.782941 cuda_h.py:19] end gpu_sexperts cost 0.00027751922607421875 seconds
DEBUG 01-14 20:42:33.782479.782479 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-14 20:42:33.782851.782851 lmp.py:1683] 
DEBUG 01-14 20:42:33.782851.782851 lmp.py:1683]   Computing 32 experts on CPU...
DEBUG 01-14 20:42:33.782025.782025 cuda_h.py:19] end cpu_experts_submit cost 5.7697296142578125e-05 seconds
DEBUG 01-14 20:42:33.782059.782059 cuda_h.py:10] start experts_func_mgpu_group_pad
DEBUG 01-14 20:42:33.792180.792180 mlpmodule.py:1460] group tensors cost 0.009656190872192383 s
DEBUG 01-14 20:42:33.793052.793052 cuda_h.py:10] start move_flat_hidden2cpu
DEBUG 01-14 20:42:33.798420.798420 cuda_h.py:19] end experts_func_mgpu_group_pad cost 0.015435457229614258 seconds
DEBUG 01-14 20:42:33.800968.800968 cuda_h.py:19] end move_flat_hidden2cpu cost 0.006894826889038086 seconds
DEBUG 01-14 20:42:33.801153.801153 cuda_h.py:10] start gpu_group_list
DEBUG 01-14 20:42:33.802417.802417 cuda_h.py:19] end gpu_group_list cost 0.0009534358978271484 seconds
DEBUG 01-14 20:42:33.802728.802728 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-14 20:42:33.802244.802244 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 3.814697265625e-05 seconds
DEBUG 01-14 20:42:33.803678.803678 cuda_h.py:10] start wait_experts
INFO 01-14 20:42:33.803694.803694 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 56ea1ec3-75f8-4da8-8bc9-eaedee0c04b1
DEBUG 01-14 20:42:33.804818.804818 mlpmodule.py:1533] pad cost 0.003707408905029297 s
DEBUG 01-14 20:42:33.804034.804034 mlpmodule.py:1539] create cpu tensor cost 3.790855407714844e-05 s
DEBUG 01-14 20:42:33.806808.806808 mlpmodule.py:1544] move to cpu cost 0.0021123886108398438 s
DEBUG 01-14 20:42:33.816232.816232 mlpmodule.py:1558] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-14 20:42:33.816384.816384 mlpmodule.py:1559] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-14 20:42:33.816679.816679 mlpmodule.py:1564] group_w3 first element: 0.08447265625
WARNING 01-14 20:42:33.816034.816034 mlpmodule.py:1574] start einsum2
DEBUG 01-14 20:42:33.834659.834659 mlpmodule.py:1584] group einsum cost 0.02772808074951172 s
INFO 01-14 20:42:33.834166.834166 client.py:127] Model loaded
DEBUG 01-14 20:42:33.835394.835394 cuda_h.py:19] end wait_experts cost 0.03194761276245117 seconds
DEBUG 01-14 20:42:33.835811.835811 cuda_h.py:10] start gpu_experts
DEBUG 01-14 20:42:33.835518.835518 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-14 20:42:33.835230.835230 mlpmodule.py:1593] cpy2cputensor cost 0.0007319450378417969 s
DEBUG 01-14 20:42:33.835710.835710 cuda_h.py:10] start move_outputs
DEBUG 01-14 20:42:33.837654.837654 cuda_h.py:19] end move_outputs cost 0.0020656585693359375 seconds
DEBUG 01-14 20:42:33.841901.841901 cuda_h.py:19] end wait_cetm_experts cost 0.006026506423950195 seconds
DEBUG 01-14 20:42:33.841972.841972 cuda_h.py:10] start gpu_group_einsum_mp_multi_list
DEBUG 01-14 20:42:33.841926.841926 cuda_h.py:10] start gpu_group_tensor
DEBUG 01-14 20:42:33.842439.842439 cuda_h.py:19] end gpu_group_tensor cost 0.00024008750915527344 seconds
DEBUG 01-14 20:42:33.842893.842893 cuda_h.py:10] start gpu_group_einsum
DEBUG 01-14 20:42:33.842056.842056 cuda_h.py:19] end gpu_group_einsum cost 0.0006575584411621094 seconds
DEBUG 01-14 20:42:33.843975.843975 cuda_h.py:10] start gpu_final_hidden_states_scatter
DEBUG 01-14 20:42:33.843402.843402 cuda_h.py:10] start all_expert_outputs_slices
DEBUG 01-14 20:42:33.843567.843567 cuda_h.py:19] end all_expert_outputs_slices cost 0.00036525726318359375 seconds
DEBUG 01-14 20:42:33.843608.843608 cuda_h.py:10] start concat_expert_out
DEBUG 01-14 20:42:33.843698.843698 cuda_h.py:19] end concat_expert_out cost 6.127357482910156e-05 seconds
DEBUG 01-14 20:42:33.843170.843170 cuda_h.py:10] start index_scatter
DEBUG 01-14 20:42:33.843121.843121 cuda_h.py:19] end index_scatter cost 7.033348083496094e-05 seconds
DEBUG 01-14 20:42:33.843930.843930 cuda_h.py:19] end gpu_final_hidden_states_scatter cost 0.0007593631744384766 seconds
DEBUG 01-14 20:42:33.843985.843985 cuda_h.py:19] end gpu_experts cost 0.008481979370117188 seconds
DEBUG 01-14 20:42:33.843688.843688 cuda_h.py:10] start all_expert_weight_slices
DEBUG 01-14 20:42:33.844716.844716 cuda_h.py:19] end all_expert_weight_slices cost 0.0010042190551757812 seconds
DEBUG 01-14 20:42:33.845023.845023 cuda_h.py:10] start cpuoutputsdeal
DEBUG 01-14 20:42:33.845090.845090 cuda_h.py:10] start index_scatter
DEBUG 01-14 20:42:33.845564.845564 cuda_h.py:19] end index_scatter cost 5.221366882324219e-05 seconds
DEBUG 01-14 20:42:33.845380.845380 cuda_h.py:19] end cpuoutputsdeal cost 0.0005505084991455078 seconds
DEBUG 01-14 20:42:33.845766.845766 cuda_h.py:19] end layer_moe_generate_mp_l_24 cost 0.07275080680847168 seconds
DEBUG 01-14 20:42:33.846150.846150 cuda_h.py:19] end prefill_layer cost 0.08139705657958984 seconds
DEBUG 01-14 20:42:33.846456.846456 lmp.py:1551] -------------------------------- end prefill layer 23 --------------------------------
DEBUG 01-14 20:42:33.846875.846875 cuda_h.py:10] start prefill_layer
DEBUG 01-14 20:42:33.846008.846008 lmp.py:1494] -------------------------------- start prefill layer 24 --------------------------------
DEBUG 01-14 20:42:33.846479.846479 cuda_h.py:10] start start_load_qkvogn_s_weight_l_25
DEBUG 01-14 20:42:33.846997.846997 cuda_h.py:10] start start_load_qkvogn_s_weight_l_25
DEBUG 01-14 20:42:33.846185.846185 cuda_h.py:19] end start_load_qkvogn_s_weight_l_25 cost 4.0531158447265625e-05 seconds
DEBUG 01-14 20:42:33.846225.846225 cuda_h.py:19] end start_load_qkvogn_s_weight_l_25 cost 7.367134094238281e-05 seconds
DEBUG 01-14 20:42:33.846637.846637 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-14 20:42:33.846606.846606 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-14 20:42:33.846047.846047 cuda_h.py:10] start sllm_worker_task
DEBUG 01-14 20:42:33.846067.846067 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-14 20:42:33.846085.846085 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-14 20:42:33.849317.849317 cuda_h.py:19] end allocate_cuda_memory cost 0.0020275115966796875 seconds
DEBUG 01-14 20:42:33.849571.849571 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-14 20:42:33.849893.849893 sllm_store_c.py:27] get device uuid map
DEBUG 01-14 20:42:33.849488.849488 sllm_store_c.py:29] call client load into gpu
DEBUG 01-14 20:42:33.849935.849935 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 5d721562-875b-41a5-887e-87f081c859c5
DEBUG 01-14 20:42:33.849591.849591 client.py:106] call stub.LoadModelAsync
DEBUG 01-14 20:42:33.850314.850314 cuda_h.py:10] start self_attn
INFO 01-14 20:42:33.851333.851333 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 5d721562-875b-41a5-887e-87f081c859c5
DEBUG 01-14 20:42:33.851898.851898 cuda_h.py:19] end load_into_gpu_async cost 0.0019481182098388672 seconds
DEBUG 01-14 20:42:33.851085.851085 cuda_h.py:10] start restore_tensors2
DEBUG 01-14 20:42:33.851081.851081 cuda_h.py:19] end restore_tensors2 cost 7.176399230957031e-05 seconds
DEBUG 01-14 20:42:33.851553.851553 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.004714250564575195 seconds
INFO 01-14 20:42:33.851442.851442 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 5d721562-875b-41a5-887e-87f081c859c5
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-14 20:42:33.853841.853841 mlpmodule.py:1367]  experts func einsum cost 0.0701754093170166 s
DEBUG 01-14 20:42:33.853813.853813 cuda_h.py:19] end self_attn cost 0.003543376922607422 seconds
DEBUG 01-14 20:42:33.854837.854837 cuda_h.py:19] end iln_self_attn_paln cost 0.007734060287475586 seconds
DEBUG 01-14 20:42:33.854356.854356 cuda_h.py:10] start layer_moe_generate_mp_l_25
DEBUG 01-14 20:42:33.854119.854119 cuda_h.py:10] start gate
DEBUG 01-14 20:42:33.854943.854943 cuda_h.py:19] end gate cost 0.0006420612335205078 seconds
DEBUG 01-14 20:42:33.854554.854554 cuda_h.py:10] start experts_map_get
DEBUG 01-14 20:42:33.855790.855790 lmp.py:1615] 
DEBUG 01-14 20:42:33.855790.855790 lmp.py:1615] Expert Token Distribution & Device Allocation:
DEBUG 01-14 20:42:33.855738.855738 lmp.py:1616]   Total experts: 64
DEBUG 01-14 20:42:33.855103.855103 lmp.py:1617]   CPU experts: 32 (50%)
DEBUG 01-14 20:42:33.855892.855892 lmp.py:1618]   GPU experts: 32 (50%)
DEBUG 01-14 20:42:33.855058.855058 lmp.py:1619] 
DEBUG 01-14 20:42:33.855058.855058 lmp.py:1619]   Expert ID | Tokens | Device
DEBUG 01-14 20:42:33.855178.855178 lmp.py:1620]   -----------------------------------
DEBUG 01-14 20:42:33.855536.855536 lmp.py:1625]   Expert 36 |     26 | CPU
DEBUG 01-14 20:42:33.855179.855179 lmp.py:1625]   Expert 35 |     45 | CPU
DEBUG 01-14 20:42:33.855060.855060 lmp.py:1625]   Expert 25 |     47 | CPU
DEBUG 01-14 20:42:33.855180.855180 lmp.py:1625]   Expert 51 |     55 | CPU
DEBUG 01-14 20:42:33.855869.855869 lmp.py:1625]   Expert 30 |     59 | CPU
DEBUG 01-14 20:42:33.855559.855559 lmp.py:1625]   Expert 55 |     59 | CPU
DEBUG 01-14 20:42:33.855009.855009 lmp.py:1625]   Expert 46 |     60 | CPU
DEBUG 01-14 20:42:33.855460.855460 lmp.py:1625]   Expert 43 |     61 | CPU
DEBUG 01-14 20:42:33.855434.855434 lmp.py:1625]   Expert 44 |     72 | CPU
DEBUG 01-14 20:42:33.855647.855647 lmp.py:1625]   Expert 47 |     75 | CPU
DEBUG 01-14 20:42:33.855575.855575 lmp.py:1625]   Expert  0 |     79 | CPU
DEBUG 01-14 20:42:33.855502.855502 lmp.py:1625]   Expert 16 |     82 | CPU
DEBUG 01-14 20:42:33.855715.855715 lmp.py:1625]   Expert 39 |     83 | CPU
DEBUG 01-14 20:42:33.855927.855927 lmp.py:1625]   Expert  2 |     86 | CPU
DEBUG 01-14 20:42:33.855901.855901 lmp.py:1625]   Expert 42 |     90 | CPU
DEBUG 01-14 20:42:33.855114.855114 lmp.py:1625]   Expert  4 |    106 | CPU
DEBUG 01-14 20:42:33.855088.855088 lmp.py:1625]   Expert 48 |    121 | CPU
DEBUG 01-14 20:42:33.855300.855300 lmp.py:1625]   Expert 61 |    123 | CPU
DEBUG 01-14 20:42:33.855036.855036 lmp.py:1625]   Expert 33 |    124 | CPU
DEBUG 01-14 20:42:33.855248.855248 lmp.py:1625]   Expert 54 |    124 | CPU
DEBUG 01-14 20:42:33.855699.855699 lmp.py:1625]   Expert 24 |    132 | CPU
DEBUG 01-14 20:42:33.855673.855673 lmp.py:1625]   Expert  6 |    135 | CPU
DEBUG 01-14 20:42:33.855508.855508 lmp.py:1625]   Expert 29 |    138 | CPU
DEBUG 01-14 20:42:33.855436.855436 lmp.py:1625]   Expert 15 |    142 | CPU
DEBUG 01-14 20:42:33.855125.855125 lmp.py:1625]   Expert 38 |    142 | CPU
DEBUG 01-14 20:42:33.855576.855576 lmp.py:1625]   Expert 56 |    144 | CPU
DEBUG 01-14 20:42:33.855789.855789 lmp.py:1625]   Expert  7 |    147 | CPU
DEBUG 01-14 20:42:33.855763.855763 lmp.py:1625]   Expert 19 |    148 | CPU
DEBUG 01-14 20:42:33.855975.855975 lmp.py:1625]   Expert  9 |    153 | CPU
DEBUG 01-14 20:42:33.855949.855949 lmp.py:1625]   Expert 59 |    154 | CPU
DEBUG 01-14 20:42:33.855162.855162 lmp.py:1625]   Expert 62 |    157 | CPU
DEBUG 01-14 20:42:33.855328.855328 lmp.py:1625]   Expert 13 |    160 | CPU
DEBUG 01-14 20:42:33.855017.855017 lmp.py:1625]   Expert 20 |    163 | GPU
DEBUG 01-14 20:42:33.855468.855468 lmp.py:1625]   Expert 45 |    179 | GPU
DEBUG 01-14 20:42:33.855204.855204 lmp.py:1625]   Expert  8 |    182 | GPU
DEBUG 01-14 20:42:33.855655.855655 lmp.py:1625]   Expert 34 |    182 | GPU
DEBUG 01-14 20:42:33.856867.856867 lmp.py:1625]   Expert 18 |    184 | GPU
DEBUG 01-14 20:42:33.856987.856987 lmp.py:1625]   Expert 50 |    186 | GPU
DEBUG 01-14 20:42:33.856391.856391 lmp.py:1625]   Expert 57 |    193 | GPU
DEBUG 01-14 20:42:33.856319.856319 lmp.py:1625]   Expert 23 |    195 | GPU
DEBUG 01-14 20:42:33.856962.856962 lmp.py:1625]   Expert 60 |    199 | GPU
DEBUG 01-14 20:42:33.856605.856605 lmp.py:1625]   Expert 31 |    202 | GPU
DEBUG 01-14 20:42:33.856771.856771 lmp.py:1625]   Expert 10 |    210 | GPU
DEBUG 01-14 20:42:33.856699.856699 lmp.py:1625]   Expert 22 |    214 | GPU
DEBUG 01-14 20:42:33.856627.856627 lmp.py:1625]   Expert 17 |    229 | GPU
DEBUG 01-14 20:42:33.856316.856316 lmp.py:1625]   Expert 37 |    234 | GPU
DEBUG 01-14 20:42:33.856244.856244 lmp.py:1625]   Expert  5 |    237 | GPU
DEBUG 01-14 20:42:33.856410.856410 lmp.py:1625]   Expert 11 |    239 | GPU
DEBUG 01-14 20:42:33.856814.856814 lmp.py:1625]   Expert 52 |    239 | GPU
DEBUG 01-14 20:42:33.856742.856742 lmp.py:1625]   Expert 53 |    252 | GPU
DEBUG 01-14 20:42:33.856908.856908 lmp.py:1625]   Expert  1 |    266 | GPU
DEBUG 01-14 20:42:33.856266.856266 lmp.py:1625]   Expert 49 |    268 | GPU
DEBUG 01-14 20:42:33.856671.856671 lmp.py:1625]   Expert 14 |    281 | GPU
DEBUG 01-14 20:42:33.856837.856837 lmp.py:1625]   Expert 26 |    281 | GPU
DEBUG 01-14 20:42:33.856765.856765 lmp.py:1625]   Expert 41 |    281 | GPU
DEBUG 01-14 20:42:33.856693.856693 lmp.py:1625]   Expert 58 |    285 | GPU
DEBUG 01-14 20:42:33.856382.856382 lmp.py:1625]   Expert 40 |    295 | GPU
DEBUG 01-14 20:42:33.856310.856310 lmp.py:1625]   Expert 28 |    305 | GPU
DEBUG 01-14 20:42:33.856059.856059 lmp.py:1625]   Expert 12 |    318 | GPU
DEBUG 01-14 20:42:33.856894.856894 lmp.py:1625]   Expert 32 |    323 | GPU
DEBUG 01-14 20:42:33.856298.856298 lmp.py:1625]   Expert 21 |    351 | GPU
DEBUG 01-14 20:42:33.856465.856465 lmp.py:1625]   Expert 63 |    359 | GPU
DEBUG 01-14 20:42:33.856392.856392 lmp.py:1625]   Expert 27 |    604 | GPU
DEBUG 01-14 20:42:33.856558.856558 lmp.py:1625]   Expert  3 |   1023 | GPU
DEBUG 01-14 20:42:33.856678.856678 lmp.py:1626] 
DEBUG 01-14 20:42:33.856678.856678 lmp.py:1626]   CPU total tokens: 3329 (27.1%)
DEBUG 01-14 20:42:33.856275.856275 lmp.py:1627]   GPU total tokens: 8959 (72.9%)
DEBUG 01-14 20:42:33.856686.856686 cuda_h.py:19] end experts_map_get cost 0.0015408992767333984 seconds
DEBUG 01-14 20:42:33.856159.856159 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-14 20:42:33.856763.856763 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-14 20:42:33.856868.856868 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-14 20:42:33.857839.857839 cuda_h.py:19] end allocate_cuda_memory cost 0.0011043548583984375 seconds
DEBUG 01-14 20:42:33.858272.858272 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-14 20:42:33.858697.858697 sllm_store_c.py:27] get device uuid map
DEBUG 01-14 20:42:33.858652.858652 sllm_store_c.py:29] call client load into gpu
DEBUG 01-14 20:42:33.858017.858017 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, e3d4a36e-0b2b-4a0b-ba1d-a26410e54d13
DEBUG 01-14 20:42:33.858620.858620 client.py:106] call stub.LoadModelAsync
INFO 01-14 20:42:33.858052.858052 client.py:127] Model loaded
DEBUG 01-14 20:42:33.858504.858504 cuda_h.py:10] start restore2model
DEBUG 01-14 20:42:33.858907.858907 cuda_h.py:19] end restore2model cost 0.0003368854522705078 seconds
DEBUG 01-14 20:42:33.859339.859339 cuda_h.py:19] end sllm_worker_task cost 0.012306451797485352 seconds
INFO 01-14 20:42:33.860523.860523 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, e3d4a36e-0b2b-4a0b-ba1d-a26410e54d13
DEBUG 01-14 20:42:33.860989.860989 cuda_h.py:19] end load_into_gpu_async cost 0.002178668975830078 seconds
DEBUG 01-14 20:42:33.860930.860930 cuda_h.py:10] start restore_tensors2
DEBUG 01-14 20:42:33.860804.860804 cuda_h.py:19] end restore_tensors2 cost 0.0003712177276611328 seconds
DEBUG 01-14 20:42:33.860025.860025 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0040318965911865234 seconds
DEBUG 01-14 20:42:33.860126.860126 cuda_h.py:10] start restore2model
DEBUG 01-14 20:42:33.863728.863728 cuda_h.py:19] end restore2model cost 0.002521991729736328 seconds
DEBUG 01-14 20:42:33.863511.863511 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.006726503372192383 seconds
DEBUG 01-14 20:42:33.863306.863306 cuda_h.py:10] start gpu_sexperts
DEBUG 01-14 20:42:33.863913.863913 cuda_h.py:19] end gpu_sexperts cost 0.0002753734588623047 seconds
DEBUG 01-14 20:42:33.863404.863404 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-14 20:42:33.863299.863299 lmp.py:1683] 
DEBUG 01-14 20:42:33.863299.863299 lmp.py:1683]   Computing 32 experts on CPU...
DEBUG 01-14 20:42:33.863235.863235 cuda_h.py:19] end cpu_experts_submit cost 5.841255187988281e-05 seconds
DEBUG 01-14 20:42:33.863554.863554 cuda_h.py:10] start experts_func_mgpu_group_pad
DEBUG 01-14 20:42:33.877241.877241 mlpmodule.py:1460] group tensors cost 0.013107061386108398 s
DEBUG 01-14 20:42:33.878897.878897 cuda_h.py:10] start move_flat_hidden2cpu
DEBUG 01-14 20:42:33.880447.880447 cuda_h.py:19] end experts_func_mgpu_group_pad cost 0.016546964645385742 seconds
DEBUG 01-14 20:42:33.882269.882269 cuda_h.py:10] start gpu_group_list
DEBUG 01-14 20:42:33.882462.882462 cuda_h.py:19] end gpu_group_list cost 0.0005168914794921875 seconds
DEBUG 01-14 20:42:33.882243.882243 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-14 20:42:33.882544.882544 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.1457672119140625e-05 seconds
DEBUG 01-14 20:42:33.882737.882737 cuda_h.py:10] start wait_experts
INFO 01-14 20:42:33.883169.883169 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, e3d4a36e-0b2b-4a0b-ba1d-a26410e54d13
DEBUG 01-14 20:42:33.884627.884627 cuda_h.py:19] end move_flat_hidden2cpu cost 0.006691932678222656 seconds
DEBUG 01-14 20:42:33.886185.886185 mlpmodule.py:1533] pad cost 0.001527547836303711 s
DEBUG 01-14 20:42:33.886427.886427 mlpmodule.py:1539] create cpu tensor cost 3.695487976074219e-05 s
DEBUG 01-14 20:42:33.888485.888485 mlpmodule.py:1544] move to cpu cost 0.00189971923828125 s
DEBUG 01-14 20:42:33.897859.897859 mlpmodule.py:1558] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-14 20:42:33.898924.898924 mlpmodule.py:1559] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-14 20:42:33.898092.898092 mlpmodule.py:1564] group_w3 first element: 0.00653076171875
WARNING 01-14 20:42:33.898825.898825 mlpmodule.py:1574] start einsum2
DEBUG 01-14 20:42:33.915299.915299 mlpmodule.py:1584] group einsum cost 0.026769638061523438 s
INFO 01-14 20:42:33.916424.916424 client.py:127] Model loaded
DEBUG 01-14 20:42:33.916159.916159 mlpmodule.py:1593] cpy2cputensor cost 0.0009431838989257812 s
DEBUG 01-14 20:42:33.916111.916111 cuda_h.py:19] end wait_experts cost 0.03363513946533203 seconds
DEBUG 01-14 20:42:33.916398.916398 cuda_h.py:10] start move_outputs
DEBUG 01-14 20:42:33.916918.916918 cuda_h.py:10] start gpu_experts
DEBUG 01-14 20:42:33.917049.917049 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-14 20:42:33.918050.918050 cuda_h.py:19] end move_outputs cost 0.0018703937530517578 seconds
DEBUG 01-14 20:42:33.922423.922423 cuda_h.py:19] end wait_cetm_experts cost 0.0053861141204833984 seconds
DEBUG 01-14 20:42:33.922533.922533 cuda_h.py:10] start gpu_group_einsum_mp_multi_list
DEBUG 01-14 20:42:33.922773.922773 cuda_h.py:10] start gpu_group_tensor
DEBUG 01-14 20:42:33.922285.922285 cuda_h.py:19] end gpu_group_tensor cost 0.00023984909057617188 seconds
DEBUG 01-14 20:42:33.923879.923879 cuda_h.py:10] start gpu_group_einsum
DEBUG 01-14 20:42:33.923699.923699 cuda_h.py:19] end gpu_group_einsum cost 0.0005185604095458984 seconds
DEBUG 01-14 20:42:33.923769.923769 cuda_h.py:10] start gpu_final_hidden_states_scatter
DEBUG 01-14 20:42:33.923705.923705 cuda_h.py:10] start all_expert_outputs_slices
DEBUG 01-14 20:42:33.924570.924570 cuda_h.py:19] end all_expert_outputs_slices cost 0.0002880096435546875 seconds
DEBUG 01-14 20:42:33.924849.924849 cuda_h.py:10] start concat_expert_out
DEBUG 01-14 20:42:33.924548.924548 cuda_h.py:19] end concat_expert_out cost 5.698204040527344e-05 seconds
DEBUG 01-14 20:42:33.924636.924636 cuda_h.py:10] start index_scatter
DEBUG 01-14 20:42:33.924204.924204 cuda_h.py:19] end index_scatter cost 7.224082946777344e-05 seconds
DEBUG 01-14 20:42:33.924589.924589 cuda_h.py:19] end gpu_final_hidden_states_scatter cost 0.0007023811340332031 seconds
DEBUG 01-14 20:42:33.924228.924228 cuda_h.py:19] end gpu_experts cost 0.007521390914916992 seconds
DEBUG 01-14 20:42:33.924123.924123 cuda_h.py:10] start all_expert_weight_slices
DEBUG 01-14 20:42:33.925831.925831 cuda_h.py:19] end all_expert_weight_slices cost 0.0009458065032958984 seconds
DEBUG 01-14 20:42:33.925177.925177 cuda_h.py:10] start cpuoutputsdeal
DEBUG 01-14 20:42:33.926827.926827 cuda_h.py:10] start index_scatter
DEBUG 01-14 20:42:33.926440.926440 cuda_h.py:19] end index_scatter cost 4.887580871582031e-05 seconds
DEBUG 01-14 20:42:33.926064.926064 cuda_h.py:19] end cpuoutputsdeal cost 0.0005545616149902344 seconds
DEBUG 01-14 20:42:33.926881.926881 cuda_h.py:19] end layer_moe_generate_mp_l_25 cost 0.07201933860778809 seconds
DEBUG 01-14 20:42:33.926716.926716 cuda_h.py:19] end prefill_layer cost 0.08046817779541016 seconds
DEBUG 01-14 20:42:33.926221.926221 lmp.py:1551] -------------------------------- end prefill layer 24 --------------------------------
DEBUG 01-14 20:42:33.926639.926639 cuda_h.py:10] start prefill_layer
DEBUG 01-14 20:42:33.926580.926580 lmp.py:1494] -------------------------------- start prefill layer 25 --------------------------------
DEBUG 01-14 20:42:33.926283.926283 cuda_h.py:10] start start_load_qkvogn_s_weight_l_26
DEBUG 01-14 20:42:33.926324.926324 cuda_h.py:10] start start_load_qkvogn_s_weight_l_26
DEBUG 01-14 20:42:33.926743.926743 cuda_h.py:19] end start_load_qkvogn_s_weight_l_26 cost 3.5762786865234375e-05 seconds
DEBUG 01-14 20:42:33.926122.926122 cuda_h.py:19] end start_load_qkvogn_s_weight_l_26 cost 7.104873657226562e-05 seconds
DEBUG 01-14 20:42:33.926725.926725 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-14 20:42:33.927503.927503 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-14 20:42:33.927810.927810 cuda_h.py:10] start sllm_worker_task
DEBUG 01-14 20:42:33.927463.927463 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-14 20:42:33.927160.927160 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-14 20:42:33.929685.929685 cuda_h.py:19] end allocate_cuda_memory cost 0.002383708953857422 seconds
DEBUG 01-14 20:42:33.929263.929263 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-14 20:42:33.929318.929318 sllm_store_c.py:27] get device uuid map
DEBUG 01-14 20:42:33.929200.929200 sllm_store_c.py:29] call client load into gpu
DEBUG 01-14 20:42:33.929672.929672 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 872c4741-093d-4548-b3bd-d296b456a594
DEBUG 01-14 20:42:33.929516.929516 client.py:106] call stub.LoadModelAsync
DEBUG 01-14 20:42:33.930926.930926 cuda_h.py:10] start self_attn
INFO 01-14 20:42:33.931166.931166 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 872c4741-093d-4548-b3bd-d296b456a594
DEBUG 01-14 20:42:33.931764.931764 cuda_h.py:19] end load_into_gpu_async cost 0.0014541149139404297 seconds
DEBUG 01-14 20:42:33.931559.931559 cuda_h.py:10] start restore_tensors2
DEBUG 01-14 20:42:33.931702.931702 cuda_h.py:19] end restore_tensors2 cost 7.748603820800781e-05 seconds
DEBUG 01-14 20:42:33.931412.931412 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.004178047180175781 seconds
INFO 01-14 20:42:33.931917.931917 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 872c4741-093d-4548-b3bd-d296b456a594
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-14 20:42:33.933531.933531 mlpmodule.py:1367]  experts func einsum cost 0.06906867027282715 s
DEBUG 01-14 20:42:33.933166.933166 cuda_h.py:19] end self_attn cost 0.003144502639770508 seconds
DEBUG 01-14 20:42:33.933867.933867 cuda_h.py:19] end iln_self_attn_paln cost 0.006951808929443359 seconds
DEBUG 01-14 20:42:33.933624.933624 cuda_h.py:10] start layer_moe_generate_mp_l_26
DEBUG 01-14 20:42:33.934102.934102 cuda_h.py:10] start gate
DEBUG 01-14 20:42:33.934826.934826 cuda_h.py:19] end gate cost 0.0006389617919921875 seconds
DEBUG 01-14 20:42:33.934086.934086 cuda_h.py:10] start experts_map_get
DEBUG 01-14 20:42:33.935938.935938 lmp.py:1615] 
DEBUG 01-14 20:42:33.935938.935938 lmp.py:1615] Expert Token Distribution & Device Allocation:
DEBUG 01-14 20:42:33.935376.935376 lmp.py:1616]   Total experts: 64
DEBUG 01-14 20:42:33.935980.935980 lmp.py:1617]   CPU experts: 32 (50%)
DEBUG 01-14 20:42:33.935815.935815 lmp.py:1618]   GPU experts: 32 (50%)
DEBUG 01-14 20:42:33.935743.935743 lmp.py:1619] 
DEBUG 01-14 20:42:33.935743.935743 lmp.py:1619]   Expert ID | Tokens | Device
DEBUG 01-14 20:42:33.935386.935386 lmp.py:1620]   -----------------------------------
DEBUG 01-14 20:42:33.935221.935221 lmp.py:1625]   Expert 13 |     26 | CPU
DEBUG 01-14 20:42:33.935102.935102 lmp.py:1625]   Expert 33 |     37 | CPU
DEBUG 01-14 20:42:33.935745.935745 lmp.py:1625]   Expert 44 |     38 | CPU
DEBUG 01-14 20:42:33.935434.935434 lmp.py:1625]   Expert  9 |     43 | CPU
DEBUG 01-14 20:42:33.935885.935885 lmp.py:1625]   Expert 16 |     43 | CPU
DEBUG 01-14 20:42:33.935098.935098 lmp.py:1625]   Expert 38 |     51 | CPU
DEBUG 01-14 20:42:33.935787.935787 lmp.py:1625]   Expert  2 |     53 | CPU
DEBUG 01-14 20:42:33.935238.935238 lmp.py:1625]   Expert 25 |     55 | CPU
DEBUG 01-14 20:42:33.935212.935212 lmp.py:1625]   Expert 22 |     57 | CPU
DEBUG 01-14 20:42:33.935140.935140 lmp.py:1625]   Expert 42 |     57 | CPU
DEBUG 01-14 20:42:33.935306.935306 lmp.py:1625]   Expert  5 |     62 | CPU
DEBUG 01-14 20:42:33.935757.935757 lmp.py:1625]   Expert 24 |     64 | CPU
DEBUG 01-14 20:42:33.935969.935969 lmp.py:1625]   Expert 23 |     80 | CPU
DEBUG 01-14 20:42:33.935943.935943 lmp.py:1625]   Expert 10 |     85 | CPU
DEBUG 01-14 20:42:33.935632.935632 lmp.py:1625]   Expert 46 |    102 | CPU
DEBUG 01-14 20:42:33.935083.935083 lmp.py:1625]   Expert 59 |    104 | CPU
DEBUG 01-14 20:42:33.935296.935296 lmp.py:1625]   Expert 61 |    107 | CPU
DEBUG 01-14 20:42:33.935462.935462 lmp.py:1625]   Expert 55 |    108 | CPU
DEBUG 01-14 20:42:33.935390.935390 lmp.py:1625]   Expert 21 |    111 | CPU
DEBUG 01-14 20:42:33.935079.935079 lmp.py:1625]   Expert  6 |    130 | CPU
DEBUG 01-14 20:42:33.935291.935291 lmp.py:1625]   Expert 45 |    130 | CPU
DEBUG 01-14 20:42:33.935504.935504 lmp.py:1625]   Expert 31 |    134 | CPU
DEBUG 01-14 20:42:33.935716.935716 lmp.py:1625]   Expert  3 |    138 | CPU
DEBUG 01-14 20:42:33.935929.935929 lmp.py:1625]   Expert 26 |    156 | CPU
DEBUG 01-14 20:42:33.935903.935903 lmp.py:1625]   Expert 36 |    156 | CPU
DEBUG 01-14 20:42:33.935877.935877 lmp.py:1625]   Expert 43 |    156 | CPU
DEBUG 01-14 20:42:33.935851.935851 lmp.py:1625]   Expert 48 |    157 | CPU
DEBUG 01-14 20:42:33.935779.935779 lmp.py:1625]   Expert 41 |    161 | CPU
DEBUG 01-14 20:42:33.935706.935706 lmp.py:1625]   Expert 51 |    162 | CPU
DEBUG 01-14 20:42:33.935919.935919 lmp.py:1625]   Expert 18 |    163 | CPU
DEBUG 01-14 20:42:33.935893.935893 lmp.py:1625]   Expert 28 |    166 | CPU
DEBUG 01-14 20:42:33.935105.935105 lmp.py:1625]   Expert 56 |    166 | CPU
DEBUG 01-14 20:42:33.935556.935556 lmp.py:1625]   Expert  8 |    168 | GPU
DEBUG 01-14 20:42:33.935246.935246 lmp.py:1625]   Expert 20 |    172 | GPU
DEBUG 01-14 20:42:33.935220.935220 lmp.py:1625]   Expert 12 |    176 | GPU
DEBUG 01-14 20:42:33.935670.935670 lmp.py:1625]   Expert  0 |    184 | GPU
DEBUG 01-14 20:42:33.935360.935360 lmp.py:1625]   Expert 27 |    184 | GPU
DEBUG 01-14 20:42:33.935572.935572 lmp.py:1625]   Expert  7 |    187 | GPU
DEBUG 01-14 20:42:33.935546.935546 lmp.py:1625]   Expert 47 |    200 | GPU
DEBUG 01-14 20:42:33.935759.935759 lmp.py:1625]   Expert  1 |    210 | GPU
DEBUG 01-14 20:42:33.935733.935733 lmp.py:1625]   Expert 34 |    211 | GPU
DEBUG 01-14 20:42:33.935945.935945 lmp.py:1625]   Expert 15 |    214 | GPU
DEBUG 01-14 20:42:33.935919.935919 lmp.py:1625]   Expert 40 |    225 | GPU
DEBUG 01-14 20:42:33.935893.935893 lmp.py:1625]   Expert 11 |    231 | GPU
DEBUG 01-14 20:42:33.935583.935583 lmp.py:1625]   Expert 49 |    231 | GPU
DEBUG 01-14 20:42:33.935272.935272 lmp.py:1625]   Expert 32 |    234 | GPU
DEBUG 01-14 20:42:33.935246.935246 lmp.py:1625]   Expert 50 |    235 | GPU
DEBUG 01-14 20:42:33.935220.935220 lmp.py:1625]   Expert 63 |    243 | GPU
DEBUG 01-14 20:42:33.935194.935194 lmp.py:1625]   Expert 53 |    246 | GPU
DEBUG 01-14 20:42:33.936930.936930 lmp.py:1625]   Expert 30 |    255 | GPU
DEBUG 01-14 20:42:33.936857.936857 lmp.py:1625]   Expert 29 |    259 | GPU
DEBUG 01-14 20:42:33.936547.936547 lmp.py:1625]   Expert  4 |    260 | GPU
DEBUG 01-14 20:42:33.936521.936521 lmp.py:1625]   Expert 35 |    276 | GPU
DEBUG 01-14 20:42:33.936495.936495 lmp.py:1625]   Expert 14 |    277 | GPU
DEBUG 01-14 20:42:33.936230.936230 lmp.py:1625]   Expert 37 |    300 | GPU
DEBUG 01-14 20:42:33.936966.936966 lmp.py:1625]   Expert 17 |    356 | GPU
DEBUG 01-14 20:42:33.936940.936940 lmp.py:1625]   Expert 52 |    361 | GPU
DEBUG 01-14 20:42:33.936676.936676 lmp.py:1625]   Expert 54 |    371 | GPU
DEBUG 01-14 20:42:33.936127.936127 lmp.py:1625]   Expert 39 |    383 | GPU
DEBUG 01-14 20:42:33.936770.936770 lmp.py:1625]   Expert 57 |    410 | GPU
DEBUG 01-14 20:42:33.936936.936936 lmp.py:1625]   Expert 60 |    445 | GPU
DEBUG 01-14 20:42:33.936863.936863 lmp.py:1625]   Expert 62 |    458 | GPU
DEBUG 01-14 20:42:33.936791.936791 lmp.py:1625]   Expert 19 |    505 | GPU
DEBUG 01-14 20:42:33.936242.936242 lmp.py:1625]   Expert 58 |    563 | GPU
DEBUG 01-14 20:42:33.936362.936362 lmp.py:1626] 
DEBUG 01-14 20:42:33.936362.936362 lmp.py:1626]   CPU total tokens: 3258 (26.5%)
DEBUG 01-14 20:42:33.936243.936243 lmp.py:1627]   GPU total tokens: 9030 (73.5%)
DEBUG 01-14 20:42:33.936715.936715 cuda_h.py:19] end experts_map_get cost 0.0015206336975097656 seconds
DEBUG 01-14 20:42:33.936041.936041 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-14 20:42:33.936567.936567 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-14 20:42:33.936433.936433 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-14 20:42:33.938051.938051 cuda_h.py:19] end allocate_cuda_memory cost 0.0018277168273925781 seconds
DEBUG 01-14 20:42:33.938915.938915 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-14 20:42:33.938770.938770 sllm_store_c.py:27] get device uuid map
DEBUG 01-14 20:42:33.938294.938294 sllm_store_c.py:29] call client load into gpu
DEBUG 01-14 20:42:33.938944.938944 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 48b3c937-5206-4986-b27f-29f65ef66d84
DEBUG 01-14 20:42:33.938832.938832 client.py:106] call stub.LoadModelAsync
INFO 01-14 20:42:33.939152.939152 client.py:127] Model loaded
DEBUG 01-14 20:42:33.939982.939982 cuda_h.py:10] start restore2model
DEBUG 01-14 20:42:33.939232.939232 cuda_h.py:19] end restore2model cost 0.00033020973205566406 seconds
DEBUG 01-14 20:42:33.939426.939426 cuda_h.py:19] end sllm_worker_task cost 0.01255345344543457 seconds
INFO 01-14 20:42:33.940643.940643 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 48b3c937-5206-4986-b27f-29f65ef66d84
DEBUG 01-14 20:42:33.941701.941701 cuda_h.py:19] end load_into_gpu_async cost 0.002458810806274414 seconds
DEBUG 01-14 20:42:33.941856.941856 cuda_h.py:10] start restore_tensors2
DEBUG 01-14 20:42:33.941580.941580 cuda_h.py:19] end restore_tensors2 cost 0.0006117820739746094 seconds
DEBUG 01-14 20:42:33.941787.941787 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.005370140075683594 seconds
DEBUG 01-14 20:42:33.941027.941027 cuda_h.py:10] start restore2model
DEBUG 01-14 20:42:33.944048.944048 cuda_h.py:19] end restore2model cost 0.0025832653045654297 seconds
DEBUG 01-14 20:42:33.944792.944792 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.0081329345703125 seconds
DEBUG 01-14 20:42:33.944110.944110 cuda_h.py:10] start gpu_sexperts
DEBUG 01-14 20:42:33.944803.944803 cuda_h.py:19] end gpu_sexperts cost 0.00026798248291015625 seconds
DEBUG 01-14 20:42:33.944387.944387 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-14 20:42:33.944282.944282 lmp.py:1683] 
DEBUG 01-14 20:42:33.944282.944282 lmp.py:1683]   Computing 32 experts on CPU...
DEBUG 01-14 20:42:33.944787.944787 cuda_h.py:19] end cpu_experts_submit cost 5.626678466796875e-05 seconds
DEBUG 01-14 20:42:33.945205.945205 cuda_h.py:10] start experts_func_mgpu_group_pad
DEBUG 01-14 20:42:33.958348.958348 mlpmodule.py:1460] group tensors cost 0.013062000274658203 s
DEBUG 01-14 20:42:33.959269.959269 cuda_h.py:10] start move_flat_hidden2cpu
DEBUG 01-14 20:42:33.965830.965830 cuda_h.py:19] end experts_func_mgpu_group_pad cost 0.019976139068603516 seconds
DEBUG 01-14 20:42:33.965944.965944 cuda_h.py:19] end move_flat_hidden2cpu cost 0.006642818450927734 seconds
DEBUG 01-14 20:42:33.968364.968364 cuda_h.py:10] start gpu_group_list
DEBUG 01-14 20:42:33.969066.969066 cuda_h.py:19] end gpu_group_list cost 0.0008132457733154297 seconds
DEBUG 01-14 20:42:33.969819.969819 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-14 20:42:33.969030.969030 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 3.218650817871094e-05 seconds
DEBUG 01-14 20:42:33.969641.969641 cuda_h.py:10] start wait_experts
INFO 01-14 20:42:33.969961.969961 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 48b3c937-5206-4986-b27f-29f65ef66d84
DEBUG 01-14 20:42:33.970069.970069 mlpmodule.py:1533] pad cost 0.004008054733276367 s
DEBUG 01-14 20:42:33.970239.970239 mlpmodule.py:1539] create cpu tensor cost 4.00543212890625e-05 s
DEBUG 01-14 20:42:33.972670.972670 mlpmodule.py:1544] move to cpu cost 0.0019652843475341797 s
DEBUG 01-14 20:42:33.981147.981147 mlpmodule.py:1558] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-14 20:42:33.982755.982755 mlpmodule.py:1559] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-14 20:42:33.982182.982182 mlpmodule.py:1564] group_w3 first element: -0.02734375
WARNING 01-14 20:42:33.982551.982551 mlpmodule.py:1574] start einsum2
INFO 01-14 20:42:33.996984.996984 client.py:127] Model loaded
DEBUG 01-14 20:42:33.996468.996468 cuda_h.py:19] end wait_experts cost 0.026795148849487305 seconds
DEBUG 01-14 20:42:33.996437.996437 cuda_h.py:10] start gpu_experts
DEBUG 01-14 20:42:33.996650.996650 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-14 20:42:33.998873.998873 mlpmodule.py:1584] group einsum cost 0.026163578033447266 s
DEBUG 01-14 20:42:33.999121.999121 mlpmodule.py:1593] cpy2cputensor cost 0.0007059574127197266 s
DEBUG 01-14 20:42:33.999083.999083 cuda_h.py:10] start move_outputs
DEBUG 01-14 20:42:34.001300.001300 cuda_h.py:19] end move_outputs cost 0.0019195079803466797 seconds
DEBUG 01-14 20:42:34.004813.004813 cuda_h.py:19] end wait_cetm_experts cost 0.008164644241333008 seconds
DEBUG 01-14 20:42:34.005533.005533 cuda_h.py:10] start gpu_group_einsum_mp_multi_list
DEBUG 01-14 20:42:34.005349.005349 cuda_h.py:10] start gpu_group_tensor
DEBUG 01-14 20:42:34.005299.005299 cuda_h.py:19] end gpu_group_tensor cost 0.0002434253692626953 seconds
DEBUG 01-14 20:42:34.005230.005230 cuda_h.py:10] start gpu_group_einsum
DEBUG 01-14 20:42:34.006249.006249 cuda_h.py:19] end gpu_group_einsum cost 0.0006968975067138672 seconds
DEBUG 01-14 20:42:34.006545.006545 cuda_h.py:10] start gpu_final_hidden_states_scatter
DEBUG 01-14 20:42:34.006541.006541 cuda_h.py:10] start all_expert_outputs_slices
DEBUG 01-14 20:42:34.006912.006912 cuda_h.py:19] end all_expert_outputs_slices cost 0.0003745555877685547 seconds
DEBUG 01-14 20:42:34.006337.006337 cuda_h.py:10] start concat_expert_out
DEBUG 01-14 20:42:34.007513.007513 cuda_h.py:19] end concat_expert_out cost 5.745887756347656e-05 seconds
DEBUG 01-14 20:42:34.007508.007508 cuda_h.py:10] start index_scatter
DEBUG 01-14 20:42:34.007320.007320 cuda_h.py:19] end index_scatter cost 7.390975952148438e-05 seconds
DEBUG 01-14 20:42:34.007175.007175 cuda_h.py:19] end gpu_final_hidden_states_scatter cost 0.000766754150390625 seconds
DEBUG 01-14 20:42:34.007376.007376 cuda_h.py:19] end gpu_experts cost 0.01062917709350586 seconds
DEBUG 01-14 20:42:34.007556.007556 cuda_h.py:10] start all_expert_weight_slices
DEBUG 01-14 20:42:34.008854.008854 cuda_h.py:19] end all_expert_weight_slices cost 0.000957489013671875 seconds
DEBUG 01-14 20:42:34.008015.008015 cuda_h.py:10] start cpuoutputsdeal
DEBUG 01-14 20:42:34.008090.008090 cuda_h.py:10] start index_scatter
DEBUG 01-14 20:42:34.008610.008610 cuda_h.py:19] end index_scatter cost 5.054473876953125e-05 seconds
DEBUG 01-14 20:42:34.008996.008996 cuda_h.py:19] end cpuoutputsdeal cost 0.0005545616149902344 seconds
DEBUG 01-14 20:42:34.009190.009190 cuda_h.py:19] end layer_moe_generate_mp_l_26 cost 0.07503294944763184 seconds
DEBUG 01-14 20:42:34.009257.009257 cuda_h.py:19] end prefill_layer cost 0.08269143104553223 seconds
DEBUG 01-14 20:42:34.009378.009378 lmp.py:1551] -------------------------------- end prefill layer 25 --------------------------------
DEBUG 01-14 20:42:34.009319.009319 cuda_h.py:10] start prefill_layer
DEBUG 01-14 20:42:34.009214.009214 lmp.py:1494] -------------------------------- start prefill layer 26 --------------------------------
DEBUG 01-14 20:42:34.009109.009109 cuda_h.py:10] start start_load_qkvogn_s_weight_l_27
DEBUG 01-14 20:42:34.009673.009673 cuda_h.py:10] start start_load_qkvogn_s_weight_l_27
DEBUG 01-14 20:42:34.009807.009807 cuda_h.py:19] end start_load_qkvogn_s_weight_l_27 cost 3.647804260253906e-05 seconds
DEBUG 01-14 20:42:34.009802.009802 cuda_h.py:19] end start_load_qkvogn_s_weight_l_27 cost 6.961822509765625e-05 seconds
DEBUG 01-14 20:42:34.009359.009359 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-14 20:42:34.009507.009507 cuda_h.py:10] start sllm_worker_task
DEBUG 01-14 20:42:34.009433.009433 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-14 20:42:34.010501.010501 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-14 20:42:34.010605.010605 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-14 20:42:34.011054.011054 cuda_h.py:19] end allocate_cuda_memory cost 0.001096487045288086 seconds
DEBUG 01-14 20:42:34.011679.011679 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-14 20:42:34.011303.011303 sllm_store_c.py:27] get device uuid map
DEBUG 01-14 20:42:34.011377.011377 sllm_store_c.py:29] call client load into gpu
DEBUG 01-14 20:42:34.011848.011848 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 8161e7cf-8ca5-478a-abed-24bc7794eb6e
DEBUG 01-14 20:42:34.011461.011461 client.py:106] call stub.LoadModelAsync
DEBUG 01-14 20:42:34.011473.011473 cuda_h.py:10] start self_attn
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-14 20:42:34.014364.014364 mlpmodule.py:1367]  experts func einsum cost 0.06914210319519043 s
INFO 01-14 20:42:34.014406.014406 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 8161e7cf-8ca5-478a-abed-24bc7794eb6e
DEBUG 01-14 20:42:34.015350.015350 cuda_h.py:19] end load_into_gpu_async cost 0.0035784244537353516 seconds
DEBUG 01-14 20:42:34.015775.015775 cuda_h.py:10] start restore_tensors2
DEBUG 01-14 20:42:34.015679.015679 cuda_h.py:19] end restore_tensors2 cost 7.748603820800781e-05 seconds
DEBUG 01-14 20:42:34.015388.015388 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0050275325775146484 seconds
INFO 01-14 20:42:34.015933.015933 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 8161e7cf-8ca5-478a-abed-24bc7794eb6e
DEBUG 01-14 20:42:34.015323.015323 cuda_h.py:19] end self_attn cost 0.003362417221069336 seconds
DEBUG 01-14 20:42:34.015154.015154 cuda_h.py:19] end iln_self_attn_paln cost 0.005925655364990234 seconds
DEBUG 01-14 20:42:34.015859.015859 cuda_h.py:10] start layer_moe_generate_mp_l_27
DEBUG 01-14 20:42:34.015337.015337 cuda_h.py:10] start gate
DEBUG 01-14 20:42:34.016241.016241 cuda_h.py:19] end gate cost 0.0006678104400634766 seconds
DEBUG 01-14 20:42:34.016024.016024 cuda_h.py:10] start experts_map_get
DEBUG 01-14 20:42:34.016876.016876 lmp.py:1615] 
DEBUG 01-14 20:42:34.016876.016876 lmp.py:1615] Expert Token Distribution & Device Allocation:
DEBUG 01-14 20:42:34.016585.016585 lmp.py:1616]   Total experts: 64
DEBUG 01-14 20:42:34.016950.016950 lmp.py:1617]   CPU experts: 32 (50%)
DEBUG 01-14 20:42:34.016501.016501 lmp.py:1618]   GPU experts: 32 (50%)
DEBUG 01-14 20:42:34.016104.016104 lmp.py:1619] 
DEBUG 01-14 20:42:34.016104.016104 lmp.py:1619]   Expert ID | Tokens | Device
DEBUG 01-14 20:42:34.016509.016509 lmp.py:1620]   -----------------------------------
DEBUG 01-14 20:42:34.017344.017344 lmp.py:1625]   Expert 20 |     14 | CPU
DEBUG 01-14 20:42:34.017987.017987 lmp.py:1625]   Expert 61 |     21 | CPU
DEBUG 01-14 20:42:34.017437.017437 lmp.py:1625]   Expert 62 |     41 | CPU
DEBUG 01-14 20:42:34.017842.017842 lmp.py:1625]   Expert 51 |     42 | CPU
DEBUG 01-14 20:42:34.017293.017293 lmp.py:1625]   Expert 11 |     49 | CPU
DEBUG 01-14 20:42:34.017505.017505 lmp.py:1625]   Expert  7 |     52 | CPU
DEBUG 01-14 20:42:34.017241.017241 lmp.py:1625]   Expert  3 |     55 | CPU
DEBUG 01-14 20:42:34.017692.017692 lmp.py:1625]   Expert 30 |     55 | CPU
DEBUG 01-14 20:42:34.017904.017904 lmp.py:1625]   Expert 29 |     58 | CPU
DEBUG 01-14 20:42:34.017640.017640 lmp.py:1625]   Expert 17 |     62 | CPU
DEBUG 01-14 20:42:34.017614.017614 lmp.py:1625]   Expert  9 |     65 | CPU
DEBUG 01-14 20:42:34.017350.017350 lmp.py:1625]   Expert  8 |     69 | CPU
DEBUG 01-14 20:42:34.017324.017324 lmp.py:1625]   Expert  6 |     73 | CPU
DEBUG 01-14 20:42:34.017775.017775 lmp.py:1625]   Expert 59 |     78 | CPU
DEBUG 01-14 20:42:34.017464.017464 lmp.py:1625]   Expert 63 |     86 | CPU
DEBUG 01-14 20:42:34.017200.017200 lmp.py:1625]   Expert 55 |     93 | CPU
DEBUG 01-14 20:42:34.017412.017412 lmp.py:1625]   Expert 48 |     96 | CPU
DEBUG 01-14 20:42:34.017148.017148 lmp.py:1625]   Expert 38 |     98 | CPU
DEBUG 01-14 20:42:34.017360.017360 lmp.py:1625]   Expert 49 |    110 | CPU
DEBUG 01-14 20:42:34.017334.017334 lmp.py:1625]   Expert 19 |    112 | CPU
DEBUG 01-14 20:42:34.017308.017308 lmp.py:1625]   Expert 24 |    113 | CPU
DEBUG 01-14 20:42:34.017044.017044 lmp.py:1625]   Expert 36 |    118 | CPU
DEBUG 01-14 20:42:34.017733.017733 lmp.py:1625]   Expert 50 |    119 | CPU
DEBUG 01-14 20:42:34.017661.017661 lmp.py:1625]   Expert 39 |    120 | CPU
DEBUG 01-14 20:42:34.017873.017873 lmp.py:1625]   Expert  4 |    121 | CPU
DEBUG 01-14 20:42:34.017086.017086 lmp.py:1625]   Expert 42 |    129 | CPU
DEBUG 01-14 20:42:34.017821.017821 lmp.py:1625]   Expert 22 |    137 | CPU
DEBUG 01-14 20:42:34.017795.017795 lmp.py:1625]   Expert 34 |    137 | CPU
DEBUG 01-14 20:42:34.017293.017293 lmp.py:1625]   Expert 41 |    137 | CPU
DEBUG 01-14 20:42:34.017028.017028 lmp.py:1625]   Expert 15 |    153 | CPU
DEBUG 01-14 20:42:34.017241.017241 lmp.py:1625]   Expert 37 |    156 | CPU
DEBUG 01-14 20:42:34.017738.017738 lmp.py:1625]   Expert 60 |    162 | CPU
DEBUG 01-14 20:42:34.017666.017666 lmp.py:1625]   Expert 56 |    165 | GPU
DEBUG 01-14 20:42:34.017547.017547 lmp.py:1625]   Expert 21 |    168 | GPU
DEBUG 01-14 20:42:34.017475.017475 lmp.py:1625]   Expert 23 |    170 | GPU
DEBUG 01-14 20:42:34.017402.017402 lmp.py:1625]   Expert 44 |    174 | GPU
DEBUG 01-14 20:42:34.017330.017330 lmp.py:1625]   Expert 33 |    177 | GPU
DEBUG 01-14 20:42:34.017781.017781 lmp.py:1625]   Expert 16 |    179 | GPU
DEBUG 01-14 20:42:34.017470.017470 lmp.py:1625]   Expert 47 |    183 | GPU
DEBUG 01-14 20:42:34.017398.017398 lmp.py:1625]   Expert  1 |    185 | GPU
DEBUG 01-14 20:42:34.017279.017279 lmp.py:1625]   Expert 43 |    190 | GPU
DEBUG 01-14 20:42:34.017446.017446 lmp.py:1625]   Expert 53 |    204 | GPU
DEBUG 01-14 20:42:34.017373.017373 lmp.py:1625]   Expert 13 |    205 | GPU
DEBUG 01-14 20:42:34.017301.017301 lmp.py:1625]   Expert 32 |    224 | GPU
DEBUG 01-14 20:42:34.017229.017229 lmp.py:1625]   Expert 28 |    226 | GPU
DEBUG 01-14 20:42:34.017156.017156 lmp.py:1625]   Expert 12 |    228 | GPU
DEBUG 01-14 20:42:34.017084.017084 lmp.py:1625]   Expert 25 |    244 | GPU
DEBUG 01-14 20:42:34.017535.017535 lmp.py:1625]   Expert 31 |    244 | GPU
DEBUG 01-14 20:42:34.017224.017224 lmp.py:1625]   Expert  2 |    247 | GPU
DEBUG 01-14 20:42:34.017914.017914 lmp.py:1625]   Expert 26 |    259 | GPU
DEBUG 01-14 20:42:34.017080.017080 lmp.py:1625]   Expert  0 |    262 | GPU
DEBUG 01-14 20:42:34.017769.017769 lmp.py:1625]   Expert 18 |    267 | GPU
DEBUG 01-14 20:42:34.017935.017935 lmp.py:1625]   Expert 54 |    274 | GPU
DEBUG 01-14 20:42:34.017625.017625 lmp.py:1625]   Expert 10 |    276 | GPU
DEBUG 01-14 20:42:34.017744.017744 lmp.py:1625]   Expert 57 |    276 | GPU
DEBUG 01-14 20:42:34.017434.017434 lmp.py:1625]   Expert 58 |    281 | GPU
DEBUG 01-14 20:42:34.017123.017123 lmp.py:1625]   Expert 40 |    331 | GPU
DEBUG 01-14 20:42:34.017051.017051 lmp.py:1625]   Expert 45 |    377 | GPU
DEBUG 01-14 20:42:34.017217.017217 lmp.py:1625]   Expert 35 |    436 | GPU
DEBUG 01-14 20:42:34.017906.017906 lmp.py:1625]   Expert  5 |    479 | GPU
DEBUG 01-14 20:42:34.017072.017072 lmp.py:1625]   Expert 46 |    498 | GPU
DEBUG 01-14 20:42:34.018762.018762 lmp.py:1625]   Expert 27 |    513 | GPU
DEBUG 01-14 20:42:34.018643.018643 lmp.py:1625]   Expert 52 |    565 | GPU
DEBUG 01-14 20:42:34.018524.018524 lmp.py:1625]   Expert 14 |    850 | GPU
DEBUG 01-14 20:42:34.018406.018406 lmp.py:1626] 
DEBUG 01-14 20:42:34.018406.018406 lmp.py:1626]   CPU total tokens: 2931 (23.9%)
DEBUG 01-14 20:42:34.018526.018526 lmp.py:1627]   GPU total tokens: 9357 (76.1%)
DEBUG 01-14 20:42:34.018698.018698 cuda_h.py:19] end experts_map_get cost 0.0015223026275634766 seconds
DEBUG 01-14 20:42:34.018502.018502 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-14 20:42:34.018060.018060 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-14 20:42:34.018026.018026 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-14 20:42:34.018181.018181 cuda_h.py:19] end allocate_cuda_memory cost 0.0004673004150390625 seconds
DEBUG 01-14 20:42:34.018693.018693 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-14 20:42:34.018926.018926 sllm_store_c.py:27] get device uuid map
DEBUG 01-14 20:42:34.019497.019497 sllm_store_c.py:29] call client load into gpu
DEBUG 01-14 20:42:34.019385.019385 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, cb44019c-d134-4f6c-91d4-593226c2adcd
DEBUG 01-14 20:42:34.019034.019034 client.py:106] call stub.LoadModelAsync
INFO 01-14 20:42:34.022615.022615 client.py:127] Model loaded
DEBUG 01-14 20:42:34.022299.022299 cuda_h.py:10] start restore2model
DEBUG 01-14 20:42:34.022165.022165 cuda_h.py:19] end restore2model cost 0.0003266334533691406 seconds
DEBUG 01-14 20:42:34.022312.022312 cuda_h.py:19] end sllm_worker_task cost 0.012972593307495117 seconds
INFO 01-14 20:42:34.023049.023049 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, cb44019c-d134-4f6c-91d4-593226c2adcd
DEBUG 01-14 20:42:34.023469.023469 cuda_h.py:19] end load_into_gpu_async cost 0.0043294429779052734 seconds
DEBUG 01-14 20:42:34.023364.023364 cuda_h.py:10] start restore_tensors2
DEBUG 01-14 20:42:34.023992.023992 cuda_h.py:19] end restore_tensors2 cost 0.0003311634063720703 seconds
DEBUG 01-14 20:42:34.023629.023629 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.005486965179443359 seconds
DEBUG 01-14 20:42:34.023538.023538 cuda_h.py:10] start restore2model
DEBUG 01-14 20:42:34.026371.026371 cuda_h.py:19] end restore2model cost 0.0025167465209960938 seconds
DEBUG 01-14 20:42:34.026916.026916 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.008177518844604492 seconds
DEBUG 01-14 20:42:34.026778.026778 cuda_h.py:10] start gpu_sexperts
DEBUG 01-14 20:42:34.026312.026312 cuda_h.py:19] end gpu_sexperts cost 0.00028705596923828125 seconds
DEBUG 01-14 20:42:34.026088.026088 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-14 20:42:34.026222.026222 lmp.py:1683] 
DEBUG 01-14 20:42:34.026222.026222 lmp.py:1683]   Computing 32 experts on CPU...
DEBUG 01-14 20:42:34.026204.026204 cuda_h.py:19] end cpu_experts_submit cost 5.698204040527344e-05 seconds
DEBUG 01-14 20:42:34.026238.026238 cuda_h.py:10] start experts_func_mgpu_group_pad
DEBUG 01-14 20:42:34.037785.037785 mlpmodule.py:1460] group tensors cost 0.010003328323364258 s
DEBUG 01-14 20:42:34.038048.038048 cuda_h.py:10] start move_flat_hidden2cpu
DEBUG 01-14 20:42:34.040020.040020 cuda_h.py:19] end experts_func_mgpu_group_pad cost 0.01361989974975586 seconds
DEBUG 01-14 20:42:34.042245.042245 cuda_h.py:10] start gpu_group_list
DEBUG 01-14 20:42:34.042022.042022 cuda_h.py:19] end gpu_group_list cost 0.0005471706390380859 seconds
DEBUG 01-14 20:42:34.043890.043890 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-14 20:42:34.043151.043151 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.4557113647460938e-05 seconds
DEBUG 01-14 20:42:34.043048.043048 cuda_h.py:10] start wait_experts
INFO 01-14 20:42:34.043480.043480 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, cb44019c-d134-4f6c-91d4-593226c2adcd
DEBUG 01-14 20:42:34.044066.044066 cuda_h.py:19] end move_flat_hidden2cpu cost 0.0062408447265625 seconds
DEBUG 01-14 20:42:34.046660.046660 mlpmodule.py:1533] pad cost 0.0015304088592529297 s
DEBUG 01-14 20:42:34.046941.046941 mlpmodule.py:1539] create cpu tensor cost 3.62396240234375e-05 s
DEBUG 01-14 20:42:34.048828.048828 mlpmodule.py:1544] move to cpu cost 0.001917123794555664 s
DEBUG 01-14 20:42:34.057295.057295 mlpmodule.py:1558] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-14 20:42:34.057003.057003 mlpmodule.py:1559] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-14 20:42:34.057231.057231 mlpmodule.py:1564] group_w3 first element: -0.0024261474609375
WARNING 01-14 20:42:34.057216.057216 mlpmodule.py:1574] start einsum2
DEBUG 01-14 20:42:34.074698.074698 mlpmodule.py:1584] group einsum cost 0.026304244995117188 s
DEBUG 01-14 20:42:34.075501.075501 mlpmodule.py:1593] cpy2cputensor cost 0.0006399154663085938 s
DEBUG 01-14 20:42:34.075185.075185 cuda_h.py:10] start move_outputs
DEBUG 01-14 20:42:34.078215.078215 cuda_h.py:19] end move_outputs cost 0.0026597976684570312 seconds
INFO 01-14 20:42:34.080167.080167 client.py:127] Model loaded
DEBUG 01-14 20:42:34.081080.081080 cuda_h.py:19] end wait_experts cost 0.03768181800842285 seconds
DEBUG 01-14 20:42:34.081141.081141 cuda_h.py:10] start gpu_experts
DEBUG 01-14 20:42:34.081679.081679 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-14 20:42:34.082980.082980 cuda_h.py:19] end wait_cetm_experts cost 0.0008161067962646484 seconds
DEBUG 01-14 20:42:34.082380.082380 cuda_h.py:10] start gpu_group_einsum_mp_multi_list
DEBUG 01-14 20:42:34.082189.082189 cuda_h.py:10] start gpu_group_tensor
DEBUG 01-14 20:42:34.082331.082331 cuda_h.py:19] end gpu_group_tensor cost 0.00024771690368652344 seconds
DEBUG 01-14 20:42:34.082540.082540 cuda_h.py:10] start gpu_group_einsum
DEBUG 01-14 20:42:34.083612.083612 cuda_h.py:19] end gpu_group_einsum cost 0.0005314350128173828 seconds
DEBUG 01-14 20:42:34.083398.083398 cuda_h.py:10] start gpu_final_hidden_states_scatter
DEBUG 01-14 20:42:34.083095.083095 cuda_h.py:10] start all_expert_outputs_slices
DEBUG 01-14 20:42:34.083483.083483 cuda_h.py:19] end all_expert_outputs_slices cost 0.00028896331787109375 seconds
DEBUG 01-14 20:42:34.083769.083769 cuda_h.py:10] start concat_expert_out
DEBUG 01-14 20:42:34.083137.083137 cuda_h.py:19] end concat_expert_out cost 5.936622619628906e-05 seconds
DEBUG 01-14 20:42:34.083848.083848 cuda_h.py:10] start index_scatter
DEBUG 01-14 20:42:34.083798.083798 cuda_h.py:19] end index_scatter cost 7.033348083496094e-05 seconds
DEBUG 01-14 20:42:34.084177.084177 cuda_h.py:19] end gpu_final_hidden_states_scatter cost 0.0006728172302246094 seconds
DEBUG 01-14 20:42:34.084776.084776 cuda_h.py:19] end gpu_experts cost 0.002883434295654297 seconds
DEBUG 01-14 20:42:34.084432.084432 cuda_h.py:10] start all_expert_weight_slices
DEBUG 01-14 20:42:34.085183.085183 cuda_h.py:19] end all_expert_weight_slices cost 0.001013040542602539 seconds
DEBUG 01-14 20:42:34.085290.085290 cuda_h.py:10] start cpuoutputsdeal
DEBUG 01-14 20:42:34.085742.085742 cuda_h.py:10] start index_scatter
DEBUG 01-14 20:42:34.085209.085209 cuda_h.py:19] end index_scatter cost 4.935264587402344e-05 seconds
DEBUG 01-14 20:42:34.085640.085640 cuda_h.py:19] end cpuoutputsdeal cost 0.0005450248718261719 seconds
DEBUG 01-14 20:42:34.085789.085789 cuda_h.py:19] end layer_moe_generate_mp_l_27 cost 0.07007002830505371 seconds
DEBUG 01-14 20:42:34.086617.086617 cuda_h.py:19] end prefill_layer cost 0.07669687271118164 seconds
DEBUG 01-14 20:42:34.086546.086546 lmp.py:1551] -------------------------------- end prefill layer 26 --------------------------------
DEBUG 01-14 20:42:34.086964.086964 cuda_h.py:10] start prefill_layer
DEBUG 01-14 20:42:34.086812.086812 lmp.py:1494] -------------------------------- start prefill layer 27 --------------------------------
DEBUG 01-14 20:42:34.086992.086992 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-14 20:42:34.086200.086200 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-14 20:42:34.086191.086191 cuda_h.py:10] start self_attn
DEBUG 01-14 20:42:34.090305.090305 mlpmodule.py:1367]  experts func einsum cost 0.06294393539428711 s
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-14 20:42:34.091508.091508 cuda_h.py:19] end self_attn cost 0.004662752151489258 seconds
DEBUG 01-14 20:42:34.091433.091433 cuda_h.py:19] end iln_self_attn_paln cost 0.005415916442871094 seconds
DEBUG 01-14 20:42:34.091905.091905 cuda_h.py:10] start layer_moe_generate_mp_l_28
DEBUG 01-14 20:42:34.091714.091714 cuda_h.py:10] start gate
DEBUG 01-14 20:42:34.092220.092220 cuda_h.py:19] end gate cost 0.0006115436553955078 seconds
DEBUG 01-14 20:42:34.092195.092195 cuda_h.py:10] start experts_map_get
DEBUG 01-14 20:42:34.092808.092808 lmp.py:1615] 
DEBUG 01-14 20:42:34.092808.092808 lmp.py:1615] Expert Token Distribution & Device Allocation:
DEBUG 01-14 20:42:34.093802.093802 lmp.py:1616]   Total experts: 64
DEBUG 01-14 20:42:34.093167.093167 lmp.py:1617]   CPU experts: 32 (50%)
DEBUG 01-14 20:42:34.093671.093671 lmp.py:1618]   GPU experts: 32 (50%)
DEBUG 01-14 20:42:34.093076.093076 lmp.py:1619] 
DEBUG 01-14 20:42:34.093076.093076 lmp.py:1619]   Expert ID | Tokens | Device
DEBUG 01-14 20:42:34.093242.093242 lmp.py:1620]   -----------------------------------
DEBUG 01-14 20:42:34.093839.093839 lmp.py:1625]   Expert 47 |     61 | CPU
DEBUG 01-14 20:42:34.093482.093482 lmp.py:1625]   Expert 48 |     64 | CPU
DEBUG 01-14 20:42:34.093171.093171 lmp.py:1625]   Expert 18 |     74 | CPU
DEBUG 01-14 20:42:34.093860.093860 lmp.py:1625]   Expert 44 |     82 | CPU
DEBUG 01-14 20:42:34.093788.093788 lmp.py:1625]   Expert 54 |     82 | CPU
DEBUG 01-14 20:42:34.093477.093477 lmp.py:1625]   Expert 45 |     88 | CPU
DEBUG 01-14 20:42:34.093882.093882 lmp.py:1625]   Expert 23 |     89 | CPU
DEBUG 01-14 20:42:34.093571.093571 lmp.py:1625]   Expert 20 |     94 | CPU
DEBUG 01-14 20:42:34.093022.093022 lmp.py:1625]   Expert 11 |    103 | CPU
DEBUG 01-14 20:42:34.093473.093473 lmp.py:1625]   Expert 61 |    104 | CPU
DEBUG 01-14 20:42:34.093686.093686 lmp.py:1625]   Expert 36 |    115 | CPU
DEBUG 01-14 20:42:34.093660.093660 lmp.py:1625]   Expert 31 |    116 | CPU
DEBUG 01-14 20:42:34.093110.093110 lmp.py:1625]   Expert  5 |    120 | CPU
DEBUG 01-14 20:42:34.093323.093323 lmp.py:1625]   Expert 24 |    121 | CPU
DEBUG 01-14 20:42:34.093297.093297 lmp.py:1625]   Expert 10 |    124 | CPU
DEBUG 01-14 20:42:34.093271.093271 lmp.py:1625]   Expert 49 |    125 | CPU
DEBUG 01-14 20:42:34.093245.093245 lmp.py:1625]   Expert 42 |    127 | CPU
DEBUG 01-14 20:42:34.093696.093696 lmp.py:1625]   Expert 33 |    132 | CPU
DEBUG 01-14 20:42:34.093670.093670 lmp.py:1625]   Expert 43 |    132 | CPU
DEBUG 01-14 20:42:34.093644.093644 lmp.py:1625]   Expert  6 |    133 | CPU
DEBUG 01-14 20:42:34.093380.093380 lmp.py:1625]   Expert 56 |    134 | CPU
DEBUG 01-14 20:42:34.093877.093877 lmp.py:1625]   Expert 17 |    135 | CPU
DEBUG 01-14 20:42:34.093851.093851 lmp.py:1625]   Expert 57 |    140 | CPU
DEBUG 01-14 20:42:34.093587.093587 lmp.py:1625]   Expert 12 |    158 | CPU
DEBUG 01-14 20:42:34.093561.093561 lmp.py:1625]   Expert  0 |    160 | CPU
DEBUG 01-14 20:42:34.093773.093773 lmp.py:1625]   Expert 46 |    161 | CPU
DEBUG 01-14 20:42:34.093509.093509 lmp.py:1625]   Expert 51 |    161 | CPU
DEBUG 01-14 20:42:34.093483.093483 lmp.py:1625]   Expert 38 |    163 | CPU
DEBUG 01-14 20:42:34.093980.093980 lmp.py:1625]   Expert 26 |    164 | CPU
DEBUG 01-14 20:42:34.093192.093192 lmp.py:1625]   Expert 59 |    166 | CPU
DEBUG 01-14 20:42:34.093643.093643 lmp.py:1625]   Expert 35 |    168 | CPU
DEBUG 01-14 20:42:34.093571.093571 lmp.py:1625]   Expert 13 |    173 | CPU
DEBUG 01-14 20:42:34.093545.093545 lmp.py:1625]   Expert 55 |    174 | GPU
DEBUG 01-14 20:42:34.093281.093281 lmp.py:1625]   Expert 50 |    175 | GPU
DEBUG 01-14 20:42:34.093778.093778 lmp.py:1625]   Expert 40 |    176 | GPU
DEBUG 01-14 20:42:34.093513.093513 lmp.py:1625]   Expert 58 |    179 | GPU
DEBUG 01-14 20:42:34.093011.093011 lmp.py:1625]   Expert 16 |    180 | GPU
DEBUG 01-14 20:42:34.093985.093985 lmp.py:1625]   Expert  7 |    181 | GPU
DEBUG 01-14 20:42:34.093720.093720 lmp.py:1625]   Expert 30 |    190 | GPU
DEBUG 01-14 20:42:34.093694.093694 lmp.py:1625]   Expert 15 |    198 | GPU
DEBUG 01-14 20:42:34.093192.093192 lmp.py:1625]   Expert  1 |    203 | GPU
DEBUG 01-14 20:42:34.093166.093166 lmp.py:1625]   Expert 14 |    203 | GPU
DEBUG 01-14 20:42:34.093093.093093 lmp.py:1625]   Expert 32 |    212 | GPU
DEBUG 01-14 20:42:34.093306.093306 lmp.py:1625]   Expert  4 |    216 | GPU
DEBUG 01-14 20:42:34.093041.093041 lmp.py:1625]   Expert  3 |    221 | GPU
DEBUG 01-14 20:42:34.093777.093777 lmp.py:1625]   Expert 28 |    230 | GPU
DEBUG 01-14 20:42:34.093274.093274 lmp.py:1625]   Expert 25 |    238 | GPU
DEBUG 01-14 20:42:34.093248.093248 lmp.py:1625]   Expert 34 |    238 | GPU
DEBUG 01-14 20:42:34.093984.093984 lmp.py:1625]   Expert 39 |    244 | GPU
DEBUG 01-14 20:42:34.093720.093720 lmp.py:1625]   Expert 22 |    248 | GPU
DEBUG 01-14 20:42:34.093455.093455 lmp.py:1625]   Expert 52 |    255 | GPU
DEBUG 01-14 20:42:34.093668.093668 lmp.py:1625]   Expert 60 |    264 | GPU
DEBUG 01-14 20:42:34.093357.093357 lmp.py:1625]   Expert  2 |    266 | GPU
DEBUG 01-14 20:42:34.093854.093854 lmp.py:1625]   Expert 41 |    286 | GPU
DEBUG 01-14 20:42:34.093067.093067 lmp.py:1625]   Expert 27 |    290 | GPU
DEBUG 01-14 20:42:34.093802.093802 lmp.py:1625]   Expert 21 |    295 | GPU
DEBUG 01-14 20:42:34.094776.094776 lmp.py:1625]   Expert 63 |    296 | GPU
DEBUG 01-14 20:42:34.094750.094750 lmp.py:1625]   Expert 62 |    302 | GPU
DEBUG 01-14 20:42:34.094486.094486 lmp.py:1625]   Expert 29 |    303 | GPU
DEBUG 01-14 20:42:34.094460.094460 lmp.py:1625]   Expert  8 |    340 | GPU
DEBUG 01-14 20:42:34.094196.094196 lmp.py:1625]   Expert 37 |    343 | GPU
DEBUG 01-14 20:42:34.094600.094600 lmp.py:1625]   Expert 53 |    344 | GPU
DEBUG 01-14 20:42:34.094813.094813 lmp.py:1625]   Expert 19 |    459 | GPU
DEBUG 01-14 20:42:34.094787.094787 lmp.py:1625]   Expert  9 |    570 | GPU
DEBUG 01-14 20:42:34.094238.094238 lmp.py:1626] 
DEBUG 01-14 20:42:34.094238.094238 lmp.py:1626]   CPU total tokens: 3969 (32.3%)
DEBUG 01-14 20:42:34.094404.094404 lmp.py:1627]   GPU total tokens: 8319 (67.7%)
DEBUG 01-14 20:42:34.094385.094385 cuda_h.py:19] end experts_map_get cost 0.0014803409576416016 seconds
DEBUG 01-14 20:42:34.094327.094327 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-14 20:42:34.094693.094693 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-14 20:42:34.094228.094228 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-14 20:42:34.094187.094187 cuda_h.py:19] end allocate_cuda_memory cost 0.0003235340118408203 seconds
DEBUG 01-14 20:42:34.094898.094898 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-14 20:42:34.094515.094515 sllm_store_c.py:27] get device uuid map
DEBUG 01-14 20:42:34.094192.094192 sllm_store_c.py:29] call client load into gpu
DEBUG 01-14 20:42:34.094464.094464 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, c8de9492-ad4c-4333-bd02-e57f85e0586c
DEBUG 01-14 20:42:34.095008.095008 client.py:106] call stub.LoadModelAsync
INFO 01-14 20:42:34.097523.097523 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, c8de9492-ad4c-4333-bd02-e57f85e0586c
DEBUG 01-14 20:42:34.097097.097097 cuda_h.py:19] end load_into_gpu_async cost 0.0027310848236083984 seconds
DEBUG 01-14 20:42:34.097252.097252 cuda_h.py:10] start restore_tensors2
DEBUG 01-14 20:42:34.098106.098106 cuda_h.py:19] end restore_tensors2 cost 0.0005257129669189453 seconds
DEBUG 01-14 20:42:34.098532.098532 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.004069805145263672 seconds
DEBUG 01-14 20:42:34.098369.098369 cuda_h.py:10] start restore2model
DEBUG 01-14 20:42:34.102157.102157 cuda_h.py:19] end restore2model cost 0.0039098262786865234 seconds
DEBUG 01-14 20:42:34.102020.102020 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.008205413818359375 seconds
DEBUG 01-14 20:42:34.102452.102452 cuda_h.py:10] start gpu_sexperts
DEBUG 01-14 20:42:34.102214.102214 cuda_h.py:19] end gpu_sexperts cost 0.00037789344787597656 seconds
DEBUG 01-14 20:42:34.102303.102303 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-14 20:42:34.103787.103787 lmp.py:1683] 
DEBUG 01-14 20:42:34.103787.103787 lmp.py:1683]   Computing 32 experts on CPU...
DEBUG 01-14 20:42:34.103472.103472 cuda_h.py:19] end cpu_experts_submit cost 8.296966552734375e-05 seconds
DEBUG 01-14 20:42:34.103096.103096 cuda_h.py:10] start experts_func_mgpu_group_pad
DEBUG 01-14 20:42:34.114401.114401 mlpmodule.py:1460] group tensors cost 0.01043558120727539 s
DEBUG 01-14 20:42:34.115092.115092 cuda_h.py:10] start move_flat_hidden2cpu
DEBUG 01-14 20:42:34.119120.119120 cuda_h.py:19] end experts_func_mgpu_group_pad cost 0.016052722930908203 seconds
DEBUG 01-14 20:42:34.122995.122995 cuda_h.py:10] start gpu_group_list
DEBUG 01-14 20:42:34.123573.123573 cuda_h.py:19] end gpu_group_list cost 0.0010614395141601562 seconds
DEBUG 01-14 20:42:34.123352.123352 cuda_h.py:19] end move_flat_hidden2cpu cost 0.008436918258666992 seconds
DEBUG 01-14 20:42:34.124112.124112 cuda_h.py:10] start wait_experts
INFO 01-14 20:42:34.124430.124430 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, c8de9492-ad4c-4333-bd02-e57f85e0586c
DEBUG 01-14 20:42:34.126187.126187 mlpmodule.py:1533] pad cost 0.0022253990173339844 s
DEBUG 01-14 20:42:34.126583.126583 mlpmodule.py:1539] create cpu tensor cost 4.410743713378906e-05 s
DEBUG 01-14 20:42:34.128541.128541 mlpmodule.py:1544] move to cpu cost 0.0020585060119628906 s
DEBUG 01-14 20:42:34.138694.138694 mlpmodule.py:1558] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-14 20:42:34.138488.138488 mlpmodule.py:1559] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-14 20:42:34.138432.138432 mlpmodule.py:1564] group_w3 first element: -0.006439208984375
WARNING 01-14 20:42:34.138615.138615 mlpmodule.py:1574] start einsum2
INFO 01-14 20:42:34.151500.151500 client.py:127] Model loaded
DEBUG 01-14 20:42:34.152973.152973 cuda_h.py:19] end wait_experts cost 0.027674198150634766 seconds
DEBUG 01-14 20:42:34.152141.152141 cuda_h.py:10] start gpu_experts
DEBUG 01-14 20:42:34.152766.152766 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-14 20:42:34.156166.156166 mlpmodule.py:1584] group einsum cost 0.027628660202026367 s
DEBUG 01-14 20:42:34.157319.157319 mlpmodule.py:1593] cpy2cputensor cost 0.0007035732269287109 s
DEBUG 01-14 20:42:34.157818.157818 cuda_h.py:10] start move_outputs
DEBUG 01-14 20:42:34.159681.159681 cuda_h.py:19] end move_outputs cost 0.0020058155059814453 seconds
DEBUG 01-14 20:42:34.163075.163075 cuda_h.py:19] end wait_cetm_experts cost 0.010710000991821289 seconds
DEBUG 01-14 20:42:34.163266.163266 cuda_h.py:10] start gpu_group_einsum_mp_multi_list
DEBUG 01-14 20:42:34.163274.163274 cuda_h.py:10] start gpu_group_tensor
DEBUG 01-14 20:42:34.163654.163654 cuda_h.py:19] end gpu_group_tensor cost 0.0002467632293701172 seconds
DEBUG 01-14 20:42:34.163340.163340 cuda_h.py:10] start gpu_group_einsum
DEBUG 01-14 20:42:34.164347.164347 cuda_h.py:19] end gpu_group_einsum cost 0.0005538463592529297 seconds
DEBUG 01-14 20:42:34.164213.164213 cuda_h.py:10] start gpu_final_hidden_states_scatter
DEBUG 01-14 20:42:34.164725.164725 cuda_h.py:10] start all_expert_outputs_slices
DEBUG 01-14 20:42:34.164650.164650 cuda_h.py:19] end all_expert_outputs_slices cost 0.00029850006103515625 seconds
DEBUG 01-14 20:42:34.164121.164121 cuda_h.py:10] start concat_expert_out
DEBUG 01-14 20:42:34.164873.164873 cuda_h.py:19] end concat_expert_out cost 6.079673767089844e-05 seconds
DEBUG 01-14 20:42:34.165438.165438 cuda_h.py:10] start index_scatter
DEBUG 01-14 20:42:34.165303.165303 cuda_h.py:19] end index_scatter cost 7.677078247070312e-05 seconds
DEBUG 01-14 20:42:34.165874.165874 cuda_h.py:19] end gpu_final_hidden_states_scatter cost 0.0006873607635498047 seconds
DEBUG 01-14 20:42:34.165744.165744 cuda_h.py:19] end gpu_experts cost 0.013000965118408203 seconds
DEBUG 01-14 20:42:34.165592.165592 cuda_h.py:10] start all_expert_weight_slices
DEBUG 01-14 20:42:34.166115.166115 cuda_h.py:19] end all_expert_weight_slices cost 0.0009515285491943359 seconds
DEBUG 01-14 20:42:34.166792.166792 cuda_h.py:10] start cpuoutputsdeal
DEBUG 01-14 20:42:34.166284.166284 cuda_h.py:10] start index_scatter
DEBUG 01-14 20:42:34.166943.166943 cuda_h.py:19] end index_scatter cost 5.030632019042969e-05 seconds
DEBUG 01-14 20:42:34.166374.166374 cuda_h.py:19] end cpuoutputsdeal cost 0.0005407333374023438 seconds
DEBUG 01-14 20:42:34.166092.166092 cuda_h.py:19] end layer_moe_generate_mp_l_28 cost 0.0749654769897461 seconds
DEBUG 01-14 20:42:34.167483.167483 cuda_h.py:19] end prefill_layer cost 0.0809319019317627 seconds
DEBUG 01-14 20:42:34.167140.167140 lmp.py:1551] -------------------------------- end prefill layer 27 --------------------------------
DEBUG 01-14 20:42:34.167373.167373 cuda_h.py:19] end prefill cost 2.4509289264678955 seconds
DEBUG 01-14 20:42:34.194046.194046 mlpmodule.py:1367]  experts func einsum cost 0.09047603607177734 s
DEBUG 01-14 20:42:36.341607.341607 cuda_h.py:10] start generate_input_ids
generate input ids cost 0.09091997146606445 s
DEBUG 01-14 20:42:36.700933.700933 cuda_h.py:19] end generate_input_ids cost 0.35822224617004395 seconds
DEBUG 01-14 20:42:36.701039.701039 cuda_h.py:10] start init_cache
DEBUG 01-14 20:42:36.701296.701296 cuda_h.py:19] end init_cache cost 9.012222290039062e-05 seconds
DEBUG 01-14 20:42:39.133782.133782 cuda_h.py:10] start init_meta_layer
DEBUG 01-14 20:42:39.135279.135279 cuda_h.py:19] end init_meta_layer cost 1.1920928955078125e-05 seconds
DEBUG 01-14 20:42:39.135675.135675 cuda_h.py:10] start init_weights
DEBUG 01-14 20:42:39.135345.135345 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-14 20:42:39.135492.135492 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-14 20:42:39.137647.137647 cuda_h.py:19] end allocate_cuda_memory cost 0.002224445343017578 seconds
DEBUG 01-14 20:42:39.137908.137908 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-14 20:42:39.137810.137810 sllm_store_c.py:27] get device uuid map
DEBUG 01-14 20:42:39.137917.137917 sllm_store_c.py:29] call client load into gpu
DEBUG 01-14 20:42:39.138488.138488 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, ffffab38-cad6-446d-83bf-b0891c117a62
DEBUG 01-14 20:42:39.138677.138677 client.py:106] call stub.LoadModelAsync
INFO 01-14 20:42:39.139176.139176 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, ffffab38-cad6-446d-83bf-b0891c117a62
DEBUG 01-14 20:42:39.139876.139876 cuda_h.py:19] end load_into_gpu_async cost 0.0019659996032714844 seconds
DEBUG 01-14 20:42:39.139832.139832 cuda_h.py:10] start restore_tensors2
DEBUG 01-14 20:42:39.140593.140593 cuda_h.py:19] end restore_tensors2 cost 0.0001010894775390625 seconds
DEBUG 01-14 20:42:39.140985.140985 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.00466156005859375 seconds
DEBUG 01-14 20:42:39.140204.140204 cuda_h.py:10] start restore2model
DEBUG 01-14 20:42:39.140376.140376 cuda_h.py:19] end restore2model cost 0.0001735687255859375 seconds
INFO 01-14 20:42:39.140901.140901 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, ffffab38-cad6-446d-83bf-b0891c117a62
INFO 01-14 20:42:39.218381.218381 client.py:127] Model loaded
DEBUG 01-14 20:42:39.218453.218453 cuda_h.py:10] start load_qkvogns_weight_l_0
DEBUG 01-14 20:42:39.218291.218291 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-14 20:42:39.219315.219315 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-14 20:42:39.219377.219377 cuda_h.py:19] end allocate_cuda_memory cost 0.0003757476806640625 seconds
DEBUG 01-14 20:42:39.219336.219336 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-14 20:42:39.219637.219637 sllm_store_c.py:27] get device uuid map
DEBUG 01-14 20:42:39.219289.219289 sllm_store_c.py:29] call client load into gpu
DEBUG 01-14 20:42:39.219331.219331 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 4a8bb9a3-629f-48a7-9d2a-d7776ccd0dd4
DEBUG 01-14 20:42:39.220270.220270 client.py:106] call stub.LoadModelAsync
INFO 01-14 20:42:39.221548.221548 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 4a8bb9a3-629f-48a7-9d2a-d7776ccd0dd4
DEBUG 01-14 20:42:39.221427.221427 cuda_h.py:19] end load_into_gpu_async cost 0.002049684524536133 seconds
DEBUG 01-14 20:42:39.221351.221351 cuda_h.py:10] start restore_tensors2
DEBUG 01-14 20:42:39.222259.222259 cuda_h.py:19] end restore_tensors2 cost 0.00013494491577148438 seconds
DEBUG 01-14 20:42:39.222573.222573 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.003183603286743164 seconds
INFO 01-14 20:42:39.222337.222337 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 4a8bb9a3-629f-48a7-9d2a-d7776ccd0dd4
INFO 01-14 20:42:39.238791.238791 client.py:127] Model loaded
DEBUG 01-14 20:42:39.238742.238742 cuda_h.py:10] start restore2model
DEBUG 01-14 20:42:39.239204.239204 cuda_h.py:19] end restore2model cost 0.0008394718170166016 seconds
DEBUG 01-14 20:42:39.240712.240712 cuda_h.py:19] end load_qkvogns_weight_l_0 cost 0.021091461181640625 seconds
DEBUG 01-14 20:42:39.240304.240304 cuda_h.py:19] end init_weights cost 0.10460329055786133 seconds
DEBUG 01-14 20:42:39.240969.240969 cuda_h.py:10] start copy_emodel
DEBUG 01-14 20:42:39.992528.992528 cuda_h.py:19] end copy_emodel cost 0.7519559860229492 seconds
DEBUG 01-14 20:42:39.993528.993528 cuda_h.py:10] start init_inputs_tokens
DEBUG 01-14 20:42:39.993268.993268 cuda_h.py:19] end init_inputs_tokens cost 0.0002751350402832031 seconds
DEBUG 01-14 20:42:39.993945.993945 cuda_h.py:10] start prefill
DEBUG 01-14 20:42:39.993993.993993 cuda_h.py:10] start prefill_layer
DEBUG 01-14 20:42:39.993881.993881 lmp.py:1494] -------------------------------- start prefill layer 0 --------------------------------
DEBUG 01-14 20:42:39.993815.993815 cuda_h.py:10] start start_load_qkvogn_s_weight_l_1
DEBUG 01-14 20:42:39.993849.993849 cuda_h.py:10] start start_load_qkvogn_s_weight_l_1
DEBUG 01-14 20:42:39.993600.993600 cuda_h.py:19] end start_load_qkvogn_s_weight_l_1 cost 3.457069396972656e-05 seconds
DEBUG 01-14 20:42:39.993110.993110 cuda_h.py:19] end start_load_qkvogn_s_weight_l_1 cost 6.699562072753906e-05 seconds
DEBUG 01-14 20:42:39.993230.993230 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-14 20:42:39.993126.993126 cuda_h.py:10] start sllm_worker_task
DEBUG 01-14 20:42:39.993918.993918 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-14 20:42:39.993816.993816 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-14 20:42:39.994801.994801 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-14 20:42:39.994793.994793 cuda_h.py:19] end allocate_cuda_memory cost 0.00033402442932128906 seconds
DEBUG 01-14 20:42:39.994972.994972 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-14 20:42:39.994557.994557 sllm_store_c.py:27] get device uuid map
DEBUG 01-14 20:42:39.994916.994916 sllm_store_c.py:29] call client load into gpu
DEBUG 01-14 20:42:39.994056.994056 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, c658d4c6-e6d8-410d-ae33-1b942f265269
DEBUG 01-14 20:42:39.994530.994530 client.py:106] call stub.LoadModelAsync
DEBUG 01-14 20:42:39.995905.995905 cuda_h.py:10] start self_attn
INFO 01-14 20:42:39.996137.996137 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, c658d4c6-e6d8-410d-ae33-1b942f265269
DEBUG 01-14 20:42:39.996768.996768 cuda_h.py:19] end load_into_gpu_async cost 0.0017693042755126953 seconds
DEBUG 01-14 20:42:39.996670.996670 cuda_h.py:10] start restore_tensors2
DEBUG 01-14 20:42:39.996065.996065 cuda_h.py:19] end restore_tensors2 cost 8.034706115722656e-05 seconds
DEBUG 01-14 20:42:39.996881.996881 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0026123523712158203 seconds
INFO 01-14 20:42:39.996645.996645 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, c658d4c6-e6d8-410d-ae33-1b942f265269
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-14 20:42:39.999450.999450 cuda_h.py:19] end self_attn cost 0.004547119140625 seconds
DEBUG 01-14 20:42:40.000355.000355 cuda_h.py:19] end iln_self_attn_paln cost 0.006360292434692383 seconds
DEBUG 01-14 20:42:40.000515.000515 cuda_h.py:10] start dense_mlp
INFO 01-14 20:42:40.005322.005322 client.py:127] Model loaded
DEBUG 01-14 20:42:40.005225.005225 cuda_h.py:10] start restore2model
DEBUG 01-14 20:42:40.005609.005609 cuda_h.py:19] end restore2model cost 0.00054931640625 seconds
DEBUG 01-14 20:42:40.005552.005552 cuda_h.py:19] end sllm_worker_task cost 0.011895895004272461 seconds
DEBUG 01-14 20:42:40.005336.005336 cuda_h.py:19] end dense_mlp cost 0.005692720413208008 seconds
DEBUG 01-14 20:42:40.006571.006571 cuda_h.py:19] end prefill_layer cost 0.012514591217041016 seconds
DEBUG 01-14 20:42:40.006857.006857 lmp.py:1551] -------------------------------- end prefill layer 0 --------------------------------
DEBUG 01-14 20:42:40.006746.006746 cuda_h.py:10] start prefill_layer
DEBUG 01-14 20:42:40.006826.006826 lmp.py:1494] -------------------------------- start prefill layer 1 --------------------------------
DEBUG 01-14 20:42:40.006760.006760 cuda_h.py:10] start start_load_qkvogn_s_weight_l_2
DEBUG 01-14 20:42:40.006887.006887 cuda_h.py:10] start start_load_qkvogn_s_weight_l_2
DEBUG 01-14 20:42:40.006948.006948 cuda_h.py:19] end start_load_qkvogn_s_weight_l_2 cost 2.0742416381835938e-05 seconds
DEBUG 01-14 20:42:40.006128.006128 cuda_h.py:19] end start_load_qkvogn_s_weight_l_2 cost 5.078315734863281e-05 seconds
DEBUG 01-14 20:42:40.006917.006917 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-14 20:42:40.006322.006322 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-14 20:42:40.006397.006397 cuda_h.py:10] start sllm_worker_task
DEBUG 01-14 20:42:40.006717.006717 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-14 20:42:40.006328.006328 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-14 20:42:40.006728.006728 cuda_h.py:19] end allocate_cuda_memory cost 0.0002105236053466797 seconds
DEBUG 01-14 20:42:40.006195.006195 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-14 20:42:40.006376.006376 sllm_store_c.py:27] get device uuid map
DEBUG 01-14 20:42:40.006172.006172 sllm_store_c.py:29] call client load into gpu
DEBUG 01-14 20:42:40.006372.006372 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, f887b149-0c1d-494f-aa1b-e3123a14a00f
DEBUG 01-14 20:42:40.007277.007277 client.py:106] call stub.LoadModelAsync
DEBUG 01-14 20:42:40.007316.007316 cuda_h.py:10] start self_attn
INFO 01-14 20:42:40.008293.008293 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, f887b149-0c1d-494f-aa1b-e3123a14a00f
DEBUG 01-14 20:42:40.008475.008475 cuda_h.py:19] end load_into_gpu_async cost 0.0015797615051269531 seconds
DEBUG 01-14 20:42:40.008251.008251 cuda_h.py:10] start restore_tensors2
DEBUG 01-14 20:42:40.008037.008037 cuda_h.py:19] end restore_tensors2 cost 7.677078247070312e-05 seconds
DEBUG 01-14 20:42:40.008741.008741 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.002256631851196289 seconds
INFO 01-14 20:42:40.008412.008412 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, f887b149-0c1d-494f-aa1b-e3123a14a00f
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-14 20:42:40.010691.010691 cuda_h.py:19] end self_attn cost 0.0028104782104492188 seconds
DEBUG 01-14 20:42:40.010793.010793 cuda_h.py:19] end iln_self_attn_paln cost 0.004199028015136719 seconds
DEBUG 01-14 20:42:40.010497.010497 cuda_h.py:10] start layer_moe_generate_mp_l_2
DEBUG 01-14 20:42:40.010783.010783 cuda_h.py:10] start gate
DEBUG 01-14 20:42:40.011980.011980 cuda_h.py:19] end gate cost 0.0007069110870361328 seconds
DEBUG 01-14 20:42:40.011048.011048 cuda_h.py:10] start experts_map_get
DEBUG 01-14 20:42:40.011641.011641 lmp.py:1615] 
DEBUG 01-14 20:42:40.011641.011641 lmp.py:1615] Expert Token Distribution & Device Allocation:
DEBUG 01-14 20:42:40.011112.011112 lmp.py:1616]   Total experts: 64
DEBUG 01-14 20:42:40.011000.011000 lmp.py:1617]   CPU experts: 32 (50%)
DEBUG 01-14 20:42:40.011789.011789 lmp.py:1618]   GPU experts: 32 (50%)
DEBUG 01-14 20:42:40.011909.011909 lmp.py:1619] 
DEBUG 01-14 20:42:40.011909.011909 lmp.py:1619]   Expert ID | Tokens | Device
DEBUG 01-14 20:42:40.011075.011075 lmp.py:1620]   -----------------------------------
DEBUG 01-14 20:42:40.011056.011056 lmp.py:1625]   Expert 25 |     64 | CPU
DEBUG 01-14 20:42:40.011984.011984 lmp.py:1625]   Expert 54 |     67 | CPU
DEBUG 01-14 20:42:40.011434.011434 lmp.py:1625]   Expert  3 |     68 | CPU
DEBUG 01-14 20:42:40.011647.011647 lmp.py:1625]   Expert 31 |     72 | CPU
DEBUG 01-14 20:42:40.011098.011098 lmp.py:1625]   Expert 55 |     72 | CPU
DEBUG 01-14 20:42:40.011310.011310 lmp.py:1625]   Expert 62 |     87 | CPU
DEBUG 01-14 20:42:40.011715.011715 lmp.py:1625]   Expert 18 |     88 | CPU
DEBUG 01-14 20:42:40.011358.011358 lmp.py:1625]   Expert 52 |     98 | CPU
DEBUG 01-14 20:42:40.011762.011762 lmp.py:1625]   Expert 22 |    100 | CPU
DEBUG 01-14 20:42:40.011213.011213 lmp.py:1625]   Expert 47 |    104 | CPU
DEBUG 01-14 20:42:40.011664.011664 lmp.py:1625]   Expert  0 |    113 | CPU
DEBUG 01-14 20:42:40.011638.011638 lmp.py:1625]   Expert 37 |    117 | CPU
DEBUG 01-14 20:42:40.011851.011851 lmp.py:1625]   Expert 27 |    121 | CPU
DEBUG 01-14 20:42:40.011825.011825 lmp.py:1625]   Expert 32 |    123 | CPU
DEBUG 01-14 20:42:40.012037.012037 lmp.py:1625]   Expert 41 |    130 | CPU
DEBUG 01-14 20:42:40.012488.012488 lmp.py:1625]   Expert 44 |    131 | CPU
DEBUG 01-14 20:42:40.012323.012323 lmp.py:1625]   Expert 28 |    136 | CPU
DEBUG 01-14 20:42:40.012204.012204 lmp.py:1625]   Expert 13 |    138 | CPU
DEBUG 01-14 20:42:40.012655.012655 lmp.py:1625]   Expert 58 |    140 | CPU
DEBUG 01-14 20:42:40.012868.012868 lmp.py:1625]   Expert 60 |    144 | CPU
DEBUG 01-14 20:42:40.012842.012842 lmp.py:1625]   Expert 43 |    147 | CPU
DEBUG 01-14 20:42:40.012816.012816 lmp.py:1625]   Expert  1 |    150 | CPU
DEBUG 01-14 20:42:40.012075.012075 lmp.py:1625]   Expert 38 |    153 | CPU
DEBUG 01-14 20:42:40.012254.012254 lmp.py:1625]   Expert 49 |    154 | CPU
DEBUG 01-14 20:42:40.012374.012374 lmp.py:1625]   Expert 51 |    155 | CPU
DEBUG 01-14 20:42:40.012540.012540 lmp.py:1625]   Expert 34 |    161 | CPU
DEBUG 01-14 20:42:40.012183.012183 lmp.py:1625]   Expert 35 |    164 | CPU
DEBUG 01-14 20:42:40.012826.012826 lmp.py:1625]   Expert 36 |    168 | CPU
DEBUG 01-14 20:42:40.012138.012138 lmp.py:1625]   Expert 11 |    170 | CPU
DEBUG 01-14 20:42:40.012450.012450 lmp.py:1625]   Expert 17 |    170 | CPU
DEBUG 01-14 20:42:40.012570.012570 lmp.py:1625]   Expert 59 |    174 | CPU
DEBUG 01-14 20:42:40.012213.012213 lmp.py:1625]   Expert 10 |    180 | CPU
DEBUG 01-14 20:42:40.012333.012333 lmp.py:1625]   Expert 20 |    182 | GPU
DEBUG 01-14 20:42:40.012737.012737 lmp.py:1625]   Expert  2 |    186 | GPU
DEBUG 01-14 20:42:40.012619.012619 lmp.py:1625]   Expert 39 |    189 | GPU
DEBUG 01-14 20:42:40.012785.012785 lmp.py:1625]   Expert 33 |    197 | GPU
DEBUG 01-14 20:42:40.012302.012302 lmp.py:1625]   Expert 12 |    198 | GPU
DEBUG 01-14 20:42:40.012707.012707 lmp.py:1625]   Expert 21 |    198 | GPU
DEBUG 01-14 20:42:40.012304.012304 lmp.py:1625]   Expert 48 |    198 | GPU
DEBUG 01-14 20:42:40.012854.012854 lmp.py:1625]   Expert 15 |    199 | GPU
DEBUG 01-14 20:42:40.012974.012974 lmp.py:1625]   Expert 53 |    204 | GPU
DEBUG 01-14 20:42:40.012617.012617 lmp.py:1625]   Expert 19 |    220 | GPU
DEBUG 01-14 20:42:40.012498.012498 lmp.py:1625]   Expert 26 |    221 | GPU
DEBUG 01-14 20:42:40.012903.012903 lmp.py:1625]   Expert 30 |    221 | GPU
DEBUG 01-14 20:42:40.012784.012784 lmp.py:1625]   Expert 45 |    221 | GPU
DEBUG 01-14 20:42:40.012427.012427 lmp.py:1625]   Expert  5 |    227 | GPU
DEBUG 01-14 20:42:40.012070.012070 lmp.py:1625]   Expert  4 |    229 | GPU
DEBUG 01-14 20:42:40.012190.012190 lmp.py:1625]   Expert 24 |    229 | GPU
DEBUG 01-14 20:42:40.012502.012502 lmp.py:1625]   Expert 42 |    242 | GPU
DEBUG 01-14 20:42:40.012337.012337 lmp.py:1625]   Expert 50 |    245 | GPU
DEBUG 01-14 20:42:40.012410.012410 lmp.py:1625]   Expert 29 |    254 | GPU
DEBUG 01-14 20:42:40.012053.012053 lmp.py:1625]   Expert 56 |    262 | GPU
DEBUG 01-14 20:42:40.012935.012935 lmp.py:1625]   Expert 61 |    270 | GPU
DEBUG 01-14 20:42:40.012339.012339 lmp.py:1625]   Expert  8 |    283 | GPU
DEBUG 01-14 20:42:40.012982.012982 lmp.py:1625]   Expert 63 |    285 | GPU
DEBUG 01-14 20:42:40.012864.012864 lmp.py:1625]   Expert 46 |    294 | GPU
DEBUG 01-14 20:42:40.012745.012745 lmp.py:1625]   Expert  9 |    300 | GPU
DEBUG 01-14 20:42:40.012911.012911 lmp.py:1625]   Expert  6 |    316 | GPU
DEBUG 01-14 20:42:40.012554.012554 lmp.py:1625]   Expert 16 |    316 | GPU
DEBUG 01-14 20:42:40.012389.012389 lmp.py:1625]   Expert 40 |    319 | GPU
DEBUG 01-14 20:42:40.012224.012224 lmp.py:1625]   Expert  7 |    322 | GPU
DEBUG 01-14 20:42:40.012821.012821 lmp.py:1625]   Expert 23 |    325 | GPU
DEBUG 01-14 20:42:40.012941.012941 lmp.py:1625]   Expert 14 |    413 | GPU
DEBUG 01-14 20:42:40.012584.012584 lmp.py:1625]   Expert 57 |    464 | GPU
DEBUG 01-14 20:42:40.012942.012942 lmp.py:1626] 
DEBUG 01-14 20:42:40.012942.012942 lmp.py:1626]   CPU total tokens: 4059 (33.0%)
DEBUG 01-14 20:42:40.012062.012062 lmp.py:1627]   GPU total tokens: 8229 (67.0%)
DEBUG 01-14 20:42:40.012427.012427 cuda_h.py:19] end experts_map_get cost 0.001585245132446289 seconds
DEBUG 01-14 20:42:40.013429.013429 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-14 20:42:40.013557.013557 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-14 20:42:40.013879.013879 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-14 20:42:40.014192.014192 cuda_h.py:19] end allocate_cuda_memory cost 0.0013918876647949219 seconds
DEBUG 01-14 20:42:40.014386.014386 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-14 20:42:40.014858.014858 sllm_store_c.py:27] get device uuid map
DEBUG 01-14 20:42:40.014998.014998 sllm_store_c.py:29] call client load into gpu
DEBUG 01-14 20:42:40.014124.014124 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 4fd59542-e4e6-455d-a3d1-d31c6d65fdb0
DEBUG 01-14 20:42:40.015908.015908 client.py:106] call stub.LoadModelAsync
INFO 01-14 20:42:40.016113.016113 client.py:127] Model loaded
DEBUG 01-14 20:42:40.016434.016434 cuda_h.py:10] start restore2model
DEBUG 01-14 20:42:40.017282.017282 cuda_h.py:19] end restore2model cost 0.0007271766662597656 seconds
DEBUG 01-14 20:42:40.017305.017305 cuda_h.py:19] end sllm_worker_task cost 0.01103520393371582 seconds
INFO 01-14 20:42:40.017634.017634 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 4fd59542-e4e6-455d-a3d1-d31c6d65fdb0
DEBUG 01-14 20:42:40.018391.018391 cuda_h.py:19] end load_into_gpu_async cost 0.0032682418823242188 seconds
DEBUG 01-14 20:42:40.018240.018240 cuda_h.py:10] start restore_tensors2
DEBUG 01-14 20:42:40.018538.018538 cuda_h.py:19] end restore_tensors2 cost 0.0003662109375 seconds
DEBUG 01-14 20:42:40.018566.018566 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.005391120910644531 seconds
DEBUG 01-14 20:42:40.018137.018137 cuda_h.py:10] start restore2model
DEBUG 01-14 20:42:40.021081.021081 cuda_h.py:19] end restore2model cost 0.0026662349700927734 seconds
DEBUG 01-14 20:42:40.021931.021931 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.008240461349487305 seconds
DEBUG 01-14 20:42:40.021727.021727 cuda_h.py:10] start gpu_sexperts
DEBUG 01-14 20:42:40.021088.021088 cuda_h.py:19] end gpu_sexperts cost 0.00027060508728027344 seconds
DEBUG 01-14 20:42:40.021626.021626 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-14 20:42:40.021236.021236 lmp.py:1683] 
DEBUG 01-14 20:42:40.021236.021236 lmp.py:1683]   Computing 32 experts on CPU...
DEBUG 01-14 20:42:40.021933.021933 cuda_h.py:19] end cpu_experts_submit cost 5.745887756347656e-05 seconds
DEBUG 01-14 20:42:40.021682.021682 cuda_h.py:10] start experts_func_mgpu_group_pad
DEBUG 01-14 20:42:40.028877.028877 mlpmodule.py:1460] group tensors cost 0.005476951599121094 s
DEBUG 01-14 20:42:40.028674.028674 cuda_h.py:10] start move_flat_hidden2cpu
DEBUG 01-14 20:42:40.030267.030267 cuda_h.py:19] end experts_func_mgpu_group_pad cost 0.009084224700927734 seconds
DEBUG 01-14 20:42:40.032809.032809 cuda_h.py:10] start gpu_group_list
DEBUG 01-14 20:42:40.033760.033760 cuda_h.py:19] end gpu_group_list cost 0.00044155120849609375 seconds
DEBUG 01-14 20:42:40.033773.033773 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-14 20:42:40.033260.033260 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 3.218650817871094e-05 seconds
DEBUG 01-14 20:42:40.033546.033546 cuda_h.py:10] start wait_experts
INFO 01-14 20:42:40.033018.033018 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 4fd59542-e4e6-455d-a3d1-d31c6d65fdb0
DEBUG 01-14 20:42:40.035990.035990 cuda_h.py:19] end move_flat_hidden2cpu cost 0.006407499313354492 seconds
DEBUG 01-14 20:42:40.037868.037868 mlpmodule.py:1533] pad cost 0.0015933513641357422 s
DEBUG 01-14 20:42:40.037726.037726 mlpmodule.py:1539] create cpu tensor cost 3.6716461181640625e-05 s
DEBUG 01-14 20:42:40.039514.039514 mlpmodule.py:1544] move to cpu cost 0.0021245479583740234 s
DEBUG 01-14 20:42:40.049410.049410 mlpmodule.py:1558] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-14 20:42:40.050880.050880 mlpmodule.py:1559] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-14 20:42:40.050009.050009 mlpmodule.py:1564] group_w3 first element: -0.0107421875
WARNING 01-14 20:42:40.050372.050372 mlpmodule.py:1574] start einsum2
DEBUG 01-14 20:42:40.068112.068112 mlpmodule.py:1584] group einsum cost 0.028875350952148438 s
DEBUG 01-14 20:42:40.069891.069891 mlpmodule.py:1593] cpy2cputensor cost 0.0007114410400390625 s
DEBUG 01-14 20:42:40.069721.069721 cuda_h.py:10] start move_outputs
DEBUG 01-14 20:42:40.071638.071638 cuda_h.py:19] end move_outputs cost 0.0026454925537109375 seconds
INFO 01-14 20:42:40.076213.076213 client.py:127] Model loaded
DEBUG 01-14 20:42:40.076543.076543 cuda_h.py:19] end wait_experts cost 0.04278373718261719 seconds
DEBUG 01-14 20:42:40.076790.076790 cuda_h.py:10] start gpu_experts
DEBUG 01-14 20:42:40.076036.076036 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-14 20:42:40.076872.076872 cuda_h.py:19] end wait_cetm_experts cost 0.0001995563507080078 seconds
DEBUG 01-14 20:42:40.076497.076497 cuda_h.py:10] start gpu_group_einsum_mp_multi_list
DEBUG 01-14 20:42:40.076253.076253 cuda_h.py:10] start gpu_group_tensor
DEBUG 01-14 20:42:40.088786.088786 mlpmodule.py:1367]  experts func einsum cost 0.06630706787109375 s
DEBUG 01-14 20:42:40.089859.089859 cuda_h.py:19] end gpu_group_tensor cost 0.012710809707641602 seconds
DEBUG 01-14 20:42:40.089469.089469 cuda_h.py:10] start gpu_group_einsum
DEBUG 01-14 20:42:40.090310.090310 cuda_h.py:19] end gpu_group_einsum cost 0.0009515285491943359 seconds
DEBUG 01-14 20:42:40.090460.090460 cuda_h.py:10] start gpu_final_hidden_states_scatter
DEBUG 01-14 20:42:40.090435.090435 cuda_h.py:10] start all_expert_outputs_slices
DEBUG 01-14 20:42:40.090781.090781 cuda_h.py:19] end all_expert_outputs_slices cost 0.0002262592315673828 seconds
DEBUG 01-14 20:42:40.091199.091199 cuda_h.py:10] start concat_expert_out
DEBUG 01-14 20:42:40.091838.091838 cuda_h.py:19] end concat_expert_out cost 5.245208740234375e-05 seconds
DEBUG 01-14 20:42:40.091019.091019 cuda_h.py:10] start index_scatter
DEBUG 01-14 20:42:40.091824.091824 cuda_h.py:19] end index_scatter cost 7.033348083496094e-05 seconds
DEBUG 01-14 20:42:40.091772.091772 cuda_h.py:19] end gpu_final_hidden_states_scatter cost 0.0005772113800048828 seconds
DEBUG 01-14 20:42:40.091013.091013 cuda_h.py:19] end gpu_experts cost 0.01513051986694336 seconds
DEBUG 01-14 20:42:40.091901.091901 cuda_h.py:10] start all_expert_weight_slices
DEBUG 01-14 20:42:40.092206.092206 cuda_h.py:19] end all_expert_weight_slices cost 0.0007927417755126953 seconds
DEBUG 01-14 20:42:40.092314.092314 cuda_h.py:10] start cpuoutputsdeal
DEBUG 01-14 20:42:40.092869.092869 cuda_h.py:10] start index_scatter
DEBUG 01-14 20:42:40.092429.092429 cuda_h.py:19] end index_scatter cost 4.696846008300781e-05 seconds
DEBUG 01-14 20:42:40.092953.092953 cuda_h.py:19] end cpuoutputsdeal cost 0.0004818439483642578 seconds
DEBUG 01-14 20:42:40.092095.092095 cuda_h.py:19] end layer_moe_generate_mp_l_2 cost 0.0822901725769043 seconds
DEBUG 01-14 20:42:40.093191.093191 cuda_h.py:19] end prefill_layer cost 0.08706450462341309 seconds
DEBUG 01-14 20:42:40.093611.093611 lmp.py:1551] -------------------------------- end prefill layer 1 --------------------------------
DEBUG 01-14 20:42:40.093976.093976 cuda_h.py:10] start prefill_layer
DEBUG 01-14 20:42:40.093102.093102 lmp.py:1494] -------------------------------- start prefill layer 2 --------------------------------
DEBUG 01-14 20:42:40.093229.093229 cuda_h.py:10] start start_load_qkvogn_s_weight_l_3
DEBUG 01-14 20:42:40.093071.093071 cuda_h.py:10] start start_load_qkvogn_s_weight_l_3
DEBUG 01-14 20:42:40.093622.093622 cuda_h.py:19] end start_load_qkvogn_s_weight_l_3 cost 3.0994415283203125e-05 seconds
DEBUG 01-14 20:42:40.093180.093180 cuda_h.py:19] end start_load_qkvogn_s_weight_l_3 cost 5.841255187988281e-05 seconds
DEBUG 01-14 20:42:40.093015.093015 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-14 20:42:40.093660.093660 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-14 20:42:40.093060.093060 cuda_h.py:10] start sllm_worker_task
DEBUG 01-14 20:42:40.093117.093117 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-14 20:42:40.093020.093020 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-14 20:42:40.094776.094776 cuda_h.py:19] end allocate_cuda_memory cost 0.0001976490020751953 seconds
DEBUG 01-14 20:42:40.094236.094236 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-14 20:42:40.094774.094774 sllm_store_c.py:27] get device uuid map
DEBUG 01-14 20:42:40.094041.094041 sllm_store_c.py:29] call client load into gpu
DEBUG 01-14 20:42:40.094327.094327 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 3deef1f8-51b6-4895-934d-f76d3ce457a6
DEBUG 01-14 20:42:40.094370.094370 client.py:106] call stub.LoadModelAsync
DEBUG 01-14 20:42:40.094405.094405 cuda_h.py:10] start self_attn
INFO 01-14 20:42:40.095551.095551 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 3deef1f8-51b6-4895-934d-f76d3ce457a6
DEBUG 01-14 20:42:40.095069.095069 cuda_h.py:19] end load_into_gpu_async cost 0.001691579818725586 seconds
DEBUG 01-14 20:42:40.095925.095925 cuda_h.py:10] start restore_tensors2
DEBUG 01-14 20:42:40.095796.095796 cuda_h.py:19] end restore_tensors2 cost 7.987022399902344e-05 seconds
DEBUG 01-14 20:42:40.096374.096374 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.002286672592163086 seconds
INFO 01-14 20:42:40.096131.096131 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 3deef1f8-51b6-4895-934d-f76d3ce457a6
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-14 20:42:40.097586.097586 cuda_h.py:19] end self_attn cost 0.002982616424560547 seconds
DEBUG 01-14 20:42:40.097186.097186 cuda_h.py:19] end iln_self_attn_paln cost 0.004485607147216797 seconds
DEBUG 01-14 20:42:40.097837.097837 cuda_h.py:10] start layer_moe_generate_mp_l_3
DEBUG 01-14 20:42:40.098884.098884 cuda_h.py:10] start gate
DEBUG 01-14 20:42:40.098794.098794 cuda_h.py:19] end gate cost 0.0006361007690429688 seconds
DEBUG 01-14 20:42:40.098339.098339 cuda_h.py:10] start experts_map_get
DEBUG 01-14 20:42:40.099799.099799 lmp.py:1615] 
DEBUG 01-14 20:42:40.099799.099799 lmp.py:1615] Expert Token Distribution & Device Allocation:
DEBUG 01-14 20:42:40.099078.099078 lmp.py:1616]   Total experts: 64
DEBUG 01-14 20:42:40.099682.099682 lmp.py:1617]   CPU experts: 32 (50%)
DEBUG 01-14 20:42:40.099994.099994 lmp.py:1618]   GPU experts: 32 (50%)
DEBUG 01-14 20:42:40.099683.099683 lmp.py:1619] 
DEBUG 01-14 20:42:40.099683.099683 lmp.py:1619]   Expert ID | Tokens | Device
DEBUG 01-14 20:42:40.099611.099611 lmp.py:1620]   -----------------------------------
DEBUG 01-14 20:42:40.099492.099492 lmp.py:1625]   Expert 58 |     56 | CPU
DEBUG 01-14 20:42:40.099420.099420 lmp.py:1625]   Expert 27 |     80 | CPU
DEBUG 01-14 20:42:40.099632.099632 lmp.py:1625]   Expert  3 |     85 | CPU
DEBUG 01-14 20:42:40.099845.099845 lmp.py:1625]   Expert 24 |     86 | CPU
DEBUG 01-14 20:42:40.099057.099057 lmp.py:1625]   Expert  0 |     87 | CPU
DEBUG 01-14 20:42:40.099508.099508 lmp.py:1625]   Expert 17 |     87 | CPU
DEBUG 01-14 20:42:40.099244.099244 lmp.py:1625]   Expert 28 |    106 | CPU
DEBUG 01-14 20:42:40.099456.099456 lmp.py:1625]   Expert 34 |    108 | CPU
DEBUG 01-14 20:42:40.099430.099430 lmp.py:1625]   Expert 51 |    112 | CPU
DEBUG 01-14 20:42:40.099166.099166 lmp.py:1625]   Expert 32 |    119 | CPU
DEBUG 01-14 20:42:40.099140.099140 lmp.py:1625]   Expert 23 |    122 | CPU
DEBUG 01-14 20:42:40.099876.099876 lmp.py:1625]   Expert 15 |    128 | CPU
DEBUG 01-14 20:42:40.099611.099611 lmp.py:1625]   Expert  7 |    133 | CPU
DEBUG 01-14 20:42:40.099347.099347 lmp.py:1625]   Expert 26 |    135 | CPU
DEBUG 01-14 20:42:40.099182.099182 lmp.py:1625]   Expert  9 |    138 | CPU
DEBUG 01-14 20:42:40.099394.099394 lmp.py:1625]   Expert 30 |    141 | CPU
DEBUG 01-14 20:42:40.099753.099753 lmp.py:1625]   Expert 57 |    142 | CPU
DEBUG 01-14 20:42:40.099204.099204 lmp.py:1625]   Expert 62 |    145 | CPU
DEBUG 01-14 20:42:40.099893.099893 lmp.py:1625]   Expert 45 |    146 | CPU
DEBUG 01-14 20:42:40.099821.099821 lmp.py:1625]   Expert  1 |    150 | CPU
DEBUG 01-14 20:42:40.099510.099510 lmp.py:1625]   Expert  6 |    154 | CPU
DEBUG 01-14 20:42:40.099438.099438 lmp.py:1625]   Expert 48 |    156 | CPU
DEBUG 01-14 20:42:40.099127.099127 lmp.py:1625]   Expert  8 |    162 | CPU
DEBUG 01-14 20:42:40.099578.099578 lmp.py:1625]   Expert 54 |    163 | CPU
DEBUG 01-14 20:42:40.099267.099267 lmp.py:1625]   Expert 25 |    166 | CPU
DEBUG 01-14 20:42:40.099718.099718 lmp.py:1625]   Expert 49 |    168 | CPU
DEBUG 01-14 20:42:40.099407.099407 lmp.py:1625]   Expert 29 |    172 | CPU
DEBUG 01-14 20:42:40.099858.099858 lmp.py:1625]   Expert 35 |    173 | CPU
DEBUG 01-14 20:42:40.099024.099024 lmp.py:1625]   Expert 36 |    173 | CPU
DEBUG 01-14 20:42:40.099429.099429 lmp.py:1625]   Expert 12 |    176 | CPU
DEBUG 01-14 20:42:40.099357.099357 lmp.py:1625]   Expert 37 |    186 | CPU
DEBUG 01-14 20:42:40.099807.099807 lmp.py:1625]   Expert 53 |    187 | CPU
DEBUG 01-14 20:42:40.099497.099497 lmp.py:1625]   Expert 13 |    188 | GPU
DEBUG 01-14 20:42:40.099948.099948 lmp.py:1625]   Expert 33 |    190 | GPU
DEBUG 01-14 20:42:40.099637.099637 lmp.py:1625]   Expert 60 |    190 | GPU
DEBUG 01-14 20:42:40.099088.099088 lmp.py:1625]   Expert 16 |    195 | GPU
DEBUG 01-14 20:42:40.099016.099016 lmp.py:1625]   Expert 40 |    200 | GPU
DEBUG 01-14 20:42:40.099182.099182 lmp.py:1625]   Expert 21 |    201 | GPU
DEBUG 01-14 20:42:40.099063.099063 lmp.py:1625]   Expert 38 |    202 | GPU
DEBUG 01-14 20:42:40.099752.099752 lmp.py:1625]   Expert  5 |    209 | GPU
DEBUG 01-14 20:42:40.099442.099442 lmp.py:1625]   Expert 19 |    209 | GPU
DEBUG 01-14 20:42:40.099893.099893 lmp.py:1625]   Expert 41 |    213 | GPU
DEBUG 01-14 20:42:40.099582.099582 lmp.py:1625]   Expert 43 |    213 | GPU
DEBUG 01-14 20:42:40.099794.099794 lmp.py:1625]   Expert 10 |    215 | GPU
DEBUG 01-14 20:42:40.099484.099484 lmp.py:1625]   Expert 52 |    217 | GPU
DEBUG 01-14 20:42:40.099127.099127 lmp.py:1625]   Expert 50 |    218 | GPU
DEBUG 01-14 20:42:40.099531.099531 lmp.py:1625]   Expert 44 |    220 | GPU
DEBUG 01-14 20:42:40.099459.099459 lmp.py:1625]   Expert  4 |    221 | GPU
DEBUG 01-14 20:42:40.099910.099910 lmp.py:1625]   Expert 56 |    227 | GPU
DEBUG 01-14 20:42:40.099361.099361 lmp.py:1625]   Expert 59 |    230 | GPU
DEBUG 01-14 20:42:40.100811.100811 lmp.py:1625]   Expert 55 |    234 | GPU
DEBUG 01-14 20:42:40.100501.100501 lmp.py:1625]   Expert 31 |    245 | GPU
DEBUG 01-14 20:42:40.100713.100713 lmp.py:1625]   Expert 39 |    246 | GPU
DEBUG 01-14 20:42:40.100164.100164 lmp.py:1625]   Expert 22 |    255 | GPU
DEBUG 01-14 20:42:40.100569.100569 lmp.py:1625]   Expert 20 |    260 | GPU
DEBUG 01-14 20:42:40.100735.100735 lmp.py:1625]   Expert  2 |    268 | GPU
DEBUG 01-14 20:42:40.100424.100424 lmp.py:1625]   Expert 63 |    279 | GPU
DEBUG 01-14 20:42:40.100113.100113 lmp.py:1625]   Expert 47 |    284 | GPU
DEBUG 01-14 20:42:40.100564.100564 lmp.py:1625]   Expert 18 |    305 | GPU
DEBUG 01-14 20:42:40.100015.100015 lmp.py:1625]   Expert 14 |    312 | GPU
DEBUG 01-14 20:42:40.100466.100466 lmp.py:1625]   Expert 42 |    320 | GPU
DEBUG 01-14 20:42:40.100917.100917 lmp.py:1625]   Expert 46 |    372 | GPU
DEBUG 01-14 20:42:40.100368.100368 lmp.py:1625]   Expert 11 |    374 | GPU
DEBUG 01-14 20:42:40.100296.100296 lmp.py:1625]   Expert 61 |    434 | GPU
DEBUG 01-14 20:42:40.100654.100654 lmp.py:1626] 
DEBUG 01-14 20:42:40.100654.100654 lmp.py:1626]   CPU total tokens: 4342 (35.3%)
DEBUG 01-14 20:42:40.100535.100535 lmp.py:1627]   GPU total tokens: 7946 (64.7%)
DEBUG 01-14 20:42:40.100993.100993 cuda_h.py:19] end experts_map_get cost 0.0015082359313964844 seconds
DEBUG 01-14 20:42:40.100174.100174 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-14 20:42:40.100163.100163 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-14 20:42:40.100221.100221 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-14 20:42:40.102246.102246 cuda_h.py:19] end allocate_cuda_memory cost 0.0015308856964111328 seconds
DEBUG 01-14 20:42:40.102341.102341 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-14 20:42:40.102621.102621 sllm_store_c.py:27] get device uuid map
DEBUG 01-14 20:42:40.102761.102761 sllm_store_c.py:29] call client load into gpu
DEBUG 01-14 20:42:40.102887.102887 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, a64baf1d-fef6-481b-a0cf-cd83171d4656
DEBUG 01-14 20:42:40.102470.102470 client.py:106] call stub.LoadModelAsync
INFO 01-14 20:42:40.103709.103709 client.py:127] Model loaded
DEBUG 01-14 20:42:40.103188.103188 cuda_h.py:10] start restore2model
DEBUG 01-14 20:42:40.104713.104713 cuda_h.py:19] end restore2model cost 0.0005786418914794922 seconds
DEBUG 01-14 20:42:40.104662.104662 cuda_h.py:19] end sllm_worker_task cost 0.010943174362182617 seconds
INFO 01-14 20:42:40.105146.105146 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, a64baf1d-fef6-481b-a0cf-cd83171d4656
DEBUG 01-14 20:42:40.105688.105688 cuda_h.py:19] end load_into_gpu_async cost 0.0033638477325439453 seconds
DEBUG 01-14 20:42:40.105280.105280 cuda_h.py:10] start restore_tensors2
DEBUG 01-14 20:42:40.106296.106296 cuda_h.py:19] end restore_tensors2 cost 0.0008225440979003906 seconds
DEBUG 01-14 20:42:40.106848.106848 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.00620269775390625 seconds
DEBUG 01-14 20:42:40.106896.106896 cuda_h.py:10] start restore2model
DEBUG 01-14 20:42:40.109172.109172 cuda_h.py:19] end restore2model cost 0.002701997756958008 seconds
DEBUG 01-14 20:42:40.109830.109830 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.009093761444091797 seconds
DEBUG 01-14 20:42:40.109626.109626 cuda_h.py:10] start gpu_sexperts
DEBUG 01-14 20:42:40.109398.109398 cuda_h.py:19] end gpu_sexperts cost 0.0002923011779785156 seconds
DEBUG 01-14 20:42:40.109413.109413 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-14 20:42:40.109785.109785 lmp.py:1683] 
DEBUG 01-14 20:42:40.109785.109785 lmp.py:1683]   Computing 32 experts on CPU...
DEBUG 01-14 20:42:40.109290.109290 cuda_h.py:19] end cpu_experts_submit cost 5.626678466796875e-05 seconds
DEBUG 01-14 20:42:40.109847.109847 cuda_h.py:10] start experts_func_mgpu_group_pad
DEBUG 01-14 20:42:40.117525.117525 mlpmodule.py:1460] group tensors cost 0.006735563278198242 s
DEBUG 01-14 20:42:40.117267.117267 cuda_h.py:10] start move_flat_hidden2cpu
DEBUG 01-14 20:42:40.122264.122264 cuda_h.py:19] end experts_func_mgpu_group_pad cost 0.012181520462036133 seconds
DEBUG 01-14 20:42:40.124517.124517 cuda_h.py:19] end move_flat_hidden2cpu cost 0.006339073181152344 seconds
DEBUG 01-14 20:42:40.124333.124333 cuda_h.py:10] start gpu_group_list
DEBUG 01-14 20:42:40.125229.125229 cuda_h.py:19] end gpu_group_list cost 0.0007076263427734375 seconds
DEBUG 01-14 20:42:40.126610.126610 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-14 20:42:40.126210.126210 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.956390380859375e-05 seconds
DEBUG 01-14 20:42:40.126808.126808 cuda_h.py:10] start wait_experts
INFO 01-14 20:42:40.126546.126546 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, a64baf1d-fef6-481b-a0cf-cd83171d4656
DEBUG 01-14 20:42:40.127377.127377 mlpmodule.py:1533] pad cost 0.0030117034912109375 s
DEBUG 01-14 20:42:40.127136.127136 mlpmodule.py:1539] create cpu tensor cost 3.910064697265625e-05 s
DEBUG 01-14 20:42:40.129662.129662 mlpmodule.py:1544] move to cpu cost 0.0022079944610595703 s
DEBUG 01-14 20:42:40.140479.140479 mlpmodule.py:1558] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-14 20:42:40.140083.140083 mlpmodule.py:1559] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-14 20:42:40.140133.140133 mlpmodule.py:1564] group_w3 first element: -0.0380859375
WARNING 01-14 20:42:40.140747.140747 mlpmodule.py:1574] start einsum2
DEBUG 01-14 20:42:40.159720.159720 mlpmodule.py:1584] group einsum cost 0.029948711395263672 s
DEBUG 01-14 20:42:40.160964.160964 mlpmodule.py:1593] cpy2cputensor cost 0.0007495880126953125 s
DEBUG 01-14 20:42:40.160185.160185 cuda_h.py:10] start move_outputs
INFO 01-14 20:42:40.161191.161191 client.py:127] Model loaded
DEBUG 01-14 20:42:40.161450.161450 cuda_h.py:19] end wait_experts cost 0.03548169136047363 seconds
DEBUG 01-14 20:42:40.161173.161173 cuda_h.py:10] start gpu_experts
DEBUG 01-14 20:42:40.161042.161042 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-14 20:42:40.163503.163503 cuda_h.py:19] end move_outputs cost 0.002156972885131836 seconds
DEBUG 01-14 20:42:40.166625.166625 cuda_h.py:19] end wait_cetm_experts cost 0.00491642951965332 seconds
DEBUG 01-14 20:42:40.166781.166781 cuda_h.py:10] start gpu_group_einsum_mp_multi_list
DEBUG 01-14 20:42:40.166352.166352 cuda_h.py:10] start gpu_group_tensor
DEBUG 01-14 20:42:40.167686.167686 cuda_h.py:19] end gpu_group_tensor cost 0.0002498626708984375 seconds
DEBUG 01-14 20:42:40.167710.167710 cuda_h.py:10] start gpu_group_einsum
DEBUG 01-14 20:42:40.182101.182101 mlpmodule.py:1367]  experts func einsum cost 0.07161617279052734 s
DEBUG 01-14 20:42:40.182743.182743 cuda_h.py:19] end gpu_group_einsum cost 0.014757633209228516 seconds
DEBUG 01-14 20:42:40.182839.182839 cuda_h.py:10] start gpu_final_hidden_states_scatter
DEBUG 01-14 20:42:40.182464.182464 cuda_h.py:10] start all_expert_outputs_slices
DEBUG 01-14 20:42:40.182486.182486 cuda_h.py:19] end all_expert_outputs_slices cost 0.00023293495178222656 seconds
DEBUG 01-14 20:42:40.182096.182096 cuda_h.py:10] start concat_expert_out
DEBUG 01-14 20:42:40.182218.182218 cuda_h.py:19] end concat_expert_out cost 5.793571472167969e-05 seconds
DEBUG 01-14 20:42:40.183068.183068 cuda_h.py:10] start index_scatter
DEBUG 01-14 20:42:40.183965.183965 cuda_h.py:19] end index_scatter cost 6.890296936035156e-05 seconds
DEBUG 01-14 20:42:40.183629.183629 cuda_h.py:19] end gpu_final_hidden_states_scatter cost 0.000591278076171875 seconds
DEBUG 01-14 20:42:40.183638.183638 cuda_h.py:19] end gpu_experts cost 0.02138376235961914 seconds
DEBUG 01-14 20:42:40.183480.183480 cuda_h.py:10] start all_expert_weight_slices
DEBUG 01-14 20:42:40.184175.184175 cuda_h.py:19] end all_expert_weight_slices cost 0.000766754150390625 seconds
DEBUG 01-14 20:42:40.184276.184276 cuda_h.py:10] start cpuoutputsdeal
DEBUG 01-14 20:42:40.184502.184502 cuda_h.py:10] start index_scatter
DEBUG 01-14 20:42:40.184082.184082 cuda_h.py:19] end index_scatter cost 5.435943603515625e-05 seconds
DEBUG 01-14 20:42:40.184282.184282 cuda_h.py:19] end cpuoutputsdeal cost 0.0005409717559814453 seconds
DEBUG 01-14 20:42:40.184675.184675 cuda_h.py:19] end layer_moe_generate_mp_l_3 cost 0.0867164134979248 seconds
DEBUG 01-14 20:42:40.185694.185694 cuda_h.py:19] end prefill_layer cost 0.09182262420654297 seconds
DEBUG 01-14 20:42:40.185935.185935 lmp.py:1551] -------------------------------- end prefill layer 2 --------------------------------
DEBUG 01-14 20:42:40.185830.185830 cuda_h.py:10] start prefill_layer
DEBUG 01-14 20:42:40.185963.185963 lmp.py:1494] -------------------------------- start prefill layer 3 --------------------------------
DEBUG 01-14 20:42:40.185381.185381 cuda_h.py:10] start start_load_qkvogn_s_weight_l_4
DEBUG 01-14 20:42:40.185707.185707 cuda_h.py:10] start start_load_qkvogn_s_weight_l_4
DEBUG 01-14 20:42:40.185980.185980 cuda_h.py:19] end start_load_qkvogn_s_weight_l_4 cost 3.337860107421875e-05 seconds
DEBUG 01-14 20:42:40.185975.185975 cuda_h.py:19] end start_load_qkvogn_s_weight_l_4 cost 6.747245788574219e-05 seconds
DEBUG 01-14 20:42:40.185770.185770 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-14 20:42:40.185508.185508 cuda_h.py:10] start sllm_worker_task
DEBUG 01-14 20:42:40.185986.185986 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-14 20:42:40.185134.185134 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-14 20:42:40.186890.186890 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-14 20:42:40.186774.186774 cuda_h.py:19] end allocate_cuda_memory cost 0.00035834312438964844 seconds
DEBUG 01-14 20:42:40.186137.186137 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-14 20:42:40.186452.186452 sllm_store_c.py:27] get device uuid map
DEBUG 01-14 20:42:40.186960.186960 sllm_store_c.py:29] call client load into gpu
DEBUG 01-14 20:42:40.187658.187658 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 37b59ace-6456-4cf9-84eb-5dcdd35b1027
DEBUG 01-14 20:42:40.187937.187937 client.py:106] call stub.LoadModelAsync
DEBUG 01-14 20:42:40.187740.187740 cuda_h.py:10] start self_attn
INFO 01-14 20:42:40.188770.188770 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 37b59ace-6456-4cf9-84eb-5dcdd35b1027
DEBUG 01-14 20:42:40.189212.189212 cuda_h.py:19] end load_into_gpu_async cost 0.002312183380126953 seconds
DEBUG 01-14 20:42:40.189149.189149 cuda_h.py:10] start restore_tensors2
DEBUG 01-14 20:42:40.189197.189197 cuda_h.py:19] end restore_tensors2 cost 0.0001494884490966797 seconds
DEBUG 01-14 20:42:40.189485.189485 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.003571033477783203 seconds
INFO 01-14 20:42:40.189059.189059 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 37b59ace-6456-4cf9-84eb-5dcdd35b1027
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-14 20:42:40.191788.191788 cuda_h.py:19] end self_attn cost 0.003728151321411133 seconds
DEBUG 01-14 20:42:40.191363.191363 cuda_h.py:19] end iln_self_attn_paln cost 0.006186246871948242 seconds
DEBUG 01-14 20:42:40.191551.191551 cuda_h.py:10] start layer_moe_generate_mp_l_4
DEBUG 01-14 20:42:40.191082.191082 cuda_h.py:10] start gate
DEBUG 01-14 20:42:40.192179.192179 cuda_h.py:19] end gate cost 0.0006985664367675781 seconds
DEBUG 01-14 20:42:40.192354.192354 cuda_h.py:10] start experts_map_get
DEBUG 01-14 20:42:40.192233.192233 lmp.py:1615] 
DEBUG 01-14 20:42:40.192233.192233 lmp.py:1615] Expert Token Distribution & Device Allocation:
DEBUG 01-14 20:42:40.192427.192427 lmp.py:1616]   Total experts: 64
DEBUG 01-14 20:42:40.192606.192606 lmp.py:1617]   CPU experts: 32 (50%)
DEBUG 01-14 20:42:40.192164.192164 lmp.py:1618]   GPU experts: 32 (50%)
DEBUG 01-14 20:42:40.193668.193668 lmp.py:1619] 
DEBUG 01-14 20:42:40.193668.193668 lmp.py:1619]   Expert ID | Tokens | Device
DEBUG 01-14 20:42:40.193172.193172 lmp.py:1620]   -----------------------------------
DEBUG 01-14 20:42:40.193583.193583 lmp.py:1625]   Expert  1 |     55 | CPU
DEBUG 01-14 20:42:40.193802.193802 lmp.py:1625]   Expert 27 |     59 | CPU
DEBUG 01-14 20:42:40.193068.193068 lmp.py:1625]   Expert 48 |     81 | CPU
DEBUG 01-14 20:42:40.193572.193572 lmp.py:1625]   Expert  7 |     84 | CPU
DEBUG 01-14 20:42:40.193122.193122 lmp.py:1625]   Expert 30 |    100 | CPU
DEBUG 01-14 20:42:40.193341.193341 lmp.py:1625]   Expert 15 |    102 | CPU
DEBUG 01-14 20:42:40.193322.193322 lmp.py:1625]   Expert 32 |    114 | CPU
DEBUG 01-14 20:42:40.193349.193349 lmp.py:1625]   Expert 61 |    114 | CPU
DEBUG 01-14 20:42:40.193138.193138 lmp.py:1625]   Expert 18 |    116 | CPU
DEBUG 01-14 20:42:40.193073.193073 lmp.py:1625]   Expert 39 |    116 | CPU
DEBUG 01-14 20:42:40.193484.193484 lmp.py:1625]   Expert 45 |    134 | CPU
DEBUG 01-14 20:42:40.193418.193418 lmp.py:1625]   Expert 34 |    135 | CPU
DEBUG 01-14 20:42:40.193876.193876 lmp.py:1625]   Expert 59 |    138 | CPU
DEBUG 01-14 20:42:40.193287.193287 lmp.py:1625]   Expert 11 |    144 | CPU
DEBUG 01-14 20:42:40.193699.193699 lmp.py:1625]   Expert 36 |    145 | CPU
DEBUG 01-14 20:42:40.193633.193633 lmp.py:1625]   Expert 26 |    147 | CPU
DEBUG 01-14 20:42:40.193853.193853 lmp.py:1625]   Expert  9 |    150 | CPU
DEBUG 01-14 20:42:40.193549.193549 lmp.py:1625]   Expert 23 |    151 | CPU
DEBUG 01-14 20:42:40.193245.193245 lmp.py:1625]   Expert  5 |    152 | CPU
DEBUG 01-14 20:42:40.193702.193702 lmp.py:1625]   Expert 49 |    152 | CPU
DEBUG 01-14 20:42:40.193160.193160 lmp.py:1625]   Expert  6 |    153 | CPU
DEBUG 01-14 20:42:40.193856.193856 lmp.py:1625]   Expert 51 |    153 | CPU
DEBUG 01-14 20:42:40.193075.193075 lmp.py:1625]   Expert  2 |    162 | CPU
DEBUG 01-14 20:42:40.193772.193772 lmp.py:1625]   Expert 16 |    165 | CPU
DEBUG 01-14 20:42:40.193991.193991 lmp.py:1625]   Expert 50 |    165 | CPU
DEBUG 01-14 20:42:40.193164.193164 lmp.py:1625]   Expert 40 |    166 | CPU
DEBUG 01-14 20:42:40.193337.193337 lmp.py:1625]   Expert 56 |    169 | CPU
DEBUG 01-14 20:42:40.193794.193794 lmp.py:1625]   Expert  4 |    170 | CPU
DEBUG 01-14 20:42:40.193252.193252 lmp.py:1625]   Expert 52 |    178 | CPU
DEBUG 01-14 20:42:40.193233.193233 lmp.py:1625]   Expert 17 |    184 | CPU
DEBUG 01-14 20:42:40.193406.193406 lmp.py:1625]   Expert 44 |    184 | CPU
DEBUG 01-14 20:42:40.193340.193340 lmp.py:1625]   Expert 35 |    185 | CPU
DEBUG 01-14 20:42:40.193798.193798 lmp.py:1625]   Expert 37 |    187 | GPU
DEBUG 01-14 20:42:40.193017.193017 lmp.py:1625]   Expert 38 |    194 | GPU
DEBUG 01-14 20:42:40.193475.193475 lmp.py:1625]   Expert 42 |    194 | GPU
DEBUG 01-14 20:42:40.193171.193171 lmp.py:1625]   Expert 13 |    202 | GPU
DEBUG 01-14 20:42:40.193629.193629 lmp.py:1625]   Expert 21 |    205 | GPU
DEBUG 01-14 20:42:40.193848.193848 lmp.py:1625]   Expert  3 |    209 | GPU
DEBUG 01-14 20:42:40.193782.193782 lmp.py:1625]   Expert 53 |    209 | GPU
DEBUG 01-14 20:42:40.193717.193717 lmp.py:1625]   Expert 28 |    210 | GPU
DEBUG 01-14 20:42:40.193175.193175 lmp.py:1625]   Expert 10 |    213 | GPU
DEBUG 01-14 20:42:40.193394.193394 lmp.py:1625]   Expert 20 |    215 | GPU
DEBUG 01-14 20:42:40.193375.193375 lmp.py:1625]   Expert 47 |    216 | GPU
DEBUG 01-14 20:42:40.193594.193594 lmp.py:1625]   Expert 58 |    216 | GPU
DEBUG 01-14 20:42:40.193813.193813 lmp.py:1625]   Expert 19 |    224 | GPU
DEBUG 01-14 20:42:40.194748.194748 lmp.py:1625]   Expert 33 |    225 | GPU
DEBUG 01-14 20:42:40.194682.194682 lmp.py:1625]   Expert  8 |    227 | GPU
DEBUG 01-14 20:42:40.194901.194901 lmp.py:1625]   Expert 55 |    227 | GPU
DEBUG 01-14 20:42:40.194121.194121 lmp.py:1625]   Expert 31 |    229 | GPU
DEBUG 01-14 20:42:40.194101.194101 lmp.py:1625]   Expert 60 |    230 | GPU
DEBUG 01-14 20:42:40.194559.194559 lmp.py:1625]   Expert 57 |    234 | GPU
DEBUG 01-14 20:42:40.194778.194778 lmp.py:1625]   Expert 46 |    236 | GPU
DEBUG 01-14 20:42:40.194998.194998 lmp.py:1625]   Expert 62 |    240 | GPU
DEBUG 01-14 20:42:40.194171.194171 lmp.py:1625]   Expert 24 |    243 | GPU
DEBUG 01-14 20:42:40.194628.194628 lmp.py:1625]   Expert 63 |    252 | GPU
DEBUG 01-14 20:42:40.194848.194848 lmp.py:1625]   Expert 14 |    257 | GPU
DEBUG 01-14 20:42:40.194067.194067 lmp.py:1625]   Expert 12 |    260 | GPU
DEBUG 01-14 20:42:40.194286.194286 lmp.py:1625]   Expert 22 |    273 | GPU
DEBUG 01-14 20:42:40.194267.194267 lmp.py:1625]   Expert 43 |    290 | GPU
DEBUG 01-14 20:42:40.194248.194248 lmp.py:1625]   Expert 29 |    296 | GPU
DEBUG 01-14 20:42:40.194944.194944 lmp.py:1625]   Expert  0 |    309 | GPU
DEBUG 01-14 20:42:40.194878.194878 lmp.py:1625]   Expert 54 |    342 | GPU
DEBUG 01-14 20:42:40.194621.194621 lmp.py:1625]   Expert 41 |    386 | GPU
DEBUG 01-14 20:42:40.194840.194840 lmp.py:1625]   Expert 25 |    415 | GPU
DEBUG 01-14 20:42:40.194251.194251 lmp.py:1626] 
DEBUG 01-14 20:42:40.194251.194251 lmp.py:1626]   CPU total tokens: 4423 (36.0%)
DEBUG 01-14 20:42:40.194901.194901 lmp.py:1627]   GPU total tokens: 7865 (64.0%)
DEBUG 01-14 20:42:40.194319.194319 cuda_h.py:19] end experts_map_get cost 0.0019071102142333984 seconds
DEBUG 01-14 20:42:40.194421.194421 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-14 20:42:40.194278.194278 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-14 20:42:40.194879.194879 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-14 20:42:40.196157.196157 cuda_h.py:19] end allocate_cuda_memory cost 0.0013301372528076172 seconds
DEBUG 01-14 20:42:40.196669.196669 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-14 20:42:40.196709.196709 sllm_store_c.py:27] get device uuid map
DEBUG 01-14 20:42:40.196850.196850 sllm_store_c.py:29] call client load into gpu
DEBUG 01-14 20:42:40.196930.196930 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, d8f4ace0-650a-497d-9222-dd6bf86fad5e
DEBUG 01-14 20:42:40.196804.196804 client.py:106] call stub.LoadModelAsync
INFO 01-14 20:42:40.196212.196212 client.py:127] Model loaded
DEBUG 01-14 20:42:40.197136.197136 cuda_h.py:10] start restore2model
DEBUG 01-14 20:42:40.198171.198171 cuda_h.py:19] end restore2model cost 0.0009522438049316406 seconds
DEBUG 01-14 20:42:40.198123.198123 cuda_h.py:19] end sllm_worker_task cost 0.012543678283691406 seconds
INFO 01-14 20:42:40.198750.198750 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, d8f4ace0-650a-497d-9222-dd6bf86fad5e
DEBUG 01-14 20:42:40.198269.198269 cuda_h.py:19] end load_into_gpu_async cost 0.002269268035888672 seconds
DEBUG 01-14 20:42:40.198356.198356 cuda_h.py:10] start restore_tensors2
DEBUG 01-14 20:42:40.198185.198185 cuda_h.py:19] end restore_tensors2 cost 0.0004017353057861328 seconds
DEBUG 01-14 20:42:40.199128.199128 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.004391670227050781 seconds
DEBUG 01-14 20:42:40.199798.199798 cuda_h.py:10] start restore2model
DEBUG 01-14 20:42:40.201226.201226 cuda_h.py:19] end restore2model cost 0.0026726722717285156 seconds
DEBUG 01-14 20:42:40.201069.201069 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.007256746292114258 seconds
DEBUG 01-14 20:42:40.201149.201149 cuda_h.py:10] start gpu_sexperts
DEBUG 01-14 20:42:40.202061.202061 cuda_h.py:19] end gpu_sexperts cost 0.0002911090850830078 seconds
DEBUG 01-14 20:42:40.202599.202599 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-14 20:42:40.202686.202686 lmp.py:1683] 
DEBUG 01-14 20:42:40.202686.202686 lmp.py:1683]   Computing 32 experts on CPU...
DEBUG 01-14 20:42:40.202714.202714 cuda_h.py:19] end cpu_experts_submit cost 5.650520324707031e-05 seconds
DEBUG 01-14 20:42:40.202748.202748 cuda_h.py:10] start experts_func_mgpu_group_pad
DEBUG 01-14 20:42:40.214398.214398 mlpmodule.py:1460] group tensors cost 0.01159811019897461 s
DEBUG 01-14 20:42:40.215723.215723 cuda_h.py:10] start move_flat_hidden2cpu
DEBUG 01-14 20:42:40.221156.221156 cuda_h.py:19] end move_flat_hidden2cpu cost 0.006169557571411133 seconds
DEBUG 01-14 20:42:40.221915.221915 cuda_h.py:19] end experts_func_mgpu_group_pad cost 0.019150972366333008 seconds
DEBUG 01-14 20:42:40.225468.225468 mlpmodule.py:1533] pad cost 0.0036821365356445312 s
DEBUG 01-14 20:42:40.225745.225745 mlpmodule.py:1539] create cpu tensor cost 7.62939453125e-05 s
DEBUG 01-14 20:42:40.225268.225268 cuda_h.py:10] start gpu_group_list
DEBUG 01-14 20:42:40.226665.226665 cuda_h.py:19] end gpu_group_list cost 0.0006334781646728516 seconds
DEBUG 01-14 20:42:40.226890.226890 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-14 20:42:40.226059.226059 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.5272369384765625e-05 seconds
DEBUG 01-14 20:42:40.226451.226451 cuda_h.py:10] start wait_experts
INFO 01-14 20:42:40.226605.226605 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, d8f4ace0-650a-497d-9222-dd6bf86fad5e
DEBUG 01-14 20:42:40.227641.227641 mlpmodule.py:1544] move to cpu cost 0.0021903514862060547 s
DEBUG 01-14 20:42:40.238285.238285 mlpmodule.py:1558] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-14 20:42:40.238238.238238 mlpmodule.py:1559] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-14 20:42:40.238943.238943 mlpmodule.py:1564] group_w3 first element: -0.054931640625
WARNING 01-14 20:42:40.238603.238603 mlpmodule.py:1574] start einsum2
INFO 01-14 20:42:40.253884.253884 client.py:127] Model loaded
DEBUG 01-14 20:42:40.253244.253244 cuda_h.py:19] end wait_experts cost 0.026762008666992188 seconds
DEBUG 01-14 20:42:40.253776.253776 cuda_h.py:10] start gpu_experts
DEBUG 01-14 20:42:40.253600.253600 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-14 20:42:40.257714.257714 mlpmodule.py:1584] group einsum cost 0.029761791229248047 s
DEBUG 01-14 20:42:40.258811.258811 mlpmodule.py:1593] cpy2cputensor cost 0.0007376670837402344 s
DEBUG 01-14 20:42:40.258826.258826 cuda_h.py:10] start move_outputs
DEBUG 01-14 20:42:40.260337.260337 cuda_h.py:19] end move_outputs cost 0.002168893814086914 seconds
DEBUG 01-14 20:42:40.264426.264426 cuda_h.py:19] end wait_cetm_experts cost 0.010529279708862305 seconds
DEBUG 01-14 20:42:40.264895.264895 cuda_h.py:10] start gpu_group_einsum_mp_multi_list
DEBUG 01-14 20:42:40.264188.264188 cuda_h.py:10] start gpu_group_tensor
DEBUG 01-14 20:42:40.264012.264012 cuda_h.py:19] end gpu_group_tensor cost 0.00025844573974609375 seconds
DEBUG 01-14 20:42:40.264943.264943 cuda_h.py:10] start gpu_group_einsum
DEBUG 01-14 20:42:40.265864.265864 cuda_h.py:19] end gpu_group_einsum cost 0.0005590915679931641 seconds
DEBUG 01-14 20:42:40.265511.265511 cuda_h.py:10] start gpu_final_hidden_states_scatter
DEBUG 01-14 20:42:40.265301.265301 cuda_h.py:10] start all_expert_outputs_slices
DEBUG 01-14 20:42:40.265212.265212 cuda_h.py:19] end all_expert_outputs_slices cost 0.00028967857360839844 seconds
DEBUG 01-14 20:42:40.265538.265538 cuda_h.py:10] start concat_expert_out
DEBUG 01-14 20:42:40.274889.274889 cuda_h.py:19] end concat_expert_out cost 0.008471965789794922 seconds
DEBUG 01-14 20:42:40.274549.274549 cuda_h.py:10] start index_scatter
DEBUG 01-14 20:42:40.274878.274878 cuda_h.py:19] end index_scatter cost 7.414817810058594e-05 seconds
DEBUG 01-14 20:42:40.274595.274595 cuda_h.py:19] end gpu_final_hidden_states_scatter cost 0.00918436050415039 seconds
DEBUG 01-14 20:42:40.274194.274194 cuda_h.py:19] end gpu_experts cost 0.021327733993530273 seconds
DEBUG 01-14 20:42:40.274513.274513 cuda_h.py:10] start all_expert_weight_slices
DEBUG 01-14 20:42:40.275908.275908 cuda_h.py:19] end all_expert_weight_slices cost 0.0008924007415771484 seconds
DEBUG 01-14 20:42:40.275837.275837 cuda_h.py:10] start cpuoutputsdeal
DEBUG 01-14 20:42:40.276249.276249 cuda_h.py:10] start index_scatter
DEBUG 01-14 20:42:40.276882.276882 cuda_h.py:19] end index_scatter cost 5.7697296142578125e-05 seconds
DEBUG 01-14 20:42:40.276387.276387 cuda_h.py:19] end cpuoutputsdeal cost 0.0005838871002197266 seconds
DEBUG 01-14 20:42:40.276370.276370 cuda_h.py:19] end layer_moe_generate_mp_l_4 cost 0.08476519584655762 seconds
DEBUG 01-14 20:42:40.276356.276356 cuda_h.py:19] end prefill_layer cost 0.09164762496948242 seconds
DEBUG 01-14 20:42:40.276081.276081 lmp.py:1551] -------------------------------- end prefill layer 3 --------------------------------
DEBUG 01-14 20:42:40.276837.276837 cuda_h.py:10] start prefill_layer
DEBUG 01-14 20:42:40.277162.277162 lmp.py:1494] -------------------------------- start prefill layer 4 --------------------------------
DEBUG 01-14 20:42:40.277488.277488 cuda_h.py:10] start start_load_qkvogn_s_weight_l_5
DEBUG 01-14 20:42:40.277005.277005 cuda_h.py:10] start start_load_qkvogn_s_weight_l_5
DEBUG 01-14 20:42:40.277571.277571 cuda_h.py:19] end start_load_qkvogn_s_weight_l_5 cost 3.457069396972656e-05 seconds
DEBUG 01-14 20:42:40.277519.277519 cuda_h.py:19] end start_load_qkvogn_s_weight_l_5 cost 7.009506225585938e-05 seconds
DEBUG 01-14 20:42:40.277360.277360 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-14 20:42:40.277694.277694 cuda_h.py:10] start sllm_worker_task
DEBUG 01-14 20:42:40.277553.277553 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-14 20:42:40.277568.277568 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-14 20:42:40.277976.277976 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-14 20:42:40.279780.279780 cuda_h.py:19] end allocate_cuda_memory cost 0.002206563949584961 seconds
DEBUG 01-14 20:42:40.279629.279629 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-14 20:42:40.279545.279545 sllm_store_c.py:27] get device uuid map
DEBUG 01-14 20:42:40.279467.279467 sllm_store_c.py:29] call client load into gpu
DEBUG 01-14 20:42:40.280362.280362 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 2996a0ea-728c-4116-82c2-180ac25b5796
DEBUG 01-14 20:42:40.280762.280762 client.py:106] call stub.LoadModelAsync
DEBUG 01-14 20:42:40.280140.280140 mlpmodule.py:1367]  experts func einsum cost 0.07748174667358398 s
DEBUG 01-14 20:42:40.280285.280285 cuda_h.py:10] start self_attn
INFO 01-14 20:42:40.281011.281011 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 2996a0ea-728c-4116-82c2-180ac25b5796
DEBUG 01-14 20:42:40.281423.281423 cuda_h.py:19] end load_into_gpu_async cost 0.0019099712371826172 seconds
DEBUG 01-14 20:42:40.281365.281365 cuda_h.py:10] start restore_tensors2
DEBUG 01-14 20:42:40.281401.281401 cuda_h.py:19] end restore_tensors2 cost 7.009506225585938e-05 seconds
DEBUG 01-14 20:42:40.281488.281488 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0044367313385009766 seconds
INFO 01-14 20:42:40.282947.282947 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 2996a0ea-728c-4116-82c2-180ac25b5796
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-14 20:42:40.284326.284326 cuda_h.py:19] end self_attn cost 0.0032770633697509766 seconds
DEBUG 01-14 20:42:40.284405.284405 cuda_h.py:19] end iln_self_attn_paln cost 0.007228851318359375 seconds
DEBUG 01-14 20:42:40.284076.284076 cuda_h.py:10] start layer_moe_generate_mp_l_5
DEBUG 01-14 20:42:40.284138.284138 cuda_h.py:10] start gate
DEBUG 01-14 20:42:40.285832.285832 cuda_h.py:19] end gate cost 0.0007143020629882812 seconds
DEBUG 01-14 20:42:40.285059.285059 cuda_h.py:10] start experts_map_get
DEBUG 01-14 20:42:40.285276.285276 lmp.py:1615] 
DEBUG 01-14 20:42:40.285276.285276 lmp.py:1615] Expert Token Distribution & Device Allocation:
DEBUG 01-14 20:42:40.285985.285985 lmp.py:1616]   Total experts: 64
DEBUG 01-14 20:42:40.285827.285827 lmp.py:1617]   CPU experts: 32 (50%)
DEBUG 01-14 20:42:40.285093.285093 lmp.py:1618]   GPU experts: 32 (50%)
DEBUG 01-14 20:42:40.285974.285974 lmp.py:1619] 
DEBUG 01-14 20:42:40.285974.285974 lmp.py:1619]   Expert ID | Tokens | Device
DEBUG 01-14 20:42:40.285617.285617 lmp.py:1620]   -----------------------------------
DEBUG 01-14 20:42:40.285975.285975 lmp.py:1625]   Expert 14 |     68 | CPU
DEBUG 01-14 20:42:40.285903.285903 lmp.py:1625]   Expert 13 |     72 | CPU
DEBUG 01-14 20:42:40.285592.285592 lmp.py:1625]   Expert 57 |     77 | CPU
DEBUG 01-14 20:42:40.285520.285520 lmp.py:1625]   Expert 11 |     84 | CPU
DEBUG 01-14 20:42:40.285732.285732 lmp.py:1625]   Expert 31 |     88 | CPU
DEBUG 01-14 20:42:40.285422.285422 lmp.py:1625]   Expert 26 |     89 | CPU
DEBUG 01-14 20:42:40.285111.285111 lmp.py:1625]   Expert 45 |     90 | CPU
DEBUG 01-14 20:42:40.285800.285800 lmp.py:1625]   Expert 54 |     90 | CPU
DEBUG 01-14 20:42:40.286490.286490 lmp.py:1625]   Expert 10 |     96 | CPU
DEBUG 01-14 20:42:40.286941.286941 lmp.py:1625]   Expert 58 |    105 | CPU
DEBUG 01-14 20:42:40.286107.286107 lmp.py:1625]   Expert 30 |    108 | CPU
DEBUG 01-14 20:42:40.286326.286326 lmp.py:1625]   Expert 51 |    109 | CPU
DEBUG 01-14 20:42:40.286254.286254 lmp.py:1625]   Expert 36 |    115 | CPU
DEBUG 01-14 20:42:40.286466.286466 lmp.py:1625]   Expert 32 |    126 | CPU
DEBUG 01-14 20:42:40.286155.286155 lmp.py:1625]   Expert 20 |    128 | CPU
DEBUG 01-14 20:42:40.286368.286368 lmp.py:1625]   Expert  4 |    138 | CPU
DEBUG 01-14 20:42:40.286580.286580 lmp.py:1625]   Expert 61 |    140 | CPU
DEBUG 01-14 20:42:40.286031.286031 lmp.py:1625]   Expert 63 |    140 | CPU
DEBUG 01-14 20:42:40.286005.286005 lmp.py:1625]   Expert 16 |    142 | CPU
DEBUG 01-14 20:42:40.286456.286456 lmp.py:1625]   Expert 47 |    149 | CPU
DEBUG 01-14 20:42:40.286907.286907 lmp.py:1625]   Expert 34 |    151 | CPU
DEBUG 01-14 20:42:40.286073.286073 lmp.py:1625]   Expert 42 |    151 | CPU
DEBUG 01-14 20:42:40.286524.286524 lmp.py:1625]   Expert 53 |    151 | CPU
DEBUG 01-14 20:42:40.286498.286498 lmp.py:1625]   Expert  8 |    154 | CPU
DEBUG 01-14 20:42:40.286711.286711 lmp.py:1625]   Expert 60 |    156 | CPU
DEBUG 01-14 20:42:40.286685.286685 lmp.py:1625]   Expert 28 |    157 | CPU
DEBUG 01-14 20:42:40.286897.286897 lmp.py:1625]   Expert 17 |    169 | CPU
DEBUG 01-14 20:42:40.286110.286110 lmp.py:1625]   Expert 27 |    171 | CPU
DEBUG 01-14 20:42:40.286084.286084 lmp.py:1625]   Expert 44 |    176 | CPU
DEBUG 01-14 20:42:40.286296.286296 lmp.py:1625]   Expert 56 |    176 | CPU
DEBUG 01-14 20:42:40.286270.286270 lmp.py:1625]   Expert 29 |    179 | CPU
DEBUG 01-14 20:42:40.286244.286244 lmp.py:1625]   Expert 24 |    181 | CPU
DEBUG 01-14 20:42:40.286602.286602 lmp.py:1625]   Expert 41 |    181 | GPU
DEBUG 01-14 20:42:40.286530.286530 lmp.py:1625]   Expert  0 |    182 | GPU
DEBUG 01-14 20:42:40.286981.286981 lmp.py:1625]   Expert 48 |    183 | GPU
DEBUG 01-14 20:42:40.286193.286193 lmp.py:1625]   Expert  7 |    186 | GPU
DEBUG 01-14 20:42:40.286836.286836 lmp.py:1625]   Expert  9 |    186 | GPU
DEBUG 01-14 20:42:40.286003.286003 lmp.py:1625]   Expert  2 |    187 | GPU
DEBUG 01-14 20:42:40.286407.286407 lmp.py:1625]   Expert 15 |    188 | GPU
DEBUG 01-14 20:42:40.286812.286812 lmp.py:1625]   Expert  3 |    189 | GPU
DEBUG 01-14 20:42:40.286216.286216 lmp.py:1625]   Expert 18 |    196 | GPU
DEBUG 01-14 20:42:40.286382.286382 lmp.py:1625]   Expert 40 |    199 | GPU
DEBUG 01-14 20:42:40.286502.286502 lmp.py:1625]   Expert 55 |    199 | GPU
DEBUG 01-14 20:42:40.286860.286860 lmp.py:1625]   Expert  6 |    214 | GPU
DEBUG 01-14 20:42:40.286027.286027 lmp.py:1625]   Expert 22 |    214 | GPU
DEBUG 01-14 20:42:40.286431.286431 lmp.py:1625]   Expert 38 |    215 | GPU
DEBUG 01-14 20:42:40.286597.286597 lmp.py:1625]   Expert 37 |    224 | GPU
DEBUG 01-14 20:42:40.286525.286525 lmp.py:1625]   Expert 23 |    230 | GPU
DEBUG 01-14 20:42:40.286453.286453 lmp.py:1625]   Expert 25 |    238 | GPU
DEBUG 01-14 20:42:40.286380.286380 lmp.py:1625]   Expert 46 |    241 | GPU
DEBUG 01-14 20:42:40.286308.286308 lmp.py:1625]   Expert 50 |    250 | GPU
DEBUG 01-14 20:42:40.286236.286236 lmp.py:1625]   Expert 39 |    258 | GPU
DEBUG 01-14 20:42:40.286687.286687 lmp.py:1625]   Expert 62 |    261 | GPU
DEBUG 01-14 20:42:40.286614.286614 lmp.py:1625]   Expert 12 |    262 | GPU
DEBUG 01-14 20:42:40.286496.286496 lmp.py:1625]   Expert 21 |    268 | GPU
DEBUG 01-14 20:42:40.286854.286854 lmp.py:1625]   Expert 19 |    272 | GPU
DEBUG 01-14 20:42:40.286020.286020 lmp.py:1625]   Expert 35 |    289 | GPU
DEBUG 01-14 20:42:40.286186.286186 lmp.py:1625]   Expert 49 |    291 | GPU
DEBUG 01-14 20:42:40.286114.286114 lmp.py:1625]   Expert 52 |    300 | GPU
DEBUG 01-14 20:42:40.286042.286042 lmp.py:1625]   Expert 33 |    309 | GPU
DEBUG 01-14 20:42:40.286446.286446 lmp.py:1625]   Expert  1 |    346 | GPU
DEBUG 01-14 20:42:40.286374.286374 lmp.py:1625]   Expert  5 |    377 | GPU
DEBUG 01-14 20:42:40.286540.286540 lmp.py:1625]   Expert 43 |    433 | GPU
DEBUG 01-14 20:42:40.286468.286468 lmp.py:1625]   Expert 59 |    594 | GPU
DEBUG 01-14 20:42:40.286826.286826 lmp.py:1626] 
DEBUG 01-14 20:42:40.286826.286826 lmp.py:1626]   CPU total tokens: 4126 (33.6%)
DEBUG 01-14 20:42:40.286900.286900 lmp.py:1627]   GPU total tokens: 8162 (66.4%)
DEBUG 01-14 20:42:40.286073.286073 cuda_h.py:19] end experts_map_get cost 0.0015549659729003906 seconds
DEBUG 01-14 20:42:40.287115.287115 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-14 20:42:40.287527.287527 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-14 20:42:40.287949.287949 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-14 20:42:40.289801.289801 cuda_h.py:19] end allocate_cuda_memory cost 0.0018961429595947266 seconds
DEBUG 01-14 20:42:40.289506.289506 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-14 20:42:40.289262.289262 sllm_store_c.py:27] get device uuid map
DEBUG 01-14 20:42:40.289117.289117 sllm_store_c.py:29] call client load into gpu
DEBUG 01-14 20:42:40.289436.289436 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 629254f2-c4ab-42d4-b1ac-29cec723300b
DEBUG 01-14 20:42:40.289448.289448 client.py:106] call stub.LoadModelAsync
INFO 01-14 20:42:40.289536.289536 client.py:127] Model loaded
DEBUG 01-14 20:42:40.290856.290856 cuda_h.py:10] start restore2model
DEBUG 01-14 20:42:40.290322.290322 cuda_h.py:19] end restore2model cost 0.0004086494445800781 seconds
DEBUG 01-14 20:42:40.290436.290436 cuda_h.py:19] end sllm_worker_task cost 0.013082027435302734 seconds
INFO 01-14 20:42:40.291151.291151 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 629254f2-c4ab-42d4-b1ac-29cec723300b
DEBUG 01-14 20:42:40.291855.291855 cuda_h.py:19] end load_into_gpu_async cost 0.002294301986694336 seconds
DEBUG 01-14 20:42:40.291465.291465 cuda_h.py:10] start restore_tensors2
DEBUG 01-14 20:42:40.292181.292181 cuda_h.py:19] end restore_tensors2 cost 0.00039458274841308594 seconds
DEBUG 01-14 20:42:40.292640.292640 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.004939556121826172 seconds
DEBUG 01-14 20:42:40.292787.292787 cuda_h.py:10] start restore2model
DEBUG 01-14 20:42:40.294445.294445 cuda_h.py:19] end restore2model cost 0.0025970935821533203 seconds
DEBUG 01-14 20:42:40.294619.294619 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.007718324661254883 seconds
DEBUG 01-14 20:42:40.294699.294699 cuda_h.py:10] start gpu_sexperts
DEBUG 01-14 20:42:40.295372.295372 cuda_h.py:19] end gpu_sexperts cost 0.0002899169921875 seconds
DEBUG 01-14 20:42:40.295864.295864 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-14 20:42:40.295236.295236 lmp.py:1683] 
DEBUG 01-14 20:42:40.295236.295236 lmp.py:1683]   Computing 32 experts on CPU...
DEBUG 01-14 20:42:40.295979.295979 cuda_h.py:19] end cpu_experts_submit cost 5.626678466796875e-05 seconds
DEBUG 01-14 20:42:40.295252.295252 cuda_h.py:10] start experts_func_mgpu_group_pad
DEBUG 01-14 20:42:40.300949.300949 mlpmodule.py:1460] group tensors cost 0.005148172378540039 s
DEBUG 01-14 20:42:40.301182.301182 cuda_h.py:10] start move_flat_hidden2cpu
DEBUG 01-14 20:42:40.303554.303554 cuda_h.py:19] end experts_func_mgpu_group_pad cost 0.008152008056640625 seconds
DEBUG 01-14 20:42:40.304023.304023 cuda_h.py:10] start gpu_group_list
DEBUG 01-14 20:42:40.305459.305459 cuda_h.py:19] end gpu_group_list cost 0.00043702125549316406 seconds
DEBUG 01-14 20:42:40.305234.305234 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-14 20:42:40.305521.305521 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.09808349609375e-05 seconds
DEBUG 01-14 20:42:40.305231.305231 cuda_h.py:10] start wait_experts
INFO 01-14 20:42:40.305510.305510 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 629254f2-c4ab-42d4-b1ac-29cec723300b
DEBUG 01-14 20:42:40.308008.308008 cuda_h.py:19] end move_flat_hidden2cpu cost 0.006986379623413086 seconds
DEBUG 01-14 20:42:40.310375.310375 mlpmodule.py:1533] pad cost 0.0019402503967285156 s
DEBUG 01-14 20:42:40.310307.310307 mlpmodule.py:1539] create cpu tensor cost 4.267692565917969e-05 s
DEBUG 01-14 20:42:40.312989.312989 mlpmodule.py:1544] move to cpu cost 0.0021419525146484375 s
DEBUG 01-14 20:42:40.323271.323271 mlpmodule.py:1558] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-14 20:42:40.323588.323588 mlpmodule.py:1559] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-14 20:42:40.323472.323472 mlpmodule.py:1564] group_w3 first element: 0.0086669921875
WARNING 01-14 20:42:40.323204.323204 mlpmodule.py:1574] start einsum2
DEBUG 01-14 20:42:40.342234.342234 mlpmodule.py:1584] group einsum cost 0.029170989990234375 s
DEBUG 01-14 20:42:40.343497.343497 mlpmodule.py:1593] cpy2cputensor cost 0.0007331371307373047 s
DEBUG 01-14 20:42:40.343287.343287 cuda_h.py:10] start move_outputs
DEBUG 01-14 20:42:40.346854.346854 cuda_h.py:19] end move_outputs cost 0.0028760433197021484 seconds
INFO 01-14 20:42:40.349743.349743 client.py:127] Model loaded
DEBUG 01-14 20:42:40.349166.349166 cuda_h.py:19] end wait_experts cost 0.04410696029663086 seconds
DEBUG 01-14 20:42:40.349267.349267 cuda_h.py:10] start gpu_experts
DEBUG 01-14 20:42:40.349705.349705 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-14 20:42:40.350421.350421 cuda_h.py:19] end wait_cetm_experts cost 0.0001823902130126953 seconds
DEBUG 01-14 20:42:40.350708.350708 cuda_h.py:10] start gpu_group_einsum_mp_multi_list
DEBUG 01-14 20:42:40.350656.350656 cuda_h.py:10] start gpu_group_tensor
DEBUG 01-14 20:42:40.360106.360106 cuda_h.py:19] end gpu_group_tensor cost 0.01001286506652832 seconds
DEBUG 01-14 20:42:40.360635.360635 cuda_h.py:10] start gpu_group_einsum
DEBUG 01-14 20:42:40.361021.361021 cuda_h.py:19] end gpu_group_einsum cost 0.00060272216796875 seconds
DEBUG 01-14 20:42:40.361714.361714 cuda_h.py:10] start gpu_final_hidden_states_scatter
DEBUG 01-14 20:42:40.361081.361081 cuda_h.py:10] start all_expert_outputs_slices
DEBUG 01-14 20:42:40.361898.361898 cuda_h.py:19] end all_expert_outputs_slices cost 0.00025391578674316406 seconds
DEBUG 01-14 20:42:40.361893.361893 cuda_h.py:10] start concat_expert_out
DEBUG 01-14 20:42:40.361128.361128 cuda_h.py:19] end concat_expert_out cost 5.888938903808594e-05 seconds
DEBUG 01-14 20:42:40.361163.361163 cuda_h.py:10] start index_scatter
DEBUG 01-14 20:42:40.361391.361391 cuda_h.py:19] end index_scatter cost 6.651878356933594e-05 seconds
DEBUG 01-14 20:42:40.362339.362339 cuda_h.py:19] end gpu_final_hidden_states_scatter cost 0.0006265640258789062 seconds
DEBUG 01-14 20:42:40.362911.362911 cuda_h.py:19] end gpu_experts cost 0.012105464935302734 seconds
DEBUG 01-14 20:42:40.362323.362323 cuda_h.py:10] start all_expert_weight_slices
DEBUG 01-14 20:42:40.362747.362747 cuda_h.py:19] end all_expert_weight_slices cost 0.0007765293121337891 seconds
DEBUG 01-14 20:42:40.362854.362854 cuda_h.py:10] start cpuoutputsdeal
DEBUG 01-14 20:42:40.363913.363913 cuda_h.py:10] start index_scatter
DEBUG 01-14 20:42:40.363472.363472 cuda_h.py:19] end index_scatter cost 4.863739013671875e-05 seconds
DEBUG 01-14 20:42:40.363520.363520 cuda_h.py:19] end cpuoutputsdeal cost 0.00046539306640625 seconds
DEBUG 01-14 20:42:40.363992.363992 cuda_h.py:19] end layer_moe_generate_mp_l_5 cost 0.07893729209899902 seconds
DEBUG 01-14 20:42:40.363911.363911 cuda_h.py:19] end prefill_layer cost 0.08681964874267578 seconds
DEBUG 01-14 20:42:40.363661.363661 lmp.py:1551] -------------------------------- end prefill layer 4 --------------------------------
DEBUG 01-14 20:42:40.363026.363026 cuda_h.py:10] start prefill_layer
DEBUG 01-14 20:42:40.363153.363153 lmp.py:1494] -------------------------------- start prefill layer 5 --------------------------------
DEBUG 01-14 20:42:40.363756.363756 cuda_h.py:10] start start_load_qkvogn_s_weight_l_6
DEBUG 01-14 20:42:40.363313.363313 cuda_h.py:10] start start_load_qkvogn_s_weight_l_6
DEBUG 01-14 20:42:40.364242.364242 cuda_h.py:19] end start_load_qkvogn_s_weight_l_6 cost 2.9325485229492188e-05 seconds
DEBUG 01-14 20:42:40.364514.364514 cuda_h.py:19] end start_load_qkvogn_s_weight_l_6 cost 5.7220458984375e-05 seconds
DEBUG 01-14 20:42:40.364873.364873 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-14 20:42:40.364875.364875 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-14 20:42:40.364984.364984 cuda_h.py:10] start sllm_worker_task
DEBUG 01-14 20:42:40.364934.364934 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-14 20:42:40.364493.364493 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-14 20:42:40.365002.365002 cuda_h.py:19] end allocate_cuda_memory cost 0.0011310577392578125 seconds
DEBUG 01-14 20:42:40.365567.365567 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-14 20:42:40.365992.365992 sllm_store_c.py:27] get device uuid map
DEBUG 01-14 20:42:40.365915.365915 sllm_store_c.py:29] call client load into gpu
DEBUG 01-14 20:42:40.365664.365664 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 5a6a9c72-9a71-4bf7-9b1b-4bdb5af5373d
DEBUG 01-14 20:42:40.365488.365488 client.py:106] call stub.LoadModelAsync
DEBUG 01-14 20:42:40.366416.366416 mlpmodule.py:1367]  experts func einsum cost 0.07033371925354004 s
DEBUG 01-14 20:42:40.366689.366689 cuda_h.py:10] start self_attn
INFO 01-14 20:42:40.367483.367483 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 5a6a9c72-9a71-4bf7-9b1b-4bdb5af5373d
DEBUG 01-14 20:42:40.367002.367002 cuda_h.py:19] end load_into_gpu_async cost 0.0016524791717529297 seconds
DEBUG 01-14 20:42:40.367142.367142 cuda_h.py:10] start restore_tensors2
DEBUG 01-14 20:42:40.367252.367252 cuda_h.py:19] end restore_tensors2 cost 8.130073547363281e-05 seconds
DEBUG 01-14 20:42:40.367127.367127 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0031614303588867188 seconds
INFO 01-14 20:42:40.367500.367500 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 5a6a9c72-9a71-4bf7-9b1b-4bdb5af5373d
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-14 20:42:40.369963.369963 cuda_h.py:19] end self_attn cost 0.0029451847076416016 seconds
DEBUG 01-14 20:42:40.369900.369900 cuda_h.py:19] end iln_self_attn_paln cost 0.005539894104003906 seconds
DEBUG 01-14 20:42:40.369743.369743 cuda_h.py:10] start layer_moe_generate_mp_l_6
DEBUG 01-14 20:42:40.369029.369029 cuda_h.py:10] start gate
DEBUG 01-14 20:42:40.370939.370939 cuda_h.py:19] end gate cost 0.0006361007690429688 seconds
DEBUG 01-14 20:42:40.370722.370722 cuda_h.py:10] start experts_map_get
DEBUG 01-14 20:42:40.370845.370845 lmp.py:1615] 
DEBUG 01-14 20:42:40.370845.370845 lmp.py:1615] Expert Token Distribution & Device Allocation:
DEBUG 01-14 20:42:40.370601.370601 lmp.py:1616]   Total experts: 64
DEBUG 01-14 20:42:40.370727.370727 lmp.py:1617]   CPU experts: 32 (50%)
DEBUG 01-14 20:42:40.370039.370039 lmp.py:1618]   GPU experts: 32 (50%)
DEBUG 01-14 20:42:40.370682.370682 lmp.py:1619] 
DEBUG 01-14 20:42:40.370682.370682 lmp.py:1619]   Expert ID | Tokens | Device
DEBUG 01-14 20:42:40.370087.370087 lmp.py:1620]   -----------------------------------
DEBUG 01-14 20:42:40.370684.370684 lmp.py:1625]   Expert 34 |     38 | CPU
DEBUG 01-14 20:42:40.370373.370373 lmp.py:1625]   Expert 45 |     70 | CPU
DEBUG 01-14 20:42:40.370731.370731 lmp.py:1625]   Expert 22 |     77 | CPU
DEBUG 01-14 20:42:40.370612.370612 lmp.py:1625]   Expert 57 |     94 | CPU
DEBUG 01-14 20:42:40.370017.370017 lmp.py:1625]   Expert 17 |     97 | CPU
DEBUG 01-14 20:42:40.370183.370183 lmp.py:1625]   Expert 15 |    100 | CPU
DEBUG 01-14 20:42:40.371780.371780 lmp.py:1625]   Expert  4 |    105 | CPU
DEBUG 01-14 20:42:40.371615.371615 lmp.py:1625]   Expert 28 |    110 | CPU
DEBUG 01-14 20:42:40.371019.371019 lmp.py:1625]   Expert 16 |    113 | CPU
DEBUG 01-14 20:42:40.371662.371662 lmp.py:1625]   Expert 12 |    120 | CPU
DEBUG 01-14 20:42:40.371829.371829 lmp.py:1625]   Expert 60 |    121 | CPU
DEBUG 01-14 20:42:40.371518.371518 lmp.py:1625]   Expert 14 |    127 | CPU
DEBUG 01-14 20:42:40.371922.371922 lmp.py:1625]   Expert 32 |    127 | CPU
DEBUG 01-14 20:42:40.371089.371089 lmp.py:1625]   Expert 36 |    128 | CPU
DEBUG 01-14 20:42:40.371255.371255 lmp.py:1625]   Expert 25 |    129 | CPU
DEBUG 01-14 20:42:40.371659.371659 lmp.py:1625]   Expert  8 |    130 | CPU
DEBUG 01-14 20:42:40.371779.371779 lmp.py:1625]   Expert 52 |    130 | CPU
DEBUG 01-14 20:42:40.371184.371184 lmp.py:1625]   Expert  2 |    134 | CPU
DEBUG 01-14 20:42:40.371588.371588 lmp.py:1625]   Expert  0 |    138 | CPU
DEBUG 01-14 20:42:40.371516.371516 lmp.py:1625]   Expert  5 |    142 | CPU
DEBUG 01-14 20:42:40.371444.371444 lmp.py:1625]   Expert 35 |    146 | CPU
DEBUG 01-14 20:42:40.371848.371848 lmp.py:1625]   Expert 41 |    153 | CPU
DEBUG 01-14 20:42:40.371014.371014 lmp.py:1625]   Expert 23 |    154 | CPU
DEBUG 01-14 20:42:40.371180.371180 lmp.py:1625]   Expert 39 |    159 | CPU
DEBUG 01-14 20:42:40.371108.371108 lmp.py:1625]   Expert 61 |    162 | CPU
DEBUG 01-14 20:42:40.371274.371274 lmp.py:1625]   Expert 30 |    164 | CPU
DEBUG 01-14 20:42:40.371440.371440 lmp.py:1625]   Expert 44 |    168 | CPU
DEBUG 01-14 20:42:40.371130.371130 lmp.py:1625]   Expert 43 |    170 | CPU
DEBUG 01-14 20:42:40.371819.371819 lmp.py:1625]   Expert 13 |    174 | CPU
DEBUG 01-14 20:42:40.371462.371462 lmp.py:1625]   Expert 31 |    174 | CPU
DEBUG 01-14 20:42:40.371105.371105 lmp.py:1625]   Expert  3 |    175 | CPU
DEBUG 01-14 20:42:40.371271.371271 lmp.py:1625]   Expert  9 |    176 | CPU
DEBUG 01-14 20:42:40.371722.371722 lmp.py:1625]   Expert 50 |    187 | GPU
DEBUG 01-14 20:42:40.371411.371411 lmp.py:1625]   Expert 62 |    187 | GPU
DEBUG 01-14 20:42:40.371339.371339 lmp.py:1625]   Expert 42 |    188 | GPU
DEBUG 01-14 20:42:40.371028.371028 lmp.py:1625]   Expert 46 |    188 | GPU
DEBUG 01-14 20:42:40.371956.371956 lmp.py:1625]   Expert 11 |    193 | GPU
DEBUG 01-14 20:42:40.371837.371837 lmp.py:1625]   Expert 47 |    193 | GPU
DEBUG 01-14 20:42:40.371765.371765 lmp.py:1625]   Expert 20 |    195 | GPU
DEBUG 01-14 20:42:40.371454.371454 lmp.py:1625]   Expert 26 |    196 | GPU
DEBUG 01-14 20:42:40.371382.371382 lmp.py:1625]   Expert 51 |    196 | GPU
DEBUG 01-14 20:42:40.371310.371310 lmp.py:1625]   Expert 19 |    201 | GPU
DEBUG 01-14 20:42:40.371999.371999 lmp.py:1625]   Expert 18 |    203 | GPU
DEBUG 01-14 20:42:40.371927.371927 lmp.py:1625]   Expert 63 |    203 | GPU
DEBUG 01-14 20:42:40.371855.371855 lmp.py:1625]   Expert 27 |    205 | GPU
DEBUG 01-14 20:42:40.371021.371021 lmp.py:1625]   Expert 56 |    208 | GPU
DEBUG 01-14 20:42:40.371425.371425 lmp.py:1625]   Expert 55 |    212 | GPU
DEBUG 01-14 20:42:40.371307.371307 lmp.py:1625]   Expert 38 |    216 | GPU
DEBUG 01-14 20:42:40.371234.371234 lmp.py:1625]   Expert 49 |    219 | GPU
DEBUG 01-14 20:42:40.371162.371162 lmp.py:1625]   Expert 48 |    225 | GPU
DEBUG 01-14 20:42:40.371851.371851 lmp.py:1625]   Expert  1 |    234 | GPU
DEBUG 01-14 20:42:40.371541.371541 lmp.py:1625]   Expert 54 |    241 | GPU
DEBUG 01-14 20:42:40.371230.371230 lmp.py:1625]   Expert  7 |    243 | GPU
DEBUG 01-14 20:42:40.371158.371158 lmp.py:1625]   Expert 10 |    243 | GPU
DEBUG 01-14 20:42:40.371086.371086 lmp.py:1625]   Expert 21 |    248 | GPU
DEBUG 01-14 20:42:40.371728.371728 lmp.py:1625]   Expert 24 |    251 | GPU
DEBUG 01-14 20:42:40.371371.371371 lmp.py:1625]   Expert 33 |    252 | GPU
DEBUG 01-14 20:42:40.371776.371776 lmp.py:1625]   Expert 29 |    261 | GPU
DEBUG 01-14 20:42:40.371704.371704 lmp.py:1625]   Expert 40 |    273 | GPU
DEBUG 01-14 20:42:40.371155.371155 lmp.py:1625]   Expert 59 |    294 | GPU
DEBUG 01-14 20:42:40.371082.371082 lmp.py:1625]   Expert 37 |    337 | GPU
DEBUG 01-14 20:42:40.371010.371010 lmp.py:1625]   Expert 58 |    356 | GPU
DEBUG 01-14 20:42:40.371938.371938 lmp.py:1625]   Expert  6 |    385 | GPU
DEBUG 01-14 20:42:40.371104.371104 lmp.py:1625]   Expert 53 |    850 | GPU
DEBUG 01-14 20:42:40.372224.372224 lmp.py:1626] 
DEBUG 01-14 20:42:40.372224.372224 lmp.py:1626]   CPU total tokens: 4205 (34.2%)
DEBUG 01-14 20:42:40.372820.372820 lmp.py:1627]   GPU total tokens: 8083 (65.8%)
DEBUG 01-14 20:42:40.372755.372755 cuda_h.py:19] end experts_map_get cost 0.0015411376953125 seconds
DEBUG 01-14 20:42:40.372128.372128 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-14 20:42:40.372395.372395 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-14 20:42:40.372148.372148 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-14 20:42:40.373881.373881 cuda_h.py:19] end allocate_cuda_memory cost 0.0013165473937988281 seconds
DEBUG 01-14 20:42:40.373506.373506 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-14 20:42:40.373739.373739 sllm_store_c.py:27] get device uuid map
DEBUG 01-14 20:42:40.373926.373926 sllm_store_c.py:29] call client load into gpu
DEBUG 01-14 20:42:40.373337.373337 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 3c5173f8-13a7-4efb-9c86-79b084d39f5d
DEBUG 01-14 20:42:40.373628.373628 client.py:106] call stub.LoadModelAsync
INFO 01-14 20:42:40.375585.375585 client.py:127] Model loaded
DEBUG 01-14 20:42:40.375893.375893 cuda_h.py:10] start restore2model
DEBUG 01-14 20:42:40.376088.376088 cuda_h.py:19] end restore2model cost 0.0005927085876464844 seconds
DEBUG 01-14 20:42:40.376249.376249 cuda_h.py:19] end sllm_worker_task cost 0.011966943740844727 seconds
INFO 01-14 20:42:40.376353.376353 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 3c5173f8-13a7-4efb-9c86-79b084d39f5d
DEBUG 01-14 20:42:40.376818.376818 cuda_h.py:19] end load_into_gpu_async cost 0.003144979476928711 seconds
DEBUG 01-14 20:42:40.376475.376475 cuda_h.py:10] start restore_tensors2
DEBUG 01-14 20:42:40.377833.377833 cuda_h.py:19] end restore_tensors2 cost 0.00037741661071777344 seconds
DEBUG 01-14 20:42:40.377623.377623 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.00520014762878418 seconds
DEBUG 01-14 20:42:40.377862.377862 cuda_h.py:10] start restore2model
DEBUG 01-14 20:42:40.380645.380645 cuda_h.py:19] end restore2model cost 0.0025854110717773438 seconds
DEBUG 01-14 20:42:40.380720.380720 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.007957935333251953 seconds
DEBUG 01-14 20:42:40.380536.380536 cuda_h.py:10] start gpu_sexperts
DEBUG 01-14 20:42:40.380579.380579 cuda_h.py:19] end gpu_sexperts cost 0.00028324127197265625 seconds
DEBUG 01-14 20:42:40.380356.380356 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-14 20:42:40.380012.380012 lmp.py:1683] 
DEBUG 01-14 20:42:40.380012.380012 lmp.py:1683]   Computing 32 experts on CPU...
DEBUG 01-14 20:42:40.380802.380802 cuda_h.py:19] end cpu_experts_submit cost 5.53131103515625e-05 seconds
DEBUG 01-14 20:42:40.380697.380697 cuda_h.py:10] start experts_func_mgpu_group_pad
DEBUG 01-14 20:42:40.392195.392195 mlpmodule.py:1460] group tensors cost 0.011291027069091797 s
DEBUG 01-14 20:42:40.393110.393110 cuda_h.py:10] start move_flat_hidden2cpu
DEBUG 01-14 20:42:40.398977.398977 cuda_h.py:19] end experts_func_mgpu_group_pad cost 0.017966270446777344 seconds
DEBUG 01-14 20:42:40.399652.399652 cuda_h.py:19] end move_flat_hidden2cpu cost 0.006579160690307617 seconds
DEBUG 01-14 20:42:40.402853.402853 cuda_h.py:10] start gpu_group_list
DEBUG 01-14 20:42:40.403793.403793 cuda_h.py:19] end gpu_group_list cost 0.001146554946899414 seconds
DEBUG 01-14 20:42:40.404874.404874 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-14 20:42:40.404530.404530 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 4.220008850097656e-05 seconds
DEBUG 01-14 20:42:40.404044.404044 cuda_h.py:10] start wait_experts
INFO 01-14 20:42:40.404843.404843 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 3c5173f8-13a7-4efb-9c86-79b084d39f5d
DEBUG 01-14 20:42:40.404148.404148 mlpmodule.py:1533] pad cost 0.0050237178802490234 s
DEBUG 01-14 20:42:40.405887.405887 mlpmodule.py:1539] create cpu tensor cost 3.7670135498046875e-05 s
DEBUG 01-14 20:42:40.407044.407044 mlpmodule.py:1544] move to cpu cost 0.0020792484283447266 s
DEBUG 01-14 20:42:40.417878.417878 mlpmodule.py:1558] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-14 20:42:40.417963.417963 mlpmodule.py:1559] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-14 20:42:40.417370.417370 mlpmodule.py:1564] group_w3 first element: 0.03369140625
WARNING 01-14 20:42:40.417818.417818 mlpmodule.py:1574] start einsum2
INFO 01-14 20:42:40.432682.432682 client.py:127] Model loaded
DEBUG 01-14 20:42:40.432407.432407 cuda_h.py:19] end wait_experts cost 0.02783656120300293 seconds
DEBUG 01-14 20:42:40.432562.432562 cuda_h.py:10] start gpu_experts
DEBUG 01-14 20:42:40.432326.432326 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-14 20:42:40.435525.435525 mlpmodule.py:1584] group einsum cost 0.027914762496948242 s
DEBUG 01-14 20:42:40.436627.436627 mlpmodule.py:1593] cpy2cputensor cost 0.0007164478302001953 s
DEBUG 01-14 20:42:40.436112.436112 cuda_h.py:10] start move_outputs
DEBUG 01-14 20:42:40.438777.438777 cuda_h.py:19] end move_outputs cost 0.0020363330841064453 seconds
DEBUG 01-14 20:42:40.441885.441885 cuda_h.py:19] end wait_cetm_experts cost 0.009115457534790039 seconds
DEBUG 01-14 20:42:40.441513.441513 cuda_h.py:10] start gpu_group_einsum_mp_multi_list
DEBUG 01-14 20:42:40.441137.441137 cuda_h.py:10] start gpu_group_tensor
DEBUG 01-14 20:42:40.442431.442431 cuda_h.py:19] end gpu_group_tensor cost 0.00025463104248046875 seconds
DEBUG 01-14 20:42:40.442117.442117 cuda_h.py:10] start gpu_group_einsum
DEBUG 01-14 20:42:40.458195.458195 mlpmodule.py:1367]  experts func einsum cost 0.07719135284423828 s
DEBUG 01-14 20:42:40.459189.459189 cuda_h.py:19] end gpu_group_einsum cost 0.01710653305053711 seconds
DEBUG 01-14 20:42:40.459001.459001 cuda_h.py:10] start gpu_final_hidden_states_scatter
DEBUG 01-14 20:42:40.460622.460622 cuda_h.py:10] start all_expert_outputs_slices
DEBUG 01-14 20:42:40.460879.460879 cuda_h.py:19] end all_expert_outputs_slices cost 0.0006608963012695312 seconds
DEBUG 01-14 20:42:40.460140.460140 cuda_h.py:10] start concat_expert_out
DEBUG 01-14 20:42:40.461823.461823 cuda_h.py:19] end concat_expert_out cost 0.0001418590545654297 seconds
DEBUG 01-14 20:42:40.461418.461418 cuda_h.py:10] start index_scatter
DEBUG 01-14 20:42:40.461306.461306 cuda_h.py:19] end index_scatter cost 0.00014472007751464844 seconds
DEBUG 01-14 20:42:40.461051.461051 cuda_h.py:19] end gpu_final_hidden_states_scatter cost 0.0015711784362792969 seconds
DEBUG 01-14 20:42:40.461772.461772 cuda_h.py:19] end gpu_experts cost 0.029168367385864258 seconds
DEBUG 01-14 20:42:40.461351.461351 cuda_h.py:10] start all_expert_weight_slices
DEBUG 01-14 20:42:40.464793.464793 cuda_h.py:19] end all_expert_weight_slices cost 0.0022449493408203125 seconds
DEBUG 01-14 20:42:40.464221.464221 cuda_h.py:10] start cpuoutputsdeal
DEBUG 01-14 20:42:40.465559.465559 cuda_h.py:10] start index_scatter
DEBUG 01-14 20:42:40.465084.465084 cuda_h.py:19] end index_scatter cost 0.0001220703125 seconds
DEBUG 01-14 20:42:40.465988.465988 cuda_h.py:19] end cpuoutputsdeal cost 0.0012962818145751953 seconds
DEBUG 01-14 20:42:40.465948.465948 cuda_h.py:19] end layer_moe_generate_mp_l_6 cost 0.09606719017028809 seconds
DEBUG 01-14 20:42:40.466395.466395 cuda_h.py:19] end prefill_layer cost 0.10254526138305664 seconds
DEBUG 01-14 20:42:40.466830.466830 lmp.py:1551] -------------------------------- end prefill layer 5 --------------------------------
DEBUG 01-14 20:42:40.466164.466164 cuda_h.py:10] start prefill_layer
DEBUG 01-14 20:42:40.466451.466451 lmp.py:1494] -------------------------------- start prefill layer 6 --------------------------------
DEBUG 01-14 20:42:40.466261.466261 cuda_h.py:10] start start_load_qkvogn_s_weight_l_7
DEBUG 01-14 20:42:40.466694.466694 cuda_h.py:10] start start_load_qkvogn_s_weight_l_7
DEBUG 01-14 20:42:40.467692.467692 cuda_h.py:19] end start_load_qkvogn_s_weight_l_7 cost 6.222724914550781e-05 seconds
DEBUG 01-14 20:42:40.467655.467655 cuda_h.py:19] end start_load_qkvogn_s_weight_l_7 cost 0.00015115737915039062 seconds
DEBUG 01-14 20:42:40.467405.467405 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-14 20:42:40.467788.467788 cuda_h.py:10] start sllm_worker_task
DEBUG 01-14 20:42:40.467874.467874 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-14 20:42:40.467249.467249 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-14 20:42:40.468590.468590 cuda_h.py:19] end allocate_cuda_memory cost 0.00039577484130859375 seconds
DEBUG 01-14 20:42:40.468609.468609 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-14 20:42:40.468302.468302 sllm_store_c.py:27] get device uuid map
DEBUG 01-14 20:42:40.468074.468074 sllm_store_c.py:29] call client load into gpu
DEBUG 01-14 20:42:40.468428.468428 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 84214e9a-c916-4207-9bab-1c8930ff36ae
DEBUG 01-14 20:42:40.468313.468313 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-14 20:42:40.469677.469677 client.py:106] call stub.LoadModelAsync
DEBUG 01-14 20:42:40.469661.469661 cuda_h.py:10] start self_attn
INFO 01-14 20:42:40.470613.470613 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 84214e9a-c916-4207-9bab-1c8930ff36ae
DEBUG 01-14 20:42:40.471062.471062 cuda_h.py:19] end load_into_gpu_async cost 0.0025222301483154297 seconds
DEBUG 01-14 20:42:40.471668.471668 cuda_h.py:10] start restore_tensors2
DEBUG 01-14 20:42:40.471126.471126 cuda_h.py:19] end restore_tensors2 cost 0.0001518726348876953 seconds
DEBUG 01-14 20:42:40.471560.471560 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.003780364990234375 seconds
INFO 01-14 20:42:40.471518.471518 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 84214e9a-c916-4207-9bab-1c8930ff36ae
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-14 20:42:40.473847.473847 cuda_h.py:19] end self_attn cost 0.003889322280883789 seconds
DEBUG 01-14 20:42:40.473197.473197 cuda_h.py:19] end iln_self_attn_paln cost 0.006555795669555664 seconds
DEBUG 01-14 20:42:40.473391.473391 cuda_h.py:10] start layer_moe_generate_mp_l_7
DEBUG 01-14 20:42:40.473737.473737 cuda_h.py:10] start gate
DEBUG 01-14 20:42:40.474445.474445 cuda_h.py:19] end gate cost 0.0007176399230957031 seconds
DEBUG 01-14 20:42:40.474195.474195 cuda_h.py:10] start experts_map_get
DEBUG 01-14 20:42:40.475625.475625 lmp.py:1615] 
DEBUG 01-14 20:42:40.475625.475625 lmp.py:1615] Expert Token Distribution & Device Allocation:
DEBUG 01-14 20:42:40.475018.475018 lmp.py:1616]   Total experts: 64
DEBUG 01-14 20:42:40.475635.475635 lmp.py:1617]   CPU experts: 32 (50%)
DEBUG 01-14 20:42:40.475006.475006 lmp.py:1618]   GPU experts: 32 (50%)
DEBUG 01-14 20:42:40.475709.475709 lmp.py:1619] 
DEBUG 01-14 20:42:40.475709.475709 lmp.py:1619]   Expert ID | Tokens | Device
DEBUG 01-14 20:42:40.475459.475459 lmp.py:1620]   -----------------------------------
DEBUG 01-14 20:42:40.475400.475400 lmp.py:1625]   Expert  1 |     51 | CPU
DEBUG 01-14 20:42:40.475911.475911 lmp.py:1625]   Expert 37 |     64 | CPU
DEBUG 01-14 20:42:40.475229.475229 lmp.py:1625]   Expert 17 |     75 | CPU
DEBUG 01-14 20:42:40.475025.475025 lmp.py:1625]   Expert  7 |     77 | CPU
DEBUG 01-14 20:42:40.475820.475820 lmp.py:1625]   Expert 18 |     81 | CPU
DEBUG 01-14 20:42:40.475854.475854 lmp.py:1625]   Expert 13 |     83 | CPU
DEBUG 01-14 20:42:40.475127.475127 lmp.py:1625]   Expert  9 |     88 | CPU
DEBUG 01-14 20:42:40.475637.475637 lmp.py:1625]   Expert 54 |     96 | CPU
DEBUG 01-14 20:42:40.475479.475479 lmp.py:1625]   Expert 58 |     97 | CPU
DEBUG 01-14 20:42:40.475798.475798 lmp.py:1625]   Expert  0 |    108 | CPU
DEBUG 01-14 20:42:40.475117.475117 lmp.py:1625]   Expert 22 |    110 | CPU
DEBUG 01-14 20:42:40.475959.475959 lmp.py:1625]   Expert 59 |    110 | CPU
DEBUG 01-14 20:42:40.475562.475562 lmp.py:1625]   Expert 26 |    114 | CPU
DEBUG 01-14 20:42:40.475404.475404 lmp.py:1625]   Expert 10 |    116 | CPU
DEBUG 01-14 20:42:40.475199.475199 lmp.py:1625]   Expert 16 |    121 | CPU
DEBUG 01-14 20:42:40.475518.475518 lmp.py:1625]   Expert 43 |    128 | CPU
DEBUG 01-14 20:42:40.475360.475360 lmp.py:1625]   Expert 63 |    130 | CPU
DEBUG 01-14 20:42:40.475202.475202 lmp.py:1625]   Expert 28 |    138 | CPU
DEBUG 01-14 20:42:40.475282.475282 lmp.py:1625]   Expert 29 |    139 | CPU
DEBUG 01-14 20:42:40.475647.475647 lmp.py:1625]   Expert 33 |    140 | CPU
DEBUG 01-14 20:42:40.475251.475251 lmp.py:1625]   Expert  2 |    148 | CPU
DEBUG 01-14 20:42:40.475854.475854 lmp.py:1625]   Expert 51 |    151 | CPU
DEBUG 01-14 20:42:40.475219.475219 lmp.py:1625]   Expert 45 |    157 | CPU
DEBUG 01-14 20:42:40.475776.475776 lmp.py:1625]   Expert 62 |    161 | CPU
DEBUG 01-14 20:42:40.475333.475333 lmp.py:1625]   Expert 40 |    162 | CPU
DEBUG 01-14 20:42:40.475937.475937 lmp.py:1625]   Expert 55 |    163 | CPU
DEBUG 01-14 20:42:40.475063.475063 lmp.py:1625]   Expert 23 |    165 | CPU
DEBUG 01-14 20:42:40.476428.476428 lmp.py:1625]   Expert 32 |    165 | CPU
DEBUG 01-14 20:42:40.476793.476793 lmp.py:1625]   Expert 11 |    169 | CPU
DEBUG 01-14 20:42:40.476397.476397 lmp.py:1625]   Expert 34 |    170 | CPU
DEBUG 01-14 20:42:40.476530.476530 lmp.py:1625]   Expert 52 |    173 | CPU
DEBUG 01-14 20:42:40.476326.476326 lmp.py:1625]   Expert 41 |    176 | CPU
DEBUG 01-14 20:42:40.476883.476883 lmp.py:1625]   Expert 14 |    178 | GPU
DEBUG 01-14 20:42:40.476725.476725 lmp.py:1625]   Expert  3 |    179 | GPU
DEBUG 01-14 20:42:40.476613.476613 lmp.py:1625]   Expert 53 |    181 | GPU
DEBUG 01-14 20:42:40.476455.476455 lmp.py:1625]   Expert 42 |    189 | GPU
DEBUG 01-14 20:42:40.476058.476058 lmp.py:1625]   Expert 57 |    193 | GPU
DEBUG 01-14 20:42:40.476423.476423 lmp.py:1625]   Expert 15 |    201 | GPU
DEBUG 01-14 20:42:40.476788.476788 lmp.py:1625]   Expert 35 |    202 | GPU
DEBUG 01-14 20:42:40.476868.476868 lmp.py:1625]   Expert 30 |    210 | GPU
DEBUG 01-14 20:42:40.476426.476426 lmp.py:1625]   Expert 21 |    213 | GPU
DEBUG 01-14 20:42:40.476460.476460 lmp.py:1625]   Expert 24 |    217 | GPU
DEBUG 01-14 20:42:40.476977.476977 lmp.py:1625]   Expert  4 |    220 | GPU
DEBUG 01-14 20:42:40.476773.476773 lmp.py:1625]   Expert 44 |    225 | GPU
DEBUG 01-14 20:42:40.476138.476138 lmp.py:1625]   Expert 12 |    226 | GPU
DEBUG 01-14 20:42:40.476741.476741 lmp.py:1625]   Expert 49 |    229 | GPU
DEBUG 01-14 20:42:40.476583.476583 lmp.py:1625]   Expert 19 |    232 | GPU
DEBUG 01-14 20:42:40.476186.476186 lmp.py:1625]   Expert 38 |    236 | GPU
DEBUG 01-14 20:42:40.476028.476028 lmp.py:1625]   Expert 47 |    237 | GPU
DEBUG 01-14 20:42:40.476062.476062 lmp.py:1625]   Expert 50 |    244 | GPU
DEBUG 01-14 20:42:40.476096.476096 lmp.py:1625]   Expert 61 |    244 | GPU
DEBUG 01-14 20:42:40.476176.476176 lmp.py:1625]   Expert 31 |    247 | GPU
DEBUG 01-14 20:42:40.476780.476780 lmp.py:1625]   Expert  8 |    250 | GPU
DEBUG 01-14 20:42:40.476622.476622 lmp.py:1625]   Expert 46 |    251 | GPU
DEBUG 01-14 20:42:40.476748.476748 lmp.py:1625]   Expert  6 |    253 | GPU
DEBUG 01-14 20:42:40.476352.476352 lmp.py:1625]   Expert 39 |    262 | GPU
DEBUG 01-14 20:42:40.476955.476955 lmp.py:1625]   Expert  5 |    302 | GPU
DEBUG 01-14 20:42:40.476559.476559 lmp.py:1625]   Expert 27 |    303 | GPU
DEBUG 01-14 20:42:40.476877.476877 lmp.py:1625]   Expert 48 |    305 | GPU
DEBUG 01-14 20:42:40.476434.476434 lmp.py:1625]   Expert 20 |    342 | GPU
DEBUG 01-14 20:42:40.476515.476515 lmp.py:1625]   Expert 36 |    360 | GPU
DEBUG 01-14 20:42:40.476357.476357 lmp.py:1625]   Expert 60 |    365 | GPU
DEBUG 01-14 20:42:40.476960.476960 lmp.py:1625]   Expert 25 |    396 | GPU
DEBUG 01-14 20:42:40.476802.476802 lmp.py:1625]   Expert 56 |    570 | GPU
DEBUG 01-14 20:42:40.476359.476359 lmp.py:1626] 
DEBUG 01-14 20:42:40.476359.476359 lmp.py:1626]   CPU total tokens: 4026 (32.8%)
DEBUG 01-14 20:42:40.476870.476870 lmp.py:1627]   GPU total tokens: 8262 (67.2%)
DEBUG 01-14 20:42:40.476434.476434 cuda_h.py:19] end experts_map_get cost 0.0021407604217529297 seconds
DEBUG 01-14 20:42:40.477542.477542 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-14 20:42:40.477214.477214 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-14 20:42:40.477530.477530 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-14 20:42:40.478424.478424 cuda_h.py:19] end allocate_cuda_memory cost 0.0009348392486572266 seconds
DEBUG 01-14 20:42:40.478811.478811 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-14 20:42:40.478388.478388 sllm_store_c.py:27] get device uuid map
DEBUG 01-14 20:42:40.478787.478787 sllm_store_c.py:29] call client load into gpu
DEBUG 01-14 20:42:40.478318.478318 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 173f591e-6abc-45d4-be1b-714d266d6276
DEBUG 01-14 20:42:40.478947.478947 client.py:106] call stub.LoadModelAsync
INFO 01-14 20:42:40.479693.479693 client.py:127] Model loaded
DEBUG 01-14 20:42:40.479140.479140 cuda_h.py:10] start restore2model
DEBUG 01-14 20:42:40.480666.480666 cuda_h.py:19] end restore2model cost 0.0009622573852539062 seconds
DEBUG 01-14 20:42:40.480134.480134 cuda_h.py:19] end sllm_worker_task cost 0.012920141220092773 seconds
INFO 01-14 20:42:40.480528.480528 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 173f591e-6abc-45d4-be1b-714d266d6276
DEBUG 01-14 20:42:40.480652.480652 cuda_h.py:19] end load_into_gpu_async cost 0.0023331642150878906 seconds
DEBUG 01-14 20:42:40.480792.480792 cuda_h.py:10] start restore_tensors2
DEBUG 01-14 20:42:40.481071.481071 cuda_h.py:19] end restore_tensors2 cost 0.00038695335388183594 seconds
DEBUG 01-14 20:42:40.481867.481867 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.004067659378051758 seconds
DEBUG 01-14 20:42:40.481445.481445 cuda_h.py:10] start restore2model
DEBUG 01-14 20:42:40.483781.483781 cuda_h.py:19] end restore2model cost 0.002501964569091797 seconds
DEBUG 01-14 20:42:40.483426.483426 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.006760120391845703 seconds
DEBUG 01-14 20:42:40.483765.483765 cuda_h.py:10] start gpu_sexperts
DEBUG 01-14 20:42:40.484834.484834 cuda_h.py:19] end gpu_sexperts cost 0.00026679039001464844 seconds
DEBUG 01-14 20:42:40.484895.484895 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-14 20:42:40.484790.484790 lmp.py:1683] 
DEBUG 01-14 20:42:40.484790.484790 lmp.py:1683]   Computing 32 experts on CPU...
DEBUG 01-14 20:42:40.484534.484534 cuda_h.py:19] end cpu_experts_submit cost 5.7220458984375e-05 seconds
DEBUG 01-14 20:42:40.484853.484853 cuda_h.py:10] start experts_func_mgpu_group_pad
DEBUG 01-14 20:42:40.497277.497277 mlpmodule.py:1460] group tensors cost 0.012388467788696289 s
DEBUG 01-14 20:42:40.497403.497403 cuda_h.py:10] start move_flat_hidden2cpu
DEBUG 01-14 20:42:40.503170.503170 cuda_h.py:19] end experts_func_mgpu_group_pad cost 0.019078969955444336 seconds
DEBUG 01-14 20:42:40.504859.504859 cuda_h.py:19] end move_flat_hidden2cpu cost 0.006615400314331055 seconds
DEBUG 01-14 20:42:40.507811.507811 cuda_h.py:10] start gpu_group_list
DEBUG 01-14 20:42:40.508513.508513 cuda_h.py:19] end gpu_group_list cost 0.0011370182037353516 seconds
DEBUG 01-14 20:42:40.509938.509938 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-14 20:42:40.509173.509173 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.4080276489257812e-05 seconds
DEBUG 01-14 20:42:40.509612.509612 cuda_h.py:10] start wait_experts
INFO 01-14 20:42:40.509997.509997 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 173f591e-6abc-45d4-be1b-714d266d6276
DEBUG 01-14 20:42:40.509588.509588 mlpmodule.py:1533] pad cost 0.0048449039459228516 s
DEBUG 01-14 20:42:40.509413.509413 mlpmodule.py:1539] create cpu tensor cost 3.695487976074219e-05 s
DEBUG 01-14 20:42:40.511630.511630 mlpmodule.py:1544] move to cpu cost 0.002088785171508789 s
DEBUG 01-14 20:42:40.521819.521819 mlpmodule.py:1558] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-14 20:42:40.521573.521573 mlpmodule.py:1559] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-14 20:42:40.521563.521563 mlpmodule.py:1564] group_w3 first element: -0.003631591796875
WARNING 01-14 20:42:40.521832.521832 mlpmodule.py:1574] start einsum2
INFO 01-14 20:42:40.535460.535460 client.py:127] Model loaded
DEBUG 01-14 20:42:40.536217.536217 cuda_h.py:19] end wait_experts cost 0.026872873306274414 seconds
DEBUG 01-14 20:42:40.536934.536934 cuda_h.py:10] start gpu_experts
DEBUG 01-14 20:42:40.536606.536606 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-14 20:42:40.538642.538642 mlpmodule.py:1584] group einsum cost 0.027186155319213867 s
DEBUG 01-14 20:42:40.539771.539771 mlpmodule.py:1593] cpy2cputensor cost 0.0007257461547851562 s
DEBUG 01-14 20:42:40.539448.539448 cuda_h.py:10] start move_outputs
DEBUG 01-14 20:42:40.541690.541690 cuda_h.py:19] end move_outputs cost 0.0020427703857421875 seconds
DEBUG 01-14 20:42:40.545810.545810 cuda_h.py:19] end wait_cetm_experts cost 0.009208917617797852 seconds
DEBUG 01-14 20:42:40.545199.545199 cuda_h.py:10] start gpu_group_einsum_mp_multi_list
DEBUG 01-14 20:42:40.545254.545254 cuda_h.py:10] start gpu_group_tensor
DEBUG 01-14 20:42:40.546826.546826 cuda_h.py:19] end gpu_group_tensor cost 0.00024771690368652344 seconds
DEBUG 01-14 20:42:40.546373.546373 cuda_h.py:10] start gpu_group_einsum
DEBUG 01-14 20:42:40.546970.546970 cuda_h.py:19] end gpu_group_einsum cost 0.0005655288696289062 seconds
DEBUG 01-14 20:42:40.546762.546762 cuda_h.py:10] start gpu_final_hidden_states_scatter
DEBUG 01-14 20:42:40.546791.546791 cuda_h.py:10] start all_expert_outputs_slices
DEBUG 01-14 20:42:40.547987.547987 cuda_h.py:19] end all_expert_outputs_slices cost 0.0002899169921875 seconds
DEBUG 01-14 20:42:40.547266.547266 cuda_h.py:10] start concat_expert_out
DEBUG 01-14 20:42:40.547103.547103 cuda_h.py:19] end concat_expert_out cost 5.53131103515625e-05 seconds
DEBUG 01-14 20:42:40.547192.547192 cuda_h.py:10] start index_scatter
DEBUG 01-14 20:42:40.547911.547911 cuda_h.py:19] end index_scatter cost 7.343292236328125e-05 seconds
DEBUG 01-14 20:42:40.547958.547958 cuda_h.py:19] end gpu_final_hidden_states_scatter cost 0.0006649494171142578 seconds
DEBUG 01-14 20:42:40.547828.547828 cuda_h.py:19] end gpu_experts cost 0.011426210403442383 seconds
DEBUG 01-14 20:42:40.547008.547008 cuda_h.py:10] start all_expert_weight_slices
DEBUG 01-14 20:42:40.548049.548049 cuda_h.py:19] end all_expert_weight_slices cost 0.0009791851043701172 seconds
DEBUG 01-14 20:42:40.548779.548779 cuda_h.py:10] start cpuoutputsdeal
DEBUG 01-14 20:42:40.549224.549224 cuda_h.py:10] start index_scatter
DEBUG 01-14 20:42:40.549214.549214 cuda_h.py:19] end index_scatter cost 4.9114227294921875e-05 seconds
DEBUG 01-14 20:42:40.549453.549453 cuda_h.py:19] end cpuoutputsdeal cost 0.0005390644073486328 seconds
DEBUG 01-14 20:42:40.549601.549601 cuda_h.py:19] end layer_moe_generate_mp_l_7 cost 0.07546734809875488 seconds
DEBUG 01-14 20:42:40.549402.549402 cuda_h.py:19] end prefill_layer cost 0.08301138877868652 seconds
DEBUG 01-14 20:42:40.549822.549822 lmp.py:1551] -------------------------------- end prefill layer 6 --------------------------------
DEBUG 01-14 20:42:40.549001.549001 cuda_h.py:10] start prefill_layer
DEBUG 01-14 20:42:40.549658.549658 lmp.py:1494] -------------------------------- start prefill layer 7 --------------------------------
DEBUG 01-14 20:42:40.549553.549553 cuda_h.py:10] start start_load_qkvogn_s_weight_l_8
DEBUG 01-14 20:42:40.549170.549170 cuda_h.py:10] start start_load_qkvogn_s_weight_l_8
DEBUG 01-14 20:42:40.550159.550159 cuda_h.py:19] end start_load_qkvogn_s_weight_l_8 cost 3.457069396972656e-05 seconds
DEBUG 01-14 20:42:40.550823.550823 cuda_h.py:10] start sllm_worker_task
DEBUG 01-14 20:42:40.550282.550282 cuda_h.py:19] end start_load_qkvogn_s_weight_l_8 cost 0.0001590251922607422 seconds
DEBUG 01-14 20:42:40.550173.550173 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-14 20:42:40.550340.550340 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-14 20:42:40.550879.550879 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-14 20:42:40.551984.551984 cuda_h.py:19] end allocate_cuda_memory cost 0.0006442070007324219 seconds
DEBUG 01-14 20:42:40.551324.551324 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-14 20:42:40.551709.551709 sllm_store_c.py:27] get device uuid map
DEBUG 01-14 20:42:40.551499.551499 sllm_store_c.py:29] call client load into gpu
DEBUG 01-14 20:42:40.551924.551924 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, fafc79d3-caa0-4dd7-8f09-35181ba5a226
DEBUG 01-14 20:42:40.551967.551967 client.py:106] call stub.LoadModelAsync
DEBUG 01-14 20:42:40.551172.551172 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-14 20:42:40.551780.551780 cuda_h.py:10] start self_attn
INFO 01-14 20:42:40.552752.552752 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, fafc79d3-caa0-4dd7-8f09-35181ba5a226
DEBUG 01-14 20:42:40.553264.553264 cuda_h.py:19] end load_into_gpu_async cost 0.0017428398132324219 seconds
DEBUG 01-14 20:42:40.553305.553305 cuda_h.py:10] start restore_tensors2
DEBUG 01-14 20:42:40.553700.553700 cuda_h.py:19] end restore_tensors2 cost 8.320808410644531e-05 seconds
DEBUG 01-14 20:42:40.553509.553509 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0028104782104492188 seconds
INFO 01-14 20:42:40.553703.553703 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, fafc79d3-caa0-4dd7-8f09-35181ba5a226
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-14 20:42:40.555362.555362 cuda_h.py:19] end self_attn cost 0.0034961700439453125 seconds
DEBUG 01-14 20:42:40.555075.555075 cuda_h.py:19] end iln_self_attn_paln cost 0.005387544631958008 seconds
DEBUG 01-14 20:42:40.555679.555679 cuda_h.py:10] start layer_moe_generate_mp_l_8
DEBUG 01-14 20:42:40.555489.555489 cuda_h.py:10] start gate
DEBUG 01-14 20:42:40.556710.556710 cuda_h.py:19] end gate cost 0.0006561279296875 seconds
DEBUG 01-14 20:42:40.556255.556255 cuda_h.py:10] start experts_map_get
DEBUG 01-14 20:42:40.556345.556345 lmp.py:1615] 
DEBUG 01-14 20:42:40.556345.556345 lmp.py:1615] Expert Token Distribution & Device Allocation:
DEBUG 01-14 20:42:40.557154.557154 lmp.py:1616]   Total experts: 64
DEBUG 01-14 20:42:40.557380.557380 lmp.py:1617]   CPU experts: 32 (50%)
DEBUG 01-14 20:42:40.557315.557315 lmp.py:1618]   GPU experts: 32 (50%)
DEBUG 01-14 20:42:40.557865.557865 lmp.py:1619] 
DEBUG 01-14 20:42:40.557865.557865 lmp.py:1619]   Expert ID | Tokens | Device
DEBUG 01-14 20:42:40.557654.557654 lmp.py:1620]   -----------------------------------
DEBUG 01-14 20:42:40.557827.557827 lmp.py:1625]   Expert 46 |     36 | CPU
DEBUG 01-14 20:42:40.557900.557900 lmp.py:1625]   Expert 50 |     50 | CPU
DEBUG 01-14 20:42:40.557689.557689 lmp.py:1625]   Expert  3 |     60 | CPU
DEBUG 01-14 20:42:40.557524.557524 lmp.py:1625]   Expert  1 |     88 | CPU
DEBUG 01-14 20:42:40.557597.557597 lmp.py:1625]   Expert 15 |     95 | CPU
DEBUG 01-14 20:42:40.557909.557909 lmp.py:1625]   Expert 29 |     95 | CPU
DEBUG 01-14 20:42:40.557221.557221 lmp.py:1625]   Expert 40 |    100 | CPU
DEBUG 01-14 20:42:40.557533.557533 lmp.py:1625]   Expert  4 |    102 | CPU
DEBUG 01-14 20:42:40.557607.557607 lmp.py:1625]   Expert 28 |    105 | CPU
DEBUG 01-14 20:42:40.557203.557203 lmp.py:1625]   Expert 54 |    115 | CPU
DEBUG 01-14 20:42:40.557515.557515 lmp.py:1625]   Expert  8 |    116 | CPU
DEBUG 01-14 20:42:40.557589.557589 lmp.py:1625]   Expert 41 |    119 | CPU
DEBUG 01-14 20:42:40.557662.557662 lmp.py:1625]   Expert 13 |    131 | CPU
DEBUG 01-14 20:42:40.557736.557736 lmp.py:1625]   Expert 16 |    132 | CPU
DEBUG 01-14 20:42:40.557286.557286 lmp.py:1625]   Expert 18 |    133 | CPU
DEBUG 01-14 20:42:40.557598.557598 lmp.py:1625]   Expert  6 |    134 | CPU
DEBUG 01-14 20:42:40.557910.557910 lmp.py:1625]   Expert  7 |    135 | CPU
DEBUG 01-14 20:42:40.557030.557030 lmp.py:1625]   Expert 48 |    135 | CPU
DEBUG 01-14 20:42:40.557342.557342 lmp.py:1625]   Expert 51 |    136 | CPU
DEBUG 01-14 20:42:40.557700.557700 lmp.py:1625]   Expert 36 |    139 | CPU
DEBUG 01-14 20:42:40.557535.557535 lmp.py:1625]   Expert 20 |    140 | CPU
DEBUG 01-14 20:42:40.557131.557131 lmp.py:1625]   Expert 52 |    140 | CPU
DEBUG 01-14 20:42:40.557967.557967 lmp.py:1625]   Expert 60 |    140 | CPU
DEBUG 01-14 20:42:40.557278.557278 lmp.py:1625]   Expert 27 |    141 | CPU
DEBUG 01-14 20:42:40.557067.557067 lmp.py:1625]   Expert 39 |    141 | CPU
DEBUG 01-14 20:42:40.557856.557856 lmp.py:1625]   Expert 43 |    143 | CPU
DEBUG 01-14 20:42:40.557691.557691 lmp.py:1625]   Expert 11 |    144 | CPU
DEBUG 01-14 20:42:40.557049.557049 lmp.py:1625]   Expert 62 |    153 | CPU
DEBUG 01-14 20:42:40.557407.557407 lmp.py:1625]   Expert 35 |    155 | CPU
DEBUG 01-14 20:42:40.557527.557527 lmp.py:1625]   Expert 14 |    158 | CPU
DEBUG 01-14 20:42:40.557409.557409 lmp.py:1625]   Expert 56 |    158 | CPU
DEBUG 01-14 20:42:40.557290.557290 lmp.py:1625]   Expert 45 |    160 | CPU
DEBUG 01-14 20:42:40.557887.557887 lmp.py:1625]   Expert  5 |    166 | GPU
DEBUG 01-14 20:42:40.557199.557199 lmp.py:1625]   Expert 10 |    173 | GPU
DEBUG 01-14 20:42:40.557318.557318 lmp.py:1625]   Expert 44 |    173 | GPU
DEBUG 01-14 20:42:40.557200.557200 lmp.py:1625]   Expert 55 |    177 | GPU
DEBUG 01-14 20:42:40.557081.557081 lmp.py:1625]   Expert 25 |    183 | GPU
DEBUG 01-14 20:42:40.557439.557439 lmp.py:1625]   Expert 57 |    185 | GPU
DEBUG 01-14 20:42:40.557513.557513 lmp.py:1625]   Expert 58 |    185 | GPU
DEBUG 01-14 20:42:40.557110.557110 lmp.py:1625]   Expert 31 |    186 | GPU
DEBUG 01-14 20:42:40.557706.557706 lmp.py:1625]   Expert 32 |    189 | GPU
DEBUG 01-14 20:42:40.557588.557588 lmp.py:1625]   Expert 33 |    189 | GPU
DEBUG 01-14 20:42:40.557707.557707 lmp.py:1625]   Expert  2 |    195 | GPU
DEBUG 01-14 20:42:40.557827.557827 lmp.py:1625]   Expert 53 |    196 | GPU
DEBUG 01-14 20:42:40.557424.557424 lmp.py:1625]   Expert 21 |    200 | GPU
DEBUG 01-14 20:42:40.557544.557544 lmp.py:1625]   Expert 17 |    202 | GPU
DEBUG 01-14 20:42:40.558902.558902 lmp.py:1625]   Expert 49 |    212 | GPU
DEBUG 01-14 20:42:40.558260.558260 lmp.py:1625]   Expert 59 |    214 | GPU
DEBUG 01-14 20:42:40.558857.558857 lmp.py:1625]   Expert  0 |    222 | GPU
DEBUG 01-14 20:42:40.558738.558738 lmp.py:1625]   Expert 63 |    223 | GPU
DEBUG 01-14 20:42:40.558858.558858 lmp.py:1625]   Expert 34 |    241 | GPU
DEBUG 01-14 20:42:40.558216.558216 lmp.py:1625]   Expert 37 |    243 | GPU
DEBUG 01-14 20:42:40.558574.558574 lmp.py:1625]   Expert 42 |    244 | GPU
DEBUG 01-14 20:42:40.558694.558694 lmp.py:1625]   Expert 22 |    251 | GPU
DEBUG 01-14 20:42:40.558576.558576 lmp.py:1625]   Expert 19 |    255 | GPU
DEBUG 01-14 20:42:40.558649.558649 lmp.py:1625]   Expert 24 |    274 | GPU
DEBUG 01-14 20:42:40.558246.558246 lmp.py:1625]   Expert 61 |    280 | GPU
DEBUG 01-14 20:42:40.558842.558842 lmp.py:1625]   Expert 30 |    317 | GPU
DEBUG 01-14 20:42:40.558439.558439 lmp.py:1625]   Expert 47 |    323 | GPU
DEBUG 01-14 20:42:40.558797.558797 lmp.py:1625]   Expert 38 |    377 | GPU
DEBUG 01-14 20:42:40.558156.558156 lmp.py:1625]   Expert 26 |    394 | GPU
DEBUG 01-14 20:42:40.558752.558752 lmp.py:1625]   Expert 12 |    409 | GPU
DEBUG 01-14 20:42:40.558349.558349 lmp.py:1625]   Expert 23 |    591 | GPU
DEBUG 01-14 20:42:40.558946.558946 lmp.py:1625]   Expert  9 |    690 | GPU
DEBUG 01-14 20:42:40.558211.558211 lmp.py:1626] 
DEBUG 01-14 20:42:40.558211.558211 lmp.py:1626]   CPU total tokens: 3929 (32.0%)
DEBUG 01-14 20:42:40.558761.558761 lmp.py:1627]   GPU total tokens: 8359 (68.0%)
DEBUG 01-14 20:42:40.558126.558126 cuda_h.py:19] end experts_map_get cost 0.0016663074493408203 seconds
DEBUG 01-14 20:42:40.558288.558288 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-14 20:42:40.558099.558099 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-14 20:42:40.558527.558527 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-14 20:42:40.563485.563485 cuda_h.py:19] end allocate_cuda_memory cost 0.004850864410400391 seconds
DEBUG 01-14 20:42:40.563634.563634 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-14 20:42:40.563251.563251 sllm_store_c.py:27] get device uuid map
DEBUG 01-14 20:42:40.563682.563682 sllm_store_c.py:29] call client load into gpu
DEBUG 01-14 20:42:40.563047.563047 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, cefeaf93-3329-4169-a3a1-f4250e38e42a
DEBUG 01-14 20:42:40.563358.563358 client.py:106] call stub.LoadModelAsync
INFO 01-14 20:42:40.564159.564159 client.py:127] Model loaded
DEBUG 01-14 20:42:40.564326.564326 cuda_h.py:10] start restore2model
DEBUG 01-14 20:42:40.564845.564845 mlpmodule.py:1367]  experts func einsum cost 0.07961392402648926 s
DEBUG 01-14 20:42:40.564660.564660 cuda_h.py:19] end restore2model cost 0.0006198883056640625 seconds
DEBUG 01-14 20:42:40.564484.564484 cuda_h.py:19] end sllm_worker_task cost 0.014639139175415039 seconds
INFO 01-14 20:42:40.565759.565759 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, cefeaf93-3329-4169-a3a1-f4250e38e42a
DEBUG 01-14 20:42:40.565993.565993 cuda_h.py:19] end load_into_gpu_async cost 0.002194643020629883 seconds
DEBUG 01-14 20:42:40.565126.565126 cuda_h.py:10] start restore_tensors2
DEBUG 01-14 20:42:40.566266.566266 cuda_h.py:19] end restore_tensors2 cost 0.0003917217254638672 seconds
DEBUG 01-14 20:42:40.566440.566440 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.007812738418579102 seconds
DEBUG 01-14 20:42:40.566111.566111 cuda_h.py:10] start restore2model
DEBUG 01-14 20:42:40.569453.569453 cuda_h.py:19] end restore2model cost 0.002679586410522461 seconds
DEBUG 01-14 20:42:40.569058.569058 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.010677099227905273 seconds
DEBUG 01-14 20:42:40.569284.569284 cuda_h.py:10] start gpu_sexperts
DEBUG 01-14 20:42:40.569950.569950 cuda_h.py:19] end gpu_sexperts cost 0.00028395652770996094 seconds
DEBUG 01-14 20:42:40.569726.569726 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-14 20:42:40.569098.569098 lmp.py:1683] 
DEBUG 01-14 20:42:40.569098.569098 lmp.py:1683]   Computing 32 experts on CPU...
DEBUG 01-14 20:42:40.569464.569464 cuda_h.py:19] end cpu_experts_submit cost 5.888938903808594e-05 seconds
DEBUG 01-14 20:42:40.569882.569882 cuda_h.py:10] start experts_func_mgpu_group_pad
DEBUG 01-14 20:42:40.574757.574757 mlpmodule.py:1460] group tensors cost 0.004196643829345703 s
DEBUG 01-14 20:42:40.574742.574742 cuda_h.py:10] start move_flat_hidden2cpu
DEBUG 01-14 20:42:40.577735.577735 cuda_h.py:19] end experts_func_mgpu_group_pad cost 0.007808208465576172 seconds
DEBUG 01-14 20:42:40.579056.579056 cuda_h.py:10] start gpu_group_list
DEBUG 01-14 20:42:40.579504.579504 cuda_h.py:19] end gpu_group_list cost 0.0004353523254394531 seconds
DEBUG 01-14 20:42:40.579563.579563 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-14 20:42:40.579262.579262 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.4557113647460938e-05 seconds
DEBUG 01-14 20:42:40.579455.579455 cuda_h.py:10] start wait_experts
INFO 01-14 20:42:40.579165.579165 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, cefeaf93-3329-4169-a3a1-f4250e38e42a
DEBUG 01-14 20:42:40.581045.581045 cuda_h.py:19] end move_flat_hidden2cpu cost 0.006238222122192383 seconds
DEBUG 01-14 20:42:40.582000.582000 mlpmodule.py:1533] pad cost 0.0015101432800292969 s
DEBUG 01-14 20:42:40.582043.582043 mlpmodule.py:1539] create cpu tensor cost 3.600120544433594e-05 s
DEBUG 01-14 20:42:40.584578.584578 mlpmodule.py:1544] move to cpu cost 0.0019030570983886719 s
DEBUG 01-14 20:42:40.594310.594310 mlpmodule.py:1558] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-14 20:42:40.594673.594673 mlpmodule.py:1559] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-14 20:42:40.594795.594795 mlpmodule.py:1564] group_w3 first element: 0.01263427734375
WARNING 01-14 20:42:40.594004.594004 mlpmodule.py:1574] start einsum2
DEBUG 01-14 20:42:40.612570.612570 mlpmodule.py:1584] group einsum cost 0.0275421142578125 s
DEBUG 01-14 20:42:40.613375.613375 mlpmodule.py:1593] cpy2cputensor cost 0.0006730556488037109 s
DEBUG 01-14 20:42:40.613105.613105 cuda_h.py:10] start move_outputs
DEBUG 01-14 20:42:40.616661.616661 cuda_h.py:19] end move_outputs cost 0.0027306079864501953 seconds
INFO 01-14 20:42:40.623042.623042 client.py:127] Model loaded
DEBUG 01-14 20:42:40.623796.623796 cuda_h.py:19] end wait_experts cost 0.04374074935913086 seconds
DEBUG 01-14 20:42:40.623850.623850 cuda_h.py:10] start gpu_experts
DEBUG 01-14 20:42:40.623288.623288 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-14 20:42:40.623673.623673 cuda_h.py:19] end wait_cetm_experts cost 0.00018358230590820312 seconds
DEBUG 01-14 20:42:40.624914.624914 cuda_h.py:10] start gpu_group_einsum_mp_multi_list
DEBUG 01-14 20:42:40.624862.624862 cuda_h.py:10] start gpu_group_tensor
DEBUG 01-14 20:42:40.624971.624971 cuda_h.py:19] end gpu_group_tensor cost 0.00025773048400878906 seconds
DEBUG 01-14 20:42:40.624427.624427 cuda_h.py:10] start gpu_group_einsum
DEBUG 01-14 20:42:40.625532.625532 cuda_h.py:19] end gpu_group_einsum cost 0.0007221698760986328 seconds
DEBUG 01-14 20:42:40.625796.625796 cuda_h.py:10] start gpu_final_hidden_states_scatter
DEBUG 01-14 20:42:40.625606.625606 cuda_h.py:10] start all_expert_outputs_slices
DEBUG 01-14 20:42:40.625010.625010 cuda_h.py:19] end all_expert_outputs_slices cost 0.00036406517028808594 seconds
DEBUG 01-14 20:42:40.625766.625766 cuda_h.py:10] start concat_expert_out
DEBUG 01-14 20:42:40.626227.626227 cuda_h.py:19] end concat_expert_out cost 5.745887756347656e-05 seconds
DEBUG 01-14 20:42:40.626984.626984 cuda_h.py:10] start index_scatter
DEBUG 01-14 20:42:40.626802.626802 cuda_h.py:19] end index_scatter cost 7.62939453125e-05 seconds
DEBUG 01-14 20:42:40.626803.626803 cuda_h.py:19] end gpu_final_hidden_states_scatter cost 0.0007615089416503906 seconds
DEBUG 01-14 20:42:40.626011.626011 cuda_h.py:19] end gpu_experts cost 0.002619504928588867 seconds
DEBUG 01-14 20:42:40.626714.626714 cuda_h.py:10] start all_expert_weight_slices
DEBUG 01-14 20:42:40.627608.627608 cuda_h.py:19] end all_expert_weight_slices cost 0.0009453296661376953 seconds
DEBUG 01-14 20:42:40.627046.627046 cuda_h.py:10] start cpuoutputsdeal
DEBUG 01-14 20:42:40.627843.627843 cuda_h.py:10] start index_scatter
DEBUG 01-14 20:42:40.627409.627409 cuda_h.py:19] end index_scatter cost 5.054473876953125e-05 seconds
DEBUG 01-14 20:42:40.627318.627318 cuda_h.py:19] end cpuoutputsdeal cost 0.0005576610565185547 seconds
DEBUG 01-14 20:42:40.628605.628605 cuda_h.py:19] end layer_moe_generate_mp_l_8 cost 0.07210469245910645 seconds
DEBUG 01-14 20:42:40.628868.628868 cuda_h.py:19] end prefill_layer cost 0.07845139503479004 seconds
DEBUG 01-14 20:42:40.628076.628076 lmp.py:1551] -------------------------------- end prefill layer 7 --------------------------------
DEBUG 01-14 20:42:40.628156.628156 cuda_h.py:10] start prefill_layer
DEBUG 01-14 20:42:40.628998.628998 lmp.py:1494] -------------------------------- start prefill layer 8 --------------------------------
DEBUG 01-14 20:42:40.628363.628363 cuda_h.py:10] start start_load_qkvogn_s_weight_l_9
DEBUG 01-14 20:42:40.628158.628158 cuda_h.py:10] start start_load_qkvogn_s_weight_l_9
DEBUG 01-14 20:42:40.628809.628809 cuda_h.py:19] end start_load_qkvogn_s_weight_l_9 cost 3.4809112548828125e-05 seconds
DEBUG 01-14 20:42:40.628605.628605 cuda_h.py:19] end start_load_qkvogn_s_weight_l_9 cost 6.246566772460938e-05 seconds
DEBUG 01-14 20:42:40.628917.628917 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-14 20:42:40.628509.628509 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-14 20:42:40.628055.628055 cuda_h.py:10] start sllm_worker_task
DEBUG 01-14 20:42:40.628403.628403 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-14 20:42:40.629723.629723 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-14 20:42:40.631738.631738 cuda_h.py:19] end allocate_cuda_memory cost 0.002546548843383789 seconds
DEBUG 01-14 20:42:40.631578.631578 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-14 20:42:40.631182.631182 sllm_store_c.py:27] get device uuid map
DEBUG 01-14 20:42:40.631576.631576 sllm_store_c.py:29] call client load into gpu
DEBUG 01-14 20:42:40.631306.631306 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 201a123e-cca2-4bf7-9f5a-920b48bac3af
DEBUG 01-14 20:42:40.632753.632753 client.py:106] call stub.LoadModelAsync
DEBUG 01-14 20:42:40.632422.632422 cuda_h.py:10] start self_attn
INFO 01-14 20:42:40.633511.633511 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 201a123e-cca2-4bf7-9f5a-920b48bac3af
DEBUG 01-14 20:42:40.634389.634389 cuda_h.py:19] end load_into_gpu_async cost 0.002210378646850586 seconds
DEBUG 01-14 20:42:40.634471.634471 cuda_h.py:10] start restore_tensors2
DEBUG 01-14 20:42:40.634244.634244 cuda_h.py:19] end restore_tensors2 cost 9.703636169433594e-05 seconds
DEBUG 01-14 20:42:40.634902.634902 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.00534367561340332 seconds
INFO 01-14 20:42:40.634441.634441 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 201a123e-cca2-4bf7-9f5a-920b48bac3af
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-14 20:42:40.635046.635046 cuda_h.py:19] end self_attn cost 0.0031251907348632812 seconds
DEBUG 01-14 20:42:40.635374.635374 cuda_h.py:19] end iln_self_attn_paln cost 0.007294893264770508 seconds
DEBUG 01-14 20:42:40.636979.636979 cuda_h.py:10] start layer_moe_generate_mp_l_9
DEBUG 01-14 20:42:40.636026.636026 cuda_h.py:10] start gate
DEBUG 01-14 20:42:40.636181.636181 cuda_h.py:19] end gate cost 0.0006418228149414062 seconds
DEBUG 01-14 20:42:40.636680.636680 cuda_h.py:10] start experts_map_get
DEBUG 01-14 20:42:40.637193.637193 lmp.py:1615] 
DEBUG 01-14 20:42:40.637193.637193 lmp.py:1615] Expert Token Distribution & Device Allocation:
DEBUG 01-14 20:42:40.637380.637380 lmp.py:1616]   Total experts: 64
DEBUG 01-14 20:42:40.637175.637175 lmp.py:1617]   CPU experts: 32 (50%)
DEBUG 01-14 20:42:40.637395.637395 lmp.py:1618]   GPU experts: 32 (50%)
DEBUG 01-14 20:42:40.637945.637945 lmp.py:1619] 
DEBUG 01-14 20:42:40.637945.637945 lmp.py:1619]   Expert ID | Tokens | Device
DEBUG 01-14 20:42:40.637303.637303 lmp.py:1620]   -----------------------------------
DEBUG 01-14 20:42:40.637092.637092 lmp.py:1625]   Expert 38 |     20 | CPU
DEBUG 01-14 20:42:40.637695.637695 lmp.py:1625]   Expert 39 |     62 | CPU
DEBUG 01-14 20:42:40.637054.637054 lmp.py:1625]   Expert 30 |     68 | CPU
DEBUG 01-14 20:42:40.637935.637935 lmp.py:1625]   Expert 59 |     72 | CPU
DEBUG 01-14 20:42:40.637293.637293 lmp.py:1625]   Expert  7 |     78 | CPU
DEBUG 01-14 20:42:40.637890.637890 lmp.py:1625]   Expert 36 |     89 | CPU
DEBUG 01-14 20:42:40.637725.637725 lmp.py:1625]   Expert 24 |     95 | CPU
DEBUG 01-14 20:42:40.637322.637322 lmp.py:1625]   Expert 27 |     95 | CPU
DEBUG 01-14 20:42:40.637918.637918 lmp.py:1625]   Expert 17 |     97 | CPU
DEBUG 01-14 20:42:40.637515.637515 lmp.py:1625]   Expert 40 |     98 | CPU
DEBUG 01-14 20:42:40.637111.637111 lmp.py:1625]   Expert 12 |    103 | CPU
DEBUG 01-14 20:42:40.637231.637231 lmp.py:1625]   Expert 14 |    104 | CPU
DEBUG 01-14 20:42:40.637351.637351 lmp.py:1625]   Expert 18 |    105 | CPU
DEBUG 01-14 20:42:40.637471.637471 lmp.py:1625]   Expert  1 |    111 | CPU
DEBUG 01-14 20:42:40.637068.637068 lmp.py:1625]   Expert  6 |    113 | CPU
DEBUG 01-14 20:42:40.637426.637426 lmp.py:1625]   Expert 16 |    118 | CPU
DEBUG 01-14 20:42:40.637546.637546 lmp.py:1625]   Expert 48 |    124 | CPU
DEBUG 01-14 20:42:40.637142.637142 lmp.py:1625]   Expert 32 |    126 | CPU
DEBUG 01-14 20:42:40.637739.637739 lmp.py:1625]   Expert 44 |    146 | CPU
DEBUG 01-14 20:42:40.637097.637097 lmp.py:1625]   Expert 51 |    146 | CPU
DEBUG 01-14 20:42:40.637694.637694 lmp.py:1625]   Expert  0 |    148 | CPU
DEBUG 01-14 20:42:40.637814.637814 lmp.py:1625]   Expert 53 |    157 | CPU
DEBUG 01-14 20:42:40.637695.637695 lmp.py:1625]   Expert 35 |    161 | CPU
DEBUG 01-14 20:42:40.637576.637576 lmp.py:1625]   Expert  8 |    162 | CPU
DEBUG 01-14 20:42:40.637696.637696 lmp.py:1625]   Expert 42 |    166 | CPU
DEBUG 01-14 20:42:40.637054.637054 lmp.py:1625]   Expert 22 |    168 | CPU
DEBUG 01-14 20:42:40.637605.637605 lmp.py:1625]   Expert 60 |    171 | CPU
DEBUG 01-14 20:42:40.637963.637963 lmp.py:1625]   Expert 34 |    180 | CPU
DEBUG 01-14 20:42:40.637321.637321 lmp.py:1625]   Expert 29 |    186 | CPU
DEBUG 01-14 20:42:40.637309.637309 lmp.py:1625]   Expert 33 |    186 | CPU
DEBUG 01-14 20:42:40.637144.637144 lmp.py:1625]   Expert 45 |    188 | CPU
DEBUG 01-14 20:42:40.637502.637502 lmp.py:1625]   Expert 54 |    190 | CPU
DEBUG 01-14 20:42:40.637860.637860 lmp.py:1625]   Expert 19 |    192 | GPU
DEBUG 01-14 20:42:40.637457.637457 lmp.py:1625]   Expert 47 |    192 | GPU
DEBUG 01-14 20:42:40.637054.637054 lmp.py:1625]   Expert 49 |    195 | GPU
DEBUG 01-14 20:42:40.637366.637366 lmp.py:1625]   Expert 15 |    200 | GPU
DEBUG 01-14 20:42:40.637724.637724 lmp.py:1625]   Expert 56 |    201 | GPU
DEBUG 01-14 20:42:40.637082.637082 lmp.py:1625]   Expert 28 |    202 | GPU
DEBUG 01-14 20:42:40.637679.637679 lmp.py:1625]   Expert  9 |    204 | GPU
DEBUG 01-14 20:42:40.637275.637275 lmp.py:1625]   Expert 21 |    205 | GPU
DEBUG 01-14 20:42:40.638634.638634 lmp.py:1625]   Expert  3 |    206 | GPU
DEBUG 01-14 20:42:40.638707.638707 lmp.py:1625]   Expert 13 |    209 | GPU
DEBUG 01-14 20:42:40.638065.638065 lmp.py:1625]   Expert 10 |    210 | GPU
DEBUG 01-14 20:42:40.638662.638662 lmp.py:1625]   Expert 41 |    213 | GPU
DEBUG 01-14 20:42:40.638497.638497 lmp.py:1625]   Expert 20 |    214 | GPU
DEBUG 01-14 20:42:40.638855.638855 lmp.py:1625]   Expert 46 |    217 | GPU
DEBUG 01-14 20:42:40.638452.638452 lmp.py:1625]   Expert 57 |    219 | GPU
DEBUG 01-14 20:42:40.638287.638287 lmp.py:1625]   Expert  4 |    221 | GPU
DEBUG 01-14 20:42:40.638884.638884 lmp.py:1625]   Expert 43 |    224 | GPU
DEBUG 01-14 20:42:40.638480.638480 lmp.py:1625]   Expert 63 |    229 | GPU
DEBUG 01-14 20:42:40.638838.638838 lmp.py:1625]   Expert  2 |    230 | GPU
DEBUG 01-14 20:42:40.638197.638197 lmp.py:1625]   Expert 37 |    232 | GPU
DEBUG 01-14 20:42:40.638555.638555 lmp.py:1625]   Expert 50 |    251 | GPU
DEBUG 01-14 20:42:40.638913.638913 lmp.py:1625]   Expert 26 |    266 | GPU
DEBUG 01-14 20:42:40.638271.638271 lmp.py:1625]   Expert 61 |    266 | GPU
DEBUG 01-14 20:42:40.638391.638391 lmp.py:1625]   Expert 31 |    279 | GPU
DEBUG 01-14 20:42:40.638226.638226 lmp.py:1625]   Expert 58 |    285 | GPU
DEBUG 01-14 20:42:40.638777.638777 lmp.py:1625]   Expert 52 |    305 | GPU
DEBUG 01-14 20:42:40.638135.638135 lmp.py:1625]   Expert 62 |    307 | GPU
DEBUG 01-14 20:42:40.638255.638255 lmp.py:1625]   Expert 55 |    344 | GPU
DEBUG 01-14 20:42:40.638613.638613 lmp.py:1625]   Expert 11 |    377 | GPU
DEBUG 01-14 20:42:40.638733.638733 lmp.py:1625]   Expert 23 |    413 | GPU
DEBUG 01-14 20:42:40.638614.638614 lmp.py:1625]   Expert 25 |    431 | GPU
DEBUG 01-14 20:42:40.638734.638734 lmp.py:1625]   Expert  5 |    516 | GPU
DEBUG 01-14 20:42:40.638807.638807 lmp.py:1626] 
DEBUG 01-14 20:42:40.638807.638807 lmp.py:1626]   CPU total tokens: 4033 (32.8%)
DEBUG 01-14 20:42:40.638835.638835 lmp.py:1627]   GPU total tokens: 8255 (67.2%)
DEBUG 01-14 20:42:40.638868.638868 cuda_h.py:19] end experts_map_get cost 0.0016536712646484375 seconds
DEBUG 01-14 20:42:40.638725.638725 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-14 20:42:40.638721.638721 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-14 20:42:40.638156.638156 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-14 20:42:40.640850.640850 cuda_h.py:19] end allocate_cuda_memory cost 0.0020906925201416016 seconds
DEBUG 01-14 20:42:40.640130.640130 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-14 20:42:40.640078.640078 sllm_store_c.py:27] get device uuid map
DEBUG 01-14 20:42:40.641272.641272 sllm_store_c.py:29] call client load into gpu
DEBUG 01-14 20:42:40.641782.641782 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, a152dff6-0d1f-436d-b339-4b12cbe68993
DEBUG 01-14 20:42:40.641279.641279 client.py:106] call stub.LoadModelAsync
DEBUG 01-14 20:42:40.641038.641038 mlpmodule.py:1367]  experts func einsum cost 0.07134032249450684 s
INFO 01-14 20:42:40.641435.641435 client.py:127] Model loaded
DEBUG 01-14 20:42:40.641951.641951 cuda_h.py:10] start restore2model
DEBUG 01-14 20:42:40.642585.642585 cuda_h.py:19] end restore2model cost 0.0006663799285888672 seconds
DEBUG 01-14 20:42:40.642363.642363 cuda_h.py:19] end sllm_worker_task cost 0.013633251190185547 seconds
INFO 01-14 20:42:40.642533.642533 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, a152dff6-0d1f-436d-b339-4b12cbe68993
DEBUG 01-14 20:42:40.642244.642244 cuda_h.py:19] end load_into_gpu_async cost 0.0017690658569335938 seconds
DEBUG 01-14 20:42:40.642423.642423 cuda_h.py:10] start restore_tensors2
DEBUG 01-14 20:42:40.643014.643014 cuda_h.py:19] end restore_tensors2 cost 0.0004074573516845703 seconds
DEBUG 01-14 20:42:40.643903.643903 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.004637002944946289 seconds
DEBUG 01-14 20:42:40.643527.643527 cuda_h.py:10] start restore2model
DEBUG 01-14 20:42:40.646292.646292 cuda_h.py:19] end restore2model cost 0.0026407241821289062 seconds
DEBUG 01-14 20:42:40.646228.646228 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.007462978363037109 seconds
DEBUG 01-14 20:42:40.646759.646759 cuda_h.py:10] start gpu_sexperts
DEBUG 01-14 20:42:40.646226.646226 cuda_h.py:19] end gpu_sexperts cost 0.00027871131896972656 seconds
DEBUG 01-14 20:42:40.646480.646480 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-14 20:42:40.646805.646805 lmp.py:1683] 
DEBUG 01-14 20:42:40.646805.646805 lmp.py:1683]   Computing 32 experts on CPU...
DEBUG 01-14 20:42:40.646549.646549 cuda_h.py:19] end cpu_experts_submit cost 5.6743621826171875e-05 seconds
DEBUG 01-14 20:42:40.646344.646344 cuda_h.py:10] start experts_func_mgpu_group_pad
DEBUG 01-14 20:42:40.656876.656876 mlpmodule.py:1460] group tensors cost 0.009719133377075195 s
DEBUG 01-14 20:42:40.657018.657018 cuda_h.py:10] start move_flat_hidden2cpu
DEBUG 01-14 20:42:40.659376.659376 cuda_h.py:19] end experts_func_mgpu_group_pad cost 0.012736082077026367 seconds
DEBUG 01-14 20:42:40.660277.660277 cuda_h.py:10] start gpu_group_list
DEBUG 01-14 20:42:40.661413.661413 cuda_h.py:19] end gpu_group_list cost 0.0004317760467529297 seconds
DEBUG 01-14 20:42:40.661440.661440 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-14 20:42:40.661317.661317 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.2411346435546875e-05 seconds
DEBUG 01-14 20:42:40.661265.661265 cuda_h.py:10] start wait_experts
INFO 01-14 20:42:40.661259.661259 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, a152dff6-0d1f-436d-b339-4b12cbe68993
DEBUG 01-14 20:42:40.663334.663334 cuda_h.py:19] end move_flat_hidden2cpu cost 0.006205081939697266 seconds
DEBUG 01-14 20:42:40.665536.665536 mlpmodule.py:1533] pad cost 0.0015902519226074219 s
DEBUG 01-14 20:42:40.665533.665533 mlpmodule.py:1539] create cpu tensor cost 3.5762786865234375e-05 s
DEBUG 01-14 20:42:40.667523.667523 mlpmodule.py:1544] move to cpu cost 0.002239227294921875 s
DEBUG 01-14 20:42:40.678497.678497 mlpmodule.py:1558] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-14 20:42:40.678105.678105 mlpmodule.py:1559] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-14 20:42:40.678718.678718 mlpmodule.py:1564] group_w3 first element: 0.0859375
WARNING 01-14 20:42:40.678200.678200 mlpmodule.py:1574] start einsum2
DEBUG 01-14 20:42:40.696218.696218 mlpmodule.py:1584] group einsum cost 0.02898097038269043 s
DEBUG 01-14 20:42:40.697919.697919 mlpmodule.py:1593] cpy2cputensor cost 0.0007748603820800781 s
DEBUG 01-14 20:42:40.697941.697941 cuda_h.py:10] start move_outputs
INFO 01-14 20:42:40.698688.698688 client.py:127] Model loaded
DEBUG 01-14 20:42:40.698092.698092 cuda_h.py:19] end wait_experts cost 0.036896467208862305 seconds
DEBUG 01-14 20:42:40.698100.698100 cuda_h.py:10] start gpu_experts
DEBUG 01-14 20:42:40.698969.698969 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-14 20:42:40.700022.700022 cuda_h.py:19] end move_outputs cost 0.002193927764892578 seconds
DEBUG 01-14 20:42:40.703798.703798 cuda_h.py:19] end wait_cetm_experts cost 0.005127668380737305 seconds
DEBUG 01-14 20:42:40.703245.703245 cuda_h.py:10] start gpu_group_einsum_mp_multi_list
DEBUG 01-14 20:42:40.703578.703578 cuda_h.py:10] start gpu_group_tensor
DEBUG 01-14 20:42:40.704057.704057 cuda_h.py:19] end gpu_group_tensor cost 0.0002498626708984375 seconds
DEBUG 01-14 20:42:40.704982.704982 cuda_h.py:10] start gpu_group_einsum
DEBUG 01-14 20:42:40.705700.705700 cuda_h.py:19] end gpu_group_einsum cost 0.0005698204040527344 seconds
DEBUG 01-14 20:42:40.705392.705392 cuda_h.py:10] start gpu_final_hidden_states_scatter
DEBUG 01-14 20:42:40.705944.705944 cuda_h.py:10] start all_expert_outputs_slices
DEBUG 01-14 20:42:40.705716.705716 cuda_h.py:19] end all_expert_outputs_slices cost 0.0002930164337158203 seconds
DEBUG 01-14 20:42:40.705280.705280 cuda_h.py:10] start concat_expert_out
DEBUG 01-14 20:42:40.705694.705694 cuda_h.py:19] end concat_expert_out cost 5.841255187988281e-05 seconds
DEBUG 01-14 20:42:40.705498.705498 cuda_h.py:10] start index_scatter
DEBUG 01-14 20:42:40.705594.705594 cuda_h.py:19] end index_scatter cost 7.176399230957031e-05 seconds
DEBUG 01-14 20:42:40.705257.705257 cuda_h.py:19] end gpu_final_hidden_states_scatter cost 0.0006670951843261719 seconds
DEBUG 01-14 20:42:40.705988.705988 cuda_h.py:19] end gpu_experts cost 0.0073337554931640625 seconds
DEBUG 01-14 20:42:40.705883.705883 cuda_h.py:10] start all_expert_weight_slices
DEBUG 01-14 20:42:40.706956.706956 cuda_h.py:19] end all_expert_weight_slices cost 0.0009360313415527344 seconds
DEBUG 01-14 20:42:40.707017.707017 cuda_h.py:10] start cpuoutputsdeal
DEBUG 01-14 20:42:40.707362.707362 cuda_h.py:10] start index_scatter
DEBUG 01-14 20:42:40.707445.707445 cuda_h.py:19] end index_scatter cost 4.792213439941406e-05 seconds
DEBUG 01-14 20:42:40.707161.707161 cuda_h.py:19] end cpuoutputsdeal cost 0.0005335807800292969 seconds
DEBUG 01-14 20:42:40.707409.707409 cuda_h.py:19] end layer_moe_generate_mp_l_9 cost 0.07156229019165039 seconds
DEBUG 01-14 20:42:40.708786.708786 cuda_h.py:19] end prefill_layer cost 0.07950997352600098 seconds
DEBUG 01-14 20:42:40.708391.708391 lmp.py:1551] -------------------------------- end prefill layer 8 --------------------------------
DEBUG 01-14 20:42:40.708570.708570 cuda_h.py:10] start prefill_layer
DEBUG 01-14 20:42:40.708227.708227 lmp.py:1494] -------------------------------- start prefill layer 9 --------------------------------
DEBUG 01-14 20:42:40.708122.708122 cuda_h.py:10] start start_load_qkvogn_s_weight_l_10
DEBUG 01-14 20:42:40.708924.708924 cuda_h.py:10] start start_load_qkvogn_s_weight_l_10
DEBUG 01-14 20:42:40.708874.708874 cuda_h.py:19] end start_load_qkvogn_s_weight_l_10 cost 4.00543212890625e-05 seconds
DEBUG 01-14 20:42:40.708775.708775 cuda_h.py:19] end start_load_qkvogn_s_weight_l_10 cost 7.486343383789062e-05 seconds
DEBUG 01-14 20:42:40.708332.708332 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-14 20:42:40.708150.708150 cuda_h.py:10] start sllm_worker_task
DEBUG 01-14 20:42:40.708552.708552 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-14 20:42:40.708428.708428 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-14 20:42:40.708519.708519 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-14 20:42:40.710969.710969 cuda_h.py:19] end allocate_cuda_memory cost 0.0013422966003417969 seconds
DEBUG 01-14 20:42:40.710309.710309 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-14 20:42:40.710887.710887 sllm_store_c.py:27] get device uuid map
DEBUG 01-14 20:42:40.710438.710438 sllm_store_c.py:29] call client load into gpu
DEBUG 01-14 20:42:40.710194.710194 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 1cdeb7b5-bf0a-4b76-aa74-27c6ee5ca135
DEBUG 01-14 20:42:40.710999.710999 client.py:106] call stub.LoadModelAsync
DEBUG 01-14 20:42:40.710944.710944 cuda_h.py:10] start self_attn
INFO 01-14 20:42:40.711153.711153 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 1cdeb7b5-bf0a-4b76-aa74-27c6ee5ca135
DEBUG 01-14 20:42:40.711804.711804 cuda_h.py:19] end load_into_gpu_async cost 0.0010981559753417969 seconds
DEBUG 01-14 20:42:40.711891.711891 cuda_h.py:10] start restore_tensors2
DEBUG 01-14 20:42:40.711809.711809 cuda_h.py:19] end restore_tensors2 cost 8.511543273925781e-05 seconds
DEBUG 01-14 20:42:40.711665.711665 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0028028488159179688 seconds
INFO 01-14 20:42:40.711521.711521 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 1cdeb7b5-bf0a-4b76-aa74-27c6ee5ca135
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-14 20:42:40.713101.713101 cuda_h.py:19] end self_attn cost 0.003025054931640625 seconds
DEBUG 01-14 20:42:40.714953.714953 cuda_h.py:19] end iln_self_attn_paln cost 0.00583195686340332 seconds
DEBUG 01-14 20:42:40.714604.714604 cuda_h.py:10] start layer_moe_generate_mp_l_10
DEBUG 01-14 20:42:40.714565.714565 cuda_h.py:10] start gate
DEBUG 01-14 20:42:40.714966.714966 cuda_h.py:19] end gate cost 0.0006473064422607422 seconds
DEBUG 01-14 20:42:40.715987.715987 cuda_h.py:10] start experts_map_get
DEBUG 01-14 20:42:40.715540.715540 lmp.py:1615] 
DEBUG 01-14 20:42:40.715540.715540 lmp.py:1615] Expert Token Distribution & Device Allocation:
DEBUG 01-14 20:42:40.715296.715296 lmp.py:1616]   Total experts: 64
DEBUG 01-14 20:42:40.715423.715423 lmp.py:1617]   CPU experts: 32 (50%)
DEBUG 01-14 20:42:40.715973.715973 lmp.py:1618]   GPU experts: 32 (50%)
DEBUG 01-14 20:42:40.715901.715901 lmp.py:1619] 
DEBUG 01-14 20:42:40.715901.715901 lmp.py:1619]   Expert ID | Tokens | Device
DEBUG 01-14 20:42:40.715306.715306 lmp.py:1620]   -----------------------------------
DEBUG 01-14 20:42:40.715141.715141 lmp.py:1625]   Expert 24 |     41 | CPU
DEBUG 01-14 20:42:40.715784.715784 lmp.py:1625]   Expert  2 |     42 | CPU
DEBUG 01-14 20:42:40.715950.715950 lmp.py:1625]   Expert 26 |     67 | CPU
DEBUG 01-14 20:42:40.715646.715646 lmp.py:1625]   Expert 32 |     69 | CPU
DEBUG 01-14 20:42:40.715812.715812 lmp.py:1625]   Expert 19 |     73 | CPU
DEBUG 01-14 20:42:40.715501.715501 lmp.py:1625]   Expert  4 |     76 | CPU
DEBUG 01-14 20:42:40.715714.715714 lmp.py:1625]   Expert 59 |     76 | CPU
DEBUG 01-14 20:42:40.715165.715165 lmp.py:1625]   Expert 50 |     77 | CPU
DEBUG 01-14 20:42:40.715092.715092 lmp.py:1625]   Expert 23 |     78 | CPU
DEBUG 01-14 20:42:40.715020.715020 lmp.py:1625]   Expert 60 |     86 | CPU
DEBUG 01-14 20:42:40.715709.715709 lmp.py:1625]   Expert 28 |     92 | CPU
DEBUG 01-14 20:42:40.715922.715922 lmp.py:1625]   Expert  7 |     97 | CPU
DEBUG 01-14 20:42:40.715611.715611 lmp.py:1625]   Expert 15 |    104 | CPU
DEBUG 01-14 20:42:40.715824.715824 lmp.py:1625]   Expert 49 |    104 | CPU
DEBUG 01-14 20:42:40.715798.715798 lmp.py:1625]   Expert 27 |    106 | CPU
DEBUG 01-14 20:42:40.715248.715248 lmp.py:1625]   Expert 12 |    114 | CPU
DEBUG 01-14 20:42:40.715176.715176 lmp.py:1625]   Expert 10 |    115 | CPU
DEBUG 01-14 20:42:40.715865.715865 lmp.py:1625]   Expert  3 |    125 | CPU
DEBUG 01-14 20:42:40.715601.715601 lmp.py:1625]   Expert  5 |    126 | CPU
DEBUG 01-14 20:42:40.715575.715575 lmp.py:1625]   Expert 13 |    131 | CPU
DEBUG 01-14 20:42:40.715788.715788 lmp.py:1625]   Expert 20 |    131 | CPU
DEBUG 01-14 20:42:40.715523.715523 lmp.py:1625]   Expert 25 |    135 | CPU
DEBUG 01-14 20:42:40.715497.715497 lmp.py:1625]   Expert 41 |    137 | CPU
DEBUG 01-14 20:42:40.715471.715471 lmp.py:1625]   Expert 37 |    144 | CPU
DEBUG 01-14 20:42:40.715445.715445 lmp.py:1625]   Expert 35 |    145 | CPU
DEBUG 01-14 20:42:40.715658.715658 lmp.py:1625]   Expert 40 |    147 | CPU
DEBUG 01-14 20:42:40.715155.715155 lmp.py:1625]   Expert 17 |    160 | CPU
DEBUG 01-14 20:42:40.715368.715368 lmp.py:1625]   Expert 22 |    163 | CPU
DEBUG 01-14 20:42:40.715103.715103 lmp.py:1625]   Expert 47 |    165 | CPU
DEBUG 01-14 20:42:40.715839.715839 lmp.py:1625]   Expert 36 |    167 | CPU
DEBUG 01-14 20:42:40.715574.715574 lmp.py:1625]   Expert 53 |    170 | CPU
DEBUG 01-14 20:42:40.715548.715548 lmp.py:1625]   Expert 16 |    175 | CPU
DEBUG 01-14 20:42:40.715999.715999 lmp.py:1625]   Expert 52 |    175 | GPU
DEBUG 01-14 20:42:40.715358.715358 lmp.py:1625]   Expert 58 |    175 | GPU
DEBUG 01-14 20:42:40.716762.716762 lmp.py:1625]   Expert 44 |    181 | GPU
DEBUG 01-14 20:42:40.716690.716690 lmp.py:1625]   Expert 18 |    185 | GPU
DEBUG 01-14 20:42:40.716856.716856 lmp.py:1625]   Expert 39 |    190 | GPU
DEBUG 01-14 20:42:40.716545.716545 lmp.py:1625]   Expert 48 |    195 | GPU
DEBUG 01-14 20:42:40.716711.716711 lmp.py:1625]   Expert 30 |    200 | GPU
DEBUG 01-14 20:42:40.716878.716878 lmp.py:1625]   Expert 38 |    200 | GPU
DEBUG 01-14 20:42:40.716805.716805 lmp.py:1625]   Expert 11 |    205 | GPU
DEBUG 01-14 20:42:40.716733.716733 lmp.py:1625]   Expert 45 |    206 | GPU
DEBUG 01-14 20:42:40.716899.716899 lmp.py:1625]   Expert 62 |    212 | GPU
DEBUG 01-14 20:42:40.716781.716781 lmp.py:1625]   Expert  1 |    217 | GPU
DEBUG 01-14 20:42:40.716947.716947 lmp.py:1625]   Expert 29 |    217 | GPU
DEBUG 01-14 20:42:40.716874.716874 lmp.py:1625]   Expert 51 |    224 | GPU
DEBUG 01-14 20:42:40.716041.716041 lmp.py:1625]   Expert 14 |    233 | GPU
DEBUG 01-14 20:42:40.716968.716968 lmp.py:1625]   Expert 31 |    245 | GPU
DEBUG 01-14 20:42:40.716896.716896 lmp.py:1625]   Expert 34 |    256 | GPU
DEBUG 01-14 20:42:40.716400.716400 lmp.py:1625]   Expert  6 |    266 | GPU
DEBUG 01-14 20:42:40.716520.716520 lmp.py:1625]   Expert 43 |    270 | GPU
DEBUG 01-14 20:42:40.716640.716640 lmp.py:1625]   Expert 61 |    275 | GPU
DEBUG 01-14 20:42:40.716806.716806 lmp.py:1625]   Expert 42 |    289 | GPU
DEBUG 01-14 20:42:40.716972.716972 lmp.py:1625]   Expert 33 |    290 | GPU
DEBUG 01-14 20:42:40.716138.716138 lmp.py:1625]   Expert  0 |    297 | GPU
DEBUG 01-14 20:42:40.716496.716496 lmp.py:1625]   Expert 56 |    301 | GPU
DEBUG 01-14 20:42:40.716438.716438 lmp.py:1625]   Expert 57 |    314 | GPU
DEBUG 01-14 20:42:40.716320.716320 lmp.py:1625]   Expert 46 |    319 | GPU
DEBUG 01-14 20:42:40.716824.716824 lmp.py:1625]   Expert 54 |    369 | GPU
DEBUG 01-14 20:42:40.716659.716659 lmp.py:1625]   Expert  9 |    396 | GPU
DEBUG 01-14 20:42:40.716017.716017 lmp.py:1625]   Expert 63 |    406 | GPU
DEBUG 01-14 20:42:40.716091.716091 lmp.py:1625]   Expert  8 |    419 | GPU
DEBUG 01-14 20:42:40.716688.716688 lmp.py:1625]   Expert 55 |    460 | GPU
DEBUG 01-14 20:42:40.716761.716761 lmp.py:1625]   Expert 21 |    463 | GPU
DEBUG 01-14 20:42:40.716265.716265 lmp.py:1626] 
DEBUG 01-14 20:42:40.716265.716265 lmp.py:1626]   CPU total tokens: 3638 (29.6%)
DEBUG 01-14 20:42:40.716531.716531 lmp.py:1627]   GPU total tokens: 8650 (70.4%)
DEBUG 01-14 20:42:40.716280.716280 cuda_h.py:19] end experts_map_get cost 0.0015904903411865234 seconds
DEBUG 01-14 20:42:40.716428.716428 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-14 20:42:40.716377.716377 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-14 20:42:40.716044.716044 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-14 20:42:40.722654.722654 cuda_h.py:19] end allocate_cuda_memory cost 0.005716562271118164 seconds
DEBUG 01-14 20:42:40.722883.722883 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-14 20:42:40.722930.722930 sllm_store_c.py:27] get device uuid map
DEBUG 01-14 20:42:40.722984.722984 sllm_store_c.py:29] call client load into gpu
DEBUG 01-14 20:42:40.722541.722541 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 3b7511a8-961f-4bdc-a725-9c725a1787a5
DEBUG 01-14 20:42:40.723945.723945 client.py:106] call stub.LoadModelAsync
INFO 01-14 20:42:40.723931.723931 client.py:127] Model loaded
DEBUG 01-14 20:42:40.723099.723099 cuda_h.py:10] start restore2model
DEBUG 01-14 20:42:40.723326.723326 mlpmodule.py:1367]  experts func einsum cost 0.07678675651550293 s
DEBUG 01-14 20:42:40.724841.724841 cuda_h.py:19] end restore2model cost 0.0007338523864746094 seconds
DEBUG 01-14 20:42:40.724343.724343 cuda_h.py:19] end sllm_worker_task cost 0.015674352645874023 seconds
INFO 01-14 20:42:40.724007.724007 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 3b7511a8-961f-4bdc-a725-9c725a1787a5
DEBUG 01-14 20:42:40.724711.724711 cuda_h.py:19] end load_into_gpu_async cost 0.0017676353454589844 seconds
DEBUG 01-14 20:42:40.724845.724845 cuda_h.py:10] start restore_tensors2
DEBUG 01-14 20:42:40.725945.725945 cuda_h.py:19] end restore_tensors2 cost 0.0003986358642578125 seconds
DEBUG 01-14 20:42:40.725688.725688 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.008281707763671875 seconds
DEBUG 01-14 20:42:40.725597.725597 cuda_h.py:10] start restore2model
DEBUG 01-14 20:42:40.727320.727320 cuda_h.py:19] end restore2model cost 0.002576112747192383 seconds
DEBUG 01-14 20:42:40.727872.727872 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.011036872863769531 seconds
DEBUG 01-14 20:42:40.727880.727880 cuda_h.py:10] start gpu_sexperts
DEBUG 01-14 20:42:40.728115.728115 cuda_h.py:19] end gpu_sexperts cost 0.0002830028533935547 seconds
DEBUG 01-14 20:42:40.728415.728415 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-14 20:42:40.728025.728025 lmp.py:1683] 
DEBUG 01-14 20:42:40.728025.728025 lmp.py:1683]   Computing 32 experts on CPU...
DEBUG 01-14 20:42:40.728961.728961 cuda_h.py:19] end cpu_experts_submit cost 5.793571472167969e-05 seconds
DEBUG 01-14 20:42:40.728094.728094 cuda_h.py:10] start experts_func_mgpu_group_pad
DEBUG 01-14 20:42:40.733763.733763 mlpmodule.py:1460] group tensors cost 0.004338502883911133 s
DEBUG 01-14 20:42:40.733277.733277 cuda_h.py:10] start move_flat_hidden2cpu
DEBUG 01-14 20:42:40.735643.735643 cuda_h.py:19] end experts_func_mgpu_group_pad cost 0.007227182388305664 seconds
DEBUG 01-14 20:42:40.737226.737226 cuda_h.py:10] start gpu_group_list
DEBUG 01-14 20:42:40.737437.737437 cuda_h.py:19] end gpu_group_list cost 0.00043892860412597656 seconds
DEBUG 01-14 20:42:40.737808.737808 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-14 20:42:40.737340.737340 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.0503997802734375e-05 seconds
DEBUG 01-14 20:42:40.737719.737719 cuda_h.py:10] start wait_experts
INFO 01-14 20:42:40.737951.737951 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 3b7511a8-961f-4bdc-a725-9c725a1787a5
DEBUG 01-14 20:42:40.739869.739869 cuda_h.py:19] end move_flat_hidden2cpu cost 0.00633692741394043 seconds
DEBUG 01-14 20:42:40.741043.741043 mlpmodule.py:1533] pad cost 0.001535177230834961 s
DEBUG 01-14 20:42:40.741417.741417 mlpmodule.py:1539] create cpu tensor cost 3.4809112548828125e-05 s
DEBUG 01-14 20:42:40.743362.743362 mlpmodule.py:1544] move to cpu cost 0.0020644664764404297 s
DEBUG 01-14 20:42:40.754214.754214 mlpmodule.py:1558] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-14 20:42:40.754968.754968 mlpmodule.py:1559] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-14 20:42:40.754527.754527 mlpmodule.py:1564] group_w3 first element: 0.0157470703125
WARNING 01-14 20:42:40.754604.754604 mlpmodule.py:1574] start einsum2
DEBUG 01-14 20:42:40.772683.772683 mlpmodule.py:1584] group einsum cost 0.028495311737060547 s
DEBUG 01-14 20:42:40.773230.773230 mlpmodule.py:1593] cpy2cputensor cost 0.0007233619689941406 s
DEBUG 01-14 20:42:40.773768.773768 cuda_h.py:10] start move_outputs
DEBUG 01-14 20:42:40.775208.775208 cuda_h.py:19] end move_outputs cost 0.0026102066040039062 seconds
INFO 01-14 20:42:40.782737.782737 client.py:127] Model loaded
DEBUG 01-14 20:42:40.783359.783359 cuda_h.py:19] end wait_experts cost 0.04518938064575195 seconds
DEBUG 01-14 20:42:40.783268.783268 cuda_h.py:10] start gpu_experts
DEBUG 01-14 20:42:40.783945.783945 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-14 20:42:40.783462.783462 cuda_h.py:19] end wait_cetm_experts cost 0.0001761913299560547 seconds
DEBUG 01-14 20:42:40.783126.783126 cuda_h.py:10] start gpu_group_einsum_mp_multi_list
DEBUG 01-14 20:42:40.783644.783644 cuda_h.py:10] start gpu_group_tensor
DEBUG 01-14 20:42:40.783454.783454 cuda_h.py:19] end gpu_group_tensor cost 0.0002472400665283203 seconds
DEBUG 01-14 20:42:40.783525.783525 cuda_h.py:10] start gpu_group_einsum
DEBUG 01-14 20:42:40.784718.784718 cuda_h.py:19] end gpu_group_einsum cost 0.0005846023559570312 seconds
DEBUG 01-14 20:42:40.784418.784418 cuda_h.py:10] start gpu_final_hidden_states_scatter
DEBUG 01-14 20:42:40.784923.784923 cuda_h.py:10] start all_expert_outputs_slices
DEBUG 01-14 20:42:40.785364.785364 cuda_h.py:19] end all_expert_outputs_slices cost 0.0002930164337158203 seconds
DEBUG 01-14 20:42:40.785359.785359 cuda_h.py:10] start concat_expert_out
DEBUG 01-14 20:42:40.785296.785296 cuda_h.py:19] end concat_expert_out cost 5.841255187988281e-05 seconds
DEBUG 01-14 20:42:40.785477.785477 cuda_h.py:10] start index_scatter
DEBUG 01-14 20:42:40.785666.785666 cuda_h.py:19] end index_scatter cost 7.224082946777344e-05 seconds
DEBUG 01-14 20:42:40.785806.785806 cuda_h.py:19] end gpu_final_hidden_states_scatter cost 0.0006661415100097656 seconds
DEBUG 01-14 20:42:40.785861.785861 cuda_h.py:19] end gpu_experts cost 0.0022699832916259766 seconds
DEBUG 01-14 20:42:40.785280.785280 cuda_h.py:10] start all_expert_weight_slices
DEBUG 01-14 20:42:40.786941.786941 cuda_h.py:19] end all_expert_weight_slices cost 0.0009496212005615234 seconds
DEBUG 01-14 20:42:40.786287.786287 cuda_h.py:10] start cpuoutputsdeal
DEBUG 01-14 20:42:40.786348.786348 cuda_h.py:10] start index_scatter
DEBUG 01-14 20:42:40.787477.787477 cuda_h.py:19] end index_scatter cost 4.76837158203125e-05 seconds
DEBUG 01-14 20:42:40.787478.787478 cuda_h.py:19] end cpuoutputsdeal cost 0.0005347728729248047 seconds
DEBUG 01-14 20:42:40.787434.787434 cuda_h.py:19] end layer_moe_generate_mp_l_10 cost 0.07283568382263184 seconds
DEBUG 01-14 20:42:40.787619.787619 cuda_h.py:19] end prefill_layer cost 0.07935953140258789 seconds
DEBUG 01-14 20:42:40.787178.787178 lmp.py:1551] -------------------------------- end prefill layer 9 --------------------------------
DEBUG 01-14 20:42:40.787642.787642 cuda_h.py:10] start prefill_layer
DEBUG 01-14 20:42:40.787868.787868 lmp.py:1494] -------------------------------- start prefill layer 10 --------------------------------
DEBUG 01-14 20:42:40.787763.787763 cuda_h.py:10] start start_load_qkvogn_s_weight_l_11
DEBUG 01-14 20:42:40.787897.787897 cuda_h.py:10] start start_load_qkvogn_s_weight_l_11
DEBUG 01-14 20:42:40.787216.787216 cuda_h.py:19] end start_load_qkvogn_s_weight_l_11 cost 3.218650817871094e-05 seconds
DEBUG 01-14 20:42:40.787588.787588 cuda_h.py:19] end start_load_qkvogn_s_weight_l_11 cost 6.318092346191406e-05 seconds
DEBUG 01-14 20:42:40.787615.787615 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-14 20:42:40.787909.787909 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-14 20:42:40.787349.787349 cuda_h.py:10] start sllm_worker_task
DEBUG 01-14 20:42:40.788749.788749 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-14 20:42:40.788486.788486 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-14 20:42:40.791584.791584 cuda_h.py:19] end allocate_cuda_memory cost 0.0036818981170654297 seconds
DEBUG 01-14 20:42:40.791017.791017 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-14 20:42:40.791661.791661 sllm_store_c.py:27] get device uuid map
DEBUG 01-14 20:42:40.791915.791915 sllm_store_c.py:29] call client load into gpu
DEBUG 01-14 20:42:40.791472.791472 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 5515c977-05b4-4de5-959d-6d9ed6f01464
DEBUG 01-14 20:42:40.792104.792104 client.py:106] call stub.LoadModelAsync
DEBUG 01-14 20:42:40.792673.792673 cuda_h.py:10] start self_attn
INFO 01-14 20:42:40.793079.793079 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 5515c977-05b4-4de5-959d-6d9ed6f01464
DEBUG 01-14 20:42:40.793645.793645 cuda_h.py:19] end load_into_gpu_async cost 0.0016722679138183594 seconds
DEBUG 01-14 20:42:40.793632.793632 cuda_h.py:10] start restore_tensors2
DEBUG 01-14 20:42:40.793921.793921 cuda_h.py:19] end restore_tensors2 cost 8.177757263183594e-05 seconds
DEBUG 01-14 20:42:40.793292.793292 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.005707979202270508 seconds
INFO 01-14 20:42:40.793652.793652 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 5515c977-05b4-4de5-959d-6d9ed6f01464
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-14 20:42:40.795010.795010 cuda_h.py:19] end self_attn cost 0.0028738975524902344 seconds
DEBUG 01-14 20:42:40.795795.795795 cuda_h.py:19] end iln_self_attn_paln cost 0.007898092269897461 seconds
DEBUG 01-14 20:42:40.795062.795062 cuda_h.py:10] start layer_moe_generate_mp_l_11
DEBUG 01-14 20:42:40.795632.795632 cuda_h.py:10] start gate
DEBUG 01-14 20:42:40.796953.796953 cuda_h.py:19] end gate cost 0.0006592273712158203 seconds
DEBUG 01-14 20:42:40.796021.796021 cuda_h.py:10] start experts_map_get
DEBUG 01-14 20:42:40.796005.796005 lmp.py:1615] 
DEBUG 01-14 20:42:40.796005.796005 lmp.py:1615] Expert Token Distribution & Device Allocation:
DEBUG 01-14 20:42:40.796861.796861 lmp.py:1616]   Total experts: 64
DEBUG 01-14 20:42:40.796272.796272 lmp.py:1617]   CPU experts: 32 (50%)
DEBUG 01-14 20:42:40.796869.796869 lmp.py:1618]   GPU experts: 32 (50%)
DEBUG 01-14 20:42:40.796319.796319 lmp.py:1619] 
DEBUG 01-14 20:42:40.796319.796319 lmp.py:1619]   Expert ID | Tokens | Device
DEBUG 01-14 20:42:40.796201.796201 lmp.py:1620]   -----------------------------------
DEBUG 01-14 20:42:40.796559.796559 lmp.py:1625]   Expert 43 |     20 | CPU
DEBUG 01-14 20:42:40.796487.796487 lmp.py:1625]   Expert 27 |     31 | CPU
DEBUG 01-14 20:42:40.797938.797938 lmp.py:1625]   Expert 26 |     47 | CPU
DEBUG 01-14 20:42:40.797389.797389 lmp.py:1625]   Expert 34 |     58 | CPU
DEBUG 01-14 20:42:40.797601.797601 lmp.py:1625]   Expert  3 |     61 | CPU
DEBUG 01-14 20:42:40.797813.797813 lmp.py:1625]   Expert 56 |     80 | CPU
DEBUG 01-14 20:42:40.797549.797549 lmp.py:1625]   Expert 61 |     86 | CPU
DEBUG 01-14 20:42:40.797000.797000 lmp.py:1625]   Expert  4 |     97 | CPU
DEBUG 01-14 20:42:40.797451.797451 lmp.py:1625]   Expert 38 |    103 | CPU
DEBUG 01-14 20:42:40.797047.797047 lmp.py:1625]   Expert  7 |    106 | CPU
DEBUG 01-14 20:42:40.797690.797690 lmp.py:1625]   Expert 14 |    109 | CPU
DEBUG 01-14 20:42:40.797857.797857 lmp.py:1625]   Expert  5 |    119 | CPU
DEBUG 01-14 20:42:40.797023.797023 lmp.py:1625]   Expert 22 |    120 | CPU
DEBUG 01-14 20:42:40.797427.797427 lmp.py:1625]   Expert  2 |    124 | CPU
DEBUG 01-14 20:42:40.797832.797832 lmp.py:1625]   Expert 47 |    124 | CPU
DEBUG 01-14 20:42:40.797998.797998 lmp.py:1625]   Expert 45 |    133 | CPU
DEBUG 01-14 20:42:40.797164.797164 lmp.py:1625]   Expert 17 |    134 | CPU
DEBUG 01-14 20:42:40.797330.797330 lmp.py:1625]   Expert 54 |    134 | CPU
DEBUG 01-14 20:42:40.797258.797258 lmp.py:1625]   Expert 48 |    135 | CPU
DEBUG 01-14 20:42:40.797424.797424 lmp.py:1625]   Expert 51 |    141 | CPU
DEBUG 01-14 20:42:40.797352.797352 lmp.py:1625]   Expert 19 |    145 | CPU
DEBUG 01-14 20:42:40.797518.797518 lmp.py:1625]   Expert 15 |    151 | CPU
DEBUG 01-14 20:42:40.797207.797207 lmp.py:1625]   Expert 28 |    152 | CPU
DEBUG 01-14 20:42:40.797373.797373 lmp.py:1625]   Expert 57 |    152 | CPU
DEBUG 01-14 20:42:40.797069.797069 lmp.py:1625]   Expert 63 |    153 | CPU
DEBUG 01-14 20:42:40.797520.797520 lmp.py:1625]   Expert 12 |    155 | CPU
DEBUG 01-14 20:42:40.797733.797733 lmp.py:1625]   Expert 55 |    155 | CPU
DEBUG 01-14 20:42:40.797468.797468 lmp.py:1625]   Expert 37 |    161 | CPU
DEBUG 01-14 20:42:40.797443.797443 lmp.py:1625]   Expert 18 |    168 | CPU
DEBUG 01-14 20:42:40.797178.797178 lmp.py:1625]   Expert 60 |    168 | CPU
DEBUG 01-14 20:42:40.797391.797391 lmp.py:1625]   Expert 50 |    175 | CPU
DEBUG 01-14 20:42:40.797365.797365 lmp.py:1625]   Expert  6 |    184 | CPU
DEBUG 01-14 20:42:40.797100.797100 lmp.py:1625]   Expert 44 |    188 | GPU
DEBUG 01-14 20:42:40.797074.797074 lmp.py:1625]   Expert 52 |    192 | GPU
DEBUG 01-14 20:42:40.797048.797048 lmp.py:1625]   Expert 31 |    194 | GPU
DEBUG 01-14 20:42:40.797499.797499 lmp.py:1625]   Expert 53 |    195 | GPU
DEBUG 01-14 20:42:40.797473.797473 lmp.py:1625]   Expert 39 |    196 | GPU
DEBUG 01-14 20:42:40.797209.797209 lmp.py:1625]   Expert 23 |    197 | GPU
DEBUG 01-14 20:42:40.797673.797673 lmp.py:1625]   Expert 30 |    200 | GPU
DEBUG 01-14 20:42:40.797647.797647 lmp.py:1625]   Expert 21 |    204 | GPU
DEBUG 01-14 20:42:40.797906.797906 lmp.py:1625]   Expert 29 |    204 | GPU
DEBUG 01-14 20:42:40.797403.797403 lmp.py:1625]   Expert 16 |    210 | GPU
DEBUG 01-14 20:42:40.797139.797139 lmp.py:1625]   Expert 20 |    211 | GPU
DEBUG 01-14 20:42:40.797888.797888 lmp.py:1625]   Expert 42 |    213 | GPU
DEBUG 01-14 20:42:40.797909.797909 lmp.py:1625]   Expert 13 |    215 | GPU
DEBUG 01-14 20:42:40.797790.797790 lmp.py:1625]   Expert 36 |    216 | GPU
DEBUG 01-14 20:42:40.797526.797526 lmp.py:1625]   Expert 41 |    220 | GPU
DEBUG 01-14 20:42:40.797308.797308 lmp.py:1625]   Expert 49 |    229 | GPU
DEBUG 01-14 20:42:40.797090.797090 lmp.py:1625]   Expert  8 |    231 | GPU
DEBUG 01-14 20:42:40.797871.797871 lmp.py:1625]   Expert 25 |    231 | GPU
DEBUG 01-14 20:42:40.797415.797415 lmp.py:1625]   Expert 59 |    231 | GPU
DEBUG 01-14 20:42:40.797197.797197 lmp.py:1625]   Expert 11 |    233 | GPU
DEBUG 01-14 20:42:40.797317.797317 lmp.py:1625]   Expert 10 |    246 | GPU
DEBUG 01-14 20:42:40.797198.797198 lmp.py:1625]   Expert 33 |    249 | GPU
DEBUG 01-14 20:42:40.797603.797603 lmp.py:1625]   Expert 32 |    257 | GPU
DEBUG 01-14 20:42:40.797484.797484 lmp.py:1625]   Expert 46 |    265 | GPU
DEBUG 01-14 20:42:40.797889.797889 lmp.py:1625]   Expert 58 |    279 | GPU
DEBUG 01-14 20:42:40.797055.797055 lmp.py:1625]   Expert 35 |    299 | GPU
DEBUG 01-14 20:42:40.797459.797459 lmp.py:1625]   Expert 62 |    305 | GPU
DEBUG 01-14 20:42:40.797626.797626 lmp.py:1625]   Expert  9 |    318 | GPU
DEBUG 01-14 20:42:40.797553.797553 lmp.py:1625]   Expert  0 |    389 | GPU
DEBUG 01-14 20:42:40.798958.798958 lmp.py:1625]   Expert 40 |    417 | GPU
DEBUG 01-14 20:42:40.798362.798362 lmp.py:1625]   Expert 24 |    548 | GPU
DEBUG 01-14 20:42:40.798767.798767 lmp.py:1625]   Expert  1 |    625 | GPU
DEBUG 01-14 20:42:40.798887.798887 lmp.py:1626] 
DEBUG 01-14 20:42:40.798887.798887 lmp.py:1626]   CPU total tokens: 3881 (31.6%)
DEBUG 01-14 20:42:40.798722.798722 lmp.py:1627]   GPU total tokens: 8407 (68.4%)
DEBUG 01-14 20:42:40.798610.798610 cuda_h.py:19] end experts_map_get cost 0.0015306472778320312 seconds
DEBUG 01-14 20:42:40.798686.798686 mlpmodule.py:1367]  experts func einsum cost 0.0695037841796875 s
DEBUG 01-14 20:42:40.798736.798736 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-14 20:42:40.798416.798416 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-14 20:42:40.798673.798673 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-14 20:42:40.799040.799040 cuda_h.py:19] end allocate_cuda_memory cost 0.0012192726135253906 seconds
DEBUG 01-14 20:42:40.799313.799313 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-14 20:42:40.799685.799685 sllm_store_c.py:27] get device uuid map
DEBUG 01-14 20:42:40.799587.799587 sllm_store_c.py:29] call client load into gpu
DEBUG 01-14 20:42:40.800574.800574 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 48bb50e9-dbf1-419c-99dc-9bd1a778e7be
DEBUG 01-14 20:42:40.800196.800196 client.py:106] call stub.LoadModelAsync
INFO 01-14 20:42:40.801915.801915 client.py:127] Model loaded
DEBUG 01-14 20:42:40.801122.801122 cuda_h.py:10] start restore2model
DEBUG 01-14 20:42:40.801465.801465 cuda_h.py:19] end restore2model cost 0.00032901763916015625 seconds
DEBUG 01-14 20:42:40.801136.801136 cuda_h.py:19] end sllm_worker_task cost 0.013917684555053711 seconds
INFO 01-14 20:42:40.802932.802932 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 48bb50e9-dbf1-419c-99dc-9bd1a778e7be
DEBUG 01-14 20:42:40.803444.803444 cuda_h.py:19] end load_into_gpu_async cost 0.003084421157836914 seconds
DEBUG 01-14 20:42:40.803909.803909 cuda_h.py:10] start restore_tensors2
DEBUG 01-14 20:42:40.803844.803844 cuda_h.py:19] end restore_tensors2 cost 0.00041794776916503906 seconds
DEBUG 01-14 20:42:40.803872.803872 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.005084991455078125 seconds
DEBUG 01-14 20:42:40.803350.803350 cuda_h.py:10] start restore2model
DEBUG 01-14 20:42:40.806952.806952 cuda_h.py:19] end restore2model cost 0.002518177032470703 seconds
DEBUG 01-14 20:42:40.806835.806835 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.007786750793457031 seconds
DEBUG 01-14 20:42:40.806246.806246 cuda_h.py:10] start gpu_sexperts
DEBUG 01-14 20:42:40.806316.806316 cuda_h.py:19] end gpu_sexperts cost 0.0002675056457519531 seconds
DEBUG 01-14 20:42:40.806277.806277 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-14 20:42:40.806788.806788 lmp.py:1683] 
DEBUG 01-14 20:42:40.806788.806788 lmp.py:1683]   Computing 32 experts on CPU...
DEBUG 01-14 20:42:40.806909.806909 cuda_h.py:19] end cpu_experts_submit cost 5.412101745605469e-05 seconds
DEBUG 01-14 20:42:40.806797.806797 cuda_h.py:10] start experts_func_mgpu_group_pad
DEBUG 01-14 20:42:40.815649.815649 mlpmodule.py:1460] group tensors cost 0.008600950241088867 s
DEBUG 01-14 20:42:40.816456.816456 cuda_h.py:10] start move_flat_hidden2cpu
DEBUG 01-14 20:42:40.821731.821731 cuda_h.py:19] end experts_func_mgpu_group_pad cost 0.015147686004638672 seconds
DEBUG 01-14 20:42:40.822738.822738 cuda_h.py:19] end move_flat_hidden2cpu cost 0.006400108337402344 seconds
DEBUG 01-14 20:42:40.825943.825943 cuda_h.py:10] start gpu_group_list
DEBUG 01-14 20:42:40.826872.826872 cuda_h.py:19] end gpu_group_list cost 0.000698089599609375 seconds
DEBUG 01-14 20:42:40.826662.826662 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-14 20:42:40.826990.826990 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.8133392333984375e-05 seconds
DEBUG 01-14 20:42:40.826012.826012 cuda_h.py:10] start wait_experts
INFO 01-14 20:42:40.826557.826557 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 48bb50e9-dbf1-419c-99dc-9bd1a778e7be
DEBUG 01-14 20:42:40.826876.826876 mlpmodule.py:1533] pad cost 0.003994464874267578 s
DEBUG 01-14 20:42:40.826509.826509 mlpmodule.py:1539] create cpu tensor cost 3.7670135498046875e-05 s
DEBUG 01-14 20:42:40.829503.829503 mlpmodule.py:1544] move to cpu cost 0.0021724700927734375 s
DEBUG 01-14 20:42:40.839012.839012 mlpmodule.py:1558] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-14 20:42:40.839792.839792 mlpmodule.py:1559] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-14 20:42:40.839206.839206 mlpmodule.py:1564] group_w3 first element: -0.0213623046875
WARNING 01-14 20:42:40.839176.839176 mlpmodule.py:1574] start einsum2
DEBUG 01-14 20:42:40.857646.857646 mlpmodule.py:1584] group einsum cost 0.028503894805908203 s
DEBUG 01-14 20:42:40.858121.858121 mlpmodule.py:1593] cpy2cputensor cost 0.0007495880126953125 s
DEBUG 01-14 20:42:40.858388.858388 cuda_h.py:10] start move_outputs
INFO 01-14 20:42:40.859115.859115 client.py:127] Model loaded
DEBUG 01-14 20:42:40.859565.859565 cuda_h.py:19] end wait_experts cost 0.033063411712646484 seconds
DEBUG 01-14 20:42:40.859149.859149 cuda_h.py:10] start gpu_experts
DEBUG 01-14 20:42:40.859303.859303 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-14 20:42:40.860421.860421 cuda_h.py:19] end move_outputs cost 0.0021219253540039062 seconds
DEBUG 01-14 20:42:40.864085.864085 cuda_h.py:19] end wait_cetm_experts cost 0.0047092437744140625 seconds
DEBUG 01-14 20:42:40.864864.864864 cuda_h.py:10] start gpu_group_einsum_mp_multi_list
DEBUG 01-14 20:42:40.864957.864957 cuda_h.py:10] start gpu_group_tensor
DEBUG 01-14 20:42:40.864768.864768 cuda_h.py:19] end gpu_group_tensor cost 0.000247955322265625 seconds
DEBUG 01-14 20:42:40.865216.865216 cuda_h.py:10] start gpu_group_einsum
DEBUG 01-14 20:42:40.865632.865632 cuda_h.py:19] end gpu_group_einsum cost 0.0007112026214599609 seconds
DEBUG 01-14 20:42:40.865167.865167 cuda_h.py:10] start gpu_final_hidden_states_scatter
DEBUG 01-14 20:42:40.866223.866223 cuda_h.py:10] start all_expert_outputs_slices
DEBUG 01-14 20:42:40.866905.866905 cuda_h.py:19] end all_expert_outputs_slices cost 0.0003590583801269531 seconds
DEBUG 01-14 20:42:40.866753.866753 cuda_h.py:10] start concat_expert_out
DEBUG 01-14 20:42:40.866783.866783 cuda_h.py:19] end concat_expert_out cost 5.7697296142578125e-05 seconds
DEBUG 01-14 20:42:40.866918.866918 cuda_h.py:10] start index_scatter
DEBUG 01-14 20:42:40.866106.866106 cuda_h.py:19] end index_scatter cost 7.200241088867188e-05 seconds
DEBUG 01-14 20:42:40.866770.866770 cuda_h.py:19] end gpu_final_hidden_states_scatter cost 0.0007474422454833984 seconds
DEBUG 01-14 20:42:40.866971.866971 cuda_h.py:19] end gpu_experts cost 0.007108926773071289 seconds
DEBUG 01-14 20:42:40.866674.866674 cuda_h.py:10] start all_expert_weight_slices
DEBUG 01-14 20:42:40.867475.867475 cuda_h.py:19] end all_expert_weight_slices cost 0.0009455680847167969 seconds
DEBUG 01-14 20:42:40.867821.867821 cuda_h.py:10] start cpuoutputsdeal
DEBUG 01-14 20:42:40.868060.868060 cuda_h.py:10] start index_scatter
DEBUG 01-14 20:42:40.868561.868561 cuda_h.py:19] end index_scatter cost 7.605552673339844e-05 seconds
DEBUG 01-14 20:42:40.868900.868900 cuda_h.py:19] end cpuoutputsdeal cost 0.00055694580078125 seconds
DEBUG 01-14 20:42:40.868717.868717 cuda_h.py:19] end layer_moe_generate_mp_l_11 cost 0.07274889945983887 seconds
DEBUG 01-14 20:42:40.868624.868624 cuda_h.py:19] end prefill_layer cost 0.08131098747253418 seconds
DEBUG 01-14 20:42:40.868182.868182 lmp.py:1551] -------------------------------- end prefill layer 10 --------------------------------
DEBUG 01-14 20:42:40.869170.869170 cuda_h.py:10] start prefill_layer
DEBUG 01-14 20:42:40.869634.869634 lmp.py:1494] -------------------------------- start prefill layer 11 --------------------------------
DEBUG 01-14 20:42:40.869291.869291 cuda_h.py:10] start start_load_qkvogn_s_weight_l_12
DEBUG 01-14 20:42:40.869663.869663 cuda_h.py:10] start start_load_qkvogn_s_weight_l_12
DEBUG 01-14 20:42:40.869797.869797 cuda_h.py:19] end start_load_qkvogn_s_weight_l_12 cost 3.647804260253906e-05 seconds
DEBUG 01-14 20:42:40.869553.869553 cuda_h.py:19] end start_load_qkvogn_s_weight_l_12 cost 6.914138793945312e-05 seconds
DEBUG 01-14 20:42:40.869203.869203 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-14 20:42:40.869703.869703 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-14 20:42:40.869487.869487 cuda_h.py:10] start sllm_worker_task
DEBUG 01-14 20:42:40.869769.869769 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-14 20:42:40.869903.869903 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-14 20:42:40.871283.871283 cuda_h.py:19] end allocate_cuda_memory cost 0.0016086101531982422 seconds
DEBUG 01-14 20:42:40.871431.871431 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-14 20:42:40.871340.871340 sllm_store_c.py:27] get device uuid map
DEBUG 01-14 20:42:40.871938.871938 sllm_store_c.py:29] call client load into gpu
DEBUG 01-14 20:42:40.871647.871647 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 5f0e8b27-324f-40fd-a617-783d8d5316c4
DEBUG 01-14 20:42:40.871837.871837 client.py:106] call stub.LoadModelAsync
DEBUG 01-14 20:42:40.871768.871768 cuda_h.py:10] start self_attn
INFO 01-14 20:42:40.872308.872308 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 5f0e8b27-324f-40fd-a617-783d8d5316c4
DEBUG 01-14 20:42:40.872979.872979 cuda_h.py:19] end load_into_gpu_async cost 0.0011029243469238281 seconds
DEBUG 01-14 20:42:40.872066.872066 cuda_h.py:10] start restore_tensors2
DEBUG 01-14 20:42:40.872991.872991 cuda_h.py:19] end restore_tensors2 cost 8.797645568847656e-05 seconds
DEBUG 01-14 20:42:40.872754.872754 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.003080606460571289 seconds
INFO 01-14 20:42:40.872690.872690 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 5f0e8b27-324f-40fd-a617-783d8d5316c4
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-14 20:42:40.875638.875638 cuda_h.py:19] end self_attn cost 0.003762960433959961 seconds
DEBUG 01-14 20:42:40.875920.875920 cuda_h.py:19] end iln_self_attn_paln cost 0.006746053695678711 seconds
DEBUG 01-14 20:42:40.876731.876731 cuda_h.py:10] start layer_moe_generate_mp_l_12
DEBUG 01-14 20:42:40.876447.876447 cuda_h.py:10] start gate
DEBUG 01-14 20:42:40.876384.876384 cuda_h.py:19] end gate cost 0.0006563663482666016 seconds
DEBUG 01-14 20:42:40.876452.876452 cuda_h.py:10] start experts_map_get
DEBUG 01-14 20:42:40.877767.877767 lmp.py:1615] 
DEBUG 01-14 20:42:40.877767.877767 lmp.py:1615] Expert Token Distribution & Device Allocation:
DEBUG 01-14 20:42:40.877430.877430 lmp.py:1616]   Total experts: 64
DEBUG 01-14 20:42:40.877802.877802 lmp.py:1617]   CPU experts: 32 (50%)
DEBUG 01-14 20:42:40.877306.877306 lmp.py:1618]   GPU experts: 32 (50%)
DEBUG 01-14 20:42:40.877710.877710 lmp.py:1619] 
DEBUG 01-14 20:42:40.877710.877710 lmp.py:1619]   Expert ID | Tokens | Device
DEBUG 01-14 20:42:40.877592.877592 lmp.py:1620]   -----------------------------------
DEBUG 01-14 20:42:40.877427.877427 lmp.py:1625]   Expert 39 |     11 | CPU
DEBUG 01-14 20:42:40.877977.877977 lmp.py:1625]   Expert 13 |     22 | CPU
DEBUG 01-14 20:42:40.877574.877574 lmp.py:1625]   Expert 49 |     36 | CPU
DEBUG 01-14 20:42:40.877647.877647 lmp.py:1625]   Expert  9 |     60 | CPU
DEBUG 01-14 20:42:40.877006.877006 lmp.py:1625]   Expert 19 |     63 | CPU
DEBUG 01-14 20:42:40.877079.877079 lmp.py:1625]   Expert 26 |     63 | CPU
DEBUG 01-14 20:42:40.877199.877199 lmp.py:1625]   Expert 33 |     69 | CPU
DEBUG 01-14 20:42:40.877080.877080 lmp.py:1625]   Expert 35 |     70 | CPU
DEBUG 01-14 20:42:40.877962.877962 lmp.py:1625]   Expert 46 |     75 | CPU
DEBUG 01-14 20:42:40.877843.877843 lmp.py:1625]   Expert 32 |     85 | CPU
DEBUG 01-14 20:42:40.877963.877963 lmp.py:1625]   Expert 41 |     87 | CPU
DEBUG 01-14 20:42:40.877083.877083 lmp.py:1625]   Expert 23 |     92 | CPU
DEBUG 01-14 20:42:40.877202.877202 lmp.py:1625]   Expert 17 |    100 | CPU
DEBUG 01-14 20:42:40.877084.877084 lmp.py:1625]   Expert 31 |    101 | CPU
DEBUG 01-14 20:42:40.877965.877965 lmp.py:1625]   Expert  6 |    106 | CPU
DEBUG 01-14 20:42:40.877085.877085 lmp.py:1625]   Expert 18 |    106 | CPU
DEBUG 01-14 20:42:40.877205.877205 lmp.py:1625]   Expert  3 |    113 | CPU
DEBUG 01-14 20:42:40.877325.877325 lmp.py:1625]   Expert 50 |    119 | CPU
DEBUG 01-14 20:42:40.877935.877935 lmp.py:1625]   Expert 38 |    120 | CPU
DEBUG 01-14 20:42:40.877339.877339 lmp.py:1625]   Expert 40 |    126 | CPU
DEBUG 01-14 20:42:40.877221.877221 lmp.py:1625]   Expert 20 |    130 | CPU
DEBUG 01-14 20:42:40.877275.877275 lmp.py:1625]   Expert 15 |    132 | CPU
DEBUG 01-14 20:42:40.877018.877018 lmp.py:1625]   Expert 63 |    134 | CPU
DEBUG 01-14 20:42:40.877376.877376 lmp.py:1625]   Expert 61 |    137 | CPU
DEBUG 01-14 20:42:40.877257.877257 lmp.py:1625]   Expert 62 |    138 | CPU
DEBUG 01-14 20:42:40.877569.877569 lmp.py:1625]   Expert 36 |    142 | CPU
DEBUG 01-14 20:42:40.877451.877451 lmp.py:1625]   Expert 43 |    146 | CPU
DEBUG 01-14 20:42:40.877047.877047 lmp.py:1625]   Expert  2 |    147 | CPU
DEBUG 01-14 20:42:40.877644.877644 lmp.py:1625]   Expert 42 |    151 | CPU
DEBUG 01-14 20:42:40.877764.877764 lmp.py:1625]   Expert 44 |    155 | CPU
DEBUG 01-14 20:42:40.877645.877645 lmp.py:1625]   Expert 10 |    158 | CPU
DEBUG 01-14 20:42:40.877765.877765 lmp.py:1625]   Expert 16 |    164 | CPU
DEBUG 01-14 20:42:40.877362.877362 lmp.py:1625]   Expert 56 |    174 | GPU
DEBUG 01-14 20:42:40.877481.877481 lmp.py:1625]   Expert  5 |    175 | GPU
DEBUG 01-14 20:42:40.877601.877601 lmp.py:1625]   Expert 59 |    179 | GPU
DEBUG 01-14 20:42:40.877483.877483 lmp.py:1625]   Expert 52 |    194 | GPU
DEBUG 01-14 20:42:40.877364.877364 lmp.py:1625]   Expert 45 |    196 | GPU
DEBUG 01-14 20:42:40.877722.877722 lmp.py:1625]   Expert 34 |    198 | GPU
DEBUG 01-14 20:42:40.878365.878365 lmp.py:1625]   Expert 27 |    201 | GPU
DEBUG 01-14 20:42:40.878962.878962 lmp.py:1625]   Expert 60 |    202 | GPU
DEBUG 01-14 20:42:40.878843.878843 lmp.py:1625]   Expert 51 |    209 | GPU
DEBUG 01-14 20:42:40.878440.878440 lmp.py:1625]   Expert 24 |    218 | GPU
DEBUG 01-14 20:42:40.878083.878083 lmp.py:1625]   Expert 53 |    222 | GPU
DEBUG 01-14 20:42:40.878679.878679 lmp.py:1625]   Expert 48 |    223 | GPU
DEBUG 01-14 20:42:40.878561.878561 lmp.py:1625]   Expert 47 |    243 | GPU
DEBUG 01-14 20:42:40.878919.878919 lmp.py:1625]   Expert  8 |    247 | GPU
DEBUG 01-14 20:42:40.878800.878800 lmp.py:1625]   Expert  7 |    254 | GPU
DEBUG 01-14 20:42:40.878920.878920 lmp.py:1625]   Expert 29 |    263 | GPU
DEBUG 01-14 20:42:40.878802.878802 lmp.py:1625]   Expert 58 |    267 | GPU
DEBUG 01-14 20:42:40.878921.878921 lmp.py:1625]   Expert 21 |    271 | GPU
DEBUG 01-14 20:42:40.878280.878280 lmp.py:1625]   Expert 57 |    280 | GPU
DEBUG 01-14 20:42:40.878638.878638 lmp.py:1625]   Expert 14 |    292 | GPU
DEBUG 01-14 20:42:40.878519.878519 lmp.py:1625]   Expert 37 |    296 | GPU
DEBUG 01-14 20:42:40.878162.878162 lmp.py:1625]   Expert 11 |    297 | GPU
DEBUG 01-14 20:42:40.878805.878805 lmp.py:1625]   Expert  1 |    299 | GPU
DEBUG 01-14 20:42:40.878925.878925 lmp.py:1625]   Expert  4 |    306 | GPU
DEBUG 01-14 20:42:40.878283.878283 lmp.py:1625]   Expert  0 |    309 | GPU
DEBUG 01-14 20:42:40.878403.878403 lmp.py:1625]   Expert 22 |    311 | GPU
DEBUG 01-14 20:42:40.878285.878285 lmp.py:1625]   Expert 55 |    322 | GPU
DEBUG 01-14 20:42:40.878643.878643 lmp.py:1625]   Expert 54 |    335 | GPU
DEBUG 01-14 20:42:40.878001.878001 lmp.py:1625]   Expert 25 |    368 | GPU
DEBUG 01-14 20:42:40.878359.878359 lmp.py:1625]   Expert 28 |    412 | GPU
DEBUG 01-14 20:42:40.878479.878479 lmp.py:1625]   Expert 12 |    417 | GPU
DEBUG 01-14 20:42:40.878599.878599 lmp.py:1625]   Expert 30 |    750 | GPU
DEBUG 01-14 20:42:40.878554.878554 lmp.py:1626] 
DEBUG 01-14 20:42:40.878554.878554 lmp.py:1626]   CPU total tokens: 3358 (27.3%)
DEBUG 01-14 20:42:40.878389.878389 lmp.py:1627]   GPU total tokens: 8930 (72.7%)
DEBUG 01-14 20:42:40.878277.878277 cuda_h.py:19] end experts_map_get cost 0.0016694068908691406 seconds
DEBUG 01-14 20:42:40.878279.878279 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-14 20:42:40.878652.878652 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-14 20:42:40.878597.878597 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-14 20:42:40.884674.884674 cuda_h.py:19] end allocate_cuda_memory cost 0.005605459213256836 seconds
DEBUG 01-14 20:42:40.884762.884762 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-14 20:42:40.884849.884849 sllm_store_c.py:27] get device uuid map
DEBUG 01-14 20:42:40.884950.884950 sllm_store_c.py:29] call client load into gpu
DEBUG 01-14 20:42:40.884507.884507 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, ff09f906-7c12-440f-9f94-5fcde6f0b5e2
DEBUG 01-14 20:42:40.884811.884811 client.py:106] call stub.LoadModelAsync
INFO 01-14 20:42:40.884088.884088 client.py:127] Model loaded
DEBUG 01-14 20:42:40.885581.885581 cuda_h.py:10] start restore2model
DEBUG 01-14 20:42:40.885793.885793 mlpmodule.py:1367]  experts func einsum cost 0.07838821411132812 s
DEBUG 01-14 20:42:40.885567.885567 cuda_h.py:19] end restore2model cost 0.0007081031799316406 seconds
DEBUG 01-14 20:42:40.885386.885386 cuda_h.py:19] end sllm_worker_task cost 0.016471147537231445 seconds
INFO 01-14 20:42:40.886207.886207 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, ff09f906-7c12-440f-9f94-5fcde6f0b5e2
DEBUG 01-14 20:42:40.886626.886626 cuda_h.py:19] end load_into_gpu_async cost 0.0016591548919677734 seconds
DEBUG 01-14 20:42:40.886806.886806 cuda_h.py:10] start restore_tensors2
DEBUG 01-14 20:42:40.886124.886124 cuda_h.py:19] end restore_tensors2 cost 0.0003838539123535156 seconds
DEBUG 01-14 20:42:40.886199.886199 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.008000850677490234 seconds
DEBUG 01-14 20:42:40.886108.886108 cuda_h.py:10] start restore2model
DEBUG 01-14 20:42:40.889974.889974 cuda_h.py:19] end restore2model cost 0.0025064945220947266 seconds
DEBUG 01-14 20:42:40.889810.889810 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.010681629180908203 seconds
DEBUG 01-14 20:42:40.889175.889175 cuda_h.py:10] start gpu_sexperts
DEBUG 01-14 20:42:40.889967.889967 cuda_h.py:19] end gpu_sexperts cost 0.0002727508544921875 seconds
DEBUG 01-14 20:42:40.889074.889074 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-14 20:42:40.889539.889539 lmp.py:1683] 
DEBUG 01-14 20:42:40.889539.889539 lmp.py:1683]   Computing 32 experts on CPU...
DEBUG 01-14 20:42:40.889044.889044 cuda_h.py:19] end cpu_experts_submit cost 5.5789947509765625e-05 seconds
DEBUG 01-14 20:42:40.889747.889747 cuda_h.py:10] start experts_func_mgpu_group_pad
DEBUG 01-14 20:42:40.898947.898947 mlpmodule.py:1460] group tensors cost 0.008758783340454102 s
DEBUG 01-14 20:42:40.899785.899785 cuda_h.py:10] start move_flat_hidden2cpu
DEBUG 01-14 20:42:40.904120.904120 cuda_h.py:19] end experts_func_mgpu_group_pad cost 0.014636993408203125 seconds
DEBUG 01-14 20:42:40.906919.906919 cuda_h.py:19] end move_flat_hidden2cpu cost 0.006499052047729492 seconds
DEBUG 01-14 20:42:40.907994.907994 cuda_h.py:10] start gpu_group_list
DEBUG 01-14 20:42:40.908980.908980 cuda_h.py:19] end gpu_group_list cost 0.0007965564727783203 seconds
DEBUG 01-14 20:42:40.908891.908891 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-14 20:42:40.908035.908035 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 3.24249267578125e-05 seconds
DEBUG 01-14 20:42:40.908262.908262 cuda_h.py:10] start wait_experts
INFO 01-14 20:42:40.908960.908960 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, ff09f906-7c12-440f-9f94-5fcde6f0b5e2
DEBUG 01-14 20:42:40.909915.909915 mlpmodule.py:1533] pad cost 0.0035419464111328125 s
DEBUG 01-14 20:42:40.909594.909594 mlpmodule.py:1539] create cpu tensor cost 3.600120544433594e-05 s
DEBUG 01-14 20:42:40.911084.911084 mlpmodule.py:1544] move to cpu cost 0.0019404888153076172 s
DEBUG 01-14 20:42:40.922730.922730 mlpmodule.py:1558] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-14 20:42:40.922325.922325 mlpmodule.py:1559] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-14 20:42:40.922301.922301 mlpmodule.py:1564] group_w3 first element: -0.006134033203125
WARNING 01-14 20:42:40.922841.922841 mlpmodule.py:1574] start einsum2
DEBUG 01-14 20:42:40.940557.940557 mlpmodule.py:1584] group einsum cost 0.029064178466796875 s
DEBUG 01-14 20:42:40.941380.941380 mlpmodule.py:1593] cpy2cputensor cost 0.0006697177886962891 s
DEBUG 01-14 20:42:40.941534.941534 cuda_h.py:10] start move_outputs
INFO 01-14 20:42:40.942310.942310 client.py:127] Model loaded
DEBUG 01-14 20:42:40.942389.942389 cuda_h.py:19] end wait_experts cost 0.03397321701049805 seconds
DEBUG 01-14 20:42:40.942874.942874 cuda_h.py:10] start gpu_experts
DEBUG 01-14 20:42:40.942789.942789 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-14 20:42:40.943566.943566 cuda_h.py:19] end move_outputs cost 0.001909494400024414 seconds
DEBUG 01-14 20:42:40.947854.947854 cuda_h.py:19] end wait_cetm_experts cost 0.00446319580078125 seconds
DEBUG 01-14 20:42:40.947726.947726 cuda_h.py:10] start gpu_group_einsum_mp_multi_list
DEBUG 01-14 20:42:40.947627.947627 cuda_h.py:10] start gpu_group_tensor
DEBUG 01-14 20:42:40.947431.947431 cuda_h.py:19] end gpu_group_tensor cost 0.00024437904357910156 seconds
DEBUG 01-14 20:42:40.947117.947117 cuda_h.py:10] start gpu_group_einsum
DEBUG 01-14 20:42:40.948070.948070 cuda_h.py:19] end gpu_group_einsum cost 0.0007183551788330078 seconds
DEBUG 01-14 20:42:40.948698.948698 cuda_h.py:10] start gpu_final_hidden_states_scatter
DEBUG 01-14 20:42:40.948263.948263 cuda_h.py:10] start all_expert_outputs_slices
DEBUG 01-14 20:42:40.949528.949528 cuda_h.py:19] end all_expert_outputs_slices cost 0.0003681182861328125 seconds
DEBUG 01-14 20:42:40.949900.949900 cuda_h.py:10] start concat_expert_out
DEBUG 01-14 20:42:40.949883.949883 cuda_h.py:19] end concat_expert_out cost 5.793571472167969e-05 seconds
DEBUG 01-14 20:42:40.949018.949018 cuda_h.py:10] start index_scatter
DEBUG 01-14 20:42:40.949637.949637 cuda_h.py:19] end index_scatter cost 7.295608520507812e-05 seconds
DEBUG 01-14 20:42:40.949301.949301 cuda_h.py:19] end gpu_final_hidden_states_scatter cost 0.0007479190826416016 seconds
DEBUG 01-14 20:42:40.949164.949164 cuda_h.py:19] end gpu_experts cost 0.006857633590698242 seconds
DEBUG 01-14 20:42:40.949105.949105 cuda_h.py:10] start all_expert_weight_slices
DEBUG 01-14 20:42:40.950145.950145 cuda_h.py:19] end all_expert_weight_slices cost 0.0009455680847167969 seconds
DEBUG 01-14 20:42:40.950537.950537 cuda_h.py:10] start cpuoutputsdeal
DEBUG 01-14 20:42:40.951876.951876 cuda_h.py:10] start index_scatter
DEBUG 01-14 20:42:40.951204.951204 cuda_h.py:19] end index_scatter cost 5.1975250244140625e-05 seconds
DEBUG 01-14 20:42:40.951066.951066 cuda_h.py:19] end cpuoutputsdeal cost 0.000537872314453125 seconds
DEBUG 01-14 20:42:40.951598.951598 cuda_h.py:19] end layer_moe_generate_mp_l_12 cost 0.07532548904418945 seconds
DEBUG 01-14 20:42:40.951697.951697 cuda_h.py:19] end prefill_layer cost 0.08276748657226562 seconds
DEBUG 01-14 20:42:40.951686.951686 lmp.py:1551] -------------------------------- end prefill layer 11 --------------------------------
DEBUG 01-14 20:42:40.951197.951197 cuda_h.py:10] start prefill_layer
DEBUG 01-14 20:42:40.951377.951377 lmp.py:1494] -------------------------------- start prefill layer 12 --------------------------------
DEBUG 01-14 20:42:40.951272.951272 cuda_h.py:10] start start_load_qkvogn_s_weight_l_13
DEBUG 01-14 20:42:40.951359.951359 cuda_h.py:10] start start_load_qkvogn_s_weight_l_13
DEBUG 01-14 20:42:40.952970.952970 cuda_h.py:19] end start_load_qkvogn_s_weight_l_13 cost 3.647804260253906e-05 seconds
DEBUG 01-14 20:42:40.952488.952488 cuda_h.py:19] end start_load_qkvogn_s_weight_l_13 cost 6.937980651855469e-05 seconds
DEBUG 01-14 20:42:40.952045.952045 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-14 20:42:40.952260.952260 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-14 20:42:40.952044.952044 cuda_h.py:10] start sllm_worker_task
DEBUG 01-14 20:42:40.952260.952260 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-14 20:42:40.952342.952342 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-14 20:42:40.954581.954581 cuda_h.py:19] end allocate_cuda_memory cost 0.0015749931335449219 seconds
DEBUG 01-14 20:42:40.954968.954968 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-14 20:42:40.954446.954446 sllm_store_c.py:27] get device uuid map
DEBUG 01-14 20:42:40.954282.954282 sllm_store_c.py:29] call client load into gpu
DEBUG 01-14 20:42:40.954038.954038 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 9555146b-fb6d-4432-bc74-50d28cf62811
DEBUG 01-14 20:42:40.954307.954307 client.py:106] call stub.LoadModelAsync
DEBUG 01-14 20:42:40.954576.954576 cuda_h.py:10] start self_attn
INFO 01-14 20:42:40.955606.955606 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 9555146b-fb6d-4432-bc74-50d28cf62811
DEBUG 01-14 20:42:40.955065.955065 cuda_h.py:19] end load_into_gpu_async cost 0.0010876655578613281 seconds
DEBUG 01-14 20:42:40.955152.955152 cuda_h.py:10] start restore_tensors2
DEBUG 01-14 20:42:40.955077.955077 cuda_h.py:19] end restore_tensors2 cost 8.893013000488281e-05 seconds
DEBUG 01-14 20:42:40.955363.955363 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.003025531768798828 seconds
INFO 01-14 20:42:40.955073.955073 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 9555146b-fb6d-4432-bc74-50d28cf62811
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-14 20:42:40.957638.957638 cuda_h.py:19] end self_attn cost 0.0031669139862060547 seconds
DEBUG 01-14 20:42:40.958191.958191 cuda_h.py:19] end iln_self_attn_paln cost 0.006114482879638672 seconds
DEBUG 01-14 20:42:40.958710.958710 cuda_h.py:10] start layer_moe_generate_mp_l_13
DEBUG 01-14 20:42:40.958419.958419 cuda_h.py:10] start gate
DEBUG 01-14 20:42:40.959733.959733 cuda_h.py:19] end gate cost 0.0006201267242431641 seconds
DEBUG 01-14 20:42:40.959370.959370 cuda_h.py:10] start experts_map_get
DEBUG 01-14 20:42:40.959294.959294 lmp.py:1615] 
DEBUG 01-14 20:42:40.959294.959294 lmp.py:1615] Expert Token Distribution & Device Allocation:
DEBUG 01-14 20:42:40.959189.959189 lmp.py:1616]   Total experts: 64
DEBUG 01-14 20:42:40.959216.959216 lmp.py:1617]   CPU experts: 32 (50%)
DEBUG 01-14 20:42:40.959621.959621 lmp.py:1618]   GPU experts: 32 (50%)
DEBUG 01-14 20:42:40.959833.959833 lmp.py:1619] 
DEBUG 01-14 20:42:40.959833.959833 lmp.py:1619]   Expert ID | Tokens | Device
DEBUG 01-14 20:42:40.959046.959046 lmp.py:1620]   -----------------------------------
DEBUG 01-14 20:42:40.959927.959927 lmp.py:1625]   Expert 12 |     28 | CPU
DEBUG 01-14 20:42:40.959378.959378 lmp.py:1625]   Expert 52 |     29 | CPU
DEBUG 01-14 20:42:40.959875.959875 lmp.py:1625]   Expert 38 |     32 | CPU
DEBUG 01-14 20:42:40.959611.959611 lmp.py:1625]   Expert 16 |     33 | CPU
DEBUG 01-14 20:42:40.959631.959631 lmp.py:1625]   Expert 47 |     37 | CPU
DEBUG 01-14 20:42:40.959890.959890 lmp.py:1625]   Expert 63 |     44 | CPU
DEBUG 01-14 20:42:40.959625.959625 lmp.py:1625]   Expert 27 |     57 | CPU
DEBUG 01-14 20:42:40.959884.959884 lmp.py:1625]   Expert  4 |     70 | CPU
DEBUG 01-14 20:42:40.959381.959381 lmp.py:1625]   Expert 61 |     75 | CPU
DEBUG 01-14 20:42:40.959163.959163 lmp.py:1625]   Expert 53 |     78 | CPU
DEBUG 01-14 20:42:40.959184.959184 lmp.py:1625]   Expert 43 |     80 | CPU
DEBUG 01-14 20:42:40.959681.959681 lmp.py:1625]   Expert 34 |     84 | CPU
DEBUG 01-14 20:42:40.959701.959701 lmp.py:1625]   Expert 44 |     85 | CPU
DEBUG 01-14 20:42:40.959722.959722 lmp.py:1625]   Expert 13 |     96 | CPU
DEBUG 01-14 20:42:40.959980.959980 lmp.py:1625]   Expert 37 |    102 | CPU
DEBUG 01-14 20:42:40.959762.959762 lmp.py:1625]   Expert 39 |    104 | CPU
DEBUG 01-14 20:42:40.959544.959544 lmp.py:1625]   Expert 32 |    106 | CPU
DEBUG 01-14 20:42:40.959803.959803 lmp.py:1625]   Expert  0 |    113 | CPU
DEBUG 01-14 20:42:40.959824.959824 lmp.py:1625]   Expert 20 |    120 | CPU
DEBUG 01-14 20:42:40.959605.959605 lmp.py:1625]   Expert 14 |    124 | CPU
DEBUG 01-14 20:42:40.959864.959864 lmp.py:1625]   Expert 21 |    128 | CPU
DEBUG 01-14 20:42:40.959746.959746 lmp.py:1625]   Expert 30 |    131 | CPU
DEBUG 01-14 20:42:40.959004.959004 lmp.py:1625]   Expert 45 |    136 | CPU
DEBUG 01-14 20:42:40.959263.959263 lmp.py:1625]   Expert 60 |    137 | CPU
DEBUG 01-14 20:42:40.959284.959284 lmp.py:1625]   Expert  8 |    138 | CPU
DEBUG 01-14 20:42:40.959542.959542 lmp.py:1625]   Expert 18 |    138 | CPU
DEBUG 01-14 20:42:40.959801.959801 lmp.py:1625]   Expert 11 |    146 | CPU
DEBUG 01-14 20:42:40.959583.959583 lmp.py:1625]   Expert 22 |    153 | CPU
DEBUG 01-14 20:42:40.959604.959604 lmp.py:1625]   Expert 57 |    154 | CPU
DEBUG 01-14 20:42:40.959770.959770 lmp.py:1625]   Expert 17 |    156 | CPU
DEBUG 01-14 20:42:40.959512.959512 lmp.py:1625]   Expert 36 |    158 | CPU
DEBUG 01-14 20:42:40.959725.959725 lmp.py:1625]   Expert 42 |    162 | CPU
DEBUG 01-14 20:42:40.959937.959937 lmp.py:1625]   Expert  2 |    166 | GPU
DEBUG 01-14 20:42:40.959673.959673 lmp.py:1625]   Expert  7 |    166 | GPU
DEBUG 01-14 20:42:40.959885.959885 lmp.py:1625]   Expert 58 |    171 | GPU
DEBUG 01-14 20:42:40.960621.960621 lmp.py:1625]   Expert 23 |    173 | GPU
DEBUG 01-14 20:42:40.960787.960787 lmp.py:1625]   Expert 49 |    174 | GPU
DEBUG 01-14 20:42:40.960476.960476 lmp.py:1625]   Expert 25 |    176 | GPU
DEBUG 01-14 20:42:40.960404.960404 lmp.py:1625]   Expert 35 |    177 | GPU
DEBUG 01-14 20:42:40.960855.960855 lmp.py:1625]   Expert 62 |    180 | GPU
DEBUG 01-14 20:42:40.960306.960306 lmp.py:1625]   Expert 55 |    190 | GPU
DEBUG 01-14 20:42:40.960995.960995 lmp.py:1625]   Expert  6 |    191 | GPU
DEBUG 01-14 20:42:40.960446.960446 lmp.py:1625]   Expert 48 |    197 | GPU
DEBUG 01-14 20:42:40.960135.960135 lmp.py:1625]   Expert 29 |    199 | GPU
DEBUG 01-14 20:42:40.960824.960824 lmp.py:1625]   Expert  1 |    204 | GPU
DEBUG 01-14 20:42:40.960514.960514 lmp.py:1625]   Expert 31 |    206 | GPU
DEBUG 01-14 20:42:40.960441.960441 lmp.py:1625]   Expert 51 |    213 | GPU
DEBUG 01-14 20:42:40.960369.960369 lmp.py:1625]   Expert  5 |    218 | GPU
DEBUG 01-14 20:42:40.960535.960535 lmp.py:1625]   Expert 28 |    219 | GPU
DEBUG 01-14 20:42:40.960225.960225 lmp.py:1625]   Expert 54 |    225 | GPU
DEBUG 01-14 20:42:40.960914.960914 lmp.py:1625]   Expert 19 |    226 | GPU
DEBUG 01-14 20:42:40.960080.960080 lmp.py:1625]   Expert  9 |    242 | GPU
DEBUG 01-14 20:42:40.960769.960769 lmp.py:1625]   Expert 41 |    258 | GPU
DEBUG 01-14 20:42:40.960459.960459 lmp.py:1625]   Expert 24 |    262 | GPU
DEBUG 01-14 20:42:40.960148.960148 lmp.py:1625]   Expert 50 |    269 | GPU
DEBUG 01-14 20:42:40.960837.960837 lmp.py:1625]   Expert 46 |    290 | GPU
DEBUG 01-14 20:42:40.960765.960765 lmp.py:1625]   Expert 59 |    325 | GPU
DEBUG 01-14 20:42:40.960693.960693 lmp.py:1625]   Expert 33 |    400 | GPU
DEBUG 01-14 20:42:40.960011.960011 lmp.py:1625]   Expert 56 |    410 | GPU
DEBUG 01-14 20:42:40.960867.960867 lmp.py:1625]   Expert 10 |    432 | GPU
DEBUG 01-14 20:42:40.960748.960748 lmp.py:1625]   Expert 26 |    435 | GPU
DEBUG 01-14 20:42:40.960391.960391 lmp.py:1625]   Expert 15 |    599 | GPU
DEBUG 01-14 20:42:40.960034.960034 lmp.py:1625]   Expert  3 |    601 | GPU
DEBUG 01-14 20:42:40.960439.960439 lmp.py:1625]   Expert 40 |    860 | GPU
DEBUG 01-14 20:42:40.960035.960035 lmp.py:1626] 
DEBUG 01-14 20:42:40.960035.960035 lmp.py:1626]   CPU total tokens: 3234 (26.3%)
DEBUG 01-14 20:42:40.960586.960586 lmp.py:1627]   GPU total tokens: 9054 (73.7%)
DEBUG 01-14 20:42:40.960666.960666 cuda_h.py:19] end experts_map_get cost 0.0014874935150146484 seconds
DEBUG 01-14 20:42:40.960238.960238 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-14 20:42:40.960995.960995 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-14 20:42:40.960530.960530 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-14 20:42:40.962337.962337 cuda_h.py:19] end allocate_cuda_memory cost 0.0017197132110595703 seconds
DEBUG 01-14 20:42:40.962657.962657 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-14 20:42:40.962267.962267 sllm_store_c.py:27] get device uuid map
DEBUG 01-14 20:42:40.962652.962652 sllm_store_c.py:29] call client load into gpu
DEBUG 01-14 20:42:40.962733.962733 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, df35c7c5-ae08-47d7-a25a-b22ce3044e62
DEBUG 01-14 20:42:40.962064.962064 client.py:106] call stub.LoadModelAsync
INFO 01-14 20:42:40.963557.963557 client.py:127] Model loaded
DEBUG 01-14 20:42:40.963149.963149 cuda_h.py:10] start restore2model
DEBUG 01-14 20:42:40.963001.963001 cuda_h.py:19] end restore2model cost 0.0003178119659423828 seconds
DEBUG 01-14 20:42:40.963049.963049 cuda_h.py:19] end sllm_worker_task cost 0.011324882507324219 seconds
INFO 01-14 20:42:40.963014.963014 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, df35c7c5-ae08-47d7-a25a-b22ce3044e62
DEBUG 01-14 20:42:40.963241.963241 cuda_h.py:19] end load_into_gpu_async cost 0.0012066364288330078 seconds
DEBUG 01-14 20:42:40.963467.963467 cuda_h.py:10] start restore_tensors2
DEBUG 01-14 20:42:40.964667.964667 cuda_h.py:19] end restore_tensors2 cost 0.00040149688720703125 seconds
DEBUG 01-14 20:42:40.964378.964378 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0036971569061279297 seconds
DEBUG 01-14 20:42:40.964267.964267 cuda_h.py:10] start restore2model
DEBUG 01-14 20:42:40.967267.967267 cuda_h.py:19] end restore2model cost 0.0025353431701660156 seconds
DEBUG 01-14 20:42:40.967680.967680 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.00643610954284668 seconds
DEBUG 01-14 20:42:40.967091.967091 cuda_h.py:10] start gpu_sexperts
DEBUG 01-14 20:42:40.967677.967677 cuda_h.py:19] end gpu_sexperts cost 0.00026226043701171875 seconds
DEBUG 01-14 20:42:40.967592.967592 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-14 20:42:40.967865.967865 lmp.py:1683] 
DEBUG 01-14 20:42:40.967865.967865 lmp.py:1683]   Computing 32 experts on CPU...
DEBUG 01-14 20:42:40.967715.967715 cuda_h.py:19] end cpu_experts_submit cost 4.9114227294921875e-05 seconds
DEBUG 01-14 20:42:40.967841.967841 cuda_h.py:10] start experts_func_mgpu_group_pad
DEBUG 01-14 20:42:40.968075.968075 mlpmodule.py:1367]  experts func einsum cost 0.07867240905761719 s
DEBUG 01-14 20:42:40.977927.977927 mlpmodule.py:1460] group tensors cost 0.008400678634643555 s
DEBUG 01-14 20:42:40.978070.978070 cuda_h.py:10] start move_flat_hidden2cpu
DEBUG 01-14 20:42:40.979901.979901 cuda_h.py:19] end experts_func_mgpu_group_pad cost 0.012017011642456055 seconds
DEBUG 01-14 20:42:40.982924.982924 cuda_h.py:10] start gpu_group_list
DEBUG 01-14 20:42:40.984918.984918 cuda_h.py:19] end gpu_group_list cost 0.0010027885437011719 seconds
DEBUG 01-14 20:42:40.984972.984972 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-14 20:42:40.984427.984427 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 3.719329833984375e-05 seconds
DEBUG 01-14 20:42:40.984563.984563 cuda_h.py:10] start wait_experts
INFO 01-14 20:42:40.984910.984910 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, df35c7c5-ae08-47d7-a25a-b22ce3044e62
DEBUG 01-14 20:42:40.985540.985540 cuda_h.py:19] end move_flat_hidden2cpu cost 0.007455110549926758 seconds
DEBUG 01-14 20:42:40.987071.987071 mlpmodule.py:1533] pad cost 0.0015208721160888672 s
DEBUG 01-14 20:42:40.987723.987723 mlpmodule.py:1539] create cpu tensor cost 3.361701965332031e-05 s
DEBUG 01-14 20:42:40.989133.989133 mlpmodule.py:1544] move to cpu cost 0.0019180774688720703 s
DEBUG 01-14 20:42:40.999086.999086 mlpmodule.py:1558] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-14 20:42:40.999018.999018 mlpmodule.py:1559] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-14 20:42:40.999525.999525 mlpmodule.py:1564] group_w3 first element: -0.0162353515625
WARNING 01-14 20:42:40.999542.999542 mlpmodule.py:1574] start einsum2
DEBUG 01-14 20:42:41.016104.016104 mlpmodule.py:1584] group einsum cost 0.02693486213684082 s
DEBUG 01-14 20:42:41.017398.017398 mlpmodule.py:1593] cpy2cputensor cost 0.0006546974182128906 s
DEBUG 01-14 20:42:41.017122.017122 cuda_h.py:10] start move_outputs
DEBUG 01-14 20:42:41.019991.019991 cuda_h.py:19] end move_outputs cost 0.0023975372314453125 seconds
INFO 01-14 20:42:41.021249.021249 client.py:127] Model loaded
DEBUG 01-14 20:42:41.021652.021652 cuda_h.py:19] end wait_experts cost 0.03659701347351074 seconds
DEBUG 01-14 20:42:41.021760.021760 cuda_h.py:10] start gpu_experts
DEBUG 01-14 20:42:41.021775.021775 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-14 20:42:41.023195.023195 cuda_h.py:19] end wait_cetm_experts cost 0.0022382736206054688 seconds
DEBUG 01-14 20:42:41.023973.023973 cuda_h.py:10] start gpu_group_einsum_mp_multi_list
DEBUG 01-14 20:42:41.023113.023113 cuda_h.py:10] start gpu_group_tensor
DEBUG 01-14 20:42:41.024056.024056 cuda_h.py:19] end gpu_group_tensor cost 0.0002422332763671875 seconds
DEBUG 01-14 20:42:41.024265.024265 cuda_h.py:10] start gpu_group_einsum
DEBUG 01-14 20:42:41.024239.024239 cuda_h.py:19] end gpu_group_einsum cost 0.0005314350128173828 seconds
DEBUG 01-14 20:42:41.025349.025349 cuda_h.py:10] start gpu_final_hidden_states_scatter
DEBUG 01-14 20:42:41.025947.025947 cuda_h.py:10] start all_expert_outputs_slices
DEBUG 01-14 20:42:41.025388.025388 cuda_h.py:19] end all_expert_outputs_slices cost 0.0002942085266113281 seconds
DEBUG 01-14 20:42:41.025522.025522 cuda_h.py:10] start concat_expert_out
DEBUG 01-14 20:42:41.025042.025042 cuda_h.py:19] end concat_expert_out cost 6.699562072753906e-05 seconds
DEBUG 01-14 20:42:41.025422.025422 cuda_h.py:10] start index_scatter
DEBUG 01-14 20:42:41.025094.025094 cuda_h.py:19] end index_scatter cost 7.43865966796875e-05 seconds
DEBUG 01-14 20:42:41.025903.025903 cuda_h.py:19] end gpu_final_hidden_states_scatter cost 0.0006833076477050781 seconds
DEBUG 01-14 20:42:41.025297.025297 cuda_h.py:19] end gpu_experts cost 0.004331827163696289 seconds
DEBUG 01-14 20:42:41.025238.025238 cuda_h.py:10] start all_expert_weight_slices
DEBUG 01-14 20:42:41.026046.026046 cuda_h.py:19] end all_expert_weight_slices cost 0.0009510517120361328 seconds
DEBUG 01-14 20:42:41.026961.026961 cuda_h.py:10] start cpuoutputsdeal
DEBUG 01-14 20:42:41.027399.027399 cuda_h.py:10] start index_scatter
DEBUG 01-14 20:42:41.027197.027197 cuda_h.py:19] end index_scatter cost 4.935264587402344e-05 seconds
DEBUG 01-14 20:42:41.027198.027198 cuda_h.py:19] end cpuoutputsdeal cost 0.0005335807800292969 seconds
DEBUG 01-14 20:42:41.027678.027678 cuda_h.py:19] end layer_moe_generate_mp_l_13 cost 0.06922364234924316 seconds
DEBUG 01-14 20:42:41.027373.027373 cuda_h.py:19] end prefill_layer cost 0.07604598999023438 seconds
DEBUG 01-14 20:42:41.028018.028018 lmp.py:1551] -------------------------------- end prefill layer 12 --------------------------------
DEBUG 01-14 20:42:41.028244.028244 cuda_h.py:10] start prefill_layer
DEBUG 01-14 20:42:41.028470.028470 lmp.py:1494] -------------------------------- start prefill layer 13 --------------------------------
DEBUG 01-14 20:42:41.028411.028411 cuda_h.py:10] start start_load_qkvogn_s_weight_l_14
DEBUG 01-14 20:42:41.028736.028736 cuda_h.py:10] start start_load_qkvogn_s_weight_l_14
DEBUG 01-14 20:42:41.028394.028394 cuda_h.py:19] end start_load_qkvogn_s_weight_l_14 cost 3.600120544433594e-05 seconds
DEBUG 01-14 20:42:41.028150.028150 cuda_h.py:19] end start_load_qkvogn_s_weight_l_14 cost 6.937980651855469e-05 seconds
DEBUG 01-14 20:42:41.028469.028469 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-14 20:42:41.028584.028584 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-14 20:42:41.028681.028681 cuda_h.py:10] start sllm_worker_task
DEBUG 01-14 20:42:41.028863.028863 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-14 20:42:41.028560.028560 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-14 20:42:41.031333.031333 cuda_h.py:19] end allocate_cuda_memory cost 0.003058195114135742 seconds
DEBUG 01-14 20:42:41.031236.031236 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-14 20:42:41.031760.031760 sllm_store_c.py:27] get device uuid map
DEBUG 01-14 20:42:41.031444.031444 sllm_store_c.py:29] call client load into gpu
DEBUG 01-14 20:42:41.031623.031623 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 687ebfa9-7e39-4a83-9acf-81bf7287e37b
DEBUG 01-14 20:42:41.031250.031250 client.py:106] call stub.LoadModelAsync
DEBUG 01-14 20:42:41.032994.032994 cuda_h.py:10] start self_attn
INFO 01-14 20:42:41.032812.032812 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 687ebfa9-7e39-4a83-9acf-81bf7287e37b
DEBUG 01-14 20:42:41.032761.032761 cuda_h.py:19] end load_into_gpu_async cost 0.0010187625885009766 seconds
DEBUG 01-14 20:42:41.032749.032749 cuda_h.py:10] start restore_tensors2
DEBUG 01-14 20:42:41.032216.032216 cuda_h.py:19] end restore_tensors2 cost 7.200241088867188e-05 seconds
DEBUG 01-14 20:42:41.032071.032071 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.004405498504638672 seconds
INFO 01-14 20:42:41.033729.033729 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 687ebfa9-7e39-4a83-9acf-81bf7287e37b
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-14 20:42:41.035718.035718 cuda_h.py:19] end self_attn cost 0.0035583972930908203 seconds
DEBUG 01-14 20:42:41.036225.036225 cuda_h.py:19] end iln_self_attn_paln cost 0.007897615432739258 seconds
DEBUG 01-14 20:42:41.036491.036491 cuda_h.py:10] start layer_moe_generate_mp_l_14
DEBUG 01-14 20:42:41.036824.036824 cuda_h.py:10] start gate
DEBUG 01-14 20:42:41.037192.037192 cuda_h.py:19] end gate cost 0.0006935596466064453 seconds
DEBUG 01-14 20:42:41.037214.037214 cuda_h.py:10] start experts_map_get
DEBUG 01-14 20:42:41.037443.037443 lmp.py:1615] 
DEBUG 01-14 20:42:41.037443.037443 lmp.py:1615] Expert Token Distribution & Device Allocation:
DEBUG 01-14 20:42:41.037530.037530 lmp.py:1616]   Total experts: 64
DEBUG 01-14 20:42:41.037418.037418 lmp.py:1617]   CPU experts: 32 (50%)
DEBUG 01-14 20:42:41.037399.037399 lmp.py:1618]   GPU experts: 32 (50%)
DEBUG 01-14 20:42:41.037519.037519 lmp.py:1619] 
DEBUG 01-14 20:42:41.037519.037519 lmp.py:1619]   Expert ID | Tokens | Device
DEBUG 01-14 20:42:41.037639.037639 lmp.py:1620]   -----------------------------------
DEBUG 01-14 20:42:41.037950.037950 lmp.py:1625]   Expert 42 |     18 | CPU
DEBUG 01-14 20:42:41.037832.037832 lmp.py:1625]   Expert 19 |     24 | CPU
DEBUG 01-14 20:42:41.037475.037475 lmp.py:1625]   Expert 30 |     26 | CPU
DEBUG 01-14 20:42:41.037879.037879 lmp.py:1625]   Expert  6 |     60 | CPU
DEBUG 01-14 20:42:41.037284.037284 lmp.py:1625]   Expert 32 |     68 | CPU
DEBUG 01-14 20:42:41.037179.037179 lmp.py:1625]   Expert  5 |     69 | CPU
DEBUG 01-14 20:42:41.037107.037107 lmp.py:1625]   Expert  1 |     71 | CPU
DEBUG 01-14 20:42:41.037034.037034 lmp.py:1625]   Expert 53 |    101 | CPU
DEBUG 01-14 20:42:41.037200.037200 lmp.py:1625]   Expert 18 |    107 | CPU
DEBUG 01-14 20:42:41.037651.037651 lmp.py:1625]   Expert 11 |    111 | CPU
DEBUG 01-14 20:42:41.037579.037579 lmp.py:1625]   Expert 63 |    126 | CPU
DEBUG 01-14 20:42:41.037268.037268 lmp.py:1625]   Expert 13 |    131 | CPU
DEBUG 01-14 20:42:41.037958.037958 lmp.py:1625]   Expert 59 |    132 | CPU
DEBUG 01-14 20:42:41.037647.037647 lmp.py:1625]   Expert 58 |    136 | CPU
DEBUG 01-14 20:42:41.037336.037336 lmp.py:1625]   Expert 40 |    142 | CPU
DEBUG 01-14 20:42:41.037787.037787 lmp.py:1625]   Expert 51 |    144 | CPU
DEBUG 01-14 20:42:41.037715.037715 lmp.py:1625]   Expert 31 |    145 | CPU
DEBUG 01-14 20:42:41.037166.037166 lmp.py:1625]   Expert  4 |    147 | CPU
DEBUG 01-14 20:42:41.037093.037093 lmp.py:1625]   Expert 26 |    147 | CPU
DEBUG 01-14 20:42:41.037783.037783 lmp.py:1625]   Expert 34 |    147 | CPU
DEBUG 01-14 20:42:41.037234.037234 lmp.py:1625]   Expert 61 |    147 | CPU
DEBUG 01-14 20:42:41.037784.037784 lmp.py:1625]   Expert 56 |    149 | CPU
DEBUG 01-14 20:42:41.037758.037758 lmp.py:1625]   Expert 50 |    153 | CPU
DEBUG 01-14 20:42:41.037255.037255 lmp.py:1625]   Expert 20 |    154 | CPU
DEBUG 01-14 20:42:41.037991.037991 lmp.py:1625]   Expert 48 |    154 | CPU
DEBUG 01-14 20:42:41.037488.037488 lmp.py:1625]   Expert  9 |    160 | CPU
DEBUG 01-14 20:42:41.037224.037224 lmp.py:1625]   Expert 12 |    163 | CPU
DEBUG 01-14 20:42:41.037483.037483 lmp.py:1625]   Expert 35 |    164 | CPU
DEBUG 01-14 20:42:41.037741.037741 lmp.py:1625]   Expert 37 |    165 | CPU
DEBUG 01-14 20:42:41.037238.037238 lmp.py:1625]   Expert 33 |    168 | CPU
DEBUG 01-14 20:42:41.038736.038736 lmp.py:1625]   Expert 55 |    171 | CPU
DEBUG 01-14 20:42:41.038471.038471 lmp.py:1625]   Expert 10 |    173 | CPU
DEBUG 01-14 20:42:41.038730.038730 lmp.py:1625]   Expert 46 |    174 | GPU
DEBUG 01-14 20:42:41.038466.038466 lmp.py:1625]   Expert  2 |    178 | GPU
DEBUG 01-14 20:42:41.038963.038963 lmp.py:1625]   Expert 52 |    178 | GPU
DEBUG 01-14 20:42:41.038036.038036 lmp.py:1625]   Expert 36 |    180 | GPU
DEBUG 01-14 20:42:41.038156.038156 lmp.py:1625]   Expert  8 |    190 | GPU
DEBUG 01-14 20:42:41.038653.038653 lmp.py:1625]   Expert 39 |    200 | GPU
DEBUG 01-14 20:42:41.038389.038389 lmp.py:1625]   Expert 25 |    202 | GPU
DEBUG 01-14 20:42:41.038648.038648 lmp.py:1625]   Expert 57 |    210 | GPU
DEBUG 01-14 20:42:41.038145.038145 lmp.py:1625]   Expert  0 |    213 | GPU
DEBUG 01-14 20:42:41.038642.038642 lmp.py:1625]   Expert  3 |    214 | GPU
DEBUG 01-14 20:42:41.038378.038378 lmp.py:1625]   Expert 24 |    222 | GPU
DEBUG 01-14 20:42:41.038875.038875 lmp.py:1625]   Expert  7 |    235 | GPU
DEBUG 01-14 20:42:41.038611.038611 lmp.py:1625]   Expert 27 |    235 | GPU
DEBUG 01-14 20:42:41.038346.038346 lmp.py:1625]   Expert 62 |    241 | GPU
DEBUG 01-14 20:42:41.038082.038082 lmp.py:1625]   Expert 21 |    243 | GPU
DEBUG 01-14 20:42:41.038579.038579 lmp.py:1625]   Expert 38 |    244 | GPU
DEBUG 01-14 20:42:41.038553.038553 lmp.py:1625]   Expert 23 |    245 | GPU
DEBUG 01-14 20:42:41.038812.038812 lmp.py:1625]   Expert 28 |    266 | GPU
DEBUG 01-14 20:42:41.038548.038548 lmp.py:1625]   Expert 43 |    270 | GPU
DEBUG 01-14 20:42:41.038045.038045 lmp.py:1625]   Expert 29 |    272 | GPU
DEBUG 01-14 20:42:41.038019.038019 lmp.py:1625]   Expert 60 |    274 | GPU
DEBUG 01-14 20:42:41.038516.038516 lmp.py:1625]   Expert 16 |    283 | GPU
DEBUG 01-14 20:42:41.038490.038490 lmp.py:1625]   Expert 15 |    285 | GPU
DEBUG 01-14 20:42:41.038749.038749 lmp.py:1625]   Expert 41 |    285 | GPU
DEBUG 01-14 20:42:41.038975.038975 lmp.py:1625]   Expert 22 |    286 | GPU
DEBUG 01-14 20:42:41.038757.038757 lmp.py:1625]   Expert 49 |    286 | GPU
DEBUG 01-14 20:42:41.038300.038300 lmp.py:1625]   Expert 54 |    286 | GPU
DEBUG 01-14 20:42:41.038321.038321 lmp.py:1625]   Expert 44 |    314 | GPU
DEBUG 01-14 20:42:41.038341.038341 lmp.py:1625]   Expert 47 |    316 | GPU
DEBUG 01-14 20:42:41.038885.038885 lmp.py:1625]   Expert 14 |    372 | GPU
DEBUG 01-14 20:42:41.038428.038428 lmp.py:1625]   Expert 17 |    388 | GPU
DEBUG 01-14 20:42:41.038449.038449 lmp.py:1625]   Expert 45 |    528 | GPU
DEBUG 01-14 20:42:41.038946.038946 lmp.py:1626] 
DEBUG 01-14 20:42:41.038946.038946 lmp.py:1626]   CPU total tokens: 3973 (32.3%)
DEBUG 01-14 20:42:41.038158.038158 lmp.py:1627]   GPU total tokens: 8315 (67.7%)
DEBUG 01-14 20:42:41.038662.038662 cuda_h.py:19] end experts_map_get cost 0.0014965534210205078 seconds
DEBUG 01-14 20:42:41.038221.038221 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-14 20:42:41.038626.038626 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-14 20:42:41.038678.038678 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-14 20:42:41.039401.039401 cuda_h.py:19] end allocate_cuda_memory cost 0.0006072521209716797 seconds
DEBUG 01-14 20:42:41.039820.039820 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-14 20:42:41.039907.039907 sllm_store_c.py:27] get device uuid map
DEBUG 01-14 20:42:41.039797.039797 sllm_store_c.py:29] call client load into gpu
DEBUG 01-14 20:42:41.039784.039784 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 337fedc4-f48f-45e5-a68c-c42b644e713b
DEBUG 01-14 20:42:41.039970.039970 client.py:106] call stub.LoadModelAsync
INFO 01-14 20:42:41.040678.040678 client.py:127] Model loaded
DEBUG 01-14 20:42:41.040614.040614 cuda_h.py:10] start restore2model
DEBUG 01-14 20:42:41.040342.040342 cuda_h.py:19] end restore2model cost 0.0003657341003417969 seconds
DEBUG 01-14 20:42:41.040873.040873 cuda_h.py:19] end sllm_worker_task cost 0.011991500854492188 seconds
INFO 01-14 20:42:41.040295.040295 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 337fedc4-f48f-45e5-a68c-c42b644e713b
DEBUG 01-14 20:42:41.040569.040569 cuda_h.py:19] end load_into_gpu_async cost 0.0011513233184814453 seconds
DEBUG 01-14 20:42:41.040033.040033 cuda_h.py:10] start restore_tensors2
DEBUG 01-14 20:42:41.041320.041320 cuda_h.py:19] end restore_tensors2 cost 0.00043082237243652344 seconds
DEBUG 01-14 20:42:41.041309.041309 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0025517940521240234 seconds
DEBUG 01-14 20:42:41.041932.041932 cuda_h.py:10] start restore2model
DEBUG 01-14 20:42:41.043022.043022 cuda_h.py:19] end restore2model cost 0.002462148666381836 seconds
DEBUG 01-14 20:42:41.043243.043243 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.0051877498626708984 seconds
DEBUG 01-14 20:42:41.043654.043654 cuda_h.py:10] start gpu_sexperts
DEBUG 01-14 20:42:41.044101.044101 cuda_h.py:19] end gpu_sexperts cost 0.00026535987854003906 seconds
DEBUG 01-14 20:42:41.044540.044540 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-14 20:42:41.044527.044527 lmp.py:1683] 
DEBUG 01-14 20:42:41.044527.044527 lmp.py:1683]   Computing 32 experts on CPU...
DEBUG 01-14 20:42:41.044211.044211 cuda_h.py:19] end cpu_experts_submit cost 4.76837158203125e-05 seconds
DEBUG 01-14 20:42:41.044907.044907 cuda_h.py:10] start experts_func_mgpu_group_pad
DEBUG 01-14 20:42:41.045543.045543 cuda_h.py:19] end experts_func_mgpu_group_pad cost 0.0015592575073242188 seconds
DEBUG 01-14 20:42:41.046688.046688 cuda_h.py:10] start gpu_group_list
DEBUG 01-14 20:42:41.047674.047674 cuda_h.py:19] end gpu_group_list cost 0.0003204345703125 seconds
DEBUG 01-14 20:42:41.047446.047446 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-14 20:42:41.047845.047845 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 1.3589859008789062e-05 seconds
DEBUG 01-14 20:42:41.047542.047542 cuda_h.py:10] start wait_experts
INFO 01-14 20:42:41.047860.047860 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 337fedc4-f48f-45e5-a68c-c42b644e713b
DEBUG 01-14 20:42:41.047891.047891 mlpmodule.py:1367]  experts func einsum cost 0.078155517578125 s
DEBUG 01-14 20:42:41.056182.056182 mlpmodule.py:1460] group tensors cost 0.008834362030029297 s
DEBUG 01-14 20:42:41.057679.057679 cuda_h.py:10] start move_flat_hidden2cpu
DEBUG 01-14 20:42:41.062681.062681 cuda_h.py:19] end move_flat_hidden2cpu cost 0.005570650100708008 seconds
DEBUG 01-14 20:42:41.064033.064033 mlpmodule.py:1533] pad cost 0.0015149116516113281 s
DEBUG 01-14 20:42:41.064109.064109 mlpmodule.py:1539] create cpu tensor cost 3.457069396972656e-05 s
DEBUG 01-14 20:42:41.066178.066178 mlpmodule.py:1544] move to cpu cost 0.0020439624786376953 s
DEBUG 01-14 20:42:41.076232.076232 mlpmodule.py:1558] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-14 20:42:41.076000.076000 mlpmodule.py:1559] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-14 20:42:41.076029.076029 mlpmodule.py:1564] group_w3 first element: -0.0211181640625
WARNING 01-14 20:42:41.076901.076901 mlpmodule.py:1574] start einsum2
DEBUG 01-14 20:42:41.093148.093148 mlpmodule.py:1584] group einsum cost 0.026902437210083008 s
DEBUG 01-14 20:42:41.094415.094415 mlpmodule.py:1593] cpy2cputensor cost 0.0006651878356933594 s
DEBUG 01-14 20:42:41.094900.094900 cuda_h.py:10] start move_outputs
INFO 01-14 20:42:41.096874.096874 client.py:127] Model loaded
DEBUG 01-14 20:42:41.304871.304871 cuda_h.py:19] end wait_experts cost 0.25681304931640625 seconds
DEBUG 01-14 20:42:41.304101.304101 cuda_h.py:10] start gpu_experts
DEBUG 01-14 20:42:41.304700.304700 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-14 20:42:41.306229.306229 cuda_h.py:19] end move_outputs cost 0.002123594284057617 seconds
DEBUG 01-14 20:42:41.310932.310932 cuda_h.py:19] end wait_cetm_experts cost 0.006089210510253906 seconds
DEBUG 01-14 20:42:41.310248.310248 cuda_h.py:10] start gpu_group_einsum_mp_multi_list
DEBUG 01-14 20:42:41.310567.310567 cuda_h.py:10] start gpu_group_tensor
DEBUG 01-14 20:42:41.310319.310319 cuda_h.py:19] end gpu_group_tensor cost 0.0002567768096923828 seconds
DEBUG 01-14 20:42:41.311669.311669 cuda_h.py:10] start gpu_group_einsum
DEBUG 01-14 20:42:41.311350.311350 cuda_h.py:19] end gpu_group_einsum cost 0.0006721019744873047 seconds
DEBUG 01-14 20:42:41.312773.312773 cuda_h.py:10] start gpu_final_hidden_states_scatter
DEBUG 01-14 20:42:41.312835.312835 cuda_h.py:10] start all_expert_outputs_slices
DEBUG 01-14 20:42:41.312585.312585 cuda_h.py:19] end all_expert_outputs_slices cost 0.0003981590270996094 seconds
DEBUG 01-14 20:42:41.312137.312137 cuda_h.py:10] start concat_expert_out
DEBUG 01-14 20:42:41.312088.312088 cuda_h.py:19] end concat_expert_out cost 8.702278137207031e-05 seconds
DEBUG 01-14 20:42:41.312164.312164 cuda_h.py:10] start index_scatter
DEBUG 01-14 20:42:41.313632.313632 cuda_h.py:19] end index_scatter cost 8.0108642578125e-05 seconds
DEBUG 01-14 20:42:41.313230.313230 cuda_h.py:19] end gpu_final_hidden_states_scatter cost 0.0009405612945556641 seconds
DEBUG 01-14 20:42:41.313618.313618 cuda_h.py:19] end gpu_experts cost 0.008827924728393555 seconds
DEBUG 01-14 20:42:41.313864.313864 cuda_h.py:10] start all_expert_weight_slices
DEBUG 01-14 20:42:41.314984.314984 cuda_h.py:19] end all_expert_weight_slices cost 0.0013384819030761719 seconds
DEBUG 01-14 20:42:41.314092.314092 cuda_h.py:10] start cpuoutputsdeal
DEBUG 01-14 20:42:41.315417.315417 cuda_h.py:10] start index_scatter
DEBUG 01-14 20:42:41.315667.315667 cuda_h.py:19] end index_scatter cost 7.43865966796875e-05 seconds
DEBUG 01-14 20:42:41.315510.315510 cuda_h.py:19] end cpuoutputsdeal cost 0.0007534027099609375 seconds
DEBUG 01-14 20:42:41.315944.315944 cuda_h.py:19] end layer_moe_generate_mp_l_14 cost 0.2793004512786865 seconds
DEBUG 01-14 20:42:41.316536.316536 cuda_h.py:19] end prefill_layer cost 0.28795933723449707 seconds
DEBUG 01-14 20:42:41.316459.316459 lmp.py:1551] -------------------------------- end prefill layer 13 --------------------------------
DEBUG 01-14 20:42:41.316421.316421 cuda_h.py:10] start prefill_layer
DEBUG 01-14 20:42:41.316859.316859 lmp.py:1494] -------------------------------- start prefill layer 14 --------------------------------
DEBUG 01-14 20:42:41.316675.316675 cuda_h.py:10] start start_load_qkvogn_s_weight_l_15
DEBUG 01-14 20:42:41.316114.316114 cuda_h.py:10] start start_load_qkvogn_s_weight_l_15
DEBUG 01-14 20:42:41.316428.316428 cuda_h.py:19] end start_load_qkvogn_s_weight_l_15 cost 3.8623809814453125e-05 seconds
DEBUG 01-14 20:42:41.316396.316396 cuda_h.py:19] end start_load_qkvogn_s_weight_l_15 cost 9.870529174804688e-05 seconds
DEBUG 01-14 20:42:41.316543.316543 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-14 20:42:41.316978.316978 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-14 20:42:41.316883.316883 cuda_h.py:10] start sllm_worker_task
DEBUG 01-14 20:42:41.316028.316028 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-14 20:42:41.317450.317450 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-14 20:42:41.319666.319666 cuda_h.py:19] end allocate_cuda_memory cost 0.0024018287658691406 seconds
DEBUG 01-14 20:42:41.319984.319984 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-14 20:42:41.319981.319981 sllm_store_c.py:27] get device uuid map
DEBUG 01-14 20:42:41.320298.320298 sllm_store_c.py:29] call client load into gpu
DEBUG 01-14 20:42:41.320315.320315 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 802d764f-84e5-4f02-b287-3b50bcdd9df6
DEBUG 01-14 20:42:41.320223.320223 client.py:106] call stub.LoadModelAsync
DEBUG 01-14 20:42:41.320551.320551 cuda_h.py:10] start self_attn
INFO 01-14 20:42:41.322406.322406 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 802d764f-84e5-4f02-b287-3b50bcdd9df6
DEBUG 01-14 20:42:41.322524.322524 cuda_h.py:19] end load_into_gpu_async cost 0.0025739669799804688 seconds
DEBUG 01-14 20:42:41.322700.322700 cuda_h.py:10] start restore_tensors2
DEBUG 01-14 20:42:41.322979.322979 cuda_h.py:19] end restore_tensors2 cost 0.0001475811004638672 seconds
DEBUG 01-14 20:42:41.322744.322744 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.005873203277587891 seconds
INFO 01-14 20:42:41.323107.323107 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 802d764f-84e5-4f02-b287-3b50bcdd9df6
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-14 20:42:41.324998.324998 cuda_h.py:19] end self_attn cost 0.003753662109375 seconds
DEBUG 01-14 20:42:41.324989.324989 cuda_h.py:19] end iln_self_attn_paln cost 0.008324384689331055 seconds
DEBUG 01-14 20:42:41.324700.324700 cuda_h.py:10] start layer_moe_generate_mp_l_15
DEBUG 01-14 20:42:41.324615.324615 cuda_h.py:10] start gate
DEBUG 01-14 20:42:41.325336.325336 cuda_h.py:19] end gate cost 0.0006968975067138672 seconds
DEBUG 01-14 20:42:41.325940.325940 cuda_h.py:10] start experts_map_get
DEBUG 01-14 20:42:41.326707.326707 lmp.py:1615] 
DEBUG 01-14 20:42:41.326707.326707 lmp.py:1615] Expert Token Distribution & Device Allocation:
DEBUG 01-14 20:42:41.326377.326377 lmp.py:1616]   Total experts: 64
DEBUG 01-14 20:42:41.326511.326511 lmp.py:1617]   CPU experts: 32 (50%)
DEBUG 01-14 20:42:41.326829.326829 lmp.py:1618]   GPU experts: 32 (50%)
DEBUG 01-14 20:42:41.326764.326764 lmp.py:1619] 
DEBUG 01-14 20:42:41.326764.326764 lmp.py:1619]   Expert ID | Tokens | Device
DEBUG 01-14 20:42:41.326460.326460 lmp.py:1620]   -----------------------------------
DEBUG 01-14 20:42:41.326110.326110 lmp.py:1625]   Expert 34 |     19 | CPU
DEBUG 01-14 20:42:41.326806.326806 lmp.py:1625]   Expert  7 |     41 | CPU
DEBUG 01-14 20:42:41.326787.326787 lmp.py:1625]   Expert 13 |     42 | CPU
DEBUG 01-14 20:42:41.326291.326291 lmp.py:1625]   Expert 39 |     84 | CPU
DEBUG 01-14 20:42:41.326795.326795 lmp.py:1625]   Expert 54 |     85 | CPU
DEBUG 01-14 20:42:41.326822.326822 lmp.py:1625]   Expert 18 |     93 | CPU
DEBUG 01-14 20:42:41.326803.326803 lmp.py:1625]   Expert 49 |     93 | CPU
DEBUG 01-14 20:42:41.326022.326022 lmp.py:1625]   Expert 59 |     96 | CPU
DEBUG 01-14 20:42:41.326718.326718 lmp.py:1625]   Expert 16 |    101 | CPU
DEBUG 01-14 20:42:41.326984.326984 lmp.py:1625]   Expert 41 |    107 | CPU
DEBUG 01-14 20:42:41.326534.326534 lmp.py:1625]   Expert 45 |    107 | CPU
DEBUG 01-14 20:42:41.326084.326084 lmp.py:1625]   Expert  0 |    111 | CPU
DEBUG 01-14 20:42:41.326111.326111 lmp.py:1625]   Expert 22 |    114 | CPU
DEBUG 01-14 20:42:41.326662.326662 lmp.py:1625]   Expert 21 |    120 | CPU
DEBUG 01-14 20:42:41.326974.326974 lmp.py:1625]   Expert 52 |    129 | CPU
DEBUG 01-14 20:42:41.326762.326762 lmp.py:1625]   Expert 61 |    141 | CPU
DEBUG 01-14 20:42:41.326935.326935 lmp.py:1625]   Expert  8 |    142 | CPU
DEBUG 01-14 20:42:41.326492.326492 lmp.py:1625]   Expert 12 |    143 | CPU
DEBUG 01-14 20:42:41.326857.326857 lmp.py:1625]   Expert 35 |    143 | CPU
DEBUG 01-14 20:42:41.326507.326507 lmp.py:1625]   Expert 38 |    143 | CPU
DEBUG 01-14 20:42:41.326203.326203 lmp.py:1625]   Expert 17 |    145 | CPU
DEBUG 01-14 20:42:41.326899.326899 lmp.py:1625]   Expert 15 |    151 | CPU
DEBUG 01-14 20:42:41.326357.326357 lmp.py:1625]   Expert 36 |    152 | CPU
DEBUG 01-14 20:42:41.326053.326053 lmp.py:1625]   Expert 48 |    158 | CPU
DEBUG 01-14 20:42:41.326988.326988 lmp.py:1625]   Expert 60 |    158 | CPU
DEBUG 01-14 20:42:41.326445.326445 lmp.py:1625]   Expert 27 |    168 | CPU
DEBUG 01-14 20:42:41.326380.326380 lmp.py:1625]   Expert 31 |    169 | CPU
DEBUG 01-14 20:42:41.326076.326076 lmp.py:1625]   Expert 53 |    179 | CPU
DEBUG 01-14 20:42:41.326964.326964 lmp.py:1625]   Expert 40 |    185 | CPU
DEBUG 01-14 20:42:41.326852.326852 lmp.py:1625]   Expert 20 |    186 | CPU
DEBUG 01-14 20:42:41.326548.326548 lmp.py:1625]   Expert 19 |    187 | CPU
DEBUG 01-14 20:42:41.326244.326244 lmp.py:1625]   Expert  4 |    188 | CPU
DEBUG 01-14 20:42:41.326179.326179 lmp.py:1625]   Expert 50 |    189 | GPU
DEBUG 01-14 20:42:41.326637.326637 lmp.py:1625]   Expert 46 |    195 | GPU
DEBUG 01-14 20:42:41.327333.327333 lmp.py:1625]   Expert 11 |    202 | GPU
DEBUG 01-14 20:42:41.327790.327790 lmp.py:1625]   Expert 30 |    207 | GPU
DEBUG 01-14 20:42:41.327725.327725 lmp.py:1625]   Expert 26 |    209 | GPU
DEBUG 01-14 20:42:41.327421.327421 lmp.py:1625]   Expert 43 |    212 | GPU
DEBUG 01-14 20:42:41.327117.327117 lmp.py:1625]   Expert 29 |    217 | GPU
DEBUG 01-14 20:42:41.327290.327290 lmp.py:1625]   Expert 14 |    220 | GPU
DEBUG 01-14 20:42:41.327178.327178 lmp.py:1625]   Expert 57 |    226 | GPU
DEBUG 01-14 20:42:41.327113.327113 lmp.py:1625]   Expert  6 |    230 | GPU
DEBUG 01-14 20:42:41.327047.327047 lmp.py:1625]   Expert  3 |    239 | GPU
DEBUG 01-14 20:42:41.327505.327505 lmp.py:1625]   Expert 23 |    240 | GPU
DEBUG 01-14 20:42:41.327963.327963 lmp.py:1625]   Expert 33 |    240 | GPU
DEBUG 01-14 20:42:41.327659.327659 lmp.py:1625]   Expert  2 |    242 | GPU
DEBUG 01-14 20:42:41.327593.327593 lmp.py:1625]   Expert 56 |    248 | GPU
DEBUG 01-14 20:42:41.327289.327289 lmp.py:1625]   Expert 42 |    256 | GPU
DEBUG 01-14 20:42:41.327985.327985 lmp.py:1625]   Expert  9 |    260 | GPU
DEBUG 01-14 20:42:41.327681.327681 lmp.py:1625]   Expert 37 |    262 | GPU
DEBUG 01-14 20:42:41.327331.327331 lmp.py:1625]   Expert 44 |    265 | GPU
DEBUG 01-14 20:42:41.327743.327743 lmp.py:1625]   Expert 32 |    269 | GPU
DEBUG 01-14 20:42:41.327677.327677 lmp.py:1625]   Expert 55 |    274 | GPU
DEBUG 01-14 20:42:41.327896.327896 lmp.py:1625]   Expert 51 |    275 | GPU
DEBUG 01-14 20:42:41.327116.327116 lmp.py:1625]   Expert 28 |    279 | GPU
DEBUG 01-14 20:42:41.327573.327573 lmp.py:1625]   Expert  1 |    287 | GPU
DEBUG 01-14 20:42:41.327792.327792 lmp.py:1625]   Expert 24 |    288 | GPU
DEBUG 01-14 20:42:41.327250.327250 lmp.py:1625]   Expert 10 |    289 | GPU
DEBUG 01-14 20:42:41.327946.327946 lmp.py:1625]   Expert 58 |    289 | GPU
DEBUG 01-14 20:42:41.327166.327166 lmp.py:1625]   Expert 63 |    293 | GPU
DEBUG 01-14 20:42:41.327577.327577 lmp.py:1625]   Expert 25 |    308 | GPU
DEBUG 01-14 20:42:41.327988.327988 lmp.py:1625]   Expert 47 |    319 | GPU
DEBUG 01-14 20:42:41.327400.327400 lmp.py:1625]   Expert 62 |    328 | GPU
DEBUG 01-14 20:42:41.327096.327096 lmp.py:1625]   Expert  5 |    351 | GPU
DEBUG 01-14 20:42:41.327183.327183 lmp.py:1626] 
DEBUG 01-14 20:42:41.327183.327183 lmp.py:1626]   CPU total tokens: 4080 (33.2%)
DEBUG 01-14 20:42:41.327309.327309 lmp.py:1627]   GPU total tokens: 8208 (66.8%)
DEBUG 01-14 20:42:41.327204.327204 cuda_h.py:19] end experts_map_get cost 0.0019156932830810547 seconds
DEBUG 01-14 20:42:41.327498.327498 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-14 20:42:41.327878.327878 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-14 20:42:41.328612.328612 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-14 20:42:41.329374.329374 cuda_h.py:19] end allocate_cuda_memory cost 0.0015769004821777344 seconds
DEBUG 01-14 20:42:41.329655.329655 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-14 20:42:41.329649.329649 sllm_store_c.py:27] get device uuid map
DEBUG 01-14 20:42:41.329379.329379 sllm_store_c.py:29] call client load into gpu
DEBUG 01-14 20:42:41.329652.329652 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 390f74a0-d2ec-4416-bf31-49dfca43e5c1
DEBUG 01-14 20:42:41.329102.329102 client.py:106] call stub.LoadModelAsync
INFO 01-14 20:42:41.330873.330873 client.py:127] Model loaded
DEBUG 01-14 20:42:41.330613.330613 cuda_h.py:10] start restore2model
DEBUG 01-14 20:42:41.331919.331919 cuda_h.py:19] end restore2model cost 0.0009415149688720703 seconds
DEBUG 01-14 20:42:41.331056.331056 cuda_h.py:19] end sllm_worker_task cost 0.014882087707519531 seconds
INFO 01-14 20:42:41.331128.331128 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 390f74a0-d2ec-4416-bf31-49dfca43e5c1
DEBUG 01-14 20:42:41.332939.332939 cuda_h.py:19] end load_into_gpu_async cost 0.0023164749145507812 seconds
DEBUG 01-14 20:42:41.332503.332503 cuda_h.py:10] start restore_tensors2
DEBUG 01-14 20:42:41.332688.332688 cuda_h.py:19] end restore_tensors2 cost 0.0003535747528076172 seconds
DEBUG 01-14 20:42:41.332054.332054 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.004632711410522461 seconds
DEBUG 01-14 20:42:41.332393.332393 cuda_h.py:10] start restore2model
DEBUG 01-14 20:42:41.335161.335161 cuda_h.py:19] end restore2model cost 0.0025374889373779297 seconds
DEBUG 01-14 20:42:41.335236.335236 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.007357597351074219 seconds
DEBUG 01-14 20:42:41.335316.335316 cuda_h.py:10] start gpu_sexperts
DEBUG 01-14 20:42:41.335975.335975 cuda_h.py:19] end gpu_sexperts cost 0.0002796649932861328 seconds
DEBUG 01-14 20:42:41.335182.335182 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-14 20:42:41.335316.335316 lmp.py:1683] 
DEBUG 01-14 20:42:41.335316.335316 lmp.py:1683]   Computing 32 experts on CPU...
DEBUG 01-14 20:42:41.335529.335529 cuda_h.py:19] end cpu_experts_submit cost 5.14984130859375e-05 seconds
DEBUG 01-14 20:42:41.335371.335371 cuda_h.py:10] start experts_func_mgpu_group_pad
DEBUG 01-14 20:42:41.337398.337398 cuda_h.py:19] end experts_func_mgpu_group_pad cost 0.0015668869018554688 seconds
DEBUG 01-14 20:42:41.338704.338704 cuda_h.py:10] start gpu_group_list
DEBUG 01-14 20:42:41.338664.338664 cuda_h.py:19] end gpu_group_list cost 0.00032591819763183594 seconds
DEBUG 01-14 20:42:41.338450.338450 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-14 20:42:41.338855.338855 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 1.3828277587890625e-05 seconds
DEBUG 01-14 20:42:41.338982.338982 cuda_h.py:10] start wait_experts
INFO 01-14 20:42:41.338393.338393 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 390f74a0-d2ec-4416-bf31-49dfca43e5c1
DEBUG 01-14 20:42:41.339346.339346 mlpmodule.py:1367]  experts func einsum cost 0.2914245128631592 s
DEBUG 01-14 20:42:41.343292.343292 mlpmodule.py:1460] group tensors cost 0.0045893192291259766 s
DEBUG 01-14 20:42:41.344611.344611 cuda_h.py:10] start move_flat_hidden2cpu
DEBUG 01-14 20:42:41.350536.350536 cuda_h.py:19] end move_flat_hidden2cpu cost 0.005988121032714844 seconds
DEBUG 01-14 20:42:41.352484.352484 mlpmodule.py:1533] pad cost 0.0017366409301757812 s
DEBUG 01-14 20:42:41.352508.352508 mlpmodule.py:1539] create cpu tensor cost 3.6716461181640625e-05 s
DEBUG 01-14 20:42:41.354332.354332 mlpmodule.py:1544] move to cpu cost 0.002218484878540039 s
DEBUG 01-14 20:42:41.364704.364704 mlpmodule.py:1558] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-14 20:42:41.364227.364227 mlpmodule.py:1559] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-14 20:42:41.364177.364177 mlpmodule.py:1564] group_w3 first element: 0.000789642333984375
WARNING 01-14 20:42:41.365129.365129 mlpmodule.py:1574] start einsum2
DEBUG 01-14 20:42:41.382031.382031 mlpmodule.py:1584] group einsum cost 0.027331113815307617 s
DEBUG 01-14 20:42:41.383978.383978 mlpmodule.py:1593] cpy2cputensor cost 0.0007674694061279297 s
DEBUG 01-14 20:42:41.383298.383298 cuda_h.py:10] start move_outputs
DEBUG 01-14 20:42:41.385593.385593 cuda_h.py:19] end move_outputs cost 0.0026390552520751953 seconds
INFO 01-14 20:42:41.389638.389638 client.py:127] Model loaded
DEBUG 01-14 20:42:41.389092.389092 cuda_h.py:19] end wait_experts cost 0.05110502243041992 seconds
DEBUG 01-14 20:42:41.389331.389331 cuda_h.py:10] start gpu_experts
DEBUG 01-14 20:42:41.389048.389048 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-14 20:42:41.390851.390851 cuda_h.py:19] end wait_cetm_experts cost 0.0004191398620605469 seconds
DEBUG 01-14 20:42:41.390999.390999 cuda_h.py:10] start gpu_group_einsum_mp_multi_list
DEBUG 01-14 20:42:41.390424.390424 cuda_h.py:10] start gpu_group_tensor
DEBUG 01-14 20:42:41.390287.390287 cuda_h.py:19] end gpu_group_tensor cost 0.000217437744140625 seconds
DEBUG 01-14 20:42:41.390105.390105 cuda_h.py:10] start gpu_group_einsum
DEBUG 01-14 20:42:41.391395.391395 cuda_h.py:19] end gpu_group_einsum cost 0.0006871223449707031 seconds
DEBUG 01-14 20:42:41.391320.391320 cuda_h.py:10] start gpu_final_hidden_states_scatter
DEBUG 01-14 20:42:41.391793.391793 cuda_h.py:10] start all_expert_outputs_slices
DEBUG 01-14 20:42:41.392813.392813 cuda_h.py:19] end all_expert_outputs_slices cost 0.00036215782165527344 seconds
DEBUG 01-14 20:42:41.392384.392384 cuda_h.py:10] start concat_expert_out
DEBUG 01-14 20:42:41.392089.392089 cuda_h.py:19] end concat_expert_out cost 6.103515625e-05 seconds
DEBUG 01-14 20:42:41.392362.392362 cuda_h.py:10] start index_scatter
DEBUG 01-14 20:42:41.392949.392949 cuda_h.py:19] end index_scatter cost 5.698204040527344e-05 seconds
DEBUG 01-14 20:42:41.392235.392235 cuda_h.py:19] end gpu_final_hidden_states_scatter cost 0.0007641315460205078 seconds
DEBUG 01-14 20:42:41.392827.392827 cuda_h.py:19] end gpu_experts cost 0.0027244091033935547 seconds
DEBUG 01-14 20:42:41.392484.392484 cuda_h.py:10] start all_expert_weight_slices
DEBUG 01-14 20:42:41.393715.393715 cuda_h.py:19] end all_expert_weight_slices cost 0.0009469985961914062 seconds
DEBUG 01-14 20:42:41.393313.393313 cuda_h.py:10] start cpuoutputsdeal
DEBUG 01-14 20:42:41.394360.394360 cuda_h.py:10] start index_scatter
DEBUG 01-14 20:42:41.394748.394748 cuda_h.py:19] end index_scatter cost 4.9591064453125e-05 seconds
DEBUG 01-14 20:42:41.394610.394610 cuda_h.py:19] end cpuoutputsdeal cost 0.0005395412445068359 seconds
DEBUG 01-14 20:42:41.394428.394428 cuda_h.py:19] end layer_moe_generate_mp_l_15 cost 0.06935334205627441 seconds
DEBUG 01-14 20:42:41.394937.394937 cuda_h.py:19] end prefill_layer cost 0.07846283912658691 seconds
DEBUG 01-14 20:42:41.394488.394488 lmp.py:1551] -------------------------------- end prefill layer 14 --------------------------------
DEBUG 01-14 20:42:41.394906.394906 cuda_h.py:10] start prefill_layer
DEBUG 01-14 20:42:41.394801.394801 lmp.py:1494] -------------------------------- start prefill layer 15 --------------------------------
DEBUG 01-14 20:42:41.394743.394743 cuda_h.py:10] start start_load_qkvogn_s_weight_l_16
DEBUG 01-14 20:42:41.394830.394830 cuda_h.py:10] start start_load_qkvogn_s_weight_l_16
DEBUG 01-14 20:42:41.394242.394242 cuda_h.py:19] end start_load_qkvogn_s_weight_l_16 cost 3.0279159545898438e-05 seconds
DEBUG 01-14 20:42:41.394190.394190 cuda_h.py:19] end start_load_qkvogn_s_weight_l_16 cost 6.461143493652344e-05 seconds
DEBUG 01-14 20:42:41.394079.394079 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-14 20:42:41.395386.395386 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-14 20:42:41.395303.395303 cuda_h.py:10] start sllm_worker_task
DEBUG 01-14 20:42:41.395127.395127 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-14 20:42:41.395586.395586 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-14 20:42:41.395126.395126 cuda_h.py:19] end allocate_cuda_memory cost 0.0006756782531738281 seconds
DEBUG 01-14 20:42:41.396500.396500 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-14 20:42:41.396362.396362 sllm_store_c.py:27] get device uuid map
DEBUG 01-14 20:42:41.396291.396291 sllm_store_c.py:29] call client load into gpu
DEBUG 01-14 20:42:41.396001.396001 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 97d18565-31e3-4c92-a1e0-8938381a9bef
DEBUG 01-14 20:42:41.396137.396137 client.py:106] call stub.LoadModelAsync
DEBUG 01-14 20:42:41.396909.396909 cuda_h.py:10] start self_attn
INFO 01-14 20:42:41.397775.397775 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 97d18565-31e3-4c92-a1e0-8938381a9bef
DEBUG 01-14 20:42:41.397048.397048 cuda_h.py:19] end load_into_gpu_async cost 0.0011022090911865234 seconds
DEBUG 01-14 20:42:41.397957.397957 cuda_h.py:10] start restore_tensors2
DEBUG 01-14 20:42:41.397715.397715 cuda_h.py:19] end restore_tensors2 cost 7.414817810058594e-05 seconds
DEBUG 01-14 20:42:41.397948.397948 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.002153158187866211 seconds
INFO 01-14 20:42:41.397877.397877 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 97d18565-31e3-4c92-a1e0-8938381a9bef
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-14 20:42:41.399587.399587 cuda_h.py:19] end self_attn cost 0.0029518604278564453 seconds
DEBUG 01-14 20:42:41.399591.399591 cuda_h.py:19] end iln_self_attn_paln cost 0.00497889518737793 seconds
DEBUG 01-14 20:42:41.400672.400672 cuda_h.py:10] start layer_moe_generate_mp_l_16
DEBUG 01-14 20:42:41.400958.400958 cuda_h.py:10] start gate
DEBUG 01-14 20:42:41.400504.400504 cuda_h.py:19] end gate cost 0.00064849853515625 seconds
DEBUG 01-14 20:42:41.400056.400056 cuda_h.py:10] start experts_map_get
DEBUG 01-14 20:42:41.401232.401232 lmp.py:1615] 
DEBUG 01-14 20:42:41.401232.401232 lmp.py:1615] Expert Token Distribution & Device Allocation:
DEBUG 01-14 20:42:41.401756.401756 lmp.py:1616]   Total experts: 64
DEBUG 01-14 20:42:41.401836.401836 lmp.py:1617]   CPU experts: 32 (50%)
DEBUG 01-14 20:42:41.401625.401625 lmp.py:1618]   GPU experts: 32 (50%)
DEBUG 01-14 20:42:41.401791.401791 lmp.py:1619] 
DEBUG 01-14 20:42:41.401791.401791 lmp.py:1619]   Expert ID | Tokens | Device
DEBUG 01-14 20:42:41.401309.401309 lmp.py:1620]   -----------------------------------
DEBUG 01-14 20:42:41.401290.401290 lmp.py:1625]   Expert 20 |     72 | CPU
DEBUG 01-14 20:42:41.401886.401886 lmp.py:1625]   Expert  0 |     73 | CPU
DEBUG 01-14 20:42:41.401006.401006 lmp.py:1625]   Expert 15 |     80 | CPU
DEBUG 01-14 20:42:41.401887.401887 lmp.py:1625]   Expert 63 |     83 | CPU
DEBUG 01-14 20:42:41.401292.401292 lmp.py:1625]   Expert  7 |     84 | CPU
DEBUG 01-14 20:42:41.401458.401458 lmp.py:1625]   Expert 41 |     87 | CPU
DEBUG 01-14 20:42:41.401863.401863 lmp.py:1625]   Expert 52 |     89 | CPU
DEBUG 01-14 20:42:41.401221.401221 lmp.py:1625]   Expert 28 |     91 | CPU
DEBUG 01-14 20:42:41.401102.401102 lmp.py:1625]   Expert 45 |     93 | CPU
DEBUG 01-14 20:42:41.401984.401984 lmp.py:1625]   Expert 54 |    105 | CPU
DEBUG 01-14 20:42:41.401388.401388 lmp.py:1625]   Expert 12 |    112 | CPU
DEBUG 01-14 20:42:41.401793.401793 lmp.py:1625]   Expert 21 |    115 | CPU
DEBUG 01-14 20:42:41.401959.401959 lmp.py:1625]   Expert 59 |    119 | CPU
DEBUG 01-14 20:42:41.401125.401125 lmp.py:1625]   Expert 62 |    119 | CPU
DEBUG 01-14 20:42:41.401722.401722 lmp.py:1625]   Expert  5 |    127 | CPU
DEBUG 01-14 20:42:41.401842.401842 lmp.py:1625]   Expert 55 |    127 | CPU
DEBUG 01-14 20:42:41.401246.401246 lmp.py:1625]   Expert 14 |    142 | CPU
DEBUG 01-14 20:42:41.401412.401412 lmp.py:1625]   Expert 34 |    145 | CPU
DEBUG 01-14 20:42:41.401578.401578 lmp.py:1625]   Expert  4 |    146 | CPU
DEBUG 01-14 20:42:41.401983.401983 lmp.py:1625]   Expert 51 |    150 | CPU
DEBUG 01-14 20:42:41.401149.401149 lmp.py:1625]   Expert 13 |    152 | CPU
DEBUG 01-14 20:42:41.401315.401315 lmp.py:1625]   Expert 40 |    153 | CPU
DEBUG 01-14 20:42:41.401720.401720 lmp.py:1625]   Expert 61 |    155 | CPU
DEBUG 01-14 20:42:41.401363.401363 lmp.py:1625]   Expert  1 |    156 | CPU
DEBUG 01-14 20:42:41.401767.401767 lmp.py:1625]   Expert 16 |    163 | CPU
DEBUG 01-14 20:42:41.401933.401933 lmp.py:1625]   Expert 32 |    166 | CPU
DEBUG 01-14 20:42:41.401861.401861 lmp.py:1625]   Expert 10 |    169 | CPU
DEBUG 01-14 20:42:41.401027.401027 lmp.py:1625]   Expert 11 |    169 | CPU
DEBUG 01-14 20:42:41.401193.401193 lmp.py:1625]   Expert 42 |    169 | CPU
DEBUG 01-14 20:42:41.401360.401360 lmp.py:1625]   Expert  2 |    171 | CPU
DEBUG 01-14 20:42:41.401764.401764 lmp.py:1625]   Expert 22 |    171 | CPU
DEBUG 01-14 20:42:41.401692.401692 lmp.py:1625]   Expert  6 |    172 | CPU
DEBUG 01-14 20:42:41.401096.401096 lmp.py:1625]   Expert 44 |    172 | GPU
DEBUG 01-14 20:42:41.401501.401501 lmp.py:1625]   Expert 30 |    181 | GPU
DEBUG 01-14 20:42:41.401667.401667 lmp.py:1625]   Expert 19 |    182 | GPU
DEBUG 01-14 20:42:41.401833.401833 lmp.py:1625]   Expert 25 |    182 | GPU
DEBUG 01-14 20:42:41.401999.401999 lmp.py:1625]   Expert 35 |    184 | GPU
DEBUG 01-14 20:42:41.401927.401927 lmp.py:1625]   Expert 56 |    185 | GPU
DEBUG 01-14 20:42:41.401093.401093 lmp.py:1625]   Expert 53 |    187 | GPU
DEBUG 01-14 20:42:41.401213.401213 lmp.py:1625]   Expert 26 |    191 | GPU
DEBUG 01-14 20:42:41.401379.401379 lmp.py:1625]   Expert 47 |    191 | GPU
DEBUG 01-14 20:42:41.401545.401545 lmp.py:1625]   Expert 24 |    197 | GPU
DEBUG 01-14 20:42:41.401473.401473 lmp.py:1625]   Expert 57 |    204 | GPU
DEBUG 01-14 20:42:41.402162.402162 lmp.py:1625]   Expert 50 |    220 | GPU
DEBUG 01-14 20:42:41.402090.402090 lmp.py:1625]   Expert 48 |    221 | GPU
DEBUG 01-14 20:42:41.402018.402018 lmp.py:1625]   Expert 46 |    227 | GPU
DEBUG 01-14 20:42:41.402661.402661 lmp.py:1625]   Expert 18 |    235 | GPU
DEBUG 01-14 20:42:41.402065.402065 lmp.py:1625]   Expert 37 |    235 | GPU
DEBUG 01-14 20:42:41.402231.402231 lmp.py:1625]   Expert  3 |    238 | GPU
DEBUG 01-14 20:42:41.402398.402398 lmp.py:1625]   Expert 39 |    239 | GPU
DEBUG 01-14 20:42:41.402802.402802 lmp.py:1625]   Expert 29 |    252 | GPU
DEBUG 01-14 20:42:41.402968.402968 lmp.py:1625]   Expert 60 |    253 | GPU
DEBUG 01-14 20:42:41.402896.402896 lmp.py:1625]   Expert 31 |    258 | GPU
DEBUG 01-14 20:42:41.402062.402062 lmp.py:1625]   Expert 36 |    259 | GPU
DEBUG 01-14 20:42:41.402467.402467 lmp.py:1625]   Expert 17 |    260 | GPU
DEBUG 01-14 20:42:41.402871.402871 lmp.py:1625]   Expert 23 |    260 | GPU
DEBUG 01-14 20:42:41.402037.402037 lmp.py:1625]   Expert 38 |    265 | GPU
DEBUG 01-14 20:42:41.402204.402204 lmp.py:1625]   Expert  9 |    271 | GPU
DEBUG 01-14 20:42:41.402370.402370 lmp.py:1625]   Expert  8 |    293 | GPU
DEBUG 01-14 20:42:41.402536.402536 lmp.py:1625]   Expert 27 |    330 | GPU
DEBUG 01-14 20:42:41.402987.402987 lmp.py:1625]   Expert 43 |    371 | GPU
DEBUG 01-14 20:42:41.402914.402914 lmp.py:1625]   Expert 33 |    414 | GPU
DEBUG 01-14 20:42:41.402842.402842 lmp.py:1625]   Expert 58 |    479 | GPU
DEBUG 01-14 20:42:41.402485.402485 lmp.py:1625]   Expert 49 |    527 | GPU
DEBUG 01-14 20:42:41.402082.402082 lmp.py:1626] 
DEBUG 01-14 20:42:41.402082.402082 lmp.py:1626]   CPU total tokens: 4125 (33.6%)
DEBUG 01-14 20:42:41.402917.402917 lmp.py:1627]   GPU total tokens: 8163 (66.4%)
DEBUG 01-14 20:42:41.402282.402282 cuda_h.py:19] end experts_map_get cost 0.0015766620635986328 seconds
DEBUG 01-14 20:42:41.402152.402152 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-14 20:42:41.402479.402479 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-14 20:42:41.402762.402762 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-14 20:42:41.407978.407978 cuda_h.py:19] end allocate_cuda_memory cost 0.004654645919799805 seconds
DEBUG 01-14 20:42:41.407372.407372 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-14 20:42:41.407512.407512 sllm_store_c.py:27] get device uuid map
DEBUG 01-14 20:42:41.407441.407441 sllm_store_c.py:29] call client load into gpu
DEBUG 01-14 20:42:41.407951.407951 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 4b8a5b4a-fa34-4e63-ba9e-606878381a11
DEBUG 01-14 20:42:41.407177.407177 client.py:106] call stub.LoadModelAsync
DEBUG 01-14 20:42:41.407784.407784 mlpmodule.py:1367]  experts func einsum cost 0.06872320175170898 s
INFO 01-14 20:42:41.408113.408113 client.py:127] Model loaded
DEBUG 01-14 20:42:41.408327.408327 cuda_h.py:10] start restore2model
DEBUG 01-14 20:42:41.408359.408359 cuda_h.py:19] end restore2model cost 0.0003376007080078125 seconds
DEBUG 01-14 20:42:41.408652.408652 cuda_h.py:19] end sllm_worker_task cost 0.013314962387084961 seconds
INFO 01-14 20:42:41.408240.408240 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 4b8a5b4a-fa34-4e63-ba9e-606878381a11
DEBUG 01-14 20:42:41.408275.408275 cuda_h.py:19] end load_into_gpu_async cost 0.0014379024505615234 seconds
DEBUG 01-14 20:42:41.408501.408501 cuda_h.py:10] start restore_tensors2
DEBUG 01-14 20:42:41.409177.409177 cuda_h.py:19] end restore_tensors2 cost 0.0003662109375 seconds
DEBUG 01-14 20:42:41.409728.409728 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.006830692291259766 seconds
DEBUG 01-14 20:42:41.409067.409067 cuda_h.py:10] start restore2model
DEBUG 01-14 20:42:41.412108.412108 cuda_h.py:19] end restore2model cost 0.0025653839111328125 seconds
DEBUG 01-14 20:42:41.412752.412752 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.009574651718139648 seconds
DEBUG 01-14 20:42:41.412786.412786 cuda_h.py:10] start gpu_sexperts
DEBUG 01-14 20:42:41.412857.412857 cuda_h.py:19] end gpu_sexperts cost 0.0003018379211425781 seconds
DEBUG 01-14 20:42:41.412063.412063 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-14 20:42:41.412151.412151 lmp.py:1683] 
DEBUG 01-14 20:42:41.412151.412151 lmp.py:1683]   Computing 32 experts on CPU...
DEBUG 01-14 20:42:41.412987.412987 cuda_h.py:19] end cpu_experts_submit cost 5.507469177246094e-05 seconds
DEBUG 01-14 20:42:41.412928.412928 cuda_h.py:10] start experts_func_mgpu_group_pad
DEBUG 01-14 20:42:41.417586.417586 mlpmodule.py:1460] group tensors cost 0.004734039306640625 s
DEBUG 01-14 20:42:41.418469.418469 cuda_h.py:10] start move_flat_hidden2cpu
DEBUG 01-14 20:42:41.420754.420754 cuda_h.py:19] end experts_func_mgpu_group_pad cost 0.00741887092590332 seconds
DEBUG 01-14 20:42:41.421936.421936 cuda_h.py:10] start gpu_group_list
DEBUG 01-14 20:42:41.421622.421622 cuda_h.py:19] end gpu_group_list cost 0.0004305839538574219 seconds
DEBUG 01-14 20:42:41.422793.422793 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-14 20:42:41.422836.422836 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 1.7881393432617188e-05 seconds
DEBUG 01-14 20:42:41.422361.422361 cuda_h.py:10] start wait_experts
INFO 01-14 20:42:41.422448.422448 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 4b8a5b4a-fa34-4e63-ba9e-606878381a11
DEBUG 01-14 20:42:41.424761.424761 cuda_h.py:19] end move_flat_hidden2cpu cost 0.006293296813964844 seconds
DEBUG 01-14 20:42:41.426054.426054 mlpmodule.py:1533] pad cost 0.0017364025115966797 s
DEBUG 01-14 20:42:41.426905.426905 mlpmodule.py:1539] create cpu tensor cost 3.933906555175781e-05 s
DEBUG 01-14 20:42:41.428001.428001 mlpmodule.py:1544] move to cpu cost 0.002032756805419922 s
DEBUG 01-14 20:42:41.437538.437538 mlpmodule.py:1558] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-14 20:42:41.438061.438061 mlpmodule.py:1559] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-14 20:42:41.438680.438680 mlpmodule.py:1564] group_w3 first element: -0.0595703125
WARNING 01-14 20:42:41.438426.438426 mlpmodule.py:1574] start einsum2
DEBUG 01-14 20:42:41.454810.454810 mlpmodule.py:1584] group einsum cost 0.02624988555908203 s
DEBUG 01-14 20:42:41.455643.455643 mlpmodule.py:1593] cpy2cputensor cost 0.0007200241088867188 s
DEBUG 01-14 20:42:41.455009.455009 cuda_h.py:10] start move_outputs
DEBUG 01-14 20:42:41.458035.458035 cuda_h.py:19] end move_outputs cost 0.0029342174530029297 seconds
INFO 01-14 20:42:41.466908.466908 client.py:127] Model loaded
DEBUG 01-14 20:42:41.466302.466302 cuda_h.py:19] end wait_experts cost 0.04409480094909668 seconds
DEBUG 01-14 20:42:41.466727.466727 cuda_h.py:10] start gpu_experts
DEBUG 01-14 20:42:41.466867.466867 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-14 20:42:41.466692.466692 cuda_h.py:19] end wait_cetm_experts cost 8.153915405273438e-05 seconds
DEBUG 01-14 20:42:41.466449.466449 cuda_h.py:10] start gpu_group_einsum_mp_multi_list
DEBUG 01-14 20:42:41.466397.466397 cuda_h.py:10] start gpu_group_tensor
DEBUG 01-14 20:42:41.466624.466624 cuda_h.py:19] end gpu_group_tensor cost 0.00020599365234375 seconds
DEBUG 01-14 20:42:41.466389.466389 cuda_h.py:10] start gpu_group_einsum
DEBUG 01-14 20:42:41.467361.467361 cuda_h.py:19] end gpu_group_einsum cost 0.0004951953887939453 seconds
DEBUG 01-14 20:42:41.467762.467762 cuda_h.py:10] start gpu_final_hidden_states_scatter
DEBUG 01-14 20:42:41.467552.467552 cuda_h.py:10] start all_expert_outputs_slices
DEBUG 01-14 20:42:41.467814.467814 cuda_h.py:19] end all_expert_outputs_slices cost 0.0002677440643310547 seconds
DEBUG 01-14 20:42:41.467616.467616 cuda_h.py:10] start concat_expert_out
DEBUG 01-14 20:42:41.468308.468308 cuda_h.py:19] end concat_expert_out cost 5.793571472167969e-05 seconds
DEBUG 01-14 20:42:41.468290.468290 cuda_h.py:10] start index_scatter
DEBUG 01-14 20:42:41.468551.468551 cuda_h.py:19] end index_scatter cost 5.2928924560546875e-05 seconds
DEBUG 01-14 20:42:41.468168.468168 cuda_h.py:19] end gpu_final_hidden_states_scatter cost 0.0006082057952880859 seconds
DEBUG 01-14 20:42:41.468084.468084 cuda_h.py:19] end gpu_experts cost 0.0019571781158447266 seconds
DEBUG 01-14 20:42:41.468947.468947 cuda_h.py:10] start all_expert_weight_slices
DEBUG 01-14 20:42:41.469589.469589 cuda_h.py:19] end all_expert_weight_slices cost 0.0009686946868896484 seconds
DEBUG 01-14 20:42:41.469412.469412 cuda_h.py:10] start cpuoutputsdeal
DEBUG 01-14 20:42:41.469089.469089 cuda_h.py:10] start index_scatter
DEBUG 01-14 20:42:41.469986.469986 cuda_h.py:19] end index_scatter cost 5.125999450683594e-05 seconds
DEBUG 01-14 20:42:41.469656.469656 cuda_h.py:19] end cpuoutputsdeal cost 0.0005373954772949219 seconds
DEBUG 01-14 20:42:41.470612.470612 cuda_h.py:19] end layer_moe_generate_mp_l_16 cost 0.06997299194335938 seconds
DEBUG 01-14 20:42:41.470837.470837 cuda_h.py:19] end prefill_layer cost 0.07561802864074707 seconds
DEBUG 01-14 20:42:41.470196.470196 lmp.py:1551] -------------------------------- end prefill layer 15 --------------------------------
DEBUG 01-14 20:42:41.470561.470561 cuda_h.py:10] start prefill_layer
DEBUG 01-14 20:42:41.470165.470165 lmp.py:1494] -------------------------------- start prefill layer 16 --------------------------------
DEBUG 01-14 20:42:41.470768.470768 cuda_h.py:10] start start_load_qkvogn_s_weight_l_17
DEBUG 01-14 20:42:41.470802.470802 cuda_h.py:10] start start_load_qkvogn_s_weight_l_17
DEBUG 01-14 20:42:41.470354.470354 cuda_h.py:19] end start_load_qkvogn_s_weight_l_17 cost 3.123283386230469e-05 seconds
DEBUG 01-14 20:42:41.470726.470726 cuda_h.py:19] end start_load_qkvogn_s_weight_l_17 cost 6.29425048828125e-05 seconds
DEBUG 01-14 20:42:41.470753.470753 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-14 20:42:41.470093.470093 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-14 20:42:41.470519.470519 cuda_h.py:10] start sllm_worker_task
DEBUG 01-14 20:42:41.470614.470614 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-14 20:42:41.470252.470252 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-14 20:42:41.473188.473188 cuda_h.py:19] end allocate_cuda_memory cost 0.0026197433471679688 seconds
DEBUG 01-14 20:42:41.473091.473091 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-14 20:42:41.473278.473278 sllm_store_c.py:27] get device uuid map
DEBUG 01-14 20:42:41.473021.473021 sllm_store_c.py:29] call client load into gpu
DEBUG 01-14 20:42:41.473439.473439 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 53acb3b4-9ec6-43d4-b769-3af5455bf78a
DEBUG 01-14 20:42:41.473886.473886 client.py:106] call stub.LoadModelAsync
DEBUG 01-14 20:42:41.474692.474692 cuda_h.py:10] start self_attn
INFO 01-14 20:42:41.475524.475524 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 53acb3b4-9ec6-43d4-b769-3af5455bf78a
DEBUG 01-14 20:42:41.475883.475883 cuda_h.py:19] end load_into_gpu_async cost 0.0014636516571044922 seconds
DEBUG 01-14 20:42:41.475679.475679 cuda_h.py:10] start restore_tensors2
DEBUG 01-14 20:42:41.475708.475708 cuda_h.py:19] end restore_tensors2 cost 6.580352783203125e-05 seconds
DEBUG 01-14 20:42:41.475510.475510 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.004388093948364258 seconds
INFO 01-14 20:42:41.475168.475168 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 53acb3b4-9ec6-43d4-b769-3af5455bf78a
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-14 20:42:41.477148.477148 cuda_h.py:19] end self_attn cost 0.002846956253051758 seconds
DEBUG 01-14 20:42:41.477111.477111 cuda_h.py:19] end iln_self_attn_paln cost 0.0067310333251953125 seconds
DEBUG 01-14 20:42:41.477239.477239 cuda_h.py:10] start layer_moe_generate_mp_l_17
DEBUG 01-14 20:42:41.477764.477764 cuda_h.py:10] start gate
DEBUG 01-14 20:42:41.478740.478740 cuda_h.py:19] end gate cost 0.0006501674652099609 seconds
DEBUG 01-14 20:42:41.478523.478523 cuda_h.py:10] start experts_map_get
DEBUG 01-14 20:42:41.478368.478368 lmp.py:1615] 
DEBUG 01-14 20:42:41.478368.478368 lmp.py:1615] Expert Token Distribution & Device Allocation:
DEBUG 01-14 20:42:41.478647.478647 lmp.py:1616]   Total experts: 64
DEBUG 01-14 20:42:41.478297.478297 lmp.py:1617]   CPU experts: 32 (50%)
DEBUG 01-14 20:42:41.478132.478132 lmp.py:1618]   GPU experts: 32 (50%)
DEBUG 01-14 20:42:41.478298.478298 lmp.py:1619] 
DEBUG 01-14 20:42:41.478298.478298 lmp.py:1619]   Expert ID | Tokens | Device
DEBUG 01-14 20:42:41.478372.478372 lmp.py:1620]   -----------------------------------
DEBUG 01-14 20:42:41.478684.478684 lmp.py:1625]   Expert 45 |     49 | CPU
DEBUG 01-14 20:42:41.478426.478426 lmp.py:1625]   Expert 58 |     52 | CPU
DEBUG 01-14 20:42:41.478453.478453 lmp.py:1625]   Expert 49 |     66 | CPU
DEBUG 01-14 20:42:41.478335.478335 lmp.py:1625]   Expert 38 |     68 | CPU
DEBUG 01-14 20:42:41.478978.478978 lmp.py:1625]   Expert  4 |     70 | CPU
DEBUG 01-14 20:42:41.478144.478144 lmp.py:1625]   Expert 31 |     70 | CPU
DEBUG 01-14 20:42:41.478548.478548 lmp.py:1625]   Expert 43 |     76 | CPU
DEBUG 01-14 20:42:41.478476.478476 lmp.py:1625]   Expert 47 |     77 | CPU
DEBUG 01-14 20:42:41.478165.478165 lmp.py:1625]   Expert 41 |     81 | CPU
DEBUG 01-14 20:42:41.478331.478331 lmp.py:1625]   Expert  0 |     94 | CPU
DEBUG 01-14 20:42:41.478259.478259 lmp.py:1625]   Expert 14 |     94 | CPU
DEBUG 01-14 20:42:41.478379.478379 lmp.py:1625]   Expert 57 |     97 | CPU
DEBUG 01-14 20:42:41.478784.478784 lmp.py:1625]   Expert 51 |    100 | CPU
DEBUG 01-14 20:42:41.478711.478711 lmp.py:1625]   Expert 11 |    112 | CPU
DEBUG 01-14 20:42:41.478401.478401 lmp.py:1625]   Expert 26 |    114 | CPU
DEBUG 01-14 20:42:41.478567.478567 lmp.py:1625]   Expert 33 |    114 | CPU
DEBUG 01-14 20:42:41.478018.478018 lmp.py:1625]   Expert  2 |    116 | CPU
DEBUG 01-14 20:42:41.478184.478184 lmp.py:1625]   Expert 50 |    117 | CPU
DEBUG 01-14 20:42:41.479111.479111 lmp.py:1625]   Expert 27 |    129 | CPU
DEBUG 01-14 20:42:41.479039.479039 lmp.py:1625]   Expert 55 |    129 | CPU
DEBUG 01-14 20:42:41.479490.479490 lmp.py:1625]   Expert 34 |    151 | CPU
DEBUG 01-14 20:42:41.479371.479371 lmp.py:1625]   Expert 28 |    154 | CPU
DEBUG 01-14 20:42:41.479776.479776 lmp.py:1625]   Expert 25 |    159 | CPU
DEBUG 01-14 20:42:41.479942.479942 lmp.py:1625]   Expert  9 |    169 | CPU
DEBUG 01-14 20:42:41.479631.479631 lmp.py:1625]   Expert 13 |    171 | CPU
DEBUG 01-14 20:42:41.479559.479559 lmp.py:1625]   Expert 56 |    178 | CPU
DEBUG 01-14 20:42:41.479010.479010 lmp.py:1625]   Expert 54 |    180 | CPU
DEBUG 01-14 20:42:41.479938.479938 lmp.py:1625]   Expert 48 |    181 | CPU
DEBUG 01-14 20:42:41.479627.479627 lmp.py:1625]   Expert  6 |    182 | CPU
DEBUG 01-14 20:42:41.479793.479793 lmp.py:1625]   Expert  7 |    187 | CPU
DEBUG 01-14 20:42:41.479959.479959 lmp.py:1625]   Expert 10 |    190 | CPU
DEBUG 01-14 20:42:41.479125.479125 lmp.py:1625]   Expert 46 |    196 | CPU
DEBUG 01-14 20:42:41.479053.479053 lmp.py:1625]   Expert 24 |    198 | GPU
DEBUG 01-14 20:42:41.479219.479219 lmp.py:1625]   Expert 61 |    199 | GPU
DEBUG 01-14 20:42:41.479670.479670 lmp.py:1625]   Expert 29 |    201 | GPU
DEBUG 01-14 20:42:41.479598.479598 lmp.py:1625]   Expert 40 |    206 | GPU
DEBUG 01-14 20:42:41.479049.479049 lmp.py:1625]   Expert 63 |    209 | GPU
DEBUG 01-14 20:42:41.479738.479738 lmp.py:1625]   Expert 18 |    217 | GPU
DEBUG 01-14 20:42:41.479427.479427 lmp.py:1625]   Expert 42 |    218 | GPU
DEBUG 01-14 20:42:41.479640.479640 lmp.py:1625]   Expert 21 |    219 | GPU
DEBUG 01-14 20:42:41.479329.479329 lmp.py:1625]   Expert 22 |    222 | GPU
DEBUG 01-14 20:42:41.479734.479734 lmp.py:1625]   Expert  1 |    223 | GPU
DEBUG 01-14 20:42:41.479423.479423 lmp.py:1625]   Expert 12 |    224 | GPU
DEBUG 01-14 20:42:41.479112.479112 lmp.py:1625]   Expert 16 |    231 | GPU
DEBUG 01-14 20:42:41.479802.479802 lmp.py:1625]   Expert 32 |    231 | GPU
DEBUG 01-14 20:42:41.479252.479252 lmp.py:1625]   Expert  3 |    232 | GPU
DEBUG 01-14 20:42:41.479942.479942 lmp.py:1625]   Expert 39 |    233 | GPU
DEBUG 01-14 20:42:41.479631.479631 lmp.py:1625]   Expert 19 |    237 | GPU
DEBUG 01-14 20:42:41.479036.479036 lmp.py:1625]   Expert 36 |    240 | GPU
DEBUG 01-14 20:42:41.479917.479917 lmp.py:1625]   Expert 59 |    243 | GPU
DEBUG 01-14 20:42:41.479845.479845 lmp.py:1625]   Expert 37 |    252 | GPU
DEBUG 01-14 20:42:41.479772.479772 lmp.py:1625]   Expert  5 |    253 | GPU
DEBUG 01-14 20:42:41.479700.479700 lmp.py:1625]   Expert  8 |    254 | GPU
DEBUG 01-14 20:42:41.479389.479389 lmp.py:1625]   Expert 20 |    257 | GPU
DEBUG 01-14 20:42:41.479840.479840 lmp.py:1625]   Expert 30 |    275 | GPU
DEBUG 01-14 20:42:41.479530.479530 lmp.py:1625]   Expert 62 |    288 | GPU
DEBUG 01-14 20:42:41.479742.479742 lmp.py:1625]   Expert 15 |    295 | GPU
DEBUG 01-14 20:42:41.479908.479908 lmp.py:1625]   Expert 35 |    301 | GPU
DEBUG 01-14 20:42:41.479074.479074 lmp.py:1625]   Expert 17 |    309 | GPU
DEBUG 01-14 20:42:41.479764.479764 lmp.py:1625]   Expert 60 |    338 | GPU
DEBUG 01-14 20:42:41.479215.479215 lmp.py:1625]   Expert 23 |    355 | GPU
DEBUG 01-14 20:42:41.479665.479665 lmp.py:1625]   Expert 52 |    368 | GPU
DEBUG 01-14 20:42:41.479355.479355 lmp.py:1625]   Expert 44 |    398 | GPU
DEBUG 01-14 20:42:41.479567.479567 lmp.py:1625]   Expert 53 |    439 | GPU
DEBUG 01-14 20:42:41.479972.479972 lmp.py:1626] 
DEBUG 01-14 20:42:41.479972.479972 lmp.py:1626]   CPU total tokens: 3923 (31.9%)
DEBUG 01-14 20:42:41.479330.479330 lmp.py:1627]   GPU total tokens: 8365 (68.1%)
DEBUG 01-14 20:42:41.479980.479980 cuda_h.py:19] end experts_map_get cost 0.0015361309051513672 seconds
DEBUG 01-14 20:42:41.479267.479267 mlpmodule.py:1367]  experts func einsum cost 0.06702041625976562 s
DEBUG 01-14 20:42:41.479389.479389 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-14 20:42:41.480206.480206 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-14 20:42:41.480450.480450 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-14 20:42:41.480027.480027 cuda_h.py:19] end allocate_cuda_memory cost 0.0003910064697265625 seconds
DEBUG 01-14 20:42:41.480830.480830 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-14 20:42:41.480825.480825 sllm_store_c.py:27] get device uuid map
DEBUG 01-14 20:42:41.480395.480395 sllm_store_c.py:29] call client load into gpu
DEBUG 01-14 20:42:41.480290.480290 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, e61de1e8-6b9f-45d2-bd82-42833026a330
DEBUG 01-14 20:42:41.480270.480270 client.py:106] call stub.LoadModelAsync
INFO 01-14 20:42:41.483612.483612 client.py:127] Model loaded
DEBUG 01-14 20:42:41.483444.483444 cuda_h.py:10] start restore2model
DEBUG 01-14 20:42:41.484536.484536 cuda_h.py:19] end restore2model cost 0.0006954669952392578 seconds
INFO 01-14 20:42:41.484605.484605 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, e61de1e8-6b9f-45d2-bd82-42833026a330
DEBUG 01-14 20:42:41.484938.484938 cuda_h.py:19] end sllm_worker_task cost 0.013442516326904297 seconds
DEBUG 01-14 20:42:41.484795.484795 cuda_h.py:19] end load_into_gpu_async cost 0.0036590099334716797 seconds
DEBUG 01-14 20:42:41.484658.484658 cuda_h.py:10] start restore_tensors2
DEBUG 01-14 20:42:41.484360.484360 cuda_h.py:19] end restore_tensors2 cost 0.0003478527069091797 seconds
DEBUG 01-14 20:42:41.484911.484911 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.004814624786376953 seconds
DEBUG 01-14 20:42:41.484250.484250 cuda_h.py:10] start restore2model
DEBUG 01-14 20:42:41.487999.487999 cuda_h.py:19] end restore2model cost 0.002560138702392578 seconds
DEBUG 01-14 20:42:41.487167.487167 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.0075528621673583984 seconds
DEBUG 01-14 20:42:41.487485.487485 cuda_h.py:10] start gpu_sexperts
DEBUG 01-14 20:42:41.487628.487628 cuda_h.py:19] end gpu_sexperts cost 0.00028514862060546875 seconds
DEBUG 01-14 20:42:41.487120.487120 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-14 20:42:41.488730.488730 lmp.py:1683] 
DEBUG 01-14 20:42:41.488730.488730 lmp.py:1683]   Computing 32 experts on CPU...
DEBUG 01-14 20:42:41.488235.488235 cuda_h.py:19] end cpu_experts_submit cost 5.626678466796875e-05 seconds
DEBUG 01-14 20:42:41.488746.488746 cuda_h.py:10] start experts_func_mgpu_group_pad
DEBUG 01-14 20:42:41.498575.498575 mlpmodule.py:1460] group tensors cost 0.010042905807495117 s
DEBUG 01-14 20:42:41.499074.499074 cuda_h.py:10] start move_flat_hidden2cpu
DEBUG 01-14 20:42:41.500842.500842 cuda_h.py:19] end experts_func_mgpu_group_pad cost 0.012709379196166992 seconds
DEBUG 01-14 20:42:41.502920.502920 cuda_h.py:10] start gpu_group_list
DEBUG 01-14 20:42:41.503876.503876 cuda_h.py:19] end gpu_group_list cost 0.0005581378936767578 seconds
DEBUG 01-14 20:42:41.503936.503936 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-14 20:42:41.503105.503105 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.0503997802734375e-05 seconds
DEBUG 01-14 20:42:41.503398.503398 cuda_h.py:10] start wait_experts
INFO 01-14 20:42:41.503545.503545 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, e61de1e8-6b9f-45d2-bd82-42833026a330
DEBUG 01-14 20:42:41.506543.506543 cuda_h.py:19] end move_flat_hidden2cpu cost 0.0070247650146484375 seconds
DEBUG 01-14 20:42:41.508089.508089 mlpmodule.py:1533] pad cost 0.0017473697662353516 s
DEBUG 01-14 20:42:41.508178.508178 mlpmodule.py:1539] create cpu tensor cost 3.838539123535156e-05 s
DEBUG 01-14 20:42:41.510846.510846 mlpmodule.py:1544] move to cpu cost 0.002314329147338867 s
DEBUG 01-14 20:42:41.520303.520303 mlpmodule.py:1558] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-14 20:42:41.520249.520249 mlpmodule.py:1559] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-14 20:42:41.520324.520324 mlpmodule.py:1564] group_w3 first element: -0.02490234375
WARNING 01-14 20:42:41.520998.520998 mlpmodule.py:1574] start einsum2
DEBUG 01-14 20:42:41.539723.539723 mlpmodule.py:1584] group einsum cost 0.02826857566833496 s
INFO 01-14 20:42:41.539779.539779 client.py:127] Model loaded
DEBUG 01-14 20:42:41.539765.539765 cuda_h.py:19] end wait_experts cost 0.036039113998413086 seconds
DEBUG 01-14 20:42:41.539740.539740 cuda_h.py:10] start gpu_experts
DEBUG 01-14 20:42:41.539155.539155 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-14 20:42:41.540346.540346 mlpmodule.py:1593] cpy2cputensor cost 0.0007781982421875 s
DEBUG 01-14 20:42:41.540818.540818 cuda_h.py:10] start move_outputs
DEBUG 01-14 20:42:41.542784.542784 cuda_h.py:19] end move_outputs cost 0.002292156219482422 seconds
DEBUG 01-14 20:42:41.546404.546404 cuda_h.py:19] end wait_cetm_experts cost 0.00678253173828125 seconds
DEBUG 01-14 20:42:41.546381.546381 cuda_h.py:10] start gpu_group_einsum_mp_multi_list
DEBUG 01-14 20:42:41.546667.546667 cuda_h.py:10] start gpu_group_tensor
DEBUG 01-14 20:42:41.546284.546284 cuda_h.py:19] end gpu_group_tensor cost 0.0002129077911376953 seconds
DEBUG 01-14 20:42:41.546049.546049 cuda_h.py:10] start gpu_group_einsum
DEBUG 01-14 20:42:41.547141.547141 cuda_h.py:19] end gpu_group_einsum cost 0.0005121231079101562 seconds
DEBUG 01-14 20:42:41.547774.547774 cuda_h.py:10] start gpu_final_hidden_states_scatter
DEBUG 01-14 20:42:41.547418.547418 cuda_h.py:10] start all_expert_outputs_slices
DEBUG 01-14 20:42:41.548488.548488 cuda_h.py:19] end all_expert_outputs_slices cost 0.0002665519714355469 seconds
DEBUG 01-14 20:42:41.548575.548575 cuda_h.py:10] start concat_expert_out
DEBUG 01-14 20:42:41.548843.548843 cuda_h.py:19] end concat_expert_out cost 5.6743621826171875e-05 seconds
DEBUG 01-14 20:42:41.548540.548540 cuda_h.py:10] start index_scatter
DEBUG 01-14 20:42:41.548417.548417 cuda_h.py:19] end index_scatter cost 5.221366882324219e-05 seconds
DEBUG 01-14 20:42:41.548557.548557 cuda_h.py:19] end gpu_final_hidden_states_scatter cost 0.0006077289581298828 seconds
DEBUG 01-14 20:42:41.548813.548813 cuda_h.py:19] end gpu_experts cost 0.008795738220214844 seconds
DEBUG 01-14 20:42:41.548615.548615 cuda_h.py:10] start all_expert_weight_slices
DEBUG 01-14 20:42:41.549681.549681 cuda_h.py:19] end all_expert_weight_slices cost 0.0009298324584960938 seconds
DEBUG 01-14 20:42:41.549457.549457 cuda_h.py:10] start cpuoutputsdeal
DEBUG 01-14 20:42:41.549657.549657 cuda_h.py:10] start index_scatter
DEBUG 01-14 20:42:41.549792.549792 cuda_h.py:19] end index_scatter cost 4.935264587402344e-05 seconds
DEBUG 01-14 20:42:41.550463.550463 cuda_h.py:19] end cpuoutputsdeal cost 0.0005366802215576172 seconds
DEBUG 01-14 20:42:41.550657.550657 cuda_h.py:19] end layer_moe_generate_mp_l_17 cost 0.07257199287414551 seconds
DEBUG 01-14 20:42:41.550749.550749 cuda_h.py:19] end prefill_layer cost 0.07994532585144043 seconds
DEBUG 01-14 20:42:41.550155.550155 lmp.py:1551] -------------------------------- end prefill layer 16 --------------------------------
DEBUG 01-14 20:42:41.550858.550858 cuda_h.py:10] start prefill_layer
DEBUG 01-14 20:42:41.550276.550276 lmp.py:1494] -------------------------------- start prefill layer 17 --------------------------------
DEBUG 01-14 20:42:41.550456.550456 cuda_h.py:10] start start_load_qkvogn_s_weight_l_18
DEBUG 01-14 20:42:41.550305.550305 cuda_h.py:10] start start_load_qkvogn_s_weight_l_18
DEBUG 01-14 20:42:41.550909.550909 cuda_h.py:19] end start_load_qkvogn_s_weight_l_18 cost 3.1948089599609375e-05 seconds
DEBUG 01-14 20:42:41.550427.550427 cuda_h.py:19] end start_load_qkvogn_s_weight_l_18 cost 6.4849853515625e-05 seconds
DEBUG 01-14 20:42:41.550507.550507 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-14 20:42:41.550834.550834 cuda_h.py:10] start sllm_worker_task
DEBUG 01-14 20:42:41.550309.550309 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-14 20:42:41.551847.551847 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-14 20:42:41.551745.551745 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-14 20:42:41.552421.552421 cuda_h.py:19] end allocate_cuda_memory cost 0.0009491443634033203 seconds
DEBUG 01-14 20:42:41.552476.552476 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-14 20:42:41.552431.552431 sllm_store_c.py:27] get device uuid map
DEBUG 01-14 20:42:41.552883.552883 sllm_store_c.py:29] call client load into gpu
DEBUG 01-14 20:42:41.552924.552924 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, fc80ba63-13a6-4c21-a55e-d63f6e9e64a6
DEBUG 01-14 20:42:41.552855.552855 client.py:106] call stub.LoadModelAsync
DEBUG 01-14 20:42:41.552861.552861 cuda_h.py:10] start self_attn
INFO 01-14 20:42:41.553704.553704 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, fc80ba63-13a6-4c21-a55e-d63f6e9e64a6
DEBUG 01-14 20:42:41.553879.553879 cuda_h.py:19] end load_into_gpu_async cost 0.0011014938354492188 seconds
DEBUG 01-14 20:42:41.553919.553919 cuda_h.py:10] start restore_tensors2
DEBUG 01-14 20:42:41.553115.553115 cuda_h.py:19] end restore_tensors2 cost 7.939338684082031e-05 seconds
DEBUG 01-14 20:42:41.553447.553447 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0024039745330810547 seconds
INFO 01-14 20:42:41.553290.553290 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, fc80ba63-13a6-4c21-a55e-d63f6e9e64a6
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-14 20:42:41.556441.556441 cuda_h.py:19] end self_attn cost 0.0032320022583007812 seconds
DEBUG 01-14 20:42:41.556837.556837 cuda_h.py:19] end iln_self_attn_paln cost 0.00565028190612793 seconds
DEBUG 01-14 20:42:41.556156.556156 cuda_h.py:10] start layer_moe_generate_mp_l_18
DEBUG 01-14 20:42:41.556681.556681 cuda_h.py:10] start gate
DEBUG 01-14 20:42:41.557829.557829 cuda_h.py:19] end gate cost 0.0006363391876220703 seconds
DEBUG 01-14 20:42:41.557374.557374 cuda_h.py:10] start experts_map_get
DEBUG 01-14 20:42:41.557881.557881 lmp.py:1615] 
DEBUG 01-14 20:42:41.557881.557881 lmp.py:1615] Expert Token Distribution & Device Allocation:
DEBUG 01-14 20:42:41.557160.557160 lmp.py:1616]   Total experts: 64
DEBUG 01-14 20:42:41.557286.557286 lmp.py:1617]   CPU experts: 32 (50%)
DEBUG 01-14 20:42:41.557075.557075 lmp.py:1618]   GPU experts: 32 (50%)
DEBUG 01-14 20:42:41.557957.557957 lmp.py:1619] 
DEBUG 01-14 20:42:41.557957.557957 lmp.py:1619]   Expert ID | Tokens | Device
DEBUG 01-14 20:42:41.557600.557600 lmp.py:1620]   -----------------------------------
DEBUG 01-14 20:42:41.557196.557196 lmp.py:1625]   Expert  4 |     14 | CPU
DEBUG 01-14 20:42:41.557177.557177 lmp.py:1625]   Expert 28 |     39 | CPU
DEBUG 01-14 20:42:41.557535.557535 lmp.py:1625]   Expert  7 |     42 | CPU
DEBUG 01-14 20:42:41.557940.557940 lmp.py:1625]   Expert 53 |     57 | CPU
DEBUG 01-14 20:42:41.557344.557344 lmp.py:1625]   Expert 52 |     73 | CPU
DEBUG 01-14 20:42:41.557034.557034 lmp.py:1625]   Expert 43 |     77 | CPU
DEBUG 01-14 20:42:41.557723.557723 lmp.py:1625]   Expert 49 |     82 | CPU
DEBUG 01-14 20:42:41.557558.557558 lmp.py:1625]   Expert 12 |     95 | CPU
DEBUG 01-14 20:42:41.557724.557724 lmp.py:1625]   Expert 60 |    100 | CPU
DEBUG 01-14 20:42:41.557129.557129 lmp.py:1625]   Expert 47 |    101 | CPU
DEBUG 01-14 20:42:41.557533.557533 lmp.py:1625]   Expert 15 |    102 | CPU
DEBUG 01-14 20:42:41.557653.557653 lmp.py:1625]   Expert  2 |    107 | CPU
DEBUG 01-14 20:42:41.557296.557296 lmp.py:1625]   Expert 33 |    108 | CPU
DEBUG 01-14 20:42:41.557939.557939 lmp.py:1625]   Expert 36 |    110 | CPU
DEBUG 01-14 20:42:41.557867.557867 lmp.py:1625]   Expert 50 |    115 | CPU
DEBUG 01-14 20:42:41.557271.557271 lmp.py:1625]   Expert  6 |    116 | CPU
DEBUG 01-14 20:42:41.557437.557437 lmp.py:1625]   Expert 59 |    116 | CPU
DEBUG 01-14 20:42:41.557127.557127 lmp.py:1625]   Expert 25 |    119 | CPU
DEBUG 01-14 20:42:41.558247.558247 lmp.py:1625]   Expert 24 |    123 | CPU
DEBUG 01-14 20:42:41.558651.558651 lmp.py:1625]   Expert 30 |    123 | CPU
DEBUG 01-14 20:42:41.558056.558056 lmp.py:1625]   Expert 39 |    124 | CPU
DEBUG 01-14 20:42:41.558983.558983 lmp.py:1625]   Expert  8 |    129 | CPU
DEBUG 01-14 20:42:41.558673.558673 lmp.py:1625]   Expert 27 |    132 | CPU
DEBUG 01-14 20:42:41.558839.558839 lmp.py:1625]   Expert  3 |    140 | CPU
DEBUG 01-14 20:42:41.558767.558767 lmp.py:1625]   Expert 10 |    144 | CPU
DEBUG 01-14 20:42:41.558456.558456 lmp.py:1625]   Expert 14 |    147 | CPU
DEBUG 01-14 20:42:41.558006.558006 lmp.py:1625]   Expert 37 |    152 | CPU
DEBUG 01-14 20:42:41.558126.558126 lmp.py:1625]   Expert 38 |    154 | CPU
DEBUG 01-14 20:42:41.558769.558769 lmp.py:1625]   Expert 32 |    155 | CPU
DEBUG 01-14 20:42:41.558935.558935 lmp.py:1625]   Expert 11 |    157 | CPU
DEBUG 01-14 20:42:41.558101.558101 lmp.py:1625]   Expert 58 |    157 | CPU
DEBUG 01-14 20:42:41.558029.558029 lmp.py:1625]   Expert 61 |    157 | CPU
DEBUG 01-14 20:42:41.558672.558672 lmp.py:1625]   Expert 19 |    160 | GPU
DEBUG 01-14 20:42:41.558600.558600 lmp.py:1625]   Expert 31 |    161 | GPU
DEBUG 01-14 20:42:41.558766.558766 lmp.py:1625]   Expert 40 |    163 | GPU
DEBUG 01-14 20:42:41.558978.558978 lmp.py:1625]   Expert 41 |    163 | GPU
DEBUG 01-14 20:42:41.558621.558621 lmp.py:1625]   Expert 54 |    163 | GPU
DEBUG 01-14 20:42:41.558787.558787 lmp.py:1625]   Expert 22 |    168 | GPU
DEBUG 01-14 20:42:41.558954.558954 lmp.py:1625]   Expert 46 |    171 | GPU
DEBUG 01-14 20:42:41.558881.558881 lmp.py:1625]   Expert 18 |    178 | GPU
DEBUG 01-14 20:42:41.558809.558809 lmp.py:1625]   Expert 57 |    178 | GPU
DEBUG 01-14 20:42:41.558452.558452 lmp.py:1625]   Expert 42 |    180 | GPU
DEBUG 01-14 20:42:41.558810.558810 lmp.py:1625]   Expert 34 |    186 | GPU
DEBUG 01-14 20:42:41.558738.558738 lmp.py:1625]   Expert 26 |    188 | GPU
DEBUG 01-14 20:42:41.558904.558904 lmp.py:1625]   Expert 56 |    188 | GPU
DEBUG 01-14 20:42:41.558832.558832 lmp.py:1625]   Expert 44 |    196 | GPU
DEBUG 01-14 20:42:41.558998.558998 lmp.py:1625]   Expert  0 |    205 | GPU
DEBUG 01-14 20:42:41.558926.558926 lmp.py:1625]   Expert  1 |    211 | GPU
DEBUG 01-14 20:42:41.558092.558092 lmp.py:1625]   Expert 20 |    227 | GPU
DEBUG 01-14 20:42:41.558735.558735 lmp.py:1625]   Expert 48 |    231 | GPU
DEBUG 01-14 20:42:41.558139.558139 lmp.py:1625]   Expert 51 |    234 | GPU
DEBUG 01-14 20:42:41.558067.558067 lmp.py:1625]   Expert 55 |    239 | GPU
DEBUG 01-14 20:42:41.558472.558472 lmp.py:1625]   Expert 29 |    241 | GPU
DEBUG 01-14 20:42:41.558638.558638 lmp.py:1625]   Expert 35 |    244 | GPU
DEBUG 01-14 20:42:41.558804.558804 lmp.py:1625]   Expert 21 |    245 | GPU
DEBUG 01-14 20:42:41.558732.558732 lmp.py:1625]   Expert 45 |    252 | GPU
DEBUG 01-14 20:42:41.558375.558375 lmp.py:1625]   Expert 16 |    261 | GPU
DEBUG 01-14 20:42:41.558779.558779 lmp.py:1625]   Expert  5 |    298 | GPU
DEBUG 01-14 20:42:41.558945.558945 lmp.py:1625]   Expert 13 |    366 | GPU
DEBUG 01-14 20:42:41.558635.558635 lmp.py:1625]   Expert 23 |    377 | GPU
DEBUG 01-14 20:42:41.558801.558801 lmp.py:1625]   Expert 17 |    419 | GPU
DEBUG 01-14 20:42:41.558728.558728 lmp.py:1625]   Expert 63 |    482 | GPU
DEBUG 01-14 20:42:41.558895.558895 lmp.py:1625]   Expert  9 |    511 | GPU
DEBUG 01-14 20:42:41.558822.558822 lmp.py:1625]   Expert 62 |   1235 | GPU
DEBUG 01-14 20:42:41.558419.558419 lmp.py:1626] 
DEBUG 01-14 20:42:41.558419.558419 lmp.py:1626]   CPU total tokens: 3567 (29.0%)
DEBUG 01-14 20:42:41.558969.558969 lmp.py:1627]   GPU total tokens: 8721 (71.0%)
DEBUG 01-14 20:42:41.558096.558096 cuda_h.py:19] end experts_map_get cost 0.0015575885772705078 seconds
DEBUG 01-14 20:42:41.558568.558568 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-14 20:42:41.558557.558557 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-14 20:42:41.559039.559039 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-14 20:42:41.564089.564089 cuda_h.py:19] end allocate_cuda_memory cost 0.005023956298828125 seconds
DEBUG 01-14 20:42:41.564575.564575 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-14 20:42:41.564238.564238 sllm_store_c.py:27] get device uuid map
DEBUG 01-14 20:42:41.564769.564769 sllm_store_c.py:29] call client load into gpu
DEBUG 01-14 20:42:41.564088.564088 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 2ab829f7-a2d3-474a-99a3-ed9dd4f95f4c
DEBUG 01-14 20:42:41.564042.564042 client.py:106] call stub.LoadModelAsync
DEBUG 01-14 20:42:41.564610.564610 mlpmodule.py:1367]  experts func einsum cost 0.07637476921081543 s
INFO 01-14 20:42:41.564819.564819 client.py:127] Model loaded
DEBUG 01-14 20:42:41.564106.564106 cuda_h.py:10] start restore2model
DEBUG 01-14 20:42:41.565391.565391 cuda_h.py:19] end restore2model cost 0.00034880638122558594 seconds
DEBUG 01-14 20:42:41.565399.565399 cuda_h.py:19] end sllm_worker_task cost 0.014322042465209961 seconds
INFO 01-14 20:42:41.565056.565056 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 2ab829f7-a2d3-474a-99a3-ed9dd4f95f4c
DEBUG 01-14 20:42:41.565522.565522 cuda_h.py:19] end load_into_gpu_async cost 0.0015401840209960938 seconds
DEBUG 01-14 20:42:41.565701.565701 cuda_h.py:10] start restore_tensors2
DEBUG 01-14 20:42:41.566495.566495 cuda_h.py:19] end restore_tensors2 cost 0.0003490447998046875 seconds
DEBUG 01-14 20:42:41.566517.566517 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.007285356521606445 seconds
DEBUG 01-14 20:42:41.566763.566763 cuda_h.py:10] start restore2model
DEBUG 01-14 20:42:41.568540.568540 cuda_h.py:19] end restore2model cost 0.0025794506072998047 seconds
DEBUG 01-14 20:42:41.568330.568330 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.01004648208618164 seconds
DEBUG 01-14 20:42:41.569224.569224 cuda_h.py:10] start gpu_sexperts
DEBUG 01-14 20:42:41.569421.569421 cuda_h.py:19] end gpu_sexperts cost 0.0002880096435546875 seconds
DEBUG 01-14 20:42:41.569628.569628 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-14 20:42:41.569522.569522 lmp.py:1683] 
DEBUG 01-14 20:42:41.569522.569522 lmp.py:1683]   Computing 32 experts on CPU...
DEBUG 01-14 20:42:41.569167.569167 cuda_h.py:19] end cpu_experts_submit cost 5.364418029785156e-05 seconds
DEBUG 01-14 20:42:41.569393.569393 cuda_h.py:10] start experts_func_mgpu_group_pad
DEBUG 01-14 20:42:41.579481.579481 mlpmodule.py:1460] group tensors cost 0.009708881378173828 s
DEBUG 01-14 20:42:41.580011.580011 cuda_h.py:10] start move_flat_hidden2cpu
DEBUG 01-14 20:42:41.582575.582575 cuda_h.py:19] end experts_func_mgpu_group_pad cost 0.012525081634521484 seconds
DEBUG 01-14 20:42:41.583350.583350 cuda_h.py:10] start gpu_group_list
DEBUG 01-14 20:42:41.584809.584809 cuda_h.py:19] end gpu_group_list cost 0.0005743503570556641 seconds
DEBUG 01-14 20:42:41.584136.584136 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-14 20:42:41.584054.584054 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.2649765014648438e-05 seconds
DEBUG 01-14 20:42:41.584399.584399 cuda_h.py:10] start wait_experts
INFO 01-14 20:42:41.584454.584454 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 2ab829f7-a2d3-474a-99a3-ed9dd4f95f4c
DEBUG 01-14 20:42:41.586848.586848 cuda_h.py:19] end move_flat_hidden2cpu cost 0.0065691471099853516 seconds
DEBUG 01-14 20:42:41.588772.588772 mlpmodule.py:1533] pad cost 0.0017681121826171875 s
DEBUG 01-14 20:42:41.588623.588623 mlpmodule.py:1539] create cpu tensor cost 3.695487976074219e-05 s
DEBUG 01-14 20:42:41.590528.590528 mlpmodule.py:1544] move to cpu cost 0.001859426498413086 s
DEBUG 01-14 20:42:41.601589.601589 mlpmodule.py:1558] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-14 20:42:41.601920.601920 mlpmodule.py:1559] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-14 20:42:41.601243.601243 mlpmodule.py:1564] group_w3 first element: 0.00457763671875
WARNING 01-14 20:42:41.601089.601089 mlpmodule.py:1574] start einsum2
DEBUG 01-14 20:42:41.620649.620649 mlpmodule.py:1584] group einsum cost 0.029636621475219727 s
INFO 01-14 20:42:41.621056.621056 client.py:127] Model loaded
DEBUG 01-14 20:42:41.621884.621884 mlpmodule.py:1593] cpy2cputensor cost 0.0008170604705810547 s
DEBUG 01-14 20:42:41.621504.621504 cuda_h.py:19] end wait_experts cost 0.03708505630493164 seconds
DEBUG 01-14 20:42:41.621421.621421 cuda_h.py:10] start move_outputs
DEBUG 01-14 20:42:41.621901.621901 cuda_h.py:10] start gpu_experts
DEBUG 01-14 20:42:41.622815.622815 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-14 20:42:41.623517.623517 cuda_h.py:19] end move_outputs cost 0.0018622875213623047 seconds
DEBUG 01-14 20:42:41.628862.628862 cuda_h.py:19] end wait_cetm_experts cost 0.005917072296142578 seconds
DEBUG 01-14 20:42:41.628257.628257 cuda_h.py:10] start gpu_group_einsum_mp_multi_list
DEBUG 01-14 20:42:41.628689.628689 cuda_h.py:10] start gpu_group_tensor
DEBUG 01-14 20:42:41.628851.628851 cuda_h.py:19] end gpu_group_tensor cost 0.0002617835998535156 seconds
DEBUG 01-14 20:42:41.628259.628259 cuda_h.py:10] start gpu_group_einsum
DEBUG 01-14 20:42:41.645490.645490 mlpmodule.py:1367]  experts func einsum cost 0.07543563842773438 s
DEBUG 01-14 20:42:41.645198.645198 cuda_h.py:19] end gpu_group_einsum cost 0.017093420028686523 seconds
DEBUG 01-14 20:42:41.645694.645694 cuda_h.py:10] start gpu_final_hidden_states_scatter
DEBUG 01-14 20:42:41.646180.646180 cuda_h.py:10] start all_expert_outputs_slices
DEBUG 01-14 20:42:41.646589.646589 cuda_h.py:19] end all_expert_outputs_slices cost 0.00029754638671875 seconds
DEBUG 01-14 20:42:41.646736.646736 cuda_h.py:10] start concat_expert_out
DEBUG 01-14 20:42:41.646746.646746 cuda_h.py:19] end concat_expert_out cost 7.009506225585938e-05 seconds
DEBUG 01-14 20:42:41.646709.646709 cuda_h.py:10] start index_scatter
DEBUG 01-14 20:42:41.646541.646541 cuda_h.py:19] end index_scatter cost 8.082389831542969e-05 seconds
DEBUG 01-14 20:42:41.646264.646264 cuda_h.py:19] end gpu_final_hidden_states_scatter cost 0.0007519721984863281 seconds
DEBUG 01-14 20:42:41.646910.646910 cuda_h.py:19] end gpu_experts cost 0.024807214736938477 seconds
DEBUG 01-14 20:42:41.646904.646904 cuda_h.py:10] start all_expert_weight_slices
DEBUG 01-14 20:42:41.647131.647131 cuda_h.py:19] end all_expert_weight_slices cost 0.0009927749633789062 seconds
DEBUG 01-14 20:42:41.647113.647113 cuda_h.py:10] start cpuoutputsdeal
DEBUG 01-14 20:42:41.648076.648076 cuda_h.py:10] start index_scatter
DEBUG 01-14 20:42:41.648722.648722 cuda_h.py:19] end index_scatter cost 6.031990051269531e-05 seconds
DEBUG 01-14 20:42:41.648214.648214 cuda_h.py:19] end cpuoutputsdeal cost 0.0006024837493896484 seconds
DEBUG 01-14 20:42:41.648329.648329 cuda_h.py:19] end layer_moe_generate_mp_l_18 cost 0.09215784072875977 seconds
DEBUG 01-14 20:42:41.649852.649852 cuda_h.py:19] end prefill_layer cost 0.09848642349243164 seconds
DEBUG 01-14 20:42:41.649795.649795 lmp.py:1551] -------------------------------- end prefill layer 17 --------------------------------
DEBUG 01-14 20:42:41.649836.649836 cuda_h.py:10] start prefill_layer
DEBUG 01-14 20:42:41.649876.649876 lmp.py:1494] -------------------------------- start prefill layer 18 --------------------------------
DEBUG 01-14 20:42:41.649440.649440 cuda_h.py:10] start start_load_qkvogn_s_weight_l_19
DEBUG 01-14 20:42:41.649819.649819 cuda_h.py:10] start start_load_qkvogn_s_weight_l_19
DEBUG 01-14 20:42:41.649291.649291 cuda_h.py:19] end start_load_qkvogn_s_weight_l_19 cost 3.6716461181640625e-05 seconds
DEBUG 01-14 20:42:41.649908.649908 cuda_h.py:19] end start_load_qkvogn_s_weight_l_19 cost 7.319450378417969e-05 seconds
DEBUG 01-14 20:42:41.649757.649757 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-14 20:42:41.649588.649588 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-14 20:42:41.649909.649909 cuda_h.py:10] start sllm_worker_task
DEBUG 01-14 20:42:41.649475.649475 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-14 20:42:41.649656.649656 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-14 20:42:41.649081.649081 cuda_h.py:19] end allocate_cuda_memory cost 0.00020122528076171875 seconds
DEBUG 01-14 20:42:41.650037.650037 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-14 20:42:41.650092.650092 sllm_store_c.py:27] get device uuid map
DEBUG 01-14 20:42:41.650974.650974 sllm_store_c.py:29] call client load into gpu
DEBUG 01-14 20:42:41.650446.650446 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 7cb5c1a1-af42-4d82-b71f-8adaba43d9b5
DEBUG 01-14 20:42:41.650528.650528 client.py:106] call stub.LoadModelAsync
DEBUG 01-14 20:42:41.650420.650420 cuda_h.py:10] start self_attn
INFO 01-14 20:42:41.651910.651910 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 7cb5c1a1-af42-4d82-b71f-8adaba43d9b5
DEBUG 01-14 20:42:41.651667.651667 cuda_h.py:19] end load_into_gpu_async cost 0.0017573833465576172 seconds
DEBUG 01-14 20:42:41.651662.651662 cuda_h.py:10] start restore_tensors2
DEBUG 01-14 20:42:41.652149.652149 cuda_h.py:19] end restore_tensors2 cost 8.0108642578125e-05 seconds
DEBUG 01-14 20:42:41.652296.652296 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0023212432861328125 seconds
INFO 01-14 20:42:41.652139.652139 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 7cb5c1a1-af42-4d82-b71f-8adaba43d9b5
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-14 20:42:41.654833.654833 cuda_h.py:19] end self_attn cost 0.0033566951751708984 seconds
DEBUG 01-14 20:42:41.654044.654044 cuda_h.py:19] end iln_self_attn_paln cost 0.0049855709075927734 seconds
DEBUG 01-14 20:42:41.654524.654524 cuda_h.py:10] start layer_moe_generate_mp_l_19
DEBUG 01-14 20:42:41.654777.654777 cuda_h.py:10] start gate
DEBUG 01-14 20:42:41.655780.655780 cuda_h.py:19] end gate cost 0.0006628036499023438 seconds
DEBUG 01-14 20:42:41.655517.655517 cuda_h.py:10] start experts_map_get
DEBUG 01-14 20:42:41.655402.655402 lmp.py:1615] 
DEBUG 01-14 20:42:41.655402.655402 lmp.py:1615] Expert Token Distribution & Device Allocation:
DEBUG 01-14 20:42:41.655111.655111 lmp.py:1616]   Total experts: 64
DEBUG 01-14 20:42:41.655430.655430 lmp.py:1617]   CPU experts: 32 (50%)
DEBUG 01-14 20:42:41.655411.655411 lmp.py:1618]   GPU experts: 32 (50%)
DEBUG 01-14 20:42:41.655531.655531 lmp.py:1619] 
DEBUG 01-14 20:42:41.655531.655531 lmp.py:1619]   Expert ID | Tokens | Device
DEBUG 01-14 20:42:41.655650.655650 lmp.py:1620]   -----------------------------------
DEBUG 01-14 20:42:41.655439.655439 lmp.py:1625]   Expert 32 |     48 | CPU
DEBUG 01-14 20:42:41.655559.655559 lmp.py:1625]   Expert 30 |     53 | CPU
DEBUG 01-14 20:42:41.655202.655202 lmp.py:1625]   Expert 46 |     55 | CPU
DEBUG 01-14 20:42:41.655845.655845 lmp.py:1625]   Expert  5 |     56 | CPU
DEBUG 01-14 20:42:41.655726.655726 lmp.py:1625]   Expert 12 |     98 | CPU
DEBUG 01-14 20:42:41.655369.655369 lmp.py:1625]   Expert  8 |    101 | CPU
DEBUG 01-14 20:42:41.655774.655774 lmp.py:1625]   Expert 60 |    101 | CPU
DEBUG 01-14 20:42:41.655370.655370 lmp.py:1625]   Expert 40 |    103 | CPU
DEBUG 01-14 20:42:41.655013.655013 lmp.py:1625]   Expert 27 |    104 | CPU
DEBUG 01-14 20:42:41.655895.655895 lmp.py:1625]   Expert  3 |    113 | CPU
DEBUG 01-14 20:42:41.655061.655061 lmp.py:1625]   Expert 28 |    113 | CPU
DEBUG 01-14 20:42:41.655227.655227 lmp.py:1625]   Expert 17 |    118 | CPU
DEBUG 01-14 20:42:41.655393.655393 lmp.py:1625]   Expert 21 |    119 | CPU
DEBUG 01-14 20:42:41.655559.655559 lmp.py:1625]   Expert 41 |    121 | CPU
DEBUG 01-14 20:42:41.655249.655249 lmp.py:1625]   Expert 29 |    122 | CPU
DEBUG 01-14 20:42:41.655415.655415 lmp.py:1625]   Expert 25 |    126 | CPU
DEBUG 01-14 20:42:41.656104.656104 lmp.py:1625]   Expert 58 |    126 | CPU
DEBUG 01-14 20:42:41.656270.656270 lmp.py:1625]   Expert 54 |    129 | CPU
DEBUG 01-14 20:42:41.656913.656913 lmp.py:1625]   Expert 35 |    130 | CPU
DEBUG 01-14 20:42:41.656271.656271 lmp.py:1625]   Expert  6 |    131 | CPU
DEBUG 01-14 20:42:41.656676.656676 lmp.py:1625]   Expert 19 |    139 | CPU
DEBUG 01-14 20:42:41.656081.656081 lmp.py:1625]   Expert  0 |    144 | CPU
DEBUG 01-14 20:42:41.656247.656247 lmp.py:1625]   Expert 52 |    145 | CPU
DEBUG 01-14 20:42:41.656413.656413 lmp.py:1625]   Expert 37 |    148 | CPU
DEBUG 01-14 20:42:41.656102.656102 lmp.py:1625]   Expert  9 |    149 | CPU
DEBUG 01-14 20:42:41.656268.656268 lmp.py:1625]   Expert 63 |    156 | CPU
DEBUG 01-14 20:42:41.656958.656958 lmp.py:1625]   Expert 53 |    160 | CPU
DEBUG 01-14 20:42:41.656885.656885 lmp.py:1625]   Expert 36 |    163 | CPU
DEBUG 01-14 20:42:41.656813.656813 lmp.py:1625]   Expert 48 |    168 | CPU
DEBUG 01-14 20:42:41.656502.656502 lmp.py:1625]   Expert 56 |    168 | CPU
DEBUG 01-14 20:42:41.656384.656384 lmp.py:1625]   Expert  1 |    174 | CPU
DEBUG 01-14 20:42:41.656311.656311 lmp.py:1625]   Expert 59 |    175 | CPU
DEBUG 01-14 20:42:41.656001.656001 lmp.py:1625]   Expert 47 |    189 | GPU
DEBUG 01-14 20:42:41.656405.656405 lmp.py:1625]   Expert 20 |    196 | GPU
DEBUG 01-14 20:42:41.656095.656095 lmp.py:1625]   Expert 39 |    199 | GPU
DEBUG 01-14 20:42:41.656261.656261 lmp.py:1625]   Expert 42 |    205 | GPU
DEBUG 01-14 20:42:41.656712.656712 lmp.py:1625]   Expert 61 |    207 | GPU
DEBUG 01-14 20:42:41.656878.656878 lmp.py:1625]   Expert 34 |    215 | GPU
DEBUG 01-14 20:42:41.656958.656958 lmp.py:1625]   Expert 11 |    221 | GPU
DEBUG 01-14 20:42:41.656124.656124 lmp.py:1625]   Expert  7 |    222 | GPU
DEBUG 01-14 20:42:41.656813.656813 lmp.py:1625]   Expert 57 |    222 | GPU
DEBUG 01-14 20:42:41.656178.656178 lmp.py:1625]   Expert 16 |    223 | GPU
DEBUG 01-14 20:42:41.656583.656583 lmp.py:1625]   Expert 13 |    224 | GPU
DEBUG 01-14 20:42:41.656795.656795 lmp.py:1625]   Expert 18 |    226 | GPU
DEBUG 01-14 20:42:41.656008.656008 lmp.py:1625]   Expert 55 |    231 | GPU
DEBUG 01-14 20:42:41.656982.656982 lmp.py:1625]   Expert 15 |    247 | GPU
DEBUG 01-14 20:42:41.656718.656718 lmp.py:1625]   Expert 43 |    247 | GPU
DEBUG 01-14 20:42:41.656692.656692 lmp.py:1625]   Expert 49 |    248 | GPU
DEBUG 01-14 20:42:41.656427.656427 lmp.py:1625]   Expert  4 |    250 | GPU
DEBUG 01-14 20:42:41.656401.656401 lmp.py:1625]   Expert 50 |    250 | GPU
DEBUG 01-14 20:42:41.656137.656137 lmp.py:1625]   Expert  2 |    253 | GPU
DEBUG 01-14 20:42:41.656349.656349 lmp.py:1625]   Expert 51 |    254 | GPU
DEBUG 01-14 20:42:41.656323.656323 lmp.py:1625]   Expert 22 |    259 | GPU
DEBUG 01-14 20:42:41.656774.656774 lmp.py:1625]   Expert 45 |    259 | GPU
DEBUG 01-14 20:42:41.656702.656702 lmp.py:1625]   Expert 31 |    261 | GPU
DEBUG 01-14 20:42:41.656915.656915 lmp.py:1625]   Expert 33 |    261 | GPU
DEBUG 01-14 20:42:41.656889.656889 lmp.py:1625]   Expert 38 |    280 | GPU
DEBUG 01-14 20:42:41.656386.656386 lmp.py:1625]   Expert 23 |    287 | GPU
DEBUG 01-14 20:42:41.656360.656360 lmp.py:1625]   Expert 44 |    287 | GPU
DEBUG 01-14 20:42:41.656095.656095 lmp.py:1625]   Expert 26 |    294 | GPU
DEBUG 01-14 20:42:41.656069.656069 lmp.py:1625]   Expert 10 |    302 | GPU
DEBUG 01-14 20:42:41.656044.656044 lmp.py:1625]   Expert 24 |    305 | GPU
DEBUG 01-14 20:42:41.656018.656018 lmp.py:1625]   Expert 14 |    306 | GPU
DEBUG 01-14 20:42:41.656184.656184 lmp.py:1625]   Expert 62 |    702 | GPU
DEBUG 01-14 20:42:41.656304.656304 lmp.py:1626] 
DEBUG 01-14 20:42:41.656304.656304 lmp.py:1626]   CPU total tokens: 3956 (32.2%)
DEBUG 01-14 20:42:41.656662.656662 lmp.py:1627]   GPU total tokens: 8332 (67.8%)
DEBUG 01-14 20:42:41.656596.656596 cuda_h.py:19] end experts_map_get cost 0.0015399456024169922 seconds
DEBUG 01-14 20:42:41.656969.656969 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-14 20:42:41.656382.656382 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-14 20:42:41.657241.657241 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-14 20:42:41.659050.659050 cuda_h.py:19] end allocate_cuda_memory cost 0.0019676685333251953 seconds
DEBUG 01-14 20:42:41.659376.659376 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-14 20:42:41.659040.659040 sllm_store_c.py:27] get device uuid map
DEBUG 01-14 20:42:41.659756.659756 sllm_store_c.py:29] call client load into gpu
DEBUG 01-14 20:42:41.659505.659505 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, c4e2b585-f0cb-4621-802e-4c3383678b71
DEBUG 01-14 20:42:41.659233.659233 client.py:106] call stub.LoadModelAsync
INFO 01-14 20:42:41.659407.659407 client.py:127] Model loaded
DEBUG 01-14 20:42:41.659694.659694 cuda_h.py:10] start restore2model
DEBUG 01-14 20:42:41.660482.660482 cuda_h.py:19] end restore2model cost 0.0005300045013427734 seconds
DEBUG 01-14 20:42:41.660378.660378 cuda_h.py:19] end sllm_worker_task cost 0.010961771011352539 seconds
INFO 01-14 20:42:41.661684.661684 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, c4e2b585-f0cb-4621-802e-4c3383678b71
DEBUG 01-14 20:42:41.661865.661865 cuda_h.py:19] end load_into_gpu_async cost 0.002290964126586914 seconds
DEBUG 01-14 20:42:41.661806.661806 cuda_h.py:10] start restore_tensors2
DEBUG 01-14 20:42:41.661944.661944 cuda_h.py:19] end restore_tensors2 cost 0.0003211498260498047 seconds
DEBUG 01-14 20:42:41.661250.661250 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.004935503005981445 seconds
DEBUG 01-14 20:42:41.661059.661059 cuda_h.py:10] start restore2model
DEBUG 01-14 20:42:41.664921.664921 cuda_h.py:19] end restore2model cost 0.002572298049926758 seconds
DEBUG 01-14 20:42:41.664095.664095 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.0076847076416015625 seconds
DEBUG 01-14 20:42:41.664367.664367 cuda_h.py:10] start gpu_sexperts
DEBUG 01-14 20:42:41.664205.664205 cuda_h.py:19] end gpu_sexperts cost 0.00027060508728027344 seconds
DEBUG 01-14 20:42:41.665459.665459 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-14 20:42:41.665830.665830 lmp.py:1683] 
DEBUG 01-14 20:42:41.665830.665830 lmp.py:1683]   Computing 32 experts on CPU...
DEBUG 01-14 20:42:41.665766.665766 cuda_h.py:19] end cpu_experts_submit cost 5.793571472167969e-05 seconds
DEBUG 01-14 20:42:41.665800.665800 cuda_h.py:10] start experts_func_mgpu_group_pad
DEBUG 01-14 20:42:41.675591.675591 mlpmodule.py:1460] group tensors cost 0.010156393051147461 s
DEBUG 01-14 20:42:41.676774.676774 cuda_h.py:10] start move_flat_hidden2cpu
DEBUG 01-14 20:42:41.679079.679079 cuda_h.py:19] end experts_func_mgpu_group_pad cost 0.014186382293701172 seconds
DEBUG 01-14 20:42:41.681435.681435 cuda_h.py:10] start gpu_group_list
DEBUG 01-14 20:42:41.681012.681012 cuda_h.py:19] end gpu_group_list cost 0.0005471706390380859 seconds
DEBUG 01-14 20:42:41.681529.681529 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-14 20:42:41.682659.682659 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 3.337860107421875e-05 seconds
DEBUG 01-14 20:42:41.682244.682244 cuda_h.py:10] start wait_experts
INFO 01-14 20:42:41.682821.682821 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, c4e2b585-f0cb-4621-802e-4c3383678b71
DEBUG 01-14 20:42:41.684034.684034 cuda_h.py:19] end move_flat_hidden2cpu cost 0.0078008174896240234 seconds
DEBUG 01-14 20:42:41.686827.686827 mlpmodule.py:1533] pad cost 0.0017960071563720703 s
DEBUG 01-14 20:42:41.686169.686169 mlpmodule.py:1539] create cpu tensor cost 3.743171691894531e-05 s
DEBUG 01-14 20:42:41.688266.688266 mlpmodule.py:1544] move to cpu cost 0.002068042755126953 s
DEBUG 01-14 20:42:41.698947.698947 mlpmodule.py:1558] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-14 20:42:41.698351.698351 mlpmodule.py:1559] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-14 20:42:41.699401.699401 mlpmodule.py:1564] group_w3 first element: 0.0024871826171875
WARNING 01-14 20:42:41.699413.699413 mlpmodule.py:1574] start einsum2
INFO 01-14 20:42:41.717968.717968 client.py:127] Model loaded
DEBUG 01-14 20:42:41.717757.717757 mlpmodule.py:1584] group einsum cost 0.02843642234802246 s
DEBUG 01-14 20:42:41.717917.717917 cuda_h.py:19] end wait_experts cost 0.03546571731567383 seconds
DEBUG 01-14 20:42:41.717189.717189 cuda_h.py:10] start gpu_experts
DEBUG 01-14 20:42:41.718429.718429 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-14 20:42:41.718052.718052 mlpmodule.py:1593] cpy2cputensor cost 0.0007345676422119141 s
DEBUG 01-14 20:42:41.718644.718644 cuda_h.py:10] start move_outputs
DEBUG 01-14 20:42:41.720370.720370 cuda_h.py:19] end move_outputs cost 0.0020449161529541016 seconds
DEBUG 01-14 20:42:41.724627.724627 cuda_h.py:19] end wait_cetm_experts cost 0.006516218185424805 seconds
DEBUG 01-14 20:42:41.724512.724512 cuda_h.py:10] start gpu_group_einsum_mp_multi_list
DEBUG 01-14 20:42:41.724990.724990 cuda_h.py:10] start gpu_group_tensor
DEBUG 01-14 20:42:41.725893.725893 cuda_h.py:19] end gpu_group_tensor cost 0.0002460479736328125 seconds
DEBUG 01-14 20:42:41.725269.725269 cuda_h.py:10] start gpu_group_einsum
DEBUG 01-14 20:42:41.726672.726672 cuda_h.py:19] end gpu_group_einsum cost 0.0006968975067138672 seconds
DEBUG 01-14 20:42:41.726491.726491 cuda_h.py:10] start gpu_final_hidden_states_scatter
DEBUG 01-14 20:42:41.726109.726109 cuda_h.py:10] start all_expert_outputs_slices
DEBUG 01-14 20:42:41.726514.726514 cuda_h.py:19] end all_expert_outputs_slices cost 0.0003654956817626953 seconds
DEBUG 01-14 20:42:41.726270.726270 cuda_h.py:10] start concat_expert_out
DEBUG 01-14 20:42:41.726730.726730 cuda_h.py:19] end concat_expert_out cost 5.745887756347656e-05 seconds
DEBUG 01-14 20:42:41.726248.726248 cuda_h.py:10] start index_scatter
DEBUG 01-14 20:42:41.727106.727106 cuda_h.py:19] end index_scatter cost 7.152557373046875e-05 seconds
DEBUG 01-14 20:42:41.727246.727246 cuda_h.py:19] end gpu_final_hidden_states_scatter cost 0.0007519721984863281 seconds
DEBUG 01-14 20:42:41.727355.727355 cuda_h.py:19] end gpu_experts cost 0.009225130081176758 seconds
DEBUG 01-14 20:42:41.727535.727535 cuda_h.py:10] start all_expert_weight_slices
DEBUG 01-14 20:42:41.728084.728084 cuda_h.py:19] end all_expert_weight_slices cost 0.0009357929229736328 seconds
DEBUG 01-14 20:42:41.728191.728191 cuda_h.py:10] start cpuoutputsdeal
DEBUG 01-14 20:42:41.728274.728274 cuda_h.py:10] start index_scatter
DEBUG 01-14 20:42:41.728416.728416 cuda_h.py:19] end index_scatter cost 5.1021575927734375e-05 seconds
DEBUG 01-14 20:42:41.728325.728325 cuda_h.py:19] end cpuoutputsdeal cost 0.0005953311920166016 seconds
DEBUG 01-14 20:42:41.728188.728188 cuda_h.py:19] end layer_moe_generate_mp_l_19 cost 0.07439708709716797 seconds
DEBUG 01-14 20:42:41.729532.729532 cuda_h.py:19] end prefill_layer cost 0.08011555671691895 seconds
DEBUG 01-14 20:42:41.729177.729177 lmp.py:1551] -------------------------------- end prefill layer 18 --------------------------------
DEBUG 01-14 20:42:41.729356.729356 cuda_h.py:10] start prefill_layer
DEBUG 01-14 20:42:41.729774.729774 lmp.py:1494] -------------------------------- start prefill layer 19 --------------------------------
DEBUG 01-14 20:42:41.729669.729669 cuda_h.py:10] start start_load_qkvogn_s_weight_l_20
DEBUG 01-14 20:42:41.729995.729995 cuda_h.py:10] start start_load_qkvogn_s_weight_l_20
DEBUG 01-14 20:42:41.729275.729275 cuda_h.py:19] end start_load_qkvogn_s_weight_l_20 cost 3.719329833984375e-05 seconds
DEBUG 01-14 20:42:41.729084.729084 cuda_h.py:19] end start_load_qkvogn_s_weight_l_20 cost 7.534027099609375e-05 seconds
DEBUG 01-14 20:42:41.729688.729688 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-14 20:42:41.729664.729664 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-14 20:42:41.729310.729310 cuda_h.py:10] start sllm_worker_task
DEBUG 01-14 20:42:41.729810.729810 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-14 20:42:41.729177.729177 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-14 20:42:41.730331.730331 cuda_h.py:19] end allocate_cuda_memory cost 0.0005986690521240234 seconds
DEBUG 01-14 20:42:41.730625.730625 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-14 20:42:41.730772.730772 sllm_store_c.py:27] get device uuid map
DEBUG 01-14 20:42:41.730561.730561 sllm_store_c.py:29] call client load into gpu
DEBUG 01-14 20:42:41.730271.730271 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, b6e19d99-73e2-46f2-a8aa-5e79d52f8095
DEBUG 01-14 20:42:41.730261.730261 client.py:106] call stub.LoadModelAsync
DEBUG 01-14 20:42:41.731802.731802 cuda_h.py:10] start self_attn
INFO 01-14 20:42:41.731395.731395 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, b6e19d99-73e2-46f2-a8aa-5e79d52f8095
DEBUG 01-14 20:42:41.731285.731285 cuda_h.py:19] end load_into_gpu_async cost 0.001079559326171875 seconds
DEBUG 01-14 20:42:41.731895.731895 cuda_h.py:10] start restore_tensors2
DEBUG 01-14 20:42:41.731144.731144 cuda_h.py:19] end restore_tensors2 cost 8.344650268554688e-05 seconds
DEBUG 01-14 20:42:41.731714.731714 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0020356178283691406 seconds
INFO 01-14 20:42:41.732471.732471 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, b6e19d99-73e2-46f2-a8aa-5e79d52f8095
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-14 20:42:41.734534.734534 cuda_h.py:19] end self_attn cost 0.003202199935913086 seconds
DEBUG 01-14 20:42:41.734724.734724 cuda_h.py:19] end iln_self_attn_paln cost 0.005190134048461914 seconds
DEBUG 01-14 20:42:41.734236.734236 cuda_h.py:10] start layer_moe_generate_mp_l_20
DEBUG 01-14 20:42:41.734714.734714 cuda_h.py:10] start gate
DEBUG 01-14 20:42:41.735326.735326 cuda_h.py:19] end gate cost 0.0006630420684814453 seconds
DEBUG 01-14 20:42:41.735991.735991 cuda_h.py:10] start experts_map_get
DEBUG 01-14 20:42:41.736956.736956 lmp.py:1615] 
DEBUG 01-14 20:42:41.736956.736956 lmp.py:1615] Expert Token Distribution & Device Allocation:
DEBUG 01-14 20:42:41.736241.736241 lmp.py:1616]   Total experts: 64
DEBUG 01-14 20:42:41.736097.736097 lmp.py:1617]   CPU experts: 32 (50%)
DEBUG 01-14 20:42:41.736747.736747 lmp.py:1618]   GPU experts: 32 (50%)
DEBUG 01-14 20:42:41.736489.736489 lmp.py:1619] 
DEBUG 01-14 20:42:41.736489.736489 lmp.py:1619]   Expert ID | Tokens | Device
DEBUG 01-14 20:42:41.736993.736993 lmp.py:1620]   -----------------------------------
DEBUG 01-14 20:42:41.736212.736212 lmp.py:1625]   Expert  1 |     41 | CPU
DEBUG 01-14 20:42:41.736001.736001 lmp.py:1625]   Expert 44 |     51 | CPU
DEBUG 01-14 20:42:41.736505.736505 lmp.py:1625]   Expert 60 |     71 | CPU
DEBUG 01-14 20:42:41.736532.736532 lmp.py:1625]   Expert 28 |     75 | CPU
DEBUG 01-14 20:42:41.736083.736083 lmp.py:1625]   Expert 27 |     87 | CPU
DEBUG 01-14 20:42:41.736633.736633 lmp.py:1625]   Expert 62 |     92 | CPU
DEBUG 01-14 20:42:41.736468.736468 lmp.py:1625]   Expert 30 |     93 | CPU
DEBUG 01-14 20:42:41.736541.736541 lmp.py:1625]   Expert 48 |     96 | CPU
DEBUG 01-14 20:42:41.736853.736853 lmp.py:1625]   Expert  0 |    101 | CPU
DEBUG 01-14 20:42:41.736927.736927 lmp.py:1625]   Expert 22 |    105 | CPU
DEBUG 01-14 20:42:41.736000.736000 lmp.py:1625]   Expert 42 |    114 | CPU
DEBUG 01-14 20:42:41.736703.736703 lmp.py:1625]   Expert 58 |    118 | CPU
DEBUG 01-14 20:42:41.736300.736300 lmp.py:1625]   Expert 59 |    129 | CPU
DEBUG 01-14 20:42:41.736658.736658 lmp.py:1625]   Expert  8 |    130 | CPU
DEBUG 01-14 20:42:41.736539.736539 lmp.py:1625]   Expert 50 |    131 | CPU
DEBUG 01-14 20:42:41.736659.736659 lmp.py:1625]   Expert 12 |    133 | CPU
DEBUG 01-14 20:42:41.736541.736541 lmp.py:1625]   Expert 32 |    141 | CPU
DEBUG 01-14 20:42:41.736660.736660 lmp.py:1625]   Expert 56 |    141 | CPU
DEBUG 01-14 20:42:41.736734.736734 lmp.py:1625]   Expert  5 |    142 | CPU
DEBUG 01-14 20:42:41.736331.736331 lmp.py:1625]   Expert 34 |    145 | CPU
DEBUG 01-14 20:42:41.736404.736404 lmp.py:1625]   Expert 55 |    148 | CPU
DEBUG 01-14 20:42:41.736285.736285 lmp.py:1625]   Expert 16 |    151 | CPU
DEBUG 01-14 20:42:41.736928.736928 lmp.py:1625]   Expert 26 |    152 | CPU
DEBUG 01-14 20:42:41.736333.736333 lmp.py:1625]   Expert  2 |    158 | CPU
DEBUG 01-14 20:42:41.736214.736214 lmp.py:1625]   Expert 15 |    158 | CPU
DEBUG 01-14 20:42:41.736096.736096 lmp.py:1625]   Expert 19 |    159 | CPU
DEBUG 01-14 20:42:41.736977.736977 lmp.py:1625]   Expert 47 |    161 | CPU
DEBUG 01-14 20:42:41.736097.736097 lmp.py:1625]   Expert 13 |    165 | CPU
DEBUG 01-14 20:42:41.736978.736978 lmp.py:1625]   Expert 41 |    168 | CPU
DEBUG 01-14 20:42:41.736337.736337 lmp.py:1625]   Expert 52 |    170 | CPU
DEBUG 01-14 20:42:41.736172.736172 lmp.py:1625]   Expert 25 |    175 | CPU
DEBUG 01-14 20:42:41.736053.736053 lmp.py:1625]   Expert 40 |    177 | CPU
DEBUG 01-14 20:42:41.736934.736934 lmp.py:1625]   Expert  6 |    178 | GPU
DEBUG 01-14 20:42:41.736577.736577 lmp.py:1625]   Expert 18 |    179 | GPU
DEBUG 01-14 20:42:41.736220.736220 lmp.py:1625]   Expert 20 |    179 | GPU
DEBUG 01-14 20:42:41.736863.736863 lmp.py:1625]   Expert 24 |    179 | GPU
DEBUG 01-14 20:42:41.736506.736506 lmp.py:1625]   Expert 37 |    182 | GPU
DEBUG 01-14 20:42:41.736388.736388 lmp.py:1625]   Expert 51 |    185 | GPU
DEBUG 01-14 20:42:41.736223.736223 lmp.py:1625]   Expert 17 |    186 | GPU
DEBUG 01-14 20:42:41.736257.736257 lmp.py:1625]   Expert 54 |    189 | GPU
DEBUG 01-14 20:42:41.736807.736807 lmp.py:1625]   Expert 57 |    189 | GPU
DEBUG 01-14 20:42:41.736689.736689 lmp.py:1625]   Expert  3 |    190 | GPU
DEBUG 01-14 20:42:41.736047.736047 lmp.py:1625]   Expert 46 |    194 | GPU
DEBUG 01-14 20:42:41.736882.736882 lmp.py:1625]   Expert 11 |    201 | GPU
DEBUG 01-14 20:42:41.737194.737194 lmp.py:1625]   Expert 23 |    202 | GPU
DEBUG 01-14 20:42:41.737029.737029 lmp.py:1625]   Expert 43 |    208 | GPU
DEBUG 01-14 20:42:41.737625.737625 lmp.py:1625]   Expert 49 |    217 | GPU
DEBUG 01-14 20:42:41.737984.737984 lmp.py:1625]   Expert 31 |    223 | GPU
DEBUG 01-14 20:42:41.737057.737057 lmp.py:1625]   Expert 35 |    229 | GPU
DEBUG 01-14 20:42:41.737415.737415 lmp.py:1625]   Expert 10 |    230 | GPU
DEBUG 01-14 20:42:41.737012.737012 lmp.py:1625]   Expert 53 |    230 | GPU
DEBUG 01-14 20:42:41.737609.737609 lmp.py:1625]   Expert 36 |    247 | GPU
DEBUG 01-14 20:42:41.737967.737967 lmp.py:1625]   Expert 33 |    252 | GPU
DEBUG 01-14 20:42:41.737802.737802 lmp.py:1625]   Expert 39 |    258 | GPU
DEBUG 01-14 20:42:41.737399.737399 lmp.py:1625]   Expert 38 |    261 | GPU
DEBUG 01-14 20:42:41.737234.737234 lmp.py:1625]   Expert  4 |    308 | GPU
DEBUG 01-14 20:42:41.737307.737307 lmp.py:1625]   Expert 21 |    324 | GPU
DEBUG 01-14 20:42:41.737904.737904 lmp.py:1625]   Expert  9 |    327 | GPU
DEBUG 01-14 20:42:41.737024.737024 lmp.py:1625]   Expert 14 |    345 | GPU
DEBUG 01-14 20:42:41.737382.737382 lmp.py:1625]   Expert 45 |    362 | GPU
DEBUG 01-14 20:42:41.737217.737217 lmp.py:1625]   Expert 63 |    367 | GPU
DEBUG 01-14 20:42:41.737052.737052 lmp.py:1625]   Expert 61 |    388 | GPU
DEBUG 01-14 20:42:41.737649.737649 lmp.py:1625]   Expert 29 |    487 | GPU
DEBUG 01-14 20:42:41.737484.737484 lmp.py:1625]   Expert  7 |    514 | GPU
DEBUG 01-14 20:42:41.737749.737749 lmp.py:1626] 
DEBUG 01-14 20:42:41.737749.737749 lmp.py:1626]   CPU total tokens: 4078 (33.2%)
DEBUG 01-14 20:42:41.737300.737300 lmp.py:1627]   GPU total tokens: 8210 (66.8%)
DEBUG 01-14 20:42:41.737618.737618 cuda_h.py:19] end experts_map_get cost 0.0016906261444091797 seconds
DEBUG 01-14 20:42:41.737435.737435 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-14 20:42:41.737855.737855 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-14 20:42:41.737866.737866 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-14 20:42:41.742773.742773 cuda_h.py:19] end allocate_cuda_memory cost 0.004285573959350586 seconds
DEBUG 01-14 20:42:41.742484.742484 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-14 20:42:41.742478.742478 sllm_store_c.py:27] get device uuid map
DEBUG 01-14 20:42:41.742771.742771 sllm_store_c.py:29] call client load into gpu
DEBUG 01-14 20:42:41.742997.742997 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, e47b9850-ab93-4968-8873-1974b3ffb0b4
DEBUG 01-14 20:42:41.742785.742785 client.py:106] call stub.LoadModelAsync
DEBUG 01-14 20:42:41.742340.742340 mlpmodule.py:1367]  experts func einsum cost 0.0768735408782959 s
INFO 01-14 20:42:41.742650.742650 client.py:127] Model loaded
DEBUG 01-14 20:42:41.742217.742217 cuda_h.py:10] start restore2model
DEBUG 01-14 20:42:41.743534.743534 cuda_h.py:19] end restore2model cost 0.00033092498779296875 seconds
DEBUG 01-14 20:42:41.743112.743112 cuda_h.py:19] end sllm_worker_task cost 0.013364553451538086 seconds
INFO 01-14 20:42:41.743082.743082 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, e47b9850-ab93-4968-8873-1974b3ffb0b4
DEBUG 01-14 20:42:41.744693.744693 cuda_h.py:19] end load_into_gpu_async cost 0.0018761157989501953 seconds
DEBUG 01-14 20:42:41.744065.744065 cuda_h.py:10] start restore_tensors2
DEBUG 01-14 20:42:41.744866.744866 cuda_h.py:19] end restore_tensors2 cost 0.0003514289855957031 seconds
DEBUG 01-14 20:42:41.744987.744987 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.006885528564453125 seconds
DEBUG 01-14 20:42:41.744803.744803 cuda_h.py:10] start restore2model
DEBUG 01-14 20:42:41.747345.747345 cuda_h.py:19] end restore2model cost 0.0025129318237304688 seconds
DEBUG 01-14 20:42:41.747274.747274 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.009575605392456055 seconds
DEBUG 01-14 20:42:41.747851.747851 cuda_h.py:10] start gpu_sexperts
DEBUG 01-14 20:42:41.747041.747041 cuda_h.py:19] end gpu_sexperts cost 0.00028443336486816406 seconds
DEBUG 01-14 20:42:41.747724.747724 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-14 20:42:41.747858.747858 lmp.py:1683] 
DEBUG 01-14 20:42:41.747858.747858 lmp.py:1683]   Computing 32 experts on CPU...
DEBUG 01-14 20:42:41.747985.747985 cuda_h.py:19] end cpu_experts_submit cost 5.91278076171875e-05 seconds
DEBUG 01-14 20:42:41.747880.747880 cuda_h.py:10] start experts_func_mgpu_group_pad
DEBUG 01-14 20:42:41.752422.752422 mlpmodule.py:1460] group tensors cost 0.0043637752532958984 s
DEBUG 01-14 20:42:41.753500.753500 cuda_h.py:10] start move_flat_hidden2cpu
DEBUG 01-14 20:42:41.755909.755909 cuda_h.py:19] end experts_func_mgpu_group_pad cost 0.007340431213378906 seconds
DEBUG 01-14 20:42:41.756805.756805 cuda_h.py:10] start gpu_group_list
DEBUG 01-14 20:42:41.756206.756206 cuda_h.py:19] end gpu_group_list cost 0.0004279613494873047 seconds
DEBUG 01-14 20:42:41.757338.757338 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-14 20:42:41.757347.757347 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 1.8358230590820312e-05 seconds
DEBUG 01-14 20:42:41.757103.757103 cuda_h.py:10] start wait_experts
INFO 01-14 20:42:41.757336.757336 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, e47b9850-ab93-4968-8873-1974b3ffb0b4
DEBUG 01-14 20:42:41.759208.759208 cuda_h.py:19] end move_flat_hidden2cpu cost 0.006844520568847656 seconds
DEBUG 01-14 20:42:41.761460.761460 mlpmodule.py:1533] pad cost 0.0018568038940429688 s
DEBUG 01-14 20:42:41.762377.762377 mlpmodule.py:1539] create cpu tensor cost 3.814697265625e-05 s
DEBUG 01-14 20:42:41.764217.764217 mlpmodule.py:1544] move to cpu cost 0.002089262008666992 s
DEBUG 01-14 20:42:41.774546.774546 mlpmodule.py:1558] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-14 20:42:41.774804.774804 mlpmodule.py:1559] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-14 20:42:41.774231.774231 mlpmodule.py:1564] group_w3 first element: -0.0034942626953125
WARNING 01-14 20:42:41.774567.774567 mlpmodule.py:1574] start einsum2
DEBUG 01-14 20:42:41.792594.792594 mlpmodule.py:1584] group einsum cost 0.027997970581054688 s
DEBUG 01-14 20:42:41.793707.793707 mlpmodule.py:1593] cpy2cputensor cost 0.0007350444793701172 s
DEBUG 01-14 20:42:41.793981.793981 cuda_h.py:10] start move_outputs
DEBUG 01-14 20:42:41.796767.796767 cuda_h.py:19] end move_outputs cost 0.0026884078979492188 seconds
INFO 01-14 20:42:41.801458.801458 client.py:127] Model loaded
DEBUG 01-14 20:42:41.801795.801795 cuda_h.py:19] end wait_experts cost 0.04434776306152344 seconds
DEBUG 01-14 20:42:41.801564.801564 cuda_h.py:10] start gpu_experts
DEBUG 01-14 20:42:41.801480.801480 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-14 20:42:41.801348.801348 cuda_h.py:19] end wait_cetm_experts cost 0.0001881122589111328 seconds
DEBUG 01-14 20:42:41.802350.802350 cuda_h.py:10] start gpu_group_einsum_mp_multi_list
DEBUG 01-14 20:42:41.802775.802775 cuda_h.py:10] start gpu_group_tensor
DEBUG 01-14 20:42:41.802626.802626 cuda_h.py:19] end gpu_group_tensor cost 0.00024437904357910156 seconds
DEBUG 01-14 20:42:41.802835.802835 cuda_h.py:10] start gpu_group_einsum
DEBUG 01-14 20:42:41.803714.803714 cuda_h.py:19] end gpu_group_einsum cost 0.0006999969482421875 seconds
DEBUG 01-14 20:42:41.803494.803494 cuda_h.py:10] start gpu_final_hidden_states_scatter
DEBUG 01-14 20:42:41.803589.803589 cuda_h.py:10] start all_expert_outputs_slices
DEBUG 01-14 20:42:41.803616.803616 cuda_h.py:19] end all_expert_outputs_slices cost 0.00036597251892089844 seconds
DEBUG 01-14 20:42:41.803564.803564 cuda_h.py:10] start concat_expert_out
DEBUG 01-14 20:42:41.803693.803693 cuda_h.py:19] end concat_expert_out cost 5.888938903808594e-05 seconds
DEBUG 01-14 20:42:41.804550.804550 cuda_h.py:10] start index_scatter
DEBUG 01-14 20:42:41.804600.804600 cuda_h.py:19] end index_scatter cost 7.2479248046875e-05 seconds
DEBUG 01-14 20:42:41.804409.804409 cuda_h.py:19] end gpu_final_hidden_states_scatter cost 0.0007624626159667969 seconds
DEBUG 01-14 20:42:41.804087.804087 cuda_h.py:19] end gpu_experts cost 0.002535104751586914 seconds
DEBUG 01-14 20:42:41.804267.804267 cuda_h.py:10] start all_expert_weight_slices
DEBUG 01-14 20:42:41.805645.805645 cuda_h.py:19] end all_expert_weight_slices cost 0.0009822845458984375 seconds
DEBUG 01-14 20:42:41.805283.805283 cuda_h.py:10] start cpuoutputsdeal
DEBUG 01-14 20:42:41.805834.805834 cuda_h.py:10] start index_scatter
DEBUG 01-14 20:42:41.805784.805784 cuda_h.py:19] end index_scatter cost 5.0067901611328125e-05 seconds
DEBUG 01-14 20:42:41.805647.805647 cuda_h.py:19] end cpuoutputsdeal cost 0.0005550384521484375 seconds
DEBUG 01-14 20:42:41.805272.805272 cuda_h.py:19] end layer_moe_generate_mp_l_20 cost 0.07106161117553711 seconds
DEBUG 01-14 20:42:41.806153.806153 cuda_h.py:19] end prefill_layer cost 0.07696008682250977 seconds
DEBUG 01-14 20:42:41.806526.806526 lmp.py:1551] -------------------------------- end prefill layer 19 --------------------------------
DEBUG 01-14 20:42:41.806182.806182 cuda_h.py:10] start prefill_layer
DEBUG 01-14 20:42:41.806793.806793 lmp.py:1494] -------------------------------- start prefill layer 20 --------------------------------
DEBUG 01-14 20:42:41.806972.806972 cuda_h.py:10] start start_load_qkvogn_s_weight_l_21
DEBUG 01-14 20:42:41.806775.806775 cuda_h.py:10] start start_load_qkvogn_s_weight_l_21
DEBUG 01-14 20:42:41.806909.806909 cuda_h.py:19] end start_load_qkvogn_s_weight_l_21 cost 3.600120544433594e-05 seconds
DEBUG 01-14 20:42:41.806811.806811 cuda_h.py:19] end start_load_qkvogn_s_weight_l_21 cost 7.176399230957031e-05 seconds
DEBUG 01-14 20:42:41.806130.806130 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-14 20:42:41.806960.806960 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-14 20:42:41.806526.806526 cuda_h.py:10] start sllm_worker_task
DEBUG 01-14 20:42:41.807167.807167 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-14 20:42:41.807202.807202 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-14 20:42:41.807102.807102 cuda_h.py:19] end allocate_cuda_memory cost 0.0007302761077880859 seconds
DEBUG 01-14 20:42:41.807481.807481 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-14 20:42:41.807291.807291 sllm_store_c.py:27] get device uuid map
DEBUG 01-14 20:42:41.807259.807259 sllm_store_c.py:29] call client load into gpu
DEBUG 01-14 20:42:41.808723.808723 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 313e666e-8c8e-4f60-a619-c7ce36018b42
DEBUG 01-14 20:42:41.808124.808124 client.py:106] call stub.LoadModelAsync
DEBUG 01-14 20:42:41.808724.808724 cuda_h.py:10] start self_attn
INFO 01-14 20:42:41.808096.808096 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 313e666e-8c8e-4f60-a619-c7ce36018b42
DEBUG 01-14 20:42:41.808131.808131 cuda_h.py:19] end load_into_gpu_async cost 0.0009698867797851562 seconds
DEBUG 01-14 20:42:41.808933.808933 cuda_h.py:10] start restore_tensors2
DEBUG 01-14 20:42:41.809361.809361 cuda_h.py:19] end restore_tensors2 cost 7.891654968261719e-05 seconds
DEBUG 01-14 20:42:41.809686.809686 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0020334720611572266 seconds
INFO 01-14 20:42:41.809960.809960 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 313e666e-8c8e-4f60-a619-c7ce36018b42
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-14 20:42:41.811967.811967 cuda_h.py:19] end self_attn cost 0.002811431884765625 seconds
DEBUG 01-14 20:42:41.811820.811820 mlpmodule.py:1367]  experts func einsum cost 0.06334662437438965 s
DEBUG 01-14 20:42:41.811150.811150 cuda_h.py:19] end iln_self_attn_paln cost 0.005095481872558594 seconds
DEBUG 01-14 20:42:41.811477.811477 cuda_h.py:10] start layer_moe_generate_mp_l_21
DEBUG 01-14 20:42:41.811432.811432 cuda_h.py:10] start gate
DEBUG 01-14 20:42:41.812925.812925 cuda_h.py:19] end gate cost 0.0006444454193115234 seconds
DEBUG 01-14 20:42:41.812808.812808 cuda_h.py:10] start experts_map_get
DEBUG 01-14 20:42:41.813845.813845 lmp.py:1615] 
DEBUG 01-14 20:42:41.813845.813845 lmp.py:1615] Expert Token Distribution & Device Allocation:
DEBUG 01-14 20:42:41.813362.813362 lmp.py:1616]   Total experts: 64
DEBUG 01-14 20:42:41.813774.813774 lmp.py:1617]   CPU experts: 32 (50%)
DEBUG 01-14 20:42:41.813562.813562 lmp.py:1618]   GPU experts: 32 (50%)
DEBUG 01-14 20:42:41.813252.813252 lmp.py:1619] 
DEBUG 01-14 20:42:41.813252.813252 lmp.py:1619]   Expert ID | Tokens | Device
DEBUG 01-14 20:42:41.813418.813418 lmp.py:1620]   -----------------------------------
DEBUG 01-14 20:42:41.813299.813299 lmp.py:1625]   Expert 54 |     27 | CPU
DEBUG 01-14 20:42:41.813465.813465 lmp.py:1625]   Expert  8 |     36 | CPU
DEBUG 01-14 20:42:41.813439.813439 lmp.py:1625]   Expert 28 |     42 | CPU
DEBUG 01-14 20:42:41.813129.813129 lmp.py:1625]   Expert  3 |     43 | CPU
DEBUG 01-14 20:42:41.813295.813295 lmp.py:1625]   Expert 43 |     58 | CPU
DEBUG 01-14 20:42:41.813746.813746 lmp.py:1625]   Expert 63 |     63 | CPU
DEBUG 01-14 20:42:41.813958.813958 lmp.py:1625]   Expert  6 |     82 | CPU
DEBUG 01-14 20:42:41.813932.813932 lmp.py:1625]   Expert 57 |     82 | CPU
DEBUG 01-14 20:42:41.813383.813383 lmp.py:1625]   Expert 38 |     84 | CPU
DEBUG 01-14 20:42:41.813834.813834 lmp.py:1625]   Expert 39 |     91 | CPU
DEBUG 01-14 20:42:41.813808.813808 lmp.py:1625]   Expert 36 |     92 | CPU
DEBUG 01-14 20:42:41.813020.813020 lmp.py:1625]   Expert 41 |     94 | CPU
DEBUG 01-14 20:42:41.813710.813710 lmp.py:1625]   Expert 47 |    102 | CPU
DEBUG 01-14 20:42:41.813684.813684 lmp.py:1625]   Expert 12 |    111 | CPU
DEBUG 01-14 20:42:41.813896.813896 lmp.py:1625]   Expert 19 |    111 | CPU
DEBUG 01-14 20:42:41.813347.813347 lmp.py:1625]   Expert 52 |    113 | CPU
DEBUG 01-14 20:42:41.813560.813560 lmp.py:1625]   Expert 13 |    132 | CPU
DEBUG 01-14 20:42:41.813249.813249 lmp.py:1625]   Expert 22 |    143 | CPU
DEBUG 01-14 20:42:41.813177.813177 lmp.py:1625]   Expert 40 |    145 | CPU
DEBUG 01-14 20:42:41.813866.813866 lmp.py:1625]   Expert 50 |    146 | CPU
DEBUG 01-14 20:42:41.813317.813317 lmp.py:1625]   Expert  2 |    147 | CPU
DEBUG 01-14 20:42:41.813291.813291 lmp.py:1625]   Expert 46 |    149 | CPU
DEBUG 01-14 20:42:41.813503.813503 lmp.py:1625]   Expert 37 |    157 | CPU
DEBUG 01-14 20:42:41.813477.813477 lmp.py:1625]   Expert 53 |    161 | CPU
DEBUG 01-14 20:42:41.813213.813213 lmp.py:1625]   Expert 20 |    164 | CPU
DEBUG 01-14 20:42:41.813571.813571 lmp.py:1625]   Expert 21 |    165 | CPU
DEBUG 01-14 20:42:41.813691.813691 lmp.py:1625]   Expert 14 |    171 | CPU
DEBUG 01-14 20:42:41.813619.813619 lmp.py:1625]   Expert 23 |    171 | CPU
DEBUG 01-14 20:42:41.813546.813546 lmp.py:1625]   Expert 55 |    171 | CPU
DEBUG 01-14 20:42:41.813713.813713 lmp.py:1625]   Expert 24 |    179 | CPU
DEBUG 01-14 20:42:41.813879.813879 lmp.py:1625]   Expert 42 |    180 | CPU
DEBUG 01-14 20:42:41.813806.813806 lmp.py:1625]   Expert 61 |    184 | CPU
DEBUG 01-14 20:42:41.813211.813211 lmp.py:1625]   Expert  0 |    187 | GPU
DEBUG 01-14 20:42:41.813377.813377 lmp.py:1625]   Expert  5 |    191 | GPU
DEBUG 01-14 20:42:41.813259.813259 lmp.py:1625]   Expert 33 |    195 | GPU
DEBUG 01-14 20:42:41.813902.813902 lmp.py:1625]   Expert 49 |    196 | GPU
DEBUG 01-14 20:42:41.813068.813068 lmp.py:1625]   Expert 18 |    199 | GPU
DEBUG 01-14 20:42:41.813472.813472 lmp.py:1625]   Expert 32 |    200 | GPU
DEBUG 01-14 20:42:41.813638.813638 lmp.py:1625]   Expert 16 |    202 | GPU
DEBUG 01-14 20:42:41.813804.813804 lmp.py:1625]   Expert 30 |    202 | GPU
DEBUG 01-14 20:42:41.813209.813209 lmp.py:1625]   Expert 34 |    202 | GPU
DEBUG 01-14 20:42:41.813614.813614 lmp.py:1625]   Expert  7 |    205 | GPU
DEBUG 01-14 20:42:41.813303.813303 lmp.py:1625]   Expert 59 |    211 | GPU
DEBUG 01-14 20:42:41.813231.813231 lmp.py:1625]   Expert 62 |    216 | GPU
DEBUG 01-14 20:42:41.813397.813397 lmp.py:1625]   Expert  9 |    217 | GPU
DEBUG 01-14 20:42:41.813040.813040 lmp.py:1625]   Expert 31 |    219 | GPU
DEBUG 01-14 20:42:41.813921.813921 lmp.py:1625]   Expert 10 |    220 | GPU
DEBUG 01-14 20:42:41.813326.813326 lmp.py:1625]   Expert 60 |    227 | GPU
DEBUG 01-14 20:42:41.813253.813253 lmp.py:1625]   Expert  4 |    231 | GPU
DEBUG 01-14 20:42:41.813181.813181 lmp.py:1625]   Expert 15 |    233 | GPU
DEBUG 01-14 20:42:41.813109.813109 lmp.py:1625]   Expert 17 |    234 | GPU
DEBUG 01-14 20:42:41.814560.814560 lmp.py:1625]   Expert 58 |    236 | GPU
DEBUG 01-14 20:42:41.814249.814249 lmp.py:1625]   Expert 29 |    237 | GPU
DEBUG 01-14 20:42:41.814654.814654 lmp.py:1625]   Expert 26 |    248 | GPU
DEBUG 01-14 20:42:41.814297.814297 lmp.py:1625]   Expert 44 |    271 | GPU
DEBUG 01-14 20:42:41.814224.814224 lmp.py:1625]   Expert 51 |    272 | GPU
DEBUG 01-14 20:42:41.814914.814914 lmp.py:1625]   Expert 11 |    276 | GPU
DEBUG 01-14 20:42:41.814080.814080 lmp.py:1625]   Expert 56 |    284 | GPU
DEBUG 01-14 20:42:41.814007.814007 lmp.py:1625]   Expert 27 |    297 | GPU
DEBUG 01-14 20:42:41.814174.814174 lmp.py:1625]   Expert  1 |    346 | GPU
DEBUG 01-14 20:42:41.814340.814340 lmp.py:1625]   Expert 45 |    363 | GPU
DEBUG 01-14 20:42:41.814506.814506 lmp.py:1625]   Expert 25 |    444 | GPU
DEBUG 01-14 20:42:41.814195.814195 lmp.py:1625]   Expert 35 |    513 | GPU
DEBUG 01-14 20:42:41.814123.814123 lmp.py:1625]   Expert 48 |    718 | GPU
DEBUG 01-14 20:42:41.814243.814243 lmp.py:1626] 
DEBUG 01-14 20:42:41.814243.814243 lmp.py:1626]   CPU total tokens: 3796 (30.9%)
DEBUG 01-14 20:42:41.814362.814362 lmp.py:1627]   GPU total tokens: 8492 (69.1%)
DEBUG 01-14 20:42:41.814297.814297 cuda_h.py:19] end experts_map_get cost 0.0015268325805664062 seconds
DEBUG 01-14 20:42:41.814816.814816 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-14 20:42:41.814613.814613 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-14 20:42:41.814194.814194 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-14 20:42:41.816219.816219 cuda_h.py:19] end allocate_cuda_memory cost 0.001705169677734375 seconds
DEBUG 01-14 20:42:41.816797.816797 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-14 20:42:41.816660.816660 sllm_store_c.py:27] get device uuid map
DEBUG 01-14 20:42:41.816230.816230 sllm_store_c.py:29] call client load into gpu
DEBUG 01-14 20:42:41.816119.816119 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 155a1cd1-afc0-439e-ad79-735f7d99ca31
DEBUG 01-14 20:42:41.816238.816238 client.py:106] call stub.LoadModelAsync
INFO 01-14 20:42:41.816107.816107 client.py:127] Model loaded
DEBUG 01-14 20:42:41.816950.816950 cuda_h.py:10] start restore2model
DEBUG 01-14 20:42:41.817469.817469 cuda_h.py:19] end restore2model cost 0.0004127025604248047 seconds
INFO 01-14 20:42:41.817346.817346 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 155a1cd1-afc0-439e-ad79-735f7d99ca31
DEBUG 01-14 20:42:41.817103.817103 cuda_h.py:19] end sllm_worker_task cost 0.010563135147094727 seconds
DEBUG 01-14 20:42:41.817284.817284 cuda_h.py:19] end load_into_gpu_async cost 0.0012331008911132812 seconds
DEBUG 01-14 20:42:41.817048.817048 cuda_h.py:10] start restore_tensors2
DEBUG 01-14 20:42:41.818874.818874 cuda_h.py:19] end restore_tensors2 cost 0.00033545494079589844 seconds
DEBUG 01-14 20:42:41.818896.818896 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.003696441650390625 seconds
DEBUG 01-14 20:42:41.818758.818758 cuda_h.py:10] start restore2model
DEBUG 01-14 20:42:41.820461.820461 cuda_h.py:19] end restore2model cost 0.0025556087493896484 seconds
DEBUG 01-14 20:42:41.820059.820059 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.00643610954284668 seconds
DEBUG 01-14 20:42:41.820285.820285 cuda_h.py:10] start gpu_sexperts
DEBUG 01-14 20:42:41.821004.821004 cuda_h.py:19] end gpu_sexperts cost 0.0002875328063964844 seconds
DEBUG 01-14 20:42:41.821211.821211 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-14 20:42:41.821583.821583 lmp.py:1683] 
DEBUG 01-14 20:42:41.821583.821583 lmp.py:1683]   Computing 32 experts on CPU...
DEBUG 01-14 20:42:41.821618.821618 cuda_h.py:19] end cpu_experts_submit cost 6.031990051269531e-05 seconds
DEBUG 01-14 20:42:41.821751.821751 cuda_h.py:10] start experts_func_mgpu_group_pad
DEBUG 01-14 20:42:41.831967.831967 mlpmodule.py:1460] group tensors cost 0.009424448013305664 s
DEBUG 01-14 20:42:41.831168.831168 cuda_h.py:10] start move_flat_hidden2cpu
DEBUG 01-14 20:42:41.836300.836300 cuda_h.py:19] end experts_func_mgpu_group_pad cost 0.014726400375366211 seconds
DEBUG 01-14 20:42:41.838781.838781 cuda_h.py:10] start gpu_group_list
DEBUG 01-14 20:42:41.839516.839516 cuda_h.py:19] end gpu_group_list cost 0.0008482933044433594 seconds
DEBUG 01-14 20:42:41.839412.839412 cuda_h.py:19] end move_flat_hidden2cpu cost 0.0077972412109375 seconds
DEBUG 01-14 20:42:41.840150.840150 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-14 20:42:41.840375.840375 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 3.790855407714844e-05 seconds
DEBUG 01-14 20:42:41.840259.840259 cuda_h.py:10] start wait_experts
INFO 01-14 20:42:41.840871.840871 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 155a1cd1-afc0-439e-ad79-735f7d99ca31
DEBUG 01-14 20:42:41.842872.842872 mlpmodule.py:1533] pad cost 0.002343893051147461 s
DEBUG 01-14 20:42:41.842963.842963 mlpmodule.py:1539] create cpu tensor cost 3.981590270996094e-05 s
DEBUG 01-14 20:42:41.844017.844017 mlpmodule.py:1544] move to cpu cost 0.002177000045776367 s
DEBUG 01-14 20:42:41.854413.854413 mlpmodule.py:1558] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-14 20:42:41.854969.854969 mlpmodule.py:1559] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-14 20:42:41.854396.854396 mlpmodule.py:1564] group_w3 first element: 0.039306640625
WARNING 01-14 20:42:41.854586.854586 mlpmodule.py:1574] start einsum2
DEBUG 01-14 20:42:41.872444.872444 mlpmodule.py:1584] group einsum cost 0.028068065643310547 s
INFO 01-14 20:42:41.873919.873919 client.py:127] Model loaded
DEBUG 01-14 20:42:41.873697.873697 cuda_h.py:19] end wait_experts cost 0.032967567443847656 seconds
DEBUG 01-14 20:42:41.873609.873609 cuda_h.py:10] start gpu_experts
DEBUG 01-14 20:42:41.873999.873999 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-14 20:42:41.874761.874761 mlpmodule.py:1593] cpy2cputensor cost 0.0007739067077636719 s
DEBUG 01-14 20:42:41.874095.874095 cuda_h.py:10] start move_outputs
DEBUG 01-14 20:42:41.876903.876903 cuda_h.py:19] end move_outputs cost 0.0021402835845947266 seconds
DEBUG 01-14 20:42:41.880272.880272 cuda_h.py:19] end wait_cetm_experts cost 0.00669097900390625 seconds
DEBUG 01-14 20:42:41.880442.880442 cuda_h.py:10] start gpu_group_einsum_mp_multi_list
DEBUG 01-14 20:42:41.880443.880443 cuda_h.py:10] start gpu_group_tensor
DEBUG 01-14 20:42:41.881525.881525 cuda_h.py:19] end gpu_group_tensor cost 0.00023865699768066406 seconds
DEBUG 01-14 20:42:41.881450.881450 cuda_h.py:10] start gpu_group_einsum
DEBUG 01-14 20:42:41.881594.881594 cuda_h.py:19] end gpu_group_einsum cost 0.0006833076477050781 seconds
DEBUG 01-14 20:42:41.882711.882711 cuda_h.py:10] start gpu_final_hidden_states_scatter
DEBUG 01-14 20:42:41.882522.882522 cuda_h.py:10] start all_expert_outputs_slices
DEBUG 01-14 20:42:41.882502.882502 cuda_h.py:19] end all_expert_outputs_slices cost 0.00036835670471191406 seconds
DEBUG 01-14 20:42:41.882781.882781 cuda_h.py:10] start concat_expert_out
DEBUG 01-14 20:42:41.882579.882579 cuda_h.py:19] end concat_expert_out cost 5.8650970458984375e-05 seconds
DEBUG 01-14 20:42:41.882575.882575 cuda_h.py:10] start index_scatter
DEBUG 01-14 20:42:41.882486.882486 cuda_h.py:19] end index_scatter cost 7.390975952148438e-05 seconds
DEBUG 01-14 20:42:41.882726.882726 cuda_h.py:19] end gpu_final_hidden_states_scatter cost 0.0007660388946533203 seconds
DEBUG 01-14 20:42:41.882980.882980 cuda_h.py:19] end gpu_experts cost 0.00923466682434082 seconds
DEBUG 01-14 20:42:41.882352.882352 cuda_h.py:10] start all_expert_weight_slices
DEBUG 01-14 20:42:41.883285.883285 cuda_h.py:19] end all_expert_weight_slices cost 0.0009379386901855469 seconds
DEBUG 01-14 20:42:41.883439.883439 cuda_h.py:10] start cpuoutputsdeal
DEBUG 01-14 20:42:41.884766.884766 cuda_h.py:10] start index_scatter
DEBUG 01-14 20:42:41.884869.884869 cuda_h.py:19] end index_scatter cost 5.078315734863281e-05 seconds
DEBUG 01-14 20:42:41.884162.884162 cuda_h.py:19] end cpuoutputsdeal cost 0.0006093978881835938 seconds
DEBUG 01-14 20:42:41.884025.884025 cuda_h.py:19] end layer_moe_generate_mp_l_21 cost 0.07270145416259766 seconds
DEBUG 01-14 20:42:41.885953.885953 cuda_h.py:19] end prefill_layer cost 0.07855582237243652 seconds
DEBUG 01-14 20:42:41.885849.885849 lmp.py:1551] -------------------------------- end prefill layer 20 --------------------------------
DEBUG 01-14 20:42:41.885506.885506 cuda_h.py:10] start prefill_layer
DEBUG 01-14 20:42:41.885401.885401 lmp.py:1494] -------------------------------- start prefill layer 21 --------------------------------
DEBUG 01-14 20:42:41.885819.885819 cuda_h.py:10] start start_load_qkvogn_s_weight_l_22
DEBUG 01-14 20:42:41.885383.885383 cuda_h.py:10] start start_load_qkvogn_s_weight_l_22
DEBUG 01-14 20:42:41.885895.885895 cuda_h.py:19] end start_load_qkvogn_s_weight_l_22 cost 3.4332275390625e-05 seconds
DEBUG 01-14 20:42:41.885604.885604 cuda_h.py:19] end start_load_qkvogn_s_weight_l_22 cost 6.866455078125e-05 seconds
DEBUG 01-14 20:42:41.885969.885969 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-14 20:42:41.885469.885469 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-14 20:42:41.885730.885730 cuda_h.py:10] start sllm_worker_task
DEBUG 01-14 20:42:41.885264.885264 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-14 20:42:41.885776.885776 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-14 20:42:41.888193.888193 cuda_h.py:19] end allocate_cuda_memory cost 0.0027267932891845703 seconds
DEBUG 01-14 20:42:41.888288.888288 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-14 20:42:41.888574.888574 sllm_store_c.py:27] get device uuid map
DEBUG 01-14 20:42:41.888403.888403 sllm_store_c.py:29] call client load into gpu
DEBUG 01-14 20:42:41.888868.888868 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 52beaaad-4e12-4254-b4ef-dc0e06af7bcb
DEBUG 01-14 20:42:41.888837.888837 client.py:106] call stub.LoadModelAsync
DEBUG 01-14 20:42:41.889193.889193 cuda_h.py:10] start self_attn
INFO 01-14 20:42:41.889875.889875 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 52beaaad-4e12-4254-b4ef-dc0e06af7bcb
DEBUG 01-14 20:42:41.889838.889838 cuda_h.py:19] end load_into_gpu_async cost 0.0009515285491943359 seconds
DEBUG 01-14 20:42:41.889409.889409 cuda_h.py:10] start restore_tensors2
DEBUG 01-14 20:42:41.889518.889518 cuda_h.py:19] end restore_tensors2 cost 9.036064147949219e-05 seconds
DEBUG 01-14 20:42:41.889844.889844 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.004044055938720703 seconds
INFO 01-14 20:42:41.889270.889270 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 52beaaad-4e12-4254-b4ef-dc0e06af7bcb
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
DEBUG 01-14 20:42:41.892963.892963 mlpmodule.py:1367]  experts func einsum cost 0.07027411460876465 s
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-14 20:42:41.892350.892350 cuda_h.py:19] end self_attn cost 0.003828763961791992 seconds
DEBUG 01-14 20:42:41.893203.893203 cuda_h.py:19] end iln_self_attn_paln cost 0.007932901382446289 seconds
DEBUG 01-14 20:42:41.893245.893245 cuda_h.py:10] start layer_moe_generate_mp_l_22
DEBUG 01-14 20:42:41.893054.893054 cuda_h.py:10] start gate
DEBUG 01-14 20:42:41.894586.894586 cuda_h.py:19] end gate cost 0.0006380081176757812 seconds
DEBUG 01-14 20:42:41.894277.894277 cuda_h.py:10] start experts_map_get
DEBUG 01-14 20:42:41.894890.894890 lmp.py:1615] 
DEBUG 01-14 20:42:41.894890.894890 lmp.py:1615] Expert Token Distribution & Device Allocation:
DEBUG 01-14 20:42:41.894553.894553 lmp.py:1616]   Total experts: 64
DEBUG 01-14 20:42:41.894634.894634 lmp.py:1617]   CPU experts: 32 (50%)
DEBUG 01-14 20:42:41.894376.894376 lmp.py:1618]   GPU experts: 32 (50%)
DEBUG 01-14 20:42:41.894734.894734 lmp.py:1619] 
DEBUG 01-14 20:42:41.894734.894734 lmp.py:1619]   Expert ID | Tokens | Device
DEBUG 01-14 20:42:41.894331.894331 lmp.py:1620]   -----------------------------------
DEBUG 01-14 20:42:41.894643.894643 lmp.py:1625]   Expert 11 |     36 | CPU
DEBUG 01-14 20:42:41.894763.894763 lmp.py:1625]   Expert 44 |     41 | CPU
DEBUG 01-14 20:42:41.894883.894883 lmp.py:1625]   Expert  9 |     43 | CPU
DEBUG 01-14 20:42:41.894764.894764 lmp.py:1625]   Expert 54 |     60 | CPU
DEBUG 01-14 20:42:41.894884.894884 lmp.py:1625]   Expert 56 |     67 | CPU
DEBUG 01-14 20:42:41.894527.894527 lmp.py:1625]   Expert 62 |     91 | CPU
DEBUG 01-14 20:42:41.894931.894931 lmp.py:1625]   Expert 22 |    101 | CPU
DEBUG 01-14 20:42:41.894336.894336 lmp.py:1625]   Expert 47 |    102 | CPU
DEBUG 01-14 20:42:41.894502.894502 lmp.py:1625]   Expert 51 |    102 | CPU
DEBUG 01-14 20:42:41.894906.894906 lmp.py:1625]   Expert 35 |    105 | CPU
DEBUG 01-14 20:42:41.894311.894311 lmp.py:1625]   Expert 52 |    108 | CPU
DEBUG 01-14 20:42:41.894477.894477 lmp.py:1625]   Expert 60 |    108 | CPU
DEBUG 01-14 20:42:41.894882.894882 lmp.py:1625]   Expert 41 |    109 | CPU
DEBUG 01-14 20:42:41.894286.894286 lmp.py:1625]   Expert  7 |    110 | CPU
DEBUG 01-14 20:42:41.894406.894406 lmp.py:1625]   Expert  1 |    113 | CPU
DEBUG 01-14 20:42:41.894811.894811 lmp.py:1625]   Expert  8 |    116 | CPU
DEBUG 01-14 20:42:41.894738.894738 lmp.py:1625]   Expert 48 |    120 | CPU
DEBUG 01-14 20:42:41.894905.894905 lmp.py:1625]   Expert  6 |    127 | CPU
DEBUG 01-14 20:42:41.894832.894832 lmp.py:1625]   Expert  2 |    130 | CPU
DEBUG 01-14 20:42:41.894760.894760 lmp.py:1625]   Expert 32 |    135 | CPU
DEBUG 01-14 20:42:41.894688.894688 lmp.py:1625]   Expert 23 |    137 | CPU
DEBUG 01-14 20:42:41.894092.894092 lmp.py:1625]   Expert 53 |    137 | CPU
DEBUG 01-14 20:42:41.894450.894450 lmp.py:1625]   Expert 27 |    144 | CPU
DEBUG 01-14 20:42:41.895617.895617 lmp.py:1625]   Expert 50 |    145 | CPU
DEBUG 01-14 20:42:41.895544.895544 lmp.py:1625]   Expert 59 |    146 | CPU
DEBUG 01-14 20:42:41.895710.895710 lmp.py:1625]   Expert 49 |    148 | CPU
DEBUG 01-14 20:42:41.895638.895638 lmp.py:1625]   Expert 14 |    150 | CPU
DEBUG 01-14 20:42:41.895566.895566 lmp.py:1625]   Expert 39 |    152 | CPU
DEBUG 01-14 20:42:41.895494.895494 lmp.py:1625]   Expert 26 |    155 | CPU
DEBUG 01-14 20:42:41.895898.895898 lmp.py:1625]   Expert 34 |    160 | CPU
DEBUG 01-14 20:42:41.895303.895303 lmp.py:1625]   Expert 38 |    163 | CPU
DEBUG 01-14 20:42:41.895230.895230 lmp.py:1625]   Expert 24 |    167 | CPU
DEBUG 01-14 20:42:41.895635.895635 lmp.py:1625]   Expert  4 |    175 | GPU
DEBUG 01-14 20:42:41.895801.895801 lmp.py:1625]   Expert 40 |    182 | GPU
DEBUG 01-14 20:42:41.895967.895967 lmp.py:1625]   Expert 57 |    183 | GPU
DEBUG 01-14 20:42:41.895895.895895 lmp.py:1625]   Expert  0 |    185 | GPU
DEBUG 01-14 20:42:41.895823.895823 lmp.py:1625]   Expert 61 |    188 | GPU
DEBUG 01-14 20:42:41.895512.895512 lmp.py:1625]   Expert 46 |    190 | GPU
DEBUG 01-14 20:42:41.895155.895155 lmp.py:1625]   Expert 43 |    192 | GPU
DEBUG 01-14 20:42:41.895798.895798 lmp.py:1625]   Expert 63 |    193 | GPU
DEBUG 01-14 20:42:41.895726.895726 lmp.py:1625]   Expert 13 |    197 | GPU
DEBUG 01-14 20:42:41.895653.895653 lmp.py:1625]   Expert 19 |    197 | GPU
DEBUG 01-14 20:42:41.895581.895581 lmp.py:1625]   Expert  5 |    207 | GPU
DEBUG 01-14 20:42:41.895270.895270 lmp.py:1625]   Expert 29 |    209 | GPU
DEBUG 01-14 20:42:41.895675.895675 lmp.py:1625]   Expert 31 |    214 | GPU
DEBUG 01-14 20:42:41.895603.895603 lmp.py:1625]   Expert 33 |    221 | GPU
DEBUG 01-14 20:42:41.895769.895769 lmp.py:1625]   Expert 16 |    240 | GPU
DEBUG 01-14 20:42:41.895220.895220 lmp.py:1625]   Expert 37 |    242 | GPU
DEBUG 01-14 20:42:41.895147.895147 lmp.py:1625]   Expert 20 |    256 | GPU
DEBUG 01-14 20:42:41.895837.895837 lmp.py:1625]   Expert  3 |    259 | GPU
DEBUG 01-14 20:42:41.895526.895526 lmp.py:1625]   Expert 15 |    267 | GPU
DEBUG 01-14 20:42:41.895215.895215 lmp.py:1625]   Expert 36 |    271 | GPU
DEBUG 01-14 20:42:41.895620.895620 lmp.py:1625]   Expert 18 |    285 | GPU
DEBUG 01-14 20:42:41.895786.895786 lmp.py:1625]   Expert 17 |    310 | GPU
DEBUG 01-14 20:42:41.895952.895952 lmp.py:1625]   Expert 30 |    313 | GPU
DEBUG 01-14 20:42:41.895641.895641 lmp.py:1625]   Expert 55 |    315 | GPU
DEBUG 01-14 20:42:41.895569.895569 lmp.py:1625]   Expert 12 |    322 | GPU
DEBUG 01-14 20:42:41.895497.895497 lmp.py:1625]   Expert 28 |    324 | GPU
DEBUG 01-14 20:42:41.895425.895425 lmp.py:1625]   Expert 58 |    328 | GPU
DEBUG 01-14 20:42:41.895876.895876 lmp.py:1625]   Expert 25 |    371 | GPU
DEBUG 01-14 20:42:41.895518.895518 lmp.py:1625]   Expert 10 |    375 | GPU
DEBUG 01-14 20:42:41.895923.895923 lmp.py:1625]   Expert 45 |    380 | GPU
DEBUG 01-14 20:42:41.895851.895851 lmp.py:1625]   Expert 21 |    385 | GPU
DEBUG 01-14 20:42:41.895540.895540 lmp.py:1625]   Expert 42 |    584 | GPU
DEBUG 01-14 20:42:41.895183.895183 lmp.py:1626] 
DEBUG 01-14 20:42:41.895183.895183 lmp.py:1626]   CPU total tokens: 3728 (30.3%)
DEBUG 01-14 20:42:41.895018.895018 lmp.py:1627]   GPU total tokens: 8560 (69.7%)
DEBUG 01-14 20:42:41.895191.895191 cuda_h.py:19] end experts_map_get cost 0.0015566349029541016 seconds
DEBUG 01-14 20:42:41.895756.895756 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-14 20:42:41.895553.895553 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-14 20:42:41.896750.896750 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-14 20:42:41.896475.896475 cuda_h.py:19] end allocate_cuda_memory cost 0.0002548694610595703 seconds
DEBUG 01-14 20:42:41.896894.896894 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-14 20:42:41.896518.896518 sllm_store_c.py:27] get device uuid map
DEBUG 01-14 20:42:41.896327.896327 sllm_store_c.py:29] call client load into gpu
DEBUG 01-14 20:42:41.896977.896977 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 894737bd-c47b-4bf4-be5c-46cafe73b7ef
DEBUG 01-14 20:42:41.896718.896718 client.py:106] call stub.LoadModelAsync
INFO 01-14 20:42:41.896956.896956 client.py:127] Model loaded
DEBUG 01-14 20:42:41.896501.896501 cuda_h.py:10] start restore2model
DEBUG 01-14 20:42:41.897344.897344 cuda_h.py:19] end restore2model cost 0.0004131793975830078 seconds
DEBUG 01-14 20:42:41.897504.897504 cuda_h.py:19] end sllm_worker_task cost 0.011738777160644531 seconds
INFO 01-14 20:42:41.897818.897818 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 894737bd-c47b-4bf4-be5c-46cafe73b7ef
DEBUG 01-14 20:42:41.897807.897807 cuda_h.py:19] end load_into_gpu_async cost 0.001123666763305664 seconds
DEBUG 01-14 20:42:41.897033.897033 cuda_h.py:10] start restore_tensors2
DEBUG 01-14 20:42:41.897575.897575 cuda_h.py:19] end restore_tensors2 cost 0.00033855438232421875 seconds
DEBUG 01-14 20:42:41.897928.897928 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0020787715911865234 seconds
DEBUG 01-14 20:42:41.898883.898883 cuda_h.py:10] start restore2model
DEBUG 01-14 20:42:41.900632.900632 cuda_h.py:19] end restore2model cost 0.0025599002838134766 seconds
DEBUG 01-14 20:42:41.900852.900852 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.00481724739074707 seconds
DEBUG 01-14 20:42:41.900986.900986 cuda_h.py:10] start gpu_sexperts
DEBUG 01-14 20:42:41.901691.901691 cuda_h.py:19] end gpu_sexperts cost 0.00027871131896972656 seconds
DEBUG 01-14 20:42:41.901945.901945 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-14 20:42:41.901078.901078 lmp.py:1683] 
DEBUG 01-14 20:42:41.901078.901078 lmp.py:1683]   Computing 32 experts on CPU...
DEBUG 01-14 20:42:41.901298.901298 cuda_h.py:19] end cpu_experts_submit cost 5.7220458984375e-05 seconds
DEBUG 01-14 20:42:41.901902.901902 cuda_h.py:10] start experts_func_mgpu_group_pad
DEBUG 01-14 20:42:41.911649.911649 mlpmodule.py:1460] group tensors cost 0.009338140487670898 s
DEBUG 01-14 20:42:41.911035.911035 cuda_h.py:10] start move_flat_hidden2cpu
DEBUG 01-14 20:42:41.916899.916899 cuda_h.py:19] end experts_func_mgpu_group_pad cost 0.015480279922485352 seconds
DEBUG 01-14 20:42:41.918819.918819 cuda_h.py:19] end move_flat_hidden2cpu cost 0.006935834884643555 seconds
DEBUG 01-14 20:42:41.919434.919434 cuda_h.py:10] start gpu_group_list
DEBUG 01-14 20:42:41.920017.920017 cuda_h.py:19] end gpu_group_list cost 0.0008254051208496094 seconds
DEBUG 01-14 20:42:41.920359.920359 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-14 20:42:41.921861.921861 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 3.1948089599609375e-05 seconds
DEBUG 01-14 20:42:41.921996.921996 cuda_h.py:10] start wait_experts
INFO 01-14 20:42:41.921693.921693 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 894737bd-c47b-4bf4-be5c-46cafe73b7ef
DEBUG 01-14 20:42:41.922662.922662 mlpmodule.py:1533] pad cost 0.0036835670471191406 s
DEBUG 01-14 20:42:41.922217.922217 mlpmodule.py:1539] create cpu tensor cost 4.2438507080078125e-05 s
DEBUG 01-14 20:42:41.924391.924391 mlpmodule.py:1544] move to cpu cost 0.001978635787963867 s
DEBUG 01-14 20:42:41.934314.934314 mlpmodule.py:1558] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-14 20:42:41.934664.934664 mlpmodule.py:1559] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-14 20:42:41.934522.934522 mlpmodule.py:1564] group_w3 first element: 0.00066375732421875
WARNING 01-14 20:42:41.934573.934573 mlpmodule.py:1574] start einsum2
DEBUG 01-14 20:42:41.952857.952857 mlpmodule.py:1584] group einsum cost 0.02765178680419922 s
INFO 01-14 20:42:41.953587.953587 client.py:127] Model loaded
DEBUG 01-14 20:42:41.953129.953129 mlpmodule.py:1593] cpy2cputensor cost 0.0009632110595703125 s
DEBUG 01-14 20:42:41.953664.953664 cuda_h.py:19] end wait_experts cost 0.032536983489990234 seconds
DEBUG 01-14 20:42:41.953058.953058 cuda_h.py:10] start move_outputs
DEBUG 01-14 20:42:41.953008.953008 cuda_h.py:10] start gpu_experts
DEBUG 01-14 20:42:41.954921.954921 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-14 20:42:41.956329.956329 cuda_h.py:19] end move_outputs cost 0.001961231231689453 seconds
DEBUG 01-14 20:42:41.960529.960529 cuda_h.py:19] end wait_cetm_experts cost 0.006014823913574219 seconds
DEBUG 01-14 20:42:41.960592.960592 cuda_h.py:10] start gpu_group_einsum_mp_multi_list
DEBUG 01-14 20:42:41.960005.960005 cuda_h.py:10] start gpu_group_tensor
DEBUG 01-14 20:42:41.960623.960623 cuda_h.py:19] end gpu_group_tensor cost 0.0002460479736328125 seconds
DEBUG 01-14 20:42:41.960362.960362 cuda_h.py:10] start gpu_group_einsum
DEBUG 01-14 20:42:41.961858.961858 cuda_h.py:19] end gpu_group_einsum cost 0.0006983280181884766 seconds
DEBUG 01-14 20:42:41.961532.961532 cuda_h.py:10] start gpu_final_hidden_states_scatter
DEBUG 01-14 20:42:41.961772.961772 cuda_h.py:10] start all_expert_outputs_slices
DEBUG 01-14 20:42:41.962700.962700 cuda_h.py:19] end all_expert_outputs_slices cost 0.00036525726318359375 seconds
DEBUG 01-14 20:42:41.962025.962025 cuda_h.py:10] start concat_expert_out
DEBUG 01-14 20:42:41.962393.962393 cuda_h.py:19] end concat_expert_out cost 5.841255187988281e-05 seconds
DEBUG 01-14 20:42:41.962150.962150 cuda_h.py:10] start index_scatter
DEBUG 01-14 20:42:41.962207.962207 cuda_h.py:19] end index_scatter cost 7.653236389160156e-05 seconds
DEBUG 01-14 20:42:41.962969.962969 cuda_h.py:19] end gpu_final_hidden_states_scatter cost 0.0007605552673339844 seconds
DEBUG 01-14 20:42:41.962409.962409 cuda_h.py:19] end gpu_experts cost 0.008454561233520508 seconds
DEBUG 01-14 20:42:41.962304.962304 cuda_h.py:10] start all_expert_weight_slices
DEBUG 01-14 20:42:41.963098.963098 cuda_h.py:19] end all_expert_weight_slices cost 0.0009410381317138672 seconds
DEBUG 01-14 20:42:41.963206.963206 cuda_h.py:10] start cpuoutputsdeal
DEBUG 01-14 20:42:41.964141.964141 cuda_h.py:10] start index_scatter
DEBUG 01-14 20:42:41.964469.964469 cuda_h.py:19] end index_scatter cost 4.9591064453125e-05 seconds
DEBUG 01-14 20:42:41.964570.964570 cuda_h.py:19] end cpuoutputsdeal cost 0.0005555152893066406 seconds
DEBUG 01-14 20:42:41.964479.964479 cuda_h.py:19] end layer_moe_generate_mp_l_22 cost 0.07085728645324707 seconds
DEBUG 01-14 20:42:41.964507.964507 cuda_h.py:19] end prefill_layer cost 0.07953238487243652 seconds
DEBUG 01-14 20:42:41.964251.964251 lmp.py:1551] -------------------------------- end prefill layer 21 --------------------------------
DEBUG 01-14 20:42:41.964146.964146 cuda_h.py:10] start prefill_layer
DEBUG 01-14 20:42:41.964803.964803 lmp.py:1494] -------------------------------- start prefill layer 22 --------------------------------
DEBUG 01-14 20:42:41.964459.964459 cuda_h.py:10] start start_load_qkvogn_s_weight_l_23
DEBUG 01-14 20:42:41.964023.964023 cuda_h.py:10] start start_load_qkvogn_s_weight_l_23
DEBUG 01-14 20:42:41.964442.964442 cuda_h.py:19] end start_load_qkvogn_s_weight_l_23 cost 3.504753112792969e-05 seconds
DEBUG 01-14 20:42:41.964722.964722 cuda_h.py:19] end start_load_qkvogn_s_weight_l_23 cost 6.771087646484375e-05 seconds
DEBUG 01-14 20:42:41.965517.965517 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-14 20:42:41.965897.965897 cuda_h.py:10] start sllm_worker_task
DEBUG 01-14 20:42:41.965538.965538 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-14 20:42:41.965414.965414 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-14 20:42:41.965365.965365 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-14 20:42:41.968589.968589 cuda_h.py:19] end allocate_cuda_memory cost 0.0026869773864746094 seconds
DEBUG 01-14 20:42:41.968638.968638 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-14 20:42:41.968692.968692 sllm_store_c.py:27] get device uuid map
DEBUG 01-14 20:42:41.968661.968661 sllm_store_c.py:29] call client load into gpu
DEBUG 01-14 20:42:41.968317.968317 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, ed0701f5-e56e-4198-b1d8-46cac75e0573
DEBUG 01-14 20:42:41.968254.968254 client.py:106] call stub.LoadModelAsync
DEBUG 01-14 20:42:41.968573.968573 cuda_h.py:10] start self_attn
INFO 01-14 20:42:41.969175.969175 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, ed0701f5-e56e-4198-b1d8-46cac75e0573
DEBUG 01-14 20:42:41.969342.969342 cuda_h.py:19] end load_into_gpu_async cost 0.0010046958923339844 seconds
DEBUG 01-14 20:42:41.969422.969422 cuda_h.py:10] start restore_tensors2
DEBUG 01-14 20:42:41.969743.969743 cuda_h.py:19] end restore_tensors2 cost 7.033348083496094e-05 seconds
DEBUG 01-14 20:42:41.969353.969353 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.004022359848022461 seconds
INFO 01-14 20:42:41.969289.969289 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, ed0701f5-e56e-4198-b1d8-46cac75e0573
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
DEBUG 01-14 20:42:41.971696.971696 mlpmodule.py:1367]  experts func einsum cost 0.07010388374328613 s
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-14 20:42:41.972001.972001 cuda_h.py:19] end self_attn cost 0.0036063194274902344 seconds
DEBUG 01-14 20:42:41.972873.972873 cuda_h.py:19] end iln_self_attn_paln cost 0.0078105926513671875 seconds
DEBUG 01-14 20:42:41.972537.972537 cuda_h.py:10] start layer_moe_generate_mp_l_23
DEBUG 01-14 20:42:41.972254.972254 cuda_h.py:10] start gate
DEBUG 01-14 20:42:41.973369.973369 cuda_h.py:19] end gate cost 0.0006468296051025391 seconds
DEBUG 01-14 20:42:41.973444.973444 cuda_h.py:10] start experts_map_get
DEBUG 01-14 20:42:41.974626.974626 lmp.py:1615] 
DEBUG 01-14 20:42:41.974626.974626 lmp.py:1615] Expert Token Distribution & Device Allocation:
DEBUG 01-14 20:42:41.974005.974005 lmp.py:1616]   Total experts: 64
DEBUG 01-14 20:42:41.974801.974801 lmp.py:1617]   CPU experts: 32 (50%)
DEBUG 01-14 20:42:41.974305.974305 lmp.py:1618]   GPU experts: 32 (50%)
DEBUG 01-14 20:42:41.974186.974186 lmp.py:1619] 
DEBUG 01-14 20:42:41.974186.974186 lmp.py:1619]   Expert ID | Tokens | Device
DEBUG 01-14 20:42:41.974067.974067 lmp.py:1620]   -----------------------------------
DEBUG 01-14 20:42:41.974333.974333 lmp.py:1625]   Expert 25 |     16 | CPU
DEBUG 01-14 20:42:41.974453.974453 lmp.py:1625]   Expert 45 |     33 | CPU
DEBUG 01-14 20:42:41.974096.974096 lmp.py:1625]   Expert 48 |     38 | CPU
DEBUG 01-14 20:42:41.974739.974739 lmp.py:1625]   Expert  9 |     62 | CPU
DEBUG 01-14 20:42:41.974143.974143 lmp.py:1625]   Expert 43 |     69 | CPU
DEBUG 01-14 20:42:41.974740.974740 lmp.py:1625]   Expert 54 |     78 | CPU
DEBUG 01-14 20:42:41.974621.974621 lmp.py:1625]   Expert 47 |     87 | CPU
DEBUG 01-14 20:42:41.974264.974264 lmp.py:1625]   Expert 50 |     88 | CPU
DEBUG 01-14 20:42:41.974669.974669 lmp.py:1625]   Expert  0 |     93 | CPU
DEBUG 01-14 20:42:41.974073.974073 lmp.py:1625]   Expert  1 |     93 | CPU
DEBUG 01-14 20:42:41.974478.974478 lmp.py:1625]   Expert  6 |     93 | CPU
DEBUG 01-14 20:42:41.974882.974882 lmp.py:1625]   Expert 20 |    100 | CPU
DEBUG 01-14 20:42:41.974049.974049 lmp.py:1625]   Expert 62 |    102 | CPU
DEBUG 01-14 20:42:41.974692.974692 lmp.py:1625]   Expert 13 |    103 | CPU
DEBUG 01-14 20:42:41.974096.974096 lmp.py:1625]   Expert 15 |    103 | CPU
DEBUG 01-14 20:42:41.974262.974262 lmp.py:1625]   Expert 36 |    111 | CPU
DEBUG 01-14 20:42:41.974190.974190 lmp.py:1625]   Expert 61 |    112 | CPU
DEBUG 01-14 20:42:41.974595.974595 lmp.py:1625]   Expert 37 |    117 | CPU
DEBUG 01-14 20:42:41.974761.974761 lmp.py:1625]   Expert 21 |    119 | CPU
DEBUG 01-14 20:42:41.974688.974688 lmp.py:1625]   Expert 57 |    119 | CPU
DEBUG 01-14 20:42:41.974855.974855 lmp.py:1625]   Expert 46 |    122 | CPU
DEBUG 01-14 20:42:41.974544.974544 lmp.py:1625]   Expert 38 |    125 | CPU
DEBUG 01-14 20:42:41.974948.974948 lmp.py:1625]   Expert  7 |    130 | CPU
DEBUG 01-14 20:42:41.974876.974876 lmp.py:1625]   Expert 24 |    141 | CPU
DEBUG 01-14 20:42:41.974519.974519 lmp.py:1625]   Expert 42 |    144 | CPU
DEBUG 01-14 20:42:41.974685.974685 lmp.py:1625]   Expert 14 |    146 | CPU
DEBUG 01-14 20:42:41.974851.974851 lmp.py:1625]   Expert 26 |    152 | CPU
DEBUG 01-14 20:42:41.974779.974779 lmp.py:1625]   Expert 31 |    153 | CPU
DEBUG 01-14 20:42:41.974707.974707 lmp.py:1625]   Expert 10 |    158 | CPU
DEBUG 01-14 20:42:41.974634.974634 lmp.py:1625]   Expert  2 |    159 | CPU
DEBUG 01-14 20:42:41.974801.974801 lmp.py:1625]   Expert 11 |    162 | CPU
DEBUG 01-14 20:42:41.974490.974490 lmp.py:1625]   Expert 44 |    163 | CPU
DEBUG 01-14 20:42:41.974133.974133 lmp.py:1625]   Expert 52 |    169 | GPU
DEBUG 01-14 20:42:41.974299.974299 lmp.py:1625]   Expert  3 |    176 | GPU
DEBUG 01-14 20:42:41.974227.974227 lmp.py:1625]   Expert 32 |    176 | GPU
DEBUG 01-14 20:42:41.974916.974916 lmp.py:1625]   Expert 28 |    178 | GPU
DEBUG 01-14 20:42:41.974605.974605 lmp.py:1625]   Expert 35 |    180 | GPU
DEBUG 01-14 20:42:41.974772.974772 lmp.py:1625]   Expert 19 |    192 | GPU
DEBUG 01-14 20:42:41.974938.974938 lmp.py:1625]   Expert 12 |    195 | GPU
DEBUG 01-14 20:42:41.974627.974627 lmp.py:1625]   Expert  8 |    200 | GPU
DEBUG 01-14 20:42:41.974555.974555 lmp.py:1625]   Expert 56 |    205 | GPU
DEBUG 01-14 20:42:41.974959.974959 lmp.py:1625]   Expert 60 |    213 | GPU
DEBUG 01-14 20:42:41.974125.974125 lmp.py:1625]   Expert 41 |    214 | GPU
DEBUG 01-14 20:42:41.974053.974053 lmp.py:1625]   Expert 59 |    214 | GPU
DEBUG 01-14 20:42:41.974458.974458 lmp.py:1625]   Expert  4 |    222 | GPU
DEBUG 01-14 20:42:41.974385.974385 lmp.py:1625]   Expert 16 |    229 | GPU
DEBUG 01-14 20:42:41.974267.974267 lmp.py:1625]   Expert 40 |    235 | GPU
DEBUG 01-14 20:42:41.974671.974671 lmp.py:1625]   Expert 55 |    239 | GPU
DEBUG 01-14 20:42:41.974837.974837 lmp.py:1625]   Expert 23 |    243 | GPU
DEBUG 01-14 20:42:41.975288.975288 lmp.py:1625]   Expert 53 |    250 | GPU
DEBUG 01-14 20:42:41.975454.975454 lmp.py:1625]   Expert 58 |    255 | GPU
DEBUG 01-14 20:42:41.975144.975144 lmp.py:1625]   Expert 51 |    257 | GPU
DEBUG 01-14 20:42:41.975071.975071 lmp.py:1625]   Expert 49 |    259 | GPU
DEBUG 01-14 20:42:41.975238.975238 lmp.py:1625]   Expert 18 |    276 | GPU
DEBUG 01-14 20:42:41.975881.975881 lmp.py:1625]   Expert 34 |    277 | GPU
DEBUG 01-14 20:42:41.975285.975285 lmp.py:1625]   Expert 29 |    286 | GPU
DEBUG 01-14 20:42:41.975213.975213 lmp.py:1625]   Expert 63 |    296 | GPU
DEBUG 01-14 20:42:41.975141.975141 lmp.py:1625]   Expert 39 |    381 | GPU
DEBUG 01-14 20:42:41.975068.975068 lmp.py:1625]   Expert 27 |    386 | GPU
DEBUG 01-14 20:42:41.975758.975758 lmp.py:1625]   Expert 33 |    398 | GPU
DEBUG 01-14 20:42:41.975924.975924 lmp.py:1625]   Expert 22 |    410 | GPU
DEBUG 01-14 20:42:41.975851.975851 lmp.py:1625]   Expert 17 |    414 | GPU
DEBUG 01-14 20:42:41.975494.975494 lmp.py:1625]   Expert 30 |    479 | GPU
DEBUG 01-14 20:42:41.975899.975899 lmp.py:1625]   Expert  5 |    693 | GPU
DEBUG 01-14 20:42:41.975257.975257 lmp.py:1626] 
DEBUG 01-14 20:42:41.975257.975257 lmp.py:1626]   CPU total tokens: 3491 (28.4%)
DEBUG 01-14 20:42:41.975854.975854 lmp.py:1627]   GPU total tokens: 8797 (71.6%)
DEBUG 01-14 20:42:41.975027.975027 cuda_h.py:19] end experts_map_get cost 0.0015599727630615234 seconds
DEBUG 01-14 20:42:41.975592.975592 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-14 20:42:41.975104.975104 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-14 20:42:41.975678.975678 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-14 20:42:41.975618.975618 cuda_h.py:19] end allocate_cuda_memory cost 0.0003445148468017578 seconds
DEBUG 01-14 20:42:41.976753.976753 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-14 20:42:41.976555.976555 sllm_store_c.py:27] get device uuid map
DEBUG 01-14 20:42:41.976172.976172 sllm_store_c.py:29] call client load into gpu
DEBUG 01-14 20:42:41.976583.976583 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 631cfd1f-7aef-4399-b900-22f741b70d6f
DEBUG 01-14 20:42:41.976318.976318 client.py:106] call stub.LoadModelAsync
INFO 01-14 20:42:41.976756.976756 client.py:127] Model loaded
DEBUG 01-14 20:42:41.976592.976592 cuda_h.py:10] start restore2model
DEBUG 01-14 20:42:41.976783.976783 cuda_h.py:19] end restore2model cost 0.00032019615173339844 seconds
DEBUG 01-14 20:42:41.976168.976168 cuda_h.py:19] end sllm_worker_task cost 0.011667013168334961 seconds
INFO 01-14 20:42:41.977260.977260 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 631cfd1f-7aef-4399-b900-22f741b70d6f
DEBUG 01-14 20:42:41.977633.977633 cuda_h.py:19] end load_into_gpu_async cost 0.0011429786682128906 seconds
DEBUG 01-14 20:42:41.977813.977813 cuda_h.py:10] start restore_tensors2
DEBUG 01-14 20:42:41.977971.977971 cuda_h.py:19] end restore_tensors2 cost 0.00033593177795410156 seconds
DEBUG 01-14 20:42:41.977237.977237 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.002182483673095703 seconds
DEBUG 01-14 20:42:41.977861.977861 cuda_h.py:10] start restore2model
DEBUG 01-14 20:42:41.980100.980100 cuda_h.py:19] end restore2model cost 0.002570629119873047 seconds
DEBUG 01-14 20:42:41.980506.980506 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.004929542541503906 seconds
DEBUG 01-14 20:42:41.980110.980110 cuda_h.py:10] start gpu_sexperts
DEBUG 01-14 20:42:41.980160.980160 cuda_h.py:19] end gpu_sexperts cost 0.00028705596923828125 seconds
DEBUG 01-14 20:42:41.980698.980698 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-14 20:42:41.980746.980746 lmp.py:1683] 
DEBUG 01-14 20:42:41.980746.980746 lmp.py:1683]   Computing 32 experts on CPU...
DEBUG 01-14 20:42:41.980158.980158 cuda_h.py:19] end cpu_experts_submit cost 5.841255187988281e-05 seconds
DEBUG 01-14 20:42:41.980729.980729 cuda_h.py:10] start experts_func_mgpu_group_pad
DEBUG 01-14 20:42:41.989447.989447 mlpmodule.py:1460] group tensors cost 0.008399248123168945 s
DEBUG 01-14 20:42:41.990299.990299 cuda_h.py:10] start move_flat_hidden2cpu
DEBUG 01-14 20:42:41.995325.995325 cuda_h.py:19] end experts_func_mgpu_group_pad cost 0.014765262603759766 seconds
DEBUG 01-14 20:42:41.997021.997021 cuda_h.py:19] end move_flat_hidden2cpu cost 0.007074832916259766 seconds
DEBUG 01-14 20:42:41.999743.999743 cuda_h.py:10] start gpu_group_list
DEBUG 01-14 20:42:41.999015.999015 cuda_h.py:19] end gpu_group_list cost 0.0006535053253173828 seconds
DEBUG 01-14 20:42:42.000156.000156 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-14 20:42:42.000550.000550 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.5987625122070312e-05 seconds
DEBUG 01-14 20:42:42.000380.000380 cuda_h.py:10] start wait_experts
INFO 01-14 20:42:42.000348.000348 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 631cfd1f-7aef-4399-b900-22f741b70d6f
DEBUG 01-14 20:42:42.001659.001659 mlpmodule.py:1533] pad cost 0.0037076473236083984 s
DEBUG 01-14 20:42:42.001796.001796 mlpmodule.py:1539] create cpu tensor cost 3.886222839355469e-05 s
DEBUG 01-14 20:42:42.003227.003227 mlpmodule.py:1544] move to cpu cost 0.001928567886352539 s
DEBUG 01-14 20:42:42.012352.012352 mlpmodule.py:1558] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-14 20:42:42.012901.012901 mlpmodule.py:1559] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-14 20:42:42.012858.012858 mlpmodule.py:1564] group_w3 first element: -0.018798828125
WARNING 01-14 20:42:42.013678.013678 mlpmodule.py:1574] start einsum2
DEBUG 01-14 20:42:42.030834.030834 mlpmodule.py:1584] group einsum cost 0.02753734588623047 s
DEBUG 01-14 20:42:42.031177.031177 mlpmodule.py:1593] cpy2cputensor cost 0.0007135868072509766 s
DEBUG 01-14 20:42:42.031358.031358 cuda_h.py:10] start move_outputs
INFO 01-14 20:42:42.032013.032013 client.py:127] Model loaded
DEBUG 01-14 20:42:42.032794.032794 cuda_h.py:19] end wait_experts cost 0.03247237205505371 seconds
DEBUG 01-14 20:42:42.032232.032232 cuda_h.py:10] start gpu_experts
DEBUG 01-14 20:42:42.032863.032863 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-14 20:42:42.033119.033119 cuda_h.py:19] end move_outputs cost 0.0019173622131347656 seconds
DEBUG 01-14 20:42:42.037403.037403 cuda_h.py:19] end wait_cetm_experts cost 0.0050237178802490234 seconds
DEBUG 01-14 20:42:42.038036.038036 cuda_h.py:10] start gpu_group_einsum_mp_multi_list
DEBUG 01-14 20:42:42.038514.038514 cuda_h.py:10] start gpu_group_tensor
DEBUG 01-14 20:42:42.038404.038404 cuda_h.py:19] end gpu_group_tensor cost 0.00023865699768066406 seconds
DEBUG 01-14 20:42:42.038044.038044 cuda_h.py:10] start gpu_group_einsum
DEBUG 01-14 20:42:42.039691.039691 cuda_h.py:19] end gpu_group_einsum cost 0.0006682872772216797 seconds
DEBUG 01-14 20:42:42.039656.039656 cuda_h.py:10] start gpu_final_hidden_states_scatter
DEBUG 01-14 20:42:42.039659.039659 cuda_h.py:10] start all_expert_outputs_slices
DEBUG 01-14 20:42:42.039593.039593 cuda_h.py:19] end all_expert_outputs_slices cost 0.00036644935607910156 seconds
DEBUG 01-14 20:42:42.039633.039633 cuda_h.py:10] start concat_expert_out
DEBUG 01-14 20:42:42.039524.039524 cuda_h.py:19] end concat_expert_out cost 5.817413330078125e-05 seconds
DEBUG 01-14 20:42:42.040520.040520 cuda_h.py:10] start index_scatter
DEBUG 01-14 20:42:42.040477.040477 cuda_h.py:19] end index_scatter cost 7.271766662597656e-05 seconds
DEBUG 01-14 20:42:42.040101.040101 cuda_h.py:19] end gpu_final_hidden_states_scatter cost 0.0007655620574951172 seconds
DEBUG 01-14 20:42:42.040779.040779 cuda_h.py:19] end gpu_experts cost 0.00739741325378418 seconds
DEBUG 01-14 20:42:42.040482.040482 cuda_h.py:10] start all_expert_weight_slices
DEBUG 01-14 20:42:42.041013.041013 cuda_h.py:19] end all_expert_weight_slices cost 0.000990152359008789 seconds
DEBUG 01-14 20:42:42.041696.041696 cuda_h.py:10] start cpuoutputsdeal
DEBUG 01-14 20:42:42.041141.041141 cuda_h.py:10] start index_scatter
DEBUG 01-14 20:42:42.041185.041185 cuda_h.py:19] end index_scatter cost 4.982948303222656e-05 seconds
DEBUG 01-14 20:42:42.041570.041570 cuda_h.py:19] end cpuoutputsdeal cost 0.0005445480346679688 seconds
DEBUG 01-14 20:42:42.042672.042672 cuda_h.py:19] end layer_moe_generate_mp_l_23 cost 0.0690622329711914 seconds
DEBUG 01-14 20:42:42.042924.042924 cuda_h.py:19] end prefill_layer cost 0.07757759094238281 seconds
DEBUG 01-14 20:42:42.042104.042104 lmp.py:1551] -------------------------------- end prefill layer 22 --------------------------------
DEBUG 01-14 20:42:42.042046.042046 cuda_h.py:10] start prefill_layer
DEBUG 01-14 20:42:42.042179.042179 lmp.py:1494] -------------------------------- start prefill layer 23 --------------------------------
DEBUG 01-14 20:42:42.042836.042836 cuda_h.py:10] start start_load_qkvogn_s_weight_l_24
DEBUG 01-14 20:42:42.042400.042400 cuda_h.py:10] start start_load_qkvogn_s_weight_l_24
DEBUG 01-14 20:42:42.042773.042773 cuda_h.py:19] end start_load_qkvogn_s_weight_l_24 cost 3.647804260253906e-05 seconds
DEBUG 01-14 20:42:42.042436.042436 cuda_h.py:19] end start_load_qkvogn_s_weight_l_24 cost 7.104873657226562e-05 seconds
DEBUG 01-14 20:42:42.042039.042039 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-14 20:42:42.042539.042539 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-14 20:42:42.042150.042150 cuda_h.py:10] start sllm_worker_task
DEBUG 01-14 20:42:42.043539.043539 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-14 20:42:42.043859.043859 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-14 20:42:42.046583.046583 cuda_h.py:19] end allocate_cuda_memory cost 0.0037565231323242188 seconds
DEBUG 01-14 20:42:42.046300.046300 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-14 20:42:42.046586.046586 sllm_store_c.py:27] get device uuid map
DEBUG 01-14 20:42:42.047091.047091 sllm_store_c.py:29] call client load into gpu
DEBUG 01-14 20:42:42.047702.047702 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, d7985690-35cd-418f-87c1-c0de63a24a45
DEBUG 01-14 20:42:42.047592.047592 client.py:106] call stub.LoadModelAsync
DEBUG 01-14 20:42:42.047043.047043 cuda_h.py:10] start self_attn
INFO 01-14 20:42:42.048047.048047 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, d7985690-35cd-418f-87c1-c0de63a24a45
DEBUG 01-14 20:42:42.048354.048354 cuda_h.py:19] end load_into_gpu_async cost 0.0011625289916992188 seconds
DEBUG 01-14 20:42:42.048149.048149 cuda_h.py:10] start restore_tensors2
DEBUG 01-14 20:42:42.048470.048470 cuda_h.py:19] end restore_tensors2 cost 7.05718994140625e-05 seconds
DEBUG 01-14 20:42:42.048749.048749 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.005247592926025391 seconds
INFO 01-14 20:42:42.048771.048771 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, d7985690-35cd-418f-87c1-c0de63a24a45
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-14 20:42:42.050816.050816 cuda_h.py:19] end self_attn cost 0.002850770950317383 seconds
DEBUG 01-14 20:42:42.050793.050793 cuda_h.py:19] end iln_self_attn_paln cost 0.008036136627197266 seconds
DEBUG 01-14 20:42:42.050444.050444 cuda_h.py:10] start layer_moe_generate_mp_l_24
DEBUG 01-14 20:42:42.050492.050492 cuda_h.py:10] start gate
DEBUG 01-14 20:42:42.051865.051865 cuda_h.py:19] end gate cost 0.0006272792816162109 seconds
DEBUG 01-14 20:42:42.051456.051456 cuda_h.py:10] start experts_map_get
DEBUG 01-14 20:42:42.051294.051294 lmp.py:1615] 
DEBUG 01-14 20:42:42.051294.051294 lmp.py:1615] Expert Token Distribution & Device Allocation:
DEBUG 01-14 20:42:42.051341.051341 lmp.py:1616]   Total experts: 64
DEBUG 01-14 20:42:42.051183.051183 lmp.py:1617]   CPU experts: 32 (50%)
DEBUG 01-14 20:42:42.051449.051449 lmp.py:1618]   GPU experts: 32 (50%)
DEBUG 01-14 20:42:42.051568.051568 lmp.py:1619] 
DEBUG 01-14 20:42:42.051568.051568 lmp.py:1619]   Expert ID | Tokens | Device
DEBUG 01-14 20:42:42.052688.052688 lmp.py:1620]   -----------------------------------
DEBUG 01-14 20:42:42.052239.052239 lmp.py:1625]   Expert  5 |     11 | CPU
DEBUG 01-14 20:42:42.052358.052358 lmp.py:1625]   Expert 56 |     41 | CPU
DEBUG 01-14 20:42:42.052001.052001 lmp.py:1625]   Expert 27 |     94 | CPU
DEBUG 01-14 20:42:42.052406.052406 lmp.py:1625]   Expert 16 |     95 | CPU
DEBUG 01-14 20:42:42.052810.052810 lmp.py:1625]   Expert 53 |     95 | CPU
DEBUG 01-14 20:42:42.052977.052977 lmp.py:1625]   Expert 40 |     98 | CPU
DEBUG 01-14 20:42:42.052904.052904 lmp.py:1625]   Expert 47 |     98 | CPU
DEBUG 01-14 20:42:42.052832.052832 lmp.py:1625]   Expert 17 |    101 | CPU
DEBUG 01-14 20:42:42.052521.052521 lmp.py:1625]   Expert 51 |    111 | CPU
DEBUG 01-14 20:42:42.052687.052687 lmp.py:1625]   Expert  7 |    112 | CPU
DEBUG 01-14 20:42:42.052092.052092 lmp.py:1625]   Expert 28 |    112 | CPU
DEBUG 01-14 20:42:42.052258.052258 lmp.py:1625]   Expert 37 |    115 | CPU
DEBUG 01-14 20:42:42.052424.052424 lmp.py:1625]   Expert 63 |    116 | CPU
DEBUG 01-14 20:42:42.052114.052114 lmp.py:1625]   Expert 49 |    117 | CPU
DEBUG 01-14 20:42:42.052280.052280 lmp.py:1625]   Expert 58 |    129 | CPU
DEBUG 01-14 20:42:42.052969.052969 lmp.py:1625]   Expert 38 |    137 | CPU
DEBUG 01-14 20:42:42.052897.052897 lmp.py:1625]   Expert 57 |    138 | CPU
DEBUG 01-14 20:42:42.052348.052348 lmp.py:1625]   Expert 14 |    143 | CPU
DEBUG 01-14 20:42:42.052752.052752 lmp.py:1625]   Expert 39 |    146 | CPU
DEBUG 01-14 20:42:42.052634.052634 lmp.py:1625]   Expert 62 |    150 | CPU
DEBUG 01-14 20:42:42.052561.052561 lmp.py:1625]   Expert  1 |    154 | CPU
DEBUG 01-14 20:42:42.052264.052264 lmp.py:1625]   Expert 11 |    156 | CPU
DEBUG 01-14 20:42:42.052192.052192 lmp.py:1625]   Expert 12 |    156 | CPU
DEBUG 01-14 20:42:42.052120.052120 lmp.py:1625]   Expert 25 |    160 | CPU
DEBUG 01-14 20:42:42.052286.052286 lmp.py:1625]   Expert 52 |    162 | CPU
DEBUG 01-14 20:42:42.052452.052452 lmp.py:1625]   Expert 23 |    164 | CPU
DEBUG 01-14 20:42:42.052095.052095 lmp.py:1625]   Expert 33 |    164 | CPU
DEBUG 01-14 20:42:42.052261.052261 lmp.py:1625]   Expert 21 |    167 | CPU
DEBUG 01-14 20:42:42.052427.052427 lmp.py:1625]   Expert 30 |    172 | CPU
DEBUG 01-14 20:42:42.052593.052593 lmp.py:1625]   Expert 45 |    173 | CPU
DEBUG 01-14 20:42:42.052998.052998 lmp.py:1625]   Expert  6 |    174 | CPU
DEBUG 01-14 20:42:42.052926.052926 lmp.py:1625]   Expert 36 |    176 | CPU
DEBUG 01-14 20:42:42.052853.052853 lmp.py:1625]   Expert 55 |    181 | GPU
DEBUG 01-14 20:42:42.052019.052019 lmp.py:1625]   Expert  9 |    186 | GPU
DEBUG 01-14 20:42:42.052901.052901 lmp.py:1625]   Expert 31 |    189 | GPU
DEBUG 01-14 20:42:42.052590.052590 lmp.py:1625]   Expert 60 |    192 | GPU
DEBUG 01-14 20:42:42.052518.052518 lmp.py:1625]   Expert  3 |    201 | GPU
DEBUG 01-14 20:42:42.052446.052446 lmp.py:1625]   Expert  4 |    203 | GPU
DEBUG 01-14 20:42:42.052373.052373 lmp.py:1625]   Expert 19 |    204 | GPU
DEBUG 01-14 20:42:42.052301.052301 lmp.py:1625]   Expert 44 |    206 | GPU
DEBUG 01-14 20:42:42.052990.052990 lmp.py:1625]   Expert 34 |    210 | GPU
DEBUG 01-14 20:42:42.052156.052156 lmp.py:1625]   Expert 50 |    224 | GPU
DEBUG 01-14 20:42:42.052846.052846 lmp.py:1625]   Expert 41 |    226 | GPU
DEBUG 01-14 20:42:42.052773.052773 lmp.py:1625]   Expert 22 |    227 | GPU
DEBUG 01-14 20:42:42.052701.052701 lmp.py:1625]   Expert  0 |    229 | GPU
DEBUG 01-14 20:42:42.052106.052106 lmp.py:1625]   Expert 26 |    229 | GPU
DEBUG 01-14 20:42:42.052272.052272 lmp.py:1625]   Expert 43 |    230 | GPU
DEBUG 01-14 20:42:42.052200.052200 lmp.py:1625]   Expert 59 |    237 | GPU
DEBUG 01-14 20:42:42.052127.052127 lmp.py:1625]   Expert 13 |    239 | GPU
DEBUG 01-14 20:42:42.052293.052293 lmp.py:1625]   Expert 18 |    242 | GPU
DEBUG 01-14 20:42:42.052221.052221 lmp.py:1625]   Expert 42 |    250 | GPU
DEBUG 01-14 20:42:42.052109.052109 lmp.py:1625]   Expert 54 |    254 | GPU
DEBUG 01-14 20:42:42.052468.052468 lmp.py:1625]   Expert 24 |    260 | GPU
DEBUG 01-14 20:42:42.052111.052111 lmp.py:1625]   Expert 61 |    260 | GPU
DEBUG 01-14 20:42:42.052515.052515 lmp.py:1625]   Expert 20 |    262 | GPU
DEBUG 01-14 20:42:42.052443.052443 lmp.py:1625]   Expert 15 |    263 | GPU
DEBUG 01-14 20:42:42.053371.053371 lmp.py:1625]   Expert 35 |    269 | GPU
DEBUG 01-14 20:42:42.053537.053537 lmp.py:1625]   Expert 32 |    283 | GPU
DEBUG 01-14 20:42:42.053703.053703 lmp.py:1625]   Expert 29 |    284 | GPU
DEBUG 01-14 20:42:42.053869.053869 lmp.py:1625]   Expert 10 |    300 | GPU
DEBUG 01-14 20:42:42.053512.053512 lmp.py:1625]   Expert  2 |    343 | GPU
DEBUG 01-14 20:42:42.053976.053976 lmp.py:1625]   Expert  8 |    343 | GPU
DEBUG 01-14 20:42:42.053904.053904 lmp.py:1625]   Expert 46 |    456 | GPU
DEBUG 01-14 20:42:42.053355.053355 lmp.py:1625]   Expert 48 |    469 | GPU
DEBUG 01-14 20:42:42.053283.053283 lmp.py:1626] 
DEBUG 01-14 20:42:42.053283.053283 lmp.py:1626]   CPU total tokens: 4137 (33.7%)
DEBUG 01-14 20:42:42.053926.053926 lmp.py:1627]   GPU total tokens: 8151 (66.3%)
DEBUG 01-14 20:42:42.053337.053337 cuda_h.py:19] end experts_map_get cost 0.0015685558319091797 seconds
DEBUG 01-14 20:42:42.053333.053333 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-14 20:42:42.053083.053083 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-14 20:42:42.053095.053095 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-14 20:42:42.055517.055517 cuda_h.py:19] end allocate_cuda_memory cost 0.002102375030517578 seconds
DEBUG 01-14 20:42:42.055957.055957 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-14 20:42:42.055097.055097 sllm_store_c.py:27] get device uuid map
DEBUG 01-14 20:42:42.055834.055834 sllm_store_c.py:29] call client load into gpu
DEBUG 01-14 20:42:42.055060.055060 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, b4134644-89d9-4a0c-a600-60cdb0ecdca0
DEBUG 01-14 20:42:42.055755.055755 client.py:106] call stub.LoadModelAsync
DEBUG 01-14 20:42:42.056299.056299 mlpmodule.py:1367]  experts func einsum cost 0.07500314712524414 s
INFO 01-14 20:42:42.056513.056513 client.py:127] Model loaded
DEBUG 01-14 20:42:42.056201.056201 cuda_h.py:10] start restore2model
INFO 01-14 20:42:42.056077.056077 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, b4134644-89d9-4a0c-a600-60cdb0ecdca0
DEBUG 01-14 20:42:42.057764.057764 cuda_h.py:19] end load_into_gpu_async cost 0.0013306140899658203 seconds
DEBUG 01-14 20:42:42.057905.057905 cuda_h.py:10] start restore_tensors2
DEBUG 01-14 20:42:42.057645.057645 cuda_h.py:19] end restore_tensors2 cost 0.00034236907958984375 seconds
DEBUG 01-14 20:42:42.057345.057345 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.004241228103637695 seconds
DEBUG 01-14 20:42:42.057406.057406 cuda_h.py:10] start restore2model
DEBUG 01-14 20:42:42.057371.057371 cuda_h.py:19] end restore2model cost 0.000293731689453125 seconds
DEBUG 01-14 20:42:42.058453.058453 cuda_h.py:19] end sllm_worker_task cost 0.015044927597045898 seconds
DEBUG 01-14 20:42:42.060800.060800 cuda_h.py:19] end restore2model cost 0.0028183460235595703 seconds
DEBUG 01-14 20:42:42.060418.060418 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.007266044616699219 seconds
DEBUG 01-14 20:42:42.060929.060929 cuda_h.py:10] start gpu_sexperts
DEBUG 01-14 20:42:42.060787.060787 cuda_h.py:19] end gpu_sexperts cost 0.0002853870391845703 seconds
DEBUG 01-14 20:42:42.060948.060948 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-14 20:42:42.060319.060319 lmp.py:1683] 
DEBUG 01-14 20:42:42.060319.060319 lmp.py:1683]   Computing 32 experts on CPU...
DEBUG 01-14 20:42:42.061686.061686 cuda_h.py:19] end cpu_experts_submit cost 5.936622619628906e-05 seconds
DEBUG 01-14 20:42:42.061004.061004 cuda_h.py:10] start experts_func_mgpu_group_pad
DEBUG 01-14 20:42:42.072204.072204 mlpmodule.py:1460] group tensors cost 0.01109004020690918 s
DEBUG 01-14 20:42:42.073399.073399 cuda_h.py:10] start move_flat_hidden2cpu
DEBUG 01-14 20:42:42.079450.079450 cuda_h.py:19] end experts_func_mgpu_group_pad cost 0.017986536026000977 seconds
DEBUG 01-14 20:42:42.080721.080721 cuda_h.py:19] end move_flat_hidden2cpu cost 0.006551265716552734 seconds
DEBUG 01-14 20:42:42.082158.082158 cuda_h.py:10] start gpu_group_list
DEBUG 01-14 20:42:42.083519.083519 cuda_h.py:19] end gpu_group_list cost 0.0008943080902099609 seconds
DEBUG 01-14 20:42:42.083483.083483 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-14 20:42:42.083164.083164 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 3.457069396972656e-05 seconds
DEBUG 01-14 20:42:42.083590.083590 cuda_h.py:10] start wait_experts
INFO 01-14 20:42:42.083248.083248 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, b4134644-89d9-4a0c-a600-60cdb0ecdca0
DEBUG 01-14 20:42:42.084632.084632 mlpmodule.py:1533] pad cost 0.004134654998779297 s
DEBUG 01-14 20:42:42.084014.084014 mlpmodule.py:1539] create cpu tensor cost 3.981590270996094e-05 s
DEBUG 01-14 20:42:42.086648.086648 mlpmodule.py:1544] move to cpu cost 0.0020797252655029297 s
DEBUG 01-14 20:42:42.096375.096375 mlpmodule.py:1558] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-14 20:42:42.096031.096031 mlpmodule.py:1559] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-14 20:42:42.096630.096630 mlpmodule.py:1564] group_w3 first element: 0.08447265625
WARNING 01-14 20:42:42.096078.096078 mlpmodule.py:1574] start einsum2
INFO 01-14 20:42:42.112077.112077 client.py:127] Model loaded
DEBUG 01-14 20:42:42.112627.112627 cuda_h.py:19] end wait_experts cost 0.028705120086669922 seconds
DEBUG 01-14 20:42:42.112489.112489 cuda_h.py:10] start gpu_experts
DEBUG 01-14 20:42:42.112358.112358 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-14 20:42:42.113948.113948 mlpmodule.py:1584] group einsum cost 0.02707815170288086 s
DEBUG 01-14 20:42:42.114633.114633 mlpmodule.py:1593] cpy2cputensor cost 0.0007174015045166016 s
DEBUG 01-14 20:42:42.114356.114356 cuda_h.py:10] start move_outputs
DEBUG 01-14 20:42:42.116730.116730 cuda_h.py:19] end move_outputs cost 0.002033233642578125 seconds
DEBUG 01-14 20:42:42.120667.120667 cuda_h.py:19] end wait_cetm_experts cost 0.007560253143310547 seconds
DEBUG 01-14 20:42:42.120255.120255 cuda_h.py:10] start gpu_group_einsum_mp_multi_list
DEBUG 01-14 20:42:42.120309.120309 cuda_h.py:10] start gpu_group_tensor
DEBUG 01-14 20:42:42.120444.120444 cuda_h.py:19] end gpu_group_tensor cost 0.00024199485778808594 seconds
DEBUG 01-14 20:42:42.120614.120614 cuda_h.py:10] start gpu_group_einsum
DEBUG 01-14 20:42:42.121109.121109 cuda_h.py:19] end gpu_group_einsum cost 0.0006821155548095703 seconds
DEBUG 01-14 20:42:42.121266.121266 cuda_h.py:10] start gpu_final_hidden_states_scatter
DEBUG 01-14 20:42:42.121216.121216 cuda_h.py:10] start all_expert_outputs_slices
DEBUG 01-14 20:42:42.122587.122587 cuda_h.py:19] end all_expert_outputs_slices cost 0.00037598609924316406 seconds
DEBUG 01-14 20:42:42.122820.122820 cuda_h.py:10] start concat_expert_out
DEBUG 01-14 20:42:42.122664.122664 cuda_h.py:19] end concat_expert_out cost 5.91278076171875e-05 seconds
DEBUG 01-14 20:42:42.122183.122183 cuda_h.py:10] start index_scatter
DEBUG 01-14 20:42:42.122902.122902 cuda_h.py:19] end index_scatter cost 7.2479248046875e-05 seconds
DEBUG 01-14 20:42:42.122188.122188 cuda_h.py:19] end gpu_final_hidden_states_scatter cost 0.0007698535919189453 seconds
DEBUG 01-14 20:42:42.122151.122151 cuda_h.py:19] end gpu_experts cost 0.010044336318969727 seconds
DEBUG 01-14 20:42:42.122046.122046 cuda_h.py:10] start all_expert_weight_slices
DEBUG 01-14 20:42:42.123708.123708 cuda_h.py:19] end all_expert_weight_slices cost 0.0009474754333496094 seconds
DEBUG 01-14 20:42:42.123153.123153 cuda_h.py:10] start cpuoutputsdeal
DEBUG 01-14 20:42:42.124512.124512 cuda_h.py:10] start index_scatter
DEBUG 01-14 20:42:42.124291.124291 cuda_h.py:19] end index_scatter cost 4.9591064453125e-05 seconds
DEBUG 01-14 20:42:42.124922.124922 cuda_h.py:19] end cpuoutputsdeal cost 0.0005714893341064453 seconds
DEBUG 01-14 20:42:42.124123.124123 cuda_h.py:19] end layer_moe_generate_mp_l_24 cost 0.07364273071289062 seconds
DEBUG 01-14 20:42:42.124289.124289 cuda_h.py:19] end prefill_layer cost 0.08237934112548828 seconds
DEBUG 01-14 20:42:42.124854.124854 lmp.py:1551] -------------------------------- end prefill layer 23 --------------------------------
DEBUG 01-14 20:42:42.125272.125272 cuda_h.py:10] start prefill_layer
DEBUG 01-14 20:42:42.125405.125405 lmp.py:1494] -------------------------------- start prefill layer 24 --------------------------------
DEBUG 01-14 20:42:42.125585.125585 cuda_h.py:10] start start_load_qkvogn_s_weight_l_25
DEBUG 01-14 20:42:42.125387.125387 cuda_h.py:10] start start_load_qkvogn_s_weight_l_25
DEBUG 01-14 20:42:42.125807.125807 cuda_h.py:19] end start_load_qkvogn_s_weight_l_25 cost 3.552436828613281e-05 seconds
DEBUG 01-14 20:42:42.125993.125993 cuda_h.py:19] end start_load_qkvogn_s_weight_l_25 cost 6.961822509765625e-05 seconds
DEBUG 01-14 20:42:42.125073.125073 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-14 20:42:42.125546.125546 cuda_h.py:10] start sllm_worker_task
DEBUG 01-14 20:42:42.125212.125212 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-14 20:42:42.125624.125624 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-14 20:42:42.127184.127184 cuda_h.py:19] end allocate_cuda_memory cost 0.0018472671508789062 seconds
DEBUG 01-14 20:42:42.127048.127048 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-14 20:42:42.127241.127241 sllm_store_c.py:27] get device uuid map
DEBUG 01-14 20:42:42.127316.127316 sllm_store_c.py:29] call client load into gpu
DEBUG 01-14 20:42:42.127025.127025 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 7cbf2e35-11b9-4fa0-a734-c3804cae8c29
DEBUG 01-14 20:42:42.127923.127923 client.py:106] call stub.LoadModelAsync
DEBUG 01-14 20:42:42.127352.127352 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-14 20:42:42.128755.128755 cuda_h.py:10] start self_attn
INFO 01-14 20:42:42.128414.128414 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 7cbf2e35-11b9-4fa0-a734-c3804cae8c29
DEBUG 01-14 20:42:42.128879.128879 cuda_h.py:19] end load_into_gpu_async cost 0.001065969467163086 seconds
DEBUG 01-14 20:42:42.128119.128119 cuda_h.py:10] start restore_tensors2
DEBUG 01-14 20:42:42.128798.128798 cuda_h.py:19] end restore_tensors2 cost 8.344650268554688e-05 seconds
DEBUG 01-14 20:42:42.128415.128415 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.003278017044067383 seconds
INFO 01-14 20:42:42.128087.128087 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 7cbf2e35-11b9-4fa0-a734-c3804cae8c29
DEBUG 01-14 20:42:42.131121.131121 mlpmodule.py:1367]  experts func einsum cost 0.0695641040802002 s
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-14 20:42:42.132807.132807 cuda_h.py:19] end self_attn cost 0.0040357112884521484 seconds
DEBUG 01-14 20:42:42.132243.132243 cuda_h.py:19] end iln_self_attn_paln cost 0.0073926448822021484 seconds
DEBUG 01-14 20:42:42.132000.132000 cuda_h.py:10] start layer_moe_generate_mp_l_25
DEBUG 01-14 20:42:42.132001.132001 cuda_h.py:10] start gate
DEBUG 01-14 20:42:42.133779.133779 cuda_h.py:19] end gate cost 0.0006427764892578125 seconds
DEBUG 01-14 20:42:42.133377.133377 cuda_h.py:10] start experts_map_get
DEBUG 01-14 20:42:42.133612.133612 lmp.py:1615] 
DEBUG 01-14 20:42:42.133612.133612 lmp.py:1615] Expert Token Distribution & Device Allocation:
DEBUG 01-14 20:42:42.133368.133368 lmp.py:1616]   Total experts: 64
DEBUG 01-14 20:42:42.133733.133733 lmp.py:1617]   CPU experts: 32 (50%)
DEBUG 01-14 20:42:42.133761.133761 lmp.py:1618]   GPU experts: 32 (50%)
DEBUG 01-14 20:42:42.133642.133642 lmp.py:1619] 
DEBUG 01-14 20:42:42.133642.133642 lmp.py:1619]   Expert ID | Tokens | Device
DEBUG 01-14 20:42:42.133808.133808 lmp.py:1620]   -----------------------------------
DEBUG 01-14 20:42:42.133928.133928 lmp.py:1625]   Expert 36 |     24 | CPU
DEBUG 01-14 20:42:42.133571.133571 lmp.py:1625]   Expert 35 |     40 | CPU
DEBUG 01-14 20:42:42.133737.133737 lmp.py:1625]   Expert 25 |     46 | CPU
DEBUG 01-14 20:42:42.133188.133188 lmp.py:1625]   Expert 30 |     53 | CPU
DEBUG 01-14 20:42:42.134592.134592 lmp.py:1625]   Expert 51 |     53 | CPU
DEBUG 01-14 20:42:42.134282.134282 lmp.py:1625]   Expert 46 |     56 | CPU
DEBUG 01-14 20:42:42.134971.134971 lmp.py:1625]   Expert 55 |     57 | CPU
DEBUG 01-14 20:42:42.134660.134660 lmp.py:1625]   Expert 43 |     66 | CPU
DEBUG 01-14 20:42:42.134111.134111 lmp.py:1625]   Expert 47 |     68 | CPU
DEBUG 01-14 20:42:42.134324.134324 lmp.py:1625]   Expert 44 |     73 | CPU
DEBUG 01-14 20:42:42.134013.134013 lmp.py:1625]   Expert  0 |     81 | CPU
DEBUG 01-14 20:42:42.134702.134702 lmp.py:1625]   Expert 16 |     81 | CPU
DEBUG 01-14 20:42:42.134630.134630 lmp.py:1625]   Expert  2 |     82 | CPU
DEBUG 01-14 20:42:42.134081.134081 lmp.py:1625]   Expert 39 |     85 | CPU
DEBUG 01-14 20:42:42.134532.134532 lmp.py:1625]   Expert 42 |     89 | CPU
DEBUG 01-14 20:42:42.134506.134506 lmp.py:1625]   Expert  4 |    104 | CPU
DEBUG 01-14 20:42:42.134480.134480 lmp.py:1625]   Expert 54 |    120 | CPU
DEBUG 01-14 20:42:42.134215.134215 lmp.py:1625]   Expert 33 |    123 | CPU
DEBUG 01-14 20:42:42.134428.134428 lmp.py:1625]   Expert 24 |    130 | CPU
DEBUG 01-14 20:42:42.134402.134402 lmp.py:1625]   Expert 48 |    131 | CPU
DEBUG 01-14 20:42:42.134853.134853 lmp.py:1625]   Expert 61 |    132 | CPU
DEBUG 01-14 20:42:42.134542.134542 lmp.py:1625]   Expert  6 |    137 | CPU
DEBUG 01-14 20:42:42.134139.134139 lmp.py:1625]   Expert 15 |    138 | CPU
DEBUG 01-14 20:42:42.134067.134067 lmp.py:1625]   Expert 38 |    144 | CPU
DEBUG 01-14 20:42:42.134756.134756 lmp.py:1625]   Expert 29 |    145 | CPU
DEBUG 01-14 20:42:42.134207.134207 lmp.py:1625]   Expert 56 |    145 | CPU
DEBUG 01-14 20:42:42.134419.134419 lmp.py:1625]   Expert 19 |    149 | CPU
DEBUG 01-14 20:42:42.134632.134632 lmp.py:1625]   Expert  7 |    151 | CPU
DEBUG 01-14 20:42:42.134082.134082 lmp.py:1625]   Expert 59 |    153 | CPU
DEBUG 01-14 20:42:42.134295.134295 lmp.py:1625]   Expert 62 |    155 | CPU
DEBUG 01-14 20:42:42.134507.134507 lmp.py:1625]   Expert  9 |    157 | CPU
DEBUG 01-14 20:42:42.134720.134720 lmp.py:1625]   Expert 13 |    161 | CPU
DEBUG 01-14 20:42:42.134601.134601 lmp.py:1625]   Expert 20 |    161 | GPU
DEBUG 01-14 20:42:42.134291.134291 lmp.py:1625]   Expert 34 |    176 | GPU
DEBUG 01-14 20:42:42.134503.134503 lmp.py:1625]   Expert 45 |    177 | GPU
DEBUG 01-14 20:42:42.134477.134477 lmp.py:1625]   Expert 18 |    184 | GPU
DEBUG 01-14 20:42:42.134690.134690 lmp.py:1625]   Expert  8 |    189 | GPU
DEBUG 01-14 20:42:42.134902.134902 lmp.py:1625]   Expert 57 |    189 | GPU
DEBUG 01-14 20:42:42.134114.134114 lmp.py:1625]   Expert 50 |    190 | GPU
DEBUG 01-14 20:42:42.134327.134327 lmp.py:1625]   Expert 23 |    198 | GPU
DEBUG 01-14 20:42:42.134301.134301 lmp.py:1625]   Expert 60 |    203 | GPU
DEBUG 01-14 20:42:42.134275.134275 lmp.py:1625]   Expert 31 |    204 | GPU
DEBUG 01-14 20:42:42.134487.134487 lmp.py:1625]   Expert 22 |    209 | GPU
DEBUG 01-14 20:42:42.134700.134700 lmp.py:1625]   Expert 10 |    210 | GPU
DEBUG 01-14 20:42:42.134912.134912 lmp.py:1625]   Expert 17 |    227 | GPU
DEBUG 01-14 20:42:42.134363.134363 lmp.py:1625]   Expert  5 |    230 | GPU
DEBUG 01-14 20:42:42.134337.134337 lmp.py:1625]   Expert 37 |    234 | GPU
DEBUG 01-14 20:42:42.134788.134788 lmp.py:1625]   Expert 11 |    237 | GPU
DEBUG 01-14 20:42:42.134001.134001 lmp.py:1625]   Expert 52 |    242 | GPU
DEBUG 01-14 20:42:42.134644.134644 lmp.py:1625]   Expert 53 |    253 | GPU
DEBUG 01-14 20:42:42.134571.134571 lmp.py:1625]   Expert  1 |    269 | GPU
DEBUG 01-14 20:42:42.134545.134545 lmp.py:1625]   Expert 49 |    270 | GPU
DEBUG 01-14 20:42:42.134758.134758 lmp.py:1625]   Expert 26 |    279 | GPU
DEBUG 01-14 20:42:42.134209.134209 lmp.py:1625]   Expert 41 |    283 | GPU
DEBUG 01-14 20:42:42.134660.134660 lmp.py:1625]   Expert 58 |    283 | GPU
DEBUG 01-14 20:42:42.134872.134872 lmp.py:1625]   Expert 14 |    286 | GPU
DEBUG 01-14 20:42:42.134846.134846 lmp.py:1625]   Expert 40 |    295 | GPU
DEBUG 01-14 20:42:42.134297.134297 lmp.py:1625]   Expert 28 |    306 | GPU
DEBUG 01-14 20:42:42.134748.134748 lmp.py:1625]   Expert 32 |    322 | GPU
DEBUG 01-14 20:42:42.134722.134722 lmp.py:1625]   Expert 12 |    327 | GPU
DEBUG 01-14 20:42:42.134219.134219 lmp.py:1625]   Expert 21 |    351 | GPU
DEBUG 01-14 20:42:42.134432.134432 lmp.py:1625]   Expert 63 |    353 | GPU
DEBUG 01-14 20:42:42.134167.134167 lmp.py:1625]   Expert 27 |    597 | GPU
DEBUG 01-14 20:42:42.134141.134141 lmp.py:1625]   Expert  3 |   1025 | GPU
DEBUG 01-14 20:42:42.134069.134069 lmp.py:1626] 
DEBUG 01-14 20:42:42.134069.134069 lmp.py:1626]   CPU total tokens: 3329 (27.1%)
DEBUG 01-14 20:42:42.135474.135474 lmp.py:1627]   GPU total tokens: 8959 (72.9%)
DEBUG 01-14 20:42:42.135123.135123 cuda_h.py:19] end experts_map_get cost 0.0015044212341308594 seconds
DEBUG 01-14 20:42:42.135496.135496 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-14 20:42:42.135816.135816 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-14 20:42:42.135457.135457 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-14 20:42:42.135521.135521 cuda_h.py:19] end allocate_cuda_memory cost 0.0002913475036621094 seconds
DEBUG 01-14 20:42:42.135285.135285 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-14 20:42:42.135041.135041 sllm_store_c.py:27] get device uuid map
DEBUG 01-14 20:42:42.135711.135711 sllm_store_c.py:29] call client load into gpu
DEBUG 01-14 20:42:42.135076.135076 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, a81df5b8-c843-4c58-8ce6-dd8c22f964a7
DEBUG 01-14 20:42:42.136110.136110 client.py:106] call stub.LoadModelAsync
INFO 01-14 20:42:42.136387.136387 client.py:127] Model loaded
DEBUG 01-14 20:42:42.136739.136739 cuda_h.py:10] start restore2model
DEBUG 01-14 20:42:42.136043.136043 cuda_h.py:19] end restore2model cost 0.00033402442932128906 seconds
DEBUG 01-14 20:42:42.136813.136813 cuda_h.py:19] end sllm_worker_task cost 0.011233806610107422 seconds
INFO 01-14 20:42:42.136421.136421 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, a81df5b8-c843-4c58-8ce6-dd8c22f964a7
DEBUG 01-14 20:42:42.136794.136794 cuda_h.py:19] end load_into_gpu_async cost 0.0011138916015625 seconds
DEBUG 01-14 20:42:42.136497.136497 cuda_h.py:10] start restore_tensors2
DEBUG 01-14 20:42:42.137992.137992 cuda_h.py:19] end restore_tensors2 cost 0.0003409385681152344 seconds
DEBUG 01-14 20:42:42.137544.137544 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.002126932144165039 seconds
DEBUG 01-14 20:42:42.137598.137598 cuda_h.py:10] start restore2model
DEBUG 01-14 20:42:42.139366.139366 cuda_h.py:19] end restore2model cost 0.0025398731231689453 seconds
DEBUG 01-14 20:42:42.139679.139679 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.004847288131713867 seconds
DEBUG 01-14 20:42:42.139521.139521 cuda_h.py:10] start gpu_sexperts
DEBUG 01-14 20:42:42.140889.140889 cuda_h.py:19] end gpu_sexperts cost 0.00027561187744140625 seconds
DEBUG 01-14 20:42:42.140858.140858 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-14 20:42:42.140276.140276 lmp.py:1683] 
DEBUG 01-14 20:42:42.140276.140276 lmp.py:1683]   Computing 32 experts on CPU...
DEBUG 01-14 20:42:42.140748.140748 cuda_h.py:19] end cpu_experts_submit cost 6.747245788574219e-05 seconds
DEBUG 01-14 20:42:42.140067.140067 cuda_h.py:10] start experts_func_mgpu_group_pad
DEBUG 01-14 20:42:42.155611.155611 mlpmodule.py:1460] group tensors cost 0.014834403991699219 s
DEBUG 01-14 20:42:42.156473.156473 cuda_h.py:10] start move_flat_hidden2cpu
DEBUG 01-14 20:42:42.162463.162463 cuda_h.py:19] end experts_func_mgpu_group_pad cost 0.021837472915649414 seconds
DEBUG 01-14 20:42:42.163549.163549 cuda_h.py:19] end move_flat_hidden2cpu cost 0.00654149055480957 seconds
DEBUG 01-14 20:42:42.166081.166081 cuda_h.py:10] start gpu_group_list
DEBUG 01-14 20:42:42.167255.167255 cuda_h.py:19] end gpu_group_list cost 0.0012390613555908203 seconds
DEBUG 01-14 20:42:42.168583.168583 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-14 20:42:42.168439.168439 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 4.553794860839844e-05 seconds
DEBUG 01-14 20:42:42.168814.168814 cuda_h.py:10] start wait_experts
INFO 01-14 20:42:42.168659.168659 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, a81df5b8-c843-4c58-8ce6-dd8c22f964a7
DEBUG 01-14 20:42:42.169945.169945 mlpmodule.py:1533] pad cost 0.005582571029663086 s
DEBUG 01-14 20:42:42.169082.169082 mlpmodule.py:1539] create cpu tensor cost 4.4345855712890625e-05 s
DEBUG 01-14 20:42:42.171406.171406 mlpmodule.py:1544] move to cpu cost 0.0019176006317138672 s
DEBUG 01-14 20:42:42.180671.180671 mlpmodule.py:1558] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-14 20:42:42.180034.180034 mlpmodule.py:1559] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-14 20:42:42.180308.180308 mlpmodule.py:1564] group_w3 first element: 0.00653076171875
WARNING 01-14 20:42:42.180207.180207 mlpmodule.py:1574] start einsum2
INFO 01-14 20:42:42.190448.190448 client.py:127] Model loaded
DEBUG 01-14 20:42:42.190598.190598 cuda_h.py:19] end wait_experts cost 0.021684646606445312 seconds
DEBUG 01-14 20:42:42.190734.190734 cuda_h.py:10] start gpu_experts
DEBUG 01-14 20:42:42.190485.190485 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-14 20:42:42.196751.196751 mlpmodule.py:1584] group einsum cost 0.025667190551757812 s
DEBUG 01-14 20:42:42.197569.197569 mlpmodule.py:1593] cpy2cputensor cost 0.0006883144378662109 s
DEBUG 01-14 20:42:42.197054.197054 cuda_h.py:10] start move_outputs
DEBUG 01-14 20:42:42.199131.199131 cuda_h.py:19] end move_outputs cost 0.0018765926361083984 seconds
DEBUG 01-14 20:42:42.203763.203763 cuda_h.py:19] end wait_cetm_experts cost 0.012751340866088867 seconds
DEBUG 01-14 20:42:42.203558.203558 cuda_h.py:10] start gpu_group_einsum_mp_multi_list
DEBUG 01-14 20:42:42.203281.203281 cuda_h.py:10] start gpu_group_tensor
DEBUG 01-14 20:42:42.204092.204092 cuda_h.py:19] end gpu_group_tensor cost 0.000247955322265625 seconds
DEBUG 01-14 20:42:42.204646.204646 cuda_h.py:10] start gpu_group_einsum
DEBUG 01-14 20:42:42.205348.205348 cuda_h.py:19] end gpu_group_einsum cost 0.0007441043853759766 seconds
DEBUG 01-14 20:42:42.205744.205744 cuda_h.py:10] start gpu_final_hidden_states_scatter
DEBUG 01-14 20:42:42.205408.205408 cuda_h.py:10] start all_expert_outputs_slices
DEBUG 01-14 20:42:42.205190.205190 cuda_h.py:19] end all_expert_outputs_slices cost 0.00036144256591796875 seconds
DEBUG 01-14 20:42:42.205900.205900 cuda_h.py:10] start concat_expert_out
DEBUG 01-14 20:42:42.205837.205837 cuda_h.py:19] end concat_expert_out cost 5.793571472167969e-05 seconds
DEBUG 01-14 20:42:42.205402.205402 cuda_h.py:10] start index_scatter
DEBUG 01-14 20:42:42.205929.205929 cuda_h.py:19] end index_scatter cost 7.319450378417969e-05 seconds
DEBUG 01-14 20:42:42.205546.205546 cuda_h.py:19] end gpu_final_hidden_states_scatter cost 0.0007522106170654297 seconds
DEBUG 01-14 20:42:42.206177.206177 cuda_h.py:19] end gpu_experts cost 0.015369892120361328 seconds
DEBUG 01-14 20:42:42.206834.206834 cuda_h.py:10] start all_expert_weight_slices
DEBUG 01-14 20:42:42.207065.207065 cuda_h.py:19] end all_expert_weight_slices cost 0.0009465217590332031 seconds
DEBUG 01-14 20:42:42.207934.207934 cuda_h.py:10] start cpuoutputsdeal
DEBUG 01-14 20:42:42.207856.207856 cuda_h.py:10] start index_scatter
DEBUG 01-14 20:42:42.207323.207323 cuda_h.py:19] end index_scatter cost 4.887580871582031e-05 seconds
DEBUG 01-14 20:42:42.207755.207755 cuda_h.py:19] end cpuoutputsdeal cost 0.0005409717559814453 seconds
DEBUG 01-14 20:42:42.207903.207903 cuda_h.py:19] end layer_moe_generate_mp_l_25 cost 0.07500100135803223 seconds
DEBUG 01-14 20:42:42.208307.208307 cuda_h.py:19] end prefill_layer cost 0.08310461044311523 seconds
DEBUG 01-14 20:42:42.208097.208097 lmp.py:1551] -------------------------------- end prefill layer 24 --------------------------------
DEBUG 01-14 20:42:42.208754.208754 cuda_h.py:10] start prefill_layer
DEBUG 01-14 20:42:42.208410.208410 lmp.py:1494] -------------------------------- start prefill layer 25 --------------------------------
DEBUG 01-14 20:42:42.208305.208305 cuda_h.py:10] start start_load_qkvogn_s_weight_l_26
DEBUG 01-14 20:42:42.208108.208108 cuda_h.py:10] start start_load_qkvogn_s_weight_l_26
DEBUG 01-14 20:42:42.208832.208832 cuda_h.py:19] end start_load_qkvogn_s_weight_l_26 cost 4.9114227294921875e-05 seconds
DEBUG 01-14 20:42:42.208211.208211 cuda_h.py:19] end start_load_qkvogn_s_weight_l_26 cost 8.535385131835938e-05 seconds
DEBUG 01-14 20:42:42.208576.208576 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-14 20:42:42.208791.208791 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-14 20:42:42.208244.208244 cuda_h.py:10] start sllm_worker_task
DEBUG 01-14 20:42:42.208910.208910 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-14 20:42:42.208945.208945 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-14 20:42:42.210504.210504 cuda_h.py:19] end allocate_cuda_memory cost 0.0016350746154785156 seconds
DEBUG 01-14 20:42:42.210699.210699 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-14 20:42:42.210130.210130 sllm_store_c.py:27] get device uuid map
DEBUG 01-14 20:42:42.210444.210444 sllm_store_c.py:29] call client load into gpu
DEBUG 01-14 20:42:42.210392.210392 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 4fc2a7bb-8331-436f-bc5d-22dd1ee5d750
DEBUG 01-14 20:42:42.210196.210196 client.py:106] call stub.LoadModelAsync
DEBUG 01-14 20:42:42.211050.211050 cuda_h.py:10] start self_attn
INFO 01-14 20:42:42.212312.212312 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 4fc2a7bb-8331-436f-bc5d-22dd1ee5d750
DEBUG 01-14 20:42:42.212009.212009 cuda_h.py:19] end load_into_gpu_async cost 0.0015256404876708984 seconds
DEBUG 01-14 20:42:42.212759.212759 cuda_h.py:10] start restore_tensors2
DEBUG 01-14 20:42:42.212808.212808 cuda_h.py:19] end restore_tensors2 cost 7.748603820800781e-05 seconds
DEBUG 01-14 20:42:42.212472.212472 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.003505706787109375 seconds
INFO 01-14 20:42:42.212606.212606 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 4fc2a7bb-8331-436f-bc5d-22dd1ee5d750
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-14 20:42:42.214833.214833 mlpmodule.py:1367]  experts func einsum cost 0.07311558723449707 s
DEBUG 01-14 20:42:42.214678.214678 cuda_h.py:19] end self_attn cost 0.003221273422241211 seconds
DEBUG 01-14 20:42:42.214384.214384 cuda_h.py:19] end iln_self_attn_paln cost 0.006319999694824219 seconds
DEBUG 01-14 20:42:42.214619.214619 cuda_h.py:10] start layer_moe_generate_mp_l_26
DEBUG 01-14 20:42:42.214573.214573 cuda_h.py:10] start gate
DEBUG 01-14 20:42:42.215510.215510 cuda_h.py:19] end gate cost 0.0006537437438964844 seconds
DEBUG 01-14 20:42:42.215731.215731 cuda_h.py:10] start experts_map_get
DEBUG 01-14 20:42:42.215967.215967 lmp.py:1615] 
DEBUG 01-14 20:42:42.215967.215967 lmp.py:1615] Expert Token Distribution & Device Allocation:
DEBUG 01-14 20:42:42.216723.216723 lmp.py:1616]   Total experts: 64
DEBUG 01-14 20:42:42.216372.216372 lmp.py:1617]   CPU experts: 32 (50%)
DEBUG 01-14 20:42:42.216161.216161 lmp.py:1618]   GPU experts: 32 (50%)
DEBUG 01-14 20:42:42.216327.216327 lmp.py:1619] 
DEBUG 01-14 20:42:42.216327.216327 lmp.py:1619]   Expert ID | Tokens | Device
DEBUG 01-14 20:42:42.216732.216732 lmp.py:1620]   -----------------------------------
DEBUG 01-14 20:42:42.216328.216328 lmp.py:1625]   Expert 13 |     23 | CPU
DEBUG 01-14 20:42:42.216495.216495 lmp.py:1625]   Expert 33 |     38 | CPU
DEBUG 01-14 20:42:42.216184.216184 lmp.py:1625]   Expert 44 |     38 | CPU
DEBUG 01-14 20:42:42.216396.216396 lmp.py:1625]   Expert 16 |     40 | CPU
DEBUG 01-14 20:42:42.216324.216324 lmp.py:1625]   Expert  9 |     41 | CPU
DEBUG 01-14 20:42:42.216537.216537 lmp.py:1625]   Expert 38 |     46 | CPU
DEBUG 01-14 20:42:42.216749.216749 lmp.py:1625]   Expert  2 |     50 | CPU
DEBUG 01-14 20:42:42.216723.216723 lmp.py:1625]   Expert 22 |     55 | CPU
DEBUG 01-14 20:42:42.216697.216697 lmp.py:1625]   Expert 25 |     61 | CPU
DEBUG 01-14 20:42:42.216433.216433 lmp.py:1625]   Expert 42 |     63 | CPU
DEBUG 01-14 20:42:42.216168.216168 lmp.py:1625]   Expert 24 |     64 | CPU
DEBUG 01-14 20:42:42.216142.216142 lmp.py:1625]   Expert  5 |     68 | CPU
DEBUG 01-14 20:42:42.216116.216116 lmp.py:1625]   Expert 23 |     77 | CPU
DEBUG 01-14 20:42:42.216090.216090 lmp.py:1625]   Expert 10 |     91 | CPU
DEBUG 01-14 20:42:42.216303.216303 lmp.py:1625]   Expert 55 |    103 | CPU
DEBUG 01-14 20:42:42.216277.216277 lmp.py:1625]   Expert 59 |    103 | CPU
DEBUG 01-14 20:42:42.216966.216966 lmp.py:1625]   Expert 46 |    104 | CPU
DEBUG 01-14 20:42:42.216000.216000 lmp.py:1625]   Expert 61 |    106 | CPU
DEBUG 01-14 20:42:42.216451.216451 lmp.py:1625]   Expert 21 |    109 | CPU
DEBUG 01-14 20:42:42.216332.216332 lmp.py:1625]   Expert  6 |    129 | CPU
DEBUG 01-14 20:42:42.216545.216545 lmp.py:1625]   Expert 31 |    135 | CPU
DEBUG 01-14 20:42:42.216757.216757 lmp.py:1625]   Expert  3 |    138 | CPU
DEBUG 01-14 20:42:42.216731.216731 lmp.py:1625]   Expert 45 |    138 | CPU
DEBUG 01-14 20:42:42.216467.216467 lmp.py:1625]   Expert 36 |    152 | CPU
DEBUG 01-14 20:42:42.216441.216441 lmp.py:1625]   Expert 43 |    154 | CPU
DEBUG 01-14 20:42:42.216654.216654 lmp.py:1625]   Expert 48 |    156 | CPU
DEBUG 01-14 20:42:42.216343.216343 lmp.py:1625]   Expert 26 |    158 | CPU
DEBUG 01-14 20:42:42.216317.216317 lmp.py:1625]   Expert 51 |    161 | CPU
DEBUG 01-14 20:42:42.216529.216529 lmp.py:1625]   Expert 18 |    162 | CPU
DEBUG 01-14 20:42:42.216980.216980 lmp.py:1625]   Expert 41 |    163 | CPU
DEBUG 01-14 20:42:42.216716.216716 lmp.py:1625]   Expert 28 |    166 | CPU
DEBUG 01-14 20:42:42.216928.216928 lmp.py:1625]   Expert  8 |    167 | CPU
DEBUG 01-14 20:42:42.216141.216141 lmp.py:1625]   Expert 56 |    172 | GPU
DEBUG 01-14 20:42:42.216115.216115 lmp.py:1625]   Expert 12 |    176 | GPU
DEBUG 01-14 20:42:42.216327.216327 lmp.py:1625]   Expert 20 |    180 | GPU
DEBUG 01-14 20:42:42.216255.216255 lmp.py:1625]   Expert 27 |    181 | GPU
DEBUG 01-14 20:42:42.216421.216421 lmp.py:1625]   Expert  0 |    183 | GPU
DEBUG 01-14 20:42:42.216157.216157 lmp.py:1625]   Expert  7 |    183 | GPU
DEBUG 01-14 20:42:42.216038.216038 lmp.py:1625]   Expert 47 |    198 | GPU
DEBUG 01-14 20:42:42.216204.216204 lmp.py:1625]   Expert 15 |    211 | GPU
DEBUG 01-14 20:42:42.216132.216132 lmp.py:1625]   Expert  1 |    212 | GPU
DEBUG 01-14 20:42:42.216537.216537 lmp.py:1625]   Expert 34 |    212 | GPU
DEBUG 01-14 20:42:42.216941.216941 lmp.py:1625]   Expert 40 |    222 | GPU
DEBUG 01-14 20:42:42.216107.216107 lmp.py:1625]   Expert 11 |    225 | GPU
DEBUG 01-14 20:42:42.216750.216750 lmp.py:1625]   Expert 32 |    227 | GPU
DEBUG 01-14 20:42:42.216393.216393 lmp.py:1625]   Expert 49 |    233 | GPU
DEBUG 01-14 20:42:42.216798.216798 lmp.py:1625]   Expert 50 |    235 | GPU
DEBUG 01-14 20:42:42.216726.216726 lmp.py:1625]   Expert 53 |    246 | GPU
DEBUG 01-14 20:42:42.216892.216892 lmp.py:1625]   Expert 63 |    249 | GPU
DEBUG 01-14 20:42:42.216058.216058 lmp.py:1625]   Expert 30 |    258 | GPU
DEBUG 01-14 20:42:42.216224.216224 lmp.py:1625]   Expert 29 |    260 | GPU
DEBUG 01-14 20:42:42.216390.216390 lmp.py:1625]   Expert  4 |    261 | GPU
DEBUG 01-14 20:42:42.216272.216272 lmp.py:1625]   Expert 35 |    271 | GPU
DEBUG 01-14 20:42:42.217676.217676 lmp.py:1625]   Expert 14 |    276 | GPU
DEBUG 01-14 20:42:42.217081.217081 lmp.py:1625]   Expert 37 |    304 | GPU
DEBUG 01-14 20:42:42.217724.217724 lmp.py:1625]   Expert 17 |    357 | GPU
DEBUG 01-14 20:42:42.217128.217128 lmp.py:1625]   Expert 52 |    360 | GPU
DEBUG 01-14 20:42:42.217533.217533 lmp.py:1625]   Expert 54 |    369 | GPU
DEBUG 01-14 20:42:42.217699.217699 lmp.py:1625]   Expert 39 |    384 | GPU
DEBUG 01-14 20:42:42.217865.217865 lmp.py:1625]   Expert 57 |    410 | GPU
DEBUG 01-14 20:42:42.217746.217746 lmp.py:1625]   Expert 60 |    447 | GPU
DEBUG 01-14 20:42:42.217389.217389 lmp.py:1625]   Expert 62 |    460 | GPU
DEBUG 01-14 20:42:42.217794.217794 lmp.py:1625]   Expert 19 |    503 | GPU
DEBUG 01-14 20:42:42.217722.217722 lmp.py:1625]   Expert 58 |    564 | GPU
DEBUG 01-14 20:42:42.217080.217080 lmp.py:1626] 
DEBUG 01-14 20:42:42.217080.217080 lmp.py:1626]   CPU total tokens: 3259 (26.5%)
DEBUG 01-14 20:42:42.217677.217677 lmp.py:1627]   GPU total tokens: 9029 (73.5%)
DEBUG 01-14 20:42:42.217565.217565 cuda_h.py:19] end experts_map_get cost 0.0015337467193603516 seconds
DEBUG 01-14 20:42:42.217514.217514 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-14 20:42:42.217741.217741 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-14 20:42:42.217038.217038 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-14 20:42:42.219810.219810 cuda_h.py:19] end allocate_cuda_memory cost 0.0018684864044189453 seconds
DEBUG 01-14 20:42:42.219395.219395 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-14 20:42:42.219536.219536 sllm_store_c.py:27] get device uuid map
DEBUG 01-14 20:42:42.219583.219583 sllm_store_c.py:29] call client load into gpu
DEBUG 01-14 20:42:42.219710.219710 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 4e6db955-d82b-4c20-bde1-b910147039bc
DEBUG 01-14 20:42:42.219312.219312 client.py:106] call stub.LoadModelAsync
INFO 01-14 20:42:42.220111.220111 client.py:127] Model loaded
DEBUG 01-14 20:42:42.220086.220086 cuda_h.py:10] start restore2model
DEBUG 01-14 20:42:42.220464.220464 cuda_h.py:19] end restore2model cost 0.00038433074951171875 seconds
DEBUG 01-14 20:42:42.220486.220486 cuda_h.py:19] end sllm_worker_task cost 0.011880874633789062 seconds
INFO 01-14 20:42:42.221812.221812 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 4e6db955-d82b-4c20-bde1-b910147039bc
DEBUG 01-14 20:42:42.221523.221523 cuda_h.py:19] end load_into_gpu_async cost 0.0016024112701416016 seconds
DEBUG 01-14 20:42:42.221703.221703 cuda_h.py:10] start restore_tensors2
DEBUG 01-14 20:42:42.221735.221735 cuda_h.py:19] end restore_tensors2 cost 0.0003497600555419922 seconds
DEBUG 01-14 20:42:42.221803.221803 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.004200458526611328 seconds
DEBUG 01-14 20:42:42.221427.221427 cuda_h.py:10] start restore2model
DEBUG 01-14 20:42:42.224593.224593 cuda_h.py:19] end restore2model cost 0.0025513172149658203 seconds
DEBUG 01-14 20:42:42.224052.224052 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.006932735443115234 seconds
DEBUG 01-14 20:42:42.224847.224847 cuda_h.py:10] start gpu_sexperts
DEBUG 01-14 20:42:42.224858.224858 cuda_h.py:19] end gpu_sexperts cost 0.0002932548522949219 seconds
DEBUG 01-14 20:42:42.224303.224303 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-14 20:42:42.224914.224914 lmp.py:1683] 
DEBUG 01-14 20:42:42.224914.224914 lmp.py:1683]   Computing 32 experts on CPU...
DEBUG 01-14 20:42:42.224134.224134 cuda_h.py:19] end cpu_experts_submit cost 5.745887756347656e-05 seconds
DEBUG 01-14 20:42:42.224691.224691 cuda_h.py:10] start experts_func_mgpu_group_pad
DEBUG 01-14 20:42:42.239427.239427 mlpmodule.py:1460] group tensors cost 0.014075756072998047 s
DEBUG 01-14 20:42:42.240957.240957 cuda_h.py:10] start move_flat_hidden2cpu
DEBUG 01-14 20:42:42.244956.244956 cuda_h.py:19] end experts_func_mgpu_group_pad cost 0.02008986473083496 seconds
DEBUG 01-14 20:42:42.246278.246278 cuda_h.py:19] end move_flat_hidden2cpu cost 0.006565570831298828 seconds
DEBUG 01-14 20:42:42.248294.248294 cuda_h.py:10] start gpu_group_list
DEBUG 01-14 20:42:42.250085.250085 cuda_h.py:19] end gpu_group_list cost 0.0012345314025878906 seconds
DEBUG 01-14 20:42:42.250524.250524 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-14 20:42:42.250657.250657 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 4.363059997558594e-05 seconds
DEBUG 01-14 20:42:42.250766.250766 cuda_h.py:10] start wait_experts
INFO 01-14 20:42:42.251273.251273 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 4e6db955-d82b-4c20-bde1-b910147039bc
DEBUG 01-14 20:42:42.251374.251374 mlpmodule.py:1533] pad cost 0.0048999786376953125 s
DEBUG 01-14 20:42:42.251583.251583 mlpmodule.py:1539] create cpu tensor cost 3.743171691894531e-05 s
DEBUG 01-14 20:42:42.253220.253220 mlpmodule.py:1544] move to cpu cost 0.0019767284393310547 s
DEBUG 01-14 20:42:42.263050.263050 mlpmodule.py:1558] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-14 20:42:42.263883.263883 mlpmodule.py:1559] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-14 20:42:42.264959.264959 mlpmodule.py:1564] group_w3 first element: -0.02734375
WARNING 01-14 20:42:42.264930.264930 mlpmodule.py:1574] start einsum2
INFO 01-14 20:42:42.275846.275846 client.py:127] Model loaded
DEBUG 01-14 20:42:42.275248.275248 cuda_h.py:19] end wait_experts cost 0.024721384048461914 seconds
DEBUG 01-14 20:42:42.275669.275669 cuda_h.py:10] start gpu_experts
DEBUG 01-14 20:42:42.276930.276930 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-14 20:42:42.281513.281513 mlpmodule.py:1584] group einsum cost 0.027279376983642578 s
DEBUG 01-14 20:42:42.282332.282332 mlpmodule.py:1593] cpy2cputensor cost 0.0007090568542480469 s
DEBUG 01-14 20:42:42.282870.282870 cuda_h.py:10] start move_outputs
DEBUG 01-14 20:42:42.284599.284599 cuda_h.py:19] end move_outputs cost 0.0019440650939941406 seconds
DEBUG 01-14 20:42:42.287273.287273 cuda_h.py:19] end wait_cetm_experts cost 0.01175069808959961 seconds
DEBUG 01-14 20:42:42.288094.288094 cuda_h.py:10] start gpu_group_einsum_mp_multi_list
DEBUG 01-14 20:42:42.288532.288532 cuda_h.py:10] start gpu_group_tensor
DEBUG 01-14 20:42:42.288336.288336 cuda_h.py:19] end gpu_group_tensor cost 0.000240325927734375 seconds
DEBUG 01-14 20:42:42.288719.288719 cuda_h.py:10] start gpu_group_einsum
DEBUG 01-14 20:42:42.289094.289094 cuda_h.py:19] end gpu_group_einsum cost 0.0006768703460693359 seconds
DEBUG 01-14 20:42:42.289483.289483 cuda_h.py:10] start gpu_final_hidden_states_scatter
DEBUG 01-14 20:42:42.289909.289909 cuda_h.py:10] start all_expert_outputs_slices
DEBUG 01-14 20:42:42.289466.289466 cuda_h.py:19] end all_expert_outputs_slices cost 0.0003705024719238281 seconds
DEBUG 01-14 20:42:42.289984.289984 cuda_h.py:10] start concat_expert_out
DEBUG 01-14 20:42:42.289967.289967 cuda_h.py:19] end concat_expert_out cost 5.817413330078125e-05 seconds
DEBUG 01-14 20:42:42.290770.290770 cuda_h.py:10] start index_scatter
DEBUG 01-14 20:42:42.290105.290105 cuda_h.py:19] end index_scatter cost 7.2479248046875e-05 seconds
DEBUG 01-14 20:42:42.290722.290722 cuda_h.py:19] end gpu_final_hidden_states_scatter cost 0.0007593631744384766 seconds
DEBUG 01-14 20:42:42.290639.290639 cuda_h.py:19] end gpu_experts cost 0.014288187026977539 seconds
DEBUG 01-14 20:42:42.290342.290342 cuda_h.py:10] start all_expert_weight_slices
DEBUG 01-14 20:42:42.291587.291587 cuda_h.py:19] end all_expert_weight_slices cost 0.0009565353393554688 seconds
DEBUG 01-14 20:42:42.291979.291979 cuda_h.py:10] start cpuoutputsdeal
DEBUG 01-14 20:42:42.291046.291046 cuda_h.py:10] start index_scatter
DEBUG 01-14 20:42:42.291182.291182 cuda_h.py:19] end index_scatter cost 4.982948303222656e-05 seconds
DEBUG 01-14 20:42:42.291899.291899 cuda_h.py:19] end cpuoutputsdeal cost 0.0005443096160888672 seconds
DEBUG 01-14 20:42:42.291901.291901 cuda_h.py:19] end layer_moe_generate_mp_l_26 cost 0.07703590393066406 seconds
DEBUG 01-14 20:42:42.292352.292352 cuda_h.py:19] end prefill_layer cost 0.08408141136169434 seconds
DEBUG 01-14 20:42:42.292249.292249 lmp.py:1551] -------------------------------- end prefill layer 25 --------------------------------
DEBUG 01-14 20:42:42.292396.292396 cuda_h.py:10] start prefill_layer
DEBUG 01-14 20:42:42.292768.292768 lmp.py:1494] -------------------------------- start prefill layer 26 --------------------------------
DEBUG 01-14 20:42:42.292186.292186 cuda_h.py:10] start start_load_qkvogn_s_weight_l_27
DEBUG 01-14 20:42:42.292227.292227 cuda_h.py:10] start start_load_qkvogn_s_weight_l_27
DEBUG 01-14 20:42:42.292361.292361 cuda_h.py:19] end start_load_qkvogn_s_weight_l_27 cost 3.647804260253906e-05 seconds
DEBUG 01-14 20:42:42.292647.292647 cuda_h.py:19] end start_load_qkvogn_s_weight_l_27 cost 7.462501525878906e-05 seconds
DEBUG 01-14 20:42:42.292535.292535 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-14 20:42:42.292531.292531 cuda_h.py:10] start sllm_worker_task
DEBUG 01-14 20:42:42.292488.292488 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-14 20:42:42.292616.292616 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-14 20:42:42.294170.294170 cuda_h.py:19] end allocate_cuda_memory cost 0.0012807846069335938 seconds
DEBUG 01-14 20:42:42.294034.294034 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-14 20:42:42.294850.294850 sllm_store_c.py:27] get device uuid map
DEBUG 01-14 20:42:42.294924.294924 sllm_store_c.py:29] call client load into gpu
DEBUG 01-14 20:42:42.294396.294396 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 604ba708-6a12-41f8-ab76-f252778e8dfe
DEBUG 01-14 20:42:42.294584.294584 client.py:106] call stub.LoadModelAsync
DEBUG 01-14 20:42:42.294280.294280 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-14 20:42:42.295477.295477 cuda_h.py:10] start self_attn
INFO 01-14 20:42:42.295589.295589 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 604ba708-6a12-41f8-ab76-f252778e8dfe
DEBUG 01-14 20:42:42.295432.295432 cuda_h.py:19] end load_into_gpu_async cost 0.0013768672943115234 seconds
DEBUG 01-14 20:42:42.295519.295519 cuda_h.py:10] start restore_tensors2
DEBUG 01-14 20:42:42.295391.295391 cuda_h.py:19] end restore_tensors2 cost 8.606910705566406e-05 seconds
DEBUG 01-14 20:42:42.295008.295008 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.003017902374267578 seconds
INFO 01-14 20:42:42.296580.296580 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 604ba708-6a12-41f8-ab76-f252778e8dfe
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
DEBUG 01-14 20:42:42.297367.297367 mlpmodule.py:1367]  experts func einsum cost 0.07245206832885742 s
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-14 20:42:42.298864.298864 cuda_h.py:19] end self_attn cost 0.0033714771270751953 seconds
DEBUG 01-14 20:42:42.298312.298312 cuda_h.py:19] end iln_self_attn_paln cost 0.006156444549560547 seconds
DEBUG 01-14 20:42:42.298930.298930 cuda_h.py:10] start layer_moe_generate_mp_l_27
DEBUG 01-14 20:42:42.299408.299408 cuda_h.py:10] start gate
DEBUG 01-14 20:42:42.299981.299981 cuda_h.py:19] end gate cost 0.0006296634674072266 seconds
DEBUG 01-14 20:42:42.299055.299055 cuda_h.py:10] start experts_map_get
DEBUG 01-14 20:42:42.300708.300708 lmp.py:1615] 
DEBUG 01-14 20:42:42.300708.300708 lmp.py:1615] Expert Token Distribution & Device Allocation:
DEBUG 01-14 20:42:42.300702.300702 lmp.py:1616]   Total experts: 64
DEBUG 01-14 20:42:42.300590.300590 lmp.py:1617]   CPU experts: 32 (50%)
DEBUG 01-14 20:42:42.300141.300141 lmp.py:1618]   GPU experts: 32 (50%)
DEBUG 01-14 20:42:42.300545.300545 lmp.py:1619] 
DEBUG 01-14 20:42:42.300545.300545 lmp.py:1619]   Expert ID | Tokens | Device
DEBUG 01-14 20:42:42.300950.300950 lmp.py:1620]   -----------------------------------
DEBUG 01-14 20:42:42.300546.300546 lmp.py:1625]   Expert 20 |     16 | CPU
DEBUG 01-14 20:42:42.300474.300474 lmp.py:1625]   Expert 61 |     22 | CPU
DEBUG 01-14 20:42:42.300925.300925 lmp.py:1625]   Expert 51 |     36 | CPU
DEBUG 01-14 20:42:42.300138.300138 lmp.py:1625]   Expert 62 |     41 | CPU
DEBUG 01-14 20:42:42.300588.300588 lmp.py:1625]   Expert 11 |     46 | CPU
DEBUG 01-14 20:42:42.300801.300801 lmp.py:1625]   Expert  7 |     49 | CPU
DEBUG 01-14 20:42:42.300013.300013 lmp.py:1625]   Expert  3 |     54 | CPU
DEBUG 01-14 20:42:42.300180.300180 lmp.py:1625]   Expert 30 |     56 | CPU
DEBUG 01-14 20:42:42.300630.300630 lmp.py:1625]   Expert 29 |     59 | CPU
DEBUG 01-14 20:42:42.300366.300366 lmp.py:1625]   Expert  9 |     65 | CPU
DEBUG 01-14 20:42:42.300340.300340 lmp.py:1625]   Expert 17 |     67 | CPU
DEBUG 01-14 20:42:42.300076.300076 lmp.py:1625]   Expert 59 |     67 | CPU
DEBUG 01-14 20:42:42.300050.300050 lmp.py:1625]   Expert  8 |     72 | CPU
DEBUG 01-14 20:42:42.300785.300785 lmp.py:1625]   Expert  6 |     74 | CPU
DEBUG 01-14 20:42:42.300104.300104 lmp.py:1625]   Expert 63 |     86 | CPU
DEBUG 01-14 20:42:42.300939.300939 lmp.py:1625]   Expert 38 |     95 | CPU
DEBUG 01-14 20:42:42.300059.300059 lmp.py:1625]   Expert 48 |     96 | CPU
DEBUG 01-14 20:42:42.300940.300940 lmp.py:1625]   Expert 55 |     97 | CPU
DEBUG 01-14 20:42:42.300106.300106 lmp.py:1625]   Expert 49 |    108 | CPU
DEBUG 01-14 20:42:42.300034.300034 lmp.py:1625]   Expert 24 |    109 | CPU
DEBUG 01-14 20:42:42.300200.300200 lmp.py:1625]   Expert 19 |    114 | CPU
DEBUG 01-14 20:42:42.300128.300128 lmp.py:1625]   Expert 50 |    118 | CPU
DEBUG 01-14 20:42:42.300294.300294 lmp.py:1625]   Expert 39 |    120 | CPU
DEBUG 01-14 20:42:42.300983.300983 lmp.py:1625]   Expert 36 |    122 | CPU
DEBUG 01-14 20:42:42.300434.300434 lmp.py:1625]   Expert  4 |    123 | CPU
DEBUG 01-14 20:42:42.300839.300839 lmp.py:1625]   Expert 42 |    127 | CPU
DEBUG 01-14 20:42:42.300005.300005 lmp.py:1625]   Expert 41 |    133 | CPU
DEBUG 01-14 20:42:42.300933.300933 lmp.py:1625]   Expert 34 |    138 | CPU
DEBUG 01-14 20:42:42.300099.300099 lmp.py:1625]   Expert 22 |    139 | CPU
DEBUG 01-14 20:42:42.300027.300027 lmp.py:1625]   Expert 37 |    154 | CPU
DEBUG 01-14 20:42:42.300954.300954 lmp.py:1625]   Expert 15 |    159 | CPU
DEBUG 01-14 20:42:42.300882.300882 lmp.py:1625]   Expert 56 |    160 | CPU
DEBUG 01-14 20:42:42.300810.300810 lmp.py:1625]   Expert 60 |    161 | GPU
DEBUG 01-14 20:42:42.300261.300261 lmp.py:1625]   Expert 21 |    169 | GPU
DEBUG 01-14 20:42:42.300665.300665 lmp.py:1625]   Expert 23 |    170 | GPU
DEBUG 01-14 20:42:42.300831.300831 lmp.py:1625]   Expert 44 |    174 | GPU
DEBUG 01-14 20:42:42.300759.300759 lmp.py:1625]   Expert 16 |    178 | GPU
DEBUG 01-14 20:42:42.300210.300210 lmp.py:1625]   Expert 33 |    179 | GPU
DEBUG 01-14 20:42:42.300615.300615 lmp.py:1625]   Expert 47 |    182 | GPU
DEBUG 01-14 20:42:42.300542.300542 lmp.py:1625]   Expert  1 |    190 | GPU
DEBUG 01-14 20:42:42.300470.300470 lmp.py:1625]   Expert 43 |    190 | GPU
DEBUG 01-14 20:42:42.300398.300398 lmp.py:1625]   Expert 13 |    205 | GPU
DEBUG 01-14 20:42:42.300087.300087 lmp.py:1625]   Expert 53 |    208 | GPU
DEBUG 01-14 20:42:42.300684.300684 lmp.py:1625]   Expert 32 |    226 | GPU
DEBUG 01-14 20:42:42.300565.300565 lmp.py:1625]   Expert 28 |    229 | GPU
DEBUG 01-14 20:42:42.300493.300493 lmp.py:1625]   Expert 12 |    233 | GPU
DEBUG 01-14 20:42:42.300420.300420 lmp.py:1625]   Expert  2 |    244 | GPU
DEBUG 01-14 20:42:42.300587.300587 lmp.py:1625]   Expert 25 |    249 | GPU
DEBUG 01-14 20:42:42.300037.300037 lmp.py:1625]   Expert 31 |    250 | GPU
DEBUG 01-14 20:42:42.300396.300396 lmp.py:1625]   Expert 26 |    259 | GPU
DEBUG 01-14 20:42:42.301562.301562 lmp.py:1625]   Expert  0 |    261 | GPU
DEBUG 01-14 20:42:42.301251.301251 lmp.py:1625]   Expert 18 |    267 | GPU
DEBUG 01-14 20:42:42.301656.301656 lmp.py:1625]   Expert 57 |    273 | GPU
DEBUG 01-14 20:42:42.301583.301583 lmp.py:1625]   Expert 10 |    276 | GPU
DEBUG 01-14 20:42:42.301511.301511 lmp.py:1625]   Expert 54 |    276 | GPU
DEBUG 01-14 20:42:42.301916.301916 lmp.py:1625]   Expert 58 |    280 | GPU
DEBUG 01-14 20:42:42.301843.301843 lmp.py:1625]   Expert 40 |    328 | GPU
DEBUG 01-14 20:42:42.301010.301010 lmp.py:1625]   Expert 45 |    379 | GPU
DEBUG 01-14 20:42:42.301937.301937 lmp.py:1625]   Expert 35 |    439 | GPU
DEBUG 01-14 20:42:42.301342.301342 lmp.py:1625]   Expert  5 |    472 | GPU
DEBUG 01-14 20:42:42.301985.301985 lmp.py:1625]   Expert 46 |    494 | GPU
DEBUG 01-14 20:42:42.301151.301151 lmp.py:1625]   Expert 27 |    511 | GPU
DEBUG 01-14 20:42:42.301317.301317 lmp.py:1625]   Expert 52 |    560 | GPU
DEBUG 01-14 20:42:42.301245.301245 lmp.py:1625]   Expert 14 |    854 | GPU
DEBUG 01-14 20:42:42.301888.301888 lmp.py:1626] 
DEBUG 01-14 20:42:42.301888.301888 lmp.py:1626]   CPU total tokens: 2922 (23.8%)
DEBUG 01-14 20:42:42.301008.301008 lmp.py:1627]   GPU total tokens: 9366 (76.2%)
DEBUG 01-14 20:42:42.301657.301657 cuda_h.py:19] end experts_map_get cost 0.0015385150909423828 seconds
DEBUG 01-14 20:42:42.301130.301130 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-14 20:42:42.301688.301688 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-14 20:42:42.301799.301799 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-14 20:42:42.303121.303121 cuda_h.py:19] end allocate_cuda_memory cost 0.0014667510986328125 seconds
DEBUG 01-14 20:42:42.303382.303382 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-14 20:42:42.303953.303953 sllm_store_c.py:27] get device uuid map
DEBUG 01-14 20:42:42.303716.303716 sllm_store_c.py:29] call client load into gpu
DEBUG 01-14 20:42:42.303604.303604 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 9a6207eb-2c28-4c66-9c7c-3ba85e67297a
DEBUG 01-14 20:42:42.303683.303683 client.py:106] call stub.LoadModelAsync
INFO 01-14 20:42:42.303201.303201 client.py:127] Model loaded
DEBUG 01-14 20:42:42.303985.303985 cuda_h.py:10] start restore2model
DEBUG 01-14 20:42:42.304513.304513 cuda_h.py:19] end restore2model cost 0.000324249267578125 seconds
DEBUG 01-14 20:42:42.304183.304183 cuda_h.py:19] end sllm_worker_task cost 0.01126861572265625 seconds
INFO 01-14 20:42:42.304873.304873 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 9a6207eb-2c28-4c66-9c7c-3ba85e67297a
DEBUG 01-14 20:42:42.304671.304671 cuda_h.py:19] end load_into_gpu_async cost 0.0012629032135009766 seconds
DEBUG 01-14 20:42:42.304089.304089 cuda_h.py:10] start restore_tensors2
DEBUG 01-14 20:42:42.304015.304015 cuda_h.py:19] end restore_tensors2 cost 0.00034117698669433594 seconds
DEBUG 01-14 20:42:42.304083.304083 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.003464221954345703 seconds
DEBUG 01-14 20:42:42.304707.304707 cuda_h.py:10] start restore2model
DEBUG 01-14 20:42:42.307264.307264 cuda_h.py:19] end restore2model cost 0.002553224563598633 seconds
DEBUG 01-14 20:42:42.307292.307292 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.006201028823852539 seconds
DEBUG 01-14 20:42:42.307041.307041 cuda_h.py:10] start gpu_sexperts
DEBUG 01-14 20:42:42.307608.307608 cuda_h.py:19] end gpu_sexperts cost 0.0002803802490234375 seconds
DEBUG 01-14 20:42:42.307053.307053 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-14 20:42:42.308379.308379 lmp.py:1683] 
DEBUG 01-14 20:42:42.308379.308379 lmp.py:1683]   Computing 32 experts on CPU...
DEBUG 01-14 20:42:42.308652.308652 cuda_h.py:19] end cpu_experts_submit cost 6.0558319091796875e-05 seconds
DEBUG 01-14 20:42:42.308209.308209 cuda_h.py:10] start experts_func_mgpu_group_pad
DEBUG 01-14 20:42:42.324514.324514 mlpmodule.py:1460] group tensors cost 0.015798568725585938 s
DEBUG 01-14 20:42:42.325244.325244 cuda_h.py:10] start move_flat_hidden2cpu
DEBUG 01-14 20:42:42.327773.327773 cuda_h.py:19] end experts_func_mgpu_group_pad cost 0.01953577995300293 seconds
DEBUG 01-14 20:42:42.329147.329147 cuda_h.py:10] start gpu_group_list
DEBUG 01-14 20:42:42.330659.330659 cuda_h.py:19] end gpu_group_list cost 0.00054931640625 seconds
DEBUG 01-14 20:42:42.330561.330561 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-14 20:42:42.330299.330299 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.47955322265625e-05 seconds
DEBUG 01-14 20:42:42.330877.330877 cuda_h.py:10] start wait_experts
INFO 01-14 20:42:42.330216.330216 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 9a6207eb-2c28-4c66-9c7c-3ba85e67297a
DEBUG 01-14 20:42:42.331102.331102 cuda_h.py:19] end move_flat_hidden2cpu cost 0.00635075569152832 seconds
DEBUG 01-14 20:42:42.333330.333330 mlpmodule.py:1533] pad cost 0.0015745162963867188 s
DEBUG 01-14 20:42:42.333419.333419 mlpmodule.py:1539] create cpu tensor cost 3.528594970703125e-05 s
DEBUG 01-14 20:42:42.335464.335464 mlpmodule.py:1544] move to cpu cost 0.001894235610961914 s
DEBUG 01-14 20:42:42.345195.345195 mlpmodule.py:1558] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-14 20:42:42.345333.345333 mlpmodule.py:1559] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-14 20:42:42.345846.345846 mlpmodule.py:1564] group_w3 first element: -0.0024261474609375
WARNING 01-14 20:42:42.345638.345638 mlpmodule.py:1574] start einsum2
INFO 01-14 20:42:42.359458.359458 client.py:127] Model loaded
DEBUG 01-14 20:42:42.360578.360578 cuda_h.py:19] end wait_experts cost 0.029587984085083008 seconds
DEBUG 01-14 20:42:42.360488.360488 cuda_h.py:10] start gpu_experts
DEBUG 01-14 20:42:42.360822.360822 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-14 20:42:42.362580.362580 mlpmodule.py:1584] group einsum cost 0.027121305465698242 s
DEBUG 01-14 20:42:42.363065.363065 mlpmodule.py:1593] cpy2cputensor cost 0.0006799697875976562 s
DEBUG 01-14 20:42:42.363173.363173 cuda_h.py:10] start move_outputs
DEBUG 01-14 20:42:42.365985.365985 cuda_h.py:19] end move_outputs cost 0.0018658638000488281 seconds
DEBUG 01-14 20:42:42.368059.368059 cuda_h.py:19] end wait_cetm_experts cost 0.008605480194091797 seconds
DEBUG 01-14 20:42:42.368335.368335 cuda_h.py:10] start gpu_group_einsum_mp_multi_list
DEBUG 01-14 20:42:42.369197.369197 cuda_h.py:10] start gpu_group_tensor
DEBUG 01-14 20:42:42.369193.369193 cuda_h.py:19] end gpu_group_tensor cost 0.0002448558807373047 seconds
DEBUG 01-14 20:42:42.369787.369787 cuda_h.py:10] start gpu_group_einsum
DEBUG 01-14 20:42:42.370076.370076 cuda_h.py:19] end gpu_group_einsum cost 0.0006864070892333984 seconds
DEBUG 01-14 20:42:42.370856.370856 cuda_h.py:10] start gpu_final_hidden_states_scatter
DEBUG 01-14 20:42:42.370859.370859 cuda_h.py:10] start all_expert_outputs_slices
DEBUG 01-14 20:42:42.370548.370548 cuda_h.py:19] end all_expert_outputs_slices cost 0.00036144256591796875 seconds
DEBUG 01-14 20:42:42.370350.370350 cuda_h.py:10] start concat_expert_out
DEBUG 01-14 20:42:42.370241.370241 cuda_h.py:19] end concat_expert_out cost 5.817413330078125e-05 seconds
DEBUG 01-14 20:42:42.370475.370475 cuda_h.py:10] start index_scatter
DEBUG 01-14 20:42:42.371240.371240 cuda_h.py:19] end index_scatter cost 7.295608520507812e-05 seconds
DEBUG 01-14 20:42:42.371718.371718 cuda_h.py:19] end gpu_final_hidden_states_scatter cost 0.0007598400115966797 seconds
DEBUG 01-14 20:42:42.371065.371065 cuda_h.py:19] end gpu_experts cost 0.011053085327148438 seconds
DEBUG 01-14 20:42:42.371245.371245 cuda_h.py:10] start all_expert_weight_slices
DEBUG 01-14 20:42:42.372219.372219 cuda_h.py:19] end all_expert_weight_slices cost 0.0009675025939941406 seconds
DEBUG 01-14 20:42:42.372293.372293 cuda_h.py:10] start cpuoutputsdeal
DEBUG 01-14 20:42:42.372011.372011 cuda_h.py:10] start index_scatter
DEBUG 01-14 20:42:42.372683.372683 cuda_h.py:19] end index_scatter cost 5.316734313964844e-05 seconds
DEBUG 01-14 20:42:42.372830.372830 cuda_h.py:19] end cpuoutputsdeal cost 0.0005767345428466797 seconds
DEBUG 01-14 20:42:42.372217.372217 cuda_h.py:19] end layer_moe_generate_mp_l_27 cost 0.07398414611816406 seconds
DEBUG 01-14 20:42:42.373369.373369 cuda_h.py:19] end prefill_layer cost 0.08084630966186523 seconds
DEBUG 01-14 20:42:42.373490.373490 lmp.py:1551] -------------------------------- end prefill layer 26 --------------------------------
DEBUG 01-14 20:42:42.373193.373193 cuda_h.py:10] start prefill_layer
DEBUG 01-14 20:42:42.373373.373373 lmp.py:1494] -------------------------------- start prefill layer 27 --------------------------------
DEBUG 01-14 20:42:42.373599.373599 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-14 20:42:42.373568.373568 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-14 20:42:42.373042.373042 cuda_h.py:10] start self_attn
DEBUG 01-14 20:42:42.377737.377737 mlpmodule.py:1367]  experts func einsum cost 0.06839752197265625 s
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-14 20:42:42.378850.378850 cuda_h.py:19] end self_attn cost 0.004461526870727539 seconds
DEBUG 01-14 20:42:42.378934.378934 cuda_h.py:19] end iln_self_attn_paln cost 0.0052356719970703125 seconds
DEBUG 01-14 20:42:42.378168.378168 cuda_h.py:10] start layer_moe_generate_mp_l_28
DEBUG 01-14 20:42:42.378977.378977 cuda_h.py:10] start gate
DEBUG 01-14 20:42:42.379025.379025 cuda_h.py:19] end gate cost 0.0005960464477539062 seconds
DEBUG 01-14 20:42:42.379669.379669 cuda_h.py:10] start experts_map_get
DEBUG 01-14 20:42:42.379759.379759 lmp.py:1615] 
DEBUG 01-14 20:42:42.379759.379759 lmp.py:1615] Expert Token Distribution & Device Allocation:
DEBUG 01-14 20:42:42.379515.379515 lmp.py:1616]   Total experts: 64
DEBUG 01-14 20:42:42.379165.379165 lmp.py:1617]   CPU experts: 32 (50%)
DEBUG 01-14 20:42:42.379715.379715 lmp.py:1618]   GPU experts: 32 (50%)
DEBUG 01-14 20:42:42.379404.379404 lmp.py:1619] 
DEBUG 01-14 20:42:42.379404.379404 lmp.py:1619]   Expert ID | Tokens | Device
DEBUG 01-14 20:42:42.379570.379570 lmp.py:1620]   -----------------------------------
DEBUG 01-14 20:42:42.380167.380167 lmp.py:1625]   Expert 48 |     63 | CPU
DEBUG 01-14 20:42:42.380618.380618 lmp.py:1625]   Expert 47 |     64 | CPU
DEBUG 01-14 20:42:42.380830.380830 lmp.py:1625]   Expert 18 |     73 | CPU
DEBUG 01-14 20:42:42.380043.380043 lmp.py:1625]   Expert 54 |     79 | CPU
DEBUG 01-14 20:42:42.380209.380209 lmp.py:1625]   Expert 44 |     85 | CPU
DEBUG 01-14 20:42:42.380421.380421 lmp.py:1625]   Expert 45 |     89 | CPU
DEBUG 01-14 20:42:42.380634.380634 lmp.py:1625]   Expert 20 |     94 | CPU
DEBUG 01-14 20:42:42.380846.380846 lmp.py:1625]   Expert 23 |     94 | CPU
DEBUG 01-14 20:42:42.380820.380820 lmp.py:1625]   Expert 11 |     98 | CPU
DEBUG 01-14 20:42:42.380033.380033 lmp.py:1625]   Expert 61 |    102 | CPU
DEBUG 01-14 20:42:42.380484.380484 lmp.py:1625]   Expert 31 |    113 | CPU
DEBUG 01-14 20:42:42.380458.380458 lmp.py:1625]   Expert 36 |    114 | CPU
DEBUG 01-14 20:42:42.380432.380432 lmp.py:1625]   Expert 24 |    115 | CPU
DEBUG 01-14 20:42:42.380644.380644 lmp.py:1625]   Expert  5 |    118 | CPU
DEBUG 01-14 20:42:42.380095.380095 lmp.py:1625]   Expert 10 |    125 | CPU
DEBUG 01-14 20:42:42.380785.380785 lmp.py:1625]   Expert 17 |    128 | CPU
DEBUG 01-14 20:42:42.380997.380997 lmp.py:1625]   Expert 42 |    128 | CPU
DEBUG 01-14 20:42:42.380733.380733 lmp.py:1625]   Expert  6 |    129 | CPU
DEBUG 01-14 20:42:42.380945.380945 lmp.py:1625]   Expert 49 |    129 | CPU
DEBUG 01-14 20:42:42.380681.380681 lmp.py:1625]   Expert 33 |    130 | CPU
DEBUG 01-14 20:42:42.380416.380416 lmp.py:1625]   Expert 43 |    134 | CPU
DEBUG 01-14 20:42:42.380152.380152 lmp.py:1625]   Expert 56 |    134 | CPU
DEBUG 01-14 20:42:42.380126.380126 lmp.py:1625]   Expert 57 |    139 | CPU
DEBUG 01-14 20:42:42.380577.380577 lmp.py:1625]   Expert 12 |    154 | CPU
DEBUG 01-14 20:42:42.380041.380041 lmp.py:1625]   Expert  0 |    158 | CPU
DEBUG 01-14 20:42:42.380492.380492 lmp.py:1625]   Expert 51 |    159 | CPU
DEBUG 01-14 20:42:42.380466.380466 lmp.py:1625]   Expert 46 |    162 | CPU
DEBUG 01-14 20:42:42.380440.380440 lmp.py:1625]   Expert 38 |    163 | CPU
DEBUG 01-14 20:42:42.380176.380176 lmp.py:1625]   Expert 59 |    164 | CPU
DEBUG 01-14 20:42:42.380388.380388 lmp.py:1625]   Expert 26 |    166 | CPU
DEBUG 01-14 20:42:42.380124.380124 lmp.py:1625]   Expert 35 |    168 | CPU
DEBUG 01-14 20:42:42.380052.380052 lmp.py:1625]   Expert 13 |    174 | CPU
DEBUG 01-14 20:42:42.380979.380979 lmp.py:1625]   Expert 16 |    174 | GPU
DEBUG 01-14 20:42:42.380192.380192 lmp.py:1625]   Expert 40 |    174 | GPU
DEBUG 01-14 20:42:42.380166.380166 lmp.py:1625]   Expert 55 |    174 | GPU
DEBUG 01-14 20:42:42.380378.380378 lmp.py:1625]   Expert 50 |    176 | GPU
DEBUG 01-14 20:42:42.380591.380591 lmp.py:1625]   Expert 58 |    181 | GPU
DEBUG 01-14 20:42:42.380565.380565 lmp.py:1625]   Expert  7 |    184 | GPU
DEBUG 01-14 20:42:42.380539.380539 lmp.py:1625]   Expert 30 |    190 | GPU
DEBUG 01-14 20:42:42.380275.380275 lmp.py:1625]   Expert 15 |    195 | GPU
DEBUG 01-14 20:42:42.380964.380964 lmp.py:1625]   Expert  1 |    202 | GPU
DEBUG 01-14 20:42:42.380653.380653 lmp.py:1625]   Expert 14 |    206 | GPU
DEBUG 01-14 20:42:42.380866.380866 lmp.py:1625]   Expert 32 |    213 | GPU
DEBUG 01-14 20:42:42.380601.380601 lmp.py:1625]   Expert  4 |    218 | GPU
DEBUG 01-14 20:42:42.380575.380575 lmp.py:1625]   Expert  3 |    227 | GPU
DEBUG 01-14 20:42:42.380311.380311 lmp.py:1625]   Expert 25 |    234 | GPU
DEBUG 01-14 20:42:42.380047.380047 lmp.py:1625]   Expert 28 |    235 | GPU
DEBUG 01-14 20:42:42.380782.380782 lmp.py:1625]   Expert 34 |    240 | GPU
DEBUG 01-14 20:42:42.380756.380756 lmp.py:1625]   Expert 39 |    248 | GPU
DEBUG 01-14 20:42:42.380207.380207 lmp.py:1625]   Expert 22 |    255 | GPU
DEBUG 01-14 20:42:42.380420.380420 lmp.py:1625]   Expert 52 |    259 | GPU
DEBUG 01-14 20:42:42.380155.380155 lmp.py:1625]   Expert 60 |    261 | GPU
DEBUG 01-14 20:42:42.380129.380129 lmp.py:1625]   Expert  2 |    269 | GPU
DEBUG 01-14 20:42:42.380626.380626 lmp.py:1625]   Expert 41 |    285 | GPU
DEBUG 01-14 20:42:42.380362.380362 lmp.py:1625]   Expert 27 |    291 | GPU
DEBUG 01-14 20:42:42.380859.380859 lmp.py:1625]   Expert 21 |    295 | GPU
DEBUG 01-14 20:42:42.380833.380833 lmp.py:1625]   Expert 63 |    296 | GPU
DEBUG 01-14 20:42:42.380569.380569 lmp.py:1625]   Expert 29 |    303 | GPU
DEBUG 01-14 20:42:42.380020.380020 lmp.py:1625]   Expert 62 |    303 | GPU
DEBUG 01-14 20:42:42.380471.380471 lmp.py:1625]   Expert  8 |    339 | GPU
DEBUG 01-14 20:42:42.380968.380968 lmp.py:1625]   Expert 37 |    341 | GPU
DEBUG 01-14 20:42:42.380942.380942 lmp.py:1625]   Expert 53 |    342 | GPU
DEBUG 01-14 20:42:42.381678.381678 lmp.py:1625]   Expert 19 |    460 | GPU
DEBUG 01-14 20:42:42.381175.381175 lmp.py:1625]   Expert  9 |    573 | GPU
DEBUG 01-14 20:42:42.381626.381626 lmp.py:1626] 
DEBUG 01-14 20:42:42.381626.381626 lmp.py:1626]   CPU total tokens: 3945 (32.1%)
DEBUG 01-14 20:42:42.381792.381792 lmp.py:1627]   GPU total tokens: 8343 (67.9%)
DEBUG 01-14 20:42:42.381773.381773 cuda_h.py:19] end experts_map_get cost 0.0014879703521728516 seconds
DEBUG 01-14 20:42:42.381384.381384 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-14 20:42:42.381658.381658 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-14 20:42:42.381530.381530 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-14 20:42:42.381490.381490 cuda_h.py:19] end allocate_cuda_memory cost 0.0003571510314941406 seconds
DEBUG 01-14 20:42:42.381254.381254 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-14 20:42:42.381110.381110 sllm_store_c.py:27] get device uuid map
DEBUG 01-14 20:42:42.381217.381217 sllm_store_c.py:29] call client load into gpu
DEBUG 01-14 20:42:42.381443.381443 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 5c35d5dd-6b83-445a-8a5f-700a397e30cf
DEBUG 01-14 20:42:42.382365.382365 client.py:106] call stub.LoadModelAsync
INFO 01-14 20:42:42.384925.384925 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 5c35d5dd-6b83-445a-8a5f-700a397e30cf
DEBUG 01-14 20:42:42.384307.384307 cuda_h.py:19] end load_into_gpu_async cost 0.0023050308227539062 seconds
DEBUG 01-14 20:42:42.384369.384369 cuda_h.py:10] start restore_tensors2
DEBUG 01-14 20:42:42.384195.384195 cuda_h.py:19] end restore_tensors2 cost 0.00047206878662109375 seconds
DEBUG 01-14 20:42:42.384601.384601 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.003620624542236328 seconds
DEBUG 01-14 20:42:42.384609.384609 cuda_h.py:10] start restore2model
DEBUG 01-14 20:42:42.387780.387780 cuda_h.py:19] end restore2model cost 0.0025207996368408203 seconds
DEBUG 01-14 20:42:42.387425.387425 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.006322383880615234 seconds
DEBUG 01-14 20:42:42.387240.387240 cuda_h.py:10] start gpu_sexperts
DEBUG 01-14 20:42:42.387907.387907 cuda_h.py:19] end gpu_sexperts cost 0.00027823448181152344 seconds
DEBUG 01-14 20:42:42.387590.387590 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-14 20:42:42.387677.387677 lmp.py:1683] 
DEBUG 01-14 20:42:42.387677.387677 lmp.py:1683]   Computing 32 experts on CPU...
DEBUG 01-14 20:42:42.387713.387713 cuda_h.py:19] end cpu_experts_submit cost 6.151199340820312e-05 seconds
DEBUG 01-14 20:42:42.388892.388892 cuda_h.py:10] start experts_func_mgpu_group_pad
DEBUG 01-14 20:42:42.392545.392545 mlpmodule.py:1460] group tensors cost 0.0042917728424072266 s
DEBUG 01-14 20:42:42.393797.393797 cuda_h.py:10] start move_flat_hidden2cpu
DEBUG 01-14 20:42:42.398163.398163 cuda_h.py:19] end experts_func_mgpu_group_pad cost 0.009996414184570312 seconds
DEBUG 01-14 20:42:42.399872.399872 cuda_h.py:19] end move_flat_hidden2cpu cost 0.006474971771240234 seconds
DEBUG 01-14 20:42:42.401527.401527 cuda_h.py:10] start gpu_group_list
DEBUG 01-14 20:42:42.402253.402253 cuda_h.py:19] end gpu_group_list cost 0.0009386539459228516 seconds
DEBUG 01-14 20:42:42.402048.402048 cuda_h.py:10] start wait_experts
INFO 01-14 20:42:42.402377.402377 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 5c35d5dd-6b83-445a-8a5f-700a397e30cf
DEBUG 01-14 20:42:42.403598.403598 mlpmodule.py:1533] pad cost 0.0037512779235839844 s
DEBUG 01-14 20:42:42.403569.403569 mlpmodule.py:1539] create cpu tensor cost 3.695487976074219e-05 s
DEBUG 01-14 20:42:42.405745.405745 mlpmodule.py:1544] move to cpu cost 0.0020575523376464844 s
DEBUG 01-14 20:42:42.415583.415583 mlpmodule.py:1558] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-14 20:42:42.416561.416561 mlpmodule.py:1559] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-14 20:42:42.416783.416783 mlpmodule.py:1564] group_w3 first element: -0.006439208984375
WARNING 01-14 20:42:42.416323.416323 mlpmodule.py:1574] start einsum2
DEBUG 01-14 20:42:42.434794.434794 mlpmodule.py:1584] group einsum cost 0.028501033782958984 s
DEBUG 01-14 20:42:42.435952.435952 mlpmodule.py:1593] cpy2cputensor cost 0.0007469654083251953 s
DEBUG 01-14 20:42:42.435206.435206 cuda_h.py:10] start move_outputs
DEBUG 01-14 20:42:42.438404.438404 cuda_h.py:19] end move_outputs cost 0.0025377273559570312 seconds
INFO 01-14 20:42:42.442915.442915 client.py:127] Model loaded
DEBUG 01-14 20:42:42.442875.442875 cuda_h.py:19] end wait_experts cost 0.039406776428222656 seconds
DEBUG 01-14 20:42:42.442406.442406 cuda_h.py:10] start gpu_experts
DEBUG 01-14 20:42:42.442083.442083 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-14 20:42:42.442276.442276 cuda_h.py:19] end wait_cetm_experts cost 0.0001823902130126953 seconds
DEBUG 01-14 20:42:42.442371.442371 cuda_h.py:10] start gpu_group_einsum_mp_multi_list
DEBUG 01-14 20:42:42.442796.442796 cuda_h.py:10] start gpu_group_tensor
DEBUG 01-14 20:42:42.442931.442931 cuda_h.py:19] end gpu_group_tensor cost 0.00024199485778808594 seconds
DEBUG 01-14 20:42:42.443054.443054 cuda_h.py:10] start gpu_group_einsum
DEBUG 01-14 20:42:42.443642.443642 cuda_h.py:19] end gpu_group_einsum cost 0.0006923675537109375 seconds
DEBUG 01-14 20:42:42.443714.443714 cuda_h.py:10] start gpu_final_hidden_states_scatter
DEBUG 01-14 20:42:42.444901.444901 cuda_h.py:10] start all_expert_outputs_slices
DEBUG 01-14 20:42:42.444677.444677 cuda_h.py:19] end all_expert_outputs_slices cost 0.00038814544677734375 seconds
DEBUG 01-14 20:42:42.444017.444017 cuda_h.py:10] start concat_expert_out
DEBUG 01-14 20:42:42.444066.444066 cuda_h.py:19] end concat_expert_out cost 6.67572021484375e-05 seconds
DEBUG 01-14 20:42:42.444559.444559 cuda_h.py:10] start index_scatter
DEBUG 01-14 20:42:42.444854.444854 cuda_h.py:19] end index_scatter cost 7.510185241699219e-05 seconds
DEBUG 01-14 20:42:42.444187.444187 cuda_h.py:19] end gpu_final_hidden_states_scatter cost 0.0008251667022705078 seconds
DEBUG 01-14 20:42:42.444918.444918 cuda_h.py:19] end gpu_experts cost 0.0025963783264160156 seconds
DEBUG 01-14 20:42:42.444336.444336 cuda_h.py:10] start all_expert_weight_slices
DEBUG 01-14 20:42:42.445012.445012 cuda_h.py:19] end all_expert_weight_slices cost 0.0009579658508300781 seconds
DEBUG 01-14 20:42:42.446318.446318 cuda_h.py:10] start cpuoutputsdeal
DEBUG 01-14 20:42:42.446280.446280 cuda_h.py:10] start index_scatter
DEBUG 01-14 20:42:42.446450.446450 cuda_h.py:19] end index_scatter cost 5.8650970458984375e-05 seconds
DEBUG 01-14 20:42:42.446233.446233 cuda_h.py:19] end cpuoutputsdeal cost 0.0006082057952880859 seconds
DEBUG 01-14 20:42:42.446541.446541 cuda_h.py:19] end layer_moe_generate_mp_l_28 cost 0.06786942481994629 seconds
DEBUG 01-14 20:42:42.447195.447195 cuda_h.py:19] end prefill_layer cost 0.07380342483520508 seconds
DEBUG 01-14 20:42:42.447177.447177 lmp.py:1551] -------------------------------- end prefill layer 27 --------------------------------
DEBUG 01-14 20:42:42.447125.447125 cuda_h.py:19] end prefill cost 2.453934907913208 seconds
DEBUG 01-14 20:42:42.470549.470549 mlpmodule.py:1367]  experts func einsum cost 0.08235311508178711 s
DEBUG 01-14 20:42:44.618781.618781 cuda_h.py:10] start generate_input_ids
generate input ids cost 0.0888824462890625 s
DEBUG 01-14 20:42:44.979796.979796 cuda_h.py:19] end generate_input_ids cost 0.35985517501831055 seconds
DEBUG 01-14 20:42:44.980822.980822 cuda_h.py:10] start init_cache
DEBUG 01-14 20:42:44.980786.980786 cuda_h.py:19] end init_cache cost 5.435943603515625e-05 seconds
DEBUG 01-14 20:42:47.476371.476371 cuda_h.py:10] start init_meta_layer
DEBUG 01-14 20:42:47.477562.477562 cuda_h.py:19] end init_meta_layer cost 1.1444091796875e-05 seconds
DEBUG 01-14 20:42:47.477286.477286 cuda_h.py:10] start init_weights
DEBUG 01-14 20:42:47.477910.477910 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-14 20:42:47.477117.477117 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-14 20:42:47.479216.479216 cuda_h.py:19] end allocate_cuda_memory cost 0.002149820327758789 seconds
DEBUG 01-14 20:42:47.480450.480450 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-14 20:42:47.480729.480729 sllm_store_c.py:27] get device uuid map
DEBUG 01-14 20:42:47.480142.480142 sllm_store_c.py:29] call client load into gpu
DEBUG 01-14 20:42:47.480368.480368 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 0129ef43-45df-4e95-b01b-0edd53283916
DEBUG 01-14 20:42:47.480099.480099 client.py:106] call stub.LoadModelAsync
INFO 01-14 20:42:47.482809.482809 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 0129ef43-45df-4e95-b01b-0edd53283916
DEBUG 01-14 20:42:47.482580.482580 cuda_h.py:19] end load_into_gpu_async cost 0.002050638198852539 seconds
DEBUG 01-14 20:42:47.482852.482852 cuda_h.py:10] start restore_tensors2
DEBUG 01-14 20:42:47.482028.482028 cuda_h.py:19] end restore_tensors2 cost 6.961822509765625e-05 seconds
DEBUG 01-14 20:42:47.482208.482208 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.004516124725341797 seconds
DEBUG 01-14 20:42:47.482904.482904 cuda_h.py:10] start restore2model
DEBUG 01-14 20:42:47.482923.482923 cuda_h.py:19] end restore2model cost 0.0001671314239501953 seconds
INFO 01-14 20:42:47.482110.482110 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 0129ef43-45df-4e95-b01b-0edd53283916
INFO 01-14 20:42:47.562301.562301 client.py:127] Model loaded
DEBUG 01-14 20:42:47.562611.562611 cuda_h.py:10] start load_qkvogns_weight_l_0
DEBUG 01-14 20:42:47.562112.562112 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-14 20:42:47.562407.562407 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-14 20:42:47.562788.562788 cuda_h.py:19] end allocate_cuda_memory cost 0.0003993511199951172 seconds
DEBUG 01-14 20:42:47.563607.563607 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-14 20:42:47.563339.563339 sllm_store_c.py:27] get device uuid map
DEBUG 01-14 20:42:47.563468.563468 sllm_store_c.py:29] call client load into gpu
DEBUG 01-14 20:42:47.563655.563655 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 3ed700fa-8bf8-49ab-a765-ed4f0a138743
DEBUG 01-14 20:42:47.563979.563979 client.py:106] call stub.LoadModelAsync
INFO 01-14 20:42:47.565953.565953 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 3ed700fa-8bf8-49ab-a765-ed4f0a138743
DEBUG 01-14 20:42:47.565215.565215 cuda_h.py:19] end load_into_gpu_async cost 0.002045869827270508 seconds
DEBUG 01-14 20:42:47.565310.565310 cuda_h.py:10] start restore_tensors2
DEBUG 01-14 20:42:47.565218.565218 cuda_h.py:19] end restore_tensors2 cost 0.0001404285430908203 seconds
DEBUG 01-14 20:42:47.565764.565764 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.003173828125 seconds
INFO 01-14 20:42:47.565336.565336 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 3ed700fa-8bf8-49ab-a765-ed4f0a138743
INFO 01-14 20:42:47.582036.582036 client.py:127] Model loaded
DEBUG 01-14 20:42:47.582272.582272 cuda_h.py:10] start restore2model
DEBUG 01-14 20:42:47.583993.583993 cuda_h.py:19] end restore2model cost 0.0008544921875 seconds
DEBUG 01-14 20:42:47.583977.583977 cuda_h.py:19] end load_qkvogns_weight_l_0 cost 0.02131485939025879 seconds
DEBUG 01-14 20:42:47.583192.583192 cuda_h.py:19] end init_weights cost 0.10592937469482422 seconds
DEBUG 01-14 20:42:47.583856.583856 cuda_h.py:10] start copy_emodel
DEBUG 01-14 20:42:48.350247.350247 cuda_h.py:19] end copy_emodel cost 0.7663097381591797 seconds
DEBUG 01-14 20:42:48.350174.350174 cuda_h.py:10] start init_inputs_tokens
DEBUG 01-14 20:42:48.351628.351628 cuda_h.py:19] end init_inputs_tokens cost 0.00025582313537597656 seconds
DEBUG 01-14 20:42:48.351709.351709 cuda_h.py:10] start prefill
DEBUG 01-14 20:42:48.351565.351565 cuda_h.py:10] start prefill_layer
DEBUG 01-14 20:42:48.351691.351691 lmp.py:1494] -------------------------------- start prefill layer 0 --------------------------------
DEBUG 01-14 20:42:48.351910.351910 cuda_h.py:10] start start_load_qkvogn_s_weight_l_1
DEBUG 01-14 20:42:48.351275.351275 cuda_h.py:10] start start_load_qkvogn_s_weight_l_1
DEBUG 01-14 20:42:48.351933.351933 cuda_h.py:19] end start_load_qkvogn_s_weight_l_1 cost 3.62396240234375e-05 seconds
DEBUG 01-14 20:42:48.351013.351013 cuda_h.py:19] end start_load_qkvogn_s_weight_l_1 cost 6.699562072753906e-05 seconds
DEBUG 01-14 20:42:48.351372.351372 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-14 20:42:48.351122.351122 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-14 20:42:48.351761.351761 cuda_h.py:10] start sllm_worker_task
DEBUG 01-14 20:42:48.351719.351719 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-14 20:42:48.351807.351807 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-14 20:42:48.352348.352348 cuda_h.py:19] end allocate_cuda_memory cost 0.0002849102020263672 seconds
DEBUG 01-14 20:42:48.352669.352669 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-14 20:42:48.352823.352823 sllm_store_c.py:27] get device uuid map
DEBUG 01-14 20:42:48.352083.352083 sllm_store_c.py:29] call client load into gpu
DEBUG 01-14 20:42:48.352191.352191 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, f9a386c4-acd2-470a-934c-0857c44160dd
DEBUG 01-14 20:42:48.352280.352280 client.py:106] call stub.LoadModelAsync
DEBUG 01-14 20:42:48.352953.352953 cuda_h.py:10] start self_attn
INFO 01-14 20:42:48.354518.354518 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, f9a386c4-acd2-470a-934c-0857c44160dd
DEBUG 01-14 20:42:48.354414.354414 cuda_h.py:19] end load_into_gpu_async cost 0.0020151138305664062 seconds
DEBUG 01-14 20:42:48.354885.354885 cuda_h.py:10] start restore_tensors2
DEBUG 01-14 20:42:48.354041.354041 cuda_h.py:19] end restore_tensors2 cost 8.082389831542969e-05 seconds
DEBUG 01-14 20:42:48.354540.354540 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.002702951431274414 seconds
INFO 01-14 20:42:48.354528.354528 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, f9a386c4-acd2-470a-934c-0857c44160dd
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-14 20:42:48.356774.356774 cuda_h.py:19] end self_attn cost 0.003274202346801758 seconds
DEBUG 01-14 20:42:48.356241.356241 cuda_h.py:19] end iln_self_attn_paln cost 0.0049610137939453125 seconds
DEBUG 01-14 20:42:48.356117.356117 cuda_h.py:10] start dense_mlp
INFO 01-14 20:42:48.363099.363099 client.py:127] Model loaded
DEBUG 01-14 20:42:48.363002.363002 cuda_h.py:10] start restore2model
DEBUG 01-14 20:42:48.364280.364280 cuda_h.py:19] end restore2model cost 0.0005412101745605469 seconds
DEBUG 01-14 20:42:48.364508.364508 cuda_h.py:19] end sllm_worker_task cost 0.012282133102416992 seconds
DEBUG 01-14 20:42:48.364822.364822 cuda_h.py:19] end dense_mlp cost 0.007572650909423828 seconds
DEBUG 01-14 20:42:48.364249.364249 cuda_h.py:19] end prefill_layer cost 0.012907743453979492 seconds
DEBUG 01-14 20:42:48.364582.364582 lmp.py:1551] -------------------------------- end prefill layer 0 --------------------------------
DEBUG 01-14 20:42:48.364755.364755 cuda_h.py:10] start prefill_layer
DEBUG 01-14 20:42:48.364120.364120 lmp.py:1494] -------------------------------- start prefill layer 1 --------------------------------
DEBUG 01-14 20:42:48.364008.364008 cuda_h.py:10] start start_load_qkvogn_s_weight_l_2
DEBUG 01-14 20:42:48.364671.364671 cuda_h.py:10] start start_load_qkvogn_s_weight_l_2
DEBUG 01-14 20:42:48.364593.364593 cuda_h.py:19] end start_load_qkvogn_s_weight_l_2 cost 2.2411346435546875e-05 seconds
DEBUG 01-14 20:42:48.364534.364534 cuda_h.py:19] end start_load_qkvogn_s_weight_l_2 cost 5.245208740234375e-05 seconds
DEBUG 01-14 20:42:48.364562.364562 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-14 20:42:48.364352.364352 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-14 20:42:48.364572.364572 cuda_h.py:10] start sllm_worker_task
DEBUG 01-14 20:42:48.364528.364528 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-14 20:42:48.364186.364186 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-14 20:42:48.365493.365493 cuda_h.py:19] end allocate_cuda_memory cost 0.00021195411682128906 seconds
DEBUG 01-14 20:42:48.365436.365436 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-14 20:42:48.365888.365888 sllm_store_c.py:27] get device uuid map
DEBUG 01-14 20:42:48.365539.365539 sllm_store_c.py:29] call client load into gpu
DEBUG 01-14 20:42:48.365853.365853 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 65366409-545d-4de4-9024-7ce646de749e
DEBUG 01-14 20:42:48.365208.365208 client.py:106] call stub.LoadModelAsync
DEBUG 01-14 20:42:48.365863.365863 cuda_h.py:10] start self_attn
INFO 01-14 20:42:48.366445.366445 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 65366409-545d-4de4-9024-7ce646de749e
DEBUG 01-14 20:42:48.366647.366647 cuda_h.py:19] end load_into_gpu_async cost 0.0016794204711914062 seconds
DEBUG 01-14 20:42:48.366085.366085 cuda_h.py:10] start restore_tensors2
DEBUG 01-14 20:42:48.367063.367063 cuda_h.py:19] end restore_tensors2 cost 7.796287536621094e-05 seconds
DEBUG 01-14 20:42:48.367244.367244 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0023462772369384766 seconds
INFO 01-14 20:42:48.367690.367690 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 65366409-545d-4de4-9024-7ce646de749e
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-14 20:42:48.368558.368558 cuda_h.py:19] end self_attn cost 0.0028684139251708984 seconds
DEBUG 01-14 20:42:48.368475.368475 cuda_h.py:19] end iln_self_attn_paln cost 0.0042951107025146484 seconds
DEBUG 01-14 20:42:48.368841.368841 cuda_h.py:10] start layer_moe_generate_mp_l_2
DEBUG 01-14 20:42:48.368127.368127 cuda_h.py:10] start gate
DEBUG 01-14 20:42:48.369463.369463 cuda_h.py:19] end gate cost 0.0007035732269287109 seconds
DEBUG 01-14 20:42:48.369961.369961 cuda_h.py:10] start experts_map_get
DEBUG 01-14 20:42:48.370475.370475 lmp.py:1615] 
DEBUG 01-14 20:42:48.370475.370475 lmp.py:1615] Expert Token Distribution & Device Allocation:
DEBUG 01-14 20:42:48.370231.370231 lmp.py:1616]   Total experts: 64
DEBUG 01-14 20:42:48.370358.370358 lmp.py:1617]   CPU experts: 32 (50%)
DEBUG 01-14 20:42:48.370862.370862 lmp.py:1618]   GPU experts: 32 (50%)
DEBUG 01-14 20:42:48.370220.370220 lmp.py:1619] 
DEBUG 01-14 20:42:48.370220.370220 lmp.py:1619]   Expert ID | Tokens | Device
DEBUG 01-14 20:42:48.370147.370147 lmp.py:1620]   -----------------------------------
DEBUG 01-14 20:42:48.370506.370506 lmp.py:1625]   Expert 25 |     64 | CPU
DEBUG 01-14 20:42:48.370433.370433 lmp.py:1625]   Expert 54 |     67 | CPU
DEBUG 01-14 20:42:48.370646.370646 lmp.py:1625]   Expert  3 |     68 | CPU
DEBUG 01-14 20:42:48.370858.370858 lmp.py:1625]   Expert 31 |     72 | CPU
DEBUG 01-14 20:42:48.370071.370071 lmp.py:1625]   Expert 55 |     72 | CPU
DEBUG 01-14 20:42:48.370283.370283 lmp.py:1625]   Expert 62 |     87 | CPU
DEBUG 01-14 20:42:48.370734.370734 lmp.py:1625]   Expert 18 |     88 | CPU
DEBUG 01-14 20:42:48.370185.370185 lmp.py:1625]   Expert 52 |     98 | CPU
DEBUG 01-14 20:42:48.370874.370874 lmp.py:1625]   Expert 22 |    100 | CPU
DEBUG 01-14 20:42:48.370279.370279 lmp.py:1625]   Expert 47 |    104 | CPU
DEBUG 01-14 20:42:48.370730.370730 lmp.py:1625]   Expert  0 |    113 | CPU
DEBUG 01-14 20:42:48.370704.370704 lmp.py:1625]   Expert 37 |    117 | CPU
DEBUG 01-14 20:42:48.370916.370916 lmp.py:1625]   Expert 27 |    121 | CPU
DEBUG 01-14 20:42:48.370652.370652 lmp.py:1625]   Expert 32 |    123 | CPU
DEBUG 01-14 20:42:48.370864.370864 lmp.py:1625]   Expert 41 |    130 | CPU
DEBUG 01-14 20:42:48.370600.370600 lmp.py:1625]   Expert 44 |    131 | CPU
DEBUG 01-14 20:42:48.370574.370574 lmp.py:1625]   Expert 28 |    136 | CPU
DEBUG 01-14 20:42:48.370548.370548 lmp.py:1625]   Expert 13 |    138 | CPU
DEBUG 01-14 20:42:48.370284.370284 lmp.py:1625]   Expert 58 |    140 | CPU
DEBUG 01-14 20:42:48.370019.370019 lmp.py:1625]   Expert 60 |    144 | CPU
DEBUG 01-14 20:42:48.370993.370993 lmp.py:1625]   Expert 43 |    147 | CPU
DEBUG 01-14 20:42:48.370206.370206 lmp.py:1625]   Expert  1 |    150 | CPU
DEBUG 01-14 20:42:48.370941.370941 lmp.py:1625]   Expert 38 |    153 | CPU
DEBUG 01-14 20:42:48.370154.370154 lmp.py:1625]   Expert 49 |    154 | CPU
DEBUG 01-14 20:42:48.370274.370274 lmp.py:1625]   Expert 51 |    155 | CPU
DEBUG 01-14 20:42:48.370347.370347 lmp.py:1625]   Expert 34 |    161 | CPU
DEBUG 01-14 20:42:48.370467.370467 lmp.py:1625]   Expert 35 |    164 | CPU
DEBUG 01-14 20:42:48.370110.370110 lmp.py:1625]   Expert 36 |    168 | CPU
DEBUG 01-14 20:42:48.370515.370515 lmp.py:1625]   Expert 11 |    170 | CPU
DEBUG 01-14 20:42:48.370158.370158 lmp.py:1625]   Expert 17 |    170 | CPU
DEBUG 01-14 20:42:48.370324.370324 lmp.py:1625]   Expert 59 |    174 | CPU
DEBUG 01-14 20:42:48.370967.370967 lmp.py:1625]   Expert 10 |    180 | CPU
DEBUG 01-14 20:42:48.370133.370133 lmp.py:1625]   Expert 20 |    182 | GPU
DEBUG 01-14 20:42:48.370014.370014 lmp.py:1625]   Expert  2 |    186 | GPU
DEBUG 01-14 20:42:48.370419.370419 lmp.py:1625]   Expert 39 |    189 | GPU
DEBUG 01-14 20:42:48.370777.370777 lmp.py:1625]   Expert 33 |    197 | GPU
DEBUG 01-14 20:42:48.370135.370135 lmp.py:1625]   Expert 12 |    198 | GPU
DEBUG 01-14 20:42:48.370732.370732 lmp.py:1625]   Expert 21 |    198 | GPU
DEBUG 01-14 20:42:48.370898.370898 lmp.py:1625]   Expert 48 |    198 | GPU
DEBUG 01-14 20:42:48.370541.370541 lmp.py:1625]   Expert 15 |    199 | GPU
DEBUG 01-14 20:42:48.370230.370230 lmp.py:1625]   Expert 53 |    204 | GPU
DEBUG 01-14 20:42:48.370635.370635 lmp.py:1625]   Expert 19 |    220 | GPU
DEBUG 01-14 20:42:48.370801.370801 lmp.py:1625]   Expert 26 |    221 | GPU
DEBUG 01-14 20:42:48.370490.370490 lmp.py:1625]   Expert 30 |    221 | GPU
DEBUG 01-14 20:42:48.370656.370656 lmp.py:1625]   Expert 45 |    221 | GPU
DEBUG 01-14 20:42:48.370299.370299 lmp.py:1625]   Expert  5 |    227 | GPU
DEBUG 01-14 20:42:48.370419.370419 lmp.py:1625]   Expert  4 |    229 | GPU
DEBUG 01-14 20:42:48.370493.370493 lmp.py:1625]   Expert 24 |    229 | GPU
DEBUG 01-14 20:42:48.370520.370520 lmp.py:1625]   Expert 42 |    242 | GPU
DEBUG 01-14 20:42:48.370640.370640 lmp.py:1625]   Expert 50 |    245 | GPU
DEBUG 01-14 20:42:48.370806.370806 lmp.py:1625]   Expert 29 |    254 | GPU
DEBUG 01-14 20:42:48.371210.371210 lmp.py:1625]   Expert 56 |    262 | GPU
DEBUG 01-14 20:42:48.371615.371615 lmp.py:1625]   Expert 61 |    270 | GPU
DEBUG 01-14 20:42:48.371019.371019 lmp.py:1625]   Expert  8 |    283 | GPU
DEBUG 01-14 20:42:48.371709.371709 lmp.py:1625]   Expert 63 |    285 | GPU
DEBUG 01-14 20:42:48.371113.371113 lmp.py:1625]   Expert 46 |    294 | GPU
DEBUG 01-14 20:42:48.371279.371279 lmp.py:1625]   Expert  9 |    300 | GPU
DEBUG 01-14 20:42:48.371684.371684 lmp.py:1625]   Expert  6 |    316 | GPU
DEBUG 01-14 20:42:48.371042.371042 lmp.py:1625]   Expert 16 |    316 | GPU
DEBUG 01-14 20:42:48.371162.371162 lmp.py:1625]   Expert 40 |    319 | GPU
DEBUG 01-14 20:42:48.371567.371567 lmp.py:1625]   Expert  7 |    322 | GPU
DEBUG 01-14 20:42:48.371210.371210 lmp.py:1625]   Expert 23 |    325 | GPU
DEBUG 01-14 20:42:48.371376.371376 lmp.py:1625]   Expert 14 |    413 | GPU
DEBUG 01-14 20:42:48.371780.371780 lmp.py:1625]   Expert 57 |    464 | GPU
DEBUG 01-14 20:42:48.371900.371900 lmp.py:1626] 
DEBUG 01-14 20:42:48.371900.371900 lmp.py:1626]   CPU total tokens: 4059 (33.0%)
DEBUG 01-14 20:42:48.371258.371258 lmp.py:1627]   GPU total tokens: 8229 (67.0%)
DEBUG 01-14 20:42:48.371385.371385 cuda_h.py:19] end experts_map_get cost 0.0015480518341064453 seconds
DEBUG 01-14 20:42:48.371387.371387 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-14 20:42:48.371707.371707 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-14 20:42:48.371321.371321 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-14 20:42:48.372833.372833 cuda_h.py:19] end allocate_cuda_memory cost 0.0013968944549560547 seconds
DEBUG 01-14 20:42:48.373775.373775 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-14 20:42:48.373438.373438 sllm_store_c.py:27] get device uuid map
DEBUG 01-14 20:42:48.373884.373884 sllm_store_c.py:29] call client load into gpu
DEBUG 01-14 20:42:48.373249.373249 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, bb3e037e-d1a5-481d-bf55-44ee2336b2e5
DEBUG 01-14 20:42:48.373889.373889 client.py:106] call stub.LoadModelAsync
INFO 01-14 20:42:48.374866.374866 client.py:127] Model loaded
DEBUG 01-14 20:42:48.374756.374756 cuda_h.py:10] start restore2model
DEBUG 01-14 20:42:48.375929.375929 cuda_h.py:19] end restore2model cost 0.0007219314575195312 seconds
DEBUG 01-14 20:42:48.375713.375713 cuda_h.py:19] end sllm_worker_task cost 0.011054515838623047 seconds
INFO 01-14 20:42:48.376417.376417 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, bb3e037e-d1a5-481d-bf55-44ee2336b2e5
DEBUG 01-14 20:42:48.376320.376320 cuda_h.py:19] end load_into_gpu_async cost 0.0031731128692626953 seconds
DEBUG 01-14 20:42:48.376930.376930 cuda_h.py:10] start restore_tensors2
DEBUG 01-14 20:42:48.376957.376957 cuda_h.py:19] end restore_tensors2 cost 0.00037741661071777344 seconds
DEBUG 01-14 20:42:48.376323.376323 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.005310773849487305 seconds
DEBUG 01-14 20:42:48.376370.376370 cuda_h.py:10] start restore2model
DEBUG 01-14 20:42:48.379347.379347 cuda_h.py:19] end restore2model cost 0.0026204586029052734 seconds
DEBUG 01-14 20:42:48.379951.379951 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.008111238479614258 seconds
DEBUG 01-14 20:42:48.379508.379508 cuda_h.py:10] start gpu_sexperts
DEBUG 01-14 20:42:48.379175.379175 cuda_h.py:19] end gpu_sexperts cost 0.0002856254577636719 seconds
DEBUG 01-14 20:42:48.379905.379905 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-14 20:42:48.379038.379038 lmp.py:1683] 
DEBUG 01-14 20:42:48.379038.379038 lmp.py:1683]   Computing 32 experts on CPU...
DEBUG 01-14 20:42:48.379212.379212 cuda_h.py:19] end cpu_experts_submit cost 5.817413330078125e-05 seconds
DEBUG 01-14 20:42:48.379200.379200 cuda_h.py:10] start experts_func_mgpu_group_pad
DEBUG 01-14 20:42:48.391832.391832 mlpmodule.py:1460] group tensors cost 0.010178327560424805 s
DEBUG 01-14 20:42:48.392460.392460 cuda_h.py:10] start move_flat_hidden2cpu
DEBUG 01-14 20:42:48.400071.400071 cuda_h.py:19] end experts_func_mgpu_group_pad cost 0.020422697067260742 seconds
DEBUG 01-14 20:42:48.402397.402397 cuda_h.py:10] start gpu_group_list
DEBUG 01-14 20:42:48.403585.403585 cuda_h.py:19] end gpu_group_list cost 0.0007297992706298828 seconds
DEBUG 01-14 20:42:48.403972.403972 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-14 20:42:48.403121.403121 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.8133392333984375e-05 seconds
DEBUG 01-14 20:42:48.404289.404289 cuda_h.py:10] start wait_experts
INFO 01-14 20:42:48.404072.404072 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, bb3e037e-d1a5-481d-bf55-44ee2336b2e5
DEBUG 01-14 20:42:48.404852.404852 cuda_h.py:19] end move_flat_hidden2cpu cost 0.012582063674926758 seconds
DEBUG 01-14 20:42:48.406143.406143 mlpmodule.py:1533] pad cost 0.0016455650329589844 s
DEBUG 01-14 20:42:48.406669.406669 mlpmodule.py:1539] create cpu tensor cost 3.8623809814453125e-05 s
DEBUG 01-14 20:42:48.408033.408033 mlpmodule.py:1544] move to cpu cost 0.0021266937255859375 s
DEBUG 01-14 20:42:48.421523.421523 mlpmodule.py:1558] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-14 20:42:48.421953.421953 mlpmodule.py:1559] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-14 20:42:48.421784.421784 mlpmodule.py:1564] group_w3 first element: -0.0107421875
WARNING 01-14 20:42:48.422808.422808 mlpmodule.py:1574] start einsum2
INFO 01-14 20:42:48.429783.429783 client.py:127] Model loaded
DEBUG 01-14 20:42:48.429259.429259 cuda_h.py:19] end wait_experts cost 0.025155067443847656 seconds
DEBUG 01-14 20:42:48.429744.429744 cuda_h.py:10] start gpu_experts
DEBUG 01-14 20:42:48.429898.429898 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-14 20:42:48.441135.441135 mlpmodule.py:1584] group einsum cost 0.03222489356994629 s
DEBUG 01-14 20:42:48.442012.442012 mlpmodule.py:1593] cpy2cputensor cost 0.0006930828094482422 s
DEBUG 01-14 20:42:48.442272.442272 cuda_h.py:10] start move_outputs
DEBUG 01-14 20:42:48.444177.444177 cuda_h.py:19] end move_outputs cost 0.0020759105682373047 seconds
DEBUG 01-14 20:42:48.447055.447055 cuda_h.py:19] end wait_cetm_experts cost 0.018468856811523438 seconds
DEBUG 01-14 20:42:48.448989.448989 cuda_h.py:10] start gpu_group_einsum_mp_multi_list
DEBUG 01-14 20:42:48.448904.448904 cuda_h.py:10] start gpu_group_tensor
DEBUG 01-14 20:42:48.461218.461218 mlpmodule.py:1367]  experts func einsum cost 0.08029675483703613 s
DEBUG 01-14 20:42:48.461535.461535 cuda_h.py:19] end gpu_group_tensor cost 0.013431787490844727 seconds
DEBUG 01-14 20:42:48.461258.461258 cuda_h.py:10] start gpu_group_einsum
DEBUG 01-14 20:42:48.463926.463926 cuda_h.py:19] end gpu_group_einsum cost 0.0010886192321777344 seconds
DEBUG 01-14 20:42:48.463448.463448 cuda_h.py:10] start gpu_final_hidden_states_scatter
DEBUG 01-14 20:42:48.463297.463297 cuda_h.py:10] start all_expert_outputs_slices
DEBUG 01-14 20:42:48.463050.463050 cuda_h.py:19] end all_expert_outputs_slices cost 0.0002713203430175781 seconds
DEBUG 01-14 20:42:48.463051.463051 cuda_h.py:10] start concat_expert_out
DEBUG 01-14 20:42:48.463802.463802 cuda_h.py:19] end concat_expert_out cost 0.0002295970916748047 seconds
DEBUG 01-14 20:42:48.463560.463560 cuda_h.py:10] start index_scatter
DEBUG 01-14 20:42:48.464551.464551 cuda_h.py:19] end index_scatter cost 8.368492126464844e-05 seconds
DEBUG 01-14 20:42:48.464228.464228 cuda_h.py:19] end gpu_final_hidden_states_scatter cost 0.0009124279022216797 seconds
DEBUG 01-14 20:42:48.464158.464158 cuda_h.py:19] end gpu_experts cost 0.034895896911621094 seconds
DEBUG 01-14 20:42:48.464914.464914 cuda_h.py:10] start all_expert_weight_slices
DEBUG 01-14 20:42:48.465505.465505 cuda_h.py:19] end all_expert_weight_slices cost 0.0009953975677490234 seconds
DEBUG 01-14 20:42:48.465971.465971 cuda_h.py:10] start cpuoutputsdeal
DEBUG 01-14 20:42:48.465469.465469 cuda_h.py:10] start index_scatter
DEBUG 01-14 20:42:48.465248.465248 cuda_h.py:19] end index_scatter cost 5.841255187988281e-05 seconds
DEBUG 01-14 20:42:48.465832.465832 cuda_h.py:19] end cpuoutputsdeal cost 0.0005664825439453125 seconds
DEBUG 01-14 20:42:48.466040.466040 cuda_h.py:19] end layer_moe_generate_mp_l_2 cost 0.09709358215332031 seconds
DEBUG 01-14 20:42:48.466205.466205 cuda_h.py:19] end prefill_layer cost 0.10202288627624512 seconds
DEBUG 01-14 20:42:48.466307.466307 lmp.py:1551] -------------------------------- end prefill layer 1 --------------------------------
DEBUG 01-14 20:42:48.466347.466347 cuda_h.py:10] start prefill_layer
DEBUG 01-14 20:42:48.466196.466196 lmp.py:1494] -------------------------------- start prefill layer 2 --------------------------------
DEBUG 01-14 20:42:48.466237.466237 cuda_h.py:10] start start_load_qkvogn_s_weight_l_3
DEBUG 01-14 20:42:48.466470.466470 cuda_h.py:10] start start_load_qkvogn_s_weight_l_3
DEBUG 01-14 20:42:48.466412.466412 cuda_h.py:19] end start_load_qkvogn_s_weight_l_3 cost 3.337860107421875e-05 seconds
DEBUG 01-14 20:42:48.466599.466599 cuda_h.py:19] end start_load_qkvogn_s_weight_l_3 cost 6.866455078125e-05 seconds
DEBUG 01-14 20:42:48.466964.466964 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-14 20:42:48.466330.466330 cuda_h.py:10] start sllm_worker_task
DEBUG 01-14 20:42:48.466075.466075 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-14 20:42:48.466911.466911 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-14 20:42:48.467535.467535 cuda_h.py:19] end allocate_cuda_memory cost 0.00021266937255859375 seconds
DEBUG 01-14 20:42:48.467585.467585 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-14 20:42:48.467752.467752 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-14 20:42:48.467994.467994 sllm_store_c.py:27] get device uuid map
DEBUG 01-14 20:42:48.467393.467393 sllm_store_c.py:29] call client load into gpu
DEBUG 01-14 20:42:48.467335.467335 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 1c9bca5a-6198-4010-9b9a-f8e86b3640c9
DEBUG 01-14 20:42:48.467450.467450 client.py:106] call stub.LoadModelAsync
DEBUG 01-14 20:42:48.467336.467336 cuda_h.py:10] start self_attn
INFO 01-14 20:42:48.469088.469088 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 1c9bca5a-6198-4010-9b9a-f8e86b3640c9
DEBUG 01-14 20:42:48.469640.469640 cuda_h.py:19] end load_into_gpu_async cost 0.0022673606872558594 seconds
DEBUG 01-14 20:42:48.469674.469674 cuda_h.py:10] start restore_tensors2
DEBUG 01-14 20:42:48.469849.469849 cuda_h.py:19] end restore_tensors2 cost 6.771087646484375e-05 seconds
DEBUG 01-14 20:42:48.469175.469175 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.002955198287963867 seconds
INFO 01-14 20:42:48.469772.469772 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 1c9bca5a-6198-4010-9b9a-f8e86b3640c9
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-14 20:42:48.471540.471540 cuda_h.py:19] end self_attn cost 0.0032579898834228516 seconds
DEBUG 01-14 20:42:48.471153.471153 cuda_h.py:19] end iln_self_attn_paln cost 0.004845142364501953 seconds
DEBUG 01-14 20:42:48.471473.471473 cuda_h.py:10] start layer_moe_generate_mp_l_3
DEBUG 01-14 20:42:48.471806.471806 cuda_h.py:10] start gate
DEBUG 01-14 20:42:48.472438.472438 cuda_h.py:19] end gate cost 0.0006411075592041016 seconds
DEBUG 01-14 20:42:48.472950.472950 cuda_h.py:10] start experts_map_get
DEBUG 01-14 20:42:48.472861.472861 lmp.py:1615] 
DEBUG 01-14 20:42:48.472861.472861 lmp.py:1615] Expert Token Distribution & Device Allocation:
DEBUG 01-14 20:42:48.472809.472809 lmp.py:1616]   Total experts: 64
DEBUG 01-14 20:42:48.472697.472697 lmp.py:1617]   CPU experts: 32 (50%)
DEBUG 01-14 20:42:48.472771.472771 lmp.py:1618]   GPU experts: 32 (50%)
DEBUG 01-14 20:42:48.472698.472698 lmp.py:1619] 
DEBUG 01-14 20:42:48.472698.472698 lmp.py:1619]   Expert ID | Tokens | Device
DEBUG 01-14 20:42:48.472865.472865 lmp.py:1620]   -----------------------------------
DEBUG 01-14 20:42:48.472984.472984 lmp.py:1625]   Expert 58 |     58 | CPU
DEBUG 01-14 20:42:48.472151.472151 lmp.py:1625]   Expert 27 |     80 | CPU
DEBUG 01-14 20:42:48.472840.472840 lmp.py:1625]   Expert  3 |     85 | CPU
DEBUG 01-14 20:42:48.472291.472291 lmp.py:1625]   Expert 24 |     86 | CPU
DEBUG 01-14 20:42:48.472742.472742 lmp.py:1625]   Expert  0 |     87 | CPU
DEBUG 01-14 20:42:48.472477.472477 lmp.py:1625]   Expert 17 |     87 | CPU
DEBUG 01-14 20:42:48.472690.472690 lmp.py:1625]   Expert 28 |    106 | CPU
DEBUG 01-14 20:42:48.472141.472141 lmp.py:1625]   Expert 34 |    108 | CPU
DEBUG 01-14 20:42:48.472830.472830 lmp.py:1625]   Expert 51 |    112 | CPU
DEBUG 01-14 20:42:48.472042.472042 lmp.py:1625]   Expert 32 |    118 | CPU
DEBUG 01-14 20:42:48.473493.473493 lmp.py:1625]   Expert 23 |    122 | CPU
DEBUG 01-14 20:42:48.473467.473467 lmp.py:1625]   Expert 15 |    128 | CPU
DEBUG 01-14 20:42:48.473441.473441 lmp.py:1625]   Expert  7 |    133 | CPU
DEBUG 01-14 20:42:48.473415.473415 lmp.py:1625]   Expert 26 |    135 | CPU
DEBUG 01-14 20:42:48.473151.473151 lmp.py:1625]   Expert  9 |    138 | CPU
DEBUG 01-14 20:42:48.473363.473363 lmp.py:1625]   Expert 30 |    141 | CPU
DEBUG 01-14 20:42:48.473861.473861 lmp.py:1625]   Expert 57 |    141 | CPU
DEBUG 01-14 20:42:48.473835.473835 lmp.py:1625]   Expert 62 |    145 | CPU
DEBUG 01-14 20:42:48.473332.473332 lmp.py:1625]   Expert 45 |    146 | CPU
DEBUG 01-14 20:42:48.473067.473067 lmp.py:1625]   Expert  1 |    150 | CPU
DEBUG 01-14 20:42:48.473518.473518 lmp.py:1625]   Expert  6 |    153 | CPU
DEBUG 01-14 20:42:48.473254.473254 lmp.py:1625]   Expert 48 |    156 | CPU
DEBUG 01-14 20:42:48.473374.473374 lmp.py:1625]   Expert  8 |    162 | CPU
DEBUG 01-14 20:42:48.473302.473302 lmp.py:1625]   Expert 54 |    164 | CPU
DEBUG 01-14 20:42:48.473991.473991 lmp.py:1625]   Expert 25 |    166 | CPU
DEBUG 01-14 20:42:48.473680.473680 lmp.py:1625]   Expert 49 |    168 | CPU
DEBUG 01-14 20:42:48.473085.473085 lmp.py:1625]   Expert 29 |    172 | CPU
DEBUG 01-14 20:42:48.473489.473489 lmp.py:1625]   Expert 36 |    172 | CPU
DEBUG 01-14 20:42:48.473417.473417 lmp.py:1625]   Expert 35 |    173 | CPU
DEBUG 01-14 20:42:48.473106.473106 lmp.py:1625]   Expert 12 |    177 | CPU
DEBUG 01-14 20:42:48.473796.473796 lmp.py:1625]   Expert 37 |    186 | CPU
DEBUG 01-14 20:42:48.473485.473485 lmp.py:1625]   Expert 53 |    187 | CPU
DEBUG 01-14 20:42:48.473651.473651 lmp.py:1625]   Expert 13 |    188 | GPU
DEBUG 01-14 20:42:48.473340.473340 lmp.py:1625]   Expert 60 |    189 | GPU
DEBUG 01-14 20:42:48.473983.473983 lmp.py:1625]   Expert 33 |    190 | GPU
DEBUG 01-14 20:42:48.473626.473626 lmp.py:1625]   Expert 16 |    195 | GPU
DEBUG 01-14 20:42:48.473792.473792 lmp.py:1625]   Expert 21 |    201 | GPU
DEBUG 01-14 20:42:48.473482.473482 lmp.py:1625]   Expert 40 |    201 | GPU
DEBUG 01-14 20:42:48.473409.473409 lmp.py:1625]   Expert 38 |    202 | GPU
DEBUG 01-14 20:42:48.473337.473337 lmp.py:1625]   Expert 19 |    208 | GPU
DEBUG 01-14 20:42:48.473503.473503 lmp.py:1625]   Expert  5 |    209 | GPU
DEBUG 01-14 20:42:48.473669.473669 lmp.py:1625]   Expert 41 |    213 | GPU
DEBUG 01-14 20:42:48.473597.473597 lmp.py:1625]   Expert 43 |    214 | GPU
DEBUG 01-14 20:42:48.473955.473955 lmp.py:1625]   Expert 10 |    215 | GPU
DEBUG 01-14 20:42:48.473552.473552 lmp.py:1625]   Expert 52 |    217 | GPU
DEBUG 01-14 20:42:48.473480.473480 lmp.py:1625]   Expert 50 |    219 | GPU
DEBUG 01-14 20:42:48.473646.473646 lmp.py:1625]   Expert 44 |    220 | GPU
DEBUG 01-14 20:42:48.473812.473812 lmp.py:1625]   Expert  4 |    221 | GPU
DEBUG 01-14 20:42:48.473978.473978 lmp.py:1625]   Expert 56 |    227 | GPU
DEBUG 01-14 20:42:48.473906.473906 lmp.py:1625]   Expert 59 |    230 | GPU
DEBUG 01-14 20:42:48.473595.473595 lmp.py:1625]   Expert 55 |    234 | GPU
DEBUG 01-14 20:42:48.473477.473477 lmp.py:1625]   Expert 31 |    245 | GPU
DEBUG 01-14 20:42:48.473358.473358 lmp.py:1625]   Expert 39 |    246 | GPU
DEBUG 01-14 20:42:48.473524.473524 lmp.py:1625]   Expert 22 |    255 | GPU
DEBUG 01-14 20:42:48.473690.473690 lmp.py:1625]   Expert 20 |    261 | GPU
DEBUG 01-14 20:42:48.473380.473380 lmp.py:1625]   Expert  2 |    268 | GPU
DEBUG 01-14 20:42:48.473307.473307 lmp.py:1625]   Expert 63 |    279 | GPU
DEBUG 01-14 20:42:48.473997.473997 lmp.py:1625]   Expert 47 |    284 | GPU
DEBUG 01-14 20:42:48.473686.473686 lmp.py:1625]   Expert 18 |    304 | GPU
DEBUG 01-14 20:42:48.473614.473614 lmp.py:1625]   Expert 14 |    310 | GPU
DEBUG 01-14 20:42:48.473257.473257 lmp.py:1625]   Expert 42 |    320 | GPU
DEBUG 01-14 20:42:48.473184.473184 lmp.py:1625]   Expert 46 |    372 | GPU
DEBUG 01-14 20:42:48.473112.473112 lmp.py:1625]   Expert 11 |    375 | GPU
DEBUG 01-14 20:42:48.473563.473563 lmp.py:1625]   Expert 61 |    434 | GPU
DEBUG 01-14 20:42:48.473967.473967 lmp.py:1626] 
DEBUG 01-14 20:42:48.473967.473967 lmp.py:1626]   CPU total tokens: 4342 (35.3%)
DEBUG 01-14 20:42:48.473326.473326 lmp.py:1627]   GPU total tokens: 7946 (64.7%)
DEBUG 01-14 20:42:48.473737.473737 cuda_h.py:19] end experts_map_get cost 0.0015342235565185547 seconds
DEBUG 01-14 20:42:48.474256.474256 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-14 20:42:48.474145.474145 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-14 20:42:48.474382.474382 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-14 20:42:48.476146.476146 cuda_h.py:19] end allocate_cuda_memory cost 0.0018296241760253906 seconds
DEBUG 01-14 20:42:48.476088.476088 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-14 20:42:48.476844.476844 sllm_store_c.py:27] get device uuid map
DEBUG 01-14 20:42:48.476846.476846 sllm_store_c.py:29] call client load into gpu
DEBUG 01-14 20:42:48.476449.476449 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 587e9438-0bf2-49ba-9d2a-3fa650aef469
DEBUG 01-14 20:42:48.476522.476522 client.py:106] call stub.LoadModelAsync
INFO 01-14 20:42:48.477947.477947 client.py:127] Model loaded
DEBUG 01-14 20:42:48.477214.477214 cuda_h.py:10] start restore2model
DEBUG 01-14 20:42:48.478309.478309 cuda_h.py:19] end restore2model cost 0.0004165172576904297 seconds
DEBUG 01-14 20:42:48.478662.478662 cuda_h.py:19] end sllm_worker_task cost 0.011607885360717773 seconds
INFO 01-14 20:42:48.479849.479849 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 587e9438-0bf2-49ba-9d2a-3fa650aef469
DEBUG 01-14 20:42:48.479245.479245 cuda_h.py:19] end load_into_gpu_async cost 0.0034363269805908203 seconds
DEBUG 01-14 20:42:48.479115.479115 cuda_h.py:10] start restore_tensors2
DEBUG 01-14 20:42:48.480524.480524 cuda_h.py:19] end restore_tensors2 cost 0.0008664131164550781 seconds
DEBUG 01-14 20:42:48.480175.480175 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.006598234176635742 seconds
DEBUG 01-14 20:42:48.480130.480130 cuda_h.py:10] start restore2model
DEBUG 01-14 20:42:48.483112.483112 cuda_h.py:19] end restore2model cost 0.00258636474609375 seconds
DEBUG 01-14 20:42:48.483147.483147 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.009370565414428711 seconds
DEBUG 01-14 20:42:48.483989.483989 cuda_h.py:10] start gpu_sexperts
DEBUG 01-14 20:42:48.483608.483608 cuda_h.py:19] end gpu_sexperts cost 0.0002849102020263672 seconds
DEBUG 01-14 20:42:48.483484.483484 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-14 20:42:48.483094.483094 lmp.py:1683] 
DEBUG 01-14 20:42:48.483094.483094 lmp.py:1683]   Computing 32 experts on CPU...
DEBUG 01-14 20:42:48.483646.483646 cuda_h.py:19] end cpu_experts_submit cost 5.602836608886719e-05 seconds
DEBUG 01-14 20:42:48.483680.483680 cuda_h.py:10] start experts_func_mgpu_group_pad
DEBUG 01-14 20:42:48.490899.490899 mlpmodule.py:1460] group tensors cost 0.006007194519042969 s
DEBUG 01-14 20:42:48.491526.491526 cuda_h.py:10] start move_flat_hidden2cpu
DEBUG 01-14 20:42:48.492841.492841 cuda_h.py:19] end experts_func_mgpu_group_pad cost 0.008907318115234375 seconds
DEBUG 01-14 20:42:48.494696.494696 cuda_h.py:10] start gpu_group_list
DEBUG 01-14 20:42:48.494534.494534 cuda_h.py:19] end gpu_group_list cost 0.0004305839538574219 seconds
DEBUG 01-14 20:42:48.494679.494679 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-14 20:42:48.494477.494477 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 1.7881393432617188e-05 seconds
DEBUG 01-14 20:42:48.494193.494193 cuda_h.py:10] start wait_experts
INFO 01-14 20:42:48.494519.494519 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 587e9438-0bf2-49ba-9d2a-3fa650aef469
DEBUG 01-14 20:42:48.497790.497790 cuda_h.py:19] end move_flat_hidden2cpu cost 0.006630659103393555 seconds
DEBUG 01-14 20:42:48.499713.499713 mlpmodule.py:1533] pad cost 0.0017445087432861328 s
DEBUG 01-14 20:42:48.499610.499610 mlpmodule.py:1539] create cpu tensor cost 3.647804260253906e-05 s
DEBUG 01-14 20:42:48.501129.501129 mlpmodule.py:1544] move to cpu cost 0.00220489501953125 s
DEBUG 01-14 20:42:48.512374.512374 mlpmodule.py:1558] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-14 20:42:48.512094.512094 mlpmodule.py:1559] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-14 20:42:48.512237.512237 mlpmodule.py:1564] group_w3 first element: -0.0380859375
WARNING 01-14 20:42:48.512938.512938 mlpmodule.py:1574] start einsum2
DEBUG 01-14 20:42:48.531310.531310 mlpmodule.py:1584] group einsum cost 0.029651641845703125 s
DEBUG 01-14 20:42:48.532501.532501 mlpmodule.py:1593] cpy2cputensor cost 0.0007491111755371094 s
DEBUG 01-14 20:42:48.532330.532330 cuda_h.py:10] start move_outputs
DEBUG 01-14 20:42:48.534597.534597 cuda_h.py:19] end move_outputs cost 0.002201080322265625 seconds
INFO 01-14 20:42:48.535901.535901 client.py:127] Model loaded
DEBUG 01-14 20:42:48.535782.535782 cuda_h.py:19] end wait_experts cost 0.040868520736694336 seconds
DEBUG 01-14 20:42:48.535128.535128 cuda_h.py:10] start gpu_experts
DEBUG 01-14 20:42:48.535951.535951 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-14 20:42:48.538653.538653 cuda_h.py:19] end wait_cetm_experts cost 0.0029358863830566406 seconds
DEBUG 01-14 20:42:48.538960.538960 cuda_h.py:10] start gpu_group_einsum_mp_multi_list
DEBUG 01-14 20:42:48.539339.539339 cuda_h.py:10] start gpu_group_tensor
DEBUG 01-14 20:42:48.539481.539481 cuda_h.py:19] end gpu_group_tensor cost 0.0002486705780029297 seconds
DEBUG 01-14 20:42:48.539220.539220 cuda_h.py:10] start gpu_group_einsum
DEBUG 01-14 20:42:48.549077.549077 cuda_h.py:19] end gpu_group_einsum cost 0.009705066680908203 seconds
DEBUG 01-14 20:42:48.549181.549181 cuda_h.py:10] start gpu_final_hidden_states_scatter
DEBUG 01-14 20:42:48.549786.549786 cuda_h.py:10] start all_expert_outputs_slices
DEBUG 01-14 20:42:48.549370.549370 cuda_h.py:19] end all_expert_outputs_slices cost 0.00022530555725097656 seconds
DEBUG 01-14 20:42:48.549265.549265 cuda_h.py:10] start concat_expert_out
DEBUG 01-14 20:42:48.549679.549679 cuda_h.py:19] end concat_expert_out cost 6.103515625e-05 seconds
DEBUG 01-14 20:42:48.549198.549198 cuda_h.py:10] start index_scatter
DEBUG 01-14 20:42:48.549287.549287 cuda_h.py:19] end index_scatter cost 6.890296936035156e-05 seconds
DEBUG 01-14 20:42:48.549427.549427 cuda_h.py:19] end gpu_final_hidden_states_scatter cost 0.0005939006805419922 seconds
DEBUG 01-14 20:42:48.550238.550238 cuda_h.py:19] end gpu_experts cost 0.014130592346191406 seconds
DEBUG 01-14 20:42:48.550318.550318 cuda_h.py:10] start all_expert_weight_slices
DEBUG 01-14 20:42:48.550121.550121 cuda_h.py:19] end all_expert_weight_slices cost 0.0008037090301513672 seconds
DEBUG 01-14 20:42:48.550427.550427 cuda_h.py:10] start cpuoutputsdeal
DEBUG 01-14 20:42:48.551877.551877 cuda_h.py:10] start index_scatter
DEBUG 01-14 20:42:48.551820.551820 cuda_h.py:19] end index_scatter cost 4.76837158203125e-05 seconds
DEBUG 01-14 20:42:48.551060.551060 cuda_h.py:19] end cpuoutputsdeal cost 0.0004763603210449219 seconds
DEBUG 01-14 20:42:48.551917.551917 cuda_h.py:19] end layer_moe_generate_mp_l_3 cost 0.07986068725585938 seconds
DEBUG 01-14 20:42:48.551782.551782 cuda_h.py:19] end prefill_layer cost 0.08533024787902832 seconds
DEBUG 01-14 20:42:48.551201.551201 lmp.py:1551] -------------------------------- end prefill layer 2 --------------------------------
DEBUG 01-14 20:42:48.551612.551612 cuda_h.py:10] start prefill_layer
DEBUG 01-14 20:42:48.551024.551024 lmp.py:1494] -------------------------------- start prefill layer 3 --------------------------------
DEBUG 01-14 20:42:48.551389.551389 cuda_h.py:10] start start_load_qkvogn_s_weight_l_4
DEBUG 01-14 20:42:48.551469.551469 cuda_h.py:10] start start_load_qkvogn_s_weight_l_4
DEBUG 01-14 20:42:48.552974.552974 cuda_h.py:19] end start_load_qkvogn_s_weight_l_4 cost 3.361701965332031e-05 seconds
DEBUG 01-14 20:42:48.552054.552054 cuda_h.py:19] end start_load_qkvogn_s_weight_l_4 cost 6.031990051269531e-05 seconds
DEBUG 01-14 20:42:48.552174.552174 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-14 20:42:48.552230.552230 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-14 20:42:48.552411.552411 cuda_h.py:10] start sllm_worker_task
DEBUG 01-14 20:42:48.552448.552448 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-14 20:42:48.552636.552636 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-14 20:42:48.554591.554591 cuda_h.py:19] end allocate_cuda_memory cost 0.0021393299102783203 seconds
DEBUG 01-14 20:42:48.554849.554849 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-14 20:42:48.554918.554918 sllm_store_c.py:27] get device uuid map
DEBUG 01-14 20:42:48.555788.555788 sllm_store_c.py:29] call client load into gpu
DEBUG 01-14 20:42:48.555764.555764 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, ad81720b-7f8e-417a-a2ab-d12c73661027
DEBUG 01-14 20:42:48.555278.555278 client.py:106] call stub.LoadModelAsync
DEBUG 01-14 20:42:48.555698.555698 mlpmodule.py:1367]  experts func einsum cost 0.07121038436889648 s
DEBUG 01-14 20:42:48.555198.555198 cuda_h.py:10] start self_attn
INFO 01-14 20:42:48.556115.556115 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, ad81720b-7f8e-417a-a2ab-d12c73661027
DEBUG 01-14 20:42:48.556880.556880 cuda_h.py:19] end load_into_gpu_async cost 0.0014450550079345703 seconds
DEBUG 01-14 20:42:48.556969.556969 cuda_h.py:10] start restore_tensors2
DEBUG 01-14 20:42:48.556033.556033 cuda_h.py:19] end restore_tensors2 cost 0.00010418891906738281 seconds
DEBUG 01-14 20:42:48.556380.556380 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.004250049591064453 seconds
INFO 01-14 20:42:48.556443.556443 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, ad81720b-7f8e-417a-a2ab-d12c73661027
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-14 20:42:48.559196.559196 cuda_h.py:19] end self_attn cost 0.0031900405883789062 seconds
DEBUG 01-14 20:42:48.559272.559272 cuda_h.py:19] end iln_self_attn_paln cost 0.007241487503051758 seconds
DEBUG 01-14 20:42:48.559115.559115 cuda_h.py:10] start layer_moe_generate_mp_l_4
DEBUG 01-14 20:42:48.559878.559878 cuda_h.py:10] start gate
DEBUG 01-14 20:42:48.560079.560079 cuda_h.py:19] end gate cost 0.0006394386291503906 seconds
DEBUG 01-14 20:42:48.560200.560200 cuda_h.py:10] start experts_map_get
DEBUG 01-14 20:42:48.560926.560926 lmp.py:1615] 
DEBUG 01-14 20:42:48.560926.560926 lmp.py:1615] Expert Token Distribution & Device Allocation:
DEBUG 01-14 20:42:48.560736.560736 lmp.py:1616]   Total experts: 64
DEBUG 01-14 20:42:48.560293.560293 lmp.py:1617]   CPU experts: 32 (50%)
DEBUG 01-14 20:42:48.560035.560035 lmp.py:1618]   GPU experts: 32 (50%)
DEBUG 01-14 20:42:48.560870.560870 lmp.py:1619] 
DEBUG 01-14 20:42:48.560870.560870 lmp.py:1619]   Expert ID | Tokens | Device
DEBUG 01-14 20:42:48.560990.560990 lmp.py:1620]   -----------------------------------
DEBUG 01-14 20:42:48.560302.560302 lmp.py:1625]   Expert  1 |     55 | CPU
DEBUG 01-14 20:42:48.560183.560183 lmp.py:1625]   Expert 27 |     59 | CPU
DEBUG 01-14 20:42:48.560588.560588 lmp.py:1625]   Expert 48 |     81 | CPU
DEBUG 01-14 20:42:48.560708.560708 lmp.py:1625]   Expert  7 |     83 | CPU
DEBUG 01-14 20:42:48.560020.560020 lmp.py:1625]   Expert 30 |    100 | CPU
DEBUG 01-14 20:42:48.560616.560616 lmp.py:1625]   Expert 15 |    101 | CPU
DEBUG 01-14 20:42:48.560021.560021 lmp.py:1625]   Expert 32 |    113 | CPU
DEBUG 01-14 20:42:48.560425.560425 lmp.py:1625]   Expert 39 |    115 | CPU
DEBUG 01-14 20:42:48.560830.560830 lmp.py:1625]   Expert 61 |    115 | CPU
DEBUG 01-14 20:42:48.560711.560711 lmp.py:1625]   Expert 18 |    117 | CPU
DEBUG 01-14 20:42:48.560877.560877 lmp.py:1625]   Expert 34 |    136 | CPU
DEBUG 01-14 20:42:48.560282.560282 lmp.py:1625]   Expert 45 |    136 | CPU
DEBUG 01-14 20:42:48.560448.560448 lmp.py:1625]   Expert 59 |    139 | CPU
DEBUG 01-14 20:42:48.560614.560614 lmp.py:1625]   Expert 11 |    144 | CPU
DEBUG 01-14 20:42:48.560780.560780 lmp.py:1625]   Expert 36 |    146 | CPU
DEBUG 01-14 20:42:48.560423.560423 lmp.py:1625]   Expert 26 |    148 | CPU
DEBUG 01-14 20:42:48.560020.560020 lmp.py:1625]   Expert  9 |    150 | CPU
DEBUG 01-14 20:42:48.560855.560855 lmp.py:1625]   Expert 49 |    150 | CPU
DEBUG 01-14 20:42:48.560498.560498 lmp.py:1625]   Expert 23 |    151 | CPU
DEBUG 01-14 20:42:48.560903.560903 lmp.py:1625]   Expert  5 |    153 | CPU
DEBUG 01-14 20:42:48.561069.561069 lmp.py:1625]   Expert 51 |    153 | CPU
DEBUG 01-14 20:42:48.561950.561950 lmp.py:1625]   Expert  6 |    154 | CPU
DEBUG 01-14 20:42:48.561831.561831 lmp.py:1625]   Expert  2 |    161 | CPU
DEBUG 01-14 20:42:48.561474.561474 lmp.py:1625]   Expert 50 |    165 | CPU
DEBUG 01-14 20:42:48.561402.561402 lmp.py:1625]   Expert 16 |    166 | CPU
DEBUG 01-14 20:42:48.561568.561568 lmp.py:1625]   Expert 40 |    166 | CPU
DEBUG 01-14 20:42:48.561973.561973 lmp.py:1625]   Expert  4 |    170 | CPU
DEBUG 01-14 20:42:48.561854.561854 lmp.py:1625]   Expert 56 |    170 | CPU
DEBUG 01-14 20:42:48.561020.561020 lmp.py:1625]   Expert 52 |    177 | CPU
DEBUG 01-14 20:42:48.561663.561663 lmp.py:1625]   Expert 17 |    184 | CPU
DEBUG 01-14 20:42:48.561545.561545 lmp.py:1625]   Expert 44 |    185 | CPU
DEBUG 01-14 20:42:48.561903.561903 lmp.py:1625]   Expert 35 |    187 | CPU
DEBUG 01-14 20:42:48.561069.561069 lmp.py:1625]   Expert 37 |    187 | GPU
DEBUG 01-14 20:42:48.561474.561474 lmp.py:1625]   Expert 38 |    193 | GPU
DEBUG 01-14 20:42:48.561640.561640 lmp.py:1625]   Expert 42 |    194 | GPU
DEBUG 01-14 20:42:48.561806.561806 lmp.py:1625]   Expert 13 |    202 | GPU
DEBUG 01-14 20:42:48.561972.561972 lmp.py:1625]   Expert 21 |    205 | GPU
DEBUG 01-14 20:42:48.561853.561853 lmp.py:1625]   Expert  3 |    209 | GPU
DEBUG 01-14 20:42:48.561258.561258 lmp.py:1625]   Expert 28 |    210 | GPU
DEBUG 01-14 20:42:48.561616.561616 lmp.py:1625]   Expert 53 |    211 | GPU
DEBUG 01-14 20:42:48.561650.561650 lmp.py:1625]   Expert 10 |    213 | GPU
DEBUG 01-14 20:42:48.561340.561340 lmp.py:1625]   Expert 20 |    215 | GPU
DEBUG 01-14 20:42:48.561552.561552 lmp.py:1625]   Expert 47 |    216 | GPU
DEBUG 01-14 20:42:48.561288.561288 lmp.py:1625]   Expert 58 |    216 | GPU
DEBUG 01-14 20:42:48.561262.561262 lmp.py:1625]   Expert  8 |    224 | GPU
DEBUG 01-14 20:42:48.561236.561236 lmp.py:1625]   Expert 33 |    224 | GPU
DEBUG 01-14 20:42:48.561971.561971 lmp.py:1625]   Expert 19 |    226 | GPU
DEBUG 01-14 20:42:48.561137.561137 lmp.py:1625]   Expert 55 |    226 | GPU
DEBUG 01-14 20:42:48.561827.561827 lmp.py:1625]   Expert 60 |    229 | GPU
DEBUG 01-14 20:42:48.561278.561278 lmp.py:1625]   Expert 31 |    230 | GPU
DEBUG 01-14 20:42:48.561252.561252 lmp.py:1625]   Expert 57 |    233 | GPU
DEBUG 01-14 20:42:48.561226.561226 lmp.py:1625]   Expert 46 |    236 | GPU
DEBUG 01-14 20:42:48.561200.561200 lmp.py:1625]   Expert 62 |    240 | GPU
DEBUG 01-14 20:42:48.561174.561174 lmp.py:1625]   Expert 24 |    243 | GPU
DEBUG 01-14 20:42:48.561148.561148 lmp.py:1625]   Expert 63 |    252 | GPU
DEBUG 01-14 20:42:48.561122.561122 lmp.py:1625]   Expert 14 |    256 | GPU
DEBUG 01-14 20:42:48.561811.561811 lmp.py:1625]   Expert 12 |    260 | GPU
DEBUG 01-14 20:42:48.561216.561216 lmp.py:1625]   Expert 22 |    273 | GPU
DEBUG 01-14 20:42:48.561428.561428 lmp.py:1625]   Expert 43 |    290 | GPU
DEBUG 01-14 20:42:48.561164.561164 lmp.py:1625]   Expert 29 |    296 | GPU
DEBUG 01-14 20:42:48.561138.561138 lmp.py:1625]   Expert  0 |    309 | GPU
DEBUG 01-14 20:42:48.561397.561397 lmp.py:1625]   Expert 54 |    339 | GPU
DEBUG 01-14 20:42:48.561132.561132 lmp.py:1625]   Expert 41 |    386 | GPU
DEBUG 01-14 20:42:48.561868.561868 lmp.py:1625]   Expert 25 |    415 | GPU
DEBUG 01-14 20:42:48.561557.561557 lmp.py:1626] 
DEBUG 01-14 20:42:48.561557.561557 lmp.py:1626]   CPU total tokens: 4430 (36.1%)
DEBUG 01-14 20:42:48.561962.561962 lmp.py:1627]   GPU total tokens: 7858 (63.9%)
DEBUG 01-14 20:42:48.561373.561373 cuda_h.py:19] end experts_map_get cost 0.0015730857849121094 seconds
DEBUG 01-14 20:42:48.561985.561985 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-14 20:42:48.561920.561920 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-14 20:42:48.562580.562580 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-14 20:42:48.563204.563204 cuda_h.py:19] end allocate_cuda_memory cost 0.0015842914581298828 seconds
DEBUG 01-14 20:42:48.563577.563577 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-14 20:42:48.563810.563810 sllm_store_c.py:27] get device uuid map
DEBUG 01-14 20:42:48.563911.563911 sllm_store_c.py:29] call client load into gpu
DEBUG 01-14 20:42:48.563468.563468 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 0bda7f43-58f7-4672-9414-08007ce5d740
DEBUG 01-14 20:42:48.564911.564911 client.py:106] call stub.LoadModelAsync
INFO 01-14 20:42:48.564397.564397 client.py:127] Model loaded
DEBUG 01-14 20:42:48.564811.564811 cuda_h.py:10] start restore2model
DEBUG 01-14 20:42:48.565303.565303 cuda_h.py:19] end restore2model cost 0.0007846355438232422 seconds
INFO 01-14 20:42:48.565128.565128 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 0bda7f43-58f7-4672-9414-08007ce5d740
DEBUG 01-14 20:42:48.565343.565343 cuda_h.py:19] end sllm_worker_task cost 0.013263940811157227 seconds
DEBUG 01-14 20:42:48.565889.565889 cuda_h.py:19] end load_into_gpu_async cost 0.0019466876983642578 seconds
DEBUG 01-14 20:42:48.565726.565726 cuda_h.py:10] start restore_tensors2
DEBUG 01-14 20:42:48.566410.566410 cuda_h.py:19] end restore_tensors2 cost 0.00040340423583984375 seconds
DEBUG 01-14 20:42:48.566253.566253 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0043642520904541016 seconds
DEBUG 01-14 20:42:48.566923.566923 cuda_h.py:10] start restore2model
DEBUG 01-14 20:42:48.568640.568640 cuda_h.py:19] end restore2model cost 0.0026051998138427734 seconds
DEBUG 01-14 20:42:48.569397.569397 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.0071582794189453125 seconds
DEBUG 01-14 20:42:48.569431.569431 cuda_h.py:10] start gpu_sexperts
DEBUG 01-14 20:42:48.569468.569468 cuda_h.py:19] end gpu_sexperts cost 0.00027561187744140625 seconds
DEBUG 01-14 20:42:48.569913.569913 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-14 20:42:48.569762.569762 lmp.py:1683] 
DEBUG 01-14 20:42:48.569762.569762 lmp.py:1683]   Computing 32 experts on CPU...
DEBUG 01-14 20:42:48.569413.569413 cuda_h.py:19] end cpu_experts_submit cost 5.841255187988281e-05 seconds
DEBUG 01-14 20:42:48.569831.569831 cuda_h.py:10] start experts_func_mgpu_group_pad
DEBUG 01-14 20:42:48.579884.579884 mlpmodule.py:1460] group tensors cost 0.009856462478637695 s
DEBUG 01-14 20:42:48.580631.580631 cuda_h.py:10] start move_flat_hidden2cpu
DEBUG 01-14 20:42:48.582551.582551 cuda_h.py:19] end experts_func_mgpu_group_pad cost 0.012923955917358398 seconds
DEBUG 01-14 20:42:48.584179.584179 cuda_h.py:10] start gpu_group_list
DEBUG 01-14 20:42:48.585401.585401 cuda_h.py:19] end gpu_group_list cost 0.0005548000335693359 seconds
DEBUG 01-14 20:42:48.585005.585005 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-14 20:42:48.585796.585796 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.384185791015625e-05 seconds
DEBUG 01-14 20:42:48.585042.585042 cuda_h.py:10] start wait_experts
INFO 01-14 20:42:48.585527.585527 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 0bda7f43-58f7-4672-9414-08007ce5d740
DEBUG 01-14 20:42:48.587439.587439 cuda_h.py:19] end move_flat_hidden2cpu cost 0.006462812423706055 seconds
DEBUG 01-14 20:42:48.588852.588852 mlpmodule.py:1533] pad cost 0.0015702247619628906 s
DEBUG 01-14 20:42:48.588955.588955 mlpmodule.py:1539] create cpu tensor cost 4.2438507080078125e-05 s
DEBUG 01-14 20:42:48.591620.591620 mlpmodule.py:1544] move to cpu cost 0.0022072792053222656 s
DEBUG 01-14 20:42:48.600173.600173 mlpmodule.py:1558] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-14 20:42:48.600259.600259 mlpmodule.py:1559] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-14 20:42:48.600666.600666 mlpmodule.py:1564] group_w3 first element: -0.054931640625
WARNING 01-14 20:42:48.601683.601683 mlpmodule.py:1574] start einsum2
DEBUG 01-14 20:42:48.619564.619564 mlpmodule.py:1584] group einsum cost 0.028111696243286133 s
INFO 01-14 20:42:48.620832.620832 client.py:127] Model loaded
DEBUG 01-14 20:42:48.620828.620828 mlpmodule.py:1593] cpy2cputensor cost 0.0008747577667236328 s
DEBUG 01-14 20:42:48.620674.620674 cuda_h.py:19] end wait_experts cost 0.03501725196838379 seconds
DEBUG 01-14 20:42:48.620783.620783 cuda_h.py:10] start move_outputs
DEBUG 01-14 20:42:48.620779.620779 cuda_h.py:10] start gpu_experts
DEBUG 01-14 20:42:48.620388.620388 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-14 20:42:48.623206.623206 cuda_h.py:19] end move_outputs cost 0.0021567344665527344 seconds
DEBUG 01-14 20:42:48.626619.626619 cuda_h.py:19] end wait_cetm_experts cost 0.0056688785552978516 seconds
DEBUG 01-14 20:42:48.626497.626497 cuda_h.py:10] start gpu_group_einsum_mp_multi_list
DEBUG 01-14 20:42:48.626260.626260 cuda_h.py:10] start gpu_group_tensor
DEBUG 01-14 20:42:48.627263.627263 cuda_h.py:19] end gpu_group_tensor cost 0.0002510547637939453 seconds
DEBUG 01-14 20:42:48.627618.627618 cuda_h.py:10] start gpu_group_einsum
DEBUG 01-14 20:42:48.627599.627599 cuda_h.py:19] end gpu_group_einsum cost 0.0005671977996826172 seconds
DEBUG 01-14 20:42:48.627444.627444 cuda_h.py:10] start gpu_final_hidden_states_scatter
DEBUG 01-14 20:42:48.628903.628903 cuda_h.py:10] start all_expert_outputs_slices
DEBUG 01-14 20:42:48.628148.628148 cuda_h.py:19] end all_expert_outputs_slices cost 0.0003590583801269531 seconds
DEBUG 01-14 20:42:48.628295.628295 cuda_h.py:10] start concat_expert_out
DEBUG 01-14 20:42:48.637951.637951 cuda_h.py:19] end concat_expert_out cost 0.008846759796142578 seconds
DEBUG 01-14 20:42:48.637740.637740 cuda_h.py:10] start index_scatter
DEBUG 01-14 20:42:48.637915.637915 cuda_h.py:19] end index_scatter cost 0.00015807151794433594 seconds
DEBUG 01-14 20:42:48.638965.638965 cuda_h.py:19] end gpu_final_hidden_states_scatter cost 0.009948492050170898 seconds
DEBUG 01-14 20:42:48.638777.638777 cuda_h.py:19] end gpu_experts cost 0.01719522476196289 seconds
DEBUG 01-14 20:42:48.638811.638811 cuda_h.py:10] start all_expert_weight_slices
DEBUG 01-14 20:42:48.639323.639323 cuda_h.py:19] end all_expert_weight_slices cost 0.0008034706115722656 seconds
DEBUG 01-14 20:42:48.639106.639106 cuda_h.py:10] start cpuoutputsdeal
DEBUG 01-14 20:42:48.639211.639211 cuda_h.py:10] start index_scatter
DEBUG 01-14 20:42:48.639168.639168 cuda_h.py:19] end index_scatter cost 5.340576171875e-05 seconds
DEBUG 01-14 20:42:48.639553.639553 cuda_h.py:19] end cpuoutputsdeal cost 0.00048041343688964844 seconds
DEBUG 01-14 20:42:48.639171.639171 cuda_h.py:19] end layer_moe_generate_mp_l_4 cost 0.08017110824584961 seconds
DEBUG 01-14 20:42:48.639441.639441 cuda_h.py:19] end prefill_layer cost 0.08801412582397461 seconds
DEBUG 01-14 20:42:48.640245.640245 lmp.py:1551] -------------------------------- end prefill layer 3 --------------------------------
DEBUG 01-14 20:42:48.640146.640146 cuda_h.py:10] start prefill_layer
DEBUG 01-14 20:42:48.640511.640511 lmp.py:1494] -------------------------------- start prefill layer 4 --------------------------------
DEBUG 01-14 20:42:48.640876.640876 cuda_h.py:10] start start_load_qkvogn_s_weight_l_5
DEBUG 01-14 20:42:48.640195.640195 cuda_h.py:10] start start_load_qkvogn_s_weight_l_5
DEBUG 01-14 20:42:48.640793.640793 cuda_h.py:19] end start_load_qkvogn_s_weight_l_5 cost 3.075599670410156e-05 seconds
DEBUG 01-14 20:42:48.640065.640065 cuda_h.py:19] end start_load_qkvogn_s_weight_l_5 cost 5.8650970458984375e-05 seconds
DEBUG 01-14 20:42:48.640424.640424 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-14 20:42:48.640572.640572 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-14 20:42:48.640694.640694 cuda_h.py:10] start sllm_worker_task
DEBUG 01-14 20:42:48.640353.640353 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-14 20:42:48.640712.640712 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-14 20:42:48.643058.643058 cuda_h.py:19] end allocate_cuda_memory cost 0.002546548843383789 seconds
DEBUG 01-14 20:42:48.643939.643939 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-14 20:42:48.643174.643174 sllm_store_c.py:27] get device uuid map
DEBUG 01-14 20:42:48.643337.643337 sllm_store_c.py:29] call client load into gpu
DEBUG 01-14 20:42:48.643730.643730 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, be7fe602-115f-4dba-a242-738c2422ab14
DEBUG 01-14 20:42:48.643465.643465 client.py:106] call stub.LoadModelAsync
DEBUG 01-14 20:42:48.644098.644098 mlpmodule.py:1367]  experts func einsum cost 0.07422280311584473 s
DEBUG 01-14 20:42:48.644116.644116 cuda_h.py:10] start self_attn
INFO 01-14 20:42:48.644297.644297 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, be7fe602-115f-4dba-a242-738c2422ab14
DEBUG 01-14 20:42:48.645093.645093 cuda_h.py:19] end load_into_gpu_async cost 0.0015671253204345703 seconds
DEBUG 01-14 20:42:48.645704.645704 cuda_h.py:10] start restore_tensors2
DEBUG 01-14 20:42:48.645601.645601 cuda_h.py:19] end restore_tensors2 cost 7.128715515136719e-05 seconds
DEBUG 01-14 20:42:48.645788.645788 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.004639863967895508 seconds
INFO 01-14 20:42:48.645677.645677 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, be7fe602-115f-4dba-a242-738c2422ab14
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-14 20:42:48.647605.647605 cuda_h.py:19] end self_attn cost 0.002813577651977539 seconds
DEBUG 01-14 20:42:48.647827.647827 cuda_h.py:19] end iln_self_attn_paln cost 0.007467031478881836 seconds
DEBUG 01-14 20:42:48.647862.647862 cuda_h.py:10] start layer_moe_generate_mp_l_5
DEBUG 01-14 20:42:48.647148.647148 cuda_h.py:10] start gate
DEBUG 01-14 20:42:48.648277.648277 cuda_h.py:19] end gate cost 0.0006573200225830078 seconds
DEBUG 01-14 20:42:48.648921.648921 cuda_h.py:10] start experts_map_get
DEBUG 01-14 20:42:48.648534.648534 lmp.py:1615] 
DEBUG 01-14 20:42:48.648534.648534 lmp.py:1615] Expert Token Distribution & Device Allocation:
DEBUG 01-14 20:42:48.648529.648529 lmp.py:1616]   Total experts: 64
DEBUG 01-14 20:42:48.648563.648563 lmp.py:1617]   CPU experts: 32 (50%)
DEBUG 01-14 20:42:48.648828.648828 lmp.py:1618]   GPU experts: 32 (50%)
DEBUG 01-14 20:42:48.648233.648233 lmp.py:1619] 
DEBUG 01-14 20:42:48.648233.648233 lmp.py:1619]   Expert ID | Tokens | Device
DEBUG 01-14 20:42:48.648876.648876 lmp.py:1620]   -----------------------------------
DEBUG 01-14 20:42:48.649996.649996 lmp.py:1625]   Expert 14 |     69 | CPU
DEBUG 01-14 20:42:48.649685.649685 lmp.py:1625]   Expert 13 |     71 | CPU
DEBUG 01-14 20:42:48.649136.649136 lmp.py:1625]   Expert 57 |     77 | CPU
DEBUG 01-14 20:42:48.649348.649348 lmp.py:1625]   Expert 11 |     83 | CPU
DEBUG 01-14 20:42:48.649799.649799 lmp.py:1625]   Expert 31 |     88 | CPU
DEBUG 01-14 20:42:48.649012.649012 lmp.py:1625]   Expert 54 |     88 | CPU
DEBUG 01-14 20:42:48.649986.649986 lmp.py:1625]   Expert 26 |     90 | CPU
DEBUG 01-14 20:42:48.649437.649437 lmp.py:1625]   Expert 45 |     91 | CPU
DEBUG 01-14 20:42:48.649887.649887 lmp.py:1625]   Expert 10 |     96 | CPU
DEBUG 01-14 20:42:48.649861.649861 lmp.py:1625]   Expert 58 |    106 | CPU
DEBUG 01-14 20:42:48.649074.649074 lmp.py:1625]   Expert 51 |    108 | CPU
DEBUG 01-14 20:42:48.649525.649525 lmp.py:1625]   Expert 30 |    110 | CPU
DEBUG 01-14 20:42:48.649260.649260 lmp.py:1625]   Expert 36 |    114 | CPU
DEBUG 01-14 20:42:48.649996.649996 lmp.py:1625]   Expert 32 |    126 | CPU
DEBUG 01-14 20:42:48.649970.649970 lmp.py:1625]   Expert 20 |    128 | CPU
DEBUG 01-14 20:42:48.649944.649944 lmp.py:1625]   Expert 61 |    137 | CPU
DEBUG 01-14 20:42:48.649918.649918 lmp.py:1625]   Expert  4 |    139 | CPU
DEBUG 01-14 20:42:48.649892.649892 lmp.py:1625]   Expert 63 |    141 | CPU
DEBUG 01-14 20:42:48.649343.649343 lmp.py:1625]   Expert 16 |    144 | CPU
DEBUG 01-14 20:42:48.649509.649509 lmp.py:1625]   Expert 42 |    149 | CPU
DEBUG 01-14 20:42:48.649960.649960 lmp.py:1625]   Expert 53 |    150 | CPU
DEBUG 01-14 20:42:48.649934.649934 lmp.py:1625]   Expert  8 |    151 | CPU
DEBUG 01-14 20:42:48.649147.649147 lmp.py:1625]   Expert 47 |    151 | CPU
DEBUG 01-14 20:42:48.649359.649359 lmp.py:1625]   Expert 34 |    152 | CPU
DEBUG 01-14 20:42:48.649333.649333 lmp.py:1625]   Expert 60 |    154 | CPU
DEBUG 01-14 20:42:48.649307.649307 lmp.py:1625]   Expert 28 |    158 | CPU
DEBUG 01-14 20:42:48.649473.649473 lmp.py:1625]   Expert 17 |    168 | CPU
DEBUG 01-14 20:42:48.649686.649686 lmp.py:1625]   Expert 27 |    170 | CPU
DEBUG 01-14 20:42:48.649898.649898 lmp.py:1625]   Expert 56 |    176 | CPU
DEBUG 01-14 20:42:48.649872.649872 lmp.py:1625]   Expert 44 |    177 | CPU
DEBUG 01-14 20:42:48.649370.649370 lmp.py:1625]   Expert 29 |    179 | CPU
DEBUG 01-14 20:42:48.649344.649344 lmp.py:1625]   Expert 24 |    180 | CPU
DEBUG 01-14 20:42:48.649079.649079 lmp.py:1625]   Expert 41 |    181 | GPU
DEBUG 01-14 20:42:48.649292.649292 lmp.py:1625]   Expert  0 |    182 | GPU
DEBUG 01-14 20:42:48.649266.649266 lmp.py:1625]   Expert 48 |    182 | GPU
DEBUG 01-14 20:42:48.649001.649001 lmp.py:1625]   Expert  2 |    187 | GPU
DEBUG 01-14 20:42:48.649883.649883 lmp.py:1625]   Expert  9 |    187 | GPU
DEBUG 01-14 20:42:48.649095.649095 lmp.py:1625]   Expert  7 |    188 | GPU
DEBUG 01-14 20:42:48.649308.649308 lmp.py:1625]   Expert 15 |    189 | GPU
DEBUG 01-14 20:42:48.649712.649712 lmp.py:1625]   Expert  3 |    191 | GPU
DEBUG 01-14 20:42:48.649402.649402 lmp.py:1625]   Expert 18 |    196 | GPU
DEBUG 01-14 20:42:48.649329.649329 lmp.py:1625]   Expert 55 |    197 | GPU
DEBUG 01-14 20:42:48.649019.649019 lmp.py:1625]   Expert 40 |    199 | GPU
DEBUG 01-14 20:42:48.649946.649946 lmp.py:1625]   Expert  6 |    214 | GPU
DEBUG 01-14 20:42:48.649636.649636 lmp.py:1625]   Expert 38 |    214 | GPU
DEBUG 01-14 20:42:48.649563.649563 lmp.py:1625]   Expert 22 |    215 | GPU
DEBUG 01-14 20:42:48.649683.649683 lmp.py:1625]   Expert 37 |    224 | GPU
DEBUG 01-14 20:42:48.649611.649611 lmp.py:1625]   Expert 23 |    230 | GPU
DEBUG 01-14 20:42:48.649539.649539 lmp.py:1625]   Expert 25 |    237 | GPU
DEBUG 01-14 20:42:48.649989.649989 lmp.py:1625]   Expert 46 |    241 | GPU
DEBUG 01-14 20:42:48.649679.649679 lmp.py:1625]   Expert 50 |    252 | GPU
DEBUG 01-14 20:42:48.649368.649368 lmp.py:1625]   Expert 39 |    258 | GPU
DEBUG 01-14 20:42:48.649296.649296 lmp.py:1625]   Expert 12 |    261 | GPU
DEBUG 01-14 20:42:48.649747.649747 lmp.py:1625]   Expert 62 |    263 | GPU
DEBUG 01-14 20:42:48.649197.649197 lmp.py:1625]   Expert 19 |    267 | GPU
DEBUG 01-14 20:42:48.649648.649648 lmp.py:1625]   Expert 21 |    269 | GPU
DEBUG 01-14 20:42:48.649815.649815 lmp.py:1625]   Expert 35 |    289 | GPU
DEBUG 01-14 20:42:48.649742.649742 lmp.py:1625]   Expert 49 |    293 | GPU
DEBUG 01-14 20:42:48.649670.649670 lmp.py:1625]   Expert 52 |    301 | GPU
DEBUG 01-14 20:42:48.649598.649598 lmp.py:1625]   Expert 33 |    308 | GPU
DEBUG 01-14 20:42:48.650956.650956 lmp.py:1625]   Expert  1 |    347 | GPU
DEBUG 01-14 20:42:48.650076.650076 lmp.py:1625]   Expert  5 |    377 | GPU
DEBUG 01-14 20:42:48.650434.650434 lmp.py:1625]   Expert 43 |    434 | GPU
DEBUG 01-14 20:42:48.650792.650792 lmp.py:1625]   Expert 59 |    594 | GPU
DEBUG 01-14 20:42:48.650435.650435 lmp.py:1626] 
DEBUG 01-14 20:42:48.650435.650435 lmp.py:1626]   CPU total tokens: 4121 (33.5%)
DEBUG 01-14 20:42:48.650270.650270 lmp.py:1627]   GPU total tokens: 8167 (66.5%)
DEBUG 01-14 20:42:48.650019.650019 cuda_h.py:19] end experts_map_get cost 0.0015180110931396484 seconds
DEBUG 01-14 20:42:48.650392.650392 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-14 20:42:48.650282.650282 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-14 20:42:48.650227.650227 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-14 20:42:48.652333.652333 cuda_h.py:19] end allocate_cuda_memory cost 0.0019404888153076172 seconds
DEBUG 01-14 20:42:48.652779.652779 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-14 20:42:48.652972.652972 sllm_store_c.py:27] get device uuid map
DEBUG 01-14 20:42:48.652828.652828 sllm_store_c.py:29] call client load into gpu
DEBUG 01-14 20:42:48.652478.652478 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 81f8f2ab-8b25-4886-9b1f-a977123f9039
DEBUG 01-14 20:42:48.652782.652782 client.py:106] call stub.LoadModelAsync
INFO 01-14 20:42:48.653628.653628 client.py:127] Model loaded
DEBUG 01-14 20:42:48.653047.653047 cuda_h.py:10] start restore2model
DEBUG 01-14 20:42:48.653302.653302 cuda_h.py:19] end restore2model cost 0.0004591941833496094 seconds
INFO 01-14 20:42:48.653663.653663 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 81f8f2ab-8b25-4886-9b1f-a977123f9039
DEBUG 01-14 20:42:48.653235.653235 cuda_h.py:19] end sllm_worker_task cost 0.013294458389282227 seconds
DEBUG 01-14 20:42:48.653615.653615 cuda_h.py:19] end load_into_gpu_async cost 0.0013811588287353516 seconds
DEBUG 01-14 20:42:48.653869.653869 cuda_h.py:10] start restore_tensors2
DEBUG 01-14 20:42:48.654275.654275 cuda_h.py:19] end restore_tensors2 cost 0.00040984153747558594 seconds
DEBUG 01-14 20:42:48.654402.654402 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0041730403900146484 seconds
DEBUG 01-14 20:42:48.654549.654549 cuda_h.py:10] start restore2model
DEBUG 01-14 20:42:48.657447.657447 cuda_h.py:19] end restore2model cost 0.002632617950439453 seconds
DEBUG 01-14 20:42:48.657296.657296 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.006993532180786133 seconds
DEBUG 01-14 20:42:48.657854.657854 cuda_h.py:10] start gpu_sexperts
DEBUG 01-14 20:42:48.657904.657904 cuda_h.py:19] end gpu_sexperts cost 0.0002872943878173828 seconds
DEBUG 01-14 20:42:48.657064.657064 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-14 20:42:48.657867.657867 lmp.py:1683] 
DEBUG 01-14 20:42:48.657867.657867 lmp.py:1683]   Computing 32 experts on CPU...
DEBUG 01-14 20:42:48.657657.657657 cuda_h.py:19] end cpu_experts_submit cost 5.5789947509765625e-05 seconds
DEBUG 01-14 20:42:48.657975.657975 cuda_h.py:10] start experts_func_mgpu_group_pad
DEBUG 01-14 20:42:48.663440.663440 mlpmodule.py:1460] group tensors cost 0.00490880012512207 s
DEBUG 01-14 20:42:48.663883.663883 cuda_h.py:10] start move_flat_hidden2cpu
DEBUG 01-14 20:42:48.665655.665655 cuda_h.py:19] end experts_func_mgpu_group_pad cost 0.008171796798706055 seconds
DEBUG 01-14 20:42:48.667125.667125 cuda_h.py:10] start gpu_group_list
DEBUG 01-14 20:42:48.668321.668321 cuda_h.py:19] end gpu_group_list cost 0.00043129920959472656 seconds
DEBUG 01-14 20:42:48.668520.668520 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-14 20:42:48.668145.668145 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.09808349609375e-05 seconds
DEBUG 01-14 20:42:48.668046.668046 cuda_h.py:10] start wait_experts
INFO 01-14 20:42:48.668518.668518 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 81f8f2ab-8b25-4886-9b1f-a977123f9039
DEBUG 01-14 20:42:48.670685.670685 cuda_h.py:19] end move_flat_hidden2cpu cost 0.006651163101196289 seconds
DEBUG 01-14 20:42:48.672187.672187 mlpmodule.py:1533] pad cost 0.0018296241760253906 s
DEBUG 01-14 20:42:48.672184.672184 mlpmodule.py:1539] create cpu tensor cost 3.600120544433594e-05 s
DEBUG 01-14 20:42:48.674164.674164 mlpmodule.py:1544] move to cpu cost 0.0021255016326904297 s
DEBUG 01-14 20:42:48.683827.683827 mlpmodule.py:1558] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-14 20:42:48.684773.684773 mlpmodule.py:1559] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-14 20:42:48.684803.684803 mlpmodule.py:1564] group_w3 first element: 0.0086669921875
WARNING 01-14 20:42:48.684727.684727 mlpmodule.py:1574] start einsum2
DEBUG 01-14 20:42:48.701563.701563 mlpmodule.py:1584] group einsum cost 0.026271343231201172 s
DEBUG 01-14 20:42:48.702713.702713 mlpmodule.py:1593] cpy2cputensor cost 0.0007164478302001953 s
DEBUG 01-14 20:42:48.702873.702873 cuda_h.py:10] start move_outputs
DEBUG 01-14 20:42:48.705744.705744 cuda_h.py:19] end move_outputs cost 0.0030095577239990234 seconds
INFO 01-14 20:42:48.710880.710880 client.py:127] Model loaded
DEBUG 01-14 20:42:48.710125.710125 cuda_h.py:19] end wait_experts cost 0.042244911193847656 seconds
DEBUG 01-14 20:42:48.710179.710179 cuda_h.py:10] start gpu_experts
DEBUG 01-14 20:42:48.710810.710810 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-14 20:42:48.710241.710241 cuda_h.py:19] end wait_cetm_experts cost 0.00018262863159179688 seconds
DEBUG 01-14 20:42:48.710243.710243 cuda_h.py:10] start gpu_group_einsum_mp_multi_list
DEBUG 01-14 20:42:48.711668.711668 cuda_h.py:10] start gpu_group_tensor
DEBUG 01-14 20:42:48.720870.720870 cuda_h.py:19] end gpu_group_tensor cost 0.009154796600341797 seconds
DEBUG 01-14 20:42:48.720585.720585 cuda_h.py:10] start gpu_group_einsum
DEBUG 01-14 20:42:48.720935.720935 cuda_h.py:19] end gpu_group_einsum cost 0.0005214214324951172 seconds
DEBUG 01-14 20:42:48.721191.721191 cuda_h.py:10] start gpu_final_hidden_states_scatter
DEBUG 01-14 20:42:48.721835.721835 cuda_h.py:10] start all_expert_outputs_slices
DEBUG 01-14 20:42:48.721506.721506 cuda_h.py:19] end all_expert_outputs_slices cost 0.0002205371856689453 seconds
DEBUG 01-14 20:42:48.721209.721209 cuda_h.py:10] start concat_expert_out
DEBUG 01-14 20:42:48.721847.721847 cuda_h.py:19] end concat_expert_out cost 5.269050598144531e-05 seconds
DEBUG 01-14 20:42:48.721220.721220 cuda_h.py:10] start index_scatter
DEBUG 01-14 20:42:48.721740.721740 cuda_h.py:19] end index_scatter cost 7.009506225585938e-05 seconds
DEBUG 01-14 20:42:48.721927.721927 cuda_h.py:19] end gpu_final_hidden_states_scatter cost 0.00057220458984375 seconds
DEBUG 01-14 20:42:48.721360.721360 cuda_h.py:19] end gpu_experts cost 0.011095046997070312 seconds
DEBUG 01-14 20:42:48.721486.721486 cuda_h.py:10] start all_expert_weight_slices
DEBUG 01-14 20:42:48.722938.722938 cuda_h.py:19] end all_expert_weight_slices cost 0.0007965564727783203 seconds
DEBUG 01-14 20:42:48.722813.722813 cuda_h.py:10] start cpuoutputsdeal
DEBUG 01-14 20:42:48.723766.723766 cuda_h.py:10] start index_scatter
DEBUG 01-14 20:42:48.723239.723239 cuda_h.py:19] end index_scatter cost 5.4836273193359375e-05 seconds
DEBUG 01-14 20:42:48.723433.723433 cuda_h.py:19] end cpuoutputsdeal cost 0.0004673004150390625 seconds
DEBUG 01-14 20:42:48.723335.723335 cuda_h.py:19] end layer_moe_generate_mp_l_5 cost 0.07542276382446289 seconds
DEBUG 01-14 20:42:48.723506.723506 cuda_h.py:19] end prefill_layer cost 0.08348894119262695 seconds
DEBUG 01-14 20:42:48.723932.723932 lmp.py:1551] -------------------------------- end prefill layer 4 --------------------------------
DEBUG 01-14 20:42:48.723297.723297 cuda_h.py:10] start prefill_layer
DEBUG 01-14 20:42:48.723708.723708 lmp.py:1494] -------------------------------- start prefill layer 5 --------------------------------
DEBUG 01-14 20:42:48.723881.723881 cuda_h.py:10] start start_load_qkvogn_s_weight_l_6
DEBUG 01-14 20:42:48.723677.723677 cuda_h.py:10] start start_load_qkvogn_s_weight_l_6
DEBUG 01-14 20:42:48.723798.723798 cuda_h.py:19] end start_load_qkvogn_s_weight_l_6 cost 3.0517578125e-05 seconds
DEBUG 01-14 20:42:48.723308.723308 cuda_h.py:19] end start_load_qkvogn_s_weight_l_6 cost 5.91278076171875e-05 seconds
DEBUG 01-14 20:42:48.723428.723428 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-14 20:42:48.723908.723908 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-14 20:42:48.723970.723970 cuda_h.py:10] start sllm_worker_task
DEBUG 01-14 20:42:48.724728.724728 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-14 20:42:48.724876.724876 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-14 20:42:48.725777.725777 cuda_h.py:19] end allocate_cuda_memory cost 0.0009360313415527344 seconds
DEBUG 01-14 20:42:48.725832.725832 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-14 20:42:48.725648.725648 sllm_store_c.py:27] get device uuid map
DEBUG 01-14 20:42:48.725677.725677 sllm_store_c.py:29] call client load into gpu
DEBUG 01-14 20:42:48.725532.725532 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, ed118b04-54a4-42a6-a66c-cc09c02591fc
DEBUG 01-14 20:42:48.725092.725092 client.py:106] call stub.LoadModelAsync
DEBUG 01-14 20:42:48.725665.725665 mlpmodule.py:1367]  experts func einsum cost 0.0676121711730957 s
DEBUG 01-14 20:42:48.726234.726234 cuda_h.py:10] start self_attn
INFO 01-14 20:42:48.726064.726064 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, ed118b04-54a4-42a6-a66c-cc09c02591fc
DEBUG 01-14 20:42:48.726345.726345 cuda_h.py:19] end load_into_gpu_async cost 0.0012137889862060547 seconds
DEBUG 01-14 20:42:48.726723.726723 cuda_h.py:10] start restore_tensors2
DEBUG 01-14 20:42:48.726687.726687 cuda_h.py:19] end restore_tensors2 cost 7.987022399902344e-05 seconds
DEBUG 01-14 20:42:48.726834.726834 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0025284290313720703 seconds
INFO 01-14 20:42:48.726121.726121 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, ed118b04-54a4-42a6-a66c-cc09c02591fc
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-14 20:42:48.729711.729711 cuda_h.py:19] end self_attn cost 0.003055095672607422 seconds
DEBUG 01-14 20:42:48.729900.729900 cuda_h.py:19] end iln_self_attn_paln cost 0.0057621002197265625 seconds
DEBUG 01-14 20:42:48.729697.729697 cuda_h.py:10] start layer_moe_generate_mp_l_6
DEBUG 01-14 20:42:48.729652.729652 cuda_h.py:10] start gate
DEBUG 01-14 20:42:48.730402.730402 cuda_h.py:19] end gate cost 0.0006234645843505859 seconds
DEBUG 01-14 20:42:48.730570.730570 cuda_h.py:10] start experts_map_get
DEBUG 01-14 20:42:48.730176.730176 lmp.py:1615] 
DEBUG 01-14 20:42:48.730176.730176 lmp.py:1615] Expert Token Distribution & Device Allocation:
DEBUG 01-14 20:42:48.730932.730932 lmp.py:1616]   Total experts: 64
DEBUG 01-14 20:42:48.730059.730059 lmp.py:1617]   CPU experts: 32 (50%)
DEBUG 01-14 20:42:48.730847.730847 lmp.py:1618]   GPU experts: 32 (50%)
DEBUG 01-14 20:42:48.730490.730490 lmp.py:1619] 
DEBUG 01-14 20:42:48.730490.730490 lmp.py:1619]   Expert ID | Tokens | Device
DEBUG 01-14 20:42:48.730657.730657 lmp.py:1620]   -----------------------------------
DEBUG 01-14 20:42:48.730776.730776 lmp.py:1625]   Expert 34 |     38 | CPU
DEBUG 01-14 20:42:48.730181.730181 lmp.py:1625]   Expert 45 |     70 | CPU
DEBUG 01-14 20:42:48.730347.730347 lmp.py:1625]   Expert 22 |     75 | CPU
DEBUG 01-14 20:42:48.730275.730275 lmp.py:1625]   Expert 57 |     93 | CPU
DEBUG 01-14 20:42:48.730441.730441 lmp.py:1625]   Expert 17 |     96 | CPU
DEBUG 01-14 20:42:48.730084.730084 lmp.py:1625]   Expert 15 |    103 | CPU
DEBUG 01-14 20:42:48.730012.730012 lmp.py:1625]   Expert  4 |    106 | CPU
DEBUG 01-14 20:42:48.730462.730462 lmp.py:1625]   Expert 28 |    109 | CPU
DEBUG 01-14 20:42:48.731913.731913 lmp.py:1625]   Expert 16 |    114 | CPU
DEBUG 01-14 20:42:48.731126.731126 lmp.py:1625]   Expert 12 |    120 | CPU
DEBUG 01-14 20:42:48.731338.731338 lmp.py:1625]   Expert 60 |    121 | CPU
DEBUG 01-14 20:42:48.731789.731789 lmp.py:1625]   Expert 32 |    125 | CPU
DEBUG 01-14 20:42:48.731002.731002 lmp.py:1625]   Expert 14 |    127 | CPU
DEBUG 01-14 20:42:48.731168.731168 lmp.py:1625]   Expert 25 |    128 | CPU
DEBUG 01-14 20:42:48.731334.731334 lmp.py:1625]   Expert 36 |    128 | CPU
DEBUG 01-14 20:42:48.731692.731692 lmp.py:1625]   Expert  8 |    129 | CPU
DEBUG 01-14 20:42:48.731097.731097 lmp.py:1625]   Expert 52 |    130 | CPU
DEBUG 01-14 20:42:48.731501.731501 lmp.py:1625]   Expert  2 |    134 | CPU
DEBUG 01-14 20:42:48.731906.731906 lmp.py:1625]   Expert  0 |    141 | CPU
DEBUG 01-14 20:42:48.731549.731549 lmp.py:1625]   Expert  5 |    143 | CPU
DEBUG 01-14 20:42:48.731907.731907 lmp.py:1625]   Expert 35 |    144 | CPU
DEBUG 01-14 20:42:48.731312.731312 lmp.py:1625]   Expert 23 |    154 | CPU
DEBUG 01-14 20:42:48.731716.731716 lmp.py:1625]   Expert 41 |    154 | CPU
DEBUG 01-14 20:42:48.731882.731882 lmp.py:1625]   Expert 39 |    158 | CPU
DEBUG 01-14 20:42:48.731287.731287 lmp.py:1625]   Expert 61 |    162 | CPU
DEBUG 01-14 20:42:48.731168.731168 lmp.py:1625]   Expert 30 |    164 | CPU
DEBUG 01-14 20:42:48.731526.731526 lmp.py:1625]   Expert 43 |    167 | CPU
DEBUG 01-14 20:42:48.731931.731931 lmp.py:1625]   Expert 44 |    168 | CPU
DEBUG 01-14 20:42:48.731097.731097 lmp.py:1625]   Expert  9 |    174 | CPU
DEBUG 01-14 20:42:48.731502.731502 lmp.py:1625]   Expert 13 |    175 | CPU
DEBUG 01-14 20:42:48.731429.731429 lmp.py:1625]   Expert 31 |    177 | CPU
DEBUG 01-14 20:42:48.731834.731834 lmp.py:1625]   Expert  3 |    178 | CPU
DEBUG 01-14 20:42:48.731000.731000 lmp.py:1625]   Expert 46 |    186 | GPU
DEBUG 01-14 20:42:48.731643.731643 lmp.py:1625]   Expert 62 |    187 | GPU
DEBUG 01-14 20:42:48.731524.731524 lmp.py:1625]   Expert 42 |    188 | GPU
DEBUG 01-14 20:42:48.731691.731691 lmp.py:1625]   Expert 50 |    189 | GPU
DEBUG 01-14 20:42:48.731857.731857 lmp.py:1625]   Expert 47 |    192 | GPU
DEBUG 01-14 20:42:48.731023.731023 lmp.py:1625]   Expert 11 |    195 | GPU
DEBUG 01-14 20:42:48.731427.731427 lmp.py:1625]   Expert 20 |    195 | GPU
DEBUG 01-14 20:42:48.731594.731594 lmp.py:1625]   Expert 26 |    196 | GPU
DEBUG 01-14 20:42:48.731760.731760 lmp.py:1625]   Expert 51 |    198 | GPU
DEBUG 01-14 20:42:48.731926.731926 lmp.py:1625]   Expert 63 |    201 | GPU
DEBUG 01-14 20:42:48.731569.731569 lmp.py:1625]   Expert 19 |    202 | GPU
DEBUG 01-14 20:42:48.731689.731689 lmp.py:1625]   Expert 18 |    203 | GPU
DEBUG 01-14 20:42:48.731093.731093 lmp.py:1625]   Expert 27 |    205 | GPU
DEBUG 01-14 20:42:48.731259.731259 lmp.py:1625]   Expert 56 |    209 | GPU
DEBUG 01-14 20:42:48.731425.731425 lmp.py:1625]   Expert 55 |    212 | GPU
DEBUG 01-14 20:42:48.731353.731353 lmp.py:1625]   Expert 38 |    216 | GPU
DEBUG 01-14 20:42:48.731519.731519 lmp.py:1625]   Expert 49 |    219 | GPU
DEBUG 01-14 20:42:48.731685.731685 lmp.py:1625]   Expert 48 |    224 | GPU
DEBUG 01-14 20:42:48.731852.731852 lmp.py:1625]   Expert  1 |    234 | GPU
DEBUG 01-14 20:42:48.731256.731256 lmp.py:1625]   Expert 54 |    240 | GPU
DEBUG 01-14 20:42:48.731661.731661 lmp.py:1625]   Expert 10 |    243 | GPU
DEBUG 01-14 20:42:48.731827.731827 lmp.py:1625]   Expert  7 |    244 | GPU
DEBUG 01-14 20:42:48.731708.731708 lmp.py:1625]   Expert 21 |    247 | GPU
DEBUG 01-14 20:42:48.731590.731590 lmp.py:1625]   Expert 24 |    251 | GPU
DEBUG 01-14 20:42:48.731994.731994 lmp.py:1625]   Expert 33 |    252 | GPU
DEBUG 01-14 20:42:48.731922.731922 lmp.py:1625]   Expert 29 |    260 | GPU
DEBUG 01-14 20:42:48.731088.731088 lmp.py:1625]   Expert 40 |    271 | GPU
DEBUG 01-14 20:42:48.731254.731254 lmp.py:1625]   Expert 59 |    294 | GPU
DEBUG 01-14 20:42:48.731182.731182 lmp.py:1625]   Expert 37 |    337 | GPU
DEBUG 01-14 20:42:48.731348.731348 lmp.py:1625]   Expert 58 |    356 | GPU
DEBUG 01-14 20:42:48.731276.731276 lmp.py:1625]   Expert  6 |    388 | GPU
DEBUG 01-14 20:42:48.731919.731919 lmp.py:1625]   Expert 53 |    849 | GPU
DEBUG 01-14 20:42:48.731562.731562 lmp.py:1626] 
DEBUG 01-14 20:42:48.731562.731562 lmp.py:1626]   CPU total tokens: 4205 (34.2%)
DEBUG 01-14 20:42:48.731682.731682 lmp.py:1627]   GPU total tokens: 8083 (65.8%)
DEBUG 01-14 20:42:48.732854.732854 cuda_h.py:19] end experts_map_get cost 0.0015516281127929688 seconds
DEBUG 01-14 20:42:48.732704.732704 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-14 20:42:48.732355.732355 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-14 20:42:48.732638.732638 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-14 20:42:48.733224.733224 cuda_h.py:19] end allocate_cuda_memory cost 0.0014519691467285156 seconds
DEBUG 01-14 20:42:48.733882.733882 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-14 20:42:48.733400.733400 sllm_store_c.py:27] get device uuid map
DEBUG 01-14 20:42:48.733354.733354 sllm_store_c.py:29] call client load into gpu
DEBUG 01-14 20:42:48.733481.733481 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 5bfe3c9b-5f6f-47c5-ae7c-dfd4743cf8ca
DEBUG 01-14 20:42:48.734832.734832 client.py:106] call stub.LoadModelAsync
INFO 01-14 20:42:48.734003.734003 client.py:127] Model loaded
DEBUG 01-14 20:42:48.734767.734767 cuda_h.py:10] start restore2model
DEBUG 01-14 20:42:48.735032.735032 cuda_h.py:19] end restore2model cost 0.0005285739898681641 seconds
DEBUG 01-14 20:42:48.735974.735974 cuda_h.py:19] end sllm_worker_task cost 0.011107683181762695 seconds
INFO 01-14 20:42:48.735070.735070 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 5bfe3c9b-5f6f-47c5-ae7c-dfd4743cf8ca
DEBUG 01-14 20:42:48.735774.735774 cuda_h.py:19] end load_into_gpu_async cost 0.0015010833740234375 seconds
DEBUG 01-14 20:42:48.735385.735385 cuda_h.py:10] start restore_tensors2
DEBUG 01-14 20:42:48.735928.735928 cuda_h.py:19] end restore_tensors2 cost 0.00037169456481933594 seconds
DEBUG 01-14 20:42:48.735102.735102 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0036873817443847656 seconds
DEBUG 01-14 20:42:48.735726.735726 cuda_h.py:10] start restore2model
DEBUG 01-14 20:42:48.738277.738277 cuda_h.py:19] end restore2model cost 0.002588510513305664 seconds
DEBUG 01-14 20:42:48.738074.738074 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.006451606750488281 seconds
DEBUG 01-14 20:42:48.738559.738559 cuda_h.py:10] start gpu_sexperts
DEBUG 01-14 20:42:48.738470.738470 cuda_h.py:19] end gpu_sexperts cost 0.00029015541076660156 seconds
DEBUG 01-14 20:42:48.738154.738154 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-14 20:42:48.739526.739526 lmp.py:1683] 
DEBUG 01-14 20:42:48.739526.739526 lmp.py:1683]   Computing 32 experts on CPU...
DEBUG 01-14 20:42:48.739269.739269 cuda_h.py:19] end cpu_experts_submit cost 5.626678466796875e-05 seconds
DEBUG 01-14 20:42:48.739588.739588 cuda_h.py:10] start experts_func_mgpu_group_pad
DEBUG 01-14 20:42:48.756473.756473 mlpmodule.py:1460] group tensors cost 0.016939640045166016 s
DEBUG 01-14 20:42:48.757444.757444 cuda_h.py:10] start move_flat_hidden2cpu
DEBUG 01-14 20:42:48.763645.763645 cuda_h.py:19] end experts_func_mgpu_group_pad cost 0.02397465705871582 seconds
DEBUG 01-14 20:42:48.764358.764358 cuda_h.py:19] end move_flat_hidden2cpu cost 0.006858348846435547 seconds
DEBUG 01-14 20:42:48.766738.766738 cuda_h.py:10] start gpu_group_list
DEBUG 01-14 20:42:48.767412.767412 cuda_h.py:19] end gpu_group_list cost 0.0007653236389160156 seconds
DEBUG 01-14 20:42:48.767230.767230 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-14 20:42:48.767221.767221 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 3.147125244140625e-05 seconds
DEBUG 01-14 20:42:48.767872.767872 cuda_h.py:10] start wait_experts
INFO 01-14 20:42:48.768662.768662 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 5bfe3c9b-5f6f-47c5-ae7c-dfd4743cf8ca
DEBUG 01-14 20:42:48.768396.768396 mlpmodule.py:1533] pad cost 0.0039861202239990234 s
DEBUG 01-14 20:42:48.768237.768237 mlpmodule.py:1539] create cpu tensor cost 4.029273986816406e-05 s
DEBUG 01-14 20:42:48.770118.770118 mlpmodule.py:1544] move to cpu cost 0.002121448516845703 s
DEBUG 01-14 20:42:48.780669.780669 mlpmodule.py:1558] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-14 20:42:48.780569.780569 mlpmodule.py:1559] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-14 20:42:48.780499.780499 mlpmodule.py:1564] group_w3 first element: 0.03369140625
WARNING 01-14 20:42:48.780900.780900 mlpmodule.py:1574] start einsum2
INFO 01-14 20:42:48.787409.787409 client.py:127] Model loaded
DEBUG 01-14 20:42:48.787646.787646 cuda_h.py:19] end wait_experts cost 0.019883155822753906 seconds
DEBUG 01-14 20:42:48.787323.787323 cuda_h.py:10] start gpu_experts
DEBUG 01-14 20:42:48.787146.787146 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-14 20:42:48.798254.798254 mlpmodule.py:1584] group einsum cost 0.02811264991760254 s
DEBUG 01-14 20:42:48.799836.799836 mlpmodule.py:1593] cpy2cputensor cost 0.0007867813110351562 s
DEBUG 01-14 20:42:48.799851.799851 cuda_h.py:10] start move_outputs
DEBUG 01-14 20:42:48.802286.802286 cuda_h.py:19] end move_outputs cost 0.002069234848022461 seconds
DEBUG 01-14 20:42:48.805411.805411 cuda_h.py:19] end wait_cetm_experts cost 0.0177309513092041 seconds
DEBUG 01-14 20:42:48.806829.806829 cuda_h.py:10] start gpu_group_einsum_mp_multi_list
DEBUG 01-14 20:42:48.806413.806413 cuda_h.py:10] start gpu_group_tensor
DEBUG 01-14 20:42:48.806747.806747 cuda_h.py:19] end gpu_group_tensor cost 0.000247955322265625 seconds
DEBUG 01-14 20:42:48.806202.806202 cuda_h.py:10] start gpu_group_einsum
DEBUG 01-14 20:42:48.821004.821004 mlpmodule.py:1367]  experts func einsum cost 0.08187413215637207 s
DEBUG 01-14 20:42:48.822170.822170 cuda_h.py:19] end gpu_group_einsum cost 0.01582026481628418 seconds
DEBUG 01-14 20:42:48.822924.822924 cuda_h.py:10] start gpu_final_hidden_states_scatter
DEBUG 01-14 20:42:48.822430.822430 cuda_h.py:10] start all_expert_outputs_slices
DEBUG 01-14 20:42:48.822723.822723 cuda_h.py:19] end all_expert_outputs_slices cost 0.0002219676971435547 seconds
DEBUG 01-14 20:42:48.822426.822426 cuda_h.py:10] start concat_expert_out
DEBUG 01-14 20:42:48.822230.822230 cuda_h.py:19] end concat_expert_out cost 6.079673767089844e-05 seconds
DEBUG 01-14 20:42:48.823080.823080 cuda_h.py:10] start index_scatter
DEBUG 01-14 20:42:48.823316.823316 cuda_h.py:19] end index_scatter cost 7.033348083496094e-05 seconds
DEBUG 01-14 20:42:48.823694.823694 cuda_h.py:19] end gpu_final_hidden_states_scatter cost 0.0005955696105957031 seconds
DEBUG 01-14 20:42:48.823034.823034 cuda_h.py:19] end gpu_experts cost 0.035256385803222656 seconds
DEBUG 01-14 20:42:48.823592.823592 cuda_h.py:10] start all_expert_weight_slices
DEBUG 01-14 20:42:48.824247.824247 cuda_h.py:19] end all_expert_weight_slices cost 0.0007710456848144531 seconds
DEBUG 01-14 20:42:48.824448.824448 cuda_h.py:10] start cpuoutputsdeal
DEBUG 01-14 20:42:48.824983.824983 cuda_h.py:10] start index_scatter
DEBUG 01-14 20:42:48.824119.824119 cuda_h.py:19] end index_scatter cost 4.839897155761719e-05 seconds
DEBUG 01-14 20:42:48.824597.824597 cuda_h.py:19] end cpuoutputsdeal cost 0.0004711151123046875 seconds
DEBUG 01-14 20:42:48.824976.824976 cuda_h.py:19] end layer_moe_generate_mp_l_6 cost 0.09494161605834961 seconds
DEBUG 01-14 20:42:48.824570.824570 cuda_h.py:19] end prefill_layer cost 0.10129833221435547 seconds
DEBUG 01-14 20:42:48.825659.825659 lmp.py:1551] -------------------------------- end prefill layer 5 --------------------------------
DEBUG 01-14 20:42:48.825785.825785 cuda_h.py:10] start prefill_layer
DEBUG 01-14 20:42:48.825958.825958 lmp.py:1494] -------------------------------- start prefill layer 6 --------------------------------
DEBUG 01-14 20:42:48.825846.825846 cuda_h.py:10] start start_load_qkvogn_s_weight_l_7
DEBUG 01-14 20:42:48.825165.825165 cuda_h.py:10] start start_load_qkvogn_s_weight_l_7
DEBUG 01-14 20:42:48.825955.825955 cuda_h.py:19] end start_load_qkvogn_s_weight_l_7 cost 3.266334533691406e-05 seconds
DEBUG 01-14 20:42:48.825989.825989 cuda_h.py:19] end start_load_qkvogn_s_weight_l_7 cost 6.031990051269531e-05 seconds
DEBUG 01-14 20:42:48.825632.825632 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-14 20:42:48.825780.825780 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-14 20:42:48.825366.825366 cuda_h.py:10] start sllm_worker_task
DEBUG 01-14 20:42:48.825138.825138 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-14 20:42:48.825166.825166 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-14 20:42:48.825147.825147 cuda_h.py:19] end allocate_cuda_memory cost 0.00019478797912597656 seconds
DEBUG 01-14 20:42:48.825793.825793 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-14 20:42:48.825423.825423 sllm_store_c.py:27] get device uuid map
DEBUG 01-14 20:42:48.825259.825259 sllm_store_c.py:29] call client load into gpu
DEBUG 01-14 20:42:48.826876.826876 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 89920383-b3a7-4503-866a-a4077ea309bb
DEBUG 01-14 20:42:48.826297.826297 client.py:106] call stub.LoadModelAsync
DEBUG 01-14 20:42:48.826041.826041 cuda_h.py:10] start self_attn
INFO 01-14 20:42:48.827014.827014 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 89920383-b3a7-4503-866a-a4077ea309bb
DEBUG 01-14 20:42:48.827148.827148 cuda_h.py:19] end load_into_gpu_async cost 0.001481771469116211 seconds
DEBUG 01-14 20:42:48.827335.827335 cuda_h.py:10] start restore_tensors2
DEBUG 01-14 20:42:48.827445.827445 cuda_h.py:19] end restore_tensors2 cost 8.130073547363281e-05 seconds
DEBUG 01-14 20:42:48.827022.827022 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.002054452896118164 seconds
INFO 01-14 20:42:48.827442.827442 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 89920383-b3a7-4503-866a-a4077ea309bb
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-14 20:42:48.829202.829202 cuda_h.py:19] end self_attn cost 0.002965211868286133 seconds
DEBUG 01-14 20:42:48.829477.829477 cuda_h.py:19] end iln_self_attn_paln cost 0.004456043243408203 seconds
DEBUG 01-14 20:42:48.829751.829751 cuda_h.py:10] start layer_moe_generate_mp_l_7
DEBUG 01-14 20:42:48.829560.829560 cuda_h.py:10] start gate
DEBUG 01-14 20:42:48.830815.830815 cuda_h.py:19] end gate cost 0.0006453990936279297 seconds
DEBUG 01-14 20:42:48.830459.830459 cuda_h.py:10] start experts_map_get
DEBUG 01-14 20:42:48.830072.830072 lmp.py:1615] 
DEBUG 01-14 20:42:48.830072.830072 lmp.py:1615] Expert Token Distribution & Device Allocation:
DEBUG 01-14 20:42:48.830173.830173 lmp.py:1616]   Total experts: 64
DEBUG 01-14 20:42:48.830014.830014 lmp.py:1617]   CPU experts: 32 (50%)
DEBUG 01-14 20:42:48.830042.830042 lmp.py:1618]   GPU experts: 32 (50%)
DEBUG 01-14 20:42:48.830969.830969 lmp.py:1619] 
DEBUG 01-14 20:42:48.830969.830969 lmp.py:1619]   Expert ID | Tokens | Device
DEBUG 01-14 20:42:48.830374.830374 lmp.py:1620]   -----------------------------------
DEBUG 01-14 20:42:48.831355.831355 lmp.py:1625]   Expert  1 |     51 | CPU
DEBUG 01-14 20:42:48.831951.831951 lmp.py:1625]   Expert 37 |     65 | CPU
DEBUG 01-14 20:42:48.831833.831833 lmp.py:1625]   Expert 17 |     74 | CPU
DEBUG 01-14 20:42:48.831237.831237 lmp.py:1625]   Expert  7 |     76 | CPU
DEBUG 01-14 20:42:48.831880.831880 lmp.py:1625]   Expert 13 |     80 | CPU
DEBUG 01-14 20:42:48.831285.831285 lmp.py:1625]   Expert 18 |     80 | CPU
DEBUG 01-14 20:42:48.831928.831928 lmp.py:1625]   Expert  9 |     89 | CPU
DEBUG 01-14 20:42:48.831809.831809 lmp.py:1625]   Expert 54 |     95 | CPU
DEBUG 01-14 20:42:48.831214.831214 lmp.py:1625]   Expert 58 |     97 | CPU
DEBUG 01-14 20:42:48.831380.831380 lmp.py:1625]   Expert 22 |    108 | CPU
DEBUG 01-14 20:42:48.831784.831784 lmp.py:1625]   Expert  0 |    109 | CPU
DEBUG 01-14 20:42:48.831712.831712 lmp.py:1625]   Expert 59 |    111 | CPU
DEBUG 01-14 20:42:48.831640.831640 lmp.py:1625]   Expert 26 |    113 | CPU
DEBUG 01-14 20:42:48.831568.831568 lmp.py:1625]   Expert 10 |    116 | CPU
DEBUG 01-14 20:42:48.831734.831734 lmp.py:1625]   Expert 16 |    122 | CPU
DEBUG 01-14 20:42:48.831900.831900 lmp.py:1625]   Expert 63 |    129 | CPU
DEBUG 01-14 20:42:48.831020.831020 lmp.py:1625]   Expert 43 |    131 | CPU
DEBUG 01-14 20:42:48.831186.831186 lmp.py:1625]   Expert 28 |    137 | CPU
DEBUG 01-14 20:42:48.831590.831590 lmp.py:1625]   Expert 29 |    139 | CPU
DEBUG 01-14 20:42:48.831280.831280 lmp.py:1625]   Expert 33 |    139 | CPU
DEBUG 01-14 20:42:48.831207.831207 lmp.py:1625]   Expert  2 |    147 | CPU
DEBUG 01-14 20:42:48.831374.831374 lmp.py:1625]   Expert 51 |    152 | CPU
DEBUG 01-14 20:42:48.831778.831778 lmp.py:1625]   Expert 45 |    158 | CPU
DEBUG 01-14 20:42:48.831706.831706 lmp.py:1625]   Expert 40 |    161 | CPU
DEBUG 01-14 20:42:48.831395.831395 lmp.py:1625]   Expert 62 |    161 | CPU
DEBUG 01-14 20:42:48.831846.831846 lmp.py:1625]   Expert 23 |    165 | CPU
DEBUG 01-14 20:42:48.831774.831774 lmp.py:1625]   Expert 55 |    165 | CPU
DEBUG 01-14 20:42:48.831940.831940 lmp.py:1625]   Expert 32 |    166 | CPU
DEBUG 01-14 20:42:48.831344.831344 lmp.py:1625]   Expert 11 |    169 | CPU
DEBUG 01-14 20:42:48.831511.831511 lmp.py:1625]   Expert 34 |    169 | CPU
DEBUG 01-14 20:42:48.831438.831438 lmp.py:1625]   Expert 52 |    172 | CPU
DEBUG 01-14 20:42:48.831128.831128 lmp.py:1625]   Expert 41 |    175 | CPU
DEBUG 01-14 20:42:48.831055.831055 lmp.py:1625]   Expert 14 |    178 | GPU
DEBUG 01-14 20:42:48.831221.831221 lmp.py:1625]   Expert  3 |    179 | GPU
DEBUG 01-14 20:42:48.831911.831911 lmp.py:1625]   Expert 53 |    184 | GPU
DEBUG 01-14 20:42:48.831838.831838 lmp.py:1625]   Expert 42 |    189 | GPU
DEBUG 01-14 20:42:48.831243.831243 lmp.py:1625]   Expert 57 |    193 | GPU
DEBUG 01-14 20:42:48.831409.831409 lmp.py:1625]   Expert 15 |    200 | GPU
DEBUG 01-14 20:42:48.831337.831337 lmp.py:1625]   Expert 35 |    204 | GPU
DEBUG 01-14 20:42:48.831026.831026 lmp.py:1625]   Expert 30 |    210 | GPU
DEBUG 01-14 20:42:48.831192.831192 lmp.py:1625]   Expert 21 |    213 | GPU
DEBUG 01-14 20:42:48.831882.831882 lmp.py:1625]   Expert 24 |    218 | GPU
DEBUG 01-14 20:42:48.831048.831048 lmp.py:1625]   Expert  4 |    220 | GPU
DEBUG 01-14 20:42:48.831499.831499 lmp.py:1625]   Expert 12 |    224 | GPU
DEBUG 01-14 20:42:48.831426.831426 lmp.py:1625]   Expert 44 |    226 | GPU
DEBUG 01-14 20:42:48.831354.831354 lmp.py:1625]   Expert 19 |    230 | GPU
DEBUG 01-14 20:42:48.831282.831282 lmp.py:1625]   Expert 49 |    232 | GPU
DEBUG 01-14 20:42:48.831925.831925 lmp.py:1625]   Expert 38 |    236 | GPU
DEBUG 01-14 20:42:48.831045.831045 lmp.py:1625]   Expert 47 |    236 | GPU
DEBUG 01-14 20:42:48.831449.831449 lmp.py:1625]   Expert 50 |    244 | GPU
DEBUG 01-14 20:42:48.831377.831377 lmp.py:1625]   Expert 61 |    246 | GPU
DEBUG 01-14 20:42:48.831066.831066 lmp.py:1625]   Expert  8 |    249 | GPU
DEBUG 01-14 20:42:48.831994.831994 lmp.py:1625]   Expert 31 |    249 | GPU
DEBUG 01-14 20:42:48.831160.831160 lmp.py:1625]   Expert  6 |    253 | GPU
DEBUG 01-14 20:42:48.831088.831088 lmp.py:1625]   Expert 46 |    253 | GPU
DEBUG 01-14 20:42:48.831208.831208 lmp.py:1625]   Expert 39 |    262 | GPU
DEBUG 01-14 20:42:48.831327.831327 lmp.py:1625]   Expert 27 |    303 | GPU
DEBUG 01-14 20:42:48.832732.832732 lmp.py:1625]   Expert  5 |    304 | GPU
DEBUG 01-14 20:42:48.832660.832660 lmp.py:1625]   Expert 48 |    304 | GPU
DEBUG 01-14 20:42:48.832587.832587 lmp.py:1625]   Expert 20 |    341 | GPU
DEBUG 01-14 20:42:48.832277.832277 lmp.py:1625]   Expert 36 |    359 | GPU
DEBUG 01-14 20:42:48.832443.832443 lmp.py:1625]   Expert 60 |    366 | GPU
DEBUG 01-14 20:42:48.832132.832132 lmp.py:1625]   Expert 25 |    395 | GPU
DEBUG 01-14 20:42:48.832583.832583 lmp.py:1625]   Expert 56 |    567 | GPU
DEBUG 01-14 20:42:48.832703.832703 lmp.py:1626] 
DEBUG 01-14 20:42:48.832703.832703 lmp.py:1626]   CPU total tokens: 4021 (32.7%)
DEBUG 01-14 20:42:48.832253.832253 lmp.py:1627]   GPU total tokens: 8267 (67.3%)
DEBUG 01-14 20:42:48.832141.832141 cuda_h.py:19] end experts_map_get cost 0.001562356948852539 seconds
DEBUG 01-14 20:42:48.832375.832375 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-14 20:42:48.832026.832026 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-14 20:42:48.832084.832084 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-14 20:42:48.833753.833753 cuda_h.py:19] end allocate_cuda_memory cost 0.0013358592987060547 seconds
DEBUG 01-14 20:42:48.833278.833278 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-14 20:42:48.833988.833988 sllm_store_c.py:27] get device uuid map
DEBUG 01-14 20:42:48.833936.833936 sllm_store_c.py:29] call client load into gpu
DEBUG 01-14 20:42:48.833155.833155 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 2819e0bd-e694-457d-99e9-b8ab1c9f762b
DEBUG 01-14 20:42:48.834214.834214 client.py:106] call stub.LoadModelAsync
INFO 01-14 20:42:48.835358.835358 client.py:127] Model loaded
DEBUG 01-14 20:42:48.835387.835387 cuda_h.py:10] start restore2model
DEBUG 01-14 20:42:48.835667.835667 cuda_h.py:19] end restore2model cost 0.0004134178161621094 seconds
DEBUG 01-14 20:42:48.836827.836827 cuda_h.py:19] end sllm_worker_task cost 0.010523796081542969 seconds
INFO 01-14 20:42:48.836834.836834 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 2819e0bd-e694-457d-99e9-b8ab1c9f762b
DEBUG 01-14 20:42:48.836829.836829 cuda_h.py:19] end load_into_gpu_async cost 0.002583742141723633 seconds
DEBUG 01-14 20:42:48.836155.836155 cuda_h.py:10] start restore_tensors2
DEBUG 01-14 20:42:48.836499.836499 cuda_h.py:19] end restore_tensors2 cost 0.00036597251892089844 seconds
DEBUG 01-14 20:42:48.836528.836528 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.004663944244384766 seconds
DEBUG 01-14 20:42:48.837290.837290 cuda_h.py:10] start restore2model
DEBUG 01-14 20:42:48.839854.839854 cuda_h.py:19] end restore2model cost 0.0025587081909179688 seconds
DEBUG 01-14 20:42:48.839075.839075 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.007403850555419922 seconds
DEBUG 01-14 20:42:48.839632.839632 cuda_h.py:10] start gpu_sexperts
DEBUG 01-14 20:42:48.839761.839761 cuda_h.py:19] end gpu_sexperts cost 0.00027489662170410156 seconds
DEBUG 01-14 20:42:48.840491.840491 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-14 20:42:48.840863.840863 lmp.py:1683] 
DEBUG 01-14 20:42:48.840863.840863 lmp.py:1683]   Computing 32 experts on CPU...
DEBUG 01-14 20:42:48.840845.840845 cuda_h.py:19] end cpu_experts_submit cost 5.6743621826171875e-05 seconds
DEBUG 01-14 20:42:48.840356.840356 cuda_h.py:10] start experts_func_mgpu_group_pad
DEBUG 01-14 20:42:48.855048.855048 mlpmodule.py:1460] group tensors cost 0.015172004699707031 s
DEBUG 01-14 20:42:48.856851.856851 cuda_h.py:10] start move_flat_hidden2cpu
DEBUG 01-14 20:42:48.859221.859221 cuda_h.py:19] end experts_func_mgpu_group_pad cost 0.018880605697631836 seconds
DEBUG 01-14 20:42:48.860048.860048 cuda_h.py:10] start gpu_group_list
DEBUG 01-14 20:42:48.861771.861771 cuda_h.py:19] end gpu_group_list cost 0.0005326271057128906 seconds
DEBUG 01-14 20:42:48.861327.861327 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-14 20:42:48.861014.861014 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.8133392333984375e-05 seconds
DEBUG 01-14 20:42:48.861718.861718 cuda_h.py:10] start wait_experts
INFO 01-14 20:42:48.861918.861918 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 2819e0bd-e694-457d-99e9-b8ab1c9f762b
DEBUG 01-14 20:42:48.863619.863619 cuda_h.py:19] end move_flat_hidden2cpu cost 0.0066432952880859375 seconds
DEBUG 01-14 20:42:48.865026.865026 mlpmodule.py:1533] pad cost 0.0017659664154052734 s
DEBUG 01-14 20:42:48.865454.865454 mlpmodule.py:1539] create cpu tensor cost 3.62396240234375e-05 s
DEBUG 01-14 20:42:48.867021.867021 mlpmodule.py:1544] move to cpu cost 0.002067089080810547 s
DEBUG 01-14 20:42:48.876949.876949 mlpmodule.py:1558] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-14 20:42:48.876650.876650 mlpmodule.py:1559] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-14 20:42:48.876296.876296 mlpmodule.py:1564] group_w3 first element: -0.003631591796875
WARNING 01-14 20:42:48.876982.876982 mlpmodule.py:1574] start einsum2
INFO 01-14 20:42:48.891489.891489 client.py:127] Model loaded
DEBUG 01-14 20:42:48.891179.891179 cuda_h.py:19] end wait_experts cost 0.029514551162719727 seconds
DEBUG 01-14 20:42:48.891241.891241 cuda_h.py:10] start gpu_experts
DEBUG 01-14 20:42:48.891098.891098 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-14 20:42:48.892506.892506 mlpmodule.py:1584] group einsum cost 0.0254971981048584 s
DEBUG 01-14 20:42:48.893668.893668 mlpmodule.py:1593] cpy2cputensor cost 0.0007216930389404297 s
DEBUG 01-14 20:42:48.893060.893060 cuda_h.py:10] start move_outputs
DEBUG 01-14 20:42:48.895898.895898 cuda_h.py:19] end move_outputs cost 0.0020253658294677734 seconds
DEBUG 01-14 20:42:48.899983.899983 cuda_h.py:19] end wait_cetm_experts cost 0.007986307144165039 seconds
DEBUG 01-14 20:42:48.899379.899379 cuda_h.py:10] start gpu_group_einsum_mp_multi_list
DEBUG 01-14 20:42:48.899765.899765 cuda_h.py:10] start gpu_group_tensor
DEBUG 01-14 20:42:48.900198.900198 cuda_h.py:19] end gpu_group_tensor cost 0.0002532005310058594 seconds
DEBUG 01-14 20:42:48.900308.900308 cuda_h.py:10] start gpu_group_einsum
DEBUG 01-14 20:42:48.900926.900926 cuda_h.py:19] end gpu_group_einsum cost 0.0006194114685058594 seconds
DEBUG 01-14 20:42:48.901142.901142 cuda_h.py:10] start gpu_final_hidden_states_scatter
DEBUG 01-14 20:42:48.901647.901647 cuda_h.py:10] start all_expert_outputs_slices
DEBUG 01-14 20:42:48.901897.901897 cuda_h.py:19] end all_expert_outputs_slices cost 0.0002923011779785156 seconds
DEBUG 01-14 20:42:48.901461.901461 cuda_h.py:10] start concat_expert_out
DEBUG 01-14 20:42:48.901874.901874 cuda_h.py:19] end concat_expert_out cost 5.793571472167969e-05 seconds
DEBUG 01-14 20:42:48.901347.901347 cuda_h.py:10] start index_scatter
DEBUG 01-14 20:42:48.901827.901827 cuda_h.py:19] end index_scatter cost 7.486343383789062e-05 seconds
DEBUG 01-14 20:42:48.901875.901875 cuda_h.py:19] end gpu_final_hidden_states_scatter cost 0.0006735324859619141 seconds
DEBUG 01-14 20:42:48.901891.901891 cuda_h.py:19] end gpu_experts cost 0.01026153564453125 seconds
DEBUG 01-14 20:42:48.901693.901693 cuda_h.py:10] start all_expert_weight_slices
DEBUG 01-14 20:42:48.902732.902732 cuda_h.py:19] end all_expert_weight_slices cost 0.0009469985961914062 seconds
DEBUG 01-14 20:42:48.902125.902125 cuda_h.py:10] start cpuoutputsdeal
DEBUG 01-14 20:42:48.903093.903093 cuda_h.py:10] start index_scatter
DEBUG 01-14 20:42:48.903229.903229 cuda_h.py:19] end index_scatter cost 4.982948303222656e-05 seconds
DEBUG 01-14 20:42:48.903137.903137 cuda_h.py:19] end cpuoutputsdeal cost 0.0005412101745605469 seconds
DEBUG 01-14 20:42:48.903524.903524 cuda_h.py:19] end layer_moe_generate_mp_l_7 cost 0.07367682456970215 seconds
DEBUG 01-14 20:42:48.903715.903715 cuda_h.py:19] end prefill_layer cost 0.07878398895263672 seconds
DEBUG 01-14 20:42:48.903334.903334 lmp.py:1551] -------------------------------- end prefill layer 6 --------------------------------
DEBUG 01-14 20:42:48.903706.903706 cuda_h.py:10] start prefill_layer
DEBUG 01-14 20:42:48.904077.904077 lmp.py:1494] -------------------------------- start prefill layer 7 --------------------------------
DEBUG 01-14 20:42:48.904211.904211 cuda_h.py:10] start start_load_qkvogn_s_weight_l_8
DEBUG 01-14 20:42:48.904821.904821 cuda_h.py:10] start start_load_qkvogn_s_weight_l_8
DEBUG 01-14 20:42:48.904731.904731 cuda_h.py:19] end start_load_qkvogn_s_weight_l_8 cost 4.5299530029296875e-05 seconds
DEBUG 01-14 20:42:48.904679.904679 cuda_h.py:19] end start_load_qkvogn_s_weight_l_8 cost 7.987022399902344e-05 seconds
DEBUG 01-14 20:42:48.904236.904236 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-14 20:42:48.904358.904358 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-14 20:42:48.904587.904587 cuda_h.py:10] start sllm_worker_task
DEBUG 01-14 20:42:48.904868.904868 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-14 20:42:48.904758.904758 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-14 20:42:48.905036.905036 cuda_h.py:19] end allocate_cuda_memory cost 0.0005507469177246094 seconds
DEBUG 01-14 20:42:48.905376.905376 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-14 20:42:48.905000.905000 sllm_store_c.py:27] get device uuid map
DEBUG 01-14 20:42:48.905790.905790 sllm_store_c.py:29] call client load into gpu
DEBUG 01-14 20:42:48.905261.905261 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, ac1580ba-afa5-4c11-9d27-4db6a8e3241f
DEBUG 01-14 20:42:48.905728.905728 client.py:106] call stub.LoadModelAsync
DEBUG 01-14 20:42:48.905832.905832 cuda_h.py:10] start self_attn
INFO 01-14 20:42:48.906928.906928 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, ac1580ba-afa5-4c11-9d27-4db6a8e3241f
DEBUG 01-14 20:42:48.906103.906103 cuda_h.py:19] end load_into_gpu_async cost 0.0010933876037597656 seconds
DEBUG 01-14 20:42:48.906951.906951 cuda_h.py:10] start restore_tensors2
DEBUG 01-14 20:42:48.906584.906584 cuda_h.py:19] end restore_tensors2 cost 8.487701416015625e-05 seconds
DEBUG 01-14 20:42:48.906446.906446 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0020062923431396484 seconds
INFO 01-14 20:42:48.906819.906819 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, ac1580ba-afa5-4c11-9d27-4db6a8e3241f
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-14 20:42:48.909461.909461 cuda_h.py:19] end self_attn cost 0.003857135772705078 seconds
DEBUG 01-14 20:42:48.910293.910293 cuda_h.py:19] end iln_self_attn_paln cost 0.005835533142089844 seconds
DEBUG 01-14 20:42:48.910044.910044 cuda_h.py:10] start layer_moe_generate_mp_l_8
DEBUG 01-14 20:42:48.910807.910807 cuda_h.py:10] start gate
DEBUG 01-14 20:42:48.910943.910943 cuda_h.py:19] end gate cost 0.0006606578826904297 seconds
DEBUG 01-14 20:42:48.910209.910209 cuda_h.py:10] start experts_map_get
DEBUG 01-14 20:42:48.911657.911657 lmp.py:1615] 
DEBUG 01-14 20:42:48.911657.911657 lmp.py:1615] Expert Token Distribution & Device Allocation:
DEBUG 01-14 20:42:48.911420.911420 lmp.py:1616]   Total experts: 64
DEBUG 01-14 20:42:48.911216.911216 lmp.py:1617]   CPU experts: 32 (50%)
DEBUG 01-14 20:42:48.911389.911389 lmp.py:1618]   GPU experts: 32 (50%)
DEBUG 01-14 20:42:48.911747.911747 lmp.py:1619] 
DEBUG 01-14 20:42:48.911747.911747 lmp.py:1619]   Expert ID | Tokens | Device
DEBUG 01-14 20:42:48.911013.911013 lmp.py:1620]   -----------------------------------
DEBUG 01-14 20:42:48.911040.911040 lmp.py:1625]   Expert 46 |     36 | CPU
DEBUG 01-14 20:42:48.911828.911828 lmp.py:1625]   Expert 50 |     48 | CPU
DEBUG 01-14 20:42:48.911948.911948 lmp.py:1625]   Expert  3 |     59 | CPU
DEBUG 01-14 20:42:48.911214.911214 lmp.py:1625]   Expert  1 |     85 | CPU
DEBUG 01-14 20:42:48.911049.911049 lmp.py:1625]   Expert 15 |     96 | CPU
DEBUG 01-14 20:42:48.911937.911937 lmp.py:1625]   Expert 29 |     96 | CPU
DEBUG 01-14 20:42:48.911580.911580 lmp.py:1625]   Expert  4 |    100 | CPU
DEBUG 01-14 20:42:48.911933.911933 lmp.py:1625]   Expert 40 |    102 | CPU
DEBUG 01-14 20:42:48.911529.911529 lmp.py:1625]   Expert 28 |    104 | CPU
DEBUG 01-14 20:42:48.911934.911934 lmp.py:1625]   Expert 54 |    116 | CPU
DEBUG 01-14 20:42:48.911769.911769 lmp.py:1625]   Expert  8 |    118 | CPU
DEBUG 01-14 20:42:48.911412.911412 lmp.py:1625]   Expert 41 |    118 | CPU
DEBUG 01-14 20:42:48.911578.911578 lmp.py:1625]   Expert 13 |    129 | CPU
DEBUG 01-14 20:42:48.911983.911983 lmp.py:1625]   Expert 16 |    132 | CPU
DEBUG 01-14 20:42:48.911149.911149 lmp.py:1625]   Expert 18 |    132 | CPU
DEBUG 01-14 20:42:48.911030.911030 lmp.py:1625]   Expert  7 |    134 | CPU
DEBUG 01-14 20:42:48.911196.911196 lmp.py:1625]   Expert 51 |    134 | CPU
DEBUG 01-14 20:42:48.911316.911316 lmp.py:1625]   Expert 48 |    135 | CPU
DEBUG 01-14 20:42:48.911913.911913 lmp.py:1625]   Expert  6 |    138 | CPU
DEBUG 01-14 20:42:48.911317.911317 lmp.py:1625]   Expert 36 |    138 | CPU
DEBUG 01-14 20:42:48.911722.911722 lmp.py:1625]   Expert 27 |    139 | CPU
DEBUG 01-14 20:42:48.911888.911888 lmp.py:1625]   Expert 52 |    139 | CPU
DEBUG 01-14 20:42:48.911054.911054 lmp.py:1625]   Expert 60 |    140 | CPU
DEBUG 01-14 20:42:48.911459.911459 lmp.py:1625]   Expert 39 |    141 | CPU
DEBUG 01-14 20:42:48.911102.911102 lmp.py:1625]   Expert 43 |    141 | CPU
DEBUG 01-14 20:42:48.911506.911506 lmp.py:1625]   Expert 20 |    142 | CPU
DEBUG 01-14 20:42:48.911911.911911 lmp.py:1625]   Expert 11 |    145 | CPU
DEBUG 01-14 20:42:48.911077.911077 lmp.py:1625]   Expert 35 |    154 | CPU
DEBUG 01-14 20:42:48.911243.911243 lmp.py:1625]   Expert 62 |    155 | CPU
DEBUG 01-14 20:42:48.911886.911886 lmp.py:1625]   Expert 56 |    158 | CPU
DEBUG 01-14 20:42:48.911529.911529 lmp.py:1625]   Expert 45 |    159 | CPU
DEBUG 01-14 20:42:48.911934.911934 lmp.py:1625]   Expert 14 |    160 | CPU
DEBUG 01-14 20:42:48.912338.912338 lmp.py:1625]   Expert  5 |    163 | GPU
DEBUG 01-14 20:42:48.912027.912027 lmp.py:1625]   Expert 10 |    172 | GPU
DEBUG 01-14 20:42:48.912717.912717 lmp.py:1625]   Expert 55 |    176 | GPU
DEBUG 01-14 20:42:48.912883.912883 lmp.py:1625]   Expert 44 |    178 | GPU
DEBUG 01-14 20:42:48.912049.912049 lmp.py:1625]   Expert 25 |    183 | GPU
DEBUG 01-14 20:42:48.912215.912215 lmp.py:1625]   Expert 31 |    184 | GPU
DEBUG 01-14 20:42:48.912381.912381 lmp.py:1625]   Expert 57 |    185 | GPU
DEBUG 01-14 20:42:48.912547.912547 lmp.py:1625]   Expert 58 |    185 | GPU
DEBUG 01-14 20:42:48.912190.912190 lmp.py:1625]   Expert 32 |    189 | GPU
DEBUG 01-14 20:42:48.912833.912833 lmp.py:1625]   Expert 33 |    189 | GPU
DEBUG 01-14 20:42:48.912476.912476 lmp.py:1625]   Expert  2 |    195 | GPU
DEBUG 01-14 20:42:48.912166.912166 lmp.py:1625]   Expert 53 |    196 | GPU
DEBUG 01-14 20:42:48.912093.912093 lmp.py:1625]   Expert 21 |    201 | GPU
DEBUG 01-14 20:42:48.912260.912260 lmp.py:1625]   Expert 17 |    204 | GPU
DEBUG 01-14 20:42:48.912949.912949 lmp.py:1625]   Expert 49 |    211 | GPU
DEBUG 01-14 20:42:48.912115.912115 lmp.py:1625]   Expert 59 |    213 | GPU
DEBUG 01-14 20:42:48.912758.912758 lmp.py:1625]   Expert 63 |    222 | GPU
DEBUG 01-14 20:42:48.912878.912878 lmp.py:1625]   Expert  0 |    226 | GPU
DEBUG 01-14 20:42:48.912805.912805 lmp.py:1625]   Expert 34 |    239 | GPU
DEBUG 01-14 20:42:48.912495.912495 lmp.py:1625]   Expert 37 |    244 | GPU
DEBUG 01-14 20:42:48.912422.912422 lmp.py:1625]   Expert 42 |    246 | GPU
DEBUG 01-14 20:42:48.912112.912112 lmp.py:1625]   Expert 22 |    253 | GPU
DEBUG 01-14 20:42:48.912530.912530 lmp.py:1625]   Expert 19 |    255 | GPU
DEBUG 01-14 20:42:48.912365.912365 lmp.py:1625]   Expert 24 |    274 | GPU
DEBUG 01-14 20:42:48.912770.912770 lmp.py:1625]   Expert 61 |    280 | GPU
DEBUG 01-14 20:42:48.912936.912936 lmp.py:1625]   Expert 30 |    316 | GPU
DEBUG 01-14 20:42:48.912863.912863 lmp.py:1625]   Expert 47 |    324 | GPU
DEBUG 01-14 20:42:48.912553.912553 lmp.py:1625]   Expert 38 |    377 | GPU
DEBUG 01-14 20:42:48.912480.912480 lmp.py:1625]   Expert 26 |    395 | GPU
DEBUG 01-14 20:42:48.912647.912647 lmp.py:1625]   Expert 12 |    405 | GPU
DEBUG 01-14 20:42:48.912813.912813 lmp.py:1625]   Expert 23 |    593 | GPU
DEBUG 01-14 20:42:48.912979.912979 lmp.py:1625]   Expert  9 |    692 | GPU
DEBUG 01-14 20:42:48.912052.912052 lmp.py:1626] 
DEBUG 01-14 20:42:48.912052.912052 lmp.py:1626]   CPU total tokens: 3923 (31.9%)
DEBUG 01-14 20:42:48.912126.912126 lmp.py:1627]   GPU total tokens: 8365 (68.1%)
DEBUG 01-14 20:42:48.912729.912729 cuda_h.py:19] end experts_map_get cost 0.0016405582427978516 seconds
DEBUG 01-14 20:42:48.912824.912824 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-14 20:42:48.912674.912674 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-14 20:42:48.912248.912248 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-14 20:42:48.913915.913915 cuda_h.py:19] end allocate_cuda_memory cost 0.00028228759765625 seconds
DEBUG 01-14 20:42:48.913195.913195 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-14 20:42:48.913143.913143 sllm_store_c.py:27] get device uuid map
DEBUG 01-14 20:42:48.913197.913197 sllm_store_c.py:29] call client load into gpu
DEBUG 01-14 20:42:48.913847.913847 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 38a82409-3bfc-4821-9137-6a0ba2e7f7a1
DEBUG 01-14 20:42:48.913443.913443 client.py:106] call stub.LoadModelAsync
INFO 01-14 20:42:48.913767.913767 client.py:127] Model loaded
DEBUG 01-14 20:42:48.913550.913550 cuda_h.py:10] start restore2model
DEBUG 01-14 20:42:48.914615.914615 cuda_h.py:19] end restore2model cost 0.0003261566162109375 seconds
DEBUG 01-14 20:42:48.914000.914000 cuda_h.py:19] end sllm_worker_task cost 0.009693622589111328 seconds
INFO 01-14 20:42:48.914442.914442 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 38a82409-3bfc-4821-9137-6a0ba2e7f7a1
DEBUG 01-14 20:42:48.914193.914193 cuda_h.py:19] end load_into_gpu_async cost 0.0010874271392822266 seconds
DEBUG 01-14 20:42:48.914180.914180 cuda_h.py:10] start restore_tensors2
DEBUG 01-14 20:42:48.914360.914360 cuda_h.py:19] end restore_tensors2 cost 0.0003871917724609375 seconds
DEBUG 01-14 20:42:48.914296.914296 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0021195411682128906 seconds
DEBUG 01-14 20:42:48.914681.914681 cuda_h.py:10] start restore2model
DEBUG 01-14 20:42:48.917809.917809 cuda_h.py:19] end restore2model cost 0.0025925636291503906 seconds
DEBUG 01-14 20:42:48.917744.917744 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.0048940181732177734 seconds
DEBUG 01-14 20:42:48.917255.917255 cuda_h.py:10] start gpu_sexperts
DEBUG 01-14 20:42:48.917775.917775 cuda_h.py:19] end gpu_sexperts cost 0.0002818107604980469 seconds
DEBUG 01-14 20:42:48.918221.918221 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-14 20:42:48.918599.918599 lmp.py:1683] 
DEBUG 01-14 20:42:48.918599.918599 lmp.py:1683]   Computing 32 experts on CPU...
DEBUG 01-14 20:42:48.918005.918005 cuda_h.py:19] end cpu_experts_submit cost 5.364418029785156e-05 seconds
DEBUG 01-14 20:42:48.918324.918324 cuda_h.py:10] start experts_func_mgpu_group_pad
DEBUG 01-14 20:42:48.918371.918371 mlpmodule.py:1367]  experts func einsum cost 0.07827210426330566 s
DEBUG 01-14 20:42:48.923049.923049 mlpmodule.py:1460] group tensors cost 0.004608631134033203 s
DEBUG 01-14 20:42:48.924863.924863 cuda_h.py:10] start move_flat_hidden2cpu
DEBUG 01-14 20:42:48.925818.925818 cuda_h.py:19] end experts_func_mgpu_group_pad cost 0.007000923156738281 seconds
DEBUG 01-14 20:42:48.926833.926833 cuda_h.py:10] start gpu_group_list
DEBUG 01-14 20:42:48.926161.926161 cuda_h.py:19] end gpu_group_list cost 0.00043463706970214844 seconds
DEBUG 01-14 20:42:48.927684.927684 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-14 20:42:48.927435.927435 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 1.7881393432617188e-05 seconds
DEBUG 01-14 20:42:48.927483.927483 cuda_h.py:10] start wait_experts
INFO 01-14 20:42:48.927285.927285 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 38a82409-3bfc-4821-9137-6a0ba2e7f7a1
DEBUG 01-14 20:42:48.930507.930507 cuda_h.py:19] end move_flat_hidden2cpu cost 0.006101846694946289 seconds
DEBUG 01-14 20:42:48.932337.932337 mlpmodule.py:1533] pad cost 0.001745462417602539 s
DEBUG 01-14 20:42:48.932314.932314 mlpmodule.py:1539] create cpu tensor cost 3.981590270996094e-05 s
DEBUG 01-14 20:42:48.934651.934651 mlpmodule.py:1544] move to cpu cost 0.0018939971923828125 s
DEBUG 01-14 20:42:48.943572.943572 mlpmodule.py:1558] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-14 20:42:48.944413.944413 mlpmodule.py:1559] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-14 20:42:48.944345.944345 mlpmodule.py:1564] group_w3 first element: 0.01263427734375
WARNING 01-14 20:42:48.944441.944441 mlpmodule.py:1574] start einsum2
DEBUG 01-14 20:42:48.961330.961330 mlpmodule.py:1584] group einsum cost 0.026544809341430664 s
DEBUG 01-14 20:42:48.961282.961282 mlpmodule.py:1593] cpy2cputensor cost 0.0007317066192626953 s
DEBUG 01-14 20:42:48.962436.962436 cuda_h.py:10] start move_outputs
DEBUG 01-14 20:42:48.964636.964636 cuda_h.py:19] end move_outputs cost 0.0027801990509033203 seconds
INFO 01-14 20:42:48.971080.971080 client.py:127] Model loaded
DEBUG 01-14 20:42:48.971795.971795 cuda_h.py:19] end wait_experts cost 0.04406881332397461 seconds
DEBUG 01-14 20:42:48.971372.971372 cuda_h.py:10] start gpu_experts
DEBUG 01-14 20:42:48.971526.971526 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-14 20:42:48.971434.971434 cuda_h.py:19] end wait_cetm_experts cost 0.0001838207244873047 seconds
DEBUG 01-14 20:42:48.971906.971906 cuda_h.py:10] start gpu_group_einsum_mp_multi_list
DEBUG 01-14 20:42:48.971285.971285 cuda_h.py:10] start gpu_group_tensor
DEBUG 01-14 20:42:48.972771.972771 cuda_h.py:19] end gpu_group_tensor cost 0.00025463104248046875 seconds
DEBUG 01-14 20:42:48.972226.972226 cuda_h.py:10] start gpu_group_einsum
DEBUG 01-14 20:42:48.972546.972546 cuda_h.py:19] end gpu_group_einsum cost 0.0006041526794433594 seconds
DEBUG 01-14 20:42:48.972113.972113 cuda_h.py:10] start gpu_final_hidden_states_scatter
DEBUG 01-14 20:42:48.973003.973003 cuda_h.py:10] start all_expert_outputs_slices
DEBUG 01-14 20:42:48.973789.973789 cuda_h.py:19] end all_expert_outputs_slices cost 0.000301361083984375 seconds
DEBUG 01-14 20:42:48.973737.973737 cuda_h.py:10] start concat_expert_out
DEBUG 01-14 20:42:48.973389.973389 cuda_h.py:19] end concat_expert_out cost 5.8650970458984375e-05 seconds
DEBUG 01-14 20:42:48.973861.973861 cuda_h.py:10] start index_scatter
DEBUG 01-14 20:42:48.973157.973157 cuda_h.py:19] end index_scatter cost 7.724761962890625e-05 seconds
DEBUG 01-14 20:42:48.973827.973827 cuda_h.py:19] end gpu_final_hidden_states_scatter cost 0.0006923675537109375 seconds
DEBUG 01-14 20:42:48.973393.973393 cuda_h.py:19] end gpu_experts cost 0.0023736953735351562 seconds
DEBUG 01-14 20:42:48.973434.973434 cuda_h.py:10] start all_expert_weight_slices
DEBUG 01-14 20:42:48.974130.974130 cuda_h.py:19] end all_expert_weight_slices cost 0.0009729862213134766 seconds
DEBUG 01-14 20:42:48.974105.974105 cuda_h.py:10] start cpuoutputsdeal
DEBUG 01-14 20:42:48.975967.975967 cuda_h.py:10] start index_scatter
DEBUG 01-14 20:42:48.975103.975103 cuda_h.py:19] end index_scatter cost 4.9591064453125e-05 seconds
DEBUG 01-14 20:42:48.975058.975058 cuda_h.py:19] end cpuoutputsdeal cost 0.0005333423614501953 seconds
DEBUG 01-14 20:42:48.975252.975252 cuda_h.py:19] end layer_moe_generate_mp_l_8 cost 0.06532573699951172 seconds
DEBUG 01-14 20:42:48.975106.975106 cuda_h.py:19] end prefill_layer cost 0.07185673713684082 seconds
DEBUG 01-14 20:42:48.975916.975916 lmp.py:1551] -------------------------------- end prefill layer 7 --------------------------------
DEBUG 01-14 20:42:48.975334.975334 cuda_h.py:10] start prefill_layer
DEBUG 01-14 20:42:48.976229.976229 lmp.py:1494] -------------------------------- start prefill layer 8 --------------------------------
DEBUG 01-14 20:42:48.976363.976363 cuda_h.py:10] start start_load_qkvogn_s_weight_l_9
DEBUG 01-14 20:42:48.976688.976688 cuda_h.py:10] start start_load_qkvogn_s_weight_l_9
DEBUG 01-14 20:42:48.976929.976929 cuda_h.py:19] end start_load_qkvogn_s_weight_l_9 cost 4.458427429199219e-05 seconds
DEBUG 01-14 20:42:48.976208.976208 cuda_h.py:19] end start_load_qkvogn_s_weight_l_9 cost 7.82012939453125e-05 seconds
DEBUG 01-14 20:42:48.976096.976096 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-14 20:42:48.976754.976754 cuda_h.py:10] start sllm_worker_task
DEBUG 01-14 20:42:48.976592.976592 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-14 20:42:48.976858.976858 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-14 20:42:48.979052.979052 cuda_h.py:19] end allocate_cuda_memory cost 0.0027647018432617188 seconds
DEBUG 01-14 20:42:48.979486.979486 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-14 20:42:48.979985.979985 sllm_store_c.py:27] get device uuid map
DEBUG 01-14 20:42:48.979020.979020 sllm_store_c.py:29] call client load into gpu
DEBUG 01-14 20:42:48.979213.979213 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, bc4dfe75-73c0-4099-ad2d-df962c52ef7d
DEBUG 01-14 20:42:48.979064.979064 client.py:106] call stub.LoadModelAsync
DEBUG 01-14 20:42:48.979330.979330 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-14 20:42:48.980298.980298 cuda_h.py:10] start self_attn
INFO 01-14 20:42:48.980277.980277 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, bc4dfe75-73c0-4099-ad2d-df962c52ef7d
DEBUG 01-14 20:42:48.980988.980988 cuda_h.py:19] end load_into_gpu_async cost 0.001302480697631836 seconds
DEBUG 01-14 20:42:48.980082.980082 cuda_h.py:10] start restore_tensors2
DEBUG 01-14 20:42:48.980295.980295 cuda_h.py:19] end restore_tensors2 cost 0.00018668174743652344 seconds
DEBUG 01-14 20:42:48.981615.981615 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0046215057373046875 seconds
INFO 01-14 20:42:48.981599.981599 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, bc4dfe75-73c0-4099-ad2d-df962c52ef7d
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-14 20:42:48.984396.984396 cuda_h.py:19] end self_attn cost 0.0044171810150146484 seconds
DEBUG 01-14 20:42:48.985236.985236 cuda_h.py:19] end iln_self_attn_paln cost 0.008880615234375 seconds
DEBUG 01-14 20:42:48.985961.985961 cuda_h.py:10] start layer_moe_generate_mp_l_9
DEBUG 01-14 20:42:48.985598.985598 cuda_h.py:10] start gate
DEBUG 01-14 20:42:48.985994.985994 mlpmodule.py:1367]  experts func einsum cost 0.06626176834106445 s
DEBUG 01-14 20:42:48.986808.986808 cuda_h.py:19] end gate cost 0.0008692741394042969 seconds
DEBUG 01-14 20:42:48.986328.986328 cuda_h.py:10] start experts_map_get
DEBUG 01-14 20:42:48.986301.986301 lmp.py:1615] 
DEBUG 01-14 20:42:48.986301.986301 lmp.py:1615] Expert Token Distribution & Device Allocation:
DEBUG 01-14 20:42:48.986694.986694 lmp.py:1616]   Total experts: 64
DEBUG 01-14 20:42:48.986702.986702 lmp.py:1617]   CPU experts: 32 (50%)
DEBUG 01-14 20:42:48.986881.986881 lmp.py:1618]   GPU experts: 32 (50%)
DEBUG 01-14 20:42:48.986246.986246 lmp.py:1619] 
DEBUG 01-14 20:42:48.986246.986246 lmp.py:1619]   Expert ID | Tokens | Device
DEBUG 01-14 20:42:48.986850.986850 lmp.py:1620]   -----------------------------------
DEBUG 01-14 20:42:48.986407.986407 lmp.py:1625]   Expert 38 |     20 | CPU
DEBUG 01-14 20:42:48.986295.986295 lmp.py:1625]   Expert 39 |     62 | CPU
DEBUG 01-14 20:42:48.986945.986945 lmp.py:1625]   Expert 30 |     67 | CPU
DEBUG 01-14 20:42:48.986787.986787 lmp.py:1625]   Expert 59 |     72 | CPU
DEBUG 01-14 20:42:48.986390.986390 lmp.py:1625]   Expert  7 |     80 | CPU
DEBUG 01-14 20:42:48.986040.986040 lmp.py:1625]   Expert 36 |     89 | CPU
DEBUG 01-14 20:42:48.986928.986928 lmp.py:1625]   Expert 24 |     94 | CPU
DEBUG 01-14 20:42:48.987101.987101 lmp.py:1625]   Expert 40 |     97 | CPU
DEBUG 01-14 20:42:48.987274.987274 lmp.py:1625]   Expert 27 |     98 | CPU
DEBUG 01-14 20:42:48.987924.987924 lmp.py:1625]   Expert 17 |     99 | CPU
DEBUG 01-14 20:42:48.987858.987858 lmp.py:1625]   Expert 14 |    102 | CPU
DEBUG 01-14 20:42:48.987746.987746 lmp.py:1625]   Expert 12 |    103 | CPU
DEBUG 01-14 20:42:48.987158.987158 lmp.py:1625]   Expert  1 |    108 | CPU
DEBUG 01-14 20:42:48.987569.987569 lmp.py:1625]   Expert 18 |    108 | CPU
DEBUG 01-14 20:42:48.987742.987742 lmp.py:1625]   Expert  6 |    114 | CPU
DEBUG 01-14 20:42:48.987915.987915 lmp.py:1625]   Expert 16 |    118 | CPU
DEBUG 01-14 20:42:48.987373.987373 lmp.py:1625]   Expert 48 |    124 | CPU
DEBUG 01-14 20:42:48.987069.987069 lmp.py:1625]   Expert 32 |    128 | CPU
DEBUG 01-14 20:42:48.987672.987672 lmp.py:1625]   Expert 51 |    142 | CPU
DEBUG 01-14 20:42:48.987037.987037 lmp.py:1625]   Expert 44 |    147 | CPU
DEBUG 01-14 20:42:48.987687.987687 lmp.py:1625]   Expert  0 |    148 | CPU
DEBUG 01-14 20:42:48.987860.987860 lmp.py:1625]   Expert 53 |    156 | CPU
DEBUG 01-14 20:42:48.987794.987794 lmp.py:1625]   Expert  8 |    161 | CPU
DEBUG 01-14 20:42:48.987444.987444 lmp.py:1625]   Expert 35 |    163 | CPU
DEBUG 01-14 20:42:48.987332.987332 lmp.py:1625]   Expert 22 |    165 | CPU
DEBUG 01-14 20:42:48.987267.987267 lmp.py:1625]   Expert 42 |    167 | CPU
DEBUG 01-14 20:42:48.987440.987440 lmp.py:1625]   Expert 60 |    170 | CPU
DEBUG 01-14 20:42:48.987136.987136 lmp.py:1625]   Expert 34 |    179 | CPU
DEBUG 01-14 20:42:48.987501.987501 lmp.py:1625]   Expert 33 |    186 | CPU
DEBUG 01-14 20:42:48.987389.987389 lmp.py:1625]   Expert 29 |    187 | CPU
DEBUG 01-14 20:42:48.987800.987800 lmp.py:1625]   Expert 45 |    190 | CPU
DEBUG 01-14 20:42:48.987497.987497 lmp.py:1625]   Expert 47 |    190 | CPU
DEBUG 01-14 20:42:48.987193.987193 lmp.py:1625]   Expert 19 |    191 | GPU
DEBUG 01-14 20:42:48.987889.987889 lmp.py:1625]   Expert 54 |    192 | GPU
DEBUG 01-14 20:42:48.987346.987346 lmp.py:1625]   Expert 49 |    193 | GPU
DEBUG 01-14 20:42:48.987996.987996 lmp.py:1625]   Expert 15 |    195 | GPU
DEBUG 01-14 20:42:48.987884.987884 lmp.py:1625]   Expert 28 |    202 | GPU
DEBUG 01-14 20:42:48.987057.987057 lmp.py:1625]   Expert 56 |    202 | GPU
DEBUG 01-14 20:42:48.987529.987529 lmp.py:1625]   Expert  9 |    203 | GPU
DEBUG 01-14 20:42:48.987979.987979 lmp.py:1625]   Expert 21 |    205 | GPU
DEBUG 01-14 20:42:48.987953.987953 lmp.py:1625]   Expert  3 |    209 | GPU
DEBUG 01-14 20:42:48.987166.987166 lmp.py:1625]   Expert 13 |    209 | GPU
DEBUG 01-14 20:42:48.987378.987378 lmp.py:1625]   Expert 10 |    211 | GPU
DEBUG 01-14 20:42:48.987021.987021 lmp.py:1625]   Expert 20 |    212 | GPU
DEBUG 01-14 20:42:48.987426.987426 lmp.py:1625]   Expert 41 |    215 | GPU
DEBUG 01-14 20:42:48.987307.987307 lmp.py:1625]   Expert 46 |    218 | GPU
DEBUG 01-14 20:42:48.987189.987189 lmp.py:1625]   Expert 57 |    219 | GPU
DEBUG 01-14 20:42:48.987832.987832 lmp.py:1625]   Expert  4 |    221 | GPU
DEBUG 01-14 20:42:48.987998.987998 lmp.py:1625]   Expert 43 |    223 | GPU
DEBUG 01-14 20:42:48.987164.987164 lmp.py:1625]   Expert  2 |    231 | GPU
DEBUG 01-14 20:42:48.987330.987330 lmp.py:1625]   Expert 63 |    231 | GPU
DEBUG 01-14 20:42:48.987543.987543 lmp.py:1625]   Expert 37 |    234 | GPU
DEBUG 01-14 20:42:48.987278.987278 lmp.py:1625]   Expert 50 |    252 | GPU
DEBUG 01-14 20:42:48.987491.987491 lmp.py:1625]   Expert 61 |    265 | GPU
DEBUG 01-14 20:42:48.987465.987465 lmp.py:1625]   Expert 26 |    267 | GPU
DEBUG 01-14 20:42:48.988075.988075 lmp.py:1625]   Expert 31 |    280 | GPU
DEBUG 01-14 20:42:48.988433.988433 lmp.py:1625]   Expert 58 |    285 | GPU
DEBUG 01-14 20:42:48.988599.988599 lmp.py:1625]   Expert 52 |    303 | GPU
DEBUG 01-14 20:42:48.988765.988765 lmp.py:1625]   Expert 62 |    311 | GPU
DEBUG 01-14 20:42:48.988932.988932 lmp.py:1625]   Expert 55 |    342 | GPU
DEBUG 01-14 20:42:48.988336.988336 lmp.py:1625]   Expert 11 |    373 | GPU
DEBUG 01-14 20:42:48.988741.988741 lmp.py:1625]   Expert 23 |    412 | GPU
DEBUG 01-14 20:42:48.988907.988907 lmp.py:1625]   Expert 25 |    430 | GPU
DEBUG 01-14 20:42:48.988073.988073 lmp.py:1625]   Expert  5 |    518 | GPU
DEBUG 01-14 20:42:48.988954.988954 lmp.py:1626] 
DEBUG 01-14 20:42:48.988954.988954 lmp.py:1626]   CPU total tokens: 4034 (32.8%)
DEBUG 01-14 20:42:48.988551.988551 lmp.py:1627]   GPU total tokens: 8254 (67.2%)
DEBUG 01-14 20:42:48.988585.988585 cuda_h.py:19] end experts_map_get cost 0.0019075870513916016 seconds
INFO 01-14 20:42:48.988575.988575 client.py:127] Model loaded
DEBUG 01-14 20:42:48.988982.988982 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-14 20:42:48.988315.988315 cuda_h.py:10] start restore2model
DEBUG 01-14 20:42:48.988510.988510 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-14 20:42:48.989010.989010 cuda_h.py:19] end restore2model cost 0.0006146430969238281 seconds
DEBUG 01-14 20:42:48.989638.989638 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-14 20:42:48.989800.989800 cuda_h.py:19] end sllm_worker_task cost 0.013147115707397461 seconds
DEBUG 01-14 20:42:48.989326.989326 cuda_h.py:19] end allocate_cuda_memory cost 0.00021982192993164062 seconds
DEBUG 01-14 20:42:48.989324.989324 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-14 20:42:48.989987.989987 sllm_store_c.py:27] get device uuid map
DEBUG 01-14 20:42:48.989320.989320 sllm_store_c.py:29] call client load into gpu
DEBUG 01-14 20:42:48.990970.990970 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 4d7b6d3b-f8f3-460f-9b7b-e753c6bb88e6
DEBUG 01-14 20:42:48.990612.990612 client.py:106] call stub.LoadModelAsync
INFO 01-14 20:42:48.991822.991822 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 4d7b6d3b-f8f3-460f-9b7b-e753c6bb88e6
DEBUG 01-14 20:42:48.991943.991943 cuda_h.py:19] end load_into_gpu_async cost 0.0016505718231201172 seconds
DEBUG 01-14 20:42:48.991216.991216 cuda_h.py:10] start restore_tensors2
DEBUG 01-14 20:42:48.992713.992713 cuda_h.py:19] end restore_tensors2 cost 0.00037479400634765625 seconds
DEBUG 01-14 20:42:48.992503.992503 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.00279998779296875 seconds
DEBUG 01-14 20:42:48.992458.992458 cuda_h.py:10] start restore2model
DEBUG 01-14 20:42:48.994896.994896 cuda_h.py:19] end restore2model cost 0.0025763511657714844 seconds
DEBUG 01-14 20:42:48.994116.994116 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.006276130676269531 seconds
DEBUG 01-14 20:42:48.994958.994958 cuda_h.py:10] start gpu_sexperts
DEBUG 01-14 20:42:48.995353.995353 cuda_h.py:19] end gpu_sexperts cost 0.0002963542938232422 seconds
DEBUG 01-14 20:42:48.995798.995798 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-14 20:42:48.995932.995932 lmp.py:1683] 
DEBUG 01-14 20:42:48.995932.995932 lmp.py:1683]   Computing 32 experts on CPU...
DEBUG 01-14 20:42:48.995060.995060 cuda_h.py:19] end cpu_experts_submit cost 5.841255187988281e-05 seconds
DEBUG 01-14 20:42:48.995908.995908 cuda_h.py:10] start experts_func_mgpu_group_pad
DEBUG 01-14 20:42:49.005378.005378 mlpmodule.py:1460] group tensors cost 0.009655952453613281 s
DEBUG 01-14 20:42:49.006466.006466 cuda_h.py:10] start move_flat_hidden2cpu
DEBUG 01-14 20:42:49.010383.010383 cuda_h.py:19] end experts_func_mgpu_group_pad cost 0.015308856964111328 seconds
DEBUG 01-14 20:42:49.012341.012341 cuda_h.py:19] end move_flat_hidden2cpu cost 0.006864070892333984 seconds
DEBUG 01-14 20:42:49.014864.014864 cuda_h.py:10] start gpu_group_list
DEBUG 01-14 20:42:49.015144.015144 cuda_h.py:19] end gpu_group_list cost 0.0009999275207519531 seconds
DEBUG 01-14 20:42:49.015985.015985 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-14 20:42:49.015554.015554 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 3.933906555175781e-05 seconds
DEBUG 01-14 20:42:49.016233.016233 cuda_h.py:10] start wait_experts
INFO 01-14 20:42:49.016865.016865 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 4d7b6d3b-f8f3-460f-9b7b-e753c6bb88e6
DEBUG 01-14 20:42:49.017289.017289 mlpmodule.py:1533] pad cost 0.004058837890625 s
DEBUG 01-14 20:42:49.017266.017266 mlpmodule.py:1539] create cpu tensor cost 3.790855407714844e-05 s
DEBUG 01-14 20:42:49.019640.019640 mlpmodule.py:1544] move to cpu cost 0.0022394657135009766 s
DEBUG 01-14 20:42:49.029686.029686 mlpmodule.py:1558] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-14 20:42:49.029095.029095 mlpmodule.py:1559] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-14 20:42:49.029409.029409 mlpmodule.py:1564] group_w3 first element: 0.0859375
WARNING 01-14 20:42:49.029202.029202 mlpmodule.py:1574] start einsum2
INFO 01-14 20:42:49.046983.046983 client.py:127] Model loaded
DEBUG 01-14 20:42:49.046274.046274 cuda_h.py:19] end wait_experts cost 0.030590534210205078 seconds
DEBUG 01-14 20:42:49.046374.046374 cuda_h.py:10] start gpu_experts
DEBUG 01-14 20:42:49.046244.046244 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-14 20:42:49.047901.047901 mlpmodule.py:1584] group einsum cost 0.02767801284790039 s
DEBUG 01-14 20:42:49.048195.048195 mlpmodule.py:1593] cpy2cputensor cost 0.0006997585296630859 s
DEBUG 01-14 20:42:49.048071.048071 cuda_h.py:10] start move_outputs
DEBUG 01-14 20:42:49.050033.050033 cuda_h.py:19] end move_outputs cost 0.002185344696044922 seconds
DEBUG 01-14 20:42:49.054983.054983 cuda_h.py:19] end wait_cetm_experts cost 0.007189512252807617 seconds
DEBUG 01-14 20:42:49.054478.054478 cuda_h.py:10] start gpu_group_einsum_mp_multi_list
DEBUG 01-14 20:42:49.054294.054294 cuda_h.py:10] start gpu_group_tensor
DEBUG 01-14 20:42:49.054297.054297 cuda_h.py:19] end gpu_group_tensor cost 0.0002484321594238281 seconds
DEBUG 01-14 20:42:49.054659.054659 cuda_h.py:10] start gpu_group_einsum
DEBUG 01-14 20:42:49.055137.055137 cuda_h.py:19] end gpu_group_einsum cost 0.0005824565887451172 seconds
DEBUG 01-14 20:42:49.055221.055221 cuda_h.py:10] start gpu_final_hidden_states_scatter
DEBUG 01-14 20:42:49.055395.055395 cuda_h.py:10] start all_expert_outputs_slices
DEBUG 01-14 20:42:49.055704.055704 cuda_h.py:19] end all_expert_outputs_slices cost 0.00030112266540527344 seconds
DEBUG 01-14 20:42:49.055606.055606 cuda_h.py:10] start concat_expert_out
DEBUG 01-14 20:42:49.055304.055304 cuda_h.py:19] end concat_expert_out cost 5.7697296142578125e-05 seconds
DEBUG 01-14 20:42:49.056823.056823 cuda_h.py:10] start index_scatter
DEBUG 01-14 20:42:49.056973.056973 cuda_h.py:19] end index_scatter cost 7.557868957519531e-05 seconds
DEBUG 01-14 20:42:49.056259.056259 cuda_h.py:19] end gpu_final_hidden_states_scatter cost 0.0006871223449707031 seconds
DEBUG 01-14 20:42:49.056798.056798 cuda_h.py:19] end gpu_experts cost 0.00944662094116211 seconds
DEBUG 01-14 20:42:49.056931.056931 cuda_h.py:10] start all_expert_weight_slices
DEBUG 01-14 20:42:49.057537.057537 cuda_h.py:19] end all_expert_weight_slices cost 0.0010447502136230469 seconds
DEBUG 01-14 20:42:49.057042.057042 cuda_h.py:10] start cpuoutputsdeal
DEBUG 01-14 20:42:49.057255.057255 cuda_h.py:10] start index_scatter
DEBUG 01-14 20:42:49.057683.057683 cuda_h.py:19] end index_scatter cost 4.982948303222656e-05 seconds
DEBUG 01-14 20:42:49.058783.058783 cuda_h.py:19] end cpuoutputsdeal cost 0.0005514621734619141 seconds
DEBUG 01-14 20:42:49.058170.058170 cuda_h.py:19] end layer_moe_generate_mp_l_9 cost 0.07286381721496582 seconds
DEBUG 01-14 20:42:49.058448.058448 cuda_h.py:19] end prefill_layer cost 0.08246040344238281 seconds
DEBUG 01-14 20:42:49.058536.058536 lmp.py:1551] -------------------------------- end prefill layer 8 --------------------------------
DEBUG 01-14 20:42:49.058000.058000 cuda_h.py:10] start prefill_layer
DEBUG 01-14 20:42:49.058703.058703 lmp.py:1494] -------------------------------- start prefill layer 9 --------------------------------
DEBUG 01-14 20:42:49.058883.058883 cuda_h.py:10] start start_load_qkvogn_s_weight_l_10
DEBUG 01-14 20:42:49.058970.058970 cuda_h.py:10] start start_load_qkvogn_s_weight_l_10
DEBUG 01-14 20:42:49.058058.058058 cuda_h.py:19] end start_load_qkvogn_s_weight_l_10 cost 3.695487976074219e-05 seconds
DEBUG 01-14 20:42:49.058529.058529 cuda_h.py:19] end start_load_qkvogn_s_weight_l_10 cost 7.104873657226562e-05 seconds
DEBUG 01-14 20:42:49.058133.058133 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-14 20:42:49.058679.058679 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-14 20:42:49.058635.058635 cuda_h.py:10] start sllm_worker_task
DEBUG 01-14 20:42:49.059269.059269 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-14 20:42:49.059258.059258 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-14 20:42:49.060128.060128 cuda_h.py:19] end allocate_cuda_memory cost 0.0010213851928710938 seconds
DEBUG 01-14 20:42:49.060607.060607 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-14 20:42:49.060231.060231 sllm_store_c.py:27] get device uuid map
DEBUG 01-14 20:42:49.060452.060452 sllm_store_c.py:29] call client load into gpu
DEBUG 01-14 20:42:49.060851.060851 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 940287b4-fbb1-437a-ae53-726fef82b21a
DEBUG 01-14 20:42:49.060132.060132 client.py:106] call stub.LoadModelAsync
DEBUG 01-14 20:42:49.060534.060534 cuda_h.py:10] start self_attn
INFO 01-14 20:42:49.061724.061724 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 940287b4-fbb1-437a-ae53-726fef82b21a
DEBUG 01-14 20:42:49.061044.061044 cuda_h.py:19] end load_into_gpu_async cost 0.0011243820190429688 seconds
DEBUG 01-14 20:42:49.061608.061608 cuda_h.py:10] start restore_tensors2
DEBUG 01-14 20:42:49.061194.061194 cuda_h.py:19] end restore_tensors2 cost 8.58306884765625e-05 seconds
DEBUG 01-14 20:42:49.061526.061526 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0025048255920410156 seconds
INFO 01-14 20:42:49.061542.061542 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 940287b4-fbb1-437a-ae53-726fef82b21a
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-14 20:42:49.064768.064768 cuda_h.py:19] end self_attn cost 0.003152132034301758 seconds
DEBUG 01-14 20:42:49.064461.064461 cuda_h.py:19] end iln_self_attn_paln cost 0.0056149959564208984 seconds
DEBUG 01-14 20:42:49.064019.064019 cuda_h.py:10] start layer_moe_generate_mp_l_10
DEBUG 01-14 20:42:49.064590.064590 cuda_h.py:10] start gate
DEBUG 01-14 20:42:49.065567.065567 cuda_h.py:19] end gate cost 0.0006504058837890625 seconds
DEBUG 01-14 20:42:49.065304.065304 cuda_h.py:10] start experts_map_get
DEBUG 01-14 20:42:49.065493.065493 lmp.py:1615] 
DEBUG 01-14 20:42:49.065493.065493 lmp.py:1615] Expert Token Distribution & Device Allocation:
DEBUG 01-14 20:42:49.065726.065726 lmp.py:1616]   Total experts: 64
DEBUG 01-14 20:42:49.065091.065091 lmp.py:1617]   CPU experts: 32 (50%)
DEBUG 01-14 20:42:49.065264.065264 lmp.py:1618]   GPU experts: 32 (50%)
DEBUG 01-14 20:42:49.065529.065529 lmp.py:1619] 
DEBUG 01-14 20:42:49.065529.065529 lmp.py:1619]   Expert ID | Tokens | Device
DEBUG 01-14 20:42:49.065172.065172 lmp.py:1620]   -----------------------------------
DEBUG 01-14 20:42:49.065007.065007 lmp.py:1625]   Expert 24 |     40 | CPU
DEBUG 01-14 20:42:49.065412.065412 lmp.py:1625]   Expert  2 |     41 | CPU
DEBUG 01-14 20:42:49.065340.065340 lmp.py:1625]   Expert 32 |     70 | CPU
DEBUG 01-14 20:42:49.065791.065791 lmp.py:1625]   Expert 19 |     72 | CPU
DEBUG 01-14 20:42:49.065241.065241 lmp.py:1625]   Expert 26 |     73 | CPU
DEBUG 01-14 20:42:49.065931.065931 lmp.py:1625]   Expert 23 |     74 | CPU
DEBUG 01-14 20:42:49.065620.065620 lmp.py:1625]   Expert  4 |     77 | CPU
DEBUG 01-14 20:42:49.065786.065786 lmp.py:1625]   Expert 50 |     78 | CPU
DEBUG 01-14 20:42:49.065237.065237 lmp.py:1625]   Expert 59 |     79 | CPU
DEBUG 01-14 20:42:49.065688.065688 lmp.py:1625]   Expert 60 |     88 | CPU
DEBUG 01-14 20:42:49.065662.065662 lmp.py:1625]   Expert 28 |     93 | CPU
DEBUG 01-14 20:42:49.065113.065113 lmp.py:1625]   Expert  7 |    100 | CPU
DEBUG 01-14 20:42:49.065802.065802 lmp.py:1625]   Expert 15 |    102 | CPU
DEBUG 01-14 20:42:49.065253.065253 lmp.py:1625]   Expert 49 |    104 | CPU
DEBUG 01-14 20:42:49.065465.065465 lmp.py:1625]   Expert 27 |    106 | CPU
DEBUG 01-14 20:42:49.065632.065632 lmp.py:1625]   Expert 10 |    111 | CPU
DEBUG 01-14 20:42:49.065321.065321 lmp.py:1625]   Expert 12 |    114 | CPU
DEBUG 01-14 20:42:49.065772.065772 lmp.py:1625]   Expert  5 |    125 | CPU
DEBUG 01-14 20:42:49.066223.066223 lmp.py:1625]   Expert  3 |    126 | CPU
DEBUG 01-14 20:42:49.066197.066197 lmp.py:1625]   Expert 20 |    131 | CPU
DEBUG 01-14 20:42:49.066648.066648 lmp.py:1625]   Expert 13 |    133 | CPU
DEBUG 01-14 20:42:49.066098.066098 lmp.py:1625]   Expert 41 |    135 | CPU
DEBUG 01-14 20:42:49.066073.066073 lmp.py:1625]   Expert 25 |    137 | CPU
DEBUG 01-14 20:42:49.066861.066861 lmp.py:1625]   Expert 35 |    142 | CPU
DEBUG 01-14 20:42:49.066551.066551 lmp.py:1625]   Expert 37 |    146 | CPU
DEBUG 01-14 20:42:49.066001.066001 lmp.py:1625]   Expert 40 |    146 | CPU
DEBUG 01-14 20:42:49.066214.066214 lmp.py:1625]   Expert 17 |    159 | CPU
DEBUG 01-14 20:42:49.066903.066903 lmp.py:1625]   Expert 22 |    161 | CPU
DEBUG 01-14 20:42:49.066069.066069 lmp.py:1625]   Expert 36 |    162 | CPU
DEBUG 01-14 20:42:49.066759.066759 lmp.py:1625]   Expert 53 |    168 | CPU
DEBUG 01-14 20:42:49.066733.066733 lmp.py:1625]   Expert 47 |    171 | CPU
DEBUG 01-14 20:42:49.066184.066184 lmp.py:1625]   Expert 16 |    176 | CPU
DEBUG 01-14 20:42:49.066396.066396 lmp.py:1625]   Expert 52 |    176 | GPU
DEBUG 01-14 20:42:49.066085.066085 lmp.py:1625]   Expert 58 |    176 | GPU
DEBUG 01-14 20:42:49.066298.066298 lmp.py:1625]   Expert 44 |    180 | GPU
DEBUG 01-14 20:42:49.066749.066749 lmp.py:1625]   Expert 18 |    185 | GPU
DEBUG 01-14 20:42:49.066961.066961 lmp.py:1625]   Expert 39 |    190 | GPU
DEBUG 01-14 20:42:49.066889.066889 lmp.py:1625]   Expert 48 |    194 | GPU
DEBUG 01-14 20:42:49.066101.066101 lmp.py:1625]   Expert 30 |    199 | GPU
DEBUG 01-14 20:42:49.066552.066552 lmp.py:1625]   Expert 38 |    201 | GPU
DEBUG 01-14 20:42:49.066765.066765 lmp.py:1625]   Expert 11 |    203 | GPU
DEBUG 01-14 20:42:49.066739.066739 lmp.py:1625]   Expert 45 |    205 | GPU
DEBUG 01-14 20:42:49.066474.066474 lmp.py:1625]   Expert 62 |    211 | GPU
DEBUG 01-14 20:42:49.066687.066687 lmp.py:1625]   Expert 29 |    215 | GPU
DEBUG 01-14 20:42:49.066476.066476 lmp.py:1625]   Expert  1 |    217 | GPU
DEBUG 01-14 20:42:49.066119.066119 lmp.py:1625]   Expert 51 |    223 | GPU
DEBUG 01-14 20:42:49.066046.066046 lmp.py:1625]   Expert 14 |    235 | GPU
DEBUG 01-14 20:42:49.066497.066497 lmp.py:1625]   Expert 31 |    246 | GPU
DEBUG 01-14 20:42:49.066233.066233 lmp.py:1625]   Expert 34 |    256 | GPU
DEBUG 01-14 20:42:49.066445.066445 lmp.py:1625]   Expert  6 |    266 | GPU
DEBUG 01-14 20:42:49.066419.066419 lmp.py:1625]   Expert 43 |    271 | GPU
DEBUG 01-14 20:42:49.066393.066393 lmp.py:1625]   Expert 61 |    274 | GPU
DEBUG 01-14 20:42:49.066606.066606 lmp.py:1625]   Expert 42 |    289 | GPU
DEBUG 01-14 20:42:49.066341.066341 lmp.py:1625]   Expert 33 |    292 | GPU
DEBUG 01-14 20:42:49.066792.066792 lmp.py:1625]   Expert  0 |    296 | GPU
DEBUG 01-14 20:42:49.066243.066243 lmp.py:1625]   Expert 56 |    298 | GPU
DEBUG 01-14 20:42:49.066694.066694 lmp.py:1625]   Expert 57 |    308 | GPU
DEBUG 01-14 20:42:49.066668.066668 lmp.py:1625]   Expert 46 |    321 | GPU
DEBUG 01-14 20:42:49.066742.066742 lmp.py:1625]   Expert 54 |    367 | GPU
DEBUG 01-14 20:42:49.066815.066815 lmp.py:1625]   Expert  9 |    396 | GPU
DEBUG 01-14 20:42:49.066889.066889 lmp.py:1625]   Expert 63 |    413 | GPU
DEBUG 01-14 20:42:49.066485.066485 lmp.py:1625]   Expert  8 |    422 | GPU
DEBUG 01-14 20:42:49.066082.066082 lmp.py:1625]   Expert 55 |    459 | GPU
DEBUG 01-14 20:42:49.066109.066109 lmp.py:1625]   Expert 21 |    464 | GPU
DEBUG 01-14 20:42:49.066136.066136 lmp.py:1626] 
DEBUG 01-14 20:42:49.066136.066136 lmp.py:1626]   CPU total tokens: 3640 (29.6%)
DEBUG 01-14 20:42:49.066163.066163 lmp.py:1627]   GPU total tokens: 8648 (70.4%)
DEBUG 01-14 20:42:49.066720.066720 cuda_h.py:19] end experts_map_get cost 0.0015425682067871094 seconds
DEBUG 01-14 20:42:49.066345.066345 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-14 20:42:49.066156.066156 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-14 20:42:49.067220.067220 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-14 20:42:49.068280.068280 cuda_h.py:19] end allocate_cuda_memory cost 0.0017273426055908203 seconds
DEBUG 01-14 20:42:49.068467.068467 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-14 20:42:49.068654.068654 sllm_store_c.py:27] get device uuid map
DEBUG 01-14 20:42:49.069231.069231 sllm_store_c.py:29] call client load into gpu
DEBUG 01-14 20:42:49.069742.069742 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 5c3b5a79-383b-4264-8a67-914d8ad422d0
DEBUG 01-14 20:42:49.069292.069292 client.py:106] call stub.LoadModelAsync
INFO 01-14 20:42:49.069106.069106 client.py:127] Model loaded
DEBUG 01-14 20:42:49.069944.069944 cuda_h.py:10] start restore2model
DEBUG 01-14 20:42:49.069216.069216 cuda_h.py:19] end restore2model cost 0.00036978721618652344 seconds
DEBUG 01-14 20:42:49.070900.070900 cuda_h.py:19] end sllm_worker_task cost 0.010939836502075195 seconds
INFO 01-14 20:42:49.070684.070684 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 5c3b5a79-383b-4264-8a67-914d8ad422d0
DEBUG 01-14 20:42:49.070819.070819 cuda_h.py:19] end load_into_gpu_async cost 0.0011720657348632812 seconds
DEBUG 01-14 20:42:49.070522.070522 cuda_h.py:10] start restore_tensors2
DEBUG 01-14 20:42:49.070509.070509 cuda_h.py:19] end restore_tensors2 cost 0.0003845691680908203 seconds
DEBUG 01-14 20:42:49.070352.070352 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0036547183990478516 seconds
DEBUG 01-14 20:42:49.070645.070645 cuda_h.py:10] start restore2model
DEBUG 01-14 20:42:49.073553.073553 cuda_h.py:19] end restore2model cost 0.002570629119873047 seconds
DEBUG 01-14 20:42:49.073542.073542 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.006426095962524414 seconds
DEBUG 01-14 20:42:49.073530.073530 cuda_h.py:10] start gpu_sexperts
DEBUG 01-14 20:42:49.073818.073818 cuda_h.py:19] end gpu_sexperts cost 0.00028705596923828125 seconds
DEBUG 01-14 20:42:49.073608.073608 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-14 20:42:49.073219.073219 lmp.py:1683] 
DEBUG 01-14 20:42:49.073219.073219 lmp.py:1683]   Computing 32 experts on CPU...
DEBUG 01-14 20:42:49.073101.073101 cuda_h.py:19] end cpu_experts_submit cost 5.364418029785156e-05 seconds
DEBUG 01-14 20:42:49.073420.073420 cuda_h.py:10] start experts_func_mgpu_group_pad
DEBUG 01-14 20:42:49.080650.080650 mlpmodule.py:1367]  experts func einsum cost 0.08445477485656738 s
DEBUG 01-14 20:42:49.084166.084166 mlpmodule.py:1460] group tensors cost 0.004313945770263672 s
DEBUG 01-14 20:42:49.085211.085211 cuda_h.py:10] start move_flat_hidden2cpu
DEBUG 01-14 20:42:49.086339.086339 cuda_h.py:19] end experts_func_mgpu_group_pad cost 0.012569665908813477 seconds
DEBUG 01-14 20:42:49.087280.087280 cuda_h.py:10] start gpu_group_list
DEBUG 01-14 20:42:49.088611.088611 cuda_h.py:19] end gpu_group_list cost 0.00048661231994628906 seconds
DEBUG 01-14 20:42:49.088445.088445 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-14 20:42:49.088363.088363 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 3.147125244140625e-05 seconds
DEBUG 01-14 20:42:49.088656.088656 cuda_h.py:10] start wait_experts
INFO 01-14 20:42:49.088842.088842 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 5c3b5a79-383b-4264-8a67-914d8ad422d0
DEBUG 01-14 20:42:49.091114.091114 cuda_h.py:19] end move_flat_hidden2cpu cost 0.005941867828369141 seconds
DEBUG 01-14 20:42:49.093760.093760 mlpmodule.py:1533] pad cost 0.00156402587890625 s
DEBUG 01-14 20:42:49.093426.093426 mlpmodule.py:1539] create cpu tensor cost 3.600120544433594e-05 s
DEBUG 01-14 20:42:49.095245.095245 mlpmodule.py:1544] move to cpu cost 0.0020780563354492188 s
DEBUG 01-14 20:42:49.104177.104177 mlpmodule.py:1558] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-14 20:42:49.104448.104448 mlpmodule.py:1559] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-14 20:42:49.105140.105140 mlpmodule.py:1564] group_w3 first element: 0.0157470703125
WARNING 01-14 20:42:49.105018.105018 mlpmodule.py:1574] start einsum2
DEBUG 01-14 20:42:49.122269.122269 mlpmodule.py:1584] group einsum cost 0.027364253997802734 s
DEBUG 01-14 20:42:49.123611.123611 mlpmodule.py:1593] cpy2cputensor cost 0.0007021427154541016 s
DEBUG 01-14 20:42:49.123249.123249 cuda_h.py:10] start move_outputs
DEBUG 01-14 20:42:49.126943.126943 cuda_h.py:19] end move_outputs cost 0.002515554428100586 seconds
INFO 01-14 20:42:49.127229.127229 client.py:127] Model loaded
DEBUG 01-14 20:42:49.127044.127044 cuda_h.py:19] end wait_experts cost 0.03843426704406738 seconds
DEBUG 01-14 20:42:49.127059.127059 cuda_h.py:10] start gpu_experts
DEBUG 01-14 20:42:49.127881.127881 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-14 20:42:49.130836.130836 cuda_h.py:19] end wait_cetm_experts cost 0.002947092056274414 seconds
DEBUG 01-14 20:42:49.130951.130951 cuda_h.py:10] start gpu_group_einsum_mp_multi_list
DEBUG 01-14 20:42:49.130091.130091 cuda_h.py:10] start gpu_group_tensor
DEBUG 01-14 20:42:49.130055.130055 cuda_h.py:19] end gpu_group_tensor cost 0.00025463104248046875 seconds
DEBUG 01-14 20:42:49.130555.130555 cuda_h.py:10] start gpu_group_einsum
DEBUG 01-14 20:42:49.131417.131417 cuda_h.py:19] end gpu_group_einsum cost 0.0005488395690917969 seconds
DEBUG 01-14 20:42:49.131785.131785 cuda_h.py:10] start gpu_final_hidden_states_scatter
DEBUG 01-14 20:42:49.131767.131767 cuda_h.py:10] start all_expert_outputs_slices
DEBUG 01-14 20:42:49.132891.132891 cuda_h.py:19] end all_expert_outputs_slices cost 0.00030612945556640625 seconds
DEBUG 01-14 20:42:49.132839.132839 cuda_h.py:10] start concat_expert_out
DEBUG 01-14 20:42:49.132154.132154 cuda_h.py:19] end concat_expert_out cost 5.602836608886719e-05 seconds
DEBUG 01-14 20:42:49.132911.132911 cuda_h.py:10] start index_scatter
DEBUG 01-14 20:42:49.132391.132391 cuda_h.py:19] end index_scatter cost 7.534027099609375e-05 seconds
DEBUG 01-14 20:42:49.132723.132723 cuda_h.py:19] end gpu_final_hidden_states_scatter cost 0.0006847381591796875 seconds
DEBUG 01-14 20:42:49.132886.132886 cuda_h.py:19] end gpu_experts cost 0.005107402801513672 seconds
DEBUG 01-14 20:42:49.132258.132258 cuda_h.py:10] start all_expert_weight_slices
DEBUG 01-14 20:42:49.133100.133100 cuda_h.py:19] end all_expert_weight_slices cost 0.0009751319885253906 seconds
DEBUG 01-14 20:42:49.133691.133691 cuda_h.py:10] start cpuoutputsdeal
DEBUG 01-14 20:42:49.134507.134507 cuda_h.py:10] start index_scatter
DEBUG 01-14 20:42:49.134166.134166 cuda_h.py:19] end index_scatter cost 5.125999450683594e-05 seconds
DEBUG 01-14 20:42:49.134796.134796 cuda_h.py:19] end cpuoutputsdeal cost 0.0005388259887695312 seconds
DEBUG 01-14 20:42:49.134282.134282 cuda_h.py:19] end layer_moe_generate_mp_l_10 cost 0.06971955299377441 seconds
DEBUG 01-14 20:42:49.134620.134620 cuda_h.py:19] end prefill_layer cost 0.07602334022521973 seconds
DEBUG 01-14 20:42:49.134861.134861 lmp.py:1551] -------------------------------- end prefill layer 9 --------------------------------
DEBUG 01-14 20:42:49.134040.134040 cuda_h.py:10] start prefill_layer
DEBUG 01-14 20:42:49.134412.134412 lmp.py:1494] -------------------------------- start prefill layer 10 --------------------------------
DEBUG 01-14 20:42:49.134830.134830 cuda_h.py:10] start start_load_qkvogn_s_weight_l_11
DEBUG 01-14 20:42:49.134917.134917 cuda_h.py:10] start start_load_qkvogn_s_weight_l_11
DEBUG 01-14 20:42:49.134482.134482 cuda_h.py:19] end start_load_qkvogn_s_weight_l_11 cost 3.743171691894531e-05 seconds
DEBUG 01-14 20:42:49.134715.134715 cuda_h.py:19] end start_load_qkvogn_s_weight_l_11 cost 7.104873657226562e-05 seconds
DEBUG 01-14 20:42:49.134842.134842 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-14 20:42:49.135149.135149 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-14 20:42:49.135702.135702 cuda_h.py:10] start sllm_worker_task
DEBUG 01-14 20:42:49.135460.135460 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-14 20:42:49.135919.135919 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-14 20:42:49.136660.136660 cuda_h.py:19] end allocate_cuda_memory cost 0.0015218257904052734 seconds
DEBUG 01-14 20:42:49.136524.136524 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-14 20:42:49.136386.136386 sllm_store_c.py:27] get device uuid map
DEBUG 01-14 20:42:49.136222.136222 sllm_store_c.py:29] call client load into gpu
DEBUG 01-14 20:42:49.137647.137647 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 80d6caab-f1e6-4e8e-8e47-2212adbb2a57
DEBUG 01-14 20:42:49.137022.137022 client.py:106] call stub.LoadModelAsync
DEBUG 01-14 20:42:49.137708.137708 cuda_h.py:10] start self_attn
INFO 01-14 20:42:49.138522.138522 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 80d6caab-f1e6-4e8e-8e47-2212adbb2a57
DEBUG 01-14 20:42:49.138212.138212 cuda_h.py:19] end load_into_gpu_async cost 0.0011363029479980469 seconds
DEBUG 01-14 20:42:49.138961.138961 cuda_h.py:10] start restore_tensors2
DEBUG 01-14 20:42:49.138676.138676 cuda_h.py:19] end restore_tensors2 cost 7.462501525878906e-05 seconds
DEBUG 01-14 20:42:49.138174.138174 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0030896663665771484 seconds
INFO 01-14 20:42:49.138846.138846 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 80d6caab-f1e6-4e8e-8e47-2212adbb2a57
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-14 20:42:49.140262.140262 cuda_h.py:19] end self_attn cost 0.003213644027709961 seconds
DEBUG 01-14 20:42:49.141829.141829 cuda_h.py:19] end iln_self_attn_paln cost 0.006101846694946289 seconds
DEBUG 01-14 20:42:49.141910.141910 cuda_h.py:10] start layer_moe_generate_mp_l_11
DEBUG 01-14 20:42:49.141388.141388 cuda_h.py:10] start gate
DEBUG 01-14 20:42:49.141226.141226 cuda_h.py:19] end gate cost 0.0006542205810546875 seconds
DEBUG 01-14 20:42:49.141916.141916 cuda_h.py:10] start experts_map_get
DEBUG 01-14 20:42:49.142344.142344 lmp.py:1615] 
DEBUG 01-14 20:42:49.142344.142344 lmp.py:1615] Expert Token Distribution & Device Allocation:
DEBUG 01-14 20:42:49.142292.142292 lmp.py:1616]   Total experts: 64
DEBUG 01-14 20:42:49.142419.142419 lmp.py:1617]   CPU experts: 32 (50%)
DEBUG 01-14 20:42:49.142969.142969 lmp.py:1618]   GPU experts: 32 (50%)
DEBUG 01-14 20:42:49.142374.142374 lmp.py:1619] 
DEBUG 01-14 20:42:49.142374.142374 lmp.py:1619]   Expert ID | Tokens | Device
DEBUG 01-14 20:42:49.142540.142540 lmp.py:1620]   -----------------------------------
DEBUG 01-14 20:42:49.142421.142421 lmp.py:1625]   Expert 43 |     19 | CPU
DEBUG 01-14 20:42:49.142587.142587 lmp.py:1625]   Expert 27 |     30 | CPU
DEBUG 01-14 20:42:49.142515.142515 lmp.py:1625]   Expert 26 |     47 | CPU
DEBUG 01-14 20:42:49.142727.142727 lmp.py:1625]   Expert  3 |     58 | CPU
DEBUG 01-14 20:42:49.142940.142940 lmp.py:1625]   Expert 34 |     59 | CPU
DEBUG 01-14 20:42:49.142629.142629 lmp.py:1625]   Expert 56 |     81 | CPU
DEBUG 01-14 20:42:49.142795.142795 lmp.py:1625]   Expert 61 |     86 | CPU
DEBUG 01-14 20:42:49.142246.142246 lmp.py:1625]   Expert  4 |     97 | CPU
DEBUG 01-14 20:42:49.142697.142697 lmp.py:1625]   Expert 38 |    100 | CPU
DEBUG 01-14 20:42:49.142148.142148 lmp.py:1625]   Expert  7 |    106 | CPU
DEBUG 01-14 20:42:49.142076.142076 lmp.py:1625]   Expert 14 |    106 | CPU
DEBUG 01-14 20:42:49.142003.142003 lmp.py:1625]   Expert 22 |    121 | CPU
DEBUG 01-14 20:42:49.142693.142693 lmp.py:1625]   Expert  2 |    122 | CPU
DEBUG 01-14 20:42:49.142144.142144 lmp.py:1625]   Expert 47 |    122 | CPU
DEBUG 01-14 20:42:49.142071.142071 lmp.py:1625]   Expert  5 |    123 | CPU
DEBUG 01-14 20:42:49.142761.142761 lmp.py:1625]   Expert 45 |    131 | CPU
DEBUG 01-14 20:42:49.142450.142450 lmp.py:1625]   Expert 17 |    133 | CPU
DEBUG 01-14 20:42:49.142662.142662 lmp.py:1625]   Expert 48 |    135 | CPU
DEBUG 01-14 20:42:49.142875.142875 lmp.py:1625]   Expert 54 |    135 | CPU
DEBUG 01-14 20:42:49.142564.142564 lmp.py:1625]   Expert 51 |    139 | CPU
DEBUG 01-14 20:42:49.142777.142777 lmp.py:1625]   Expert 19 |    143 | CPU
DEBUG 01-14 20:42:49.142989.142989 lmp.py:1625]   Expert 15 |    150 | CPU
DEBUG 01-14 20:42:49.142202.142202 lmp.py:1625]   Expert 28 |    151 | CPU
DEBUG 01-14 20:42:49.142176.142176 lmp.py:1625]   Expert 55 |    152 | CPU
DEBUG 01-14 20:42:49.142627.142627 lmp.py:1625]   Expert 57 |    153 | CPU
DEBUG 01-14 20:42:49.142601.142601 lmp.py:1625]   Expert 63 |    153 | CPU
DEBUG 01-14 20:42:49.142290.142290 lmp.py:1625]   Expert 12 |    160 | CPU
DEBUG 01-14 20:42:49.142264.142264 lmp.py:1625]   Expert 37 |    162 | CPU
DEBUG 01-14 20:42:49.142715.142715 lmp.py:1625]   Expert 18 |    169 | CPU
DEBUG 01-14 20:42:49.142404.142404 lmp.py:1625]   Expert 60 |    174 | CPU
DEBUG 01-14 20:42:49.142809.142809 lmp.py:1625]   Expert 50 |    177 | CPU
DEBUG 01-14 20:42:49.142789.142789 lmp.py:1625]   Expert  6 |    187 | CPU
DEBUG 01-14 20:42:49.142386.142386 lmp.py:1625]   Expert 44 |    190 | GPU
DEBUG 01-14 20:42:49.142791.142791 lmp.py:1625]   Expert 52 |    190 | GPU
DEBUG 01-14 20:42:49.142718.142718 lmp.py:1625]   Expert 53 |    194 | GPU
DEBUG 01-14 20:42:49.142646.142646 lmp.py:1625]   Expert 31 |    195 | GPU
DEBUG 01-14 20:42:49.142574.142574 lmp.py:1625]   Expert 39 |    195 | GPU
DEBUG 01-14 20:42:49.142409.142409 lmp.py:1625]   Expert 21 |    198 | GPU
DEBUG 01-14 20:42:49.142529.142529 lmp.py:1625]   Expert 23 |    198 | GPU
DEBUG 01-14 20:42:49.142649.142649 lmp.py:1625]   Expert 30 |    202 | GPU
DEBUG 01-14 20:42:49.143530.143530 lmp.py:1625]   Expert 29 |    204 | GPU
DEBUG 01-14 20:42:49.143650.143650 lmp.py:1625]   Expert 20 |    210 | GPU
DEBUG 01-14 20:42:49.143293.143293 lmp.py:1625]   Expert 16 |    212 | GPU
DEBUG 01-14 20:42:49.143413.143413 lmp.py:1625]   Expert 13 |    214 | GPU
DEBUG 01-14 20:42:49.143294.143294 lmp.py:1625]   Expert 42 |    214 | GPU
DEBUG 01-14 20:42:49.143652.143652 lmp.py:1625]   Expert 36 |    219 | GPU
DEBUG 01-14 20:42:49.143249.143249 lmp.py:1625]   Expert 41 |    220 | GPU
DEBUG 01-14 20:42:49.143607.143607 lmp.py:1625]   Expert 11 |    227 | GPU
DEBUG 01-14 20:42:49.143250.143250 lmp.py:1625]   Expert 25 |    230 | GPU
DEBUG 01-14 20:42:49.143370.143370 lmp.py:1625]   Expert 59 |    230 | GPU
DEBUG 01-14 20:42:49.143013.143013 lmp.py:1625]   Expert 49 |    231 | GPU
DEBUG 01-14 20:42:49.143894.143894 lmp.py:1625]   Expert  8 |    234 | GPU
DEBUG 01-14 20:42:49.143743.143743 lmp.py:1625]   Expert 10 |    249 | GPU
DEBUG 01-14 20:42:49.143578.143578 lmp.py:1625]   Expert 33 |    249 | GPU
DEBUG 01-14 20:42:49.143459.143459 lmp.py:1625]   Expert 32 |    254 | GPU
DEBUG 01-14 20:42:49.143102.143102 lmp.py:1625]   Expert 46 |    270 | GPU
DEBUG 01-14 20:42:49.143461.143461 lmp.py:1625]   Expert 58 |    276 | GPU
DEBUG 01-14 20:42:49.143103.143103 lmp.py:1625]   Expert 35 |    296 | GPU
DEBUG 01-14 20:42:49.143462.143462 lmp.py:1625]   Expert 62 |    307 | GPU
DEBUG 01-14 20:42:49.143820.143820 lmp.py:1625]   Expert  9 |    321 | GPU
DEBUG 01-14 20:42:49.143178.143178 lmp.py:1625]   Expert  0 |    396 | GPU
DEBUG 01-14 20:42:49.143298.143298 lmp.py:1625]   Expert 40 |    412 | GPU
DEBUG 01-14 20:42:49.143656.143656 lmp.py:1625]   Expert 24 |    551 | GPU
DEBUG 01-14 20:42:49.143538.143538 lmp.py:1625]   Expert  1 |    619 | GPU
DEBUG 01-14 20:42:49.143611.143611 lmp.py:1626] 
DEBUG 01-14 20:42:49.143611.143611 lmp.py:1626]   CPU total tokens: 3881 (31.6%)
DEBUG 01-14 20:42:49.143446.143446 lmp.py:1627]   GPU total tokens: 8407 (68.4%)
DEBUG 01-14 20:42:49.143288.143288 cuda_h.py:19] end experts_map_get cost 0.0015783309936523438 seconds
DEBUG 01-14 20:42:49.143165.143165 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-14 20:42:49.143499.143499 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-14 20:42:49.143795.143795 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-14 20:42:49.149780.149780 cuda_h.py:19] end allocate_cuda_memory cost 0.005830049514770508 seconds
DEBUG 01-14 20:42:49.149810.149810 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-14 20:42:49.149387.149387 sllm_store_c.py:27] get device uuid map
DEBUG 01-14 20:42:49.149277.149277 sllm_store_c.py:29] call client load into gpu
DEBUG 01-14 20:42:49.149218.149218 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, ffe9d7cd-9b2c-472e-a80f-ccf7635a510a
DEBUG 01-14 20:42:49.150231.150231 client.py:106] call stub.LoadModelAsync
DEBUG 01-14 20:42:49.150799.150799 mlpmodule.py:1367]  experts func einsum cost 0.0697166919708252 s
INFO 01-14 20:42:49.150169.150169 client.py:127] Model loaded
DEBUG 01-14 20:42:49.150803.150803 cuda_h.py:10] start restore2model
DEBUG 01-14 20:42:49.151912.151912 cuda_h.py:19] end restore2model cost 0.0004138946533203125 seconds
DEBUG 01-14 20:42:49.151457.151457 cuda_h.py:19] end sllm_worker_task cost 0.015911340713500977 seconds
INFO 01-14 20:42:49.151400.151400 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, ffe9d7cd-9b2c-472e-a80f-ccf7635a510a
DEBUG 01-14 20:42:49.151581.151581 cuda_h.py:19] end load_into_gpu_async cost 0.001439809799194336 seconds
DEBUG 01-14 20:42:49.151522.151522 cuda_h.py:10] start restore_tensors2
DEBUG 01-14 20:42:49.151338.151338 cuda_h.py:19] end restore_tensors2 cost 0.00039839744567871094 seconds
DEBUG 01-14 20:42:49.151466.151466 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.008096933364868164 seconds
DEBUG 01-14 20:42:49.151560.151560 cuda_h.py:10] start restore2model
DEBUG 01-14 20:42:49.154555.154555 cuda_h.py:19] end restore2model cost 0.0026006698608398438 seconds
DEBUG 01-14 20:42:49.154875.154875 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.010879278182983398 seconds
DEBUG 01-14 20:42:49.154909.154909 cuda_h.py:10] start gpu_sexperts
DEBUG 01-14 20:42:49.154966.154966 cuda_h.py:19] end gpu_sexperts cost 0.0002913475036621094 seconds
DEBUG 01-14 20:42:49.154888.154888 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-14 20:42:49.154498.154498 lmp.py:1683] 
DEBUG 01-14 20:42:49.154498.154498 lmp.py:1683]   Computing 32 experts on CPU...
DEBUG 01-14 20:42:49.154480.154480 cuda_h.py:19] end cpu_experts_submit cost 5.6743621826171875e-05 seconds
DEBUG 01-14 20:42:49.155799.155799 cuda_h.py:10] start experts_func_mgpu_group_pad
DEBUG 01-14 20:42:49.164510.164510 mlpmodule.py:1460] group tensors cost 0.008778572082519531 s
DEBUG 01-14 20:42:49.164288.164288 cuda_h.py:10] start move_flat_hidden2cpu
DEBUG 01-14 20:42:49.169916.169916 cuda_h.py:19] end experts_func_mgpu_group_pad cost 0.014486551284790039 seconds
DEBUG 01-14 20:42:49.171868.171868 cuda_h.py:19] end move_flat_hidden2cpu cost 0.00640869140625 seconds
DEBUG 01-14 20:42:49.172411.172411 cuda_h.py:10] start gpu_group_list
DEBUG 01-14 20:42:49.173502.173502 cuda_h.py:19] end gpu_group_list cost 0.0007603168487548828 seconds
DEBUG 01-14 20:42:49.173273.173273 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-14 20:42:49.173794.173794 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 3.1948089599609375e-05 seconds
DEBUG 01-14 20:42:49.173922.173922 cuda_h.py:10] start wait_experts
INFO 01-14 20:42:49.173614.173614 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, ffe9d7cd-9b2c-472e-a80f-ccf7635a510a
DEBUG 01-14 20:42:49.174991.174991 mlpmodule.py:1533] pad cost 0.003348827362060547 s
DEBUG 01-14 20:42:49.174631.174631 mlpmodule.py:1539] create cpu tensor cost 3.719329833984375e-05 s
DEBUG 01-14 20:42:49.177256.177256 mlpmodule.py:1544] move to cpu cost 0.0022139549255371094 s
DEBUG 01-14 20:42:49.186093.186093 mlpmodule.py:1558] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-14 20:42:49.187086.187086 mlpmodule.py:1559] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-14 20:42:49.187784.187784 mlpmodule.py:1564] group_w3 first element: -0.0213623046875
WARNING 01-14 20:42:49.187570.187570 mlpmodule.py:1574] start einsum2
DEBUG 01-14 20:42:49.205690.205690 mlpmodule.py:1584] group einsum cost 0.028714895248413086 s
INFO 01-14 20:42:49.207430.207430 client.py:127] Model loaded
DEBUG 01-14 20:42:49.207412.207412 mlpmodule.py:1593] cpy2cputensor cost 0.0011560916900634766 s
DEBUG 01-14 20:42:49.207994.207994 cuda_h.py:19] end wait_experts cost 0.03366899490356445 seconds
DEBUG 01-14 20:42:49.207401.207401 cuda_h.py:10] start move_outputs
DEBUG 01-14 20:42:49.207538.207538 cuda_h.py:10] start gpu_experts
DEBUG 01-14 20:42:49.207784.207784 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-14 20:42:49.210760.210760 cuda_h.py:19] end move_outputs cost 0.0021619796752929688 seconds
DEBUG 01-14 20:42:49.213772.213772 cuda_h.py:19] end wait_cetm_experts cost 0.0056726932525634766 seconds
DEBUG 01-14 20:42:49.213939.213939 cuda_h.py:10] start gpu_group_einsum_mp_multi_list
DEBUG 01-14 20:42:49.214889.214889 cuda_h.py:10] start gpu_group_tensor
DEBUG 01-14 20:42:49.214821.214821 cuda_h.py:19] end gpu_group_tensor cost 0.0004558563232421875 seconds
DEBUG 01-14 20:42:49.214466.214466 cuda_h.py:10] start gpu_group_einsum
DEBUG 01-14 20:42:49.216491.216491 cuda_h.py:19] end gpu_group_einsum cost 0.0012290477752685547 seconds
DEBUG 01-14 20:42:49.216305.216305 cuda_h.py:10] start gpu_final_hidden_states_scatter
DEBUG 01-14 20:42:49.216634.216634 cuda_h.py:10] start all_expert_outputs_slices
DEBUG 01-14 20:42:49.217951.217951 cuda_h.py:19] end all_expert_outputs_slices cost 0.0006544589996337891 seconds
DEBUG 01-14 20:42:49.217066.217066 cuda_h.py:10] start concat_expert_out
DEBUG 01-14 20:42:49.217762.217762 cuda_h.py:19] end concat_expert_out cost 0.00014448165893554688 seconds
DEBUG 01-14 20:42:49.217980.217980 cuda_h.py:10] start index_scatter
DEBUG 01-14 20:42:49.218021.218021 cuda_h.py:19] end index_scatter cost 0.0001499652862548828 seconds
DEBUG 01-14 20:42:49.218196.218196 cuda_h.py:19] end gpu_final_hidden_states_scatter cost 0.001600503921508789 seconds
DEBUG 01-14 20:42:49.218408.218408 cuda_h.py:19] end gpu_experts cost 0.01056051254272461 seconds
DEBUG 01-14 20:42:49.218033.218033 cuda_h.py:10] start all_expert_weight_slices
DEBUG 01-14 20:42:49.220330.220330 cuda_h.py:19] end all_expert_weight_slices cost 0.0020723342895507812 seconds
DEBUG 01-14 20:42:49.220572.220572 cuda_h.py:10] start cpuoutputsdeal
DEBUG 01-14 20:42:49.221943.221943 cuda_h.py:10] start index_scatter
DEBUG 01-14 20:42:49.221215.221215 cuda_h.py:19] end index_scatter cost 9.5367431640625e-05 seconds
DEBUG 01-14 20:42:49.221324.221324 cuda_h.py:19] end cpuoutputsdeal cost 0.0010190010070800781 seconds
DEBUG 01-14 20:42:49.222798.222798 cuda_h.py:19] end layer_moe_generate_mp_l_11 cost 0.08088064193725586 seconds
DEBUG 01-14 20:42:49.222152.222152 cuda_h.py:19] end prefill_layer cost 0.08796143531799316 seconds
DEBUG 01-14 20:42:49.222091.222091 lmp.py:1551] -------------------------------- end prefill layer 10 --------------------------------
DEBUG 01-14 20:42:49.222735.222735 cuda_h.py:10] start prefill_layer
DEBUG 01-14 20:42:49.222856.222856 lmp.py:1494] -------------------------------- start prefill layer 11 --------------------------------
DEBUG 01-14 20:42:49.223977.223977 cuda_h.py:10] start start_load_qkvogn_s_weight_l_12
DEBUG 01-14 20:42:49.223959.223959 cuda_h.py:10] start start_load_qkvogn_s_weight_l_12
DEBUG 01-14 20:42:49.223585.223585 cuda_h.py:19] end start_load_qkvogn_s_weight_l_12 cost 5.53131103515625e-05 seconds
DEBUG 01-14 20:42:49.223766.223766 cuda_h.py:19] end start_load_qkvogn_s_weight_l_12 cost 0.0001246929168701172 seconds
DEBUG 01-14 20:42:49.223688.223688 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-14 20:42:49.223474.223474 cuda_h.py:10] start sllm_worker_task
DEBUG 01-14 20:42:49.223877.223877 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-14 20:42:49.223370.223370 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-14 20:42:49.226932.226932 cuda_h.py:19] end allocate_cuda_memory cost 0.0022940635681152344 seconds
DEBUG 01-14 20:42:49.226638.226638 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-14 20:42:49.226930.226930 sllm_store_c.py:27] get device uuid map
DEBUG 01-14 20:42:49.226688.226688 sllm_store_c.py:29] call client load into gpu
DEBUG 01-14 20:42:49.226444.226444 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 5a05752b-c9c7-4a9e-874c-90cb38571f4b
DEBUG 01-14 20:42:49.226553.226553 client.py:106] call stub.LoadModelAsync
DEBUG 01-14 20:42:49.226515.226515 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-14 20:42:49.227128.227128 cuda_h.py:10] start self_attn
INFO 01-14 20:42:49.227636.227636 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 5a05752b-c9c7-4a9e-874c-90cb38571f4b
DEBUG 01-14 20:42:49.228453.228453 cuda_h.py:19] end load_into_gpu_async cost 0.0019598007202148438 seconds
DEBUG 01-14 20:42:49.228799.228799 cuda_h.py:10] start restore_tensors2
DEBUG 01-14 20:42:49.228446.228446 cuda_h.py:19] end restore_tensors2 cost 9.179115295410156e-05 seconds
DEBUG 01-14 20:42:49.228347.228347 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.004683732986450195 seconds
INFO 01-14 20:42:49.228621.228621 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 5a05752b-c9c7-4a9e-874c-90cb38571f4b
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-14 20:42:49.232042.232042 cuda_h.py:19] end self_attn cost 0.0052127838134765625 seconds
DEBUG 01-14 20:42:49.232878.232878 mlpmodule.py:1367]  experts func einsum cost 0.0775291919708252 s
DEBUG 01-14 20:42:49.233260.233260 cuda_h.py:19] end iln_self_attn_paln cost 0.010078668594360352 seconds
DEBUG 01-14 20:42:49.233946.233946 cuda_h.py:10] start layer_moe_generate_mp_l_12
DEBUG 01-14 20:42:49.233444.233444 cuda_h.py:10] start gate
DEBUG 01-14 20:42:49.234978.234978 cuda_h.py:19] end gate cost 0.0008685588836669922 seconds
DEBUG 01-14 20:42:49.234425.234425 cuda_h.py:10] start experts_map_get
DEBUG 01-14 20:42:49.235394.235394 lmp.py:1615] 
DEBUG 01-14 20:42:49.235394.235394 lmp.py:1615] Expert Token Distribution & Device Allocation:
DEBUG 01-14 20:42:49.235932.235932 lmp.py:1616]   Total experts: 64
DEBUG 01-14 20:42:49.235596.235596 lmp.py:1617]   CPU experts: 32 (50%)
DEBUG 01-14 20:42:49.235398.235398 lmp.py:1618]   GPU experts: 32 (50%)
DEBUG 01-14 20:42:49.235385.235385 lmp.py:1619] 
DEBUG 01-14 20:42:49.235385.235385 lmp.py:1619]   Expert ID | Tokens | Device
DEBUG 01-14 20:42:49.235373.235373 lmp.py:1620]   -----------------------------------
DEBUG 01-14 20:42:49.235844.235844 lmp.py:1625]   Expert 39 |     16 | CPU
DEBUG 01-14 20:42:49.235216.235216 lmp.py:1625]   Expert 13 |     22 | CPU
DEBUG 01-14 20:42:49.235111.235111 lmp.py:1625]   Expert 49 |     38 | CPU
DEBUG 01-14 20:42:49.235721.235721 lmp.py:1625]   Expert  9 |     63 | CPU
DEBUG 01-14 20:42:49.235855.235855 lmp.py:1625]   Expert 19 |     63 | CPU
DEBUG 01-14 20:42:49.235796.235796 lmp.py:1625]   Expert 26 |     65 | CPU
DEBUG 01-14 20:42:49.235976.235976 lmp.py:1625]   Expert 35 |     69 | CPU
DEBUG 01-14 20:42:49.235294.235294 lmp.py:1625]   Expert 33 |     72 | CPU
DEBUG 01-14 20:42:49.235852.235852 lmp.py:1625]   Expert 46 |     74 | CPU
DEBUG 01-14 20:42:49.235839.235839 lmp.py:1625]   Expert 32 |     80 | CPU
DEBUG 01-14 20:42:49.235112.235112 lmp.py:1625]   Expert 23 |     88 | CPU
DEBUG 01-14 20:42:49.235338.235338 lmp.py:1625]   Expert 41 |     88 | CPU
DEBUG 01-14 20:42:49.235279.235279 lmp.py:1625]   Expert 17 |    101 | CPU
DEBUG 01-14 20:42:49.235697.235697 lmp.py:1625]   Expert 31 |    101 | CPU
DEBUG 01-14 20:42:49.235877.235877 lmp.py:1625]   Expert 18 |    106 | CPU
DEBUG 01-14 20:42:49.235010.235010 lmp.py:1625]   Expert  6 |    109 | CPU
DEBUG 01-14 20:42:49.235667.235667 lmp.py:1625]   Expert  3 |    115 | CPU
DEBUG 01-14 20:42:49.235800.235800 lmp.py:1625]   Expert 38 |    115 | CPU
DEBUG 01-14 20:42:49.235933.235933 lmp.py:1625]   Expert 50 |    120 | CPU
DEBUG 01-14 20:42:49.235590.235590 lmp.py:1625]   Expert 40 |    125 | CPU
DEBUG 01-14 20:42:49.235862.235862 lmp.py:1625]   Expert 15 |    130 | CPU
DEBUG 01-14 20:42:49.235255.235255 lmp.py:1625]   Expert 20 |    130 | CPU
DEBUG 01-14 20:42:49.235626.235626 lmp.py:1625]   Expert 63 |    132 | CPU
DEBUG 01-14 20:42:49.235568.235568 lmp.py:1625]   Expert 62 |    137 | CPU
DEBUG 01-14 20:42:49.235986.235986 lmp.py:1625]   Expert 61 |    139 | CPU
DEBUG 01-14 20:42:49.235881.235881 lmp.py:1625]   Expert 43 |    144 | CPU
DEBUG 01-14 20:42:49.236253.236253 lmp.py:1625]   Expert 36 |    145 | CPU
DEBUG 01-14 20:42:49.236671.236671 lmp.py:1625]   Expert  2 |    147 | CPU
DEBUG 01-14 20:42:49.236612.236612 lmp.py:1625]   Expert 42 |    152 | CPU
DEBUG 01-14 20:42:49.236600.236600 lmp.py:1625]   Expert 10 |    155 | CPU
DEBUG 01-14 20:42:49.236687.236687 lmp.py:1625]   Expert 44 |    159 | CPU
DEBUG 01-14 20:42:49.236866.236866 lmp.py:1625]   Expert 16 |    164 | CPU
DEBUG 01-14 20:42:49.236238.236238 lmp.py:1625]   Expert  5 |    172 | GPU
DEBUG 01-14 20:42:49.236180.236180 lmp.py:1625]   Expert 56 |    172 | GPU
DEBUG 01-14 20:42:49.236598.236598 lmp.py:1625]   Expert 59 |    175 | GPU
DEBUG 01-14 20:42:49.236539.236539 lmp.py:1625]   Expert 34 |    195 | GPU
DEBUG 01-14 20:42:49.236480.236480 lmp.py:1625]   Expert 45 |    196 | GPU
DEBUG 01-14 20:42:49.236468.236468 lmp.py:1625]   Expert 52 |    196 | GPU
DEBUG 01-14 20:42:49.236125.236125 lmp.py:1625]   Expert 60 |    202 | GPU
DEBUG 01-14 20:42:49.236543.236543 lmp.py:1625]   Expert 27 |    206 | GPU
DEBUG 01-14 20:42:49.236690.236690 lmp.py:1625]   Expert 51 |    210 | GPU
DEBUG 01-14 20:42:49.236300.236300 lmp.py:1625]   Expert 24 |    216 | GPU
DEBUG 01-14 20:42:49.236447.236447 lmp.py:1625]   Expert 48 |    225 | GPU
DEBUG 01-14 20:42:49.236819.236819 lmp.py:1625]   Expert 53 |    225 | GPU
DEBUG 01-14 20:42:49.236237.236237 lmp.py:1625]   Expert 47 |    247 | GPU
DEBUG 01-14 20:42:49.236893.236893 lmp.py:1625]   Expert  8 |    248 | GPU
DEBUG 01-14 20:42:49.236265.236265 lmp.py:1625]   Expert  7 |    251 | GPU
DEBUG 01-14 20:42:49.236637.236637 lmp.py:1625]   Expert 29 |    261 | GPU
DEBUG 01-14 20:42:49.236962.236962 lmp.py:1625]   Expert 58 |    269 | GPU
DEBUG 01-14 20:42:49.236096.236096 lmp.py:1625]   Expert 21 |    270 | GPU
DEBUG 01-14 20:42:49.236898.236898 lmp.py:1625]   Expert 57 |    283 | GPU
DEBUG 01-14 20:42:49.236078.236078 lmp.py:1625]   Expert 14 |    288 | GPU
DEBUG 01-14 20:42:49.236734.236734 lmp.py:1625]   Expert 37 |    293 | GPU
DEBUG 01-14 20:42:49.236629.236629 lmp.py:1625]   Expert 11 |    297 | GPU
DEBUG 01-14 20:42:49.236048.236048 lmp.py:1625]   Expert  1 |    300 | GPU
DEBUG 01-14 20:42:49.236704.236704 lmp.py:1625]   Expert  0 |    306 | GPU
DEBUG 01-14 20:42:49.236314.236314 lmp.py:1625]   Expert  4 |    308 | GPU
DEBUG 01-14 20:42:49.236209.236209 lmp.py:1625]   Expert 22 |    309 | GPU
DEBUG 01-14 20:42:49.236104.236104 lmp.py:1625]   Expert 55 |    323 | GPU
DEBUG 01-14 20:42:49.236046.236046 lmp.py:1625]   Expert 54 |    333 | GPU
DEBUG 01-14 20:42:49.236748.236748 lmp.py:1625]   Expert 25 |    364 | GPU
DEBUG 01-14 20:42:49.236690.236690 lmp.py:1625]   Expert 12 |    416 | GPU
DEBUG 01-14 20:42:49.237108.237108 lmp.py:1625]   Expert 28 |    419 | GPU
DEBUG 01-14 20:42:49.237003.237003 lmp.py:1625]   Expert 30 |    749 | GPU
DEBUG 01-14 20:42:49.237236.237236 lmp.py:1626] 
DEBUG 01-14 20:42:49.237236.237236 lmp.py:1626]   CPU total tokens: 3364 (27.4%)
DEBUG 01-14 20:42:49.237038.237038 lmp.py:1627]   GPU total tokens: 8924 (72.6%)
DEBUG 01-14 20:42:49.237754.237754 cuda_h.py:19] end experts_map_get cost 0.002482175827026367 seconds
DEBUG 01-14 20:42:49.237698.237698 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-14 20:42:49.237503.237503 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-14 20:42:49.237021.237021 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-14 20:42:49.237821.237821 cuda_h.py:19] end allocate_cuda_memory cost 0.0002911090850830078 seconds
DEBUG 01-14 20:42:49.238049.238049 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-14 20:42:49.238494.238494 sllm_store_c.py:27] get device uuid map
DEBUG 01-14 20:42:49.238437.238437 sllm_store_c.py:29] call client load into gpu
DEBUG 01-14 20:42:49.238061.238061 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 43978086-ee20-4e84-b747-00e140cf732c
DEBUG 01-14 20:42:49.238349.238349 client.py:106] call stub.LoadModelAsync
INFO 01-14 20:42:49.238539.238539 client.py:127] Model loaded
DEBUG 01-14 20:42:49.238988.238988 cuda_h.py:10] start restore2model
DEBUG 01-14 20:42:49.240232.240232 cuda_h.py:19] end restore2model cost 0.0012717247009277344 seconds
INFO 01-14 20:42:49.240323.240323 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 43978086-ee20-4e84-b747-00e140cf732c
DEBUG 01-14 20:42:49.240531.240531 cuda_h.py:19] end sllm_worker_task cost 0.017342329025268555 seconds
DEBUG 01-14 20:42:49.241452.241452 cuda_h.py:19] end load_into_gpu_async cost 0.003086566925048828 seconds
DEBUG 01-14 20:42:49.241503.241503 cuda_h.py:10] start restore_tensors2
DEBUG 01-14 20:42:49.241986.241986 cuda_h.py:19] end restore_tensors2 cost 0.0005342960357666016 seconds
DEBUG 01-14 20:42:49.241194.241194 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.004570484161376953 seconds
DEBUG 01-14 20:42:49.242739.242739 cuda_h.py:10] start restore2model
DEBUG 01-14 20:42:49.244839.244839 cuda_h.py:19] end restore2model cost 0.002781391143798828 seconds
DEBUG 01-14 20:42:49.244756.244756 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.007617473602294922 seconds
DEBUG 01-14 20:42:49.244790.244790 cuda_h.py:10] start gpu_sexperts
DEBUG 01-14 20:42:49.245881.245881 cuda_h.py:19] end gpu_sexperts cost 0.00031495094299316406 seconds
DEBUG 01-14 20:42:49.245572.245572 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-14 20:42:49.245851.245851 lmp.py:1683] 
DEBUG 01-14 20:42:49.245851.245851 lmp.py:1683]   Computing 32 experts on CPU...
DEBUG 01-14 20:42:49.245515.245515 cuda_h.py:19] end cpu_experts_submit cost 6.937980651855469e-05 seconds
DEBUG 01-14 20:42:49.245602.245602 cuda_h.py:10] start experts_func_mgpu_group_pad
DEBUG 01-14 20:42:49.255745.255745 mlpmodule.py:1460] group tensors cost 0.009252786636352539 s
DEBUG 01-14 20:42:49.255180.255180 cuda_h.py:10] start move_flat_hidden2cpu
DEBUG 01-14 20:42:49.258574.258574 cuda_h.py:19] end experts_func_mgpu_group_pad cost 0.01274728775024414 seconds
DEBUG 01-14 20:42:49.259158.259158 cuda_h.py:10] start gpu_group_list
DEBUG 01-14 20:42:49.260242.260242 cuda_h.py:19] end gpu_group_list cost 0.0004062652587890625 seconds
DEBUG 01-14 20:42:49.260248.260248 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-14 20:42:49.260437.260437 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.9087066650390625e-05 seconds
DEBUG 01-14 20:42:49.260723.260723 cuda_h.py:10] start wait_experts
INFO 01-14 20:42:49.260148.260148 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 43978086-ee20-4e84-b747-00e140cf732c
DEBUG 01-14 20:42:49.262783.262783 cuda_h.py:19] end move_flat_hidden2cpu cost 0.006447315216064453 seconds
DEBUG 01-14 20:42:49.264026.264026 mlpmodule.py:1533] pad cost 0.0015900135040283203 s
DEBUG 01-14 20:42:49.264268.264268 mlpmodule.py:1539] create cpu tensor cost 3.7670135498046875e-05 s
DEBUG 01-14 20:42:49.266547.266547 mlpmodule.py:1544] move to cpu cost 0.001959562301635742 s
DEBUG 01-14 20:42:49.275237.275237 mlpmodule.py:1558] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-14 20:42:49.276176.276176 mlpmodule.py:1559] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-14 20:42:49.276497.276497 mlpmodule.py:1564] group_w3 first element: -0.006134033203125
WARNING 01-14 20:42:49.276482.276482 mlpmodule.py:1574] start einsum2
DEBUG 01-14 20:42:49.293997.293997 mlpmodule.py:1584] group einsum cost 0.026622295379638672 s
DEBUG 01-14 20:42:49.293737.293737 mlpmodule.py:1593] cpy2cputensor cost 0.0007443428039550781 s
DEBUG 01-14 20:42:49.294844.294844 cuda_h.py:10] start move_outputs
DEBUG 01-14 20:42:49.296958.296958 cuda_h.py:19] end move_outputs cost 0.0019817352294921875 seconds
INFO 01-14 20:42:49.296211.296211 client.py:127] Model loaded
DEBUG 01-14 20:42:49.297424.297424 cuda_h.py:19] end wait_experts cost 0.03669333457946777 seconds
DEBUG 01-14 20:42:49.297851.297851 cuda_h.py:10] start gpu_experts
DEBUG 01-14 20:42:49.297920.297920 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-14 20:42:49.300302.300302 cuda_h.py:19] end wait_cetm_experts cost 0.0030133724212646484 seconds
DEBUG 01-14 20:42:49.300069.300069 cuda_h.py:10] start gpu_group_einsum_mp_multi_list
DEBUG 01-14 20:42:49.300787.300787 cuda_h.py:10] start gpu_group_tensor
DEBUG 01-14 20:42:49.301612.301612 cuda_h.py:19] end gpu_group_tensor cost 0.0004298686981201172 seconds
DEBUG 01-14 20:42:49.301872.301872 cuda_h.py:10] start gpu_group_einsum
DEBUG 01-14 20:42:49.302844.302844 cuda_h.py:19] end gpu_group_einsum cost 0.0013523101806640625 seconds
DEBUG 01-14 20:42:49.303299.303299 cuda_h.py:10] start gpu_final_hidden_states_scatter
DEBUG 01-14 20:42:49.303679.303679 cuda_h.py:10] start all_expert_outputs_slices
DEBUG 01-14 20:42:49.303756.303756 cuda_h.py:19] end all_expert_outputs_slices cost 0.00030517578125 seconds
DEBUG 01-14 20:42:49.303943.303943 cuda_h.py:10] start concat_expert_out
DEBUG 01-14 20:42:49.303529.303529 cuda_h.py:19] end concat_expert_out cost 7.915496826171875e-05 seconds
DEBUG 01-14 20:42:49.303154.303154 cuda_h.py:10] start index_scatter
DEBUG 01-14 20:42:49.303496.303496 cuda_h.py:19] end index_scatter cost 7.724761962890625e-05 seconds
DEBUG 01-14 20:42:49.304782.304782 cuda_h.py:19] end gpu_final_hidden_states_scatter cost 0.0007302761077880859 seconds
DEBUG 01-14 20:42:49.304422.304422 cuda_h.py:19] end gpu_experts cost 0.006889820098876953 seconds
DEBUG 01-14 20:42:49.304701.304701 cuda_h.py:10] start all_expert_weight_slices
DEBUG 01-14 20:42:49.305940.305940 cuda_h.py:19] end all_expert_weight_slices cost 0.0009872913360595703 seconds
DEBUG 01-14 20:42:49.305869.305869 cuda_h.py:10] start cpuoutputsdeal
DEBUG 01-14 20:42:49.305983.305983 cuda_h.py:10] start index_scatter
DEBUG 01-14 20:42:49.305403.305403 cuda_h.py:19] end index_scatter cost 4.863739013671875e-05 seconds
DEBUG 01-14 20:42:49.305550.305550 cuda_h.py:19] end cpuoutputsdeal cost 0.0005428791046142578 seconds
DEBUG 01-14 20:42:49.305467.305467 cuda_h.py:19] end layer_moe_generate_mp_l_12 cost 0.07228636741638184 seconds
DEBUG 01-14 20:42:49.306514.306514 cuda_h.py:19] end prefill_layer cost 0.08335280418395996 seconds
DEBUG 01-14 20:42:49.306795.306795 lmp.py:1551] -------------------------------- end prefill layer 11 --------------------------------
DEBUG 01-14 20:42:49.306451.306451 cuda_h.py:10] start prefill_layer
DEBUG 01-14 20:42:49.306869.306869 lmp.py:1494] -------------------------------- start prefill layer 12 --------------------------------
DEBUG 01-14 20:42:49.306003.306003 cuda_h.py:10] start start_load_qkvogn_s_weight_l_13
DEBUG 01-14 20:42:49.306242.306242 cuda_h.py:10] start start_load_qkvogn_s_weight_l_13
DEBUG 01-14 20:42:49.306344.306344 cuda_h.py:19] end start_load_qkvogn_s_weight_l_13 cost 4.267692565917969e-05 seconds
DEBUG 01-14 20:42:49.306246.306246 cuda_h.py:19] end start_load_qkvogn_s_weight_l_13 cost 7.891654968261719e-05 seconds
DEBUG 01-14 20:42:49.306849.306849 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-14 20:42:49.306323.306323 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-14 20:42:49.306910.306910 cuda_h.py:10] start sllm_worker_task
DEBUG 01-14 20:42:49.306549.306549 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-14 20:42:49.307061.307061 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-14 20:42:49.312380.312380 cuda_h.py:19] end allocate_cuda_memory cost 0.005910634994506836 seconds
DEBUG 01-14 20:42:49.313754.313754 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-14 20:42:49.313047.313047 sllm_store_c.py:27] get device uuid map
DEBUG 01-14 20:42:49.313069.313069 sllm_store_c.py:29] call client load into gpu
DEBUG 01-14 20:42:49.313302.313302 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 2acc865b-3a58-40c6-b8ee-8d0024d7376e
DEBUG 01-14 20:42:49.313616.313616 client.py:106] call stub.LoadModelAsync
DEBUG 01-14 20:42:49.313905.313905 cuda_h.py:10] start self_attn
INFO 01-14 20:42:49.314101.314101 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 2acc865b-3a58-40c6-b8ee-8d0024d7376e
DEBUG 01-14 20:42:49.314937.314937 cuda_h.py:19] end load_into_gpu_async cost 0.0012545585632324219 seconds
DEBUG 01-14 20:42:49.314448.314448 cuda_h.py:10] start restore_tensors2
DEBUG 01-14 20:42:49.314868.314868 cuda_h.py:19] end restore_tensors2 cost 7.343292236328125e-05 seconds
DEBUG 01-14 20:42:49.314008.314008 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.00753474235534668 seconds
INFO 01-14 20:42:49.314537.314537 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 2acc865b-3a58-40c6-b8ee-8d0024d7376e
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-14 20:42:49.317362.317362 cuda_h.py:19] end self_attn cost 0.003878355026245117 seconds
DEBUG 01-14 20:42:49.317829.317829 cuda_h.py:19] end iln_self_attn_paln cost 0.011220693588256836 seconds
DEBUG 01-14 20:42:49.317910.317910 cuda_h.py:10] start layer_moe_generate_mp_l_13
DEBUG 01-14 20:42:49.317766.317766 cuda_h.py:10] start gate
DEBUG 01-14 20:42:49.318359.318359 cuda_h.py:19] end gate cost 0.0006814002990722656 seconds
DEBUG 01-14 20:42:49.318904.318904 cuda_h.py:10] start experts_map_get
DEBUG 01-14 20:42:49.319663.319663 lmp.py:1615] 
DEBUG 01-14 20:42:49.319663.319663 lmp.py:1615] Expert Token Distribution & Device Allocation:
DEBUG 01-14 20:42:49.319088.319088 lmp.py:1616]   Total experts: 64
DEBUG 01-14 20:42:49.319407.319407 lmp.py:1617]   CPU experts: 32 (50%)
DEBUG 01-14 20:42:49.319672.319672 lmp.py:1618]   GPU experts: 32 (50%)
DEBUG 01-14 20:42:49.319838.319838 lmp.py:1619] 
DEBUG 01-14 20:42:49.319838.319838 lmp.py:1619]   Expert ID | Tokens | Device
DEBUG 01-14 20:42:49.319004.319004 lmp.py:1620]   -----------------------------------
DEBUG 01-14 20:42:49.319840.319840 lmp.py:1625]   Expert 12 |     27 | CPU
DEBUG 01-14 20:42:49.319529.319529 lmp.py:1625]   Expert 52 |     27 | CPU
DEBUG 01-14 20:42:49.319741.319741 lmp.py:1625]   Expert 16 |     32 | CPU
DEBUG 01-14 20:42:49.319768.319768 lmp.py:1625]   Expert 38 |     32 | CPU
DEBUG 01-14 20:42:49.319557.319557 lmp.py:1625]   Expert 47 |     38 | CPU
DEBUG 01-14 20:42:49.319915.319915 lmp.py:1625]   Expert 63 |     43 | CPU
DEBUG 01-14 20:42:49.319320.319320 lmp.py:1625]   Expert 27 |     51 | CPU
DEBUG 01-14 20:42:49.319155.319155 lmp.py:1625]   Expert  4 |     70 | CPU
DEBUG 01-14 20:42:49.319560.319560 lmp.py:1625]   Expert 43 |     76 | CPU
DEBUG 01-14 20:42:49.319918.319918 lmp.py:1625]   Expert 61 |     79 | CPU
DEBUG 01-14 20:42:49.319084.319084 lmp.py:1625]   Expert 53 |     80 | CPU
DEBUG 01-14 20:42:49.319442.319442 lmp.py:1625]   Expert 34 |     82 | CPU
DEBUG 01-14 20:42:49.319608.319608 lmp.py:1625]   Expert 44 |     87 | CPU
DEBUG 01-14 20:42:49.319728.319728 lmp.py:1625]   Expert 13 |     97 | CPU
DEBUG 01-14 20:42:49.319656.319656 lmp.py:1625]   Expert 37 |    103 | CPU
DEBUG 01-14 20:42:49.319014.319014 lmp.py:1625]   Expert 39 |    104 | CPU
DEBUG 01-14 20:42:49.319465.319465 lmp.py:1625]   Expert 32 |    108 | CPU
DEBUG 01-14 20:42:49.319062.319062 lmp.py:1625]   Expert  0 |    113 | CPU
DEBUG 01-14 20:42:49.319989.319989 lmp.py:1625]   Expert 20 |    118 | CPU
DEBUG 01-14 20:42:49.319871.319871 lmp.py:1625]   Expert 14 |    125 | CPU
DEBUG 01-14 20:42:49.319798.319798 lmp.py:1625]   Expert 30 |    130 | CPU
DEBUG 01-14 20:42:49.319395.319395 lmp.py:1625]   Expert 21 |    131 | CPU
DEBUG 01-14 20:42:49.319561.319561 lmp.py:1625]   Expert 60 |    136 | CPU
DEBUG 01-14 20:42:49.319443.319443 lmp.py:1625]   Expert  8 |    139 | CPU
DEBUG 01-14 20:42:49.319132.319132 lmp.py:1625]   Expert 18 |    140 | CPU
DEBUG 01-14 20:42:49.319252.319252 lmp.py:1625]   Expert 45 |    140 | CPU
DEBUG 01-14 20:42:49.319418.319418 lmp.py:1625]   Expert 11 |    147 | CPU
DEBUG 01-14 20:42:49.319538.319538 lmp.py:1625]   Expert 57 |    154 | CPU
DEBUG 01-14 20:42:49.319989.319989 lmp.py:1625]   Expert 17 |    155 | CPU
DEBUG 01-14 20:42:49.319870.319870 lmp.py:1625]   Expert 22 |    156 | CPU
DEBUG 01-14 20:42:49.319559.319559 lmp.py:1625]   Expert 36 |    156 | CPU
DEBUG 01-14 20:42:49.319918.319918 lmp.py:1625]   Expert 42 |    161 | CPU
DEBUG 01-14 20:42:49.319845.319845 lmp.py:1625]   Expert  2 |    165 | GPU
DEBUG 01-14 20:42:49.319965.319965 lmp.py:1625]   Expert  7 |    166 | GPU
DEBUG 01-14 20:42:49.319893.319893 lmp.py:1625]   Expert 23 |    169 | GPU
DEBUG 01-14 20:42:49.319536.319536 lmp.py:1625]   Expert 58 |    172 | GPU
DEBUG 01-14 20:42:49.319463.319463 lmp.py:1625]   Expert 49 |    174 | GPU
DEBUG 01-14 20:42:49.319345.319345 lmp.py:1625]   Expert 25 |    175 | GPU
DEBUG 01-14 20:42:49.319273.319273 lmp.py:1625]   Expert 62 |    180 | GPU
DEBUG 01-14 20:42:49.319869.319869 lmp.py:1625]   Expert 35 |    181 | GPU
DEBUG 01-14 20:42:49.319082.319082 lmp.py:1625]   Expert 55 |    192 | GPU
DEBUG 01-14 20:42:49.319201.319201 lmp.py:1625]   Expert  6 |    194 | GPU
DEBUG 01-14 20:42:49.319129.319129 lmp.py:1625]   Expert 48 |    195 | GPU
DEBUG 01-14 20:42:49.319772.319772 lmp.py:1625]   Expert 29 |    201 | GPU
DEBUG 01-14 20:42:49.319461.319461 lmp.py:1625]   Expert  1 |    203 | GPU
DEBUG 01-14 20:42:49.319343.319343 lmp.py:1625]   Expert 31 |    205 | GPU
DEBUG 01-14 20:42:49.320032.320032 lmp.py:1625]   Expert 51 |    215 | GPU
DEBUG 01-14 20:42:49.320390.320390 lmp.py:1625]   Expert 28 |    221 | GPU
DEBUG 01-14 20:42:49.320557.320557 lmp.py:1625]   Expert  5 |    222 | GPU
DEBUG 01-14 20:42:49.320676.320676 lmp.py:1625]   Expert 54 |    224 | GPU
DEBUG 01-14 20:42:49.320127.320127 lmp.py:1625]   Expert 19 |    226 | GPU
DEBUG 01-14 20:42:49.320770.320770 lmp.py:1625]   Expert  9 |    242 | GPU
DEBUG 01-14 20:42:49.320460.320460 lmp.py:1625]   Expert 41 |    252 | GPU
DEBUG 01-14 20:42:49.320579.320579 lmp.py:1625]   Expert 24 |    261 | GPU
DEBUG 01-14 20:42:49.320269.320269 lmp.py:1625]   Expert 50 |    268 | GPU
DEBUG 01-14 20:42:49.320912.320912 lmp.py:1625]   Expert 46 |    289 | GPU
DEBUG 01-14 20:42:49.320839.320839 lmp.py:1625]   Expert 59 |    326 | GPU
DEBUG 01-14 20:42:49.320913.320913 lmp.py:1625]   Expert 33 |    395 | GPU
DEBUG 01-14 20:42:49.320079.320079 lmp.py:1625]   Expert 56 |    408 | GPU
DEBUG 01-14 20:42:49.320960.320960 lmp.py:1625]   Expert 10 |    434 | GPU
DEBUG 01-14 20:42:49.320888.320888 lmp.py:1625]   Expert 26 |    435 | GPU
DEBUG 01-14 20:42:49.320008.320008 lmp.py:1625]   Expert  3 |    598 | GPU
DEBUG 01-14 20:42:49.320174.320174 lmp.py:1625]   Expert 15 |    603 | GPU
DEBUG 01-14 20:42:49.320294.320294 lmp.py:1625]   Expert 40 |    860 | GPU
DEBUG 01-14 20:42:49.320937.320937 lmp.py:1626] 
DEBUG 01-14 20:42:49.320937.320937 lmp.py:1626]   CPU total tokens: 3237 (26.3%)
DEBUG 01-14 20:42:49.320679.320679 lmp.py:1627]   GPU total tokens: 9051 (73.7%)
DEBUG 01-14 20:42:49.320329.320329 cuda_h.py:19] end experts_map_get cost 0.0015840530395507812 seconds
DEBUG 01-14 20:42:49.320319.320319 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-14 20:42:49.320652.320652 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-14 20:42:49.320234.320234 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-14 20:42:49.321197.321197 cuda_h.py:19] end allocate_cuda_memory cost 0.0004642009735107422 seconds
DEBUG 01-14 20:42:49.321948.321948 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-14 20:42:49.321657.321657 sllm_store_c.py:27] get device uuid map
DEBUG 01-14 20:42:49.321043.321043 sllm_store_c.py:29] call client load into gpu
DEBUG 01-14 20:42:49.321315.321315 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 3dee6679-15fd-4547-9032-3a611715de7c
DEBUG 01-14 20:42:49.321381.321381 client.py:106] call stub.LoadModelAsync
DEBUG 01-14 20:42:49.321293.321293 mlpmodule.py:1367]  experts func einsum cost 0.07569622993469238 s
INFO 01-14 20:42:49.321160.321160 client.py:127] Model loaded
DEBUG 01-14 20:42:49.322391.322391 cuda_h.py:10] start restore2model
INFO 01-14 20:42:49.322438.322438 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 3dee6679-15fd-4547-9032-3a611715de7c
DEBUG 01-14 20:42:49.322712.322712 cuda_h.py:19] end load_into_gpu_async cost 0.0012295246124267578 seconds
DEBUG 01-14 20:42:49.322700.322700 cuda_h.py:10] start restore_tensors2
DEBUG 01-14 20:42:49.322416.322416 cuda_h.py:19] end restore_tensors2 cost 0.0003962516784667969 seconds
DEBUG 01-14 20:42:49.323544.323544 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0024564266204833984 seconds
DEBUG 01-14 20:42:49.323598.323598 cuda_h.py:10] start restore2model
DEBUG 01-14 20:42:49.323062.323062 cuda_h.py:19] end restore2model cost 0.000164031982421875 seconds
DEBUG 01-14 20:42:49.323749.323749 cuda_h.py:19] end sllm_worker_task cost 0.016446352005004883 seconds
DEBUG 01-14 20:42:49.325640.325640 cuda_h.py:19] end restore2model cost 0.0028066635131835938 seconds
DEBUG 01-14 20:42:49.325490.325490 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.005461454391479492 seconds
DEBUG 01-14 20:42:49.325067.325067 cuda_h.py:10] start gpu_sexperts
DEBUG 01-14 20:42:49.326396.326396 cuda_h.py:19] end gpu_sexperts cost 0.00028204917907714844 seconds
DEBUG 01-14 20:42:49.326457.326457 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-14 20:42:49.326590.326590 lmp.py:1683] 
DEBUG 01-14 20:42:49.326590.326590 lmp.py:1683]   Computing 32 experts on CPU...
DEBUG 01-14 20:42:49.326149.326149 cuda_h.py:19] end cpu_experts_submit cost 6.008148193359375e-05 seconds
DEBUG 01-14 20:42:49.326851.326851 cuda_h.py:10] start experts_func_mgpu_group_pad
DEBUG 01-14 20:42:49.335431.335431 mlpmodule.py:1460] group tensors cost 0.00862431526184082 s
DEBUG 01-14 20:42:49.336119.336119 cuda_h.py:10] start move_flat_hidden2cpu
DEBUG 01-14 20:42:49.338139.338139 cuda_h.py:19] end experts_func_mgpu_group_pad cost 0.012099266052246094 seconds
DEBUG 01-14 20:42:49.340722.340722 cuda_h.py:10] start gpu_group_list
DEBUG 01-14 20:42:49.340840.340840 cuda_h.py:19] end gpu_group_list cost 0.0004448890686035156 seconds
DEBUG 01-14 20:42:49.340316.340316 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-14 20:42:49.341947.341947 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.0265579223632812e-05 seconds
DEBUG 01-14 20:42:49.341419.341419 cuda_h.py:10] start wait_experts
INFO 01-14 20:42:49.341142.341142 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 3dee6679-15fd-4547-9032-3a611715de7c
DEBUG 01-14 20:42:49.342436.342436 cuda_h.py:19] end move_flat_hidden2cpu cost 0.0062329769134521484 seconds
DEBUG 01-14 20:42:49.343411.343411 mlpmodule.py:1533] pad cost 0.0015213489532470703 s
DEBUG 01-14 20:42:49.344978.344978 mlpmodule.py:1539] create cpu tensor cost 3.600120544433594e-05 s
DEBUG 01-14 20:42:49.346089.346089 mlpmodule.py:1544] move to cpu cost 0.0019054412841796875 s
DEBUG 01-14 20:42:49.355085.355085 mlpmodule.py:1558] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-14 20:42:49.355561.355561 mlpmodule.py:1559] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-14 20:42:49.355220.355220 mlpmodule.py:1564] group_w3 first element: -0.0162353515625
WARNING 01-14 20:42:49.355681.355681 mlpmodule.py:1574] start einsum2
DEBUG 01-14 20:42:49.372841.372841 mlpmodule.py:1584] group einsum cost 0.025927066802978516 s
DEBUG 01-14 20:42:49.372402.372402 mlpmodule.py:1593] cpy2cputensor cost 0.0007441043853759766 s
DEBUG 01-14 20:42:49.373225.373225 cuda_h.py:10] start move_outputs
DEBUG 01-14 20:42:49.375536.375536 cuda_h.py:19] end move_outputs cost 0.0027179718017578125 seconds
INFO 01-14 20:42:49.379732.379732 client.py:127] Model loaded
DEBUG 01-14 20:42:49.379659.379659 cuda_h.py:19] end wait_experts cost 0.038352012634277344 seconds
DEBUG 01-14 20:42:49.379812.379812 cuda_h.py:10] start gpu_experts
DEBUG 01-14 20:42:49.379920.379920 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-14 20:42:49.379147.379147 cuda_h.py:19] end wait_cetm_experts cost 0.0004093647003173828 seconds
DEBUG 01-14 20:42:49.380732.380732 cuda_h.py:10] start gpu_group_einsum_mp_multi_list
DEBUG 01-14 20:42:49.380919.380919 cuda_h.py:10] start gpu_group_tensor
DEBUG 01-14 20:42:49.380518.380518 cuda_h.py:19] end gpu_group_tensor cost 0.0002465248107910156 seconds
DEBUG 01-14 20:42:49.380118.380118 cuda_h.py:10] start gpu_group_einsum
DEBUG 01-14 20:42:49.381747.381747 cuda_h.py:19] end gpu_group_einsum cost 0.0005204677581787109 seconds
DEBUG 01-14 20:42:49.381062.381062 cuda_h.py:10] start gpu_final_hidden_states_scatter
DEBUG 01-14 20:42:49.381329.381329 cuda_h.py:10] start all_expert_outputs_slices
DEBUG 01-14 20:42:49.381254.381254 cuda_h.py:19] end all_expert_outputs_slices cost 0.00030040740966796875 seconds
DEBUG 01-14 20:42:49.381917.381917 cuda_h.py:10] start concat_expert_out
DEBUG 01-14 20:42:49.381961.381961 cuda_h.py:19] end concat_expert_out cost 6.079673767089844e-05 seconds
DEBUG 01-14 20:42:49.381526.381526 cuda_h.py:10] start index_scatter
DEBUG 01-14 20:42:49.381337.381337 cuda_h.py:19] end index_scatter cost 7.319450378417969e-05 seconds
DEBUG 01-14 20:42:49.381001.381001 cuda_h.py:19] end gpu_final_hidden_states_scatter cost 0.0006854534149169922 seconds
DEBUG 01-14 20:42:49.382824.382824 cuda_h.py:19] end gpu_experts cost 0.0025064945220947266 seconds
DEBUG 01-14 20:42:49.382004.382004 cuda_h.py:10] start all_expert_weight_slices
DEBUG 01-14 20:42:49.383932.383932 cuda_h.py:19] end all_expert_weight_slices cost 0.0009691715240478516 seconds
DEBUG 01-14 20:42:49.383953.383953 cuda_h.py:10] start cpuoutputsdeal
DEBUG 01-14 20:42:49.383908.383908 cuda_h.py:10] start index_scatter
DEBUG 01-14 20:42:49.383421.383421 cuda_h.py:19] end index_scatter cost 4.863739013671875e-05 seconds
DEBUG 01-14 20:42:49.383283.383283 cuda_h.py:19] end cpuoutputsdeal cost 0.0005283355712890625 seconds
DEBUG 01-14 20:42:49.383915.383915 cuda_h.py:19] end layer_moe_generate_mp_l_13 cost 0.06577277183532715 seconds
DEBUG 01-14 20:42:49.384875.384875 cuda_h.py:19] end prefill_layer cost 0.07770442962646484 seconds
DEBUG 01-14 20:42:49.384957.384957 lmp.py:1551] -------------------------------- end prefill layer 12 --------------------------------
DEBUG 01-14 20:42:49.384375.384375 cuda_h.py:10] start prefill_layer
DEBUG 01-14 20:42:49.384316.384316 lmp.py:1494] -------------------------------- start prefill layer 13 --------------------------------
DEBUG 01-14 20:42:49.384542.384542 cuda_h.py:10] start start_load_qkvogn_s_weight_l_14
DEBUG 01-14 20:42:49.384629.384629 cuda_h.py:10] start start_load_qkvogn_s_weight_l_14
DEBUG 01-14 20:42:49.384618.384618 cuda_h.py:19] end start_load_qkvogn_s_weight_l_14 cost 3.4332275390625e-05 seconds
DEBUG 01-14 20:42:49.384945.384945 cuda_h.py:19] end start_load_qkvogn_s_weight_l_14 cost 0.00010275840759277344 seconds
DEBUG 01-14 20:42:49.384740.384740 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-14 20:42:49.384067.384067 cuda_h.py:10] start sllm_worker_task
DEBUG 01-14 20:42:49.384210.384210 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-14 20:42:49.384622.384622 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-14 20:42:49.387085.387085 cuda_h.py:19] end allocate_cuda_memory cost 0.0031096935272216797 seconds
DEBUG 01-14 20:42:49.387564.387564 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-14 20:42:49.387235.387235 sllm_store_c.py:27] get device uuid map
DEBUG 01-14 20:42:49.388349.388349 sllm_store_c.py:29] call client load into gpu
DEBUG 01-14 20:42:49.388767.388767 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, f0ef00a5-91a8-4a94-a39f-cb076cf8e750
DEBUG 01-14 20:42:49.388498.388498 client.py:106] call stub.LoadModelAsync
DEBUG 01-14 20:42:49.388581.388581 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-14 20:42:49.388204.388204 cuda_h.py:10] start self_attn
INFO 01-14 20:42:49.389448.389448 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, f0ef00a5-91a8-4a94-a39f-cb076cf8e750
DEBUG 01-14 20:42:49.389331.389331 cuda_h.py:19] end load_into_gpu_async cost 0.0013005733489990234 seconds
DEBUG 01-14 20:42:49.389603.389603 cuda_h.py:10] start restore_tensors2
DEBUG 01-14 20:42:49.389501.389501 cuda_h.py:19] end restore_tensors2 cost 7.414817810058594e-05 seconds
DEBUG 01-14 20:42:49.389303.389303 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0047419071197509766 seconds
INFO 01-14 20:42:49.389961.389961 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, f0ef00a5-91a8-4a94-a39f-cb076cf8e750
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-14 20:42:49.391736.391736 cuda_h.py:19] end self_attn cost 0.002966642379760742 seconds
DEBUG 01-14 20:42:49.391283.391283 cuda_h.py:19] end iln_self_attn_paln cost 0.0074596405029296875 seconds
DEBUG 01-14 20:42:49.392503.392503 cuda_h.py:10] start layer_moe_generate_mp_l_14
DEBUG 01-14 20:42:49.392312.392312 cuda_h.py:10] start gate
DEBUG 01-14 20:42:49.392354.392354 cuda_h.py:19] end gate cost 0.0006287097930908203 seconds
DEBUG 01-14 20:42:49.392945.392945 cuda_h.py:10] start experts_map_get
DEBUG 01-14 20:42:49.393644.393644 lmp.py:1615] 
DEBUG 01-14 20:42:49.393644.393644 lmp.py:1615] Expert Token Distribution & Device Allocation:
DEBUG 01-14 20:42:49.393069.393069 lmp.py:1616]   Total experts: 64
DEBUG 01-14 20:42:49.393626.393626 lmp.py:1617]   CPU experts: 32 (50%)
DEBUG 01-14 20:42:49.393369.393369 lmp.py:1618]   GPU experts: 32 (50%)
DEBUG 01-14 20:42:49.393965.393965 lmp.py:1619] 
DEBUG 01-14 20:42:49.393965.393965 lmp.py:1619]   Expert ID | Tokens | Device
DEBUG 01-14 20:42:49.393661.393661 lmp.py:1620]   -----------------------------------
DEBUG 01-14 20:42:49.393834.393834 lmp.py:1625]   Expert 42 |     18 | CPU
DEBUG 01-14 20:42:49.393477.393477 lmp.py:1625]   Expert 19 |     23 | CPU
DEBUG 01-14 20:42:49.393882.393882 lmp.py:1625]   Expert 30 |     24 | CPU
DEBUG 01-14 20:42:49.393002.393002 lmp.py:1625]   Expert  6 |     59 | CPU
DEBUG 01-14 20:42:49.393883.393883 lmp.py:1625]   Expert  5 |     66 | CPU
DEBUG 01-14 20:42:49.393288.393288 lmp.py:1625]   Expert 32 |     68 | CPU
DEBUG 01-14 20:42:49.393931.393931 lmp.py:1625]   Expert  1 |     71 | CPU
DEBUG 01-14 20:42:49.393574.393574 lmp.py:1625]   Expert 53 |     99 | CPU
DEBUG 01-14 20:42:49.393978.393978 lmp.py:1625]   Expert 11 |    109 | CPU
DEBUG 01-14 20:42:49.393859.393859 lmp.py:1625]   Expert 18 |    113 | CPU
DEBUG 01-14 20:42:49.393979.393979 lmp.py:1625]   Expert 63 |    131 | CPU
DEBUG 01-14 20:42:49.393099.393099 lmp.py:1625]   Expert 13 |    135 | CPU
DEBUG 01-14 20:42:49.393981.393981 lmp.py:1625]   Expert 59 |    135 | CPU
DEBUG 01-14 20:42:49.393385.393385 lmp.py:1625]   Expert 58 |    138 | CPU
DEBUG 01-14 20:42:49.393551.393551 lmp.py:1625]   Expert 31 |    142 | CPU
DEBUG 01-14 20:42:49.393717.393717 lmp.py:1625]   Expert 26 |    143 | CPU
DEBUG 01-14 20:42:49.393883.393883 lmp.py:1625]   Expert 40 |    143 | CPU
DEBUG 01-14 20:42:49.393288.393288 lmp.py:1625]   Expert 51 |    143 | CPU
DEBUG 01-14 20:42:49.393693.393693 lmp.py:1625]   Expert  4 |    146 | CPU
DEBUG 01-14 20:42:49.393336.393336 lmp.py:1625]   Expert 61 |    147 | CPU
DEBUG 01-14 20:42:49.393217.393217 lmp.py:1625]   Expert 34 |    149 | CPU
DEBUG 01-14 20:42:49.393860.393860 lmp.py:1625]   Expert 20 |    152 | CPU
DEBUG 01-14 20:42:49.393026.393026 lmp.py:1625]   Expert 50 |    152 | CPU
DEBUG 01-14 20:42:49.393431.393431 lmp.py:1625]   Expert 48 |    156 | CPU
DEBUG 01-14 20:42:49.393835.393835 lmp.py:1625]   Expert 56 |    156 | CPU
DEBUG 01-14 20:42:49.393001.393001 lmp.py:1625]   Expert  9 |    161 | CPU
DEBUG 01-14 20:42:49.393406.393406 lmp.py:1625]   Expert 12 |    161 | CPU
DEBUG 01-14 20:42:49.393810.393810 lmp.py:1625]   Expert 35 |    163 | CPU
DEBUG 01-14 20:42:49.393977.393977 lmp.py:1625]   Expert 33 |    168 | CPU
DEBUG 01-14 20:42:49.393620.393620 lmp.py:1625]   Expert 37 |    169 | CPU
DEBUG 01-14 20:42:49.393263.393263 lmp.py:1625]   Expert  2 |    174 | CPU
DEBUG 01-14 20:42:49.393429.393429 lmp.py:1625]   Expert 10 |    174 | CPU
DEBUG 01-14 20:42:49.393595.393595 lmp.py:1625]   Expert 55 |    174 | GPU
DEBUG 01-14 20:42:49.393761.393761 lmp.py:1625]   Expert 36 |    175 | GPU
DEBUG 01-14 20:42:49.393689.393689 lmp.py:1625]   Expert 46 |    175 | GPU
DEBUG 01-14 20:42:49.393855.393855 lmp.py:1625]   Expert 52 |    183 | GPU
DEBUG 01-14 20:42:49.393783.393783 lmp.py:1625]   Expert  8 |    190 | GPU
DEBUG 01-14 20:42:49.393425.393425 lmp.py:1625]   Expert 25 |    200 | GPU
DEBUG 01-14 20:42:49.393068.393068 lmp.py:1625]   Expert 39 |    203 | GPU
DEBUG 01-14 20:42:49.393473.393473 lmp.py:1625]   Expert 57 |    209 | GPU
DEBUG 01-14 20:42:49.393878.393878 lmp.py:1625]   Expert  3 |    211 | GPU
DEBUG 01-14 20:42:49.393044.393044 lmp.py:1625]   Expert 24 |    213 | GPU
DEBUG 01-14 20:42:49.393448.393448 lmp.py:1625]   Expert  0 |    216 | GPU
DEBUG 01-14 20:42:49.393853.393853 lmp.py:1625]   Expert  7 |    236 | GPU
DEBUG 01-14 20:42:49.393019.393019 lmp.py:1625]   Expert 27 |    236 | GPU
DEBUG 01-14 20:42:49.393662.393662 lmp.py:1625]   Expert 62 |    239 | GPU
DEBUG 01-14 20:42:49.394543.394543 lmp.py:1625]   Expert 21 |    240 | GPU
DEBUG 01-14 20:42:49.394709.394709 lmp.py:1625]   Expert 23 |    243 | GPU
DEBUG 01-14 20:42:49.394114.394114 lmp.py:1625]   Expert 38 |    244 | GPU
DEBUG 01-14 20:42:49.394519.394519 lmp.py:1625]   Expert 28 |    263 | GPU
DEBUG 01-14 20:42:49.394446.394446 lmp.py:1625]   Expert 29 |    271 | GPU
DEBUG 01-14 20:42:49.394612.394612 lmp.py:1625]   Expert 60 |    271 | GPU
DEBUG 01-14 20:42:49.394779.394779 lmp.py:1625]   Expert 43 |    273 | GPU
DEBUG 01-14 20:42:49.394660.394660 lmp.py:1625]   Expert 16 |    286 | GPU
DEBUG 01-14 20:42:49.394541.394541 lmp.py:1625]   Expert 49 |    287 | GPU
DEBUG 01-14 20:42:49.394184.394184 lmp.py:1625]   Expert 54 |    287 | GPU
DEBUG 01-14 20:42:49.394350.394350 lmp.py:1625]   Expert 41 |    288 | GPU
DEBUG 01-14 20:42:49.394278.394278 lmp.py:1625]   Expert 15 |    289 | GPU
DEBUG 01-14 20:42:49.394206.394206 lmp.py:1625]   Expert 22 |    294 | GPU
DEBUG 01-14 20:42:49.394372.394372 lmp.py:1625]   Expert 47 |    314 | GPU
DEBUG 01-14 20:42:49.394538.394538 lmp.py:1625]   Expert 44 |    318 | GPU
DEBUG 01-14 20:42:49.394181.394181 lmp.py:1625]   Expert 14 |    372 | GPU
DEBUG 01-14 20:42:49.394824.394824 lmp.py:1625]   Expert 17 |    382 | GPU
DEBUG 01-14 20:42:49.394990.394990 lmp.py:1625]   Expert 45 |    518 | GPU
DEBUG 01-14 20:42:49.394872.394872 lmp.py:1626] 
DEBUG 01-14 20:42:49.394872.394872 lmp.py:1626]   CPU total tokens: 3988 (32.5%)
DEBUG 01-14 20:42:49.394230.394230 lmp.py:1627]   GPU total tokens: 8300 (67.5%)
DEBUG 01-14 20:42:49.394641.394641 cuda_h.py:19] end experts_map_get cost 0.001573324203491211 seconds
DEBUG 01-14 20:42:49.394299.394299 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-14 20:42:49.394480.394480 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-14 20:42:49.394823.394823 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-14 20:42:49.396329.396329 cuda_h.py:19] end allocate_cuda_memory cost 0.0020248889923095703 seconds
DEBUG 01-14 20:42:49.396576.396576 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-14 20:42:49.396624.396624 sllm_store_c.py:27] get device uuid map
DEBUG 01-14 20:42:49.396201.396201 sllm_store_c.py:29] call client load into gpu
DEBUG 01-14 20:42:49.396474.396474 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, ca6ac543-27a0-4018-9054-0a1d7fee873f
DEBUG 01-14 20:42:49.397639.397639 client.py:106] call stub.LoadModelAsync
INFO 01-14 20:42:49.397612.397612 client.py:127] Model loaded
DEBUG 01-14 20:42:49.397153.397153 cuda_h.py:10] start restore2model
DEBUG 01-14 20:42:49.397848.397848 cuda_h.py:19] end restore2model cost 0.00036525726318359375 seconds
DEBUG 01-14 20:42:49.397294.397294 cuda_h.py:19] end sllm_worker_task cost 0.013205528259277344 seconds
INFO 01-14 20:42:49.397330.397330 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, ca6ac543-27a0-4018-9054-0a1d7fee873f
DEBUG 01-14 20:42:49.397127.397127 cuda_h.py:19] end load_into_gpu_async cost 0.0011758804321289062 seconds
DEBUG 01-14 20:42:49.398353.398353 cuda_h.py:10] start restore_tensors2
DEBUG 01-14 20:42:49.398916.398916 cuda_h.py:19] end restore_tensors2 cost 0.0003886222839355469 seconds
DEBUG 01-14 20:42:49.398521.398521 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.003973484039306641 seconds
DEBUG 01-14 20:42:49.398191.398191 cuda_h.py:10] start restore2model
DEBUG 01-14 20:42:49.401292.401292 cuda_h.py:19] end restore2model cost 0.002573251724243164 seconds
DEBUG 01-14 20:42:49.401605.401605 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.006727695465087891 seconds
DEBUG 01-14 20:42:49.401400.401400 cuda_h.py:10] start gpu_sexperts
DEBUG 01-14 20:42:49.401616.401616 cuda_h.py:19] end gpu_sexperts cost 0.0002684593200683594 seconds
DEBUG 01-14 20:42:49.401677.401677 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-14 20:42:49.401380.401380 lmp.py:1683] 
DEBUG 01-14 20:42:49.401380.401380 lmp.py:1683]   Computing 32 experts on CPU...
DEBUG 01-14 20:42:49.401447.401447 cuda_h.py:19] end cpu_experts_submit cost 5.054473876953125e-05 seconds
DEBUG 01-14 20:42:49.401528.401528 cuda_h.py:10] start experts_func_mgpu_group_pad
DEBUG 01-14 20:42:49.403508.403508 cuda_h.py:19] end experts_func_mgpu_group_pad cost 0.0015711784362792969 seconds
DEBUG 01-14 20:42:49.404265.404265 cuda_h.py:10] start gpu_group_list
DEBUG 01-14 20:42:49.404994.404994 cuda_h.py:19] end gpu_group_list cost 0.0003376007080078125 seconds
DEBUG 01-14 20:42:49.404402.404402 mlpmodule.py:1367]  experts func einsum cost 0.07779145240783691 s
DEBUG 01-14 20:42:49.404747.404747 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-14 20:42:49.404619.404619 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.384185791015625e-05 seconds
DEBUG 01-14 20:42:49.405375.405375 cuda_h.py:10] start wait_experts
INFO 01-14 20:42:49.405363.405363 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, ca6ac543-27a0-4018-9054-0a1d7fee873f
DEBUG 01-14 20:42:49.414884.414884 mlpmodule.py:1460] group tensors cost 0.008838653564453125 s
DEBUG 01-14 20:42:49.414983.414983 cuda_h.py:10] start move_flat_hidden2cpu
DEBUG 01-14 20:42:49.419793.419793 cuda_h.py:19] end move_flat_hidden2cpu cost 0.005133152008056641 seconds
DEBUG 01-14 20:42:49.421894.421894 mlpmodule.py:1533] pad cost 0.001539468765258789 s
DEBUG 01-14 20:42:49.421354.421354 mlpmodule.py:1539] create cpu tensor cost 3.600120544433594e-05 s
DEBUG 01-14 20:42:49.423146.423146 mlpmodule.py:1544] move to cpu cost 0.002059459686279297 s
DEBUG 01-14 20:42:49.433220.433220 mlpmodule.py:1558] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-14 20:42:49.433464.433464 mlpmodule.py:1559] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-14 20:42:49.433991.433991 mlpmodule.py:1564] group_w3 first element: -0.0211181640625
WARNING 01-14 20:42:49.434982.434982 mlpmodule.py:1574] start einsum2
DEBUG 01-14 20:42:49.451128.451128 mlpmodule.py:1584] group einsum cost 0.02767777442932129 s
DEBUG 01-14 20:42:49.452231.452231 mlpmodule.py:1593] cpy2cputensor cost 0.0006892681121826172 s
DEBUG 01-14 20:42:49.452053.452053 cuda_h.py:10] start move_outputs
DEBUG 01-14 20:42:49.454954.454954 cuda_h.py:19] end move_outputs cost 0.0021409988403320312 seconds
INFO 01-14 20:42:49.455219.455219 client.py:127] Model loaded
DEBUG 01-14 20:42:49.455490.455490 cuda_h.py:19] end wait_experts cost 0.05045747756958008 seconds
DEBUG 01-14 20:42:49.455651.455651 cuda_h.py:10] start gpu_experts
DEBUG 01-14 20:42:49.455427.455427 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-14 20:42:49.458362.458362 cuda_h.py:19] end wait_cetm_experts cost 0.0029671192169189453 seconds
DEBUG 01-14 20:42:49.458432.458432 cuda_h.py:10] start gpu_group_einsum_mp_multi_list
DEBUG 01-14 20:42:49.458287.458287 cuda_h.py:10] start gpu_group_tensor
DEBUG 01-14 20:42:49.459806.459806 cuda_h.py:19] end gpu_group_tensor cost 0.0002465248107910156 seconds
DEBUG 01-14 20:42:49.459678.459678 cuda_h.py:10] start gpu_group_einsum
DEBUG 01-14 20:42:49.459923.459923 cuda_h.py:19] end gpu_group_einsum cost 0.0005538463592529297 seconds
DEBUG 01-14 20:42:49.459709.459709 cuda_h.py:10] start gpu_final_hidden_states_scatter
DEBUG 01-14 20:42:49.459022.459022 cuda_h.py:10] start all_expert_outputs_slices
DEBUG 01-14 20:42:49.460782.460782 cuda_h.py:19] end all_expert_outputs_slices cost 0.0003173351287841797 seconds
DEBUG 01-14 20:42:49.460306.460306 cuda_h.py:10] start concat_expert_out
DEBUG 01-14 20:42:49.460430.460430 cuda_h.py:19] end concat_expert_out cost 8.869171142578125e-05 seconds
DEBUG 01-14 20:42:49.460525.460525 cuda_h.py:10] start index_scatter
DEBUG 01-14 20:42:49.460959.460959 cuda_h.py:19] end index_scatter cost 7.486343383789062e-05 seconds
DEBUG 01-14 20:42:49.460721.460721 cuda_h.py:19] end gpu_final_hidden_states_scatter cost 0.0007398128509521484 seconds
DEBUG 01-14 20:42:49.460453.460453 cuda_h.py:19] end gpu_experts cost 0.005124807357788086 seconds
DEBUG 01-14 20:42:49.460632.460632 cuda_h.py:10] start all_expert_weight_slices
DEBUG 01-14 20:42:49.461421.461421 cuda_h.py:19] end all_expert_weight_slices cost 0.0009708404541015625 seconds
DEBUG 01-14 20:42:49.461827.461827 cuda_h.py:10] start cpuoutputsdeal
DEBUG 01-14 20:42:49.462749.462749 cuda_h.py:10] start index_scatter
DEBUG 01-14 20:42:49.462030.462030 cuda_h.py:19] end index_scatter cost 4.887580871582031e-05 seconds
DEBUG 01-14 20:42:49.462939.462939 cuda_h.py:19] end cpuoutputsdeal cost 0.0005447864532470703 seconds
DEBUG 01-14 20:42:49.462564.462564 cuda_h.py:19] end layer_moe_generate_mp_l_14 cost 0.07041311264038086 seconds
DEBUG 01-14 20:42:49.462133.462133 cuda_h.py:19] end prefill_layer cost 0.0785837173461914 seconds
DEBUG 01-14 20:42:49.462545.462545 lmp.py:1551] -------------------------------- end prefill layer 13 --------------------------------
DEBUG 01-14 20:42:49.462964.462964 cuda_h.py:10] start prefill_layer
DEBUG 01-14 20:42:49.462905.462905 lmp.py:1494] -------------------------------- start prefill layer 14 --------------------------------
DEBUG 01-14 20:42:49.462131.462131 cuda_h.py:10] start start_load_qkvogn_s_weight_l_15
DEBUG 01-14 20:42:49.463741.463741 cuda_h.py:10] start start_load_qkvogn_s_weight_l_15
DEBUG 01-14 20:42:49.463160.463160 cuda_h.py:19] end start_load_qkvogn_s_weight_l_15 cost 3.528594970703125e-05 seconds
DEBUG 01-14 20:42:49.463393.463393 cuda_h.py:19] end start_load_qkvogn_s_weight_l_15 cost 6.866455078125e-05 seconds
DEBUG 01-14 20:42:49.463758.463758 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-14 20:42:49.463496.463496 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-14 20:42:49.463095.463095 cuda_h.py:10] start sllm_worker_task
DEBUG 01-14 20:42:49.463662.463662 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-14 20:42:49.463074.463074 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-14 20:42:49.467443.467443 cuda_h.py:19] end allocate_cuda_memory cost 0.003847837448120117 seconds
DEBUG 01-14 20:42:49.467445.467445 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-14 20:42:49.467447.467447 sllm_store_c.py:27] get device uuid map
DEBUG 01-14 20:42:49.467607.467607 sllm_store_c.py:29] call client load into gpu
DEBUG 01-14 20:42:49.467787.467787 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, fb40d6c5-9c35-4899-ac4e-4b250f20fc7f
DEBUG 01-14 20:42:49.467571.467571 client.py:106] call stub.LoadModelAsync
DEBUG 01-14 20:42:49.467987.467987 cuda_h.py:10] start self_attn
INFO 01-14 20:42:49.469170.469170 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, fb40d6c5-9c35-4899-ac4e-4b250f20fc7f
DEBUG 01-14 20:42:49.469483.469483 cuda_h.py:19] end load_into_gpu_async cost 0.0016760826110839844 seconds
DEBUG 01-14 20:42:49.469470.469470 cuda_h.py:10] start restore_tensors2
DEBUG 01-14 20:42:49.469368.469368 cuda_h.py:19] end restore_tensors2 cost 7.319450378417969e-05 seconds
DEBUG 01-14 20:42:49.469455.469455 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.005852937698364258 seconds
INFO 01-14 20:42:49.469384.469384 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, fb40d6c5-9c35-4899-ac4e-4b250f20fc7f
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-14 20:42:49.470491.470491 cuda_h.py:19] end self_attn cost 0.0029404163360595703 seconds
DEBUG 01-14 20:42:49.471739.471739 cuda_h.py:19] end iln_self_attn_paln cost 0.008098840713500977 seconds
DEBUG 01-14 20:42:49.471582.471582 cuda_h.py:10] start layer_moe_generate_mp_l_15
DEBUG 01-14 20:42:49.471014.471014 cuda_h.py:10] start gate
DEBUG 01-14 20:42:49.472824.472824 cuda_h.py:19] end gate cost 0.0006330013275146484 seconds
DEBUG 01-14 20:42:49.472369.472369 cuda_h.py:10] start experts_map_get
DEBUG 01-14 20:42:49.472730.472730 lmp.py:1615] 
DEBUG 01-14 20:42:49.472730.472730 lmp.py:1615] Expert Token Distribution & Device Allocation:
DEBUG 01-14 20:42:49.472898.472898 lmp.py:1616]   Total experts: 64
DEBUG 01-14 20:42:49.472269.472269 lmp.py:1617]   CPU experts: 32 (50%)
DEBUG 01-14 20:42:49.472820.472820 lmp.py:1618]   GPU experts: 32 (50%)
DEBUG 01-14 20:42:49.472986.472986 lmp.py:1619] 
DEBUG 01-14 20:42:49.472986.472986 lmp.py:1619]   Expert ID | Tokens | Device
DEBUG 01-14 20:42:49.472152.472152 lmp.py:1620]   -----------------------------------
DEBUG 01-14 20:42:49.472987.472987 lmp.py:1625]   Expert 34 |     18 | CPU
DEBUG 01-14 20:42:49.472392.472392 lmp.py:1625]   Expert  7 |     43 | CPU
DEBUG 01-14 20:42:49.472843.472843 lmp.py:1625]   Expert 13 |     45 | CPU
DEBUG 01-14 20:42:49.472532.472532 lmp.py:1625]   Expert 39 |     83 | CPU
DEBUG 01-14 20:42:49.472744.472744 lmp.py:1625]   Expert 54 |     83 | CPU
DEBUG 01-14 20:42:49.472195.472195 lmp.py:1625]   Expert 18 |     95 | CPU
DEBUG 01-14 20:42:49.472123.472123 lmp.py:1625]   Expert 49 |     95 | CPU
DEBUG 01-14 20:42:49.472289.472289 lmp.py:1625]   Expert 59 |     98 | CPU
DEBUG 01-14 20:42:49.472217.472217 lmp.py:1625]   Expert 16 |    104 | CPU
DEBUG 01-14 20:42:49.472429.472429 lmp.py:1625]   Expert 41 |    106 | CPU
DEBUG 01-14 20:42:49.472880.472880 lmp.py:1625]   Expert 45 |    111 | CPU
DEBUG 01-14 20:42:49.472331.472331 lmp.py:1625]   Expert  0 |    112 | CPU
DEBUG 01-14 20:42:49.472067.472067 lmp.py:1625]   Expert 22 |    116 | CPU
DEBUG 01-14 20:42:49.472902.472902 lmp.py:1625]   Expert 21 |    120 | CPU
DEBUG 01-14 20:42:49.472545.472545 lmp.py:1625]   Expert 52 |    132 | CPU
DEBUG 01-14 20:42:49.472188.472188 lmp.py:1625]   Expert 12 |    140 | CPU
DEBUG 01-14 20:42:49.472592.472592 lmp.py:1625]   Expert  8 |    141 | CPU
DEBUG 01-14 20:42:49.472758.472758 lmp.py:1625]   Expert 17 |    142 | CPU
DEBUG 01-14 20:42:49.472924.472924 lmp.py:1625]   Expert 38 |    142 | CPU
DEBUG 01-14 20:42:49.472329.472329 lmp.py:1625]   Expert 61 |    142 | CPU
DEBUG 01-14 20:42:49.472734.472734 lmp.py:1625]   Expert 35 |    143 | CPU
DEBUG 01-14 20:42:49.472900.472900 lmp.py:1625]   Expert 36 |    156 | CPU
DEBUG 01-14 20:42:49.472066.472066 lmp.py:1625]   Expert 60 |    156 | CPU
DEBUG 01-14 20:42:49.472947.472947 lmp.py:1625]   Expert 48 |    157 | CPU
DEBUG 01-14 20:42:49.472113.472113 lmp.py:1625]   Expert 15 |    158 | CPU
DEBUG 01-14 20:42:49.472041.472041 lmp.py:1625]   Expert 27 |    166 | CPU
DEBUG 01-14 20:42:49.472446.472446 lmp.py:1625]   Expert 31 |    169 | CPU
DEBUG 01-14 20:42:49.472612.472612 lmp.py:1625]   Expert 53 |    176 | CPU
DEBUG 01-14 20:42:49.473540.473540 lmp.py:1625]   Expert 19 |    182 | CPU
DEBUG 01-14 20:42:49.473467.473467 lmp.py:1625]   Expert 40 |    186 | CPU
DEBUG 01-14 20:42:49.473633.473633 lmp.py:1625]   Expert 50 |    186 | CPU
DEBUG 01-14 20:42:49.473561.473561 lmp.py:1625]   Expert 20 |    187 | CPU
DEBUG 01-14 20:42:49.473204.473204 lmp.py:1625]   Expert  4 |    190 | GPU
DEBUG 01-14 20:42:49.473370.473370 lmp.py:1625]   Expert 46 |    191 | GPU
DEBUG 01-14 20:42:49.473536.473536 lmp.py:1625]   Expert 11 |    202 | GPU
DEBUG 01-14 20:42:49.473702.473702 lmp.py:1625]   Expert 30 |    206 | GPU
DEBUG 01-14 20:42:49.473630.473630 lmp.py:1625]   Expert 43 |    210 | GPU
DEBUG 01-14 20:42:49.473558.473558 lmp.py:1625]   Expert 26 |    213 | GPU
DEBUG 01-14 20:42:49.473724.473724 lmp.py:1625]   Expert 29 |    217 | GPU
DEBUG 01-14 20:42:49.473367.473367 lmp.py:1625]   Expert 14 |    220 | GPU
DEBUG 01-14 20:42:49.473778.473778 lmp.py:1625]   Expert  6 |    226 | GPU
DEBUG 01-14 20:42:49.473660.473660 lmp.py:1625]   Expert 57 |    226 | GPU
DEBUG 01-14 20:42:49.473349.473349 lmp.py:1625]   Expert  3 |    241 | GPU
DEBUG 01-14 20:42:49.473277.473277 lmp.py:1625]   Expert 23 |    242 | GPU
DEBUG 01-14 20:42:49.473205.473205 lmp.py:1625]   Expert 33 |    242 | GPU
DEBUG 01-14 20:42:49.473371.473371 lmp.py:1625]   Expert  2 |    246 | GPU
DEBUG 01-14 20:42:49.473060.473060 lmp.py:1625]   Expert 56 |    248 | GPU
DEBUG 01-14 20:42:49.473226.473226 lmp.py:1625]   Expert 42 |    256 | GPU
DEBUG 01-14 20:42:49.473869.473869 lmp.py:1625]   Expert 37 |    259 | GPU
DEBUG 01-14 20:42:49.473035.473035 lmp.py:1625]   Expert  9 |    260 | GPU
DEBUG 01-14 20:42:49.473963.473963 lmp.py:1625]   Expert 32 |    269 | GPU
DEBUG 01-14 20:42:49.473129.473129 lmp.py:1625]   Expert 44 |    273 | GPU
DEBUG 01-14 20:42:49.473057.473057 lmp.py:1625]   Expert 55 |    273 | GPU
DEBUG 01-14 20:42:49.473746.473746 lmp.py:1625]   Expert 51 |    275 | GPU
DEBUG 01-14 20:42:49.473912.473912 lmp.py:1625]   Expert 28 |    277 | GPU
DEBUG 01-14 20:42:49.473840.473840 lmp.py:1625]   Expert 58 |    283 | GPU
DEBUG 01-14 20:42:49.473244.473244 lmp.py:1625]   Expert  1 |    285 | GPU
DEBUG 01-14 20:42:49.473649.473649 lmp.py:1625]   Expert 24 |    286 | GPU
DEBUG 01-14 20:42:49.473577.473577 lmp.py:1625]   Expert 10 |    289 | GPU
DEBUG 01-14 20:42:49.473504.473504 lmp.py:1625]   Expert 63 |    295 | GPU
DEBUG 01-14 20:42:49.473432.473432 lmp.py:1625]   Expert 25 |    307 | GPU
DEBUG 01-14 20:42:49.473360.473360 lmp.py:1625]   Expert 47 |    317 | GPU
DEBUG 01-14 20:42:49.473288.473288 lmp.py:1625]   Expert 62 |    329 | GPU
DEBUG 01-14 20:42:49.473739.473739 lmp.py:1625]   Expert  5 |    345 | GPU
DEBUG 01-14 20:42:49.473858.473858 lmp.py:1626] 
DEBUG 01-14 20:42:49.473858.473858 lmp.py:1626]   CPU total tokens: 4090 (33.3%)
DEBUG 01-14 20:42:49.473978.473978 lmp.py:1627]   GPU total tokens: 8198 (66.7%)
DEBUG 01-14 20:42:49.473866.473866 cuda_h.py:19] end experts_map_get cost 0.0015666484832763672 seconds
DEBUG 01-14 20:42:49.473431.473431 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-14 20:42:49.473321.473321 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-14 20:42:49.473465.473465 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-14 20:42:49.476357.476357 cuda_h.py:19] end allocate_cuda_memory cost 0.0026886463165283203 seconds
DEBUG 01-14 20:42:49.476851.476851 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-14 20:42:49.476038.476038 sllm_store_c.py:27] get device uuid map
DEBUG 01-14 20:42:49.476139.476139 sllm_store_c.py:29] call client load into gpu
DEBUG 01-14 20:42:49.476219.476219 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 159c38f0-b4fc-40e9-88e8-148049692895
DEBUG 01-14 20:42:49.477623.477623 client.py:106] call stub.LoadModelAsync
INFO 01-14 20:42:49.477536.477536 client.py:127] Model loaded
DEBUG 01-14 20:42:49.477373.477373 cuda_h.py:10] start restore2model
DEBUG 01-14 20:42:49.477035.477035 cuda_h.py:19] end restore2model cost 0.0003452301025390625 seconds
DEBUG 01-14 20:42:49.477951.477951 cuda_h.py:19] end sllm_worker_task cost 0.014373779296875 seconds
INFO 01-14 20:42:49.477397.477397 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 159c38f0-b4fc-40e9-88e8-148049692895
DEBUG 01-14 20:42:49.477094.477094 cuda_h.py:19] end load_into_gpu_async cost 0.001092672348022461 seconds
DEBUG 01-14 20:42:49.477605.477605 cuda_h.py:10] start restore_tensors2
DEBUG 01-14 20:42:49.478725.478725 cuda_h.py:19] end restore_tensors2 cost 0.0003781318664550781 seconds
DEBUG 01-14 20:42:49.478561.478561 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0045778751373291016 seconds
DEBUG 01-14 20:42:49.478324.478324 cuda_h.py:10] start restore2model
DEBUG 01-14 20:42:49.481597.481597 cuda_h.py:19] end restore2model cost 0.0025947093963623047 seconds
DEBUG 01-14 20:42:49.481162.481162 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.007357597351074219 seconds
DEBUG 01-14 20:42:49.481435.481435 cuda_h.py:10] start gpu_sexperts
DEBUG 01-14 20:42:49.481372.481372 cuda_h.py:19] end gpu_sexperts cost 0.0002739429473876953 seconds
DEBUG 01-14 20:42:49.481195.481195 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-14 20:42:49.481851.481851 lmp.py:1683] 
DEBUG 01-14 20:42:49.481851.481851 lmp.py:1683]   Computing 32 experts on CPU...
DEBUG 01-14 20:42:49.481588.481588 cuda_h.py:19] end cpu_experts_submit cost 5.173683166503906e-05 seconds
DEBUG 01-14 20:42:49.481384.481384 cuda_h.py:10] start experts_func_mgpu_group_pad
DEBUG 01-14 20:42:49.483841.483841 cuda_h.py:19] end experts_func_mgpu_group_pad cost 0.0015707015991210938 seconds
DEBUG 01-14 20:42:49.484750.484750 cuda_h.py:10] start gpu_group_list
DEBUG 01-14 20:42:49.484029.484029 cuda_h.py:19] end gpu_group_list cost 0.0003554821014404297 seconds
DEBUG 01-14 20:42:49.484245.484245 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-14 20:42:49.484936.484936 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 1.430511474609375e-05 seconds
DEBUG 01-14 20:42:49.484539.484539 cuda_h.py:10] start wait_experts
INFO 01-14 20:42:49.484666.484666 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 159c38f0-b4fc-40e9-88e8-148049692895
DEBUG 01-14 20:42:49.485819.485819 mlpmodule.py:1367]  experts func einsum cost 0.08050417900085449 s
DEBUG 01-14 20:42:49.490151.490151 mlpmodule.py:1460] group tensors cost 0.004297971725463867 s
DEBUG 01-14 20:42:49.490023.490023 cuda_h.py:10] start move_flat_hidden2cpu
DEBUG 01-14 20:42:49.495921.495921 cuda_h.py:19] end move_flat_hidden2cpu cost 0.004952669143676758 seconds
DEBUG 01-14 20:42:49.497328.497328 mlpmodule.py:1533] pad cost 0.001585245132446289 s
DEBUG 01-14 20:42:49.497980.497980 mlpmodule.py:1539] create cpu tensor cost 3.4332275390625e-05 s
DEBUG 01-14 20:42:49.499307.499307 mlpmodule.py:1544] move to cpu cost 0.0022063255310058594 s
DEBUG 01-14 20:42:49.509322.509322 mlpmodule.py:1558] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-14 20:42:49.509016.509016 mlpmodule.py:1559] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-14 20:42:49.510569.510569 mlpmodule.py:1564] group_w3 first element: 0.000789642333984375
WARNING 01-14 20:42:49.510653.510653 mlpmodule.py:1574] start einsum2
DEBUG 01-14 20:42:49.528262.528262 mlpmodule.py:1584] group einsum cost 0.028043270111083984 s
DEBUG 01-14 20:42:49.528003.528003 mlpmodule.py:1593] cpy2cputensor cost 0.0007612705230712891 s
DEBUG 01-14 20:42:49.529369.529369 cuda_h.py:10] start move_outputs
DEBUG 01-14 20:42:49.532930.532930 cuda_h.py:19] end move_outputs cost 0.0030832290649414062 seconds
INFO 01-14 20:42:49.535051.535051 client.py:127] Model loaded
DEBUG 01-14 20:42:49.535653.535653 cuda_h.py:19] end wait_experts cost 0.050635576248168945 seconds
DEBUG 01-14 20:42:49.535953.535953 cuda_h.py:10] start gpu_experts
DEBUG 01-14 20:42:49.535968.535968 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-14 20:42:49.536698.536698 cuda_h.py:19] end wait_cetm_experts cost 0.0008149147033691406 seconds
DEBUG 01-14 20:42:49.536383.536383 cuda_h.py:10] start gpu_group_einsum_mp_multi_list
DEBUG 01-14 20:42:49.536736.536736 cuda_h.py:10] start gpu_group_tensor
DEBUG 01-14 20:42:49.536308.536308 cuda_h.py:19] end gpu_group_tensor cost 0.0002493858337402344 seconds
DEBUG 01-14 20:42:49.536994.536994 cuda_h.py:10] start gpu_group_einsum
DEBUG 01-14 20:42:49.537351.537351 cuda_h.py:19] end gpu_group_einsum cost 0.0006985664367675781 seconds
DEBUG 01-14 20:42:49.537045.537045 cuda_h.py:10] start gpu_final_hidden_states_scatter
DEBUG 01-14 20:42:49.537994.537994 cuda_h.py:10] start all_expert_outputs_slices
DEBUG 01-14 20:42:49.538604.538604 cuda_h.py:19] end all_expert_outputs_slices cost 0.0003757476806640625 seconds
DEBUG 01-14 20:42:49.538506.538506 cuda_h.py:10] start concat_expert_out
DEBUG 01-14 20:42:49.538125.538125 cuda_h.py:19] end concat_expert_out cost 5.817413330078125e-05 seconds
DEBUG 01-14 20:42:49.538989.538989 cuda_h.py:10] start index_scatter
DEBUG 01-14 20:42:49.538992.538992 cuda_h.py:19] end index_scatter cost 7.343292236328125e-05 seconds
DEBUG 01-14 20:42:49.538563.538563 cuda_h.py:19] end gpu_final_hidden_states_scatter cost 0.0007879734039306641 seconds
DEBUG 01-14 20:42:49.538533.538533 cuda_h.py:19] end gpu_experts cost 0.003239870071411133 seconds
DEBUG 01-14 20:42:49.538759.538759 cuda_h.py:10] start all_expert_weight_slices
DEBUG 01-14 20:42:49.539978.539978 cuda_h.py:19] end all_expert_weight_slices cost 0.0009715557098388672 seconds
DEBUG 01-14 20:42:49.539383.539383 cuda_h.py:10] start cpuoutputsdeal
DEBUG 01-14 20:42:49.540113.540113 cuda_h.py:10] start index_scatter
DEBUG 01-14 20:42:49.540434.540434 cuda_h.py:19] end index_scatter cost 4.839897155761719e-05 seconds
DEBUG 01-14 20:42:49.540104.540104 cuda_h.py:19] end cpuoutputsdeal cost 0.0005371570587158203 seconds
DEBUG 01-14 20:42:49.540585.540585 cuda_h.py:19] end layer_moe_generate_mp_l_15 cost 0.06906938552856445 seconds
DEBUG 01-14 20:42:49.540082.540082 cuda_h.py:19] end prefill_layer cost 0.0778648853302002 seconds
DEBUG 01-14 20:42:49.540885.540885 lmp.py:1551] -------------------------------- end prefill layer 14 --------------------------------
DEBUG 01-14 20:42:49.540780.540780 cuda_h.py:10] start prefill_layer
DEBUG 01-14 20:42:49.540675.540675 lmp.py:1494] -------------------------------- start prefill layer 15 --------------------------------
DEBUG 01-14 20:42:49.540855.540855 cuda_h.py:10] start start_load_qkvogn_s_weight_l_16
DEBUG 01-14 20:42:49.541180.541180 cuda_h.py:10] start start_load_qkvogn_s_weight_l_16
DEBUG 01-14 20:42:49.541077.541077 cuda_h.py:19] end start_load_qkvogn_s_weight_l_16 cost 3.552436828613281e-05 seconds
DEBUG 01-14 20:42:49.541548.541548 cuda_h.py:19] end start_load_qkvogn_s_weight_l_16 cost 6.914138793945312e-05 seconds
DEBUG 01-14 20:42:49.541913.541913 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-14 20:42:49.541744.541744 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-14 20:42:49.541965.541965 cuda_h.py:10] start sllm_worker_task
DEBUG 01-14 20:42:49.541485.541485 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-14 20:42:49.541851.541851 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-14 20:42:49.541328.541328 cuda_h.py:19] end allocate_cuda_memory cost 0.0003457069396972656 seconds
DEBUG 01-14 20:42:49.541378.541378 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-14 20:42:49.541671.541671 sllm_store_c.py:27] get device uuid map
DEBUG 01-14 20:42:49.542792.542792 sllm_store_c.py:29] call client load into gpu
DEBUG 01-14 20:42:49.542740.542740 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, e9e916ce-2a58-41fe-b37a-6c796c4a9ce6
DEBUG 01-14 20:42:49.542399.542399 client.py:106] call stub.LoadModelAsync
DEBUG 01-14 20:42:49.542422.542422 cuda_h.py:10] start self_attn
INFO 01-14 20:42:49.543944.543944 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, e9e916ce-2a58-41fe-b37a-6c796c4a9ce6
DEBUG 01-14 20:42:49.543741.543741 cuda_h.py:19] end load_into_gpu_async cost 0.001104593276977539 seconds
DEBUG 01-14 20:42:49.543828.543828 cuda_h.py:10] start restore_tensors2
DEBUG 01-14 20:42:49.543855.543855 cuda_h.py:19] end restore_tensors2 cost 0.00019621849060058594 seconds
DEBUG 01-14 20:42:49.543758.543758 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.001991748809814453 seconds
INFO 01-14 20:42:49.543131.543131 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, e9e916ce-2a58-41fe-b37a-6c796c4a9ce6
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-14 20:42:49.546124.546124 cuda_h.py:19] end self_attn cost 0.0038869380950927734 seconds
DEBUG 01-14 20:42:49.546247.546247 cuda_h.py:19] end iln_self_attn_paln cost 0.005585193634033203 seconds
DEBUG 01-14 20:42:49.546759.546759 cuda_h.py:10] start layer_moe_generate_mp_l_16
DEBUG 01-14 20:42:49.546475.546475 cuda_h.py:10] start gate
DEBUG 01-14 20:42:49.547518.547518 cuda_h.py:19] end gate cost 0.0006606578826904297 seconds
DEBUG 01-14 20:42:49.547209.547209 cuda_h.py:10] start experts_map_get
DEBUG 01-14 20:42:49.547160.547160 lmp.py:1615] 
DEBUG 01-14 20:42:49.547160.547160 lmp.py:1615] Expert Token Distribution & Device Allocation:
DEBUG 01-14 20:42:49.547585.547585 lmp.py:1616]   Total experts: 64
DEBUG 01-14 20:42:49.547334.547334 lmp.py:1617]   CPU experts: 32 (50%)
DEBUG 01-14 20:42:49.547076.547076 lmp.py:1618]   GPU experts: 32 (50%)
DEBUG 01-14 20:42:49.548911.548911 lmp.py:1619] 
DEBUG 01-14 20:42:49.548911.548911 lmp.py:1619]   Expert ID | Tokens | Device
DEBUG 01-14 20:42:49.548747.548747 lmp.py:1620]   -----------------------------------
DEBUG 01-14 20:42:49.548820.548820 lmp.py:1625]   Expert 20 |     72 | CPU
DEBUG 01-14 20:42:49.548940.548940 lmp.py:1625]   Expert  0 |     74 | CPU
DEBUG 01-14 20:42:49.548344.548344 lmp.py:1625]   Expert  7 |     82 | CPU
DEBUG 01-14 20:42:49.548987.548987 lmp.py:1625]   Expert 63 |     82 | CPU
DEBUG 01-14 20:42:49.548630.548630 lmp.py:1625]   Expert 15 |     84 | CPU
DEBUG 01-14 20:42:49.548035.548035 lmp.py:1625]   Expert 41 |     86 | CPU
DEBUG 01-14 20:42:49.548439.548439 lmp.py:1625]   Expert 52 |     86 | CPU
DEBUG 01-14 20:42:49.548844.548844 lmp.py:1625]   Expert 45 |     90 | CPU
DEBUG 01-14 20:42:49.548010.548010 lmp.py:1625]   Expert 28 |     93 | CPU
DEBUG 01-14 20:42:49.548415.548415 lmp.py:1625]   Expert 54 |    104 | CPU
DEBUG 01-14 20:42:49.548581.548581 lmp.py:1625]   Expert 12 |    117 | CPU
DEBUG 01-14 20:42:49.548462.548462 lmp.py:1625]   Expert 62 |    117 | CPU
DEBUG 01-14 20:42:49.548344.548344 lmp.py:1625]   Expert 59 |    118 | CPU
DEBUG 01-14 20:42:49.548748.548748 lmp.py:1625]   Expert 21 |    119 | CPU
DEBUG 01-14 20:42:49.548153.548153 lmp.py:1625]   Expert 55 |    125 | CPU
DEBUG 01-14 20:42:49.548557.548557 lmp.py:1625]   Expert  5 |    126 | CPU
DEBUG 01-14 20:42:49.548723.548723 lmp.py:1625]   Expert 14 |    141 | CPU
DEBUG 01-14 20:42:49.548651.548651 lmp.py:1625]   Expert 34 |    142 | CPU
DEBUG 01-14 20:42:49.548579.548579 lmp.py:1625]   Expert  4 |    147 | CPU
DEBUG 01-14 20:42:49.548268.548268 lmp.py:1625]   Expert 51 |    148 | CPU
DEBUG 01-14 20:42:49.548825.548825 lmp.py:1625]   Expert 13 |    150 | CPU
DEBUG 01-14 20:42:49.548230.548230 lmp.py:1625]   Expert 61 |    154 | CPU
DEBUG 01-14 20:42:49.548111.548111 lmp.py:1625]   Expert  1 |    155 | CPU
DEBUG 01-14 20:42:49.548516.548516 lmp.py:1625]   Expert 40 |    157 | CPU
DEBUG 01-14 20:42:49.548682.548682 lmp.py:1625]   Expert 32 |    161 | CPU
DEBUG 01-14 20:42:49.548610.548610 lmp.py:1625]   Expert 16 |    167 | CPU
DEBUG 01-14 20:42:49.548537.548537 lmp.py:1625]   Expert 42 |    167 | CPU
DEBUG 01-14 20:42:49.548465.548465 lmp.py:1625]   Expert 10 |    168 | CPU
DEBUG 01-14 20:42:49.548154.548154 lmp.py:1625]   Expert 22 |    169 | CPU
DEBUG 01-14 20:42:49.548321.548321 lmp.py:1625]   Expert 11 |    174 | CPU
DEBUG 01-14 20:42:49.548248.548248 lmp.py:1625]   Expert 44 |    174 | CPU
DEBUG 01-14 20:42:49.548176.548176 lmp.py:1625]   Expert  6 |    175 | CPU
DEBUG 01-14 20:42:49.548342.548342 lmp.py:1625]   Expert  2 |    177 | GPU
DEBUG 01-14 20:42:49.548270.548270 lmp.py:1625]   Expert 30 |    180 | GPU
DEBUG 01-14 20:42:49.548959.548959 lmp.py:1625]   Expert 25 |    183 | GPU
DEBUG 01-14 20:42:49.548033.548033 lmp.py:1625]   Expert 35 |    183 | GPU
DEBUG 01-14 20:42:49.548914.548914 lmp.py:1625]   Expert 19 |    185 | GPU
DEBUG 01-14 20:42:49.548080.548080 lmp.py:1625]   Expert 47 |    187 | GPU
DEBUG 01-14 20:42:49.548008.548008 lmp.py:1625]   Expert 56 |    189 | GPU
DEBUG 01-14 20:42:49.548174.548174 lmp.py:1625]   Expert 26 |    190 | GPU
DEBUG 01-14 20:42:49.548863.548863 lmp.py:1625]   Expert 53 |    192 | GPU
DEBUG 01-14 20:42:49.548791.548791 lmp.py:1625]   Expert 24 |    202 | GPU
DEBUG 01-14 20:42:49.548242.548242 lmp.py:1625]   Expert 57 |    204 | GPU
DEBUG 01-14 20:42:49.548931.548931 lmp.py:1625]   Expert 48 |    218 | GPU
DEBUG 01-14 20:42:49.548859.548859 lmp.py:1625]   Expert 50 |    223 | GPU
DEBUG 01-14 20:42:49.548025.548025 lmp.py:1625]   Expert 39 |    232 | GPU
DEBUG 01-14 20:42:49.548668.548668 lmp.py:1625]   Expert 46 |    233 | GPU
DEBUG 01-14 20:42:49.548596.548596 lmp.py:1625]   Expert 37 |    235 | GPU
DEBUG 01-14 20:42:49.548523.548523 lmp.py:1625]   Expert 18 |    237 | GPU
DEBUG 01-14 20:42:49.548451.548451 lmp.py:1625]   Expert  3 |    238 | GPU
DEBUG 01-14 20:42:49.548379.548379 lmp.py:1625]   Expert 29 |    250 | GPU
DEBUG 01-14 20:42:49.548883.548883 lmp.py:1625]   Expert 60 |    253 | GPU
DEBUG 01-14 20:42:49.548526.548526 lmp.py:1625]   Expert 23 |    258 | GPU
DEBUG 01-14 20:42:49.548930.548930 lmp.py:1625]   Expert 31 |    258 | GPU
DEBUG 01-14 20:42:49.548620.548620 lmp.py:1625]   Expert 36 |    258 | GPU
DEBUG 01-14 20:42:49.548309.548309 lmp.py:1625]   Expert 17 |    259 | GPU
DEBUG 01-14 20:42:49.549760.549760 lmp.py:1625]   Expert 38 |    263 | GPU
DEBUG 01-14 20:42:49.549449.549449 lmp.py:1625]   Expert  9 |    274 | GPU
DEBUG 01-14 20:42:49.549139.549139 lmp.py:1625]   Expert  8 |    283 | GPU
DEBUG 01-14 20:42:49.549066.549066 lmp.py:1625]   Expert 27 |    325 | GPU
DEBUG 01-14 20:42:49.549517.549517 lmp.py:1625]   Expert 43 |    367 | GPU
DEBUG 01-14 20:42:49.549445.549445 lmp.py:1625]   Expert 33 |    421 | GPU
DEBUG 01-14 20:42:49.549611.549611 lmp.py:1625]   Expert 58 |    476 | GPU
DEBUG 01-14 20:42:49.549539.549539 lmp.py:1625]   Expert 49 |    531 | GPU
DEBUG 01-14 20:42:49.549182.549182 lmp.py:1626] 
DEBUG 01-14 20:42:49.549182.549182 lmp.py:1626]   CPU total tokens: 4124 (33.6%)
DEBUG 01-14 20:42:49.549301.549301 lmp.py:1627]   GPU total tokens: 8164 (66.4%)
DEBUG 01-14 20:42:49.549190.549190 cuda_h.py:19] end experts_map_get cost 0.0015714168548583984 seconds
DEBUG 01-14 20:42:49.549424.549424 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-14 20:42:49.549459.549459 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-14 20:42:49.549603.549603 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-14 20:42:49.551546.551546 cuda_h.py:19] end allocate_cuda_memory cost 0.0024178028106689453 seconds
DEBUG 01-14 20:42:49.551893.551893 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-14 20:42:49.552887.552887 sllm_store_c.py:27] get device uuid map
DEBUG 01-14 20:42:49.552749.552749 sllm_store_c.py:29] call client load into gpu
DEBUG 01-14 20:42:49.552174.552174 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 9c6b9549-4539-49eb-9ce7-e156889ea0a7
DEBUG 01-14 20:42:49.552724.552724 client.py:106] call stub.LoadModelAsync
INFO 01-14 20:42:49.552585.552585 client.py:127] Model loaded
DEBUG 01-14 20:42:49.552091.552091 cuda_h.py:10] start restore2model
DEBUG 01-14 20:42:49.552707.552707 mlpmodule.py:1367]  experts func einsum cost 0.06701469421386719 s
DEBUG 01-14 20:42:49.553837.553837 cuda_h.py:19] end restore2model cost 0.0006766319274902344 seconds
DEBUG 01-14 20:42:49.553714.553714 cuda_h.py:19] end sllm_worker_task cost 0.011976003646850586 seconds
INFO 01-14 20:42:49.553927.553927 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 9c6b9549-4539-49eb-9ce7-e156889ea0a7
DEBUG 01-14 20:42:49.553008.553008 cuda_h.py:19] end load_into_gpu_async cost 0.0016314983367919922 seconds
DEBUG 01-14 20:42:49.553903.553903 cuda_h.py:10] start restore_tensors2
DEBUG 01-14 20:42:49.554110.554110 cuda_h.py:19] end restore_tensors2 cost 0.0004062652587890625 seconds
DEBUG 01-14 20:42:49.554900.554900 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.004831552505493164 seconds
DEBUG 01-14 20:42:49.554000.554000 cuda_h.py:10] start restore2model
DEBUG 01-14 20:42:49.556723.556723 cuda_h.py:19] end restore2model cost 0.0025758743286132812 seconds
DEBUG 01-14 20:42:49.556758.556758 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.0075910091400146484 seconds
DEBUG 01-14 20:42:49.556415.556415 cuda_h.py:10] start gpu_sexperts
DEBUG 01-14 20:42:49.557637.557637 cuda_h.py:19] end gpu_sexperts cost 0.00027298927307128906 seconds
DEBUG 01-14 20:42:49.557983.557983 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-14 20:42:49.557639.557639 lmp.py:1683] 
DEBUG 01-14 20:42:49.557639.557639 lmp.py:1683]   Computing 32 experts on CPU...
DEBUG 01-14 20:42:49.557529.557529 cuda_h.py:19] end cpu_experts_submit cost 5.8650970458984375e-05 seconds
DEBUG 01-14 20:42:49.557993.557993 cuda_h.py:10] start experts_func_mgpu_group_pad
DEBUG 01-14 20:42:49.561574.561574 mlpmodule.py:1460] group tensors cost 0.004082679748535156 s
DEBUG 01-14 20:42:49.562079.562079 cuda_h.py:10] start move_flat_hidden2cpu
DEBUG 01-14 20:42:49.565347.565347 cuda_h.py:19] end experts_func_mgpu_group_pad cost 0.00775599479675293 seconds
DEBUG 01-14 20:42:49.566751.566751 cuda_h.py:10] start gpu_group_list
DEBUG 01-14 20:42:49.567332.567332 cuda_h.py:19] end gpu_group_list cost 0.00043201446533203125 seconds
DEBUG 01-14 20:42:49.567953.567953 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-14 20:42:49.567434.567434 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.8371810913085938e-05 seconds
DEBUG 01-14 20:42:49.567481.567481 cuda_h.py:10] start wait_experts
INFO 01-14 20:42:49.567052.567052 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 9c6b9549-4539-49eb-9ce7-e156889ea0a7
DEBUG 01-14 20:42:49.569297.569297 cuda_h.py:19] end move_flat_hidden2cpu cost 0.006417751312255859 seconds
DEBUG 01-14 20:42:49.570172.570172 mlpmodule.py:1533] pad cost 0.0015273094177246094 s
DEBUG 01-14 20:42:49.570070.570070 mlpmodule.py:1539] create cpu tensor cost 3.3855438232421875e-05 s
DEBUG 01-14 20:42:49.572637.572637 mlpmodule.py:1544] move to cpu cost 0.00206756591796875 s
DEBUG 01-14 20:42:49.582075.582075 mlpmodule.py:1558] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-14 20:42:49.582306.582306 mlpmodule.py:1559] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-14 20:42:49.582667.582667 mlpmodule.py:1564] group_w3 first element: -0.0595703125
WARNING 01-14 20:42:49.582128.582128 mlpmodule.py:1574] start einsum2
DEBUG 01-14 20:42:49.600489.600489 mlpmodule.py:1584] group einsum cost 0.027341604232788086 s
DEBUG 01-14 20:42:49.601381.601381 mlpmodule.py:1593] cpy2cputensor cost 0.0007064342498779297 s
DEBUG 01-14 20:42:49.601873.601873 cuda_h.py:10] start move_outputs
DEBUG 01-14 20:42:49.603613.603613 cuda_h.py:19] end move_outputs cost 0.002690553665161133 seconds
INFO 01-14 20:42:49.611422.611422 client.py:127] Model loaded
DEBUG 01-14 20:42:49.611507.611507 cuda_h.py:19] end wait_experts cost 0.043820858001708984 seconds
DEBUG 01-14 20:42:49.611813.611813 cuda_h.py:10] start gpu_experts
DEBUG 01-14 20:42:49.611013.611013 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-14 20:42:49.611014.611014 cuda_h.py:19] end wait_cetm_experts cost 0.00018095970153808594 seconds
DEBUG 01-14 20:42:49.611493.611493 cuda_h.py:10] start gpu_group_einsum_mp_multi_list
DEBUG 01-14 20:42:49.611348.611348 cuda_h.py:10] start gpu_group_tensor
DEBUG 01-14 20:42:49.612384.612384 cuda_h.py:19] end gpu_group_tensor cost 0.00024175643920898438 seconds
DEBUG 01-14 20:42:49.612163.612163 cuda_h.py:10] start gpu_group_einsum
DEBUG 01-14 20:42:49.613335.613335 cuda_h.py:19] end gpu_group_einsum cost 0.0007414817810058594 seconds
DEBUG 01-14 20:42:49.613267.613267 cuda_h.py:10] start gpu_final_hidden_states_scatter
DEBUG 01-14 20:42:49.613363.613363 cuda_h.py:10] start all_expert_outputs_slices
DEBUG 01-14 20:42:49.613039.613039 cuda_h.py:19] end all_expert_outputs_slices cost 0.0003886222839355469 seconds
DEBUG 01-14 20:42:49.613517.613517 cuda_h.py:10] start concat_expert_out
DEBUG 01-14 20:42:49.613315.613315 cuda_h.py:19] end concat_expert_out cost 6.031990051269531e-05 seconds
DEBUG 01-14 20:42:49.613880.613880 cuda_h.py:10] start index_scatter
DEBUG 01-14 20:42:49.614738.614738 cuda_h.py:19] end index_scatter cost 7.271766662597656e-05 seconds
DEBUG 01-14 20:42:49.614786.614786 cuda_h.py:19] end gpu_final_hidden_states_scatter cost 0.0007867813110351562 seconds
DEBUG 01-14 20:42:49.614325.614325 cuda_h.py:19] end gpu_experts cost 0.0025959014892578125 seconds
DEBUG 01-14 20:42:49.614220.614220 cuda_h.py:10] start all_expert_weight_slices
DEBUG 01-14 20:42:49.615505.615505 cuda_h.py:19] end all_expert_weight_slices cost 0.0009860992431640625 seconds
DEBUG 01-14 20:42:49.615256.615256 cuda_h.py:10] start cpuoutputsdeal
DEBUG 01-14 20:42:49.615224.615224 cuda_h.py:10] start index_scatter
DEBUG 01-14 20:42:49.615068.615068 cuda_h.py:19] end index_scatter cost 4.744529724121094e-05 seconds
DEBUG 01-14 20:42:49.615692.615692 cuda_h.py:19] end cpuoutputsdeal cost 0.0005393028259277344 seconds
DEBUG 01-14 20:42:49.615549.615549 cuda_h.py:19] end layer_moe_generate_mp_l_16 cost 0.06905484199523926 seconds
DEBUG 01-14 20:42:49.616143.616143 cuda_h.py:19] end prefill_layer cost 0.0752718448638916 seconds
DEBUG 01-14 20:42:49.616907.616907 lmp.py:1551] -------------------------------- end prefill layer 15 --------------------------------
DEBUG 01-14 20:42:49.616510.616510 cuda_h.py:10] start prefill_layer
DEBUG 01-14 20:42:49.616637.616637 lmp.py:1494] -------------------------------- start prefill layer 16 --------------------------------
DEBUG 01-14 20:42:49.616002.616002 cuda_h.py:10] start start_load_qkvogn_s_weight_l_17
DEBUG 01-14 20:42:49.616188.616188 cuda_h.py:10] start start_load_qkvogn_s_weight_l_17
DEBUG 01-14 20:42:49.616548.616548 cuda_h.py:19] end start_load_qkvogn_s_weight_l_17 cost 2.956390380859375e-05 seconds
DEBUG 01-14 20:42:49.616966.616966 cuda_h.py:19] end start_load_qkvogn_s_weight_l_17 cost 5.936622619628906e-05 seconds
DEBUG 01-14 20:42:49.616993.616993 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-14 20:42:49.616935.616935 cuda_h.py:10] start sllm_worker_task
DEBUG 01-14 20:42:49.616139.616139 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-14 20:42:49.616154.616154 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-14 20:42:49.616217.616217 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-14 20:42:49.617219.617219 cuda_h.py:19] end allocate_cuda_memory cost 0.0008044242858886719 seconds
DEBUG 01-14 20:42:49.617414.617414 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-14 20:42:49.617984.617984 sllm_store_c.py:27] get device uuid map
DEBUG 01-14 20:42:49.617383.617383 sllm_store_c.py:29] call client load into gpu
DEBUG 01-14 20:42:49.617563.617563 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 0278383d-157f-45e1-b22d-be57d73aae2b
DEBUG 01-14 20:42:49.617294.617294 client.py:106] call stub.LoadModelAsync
DEBUG 01-14 20:42:49.618173.618173 cuda_h.py:10] start self_attn
INFO 01-14 20:42:49.618373.618373 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 0278383d-157f-45e1-b22d-be57d73aae2b
DEBUG 01-14 20:42:49.619825.619825 cuda_h.py:19] end load_into_gpu_async cost 0.0011813640594482422 seconds
DEBUG 01-14 20:42:49.619105.619105 cuda_h.py:10] start restore_tensors2
DEBUG 01-14 20:42:49.619578.619578 cuda_h.py:19] end restore_tensors2 cost 7.557868957519531e-05 seconds
DEBUG 01-14 20:42:49.619626.619626 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.002323627471923828 seconds
INFO 01-14 20:42:49.619813.619813 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 0278383d-157f-45e1-b22d-be57d73aae2b
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-14 20:42:49.622371.622371 cuda_h.py:19] end self_attn cost 0.0036606788635253906 seconds
DEBUG 01-14 20:42:49.622831.622831 cuda_h.py:19] end iln_self_attn_paln cost 0.005820035934448242 seconds
DEBUG 01-14 20:42:49.622052.622052 cuda_h.py:10] start layer_moe_generate_mp_l_17
DEBUG 01-14 20:42:49.622099.622099 cuda_h.py:10] start gate
DEBUG 01-14 20:42:49.622194.622194 mlpmodule.py:1367]  experts func einsum cost 0.0651242733001709 s
DEBUG 01-14 20:42:49.623927.623927 cuda_h.py:19] end gate cost 0.0007388591766357422 seconds
DEBUG 01-14 20:42:49.623049.623049 cuda_h.py:10] start experts_map_get
DEBUG 01-14 20:42:49.623079.623079 lmp.py:1615] 
DEBUG 01-14 20:42:49.623079.623079 lmp.py:1615] Expert Token Distribution & Device Allocation:
DEBUG 01-14 20:42:49.623074.623074 lmp.py:1616]   Total experts: 64
DEBUG 01-14 20:42:49.623200.623200 lmp.py:1617]   CPU experts: 32 (50%)
DEBUG 01-14 20:42:49.623419.623419 lmp.py:1618]   GPU experts: 32 (50%)
DEBUG 01-14 20:42:49.623539.623539 lmp.py:1619] 
DEBUG 01-14 20:42:49.623539.623539 lmp.py:1619]   Expert ID | Tokens | Device
DEBUG 01-14 20:42:49.623659.623659 lmp.py:1620]   -----------------------------------
DEBUG 01-14 20:42:49.623971.623971 lmp.py:1625]   Expert 58 |     47 | CPU
DEBUG 01-14 20:42:49.623091.623091 lmp.py:1625]   Expert 45 |     48 | CPU
DEBUG 01-14 20:42:49.623734.623734 lmp.py:1625]   Expert 49 |     64 | CPU
DEBUG 01-14 20:42:49.623853.623853 lmp.py:1625]   Expert  4 |     69 | CPU
DEBUG 01-14 20:42:49.623496.623496 lmp.py:1625]   Expert 31 |     69 | CPU
DEBUG 01-14 20:42:49.623901.623901 lmp.py:1625]   Expert 38 |     71 | CPU
DEBUG 01-14 20:42:49.623067.623067 lmp.py:1625]   Expert 43 |     71 | CPU
DEBUG 01-14 20:42:49.623233.623233 lmp.py:1625]   Expert 47 |     74 | CPU
DEBUG 01-14 20:42:49.623399.623399 lmp.py:1625]   Expert 41 |     79 | CPU
DEBUG 01-14 20:42:49.623566.623566 lmp.py:1625]   Expert 14 |     97 | CPU
DEBUG 01-14 20:42:49.623493.623493 lmp.py:1625]   Expert  0 |     99 | CPU
DEBUG 01-14 20:42:49.623136.623136 lmp.py:1625]   Expert 57 |     99 | CPU
DEBUG 01-14 20:42:49.623064.623064 lmp.py:1625]   Expert 51 |    100 | CPU
DEBUG 01-14 20:42:49.623230.623230 lmp.py:1625]   Expert  2 |    111 | CPU
DEBUG 01-14 20:42:49.623158.623158 lmp.py:1625]   Expert 26 |    113 | CPU
DEBUG 01-14 20:42:49.624086.624086 lmp.py:1625]   Expert 11 |    116 | CPU
DEBUG 01-14 20:42:49.624536.624536 lmp.py:1625]   Expert 33 |    117 | CPU
DEBUG 01-14 20:42:49.624703.624703 lmp.py:1625]   Expert 50 |    120 | CPU
DEBUG 01-14 20:42:49.624630.624630 lmp.py:1625]   Expert 55 |    129 | CPU
DEBUG 01-14 20:42:49.624273.624273 lmp.py:1625]   Expert 27 |    133 | CPU
DEBUG 01-14 20:42:49.624439.624439 lmp.py:1625]   Expert 34 |    150 | CPU
DEBUG 01-14 20:42:49.624367.624367 lmp.py:1625]   Expert 28 |    151 | CPU
DEBUG 01-14 20:42:49.624295.624295 lmp.py:1625]   Expert 25 |    157 | CPU
DEBUG 01-14 20:42:49.624223.624223 lmp.py:1625]   Expert  9 |    163 | CPU
DEBUG 01-14 20:42:49.624150.624150 lmp.py:1625]   Expert 13 |    167 | CPU
DEBUG 01-14 20:42:49.624601.624601 lmp.py:1625]   Expert 54 |    178 | CPU
DEBUG 01-14 20:42:49.624529.624529 lmp.py:1625]   Expert  7 |    182 | CPU
DEBUG 01-14 20:42:49.624218.624218 lmp.py:1625]   Expert 48 |    184 | CPU
DEBUG 01-14 20:42:49.624100.624100 lmp.py:1625]   Expert  6 |    186 | CPU
DEBUG 01-14 20:42:49.624743.624743 lmp.py:1625]   Expert 10 |    186 | CPU
DEBUG 01-14 20:42:49.624909.624909 lmp.py:1625]   Expert 56 |    190 | CPU
DEBUG 01-14 20:42:49.624836.624836 lmp.py:1625]   Expert 24 |    200 | CPU
DEBUG 01-14 20:42:49.624003.624003 lmp.py:1625]   Expert 46 |    200 | GPU
DEBUG 01-14 20:42:49.624169.624169 lmp.py:1625]   Expert 61 |    200 | GPU
DEBUG 01-14 20:42:49.624812.624812 lmp.py:1625]   Expert 29 |    203 | GPU
DEBUG 01-14 20:42:49.624455.624455 lmp.py:1625]   Expert 40 |    205 | GPU
DEBUG 01-14 20:42:49.624382.624382 lmp.py:1625]   Expert 63 |    209 | GPU
DEBUG 01-14 20:42:49.624463.624463 lmp.py:1625]   Expert 42 |    218 | GPU
DEBUG 01-14 20:42:49.624867.624867 lmp.py:1625]   Expert  1 |    219 | GPU
DEBUG 01-14 20:42:49.624556.624556 lmp.py:1625]   Expert 21 |    220 | GPU
DEBUG 01-14 20:42:49.624246.624246 lmp.py:1625]   Expert 18 |    223 | GPU
DEBUG 01-14 20:42:49.624174.624174 lmp.py:1625]   Expert 22 |    223 | GPU
DEBUG 01-14 20:42:49.624816.624816 lmp.py:1625]   Expert 12 |    228 | GPU
DEBUG 01-14 20:42:49.624698.624698 lmp.py:1625]   Expert 16 |    231 | GPU
DEBUG 01-14 20:42:49.624102.624102 lmp.py:1625]   Expert 32 |    231 | GPU
DEBUG 01-14 20:42:49.624030.624030 lmp.py:1625]   Expert  3 |    234 | GPU
DEBUG 01-14 20:42:49.624196.624196 lmp.py:1625]   Expert 19 |    240 | GPU
DEBUG 01-14 20:42:49.624362.624362 lmp.py:1625]   Expert 39 |    240 | GPU
DEBUG 01-14 20:42:49.624290.624290 lmp.py:1625]   Expert 36 |    243 | GPU
DEBUG 01-14 20:42:49.624218.624218 lmp.py:1625]   Expert 59 |    244 | GPU
DEBUG 01-14 20:42:49.624861.624861 lmp.py:1625]   Expert  8 |    250 | GPU
DEBUG 01-14 20:42:49.624742.624742 lmp.py:1625]   Expert 37 |    252 | GPU
DEBUG 01-14 20:42:49.624670.624670 lmp.py:1625]   Expert  5 |    254 | GPU
DEBUG 01-14 20:42:49.624598.624598 lmp.py:1625]   Expert 20 |    256 | GPU
DEBUG 01-14 20:42:49.624764.624764 lmp.py:1625]   Expert 30 |    273 | GPU
DEBUG 01-14 20:42:49.624692.624692 lmp.py:1625]   Expert 62 |    286 | GPU
DEBUG 01-14 20:42:49.624619.624619 lmp.py:1625]   Expert 15 |    295 | GPU
DEBUG 01-14 20:42:49.624309.624309 lmp.py:1625]   Expert 35 |    298 | GPU
DEBUG 01-14 20:42:49.624713.624713 lmp.py:1625]   Expert 17 |    311 | GPU
DEBUG 01-14 20:42:49.624879.624879 lmp.py:1625]   Expert 60 |    337 | GPU
DEBUG 01-14 20:42:49.624569.624569 lmp.py:1625]   Expert 23 |    351 | GPU
DEBUG 01-14 20:42:49.624258.624258 lmp.py:1625]   Expert 52 |    359 | GPU
DEBUG 01-14 20:42:49.624947.624947 lmp.py:1625]   Expert 44 |    398 | GPU
DEBUG 01-14 20:42:49.624636.624636 lmp.py:1625]   Expert 53 |    437 | GPU
DEBUG 01-14 20:42:49.624279.624279 lmp.py:1626] 
DEBUG 01-14 20:42:49.624279.624279 lmp.py:1626]   CPU total tokens: 3920 (31.9%)
DEBUG 01-14 20:42:49.624638.624638 lmp.py:1627]   GPU total tokens: 8368 (68.1%)
DEBUG 01-14 20:42:49.624526.624526 cuda_h.py:19] end experts_map_get cost 0.0015521049499511719 seconds
DEBUG 01-14 20:42:49.624521.624521 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-14 20:42:49.625649.625649 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-14 20:42:49.625416.625416 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-14 20:42:49.625554.625554 cuda_h.py:19] end allocate_cuda_memory cost 0.0005235671997070312 seconds
DEBUG 01-14 20:42:49.625450.625450 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-14 20:42:49.625775.625775 sllm_store_c.py:27] get device uuid map
DEBUG 01-14 20:42:49.625439.625439 sllm_store_c.py:29] call client load into gpu
DEBUG 01-14 20:42:49.625611.625611 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 85f8eb89-a467-4cdf-a5eb-2903b5719dc7
DEBUG 01-14 20:42:49.626717.626717 client.py:106] call stub.LoadModelAsync
INFO 01-14 20:42:49.626257.626257 client.py:127] Model loaded
DEBUG 01-14 20:42:49.626822.626822 cuda_h.py:10] start restore2model
DEBUG 01-14 20:42:49.626799.626799 cuda_h.py:19] end restore2model cost 0.00046515464782714844 seconds
INFO 01-14 20:42:49.627683.627683 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 85f8eb89-a467-4cdf-a5eb-2903b5719dc7
DEBUG 01-14 20:42:49.627917.627917 cuda_h.py:19] end sllm_worker_task cost 0.010331392288208008 seconds
DEBUG 01-14 20:42:49.627204.627204 cuda_h.py:19] end load_into_gpu_async cost 0.0013229846954345703 seconds
DEBUG 01-14 20:42:49.627831.627831 cuda_h.py:10] start restore_tensors2
DEBUG 01-14 20:42:49.627196.627196 cuda_h.py:19] end restore_tensors2 cost 0.00037932395935058594 seconds
DEBUG 01-14 20:42:49.627324.627324 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0027201175689697266 seconds
DEBUG 01-14 20:42:49.627471.627471 cuda_h.py:10] start restore2model
DEBUG 01-14 20:42:49.630048.630048 cuda_h.py:19] end restore2model cost 0.0025703907012939453 seconds
DEBUG 01-14 20:42:49.630262.630262 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.005469083786010742 seconds
DEBUG 01-14 20:42:49.630580.630580 cuda_h.py:10] start gpu_sexperts
DEBUG 01-14 20:42:49.630988.630988 cuda_h.py:19] end gpu_sexperts cost 0.00026988983154296875 seconds
DEBUG 01-14 20:42:49.630572.630572 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-14 20:42:49.630706.630706 lmp.py:1683] 
DEBUG 01-14 20:42:49.630706.630706 lmp.py:1683]   Computing 32 experts on CPU...
DEBUG 01-14 20:42:49.630449.630449 cuda_h.py:19] end cpu_experts_submit cost 5.6743621826171875e-05 seconds
DEBUG 01-14 20:42:49.630529.630529 cuda_h.py:10] start experts_func_mgpu_group_pad
DEBUG 01-14 20:42:49.639618.639618 mlpmodule.py:1460] group tensors cost 0.008502960205078125 s
DEBUG 01-14 20:42:49.640204.640204 cuda_h.py:10] start move_flat_hidden2cpu
DEBUG 01-14 20:42:49.646756.646756 cuda_h.py:19] end experts_func_mgpu_group_pad cost 0.015199422836303711 seconds
DEBUG 01-14 20:42:49.648391.648391 cuda_h.py:10] start gpu_group_list
DEBUG 01-14 20:42:49.649063.649063 cuda_h.py:19] end gpu_group_list cost 0.0007395744323730469 seconds
DEBUG 01-14 20:42:49.649861.649861 cuda_h.py:19] end move_flat_hidden2cpu cost 0.008883476257324219 seconds
DEBUG 01-14 20:42:49.649289.649289 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-14 20:42:49.650149.650149 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 3.3855438232421875e-05 seconds
DEBUG 01-14 20:42:49.650184.650184 cuda_h.py:10] start wait_experts
INFO 01-14 20:42:49.650783.650783 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 85f8eb89-a467-4cdf-a5eb-2903b5719dc7
DEBUG 01-14 20:42:49.651463.651463 mlpmodule.py:1533] pad cost 0.0019960403442382812 s
DEBUG 01-14 20:42:49.651726.651726 mlpmodule.py:1539] create cpu tensor cost 3.790855407714844e-05 s
DEBUG 01-14 20:42:49.654972.654972 mlpmodule.py:1544] move to cpu cost 0.002355813980102539 s
DEBUG 01-14 20:42:49.665095.665095 mlpmodule.py:1558] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-14 20:42:49.665319.665319 mlpmodule.py:1559] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-14 20:42:49.665070.665070 mlpmodule.py:1564] group_w3 first element: -0.02490234375
WARNING 01-14 20:42:49.665816.665816 mlpmodule.py:1574] start einsum2
INFO 01-14 20:42:49.682531.682531 client.py:127] Model loaded
DEBUG 01-14 20:42:49.682677.682677 cuda_h.py:19] end wait_experts cost 0.03220248222351074 seconds
DEBUG 01-14 20:42:49.682904.682904 cuda_h.py:10] start gpu_experts
DEBUG 01-14 20:42:49.682310.682310 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-14 20:42:49.684485.684485 mlpmodule.py:1584] group einsum cost 0.03050088882446289 s
DEBUG 01-14 20:42:49.685093.685093 mlpmodule.py:1593] cpy2cputensor cost 0.0007703304290771484 s
DEBUG 01-14 20:42:49.685254.685254 cuda_h.py:10] start move_outputs
DEBUG 01-14 20:42:49.688504.688504 cuda_h.py:19] end move_outputs cost 0.0022935867309570312 seconds
DEBUG 01-14 20:42:49.691816.691816 cuda_h.py:19] end wait_cetm_experts cost 0.00912022590637207 seconds
DEBUG 01-14 20:42:49.691497.691497 cuda_h.py:10] start gpu_group_einsum_mp_multi_list
DEBUG 01-14 20:42:49.691359.691359 cuda_h.py:10] start gpu_group_tensor
DEBUG 01-14 20:42:49.692978.692978 cuda_h.py:19] end gpu_group_tensor cost 0.0002467632293701172 seconds
DEBUG 01-14 20:42:49.692280.692280 cuda_h.py:10] start gpu_group_einsum
DEBUG 01-14 20:42:49.692413.692413 cuda_h.py:19] end gpu_group_einsum cost 0.0005762577056884766 seconds
DEBUG 01-14 20:42:49.693497.693497 cuda_h.py:10] start gpu_final_hidden_states_scatter
DEBUG 01-14 20:42:49.693718.693718 cuda_h.py:10] start all_expert_outputs_slices
DEBUG 01-14 20:42:49.693093.693093 cuda_h.py:19] end all_expert_outputs_slices cost 0.0003154277801513672 seconds
DEBUG 01-14 20:42:49.693571.693571 cuda_h.py:10] start concat_expert_out
DEBUG 01-14 20:42:49.693700.693700 cuda_h.py:19] end concat_expert_out cost 5.7697296142578125e-05 seconds
DEBUG 01-14 20:42:49.693319.693319 cuda_h.py:10] start index_scatter
DEBUG 01-14 20:42:49.693899.693899 cuda_h.py:19] end index_scatter cost 7.62939453125e-05 seconds
DEBUG 01-14 20:42:49.693138.693138 cuda_h.py:19] end gpu_final_hidden_states_scatter cost 0.0007104873657226562 seconds
DEBUG 01-14 20:42:49.693538.693538 cuda_h.py:19] end gpu_experts cost 0.011386632919311523 seconds
DEBUG 01-14 20:42:49.693672.693672 cuda_h.py:10] start all_expert_weight_slices
DEBUG 01-14 20:42:49.694374.694374 cuda_h.py:19] end all_expert_weight_slices cost 0.000978231430053711 seconds
DEBUG 01-14 20:42:49.694972.694972 cuda_h.py:10] start cpuoutputsdeal
DEBUG 01-14 20:42:49.695033.695033 cuda_h.py:10] start index_scatter
DEBUG 01-14 20:42:49.695308.695308 cuda_h.py:19] end index_scatter cost 4.76837158203125e-05 seconds
DEBUG 01-14 20:42:49.695024.695024 cuda_h.py:19] end cpuoutputsdeal cost 0.0005357265472412109 seconds
DEBUG 01-14 20:42:49.695457.695457 cuda_h.py:19] end layer_moe_generate_mp_l_17 cost 0.07319521903991699 seconds
DEBUG 01-14 20:42:49.696908.696908 cuda_h.py:19] end prefill_layer cost 0.07968950271606445 seconds
DEBUG 01-14 20:42:49.696360.696360 lmp.py:1551] -------------------------------- end prefill layer 16 --------------------------------
DEBUG 01-14 20:42:49.696063.696063 cuda_h.py:10] start prefill_layer
DEBUG 01-14 20:42:49.696242.696242 lmp.py:1494] -------------------------------- start prefill layer 17 --------------------------------
DEBUG 01-14 20:42:49.696422.696422 cuda_h.py:10] start start_load_qkvogn_s_weight_l_18
DEBUG 01-14 20:42:49.696940.696940 cuda_h.py:10] start start_load_qkvogn_s_weight_l_18
DEBUG 01-14 20:42:49.696028.696028 cuda_h.py:19] end start_load_qkvogn_s_weight_l_18 cost 3.743171691894531e-05 seconds
DEBUG 01-14 20:42:49.696976.696976 cuda_h.py:19] end start_load_qkvogn_s_weight_l_18 cost 7.152557373046875e-05 seconds
DEBUG 01-14 20:42:49.696626.696626 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-14 20:42:49.696272.696272 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-14 20:42:49.696652.696652 cuda_h.py:10] start sllm_worker_task
DEBUG 01-14 20:42:49.696532.696532 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-14 20:42:49.696521.696521 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-14 20:42:49.701092.701092 cuda_h.py:19] end allocate_cuda_memory cost 0.004766941070556641 seconds
DEBUG 01-14 20:42:49.701077.701077 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-14 20:42:49.701323.701323 sllm_store_c.py:27] get device uuid map
DEBUG 01-14 20:42:49.701550.701550 sllm_store_c.py:29] call client load into gpu
DEBUG 01-14 20:42:49.701730.701730 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, a759966f-630e-44ec-8e33-06bf17e9fc3f
DEBUG 01-14 20:42:49.701568.701568 client.py:106] call stub.LoadModelAsync
DEBUG 01-14 20:42:49.702520.702520 cuda_h.py:10] start self_attn
INFO 01-14 20:42:49.703303.703303 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, a759966f-630e-44ec-8e33-06bf17e9fc3f
DEBUG 01-14 20:42:49.703424.703424 cuda_h.py:19] end load_into_gpu_async cost 0.0014433860778808594 seconds
DEBUG 01-14 20:42:49.703028.703028 cuda_h.py:10] start restore_tensors2
DEBUG 01-14 20:42:49.703018.703018 cuda_h.py:19] end restore_tensors2 cost 7.104873657226562e-05 seconds
DEBUG 01-14 20:42:49.703059.703059 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.006603717803955078 seconds
INFO 01-14 20:42:49.703416.703416 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, a759966f-630e-44ec-8e33-06bf17e9fc3f
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-14 20:42:49.705009.705009 cuda_h.py:19] end self_attn cost 0.0030622482299804688 seconds
DEBUG 01-14 20:42:49.705621.705621 cuda_h.py:19] end iln_self_attn_paln cost 0.009303569793701172 seconds
DEBUG 01-14 20:42:49.705371.705371 cuda_h.py:10] start layer_moe_generate_mp_l_18
DEBUG 01-14 20:42:49.705180.705180 cuda_h.py:10] start gate
DEBUG 01-14 20:42:49.706229.706229 cuda_h.py:19] end gate cost 0.0006310939788818359 seconds
DEBUG 01-14 20:42:49.706820.706820 cuda_h.py:10] start experts_map_get
DEBUG 01-14 20:42:49.706155.706155 lmp.py:1615] 
DEBUG 01-14 20:42:49.706155.706155 lmp.py:1615] Expert Token Distribution & Device Allocation:
DEBUG 01-14 20:42:49.706865.706865 lmp.py:1616]   Total experts: 64
DEBUG 01-14 20:42:49.706991.706991 lmp.py:1617]   CPU experts: 32 (50%)
DEBUG 01-14 20:42:49.706780.706780 lmp.py:1618]   GPU experts: 32 (50%)
DEBUG 01-14 20:42:49.706377.706377 lmp.py:1619] 
DEBUG 01-14 20:42:49.706377.706377 lmp.py:1619]   Expert ID | Tokens | Device
DEBUG 01-14 20:42:49.706735.706735 lmp.py:1620]   -----------------------------------
DEBUG 01-14 20:42:49.706285.706285 lmp.py:1625]   Expert  4 |     13 | CPU
DEBUG 01-14 20:42:49.706405.706405 lmp.py:1625]   Expert 28 |     40 | CPU
DEBUG 01-14 20:42:49.706048.706048 lmp.py:1625]   Expert  7 |     47 | CPU
DEBUG 01-14 20:42:49.706930.706930 lmp.py:1625]   Expert 53 |     65 | CPU
DEBUG 01-14 20:42:49.706096.706096 lmp.py:1625]   Expert 52 |     67 | CPU
DEBUG 01-14 20:42:49.707739.707739 lmp.py:1625]   Expert 43 |     73 | CPU
DEBUG 01-14 20:42:49.707382.707382 lmp.py:1625]   Expert 49 |     85 | CPU
DEBUG 01-14 20:42:49.707025.707025 lmp.py:1625]   Expert 12 |     91 | CPU
DEBUG 01-14 20:42:49.707429.707429 lmp.py:1625]   Expert 60 |     98 | CPU
DEBUG 01-14 20:42:49.707595.707595 lmp.py:1625]   Expert 15 |    100 | CPU
DEBUG 01-14 20:42:49.707000.707000 lmp.py:1625]   Expert 47 |    101 | CPU
DEBUG 01-14 20:42:49.707881.707881 lmp.py:1625]   Expert 33 |    105 | CPU
DEBUG 01-14 20:42:49.707047.707047 lmp.py:1625]   Expert 59 |    105 | CPU
DEBUG 01-14 20:42:49.707929.707929 lmp.py:1625]   Expert 36 |    106 | CPU
DEBUG 01-14 20:42:49.707049.707049 lmp.py:1625]   Expert  2 |    114 | CPU
DEBUG 01-14 20:42:49.707407.707407 lmp.py:1625]   Expert 25 |    120 | CPU
DEBUG 01-14 20:42:49.707811.707811 lmp.py:1625]   Expert  6 |    121 | CPU
DEBUG 01-14 20:42:49.707978.707978 lmp.py:1625]   Expert 50 |    125 | CPU
DEBUG 01-14 20:42:49.707144.707144 lmp.py:1625]   Expert 30 |    126 | CPU
DEBUG 01-14 20:42:49.707548.707548 lmp.py:1625]   Expert 39 |    126 | CPU
DEBUG 01-14 20:42:49.707953.707953 lmp.py:1625]   Expert 24 |    128 | CPU
DEBUG 01-14 20:42:49.707119.707119 lmp.py:1625]   Expert  8 |    130 | CPU
DEBUG 01-14 20:42:49.707000.707000 lmp.py:1625]   Expert 27 |    130 | CPU
DEBUG 01-14 20:42:49.707882.707882 lmp.py:1625]   Expert  3 |    143 | CPU
DEBUG 01-14 20:42:49.707286.707286 lmp.py:1625]   Expert 10 |    147 | CPU
DEBUG 01-14 20:42:49.707691.707691 lmp.py:1625]   Expert 14 |    148 | CPU
DEBUG 01-14 20:42:49.707857.707857 lmp.py:1625]   Expert 38 |    150 | CPU
DEBUG 01-14 20:42:49.707262.707262 lmp.py:1625]   Expert 37 |    152 | CPU
DEBUG 01-14 20:42:49.707905.707905 lmp.py:1625]   Expert 58 |    152 | CPU
DEBUG 01-14 20:42:49.707548.707548 lmp.py:1625]   Expert 32 |    156 | CPU
DEBUG 01-14 20:42:49.707714.707714 lmp.py:1625]   Expert 61 |    158 | CPU
DEBUG 01-14 20:42:49.707118.707118 lmp.py:1625]   Expert 11 |    159 | CPU
DEBUG 01-14 20:42:49.707761.707761 lmp.py:1625]   Expert 40 |    159 | GPU
DEBUG 01-14 20:42:49.707404.707404 lmp.py:1625]   Expert 31 |    161 | GPU
DEBUG 01-14 20:42:49.707570.707570 lmp.py:1625]   Expert 19 |    163 | GPU
DEBUG 01-14 20:42:49.707975.707975 lmp.py:1625]   Expert 41 |    163 | GPU
DEBUG 01-14 20:42:49.707141.707141 lmp.py:1625]   Expert 54 |    163 | GPU
DEBUG 01-14 20:42:49.707546.707546 lmp.py:1625]   Expert 22 |    169 | GPU
DEBUG 01-14 20:42:49.707473.707473 lmp.py:1625]   Expert 46 |    171 | GPU
DEBUG 01-14 20:42:49.707116.707116 lmp.py:1625]   Expert 57 |    174 | GPU
DEBUG 01-14 20:42:49.707998.707998 lmp.py:1625]   Expert 18 |    177 | GPU
DEBUG 01-14 20:42:49.707164.707164 lmp.py:1625]   Expert 42 |    180 | GPU
DEBUG 01-14 20:42:49.707330.707330 lmp.py:1625]   Expert 34 |    186 | GPU
DEBUG 01-14 20:42:49.707496.707496 lmp.py:1625]   Expert 26 |    187 | GPU
DEBUG 01-14 20:42:49.707954.707954 lmp.py:1625]   Expert 56 |    192 | GPU
DEBUG 01-14 20:42:49.707881.707881 lmp.py:1625]   Expert 44 |    193 | GPU
DEBUG 01-14 20:42:49.707048.707048 lmp.py:1625]   Expert  1 |    205 | GPU
DEBUG 01-14 20:42:49.707452.707452 lmp.py:1625]   Expert  0 |    217 | GPU
DEBUG 01-14 20:42:49.707095.707095 lmp.py:1625]   Expert 20 |    226 | GPU
DEBUG 01-14 20:42:49.707738.707738 lmp.py:1625]   Expert 48 |    231 | GPU
DEBUG 01-14 20:42:49.707904.707904 lmp.py:1625]   Expert 51 |    231 | GPU
DEBUG 01-14 20:42:49.707832.707832 lmp.py:1625]   Expert 29 |    239 | GPU
DEBUG 01-14 20:42:49.707760.707760 lmp.py:1625]   Expert 55 |    240 | GPU
DEBUG 01-14 20:42:49.707687.707687 lmp.py:1625]   Expert 35 |    244 | GPU
DEBUG 01-14 20:42:49.707615.707615 lmp.py:1625]   Expert 21 |    247 | GPU
DEBUG 01-14 20:42:49.707781.707781 lmp.py:1625]   Expert 45 |    254 | GPU
DEBUG 01-14 20:42:49.707947.707947 lmp.py:1625]   Expert 16 |    257 | GPU
DEBUG 01-14 20:42:49.707829.707829 lmp.py:1625]   Expert  5 |    295 | GPU
DEBUG 01-14 20:42:49.707995.707995 lmp.py:1625]   Expert 13 |    372 | GPU
DEBUG 01-14 20:42:49.707161.707161 lmp.py:1625]   Expert 23 |    378 | GPU
DEBUG 01-14 20:42:49.707566.707566 lmp.py:1625]   Expert 17 |    417 | GPU
DEBUG 01-14 20:42:49.707970.707970 lmp.py:1625]   Expert 63 |    477 | GPU
DEBUG 01-14 20:42:49.708659.708659 lmp.py:1625]   Expert  9 |    506 | GPU
DEBUG 01-14 20:42:49.708826.708826 lmp.py:1625]   Expert 62 |   1233 | GPU
DEBUG 01-14 20:42:49.708661.708661 lmp.py:1626] 
DEBUG 01-14 20:42:49.708661.708661 lmp.py:1626]   CPU total tokens: 3581 (29.1%)
DEBUG 01-14 20:42:49.708496.708496 lmp.py:1627]   GPU total tokens: 8707 (70.9%)
DEBUG 01-14 20:42:49.708622.708622 cuda_h.py:19] end experts_map_get cost 0.0015807151794433594 seconds
DEBUG 01-14 20:42:49.708757.708757 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-14 20:42:49.708169.708169 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-14 20:42:49.708929.708929 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-14 20:42:49.710879.710879 cuda_h.py:19] end allocate_cuda_memory cost 0.0024034976959228516 seconds
DEBUG 01-14 20:42:49.710050.710050 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-14 20:42:49.711649.711649 sllm_store_c.py:27] get device uuid map
DEBUG 01-14 20:42:49.711289.711289 sllm_store_c.py:29] call client load into gpu
DEBUG 01-14 20:42:49.711059.711059 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, b459f0d3-62ec-4baf-a67f-04269ef304d7
DEBUG 01-14 20:42:49.711987.711987 client.py:106] call stub.LoadModelAsync
INFO 01-14 20:42:49.711893.711893 client.py:127] Model loaded
DEBUG 01-14 20:42:49.711730.711730 cuda_h.py:10] start restore2model
DEBUG 01-14 20:42:49.712119.712119 cuda_h.py:19] end restore2model cost 0.0003273487091064453 seconds
DEBUG 01-14 20:42:49.712981.712981 cuda_h.py:19] end sllm_worker_task cost 0.01561594009399414 seconds
INFO 01-14 20:42:49.712717.712717 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, b459f0d3-62ec-4baf-a67f-04269ef304d7
DEBUG 01-14 20:42:49.712468.712468 cuda_h.py:19] end load_into_gpu_async cost 0.0019125938415527344 seconds
DEBUG 01-14 20:42:49.712170.712170 cuda_h.py:10] start restore_tensors2
DEBUG 01-14 20:42:49.713839.713839 cuda_h.py:19] end restore_tensors2 cost 0.00036072731018066406 seconds
DEBUG 01-14 20:42:49.713198.713198 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.005193948745727539 seconds
DEBUG 01-14 20:42:49.713869.713869 cuda_h.py:10] start restore2model
DEBUG 01-14 20:42:49.714439.714439 mlpmodule.py:1367]  experts func einsum cost 0.08306598663330078 s
DEBUG 01-14 20:42:49.716288.716288 cuda_h.py:19] end restore2model cost 0.0033953189849853516 seconds
DEBUG 01-14 20:42:49.716126.716126 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.00881195068359375 seconds
DEBUG 01-14 20:42:49.717398.717398 cuda_h.py:10] start gpu_sexperts
DEBUG 01-14 20:42:49.717627.717627 cuda_h.py:19] end gpu_sexperts cost 0.00027751922607421875 seconds
DEBUG 01-14 20:42:49.717026.717026 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-14 20:42:49.717636.717636 lmp.py:1683] 
DEBUG 01-14 20:42:49.717636.717636 lmp.py:1683]   Computing 32 experts on CPU...
DEBUG 01-14 20:42:49.717148.717148 cuda_h.py:19] end cpu_experts_submit cost 6.079673767089844e-05 seconds
DEBUG 01-14 20:42:49.717997.717997 cuda_h.py:10] start experts_func_mgpu_group_pad
DEBUG 01-14 20:42:49.729599.729599 mlpmodule.py:1460] group tensors cost 0.011744260787963867 s
DEBUG 01-14 20:42:49.730851.730851 cuda_h.py:10] start move_flat_hidden2cpu
DEBUG 01-14 20:42:49.733936.733936 cuda_h.py:19] end experts_func_mgpu_group_pad cost 0.01611924171447754 seconds
DEBUG 01-14 20:42:49.735301.735301 cuda_h.py:10] start gpu_group_list
DEBUG 01-14 20:42:49.736198.736198 cuda_h.py:19] end gpu_group_list cost 0.0005381107330322266 seconds
DEBUG 01-14 20:42:49.736258.736258 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-14 20:42:49.736065.736065 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 3.0517578125e-05 seconds
DEBUG 01-14 20:42:49.736603.736603 cuda_h.py:10] start wait_experts
INFO 01-14 20:42:49.736565.736565 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, b459f0d3-62ec-4baf-a67f-04269ef304d7
DEBUG 01-14 20:42:49.737094.737094 cuda_h.py:19] end move_flat_hidden2cpu cost 0.0066187381744384766 seconds
DEBUG 01-14 20:42:49.738792.738792 mlpmodule.py:1533] pad cost 0.0015213489532470703 s
DEBUG 01-14 20:42:49.738066.738066 mlpmodule.py:1539] create cpu tensor cost 3.504753112792969e-05 s
DEBUG 01-14 20:42:49.740005.740005 mlpmodule.py:1544] move to cpu cost 0.0018851757049560547 s
DEBUG 01-14 20:42:49.750584.750584 mlpmodule.py:1558] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-14 20:42:49.750278.750278 mlpmodule.py:1559] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-14 20:42:49.750447.750447 mlpmodule.py:1564] group_w3 first element: 0.00457763671875
WARNING 01-14 20:42:49.750610.750610 mlpmodule.py:1574] start einsum2
DEBUG 01-14 20:42:49.767821.767821 mlpmodule.py:1584] group einsum cost 0.0268552303314209 s
INFO 01-14 20:42:49.768364.768364 client.py:127] Model loaded
DEBUG 01-14 20:42:49.768999.768999 mlpmodule.py:1593] cpy2cputensor cost 0.0009706020355224609 s
DEBUG 01-14 20:42:49.768613.768613 cuda_h.py:19] end wait_experts cost 0.032273292541503906 seconds
DEBUG 01-14 20:42:49.768470.768470 cuda_h.py:10] start move_outputs
DEBUG 01-14 20:42:49.769513.769513 cuda_h.py:10] start gpu_experts
DEBUG 01-14 20:42:49.769221.769221 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-14 20:42:49.771307.771307 cuda_h.py:19] end move_outputs cost 0.001865386962890625 seconds
DEBUG 01-14 20:42:49.774118.774118 cuda_h.py:19] end wait_cetm_experts cost 0.005384683609008789 seconds
DEBUG 01-14 20:42:49.774658.774658 cuda_h.py:10] start gpu_group_einsum_mp_multi_list
DEBUG 01-14 20:42:49.774660.774660 cuda_h.py:10] start gpu_group_tensor
DEBUG 01-14 20:42:49.775887.775887 cuda_h.py:19] end gpu_group_tensor cost 0.0002410411834716797 seconds
DEBUG 01-14 20:42:49.775428.775428 cuda_h.py:10] start gpu_group_einsum
DEBUG 01-14 20:42:49.790955.790955 mlpmodule.py:1367]  experts func einsum cost 0.0724635124206543 s
DEBUG 01-14 20:42:49.791733.791733 cuda_h.py:19] end gpu_group_einsum cost 0.01578211784362793 seconds
DEBUG 01-14 20:42:49.791020.791020 cuda_h.py:10] start gpu_final_hidden_states_scatter
DEBUG 01-14 20:42:49.791679.791679 cuda_h.py:10] start all_expert_outputs_slices
DEBUG 01-14 20:42:49.791649.791649 cuda_h.py:19] end all_expert_outputs_slices cost 0.00043487548828125 seconds
DEBUG 01-14 20:42:49.792300.792300 cuda_h.py:10] start concat_expert_out
DEBUG 01-14 20:42:49.792133.792133 cuda_h.py:19] end concat_expert_out cost 0.00010418891906738281 seconds
DEBUG 01-14 20:42:49.792236.792236 cuda_h.py:10] start index_scatter
DEBUG 01-14 20:42:49.792626.792626 cuda_h.py:19] end index_scatter cost 0.00012087821960449219 seconds
DEBUG 01-14 20:42:49.792053.792053 cuda_h.py:19] end gpu_final_hidden_states_scatter cost 0.001104116439819336 seconds
DEBUG 01-14 20:42:49.792898.792898 cuda_h.py:19] end gpu_experts cost 0.02340531349182129 seconds
DEBUG 01-14 20:42:49.792012.792012 cuda_h.py:10] start all_expert_weight_slices
DEBUG 01-14 20:42:49.794058.794058 cuda_h.py:19] end all_expert_weight_slices cost 0.001522064208984375 seconds
DEBUG 01-14 20:42:49.794829.794829 cuda_h.py:10] start cpuoutputsdeal
DEBUG 01-14 20:42:49.795276.795276 cuda_h.py:10] start index_scatter
DEBUG 01-14 20:42:49.795752.795752 cuda_h.py:19] end index_scatter cost 8.511543273925781e-05 seconds
DEBUG 01-14 20:42:49.795324.795324 cuda_h.py:19] end cpuoutputsdeal cost 0.0008745193481445312 seconds
DEBUG 01-14 20:42:49.795017.795017 cuda_h.py:19] end layer_moe_generate_mp_l_18 cost 0.08965873718261719 seconds
DEBUG 01-14 20:42:49.795068.795068 cuda_h.py:19] end prefill_layer cost 0.09978771209716797 seconds
DEBUG 01-14 20:42:49.796375.796375 lmp.py:1551] -------------------------------- end prefill layer 17 --------------------------------
DEBUG 01-14 20:42:49.796390.796390 cuda_h.py:10] start prefill_layer
DEBUG 01-14 20:42:49.796074.796074 lmp.py:1494] -------------------------------- start prefill layer 18 --------------------------------
DEBUG 01-14 20:42:49.796281.796281 cuda_h.py:10] start start_load_qkvogn_s_weight_l_19
DEBUG 01-14 20:42:49.796587.796587 cuda_h.py:10] start start_load_qkvogn_s_weight_l_19
DEBUG 01-14 20:42:49.796623.796623 cuda_h.py:19] end start_load_qkvogn_s_weight_l_19 cost 4.7206878662109375e-05 seconds
DEBUG 01-14 20:42:49.796645.796645 cuda_h.py:19] end start_load_qkvogn_s_weight_l_19 cost 0.00010323524475097656 seconds
DEBUG 01-14 20:42:49.796481.796481 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-14 20:42:49.796889.796889 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-14 20:42:49.796073.796073 cuda_h.py:10] start sllm_worker_task
DEBUG 01-14 20:42:49.796170.796170 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-14 20:42:49.796915.796915 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-14 20:42:49.797444.797444 cuda_h.py:19] end allocate_cuda_memory cost 0.00032210350036621094 seconds
DEBUG 01-14 20:42:49.797873.797873 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-14 20:42:49.797153.797153 sllm_store_c.py:27] get device uuid map
DEBUG 01-14 20:42:49.797308.797308 sllm_store_c.py:29] call client load into gpu
DEBUG 01-14 20:42:49.797476.797476 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, eb6208b3-8536-474f-ac86-07f7cbb57fa0
DEBUG 01-14 20:42:49.797858.797858 client.py:106] call stub.LoadModelAsync
DEBUG 01-14 20:42:49.798455.798455 cuda_h.py:10] start self_attn
INFO 01-14 20:42:49.799271.799271 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, eb6208b3-8536-474f-ac86-07f7cbb57fa0
DEBUG 01-14 20:42:49.799275.799275 cuda_h.py:19] end load_into_gpu_async cost 0.001878976821899414 seconds
DEBUG 01-14 20:42:49.799584.799584 cuda_h.py:10] start restore_tensors2
DEBUG 01-14 20:42:49.800409.800409 cuda_h.py:19] end restore_tensors2 cost 0.0001456737518310547 seconds
DEBUG 01-14 20:42:49.800844.800844 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0032372474670410156 seconds
INFO 01-14 20:42:49.800365.800365 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, eb6208b3-8536-474f-ac86-07f7cbb57fa0
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-14 20:42:49.802343.802343 cuda_h.py:19] end self_attn cost 0.004660367965698242 seconds
DEBUG 01-14 20:42:49.803131.803131 cuda_h.py:19] end iln_self_attn_paln cost 0.0068874359130859375 seconds
DEBUG 01-14 20:42:49.803802.803802 cuda_h.py:10] start layer_moe_generate_mp_l_19
DEBUG 01-14 20:42:49.803340.803340 cuda_h.py:10] start gate
DEBUG 01-14 20:42:49.804174.804174 cuda_h.py:19] end gate cost 0.0007457733154296875 seconds
DEBUG 01-14 20:42:49.804594.804594 cuda_h.py:10] start experts_map_get
DEBUG 01-14 20:42:49.804866.804866 lmp.py:1615] 
DEBUG 01-14 20:42:49.804866.804866 lmp.py:1615] Expert Token Distribution & Device Allocation:
DEBUG 01-14 20:42:49.804496.804496 lmp.py:1616]   Total experts: 64
DEBUG 01-14 20:42:49.804259.804259 lmp.py:1617]   CPU experts: 32 (50%)
DEBUG 01-14 20:42:49.804677.804677 lmp.py:1618]   GPU experts: 32 (50%)
DEBUG 01-14 20:42:49.804380.804380 lmp.py:1619] 
DEBUG 01-14 20:42:49.804380.804380 lmp.py:1619]   Expert ID | Tokens | Device
DEBUG 01-14 20:42:49.804891.804891 lmp.py:1620]   -----------------------------------
DEBUG 01-14 20:42:49.804594.804594 lmp.py:1625]   Expert 32 |     49 | CPU
DEBUG 01-14 20:42:49.804581.804581 lmp.py:1625]   Expert  5 |     54 | CPU
DEBUG 01-14 20:42:49.804377.804377 lmp.py:1625]   Expert 30 |     55 | CPU
DEBUG 01-14 20:42:49.805934.805934 lmp.py:1625]   Expert 46 |     59 | CPU
DEBUG 01-14 20:42:49.805253.805253 lmp.py:1625]   Expert 12 |     96 | CPU
DEBUG 01-14 20:42:49.805525.805525 lmp.py:1625]   Expert  8 |     97 | CPU
DEBUG 01-14 20:42:49.805274.805274 lmp.py:1625]   Expert 40 |    100 | CPU
DEBUG 01-14 20:42:49.805500.805500 lmp.py:1625]   Expert 60 |    100 | CPU
DEBUG 01-14 20:42:49.805819.805819 lmp.py:1625]   Expert 27 |    104 | CPU
DEBUG 01-14 20:42:49.805376.805376 lmp.py:1625]   Expert 28 |    113 | CPU
DEBUG 01-14 20:42:49.805695.805695 lmp.py:1625]   Expert 41 |    114 | CPU
DEBUG 01-14 20:42:49.805775.805775 lmp.py:1625]   Expert 17 |    116 | CPU
DEBUG 01-14 20:42:49.805855.805855 lmp.py:1625]   Expert 21 |    119 | CPU
DEBUG 01-14 20:42:49.805936.805936 lmp.py:1625]   Expert 29 |    119 | CPU
DEBUG 01-14 20:42:49.805778.805778 lmp.py:1625]   Expert  3 |    120 | CPU
DEBUG 01-14 20:42:49.805858.805858 lmp.py:1625]   Expert 25 |    121 | CPU
DEBUG 01-14 20:42:49.805938.805938 lmp.py:1625]   Expert  6 |    129 | CPU
DEBUG 01-14 20:42:49.805018.805018 lmp.py:1625]   Expert 54 |    130 | CPU
DEBUG 01-14 20:42:49.805337.805337 lmp.py:1625]   Expert 35 |    132 | CPU
DEBUG 01-14 20:42:49.805656.805656 lmp.py:1625]   Expert 58 |    132 | CPU
DEBUG 01-14 20:42:49.805498.805498 lmp.py:1625]   Expert 19 |    137 | CPU
DEBUG 01-14 20:42:49.805770.805770 lmp.py:1625]   Expert 52 |    142 | CPU
DEBUG 01-14 20:42:49.805850.805850 lmp.py:1625]   Expert  0 |    144 | CPU
DEBUG 01-14 20:42:49.805215.805215 lmp.py:1625]   Expert 37 |    144 | CPU
DEBUG 01-14 20:42:49.805819.805819 lmp.py:1625]   Expert  9 |    155 | CPU
DEBUG 01-14 20:42:49.805661.805661 lmp.py:1625]   Expert 63 |    156 | CPU
DEBUG 01-14 20:42:49.805847.805847 lmp.py:1625]   Expert 48 |    161 | CPU
DEBUG 01-14 20:42:49.805404.805404 lmp.py:1625]   Expert 53 |    164 | CPU
DEBUG 01-14 20:42:49.805485.805485 lmp.py:1625]   Expert 36 |    168 | CPU
DEBUG 01-14 20:42:49.805234.805234 lmp.py:1625]   Expert 56 |    172 | CPU
DEBUG 01-14 20:42:49.805983.805983 lmp.py:1625]   Expert  1 |    173 | CPU
DEBUG 01-14 20:42:49.805971.805971 lmp.py:1625]   Expert 59 |    175 | CPU
DEBUG 01-14 20:42:49.805289.805289 lmp.py:1625]   Expert 47 |    190 | GPU
DEBUG 01-14 20:42:49.805846.805846 lmp.py:1625]   Expert 20 |    197 | GPU
DEBUG 01-14 20:42:49.805927.805927 lmp.py:1625]   Expert 39 |    201 | GPU
DEBUG 01-14 20:42:49.805007.805007 lmp.py:1625]   Expert 42 |    204 | GPU
DEBUG 01-14 20:42:49.805564.805564 lmp.py:1625]   Expert 61 |    208 | GPU
DEBUG 01-14 20:42:49.805883.805883 lmp.py:1625]   Expert 34 |    215 | GPU
DEBUG 01-14 20:42:49.805301.805301 lmp.py:1625]   Expert  7 |    218 | GPU
DEBUG 01-14 20:42:49.805573.805573 lmp.py:1625]   Expert 57 |    218 | GPU
DEBUG 01-14 20:42:49.805322.805322 lmp.py:1625]   Expert 13 |    220 | GPU
DEBUG 01-14 20:42:49.805641.805641 lmp.py:1625]   Expert 11 |    224 | GPU
DEBUG 01-14 20:42:49.805245.805245 lmp.py:1625]   Expert 18 |    226 | GPU
DEBUG 01-14 20:42:49.805563.805563 lmp.py:1625]   Expert 16 |    229 | GPU
DEBUG 01-14 20:42:49.806882.806882 lmp.py:1625]   Expert 55 |    234 | GPU
DEBUG 01-14 20:42:49.806201.806201 lmp.py:1625]   Expert 15 |    247 | GPU
DEBUG 01-14 20:42:49.806857.806857 lmp.py:1625]   Expert 49 |    247 | GPU
DEBUG 01-14 20:42:49.806130.806130 lmp.py:1625]   Expert 50 |    248 | GPU
DEBUG 01-14 20:42:49.806640.806640 lmp.py:1625]   Expert 43 |    249 | GPU
DEBUG 01-14 20:42:49.806197.806197 lmp.py:1625]   Expert  4 |    253 | GPU
DEBUG 01-14 20:42:49.806516.806516 lmp.py:1625]   Expert 51 |    253 | GPU
DEBUG 01-14 20:42:49.806073.806073 lmp.py:1625]   Expert  2 |    257 | GPU
DEBUG 01-14 20:42:49.806392.806392 lmp.py:1625]   Expert 22 |    257 | GPU
DEBUG 01-14 20:42:49.806711.806711 lmp.py:1625]   Expert 45 |    258 | GPU
DEBUG 01-14 20:42:49.806268.806268 lmp.py:1625]   Expert 33 |    259 | GPU
DEBUG 01-14 20:42:49.806302.806302 lmp.py:1625]   Expert 31 |    264 | GPU
DEBUG 01-14 20:42:49.806051.806051 lmp.py:1625]   Expert 38 |    275 | GPU
DEBUG 01-14 20:42:49.806608.806608 lmp.py:1625]   Expert 44 |    284 | GPU
DEBUG 01-14 20:42:49.806688.806688 lmp.py:1625]   Expert 26 |    291 | GPU
DEBUG 01-14 20:42:49.806530.806530 lmp.py:1625]   Expert 23 |    295 | GPU
DEBUG 01-14 20:42:49.806849.806849 lmp.py:1625]   Expert 10 |    306 | GPU
DEBUG 01-14 20:42:49.806644.806644 lmp.py:1625]   Expert 14 |    306 | GPU
DEBUG 01-14 20:42:49.806963.806963 lmp.py:1625]   Expert 24 |    306 | GPU
DEBUG 01-14 20:42:49.806520.806520 lmp.py:1625]   Expert 62 |    699 | GPU
DEBUG 01-14 20:42:49.806985.806985 lmp.py:1626] 
DEBUG 01-14 20:42:49.806985.806985 lmp.py:1626]   CPU total tokens: 3950 (32.1%)
DEBUG 01-14 20:42:49.806164.806164 lmp.py:1627]   GPU total tokens: 8338 (67.9%)
DEBUG 01-14 20:42:49.806066.806066 cuda_h.py:19] end experts_map_get cost 0.0022063255310058594 seconds
DEBUG 01-14 20:42:49.806182.806182 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-14 20:42:49.806860.806860 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-14 20:42:49.806905.806905 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-14 20:42:49.807630.807630 cuda_h.py:19] end allocate_cuda_memory cost 0.00024437904357910156 seconds
DEBUG 01-14 20:42:49.807394.807394 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-14 20:42:49.807402.807402 sllm_store_c.py:27] get device uuid map
DEBUG 01-14 20:42:49.807755.807755 sllm_store_c.py:29] call client load into gpu
DEBUG 01-14 20:42:49.807988.807988 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 816b6fb7-b6e7-4e73-a4e2-1881bf865f2d
DEBUG 01-14 20:42:49.807307.807307 client.py:106] call stub.LoadModelAsync
INFO 01-14 20:42:49.807520.807520 client.py:127] Model loaded
DEBUG 01-14 20:42:49.807014.807014 cuda_h.py:10] start restore2model
DEBUG 01-14 20:42:49.808186.808186 cuda_h.py:19] end restore2model cost 0.0009157657623291016 seconds
DEBUG 01-14 20:42:49.809919.809919 cuda_h.py:19] end sllm_worker_task cost 0.012286186218261719 seconds
INFO 01-14 20:42:49.809491.809491 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 816b6fb7-b6e7-4e73-a4e2-1881bf865f2d
DEBUG 01-14 20:42:49.809818.809818 cuda_h.py:19] end load_into_gpu_async cost 0.0021305084228515625 seconds
DEBUG 01-14 20:42:49.809428.809428 cuda_h.py:10] start restore_tensors2
DEBUG 01-14 20:42:49.809872.809872 cuda_h.py:19] end restore_tensors2 cost 0.00037097930908203125 seconds
DEBUG 01-14 20:42:49.809423.809423 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0031588077545166016 seconds
DEBUG 01-14 20:42:49.809378.809378 cuda_h.py:10] start restore2model
DEBUG 01-14 20:42:49.812961.812961 cuda_h.py:19] end restore2model cost 0.0025420188903808594 seconds
DEBUG 01-14 20:42:49.812797.812797 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.005895376205444336 seconds
DEBUG 01-14 20:42:49.812878.812878 cuda_h.py:10] start gpu_sexperts
DEBUG 01-14 20:42:49.812033.812033 cuda_h.py:19] end gpu_sexperts cost 0.00025916099548339844 seconds
DEBUG 01-14 20:42:49.812286.812286 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-14 20:42:49.812658.812658 lmp.py:1683] 
DEBUG 01-14 20:42:49.812658.812658 lmp.py:1683]   Computing 32 experts on CPU...
DEBUG 01-14 20:42:49.813925.813925 cuda_h.py:19] end cpu_experts_submit cost 5.6743621826171875e-05 seconds
DEBUG 01-14 20:42:49.813820.813820 cuda_h.py:10] start experts_func_mgpu_group_pad
DEBUG 01-14 20:42:49.819008.819008 mlpmodule.py:1460] group tensors cost 0.005524396896362305 s
DEBUG 01-14 20:42:49.819150.819150 cuda_h.py:10] start move_flat_hidden2cpu
DEBUG 01-14 20:42:49.822792.822792 cuda_h.py:19] end experts_func_mgpu_group_pad cost 0.009405374526977539 seconds
DEBUG 01-14 20:42:49.824087.824087 cuda_h.py:10] start gpu_group_list
DEBUG 01-14 20:42:49.824788.824788 cuda_h.py:19] end gpu_group_list cost 0.0004744529724121094 seconds
DEBUG 01-14 20:42:49.824270.824270 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-14 20:42:49.824002.824002 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.0265579223632812e-05 seconds
DEBUG 01-14 20:42:49.824996.824996 cuda_h.py:10] start wait_experts
INFO 01-14 20:42:49.824798.824798 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 816b6fb7-b6e7-4e73-a4e2-1881bf865f2d
DEBUG 01-14 20:42:49.826949.826949 cuda_h.py:19] end move_flat_hidden2cpu cost 0.0067539215087890625 seconds
DEBUG 01-14 20:42:49.828515.828515 mlpmodule.py:1533] pad cost 0.0019459724426269531 s
DEBUG 01-14 20:42:49.828518.828518 mlpmodule.py:1539] create cpu tensor cost 3.695487976074219e-05 s
DEBUG 01-14 20:42:49.830801.830801 mlpmodule.py:1544] move to cpu cost 0.00206756591796875 s
DEBUG 01-14 20:42:49.840673.840673 mlpmodule.py:1558] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-14 20:42:49.840175.840175 mlpmodule.py:1559] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-14 20:42:49.840728.840728 mlpmodule.py:1564] group_w3 first element: 0.0024871826171875
WARNING 01-14 20:42:49.841653.841653 mlpmodule.py:1574] start einsum2
DEBUG 01-14 20:42:49.858697.858697 mlpmodule.py:1584] group einsum cost 0.027690649032592773 s
DEBUG 01-14 20:42:49.859410.859410 mlpmodule.py:1593] cpy2cputensor cost 0.0007035732269287109 s
DEBUG 01-14 20:42:49.859233.859233 cuda_h.py:10] start move_outputs
DEBUG 01-14 20:42:49.862777.862777 cuda_h.py:19] end move_outputs cost 0.002577066421508789 seconds
INFO 01-14 20:42:49.866018.866018 client.py:127] Model loaded
DEBUG 01-14 20:42:49.866395.866395 cuda_h.py:19] end wait_experts cost 0.04192161560058594 seconds
DEBUG 01-14 20:42:49.866734.866734 cuda_h.py:10] start gpu_experts
DEBUG 01-14 20:42:49.866888.866888 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-14 20:42:49.867981.867981 cuda_h.py:19] end wait_cetm_experts cost 0.000179290771484375 seconds
DEBUG 01-14 20:42:49.867361.867361 cuda_h.py:10] start gpu_group_einsum_mp_multi_list
DEBUG 01-14 20:42:49.867070.867070 cuda_h.py:10] start gpu_group_tensor
DEBUG 01-14 20:42:49.867059.867059 cuda_h.py:19] end gpu_group_tensor cost 0.00024175643920898438 seconds
DEBUG 01-14 20:42:49.867646.867646 cuda_h.py:10] start gpu_group_einsum
DEBUG 01-14 20:42:49.868584.868584 cuda_h.py:19] end gpu_group_einsum cost 0.0006754398345947266 seconds
DEBUG 01-14 20:42:49.868240.868240 cuda_h.py:10] start gpu_final_hidden_states_scatter
DEBUG 01-14 20:42:49.868051.868051 cuda_h.py:10] start all_expert_outputs_slices
DEBUG 01-14 20:42:49.869892.869892 cuda_h.py:19] end all_expert_outputs_slices cost 0.0003597736358642578 seconds
DEBUG 01-14 20:42:49.869555.869555 cuda_h.py:10] start concat_expert_out
DEBUG 01-14 20:42:49.869115.869115 cuda_h.py:19] end concat_expert_out cost 6.079673767089844e-05 seconds
DEBUG 01-14 20:42:49.869203.869203 cuda_h.py:10] start index_scatter
DEBUG 01-14 20:42:49.869253.869253 cuda_h.py:19] end index_scatter cost 7.343292236328125e-05 seconds
DEBUG 01-14 20:42:49.869870.869870 cuda_h.py:19] end gpu_final_hidden_states_scatter cost 0.0007643699645996094 seconds
DEBUG 01-14 20:42:49.869409.869409 cuda_h.py:19] end gpu_experts cost 0.0025398731231689453 seconds
DEBUG 01-14 20:42:49.869827.869827 cuda_h.py:10] start all_expert_weight_slices
DEBUG 01-14 20:42:49.870258.870258 cuda_h.py:19] end all_expert_weight_slices cost 0.000942230224609375 seconds
DEBUG 01-14 20:42:49.870557.870557 cuda_h.py:10] start cpuoutputsdeal
DEBUG 01-14 20:42:49.870863.870863 cuda_h.py:10] start index_scatter
DEBUG 01-14 20:42:49.871284.871284 cuda_h.py:19] end index_scatter cost 4.982948303222656e-05 seconds
DEBUG 01-14 20:42:49.871477.871477 cuda_h.py:19] end cpuoutputsdeal cost 0.0005390644073486328 seconds
DEBUG 01-14 20:42:49.871526.871526 cuda_h.py:19] end layer_moe_generate_mp_l_19 cost 0.06766510009765625 seconds
DEBUG 01-14 20:42:49.871069.871069 cuda_h.py:19] end prefill_layer cost 0.07541847229003906 seconds
DEBUG 01-14 20:42:49.871044.871044 lmp.py:1551] -------------------------------- end prefill layer 18 --------------------------------
DEBUG 01-14 20:42:49.871747.871747 cuda_h.py:10] start prefill_layer
DEBUG 01-14 20:42:49.871642.871642 lmp.py:1494] -------------------------------- start prefill layer 19 --------------------------------
DEBUG 01-14 20:42:49.871345.871345 cuda_h.py:10] start start_load_qkvogn_s_weight_l_20
DEBUG 01-14 20:42:49.871962.871962 cuda_h.py:10] start start_load_qkvogn_s_weight_l_20
DEBUG 01-14 20:42:49.871050.871050 cuda_h.py:19] end start_load_qkvogn_s_weight_l_20 cost 3.695487976074219e-05 seconds
DEBUG 01-14 20:42:49.871237.871237 cuda_h.py:19] end start_load_qkvogn_s_weight_l_20 cost 7.104873657226562e-05 seconds
DEBUG 01-14 20:42:49.871363.871363 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-14 20:42:49.871055.871055 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-14 20:42:49.872939.872939 cuda_h.py:10] start sllm_worker_task
DEBUG 01-14 20:42:49.872366.872366 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-14 20:42:49.872348.872348 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-14 20:42:49.875090.875090 cuda_h.py:19] end allocate_cuda_memory cost 0.003313302993774414 seconds
DEBUG 01-14 20:42:49.875119.875119 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-14 20:42:49.875134.875134 sllm_store_c.py:27] get device uuid map
DEBUG 01-14 20:42:49.875248.875248 sllm_store_c.py:29] call client load into gpu
DEBUG 01-14 20:42:49.875474.875474 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 3e740e66-8389-462b-bd16-16f2d1d1a593
DEBUG 01-14 20:42:49.875967.875967 client.py:106] call stub.LoadModelAsync
DEBUG 01-14 20:42:49.876000.876000 cuda_h.py:10] start self_attn
INFO 01-14 20:42:49.876319.876319 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 3e740e66-8389-462b-bd16-16f2d1d1a593
DEBUG 01-14 20:42:49.876009.876009 cuda_h.py:19] end load_into_gpu_async cost 0.0012073516845703125 seconds
DEBUG 01-14 20:42:49.876281.876281 cuda_h.py:10] start restore_tensors2
DEBUG 01-14 20:42:49.876801.876801 cuda_h.py:19] end restore_tensors2 cost 7.510185241699219e-05 seconds
DEBUG 01-14 20:42:49.877796.877796 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0048830509185791016 seconds
INFO 01-14 20:42:49.877394.877394 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 3e740e66-8389-462b-bd16-16f2d1d1a593
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
INFO 01-14 20:42:49.884779.884779 client.py:127] Model loaded
DEBUG 01-14 20:42:49.884476.884476 cuda_h.py:10] start restore2model
DEBUG 01-14 20:42:49.891819.891819 mlpmodule.py:1367]  experts func einsum cost 0.07784700393676758 s
DEBUG 01-14 20:42:49.891522.891522 cuda_h.py:19] end restore2model cost 0.007850408554077148 seconds
DEBUG 01-14 20:42:49.892072.892072 cuda_h.py:19] end sllm_worker_task cost 0.02008199691772461 seconds
DEBUG 01-14 20:42:49.892978.892978 cuda_h.py:19] end self_attn cost 0.016253232955932617 seconds
DEBUG 01-14 20:42:49.894199.894199 cuda_h.py:19] end iln_self_attn_paln cost 0.022945880889892578 seconds
DEBUG 01-14 20:42:49.896774.896774 cuda_h.py:10] start layer_moe_generate_mp_l_20
DEBUG 01-14 20:42:49.898061.898061 cuda_h.py:10] start gate
DEBUG 01-14 20:42:49.899461.899461 cuda_h.py:19] end gate cost 0.0007884502410888672 seconds
DEBUG 01-14 20:42:49.899588.899588 cuda_h.py:10] start experts_map_get
DEBUG 01-14 20:42:49.900054.900054 lmp.py:1615] 
DEBUG 01-14 20:42:49.900054.900054 lmp.py:1615] Expert Token Distribution & Device Allocation:
DEBUG 01-14 20:42:49.900082.900082 lmp.py:1616]   Total experts: 64
DEBUG 01-14 20:42:49.900461.900461 lmp.py:1617]   CPU experts: 32 (50%)
DEBUG 01-14 20:42:49.900833.900833 lmp.py:1618]   GPU experts: 32 (50%)
DEBUG 01-14 20:42:49.900105.900105 lmp.py:1619] 
DEBUG 01-14 20:42:49.900105.900105 lmp.py:1619]   Expert ID | Tokens | Device
DEBUG 01-14 20:42:49.900377.900377 lmp.py:1620]   -----------------------------------
DEBUG 01-14 20:42:49.900902.900902 lmp.py:1625]   Expert  1 |     42 | CPU
DEBUG 01-14 20:42:49.900135.900135 lmp.py:1625]   Expert 44 |     52 | CPU
DEBUG 01-14 20:42:49.900652.900652 lmp.py:1625]   Expert 60 |     71 | CPU
DEBUG 01-14 20:42:49.900262.900262 lmp.py:1625]   Expert 28 |     72 | CPU
DEBUG 01-14 20:42:49.900926.900926 lmp.py:1625]   Expert 27 |     94 | CPU
DEBUG 01-14 20:42:49.900066.900066 lmp.py:1625]   Expert 30 |     95 | CPU
DEBUG 01-14 20:42:49.900060.900060 lmp.py:1625]   Expert 48 |     95 | CPU
DEBUG 01-14 20:42:49.900671.900671 lmp.py:1625]   Expert 62 |     96 | CPU
DEBUG 01-14 20:42:49.900711.900711 lmp.py:1625]   Expert  0 |    100 | CPU
DEBUG 01-14 20:42:49.900937.900937 lmp.py:1625]   Expert 42 |    107 | CPU
DEBUG 01-14 20:42:49.900302.900302 lmp.py:1625]   Expert 22 |    109 | CPU
DEBUG 01-14 20:42:49.900290.900290 lmp.py:1625]   Expert 58 |    116 | CPU
DEBUG 01-14 20:42:49.900754.900754 lmp.py:1625]   Expert 59 |    125 | CPU
DEBUG 01-14 20:42:49.900643.900643 lmp.py:1625]   Expert  8 |    130 | CPU
DEBUG 01-14 20:42:49.900292.900292 lmp.py:1625]   Expert 50 |    131 | CPU
DEBUG 01-14 20:42:49.900134.900134 lmp.py:1625]   Expert 12 |    134 | CPU
DEBUG 01-14 20:42:49.900784.900784 lmp.py:1625]   Expert 56 |    139 | CPU
DEBUG 01-14 20:42:49.901911.901911 lmp.py:1625]   Expert  5 |    141 | CPU
DEBUG 01-14 20:42:49.901322.901322 lmp.py:1625]   Expert 32 |    145 | CPU
DEBUG 01-14 20:42:49.901733.901733 lmp.py:1625]   Expert 34 |    147 | CPU
DEBUG 01-14 20:42:49.901436.901436 lmp.py:1625]   Expert 16 |    149 | CPU
DEBUG 01-14 20:42:49.901232.901232 lmp.py:1625]   Expert 55 |    149 | CPU
DEBUG 01-14 20:42:49.901266.901266 lmp.py:1625]   Expert 26 |    152 | CPU
DEBUG 01-14 20:42:49.901631.901631 lmp.py:1625]   Expert 19 |    155 | CPU
DEBUG 01-14 20:42:49.901280.901280 lmp.py:1625]   Expert 47 |    157 | CPU
DEBUG 01-14 20:42:49.901407.901407 lmp.py:1625]   Expert  2 |    158 | CPU
DEBUG 01-14 20:42:49.901295.901295 lmp.py:1625]   Expert 15 |    160 | CPU
DEBUG 01-14 20:42:49.901375.901375 lmp.py:1625]   Expert 13 |    162 | CPU
DEBUG 01-14 20:42:49.901648.901648 lmp.py:1625]   Expert 41 |    167 | CPU
DEBUG 01-14 20:42:49.901159.901159 lmp.py:1625]   Expert 52 |    172 | CPU
DEBUG 01-14 20:42:49.901524.901524 lmp.py:1625]   Expert 25 |    175 | CPU
DEBUG 01-14 20:42:49.901458.901458 lmp.py:1625]   Expert 24 |    176 | CPU
DEBUG 01-14 20:42:49.901870.901870 lmp.py:1625]   Expert 20 |    178 | GPU
DEBUG 01-14 20:42:49.901619.901619 lmp.py:1625]   Expert  6 |    179 | GPU
DEBUG 01-14 20:42:49.901322.901322 lmp.py:1625]   Expert 40 |    179 | GPU
DEBUG 01-14 20:42:49.901217.901217 lmp.py:1625]   Expert 18 |    180 | GPU
DEBUG 01-14 20:42:49.901588.901588 lmp.py:1625]   Expert 54 |    182 | GPU
DEBUG 01-14 20:42:49.901536.901536 lmp.py:1625]   Expert 37 |    183 | GPU
DEBUG 01-14 20:42:49.901147.901147 lmp.py:1625]   Expert  3 |    186 | GPU
DEBUG 01-14 20:42:49.901088.901088 lmp.py:1625]   Expert 17 |    186 | GPU
DEBUG 01-14 20:42:49.901314.901314 lmp.py:1625]   Expert 51 |    186 | GPU
DEBUG 01-14 20:42:49.901116.901116 lmp.py:1625]   Expert 57 |    188 | GPU
DEBUG 01-14 20:42:49.901826.901826 lmp.py:1625]   Expert 46 |    193 | GPU
DEBUG 01-14 20:42:49.901959.901959 lmp.py:1625]   Expert 11 |    194 | GPU
DEBUG 01-14 20:42:49.901046.901046 lmp.py:1625]   Expert 23 |    200 | GPU
DEBUG 01-14 20:42:49.901134.901134 lmp.py:1625]   Expert 43 |    206 | GPU
DEBUG 01-14 20:42:49.901982.901982 lmp.py:1625]   Expert 31 |    223 | GPU
DEBUG 01-14 20:42:49.901453.901453 lmp.py:1625]   Expert 49 |    224 | GPU
DEBUG 01-14 20:42:49.901302.901302 lmp.py:1625]   Expert 35 |    227 | GPU
DEBUG 01-14 20:42:49.901297.901297 lmp.py:1625]   Expert 10 |    229 | GPU
DEBUG 01-14 20:42:49.901053.901053 lmp.py:1625]   Expert 53 |    234 | GPU
DEBUG 01-14 20:42:49.901994.901994 lmp.py:1625]   Expert 36 |    247 | GPU
DEBUG 01-14 20:42:49.901743.901743 lmp.py:1625]   Expert 33 |    250 | GPU
DEBUG 01-14 20:42:49.901731.901731 lmp.py:1625]   Expert 38 |    262 | GPU
DEBUG 01-14 20:42:49.902910.902910 lmp.py:1625]   Expert 39 |    262 | GPU
DEBUG 01-14 20:42:49.902329.902329 lmp.py:1625]   Expert  4 |    304 | GPU
DEBUG 01-14 20:42:49.902031.902031 lmp.py:1625]   Expert 21 |    327 | GPU
DEBUG 01-14 20:42:49.902973.902973 lmp.py:1625]   Expert  9 |    332 | GPU
DEBUG 01-14 20:42:49.902483.902483 lmp.py:1625]   Expert 14 |    345 | GPU
DEBUG 01-14 20:42:49.902710.902710 lmp.py:1625]   Expert 45 |    366 | GPU
DEBUG 01-14 20:42:49.902936.902936 lmp.py:1625]   Expert 63 |    368 | GPU
DEBUG 01-14 20:42:49.902592.902592 lmp.py:1625]   Expert 61 |    389 | GPU
DEBUG 01-14 20:42:49.902772.902772 lmp.py:1625]   Expert 29 |    488 | GPU
DEBUG 01-14 20:42:49.902475.902475 lmp.py:1625]   Expert  7 |    518 | GPU
DEBUG 01-14 20:42:49.902608.902608 lmp.py:1626] 
DEBUG 01-14 20:42:49.902608.902608 lmp.py:1626]   CPU total tokens: 4073 (33.1%)
DEBUG 01-14 20:42:49.902503.902503 lmp.py:1627]   GPU total tokens: 8215 (66.9%)
DEBUG 01-14 20:42:49.902597.902597 cuda_h.py:19] end experts_map_get cost 0.0023899078369140625 seconds
DEBUG 01-14 20:42:49.902812.902812 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-14 20:42:49.902093.902093 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-14 20:42:49.902790.902790 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-14 20:42:49.903014.903014 cuda_h.py:19] end allocate_cuda_memory cost 0.00031948089599609375 seconds
DEBUG 01-14 20:42:49.903560.903560 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-14 20:42:49.903483.903483 sllm_store_c.py:27] get device uuid map
DEBUG 01-14 20:42:49.903465.903465 sllm_store_c.py:29] call client load into gpu
DEBUG 01-14 20:42:49.903373.903373 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, c9c7f550-90b9-4198-9dbf-74a8ab741d9f
DEBUG 01-14 20:42:49.903835.903835 client.py:106] call stub.LoadModelAsync
INFO 01-14 20:42:49.904497.904497 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, c9c7f550-90b9-4198-9dbf-74a8ab741d9f
DEBUG 01-14 20:42:49.904778.904778 cuda_h.py:19] end load_into_gpu_async cost 0.0016939640045166016 seconds
DEBUG 01-14 20:42:49.904918.904918 cuda_h.py:10] start restore_tensors2
DEBUG 01-14 20:42:49.905162.905162 cuda_h.py:19] end restore_tensors2 cost 0.000530242919921875 seconds
DEBUG 01-14 20:42:49.905185.905185 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0030853748321533203 seconds
DEBUG 01-14 20:42:49.905160.905160 cuda_h.py:10] start restore2model
DEBUG 01-14 20:42:49.909362.909362 cuda_h.py:19] end restore2model cost 0.0036230087280273438 seconds
DEBUG 01-14 20:42:49.909855.909855 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.0069713592529296875 seconds
DEBUG 01-14 20:42:49.909326.909326 cuda_h.py:10] start gpu_sexperts
DEBUG 01-14 20:42:49.909095.909095 cuda_h.py:19] end gpu_sexperts cost 0.0003719329833984375 seconds
DEBUG 01-14 20:42:49.909124.909124 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-14 20:42:49.909555.909555 lmp.py:1683] 
DEBUG 01-14 20:42:49.909555.909555 lmp.py:1683]   Computing 32 experts on CPU...
DEBUG 01-14 20:42:49.910750.910750 cuda_h.py:19] end cpu_experts_submit cost 7.295608520507812e-05 seconds
DEBUG 01-14 20:42:49.910797.910797 cuda_h.py:10] start experts_func_mgpu_group_pad
DEBUG 01-14 20:42:49.917723.917723 mlpmodule.py:1460] group tensors cost 0.00670170783996582 s
DEBUG 01-14 20:42:49.918954.918954 cuda_h.py:10] start move_flat_hidden2cpu
DEBUG 01-14 20:42:49.920541.920541 cuda_h.py:19] end experts_func_mgpu_group_pad cost 0.01066899299621582 seconds
DEBUG 01-14 20:42:49.922854.922854 cuda_h.py:10] start gpu_group_list
DEBUG 01-14 20:42:49.923415.923415 cuda_h.py:19] end gpu_group_list cost 0.0006158351898193359 seconds
DEBUG 01-14 20:42:49.923589.923589 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-14 20:42:49.923190.923190 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 3.4332275390625e-05 seconds
DEBUG 01-14 20:42:49.923343.923343 cuda_h.py:10] start wait_experts
INFO 01-14 20:42:49.923159.923159 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, c9c7f550-90b9-4198-9dbf-74a8ab741d9f
DEBUG 01-14 20:42:49.925515.925515 cuda_h.py:19] end move_flat_hidden2cpu cost 0.007179975509643555 seconds
DEBUG 01-14 20:42:49.927717.927717 mlpmodule.py:1533] pad cost 0.0015506744384765625 s
DEBUG 01-14 20:42:49.927356.927356 mlpmodule.py:1539] create cpu tensor cost 4.7206878662109375e-05 s
DEBUG 01-14 20:42:49.929050.929050 mlpmodule.py:1544] move to cpu cost 0.0020835399627685547 s
DEBUG 01-14 20:42:49.939067.939067 mlpmodule.py:1558] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-14 20:42:49.939668.939668 mlpmodule.py:1559] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-14 20:42:49.939744.939744 mlpmodule.py:1564] group_w3 first element: -0.0034942626953125
WARNING 01-14 20:42:49.939907.939907 mlpmodule.py:1574] start einsum2
DEBUG 01-14 20:42:49.957720.957720 mlpmodule.py:1584] group einsum cost 0.02782154083251953 s
DEBUG 01-14 20:42:49.958363.958363 mlpmodule.py:1593] cpy2cputensor cost 0.0007607936859130859 s
DEBUG 01-14 20:42:49.958259.958259 cuda_h.py:10] start move_outputs
DEBUG 01-14 20:42:49.960480.960480 cuda_h.py:19] end move_outputs cost 0.002610445022583008 seconds
INFO 01-14 20:42:49.961335.961335 client.py:127] Model loaded
DEBUG 01-14 20:42:49.961090.961090 cuda_h.py:19] end wait_experts cost 0.03827309608459473 seconds
DEBUG 01-14 20:42:49.962841.962841 cuda_h.py:10] start gpu_experts
DEBUG 01-14 20:42:49.962571.962571 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-14 20:42:49.965403.965403 cuda_h.py:19] end wait_cetm_experts cost 0.003240823745727539 seconds
DEBUG 01-14 20:42:49.965333.965333 cuda_h.py:10] start gpu_group_einsum_mp_multi_list
DEBUG 01-14 20:42:49.965288.965288 cuda_h.py:10] start gpu_group_tensor
DEBUG 01-14 20:42:49.965522.965522 cuda_h.py:19] end gpu_group_tensor cost 0.0002455711364746094 seconds
DEBUG 01-14 20:42:49.965453.965453 cuda_h.py:10] start gpu_group_einsum
DEBUG 01-14 20:42:49.966500.966500 cuda_h.py:19] end gpu_group_einsum cost 0.0005435943603515625 seconds
DEBUG 01-14 20:42:49.966047.966047 cuda_h.py:10] start gpu_final_hidden_states_scatter
DEBUG 01-14 20:42:49.966321.966321 cuda_h.py:10] start all_expert_outputs_slices
DEBUG 01-14 20:42:49.967630.967630 cuda_h.py:19] end all_expert_outputs_slices cost 0.0002987384796142578 seconds
DEBUG 01-14 20:42:49.967147.967147 cuda_h.py:10] start concat_expert_out
DEBUG 01-14 20:42:49.967329.967329 cuda_h.py:19] end concat_expert_out cost 6.031990051269531e-05 seconds
DEBUG 01-14 20:42:49.967756.967756 cuda_h.py:10] start index_scatter
DEBUG 01-14 20:42:49.967097.967097 cuda_h.py:19] end index_scatter cost 7.557868957519531e-05 seconds
DEBUG 01-14 20:42:49.967767.967767 cuda_h.py:19] end gpu_final_hidden_states_scatter cost 0.0006957054138183594 seconds
DEBUG 01-14 20:42:49.967135.967135 cuda_h.py:19] end gpu_experts cost 0.005380392074584961 seconds
DEBUG 01-14 20:42:49.967983.967983 cuda_h.py:10] start all_expert_weight_slices
DEBUG 01-14 20:42:49.968330.968330 cuda_h.py:19] end all_expert_weight_slices cost 0.0010287761688232422 seconds
DEBUG 01-14 20:42:49.968352.968352 cuda_h.py:10] start cpuoutputsdeal
DEBUG 01-14 20:42:49.969016.969016 cuda_h.py:10] start index_scatter
DEBUG 01-14 20:42:49.969390.969390 cuda_h.py:19] end index_scatter cost 4.887580871582031e-05 seconds
DEBUG 01-14 20:42:49.969729.969729 cuda_h.py:19] end cpuoutputsdeal cost 0.0005612373352050781 seconds
DEBUG 01-14 20:42:49.969831.969831 cuda_h.py:19] end layer_moe_generate_mp_l_20 cost 0.07066535949707031 seconds
DEBUG 01-14 20:42:49.969931.969931 cuda_h.py:19] end prefill_layer cost 0.09803223609924316 seconds
DEBUG 01-14 20:42:49.969080.969080 lmp.py:1551] -------------------------------- end prefill layer 19 --------------------------------
DEBUG 01-14 20:42:49.969928.969928 cuda_h.py:10] start prefill_layer
DEBUG 01-14 20:42:49.969300.969300 lmp.py:1494] -------------------------------- start prefill layer 20 --------------------------------
DEBUG 01-14 20:42:49.969195.969195 cuda_h.py:10] start start_load_qkvogn_s_weight_l_21
DEBUG 01-14 20:42:49.969474.969474 cuda_h.py:10] start start_load_qkvogn_s_weight_l_21
DEBUG 01-14 20:42:49.969132.969132 cuda_h.py:19] end start_load_qkvogn_s_weight_l_21 cost 3.528594970703125e-05 seconds
DEBUG 01-14 20:42:49.969365.969365 cuda_h.py:19] end start_load_qkvogn_s_weight_l_21 cost 6.961822509765625e-05 seconds
DEBUG 01-14 20:42:49.969683.969683 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-14 20:42:49.970945.970945 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-14 20:42:49.970352.970352 cuda_h.py:10] start sllm_worker_task
DEBUG 01-14 20:42:49.970441.970441 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-14 20:42:49.970807.970807 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-14 20:42:49.973275.973275 cuda_h.py:19] end allocate_cuda_memory cost 0.0030434131622314453 seconds
DEBUG 01-14 20:42:49.973423.973423 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-14 20:42:49.973047.973047 sllm_store_c.py:27] get device uuid map
DEBUG 01-14 20:42:49.973499.973499 sllm_store_c.py:29] call client load into gpu
DEBUG 01-14 20:42:49.973447.973447 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, b4db9b59-ac23-4c42-b395-38844a033902
DEBUG 01-14 20:42:49.973536.973536 client.py:106] call stub.LoadModelAsync
DEBUG 01-14 20:42:49.974700.974700 cuda_h.py:10] start self_attn
INFO 01-14 20:42:49.974102.974102 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, b4db9b59-ac23-4c42-b395-38844a033902
DEBUG 01-14 20:42:49.974654.974654 cuda_h.py:19] end load_into_gpu_async cost 0.0011150836944580078 seconds
DEBUG 01-14 20:42:49.974595.974595 cuda_h.py:10] start restore_tensors2
DEBUG 01-14 20:42:49.974684.974684 cuda_h.py:19] end restore_tensors2 cost 7.367134094238281e-05 seconds
DEBUG 01-14 20:42:49.974679.974679 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.004495143890380859 seconds
INFO 01-14 20:42:49.974853.974853 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, b4db9b59-ac23-4c42-b395-38844a033902
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-14 20:42:49.977548.977548 cuda_h.py:19] end self_attn cost 0.002907276153564453 seconds
DEBUG 01-14 20:42:49.977454.977454 mlpmodule.py:1367]  experts func einsum cost 0.06671476364135742 s
DEBUG 01-14 20:42:49.977195.977195 cuda_h.py:19] end iln_self_attn_paln cost 0.0075283050537109375 seconds
DEBUG 01-14 20:42:49.977722.977722 cuda_h.py:10] start layer_moe_generate_mp_l_21
DEBUG 01-14 20:42:49.977776.977776 cuda_h.py:10] start gate
DEBUG 01-14 20:42:49.978885.978885 cuda_h.py:19] end gate cost 0.0006425380706787109 seconds
DEBUG 01-14 20:42:49.978953.978953 cuda_h.py:10] start experts_map_get
DEBUG 01-14 20:42:49.978672.978672 lmp.py:1615] 
DEBUG 01-14 20:42:49.978672.978672 lmp.py:1615] Expert Token Distribution & Device Allocation:
DEBUG 01-14 20:42:49.978905.978905 lmp.py:1616]   Total experts: 64
DEBUG 01-14 20:42:49.978986.978986 lmp.py:1617]   CPU experts: 32 (50%)
DEBUG 01-14 20:42:49.978297.978297 lmp.py:1618]   GPU experts: 32 (50%)
DEBUG 01-14 20:42:49.978464.978464 lmp.py:1619] 
DEBUG 01-14 20:42:49.978464.978464 lmp.py:1619]   Expert ID | Tokens | Device
DEBUG 01-14 20:42:49.978630.978630 lmp.py:1620]   -----------------------------------
DEBUG 01-14 20:42:49.978511.978511 lmp.py:1625]   Expert 54 |     32 | CPU
DEBUG 01-14 20:42:49.978677.978677 lmp.py:1625]   Expert  8 |     41 | CPU
DEBUG 01-14 20:42:49.978413.978413 lmp.py:1625]   Expert 28 |     41 | CPU
DEBUG 01-14 20:42:49.978625.978625 lmp.py:1625]   Expert  3 |     44 | CPU
DEBUG 01-14 20:42:49.978361.978361 lmp.py:1625]   Expert 43 |     59 | CPU
DEBUG 01-14 20:42:49.978573.978573 lmp.py:1625]   Expert 63 |     59 | CPU
DEBUG 01-14 20:42:49.978309.978309 lmp.py:1625]   Expert  6 |     77 | CPU
DEBUG 01-14 20:42:49.979522.979522 lmp.py:1625]   Expert 38 |     80 | CPU
DEBUG 01-14 20:42:49.979211.979211 lmp.py:1625]   Expert 57 |     85 | CPU
DEBUG 01-14 20:42:49.979662.979662 lmp.py:1625]   Expert 39 |     87 | CPU
DEBUG 01-14 20:42:49.979159.979159 lmp.py:1625]   Expert 36 |     93 | CPU
DEBUG 01-14 20:42:49.979371.979371 lmp.py:1625]   Expert 41 |     96 | CPU
DEBUG 01-14 20:42:49.979345.979345 lmp.py:1625]   Expert 47 |    100 | CPU
DEBUG 01-14 20:42:49.979081.979081 lmp.py:1625]   Expert 19 |    107 | CPU
DEBUG 01-14 20:42:49.979055.979055 lmp.py:1625]   Expert 52 |    107 | CPU
DEBUG 01-14 20:42:49.979029.979029 lmp.py:1625]   Expert 12 |    108 | CPU
DEBUG 01-14 20:42:49.979003.979003 lmp.py:1625]   Expert 13 |    129 | CPU
DEBUG 01-14 20:42:49.979931.979931 lmp.py:1625]   Expert 22 |    143 | CPU
DEBUG 01-14 20:42:49.979905.979905 lmp.py:1625]   Expert 40 |    147 | CPU
DEBUG 01-14 20:42:49.979879.979879 lmp.py:1625]   Expert 50 |    147 | CPU
DEBUG 01-14 20:42:49.979091.979091 lmp.py:1625]   Expert  2 |    148 | CPU
DEBUG 01-14 20:42:49.979827.979827 lmp.py:1625]   Expert 46 |    151 | CPU
DEBUG 01-14 20:42:49.979801.979801 lmp.py:1625]   Expert 53 |    158 | CPU
DEBUG 01-14 20:42:49.979537.979537 lmp.py:1625]   Expert 20 |    161 | CPU
DEBUG 01-14 20:42:49.979272.979272 lmp.py:1625]   Expert 37 |    162 | CPU
DEBUG 01-14 20:42:49.979485.979485 lmp.py:1625]   Expert 14 |    166 | CPU
DEBUG 01-14 20:42:49.979697.979697 lmp.py:1625]   Expert 23 |    167 | CPU
DEBUG 01-14 20:42:49.979009.979009 lmp.py:1625]   Expert 21 |    169 | CPU
DEBUG 01-14 20:42:49.979414.979414 lmp.py:1625]   Expert 55 |    174 | CPU
DEBUG 01-14 20:42:49.979342.979342 lmp.py:1625]   Expert 24 |    179 | CPU
DEBUG 01-14 20:42:49.979269.979269 lmp.py:1625]   Expert 61 |    181 | CPU
DEBUG 01-14 20:42:49.979959.979959 lmp.py:1625]   Expert 42 |    186 | CPU
DEBUG 01-14 20:42:49.979602.979602 lmp.py:1625]   Expert  0 |    188 | GPU
DEBUG 01-14 20:42:49.979404.979404 lmp.py:1625]   Expert  5 |    190 | GPU
DEBUG 01-14 20:42:49.979332.979332 lmp.py:1625]   Expert 32 |    199 | GPU
DEBUG 01-14 20:42:49.979544.979544 lmp.py:1625]   Expert 33 |    200 | GPU
DEBUG 01-14 20:42:49.979041.979041 lmp.py:1625]   Expert 49 |    200 | GPU
DEBUG 01-14 20:42:49.979015.979015 lmp.py:1625]   Expert 30 |    201 | GPU
DEBUG 01-14 20:42:49.979751.979751 lmp.py:1625]   Expert 34 |    201 | GPU
DEBUG 01-14 20:42:49.979487.979487 lmp.py:1625]   Expert 16 |    209 | GPU
DEBUG 01-14 20:42:49.979461.979461 lmp.py:1625]   Expert 18 |    209 | GPU
DEBUG 01-14 20:42:49.979150.979150 lmp.py:1625]   Expert  7 |    211 | GPU
DEBUG 01-14 20:42:49.979362.979362 lmp.py:1625]   Expert 59 |    211 | GPU
DEBUG 01-14 20:42:49.979860.979860 lmp.py:1625]   Expert 31 |    213 | GPU
DEBUG 01-14 20:42:49.979595.979595 lmp.py:1625]   Expert 62 |    214 | GPU
DEBUG 01-14 20:42:49.979092.979092 lmp.py:1625]   Expert  9 |    216 | GPU
DEBUG 01-14 20:42:49.979066.979066 lmp.py:1625]   Expert 60 |    222 | GPU
DEBUG 01-14 20:42:49.979802.979802 lmp.py:1625]   Expert 10 |    225 | GPU
DEBUG 01-14 20:42:49.979776.979776 lmp.py:1625]   Expert 15 |    226 | GPU
DEBUG 01-14 20:42:49.979989.979989 lmp.py:1625]   Expert  4 |    233 | GPU
DEBUG 01-14 20:42:49.979632.979632 lmp.py:1625]   Expert 58 |    237 | GPU
DEBUG 01-14 20:42:49.979367.979367 lmp.py:1625]   Expert 29 |    239 | GPU
DEBUG 01-14 20:42:49.979103.979103 lmp.py:1625]   Expert 17 |    243 | GPU
DEBUG 01-14 20:42:49.979838.979838 lmp.py:1625]   Expert 26 |    251 | GPU
DEBUG 01-14 20:42:49.979336.979336 lmp.py:1625]   Expert 44 |    276 | GPU
DEBUG 01-14 20:42:49.979833.979833 lmp.py:1625]   Expert 51 |    277 | GPU
DEBUG 01-14 20:42:49.979568.979568 lmp.py:1625]   Expert 11 |    281 | GPU
DEBUG 01-14 20:42:49.979304.979304 lmp.py:1625]   Expert 56 |    285 | GPU
DEBUG 01-14 20:42:49.979517.979517 lmp.py:1625]   Expert 27 |    295 | GPU
DEBUG 01-14 20:42:49.979967.979967 lmp.py:1625]   Expert  1 |    344 | GPU
DEBUG 01-14 20:42:49.979703.979703 lmp.py:1625]   Expert 45 |    352 | GPU
DEBUG 01-14 20:42:49.979677.979677 lmp.py:1625]   Expert 25 |    443 | GPU
DEBUG 01-14 20:42:49.979174.979174 lmp.py:1625]   Expert 35 |    504 | GPU
DEBUG 01-14 20:42:49.979148.979148 lmp.py:1625]   Expert 48 |    709 | GPU
DEBUG 01-14 20:42:49.979076.979076 lmp.py:1626] 
DEBUG 01-14 20:42:49.979076.979076 lmp.py:1626]   CPU total tokens: 3784 (30.8%)
DEBUG 01-14 20:42:49.979242.979242 lmp.py:1627]   GPU total tokens: 8504 (69.2%)
DEBUG 01-14 20:42:49.979938.979938 cuda_h.py:19] end experts_map_get cost 0.0015044212341308594 seconds
DEBUG 01-14 20:42:49.980596.980596 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-14 20:42:49.980015.980015 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-14 20:42:49.980643.980643 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-14 20:42:49.982345.982345 cuda_h.py:19] end allocate_cuda_memory cost 0.0017478466033935547 seconds
DEBUG 01-14 20:42:49.982924.982924 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-14 20:42:49.982633.982633 sllm_store_c.py:27] get device uuid map
DEBUG 01-14 20:42:49.982727.982727 sllm_store_c.py:29] call client load into gpu
DEBUG 01-14 20:42:49.982569.982569 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, a2b73eca-5e27-4fd3-9451-8a2753dc23cc
DEBUG 01-14 20:42:49.982761.982761 client.py:106] call stub.LoadModelAsync
INFO 01-14 20:42:49.982984.982984 client.py:127] Model loaded
DEBUG 01-14 20:42:49.982966.982966 cuda_h.py:10] start restore2model
DEBUG 01-14 20:42:49.983055.983055 cuda_h.py:19] end restore2model cost 0.0004496574401855469 seconds
DEBUG 01-14 20:42:49.983984.983984 cuda_h.py:19] end sllm_worker_task cost 0.013050079345703125 seconds
INFO 01-14 20:42:49.983777.983777 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, a2b73eca-5e27-4fd3-9451-8a2753dc23cc
DEBUG 01-14 20:42:49.983481.983481 cuda_h.py:19] end load_into_gpu_async cost 0.0013952255249023438 seconds
DEBUG 01-14 20:42:49.983191.983191 cuda_h.py:10] start restore_tensors2
DEBUG 01-14 20:42:49.984975.984975 cuda_h.py:19] end restore_tensors2 cost 0.000446319580078125 seconds
DEBUG 01-14 20:42:49.984309.984309 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0039844512939453125 seconds
DEBUG 01-14 20:42:49.984363.984363 cuda_h.py:10] start restore2model
DEBUG 01-14 20:42:49.986962.986962 cuda_h.py:19] end restore2model cost 0.0026226043701171875 seconds
DEBUG 01-14 20:42:49.986950.986950 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.006796836853027344 seconds
DEBUG 01-14 20:42:49.986554.986554 cuda_h.py:10] start gpu_sexperts
DEBUG 01-14 20:42:49.987750.987750 cuda_h.py:19] end gpu_sexperts cost 0.0002903938293457031 seconds
DEBUG 01-14 20:42:49.987679.987679 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-14 20:42:49.987574.987574 lmp.py:1683] 
DEBUG 01-14 20:42:49.987574.987574 lmp.py:1683]   Computing 32 experts on CPU...
DEBUG 01-14 20:42:49.987364.987364 cuda_h.py:19] end cpu_experts_submit cost 5.555152893066406e-05 seconds
DEBUG 01-14 20:42:49.987636.987636 cuda_h.py:10] start experts_func_mgpu_group_pad
DEBUG 01-14 20:42:49.997235.997235 mlpmodule.py:1460] group tensors cost 0.009296894073486328 s
DEBUG 01-14 20:42:49.997675.997675 cuda_h.py:10] start move_flat_hidden2cpu
DEBUG 01-14 20:42:50.001094.001094 cuda_h.py:19] end experts_func_mgpu_group_pad cost 0.013783454895019531 seconds
DEBUG 01-14 20:42:50.004920.004920 cuda_h.py:10] start gpu_group_list
DEBUG 01-14 20:42:50.005482.005482 cuda_h.py:19] end gpu_group_list cost 0.0009694099426269531 seconds
DEBUG 01-14 20:42:50.005220.005220 cuda_h.py:19] end move_flat_hidden2cpu cost 0.0077114105224609375 seconds
DEBUG 01-14 20:42:50.005624.005624 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-14 20:42:50.006612.006612 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 4.1484832763671875e-05 seconds
DEBUG 01-14 20:42:50.006311.006311 cuda_h.py:10] start wait_experts
INFO 01-14 20:42:50.006076.006076 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, a2b73eca-5e27-4fd3-9451-8a2753dc23cc
DEBUG 01-14 20:42:50.007486.007486 mlpmodule.py:1533] pad cost 0.0020761489868164062 s
DEBUG 01-14 20:42:50.007887.007887 mlpmodule.py:1539] create cpu tensor cost 3.695487976074219e-05 s
DEBUG 01-14 20:42:50.010976.010976 mlpmodule.py:1544] move to cpu cost 0.0021991729736328125 s
DEBUG 01-14 20:42:50.019502.019502 mlpmodule.py:1558] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-14 20:42:50.020389.020389 mlpmodule.py:1559] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-14 20:42:50.020749.020749 mlpmodule.py:1564] group_w3 first element: 0.039306640625
WARNING 01-14 20:42:50.020435.020435 mlpmodule.py:1574] start einsum2
DEBUG 01-14 20:42:50.038089.038089 mlpmodule.py:1584] group einsum cost 0.028016328811645508 s
DEBUG 01-14 20:42:50.039367.039367 mlpmodule.py:1593] cpy2cputensor cost 0.0007817745208740234 s
DEBUG 01-14 20:42:50.039601.039601 cuda_h.py:10] start move_outputs
INFO 01-14 20:42:50.039416.039416 client.py:127] Model loaded
DEBUG 01-14 20:42:50.039018.039018 cuda_h.py:19] end wait_experts cost 0.033475399017333984 seconds
DEBUG 01-14 20:42:50.039503.039503 cuda_h.py:10] start gpu_experts
DEBUG 01-14 20:42:50.039942.039942 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-14 20:42:50.041264.041264 cuda_h.py:19] end move_outputs cost 0.0021581649780273438 seconds
DEBUG 01-14 20:42:50.045982.045982 cuda_h.py:19] end wait_cetm_experts cost 0.005320072174072266 seconds
DEBUG 01-14 20:42:50.045576.045576 cuda_h.py:10] start gpu_group_einsum_mp_multi_list
DEBUG 01-14 20:42:50.045438.045438 cuda_h.py:10] start gpu_group_tensor
DEBUG 01-14 20:42:50.045487.045487 cuda_h.py:19] end gpu_group_tensor cost 0.0002491474151611328 seconds
DEBUG 01-14 20:42:50.045664.045664 cuda_h.py:10] start gpu_group_einsum
DEBUG 01-14 20:42:50.046277.046277 cuda_h.py:19] end gpu_group_einsum cost 0.0006382465362548828 seconds
DEBUG 01-14 20:42:50.046288.046288 cuda_h.py:10] start gpu_final_hidden_states_scatter
DEBUG 01-14 20:42:50.046237.046237 cuda_h.py:10] start all_expert_outputs_slices
DEBUG 01-14 20:42:50.047125.047125 cuda_h.py:19] end all_expert_outputs_slices cost 0.00035953521728515625 seconds
DEBUG 01-14 20:42:50.047597.047597 cuda_h.py:10] start concat_expert_out
DEBUG 01-14 20:42:50.047209.047209 cuda_h.py:19] end concat_expert_out cost 6.079673767089844e-05 seconds
DEBUG 01-14 20:42:50.047443.047443 cuda_h.py:10] start index_scatter
DEBUG 01-14 20:42:50.047401.047401 cuda_h.py:19] end index_scatter cost 7.486343383789062e-05 seconds
DEBUG 01-14 20:42:50.047733.047733 cuda_h.py:19] end gpu_final_hidden_states_scatter cost 0.0007693767547607422 seconds
DEBUG 01-14 20:42:50.047133.047133 cuda_h.py:19] end gpu_experts cost 0.007704973220825195 seconds
DEBUG 01-14 20:42:50.047266.047266 cuda_h.py:10] start all_expert_weight_slices
DEBUG 01-14 20:42:50.048991.048991 cuda_h.py:19] end all_expert_weight_slices cost 0.0010271072387695312 seconds
DEBUG 01-14 20:42:50.048489.048489 cuda_h.py:10] start cpuoutputsdeal
DEBUG 01-14 20:42:50.049895.049895 cuda_h.py:10] start index_scatter
DEBUG 01-14 20:42:50.049938.049938 cuda_h.py:19] end index_scatter cost 5.316734313964844e-05 seconds
DEBUG 01-14 20:42:50.049038.049038 cuda_h.py:19] end cpuoutputsdeal cost 0.0005514621734619141 seconds
DEBUG 01-14 20:42:50.049140.049140 cuda_h.py:19] end layer_moe_generate_mp_l_21 cost 0.07158565521240234 seconds
DEBUG 01-14 20:42:50.049393.049393 cuda_h.py:19] end prefill_layer cost 0.07989835739135742 seconds
DEBUG 01-14 20:42:50.049316.049316 lmp.py:1551] -------------------------------- end prefill layer 20 --------------------------------
DEBUG 01-14 20:42:50.049927.049927 cuda_h.py:10] start prefill_layer
DEBUG 01-14 20:42:50.049298.049298 lmp.py:1494] -------------------------------- start prefill layer 21 --------------------------------
DEBUG 01-14 20:42:50.049717.049717 cuda_h.py:10] start start_load_qkvogn_s_weight_l_22
DEBUG 01-14 20:42:50.049042.049042 cuda_h.py:10] start start_load_qkvogn_s_weight_l_22
DEBUG 01-14 20:42:50.049938.049938 cuda_h.py:19] end start_load_qkvogn_s_weight_l_22 cost 3.62396240234375e-05 seconds
DEBUG 01-14 20:42:50.050933.050933 cuda_h.py:19] end start_load_qkvogn_s_weight_l_22 cost 6.985664367675781e-05 seconds
DEBUG 01-14 20:42:50.050251.050251 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-14 20:42:50.050082.050082 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-14 20:42:50.050535.050535 cuda_h.py:10] start sllm_worker_task
DEBUG 01-14 20:42:50.050578.050578 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-14 20:42:50.050514.050514 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-14 20:42:50.052766.052766 cuda_h.py:19] end allocate_cuda_memory cost 0.0019345283508300781 seconds
DEBUG 01-14 20:42:50.052557.052557 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-14 20:42:50.052134.052134 sllm_store_c.py:27] get device uuid map
DEBUG 01-14 20:42:50.052924.052924 sllm_store_c.py:29] call client load into gpu
DEBUG 01-14 20:42:50.052396.052396 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, de132795-c7d9-4db1-af98-dec8dd0daa6c
DEBUG 01-14 20:42:50.052863.052863 client.py:106] call stub.LoadModelAsync
DEBUG 01-14 20:42:50.053120.053120 cuda_h.py:10] start self_attn
INFO 01-14 20:42:50.053288.053288 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, de132795-c7d9-4db1-af98-dec8dd0daa6c
DEBUG 01-14 20:42:50.053515.053515 cuda_h.py:19] end load_into_gpu_async cost 0.0010864734649658203 seconds
DEBUG 01-14 20:42:50.053125.053125 cuda_h.py:10] start restore_tensors2
DEBUG 01-14 20:42:50.053555.053555 cuda_h.py:19] end restore_tensors2 cost 0.00014662742614746094 seconds
DEBUG 01-14 20:42:50.053808.053808 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.00347137451171875 seconds
INFO 01-14 20:42:50.053123.053123 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, de132795-c7d9-4db1-af98-dec8dd0daa6c
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-14 20:42:50.056136.056136 mlpmodule.py:1367]  experts func einsum cost 0.06827306747436523 s
DEBUG 01-14 20:42:50.056146.056146 cuda_h.py:19] end self_attn cost 0.003260374069213867 seconds
DEBUG 01-14 20:42:50.056721.056721 cuda_h.py:19] end iln_self_attn_paln cost 0.0066683292388916016 seconds
DEBUG 01-14 20:42:50.056902.056902 cuda_h.py:10] start layer_moe_generate_mp_l_22
DEBUG 01-14 20:42:50.056618.056618 cuda_h.py:10] start gate
DEBUG 01-14 20:42:50.057058.057058 cuda_h.py:19] end gate cost 0.0006411075592041016 seconds
DEBUG 01-14 20:42:50.057841.057841 cuda_h.py:10] start experts_map_get
DEBUG 01-14 20:42:50.057653.057653 lmp.py:1615] 
DEBUG 01-14 20:42:50.057653.057653 lmp.py:1615] Expert Token Distribution & Device Allocation:
DEBUG 01-14 20:42:50.057171.057171 lmp.py:1616]   Total experts: 64
DEBUG 01-14 20:42:50.057774.057774 lmp.py:1617]   CPU experts: 32 (50%)
DEBUG 01-14 20:42:50.057040.057040 lmp.py:1618]   GPU experts: 32 (50%)
DEBUG 01-14 20:42:50.057683.057683 lmp.py:1619] 
DEBUG 01-14 20:42:50.057683.057683 lmp.py:1619]   Expert ID | Tokens | Device
DEBUG 01-14 20:42:50.057849.057849 lmp.py:1620]   -----------------------------------
DEBUG 01-14 20:42:50.058207.058207 lmp.py:1625]   Expert 11 |     33 | CPU
DEBUG 01-14 20:42:50.058373.058373 lmp.py:1625]   Expert 44 |     40 | CPU
DEBUG 01-14 20:42:50.058301.058301 lmp.py:1625]   Expert  9 |     45 | CPU
DEBUG 01-14 20:42:50.058513.058513 lmp.py:1625]   Expert 54 |     55 | CPU
DEBUG 01-14 20:42:50.058203.058203 lmp.py:1625]   Expert 56 |     66 | CPU
DEBUG 01-14 20:42:50.058130.058130 lmp.py:1625]   Expert 62 |     91 | CPU
DEBUG 01-14 20:42:50.058058.058058 lmp.py:1625]   Expert 51 |    101 | CPU
DEBUG 01-14 20:42:50.058271.058271 lmp.py:1625]   Expert 35 |    102 | CPU
DEBUG 01-14 20:42:50.058483.058483 lmp.py:1625]   Expert 47 |    104 | CPU
DEBUG 01-14 20:42:50.058457.058457 lmp.py:1625]   Expert 52 |    106 | CPU
DEBUG 01-14 20:42:50.058193.058193 lmp.py:1625]   Expert 60 |    106 | CPU
DEBUG 01-14 20:42:50.058405.058405 lmp.py:1625]   Expert 22 |    108 | CPU
DEBUG 01-14 20:42:50.058141.058141 lmp.py:1625]   Expert  7 |    110 | CPU
DEBUG 01-14 20:42:50.058115.058115 lmp.py:1625]   Expert 41 |    110 | CPU
DEBUG 01-14 20:42:50.058566.058566 lmp.py:1625]   Expert  8 |    116 | CPU
DEBUG 01-14 20:42:50.058301.058301 lmp.py:1625]   Expert  1 |    121 | CPU
DEBUG 01-14 20:42:50.058752.058752 lmp.py:1625]   Expert 48 |    122 | CPU
DEBUG 01-14 20:42:50.058203.058203 lmp.py:1625]   Expert  6 |    127 | CPU
DEBUG 01-14 20:42:50.058654.058654 lmp.py:1625]   Expert 53 |    128 | CPU
DEBUG 01-14 20:42:50.058343.058343 lmp.py:1625]   Expert 32 |    132 | CPU
DEBUG 01-14 20:42:50.058794.058794 lmp.py:1625]   Expert  2 |    135 | CPU
DEBUG 01-14 20:42:50.058398.058398 lmp.py:1625]   Expert 27 |    136 | CPU
DEBUG 01-14 20:42:50.058756.058756 lmp.py:1625]   Expert 23 |    143 | CPU
DEBUG 01-14 20:42:50.058207.058207 lmp.py:1625]   Expert 14 |    147 | CPU
DEBUG 01-14 20:42:50.058181.058181 lmp.py:1625]   Expert 50 |    147 | CPU
DEBUG 01-14 20:42:50.058155.058155 lmp.py:1625]   Expert 59 |    147 | CPU
DEBUG 01-14 20:42:50.058890.058890 lmp.py:1625]   Expert 49 |    150 | CPU
DEBUG 01-14 20:42:50.058103.058103 lmp.py:1625]   Expert 39 |    152 | CPU
DEBUG 01-14 20:42:50.058984.058984 lmp.py:1625]   Expert 26 |    153 | CPU
DEBUG 01-14 20:42:50.058912.058912 lmp.py:1625]   Expert 34 |    158 | CPU
DEBUG 01-14 20:42:50.058363.058363 lmp.py:1625]   Expert 38 |    160 | CPU
DEBUG 01-14 20:42:50.058099.058099 lmp.py:1625]   Expert 24 |    170 | CPU
DEBUG 01-14 20:42:50.058311.058311 lmp.py:1625]   Expert  4 |    175 | GPU
DEBUG 01-14 20:42:50.058285.058285 lmp.py:1625]   Expert 57 |    184 | GPU
DEBUG 01-14 20:42:50.058021.058021 lmp.py:1625]   Expert 40 |    186 | GPU
DEBUG 01-14 20:42:50.058948.058948 lmp.py:1625]   Expert  0 |    188 | GPU
DEBUG 01-14 20:42:50.058399.058399 lmp.py:1625]   Expert 43 |    191 | GPU
DEBUG 01-14 20:42:50.058135.058135 lmp.py:1625]   Expert 63 |    192 | GPU
DEBUG 01-14 20:42:50.058347.058347 lmp.py:1625]   Expert 13 |    193 | GPU
DEBUG 01-14 20:42:50.058083.058083 lmp.py:1625]   Expert 46 |    193 | GPU
DEBUG 01-14 20:42:50.058057.058057 lmp.py:1625]   Expert 61 |    196 | GPU
DEBUG 01-14 20:42:50.058031.058031 lmp.py:1625]   Expert 19 |    197 | GPU
DEBUG 01-14 20:42:50.058767.058767 lmp.py:1625]   Expert 29 |    204 | GPU
DEBUG 01-14 20:42:50.058741.058741 lmp.py:1625]   Expert  5 |    208 | GPU
DEBUG 01-14 20:42:50.058238.058238 lmp.py:1625]   Expert 31 |    208 | GPU
DEBUG 01-14 20:42:50.058212.058212 lmp.py:1625]   Expert 33 |    220 | GPU
DEBUG 01-14 20:42:50.058709.058709 lmp.py:1625]   Expert 16 |    240 | GPU
DEBUG 01-14 20:42:50.058067.058067 lmp.py:1625]   Expert 37 |    243 | GPU
DEBUG 01-14 20:42:50.058280.058280 lmp.py:1625]   Expert 20 |    254 | GPU
DEBUG 01-14 20:42:50.058492.058492 lmp.py:1625]   Expert  3 |    256 | GPU
DEBUG 01-14 20:42:50.058990.058990 lmp.py:1625]   Expert 36 |    268 | GPU
DEBUG 01-14 20:42:50.058725.058725 lmp.py:1625]   Expert 15 |    274 | GPU
DEBUG 01-14 20:42:50.058938.058938 lmp.py:1625]   Expert 18 |    286 | GPU
DEBUG 01-14 20:42:50.058435.058435 lmp.py:1625]   Expert 17 |    297 | GPU
DEBUG 01-14 20:42:50.058409.058409 lmp.py:1625]   Expert 30 |    316 | GPU
DEBUG 01-14 20:42:50.058145.058145 lmp.py:1625]   Expert 55 |    318 | GPU
DEBUG 01-14 20:42:50.058595.058595 lmp.py:1625]   Expert 28 |    320 | GPU
DEBUG 01-14 20:42:50.058238.058238 lmp.py:1625]   Expert 12 |    327 | GPU
DEBUG 01-14 20:42:50.058689.058689 lmp.py:1625]   Expert 58 |    335 | GPU
DEBUG 01-14 20:42:50.058425.058425 lmp.py:1625]   Expert 25 |    367 | GPU
DEBUG 01-14 20:42:50.059161.059161 lmp.py:1625]   Expert 10 |    376 | GPU
DEBUG 01-14 20:42:50.059658.059658 lmp.py:1625]   Expert 45 |    382 | GPU
DEBUG 01-14 20:42:50.059393.059393 lmp.py:1625]   Expert 21 |    385 | GPU
DEBUG 01-14 20:42:50.059891.059891 lmp.py:1625]   Expert 42 |    588 | GPU
DEBUG 01-14 20:42:50.059580.059580 lmp.py:1626] 
DEBUG 01-14 20:42:50.059580.059580 lmp.py:1626]   CPU total tokens: 3721 (30.3%)
DEBUG 01-14 20:42:50.059223.059223 lmp.py:1627]   GPU total tokens: 8567 (69.7%)
DEBUG 01-14 20:42:50.059588.059588 cuda_h.py:19] end experts_map_get cost 0.0015003681182861328 seconds
DEBUG 01-14 20:42:50.059815.059815 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-14 20:42:50.059658.059658 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-14 20:42:50.059762.059762 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-14 20:42:50.060704.060704 cuda_h.py:19] end allocate_cuda_memory cost 0.0015721321105957031 seconds
DEBUG 01-14 20:42:50.061905.061905 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-14 20:42:50.061714.061714 sllm_store_c.py:27] get device uuid map
DEBUG 01-14 20:42:50.061000.061000 sllm_store_c.py:29] call client load into gpu
DEBUG 01-14 20:42:50.061173.061173 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 00854514-7f2f-4828-8716-20a652bee40f
DEBUG 01-14 20:42:50.061113.061113 client.py:106] call stub.LoadModelAsync
INFO 01-14 20:42:50.061593.061593 client.py:127] Model loaded
DEBUG 01-14 20:42:50.061052.061052 cuda_h.py:10] start restore2model
DEBUG 01-14 20:42:50.062437.062437 cuda_h.py:19] end restore2model cost 0.0003876686096191406 seconds
DEBUG 01-14 20:42:50.062790.062790 cuda_h.py:19] end sllm_worker_task cost 0.011857748031616211 seconds
INFO 01-14 20:42:50.062677.062677 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 00854514-7f2f-4828-8716-20a652bee40f
DEBUG 01-14 20:42:50.062620.062620 cuda_h.py:19] end load_into_gpu_async cost 0.0013337135314941406 seconds
DEBUG 01-14 20:42:50.062038.062038 cuda_h.py:10] start restore_tensors2
DEBUG 01-14 20:42:50.062556.062556 cuda_h.py:19] end restore_tensors2 cost 0.0004260540008544922 seconds
DEBUG 01-14 20:42:50.062175.062175 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.003725767135620117 seconds
DEBUG 01-14 20:42:50.063798.063798 cuda_h.py:10] start restore2model
DEBUG 01-14 20:42:50.065389.065389 cuda_h.py:19] end restore2model cost 0.0025823116302490234 seconds
DEBUG 01-14 20:42:50.065325.065325 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.006493806838989258 seconds
DEBUG 01-14 20:42:50.065451.065451 cuda_h.py:10] start gpu_sexperts
DEBUG 01-14 20:42:50.066104.066104 cuda_h.py:19] end gpu_sexperts cost 0.0002765655517578125 seconds
DEBUG 01-14 20:42:50.066834.066834 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-14 20:42:50.066729.066729 lmp.py:1683] 
DEBUG 01-14 20:42:50.066729.066729 lmp.py:1683]   Computing 32 experts on CPU...
DEBUG 01-14 20:42:50.066731.066731 cuda_h.py:19] end cpu_experts_submit cost 5.626678466796875e-05 seconds
DEBUG 01-14 20:42:50.066289.066289 cuda_h.py:10] start experts_func_mgpu_group_pad
DEBUG 01-14 20:42:50.075984.075984 mlpmodule.py:1460] group tensors cost 0.008846759796142578 s
DEBUG 01-14 20:42:50.076627.076627 cuda_h.py:10] start move_flat_hidden2cpu
DEBUG 01-14 20:42:50.080764.080764 cuda_h.py:19] end experts_func_mgpu_group_pad cost 0.014534950256347656 seconds
DEBUG 01-14 20:42:50.082202.082202 cuda_h.py:19] end move_flat_hidden2cpu cost 0.0060579776763916016 seconds
DEBUG 01-14 20:42:50.083302.083302 cuda_h.py:10] start gpu_group_list
DEBUG 01-14 20:42:50.084842.084842 cuda_h.py:19] end gpu_group_list cost 0.0007262229919433594 seconds
DEBUG 01-14 20:42:50.084151.084151 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-14 20:42:50.084904.084904 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 3.0517578125e-05 seconds
DEBUG 01-14 20:42:50.084363.084363 cuda_h.py:10] start wait_experts
INFO 01-14 20:42:50.084053.084053 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 00854514-7f2f-4828-8716-20a652bee40f
DEBUG 01-14 20:42:50.085194.085194 mlpmodule.py:1533] pad cost 0.003390073776245117 s
DEBUG 01-14 20:42:50.085218.085218 mlpmodule.py:1539] create cpu tensor cost 3.8623809814453125e-05 s
DEBUG 01-14 20:42:50.087340.087340 mlpmodule.py:1544] move to cpu cost 0.0020170211791992188 s
DEBUG 01-14 20:42:50.097234.097234 mlpmodule.py:1558] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-14 20:42:50.098426.098426 mlpmodule.py:1559] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-14 20:42:50.098131.098131 mlpmodule.py:1564] group_w3 first element: 0.00066375732421875
WARNING 01-14 20:42:50.098712.098712 mlpmodule.py:1574] start einsum2
DEBUG 01-14 20:42:50.117754.117754 mlpmodule.py:1584] group einsum cost 0.029288768768310547 s
INFO 01-14 20:42:50.118375.118375 client.py:127] Model loaded
DEBUG 01-14 20:42:50.118172.118172 mlpmodule.py:1593] cpy2cputensor cost 0.0008072853088378906 s
DEBUG 01-14 20:42:50.118971.118971 cuda_h.py:19] end wait_experts cost 0.033515214920043945 seconds
DEBUG 01-14 20:42:50.118742.118742 cuda_h.py:10] start move_outputs
DEBUG 01-14 20:42:50.118215.118215 cuda_h.py:10] start gpu_experts
DEBUG 01-14 20:42:50.118698.118698 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-14 20:42:50.120146.120146 cuda_h.py:19] end move_outputs cost 0.0019884109497070312 seconds
DEBUG 01-14 20:42:50.124526.124526 cuda_h.py:19] end wait_cetm_experts cost 0.005465030670166016 seconds
DEBUG 01-14 20:42:50.124795.124795 cuda_h.py:10] start gpu_group_einsum_mp_multi_list
DEBUG 01-14 20:42:50.124479.124479 cuda_h.py:10] start gpu_group_tensor
DEBUG 01-14 20:42:50.124236.124236 cuda_h.py:19] end gpu_group_tensor cost 0.000244140625 seconds
DEBUG 01-14 20:42:50.124452.124452 cuda_h.py:10] start gpu_group_einsum
DEBUG 01-14 20:42:50.125715.125715 cuda_h.py:19] end gpu_group_einsum cost 0.0006630420684814453 seconds
DEBUG 01-14 20:42:50.125150.125150 cuda_h.py:10] start gpu_final_hidden_states_scatter
DEBUG 01-14 20:42:50.125192.125192 cuda_h.py:10] start all_expert_outputs_slices
DEBUG 01-14 20:42:50.126312.126312 cuda_h.py:19] end all_expert_outputs_slices cost 0.00035691261291503906 seconds
DEBUG 01-14 20:42:50.126829.126829 cuda_h.py:10] start concat_expert_out
DEBUG 01-14 20:42:50.126203.126203 cuda_h.py:19] end concat_expert_out cost 6.29425048828125e-05 seconds
DEBUG 01-14 20:42:50.126583.126583 cuda_h.py:10] start index_scatter
DEBUG 01-14 20:42:50.126494.126494 cuda_h.py:19] end index_scatter cost 7.486343383789062e-05 seconds
DEBUG 01-14 20:42:50.126542.126542 cuda_h.py:19] end gpu_final_hidden_states_scatter cost 0.0007660388946533203 seconds
DEBUG 01-14 20:42:50.126896.126896 cuda_h.py:19] end gpu_experts cost 0.007887601852416992 seconds
DEBUG 01-14 20:42:50.126267.126267 cuda_h.py:10] start all_expert_weight_slices
DEBUG 01-14 20:42:50.127672.127672 cuda_h.py:19] end all_expert_weight_slices cost 0.0009691715240478516 seconds
DEBUG 01-14 20:42:50.127302.127302 cuda_h.py:10] start cpuoutputsdeal
DEBUG 01-14 20:42:50.128092.128092 cuda_h.py:10] start index_scatter
DEBUG 01-14 20:42:50.128235.128235 cuda_h.py:19] end index_scatter cost 5.316734313964844e-05 seconds
DEBUG 01-14 20:42:50.128574.128574 cuda_h.py:19] end cpuoutputsdeal cost 0.0005571842193603516 seconds
DEBUG 01-14 20:42:50.128768.128768 cuda_h.py:19] end layer_moe_generate_mp_l_22 cost 0.071533203125 seconds
DEBUG 01-14 20:42:50.128619.128619 cuda_h.py:19] end prefill_layer cost 0.07898926734924316 seconds
DEBUG 01-14 20:42:50.128045.128045 lmp.py:1551] -------------------------------- end prefill layer 21 --------------------------------
DEBUG 01-14 20:42:50.128178.128178 cuda_h.py:10] start prefill_layer
DEBUG 01-14 20:42:50.128842.128842 lmp.py:1494] -------------------------------- start prefill layer 22 --------------------------------
DEBUG 01-14 20:42:50.129737.129737 cuda_h.py:10] start start_load_qkvogn_s_weight_l_23
DEBUG 01-14 20:42:50.129585.129585 cuda_h.py:10] start start_load_qkvogn_s_weight_l_23
DEBUG 01-14 20:42:50.129482.129482 cuda_h.py:19] end start_load_qkvogn_s_weight_l_23 cost 3.647804260253906e-05 seconds
DEBUG 01-14 20:42:50.129238.129238 cuda_h.py:19] end start_load_qkvogn_s_weight_l_23 cost 6.961822509765625e-05 seconds
DEBUG 01-14 20:42:50.129556.129556 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-14 20:42:50.129864.129864 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-14 20:42:50.129271.129271 cuda_h.py:10] start sllm_worker_task
DEBUG 01-14 20:42:50.129837.129837 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-14 20:42:50.129581.129581 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-14 20:42:50.131637.131637 cuda_h.py:19] end allocate_cuda_memory cost 0.002247333526611328 seconds
DEBUG 01-14 20:42:50.131931.131931 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-14 20:42:50.131555.131555 sllm_store_c.py:27] get device uuid map
DEBUG 01-14 20:42:50.131153.131153 sllm_store_c.py:29] call client load into gpu
DEBUG 01-14 20:42:50.131386.131386 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, a1598f93-0d27-4828-ada6-dc5451ed4884
DEBUG 01-14 20:42:50.132283.132283 client.py:106] call stub.LoadModelAsync
DEBUG 01-14 20:42:50.132243.132243 cuda_h.py:10] start self_attn
INFO 01-14 20:42:50.132192.132192 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, a1598f93-0d27-4828-ada6-dc5451ed4884
DEBUG 01-14 20:42:50.132267.132267 cuda_h.py:19] end load_into_gpu_async cost 0.0010862350463867188 seconds
DEBUG 01-14 20:42:50.133255.133255 cuda_h.py:10] start restore_tensors2
DEBUG 01-14 20:42:50.133344.133344 cuda_h.py:19] end restore_tensors2 cost 7.462501525878906e-05 seconds
DEBUG 01-14 20:42:50.133554.133554 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.003757476806640625 seconds
INFO 01-14 20:42:50.133060.133060 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, a1598f93-0d27-4828-ada6-dc5451ed4884
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-14 20:42:50.135773.135773 cuda_h.py:19] end self_attn cost 0.002876758575439453 seconds
DEBUG 01-14 20:42:50.135224.135224 mlpmodule.py:1367]  experts func einsum cost 0.06905174255371094 s
DEBUG 01-14 20:42:50.135638.135638 cuda_h.py:19] end iln_self_attn_paln cost 0.0067577362060546875 seconds
DEBUG 01-14 20:42:50.136966.136966 cuda_h.py:10] start layer_moe_generate_mp_l_23
DEBUG 01-14 20:42:50.136444.136444 cuda_h.py:10] start gate
DEBUG 01-14 20:42:50.136805.136805 cuda_h.py:19] end gate cost 0.0006527900695800781 seconds
DEBUG 01-14 20:42:50.136688.136688 cuda_h.py:10] start experts_map_get
DEBUG 01-14 20:42:50.137645.137645 lmp.py:1615] 
DEBUG 01-14 20:42:50.137645.137645 lmp.py:1615] Expert Token Distribution & Device Allocation:
DEBUG 01-14 20:42:50.137832.137832 lmp.py:1616]   Total experts: 64
DEBUG 01-14 20:42:50.137720.137720 lmp.py:1617]   CPU experts: 32 (50%)
DEBUG 01-14 20:42:50.137509.137509 lmp.py:1618]   GPU experts: 32 (50%)
DEBUG 01-14 20:42:50.137105.137105 lmp.py:1619] 
DEBUG 01-14 20:42:50.137105.137105 lmp.py:1619]   Expert ID | Tokens | Device
DEBUG 01-14 20:42:50.137179.137179 lmp.py:1620]   -----------------------------------
DEBUG 01-14 20:42:50.137491.137491 lmp.py:1625]   Expert 25 |     16 | CPU
DEBUG 01-14 20:42:50.137895.137895 lmp.py:1625]   Expert 45 |     34 | CPU
DEBUG 01-14 20:42:50.137062.137062 lmp.py:1625]   Expert 48 |     43 | CPU
DEBUG 01-14 20:42:50.137466.137466 lmp.py:1625]   Expert  9 |     63 | CPU
DEBUG 01-14 20:42:50.137871.137871 lmp.py:1625]   Expert 43 |     67 | CPU
DEBUG 01-14 20:42:50.137798.137798 lmp.py:1625]   Expert 54 |     77 | CPU
DEBUG 01-14 20:42:50.137203.137203 lmp.py:1625]   Expert  0 |     86 | CPU
DEBUG 01-14 20:42:50.137607.137607 lmp.py:1625]   Expert 47 |     89 | CPU
DEBUG 01-14 20:42:50.137250.137250 lmp.py:1625]   Expert 50 |     90 | CPU
DEBUG 01-14 20:42:50.137655.137655 lmp.py:1625]   Expert  6 |     91 | CPU
DEBUG 01-14 20:42:50.137344.137344 lmp.py:1625]   Expert  1 |     93 | CPU
DEBUG 01-14 20:42:50.137034.137034 lmp.py:1625]   Expert 13 |    101 | CPU
DEBUG 01-14 20:42:50.137438.137438 lmp.py:1625]   Expert 20 |    102 | CPU
DEBUG 01-14 20:42:50.137889.137889 lmp.py:1625]   Expert 15 |    103 | CPU
DEBUG 01-14 20:42:50.137817.137817 lmp.py:1625]   Expert 62 |    104 | CPU
DEBUG 01-14 20:42:50.137619.137619 lmp.py:1625]   Expert 61 |    110 | CPU
DEBUG 01-14 20:42:50.137739.137739 lmp.py:1625]   Expert 57 |    114 | CPU
DEBUG 01-14 20:42:50.137951.137951 lmp.py:1625]   Expert 37 |    115 | CPU
DEBUG 01-14 20:42:50.137925.137925 lmp.py:1625]   Expert 36 |    117 | CPU
DEBUG 01-14 20:42:50.137661.137661 lmp.py:1625]   Expert 21 |    120 | CPU
DEBUG 01-14 20:42:50.137158.137158 lmp.py:1625]   Expert 38 |    124 | CPU
DEBUG 01-14 20:42:50.137132.137132 lmp.py:1625]   Expert  7 |    126 | CPU
DEBUG 01-14 20:42:50.137868.137868 lmp.py:1625]   Expert 46 |    126 | CPU
DEBUG 01-14 20:42:50.137365.137365 lmp.py:1625]   Expert 14 |    145 | CPU
DEBUG 01-14 20:42:50.137816.137816 lmp.py:1625]   Expert 24 |    145 | CPU
DEBUG 01-14 20:42:50.137028.137028 lmp.py:1625]   Expert 42 |    148 | CPU
DEBUG 01-14 20:42:50.137003.137003 lmp.py:1625]   Expert 26 |    153 | CPU
DEBUG 01-14 20:42:50.137977.137977 lmp.py:1625]   Expert 44 |    155 | CPU
DEBUG 01-14 20:42:50.137712.137712 lmp.py:1625]   Expert 31 |    156 | CPU
DEBUG 01-14 20:42:50.137209.137209 lmp.py:1625]   Expert 10 |    158 | CPU
DEBUG 01-14 20:42:50.137183.137183 lmp.py:1625]   Expert  2 |    159 | CPU
DEBUG 01-14 20:42:50.137634.137634 lmp.py:1625]   Expert 11 |    161 | CPU
DEBUG 01-14 20:42:50.137324.137324 lmp.py:1625]   Expert 28 |    167 | GPU
DEBUG 01-14 20:42:50.137298.137298 lmp.py:1625]   Expert 52 |    174 | GPU
DEBUG 01-14 20:42:50.137033.137033 lmp.py:1625]   Expert  3 |    176 | GPU
DEBUG 01-14 20:42:50.137530.137530 lmp.py:1625]   Expert 32 |    179 | GPU
DEBUG 01-14 20:42:50.137266.137266 lmp.py:1625]   Expert 35 |    181 | GPU
DEBUG 01-14 20:42:50.137525.137525 lmp.py:1625]   Expert 19 |    190 | GPU
DEBUG 01-14 20:42:50.137499.137499 lmp.py:1625]   Expert 12 |    195 | GPU
DEBUG 01-14 20:42:50.137996.137996 lmp.py:1625]   Expert 56 |    202 | GPU
DEBUG 01-14 20:42:50.137732.137732 lmp.py:1625]   Expert  8 |    209 | GPU
DEBUG 01-14 20:42:50.137467.137467 lmp.py:1625]   Expert 60 |    214 | GPU
DEBUG 01-14 20:42:50.138203.138203 lmp.py:1625]   Expert 41 |    215 | GPU
DEBUG 01-14 20:42:50.138939.138939 lmp.py:1625]   Expert 59 |    216 | GPU
DEBUG 01-14 20:42:50.138436.138436 lmp.py:1625]   Expert  4 |    226 | GPU
DEBUG 01-14 20:42:50.138695.138695 lmp.py:1625]   Expert 16 |    228 | GPU
DEBUG 01-14 20:42:50.138430.138430 lmp.py:1625]   Expert 40 |    234 | GPU
DEBUG 01-14 20:42:50.138689.138689 lmp.py:1625]   Expert 55 |    242 | GPU
DEBUG 01-14 20:42:50.138186.138186 lmp.py:1625]   Expert 23 |    243 | GPU
DEBUG 01-14 20:42:50.138922.138922 lmp.py:1625]   Expert 53 |    247 | GPU
DEBUG 01-14 20:42:50.138419.138419 lmp.py:1625]   Expert 58 |    256 | GPU
DEBUG 01-14 20:42:50.138916.138916 lmp.py:1625]   Expert 51 |    257 | GPU
DEBUG 01-14 20:42:50.138175.138175 lmp.py:1625]   Expert 49 |    258 | GPU
DEBUG 01-14 20:42:50.138672.138672 lmp.py:1625]   Expert 34 |    272 | GPU
DEBUG 01-14 20:42:50.138170.138170 lmp.py:1625]   Expert 18 |    273 | GPU
DEBUG 01-14 20:42:50.138667.138667 lmp.py:1625]   Expert 29 |    286 | GPU
DEBUG 01-14 20:42:50.138402.138402 lmp.py:1625]   Expert 63 |    291 | GPU
DEBUG 01-14 20:42:50.138900.138900 lmp.py:1625]   Expert 39 |    383 | GPU
DEBUG 01-14 20:42:50.138158.138158 lmp.py:1625]   Expert 27 |    385 | GPU
DEBUG 01-14 20:42:50.138894.138894 lmp.py:1625]   Expert 33 |    401 | GPU
DEBUG 01-14 20:42:50.138391.138391 lmp.py:1625]   Expert 17 |    415 | GPU
DEBUG 01-14 20:42:50.138041.138041 lmp.py:1625]   Expert 22 |    416 | GPU
DEBUG 01-14 20:42:50.138015.138015 lmp.py:1625]   Expert 30 |    485 | GPU
DEBUG 01-14 20:42:50.138704.138704 lmp.py:1625]   Expert  5 |    681 | GPU
DEBUG 01-14 20:42:50.138632.138632 lmp.py:1626] 
DEBUG 01-14 20:42:50.138632.138632 lmp.py:1626]   CPU total tokens: 3491 (28.4%)
DEBUG 01-14 20:42:50.138560.138560 lmp.py:1627]   GPU total tokens: 8797 (71.6%)
DEBUG 01-14 20:42:50.138071.138071 cuda_h.py:19] end experts_map_get cost 0.0015172958374023438 seconds
DEBUG 01-14 20:42:50.138728.138728 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-14 20:42:50.138333.138333 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-14 20:42:50.138477.138477 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-14 20:42:50.140031.140031 cuda_h.py:19] end allocate_cuda_memory cost 0.001672506332397461 seconds
DEBUG 01-14 20:42:50.140815.140815 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-14 20:42:50.140101.140101 sllm_store_c.py:27] get device uuid map
DEBUG 01-14 20:42:50.140102.140102 sllm_store_c.py:29] call client load into gpu
DEBUG 01-14 20:42:50.140467.140467 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 6ce907c2-b76a-4aca-8822-8f25bdee80f2
DEBUG 01-14 20:42:50.140633.140633 client.py:106] call stub.LoadModelAsync
INFO 01-14 20:42:50.141443.141443 client.py:127] Model loaded
DEBUG 01-14 20:42:50.141803.141803 cuda_h.py:10] start restore2model
DEBUG 01-14 20:42:50.141487.141487 cuda_h.py:19] end restore2model cost 0.0004334449768066406 seconds
DEBUG 01-14 20:42:50.141939.141939 cuda_h.py:19] end sllm_worker_task cost 0.012163877487182617 seconds
INFO 01-14 20:42:50.141340.141340 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 6ce907c2-b76a-4aca-8822-8f25bdee80f2
DEBUG 01-14 20:42:50.141997.141997 cuda_h.py:19] end load_into_gpu_async cost 0.0012545585632324219 seconds
DEBUG 01-14 20:42:50.141892.141892 cuda_h.py:10] start restore_tensors2
DEBUG 01-14 20:42:50.142802.142802 cuda_h.py:19] end restore_tensors2 cost 0.00043201446533203125 seconds
DEBUG 01-14 20:42:50.142751.142751 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0037615299224853516 seconds
DEBUG 01-14 20:42:50.142898.142898 cuda_h.py:10] start restore2model
DEBUG 01-14 20:42:50.144814.144814 cuda_h.py:19] end restore2model cost 0.002612590789794922 seconds
DEBUG 01-14 20:42:50.145704.145704 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.006555080413818359 seconds
DEBUG 01-14 20:42:50.145976.145976 cuda_h.py:10] start gpu_sexperts
DEBUG 01-14 20:42:50.145483.145483 cuda_h.py:19] end gpu_sexperts cost 0.0002720355987548828 seconds
DEBUG 01-14 20:42:50.145021.145021 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-14 20:42:50.145869.145869 lmp.py:1683] 
DEBUG 01-14 20:42:50.145869.145869 lmp.py:1683]   Computing 32 experts on CPU...
DEBUG 01-14 20:42:50.145951.145951 cuda_h.py:19] end cpu_experts_submit cost 6.031990051269531e-05 seconds
DEBUG 01-14 20:42:50.145270.145270 cuda_h.py:10] start experts_func_mgpu_group_pad
DEBUG 01-14 20:42:50.155532.155532 mlpmodule.py:1460] group tensors cost 0.009950399398803711 s
DEBUG 01-14 20:42:50.156457.156457 cuda_h.py:10] start move_flat_hidden2cpu
DEBUG 01-14 20:42:50.158091.158091 cuda_h.py:19] end experts_func_mgpu_group_pad cost 0.01300501823425293 seconds
DEBUG 01-14 20:42:50.160684.160684 cuda_h.py:10] start gpu_group_list
DEBUG 01-14 20:42:50.160272.160272 cuda_h.py:19] end gpu_group_list cost 0.0004494190216064453 seconds
DEBUG 01-14 20:42:50.160954.160954 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-14 20:42:50.160381.160381 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.5987625122070312e-05 seconds
DEBUG 01-14 20:42:50.160621.160621 cuda_h.py:10] start wait_experts
INFO 01-14 20:42:50.160284.160284 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 6ce907c2-b76a-4aca-8822-8f25bdee80f2
DEBUG 01-14 20:42:50.162021.162021 cuda_h.py:19] end move_flat_hidden2cpu cost 0.006105899810791016 seconds
DEBUG 01-14 20:42:50.164402.164402 mlpmodule.py:1533] pad cost 0.0015730857849121094 s
DEBUG 01-14 20:42:50.164220.164220 mlpmodule.py:1539] create cpu tensor cost 4.482269287109375e-05 s
DEBUG 01-14 20:42:50.166153.166153 mlpmodule.py:1544] move to cpu cost 0.0019102096557617188 s
DEBUG 01-14 20:42:50.175485.175485 mlpmodule.py:1558] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-14 20:42:50.176662.176662 mlpmodule.py:1559] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-14 20:42:50.176474.176474 mlpmodule.py:1564] group_w3 first element: -0.018798828125
WARNING 01-14 20:42:50.176743.176743 mlpmodule.py:1574] start einsum2
DEBUG 01-14 20:42:50.193014.193014 mlpmodule.py:1584] group einsum cost 0.02698349952697754 s
DEBUG 01-14 20:42:50.194669.194669 mlpmodule.py:1593] cpy2cputensor cost 0.0007412433624267578 s
DEBUG 01-14 20:42:50.194843.194843 cuda_h.py:10] start move_outputs
DEBUG 01-14 20:42:50.197837.197837 cuda_h.py:19] end move_outputs cost 0.0025527477264404297 seconds
INFO 01-14 20:42:50.198460.198460 client.py:127] Model loaded
DEBUG 01-14 20:42:50.198301.198301 cuda_h.py:19] end wait_experts cost 0.03728199005126953 seconds
DEBUG 01-14 20:42:50.198362.198362 cuda_h.py:10] start gpu_experts
DEBUG 01-14 20:42:50.198423.198423 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-14 20:42:50.201339.201339 cuda_h.py:19] end wait_cetm_experts cost 0.0029888153076171875 seconds
DEBUG 01-14 20:42:50.201885.201885 cuda_h.py:10] start gpu_group_einsum_mp_multi_list
DEBUG 01-14 20:42:50.201218.201218 cuda_h.py:10] start gpu_group_tensor
DEBUG 01-14 20:42:50.201783.201783 cuda_h.py:19] end gpu_group_tensor cost 0.00024437904357910156 seconds
DEBUG 01-14 20:42:50.201946.201946 cuda_h.py:10] start gpu_group_einsum
DEBUG 01-14 20:42:50.202593.202593 cuda_h.py:19] end gpu_group_einsum cost 0.0006656646728515625 seconds
DEBUG 01-14 20:42:50.202896.202896 cuda_h.py:10] start gpu_final_hidden_states_scatter
DEBUG 01-14 20:42:50.202368.202368 cuda_h.py:10] start all_expert_outputs_slices
DEBUG 01-14 20:42:50.203726.203726 cuda_h.py:19] end all_expert_outputs_slices cost 0.00035691261291503906 seconds
DEBUG 01-14 20:42:50.203290.203290 cuda_h.py:10] start concat_expert_out
DEBUG 01-14 20:42:50.203611.203611 cuda_h.py:19] end concat_expert_out cost 5.91278076171875e-05 seconds
DEBUG 01-14 20:42:50.203514.203514 cuda_h.py:10] start index_scatter
DEBUG 01-14 20:42:50.203756.203756 cuda_h.py:19] end index_scatter cost 7.510185241699219e-05 seconds
DEBUG 01-14 20:42:50.203850.203850 cuda_h.py:19] end gpu_final_hidden_states_scatter cost 0.0007586479187011719 seconds
DEBUG 01-14 20:42:50.203005.203005 cuda_h.py:19] end gpu_experts cost 0.005323171615600586 seconds
DEBUG 01-14 20:42:50.203615.203615 cuda_h.py:10] start all_expert_weight_slices
DEBUG 01-14 20:42:50.204333.204333 cuda_h.py:19] end all_expert_weight_slices cost 0.0010223388671875 seconds
DEBUG 01-14 20:42:50.204878.204878 cuda_h.py:10] start cpuoutputsdeal
DEBUG 01-14 20:42:50.205383.205383 cuda_h.py:10] start index_scatter
DEBUG 01-14 20:42:50.205717.205717 cuda_h.py:19] end index_scatter cost 5.1021575927734375e-05 seconds
DEBUG 01-14 20:42:50.205341.205341 cuda_h.py:19] end cpuoutputsdeal cost 0.0005574226379394531 seconds
DEBUG 01-14 20:42:50.205728.205728 cuda_h.py:19] end layer_moe_generate_mp_l_23 cost 0.06938385963439941 seconds
DEBUG 01-14 20:42:50.205960.205960 cuda_h.py:19] end prefill_layer cost 0.07691073417663574 seconds
DEBUG 01-14 20:42:50.205108.205108 lmp.py:1551] -------------------------------- end prefill layer 22 --------------------------------
DEBUG 01-14 20:42:50.206719.206719 cuda_h.py:10] start prefill_layer
DEBUG 01-14 20:42:50.206375.206375 lmp.py:1494] -------------------------------- start prefill layer 23 --------------------------------
DEBUG 01-14 20:42:50.206316.206316 cuda_h.py:10] start start_load_qkvogn_s_weight_l_24
DEBUG 01-14 20:42:50.206403.206403 cuda_h.py:10] start start_load_qkvogn_s_weight_l_24
DEBUG 01-14 20:42:50.206776.206776 cuda_h.py:19] end start_load_qkvogn_s_weight_l_24 cost 3.647804260253906e-05 seconds
DEBUG 01-14 20:42:50.206009.206009 cuda_h.py:19] end start_load_qkvogn_s_weight_l_24 cost 7.033348083496094e-05 seconds
DEBUG 01-14 20:42:50.206759.206759 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-14 20:42:50.206304.206304 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-14 20:42:50.206096.206096 cuda_h.py:10] start sllm_worker_task
DEBUG 01-14 20:42:50.206259.206259 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-14 20:42:50.206698.206698 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-14 20:42:50.208398.208398 cuda_h.py:19] end allocate_cuda_memory cost 0.001878499984741211 seconds
DEBUG 01-14 20:42:50.208076.208076 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-14 20:42:50.208462.208462 sllm_store_c.py:27] get device uuid map
DEBUG 01-14 20:42:50.208013.208013 sllm_store_c.py:29] call client load into gpu
DEBUG 01-14 20:42:50.208008.208008 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 299d6fd7-1b7b-4d65-8aa4-d0a7c718d283
DEBUG 01-14 20:42:50.208144.208144 client.py:106] call stub.LoadModelAsync
DEBUG 01-14 20:42:50.209340.209340 cuda_h.py:10] start self_attn
INFO 01-14 20:42:50.209785.209785 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 299d6fd7-1b7b-4d65-8aa4-d0a7c718d283
DEBUG 01-14 20:42:50.209389.209389 cuda_h.py:19] end load_into_gpu_async cost 0.0009996891021728516 seconds
DEBUG 01-14 20:42:50.209423.209423 cuda_h.py:10] start restore_tensors2
DEBUG 01-14 20:42:50.209621.209621 cuda_h.py:19] end restore_tensors2 cost 0.0001518726348876953 seconds
DEBUG 01-14 20:42:50.209636.209636 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0033140182495117188 seconds
INFO 01-14 20:42:50.209957.209957 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 299d6fd7-1b7b-4d65-8aa4-d0a7c718d283
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
DEBUG 01-14 20:42:50.212107.212107 mlpmodule.py:1367]  experts func einsum cost 0.06630611419677734 s
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-14 20:42:50.213574.213574 cuda_h.py:19] end self_attn cost 0.003942728042602539 seconds
DEBUG 01-14 20:42:50.213573.213573 cuda_h.py:19] end iln_self_attn_paln cost 0.007273435592651367 seconds
DEBUG 01-14 20:42:50.213469.213469 cuda_h.py:10] start layer_moe_generate_mp_l_24
DEBUG 01-14 20:42:50.213424.213424 cuda_h.py:10] start gate
DEBUG 01-14 20:42:50.214148.214148 cuda_h.py:19] end gate cost 0.0006394386291503906 seconds
DEBUG 01-14 20:42:50.214839.214839 cuda_h.py:10] start experts_map_get
DEBUG 01-14 20:42:50.214214.214214 lmp.py:1615] 
DEBUG 01-14 20:42:50.214214.214214 lmp.py:1615] Expert Token Distribution & Device Allocation:
DEBUG 01-14 20:42:50.214592.214592 lmp.py:1616]   Total experts: 64
DEBUG 01-14 20:42:50.214116.214116 lmp.py:1617]   CPU experts: 32 (50%)
DEBUG 01-14 20:42:50.214051.214051 lmp.py:1618]   GPU experts: 32 (50%)
DEBUG 01-14 20:42:50.214932.214932 lmp.py:1619] 
DEBUG 01-14 20:42:50.214932.214932 lmp.py:1619]   Expert ID | Tokens | Device
DEBUG 01-14 20:42:50.214575.214575 lmp.py:1620]   -----------------------------------
DEBUG 01-14 20:42:50.214172.214172 lmp.py:1625]   Expert  5 |     13 | CPU
DEBUG 01-14 20:42:50.214577.214577 lmp.py:1625]   Expert 56 |     43 | CPU
DEBUG 01-14 20:42:50.214504.214504 lmp.py:1625]   Expert 27 |     91 | CPU
DEBUG 01-14 20:42:50.214670.214670 lmp.py:1625]   Expert 53 |     93 | CPU
DEBUG 01-14 20:42:50.214837.214837 lmp.py:1625]   Expert 40 |     94 | CPU
DEBUG 01-14 20:42:50.214287.214287 lmp.py:1625]   Expert 16 |     97 | CPU
DEBUG 01-14 20:42:50.214261.214261 lmp.py:1625]   Expert 47 |    100 | CPU
DEBUG 01-14 20:42:50.214712.214712 lmp.py:1625]   Expert 17 |    103 | CPU
DEBUG 01-14 20:42:50.214925.214925 lmp.py:1625]   Expert 28 |    106 | CPU
DEBUG 01-14 20:42:50.214899.214899 lmp.py:1625]   Expert  7 |    110 | CPU
DEBUG 01-14 20:42:50.214350.214350 lmp.py:1625]   Expert 37 |    111 | CPU
DEBUG 01-14 20:42:50.214562.214562 lmp.py:1625]   Expert 51 |    112 | CPU
DEBUG 01-14 20:42:50.215775.215775 lmp.py:1625]   Expert 49 |    115 | CPU
DEBUG 01-14 20:42:50.215702.215702 lmp.py:1625]   Expert 63 |    123 | CPU
DEBUG 01-14 20:42:50.215153.215153 lmp.py:1625]   Expert 58 |    131 | CPU
DEBUG 01-14 20:42:50.215366.215366 lmp.py:1625]   Expert 38 |    135 | CPU
DEBUG 01-14 20:42:50.215101.215101 lmp.py:1625]   Expert 57 |    137 | CPU
DEBUG 01-14 20:42:50.215314.215314 lmp.py:1625]   Expert 39 |    140 | CPU
DEBUG 01-14 20:42:50.215049.215049 lmp.py:1625]   Expert 14 |    147 | CPU
DEBUG 01-14 20:42:50.215262.215262 lmp.py:1625]   Expert 11 |    152 | CPU
DEBUG 01-14 20:42:50.215474.215474 lmp.py:1625]   Expert  1 |    154 | CPU
DEBUG 01-14 20:42:50.215448.215448 lmp.py:1625]   Expert 62 |    157 | CPU
DEBUG 01-14 20:42:50.215422.215422 lmp.py:1625]   Expert 25 |    158 | CPU
DEBUG 01-14 20:42:50.215589.215589 lmp.py:1625]   Expert 12 |    160 | CPU
DEBUG 01-14 20:42:50.215040.215040 lmp.py:1625]   Expert 33 |    160 | CPU
DEBUG 01-14 20:42:50.215014.215014 lmp.py:1625]   Expert 52 |    162 | CPU
DEBUG 01-14 20:42:50.215226.215226 lmp.py:1625]   Expert 23 |    165 | CPU
DEBUG 01-14 20:42:50.215962.215962 lmp.py:1625]   Expert 21 |    167 | CPU
DEBUG 01-14 20:42:50.215936.215936 lmp.py:1625]   Expert 30 |    168 | CPU
DEBUG 01-14 20:42:50.215148.215148 lmp.py:1625]   Expert 45 |    169 | CPU
DEBUG 01-14 20:42:50.215884.215884 lmp.py:1625]   Expert  6 |    179 | CPU
DEBUG 01-14 20:42:50.215096.215096 lmp.py:1625]   Expert 55 |    180 | CPU
DEBUG 01-14 20:42:50.215309.215309 lmp.py:1625]   Expert 36 |    181 | GPU
DEBUG 01-14 20:42:50.215521.215521 lmp.py:1625]   Expert  9 |    186 | GPU
DEBUG 01-14 20:42:50.215734.215734 lmp.py:1625]   Expert 31 |    186 | GPU
DEBUG 01-14 20:42:50.215708.215708 lmp.py:1625]   Expert 60 |    194 | GPU
DEBUG 01-14 20:42:50.215443.215443 lmp.py:1625]   Expert  4 |    197 | GPU
DEBUG 01-14 20:42:50.215179.215179 lmp.py:1625]   Expert  3 |    201 | GPU
DEBUG 01-14 20:42:50.215153.215153 lmp.py:1625]   Expert 19 |    205 | GPU
DEBUG 01-14 20:42:50.215365.215365 lmp.py:1625]   Expert 44 |    207 | GPU
DEBUG 01-14 20:42:50.215532.215532 lmp.py:1625]   Expert 34 |    208 | GPU
DEBUG 01-14 20:42:50.215982.215982 lmp.py:1625]   Expert 50 |    224 | GPU
DEBUG 01-14 20:42:50.215718.215718 lmp.py:1625]   Expert 22 |    225 | GPU
DEBUG 01-14 20:42:50.215692.215692 lmp.py:1625]   Expert  0 |    227 | GPU
DEBUG 01-14 20:42:50.215428.215428 lmp.py:1625]   Expert 41 |    229 | GPU
DEBUG 01-14 20:42:50.215163.215163 lmp.py:1625]   Expert 26 |    230 | GPU
DEBUG 01-14 20:42:50.215899.215899 lmp.py:1625]   Expert 43 |    231 | GPU
DEBUG 01-14 20:42:50.215111.215111 lmp.py:1625]   Expert 59 |    236 | GPU
DEBUG 01-14 20:42:50.215324.215324 lmp.py:1625]   Expert 13 |    239 | GPU
DEBUG 01-14 20:42:50.215775.215775 lmp.py:1625]   Expert 18 |    239 | GPU
DEBUG 01-14 20:42:50.215464.215464 lmp.py:1625]   Expert 42 |    252 | GPU
DEBUG 01-14 20:42:50.215915.215915 lmp.py:1625]   Expert 54 |    254 | GPU
DEBUG 01-14 20:42:50.215651.215651 lmp.py:1625]   Expert 61 |    256 | GPU
DEBUG 01-14 20:42:50.215863.215863 lmp.py:1625]   Expert 20 |    258 | GPU
DEBUG 01-14 20:42:50.215837.215837 lmp.py:1625]   Expert 24 |    263 | GPU
DEBUG 01-14 20:42:50.215811.215811 lmp.py:1625]   Expert 15 |    264 | GPU
DEBUG 01-14 20:42:50.215547.215547 lmp.py:1625]   Expert 35 |    271 | GPU
DEBUG 01-14 20:42:50.215282.215282 lmp.py:1625]   Expert 29 |    279 | GPU
DEBUG 01-14 20:42:50.215210.215210 lmp.py:1625]   Expert 32 |    284 | GPU
DEBUG 01-14 20:42:50.215899.215899 lmp.py:1625]   Expert 10 |    298 | GPU
DEBUG 01-14 20:42:50.215112.215112 lmp.py:1625]   Expert  8 |    344 | GPU
DEBUG 01-14 20:42:50.215278.215278 lmp.py:1625]   Expert  2 |    350 | GPU
DEBUG 01-14 20:42:50.215206.215206 lmp.py:1625]   Expert 46 |    468 | GPU
DEBUG 01-14 20:42:50.215133.215133 lmp.py:1625]   Expert 48 |    470 | GPU
DEBUG 01-14 20:42:50.215253.215253 lmp.py:1626] 
DEBUG 01-14 20:42:50.215253.215253 lmp.py:1626]   CPU total tokens: 4132 (33.6%)
DEBUG 01-14 20:42:50.215373.215373 lmp.py:1627]   GPU total tokens: 8156 (66.4%)
DEBUG 01-14 20:42:50.215784.215784 cuda_h.py:19] end experts_map_get cost 0.0015110969543457031 seconds
DEBUG 01-14 20:42:50.215873.215873 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-14 20:42:50.216954.216954 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-14 20:42:50.216012.216012 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-14 20:42:50.216864.216864 cuda_h.py:19] end allocate_cuda_memory cost 0.0002703666687011719 seconds
DEBUG 01-14 20:42:50.216714.216714 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-14 20:42:50.216801.216801 sllm_store_c.py:27] get device uuid map
DEBUG 01-14 20:42:50.216656.216656 sllm_store_c.py:29] call client load into gpu
DEBUG 01-14 20:42:50.216306.216306 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, bbfc11a3-25f7-4299-bd65-ef2cff026d32
DEBUG 01-14 20:42:50.216763.216763 client.py:106] call stub.LoadModelAsync
INFO 01-14 20:42:50.217466.217466 client.py:127] Model loaded
DEBUG 01-14 20:42:50.217110.217110 cuda_h.py:10] start restore2model
DEBUG 01-14 20:42:50.217799.217799 cuda_h.py:19] end restore2model cost 0.0003681182861328125 seconds
DEBUG 01-14 20:42:50.217529.217529 cuda_h.py:19] end sllm_worker_task cost 0.011059761047363281 seconds
INFO 01-14 20:42:50.217296.217296 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, bbfc11a3-25f7-4299-bd65-ef2cff026d32
DEBUG 01-14 20:42:50.217338.217338 cuda_h.py:19] end load_into_gpu_async cost 0.0012001991271972656 seconds
DEBUG 01-14 20:42:50.217994.217994 cuda_h.py:10] start restore_tensors2
DEBUG 01-14 20:42:50.218056.218056 cuda_h.py:19] end restore_tensors2 cost 0.0004394054412841797 seconds
DEBUG 01-14 20:42:50.218390.218390 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.002298116683959961 seconds
DEBUG 01-14 20:42:50.218682.218682 cuda_h.py:10] start restore2model
DEBUG 01-14 20:42:50.220253.220253 cuda_h.py:19] end restore2model cost 0.0025675296783447266 seconds
DEBUG 01-14 20:42:50.221003.221003 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.005053997039794922 seconds
DEBUG 01-14 20:42:50.221276.221276 cuda_h.py:10] start gpu_sexperts
DEBUG 01-14 20:42:50.221451.221451 cuda_h.py:19] end gpu_sexperts cost 0.00027298927307128906 seconds
DEBUG 01-14 20:42:50.221466.221466 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-14 20:42:50.221076.221076 lmp.py:1683] 
DEBUG 01-14 20:42:50.221076.221076 lmp.py:1683]   Computing 32 experts on CPU...
DEBUG 01-14 20:42:50.221012.221012 cuda_h.py:19] end cpu_experts_submit cost 5.793571472167969e-05 seconds
DEBUG 01-14 20:42:50.221622.221622 cuda_h.py:10] start experts_func_mgpu_group_pad
DEBUG 01-14 20:42:50.231352.231352 mlpmodule.py:1460] group tensors cost 0.00935220718383789 s
DEBUG 01-14 20:42:50.231983.231983 cuda_h.py:10] start move_flat_hidden2cpu
DEBUG 01-14 20:42:50.235441.235441 cuda_h.py:19] end experts_func_mgpu_group_pad cost 0.014087438583374023 seconds
DEBUG 01-14 20:42:50.238063.238063 cuda_h.py:10] start gpu_group_list
DEBUG 01-14 20:42:50.239758.239758 cuda_h.py:19] end gpu_group_list cost 0.0008337497711181641 seconds
DEBUG 01-14 20:42:50.239225.239225 cuda_h.py:19] end move_flat_hidden2cpu cost 0.00733184814453125 seconds
DEBUG 01-14 20:42:50.239143.239143 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-14 20:42:50.239454.239454 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 3.528594970703125e-05 seconds
DEBUG 01-14 20:42:50.239265.239265 cuda_h.py:10] start wait_experts
INFO 01-14 20:42:50.240295.240295 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, bbfc11a3-25f7-4299-bd65-ef2cff026d32
DEBUG 01-14 20:42:50.241149.241149 mlpmodule.py:1533] pad cost 0.002125978469848633 s
DEBUG 01-14 20:42:50.241372.241372 mlpmodule.py:1539] create cpu tensor cost 4.6253204345703125e-05 s
DEBUG 01-14 20:42:50.243717.243717 mlpmodule.py:1544] move to cpu cost 0.002132415771484375 s
DEBUG 01-14 20:42:50.253053.253053 mlpmodule.py:1558] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-14 20:42:50.253052.253052 mlpmodule.py:1559] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-14 20:42:50.253559.253559 mlpmodule.py:1564] group_w3 first element: 0.08447265625
WARNING 01-14 20:42:50.253722.253722 mlpmodule.py:1574] start einsum2
DEBUG 01-14 20:42:50.271878.271878 mlpmodule.py:1584] group einsum cost 0.0272824764251709 s
DEBUG 01-14 20:42:50.272520.272520 mlpmodule.py:1593] cpy2cputensor cost 0.000759124755859375 s
DEBUG 01-14 20:42:50.272058.272058 cuda_h.py:10] start move_outputs
INFO 01-14 20:42:50.273043.273043 client.py:127] Model loaded
DEBUG 01-14 20:42:50.273719.273719 cuda_h.py:19] end wait_experts cost 0.03340888023376465 seconds
DEBUG 01-14 20:42:50.273727.273727 cuda_h.py:10] start gpu_experts
DEBUG 01-14 20:42:50.273642.273642 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-14 20:42:50.274997.274997 cuda_h.py:19] end move_outputs cost 0.0020906925201416016 seconds
DEBUG 01-14 20:42:50.278149.278149 cuda_h.py:19] end wait_cetm_experts cost 0.0046117305755615234 seconds
DEBUG 01-14 20:42:50.278782.278782 cuda_h.py:10] start gpu_group_einsum_mp_multi_list
DEBUG 01-14 20:42:50.278306.278306 cuda_h.py:10] start gpu_group_tensor
DEBUG 01-14 20:42:50.278488.278488 cuda_h.py:19] end gpu_group_tensor cost 0.0002429485321044922 seconds
DEBUG 01-14 20:42:50.278373.278373 cuda_h.py:10] start gpu_group_einsum
DEBUG 01-14 20:42:50.279085.279085 cuda_h.py:19] end gpu_group_einsum cost 0.0006430149078369141 seconds
DEBUG 01-14 20:42:50.279858.279858 cuda_h.py:10] start gpu_final_hidden_states_scatter
DEBUG 01-14 20:42:50.279807.279807 cuda_h.py:10] start all_expert_outputs_slices
DEBUG 01-14 20:42:50.280073.280073 cuda_h.py:19] end all_expert_outputs_slices cost 0.0003578662872314453 seconds
DEBUG 01-14 20:42:50.280829.280829 cuda_h.py:10] start concat_expert_out
DEBUG 01-14 20:42:50.280349.280349 cuda_h.py:19] end concat_expert_out cost 6.222724914550781e-05 seconds
DEBUG 01-14 20:42:50.280782.280782 cuda_h.py:10] start index_scatter
DEBUG 01-14 20:42:50.280284.280284 cuda_h.py:19] end index_scatter cost 7.510185241699219e-05 seconds
DEBUG 01-14 20:42:50.280623.280623 cuda_h.py:19] end gpu_final_hidden_states_scatter cost 0.0008280277252197266 seconds
DEBUG 01-14 20:42:50.280791.280791 cuda_h.py:19] end gpu_experts cost 0.007042407989501953 seconds
DEBUG 01-14 20:42:50.280070.280070 cuda_h.py:10] start all_expert_weight_slices
DEBUG 01-14 20:42:50.281574.281574 cuda_h.py:19] end all_expert_weight_slices cost 0.0009717941284179688 seconds
DEBUG 01-14 20:42:50.281966.281966 cuda_h.py:10] start cpuoutputsdeal
DEBUG 01-14 20:42:50.282902.282902 cuda_h.py:10] start index_scatter
DEBUG 01-14 20:42:50.282799.282799 cuda_h.py:19] end index_scatter cost 4.887580871582031e-05 seconds
DEBUG 01-14 20:42:50.282423.282423 cuda_h.py:19] end cpuoutputsdeal cost 0.0005526542663574219 seconds
DEBUG 01-14 20:42:50.282286.282286 cuda_h.py:19] end layer_moe_generate_mp_l_24 cost 0.06868815422058105 seconds
DEBUG 01-14 20:42:50.282420.282420 cuda_h.py:19] end prefill_layer cost 0.07667875289916992 seconds
DEBUG 01-14 20:42:50.282753.282753 lmp.py:1551] -------------------------------- end prefill layer 23 --------------------------------
DEBUG 01-14 20:42:50.282886.282886 cuda_h.py:10] start prefill_layer
DEBUG 01-14 20:42:50.282258.282258 lmp.py:1494] -------------------------------- start prefill layer 24 --------------------------------
DEBUG 01-14 20:42:50.282723.282723 cuda_h.py:10] start start_load_qkvogn_s_weight_l_25
DEBUG 01-14 20:42:50.282048.282048 cuda_h.py:10] start start_load_qkvogn_s_weight_l_25
DEBUG 01-14 20:42:50.282852.282852 cuda_h.py:19] end start_load_qkvogn_s_weight_l_25 cost 3.7670135498046875e-05 seconds
DEBUG 01-14 20:42:50.283370.283370 cuda_h.py:10] start sllm_worker_task
DEBUG 01-14 20:42:50.283551.283551 cuda_h.py:19] end start_load_qkvogn_s_weight_l_25 cost 0.00016617774963378906 seconds
DEBUG 01-14 20:42:50.283011.283011 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-14 20:42:50.283940.283940 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-14 20:42:50.283811.283811 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-14 20:42:50.285476.285476 cuda_h.py:19] end allocate_cuda_memory cost 0.0017552375793457031 seconds
DEBUG 01-14 20:42:50.285584.285584 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-14 20:42:50.285877.285877 sllm_store_c.py:27] get device uuid map
DEBUG 01-14 20:42:50.285236.285236 sllm_store_c.py:29] call client load into gpu
DEBUG 01-14 20:42:50.285708.285708 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, c66667fb-317d-4dba-82f1-8aa306ad2d36
DEBUG 01-14 20:42:50.285559.285559 client.py:106] call stub.LoadModelAsync
DEBUG 01-14 20:42:50.285903.285903 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-14 20:42:50.286524.286524 cuda_h.py:10] start self_attn
INFO 01-14 20:42:50.286900.286900 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, c66667fb-317d-4dba-82f1-8aa306ad2d36
DEBUG 01-14 20:42:50.286557.286557 cuda_h.py:19] end load_into_gpu_async cost 0.0011324882507324219 seconds
DEBUG 01-14 20:42:50.286121.286121 cuda_h.py:10] start restore_tensors2
DEBUG 01-14 20:42:50.286763.286763 cuda_h.py:19] end restore_tensors2 cost 7.200241088867188e-05 seconds
DEBUG 01-14 20:42:50.286679.286679 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.003406524658203125 seconds
INFO 01-14 20:42:50.286775.286775 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, c66667fb-317d-4dba-82f1-8aa306ad2d36
DEBUG 01-14 20:42:50.289028.289028 mlpmodule.py:1367]  experts func einsum cost 0.0671384334564209 s
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-14 20:42:50.290410.290410 cuda_h.py:19] end self_attn cost 0.004055976867675781 seconds
DEBUG 01-14 20:42:50.290164.290164 cuda_h.py:19] end iln_self_attn_paln cost 0.0071163177490234375 seconds
DEBUG 01-14 20:42:50.290682.290682 cuda_h.py:10] start layer_moe_generate_mp_l_25
DEBUG 01-14 20:42:50.290968.290968 cuda_h.py:10] start gate
DEBUG 01-14 20:42:50.291885.291885 cuda_h.py:19] end gate cost 0.0006403923034667969 seconds
DEBUG 01-14 20:42:50.291198.291198 cuda_h.py:10] start experts_map_get
DEBUG 01-14 20:42:50.291911.291911 lmp.py:1615] 
DEBUG 01-14 20:42:50.291911.291911 lmp.py:1615] Expert Token Distribution & Device Allocation:
DEBUG 01-14 20:42:50.291382.291382 lmp.py:1616]   Total experts: 64
DEBUG 01-14 20:42:50.291747.291747 lmp.py:1617]   CPU experts: 32 (50%)
DEBUG 01-14 20:42:50.291774.291774 lmp.py:1618]   GPU experts: 32 (50%)
DEBUG 01-14 20:42:50.291940.291940 lmp.py:1619] 
DEBUG 01-14 20:42:50.291940.291940 lmp.py:1619]   Expert ID | Tokens | Device
DEBUG 01-14 20:42:50.291868.291868 lmp.py:1620]   -----------------------------------
DEBUG 01-14 20:42:50.291988.291988 lmp.py:1625]   Expert 36 |     23 | CPU
DEBUG 01-14 20:42:50.291915.291915 lmp.py:1625]   Expert 35 |     39 | CPU
DEBUG 01-14 20:42:50.291366.291366 lmp.py:1625]   Expert 46 |     52 | CPU
DEBUG 01-14 20:42:50.291579.291579 lmp.py:1625]   Expert 25 |     55 | CPU
DEBUG 01-14 20:42:50.291553.291553 lmp.py:1625]   Expert 30 |     56 | CPU
DEBUG 01-14 20:42:50.291242.291242 lmp.py:1625]   Expert 51 |     58 | CPU
DEBUG 01-14 20:42:50.291693.291693 lmp.py:1625]   Expert 43 |     62 | CPU
DEBUG 01-14 20:42:50.291144.291144 lmp.py:1625]   Expert 55 |     62 | CPU
DEBUG 01-14 20:42:50.291118.291118 lmp.py:1625]   Expert 44 |     75 | CPU
DEBUG 01-14 20:42:50.291092.291092 lmp.py:1625]   Expert 47 |     76 | CPU
DEBUG 01-14 20:42:50.291543.291543 lmp.py:1625]   Expert  0 |     79 | CPU
DEBUG 01-14 20:42:50.291755.291755 lmp.py:1625]   Expert  2 |     81 | CPU
DEBUG 01-14 20:42:50.291729.291729 lmp.py:1625]   Expert 16 |     86 | CPU
DEBUG 01-14 20:42:50.291703.291703 lmp.py:1625]   Expert 39 |     86 | CPU
DEBUG 01-14 20:42:50.292677.292677 lmp.py:1625]   Expert 42 |     90 | CPU
DEBUG 01-14 20:42:50.292605.292605 lmp.py:1625]   Expert  4 |    104 | CPU
DEBUG 01-14 20:42:50.292056.292056 lmp.py:1625]   Expert 54 |    118 | CPU
DEBUG 01-14 20:42:50.292030.292030 lmp.py:1625]   Expert 33 |    123 | CPU
DEBUG 01-14 20:42:50.292766.292766 lmp.py:1625]   Expert 61 |    125 | CPU
DEBUG 01-14 20:42:50.292978.292978 lmp.py:1625]   Expert 48 |    127 | CPU
DEBUG 01-14 20:42:50.292952.292952 lmp.py:1625]   Expert 24 |    132 | CPU
DEBUG 01-14 20:42:50.292688.292688 lmp.py:1625]   Expert  6 |    139 | CPU
DEBUG 01-14 20:42:50.292662.292662 lmp.py:1625]   Expert 15 |    139 | CPU
DEBUG 01-14 20:42:50.292397.292397 lmp.py:1625]   Expert 29 |    139 | CPU
DEBUG 01-14 20:42:50.292610.292610 lmp.py:1625]   Expert 56 |    144 | CPU
DEBUG 01-14 20:42:50.292346.292346 lmp.py:1625]   Expert  9 |    150 | CPU
DEBUG 01-14 20:42:50.292373.292373 lmp.py:1625]   Expert  7 |    151 | CPU
DEBUG 01-14 20:42:50.292539.292539 lmp.py:1625]   Expert 38 |    152 | CPU
DEBUG 01-14 20:42:50.292705.292705 lmp.py:1625]   Expert 62 |    153 | CPU
DEBUG 01-14 20:42:50.292110.292110 lmp.py:1625]   Expert 59 |    154 | CPU
DEBUG 01-14 20:42:50.292276.292276 lmp.py:1625]   Expert 19 |    155 | CPU
DEBUG 01-14 20:42:50.292203.292203 lmp.py:1625]   Expert 20 |    160 | CPU
DEBUG 01-14 20:42:50.292608.292608 lmp.py:1625]   Expert 13 |    165 | GPU
DEBUG 01-14 20:42:50.292820.292820 lmp.py:1625]   Expert 34 |    175 | GPU
DEBUG 01-14 20:42:50.292556.292556 lmp.py:1625]   Expert 45 |    175 | GPU
DEBUG 01-14 20:42:50.292530.292530 lmp.py:1625]   Expert 18 |    186 | GPU
DEBUG 01-14 20:42:50.292027.292027 lmp.py:1625]   Expert  8 |    187 | GPU
DEBUG 01-14 20:42:50.292015.292015 lmp.py:1625]   Expert 50 |    188 | GPU
DEBUG 01-14 20:42:50.292850.292850 lmp.py:1625]   Expert 23 |    192 | GPU
DEBUG 01-14 20:42:50.292016.292016 lmp.py:1625]   Expert 57 |    193 | GPU
DEBUG 01-14 20:42:50.292136.292136 lmp.py:1625]   Expert 60 |    201 | GPU
DEBUG 01-14 20:42:50.292064.292064 lmp.py:1625]   Expert 31 |    202 | GPU
DEBUG 01-14 20:42:50.292991.292991 lmp.py:1625]   Expert 22 |    211 | GPU
DEBUG 01-14 20:42:50.292681.292681 lmp.py:1625]   Expert 10 |    213 | GPU
DEBUG 01-14 20:42:50.292370.292370 lmp.py:1625]   Expert 17 |    230 | GPU
DEBUG 01-14 20:42:50.292582.292582 lmp.py:1625]   Expert 37 |    230 | GPU
DEBUG 01-14 20:42:50.292510.292510 lmp.py:1625]   Expert  5 |    233 | GPU
DEBUG 01-14 20:42:50.292199.292199 lmp.py:1625]   Expert 11 |    240 | GPU
DEBUG 01-14 20:42:50.292180.292180 lmp.py:1625]   Expert 52 |    245 | GPU
DEBUG 01-14 20:42:50.292631.292631 lmp.py:1625]   Expert 53 |    257 | GPU
DEBUG 01-14 20:42:50.292367.292367 lmp.py:1625]   Expert  1 |    268 | GPU
DEBUG 01-14 20:42:50.292102.292102 lmp.py:1625]   Expert 49 |    270 | GPU
DEBUG 01-14 20:42:50.292600.292600 lmp.py:1625]   Expert 14 |    279 | GPU
DEBUG 01-14 20:42:50.292335.292335 lmp.py:1625]   Expert 26 |    280 | GPU
DEBUG 01-14 20:42:50.292071.292071 lmp.py:1625]   Expert 58 |    280 | GPU
DEBUG 01-14 20:42:50.292568.292568 lmp.py:1625]   Expert 41 |    284 | GPU
DEBUG 01-14 20:42:50.292542.292542 lmp.py:1625]   Expert 40 |    295 | GPU
DEBUG 01-14 20:42:50.292616.292616 lmp.py:1625]   Expert 28 |    306 | GPU
DEBUG 01-14 20:42:50.292828.292828 lmp.py:1625]   Expert 32 |    318 | GPU
DEBUG 01-14 20:42:50.292087.292087 lmp.py:1625]   Expert 12 |    322 | GPU
DEBUG 01-14 20:42:50.292823.292823 lmp.py:1625]   Expert 21 |    345 | GPU
DEBUG 01-14 20:42:50.292320.292320 lmp.py:1625]   Expert 63 |    353 | GPU
DEBUG 01-14 20:42:50.292817.292817 lmp.py:1625]   Expert 27 |    599 | GPU
DEBUG 01-14 20:42:50.292791.292791 lmp.py:1625]   Expert  3 |   1021 | GPU
DEBUG 01-14 20:42:50.292719.292719 lmp.py:1626] 
DEBUG 01-14 20:42:50.292719.292719 lmp.py:1626]   CPU total tokens: 3345 (27.2%)
DEBUG 01-14 20:42:50.292885.292885 lmp.py:1627]   GPU total tokens: 8943 (72.8%)
DEBUG 01-14 20:42:50.292104.292104 cuda_h.py:19] end experts_map_get cost 0.0015163421630859375 seconds
DEBUG 01-14 20:42:50.292523.292523 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-14 20:42:50.293228.293228 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-14 20:42:50.293524.293524 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-14 20:42:50.293567.293567 cuda_h.py:19] end allocate_cuda_memory cost 0.00027871131896972656 seconds
DEBUG 01-14 20:42:50.293722.293722 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-14 20:42:50.293286.293286 sllm_store_c.py:27] get device uuid map
DEBUG 01-14 20:42:50.293619.293619 sllm_store_c.py:29] call client load into gpu
DEBUG 01-14 20:42:50.293268.293268 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, d4d36679-d24a-4eeb-a399-ca77fd2bda08
DEBUG 01-14 20:42:50.293686.293686 client.py:106] call stub.LoadModelAsync
INFO 01-14 20:42:50.294370.294370 client.py:127] Model loaded
DEBUG 01-14 20:42:50.294637.294637 cuda_h.py:10] start restore2model
DEBUG 01-14 20:42:50.294887.294887 cuda_h.py:19] end restore2model cost 0.00032782554626464844 seconds
DEBUG 01-14 20:42:50.294465.294465 cuda_h.py:19] end sllm_worker_task cost 0.011373043060302734 seconds
INFO 01-14 20:42:50.295355.295355 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, d4d36679-d24a-4eeb-a399-ca77fd2bda08
DEBUG 01-14 20:42:50.295022.295022 cuda_h.py:19] end load_into_gpu_async cost 0.0021746158599853516 seconds
DEBUG 01-14 20:42:50.295601.295601 cuda_h.py:10] start restore_tensors2
DEBUG 01-14 20:42:50.296673.296673 cuda_h.py:19] end restore_tensors2 cost 0.0005166530609130859 seconds
DEBUG 01-14 20:42:50.296490.296490 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.00347137451171875 seconds
DEBUG 01-14 20:42:50.296406.296406 cuda_h.py:10] start restore2model
DEBUG 01-14 20:42:50.299041.299041 cuda_h.py:19] end restore2model cost 0.002547740936279297 seconds
DEBUG 01-14 20:42:50.299739.299739 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.006204128265380859 seconds
DEBUG 01-14 20:42:50.299057.299057 cuda_h.py:10] start gpu_sexperts
DEBUG 01-14 20:42:50.299412.299412 cuda_h.py:19] end gpu_sexperts cost 0.00026535987854003906 seconds
DEBUG 01-14 20:42:50.299665.299665 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-14 20:42:50.299752.299752 lmp.py:1683] 
DEBUG 01-14 20:42:50.299752.299752 lmp.py:1683]   Computing 32 experts on CPU...
DEBUG 01-14 20:42:50.299304.299304 cuda_h.py:19] end cpu_experts_submit cost 5.745887756347656e-05 seconds
DEBUG 01-14 20:42:50.299338.299338 cuda_h.py:10] start experts_func_mgpu_group_pad
DEBUG 01-14 20:42:50.308564.308564 mlpmodule.py:1460] group tensors cost 0.008497953414916992 s
DEBUG 01-14 20:42:50.309225.309225 cuda_h.py:10] start move_flat_hidden2cpu
DEBUG 01-14 20:42:50.314350.314350 cuda_h.py:19] end experts_func_mgpu_group_pad cost 0.01454615592956543 seconds
DEBUG 01-14 20:42:50.315781.315781 cuda_h.py:19] end move_flat_hidden2cpu cost 0.006462574005126953 seconds
DEBUG 01-14 20:42:50.317534.317534 cuda_h.py:10] start gpu_group_list
DEBUG 01-14 20:42:50.318257.318257 cuda_h.py:19] end gpu_group_list cost 0.0006937980651855469 seconds
DEBUG 01-14 20:42:50.318783.318783 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-14 20:42:50.318907.318907 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.9087066650390625e-05 seconds
DEBUG 01-14 20:42:50.318982.318982 cuda_h.py:10] start wait_experts
INFO 01-14 20:42:50.318526.318526 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, d4d36679-d24a-4eeb-a399-ca77fd2bda08
DEBUG 01-14 20:42:50.319636.319636 mlpmodule.py:1533] pad cost 0.003464221954345703 s
DEBUG 01-14 20:42:50.319144.319144 mlpmodule.py:1539] create cpu tensor cost 3.790855407714844e-05 s
DEBUG 01-14 20:42:50.321665.321665 mlpmodule.py:1544] move to cpu cost 0.00189208984375 s
DEBUG 01-14 20:42:50.330911.330911 mlpmodule.py:1558] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-14 20:42:50.330512.330512 mlpmodule.py:1559] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-14 20:42:50.330873.330873 mlpmodule.py:1564] group_w3 first element: 0.00653076171875
WARNING 01-14 20:42:50.330036.330036 mlpmodule.py:1574] start einsum2
DEBUG 01-14 20:42:50.348647.348647 mlpmodule.py:1584] group einsum cost 0.026871204376220703 s
DEBUG 01-14 20:42:50.349999.349999 mlpmodule.py:1593] cpy2cputensor cost 0.0007541179656982422 s
DEBUG 01-14 20:42:50.349451.349451 cuda_h.py:10] start move_outputs
DEBUG 01-14 20:42:50.351065.351065 cuda_h.py:19] end move_outputs cost 0.0020995140075683594 seconds
INFO 01-14 20:42:50.352131.352131 client.py:127] Model loaded
DEBUG 01-14 20:42:50.352092.352092 cuda_h.py:19] end wait_experts cost 0.03389692306518555 seconds
DEBUG 01-14 20:42:50.352299.352299 cuda_h.py:10] start gpu_experts
DEBUG 01-14 20:42:50.352883.352883 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-14 20:42:50.355337.355337 cuda_h.py:19] end wait_cetm_experts cost 0.0030221939086914062 seconds
DEBUG 01-14 20:42:50.355545.355545 cuda_h.py:10] start gpu_group_einsum_mp_multi_list
DEBUG 01-14 20:42:50.355162.355162 cuda_h.py:10] start gpu_group_tensor
DEBUG 01-14 20:42:50.356536.356536 cuda_h.py:19] end gpu_group_tensor cost 0.00024390220642089844 seconds
DEBUG 01-14 20:42:50.356845.356845 cuda_h.py:10] start gpu_group_einsum
DEBUG 01-14 20:42:50.356630.356630 cuda_h.py:19] end gpu_group_einsum cost 0.0006647109985351562 seconds
DEBUG 01-14 20:42:50.357880.357880 cuda_h.py:10] start gpu_final_hidden_states_scatter
DEBUG 01-14 20:42:50.357307.357307 cuda_h.py:10] start all_expert_outputs_slices
DEBUG 01-14 20:42:50.357141.357141 cuda_h.py:19] end all_expert_outputs_slices cost 0.00035572052001953125 seconds
DEBUG 01-14 20:42:50.357420.357420 cuda_h.py:10] start concat_expert_out
DEBUG 01-14 20:42:50.357788.357788 cuda_h.py:19] end concat_expert_out cost 5.8650970458984375e-05 seconds
DEBUG 01-14 20:42:50.357876.357876 cuda_h.py:10] start index_scatter
DEBUG 01-14 20:42:50.357840.357840 cuda_h.py:19] end index_scatter cost 7.939338684082031e-05 seconds
DEBUG 01-14 20:42:50.357126.357126 cuda_h.py:19] end gpu_final_hidden_states_scatter cost 0.0007622241973876953 seconds
DEBUG 01-14 20:42:50.357857.357857 cuda_h.py:19] end gpu_experts cost 0.005366325378417969 seconds
DEBUG 01-14 20:42:50.357944.357944 cuda_h.py:10] start all_expert_weight_slices
DEBUG 01-14 20:42:50.358541.358541 cuda_h.py:19] end all_expert_weight_slices cost 0.0009694099426269531 seconds
DEBUG 01-14 20:42:50.358602.358602 cuda_h.py:10] start cpuoutputsdeal
DEBUG 01-14 20:42:50.359299.359299 cuda_h.py:10] start index_scatter
DEBUG 01-14 20:42:50.359435.359435 cuda_h.py:19] end index_scatter cost 4.935264587402344e-05 seconds
DEBUG 01-14 20:42:50.359820.359820 cuda_h.py:19] end cpuoutputsdeal cost 0.0005528926849365234 seconds
DEBUG 01-14 20:42:50.359492.359492 cuda_h.py:19] end layer_moe_generate_mp_l_25 cost 0.06903433799743652 seconds
DEBUG 01-14 20:42:50.360194.360194 cuda_h.py:19] end prefill_layer cost 0.07719612121582031 seconds
DEBUG 01-14 20:42:50.360528.360528 lmp.py:1551] -------------------------------- end prefill layer 24 --------------------------------
DEBUG 01-14 20:42:50.360184.360184 cuda_h.py:10] start prefill_layer
DEBUG 01-14 20:42:50.360318.360318 lmp.py:1494] -------------------------------- start prefill layer 25 --------------------------------
DEBUG 01-14 20:42:50.360259.360259 cuda_h.py:10] start start_load_qkvogn_s_weight_l_26
DEBUG 01-14 20:42:50.360392.360392 cuda_h.py:10] start start_load_qkvogn_s_weight_l_26
DEBUG 01-14 20:42:50.360050.360050 cuda_h.py:19] end start_load_qkvogn_s_weight_l_26 cost 3.5762786865234375e-05 seconds
DEBUG 01-14 20:42:50.360237.360237 cuda_h.py:19] end start_load_qkvogn_s_weight_l_26 cost 7.033348083496094e-05 seconds
DEBUG 01-14 20:42:50.360107.360107 cuda_h.py:10] start sllm_worker_task
DEBUG 01-14 20:42:50.360910.360910 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-14 20:42:50.360039.360039 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-14 20:42:50.360110.360110 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-14 20:42:50.363522.363522 cuda_h.py:19] end allocate_cuda_memory cost 0.0025758743286132812 seconds
DEBUG 01-14 20:42:50.363147.363147 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-14 20:42:50.363248.363248 sllm_store_c.py:27] get device uuid map
DEBUG 01-14 20:42:50.363813.363813 sllm_store_c.py:29] call client load into gpu
DEBUG 01-14 20:42:50.363045.363045 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 2ebd1539-cc82-4179-a719-d5365efbda26
DEBUG 01-14 20:42:50.363075.363075 client.py:106] call stub.LoadModelAsync
DEBUG 01-14 20:42:50.363021.363021 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-14 20:42:50.364020.364020 cuda_h.py:10] start self_attn
INFO 01-14 20:42:50.364682.364682 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 2ebd1539-cc82-4179-a719-d5365efbda26
DEBUG 01-14 20:42:50.364962.364962 cuda_h.py:19] end load_into_gpu_async cost 0.0013701915740966797 seconds
DEBUG 01-14 20:42:50.364758.364758 cuda_h.py:10] start restore_tensors2
DEBUG 01-14 20:42:50.364172.364172 cuda_h.py:19] end restore_tensors2 cost 6.914138793945312e-05 seconds
DEBUG 01-14 20:42:50.364259.364259 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.004284381866455078 seconds
INFO 01-14 20:42:50.365367.365367 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 2ebd1539-cc82-4179-a719-d5365efbda26
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
DEBUG 01-14 20:42:50.367718.367718 mlpmodule.py:1367]  experts func einsum cost 0.06709408760070801 s
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-14 20:42:50.368019.368019 cuda_h.py:19] end self_attn cost 0.0038590431213378906 seconds
DEBUG 01-14 20:42:50.368786.368786 cuda_h.py:19] end iln_self_attn_paln cost 0.007791996002197266 seconds
DEBUG 01-14 20:42:50.368728.368728 cuda_h.py:10] start layer_moe_generate_mp_l_26
DEBUG 01-14 20:42:50.368683.368683 cuda_h.py:10] start gate
DEBUG 01-14 20:42:50.369269.369269 cuda_h.py:19] end gate cost 0.0006411075592041016 seconds
DEBUG 01-14 20:42:50.369198.369198 cuda_h.py:10] start experts_map_get
DEBUG 01-14 20:42:50.369764.369764 lmp.py:1615] 
DEBUG 01-14 20:42:50.369764.369764 lmp.py:1615] Expert Token Distribution & Device Allocation:
DEBUG 01-14 20:42:50.369620.369620 lmp.py:1616]   Total experts: 64
DEBUG 01-14 20:42:50.369746.369746 lmp.py:1617]   CPU experts: 32 (50%)
DEBUG 01-14 20:42:50.369727.369727 lmp.py:1618]   GPU experts: 32 (50%)
DEBUG 01-14 20:42:50.369085.369085 lmp.py:1619] 
DEBUG 01-14 20:42:50.369085.369085 lmp.py:1619]   Expert ID | Tokens | Device
DEBUG 01-14 20:42:50.369682.369682 lmp.py:1620]   -----------------------------------
DEBUG 01-14 20:42:50.369994.369994 lmp.py:1625]   Expert 13 |     26 | CPU
DEBUG 01-14 20:42:50.369114.369114 lmp.py:1625]   Expert 33 |     34 | CPU
DEBUG 01-14 20:42:50.369995.369995 lmp.py:1625]   Expert 44 |     38 | CPU
DEBUG 01-14 20:42:50.369638.369638 lmp.py:1625]   Expert  9 |     40 | CPU
DEBUG 01-14 20:42:50.369996.369996 lmp.py:1625]   Expert 16 |     43 | CPU
DEBUG 01-14 20:42:50.369116.369116 lmp.py:1625]   Expert  2 |     49 | CPU
DEBUG 01-14 20:42:50.369998.369998 lmp.py:1625]   Expert 38 |     51 | CPU
DEBUG 01-14 20:42:50.369402.369402 lmp.py:1625]   Expert 22 |     54 | CPU
DEBUG 01-14 20:42:50.369807.369807 lmp.py:1625]   Expert 25 |     60 | CPU
DEBUG 01-14 20:42:50.369211.369211 lmp.py:1625]   Expert 42 |     62 | CPU
DEBUG 01-14 20:42:50.369616.369616 lmp.py:1625]   Expert  5 |     66 | CPU
DEBUG 01-14 20:42:50.369782.369782 lmp.py:1625]   Expert 24 |     66 | CPU
DEBUG 01-14 20:42:50.369425.369425 lmp.py:1625]   Expert 23 |     78 | CPU
DEBUG 01-14 20:42:50.369830.369830 lmp.py:1625]   Expert 10 |     89 | CPU
DEBUG 01-14 20:42:50.369711.369711 lmp.py:1625]   Expert 59 |     99 | CPU
DEBUG 01-14 20:42:50.369354.369354 lmp.py:1625]   Expert 61 |    104 | CPU
DEBUG 01-14 20:42:50.369520.369520 lmp.py:1625]   Expert 46 |    105 | CPU
DEBUG 01-14 20:42:50.369686.369686 lmp.py:1625]   Expert 55 |    110 | CPU
DEBUG 01-14 20:42:50.370614.370614 lmp.py:1625]   Expert 21 |    116 | CPU
DEBUG 01-14 20:42:50.370542.370542 lmp.py:1625]   Expert 45 |    132 | CPU
DEBUG 01-14 20:42:50.370708.370708 lmp.py:1625]   Expert  6 |    133 | CPU
DEBUG 01-14 20:42:50.370874.370874 lmp.py:1625]   Expert  3 |    136 | CPU
DEBUG 01-14 20:42:50.370278.370278 lmp.py:1625]   Expert 31 |    149 | CPU
DEBUG 01-14 20:42:50.370921.370921 lmp.py:1625]   Expert 36 |    151 | CPU
DEBUG 01-14 20:42:50.370088.370088 lmp.py:1625]   Expert 48 |    153 | CPU
DEBUG 01-14 20:42:50.370254.370254 lmp.py:1625]   Expert 43 |    155 | CPU
DEBUG 01-14 20:42:50.370658.370658 lmp.py:1625]   Expert 26 |    156 | CPU
DEBUG 01-14 20:42:50.370348.370348 lmp.py:1625]   Expert 18 |    159 | CPU
DEBUG 01-14 20:42:50.370037.370037 lmp.py:1625]   Expert 51 |    159 | CPU
DEBUG 01-14 20:42:50.370441.370441 lmp.py:1625]   Expert  8 |    160 | CPU
DEBUG 01-14 20:42:50.370369.370369 lmp.py:1625]   Expert 41 |    163 | CPU
DEBUG 01-14 20:42:50.370297.370297 lmp.py:1625]   Expert 28 |    165 | CPU
DEBUG 01-14 20:42:50.370701.370701 lmp.py:1625]   Expert 56 |    170 | GPU
DEBUG 01-14 20:42:50.370106.370106 lmp.py:1625]   Expert 12 |    174 | GPU
DEBUG 01-14 20:42:50.370511.370511 lmp.py:1625]   Expert  0 |    179 | GPU
DEBUG 01-14 20:42:50.370438.370438 lmp.py:1625]   Expert 20 |    179 | GPU
DEBUG 01-14 20:42:50.370366.370366 lmp.py:1625]   Expert  7 |    180 | GPU
DEBUG 01-14 20:42:50.370771.370771 lmp.py:1625]   Expert 27 |    182 | GPU
DEBUG 01-14 20:42:50.370698.370698 lmp.py:1625]   Expert 47 |    198 | GPU
DEBUG 01-14 20:42:50.370341.370341 lmp.py:1625]   Expert  1 |    206 | GPU
DEBUG 01-14 20:42:50.370984.370984 lmp.py:1625]   Expert 34 |    207 | GPU
DEBUG 01-14 20:42:50.370150.370150 lmp.py:1625]   Expert 15 |    220 | GPU
DEBUG 01-14 20:42:50.370078.370078 lmp.py:1625]   Expert 40 |    225 | GPU
DEBUG 01-14 20:42:50.370244.370244 lmp.py:1625]   Expert 11 |    230 | GPU
DEBUG 01-14 20:42:50.370172.370172 lmp.py:1625]   Expert 32 |    230 | GPU
DEBUG 01-14 20:42:50.370100.370100 lmp.py:1625]   Expert 49 |    231 | GPU
DEBUG 01-14 20:42:50.370027.370027 lmp.py:1625]   Expert 50 |    236 | GPU
DEBUG 01-14 20:42:50.370955.370955 lmp.py:1625]   Expert 63 |    248 | GPU
DEBUG 01-14 20:42:50.370883.370883 lmp.py:1625]   Expert 53 |    249 | GPU
DEBUG 01-14 20:42:50.370526.370526 lmp.py:1625]   Expert 30 |    257 | GPU
DEBUG 01-14 20:42:50.370930.370930 lmp.py:1625]   Expert  4 |    264 | GPU
DEBUG 01-14 20:42:50.370620.370620 lmp.py:1625]   Expert 29 |    264 | GPU
DEBUG 01-14 20:42:50.370547.370547 lmp.py:1625]   Expert 35 |    272 | GPU
DEBUG 01-14 20:42:50.370475.370475 lmp.py:1625]   Expert 14 |    274 | GPU
DEBUG 01-14 20:42:50.370164.370164 lmp.py:1625]   Expert 37 |    300 | GPU
DEBUG 01-14 20:42:50.370854.370854 lmp.py:1625]   Expert 17 |    356 | GPU
DEBUG 01-14 20:42:50.370781.370781 lmp.py:1625]   Expert 52 |    361 | GPU
DEBUG 01-14 20:42:50.370947.370947 lmp.py:1625]   Expert 54 |    371 | GPU
DEBUG 01-14 20:42:50.370352.370352 lmp.py:1625]   Expert 39 |    386 | GPU
DEBUG 01-14 20:42:50.370280.370280 lmp.py:1625]   Expert 57 |    405 | GPU
DEBUG 01-14 20:42:50.370969.370969 lmp.py:1625]   Expert 60 |    444 | GPU
DEBUG 01-14 20:42:50.370897.370897 lmp.py:1625]   Expert 62 |    458 | GPU
DEBUG 01-14 20:42:50.370825.370825 lmp.py:1625]   Expert 19 |    503 | GPU
DEBUG 01-14 20:42:50.370275.370275 lmp.py:1625]   Expert 58 |    568 | GPU
DEBUG 01-14 20:42:50.370395.370395 lmp.py:1626] 
DEBUG 01-14 20:42:50.370395.370395 lmp.py:1626]   CPU total tokens: 3261 (26.5%)
DEBUG 01-14 20:42:50.370753.370753 lmp.py:1627]   GPU total tokens: 9027 (73.5%)
DEBUG 01-14 20:42:50.370688.370688 cuda_h.py:19] end experts_map_get cost 0.0015616416931152344 seconds
DEBUG 01-14 20:42:50.370584.370584 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-14 20:42:50.370427.370427 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-14 20:42:50.371200.371200 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-14 20:42:50.371853.371853 cuda_h.py:19] end allocate_cuda_memory cost 0.00027179718017578125 seconds
DEBUG 01-14 20:42:50.371173.371173 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-14 20:42:50.371975.371975 sllm_store_c.py:27] get device uuid map
DEBUG 01-14 20:42:50.371831.371831 sllm_store_c.py:29] call client load into gpu
DEBUG 01-14 20:42:50.371004.371004 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, eaeb80c7-e098-4283-a26c-642855181ae4
DEBUG 01-14 20:42:50.371745.371745 client.py:106] call stub.LoadModelAsync
INFO 01-14 20:42:50.371705.371705 client.py:127] Model loaded
DEBUG 01-14 20:42:50.371349.371349 cuda_h.py:10] start restore2model
DEBUG 01-14 20:42:50.372070.372070 cuda_h.py:19] end restore2model cost 0.0003249645233154297 seconds
DEBUG 01-14 20:42:50.372661.372661 cuda_h.py:19] end sllm_worker_task cost 0.011837244033813477 seconds
INFO 01-14 20:42:50.372774.372774 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, eaeb80c7-e098-4283-a26c-642855181ae4
DEBUG 01-14 20:42:50.372538.372538 cuda_h.py:19] end load_into_gpu_async cost 0.001184701919555664 seconds
DEBUG 01-14 20:42:50.372148.372148 cuda_h.py:10] start restore_tensors2
DEBUG 01-14 20:42:50.373005.373005 cuda_h.py:19] end restore_tensors2 cost 0.0004286766052246094 seconds
DEBUG 01-14 20:42:50.373053.373053 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0022630691528320312 seconds
DEBUG 01-14 20:42:50.373777.373777 cuda_h.py:10] start restore2model
DEBUG 01-14 20:42:50.375997.375997 cuda_h.py:19] end restore2model cost 0.002591371536254883 seconds
DEBUG 01-14 20:42:50.375555.375555 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.0050411224365234375 seconds
DEBUG 01-14 20:42:50.375066.375066 cuda_h.py:10] start gpu_sexperts
DEBUG 01-14 20:42:50.376334.376334 cuda_h.py:19] end gpu_sexperts cost 0.00027060508728027344 seconds
DEBUG 01-14 20:42:50.376111.376111 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-14 20:42:50.376721.376721 lmp.py:1683] 
DEBUG 01-14 20:42:50.376721.376721 lmp.py:1683]   Computing 32 experts on CPU...
DEBUG 01-14 20:42:50.376247.376247 cuda_h.py:19] end cpu_experts_submit cost 7.104873657226562e-05 seconds
DEBUG 01-14 20:42:50.376142.376142 cuda_h.py:10] start experts_func_mgpu_group_pad
DEBUG 01-14 20:42:50.386530.386530 mlpmodule.py:1460] group tensors cost 0.009808540344238281 s
DEBUG 01-14 20:42:50.387299.387299 cuda_h.py:10] start move_flat_hidden2cpu
DEBUG 01-14 20:42:50.393038.393038 cuda_h.py:19] end move_flat_hidden2cpu cost 0.005781412124633789 seconds
DEBUG 01-14 20:42:50.393567.393567 cuda_h.py:19] end experts_func_mgpu_group_pad cost 0.016987085342407227 seconds
DEBUG 01-14 20:42:50.396700.396700 mlpmodule.py:1533] pad cost 0.003658771514892578 s
DEBUG 01-14 20:42:50.397548.397548 mlpmodule.py:1539] create cpu tensor cost 8.249282836914062e-05 s
DEBUG 01-14 20:42:50.397052.397052 cuda_h.py:10] start gpu_group_list
DEBUG 01-14 20:42:50.398919.398919 cuda_h.py:19] end gpu_group_list cost 0.0006392002105712891 seconds
DEBUG 01-14 20:42:50.398165.398165 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-14 20:42:50.398194.398194 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.5510787963867188e-05 seconds
DEBUG 01-14 20:42:50.398255.398255 cuda_h.py:10] start wait_experts
INFO 01-14 20:42:50.398363.398363 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, eaeb80c7-e098-4283-a26c-642855181ae4
DEBUG 01-14 20:42:50.399330.399330 mlpmodule.py:1544] move to cpu cost 0.001961946487426758 s
DEBUG 01-14 20:42:50.409917.409917 mlpmodule.py:1558] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-14 20:42:50.409334.409334 mlpmodule.py:1559] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-14 20:42:50.409655.409655 mlpmodule.py:1564] group_w3 first element: -0.02734375
WARNING 01-14 20:42:50.409852.409852 mlpmodule.py:1574] start einsum2
INFO 01-14 20:42:50.427028.427028 client.py:127] Model loaded
DEBUG 01-14 20:42:50.427466.427466 mlpmodule.py:1584] group einsum cost 0.02846693992614746 s
DEBUG 01-14 20:42:50.427830.427830 cuda_h.py:19] end wait_experts cost 0.029355525970458984 seconds
DEBUG 01-14 20:42:50.428429.428429 cuda_h.py:10] start gpu_experts
DEBUG 01-14 20:42:50.428856.428856 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-14 20:42:50.428456.428456 mlpmodule.py:1593] cpy2cputensor cost 0.0007708072662353516 s
DEBUG 01-14 20:42:50.428167.428167 cuda_h.py:10] start move_outputs
DEBUG 01-14 20:42:50.430159.430159 cuda_h.py:19] end move_outputs cost 0.0019261837005615234 seconds
DEBUG 01-14 20:42:50.434679.434679 cuda_h.py:19] end wait_cetm_experts cost 0.005738973617553711 seconds
DEBUG 01-14 20:42:50.434418.434418 cuda_h.py:10] start gpu_group_einsum_mp_multi_list
DEBUG 01-14 20:42:50.434612.434612 cuda_h.py:10] start gpu_group_tensor
DEBUG 01-14 20:42:50.434084.434084 cuda_h.py:19] end gpu_group_tensor cost 0.0002453327178955078 seconds
DEBUG 01-14 20:42:50.435493.435493 cuda_h.py:10] start gpu_group_einsum
DEBUG 01-14 20:42:50.435162.435162 cuda_h.py:19] end gpu_group_einsum cost 0.000545501708984375 seconds
DEBUG 01-14 20:42:50.435908.435908 cuda_h.py:10] start gpu_final_hidden_states_scatter
DEBUG 01-14 20:42:50.435890.435890 cuda_h.py:10] start all_expert_outputs_slices
DEBUG 01-14 20:42:50.436417.436417 cuda_h.py:19] end all_expert_outputs_slices cost 0.0002868175506591797 seconds
DEBUG 01-14 20:42:50.436981.436981 cuda_h.py:10] start concat_expert_out
DEBUG 01-14 20:42:50.436726.436726 cuda_h.py:19] end concat_expert_out cost 5.650520324707031e-05 seconds
DEBUG 01-14 20:42:50.436536.436536 cuda_h.py:10] start index_scatter
DEBUG 01-14 20:42:50.436925.436925 cuda_h.py:19] end index_scatter cost 0.00011301040649414062 seconds
DEBUG 01-14 20:42:50.436787.436787 cuda_h.py:19] end gpu_final_hidden_states_scatter cost 0.0007121562957763672 seconds
DEBUG 01-14 20:42:50.436717.436717 cuda_h.py:19] end gpu_experts cost 0.00803065299987793 seconds
DEBUG 01-14 20:42:50.436328.436328 cuda_h.py:10] start all_expert_weight_slices
DEBUG 01-14 20:42:50.437301.437301 cuda_h.py:19] end all_expert_weight_slices cost 0.0009679794311523438 seconds
DEBUG 01-14 20:42:50.437647.437647 cuda_h.py:10] start cpuoutputsdeal
DEBUG 01-14 20:42:50.438722.438722 cuda_h.py:10] start index_scatter
DEBUG 01-14 20:42:50.438758.438758 cuda_h.py:19] end index_scatter cost 4.792213439941406e-05 seconds
DEBUG 01-14 20:42:50.438428.438428 cuda_h.py:19] end cpuoutputsdeal cost 0.0005433559417724609 seconds
DEBUG 01-14 20:42:50.438338.438338 cuda_h.py:19] end layer_moe_generate_mp_l_26 cost 0.06979799270629883 seconds
DEBUG 01-14 20:42:50.438617.438617 cuda_h.py:19] end prefill_layer cost 0.0785512924194336 seconds
DEBUG 01-14 20:42:50.438612.438612 lmp.py:1551] -------------------------------- end prefill layer 25 --------------------------------
DEBUG 01-14 20:42:50.438507.438507 cuda_h.py:10] start prefill_layer
DEBUG 01-14 20:42:50.438164.438164 lmp.py:1494] -------------------------------- start prefill layer 26 --------------------------------
DEBUG 01-14 20:42:50.438582.438582 cuda_h.py:10] start start_load_qkvogn_s_weight_l_27
DEBUG 01-14 20:42:50.438908.438908 cuda_h.py:10] start start_load_qkvogn_s_weight_l_27
DEBUG 01-14 20:42:50.438757.438757 cuda_h.py:19] end start_load_qkvogn_s_weight_l_27 cost 3.719329833984375e-05 seconds
DEBUG 01-14 20:42:50.439513.439513 cuda_h.py:19] end start_load_qkvogn_s_weight_l_27 cost 7.033348083496094e-05 seconds
DEBUG 01-14 20:42:50.439640.439640 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-14 20:42:50.439616.439616 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-14 20:42:50.439070.439070 cuda_h.py:10] start sllm_worker_task
DEBUG 01-14 20:42:50.439730.439730 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-14 20:42:50.439096.439096 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-14 20:42:50.441715.441715 cuda_h.py:19] end allocate_cuda_memory cost 0.002029895782470703 seconds
DEBUG 01-14 20:42:50.441877.441877 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-14 20:42:50.441739.441739 sllm_store_c.py:27] get device uuid map
DEBUG 01-14 20:42:50.441781.441781 sllm_store_c.py:29] call client load into gpu
DEBUG 01-14 20:42:50.441252.441252 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 4f38532b-0262-4bca-a80c-1f7c2a25b0be
DEBUG 01-14 20:42:50.441150.441150 client.py:106] call stub.LoadModelAsync
DEBUG 01-14 20:42:50.442716.442716 cuda_h.py:10] start self_attn
INFO 01-14 20:42:50.442219.442219 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 4f38532b-0262-4bca-a80c-1f7c2a25b0be
DEBUG 01-14 20:42:50.442539.442539 cuda_h.py:19] end load_into_gpu_async cost 0.0011508464813232422 seconds
DEBUG 01-14 20:42:50.442818.442818 cuda_h.py:10] start restore_tensors2
DEBUG 01-14 20:42:50.442912.442912 cuda_h.py:19] end restore_tensors2 cost 0.00017547607421875 seconds
DEBUG 01-14 20:42:50.443768.443768 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0036776065826416016 seconds
INFO 01-14 20:42:50.443612.443612 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 4f38532b-0262-4bca-a80c-1f7c2a25b0be
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
DEBUG 01-14 20:42:50.444048.444048 mlpmodule.py:1367]  experts func einsum cost 0.0680091381072998 s
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-14 20:42:50.445689.445689 cuda_h.py:19] end self_attn cost 0.0034389495849609375 seconds
DEBUG 01-14 20:42:50.445283.445283 cuda_h.py:19] end iln_self_attn_paln cost 0.006899595260620117 seconds
DEBUG 01-14 20:42:50.446941.446941 cuda_h.py:10] start layer_moe_generate_mp_l_27
DEBUG 01-14 20:42:50.446180.446180 cuda_h.py:10] start gate
DEBUG 01-14 20:42:50.446176.446176 cuda_h.py:19] end gate cost 0.0006287097930908203 seconds
DEBUG 01-14 20:42:50.446390.446390 cuda_h.py:10] start experts_map_get
DEBUG 01-14 20:42:50.447241.447241 lmp.py:1615] 
DEBUG 01-14 20:42:50.447241.447241 lmp.py:1615] Expert Token Distribution & Device Allocation:
DEBUG 01-14 20:42:50.447951.447951 lmp.py:1616]   Total experts: 64
DEBUG 01-14 20:42:50.447031.447031 lmp.py:1617]   CPU experts: 32 (50%)
DEBUG 01-14 20:42:50.447820.447820 lmp.py:1618]   GPU experts: 32 (50%)
DEBUG 01-14 20:42:50.447224.447224 lmp.py:1619] 
DEBUG 01-14 20:42:50.447224.447224 lmp.py:1619]   Expert ID | Tokens | Device
DEBUG 01-14 20:42:50.447390.447390 lmp.py:1620]   -----------------------------------
DEBUG 01-14 20:42:50.447987.447987 lmp.py:1625]   Expert 20 |     17 | CPU
DEBUG 01-14 20:42:50.447676.447676 lmp.py:1625]   Expert 61 |     23 | CPU
DEBUG 01-14 20:42:50.447366.447366 lmp.py:1625]   Expert 51 |     36 | CPU
DEBUG 01-14 20:42:50.447578.447578 lmp.py:1625]   Expert 62 |     43 | CPU
DEBUG 01-14 20:42:50.447791.447791 lmp.py:1625]   Expert 11 |     45 | CPU
DEBUG 01-14 20:42:50.447003.447003 lmp.py:1625]   Expert  7 |     49 | CPU
DEBUG 01-14 20:42:50.447931.447931 lmp.py:1625]   Expert 30 |     52 | CPU
DEBUG 01-14 20:42:50.447097.447097 lmp.py:1625]   Expert  3 |     59 | CPU
DEBUG 01-14 20:42:50.447786.447786 lmp.py:1625]   Expert 29 |     59 | CPU
DEBUG 01-14 20:42:50.447999.447999 lmp.py:1625]   Expert 17 |     62 | CPU
DEBUG 01-14 20:42:50.447973.447973 lmp.py:1625]   Expert  9 |     63 | CPU
DEBUG 01-14 20:42:50.447424.447424 lmp.py:1625]   Expert  6 |     72 | CPU
DEBUG 01-14 20:42:50.447636.447636 lmp.py:1625]   Expert  8 |     73 | CPU
DEBUG 01-14 20:42:50.447372.447372 lmp.py:1625]   Expert 59 |     77 | CPU
DEBUG 01-14 20:42:50.447584.447584 lmp.py:1625]   Expert 63 |     84 | CPU
DEBUG 01-14 20:42:50.447081.447081 lmp.py:1625]   Expert 48 |     92 | CPU
DEBUG 01-14 20:42:50.447294.447294 lmp.py:1625]   Expert 38 |     94 | CPU
DEBUG 01-14 20:42:50.447745.447745 lmp.py:1625]   Expert 55 |     97 | CPU
DEBUG 01-14 20:42:50.447196.447196 lmp.py:1625]   Expert 49 |    105 | CPU
DEBUG 01-14 20:42:50.447885.447885 lmp.py:1625]   Expert 24 |    113 | CPU
DEBUG 01-14 20:42:50.447097.447097 lmp.py:1625]   Expert 19 |    117 | CPU
DEBUG 01-14 20:42:50.447833.447833 lmp.py:1625]   Expert 50 |    117 | CPU
DEBUG 01-14 20:42:50.447569.447569 lmp.py:1625]   Expert 39 |    118 | CPU
DEBUG 01-14 20:42:50.447066.447066 lmp.py:1625]   Expert 36 |    123 | CPU
DEBUG 01-14 20:42:50.447278.447278 lmp.py:1625]   Expert  4 |    127 | CPU
DEBUG 01-14 20:42:50.447252.447252 lmp.py:1625]   Expert 42 |    127 | CPU
DEBUG 01-14 20:42:50.447988.447988 lmp.py:1625]   Expert 41 |    134 | CPU
DEBUG 01-14 20:42:50.447962.447962 lmp.py:1625]   Expert 34 |    138 | CPU
DEBUG 01-14 20:42:50.447459.447459 lmp.py:1625]   Expert 22 |    140 | CPU
DEBUG 01-14 20:42:50.447195.447195 lmp.py:1625]   Expert 60 |    158 | CPU
DEBUG 01-14 20:42:50.447169.447169 lmp.py:1625]   Expert 15 |    159 | CPU
DEBUG 01-14 20:42:50.447858.447858 lmp.py:1625]   Expert 37 |    159 | CPU
DEBUG 01-14 20:42:50.447548.447548 lmp.py:1625]   Expert 56 |    159 | GPU
DEBUG 01-14 20:42:50.447522.447522 lmp.py:1625]   Expert 21 |    167 | GPU
DEBUG 01-14 20:42:50.447019.447019 lmp.py:1625]   Expert 23 |    169 | GPU
DEBUG 01-14 20:42:50.447993.447993 lmp.py:1625]   Expert 44 |    175 | GPU
DEBUG 01-14 20:42:50.447728.447728 lmp.py:1625]   Expert 16 |    177 | GPU
DEBUG 01-14 20:42:50.447464.447464 lmp.py:1625]   Expert 47 |    182 | GPU
DEBUG 01-14 20:42:50.447200.447200 lmp.py:1625]   Expert 33 |    183 | GPU
DEBUG 01-14 20:42:50.447935.447935 lmp.py:1625]   Expert  1 |    185 | GPU
DEBUG 01-14 20:42:50.447909.447909 lmp.py:1625]   Expert 43 |    187 | GPU
DEBUG 01-14 20:42:50.447645.447645 lmp.py:1625]   Expert 13 |    205 | GPU
DEBUG 01-14 20:42:50.447096.447096 lmp.py:1625]   Expert 53 |    206 | GPU
DEBUG 01-14 20:42:50.447547.447547 lmp.py:1625]   Expert 32 |    227 | GPU
DEBUG 01-14 20:42:50.447759.447759 lmp.py:1625]   Expert 12 |    229 | GPU
DEBUG 01-14 20:42:50.447972.447972 lmp.py:1625]   Expert 28 |    231 | GPU
DEBUG 01-14 20:42:50.447707.447707 lmp.py:1625]   Expert  2 |    245 | GPU
DEBUG 01-14 20:42:50.447681.447681 lmp.py:1625]   Expert 31 |    249 | GPU
DEBUG 01-14 20:42:50.447417.447417 lmp.py:1625]   Expert 25 |    250 | GPU
DEBUG 01-14 20:42:50.448153.448153 lmp.py:1625]   Expert 26 |    254 | GPU
DEBUG 01-14 20:42:50.448365.448365 lmp.py:1625]   Expert  0 |    260 | GPU
DEBUG 01-14 20:42:50.448101.448101 lmp.py:1625]   Expert 18 |    266 | GPU
DEBUG 01-14 20:42:50.448790.448790 lmp.py:1625]   Expert 54 |    273 | GPU
DEBUG 01-14 20:42:50.448241.448241 lmp.py:1625]   Expert 57 |    273 | GPU
DEBUG 01-14 20:42:50.448215.448215 lmp.py:1625]   Expert 10 |    275 | GPU
DEBUG 01-14 20:42:50.448666.448666 lmp.py:1625]   Expert 58 |    282 | GPU
DEBUG 01-14 20:42:50.448640.448640 lmp.py:1625]   Expert 40 |    331 | GPU
DEBUG 01-14 20:42:50.448375.448375 lmp.py:1625]   Expert 45 |    376 | GPU
DEBUG 01-14 20:42:50.448350.448350 lmp.py:1625]   Expert 35 |    445 | GPU
DEBUG 01-14 20:42:50.448324.448324 lmp.py:1625]   Expert  5 |    474 | GPU
DEBUG 01-14 20:42:50.448298.448298 lmp.py:1625]   Expert 46 |    501 | GPU
DEBUG 01-14 20:42:50.448510.448510 lmp.py:1625]   Expert 27 |    510 | GPU
DEBUG 01-14 20:42:50.448438.448438 lmp.py:1625]   Expert 52 |    566 | GPU
DEBUG 01-14 20:42:50.448366.448366 lmp.py:1625]   Expert 14 |    844 | GPU
DEBUG 01-14 20:42:50.448293.448293 lmp.py:1626] 
DEBUG 01-14 20:42:50.448293.448293 lmp.py:1626]   CPU total tokens: 2932 (23.9%)
DEBUG 01-14 20:42:50.448221.448221 lmp.py:1627]   GPU total tokens: 9356 (76.1%)
DEBUG 01-14 20:42:50.448202.448202 cuda_h.py:19] end experts_map_get cost 0.0014841556549072266 seconds
DEBUG 01-14 20:42:50.448191.448191 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-14 20:42:50.448524.448524 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-14 20:42:50.448338.448338 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-14 20:42:50.450634.450634 cuda_h.py:19] end allocate_cuda_memory cost 0.0014793872833251953 seconds
DEBUG 01-14 20:42:50.450557.450557 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-14 20:42:50.450989.450989 sllm_store_c.py:27] get device uuid map
DEBUG 01-14 20:42:50.450705.450705 sllm_store_c.py:29] call client load into gpu
DEBUG 01-14 20:42:50.450309.450309 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, cb25ade3-838e-4a9a-b827-1b5a133f8c71
DEBUG 01-14 20:42:50.450071.450071 client.py:106] call stub.LoadModelAsync
INFO 01-14 20:42:50.450386.450386 client.py:127] Model loaded
DEBUG 01-14 20:42:50.450083.450083 cuda_h.py:10] start restore2model
DEBUG 01-14 20:42:50.451472.451472 cuda_h.py:19] end restore2model cost 0.000324249267578125 seconds
DEBUG 01-14 20:42:50.451573.451573 cuda_h.py:19] end sllm_worker_task cost 0.011939048767089844 seconds
INFO 01-14 20:42:50.451988.451988 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, cb25ade3-838e-4a9a-b827-1b5a133f8c71
DEBUG 01-14 20:42:50.451361.451361 cuda_h.py:19] end load_into_gpu_async cost 0.0012195110321044922 seconds
DEBUG 01-14 20:42:50.451825.451825 cuda_h.py:10] start restore_tensors2
DEBUG 01-14 20:42:50.451351.451351 cuda_h.py:19] end restore_tensors2 cost 0.0004315376281738281 seconds
DEBUG 01-14 20:42:50.452062.452062 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.003566265106201172 seconds
DEBUG 01-14 20:42:50.452877.452877 cuda_h.py:10] start restore2model
DEBUG 01-14 20:42:50.454395.454395 cuda_h.py:19] end restore2model cost 0.0025641918182373047 seconds
DEBUG 01-14 20:42:50.454814.454814 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.006331920623779297 seconds
DEBUG 01-14 20:42:50.454894.454894 cuda_h.py:10] start gpu_sexperts
DEBUG 01-14 20:42:50.455924.455924 cuda_h.py:19] end gpu_sexperts cost 0.0002727508544921875 seconds
DEBUG 01-14 20:42:50.455675.455675 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-14 20:42:50.455331.455331 lmp.py:1683] 
DEBUG 01-14 20:42:50.455331.455331 lmp.py:1683]   Computing 32 experts on CPU...
DEBUG 01-14 20:42:50.455598.455598 cuda_h.py:19] end cpu_experts_submit cost 5.6743621826171875e-05 seconds
DEBUG 01-14 20:42:50.455824.455824 cuda_h.py:10] start experts_func_mgpu_group_pad
DEBUG 01-14 20:42:50.465938.465938 mlpmodule.py:1460] group tensors cost 0.009696245193481445 s
DEBUG 01-14 20:42:50.466697.466697 cuda_h.py:10] start move_flat_hidden2cpu
DEBUG 01-14 20:42:50.468356.468356 cuda_h.py:19] end experts_func_mgpu_group_pad cost 0.01286625862121582 seconds
DEBUG 01-14 20:42:50.469929.469929 cuda_h.py:10] start gpu_group_list
DEBUG 01-14 20:42:50.470825.470825 cuda_h.py:19] end gpu_group_list cost 0.0005335807800292969 seconds
DEBUG 01-14 20:42:50.470674.470674 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-14 20:42:50.470657.470657 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.3603439331054688e-05 seconds
DEBUG 01-14 20:42:50.470903.470903 cuda_h.py:10] start wait_experts
INFO 01-14 20:42:50.470766.470766 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, cb25ade3-838e-4a9a-b827-1b5a133f8c71
DEBUG 01-14 20:42:50.472132.472132 cuda_h.py:19] end move_flat_hidden2cpu cost 0.006220579147338867 seconds
DEBUG 01-14 20:42:50.474516.474516 mlpmodule.py:1533] pad cost 0.0015723705291748047 s
DEBUG 01-14 20:42:50.474142.474142 mlpmodule.py:1539] create cpu tensor cost 3.8623809814453125e-05 s
DEBUG 01-14 20:42:50.476803.476803 mlpmodule.py:1544] move to cpu cost 0.0018873214721679688 s
DEBUG 01-14 20:42:50.485879.485879 mlpmodule.py:1558] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-14 20:42:50.485951.485951 mlpmodule.py:1559] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-14 20:42:50.485642.485642 mlpmodule.py:1564] group_w3 first element: -0.0024261474609375
WARNING 01-14 20:42:50.486634.486634 mlpmodule.py:1574] start einsum2
DEBUG 01-14 20:42:50.503424.503424 mlpmodule.py:1584] group einsum cost 0.026978015899658203 s
DEBUG 01-14 20:42:50.504025.504025 mlpmodule.py:1593] cpy2cputensor cost 0.0007257461547851562 s
DEBUG 01-14 20:42:50.504107.504107 cuda_h.py:10] start move_outputs
DEBUG 01-14 20:42:50.506360.506360 cuda_h.py:19] end move_outputs cost 0.0025713443756103516 seconds
INFO 01-14 20:42:50.508899.508899 client.py:127] Model loaded
DEBUG 01-14 20:42:50.508821.508821 cuda_h.py:19] end wait_experts cost 0.037626028060913086 seconds
DEBUG 01-14 20:42:50.508266.508266 cuda_h.py:10] start gpu_experts
DEBUG 01-14 20:42:50.508327.508327 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-14 20:42:50.511553.511553 cuda_h.py:19] end wait_cetm_experts cost 0.002550840377807617 seconds
DEBUG 01-14 20:42:50.511715.511715 cuda_h.py:10] start gpu_group_einsum_mp_multi_list
DEBUG 01-14 20:42:50.511809.511809 cuda_h.py:10] start gpu_group_tensor
DEBUG 01-14 20:42:50.511811.511811 cuda_h.py:19] end gpu_group_tensor cost 0.0002498626708984375 seconds
DEBUG 01-14 20:42:50.511213.511213 cuda_h.py:10] start gpu_group_einsum
DEBUG 01-14 20:42:50.512734.512734 cuda_h.py:19] end gpu_group_einsum cost 0.000640869140625 seconds
DEBUG 01-14 20:42:50.512176.512176 cuda_h.py:10] start gpu_final_hidden_states_scatter
DEBUG 01-14 20:42:50.512410.512410 cuda_h.py:10] start all_expert_outputs_slices
DEBUG 01-14 20:42:50.513437.513437 cuda_h.py:19] end all_expert_outputs_slices cost 0.00036597251892089844 seconds
DEBUG 01-14 20:42:50.513670.513670 cuda_h.py:10] start concat_expert_out
DEBUG 01-14 20:42:50.513753.513753 cuda_h.py:19] end concat_expert_out cost 5.984306335449219e-05 seconds
DEBUG 01-14 20:42:50.513463.513463 cuda_h.py:10] start index_scatter
DEBUG 01-14 20:42:50.513229.513229 cuda_h.py:19] end index_scatter cost 7.486343383789062e-05 seconds
DEBUG 01-14 20:42:50.513323.513323 cuda_h.py:19] end gpu_final_hidden_states_scatter cost 0.0007607936859130859 seconds
DEBUG 01-14 20:42:50.513491.513491 cuda_h.py:19] end gpu_experts cost 0.004909515380859375 seconds
DEBUG 01-14 20:42:50.513770.513770 cuda_h.py:10] start all_expert_weight_slices
DEBUG 01-14 20:42:50.514744.514744 cuda_h.py:19] end all_expert_weight_slices cost 0.0009679794311523438 seconds
DEBUG 01-14 20:42:50.514852.514852 cuda_h.py:10] start cpuoutputsdeal
DEBUG 01-14 20:42:50.515442.515442 cuda_h.py:10] start index_scatter
DEBUG 01-14 20:42:50.515154.515154 cuda_h.py:19] end index_scatter cost 5.030632019042969e-05 seconds
DEBUG 01-14 20:42:50.515255.515255 cuda_h.py:19] end cpuoutputsdeal cost 0.0005488395690917969 seconds
DEBUG 01-14 20:42:50.515926.515926 cuda_h.py:19] end layer_moe_generate_mp_l_27 cost 0.06916308403015137 seconds
DEBUG 01-14 20:42:50.515920.515920 cuda_h.py:19] end prefill_layer cost 0.0767829418182373 seconds
DEBUG 01-14 20:42:50.515022.515022 lmp.py:1551] -------------------------------- end prefill layer 26 --------------------------------
DEBUG 01-14 20:42:50.515156.515156 cuda_h.py:10] start prefill_layer
DEBUG 01-14 20:42:50.515289.515289 lmp.py:1494] -------------------------------- start prefill layer 27 --------------------------------
DEBUG 01-14 20:42:50.515469.515469 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-14 20:42:50.515915.515915 mlpmodule.py:393] cuda:1 cuda:1
DEBUG 01-14 20:42:50.516105.516105 cuda_h.py:10] start self_attn
DEBUG 01-14 20:42:50.519758.519758 mlpmodule.py:1367]  experts func einsum cost 0.06386804580688477 s
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-14 20:42:50.520843.520843 cuda_h.py:19] end self_attn cost 0.00437474250793457 seconds
DEBUG 01-14 20:42:50.520212.520212 cuda_h.py:19] end iln_self_attn_paln cost 0.005146980285644531 seconds
DEBUG 01-14 20:42:50.521161.521161 cuda_h.py:10] start layer_moe_generate_mp_l_28
DEBUG 01-14 20:42:50.521401.521401 cuda_h.py:10] start gate
DEBUG 01-14 20:42:50.521097.521097 cuda_h.py:19] end gate cost 0.0005843639373779297 seconds
DEBUG 01-14 20:42:50.521026.521026 cuda_h.py:10] start experts_map_get
DEBUG 01-14 20:42:50.522215.522215 lmp.py:1615] 
DEBUG 01-14 20:42:50.522215.522215 lmp.py:1615] Expert Token Distribution & Device Allocation:
DEBUG 01-14 20:42:50.522733.522733 lmp.py:1616]   Total experts: 64
DEBUG 01-14 20:42:50.522859.522859 lmp.py:1617]   CPU experts: 32 (50%)
DEBUG 01-14 20:42:50.522648.522648 lmp.py:1618]   GPU experts: 32 (50%)
DEBUG 01-14 20:42:50.522291.522291 lmp.py:1619] 
DEBUG 01-14 20:42:50.522291.522291 lmp.py:1619]   Expert ID | Tokens | Device
DEBUG 01-14 20:42:50.522219.522219 lmp.py:1620]   -----------------------------------
DEBUG 01-14 20:42:50.522100.522100 lmp.py:1625]   Expert 47 |     63 | CPU
DEBUG 01-14 20:42:50.522028.522028 lmp.py:1625]   Expert 48 |     67 | CPU
DEBUG 01-14 20:42:50.522479.522479 lmp.py:1625]   Expert 18 |     72 | CPU
DEBUG 01-14 20:42:50.522930.522930 lmp.py:1625]   Expert 54 |     82 | CPU
DEBUG 01-14 20:42:50.522142.522142 lmp.py:1625]   Expert 44 |     84 | CPU
DEBUG 01-14 20:42:50.522070.522070 lmp.py:1625]   Expert 45 |     88 | CPU
DEBUG 01-14 20:42:50.522521.522521 lmp.py:1625]   Expert 23 |     92 | CPU
DEBUG 01-14 20:42:50.522972.522972 lmp.py:1625]   Expert 20 |     95 | CPU
DEBUG 01-14 20:42:50.522707.522707 lmp.py:1625]   Expert 11 |     98 | CPU
DEBUG 01-14 20:42:50.522681.522681 lmp.py:1625]   Expert 61 |    103 | CPU
DEBUG 01-14 20:42:50.522417.522417 lmp.py:1625]   Expert  5 |    114 | CPU
DEBUG 01-14 20:42:50.522868.522868 lmp.py:1625]   Expert 24 |    114 | CPU
DEBUG 01-14 20:42:50.522842.522842 lmp.py:1625]   Expert 36 |    117 | CPU
DEBUG 01-14 20:42:50.522578.522578 lmp.py:1625]   Expert 31 |    120 | CPU
DEBUG 01-14 20:42:50.522313.522313 lmp.py:1625]   Expert 10 |    124 | CPU
DEBUG 01-14 20:42:50.522810.522810 lmp.py:1625]   Expert 49 |    127 | CPU
DEBUG 01-14 20:42:50.522784.522784 lmp.py:1625]   Expert 33 |    129 | CPU
DEBUG 01-14 20:42:50.522520.522520 lmp.py:1625]   Expert 17 |    130 | CPU
DEBUG 01-14 20:42:50.522494.522494 lmp.py:1625]   Expert  6 |    132 | CPU
DEBUG 01-14 20:42:50.522945.522945 lmp.py:1625]   Expert 42 |    132 | CPU
DEBUG 01-14 20:42:50.522157.522157 lmp.py:1625]   Expert 43 |    136 | CPU
DEBUG 01-14 20:42:50.522608.522608 lmp.py:1625]   Expert 56 |    137 | CPU
DEBUG 01-14 20:42:50.522344.522344 lmp.py:1625]   Expert 57 |    141 | CPU
DEBUG 01-14 20:42:50.522080.522080 lmp.py:1625]   Expert 12 |    151 | CPU
DEBUG 01-14 20:42:50.522292.522292 lmp.py:1625]   Expert 51 |    156 | CPU
DEBUG 01-14 20:42:50.522505.522505 lmp.py:1625]   Expert  0 |    158 | CPU
DEBUG 01-14 20:42:50.522240.522240 lmp.py:1625]   Expert 38 |    161 | CPU
DEBUG 01-14 20:42:50.522214.522214 lmp.py:1625]   Expert 46 |    161 | CPU
DEBUG 01-14 20:42:50.522950.522950 lmp.py:1625]   Expert 26 |    164 | CPU
DEBUG 01-14 20:42:50.522401.522401 lmp.py:1625]   Expert 59 |    166 | CPU
DEBUG 01-14 20:42:50.522852.522852 lmp.py:1625]   Expert 35 |    168 | CPU
DEBUG 01-14 20:42:50.522779.522779 lmp.py:1625]   Expert 50 |    172 | CPU
DEBUG 01-14 20:42:50.522753.522753 lmp.py:1625]   Expert 13 |    174 | GPU
DEBUG 01-14 20:42:50.522727.522727 lmp.py:1625]   Expert 55 |    175 | GPU
DEBUG 01-14 20:42:50.522463.522463 lmp.py:1625]   Expert 40 |    179 | GPU
DEBUG 01-14 20:42:50.522675.522675 lmp.py:1625]   Expert  7 |    180 | GPU
DEBUG 01-14 20:42:50.522888.522888 lmp.py:1625]   Expert 16 |    182 | GPU
DEBUG 01-14 20:42:50.522100.522100 lmp.py:1625]   Expert 58 |    182 | GPU
DEBUG 01-14 20:42:50.522074.522074 lmp.py:1625]   Expert 30 |    192 | GPU
DEBUG 01-14 20:42:50.522002.522002 lmp.py:1625]   Expert 15 |    200 | GPU
DEBUG 01-14 20:42:50.522930.522930 lmp.py:1625]   Expert  1 |    204 | GPU
DEBUG 01-14 20:42:50.522381.522381 lmp.py:1625]   Expert 14 |    207 | GPU
DEBUG 01-14 20:42:50.522355.522355 lmp.py:1625]   Expert 32 |    210 | GPU
DEBUG 01-14 20:42:50.522567.522567 lmp.py:1625]   Expert  4 |    214 | GPU
DEBUG 01-14 20:42:50.522541.522541 lmp.py:1625]   Expert  3 |    227 | GPU
DEBUG 01-14 20:42:50.522515.522515 lmp.py:1625]   Expert 28 |    231 | GPU
DEBUG 01-14 20:42:50.522728.522728 lmp.py:1625]   Expert 34 |    239 | GPU
DEBUG 01-14 20:42:50.522463.522463 lmp.py:1625]   Expert 25 |    246 | GPU
DEBUG 01-14 20:42:50.522676.522676 lmp.py:1625]   Expert 39 |    246 | GPU
DEBUG 01-14 20:42:50.522080.522080 lmp.py:1625]   Expert 22 |    251 | GPU
DEBUG 01-14 20:42:50.523055.523055 lmp.py:1625]   Expert 52 |    258 | GPU
DEBUG 01-14 20:42:50.523267.523267 lmp.py:1625]   Expert  2 |    262 | GPU
DEBUG 01-14 20:42:50.523479.523479 lmp.py:1625]   Expert 60 |    262 | GPU
DEBUG 01-14 20:42:50.523453.523453 lmp.py:1625]   Expert 41 |    287 | GPU
DEBUG 01-14 20:42:50.523666.523666 lmp.py:1625]   Expert 27 |    290 | GPU
DEBUG 01-14 20:42:50.523640.523640 lmp.py:1625]   Expert 63 |    294 | GPU
DEBUG 01-14 20:42:50.523137.523137 lmp.py:1625]   Expert 21 |    296 | GPU
DEBUG 01-14 20:42:50.523111.523111 lmp.py:1625]   Expert 62 |    298 | GPU
DEBUG 01-14 20:42:50.523085.523085 lmp.py:1625]   Expert 29 |    304 | GPU
DEBUG 01-14 20:42:50.523775.523775 lmp.py:1625]   Expert 37 |    335 | GPU
DEBUG 01-14 20:42:50.523702.523702 lmp.py:1625]   Expert  8 |    338 | GPU
DEBUG 01-14 20:42:50.523915.523915 lmp.py:1625]   Expert 53 |    347 | GPU
DEBUG 01-14 20:42:50.523650.523650 lmp.py:1625]   Expert 19 |    453 | GPU
DEBUG 01-14 20:42:50.523386.523386 lmp.py:1625]   Expert  9 |    571 | GPU
DEBUG 01-14 20:42:50.523314.523314 lmp.py:1626] 
DEBUG 01-14 20:42:50.523314.523314 lmp.py:1626]   CPU total tokens: 3954 (32.2%)
DEBUG 01-14 20:42:50.523003.523003 lmp.py:1627]   GPU total tokens: 8334 (67.8%)
DEBUG 01-14 20:42:50.523984.523984 cuda_h.py:19] end experts_map_get cost 0.0014858245849609375 seconds
DEBUG 01-14 20:42:50.523734.523734 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-14 20:42:50.523769.523769 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-14 20:42:50.523112.523112 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-14 20:42:50.523734.523734 cuda_h.py:19] end allocate_cuda_memory cost 0.00035500526428222656 seconds
DEBUG 01-14 20:42:50.523684.523684 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-14 20:42:50.524678.524678 sllm_store_c.py:27] get device uuid map
DEBUG 01-14 20:42:50.524355.524355 sllm_store_c.py:29] call client load into gpu
DEBUG 01-14 20:42:50.524912.524912 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 20877076-8192-46d6-82ca-f26111c8ac55
DEBUG 01-14 20:42:50.524767.524767 client.py:106] call stub.LoadModelAsync
INFO 01-14 20:42:50.525157.525157 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 20877076-8192-46d6-82ca-f26111c8ac55
DEBUG 01-14 20:42:50.525470.525470 cuda_h.py:19] end load_into_gpu_async cost 0.0014958381652832031 seconds
DEBUG 01-14 20:42:50.525027.525027 cuda_h.py:10] start restore_tensors2
DEBUG 01-14 20:42:50.526228.526228 cuda_h.py:19] end restore_tensors2 cost 0.0004382133483886719 seconds
DEBUG 01-14 20:42:50.526747.526747 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0026636123657226562 seconds
DEBUG 01-14 20:42:50.526324.526324 cuda_h.py:10] start restore2model
DEBUG 01-14 20:42:50.528855.528855 cuda_h.py:19] end restore2model cost 0.0025746822357177734 seconds
DEBUG 01-14 20:42:50.528467.528467 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.005427837371826172 seconds
DEBUG 01-14 20:42:50.528501.528501 cuda_h.py:10] start gpu_sexperts
DEBUG 01-14 20:42:50.529862.529862 cuda_h.py:19] end gpu_sexperts cost 0.0002701282501220703 seconds
DEBUG 01-14 20:42:50.529069.529069 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-14 20:42:50.529156.529156 lmp.py:1683] 
DEBUG 01-14 20:42:50.529156.529156 lmp.py:1683]   Computing 32 experts on CPU...
DEBUG 01-14 20:42:50.529621.529621 cuda_h.py:19] end cpu_experts_submit cost 6.222724914550781e-05 seconds
DEBUG 01-14 20:42:50.529516.529516 cuda_h.py:10] start experts_func_mgpu_group_pad
DEBUG 01-14 20:42:50.534751.534751 mlpmodule.py:1460] group tensors cost 0.005208730697631836 s
DEBUG 01-14 20:42:50.535075.535075 cuda_h.py:10] start move_flat_hidden2cpu
DEBUG 01-14 20:42:50.537755.537755 cuda_h.py:19] end experts_func_mgpu_group_pad cost 0.00865626335144043 seconds
DEBUG 01-14 20:42:50.539783.539783 cuda_h.py:10] start gpu_group_list
DEBUG 01-14 20:42:50.539933.539933 cuda_h.py:19] end gpu_group_list cost 0.00043392181396484375 seconds
DEBUG 01-14 20:42:50.540608.540608 cuda_h.py:10] start wait_experts
INFO 01-14 20:42:50.540537.540537 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 20877076-8192-46d6-82ca-f26111c8ac55
DEBUG 01-14 20:42:50.541398.541398 cuda_h.py:19] end move_flat_hidden2cpu cost 0.006420612335205078 seconds
DEBUG 01-14 20:42:50.543658.543658 mlpmodule.py:1533] pad cost 0.001527547836303711 s
DEBUG 01-14 20:42:50.543470.543470 mlpmodule.py:1539] create cpu tensor cost 3.647804260253906e-05 s
DEBUG 01-14 20:42:50.545235.545235 mlpmodule.py:1544] move to cpu cost 0.0020363330841064453 s
DEBUG 01-14 20:42:50.555129.555129 mlpmodule.py:1558] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-14 20:42:50.555215.555215 mlpmodule.py:1559] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-14 20:42:50.555675.555675 mlpmodule.py:1564] group_w3 first element: -0.006439208984375
WARNING 01-14 20:42:50.555361.555361 mlpmodule.py:1574] start einsum2
DEBUG 01-14 20:42:50.573586.573586 mlpmodule.py:1584] group einsum cost 0.027620792388916016 s
DEBUG 01-14 20:42:50.574758.574758 mlpmodule.py:1593] cpy2cputensor cost 0.0007610321044921875 s
DEBUG 01-14 20:42:50.574587.574587 cuda_h.py:10] start move_outputs
DEBUG 01-14 20:42:50.577414.577414 cuda_h.py:19] end move_outputs cost 0.002893209457397461 seconds
INFO 01-14 20:42:50.582420.582420 client.py:127] Model loaded
DEBUG 01-14 20:42:50.582134.582134 cuda_h.py:19] end wait_experts cost 0.04234790802001953 seconds
DEBUG 01-14 20:42:50.582619.582619 cuda_h.py:10] start gpu_experts
DEBUG 01-14 20:42:50.582773.582773 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-14 20:42:50.582264.582264 cuda_h.py:19] end wait_cetm_experts cost 0.00019073486328125 seconds
DEBUG 01-14 20:42:50.582074.582074 cuda_h.py:10] start gpu_group_einsum_mp_multi_list
DEBUG 01-14 20:42:50.582929.582929 cuda_h.py:10] start gpu_group_tensor
DEBUG 01-14 20:42:50.583018.583018 cuda_h.py:19] end gpu_group_tensor cost 0.000244140625 seconds
DEBUG 01-14 20:42:50.583181.583181 cuda_h.py:10] start gpu_group_einsum
DEBUG 01-14 20:42:50.584205.584205 cuda_h.py:19] end gpu_group_einsum cost 0.0006639957427978516 seconds
DEBUG 01-14 20:42:50.584594.584594 cuda_h.py:10] start gpu_final_hidden_states_scatter
DEBUG 01-14 20:42:50.584782.584782 cuda_h.py:10] start all_expert_outputs_slices
DEBUG 01-14 20:42:50.584618.584618 cuda_h.py:19] end all_expert_outputs_slices cost 0.0003972053527832031 seconds
DEBUG 01-14 20:42:50.584281.584281 cuda_h.py:10] start concat_expert_out
DEBUG 01-14 20:42:50.584709.584709 cuda_h.py:19] end concat_expert_out cost 6.67572021484375e-05 seconds
DEBUG 01-14 20:42:50.584704.584704 cuda_h.py:10] start index_scatter
DEBUG 01-14 20:42:50.585324.585324 cuda_h.py:19] end index_scatter cost 7.224082946777344e-05 seconds
DEBUG 01-14 20:42:50.585656.585656 cuda_h.py:19] end gpu_final_hidden_states_scatter cost 0.0008032321929931641 seconds
DEBUG 01-14 20:42:50.585010.585010 cuda_h.py:19] end gpu_experts cost 0.0025415420532226562 seconds
DEBUG 01-14 20:42:50.585382.585382 cuda_h.py:10] start all_expert_weight_slices
DEBUG 01-14 20:42:50.586064.586064 cuda_h.py:19] end all_expert_weight_slices cost 0.0009624958038330078 seconds
DEBUG 01-14 20:42:50.586171.586171 cuda_h.py:10] start cpuoutputsdeal
DEBUG 01-14 20:42:50.586525.586525 cuda_h.py:10] start index_scatter
DEBUG 01-14 20:42:50.586065.586065 cuda_h.py:19] end index_scatter cost 5.1021575927734375e-05 seconds
DEBUG 01-14 20:42:50.586835.586835 cuda_h.py:19] end cpuoutputsdeal cost 0.0005993843078613281 seconds
DEBUG 01-14 20:42:50.586221.586221 cuda_h.py:19] end layer_moe_generate_mp_l_28 cost 0.06584715843200684 seconds
DEBUG 01-14 20:42:50.587831.587831 cuda_h.py:19] end prefill_layer cost 0.07156825065612793 seconds
DEBUG 01-14 20:42:50.587211.587211 lmp.py:1551] -------------------------------- end prefill layer 27 --------------------------------
DEBUG 01-14 20:42:50.587636.587636 cuda_h.py:19] end prefill cost 2.23612117767334 seconds
DEBUG 01-14 20:42:50.613537.613537 mlpmodule.py:1367]  experts func einsum cost 0.08350539207458496 s
Collecting data...
Generating '/tmp/nsys-report-a1f7.qdstrm'
[1/1] [0%                          ] report1.nsys-rep[1/1] [0%                          ] report1.nsys-rep[1/1] [0%                          ] report1.nsys-rep[1/1] [5%                          ] report1.nsys-rep[1/1] [7%                          ] report1.nsys-rep[1/1] [10%                         ] report1.nsys-rep[1/1] [12%                         ] report1.nsys-rep[1/1] [=15%                        ] report1.nsys-rep[1/1] [=17%                        ] report1.nsys-rep[1/1] [==19%                       ] report1.nsys-rep[1/1] [===22%                      ] report1.nsys-rep[1/1] [====25%                     ] report1.nsys-rep[1/1] [====27%                     ] report1.nsys-rep[1/1] [=====30%                    ] report1.nsys-rep[1/1] [======33%                   ] report1.nsys-rep[1/1] [=======36%                  ] report1.nsys-rep[1/1] [=======39%                  ] report1.nsys-rep[1/1] [========42%                 ] report1.nsys-rep[1/1] [=========45%                ] report1.nsys-rep[1/1] [==========48%               ] report1.nsys-rep[1/1] [===========50%              ] report1.nsys-rep[1/1] [========================100%] report1.nsys-rep[1/1] [========================100%] report1.nsys-rep
Generated:
	/mnt/zhengcf3/lmp/examples/report1.nsys-rep
