here pin
INFO 01-06 17:10:52.588081.588081 pinpool.py:28] Initializing PinnedMemoryPool with 2GB total, allocating in 1024MB chunks...
DEBUG 01-06 17:10:53.452830.452830 pinpool.py:40] Allocated chunk 1: 536870912 elements (1024.0 MB)
DEBUG 01-06 17:10:53.916675.916675 pinpool.py:40] Allocated chunk 2: 536870912 elements (1024.0 MB)
INFO 01-06 17:10:53.917192.917192 pinpool.py:52] Successfully allocated 2 chunks, total 1073741824 elements (2048.0 MB) in 1.329s
DEBUG 01-06 17:10:54.101407.101407 cuda_memory_view.py:384] 
DEBUG 01-06 17:10:54.101407.101407 cuda_memory_view.py:384] restore_tensors_from_shared_memory_names time: 0.01387333869934082
DEBUG 01-06 17:10:56.125976.125976 cuda_h.py:10] start generate_input_ids
generate input ids cost 0.1197652816772461 s
DEBUG 01-06 17:10:56.662230.662230 cuda_h.py:19] end generate_input_ids cost 0.5367918014526367 seconds
DEBUG 01-06 17:10:56.662635.662635 cuda_h.py:10] start init_cache
DEBUG 01-06 17:10:56.662633.662633 cuda_h.py:19] end init_cache cost 0.00010275840759277344 seconds
DEBUG 01-06 17:10:59.117339.117339 cuda_h.py:10] start init_weights
DEBUG 01-06 17:10:59.117871.117871 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 17:10:59.117945.117945 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 17:10:59.118032.118032 cuda_h.py:19] end allocate_cuda_memory cost 0.0005691051483154297 seconds
DEBUG 01-06 17:10:59.118645.118645 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 17:10:59.118958.118958 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 17:10:59.118352.118352 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 17:10:59.118631.118631 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, ad303868-6e27-4a13-a4bb-6d82be9dd99a
DEBUG 01-06 17:10:59.118250.118250 client.py:106] call stub.LoadModelAsync
INFO 01-06 17:10:59.119372.119372 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, ad303868-6e27-4a13-a4bb-6d82be9dd99a
DEBUG 01-06 17:10:59.120960.120960 cuda_h.py:19] end load_into_gpu_async cost 0.0018260478973388672 seconds
DEBUG 01-06 17:10:59.120446.120446 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 17:10:59.120527.120527 cuda_h.py:19] end restore_tensors2 cost 0.0001666545867919922 seconds
DEBUG 01-06 17:10:59.120316.120316 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0029914379119873047 seconds
INFO 01-06 17:10:59.120317.120317 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, ad303868-6e27-4a13-a4bb-6d82be9dd99a
INFO 01-06 17:10:59.200562.200562 client.py:127] Model loaded
DEBUG 01-06 17:10:59.201740.201740 cuda_h.py:10] start load_qkvogns_weight_l_0
DEBUG 01-06 17:10:59.201414.201414 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 17:10:59.201352.201352 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 17:10:59.201480.201480 cuda_h.py:19] end allocate_cuda_memory cost 0.00038361549377441406 seconds
DEBUG 01-06 17:10:59.202751.202751 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 17:10:59.202410.202410 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 17:10:59.202784.202784 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 17:10:59.202217.202217 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 938b7a95-5961-4678-aad2-c0038a5bd21f
DEBUG 01-06 17:10:59.202084.202084 client.py:106] call stub.LoadModelAsync
INFO 01-06 17:10:59.203545.203545 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 938b7a95-5961-4678-aad2-c0038a5bd21f
DEBUG 01-06 17:10:59.204669.204669 cuda_h.py:19] end load_into_gpu_async cost 0.002014636993408203 seconds
DEBUG 01-06 17:10:59.204600.204600 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 17:10:59.204177.204177 cuda_h.py:19] end restore_tensors2 cost 0.00016546249389648438 seconds
DEBUG 01-06 17:10:59.204128.204128 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0032477378845214844 seconds
INFO 01-06 17:10:59.204422.204422 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 938b7a95-5961-4678-aad2-c0038a5bd21f
INFO 01-06 17:10:59.221226.221226 client.py:127] Model loaded
DEBUG 01-06 17:10:59.222303.222303 cuda_h.py:19] end load_qkvogns_weight_l_0 cost 0.021044254302978516 seconds
DEBUG 01-06 17:10:59.222817.222817 cuda_h.py:19] end init_weights cost 0.10502290725708008 seconds
DEBUG 01-06 17:10:59.222403.222403 cuda_h.py:10] start copy_emodel
DEBUG 01-06 17:11:00.137067.137067 cuda_h.py:19] end copy_emodel cost 0.9150922298431396 seconds
DEBUG 01-06 17:11:00.138708.138708 cuda_h.py:10] start init_hmv
DEBUG 01-06 17:11:00.281419.281419 mlpmodule.py:207] restore_hm_state_dict2model loaded 5265 expert tensors (including shared_experts) for Deepseek model
DEBUG 01-06 17:11:00.282306.282306 cuda_h.py:19] end init_hmv cost 0.1436150074005127 seconds
DEBUG 01-06 17:11:00.282115.282115 cuda_h.py:10] start init_inputs_tokens
DEBUG 01-06 17:11:00.360685.360685 cuda_h.py:19] end init_inputs_tokens cost 0.07825922966003418 seconds
DEBUG 01-06 17:11:00.360034.360034 cuda_h.py:10] start multi_layer
DEBUG 01-06 17:11:00.360129.360129 lmp.py:176] -------------------------------- start layer 0 --------------------------------
DEBUG 01-06 17:11:00.360308.360308 cuda_h.py:10] start start_load_qkvogn_s_weight_l_1
DEBUG 01-06 17:11:00.360349.360349 cuda_h.py:10] start start_load_qkvogn_s_weight_l_1
DEBUG 01-06 17:11:00.360537.360537 cuda_h.py:19] end start_load_qkvogn_s_weight_l_1 cost 4.00543212890625e-05 seconds
DEBUG 01-06 17:11:00.360909.360909 cuda_h.py:19] end start_load_qkvogn_s_weight_l_1 cost 7.224082946777344e-05 seconds
DEBUG 01-06 17:11:00.360936.360936 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-06 17:11:00.360713.360713 mlpmodule.py:367] cuda:1 cuda:1
DEBUG 01-06 17:11:00.361750.361750 cuda_h.py:10] start sllm_worker_task
DEBUG 01-06 17:11:00.361549.361549 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 17:11:00.361572.361572 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 17:11:00.361663.361663 cuda_h.py:19] end allocate_cuda_memory cost 0.0002880096435546875 seconds
DEBUG 01-06 17:11:00.361660.361660 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 17:11:00.361542.361542 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 17:11:00.361207.361207 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 17:11:00.361268.361268 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 1d06973d-0d9f-4c97-b66f-041ccb7bdb3f
DEBUG 01-06 17:11:00.361299.361299 client.py:106] call stub.LoadModelAsync
INFO 01-06 17:11:00.363933.363933 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 1d06973d-0d9f-4c97-b66f-041ccb7bdb3f
DEBUG 01-06 17:11:00.363379.363379 cuda_h.py:19] end load_into_gpu_async cost 0.002054929733276367 seconds
DEBUG 01-06 17:11:00.363579.363579 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 17:11:00.364797.364797 cuda_h.py:19] end restore_tensors2 cost 0.00011205673217773438 seconds
DEBUG 01-06 17:11:00.364010.364010 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0028464794158935547 seconds
INFO 01-06 17:11:00.364701.364701 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 1d06973d-0d9f-4c97-b66f-041ccb7bdb3f
INFO 01-06 17:11:00.371578.371578 client.py:127] Model loaded
DEBUG 01-06 17:11:00.372704.372704 cuda_h.py:19] end sllm_worker_task cost 0.011736631393432617 seconds
DEBUG 01-06 17:11:00.452816.452816 cuda_h.py:10] start self_attn
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-06 17:11:00.707463.707463 cuda_h.py:19] end self_attn cost 0.25473809242248535 seconds
DEBUG 01-06 17:11:00.707896.707896 cuda_h.py:19] end iln_self_attn_paln cost 0.3466670513153076 seconds
DEBUG 01-06 17:11:00.707428.707428 cuda_h.py:10] start dense_mlp
DEBUG 01-06 17:11:00.714180.714180 cuda_h.py:19] end dense_mlp cost 0.006798267364501953 seconds
DEBUG 01-06 17:11:00.714700.714700 lmp.py:220] -------------------------------- end layer 0 --------------------------------
DEBUG 01-06 17:11:00.714225.714225 lmp.py:176] -------------------------------- start layer 1 --------------------------------
DEBUG 01-06 17:11:00.714206.714206 cuda_h.py:10] start start_load_qkvogn_s_weight_l_2
DEBUG 01-06 17:11:00.714723.714723 cuda_h.py:10] start start_load_qkvogn_s_weight_l_2
DEBUG 01-06 17:11:00.714944.714944 cuda_h.py:19] end start_load_qkvogn_s_weight_l_2 cost 2.9087066650390625e-05 seconds
DEBUG 01-06 17:11:00.714859.714859 cuda_h.py:19] end start_load_qkvogn_s_weight_l_2 cost 7.82012939453125e-05 seconds
DEBUG 01-06 17:11:00.714171.714171 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-06 17:11:00.714101.714101 cuda_h.py:10] start sllm_worker_task
DEBUG 01-06 17:11:00.715552.715552 mlpmodule.py:367] cuda:1 cuda:1
DEBUG 01-06 17:11:00.715508.715508 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 17:11:00.715059.715059 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 17:11:00.715245.715245 cuda_h.py:19] end allocate_cuda_memory cost 0.0002982616424560547 seconds
DEBUG 01-06 17:11:00.715509.715509 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 17:11:00.716519.716519 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 17:11:00.716318.716318 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 17:11:00.716825.716825 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, c3d75aa9-ba72-43dc-907d-ae71c1c11e5d
DEBUG 01-06 17:11:00.716991.716991 client.py:106] call stub.LoadModelAsync
DEBUG 01-06 17:11:00.716087.716087 cuda_h.py:10] start self_attn
INFO 01-06 17:11:00.718166.718166 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, c3d75aa9-ba72-43dc-907d-ae71c1c11e5d
DEBUG 01-06 17:11:00.718569.718569 cuda_h.py:19] end load_into_gpu_async cost 0.0026662349700927734 seconds
DEBUG 01-06 17:11:00.718096.718096 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 17:11:00.719953.719953 cuda_h.py:19] end restore_tensors2 cost 0.00014519691467285156 seconds
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
DEBUG 01-06 17:11:00.719734.719734 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.003981590270996094 seconds
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
INFO 01-06 17:11:00.719310.719310 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, c3d75aa9-ba72-43dc-907d-ae71c1c11e5d
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-06 17:11:00.720860.720860 cuda_h.py:19] end self_attn cost 0.003446817398071289 seconds
DEBUG 01-06 17:11:00.720354.720354 cuda_h.py:19] end iln_self_attn_paln cost 0.0058290958404541016 seconds
DEBUG 01-06 17:11:00.720986.720986 cuda_h.py:10] start layer_moe_generate_1
DEBUG 01-06 17:11:00.720047.720047 cuda_h.py:10] start gate
INFO 01-06 17:11:00.726715.726715 client.py:127] Model loaded
DEBUG 01-06 17:11:00.727015.727015 cuda_h.py:19] end sllm_worker_task cost 0.012775421142578125 seconds
DEBUG 01-06 17:11:00.819506.819506 cuda_h.py:19] end gate cost 0.0986778736114502 seconds
DEBUG 01-06 17:11:00.819960.819960 cuda_h.py:10] start experts_map_get
DEBUG 01-06 17:11:00.819846.819846 lmp.py:403] 
DEBUG 01-06 17:11:00.819846.819846 lmp.py:403] Expert Token Distribution & Device Allocation:
DEBUG 01-06 17:11:00.820993.820993 lmp.py:404]   Total experts: 64
DEBUG 01-06 17:11:00.820311.820311 lmp.py:405]   CPU experts: 32 (50%)
DEBUG 01-06 17:11:00.820100.820100 lmp.py:406]   GPU experts: 32 (50%)
DEBUG 01-06 17:11:00.820981.820981 lmp.py:407] 
DEBUG 01-06 17:11:00.820981.820981 lmp.py:407]   Expert ID | Tokens | Device
DEBUG 01-06 17:11:00.820624.820624 lmp.py:408]   -----------------------------------
DEBUG 01-06 17:11:00.820394.820394 lmp.py:414]   Expert 25 |     64 | CPU
DEBUG 01-06 17:11:00.820752.820752 lmp.py:414]   Expert 54 |     67 | CPU
DEBUG 01-06 17:11:00.820157.820157 lmp.py:414]   Expert  3 |     68 | CPU
DEBUG 01-06 17:11:00.820561.820561 lmp.py:414]   Expert 31 |     72 | CPU
DEBUG 01-06 17:11:00.820728.820728 lmp.py:414]   Expert 55 |     72 | CPU
DEBUG 01-06 17:11:00.820132.820132 lmp.py:414]   Expert 62 |     87 | CPU
DEBUG 01-06 17:11:00.820060.820060 lmp.py:414]   Expert 18 |     88 | CPU
DEBUG 01-06 17:11:00.820226.820226 lmp.py:414]   Expert 52 |     98 | CPU
DEBUG 01-06 17:11:00.820915.820915 lmp.py:414]   Expert 22 |    100 | CPU
DEBUG 01-06 17:11:00.820081.820081 lmp.py:414]   Expert 47 |    104 | CPU
DEBUG 01-06 17:11:00.820248.820248 lmp.py:414]   Expert  0 |    113 | CPU
DEBUG 01-06 17:11:00.820175.820175 lmp.py:414]   Expert 37 |    117 | CPU
DEBUG 01-06 17:11:00.820103.820103 lmp.py:414]   Expert 27 |    121 | CPU
DEBUG 01-06 17:11:00.820031.820031 lmp.py:414]   Expert 32 |    123 | CPU
DEBUG 01-06 17:11:00.820958.820958 lmp.py:414]   Expert 41 |    130 | CPU
DEBUG 01-06 17:11:00.820562.820562 lmp.py:414]   Expert 44 |    131 | CPU
DEBUG 01-06 17:11:00.820728.820728 lmp.py:414]   Expert 28 |    136 | CPU
DEBUG 01-06 17:11:00.820417.820417 lmp.py:414]   Expert 13 |    138 | CPU
DEBUG 01-06 17:11:00.820107.820107 lmp.py:414]   Expert 58 |    140 | CPU
DEBUG 01-06 17:11:00.820034.820034 lmp.py:414]   Expert 60 |    144 | CPU
DEBUG 01-06 17:11:00.820200.820200 lmp.py:414]   Expert 43 |    147 | CPU
DEBUG 01-06 17:11:00.820890.820890 lmp.py:414]   Expert  1 |    150 | CPU
DEBUG 01-06 17:11:00.820056.820056 lmp.py:414]   Expert 38 |    153 | CPU
DEBUG 01-06 17:11:00.820176.820176 lmp.py:414]   Expert 49 |    154 | CPU
DEBUG 01-06 17:11:00.820103.820103 lmp.py:414]   Expert 51 |    155 | CPU
DEBUG 01-06 17:11:00.820793.820793 lmp.py:414]   Expert 34 |    161 | CPU
DEBUG 01-06 17:11:00.820244.820244 lmp.py:414]   Expert 35 |    164 | CPU
DEBUG 01-06 17:11:00.820933.820933 lmp.py:414]   Expert 36 |    168 | CPU
DEBUG 01-06 17:11:00.820622.820622 lmp.py:414]   Expert 11 |    170 | CPU
DEBUG 01-06 17:11:00.820550.820550 lmp.py:414]   Expert 17 |    170 | CPU
DEBUG 01-06 17:11:00.820478.820478 lmp.py:414]   Expert 59 |    174 | CPU
DEBUG 01-06 17:11:00.820167.820167 lmp.py:414]   Expert 10 |    180 | CPU
DEBUG 01-06 17:11:00.820856.820856 lmp.py:414]   Expert 20 |    182 | GPU
DEBUG 01-06 17:11:00.820784.820784 lmp.py:414]   Expert  2 |    186 | GPU
DEBUG 01-06 17:11:00.820712.820712 lmp.py:414]   Expert 39 |    189 | GPU
DEBUG 01-06 17:11:00.820163.820163 lmp.py:414]   Expert 33 |    197 | GPU
DEBUG 01-06 17:11:00.820613.820613 lmp.py:414]   Expert 12 |    198 | GPU
DEBUG 01-06 17:11:00.820826.820826 lmp.py:414]   Expert 21 |    198 | GPU
DEBUG 01-06 17:11:00.820277.820277 lmp.py:414]   Expert 48 |    198 | GPU
DEBUG 01-06 17:11:00.820489.820489 lmp.py:414]   Expert 15 |    199 | GPU
DEBUG 01-06 17:11:00.820702.820702 lmp.py:414]   Expert 53 |    204 | GPU
DEBUG 01-06 17:11:00.820252.820252 lmp.py:414]   Expert 19 |    220 | GPU
DEBUG 01-06 17:11:00.820372.820372 lmp.py:414]   Expert 26 |    221 | GPU
DEBUG 01-06 17:11:00.820922.820922 lmp.py:414]   Expert 30 |    221 | GPU
DEBUG 01-06 17:11:00.820611.820611 lmp.py:414]   Expert 45 |    221 | GPU
DEBUG 01-06 17:11:00.820824.820824 lmp.py:414]   Expert  5 |    227 | GPU
DEBUG 01-06 17:11:00.820275.820275 lmp.py:414]   Expert  4 |    229 | GPU
DEBUG 01-06 17:11:00.820487.820487 lmp.py:414]   Expert 24 |    229 | GPU
DEBUG 01-06 17:11:00.820461.820461 lmp.py:414]   Expert 42 |    242 | GPU
DEBUG 01-06 17:11:00.820912.820912 lmp.py:414]   Expert 50 |    245 | GPU
DEBUG 01-06 17:11:00.820125.820125 lmp.py:414]   Expert 29 |    254 | GPU
DEBUG 01-06 17:11:00.821099.821099 lmp.py:414]   Expert 56 |    262 | GPU
DEBUG 01-06 17:11:00.821550.821550 lmp.py:414]   Expert 61 |    270 | GPU
DEBUG 01-06 17:11:00.821239.821239 lmp.py:414]   Expert  8 |    283 | GPU
DEBUG 01-06 17:11:00.821928.821928 lmp.py:414]   Expert 63 |    285 | GPU
DEBUG 01-06 17:11:00.821909.821909 lmp.py:414]   Expert 46 |    294 | GPU
DEBUG 01-06 17:11:00.821790.821790 lmp.py:414]   Expert  9 |    300 | GPU
DEBUG 01-06 17:11:00.821480.821480 lmp.py:414]   Expert  6 |    316 | GPU
DEBUG 01-06 17:11:00.821931.821931 lmp.py:414]   Expert 16 |    316 | GPU
DEBUG 01-06 17:11:00.821143.821143 lmp.py:414]   Expert 40 |    319 | GPU
DEBUG 01-06 17:11:00.821594.821594 lmp.py:414]   Expert  7 |    322 | GPU
DEBUG 01-06 17:11:00.821045.821045 lmp.py:414]   Expert 23 |    325 | GPU
DEBUG 01-06 17:11:00.821496.821496 lmp.py:414]   Expert 14 |    413 | GPU
DEBUG 01-06 17:11:00.821947.821947 lmp.py:414]   Expert 57 |    464 | GPU
DEBUG 01-06 17:11:00.821351.821351 lmp.py:415] 
DEBUG 01-06 17:11:00.821351.821351 lmp.py:415]   CPU total tokens: 4059 (33.0%)
DEBUG 01-06 17:11:00.821471.821471 lmp.py:416]   GPU total tokens: 8229 (67.0%)
DEBUG 01-06 17:11:00.821028.821028 cuda_h.py:19] end experts_map_get cost 0.0015993118286132812 seconds
DEBUG 01-06 17:11:00.821817.821817 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-06 17:11:00.821554.821554 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 17:11:00.823374.823374 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 17:11:00.823658.823658 cuda_h.py:19] end allocate_cuda_memory cost 0.0003077983856201172 seconds
DEBUG 01-06 17:11:00.823787.823787 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 17:11:00.823404.823404 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 17:11:00.824273.824273 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 17:11:00.824023.824023 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, fc49f5f1-a07c-41ed-a091-6187c9106a40
DEBUG 01-06 17:11:00.824229.824229 client.py:106] call stub.LoadModelAsync
INFO 01-06 17:11:00.826082.826082 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, fc49f5f1-a07c-41ed-a091-6187c9106a40
DEBUG 01-06 17:11:00.826345.826345 cuda_h.py:19] end load_into_gpu_async cost 0.002959728240966797 seconds
DEBUG 01-06 17:11:00.827646.827646 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 17:11:00.827852.827852 cuda_h.py:19] end restore_tensors2 cost 0.0003676414489746094 seconds
DEBUG 01-06 17:11:00.827668.827668 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.006167173385620117 seconds
DEBUG 01-06 17:11:00.830476.830476 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.00898432731628418 seconds
DEBUG 01-06 17:11:00.830657.830657 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-06 17:11:00.830358.830358 lmp.py:461] 
DEBUG 01-06 17:11:00.830358.830358 lmp.py:461]   Computing 32 experts on CPU...
DEBUG 01-06 17:11:00.830566.830566 cuda_h.py:19] end cpu_experts_submit cost 0.0002155303955078125 seconds
DEBUG 01-06 17:11:00.830700.830700 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-06 17:11:00.843816.843816 mlpmodule.py:706] group tensors cost 0.012516021728515625 s
DEBUG 01-06 17:11:00.846653.846653 mlpmodule.py:744] pad cost 0.0020639896392822266 s
DEBUG 01-06 17:11:00.846545.846545 mlpmodule.py:750] create cpu tensor cost 5.888938903808594e-05 s
DEBUG 01-06 17:11:00.846958.846958 mlpmodule.py:755] move to cpu cost 4.4345855712890625e-05 s
DEBUG 01-06 17:11:00.899917.899917 mlpmodule.py:769] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-06 17:11:00.900081.900081 mlpmodule.py:770] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-06 17:11:00.917717.917717 mlpmodule.py:775] group_w3 first element: -0.0107421875
WARNING 01-06 17:11:00.918682.918682 mlpmodule.py:785] start einsum2
DEBUG 01-06 17:11:00.938481.938481 mlpmodule.py:795] group einsum cost 0.09186339378356934 s
DEBUG 01-06 17:11:00.939055.939055 mlpmodule.py:803] cpy2cputensor cost 0.0006911754608154297 s
DEBUG 01-06 17:11:00.947180.947180 cuda_h.py:19] end wait_cetm_experts cost 0.11635208129882812 seconds
DEBUG 01-06 17:11:00.947911.947911 cuda_h.py:10] start gpu_sexperts
DEBUG 01-06 17:11:00.947246.947246 cuda_h.py:19] end gpu_sexperts cost 0.0006544589996337891 seconds
DEBUG 01-06 17:11:00.947308.947308 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-06 17:11:00.947503.947503 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.574920654296875e-05 seconds
DEBUG 01-06 17:11:00.948981.948981 cuda_h.py:10] start wait_experts
INFO 01-06 17:11:00.948234.948234 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, fc49f5f1-a07c-41ed-a091-6187c9106a40
INFO 01-06 17:11:00.953928.953928 client.py:127] Model loaded
DEBUG 01-06 17:11:00.953930.953930 cuda_h.py:19] end wait_experts cost 0.0053653717041015625 seconds
DEBUG 01-06 17:11:00.953593.953593 cuda_h.py:10] start gpu_experts
DEBUG 01-06 17:11:00.953349.953349 lmp.py:506]   Computing 32 experts on GPU...
DEBUG 01-06 17:11:00.957468.957468 mlpmodule.py:664]  experts func einsum cost 0.12641286849975586 s
DEBUG 01-06 17:11:00.957718.957718 mlpmodule.py:533] gpu group tensors cost 0.004172801971435547 s
DEBUG 01-06 17:11:00.959845.959845 mlpmodule.py:566] gpu pad cost 0.0015707015991210938 s
DEBUG 01-06 17:11:00.960610.960610 mlpmodule.py:584] gpu group einsum cost 0.0008156299591064453 s
DEBUG 01-06 17:11:00.963624.963624 mlpmodule.py:613] gpu experts func einsum cost 0.009690046310424805 s
DEBUG 01-06 17:11:00.963614.963614 cuda_h.py:19] end gpu_experts cost 0.009888410568237305 seconds
DEBUG 01-06 17:11:00.963730.963730 cuda_h.py:19] end layer_moe_generate_1 cost 0.24271464347839355 seconds
DEBUG 01-06 17:11:00.963033.963033 lmp.py:220] -------------------------------- end layer 1 --------------------------------
DEBUG 01-06 17:11:00.963511.963511 lmp.py:176] -------------------------------- start layer 2 --------------------------------
DEBUG 01-06 17:11:00.963730.963730 cuda_h.py:10] start start_load_qkvogn_s_weight_l_3
DEBUG 01-06 17:11:00.963301.963301 cuda_h.py:10] start start_load_qkvogn_s_weight_l_3
DEBUG 01-06 17:11:00.963236.963236 cuda_h.py:19] end start_load_qkvogn_s_weight_l_3 cost 3.0517578125e-05 seconds
DEBUG 01-06 17:11:00.963198.963198 cuda_h.py:19] end start_load_qkvogn_s_weight_l_3 cost 7.724761962890625e-05 seconds
DEBUG 01-06 17:11:00.963033.963033 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-06 17:11:00.963816.963816 cuda_h.py:10] start sllm_worker_task
DEBUG 01-06 17:11:00.963364.963364 mlpmodule.py:367] cuda:1 cuda:1
DEBUG 01-06 17:11:00.964233.964233 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 17:11:00.964979.964979 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 17:11:00.964723.964723 cuda_h.py:19] end allocate_cuda_memory cost 0.00021982192993164062 seconds
DEBUG 01-06 17:11:00.964354.964354 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 17:11:00.964839.964839 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 17:11:00.964768.964768 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 17:11:00.964908.964908 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, dd9e263a-2203-46bb-b811-0b73e20ca153
DEBUG 01-06 17:11:00.964468.964468 client.py:106] call stub.LoadModelAsync
DEBUG 01-06 17:11:00.965316.965316 cuda_h.py:10] start self_attn
INFO 01-06 17:11:00.966418.966418 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, dd9e263a-2203-46bb-b811-0b73e20ca153
DEBUG 01-06 17:11:00.966507.966507 cuda_h.py:19] end load_into_gpu_async cost 0.0019299983978271484 seconds
DEBUG 01-06 17:11:00.966647.966647 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 17:11:00.966942.966942 cuda_h.py:19] end restore_tensors2 cost 7.390975952148438e-05 seconds
DEBUG 01-06 17:11:00.966804.966804 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0025260448455810547 seconds
INFO 01-06 17:11:00.966740.966740 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, dd9e263a-2203-46bb-b811-0b73e20ca153
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-06 17:11:00.968287.968287 cuda_h.py:19] end self_attn cost 0.0034034252166748047 seconds
DEBUG 01-06 17:11:00.969783.969783 cuda_h.py:19] end iln_self_attn_paln cost 0.005154132843017578 seconds
DEBUG 01-06 17:11:00.969322.969322 cuda_h.py:10] start layer_moe_generate_2
DEBUG 01-06 17:11:00.969774.969774 cuda_h.py:10] start gate
DEBUG 01-06 17:11:00.969940.969940 cuda_h.py:19] end gate cost 0.0007424354553222656 seconds
DEBUG 01-06 17:11:00.969644.969644 cuda_h.py:10] start experts_map_get
DEBUG 01-06 17:11:00.970716.970716 lmp.py:403] 
DEBUG 01-06 17:11:00.970716.970716 lmp.py:403] Expert Token Distribution & Device Allocation:
DEBUG 01-06 17:11:00.970916.970916 lmp.py:404]   Total experts: 64
DEBUG 01-06 17:11:00.970626.970626 lmp.py:405]   CPU experts: 32 (50%)
DEBUG 01-06 17:11:00.970521.970521 lmp.py:406]   GPU experts: 32 (50%)
DEBUG 01-06 17:11:00.970078.970078 lmp.py:407] 
DEBUG 01-06 17:11:00.970078.970078 lmp.py:407]   Expert ID | Tokens | Device
DEBUG 01-06 17:11:00.970350.970350 lmp.py:408]   -----------------------------------
DEBUG 01-06 17:11:00.970775.970775 lmp.py:414]   Expert 58 |     51 | CPU
DEBUG 01-06 17:11:00.970286.970286 lmp.py:414]   Expert 27 |     56 | CPU
DEBUG 01-06 17:11:00.970605.970605 lmp.py:414]   Expert  3 |     68 | CPU
DEBUG 01-06 17:11:00.970685.970685 lmp.py:414]   Expert 17 |     84 | CPU
DEBUG 01-06 17:11:00.970527.970527 lmp.py:414]   Expert  0 |     88 | CPU
DEBUG 01-06 17:11:00.970614.970614 lmp.py:414]   Expert 24 |     88 | CPU
DEBUG 01-06 17:11:00.970171.970171 lmp.py:414]   Expert 28 |    105 | CPU
DEBUG 01-06 17:11:00.970297.970297 lmp.py:414]   Expert 34 |    114 | CPU
DEBUG 01-06 17:11:00.970186.970186 lmp.py:414]   Expert 51 |    118 | CPU
DEBUG 01-06 17:11:00.970835.970835 lmp.py:414]   Expert 32 |    120 | CPU
DEBUG 01-06 17:11:00.970485.970485 lmp.py:414]   Expert  9 |    129 | CPU
DEBUG 01-06 17:11:00.970896.970896 lmp.py:414]   Expert 23 |    135 | CPU
DEBUG 01-06 17:11:00.970546.970546 lmp.py:414]   Expert  7 |    136 | CPU
DEBUG 01-06 17:11:00.970719.970719 lmp.py:414]   Expert 15 |    136 | CPU
DEBUG 01-06 17:11:00.970892.970892 lmp.py:414]   Expert 26 |    138 | CPU
DEBUG 01-06 17:11:00.970257.970257 lmp.py:414]   Expert 30 |    144 | CPU
DEBUG 01-06 17:11:00.970622.970622 lmp.py:414]   Expert 45 |    146 | CPU
DEBUG 01-06 17:11:00.970272.970272 lmp.py:414]   Expert 62 |    147 | CPU
DEBUG 01-06 17:11:00.970445.970445 lmp.py:414]   Expert 57 |    150 | CPU
DEBUG 01-06 17:11:00.970618.970618 lmp.py:414]   Expert  1 |    152 | CPU
DEBUG 01-06 17:11:00.971268.971268 lmp.py:414]   Expert 36 |    155 | CPU
DEBUG 01-06 17:11:00.971440.971440 lmp.py:414]   Expert  8 |    159 | CPU
DEBUG 01-06 17:11:00.971044.971044 lmp.py:414]   Expert 29 |    160 | CPU
DEBUG 01-06 17:11:00.971363.971363 lmp.py:414]   Expert 25 |    164 | CPU
DEBUG 01-06 17:11:00.971251.971251 lmp.py:414]   Expert 54 |    167 | CPU
DEBUG 01-06 17:11:00.971424.971424 lmp.py:414]   Expert  6 |    171 | CPU
DEBUG 01-06 17:11:00.971073.971073 lmp.py:414]   Expert 49 |    171 | CPU
DEBUG 01-06 17:11:00.971723.971723 lmp.py:414]   Expert 48 |    174 | CPU
DEBUG 01-06 17:11:00.971373.971373 lmp.py:414]   Expert 12 |    176 | CPU
DEBUG 01-06 17:11:00.971215.971215 lmp.py:414]   Expert 35 |    176 | CPU
DEBUG 01-06 17:11:00.971580.971580 lmp.py:414]   Expert 37 |    178 | CPU
DEBUG 01-06 17:11:00.971230.971230 lmp.py:414]   Expert 60 |    186 | CPU
DEBUG 01-06 17:11:00.971641.971641 lmp.py:414]   Expert 13 |    188 | GPU
DEBUG 01-06 17:11:00.971291.971291 lmp.py:414]   Expert 33 |    189 | GPU
DEBUG 01-06 17:11:00.971464.971464 lmp.py:414]   Expert 53 |    189 | GPU
DEBUG 01-06 17:11:00.971875.971875 lmp.py:414]   Expert 10 |    194 | GPU
DEBUG 01-06 17:11:00.971240.971240 lmp.py:414]   Expert 16 |    194 | GPU
DEBUG 01-06 17:11:00.971843.971843 lmp.py:414]   Expert 21 |    198 | GPU
DEBUG 01-06 17:11:00.971209.971209 lmp.py:414]   Expert 40 |    200 | GPU
DEBUG 01-06 17:11:00.971050.971050 lmp.py:414]   Expert 43 |    202 | GPU
DEBUG 01-06 17:11:00.971654.971654 lmp.py:414]   Expert 38 |    204 | GPU
DEBUG 01-06 17:11:00.971780.971780 lmp.py:414]   Expert  5 |    208 | GPU
DEBUG 01-06 17:11:00.971384.971384 lmp.py:414]   Expert 44 |    216 | GPU
DEBUG 01-06 17:11:00.971987.971987 lmp.py:414]   Expert 19 |    217 | GPU
DEBUG 01-06 17:11:00.971399.971399 lmp.py:414]   Expert 50 |    217 | GPU
DEBUG 01-06 17:11:00.971810.971810 lmp.py:414]   Expert 52 |    217 | GPU
DEBUG 01-06 17:11:00.971744.971744 lmp.py:414]   Expert 41 |    219 | GPU
DEBUG 01-06 17:11:00.971679.971679 lmp.py:414]   Expert  4 |    221 | GPU
DEBUG 01-06 17:11:00.971190.971190 lmp.py:414]   Expert 59 |    223 | GPU
DEBUG 01-06 17:11:00.971032.971032 lmp.py:414]   Expert 55 |    233 | GPU
DEBUG 01-06 17:11:00.971681.971681 lmp.py:414]   Expert 56 |    240 | GPU
DEBUG 01-06 17:11:00.971331.971331 lmp.py:414]   Expert 31 |    241 | GPU
DEBUG 01-06 17:11:00.971173.971173 lmp.py:414]   Expert 20 |    251 | GPU
DEBUG 01-06 17:11:00.971492.971492 lmp.py:414]   Expert 39 |    252 | GPU
DEBUG 01-06 17:11:00.971049.971049 lmp.py:414]   Expert 22 |    265 | GPU
DEBUG 01-06 17:11:00.971652.971652 lmp.py:414]   Expert  2 |    267 | GPU
DEBUG 01-06 17:11:00.971017.971017 lmp.py:414]   Expert 47 |    276 | GPU
DEBUG 01-06 17:11:00.971382.971382 lmp.py:414]   Expert 63 |    276 | GPU
DEBUG 01-06 17:11:00.971986.971986 lmp.py:414]   Expert 42 |    303 | GPU
DEBUG 01-06 17:11:00.971874.971874 lmp.py:414]   Expert 18 |    314 | GPU
DEBUG 01-06 17:11:00.971431.971431 lmp.py:414]   Expert 14 |    317 | GPU
DEBUG 01-06 17:11:00.971035.971035 lmp.py:414]   Expert 46 |    367 | GPU
DEBUG 01-06 17:11:00.971638.971638 lmp.py:414]   Expert 11 |    388 | GPU
DEBUG 01-06 17:11:00.972765.972765 lmp.py:414]   Expert 61 |    460 | GPU
DEBUG 01-06 17:11:00.972083.972083 lmp.py:415] 
DEBUG 01-06 17:11:00.972083.972083 lmp.py:415]   CPU total tokens: 4342 (35.3%)
DEBUG 01-06 17:11:00.972356.972356 lmp.py:416]   GPU total tokens: 7946 (64.7%)
DEBUG 01-06 17:11:00.972503.972503 cuda_h.py:19] end experts_map_get cost 0.0020627975463867188 seconds
DEBUG 01-06 17:11:00.972490.972490 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-06 17:11:00.972380.972380 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 17:11:00.972444.972444 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 17:11:00.974019.974019 cuda_h.py:19] end allocate_cuda_memory cost 0.0018935203552246094 seconds
DEBUG 01-06 17:11:00.974677.974677 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 17:11:00.974956.974956 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 17:11:00.974864.974864 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 17:11:00.974706.974706 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, d7b3b9ce-260c-4478-bbaf-36e6098d9acc
DEBUG 01-06 17:11:00.974215.974215 client.py:106] call stub.LoadModelAsync
INFO 01-06 17:11:00.975712.975712 client.py:127] Model loaded
DEBUG 01-06 17:11:00.975270.975270 cuda_h.py:19] end sllm_worker_task cost 0.011789321899414062 seconds
INFO 01-06 17:11:00.977260.977260 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, d7b3b9ce-260c-4478-bbaf-36e6098d9acc
DEBUG 01-06 17:11:00.977570.977570 cuda_h.py:19] end load_into_gpu_async cost 0.002883434295654297 seconds
DEBUG 01-06 17:11:00.977824.977824 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 17:11:00.977072.977072 cuda_h.py:19] end restore_tensors2 cost 0.00039649009704589844 seconds
DEBUG 01-06 17:11:00.977318.977318 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.005648374557495117 seconds
DEBUG 01-06 17:11:00.980644.980644 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.008327007293701172 seconds
DEBUG 01-06 17:11:00.980872.980872 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-06 17:11:00.980980.980980 lmp.py:461] 
DEBUG 01-06 17:11:00.980980.980980 lmp.py:461]   Computing 32 experts on CPU...
DEBUG 01-06 17:11:00.980585.980585 cuda_h.py:19] end cpu_experts_submit cost 0.00010967254638671875 seconds
DEBUG 01-06 17:11:00.980573.980573 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-06 17:11:00.986826.986826 mlpmodule.py:706] group tensors cost 0.005848407745361328 s
DEBUG 01-06 17:11:00.990765.990765 mlpmodule.py:744] pad cost 0.002644062042236328 s
DEBUG 01-06 17:11:00.990492.990492 mlpmodule.py:750] create cpu tensor cost 6.0558319091796875e-05 s
DEBUG 01-06 17:11:00.990634.990634 mlpmodule.py:755] move to cpu cost 4.2438507080078125e-05 s
DEBUG 01-06 17:11:01.001222.001222 mlpmodule.py:769] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-06 17:11:01.001612.001612 mlpmodule.py:770] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-06 17:11:01.001516.001516 mlpmodule.py:775] group_w3 first element: -0.0380859375
WARNING 01-06 17:11:01.001818.001818 mlpmodule.py:785] start einsum2
DEBUG 01-06 17:11:01.021291.021291 mlpmodule.py:795] group einsum cost 0.030790090560913086 s
DEBUG 01-06 17:11:01.022654.022654 mlpmodule.py:803] cpy2cputensor cost 0.0007100105285644531 s
DEBUG 01-06 17:11:01.026205.026205 cuda_h.py:19] end wait_cetm_experts cost 0.046135663986206055 seconds
DEBUG 01-06 17:11:01.026228.026228 cuda_h.py:10] start gpu_sexperts
DEBUG 01-06 17:11:01.027513.027513 cuda_h.py:19] end gpu_sexperts cost 0.0005507469177246094 seconds
DEBUG 01-06 17:11:01.027369.027369 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-06 17:11:01.027319.027319 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.574920654296875e-05 seconds
DEBUG 01-06 17:11:01.027690.027690 cuda_h.py:10] start wait_experts
INFO 01-06 17:11:01.027784.027784 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, d7b3b9ce-260c-4478-bbaf-36e6098d9acc
INFO 01-06 17:11:01.029148.029148 client.py:127] Model loaded
DEBUG 01-06 17:11:01.029488.029488 cuda_h.py:19] end wait_experts cost 0.0014312267303466797 seconds
DEBUG 01-06 17:11:01.029052.029052 cuda_h.py:10] start gpu_experts
DEBUG 01-06 17:11:01.029808.029808 lmp.py:506]   Computing 32 experts on GPU...
DEBUG 01-06 17:11:01.029136.029136 mlpmodule.py:533] gpu group tensors cost 0.000621795654296875 s
DEBUG 01-06 17:11:01.032387.032387 mlpmodule.py:566] gpu pad cost 0.0020494461059570312 s
DEBUG 01-06 17:11:01.034745.034745 mlpmodule.py:584] gpu group einsum cost 0.0023193359375 s
DEBUG 01-06 17:11:01.037816.037816 mlpmodule.py:664]  experts func einsum cost 0.05698680877685547 s
DEBUG 01-06 17:11:01.038069.038069 mlpmodule.py:613] gpu experts func einsum cost 0.008713722229003906 s
DEBUG 01-06 17:11:01.038960.038960 cuda_h.py:19] end gpu_experts cost 0.008891582489013672 seconds
DEBUG 01-06 17:11:01.038605.038605 cuda_h.py:19] end layer_moe_generate_2 cost 0.06912493705749512 seconds
DEBUG 01-06 17:11:01.038757.038757 lmp.py:220] -------------------------------- end layer 2 --------------------------------
DEBUG 01-06 17:11:01.038851.038851 lmp.py:176] -------------------------------- start layer 3 --------------------------------
DEBUG 01-06 17:11:01.038739.038739 cuda_h.py:10] start start_load_qkvogn_s_weight_l_4
DEBUG 01-06 17:11:01.038641.038641 cuda_h.py:10] start start_load_qkvogn_s_weight_l_4
DEBUG 01-06 17:11:01.038729.038729 cuda_h.py:19] end start_load_qkvogn_s_weight_l_4 cost 3.147125244140625e-05 seconds
DEBUG 01-06 17:11:01.038194.038194 cuda_h.py:19] end start_load_qkvogn_s_weight_l_4 cost 6.914138793945312e-05 seconds
DEBUG 01-06 17:11:01.038221.038221 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-06 17:11:01.038799.038799 mlpmodule.py:367] cuda:1 cuda:1
DEBUG 01-06 17:11:01.038133.038133 cuda_h.py:10] start sllm_worker_task
DEBUG 01-06 17:11:01.038771.038771 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 17:11:01.038939.038939 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 17:11:01.039822.039822 cuda_h.py:19] end allocate_cuda_memory cost 0.00022935867309570312 seconds
DEBUG 01-06 17:11:01.039169.039169 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 17:11:01.039932.039932 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 17:11:01.039801.039801 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 17:11:01.039596.039596 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 43be6183-8b4f-4615-9124-6e17df4c583c
DEBUG 01-06 17:11:01.039943.039943 client.py:106] call stub.LoadModelAsync
DEBUG 01-06 17:11:01.039073.039073 cuda_h.py:10] start self_attn
INFO 01-06 17:11:01.040045.040045 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 43be6183-8b4f-4615-9124-6e17df4c583c
DEBUG 01-06 17:11:01.040596.040596 cuda_h.py:19] end load_into_gpu_async cost 0.0016481876373291016 seconds
DEBUG 01-06 17:11:01.040869.040869 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 17:11:01.041752.041752 cuda_h.py:19] end restore_tensors2 cost 6.389617919921875e-05 seconds
DEBUG 01-06 17:11:01.041363.041363 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0021924972534179688 seconds
INFO 01-06 17:11:01.041007.041007 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 43be6183-8b4f-4615-9124-6e17df4c583c
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-06 17:11:01.042267.042267 cuda_h.py:19] end self_attn cost 0.002949953079223633 seconds
DEBUG 01-06 17:11:01.043502.043502 cuda_h.py:19] end iln_self_attn_paln cost 0.004424571990966797 seconds
DEBUG 01-06 17:11:01.043730.043730 cuda_h.py:10] start layer_moe_generate_3
DEBUG 01-06 17:11:01.043738.043738 cuda_h.py:10] start gate
DEBUG 01-06 17:11:01.043085.043085 cuda_h.py:19] end gate cost 0.0006418228149414062 seconds
DEBUG 01-06 17:11:01.043629.043629 cuda_h.py:10] start experts_map_get
DEBUG 01-06 17:11:01.044176.044176 lmp.py:403] 
DEBUG 01-06 17:11:01.044176.044176 lmp.py:403] Expert Token Distribution & Device Allocation:
DEBUG 01-06 17:11:01.044124.044124 lmp.py:404]   Total experts: 64
DEBUG 01-06 17:11:01.044681.044681 lmp.py:405]   CPU experts: 32 (50%)
DEBUG 01-06 17:11:01.044423.044423 lmp.py:406]   GPU experts: 32 (50%)
DEBUG 01-06 17:11:01.044543.044543 lmp.py:407] 
DEBUG 01-06 17:11:01.044543.044543 lmp.py:407]   Expert ID | Tokens | Device
DEBUG 01-06 17:11:01.044663.044663 lmp.py:408]   -----------------------------------
DEBUG 01-06 17:11:01.044028.044028 lmp.py:414]   Expert  1 |     45 | CPU
DEBUG 01-06 17:11:01.044923.044923 lmp.py:414]   Expert 27 |     62 | CPU
DEBUG 01-06 17:11:01.044043.044043 lmp.py:414]   Expert  7 |     77 | CPU
DEBUG 01-06 17:11:01.044209.044209 lmp.py:414]   Expert 48 |     80 | CPU
DEBUG 01-06 17:11:01.044137.044137 lmp.py:414]   Expert 15 |     99 | CPU
DEBUG 01-06 17:11:01.044687.044687 lmp.py:414]   Expert 30 |    106 | CPU
DEBUG 01-06 17:11:01.044807.044807 lmp.py:414]   Expert 61 |    115 | CPU
DEBUG 01-06 17:11:01.044450.044450 lmp.py:414]   Expert 32 |    120 | CPU
DEBUG 01-06 17:11:01.044331.044331 lmp.py:414]   Expert 18 |    121 | CPU
DEBUG 01-06 17:11:01.044974.044974 lmp.py:414]   Expert 45 |    122 | CPU
DEBUG 01-06 17:11:01.044617.044617 lmp.py:414]   Expert 34 |    135 | CPU
DEBUG 01-06 17:11:01.044499.044499 lmp.py:414]   Expert 26 |    137 | CPU
DEBUG 01-06 17:11:01.044142.044142 lmp.py:414]   Expert 36 |    138 | CPU
DEBUG 01-06 17:11:01.044546.044546 lmp.py:414]   Expert 11 |    140 | CPU
DEBUG 01-06 17:11:01.044666.044666 lmp.py:414]   Expert  5 |    141 | CPU
DEBUG 01-06 17:11:01.044547.044547 lmp.py:414]   Expert 39 |    142 | CPU
DEBUG 01-06 17:11:01.044667.044667 lmp.py:414]   Expert  6 |    143 | CPU
DEBUG 01-06 17:11:01.044310.044310 lmp.py:414]   Expert 59 |    144 | CPU
DEBUG 01-06 17:11:01.044715.044715 lmp.py:414]   Expert 51 |    147 | CPU
DEBUG 01-06 17:11:01.044119.044119 lmp.py:414]   Expert 49 |    155 | CPU
DEBUG 01-06 17:11:01.044762.044762 lmp.py:414]   Expert 23 |    157 | CPU
DEBUG 01-06 17:11:01.044167.044167 lmp.py:414]   Expert  9 |    161 | CPU
DEBUG 01-06 17:11:01.044571.044571 lmp.py:414]   Expert  2 |    163 | CPU
DEBUG 01-06 17:11:01.044691.044691 lmp.py:414]   Expert 50 |    166 | CPU
DEBUG 01-06 17:11:01.044573.044573 lmp.py:414]   Expert 35 |    167 | CPU
DEBUG 01-06 17:11:01.044216.044216 lmp.py:414]   Expert 56 |    167 | CPU
DEBUG 01-06 17:11:01.044620.044620 lmp.py:414]   Expert 40 |    168 | CPU
DEBUG 01-06 17:11:01.044786.044786 lmp.py:414]   Expert 52 |    169 | CPU
DEBUG 01-06 17:11:01.044952.044952 lmp.py:414]   Expert 16 |    172 | CPU
DEBUG 01-06 17:11:01.044880.044880 lmp.py:414]   Expert 37 |    186 | CPU
DEBUG 01-06 17:11:01.044285.044285 lmp.py:414]   Expert  4 |    187 | CPU
DEBUG 01-06 17:11:01.044689.044689 lmp.py:414]   Expert 42 |    192 | CPU
DEBUG 01-06 17:11:01.044855.044855 lmp.py:414]   Expert 13 |    193 | GPU
DEBUG 01-06 17:11:01.044737.044737 lmp.py:414]   Expert 62 |    194 | GPU
DEBUG 01-06 17:11:01.044141.044141 lmp.py:414]   Expert 17 |    198 | GPU
DEBUG 01-06 17:11:01.044307.044307 lmp.py:414]   Expert 38 |    199 | GPU
DEBUG 01-06 17:11:01.045235.045235 lmp.py:414]   Expert 21 |    201 | GPU
DEBUG 01-06 17:11:01.045401.045401 lmp.py:414]   Expert 44 |    205 | GPU
DEBUG 01-06 17:11:01.045567.045567 lmp.py:414]   Expert 60 |    209 | GPU
DEBUG 01-06 17:11:01.045926.045926 lmp.py:414]   Expert  3 |    210 | GPU
DEBUG 01-06 17:11:01.045807.045807 lmp.py:414]   Expert 28 |    210 | GPU
DEBUG 01-06 17:11:01.045973.045973 lmp.py:414]   Expert 58 |    211 | GPU
DEBUG 01-06 17:11:01.045901.045901 lmp.py:414]   Expert 10 |    215 | GPU
DEBUG 01-06 17:11:01.045067.045067 lmp.py:414]   Expert 47 |    218 | GPU
DEBUG 01-06 17:11:01.045233.045233 lmp.py:414]   Expert 53 |    218 | GPU
DEBUG 01-06 17:11:01.045638.045638 lmp.py:414]   Expert 55 |    220 | GPU
DEBUG 01-06 17:11:01.045804.045804 lmp.py:414]   Expert 20 |    223 | GPU
DEBUG 01-06 17:11:01.045970.045970 lmp.py:414]   Expert 57 |    227 | GPU
DEBUG 01-06 17:11:01.045375.045375 lmp.py:414]   Expert 33 |    233 | GPU
DEBUG 01-06 17:11:01.045541.045541 lmp.py:414]   Expert 31 |    235 | GPU
DEBUG 01-06 17:11:01.045707.045707 lmp.py:414]   Expert  8 |    236 | GPU
DEBUG 01-06 17:11:01.045873.045873 lmp.py:414]   Expert 46 |    237 | GPU
DEBUG 01-06 17:11:01.045801.045801 lmp.py:414]   Expert 24 |    244 | GPU
DEBUG 01-06 17:11:01.045967.045967 lmp.py:414]   Expert 19 |    247 | GPU
DEBUG 01-06 17:11:01.045656.045656 lmp.py:414]   Expert 63 |    265 | GPU
DEBUG 01-06 17:11:01.045822.045822 lmp.py:414]   Expert 14 |    266 | GPU
DEBUG 01-06 17:11:01.045750.045750 lmp.py:414]   Expert 12 |    274 | GPU
DEBUG 01-06 17:11:01.045678.045678 lmp.py:414]   Expert 29 |    274 | GPU
DEBUG 01-06 17:11:01.045321.045321 lmp.py:414]   Expert 22 |    276 | GPU
DEBUG 01-06 17:11:01.045964.045964 lmp.py:414]   Expert  0 |    294 | GPU
DEBUG 01-06 17:11:01.045130.045130 lmp.py:414]   Expert 43 |    307 | GPU
DEBUG 01-06 17:11:01.045296.045296 lmp.py:414]   Expert 54 |    331 | GPU
DEBUG 01-06 17:11:01.045462.045462 lmp.py:414]   Expert 41 |    382 | GPU
DEBUG 01-06 17:11:01.045390.045390 lmp.py:414]   Expert 25 |    412 | GPU
DEBUG 01-06 17:11:01.045510.045510 lmp.py:415] 
DEBUG 01-06 17:11:01.045510.045510 lmp.py:415]   CPU total tokens: 4424 (36.0%)
DEBUG 01-06 17:11:01.045629.045629 lmp.py:416]   GPU total tokens: 7864 (64.0%)
DEBUG 01-06 17:11:01.045233.045233 cuda_h.py:19] end experts_map_get cost 0.0015666484832763672 seconds
DEBUG 01-06 17:11:01.045022.045022 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-06 17:11:01.045752.045752 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 17:11:01.045796.045796 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 17:11:01.047996.047996 cuda_h.py:19] end allocate_cuda_memory cost 0.0013763904571533203 seconds
DEBUG 01-06 17:11:01.047905.047905 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 17:11:01.047907.047907 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 17:11:01.047908.047908 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 17:11:01.047273.047273 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 7c9efb7f-71d1-4d44-a318-77f55c5c9fcd
DEBUG 01-06 17:11:01.047550.047550 client.py:106] call stub.LoadModelAsync
INFO 01-06 17:11:01.049746.049746 client.py:127] Model loaded
DEBUG 01-06 17:11:01.049779.049779 cuda_h.py:19] end sllm_worker_task cost 0.010506391525268555 seconds
INFO 01-06 17:11:01.050120.050120 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 7c9efb7f-71d1-4d44-a318-77f55c5c9fcd
DEBUG 01-06 17:11:01.050924.050924 cuda_h.py:19] end load_into_gpu_async cost 0.003490447998046875 seconds
DEBUG 01-06 17:11:01.050196.050196 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 17:11:01.051914.051914 cuda_h.py:19] end restore_tensors2 cost 0.0002586841583251953 seconds
DEBUG 01-06 17:11:01.051684.051684 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0054738521575927734 seconds
DEBUG 01-06 17:11:01.053314.053314 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.008119344711303711 seconds
DEBUG 01-06 17:11:01.053290.053290 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-06 17:11:01.053014.053014 lmp.py:461] 
DEBUG 01-06 17:11:01.053014.053014 lmp.py:461]   Computing 32 experts on CPU...
DEBUG 01-06 17:11:01.053758.053758 cuda_h.py:19] end cpu_experts_submit cost 0.00010657310485839844 seconds
DEBUG 01-06 17:11:01.053097.053097 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-06 17:11:01.059908.059908 mlpmodule.py:706] group tensors cost 0.005104780197143555 s
DEBUG 01-06 17:11:01.061052.061052 mlpmodule.py:744] pad cost 0.0019381046295166016 s
DEBUG 01-06 17:11:01.061592.061592 mlpmodule.py:750] create cpu tensor cost 4.792213439941406e-05 s
DEBUG 01-06 17:11:01.061039.061039 mlpmodule.py:755] move to cpu cost 3.552436828613281e-05 s
DEBUG 01-06 17:11:01.073071.073071 mlpmodule.py:769] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-06 17:11:01.073938.073938 mlpmodule.py:770] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-06 17:11:01.073041.073041 mlpmodule.py:775] group_w3 first element: -0.054931640625
WARNING 01-06 17:11:01.073602.073602 mlpmodule.py:785] start einsum2
DEBUG 01-06 17:11:01.092145.092145 mlpmodule.py:795] group einsum cost 0.03018498420715332 s
DEBUG 01-06 17:11:01.093595.093595 mlpmodule.py:803] cpy2cputensor cost 0.0007517337799072266 s
DEBUG 01-06 17:11:01.097214.097214 cuda_h.py:19] end wait_cetm_experts cost 0.04399514198303223 seconds
DEBUG 01-06 17:11:01.098012.098012 cuda_h.py:10] start gpu_sexperts
DEBUG 01-06 17:11:01.098732.098732 cuda_h.py:19] end gpu_sexperts cost 0.00048661231994628906 seconds
DEBUG 01-06 17:11:01.098913.098913 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-06 17:11:01.098683.098683 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 3.409385681152344e-05 seconds
DEBUG 01-06 17:11:01.098916.098916 cuda_h.py:10] start wait_experts
INFO 01-06 17:11:01.098580.098580 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 7c9efb7f-71d1-4d44-a318-77f55c5c9fcd
INFO 01-06 17:11:01.102081.102081 client.py:127] Model loaded
DEBUG 01-06 17:11:01.102409.102409 cuda_h.py:19] end wait_experts cost 0.0035915374755859375 seconds
DEBUG 01-06 17:11:01.102502.102502 cuda_h.py:10] start gpu_experts
DEBUG 01-06 17:11:01.102698.102698 lmp.py:506]   Computing 32 experts on GPU...
DEBUG 01-06 17:11:01.103817.103817 mlpmodule.py:533] gpu group tensors cost 0.0006995201110839844 s
DEBUG 01-06 17:11:01.105072.105072 mlpmodule.py:566] gpu pad cost 0.0018017292022705078 s
DEBUG 01-06 17:11:01.105466.105466 mlpmodule.py:584] gpu group einsum cost 0.0005881786346435547 s
DEBUG 01-06 17:11:01.108815.108815 mlpmodule.py:664]  experts func einsum cost 0.05490374565124512 s
DEBUG 01-06 17:11:01.109706.109706 mlpmodule.py:613] gpu experts func einsum cost 0.006866455078125 s
DEBUG 01-06 17:11:01.109140.109140 cuda_h.py:19] end gpu_experts cost 0.007143735885620117 seconds
DEBUG 01-06 17:11:01.109309.109309 cuda_h.py:19] end layer_moe_generate_3 cost 0.06651091575622559 seconds
DEBUG 01-06 17:11:01.109181.109181 lmp.py:220] -------------------------------- end layer 3 --------------------------------
DEBUG 01-06 17:11:01.109328.109328 lmp.py:176] -------------------------------- start layer 4 --------------------------------
DEBUG 01-06 17:11:01.109024.109024 cuda_h.py:10] start start_load_qkvogn_s_weight_l_5
DEBUG 01-06 17:11:01.109264.109264 cuda_h.py:10] start start_load_qkvogn_s_weight_l_5
DEBUG 01-06 17:11:01.110253.110253 cuda_h.py:19] end start_load_qkvogn_s_weight_l_5 cost 3.0517578125e-05 seconds
DEBUG 01-06 17:11:01.110671.110671 cuda_h.py:19] end start_load_qkvogn_s_weight_l_5 cost 6.437301635742188e-05 seconds
DEBUG 01-06 17:11:01.110221.110221 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-06 17:11:01.110992.110992 mlpmodule.py:367] cuda:1 cuda:1
DEBUG 01-06 17:11:01.110564.110564 cuda_h.py:10] start sllm_worker_task
DEBUG 01-06 17:11:01.110090.110090 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 17:11:01.110826.110826 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 17:11:01.110368.110368 cuda_h.py:19] end allocate_cuda_memory cost 0.00032782554626464844 seconds
DEBUG 01-06 17:11:01.110040.110040 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 17:11:01.110895.110895 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 17:11:01.110764.110764 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 17:11:01.110321.110321 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 955612c4-5caa-46a6-8c92-c45487a7bbb4
DEBUG 01-06 17:11:01.110284.110284 client.py:106] call stub.LoadModelAsync
DEBUG 01-06 17:11:01.111546.111546 cuda_h.py:10] start self_attn
INFO 01-06 17:11:01.112104.112104 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 955612c4-5caa-46a6-8c92-c45487a7bbb4
DEBUG 01-06 17:11:01.112179.112179 cuda_h.py:19] end load_into_gpu_async cost 0.0015423297882080078 seconds
DEBUG 01-06 17:11:01.112736.112736 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 17:11:01.112395.112395 cuda_h.py:19] end restore_tensors2 cost 6.4849853515625e-05 seconds
DEBUG 01-06 17:11:01.112435.112435 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.002187490463256836 seconds
INFO 01-06 17:11:01.112894.112894 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 955612c4-5caa-46a6-8c92-c45487a7bbb4
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-06 17:11:01.114740.114740 cuda_h.py:19] end self_attn cost 0.0029561519622802734 seconds
DEBUG 01-06 17:11:01.114571.114571 cuda_h.py:19] end iln_self_attn_paln cost 0.004472494125366211 seconds
DEBUG 01-06 17:11:01.114606.114606 cuda_h.py:10] start layer_moe_generate_4
DEBUG 01-06 17:11:01.114515.114515 cuda_h.py:10] start gate
DEBUG 01-06 17:11:01.115398.115398 cuda_h.py:19] end gate cost 0.0006515979766845703 seconds
DEBUG 01-06 17:11:01.115182.115182 cuda_h.py:10] start experts_map_get
DEBUG 01-06 17:11:01.115953.115953 lmp.py:403] 
DEBUG 01-06 17:11:01.115953.115953 lmp.py:403] Expert Token Distribution & Device Allocation:
DEBUG 01-06 17:11:01.115577.115577 lmp.py:404]   Total experts: 64
DEBUG 01-06 17:11:01.115995.115995 lmp.py:405]   CPU experts: 32 (50%)
DEBUG 01-06 17:11:01.115737.115737 lmp.py:406]   GPU experts: 32 (50%)
DEBUG 01-06 17:11:01.115095.115095 lmp.py:407] 
DEBUG 01-06 17:11:01.115095.115095 lmp.py:407]   Expert ID | Tokens | Device
DEBUG 01-06 17:11:01.115931.115931 lmp.py:408]   -----------------------------------
DEBUG 01-06 17:11:01.115011.115011 lmp.py:414]   Expert 14 |     64 | CPU
DEBUG 01-06 17:11:01.115607.115607 lmp.py:414]   Expert 57 |     74 | CPU
DEBUG 01-06 17:11:01.115681.115681 lmp.py:414]   Expert 13 |     76 | CPU
DEBUG 01-06 17:11:01.115801.115801 lmp.py:414]   Expert 26 |     81 | CPU
DEBUG 01-06 17:11:01.115921.115921 lmp.py:414]   Expert 54 |     89 | CPU
DEBUG 01-06 17:11:01.115564.115564 lmp.py:414]   Expert 31 |     90 | CPU
DEBUG 01-06 17:11:01.115207.115207 lmp.py:414]   Expert 11 |     91 | CPU
DEBUG 01-06 17:11:01.115849.115849 lmp.py:414]   Expert 45 |     95 | CPU
DEBUG 01-06 17:11:01.115731.115731 lmp.py:414]   Expert 30 |    104 | CPU
DEBUG 01-06 17:11:01.116135.116135 lmp.py:414]   Expert 58 |    105 | CPU
DEBUG 01-06 17:11:01.116778.116778 lmp.py:414]   Expert 10 |    110 | CPU
DEBUG 01-06 17:11:01.116898.116898 lmp.py:414]   Expert 51 |    112 | CPU
DEBUG 01-06 17:11:01.116256.116256 lmp.py:414]   Expert 32 |    114 | CPU
DEBUG 01-06 17:11:01.116138.116138 lmp.py:414]   Expert 36 |    117 | CPU
DEBUG 01-06 17:11:01.116496.116496 lmp.py:414]   Expert  8 |    125 | CPU
DEBUG 01-06 17:11:01.116901.116901 lmp.py:414]   Expert 20 |    127 | CPU
DEBUG 01-06 17:11:01.116305.116305 lmp.py:414]   Expert 61 |    136 | CPU
DEBUG 01-06 17:11:01.116471.116471 lmp.py:414]   Expert 63 |    139 | CPU
DEBUG 01-06 17:11:01.116876.116876 lmp.py:414]   Expert  4 |    140 | CPU
DEBUG 01-06 17:11:01.116042.116042 lmp.py:414]   Expert 53 |    143 | CPU
DEBUG 01-06 17:11:01.116923.116923 lmp.py:414]   Expert 16 |    144 | CPU
DEBUG 01-06 17:11:01.116805.116805 lmp.py:414]   Expert 34 |    145 | CPU
DEBUG 01-06 17:11:01.116163.116163 lmp.py:414]   Expert 47 |    145 | CPU
DEBUG 01-06 17:11:01.116283.116283 lmp.py:414]   Expert 17 |    160 | CPU
DEBUG 01-06 17:11:01.116641.116641 lmp.py:414]   Expert 60 |    161 | CPU
DEBUG 01-06 17:11:01.116046.116046 lmp.py:414]   Expert 42 |    162 | CPU
DEBUG 01-06 17:11:01.116689.116689 lmp.py:414]   Expert 28 |    163 | CPU
DEBUG 01-06 17:11:01.116093.116093 lmp.py:414]   Expert 27 |    174 | CPU
DEBUG 01-06 17:11:01.116498.116498 lmp.py:414]   Expert 29 |    174 | CPU
DEBUG 01-06 17:11:01.116902.116902 lmp.py:414]   Expert 41 |    175 | CPU
DEBUG 01-06 17:11:01.116307.116307 lmp.py:414]   Expert  7 |    180 | CPU
DEBUG 01-06 17:11:01.116533.116533 lmp.py:414]   Expert 44 |    180 | CPU
DEBUG 01-06 17:11:01.116937.116937 lmp.py:414]   Expert 48 |    182 | GPU
DEBUG 01-06 17:11:01.116057.116057 lmp.py:414]   Expert 56 |    184 | GPU
DEBUG 01-06 17:11:01.116654.116654 lmp.py:414]   Expert  2 |    186 | GPU
DEBUG 01-06 17:11:01.116251.116251 lmp.py:414]   Expert  9 |    186 | GPU
DEBUG 01-06 17:11:01.116655.116655 lmp.py:414]   Expert  3 |    188 | GPU
DEBUG 01-06 17:11:01.116060.116060 lmp.py:414]   Expert 15 |    189 | GPU
DEBUG 01-06 17:11:01.116464.116464 lmp.py:414]   Expert 24 |    194 | GPU
DEBUG 01-06 17:11:01.116869.116869 lmp.py:414]   Expert  0 |    196 | GPU
DEBUG 01-06 17:11:01.116512.116512 lmp.py:414]   Expert 18 |    203 | GPU
DEBUG 01-06 17:11:01.116916.116916 lmp.py:414]   Expert 55 |    209 | GPU
DEBUG 01-06 17:11:01.116321.116321 lmp.py:414]   Expert 38 |    211 | GPU
DEBUG 01-06 17:11:01.116487.116487 lmp.py:414]   Expert 40 |    215 | GPU
DEBUG 01-06 17:11:01.116368.116368 lmp.py:414]   Expert 22 |    216 | GPU
DEBUG 01-06 17:11:01.116727.116727 lmp.py:414]   Expert  6 |    220 | GPU
DEBUG 01-06 17:11:01.116608.116608 lmp.py:414]   Expert 37 |    222 | GPU
DEBUG 01-06 17:11:01.116966.116966 lmp.py:414]   Expert 23 |    223 | GPU
DEBUG 01-06 17:11:01.116609.116609 lmp.py:414]   Expert 46 |    233 | GPU
DEBUG 01-06 17:11:01.116775.116775 lmp.py:414]   Expert 19 |    244 | GPU
DEBUG 01-06 17:11:01.116942.116942 lmp.py:414]   Expert 39 |    249 | GPU
DEBUG 01-06 17:11:01.116346.116346 lmp.py:414]   Expert 12 |    255 | GPU
DEBUG 01-06 17:11:01.116512.116512 lmp.py:414]   Expert 25 |    255 | GPU
DEBUG 01-06 17:11:01.116917.116917 lmp.py:414]   Expert 50 |    266 | GPU
DEBUG 01-06 17:11:01.116083.116083 lmp.py:414]   Expert 62 |    268 | GPU
DEBUG 01-06 17:11:01.116487.116487 lmp.py:414]   Expert 21 |    281 | GPU
DEBUG 01-06 17:11:01.116892.116892 lmp.py:414]   Expert 35 |    285 | GPU
DEBUG 01-06 17:11:01.116297.116297 lmp.py:414]   Expert 49 |    294 | GPU
DEBUG 01-06 17:11:01.116893.116893 lmp.py:414]   Expert 52 |    297 | GPU
DEBUG 01-06 17:11:01.116775.116775 lmp.py:414]   Expert 33 |    298 | GPU
DEBUG 01-06 17:11:01.116894.116894 lmp.py:414]   Expert  1 |    347 | GPU
DEBUG 01-06 17:11:01.116253.116253 lmp.py:414]   Expert  5 |    381 | GPU
DEBUG 01-06 17:11:01.116896.116896 lmp.py:414]   Expert 43 |    436 | GPU
DEBUG 01-06 17:11:01.116539.116539 lmp.py:414]   Expert 59 |    580 | GPU
DEBUG 01-06 17:11:01.116897.116897 lmp.py:415] 
DEBUG 01-06 17:11:01.116897.116897 lmp.py:415]   CPU total tokens: 4095 (33.3%)
DEBUG 01-06 17:11:01.117255.117255 lmp.py:416]   GPU total tokens: 8193 (66.7%)
DEBUG 01-06 17:11:01.117143.117143 cuda_h.py:19] end experts_map_get cost 0.0015931129455566406 seconds
DEBUG 01-06 17:11:01.117978.117978 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-06 17:11:01.117232.117232 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 17:11:01.117792.117792 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 17:11:01.118508.118508 cuda_h.py:19] end allocate_cuda_memory cost 0.0013709068298339844 seconds
DEBUG 01-06 17:11:01.118557.118557 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 17:11:01.118743.118743 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 17:11:01.118314.118314 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 17:11:01.118679.118679 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, b4ea8b88-82a3-42e0-894c-6ca8fd705864
DEBUG 01-06 17:11:01.118811.118811 client.py:106] call stub.LoadModelAsync
INFO 01-06 17:11:01.120743.120743 client.py:127] Model loaded
DEBUG 01-06 17:11:01.121039.121039 cuda_h.py:19] end sllm_worker_task cost 0.010954141616821289 seconds
INFO 01-06 17:11:01.121133.121133 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, b4ea8b88-82a3-42e0-894c-6ca8fd705864
DEBUG 01-06 17:11:01.121029.121029 cuda_h.py:19] end load_into_gpu_async cost 0.0031926631927490234 seconds
DEBUG 01-06 17:11:01.121308.121308 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 17:11:01.122086.122086 cuda_h.py:19] end restore_tensors2 cost 0.00026607513427734375 seconds
DEBUG 01-06 17:11:01.122763.122763 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.005177974700927734 seconds
DEBUG 01-06 17:11:01.124263.124263 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.007869958877563477 seconds
DEBUG 01-06 17:11:01.125668.125668 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-06 17:11:01.125300.125300 lmp.py:461] 
DEBUG 01-06 17:11:01.125300.125300 lmp.py:461]   Computing 32 experts on CPU...
DEBUG 01-06 17:11:01.125335.125335 cuda_h.py:19] end cpu_experts_submit cost 0.00011086463928222656 seconds
DEBUG 01-06 17:11:01.125846.125846 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-06 17:11:01.130519.130519 mlpmodule.py:706] group tensors cost 0.005534648895263672 s
DEBUG 01-06 17:11:01.133127.133127 mlpmodule.py:744] pad cost 0.0019409656524658203 s
DEBUG 01-06 17:11:01.133952.133952 mlpmodule.py:750] create cpu tensor cost 4.6253204345703125e-05 s
DEBUG 01-06 17:11:01.133590.133590 mlpmodule.py:755] move to cpu cost 3.695487976074219e-05 s
DEBUG 01-06 17:11:01.142980.142980 mlpmodule.py:769] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-06 17:11:01.143270.143270 mlpmodule.py:770] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-06 17:11:01.143658.143658 mlpmodule.py:775] group_w3 first element: 0.0086669921875
WARNING 01-06 17:11:01.143788.143788 mlpmodule.py:785] start einsum2
DEBUG 01-06 17:11:01.159167.159167 mlpmodule.py:795] group einsum cost 0.02603936195373535 s
DEBUG 01-06 17:11:01.160269.160269 mlpmodule.py:803] cpy2cputensor cost 0.0008549690246582031 s
DEBUG 01-06 17:11:01.165134.165134 cuda_h.py:19] end wait_cetm_experts cost 0.04039812088012695 seconds
DEBUG 01-06 17:11:01.165999.165999 cuda_h.py:10] start gpu_sexperts
DEBUG 01-06 17:11:01.166714.166714 cuda_h.py:19] end gpu_sexperts cost 0.0005354881286621094 seconds
DEBUG 01-06 17:11:01.166943.166943 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-06 17:11:01.166482.166482 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.4318695068359375e-05 seconds
DEBUG 01-06 17:11:01.166344.166344 cuda_h.py:10] start wait_experts
INFO 01-06 17:11:01.166723.166723 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, b4ea8b88-82a3-42e0-894c-6ca8fd705864
INFO 01-06 17:11:01.173372.173372 client.py:127] Model loaded
DEBUG 01-06 17:11:01.174508.174508 cuda_h.py:19] end wait_experts cost 0.007424116134643555 seconds
DEBUG 01-06 17:11:01.174430.174430 cuda_h.py:10] start gpu_experts
DEBUG 01-06 17:11:01.174160.174160 lmp.py:506]   Computing 32 experts on GPU...
DEBUG 01-06 17:11:01.174907.174907 mlpmodule.py:533] gpu group tensors cost 0.000667572021484375 s
DEBUG 01-06 17:11:01.178697.178697 mlpmodule.py:664]  experts func einsum cost 0.053574323654174805 s
DEBUG 01-06 17:11:01.180705.180705 mlpmodule.py:566] gpu pad cost 0.00533294677734375 s
DEBUG 01-06 17:11:01.181673.181673 mlpmodule.py:584] gpu group einsum cost 0.0007355213165283203 s
DEBUG 01-06 17:11:01.183774.183774 mlpmodule.py:613] gpu experts func einsum cost 0.009734630584716797 s
DEBUG 01-06 17:11:01.184526.184526 cuda_h.py:19] end gpu_experts cost 0.009927749633789062 seconds
DEBUG 01-06 17:11:01.184833.184833 cuda_h.py:19] end layer_moe_generate_4 cost 0.06944656372070312 seconds
DEBUG 01-06 17:11:01.184381.184381 lmp.py:220] -------------------------------- end layer 4 --------------------------------
DEBUG 01-06 17:11:01.184714.184714 lmp.py:176] -------------------------------- start layer 5 --------------------------------
DEBUG 01-06 17:11:01.184648.184648 cuda_h.py:10] start start_load_qkvogn_s_weight_l_6
DEBUG 01-06 17:11:01.184881.184881 cuda_h.py:10] start start_load_qkvogn_s_weight_l_6
DEBUG 01-06 17:11:01.184665.184665 cuda_h.py:19] end start_load_qkvogn_s_weight_l_6 cost 5.602836608886719e-05 seconds
DEBUG 01-06 17:11:01.184898.184898 cuda_h.py:19] end start_load_qkvogn_s_weight_l_6 cost 9.560585021972656e-05 seconds
DEBUG 01-06 17:11:01.184641.184641 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-06 17:11:01.184550.184550 mlpmodule.py:367] cuda:1 cuda:1
DEBUG 01-06 17:11:01.184599.184599 cuda_h.py:10] start sllm_worker_task
DEBUG 01-06 17:11:01.184576.184576 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 17:11:01.184002.184002 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 17:11:01.185559.185559 cuda_h.py:19] end allocate_cuda_memory cost 0.0001971721649169922 seconds
DEBUG 01-06 17:11:01.185601.185601 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 17:11:01.185549.185549 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 17:11:01.185657.185657 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 17:11:01.185406.185406 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, af108264-dbdd-422b-a519-8d853a65ec9d
DEBUG 01-06 17:11:01.185184.185184 client.py:106] call stub.LoadModelAsync
DEBUG 01-06 17:11:01.185178.185178 cuda_h.py:10] start self_attn
INFO 01-06 17:11:01.186984.186984 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, af108264-dbdd-422b-a519-8d853a65ec9d
DEBUG 01-06 17:11:01.186788.186788 cuda_h.py:19] end load_into_gpu_async cost 0.0015773773193359375 seconds
DEBUG 01-06 17:11:01.186974.186974 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 17:11:01.186170.186170 cuda_h.py:19] end restore_tensors2 cost 7.510185241699219e-05 seconds
DEBUG 01-06 17:11:01.186046.186046 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0021228790283203125 seconds
INFO 01-06 17:11:01.186981.186981 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, af108264-dbdd-422b-a519-8d853a65ec9d
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-06 17:11:01.188620.188620 cuda_h.py:19] end self_attn cost 0.0030269622802734375 seconds
DEBUG 01-06 17:11:01.188319.188319 cuda_h.py:19] end iln_self_attn_paln cost 0.004400968551635742 seconds
DEBUG 01-06 17:11:01.188977.188977 cuda_h.py:10] start layer_moe_generate_5
DEBUG 01-06 17:11:01.189461.189461 cuda_h.py:10] start gate
DEBUG 01-06 17:11:01.189829.189829 cuda_h.py:19] end gate cost 0.0006558895111083984 seconds
DEBUG 01-06 17:11:01.189897.189897 cuda_h.py:10] start experts_map_get
DEBUG 01-06 17:11:01.190714.190714 lmp.py:403] 
DEBUG 01-06 17:11:01.190714.190714 lmp.py:403] Expert Token Distribution & Device Allocation:
DEBUG 01-06 17:11:01.190477.190477 lmp.py:404]   Total experts: 64
DEBUG 01-06 17:11:01.190081.190081 lmp.py:405]   CPU experts: 32 (50%)
DEBUG 01-06 17:11:01.190346.190346 lmp.py:406]   GPU experts: 32 (50%)
DEBUG 01-06 17:11:01.190274.190274 lmp.py:407] 
DEBUG 01-06 17:11:01.190274.190274 lmp.py:407]   Expert ID | Tokens | Device
DEBUG 01-06 17:11:01.190679.190679 lmp.py:408]   -----------------------------------
DEBUG 01-06 17:11:01.190997.190997 lmp.py:414]   Expert 34 |     23 | CPU
DEBUG 01-06 17:11:01.190409.190409 lmp.py:414]   Expert 45 |     61 | CPU
DEBUG 01-06 17:11:01.190290.190290 lmp.py:414]   Expert 22 |     73 | CPU
DEBUG 01-06 17:11:01.190171.190171 lmp.py:414]   Expert 57 |     77 | CPU
DEBUG 01-06 17:11:01.190576.190576 lmp.py:414]   Expert 17 |     97 | CPU
DEBUG 01-06 17:11:01.190981.190981 lmp.py:414]   Expert  4 |    101 | CPU
DEBUG 01-06 17:11:01.190577.190577 lmp.py:414]   Expert 15 |    101 | CPU
DEBUG 01-06 17:11:01.190982.190982 lmp.py:414]   Expert 28 |    107 | CPU
DEBUG 01-06 17:11:01.190148.190148 lmp.py:414]   Expert 32 |    114 | CPU
DEBUG 01-06 17:11:01.190552.190552 lmp.py:414]   Expert 60 |    119 | CPU
DEBUG 01-06 17:11:01.190480.190480 lmp.py:414]   Expert 52 |    122 | CPU
DEBUG 01-06 17:11:01.190646.190646 lmp.py:414]   Expert 36 |    126 | CPU
DEBUG 01-06 17:11:01.190727.190727 lmp.py:414]   Expert 12 |    128 | CPU
DEBUG 01-06 17:11:01.190615.190615 lmp.py:414]   Expert 14 |    128 | CPU
DEBUG 01-06 17:11:01.190735.190735 lmp.py:414]   Expert 16 |    132 | CPU
DEBUG 01-06 17:11:01.190616.190616 lmp.py:414]   Expert 25 |    132 | CPU
DEBUG 01-06 17:11:01.190259.190259 lmp.py:414]   Expert  2 |    139 | CPU
DEBUG 01-06 17:11:01.190856.190856 lmp.py:414]   Expert  8 |    139 | CPU
DEBUG 01-06 17:11:01.190022.190022 lmp.py:414]   Expert  5 |    141 | CPU
DEBUG 01-06 17:11:01.190380.190380 lmp.py:414]   Expert 35 |    144 | CPU
DEBUG 01-06 17:11:01.190546.190546 lmp.py:414]   Expert 61 |    153 | CPU
DEBUG 01-06 17:11:01.190712.190712 lmp.py:414]   Expert 30 |    156 | CPU
DEBUG 01-06 17:11:01.190878.190878 lmp.py:414]   Expert 23 |    158 | CPU
DEBUG 01-06 17:11:01.190044.190044 lmp.py:414]   Expert  0 |    159 | CPU
DEBUG 01-06 17:11:01.190449.190449 lmp.py:414]   Expert 39 |    159 | CPU
DEBUG 01-06 17:11:01.190377.190377 lmp.py:414]   Expert 42 |    165 | CPU
DEBUG 01-06 17:11:01.190258.190258 lmp.py:414]   Expert 13 |    168 | CPU
DEBUG 01-06 17:11:01.190908.190908 lmp.py:414]   Expert 44 |    172 | CPU
DEBUG 01-06 17:11:01.190743.190743 lmp.py:414]   Expert  3 |    174 | CPU
DEBUG 01-06 17:11:01.190101.190101 lmp.py:414]   Expert 31 |    174 | CPU
DEBUG 01-06 17:11:01.190744.190744 lmp.py:414]   Expert 46 |    175 | CPU
DEBUG 01-06 17:11:01.190387.190387 lmp.py:414]   Expert  9 |    177 | CPU
DEBUG 01-06 17:11:01.190269.190269 lmp.py:414]   Expert 41 |    178 | GPU
DEBUG 01-06 17:11:01.190196.190196 lmp.py:414]   Expert 43 |    184 | GPU
DEBUG 01-06 17:11:01.190336.190336 lmp.py:414]   Expert 27 |    186 | GPU
DEBUG 01-06 17:11:01.190979.190979 lmp.py:414]   Expert 26 |    189 | GPU
DEBUG 01-06 17:11:01.190384.190384 lmp.py:414]   Expert 62 |    191 | GPU
DEBUG 01-06 17:11:01.190550.190550 lmp.py:414]   Expert 51 |    193 | GPU
DEBUG 01-06 17:11:01.190392.190392 lmp.py:414]   Expert 49 |    196 | GPU
DEBUG 01-06 17:11:01.190465.190465 lmp.py:414]   Expert 18 |    197 | GPU
DEBUG 01-06 17:11:01.190108.190108 lmp.py:414]   Expert 50 |    197 | GPU
DEBUG 01-06 17:11:01.190705.190705 lmp.py:414]   Expert 11 |    199 | GPU
DEBUG 01-06 17:11:01.190586.190586 lmp.py:414]   Expert 47 |    200 | GPU
DEBUG 01-06 17:11:01.191229.191229 lmp.py:414]   Expert 20 |    201 | GPU
DEBUG 01-06 17:11:01.191111.191111 lmp.py:414]   Expert 19 |    203 | GPU
DEBUG 01-06 17:11:01.191515.191515 lmp.py:414]   Expert 55 |    209 | GPU
DEBUG 01-06 17:11:01.191158.191158 lmp.py:414]   Expert 56 |    210 | GPU
DEBUG 01-06 17:11:01.191563.191563 lmp.py:414]   Expert 63 |    210 | GPU
DEBUG 01-06 17:11:01.191729.191729 lmp.py:414]   Expert 38 |    217 | GPU
DEBUG 01-06 17:11:01.191134.191134 lmp.py:414]   Expert 48 |    219 | GPU
DEBUG 01-06 17:11:01.191777.191777 lmp.py:414]   Expert  1 |    236 | GPU
DEBUG 01-06 17:11:01.191181.191181 lmp.py:414]   Expert 10 |    241 | GPU
DEBUG 01-06 17:11:01.191586.191586 lmp.py:414]   Expert 54 |    246 | GPU
DEBUG 01-06 17:11:01.191659.191659 lmp.py:414]   Expert  7 |    248 | GPU
DEBUG 01-06 17:11:01.191024.191024 lmp.py:414]   Expert 33 |    255 | GPU
DEBUG 01-06 17:11:01.191859.191859 lmp.py:414]   Expert 21 |    256 | GPU
DEBUG 01-06 17:11:01.191979.191979 lmp.py:414]   Expert 29 |    260 | GPU
DEBUG 01-06 17:11:01.191576.191576 lmp.py:414]   Expert 40 |    260 | GPU
DEBUG 01-06 17:11:01.191411.191411 lmp.py:414]   Expert 24 |    265 | GPU
DEBUG 01-06 17:11:01.191815.191815 lmp.py:414]   Expert 59 |    297 | GPU
DEBUG 01-06 17:11:01.191458.191458 lmp.py:414]   Expert 37 |    331 | GPU
DEBUG 01-06 17:11:01.191863.191863 lmp.py:414]   Expert 58 |    374 | GPU
DEBUG 01-06 17:11:01.191267.191267 lmp.py:414]   Expert  6 |    385 | GPU
DEBUG 01-06 17:11:01.191910.191910 lmp.py:414]   Expert 53 |    861 | GPU
DEBUG 01-06 17:11:01.191030.191030 lmp.py:415] 
DEBUG 01-06 17:11:01.191030.191030 lmp.py:415]   CPU total tokens: 4194 (34.1%)
DEBUG 01-06 17:11:01.191104.191104 lmp.py:416]   GPU total tokens: 8094 (65.9%)
DEBUG 01-06 17:11:01.191191.191191 cuda_h.py:19] end experts_map_get cost 0.0016262531280517578 seconds
DEBUG 01-06 17:11:01.191410.191410 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-06 17:11:01.191908.191908 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 17:11:01.191920.191920 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 17:11:01.192691.192691 cuda_h.py:19] end allocate_cuda_memory cost 0.0012302398681640625 seconds
DEBUG 01-06 17:11:01.192025.192025 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 17:11:01.193403.193403 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 17:11:01.193312.193312 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 17:11:01.193346.193346 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 9c4bad3c-6d5d-47d8-b4b0-598d1b663e3b
DEBUG 01-06 17:11:01.193053.193053 client.py:106] call stub.LoadModelAsync
INFO 01-06 17:11:01.194118.194118 client.py:127] Model loaded
DEBUG 01-06 17:11:01.195789.195789 cuda_h.py:19] end sllm_worker_task cost 0.01033926010131836 seconds
INFO 01-06 17:11:01.196566.196566 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 9c4bad3c-6d5d-47d8-b4b0-598d1b663e3b
DEBUG 01-06 17:11:01.196223.196223 cuda_h.py:19] end load_into_gpu_async cost 0.0031304359436035156 seconds
DEBUG 01-06 17:11:01.196641.196641 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 17:11:01.196778.196778 cuda_h.py:19] end restore_tensors2 cost 0.0002841949462890625 seconds
DEBUG 01-06 17:11:01.196415.196415 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.005017995834350586 seconds
DEBUG 01-06 17:11:01.199819.199819 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.007640361785888672 seconds
DEBUG 01-06 17:11:01.199271.199271 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-06 17:11:01.199116.199116 lmp.py:461] 
DEBUG 01-06 17:11:01.199116.199116 lmp.py:461]   Computing 32 experts on CPU...
DEBUG 01-06 17:11:01.199767.199767 cuda_h.py:19] end cpu_experts_submit cost 0.00010943412780761719 seconds
DEBUG 01-06 17:11:01.199085.199085 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-06 17:11:01.209079.209079 mlpmodule.py:706] group tensors cost 0.01035451889038086 s
DEBUG 01-06 17:11:01.211998.211998 mlpmodule.py:744] pad cost 0.001476287841796875 s
DEBUG 01-06 17:11:01.212034.212034 mlpmodule.py:750] create cpu tensor cost 3.910064697265625e-05 s
DEBUG 01-06 17:11:01.212076.212076 mlpmodule.py:755] move to cpu cost 2.9325485229492188e-05 s
DEBUG 01-06 17:11:01.221129.221129 mlpmodule.py:769] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-06 17:11:01.221413.221413 mlpmodule.py:770] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-06 17:11:01.221563.221563 mlpmodule.py:775] group_w3 first element: 0.03369140625
WARNING 01-06 17:11:01.221475.221475 mlpmodule.py:785] start einsum2
DEBUG 01-06 17:11:01.238667.238667 mlpmodule.py:795] group einsum cost 0.026653766632080078 s
DEBUG 01-06 17:11:01.239274.239274 mlpmodule.py:803] cpy2cputensor cost 0.0007336139678955078 s
DEBUG 01-06 17:11:01.244499.244499 cuda_h.py:19] end wait_cetm_experts cost 0.04534316062927246 seconds
DEBUG 01-06 17:11:01.244959.244959 cuda_h.py:10] start gpu_sexperts
DEBUG 01-06 17:11:01.245017.245017 cuda_h.py:19] end gpu_sexperts cost 0.00048828125 seconds
DEBUG 01-06 17:11:01.245681.245681 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-06 17:11:01.245008.245008 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.4318695068359375e-05 seconds
DEBUG 01-06 17:11:01.245810.245810 cuda_h.py:10] start wait_experts
INFO 01-06 17:11:01.245805.245805 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 9c4bad3c-6d5d-47d8-b4b0-598d1b663e3b
INFO 01-06 17:11:01.247183.247183 client.py:127] Model loaded
DEBUG 01-06 17:11:01.247840.247840 cuda_h.py:19] end wait_experts cost 0.0018510818481445312 seconds
DEBUG 01-06 17:11:01.247974.247974 cuda_h.py:10] start gpu_experts
DEBUG 01-06 17:11:01.247352.247352 lmp.py:506]   Computing 32 experts on GPU...
DEBUG 01-06 17:11:01.248363.248363 mlpmodule.py:533] gpu group tensors cost 0.0006299018859863281 s
DEBUG 01-06 17:11:01.256132.256132 mlpmodule.py:566] gpu pad cost 0.008643150329589844 s
DEBUG 01-06 17:11:01.260189.260189 mlpmodule.py:664]  experts func einsum cost 0.060901641845703125 s
DEBUG 01-06 17:11:01.260130.260130 mlpmodule.py:584] gpu group einsum cost 0.0038106441497802734 s
DEBUG 01-06 17:11:01.263515.263515 mlpmodule.py:613] gpu experts func einsum cost 0.01605057716369629 s
DEBUG 01-06 17:11:01.263882.263882 cuda_h.py:19] end gpu_experts cost 0.016232013702392578 seconds
DEBUG 01-06 17:11:01.263283.263283 cuda_h.py:19] end layer_moe_generate_5 cost 0.07476806640625 seconds
DEBUG 01-06 17:11:01.263778.263778 lmp.py:220] -------------------------------- end layer 5 --------------------------------
DEBUG 01-06 17:11:01.263633.263633 lmp.py:176] -------------------------------- start layer 6 --------------------------------
DEBUG 01-06 17:11:01.264376.264376 cuda_h.py:10] start start_load_qkvogn_s_weight_l_7
DEBUG 01-06 17:11:01.264085.264085 cuda_h.py:10] start start_load_qkvogn_s_weight_l_7
DEBUG 01-06 17:11:01.264280.264280 cuda_h.py:19] end start_load_qkvogn_s_weight_l_7 cost 4.410743713378906e-05 seconds
DEBUG 01-06 17:11:01.264221.264221 cuda_h.py:19] end start_load_qkvogn_s_weight_l_7 cost 7.772445678710938e-05 seconds
DEBUG 01-06 17:11:01.264964.264964 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-06 17:11:01.264304.264304 mlpmodule.py:367] cuda:1 cuda:1
DEBUG 01-06 17:11:01.264584.264584 cuda_h.py:10] start sllm_worker_task
DEBUG 01-06 17:11:01.264866.264866 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 17:11:01.264338.264338 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 17:11:01.264412.264412 cuda_h.py:19] end allocate_cuda_memory cost 0.00019502639770507812 seconds
DEBUG 01-06 17:11:01.264190.264190 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 17:11:01.264522.264522 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 17:11:01.264437.264437 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 17:11:01.264663.264663 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, af45683f-2135-4c3a-856d-a83f281279f9
DEBUG 01-06 17:11:01.264772.264772 client.py:106] call stub.LoadModelAsync
DEBUG 01-06 17:11:01.265223.265223 cuda_h.py:10] start self_attn
INFO 01-06 17:11:01.266706.266706 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, af45683f-2135-4c3a-856d-a83f281279f9
DEBUG 01-06 17:11:01.266304.266304 cuda_h.py:19] end load_into_gpu_async cost 0.0015935897827148438 seconds
DEBUG 01-06 17:11:01.266338.266338 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 17:11:01.266083.266083 cuda_h.py:19] end restore_tensors2 cost 6.604194641113281e-05 seconds
DEBUG 01-06 17:11:01.266408.266408 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0021080970764160156 seconds
INFO 01-06 17:11:01.266675.266675 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, af45683f-2135-4c3a-856d-a83f281279f9
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-06 17:11:01.268249.268249 cuda_h.py:19] end self_attn cost 0.00286865234375 seconds
DEBUG 01-06 17:11:01.268889.268889 cuda_h.py:19] end iln_self_attn_paln cost 0.00426936149597168 seconds
DEBUG 01-06 17:11:01.268355.268355 cuda_h.py:10] start layer_moe_generate_6
DEBUG 01-06 17:11:01.268263.268263 cuda_h.py:10] start gate
DEBUG 01-06 17:11:01.269048.269048 cuda_h.py:19] end gate cost 0.000644683837890625 seconds
DEBUG 01-06 17:11:01.269831.269831 cuda_h.py:10] start experts_map_get
DEBUG 01-06 17:11:01.269079.269079 lmp.py:403] 
DEBUG 01-06 17:11:01.269079.269079 lmp.py:403] Expert Token Distribution & Device Allocation:
DEBUG 01-06 17:11:01.269073.269073 lmp.py:404]   Total experts: 64
DEBUG 01-06 17:11:01.269438.269438 lmp.py:405]   CPU experts: 32 (50%)
DEBUG 01-06 17:11:01.269466.269466 lmp.py:406]   GPU experts: 32 (50%)
DEBUG 01-06 17:11:01.269870.269870 lmp.py:407] 
DEBUG 01-06 17:11:01.269870.269870 lmp.py:407]   Expert ID | Tokens | Device
DEBUG 01-06 17:11:01.269275.269275 lmp.py:408]   -----------------------------------
DEBUG 01-06 17:11:01.269878.269878 lmp.py:414]   Expert  1 |     46 | CPU
DEBUG 01-06 17:11:01.269998.269998 lmp.py:414]   Expert  7 |     58 | CPU
DEBUG 01-06 17:11:01.269926.269926 lmp.py:414]   Expert 37 |     71 | CPU
DEBUG 01-06 17:11:01.269377.269377 lmp.py:414]   Expert 18 |     79 | CPU
DEBUG 01-06 17:11:01.269066.269066 lmp.py:414]   Expert 54 |     79 | CPU
DEBUG 01-06 17:11:01.269232.269232 lmp.py:414]   Expert 17 |     85 | CPU
DEBUG 01-06 17:11:01.269637.269637 lmp.py:414]   Expert 13 |     94 | CPU
DEBUG 01-06 17:11:01.269756.269756 lmp.py:414]   Expert  9 |     96 | CPU
DEBUG 01-06 17:11:01.269684.269684 lmp.py:414]   Expert 58 |     98 | CPU
DEBUG 01-06 17:11:01.269373.269373 lmp.py:414]   Expert  0 |    103 | CPU
DEBUG 01-06 17:11:01.269586.269586 lmp.py:414]   Expert 22 |    103 | CPU
DEBUG 01-06 17:11:01.269275.269275 lmp.py:414]   Expert 16 |    116 | CPU
DEBUG 01-06 17:11:01.269726.269726 lmp.py:414]   Expert 26 |    120 | CPU
DEBUG 01-06 17:11:01.269084.269084 lmp.py:414]   Expert 10 |    124 | CPU
DEBUG 01-06 17:11:01.269727.269727 lmp.py:414]   Expert 63 |    129 | CPU
DEBUG 01-06 17:11:01.269370.269370 lmp.py:414]   Expert 59 |    135 | CPU
DEBUG 01-06 17:11:01.269775.269775 lmp.py:414]   Expert 43 |    141 | CPU
DEBUG 01-06 17:11:01.270610.270610 lmp.py:414]   Expert 33 |    145 | CPU
DEBUG 01-06 17:11:01.270014.270014 lmp.py:414]   Expert 62 |    145 | CPU
DEBUG 01-06 17:11:01.270657.270657 lmp.py:414]   Expert 28 |    147 | CPU
DEBUG 01-06 17:11:01.270062.270062 lmp.py:414]   Expert 29 |    159 | CPU
DEBUG 01-06 17:11:01.270466.270466 lmp.py:414]   Expert 51 |    159 | CPU
DEBUG 01-06 17:11:01.270109.270109 lmp.py:414]   Expert  2 |    160 | CPU
DEBUG 01-06 17:11:01.270514.270514 lmp.py:414]   Expert 55 |    162 | CPU
DEBUG 01-06 17:11:01.270680.270680 lmp.py:414]   Expert  3 |    163 | CPU
DEBUG 01-06 17:11:01.270846.270846 lmp.py:414]   Expert 32 |    167 | CPU
DEBUG 01-06 17:11:01.270012.270012 lmp.py:414]   Expert 11 |    168 | CPU
DEBUG 01-06 17:11:01.270417.270417 lmp.py:414]   Expert 23 |    169 | CPU
DEBUG 01-06 17:11:01.270398.270398 lmp.py:414]   Expert 14 |    171 | CPU
DEBUG 01-06 17:11:01.270326.270326 lmp.py:414]   Expert 40 |    171 | CPU
DEBUG 01-06 17:11:01.270015.270015 lmp.py:414]   Expert 45 |    171 | CPU
DEBUG 01-06 17:11:01.270227.270227 lmp.py:414]   Expert 53 |    172 | CPU
DEBUG 01-06 17:11:01.270678.270678 lmp.py:414]   Expert 34 |    175 | GPU
DEBUG 01-06 17:11:01.270129.270129 lmp.py:414]   Expert 52 |    178 | GPU
DEBUG 01-06 17:11:01.270295.270295 lmp.py:414]   Expert 42 |    180 | GPU
DEBUG 01-06 17:11:01.270461.270461 lmp.py:414]   Expert 41 |    181 | GPU
DEBUG 01-06 17:11:01.270674.270674 lmp.py:414]   Expert 21 |    189 | GPU
DEBUG 01-06 17:11:01.270125.270125 lmp.py:414]   Expert 15 |    192 | GPU
DEBUG 01-06 17:11:01.270337.270337 lmp.py:414]   Expert 57 |    192 | GPU
DEBUG 01-06 17:11:01.270788.270788 lmp.py:414]   Expert 30 |    200 | GPU
DEBUG 01-06 17:11:01.270239.270239 lmp.py:414]   Expert 35 |    209 | GPU
DEBUG 01-06 17:11:01.270690.270690 lmp.py:414]   Expert 12 |    216 | GPU
DEBUG 01-06 17:11:01.270141.270141 lmp.py:414]   Expert  4 |    218 | GPU
DEBUG 01-06 17:11:01.270353.270353 lmp.py:414]   Expert 24 |    229 | GPU
DEBUG 01-06 17:11:01.270281.270281 lmp.py:414]   Expert 50 |    229 | GPU
DEBUG 01-06 17:11:01.270685.270685 lmp.py:414]   Expert 46 |    231 | GPU
DEBUG 01-06 17:11:01.270613.270613 lmp.py:414]   Expert 49 |    232 | GPU
DEBUG 01-06 17:11:01.270302.270302 lmp.py:414]   Expert  8 |    233 | GPU
DEBUG 01-06 17:11:01.270753.270753 lmp.py:414]   Expert 19 |    233 | GPU
DEBUG 01-06 17:11:01.270204.270204 lmp.py:414]   Expert 44 |    237 | GPU
DEBUG 01-06 17:11:01.270655.270655 lmp.py:414]   Expert 38 |    239 | GPU
DEBUG 01-06 17:11:01.270106.270106 lmp.py:414]   Expert  6 |    246 | GPU
DEBUG 01-06 17:11:01.270795.270795 lmp.py:414]   Expert 31 |    249 | GPU
DEBUG 01-06 17:11:01.270008.270008 lmp.py:414]   Expert 47 |    249 | GPU
DEBUG 01-06 17:11:01.270174.270174 lmp.py:414]   Expert 61 |    251 | GPU
DEBUG 01-06 17:11:01.270102.270102 lmp.py:414]   Expert 39 |    277 | GPU
DEBUG 01-06 17:11:01.270791.270791 lmp.py:414]   Expert 36 |    302 | GPU
DEBUG 01-06 17:11:01.270242.270242 lmp.py:414]   Expert  5 |    303 | GPU
DEBUG 01-06 17:11:01.270693.270693 lmp.py:414]   Expert 27 |    307 | GPU
DEBUG 01-06 17:11:01.270144.270144 lmp.py:414]   Expert 60 |    332 | GPU
DEBUG 01-06 17:11:01.270833.270833 lmp.py:414]   Expert 20 |    341 | GPU
DEBUG 01-06 17:11:01.270284.270284 lmp.py:414]   Expert 48 |    375 | GPU
DEBUG 01-06 17:11:01.270496.270496 lmp.py:414]   Expert 25 |    396 | GPU
DEBUG 01-06 17:11:01.270662.270662 lmp.py:414]   Expert 56 |    561 | GPU
DEBUG 01-06 17:11:01.270782.270782 lmp.py:415] 
DEBUG 01-06 17:11:01.270782.270782 lmp.py:415]   CPU total tokens: 4106 (33.4%)
DEBUG 01-06 17:11:01.270425.270425 lmp.py:416]   GPU total tokens: 8182 (66.6%)
DEBUG 01-06 17:11:01.270121.270121 cuda_h.py:19] end experts_map_get cost 0.0015189647674560547 seconds
DEBUG 01-06 17:11:01.270764.270764 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-06 17:11:01.270779.270779 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 17:11:01.271432.271432 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 17:11:01.272424.272424 cuda_h.py:19] end allocate_cuda_memory cost 0.001505136489868164 seconds
DEBUG 01-06 17:11:01.272367.272367 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 17:11:01.272838.272838 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 17:11:01.272031.272031 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 17:11:01.272588.272588 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 180ebda7-047c-4a57-8716-6579839b5b5a
DEBUG 01-06 17:11:01.272197.272197 client.py:106] call stub.LoadModelAsync
INFO 01-06 17:11:01.274826.274826 client.py:127] Model loaded
DEBUG 01-06 17:11:01.274411.274411 cuda_h.py:19] end sllm_worker_task cost 0.010338544845581055 seconds
INFO 01-06 17:11:01.275282.275282 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 180ebda7-047c-4a57-8716-6579839b5b5a
DEBUG 01-06 17:11:01.276460.276460 cuda_h.py:19] end load_into_gpu_async cost 0.0033054351806640625 seconds
DEBUG 01-06 17:11:01.276337.276337 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 17:11:01.276730.276730 cuda_h.py:19] end restore_tensors2 cost 0.00039887428283691406 seconds
DEBUG 01-06 17:11:01.276599.276599 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.005673885345458984 seconds
DEBUG 01-06 17:11:01.279604.279604 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.008242368698120117 seconds
DEBUG 01-06 17:11:01.279547.279547 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-06 17:11:01.279509.279509 lmp.py:461] 
DEBUG 01-06 17:11:01.279509.279509 lmp.py:461]   Computing 32 experts on CPU...
DEBUG 01-06 17:11:01.279498.279498 cuda_h.py:19] end cpu_experts_submit cost 0.00010776519775390625 seconds
DEBUG 01-06 17:11:01.279553.279553 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-06 17:11:01.289786.289786 mlpmodule.py:706] group tensors cost 0.009796380996704102 s
DEBUG 01-06 17:11:01.291050.291050 mlpmodule.py:744] pad cost 0.0015146732330322266 s
DEBUG 01-06 17:11:01.291690.291690 mlpmodule.py:750] create cpu tensor cost 5.459785461425781e-05 s
DEBUG 01-06 17:11:01.291586.291586 mlpmodule.py:755] move to cpu cost 2.956390380859375e-05 s
DEBUG 01-06 17:11:01.300306.300306 mlpmodule.py:769] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-06 17:11:01.300557.300557 mlpmodule.py:770] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-06 17:11:01.300230.300230 mlpmodule.py:775] group_w3 first element: -0.003631591796875
WARNING 01-06 17:11:01.301837.301837 mlpmodule.py:785] start einsum2
DEBUG 01-06 17:11:01.318454.318454 mlpmodule.py:795] group einsum cost 0.027025222778320312 s
DEBUG 01-06 17:11:01.319585.319585 mlpmodule.py:803] cpy2cputensor cost 0.0007309913635253906 s
DEBUG 01-06 17:11:01.324616.324616 cuda_h.py:19] end wait_cetm_experts cost 0.045154571533203125 seconds
DEBUG 01-06 17:11:01.324792.324792 cuda_h.py:10] start gpu_sexperts
DEBUG 01-06 17:11:01.325648.325648 cuda_h.py:19] end gpu_sexperts cost 0.0005693435668945312 seconds
DEBUG 01-06 17:11:01.325300.325300 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-06 17:11:01.325932.325932 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.5987625122070312e-05 seconds
DEBUG 01-06 17:11:01.325542.325542 cuda_h.py:10] start wait_experts
INFO 01-06 17:11:01.325219.325219 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 180ebda7-047c-4a57-8716-6579839b5b5a
INFO 01-06 17:11:01.327960.327960 client.py:127] Model loaded
DEBUG 01-06 17:11:01.327751.327751 cuda_h.py:19] end wait_experts cost 0.0016658306121826172 seconds
DEBUG 01-06 17:11:01.327713.327713 cuda_h.py:10] start gpu_experts
DEBUG 01-06 17:11:01.327661.327661 lmp.py:506]   Computing 32 experts on GPU...
DEBUG 01-06 17:11:01.328694.328694 mlpmodule.py:533] gpu group tensors cost 0.0007159709930419922 s
DEBUG 01-06 17:11:01.329671.329671 mlpmodule.py:566] gpu pad cost 0.0017888545989990234 s
DEBUG 01-06 17:11:01.330676.330676 mlpmodule.py:584] gpu group einsum cost 0.0006153583526611328 s
DEBUG 01-06 17:11:01.334603.334603 mlpmodule.py:613] gpu experts func einsum cost 0.006897687911987305 s
DEBUG 01-06 17:11:01.334031.334031 cuda_h.py:19] end gpu_experts cost 0.0070858001708984375 seconds
DEBUG 01-06 17:11:01.334345.334345 cuda_h.py:19] end layer_moe_generate_6 cost 0.06593608856201172 seconds
DEBUG 01-06 17:11:01.334384.334384 lmp.py:220] -------------------------------- end layer 6 --------------------------------
DEBUG 01-06 17:11:01.334107.334107 lmp.py:176] -------------------------------- start layer 7 --------------------------------
DEBUG 01-06 17:11:01.334518.334518 cuda_h.py:10] start start_load_qkvogn_s_weight_l_8
DEBUG 01-06 17:11:01.334659.334659 cuda_h.py:10] start start_load_qkvogn_s_weight_l_8
DEBUG 01-06 17:11:01.334025.334025 cuda_h.py:19] end start_load_qkvogn_s_weight_l_8 cost 3.0517578125e-05 seconds
DEBUG 01-06 17:11:01.334397.334397 cuda_h.py:19] end start_load_qkvogn_s_weight_l_8 cost 6.341934204101562e-05 seconds
DEBUG 01-06 17:11:01.334093.334093 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-06 17:11:01.334883.334883 cuda_h.py:10] start sllm_worker_task
DEBUG 01-06 17:11:01.335840.335840 mlpmodule.py:367] cuda:1 cuda:1
DEBUG 01-06 17:11:01.335464.335464 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 17:11:01.335905.335905 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 17:11:01.336561.336561 cuda_h.py:19] end allocate_cuda_memory cost 0.0009703636169433594 seconds
DEBUG 01-06 17:11:01.336325.336325 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 17:11:01.336419.336419 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 17:11:01.336526.336526 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 17:11:01.336752.336752 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, e9a70bc0-63c2-4fd6-aa6a-09392eace199
DEBUG 01-06 17:11:01.336636.336636 client.py:106] call stub.LoadModelAsync
DEBUG 01-06 17:11:01.336038.336038 cuda_h.py:10] start self_attn
INFO 01-06 17:11:01.337411.337411 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, e9a70bc0-63c2-4fd6-aa6a-09392eace199
DEBUG 01-06 17:11:01.337439.337439 cuda_h.py:19] end load_into_gpu_async cost 0.0015938282012939453 seconds
DEBUG 01-06 17:11:01.337712.337712 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 17:11:01.338695.338695 cuda_h.py:19] end restore_tensors2 cost 6.628036499023438e-05 seconds
DEBUG 01-06 17:11:01.338212.338212 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0028808116912841797 seconds
INFO 01-06 17:11:01.338519.338519 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, e9a70bc0-63c2-4fd6-aa6a-09392eace199
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-06 17:11:01.339535.339535 cuda_h.py:19] end self_attn cost 0.0028982162475585938 seconds
DEBUG 01-06 17:11:01.340439.340439 cuda_h.py:19] end iln_self_attn_paln cost 0.005174160003662109 seconds
DEBUG 01-06 17:11:01.340759.340759 cuda_h.py:10] start layer_moe_generate_7
DEBUG 01-06 17:11:01.340337.340337 cuda_h.py:10] start gate
DEBUG 01-06 17:11:01.340181.340181 cuda_h.py:19] end gate cost 0.0006582736968994141 seconds
DEBUG 01-06 17:11:01.340441.340441 cuda_h.py:10] start experts_map_get
DEBUG 01-06 17:11:01.341789.341789 lmp.py:403] 
DEBUG 01-06 17:11:01.341789.341789 lmp.py:403] Expert Token Distribution & Device Allocation:
DEBUG 01-06 17:11:01.341359.341359 lmp.py:404]   Total experts: 64
DEBUG 01-06 17:11:01.341215.341215 lmp.py:405]   CPU experts: 32 (50%)
DEBUG 01-06 17:11:01.341103.341103 lmp.py:406]   GPU experts: 32 (50%)
DEBUG 01-06 17:11:01.341699.341699 lmp.py:407] 
DEBUG 01-06 17:11:01.341699.341699 lmp.py:407]   Expert ID | Tokens | Device
DEBUG 01-06 17:11:01.341581.341581 lmp.py:408]   -----------------------------------
DEBUG 01-06 17:11:01.341469.341469 lmp.py:414]   Expert 50 |     45 | CPU
DEBUG 01-06 17:11:01.341543.341543 lmp.py:414]   Expert  3 |     55 | CPU
DEBUG 01-06 17:11:01.341570.341570 lmp.py:414]   Expert 46 |     56 | CPU
DEBUG 01-06 17:11:01.341736.341736 lmp.py:414]   Expert  1 |     80 | CPU
DEBUG 01-06 17:11:01.341902.341902 lmp.py:414]   Expert  4 |     86 | CPU
DEBUG 01-06 17:11:01.341591.341591 lmp.py:414]   Expert 29 |     92 | CPU
DEBUG 01-06 17:11:01.341903.341903 lmp.py:414]   Expert 15 |     93 | CPU
DEBUG 01-06 17:11:01.341785.341785 lmp.py:414]   Expert 40 |     96 | CPU
DEBUG 01-06 17:11:01.341474.341474 lmp.py:414]   Expert  8 |    111 | CPU
DEBUG 01-06 17:11:01.341925.341925 lmp.py:414]   Expert 41 |    111 | CPU
DEBUG 01-06 17:11:01.341376.341376 lmp.py:414]   Expert 28 |    115 | CPU
DEBUG 01-06 17:11:01.341827.341827 lmp.py:414]   Expert 48 |    126 | CPU
DEBUG 01-06 17:11:01.341516.341516 lmp.py:414]   Expert 16 |    128 | CPU
DEBUG 01-06 17:11:01.341920.341920 lmp.py:414]   Expert  6 |    131 | CPU
DEBUG 01-06 17:11:01.341848.341848 lmp.py:414]   Expert 13 |    131 | CPU
DEBUG 01-06 17:11:01.341776.341776 lmp.py:414]   Expert 27 |    132 | CPU
DEBUG 01-06 17:11:01.341896.341896 lmp.py:414]   Expert 54 |    133 | CPU
DEBUG 01-06 17:11:01.341585.341585 lmp.py:414]   Expert  7 |    139 | CPU
DEBUG 01-06 17:11:01.341036.341036 lmp.py:414]   Expert 39 |    139 | CPU
DEBUG 01-06 17:11:01.341964.341964 lmp.py:414]   Expert 60 |    139 | CPU
DEBUG 01-06 17:11:01.341414.341414 lmp.py:414]   Expert 14 |    140 | CPU
DEBUG 01-06 17:11:01.341104.341104 lmp.py:414]   Expert 51 |    142 | CPU
DEBUG 01-06 17:11:01.341555.341555 lmp.py:414]   Expert 55 |    143 | CPU
DEBUG 01-06 17:11:01.341767.341767 lmp.py:414]   Expert 56 |    143 | CPU
DEBUG 01-06 17:11:01.341172.341172 lmp.py:414]   Expert 43 |    144 | CPU
DEBUG 01-06 17:11:01.341099.341099 lmp.py:414]   Expert 18 |    145 | CPU
DEBUG 01-06 17:11:01.341742.341742 lmp.py:414]   Expert 20 |    145 | CPU
DEBUG 01-06 17:11:01.341908.341908 lmp.py:414]   Expert 52 |    145 | CPU
DEBUG 01-06 17:11:01.341075.341075 lmp.py:414]   Expert 36 |    152 | CPU
DEBUG 01-06 17:11:01.341002.341002 lmp.py:414]   Expert 11 |    156 | CPU
DEBUG 01-06 17:11:01.341692.341692 lmp.py:414]   Expert  5 |    159 | CPU
DEBUG 01-06 17:11:01.341381.341381 lmp.py:414]   Expert 10 |    159 | CPU
DEBUG 01-06 17:11:01.341832.341832 lmp.py:414]   Expert 45 |    160 | GPU
DEBUG 01-06 17:11:01.341283.341283 lmp.py:414]   Expert 62 |    163 | GPU
DEBUG 01-06 17:11:01.341687.341687 lmp.py:414]   Expert 57 |    173 | GPU
DEBUG 01-06 17:11:01.341615.341615 lmp.py:414]   Expert 33 |    177 | GPU
DEBUG 01-06 17:11:01.341496.341496 lmp.py:414]   Expert 44 |    177 | GPU
DEBUG 01-06 17:11:01.341901.341901 lmp.py:414]   Expert 53 |    180 | GPU
DEBUG 01-06 17:11:01.342067.342067 lmp.py:414]   Expert 25 |    181 | GPU
DEBUG 01-06 17:11:01.342472.342472 lmp.py:414]   Expert 58 |    181 | GPU
DEBUG 01-06 17:11:01.342876.342876 lmp.py:414]   Expert  2 |    189 | GPU
DEBUG 01-06 17:11:01.342804.342804 lmp.py:414]   Expert 32 |    189 | GPU
DEBUG 01-06 17:11:01.342493.342493 lmp.py:414]   Expert 31 |    198 | GPU
DEBUG 01-06 17:11:01.342421.342421 lmp.py:414]   Expert 63 |    198 | GPU
DEBUG 01-06 17:11:01.342872.342872 lmp.py:414]   Expert 49 |    200 | GPU
DEBUG 01-06 17:11:01.342561.342561 lmp.py:414]   Expert 35 |    201 | GPU
DEBUG 01-06 17:11:01.342250.342250 lmp.py:414]   Expert 21 |    208 | GPU
DEBUG 01-06 17:11:01.342178.342178 lmp.py:414]   Expert 17 |    210 | GPU
DEBUG 01-06 17:11:01.342536.342536 lmp.py:414]   Expert 34 |    219 | GPU
DEBUG 01-06 17:11:01.342702.342702 lmp.py:414]   Expert 42 |    220 | GPU
DEBUG 01-06 17:11:01.342345.342345 lmp.py:414]   Expert 37 |    227 | GPU
DEBUG 01-06 17:11:01.342273.342273 lmp.py:414]   Expert 59 |    231 | GPU
DEBUG 01-06 17:11:01.342678.342678 lmp.py:414]   Expert 22 |    237 | GPU
DEBUG 01-06 17:11:01.342367.342367 lmp.py:414]   Expert  0 |    246 | GPU
DEBUG 01-06 17:11:01.342056.342056 lmp.py:414]   Expert 19 |    261 | GPU
DEBUG 01-06 17:11:01.342984.342984 lmp.py:414]   Expert 24 |    285 | GPU
DEBUG 01-06 17:11:01.342673.342673 lmp.py:414]   Expert 61 |    286 | GPU
DEBUG 01-06 17:11:01.342124.342124 lmp.py:414]   Expert 30 |    302 | GPU
DEBUG 01-06 17:11:01.342052.342052 lmp.py:414]   Expert 47 |    320 | GPU
DEBUG 01-06 17:11:01.342741.342741 lmp.py:414]   Expert 38 |    366 | GPU
DEBUG 01-06 17:11:01.342623.342623 lmp.py:414]   Expert 26 |    368 | GPU
DEBUG 01-06 17:11:01.342789.342789 lmp.py:414]   Expert 12 |    434 | GPU
DEBUG 01-06 17:11:01.342193.342193 lmp.py:414]   Expert  9 |    673 | GPU
DEBUG 01-06 17:11:01.342121.342121 lmp.py:414]   Expert 23 |    717 | GPU
DEBUG 01-06 17:11:01.342956.342956 lmp.py:415] 
DEBUG 01-06 17:11:01.342956.342956 lmp.py:415]   CPU total tokens: 3911 (31.8%)
DEBUG 01-06 17:11:01.342599.342599 lmp.py:416]   GPU total tokens: 8377 (68.2%)
DEBUG 01-06 17:11:01.342487.342487 cuda_h.py:19] end experts_map_get cost 0.0015499591827392578 seconds
DEBUG 01-06 17:11:01.342369.342369 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-06 17:11:01.342907.342907 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 17:11:01.342467.342467 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 17:11:01.344860.344860 cuda_h.py:19] end allocate_cuda_memory cost 0.0014150142669677734 seconds
DEBUG 01-06 17:11:01.344564.344564 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 17:11:01.344082.344082 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 17:11:01.344798.344798 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 17:11:01.344117.344117 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 171b6b2d-dc1f-48fb-8987-136dd2e45a59
DEBUG 01-06 17:11:01.344262.344262 client.py:106] call stub.LoadModelAsync
DEBUG 01-06 17:11:01.344187.344187 mlpmodule.py:664]  experts func einsum cost 0.0650935173034668 s
INFO 01-06 17:11:01.345693.345693 client.py:127] Model loaded
DEBUG 01-06 17:11:01.346057.346057 cuda_h.py:19] end sllm_worker_task cost 0.011184215545654297 seconds
INFO 01-06 17:11:01.347622.347622 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 171b6b2d-dc1f-48fb-8987-136dd2e45a59
DEBUG 01-06 17:11:01.347779.347779 cuda_h.py:19] end load_into_gpu_async cost 0.003409147262573242 seconds
DEBUG 01-06 17:11:01.347319.347319 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 17:11:01.348913.348913 cuda_h.py:19] end restore_tensors2 cost 0.00047326087951660156 seconds
DEBUG 01-06 17:11:01.348816.348816 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.005769014358520508 seconds
DEBUG 01-06 17:11:01.352995.352995 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.010364770889282227 seconds
DEBUG 01-06 17:11:01.352481.352481 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-06 17:11:01.353690.353690 lmp.py:461] 
DEBUG 01-06 17:11:01.353690.353690 lmp.py:461]   Computing 32 experts on CPU...
DEBUG 01-06 17:11:01.353528.353528 cuda_h.py:19] end cpu_experts_submit cost 0.00016236305236816406 seconds
DEBUG 01-06 17:11:01.353821.353821 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-06 17:11:01.362917.362917 mlpmodule.py:706] group tensors cost 0.00860452651977539 s
DEBUG 01-06 17:11:01.366740.366740 mlpmodule.py:744] pad cost 0.0032019615173339844 s
DEBUG 01-06 17:11:01.366124.366124 mlpmodule.py:750] create cpu tensor cost 7.343292236328125e-05 s
DEBUG 01-06 17:11:01.366009.366009 mlpmodule.py:755] move to cpu cost 5.269050598144531e-05 s
DEBUG 01-06 17:11:01.377701.377701 mlpmodule.py:769] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-06 17:11:01.377515.377515 mlpmodule.py:770] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-06 17:11:01.377942.377942 mlpmodule.py:775] group_w3 first element: 0.01263427734375
WARNING 01-06 17:11:01.378466.378466 mlpmodule.py:785] start einsum2
DEBUG 01-06 17:11:01.395445.395445 mlpmodule.py:795] group einsum cost 0.028757810592651367 s
DEBUG 01-06 17:11:01.396481.396481 mlpmodule.py:803] cpy2cputensor cost 0.0006730556488037109 s
DEBUG 01-06 17:11:01.400238.400238 cuda_h.py:19] end wait_cetm_experts cost 0.047616004943847656 seconds
DEBUG 01-06 17:11:01.401295.401295 cuda_h.py:10] start gpu_sexperts
DEBUG 01-06 17:11:01.401525.401525 cuda_h.py:19] end gpu_sexperts cost 0.0005013942718505859 seconds
DEBUG 01-06 17:11:01.401898.401898 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-06 17:11:01.401775.401775 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.4080276489257812e-05 seconds
DEBUG 01-06 17:11:01.401478.401478 cuda_h.py:10] start wait_experts
INFO 01-06 17:11:01.401234.401234 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 171b6b2d-dc1f-48fb-8987-136dd2e45a59
INFO 01-06 17:11:01.402016.402016 client.py:127] Model loaded
DEBUG 01-06 17:11:01.403575.403575 cuda_h.py:19] end wait_experts cost 0.0012698173522949219 seconds
DEBUG 01-06 17:11:01.403013.403013 cuda_h.py:10] start gpu_experts
DEBUG 01-06 17:11:01.403292.403292 lmp.py:506]   Computing 32 experts on GPU...
DEBUG 01-06 17:11:01.403951.403951 mlpmodule.py:533] gpu group tensors cost 0.0006170272827148438 s
DEBUG 01-06 17:11:01.405216.405216 mlpmodule.py:566] gpu pad cost 0.001722574234008789 s
DEBUG 01-06 17:11:01.406925.406925 mlpmodule.py:584] gpu group einsum cost 0.0005185604095458984 s
DEBUG 01-06 17:11:01.409731.409731 mlpmodule.py:613] gpu experts func einsum cost 0.006490945816040039 s
DEBUG 01-06 17:11:01.409906.409906 cuda_h.py:19] end gpu_experts cost 0.0066683292388916016 seconds
DEBUG 01-06 17:11:01.409387.409387 cuda_h.py:19] end layer_moe_generate_7 cost 0.06974101066589355 seconds
DEBUG 01-06 17:11:01.410017.410017 lmp.py:220] -------------------------------- end layer 7 --------------------------------
DEBUG 01-06 17:11:01.410681.410681 lmp.py:176] -------------------------------- start layer 8 --------------------------------
DEBUG 01-06 17:11:01.410729.410729 cuda_h.py:10] start start_load_qkvogn_s_weight_l_9
DEBUG 01-06 17:11:01.410922.410922 cuda_h.py:10] start start_load_qkvogn_s_weight_l_9
DEBUG 01-06 17:11:01.410283.410283 cuda_h.py:19] end start_load_qkvogn_s_weight_l_9 cost 5.793571472167969e-05 seconds
DEBUG 01-06 17:11:01.410158.410158 cuda_h.py:10] start sllm_worker_task
DEBUG 01-06 17:11:01.410914.410914 cuda_h.py:19] end start_load_qkvogn_s_weight_l_9 cost 0.00014257431030273438 seconds
DEBUG 01-06 17:11:01.410315.410315 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 17:11:01.410159.410159 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-06 17:11:01.410705.410705 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 17:11:01.410849.410849 mlpmodule.py:367] cuda:1 cuda:1
DEBUG 01-06 17:11:01.412366.412366 cuda_h.py:19] end allocate_cuda_memory cost 0.0013477802276611328 seconds
DEBUG 01-06 17:11:01.412339.412339 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 17:11:01.412500.412500 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 17:11:01.412183.412183 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 17:11:01.412171.412171 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 2b638221-f166-4d0f-bf0e-afcf80f703a5
DEBUG 01-06 17:11:01.412094.412094 client.py:106] call stub.LoadModelAsync
DEBUG 01-06 17:11:01.412681.412681 cuda_h.py:10] start self_attn
INFO 01-06 17:11:01.414565.414565 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 2b638221-f166-4d0f-bf0e-afcf80f703a5
DEBUG 01-06 17:11:01.414739.414739 cuda_h.py:19] end load_into_gpu_async cost 0.0016176700592041016 seconds
DEBUG 01-06 17:11:01.414535.414535 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 17:11:01.414756.414756 cuda_h.py:19] end restore_tensors2 cost 6.699562072753906e-05 seconds
DEBUG 01-06 17:11:01.414797.414797 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0035696029663085938 seconds
INFO 01-06 17:11:01.414210.414210 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 2b638221-f166-4d0f-bf0e-afcf80f703a5
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-06 17:11:01.416342.416342 cuda_h.py:19] end self_attn cost 0.003057718276977539 seconds
DEBUG 01-06 17:11:01.416591.416591 cuda_h.py:19] end iln_self_attn_paln cost 0.005653858184814453 seconds
DEBUG 01-06 17:11:01.416673.416673 cuda_h.py:10] start layer_moe_generate_8
DEBUG 01-06 17:11:01.416105.416105 cuda_h.py:10] start gate
DEBUG 01-06 17:11:01.417174.417174 cuda_h.py:19] end gate cost 0.0006489753723144531 seconds
DEBUG 01-06 17:11:01.417573.417573 cuda_h.py:10] start experts_map_get
DEBUG 01-06 17:11:01.417059.417059 lmp.py:403] 
DEBUG 01-06 17:11:01.417059.417059 lmp.py:403] Expert Token Distribution & Device Allocation:
DEBUG 01-06 17:11:01.417054.417054 lmp.py:404]   Total experts: 64
DEBUG 01-06 17:11:01.417511.417511 lmp.py:405]   CPU experts: 32 (50%)
DEBUG 01-06 17:11:01.417823.417823 lmp.py:406]   GPU experts: 32 (50%)
DEBUG 01-06 17:11:01.417679.417679 lmp.py:407] 
DEBUG 01-06 17:11:01.417679.417679 lmp.py:407]   Expert ID | Tokens | Device
DEBUG 01-06 17:11:01.417752.417752 lmp.py:408]   -----------------------------------
DEBUG 01-06 17:11:01.417356.417356 lmp.py:414]   Expert 38 |     11 | CPU
DEBUG 01-06 17:11:01.417475.417475 lmp.py:414]   Expert 39 |     66 | CPU
DEBUG 01-06 17:11:01.417642.417642 lmp.py:414]   Expert  7 |     72 | CPU
DEBUG 01-06 17:11:01.417808.417808 lmp.py:414]   Expert 30 |     76 | CPU
DEBUG 01-06 17:11:01.417735.417735 lmp.py:414]   Expert 27 |     92 | CPU
DEBUG 01-06 17:11:01.417425.417425 lmp.py:414]   Expert 17 |     93 | CPU
DEBUG 01-06 17:11:01.417352.417352 lmp.py:414]   Expert 24 |     94 | CPU
DEBUG 01-06 17:11:01.417757.417757 lmp.py:414]   Expert 14 |     95 | CPU
DEBUG 01-06 17:11:01.417923.417923 lmp.py:414]   Expert 36 |     95 | CPU
DEBUG 01-06 17:11:01.417612.417612 lmp.py:414]   Expert 32 |    104 | CPU
DEBUG 01-06 17:11:01.417063.417063 lmp.py:414]   Expert 40 |    104 | CPU
DEBUG 01-06 17:11:01.417991.417991 lmp.py:414]   Expert 16 |    105 | CPU
DEBUG 01-06 17:11:01.417680.417680 lmp.py:414]   Expert 18 |    109 | CPU
DEBUG 01-06 17:11:01.417893.417893 lmp.py:414]   Expert 12 |    113 | CPU
DEBUG 01-06 17:11:01.417344.417344 lmp.py:414]   Expert  1 |    116 | CPU
DEBUG 01-06 17:11:01.417748.417748 lmp.py:414]   Expert 48 |    116 | CPU
DEBUG 01-06 17:11:01.417914.417914 lmp.py:414]   Expert  6 |    131 | CPU
DEBUG 01-06 17:11:01.417842.417842 lmp.py:414]   Expert 59 |    137 | CPU
DEBUG 01-06 17:11:01.417531.417531 lmp.py:414]   Expert 42 |    139 | CPU
DEBUG 01-06 17:11:01.418221.418221 lmp.py:414]   Expert 22 |    142 | CPU
DEBUG 01-06 17:11:01.418672.418672 lmp.py:414]   Expert  0 |    143 | CPU
DEBUG 01-06 17:11:01.418361.418361 lmp.py:414]   Expert 51 |    152 | CPU
DEBUG 01-06 17:11:01.418289.418289 lmp.py:414]   Expert 53 |    153 | CPU
DEBUG 01-06 17:11:01.418455.418455 lmp.py:414]   Expert 15 |    161 | CPU
DEBUG 01-06 17:11:01.418621.418621 lmp.py:414]   Expert  8 |    162 | CPU
DEBUG 01-06 17:11:01.418549.418549 lmp.py:414]   Expert 60 |    164 | CPU
DEBUG 01-06 17:11:01.418238.418238 lmp.py:414]   Expert 29 |    170 | CPU
DEBUG 01-06 17:11:01.418689.418689 lmp.py:414]   Expert 44 |    170 | CPU
DEBUG 01-06 17:11:01.418378.418378 lmp.py:414]   Expert 54 |    171 | CPU
DEBUG 01-06 17:11:01.418829.418829 lmp.py:414]   Expert 35 |    178 | CPU
DEBUG 01-06 17:11:01.418518.418518 lmp.py:414]   Expert 33 |    184 | CPU
DEBUG 01-06 17:11:01.418446.418446 lmp.py:414]   Expert 34 |    187 | CPU
DEBUG 01-06 17:11:01.418612.418612 lmp.py:414]   Expert 19 |    188 | GPU
DEBUG 01-06 17:11:01.418301.418301 lmp.py:414]   Expert 47 |    190 | GPU
DEBUG 01-06 17:11:01.418752.418752 lmp.py:414]   Expert  9 |    192 | GPU
DEBUG 01-06 17:11:01.418203.418203 lmp.py:414]   Expert  3 |    193 | GPU
DEBUG 01-06 17:11:01.418893.418893 lmp.py:414]   Expert 56 |    195 | GPU
DEBUG 01-06 17:11:01.418105.418105 lmp.py:414]   Expert 20 |    196 | GPU
DEBUG 01-06 17:11:01.418794.418794 lmp.py:414]   Expert 21 |    197 | GPU
DEBUG 01-06 17:11:01.418484.418484 lmp.py:414]   Expert 45 |    200 | GPU
DEBUG 01-06 17:11:01.418934.418934 lmp.py:414]   Expert 46 |    200 | GPU
DEBUG 01-06 17:11:01.418101.418101 lmp.py:414]   Expert 49 |    205 | GPU
DEBUG 01-06 17:11:01.418267.418267 lmp.py:414]   Expert 28 |    208 | GPU
DEBUG 01-06 17:11:01.418718.418718 lmp.py:414]   Expert 57 |    222 | GPU
DEBUG 01-06 17:11:01.418169.418169 lmp.py:414]   Expert  4 |    223 | GPU
DEBUG 01-06 17:11:01.418096.418096 lmp.py:414]   Expert  2 |    224 | GPU
DEBUG 01-06 17:11:01.418786.418786 lmp.py:414]   Expert 13 |    224 | GPU
DEBUG 01-06 17:11:01.418236.418236 lmp.py:414]   Expert 43 |    229 | GPU
DEBUG 01-06 17:11:01.418926.418926 lmp.py:414]   Expert 41 |    235 | GPU
DEBUG 01-06 17:11:01.418615.418615 lmp.py:414]   Expert 10 |    237 | GPU
DEBUG 01-06 17:11:01.418304.418304 lmp.py:414]   Expert 50 |    241 | GPU
DEBUG 01-06 17:11:01.418232.418232 lmp.py:414]   Expert 26 |    252 | GPU
DEBUG 01-06 17:11:01.418160.418160 lmp.py:414]   Expert 63 |    257 | GPU
DEBUG 01-06 17:11:01.418849.418849 lmp.py:414]   Expert 37 |    258 | GPU
DEBUG 01-06 17:11:01.418538.418538 lmp.py:414]   Expert 31 |    269 | GPU
DEBUG 01-06 17:11:01.418989.418989 lmp.py:414]   Expert 61 |    271 | GPU
DEBUG 01-06 17:11:01.418917.418917 lmp.py:414]   Expert 52 |    309 | GPU
DEBUG 01-06 17:11:01.418083.418083 lmp.py:414]   Expert 62 |    326 | GPU
DEBUG 01-06 17:11:01.418726.418726 lmp.py:414]   Expert 58 |    329 | GPU
DEBUG 01-06 17:11:01.418892.418892 lmp.py:414]   Expert 55 |    343 | GPU
DEBUG 01-06 17:11:01.418820.418820 lmp.py:414]   Expert 11 |    377 | GPU
DEBUG 01-06 17:11:01.418271.418271 lmp.py:414]   Expert 23 |    377 | GPU
DEBUG 01-06 17:11:01.418960.418960 lmp.py:414]   Expert 25 |    400 | GPU
DEBUG 01-06 17:11:01.418649.418649 lmp.py:414]   Expert  5 |    516 | GPU
DEBUG 01-06 17:11:01.418816.418816 lmp.py:415] 
DEBUG 01-06 17:11:01.418816.418816 lmp.py:415]   CPU total tokens: 4005 (32.6%)
DEBUG 01-06 17:11:01.418459.418459 lmp.py:416]   GPU total tokens: 8283 (67.4%)
DEBUG 01-06 17:11:01.418824.418824 cuda_h.py:19] end experts_map_get cost 0.0015254020690917969 seconds
DEBUG 01-06 17:11:01.418943.418943 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-06 17:11:01.418004.418004 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 17:11:01.418088.418088 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 17:11:01.420873.420873 cuda_h.py:19] end allocate_cuda_memory cost 0.0012478828430175781 seconds
DEBUG 01-06 17:11:01.420081.420081 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 17:11:01.420857.420857 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 17:11:01.420733.420733 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 17:11:01.420575.420575 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 444d98c0-69c2-4bac-bb87-407c0787f0cc
DEBUG 01-06 17:11:01.420322.420322 client.py:106] call stub.LoadModelAsync
DEBUG 01-06 17:11:01.420134.420134 mlpmodule.py:664]  experts func einsum cost 0.06733131408691406 s
INFO 01-06 17:11:01.421778.421778 client.py:127] Model loaded
DEBUG 01-06 17:11:01.422997.422997 cuda_h.py:19] end sllm_worker_task cost 0.011885643005371094 seconds
INFO 01-06 17:11:01.423003.423003 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 444d98c0-69c2-4bac-bb87-407c0787f0cc
DEBUG 01-06 17:11:01.423677.423677 cuda_h.py:19] end load_into_gpu_async cost 0.003292560577392578 seconds
DEBUG 01-06 17:11:01.423355.423355 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 17:11:01.424641.424641 cuda_h.py:19] end restore_tensors2 cost 0.0003573894500732422 seconds
DEBUG 01-06 17:11:01.424602.424602 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.005369663238525391 seconds
DEBUG 01-06 17:11:01.426782.426782 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.00800013542175293 seconds
DEBUG 01-06 17:11:01.426896.426896 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-06 17:11:01.426356.426356 lmp.py:461] 
DEBUG 01-06 17:11:01.426356.426356 lmp.py:461]   Computing 32 experts on CPU...
DEBUG 01-06 17:11:01.427391.427391 cuda_h.py:19] end cpu_experts_submit cost 0.000110626220703125 seconds
DEBUG 01-06 17:11:01.427253.427253 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-06 17:11:01.437052.437052 mlpmodule.py:706] group tensors cost 0.00986933708190918 s
DEBUG 01-06 17:11:01.439033.439033 mlpmodule.py:744] pad cost 0.0019125938415527344 s
DEBUG 01-06 17:11:01.439944.439944 mlpmodule.py:750] create cpu tensor cost 5.53131103515625e-05 s
DEBUG 01-06 17:11:01.439794.439794 mlpmodule.py:755] move to cpu cost 3.0279159545898438e-05 s
DEBUG 01-06 17:11:01.451649.451649 mlpmodule.py:769] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-06 17:11:01.451072.451072 mlpmodule.py:770] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-06 17:11:01.451407.451407 mlpmodule.py:775] group_w3 first element: 0.0859375
WARNING 01-06 17:11:01.451988.451988 mlpmodule.py:785] start einsum2
DEBUG 01-06 17:11:01.471507.471507 mlpmodule.py:795] group einsum cost 0.03148818016052246 s
DEBUG 01-06 17:11:01.472273.472273 mlpmodule.py:803] cpy2cputensor cost 0.0007162094116210938 s
DEBUG 01-06 17:11:01.477966.477966 cuda_h.py:19] end wait_cetm_experts cost 0.05013108253479004 seconds
DEBUG 01-06 17:11:01.477592.477592 cuda_h.py:10] start gpu_sexperts
DEBUG 01-06 17:11:01.477318.477318 cuda_h.py:19] end gpu_sexperts cost 0.0004916191101074219 seconds
DEBUG 01-06 17:11:01.477161.477161 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-06 17:11:01.478117.478117 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.574920654296875e-05 seconds
DEBUG 01-06 17:11:01.478297.478297 cuda_h.py:10] start wait_experts
INFO 01-06 17:11:01.478815.478815 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 444d98c0-69c2-4bac-bb87-407c0787f0cc
INFO 01-06 17:11:01.479353.479353 client.py:127] Model loaded
DEBUG 01-06 17:11:01.479448.479448 cuda_h.py:19] end wait_experts cost 0.0013077259063720703 seconds
DEBUG 01-06 17:11:01.479826.479826 cuda_h.py:10] start gpu_experts
DEBUG 01-06 17:11:01.479059.479059 lmp.py:506]   Computing 32 experts on GPU...
DEBUG 01-06 17:11:01.480037.480037 mlpmodule.py:533] gpu group tensors cost 0.0006422996520996094 s
DEBUG 01-06 17:11:01.481586.481586 mlpmodule.py:566] gpu pad cost 0.0017213821411132812 s
DEBUG 01-06 17:11:01.482667.482667 mlpmodule.py:584] gpu group einsum cost 0.0005464553833007812 s
DEBUG 01-06 17:11:01.486604.486604 mlpmodule.py:613] gpu experts func einsum cost 0.006500244140625 s
DEBUG 01-06 17:11:01.486164.486164 cuda_h.py:19] end gpu_experts cost 0.006680488586425781 seconds
DEBUG 01-06 17:11:01.486273.486273 cuda_h.py:19] end layer_moe_generate_8 cost 0.06972217559814453 seconds
DEBUG 01-06 17:11:01.486087.486087 lmp.py:220] -------------------------------- end layer 8 --------------------------------
DEBUG 01-06 17:11:01.486758.486758 lmp.py:176] -------------------------------- start layer 9 --------------------------------
DEBUG 01-06 17:11:01.486315.486315 cuda_h.py:10] start start_load_qkvogn_s_weight_l_10
DEBUG 01-06 17:11:01.486178.486178 cuda_h.py:10] start start_load_qkvogn_s_weight_l_10
DEBUG 01-06 17:11:01.486995.486995 cuda_h.py:19] end start_load_qkvogn_s_weight_l_10 cost 3.790855407714844e-05 seconds
DEBUG 01-06 17:11:01.486276.486276 cuda_h.py:10] start sllm_worker_task
DEBUG 01-06 17:11:01.486357.486357 cuda_h.py:19] end start_load_qkvogn_s_weight_l_10 cost 0.0001647472381591797 seconds
DEBUG 01-06 17:11:01.486387.486387 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 17:11:01.486469.486469 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-06 17:11:01.487346.487346 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 17:11:01.488660.488660 cuda_h.py:19] end allocate_cuda_memory cost 0.0017404556274414062 seconds
DEBUG 01-06 17:11:01.488670.488670 mlpmodule.py:367] cuda:1 cuda:1
DEBUG 01-06 17:11:01.489335.489335 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 17:11:01.489120.489120 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 17:11:01.489042.489042 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 17:11:01.489984.489984 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, b755507b-b640-4656-8d2e-1a2afe4e9e81
DEBUG 01-06 17:11:01.489722.489722 client.py:106] call stub.LoadModelAsync
DEBUG 01-06 17:11:01.489283.489283 cuda_h.py:10] start self_attn
INFO 01-06 17:11:01.490764.490764 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, b755507b-b640-4656-8d2e-1a2afe4e9e81
DEBUG 01-06 17:11:01.490131.490131 cuda_h.py:19] end load_into_gpu_async cost 0.0016946792602539062 seconds
DEBUG 01-06 17:11:01.490688.490688 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 17:11:01.490201.490201 cuda_h.py:19] end restore_tensors2 cost 7.033348083496094e-05 seconds
DEBUG 01-06 17:11:01.491494.491494 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.004030466079711914 seconds
INFO 01-06 17:11:01.491138.491138 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, b755507b-b640-4656-8d2e-1a2afe4e9e81
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-06 17:11:01.492929.492929 cuda_h.py:19] end self_attn cost 0.0030100345611572266 seconds
DEBUG 01-06 17:11:01.493052.493052 cuda_h.py:19] end iln_self_attn_paln cost 0.0059719085693359375 seconds
DEBUG 01-06 17:11:01.493133.493133 cuda_h.py:10] start layer_moe_generate_9
DEBUG 01-06 17:11:01.493088.493088 cuda_h.py:10] start gate
DEBUG 01-06 17:11:01.493879.493879 cuda_h.py:19] end gate cost 0.0006513595581054688 seconds
DEBUG 01-06 17:11:01.493563.493563 cuda_h.py:10] start experts_map_get
DEBUG 01-06 17:11:01.494056.494056 lmp.py:403] 
DEBUG 01-06 17:11:01.494056.494056 lmp.py:403] Expert Token Distribution & Device Allocation:
DEBUG 01-06 17:11:01.494581.494581 lmp.py:404]   Total experts: 64
DEBUG 01-06 17:11:01.494707.494707 lmp.py:405]   CPU experts: 32 (50%)
DEBUG 01-06 17:11:01.494688.494688 lmp.py:406]   GPU experts: 32 (50%)
DEBUG 01-06 17:11:01.494569.494569 lmp.py:407] 
DEBUG 01-06 17:11:01.494569.494569 lmp.py:407]   Expert ID | Tokens | Device
DEBUG 01-06 17:11:01.494736.494736 lmp.py:408]   -----------------------------------
DEBUG 01-06 17:11:01.494200.494200 lmp.py:414]   Expert 24 |     38 | CPU
DEBUG 01-06 17:11:01.494035.494035 lmp.py:414]   Expert  2 |     45 | CPU
DEBUG 01-06 17:11:01.494585.494585 lmp.py:414]   Expert 26 |     64 | CPU
DEBUG 01-06 17:11:01.494228.494228 lmp.py:414]   Expert 19 |     67 | CPU
DEBUG 01-06 17:11:01.494633.494633 lmp.py:414]   Expert 32 |     67 | CPU
DEBUG 01-06 17:11:01.494037.494037 lmp.py:414]   Expert 50 |     70 | CPU
DEBUG 01-06 17:11:01.494204.494204 lmp.py:414]   Expert  7 |     78 | CPU
DEBUG 01-06 17:11:01.494370.494370 lmp.py:414]   Expert  4 |     83 | CPU
DEBUG 01-06 17:11:01.494443.494443 lmp.py:414]   Expert 28 |     83 | CPU
DEBUG 01-06 17:11:01.494371.494371 lmp.py:414]   Expert 15 |     84 | CPU
DEBUG 01-06 17:11:01.494299.494299 lmp.py:414]   Expert 59 |     88 | CPU
DEBUG 01-06 17:11:01.494988.494988 lmp.py:414]   Expert 60 |     88 | CPU
DEBUG 01-06 17:11:01.494154.494154 lmp.py:414]   Expert  5 |     97 | CPU
DEBUG 01-06 17:11:01.494274.494274 lmp.py:414]   Expert 23 |    100 | CPU
DEBUG 01-06 17:11:01.494586.494586 lmp.py:414]   Expert 49 |    102 | CPU
DEBUG 01-06 17:11:01.494514.494514 lmp.py:414]   Expert 12 |    105 | CPU
DEBUG 01-06 17:11:01.494964.494964 lmp.py:414]   Expert 10 |    107 | CPU
DEBUG 01-06 17:11:01.494654.494654 lmp.py:414]   Expert 27 |    116 | CPU
DEBUG 01-06 17:11:01.494343.494343 lmp.py:414]   Expert  3 |    122 | CPU
DEBUG 01-06 17:11:01.494794.494794 lmp.py:414]   Expert 41 |    122 | CPU
DEBUG 01-06 17:11:01.494960.494960 lmp.py:414]   Expert 16 |    126 | CPU
DEBUG 01-06 17:11:01.494557.494557 lmp.py:414]   Expert 25 |    126 | CPU
DEBUG 01-06 17:11:01.494246.494246 lmp.py:414]   Expert 40 |    127 | CPU
DEBUG 01-06 17:11:01.494697.494697 lmp.py:414]   Expert 13 |    128 | CPU
DEBUG 01-06 17:11:01.494909.494909 lmp.py:414]   Expert 20 |    132 | CPU
DEBUG 01-06 17:11:01.494599.494599 lmp.py:414]   Expert 37 |    141 | CPU
DEBUG 01-06 17:11:01.494811.494811 lmp.py:414]   Expert 17 |    145 | CPU
DEBUG 01-06 17:11:01.494646.494646 lmp.py:414]   Expert 35 |    149 | CPU
DEBUG 01-06 17:11:01.494335.494335 lmp.py:414]   Expert 47 |    156 | CPU
DEBUG 01-06 17:11:01.494025.494025 lmp.py:414]   Expert 22 |    157 | CPU
DEBUG 01-06 17:11:01.494714.494714 lmp.py:414]   Expert 53 |    168 | CPU
DEBUG 01-06 17:11:01.494403.494403 lmp.py:414]   Expert 36 |    175 | CPU
DEBUG 01-06 17:11:01.494854.494854 lmp.py:414]   Expert 38 |    176 | GPU
DEBUG 01-06 17:11:01.494213.494213 lmp.py:414]   Expert 39 |    176 | GPU
DEBUG 01-06 17:11:01.494902.494902 lmp.py:414]   Expert 58 |    180 | GPU
DEBUG 01-06 17:11:01.494830.494830 lmp.py:414]   Expert 44 |    186 | GPU
DEBUG 01-06 17:11:01.494519.494519 lmp.py:414]   Expert 18 |    188 | GPU
DEBUG 01-06 17:11:01.494970.494970 lmp.py:414]   Expert 52 |    193 | GPU
DEBUG 01-06 17:11:01.494090.494090 lmp.py:414]   Expert 62 |    195 | GPU
DEBUG 01-06 17:11:01.494017.494017 lmp.py:414]   Expert 48 |    207 | GPU
DEBUG 01-06 17:11:01.495707.495707 lmp.py:414]   Expert 11 |    208 | GPU
DEBUG 01-06 17:11:01.495157.495157 lmp.py:414]   Expert 30 |    217 | GPU
DEBUG 01-06 17:11:01.495847.495847 lmp.py:414]   Expert 14 |    219 | GPU
DEBUG 01-06 17:11:01.495536.495536 lmp.py:414]   Expert  1 |    230 | GPU
DEBUG 01-06 17:11:01.495987.495987 lmp.py:414]   Expert  6 |    234 | GPU
DEBUG 01-06 17:11:01.495153.495153 lmp.py:414]   Expert 31 |    235 | GPU
DEBUG 01-06 17:11:01.495227.495227 lmp.py:414]   Expert 45 |    237 | GPU
DEBUG 01-06 17:11:01.495439.495439 lmp.py:414]   Expert 51 |    242 | GPU
DEBUG 01-06 17:11:01.495890.495890 lmp.py:414]   Expert 42 |    243 | GPU
DEBUG 01-06 17:11:01.495341.495341 lmp.py:414]   Expert 29 |    267 | GPU
DEBUG 01-06 17:11:01.495792.495792 lmp.py:414]   Expert 34 |    270 | GPU
DEBUG 01-06 17:11:01.495673.495673 lmp.py:414]   Expert 33 |    275 | GPU
DEBUG 01-06 17:11:01.495078.495078 lmp.py:414]   Expert 57 |    291 | GPU
DEBUG 01-06 17:11:01.495005.495005 lmp.py:414]   Expert 61 |    302 | GPU
DEBUG 01-06 17:11:01.495456.495456 lmp.py:414]   Expert  0 |    313 | GPU
DEBUG 01-06 17:11:01.495145.495145 lmp.py:414]   Expert 43 |    313 | GPU
DEBUG 01-06 17:11:01.495835.495835 lmp.py:414]   Expert 46 |    346 | GPU
DEBUG 01-06 17:11:01.495431.495431 lmp.py:414]   Expert  8 |    369 | GPU
DEBUG 01-06 17:11:01.495121.495121 lmp.py:414]   Expert  9 |    392 | GPU
DEBUG 01-06 17:11:01.495810.495810 lmp.py:414]   Expert 54 |    400 | GPU
DEBUG 01-06 17:11:01.495499.495499 lmp.py:414]   Expert 56 |    401 | GPU
DEBUG 01-06 17:11:01.495189.495189 lmp.py:414]   Expert 63 |    415 | GPU
DEBUG 01-06 17:11:01.495878.495878 lmp.py:414]   Expert 55 |    432 | GPU
DEBUG 01-06 17:11:01.495283.495283 lmp.py:414]   Expert 21 |    480 | GPU
DEBUG 01-06 17:11:01.495594.495594 lmp.py:415] 
DEBUG 01-06 17:11:01.495594.495594 lmp.py:415]   CPU total tokens: 3456 (28.1%)
DEBUG 01-06 17:11:01.495761.495761 lmp.py:416]   GPU total tokens: 8832 (71.9%)
DEBUG 01-06 17:11:01.495172.495172 cuda_h.py:19] end experts_map_get cost 0.0015442371368408203 seconds
DEBUG 01-06 17:11:01.495530.495530 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-06 17:11:01.495890.495890 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 17:11:01.495795.495795 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 17:11:01.497219.497219 cuda_h.py:19] end allocate_cuda_memory cost 0.0013685226440429688 seconds
DEBUG 01-06 17:11:01.497400.497400 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 17:11:01.497203.497203 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 17:11:01.497191.497191 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 17:11:01.497563.497563 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 987b0ec6-8536-4756-a222-f3cc0b5780f7
DEBUG 01-06 17:11:01.497331.497331 client.py:106] call stub.LoadModelAsync
DEBUG 01-06 17:11:01.497858.497858 mlpmodule.py:664]  experts func einsum cost 0.07034635543823242 s
INFO 01-06 17:11:01.498761.498761 client.py:127] Model loaded
DEBUG 01-06 17:11:01.499237.499237 cuda_h.py:19] end sllm_worker_task cost 0.012359857559204102 seconds
INFO 01-06 17:11:01.500075.500075 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 987b0ec6-8536-4756-a222-f3cc0b5780f7
DEBUG 01-06 17:11:01.500110.500110 cuda_h.py:19] end load_into_gpu_async cost 0.0031592845916748047 seconds
DEBUG 01-06 17:11:01.500813.500813 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 17:11:01.500817.500817 cuda_h.py:19] end restore_tensors2 cost 0.0002903938293457031 seconds
DEBUG 01-06 17:11:01.500116.500116 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.005164384841918945 seconds
DEBUG 01-06 17:11:01.503865.503865 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.007803916931152344 seconds
DEBUG 01-06 17:11:01.503026.503026 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-06 17:11:01.503870.503870 lmp.py:461] 
DEBUG 01-06 17:11:01.503870.503870 lmp.py:461]   Computing 32 experts on CPU...
DEBUG 01-06 17:11:01.503998.503998 cuda_h.py:19] end cpu_experts_submit cost 0.00011038780212402344 seconds
DEBUG 01-06 17:11:01.503939.503939 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-06 17:11:01.507364.507364 mlpmodule.py:706] group tensors cost 0.004075527191162109 s
DEBUG 01-06 17:11:01.509235.509235 mlpmodule.py:744] pad cost 0.0015225410461425781 s
DEBUG 01-06 17:11:01.509828.509828 mlpmodule.py:750] create cpu tensor cost 6.580352783203125e-05 s
DEBUG 01-06 17:11:01.509963.509963 mlpmodule.py:755] move to cpu cost 3.0040740966796875e-05 s
DEBUG 01-06 17:11:01.518858.518858 mlpmodule.py:769] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-06 17:11:01.519096.519096 mlpmodule.py:770] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-06 17:11:01.519245.519245 mlpmodule.py:775] group_w3 first element: 0.0157470703125
WARNING 01-06 17:11:01.519237.519237 mlpmodule.py:785] start einsum2
DEBUG 01-06 17:11:01.537700.537700 mlpmodule.py:795] group einsum cost 0.027081727981567383 s
DEBUG 01-06 17:11:01.538030.538030 mlpmodule.py:803] cpy2cputensor cost 0.0007452964782714844 s
DEBUG 01-06 17:11:01.542417.542417 cuda_h.py:19] end wait_cetm_experts cost 0.03935098648071289 seconds
DEBUG 01-06 17:11:01.543294.543294 cuda_h.py:10] start gpu_sexperts
DEBUG 01-06 17:11:01.543835.543835 cuda_h.py:19] end gpu_sexperts cost 0.0004916191101074219 seconds
DEBUG 01-06 17:11:01.543149.543149 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-06 17:11:01.543336.543336 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.3365020751953125e-05 seconds
DEBUG 01-06 17:11:01.543086.543086 cuda_h.py:10] start wait_experts
INFO 01-06 17:11:01.543603.543603 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 987b0ec6-8536-4756-a222-f3cc0b5780f7
INFO 01-06 17:11:01.550555.550555 client.py:127] Model loaded
DEBUG 01-06 17:11:01.550140.550140 cuda_h.py:19] end wait_experts cost 0.007135152816772461 seconds
DEBUG 01-06 17:11:01.550850.550850 cuda_h.py:10] start gpu_experts
DEBUG 01-06 17:11:01.550321.550321 lmp.py:506]   Computing 32 experts on GPU...
DEBUG 01-06 17:11:01.551446.551446 mlpmodule.py:533] gpu group tensors cost 0.0006787776947021484 s
DEBUG 01-06 17:11:01.553052.553052 mlpmodule.py:566] gpu pad cost 0.0016088485717773438 s
DEBUG 01-06 17:11:01.553158.553158 mlpmodule.py:584] gpu group einsum cost 0.0005352497100830078 s
DEBUG 01-06 17:11:01.556086.556086 mlpmodule.py:613] gpu experts func einsum cost 0.00596165657043457 s
DEBUG 01-06 17:11:01.557262.557262 cuda_h.py:19] end gpu_experts cost 0.006138324737548828 seconds
DEBUG 01-06 17:11:01.557430.557430 cuda_h.py:19] end layer_moe_generate_9 cost 0.06402158737182617 seconds
DEBUG 01-06 17:11:01.557310.557310 lmp.py:220] -------------------------------- end layer 9 --------------------------------
DEBUG 01-06 17:11:01.557311.557311 lmp.py:176] -------------------------------- start layer 10 --------------------------------
DEBUG 01-06 17:11:01.557053.557053 cuda_h.py:10] start start_load_qkvogn_s_weight_l_11
DEBUG 01-06 17:11:01.557571.557571 cuda_h.py:10] start start_load_qkvogn_s_weight_l_11
DEBUG 01-06 17:11:01.557897.557897 cuda_h.py:19] end start_load_qkvogn_s_weight_l_11 cost 3.266334533691406e-05 seconds
DEBUG 01-06 17:11:01.557362.557362 cuda_h.py:19] end start_load_qkvogn_s_weight_l_11 cost 6.604194641113281e-05 seconds
DEBUG 01-06 17:11:01.557912.557912 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-06 17:11:01.557265.557265 cuda_h.py:10] start sllm_worker_task
DEBUG 01-06 17:11:01.557936.557936 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 17:11:01.557097.557097 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 17:11:01.562186.562186 cuda_h.py:19] end allocate_cuda_memory cost 0.005012035369873047 seconds
DEBUG 01-06 17:11:01.562971.562971 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 17:11:01.562601.562601 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 17:11:01.562684.562684 mlpmodule.py:367] cuda:1 cuda:1
DEBUG 01-06 17:11:01.563342.563342 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 17:11:01.563551.563551 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 6b72bc6d-b5a3-4248-9299-507fa6a83ae9
DEBUG 01-06 17:11:01.563581.563581 client.py:106] call stub.LoadModelAsync
DEBUG 01-06 17:11:01.563426.563426 mlpmodule.py:664]  experts func einsum cost 0.05974912643432617 s
DEBUG 01-06 17:11:01.563752.563752 cuda_h.py:10] start self_attn
INFO 01-06 17:11:01.564903.564903 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 6b72bc6d-b5a3-4248-9299-507fa6a83ae9
DEBUG 01-06 17:11:01.564322.564322 cuda_h.py:19] end load_into_gpu_async cost 0.0019347667694091797 seconds
DEBUG 01-06 17:11:01.564647.564647 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 17:11:01.564982.564982 cuda_h.py:19] end restore_tensors2 cost 7.43865966796875e-05 seconds
DEBUG 01-06 17:11:01.564791.564791 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0073070526123046875 seconds
INFO 01-06 17:11:01.565012.565012 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 6b72bc6d-b5a3-4248-9299-507fa6a83ae9
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-06 17:11:01.566310.566310 cuda_h.py:19] end self_attn cost 0.0029420852661132812 seconds
DEBUG 01-06 17:11:01.566300.566300 cuda_h.py:19] end iln_self_attn_paln cost 0.009386301040649414 seconds
DEBUG 01-06 17:11:01.566905.566905 cuda_h.py:10] start layer_moe_generate_10
DEBUG 01-06 17:11:01.567621.567621 cuda_h.py:10] start gate
DEBUG 01-06 17:11:01.567339.567339 cuda_h.py:19] end gate cost 0.0006356239318847656 seconds
DEBUG 01-06 17:11:01.567129.567129 cuda_h.py:10] start experts_map_get
DEBUG 01-06 17:11:01.568854.568854 lmp.py:403] 
DEBUG 01-06 17:11:01.568854.568854 lmp.py:403] Expert Token Distribution & Device Allocation:
DEBUG 01-06 17:11:01.568372.568372 lmp.py:404]   Total experts: 64
DEBUG 01-06 17:11:01.568783.568783 lmp.py:405]   CPU experts: 32 (50%)
DEBUG 01-06 17:11:01.568333.568333 lmp.py:406]   GPU experts: 32 (50%)
DEBUG 01-06 17:11:01.568738.568738 lmp.py:407] 
DEBUG 01-06 17:11:01.568738.568738 lmp.py:407]   Expert ID | Tokens | Device
DEBUG 01-06 17:11:01.568381.568381 lmp.py:408]   -----------------------------------
DEBUG 01-06 17:11:01.568746.568746 lmp.py:414]   Expert 43 |     18 | CPU
DEBUG 01-06 17:11:01.568389.568389 lmp.py:414]   Expert 27 |     36 | CPU
DEBUG 01-06 17:11:01.568840.568840 lmp.py:414]   Expert 34 |     49 | CPU
DEBUG 01-06 17:11:01.568052.568052 lmp.py:414]   Expert 56 |     52 | CPU
DEBUG 01-06 17:11:01.568741.568741 lmp.py:414]   Expert 26 |     54 | CPU
DEBUG 01-06 17:11:01.568192.568192 lmp.py:414]   Expert  3 |     55 | CPU
DEBUG 01-06 17:11:01.568166.568166 lmp.py:414]   Expert  4 |     73 | CPU
DEBUG 01-06 17:11:01.568140.568140 lmp.py:414]   Expert 61 |     77 | CPU
DEBUG 01-06 17:11:01.568638.568638 lmp.py:414]   Expert 14 |     91 | CPU
DEBUG 01-06 17:11:01.568135.568135 lmp.py:414]   Expert 38 |     99 | CPU
DEBUG 01-06 17:11:01.568632.568632 lmp.py:414]   Expert  2 |    109 | CPU
DEBUG 01-06 17:11:01.568560.568560 lmp.py:414]   Expert 17 |    116 | CPU
DEBUG 01-06 17:11:01.568918.568918 lmp.py:414]   Expert 47 |    125 | CPU
DEBUG 01-06 17:11:01.568290.568290 lmp.py:414]   Expert 22 |    126 | CPU
DEBUG 01-06 17:11:01.568694.568694 lmp.py:414]   Expert 55 |    128 | CPU
DEBUG 01-06 17:11:01.568099.568099 lmp.py:414]   Expert 37 |    129 | CPU
DEBUG 01-06 17:11:01.568027.568027 lmp.py:414]   Expert 54 |    133 | CPU
DEBUG 01-06 17:11:01.568716.568716 lmp.py:414]   Expert 28 |    136 | CPU
DEBUG 01-06 17:11:01.568405.568405 lmp.py:414]   Expert 15 |    142 | CPU
DEBUG 01-06 17:11:01.568856.568856 lmp.py:414]   Expert 48 |    143 | CPU
DEBUG 01-06 17:11:01.568545.568545 lmp.py:414]   Expert 12 |    144 | CPU
DEBUG 01-06 17:11:01.568996.568996 lmp.py:414]   Expert 51 |    146 | CPU
DEBUG 01-06 17:11:01.568447.568447 lmp.py:414]   Expert 60 |    148 | CPU
DEBUG 01-06 17:11:01.568898.568898 lmp.py:414]   Expert 63 |    148 | CPU
DEBUG 01-06 17:11:01.568826.568826 lmp.py:414]   Expert  5 |    154 | CPU
DEBUG 01-06 17:11:01.568992.568992 lmp.py:414]   Expert 19 |    154 | CPU
DEBUG 01-06 17:11:01.568158.568158 lmp.py:414]   Expert 45 |    154 | CPU
DEBUG 01-06 17:11:01.568801.568801 lmp.py:414]   Expert  7 |    155 | CPU
DEBUG 01-06 17:11:01.568206.568206 lmp.py:414]   Expert  6 |    159 | CPU
DEBUG 01-06 17:11:01.568418.568418 lmp.py:414]   Expert 52 |    164 | CPU
DEBUG 01-06 17:11:01.568107.568107 lmp.py:414]   Expert 57 |    176 | CPU
DEBUG 01-06 17:11:01.568558.568558 lmp.py:414]   Expert 18 |    179 | CPU
DEBUG 01-06 17:11:01.568009.568009 lmp.py:414]   Expert 31 |    181 | GPU
DEBUG 01-06 17:11:01.568460.568460 lmp.py:414]   Expert 44 |    183 | GPU
DEBUG 01-06 17:11:01.568911.568911 lmp.py:414]   Expert 50 |    185 | GPU
DEBUG 01-06 17:11:01.568600.568600 lmp.py:414]   Expert 30 |    186 | GPU
DEBUG 01-06 17:11:01.568051.568051 lmp.py:414]   Expert 13 |    188 | GPU
DEBUG 01-06 17:11:01.568502.568502 lmp.py:414]   Expert 59 |    190 | GPU
DEBUG 01-06 17:11:01.568953.568953 lmp.py:414]   Expert 23 |    193 | GPU
DEBUG 01-06 17:11:01.568834.568834 lmp.py:414]   Expert 53 |    194 | GPU
DEBUG 01-06 17:11:01.568000.568000 lmp.py:414]   Expert 39 |    195 | GPU
DEBUG 01-06 17:11:01.568643.568643 lmp.py:414]   Expert 29 |    201 | GPU
DEBUG 01-06 17:11:01.568048.568048 lmp.py:414]   Expert 20 |    202 | GPU
DEBUG 01-06 17:11:01.568168.568168 lmp.py:414]   Expert 21 |    202 | GPU
DEBUG 01-06 17:11:01.568857.568857 lmp.py:414]   Expert 36 |    209 | GPU
DEBUG 01-06 17:11:01.568546.568546 lmp.py:414]   Expert 16 |    210 | GPU
DEBUG 01-06 17:11:01.568236.568236 lmp.py:414]   Expert 25 |    217 | GPU
DEBUG 01-06 17:11:01.568163.568163 lmp.py:414]   Expert 41 |    217 | GPU
DEBUG 01-06 17:11:01.568614.568614 lmp.py:414]   Expert 32 |    222 | GPU
DEBUG 01-06 17:11:01.569065.569065 lmp.py:414]   Expert 49 |    225 | GPU
DEBUG 01-06 17:11:01.569516.569516 lmp.py:414]   Expert 46 |    231 | GPU
DEBUG 01-06 17:11:01.569967.569967 lmp.py:414]   Expert  8 |    246 | GPU
DEBUG 01-06 17:11:01.569656.569656 lmp.py:414]   Expert 10 |    246 | GPU
DEBUG 01-06 17:11:01.569061.569061 lmp.py:414]   Expert 42 |    254 | GPU
DEBUG 01-06 17:11:01.569465.569465 lmp.py:414]   Expert 62 |    256 | GPU
DEBUG 01-06 17:11:01.569631.569631 lmp.py:414]   Expert 35 |    278 | GPU
DEBUG 01-06 17:11:01.569274.569274 lmp.py:414]   Expert  9 |    287 | GPU
DEBUG 01-06 17:11:01.569725.569725 lmp.py:414]   Expert 33 |    295 | GPU
DEBUG 01-06 17:11:01.569176.569176 lmp.py:414]   Expert 58 |    302 | GPU
DEBUG 01-06 17:11:01.569389.569389 lmp.py:414]   Expert 40 |    395 | GPU
DEBUG 01-06 17:11:01.569840.569840 lmp.py:414]   Expert  0 |    433 | GPU
DEBUG 01-06 17:11:01.569814.569814 lmp.py:414]   Expert 11 |    461 | GPU
DEBUG 01-06 17:11:01.569026.569026 lmp.py:414]   Expert 24 |    558 | GPU
DEBUG 01-06 17:11:01.569477.569477 lmp.py:414]   Expert  1 |    674 | GPU
DEBUG 01-06 17:11:01.569405.569405 lmp.py:415] 
DEBUG 01-06 17:11:01.569405.569405 lmp.py:415]   CPU total tokens: 3772 (30.7%)
DEBUG 01-06 17:11:01.569809.569809 lmp.py:416]   GPU total tokens: 8516 (69.3%)
DEBUG 01-06 17:11:01.569744.569744 cuda_h.py:19] end experts_map_get cost 0.0015118122100830078 seconds
DEBUG 01-06 17:11:01.569102.569102 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-06 17:11:01.569401.569401 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 17:11:01.569439.569439 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 17:11:01.570904.570904 cuda_h.py:19] end allocate_cuda_memory cost 0.0013980865478515625 seconds
DEBUG 01-06 17:11:01.571529.571529 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 17:11:01.571093.571093 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 17:11:01.571048.571048 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 17:11:01.571128.571128 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, ffbbc0f4-ea8a-4638-8e68-52a223393246
DEBUG 01-06 17:11:01.571591.571591 client.py:106] call stub.LoadModelAsync
INFO 01-06 17:11:01.572195.572195 client.py:127] Model loaded
DEBUG 01-06 17:11:01.573286.573286 cuda_h.py:19] end sllm_worker_task cost 0.015599250793457031 seconds
INFO 01-06 17:11:01.574582.574582 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, ffbbc0f4-ea8a-4638-8e68-52a223393246
DEBUG 01-06 17:11:01.574286.574286 cuda_h.py:19] end load_into_gpu_async cost 0.003194570541381836 seconds
DEBUG 01-06 17:11:01.574989.574989 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 17:11:01.574913.574913 cuda_h.py:19] end restore_tensors2 cost 0.00026869773864746094 seconds
DEBUG 01-06 17:11:01.574020.574020 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.00520777702331543 seconds
DEBUG 01-06 17:11:01.577693.577693 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.007917642593383789 seconds
DEBUG 01-06 17:11:01.577052.577052 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-06 17:11:01.577730.577730 lmp.py:461] 
DEBUG 01-06 17:11:01.577730.577730 lmp.py:461]   Computing 32 experts on CPU...
DEBUG 01-06 17:11:01.577242.577242 cuda_h.py:19] end cpu_experts_submit cost 0.00011110305786132812 seconds
DEBUG 01-06 17:11:01.577515.577515 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-06 17:11:01.588814.588814 mlpmodule.py:706] group tensors cost 0.010967493057250977 s
DEBUG 01-06 17:11:01.591956.591956 mlpmodule.py:744] pad cost 0.002313852310180664 s
DEBUG 01-06 17:11:01.591185.591185 mlpmodule.py:750] create cpu tensor cost 5.53131103515625e-05 s
DEBUG 01-06 17:11:01.591354.591354 mlpmodule.py:755] move to cpu cost 3.123283386230469e-05 s
DEBUG 01-06 17:11:01.602689.602689 mlpmodule.py:769] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-06 17:11:01.602268.602268 mlpmodule.py:770] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-06 17:11:01.602028.602028 mlpmodule.py:775] group_w3 first element: -0.0213623046875
WARNING 01-06 17:11:01.602378.602378 mlpmodule.py:785] start einsum2
DEBUG 01-06 17:11:01.618855.618855 mlpmodule.py:795] group einsum cost 0.0261685848236084 s
DEBUG 01-06 17:11:01.619529.619529 mlpmodule.py:803] cpy2cputensor cost 0.0007569789886474609 s
DEBUG 01-06 17:11:01.623692.623692 cuda_h.py:19] end wait_cetm_experts cost 0.04639840126037598 seconds
DEBUG 01-06 17:11:01.624324.624324 cuda_h.py:10] start gpu_sexperts
DEBUG 01-06 17:11:01.624091.624091 cuda_h.py:19] end gpu_sexperts cost 0.0005228519439697266 seconds
DEBUG 01-06 17:11:01.624457.624457 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-06 17:11:01.624877.624877 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.3365020751953125e-05 seconds
DEBUG 01-06 17:11:01.624057.624057 cuda_h.py:10] start wait_experts
INFO 01-06 17:11:01.624481.624481 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, ffbbc0f4-ea8a-4638-8e68-52a223393246
INFO 01-06 17:11:01.625370.625370 client.py:127] Model loaded
DEBUG 01-06 17:11:01.626306.626306 cuda_h.py:19] end wait_experts cost 0.001276254653930664 seconds
DEBUG 01-06 17:11:01.626201.626201 cuda_h.py:10] start gpu_experts
DEBUG 01-06 17:11:01.626288.626288 lmp.py:506]   Computing 32 experts on GPU...
DEBUG 01-06 17:11:01.626669.626669 mlpmodule.py:533] gpu group tensors cost 0.0006253719329833984 s
DEBUG 01-06 17:11:01.628325.628325 mlpmodule.py:566] gpu pad cost 0.0017290115356445312 s
DEBUG 01-06 17:11:01.629074.629074 mlpmodule.py:584] gpu group einsum cost 0.000545501708984375 s
DEBUG 01-06 17:11:01.632508.632508 mlpmodule.py:613] gpu experts func einsum cost 0.0065081119537353516 s
DEBUG 01-06 17:11:01.632160.632160 cuda_h.py:19] end gpu_experts cost 0.006682872772216797 seconds
DEBUG 01-06 17:11:01.632521.632521 cuda_h.py:19] end layer_moe_generate_10 cost 0.06583428382873535 seconds
DEBUG 01-06 17:11:01.633858.633858 lmp.py:220] -------------------------------- end layer 10 --------------------------------
DEBUG 01-06 17:11:01.633244.633244 lmp.py:176] -------------------------------- start layer 11 --------------------------------
DEBUG 01-06 17:11:01.633231.633231 cuda_h.py:10] start start_load_qkvogn_s_weight_l_12
DEBUG 01-06 17:11:01.633517.633517 cuda_h.py:10] start start_load_qkvogn_s_weight_l_12
DEBUG 01-06 17:11:01.633367.633367 cuda_h.py:19] end start_load_qkvogn_s_weight_l_12 cost 3.4332275390625e-05 seconds
DEBUG 01-06 17:11:01.633315.633315 cuda_h.py:19] end start_load_qkvogn_s_weight_l_12 cost 6.985664367675781e-05 seconds
DEBUG 01-06 17:11:01.633680.633680 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-06 17:11:01.633881.633881 mlpmodule.py:367] cuda:1 cuda:1
DEBUG 01-06 17:11:01.633009.633009 cuda_h.py:10] start sllm_worker_task
DEBUG 01-06 17:11:01.633980.633980 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 17:11:01.633062.633062 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 17:11:01.636385.636385 cuda_h.py:19] end allocate_cuda_memory cost 0.0026900768280029297 seconds
DEBUG 01-06 17:11:01.636593.636593 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 17:11:01.636920.636920 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 17:11:01.636650.636650 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 17:11:01.636068.636068 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, c728f7f7-362d-4e0f-b410-854237efb330
DEBUG 01-06 17:11:01.636753.636753 client.py:106] call stub.LoadModelAsync
DEBUG 01-06 17:11:01.637720.637720 cuda_h.py:10] start self_attn
INFO 01-06 17:11:01.637413.637413 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, c728f7f7-362d-4e0f-b410-854237efb330
DEBUG 01-06 17:11:01.638872.638872 cuda_h.py:19] end load_into_gpu_async cost 0.0015447139739990234 seconds
DEBUG 01-06 17:11:01.638667.638667 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 17:11:01.638035.638035 cuda_h.py:19] end restore_tensors2 cost 6.961822509765625e-05 seconds
DEBUG 01-06 17:11:01.638360.638360 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.004600048065185547 seconds
INFO 01-06 17:11:01.638243.638243 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, c728f7f7-362d-4e0f-b410-854237efb330
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-06 17:11:01.639043.639043 cuda_h.py:19] end self_attn cost 0.002860546112060547 seconds
DEBUG 01-06 17:11:01.640974.640974 cuda_h.py:19] end iln_self_attn_paln cost 0.00696110725402832 seconds
DEBUG 01-06 17:11:01.640863.640863 cuda_h.py:10] start layer_moe_generate_11
DEBUG 01-06 17:11:01.640626.640626 cuda_h.py:10] start gate
DEBUG 01-06 17:11:01.641139.641139 cuda_h.py:19] end gate cost 0.0006606578826904297 seconds
DEBUG 01-06 17:11:01.641300.641300 cuda_h.py:10] start experts_map_get
DEBUG 01-06 17:11:01.641270.641270 lmp.py:403] 
DEBUG 01-06 17:11:01.641270.641270 lmp.py:403] Expert Token Distribution & Device Allocation:
DEBUG 01-06 17:11:01.641549.641549 lmp.py:404]   Total experts: 64
DEBUG 01-06 17:11:01.641007.641007 lmp.py:405]   CPU experts: 32 (50%)
DEBUG 01-06 17:11:01.641842.641842 lmp.py:406]   GPU experts: 32 (50%)
DEBUG 01-06 17:11:01.641723.641723 lmp.py:407] 
DEBUG 01-06 17:11:01.641723.641723 lmp.py:407]   Expert ID | Tokens | Device
DEBUG 01-06 17:11:01.641128.641128 lmp.py:408]   -----------------------------------
DEBUG 01-06 17:11:01.641493.641493 lmp.py:414]   Expert 39 |     16 | CPU
DEBUG 01-06 17:11:01.641374.641374 lmp.py:414]   Expert 13 |     22 | CPU
DEBUG 01-06 17:11:01.641064.641064 lmp.py:414]   Expert 49 |     39 | CPU
DEBUG 01-06 17:11:01.641514.641514 lmp.py:414]   Expert 35 |     51 | CPU
DEBUG 01-06 17:11:01.641741.641741 lmp.py:414]   Expert 19 |     65 | CPU
DEBUG 01-06 17:11:01.641476.641476 lmp.py:414]   Expert 26 |     71 | CPU
DEBUG 01-06 17:11:01.641735.641735 lmp.py:414]   Expert 32 |     73 | CPU
DEBUG 01-06 17:11:01.641994.641994 lmp.py:414]   Expert 41 |     74 | CPU
DEBUG 01-06 17:11:01.641253.641253 lmp.py:414]   Expert  9 |     78 | CPU
DEBUG 01-06 17:11:01.641227.641227 lmp.py:414]   Expert 33 |     86 | CPU
DEBUG 01-06 17:11:01.641439.641439 lmp.py:414]   Expert 23 |     87 | CPU
DEBUG 01-06 17:11:01.641651.641651 lmp.py:414]   Expert 31 |     88 | CPU
DEBUG 01-06 17:11:01.641626.641626 lmp.py:414]   Expert 46 |     89 | CPU
DEBUG 01-06 17:11:01.641838.641838 lmp.py:414]   Expert 18 |     95 | CPU
DEBUG 01-06 17:11:01.641534.641534 lmp.py:414]   Expert 38 |     99 | CPU
DEBUG 01-06 17:11:01.641223.641223 lmp.py:414]   Expert  6 |    104 | CPU
DEBUG 01-06 17:11:01.641721.641721 lmp.py:414]   Expert 17 |    104 | CPU
DEBUG 01-06 17:11:01.641979.641979 lmp.py:414]   Expert  3 |    109 | CPU
DEBUG 01-06 17:11:01.641715.641715 lmp.py:414]   Expert 20 |    116 | CPU
DEBUG 01-06 17:11:01.641974.641974 lmp.py:414]   Expert 59 |    128 | CPU
DEBUG 01-06 17:11:01.641471.641471 lmp.py:414]   Expert 62 |    128 | CPU
DEBUG 01-06 17:11:01.641968.641968 lmp.py:414]   Expert 40 |    129 | CPU
DEBUG 01-06 17:11:01.641493.641493 lmp.py:414]   Expert 15 |    130 | CPU
DEBUG 01-06 17:11:01.641427.641427 lmp.py:414]   Expert 61 |    132 | CPU
DEBUG 01-06 17:11:01.641024.641024 lmp.py:414]   Expert 43 |    135 | CPU
DEBUG 01-06 17:11:01.641574.641574 lmp.py:414]   Expert 16 |    136 | CPU
DEBUG 01-06 17:11:01.641648.641648 lmp.py:414]   Expert 50 |    138 | CPU
DEBUG 01-06 17:11:01.641052.641052 lmp.py:414]   Expert 63 |    143 | CPU
DEBUG 01-06 17:11:01.642172.642172 lmp.py:414]   Expert 42 |    144 | CPU
DEBUG 01-06 17:11:01.642338.642338 lmp.py:414]   Expert 44 |    144 | CPU
DEBUG 01-06 17:11:01.642981.642981 lmp.py:414]   Expert  2 |    145 | CPU
DEBUG 01-06 17:11:01.642670.642670 lmp.py:414]   Expert 36 |    152 | CPU
DEBUG 01-06 17:11:01.642313.642313 lmp.py:414]   Expert 10 |    160 | GPU
DEBUG 01-06 17:11:01.642479.642479 lmp.py:414]   Expert  5 |    177 | GPU
DEBUG 01-06 17:11:01.642361.642361 lmp.py:414]   Expert 34 |    181 | GPU
DEBUG 01-06 17:11:01.642481.642481 lmp.py:414]   Expert 45 |    185 | GPU
DEBUG 01-06 17:11:01.642839.642839 lmp.py:414]   Expert 27 |    188 | GPU
DEBUG 01-06 17:11:01.642243.642243 lmp.py:414]   Expert 52 |    193 | GPU
DEBUG 01-06 17:11:01.642363.642363 lmp.py:414]   Expert 60 |    200 | GPU
DEBUG 01-06 17:11:01.642529.642529 lmp.py:414]   Expert 48 |    201 | GPU
DEBUG 01-06 17:11:01.642649.642649 lmp.py:414]   Expert 51 |    210 | GPU
DEBUG 01-06 17:11:01.642100.642100 lmp.py:414]   Expert 56 |    215 | GPU
DEBUG 01-06 17:11:01.642743.642743 lmp.py:414]   Expert  7 |    225 | GPU
DEBUG 01-06 17:11:01.642432.642432 lmp.py:414]   Expert 24 |    228 | GPU
DEBUG 01-06 17:11:01.642989.642989 lmp.py:414]   Expert 53 |    231 | GPU
DEBUG 01-06 17:11:01.642679.642679 lmp.py:414]   Expert  8 |    237 | GPU
DEBUG 01-06 17:11:01.642845.642845 lmp.py:414]   Expert 57 |    249 | GPU
DEBUG 01-06 17:11:01.642296.642296 lmp.py:414]   Expert 29 |    257 | GPU
DEBUG 01-06 17:11:01.642462.642462 lmp.py:414]   Expert 47 |    258 | GPU
DEBUG 01-06 17:11:01.642866.642866 lmp.py:414]   Expert 21 |    266 | GPU
DEBUG 01-06 17:11:01.642225.642225 lmp.py:414]   Expert  4 |    281 | GPU
DEBUG 01-06 17:11:01.642629.642629 lmp.py:414]   Expert  0 |    284 | GPU
DEBUG 01-06 17:11:01.642272.642272 lmp.py:414]   Expert 14 |    287 | GPU
DEBUG 01-06 17:11:01.642200.642200 lmp.py:414]   Expert 55 |    311 | GPU
DEBUG 01-06 17:11:01.642605.642605 lmp.py:414]   Expert 22 |    314 | GPU
DEBUG 01-06 17:11:01.642817.642817 lmp.py:414]   Expert 37 |    316 | GPU
DEBUG 01-06 17:11:01.642745.642745 lmp.py:414]   Expert  1 |    322 | GPU
DEBUG 01-06 17:11:01.642434.642434 lmp.py:414]   Expert 58 |    338 | GPU
DEBUG 01-06 17:11:01.642839.642839 lmp.py:414]   Expert 54 |    340 | GPU
DEBUG 01-06 17:11:01.642289.642289 lmp.py:414]   Expert 28 |    355 | GPU
DEBUG 01-06 17:11:01.642932.642932 lmp.py:414]   Expert 12 |    372 | GPU
DEBUG 01-06 17:11:01.642099.642099 lmp.py:414]   Expert 25 |    397 | GPU
DEBUG 01-06 17:11:01.642457.642457 lmp.py:414]   Expert 11 |    405 | GPU
DEBUG 01-06 17:11:01.642384.642384 lmp.py:414]   Expert 30 |    855 | GPU
DEBUG 01-06 17:11:01.642220.642220 lmp.py:415] 
DEBUG 01-06 17:11:01.642220.642220 lmp.py:415]   CPU total tokens: 3250 (26.4%)
DEBUG 01-06 17:11:01.642531.642531 lmp.py:416]   GPU total tokens: 9038 (73.6%)
DEBUG 01-06 17:11:01.642135.642135 cuda_h.py:19] end experts_map_get cost 0.0015702247619628906 seconds
DEBUG 01-06 17:11:01.642255.642255 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-06 17:11:01.642369.642369 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 17:11:01.642221.642221 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 17:11:01.644822.644822 cuda_h.py:19] end allocate_cuda_memory cost 0.0012869834899902344 seconds
DEBUG 01-06 17:11:01.644334.644334 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 17:11:01.644805.644805 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 17:11:01.644535.644535 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 17:11:01.644854.644854 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, d58b296a-a6e6-4dac-8577-d61e4e39d4f2
DEBUG 01-06 17:11:01.644304.644304 client.py:106] call stub.LoadModelAsync
DEBUG 01-06 17:11:01.644934.644934 mlpmodule.py:664]  experts func einsum cost 0.06716489791870117 s
INFO 01-06 17:11:01.646102.646102 client.py:127] Model loaded
DEBUG 01-06 17:11:01.646019.646019 cuda_h.py:19] end sllm_worker_task cost 0.013226985931396484 seconds
INFO 01-06 17:11:01.647463.647463 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, d58b296a-a6e6-4dac-8577-d61e4e39d4f2
DEBUG 01-06 17:11:01.647044.647044 cuda_h.py:19] end load_into_gpu_async cost 0.003351449966430664 seconds
DEBUG 01-06 17:11:01.647391.647391 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 17:11:01.648852.648852 cuda_h.py:19] end restore_tensors2 cost 0.0004515647888183594 seconds
DEBUG 01-06 17:11:01.648436.648436 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.005539655685424805 seconds
DEBUG 01-06 17:11:01.650979.650979 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.008160114288330078 seconds
DEBUG 01-06 17:11:01.650855.650855 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-06 17:11:01.651911.651911 lmp.py:461] 
DEBUG 01-06 17:11:01.651911.651911 lmp.py:461]   Computing 32 experts on CPU...
DEBUG 01-06 17:11:01.651707.651707 cuda_h.py:19] end cpu_experts_submit cost 0.00010967254638671875 seconds
DEBUG 01-06 17:11:01.651788.651788 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-06 17:11:01.660143.660143 mlpmodule.py:706] group tensors cost 0.008866548538208008 s
DEBUG 01-06 17:11:01.662530.662530 mlpmodule.py:744] pad cost 0.0016341209411621094 s
DEBUG 01-06 17:11:01.662871.662871 mlpmodule.py:750] create cpu tensor cost 5.173683166503906e-05 s
DEBUG 01-06 17:11:01.662020.662020 mlpmodule.py:755] move to cpu cost 4.1484832763671875e-05 s
DEBUG 01-06 17:11:01.673018.673018 mlpmodule.py:769] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-06 17:11:01.674324.674324 mlpmodule.py:770] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-06 17:11:01.674381.674381 mlpmodule.py:775] group_w3 first element: -0.006134033203125
WARNING 01-06 17:11:01.674968.674968 mlpmodule.py:785] start einsum2
DEBUG 01-06 17:11:01.692185.692185 mlpmodule.py:795] group einsum cost 0.029566526412963867 s
DEBUG 01-06 17:11:01.693296.693296 mlpmodule.py:803] cpy2cputensor cost 0.0006940364837646484 s
DEBUG 01-06 17:11:01.698247.698247 cuda_h.py:19] end wait_cetm_experts cost 0.04706168174743652 seconds
DEBUG 01-06 17:11:01.698776.698776 cuda_h.py:10] start gpu_sexperts
DEBUG 01-06 17:11:01.699394.699394 cuda_h.py:19] end gpu_sexperts cost 0.0006189346313476562 seconds
DEBUG 01-06 17:11:01.699767.699767 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-06 17:11:01.699425.699425 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.3365020751953125e-05 seconds
DEBUG 01-06 17:11:01.699850.699850 cuda_h.py:10] start wait_experts
INFO 01-06 17:11:01.699375.699375 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, d58b296a-a6e6-4dac-8577-d61e4e39d4f2
INFO 01-06 17:11:01.700884.700884 client.py:127] Model loaded
DEBUG 01-06 17:11:01.700071.700071 cuda_h.py:19] end wait_experts cost 0.0014302730560302734 seconds
DEBUG 01-06 17:11:01.700112.700112 cuda_h.py:10] start gpu_experts
DEBUG 01-06 17:11:01.700391.700391 lmp.py:506]   Computing 32 experts on GPU...
DEBUG 01-06 17:11:01.701295.701295 mlpmodule.py:533] gpu group tensors cost 0.000614166259765625 s
DEBUG 01-06 17:11:01.703740.703740 mlpmodule.py:566] gpu pad cost 0.0017502307891845703 s
DEBUG 01-06 17:11:01.703879.703879 mlpmodule.py:584] gpu group einsum cost 0.0005211830139160156 s
DEBUG 01-06 17:11:01.707036.707036 mlpmodule.py:613] gpu experts func einsum cost 0.006494998931884766 s
DEBUG 01-06 17:11:01.707542.707542 cuda_h.py:19] end gpu_experts cost 0.0066776275634765625 seconds
DEBUG 01-06 17:11:01.707187.707187 cuda_h.py:19] end layer_moe_generate_11 cost 0.06720137596130371 seconds
DEBUG 01-06 17:11:01.707399.707399 lmp.py:220] -------------------------------- end layer 11 --------------------------------
DEBUG 01-06 17:11:01.707169.707169 lmp.py:176] -------------------------------- start layer 12 --------------------------------
DEBUG 01-06 17:11:01.707487.707487 cuda_h.py:10] start start_load_qkvogn_s_weight_l_13
DEBUG 01-06 17:11:01.707343.707343 cuda_h.py:10] start start_load_qkvogn_s_weight_l_13
DEBUG 01-06 17:11:01.707769.707769 cuda_h.py:19] end start_load_qkvogn_s_weight_l_13 cost 3.790855407714844e-05 seconds
DEBUG 01-06 17:11:01.707764.707764 cuda_h.py:10] start sllm_worker_task
DEBUG 01-06 17:11:01.708402.708402 cuda_h.py:19] end start_load_qkvogn_s_weight_l_13 cost 0.00015425682067871094 seconds
DEBUG 01-06 17:11:01.708941.708941 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 17:11:01.708572.708572 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-06 17:11:01.708375.708375 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 17:11:01.710536.710536 cuda_h.py:19] end allocate_cuda_memory cost 0.0017452239990234375 seconds
DEBUG 01-06 17:11:01.710249.710249 mlpmodule.py:367] cuda:1 cuda:1
DEBUG 01-06 17:11:01.710430.710430 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 17:11:01.710819.710819 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 17:11:01.710695.710695 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 17:11:01.710352.710352 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, c6806a0c-1944-4f67-aca1-dff383f8b9aa
DEBUG 01-06 17:11:01.710891.710891 client.py:106] call stub.LoadModelAsync
DEBUG 01-06 17:11:01.710484.710484 cuda_h.py:10] start self_attn
INFO 01-06 17:11:01.711107.711107 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, c6806a0c-1944-4f67-aca1-dff383f8b9aa
DEBUG 01-06 17:11:01.711566.711566 cuda_h.py:19] end load_into_gpu_async cost 0.0015363693237304688 seconds
DEBUG 01-06 17:11:01.711600.711600 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 17:11:01.712206.712206 cuda_h.py:19] end restore_tensors2 cost 6.890296936035156e-05 seconds
DEBUG 01-06 17:11:01.712008.712008 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0038957595825195312 seconds
INFO 01-06 17:11:01.712983.712983 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, c6806a0c-1944-4f67-aca1-dff383f8b9aa
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-06 17:11:01.713088.713088 cuda_h.py:19] end self_attn cost 0.002946138381958008 seconds
DEBUG 01-06 17:11:01.714958.714958 cuda_h.py:19] end iln_self_attn_paln cost 0.00589442253112793 seconds
DEBUG 01-06 17:11:01.714940.714940 cuda_h.py:10] start layer_moe_generate_12
DEBUG 01-06 17:11:01.714703.714703 cuda_h.py:10] start gate
DEBUG 01-06 17:11:01.714607.714607 cuda_h.py:19] end gate cost 0.0006525516510009766 seconds
DEBUG 01-06 17:11:01.714768.714768 cuda_h.py:10] start experts_map_get
DEBUG 01-06 17:11:01.715354.715354 lmp.py:403] 
DEBUG 01-06 17:11:01.715354.715354 lmp.py:403] Expert Token Distribution & Device Allocation:
DEBUG 01-06 17:11:01.715395.715395 lmp.py:404]   Total experts: 64
DEBUG 01-06 17:11:01.715567.715567 lmp.py:405]   CPU experts: 32 (50%)
DEBUG 01-06 17:11:01.715403.715403 lmp.py:406]   GPU experts: 32 (50%)
DEBUG 01-06 17:11:01.715052.715052 lmp.py:407] 
DEBUG 01-06 17:11:01.715052.715052 lmp.py:407]   Expert ID | Tokens | Device
DEBUG 01-06 17:11:01.715411.715411 lmp.py:408]   -----------------------------------
DEBUG 01-06 17:11:01.715776.715776 lmp.py:414]   Expert 12 |     20 | CPU
DEBUG 01-06 17:11:01.715180.715180 lmp.py:414]   Expert 47 |     24 | CPU
DEBUG 01-06 17:11:01.715538.715538 lmp.py:414]   Expert 27 |     30 | CPU
DEBUG 01-06 17:11:01.715181.715181 lmp.py:414]   Expert 38 |     30 | CPU
DEBUG 01-06 17:11:01.715301.715301 lmp.py:414]   Expert 16 |     37 | CPU
DEBUG 01-06 17:11:01.715898.715898 lmp.py:414]   Expert 52 |     37 | CPU
DEBUG 01-06 17:11:01.715779.715779 lmp.py:414]   Expert 63 |     45 | CPU
DEBUG 01-06 17:11:01.715899.715899 lmp.py:414]   Expert  4 |     56 | CPU
DEBUG 01-06 17:11:01.715734.715734 lmp.py:414]   Expert 43 |     58 | CPU
DEBUG 01-06 17:11:01.715331.715331 lmp.py:414]   Expert 61 |     63 | CPU
DEBUG 01-06 17:11:01.715689.715689 lmp.py:414]   Expert 34 |     71 | CPU
DEBUG 01-06 17:11:01.715286.715286 lmp.py:414]   Expert 44 |     71 | CPU
DEBUG 01-06 17:11:01.715405.715405 lmp.py:414]   Expert 53 |     82 | CPU
DEBUG 01-06 17:11:01.715525.715525 lmp.py:414]   Expert 32 |     86 | CPU
DEBUG 01-06 17:11:01.715168.715168 lmp.py:414]   Expert  0 |     87 | CPU
DEBUG 01-06 17:11:01.715050.715050 lmp.py:414]   Expert 37 |     88 | CPU
DEBUG 01-06 17:11:01.715931.715931 lmp.py:414]   Expert 13 |     97 | CPU
DEBUG 01-06 17:11:01.715812.715812 lmp.py:414]   Expert 21 |    115 | CPU
DEBUG 01-06 17:11:01.715455.715455 lmp.py:414]   Expert 39 |    115 | CPU
DEBUG 01-06 17:11:01.715860.715860 lmp.py:414]   Expert 11 |    125 | CPU
DEBUG 01-06 17:11:01.715026.715026 lmp.py:414]   Expert  8 |    131 | CPU
DEBUG 01-06 17:11:01.715669.715669 lmp.py:414]   Expert 20 |    132 | CPU
DEBUG 01-06 17:11:01.715312.715312 lmp.py:414]   Expert 60 |    133 | CPU
DEBUG 01-06 17:11:01.715432.715432 lmp.py:414]   Expert 57 |    139 | CPU
DEBUG 01-06 17:11:01.715552.715552 lmp.py:414]   Expert 14 |    141 | CPU
DEBUG 01-06 17:11:01.715148.715148 lmp.py:414]   Expert 22 |    144 | CPU
DEBUG 01-06 17:11:01.715745.715745 lmp.py:414]   Expert 45 |    151 | CPU
DEBUG 01-06 17:11:01.715388.715388 lmp.py:414]   Expert  2 |    152 | CPU
DEBUG 01-06 17:11:01.715031.715031 lmp.py:414]   Expert 17 |    158 | CPU
DEBUG 01-06 17:11:01.715912.715912 lmp.py:414]   Expert 23 |    160 | CPU
DEBUG 01-06 17:11:01.715032.715032 lmp.py:414]   Expert 30 |    160 | CPU
DEBUG 01-06 17:11:01.715675.715675 lmp.py:414]   Expert 18 |    162 | CPU
DEBUG 01-06 17:11:01.716033.716033 lmp.py:414]   Expert 58 |    164 | GPU
DEBUG 01-06 17:11:01.716392.716392 lmp.py:414]   Expert  7 |    165 | GPU
DEBUG 01-06 17:11:01.716227.716227 lmp.py:414]   Expert 42 |    169 | GPU
DEBUG 01-06 17:11:01.716823.716823 lmp.py:414]   Expert 51 |    170 | GPU
DEBUG 01-06 17:11:01.716466.716466 lmp.py:414]   Expert 49 |    176 | GPU
DEBUG 01-06 17:11:01.716586.716586 lmp.py:414]   Expert 55 |    176 | GPU
DEBUG 01-06 17:11:01.716706.716706 lmp.py:414]   Expert 29 |    179 | GPU
DEBUG 01-06 17:11:01.716587.716587 lmp.py:414]   Expert 48 |    181 | GPU
DEBUG 01-06 17:11:01.716992.716992 lmp.py:414]   Expert 62 |    182 | GPU
DEBUG 01-06 17:11:01.716112.716112 lmp.py:414]   Expert 35 |    185 | GPU
DEBUG 01-06 17:11:01.716755.716755 lmp.py:414]   Expert 36 |    194 | GPU
DEBUG 01-06 17:11:01.716113.716113 lmp.py:414]   Expert  1 |    196 | GPU
DEBUG 01-06 17:11:01.716186.716186 lmp.py:414]   Expert 25 |    197 | GPU
DEBUG 01-06 17:11:01.716545.716545 lmp.py:414]   Expert 31 |    198 | GPU
DEBUG 01-06 17:11:01.716810.716810 lmp.py:414]   Expert  6 |    199 | GPU
DEBUG 01-06 17:11:01.716566.716566 lmp.py:414]   Expert 28 |    224 | GPU
DEBUG 01-06 17:11:01.716924.716924 lmp.py:414]   Expert 41 |    227 | GPU
DEBUG 01-06 17:11:01.716806.716806 lmp.py:414]   Expert 54 |    228 | GPU
DEBUG 01-06 17:11:01.716210.716210 lmp.py:414]   Expert  5 |    235 | GPU
DEBUG 01-06 17:11:01.716092.716092 lmp.py:414]   Expert 19 |    238 | GPU
DEBUG 01-06 17:11:01.716688.716688 lmp.py:414]   Expert  9 |    239 | GPU
DEBUG 01-06 17:11:01.716868.716868 lmp.py:414]   Expert 24 |    246 | GPU
DEBUG 01-06 17:11:01.716849.716849 lmp.py:414]   Expert 50 |    281 | GPU
DEBUG 01-06 17:11:01.716253.716253 lmp.py:414]   Expert 59 |    305 | GPU
DEBUG 01-06 17:11:01.716088.716088 lmp.py:414]   Expert 46 |    307 | GPU
DEBUG 01-06 17:11:01.716493.716493 lmp.py:414]   Expert 56 |    387 | GPU
DEBUG 01-06 17:11:01.716613.716613 lmp.py:414]   Expert 26 |    395 | GPU
DEBUG 01-06 17:11:01.716541.716541 lmp.py:414]   Expert 33 |    434 | GPU
DEBUG 01-06 17:11:01.716184.716184 lmp.py:414]   Expert  3 |    586 | GPU
DEBUG 01-06 17:11:01.716111.716111 lmp.py:414]   Expert 15 |    658 | GPU
DEBUG 01-06 17:11:01.716754.716754 lmp.py:414]   Expert 10 |    690 | GPU
DEBUG 01-06 17:11:01.716444.716444 lmp.py:414]   Expert 40 |    777 | GPU
DEBUG 01-06 17:11:01.716040.716040 lmp.py:415] 
DEBUG 01-06 17:11:01.716040.716040 lmp.py:415]   CPU total tokens: 3100 (25.2%)
DEBUG 01-06 17:11:01.716160.716160 lmp.py:416]   GPU total tokens: 9188 (74.8%)
DEBUG 01-06 17:11:01.716002.716002 cuda_h.py:19] end experts_map_get cost 0.0016188621520996094 seconds
DEBUG 01-06 17:11:01.716314.716314 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-06 17:11:01.716190.716190 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 17:11:01.716327.716327 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 17:11:01.718675.718675 cuda_h.py:19] end allocate_cuda_memory cost 0.0012767314910888672 seconds
DEBUG 01-06 17:11:01.718280.718280 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 17:11:01.718751.718751 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 17:11:01.718183.718183 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 17:11:01.718217.718217 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 7e378c48-0fd7-4573-a91b-ca514f204563
DEBUG 01-06 17:11:01.718924.718924 client.py:106] call stub.LoadModelAsync
DEBUG 01-06 17:11:01.718686.718686 mlpmodule.py:664]  experts func einsum cost 0.0674293041229248 s
INFO 01-06 17:11:01.719005.719005 client.py:127] Model loaded
DEBUG 01-06 17:11:01.720715.720715 cuda_h.py:19] end sllm_worker_task cost 0.012232542037963867 seconds
INFO 01-06 17:11:01.721873.721873 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 7e378c48-0fd7-4573-a91b-ca514f204563
DEBUG 01-06 17:11:01.721809.721809 cuda_h.py:19] end load_into_gpu_async cost 0.0033063888549804688 seconds
DEBUG 01-06 17:11:01.721889.721889 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 17:11:01.721721.721721 cuda_h.py:19] end restore_tensors2 cost 0.0003075599670410156 seconds
DEBUG 01-06 17:11:01.721398.721398 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0052220821380615234 seconds
DEBUG 01-06 17:11:01.724320.724320 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.007875919342041016 seconds
DEBUG 01-06 17:11:01.724011.724011 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-06 17:11:01.724689.724689 lmp.py:461] 
DEBUG 01-06 17:11:01.724689.724689 lmp.py:461]   Computing 32 experts on CPU...
DEBUG 01-06 17:11:01.724347.724347 cuda_h.py:19] end cpu_experts_submit cost 0.00011348724365234375 seconds
DEBUG 01-06 17:11:01.724864.724864 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-06 17:11:01.735776.735776 mlpmodule.py:706] group tensors cost 0.010030984878540039 s
DEBUG 01-06 17:11:01.737554.737554 mlpmodule.py:744] pad cost 0.001901865005493164 s
DEBUG 01-06 17:11:01.737565.737565 mlpmodule.py:750] create cpu tensor cost 5.1975250244140625e-05 s
DEBUG 01-06 17:11:01.737521.737521 mlpmodule.py:755] move to cpu cost 3.695487976074219e-05 s
DEBUG 01-06 17:11:01.748705.748705 mlpmodule.py:769] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-06 17:11:01.749784.749784 mlpmodule.py:770] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-06 17:11:01.749556.749556 mlpmodule.py:775] group_w3 first element: -0.0162353515625
WARNING 01-06 17:11:01.749674.749674 mlpmodule.py:785] start einsum2
DEBUG 01-06 17:11:01.767066.767066 mlpmodule.py:795] group einsum cost 0.029033660888671875 s
DEBUG 01-06 17:11:01.767706.767706 mlpmodule.py:803] cpy2cputensor cost 0.0006885528564453125 s
DEBUG 01-06 17:11:01.775533.775533 cuda_h.py:19] end wait_cetm_experts cost 0.05076289176940918 seconds
DEBUG 01-06 17:11:01.775831.775831 cuda_h.py:10] start gpu_sexperts
DEBUG 01-06 17:11:01.776251.776251 cuda_h.py:19] end gpu_sexperts cost 0.0006139278411865234 seconds
DEBUG 01-06 17:11:01.776008.776008 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-06 17:11:01.776858.776858 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.3603439331054688e-05 seconds
DEBUG 01-06 17:11:01.776514.776514 cuda_h.py:10] start wait_experts
INFO 01-06 17:11:01.776985.776985 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 7e378c48-0fd7-4573-a91b-ca514f204563
INFO 01-06 17:11:01.777980.777980 client.py:127] Model loaded
DEBUG 01-06 17:11:01.777916.777916 cuda_h.py:19] end wait_experts cost 0.001283884048461914 seconds
DEBUG 01-06 17:11:01.777049.777049 cuda_h.py:10] start gpu_experts
DEBUG 01-06 17:11:01.778328.778328 lmp.py:506]   Computing 32 experts on GPU...
DEBUG 01-06 17:11:01.778200.778200 mlpmodule.py:533] gpu group tensors cost 0.0006282329559326172 s
DEBUG 01-06 17:11:01.780546.780546 mlpmodule.py:566] gpu pad cost 0.0017764568328857422 s
DEBUG 01-06 17:11:01.781156.781156 mlpmodule.py:584] gpu group einsum cost 0.0005447864532470703 s
DEBUG 01-06 17:11:01.784648.784648 mlpmodule.py:613] gpu experts func einsum cost 0.0062863826751708984 s
DEBUG 01-06 17:11:01.784401.784401 cuda_h.py:19] end gpu_experts cost 0.006514310836791992 seconds
DEBUG 01-06 17:11:01.784092.784092 cuda_h.py:19] end layer_moe_generate_12 cost 0.07037615776062012 seconds
DEBUG 01-06 17:11:01.784654.784654 lmp.py:220] -------------------------------- end layer 12 --------------------------------
DEBUG 01-06 17:11:01.784656.784656 lmp.py:176] -------------------------------- start layer 13 --------------------------------
DEBUG 01-06 17:11:01.784875.784875 cuda_h.py:10] start start_load_qkvogn_s_weight_l_14
DEBUG 01-06 17:11:01.784108.784108 cuda_h.py:10] start start_load_qkvogn_s_weight_l_14
DEBUG 01-06 17:11:01.784759.784759 cuda_h.py:19] end start_load_qkvogn_s_weight_l_14 cost 3.314018249511719e-05 seconds
DEBUG 01-06 17:11:01.784223.784223 cuda_h.py:19] end start_load_qkvogn_s_weight_l_14 cost 6.413459777832031e-05 seconds
DEBUG 01-06 17:11:01.784535.784535 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-06 17:11:01.785941.785941 cuda_h.py:10] start sllm_worker_task
DEBUG 01-06 17:11:01.785972.785972 mlpmodule.py:367] cuda:1 cuda:1
DEBUG 01-06 17:11:01.785218.785218 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 17:11:01.785089.785089 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 17:11:01.788554.788554 cuda_h.py:19] end allocate_cuda_memory cost 0.0027353763580322266 seconds
DEBUG 01-06 17:11:01.788879.788879 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 17:11:01.788664.788664 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 17:11:01.788920.788920 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 17:11:01.788644.788644 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, ba8f5ad5-74db-470a-bcaa-7f0a117476c5
DEBUG 01-06 17:11:01.788465.788465 client.py:106] call stub.LoadModelAsync
DEBUG 01-06 17:11:01.789418.789418 cuda_h.py:10] start self_attn
INFO 01-06 17:11:01.790213.790213 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, ba8f5ad5-74db-470a-bcaa-7f0a117476c5
DEBUG 01-06 17:11:01.790241.790241 cuda_h.py:19] end load_into_gpu_async cost 0.0018093585968017578 seconds
DEBUG 01-06 17:11:01.790036.790036 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 17:11:01.790311.790311 cuda_h.py:19] end restore_tensors2 cost 7.05718994140625e-05 seconds
DEBUG 01-06 17:11:01.790875.790875 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.005095958709716797 seconds
INFO 01-06 17:11:01.790751.790751 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, ba8f5ad5-74db-470a-bcaa-7f0a117476c5
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-06 17:11:01.792128.792128 cuda_h.py:19] end self_attn cost 0.0029091835021972656 seconds
DEBUG 01-06 17:11:01.792397.792397 cuda_h.py:19] end iln_self_attn_paln cost 0.007523536682128906 seconds
DEBUG 01-06 17:11:01.792717.792717 cuda_h.py:10] start layer_moe_generate_13
DEBUG 01-06 17:11:01.792102.792102 cuda_h.py:10] start gate
DEBUG 01-06 17:11:01.792835.792835 mlpmodule.py:664]  experts func einsum cost 0.06799197196960449 s
DEBUG 01-06 17:11:01.793750.793750 cuda_h.py:19] end gate cost 0.0007121562957763672 seconds
DEBUG 01-06 17:11:01.793727.793727 cuda_h.py:10] start experts_map_get
DEBUG 01-06 17:11:01.793704.793704 lmp.py:403] 
DEBUG 01-06 17:11:01.793704.793704 lmp.py:403] Expert Token Distribution & Device Allocation:
DEBUG 01-06 17:11:01.793937.793937 lmp.py:404]   Total experts: 64
DEBUG 01-06 17:11:01.793540.793540 lmp.py:405]   CPU experts: 32 (50%)
DEBUG 01-06 17:11:01.793329.793329 lmp.py:406]   GPU experts: 32 (50%)
DEBUG 01-06 17:11:01.793972.793972 lmp.py:407] 
DEBUG 01-06 17:11:01.793972.793972 lmp.py:407]   Expert ID | Tokens | Device
DEBUG 01-06 17:11:01.793807.793807 lmp.py:408]   -----------------------------------
DEBUG 01-06 17:11:01.793172.793172 lmp.py:414]   Expert 19 |     22 | CPU
DEBUG 01-06 17:11:01.793768.793768 lmp.py:414]   Expert 30 |     24 | CPU
DEBUG 01-06 17:11:01.793935.793935 lmp.py:414]   Expert 42 |     24 | CPU
DEBUG 01-06 17:11:01.793862.793862 lmp.py:414]   Expert 32 |     36 | CPU
DEBUG 01-06 17:11:01.793552.793552 lmp.py:414]   Expert  6 |     56 | CPU
DEBUG 01-06 17:11:01.793764.793764 lmp.py:414]   Expert 53 |     75 | CPU
DEBUG 01-06 17:11:01.794407.794407 lmp.py:414]   Expert  5 |     77 | CPU
DEBUG 01-06 17:11:01.794573.794573 lmp.py:414]   Expert  1 |     82 | CPU
DEBUG 01-06 17:11:01.794739.794739 lmp.py:414]   Expert  9 |    114 | CPU
DEBUG 01-06 17:11:01.794905.794905 lmp.py:414]   Expert 13 |    122 | CPU
DEBUG 01-06 17:11:01.794072.794072 lmp.py:414]   Expert 63 |    126 | CPU
DEBUG 01-06 17:11:01.794999.794999 lmp.py:414]   Expert 58 |    129 | CPU
DEBUG 01-06 17:11:01.794689.794689 lmp.py:414]   Expert 26 |    132 | CPU
DEBUG 01-06 17:11:01.794378.794378 lmp.py:414]   Expert 50 |    133 | CPU
DEBUG 01-06 17:11:01.794352.794352 lmp.py:414]   Expert 34 |    136 | CPU
DEBUG 01-06 17:11:01.794803.794803 lmp.py:414]   Expert 56 |    137 | CPU
DEBUG 01-06 17:11:01.794254.794254 lmp.py:414]   Expert 59 |    137 | CPU
DEBUG 01-06 17:11:01.794705.794705 lmp.py:414]   Expert 31 |    140 | CPU
DEBUG 01-06 17:11:01.794109.794109 lmp.py:414]   Expert 18 |    141 | CPU
DEBUG 01-06 17:11:01.794798.794798 lmp.py:414]   Expert 40 |    142 | CPU
DEBUG 01-06 17:11:01.794965.794965 lmp.py:414]   Expert 12 |    144 | CPU
DEBUG 01-06 17:11:01.794131.794131 lmp.py:414]   Expert 11 |    148 | CPU
DEBUG 01-06 17:11:01.794297.794297 lmp.py:414]   Expert  2 |    149 | CPU
DEBUG 01-06 17:11:01.794986.794986 lmp.py:414]   Expert 20 |    153 | CPU
DEBUG 01-06 17:11:01.794199.794199 lmp.py:414]   Expert 48 |    153 | CPU
DEBUG 01-06 17:11:01.794650.794650 lmp.py:414]   Expert 46 |    156 | CPU
DEBUG 01-06 17:11:01.794100.794100 lmp.py:414]   Expert  4 |    157 | CPU
DEBUG 01-06 17:11:01.794551.794551 lmp.py:414]   Expert 33 |    157 | CPU
DEBUG 01-06 17:11:01.794764.794764 lmp.py:414]   Expert 55 |    159 | CPU
DEBUG 01-06 17:11:01.794976.794976 lmp.py:414]   Expert 61 |    159 | CPU
DEBUG 01-06 17:11:01.794427.794427 lmp.py:414]   Expert 10 |    168 | CPU
DEBUG 01-06 17:11:01.794070.794070 lmp.py:414]   Expert 35 |    170 | CPU
DEBUG 01-06 17:11:01.794475.794475 lmp.py:414]   Expert  8 |    176 | GPU
DEBUG 01-06 17:11:01.794879.794879 lmp.py:414]   Expert 51 |    177 | GPU
DEBUG 01-06 17:11:01.794045.794045 lmp.py:414]   Expert 36 |    178 | GPU
DEBUG 01-06 17:11:01.794211.794211 lmp.py:414]   Expert 52 |    189 | GPU
DEBUG 01-06 17:11:01.794901.794901 lmp.py:414]   Expert 37 |    191 | GPU
DEBUG 01-06 17:11:01.794113.794113 lmp.py:414]   Expert 57 |    198 | GPU
DEBUG 01-06 17:11:01.794564.794564 lmp.py:414]   Expert  0 |    203 | GPU
DEBUG 01-06 17:11:01.794777.794777 lmp.py:414]   Expert 39 |    211 | GPU
DEBUG 01-06 17:11:01.794751.794751 lmp.py:414]   Expert 62 |    230 | GPU
DEBUG 01-06 17:11:01.794202.794202 lmp.py:414]   Expert 25 |    231 | GPU
DEBUG 01-06 17:11:01.794891.794891 lmp.py:414]   Expert  7 |    249 | GPU
DEBUG 01-06 17:11:01.794342.794342 lmp.py:414]   Expert 38 |    251 | GPU
DEBUG 01-06 17:11:01.794746.794746 lmp.py:414]   Expert  3 |    253 | GPU
DEBUG 01-06 17:11:01.794912.794912 lmp.py:414]   Expert 27 |    253 | GPU
DEBUG 01-06 17:11:01.794840.794840 lmp.py:414]   Expert 24 |    254 | GPU
DEBUG 01-06 17:11:01.794768.794768 lmp.py:414]   Expert 28 |    254 | GPU
DEBUG 01-06 17:11:01.794934.794934 lmp.py:414]   Expert 60 |    256 | GPU
DEBUG 01-06 17:11:01.794623.794623 lmp.py:414]   Expert 21 |    257 | GPU
DEBUG 01-06 17:11:01.794074.794074 lmp.py:414]   Expert 16 |    258 | GPU
DEBUG 01-06 17:11:01.794525.794525 lmp.py:414]   Expert 43 |    264 | GPU
DEBUG 01-06 17:11:01.794976.794976 lmp.py:414]   Expert 49 |    275 | GPU
DEBUG 01-06 17:11:01.794427.794427 lmp.py:414]   Expert 29 |    276 | GPU
DEBUG 01-06 17:11:01.794639.794639 lmp.py:414]   Expert 23 |    285 | GPU
DEBUG 01-06 17:11:01.794090.794090 lmp.py:414]   Expert 47 |    291 | GPU
DEBUG 01-06 17:11:01.794541.794541 lmp.py:414]   Expert 22 |    293 | GPU
DEBUG 01-06 17:11:01.794469.794469 lmp.py:414]   Expert 15 |    294 | GPU
DEBUG 01-06 17:11:01.794396.794396 lmp.py:414]   Expert 41 |    300 | GPU
DEBUG 01-06 17:11:01.794324.794324 lmp.py:414]   Expert 44 |    300 | GPU
DEBUG 01-06 17:11:01.794729.794729 lmp.py:414]   Expert 54 |    354 | GPU
DEBUG 01-06 17:11:01.794133.794133 lmp.py:414]   Expert 14 |    372 | GPU
DEBUG 01-06 17:11:01.794823.794823 lmp.py:414]   Expert 17 |    408 | GPU
DEBUG 01-06 17:11:01.794035.794035 lmp.py:414]   Expert 45 |    449 | GPU
DEBUG 01-06 17:11:01.794201.794201 lmp.py:415] 
DEBUG 01-06 17:11:01.794201.794201 lmp.py:415]   CPU total tokens: 3858 (31.4%)
DEBUG 01-06 17:11:01.795606.795606 lmp.py:416]   GPU total tokens: 8430 (68.6%)
DEBUG 01-06 17:11:01.795540.795540 cuda_h.py:19] end experts_map_get cost 0.0015187263488769531 seconds
DEBUG 01-06 17:11:01.795422.795422 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-06 17:11:01.795867.795867 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 17:11:01.795905.795905 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 17:11:01.796682.796682 cuda_h.py:19] end allocate_cuda_memory cost 0.0012423992156982422 seconds
DEBUG 01-06 17:11:01.796771.796771 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 17:11:01.796003.796003 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 17:11:01.796435.796435 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 17:11:01.796515.796515 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, b12a00f3-c700-4b62-8604-012b21768f22
DEBUG 01-06 17:11:01.796985.796985 client.py:106] call stub.LoadModelAsync
INFO 01-06 17:11:01.798255.798255 client.py:127] Model loaded
DEBUG 01-06 17:11:01.798424.798424 cuda_h.py:19] end sllm_worker_task cost 0.01346445083618164 seconds
INFO 01-06 17:11:01.799035.799035 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, b12a00f3-c700-4b62-8604-012b21768f22
DEBUG 01-06 17:11:01.799070.799070 cuda_h.py:19] end load_into_gpu_async cost 0.003171205520629883 seconds
DEBUG 01-06 17:11:01.799727.799727 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 17:11:01.800425.800425 cuda_h.py:19] end restore_tensors2 cost 0.0002789497375488281 seconds
DEBUG 01-06 17:11:01.800864.800864 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.005030393600463867 seconds
DEBUG 01-06 17:11:01.802772.802772 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.0076749324798583984 seconds
DEBUG 01-06 17:11:01.802463.802463 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-06 17:11:01.802710.802710 lmp.py:461] 
DEBUG 01-06 17:11:01.802710.802710 lmp.py:461]   Computing 32 experts on CPU...
DEBUG 01-06 17:11:01.802222.802222 cuda_h.py:19] end cpu_experts_submit cost 0.00010991096496582031 seconds
DEBUG 01-06 17:11:01.802872.802872 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-06 17:11:01.812711.812711 mlpmodule.py:706] group tensors cost 0.009019136428833008 s
DEBUG 01-06 17:11:01.814738.814738 mlpmodule.py:744] pad cost 0.0015952587127685547 s
DEBUG 01-06 17:11:01.814153.814153 mlpmodule.py:750] create cpu tensor cost 7.200241088867188e-05 s
DEBUG 01-06 17:11:01.814778.814778 mlpmodule.py:755] move to cpu cost 3.361701965332031e-05 s
DEBUG 01-06 17:11:01.824492.824492 mlpmodule.py:769] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-06 17:11:01.824349.824349 mlpmodule.py:770] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-06 17:11:01.824338.824338 mlpmodule.py:775] group_w3 first element: -0.0211181640625
WARNING 01-06 17:11:01.825513.825513 mlpmodule.py:785] start einsum2
DEBUG 01-06 17:11:01.843429.843429 mlpmodule.py:795] group einsum cost 0.028278589248657227 s
DEBUG 01-06 17:11:01.843030.843030 mlpmodule.py:803] cpy2cputensor cost 0.0006728172302246094 s
DEBUG 01-06 17:11:01.848140.848140 cuda_h.py:19] end wait_cetm_experts cost 0.045090675354003906 seconds
DEBUG 01-06 17:11:01.848875.848875 cuda_h.py:10] start gpu_sexperts
DEBUG 01-06 17:11:01.848387.848387 cuda_h.py:19] end gpu_sexperts cost 0.0006120204925537109 seconds
DEBUG 01-06 17:11:01.849720.849720 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-06 17:11:01.849570.849570 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.47955322265625e-05 seconds
DEBUG 01-06 17:11:01.849750.849750 cuda_h.py:10] start wait_experts
INFO 01-06 17:11:01.849890.849890 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, b12a00f3-c700-4b62-8604-012b21768f22
INFO 01-06 17:11:01.852225.852225 client.py:127] Model loaded
DEBUG 01-06 17:11:01.852737.852737 cuda_h.py:19] end wait_experts cost 0.0031545162200927734 seconds
DEBUG 01-06 17:11:01.852586.852586 cuda_h.py:10] start gpu_experts
DEBUG 01-06 17:11:01.852740.852740 lmp.py:506]   Computing 32 experts on GPU...
DEBUG 01-06 17:11:01.853009.853009 mlpmodule.py:533] gpu group tensors cost 0.0006353855133056641 s
DEBUG 01-06 17:11:01.854884.854884 mlpmodule.py:566] gpu pad cost 0.001749277114868164 s
DEBUG 01-06 17:11:01.855771.855771 mlpmodule.py:584] gpu group einsum cost 0.0005092620849609375 s
DEBUG 01-06 17:11:01.859922.859922 mlpmodule.py:613] gpu experts func einsum cost 0.006537675857543945 s
DEBUG 01-06 17:11:01.859005.859005 cuda_h.py:19] end gpu_experts cost 0.006728410720825195 seconds
DEBUG 01-06 17:11:01.859743.859743 cuda_h.py:19] end layer_moe_generate_13 cost 0.06659340858459473 seconds
DEBUG 01-06 17:11:01.859358.859358 lmp.py:220] -------------------------------- end layer 13 --------------------------------
DEBUG 01-06 17:11:01.859836.859836 lmp.py:176] -------------------------------- start layer 14 --------------------------------
DEBUG 01-06 17:11:01.859009.859009 cuda_h.py:10] start start_load_qkvogn_s_weight_l_15
DEBUG 01-06 17:11:01.859480.859480 cuda_h.py:10] start start_load_qkvogn_s_weight_l_15
DEBUG 01-06 17:11:01.859270.859270 cuda_h.py:19] end start_load_qkvogn_s_weight_l_15 cost 2.9087066650390625e-05 seconds
DEBUG 01-06 17:11:01.859119.859119 cuda_h.py:19] end start_load_qkvogn_s_weight_l_15 cost 6.103515625e-05 seconds
DEBUG 01-06 17:11:01.859291.859291 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-06 17:11:01.859865.859865 mlpmodule.py:367] cuda:1 cuda:1
DEBUG 01-06 17:11:01.859920.859920 cuda_h.py:10] start sllm_worker_task
DEBUG 01-06 17:11:01.859128.859128 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 17:11:01.859050.859050 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 17:11:01.863306.863306 cuda_h.py:19] end allocate_cuda_memory cost 0.004052639007568359 seconds
DEBUG 01-06 17:11:01.864064.864064 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 17:11:01.864953.864953 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 17:11:01.864014.864014 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 17:11:01.864432.864432 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, ed535ba6-4c36-4db2-813c-e8db6a1c72a1
DEBUG 01-06 17:11:01.864495.864495 client.py:106] call stub.LoadModelAsync
DEBUG 01-06 17:11:01.864105.864105 mlpmodule.py:664]  experts func einsum cost 0.061356544494628906 s
DEBUG 01-06 17:11:01.864078.864078 cuda_h.py:10] start self_attn
INFO 01-06 17:11:01.865968.865968 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, ed535ba6-4c36-4db2-813c-e8db6a1c72a1
DEBUG 01-06 17:11:01.865665.865665 cuda_h.py:19] end load_into_gpu_async cost 0.001682281494140625 seconds
DEBUG 01-06 17:11:01.865653.865653 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 17:11:01.865497.865497 cuda_h.py:19] end restore_tensors2 cost 6.985664367675781e-05 seconds
DEBUG 01-06 17:11:01.865776.865776 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.006066083908081055 seconds
INFO 01-06 17:11:01.866712.866712 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, ed535ba6-4c36-4db2-813c-e8db6a1c72a1
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-06 17:11:01.867593.867593 cuda_h.py:19] end self_attn cost 0.0028371810913085938 seconds
DEBUG 01-06 17:11:01.868485.868485 cuda_h.py:19] end iln_self_attn_paln cost 0.008504629135131836 seconds
DEBUG 01-06 17:11:01.868182.868182 cuda_h.py:10] start layer_moe_generate_14
DEBUG 01-06 17:11:01.868567.868567 cuda_h.py:10] start gate
DEBUG 01-06 17:11:01.868736.868736 cuda_h.py:19] end gate cost 0.0006511211395263672 seconds
DEBUG 01-06 17:11:01.868373.868373 cuda_h.py:10] start experts_map_get
DEBUG 01-06 17:11:01.869489.869489 lmp.py:403] 
DEBUG 01-06 17:11:01.869489.869489 lmp.py:403] Expert Token Distribution & Device Allocation:
DEBUG 01-06 17:11:01.869530.869530 lmp.py:404]   Total experts: 64
DEBUG 01-06 17:11:01.869703.869703 lmp.py:405]   CPU experts: 32 (50%)
DEBUG 01-06 17:11:01.869776.869776 lmp.py:406]   GPU experts: 32 (50%)
DEBUG 01-06 17:11:01.869373.869373 lmp.py:407] 
DEBUG 01-06 17:11:01.869373.869373 lmp.py:407]   Expert ID | Tokens | Device
DEBUG 01-06 17:11:01.869970.869970 lmp.py:408]   -----------------------------------
DEBUG 01-06 17:11:01.869573.869573 lmp.py:414]   Expert  7 |     31 | CPU
DEBUG 01-06 17:11:01.869170.869170 lmp.py:414]   Expert 34 |     32 | CPU
DEBUG 01-06 17:11:01.869051.869051 lmp.py:414]   Expert 13 |     45 | CPU
DEBUG 01-06 17:11:01.869456.869456 lmp.py:414]   Expert 54 |     79 | CPU
DEBUG 01-06 17:11:01.869383.869383 lmp.py:414]   Expert 18 |     83 | CPU
DEBUG 01-06 17:11:01.869073.869073 lmp.py:414]   Expert 39 |     89 | CPU
DEBUG 01-06 17:11:01.869762.869762 lmp.py:414]   Expert 49 |     92 | CPU
DEBUG 01-06 17:11:01.869690.869690 lmp.py:414]   Expert 16 |    101 | CPU
DEBUG 01-06 17:11:01.869333.869333 lmp.py:414]   Expert 21 |    104 | CPU
DEBUG 01-06 17:11:01.869499.869499 lmp.py:414]   Expert 59 |    105 | CPU
DEBUG 01-06 17:11:01.869142.869142 lmp.py:414]   Expert  0 |    108 | CPU
DEBUG 01-06 17:11:01.869069.869069 lmp.py:414]   Expert 22 |    118 | CPU
DEBUG 01-06 17:11:01.869951.869951 lmp.py:414]   Expert 41 |    118 | CPU
DEBUG 01-06 17:11:01.869640.869640 lmp.py:414]   Expert 45 |    118 | CPU
DEBUG 01-06 17:11:01.869091.869091 lmp.py:414]   Expert 15 |    121 | CPU
DEBUG 01-06 17:11:01.869780.869780 lmp.py:414]   Expert 17 |    126 | CPU
DEBUG 01-06 17:11:01.869993.869993 lmp.py:414]   Expert 52 |    133 | CPU
DEBUG 01-06 17:11:01.869682.869682 lmp.py:414]   Expert 61 |    133 | CPU
DEBUG 01-06 17:11:01.869371.869371 lmp.py:414]   Expert  8 |    140 | CPU
DEBUG 01-06 17:11:01.869822.869822 lmp.py:414]   Expert 12 |    140 | CPU
DEBUG 01-06 17:11:01.869273.869273 lmp.py:414]   Expert 35 |    140 | CPU
DEBUG 01-06 17:11:01.869201.869201 lmp.py:414]   Expert 48 |    141 | CPU
DEBUG 01-06 17:11:01.869082.869082 lmp.py:414]   Expert 38 |    142 | CPU
DEBUG 01-06 17:11:01.869010.869010 lmp.py:414]   Expert 36 |    151 | CPU
DEBUG 01-06 17:11:01.869653.869653 lmp.py:414]   Expert 31 |    152 | CPU
DEBUG 01-06 17:11:01.869342.869342 lmp.py:414]   Expert 50 |    153 | CPU
DEBUG 01-06 17:11:01.869793.869793 lmp.py:414]   Expert 40 |    155 | CPU
DEBUG 01-06 17:11:01.869244.869244 lmp.py:414]   Expert 53 |    161 | CPU
DEBUG 01-06 17:11:01.869218.869218 lmp.py:414]   Expert 60 |    162 | CPU
DEBUG 01-06 17:11:01.869669.869669 lmp.py:414]   Expert 27 |    174 | CPU
DEBUG 01-06 17:11:01.869120.869120 lmp.py:414]   Expert 19 |    199 | CPU
DEBUG 01-06 17:11:01.869571.869571 lmp.py:414]   Expert 29 |    199 | CPU
DEBUG 01-06 17:11:01.869783.869783 lmp.py:414]   Expert  4 |    201 | GPU
DEBUG 01-06 17:11:01.869473.869473 lmp.py:414]   Expert 30 |    205 | GPU
DEBUG 01-06 17:11:01.869400.869400 lmp.py:414]   Expert 11 |    221 | GPU
DEBUG 01-06 17:11:01.869805.869805 lmp.py:414]   Expert 26 |    221 | GPU
DEBUG 01-06 17:11:01.869209.869209 lmp.py:414]   Expert  6 |    223 | GPU
DEBUG 01-06 17:11:01.870375.870375 lmp.py:414]   Expert 20 |    223 | GPU
DEBUG 01-06 17:11:01.870065.870065 lmp.py:414]   Expert 57 |    228 | GPU
DEBUG 01-06 17:11:01.870277.870277 lmp.py:414]   Expert 46 |    230 | GPU
DEBUG 01-06 17:11:01.870728.870728 lmp.py:414]   Expert 43 |    232 | GPU
DEBUG 01-06 17:11:01.870179.870179 lmp.py:414]   Expert 23 |    239 | GPU
DEBUG 01-06 17:11:01.870868.870868 lmp.py:414]   Expert 33 |    240 | GPU
DEBUG 01-06 17:11:01.870842.870842 lmp.py:414]   Expert  2 |    246 | GPU
DEBUG 01-06 17:11:01.870293.870293 lmp.py:414]   Expert 42 |    248 | GPU
DEBUG 01-06 17:11:01.870506.870506 lmp.py:414]   Expert 55 |    250 | GPU
DEBUG 01-06 17:11:01.870718.870718 lmp.py:414]   Expert 32 |    259 | GPU
DEBUG 01-06 17:11:01.870169.870169 lmp.py:414]   Expert 56 |    260 | GPU
DEBUG 01-06 17:11:01.870097.870097 lmp.py:414]   Expert 28 |    261 | GPU
DEBUG 01-06 17:11:01.870263.870263 lmp.py:414]   Expert  9 |    262 | GPU
DEBUG 01-06 17:11:01.870952.870952 lmp.py:414]   Expert  3 |    264 | GPU
DEBUG 01-06 17:11:01.870641.870641 lmp.py:414]   Expert  1 |    268 | GPU
DEBUG 01-06 17:11:01.870092.870092 lmp.py:414]   Expert 44 |    271 | GPU
DEBUG 01-06 17:11:01.870782.870782 lmp.py:414]   Expert 14 |    274 | GPU
DEBUG 01-06 17:11:01.870994.870994 lmp.py:414]   Expert 58 |    278 | GPU
DEBUG 01-06 17:11:01.870445.870445 lmp.py:414]   Expert 51 |    279 | GPU
DEBUG 01-06 17:11:01.870657.870657 lmp.py:414]   Expert 47 |    284 | GPU
DEBUG 01-06 17:11:01.870108.870108 lmp.py:414]   Expert 62 |    290 | GPU
DEBUG 01-06 17:11:01.870798.870798 lmp.py:414]   Expert 63 |    290 | GPU
DEBUG 01-06 17:11:01.870010.870010 lmp.py:414]   Expert 37 |    292 | GPU
DEBUG 01-06 17:11:01.870415.870415 lmp.py:414]   Expert 10 |    306 | GPU
DEBUG 01-06 17:11:01.870581.870581 lmp.py:414]   Expert 24 |    314 | GPU
DEBUG 01-06 17:11:01.870747.870747 lmp.py:414]   Expert 25 |    316 | GPU
DEBUG 01-06 17:11:01.870390.870390 lmp.py:414]   Expert  5 |    368 | GPU
DEBUG 01-06 17:11:01.870794.870794 lmp.py:415] 
DEBUG 01-06 17:11:01.870794.870794 lmp.py:415]   CPU total tokens: 3945 (32.1%)
DEBUG 01-06 17:11:01.870676.870676 lmp.py:416]   GPU total tokens: 8343 (67.9%)
DEBUG 01-06 17:11:01.870134.870134 cuda_h.py:19] end experts_map_get cost 0.0015153884887695312 seconds
DEBUG 01-06 17:11:01.870015.870015 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-06 17:11:01.870699.870699 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 17:11:01.870359.870359 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 17:11:01.872689.872689 cuda_h.py:19] end allocate_cuda_memory cost 0.0013344287872314453 seconds
DEBUG 01-06 17:11:01.872453.872453 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 17:11:01.872494.872494 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 17:11:01.872972.872972 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 17:11:01.872814.872814 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 53ded357-52c1-4b55-ae5f-35ce9e98934b
DEBUG 01-06 17:11:01.872304.872304 client.py:106] call stub.LoadModelAsync
INFO 01-06 17:11:01.873363.873363 client.py:127] Model loaded
DEBUG 01-06 17:11:01.874131.874131 cuda_h.py:19] end sllm_worker_task cost 0.014331340789794922 seconds
INFO 01-06 17:11:01.875915.875915 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 53ded357-52c1-4b55-ae5f-35ce9e98934b
DEBUG 01-06 17:11:01.875641.875641 cuda_h.py:19] end load_into_gpu_async cost 0.003389596939086914 seconds
DEBUG 01-06 17:11:01.875273.875273 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 17:11:01.876552.876552 cuda_h.py:19] end restore_tensors2 cost 0.00035119056701660156 seconds
DEBUG 01-06 17:11:01.876706.876706 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.00553131103515625 seconds
DEBUG 01-06 17:11:01.878276.878276 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.008171796798706055 seconds
DEBUG 01-06 17:11:01.878536.878536 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-06 17:11:01.878830.878830 lmp.py:461] 
DEBUG 01-06 17:11:01.878830.878830 lmp.py:461]   Computing 32 experts on CPU...
DEBUG 01-06 17:11:01.878846.878846 cuda_h.py:19] end cpu_experts_submit cost 0.000110626220703125 seconds
DEBUG 01-06 17:11:01.878211.878211 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-06 17:11:01.885033.885033 mlpmodule.py:706] group tensors cost 0.005962371826171875 s
DEBUG 01-06 17:11:01.887744.887744 mlpmodule.py:744] pad cost 0.0019881725311279297 s
DEBUG 01-06 17:11:01.887721.887721 mlpmodule.py:750] create cpu tensor cost 5.221366882324219e-05 s
DEBUG 01-06 17:11:01.887214.887214 mlpmodule.py:755] move to cpu cost 3.8623809814453125e-05 s
DEBUG 01-06 17:11:01.899688.899688 mlpmodule.py:769] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-06 17:11:01.899121.899121 mlpmodule.py:770] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-06 17:11:01.899070.899070 mlpmodule.py:775] group_w3 first element: 0.000789642333984375
WARNING 01-06 17:11:01.899775.899775 mlpmodule.py:785] start einsum2
DEBUG 01-06 17:11:01.919412.919412 mlpmodule.py:795] group einsum cost 0.03137564659118652 s
DEBUG 01-06 17:11:01.920480.920480 mlpmodule.py:803] cpy2cputensor cost 0.0007245540618896484 s
DEBUG 01-06 17:11:01.924302.924302 cuda_h.py:19] end wait_cetm_experts cost 0.045551300048828125 seconds
DEBUG 01-06 17:11:01.924871.924871 cuda_h.py:10] start gpu_sexperts
DEBUG 01-06 17:11:01.925244.925244 cuda_h.py:19] end gpu_sexperts cost 0.0006158351898193359 seconds
DEBUG 01-06 17:11:01.925571.925571 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-06 17:11:01.925560.925560 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.2411346435546875e-05 seconds
DEBUG 01-06 17:11:01.925501.925501 cuda_h.py:10] start wait_experts
INFO 01-06 17:11:01.925271.925271 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 53ded357-52c1-4b55-ae5f-35ce9e98934b
INFO 01-06 17:11:01.927573.927573 client.py:127] Model loaded
DEBUG 01-06 17:11:01.927569.927569 cuda_h.py:19] end wait_experts cost 0.0015974044799804688 seconds
DEBUG 01-06 17:11:01.927656.927656 cuda_h.py:10] start gpu_experts
DEBUG 01-06 17:11:01.927604.927604 lmp.py:506]   Computing 32 experts on GPU...
DEBUG 01-06 17:11:01.927873.927873 mlpmodule.py:533] gpu group tensors cost 0.0006368160247802734 s
DEBUG 01-06 17:11:01.929604.929604 mlpmodule.py:566] gpu pad cost 0.001783609390258789 s
DEBUG 01-06 17:11:01.930777.930777 mlpmodule.py:584] gpu group einsum cost 0.0005466938018798828 s
DEBUG 01-06 17:11:01.933295.933295 mlpmodule.py:664]  experts func einsum cost 0.05435442924499512 s
DEBUG 01-06 17:11:01.934128.934128 mlpmodule.py:613] gpu experts func einsum cost 0.006847858428955078 s
DEBUG 01-06 17:11:01.934955.934955 cuda_h.py:19] end gpu_experts cost 0.007108211517333984 seconds
DEBUG 01-06 17:11:01.934746.934746 cuda_h.py:19] end layer_moe_generate_14 cost 0.0662529468536377 seconds
DEBUG 01-06 17:11:01.934772.934772 lmp.py:220] -------------------------------- end layer 14 --------------------------------
DEBUG 01-06 17:11:01.934873.934873 lmp.py:176] -------------------------------- start layer 15 --------------------------------
DEBUG 01-06 17:11:01.934907.934907 cuda_h.py:10] start start_load_qkvogn_s_weight_l_16
DEBUG 01-06 17:11:01.934762.934762 cuda_h.py:10] start start_load_qkvogn_s_weight_l_16
DEBUG 01-06 17:11:01.934718.934718 cuda_h.py:19] end start_load_qkvogn_s_weight_l_16 cost 4.029273986816406e-05 seconds
DEBUG 01-06 17:11:01.934760.934760 cuda_h.py:10] start sllm_worker_task
DEBUG 01-06 17:11:01.934259.934259 cuda_h.py:19] end start_load_qkvogn_s_weight_l_16 cost 0.00016069412231445312 seconds
DEBUG 01-06 17:11:01.935182.935182 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 17:11:01.935005.935005 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-06 17:11:01.935715.935715 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 17:11:01.935060.935060 cuda_h.py:19] end allocate_cuda_memory cost 0.0003116130828857422 seconds
DEBUG 01-06 17:11:01.935103.935103 mlpmodule.py:367] cuda:1 cuda:1
DEBUG 01-06 17:11:01.935363.935363 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 17:11:01.935976.935976 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 17:11:01.935421.935421 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 17:11:01.935839.935839 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 8099242c-b583-48f0-a0d8-4722bce52fe9
DEBUG 01-06 17:11:01.935862.935862 client.py:106] call stub.LoadModelAsync
DEBUG 01-06 17:11:01.936144.936144 cuda_h.py:10] start self_attn
INFO 01-06 17:11:01.937575.937575 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 8099242c-b583-48f0-a0d8-4722bce52fe9
DEBUG 01-06 17:11:01.937656.937656 cuda_h.py:19] end load_into_gpu_async cost 0.0017282962799072266 seconds
DEBUG 01-06 17:11:01.937405.937405 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 17:11:01.937157.937157 cuda_h.py:19] end restore_tensors2 cost 7.05718994140625e-05 seconds
DEBUG 01-06 17:11:01.937721.937721 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.002555370330810547 seconds
INFO 01-06 17:11:01.937504.937504 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 8099242c-b583-48f0-a0d8-4722bce52fe9
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-06 17:11:01.939037.939037 cuda_h.py:19] end self_attn cost 0.0028755664825439453 seconds
DEBUG 01-06 17:11:01.939530.939530 cuda_h.py:19] end iln_self_attn_paln cost 0.004309177398681641 seconds
DEBUG 01-06 17:11:01.939420.939420 cuda_h.py:10] start layer_moe_generate_15
DEBUG 01-06 17:11:01.939613.939613 cuda_h.py:10] start gate
DEBUG 01-06 17:11:01.940245.940245 cuda_h.py:19] end gate cost 0.0006415843963623047 seconds
DEBUG 01-06 17:11:01.940598.940598 cuda_h.py:10] start experts_map_get
DEBUG 01-06 17:11:01.940926.940926 lmp.py:403] 
DEBUG 01-06 17:11:01.940926.940926 lmp.py:403] Expert Token Distribution & Device Allocation:
DEBUG 01-06 17:11:01.940159.940159 lmp.py:404]   Total experts: 64
DEBUG 01-06 17:11:01.940001.940001 lmp.py:405]   CPU experts: 32 (50%)
DEBUG 01-06 17:11:01.940028.940028 lmp.py:406]   GPU experts: 32 (50%)
DEBUG 01-06 17:11:01.940909.940909 lmp.py:407] 
DEBUG 01-06 17:11:01.940909.940909 lmp.py:407]   Expert ID | Tokens | Device
DEBUG 01-06 17:11:01.940791.940791 lmp.py:408]   -----------------------------------
DEBUG 01-06 17:11:01.940917.940917 lmp.py:414]   Expert 15 |     57 | CPU
DEBUG 01-06 17:11:01.940322.940322 lmp.py:414]   Expert 63 |     73 | CPU
DEBUG 01-06 17:11:01.940534.940534 lmp.py:414]   Expert 41 |     74 | CPU
DEBUG 01-06 17:11:01.940747.940747 lmp.py:414]   Expert  0 |     79 | CPU
DEBUG 01-06 17:11:01.940721.940721 lmp.py:414]   Expert 20 |     81 | CPU
DEBUG 01-06 17:11:01.940695.940695 lmp.py:414]   Expert 45 |     86 | CPU
DEBUG 01-06 17:11:01.940669.940669 lmp.py:414]   Expert  7 |     96 | CPU
DEBUG 01-06 17:11:01.940643.940643 lmp.py:414]   Expert 28 |     99 | CPU
DEBUG 01-06 17:11:01.940378.940378 lmp.py:414]   Expert 54 |    107 | CPU
DEBUG 01-06 17:11:01.940306.940306 lmp.py:414]   Expert 12 |    112 | CPU
DEBUG 01-06 17:11:01.940757.940757 lmp.py:414]   Expert 52 |    118 | CPU
DEBUG 01-06 17:11:01.940208.940208 lmp.py:414]   Expert 40 |    120 | CPU
DEBUG 01-06 17:11:01.940659.940659 lmp.py:414]   Expert 59 |    120 | CPU
DEBUG 01-06 17:11:01.940110.940110 lmp.py:414]   Expert  4 |    125 | CPU
DEBUG 01-06 17:11:01.941084.941084 lmp.py:414]   Expert  5 |    126 | CPU
DEBUG 01-06 17:11:01.941058.941058 lmp.py:414]   Expert 34 |    132 | CPU
DEBUG 01-06 17:11:01.941754.941754 lmp.py:414]   Expert 42 |    134 | CPU
DEBUG 01-06 17:11:01.941682.941682 lmp.py:414]   Expert 55 |    136 | CPU
DEBUG 01-06 17:11:01.941132.941132 lmp.py:414]   Expert 62 |    136 | CPU
DEBUG 01-06 17:11:01.941345.941345 lmp.py:414]   Expert 13 |    138 | CPU
DEBUG 01-06 17:11:01.941034.941034 lmp.py:414]   Expert 61 |    139 | CPU
DEBUG 01-06 17:11:01.941485.941485 lmp.py:414]   Expert 21 |    143 | CPU
DEBUG 01-06 17:11:01.941936.941936 lmp.py:414]   Expert 14 |    145 | CPU
DEBUG 01-06 17:11:01.941817.941817 lmp.py:414]   Expert 10 |    148 | CPU
DEBUG 01-06 17:11:01.941983.941983 lmp.py:414]   Expert 22 |    149 | CPU
DEBUG 01-06 17:11:01.941150.941150 lmp.py:414]   Expert 51 |    155 | CPU
DEBUG 01-06 17:11:01.941316.941316 lmp.py:414]   Expert 32 |    157 | CPU
DEBUG 01-06 17:11:01.941959.941959 lmp.py:414]   Expert 50 |    167 | CPU
DEBUG 01-06 17:11:01.941125.941125 lmp.py:414]   Expert 25 |    169 | CPU
DEBUG 01-06 17:11:01.941814.941814 lmp.py:414]   Expert 53 |    171 | CPU
DEBUG 01-06 17:11:01.941503.941503 lmp.py:414]   Expert 19 |    173 | CPU
DEBUG 01-06 17:11:01.941716.941716 lmp.py:414]   Expert  2 |    176 | CPU
DEBUG 01-06 17:11:01.941405.941405 lmp.py:414]   Expert 26 |    176 | GPU
DEBUG 01-06 17:11:01.941095.941095 lmp.py:414]   Expert  6 |    178 | GPU
DEBUG 01-06 17:11:01.941022.941022 lmp.py:414]   Expert 30 |    179 | GPU
DEBUG 01-06 17:11:01.941619.941619 lmp.py:414]   Expert  1 |    181 | GPU
DEBUG 01-06 17:11:01.941262.941262 lmp.py:414]   Expert 35 |    182 | GPU
DEBUG 01-06 17:11:01.941428.941428 lmp.py:414]   Expert 47 |    183 | GPU
DEBUG 01-06 17:11:01.941833.941833 lmp.py:414]   Expert 11 |    187 | GPU
DEBUG 01-06 17:11:01.941476.941476 lmp.py:414]   Expert 57 |    189 | GPU
DEBUG 01-06 17:11:01.941403.941403 lmp.py:414]   Expert 56 |    192 | GPU
DEBUG 01-06 17:11:01.941093.941093 lmp.py:414]   Expert 48 |    203 | GPU
DEBUG 01-06 17:11:01.941020.941020 lmp.py:414]   Expert 44 |    204 | GPU
DEBUG 01-06 17:11:01.941710.941710 lmp.py:414]   Expert 24 |    207 | GPU
DEBUG 01-06 17:11:01.941637.941637 lmp.py:414]   Expert 46 |    212 | GPU
DEBUG 01-06 17:11:01.941088.941088 lmp.py:414]   Expert 39 |    218 | GPU
DEBUG 01-06 17:11:01.941777.941777 lmp.py:414]   Expert 16 |    225 | GPU
DEBUG 01-06 17:11:01.941420.941420 lmp.py:414]   Expert 18 |    225 | GPU
DEBUG 01-06 17:11:01.941587.941587 lmp.py:414]   Expert 29 |    233 | GPU
DEBUG 01-06 17:11:01.941991.941991 lmp.py:414]   Expert 37 |    243 | GPU
DEBUG 01-06 17:11:01.941396.941396 lmp.py:414]   Expert 31 |    252 | GPU
DEBUG 01-06 17:11:01.941562.941562 lmp.py:414]   Expert  3 |    253 | GPU
DEBUG 01-06 17:11:01.941490.941490 lmp.py:414]   Expert 60 |    258 | GPU
DEBUG 01-06 17:11:01.941940.941940 lmp.py:414]   Expert 36 |    259 | GPU
DEBUG 01-06 17:11:01.941153.941153 lmp.py:414]   Expert 38 |    265 | GPU
DEBUG 01-06 17:11:01.941842.941842 lmp.py:414]   Expert  9 |    267 | GPU
DEBUG 01-06 17:11:01.941293.941293 lmp.py:414]   Expert 17 |    270 | GPU
DEBUG 01-06 17:11:01.941744.941744 lmp.py:414]   Expert 23 |    271 | GPU
DEBUG 01-06 17:11:01.941672.941672 lmp.py:414]   Expert 27 |    350 | GPU
DEBUG 01-06 17:11:01.941123.941123 lmp.py:414]   Expert 43 |    359 | GPU
DEBUG 01-06 17:11:01.941289.941289 lmp.py:414]   Expert 33 |    400 | GPU
DEBUG 01-06 17:11:01.941932.941932 lmp.py:414]   Expert  8 |    428 | GPU
DEBUG 01-06 17:11:01.941098.941098 lmp.py:414]   Expert 58 |    448 | GPU
DEBUG 01-06 17:11:01.941264.941264 lmp.py:414]   Expert 49 |    550 | GPU
DEBUG 01-06 17:11:01.941907.941907 lmp.py:415] 
DEBUG 01-06 17:11:01.941907.941907 lmp.py:415]   CPU total tokens: 4041 (32.9%)
DEBUG 01-06 17:11:01.941550.941550 lmp.py:416]   GPU total tokens: 8247 (67.1%)
DEBUG 01-06 17:11:01.941723.941723 cuda_h.py:19] end experts_map_get cost 0.001538991928100586 seconds
DEBUG 01-06 17:11:01.941604.941604 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-06 17:11:01.941334.941334 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 17:11:01.942425.942425 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 17:11:01.943971.943971 cuda_h.py:19] end allocate_cuda_memory cost 0.0016322135925292969 seconds
DEBUG 01-06 17:11:01.943913.943913 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 17:11:01.943669.943669 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 17:11:01.943478.943478 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 17:11:01.943843.943843 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, c216499d-b35f-4253-9433-84733514f7b5
DEBUG 01-06 17:11:01.944690.944690 client.py:106] call stub.LoadModelAsync
INFO 01-06 17:11:01.945252.945252 client.py:127] Model loaded
DEBUG 01-06 17:11:01.945778.945778 cuda_h.py:19] end sllm_worker_task cost 0.010873079299926758 seconds
INFO 01-06 17:11:01.946601.946601 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, c216499d-b35f-4253-9433-84733514f7b5
DEBUG 01-06 17:11:01.947021.947021 cuda_h.py:19] end load_into_gpu_async cost 0.003168344497680664 seconds
DEBUG 01-06 17:11:01.947439.947439 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 17:11:01.947376.947376 cuda_h.py:19] end restore_tensors2 cost 0.000278472900390625 seconds
DEBUG 01-06 17:11:01.947815.947815 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.005422830581665039 seconds
DEBUG 01-06 17:11:01.950804.950804 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.008126258850097656 seconds
DEBUG 01-06 17:11:01.950647.950647 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-06 17:11:01.950080.950080 lmp.py:461] 
DEBUG 01-06 17:11:01.950080.950080 lmp.py:461]   Computing 32 experts on CPU...
DEBUG 01-06 17:11:01.950685.950685 cuda_h.py:19] end cpu_experts_submit cost 0.00010609626770019531 seconds
DEBUG 01-06 17:11:01.950666.950666 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-06 17:11:01.956332.956332 mlpmodule.py:706] group tensors cost 0.0058441162109375 s
DEBUG 01-06 17:11:01.959039.959039 mlpmodule.py:744] pad cost 0.0020258426666259766 s
DEBUG 01-06 17:11:01.959230.959230 mlpmodule.py:750] create cpu tensor cost 5.412101745605469e-05 s
DEBUG 01-06 17:11:01.959729.959729 mlpmodule.py:755] move to cpu cost 3.838539123535156e-05 s
DEBUG 01-06 17:11:01.970597.970597 mlpmodule.py:769] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-06 17:11:01.970991.970991 mlpmodule.py:770] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-06 17:11:01.970509.970509 mlpmodule.py:775] group_w3 first element: -0.0595703125
WARNING 01-06 17:11:01.970976.970976 mlpmodule.py:785] start einsum2
DEBUG 01-06 17:11:01.988132.988132 mlpmodule.py:795] group einsum cost 0.029384851455688477 s
DEBUG 01-06 17:11:01.989933.989933 mlpmodule.py:803] cpy2cputensor cost 0.0006840229034423828 s
DEBUG 01-06 17:11:01.993527.993527 cuda_h.py:19] end wait_cetm_experts cost 0.04363584518432617 seconds
DEBUG 01-06 17:11:01.994242.994242 cuda_h.py:10] start gpu_sexperts
DEBUG 01-06 17:11:01.994793.994793 cuda_h.py:19] end gpu_sexperts cost 0.0006072521209716797 seconds
DEBUG 01-06 17:11:01.994782.994782 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-06 17:11:01.994201.994201 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.3603439331054688e-05 seconds
DEBUG 01-06 17:11:01.994573.994573 cuda_h.py:10] start wait_experts
INFO 01-06 17:11:01.995098.995098 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, c216499d-b35f-4253-9433-84733514f7b5
INFO 01-06 17:11:01.999829.999829 client.py:127] Model loaded
DEBUG 01-06 17:11:01.999070.999070 cuda_h.py:19] end wait_experts cost 0.004723072052001953 seconds
DEBUG 01-06 17:11:01.999171.999171 cuda_h.py:10] start gpu_experts
DEBUG 01-06 17:11:01.999596.999596 lmp.py:506]   Computing 32 experts on GPU...
DEBUG 01-06 17:11:02.000256.000256 mlpmodule.py:533] gpu group tensors cost 0.0006418228149414062 s
DEBUG 01-06 17:11:02.001878.001878 mlpmodule.py:664]  experts func einsum cost 0.0514674186706543 s
DEBUG 01-06 17:11:02.002728.002728 mlpmodule.py:566] gpu pad cost 0.0019576549530029297 s
DEBUG 01-06 17:11:02.003108.003108 mlpmodule.py:584] gpu group einsum cost 0.0005412101745605469 s
DEBUG 01-06 17:11:02.006028.006028 mlpmodule.py:613] gpu experts func einsum cost 0.006478071212768555 s
DEBUG 01-06 17:11:02.006057.006057 cuda_h.py:19] end gpu_experts cost 0.006663322448730469 seconds
DEBUG 01-06 17:11:02.006358.006358 cuda_h.py:19] end layer_moe_generate_15 cost 0.06695270538330078 seconds
DEBUG 01-06 17:11:02.006251.006251 lmp.py:220] -------------------------------- end layer 15 --------------------------------
DEBUG 01-06 17:11:02.006914.006914 lmp.py:176] -------------------------------- start layer 16 --------------------------------
DEBUG 01-06 17:11:02.006226.006226 cuda_h.py:10] start start_load_qkvogn_s_weight_l_17
DEBUG 01-06 17:11:02.006121.006121 cuda_h.py:10] start start_load_qkvogn_s_weight_l_17
DEBUG 01-06 17:11:02.006010.006010 cuda_h.py:19] end start_load_qkvogn_s_weight_l_17 cost 3.24249267578125e-05 seconds
DEBUG 01-06 17:11:02.006065.006065 cuda_h.py:19] end start_load_qkvogn_s_weight_l_17 cost 7.867813110351562e-05 seconds
DEBUG 01-06 17:11:02.006708.006708 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-06 17:11:02.007122.007122 mlpmodule.py:367] cuda:1 cuda:1
DEBUG 01-06 17:11:02.007131.007131 cuda_h.py:10] start sllm_worker_task
DEBUG 01-06 17:11:02.007273.007273 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 17:11:02.007640.007640 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 17:11:02.007856.007856 cuda_h.py:19] end allocate_cuda_memory cost 0.00029921531677246094 seconds
DEBUG 01-06 17:11:02.007256.007256 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 17:11:02.007973.007973 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 17:11:02.007319.007319 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 17:11:02.007829.007829 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 58b72550-b5cb-4ce7-b3cc-409b241fbac2
DEBUG 01-06 17:11:02.007415.007415 client.py:106] call stub.LoadModelAsync
DEBUG 01-06 17:11:02.008250.008250 cuda_h.py:10] start self_attn
INFO 01-06 17:11:02.009065.009065 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 58b72550-b5cb-4ce7-b3cc-409b241fbac2
DEBUG 01-06 17:11:02.009763.009763 cuda_h.py:19] end load_into_gpu_async cost 0.0016353130340576172 seconds
DEBUG 01-06 17:11:02.009558.009558 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 17:11:02.009449.009449 cuda_h.py:19] end restore_tensors2 cost 6.890296936035156e-05 seconds
DEBUG 01-06 17:11:02.009774.009774 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.002263307571411133 seconds
INFO 01-06 17:11:02.009557.009557 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 58b72550-b5cb-4ce7-b3cc-409b241fbac2
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-06 17:11:02.011806.011806 cuda_h.py:19] end self_attn cost 0.002875804901123047 seconds
DEBUG 01-06 17:11:02.011359.011359 cuda_h.py:19] end iln_self_attn_paln cost 0.004380226135253906 seconds
DEBUG 01-06 17:11:02.011553.011553 cuda_h.py:10] start layer_moe_generate_16
DEBUG 01-06 17:11:02.011555.011555 cuda_h.py:10] start gate
DEBUG 01-06 17:11:02.012379.012379 cuda_h.py:19] end gate cost 0.0006422996520996094 seconds
DEBUG 01-06 17:11:02.012115.012115 cuda_h.py:10] start experts_map_get
DEBUG 01-06 17:11:02.012775.012775 lmp.py:403] 
DEBUG 01-06 17:11:02.012775.012775 lmp.py:403] Expert Token Distribution & Device Allocation:
DEBUG 01-06 17:11:02.012961.012961 lmp.py:404]   Total experts: 64
DEBUG 01-06 17:11:02.012088.012088 lmp.py:405]   CPU experts: 32 (50%)
DEBUG 01-06 17:11:02.012877.012877 lmp.py:406]   GPU experts: 32 (50%)
DEBUG 01-06 17:11:02.012281.012281 lmp.py:407] 
DEBUG 01-06 17:11:02.012281.012281 lmp.py:407]   Expert ID | Tokens | Device
DEBUG 01-06 17:11:02.012924.012924 lmp.py:408]   -----------------------------------
DEBUG 01-06 17:11:02.012766.012766 lmp.py:414]   Expert 58 |     30 | CPU
DEBUG 01-06 17:11:02.012171.012171 lmp.py:414]   Expert 31 |     60 | CPU
DEBUG 01-06 17:11:02.012860.012860 lmp.py:414]   Expert 47 |     61 | CPU
DEBUG 01-06 17:11:02.012311.012311 lmp.py:414]   Expert 49 |     61 | CPU
DEBUG 01-06 17:11:02.012046.012046 lmp.py:414]   Expert  4 |     63 | CPU
DEBUG 01-06 17:11:02.012259.012259 lmp.py:414]   Expert 38 |     70 | CPU
DEBUG 01-06 17:11:02.012995.012995 lmp.py:414]   Expert 43 |     73 | CPU
DEBUG 01-06 17:11:02.012207.012207 lmp.py:414]   Expert 45 |     74 | CPU
DEBUG 01-06 17:11:02.012135.012135 lmp.py:414]   Expert 41 |     91 | CPU
DEBUG 01-06 17:11:02.012824.012824 lmp.py:414]   Expert 33 |     99 | CPU
DEBUG 01-06 17:11:02.012275.012275 lmp.py:414]   Expert 50 |    100 | CPU
DEBUG 01-06 17:11:02.012964.012964 lmp.py:414]   Expert 57 |    100 | CPU
DEBUG 01-06 17:11:02.012415.012415 lmp.py:414]   Expert 11 |    108 | CPU
DEBUG 01-06 17:11:02.012628.012628 lmp.py:414]   Expert 51 |    111 | CPU
DEBUG 01-06 17:11:02.012363.012363 lmp.py:414]   Expert  2 |    113 | CPU
DEBUG 01-06 17:11:02.012337.012337 lmp.py:414]   Expert 54 |    122 | CPU
DEBUG 01-06 17:11:02.012311.012311 lmp.py:414]   Expert 14 |    125 | CPU
DEBUG 01-06 17:11:02.012524.012524 lmp.py:414]   Expert  0 |    126 | CPU
DEBUG 01-06 17:11:02.012498.012498 lmp.py:414]   Expert 56 |    130 | CPU
DEBUG 01-06 17:11:02.012995.012995 lmp.py:414]   Expert 34 |    140 | CPU
DEBUG 01-06 17:11:02.012115.012115 lmp.py:414]   Expert 26 |    145 | CPU
DEBUG 01-06 17:11:02.012758.012758 lmp.py:414]   Expert 27 |    154 | CPU
DEBUG 01-06 17:11:02.012685.012685 lmp.py:414]   Expert 28 |    158 | CPU
DEBUG 01-06 17:11:02.012090.012090 lmp.py:414]   Expert 55 |    161 | CPU
DEBUG 01-06 17:11:02.013495.013495 lmp.py:414]   Expert 25 |    165 | CPU
DEBUG 01-06 17:11:02.013184.013184 lmp.py:414]   Expert 10 |    167 | CPU
DEBUG 01-06 17:11:02.013873.013873 lmp.py:414]   Expert 13 |    177 | CPU
DEBUG 01-06 17:11:02.013324.013324 lmp.py:414]   Expert  9 |    183 | CPU
DEBUG 01-06 17:11:02.013775.013775 lmp.py:414]   Expert 61 |    189 | CPU
DEBUG 01-06 17:11:02.013226.013226 lmp.py:414]   Expert 48 |    191 | CPU
DEBUG 01-06 17:11:02.013677.013677 lmp.py:414]   Expert  7 |    192 | CPU
DEBUG 01-06 17:11:02.013366.013366 lmp.py:414]   Expert 24 |    193 | CPU
DEBUG 01-06 17:11:02.013817.013817 lmp.py:414]   Expert  6 |    195 | GPU
DEBUG 01-06 17:11:02.013937.013937 lmp.py:414]   Expert 42 |    198 | GPU
DEBUG 01-06 17:11:02.013580.013580 lmp.py:414]   Expert 46 |    200 | GPU
DEBUG 01-06 17:11:02.013746.013746 lmp.py:414]   Expert 18 |    201 | GPU
DEBUG 01-06 17:11:02.013150.013150 lmp.py:414]   Expert 40 |    206 | GPU
DEBUG 01-06 17:11:02.013509.013509 lmp.py:414]   Expert 59 |    215 | GPU
DEBUG 01-06 17:11:02.013198.013198 lmp.py:414]   Expert 21 |    216 | GPU
DEBUG 01-06 17:11:02.013126.013126 lmp.py:414]   Expert 12 |    219 | GPU
DEBUG 01-06 17:11:02.013576.013576 lmp.py:414]   Expert 29 |    219 | GPU
DEBUG 01-06 17:11:02.013027.013027 lmp.py:414]   Expert 32 |    221 | GPU
DEBUG 01-06 17:11:02.013717.013717 lmp.py:414]   Expert 63 |    222 | GPU
DEBUG 01-06 17:11:02.013168.013168 lmp.py:414]   Expert 19 |    225 | GPU
DEBUG 01-06 17:11:02.013618.013618 lmp.py:414]   Expert 22 |    229 | GPU
DEBUG 01-06 17:11:02.013308.013308 lmp.py:414]   Expert 36 |    237 | GPU
DEBUG 01-06 17:11:02.013235.013235 lmp.py:414]   Expert  3 |    238 | GPU
DEBUG 01-06 17:11:02.013402.013402 lmp.py:414]   Expert  1 |    247 | GPU
DEBUG 01-06 17:11:02.013568.013568 lmp.py:414]   Expert 16 |    251 | GPU
DEBUG 01-06 17:11:02.013734.013734 lmp.py:414]   Expert 37 |    254 | GPU
DEBUG 01-06 17:11:02.013423.013423 lmp.py:414]   Expert  8 |    261 | GPU
DEBUG 01-06 17:11:02.013874.013874 lmp.py:414]   Expert  5 |    264 | GPU
DEBUG 01-06 17:11:02.013087.013087 lmp.py:414]   Expert 20 |    265 | GPU
DEBUG 01-06 17:11:02.013014.013014 lmp.py:414]   Expert 30 |    266 | GPU
DEBUG 01-06 17:11:02.013227.013227 lmp.py:414]   Expert 15 |    271 | GPU
DEBUG 01-06 17:11:02.013201.013201 lmp.py:414]   Expert 62 |    273 | GPU
DEBUG 01-06 17:11:02.013413.013413 lmp.py:414]   Expert 35 |    291 | GPU
DEBUG 01-06 17:11:02.013626.013626 lmp.py:414]   Expert 17 |    297 | GPU
DEBUG 01-06 17:11:02.013838.013838 lmp.py:414]   Expert 39 |    300 | GPU
DEBUG 01-06 17:11:02.013051.013051 lmp.py:414]   Expert 60 |    315 | GPU
DEBUG 01-06 17:11:02.013978.013978 lmp.py:414]   Expert 52 |    357 | GPU
DEBUG 01-06 17:11:02.013144.013144 lmp.py:414]   Expert 23 |    371 | GPU
DEBUG 01-06 17:11:02.013311.013311 lmp.py:414]   Expert 44 |    382 | GPU
DEBUG 01-06 17:11:02.013761.013761 lmp.py:414]   Expert 53 |    450 | GPU
DEBUG 01-06 17:11:02.013643.013643 lmp.py:415] 
DEBUG 01-06 17:11:02.013643.013643 lmp.py:415]   CPU total tokens: 3932 (32.0%)
DEBUG 01-06 17:11:02.013047.013047 lmp.py:416]   GPU total tokens: 8356 (68.0%)
DEBUG 01-06 17:11:02.013982.013982 cuda_h.py:19] end experts_map_get cost 0.0015230178833007812 seconds
DEBUG 01-06 17:11:02.013625.013625 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-06 17:11:02.013309.013309 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 17:11:02.013485.013485 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 17:11:02.014288.014288 cuda_h.py:19] end allocate_cuda_memory cost 0.0008044242858886719 seconds
DEBUG 01-06 17:11:02.014098.014098 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 17:11:02.014239.014239 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 17:11:02.014332.014332 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 17:11:02.014174.014174 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 65c83c75-4f3e-4b39-84ea-8c3e05f9ba90
DEBUG 01-06 17:11:02.015644.015644 client.py:106] call stub.LoadModelAsync
INFO 01-06 17:11:02.017452.017452 client.py:127] Model loaded
DEBUG 01-06 17:11:02.018477.018477 cuda_h.py:19] end sllm_worker_task cost 0.011038064956665039 seconds
INFO 01-06 17:11:02.018854.018854 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 65c83c75-4f3e-4b39-84ea-8c3e05f9ba90
DEBUG 01-06 17:11:02.019958.019958 cuda_h.py:19] end load_into_gpu_async cost 0.004269123077392578 seconds
DEBUG 01-06 17:11:02.019782.019782 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 17:11:02.019710.019710 cuda_h.py:19] end restore_tensors2 cost 0.0003387928009033203 seconds
DEBUG 01-06 17:11:02.019148.019148 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.005862712860107422 seconds
DEBUG 01-06 17:11:02.022248.022248 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.008509159088134766 seconds
DEBUG 01-06 17:11:02.022985.022985 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-06 17:11:02.022730.022730 lmp.py:461] 
DEBUG 01-06 17:11:02.022730.022730 lmp.py:461]   Computing 32 experts on CPU...
DEBUG 01-06 17:11:02.022004.022004 cuda_h.py:19] end cpu_experts_submit cost 0.00011014938354492188 seconds
DEBUG 01-06 17:11:02.022369.022369 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-06 17:11:02.034922.034922 mlpmodule.py:706] group tensors cost 0.012151956558227539 s
DEBUG 01-06 17:11:02.037658.037658 mlpmodule.py:744] pad cost 0.0016374588012695312 s
DEBUG 01-06 17:11:02.037616.037616 mlpmodule.py:750] create cpu tensor cost 4.673004150390625e-05 s
DEBUG 01-06 17:11:02.037996.037996 mlpmodule.py:755] move to cpu cost 3.2901763916015625e-05 s
DEBUG 01-06 17:11:02.048504.048504 mlpmodule.py:769] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-06 17:11:02.048599.048599 mlpmodule.py:770] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-06 17:11:02.049357.049357 mlpmodule.py:775] group_w3 first element: -0.02490234375
WARNING 01-06 17:11:02.049254.049254 mlpmodule.py:785] start einsum2
DEBUG 01-06 17:11:02.068680.068680 mlpmodule.py:795] group einsum cost 0.031077146530151367 s
DEBUG 01-06 17:11:02.069726.069726 mlpmodule.py:803] cpy2cputensor cost 0.0006878376007080078 s
DEBUG 01-06 17:11:02.073035.073035 cuda_h.py:19] end wait_cetm_experts cost 0.05106854438781738 seconds
DEBUG 01-06 17:11:02.073432.073432 cuda_h.py:10] start gpu_sexperts
DEBUG 01-06 17:11:02.074553.074553 cuda_h.py:19] end gpu_sexperts cost 0.0006055831909179688 seconds
DEBUG 01-06 17:11:02.074119.074119 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-06 17:11:02.074790.074790 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 3.314018249511719e-05 seconds
DEBUG 01-06 17:11:02.074208.074208 cuda_h.py:10] start wait_experts
INFO 01-06 17:11:02.074786.074786 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 65c83c75-4f3e-4b39-84ea-8c3e05f9ba90
INFO 01-06 17:11:02.075146.075146 client.py:127] Model loaded
DEBUG 01-06 17:11:02.076281.076281 cuda_h.py:19] end wait_experts cost 0.0013568401336669922 seconds
DEBUG 01-06 17:11:02.076752.076752 cuda_h.py:10] start gpu_experts
DEBUG 01-06 17:11:02.076416.076416 lmp.py:506]   Computing 32 experts on GPU...
DEBUG 01-06 17:11:02.076235.076235 mlpmodule.py:533] gpu group tensors cost 0.0006501674652099609 s
DEBUG 01-06 17:11:02.078647.078647 mlpmodule.py:566] gpu pad cost 0.0017573833465576172 s
DEBUG 01-06 17:11:02.079178.079178 mlpmodule.py:584] gpu group einsum cost 0.0005629062652587891 s
DEBUG 01-06 17:11:02.081030.081030 mlpmodule.py:664]  experts func einsum cost 0.05910611152648926 s
DEBUG 01-06 17:11:02.083436.083436 mlpmodule.py:613] gpu experts func einsum cost 0.0070345401763916016 s
DEBUG 01-06 17:11:02.083931.083931 cuda_h.py:19] end gpu_experts cost 0.0072977542877197266 seconds
DEBUG 01-06 17:11:02.083544.083544 cuda_h.py:19] end layer_moe_generate_16 cost 0.07207632064819336 seconds
DEBUG 01-06 17:11:02.083955.083955 lmp.py:220] -------------------------------- end layer 16 --------------------------------
DEBUG 01-06 17:11:02.083486.083486 lmp.py:176] -------------------------------- start layer 17 --------------------------------
DEBUG 01-06 17:11:02.083858.083858 cuda_h.py:10] start start_load_qkvogn_s_weight_l_18
DEBUG 01-06 17:11:02.083521.083521 cuda_h.py:10] start start_load_qkvogn_s_weight_l_18
DEBUG 01-06 17:11:02.083987.083987 cuda_h.py:19] end start_load_qkvogn_s_weight_l_18 cost 3.5762786865234375e-05 seconds
DEBUG 01-06 17:11:02.083359.083359 cuda_h.py:19] end start_load_qkvogn_s_weight_l_18 cost 6.818771362304688e-05 seconds
DEBUG 01-06 17:11:02.083200.083200 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-06 17:11:02.083918.083918 mlpmodule.py:367] cuda:1 cuda:1
DEBUG 01-06 17:11:02.084271.084271 cuda_h.py:10] start sllm_worker_task
DEBUG 01-06 17:11:02.084295.084295 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 17:11:02.084767.084767 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 17:11:02.084335.084335 cuda_h.py:19] end allocate_cuda_memory cost 0.0003037452697753906 seconds
DEBUG 01-06 17:11:02.084219.084219 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 17:11:02.084333.084333 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 17:11:02.084401.084401 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 17:11:02.084879.084879 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 565469dd-8a01-4652-8886-df0f08b9cdbd
DEBUG 01-06 17:11:02.084279.084279 client.py:106] call stub.LoadModelAsync
DEBUG 01-06 17:11:02.085726.085726 cuda_h.py:10] start self_attn
INFO 01-06 17:11:02.086098.086098 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 565469dd-8a01-4652-8886-df0f08b9cdbd
DEBUG 01-06 17:11:02.086557.086557 cuda_h.py:19] end load_into_gpu_async cost 0.0015366077423095703 seconds
DEBUG 01-06 17:11:02.086591.086591 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 17:11:02.086720.086720 cuda_h.py:19] end restore_tensors2 cost 6.890296936035156e-05 seconds
DEBUG 01-06 17:11:02.086959.086959 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0022096633911132812 seconds
INFO 01-06 17:11:02.086319.086319 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 565469dd-8a01-4652-8886-df0f08b9cdbd
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-06 17:11:02.088957.088957 cuda_h.py:19] end self_attn cost 0.0028836727142333984 seconds
DEBUG 01-06 17:11:02.088153.088153 cuda_h.py:19] end iln_self_attn_paln cost 0.004498958587646484 seconds
DEBUG 01-06 17:11:02.088718.088718 cuda_h.py:10] start layer_moe_generate_17
DEBUG 01-06 17:11:02.088389.088389 cuda_h.py:10] start gate
DEBUG 01-06 17:11:02.089219.089219 cuda_h.py:19] end gate cost 0.0006480216979980469 seconds
DEBUG 01-06 17:11:02.089380.089380 cuda_h.py:10] start experts_map_get
DEBUG 01-06 17:11:02.089979.089979 lmp.py:403] 
DEBUG 01-06 17:11:02.089979.089979 lmp.py:403] Expert Token Distribution & Device Allocation:
DEBUG 01-06 17:11:02.089020.089020 lmp.py:404]   Total experts: 64
DEBUG 01-06 17:11:02.089432.089432 lmp.py:405]   CPU experts: 32 (50%)
DEBUG 01-06 17:11:02.089743.089743 lmp.py:406]   GPU experts: 32 (50%)
DEBUG 01-06 17:11:02.089148.089148 lmp.py:407] 
DEBUG 01-06 17:11:02.089148.089148 lmp.py:407]   Expert ID | Tokens | Device
DEBUG 01-06 17:11:02.089837.089837 lmp.py:408]   -----------------------------------
DEBUG 01-06 17:11:02.089202.089202 lmp.py:414]   Expert  4 |     10 | CPU
DEBUG 01-06 17:11:02.089845.089845 lmp.py:414]   Expert 28 |     27 | CPU
DEBUG 01-06 17:11:02.089058.089058 lmp.py:414]   Expert  7 |     45 | CPU
DEBUG 01-06 17:11:02.089509.089509 lmp.py:414]   Expert 53 |     57 | CPU
DEBUG 01-06 17:11:02.089390.089390 lmp.py:414]   Expert 52 |     67 | CPU
DEBUG 01-06 17:11:02.089556.089556 lmp.py:414]   Expert 43 |     74 | CPU
DEBUG 01-06 17:11:02.089199.089199 lmp.py:414]   Expert 49 |     85 | CPU
DEBUG 01-06 17:11:02.089127.089127 lmp.py:414]   Expert 12 |     87 | CPU
DEBUG 01-06 17:11:02.089247.089247 lmp.py:414]   Expert 47 |     99 | CPU
DEBUG 01-06 17:11:02.089413.089413 lmp.py:414]   Expert 24 |    100 | CPU
DEBUG 01-06 17:11:02.089817.089817 lmp.py:414]   Expert 15 |    107 | CPU
DEBUG 01-06 17:11:02.089745.089745 lmp.py:414]   Expert 50 |    108 | CPU
DEBUG 01-06 17:11:02.089434.089434 lmp.py:414]   Expert 33 |    109 | CPU
DEBUG 01-06 17:11:02.089124.089124 lmp.py:414]   Expert  2 |    111 | CPU
DEBUG 01-06 17:11:02.089813.089813 lmp.py:414]   Expert 39 |    112 | CPU
DEBUG 01-06 17:11:02.089025.089025 lmp.py:414]   Expert 36 |    118 | CPU
DEBUG 01-06 17:11:02.089715.089715 lmp.py:414]   Expert 60 |    119 | CPU
DEBUG 01-06 17:11:02.090404.090404 lmp.py:414]   Expert 61 |    125 | CPU
DEBUG 01-06 17:11:02.090093.090093 lmp.py:414]   Expert 25 |    128 | CPU
DEBUG 01-06 17:11:02.090260.090260 lmp.py:414]   Expert  6 |    130 | CPU
DEBUG 01-06 17:11:02.090664.090664 lmp.py:414]   Expert 59 |    138 | CPU
DEBUG 01-06 17:11:02.090830.090830 lmp.py:414]   Expert  3 |    145 | CPU
DEBUG 01-06 17:11:02.090235.090235 lmp.py:414]   Expert 27 |    147 | CPU
DEBUG 01-06 17:11:02.090162.090162 lmp.py:414]   Expert  8 |    150 | CPU
DEBUG 01-06 17:11:02.090852.090852 lmp.py:414]   Expert 30 |    153 | CPU
DEBUG 01-06 17:11:02.090541.090541 lmp.py:414]   Expert 58 |    153 | CPU
DEBUG 01-06 17:11:02.090230.090230 lmp.py:414]   Expert 31 |    155 | CPU
DEBUG 01-06 17:11:02.090920.090920 lmp.py:414]   Expert 10 |    157 | CPU
DEBUG 01-06 17:11:02.090132.090132 lmp.py:414]   Expert 38 |    158 | CPU
DEBUG 01-06 17:11:02.090821.090821 lmp.py:414]   Expert 14 |    159 | CPU
DEBUG 01-06 17:11:02.090272.090272 lmp.py:414]   Expert 40 |    159 | CPU
DEBUG 01-06 17:11:02.090723.090723 lmp.py:414]   Expert 57 |    161 | CPU
DEBUG 01-06 17:11:02.090366.090366 lmp.py:414]   Expert 41 |    163 | GPU
DEBUG 01-06 17:11:02.090532.090532 lmp.py:414]   Expert 32 |    164 | GPU
DEBUG 01-06 17:11:02.090698.090698 lmp.py:414]   Expert 46 |    164 | GPU
DEBUG 01-06 17:11:02.090865.090865 lmp.py:414]   Expert 37 |    165 | GPU
DEBUG 01-06 17:11:02.090792.090792 lmp.py:414]   Expert 54 |    170 | GPU
DEBUG 01-06 17:11:02.090482.090482 lmp.py:414]   Expert 42 |    172 | GPU
DEBUG 01-06 17:11:02.090933.090933 lmp.py:414]   Expert 11 |    173 | GPU
DEBUG 01-06 17:11:02.090622.090622 lmp.py:414]   Expert 19 |    177 | GPU
DEBUG 01-06 17:11:02.090311.090311 lmp.py:414]   Expert 34 |    187 | GPU
DEBUG 01-06 17:11:02.090524.090524 lmp.py:414]   Expert 18 |    194 | GPU
DEBUG 01-06 17:11:02.090213.090213 lmp.py:414]   Expert  0 |    195 | GPU
DEBUG 01-06 17:11:02.090141.090141 lmp.py:414]   Expert 26 |    196 | GPU
DEBUG 01-06 17:11:02.090307.090307 lmp.py:414]   Expert 22 |    197 | GPU
DEBUG 01-06 17:11:02.090473.090473 lmp.py:414]   Expert  1 |    200 | GPU
DEBUG 01-06 17:11:02.090354.090354 lmp.py:414]   Expert 44 |    203 | GPU
DEBUG 01-06 17:11:02.090044.090044 lmp.py:414]   Expert 56 |    207 | GPU
DEBUG 01-06 17:11:02.090971.090971 lmp.py:414]   Expert 51 |    209 | GPU
DEBUG 01-06 17:11:02.090422.090422 lmp.py:414]   Expert 20 |    221 | GPU
DEBUG 01-06 17:11:02.090873.090873 lmp.py:414]   Expert 45 |    229 | GPU
DEBUG 01-06 17:11:02.090324.090324 lmp.py:414]   Expert 29 |    230 | GPU
DEBUG 01-06 17:11:02.090775.090775 lmp.py:414]   Expert 48 |    231 | GPU
DEBUG 01-06 17:11:02.090987.090987 lmp.py:414]   Expert 21 |    246 | GPU
DEBUG 01-06 17:11:02.090438.090438 lmp.py:414]   Expert 16 |    255 | GPU
DEBUG 01-06 17:11:02.090320.090320 lmp.py:414]   Expert 35 |    256 | GPU
DEBUG 01-06 17:11:02.090486.090486 lmp.py:414]   Expert 55 |    260 | GPU
DEBUG 01-06 17:11:02.090652.090652 lmp.py:414]   Expert  5 |    294 | GPU
DEBUG 01-06 17:11:02.090818.090818 lmp.py:414]   Expert 23 |    378 | GPU
DEBUG 01-06 17:11:02.090461.090461 lmp.py:414]   Expert 13 |    388 | GPU
DEBUG 01-06 17:11:02.090150.090150 lmp.py:414]   Expert 17 |    435 | GPU
DEBUG 01-06 17:11:02.090078.090078 lmp.py:414]   Expert  9 |    441 | GPU
DEBUG 01-06 17:11:02.090290.090290 lmp.py:414]   Expert 63 |    454 | GPU
DEBUG 01-06 17:11:02.090741.090741 lmp.py:414]   Expert 62 |   1181 | GPU
DEBUG 01-06 17:11:02.090907.090907 lmp.py:415] 
DEBUG 01-06 17:11:02.090907.090907 lmp.py:415]   CPU total tokens: 3653 (29.7%)
DEBUG 01-06 17:11:02.090312.090312 lmp.py:416]   GPU total tokens: 8635 (70.3%)
DEBUG 01-06 17:11:02.090008.090008 cuda_h.py:19] end experts_map_get cost 0.0015201568603515625 seconds
DEBUG 01-06 17:11:02.090082.090082 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-06 17:11:02.090719.090719 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 17:11:02.091532.091532 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 17:11:02.092120.092120 cuda_h.py:19] end allocate_cuda_memory cost 0.0015230178833007812 seconds
DEBUG 01-06 17:11:02.092792.092792 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 17:11:02.092793.092793 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 17:11:02.092701.092701 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 17:11:02.092543.092543 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, f86c5965-3e04-4542-ae55-74bfafe9fd84
DEBUG 01-06 17:11:02.092735.092735 client.py:106] call stub.LoadModelAsync
INFO 01-06 17:11:02.094914.094914 client.py:127] Model loaded
DEBUG 01-06 17:11:02.094457.094457 cuda_h.py:19] end sllm_worker_task cost 0.01058650016784668 seconds
INFO 01-06 17:11:02.095541.095541 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, f86c5965-3e04-4542-ae55-74bfafe9fd84
DEBUG 01-06 17:11:02.095715.095715 cuda_h.py:19] end load_into_gpu_async cost 0.0032091140747070312 seconds
DEBUG 01-06 17:11:02.095941.095941 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 17:11:02.096024.096024 cuda_h.py:19] end restore_tensors2 cost 0.00028204917907714844 seconds
DEBUG 01-06 17:11:02.096853.096853 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0053730010986328125 seconds
DEBUG 01-06 17:11:02.098809.098809 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.008057355880737305 seconds
DEBUG 01-06 17:11:02.098592.098592 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-06 17:11:02.099217.099217 lmp.py:461] 
DEBUG 01-06 17:11:02.099217.099217 lmp.py:461]   Computing 32 experts on CPU...
DEBUG 01-06 17:11:02.099729.099729 cuda_h.py:19] end cpu_experts_submit cost 0.00010800361633300781 seconds
DEBUG 01-06 17:11:02.099141.099141 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-06 17:11:02.111866.111866 mlpmodule.py:706] group tensors cost 0.012550592422485352 s
DEBUG 01-06 17:11:02.114549.114549 mlpmodule.py:744] pad cost 0.0016024112701416016 s
DEBUG 01-06 17:11:02.114546.114546 mlpmodule.py:750] create cpu tensor cost 4.363059997558594e-05 s
DEBUG 01-06 17:11:02.114826.114826 mlpmodule.py:755] move to cpu cost 3.2901763916015625e-05 s
DEBUG 01-06 17:11:02.125860.125860 mlpmodule.py:769] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-06 17:11:02.125525.125525 mlpmodule.py:770] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-06 17:11:02.125898.125898 mlpmodule.py:775] group_w3 first element: 0.00457763671875
WARNING 01-06 17:11:02.125795.125795 mlpmodule.py:785] start einsum2
DEBUG 01-06 17:11:02.143615.143615 mlpmodule.py:795] group einsum cost 0.028664827346801758 s
DEBUG 01-06 17:11:02.143003.143003 mlpmodule.py:803] cpy2cputensor cost 0.0006330013275146484 s
DEBUG 01-06 17:11:02.148232.148232 cuda_h.py:19] end wait_cetm_experts cost 0.048929452896118164 seconds
DEBUG 01-06 17:11:02.148662.148662 cuda_h.py:10] start gpu_sexperts
DEBUG 01-06 17:11:02.149393.149393 cuda_h.py:19] end gpu_sexperts cost 0.0006310939788818359 seconds
DEBUG 01-06 17:11:02.149072.149072 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-06 17:11:02.149829.149829 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.384185791015625e-05 seconds
DEBUG 01-06 17:11:02.149770.149770 cuda_h.py:10] start wait_experts
INFO 01-06 17:11:02.149288.149288 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, f86c5965-3e04-4542-ae55-74bfafe9fd84
INFO 01-06 17:11:02.150285.150285 client.py:127] Model loaded
DEBUG 01-06 17:11:02.150704.150704 cuda_h.py:19] end wait_experts cost 0.0013604164123535156 seconds
DEBUG 01-06 17:11:02.150937.150937 cuda_h.py:10] start gpu_experts
DEBUG 01-06 17:11:02.150845.150845 lmp.py:506]   Computing 32 experts on GPU...
DEBUG 01-06 17:11:02.151710.151710 mlpmodule.py:533] gpu group tensors cost 0.0006163120269775391 s
DEBUG 01-06 17:11:02.155666.155666 mlpmodule.py:566] gpu pad cost 0.004157066345214844 s
DEBUG 01-06 17:11:02.156375.156375 mlpmodule.py:664]  experts func einsum cost 0.0574498176574707 s
DEBUG 01-06 17:11:02.157514.157514 mlpmodule.py:584] gpu group einsum cost 0.0015106201171875 s
DEBUG 01-06 17:11:02.160805.160805 mlpmodule.py:613] gpu experts func einsum cost 0.009567975997924805 s
DEBUG 01-06 17:11:02.160225.160225 cuda_h.py:19] end gpu_experts cost 0.009761810302734375 seconds
DEBUG 01-06 17:11:02.160321.160321 cuda_h.py:19] end layer_moe_generate_17 cost 0.07197046279907227 seconds
DEBUG 01-06 17:11:02.160983.160983 lmp.py:220] -------------------------------- end layer 17 --------------------------------
DEBUG 01-06 17:11:02.160415.160415 lmp.py:176] -------------------------------- start layer 18 --------------------------------
DEBUG 01-06 17:11:02.160680.160680 cuda_h.py:10] start start_load_qkvogn_s_weight_l_19
DEBUG 01-06 17:11:02.160482.160482 cuda_h.py:10] start start_load_qkvogn_s_weight_l_19
DEBUG 01-06 17:11:02.160524.160524 cuda_h.py:19] end start_load_qkvogn_s_weight_l_19 cost 3.457069396972656e-05 seconds
DEBUG 01-06 17:11:02.160466.160466 cuda_h.py:19] end start_load_qkvogn_s_weight_l_19 cost 7.224082946777344e-05 seconds
DEBUG 01-06 17:11:02.160016.160016 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-06 17:11:02.160217.160217 mlpmodule.py:367] cuda:1 cuda:1
DEBUG 01-06 17:11:02.161034.161034 cuda_h.py:10] start sllm_worker_task
DEBUG 01-06 17:11:02.161170.161170 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 17:11:02.161576.161576 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 17:11:02.161670.161670 cuda_h.py:19] end allocate_cuda_memory cost 0.00020933151245117188 seconds
DEBUG 01-06 17:11:02.161640.161640 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 17:11:02.161926.161926 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 17:11:02.161040.161040 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 17:11:02.161505.161505 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 7e24a6e4-5a07-433d-a9a5-e72851a217fe
DEBUG 01-06 17:11:02.161236.161236 client.py:106] call stub.LoadModelAsync
DEBUG 01-06 17:11:02.161859.161859 cuda_h.py:10] start self_attn
INFO 01-06 17:11:02.163379.163379 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 7e24a6e4-5a07-433d-a9a5-e72851a217fe
DEBUG 01-06 17:11:02.163738.163738 cuda_h.py:19] end load_into_gpu_async cost 0.0015113353729248047 seconds
DEBUG 01-06 17:11:02.163057.163057 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 17:11:02.163762.163762 cuda_h.py:19] end restore_tensors2 cost 7.176399230957031e-05 seconds
DEBUG 01-06 17:11:02.163326.163326 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.002046823501586914 seconds
INFO 01-06 17:11:02.163924.163924 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 7e24a6e4-5a07-433d-a9a5-e72851a217fe
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-06 17:11:02.164890.164890 cuda_h.py:19] end self_attn cost 0.002840757369995117 seconds
DEBUG 01-06 17:11:02.165622.165622 cuda_h.py:19] end iln_self_attn_paln cost 0.004196882247924805 seconds
DEBUG 01-06 17:11:02.165604.165604 cuda_h.py:10] start layer_moe_generate_18
DEBUG 01-06 17:11:02.165082.165082 cuda_h.py:10] start gate
DEBUG 01-06 17:11:02.165329.165329 cuda_h.py:19] end gate cost 0.0006403923034667969 seconds
DEBUG 01-06 17:11:02.165775.165775 cuda_h.py:10] start experts_map_get
DEBUG 01-06 17:11:02.166937.166937 lmp.py:403] 
DEBUG 01-06 17:11:02.166937.166937 lmp.py:403] Expert Token Distribution & Device Allocation:
DEBUG 01-06 17:11:02.166739.166739 lmp.py:404]   Total experts: 64
DEBUG 01-06 17:11:02.166151.166151 lmp.py:405]   CPU experts: 32 (50%)
DEBUG 01-06 17:11:02.166224.166224 lmp.py:406]   GPU experts: 32 (50%)
DEBUG 01-06 17:11:02.166152.166152 lmp.py:407] 
DEBUG 01-06 17:11:02.166152.166152 lmp.py:407]   Expert ID | Tokens | Device
DEBUG 01-06 17:11:02.166795.166795 lmp.py:408]   -----------------------------------
DEBUG 01-06 17:11:02.166398.166398 lmp.py:414]   Expert 32 |     37 | CPU
DEBUG 01-06 17:11:02.166803.166803 lmp.py:414]   Expert  5 |     53 | CPU
DEBUG 01-06 17:11:02.166254.166254 lmp.py:414]   Expert 30 |     55 | CPU
DEBUG 01-06 17:11:02.166704.166704 lmp.py:414]   Expert 46 |     71 | CPU
DEBUG 01-06 17:11:02.166679.166679 lmp.py:414]   Expert 40 |     87 | CPU
DEBUG 01-06 17:11:02.166891.166891 lmp.py:414]   Expert  8 |     90 | CPU
DEBUG 01-06 17:11:02.166865.166865 lmp.py:414]   Expert 12 |     94 | CPU
DEBUG 01-06 17:11:02.166077.166077 lmp.py:414]   Expert 17 |    105 | CPU
DEBUG 01-06 17:11:02.166528.166528 lmp.py:414]   Expert 27 |    109 | CPU
DEBUG 01-06 17:11:02.166456.166456 lmp.py:414]   Expert  3 |    110 | CPU
DEBUG 01-06 17:11:02.166669.166669 lmp.py:414]   Expert 58 |    112 | CPU
DEBUG 01-06 17:11:02.166119.166119 lmp.py:414]   Expert 60 |    117 | CPU
DEBUG 01-06 17:11:02.166809.166809 lmp.py:414]   Expert 28 |    120 | CPU
DEBUG 01-06 17:11:02.166405.166405 lmp.py:414]   Expert 29 |    121 | CPU
DEBUG 01-06 17:11:02.166618.166618 lmp.py:414]   Expert 25 |    122 | CPU
DEBUG 01-06 17:11:02.166115.166115 lmp.py:414]   Expert 21 |    126 | CPU
DEBUG 01-06 17:11:02.166089.166089 lmp.py:414]   Expert 41 |    130 | CPU
DEBUG 01-06 17:11:02.166540.166540 lmp.py:414]   Expert 35 |    131 | CPU
DEBUG 01-06 17:11:02.166276.166276 lmp.py:414]   Expert 19 |    136 | CPU
DEBUG 01-06 17:11:02.166011.166011 lmp.py:414]   Expert 52 |    136 | CPU
DEBUG 01-06 17:11:02.166747.166747 lmp.py:414]   Expert 54 |    140 | CPU
DEBUG 01-06 17:11:02.166959.166959 lmp.py:414]   Expert  0 |    144 | CPU
DEBUG 01-06 17:11:02.166933.166933 lmp.py:414]   Expert  6 |    147 | CPU
DEBUG 01-06 17:11:02.166146.166146 lmp.py:414]   Expert 37 |    148 | CPU
DEBUG 01-06 17:11:02.166835.166835 lmp.py:414]   Expert 56 |    153 | CPU
DEBUG 01-06 17:11:02.166286.166286 lmp.py:414]   Expert 63 |    155 | CPU
DEBUG 01-06 17:11:02.166498.166498 lmp.py:414]   Expert 53 |    158 | CPU
DEBUG 01-06 17:11:02.166188.166188 lmp.py:414]   Expert 48 |    161 | CPU
DEBUG 01-06 17:11:02.166639.166639 lmp.py:414]   Expert 36 |    164 | CPU
DEBUG 01-06 17:11:02.166613.166613 lmp.py:414]   Expert 59 |    168 | CPU
DEBUG 01-06 17:11:02.166110.166110 lmp.py:414]   Expert  9 |    177 | CPU
DEBUG 01-06 17:11:02.166084.166084 lmp.py:414]   Expert 39 |    184 | CPU
DEBUG 01-06 17:11:02.166058.166058 lmp.py:414]   Expert  1 |    194 | GPU
DEBUG 01-06 17:11:02.166032.166032 lmp.py:414]   Expert 20 |    195 | GPU
DEBUG 01-06 17:11:02.166244.166244 lmp.py:414]   Expert 11 |    198 | GPU
DEBUG 01-06 17:11:02.166742.166742 lmp.py:414]   Expert 42 |    198 | GPU
DEBUG 01-06 17:11:02.166193.166193 lmp.py:414]   Expert 61 |    200 | GPU
DEBUG 01-06 17:11:02.166359.166359 lmp.py:414]   Expert  7 |    207 | GPU
DEBUG 01-06 17:11:02.166571.166571 lmp.py:414]   Expert 34 |    209 | GPU
DEBUG 01-06 17:11:02.167260.167260 lmp.py:414]   Expert 47 |    210 | GPU
DEBUG 01-06 17:11:02.167526.167526 lmp.py:414]   Expert 43 |    212 | GPU
DEBUG 01-06 17:11:02.167215.167215 lmp.py:414]   Expert 55 |    216 | GPU
DEBUG 01-06 17:11:02.167951.167951 lmp.py:414]   Expert 13 |    219 | GPU
DEBUG 01-06 17:11:02.167687.167687 lmp.py:414]   Expert 16 |    219 | GPU
DEBUG 01-06 17:11:02.167661.167661 lmp.py:414]   Expert 57 |    228 | GPU
DEBUG 01-06 17:11:02.167396.167396 lmp.py:414]   Expert 18 |    233 | GPU
DEBUG 01-06 17:11:02.167370.167370 lmp.py:414]   Expert 15 |    234 | GPU
DEBUG 01-06 17:11:02.167106.167106 lmp.py:414]   Expert  4 |    236 | GPU
DEBUG 01-06 17:11:02.167842.167842 lmp.py:414]   Expert 50 |    244 | GPU
DEBUG 01-06 17:11:02.167577.167577 lmp.py:414]   Expert 22 |    245 | GPU
DEBUG 01-06 17:11:02.167267.167267 lmp.py:414]   Expert 31 |    246 | GPU
DEBUG 01-06 17:11:02.167479.167479 lmp.py:414]   Expert 45 |    246 | GPU
DEBUG 01-06 17:11:02.167691.167691 lmp.py:414]   Expert 33 |    250 | GPU
DEBUG 01-06 17:11:02.167904.167904 lmp.py:414]   Expert 51 |    258 | GPU
DEBUG 01-06 17:11:02.167832.167832 lmp.py:414]   Expert 38 |    271 | GPU
DEBUG 01-06 17:11:02.167044.167044 lmp.py:414]   Expert 49 |    272 | GPU
DEBUG 01-06 17:11:02.167541.167541 lmp.py:414]   Expert 26 |    278 | GPU
DEBUG 01-06 17:11:02.167277.167277 lmp.py:414]   Expert 10 |    284 | GPU
DEBUG 01-06 17:11:02.167774.167774 lmp.py:414]   Expert 44 |    294 | GPU
DEBUG 01-06 17:11:02.167510.167510 lmp.py:414]   Expert 24 |    304 | GPU
DEBUG 01-06 17:11:02.167769.167769 lmp.py:414]   Expert  2 |    310 | GPU
DEBUG 01-06 17:11:02.167027.167027 lmp.py:414]   Expert 14 |    317 | GPU
DEBUG 01-06 17:11:02.167001.167001 lmp.py:414]   Expert 23 |    427 | GPU
DEBUG 01-06 17:11:02.167691.167691 lmp.py:414]   Expert 62 |    673 | GPU
DEBUG 01-06 17:11:02.167857.167857 lmp.py:415] 
DEBUG 01-06 17:11:02.167857.167857 lmp.py:415]   CPU total tokens: 3961 (32.2%)
DEBUG 01-06 17:11:02.167500.167500 lmp.py:416]   GPU total tokens: 8327 (67.8%)
DEBUG 01-06 17:11:02.167719.167719 cuda_h.py:19] end experts_map_get cost 0.001476287841796875 seconds
DEBUG 01-06 17:11:02.167124.167124 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-06 17:11:02.167330.167330 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 17:11:02.167269.167269 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 17:11:02.169794.169794 cuda_h.py:19] end allocate_cuda_memory cost 0.001615285873413086 seconds
DEBUG 01-06 17:11:02.169068.169068 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 17:11:02.169777.169777 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 17:11:02.169540.169540 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 17:11:02.169620.169620 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, ba47b172-fbde-4eff-85ee-58b425f87a2c
DEBUG 01-06 17:11:02.169844.169844 client.py:106] call stub.LoadModelAsync
INFO 01-06 17:11:02.170950.170950 client.py:127] Model loaded
DEBUG 01-06 17:11:02.171676.171676 cuda_h.py:19] end sllm_worker_task cost 0.010345697402954102 seconds
INFO 01-06 17:11:02.172368.172368 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, ba47b172-fbde-4eff-85ee-58b425f87a2c
DEBUG 01-06 17:11:02.172398.172398 cuda_h.py:19] end load_into_gpu_async cost 0.0032994747161865234 seconds
DEBUG 01-06 17:11:02.172439.172439 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 17:11:02.173038.173038 cuda_h.py:19] end restore_tensors2 cost 0.00027179718017578125 seconds
DEBUG 01-06 17:11:02.173338.173338 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.00553131103515625 seconds
DEBUG 01-06 17:11:02.175968.175968 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.008179664611816406 seconds
DEBUG 01-06 17:11:02.175367.175367 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-06 17:11:02.175012.175012 lmp.py:461] 
DEBUG 01-06 17:11:02.175012.175012 lmp.py:461]   Computing 32 experts on CPU...
DEBUG 01-06 17:11:02.175001.175001 cuda_h.py:19] end cpu_experts_submit cost 0.00010848045349121094 seconds
DEBUG 01-06 17:11:02.175889.175889 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-06 17:11:02.181745.181745 mlpmodule.py:706] group tensors cost 0.005757570266723633 s
DEBUG 01-06 17:11:02.184529.184529 mlpmodule.py:744] pad cost 0.0016219615936279297 s
DEBUG 01-06 17:11:02.184440.184440 mlpmodule.py:750] create cpu tensor cost 4.315376281738281e-05 s
DEBUG 01-06 17:11:02.184866.184866 mlpmodule.py:755] move to cpu cost 3.2901763916015625e-05 s
DEBUG 01-06 17:11:02.193822.193822 mlpmodule.py:769] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-06 17:11:02.193639.193639 mlpmodule.py:770] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-06 17:11:02.193933.193933 mlpmodule.py:775] group_w3 first element: 0.0024871826171875
WARNING 01-06 17:11:02.193877.193877 mlpmodule.py:785] start einsum2
DEBUG 01-06 17:11:02.211365.211365 mlpmodule.py:795] group einsum cost 0.02690410614013672 s
DEBUG 01-06 17:11:02.212312.212312 mlpmodule.py:803] cpy2cputensor cost 0.0007207393646240234 s
DEBUG 01-06 17:11:02.216121.216121 cuda_h.py:19] end wait_cetm_experts cost 0.04044008255004883 seconds
DEBUG 01-06 17:11:02.216366.216366 cuda_h.py:10] start gpu_sexperts
DEBUG 01-06 17:11:02.217163.217163 cuda_h.py:19] end gpu_sexperts cost 0.0006041526794433594 seconds
DEBUG 01-06 17:11:02.217251.217251 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-06 17:11:02.217147.217147 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.4080276489257812e-05 seconds
DEBUG 01-06 17:11:02.217327.217327 cuda_h.py:10] start wait_experts
INFO 01-06 17:11:02.217036.217036 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, ba47b172-fbde-4eff-85ee-58b425f87a2c
DEBUG 01-06 17:11:02.223556.223556 mlpmodule.py:664]  experts func einsum cost 0.04743194580078125 s
INFO 01-06 17:11:02.225819.225819 client.py:127] Model loaded
DEBUG 01-06 17:11:02.225677.225677 cuda_h.py:19] end wait_experts cost 0.007841348648071289 seconds
DEBUG 01-06 17:11:02.225009.225009 cuda_h.py:10] start gpu_experts
DEBUG 01-06 17:11:02.225487.225487 lmp.py:506]   Computing 32 experts on GPU...
DEBUG 01-06 17:11:02.226590.226590 mlpmodule.py:533] gpu group tensors cost 0.000614166259765625 s
DEBUG 01-06 17:11:02.227094.227094 mlpmodule.py:566] gpu pad cost 0.0015416145324707031 s
DEBUG 01-06 17:11:02.228760.228760 mlpmodule.py:584] gpu group einsum cost 0.0006153583526611328 s
DEBUG 01-06 17:11:02.231795.231795 mlpmodule.py:613] gpu experts func einsum cost 0.0057528018951416016 s
DEBUG 01-06 17:11:02.231387.231387 cuda_h.py:19] end gpu_experts cost 0.005934476852416992 seconds
DEBUG 01-06 17:11:02.231695.231695 cuda_h.py:19] end layer_moe_generate_18 cost 0.06618809700012207 seconds
DEBUG 01-06 17:11:02.231382.231382 lmp.py:220] -------------------------------- end layer 18 --------------------------------
DEBUG 01-06 17:11:02.231715.231715 lmp.py:176] -------------------------------- start layer 19 --------------------------------
DEBUG 01-06 17:11:02.231311.231311 cuda_h.py:10] start start_load_qkvogn_s_weight_l_20
DEBUG 01-06 17:11:02.231829.231829 cuda_h.py:10] start start_load_qkvogn_s_weight_l_20
DEBUG 01-06 17:11:02.231408.231408 cuda_h.py:19] end start_load_qkvogn_s_weight_l_20 cost 3.337860107421875e-05 seconds
DEBUG 01-06 17:11:02.231634.231634 cuda_h.py:19] end start_load_qkvogn_s_weight_l_20 cost 6.4849853515625e-05 seconds
DEBUG 01-06 17:11:02.231230.231230 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-06 17:11:02.231961.231961 cuda_h.py:10] start sllm_worker_task
DEBUG 01-06 17:11:02.231840.231840 mlpmodule.py:367] cuda:1 cuda:1
DEBUG 01-06 17:11:02.232324.232324 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 17:11:02.232096.232096 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 17:11:02.232638.232638 cuda_h.py:19] end allocate_cuda_memory cost 0.0003249645233154297 seconds
DEBUG 01-06 17:11:02.232939.232939 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 17:11:02.232510.232510 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 17:11:02.232386.232386 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 17:11:02.232181.232181 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 8d9c3e97-aeed-43fc-9805-ac75221e4727
DEBUG 01-06 17:11:02.232343.232343 client.py:106] call stub.LoadModelAsync
DEBUG 01-06 17:11:02.233895.233895 cuda_h.py:10] start self_attn
INFO 01-06 17:11:02.234533.234533 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 8d9c3e97-aeed-43fc-9805-ac75221e4727
DEBUG 01-06 17:11:02.234608.234608 cuda_h.py:19] end load_into_gpu_async cost 0.0015463829040527344 seconds
DEBUG 01-06 17:11:02.234165.234165 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 17:11:02.234493.234493 cuda_h.py:19] end restore_tensors2 cost 7.43865966796875e-05 seconds
DEBUG 01-06 17:11:02.234772.234772 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0022051334381103516 seconds
INFO 01-06 17:11:02.234794.234794 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 8d9c3e97-aeed-43fc-9805-ac75221e4727
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-06 17:11:02.235363.235363 cuda_h.py:19] end self_attn cost 0.0028417110443115234 seconds
DEBUG 01-06 17:11:02.236095.236095 cuda_h.py:19] end iln_self_attn_paln cost 0.004435539245605469 seconds
DEBUG 01-06 17:11:02.236792.236792 cuda_h.py:10] start layer_moe_generate_19
DEBUG 01-06 17:11:02.236747.236747 cuda_h.py:10] start gate
DEBUG 01-06 17:11:02.237538.237538 cuda_h.py:19] end gate cost 0.0006549358367919922 seconds
DEBUG 01-06 17:11:02.237222.237222 cuda_h.py:10] start experts_map_get
DEBUG 01-06 17:11:02.237570.237570 lmp.py:403] 
DEBUG 01-06 17:11:02.237570.237570 lmp.py:403] Expert Token Distribution & Device Allocation:
DEBUG 01-06 17:11:02.237372.237372 lmp.py:404]   Total experts: 64
DEBUG 01-06 17:11:02.237545.237545 lmp.py:405]   CPU experts: 32 (50%)
DEBUG 01-06 17:11:02.237095.237095 lmp.py:406]   GPU experts: 32 (50%)
DEBUG 01-06 17:11:02.237977.237977 lmp.py:407] 
DEBUG 01-06 17:11:02.237977.237977 lmp.py:407]   Expert ID | Tokens | Device
DEBUG 01-06 17:11:02.237381.237381 lmp.py:408]   -----------------------------------
DEBUG 01-06 17:11:02.237746.237746 lmp.py:414]   Expert 44 |     42 | CPU
DEBUG 01-06 17:11:02.237389.237389 lmp.py:414]   Expert  1 |     50 | CPU
DEBUG 01-06 17:11:02.237602.237602 lmp.py:414]   Expert 28 |     55 | CPU
DEBUG 01-06 17:11:02.237814.237814 lmp.py:414]   Expert 60 |     64 | CPU
DEBUG 01-06 17:11:02.237788.237788 lmp.py:414]   Expert 48 |     75 | CPU
DEBUG 01-06 17:11:02.237524.237524 lmp.py:414]   Expert 27 |     90 | CPU
DEBUG 01-06 17:11:02.237498.237498 lmp.py:414]   Expert 42 |    104 | CPU
DEBUG 01-06 17:11:02.237233.237233 lmp.py:414]   Expert  0 |    106 | CPU
DEBUG 01-06 17:11:02.237161.237161 lmp.py:414]   Expert 30 |    109 | CPU
DEBUG 01-06 17:11:02.237612.237612 lmp.py:414]   Expert 59 |    114 | CPU
DEBUG 01-06 17:11:02.237063.237063 lmp.py:414]   Expert 58 |    116 | CPU
DEBUG 01-06 17:11:02.237514.237514 lmp.py:414]   Expert 22 |    117 | CPU
DEBUG 01-06 17:11:02.237932.237932 lmp.py:414]   Expert 62 |    117 | CPU
DEBUG 01-06 17:11:02.237336.237336 lmp.py:414]   Expert 16 |    126 | CPU
DEBUG 01-06 17:11:02.237026.237026 lmp.py:414]   Expert  8 |    130 | CPU
DEBUG 01-06 17:11:02.237192.237192 lmp.py:414]   Expert 12 |    137 | CPU
DEBUG 01-06 17:11:02.237120.237120 lmp.py:414]   Expert 57 |    140 | CPU
DEBUG 01-06 17:11:02.237047.237047 lmp.py:414]   Expert 50 |    142 | CPU
DEBUG 01-06 17:11:02.237737.237737 lmp.py:414]   Expert  5 |    143 | CPU
DEBUG 01-06 17:11:02.237188.237188 lmp.py:414]   Expert 56 |    145 | CPU
DEBUG 01-06 17:11:02.237546.237546 lmp.py:414]   Expert 26 |    150 | CPU
DEBUG 01-06 17:11:02.237950.237950 lmp.py:414]   Expert 55 |    152 | CPU
DEBUG 01-06 17:11:02.237355.237355 lmp.py:414]   Expert 15 |    154 | CPU
DEBUG 01-06 17:11:02.237521.237521 lmp.py:414]   Expert 32 |    157 | CPU
DEBUG 01-06 17:11:02.237926.237926 lmp.py:414]   Expert 47 |    162 | CPU
DEBUG 01-06 17:11:02.237092.237092 lmp.py:414]   Expert 41 |    164 | CPU
DEBUG 01-06 17:11:02.237543.237543 lmp.py:414]   Expert 34 |    167 | CPU
DEBUG 01-06 17:11:02.237232.237232 lmp.py:414]   Expert  6 |    169 | CPU
DEBUG 01-06 17:11:02.237683.237683 lmp.py:414]   Expert 13 |    169 | CPU
DEBUG 01-06 17:11:02.237372.237372 lmp.py:414]   Expert 52 |    169 | CPU
DEBUG 01-06 17:11:02.238346.238346 lmp.py:414]   Expert  2 |    170 | CPU
DEBUG 01-06 17:11:02.238035.238035 lmp.py:414]   Expert 24 |    170 | CPU
DEBUG 01-06 17:11:02.238678.238678 lmp.py:414]   Expert  3 |    171 | GPU
DEBUG 01-06 17:11:02.238083.238083 lmp.py:414]   Expert 40 |    171 | GPU
DEBUG 01-06 17:11:02.238249.238249 lmp.py:414]   Expert 54 |    173 | GPU
DEBUG 01-06 17:11:02.238654.238654 lmp.py:414]   Expert 18 |    175 | GPU
DEBUG 01-06 17:11:02.238535.238535 lmp.py:414]   Expert 20 |    180 | GPU
DEBUG 01-06 17:11:02.238463.238463 lmp.py:414]   Expert 46 |    182 | GPU
DEBUG 01-06 17:11:02.238629.238629 lmp.py:414]   Expert 37 |    187 | GPU
DEBUG 01-06 17:11:02.238318.238318 lmp.py:414]   Expert 19 |    191 | GPU
DEBUG 01-06 17:11:02.238007.238007 lmp.py:414]   Expert 51 |    193 | GPU
DEBUG 01-06 17:11:02.238935.238935 lmp.py:414]   Expert 25 |    196 | GPU
DEBUG 01-06 17:11:02.238624.238624 lmp.py:414]   Expert 35 |    198 | GPU
DEBUG 01-06 17:11:02.238075.238075 lmp.py:414]   Expert 43 |    200 | GPU
DEBUG 01-06 17:11:02.238242.238242 lmp.py:414]   Expert 11 |    202 | GPU
DEBUG 01-06 17:11:02.238169.238169 lmp.py:414]   Expert 31 |    204 | GPU
DEBUG 01-06 17:11:02.238335.238335 lmp.py:414]   Expert 17 |    205 | GPU
DEBUG 01-06 17:11:02.238501.238501 lmp.py:414]   Expert 23 |    206 | GPU
DEBUG 01-06 17:11:02.238668.238668 lmp.py:414]   Expert 39 |    212 | GPU
DEBUG 01-06 17:11:02.238357.238357 lmp.py:414]   Expert 49 |    217 | GPU
DEBUG 01-06 17:11:02.238808.238808 lmp.py:414]   Expert 53 |    227 | GPU
DEBUG 01-06 17:11:02.238259.238259 lmp.py:414]   Expert 10 |    234 | GPU
DEBUG 01-06 17:11:02.238948.238948 lmp.py:414]   Expert 33 |    244 | GPU
DEBUG 01-06 17:11:02.238637.238637 lmp.py:414]   Expert 38 |    269 | GPU
DEBUG 01-06 17:11:02.238850.238850 lmp.py:414]   Expert 36 |    270 | GPU
DEBUG 01-06 17:11:02.238777.238777 lmp.py:414]   Expert  4 |    304 | GPU
DEBUG 01-06 17:11:02.238228.238228 lmp.py:414]   Expert 21 |    329 | GPU
DEBUG 01-06 17:11:02.238918.238918 lmp.py:414]   Expert 14 |    344 | GPU
DEBUG 01-06 17:11:02.238130.238130 lmp.py:414]   Expert 45 |    363 | GPU
DEBUG 01-06 17:11:02.238012.238012 lmp.py:414]   Expert 63 |    363 | GPU
DEBUG 01-06 17:11:02.238416.238416 lmp.py:414]   Expert 61 |    386 | GPU
DEBUG 01-06 17:11:02.238821.238821 lmp.py:414]   Expert  9 |    397 | GPU
DEBUG 01-06 17:11:02.238702.238702 lmp.py:414]   Expert 29 |    496 | GPU
DEBUG 01-06 17:11:02.238391.238391 lmp.py:414]   Expert  7 |    524 | GPU
DEBUG 01-06 17:11:02.238273.238273 lmp.py:415] 
DEBUG 01-06 17:11:02.238273.238273 lmp.py:415]   CPU total tokens: 4075 (33.2%)
DEBUG 01-06 17:11:02.238916.238916 lmp.py:416]   GPU total tokens: 8213 (66.8%)
DEBUG 01-06 17:11:02.238089.238089 cuda_h.py:19] end experts_map_get cost 0.0015239715576171875 seconds
DEBUG 01-06 17:11:02.238970.238970 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-06 17:11:02.238700.238700 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 17:11:02.238214.238214 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 17:11:02.240288.240288 cuda_h.py:19] end allocate_cuda_memory cost 0.0015642642974853516 seconds
DEBUG 01-06 17:11:02.240038.240038 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 17:11:02.240510.240510 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 17:11:02.240034.240034 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 17:11:02.240876.240876 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 48c87a7f-3fa7-49c7-9066-cf2c120c9a05
DEBUG 01-06 17:11:02.240868.240868 client.py:106] call stub.LoadModelAsync
INFO 01-06 17:11:02.242563.242563 client.py:127] Model loaded
DEBUG 01-06 17:11:02.242798.242798 cuda_h.py:19] end sllm_worker_task cost 0.010571002960205078 seconds
INFO 01-06 17:11:02.243680.243680 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 48c87a7f-3fa7-49c7-9066-cf2c120c9a05
DEBUG 01-06 17:11:02.243238.243238 cuda_h.py:19] end load_into_gpu_async cost 0.003168821334838867 seconds
DEBUG 01-06 17:11:02.243418.243418 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 17:11:02.243289.243289 cuda_h.py:19] end restore_tensors2 cost 0.0002644062042236328 seconds
DEBUG 01-06 17:11:02.244012.244012 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.005334138870239258 seconds
DEBUG 01-06 17:11:02.246198.246198 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.007970809936523438 seconds
DEBUG 01-06 17:11:02.246935.246935 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-06 17:11:02.246534.246534 lmp.py:461] 
DEBUG 01-06 17:11:02.246534.246534 lmp.py:461]   Computing 32 experts on CPU...
DEBUG 01-06 17:11:02.246761.246761 cuda_h.py:19] end cpu_experts_submit cost 0.00010991096496582031 seconds
DEBUG 01-06 17:11:02.246411.246411 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-06 17:11:02.254812.254812 mlpmodule.py:706] group tensors cost 0.007427215576171875 s
DEBUG 01-06 17:11:02.257926.257926 mlpmodule.py:744] pad cost 0.001931905746459961 s
DEBUG 01-06 17:11:02.257612.257612 mlpmodule.py:750] create cpu tensor cost 5.078315734863281e-05 s
DEBUG 01-06 17:11:02.257244.257244 mlpmodule.py:755] move to cpu cost 3.62396240234375e-05 s
DEBUG 01-06 17:11:02.266998.266998 mlpmodule.py:769] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-06 17:11:02.266986.266986 mlpmodule.py:770] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-06 17:11:02.266114.266114 mlpmodule.py:775] group_w3 first element: -0.0034942626953125
WARNING 01-06 17:11:02.266813.266813 mlpmodule.py:785] start einsum2
DEBUG 01-06 17:11:02.283692.283692 mlpmodule.py:795] group einsum cost 0.02597641944885254 s
DEBUG 01-06 17:11:02.284226.284226 mlpmodule.py:803] cpy2cputensor cost 0.0006062984466552734 s
DEBUG 01-06 17:11:02.288878.288878 cuda_h.py:19] end wait_cetm_experts cost 0.04155302047729492 seconds
DEBUG 01-06 17:11:02.288467.288467 cuda_h.py:10] start gpu_sexperts
DEBUG 01-06 17:11:02.289912.289912 cuda_h.py:19] end gpu_sexperts cost 0.0005967617034912109 seconds
DEBUG 01-06 17:11:02.289478.289478 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-06 17:11:02.289327.289327 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.384185791015625e-05 seconds
DEBUG 01-06 17:11:02.289222.289222 cuda_h.py:10] start wait_experts
INFO 01-06 17:11:02.289171.289171 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 48c87a7f-3fa7-49c7-9066-cf2c120c9a05
DEBUG 01-06 17:11:02.295953.295953 mlpmodule.py:664]  experts func einsum cost 0.048644065856933594 s
INFO 01-06 17:11:02.296767.296767 client.py:127] Model loaded
DEBUG 01-06 17:11:02.296816.296816 cuda_h.py:19] end wait_experts cost 0.006827592849731445 seconds
DEBUG 01-06 17:11:02.296507.296507 cuda_h.py:10] start gpu_experts
DEBUG 01-06 17:11:02.296932.296932 lmp.py:506]   Computing 32 experts on GPU...
DEBUG 01-06 17:11:02.297598.297598 mlpmodule.py:533] gpu group tensors cost 0.0006117820739746094 s
DEBUG 01-06 17:11:02.298384.298384 mlpmodule.py:566] gpu pad cost 0.0016796588897705078 s
DEBUG 01-06 17:11:02.299768.299768 mlpmodule.py:584] gpu group einsum cost 0.0004982948303222656 s
DEBUG 01-06 17:11:02.302495.302495 mlpmodule.py:613] gpu experts func einsum cost 0.005838871002197266 s
DEBUG 01-06 17:11:02.302848.302848 cuda_h.py:19] end gpu_experts cost 0.006015777587890625 seconds
DEBUG 01-06 17:11:02.302672.302672 cuda_h.py:19] end layer_moe_generate_19 cost 0.0662083625793457 seconds
DEBUG 01-06 17:11:02.302473.302473 lmp.py:220] -------------------------------- end layer 19 --------------------------------
DEBUG 01-06 17:11:02.302467.302467 lmp.py:176] -------------------------------- start layer 20 --------------------------------
DEBUG 01-06 17:11:02.302779.302779 cuda_h.py:10] start start_load_qkvogn_s_weight_l_21
DEBUG 01-06 17:11:02.302674.302674 cuda_h.py:10] start start_load_qkvogn_s_weight_l_21
DEBUG 01-06 17:11:02.302438.302438 cuda_h.py:19] end start_load_qkvogn_s_weight_l_21 cost 4.649162292480469e-05 seconds
DEBUG 01-06 17:11:02.302472.302472 cuda_h.py:19] end start_load_qkvogn_s_weight_l_21 cost 7.653236389160156e-05 seconds
DEBUG 01-06 17:11:02.302069.302069 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-06 17:11:02.302779.302779 mlpmodule.py:367] cuda:1 cuda:1
DEBUG 01-06 17:11:02.303240.303240 cuda_h.py:10] start sllm_worker_task
DEBUG 01-06 17:11:02.303177.303177 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 17:11:02.303105.303105 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 17:11:02.303342.303342 cuda_h.py:19] end allocate_cuda_memory cost 0.0003151893615722656 seconds
DEBUG 01-06 17:11:02.303650.303650 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 17:11:02.303843.303843 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 17:11:02.303235.303235 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 17:11:02.303508.303508 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, a12d53a1-a67d-4fa8-b2d8-b14f4dc8a3ee
DEBUG 01-06 17:11:02.303239.303239 client.py:106] call stub.LoadModelAsync
DEBUG 01-06 17:11:02.304652.304652 cuda_h.py:10] start self_attn
INFO 01-06 17:11:02.305637.305637 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, a12d53a1-a67d-4fa8-b2d8-b14f4dc8a3ee
DEBUG 01-06 17:11:02.305381.305381 cuda_h.py:19] end load_into_gpu_async cost 0.0016255378723144531 seconds
DEBUG 01-06 17:11:02.305700.305700 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 17:11:02.305782.305782 cuda_h.py:19] end restore_tensors2 cost 7.033348083496094e-05 seconds
DEBUG 01-06 17:11:02.305585.305585 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0022687911987304688 seconds
INFO 01-06 17:11:02.305891.305891 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, a12d53a1-a67d-4fa8-b2d8-b14f4dc8a3ee
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-06 17:11:02.307637.307637 cuda_h.py:19] end self_attn cost 0.0028429031372070312 seconds
DEBUG 01-06 17:11:02.307176.307176 cuda_h.py:19] end iln_self_attn_paln cost 0.004369020462036133 seconds
DEBUG 01-06 17:11:02.307681.307681 cuda_h.py:10] start layer_moe_generate_20
DEBUG 01-06 17:11:02.307266.307266 cuda_h.py:10] start gate
DEBUG 01-06 17:11:02.308560.308560 cuda_h.py:19] end gate cost 0.0006384849548339844 seconds
DEBUG 01-06 17:11:02.308436.308436 cuda_h.py:10] start experts_map_get
DEBUG 01-06 17:11:02.308227.308227 lmp.py:403] 
DEBUG 01-06 17:11:02.308227.308227 lmp.py:403] Expert Token Distribution & Device Allocation:
DEBUG 01-06 17:11:02.308698.308698 lmp.py:404]   Total experts: 64
DEBUG 01-06 17:11:02.308348.308348 lmp.py:405]   CPU experts: 32 (50%)
DEBUG 01-06 17:11:02.308660.308660 lmp.py:406]   GPU experts: 32 (50%)
DEBUG 01-06 17:11:02.308065.308065 lmp.py:407] 
DEBUG 01-06 17:11:02.308065.308065 lmp.py:407]   Expert ID | Tokens | Device
DEBUG 01-06 17:11:02.308754.308754 lmp.py:408]   -----------------------------------
DEBUG 01-06 17:11:02.308404.308404 lmp.py:414]   Expert 54 |     24 | CPU
DEBUG 01-06 17:11:02.308570.308570 lmp.py:414]   Expert  3 |     31 | CPU
DEBUG 01-06 17:11:02.308259.308259 lmp.py:414]   Expert  8 |     39 | CPU
DEBUG 01-06 17:11:02.308233.308233 lmp.py:414]   Expert 28 |     44 | CPU
DEBUG 01-06 17:11:02.308684.308684 lmp.py:414]   Expert 43 |     50 | CPU
DEBUG 01-06 17:11:02.308658.308658 lmp.py:414]   Expert 63 |     50 | CPU
DEBUG 01-06 17:11:02.308632.308632 lmp.py:414]   Expert 36 |     66 | CPU
DEBUG 01-06 17:11:02.308606.308606 lmp.py:414]   Expert  6 |     77 | CPU
DEBUG 01-06 17:11:02.308534.308534 lmp.py:414]   Expert 38 |     77 | CPU
DEBUG 01-06 17:11:02.308985.308985 lmp.py:414]   Expert 39 |     91 | CPU
DEBUG 01-06 17:11:02.308151.308151 lmp.py:414]   Expert 41 |    105 | CPU
DEBUG 01-06 17:11:02.308317.308317 lmp.py:414]   Expert 52 |    105 | CPU
DEBUG 01-06 17:11:02.308006.308006 lmp.py:414]   Expert 57 |    106 | CPU
DEBUG 01-06 17:11:02.308219.308219 lmp.py:414]   Expert 12 |    117 | CPU
DEBUG 01-06 17:11:02.308193.308193 lmp.py:414]   Expert 19 |    124 | CPU
DEBUG 01-06 17:11:02.308928.308928 lmp.py:414]   Expert 47 |    129 | CPU
DEBUG 01-06 17:11:02.308571.308571 lmp.py:414]   Expert 13 |    133 | CPU
DEBUG 01-06 17:11:02.308499.308499 lmp.py:414]   Expert 22 |    137 | CPU
DEBUG 01-06 17:11:02.308188.308188 lmp.py:414]   Expert 50 |    150 | CPU
DEBUG 01-06 17:11:02.308401.308401 lmp.py:414]   Expert 46 |    151 | CPU
DEBUG 01-06 17:11:02.308090.308090 lmp.py:414]   Expert 55 |    163 | CPU
DEBUG 01-06 17:11:02.308256.308256 lmp.py:414]   Expert 40 |    164 | CPU
DEBUG 01-06 17:11:02.308138.308138 lmp.py:414]   Expert  2 |    167 | CPU
DEBUG 01-06 17:11:02.308781.308781 lmp.py:414]   Expert 20 |    167 | CPU
DEBUG 01-06 17:11:02.308185.308185 lmp.py:414]   Expert 24 |    167 | CPU
DEBUG 01-06 17:11:02.308305.308305 lmp.py:414]   Expert 37 |    170 | CPU
DEBUG 01-06 17:11:02.308994.308994 lmp.py:414]   Expert 33 |    175 | CPU
DEBUG 01-06 17:11:02.309161.309161 lmp.py:414]   Expert 53 |    175 | CPU
DEBUG 01-06 17:11:02.309088.309088 lmp.py:414]   Expert 21 |    176 | CPU
DEBUG 01-06 17:11:02.309254.309254 lmp.py:414]   Expert 23 |    180 | CPU
DEBUG 01-06 17:11:02.309944.309944 lmp.py:414]   Expert 49 |    180 | CPU
DEBUG 01-06 17:11:02.309633.309633 lmp.py:414]   Expert 42 |    182 | CPU
DEBUG 01-06 17:11:02.309799.309799 lmp.py:414]   Expert 61 |    184 | GPU
DEBUG 01-06 17:11:02.309012.309012 lmp.py:414]   Expert 18 |    190 | GPU
DEBUG 01-06 17:11:02.309939.309939 lmp.py:414]   Expert  0 |    201 | GPU
DEBUG 01-06 17:11:02.309629.309629 lmp.py:414]   Expert 32 |    201 | GPU
DEBUG 01-06 17:11:02.309795.309795 lmp.py:414]   Expert 16 |    202 | GPU
DEBUG 01-06 17:11:02.309961.309961 lmp.py:414]   Expert 30 |    204 | GPU
DEBUG 01-06 17:11:02.309127.309127 lmp.py:414]   Expert  5 |    206 | GPU
DEBUG 01-06 17:11:02.309293.309293 lmp.py:414]   Expert  7 |    208 | GPU
DEBUG 01-06 17:11:02.309459.309459 lmp.py:414]   Expert 60 |    211 | GPU
DEBUG 01-06 17:11:02.309672.309672 lmp.py:414]   Expert 14 |    213 | GPU
DEBUG 01-06 17:11:02.309361.309361 lmp.py:414]   Expert 34 |    214 | GPU
DEBUG 01-06 17:11:02.309812.309812 lmp.py:414]   Expert  9 |    216 | GPU
DEBUG 01-06 17:11:02.309263.309263 lmp.py:414]   Expert 31 |    216 | GPU
DEBUG 01-06 17:11:02.309998.309998 lmp.py:414]   Expert 17 |    217 | GPU
DEBUG 01-06 17:11:02.309211.309211 lmp.py:414]   Expert 62 |    220 | GPU
DEBUG 01-06 17:11:02.309662.309662 lmp.py:414]   Expert 59 |    221 | GPU
DEBUG 01-06 17:11:02.309636.309636 lmp.py:414]   Expert 10 |    227 | GPU
DEBUG 01-06 17:11:02.309279.309279 lmp.py:414]   Expert 29 |    228 | GPU
DEBUG 01-06 17:11:02.309207.309207 lmp.py:414]   Expert 58 |    235 | GPU
DEBUG 01-06 17:11:02.309373.309373 lmp.py:414]   Expert 15 |    237 | GPU
DEBUG 01-06 17:11:02.309539.309539 lmp.py:414]   Expert 26 |    240 | GPU
DEBUG 01-06 17:11:02.309467.309467 lmp.py:414]   Expert  4 |    243 | GPU
DEBUG 01-06 17:11:02.309917.309917 lmp.py:414]   Expert 51 |    252 | GPU
DEBUG 01-06 17:11:02.309130.309130 lmp.py:414]   Expert 11 |    256 | GPU
DEBUG 01-06 17:11:02.309819.309819 lmp.py:414]   Expert 44 |    270 | GPU
DEBUG 01-06 17:11:02.309270.309270 lmp.py:414]   Expert 56 |    283 | GPU
DEBUG 01-06 17:11:02.309483.309483 lmp.py:414]   Expert 27 |    287 | GPU
DEBUG 01-06 17:11:02.309695.309695 lmp.py:414]   Expert  1 |    336 | GPU
DEBUG 01-06 17:11:02.309146.309146 lmp.py:414]   Expert 45 |    361 | GPU
DEBUG 01-06 17:11:02.309888.309888 lmp.py:414]   Expert 25 |    471 | GPU
DEBUG 01-06 17:11:02.309578.309578 lmp.py:414]   Expert 35 |    528 | GPU
DEBUG 01-06 17:11:02.309552.309552 lmp.py:414]   Expert 48 |    638 | GPU
DEBUG 01-06 17:11:02.309956.309956 lmp.py:415] 
DEBUG 01-06 17:11:02.309956.309956 lmp.py:415]   CPU total tokens: 3872 (31.5%)
DEBUG 01-06 17:11:02.309314.309314 lmp.py:416]   GPU total tokens: 8416 (68.5%)
DEBUG 01-06 17:11:02.309772.309772 cuda_h.py:19] end experts_map_get cost 0.0015192031860351562 seconds
DEBUG 01-06 17:11:02.309700.309700 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-06 17:11:02.309715.309715 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 17:11:02.309183.309183 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 17:11:02.311175.311175 cuda_h.py:19] end allocate_cuda_memory cost 0.0017173290252685547 seconds
DEBUG 01-06 17:11:02.311370.311370 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 17:11:02.311271.311271 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 17:11:02.311888.311888 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 17:11:02.311777.311777 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 9a677120-3fd8-4d92-8a10-a16c27501e1c
DEBUG 01-06 17:11:02.311862.311862 client.py:106] call stub.LoadModelAsync
INFO 01-06 17:11:02.313441.313441 client.py:127] Model loaded
DEBUG 01-06 17:11:02.314170.314170 cuda_h.py:19] end sllm_worker_task cost 0.011092662811279297 seconds
INFO 01-06 17:11:02.314595.314595 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 9a677120-3fd8-4d92-8a10-a16c27501e1c
DEBUG 01-06 17:11:02.314776.314776 cuda_h.py:19] end load_into_gpu_async cost 0.003214597702026367 seconds
DEBUG 01-06 17:11:02.314433.314433 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 17:11:02.315463.315463 cuda_h.py:19] end restore_tensors2 cost 0.0002770423889160156 seconds
DEBUG 01-06 17:11:02.315901.315901 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.005558967590332031 seconds
DEBUG 01-06 17:11:02.317241.317241 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.008238792419433594 seconds
DEBUG 01-06 17:11:02.317455.317455 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-06 17:11:02.318577.318577 lmp.py:461] 
DEBUG 01-06 17:11:02.318577.318577 lmp.py:461]   Computing 32 experts on CPU...
DEBUG 01-06 17:11:02.318328.318328 cuda_h.py:19] end cpu_experts_submit cost 0.0001087188720703125 seconds
DEBUG 01-06 17:11:02.318693.318693 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-06 17:11:02.335471.335471 mlpmodule.py:706] group tensors cost 0.01682138442993164 s
DEBUG 01-06 17:11:02.337297.337297 mlpmodule.py:744] pad cost 0.0016086101531982422 s
DEBUG 01-06 17:11:02.337447.337447 mlpmodule.py:750] create cpu tensor cost 4.696846008300781e-05 s
DEBUG 01-06 17:11:02.337111.337111 mlpmodule.py:755] move to cpu cost 3.337860107421875e-05 s
DEBUG 01-06 17:11:02.350774.350774 mlpmodule.py:769] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-06 17:11:02.350062.350062 mlpmodule.py:770] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-06 17:11:02.350534.350534 mlpmodule.py:775] group_w3 first element: 0.039306640625
WARNING 01-06 17:11:02.350299.350299 mlpmodule.py:785] start einsum2
DEBUG 01-06 17:11:02.367247.367247 mlpmodule.py:795] group einsum cost 0.03011298179626465 s
DEBUG 01-06 17:11:02.368566.368566 mlpmodule.py:803] cpy2cputensor cost 0.0007603168487548828 s
DEBUG 01-06 17:11:02.373755.373755 cuda_h.py:19] end wait_cetm_experts cost 0.05477285385131836 seconds
DEBUG 01-06 17:11:02.373383.373383 cuda_h.py:10] start gpu_sexperts
DEBUG 01-06 17:11:02.373405.373405 cuda_h.py:19] end gpu_sexperts cost 0.0006017684936523438 seconds
DEBUG 01-06 17:11:02.373348.373348 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-06 17:11:02.373528.373528 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.3365020751953125e-05 seconds
DEBUG 01-06 17:11:02.374662.374662 cuda_h.py:10] start wait_experts
INFO 01-06 17:11:02.374610.374610 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 9a677120-3fd8-4d92-8a10-a16c27501e1c
INFO 01-06 17:11:02.375256.375256 client.py:127] Model loaded
DEBUG 01-06 17:11:02.375390.375390 cuda_h.py:19] end wait_experts cost 0.0013484954833984375 seconds
DEBUG 01-06 17:11:02.375100.375100 cuda_h.py:10] start gpu_experts
DEBUG 01-06 17:11:02.375809.375809 lmp.py:506]   Computing 32 experts on GPU...
DEBUG 01-06 17:11:02.376853.376853 mlpmodule.py:533] gpu group tensors cost 0.0006105899810791016 s
DEBUG 01-06 17:11:02.378756.378756 mlpmodule.py:566] gpu pad cost 0.001804351806640625 s
DEBUG 01-06 17:11:02.378823.378823 mlpmodule.py:584] gpu group einsum cost 0.0005338191986083984 s
DEBUG 01-06 17:11:02.381310.381310 mlpmodule.py:664]  experts func einsum cost 0.06288623809814453 s
DEBUG 01-06 17:11:02.382216.382216 mlpmodule.py:613] gpu experts func einsum cost 0.006901741027832031 s
DEBUG 01-06 17:11:02.382758.382758 cuda_h.py:19] end gpu_experts cost 0.007160186767578125 seconds
DEBUG 01-06 17:11:02.382357.382357 cuda_h.py:19] end layer_moe_generate_20 cost 0.07532572746276855 seconds
DEBUG 01-06 17:11:02.382105.382105 lmp.py:220] -------------------------------- end layer 20 --------------------------------
DEBUG 01-06 17:11:02.382822.382822 lmp.py:176] -------------------------------- start layer 21 --------------------------------
DEBUG 01-06 17:11:02.382809.382809 cuda_h.py:10] start start_load_qkvogn_s_weight_l_22
DEBUG 01-06 17:11:02.383572.383572 cuda_h.py:10] start start_load_qkvogn_s_weight_l_22
DEBUG 01-06 17:11:02.383098.383098 cuda_h.py:19] end start_load_qkvogn_s_weight_l_22 cost 4.076957702636719e-05 seconds
DEBUG 01-06 17:11:02.383046.383046 cuda_h.py:19] end start_load_qkvogn_s_weight_l_22 cost 7.557868957519531e-05 seconds
DEBUG 01-06 17:11:02.383126.383126 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-06 17:11:02.383374.383374 mlpmodule.py:367] cuda:1 cuda:1
DEBUG 01-06 17:11:02.383012.383012 cuda_h.py:10] start sllm_worker_task
DEBUG 01-06 17:11:02.383996.383996 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 17:11:02.383077.383077 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 17:11:02.383599.383599 cuda_h.py:19] end allocate_cuda_memory cost 0.00030803680419921875 seconds
DEBUG 01-06 17:11:02.383966.383966 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 17:11:02.383597.383597 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 17:11:02.383757.383757 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 17:11:02.384222.384222 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, e2242b0c-10da-483c-afb0-2703ac02ef1c
DEBUG 01-06 17:11:02.384675.384675 client.py:106] call stub.LoadModelAsync
DEBUG 01-06 17:11:02.384645.384645 cuda_h.py:10] start self_attn
INFO 01-06 17:11:02.385269.385269 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, e2242b0c-10da-483c-afb0-2703ac02ef1c
DEBUG 01-06 17:11:02.385980.385980 cuda_h.py:19] end load_into_gpu_async cost 0.0015451908111572266 seconds
DEBUG 01-06 17:11:02.385405.385405 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 17:11:02.385316.385316 cuda_h.py:19] end restore_tensors2 cost 7.605552673339844e-05 seconds
DEBUG 01-06 17:11:02.385046.385046 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0022487640380859375 seconds
INFO 01-06 17:11:02.385173.385173 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, e2242b0c-10da-483c-afb0-2703ac02ef1c
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-06 17:11:02.387308.387308 cuda_h.py:19] end self_attn cost 0.0029227733612060547 seconds
DEBUG 01-06 17:11:02.387180.387180 cuda_h.py:19] end iln_self_attn_paln cost 0.004519224166870117 seconds
DEBUG 01-06 17:11:02.387685.387685 cuda_h.py:10] start layer_moe_generate_21
DEBUG 01-06 17:11:02.387686.387686 cuda_h.py:10] start gate
DEBUG 01-06 17:11:02.388637.388637 cuda_h.py:19] end gate cost 0.000667572021484375 seconds
DEBUG 01-06 17:11:02.388989.388989 cuda_h.py:10] start experts_map_get
DEBUG 01-06 17:11:02.388913.388913 lmp.py:403] 
DEBUG 01-06 17:11:02.388913.388913 lmp.py:403] Expert Token Distribution & Device Allocation:
DEBUG 01-06 17:11:02.388477.388477 lmp.py:404]   Total experts: 64
DEBUG 01-06 17:11:02.388604.388604 lmp.py:405]   CPU experts: 32 (50%)
DEBUG 01-06 17:11:02.388916.388916 lmp.py:406]   GPU experts: 32 (50%)
DEBUG 01-06 17:11:02.388320.388320 lmp.py:407] 
DEBUG 01-06 17:11:02.388320.388320 lmp.py:407]   Expert ID | Tokens | Device
DEBUG 01-06 17:11:02.388725.388725 lmp.py:408]   -----------------------------------
DEBUG 01-06 17:11:02.388851.388851 lmp.py:414]   Expert 44 |     24 | CPU
DEBUG 01-06 17:11:02.388733.388733 lmp.py:414]   Expert  9 |     31 | CPU
DEBUG 01-06 17:11:02.389899.389899 lmp.py:414]   Expert 11 |     34 | CPU
DEBUG 01-06 17:11:02.389827.389827 lmp.py:414]   Expert 56 |     60 | CPU
DEBUG 01-06 17:11:02.389039.389039 lmp.py:414]   Expert 54 |     80 | CPU
DEBUG 01-06 17:11:02.389113.389113 lmp.py:414]   Expert 47 |     88 | CPU
DEBUG 01-06 17:11:02.389517.389517 lmp.py:414]   Expert  7 |     91 | CPU
DEBUG 01-06 17:11:02.389683.389683 lmp.py:414]   Expert 62 |     95 | CPU
DEBUG 01-06 17:11:02.389326.389326 lmp.py:414]   Expert 60 |     98 | CPU
DEBUG 01-06 17:11:02.389731.389731 lmp.py:414]   Expert 41 |    104 | CPU
DEBUG 01-06 17:11:02.389897.389897 lmp.py:414]   Expert 51 |    105 | CPU
DEBUG 01-06 17:11:02.389540.389540 lmp.py:414]   Expert 52 |    106 | CPU
DEBUG 01-06 17:11:02.389706.389706 lmp.py:414]   Expert 53 |    110 | CPU
DEBUG 01-06 17:11:02.389634.389634 lmp.py:414]   Expert 22 |    116 | CPU
DEBUG 01-06 17:11:02.389323.389323 lmp.py:414]   Expert  8 |    123 | CPU
DEBUG 01-06 17:11:02.389774.389774 lmp.py:414]   Expert 32 |    123 | CPU
DEBUG 01-06 17:11:02.389463.389463 lmp.py:414]   Expert  1 |    127 | CPU
DEBUG 01-06 17:11:02.389153.389153 lmp.py:414]   Expert  6 |    128 | CPU
DEBUG 01-06 17:11:02.389034.389034 lmp.py:414]   Expert  2 |    131 | CPU
DEBUG 01-06 17:11:02.389677.389677 lmp.py:414]   Expert 27 |    134 | CPU
DEBUG 01-06 17:11:02.389605.389605 lmp.py:414]   Expert 48 |    137 | CPU
DEBUG 01-06 17:11:02.389771.389771 lmp.py:414]   Expert 59 |    139 | CPU
DEBUG 01-06 17:11:02.389937.389937 lmp.py:414]   Expert 35 |    140 | CPU
DEBUG 01-06 17:11:02.389388.389388 lmp.py:414]   Expert 23 |    143 | CPU
DEBUG 01-06 17:11:02.389600.389600 lmp.py:414]   Expert 26 |    146 | CPU
DEBUG 01-06 17:11:02.389528.389528 lmp.py:414]   Expert 39 |    146 | CPU
DEBUG 01-06 17:11:02.389979.389979 lmp.py:414]   Expert 50 |    154 | CPU
DEBUG 01-06 17:11:02.389430.389430 lmp.py:414]   Expert 14 |    156 | CPU
DEBUG 01-06 17:11:02.389642.389642 lmp.py:414]   Expert 34 |    166 | CPU
DEBUG 01-06 17:11:02.389093.389093 lmp.py:414]   Expert 38 |    168 | CPU
DEBUG 01-06 17:11:02.389259.389259 lmp.py:414]   Expert 24 |    169 | CPU
DEBUG 01-06 17:11:02.389187.389187 lmp.py:414]   Expert  4 |    171 | CPU
DEBUG 01-06 17:11:02.389592.389592 lmp.py:414]   Expert 46 |    172 | GPU
DEBUG 01-06 17:11:02.389758.389758 lmp.py:414]   Expert 49 |    175 | GPU
DEBUG 01-06 17:11:02.389162.389162 lmp.py:414]   Expert  0 |    176 | GPU
DEBUG 01-06 17:11:02.389090.389090 lmp.py:414]   Expert 40 |    183 | GPU
DEBUG 01-06 17:11:02.389541.389541 lmp.py:414]   Expert  5 |    184 | GPU
DEBUG 01-06 17:11:02.389230.389230 lmp.py:414]   Expert 19 |    191 | GPU
DEBUG 01-06 17:11:02.389681.389681 lmp.py:414]   Expert 63 |    193 | GPU
DEBUG 01-06 17:11:02.389370.389370 lmp.py:414]   Expert 13 |    196 | GPU
DEBUG 01-06 17:11:02.389298.389298 lmp.py:414]   Expert 29 |    206 | GPU
DEBUG 01-06 17:11:02.389510.389510 lmp.py:414]   Expert 43 |    207 | GPU
DEBUG 01-06 17:11:02.389200.389200 lmp.py:414]   Expert 57 |    209 | GPU
DEBUG 01-06 17:11:02.389889.389889 lmp.py:414]   Expert 33 |    219 | GPU
DEBUG 01-06 17:11:02.389532.389532 lmp.py:414]   Expert 61 |    219 | GPU
DEBUG 01-06 17:11:02.389937.389937 lmp.py:414]   Expert 31 |    239 | GPU
DEBUG 01-06 17:11:02.389103.389103 lmp.py:414]   Expert 20 |    249 | GPU
DEBUG 01-06 17:11:02.389269.389269 lmp.py:414]   Expert 16 |    251 | GPU
DEBUG 01-06 17:11:02.389912.389912 lmp.py:414]   Expert  3 |    253 | GPU
DEBUG 01-06 17:11:02.389840.389840 lmp.py:414]   Expert 15 |    257 | GPU
DEBUG 01-06 17:11:02.389290.389290 lmp.py:414]   Expert 37 |    260 | GPU
DEBUG 01-06 17:11:02.389741.389741 lmp.py:414]   Expert 36 |    273 | GPU
DEBUG 01-06 17:11:02.389192.389192 lmp.py:414]   Expert 18 |    274 | GPU
DEBUG 01-06 17:11:02.389882.389882 lmp.py:414]   Expert 12 |    276 | GPU
DEBUG 01-06 17:11:02.389332.389332 lmp.py:414]   Expert 28 |    298 | GPU
DEBUG 01-06 17:11:02.389783.389783 lmp.py:414]   Expert 55 |    305 | GPU
DEBUG 01-06 17:11:02.389473.389473 lmp.py:414]   Expert 25 |    308 | GPU
DEBUG 01-06 17:11:02.389400.389400 lmp.py:414]   Expert 17 |    309 | GPU
DEBUG 01-06 17:11:02.389328.389328 lmp.py:414]   Expert 30 |    325 | GPU
DEBUG 01-06 17:11:02.389494.389494 lmp.py:414]   Expert 58 |    338 | GPU
DEBUG 01-06 17:11:02.389137.389137 lmp.py:414]   Expert 10 |    365 | GPU
DEBUG 01-06 17:11:02.390826.390826 lmp.py:414]   Expert 45 |    380 | GPU
DEBUG 01-06 17:11:02.390039.390039 lmp.py:414]   Expert 21 |    391 | GPU
DEBUG 01-06 17:11:02.390490.390490 lmp.py:414]   Expert 42 |    664 | GPU
DEBUG 01-06 17:11:02.390894.390894 lmp.py:415] 
DEBUG 01-06 17:11:02.390894.390894 lmp.py:415]   CPU total tokens: 3743 (30.5%)
DEBUG 01-06 17:11:02.390299.390299 lmp.py:416]   GPU total tokens: 8545 (69.5%)
DEBUG 01-06 17:11:02.390995.390995 cuda_h.py:19] end experts_map_get cost 0.0015206336975097656 seconds
DEBUG 01-06 17:11:02.390876.390876 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-06 17:11:02.390368.390368 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 17:11:02.390797.390797 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 17:11:02.391772.391772 cuda_h.py:19] end allocate_cuda_memory cost 0.001413583755493164 seconds
DEBUG 01-06 17:11:02.391715.391715 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 17:11:02.391709.391709 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 17:11:02.391380.391380 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 17:11:02.391268.391268 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 07df3fa8-dc06-4951-9afe-4a467b063b1f
DEBUG 01-06 17:11:02.392996.392996 client.py:106] call stub.LoadModelAsync
INFO 01-06 17:11:02.393701.393701 client.py:127] Model loaded
DEBUG 01-06 17:11:02.394508.394508 cuda_h.py:19] end sllm_worker_task cost 0.010951757431030273 seconds
INFO 01-06 17:11:02.395371.395371 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 07df3fa8-dc06-4951-9afe-4a467b063b1f
DEBUG 01-06 17:11:02.395360.395360 cuda_h.py:19] end load_into_gpu_async cost 0.003216981887817383 seconds
DEBUG 01-06 17:11:02.395586.395586 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 17:11:02.395014.395014 cuda_h.py:19] end restore_tensors2 cost 0.0002899169921875 seconds
DEBUG 01-06 17:11:02.395691.395691 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.005270957946777344 seconds
DEBUG 01-06 17:11:02.398318.398318 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.00802302360534668 seconds
DEBUG 01-06 17:11:02.398956.398956 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-06 17:11:02.398985.398985 lmp.py:461] 
DEBUG 01-06 17:11:02.398985.398985 lmp.py:461]   Computing 32 experts on CPU...
DEBUG 01-06 17:11:02.398881.398881 cuda_h.py:19] end cpu_experts_submit cost 0.00011229515075683594 seconds
DEBUG 01-06 17:11:02.398246.398246 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-06 17:11:02.408716.408716 mlpmodule.py:706] group tensors cost 0.010088205337524414 s
DEBUG 01-06 17:11:02.410024.410024 mlpmodule.py:744] pad cost 0.0015840530395507812 s
DEBUG 01-06 17:11:02.411048.411048 mlpmodule.py:750] create cpu tensor cost 6.0558319091796875e-05 s
DEBUG 01-06 17:11:02.411045.411045 mlpmodule.py:755] move to cpu cost 5.793571472167969e-05 s
DEBUG 01-06 17:11:02.427392.427392 mlpmodule.py:769] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-06 17:11:02.427519.427519 mlpmodule.py:770] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-06 17:11:02.427654.427654 mlpmodule.py:775] group_w3 first element: 0.00066375732421875
WARNING 01-06 17:11:02.427171.427171 mlpmodule.py:785] start einsum2
DEBUG 01-06 17:11:02.446240.446240 mlpmodule.py:795] group einsum cost 0.034860849380493164 s
DEBUG 01-06 17:11:02.446437.446437 mlpmodule.py:803] cpy2cputensor cost 0.0006270408630371094 s
DEBUG 01-06 17:11:02.452124.452124 cuda_h.py:19] end wait_cetm_experts cost 0.05442452430725098 seconds
DEBUG 01-06 17:11:02.453073.453073 cuda_h.py:10] start gpu_sexperts
DEBUG 01-06 17:11:02.454479.454479 cuda_h.py:19] end gpu_sexperts cost 0.0008075237274169922 seconds
DEBUG 01-06 17:11:02.454396.454396 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-06 17:11:02.454875.454875 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 3.266334533691406e-05 seconds
DEBUG 01-06 17:11:02.454293.454293 cuda_h.py:10] start wait_experts
INFO 01-06 17:11:02.454294.454294 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 07df3fa8-dc06-4951-9afe-4a467b063b1f
INFO 01-06 17:11:02.455506.455506 client.py:127] Model loaded
DEBUG 01-06 17:11:02.455641.455641 cuda_h.py:19] end wait_experts cost 0.0014541149139404297 seconds
DEBUG 01-06 17:11:02.455490.455490 cuda_h.py:10] start gpu_experts
DEBUG 01-06 17:11:02.455815.455815 lmp.py:506]   Computing 32 experts on GPU...
DEBUG 01-06 17:11:02.456984.456984 mlpmodule.py:533] gpu group tensors cost 0.0007982254028320312 s
DEBUG 01-06 17:11:02.458735.458735 mlpmodule.py:566] gpu pad cost 0.0019996166229248047 s
DEBUG 01-06 17:11:02.459354.459354 mlpmodule.py:584] gpu group einsum cost 0.0005786418914794922 s
DEBUG 01-06 17:11:02.460396.460396 mlpmodule.py:664]  experts func einsum cost 0.06166648864746094 s
DEBUG 01-06 17:11:02.462209.462209 mlpmodule.py:613] gpu experts func einsum cost 0.007100582122802734 s
DEBUG 01-06 17:11:02.463763.463763 cuda_h.py:19] end gpu_experts cost 0.0073354244232177734 seconds
DEBUG 01-06 17:11:02.463230.463230 cuda_h.py:19] end layer_moe_generate_21 cost 0.07537055015563965 seconds
DEBUG 01-06 17:11:02.463050.463050 lmp.py:220] -------------------------------- end layer 21 --------------------------------
DEBUG 01-06 17:11:02.463005.463005 lmp.py:176] -------------------------------- start layer 22 --------------------------------
DEBUG 01-06 17:11:02.463006.463006 cuda_h.py:10] start start_load_qkvogn_s_weight_l_23
DEBUG 01-06 17:11:02.463716.463716 cuda_h.py:10] start start_load_qkvogn_s_weight_l_23
DEBUG 01-06 17:11:02.463566.463566 cuda_h.py:19] end start_load_qkvogn_s_weight_l_23 cost 3.719329833984375e-05 seconds
DEBUG 01-06 17:11:02.463792.463792 cuda_h.py:19] end start_load_qkvogn_s_weight_l_23 cost 6.961822509765625e-05 seconds
DEBUG 01-06 17:11:02.463409.463409 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-06 17:11:02.463895.463895 mlpmodule.py:367] cuda:1 cuda:1
DEBUG 01-06 17:11:02.463560.463560 cuda_h.py:10] start sllm_worker_task
DEBUG 01-06 17:11:02.463697.463697 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 17:11:02.463070.463070 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 17:11:02.464674.464674 cuda_h.py:19] end allocate_cuda_memory cost 0.000408172607421875 seconds
DEBUG 01-06 17:11:02.464115.464115 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 17:11:02.464097.464097 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 17:11:02.464456.464456 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 17:11:02.464113.464113 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, e00e76db-f88c-4d6f-9d45-97f640f558b7
DEBUG 01-06 17:11:02.464950.464950 client.py:106] call stub.LoadModelAsync
DEBUG 01-06 17:11:02.464807.464807 cuda_h.py:10] start self_attn
INFO 01-06 17:11:02.466293.466293 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, e00e76db-f88c-4d6f-9d45-97f640f558b7
DEBUG 01-06 17:11:02.466421.466421 cuda_h.py:19] end load_into_gpu_async cost 0.0015730857849121094 seconds
DEBUG 01-06 17:11:02.466170.466170 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 17:11:02.466028.466028 cuda_h.py:19] end restore_tensors2 cost 7.843971252441406e-05 seconds
DEBUG 01-06 17:11:02.466023.466023 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0023822784423828125 seconds
INFO 01-06 17:11:02.466958.466958 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, e00e76db-f88c-4d6f-9d45-97f640f558b7
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-06 17:11:02.468377.468377 cuda_h.py:19] end self_attn cost 0.003098726272583008 seconds
DEBUG 01-06 17:11:02.468335.468335 cuda_h.py:19] end iln_self_attn_paln cost 0.0048673152923583984 seconds
DEBUG 01-06 17:11:02.468747.468747 cuda_h.py:10] start layer_moe_generate_22
DEBUG 01-06 17:11:02.468940.468940 cuda_h.py:10] start gate
DEBUG 01-06 17:11:02.469098.469098 cuda_h.py:19] end gate cost 0.0007114410400390625 seconds
DEBUG 01-06 17:11:02.469305.469305 cuda_h.py:10] start experts_map_get
DEBUG 01-06 17:11:02.469189.469189 lmp.py:403] 
DEBUG 01-06 17:11:02.469189.469189 lmp.py:403] Expert Token Distribution & Device Allocation:
DEBUG 01-06 17:11:02.469760.469760 lmp.py:404]   Total experts: 64
DEBUG 01-06 17:11:02.469125.469125 lmp.py:405]   CPU experts: 32 (50%)
DEBUG 01-06 17:11:02.469960.469960 lmp.py:406]   GPU experts: 32 (50%)
DEBUG 01-06 17:11:02.469887.469887 lmp.py:407] 
DEBUG 01-06 17:11:02.469887.469887 lmp.py:407]   Expert ID | Tokens | Device
DEBUG 01-06 17:11:02.469530.469530 lmp.py:408]   -----------------------------------
DEBUG 01-06 17:11:02.469895.469895 lmp.py:414]   Expert 25 |     17 | CPU
DEBUG 01-06 17:11:02.469300.469300 lmp.py:414]   Expert 48 |     30 | CPU
DEBUG 01-06 17:11:02.469989.469989 lmp.py:414]   Expert 45 |     34 | CPU
DEBUG 01-06 17:11:02.469202.469202 lmp.py:414]   Expert  9 |     58 | CPU
DEBUG 01-06 17:11:02.469653.469653 lmp.py:414]   Expert  0 |     80 | CPU
DEBUG 01-06 17:11:02.469865.469865 lmp.py:414]   Expert 43 |     80 | CPU
DEBUG 01-06 17:11:02.469601.469601 lmp.py:414]   Expert 20 |     84 | CPU
DEBUG 01-06 17:11:02.469575.469575 lmp.py:414]   Expert 57 |     86 | CPU
DEBUG 01-06 17:11:02.469787.469787 lmp.py:414]   Expert 54 |     87 | CPU
DEBUG 01-06 17:11:02.469000.469000 lmp.py:414]   Expert  6 |     93 | CPU
DEBUG 01-06 17:11:02.469404.469404 lmp.py:414]   Expert 36 |     98 | CPU
DEBUG 01-06 17:11:02.469570.469570 lmp.py:414]   Expert 47 |    102 | CPU
DEBUG 01-06 17:11:02.469260.469260 lmp.py:414]   Expert 13 |    103 | CPU
DEBUG 01-06 17:11:02.470234.470234 lmp.py:414]   Expert 15 |    104 | CPU
DEBUG 01-06 17:11:02.470969.470969 lmp.py:414]   Expert  1 |    105 | CPU
DEBUG 01-06 17:11:02.470705.470705 lmp.py:414]   Expert 61 |    105 | CPU
DEBUG 01-06 17:11:02.470202.470202 lmp.py:414]   Expert 38 |    106 | CPU
DEBUG 01-06 17:11:02.470699.470699 lmp.py:414]   Expert 62 |    108 | CPU
DEBUG 01-06 17:11:02.470958.470958 lmp.py:414]   Expert 46 |    109 | CPU
DEBUG 01-06 17:11:02.470694.470694 lmp.py:414]   Expert 50 |    109 | CPU
DEBUG 01-06 17:11:02.470714.470714 lmp.py:414]   Expert 37 |    115 | CPU
DEBUG 01-06 17:11:02.470450.470450 lmp.py:414]   Expert 14 |    119 | CPU
DEBUG 01-06 17:11:02.470139.470139 lmp.py:414]   Expert 21 |    131 | CPU
DEBUG 01-06 17:11:02.470590.470590 lmp.py:414]   Expert 44 |    138 | CPU
DEBUG 01-06 17:11:02.470279.470279 lmp.py:414]   Expert 28 |    140 | CPU
DEBUG 01-06 17:11:02.470969.470969 lmp.py:414]   Expert  7 |    144 | CPU
DEBUG 01-06 17:11:02.470943.470943 lmp.py:414]   Expert 52 |    144 | CPU
DEBUG 01-06 17:11:02.470678.470678 lmp.py:414]   Expert 10 |    149 | CPU
DEBUG 01-06 17:11:02.470176.470176 lmp.py:414]   Expert 24 |    154 | CPU
DEBUG 01-06 17:11:02.470911.470911 lmp.py:414]   Expert 11 |    159 | CPU
DEBUG 01-06 17:11:02.470170.470170 lmp.py:414]   Expert 42 |    160 | CPU
DEBUG 01-06 17:11:02.470906.470906 lmp.py:414]   Expert  2 |    165 | CPU
DEBUG 01-06 17:11:02.470403.470403 lmp.py:414]   Expert 26 |    166 | GPU
DEBUG 01-06 17:11:02.470138.470138 lmp.py:414]   Expert 35 |    169 | GPU
DEBUG 01-06 17:11:02.470397.470397 lmp.py:414]   Expert 32 |    178 | GPU
DEBUG 01-06 17:11:02.470133.470133 lmp.py:414]   Expert 31 |    180 | GPU
DEBUG 01-06 17:11:02.470584.470584 lmp.py:414]   Expert  3 |    182 | GPU
DEBUG 01-06 17:11:02.470035.470035 lmp.py:414]   Expert 19 |    185 | GPU
DEBUG 01-06 17:11:02.470485.470485 lmp.py:414]   Expert 12 |    190 | GPU
DEBUG 01-06 17:11:02.470413.470413 lmp.py:414]   Expert 56 |    206 | GPU
DEBUG 01-06 17:11:02.470910.470910 lmp.py:414]   Expert 60 |    206 | GPU
DEBUG 01-06 17:11:02.470931.470931 lmp.py:414]   Expert 40 |    210 | GPU
DEBUG 01-06 17:11:02.470666.470666 lmp.py:414]   Expert 53 |    220 | GPU
DEBUG 01-06 17:11:02.470925.470925 lmp.py:414]   Expert 41 |    223 | GPU
DEBUG 01-06 17:11:02.470422.470422 lmp.py:414]   Expert 16 |    229 | GPU
DEBUG 01-06 17:11:02.470920.470920 lmp.py:414]   Expert 58 |    230 | GPU
DEBUG 01-06 17:11:02.470417.470417 lmp.py:414]   Expert 23 |    235 | GPU
DEBUG 01-06 17:11:02.470914.470914 lmp.py:414]   Expert  8 |    236 | GPU
DEBUG 01-06 17:11:02.470650.470650 lmp.py:414]   Expert 51 |    242 | GPU
DEBUG 01-06 17:11:02.470862.470862 lmp.py:414]   Expert 59 |    245 | GPU
DEBUG 01-06 17:11:02.470313.470313 lmp.py:414]   Expert  4 |    255 | GPU
DEBUG 01-06 17:11:02.470002.470002 lmp.py:414]   Expert 49 |    275 | GPU
DEBUG 01-06 17:11:02.470930.470930 lmp.py:414]   Expert 29 |    280 | GPU
DEBUG 01-06 17:11:02.470427.470427 lmp.py:414]   Expert 55 |    281 | GPU
DEBUG 01-06 17:11:02.470163.470163 lmp.py:414]   Expert 18 |    283 | GPU
DEBUG 01-06 17:11:02.470660.470660 lmp.py:414]   Expert 34 |    290 | GPU
DEBUG 01-06 17:11:02.470157.470157 lmp.py:414]   Expert 63 |    291 | GPU
DEBUG 01-06 17:11:02.470416.470416 lmp.py:414]   Expert 27 |    351 | GPU
DEBUG 01-06 17:11:02.470152.470152 lmp.py:414]   Expert 39 |    377 | GPU
DEBUG 01-06 17:11:02.470649.470649 lmp.py:414]   Expert 17 |    392 | GPU
DEBUG 01-06 17:11:02.470146.470146 lmp.py:414]   Expert 22 |    434 | GPU
DEBUG 01-06 17:11:02.470882.470882 lmp.py:414]   Expert 30 |    443 | GPU
DEBUG 01-06 17:11:02.470286.470286 lmp.py:414]   Expert 33 |    461 | GPU
DEBUG 01-06 17:11:02.470691.470691 lmp.py:414]   Expert  5 |    727 | GPU
DEBUG 01-06 17:11:02.470334.470334 lmp.py:415] 
DEBUG 01-06 17:11:02.470334.470334 lmp.py:415]   CPU total tokens: 3416 (27.8%)
DEBUG 01-06 17:11:02.470930.470930 lmp.py:416]   GPU total tokens: 8872 (72.2%)
DEBUG 01-06 17:11:02.470627.470627 cuda_h.py:19] end experts_map_get cost 0.0014731884002685547 seconds
DEBUG 01-06 17:11:02.470031.470031 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-06 17:11:02.470046.470046 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 17:11:02.471502.471502 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 17:11:02.472658.472658 cuda_h.py:19] end allocate_cuda_memory cost 0.0012698173522949219 seconds
DEBUG 01-06 17:11:02.472184.472184 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 17:11:02.472132.472132 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 17:11:02.472563.472563 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 17:11:02.472644.472644 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 09927e1a-6d30-40a5-a5cb-29a2dd1d3ff6
DEBUG 01-06 17:11:02.472312.472312 client.py:106] call stub.LoadModelAsync
INFO 01-06 17:11:02.474995.474995 client.py:127] Model loaded
DEBUG 01-06 17:11:02.474080.474080 cuda_h.py:19] end sllm_worker_task cost 0.010854721069335938 seconds
INFO 01-06 17:11:02.475963.475963 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 09927e1a-6d30-40a5-a5cb-29a2dd1d3ff6
DEBUG 01-06 17:11:02.475181.475181 cuda_h.py:19] end load_into_gpu_async cost 0.0034227371215820312 seconds
DEBUG 01-06 17:11:02.476382.476382 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 17:11:02.476834.476834 cuda_h.py:19] end restore_tensors2 cost 0.00037288665771484375 seconds
DEBUG 01-06 17:11:02.476279.476279 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.005556583404541016 seconds
DEBUG 01-06 17:11:02.479484.479484 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.008347511291503906 seconds
DEBUG 01-06 17:11:02.479883.479883 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-06 17:11:02.479276.479276 lmp.py:461] 
DEBUG 01-06 17:11:02.479276.479276 lmp.py:461]   Computing 32 experts on CPU...
DEBUG 01-06 17:11:02.479934.479934 cuda_h.py:19] end cpu_experts_submit cost 0.00011539459228515625 seconds
DEBUG 01-06 17:11:02.479060.479060 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-06 17:11:02.489072.489072 mlpmodule.py:706] group tensors cost 0.010194540023803711 s
DEBUG 01-06 17:11:02.492661.492661 mlpmodule.py:744] pad cost 0.0016710758209228516 s
DEBUG 01-06 17:11:02.492871.492871 mlpmodule.py:750] create cpu tensor cost 5.507469177246094e-05 s
DEBUG 01-06 17:11:02.492331.492331 mlpmodule.py:755] move to cpu cost 3.457069396972656e-05 s
DEBUG 01-06 17:11:02.502699.502699 mlpmodule.py:769] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-06 17:11:02.502456.502456 mlpmodule.py:770] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-06 17:11:02.502114.502114 mlpmodule.py:775] group_w3 first element: -0.018798828125
WARNING 01-06 17:11:02.502866.502866 mlpmodule.py:785] start einsum2
DEBUG 01-06 17:11:02.519328.519328 mlpmodule.py:795] group einsum cost 0.0267794132232666 s
DEBUG 01-06 17:11:02.520232.520232 mlpmodule.py:803] cpy2cputensor cost 0.0006270408630371094 s
DEBUG 01-06 17:11:02.524194.524194 cuda_h.py:19] end wait_cetm_experts cost 0.04483819007873535 seconds
DEBUG 01-06 17:11:02.524804.524804 cuda_h.py:10] start gpu_sexperts
DEBUG 01-06 17:11:02.525283.525283 cuda_h.py:19] end gpu_sexperts cost 0.000621795654296875 seconds
DEBUG 01-06 17:11:02.525987.525987 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-06 17:11:02.525453.525453 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.3365020751953125e-05 seconds
DEBUG 01-06 17:11:02.525871.525871 cuda_h.py:10] start wait_experts
INFO 01-06 17:11:02.525534.525534 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 09927e1a-6d30-40a5-a5cb-29a2dd1d3ff6
INFO 01-06 17:11:02.527287.527287 client.py:127] Model loaded
DEBUG 01-06 17:11:02.527190.527190 cuda_h.py:19] end wait_experts cost 0.002380847930908203 seconds
DEBUG 01-06 17:11:02.527231.527231 cuda_h.py:10] start gpu_experts
DEBUG 01-06 17:11:02.527239.527239 lmp.py:506]   Computing 32 experts on GPU...
DEBUG 01-06 17:11:02.528853.528853 mlpmodule.py:533] gpu group tensors cost 0.0006453990936279297 s
DEBUG 01-06 17:11:02.530027.530027 mlpmodule.py:566] gpu pad cost 0.0017919540405273438 s
DEBUG 01-06 17:11:02.531425.531425 mlpmodule.py:584] gpu group einsum cost 0.00052642822265625 s
DEBUG 01-06 17:11:02.531490.531490 mlpmodule.py:664]  experts func einsum cost 0.05196881294250488 s
DEBUG 01-06 17:11:02.534780.534780 mlpmodule.py:613] gpu experts func einsum cost 0.006758928298950195 s
DEBUG 01-06 17:11:02.534731.534731 cuda_h.py:19] end gpu_experts cost 0.00700068473815918 seconds
DEBUG 01-06 17:11:02.535615.535615 cuda_h.py:19] end layer_moe_generate_22 cost 0.06644320487976074 seconds
DEBUG 01-06 17:11:02.535946.535946 lmp.py:220] -------------------------------- end layer 22 --------------------------------
DEBUG 01-06 17:11:02.535569.535569 lmp.py:176] -------------------------------- start layer 23 --------------------------------
DEBUG 01-06 17:11:02.535789.535789 cuda_h.py:10] start start_load_qkvogn_s_weight_l_24
DEBUG 01-06 17:11:02.535545.535545 cuda_h.py:10] start start_load_qkvogn_s_weight_l_24
DEBUG 01-06 17:11:02.535911.535911 cuda_h.py:19] end start_load_qkvogn_s_weight_l_24 cost 3.337860107421875e-05 seconds
DEBUG 01-06 17:11:02.535806.535806 cuda_h.py:19] end start_load_qkvogn_s_weight_l_24 cost 6.461143493652344e-05 seconds
DEBUG 01-06 17:11:02.535071.535071 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-06 17:11:02.535796.535796 mlpmodule.py:367] cuda:1 cuda:1
DEBUG 01-06 17:11:02.535428.535428 cuda_h.py:10] start sllm_worker_task
DEBUG 01-06 17:11:02.535788.535788 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 17:11:02.535479.535479 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 17:11:02.536718.536718 cuda_h.py:19] end allocate_cuda_memory cost 0.00037932395935058594 seconds
DEBUG 01-06 17:11:02.536536.536536 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 17:11:02.536644.536644 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 17:11:02.536665.536665 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 17:11:02.536084.536084 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, e2b78e23-fbed-438e-b6f7-a989e9239971
DEBUG 01-06 17:11:02.536219.536219 client.py:106] call stub.LoadModelAsync
DEBUG 01-06 17:11:02.536222.536222 cuda_h.py:10] start self_attn
INFO 01-06 17:11:02.537966.537966 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, e2b78e23-fbed-438e-b6f7-a989e9239971
DEBUG 01-06 17:11:02.537551.537551 cuda_h.py:19] end load_into_gpu_async cost 0.0015647411346435547 seconds
DEBUG 01-06 17:11:02.537784.537784 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 17:11:02.537788.537788 cuda_h.py:19] end restore_tensors2 cost 7.486343383789062e-05 seconds
DEBUG 01-06 17:11:02.538689.538689 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0023527145385742188 seconds
INFO 01-06 17:11:02.538592.538592 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, e2b78e23-fbed-438e-b6f7-a989e9239971
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-06 17:11:02.539735.539735 cuda_h.py:19] end self_attn cost 0.0029861927032470703 seconds
DEBUG 01-06 17:11:02.540712.540712 cuda_h.py:19] end iln_self_attn_paln cost 0.004655361175537109 seconds
DEBUG 01-06 17:11:02.540647.540647 cuda_h.py:10] start layer_moe_generate_23
DEBUG 01-06 17:11:02.540556.540556 cuda_h.py:10] start gate
DEBUG 01-06 17:11:02.540261.540261 cuda_h.py:19] end gate cost 0.0006597042083740234 seconds
DEBUG 01-06 17:11:02.540422.540422 cuda_h.py:10] start experts_map_get
DEBUG 01-06 17:11:02.541690.541690 lmp.py:403] 
DEBUG 01-06 17:11:02.541690.541690 lmp.py:403] Expert Token Distribution & Device Allocation:
DEBUG 01-06 17:11:02.541970.541970 lmp.py:404]   Total experts: 64
DEBUG 01-06 17:11:02.541619.541619 lmp.py:405]   CPU experts: 32 (50%)
DEBUG 01-06 17:11:02.541454.541454 lmp.py:406]   GPU experts: 32 (50%)
DEBUG 01-06 17:11:02.541382.541382 lmp.py:407] 
DEBUG 01-06 17:11:02.541382.541382 lmp.py:407]   Expert ID | Tokens | Device
DEBUG 01-06 17:11:02.541787.541787 lmp.py:408]   -----------------------------------
DEBUG 01-06 17:11:02.541629.541629 lmp.py:414]   Expert  5 |     12 | CPU
DEBUG 01-06 17:11:02.541318.541318 lmp.py:414]   Expert 56 |     32 | CPU
DEBUG 01-06 17:11:02.541007.541007 lmp.py:414]   Expert 27 |     80 | CPU
DEBUG 01-06 17:11:02.541379.541379 lmp.py:414]   Expert 16 |     82 | CPU
DEBUG 01-06 17:11:02.541068.541068 lmp.py:414]   Expert 40 |     89 | CPU
DEBUG 01-06 17:11:02.541519.541519 lmp.py:414]   Expert 17 |     91 | CPU
DEBUG 01-06 17:11:02.541732.541732 lmp.py:414]   Expert 63 |     99 | CPU
DEBUG 01-06 17:11:02.541990.541990 lmp.py:414]   Expert 51 |    100 | CPU
DEBUG 01-06 17:11:02.541918.541918 lmp.py:414]   Expert 28 |    103 | CPU
DEBUG 01-06 17:11:02.541131.541131 lmp.py:414]   Expert 53 |    104 | CPU
DEBUG 01-06 17:11:02.541581.541581 lmp.py:414]   Expert 49 |    105 | CPU
DEBUG 01-06 17:11:02.541032.541032 lmp.py:414]   Expert  7 |    112 | CPU
DEBUG 01-06 17:11:02.541722.541722 lmp.py:414]   Expert 38 |    122 | CPU
DEBUG 01-06 17:11:02.541219.541219 lmp.py:414]   Expert 58 |    122 | CPU
DEBUG 01-06 17:11:02.541193.541193 lmp.py:414]   Expert 47 |    123 | CPU
DEBUG 01-06 17:11:02.541690.541690 lmp.py:414]   Expert 11 |    124 | CPU
DEBUG 01-06 17:11:02.541187.541187 lmp.py:414]   Expert 37 |    125 | CPU
DEBUG 01-06 17:11:02.541685.541685 lmp.py:414]   Expert 62 |    133 | CPU
DEBUG 01-06 17:11:02.541420.541420 lmp.py:414]   Expert 57 |    138 | CPU
DEBUG 01-06 17:11:02.541917.541917 lmp.py:414]   Expert  1 |    145 | CPU
DEBUG 01-06 17:11:02.541415.541415 lmp.py:414]   Expert 25 |    145 | CPU
DEBUG 01-06 17:11:02.541150.541150 lmp.py:414]   Expert 39 |    145 | CPU
DEBUG 01-06 17:11:02.541363.541363 lmp.py:414]   Expert 14 |    153 | CPU
DEBUG 01-06 17:11:02.541337.541337 lmp.py:414]   Expert 52 |    156 | CPU
DEBUG 01-06 17:11:02.541072.541072 lmp.py:414]   Expert 23 |    165 | CPU
DEBUG 01-06 17:11:02.541285.541285 lmp.py:414]   Expert 21 |    167 | CPU
DEBUG 01-06 17:11:02.541020.541020 lmp.py:414]   Expert 33 |    169 | CPU
DEBUG 01-06 17:11:02.541756.541756 lmp.py:414]   Expert 60 |    171 | CPU
DEBUG 01-06 17:11:02.541015.541015 lmp.py:414]   Expert 45 |    172 | CPU
DEBUG 01-06 17:11:02.541512.541512 lmp.py:414]   Expert 44 |    176 | CPU
DEBUG 01-06 17:11:02.541771.541771 lmp.py:414]   Expert  6 |    177 | CPU
DEBUG 01-06 17:11:02.541268.541268 lmp.py:414]   Expert  4 |    178 | CPU
DEBUG 01-06 17:11:02.541288.541288 lmp.py:414]   Expert 19 |    181 | GPU
DEBUG 01-06 17:11:02.541786.541786 lmp.py:414]   Expert 31 |    185 | GPU
DEBUG 01-06 17:11:02.541283.541283 lmp.py:414]   Expert 12 |    186 | GPU
DEBUG 01-06 17:11:02.541780.541780 lmp.py:414]   Expert  3 |    192 | GPU
DEBUG 01-06 17:11:02.541516.541516 lmp.py:414]   Expert 30 |    193 | GPU
DEBUG 01-06 17:11:02.541205.541205 lmp.py:414]   Expert 55 |    197 | GPU
DEBUG 01-06 17:11:02.541656.541656 lmp.py:414]   Expert 36 |    203 | GPU
DEBUG 01-06 17:11:02.541868.541868 lmp.py:414]   Expert  9 |    214 | GPU
DEBUG 01-06 17:11:02.541319.541319 lmp.py:414]   Expert 41 |    215 | GPU
DEBUG 01-06 17:11:02.542055.542055 lmp.py:414]   Expert  0 |    223 | GPU
DEBUG 01-06 17:11:02.542267.542267 lmp.py:414]   Expert 22 |    225 | GPU
DEBUG 01-06 17:11:02.542526.542526 lmp.py:414]   Expert 34 |    229 | GPU
DEBUG 01-06 17:11:02.542262.542262 lmp.py:414]   Expert 26 |    240 | GPU
DEBUG 01-06 17:11:02.542759.542759 lmp.py:414]   Expert 43 |    240 | GPU
DEBUG 01-06 17:11:02.542495.542495 lmp.py:414]   Expert 54 |    241 | GPU
DEBUG 01-06 17:11:02.542753.542753 lmp.py:414]   Expert 59 |    254 | GPU
DEBUG 01-06 17:11:02.542251.542251 lmp.py:414]   Expert 13 |    256 | GPU
DEBUG 01-06 17:11:02.542748.542748 lmp.py:414]   Expert 18 |    256 | GPU
DEBUG 01-06 17:11:02.542437.542437 lmp.py:414]   Expert 15 |    258 | GPU
DEBUG 01-06 17:11:02.542888.542888 lmp.py:414]   Expert 20 |    262 | GPU
DEBUG 01-06 17:11:02.542100.542100 lmp.py:414]   Expert 50 |    262 | GPU
DEBUG 01-06 17:11:02.542313.542313 lmp.py:414]   Expert 24 |    263 | GPU
DEBUG 01-06 17:11:02.542764.542764 lmp.py:414]   Expert 42 |    269 | GPU
DEBUG 01-06 17:11:02.542499.542499 lmp.py:414]   Expert 29 |    270 | GPU
DEBUG 01-06 17:11:02.542235.542235 lmp.py:414]   Expert 61 |    271 | GPU
DEBUG 01-06 17:11:02.542732.542732 lmp.py:414]   Expert 35 |    280 | GPU
DEBUG 01-06 17:11:02.542468.542468 lmp.py:414]   Expert 32 |    305 | GPU
DEBUG 01-06 17:11:02.542727.542727 lmp.py:414]   Expert  2 |    333 | GPU
DEBUG 01-06 17:11:02.542462.542462 lmp.py:414]   Expert  8 |    340 | GPU
DEBUG 01-06 17:11:02.542959.542959 lmp.py:414]   Expert 10 |    358 | GPU
DEBUG 01-06 17:11:02.542695.542695 lmp.py:414]   Expert 46 |    433 | GPU
DEBUG 01-06 17:11:02.542669.542669 lmp.py:414]   Expert 48 |    439 | GPU
DEBUG 01-06 17:11:02.542835.542835 lmp.py:415] 
DEBUG 01-06 17:11:02.542835.542835 lmp.py:415]   CPU total tokens: 4015 (32.7%)
DEBUG 01-06 17:11:02.542001.542001 lmp.py:416]   GPU total tokens: 8273 (67.3%)
DEBUG 01-06 17:11:02.542174.542174 cuda_h.py:19] end experts_map_get cost 0.0014748573303222656 seconds
DEBUG 01-06 17:11:02.542294.542294 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-06 17:11:02.542693.542693 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 17:11:02.542797.542797 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 17:11:02.544441.544441 cuda_h.py:19] end allocate_cuda_memory cost 0.0013887882232666016 seconds
DEBUG 01-06 17:11:02.544907.544907 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 17:11:02.544616.544616 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 17:11:02.544141.544141 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 17:11:02.544506.544506 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, f2fd601d-2693-4b29-8065-612c37b39590
DEBUG 01-06 17:11:02.544797.544797 client.py:106] call stub.LoadModelAsync
INFO 01-06 17:11:02.545266.545266 client.py:127] Model loaded
DEBUG 01-06 17:11:02.546390.546390 cuda_h.py:19] end sllm_worker_task cost 0.010662555694580078 seconds
INFO 01-06 17:11:02.547013.547013 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, f2fd601d-2693-4b29-8065-612c37b39590
DEBUG 01-06 17:11:02.547286.547286 cuda_h.py:19] end load_into_gpu_async cost 0.0031960010528564453 seconds
DEBUG 01-06 17:11:02.547989.547989 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 17:11:02.547258.547258 cuda_h.py:19] end restore_tensors2 cost 0.0002777576446533203 seconds
DEBUG 01-06 17:11:02.547981.547981 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.00521087646484375 seconds
DEBUG 01-06 17:11:02.555378.555378 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.012954950332641602 seconds
DEBUG 01-06 17:11:02.555830.555830 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-06 17:11:02.555137.555137 lmp.py:461] 
DEBUG 01-06 17:11:02.555137.555137 lmp.py:461]   Computing 32 experts on CPU...
DEBUG 01-06 17:11:02.555318.555318 cuda_h.py:19] end cpu_experts_submit cost 0.0001227855682373047 seconds
DEBUG 01-06 17:11:02.555730.555730 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-06 17:11:02.568021.568021 mlpmodule.py:706] group tensors cost 0.01227569580078125 s
DEBUG 01-06 17:11:02.570766.570766 mlpmodule.py:744] pad cost 0.0016064643859863281 s
DEBUG 01-06 17:11:02.570736.570736 mlpmodule.py:750] create cpu tensor cost 6.103515625e-05 s
DEBUG 01-06 17:11:02.570766.570766 mlpmodule.py:755] move to cpu cost 5.698204040527344e-05 s
DEBUG 01-06 17:11:02.580152.580152 mlpmodule.py:769] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-06 17:11:02.580485.580485 mlpmodule.py:770] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-06 17:11:02.580766.580766 mlpmodule.py:775] group_w3 first element: 0.08447265625
WARNING 01-06 17:11:02.580074.580074 mlpmodule.py:785] start einsum2
DEBUG 01-06 17:11:02.599707.599707 mlpmodule.py:795] group einsum cost 0.02882099151611328 s
DEBUG 01-06 17:11:02.600693.600693 mlpmodule.py:803] cpy2cputensor cost 0.0006654262542724609 s
DEBUG 01-06 17:11:02.604319.604319 cuda_h.py:19] end wait_cetm_experts cost 0.049156904220581055 seconds
DEBUG 01-06 17:11:02.605253.605253 cuda_h.py:10] start gpu_sexperts
DEBUG 01-06 17:11:02.605070.605070 cuda_h.py:19] end gpu_sexperts cost 0.0006263256072998047 seconds
DEBUG 01-06 17:11:02.605443.605443 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-06 17:11:02.605399.605399 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.384185791015625e-05 seconds
DEBUG 01-06 17:11:02.605055.605055 cuda_h.py:10] start wait_experts
INFO 01-06 17:11:02.605242.605242 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, f2fd601d-2693-4b29-8065-612c37b39590
INFO 01-06 17:11:02.607697.607697 client.py:127] Model loaded
DEBUG 01-06 17:11:02.607917.607917 cuda_h.py:19] end wait_experts cost 0.001377105712890625 seconds
DEBUG 01-06 17:11:02.607335.607335 cuda_h.py:10] start gpu_experts
DEBUG 01-06 17:11:02.607899.607899 lmp.py:506]   Computing 32 experts on GPU...
DEBUG 01-06 17:11:02.608169.608169 mlpmodule.py:533] gpu group tensors cost 0.0006396770477294922 s
DEBUG 01-06 17:11:02.609106.609106 mlpmodule.py:566] gpu pad cost 0.0018267631530761719 s
DEBUG 01-06 17:11:02.610607.610607 mlpmodule.py:584] gpu group einsum cost 0.0006382465362548828 s
DEBUG 01-06 17:11:02.612309.612309 mlpmodule.py:664]  experts func einsum cost 0.05630230903625488 s
DEBUG 01-06 17:11:02.614691.614691 mlpmodule.py:613] gpu experts func einsum cost 0.0069463253021240234 s
DEBUG 01-06 17:11:02.614988.614988 cuda_h.py:19] end gpu_experts cost 0.007186174392700195 seconds
DEBUG 01-06 17:11:02.614786.614786 cuda_h.py:19] end layer_moe_generate_23 cost 0.07450652122497559 seconds
DEBUG 01-06 17:11:02.614971.614971 lmp.py:220] -------------------------------- end layer 23 --------------------------------
DEBUG 01-06 17:11:02.614072.614072 lmp.py:176] -------------------------------- start layer 24 --------------------------------
DEBUG 01-06 17:11:02.614060.614060 cuda_h.py:10] start start_load_qkvogn_s_weight_l_25
DEBUG 01-06 17:11:02.614584.614584 cuda_h.py:10] start start_load_qkvogn_s_weight_l_25
DEBUG 01-06 17:11:02.615633.615633 cuda_h.py:19] end start_load_qkvogn_s_weight_l_25 cost 4.029273986816406e-05 seconds
DEBUG 01-06 17:11:02.615058.615058 cuda_h.py:19] end start_load_qkvogn_s_weight_l_25 cost 7.486343383789062e-05 seconds
DEBUG 01-06 17:11:02.615569.615569 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-06 17:11:02.615816.615816 mlpmodule.py:367] cuda:1 cuda:1
DEBUG 01-06 17:11:02.615263.615263 cuda_h.py:10] start sllm_worker_task
DEBUG 01-06 17:11:02.615524.615524 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 17:11:02.615261.615261 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 17:11:02.615359.615359 cuda_h.py:19] end allocate_cuda_memory cost 0.0003159046173095703 seconds
DEBUG 01-06 17:11:02.615342.615342 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 17:11:02.615734.615734 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 17:11:02.615325.615325 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 17:11:02.615028.615028 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 760537fe-c218-499b-99db-4d05e29a57cb
DEBUG 01-06 17:11:02.616428.616428 client.py:106] call stub.LoadModelAsync
DEBUG 01-06 17:11:02.616731.616731 cuda_h.py:10] start self_attn
INFO 01-06 17:11:02.617295.617295 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 760537fe-c218-499b-99db-4d05e29a57cb
DEBUG 01-06 17:11:02.617530.617530 cuda_h.py:19] end load_into_gpu_async cost 0.0016026496887207031 seconds
DEBUG 01-06 17:11:02.617147.617147 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 17:11:02.617296.617296 cuda_h.py:19] end restore_tensors2 cost 7.653236389160156e-05 seconds
DEBUG 01-06 17:11:02.617728.617728 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0022945404052734375 seconds
INFO 01-06 17:11:02.617425.617425 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 760537fe-c218-499b-99db-4d05e29a57cb
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-06 17:11:02.619740.619740 cuda_h.py:19] end self_attn cost 0.002989530563354492 seconds
DEBUG 01-06 17:11:02.619273.619273 cuda_h.py:19] end iln_self_attn_paln cost 0.0045926570892333984 seconds
DEBUG 01-06 17:11:02.619468.619468 cuda_h.py:10] start layer_moe_generate_24
DEBUG 01-06 17:11:02.619707.619707 cuda_h.py:10] start gate
DEBUG 01-06 17:11:02.620274.620274 cuda_h.py:19] end gate cost 0.00066375732421875 seconds
DEBUG 01-06 17:11:02.620481.620481 cuda_h.py:10] start experts_map_get
DEBUG 01-06 17:11:02.620365.620365 lmp.py:403] 
DEBUG 01-06 17:11:02.620365.620365 lmp.py:403] Expert Token Distribution & Device Allocation:
DEBUG 01-06 17:11:02.620882.620882 lmp.py:404]   Total experts: 64
DEBUG 01-06 17:11:02.620247.620247 lmp.py:405]   CPU experts: 32 (50%)
DEBUG 01-06 17:11:02.620559.620559 lmp.py:406]   GPU experts: 32 (50%)
DEBUG 01-06 17:11:02.620487.620487 lmp.py:407] 
DEBUG 01-06 17:11:02.620487.620487 lmp.py:407]   Expert ID | Tokens | Device
DEBUG 01-06 17:11:02.620892.620892 lmp.py:408]   -----------------------------------
DEBUG 01-06 17:11:02.621018.621018 lmp.py:414]   Expert 36 |     26 | CPU
DEBUG 01-06 17:11:02.621661.621661 lmp.py:414]   Expert 35 |     31 | CPU
DEBUG 01-06 17:11:02.621635.621635 lmp.py:414]   Expert 25 |     45 | CPU
DEBUG 01-06 17:11:02.621755.621755 lmp.py:414]   Expert 51 |     48 | CPU
DEBUG 01-06 17:11:02.621444.621444 lmp.py:414]   Expert 46 |     49 | CPU
DEBUG 01-06 17:11:02.621372.621372 lmp.py:414]   Expert 16 |     59 | CPU
DEBUG 01-06 17:11:02.621538.621538 lmp.py:414]   Expert  0 |     60 | CPU
DEBUG 01-06 17:11:02.621228.621228 lmp.py:414]   Expert 44 |     65 | CPU
DEBUG 01-06 17:11:02.621155.621155 lmp.py:414]   Expert 30 |     67 | CPU
DEBUG 01-06 17:11:02.621845.621845 lmp.py:414]   Expert 47 |     68 | CPU
DEBUG 01-06 17:11:02.621534.621534 lmp.py:414]   Expert 43 |     70 | CPU
DEBUG 01-06 17:11:02.621177.621177 lmp.py:414]   Expert 55 |     70 | CPU
DEBUG 01-06 17:11:02.621581.621581 lmp.py:414]   Expert 42 |     73 | CPU
DEBUG 01-06 17:11:02.621748.621748 lmp.py:414]   Expert 39 |     74 | CPU
DEBUG 01-06 17:11:02.621152.621152 lmp.py:414]   Expert  2 |     90 | CPU
DEBUG 01-06 17:11:02.621557.621557 lmp.py:414]   Expert 48 |    108 | CPU
DEBUG 01-06 17:11:02.621723.621723 lmp.py:414]   Expert  4 |    110 | CPU
DEBUG 01-06 17:11:02.621174.621174 lmp.py:414]   Expert 24 |    119 | CPU
DEBUG 01-06 17:11:02.621101.621101 lmp.py:414]   Expert 61 |    123 | CPU
DEBUG 01-06 17:11:02.621791.621791 lmp.py:414]   Expert 33 |    125 | CPU
DEBUG 01-06 17:11:02.621480.621480 lmp.py:414]   Expert 13 |    126 | CPU
DEBUG 01-06 17:11:02.621408.621408 lmp.py:414]   Expert  6 |    127 | CPU
DEBUG 01-06 17:11:02.621097.621097 lmp.py:414]   Expert 54 |    127 | CPU
DEBUG 01-06 17:11:02.621217.621217 lmp.py:414]   Expert 56 |    128 | CPU
DEBUG 01-06 17:11:02.621860.621860 lmp.py:414]   Expert 15 |    135 | CPU
DEBUG 01-06 17:11:02.621264.621264 lmp.py:414]   Expert  9 |    139 | CPU
DEBUG 01-06 17:11:02.621430.621430 lmp.py:414]   Expert 20 |    139 | CPU
DEBUG 01-06 17:11:02.621835.621835 lmp.py:414]   Expert  7 |    142 | CPU
DEBUG 01-06 17:11:02.621001.621001 lmp.py:414]   Expert 29 |    142 | CPU
DEBUG 01-06 17:11:02.621929.621929 lmp.py:414]   Expert 38 |    142 | CPU
DEBUG 01-06 17:11:02.621618.621618 lmp.py:414]   Expert 59 |    152 | CPU
DEBUG 01-06 17:11:02.621307.621307 lmp.py:414]   Expert 45 |    155 | CPU
DEBUG 01-06 17:11:02.621235.621235 lmp.py:414]   Expert 62 |    163 | GPU
DEBUG 01-06 17:11:02.621925.621925 lmp.py:414]   Expert 19 |    166 | GPU
DEBUG 01-06 17:11:02.621375.621375 lmp.py:414]   Expert 34 |    188 | GPU
DEBUG 01-06 17:11:02.621826.621826 lmp.py:414]   Expert 57 |    189 | GPU
DEBUG 01-06 17:11:02.621231.621231 lmp.py:414]   Expert 10 |    200 | GPU
DEBUG 01-06 17:11:02.621397.621397 lmp.py:414]   Expert 50 |    200 | GPU
DEBUG 01-06 17:11:02.621563.621563 lmp.py:414]   Expert 23 |    203 | GPU
DEBUG 01-06 17:11:02.621729.621729 lmp.py:414]   Expert  8 |    212 | GPU
DEBUG 01-06 17:11:02.621419.621419 lmp.py:414]   Expert 31 |    213 | GPU
DEBUG 01-06 17:11:02.621346.621346 lmp.py:414]   Expert 18 |    219 | GPU
DEBUG 01-06 17:11:02.621036.621036 lmp.py:414]   Expert 22 |    219 | GPU
DEBUG 01-06 17:11:02.621248.621248 lmp.py:414]   Expert 53 |    219 | GPU
DEBUG 01-06 17:11:02.621937.621937 lmp.py:414]   Expert 52 |    221 | GPU
DEBUG 01-06 17:11:02.621627.621627 lmp.py:414]   Expert 60 |    222 | GPU
DEBUG 01-06 17:11:02.621554.621554 lmp.py:414]   Expert 37 |    239 | GPU
DEBUG 01-06 17:11:02.621482.621482 lmp.py:414]   Expert 17 |    244 | GPU
DEBUG 01-06 17:11:02.621363.621363 lmp.py:414]   Expert  5 |    248 | GPU
DEBUG 01-06 17:11:02.621006.621006 lmp.py:414]   Expert 11 |    261 | GPU
DEBUG 01-06 17:11:02.621649.621649 lmp.py:414]   Expert  1 |    275 | GPU
DEBUG 01-06 17:11:02.621816.621816 lmp.py:414]   Expert 41 |    275 | GPU
DEBUG 01-06 17:11:02.621220.621220 lmp.py:414]   Expert 49 |    280 | GPU
DEBUG 01-06 17:11:02.621148.621148 lmp.py:414]   Expert 26 |    284 | GPU
DEBUG 01-06 17:11:02.621122.621122 lmp.py:414]   Expert 28 |    284 | GPU
DEBUG 01-06 17:11:02.621573.621573 lmp.py:414]   Expert 58 |    292 | GPU
DEBUG 01-06 17:11:02.621785.621785 lmp.py:414]   Expert 32 |    294 | GPU
DEBUG 01-06 17:11:02.621236.621236 lmp.py:414]   Expert 40 |    301 | GPU
DEBUG 01-06 17:11:02.621449.621449 lmp.py:414]   Expert 14 |    317 | GPU
DEBUG 01-06 17:11:02.622899.622899 lmp.py:414]   Expert 12 |    332 | GPU
DEBUG 01-06 17:11:02.622350.622350 lmp.py:414]   Expert 63 |    332 | GPU
DEBUG 01-06 17:11:02.622278.622278 lmp.py:414]   Expert 21 |    362 | GPU
DEBUG 01-06 17:11:02.622444.622444 lmp.py:414]   Expert 27 |    669 | GPU
DEBUG 01-06 17:11:02.622372.622372 lmp.py:414]   Expert  3 |   1031 | GPU
DEBUG 01-06 17:11:02.622492.622492 lmp.py:415] 
DEBUG 01-06 17:11:02.622492.622492 lmp.py:415]   CPU total tokens: 3134 (25.5%)
DEBUG 01-06 17:11:02.622850.622850 lmp.py:416]   GPU total tokens: 9154 (74.5%)
DEBUG 01-06 17:11:02.622546.622546 cuda_h.py:19] end experts_map_get cost 0.0015301704406738281 seconds
DEBUG 01-06 17:11:02.622951.622951 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-06 17:11:02.622396.622396 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 17:11:02.622785.622785 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 17:11:02.623778.623778 cuda_h.py:19] end allocate_cuda_memory cost 0.0013298988342285156 seconds
DEBUG 01-06 17:11:02.623972.623972 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 17:11:02.623443.623443 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 17:11:02.623113.623113 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 17:11:02.623955.623955 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 440dbc18-47ef-4a49-a3c5-1d704e2d9c6c
DEBUG 01-06 17:11:02.624028.624028 client.py:106] call stub.LoadModelAsync
INFO 01-06 17:11:02.625349.625349 client.py:127] Model loaded
DEBUG 01-06 17:11:02.626752.626752 cuda_h.py:19] end sllm_worker_task cost 0.011353731155395508 seconds
INFO 01-06 17:11:02.627816.627816 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 440dbc18-47ef-4a49-a3c5-1d704e2d9c6c
DEBUG 01-06 17:11:02.627282.627282 cuda_h.py:19] end load_into_gpu_async cost 0.003284931182861328 seconds
DEBUG 01-06 17:11:02.627985.627985 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 17:11:02.627797.627797 cuda_h.py:19] end restore_tensors2 cost 0.00029206275939941406 seconds
DEBUG 01-06 17:11:02.627997.627997 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.005265712738037109 seconds
DEBUG 01-06 17:11:02.630573.630573 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.008087158203125 seconds
DEBUG 01-06 17:11:02.630495.630495 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-06 17:11:02.630498.630498 lmp.py:461] 
DEBUG 01-06 17:11:02.630498.630498 lmp.py:461]   Computing 32 experts on CPU...
DEBUG 01-06 17:11:02.630771.630771 cuda_h.py:19] end cpu_experts_submit cost 0.00010633468627929688 seconds
DEBUG 01-06 17:11:02.630229.630229 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-06 17:11:02.640083.640083 mlpmodule.py:706] group tensors cost 0.010276556015014648 s
DEBUG 01-06 17:11:02.643265.643265 mlpmodule.py:744] pad cost 0.0015745162963867188 s
DEBUG 01-06 17:11:02.643599.643599 mlpmodule.py:750] create cpu tensor cost 4.553794860839844e-05 s
DEBUG 01-06 17:11:02.643165.643165 mlpmodule.py:755] move to cpu cost 3.075599670410156e-05 s
DEBUG 01-06 17:11:02.654003.654003 mlpmodule.py:769] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-06 17:11:02.654575.654575 mlpmodule.py:770] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-06 17:11:02.654140.654140 mlpmodule.py:775] group_w3 first element: 0.00653076171875
WARNING 01-06 17:11:02.654037.654037 mlpmodule.py:785] start einsum2
DEBUG 01-06 17:11:02.672555.672555 mlpmodule.py:795] group einsum cost 0.02882552146911621 s
DEBUG 01-06 17:11:02.672346.672346 mlpmodule.py:803] cpy2cputensor cost 0.0006077289581298828 s
DEBUG 01-06 17:11:02.677930.677930 cuda_h.py:19] end wait_cetm_experts cost 0.04674339294433594 seconds
DEBUG 01-06 17:11:02.677088.677088 cuda_h.py:10] start gpu_sexperts
DEBUG 01-06 17:11:02.678024.678024 cuda_h.py:19] end gpu_sexperts cost 0.0006074905395507812 seconds
DEBUG 01-06 17:11:02.678490.678490 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-06 17:11:02.678909.678909 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.3126602172851562e-05 seconds
DEBUG 01-06 17:11:02.678566.678566 cuda_h.py:10] start wait_experts
INFO 01-06 17:11:02.678275.678275 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 440dbc18-47ef-4a49-a3c5-1d704e2d9c6c
INFO 01-06 17:11:02.679541.679541 client.py:127] Model loaded
DEBUG 01-06 17:11:02.679668.679668 cuda_h.py:19] end wait_experts cost 0.001661062240600586 seconds
DEBUG 01-06 17:11:02.680087.680087 cuda_h.py:10] start gpu_experts
DEBUG 01-06 17:11:02.680081.680081 lmp.py:506]   Computing 32 experts on GPU...
DEBUG 01-06 17:11:02.680841.680841 mlpmodule.py:533] gpu group tensors cost 0.0006506443023681641 s
DEBUG 01-06 17:11:02.682890.682890 mlpmodule.py:566] gpu pad cost 0.0018029212951660156 s
DEBUG 01-06 17:11:02.683547.683547 mlpmodule.py:584] gpu group einsum cost 0.0005490779876708984 s
DEBUG 01-06 17:11:02.684416.684416 mlpmodule.py:664]  experts func einsum cost 0.0538792610168457 s
DEBUG 01-06 17:11:02.686472.686472 mlpmodule.py:613] gpu experts func einsum cost 0.006827354431152344 s
DEBUG 01-06 17:11:02.687199.687199 cuda_h.py:19] end gpu_experts cost 0.007074594497680664 seconds
DEBUG 01-06 17:11:02.687612.687612 cuda_h.py:19] end layer_moe_generate_24 cost 0.06738519668579102 seconds
DEBUG 01-06 17:11:02.687977.687977 lmp.py:220] -------------------------------- end layer 24 --------------------------------
DEBUG 01-06 17:11:02.687362.687362 lmp.py:176] -------------------------------- start layer 25 --------------------------------
DEBUG 01-06 17:11:02.687350.687350 cuda_h.py:10] start start_load_qkvogn_s_weight_l_26
DEBUG 01-06 17:11:02.687636.687636 cuda_h.py:10] start start_load_qkvogn_s_weight_l_26
DEBUG 01-06 17:11:02.687539.687539 cuda_h.py:19] end start_load_qkvogn_s_weight_l_26 cost 3.838539123535156e-05 seconds
DEBUG 01-06 17:11:02.687440.687440 cuda_h.py:19] end start_load_qkvogn_s_weight_l_26 cost 7.367134094238281e-05 seconds
DEBUG 01-06 17:11:02.687282.687282 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-06 17:11:02.687722.687722 mlpmodule.py:367] cuda:1 cuda:1
DEBUG 01-06 17:11:02.687692.687692 cuda_h.py:10] start sllm_worker_task
DEBUG 01-06 17:11:02.687953.687953 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 17:11:02.687419.687419 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 17:11:02.688384.688384 cuda_h.py:19] end allocate_cuda_memory cost 0.00031948089599609375 seconds
DEBUG 01-06 17:11:02.688527.688527 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 17:11:02.688350.688350 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 17:11:02.688133.688133 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 17:11:02.688028.688028 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, a1dfe7f4-cf1a-435c-9b84-8b156e2a86d7
DEBUG 01-06 17:11:02.688719.688719 client.py:106] call stub.LoadModelAsync
DEBUG 01-06 17:11:02.688305.688305 cuda_h.py:10] start self_attn
INFO 01-06 17:11:02.689618.689618 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, a1dfe7f4-cf1a-435c-9b84-8b156e2a86d7
DEBUG 01-06 17:11:02.690991.690991 cuda_h.py:19] end load_into_gpu_async cost 0.0015599727630615234 seconds
DEBUG 01-06 17:11:02.690747.690747 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 17:11:02.690373.690373 cuda_h.py:19] end restore_tensors2 cost 7.724761962890625e-05 seconds
DEBUG 01-06 17:11:02.690090.690090 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.002273082733154297 seconds
INFO 01-06 17:11:02.690225.690225 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, a1dfe7f4-cf1a-435c-9b84-8b156e2a86d7
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-06 17:11:02.691292.691292 cuda_h.py:19] end self_attn cost 0.0029129981994628906 seconds
DEBUG 01-06 17:11:02.692931.692931 cuda_h.py:19] end iln_self_attn_paln cost 0.004519224166870117 seconds
DEBUG 01-06 17:11:02.692106.692106 cuda_h.py:10] start layer_moe_generate_25
DEBUG 01-06 17:11:02.692537.692537 cuda_h.py:10] start gate
DEBUG 01-06 17:11:02.692639.692639 cuda_h.py:19] end gate cost 0.0006375312805175781 seconds
DEBUG 01-06 17:11:02.693038.693038 cuda_h.py:10] start experts_map_get
DEBUG 01-06 17:11:02.693214.693214 lmp.py:403] 
DEBUG 01-06 17:11:02.693214.693214 lmp.py:403] Expert Token Distribution & Device Allocation:
DEBUG 01-06 17:11:02.693493.693493 lmp.py:404]   Total experts: 64
DEBUG 01-06 17:11:02.693904.693904 lmp.py:405]   CPU experts: 32 (50%)
DEBUG 01-06 17:11:02.693501.693501 lmp.py:406]   GPU experts: 32 (50%)
DEBUG 01-06 17:11:02.693952.693952 lmp.py:407] 
DEBUG 01-06 17:11:02.693952.693952 lmp.py:407]   Expert ID | Tokens | Device
DEBUG 01-06 17:11:02.693641.693641 lmp.py:408]   -----------------------------------
DEBUG 01-06 17:11:02.693291.693291 lmp.py:414]   Expert 13 |     32 | CPU
DEBUG 01-06 17:11:02.693696.693696 lmp.py:414]   Expert 44 |     37 | CPU
DEBUG 01-06 17:11:02.693670.693670 lmp.py:414]   Expert  9 |     42 | CPU
DEBUG 01-06 17:11:02.693836.693836 lmp.py:414]   Expert 25 |     42 | CPU
DEBUG 01-06 17:11:02.693525.693525 lmp.py:414]   Expert 38 |     42 | CPU
DEBUG 01-06 17:11:02.693214.693214 lmp.py:414]   Expert 22 |     48 | CPU
DEBUG 01-06 17:11:02.693904.693904 lmp.py:414]   Expert 16 |     49 | CPU
DEBUG 01-06 17:11:02.693593.693593 lmp.py:414]   Expert 33 |     55 | CPU
DEBUG 01-06 17:11:02.693044.693044 lmp.py:414]   Expert  2 |     56 | CPU
DEBUG 01-06 17:11:02.693641.693641 lmp.py:414]   Expert 42 |     57 | CPU
DEBUG 01-06 17:11:02.693568.693568 lmp.py:414]   Expert  5 |     69 | CPU
DEBUG 01-06 17:11:02.693496.693496 lmp.py:414]   Expert 24 |     75 | CPU
DEBUG 01-06 17:11:02.693424.693424 lmp.py:414]   Expert 10 |     77 | CPU
DEBUG 01-06 17:11:02.693351.693351 lmp.py:414]   Expert 23 |     83 | CPU
DEBUG 01-06 17:11:02.693802.693802 lmp.py:414]   Expert 59 |     87 | CPU
DEBUG 01-06 17:11:02.693492.693492 lmp.py:414]   Expert 21 |    101 | CPU
DEBUG 01-06 17:11:02.693181.693181 lmp.py:414]   Expert 46 |    107 | CPU
DEBUG 01-06 17:11:02.693301.693301 lmp.py:414]   Expert 55 |    108 | CPU
DEBUG 01-06 17:11:02.693467.693467 lmp.py:414]   Expert 45 |    117 | CPU
DEBUG 01-06 17:11:02.693871.693871 lmp.py:414]   Expert 61 |    123 | CPU
DEBUG 01-06 17:11:02.693038.693038 lmp.py:414]   Expert 31 |    129 | CPU
DEBUG 01-06 17:11:02.693442.693442 lmp.py:414]   Expert  0 |    134 | CPU
DEBUG 01-06 17:11:02.693131.693131 lmp.py:414]   Expert 36 |    135 | CPU
DEBUG 01-06 17:11:02.693821.693821 lmp.py:414]   Expert 51 |    140 | CPU
DEBUG 01-06 17:11:02.693987.693987 lmp.py:414]   Expert  6 |    143 | CPU
DEBUG 01-06 17:11:02.693676.693676 lmp.py:414]   Expert  8 |    147 | CPU
DEBUG 01-06 17:11:02.693604.693604 lmp.py:414]   Expert 26 |    157 | CPU
DEBUG 01-06 17:11:02.693293.693293 lmp.py:414]   Expert 43 |    159 | CPU
DEBUG 01-06 17:11:02.693744.693744 lmp.py:414]   Expert 18 |    161 | CPU
DEBUG 01-06 17:11:02.693672.693672 lmp.py:414]   Expert 48 |    161 | CPU
DEBUG 01-06 17:11:02.693838.693838 lmp.py:414]   Expert  3 |    164 | CPU
DEBUG 01-06 17:11:02.693004.693004 lmp.py:414]   Expert 41 |    172 | CPU
DEBUG 01-06 17:11:02.693647.693647 lmp.py:414]   Expert 12 |    177 | GPU
DEBUG 01-06 17:11:02.693052.693052 lmp.py:414]   Expert 20 |    178 | GPU
DEBUG 01-06 17:11:02.694979.694979 lmp.py:414]   Expert  7 |    180 | GPU
DEBUG 01-06 17:11:02.694669.694669 lmp.py:414]   Expert 56 |    186 | GPU
DEBUG 01-06 17:11:02.694119.694119 lmp.py:414]   Expert 27 |    194 | GPU
DEBUG 01-06 17:11:02.694570.694570 lmp.py:414]   Expert 28 |    194 | GPU
DEBUG 01-06 17:11:02.694783.694783 lmp.py:414]   Expert  1 |    198 | GPU
DEBUG 01-06 17:11:02.694472.694472 lmp.py:414]   Expert 47 |    198 | GPU
DEBUG 01-06 17:11:02.694161.694161 lmp.py:414]   Expert 34 |    200 | GPU
DEBUG 01-06 17:11:02.694374.694374 lmp.py:414]   Expert 11 |    213 | GPU
DEBUG 01-06 17:11:02.694063.694063 lmp.py:414]   Expert 32 |    213 | GPU
DEBUG 01-06 17:11:02.694514.694514 lmp.py:414]   Expert 40 |    226 | GPU
DEBUG 01-06 17:11:02.694203.694203 lmp.py:414]   Expert 49 |    232 | GPU
DEBUG 01-06 17:11:02.694369.694369 lmp.py:414]   Expert 53 |    235 | GPU
DEBUG 01-06 17:11:02.694536.694536 lmp.py:414]   Expert 50 |    245 | GPU
DEBUG 01-06 17:11:02.694225.694225 lmp.py:414]   Expert 63 |    247 | GPU
DEBUG 01-06 17:11:02.694153.694153 lmp.py:414]   Expert 29 |    248 | GPU
DEBUG 01-06 17:11:02.694319.694319 lmp.py:414]   Expert 30 |    249 | GPU
DEBUG 01-06 17:11:02.694008.694008 lmp.py:414]   Expert 15 |    251 | GPU
DEBUG 01-06 17:11:02.694459.694459 lmp.py:414]   Expert  4 |    257 | GPU
DEBUG 01-06 17:11:02.694671.694671 lmp.py:414]   Expert 35 |    271 | GPU
DEBUG 01-06 17:11:02.694122.694122 lmp.py:414]   Expert 14 |    274 | GPU
DEBUG 01-06 17:11:02.694573.694573 lmp.py:414]   Expert 37 |    303 | GPU
DEBUG 01-06 17:11:02.694024.694024 lmp.py:414]   Expert 52 |    330 | GPU
DEBUG 01-06 17:11:02.694237.694237 lmp.py:414]   Expert 17 |    361 | GPU
DEBUG 01-06 17:11:02.694926.694926 lmp.py:414]   Expert 54 |    378 | GPU
DEBUG 01-06 17:11:02.694615.694615 lmp.py:414]   Expert 39 |    398 | GPU
DEBUG 01-06 17:11:02.694781.694781 lmp.py:414]   Expert 57 |    408 | GPU
DEBUG 01-06 17:11:02.694709.694709 lmp.py:414]   Expert 60 |    458 | GPU
DEBUG 01-06 17:11:02.694875.694875 lmp.py:414]   Expert 62 |    463 | GPU
DEBUG 01-06 17:11:02.694326.694326 lmp.py:414]   Expert 19 |    545 | GPU
DEBUG 01-06 17:11:02.694015.694015 lmp.py:414]   Expert 58 |    569 | GPU
DEBUG 01-06 17:11:02.694420.694420 lmp.py:415] 
DEBUG 01-06 17:11:02.694420.694420 lmp.py:415]   CPU total tokens: 3209 (26.1%)
DEBUG 01-06 17:11:02.694063.694063 lmp.py:416]   GPU total tokens: 9079 (73.9%)
DEBUG 01-06 17:11:02.694236.694236 cuda_h.py:19] end experts_map_get cost 0.001522064208984375 seconds
DEBUG 01-06 17:11:02.694879.694879 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-06 17:11:02.694847.694847 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 17:11:02.694521.694521 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 17:11:02.696635.696635 cuda_h.py:19] end allocate_cuda_memory cost 0.0019812583923339844 seconds
DEBUG 01-06 17:11:02.696512.696512 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 17:11:02.696367.696367 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 17:11:02.696037.696037 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 17:11:02.696641.696641 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, c5c6b225-b5ee-470a-a4aa-4b1a6dc578ab
DEBUG 01-06 17:11:02.697746.697746 client.py:106] call stub.LoadModelAsync
INFO 01-06 17:11:02.698949.698949 client.py:127] Model loaded
DEBUG 01-06 17:11:02.699496.699496 cuda_h.py:19] end sllm_worker_task cost 0.0114593505859375 seconds
INFO 01-06 17:11:02.700575.700575 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, c5c6b225-b5ee-470a-a4aa-4b1a6dc578ab
DEBUG 01-06 17:11:02.700918.700918 cuda_h.py:19] end load_into_gpu_async cost 0.0033724308013916016 seconds
DEBUG 01-06 17:11:02.700881.700881 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 17:11:02.700666.700666 cuda_h.py:19] end restore_tensors2 cost 0.0003895759582519531 seconds
DEBUG 01-06 17:11:02.700442.700442 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.006278038024902344 seconds
DEBUG 01-06 17:11:02.703302.703302 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.009063720703125 seconds
DEBUG 01-06 17:11:02.703887.703887 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-06 17:11:02.703055.703055 lmp.py:461] 
DEBUG 01-06 17:11:02.703055.703055 lmp.py:461]   Computing 32 experts on CPU...
DEBUG 01-06 17:11:02.703044.703044 cuda_h.py:19] end cpu_experts_submit cost 0.00010895729064941406 seconds
DEBUG 01-06 17:11:02.703455.703455 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-06 17:11:02.714061.714061 mlpmodule.py:706] group tensors cost 0.010364055633544922 s
DEBUG 01-06 17:11:02.716186.716186 mlpmodule.py:744] pad cost 0.0017740726470947266 s
DEBUG 01-06 17:11:02.717726.717726 mlpmodule.py:750] create cpu tensor cost 4.649162292480469e-05 s
DEBUG 01-06 17:11:02.717636.717636 mlpmodule.py:755] move to cpu cost 3.266334533691406e-05 s
DEBUG 01-06 17:11:02.727137.727137 mlpmodule.py:769] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-06 17:11:02.727378.727378 mlpmodule.py:770] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-06 17:11:02.727466.727466 mlpmodule.py:775] group_w3 first element: 0.007110595703125
WARNING 01-06 17:11:02.728072.728072 mlpmodule.py:785] start einsum2
DEBUG 01-06 17:11:02.753373.753373 mlpmodule.py:795] group einsum cost 0.03581500053405762 s
DEBUG 01-06 17:11:02.753285.753285 mlpmodule.py:803] cpy2cputensor cost 0.0006465911865234375 s
DEBUG 01-06 17:11:02.758277.758277 cuda_h.py:19] end wait_cetm_experts cost 0.054314613342285156 seconds
DEBUG 01-06 17:11:02.758965.758965 cuda_h.py:10] start gpu_sexperts
DEBUG 01-06 17:11:02.759631.759631 cuda_h.py:19] end gpu_sexperts cost 0.0006554126739501953 seconds
DEBUG 01-06 17:11:02.759627.759627 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-06 17:11:02.759238.759238 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.4318695068359375e-05 seconds
DEBUG 01-06 17:11:02.759656.759656 cuda_h.py:10] start wait_experts
INFO 01-06 17:11:02.759081.759081 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, c5c6b225-b5ee-470a-a4aa-4b1a6dc578ab
INFO 01-06 17:11:02.760946.760946 client.py:127] Model loaded
DEBUG 01-06 17:11:02.760319.760319 cuda_h.py:19] end wait_experts cost 0.0013701915740966797 seconds
DEBUG 01-06 17:11:02.760983.760983 cuda_h.py:10] start gpu_experts
DEBUG 01-06 17:11:02.760407.760407 lmp.py:506]   Computing 32 experts on GPU...
DEBUG 01-06 17:11:02.761126.761126 mlpmodule.py:533] gpu group tensors cost 0.0006189346313476562 s
DEBUG 01-06 17:11:02.763281.763281 mlpmodule.py:566] gpu pad cost 0.0017790794372558594 s
DEBUG 01-06 17:11:02.764734.764734 mlpmodule.py:584] gpu group einsum cost 0.0006091594696044922 s
DEBUG 01-06 17:11:02.765227.765227 mlpmodule.py:664]  experts func einsum cost 0.06184840202331543 s
DEBUG 01-06 17:11:02.767037.767037 mlpmodule.py:613] gpu experts func einsum cost 0.00682520866394043 s
DEBUG 01-06 17:11:02.767041.767041 cuda_h.py:19] end gpu_experts cost 0.007069110870361328 seconds
DEBUG 01-06 17:11:02.767793.767793 cuda_h.py:19] end layer_moe_generate_25 cost 0.0756843090057373 seconds
DEBUG 01-06 17:11:02.768449.768449 lmp.py:220] -------------------------------- end layer 25 --------------------------------
DEBUG 01-06 17:11:02.768788.768788 lmp.py:176] -------------------------------- start layer 26 --------------------------------
DEBUG 01-06 17:11:02.768060.768060 cuda_h.py:10] start start_load_qkvogn_s_weight_l_27
DEBUG 01-06 17:11:02.768346.768346 cuda_h.py:10] start start_load_qkvogn_s_weight_l_27
DEBUG 01-06 17:11:02.768011.768011 cuda_h.py:19] end start_load_qkvogn_s_weight_l_27 cost 3.814697265625e-05 seconds
DEBUG 01-06 17:11:02.768436.768436 cuda_h.py:19] end start_load_qkvogn_s_weight_l_27 cost 7.343292236328125e-05 seconds
DEBUG 01-06 17:11:02.768530.768530 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-06 17:11:02.768717.768717 cuda_h.py:10] start sllm_worker_task
DEBUG 01-06 17:11:02.768715.768715 mlpmodule.py:367] cuda:1 cuda:1
DEBUG 01-06 17:11:02.768823.768823 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 17:11:02.768284.768284 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 17:11:02.769139.769139 cuda_h.py:19] end allocate_cuda_memory cost 0.00036644935607910156 seconds
DEBUG 01-06 17:11:02.769069.769069 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 17:11:02.769978.769978 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 17:11:02.769039.769039 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 17:11:02.769027.769027 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, e460d03d-4cc4-447e-8ac3-08ef9591e082
DEBUG 01-06 17:11:02.769851.769851 client.py:106] call stub.LoadModelAsync
DEBUG 01-06 17:11:02.769642.769642 cuda_h.py:10] start self_attn
INFO 01-06 17:11:02.770981.770981 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, e460d03d-4cc4-447e-8ac3-08ef9591e082
DEBUG 01-06 17:11:02.770632.770632 cuda_h.py:19] end load_into_gpu_async cost 0.001535177230834961 seconds
DEBUG 01-06 17:11:02.770666.770666 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 17:11:02.770709.770709 cuda_h.py:19] end restore_tensors2 cost 7.534027099609375e-05 seconds
DEBUG 01-06 17:11:02.771988.771988 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0022690296173095703 seconds
INFO 01-06 17:11:02.771401.771401 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, e460d03d-4cc4-447e-8ac3-08ef9591e082
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-06 17:11:02.772148.772148 cuda_h.py:19] end self_attn cost 0.002979755401611328 seconds
DEBUG 01-06 17:11:02.773628.773628 cuda_h.py:19] end iln_self_attn_paln cost 0.004674434661865234 seconds
DEBUG 01-06 17:11:02.773994.773994 cuda_h.py:10] start layer_moe_generate_26
DEBUG 01-06 17:11:02.773710.773710 cuda_h.py:10] start gate
DEBUG 01-06 17:11:02.773528.773528 cuda_h.py:19] end gate cost 0.0006389617919921875 seconds
DEBUG 01-06 17:11:02.773211.773211 cuda_h.py:10] start experts_map_get
DEBUG 01-06 17:11:02.774149.774149 lmp.py:403] 
DEBUG 01-06 17:11:02.774149.774149 lmp.py:403] Expert Token Distribution & Device Allocation:
DEBUG 01-06 17:11:02.774713.774713 lmp.py:404]   Total experts: 64
DEBUG 01-06 17:11:02.774601.774601 lmp.py:405]   CPU experts: 32 (50%)
DEBUG 01-06 17:11:02.774436.774436 lmp.py:406]   GPU experts: 32 (50%)
DEBUG 01-06 17:11:02.774602.774602 lmp.py:407] 
DEBUG 01-06 17:11:02.774602.774602 lmp.py:407]   Expert ID | Tokens | Device
DEBUG 01-06 17:11:02.774006.774006 lmp.py:408]   -----------------------------------
DEBUG 01-06 17:11:02.774087.774087 lmp.py:414]   Expert 20 |      8 | CPU
DEBUG 01-06 17:11:02.774253.774253 lmp.py:414]   Expert 61 |     12 | CPU
DEBUG 01-06 17:11:02.774373.774373 lmp.py:414]   Expert 11 |     30 | CPU
DEBUG 01-06 17:11:02.774539.774539 lmp.py:414]   Expert  7 |     34 | CPU
DEBUG 01-06 17:11:02.774467.774467 lmp.py:414]   Expert  3 |     35 | CPU
DEBUG 01-06 17:11:02.774917.774917 lmp.py:414]   Expert 51 |     39 | CPU
DEBUG 01-06 17:11:02.774607.774607 lmp.py:414]   Expert 62 |     40 | CPU
DEBUG 01-06 17:11:02.774058.774058 lmp.py:414]   Expert 30 |     48 | CPU
DEBUG 01-06 17:11:02.774177.774177 lmp.py:414]   Expert 17 |     53 | CPU
DEBUG 01-06 17:11:02.774105.774105 lmp.py:414]   Expert 29 |     59 | CPU
DEBUG 01-06 17:11:02.774987.774987 lmp.py:414]   Expert  6 |     61 | CPU
DEBUG 01-06 17:11:02.774458.774458 lmp.py:414]   Expert  9 |     72 | CPU
DEBUG 01-06 17:11:02.774492.774492 lmp.py:414]   Expert 63 |     76 | CPU
DEBUG 01-06 17:11:02.774135.774135 lmp.py:414]   Expert 38 |     78 | CPU
DEBUG 01-06 17:11:02.774062.774062 lmp.py:414]   Expert 59 |     81 | CPU
DEBUG 01-06 17:11:02.774752.774752 lmp.py:414]   Expert 55 |     82 | CPU
DEBUG 01-06 17:11:02.774203.774203 lmp.py:414]   Expert 19 |     84 | CPU
DEBUG 01-06 17:11:02.774892.774892 lmp.py:414]   Expert 48 |     98 | CPU
DEBUG 01-06 17:11:02.774104.774104 lmp.py:414]   Expert  8 |    102 | CPU
DEBUG 01-06 17:11:02.774555.774555 lmp.py:414]   Expert 49 |    104 | CPU
DEBUG 01-06 17:11:02.774006.774006 lmp.py:414]   Expert 22 |    105 | CPU
DEBUG 01-06 17:11:02.774219.774219 lmp.py:414]   Expert 34 |    110 | CPU
DEBUG 01-06 17:11:02.774669.774669 lmp.py:414]   Expert 50 |    112 | CPU
DEBUG 01-06 17:11:02.774882.774882 lmp.py:414]   Expert 24 |    116 | CPU
DEBUG 01-06 17:11:02.774618.774618 lmp.py:414]   Expert 36 |    118 | CPU
DEBUG 01-06 17:11:02.774115.774115 lmp.py:414]   Expert 42 |    119 | CPU
DEBUG 01-06 17:11:02.774850.774850 lmp.py:414]   Expert  4 |    123 | CPU
DEBUG 01-06 17:11:02.774824.774824 lmp.py:414]   Expert 39 |    124 | CPU
DEBUG 01-06 17:11:02.774322.774322 lmp.py:414]   Expert 15 |    143 | CPU
DEBUG 01-06 17:11:02.774057.774057 lmp.py:414]   Expert 37 |    143 | CPU
DEBUG 01-06 17:11:02.774793.774793 lmp.py:414]   Expert 41 |    150 | CPU
DEBUG 01-06 17:11:02.774482.774482 lmp.py:414]   Expert 23 |    154 | CPU
DEBUG 01-06 17:11:02.774172.774172 lmp.py:414]   Expert 16 |    162 | GPU
DEBUG 01-06 17:11:02.774384.774384 lmp.py:414]   Expert 56 |    166 | GPU
DEBUG 01-06 17:11:02.774596.774596 lmp.py:414]   Expert 60 |    170 | GPU
DEBUG 01-06 17:11:02.774809.774809 lmp.py:414]   Expert 44 |    175 | GPU
DEBUG 01-06 17:11:02.774306.774306 lmp.py:414]   Expert  1 |    178 | GPU
DEBUG 01-06 17:11:02.774803.774803 lmp.py:414]   Expert 21 |    182 | GPU
DEBUG 01-06 17:11:02.775062.775062 lmp.py:414]   Expert 43 |    186 | GPU
DEBUG 01-06 17:11:02.775321.775321 lmp.py:414]   Expert 53 |    191 | GPU
DEBUG 01-06 17:11:02.775057.775057 lmp.py:414]   Expert 12 |    197 | GPU
DEBUG 01-06 17:11:02.775554.775554 lmp.py:414]   Expert 47 |    197 | GPU
DEBUG 01-06 17:11:02.775051.775051 lmp.py:414]   Expert 33 |    201 | GPU
DEBUG 01-06 17:11:02.775548.775548 lmp.py:414]   Expert 13 |    212 | GPU
DEBUG 01-06 17:11:02.775522.775522 lmp.py:414]   Expert 32 |    221 | GPU
DEBUG 01-06 17:11:02.775735.775735 lmp.py:414]   Expert 28 |    228 | GPU
DEBUG 01-06 17:11:02.775947.775947 lmp.py:414]   Expert  0 |    253 | GPU
DEBUG 01-06 17:11:02.775636.775636 lmp.py:414]   Expert 31 |    256 | GPU
DEBUG 01-06 17:11:02.775087.775087 lmp.py:414]   Expert 54 |    257 | GPU
DEBUG 01-06 17:11:02.775346.775346 lmp.py:414]   Expert 10 |    258 | GPU
DEBUG 01-06 17:11:02.775082.775082 lmp.py:414]   Expert 26 |    262 | GPU
DEBUG 01-06 17:11:02.775579.775579 lmp.py:414]   Expert 18 |    264 | GPU
DEBUG 01-06 17:11:02.775315.775315 lmp.py:414]   Expert 57 |    276 | GPU
DEBUG 01-06 17:11:02.775573.775573 lmp.py:414]   Expert  2 |    290 | GPU
DEBUG 01-06 17:11:02.775071.775071 lmp.py:414]   Expert 58 |    300 | GPU
DEBUG 01-06 17:11:02.775329.775329 lmp.py:414]   Expert 40 |    336 | GPU
DEBUG 01-06 17:11:02.775065.775065 lmp.py:414]   Expert 45 |    366 | GPU
DEBUG 01-06 17:11:02.775516.775516 lmp.py:414]   Expert 25 |    384 | GPU
DEBUG 01-06 17:11:02.775728.775728 lmp.py:414]   Expert  5 |    434 | GPU
DEBUG 01-06 17:11:02.775702.775702 lmp.py:414]   Expert 35 |    445 | GPU
DEBUG 01-06 17:11:02.775676.775676 lmp.py:414]   Expert 27 |    483 | GPU
DEBUG 01-06 17:11:02.775366.775366 lmp.py:414]   Expert 46 |    534 | GPU
DEBUG 01-06 17:11:02.775340.775340 lmp.py:414]   Expert 52 |    615 | GPU
DEBUG 01-06 17:11:02.775599.775599 lmp.py:414]   Expert 14 |    896 | GPU
DEBUG 01-06 17:11:02.775765.775765 lmp.py:415] 
DEBUG 01-06 17:11:02.775765.775765 lmp.py:415]   CPU total tokens: 2713 (22.1%)
DEBUG 01-06 17:11:02.775692.775692 lmp.py:416]   GPU total tokens: 9575 (77.9%)
DEBUG 01-06 17:11:02.775388.775388 cuda_h.py:19] end experts_map_get cost 0.0015053749084472656 seconds
DEBUG 01-06 17:11:02.775793.775793 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-06 17:11:02.775669.775669 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 17:11:02.775144.775144 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 17:11:02.777052.777052 cuda_h.py:19] end allocate_cuda_memory cost 0.0013720989227294922 seconds
DEBUG 01-06 17:11:02.777425.777425 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 17:11:02.777181.777181 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 17:11:02.777612.777612 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 17:11:02.777454.777454 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 23985b95-88df-43e0-9c0a-d60f8e166fa3
DEBUG 01-06 17:11:02.777136.777136 client.py:106] call stub.LoadModelAsync
INFO 01-06 17:11:02.778765.778765 client.py:127] Model loaded
DEBUG 01-06 17:11:02.779807.779807 cuda_h.py:19] end sllm_worker_task cost 0.010597944259643555 seconds
INFO 01-06 17:11:02.780781.780781 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 23985b95-88df-43e0-9c0a-d60f8e166fa3
DEBUG 01-06 17:11:02.780654.780654 cuda_h.py:19] end load_into_gpu_async cost 0.003419160842895508 seconds
DEBUG 01-06 17:11:02.780193.780193 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 17:11:02.781755.781755 cuda_h.py:19] end restore_tensors2 cost 0.0003154277801513672 seconds
DEBUG 01-06 17:11:02.781631.781631 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.005566835403442383 seconds
DEBUG 01-06 17:11:02.783081.783081 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.008366584777832031 seconds
DEBUG 01-06 17:11:02.783864.783864 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-06 17:11:02.783919.783919 lmp.py:461] 
DEBUG 01-06 17:11:02.783919.783919 lmp.py:461]   Computing 32 experts on CPU...
DEBUG 01-06 17:11:02.784623.784623 cuda_h.py:19] end cpu_experts_submit cost 0.00010991096496582031 seconds
DEBUG 01-06 17:11:02.784512.784512 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-06 17:11:02.794432.794432 mlpmodule.py:706] group tensors cost 0.010496854782104492 s
DEBUG 01-06 17:11:02.797049.797049 mlpmodule.py:744] pad cost 0.0016255378723144531 s
DEBUG 01-06 17:11:02.797006.797006 mlpmodule.py:750] create cpu tensor cost 4.57763671875e-05 s
DEBUG 01-06 17:11:02.797763.797763 mlpmodule.py:755] move to cpu cost 3.0994415283203125e-05 s
DEBUG 01-06 17:11:02.806302.806302 mlpmodule.py:769] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-06 17:11:02.806682.806682 mlpmodule.py:770] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-06 17:11:02.807240.807240 mlpmodule.py:775] group_w3 first element: -0.0024261474609375
WARNING 01-06 17:11:02.807839.807839 mlpmodule.py:785] start einsum2
DEBUG 01-06 17:11:02.824989.824989 mlpmodule.py:795] group einsum cost 0.027258872985839844 s
DEBUG 01-06 17:11:02.825489.825489 mlpmodule.py:803] cpy2cputensor cost 0.0006031990051269531 s
DEBUG 01-06 17:11:02.829160.829160 cuda_h.py:19] end wait_cetm_experts cost 0.04558229446411133 seconds
DEBUG 01-06 17:11:02.829233.829233 cuda_h.py:10] start gpu_sexperts
DEBUG 01-06 17:11:02.830136.830136 cuda_h.py:19] end gpu_sexperts cost 0.00061798095703125 seconds
DEBUG 01-06 17:11:02.830986.830986 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-06 17:11:02.830359.830359 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.3126602172851562e-05 seconds
DEBUG 01-06 17:11:02.830015.830015 cuda_h.py:10] start wait_experts
INFO 01-06 17:11:02.830202.830202 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 23985b95-88df-43e0-9c0a-d60f8e166fa3
INFO 01-06 17:11:02.832262.832262 client.py:127] Model loaded
DEBUG 01-06 17:11:02.833251.833251 cuda_h.py:19] end wait_experts cost 0.002249002456665039 seconds
DEBUG 01-06 17:11:02.833861.833861 cuda_h.py:10] start gpu_experts
DEBUG 01-06 17:11:02.833431.833431 lmp.py:506]   Computing 32 experts on GPU...
DEBUG 01-06 17:11:02.833813.833813 mlpmodule.py:533] gpu group tensors cost 0.0006170272827148438 s
DEBUG 01-06 17:11:02.835531.835531 mlpmodule.py:566] gpu pad cost 0.0018067359924316406 s
DEBUG 01-06 17:11:02.836426.836426 mlpmodule.py:584] gpu group einsum cost 0.0005512237548828125 s
DEBUG 01-06 17:11:02.836330.836330 mlpmodule.py:664]  experts func einsum cost 0.05254769325256348 s
DEBUG 01-06 17:11:02.839170.839170 mlpmodule.py:613] gpu experts func einsum cost 0.006727933883666992 s
DEBUG 01-06 17:11:02.840228.840228 cuda_h.py:19] end gpu_experts cost 0.006979465484619141 seconds
DEBUG 01-06 17:11:02.840542.840542 cuda_h.py:19] end layer_moe_generate_26 cost 0.06698036193847656 seconds
DEBUG 01-06 17:11:02.840449.840449 lmp.py:220] -------------------------------- end layer 26 --------------------------------
DEBUG 01-06 17:11:02.840748.840748 lmp.py:176] -------------------------------- start layer 27 --------------------------------
DEBUG 01-06 17:11:02.840637.840637 cuda_h.py:10] start start_load_qkvogn_s_weight_l_28
DEBUG 01-06 17:11:02.840353.840353 cuda_h.py:19] end start_load_qkvogn_s_weight_l_28 cost 1.1920928955078125e-05 seconds
DEBUG 01-06 17:11:02.840334.840334 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-06 17:11:02.840806.840806 mlpmodule.py:367] cuda:1 cuda:1
DEBUG 01-06 17:11:02.840339.840339 cuda_h.py:10] start self_attn
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-06 17:11:02.843472.843472 cuda_h.py:19] end self_attn cost 0.002532482147216797 seconds
DEBUG 01-06 17:11:02.843919.843919 cuda_h.py:19] end iln_self_attn_paln cost 0.003210783004760742 seconds
DEBUG 01-06 17:11:02.843140.843140 cuda_h.py:10] start layer_moe_generate_27
DEBUG 01-06 17:11:02.843902.843902 cuda_h.py:10] start gate
DEBUG 01-06 17:11:02.844639.844639 cuda_h.py:19] end gate cost 0.0006151199340820312 seconds
DEBUG 01-06 17:11:02.844800.844800 cuda_h.py:10] start experts_map_get
DEBUG 01-06 17:11:02.844545.844545 lmp.py:403] 
DEBUG 01-06 17:11:02.844545.844545 lmp.py:403] Expert Token Distribution & Device Allocation:
DEBUG 01-06 17:11:02.844109.844109 lmp.py:404]   Total experts: 64
DEBUG 01-06 17:11:02.844236.844236 lmp.py:405]   CPU experts: 32 (50%)
DEBUG 01-06 17:11:02.844309.844309 lmp.py:406]   GPU experts: 32 (50%)
DEBUG 01-06 17:11:02.844429.844429 lmp.py:407] 
DEBUG 01-06 17:11:02.844429.844429 lmp.py:407]   Expert ID | Tokens | Device
DEBUG 01-06 17:11:02.844072.844072 lmp.py:408]   -----------------------------------
DEBUG 01-06 17:11:02.844437.844437 lmp.py:414]   Expert 18 |     64 | CPU
DEBUG 01-06 17:11:02.844603.844603 lmp.py:414]   Expert 54 |     69 | CPU
DEBUG 01-06 17:11:02.844054.844054 lmp.py:414]   Expert 47 |     70 | CPU
DEBUG 01-06 17:11:02.845267.845267 lmp.py:414]   Expert 44 |     73 | CPU
DEBUG 01-06 17:11:02.845241.845241 lmp.py:414]   Expert 23 |     77 | CPU
DEBUG 01-06 17:11:02.845453.845453 lmp.py:414]   Expert 48 |     79 | CPU
DEBUG 01-06 17:11:02.845427.845427 lmp.py:414]   Expert 45 |     82 | CPU
DEBUG 01-06 17:11:02.845163.845163 lmp.py:414]   Expert 20 |     90 | CPU
DEBUG 01-06 17:11:02.845898.845898 lmp.py:414]   Expert 31 |     96 | CPU
DEBUG 01-06 17:11:02.845634.845634 lmp.py:414]   Expert 36 |    103 | CPU
DEBUG 01-06 17:11:02.845608.845608 lmp.py:414]   Expert 61 |    110 | CPU
DEBUG 01-06 17:11:02.845582.845582 lmp.py:414]   Expert 10 |    121 | CPU
DEBUG 01-06 17:11:02.845033.845033 lmp.py:414]   Expert 24 |    121 | CPU
DEBUG 01-06 17:11:02.845961.845961 lmp.py:414]   Expert 11 |    122 | CPU
DEBUG 01-06 17:11:02.845412.845412 lmp.py:414]   Expert 42 |    122 | CPU
DEBUG 01-06 17:11:02.845147.845147 lmp.py:414]   Expert 33 |    124 | CPU
DEBUG 01-06 17:11:02.845598.845598 lmp.py:414]   Expert 43 |    127 | CPU
DEBUG 01-06 17:11:02.845049.845049 lmp.py:414]   Expert 56 |    129 | CPU
DEBUG 01-06 17:11:02.845261.845261 lmp.py:414]   Expert 49 |    130 | CPU
DEBUG 01-06 17:11:02.845712.845712 lmp.py:414]   Expert  6 |    138 | CPU
DEBUG 01-06 17:11:02.845163.845163 lmp.py:414]   Expert 17 |    138 | CPU
DEBUG 01-06 17:11:02.845329.845329 lmp.py:414]   Expert 51 |    148 | CPU
DEBUG 01-06 17:11:02.845780.845780 lmp.py:414]   Expert  0 |    149 | CPU
DEBUG 01-06 17:11:02.845993.845993 lmp.py:414]   Expert 12 |    154 | CPU
DEBUG 01-06 17:11:02.845159.845159 lmp.py:414]   Expert  5 |    156 | CPU
DEBUG 01-06 17:11:02.845848.845848 lmp.py:414]   Expert 13 |    157 | CPU
DEBUG 01-06 17:11:02.845537.845537 lmp.py:414]   Expert 40 |    157 | CPU
DEBUG 01-06 17:11:02.845988.845988 lmp.py:414]   Expert 55 |    158 | CPU
DEBUG 01-06 17:11:02.845201.845201 lmp.py:414]   Expert 26 |    163 | CPU
DEBUG 01-06 17:11:02.845175.845175 lmp.py:414]   Expert 59 |    163 | CPU
DEBUG 01-06 17:11:02.845910.845910 lmp.py:414]   Expert 38 |    167 | CPU
DEBUG 01-06 17:11:02.845884.845884 lmp.py:414]   Expert 57 |    167 | CPU
DEBUG 01-06 17:11:02.845858.845858 lmp.py:414]   Expert 46 |    172 | GPU
DEBUG 01-06 17:11:02.845356.845356 lmp.py:414]   Expert 58 |    173 | GPU
DEBUG 01-06 17:11:02.845330.845330 lmp.py:414]   Expert 35 |    174 | GPU
DEBUG 01-06 17:11:02.845827.845827 lmp.py:414]   Expert  7 |    177 | GPU
DEBUG 01-06 17:11:02.845278.845278 lmp.py:414]   Expert 16 |    181 | GPU
DEBUG 01-06 17:11:02.845252.845252 lmp.py:414]   Expert 30 |    182 | GPU
DEBUG 01-06 17:11:02.845941.845941 lmp.py:414]   Expert 50 |    187 | GPU
DEBUG 01-06 17:11:02.845392.845392 lmp.py:414]   Expert 14 |    199 | GPU
DEBUG 01-06 17:11:02.845366.845366 lmp.py:414]   Expert 32 |    202 | GPU
DEBUG 01-06 17:11:02.845102.845102 lmp.py:414]   Expert 15 |    203 | GPU
DEBUG 01-06 17:11:02.845837.845837 lmp.py:414]   Expert  1 |    214 | GPU
DEBUG 01-06 17:11:02.845573.845573 lmp.py:414]   Expert  3 |    216 | GPU
DEBUG 01-06 17:11:02.845547.845547 lmp.py:414]   Expert  4 |    222 | GPU
DEBUG 01-06 17:11:02.845044.845044 lmp.py:414]   Expert 39 |    229 | GPU
DEBUG 01-06 17:11:02.845780.845780 lmp.py:414]   Expert 52 |    243 | GPU
DEBUG 01-06 17:11:02.845515.845515 lmp.py:414]   Expert 28 |    246 | GPU
DEBUG 01-06 17:11:02.845251.845251 lmp.py:414]   Expert 34 |    246 | GPU
DEBUG 01-06 17:11:02.845179.845179 lmp.py:414]   Expert 25 |    249 | GPU
DEBUG 01-06 17:11:02.845391.845391 lmp.py:414]   Expert 22 |    258 | GPU
DEBUG 01-06 17:11:02.845842.845842 lmp.py:414]   Expert  2 |    272 | GPU
DEBUG 01-06 17:11:02.845055.845055 lmp.py:414]   Expert 21 |    273 | GPU
DEBUG 01-06 17:11:02.845744.845744 lmp.py:414]   Expert 41 |    276 | GPU
DEBUG 01-06 17:11:02.845480.845480 lmp.py:414]   Expert 29 |    288 | GPU
DEBUG 01-06 17:11:02.845977.845977 lmp.py:414]   Expert 60 |    291 | GPU
DEBUG 01-06 17:11:02.845712.845712 lmp.py:414]   Expert 63 |    291 | GPU
DEBUG 01-06 17:11:02.845686.845686 lmp.py:414]   Expert 62 |    295 | GPU
DEBUG 01-06 17:11:02.845184.845184 lmp.py:414]   Expert 27 |    305 | GPU
DEBUG 01-06 17:11:02.845158.845158 lmp.py:414]   Expert  8 |    333 | GPU
DEBUG 01-06 17:11:02.845893.845893 lmp.py:414]   Expert 53 |    334 | GPU
DEBUG 01-06 17:11:02.845867.845867 lmp.py:414]   Expert 37 |    343 | GPU
DEBUG 01-06 17:11:02.845557.845557 lmp.py:414]   Expert 19 |    439 | GPU
DEBUG 01-06 17:11:02.845769.845769 lmp.py:414]   Expert  9 |    651 | GPU
DEBUG 01-06 17:11:02.845174.845174 lmp.py:415] 
DEBUG 01-06 17:11:02.845174.845174 lmp.py:415]   CPU total tokens: 3924 (31.9%)
DEBUG 01-06 17:11:02.846055.846055 lmp.py:416]   GPU total tokens: 8364 (68.1%)
DEBUG 01-06 17:11:02.846990.846990 cuda_h.py:19] end experts_map_get cost 0.0014810562133789062 seconds
DEBUG 01-06 17:11:02.846156.846156 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-06 17:11:02.846661.846661 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 17:11:02.846613.846613 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 17:11:02.846354.846354 cuda_h.py:19] end allocate_cuda_memory cost 0.0003371238708496094 seconds
DEBUG 01-06 17:11:02.846011.846011 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 17:11:02.846529.846529 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 17:11:02.846298.846298 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 17:11:02.846856.846856 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 69f947d8-ae35-45ba-91f0-0718f988722a
DEBUG 01-06 17:11:02.846259.846259 client.py:106] call stub.LoadModelAsync
INFO 01-06 17:11:02.848226.848226 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 69f947d8-ae35-45ba-91f0-0718f988722a
DEBUG 01-06 17:11:02.848155.848155 cuda_h.py:19] end load_into_gpu_async cost 0.002287626266479492 seconds
DEBUG 01-06 17:11:02.849904.849904 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 17:11:02.849591.849591 cuda_h.py:19] end restore_tensors2 cost 0.0003066062927246094 seconds
DEBUG 01-06 17:11:02.849837.849837 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.003268003463745117 seconds
DEBUG 01-06 17:11:02.852204.852204 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.005978822708129883 seconds
DEBUG 01-06 17:11:02.852603.852603 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-06 17:11:02.852606.852606 lmp.py:461] 
DEBUG 01-06 17:11:02.852606.852606 lmp.py:461]   Computing 32 experts on CPU...
DEBUG 01-06 17:11:02.852310.852310 cuda_h.py:19] end cpu_experts_submit cost 0.00010824203491210938 seconds
DEBUG 01-06 17:11:02.852244.852244 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-06 17:11:02.859538.859538 mlpmodule.py:706] group tensors cost 0.007349967956542969 s
DEBUG 01-06 17:11:02.862744.862744 mlpmodule.py:744] pad cost 0.0018954277038574219 s
DEBUG 01-06 17:11:02.862868.862868 mlpmodule.py:750] create cpu tensor cost 5.8650970458984375e-05 s
DEBUG 01-06 17:11:02.862578.862578 mlpmodule.py:755] move to cpu cost 3.170967102050781e-05 s
DEBUG 01-06 17:11:02.873063.873063 mlpmodule.py:769] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-06 17:11:02.873204.873204 mlpmodule.py:770] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-06 17:11:02.873809.873809 mlpmodule.py:775] group_w3 first element: -0.006439208984375
WARNING 01-06 17:11:02.873455.873455 mlpmodule.py:785] start einsum2
DEBUG 01-06 17:11:02.890314.890314 mlpmodule.py:795] group einsum cost 0.02805948257446289 s
DEBUG 01-06 17:11:02.891592.891592 mlpmodule.py:803] cpy2cputensor cost 0.0006785392761230469 s
DEBUG 01-06 17:11:02.896187.896187 cuda_h.py:19] end wait_cetm_experts cost 0.04369473457336426 seconds
DEBUG 01-06 17:11:02.896491.896491 cuda_h.py:10] start gpu_sexperts
DEBUG 01-06 17:11:02.896501.896501 cuda_h.py:19] end gpu_sexperts cost 0.0006277561187744141 seconds
DEBUG 01-06 17:11:02.896735.896735 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-06 17:11:02.897995.897995 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 1.1444091796875e-05 seconds
DEBUG 01-06 17:11:02.897698.897698 cuda_h.py:10] start wait_experts
INFO 01-06 17:11:02.897792.897792 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 69f947d8-ae35-45ba-91f0-0718f988722a
INFO 01-06 17:11:02.901019.901019 client.py:127] Model loaded
DEBUG 01-06 17:11:02.901206.901206 cuda_h.py:19] end wait_experts cost 0.00487208366394043 seconds
DEBUG 01-06 17:11:02.901201.901201 cuda_h.py:10] start gpu_experts
DEBUG 01-06 17:11:02.902718.902718 lmp.py:506]   Computing 32 experts on GPU...
DEBUG 01-06 17:11:02.902962.902962 mlpmodule.py:664]  experts func einsum cost 0.050286293029785156 s
DEBUG 01-06 17:11:02.902303.902303 mlpmodule.py:533] gpu group tensors cost 0.0007500648498535156 s
DEBUG 01-06 17:11:02.904581.904581 mlpmodule.py:566] gpu pad cost 0.0017826557159423828 s
DEBUG 01-06 17:11:02.905954.905954 mlpmodule.py:584] gpu group einsum cost 0.0005865097045898438 s
DEBUG 01-06 17:11:02.908488.908488 mlpmodule.py:613] gpu experts func einsum cost 0.006482362747192383 s
DEBUG 01-06 17:11:02.908624.908624 cuda_h.py:19] end gpu_experts cost 0.006673574447631836 seconds
DEBUG 01-06 17:11:02.908070.908070 cuda_h.py:19] end layer_moe_generate_27 cost 0.06494617462158203 seconds
DEBUG 01-06 17:11:02.908838.908838 lmp.py:220] -------------------------------- end layer 27 --------------------------------
DEBUG 01-06 17:11:02.908177.908177 cuda_h.py:19] end multi_layer cost 2.5483381748199463 seconds
DEBUG 01-06 17:11:02.909873.909873 cuda_h.py:10] start decode_layer
DEBUG 01-06 17:11:02.920865.920865 cuda_h.py:10] start async_load_ce
INFO 01-06 17:11:02.920642.920642 cuda_memory_view.py:165] Collecting expert device distribution for all layers...
INFO 01-06 17:11:02.920634.920634 cuda_memory_view.py:189] Layer 1: CPU experts = [0, 1, 3, 10, 11, 13, 17, 18, 22, 25, 27, 28, 31, 32, 34, 35, 36, 37, 38, 41, 43, 44, 47, 49, 51, 52, 54, 55, 58, 59, 60, 62] (total: 32, device_map: {0: 'meta', 1: 'meta', 2: 'cuda:1', 3: 'meta', 4: 'cuda:1', 5: 'cuda:1', 6: 'cuda:1', 7: 'cuda:1', 8: 'cuda:1', 9: 'cuda:1', 10: 'meta', 11: 'meta', 12: 'cuda:1', 13: 'meta', 14: 'cuda:1', 15: 'cuda:1', 16: 'cuda:1', 17: 'meta', 18: 'meta', 19: 'cuda:1', 20: 'cuda:1', 21: 'cuda:1', 22: 'meta', 23: 'cuda:1', 24: 'cuda:1', 25: 'meta', 26: 'cuda:1', 27: 'meta', 28: 'meta', 29: 'cuda:1', 30: 'cuda:1', 31: 'meta', 32: 'meta', 33: 'cuda:1', 34: 'meta', 35: 'meta', 36: 'meta', 37: 'meta', 38: 'meta', 39: 'cuda:1', 40: 'cuda:1', 41: 'meta', 42: 'cuda:1', 43: 'meta', 44: 'meta', 45: 'cuda:1', 46: 'cuda:1', 47: 'meta', 48: 'cuda:1', 49: 'meta', 50: 'cuda:1', 51: 'meta', 52: 'meta', 53: 'cuda:1', 54: 'meta', 55: 'meta', 56: 'cuda:1', 57: 'cuda:1', 58: 'meta', 59: 'meta', 60: 'meta', 61: 'cuda:1', 62: 'meta', 63: 'cuda:1'})
INFO 01-06 17:11:02.921523.921523 cuda_memory_view.py:189] Layer 2: CPU experts = [0, 1, 3, 6, 7, 8, 9, 12, 15, 17, 23, 24, 25, 26, 27, 28, 29, 30, 32, 34, 35, 36, 37, 45, 48, 49, 51, 54, 57, 58, 60, 62] (total: 32, device_map: {0: 'meta', 1: 'meta', 2: 'cuda:1', 3: 'meta', 4: 'cuda:1', 5: 'cuda:1', 6: 'meta', 7: 'meta', 8: 'meta', 9: 'meta', 10: 'cuda:1', 11: 'cuda:1', 12: 'meta', 13: 'cuda:1', 14: 'cuda:1', 15: 'meta', 16: 'cuda:1', 17: 'meta', 18: 'cuda:1', 19: 'cuda:1', 20: 'cuda:1', 21: 'cuda:1', 22: 'cuda:1', 23: 'meta', 24: 'meta', 25: 'meta', 26: 'meta', 27: 'meta', 28: 'meta', 29: 'meta', 30: 'meta', 31: 'cuda:1', 32: 'meta', 33: 'cuda:1', 34: 'meta', 35: 'meta', 36: 'meta', 37: 'meta', 38: 'cuda:1', 39: 'cuda:1', 40: 'cuda:1', 41: 'cuda:1', 42: 'cuda:1', 43: 'cuda:1', 44: 'cuda:1', 45: 'meta', 46: 'cuda:1', 47: 'cuda:1', 48: 'meta', 49: 'meta', 50: 'cuda:1', 51: 'meta', 52: 'cuda:1', 53: 'cuda:1', 54: 'meta', 55: 'cuda:1', 56: 'cuda:1', 57: 'meta', 58: 'meta', 59: 'cuda:1', 60: 'meta', 61: 'cuda:1', 62: 'meta', 63: 'cuda:1'})
INFO 01-06 17:11:02.921320.921320 cuda_memory_view.py:189] Layer 3: CPU experts = [1, 2, 4, 5, 6, 7, 9, 11, 15, 16, 18, 23, 26, 27, 30, 32, 34, 35, 36, 37, 39, 40, 42, 45, 48, 49, 50, 51, 52, 56, 59, 61] (total: 32, device_map: {0: 'cuda:1', 1: 'meta', 2: 'meta', 3: 'cuda:1', 4: 'meta', 5: 'meta', 6: 'meta', 7: 'meta', 8: 'cuda:1', 9: 'meta', 10: 'cuda:1', 11: 'meta', 12: 'cuda:1', 13: 'cuda:1', 14: 'cuda:1', 15: 'meta', 16: 'meta', 17: 'cuda:1', 18: 'meta', 19: 'cuda:1', 20: 'cuda:1', 21: 'cuda:1', 22: 'cuda:1', 23: 'meta', 24: 'cuda:1', 25: 'cuda:1', 26: 'meta', 27: 'meta', 28: 'cuda:1', 29: 'cuda:1', 30: 'meta', 31: 'cuda:1', 32: 'meta', 33: 'cuda:1', 34: 'meta', 35: 'meta', 36: 'meta', 37: 'meta', 38: 'cuda:1', 39: 'meta', 40: 'meta', 41: 'cuda:1', 42: 'meta', 43: 'cuda:1', 44: 'cuda:1', 45: 'meta', 46: 'cuda:1', 47: 'cuda:1', 48: 'meta', 49: 'meta', 50: 'meta', 51: 'meta', 52: 'meta', 53: 'cuda:1', 54: 'cuda:1', 55: 'cuda:1', 56: 'meta', 57: 'cuda:1', 58: 'cuda:1', 59: 'meta', 60: 'cuda:1', 61: 'meta', 62: 'cuda:1', 63: 'cuda:1'})
INFO 01-06 17:11:02.922792.922792 cuda_memory_view.py:189] Layer 4: CPU experts = [4, 7, 8, 10, 11, 13, 14, 16, 17, 20, 26, 27, 28, 29, 30, 31, 32, 34, 36, 41, 42, 44, 45, 47, 51, 53, 54, 57, 58, 60, 61, 63] (total: 32, device_map: {0: 'cuda:1', 1: 'cuda:1', 2: 'cuda:1', 3: 'cuda:1', 4: 'meta', 5: 'cuda:1', 6: 'cuda:1', 7: 'meta', 8: 'meta', 9: 'cuda:1', 10: 'meta', 11: 'meta', 12: 'cuda:1', 13: 'meta', 14: 'meta', 15: 'cuda:1', 16: 'meta', 17: 'meta', 18: 'cuda:1', 19: 'cuda:1', 20: 'meta', 21: 'cuda:1', 22: 'cuda:1', 23: 'cuda:1', 24: 'cuda:1', 25: 'cuda:1', 26: 'meta', 27: 'meta', 28: 'meta', 29: 'meta', 30: 'meta', 31: 'meta', 32: 'meta', 33: 'cuda:1', 34: 'meta', 35: 'cuda:1', 36: 'meta', 37: 'cuda:1', 38: 'cuda:1', 39: 'cuda:1', 40: 'cuda:1', 41: 'meta', 42: 'meta', 43: 'cuda:1', 44: 'meta', 45: 'meta', 46: 'cuda:1', 47: 'meta', 48: 'cuda:1', 49: 'cuda:1', 50: 'cuda:1', 51: 'meta', 52: 'cuda:1', 53: 'meta', 54: 'meta', 55: 'cuda:1', 56: 'cuda:1', 57: 'meta', 58: 'meta', 59: 'cuda:1', 60: 'meta', 61: 'meta', 62: 'cuda:1', 63: 'meta'})
INFO 01-06 17:11:02.922191.922191 cuda_memory_view.py:189] Layer 5: CPU experts = [0, 2, 3, 4, 5, 8, 9, 12, 13, 14, 15, 16, 17, 22, 23, 25, 28, 30, 31, 32, 34, 35, 36, 39, 42, 44, 45, 46, 52, 57, 60, 61] (total: 32, device_map: {0: 'meta', 1: 'cuda:1', 2: 'meta', 3: 'meta', 4: 'meta', 5: 'meta', 6: 'cuda:1', 7: 'cuda:1', 8: 'meta', 9: 'meta', 10: 'cuda:1', 11: 'cuda:1', 12: 'meta', 13: 'meta', 14: 'meta', 15: 'meta', 16: 'meta', 17: 'meta', 18: 'cuda:1', 19: 'cuda:1', 20: 'cuda:1', 21: 'cuda:1', 22: 'meta', 23: 'meta', 24: 'cuda:1', 25: 'meta', 26: 'cuda:1', 27: 'cuda:1', 28: 'meta', 29: 'cuda:1', 30: 'meta', 31: 'meta', 32: 'meta', 33: 'cuda:1', 34: 'meta', 35: 'meta', 36: 'meta', 37: 'cuda:1', 38: 'cuda:1', 39: 'meta', 40: 'cuda:1', 41: 'cuda:1', 42: 'meta', 43: 'cuda:1', 44: 'meta', 45: 'meta', 46: 'meta', 47: 'cuda:1', 48: 'cuda:1', 49: 'cuda:1', 50: 'cuda:1', 51: 'cuda:1', 52: 'meta', 53: 'cuda:1', 54: 'cuda:1', 55: 'cuda:1', 56: 'cuda:1', 57: 'meta', 58: 'cuda:1', 59: 'cuda:1', 60: 'meta', 61: 'meta', 62: 'cuda:1', 63: 'cuda:1'})
INFO 01-06 17:11:02.922231.922231 cuda_memory_view.py:189] Layer 6: CPU experts = [0, 1, 2, 3, 7, 9, 10, 11, 13, 14, 16, 17, 18, 22, 23, 26, 28, 29, 32, 33, 37, 40, 43, 45, 51, 53, 54, 55, 58, 59, 62, 63] (total: 32, device_map: {0: 'meta', 1: 'meta', 2: 'meta', 3: 'meta', 4: 'cuda:1', 5: 'cuda:1', 6: 'cuda:1', 7: 'meta', 8: 'cuda:1', 9: 'meta', 10: 'meta', 11: 'meta', 12: 'cuda:1', 13: 'meta', 14: 'meta', 15: 'cuda:1', 16: 'meta', 17: 'meta', 18: 'meta', 19: 'cuda:1', 20: 'cuda:1', 21: 'cuda:1', 22: 'meta', 23: 'meta', 24: 'cuda:1', 25: 'cuda:1', 26: 'meta', 27: 'cuda:1', 28: 'meta', 29: 'meta', 30: 'cuda:1', 31: 'cuda:1', 32: 'meta', 33: 'meta', 34: 'cuda:1', 35: 'cuda:1', 36: 'cuda:1', 37: 'meta', 38: 'cuda:1', 39: 'cuda:1', 40: 'meta', 41: 'cuda:1', 42: 'cuda:1', 43: 'meta', 44: 'cuda:1', 45: 'meta', 46: 'cuda:1', 47: 'cuda:1', 48: 'cuda:1', 49: 'cuda:1', 50: 'cuda:1', 51: 'meta', 52: 'cuda:1', 53: 'meta', 54: 'meta', 55: 'meta', 56: 'cuda:1', 57: 'cuda:1', 58: 'meta', 59: 'meta', 60: 'cuda:1', 61: 'cuda:1', 62: 'meta', 63: 'meta'})
INFO 01-06 17:11:02.923669.923669 cuda_memory_view.py:189] Layer 7: CPU experts = [1, 3, 4, 5, 6, 7, 8, 10, 11, 13, 14, 15, 16, 18, 20, 27, 28, 29, 36, 39, 40, 41, 43, 46, 48, 50, 51, 52, 54, 55, 56, 60] (total: 32, device_map: {0: 'cuda:1', 1: 'meta', 2: 'cuda:1', 3: 'meta', 4: 'meta', 5: 'meta', 6: 'meta', 7: 'meta', 8: 'meta', 9: 'cuda:1', 10: 'meta', 11: 'meta', 12: 'cuda:1', 13: 'meta', 14: 'meta', 15: 'meta', 16: 'meta', 17: 'cuda:1', 18: 'meta', 19: 'cuda:1', 20: 'meta', 21: 'cuda:1', 22: 'cuda:1', 23: 'cuda:1', 24: 'cuda:1', 25: 'cuda:1', 26: 'cuda:1', 27: 'meta', 28: 'meta', 29: 'meta', 30: 'cuda:1', 31: 'cuda:1', 32: 'cuda:1', 33: 'cuda:1', 34: 'cuda:1', 35: 'cuda:1', 36: 'meta', 37: 'cuda:1', 38: 'cuda:1', 39: 'meta', 40: 'meta', 41: 'meta', 42: 'cuda:1', 43: 'meta', 44: 'cuda:1', 45: 'cuda:1', 46: 'meta', 47: 'cuda:1', 48: 'meta', 49: 'cuda:1', 50: 'meta', 51: 'meta', 52: 'meta', 53: 'cuda:1', 54: 'meta', 55: 'meta', 56: 'meta', 57: 'cuda:1', 58: 'cuda:1', 59: 'cuda:1', 60: 'meta', 61: 'cuda:1', 62: 'cuda:1', 63: 'cuda:1'})
INFO 01-06 17:11:02.923233.923233 cuda_memory_view.py:189] Layer 8: CPU experts = [0, 1, 6, 7, 8, 12, 14, 15, 16, 17, 18, 22, 24, 27, 29, 30, 32, 33, 34, 35, 36, 38, 39, 40, 42, 44, 48, 51, 53, 54, 59, 60] (total: 32, device_map: {0: 'meta', 1: 'meta', 2: 'cuda:1', 3: 'cuda:1', 4: 'cuda:1', 5: 'cuda:1', 6: 'meta', 7: 'meta', 8: 'meta', 9: 'cuda:1', 10: 'cuda:1', 11: 'cuda:1', 12: 'meta', 13: 'cuda:1', 14: 'meta', 15: 'meta', 16: 'meta', 17: 'meta', 18: 'meta', 19: 'cuda:1', 20: 'cuda:1', 21: 'cuda:1', 22: 'meta', 23: 'cuda:1', 24: 'meta', 25: 'cuda:1', 26: 'cuda:1', 27: 'meta', 28: 'cuda:1', 29: 'meta', 30: 'meta', 31: 'cuda:1', 32: 'meta', 33: 'meta', 34: 'meta', 35: 'meta', 36: 'meta', 37: 'cuda:1', 38: 'meta', 39: 'meta', 40: 'meta', 41: 'cuda:1', 42: 'meta', 43: 'cuda:1', 44: 'meta', 45: 'cuda:1', 46: 'cuda:1', 47: 'cuda:1', 48: 'meta', 49: 'cuda:1', 50: 'cuda:1', 51: 'meta', 52: 'cuda:1', 53: 'meta', 54: 'meta', 55: 'cuda:1', 56: 'cuda:1', 57: 'cuda:1', 58: 'cuda:1', 59: 'meta', 60: 'meta', 61: 'cuda:1', 62: 'cuda:1', 63: 'cuda:1'})
INFO 01-06 17:11:02.924319.924319 cuda_memory_view.py:189] Layer 9: CPU experts = [2, 3, 4, 5, 7, 10, 12, 13, 15, 16, 17, 19, 20, 22, 23, 24, 25, 26, 27, 28, 32, 35, 36, 37, 40, 41, 47, 49, 50, 53, 59, 60] (total: 32, device_map: {0: 'cuda:1', 1: 'cuda:1', 2: 'meta', 3: 'meta', 4: 'meta', 5: 'meta', 6: 'cuda:1', 7: 'meta', 8: 'cuda:1', 9: 'cuda:1', 10: 'meta', 11: 'cuda:1', 12: 'meta', 13: 'meta', 14: 'cuda:1', 15: 'meta', 16: 'meta', 17: 'meta', 18: 'cuda:1', 19: 'meta', 20: 'meta', 21: 'cuda:1', 22: 'meta', 23: 'meta', 24: 'meta', 25: 'meta', 26: 'meta', 27: 'meta', 28: 'meta', 29: 'cuda:1', 30: 'cuda:1', 31: 'cuda:1', 32: 'meta', 33: 'cuda:1', 34: 'cuda:1', 35: 'meta', 36: 'meta', 37: 'meta', 38: 'cuda:1', 39: 'cuda:1', 40: 'meta', 41: 'meta', 42: 'cuda:1', 43: 'cuda:1', 44: 'cuda:1', 45: 'cuda:1', 46: 'cuda:1', 47: 'meta', 48: 'cuda:1', 49: 'meta', 50: 'meta', 51: 'cuda:1', 52: 'cuda:1', 53: 'meta', 54: 'cuda:1', 55: 'cuda:1', 56: 'cuda:1', 57: 'cuda:1', 58: 'cuda:1', 59: 'meta', 60: 'meta', 61: 'cuda:1', 62: 'cuda:1', 63: 'cuda:1'})
INFO 01-06 17:11:02.924341.924341 cuda_memory_view.py:189] Layer 10: CPU experts = [2, 3, 4, 5, 6, 7, 12, 14, 15, 17, 18, 19, 22, 26, 27, 28, 34, 37, 38, 43, 45, 47, 48, 51, 52, 54, 55, 56, 57, 60, 61, 63] (total: 32, device_map: {0: 'cuda:1', 1: 'cuda:1', 2: 'meta', 3: 'meta', 4: 'meta', 5: 'meta', 6: 'meta', 7: 'meta', 8: 'cuda:1', 9: 'cuda:1', 10: 'cuda:1', 11: 'cuda:1', 12: 'meta', 13: 'cuda:1', 14: 'meta', 15: 'meta', 16: 'cuda:1', 17: 'meta', 18: 'meta', 19: 'meta', 20: 'cuda:1', 21: 'cuda:1', 22: 'meta', 23: 'cuda:1', 24: 'cuda:1', 25: 'cuda:1', 26: 'meta', 27: 'meta', 28: 'meta', 29: 'cuda:1', 30: 'cuda:1', 31: 'cuda:1', 32: 'cuda:1', 33: 'cuda:1', 34: 'meta', 35: 'cuda:1', 36: 'cuda:1', 37: 'meta', 38: 'meta', 39: 'cuda:1', 40: 'cuda:1', 41: 'cuda:1', 42: 'cuda:1', 43: 'meta', 44: 'cuda:1', 45: 'meta', 46: 'cuda:1', 47: 'meta', 48: 'meta', 49: 'cuda:1', 50: 'cuda:1', 51: 'meta', 52: 'meta', 53: 'cuda:1', 54: 'meta', 55: 'meta', 56: 'meta', 57: 'meta', 58: 'cuda:1', 59: 'cuda:1', 60: 'meta', 61: 'meta', 62: 'cuda:1', 63: 'meta'})
INFO 01-06 17:11:02.924110.924110 cuda_memory_view.py:189] Layer 11: CPU experts = [2, 3, 6, 9, 13, 15, 16, 17, 18, 19, 20, 23, 26, 31, 32, 33, 35, 36, 38, 39, 40, 41, 42, 43, 44, 46, 49, 50, 59, 61, 62, 63] (total: 32, device_map: {0: 'cuda:1', 1: 'cuda:1', 2: 'meta', 3: 'meta', 4: 'cuda:1', 5: 'cuda:1', 6: 'meta', 7: 'cuda:1', 8: 'cuda:1', 9: 'meta', 10: 'cuda:1', 11: 'cuda:1', 12: 'cuda:1', 13: 'meta', 14: 'cuda:1', 15: 'meta', 16: 'meta', 17: 'meta', 18: 'meta', 19: 'meta', 20: 'meta', 21: 'cuda:1', 22: 'cuda:1', 23: 'meta', 24: 'cuda:1', 25: 'cuda:1', 26: 'meta', 27: 'cuda:1', 28: 'cuda:1', 29: 'cuda:1', 30: 'cuda:1', 31: 'meta', 32: 'meta', 33: 'meta', 34: 'cuda:1', 35: 'meta', 36: 'meta', 37: 'cuda:1', 38: 'meta', 39: 'meta', 40: 'meta', 41: 'meta', 42: 'meta', 43: 'meta', 44: 'meta', 45: 'cuda:1', 46: 'meta', 47: 'cuda:1', 48: 'cuda:1', 49: 'meta', 50: 'meta', 51: 'cuda:1', 52: 'cuda:1', 53: 'cuda:1', 54: 'cuda:1', 55: 'cuda:1', 56: 'cuda:1', 57: 'cuda:1', 58: 'cuda:1', 59: 'meta', 60: 'cuda:1', 61: 'meta', 62: 'meta', 63: 'meta'})
INFO 01-06 17:11:02.925389.925389 cuda_memory_view.py:189] Layer 12: CPU experts = [0, 2, 4, 8, 11, 12, 13, 14, 16, 17, 18, 20, 21, 22, 23, 27, 30, 32, 34, 37, 38, 39, 43, 44, 45, 47, 52, 53, 57, 60, 61, 63] (total: 32, device_map: {0: 'meta', 1: 'cuda:1', 2: 'meta', 3: 'cuda:1', 4: 'meta', 5: 'cuda:1', 6: 'cuda:1', 7: 'cuda:1', 8: 'meta', 9: 'cuda:1', 10: 'cuda:1', 11: 'meta', 12: 'meta', 13: 'meta', 14: 'meta', 15: 'cuda:1', 16: 'meta', 17: 'meta', 18: 'meta', 19: 'cuda:1', 20: 'meta', 21: 'meta', 22: 'meta', 23: 'meta', 24: 'cuda:1', 25: 'cuda:1', 26: 'cuda:1', 27: 'meta', 28: 'cuda:1', 29: 'cuda:1', 30: 'meta', 31: 'cuda:1', 32: 'meta', 33: 'cuda:1', 34: 'meta', 35: 'cuda:1', 36: 'cuda:1', 37: 'meta', 38: 'meta', 39: 'meta', 40: 'cuda:1', 41: 'cuda:1', 42: 'cuda:1', 43: 'meta', 44: 'meta', 45: 'meta', 46: 'cuda:1', 47: 'meta', 48: 'cuda:1', 49: 'cuda:1', 50: 'cuda:1', 51: 'cuda:1', 52: 'meta', 53: 'meta', 54: 'cuda:1', 55: 'cuda:1', 56: 'cuda:1', 57: 'meta', 58: 'cuda:1', 59: 'cuda:1', 60: 'meta', 61: 'meta', 62: 'cuda:1', 63: 'meta'})
INFO 01-06 17:11:02.925715.925715 cuda_memory_view.py:189] Layer 13: CPU experts = [1, 2, 4, 5, 6, 9, 10, 11, 12, 13, 18, 19, 20, 26, 30, 31, 32, 33, 34, 35, 40, 42, 46, 48, 50, 53, 55, 56, 58, 59, 61, 63] (total: 32, device_map: {0: 'cuda:1', 1: 'meta', 2: 'meta', 3: 'cuda:1', 4: 'meta', 5: 'meta', 6: 'meta', 7: 'cuda:1', 8: 'cuda:1', 9: 'meta', 10: 'meta', 11: 'meta', 12: 'meta', 13: 'meta', 14: 'cuda:1', 15: 'cuda:1', 16: 'cuda:1', 17: 'cuda:1', 18: 'meta', 19: 'meta', 20: 'meta', 21: 'cuda:1', 22: 'cuda:1', 23: 'cuda:1', 24: 'cuda:1', 25: 'cuda:1', 26: 'meta', 27: 'cuda:1', 28: 'cuda:1', 29: 'cuda:1', 30: 'meta', 31: 'meta', 32: 'meta', 33: 'meta', 34: 'meta', 35: 'meta', 36: 'cuda:1', 37: 'cuda:1', 38: 'cuda:1', 39: 'cuda:1', 40: 'meta', 41: 'cuda:1', 42: 'meta', 43: 'cuda:1', 44: 'cuda:1', 45: 'cuda:1', 46: 'meta', 47: 'cuda:1', 48: 'meta', 49: 'cuda:1', 50: 'meta', 51: 'cuda:1', 52: 'cuda:1', 53: 'meta', 54: 'cuda:1', 55: 'meta', 56: 'meta', 57: 'cuda:1', 58: 'meta', 59: 'meta', 60: 'cuda:1', 61: 'meta', 62: 'cuda:1', 63: 'meta'})
INFO 01-06 17:11:02.926551.926551 cuda_memory_view.py:189] Layer 14: CPU experts = [0, 7, 8, 12, 13, 15, 16, 17, 18, 19, 21, 22, 27, 29, 31, 34, 35, 36, 38, 39, 40, 41, 45, 48, 49, 50, 52, 53, 54, 59, 60, 61] (total: 32, device_map: {0: 'meta', 1: 'cuda:1', 2: 'cuda:1', 3: 'cuda:1', 4: 'cuda:1', 5: 'cuda:1', 6: 'cuda:1', 7: 'meta', 8: 'meta', 9: 'cuda:1', 10: 'cuda:1', 11: 'cuda:1', 12: 'meta', 13: 'meta', 14: 'cuda:1', 15: 'meta', 16: 'meta', 17: 'meta', 18: 'meta', 19: 'meta', 20: 'cuda:1', 21: 'meta', 22: 'meta', 23: 'cuda:1', 24: 'cuda:1', 25: 'cuda:1', 26: 'cuda:1', 27: 'meta', 28: 'cuda:1', 29: 'meta', 30: 'cuda:1', 31: 'meta', 32: 'cuda:1', 33: 'cuda:1', 34: 'meta', 35: 'meta', 36: 'meta', 37: 'cuda:1', 38: 'meta', 39: 'meta', 40: 'meta', 41: 'meta', 42: 'cuda:1', 43: 'cuda:1', 44: 'cuda:1', 45: 'meta', 46: 'cuda:1', 47: 'cuda:1', 48: 'meta', 49: 'meta', 50: 'meta', 51: 'cuda:1', 52: 'meta', 53: 'meta', 54: 'meta', 55: 'cuda:1', 56: 'cuda:1', 57: 'cuda:1', 58: 'cuda:1', 59: 'meta', 60: 'meta', 61: 'meta', 62: 'cuda:1', 63: 'cuda:1'})
INFO 01-06 17:11:02.926433.926433 cuda_memory_view.py:189] Layer 15: CPU experts = [0, 2, 4, 5, 7, 10, 12, 13, 14, 15, 19, 20, 21, 22, 25, 28, 32, 34, 40, 41, 42, 45, 50, 51, 52, 53, 54, 55, 59, 61, 62, 63] (total: 32, device_map: {0: 'meta', 1: 'cuda:1', 2: 'meta', 3: 'cuda:1', 4: 'meta', 5: 'meta', 6: 'cuda:1', 7: 'meta', 8: 'cuda:1', 9: 'cuda:1', 10: 'meta', 11: 'cuda:1', 12: 'meta', 13: 'meta', 14: 'meta', 15: 'meta', 16: 'cuda:1', 17: 'cuda:1', 18: 'cuda:1', 19: 'meta', 20: 'meta', 21: 'meta', 22: 'meta', 23: 'cuda:1', 24: 'cuda:1', 25: 'meta', 26: 'cuda:1', 27: 'cuda:1', 28: 'meta', 29: 'cuda:1', 30: 'cuda:1', 31: 'cuda:1', 32: 'meta', 33: 'cuda:1', 34: 'meta', 35: 'cuda:1', 36: 'cuda:1', 37: 'cuda:1', 38: 'cuda:1', 39: 'cuda:1', 40: 'meta', 41: 'meta', 42: 'meta', 43: 'cuda:1', 44: 'cuda:1', 45: 'meta', 46: 'cuda:1', 47: 'cuda:1', 48: 'cuda:1', 49: 'cuda:1', 50: 'meta', 51: 'meta', 52: 'meta', 53: 'meta', 54: 'meta', 55: 'meta', 56: 'cuda:1', 57: 'cuda:1', 58: 'cuda:1', 59: 'meta', 60: 'cuda:1', 61: 'meta', 62: 'meta', 63: 'meta'})
INFO 01-06 17:11:02.927752.927752 cuda_memory_view.py:189] Layer 16: CPU experts = [0, 2, 4, 7, 9, 10, 11, 13, 14, 24, 25, 26, 27, 28, 31, 33, 34, 38, 41, 43, 45, 47, 48, 49, 50, 51, 54, 55, 56, 57, 58, 61] (total: 32, device_map: {0: 'meta', 1: 'cuda:1', 2: 'meta', 3: 'cuda:1', 4: 'meta', 5: 'cuda:1', 6: 'cuda:1', 7: 'meta', 8: 'cuda:1', 9: 'meta', 10: 'meta', 11: 'meta', 12: 'cuda:1', 13: 'meta', 14: 'meta', 15: 'cuda:1', 16: 'cuda:1', 17: 'cuda:1', 18: 'cuda:1', 19: 'cuda:1', 20: 'cuda:1', 21: 'cuda:1', 22: 'cuda:1', 23: 'cuda:1', 24: 'meta', 25: 'meta', 26: 'meta', 27: 'meta', 28: 'meta', 29: 'cuda:1', 30: 'cuda:1', 31: 'meta', 32: 'cuda:1', 33: 'meta', 34: 'meta', 35: 'cuda:1', 36: 'cuda:1', 37: 'cuda:1', 38: 'meta', 39: 'cuda:1', 40: 'cuda:1', 41: 'meta', 42: 'cuda:1', 43: 'meta', 44: 'cuda:1', 45: 'meta', 46: 'cuda:1', 47: 'meta', 48: 'meta', 49: 'meta', 50: 'meta', 51: 'meta', 52: 'cuda:1', 53: 'cuda:1', 54: 'meta', 55: 'meta', 56: 'meta', 57: 'meta', 58: 'meta', 59: 'cuda:1', 60: 'cuda:1', 61: 'meta', 62: 'cuda:1', 63: 'cuda:1'})
INFO 01-06 17:11:02.927428.927428 cuda_memory_view.py:189] Layer 17: CPU experts = [2, 3, 4, 6, 7, 8, 10, 12, 14, 15, 24, 25, 27, 28, 30, 31, 33, 36, 38, 39, 40, 43, 47, 49, 50, 52, 53, 57, 58, 59, 60, 61] (total: 32, device_map: {0: 'cuda:1', 1: 'cuda:1', 2: 'meta', 3: 'meta', 4: 'meta', 5: 'cuda:1', 6: 'meta', 7: 'meta', 8: 'meta', 9: 'cuda:1', 10: 'meta', 11: 'cuda:1', 12: 'meta', 13: 'cuda:1', 14: 'meta', 15: 'meta', 16: 'cuda:1', 17: 'cuda:1', 18: 'cuda:1', 19: 'cuda:1', 20: 'cuda:1', 21: 'cuda:1', 22: 'cuda:1', 23: 'cuda:1', 24: 'meta', 25: 'meta', 26: 'cuda:1', 27: 'meta', 28: 'meta', 29: 'cuda:1', 30: 'meta', 31: 'meta', 32: 'cuda:1', 33: 'meta', 34: 'cuda:1', 35: 'cuda:1', 36: 'meta', 37: 'cuda:1', 38: 'meta', 39: 'meta', 40: 'meta', 41: 'cuda:1', 42: 'cuda:1', 43: 'meta', 44: 'cuda:1', 45: 'cuda:1', 46: 'cuda:1', 47: 'meta', 48: 'cuda:1', 49: 'meta', 50: 'meta', 51: 'cuda:1', 52: 'meta', 53: 'meta', 54: 'cuda:1', 55: 'cuda:1', 56: 'cuda:1', 57: 'meta', 58: 'meta', 59: 'meta', 60: 'meta', 61: 'meta', 62: 'cuda:1', 63: 'cuda:1'})
INFO 01-06 17:11:02.927157.927157 cuda_memory_view.py:189] Layer 18: CPU experts = [0, 3, 5, 6, 8, 9, 12, 17, 19, 21, 25, 27, 28, 29, 30, 32, 35, 36, 37, 39, 40, 41, 46, 48, 52, 53, 54, 56, 58, 59, 60, 63] (total: 32, device_map: {0: 'meta', 1: 'cuda:1', 2: 'cuda:1', 3: 'meta', 4: 'cuda:1', 5: 'meta', 6: 'meta', 7: 'cuda:1', 8: 'meta', 9: 'meta', 10: 'cuda:1', 11: 'cuda:1', 12: 'meta', 13: 'cuda:1', 14: 'cuda:1', 15: 'cuda:1', 16: 'cuda:1', 17: 'meta', 18: 'cuda:1', 19: 'meta', 20: 'cuda:1', 21: 'meta', 22: 'cuda:1', 23: 'cuda:1', 24: 'cuda:1', 25: 'meta', 26: 'cuda:1', 27: 'meta', 28: 'meta', 29: 'meta', 30: 'meta', 31: 'cuda:1', 32: 'meta', 33: 'cuda:1', 34: 'cuda:1', 35: 'meta', 36: 'meta', 37: 'meta', 38: 'cuda:1', 39: 'meta', 40: 'meta', 41: 'meta', 42: 'cuda:1', 43: 'cuda:1', 44: 'cuda:1', 45: 'cuda:1', 46: 'meta', 47: 'cuda:1', 48: 'meta', 49: 'cuda:1', 50: 'cuda:1', 51: 'cuda:1', 52: 'meta', 53: 'meta', 54: 'meta', 55: 'cuda:1', 56: 'meta', 57: 'cuda:1', 58: 'meta', 59: 'meta', 60: 'meta', 61: 'cuda:1', 62: 'cuda:1', 63: 'meta'})
INFO 01-06 17:11:02.928124.928124 cuda_memory_view.py:189] Layer 19: CPU experts = [0, 1, 2, 5, 6, 8, 12, 13, 15, 16, 22, 24, 26, 27, 28, 30, 32, 34, 41, 42, 44, 47, 48, 50, 52, 55, 56, 57, 58, 59, 60, 62] (total: 32, device_map: {0: 'meta', 1: 'meta', 2: 'meta', 3: 'cuda:1', 4: 'cuda:1', 5: 'meta', 6: 'meta', 7: 'cuda:1', 8: 'meta', 9: 'cuda:1', 10: 'cuda:1', 11: 'cuda:1', 12: 'meta', 13: 'meta', 14: 'cuda:1', 15: 'meta', 16: 'meta', 17: 'cuda:1', 18: 'cuda:1', 19: 'cuda:1', 20: 'cuda:1', 21: 'cuda:1', 22: 'meta', 23: 'cuda:1', 24: 'meta', 25: 'cuda:1', 26: 'meta', 27: 'meta', 28: 'meta', 29: 'cuda:1', 30: 'meta', 31: 'cuda:1', 32: 'meta', 33: 'cuda:1', 34: 'meta', 35: 'cuda:1', 36: 'cuda:1', 37: 'cuda:1', 38: 'cuda:1', 39: 'cuda:1', 40: 'cuda:1', 41: 'meta', 42: 'meta', 43: 'cuda:1', 44: 'meta', 45: 'cuda:1', 46: 'cuda:1', 47: 'meta', 48: 'meta', 49: 'cuda:1', 50: 'meta', 51: 'cuda:1', 52: 'meta', 53: 'cuda:1', 54: 'cuda:1', 55: 'meta', 56: 'meta', 57: 'meta', 58: 'meta', 59: 'meta', 60: 'meta', 61: 'cuda:1', 62: 'meta', 63: 'cuda:1'})
INFO 01-06 17:11:02.928224.928224 cuda_memory_view.py:189] Layer 20: CPU experts = [2, 3, 6, 8, 12, 13, 19, 20, 21, 22, 23, 24, 28, 33, 36, 37, 38, 39, 40, 41, 42, 43, 46, 47, 49, 50, 52, 53, 54, 55, 57, 63] (total: 32, device_map: {0: 'cuda:1', 1: 'cuda:1', 2: 'meta', 3: 'meta', 4: 'cuda:1', 5: 'cuda:1', 6: 'meta', 7: 'cuda:1', 8: 'meta', 9: 'cuda:1', 10: 'cuda:1', 11: 'cuda:1', 12: 'meta', 13: 'meta', 14: 'cuda:1', 15: 'cuda:1', 16: 'cuda:1', 17: 'cuda:1', 18: 'cuda:1', 19: 'meta', 20: 'meta', 21: 'meta', 22: 'meta', 23: 'meta', 24: 'meta', 25: 'cuda:1', 26: 'cuda:1', 27: 'cuda:1', 28: 'meta', 29: 'cuda:1', 30: 'cuda:1', 31: 'cuda:1', 32: 'cuda:1', 33: 'meta', 34: 'cuda:1', 35: 'cuda:1', 36: 'meta', 37: 'meta', 38: 'meta', 39: 'meta', 40: 'meta', 41: 'meta', 42: 'meta', 43: 'meta', 44: 'cuda:1', 45: 'cuda:1', 46: 'meta', 47: 'meta', 48: 'cuda:1', 49: 'meta', 50: 'meta', 51: 'cuda:1', 52: 'meta', 53: 'meta', 54: 'meta', 55: 'meta', 56: 'cuda:1', 57: 'meta', 58: 'cuda:1', 59: 'cuda:1', 60: 'cuda:1', 61: 'cuda:1', 62: 'cuda:1', 63: 'meta'})
INFO 01-06 17:11:02.929999.929999 cuda_memory_view.py:189] Layer 21: CPU experts = [1, 2, 4, 6, 7, 8, 9, 11, 14, 22, 23, 24, 26, 27, 32, 34, 35, 38, 39, 41, 44, 47, 48, 50, 51, 52, 53, 54, 56, 59, 60, 62] (total: 32, device_map: {0: 'cuda:1', 1: 'meta', 2: 'meta', 3: 'cuda:1', 4: 'meta', 5: 'cuda:1', 6: 'meta', 7: 'meta', 8: 'meta', 9: 'meta', 10: 'cuda:1', 11: 'meta', 12: 'cuda:1', 13: 'cuda:1', 14: 'meta', 15: 'cuda:1', 16: 'cuda:1', 17: 'cuda:1', 18: 'cuda:1', 19: 'cuda:1', 20: 'cuda:1', 21: 'cuda:1', 22: 'meta', 23: 'meta', 24: 'meta', 25: 'cuda:1', 26: 'meta', 27: 'meta', 28: 'cuda:1', 29: 'cuda:1', 30: 'cuda:1', 31: 'cuda:1', 32: 'meta', 33: 'cuda:1', 34: 'meta', 35: 'meta', 36: 'cuda:1', 37: 'cuda:1', 38: 'meta', 39: 'meta', 40: 'cuda:1', 41: 'meta', 42: 'cuda:1', 43: 'cuda:1', 44: 'meta', 45: 'cuda:1', 46: 'cuda:1', 47: 'meta', 48: 'meta', 49: 'cuda:1', 50: 'meta', 51: 'meta', 52: 'meta', 53: 'meta', 54: 'meta', 55: 'cuda:1', 56: 'meta', 57: 'cuda:1', 58: 'cuda:1', 59: 'meta', 60: 'meta', 61: 'cuda:1', 62: 'meta', 63: 'cuda:1'})
INFO 01-06 17:11:02.929158.929158 cuda_memory_view.py:189] Layer 22: CPU experts = [0, 1, 2, 6, 7, 9, 10, 11, 13, 14, 15, 20, 21, 24, 25, 28, 36, 37, 38, 42, 43, 44, 45, 46, 47, 48, 50, 52, 54, 57, 61, 62] (total: 32, device_map: {0: 'meta', 1: 'meta', 2: 'meta', 3: 'cuda:1', 4: 'cuda:1', 5: 'cuda:1', 6: 'meta', 7: 'meta', 8: 'cuda:1', 9: 'meta', 10: 'meta', 11: 'meta', 12: 'cuda:1', 13: 'meta', 14: 'meta', 15: 'meta', 16: 'cuda:1', 17: 'cuda:1', 18: 'cuda:1', 19: 'cuda:1', 20: 'meta', 21: 'meta', 22: 'cuda:1', 23: 'cuda:1', 24: 'meta', 25: 'meta', 26: 'cuda:1', 27: 'cuda:1', 28: 'meta', 29: 'cuda:1', 30: 'cuda:1', 31: 'cuda:1', 32: 'cuda:1', 33: 'cuda:1', 34: 'cuda:1', 35: 'cuda:1', 36: 'meta', 37: 'meta', 38: 'meta', 39: 'cuda:1', 40: 'cuda:1', 41: 'cuda:1', 42: 'meta', 43: 'meta', 44: 'meta', 45: 'meta', 46: 'meta', 47: 'meta', 48: 'meta', 49: 'cuda:1', 50: 'meta', 51: 'cuda:1', 52: 'meta', 53: 'cuda:1', 54: 'meta', 55: 'cuda:1', 56: 'cuda:1', 57: 'meta', 58: 'cuda:1', 59: 'cuda:1', 60: 'cuda:1', 61: 'meta', 62: 'meta', 63: 'cuda:1'})
INFO 01-06 17:11:02.930802.930802 cuda_memory_view.py:189] Layer 23: CPU experts = [1, 4, 5, 6, 7, 11, 14, 16, 17, 21, 23, 25, 27, 28, 33, 37, 38, 39, 40, 44, 45, 47, 49, 51, 52, 53, 56, 57, 58, 60, 62, 63] (total: 32, device_map: {0: 'cuda:1', 1: 'meta', 2: 'cuda:1', 3: 'cuda:1', 4: 'meta', 5: 'meta', 6: 'meta', 7: 'meta', 8: 'cuda:1', 9: 'cuda:1', 10: 'cuda:1', 11: 'meta', 12: 'cuda:1', 13: 'cuda:1', 14: 'meta', 15: 'cuda:1', 16: 'meta', 17: 'meta', 18: 'cuda:1', 19: 'cuda:1', 20: 'cuda:1', 21: 'meta', 22: 'cuda:1', 23: 'meta', 24: 'cuda:1', 25: 'meta', 26: 'cuda:1', 27: 'meta', 28: 'meta', 29: 'cuda:1', 30: 'cuda:1', 31: 'cuda:1', 32: 'cuda:1', 33: 'meta', 34: 'cuda:1', 35: 'cuda:1', 36: 'cuda:1', 37: 'meta', 38: 'meta', 39: 'meta', 40: 'meta', 41: 'cuda:1', 42: 'cuda:1', 43: 'cuda:1', 44: 'meta', 45: 'meta', 46: 'cuda:1', 47: 'meta', 48: 'cuda:1', 49: 'meta', 50: 'cuda:1', 51: 'meta', 52: 'meta', 53: 'meta', 54: 'cuda:1', 55: 'cuda:1', 56: 'meta', 57: 'meta', 58: 'meta', 59: 'cuda:1', 60: 'meta', 61: 'cuda:1', 62: 'meta', 63: 'meta'})
INFO 01-06 17:11:02.930431.930431 cuda_memory_view.py:189] Layer 24: CPU experts = [0, 2, 4, 6, 7, 9, 13, 15, 16, 20, 24, 25, 29, 30, 33, 35, 36, 38, 39, 42, 43, 44, 45, 46, 47, 48, 51, 54, 55, 56, 59, 61] (total: 32, device_map: {0: 'meta', 1: 'cuda:1', 2: 'meta', 3: 'cuda:1', 4: 'meta', 5: 'cuda:1', 6: 'meta', 7: 'meta', 8: 'cuda:1', 9: 'meta', 10: 'cuda:1', 11: 'cuda:1', 12: 'cuda:1', 13: 'meta', 14: 'cuda:1', 15: 'meta', 16: 'meta', 17: 'cuda:1', 18: 'cuda:1', 19: 'cuda:1', 20: 'meta', 21: 'cuda:1', 22: 'cuda:1', 23: 'cuda:1', 24: 'meta', 25: 'meta', 26: 'cuda:1', 27: 'cuda:1', 28: 'cuda:1', 29: 'meta', 30: 'meta', 31: 'cuda:1', 32: 'cuda:1', 33: 'meta', 34: 'cuda:1', 35: 'meta', 36: 'meta', 37: 'cuda:1', 38: 'meta', 39: 'meta', 40: 'cuda:1', 41: 'cuda:1', 42: 'meta', 43: 'meta', 44: 'meta', 45: 'meta', 46: 'meta', 47: 'meta', 48: 'meta', 49: 'cuda:1', 50: 'cuda:1', 51: 'meta', 52: 'cuda:1', 53: 'cuda:1', 54: 'meta', 55: 'meta', 56: 'meta', 57: 'cuda:1', 58: 'cuda:1', 59: 'meta', 60: 'cuda:1', 61: 'meta', 62: 'cuda:1', 63: 'cuda:1'})
INFO 01-06 17:11:02.930491.930491 cuda_memory_view.py:189] Layer 25: CPU experts = [0, 2, 3, 5, 6, 8, 9, 10, 13, 16, 18, 21, 22, 23, 24, 25, 26, 31, 33, 36, 38, 41, 42, 43, 44, 45, 46, 48, 51, 55, 59, 61] (total: 32, device_map: {0: 'meta', 1: 'cuda:1', 2: 'meta', 3: 'meta', 4: 'cuda:1', 5: 'meta', 6: 'meta', 7: 'cuda:1', 8: 'meta', 9: 'meta', 10: 'meta', 11: 'cuda:1', 12: 'cuda:1', 13: 'meta', 14: 'cuda:1', 15: 'cuda:1', 16: 'meta', 17: 'cuda:1', 18: 'meta', 19: 'cuda:1', 20: 'cuda:1', 21: 'meta', 22: 'meta', 23: 'meta', 24: 'meta', 25: 'meta', 26: 'meta', 27: 'cuda:1', 28: 'cuda:1', 29: 'cuda:1', 30: 'cuda:1', 31: 'meta', 32: 'cuda:1', 33: 'meta', 34: 'cuda:1', 35: 'cuda:1', 36: 'meta', 37: 'cuda:1', 38: 'meta', 39: 'cuda:1', 40: 'cuda:1', 41: 'meta', 42: 'meta', 43: 'meta', 44: 'meta', 45: 'meta', 46: 'meta', 47: 'cuda:1', 48: 'meta', 49: 'cuda:1', 50: 'cuda:1', 51: 'meta', 52: 'cuda:1', 53: 'cuda:1', 54: 'cuda:1', 55: 'meta', 56: 'cuda:1', 57: 'cuda:1', 58: 'cuda:1', 59: 'meta', 60: 'cuda:1', 61: 'meta', 62: 'cuda:1', 63: 'cuda:1'})
INFO 01-06 17:11:02.931451.931451 cuda_memory_view.py:189] Layer 26: CPU experts = [3, 4, 6, 7, 8, 9, 11, 15, 17, 19, 20, 22, 23, 24, 29, 30, 34, 36, 37, 38, 39, 41, 42, 48, 49, 50, 51, 55, 59, 61, 62, 63] (total: 32, device_map: {0: 'cuda:1', 1: 'cuda:1', 2: 'cuda:1', 3: 'meta', 4: 'meta', 5: 'cuda:1', 6: 'meta', 7: 'meta', 8: 'meta', 9: 'meta', 10: 'cuda:1', 11: 'meta', 12: 'cuda:1', 13: 'cuda:1', 14: 'cuda:1', 15: 'meta', 16: 'cuda:1', 17: 'meta', 18: 'cuda:1', 19: 'meta', 20: 'meta', 21: 'cuda:1', 22: 'meta', 23: 'meta', 24: 'meta', 25: 'cuda:1', 26: 'cuda:1', 27: 'cuda:1', 28: 'cuda:1', 29: 'meta', 30: 'meta', 31: 'cuda:1', 32: 'cuda:1', 33: 'cuda:1', 34: 'meta', 35: 'cuda:1', 36: 'meta', 37: 'meta', 38: 'meta', 39: 'meta', 40: 'cuda:1', 41: 'meta', 42: 'meta', 43: 'cuda:1', 44: 'cuda:1', 45: 'cuda:1', 46: 'cuda:1', 47: 'cuda:1', 48: 'meta', 49: 'meta', 50: 'meta', 51: 'meta', 52: 'cuda:1', 53: 'cuda:1', 54: 'cuda:1', 55: 'meta', 56: 'cuda:1', 57: 'cuda:1', 58: 'cuda:1', 59: 'meta', 60: 'cuda:1', 61: 'meta', 62: 'meta', 63: 'meta'})
INFO 01-06 17:11:02.931622.931622 cuda_memory_view.py:189] Layer 27: CPU experts = [0, 5, 6, 10, 11, 12, 13, 17, 18, 20, 23, 24, 26, 31, 33, 36, 38, 40, 42, 43, 44, 45, 47, 48, 49, 51, 54, 55, 56, 57, 59, 61] (total: 32, device_map: {0: 'meta', 1: 'cuda:1', 2: 'cuda:1', 3: 'cuda:1', 4: 'cuda:1', 5: 'meta', 6: 'meta', 7: 'cuda:1', 8: 'cuda:1', 9: 'cuda:1', 10: 'meta', 11: 'meta', 12: 'meta', 13: 'meta', 14: 'cuda:1', 15: 'cuda:1', 16: 'cuda:1', 17: 'meta', 18: 'meta', 19: 'cuda:1', 20: 'meta', 21: 'cuda:1', 22: 'cuda:1', 23: 'meta', 24: 'meta', 25: 'cuda:1', 26: 'meta', 27: 'cuda:1', 28: 'cuda:1', 29: 'cuda:1', 30: 'cuda:1', 31: 'meta', 32: 'cuda:1', 33: 'meta', 34: 'cuda:1', 35: 'cuda:1', 36: 'meta', 37: 'cuda:1', 38: 'meta', 39: 'cuda:1', 40: 'meta', 41: 'cuda:1', 42: 'meta', 43: 'meta', 44: 'meta', 45: 'meta', 46: 'cuda:1', 47: 'meta', 48: 'meta', 49: 'meta', 50: 'cuda:1', 51: 'meta', 52: 'cuda:1', 53: 'cuda:1', 54: 'meta', 55: 'meta', 56: 'meta', 57: 'meta', 58: 'cuda:1', 59: 'meta', 60: 'cuda:1', 61: 'meta', 62: 'cuda:1', 63: 'cuda:1'})
INFO 01-06 17:11:02.935494.935494 cuda_memory_view.py:201] Starting to load CPU experts from last layer to first layer...
INFO 01-06 17:11:02.935370.935370 cuda_memory_view.py:208] Loading Layer 27: 5 CPU experts: [0, 5, 6, 10, 11]
DEBUG 01-06 17:11:02.935649.935649 cuda_h.py:10] start start_load_experts_decode_cpu_weight_l_27
DEBUG 01-06 17:11:02.935400.935400 cuda_h.py:19] end start_load_experts_decode_cpu_weight_l_27 cost 3.24249267578125e-05 seconds
INFO 01-06 17:11:02.935672.935672 cuda_memory_view.py:208] Loading Layer 26: 5 CPU experts: [3, 4, 6, 7, 8]
DEBUG 01-06 17:11:02.935421.935421 cuda_h.py:10] start start_load_experts_decode_cpu_weight_l_26
DEBUG 01-06 17:11:02.935753.935753 cuda_h.py:19] end start_load_experts_decode_cpu_weight_l_26 cost 1.1444091796875e-05 seconds
INFO 01-06 17:11:02.935403.935403 cuda_memory_view.py:208] Loading Layer 25: 5 CPU experts: [0, 2, 3, 5, 6]
DEBUG 01-06 17:11:02.935907.935907 cuda_h.py:10] start start_load_experts_decode_cpu_weight_l_25
DEBUG 01-06 17:11:02.935047.935047 cuda_h.py:19] end start_load_experts_decode_cpu_weight_l_25 cost 1.0967254638671875e-05 seconds
INFO 01-06 17:11:02.935982.935982 cuda_memory_view.py:208] Loading Layer 24: 5 CPU experts: [0, 2, 4, 6, 7]
DEBUG 01-06 17:11:02.935248.935248 cuda_h.py:10] start start_load_experts_decode_cpu_weight_l_24
DEBUG 01-06 17:11:02.935865.935865 cuda_h.py:19] end start_load_experts_decode_cpu_weight_l_24 cost 1.1682510375976562e-05 seconds
INFO 01-06 17:11:02.935607.935607 cuda_memory_view.py:208] Loading Layer 23: 5 CPU experts: [1, 4, 5, 6, 7]
DEBUG 01-06 17:11:02.935396.935396 cuda_h.py:10] start start_load_experts_decode_cpu_weight_l_23
DEBUG 01-06 17:11:02.935059.935059 cuda_h.py:19] end start_load_experts_decode_cpu_weight_l_23 cost 1.0251998901367188e-05 seconds
INFO 01-06 17:11:02.935709.935709 cuda_memory_view.py:208] Loading Layer 22: 5 CPU experts: [0, 1, 2, 6, 7]
DEBUG 01-06 17:11:02.935736.935736 cuda_h.py:10] start start_load_experts_decode_cpu_weight_l_22
DEBUG 01-06 17:11:02.935638.935638 cuda_h.py:19] end start_load_experts_decode_cpu_weight_l_22 cost 1.1920928955078125e-05 seconds
INFO 01-06 17:11:02.935142.935142 cuda_memory_view.py:208] Loading Layer 21: 5 CPU experts: [1, 2, 4, 6, 7]
DEBUG 01-06 17:11:02.935738.935738 cuda_h.py:10] start start_load_experts_decode_cpu_weight_l_21
DEBUG 01-06 17:11:02.935779.935779 cuda_h.py:19] end start_load_experts_decode_cpu_weight_l_21 cost 9.5367431640625e-06 seconds
INFO 01-06 17:11:02.935283.935283 cuda_memory_view.py:208] Loading Layer 20: 5 CPU experts: [2, 3, 6, 8, 12]
DEBUG 01-06 17:11:02.935357.935357 cuda_h.py:10] start start_load_experts_decode_cpu_weight_l_20
DEBUG 01-06 17:11:02.935159.935159 cuda_h.py:19] end start_load_experts_decode_cpu_weight_l_20 cost 8.821487426757812e-06 seconds
INFO 01-06 17:11:02.935332.935332 cuda_memory_view.py:208] Loading Layer 19: 5 CPU experts: [0, 1, 2, 5, 6]
DEBUG 01-06 17:11:02.935836.935836 cuda_h.py:10] start start_load_experts_decode_cpu_weight_l_19
DEBUG 01-06 17:11:02.936353.936353 cuda_h.py:19] end start_load_experts_decode_cpu_weight_l_19 cost 9.775161743164062e-06 seconds
INFO 01-06 17:11:02.936857.936857 cuda_memory_view.py:208] Loading Layer 18: 5 CPU experts: [0, 3, 5, 6, 8]
DEBUG 01-06 17:11:02.936169.936169 cuda_h.py:10] start start_load_experts_decode_cpu_weight_l_18
DEBUG 01-06 17:11:02.936256.936256 cuda_h.py:19] end start_load_experts_decode_cpu_weight_l_18 cost 8.58306884765625e-06 seconds
INFO 01-06 17:11:02.936760.936760 cuda_memory_view.py:208] Loading Layer 17: 5 CPU experts: [2, 3, 4, 6, 7]
DEBUG 01-06 17:11:02.936072.936072 cuda_h.py:10] start start_load_experts_decode_cpu_weight_l_17
DEBUG 01-06 17:11:02.936398.936398 cuda_h.py:19] end start_load_experts_decode_cpu_weight_l_17 cost 8.58306884765625e-06 seconds
INFO 01-06 17:11:02.936425.936425 cuda_memory_view.py:208] Loading Layer 16: 5 CPU experts: [0, 2, 4, 7, 9]
DEBUG 01-06 17:11:02.936498.936498 cuda_h.py:10] start start_load_experts_decode_cpu_weight_l_16
DEBUG 01-06 17:11:02.936778.936778 cuda_h.py:19] end start_load_experts_decode_cpu_weight_l_16 cost 8.821487426757812e-06 seconds
INFO 01-06 17:11:02.936758.936758 cuda_memory_view.py:208] Loading Layer 15: 5 CPU experts: [0, 2, 4, 5, 7]
DEBUG 01-06 17:11:02.936832.936832 cuda_h.py:10] start start_load_experts_decode_cpu_weight_l_15
DEBUG 01-06 17:11:02.936588.936588 cuda_h.py:19] end start_load_experts_decode_cpu_weight_l_15 cost 1.0013580322265625e-05 seconds
INFO 01-06 17:11:02.936615.936615 cuda_memory_view.py:208] Loading Layer 14: 5 CPU experts: [0, 7, 8, 12, 13]
DEBUG 01-06 17:11:02.936212.936212 cuda_h.py:10] start start_load_experts_decode_cpu_weight_l_14
DEBUG 01-06 17:11:02.936537.936537 cuda_h.py:19] end start_load_experts_decode_cpu_weight_l_14 cost 8.821487426757812e-06 seconds
INFO 01-06 17:11:02.936803.936803 cuda_memory_view.py:208] Loading Layer 13: 5 CPU experts: [1, 2, 4, 5, 6]
DEBUG 01-06 17:11:02.936996.936996 cuda_h.py:10] start start_load_experts_decode_cpu_weight_l_13
DEBUG 01-06 17:11:02.936693.936693 cuda_h.py:10] start sllm_worker_task
DEBUG 01-06 17:11:02.936186.936186 cuda_h.py:19] end start_load_experts_decode_cpu_weight_l_13 cost 1.2874603271484375e-05 seconds
DEBUG 01-06 17:11:02.936528.936528 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
INFO 01-06 17:11:02.936503.936503 cuda_memory_view.py:208] Loading Layer 12: 5 CPU experts: [0, 2, 4, 8, 11]
DEBUG 01-06 17:11:02.936062.936062 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 17:11:02.936044.936044 cuda_h.py:10] start start_load_experts_decode_cpu_weight_l_12
DEBUG 01-06 17:11:02.937898.937898 cuda_h.py:19] end allocate_cuda_memory cost 0.0004858970642089844 seconds
DEBUG 01-06 17:11:02.937423.937423 cuda_h.py:19] end start_load_experts_decode_cpu_weight_l_12 cost 1.2874603271484375e-05 seconds
DEBUG 01-06 17:11:02.937619.937619 cuda_h.py:10] start load_into_gpu_async
INFO 01-06 17:11:02.937363.937363 cuda_memory_view.py:208] Loading Layer 11: 5 CPU experts: [2, 3, 6, 9, 13]
DEBUG 01-06 17:11:02.937518.937518 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 17:11:02.937155.937155 cuda_h.py:10] start start_load_experts_decode_cpu_weight_l_11
DEBUG 01-06 17:11:02.937569.937569 cuda_h.py:19] end start_load_experts_decode_cpu_weight_l_11 cost 1.1205673217773438e-05 seconds
INFO 01-06 17:11:02.937026.937026 cuda_memory_view.py:208] Loading Layer 10: 5 CPU experts: [2, 3, 4, 5, 6]
DEBUG 01-06 17:11:02.937100.937100 cuda_h.py:10] start start_load_experts_decode_cpu_weight_l_10
DEBUG 01-06 17:11:02.937948.937948 cuda_h.py:19] end start_load_experts_decode_cpu_weight_l_10 cost 9.059906005859375e-06 seconds
INFO 01-06 17:11:02.937214.937214 cuda_memory_view.py:208] Loading Layer 9: 5 CPU experts: [2, 3, 4, 5, 7]
DEBUG 01-06 17:11:02.937003.937003 cuda_h.py:10] start start_load_experts_decode_cpu_weight_l_9
DEBUG 01-06 17:11:02.938520.938520 cuda_h.py:19] end start_load_experts_decode_cpu_weight_l_9 cost 9.059906005859375e-06 seconds
INFO 01-06 17:11:02.938071.938071 cuda_memory_view.py:208] Loading Layer 8: 5 CPU experts: [0, 1, 6, 7, 8]
DEBUG 01-06 17:11:02.938906.938906 cuda_h.py:10] start start_load_experts_decode_cpu_weight_l_8
DEBUG 01-06 17:11:02.938278.938278 cuda_h.py:19] end start_load_experts_decode_cpu_weight_l_8 cost 8.821487426757812e-06 seconds
INFO 01-06 17:11:02.938828.938828 cuda_memory_view.py:208] Loading Layer 7: 5 CPU experts: [1, 3, 4, 5, 6]
DEBUG 01-06 17:11:02.938948.938948 cuda_h.py:10] start start_load_experts_decode_cpu_weight_l_7
DEBUG 01-06 17:11:02.938843.938843 cuda_h.py:19] end start_load_experts_decode_cpu_weight_l_7 cost 8.344650268554688e-06 seconds
INFO 01-06 17:11:02.938155.938155 cuda_memory_view.py:208] Loading Layer 6: 5 CPU experts: [0, 1, 2, 3, 7]
DEBUG 01-06 17:11:02.938751.938751 cuda_h.py:10] start start_load_experts_decode_cpu_weight_l_6
DEBUG 01-06 17:11:02.938037.938037 cuda_h.py:19] end start_load_experts_decode_cpu_weight_l_6 cost 9.059906005859375e-06 seconds
INFO 01-06 17:11:02.938780.938780 cuda_memory_view.py:208] Loading Layer 5: 5 CPU experts: [0, 2, 3, 4, 5]
DEBUG 01-06 17:11:02.938376.938376 cuda_h.py:10] start start_load_experts_decode_cpu_weight_l_5
DEBUG 01-06 17:11:02.938510.938510 cuda_h.py:19] end start_load_experts_decode_cpu_weight_l_5 cost 8.344650268554688e-06 seconds
INFO 01-06 17:11:02.938060.938060 cuda_memory_view.py:208] Loading Layer 4: 5 CPU experts: [4, 7, 8, 10, 11]
DEBUG 01-06 17:11:02.938418.938418 cuda_h.py:10] start start_load_experts_decode_cpu_weight_l_4
DEBUG 01-06 17:11:02.938790.938790 cuda_h.py:19] end start_load_experts_decode_cpu_weight_l_4 cost 9.059906005859375e-06 seconds
INFO 01-06 17:11:02.938201.938201 cuda_memory_view.py:208] Loading Layer 3: 5 CPU experts: [1, 2, 4, 5, 6]
DEBUG 01-06 17:11:02.938798.938798 cuda_h.py:10] start start_load_experts_decode_cpu_weight_l_3
DEBUG 01-06 17:11:02.938362.938362 cuda_h.py:19] end start_load_experts_decode_cpu_weight_l_3 cost 8.344650268554688e-06 seconds
INFO 01-06 17:11:02.938104.938104 cuda_memory_view.py:208] Loading Layer 2: 5 CPU experts: [0, 1, 3, 6, 7]
DEBUG 01-06 17:11:02.938655.938655 cuda_h.py:10] start start_load_experts_decode_cpu_weight_l_2
DEBUG 01-06 17:11:02.938265.938265 cuda_h.py:19] end start_load_experts_decode_cpu_weight_l_2 cost 8.821487426757812e-06 seconds
INFO 01-06 17:11:02.938338.938338 cuda_memory_view.py:208] Loading Layer 1: 5 CPU experts: [0, 1, 3, 10, 11]
DEBUG 01-06 17:11:02.938458.938458 cuda_h.py:10] start start_load_experts_decode_cpu_weight_l_1
DEBUG 01-06 17:11:02.938353.938353 cuda_h.py:19] end start_load_experts_decode_cpu_weight_l_1 cost 8.821487426757812e-06 seconds
DEBUG 01-06 17:11:02.938102.938102 cuda_h.py:19] end async_load_ce cost 0.018512964248657227 seconds
DEBUG 01-06 17:11:02.938461.938461 cuda_h.py:10] start init_inputs_tokens
DEBUG 01-06 17:11:02.938185.938185 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 17:11:02.938963.938963 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, afb2eb63-e13f-4771-ae5d-062622835730
DEBUG 01-06 17:11:02.938921.938921 client.py:106] call stub.LoadModelAsync
INFO 01-06 17:11:02.940612.940612 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, afb2eb63-e13f-4771-ae5d-062622835730
DEBUG 01-06 17:11:02.940761.940761 cuda_h.py:19] end load_into_gpu_async cost 0.002914905548095703 seconds
DEBUG 01-06 17:11:02.940220.940220 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 17:11:02.940797.940797 cuda_h.py:19] end restore_tensors2 cost 0.0001480579376220703 seconds
DEBUG 01-06 17:11:02.941276.941276 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0042247772216796875 seconds
INFO 01-06 17:11:02.941391.941391 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, afb2eb63-e13f-4771-ae5d-062622835730
INFO 01-06 17:11:02.949219.949219 client.py:127] Model loaded
DEBUG 01-06 17:11:02.951304.951304 cuda_h.py:19] end sllm_worker_task cost 0.014469623565673828 seconds
DEBUG 01-06 17:11:02.951110.951110 cuda_h.py:10] start sllm_worker_task
DEBUG 01-06 17:11:02.951431.951431 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 17:11:02.951455.951455 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 17:11:02.954088.954088 cuda_h.py:19] end allocate_cuda_memory cost 0.0029997825622558594 seconds
DEBUG 01-06 17:11:02.954495.954495 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 17:11:02.954095.954095 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 17:11:02.955934.955934 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 17:11:02.955704.955704 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, e29ed076-c3c5-4b5c-9710-7e2b9f96134e
DEBUG 01-06 17:11:02.955552.955552 client.py:106] call stub.LoadModelAsync
INFO 01-06 17:11:02.957447.957447 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, e29ed076-c3c5-4b5c-9710-7e2b9f96134e
DEBUG 01-06 17:11:02.957810.957810 cuda_h.py:19] end load_into_gpu_async cost 0.002176523208618164 seconds
DEBUG 01-06 17:11:02.957390.957390 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 17:11:02.957704.957704 cuda_h.py:19] end restore_tensors2 cost 0.00018453598022460938 seconds
DEBUG 01-06 17:11:02.957402.957402 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.006186723709106445 seconds
INFO 01-06 17:11:02.957347.957347 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, e29ed076-c3c5-4b5c-9710-7e2b9f96134e
INFO 01-06 17:11:02.965999.965999 client.py:127] Model loaded
DEBUG 01-06 17:11:02.967046.967046 cuda_h.py:19] end sllm_worker_task cost 0.015794992446899414 seconds
DEBUG 01-06 17:11:02.967334.967334 cuda_h.py:10] start sllm_worker_task
DEBUG 01-06 17:11:02.967522.967522 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 17:11:02.967843.967843 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 17:11:02.968732.968732 cuda_h.py:19] end allocate_cuda_memory cost 0.001146078109741211 seconds
DEBUG 01-06 17:11:02.968510.968510 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 17:11:02.968581.968581 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 17:11:02.969843.969843 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 17:11:02.969978.969978 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 1c5c5c6b-c55f-4fd6-b8e7-938654fb2001
DEBUG 01-06 17:11:02.969519.969519 client.py:106] call stub.LoadModelAsync
INFO 01-06 17:11:02.970992.970992 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 1c5c5c6b-c55f-4fd6-b8e7-938654fb2001
DEBUG 01-06 17:11:02.970586.970586 cuda_h.py:19] end load_into_gpu_async cost 0.0019278526306152344 seconds
DEBUG 01-06 17:11:02.970151.970151 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 17:11:02.971371.971371 cuda_h.py:19] end restore_tensors2 cost 0.0001652240753173828 seconds
DEBUG 01-06 17:11:02.971732.971732 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.003851175308227539 seconds
INFO 01-06 17:11:02.971338.971338 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 1c5c5c6b-c55f-4fd6-b8e7-938654fb2001
INFO 01-06 17:11:02.979585.979585 client.py:127] Model loaded
DEBUG 01-06 17:11:02.981484.981484 cuda_h.py:19] end sllm_worker_task cost 0.013896942138671875 seconds
DEBUG 01-06 17:11:02.981098.981098 cuda_h.py:10] start sllm_worker_task
DEBUG 01-06 17:11:02.981221.981221 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 17:11:02.981291.981291 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 17:11:02.982162.982162 cuda_h.py:19] end allocate_cuda_memory cost 0.00039958953857421875 seconds
DEBUG 01-06 17:11:02.982056.982056 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 17:11:02.982643.982643 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 17:11:02.982813.982813 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 17:11:02.982736.982736 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, ec219b6a-e290-4643-b1e7-d8074037e3d2
DEBUG 01-06 17:11:02.982982.982982 client.py:106] call stub.LoadModelAsync
INFO 01-06 17:11:02.984041.984041 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, ec219b6a-e290-4643-b1e7-d8074037e3d2
DEBUG 01-06 17:11:02.984125.984125 cuda_h.py:19] end load_into_gpu_async cost 0.0021424293518066406 seconds
DEBUG 01-06 17:11:02.984982.984982 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 17:11:02.984553.984553 cuda_h.py:19] end restore_tensors2 cost 0.00017261505126953125 seconds
DEBUG 01-06 17:11:02.984543.984543 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0034275054931640625 seconds
INFO 01-06 17:11:02.985540.985540 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, ec219b6a-e290-4643-b1e7-d8074037e3d2
INFO 01-06 17:11:02.993572.993572 client.py:127] Model loaded
DEBUG 01-06 17:11:02.994010.994010 cuda_h.py:19] end sllm_worker_task cost 0.013497114181518555 seconds
DEBUG 01-06 17:11:02.995002.995002 cuda_h.py:10] start sllm_worker_task
DEBUG 01-06 17:11:02.995978.995978 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 17:11:02.995174.995174 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 17:11:02.995249.995249 cuda_h.py:19] end allocate_cuda_memory cost 0.00039315223693847656 seconds
DEBUG 01-06 17:11:02.995241.995241 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 17:11:02.996296.996296 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 17:11:02.996995.996995 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 17:11:02.996222.996222 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 042b461b-5316-4e3e-8e5c-364e4882e83d
DEBUG 01-06 17:11:02.996897.996897 client.py:106] call stub.LoadModelAsync
INFO 01-06 17:11:02.997187.997187 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 042b461b-5316-4e3e-8e5c-364e4882e83d
DEBUG 01-06 17:11:02.998873.998873 cuda_h.py:19] end load_into_gpu_async cost 0.0019998550415039062 seconds
DEBUG 01-06 17:11:02.998962.998962 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 17:11:02.998982.998982 cuda_h.py:19] end restore_tensors2 cost 0.00014901161193847656 seconds
DEBUG 01-06 17:11:02.998343.998343 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.003105640411376953 seconds
INFO 01-06 17:11:02.998512.998512 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 042b461b-5316-4e3e-8e5c-364e4882e83d
INFO 01-06 17:11:03.006134.006134 client.py:127] Model loaded
DEBUG 01-06 17:11:03.008248.008248 cuda_h.py:19] end sllm_worker_task cost 0.01300954818725586 seconds
DEBUG 01-06 17:11:03.008775.008775 cuda_h.py:10] start sllm_worker_task
DEBUG 01-06 17:11:03.008175.008175 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 17:11:03.008550.008550 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 17:11:03.010062.010062 cuda_h.py:19] end allocate_cuda_memory cost 0.0023679733276367188 seconds
DEBUG 01-06 17:11:03.011226.011226 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 17:11:03.011957.011957 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 17:11:03.011735.011735 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 17:11:03.011909.011909 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 3b3316b7-2812-4a68-b603-9c0c19f0933f
DEBUG 01-06 17:11:03.011186.011186 client.py:106] call stub.LoadModelAsync
INFO 01-06 17:11:03.013013.013013 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 3b3316b7-2812-4a68-b603-9c0c19f0933f
DEBUG 01-06 17:11:03.013197.013197 cuda_h.py:19] end load_into_gpu_async cost 0.001995086669921875 seconds
DEBUG 01-06 17:11:03.013868.013868 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 17:11:03.013022.013022 cuda_h.py:19] end restore_tensors2 cost 0.0001780986785888672 seconds
DEBUG 01-06 17:11:03.013906.013906 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0051422119140625 seconds
INFO 01-06 17:11:03.013942.013942 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 3b3316b7-2812-4a68-b603-9c0c19f0933f
DEBUG 01-06 17:11:03.019384.019384 cuda_h.py:19] end init_inputs_tokens cost 0.08073902130126953 seconds
DEBUG 01-06 17:11:03.019612.019612 lmp.py:295] next_inputs_tokens shape: torch.Size([32, 1, 2048])
DEBUG 01-06 17:11:03.019521.019521 lmp.py:298] -------------------------------- start decode layer 0 --------------------------------
DEBUG 01-06 17:11:03.019263.019263 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-06 17:11:03.019067.019067 mlpmodule.py:367] cuda:1 cuda:1
DEBUG 01-06 17:11:03.019354.019354 cuda_h.py:10] start self_attn
cos shape torch.Size([65, 128]) sin shape torch.Size([65, 128]) position_ids tensor([[0]], device='cuda:1')
cos shape torch.Size([1, 1, 1, 128]) sin shape torch.Size([1, 1, 1, 128])
q_embed shape torch.Size([32, 16, 1, 128]) k_embed shape torch.Size([32, 16, 1, 128])
INFO 01-06 17:11:03.022745.022745 client.py:127] Model loaded
DEBUG 01-06 17:11:03.023467.023467 cuda_h.py:19] end sllm_worker_task cost 0.015227794647216797 seconds
DEBUG 01-06 17:11:03.023796.023796 cuda_h.py:10] start sllm_worker_task
DEBUG 01-06 17:11:03.023018.023018 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 17:11:03.024373.024373 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 17:11:03.024243.024243 cuda_h.py:19] end allocate_cuda_memory cost 0.0003733634948730469 seconds
DEBUG 01-06 17:11:03.024069.024069 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 17:11:03.024754.024754 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 17:11:03.024274.024274 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 17:11:03.024223.024223 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 38981f42-41d0-40c1-a20c-21d549c99ddc
DEBUG 01-06 17:11:03.025488.025488 client.py:106] call stub.LoadModelAsync
INFO 01-06 17:11:03.026308.026308 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 38981f42-41d0-40c1-a20c-21d549c99ddc
DEBUG 01-06 17:11:03.026386.026386 cuda_h.py:19] end load_into_gpu_async cost 0.0020401477813720703 seconds
DEBUG 01-06 17:11:03.026719.026719 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 17:11:03.027906.027906 cuda_h.py:19] end restore_tensors2 cost 0.00017070770263671875 seconds
DEBUG 01-06 17:11:03.027167.027167 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0031943321228027344 seconds
INFO 01-06 17:11:03.027296.027296 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 38981f42-41d0-40c1-a20c-21d549c99ddc
INFO 01-06 17:11:03.035159.035159 client.py:127] Model loaded
DEBUG 01-06 17:11:03.036104.036104 cuda_h.py:19] end sllm_worker_task cost 0.013043403625488281 seconds
DEBUG 01-06 17:11:03.037260.037260 cuda_h.py:10] start sllm_worker_task
DEBUG 01-06 17:11:03.037077.037077 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 17:11:03.037935.037935 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 17:11:03.037665.037665 cuda_h.py:19] end allocate_cuda_memory cost 0.00034999847412109375 seconds
DEBUG 01-06 17:11:03.037365.037365 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 17:11:03.037652.037652 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 17:11:03.037290.037290 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 17:11:03.038802.038802 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, a97bc166-b141-439f-9236-6ab9918d213e
DEBUG 01-06 17:11:03.038742.038742 client.py:106] call stub.LoadModelAsync
INFO 01-06 17:11:03.039414.039414 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, a97bc166-b141-439f-9236-6ab9918d213e
DEBUG 01-06 17:11:03.039755.039755 cuda_h.py:19] end load_into_gpu_async cost 0.0018966197967529297 seconds
DEBUG 01-06 17:11:03.039360.039360 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 17:11:03.040400.040400 cuda_h.py:19] end restore_tensors2 cost 0.00014281272888183594 seconds
DEBUG 01-06 17:11:03.040092.040092 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.002929210662841797 seconds
INFO 01-06 17:11:03.040711.040711 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, a97bc166-b141-439f-9236-6ab9918d213e
DEBUG 01-06 17:11:03.044124.044124 cuda_h.py:19] end self_attn cost 0.024091482162475586 seconds
DEBUG 01-06 17:11:03.044089.044089 cuda_h.py:19] end iln_self_attn_paln cost 0.024830102920532227 seconds
DEBUG 01-06 17:11:03.044296.044296 cuda_h.py:10] start dense_mlp
DEBUG 01-06 17:11:03.047252.047252 lmp.py:319] ghidden_states after dense_mlp_func shape: torch.Size([32, 1, 2048])
DEBUG 01-06 17:11:03.047903.047903 cuda_h.py:19] end dense_mlp cost 0.0026645660400390625 seconds
DEBUG 01-06 17:11:03.047176.047176 lmp.py:325] -------------------------------- end decode layer 0 --------------------------------
DEBUG 01-06 17:11:03.047449.047449 lmp.py:298] -------------------------------- start decode layer 1 --------------------------------
DEBUG 01-06 17:11:03.047244.047244 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-06 17:11:03.047849.047849 mlpmodule.py:367] cuda:1 cuda:1
DEBUG 01-06 17:11:03.047340.047340 cuda_h.py:10] start self_attn
cos shape torch.Size([65, 128]) sin shape torch.Size([65, 128]) position_ids tensor([[0]], device='cuda:1')
cos shape torch.Size([1, 1, 1, 128]) sin shape torch.Size([1, 1, 1, 128])
q_embed shape torch.Size([32, 16, 1, 128]) k_embed shape torch.Size([32, 16, 1, 128])
INFO 01-06 17:11:03.048076.048076 client.py:127] Model loaded
DEBUG 01-06 17:11:03.050844.050844 cuda_h.py:19] end sllm_worker_task cost 0.012987375259399414 seconds
DEBUG 01-06 17:11:03.050444.050444 cuda_h.py:10] start sllm_worker_task
DEBUG 01-06 17:11:03.050600.050600 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 17:11:03.050253.050253 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 17:11:03.050062.050062 cuda_h.py:19] end allocate_cuda_memory cost 0.00031638145446777344 seconds
DEBUG 01-06 17:11:03.051391.051391 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 17:11:03.051918.051918 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 17:11:03.051100.051100 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 17:11:03.051389.051389 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, b461ae11-fba9-42d7-bf65-c4f8254dbe35
DEBUG 01-06 17:11:03.051555.051555 client.py:106] call stub.LoadModelAsync
DEBUG 01-06 17:11:03.051062.051062 cuda_h.py:19] end self_attn cost 0.00409388542175293 seconds
DEBUG 01-06 17:11:03.052136.052136 cuda_h.py:19] end iln_self_attn_paln cost 0.0048367977142333984 seconds
DEBUG 01-06 17:11:03.052542.052542 cuda_h.py:10] start layer_moe_dgenerate_1
DEBUG 01-06 17:11:03.052450.052450 cuda_h.py:10] start gate
INFO 01-06 17:11:03.053312.053312 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, b461ae11-fba9-42d7-bf65-c4f8254dbe35
DEBUG 01-06 17:11:03.053204.053204 cuda_h.py:19] end load_into_gpu_async cost 0.002205371856689453 seconds
DEBUG 01-06 17:11:03.053968.053968 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 17:11:03.053752.053752 cuda_h.py:19] end restore_tensors2 cost 0.0001647472381591797 seconds
DEBUG 01-06 17:11:03.053695.053695 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.003337383270263672 seconds
INFO 01-06 17:11:03.053070.053070 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, b461ae11-fba9-42d7-bf65-c4f8254dbe35
INFO 01-06 17:11:03.062809.062809 client.py:127] Model loaded
DEBUG 01-06 17:11:03.063926.063926 cuda_h.py:19] end sllm_worker_task cost 0.013289928436279297 seconds
DEBUG 01-06 17:11:03.063202.063202 cuda_h.py:10] start sllm_worker_task
DEBUG 01-06 17:11:03.063139.063139 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 17:11:03.064110.064110 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 17:11:03.064729.064729 cuda_h.py:19] end allocate_cuda_memory cost 0.0004012584686279297 seconds
DEBUG 01-06 17:11:03.064363.064363 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 17:11:03.064439.064439 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 17:11:03.064714.064714 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 17:11:03.064048.064048 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 8f736f73-ef1a-4bc4-8767-d45c5386b26e
DEBUG 01-06 17:11:03.065504.065504 client.py:106] call stub.LoadModelAsync
INFO 01-06 17:11:03.066608.066608 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 8f736f73-ef1a-4bc4-8767-d45c5386b26e
DEBUG 01-06 17:11:03.066447.066447 cuda_h.py:19] end load_into_gpu_async cost 0.0020012855529785156 seconds
DEBUG 01-06 17:11:03.066588.066588 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 17:11:03.067252.067252 cuda_h.py:19] end restore_tensors2 cost 0.00016760826110839844 seconds
DEBUG 01-06 17:11:03.067228.067228 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0031855106353759766 seconds
INFO 01-06 17:11:03.067358.067358 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 8f736f73-ef1a-4bc4-8767-d45c5386b26e
INFO 01-06 17:11:03.075628.075628 client.py:127] Model loaded
DEBUG 01-06 17:11:03.076123.076123 cuda_h.py:19] end sllm_worker_task cost 0.01297307014465332 seconds
DEBUG 01-06 17:11:03.076280.076280 cuda_h.py:10] start sllm_worker_task
DEBUG 01-06 17:11:03.077189.077189 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 17:11:03.077140.077140 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 17:11:03.080425.080425 cuda_h.py:19] end allocate_cuda_memory cost 0.0028917789459228516 seconds
DEBUG 01-06 17:11:03.080014.080014 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 17:11:03.080210.080210 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 17:11:03.080730.080730 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 17:11:03.080920.080920 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, e2cb39f7-7c95-4919-93df-4810ac553c1c
DEBUG 01-06 17:11:03.080389.080389 client.py:106] call stub.LoadModelAsync
DEBUG 01-06 17:11:03.080379.080379 cuda_h.py:19] end gate cost 0.0287017822265625 seconds
DEBUG 01-06 17:11:03.081213.081213 cuda_h.py:10] start experts_map_get
INFO 01-06 17:11:03.081521.081521 lmp.py:611] using loaded check layer: False
INFO 01-06 17:11:03.081859.081859 lmp.py:620] 
INFO 01-06 17:11:03.081859.081859 lmp.py:620] Layer 1 Expert Device Distribution:
INFO 01-06 17:11:03.081053.081053 lmp.py:621]   Active experts: 58 (out of 64 total)
INFO 01-06 17:11:03.081702.081702 lmp.py:622] 
INFO 01-06 17:11:03.081702.081702 lmp.py:622]   Detailed Expert Distribution:
INFO 01-06 17:11:03.081452.081452 lmp.py:623]   Expert ID  | Tokens     | Actual Device  
INFO 01-06 17:11:03.081763.081763 lmp.py:624]   ----------------------------------------------------------------------
INFO 01-06 17:11:03.081029.081029 lmp.py:627]   0          | 1          |  meta           
INFO 01-06 17:11:03.081387.081387 lmp.py:627]   18         | 1          |  meta           
INFO 01-06 17:11:03.082507.082507 lmp.py:627]   27         | 1          |  meta           
INFO 01-06 17:11:03.082673.082673 lmp.py:627]   28         | 1          |  meta           
INFO 01-06 17:11:03.082078.082078 lmp.py:627]   31         | 1          |  meta           
INFO 01-06 17:11:03.082436.082436 lmp.py:627]   35         | 1          |  meta           
INFO 01-06 17:11:03.082841.082841 lmp.py:627]   37         | 1          |  meta           
INFO 01-06 17:11:03.082484.082484 lmp.py:627]   39         | 1          |  cuda:1         
INFO 01-06 17:11:03.082127.082127 lmp.py:627]   47         | 1          |  meta           
INFO 01-06 17:11:03.082293.082293 lmp.py:627]   59         | 1          |  meta           
INFO 01-06 17:11:03.082936.082936 lmp.py:627]   1          | 2          |  meta           
INFO 01-06 17:11:03.082294.082294 lmp.py:627]   8          | 2          |  cuda:1         
INFO 01-06 17:11:03.082513.082513 lmp.py:627]   12         | 2          |  cuda:1         
INFO 01-06 17:11:03.082348.082348 lmp.py:627]   13         | 2          |  meta           
INFO 01-06 17:11:03.082991.082991 lmp.py:627]   22         | 2          |  meta           
INFO 01-06 17:11:03.082919.082919 lmp.py:627]   23         | 2          |  cuda:1         
INFO 01-06 17:11:03.082323.082323 lmp.py:627]   29         | 2          |  cuda:1         
INFO 01-06 17:11:03.082490.082490 lmp.py:627]   30         | 2          |  cuda:1         
INFO 01-06 17:11:03.082894.082894 lmp.py:627]   32         | 2          |  meta           
INFO 01-06 17:11:03.082299.082299 lmp.py:627]   33         | 2          |  cuda:1         
INFO 01-06 17:11:03.082465.082465 lmp.py:627]   44         | 2          |  meta           
INFO 01-06 17:11:03.082869.082869 lmp.py:627]   46         | 2          |  cuda:1         
INFO 01-06 17:11:03.082512.082512 lmp.py:627]   54         | 2          |  meta           
INFO 01-06 17:11:03.082301.082301 lmp.py:627]   5          | 3          |  cuda:1         
INFO 01-06 17:11:03.082136.082136 lmp.py:627]   7          | 3          |  cuda:1         
INFO 01-06 17:11:03.082494.082494 lmp.py:627]   11         | 3          |  meta           
INFO 01-06 17:11:03.082661.082661 lmp.py:627]   19         | 3          |  cuda:1         
INFO 01-06 17:11:03.082588.082588 lmp.py:627]   24         | 3          |  cuda:1         
INFO 01-06 17:11:03.082993.082993 lmp.py:627]   26         | 3          |  cuda:1         
INFO 01-06 17:11:03.082636.082636 lmp.py:627]   36         | 3          |  meta           
INFO 01-06 17:11:03.082802.082802 lmp.py:627]   41         | 3          |  meta           
INFO 01-06 17:11:03.082968.082968 lmp.py:627]   43         | 3          |  meta           
INFO 01-06 17:11:03.082611.082611 lmp.py:627]   48         | 3          |  cuda:1         
INFO 01-06 17:11:03.082016.082016 lmp.py:627]   2          | 4          |  cuda:1         
INFO 01-06 17:11:03.082897.082897 lmp.py:627]   4          | 4          |  cuda:1         
INFO 01-06 17:11:03.082063.082063 lmp.py:627]   6          | 4          |  cuda:1         
INFO 01-06 17:11:03.082229.082229 lmp.py:627]   9          | 4          |  cuda:1         
INFO 01-06 17:11:03.082349.082349 lmp.py:627]   10         | 4          |  meta           
INFO 01-06 17:11:03.082946.082946 lmp.py:627]   16         | 4          |  cuda:1         
INFO 01-06 17:11:03.082635.082635 lmp.py:627]   17         | 4          |  meta           
INFO 01-06 17:11:03.082278.082278 lmp.py:627]   34         | 4          |  meta           
INFO 01-06 17:11:03.082206.082206 lmp.py:627]   40         | 4          |  cuda:1         
INFO 01-06 17:11:03.082610.082610 lmp.py:627]   42         | 4          |  cuda:1         
INFO 01-06 17:11:03.082776.082776 lmp.py:627]   56         | 4          |  cuda:1         
INFO 01-06 17:11:03.082466.082466 lmp.py:627]   58         | 4          |  meta           
INFO 01-06 17:11:03.082870.082870 lmp.py:627]   60         | 4          |  meta           
INFO 01-06 17:11:03.082275.082275 lmp.py:627]   63         | 4          |  cuda:1         
INFO 01-06 17:11:03.082441.082441 lmp.py:627]   15         | 5          |  cuda:1         
INFO 01-06 17:11:03.082846.082846 lmp.py:627]   21         | 5          |  cuda:1         
INFO 01-06 17:11:03.082012.082012 lmp.py:627]   49         | 5          |  meta           
INFO 01-06 17:11:03.082416.082416 lmp.py:627]   61         | 5          |  cuda:1         
INFO 01-06 17:11:03.082251.082251 lmp.py:627]   38         | 6          |  meta           
INFO 01-06 17:11:03.082656.082656 lmp.py:627]   50         | 6          |  cuda:1         
INFO 01-06 17:11:03.082252.082252 lmp.py:627]   53         | 6          |  cuda:1         
INFO 01-06 17:11:03.082895.082895 lmp.py:627]   45         | 7          |  cuda:1         
INFO 01-06 17:11:03.082300.082300 lmp.py:627]   57         | 7          |  cuda:1         
INFO 01-06 17:11:03.082705.082705 lmp.py:627]   20         | 8          |  cuda:1         
INFO 01-06 17:11:03.082109.082109 lmp.py:627]   14         | 10         |  cuda:1         
INFO 01-06 17:11:03.082275.082275 lmp.py:628] ============================================================
INFO 01-06 17:11:03.082275.082275 lmp.py:628] 
INFO 01-06 17:11:03.083163.083163 lmp.py:630] experts_gpu_list: [39, 8, 12, 23, 29, 30, 33, 46, 5, 7, 19, 24, 26, 48, 2, 4, 6, 9, 16, 40, 42, 56, 63, 15, 21, 61, 50, 53, 45, 57, 20, 14] num: 32
INFO 01-06 17:11:03.083237.083237 lmp.py:631] experts_cpu_list: [0, 18, 27, 28, 31, 35, 37, 47, 59, 1, 13, 22, 32, 44, 54, 11, 36, 41, 43, 10, 17, 34, 58, 60, 49, 38] num: 26
INFO 01-06 17:11:03.083132.083132 lmp.py:632] expert_actual_device_map {0: 'meta', 1: 'meta', 2: 'cuda:1', 3: 'meta', 4: 'cuda:1', 5: 'cuda:1', 6: 'cuda:1', 7: 'cuda:1', 8: 'cuda:1', 9: 'cuda:1', 10: 'meta', 11: 'meta', 12: 'cuda:1', 13: 'meta', 14: 'cuda:1', 15: 'cuda:1', 16: 'cuda:1', 17: 'meta', 18: 'meta', 19: 'cuda:1', 20: 'cuda:1', 21: 'cuda:1', 22: 'meta', 23: 'cuda:1', 24: 'cuda:1', 25: 'meta', 26: 'cuda:1', 27: 'meta', 28: 'meta', 29: 'cuda:1', 30: 'cuda:1', 31: 'meta', 32: 'meta', 33: 'cuda:1', 34: 'meta', 35: 'meta', 36: 'meta', 37: 'meta', 38: 'meta', 39: 'cuda:1', 40: 'cuda:1', 41: 'meta', 42: 'cuda:1', 43: 'meta', 44: 'meta', 45: 'cuda:1', 46: 'cuda:1', 47: 'meta', 48: 'cuda:1', 49: 'meta', 50: 'cuda:1', 51: 'meta', 52: 'meta', 53: 'cuda:1', 54: 'meta', 55: 'meta', 56: 'cuda:1', 57: 'cuda:1', 58: 'meta', 59: 'meta', 60: 'meta', 61: 'cuda:1', 62: 'meta', 63: 'cuda:1'}
DEBUG 01-06 17:11:03.083788.083788 cuda_h.py:19] end experts_map_get cost 0.0019359588623046875 seconds
DEBUG 01-06 17:11:03.083274.083274 cuda_h.py:10] start gpu_sexperts
INFO 01-06 17:11:03.083810.083810 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, e2cb39f7-7c95-4919-93df-4810ac553c1c
DEBUG 01-06 17:11:03.083823.083823 cuda_h.py:19] end load_into_gpu_async cost 0.003078460693359375 seconds
DEBUG 01-06 17:11:03.083463.083463 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 17:11:03.083446.083446 cuda_h.py:19] end restore_tensors2 cost 0.00016760826110839844 seconds
DEBUG 01-06 17:11:03.084768.084768 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.006925821304321289 seconds
DEBUG 01-06 17:11:03.084135.084135 cuda_h.py:19] end gpu_sexperts cost 0.0009398460388183594 seconds
DEBUG 01-06 17:11:03.084940.084940 cuda_h.py:10] start gpu_experts
INFO 01-06 17:11:03.084935.084935 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, e2cb39f7-7c95-4919-93df-4810ac553c1c
DEBUG 01-06 17:11:03.086275.086275 mlpmodule.py:533] gpu group tensors cost 0.002215862274169922 s
DEBUG 01-06 17:11:03.087244.087244 mlpmodule.py:566] gpu pad cost 0.0013911724090576172 s
INFO 01-06 17:11:03.091182.091182 client.py:127] Model loaded
DEBUG 01-06 17:11:03.093519.093519 cuda_h.py:19] end sllm_worker_task cost 0.016170263290405273 seconds
DEBUG 01-06 17:11:03.093737.093737 cuda_h.py:10] start sllm_worker_task
DEBUG 01-06 17:11:03.093152.093152 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 17:11:03.093090.093090 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 17:11:03.093689.093689 mlpmodule.py:584] gpu group einsum cost 0.005705118179321289 s
DEBUG 01-06 17:11:03.094738.094738 cuda_h.py:19] end allocate_cuda_memory cost 0.0004165172576904297 seconds
DEBUG 01-06 17:11:03.094596.094596 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 17:11:03.094196.094196 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 17:11:03.094525.094525 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 17:11:03.094667.094667 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 19907a71-5739-4a6d-a70f-6adbd9c8fc1c
DEBUG 01-06 17:11:03.095966.095966 client.py:106] call stub.LoadModelAsync
INFO 01-06 17:11:03.096616.096616 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 19907a71-5739-4a6d-a70f-6adbd9c8fc1c
DEBUG 01-06 17:11:03.096972.096972 cuda_h.py:19] end load_into_gpu_async cost 0.0022182464599609375 seconds
DEBUG 01-06 17:11:03.096108.096108 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 17:11:03.097845.097845 cuda_h.py:19] end restore_tensors2 cost 0.00016808509826660156 seconds
DEBUG 01-06 17:11:03.097015.097015 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.003744840621948242 seconds
INFO 01-06 17:11:03.097649.097649 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 19907a71-5739-4a6d-a70f-6adbd9c8fc1c
DEBUG 01-06 17:11:03.098814.098814 mlpmodule.py:613] gpu experts func einsum cost 0.014551639556884766 s
DEBUG 01-06 17:11:03.098142.098142 cuda_h.py:19] end gpu_experts cost 0.014689445495605469 seconds
DEBUG 01-06 17:11:03.099328.099328 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-06 17:11:03.099031.099031 lmp.py:661] 
DEBUG 01-06 17:11:03.099031.099031 lmp.py:661]   Computing 26 experts on CPU...
DEBUG 01-06 17:11:03.099582.099582 cuda_h.py:19] end cpu_experts_submit cost 5.459785461425781e-05 seconds
DEBUG 01-06 17:11:03.099517.099517 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-06 17:11:03.110043.110043 mlpmodule.py:706] group tensors cost 0.01062154769897461 s
INFO 01-06 17:11:03.111190.111190 client.py:127] Model loaded
DEBUG 01-06 17:11:03.113556.113556 cuda_h.py:19] end sllm_worker_task cost 0.019773483276367188 seconds
DEBUG 01-06 17:11:03.113462.113462 cuda_h.py:10] start sllm_worker_task
DEBUG 01-06 17:11:03.113267.113267 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 17:11:03.113305.113305 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 17:11:03.114501.114501 cuda_h.py:19] end allocate_cuda_memory cost 0.00042057037353515625 seconds
DEBUG 01-06 17:11:03.114800.114800 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 17:11:03.114214.114214 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 17:11:03.114310.114310 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 17:11:03.114551.114551 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 325f3de8-6642-4982-9a01-44de57a38af5
DEBUG 01-06 17:11:03.114962.114962 client.py:106] call stub.LoadModelAsync
INFO 01-06 17:11:03.116174.116174 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 325f3de8-6642-4982-9a01-44de57a38af5
DEBUG 01-06 17:11:03.116239.116239 cuda_h.py:19] end load_into_gpu_async cost 0.002119302749633789 seconds
DEBUG 01-06 17:11:03.116771.116771 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 17:11:03.117496.117496 cuda_h.py:19] end restore_tensors2 cost 0.0001735687255859375 seconds
DEBUG 01-06 17:11:03.117175.117175 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0035009384155273438 seconds
INFO 01-06 17:11:03.117729.117729 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 325f3de8-6642-4982-9a01-44de57a38af5
DEBUG 01-06 17:11:03.117663.117663 mlpmodule.py:744] pad cost 0.006375789642333984 s
DEBUG 01-06 17:11:03.117595.117595 mlpmodule.py:750] create cpu tensor cost 6.008148193359375e-05 s
DEBUG 01-06 17:11:03.117506.117506 mlpmodule.py:755] move to cpu cost 5.53131103515625e-05 s
DEBUG 01-06 17:11:03.121764.121764 mlpmodule.py:769] group_w3: shape=torch.Size([26, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=74973184
DEBUG 01-06 17:11:03.121157.121157 mlpmodule.py:770] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-06 17:11:03.121299.121299 mlpmodule.py:775] group_w3 first element: -0.0107421875
WARNING 01-06 17:11:03.121501.121501 mlpmodule.py:785] start einsum2
INFO 01-06 17:11:03.126656.126656 client.py:127] Model loaded
DEBUG 01-06 17:11:03.128365.128365 mlpmodule.py:795] group einsum cost 0.0107574462890625 s
DEBUG 01-06 17:11:03.128401.128401 mlpmodule.py:803] cpy2cputensor cost 0.0001990795135498047 s
DEBUG 01-06 17:11:03.129094.129094 cuda_h.py:19] end sllm_worker_task cost 0.015374898910522461 seconds
DEBUG 01-06 17:11:03.129789.129789 cuda_h.py:10] start sllm_worker_task
DEBUG 01-06 17:11:03.129707.129707 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 17:11:03.129262.129262 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 17:11:03.130580.130580 cuda_h.py:19] end allocate_cuda_memory cost 0.0004591941833496094 seconds
DEBUG 01-06 17:11:03.130348.130348 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 17:11:03.130088.130088 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 17:11:03.130523.130523 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 17:11:03.130129.130129 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, b90a78c1-bb6e-4740-9eb3-ed6ae104dbba
DEBUG 01-06 17:11:03.130839.130839 client.py:106] call stub.LoadModelAsync
INFO 01-06 17:11:03.132201.132201 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, b90a78c1-bb6e-4740-9eb3-ed6ae104dbba
DEBUG 01-06 17:11:03.132259.132259 cuda_h.py:19] end load_into_gpu_async cost 0.002338886260986328 seconds
DEBUG 01-06 17:11:03.132156.132156 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 17:11:03.133133.133133 cuda_h.py:19] end restore_tensors2 cost 0.00019812583923339844 seconds
DEBUG 01-06 17:11:03.133282.133282 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.003837108612060547 seconds
INFO 01-06 17:11:03.133328.133328 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, b90a78c1-bb6e-4740-9eb3-ed6ae104dbba
DEBUG 01-06 17:11:03.135223.135223 cuda_h.py:19] end wait_cetm_experts cost 0.036039113998413086 seconds
DEBUG 01-06 17:11:03.135211.135211 cuda_h.py:19] end layer_moe_dgenerate_1 cost 0.08342385292053223 seconds
DEBUG 01-06 17:11:03.135275.135275 lmp.py:325] -------------------------------- end decode layer 1 --------------------------------
DEBUG 01-06 17:11:03.135568.135568 lmp.py:298] -------------------------------- start decode layer 2 --------------------------------
DEBUG 01-06 17:11:03.135609.135609 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-06 17:11:03.136322.136322 mlpmodule.py:367] cuda:1 cuda:1
DEBUG 01-06 17:11:03.136337.136337 cuda_h.py:10] start self_attn
cos shape torch.Size([65, 128]) sin shape torch.Size([65, 128]) position_ids tensor([[0]], device='cuda:1')
cos shape torch.Size([1, 1, 1, 128]) sin shape torch.Size([1, 1, 1, 128])
q_embed shape torch.Size([32, 16, 1, 128]) k_embed shape torch.Size([32, 16, 1, 128])
DEBUG 01-06 17:11:03.138712.138712 cuda_h.py:19] end self_attn cost 0.0020325183868408203 seconds
DEBUG 01-06 17:11:03.138259.138259 cuda_h.py:19] end iln_self_attn_paln cost 0.0029697418212890625 seconds
DEBUG 01-06 17:11:03.138857.138857 cuda_h.py:10] start layer_moe_dgenerate_2
DEBUG 01-06 17:11:03.138103.138103 cuda_h.py:10] start gate
DEBUG 01-06 17:11:03.139247.139247 cuda_h.py:19] end gate cost 0.0006835460662841797 seconds
DEBUG 01-06 17:11:03.139991.139991 cuda_h.py:10] start experts_map_get
INFO 01-06 17:11:03.140401.140401 lmp.py:611] using loaded check layer: False
INFO 01-06 17:11:03.140261.140261 lmp.py:620] 
INFO 01-06 17:11:03.140261.140261 lmp.py:620] Layer 2 Expert Device Distribution:
INFO 01-06 17:11:03.140653.140653 lmp.py:621]   Active experts: 57 (out of 64 total)
INFO 01-06 17:11:03.140356.140356 lmp.py:622] 
INFO 01-06 17:11:03.140356.140356 lmp.py:622]   Detailed Expert Distribution:
INFO 01-06 17:11:03.140012.140012 lmp.py:623]   Expert ID  | Tokens     | Actual Device  
INFO 01-06 17:11:03.140046.140046 lmp.py:624]   ----------------------------------------------------------------------
INFO 01-06 17:11:03.140034.140034 lmp.py:627]   9          | 1          |  meta           
INFO 01-06 17:11:03.140829.140829 lmp.py:627]   17         | 1          |  meta           
INFO 01-06 17:11:03.140910.140910 lmp.py:627]   21         | 1          |  cuda:1         
INFO 01-06 17:11:03.140275.140275 lmp.py:627]   26         | 1          |  meta           
INFO 01-06 17:11:03.140878.140878 lmp.py:627]   30         | 1          |  meta           
INFO 01-06 17:11:03.140720.140720 lmp.py:627]   32         | 1          |  meta           
INFO 01-06 17:11:03.141277.141277 lmp.py:627]   52         | 1          |  cuda:1         
INFO 01-06 17:11:03.141596.141596 lmp.py:627]   56         | 1          |  cuda:1         
INFO 01-06 17:11:03.141676.141676 lmp.py:627]   57         | 1          |  meta           
INFO 01-06 17:11:03.141518.141518 lmp.py:627]   58         | 1          |  meta           
INFO 01-06 17:11:03.141360.141360 lmp.py:627]   4          | 2          |  cuda:1         
INFO 01-06 17:11:03.141248.141248 lmp.py:627]   8          | 2          |  meta           
INFO 01-06 17:11:03.141520.141520 lmp.py:627]   10         | 2          |  cuda:1         
INFO 01-06 17:11:03.141554.141554 lmp.py:627]   15         | 2          |  meta           
INFO 01-06 17:11:03.141727.141727 lmp.py:627]   25         | 2          |  meta           
INFO 01-06 17:11:03.141854.141854 lmp.py:627]   27         | 2          |  meta           
INFO 01-06 17:11:03.141888.141888 lmp.py:627]   34         | 2          |  meta           
INFO 01-06 17:11:03.141968.141968 lmp.py:627]   37         | 2          |  meta           
INFO 01-06 17:11:03.141048.141048 lmp.py:627]   44         | 2          |  cuda:1         
INFO 01-06 17:11:03.141367.141367 lmp.py:627]   53         | 2          |  cuda:1         
INFO 01-06 17:11:03.141732.141732 lmp.py:627]   54         | 2          |  meta           
INFO 01-06 17:11:03.141620.141620 lmp.py:627]   59         | 2          |  cuda:1         
INFO 01-06 17:11:03.141508.141508 lmp.py:627]   60         | 2          |  meta           
INFO 01-06 17:11:03.141873.141873 lmp.py:627]   3          | 3          |  meta           
INFO 01-06 17:11:03.141762.141762 lmp.py:627]   13         | 3          |  cuda:1         
INFO 01-06 17:11:03.141080.141080 lmp.py:627]   31         | 3          |  cuda:1         
INFO 01-06 17:11:03.141684.141684 lmp.py:627]   36         | 3          |  meta           
INFO 01-06 17:11:03.141287.141287 lmp.py:627]   38         | 3          |  cuda:1         
INFO 01-06 17:11:03.141891.141891 lmp.py:627]   41         | 3          |  cuda:1         
INFO 01-06 17:11:03.141779.141779 lmp.py:627]   43         | 3          |  cuda:1         
INFO 01-06 17:11:03.141905.141905 lmp.py:627]   45         | 3          |  meta           
INFO 01-06 17:11:03.141270.141270 lmp.py:627]   46         | 3          |  cuda:1         
INFO 01-06 17:11:03.141781.141781 lmp.py:627]   49         | 3          |  meta           
INFO 01-06 17:11:03.141862.141862 lmp.py:627]   51         | 3          |  meta           
INFO 01-06 17:11:03.141988.141988 lmp.py:627]   63         | 3          |  cuda:1         
INFO 01-06 17:11:03.141068.141068 lmp.py:627]   12         | 4          |  meta           
INFO 01-06 17:11:03.141672.141672 lmp.py:627]   20         | 4          |  cuda:1         
INFO 01-06 17:11:03.141229.141229 lmp.py:627]   22         | 4          |  cuda:1         
INFO 01-06 17:11:03.141117.141117 lmp.py:627]   23         | 4          |  meta           
INFO 01-06 17:11:03.141244.141244 lmp.py:627]   33         | 4          |  cuda:1         
INFO 01-06 17:11:03.141178.141178 lmp.py:627]   39         | 4          |  cuda:1         
INFO 01-06 17:11:03.141066.141066 lmp.py:627]   40         | 4          |  cuda:1         
INFO 01-06 17:11:03.141239.141239 lmp.py:627]   42         | 4          |  cuda:1         
INFO 01-06 17:11:03.141320.141320 lmp.py:627]   47         | 4          |  cuda:1         
INFO 01-06 17:11:03.141969.141969 lmp.py:627]   55         | 4          |  cuda:1         
INFO 01-06 17:11:03.141811.141811 lmp.py:627]   62         | 4          |  meta           
INFO 01-06 17:11:03.141938.141938 lmp.py:627]   2          | 5          |  cuda:1         
INFO 01-06 17:11:03.141303.141303 lmp.py:627]   7          | 5          |  meta           
INFO 01-06 17:11:03.141237.141237 lmp.py:627]   14         | 5          |  cuda:1         
INFO 01-06 17:11:03.142841.142841 lmp.py:627]   19         | 5          |  cuda:1         
INFO 01-06 17:11:03.142775.142775 lmp.py:627]   35         | 6          |  meta           
INFO 01-06 17:11:03.142902.142902 lmp.py:627]   50         | 6          |  cuda:1         
INFO 01-06 17:11:03.142029.142029 lmp.py:627]   5          | 7          |  cuda:1         
INFO 01-06 17:11:03.142394.142394 lmp.py:627]   16         | 7          |  cuda:1         
INFO 01-06 17:11:03.142759.142759 lmp.py:627]   18         | 9          |  cuda:1         
INFO 01-06 17:11:03.142600.142600 lmp.py:627]   61         | 9          |  cuda:1         
INFO 01-06 17:11:03.142012.142012 lmp.py:627]   11         | 12         |  cuda:1         
INFO 01-06 17:11:03.142423.142423 lmp.py:628] ============================================================
INFO 01-06 17:11:03.142423.142423 lmp.py:628] 
INFO 01-06 17:11:03.142272.142272 lmp.py:630] experts_gpu_list: [21, 52, 56, 4, 10, 44, 53, 59, 13, 31, 38, 41, 43, 46, 63, 20, 22, 33, 39, 40, 42, 47, 55, 2, 14, 19, 50, 5, 16, 18, 61, 11] num: 32
INFO 01-06 17:11:03.142783.142783 lmp.py:631] experts_cpu_list: [9, 17, 26, 30, 32, 57, 58, 8, 15, 25, 27, 34, 37, 54, 60, 3, 36, 45, 49, 51, 12, 23, 62, 7, 35] num: 25
INFO 01-06 17:11:03.142830.142830 lmp.py:632] expert_actual_device_map {0: 'meta', 1: 'meta', 2: 'cuda:1', 3: 'meta', 4: 'cuda:1', 5: 'cuda:1', 6: 'meta', 7: 'meta', 8: 'meta', 9: 'meta', 10: 'cuda:1', 11: 'cuda:1', 12: 'meta', 13: 'cuda:1', 14: 'cuda:1', 15: 'meta', 16: 'cuda:1', 17: 'meta', 18: 'cuda:1', 19: 'cuda:1', 20: 'cuda:1', 21: 'cuda:1', 22: 'cuda:1', 23: 'meta', 24: 'meta', 25: 'meta', 26: 'meta', 27: 'meta', 28: 'meta', 29: 'meta', 30: 'meta', 31: 'cuda:1', 32: 'meta', 33: 'cuda:1', 34: 'meta', 35: 'meta', 36: 'meta', 37: 'meta', 38: 'cuda:1', 39: 'cuda:1', 40: 'cuda:1', 41: 'cuda:1', 42: 'cuda:1', 43: 'cuda:1', 44: 'cuda:1', 45: 'meta', 46: 'cuda:1', 47: 'cuda:1', 48: 'meta', 49: 'meta', 50: 'cuda:1', 51: 'meta', 52: 'cuda:1', 53: 'cuda:1', 54: 'meta', 55: 'cuda:1', 56: 'cuda:1', 57: 'meta', 58: 'meta', 59: 'cuda:1', 60: 'meta', 61: 'cuda:1', 62: 'meta', 63: 'cuda:1'}
DEBUG 01-06 17:11:03.142593.142593 cuda_h.py:19] end experts_map_get cost 0.0025169849395751953 seconds
DEBUG 01-06 17:11:03.142238.142238 mlpmodule.py:664]  experts func einsum cost 0.043021202087402344 s
DEBUG 01-06 17:11:03.142369.142369 cuda_h.py:10] start gpu_sexperts
INFO 01-06 17:11:03.142421.142421 client.py:127] Model loaded
DEBUG 01-06 17:11:03.144583.144583 cuda_h.py:19] end sllm_worker_task cost 0.014896869659423828 seconds
DEBUG 01-06 17:11:03.144047.144047 cuda_h.py:10] start sllm_worker_task
DEBUG 01-06 17:11:03.144010.144010 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 17:11:03.144629.144629 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 17:11:03.144205.144205 cuda_h.py:19] end allocate_cuda_memory cost 0.0003192424774169922 seconds
DEBUG 01-06 17:11:03.145958.145958 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 17:11:03.145907.145907 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 17:11:03.145586.145586 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 17:11:03.145847.145847 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 60524901-54e3-43b0-a9cb-9964a1910a8f
DEBUG 01-06 17:11:03.145633.145633 client.py:106] call stub.LoadModelAsync
DEBUG 01-06 17:11:03.145924.145924 cuda_h.py:19] end gpu_sexperts cost 0.002838134765625 seconds
DEBUG 01-06 17:11:03.145815.145815 cuda_h.py:10] start gpu_experts
DEBUG 01-06 17:11:03.146323.146323 mlpmodule.py:533] gpu group tensors cost 0.0004742145538330078 s
INFO 01-06 17:11:03.146845.146845 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 60524901-54e3-43b0-a9cb-9964a1910a8f
DEBUG 01-06 17:11:03.147645.147645 cuda_h.py:19] end load_into_gpu_async cost 0.0018367767333984375 seconds
DEBUG 01-06 17:11:03.147832.147832 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 17:11:03.147920.147920 cuda_h.py:19] end restore_tensors2 cost 0.00014638900756835938 seconds
DEBUG 01-06 17:11:03.147068.147068 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0028634071350097656 seconds
INFO 01-06 17:11:03.147132.147132 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 60524901-54e3-43b0-a9cb-9964a1910a8f
DEBUG 01-06 17:11:03.148982.148982 mlpmodule.py:566] gpu pad cost 0.0022156238555908203 s
DEBUG 01-06 17:11:03.149186.149186 mlpmodule.py:584] gpu group einsum cost 0.0004355907440185547 s
DEBUG 01-06 17:11:03.152434.152434 mlpmodule.py:613] gpu experts func einsum cost 0.006138324737548828 s
DEBUG 01-06 17:11:03.152914.152914 cuda_h.py:19] end gpu_experts cost 0.006289243698120117 seconds
DEBUG 01-06 17:11:03.152100.152100 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-06 17:11:03.152611.152611 lmp.py:661] 
DEBUG 01-06 17:11:03.152611.152611 lmp.py:661]   Computing 25 experts on CPU...
DEBUG 01-06 17:11:03.152223.152223 cuda_h.py:19] end cpu_experts_submit cost 6.198883056640625e-05 seconds
DEBUG 01-06 17:11:03.152111.152111 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-06 17:11:03.156908.156908 mlpmodule.py:706] group tensors cost 0.004086971282958984 s
INFO 01-06 17:11:03.157015.157015 client.py:127] Model loaded
DEBUG 01-06 17:11:03.159106.159106 cuda_h.py:19] end sllm_worker_task cost 0.014733314514160156 seconds
DEBUG 01-06 17:11:03.159172.159172 cuda_h.py:10] start sllm_worker_task
DEBUG 01-06 17:11:03.159514.159514 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 17:11:03.159412.159412 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 17:11:03.160734.160734 cuda_h.py:19] end allocate_cuda_memory cost 0.00039267539978027344 seconds
DEBUG 01-06 17:11:03.160349.160349 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 17:11:03.160083.160083 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 17:11:03.160577.160577 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 17:11:03.160720.160720 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 5c9b7efa-b86b-47c0-9967-6c398fcafe75
DEBUG 01-06 17:11:03.160488.160488 client.py:106] call stub.LoadModelAsync
DEBUG 01-06 17:11:03.162320.162320 mlpmodule.py:744] pad cost 0.005011320114135742 s
DEBUG 01-06 17:11:03.162377.162377 mlpmodule.py:750] create cpu tensor cost 4.458427429199219e-05 s
DEBUG 01-06 17:11:03.162187.162187 mlpmodule.py:755] move to cpu cost 3.218650817871094e-05 s
INFO 01-06 17:11:03.162209.162209 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 5c9b7efa-b86b-47c0-9967-6c398fcafe75
DEBUG 01-06 17:11:03.162624.162624 cuda_h.py:19] end load_into_gpu_async cost 0.002117156982421875 seconds
DEBUG 01-06 17:11:03.162488.162488 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 17:11:03.162297.162297 cuda_h.py:19] end restore_tensors2 cost 0.0001742839813232422 seconds
DEBUG 01-06 17:11:03.163711.163711 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0034334659576416016 seconds
INFO 01-06 17:11:03.163668.163668 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 5c9b7efa-b86b-47c0-9967-6c398fcafe75
DEBUG 01-06 17:11:03.165652.165652 mlpmodule.py:769] group_w3: shape=torch.Size([25, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=72089600
DEBUG 01-06 17:11:03.165032.165032 mlpmodule.py:770] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-06 17:11:03.165352.165352 mlpmodule.py:775] group_w3 first element: 0.0024566650390625
WARNING 01-06 17:11:03.165633.165633 mlpmodule.py:785] start einsum2
DEBUG 01-06 17:11:03.172805.172805 mlpmodule.py:795] group einsum cost 0.009717464447021484 s
DEBUG 01-06 17:11:03.172752.172752 mlpmodule.py:803] cpy2cputensor cost 8.749961853027344e-05 s
INFO 01-06 17:11:03.173796.173796 client.py:127] Model loaded
DEBUG 01-06 17:11:03.174014.174014 cuda_h.py:19] end sllm_worker_task cost 0.015149831771850586 seconds
DEBUG 01-06 17:11:03.174304.174304 cuda_h.py:10] start sllm_worker_task
DEBUG 01-06 17:11:03.174393.174393 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 17:11:03.175186.175186 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 17:11:03.175034.175034 cuda_h.py:19] end allocate_cuda_memory cost 0.00031638145446777344 seconds
DEBUG 01-06 17:11:03.175747.175747 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 17:11:03.175624.175624 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 17:11:03.175978.175978 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 17:11:03.175365.175365 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, e1d868db-314d-46fd-9865-4fa5ecb905b8
DEBUG 01-06 17:11:03.176556.176556 client.py:106] call stub.LoadModelAsync
INFO 01-06 17:11:03.177554.177554 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, e1d868db-314d-46fd-9865-4fa5ecb905b8
DEBUG 01-06 17:11:03.177075.177075 cuda_h.py:19] end load_into_gpu_async cost 0.0019752979278564453 seconds
DEBUG 01-06 17:11:03.177158.177158 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 17:11:03.178319.178319 cuda_h.py:19] end restore_tensors2 cost 0.0001609325408935547 seconds
DEBUG 01-06 17:11:03.178137.178137 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0031294822692871094 seconds
INFO 01-06 17:11:03.178492.178492 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, e1d868db-314d-46fd-9865-4fa5ecb905b8
DEBUG 01-06 17:11:03.179001.179001 cuda_h.py:19] end wait_cetm_experts cost 0.026899337768554688 seconds
DEBUG 01-06 17:11:03.179824.179824 cuda_h.py:19] end layer_moe_dgenerate_2 cost 0.04069781303405762 seconds
DEBUG 01-06 17:11:03.179315.179315 lmp.py:325] -------------------------------- end decode layer 2 --------------------------------
DEBUG 01-06 17:11:03.179244.179244 lmp.py:298] -------------------------------- start decode layer 3 --------------------------------
DEBUG 01-06 17:11:03.179391.179391 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-06 17:11:03.180389.180389 mlpmodule.py:367] cuda:1 cuda:1
DEBUG 01-06 17:11:03.180347.180347 cuda_h.py:10] start self_attn
cos shape torch.Size([65, 128]) sin shape torch.Size([65, 128]) position_ids tensor([[0]], device='cuda:1')
cos shape torch.Size([1, 1, 1, 128]) sin shape torch.Size([1, 1, 1, 128])
q_embed shape torch.Size([32, 16, 1, 128]) k_embed shape torch.Size([32, 16, 1, 128])
DEBUG 01-06 17:11:03.183855.183855 cuda_h.py:19] end self_attn cost 0.0024285316467285156 seconds
DEBUG 01-06 17:11:03.183303.183303 cuda_h.py:19] end iln_self_attn_paln cost 0.0034723281860351562 seconds
DEBUG 01-06 17:11:03.183662.183662 cuda_h.py:10] start layer_moe_dgenerate_3
DEBUG 01-06 17:11:03.183432.183432 cuda_h.py:10] start gate
DEBUG 01-06 17:11:03.184601.184601 cuda_h.py:19] end gate cost 0.0006463527679443359 seconds
DEBUG 01-06 17:11:03.184967.184967 cuda_h.py:10] start experts_map_get
INFO 01-06 17:11:03.184404.184404 lmp.py:611] using loaded check layer: False
INFO 01-06 17:11:03.185588.185588 lmp.py:620] 
INFO 01-06 17:11:03.185588.185588 lmp.py:620] Layer 3 Expert Device Distribution:
INFO 01-06 17:11:03.185881.185881 lmp.py:621]   Active experts: 59 (out of 64 total)
INFO 01-06 17:11:03.185776.185776 lmp.py:622] 
INFO 01-06 17:11:03.185776.185776 lmp.py:622]   Detailed Expert Distribution:
INFO 01-06 17:11:03.185101.185101 lmp.py:623]   Expert ID  | Tokens     | Actual Device  
INFO 01-06 17:11:03.185897.185897 lmp.py:624]   ----------------------------------------------------------------------
INFO 01-06 17:11:03.185884.185884 lmp.py:627]   1          | 1          |  meta           
INFO 01-06 17:11:03.185488.185488 lmp.py:627]   2          | 1          |  meta           
INFO 01-06 17:11:03.185330.185330 lmp.py:627]   18         | 1          |  meta           
INFO 01-06 17:11:03.185933.185933 lmp.py:627]   20         | 1          |  cuda:1         
INFO 01-06 17:11:03.185821.185821 lmp.py:627]   27         | 1          |  meta           
INFO 01-06 17:11:03.185140.185140 lmp.py:627]   30         | 1          |  meta           
INFO 01-06 17:11:03.185459.185459 lmp.py:627]   35         | 1          |  meta           
INFO 01-06 17:11:03.185539.185539 lmp.py:627]   43         | 1          |  cuda:1         
INFO 01-06 17:11:03.185765.185765 lmp.py:627]   55         | 1          |  cuda:1         
INFO 01-06 17:11:03.185322.185322 lmp.py:627]   56         | 1          |  meta           
INFO 01-06 17:11:03.185449.185449 lmp.py:627]   57         | 1          |  cuda:1         
INFO 01-06 17:11:03.185099.185099 lmp.py:627]   62         | 1          |  cuda:1         
INFO 01-06 17:11:03.185464.185464 lmp.py:627]   3          | 2          |  cuda:1         
INFO 01-06 17:11:03.185067.185067 lmp.py:627]   5          | 2          |  meta           
INFO 01-06 17:11:03.185386.185386 lmp.py:627]   6          | 2          |  meta           
INFO 01-06 17:11:03.185704.185704 lmp.py:627]   12         | 2          |  cuda:1         
INFO 01-06 17:11:03.185069.185069 lmp.py:627]   14         | 2          |  cuda:1         
INFO 01-06 17:11:03.185673.185673 lmp.py:627]   21         | 2          |  cuda:1         
INFO 01-06 17:11:03.185561.185561 lmp.py:627]   34         | 2          |  meta           
INFO 01-06 17:11:03.185449.185449 lmp.py:627]   38         | 2          |  cuda:1         
INFO 01-06 17:11:03.185576.185576 lmp.py:627]   39         | 2          |  meta           
INFO 01-06 17:11:03.185941.185941 lmp.py:627]   40         | 2          |  meta           
INFO 01-06 17:11:03.185114.185114 lmp.py:627]   44         | 2          |  cuda:1         
INFO 01-06 17:11:03.185956.185956 lmp.py:627]   45         | 2          |  meta           
INFO 01-06 17:11:03.186798.186798 lmp.py:627]   46         | 2          |  cuda:1         
INFO 01-06 17:11:03.186401.186401 lmp.py:627]   48         | 2          |  meta           
INFO 01-06 17:11:03.186627.186627 lmp.py:627]   50         | 2          |  meta           
INFO 01-06 17:11:03.186992.186992 lmp.py:627]   58         | 2          |  cuda:1         
INFO 01-06 17:11:03.186880.186880 lmp.py:627]   61         | 2          |  meta           
INFO 01-06 17:11:03.186530.186530 lmp.py:627]   4          | 3          |  meta           
INFO 01-06 17:11:03.186895.186895 lmp.py:627]   9          | 3          |  meta           
INFO 01-06 17:11:03.186068.186068 lmp.py:627]   24         | 3          |  cuda:1         
INFO 01-06 17:11:03.186910.186910 lmp.py:627]   25         | 3          |  cuda:1         
INFO 01-06 17:11:03.186275.186275 lmp.py:627]   37         | 3          |  meta           
INFO 01-06 17:11:03.186878.186878 lmp.py:627]   42         | 3          |  meta           
INFO 01-06 17:11:03.186528.186528 lmp.py:627]   47         | 3          |  cuda:1         
INFO 01-06 17:11:03.186939.186939 lmp.py:627]   59         | 3          |  meta           
INFO 01-06 17:11:03.186351.186351 lmp.py:627]   60         | 3          |  cuda:1         
INFO 01-06 17:11:03.186000.186000 lmp.py:627]   0          | 4          |  cuda:1         
INFO 01-06 17:11:03.186650.186650 lmp.py:627]   16         | 4          |  meta           
INFO 01-06 17:11:03.186300.186300 lmp.py:627]   22         | 4          |  cuda:1         
INFO 01-06 17:11:03.186950.186950 lmp.py:627]   26         | 4          |  meta           
INFO 01-06 17:11:03.186076.186076 lmp.py:627]   28         | 4          |  cuda:1         
INFO 01-06 17:11:03.186488.186488 lmp.py:627]   32         | 4          |  meta           
INFO 01-06 17:11:03.186853.186853 lmp.py:627]   33         | 4          |  cuda:1         
INFO 01-06 17:11:03.186456.186456 lmp.py:627]   36         | 4          |  meta           
INFO 01-06 17:11:03.186868.186868 lmp.py:627]   52         | 4          |  meta           
INFO 01-06 17:11:03.186994.186994 lmp.py:627]   63         | 4          |  cuda:1         
INFO 01-06 17:11:03.186405.186405 lmp.py:627]   23         | 5          |  meta           
INFO 01-06 17:11:03.186055.186055 lmp.py:627]   31         | 5          |  cuda:1         
INFO 01-06 17:11:03.186182.186182 lmp.py:627]   41         | 5          |  cuda:1         
INFO 01-06 17:11:03.186593.186593 lmp.py:627]   10         | 6          |  cuda:1         
INFO 01-06 17:11:03.186766.186766 lmp.py:627]   13         | 6          |  cuda:1         
INFO 01-06 17:11:03.186370.186370 lmp.py:627]   17         | 6          |  cuda:1         
INFO 01-06 17:11:03.186973.186973 lmp.py:627]   53         | 6          |  cuda:1         
INFO 01-06 17:11:03.186775.186775 lmp.py:627]   8          | 8          |  cuda:1         
INFO 01-06 17:11:03.186187.186187 lmp.py:627]   29         | 8          |  cuda:1         
INFO 01-06 17:11:03.186836.186836 lmp.py:627]   54         | 8          |  cuda:1         
INFO 01-06 17:11:03.186486.186486 lmp.py:627]   19         | 16         |  cuda:1         
INFO 01-06 17:11:03.186659.186659 lmp.py:628] ============================================================
INFO 01-06 17:11:03.186659.186659 lmp.py:628] 
INFO 01-06 17:11:03.186508.186508 lmp.py:630] experts_gpu_list: [20, 43, 55, 57, 62, 3, 12, 14, 21, 38, 44, 46, 58, 24, 25, 47, 60, 0, 22, 28, 33, 63, 31, 41, 10, 13, 17, 53, 8, 29, 54, 19] num: 32
INFO 01-06 17:11:03.186734.186734 lmp.py:631] experts_cpu_list: [1, 2, 18, 27, 30, 35, 56, 5, 6, 34, 39, 40, 45, 48, 50, 61, 4, 9, 37, 42, 59, 16, 26, 32, 36, 52, 23] num: 27
INFO 01-06 17:11:03.186973.186973 lmp.py:632] expert_actual_device_map {0: 'cuda:1', 1: 'meta', 2: 'meta', 3: 'cuda:1', 4: 'meta', 5: 'meta', 6: 'meta', 7: 'meta', 8: 'cuda:1', 9: 'meta', 10: 'cuda:1', 11: 'meta', 12: 'cuda:1', 13: 'cuda:1', 14: 'cuda:1', 15: 'meta', 16: 'meta', 17: 'cuda:1', 18: 'meta', 19: 'cuda:1', 20: 'cuda:1', 21: 'cuda:1', 22: 'cuda:1', 23: 'meta', 24: 'cuda:1', 25: 'cuda:1', 26: 'meta', 27: 'meta', 28: 'cuda:1', 29: 'cuda:1', 30: 'meta', 31: 'cuda:1', 32: 'meta', 33: 'cuda:1', 34: 'meta', 35: 'meta', 36: 'meta', 37: 'meta', 38: 'cuda:1', 39: 'meta', 40: 'meta', 41: 'cuda:1', 42: 'meta', 43: 'cuda:1', 44: 'cuda:1', 45: 'meta', 46: 'cuda:1', 47: 'cuda:1', 48: 'meta', 49: 'meta', 50: 'meta', 51: 'meta', 52: 'meta', 53: 'cuda:1', 54: 'cuda:1', 55: 'cuda:1', 56: 'meta', 57: 'cuda:1', 58: 'cuda:1', 59: 'meta', 60: 'cuda:1', 61: 'meta', 62: 'cuda:1', 63: 'cuda:1'}
DEBUG 01-06 17:11:03.186544.186544 cuda_h.py:19] end experts_map_get cost 0.002568483352661133 seconds
DEBUG 01-06 17:11:03.187726.187726 mlpmodule.py:664]  experts func einsum cost 0.03466010093688965 s
INFO 01-06 17:11:03.187517.187517 client.py:127] Model loaded
DEBUG 01-06 17:11:03.187200.187200 cuda_h.py:10] start gpu_sexperts
DEBUG 01-06 17:11:03.189303.189303 cuda_h.py:19] end sllm_worker_task cost 0.01427769660949707 seconds
DEBUG 01-06 17:11:03.189914.189914 cuda_h.py:10] start sllm_worker_task
DEBUG 01-06 17:11:03.189196.189196 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 17:11:03.189234.189234 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 17:11:03.190535.190535 cuda_h.py:19] end allocate_cuda_memory cost 0.0003669261932373047 seconds
DEBUG 01-06 17:11:03.190899.190899 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 17:11:03.190744.190744 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 17:11:03.190238.190238 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 17:11:03.190864.190864 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, f9cbf361-badb-4531-9051-1815e97fe490
DEBUG 01-06 17:11:03.190291.190291 cuda_h.py:19] end gpu_sexperts cost 0.0015404224395751953 seconds
DEBUG 01-06 17:11:03.191684.191684 client.py:106] call stub.LoadModelAsync
DEBUG 01-06 17:11:03.191940.191940 cuda_h.py:10] start gpu_experts
DEBUG 01-06 17:11:03.192872.192872 mlpmodule.py:533] gpu group tensors cost 0.0004839897155761719 s
INFO 01-06 17:11:03.192768.192768 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, f9cbf361-badb-4531-9051-1815e97fe490
DEBUG 01-06 17:11:03.193184.193184 cuda_h.py:19] end load_into_gpu_async cost 0.002460002899169922 seconds
DEBUG 01-06 17:11:03.193910.193910 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 17:11:03.193011.193011 cuda_h.py:19] end restore_tensors2 cost 0.0001690387725830078 seconds
DEBUG 01-06 17:11:03.193186.193186 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.003775358200073242 seconds
INFO 01-06 17:11:03.193093.193093 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, f9cbf361-badb-4531-9051-1815e97fe490
DEBUG 01-06 17:11:03.194525.194525 mlpmodule.py:566] gpu pad cost 0.0024116039276123047 s
DEBUG 01-06 17:11:03.195835.195835 mlpmodule.py:584] gpu group einsum cost 0.00044417381286621094 s
DEBUG 01-06 17:11:03.197487.197487 mlpmodule.py:613] gpu experts func einsum cost 0.006381034851074219 s
DEBUG 01-06 17:11:03.197702.197702 cuda_h.py:19] end gpu_experts cost 0.006517171859741211 seconds
DEBUG 01-06 17:11:03.198835.198835 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-06 17:11:03.198584.198584 lmp.py:661] 
DEBUG 01-06 17:11:03.198584.198584 lmp.py:661]   Computing 27 experts on CPU...
DEBUG 01-06 17:11:03.198997.198997 cuda_h.py:19] end cpu_experts_submit cost 5.7697296142578125e-05 seconds
DEBUG 01-06 17:11:03.198786.198786 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-06 17:11:03.203019.203019 mlpmodule.py:706] group tensors cost 0.00539088249206543 s
INFO 01-06 17:11:03.204059.204059 client.py:127] Model loaded
DEBUG 01-06 17:11:03.206656.206656 cuda_h.py:19] end sllm_worker_task cost 0.017068862915039062 seconds
DEBUG 01-06 17:11:03.206279.206279 cuda_h.py:10] start sllm_worker_task
DEBUG 01-06 17:11:03.207224.207224 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 17:11:03.207508.207508 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 17:11:03.207244.207244 cuda_h.py:19] end allocate_cuda_memory cost 0.0005464553833007812 seconds
DEBUG 01-06 17:11:03.208270.208270 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 17:11:03.208822.208822 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 17:11:03.208879.208879 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 17:11:03.208557.208557 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, db8dfe78-4eff-45d5-a4ee-a4d8c6a89f15
DEBUG 01-06 17:11:03.208612.208612 client.py:106] call stub.LoadModelAsync
INFO 01-06 17:11:03.210620.210620 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, db8dfe78-4eff-45d5-a4ee-a4d8c6a89f15
DEBUG 01-06 17:11:03.210108.210108 cuda_h.py:19] end load_into_gpu_async cost 0.0022110939025878906 seconds
DEBUG 01-06 17:11:03.210496.210496 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 17:11:03.210062.210062 cuda_h.py:19] end restore_tensors2 cost 0.0001938343048095703 seconds
DEBUG 01-06 17:11:03.210172.210172 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0036725997924804688 seconds
INFO 01-06 17:11:03.211926.211926 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, db8dfe78-4eff-45d5-a4ee-a4d8c6a89f15
DEBUG 01-06 17:11:03.211432.211432 mlpmodule.py:744] pad cost 0.006478071212768555 s
DEBUG 01-06 17:11:03.211276.211276 mlpmodule.py:750] create cpu tensor cost 4.410743713378906e-05 s
DEBUG 01-06 17:11:03.211815.211815 mlpmodule.py:755] move to cpu cost 3.361701965332031e-05 s
DEBUG 01-06 17:11:03.214297.214297 mlpmodule.py:769] group_w3: shape=torch.Size([27, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=77856768
DEBUG 01-06 17:11:03.215623.215623 mlpmodule.py:770] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-06 17:11:03.215990.215990 mlpmodule.py:775] group_w3 first element: -0.054931640625
WARNING 01-06 17:11:03.215489.215489 mlpmodule.py:785] start einsum2
INFO 01-06 17:11:03.221998.221998 client.py:127] Model loaded
DEBUG 01-06 17:11:03.222521.222521 mlpmodule.py:795] group einsum cost 0.010546207427978516 s
DEBUG 01-06 17:11:03.223162.223162 cuda_h.py:19] end sllm_worker_task cost 0.016536712646484375 seconds
DEBUG 01-06 17:11:03.223167.223167 mlpmodule.py:803] cpy2cputensor cost 0.0016086101531982422 s
DEBUG 01-06 17:11:03.223502.223502 cuda_h.py:10] start sllm_worker_task
DEBUG 01-06 17:11:03.224284.224284 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 17:11:03.224594.224594 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 17:11:03.224765.224765 cuda_h.py:19] end allocate_cuda_memory cost 0.00045609474182128906 seconds
DEBUG 01-06 17:11:03.224516.224516 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 17:11:03.224193.224193 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 17:11:03.224705.224705 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 17:11:03.225561.225561 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 029e7a11-5f39-40f1-92ab-9554969d1cbc
DEBUG 01-06 17:11:03.225346.225346 client.py:106] call stub.LoadModelAsync
INFO 01-06 17:11:03.226543.226543 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 029e7a11-5f39-40f1-92ab-9554969d1cbc
DEBUG 01-06 17:11:03.226486.226486 cuda_h.py:19] end load_into_gpu_async cost 0.0016226768493652344 seconds
DEBUG 01-06 17:11:03.226957.226957 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 17:11:03.226724.226724 cuda_h.py:19] end restore_tensors2 cost 0.00011396408081054688 seconds
DEBUG 01-06 17:11:03.226917.226917 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0025815963745117188 seconds
INFO 01-06 17:11:03.226218.226218 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 029e7a11-5f39-40f1-92ab-9554969d1cbc
DEBUG 01-06 17:11:03.229268.229268 cuda_h.py:19] end wait_cetm_experts cost 0.030961036682128906 seconds
DEBUG 01-06 17:11:03.229734.229734 cuda_h.py:19] end layer_moe_dgenerate_3 cost 0.04580235481262207 seconds
DEBUG 01-06 17:11:03.229574.229574 lmp.py:325] -------------------------------- end decode layer 3 --------------------------------
DEBUG 01-06 17:11:03.229913.229913 lmp.py:298] -------------------------------- start decode layer 4 --------------------------------
DEBUG 01-06 17:11:03.229185.229185 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-06 17:11:03.229824.229824 mlpmodule.py:367] cuda:1 cuda:1
DEBUG 01-06 17:11:03.230359.230359 cuda_h.py:10] start self_attn
cos shape torch.Size([65, 128]) sin shape torch.Size([65, 128]) position_ids tensor([[0]], device='cuda:1')
cos shape torch.Size([1, 1, 1, 128]) sin shape torch.Size([1, 1, 1, 128])
q_embed shape torch.Size([32, 16, 1, 128]) k_embed shape torch.Size([32, 16, 1, 128])
DEBUG 01-06 17:11:03.232000.232000 cuda_h.py:19] end self_attn cost 0.0018880367279052734 seconds
DEBUG 01-06 17:11:03.232488.232488 cuda_h.py:19] end iln_self_attn_paln cost 0.0026803016662597656 seconds
DEBUG 01-06 17:11:03.232060.232060 cuda_h.py:10] start layer_moe_dgenerate_4
DEBUG 01-06 17:11:03.232598.232598 cuda_h.py:10] start gate
DEBUG 01-06 17:11:03.233482.233482 cuda_h.py:19] end gate cost 0.0006456375122070312 seconds
DEBUG 01-06 17:11:03.233841.233841 cuda_h.py:10] start experts_map_get
INFO 01-06 17:11:03.233177.233177 lmp.py:611] using loaded check layer: False
INFO 01-06 17:11:03.234441.234441 lmp.py:620] 
INFO 01-06 17:11:03.234441.234441 lmp.py:620] Layer 4 Expert Device Distribution:
INFO 01-06 17:11:03.234495.234495 lmp.py:621]   Active experts: 56 (out of 64 total)
INFO 01-06 17:11:03.234675.234675 lmp.py:622] 
INFO 01-06 17:11:03.234675.234675 lmp.py:622]   Detailed Expert Distribution:
INFO 01-06 17:11:03.234808.234808 lmp.py:623]   Expert ID  | Tokens     | Actual Device  
INFO 01-06 17:11:03.234365.234365 lmp.py:624]   ----------------------------------------------------------------------
INFO 01-06 17:11:03.234876.234876 lmp.py:627]   2          | 1          |  cuda:1         
INFO 01-06 17:11:03.234195.234195 lmp.py:627]   4          | 1          |  meta           
INFO 01-06 17:11:03.234037.234037 lmp.py:627]   11         | 1          |  meta           
INFO 01-06 17:11:03.234878.234878 lmp.py:627]   18         | 1          |  cuda:1         
INFO 01-06 17:11:03.234197.234197 lmp.py:627]   19         | 1          |  cuda:1         
INFO 01-06 17:11:03.234039.234039 lmp.py:627]   25         | 1          |  cuda:1         
INFO 01-06 17:11:03.234119.234119 lmp.py:627]   29         | 1          |  meta           
INFO 01-06 17:11:03.234484.234484 lmp.py:627]   32         | 1          |  meta           
INFO 01-06 17:11:03.234134.234134 lmp.py:627]   34         | 1          |  meta           
INFO 01-06 17:11:03.234784.234784 lmp.py:627]   36         | 1          |  meta           
INFO 01-06 17:11:03.234910.234910 lmp.py:627]   37         | 1          |  cuda:1         
INFO 01-06 17:11:03.234799.234799 lmp.py:627]   53         | 1          |  meta           
INFO 01-06 17:11:03.234972.234972 lmp.py:627]   54         | 1          |  meta           
INFO 01-06 17:11:03.234813.234813 lmp.py:627]   60         | 1          |  meta           
INFO 01-06 17:11:03.234417.234417 lmp.py:627]   3          | 2          |  cuda:1         
INFO 01-06 17:11:03.234782.234782 lmp.py:627]   7          | 2          |  meta           
INFO 01-06 17:11:03.234624.234624 lmp.py:627]   10         | 2          |  meta           
INFO 01-06 17:11:03.234512.234512 lmp.py:627]   12         | 2          |  cuda:1         
INFO 01-06 17:11:03.234400.234400 lmp.py:627]   13         | 2          |  meta           
INFO 01-06 17:11:03.234858.234858 lmp.py:627]   14         | 2          |  meta           
INFO 01-06 17:11:03.234031.234031 lmp.py:627]   16         | 2          |  meta           
INFO 01-06 17:11:03.234965.234965 lmp.py:627]   20         | 2          |  meta           
INFO 01-06 17:11:03.234377.234377 lmp.py:627]   26         | 2          |  meta           
INFO 01-06 17:11:03.234026.234026 lmp.py:627]   40         | 2          |  cuda:1         
INFO 01-06 17:11:03.234915.234915 lmp.py:627]   46         | 2          |  cuda:1         
INFO 01-06 17:11:03.234326.234326 lmp.py:627]   47         | 2          |  meta           
INFO 01-06 17:11:03.234737.234737 lmp.py:627]   49         | 2          |  cuda:1         
INFO 01-06 17:11:03.234956.234956 lmp.py:627]   58         | 2          |  meta           
INFO 01-06 17:11:03.234845.234845 lmp.py:627]   9          | 3          |  cuda:1         
INFO 01-06 17:11:03.234064.234064 lmp.py:627]   24         | 3          |  cuda:1         
INFO 01-06 17:11:03.234475.234475 lmp.py:627]   27         | 3          |  meta           
INFO 01-06 17:11:03.234456.234456 lmp.py:627]   31         | 3          |  meta           
INFO 01-06 17:11:03.234821.234821 lmp.py:627]   35         | 3          |  cuda:1         
INFO 01-06 17:11:03.235232.235232 lmp.py:627]   44         | 3          |  meta           
INFO 01-06 17:11:03.235359.235359 lmp.py:627]   61         | 3          |  meta           
INFO 01-06 17:11:03.235294.235294 lmp.py:627]   63         | 3          |  meta           
INFO 01-06 17:11:03.235182.235182 lmp.py:627]   0          | 4          |  cuda:1         
INFO 01-06 17:11:03.235639.235639 lmp.py:627]   5          | 4          |  cuda:1         
INFO 01-06 17:11:03.235528.235528 lmp.py:627]   33         | 4          |  cuda:1         
INFO 01-06 17:11:03.235270.235270 lmp.py:627]   48         | 4          |  cuda:1         
INFO 01-06 17:11:03.235443.235443 lmp.py:627]   1          | 5          |  cuda:1         
INFO 01-06 17:11:03.235424.235424 lmp.py:627]   6          | 5          |  cuda:1         
INFO 01-06 17:11:03.235789.235789 lmp.py:627]   17         | 5          |  meta           
INFO 01-06 17:11:03.235723.235723 lmp.py:627]   23         | 5          |  cuda:1         
INFO 01-06 17:11:03.235088.235088 lmp.py:627]   55         | 5          |  cuda:1         
INFO 01-06 17:11:03.235784.235784 lmp.py:627]   41         | 6          |  meta           
INFO 01-06 17:11:03.235434.235434 lmp.py:627]   62         | 6          |  cuda:1         
INFO 01-06 17:11:03.235938.235938 lmp.py:627]   21         | 7          |  cuda:1         
INFO 01-06 17:11:03.235111.235111 lmp.py:627]   38         | 7          |  cuda:1         
INFO 01-06 17:11:03.235238.235238 lmp.py:627]   52         | 7          |  cuda:1         
INFO 01-06 17:11:03.235364.235364 lmp.py:627]   15         | 8          |  cuda:1         
INFO 01-06 17:11:03.235537.235537 lmp.py:627]   22         | 8          |  cuda:1         
INFO 01-06 17:11:03.235141.235141 lmp.py:627]   39         | 8          |  cuda:1         
INFO 01-06 17:11:03.235837.235837 lmp.py:627]   42         | 8          |  meta           
INFO 01-06 17:11:03.235248.235248 lmp.py:627]   59         | 9          |  cuda:1         
INFO 01-06 17:11:03.235467.235467 lmp.py:627]   50         | 11         |  cuda:1         
INFO 01-06 17:11:03.235402.235402 lmp.py:628] ============================================================
INFO 01-06 17:11:03.235402.235402 lmp.py:628] 
INFO 01-06 17:11:03.235628.235628 lmp.py:630] experts_gpu_list: [2, 18, 19, 25, 37, 3, 12, 40, 46, 49, 9, 24, 35, 0, 5, 33, 48, 1, 6, 23, 55, 62, 21, 38, 52, 15, 22, 39, 59, 50] num: 30
INFO 01-06 17:11:03.235900.235900 lmp.py:631] experts_cpu_list: [4, 11, 29, 32, 34, 36, 53, 54, 60, 7, 10, 13, 14, 16, 20, 26, 47, 58, 27, 31, 44, 61, 63, 17, 41, 42] num: 26
INFO 01-06 17:11:03.235517.235517 lmp.py:632] expert_actual_device_map {0: 'cuda:1', 1: 'cuda:1', 2: 'cuda:1', 3: 'cuda:1', 4: 'meta', 5: 'cuda:1', 6: 'cuda:1', 7: 'meta', 8: 'meta', 9: 'cuda:1', 10: 'meta', 11: 'meta', 12: 'cuda:1', 13: 'meta', 14: 'meta', 15: 'cuda:1', 16: 'meta', 17: 'meta', 18: 'cuda:1', 19: 'cuda:1', 20: 'meta', 21: 'cuda:1', 22: 'cuda:1', 23: 'cuda:1', 24: 'cuda:1', 25: 'cuda:1', 26: 'meta', 27: 'meta', 28: 'meta', 29: 'meta', 30: 'meta', 31: 'meta', 32: 'meta', 33: 'cuda:1', 34: 'meta', 35: 'cuda:1', 36: 'meta', 37: 'cuda:1', 38: 'cuda:1', 39: 'cuda:1', 40: 'cuda:1', 41: 'meta', 42: 'meta', 43: 'cuda:1', 44: 'meta', 45: 'meta', 46: 'cuda:1', 47: 'meta', 48: 'cuda:1', 49: 'cuda:1', 50: 'cuda:1', 51: 'meta', 52: 'cuda:1', 53: 'meta', 54: 'meta', 55: 'cuda:1', 56: 'cuda:1', 57: 'meta', 58: 'meta', 59: 'cuda:1', 60: 'meta', 61: 'meta', 62: 'cuda:1', 63: 'meta'}
DEBUG 01-06 17:11:03.235326.235326 cuda_h.py:19] end experts_map_get cost 0.0023970603942871094 seconds
INFO 01-06 17:11:03.235820.235820 client.py:127] Model loaded
DEBUG 01-06 17:11:03.235881.235881 cuda_h.py:10] start gpu_sexperts
DEBUG 01-06 17:11:03.236067.236067 cuda_h.py:19] end gpu_sexperts cost 0.0005691051483154297 seconds
DEBUG 01-06 17:11:03.236965.236965 cuda_h.py:10] start gpu_experts
DEBUG 01-06 17:11:03.237402.237402 cuda_h.py:19] end sllm_worker_task cost 0.013228416442871094 seconds
DEBUG 01-06 17:11:03.237610.237610 cuda_h.py:10] start sllm_worker_task
DEBUG 01-06 17:11:03.237612.237612 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 17:11:03.237401.237401 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 17:11:03.238656.238656 cuda_h.py:19] end allocate_cuda_memory cost 0.0006432533264160156 seconds
DEBUG 01-06 17:11:03.238599.238599 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 17:11:03.238547.238547 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 17:11:03.238025.238025 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 17:11:03.238059.238059 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 7b7ba95b-7d01-4883-8fab-bd6eca092733
DEBUG 01-06 17:11:03.238299.238299 client.py:106] call stub.LoadModelAsync
DEBUG 01-06 17:11:03.238396.238396 mlpmodule.py:533] gpu group tensors cost 0.0017099380493164062 s
DEBUG 01-06 17:11:03.238494.238494 mlpmodule.py:664]  experts func einsum cost 0.040383100509643555 s
INFO 01-06 17:11:03.239230.239230 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 7b7ba95b-7d01-4883-8fab-bd6eca092733
DEBUG 01-06 17:11:03.239141.239141 cuda_h.py:19] end load_into_gpu_async cost 0.0015196800231933594 seconds
DEBUG 01-06 17:11:03.239566.239566 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 17:11:03.239847.239847 cuda_h.py:19] end restore_tensors2 cost 7.152557373046875e-05 seconds
DEBUG 01-06 17:11:03.239934.239934 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0024919509887695312 seconds
INFO 01-06 17:11:03.239803.239803 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 7b7ba95b-7d01-4883-8fab-bd6eca092733
DEBUG 01-06 17:11:03.240904.240904 mlpmodule.py:566] gpu pad cost 0.0018572807312011719 s
DEBUG 01-06 17:11:03.240451.240451 mlpmodule.py:584] gpu group einsum cost 0.0004336833953857422 s
DEBUG 01-06 17:11:03.243283.243283 mlpmodule.py:613] gpu experts func einsum cost 0.006860256195068359 s
DEBUG 01-06 17:11:03.243876.243876 cuda_h.py:19] end gpu_experts cost 0.006990671157836914 seconds
DEBUG 01-06 17:11:03.243632.243632 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-06 17:11:03.243096.243096 lmp.py:661] 
DEBUG 01-06 17:11:03.243096.243096 lmp.py:661]   Computing 26 experts on CPU...
DEBUG 01-06 17:11:03.243840.243840 cuda_h.py:19] end cpu_experts_submit cost 5.650520324707031e-05 seconds
DEBUG 01-06 17:11:03.243920.243920 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-06 17:11:03.248218.248218 mlpmodule.py:706] group tensors cost 0.004009723663330078 s
INFO 01-06 17:11:03.248476.248476 client.py:127] Model loaded
DEBUG 01-06 17:11:03.249085.249085 cuda_h.py:19] end sllm_worker_task cost 0.012350082397460938 seconds
DEBUG 01-06 17:11:03.249551.249551 cuda_h.py:10] start sllm_worker_task
DEBUG 01-06 17:11:03.249121.249121 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 17:11:03.249236.249236 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 17:11:03.250316.250316 cuda_h.py:19] end allocate_cuda_memory cost 0.00020051002502441406 seconds
DEBUG 01-06 17:11:03.250259.250259 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 17:11:03.250253.250253 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 17:11:03.250493.250493 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 17:11:03.250765.250765 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, ee777e8f-e652-4b25-9b0e-ca40fa9e8c53
DEBUG 01-06 17:11:03.250814.250814 client.py:106] call stub.LoadModelAsync
DEBUG 01-06 17:11:03.251384.251384 mlpmodule.py:744] pad cost 0.002794504165649414 s
DEBUG 01-06 17:11:03.251024.251024 mlpmodule.py:750] create cpu tensor cost 4.2438507080078125e-05 s
INFO 01-06 17:11:03.251783.251783 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, ee777e8f-e652-4b25-9b0e-ca40fa9e8c53
DEBUG 01-06 17:11:03.251613.251613 mlpmodule.py:755] move to cpu cost 0.00014591217041015625 s
DEBUG 01-06 17:11:03.251967.251967 cuda_h.py:19] end load_into_gpu_async cost 0.0015311241149902344 seconds
DEBUG 01-06 17:11:03.251084.251084 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 17:11:03.252882.252882 cuda_h.py:19] end restore_tensors2 cost 6.651878356933594e-05 seconds
DEBUG 01-06 17:11:03.252161.252161 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0021445751190185547 seconds
INFO 01-06 17:11:03.252255.252255 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, ee777e8f-e652-4b25-9b0e-ca40fa9e8c53
DEBUG 01-06 17:11:03.255174.255174 mlpmodule.py:769] group_w3: shape=torch.Size([26, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=74973184
DEBUG 01-06 17:11:03.255866.255866 mlpmodule.py:770] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-06 17:11:03.255193.255193 mlpmodule.py:775] group_w3 first element: 0.0086669921875
WARNING 01-06 17:11:03.255322.255322 mlpmodule.py:785] start einsum2
DEBUG 01-06 17:11:03.261242.261242 mlpmodule.py:795] group einsum cost 0.009934663772583008 s
DEBUG 01-06 17:11:03.261772.261772 mlpmodule.py:803] cpy2cputensor cost 0.00010013580322265625 s
INFO 01-06 17:11:03.262422.262422 client.py:127] Model loaded
DEBUG 01-06 17:11:03.264830.264830 cuda_h.py:19] end sllm_worker_task cost 0.014220714569091797 seconds
DEBUG 01-06 17:11:03.264689.264689 cuda_h.py:10] start sllm_worker_task
DEBUG 01-06 17:11:03.264889.264889 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 17:11:03.264024.264024 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 17:11:03.264542.264542 cuda_h.py:19] end allocate_cuda_memory cost 0.0003910064697265625 seconds
DEBUG 01-06 17:11:03.264267.264267 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 17:11:03.264414.264414 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 17:11:03.265634.265634 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 17:11:03.265013.265013 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 3417a94a-42af-443f-b214-e9c96a8df87b
DEBUG 01-06 17:11:03.265500.265500 client.py:106] call stub.LoadModelAsync
INFO 01-06 17:11:03.266413.266413 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 3417a94a-42af-443f-b214-e9c96a8df87b
DEBUG 01-06 17:11:03.266547.266547 cuda_h.py:19] end load_into_gpu_async cost 0.0016078948974609375 seconds
DEBUG 01-06 17:11:03.266495.266495 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 17:11:03.266785.266785 cuda_h.py:19] end restore_tensors2 cost 0.00011301040649414062 seconds
DEBUG 01-06 17:11:03.266217.266217 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0024213790893554688 seconds
INFO 01-06 17:11:03.266934.266934 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 3417a94a-42af-443f-b214-e9c96a8df87b
DEBUG 01-06 17:11:03.268783.268783 cuda_h.py:19] end wait_cetm_experts cost 0.024918079376220703 seconds
DEBUG 01-06 17:11:03.269798.269798 cuda_h.py:19] end layer_moe_dgenerate_4 cost 0.03663349151611328 seconds
DEBUG 01-06 17:11:03.269161.269161 lmp.py:325] -------------------------------- end decode layer 4 --------------------------------
DEBUG 01-06 17:11:03.269023.269023 lmp.py:298] -------------------------------- start decode layer 5 --------------------------------
DEBUG 01-06 17:11:03.269580.269580 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-06 17:11:03.269497.269497 mlpmodule.py:367] cuda:1 cuda:1
DEBUG 01-06 17:11:03.269085.269085 cuda_h.py:10] start self_attn
cos shape torch.Size([65, 128]) sin shape torch.Size([65, 128]) position_ids tensor([[0]], device='cuda:1')
cos shape torch.Size([1, 1, 1, 128]) sin shape torch.Size([1, 1, 1, 128])
q_embed shape torch.Size([32, 16, 1, 128]) k_embed shape torch.Size([32, 16, 1, 128])
DEBUG 01-06 17:11:03.271600.271600 cuda_h.py:19] end self_attn cost 0.0018639564514160156 seconds
DEBUG 01-06 17:11:03.272128.272128 cuda_h.py:19] end iln_self_attn_paln cost 0.0026869773864746094 seconds
DEBUG 01-06 17:11:03.272772.272772 cuda_h.py:10] start layer_moe_dgenerate_5
DEBUG 01-06 17:11:03.272827.272827 cuda_h.py:10] start gate
DEBUG 01-06 17:11:03.272386.272386 cuda_h.py:19] end gate cost 0.0006539821624755859 seconds
DEBUG 01-06 17:11:03.272507.272507 cuda_h.py:10] start experts_map_get
INFO 01-06 17:11:03.273718.273718 lmp.py:611] using loaded check layer: False
INFO 01-06 17:11:03.273644.273644 lmp.py:620] 
INFO 01-06 17:11:03.273644.273644 lmp.py:620] Layer 5 Expert Device Distribution:
INFO 01-06 17:11:03.273268.273268 lmp.py:621]   Active experts: 58 (out of 64 total)
INFO 01-06 17:11:03.273017.273017 lmp.py:622] 
INFO 01-06 17:11:03.273017.273017 lmp.py:622]   Detailed Expert Distribution:
INFO 01-06 17:11:03.273720.273720 lmp.py:623]   Expert ID  | Tokens     | Actual Device  
INFO 01-06 17:11:03.273085.273085 lmp.py:624]   ----------------------------------------------------------------------
INFO 01-06 17:11:03.273927.273927 lmp.py:627]   11         | 1          |  cuda:1         
INFO 01-06 17:11:03.273861.273861 lmp.py:627]   22         | 1          |  meta           
INFO 01-06 17:11:03.273796.273796 lmp.py:627]   29         | 1          |  cuda:1         
INFO 01-06 17:11:03.273015.273015 lmp.py:627]   37         | 1          |  cuda:1         
INFO 01-06 17:11:03.274234.274234 lmp.py:627]   38         | 1          |  cuda:1         
INFO 01-06 17:11:03.274692.274692 lmp.py:627]   49         | 1          |  cuda:1         
INFO 01-06 17:11:03.274388.274388 lmp.py:627]   50         | 1          |  cuda:1         
INFO 01-06 17:11:03.274899.274899 lmp.py:627]   51         | 1          |  cuda:1         
INFO 01-06 17:11:03.274310.274310 lmp.py:627]   52         | 1          |  meta           
INFO 01-06 17:11:03.274721.274721 lmp.py:627]   61         | 1          |  meta           
INFO 01-06 17:11:03.274894.274894 lmp.py:627]   62         | 1          |  cuda:1         
INFO 01-06 17:11:03.274829.274829 lmp.py:627]   3          | 2          |  meta           
INFO 01-06 17:11:03.274478.274478 lmp.py:627]   4          | 2          |  meta           
INFO 01-06 17:11:03.274651.274651 lmp.py:627]   13         | 2          |  meta           
INFO 01-06 17:11:03.274063.274063 lmp.py:627]   16         | 2          |  meta           
INFO 01-06 17:11:03.274474.274474 lmp.py:627]   18         | 2          |  cuda:1         
INFO 01-06 17:11:03.274170.274170 lmp.py:627]   25         | 2          |  meta           
INFO 01-06 17:11:03.274582.274582 lmp.py:627]   27         | 2          |  cuda:1         
INFO 01-06 17:11:03.274947.274947 lmp.py:627]   35         | 2          |  meta           
INFO 01-06 17:11:03.274835.274835 lmp.py:627]   36         | 2          |  meta           
INFO 01-06 17:11:03.274723.274723 lmp.py:627]   44         | 2          |  meta           
INFO 01-06 17:11:03.274657.274657 lmp.py:627]   45         | 2          |  meta           
INFO 01-06 17:11:03.274354.274354 lmp.py:627]   59         | 2          |  cuda:1         
INFO 01-06 17:11:03.274526.274526 lmp.py:627]   8          | 3          |  meta           
INFO 01-06 17:11:03.274223.274223 lmp.py:627]   9          | 3          |  meta           
INFO 01-06 17:11:03.274634.274634 lmp.py:627]   10         | 3          |  cuda:1         
INFO 01-06 17:11:03.274045.274045 lmp.py:627]   17         | 3          |  meta           
INFO 01-06 17:11:03.274695.274695 lmp.py:627]   21         | 3          |  cuda:1         
INFO 01-06 17:11:03.274583.274583 lmp.py:627]   23         | 3          |  meta           
INFO 01-06 17:11:03.274710.274710 lmp.py:627]   26         | 3          |  cuda:1         
INFO 01-06 17:11:03.274360.274360 lmp.py:627]   31         | 3          |  meta           
INFO 01-06 17:11:03.274248.274248 lmp.py:627]   32         | 3          |  meta           
INFO 01-06 17:11:03.274944.274944 lmp.py:627]   39         | 3          |  meta           
INFO 01-06 17:11:03.274117.274117 lmp.py:627]   55         | 3          |  cuda:1         
INFO 01-06 17:11:03.274051.274051 lmp.py:627]   60         | 3          |  meta           
INFO 01-06 17:11:03.274986.274986 lmp.py:627]   6          | 4          |  cuda:1         
INFO 01-06 17:11:03.274874.274874 lmp.py:627]   12         | 4          |  meta           
INFO 01-06 17:11:03.274239.274239 lmp.py:627]   14         | 4          |  meta           
INFO 01-06 17:11:03.274604.274604 lmp.py:627]   15         | 4          |  meta           
INFO 01-06 17:11:03.274731.274731 lmp.py:627]   24         | 4          |  cuda:1         
INFO 01-06 17:11:03.274142.274142 lmp.py:627]   28         | 4          |  meta           
INFO 01-06 17:11:03.274553.274553 lmp.py:627]   30         | 4          |  meta           
INFO 01-06 17:11:03.274965.274965 lmp.py:627]   43         | 4          |  cuda:1         
INFO 01-06 17:11:03.274899.274899 lmp.py:627]   46         | 4          |  meta           
INFO 01-06 17:11:03.274026.274026 lmp.py:627]   47         | 4          |  cuda:1         
INFO 01-06 17:11:03.274152.274152 lmp.py:627]   57         | 4          |  meta           
INFO 01-06 17:11:03.274756.274756 lmp.py:627]   58         | 4          |  cuda:1         
INFO 01-06 17:11:03.274167.274167 lmp.py:627]   63         | 4          |  cuda:1         
INFO 01-06 17:11:03.275513.275513 lmp.py:627]   5          | 5          |  meta           
INFO 01-06 17:11:03.275693.275693 lmp.py:627]   7          | 5          |  cuda:1         
INFO 01-06 17:11:03.275819.275819 lmp.py:627]   40         | 5          |  cuda:1         
INFO 01-06 17:11:03.275469.275469 lmp.py:627]   42         | 5          |  meta           
INFO 01-06 17:11:03.275119.275119 lmp.py:627]   56         | 6          |  cuda:1         
INFO 01-06 17:11:03.275769.275769 lmp.py:627]   1          | 7          |  cuda:1         
INFO 01-06 17:11:03.275372.275372 lmp.py:627]   19         | 7          |  cuda:1         
INFO 01-06 17:11:03.275975.275975 lmp.py:627]   33         | 7          |  cuda:1         
INFO 01-06 17:11:03.275294.275294 lmp.py:627]   48         | 8          |  cuda:1         
INFO 01-06 17:11:03.275659.275659 lmp.py:627]   53         | 14         |  cuda:1         
INFO 01-06 17:11:03.275547.275547 lmp.py:628] ============================================================
INFO 01-06 17:11:03.275547.275547 lmp.py:628] 
INFO 01-06 17:11:03.275919.275919 lmp.py:630] experts_gpu_list: [11, 29, 37, 38, 49, 50, 51, 62, 18, 27, 59, 10, 21, 26, 55, 6, 24, 43, 47, 58, 63, 7, 40, 56, 1, 19, 33, 48, 53] num: 29
INFO 01-06 17:11:03.275192.275192 lmp.py:631] experts_cpu_list: [22, 52, 61, 3, 4, 13, 16, 25, 35, 36, 44, 45, 8, 9, 17, 23, 31, 32, 39, 60, 12, 14, 15, 28, 30, 46, 57, 5, 42] num: 29
INFO 01-06 17:11:03.275431.275431 lmp.py:632] expert_actual_device_map {0: 'meta', 1: 'cuda:1', 2: 'meta', 3: 'meta', 4: 'meta', 5: 'meta', 6: 'cuda:1', 7: 'cuda:1', 8: 'meta', 9: 'meta', 10: 'cuda:1', 11: 'cuda:1', 12: 'meta', 13: 'meta', 14: 'meta', 15: 'meta', 16: 'meta', 17: 'meta', 18: 'cuda:1', 19: 'cuda:1', 20: 'cuda:1', 21: 'cuda:1', 22: 'meta', 23: 'meta', 24: 'cuda:1', 25: 'meta', 26: 'cuda:1', 27: 'cuda:1', 28: 'meta', 29: 'cuda:1', 30: 'meta', 31: 'meta', 32: 'meta', 33: 'cuda:1', 34: 'meta', 35: 'meta', 36: 'meta', 37: 'cuda:1', 38: 'cuda:1', 39: 'meta', 40: 'cuda:1', 41: 'cuda:1', 42: 'meta', 43: 'cuda:1', 44: 'meta', 45: 'meta', 46: 'meta', 47: 'cuda:1', 48: 'cuda:1', 49: 'cuda:1', 50: 'cuda:1', 51: 'cuda:1', 52: 'meta', 53: 'cuda:1', 54: 'cuda:1', 55: 'cuda:1', 56: 'cuda:1', 57: 'meta', 58: 'cuda:1', 59: 'cuda:1', 60: 'meta', 61: 'meta', 62: 'cuda:1', 63: 'cuda:1'}
DEBUG 01-06 17:11:03.275763.275763 cuda_h.py:19] end experts_map_get cost 0.002472400665283203 seconds
DEBUG 01-06 17:11:03.275409.275409 cuda_h.py:10] start gpu_sexperts
INFO 01-06 17:11:03.275579.275579 client.py:127] Model loaded
DEBUG 01-06 17:11:03.276655.276655 cuda_h.py:19] end gpu_sexperts cost 0.0005934238433837891 seconds
DEBUG 01-06 17:11:03.276367.276367 cuda_h.py:10] start gpu_experts
DEBUG 01-06 17:11:03.276274.276274 mlpmodule.py:533] gpu group tensors cost 0.0006966590881347656 s
DEBUG 01-06 17:11:03.277100.277100 cuda_h.py:19] end sllm_worker_task cost 0.012826681137084961 seconds
DEBUG 01-06 17:11:03.277202.277202 cuda_h.py:10] start sllm_worker_task
DEBUG 01-06 17:11:03.277442.277442 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 17:11:03.277994.277994 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 17:11:03.278431.278431 cuda_h.py:19] end allocate_cuda_memory cost 0.0007772445678710938 seconds
DEBUG 01-06 17:11:03.278581.278581 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 17:11:03.278151.278151 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 17:11:03.278391.278391 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 17:11:03.278710.278710 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 79ae151b-1736-4c9d-8555-72965d39f02f
DEBUG 01-06 17:11:03.278805.278805 client.py:106] call stub.LoadModelAsync
DEBUG 01-06 17:11:03.278836.278836 mlpmodule.py:664]  experts func einsum cost 0.03453779220581055 s
INFO 01-06 17:11:03.279914.279914 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 79ae151b-1736-4c9d-8555-72965d39f02f
DEBUG 01-06 17:11:03.279156.279156 cuda_h.py:19] end load_into_gpu_async cost 0.001506805419921875 seconds
DEBUG 01-06 17:11:03.279627.279627 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 17:11:03.279809.279809 cuda_h.py:19] end restore_tensors2 cost 7.2479248046875e-05 seconds
DEBUG 01-06 17:11:03.279327.279327 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.002660512924194336 seconds
INFO 01-06 17:11:03.280209.280209 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 79ae151b-1736-4c9d-8555-72965d39f02f
DEBUG 01-06 17:11:03.280052.280052 mlpmodule.py:566] gpu pad cost 0.0035550594329833984 s
DEBUG 01-06 17:11:03.281692.281692 mlpmodule.py:584] gpu group einsum cost 0.0004279613494873047 s
DEBUG 01-06 17:11:03.283408.283408 mlpmodule.py:613] gpu experts func einsum cost 0.007466554641723633 s
DEBUG 01-06 17:11:03.283855.283855 cuda_h.py:19] end gpu_experts cost 0.007591724395751953 seconds
DEBUG 01-06 17:11:03.283273.283273 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-06 17:11:03.283307.283307 lmp.py:661] 
DEBUG 01-06 17:11:03.283307.283307 lmp.py:661]   Computing 29 experts on CPU...
DEBUG 01-06 17:11:03.283143.283143 cuda_h.py:19] end cpu_experts_submit cost 5.4836273193359375e-05 seconds
DEBUG 01-06 17:11:03.283746.283746 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-06 17:11:03.292699.292699 mlpmodule.py:706] group tensors cost 0.00850820541381836 s
INFO 01-06 17:11:03.293403.293403 client.py:127] Model loaded
DEBUG 01-06 17:11:03.294872.294872 cuda_h.py:19] end sllm_worker_task cost 0.017372846603393555 seconds
DEBUG 01-06 17:11:03.294325.294325 cuda_h.py:10] start sllm_worker_task
DEBUG 01-06 17:11:03.294386.294386 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 17:11:03.294468.294468 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 17:11:03.295980.295980 cuda_h.py:19] end allocate_cuda_memory cost 0.0002238750457763672 seconds
DEBUG 01-06 17:11:03.295321.295321 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 17:11:03.295952.295952 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 17:11:03.295298.295298 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 17:11:03.295769.295769 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 42df49eb-3934-454c-9870-6e819fb122f0
DEBUG 01-06 17:11:03.295315.295315 client.py:106] call stub.LoadModelAsync
DEBUG 01-06 17:11:03.296330.296330 mlpmodule.py:744] pad cost 0.003359079360961914 s
DEBUG 01-06 17:11:03.296176.296176 mlpmodule.py:750] create cpu tensor cost 4.9114227294921875e-05 s
DEBUG 01-06 17:11:03.296655.296655 mlpmodule.py:755] move to cpu cost 3.266334533691406e-05 s
INFO 01-06 17:11:03.297421.297421 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 42df49eb-3934-454c-9870-6e819fb122f0
DEBUG 01-06 17:11:03.297073.297073 cuda_h.py:19] end load_into_gpu_async cost 0.0018396377563476562 seconds
DEBUG 01-06 17:11:03.297836.297836 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 17:11:03.297469.297469 cuda_h.py:19] end restore_tensors2 cost 8.463859558105469e-05 seconds
DEBUG 01-06 17:11:03.297616.297616 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.002488374710083008 seconds
INFO 01-06 17:11:03.297532.297532 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 42df49eb-3934-454c-9870-6e819fb122f0
DEBUG 01-06 17:11:03.300927.300927 mlpmodule.py:769] group_w3: shape=torch.Size([29, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=83623936
DEBUG 01-06 17:11:03.300943.300943 mlpmodule.py:770] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-06 17:11:03.300568.300568 mlpmodule.py:775] group_w3 first element: -0.022705078125
WARNING 01-06 17:11:03.300929.300929 mlpmodule.py:785] start einsum2
INFO 01-06 17:11:03.307572.307572 client.py:127] Model loaded
DEBUG 01-06 17:11:03.308087.308087 mlpmodule.py:795] group einsum cost 0.01108241081237793 s
DEBUG 01-06 17:11:03.308571.308571 mlpmodule.py:803] cpy2cputensor cost 0.00012493133544921875 s
DEBUG 01-06 17:11:03.309832.309832 cuda_h.py:19] end sllm_worker_task cost 0.014487981796264648 seconds
DEBUG 01-06 17:11:03.309439.309439 cuda_h.py:10] start sllm_worker_task
DEBUG 01-06 17:11:03.309308.309308 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 17:11:03.309443.309443 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 17:11:03.309955.309955 cuda_h.py:19] end allocate_cuda_memory cost 0.0004055500030517578 seconds
DEBUG 01-06 17:11:03.310706.310706 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 17:11:03.310476.310476 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 17:11:03.310935.310935 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 17:11:03.310883.310883 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 5417c583-204e-4b7d-9e2a-6e6c1f576893
DEBUG 01-06 17:11:03.310747.310747 client.py:106] call stub.LoadModelAsync
INFO 01-06 17:11:03.311522.311522 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 5417c583-204e-4b7d-9e2a-6e6c1f576893
DEBUG 01-06 17:11:03.311995.311995 cuda_h.py:19] end load_into_gpu_async cost 0.001646280288696289 seconds
DEBUG 01-06 17:11:03.311704.311704 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 17:11:03.311186.311186 cuda_h.py:19] end restore_tensors2 cost 0.00011467933654785156 seconds
DEBUG 01-06 17:11:03.311664.311664 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0024781227111816406 seconds
INFO 01-06 17:11:03.312435.312435 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 5417c583-204e-4b7d-9e2a-6e6c1f576893
DEBUG 01-06 17:11:03.314523.314523 cuda_h.py:19] end wait_cetm_experts cost 0.03046560287475586 seconds
DEBUG 01-06 17:11:03.314064.314064 cuda_h.py:19] end layer_moe_dgenerate_5 cost 0.04269146919250488 seconds
DEBUG 01-06 17:11:03.315416.315416 lmp.py:325] -------------------------------- end decode layer 5 --------------------------------
DEBUG 01-06 17:11:03.315458.315458 lmp.py:298] -------------------------------- start decode layer 6 --------------------------------
DEBUG 01-06 17:11:03.315519.315519 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-06 17:11:03.315034.315034 mlpmodule.py:367] cuda:1 cuda:1
DEBUG 01-06 17:11:03.315004.315004 cuda_h.py:10] start self_attn
cos shape torch.Size([65, 128]) sin shape torch.Size([65, 128]) position_ids tensor([[0]], device='cuda:1')
cos shape torch.Size([1, 1, 1, 128]) sin shape torch.Size([1, 1, 1, 128])
q_embed shape torch.Size([32, 16, 1, 128]) k_embed shape torch.Size([32, 16, 1, 128])
DEBUG 01-06 17:11:03.317103.317103 cuda_h.py:19] end self_attn cost 0.0019097328186035156 seconds
DEBUG 01-06 17:11:03.318737.318737 cuda_h.py:19] end iln_self_attn_paln cost 0.0028734207153320312 seconds
DEBUG 01-06 17:11:03.318003.318003 cuda_h.py:10] start layer_moe_dgenerate_6
DEBUG 01-06 17:11:03.318018.318018 cuda_h.py:10] start gate
DEBUG 01-06 17:11:03.318889.318889 cuda_h.py:19] end gate cost 0.0006341934204101562 seconds
DEBUG 01-06 17:11:03.318778.318778 cuda_h.py:10] start experts_map_get
INFO 01-06 17:11:03.319061.319061 lmp.py:609] using loaded check layer: True
INFO 01-06 17:11:03.319265.319265 lmp.py:620] 
INFO 01-06 17:11:03.319265.319265 lmp.py:620] Layer 6 Expert Device Distribution:
INFO 01-06 17:11:03.319418.319418 lmp.py:621]   Active experts: 56 (out of 64 total)
INFO 01-06 17:11:03.319452.319452 lmp.py:622] 
INFO 01-06 17:11:03.319452.319452 lmp.py:622]   Detailed Expert Distribution:
INFO 01-06 17:11:03.319201.319201 lmp.py:623]   Expert ID  | Tokens     | Actual Device  
INFO 01-06 17:11:03.319851.319851 lmp.py:624]   ----------------------------------------------------------------------
INFO 01-06 17:11:03.319408.319408 lmp.py:627]   0          | 1          |  cuda:1         
INFO 01-06 17:11:03.319581.319581 lmp.py:627]   7          | 1          |  cuda:1         
INFO 01-06 17:11:03.320277.320277 lmp.py:627]   17         | 1          |  meta           
INFO 01-06 17:11:03.320973.320973 lmp.py:627]   23         | 1          |  meta           
INFO 01-06 17:11:03.320670.320670 lmp.py:627]   29         | 1          |  meta           
INFO 01-06 17:11:03.320889.320889 lmp.py:627]   30         | 1          |  cuda:1         
INFO 01-06 17:11:03.320870.320870 lmp.py:627]   31         | 1          |  cuda:1         
INFO 01-06 17:11:03.320566.320566 lmp.py:627]   32         | 1          |  meta           
INFO 01-06 17:11:03.320977.320977 lmp.py:627]   47         | 1          |  cuda:1         
INFO 01-06 17:11:03.320912.320912 lmp.py:627]   48         | 1          |  cuda:1         
INFO 01-06 17:11:03.320561.320561 lmp.py:627]   53         | 1          |  meta           
INFO 01-06 17:11:03.320257.320257 lmp.py:627]   57         | 1          |  cuda:1         
INFO 01-06 17:11:03.320715.320715 lmp.py:627]   59         | 1          |  meta           
INFO 01-06 17:11:03.320650.320650 lmp.py:627]   1          | 2          |  cuda:1         
INFO 01-06 17:11:03.320107.320107 lmp.py:627]   6          | 2          |  cuda:1         
INFO 01-06 17:11:03.320042.320042 lmp.py:627]   8          | 2          |  cuda:1         
INFO 01-06 17:11:03.320453.320453 lmp.py:627]   14         | 2          |  meta           
INFO 01-06 17:11:03.320626.320626 lmp.py:627]   20         | 2          |  cuda:1         
INFO 01-06 17:11:03.320799.320799 lmp.py:627]   24         | 2          |  cuda:1         
INFO 01-06 17:11:03.320734.320734 lmp.py:627]   33         | 2          |  meta           
INFO 01-06 17:11:03.320073.320073 lmp.py:627]   34         | 2          |  cuda:1         
INFO 01-06 17:11:03.320530.320530 lmp.py:627]   35         | 2          |  cuda:1         
INFO 01-06 17:11:03.320134.320134 lmp.py:627]   49         | 2          |  cuda:1         
INFO 01-06 17:11:03.320260.320260 lmp.py:627]   50         | 2          |  cuda:1         
INFO 01-06 17:11:03.320718.320718 lmp.py:627]   52         | 2          |  cuda:1         
INFO 01-06 17:11:03.320129.320129 lmp.py:627]   54         | 2          |  meta           
INFO 01-06 17:11:03.320779.320779 lmp.py:627]   61         | 2          |  cuda:1         
INFO 01-06 17:11:03.320952.320952 lmp.py:627]   10         | 3          |  meta           
INFO 01-06 17:11:03.320125.320125 lmp.py:627]   11         | 3          |  meta           
INFO 01-06 17:11:03.320583.320583 lmp.py:627]   13         | 3          |  meta           
INFO 01-06 17:11:03.320040.320040 lmp.py:627]   19         | 3          |  cuda:1         
INFO 01-06 17:11:03.320736.320736 lmp.py:627]   46         | 3          |  cuda:1         
INFO 01-06 17:11:03.320956.320956 lmp.py:627]   58         | 3          |  meta           
INFO 01-06 17:11:03.320652.320652 lmp.py:627]   63         | 3          |  meta           
INFO 01-06 17:11:03.320871.320871 lmp.py:627]   2          | 4          |  cuda:1         
INFO 01-06 17:11:03.320805.320805 lmp.py:627]   4          | 4          |  cuda:1         
INFO 01-06 17:11:03.320217.320217 lmp.py:627]   15         | 4          |  cuda:1         
INFO 01-06 17:11:03.320105.320105 lmp.py:627]   21         | 4          |  cuda:1         
INFO 01-06 17:11:03.320755.320755 lmp.py:627]   22         | 4          |  meta           
INFO 01-06 17:11:03.320689.320689 lmp.py:627]   40         | 4          |  meta           
INFO 01-06 17:11:03.320147.320147 lmp.py:627]   42         | 4          |  cuda:1         
INFO 01-06 17:11:03.320366.320366 lmp.py:627]   44         | 4          |  cuda:1         
INFO 01-06 17:11:03.320585.320585 lmp.py:627]   62         | 4          |  meta           
INFO 01-06 17:11:03.320043.320043 lmp.py:627]   5          | 5          |  cuda:1         
INFO 01-06 17:11:03.320501.320501 lmp.py:627]   43         | 5          |  meta           
INFO 01-06 17:11:03.320958.320958 lmp.py:627]   51         | 5          |  meta           
INFO 01-06 17:11:03.320416.320416 lmp.py:627]   56         | 5          |  cuda:1         
INFO 01-06 17:11:03.321351.321351 lmp.py:627]   60         | 5          |  cuda:1         
INFO 01-06 17:11:03.321285.321285 lmp.py:627]   55         | 6          |  meta           
INFO 01-06 17:11:03.321220.321220 lmp.py:627]   12         | 7          |  cuda:1         
INFO 01-06 17:11:03.321439.321439 lmp.py:627]   27         | 7          |  cuda:1         
INFO 01-06 17:11:03.321658.321658 lmp.py:627]   28         | 7          |  meta           
INFO 01-06 17:11:03.321116.321116 lmp.py:627]   36         | 9          |  cuda:1         
INFO 01-06 17:11:03.321673.321673 lmp.py:627]   38         | 10         |  cuda:1         
INFO 01-06 17:11:03.321608.321608 lmp.py:627]   25         | 11         |  cuda:1         
INFO 01-06 17:11:03.321588.321588 lmp.py:627]   39         | 12         |  cuda:1         
INFO 01-06 17:11:03.321092.321092 lmp.py:628] ============================================================
INFO 01-06 17:11:03.321092.321092 lmp.py:628] 
INFO 01-06 17:11:03.321510.321510 lmp.py:630] experts_gpu_list: [0, 7, 30, 31, 47, 48, 57, 1, 6, 8, 20, 24, 34, 35, 49, 50, 52, 61, 19, 46, 2, 4, 15, 21, 42, 44, 5, 56, 60, 12, 27, 36, 38, 25, 39] num: 35
INFO 01-06 17:11:03.321829.321829 lmp.py:631] experts_cpu_list: [17, 23, 29, 32, 53, 59, 14, 33, 54, 10, 11, 13, 58, 63, 22, 40, 62, 43, 51, 55, 28] num: 21
INFO 01-06 17:11:03.321784.321784 lmp.py:632] expert_actual_device_map {0: 'cuda:1', 1: 'cuda:1', 2: 'cuda:1', 3: 'cuda:1', 4: 'cuda:1', 5: 'cuda:1', 6: 'cuda:1', 7: 'cuda:1', 8: 'cuda:1', 9: 'meta', 10: 'meta', 11: 'meta', 12: 'cuda:1', 13: 'meta', 14: 'meta', 15: 'cuda:1', 16: 'meta', 17: 'meta', 18: 'meta', 19: 'cuda:1', 20: 'cuda:1', 21: 'cuda:1', 22: 'meta', 23: 'meta', 24: 'cuda:1', 25: 'cuda:1', 26: 'meta', 27: 'cuda:1', 28: 'meta', 29: 'meta', 30: 'cuda:1', 31: 'cuda:1', 32: 'meta', 33: 'meta', 34: 'cuda:1', 35: 'cuda:1', 36: 'cuda:1', 37: 'meta', 38: 'cuda:1', 39: 'cuda:1', 40: 'meta', 41: 'cuda:1', 42: 'cuda:1', 43: 'meta', 44: 'cuda:1', 45: 'meta', 46: 'cuda:1', 47: 'cuda:1', 48: 'cuda:1', 49: 'cuda:1', 50: 'cuda:1', 51: 'meta', 52: 'cuda:1', 53: 'meta', 54: 'meta', 55: 'meta', 56: 'cuda:1', 57: 'cuda:1', 58: 'meta', 59: 'meta', 60: 'cuda:1', 61: 'cuda:1', 62: 'meta', 63: 'meta'}
DEBUG 01-06 17:11:03.321593.321593 cuda_h.py:19] end experts_map_get cost 0.0023572444915771484 seconds
INFO 01-06 17:11:03.321020.321020 client.py:127] Model loaded
DEBUG 01-06 17:11:03.321952.321952 cuda_h.py:10] start gpu_sexperts
DEBUG 01-06 17:11:03.322222.322222 cuda_h.py:19] end sllm_worker_task cost 0.013028860092163086 seconds
DEBUG 01-06 17:11:03.322721.322721 cuda_h.py:10] start sllm_worker_task
DEBUG 01-06 17:11:03.322153.322153 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 17:11:03.322427.322427 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 17:11:03.325449.325449 cuda_h.py:19] end allocate_cuda_memory cost 0.0026092529296875 seconds
DEBUG 01-06 17:11:03.325868.325868 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 17:11:03.325340.325340 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 17:11:03.325771.325771 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 17:11:03.325759.325759 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 6e7d0d5b-82f5-4b00-941c-0a0ceccd78cf
DEBUG 01-06 17:11:03.325477.325477 client.py:106] call stub.LoadModelAsync
DEBUG 01-06 17:11:03.325355.325355 cuda_h.py:19] end gpu_sexperts cost 0.0038497447967529297 seconds
DEBUG 01-06 17:11:03.325154.325154 mlpmodule.py:664]  experts func einsum cost 0.04168844223022461 s
DEBUG 01-06 17:11:03.325309.325309 cuda_h.py:10] start gpu_experts
INFO 01-06 17:11:03.326340.326340 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 6e7d0d5b-82f5-4b00-941c-0a0ceccd78cf
DEBUG 01-06 17:11:03.326111.326111 cuda_h.py:19] end load_into_gpu_async cost 0.0014772415161132812 seconds
DEBUG 01-06 17:11:03.326052.326052 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 17:11:03.327095.327095 cuda_h.py:19] end restore_tensors2 cost 0.00025153160095214844 seconds
DEBUG 01-06 17:11:03.327520.327520 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.004595518112182617 seconds
INFO 01-06 17:11:03.327548.327548 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 6e7d0d5b-82f5-4b00-941c-0a0ceccd78cf
DEBUG 01-06 17:11:03.327239.327239 mlpmodule.py:533] gpu group tensors cost 0.0014231204986572266 s
DEBUG 01-06 17:11:03.329902.329902 mlpmodule.py:566] gpu pad cost 0.001544952392578125 s
DEBUG 01-06 17:11:03.329720.329720 mlpmodule.py:584] gpu group einsum cost 0.00043582916259765625 s
DEBUG 01-06 17:11:03.332786.332786 mlpmodule.py:613] gpu experts func einsum cost 0.006674766540527344 s
DEBUG 01-06 17:11:03.332424.332424 cuda_h.py:19] end gpu_experts cost 0.006811857223510742 seconds
DEBUG 01-06 17:11:03.332942.332942 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-06 17:11:03.332645.332645 lmp.py:661] 
DEBUG 01-06 17:11:03.332645.332645 lmp.py:661]   Computing 21 experts on CPU...
DEBUG 01-06 17:11:03.333719.333719 cuda_h.py:19] end cpu_experts_submit cost 5.340576171875e-05 seconds
DEBUG 01-06 17:11:03.333561.333561 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-06 17:11:03.341755.341755 mlpmodule.py:706] group tensors cost 0.008406639099121094 s
INFO 01-06 17:11:03.342994.342994 client.py:127] Model loaded
DEBUG 01-06 17:11:03.344807.344807 cuda_h.py:19] end sllm_worker_task cost 0.02150416374206543 seconds
DEBUG 01-06 17:11:03.345302.345302 mlpmodule.py:744] pad cost 0.002481698989868164 s
DEBUG 01-06 17:11:03.345279.345279 mlpmodule.py:750] create cpu tensor cost 4.57763671875e-05 s
DEBUG 01-06 17:11:03.345235.345235 mlpmodule.py:755] move to cpu cost 3.337860107421875e-05 s
DEBUG 01-06 17:11:03.348846.348846 mlpmodule.py:769] group_w3: shape=torch.Size([21, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=60555264
DEBUG 01-06 17:11:03.348332.348332 mlpmodule.py:770] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-06 17:11:03.348878.348878 mlpmodule.py:775] group_w3 first element: -0.032958984375
WARNING 01-06 17:11:03.348537.348537 mlpmodule.py:785] start einsum2
DEBUG 01-06 17:11:03.353998.353998 mlpmodule.py:795] group einsum cost 0.008490562438964844 s
DEBUG 01-06 17:11:03.353110.353110 mlpmodule.py:803] cpy2cputensor cost 0.00012373924255371094 s
DEBUG 01-06 17:11:03.356155.356155 cuda_h.py:19] end wait_cetm_experts cost 0.02377462387084961 seconds
DEBUG 01-06 17:11:03.357168.357168 cuda_h.py:19] end layer_moe_dgenerate_6 cost 0.03908944129943848 seconds
DEBUG 01-06 17:11:03.357346.357346 lmp.py:325] -------------------------------- end decode layer 6 --------------------------------
DEBUG 01-06 17:11:03.357970.357970 lmp.py:298] -------------------------------- start decode layer 7 --------------------------------
DEBUG 01-06 17:11:03.357196.357196 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-06 17:11:03.357789.357789 mlpmodule.py:367] cuda:1 cuda:1
DEBUG 01-06 17:11:03.358768.358768 cuda_h.py:10] start self_attn
cos shape torch.Size([65, 128]) sin shape torch.Size([65, 128]) position_ids tensor([[0]], device='cuda:1')
cos shape torch.Size([1, 1, 1, 128]) sin shape torch.Size([1, 1, 1, 128])
q_embed shape torch.Size([32, 16, 1, 128]) k_embed shape torch.Size([32, 16, 1, 128])
DEBUG 01-06 17:11:03.359959.359959 cuda_h.py:19] end self_attn cost 0.001867532730102539 seconds
DEBUG 01-06 17:11:03.360685.360685 cuda_h.py:19] end iln_self_attn_paln cost 0.002713441848754883 seconds
DEBUG 01-06 17:11:03.360329.360329 cuda_h.py:10] start layer_moe_dgenerate_7
DEBUG 01-06 17:11:03.360437.360437 cuda_h.py:10] start gate
DEBUG 01-06 17:11:03.361650.361650 cuda_h.py:19] end gate cost 0.0005908012390136719 seconds
DEBUG 01-06 17:11:03.361725.361725 cuda_h.py:10] start experts_map_get
INFO 01-06 17:11:03.361472.361472 lmp.py:609] using loaded check layer: True
INFO 01-06 17:11:03.361059.361059 lmp.py:620] 
INFO 01-06 17:11:03.361059.361059 lmp.py:620] Layer 7 Expert Device Distribution:
INFO 01-06 17:11:03.361398.361398 lmp.py:621]   Active experts: 52 (out of 64 total)
INFO 01-06 17:11:03.362909.362909 lmp.py:622] 
INFO 01-06 17:11:03.362909.362909 lmp.py:622]   Detailed Expert Distribution:
INFO 01-06 17:11:03.362420.362420 lmp.py:623]   Expert ID  | Tokens     | Actual Device  
INFO 01-06 17:11:03.362593.362593 lmp.py:624]   ----------------------------------------------------------------------
INFO 01-06 17:11:03.362481.362481 lmp.py:627]   0          | 1          |  cuda:1         
INFO 01-06 17:11:03.362700.362700 lmp.py:627]   4          | 1          |  cuda:1         
INFO 01-06 17:11:03.362204.362204 lmp.py:627]   8          | 1          |  meta           
INFO 01-06 17:11:03.362423.362423 lmp.py:627]   10         | 1          |  meta           
INFO 01-06 17:11:03.362742.362742 lmp.py:627]   35         | 1          |  cuda:1         
INFO 01-06 17:11:03.362677.362677 lmp.py:627]   39         | 1          |  meta           
INFO 01-06 17:11:03.362896.362896 lmp.py:627]   40         | 1          |  meta           
INFO 01-06 17:11:03.362115.362115 lmp.py:627]   41         | 1          |  meta           
INFO 01-06 17:11:03.362573.362573 lmp.py:627]   48         | 1          |  meta           
INFO 01-06 17:11:03.362077.362077 lmp.py:627]   60         | 1          |  meta           
INFO 01-06 17:11:03.362819.362819 lmp.py:627]   1          | 2          |  cuda:1         
INFO 01-06 17:11:03.362323.362323 lmp.py:627]   6          | 2          |  cuda:1         
INFO 01-06 17:11:03.362880.362880 lmp.py:627]   11         | 2          |  meta           
INFO 01-06 17:11:03.362722.362722 lmp.py:627]   15         | 2          |  meta           
INFO 01-06 17:11:03.362326.362326 lmp.py:627]   17         | 2          |  cuda:1         
INFO 01-06 17:11:03.362121.362121 lmp.py:627]   20         | 2          |  meta           
INFO 01-06 17:11:03.362201.362201 lmp.py:627]   21         | 2          |  cuda:1         
INFO 01-06 17:11:03.362805.362805 lmp.py:627]   22         | 2          |  cuda:1         
INFO 01-06 17:11:03.362693.362693 lmp.py:627]   25         | 2          |  cuda:1         
INFO 01-06 17:11:03.362058.362058 lmp.py:627]   27         | 2          |  meta           
INFO 01-06 17:11:03.362185.362185 lmp.py:627]   30         | 2          |  cuda:1         
INFO 01-06 17:11:03.362027.362027 lmp.py:627]   33         | 2          |  cuda:1         
INFO 01-06 17:11:03.362868.362868 lmp.py:627]   51         | 2          |  meta           
INFO 01-06 17:11:03.362472.362472 lmp.py:627]   57         | 2          |  cuda:1         
INFO 01-06 17:11:03.362837.362837 lmp.py:627]   12         | 3          |  cuda:1         
INFO 01-06 17:11:03.362440.362440 lmp.py:627]   16         | 3          |  meta           
INFO 01-06 17:11:03.362852.362852 lmp.py:627]   52         | 3          |  meta           
INFO 01-06 17:11:03.362501.362501 lmp.py:627]   5          | 4          |  cuda:1         
INFO 01-06 17:11:03.362390.362390 lmp.py:627]   13         | 4          |  meta           
INFO 01-06 17:11:03.362278.362278 lmp.py:627]   18         | 4          |  meta           
INFO 01-06 17:11:03.362166.362166 lmp.py:627]   31         | 4          |  cuda:1         
INFO 01-06 17:11:03.362054.362054 lmp.py:627]   34         | 4          |  cuda:1         
INFO 01-06 17:11:03.362419.362419 lmp.py:627]   36         | 4          |  meta           
INFO 01-06 17:11:03.362546.362546 lmp.py:627]   43         | 4          |  meta           
INFO 01-06 17:11:03.362149.362149 lmp.py:627]   44         | 4          |  cuda:1         
INFO 01-06 17:11:03.362799.362799 lmp.py:627]   61         | 4          |  cuda:1         
INFO 01-06 17:11:03.362449.362449 lmp.py:627]   2          | 5          |  cuda:1         
INFO 01-06 17:11:03.362337.362337 lmp.py:627]   3          | 5          |  cuda:1         
INFO 01-06 17:11:03.362987.362987 lmp.py:627]   38         | 5          |  cuda:1         
INFO 01-06 17:11:03.362875.362875 lmp.py:627]   47         | 5          |  cuda:1         
INFO 01-06 17:11:03.362286.362286 lmp.py:627]   58         | 5          |  cuda:1         
INFO 01-06 17:11:03.363174.363174 lmp.py:627]   59         | 5          |  cuda:1         
INFO 01-06 17:11:03.363539.363539 lmp.py:627]   9          | 6          |  cuda:1         
INFO 01-06 17:11:03.363904.363904 lmp.py:627]   42         | 6          |  cuda:1         
INFO 01-06 17:11:03.363269.363269 lmp.py:627]   62         | 6          |  cuda:1         
INFO 01-06 17:11:03.363158.363158 lmp.py:627]   19         | 7          |  cuda:1         
INFO 01-06 17:11:03.363569.363569 lmp.py:627]   49         | 7          |  cuda:1         
INFO 01-06 17:11:03.363980.363980 lmp.py:627]   23         | 8          |  cuda:1         
INFO 01-06 17:11:03.363868.363868 lmp.py:627]   24         | 8          |  cuda:1         
INFO 01-06 17:11:03.363757.363757 lmp.py:627]   63         | 8          |  cuda:1         
INFO 01-06 17:11:03.363599.363599 lmp.py:627]   56         | 9          |  meta           
INFO 01-06 17:11:03.363440.363440 lmp.py:627]   26         | 14         |  cuda:1         
INFO 01-06 17:11:03.363613.363613 lmp.py:628] ============================================================
INFO 01-06 17:11:03.363613.363613 lmp.py:628] 
INFO 01-06 17:11:03.363985.363985 lmp.py:630] experts_gpu_list: [0, 4, 35, 1, 6, 17, 21, 22, 25, 30, 33, 57, 12, 5, 31, 34, 44, 61, 2, 3, 38, 47, 58, 59, 9, 42, 62, 19, 49, 23, 24, 63, 26] num: 33
INFO 01-06 17:11:03.363781.363781 lmp.py:631] experts_cpu_list: [8, 10, 39, 40, 41, 48, 60, 11, 15, 20, 27, 51, 16, 52, 13, 18, 36, 43, 56] num: 19
INFO 01-06 17:11:03.363590.363590 lmp.py:632] expert_actual_device_map {0: 'cuda:1', 1: 'cuda:1', 2: 'cuda:1', 3: 'cuda:1', 4: 'cuda:1', 5: 'cuda:1', 6: 'cuda:1', 7: 'meta', 8: 'meta', 9: 'cuda:1', 10: 'meta', 11: 'meta', 12: 'cuda:1', 13: 'meta', 14: 'meta', 15: 'meta', 16: 'meta', 17: 'cuda:1', 18: 'meta', 19: 'cuda:1', 20: 'meta', 21: 'cuda:1', 22: 'cuda:1', 23: 'cuda:1', 24: 'cuda:1', 25: 'cuda:1', 26: 'cuda:1', 27: 'meta', 28: 'meta', 29: 'meta', 30: 'cuda:1', 31: 'cuda:1', 32: 'cuda:1', 33: 'cuda:1', 34: 'cuda:1', 35: 'cuda:1', 36: 'meta', 37: 'cuda:1', 38: 'cuda:1', 39: 'meta', 40: 'meta', 41: 'meta', 42: 'cuda:1', 43: 'meta', 44: 'cuda:1', 45: 'cuda:1', 46: 'meta', 47: 'cuda:1', 48: 'meta', 49: 'cuda:1', 50: 'meta', 51: 'meta', 52: 'meta', 53: 'cuda:1', 54: 'meta', 55: 'meta', 56: 'meta', 57: 'cuda:1', 58: 'cuda:1', 59: 'cuda:1', 60: 'meta', 61: 'cuda:1', 62: 'cuda:1', 63: 'cuda:1'}
DEBUG 01-06 17:11:03.363637.363637 cuda_h.py:19] end experts_map_get cost 0.0022897720336914062 seconds
DEBUG 01-06 17:11:03.363449.363449 cuda_h.py:10] start gpu_sexperts
DEBUG 01-06 17:11:03.363222.363222 cuda_h.py:19] end gpu_sexperts cost 0.0003120899200439453 seconds
DEBUG 01-06 17:11:03.363383.363383 cuda_h.py:10] start gpu_experts
DEBUG 01-06 17:11:03.364797.364797 mlpmodule.py:533] gpu group tensors cost 0.0006225109100341797 s
DEBUG 01-06 17:11:03.365759.365759 mlpmodule.py:664]  experts func einsum cost 0.03265738487243652 s
DEBUG 01-06 17:11:03.366610.366610 mlpmodule.py:566] gpu pad cost 0.0018601417541503906 s
DEBUG 01-06 17:11:03.367472.367472 mlpmodule.py:584] gpu group einsum cost 0.0005030632019042969 s
DEBUG 01-06 17:11:03.370606.370606 mlpmodule.py:613] gpu experts func einsum cost 0.006588935852050781 s
DEBUG 01-06 17:11:03.370960.370960 cuda_h.py:19] end gpu_experts cost 0.006714820861816406 seconds
DEBUG 01-06 17:11:03.370100.370100 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-06 17:11:03.370088.370088 lmp.py:661] 
DEBUG 01-06 17:11:03.370088.370088 lmp.py:661]   Computing 19 experts on CPU...
DEBUG 01-06 17:11:03.370878.370878 cuda_h.py:19] end cpu_experts_submit cost 5.412101745605469e-05 seconds
DEBUG 01-06 17:11:03.370719.370719 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-06 17:11:03.374832.374832 mlpmodule.py:706] group tensors cost 0.0037996768951416016 s
DEBUG 01-06 17:11:03.376479.376479 mlpmodule.py:744] pad cost 0.00098419189453125 s
DEBUG 01-06 17:11:03.376860.376860 mlpmodule.py:750] create cpu tensor cost 4.029273986816406e-05 s
DEBUG 01-06 17:11:03.376584.376584 mlpmodule.py:755] move to cpu cost 3.0279159545898438e-05 s
DEBUG 01-06 17:11:03.379210.379210 mlpmodule.py:769] group_w3: shape=torch.Size([19, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=54788096
DEBUG 01-06 17:11:03.379206.379206 mlpmodule.py:770] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-06 17:11:03.379572.379572 mlpmodule.py:775] group_w3 first element: 0.048828125
WARNING 01-06 17:11:03.379224.379224 mlpmodule.py:785] start einsum2
DEBUG 01-06 17:11:03.384282.384282 mlpmodule.py:795] group einsum cost 0.007741689682006836 s
DEBUG 01-06 17:11:03.384441.384441 mlpmodule.py:803] cpy2cputensor cost 0.00012564659118652344 s
DEBUG 01-06 17:11:03.387190.387190 cuda_h.py:19] end wait_cetm_experts cost 0.016134262084960938 seconds
DEBUG 01-06 17:11:03.387997.387997 cuda_h.py:19] end layer_moe_dgenerate_7 cost 0.02703070640563965 seconds
DEBUG 01-06 17:11:03.387467.387467 lmp.py:325] -------------------------------- end decode layer 7 --------------------------------
DEBUG 01-06 17:11:03.387236.387236 lmp.py:298] -------------------------------- start decode layer 8 --------------------------------
DEBUG 01-06 17:11:03.387893.387893 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-06 17:11:03.387201.387201 mlpmodule.py:367] cuda:1 cuda:1
DEBUG 01-06 17:11:03.388863.388863 cuda_h.py:10] start self_attn
cos shape torch.Size([65, 128]) sin shape torch.Size([65, 128]) position_ids tensor([[0]], device='cuda:1')
cos shape torch.Size([1, 1, 1, 128]) sin shape torch.Size([1, 1, 1, 128])
q_embed shape torch.Size([32, 16, 1, 128]) k_embed shape torch.Size([32, 16, 1, 128])
DEBUG 01-06 17:11:03.390343.390343 cuda_h.py:19] end self_attn cost 0.002002239227294922 seconds
DEBUG 01-06 17:11:03.390349.390349 cuda_h.py:19] end iln_self_attn_paln cost 0.002894163131713867 seconds
DEBUG 01-06 17:11:03.390337.390337 cuda_h.py:10] start layer_moe_dgenerate_8
DEBUG 01-06 17:11:03.390014.390014 cuda_h.py:10] start gate
DEBUG 01-06 17:11:03.391063.391063 cuda_h.py:19] end gate cost 0.0006241798400878906 seconds
DEBUG 01-06 17:11:03.391237.391237 cuda_h.py:10] start experts_map_get
INFO 01-06 17:11:03.391548.391548 lmp.py:609] using loaded check layer: True
INFO 01-06 17:11:03.392594.392594 lmp.py:620] 
INFO 01-06 17:11:03.392594.392594 lmp.py:620] Layer 8 Expert Device Distribution:
INFO 01-06 17:11:03.392960.392960 lmp.py:621]   Active experts: 54 (out of 64 total)
INFO 01-06 17:11:03.392763.392763 lmp.py:622] 
INFO 01-06 17:11:03.392763.392763 lmp.py:622]   Detailed Expert Distribution:
INFO 01-06 17:11:03.392280.392280 lmp.py:623]   Expert ID  | Tokens     | Actual Device  
INFO 01-06 17:11:03.392983.392983 lmp.py:624]   ----------------------------------------------------------------------
INFO 01-06 17:11:03.392117.392117 lmp.py:627]   0          | 1          |  cuda:1         
INFO 01-06 17:11:03.392058.392058 lmp.py:627]   2          | 1          |  cuda:1         
INFO 01-06 17:11:03.392761.392761 lmp.py:627]   10         | 1          |  cuda:1         
INFO 01-06 17:11:03.392033.392033 lmp.py:627]   11         | 1          |  cuda:1         
INFO 01-06 17:11:03.392544.392544 lmp.py:627]   14         | 1          |  meta           
INFO 01-06 17:11:03.392531.392531 lmp.py:627]   15         | 1          |  meta           
INFO 01-06 17:11:03.392884.392884 lmp.py:627]   16         | 1          |  meta           
INFO 01-06 17:11:03.392925.392925 lmp.py:627]   27         | 1          |  meta           
INFO 01-06 17:11:03.392912.392912 lmp.py:627]   32         | 1          |  meta           
INFO 01-06 17:11:03.392946.392946 lmp.py:627]   38         | 1          |  meta           
INFO 01-06 17:11:03.392219.392219 lmp.py:627]   39         | 1          |  meta           
INFO 01-06 17:11:03.392445.392445 lmp.py:627]   41         | 1          |  cuda:1         
INFO 01-06 17:11:03.392194.392194 lmp.py:627]   43         | 1          |  cuda:1         
INFO 01-06 17:11:03.392659.392659 lmp.py:627]   44         | 1          |  meta           
INFO 01-06 17:11:03.392646.392646 lmp.py:627]   49         | 1          |  cuda:1         
INFO 01-06 17:11:03.392872.392872 lmp.py:627]   55         | 1          |  cuda:1         
INFO 01-06 17:11:03.392145.392145 lmp.py:627]   59         | 1          |  meta           
INFO 01-06 17:11:03.393655.393655 lmp.py:627]   1          | 2          |  cuda:1         
INFO 01-06 17:11:03.393405.393405 lmp.py:627]   4          | 2          |  cuda:1         
INFO 01-06 17:11:03.393915.393915 lmp.py:627]   6          | 2          |  cuda:1         
INFO 01-06 17:11:03.393426.393426 lmp.py:627]   17         | 2          |  meta           
INFO 01-06 17:11:03.393175.393175 lmp.py:627]   28         | 2          |  cuda:1         
INFO 01-06 17:11:03.393640.393640 lmp.py:627]   30         | 2          |  meta           
INFO 01-06 17:11:03.393389.393389 lmp.py:627]   37         | 2          |  cuda:1         
INFO 01-06 17:11:03.393377.393377 lmp.py:627]   45         | 2          |  cuda:1         
INFO 01-06 17:11:03.393364.393364 lmp.py:627]   51         | 2          |  meta           
INFO 01-06 17:11:03.393637.393637 lmp.py:627]   7          | 3          |  cuda:1         
INFO 01-06 17:11:03.393671.393671 lmp.py:627]   22         | 3          |  meta           
INFO 01-06 17:11:03.393420.393420 lmp.py:627]   36         | 3          |  meta           
INFO 01-06 17:11:03.393884.393884 lmp.py:627]   50         | 3          |  cuda:1         
INFO 01-06 17:11:03.393633.393633 lmp.py:627]   60         | 3          |  meta           
INFO 01-06 17:11:03.393144.393144 lmp.py:627]   62         | 3          |  cuda:1         
INFO 01-06 17:11:03.393417.393417 lmp.py:627]   9          | 4          |  cuda:1         
INFO 01-06 17:11:03.393451.393451 lmp.py:627]   13         | 4          |  cuda:1         
INFO 01-06 17:11:03.393200.393200 lmp.py:627]   20         | 4          |  cuda:1         
INFO 01-06 17:11:03.393757.393757 lmp.py:627]   21         | 4          |  cuda:1         
INFO 01-06 17:11:03.393791.393791 lmp.py:627]   42         | 4          |  meta           
INFO 01-06 17:11:03.393302.393302 lmp.py:627]   52         | 4          |  cuda:1         
INFO 01-06 17:11:03.393336.393336 lmp.py:627]   53         | 4          |  meta           
INFO 01-06 17:11:03.393085.393085 lmp.py:627]   54         | 4          |  meta           
INFO 01-06 17:11:03.393596.393596 lmp.py:627]   57         | 4          |  cuda:1         
INFO 01-06 17:11:03.393868.393868 lmp.py:627]   61         | 4          |  cuda:1         
INFO 01-06 17:11:03.393425.393425 lmp.py:627]   26         | 5          |  cuda:1         
INFO 01-06 17:11:03.393744.393744 lmp.py:627]   29         | 5          |  meta           
INFO 01-06 17:11:03.393062.393062 lmp.py:627]   31         | 5          |  cuda:1         
INFO 01-06 17:11:03.393858.393858 lmp.py:627]   33         | 5          |  meta           
INFO 01-06 17:11:03.393084.393084 lmp.py:627]   46         | 5          |  cuda:1         
INFO 01-06 17:11:03.393595.393595 lmp.py:627]   5          | 6          |  cuda:1         
INFO 01-06 17:11:03.393980.393980 lmp.py:627]   63         | 6          |  cuda:1         
INFO 01-06 17:11:03.393537.393537 lmp.py:627]   19         | 7          |  cuda:1         
INFO 01-06 17:11:03.393710.393710 lmp.py:627]   40         | 7          |  meta           
INFO 01-06 17:11:03.393168.393168 lmp.py:627]   34         | 8          |  meta           
INFO 01-06 17:11:03.393341.393341 lmp.py:627]   25         | 18         |  cuda:1         
INFO 01-06 17:11:03.393275.393275 lmp.py:627]   23         | 22         |  cuda:1         
INFO 01-06 17:11:03.393210.393210 lmp.py:628] ============================================================
INFO 01-06 17:11:03.393210.393210 lmp.py:628] 
INFO 01-06 17:11:03.393251.393251 lmp.py:630] experts_gpu_list: [0, 2, 10, 11, 41, 43, 49, 55, 1, 4, 6, 28, 37, 45, 7, 50, 62, 9, 13, 20, 21, 52, 57, 61, 26, 31, 46, 5, 63, 19, 25, 23] num: 32
INFO 01-06 17:11:03.393238.393238 lmp.py:631] experts_cpu_list: [14, 15, 16, 27, 32, 38, 39, 44, 59, 17, 30, 51, 22, 36, 60, 42, 53, 54, 29, 33, 40, 34] num: 22
INFO 01-06 17:11:03.394624.394624 lmp.py:632] expert_actual_device_map {0: 'cuda:1', 1: 'cuda:1', 2: 'cuda:1', 3: 'cuda:1', 4: 'cuda:1', 5: 'cuda:1', 6: 'cuda:1', 7: 'cuda:1', 8: 'cuda:1', 9: 'cuda:1', 10: 'cuda:1', 11: 'cuda:1', 12: 'meta', 13: 'cuda:1', 14: 'meta', 15: 'meta', 16: 'meta', 17: 'meta', 18: 'meta', 19: 'cuda:1', 20: 'cuda:1', 21: 'cuda:1', 22: 'meta', 23: 'cuda:1', 24: 'meta', 25: 'cuda:1', 26: 'cuda:1', 27: 'meta', 28: 'cuda:1', 29: 'meta', 30: 'meta', 31: 'cuda:1', 32: 'meta', 33: 'meta', 34: 'meta', 35: 'meta', 36: 'meta', 37: 'cuda:1', 38: 'meta', 39: 'meta', 40: 'meta', 41: 'cuda:1', 42: 'meta', 43: 'cuda:1', 44: 'meta', 45: 'cuda:1', 46: 'cuda:1', 47: 'cuda:1', 48: 'meta', 49: 'cuda:1', 50: 'cuda:1', 51: 'meta', 52: 'cuda:1', 53: 'meta', 54: 'meta', 55: 'cuda:1', 56: 'cuda:1', 57: 'cuda:1', 58: 'cuda:1', 59: 'meta', 60: 'meta', 61: 'cuda:1', 62: 'cuda:1', 63: 'cuda:1'}
DEBUG 01-06 17:11:03.394386.394386 cuda_h.py:19] end experts_map_get cost 0.0026361942291259766 seconds
DEBUG 01-06 17:11:03.394171.394171 cuda_h.py:10] start gpu_sexperts
DEBUG 01-06 17:11:03.394495.394495 cuda_h.py:19] end gpu_sexperts cost 0.000335693359375 seconds
DEBUG 01-06 17:11:03.394993.394993 cuda_h.py:10] start gpu_experts
DEBUG 01-06 17:11:03.395249.395249 mlpmodule.py:533] gpu group tensors cost 0.0006430149078369141 s
DEBUG 01-06 17:11:03.395668.395668 mlpmodule.py:664]  experts func einsum cost 0.025044918060302734 s
DEBUG 01-06 17:11:03.397903.397903 mlpmodule.py:566] gpu pad cost 0.0018467903137207031 s
DEBUG 01-06 17:11:03.397115.397115 mlpmodule.py:584] gpu group einsum cost 0.0004913806915283203 s
DEBUG 01-06 17:11:03.401230.401230 mlpmodule.py:613] gpu experts func einsum cost 0.006595134735107422 s
DEBUG 01-06 17:11:03.401359.401359 cuda_h.py:19] end gpu_experts cost 0.006731986999511719 seconds
DEBUG 01-06 17:11:03.401592.401592 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-06 17:11:03.401818.401818 lmp.py:661] 
DEBUG 01-06 17:11:03.401818.401818 lmp.py:661]   Computing 22 experts on CPU...
DEBUG 01-06 17:11:03.401230.401230 cuda_h.py:19] end cpu_experts_submit cost 5.6743621826171875e-05 seconds
DEBUG 01-06 17:11:03.401834.401834 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-06 17:11:03.405746.405746 mlpmodule.py:706] group tensors cost 0.003583192825317383 s
DEBUG 01-06 17:11:03.406828.406828 mlpmodule.py:744] pad cost 0.0011086463928222656 s
DEBUG 01-06 17:11:03.406070.406070 mlpmodule.py:750] create cpu tensor cost 4.00543212890625e-05 s
DEBUG 01-06 17:11:03.407443.407443 mlpmodule.py:755] move to cpu cost 2.8848648071289062e-05 s
DEBUG 01-06 17:11:03.409681.409681 mlpmodule.py:769] group_w3: shape=torch.Size([22, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=63438848
DEBUG 01-06 17:11:03.410345.410345 mlpmodule.py:770] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-06 17:11:03.410228.410228 mlpmodule.py:775] group_w3 first element: -0.0194091796875
WARNING 01-06 17:11:03.410668.410668 mlpmodule.py:785] start einsum2
DEBUG 01-06 17:11:03.415643.415643 mlpmodule.py:795] group einsum cost 0.008498668670654297 s
DEBUG 01-06 17:11:03.415409.415409 mlpmodule.py:803] cpy2cputensor cost 7.748603820800781e-05 s
DEBUG 01-06 17:11:03.427602.427602 cuda_h.py:19] end wait_cetm_experts cost 0.025449514389038086 seconds
DEBUG 01-06 17:11:03.427715.427715 cuda_h.py:19] end layer_moe_dgenerate_8 cost 0.036754608154296875 seconds
DEBUG 01-06 17:11:03.427747.427747 lmp.py:325] -------------------------------- end decode layer 8 --------------------------------
DEBUG 01-06 17:11:03.427848.427848 lmp.py:298] -------------------------------- start decode layer 9 --------------------------------
DEBUG 01-06 17:11:03.427643.427643 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-06 17:11:03.427137.427137 mlpmodule.py:367] cuda:1 cuda:1
DEBUG 01-06 17:11:03.428315.428315 cuda_h.py:10] start self_attn
cos shape torch.Size([65, 128]) sin shape torch.Size([65, 128]) position_ids tensor([[0]], device='cuda:1')
cos shape torch.Size([1, 1, 1, 128]) sin shape torch.Size([1, 1, 1, 128])
q_embed shape torch.Size([32, 16, 1, 128]) k_embed shape torch.Size([32, 16, 1, 128])
DEBUG 01-06 17:11:03.430557.430557 cuda_h.py:19] end self_attn cost 0.002010345458984375 seconds
DEBUG 01-06 17:11:03.430997.430997 cuda_h.py:19] end iln_self_attn_paln cost 0.002824544906616211 seconds
DEBUG 01-06 17:11:03.430827.430827 cuda_h.py:10] start layer_moe_dgenerate_9
DEBUG 01-06 17:11:03.430874.430874 cuda_h.py:10] start gate
DEBUG 01-06 17:11:03.431531.431531 cuda_h.py:19] end gate cost 0.0005869865417480469 seconds
DEBUG 01-06 17:11:03.431407.431407 cuda_h.py:10] start experts_map_get
INFO 01-06 17:11:03.431403.431403 lmp.py:609] using loaded check layer: True
INFO 01-06 17:11:03.432213.432213 lmp.py:620] 
INFO 01-06 17:11:03.432213.432213 lmp.py:620] Layer 9 Expert Device Distribution:
INFO 01-06 17:11:03.432221.432221 lmp.py:621]   Active experts: 55 (out of 64 total)
INFO 01-06 17:11:03.432679.432679 lmp.py:622] 
INFO 01-06 17:11:03.432679.432679 lmp.py:622]   Detailed Expert Distribution:
INFO 01-06 17:11:03.432375.432375 lmp.py:623]   Expert ID  | Tokens     | Actual Device  
INFO 01-06 17:11:03.432779.432779 lmp.py:624]   ----------------------------------------------------------------------
INFO 01-06 17:11:03.432137.432137 lmp.py:627]   2          | 1          |  cuda:1         
INFO 01-06 17:11:03.432542.432542 lmp.py:627]   4          | 1          |  cuda:1         
INFO 01-06 17:11:03.432231.432231 lmp.py:627]   5          | 1          |  cuda:1         
INFO 01-06 17:11:03.432066.432066 lmp.py:627]   7          | 1          |  cuda:1         
INFO 01-06 17:11:03.432663.432663 lmp.py:627]   10         | 1          |  meta           
INFO 01-06 17:11:03.432875.432875 lmp.py:627]   12         | 1          |  meta           
INFO 01-06 17:11:03.432287.432287 lmp.py:627]   14         | 1          |  cuda:1         
INFO 01-06 17:11:03.432122.432122 lmp.py:627]   16         | 1          |  meta           
INFO 01-06 17:11:03.432957.432957 lmp.py:627]   31         | 1          |  cuda:1         
INFO 01-06 17:11:03.432269.432269 lmp.py:627]   32         | 1          |  meta           
INFO 01-06 17:11:03.432342.432342 lmp.py:627]   37         | 1          |  meta           
INFO 01-06 17:11:03.432177.432177 lmp.py:627]   43         | 1          |  cuda:1         
INFO 01-06 17:11:03.432489.432489 lmp.py:627]   1          | 2          |  cuda:1         
INFO 01-06 17:11:03.432847.432847 lmp.py:627]   17         | 2          |  meta           
INFO 01-06 17:11:03.432789.432789 lmp.py:627]   19         | 2          |  meta           
INFO 01-06 17:11:03.432498.432498 lmp.py:627]   22         | 2          |  meta           
INFO 01-06 17:11:03.432857.432857 lmp.py:627]   23         | 2          |  meta           
INFO 01-06 17:11:03.432692.432692 lmp.py:627]   24         | 2          |  meta           
INFO 01-06 17:11:03.432812.432812 lmp.py:627]   27         | 2          |  meta           
INFO 01-06 17:11:03.432647.432647 lmp.py:627]   29         | 2          |  cuda:1         
INFO 01-06 17:11:03.432482.432482 lmp.py:627]   44         | 2          |  cuda:1         
INFO 01-06 17:11:03.432317.432317 lmp.py:627]   48         | 2          |  cuda:1         
INFO 01-06 17:11:03.432390.432390 lmp.py:627]   53         | 2          |  meta           
INFO 01-06 17:11:03.432510.432510 lmp.py:627]   58         | 2          |  cuda:1         
INFO 01-06 17:11:03.432868.432868 lmp.py:627]   59         | 2          |  meta           
INFO 01-06 17:11:03.432465.432465 lmp.py:627]   61         | 2          |  cuda:1         
INFO 01-06 17:11:03.432823.432823 lmp.py:627]   63         | 2          |  cuda:1         
INFO 01-06 17:11:03.432181.432181 lmp.py:627]   15         | 3          |  meta           
INFO 01-06 17:11:03.432778.432778 lmp.py:627]   28         | 3          |  meta           
INFO 01-06 17:11:03.432136.432136 lmp.py:627]   30         | 3          |  cuda:1         
INFO 01-06 17:11:03.432687.432687 lmp.py:627]   40         | 3          |  meta           
INFO 01-06 17:11:03.432283.432283 lmp.py:627]   41         | 3          |  meta           
INFO 01-06 17:11:03.432357.432357 lmp.py:627]   42         | 3          |  cuda:1         
INFO 01-06 17:11:03.432669.432669 lmp.py:627]   45         | 3          |  cuda:1         
INFO 01-06 17:11:03.432981.432981 lmp.py:627]   51         | 3          |  cuda:1         
INFO 01-06 17:11:03.432577.432577 lmp.py:627]   6          | 4          |  cuda:1         
INFO 01-06 17:11:03.432459.432459 lmp.py:627]   18         | 4          |  cuda:1         
INFO 01-06 17:11:03.432817.432817 lmp.py:627]   21         | 4          |  cuda:1         
INFO 01-06 17:11:03.432129.432129 lmp.py:627]   33         | 4          |  cuda:1         
INFO 01-06 17:11:03.432725.432725 lmp.py:627]   38         | 4          |  cuda:1         
INFO 01-06 17:11:03.432607.432607 lmp.py:627]   54         | 4          |  cuda:1         
INFO 01-06 17:11:03.432634.432634 lmp.py:627]   56         | 4          |  cuda:1         
INFO 01-06 17:11:03.432469.432469 lmp.py:627]   13         | 5          |  meta           
INFO 01-06 17:11:03.432304.432304 lmp.py:627]   34         | 6          |  cuda:1         
INFO 01-06 17:11:03.432285.432285 lmp.py:627]   39         | 6          |  cuda:1         
INFO 01-06 17:11:03.432643.432643 lmp.py:627]   52         | 6          |  cuda:1         
INFO 01-06 17:11:03.433478.433478 lmp.py:627]   0          | 7          |  cuda:1         
INFO 01-06 17:11:03.433075.433075 lmp.py:627]   9          | 7          |  cuda:1         
INFO 01-06 17:11:03.433672.433672 lmp.py:627]   25         | 7          |  meta           
INFO 01-06 17:11:03.433553.433553 lmp.py:627]   46         | 7          |  cuda:1         
INFO 01-06 17:11:03.433911.433911 lmp.py:627]   62         | 7          |  cuda:1         
INFO 01-06 17:11:03.433746.433746 lmp.py:627]   11         | 8          |  cuda:1         
INFO 01-06 17:11:03.433820.433820 lmp.py:627]   55         | 9          |  cuda:1         
INFO 01-06 17:11:03.433416.433416 lmp.py:627]   57         | 10         |  cuda:1         
INFO 01-06 17:11:03.433013.433013 lmp.py:627]   8          | 13         |  cuda:1         
INFO 01-06 17:11:03.433610.433610 lmp.py:628] ============================================================
INFO 01-06 17:11:03.433610.433610 lmp.py:628] 
INFO 01-06 17:11:03.433498.433498 lmp.py:630] experts_gpu_list: [2, 4, 5, 7, 14, 31, 43, 1, 29, 44, 48, 58, 61, 63, 30, 42, 45, 51, 6, 18, 21, 33, 38, 54, 56, 34, 39, 52, 0, 9, 46, 62, 11, 55, 57, 8] num: 36
INFO 01-06 17:11:03.433763.433763 lmp.py:631] experts_cpu_list: [10, 12, 16, 32, 37, 17, 19, 22, 23, 24, 27, 53, 59, 15, 28, 40, 41, 13, 25] num: 19
INFO 01-06 17:11:03.433897.433897 lmp.py:632] expert_actual_device_map {0: 'cuda:1', 1: 'cuda:1', 2: 'cuda:1', 3: 'cuda:1', 4: 'cuda:1', 5: 'cuda:1', 6: 'cuda:1', 7: 'cuda:1', 8: 'cuda:1', 9: 'cuda:1', 10: 'meta', 11: 'cuda:1', 12: 'meta', 13: 'meta', 14: 'cuda:1', 15: 'meta', 16: 'meta', 17: 'meta', 18: 'cuda:1', 19: 'meta', 20: 'meta', 21: 'cuda:1', 22: 'meta', 23: 'meta', 24: 'meta', 25: 'meta', 26: 'meta', 27: 'meta', 28: 'meta', 29: 'cuda:1', 30: 'cuda:1', 31: 'cuda:1', 32: 'meta', 33: 'cuda:1', 34: 'cuda:1', 35: 'meta', 36: 'meta', 37: 'meta', 38: 'cuda:1', 39: 'cuda:1', 40: 'meta', 41: 'meta', 42: 'cuda:1', 43: 'cuda:1', 44: 'cuda:1', 45: 'cuda:1', 46: 'cuda:1', 47: 'meta', 48: 'cuda:1', 49: 'meta', 50: 'meta', 51: 'cuda:1', 52: 'cuda:1', 53: 'meta', 54: 'cuda:1', 55: 'cuda:1', 56: 'cuda:1', 57: 'cuda:1', 58: 'cuda:1', 59: 'meta', 60: 'meta', 61: 'cuda:1', 62: 'cuda:1', 63: 'cuda:1'}
DEBUG 01-06 17:11:03.433507.433507 cuda_h.py:19] end experts_map_get cost 0.0019707679748535156 seconds
DEBUG 01-06 17:11:03.433742.433742 cuda_h.py:10] start gpu_sexperts
DEBUG 01-06 17:11:03.433244.433244 cuda_h.py:19] end gpu_sexperts cost 0.0002830028533935547 seconds
DEBUG 01-06 17:11:03.433589.433589 cuda_h.py:10] start gpu_experts
DEBUG 01-06 17:11:03.435643.435643 mlpmodule.py:664]  experts func einsum cost 0.03431868553161621 s
DEBUG 01-06 17:11:03.436993.436993 mlpmodule.py:533] gpu group tensors cost 0.0026781558990478516 s
DEBUG 01-06 17:11:03.438652.438652 mlpmodule.py:566] gpu pad cost 0.0015752315521240234 s
DEBUG 01-06 17:11:03.438735.438735 mlpmodule.py:584] gpu group einsum cost 0.0004353523254394531 s
DEBUG 01-06 17:11:03.441499.441499 mlpmodule.py:613] gpu experts func einsum cost 0.008119344711303711 s
DEBUG 01-06 17:11:03.442668.442668 cuda_h.py:19] end gpu_experts cost 0.008246421813964844 seconds
DEBUG 01-06 17:11:03.442708.442708 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-06 17:11:03.442458.442458 lmp.py:661] 
DEBUG 01-06 17:11:03.442458.442458 lmp.py:661]   Computing 19 experts on CPU...
DEBUG 01-06 17:11:03.442506.442506 cuda_h.py:19] end cpu_experts_submit cost 6.866455078125e-05 seconds
DEBUG 01-06 17:11:03.442348.442348 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-06 17:11:03.451994.451994 mlpmodule.py:706] group tensors cost 0.00878596305847168 s
DEBUG 01-06 17:11:03.453642.453642 mlpmodule.py:744] pad cost 0.0012290477752685547 s
DEBUG 01-06 17:11:03.453527.453527 mlpmodule.py:750] create cpu tensor cost 4.673004150390625e-05 s
DEBUG 01-06 17:11:03.453013.453013 mlpmodule.py:755] move to cpu cost 3.266334533691406e-05 s
DEBUG 01-06 17:11:03.456523.456523 mlpmodule.py:769] group_w3: shape=torch.Size([19, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=54788096
DEBUG 01-06 17:11:03.456578.456578 mlpmodule.py:770] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-06 17:11:03.456481.456481 mlpmodule.py:775] group_w3 first element: 0.042724609375
WARNING 01-06 17:11:03.456087.456087 mlpmodule.py:785] start einsum2
DEBUG 01-06 17:11:03.462405.462405 mlpmodule.py:795] group einsum cost 0.008490324020385742 s
DEBUG 01-06 17:11:03.462788.462788 mlpmodule.py:803] cpy2cputensor cost 0.00010156631469726562 s
DEBUG 01-06 17:11:03.464004.464004 cuda_h.py:19] end wait_cetm_experts cost 0.022654056549072266 seconds
DEBUG 01-06 17:11:03.465926.465926 cuda_h.py:19] end layer_moe_dgenerate_9 cost 0.03476071357727051 seconds
DEBUG 01-06 17:11:03.465012.465012 lmp.py:325] -------------------------------- end decode layer 9 --------------------------------
DEBUG 01-06 17:11:03.465564.465564 lmp.py:298] -------------------------------- start decode layer 10 --------------------------------
DEBUG 01-06 17:11:03.465234.465234 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-06 17:11:03.465954.465954 mlpmodule.py:367] cuda:1 cuda:1
DEBUG 01-06 17:11:03.466136.466136 cuda_h.py:10] start self_attn
cos shape torch.Size([65, 128]) sin shape torch.Size([65, 128]) position_ids tensor([[0]], device='cuda:1')
cos shape torch.Size([1, 1, 1, 128]) sin shape torch.Size([1, 1, 1, 128])
q_embed shape torch.Size([32, 16, 1, 128]) k_embed shape torch.Size([32, 16, 1, 128])
DEBUG 01-06 17:11:03.468303.468303 cuda_h.py:19] end self_attn cost 0.0023627281188964844 seconds
DEBUG 01-06 17:11:03.469268.469268 cuda_h.py:19] end iln_self_attn_paln cost 0.0033500194549560547 seconds
DEBUG 01-06 17:11:03.469627.469627 cuda_h.py:10] start layer_moe_dgenerate_10
DEBUG 01-06 17:11:03.469543.469543 cuda_h.py:10] start gate
DEBUG 01-06 17:11:03.469690.469690 cuda_h.py:19] end gate cost 0.0005950927734375 seconds
DEBUG 01-06 17:11:03.469334.469334 cuda_h.py:10] start experts_map_get
INFO 01-06 17:11:03.470405.470405 lmp.py:609] using loaded check layer: True
INFO 01-06 17:11:03.470039.470039 lmp.py:620] 
INFO 01-06 17:11:03.470039.470039 lmp.py:620] Layer 10 Expert Device Distribution:
INFO 01-06 17:11:03.470801.470801 lmp.py:621]   Active experts: 52 (out of 64 total)
INFO 01-06 17:11:03.470888.470888 lmp.py:622] 
INFO 01-06 17:11:03.470888.470888 lmp.py:622]   Detailed Expert Distribution:
INFO 01-06 17:11:03.470591.470591 lmp.py:623]   Expert ID  | Tokens     | Actual Device  
INFO 01-06 17:11:03.470526.470526 lmp.py:624]   ----------------------------------------------------------------------
INFO 01-06 17:11:03.470891.470891 lmp.py:627]   0          | 1          |  cuda:1         
INFO 01-06 17:11:03.470825.470825 lmp.py:627]   7          | 1          |  meta           
INFO 01-06 17:11:03.470329.470329 lmp.py:627]   16         | 1          |  cuda:1         
INFO 01-06 17:11:03.470357.470357 lmp.py:627]   19         | 1          |  meta           
INFO 01-06 17:11:03.470861.470861 lmp.py:627]   23         | 1          |  cuda:1         
INFO 01-06 17:11:03.470841.470841 lmp.py:627]   25         | 1          |  cuda:1         
INFO 01-06 17:11:03.470107.470107 lmp.py:627]   29         | 1          |  cuda:1         
INFO 01-06 17:11:03.470849.470849 lmp.py:627]   34         | 1          |  meta           
INFO 01-06 17:11:03.471307.471307 lmp.py:627]   37         | 1          |  meta           
INFO 01-06 17:11:03.471526.471526 lmp.py:627]   42         | 1          |  cuda:1         
INFO 01-06 17:11:03.471984.471984 lmp.py:627]   48         | 1          |  meta           
INFO 01-06 17:11:03.471250.471250 lmp.py:627]   50         | 1          |  cuda:1         
INFO 01-06 17:11:03.471515.471515 lmp.py:627]   51         | 1          |  meta           
INFO 01-06 17:11:03.471542.471542 lmp.py:627]   52         | 1          |  meta           
INFO 01-06 17:11:03.471569.471569 lmp.py:627]   57         | 1          |  meta           
INFO 01-06 17:11:03.471835.471835 lmp.py:627]   12         | 2          |  meta           
INFO 01-06 17:11:03.471624.471624 lmp.py:627]   14         | 2          |  meta           
INFO 01-06 17:11:03.471651.471651 lmp.py:627]   36         | 2          |  cuda:1         
INFO 01-06 17:11:03.471917.471917 lmp.py:627]   39         | 2          |  cuda:1         
INFO 01-06 17:11:03.471897.471897 lmp.py:627]   40         | 2          |  cuda:1         
INFO 01-06 17:11:03.471878.471878 lmp.py:627]   54         | 2          |  meta           
INFO 01-06 17:11:03.471621.471621 lmp.py:627]   55         | 2          |  meta           
INFO 01-06 17:11:03.471363.471363 lmp.py:627]   58         | 2          |  cuda:1         
INFO 01-06 17:11:03.471629.471629 lmp.py:627]   63         | 2          |  meta           
INFO 01-06 17:11:03.471656.471656 lmp.py:627]   5          | 3          |  cuda:1         
INFO 01-06 17:11:03.471445.471445 lmp.py:627]   31         | 3          |  cuda:1         
INFO 01-06 17:11:03.471472.471472 lmp.py:627]   33         | 3          |  cuda:1         
INFO 01-06 17:11:03.471499.471499 lmp.py:627]   41         | 3          |  cuda:1         
INFO 01-06 17:11:03.471526.471526 lmp.py:627]   60         | 3          |  meta           
INFO 01-06 17:11:03.471076.471076 lmp.py:627]   15         | 4          |  meta           
INFO 01-06 17:11:03.471534.471534 lmp.py:627]   17         | 4          |  meta           
INFO 01-06 17:11:03.471515.471515 lmp.py:627]   20         | 4          |  cuda:1         
INFO 01-06 17:11:03.471973.471973 lmp.py:627]   32         | 4          |  cuda:1         
INFO 01-06 17:11:03.471953.471953 lmp.py:627]   35         | 4          |  cuda:1         
INFO 01-06 17:11:03.471981.471981 lmp.py:627]   44         | 4          |  cuda:1         
INFO 01-06 17:11:03.471008.471008 lmp.py:627]   4          | 5          |  cuda:1         
INFO 01-06 17:11:03.471273.471273 lmp.py:627]   6          | 5          |  cuda:1         
INFO 01-06 17:11:03.471300.471300 lmp.py:627]   8          | 5          |  cuda:1         
INFO 01-06 17:11:03.471328.471328 lmp.py:627]   24         | 5          |  cuda:1         
INFO 01-06 17:11:03.471878.471878 lmp.py:627]   27         | 5          |  meta           
INFO 01-06 17:11:03.471382.471382 lmp.py:627]   28         | 5          |  meta           
INFO 01-06 17:11:03.471886.471886 lmp.py:627]   53         | 5          |  cuda:1         
INFO 01-06 17:11:03.471251.471251 lmp.py:627]   10         | 6          |  cuda:1         
INFO 01-06 17:11:03.471424.471424 lmp.py:627]   21         | 6          |  cuda:1         
INFO 01-06 17:11:03.471689.471689 lmp.py:627]   56         | 6          |  meta           
INFO 01-06 17:11:03.471478.471478 lmp.py:627]   46         | 7          |  cuda:1         
INFO 01-06 17:11:03.471267.471267 lmp.py:627]   1          | 8          |  cuda:1         
INFO 01-06 17:11:03.471056.471056 lmp.py:627]   9          | 8          |  cuda:1         
INFO 01-06 17:11:03.471321.471321 lmp.py:627]   49         | 10         |  cuda:1         
INFO 01-06 17:11:03.471878.471878 lmp.py:627]   59         | 11         |  cuda:1         
INFO 01-06 17:11:03.471767.471767 lmp.py:627]   62         | 11         |  cuda:1         
INFO 01-06 17:11:03.471370.471370 lmp.py:627]   11         | 12         |  cuda:1         
INFO 01-06 17:11:03.471258.471258 lmp.py:628] ============================================================
INFO 01-06 17:11:03.471258.471258 lmp.py:628] 
INFO 01-06 17:11:03.471868.471868 lmp.py:630] experts_gpu_list: [0, 16, 23, 25, 29, 42, 50, 36, 39, 40, 58, 5, 31, 33, 41, 20, 32, 35, 44, 4, 6, 8, 24, 53, 10, 21, 46, 1, 9, 49, 59, 62, 11] num: 33
INFO 01-06 17:11:03.471902.471902 lmp.py:631] experts_cpu_list: [7, 19, 34, 37, 48, 51, 52, 57, 12, 14, 54, 55, 63, 60, 15, 17, 27, 28, 56] num: 19
INFO 01-06 17:11:03.472711.472711 lmp.py:632] expert_actual_device_map {0: 'cuda:1', 1: 'cuda:1', 2: 'cuda:1', 3: 'cuda:1', 4: 'cuda:1', 5: 'cuda:1', 6: 'cuda:1', 7: 'meta', 8: 'cuda:1', 9: 'cuda:1', 10: 'cuda:1', 11: 'cuda:1', 12: 'meta', 13: 'cuda:1', 14: 'meta', 15: 'meta', 16: 'cuda:1', 17: 'meta', 18: 'meta', 19: 'meta', 20: 'cuda:1', 21: 'cuda:1', 22: 'meta', 23: 'cuda:1', 24: 'cuda:1', 25: 'cuda:1', 26: 'meta', 27: 'meta', 28: 'meta', 29: 'cuda:1', 30: 'cuda:1', 31: 'cuda:1', 32: 'cuda:1', 33: 'cuda:1', 34: 'meta', 35: 'cuda:1', 36: 'cuda:1', 37: 'meta', 38: 'meta', 39: 'cuda:1', 40: 'cuda:1', 41: 'cuda:1', 42: 'cuda:1', 43: 'meta', 44: 'cuda:1', 45: 'meta', 46: 'cuda:1', 47: 'meta', 48: 'meta', 49: 'cuda:1', 50: 'cuda:1', 51: 'meta', 52: 'meta', 53: 'cuda:1', 54: 'meta', 55: 'meta', 56: 'meta', 57: 'meta', 58: 'cuda:1', 59: 'cuda:1', 60: 'meta', 61: 'meta', 62: 'cuda:1', 63: 'meta'}
DEBUG 01-06 17:11:03.472090.472090 cuda_h.py:19] end experts_map_get cost 0.00217437744140625 seconds
DEBUG 01-06 17:11:03.472570.472570 cuda_h.py:10] start gpu_sexperts
DEBUG 01-06 17:11:03.472755.472755 cuda_h.py:19] end gpu_sexperts cost 0.0003342628479003906 seconds
DEBUG 01-06 17:11:03.472154.472154 cuda_h.py:10] start gpu_experts
DEBUG 01-06 17:11:03.473872.473872 mlpmodule.py:533] gpu group tensors cost 0.0005998611450195312 s
DEBUG 01-06 17:11:03.474506.474506 mlpmodule.py:566] gpu pad cost 0.0016820430755615234 s
DEBUG 01-06 17:11:03.475913.475913 mlpmodule.py:664]  experts func einsum cost 0.03309893608093262 s
DEBUG 01-06 17:11:03.475975.475975 mlpmodule.py:584] gpu group einsum cost 0.0006470680236816406 s
DEBUG 01-06 17:11:03.479365.479365 mlpmodule.py:613] gpu experts func einsum cost 0.006612539291381836 s
DEBUG 01-06 17:11:03.479581.479581 cuda_h.py:19] end gpu_experts cost 0.0067729949951171875 seconds
DEBUG 01-06 17:11:03.479960.479960 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-06 17:11:03.479193.479193 lmp.py:661] 
DEBUG 01-06 17:11:03.479193.479193 lmp.py:661]   Computing 19 experts on CPU...
DEBUG 01-06 17:11:03.479228.479228 cuda_h.py:19] end cpu_experts_submit cost 6.127357482910156e-05 seconds
DEBUG 01-06 17:11:03.479023.479023 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-06 17:11:03.483291.483291 mlpmodule.py:706] group tensors cost 0.0034894943237304688 s
DEBUG 01-06 17:11:03.484931.484931 mlpmodule.py:744] pad cost 0.0010066032409667969 s
DEBUG 01-06 17:11:03.484842.484842 mlpmodule.py:750] create cpu tensor cost 4.029273986816406e-05 s
DEBUG 01-06 17:11:03.484792.484792 mlpmodule.py:755] move to cpu cost 2.956390380859375e-05 s
DEBUG 01-06 17:11:03.487484.487484 mlpmodule.py:769] group_w3: shape=torch.Size([19, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=54788096
DEBUG 01-06 17:11:03.487049.487049 mlpmodule.py:770] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-06 17:11:03.487647.487647 mlpmodule.py:775] group_w3 first element: 0.033203125
WARNING 01-06 17:11:03.487325.487325 mlpmodule.py:785] start einsum2
DEBUG 01-06 17:11:03.491466.491466 mlpmodule.py:795] group einsum cost 0.007057666778564453 s
DEBUG 01-06 17:11:03.492478.492478 mlpmodule.py:803] cpy2cputensor cost 8.535385131835938e-05 s
DEBUG 01-06 17:11:03.494611.494611 cuda_h.py:19] end wait_cetm_experts cost 0.015095949172973633 seconds
DEBUG 01-06 17:11:03.495266.495266 cuda_h.py:19] end layer_moe_dgenerate_10 cost 0.025957584381103516 seconds
DEBUG 01-06 17:11:03.495953.495953 lmp.py:325] -------------------------------- end decode layer 10 --------------------------------
DEBUG 01-06 17:11:03.495908.495908 lmp.py:298] -------------------------------- start decode layer 11 --------------------------------
DEBUG 01-06 17:11:03.495181.495181 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-06 17:11:03.495483.495483 mlpmodule.py:367] cuda:1 cuda:1
DEBUG 01-06 17:11:03.495117.495117 cuda_h.py:10] start self_attn
cos shape torch.Size([65, 128]) sin shape torch.Size([65, 128]) position_ids tensor([[0]], device='cuda:1')
cos shape torch.Size([1, 1, 1, 128]) sin shape torch.Size([1, 1, 1, 128])
q_embed shape torch.Size([32, 16, 1, 128]) k_embed shape torch.Size([32, 16, 1, 128])
DEBUG 01-06 17:11:03.497230.497230 cuda_h.py:19] end self_attn cost 0.0019142627716064453 seconds
DEBUG 01-06 17:11:03.498380.498380 cuda_h.py:19] end iln_self_attn_paln cost 0.002744436264038086 seconds
DEBUG 01-06 17:11:03.498355.498355 cuda_h.py:10] start layer_moe_dgenerate_11
DEBUG 01-06 17:11:03.498648.498648 cuda_h.py:10] start gate
DEBUG 01-06 17:11:03.498371.498371 cuda_h.py:19] end gate cost 0.0005991458892822266 seconds
DEBUG 01-06 17:11:03.498492.498492 cuda_h.py:10] start experts_map_get
INFO 01-06 17:11:03.499582.499582 lmp.py:609] using loaded check layer: True
INFO 01-06 17:11:03.499653.499653 lmp.py:620] 
INFO 01-06 17:11:03.499653.499653 lmp.py:620] Layer 11 Expert Device Distribution:
INFO 01-06 17:11:03.499178.499178 lmp.py:621]   Active experts: 49 (out of 64 total)
INFO 01-06 17:11:03.499735.499735 lmp.py:622] 
INFO 01-06 17:11:03.499735.499735 lmp.py:622]   Detailed Expert Distribution:
INFO 01-06 17:11:03.499007.499007 lmp.py:623]   Expert ID  | Tokens     | Actual Device  
INFO 01-06 17:11:03.499233.499233 lmp.py:624]   ----------------------------------------------------------------------
INFO 01-06 17:11:03.499121.499121 lmp.py:627]   3          | 1          |  cuda:1         
INFO 01-06 17:11:03.499579.499579 lmp.py:627]   5          | 1          |  cuda:1         
INFO 01-06 17:11:03.499321.499321 lmp.py:627]   9          | 1          |  cuda:1         
INFO 01-06 17:11:03.499349.499349 lmp.py:627]   11         | 1          |  cuda:1         
INFO 01-06 17:11:03.499667.499667 lmp.py:627]   15         | 1          |  meta           
INFO 01-06 17:11:03.499079.499079 lmp.py:627]   16         | 1          |  meta           
INFO 01-06 17:11:03.500205.500205 lmp.py:627]   18         | 1          |  meta           
INFO 01-06 17:11:03.500809.500809 lmp.py:627]   19         | 1          |  meta           
INFO 01-06 17:11:03.500127.500127 lmp.py:627]   35         | 1          |  meta           
INFO 01-06 17:11:03.500731.500731 lmp.py:627]   41         | 1          |  meta           
INFO 01-06 17:11:03.500142.500142 lmp.py:627]   42         | 1          |  meta           
INFO 01-06 17:11:03.500030.500030 lmp.py:627]   46         | 1          |  meta           
INFO 01-06 17:11:03.500442.500442 lmp.py:627]   49         | 1          |  meta           
INFO 01-06 17:11:03.500568.500568 lmp.py:627]   56         | 1          |  cuda:1         
INFO 01-06 17:11:03.500456.500456 lmp.py:627]   59         | 1          |  meta           
INFO 01-06 17:11:03.500106.500106 lmp.py:627]   2          | 2          |  cuda:1         
INFO 01-06 17:11:03.500994.500994 lmp.py:627]   23         | 2          |  meta           
INFO 01-06 17:11:03.500836.500836 lmp.py:627]   30         | 2          |  cuda:1         
INFO 01-06 17:11:03.500963.500963 lmp.py:627]   31         | 2          |  meta           
INFO 01-06 17:11:03.500328.500328 lmp.py:627]   33         | 2          |  meta           
INFO 01-06 17:11:03.500454.500454 lmp.py:627]   37         | 2          |  cuda:1         
INFO 01-06 17:11:03.500866.500866 lmp.py:627]   52         | 2          |  cuda:1         
INFO 01-06 17:11:03.500516.500516 lmp.py:627]   61         | 2          |  meta           
INFO 01-06 17:11:03.500000.500000 lmp.py:627]   17         | 3          |  meta           
INFO 01-06 17:11:03.500127.500127 lmp.py:627]   36         | 3          |  meta           
INFO 01-06 17:11:03.500015.500015 lmp.py:627]   40         | 3          |  meta           
INFO 01-06 17:11:03.500188.500188 lmp.py:627]   45         | 3          |  cuda:1         
INFO 01-06 17:11:03.500599.500599 lmp.py:627]   51         | 3          |  cuda:1         
INFO 01-06 17:11:03.500726.500726 lmp.py:627]   58         | 3          |  cuda:1         
INFO 01-06 17:11:03.500614.500614 lmp.py:627]   0          | 4          |  cuda:1         
INFO 01-06 17:11:03.500787.500787 lmp.py:627]   24         | 4          |  cuda:1         
INFO 01-06 17:11:03.500437.500437 lmp.py:627]   26         | 4          |  meta           
INFO 01-06 17:11:03.500610.500610 lmp.py:627]   55         | 4          |  cuda:1         
INFO 01-06 17:11:03.500498.500498 lmp.py:627]   57         | 4          |  cuda:1         
INFO 01-06 17:11:03.500386.500386 lmp.py:627]   14         | 5          |  cuda:1         
INFO 01-06 17:11:03.500513.500513 lmp.py:627]   25         | 5          |  cuda:1         
INFO 01-06 17:11:03.500401.500401 lmp.py:627]   44         | 5          |  meta           
INFO 01-06 17:11:03.500528.500528 lmp.py:627]   54         | 5          |  cuda:1         
INFO 01-06 17:11:03.500131.500131 lmp.py:627]   60         | 5          |  cuda:1         
INFO 01-06 17:11:03.500496.500496 lmp.py:627]   62         | 5          |  meta           
INFO 01-06 17:11:03.500384.500384 lmp.py:627]   22         | 6          |  cuda:1         
INFO 01-06 17:11:03.500749.500749 lmp.py:627]   27         | 6          |  cuda:1         
INFO 01-06 17:11:03.500114.500114 lmp.py:627]   29         | 7          |  cuda:1         
INFO 01-06 17:11:03.500718.500718 lmp.py:627]   4          | 9          |  cuda:1         
INFO 01-06 17:11:03.500367.500367 lmp.py:627]   8          | 9          |  cuda:1         
INFO 01-06 17:11:03.500733.500733 lmp.py:627]   7          | 11         |  cuda:1         
INFO 01-06 17:11:03.500336.500336 lmp.py:627]   1          | 13         |  cuda:1         
INFO 01-06 17:11:03.500939.500939 lmp.py:627]   12         | 13         |  cuda:1         
INFO 01-06 17:11:03.500828.500828 lmp.py:627]   28         | 19         |  cuda:1         
INFO 01-06 17:11:03.501716.501716 lmp.py:628] ============================================================
INFO 01-06 17:11:03.501716.501716 lmp.py:628] 
INFO 01-06 17:11:03.501849.501849 lmp.py:630] experts_gpu_list: [3, 5, 9, 11, 56, 2, 30, 37, 52, 45, 51, 58, 0, 24, 55, 57, 14, 25, 54, 60, 22, 27, 29, 4, 8, 7, 1, 12, 28] num: 29
INFO 01-06 17:11:03.501360.501360 lmp.py:631] experts_cpu_list: [15, 16, 18, 19, 35, 41, 42, 46, 49, 59, 23, 31, 33, 61, 17, 36, 40, 26, 44, 62] num: 20
INFO 01-06 17:11:03.501646.501646 lmp.py:632] expert_actual_device_map {0: 'cuda:1', 1: 'cuda:1', 2: 'cuda:1', 3: 'cuda:1', 4: 'cuda:1', 5: 'cuda:1', 6: 'cuda:1', 7: 'cuda:1', 8: 'cuda:1', 9: 'cuda:1', 10: 'cuda:1', 11: 'cuda:1', 12: 'cuda:1', 13: 'cuda:1', 14: 'cuda:1', 15: 'meta', 16: 'meta', 17: 'meta', 18: 'meta', 19: 'meta', 20: 'meta', 21: 'cuda:1', 22: 'cuda:1', 23: 'meta', 24: 'cuda:1', 25: 'cuda:1', 26: 'meta', 27: 'cuda:1', 28: 'cuda:1', 29: 'cuda:1', 30: 'cuda:1', 31: 'meta', 32: 'meta', 33: 'meta', 34: 'cuda:1', 35: 'meta', 36: 'meta', 37: 'cuda:1', 38: 'meta', 39: 'meta', 40: 'meta', 41: 'meta', 42: 'meta', 43: 'meta', 44: 'meta', 45: 'cuda:1', 46: 'meta', 47: 'cuda:1', 48: 'cuda:1', 49: 'meta', 50: 'meta', 51: 'cuda:1', 52: 'cuda:1', 53: 'cuda:1', 54: 'cuda:1', 55: 'cuda:1', 56: 'cuda:1', 57: 'cuda:1', 58: 'cuda:1', 59: 'meta', 60: 'cuda:1', 61: 'meta', 62: 'meta', 63: 'meta'}
DEBUG 01-06 17:11:03.501740.501740 cuda_h.py:19] end experts_map_get cost 0.002221822738647461 seconds
DEBUG 01-06 17:11:03.501292.501292 cuda_h.py:10] start gpu_sexperts
DEBUG 01-06 17:11:03.501589.501589 cuda_h.py:19] end gpu_sexperts cost 0.00031113624572753906 seconds
DEBUG 01-06 17:11:03.501273.501273 cuda_h.py:10] start gpu_experts
DEBUG 01-06 17:11:03.502717.502717 mlpmodule.py:533] gpu group tensors cost 0.0005400180816650391 s
DEBUG 01-06 17:11:03.503571.503571 mlpmodule.py:664]  experts func einsum cost 0.023936748504638672 s
DEBUG 01-06 17:11:03.503477.503477 mlpmodule.py:566] gpu pad cost 0.001649618148803711 s
DEBUG 01-06 17:11:03.504088.504088 mlpmodule.py:584] gpu group einsum cost 0.0005314350128173828 s
DEBUG 01-06 17:11:03.507403.507403 mlpmodule.py:613] gpu experts func einsum cost 0.005994319915771484 s
DEBUG 01-06 17:11:03.507155.507155 cuda_h.py:19] end gpu_experts cost 0.006131410598754883 seconds
DEBUG 01-06 17:11:03.507149.507149 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-06 17:11:03.507614.507614 lmp.py:661] 
DEBUG 01-06 17:11:03.507614.507614 lmp.py:661]   Computing 20 experts on CPU...
DEBUG 01-06 17:11:03.507748.507748 cuda_h.py:19] end cpu_experts_submit cost 6.29425048828125e-05 seconds
DEBUG 01-06 17:11:03.507352.507352 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-06 17:11:03.511081.511081 mlpmodule.py:706] group tensors cost 0.003444194793701172 s
DEBUG 01-06 17:11:03.513912.513912 mlpmodule.py:744] pad cost 0.0011322498321533203 s
DEBUG 01-06 17:11:03.513392.513392 mlpmodule.py:750] create cpu tensor cost 4.029273986816406e-05 s
DEBUG 01-06 17:11:03.513050.513050 mlpmodule.py:755] move to cpu cost 2.8848648071289062e-05 s
DEBUG 01-06 17:11:03.516788.516788 mlpmodule.py:769] group_w3: shape=torch.Size([20, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=57671680
DEBUG 01-06 17:11:03.516075.516075 mlpmodule.py:770] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-06 17:11:03.516203.516203 mlpmodule.py:775] group_w3 first element: -0.03271484375
WARNING 01-06 17:11:03.516073.516073 mlpmodule.py:785] start einsum2
DEBUG 01-06 17:11:03.521394.521394 mlpmodule.py:795] group einsum cost 0.007868051528930664 s
DEBUG 01-06 17:11:03.521996.521996 mlpmodule.py:803] cpy2cputensor cost 9.107589721679688e-05 s
DEBUG 01-06 17:11:03.524186.524186 cuda_h.py:19] end wait_cetm_experts cost 0.01612114906311035 seconds
DEBUG 01-06 17:11:03.524689.524689 cuda_h.py:19] end layer_moe_dgenerate_11 cost 0.02636432647705078 seconds
DEBUG 01-06 17:11:03.524066.524066 lmp.py:325] -------------------------------- end decode layer 11 --------------------------------
DEBUG 01-06 17:11:03.524505.524505 lmp.py:298] -------------------------------- start decode layer 12 --------------------------------
DEBUG 01-06 17:11:03.524068.524068 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-06 17:11:03.524377.524377 mlpmodule.py:367] cuda:1 cuda:1
DEBUG 01-06 17:11:03.525675.525675 cuda_h.py:10] start self_attn
cos shape torch.Size([65, 128]) sin shape torch.Size([65, 128]) position_ids tensor([[0]], device='cuda:1')
cos shape torch.Size([1, 1, 1, 128]) sin shape torch.Size([1, 1, 1, 128])
q_embed shape torch.Size([32, 16, 1, 128]) k_embed shape torch.Size([32, 16, 1, 128])
DEBUG 01-06 17:11:03.527108.527108 cuda_h.py:19] end self_attn cost 0.001969575881958008 seconds
DEBUG 01-06 17:11:03.527252.527252 cuda_h.py:19] end iln_self_attn_paln cost 0.0028693675994873047 seconds
DEBUG 01-06 17:11:03.527194.527194 cuda_h.py:10] start layer_moe_dgenerate_12
DEBUG 01-06 17:11:03.527401.527401 cuda_h.py:10] start gate
DEBUG 01-06 17:11:03.528530.528530 cuda_h.py:19] end gate cost 0.0006470680236816406 seconds
DEBUG 01-06 17:11:03.528380.528380 cuda_h.py:10] start experts_map_get
INFO 01-06 17:11:03.528696.528696 lmp.py:609] using loaded check layer: True
INFO 01-06 17:11:03.529490.529490 lmp.py:620] 
INFO 01-06 17:11:03.529490.529490 lmp.py:620] Layer 12 Expert Device Distribution:
INFO 01-06 17:11:03.529451.529451 lmp.py:621]   Active experts: 48 (out of 64 total)
INFO 01-06 17:11:03.529200.529200 lmp.py:622] 
INFO 01-06 17:11:03.529200.529200 lmp.py:622]   Detailed Expert Distribution:
INFO 01-06 17:11:03.529334.529334 lmp.py:623]   Expert ID  | Tokens     | Actual Device  
INFO 01-06 17:11:03.529129.529129 lmp.py:624]   ----------------------------------------------------------------------
INFO 01-06 17:11:03.529436.529436 lmp.py:627]   1          | 1          |  cuda:1         
INFO 01-06 17:11:03.529476.529476 lmp.py:627]   11         | 1          |  cuda:1         
INFO 01-06 17:11:03.529841.529841 lmp.py:627]   14         | 1          |  meta           
INFO 01-06 17:11:03.529445.529445 lmp.py:627]   19         | 1          |  cuda:1         
INFO 01-06 17:11:03.529571.529571 lmp.py:627]   30         | 1          |  meta           
INFO 01-06 17:11:03.529890.529890 lmp.py:627]   33         | 1          |  cuda:1         
INFO 01-06 17:11:03.529540.529540 lmp.py:627]   38         | 1          |  meta           
INFO 01-06 17:11:03.529905.529905 lmp.py:627]   39         | 1          |  meta           
INFO 01-06 17:11:03.529747.529747 lmp.py:627]   42         | 1          |  cuda:1         
INFO 01-06 17:11:03.529589.529589 lmp.py:627]   47         | 1          |  meta           
INFO 01-06 17:11:03.529192.529192 lmp.py:627]   49         | 1          |  cuda:1         
INFO 01-06 17:11:03.529557.529557 lmp.py:627]   50         | 1          |  cuda:1         
INFO 01-06 17:11:03.529445.529445 lmp.py:627]   58         | 1          |  cuda:1         
INFO 01-06 17:11:03.529572.529572 lmp.py:627]   7          | 2          |  cuda:1         
INFO 01-06 17:11:03.529222.529222 lmp.py:627]   18         | 2          |  meta           
INFO 01-06 17:11:03.529064.529064 lmp.py:627]   22         | 2          |  meta           
INFO 01-06 17:11:03.530382.530382 lmp.py:627]   32         | 2          |  meta           
INFO 01-06 17:11:03.530224.530224 lmp.py:627]   34         | 2          |  meta           
INFO 01-06 17:11:03.530589.530589 lmp.py:627]   36         | 2          |  cuda:1         
INFO 01-06 17:11:03.530239.530239 lmp.py:627]   43         | 2          |  meta           
INFO 01-06 17:11:03.530127.530127 lmp.py:627]   53         | 2          |  meta           
INFO 01-06 17:11:03.530777.530777 lmp.py:627]   61         | 2          |  meta           
INFO 01-06 17:11:03.530665.530665 lmp.py:627]   62         | 2          |  cuda:1         
INFO 01-06 17:11:03.530838.530838 lmp.py:627]   21         | 3          |  meta           
INFO 01-06 17:11:03.530441.530441 lmp.py:627]   23         | 3          |  meta           
INFO 01-06 17:11:03.530568.530568 lmp.py:627]   25         | 3          |  cuda:1         
INFO 01-06 17:11:03.530410.530410 lmp.py:627]   28         | 3          |  cuda:1         
INFO 01-06 17:11:03.530775.530775 lmp.py:627]   31         | 3          |  cuda:1         
INFO 01-06 17:11:03.530663.530663 lmp.py:627]   48         | 3          |  cuda:1         
INFO 01-06 17:11:03.530836.530836 lmp.py:627]   59         | 3          |  cuda:1         
INFO 01-06 17:11:03.530247.530247 lmp.py:627]   60         | 3          |  meta           
INFO 01-06 17:11:03.530897.530897 lmp.py:627]   5          | 4          |  cuda:1         
INFO 01-06 17:11:03.530547.530547 lmp.py:627]   35         | 4          |  cuda:1         
INFO 01-06 17:11:03.530389.530389 lmp.py:627]   45         | 4          |  meta           
INFO 01-06 17:11:03.530231.530231 lmp.py:627]   54         | 4          |  cuda:1         
INFO 01-06 17:11:03.530357.530357 lmp.py:627]   63         | 4          |  meta           
INFO 01-06 17:11:03.530722.530722 lmp.py:627]   24         | 5          |  cuda:1         
INFO 01-06 17:11:03.530610.530610 lmp.py:627]   46         | 5          |  cuda:1         
INFO 01-06 17:11:03.530260.530260 lmp.py:627]   10         | 6          |  cuda:1         
INFO 01-06 17:11:03.530910.530910 lmp.py:627]   44         | 6          |  meta           
INFO 01-06 17:11:03.530321.530321 lmp.py:627]   51         | 6          |  cuda:1         
INFO 01-06 17:11:03.530448.530448 lmp.py:627]   56         | 6          |  cuda:1         
INFO 01-06 17:11:03.530005.530005 lmp.py:627]   57         | 6          |  meta           
INFO 01-06 17:11:03.530847.530847 lmp.py:627]   41         | 8          |  cuda:1         
INFO 01-06 17:11:03.530212.530212 lmp.py:627]   26         | 10         |  cuda:1         
INFO 01-06 17:11:03.530577.530577 lmp.py:627]   3          | 14         |  cuda:1         
INFO 01-06 17:11:03.530703.530703 lmp.py:627]   15         | 17         |  cuda:1         
INFO 01-06 17:11:03.530353.530353 lmp.py:627]   40         | 26         |  cuda:1         
INFO 01-06 17:11:03.530003.530003 lmp.py:628] ============================================================
INFO 01-06 17:11:03.530003.530003 lmp.py:628] 
INFO 01-06 17:11:03.530090.530090 lmp.py:630] experts_gpu_list: [1, 11, 19, 33, 42, 49, 50, 58, 7, 36, 62, 25, 28, 31, 48, 59, 5, 35, 54, 24, 46, 10, 51, 56, 41, 26, 3, 15, 40] num: 29
INFO 01-06 17:11:03.530886.530886 lmp.py:631] experts_cpu_list: [14, 30, 38, 39, 47, 18, 22, 32, 34, 43, 53, 61, 21, 23, 60, 45, 63, 44, 57] num: 19
INFO 01-06 17:11:03.530602.530602 lmp.py:632] expert_actual_device_map {0: 'cuda:1', 1: 'cuda:1', 2: 'cuda:1', 3: 'cuda:1', 4: 'cuda:1', 5: 'cuda:1', 6: 'cuda:1', 7: 'cuda:1', 8: 'cuda:1', 9: 'cuda:1', 10: 'cuda:1', 11: 'cuda:1', 12: 'meta', 13: 'meta', 14: 'meta', 15: 'cuda:1', 16: 'meta', 17: 'meta', 18: 'meta', 19: 'cuda:1', 20: 'meta', 21: 'meta', 22: 'meta', 23: 'meta', 24: 'cuda:1', 25: 'cuda:1', 26: 'cuda:1', 27: 'meta', 28: 'cuda:1', 29: 'cuda:1', 30: 'meta', 31: 'cuda:1', 32: 'meta', 33: 'cuda:1', 34: 'meta', 35: 'cuda:1', 36: 'cuda:1', 37: 'meta', 38: 'meta', 39: 'meta', 40: 'cuda:1', 41: 'cuda:1', 42: 'cuda:1', 43: 'meta', 44: 'meta', 45: 'meta', 46: 'cuda:1', 47: 'meta', 48: 'cuda:1', 49: 'cuda:1', 50: 'cuda:1', 51: 'cuda:1', 52: 'meta', 53: 'meta', 54: 'cuda:1', 55: 'cuda:1', 56: 'cuda:1', 57: 'meta', 58: 'cuda:1', 59: 'cuda:1', 60: 'meta', 61: 'meta', 62: 'cuda:1', 63: 'meta'}
DEBUG 01-06 17:11:03.530650.530650 cuda_h.py:19] end experts_map_get cost 0.0022687911987304688 seconds
DEBUG 01-06 17:11:03.530864.530864 cuda_h.py:10] start gpu_sexperts
DEBUG 01-06 17:11:03.531055.531055 cuda_h.py:19] end gpu_sexperts cost 0.0003104209899902344 seconds
DEBUG 01-06 17:11:03.531454.531454 cuda_h.py:10] start gpu_experts
DEBUG 01-06 17:11:03.531919.531919 mlpmodule.py:533] gpu group tensors cost 0.0005564689636230469 s
DEBUG 01-06 17:11:03.533674.533674 mlpmodule.py:664]  experts func einsum cost 0.025330066680908203 s
DEBUG 01-06 17:11:03.534091.534091 mlpmodule.py:566] gpu pad cost 0.0016231536865234375 s
DEBUG 01-06 17:11:03.535012.535012 mlpmodule.py:584] gpu group einsum cost 0.00048542022705078125 s
DEBUG 01-06 17:11:03.538070.538070 mlpmodule.py:613] gpu experts func einsum cost 0.0070569515228271484 s
DEBUG 01-06 17:11:03.538669.538669 cuda_h.py:19] end gpu_experts cost 0.007185220718383789 seconds
DEBUG 01-06 17:11:03.538809.538809 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-06 17:11:03.538651.538651 lmp.py:661] 
DEBUG 01-06 17:11:03.538651.538651 lmp.py:661]   Computing 19 experts on CPU...
DEBUG 01-06 17:11:03.538772.538772 cuda_h.py:19] end cpu_experts_submit cost 5.269050598144531e-05 seconds
DEBUG 01-06 17:11:03.538184.538184 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-06 17:11:03.546581.546581 mlpmodule.py:706] group tensors cost 0.007765531539916992 s
DEBUG 01-06 17:11:03.548187.548187 mlpmodule.py:744] pad cost 0.0009791851043701172 s
DEBUG 01-06 17:11:03.548284.548284 mlpmodule.py:750] create cpu tensor cost 4.00543212890625e-05 s
DEBUG 01-06 17:11:03.548657.548657 mlpmodule.py:755] move to cpu cost 2.8848648071289062e-05 s
DEBUG 01-06 17:11:03.550548.550548 mlpmodule.py:769] group_w3: shape=torch.Size([19, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=54788096
DEBUG 01-06 17:11:03.550345.550345 mlpmodule.py:770] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-06 17:11:03.550989.550989 mlpmodule.py:775] group_w3 first element: -0.00848388671875
WARNING 01-06 17:11:03.550899.550899 mlpmodule.py:785] start einsum2
DEBUG 01-06 17:11:03.555920.555920 mlpmodule.py:795] group einsum cost 0.006824970245361328 s
DEBUG 01-06 17:11:03.555806.555806 mlpmodule.py:803] cpy2cputensor cost 0.00010347366333007812 s
DEBUG 01-06 17:11:03.557417.557417 cuda_h.py:19] end wait_cetm_experts cost 0.0191500186920166 seconds
DEBUG 01-06 17:11:03.558471.558471 cuda_h.py:19] end layer_moe_dgenerate_12 cost 0.03056478500366211 seconds
DEBUG 01-06 17:11:03.558213.558213 lmp.py:325] -------------------------------- end decode layer 12 --------------------------------
DEBUG 01-06 17:11:03.558287.558287 lmp.py:298] -------------------------------- start decode layer 13 --------------------------------
DEBUG 01-06 17:11:03.558627.558627 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-06 17:11:03.558300.558300 mlpmodule.py:367] cuda:1 cuda:1
DEBUG 01-06 17:11:03.559952.559952 cuda_h.py:10] start self_attn
cos shape torch.Size([65, 128]) sin shape torch.Size([65, 128]) position_ids tensor([[0]], device='cuda:1')
cos shape torch.Size([1, 1, 1, 128]) sin shape torch.Size([1, 1, 1, 128])
q_embed shape torch.Size([32, 16, 1, 128]) k_embed shape torch.Size([32, 16, 1, 128])
DEBUG 01-06 17:11:03.561740.561740 cuda_h.py:19] end self_attn cost 0.002083301544189453 seconds
DEBUG 01-06 17:11:03.561082.561082 cuda_h.py:19] end iln_self_attn_paln cost 0.0030596256256103516 seconds
DEBUG 01-06 17:11:03.561110.561110 cuda_h.py:10] start layer_moe_dgenerate_13
DEBUG 01-06 17:11:03.561641.561641 cuda_h.py:10] start gate
DEBUG 01-06 17:11:03.562166.562166 cuda_h.py:19] end gate cost 0.0005931854248046875 seconds
DEBUG 01-06 17:11:03.562817.562817 cuda_h.py:10] start experts_map_get
INFO 01-06 17:11:03.562490.562490 lmp.py:609] using loaded check layer: True
INFO 01-06 17:11:03.563799.563799 lmp.py:620] 
INFO 01-06 17:11:03.563799.563799 lmp.py:620] Layer 13 Expert Device Distribution:
INFO 01-06 17:11:03.563106.563106 lmp.py:621]   Active experts: 48 (out of 64 total)
INFO 01-06 17:11:03.563285.563285 lmp.py:622] 
INFO 01-06 17:11:03.563285.563285 lmp.py:622]   Detailed Expert Distribution:
INFO 01-06 17:11:03.563419.563419 lmp.py:623]   Expert ID  | Tokens     | Actual Device  
INFO 01-06 17:11:03.563737.563737 lmp.py:624]   ----------------------------------------------------------------------
INFO 01-06 17:11:03.563963.563963 lmp.py:627]   0          | 1          |  cuda:1         
INFO 01-06 17:11:03.563520.563520 lmp.py:627]   4          | 1          |  cuda:1         
INFO 01-06 17:11:03.563362.563362 lmp.py:627]   5          | 1          |  cuda:1         
INFO 01-06 17:11:03.563204.563204 lmp.py:627]   7          | 1          |  cuda:1         
INFO 01-06 17:11:03.563046.563046 lmp.py:627]   10         | 1          |  meta           
INFO 01-06 17:11:03.563126.563126 lmp.py:627]   11         | 1          |  meta           
INFO 01-06 17:11:03.563207.563207 lmp.py:627]   18         | 1          |  meta           
INFO 01-06 17:11:03.563048.563048 lmp.py:627]   21         | 1          |  cuda:1         
INFO 01-06 17:11:03.563129.563129 lmp.py:627]   34         | 1          |  meta           
INFO 01-06 17:11:03.563447.563447 lmp.py:627]   35         | 1          |  meta           
INFO 01-06 17:11:03.563574.563574 lmp.py:627]   36         | 1          |  cuda:1         
INFO 01-06 17:11:03.563939.563939 lmp.py:627]   50         | 1          |  meta           
INFO 01-06 17:11:03.563066.563066 lmp.py:627]   58         | 1          |  meta           
INFO 01-06 17:11:03.563192.563192 lmp.py:627]   2          | 2          |  cuda:1         
INFO 01-06 17:11:03.563557.563557 lmp.py:627]   8          | 2          |  cuda:1         
INFO 01-06 17:11:03.563876.563876 lmp.py:627]   9          | 2          |  meta           
INFO 01-06 17:11:03.563956.563956 lmp.py:627]   23         | 2          |  cuda:1         
INFO 01-06 17:11:03.564798.564798 lmp.py:627]   24         | 2          |  cuda:1         
INFO 01-06 17:11:03.564878.564878 lmp.py:627]   31         | 2          |  meta           
INFO 01-06 17:11:03.564243.564243 lmp.py:627]   33         | 2          |  meta           
INFO 01-06 17:11:03.564608.564608 lmp.py:627]   37         | 2          |  cuda:1         
INFO 01-06 17:11:03.564735.564735 lmp.py:627]   40         | 2          |  meta           
INFO 01-06 17:11:03.564100.564100 lmp.py:627]   57         | 2          |  cuda:1         
INFO 01-06 17:11:03.564988.564988 lmp.py:627]   61         | 2          |  meta           
INFO 01-06 17:11:03.564876.564876 lmp.py:627]   13         | 3          |  meta           
INFO 01-06 17:11:03.564672.564672 lmp.py:627]   16         | 3          |  cuda:1         
INFO 01-06 17:11:03.564752.564752 lmp.py:627]   27         | 3          |  cuda:1         
INFO 01-06 17:11:03.564117.564117 lmp.py:627]   48         | 3          |  meta           
INFO 01-06 17:11:03.564005.564005 lmp.py:627]   14         | 4          |  cuda:1         
INFO 01-06 17:11:03.564609.564609 lmp.py:627]   20         | 4          |  meta           
INFO 01-06 17:11:03.564735.564735 lmp.py:627]   22         | 4          |  cuda:1         
INFO 01-06 17:11:03.564101.564101 lmp.py:627]   38         | 4          |  cuda:1         
INFO 01-06 17:11:03.564750.564750 lmp.py:627]   52         | 4          |  cuda:1         
INFO 01-06 17:11:03.564415.564415 lmp.py:627]   63         | 4          |  meta           
INFO 01-06 17:11:03.564740.564740 lmp.py:627]   3          | 5          |  cuda:1         
INFO 01-06 17:11:03.564913.564913 lmp.py:627]   29         | 5          |  cuda:1         
INFO 01-06 17:11:03.564656.564656 lmp.py:627]   41         | 5          |  cuda:1         
INFO 01-06 17:11:03.564683.564683 lmp.py:627]   17         | 6          |  cuda:1         
INFO 01-06 17:11:03.564948.564948 lmp.py:627]   46         | 6          |  meta           
INFO 01-06 17:11:03.564691.564691 lmp.py:627]   54         | 6          |  cuda:1         
INFO 01-06 17:11:03.564956.564956 lmp.py:627]   44         | 7          |  cuda:1         
INFO 01-06 17:11:03.564414.564414 lmp.py:627]   55         | 7          |  meta           
INFO 01-06 17:11:03.564872.564872 lmp.py:627]   59         | 8          |  meta           
INFO 01-06 17:11:03.564806.564806 lmp.py:627]   60         | 11         |  cuda:1         
INFO 01-06 17:11:03.564264.564264 lmp.py:627]   15         | 12         |  cuda:1         
INFO 01-06 17:11:03.564529.564529 lmp.py:627]   49         | 12         |  cuda:1         
INFO 01-06 17:11:03.564033.564033 lmp.py:627]   56         | 13         |  meta           
INFO 01-06 17:11:03.564776.564776 lmp.py:627]   45         | 18         |  cuda:1         
INFO 01-06 17:11:03.564326.564326 lmp.py:628] ============================================================
INFO 01-06 17:11:03.564326.564326 lmp.py:628] 
INFO 01-06 17:11:03.564075.564075 lmp.py:630] experts_gpu_list: [0, 4, 5, 7, 21, 36, 2, 8, 23, 24, 37, 57, 16, 27, 14, 22, 38, 52, 3, 29, 41, 17, 54, 44, 60, 15, 49, 45] num: 28
INFO 01-06 17:11:03.564394.564394 lmp.py:631] experts_cpu_list: [10, 11, 18, 34, 35, 50, 58, 9, 31, 33, 40, 61, 13, 48, 20, 63, 46, 55, 59, 56] num: 20
INFO 01-06 17:11:03.564250.564250 lmp.py:632] expert_actual_device_map {0: 'cuda:1', 1: 'cuda:1', 2: 'cuda:1', 3: 'cuda:1', 4: 'cuda:1', 5: 'cuda:1', 6: 'cuda:1', 7: 'cuda:1', 8: 'cuda:1', 9: 'meta', 10: 'meta', 11: 'meta', 12: 'meta', 13: 'meta', 14: 'cuda:1', 15: 'cuda:1', 16: 'cuda:1', 17: 'cuda:1', 18: 'meta', 19: 'meta', 20: 'meta', 21: 'cuda:1', 22: 'cuda:1', 23: 'cuda:1', 24: 'cuda:1', 25: 'cuda:1', 26: 'meta', 27: 'cuda:1', 28: 'cuda:1', 29: 'cuda:1', 30: 'meta', 31: 'meta', 32: 'meta', 33: 'meta', 34: 'meta', 35: 'meta', 36: 'cuda:1', 37: 'cuda:1', 38: 'cuda:1', 39: 'cuda:1', 40: 'meta', 41: 'cuda:1', 42: 'meta', 43: 'cuda:1', 44: 'cuda:1', 45: 'cuda:1', 46: 'meta', 47: 'cuda:1', 48: 'meta', 49: 'cuda:1', 50: 'meta', 51: 'cuda:1', 52: 'cuda:1', 53: 'meta', 54: 'cuda:1', 55: 'meta', 56: 'meta', 57: 'cuda:1', 58: 'meta', 59: 'meta', 60: 'cuda:1', 61: 'meta', 62: 'cuda:1', 63: 'meta'}
DEBUG 01-06 17:11:03.564867.564867 cuda_h.py:19] end experts_map_get cost 0.0022492408752441406 seconds
DEBUG 01-06 17:11:03.564220.564220 cuda_h.py:10] start gpu_sexperts
DEBUG 01-06 17:11:03.565663.565663 cuda_h.py:19] end gpu_sexperts cost 0.0003218650817871094 seconds
DEBUG 01-06 17:11:03.565155.565155 cuda_h.py:10] start gpu_experts
DEBUG 01-06 17:11:03.565201.565201 mlpmodule.py:533] gpu group tensors cost 0.0005230903625488281 s
DEBUG 01-06 17:11:03.566401.566401 mlpmodule.py:664]  experts func einsum cost 0.0279080867767334 s
DEBUG 01-06 17:11:03.567318.567318 mlpmodule.py:566] gpu pad cost 0.0016388893127441406 s
DEBUG 01-06 17:11:03.568868.568868 mlpmodule.py:584] gpu group einsum cost 0.0004935264587402344 s
DEBUG 01-06 17:11:03.571123.571123 mlpmodule.py:613] gpu experts func einsum cost 0.005905628204345703 s
DEBUG 01-06 17:11:03.571802.571802 cuda_h.py:19] end gpu_experts cost 0.0060634613037109375 seconds
DEBUG 01-06 17:11:03.571419.571419 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-06 17:11:03.571175.571175 lmp.py:661] 
DEBUG 01-06 17:11:03.571175.571175 lmp.py:661]   Computing 20 experts on CPU...
DEBUG 01-06 17:11:03.571310.571310 cuda_h.py:19] end cpu_experts_submit cost 6.318092346191406e-05 seconds
DEBUG 01-06 17:11:03.571728.571728 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-06 17:11:03.579919.579919 mlpmodule.py:706] group tensors cost 0.007552623748779297 s
DEBUG 01-06 17:11:03.580795.580795 mlpmodule.py:744] pad cost 0.0010957717895507812 s
DEBUG 01-06 17:11:03.581276.581276 mlpmodule.py:750] create cpu tensor cost 3.886222839355469e-05 s
DEBUG 01-06 17:11:03.581410.581410 mlpmodule.py:755] move to cpu cost 2.9325485229492188e-05 s
DEBUG 01-06 17:11:03.583838.583838 mlpmodule.py:769] group_w3: shape=torch.Size([20, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=57671680
DEBUG 01-06 17:11:03.584688.584688 mlpmodule.py:770] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-06 17:11:03.584855.584855 mlpmodule.py:775] group_w3 first element: 0.039306640625
WARNING 01-06 17:11:03.584288.584288 mlpmodule.py:785] start einsum2
DEBUG 01-06 17:11:03.589127.589127 mlpmodule.py:795] group einsum cost 0.008316516876220703 s
DEBUG 01-06 17:11:03.589325.589325 mlpmodule.py:803] cpy2cputensor cost 0.0001163482666015625 s
DEBUG 01-06 17:11:03.592251.592251 cuda_h.py:19] end wait_cetm_experts cost 0.020665645599365234 seconds
DEBUG 01-06 17:11:03.592032.592032 cuda_h.py:19] end layer_moe_dgenerate_13 cost 0.030873775482177734 seconds
DEBUG 01-06 17:11:03.592528.592528 lmp.py:325] -------------------------------- end decode layer 13 --------------------------------
DEBUG 01-06 17:11:03.592959.592959 lmp.py:298] -------------------------------- start decode layer 14 --------------------------------
DEBUG 01-06 17:11:03.592139.592139 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-06 17:11:03.593679.593679 mlpmodule.py:367] cuda:1 cuda:1
DEBUG 01-06 17:11:03.593871.593871 cuda_h.py:10] start self_attn
cos shape torch.Size([65, 128]) sin shape torch.Size([65, 128]) position_ids tensor([[0]], device='cuda:1')
cos shape torch.Size([1, 1, 1, 128]) sin shape torch.Size([1, 1, 1, 128])
q_embed shape torch.Size([32, 16, 1, 128]) k_embed shape torch.Size([32, 16, 1, 128])
DEBUG 01-06 17:11:03.595393.595393 cuda_h.py:19] end self_attn cost 0.0018646717071533203 seconds
DEBUG 01-06 17:11:03.595596.595596 cuda_h.py:19] end iln_self_attn_paln cost 0.002722501754760742 seconds
DEBUG 01-06 17:11:03.595147.595147 cuda_h.py:10] start layer_moe_dgenerate_14
DEBUG 01-06 17:11:03.595155.595155 cuda_h.py:10] start gate
DEBUG 01-06 17:11:03.596655.596655 cuda_h.py:19] end gate cost 0.000640869140625 seconds
DEBUG 01-06 17:11:03.596776.596776 cuda_h.py:10] start experts_map_get
INFO 01-06 17:11:03.596277.596277 lmp.py:609] using loaded check layer: True
INFO 01-06 17:11:03.597196.597196 lmp.py:620] 
INFO 01-06 17:11:03.597196.597196 lmp.py:620] Layer 14 Expert Device Distribution:
INFO 01-06 17:11:03.597495.597495 lmp.py:621]   Active experts: 51 (out of 64 total)
INFO 01-06 17:11:03.597053.597053 lmp.py:622] 
INFO 01-06 17:11:03.597053.597053 lmp.py:622]   Detailed Expert Distribution:
INFO 01-06 17:11:03.597517.597517 lmp.py:623]   Expert ID  | Tokens     | Actual Device  
INFO 01-06 17:11:03.597452.597452 lmp.py:624]   ----------------------------------------------------------------------
INFO 01-06 17:11:03.597817.597817 lmp.py:627]   10         | 1          |  cuda:1         
INFO 01-06 17:11:03.597274.597274 lmp.py:627]   11         | 1          |  cuda:1         
INFO 01-06 17:11:03.597017.597017 lmp.py:627]   12         | 1          |  cuda:1         
INFO 01-06 17:11:03.597759.597759 lmp.py:627]   13         | 1          |  cuda:1         
INFO 01-06 17:11:03.597740.597740 lmp.py:627]   19         | 1          |  meta           
INFO 01-06 17:11:03.597244.597244 lmp.py:627]   20         | 1          |  cuda:1         
INFO 01-06 17:11:03.597278.597278 lmp.py:627]   24         | 1          |  cuda:1         
INFO 01-06 17:11:03.597020.597020 lmp.py:627]   37         | 1          |  cuda:1         
INFO 01-06 17:11:03.597763.597763 lmp.py:627]   40         | 1          |  meta           
INFO 01-06 17:11:03.597459.597459 lmp.py:627]   41         | 1          |  meta           
INFO 01-06 17:11:03.597155.597155 lmp.py:627]   43         | 1          |  cuda:1         
INFO 01-06 17:11:03.597374.597374 lmp.py:627]   59         | 1          |  meta           
INFO 01-06 17:11:03.597117.597117 lmp.py:627]   3          | 2          |  cuda:1         
INFO 01-06 17:11:03.597621.597621 lmp.py:627]   14         | 2          |  cuda:1         
INFO 01-06 17:11:03.597125.597125 lmp.py:627]   17         | 2          |  meta           
INFO 01-06 17:11:03.597867.597867 lmp.py:627]   26         | 2          |  cuda:1         
INFO 01-06 17:11:03.597371.597371 lmp.py:627]   30         | 2          |  cuda:1         
INFO 01-06 17:11:03.597398.597398 lmp.py:627]   32         | 2          |  cuda:1         
INFO 01-06 17:11:03.597902.597902 lmp.py:627]   35         | 2          |  meta           
INFO 01-06 17:11:03.597406.597406 lmp.py:627]   38         | 2          |  meta           
INFO 01-06 17:11:03.598864.598864 lmp.py:627]   48         | 2          |  meta           
INFO 01-06 17:11:03.598798.598798 lmp.py:627]   57         | 2          |  cuda:1         
INFO 01-06 17:11:03.598256.598256 lmp.py:627]   0          | 3          |  cuda:1         
INFO 01-06 17:11:03.598714.598714 lmp.py:627]   4          | 3          |  cuda:1         
INFO 01-06 17:11:03.598218.598218 lmp.py:627]   5          | 3          |  cuda:1         
INFO 01-06 17:11:03.598722.598722 lmp.py:627]   27         | 3          |  meta           
INFO 01-06 17:11:03.598226.598226 lmp.py:627]   29         | 3          |  meta           
INFO 01-06 17:11:03.598491.598491 lmp.py:627]   44         | 3          |  cuda:1         
INFO 01-06 17:11:03.598518.598518 lmp.py:627]   46         | 3          |  cuda:1         
INFO 01-06 17:11:03.598022.598022 lmp.py:627]   54         | 3          |  meta           
INFO 01-06 17:11:03.598718.598718 lmp.py:627]   60         | 3          |  meta           
INFO 01-06 17:11:03.598415.598415 lmp.py:627]   56         | 4          |  cuda:1         
INFO 01-06 17:11:03.598634.598634 lmp.py:627]   8          | 5          |  cuda:1         
INFO 01-06 17:11:03.598853.598853 lmp.py:627]   18         | 5          |  meta           
INFO 01-06 17:11:03.598119.598119 lmp.py:627]   33         | 5          |  cuda:1         
INFO 01-06 17:11:03.598623.598623 lmp.py:627]   39         | 5          |  meta           
INFO 01-06 17:11:03.598888.598888 lmp.py:627]   42         | 5          |  cuda:1         
INFO 01-06 17:11:03.598677.598677 lmp.py:627]   51         | 5          |  cuda:1         
INFO 01-06 17:11:03.598704.598704 lmp.py:627]   61         | 5          |  meta           
INFO 01-06 17:11:03.598731.598731 lmp.py:627]   1          | 6          |  cuda:1         
INFO 01-06 17:11:03.598427.598427 lmp.py:627]   23         | 6          |  cuda:1         
INFO 01-06 17:11:03.598408.598408 lmp.py:627]   25         | 6          |  cuda:1         
INFO 01-06 17:11:03.598058.598058 lmp.py:627]   28         | 6          |  cuda:1         
INFO 01-06 17:11:03.598615.598615 lmp.py:627]   6          | 7          |  cuda:1         
INFO 01-06 17:11:03.598119.598119 lmp.py:627]   15         | 8          |  meta           
INFO 01-06 17:11:03.598623.598623 lmp.py:627]   31         | 8          |  meta           
INFO 01-06 17:11:03.598650.598650 lmp.py:627]   53         | 8          |  meta           
INFO 01-06 17:11:03.598154.598154 lmp.py:627]   58         | 8          |  cuda:1         
INFO 01-06 17:11:03.598420.598420 lmp.py:627]   47         | 9          |  cuda:1         
INFO 01-06 17:11:03.598262.598262 lmp.py:627]   55         | 11         |  cuda:1         
INFO 01-06 17:11:03.598819.598819 lmp.py:627]   62         | 11         |  cuda:1         
INFO 01-06 17:11:03.598707.598707 lmp.py:628] ============================================================
INFO 01-06 17:11:03.598707.598707 lmp.py:628] 
INFO 01-06 17:11:03.598986.598986 lmp.py:630] experts_gpu_list: [10, 11, 12, 13, 20, 24, 37, 43, 3, 14, 26, 30, 32, 57, 0, 4, 5, 44, 46, 56, 8, 33, 42, 51, 1, 23, 25, 28, 6, 58, 47, 55, 62] num: 33
INFO 01-06 17:11:03.598259.598259 lmp.py:631] experts_cpu_list: [19, 40, 41, 59, 17, 35, 38, 48, 27, 29, 54, 60, 18, 39, 61, 15, 31, 53] num: 18
INFO 01-06 17:11:03.598306.598306 lmp.py:632] expert_actual_device_map {0: 'cuda:1', 1: 'cuda:1', 2: 'cuda:1', 3: 'cuda:1', 4: 'cuda:1', 5: 'cuda:1', 6: 'cuda:1', 7: 'cuda:1', 8: 'cuda:1', 9: 'cuda:1', 10: 'cuda:1', 11: 'cuda:1', 12: 'cuda:1', 13: 'cuda:1', 14: 'cuda:1', 15: 'meta', 16: 'meta', 17: 'meta', 18: 'meta', 19: 'meta', 20: 'cuda:1', 21: 'meta', 22: 'meta', 23: 'cuda:1', 24: 'cuda:1', 25: 'cuda:1', 26: 'cuda:1', 27: 'meta', 28: 'cuda:1', 29: 'meta', 30: 'cuda:1', 31: 'meta', 32: 'cuda:1', 33: 'cuda:1', 34: 'meta', 35: 'meta', 36: 'meta', 37: 'cuda:1', 38: 'meta', 39: 'meta', 40: 'meta', 41: 'meta', 42: 'cuda:1', 43: 'cuda:1', 44: 'cuda:1', 45: 'meta', 46: 'cuda:1', 47: 'cuda:1', 48: 'meta', 49: 'meta', 50: 'meta', 51: 'cuda:1', 52: 'meta', 53: 'meta', 54: 'meta', 55: 'cuda:1', 56: 'cuda:1', 57: 'cuda:1', 58: 'cuda:1', 59: 'meta', 60: 'meta', 61: 'meta', 62: 'cuda:1', 63: 'cuda:1'}
DEBUG 01-06 17:11:03.598877.598877 cuda_h.py:19] end experts_map_get cost 0.0021820068359375 seconds
DEBUG 01-06 17:11:03.598853.598853 cuda_h.py:10] start gpu_sexperts
DEBUG 01-06 17:11:03.599627.599627 cuda_h.py:19] end gpu_sexperts cost 0.0003101825714111328 seconds
DEBUG 01-06 17:11:03.599503.599503 cuda_h.py:10] start gpu_experts
DEBUG 01-06 17:11:03.599750.599750 mlpmodule.py:533] gpu group tensors cost 0.0006036758422851562 s
DEBUG 01-06 17:11:03.601518.601518 mlpmodule.py:664]  experts func einsum cost 0.029988765716552734 s
DEBUG 01-06 17:11:03.601432.601432 mlpmodule.py:566] gpu pad cost 0.0019137859344482422 s
DEBUG 01-06 17:11:03.602777.602777 mlpmodule.py:584] gpu group einsum cost 0.00048089027404785156 s
DEBUG 01-06 17:11:03.605877.605877 mlpmodule.py:613] gpu experts func einsum cost 0.006558656692504883 s
DEBUG 01-06 17:11:03.606205.606205 cuda_h.py:19] end gpu_experts cost 0.006701946258544922 seconds
DEBUG 01-06 17:11:03.606815.606815 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-06 17:11:03.606564.606564 lmp.py:661] 
DEBUG 01-06 17:11:03.606564.606564 lmp.py:661]   Computing 18 experts on CPU...
DEBUG 01-06 17:11:03.606255.606255 cuda_h.py:19] end cpu_experts_submit cost 5.221366882324219e-05 seconds
DEBUG 01-06 17:11:03.606117.606117 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-06 17:11:03.609825.609825 mlpmodule.py:706] group tensors cost 0.0036046504974365234 s
DEBUG 01-06 17:11:03.611954.611954 mlpmodule.py:744] pad cost 0.0009474754333496094 s
DEBUG 01-06 17:11:03.611911.611911 mlpmodule.py:750] create cpu tensor cost 3.981590270996094e-05 s
DEBUG 01-06 17:11:03.611807.611807 mlpmodule.py:755] move to cpu cost 2.8848648071289062e-05 s
DEBUG 01-06 17:11:03.614582.614582 mlpmodule.py:769] group_w3: shape=torch.Size([18, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=51904512
DEBUG 01-06 17:11:03.614240.614240 mlpmodule.py:770] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-06 17:11:03.614884.614884 mlpmodule.py:775] group_w3 first element: 0.003143310546875
WARNING 01-06 17:11:03.614503.614503 mlpmodule.py:785] start einsum2
DEBUG 01-06 17:11:03.618187.618187 mlpmodule.py:795] group einsum cost 0.0073320865631103516 s
DEBUG 01-06 17:11:03.619814.619814 mlpmodule.py:803] cpy2cputensor cost 8.273124694824219e-05 s
DEBUG 01-06 17:11:03.621004.621004 cuda_h.py:19] end wait_cetm_experts cost 0.015317678451538086 seconds
DEBUG 01-06 17:11:03.621374.621374 cuda_h.py:19] end layer_moe_dgenerate_14 cost 0.026111364364624023 seconds
DEBUG 01-06 17:11:03.622836.622836 lmp.py:325] -------------------------------- end decode layer 14 --------------------------------
DEBUG 01-06 17:11:03.622983.622983 lmp.py:298] -------------------------------- start decode layer 15 --------------------------------
DEBUG 01-06 17:11:03.622017.622017 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-06 17:11:03.622889.622889 mlpmodule.py:367] cuda:1 cuda:1
DEBUG 01-06 17:11:03.622477.622477 cuda_h.py:10] start self_attn
cos shape torch.Size([65, 128]) sin shape torch.Size([65, 128]) position_ids tensor([[0]], device='cuda:1')
cos shape torch.Size([1, 1, 1, 128]) sin shape torch.Size([1, 1, 1, 128])
q_embed shape torch.Size([32, 16, 1, 128]) k_embed shape torch.Size([32, 16, 1, 128])
DEBUG 01-06 17:11:03.624212.624212 cuda_h.py:19] end self_attn cost 0.0019190311431884766 seconds
DEBUG 01-06 17:11:03.625821.625821 cuda_h.py:19] end iln_self_attn_paln cost 0.002801179885864258 seconds
DEBUG 01-06 17:11:03.625710.625710 cuda_h.py:10] start layer_moe_dgenerate_15
DEBUG 01-06 17:11:03.625195.625195 cuda_h.py:10] start gate
DEBUG 01-06 17:11:03.625210.625210 cuda_h.py:19] end gate cost 0.0006022453308105469 seconds
DEBUG 01-06 17:11:03.625523.625523 cuda_h.py:10] start experts_map_get
INFO 01-06 17:11:03.626992.626992 lmp.py:609] using loaded check layer: True
INFO 01-06 17:11:03.626315.626315 lmp.py:620] 
INFO 01-06 17:11:03.626315.626315 lmp.py:620] Layer 15 Expert Device Distribution:
INFO 01-06 17:11:03.626920.626920 lmp.py:621]   Active experts: 54 (out of 64 total)
INFO 01-06 17:11:03.626530.626530 lmp.py:622] 
INFO 01-06 17:11:03.626530.626530 lmp.py:622]   Detailed Expert Distribution:
INFO 01-06 17:11:03.626902.626902 lmp.py:623]   Expert ID  | Tokens     | Actual Device  
INFO 01-06 17:11:03.626697.626697 lmp.py:624]   ----------------------------------------------------------------------
INFO 01-06 17:11:03.626970.626970 lmp.py:627]   1          | 1          |  cuda:1         
INFO 01-06 17:11:03.626288.626288 lmp.py:627]   2          | 1          |  cuda:1         
INFO 01-06 17:11:03.626892.626892 lmp.py:627]   3          | 1          |  cuda:1         
INFO 01-06 17:11:03.626734.626734 lmp.py:627]   7          | 1          |  cuda:1         
INFO 01-06 17:11:03.626099.626099 lmp.py:627]   13         | 1          |  meta           
INFO 01-06 17:11:03.626417.626417 lmp.py:627]   14         | 1          |  meta           
INFO 01-06 17:11:03.627690.627690 lmp.py:627]   16         | 1          |  cuda:1         
INFO 01-06 17:11:03.627531.627531 lmp.py:627]   17         | 1          |  cuda:1         
INFO 01-06 17:11:03.627612.627612 lmp.py:627]   19         | 1          |  meta           
INFO 01-06 17:11:03.627977.627977 lmp.py:627]   20         | 1          |  meta           
INFO 01-06 17:11:03.627388.627388 lmp.py:627]   23         | 1          |  cuda:1         
INFO 01-06 17:11:03.627753.627753 lmp.py:627]   34         | 1          |  meta           
INFO 01-06 17:11:03.627880.627880 lmp.py:627]   41         | 1          |  meta           
INFO 01-06 17:11:03.627768.627768 lmp.py:627]   42         | 1          |  meta           
INFO 01-06 17:11:03.627371.627371 lmp.py:627]   54         | 1          |  meta           
INFO 01-06 17:11:03.627452.627452 lmp.py:627]   55         | 1          |  meta           
INFO 01-06 17:11:03.627532.627532 lmp.py:627]   61         | 1          |  meta           
INFO 01-06 17:11:03.627374.627374 lmp.py:627]   5          | 2          |  cuda:1         
INFO 01-06 17:11:03.627262.627262 lmp.py:627]   15         | 2          |  meta           
INFO 01-06 17:11:03.627627.627627 lmp.py:627]   21         | 2          |  meta           
INFO 01-06 17:11:03.627992.627992 lmp.py:627]   22         | 2          |  meta           
INFO 01-06 17:11:03.627357.627357 lmp.py:627]   25         | 2          |  meta           
INFO 01-06 17:11:03.627245.627245 lmp.py:627]   45         | 2          |  meta           
INFO 01-06 17:11:03.627087.627087 lmp.py:627]   57         | 2          |  cuda:1         
INFO 01-06 17:11:03.627406.627406 lmp.py:627]   60         | 2          |  cuda:1         
INFO 01-06 17:11:03.627248.627248 lmp.py:627]   63         | 2          |  meta           
INFO 01-06 17:11:03.627089.627089 lmp.py:627]   4          | 3          |  cuda:1         
INFO 01-06 17:11:03.627508.627508 lmp.py:627]   6          | 3          |  cuda:1         
INFO 01-06 17:11:03.627012.627012 lmp.py:627]   9          | 3          |  cuda:1         
INFO 01-06 17:11:03.627800.627800 lmp.py:627]   11         | 3          |  cuda:1         
INFO 01-06 17:11:03.627066.627066 lmp.py:627]   27         | 3          |  cuda:1         
INFO 01-06 17:11:03.627716.627716 lmp.py:627]   32         | 3          |  meta           
INFO 01-06 17:11:03.627081.627081 lmp.py:627]   35         | 3          |  cuda:1         
INFO 01-06 17:11:03.627545.627545 lmp.py:627]   38         | 3          |  cuda:1         
INFO 01-06 17:11:03.627864.627864 lmp.py:627]   48         | 3          |  cuda:1         
INFO 01-06 17:11:03.627183.627183 lmp.py:627]   56         | 3          |  cuda:1         
INFO 01-06 17:11:03.627217.627217 lmp.py:627]   59         | 3          |  meta           
INFO 01-06 17:11:03.627582.627582 lmp.py:627]   24         | 4          |  cuda:1         
INFO 01-06 17:11:03.627185.627185 lmp.py:627]   39         | 4          |  cuda:1         
INFO 01-06 17:11:03.627835.627835 lmp.py:627]   8          | 5          |  cuda:1         
INFO 01-06 17:11:03.627438.627438 lmp.py:627]   31         | 5          |  cuda:1         
INFO 01-06 17:11:03.627234.627234 lmp.py:627]   36         | 5          |  cuda:1         
INFO 01-06 17:11:03.627552.627552 lmp.py:627]   40         | 5          |  meta           
INFO 01-06 17:11:03.627633.627633 lmp.py:627]   51         | 5          |  meta           
INFO 01-06 17:11:03.627998.627998 lmp.py:627]   62         | 5          |  meta           
INFO 01-06 17:11:03.627886.627886 lmp.py:627]   28         | 6          |  meta           
INFO 01-06 17:11:03.627012.627012 lmp.py:627]   29         | 8          |  cuda:1         
INFO 01-06 17:11:03.627854.627854 lmp.py:627]   43         | 8          |  cuda:1         
INFO 01-06 17:11:03.628458.628458 lmp.py:627]   26         | 9          |  cuda:1         
INFO 01-06 17:11:03.628061.628061 lmp.py:627]   58         | 10         |  cuda:1         
INFO 01-06 17:11:03.628857.628857 lmp.py:627]   10         | 11         |  meta           
INFO 01-06 17:11:03.628937.628937 lmp.py:627]   47         | 11         |  cuda:1         
INFO 01-06 17:11:03.628017.628017 lmp.py:627]   49         | 11         |  cuda:1         
INFO 01-06 17:11:03.628859.628859 lmp.py:627]   33         | 12         |  cuda:1         
INFO 01-06 17:11:03.628271.628271 lmp.py:628] ============================================================
INFO 01-06 17:11:03.628271.628271 lmp.py:628] 
INFO 01-06 17:11:03.628596.628596 lmp.py:630] experts_gpu_list: [1, 2, 3, 7, 16, 17, 23, 5, 57, 60, 4, 6, 9, 11, 27, 35, 38, 48, 56, 24, 39, 8, 31, 36, 29, 43, 26, 58, 47, 49, 33] num: 31
INFO 01-06 17:11:03.628868.628868 lmp.py:631] experts_cpu_list: [13, 14, 19, 20, 34, 41, 42, 54, 55, 61, 15, 21, 22, 25, 45, 63, 32, 59, 40, 51, 62, 28, 10] num: 23
INFO 01-06 17:11:03.628870.628870 lmp.py:632] expert_actual_device_map {0: 'cuda:1', 1: 'cuda:1', 2: 'cuda:1', 3: 'cuda:1', 4: 'cuda:1', 5: 'cuda:1', 6: 'cuda:1', 7: 'cuda:1', 8: 'cuda:1', 9: 'cuda:1', 10: 'meta', 11: 'cuda:1', 12: 'meta', 13: 'meta', 14: 'meta', 15: 'meta', 16: 'cuda:1', 17: 'cuda:1', 18: 'cuda:1', 19: 'meta', 20: 'meta', 21: 'meta', 22: 'meta', 23: 'cuda:1', 24: 'cuda:1', 25: 'meta', 26: 'cuda:1', 27: 'cuda:1', 28: 'meta', 29: 'cuda:1', 30: 'cuda:1', 31: 'cuda:1', 32: 'meta', 33: 'cuda:1', 34: 'meta', 35: 'cuda:1', 36: 'cuda:1', 37: 'cuda:1', 38: 'cuda:1', 39: 'cuda:1', 40: 'meta', 41: 'meta', 42: 'meta', 43: 'cuda:1', 44: 'cuda:1', 45: 'meta', 46: 'cuda:1', 47: 'cuda:1', 48: 'cuda:1', 49: 'cuda:1', 50: 'meta', 51: 'meta', 52: 'meta', 53: 'meta', 54: 'meta', 55: 'meta', 56: 'cuda:1', 57: 'cuda:1', 58: 'cuda:1', 59: 'meta', 60: 'cuda:1', 61: 'meta', 62: 'meta', 63: 'meta'}
DEBUG 01-06 17:11:03.628156.628156 cuda_h.py:19] end experts_map_get cost 0.002433300018310547 seconds
DEBUG 01-06 17:11:03.628538.628538 mlpmodule.py:664]  experts func einsum cost 0.022086143493652344 s
DEBUG 01-06 17:11:03.628384.628384 cuda_h.py:10] start gpu_sexperts
DEBUG 01-06 17:11:03.629686.629686 cuda_h.py:19] end gpu_sexperts cost 0.00033354759216308594 seconds
DEBUG 01-06 17:11:03.629383.629383 cuda_h.py:10] start gpu_experts
DEBUG 01-06 17:11:03.629067.629067 mlpmodule.py:533] gpu group tensors cost 0.0005717277526855469 s
DEBUG 01-06 17:11:03.631188.631188 mlpmodule.py:566] gpu pad cost 0.001583099365234375 s
DEBUG 01-06 17:11:03.631736.631736 mlpmodule.py:584] gpu group einsum cost 0.0004742145538330078 s
DEBUG 01-06 17:11:03.635970.635970 mlpmodule.py:613] gpu experts func einsum cost 0.005975484848022461 s
DEBUG 01-06 17:11:03.635669.635669 cuda_h.py:19] end gpu_experts cost 0.006112098693847656 seconds
DEBUG 01-06 17:11:03.635478.635478 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-06 17:11:03.635657.635657 lmp.py:661] 
DEBUG 01-06 17:11:03.635657.635657 lmp.py:661]   Computing 23 experts on CPU...
DEBUG 01-06 17:11:03.635931.635931 cuda_h.py:19] end cpu_experts_submit cost 6.0558319091796875e-05 seconds
DEBUG 01-06 17:11:03.635534.635534 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-06 17:11:03.639315.639315 mlpmodule.py:706] group tensors cost 0.003587961196899414 s
DEBUG 01-06 17:11:03.640766.640766 mlpmodule.py:744] pad cost 0.0012764930725097656 s
DEBUG 01-06 17:11:03.641008.641008 mlpmodule.py:750] create cpu tensor cost 3.790855407714844e-05 s
DEBUG 01-06 17:11:03.641712.641712 mlpmodule.py:755] move to cpu cost 2.8133392333984375e-05 s
DEBUG 01-06 17:11:03.644059.644059 mlpmodule.py:769] group_w3: shape=torch.Size([23, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=66322432
DEBUG 01-06 17:11:03.644617.644617 mlpmodule.py:770] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-06 17:11:03.644030.644030 mlpmodule.py:775] group_w3 first element: -0.0306396484375
WARNING 01-06 17:11:03.644231.644231 mlpmodule.py:785] start einsum2
DEBUG 01-06 17:11:03.650945.650945 mlpmodule.py:795] group einsum cost 0.008873462677001953 s
DEBUG 01-06 17:11:03.650896.650896 mlpmodule.py:803] cpy2cputensor cost 7.796287536621094e-05 s
DEBUG 01-06 17:11:03.653100.653100 cuda_h.py:19] end wait_cetm_experts cost 0.017782926559448242 seconds
DEBUG 01-06 17:11:03.653900.653900 cuda_h.py:19] end layer_moe_dgenerate_15 cost 0.02857685089111328 seconds
DEBUG 01-06 17:11:03.653979.653979 lmp.py:325] -------------------------------- end decode layer 15 --------------------------------
DEBUG 01-06 17:11:03.653510.653510 lmp.py:298] -------------------------------- start decode layer 16 --------------------------------
DEBUG 01-06 17:11:03.653451.653451 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-06 17:11:03.654038.654038 mlpmodule.py:367] cuda:1 cuda:1
DEBUG 01-06 17:11:03.654706.654706 cuda_h.py:10] start self_attn
cos shape torch.Size([65, 128]) sin shape torch.Size([65, 128]) position_ids tensor([[0]], device='cuda:1')
cos shape torch.Size([1, 1, 1, 128]) sin shape torch.Size([1, 1, 1, 128])
q_embed shape torch.Size([32, 16, 1, 128]) k_embed shape torch.Size([32, 16, 1, 128])
DEBUG 01-06 17:11:03.656298.656298 cuda_h.py:19] end self_attn cost 0.001981496810913086 seconds
DEBUG 01-06 17:11:03.656376.656376 cuda_h.py:19] end iln_self_attn_paln cost 0.0028562545776367188 seconds
DEBUG 01-06 17:11:03.656881.656881 cuda_h.py:10] start layer_moe_dgenerate_16
DEBUG 01-06 17:11:03.656042.656042 cuda_h.py:10] start gate
DEBUG 01-06 17:11:03.657560.657560 cuda_h.py:19] end gate cost 0.0006191730499267578 seconds
DEBUG 01-06 17:11:03.657973.657973 cuda_h.py:10] start experts_map_get
INFO 01-06 17:11:03.657747.657747 lmp.py:609] using loaded check layer: True
INFO 01-06 17:11:03.658912.658912 lmp.py:620] 
INFO 01-06 17:11:03.658912.658912 lmp.py:620] Layer 16 Expert Device Distribution:
INFO 01-06 17:11:03.658642.658642 lmp.py:621]   Active experts: 53 (out of 64 total)
INFO 01-06 17:11:03.658676.658676 lmp.py:622] 
INFO 01-06 17:11:03.658676.658676 lmp.py:622]   Detailed Expert Distribution:
INFO 01-06 17:11:03.658379.658379 lmp.py:623]   Expert ID  | Tokens     | Actual Device  
INFO 01-06 17:11:03.658081.658081 lmp.py:624]   ----------------------------------------------------------------------
INFO 01-06 17:11:03.658592.658592 lmp.py:627]   0          | 1          |  cuda:1         
INFO 01-06 17:11:03.658719.658719 lmp.py:627]   2          | 1          |  cuda:1         
INFO 01-06 17:11:03.658415.658415 lmp.py:627]   3          | 1          |  cuda:1         
INFO 01-06 17:11:03.658634.658634 lmp.py:627]   5          | 1          |  cuda:1         
INFO 01-06 17:11:03.658092.658092 lmp.py:627]   9          | 1          |  cuda:1         
INFO 01-06 17:11:03.658788.658788 lmp.py:627]   16         | 1          |  cuda:1         
INFO 01-06 17:11:03.658676.658676 lmp.py:627]   18         | 1          |  cuda:1         
INFO 01-06 17:11:03.658849.658849 lmp.py:627]   27         | 1          |  meta           
INFO 01-06 17:11:03.658260.658260 lmp.py:627]   28         | 1          |  meta           
INFO 01-06 17:11:03.658433.658433 lmp.py:627]   38         | 1          |  meta           
INFO 01-06 17:11:03.658653.658653 lmp.py:627]   45         | 1          |  meta           
INFO 01-06 17:11:03.658687.658687 lmp.py:627]   46         | 1          |  cuda:1         
INFO 01-06 17:11:03.658667.658667 lmp.py:627]   56         | 1          |  meta           
INFO 01-06 17:11:03.659125.659125 lmp.py:627]   57         | 1          |  meta           
INFO 01-06 17:11:03.659159.659159 lmp.py:627]   4          | 2          |  cuda:1         
INFO 01-06 17:11:03.659716.659716 lmp.py:627]   21         | 2          |  cuda:1         
INFO 01-06 17:11:03.659273.659273 lmp.py:627]   30         | 2          |  cuda:1         
INFO 01-06 17:11:03.659307.659307 lmp.py:627]   33         | 2          |  meta           
INFO 01-06 17:11:03.659580.659580 lmp.py:627]   41         | 2          |  meta           
INFO 01-06 17:11:03.659898.659898 lmp.py:627]   42         | 2          |  cuda:1         
INFO 01-06 17:11:03.659217.659217 lmp.py:627]   60         | 2          |  cuda:1         
INFO 01-06 17:11:03.659774.659774 lmp.py:627]   1          | 3          |  cuda:1         
INFO 01-06 17:11:03.659854.659854 lmp.py:627]   10         | 3          |  meta           
INFO 01-06 17:11:03.659411.659411 lmp.py:627]   12         | 3          |  cuda:1         
INFO 01-06 17:11:03.659922.659922 lmp.py:627]   23         | 3          |  cuda:1         
INFO 01-06 17:11:03.659241.659241 lmp.py:627]   26         | 3          |  meta           
INFO 01-06 17:11:03.659798.659798 lmp.py:627]   29         | 3          |  cuda:1         
INFO 01-06 17:11:03.659594.659594 lmp.py:627]   40         | 3          |  cuda:1         
INFO 01-06 17:11:03.659912.659912 lmp.py:627]   47         | 3          |  meta           
INFO 01-06 17:11:03.659754.659754 lmp.py:627]   48         | 3          |  meta           
INFO 01-06 17:11:03.659073.659073 lmp.py:627]   61         | 3          |  meta           
INFO 01-06 17:11:03.659392.659392 lmp.py:627]   63         | 3          |  cuda:1         
INFO 01-06 17:11:03.659472.659472 lmp.py:627]   6          | 4          |  cuda:1         
INFO 01-06 17:11:03.659506.659506 lmp.py:627]   13         | 4          |  meta           
INFO 01-06 17:11:03.659778.659778 lmp.py:627]   24         | 4          |  meta           
INFO 01-06 17:11:03.659812.659812 lmp.py:627]   32         | 4          |  cuda:1         
INFO 01-06 17:11:03.659846.659846 lmp.py:627]   35         | 4          |  cuda:1         
INFO 01-06 17:11:03.659642.659642 lmp.py:627]   59         | 4          |  cuda:1         
INFO 01-06 17:11:03.659960.659960 lmp.py:627]   11         | 5          |  meta           
INFO 01-06 17:11:03.659517.659517 lmp.py:627]   17         | 5          |  cuda:1         
INFO 01-06 17:11:03.659598.659598 lmp.py:627]   39         | 5          |  cuda:1         
INFO 01-06 17:11:03.659678.659678 lmp.py:627]   54         | 5          |  meta           
INFO 01-06 17:11:03.659235.659235 lmp.py:627]   8          | 6          |  cuda:1         
INFO 01-06 17:11:03.659746.659746 lmp.py:627]   22         | 6          |  cuda:1         
INFO 01-06 17:11:03.659303.659303 lmp.py:627]   50         | 6          |  meta           
INFO 01-06 17:11:03.659860.659860 lmp.py:627]   52         | 6          |  cuda:1         
INFO 01-06 17:11:03.659417.659417 lmp.py:627]   44         | 7          |  cuda:1         
INFO 01-06 17:11:03.659259.659259 lmp.py:627]   7          | 8          |  cuda:1         
INFO 01-06 17:11:03.659862.659862 lmp.py:627]   15         | 8          |  cuda:1         
INFO 01-06 17:11:03.659704.659704 lmp.py:627]   53         | 9          |  cuda:1         
INFO 01-06 17:11:03.659785.659785 lmp.py:627]   36         | 10         |  cuda:1         
INFO 01-06 17:11:03.659865.659865 lmp.py:627]   62         | 10         |  cuda:1         
INFO 01-06 17:11:03.659422.659422 lmp.py:627]   20         | 11         |  cuda:1         
INFO 01-06 17:11:03.659741.659741 lmp.py:628] ============================================================
INFO 01-06 17:11:03.659741.659741 lmp.py:628] 
INFO 01-06 17:11:03.660974.660974 lmp.py:630] experts_gpu_list: [0, 2, 3, 5, 9, 16, 18, 46, 4, 21, 30, 42, 60, 1, 12, 23, 29, 40, 63, 6, 32, 35, 59, 17, 39, 8, 22, 52, 44, 7, 15, 53, 36, 62, 20] num: 35
INFO 01-06 17:11:03.660630.660630 lmp.py:631] experts_cpu_list: [27, 28, 38, 45, 56, 57, 33, 41, 10, 26, 47, 48, 61, 13, 24, 11, 54, 50] num: 18
INFO 01-06 17:11:03.660108.660108 lmp.py:632] expert_actual_device_map {0: 'cuda:1', 1: 'cuda:1', 2: 'cuda:1', 3: 'cuda:1', 4: 'cuda:1', 5: 'cuda:1', 6: 'cuda:1', 7: 'cuda:1', 8: 'cuda:1', 9: 'cuda:1', 10: 'meta', 11: 'meta', 12: 'cuda:1', 13: 'meta', 14: 'meta', 15: 'cuda:1', 16: 'cuda:1', 17: 'cuda:1', 18: 'cuda:1', 19: 'cuda:1', 20: 'cuda:1', 21: 'cuda:1', 22: 'cuda:1', 23: 'cuda:1', 24: 'meta', 25: 'meta', 26: 'meta', 27: 'meta', 28: 'meta', 29: 'cuda:1', 30: 'cuda:1', 31: 'meta', 32: 'cuda:1', 33: 'meta', 34: 'meta', 35: 'cuda:1', 36: 'cuda:1', 37: 'cuda:1', 38: 'meta', 39: 'cuda:1', 40: 'cuda:1', 41: 'meta', 42: 'cuda:1', 43: 'meta', 44: 'cuda:1', 45: 'meta', 46: 'cuda:1', 47: 'meta', 48: 'meta', 49: 'meta', 50: 'meta', 51: 'meta', 52: 'cuda:1', 53: 'cuda:1', 54: 'meta', 55: 'meta', 56: 'meta', 57: 'meta', 58: 'meta', 59: 'cuda:1', 60: 'cuda:1', 61: 'meta', 62: 'cuda:1', 63: 'cuda:1'}
DEBUG 01-06 17:11:03.660394.660394 cuda_h.py:19] end experts_map_get cost 0.0024497509002685547 seconds
DEBUG 01-06 17:11:03.660563.660563 mlpmodule.py:664]  experts func einsum cost 0.0246431827545166 s
DEBUG 01-06 17:11:03.660983.660983 cuda_h.py:10] start gpu_sexperts
DEBUG 01-06 17:11:03.660742.660742 cuda_h.py:19] end gpu_sexperts cost 0.0003387928009033203 seconds
DEBUG 01-06 17:11:03.660632.660632 cuda_h.py:10] start gpu_experts
DEBUG 01-06 17:11:03.661623.661623 mlpmodule.py:533] gpu group tensors cost 0.0006554126739501953 s
DEBUG 01-06 17:11:03.663288.663288 mlpmodule.py:566] gpu pad cost 0.0017931461334228516 s
DEBUG 01-06 17:11:03.664551.664551 mlpmodule.py:584] gpu group einsum cost 0.00047397613525390625 s
DEBUG 01-06 17:11:03.667994.667994 mlpmodule.py:613] gpu experts func einsum cost 0.0065801143646240234 s
DEBUG 01-06 17:11:03.667831.667831 cuda_h.py:19] end gpu_experts cost 0.006714820861816406 seconds
DEBUG 01-06 17:11:03.667640.667640 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-06 17:11:03.667012.667012 lmp.py:661] 
DEBUG 01-06 17:11:03.667012.667012 lmp.py:661]   Computing 18 experts on CPU...
DEBUG 01-06 17:11:03.667372.667372 cuda_h.py:19] end cpu_experts_submit cost 5.3882598876953125e-05 seconds
DEBUG 01-06 17:11:03.667975.667975 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-06 17:11:03.675519.675519 mlpmodule.py:706] group tensors cost 0.007792472839355469 s
DEBUG 01-06 17:11:03.677336.677336 mlpmodule.py:744] pad cost 0.0010907649993896484 s
DEBUG 01-06 17:11:03.677241.677241 mlpmodule.py:750] create cpu tensor cost 4.029273986816406e-05 s
DEBUG 01-06 17:11:03.677091.677091 mlpmodule.py:755] move to cpu cost 2.8133392333984375e-05 s
DEBUG 01-06 17:11:03.680732.680732 mlpmodule.py:769] group_w3: shape=torch.Size([18, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=51904512
DEBUG 01-06 17:11:03.680244.680244 mlpmodule.py:770] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-06 17:11:03.680411.680411 mlpmodule.py:775] group_w3 first element: -0.00897216796875
WARNING 01-06 17:11:03.680798.680798 mlpmodule.py:785] start einsum2
DEBUG 01-06 17:11:03.685969.685969 mlpmodule.py:795] group einsum cost 0.007418632507324219 s
DEBUG 01-06 17:11:03.685140.685140 mlpmodule.py:803] cpy2cputensor cost 9.655952453613281e-05 s
DEBUG 01-06 17:11:03.687722.687722 cuda_h.py:19] end wait_cetm_experts cost 0.01983952522277832 seconds
DEBUG 01-06 17:11:03.688081.688081 cuda_h.py:19] end layer_moe_dgenerate_16 cost 0.03124094009399414 seconds
DEBUG 01-06 17:11:03.688982.688982 lmp.py:325] -------------------------------- end decode layer 16 --------------------------------
DEBUG 01-06 17:11:03.688177.688177 lmp.py:298] -------------------------------- start decode layer 17 --------------------------------
DEBUG 01-06 17:11:03.688039.688039 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-06 17:11:03.688428.688428 mlpmodule.py:367] cuda:1 cuda:1
DEBUG 01-06 17:11:03.689332.689332 cuda_h.py:10] start self_attn
cos shape torch.Size([65, 128]) sin shape torch.Size([65, 128]) position_ids tensor([[0]], device='cuda:1')
cos shape torch.Size([1, 1, 1, 128]) sin shape torch.Size([1, 1, 1, 128])
q_embed shape torch.Size([32, 16, 1, 128]) k_embed shape torch.Size([32, 16, 1, 128])
DEBUG 01-06 17:11:03.691622.691622 cuda_h.py:19] end self_attn cost 0.0024466514587402344 seconds
DEBUG 01-06 17:11:03.692403.692403 cuda_h.py:19] end iln_self_attn_paln cost 0.003525257110595703 seconds
DEBUG 01-06 17:11:03.692611.692611 mlpmodule.py:664]  experts func einsum cost 0.024202346801757812 s
DEBUG 01-06 17:11:03.692038.692038 cuda_h.py:10] start layer_moe_dgenerate_17
DEBUG 01-06 17:11:03.692860.692860 cuda_h.py:10] start gate
DEBUG 01-06 17:11:03.693068.693068 cuda_h.py:19] end gate cost 0.0006270408630371094 seconds
DEBUG 01-06 17:11:03.693288.693288 cuda_h.py:10] start experts_map_get
INFO 01-06 17:11:03.693373.693373 lmp.py:609] using loaded check layer: True
INFO 01-06 17:11:03.694921.694921 lmp.py:620] 
INFO 01-06 17:11:03.694921.694921 lmp.py:620] Layer 17 Expert Device Distribution:
INFO 01-06 17:11:03.694730.694730 lmp.py:621]   Active experts: 53 (out of 64 total)
INFO 01-06 17:11:03.694810.694810 lmp.py:622] 
INFO 01-06 17:11:03.694810.694810 lmp.py:622]   Detailed Expert Distribution:
INFO 01-06 17:11:03.694274.694274 lmp.py:623]   Expert ID  | Tokens     | Actual Device  
INFO 01-06 17:11:03.694209.694209 lmp.py:624]   ----------------------------------------------------------------------
INFO 01-06 17:11:03.694812.694812 lmp.py:627]   0          | 1          |  cuda:1         
INFO 01-06 17:11:03.694793.694793 lmp.py:627]   7          | 1          |  cuda:1         
INFO 01-06 17:11:03.694059.694059 lmp.py:627]   8          | 1          |  meta           
INFO 01-06 17:11:03.694563.694563 lmp.py:627]   10         | 1          |  meta           
INFO 01-06 17:11:03.694828.694828 lmp.py:627]   15         | 1          |  meta           
INFO 01-06 17:11:03.694856.694856 lmp.py:627]   18         | 1          |  cuda:1         
INFO 01-06 17:11:03.694121.694121 lmp.py:627]   22         | 1          |  cuda:1         
INFO 01-06 17:11:03.694387.694387 lmp.py:627]   24         | 1          |  meta           
INFO 01-06 17:11:03.694606.694606 lmp.py:627]   27         | 1          |  meta           
INFO 01-06 17:11:03.694064.694064 lmp.py:627]   36         | 1          |  meta           
INFO 01-06 17:11:03.694283.694283 lmp.py:627]   38         | 1          |  meta           
INFO 01-06 17:11:03.694264.694264 lmp.py:627]   39         | 1          |  meta           
INFO 01-06 17:11:03.694529.694529 lmp.py:627]   50         | 1          |  meta           
INFO 01-06 17:11:03.694318.694318 lmp.py:627]   55         | 1          |  cuda:1         
INFO 01-06 17:11:03.694107.694107 lmp.py:627]   61         | 1          |  meta           
INFO 01-06 17:11:03.694134.694134 lmp.py:627]   2          | 2          |  cuda:1         
INFO 01-06 17:11:03.694638.694638 lmp.py:627]   3          | 2          |  cuda:1         
INFO 01-06 17:11:03.694665.694665 lmp.py:627]   4          | 2          |  cuda:1         
INFO 01-06 17:11:03.694407.694407 lmp.py:627]   5          | 2          |  cuda:1         
INFO 01-06 17:11:03.694388.694388 lmp.py:627]   14         | 2          |  meta           
INFO 01-06 17:11:03.694608.694608 lmp.py:627]   16         | 2          |  cuda:1         
INFO 01-06 17:11:03.694588.694588 lmp.py:627]   20         | 2          |  cuda:1         
INFO 01-06 17:11:03.694616.694616 lmp.py:627]   30         | 2          |  meta           
INFO 01-06 17:11:03.694643.694643 lmp.py:627]   41         | 2          |  cuda:1         
INFO 01-06 17:11:03.694670.694670 lmp.py:627]   42         | 2          |  cuda:1         
INFO 01-06 17:11:03.694697.694697 lmp.py:627]   44         | 2          |  cuda:1         
INFO 01-06 17:11:03.694724.694724 lmp.py:627]   49         | 2          |  meta           
INFO 01-06 17:11:03.694275.694275 lmp.py:627]   52         | 2          |  meta           
INFO 01-06 17:11:03.694017.694017 lmp.py:627]   53         | 2          |  meta           
INFO 01-06 17:11:03.694283.694283 lmp.py:627]   54         | 2          |  cuda:1         
INFO 01-06 17:11:03.694787.694787 lmp.py:627]   60         | 2          |  meta           
INFO 01-06 17:11:03.694006.694006 lmp.py:627]   6          | 3          |  cuda:1         
INFO 01-06 17:11:03.694987.694987 lmp.py:627]   11         | 3          |  cuda:1         
INFO 01-06 17:11:03.694967.694967 lmp.py:627]   19         | 3          |  cuda:1         
INFO 01-06 17:11:03.694233.694233 lmp.py:627]   25         | 3          |  meta           
INFO 01-06 17:11:03.694499.694499 lmp.py:627]   56         | 3          |  cuda:1         
INFO 01-06 17:11:03.694764.694764 lmp.py:627]   1          | 4          |  cuda:1         
INFO 01-06 17:11:03.694030.694030 lmp.py:627]   17         | 4          |  cuda:1         
INFO 01-06 17:11:03.694534.694534 lmp.py:627]   21         | 4          |  cuda:1         
INFO 01-06 17:11:03.694561.694561 lmp.py:627]   31         | 4          |  meta           
INFO 01-06 17:11:03.694588.694588 lmp.py:627]   45         | 4          |  cuda:1         
INFO 01-06 17:11:03.695807.695807 lmp.py:627]   26         | 5          |  cuda:1         
INFO 01-06 17:11:03.695788.695788 lmp.py:627]   29         | 5          |  cuda:1         
INFO 01-06 17:11:03.695007.695007 lmp.py:627]   48         | 5          |  cuda:1         
INFO 01-06 17:11:03.695704.695704 lmp.py:627]   57         | 5          |  meta           
INFO 01-06 17:11:03.695731.695731 lmp.py:627]   35         | 6          |  cuda:1         
INFO 01-06 17:11:03.695758.695758 lmp.py:627]   9          | 8          |  cuda:1         
INFO 01-06 17:11:03.695023.695023 lmp.py:627]   34         | 8          |  cuda:1         
INFO 01-06 17:11:03.695051.695051 lmp.py:627]   32         | 9          |  cuda:1         
INFO 01-06 17:11:03.695316.695316 lmp.py:627]   51         | 10         |  cuda:1         
INFO 01-06 17:11:03.695343.695343 lmp.py:627]   23         | 16         |  cuda:1         
INFO 01-06 17:11:03.695039.695039 lmp.py:627]   63         | 16         |  cuda:1         
INFO 01-06 17:11:03.695259.695259 lmp.py:627]   62         | 17         |  cuda:1         
INFO 01-06 17:11:03.695001.695001 lmp.py:628] ============================================================
INFO 01-06 17:11:03.695001.695001 lmp.py:628] 
INFO 01-06 17:11:03.695466.695466 lmp.py:630] experts_gpu_list: [0, 7, 18, 22, 55, 2, 3, 4, 5, 16, 20, 41, 42, 44, 54, 6, 11, 19, 56, 1, 17, 21, 45, 26, 29, 48, 35, 9, 34, 32, 51, 23, 63, 62] num: 34
INFO 01-06 17:11:03.695592.695592 lmp.py:631] experts_cpu_list: [8, 10, 15, 24, 27, 36, 38, 39, 50, 61, 14, 30, 49, 52, 53, 60, 25, 31, 57] num: 19
INFO 01-06 17:11:03.695686.695686 lmp.py:632] expert_actual_device_map {0: 'cuda:1', 1: 'cuda:1', 2: 'cuda:1', 3: 'cuda:1', 4: 'cuda:1', 5: 'cuda:1', 6: 'cuda:1', 7: 'cuda:1', 8: 'meta', 9: 'cuda:1', 10: 'meta', 11: 'cuda:1', 12: 'meta', 13: 'cuda:1', 14: 'meta', 15: 'meta', 16: 'cuda:1', 17: 'cuda:1', 18: 'cuda:1', 19: 'cuda:1', 20: 'cuda:1', 21: 'cuda:1', 22: 'cuda:1', 23: 'cuda:1', 24: 'meta', 25: 'meta', 26: 'cuda:1', 27: 'meta', 28: 'meta', 29: 'cuda:1', 30: 'meta', 31: 'meta', 32: 'cuda:1', 33: 'meta', 34: 'cuda:1', 35: 'cuda:1', 36: 'meta', 37: 'cuda:1', 38: 'meta', 39: 'meta', 40: 'meta', 41: 'cuda:1', 42: 'cuda:1', 43: 'meta', 44: 'cuda:1', 45: 'cuda:1', 46: 'cuda:1', 47: 'meta', 48: 'cuda:1', 49: 'meta', 50: 'meta', 51: 'cuda:1', 52: 'meta', 53: 'meta', 54: 'cuda:1', 55: 'cuda:1', 56: 'cuda:1', 57: 'meta', 58: 'meta', 59: 'meta', 60: 'meta', 61: 'meta', 62: 'cuda:1', 63: 'cuda:1'}
DEBUG 01-06 17:11:03.695442.695442 cuda_h.py:19] end experts_map_get cost 0.002187013626098633 seconds
DEBUG 01-06 17:11:03.695928.695928 cuda_h.py:10] start gpu_sexperts
DEBUG 01-06 17:11:03.695927.695927 cuda_h.py:19] end gpu_sexperts cost 0.00030994415283203125 seconds
DEBUG 01-06 17:11:03.695087.695087 cuda_h.py:10] start gpu_experts
DEBUG 01-06 17:11:03.696675.696675 mlpmodule.py:533] gpu group tensors cost 0.000675201416015625 s
DEBUG 01-06 17:11:03.698755.698755 mlpmodule.py:566] gpu pad cost 0.0017285346984863281 s
DEBUG 01-06 17:11:03.698131.698131 mlpmodule.py:584] gpu group einsum cost 0.0004894733428955078 s
DEBUG 01-06 17:11:03.702551.702551 mlpmodule.py:613] gpu experts func einsum cost 0.00665736198425293 s
DEBUG 01-06 17:11:03.702474.702474 cuda_h.py:19] end gpu_experts cost 0.006785392761230469 seconds
DEBUG 01-06 17:11:03.702230.702230 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-06 17:11:03.702648.702648 lmp.py:661] 
DEBUG 01-06 17:11:03.702648.702648 lmp.py:661]   Computing 19 experts on CPU...
DEBUG 01-06 17:11:03.702008.702008 cuda_h.py:19] end cpu_experts_submit cost 5.316734313964844e-05 seconds
DEBUG 01-06 17:11:03.702042.702042 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-06 17:11:03.711978.711978 mlpmodule.py:706] group tensors cost 0.008616447448730469 s
DEBUG 01-06 17:11:03.713054.713054 mlpmodule.py:744] pad cost 0.0012488365173339844 s
DEBUG 01-06 17:11:03.713224.713224 mlpmodule.py:750] create cpu tensor cost 4.744529724121094e-05 s
DEBUG 01-06 17:11:03.713094.713094 mlpmodule.py:755] move to cpu cost 3.457069396972656e-05 s
DEBUG 01-06 17:11:03.716171.716171 mlpmodule.py:769] group_w3: shape=torch.Size([19, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=54788096
DEBUG 01-06 17:11:03.716354.716354 mlpmodule.py:770] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-06 17:11:03.716336.716336 mlpmodule.py:775] group_w3 first element: 0.0218505859375
WARNING 01-06 17:11:03.716107.716107 mlpmodule.py:785] start einsum2
DEBUG 01-06 17:11:03.721845.721845 mlpmodule.py:795] group einsum cost 0.007738351821899414 s
DEBUG 01-06 17:11:03.721492.721492 mlpmodule.py:803] cpy2cputensor cost 9.894371032714844e-05 s
DEBUG 01-06 17:11:03.724386.724386 cuda_h.py:19] end wait_cetm_experts cost 0.021269798278808594 seconds
DEBUG 01-06 17:11:03.724757.724757 cuda_h.py:19] end layer_moe_dgenerate_17 cost 0.03216242790222168 seconds
DEBUG 01-06 17:11:03.724174.724174 lmp.py:325] -------------------------------- end decode layer 17 --------------------------------
DEBUG 01-06 17:11:03.724036.724036 lmp.py:298] -------------------------------- start decode layer 18 --------------------------------
DEBUG 01-06 17:11:03.724262.724262 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-06 17:11:03.724895.724895 mlpmodule.py:367] cuda:1 cuda:1
DEBUG 01-06 17:11:03.725728.725728 cuda_h.py:10] start self_attn
cos shape torch.Size([65, 128]) sin shape torch.Size([65, 128]) position_ids tensor([[0]], device='cuda:1')
cos shape torch.Size([1, 1, 1, 128]) sin shape torch.Size([1, 1, 1, 128])
q_embed shape torch.Size([32, 16, 1, 128]) k_embed shape torch.Size([32, 16, 1, 128])
DEBUG 01-06 17:11:03.727264.727264 cuda_h.py:19] end self_attn cost 0.0018768310546875 seconds
DEBUG 01-06 17:11:03.727334.727334 cuda_h.py:19] end iln_self_attn_paln cost 0.0027208328247070312 seconds
DEBUG 01-06 17:11:03.727548.727548 cuda_h.py:10] start layer_moe_dgenerate_18
DEBUG 01-06 17:11:03.727364.727364 cuda_h.py:10] start gate
DEBUG 01-06 17:11:03.728696.728696 cuda_h.py:19] end gate cost 0.0005927085876464844 seconds
DEBUG 01-06 17:11:03.728817.728817 cuda_h.py:10] start experts_map_get
INFO 01-06 17:11:03.728154.728154 lmp.py:609] using loaded check layer: True
INFO 01-06 17:11:03.729986.729986 lmp.py:620] 
INFO 01-06 17:11:03.729986.729986 lmp.py:620] Layer 18 Expert Device Distribution:
INFO 01-06 17:11:03.729015.729015 lmp.py:621]   Active experts: 51 (out of 64 total)
INFO 01-06 17:11:03.729671.729671 lmp.py:622] 
INFO 01-06 17:11:03.729671.729671 lmp.py:622]   Detailed Expert Distribution:
INFO 01-06 17:11:03.729566.729566 lmp.py:623]   Expert ID  | Tokens     | Actual Device  
INFO 01-06 17:11:03.729600.729600 lmp.py:624]   ----------------------------------------------------------------------
INFO 01-06 17:11:03.729634.729634 lmp.py:627]   0          | 1          |  cuda:1         
INFO 01-06 17:11:03.729238.729238 lmp.py:627]   1          | 1          |  cuda:1         
INFO 01-06 17:11:03.729080.729080 lmp.py:627]   5          | 1          |  cuda:1         
INFO 01-06 17:11:03.729921.729921 lmp.py:627]   14         | 1          |  cuda:1         
INFO 01-06 17:11:03.729286.729286 lmp.py:627]   20         | 1          |  cuda:1         
INFO 01-06 17:11:03.729320.729320 lmp.py:627]   28         | 1          |  meta           
INFO 01-06 17:11:03.729401.729401 lmp.py:627]   30         | 1          |  meta           
INFO 01-06 17:11:03.729481.729481 lmp.py:627]   32         | 1          |  meta           
INFO 01-06 17:11:03.729038.729038 lmp.py:627]   33         | 1          |  cuda:1         
INFO 01-06 17:11:03.729880.729880 lmp.py:627]   34         | 1          |  cuda:1         
INFO 01-06 17:11:03.729483.729483 lmp.py:627]   47         | 1          |  cuda:1         
INFO 01-06 17:11:03.729848.729848 lmp.py:627]   48         | 1          |  meta           
INFO 01-06 17:11:03.729737.729737 lmp.py:627]   53         | 1          |  meta           
INFO 01-06 17:11:03.729863.729863 lmp.py:627]   54         | 1          |  meta           
INFO 01-06 17:11:03.729751.729751 lmp.py:627]   55         | 1          |  cuda:1         
INFO 01-06 17:11:03.729832.729832 lmp.py:627]   57         | 1          |  cuda:1         
INFO 01-06 17:11:03.729150.729150 lmp.py:627]   58         | 1          |  meta           
INFO 01-06 17:11:03.729469.729469 lmp.py:627]   63         | 1          |  meta           
INFO 01-06 17:11:03.729596.729596 lmp.py:627]   7          | 2          |  cuda:1         
INFO 01-06 17:11:03.729961.729961 lmp.py:627]   8          | 2          |  cuda:1         
INFO 01-06 17:11:03.729372.729372 lmp.py:627]   10         | 2          |  cuda:1         
INFO 01-06 17:11:03.729737.729737 lmp.py:627]   12         | 2          |  meta           
INFO 01-06 17:11:03.729864.729864 lmp.py:627]   31         | 2          |  cuda:1         
INFO 01-06 17:11:03.729513.729513 lmp.py:627]   42         | 2          |  cuda:1         
INFO 01-06 17:11:03.729594.729594 lmp.py:627]   49         | 2          |  cuda:1         
INFO 01-06 17:11:03.729436.729436 lmp.py:627]   56         | 2          |  meta           
INFO 01-06 17:11:03.730039.730039 lmp.py:627]   59         | 2          |  meta           
INFO 01-06 17:11:03.730642.730642 lmp.py:627]   2          | 3          |  cuda:1         
INFO 01-06 17:11:03.730292.730292 lmp.py:627]   9          | 3          |  meta           
INFO 01-06 17:11:03.730180.730180 lmp.py:627]   18         | 3          |  cuda:1         
INFO 01-06 17:11:03.730592.730592 lmp.py:627]   25         | 3          |  meta           
INFO 01-06 17:11:03.730480.730480 lmp.py:627]   35         | 3          |  meta           
INFO 01-06 17:11:03.730368.730368 lmp.py:627]   29         | 4          |  meta           
INFO 01-06 17:11:03.730495.730495 lmp.py:627]   50         | 4          |  cuda:1         
INFO 01-06 17:11:03.730575.730575 lmp.py:627]   51         | 4          |  cuda:1         
INFO 01-06 17:11:03.730178.730178 lmp.py:627]   6          | 5          |  cuda:1         
INFO 01-06 17:11:03.730020.730020 lmp.py:627]   13         | 5          |  cuda:1         
INFO 01-06 17:11:03.730385.730385 lmp.py:627]   61         | 5          |  cuda:1         
INFO 01-06 17:11:03.730512.730512 lmp.py:627]   21         | 6          |  meta           
INFO 01-06 17:11:03.730877.730877 lmp.py:627]   43         | 6          |  cuda:1         
INFO 01-06 17:11:03.730765.730765 lmp.py:627]   4          | 7          |  cuda:1         
INFO 01-06 17:11:03.730653.730653 lmp.py:627]   11         | 7          |  cuda:1         
INFO 01-06 17:11:03.730065.730065 lmp.py:627]   17         | 7          |  meta           
INFO 01-06 17:11:03.730953.730953 lmp.py:627]   23         | 7          |  cuda:1         
INFO 01-06 17:11:03.730318.730318 lmp.py:627]   22         | 8          |  cuda:1         
INFO 01-06 17:11:03.730683.730683 lmp.py:627]   38         | 8          |  cuda:1         
INFO 01-06 17:11:03.730763.730763 lmp.py:627]   45         | 8          |  cuda:1         
INFO 01-06 17:11:03.730651.730651 lmp.py:627]   62         | 10         |  cuda:1         
INFO 01-06 17:11:03.730778.730778 lmp.py:627]   26         | 12         |  cuda:1         
INFO 01-06 17:11:03.730666.730666 lmp.py:627]   16         | 13         |  cuda:1         
INFO 01-06 17:11:03.730554.730554 lmp.py:627]   52         | 15         |  meta           
INFO 01-06 17:11:03.730727.730727 lmp.py:628] ============================================================
INFO 01-06 17:11:03.730727.730727 lmp.py:628] 
INFO 01-06 17:11:03.730099.730099 lmp.py:630] experts_gpu_list: [0, 1, 5, 14, 20, 33, 34, 47, 55, 57, 7, 8, 10, 31, 42, 49, 2, 18, 50, 51, 6, 13, 61, 43, 4, 11, 23, 22, 38, 45, 62, 26, 16] num: 33
INFO 01-06 17:11:03.730325.730325 lmp.py:631] experts_cpu_list: [28, 30, 32, 48, 53, 54, 58, 63, 12, 56, 59, 9, 25, 35, 29, 21, 17, 52] num: 18
INFO 01-06 17:11:03.730326.730326 lmp.py:632] expert_actual_device_map {0: 'cuda:1', 1: 'cuda:1', 2: 'cuda:1', 3: 'cuda:1', 4: 'cuda:1', 5: 'cuda:1', 6: 'cuda:1', 7: 'cuda:1', 8: 'cuda:1', 9: 'meta', 10: 'cuda:1', 11: 'cuda:1', 12: 'meta', 13: 'cuda:1', 14: 'cuda:1', 15: 'cuda:1', 16: 'cuda:1', 17: 'meta', 18: 'cuda:1', 19: 'meta', 20: 'cuda:1', 21: 'meta', 22: 'cuda:1', 23: 'cuda:1', 24: 'cuda:1', 25: 'meta', 26: 'cuda:1', 27: 'meta', 28: 'meta', 29: 'meta', 30: 'meta', 31: 'cuda:1', 32: 'meta', 33: 'cuda:1', 34: 'cuda:1', 35: 'meta', 36: 'meta', 37: 'meta', 38: 'cuda:1', 39: 'meta', 40: 'meta', 41: 'meta', 42: 'cuda:1', 43: 'cuda:1', 44: 'cuda:1', 45: 'cuda:1', 46: 'meta', 47: 'cuda:1', 48: 'meta', 49: 'cuda:1', 50: 'cuda:1', 51: 'cuda:1', 52: 'meta', 53: 'meta', 54: 'meta', 55: 'cuda:1', 56: 'meta', 57: 'cuda:1', 58: 'meta', 59: 'meta', 60: 'meta', 61: 'cuda:1', 62: 'cuda:1', 63: 'meta'}
DEBUG 01-06 17:11:03.730089.730089 cuda_h.py:19] end experts_map_get cost 0.0023424625396728516 seconds
DEBUG 01-06 17:11:03.730774.730774 mlpmodule.py:664]  experts func einsum cost 0.02786540985107422 s
DEBUG 01-06 17:11:03.730903.730903 cuda_h.py:10] start gpu_sexperts
DEBUG 01-06 17:11:03.731846.731846 cuda_h.py:19] end gpu_sexperts cost 0.0003266334533691406 seconds
DEBUG 01-06 17:11:03.731636.731636 cuda_h.py:10] start gpu_experts
DEBUG 01-06 17:11:03.732731.732731 mlpmodule.py:533] gpu group tensors cost 0.0005936622619628906 s
DEBUG 01-06 17:11:03.733202.733202 mlpmodule.py:566] gpu pad cost 0.0017368793487548828 s
DEBUG 01-06 17:11:03.734518.734518 mlpmodule.py:584] gpu group einsum cost 0.0004749298095703125 s
DEBUG 01-06 17:11:03.737553.737553 mlpmodule.py:613] gpu experts func einsum cost 0.006323337554931641 s
DEBUG 01-06 17:11:03.737390.737390 cuda_h.py:19] end gpu_experts cost 0.00645756721496582 seconds
DEBUG 01-06 17:11:03.737954.737954 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-06 17:11:03.737180.737180 lmp.py:661] 
DEBUG 01-06 17:11:03.737180.737180 lmp.py:661]   Computing 18 experts on CPU...
DEBUG 01-06 17:11:03.738347.738347 cuda_h.py:19] end cpu_experts_submit cost 5.173683166503906e-05 seconds
DEBUG 01-06 17:11:03.738567.738567 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-06 17:11:03.741526.741526 mlpmodule.py:706] group tensors cost 0.0035712718963623047 s
DEBUG 01-06 17:11:03.743102.743102 mlpmodule.py:744] pad cost 0.0009520053863525391 s
DEBUG 01-06 17:11:03.743437.743437 mlpmodule.py:750] create cpu tensor cost 3.981590270996094e-05 s
DEBUG 01-06 17:11:03.743048.743048 mlpmodule.py:755] move to cpu cost 2.956390380859375e-05 s
DEBUG 01-06 17:11:03.746709.746709 mlpmodule.py:769] group_w3: shape=torch.Size([18, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=51904512
DEBUG 01-06 17:11:03.746221.746221 mlpmodule.py:770] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-06 17:11:03.746342.746342 mlpmodule.py:775] group_w3 first element: 0.01373291015625
WARNING 01-06 17:11:03.746298.746298 mlpmodule.py:785] start einsum2
DEBUG 01-06 17:11:03.750283.750283 mlpmodule.py:795] group einsum cost 0.007364988327026367 s
DEBUG 01-06 17:11:03.751488.751488 mlpmodule.py:803] cpy2cputensor cost 0.00011658668518066406 s
DEBUG 01-06 17:11:03.753876.753876 cuda_h.py:19] end wait_cetm_experts cost 0.015491724014282227 seconds
DEBUG 01-06 17:11:03.754406.754406 cuda_h.py:19] end layer_moe_dgenerate_18 cost 0.02636575698852539 seconds
DEBUG 01-06 17:11:03.754431.754431 lmp.py:325] -------------------------------- end decode layer 18 --------------------------------
DEBUG 01-06 17:11:03.754386.754386 lmp.py:298] -------------------------------- start decode layer 19 --------------------------------
DEBUG 01-06 17:11:03.754135.754135 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-06 17:11:03.754530.754530 mlpmodule.py:367] cuda:1 cuda:1
DEBUG 01-06 17:11:03.754437.754437 cuda_h.py:10] start self_attn
cos shape torch.Size([65, 128]) sin shape torch.Size([65, 128]) position_ids tensor([[0]], device='cuda:1')
cos shape torch.Size([1, 1, 1, 128]) sin shape torch.Size([1, 1, 1, 128])
q_embed shape torch.Size([32, 16, 1, 128]) k_embed shape torch.Size([32, 16, 1, 128])
DEBUG 01-06 17:11:03.756352.756352 cuda_h.py:19] end self_attn cost 0.0019445419311523438 seconds
DEBUG 01-06 17:11:03.757138.757138 cuda_h.py:19] end iln_self_attn_paln cost 0.0028100013732910156 seconds
DEBUG 01-06 17:11:03.757590.757590 cuda_h.py:10] start layer_moe_dgenerate_19
DEBUG 01-06 17:11:03.757313.757313 cuda_h.py:10] start gate
DEBUG 01-06 17:11:03.757587.757587 mlpmodule.py:664]  experts func einsum cost 0.019645214080810547 s
DEBUG 01-06 17:11:03.757029.757029 cuda_h.py:19] end gate cost 0.0007512569427490234 seconds
DEBUG 01-06 17:11:03.758218.758218 cuda_h.py:10] start experts_map_get
INFO 01-06 17:11:03.758170.758170 lmp.py:609] using loaded check layer: True
INFO 01-06 17:11:03.758373.758373 lmp.py:620] 
INFO 01-06 17:11:03.758373.758373 lmp.py:620] Layer 19 Expert Device Distribution:
INFO 01-06 17:11:03.759090.759090 lmp.py:621]   Active experts: 55 (out of 64 total)
INFO 01-06 17:11:03.759408.759408 lmp.py:622] 
INFO 01-06 17:11:03.759408.759408 lmp.py:622]   Detailed Expert Distribution:
INFO 01-06 17:11:03.759442.759442 lmp.py:623]   Expert ID  | Tokens     | Actual Device  
INFO 01-06 17:11:03.759615.759615 lmp.py:624]   ----------------------------------------------------------------------
INFO 01-06 17:11:03.759503.759503 lmp.py:627]   1          | 1          |  cuda:1         
INFO 01-06 17:11:03.759484.759484 lmp.py:627]   4          | 1          |  cuda:1         
INFO 01-06 17:11:03.759227.759227 lmp.py:627]   7          | 1          |  cuda:1         
INFO 01-06 17:11:03.759969.759969 lmp.py:627]   10         | 1          |  cuda:1         
INFO 01-06 17:11:03.759235.759235 lmp.py:627]   11         | 1          |  cuda:1         
INFO 01-06 17:11:03.759977.759977 lmp.py:627]   15         | 1          |  meta           
INFO 01-06 17:11:03.759243.759243 lmp.py:627]   22         | 1          |  meta           
INFO 01-06 17:11:03.759223.759223 lmp.py:627]   27         | 1          |  meta           
INFO 01-06 17:11:03.759681.759681 lmp.py:627]   30         | 1          |  meta           
INFO 01-06 17:11:03.759662.759662 lmp.py:627]   33         | 1          |  cuda:1         
INFO 01-06 17:11:03.759881.759881 lmp.py:627]   35         | 1          |  cuda:1         
INFO 01-06 17:11:03.759147.759147 lmp.py:627]   36         | 1          |  cuda:1         
INFO 01-06 17:11:03.759412.759412 lmp.py:627]   38         | 1          |  cuda:1         
INFO 01-06 17:11:03.759916.759916 lmp.py:627]   52         | 1          |  meta           
INFO 01-06 17:11:03.759467.759467 lmp.py:627]   56         | 1          |  meta           
INFO 01-06 17:11:03.759494.759494 lmp.py:627]   60         | 1          |  meta           
INFO 01-06 17:11:03.759759.759759 lmp.py:627]   9          | 2          |  cuda:1         
INFO 01-06 17:11:03.759025.759025 lmp.py:627]   14         | 2          |  cuda:1         
INFO 01-06 17:11:03.759052.759052 lmp.py:627]   16         | 2          |  meta           
INFO 01-06 17:11:03.759556.759556 lmp.py:627]   19         | 2          |  cuda:1         
INFO 01-06 17:11:03.759537.759537 lmp.py:627]   21         | 2          |  cuda:1         
INFO 01-06 17:11:03.759518.759518 lmp.py:627]   25         | 2          |  cuda:1         
INFO 01-06 17:11:03.759975.759975 lmp.py:627]   40         | 2          |  cuda:1         
INFO 01-06 17:11:03.759764.759764 lmp.py:627]   42         | 2          |  meta           
INFO 01-06 17:11:03.759791.759791 lmp.py:627]   43         | 2          |  cuda:1         
INFO 01-06 17:11:03.759580.759580 lmp.py:627]   58         | 2          |  meta           
INFO 01-06 17:11:03.759130.759130 lmp.py:627]   61         | 2          |  cuda:1         
INFO 01-06 17:11:03.759158.759158 lmp.py:627]   5          | 3          |  cuda:1         
INFO 01-06 17:11:03.759423.759423 lmp.py:627]   12         | 3          |  meta           
INFO 01-06 17:11:03.759689.759689 lmp.py:627]   24         | 3          |  meta           
INFO 01-06 17:11:03.759670.759670 lmp.py:627]   3          | 4          |  cuda:1         
INFO 01-06 17:11:03.759650.759650 lmp.py:627]   17         | 4          |  cuda:1         
INFO 01-06 17:11:03.759108.759108 lmp.py:627]   23         | 4          |  cuda:1         
INFO 01-06 17:11:03.759612.759612 lmp.py:627]   26         | 4          |  meta           
INFO 01-06 17:11:03.759639.759639 lmp.py:627]   28         | 4          |  meta           
INFO 01-06 17:11:03.759905.759905 lmp.py:627]   32         | 4          |  meta           
INFO 01-06 17:11:03.759932.759932 lmp.py:627]   47         | 4          |  meta           
INFO 01-06 17:11:03.759959.759959 lmp.py:627]   50         | 4          |  meta           
INFO 01-06 17:11:03.759225.759225 lmp.py:627]   55         | 4          |  meta           
INFO 01-06 17:11:03.759490.759490 lmp.py:627]   34         | 5          |  meta           
INFO 01-06 17:11:03.759948.759948 lmp.py:627]   37         | 5          |  cuda:1         
INFO 01-06 17:11:03.759167.759167 lmp.py:627]   39         | 5          |  cuda:1         
INFO 01-06 17:11:03.759625.759625 lmp.py:627]   45         | 5          |  cuda:1         
INFO 01-06 17:11:03.759129.759129 lmp.py:627]   57         | 5          |  meta           
INFO 01-06 17:11:03.760918.760918 lmp.py:627]   0          | 6          |  cuda:1         
INFO 01-06 17:11:03.760183.760183 lmp.py:627]   20         | 6          |  cuda:1         
INFO 01-06 17:11:03.760972.760972 lmp.py:627]   63         | 6          |  cuda:1         
INFO 01-06 17:11:03.760761.760761 lmp.py:627]   31         | 7          |  cuda:1         
INFO 01-06 17:11:03.760549.760549 lmp.py:627]   53         | 7          |  cuda:1         
INFO 01-06 17:11:03.760338.760338 lmp.py:627]   18         | 8          |  cuda:1         
INFO 01-06 17:11:03.760273.760273 lmp.py:627]   41         | 8          |  meta           
INFO 01-06 17:11:03.760254.760254 lmp.py:627]   51         | 8          |  cuda:1         
INFO 01-06 17:11:03.760473.760473 lmp.py:627]   29         | 9          |  cuda:1         
INFO 01-06 17:11:03.760215.760215 lmp.py:627]   48         | 9          |  meta           
INFO 01-06 17:11:03.760958.760958 lmp.py:627]   13         | 10         |  meta           
INFO 01-06 17:11:03.760270.760270 lmp.py:628] ============================================================
INFO 01-06 17:11:03.760270.760270 lmp.py:628] 
INFO 01-06 17:11:03.760542.760542 lmp.py:630] experts_gpu_list: [1, 4, 7, 10, 11, 33, 35, 36, 38, 9, 14, 19, 21, 25, 40, 43, 61, 5, 3, 17, 23, 37, 39, 45, 0, 20, 63, 31, 53, 18, 51, 29] num: 32
INFO 01-06 17:11:03.760715.760715 lmp.py:631] experts_cpu_list: [15, 22, 27, 30, 52, 56, 60, 16, 42, 58, 12, 24, 26, 28, 32, 47, 50, 55, 34, 57, 41, 48, 13] num: 23
INFO 01-06 17:11:03.760140.760140 lmp.py:632] expert_actual_device_map {0: 'cuda:1', 1: 'cuda:1', 2: 'cuda:1', 3: 'cuda:1', 4: 'cuda:1', 5: 'cuda:1', 6: 'cuda:1', 7: 'cuda:1', 8: 'meta', 9: 'cuda:1', 10: 'cuda:1', 11: 'cuda:1', 12: 'meta', 13: 'meta', 14: 'cuda:1', 15: 'meta', 16: 'meta', 17: 'cuda:1', 18: 'cuda:1', 19: 'cuda:1', 20: 'cuda:1', 21: 'cuda:1', 22: 'meta', 23: 'cuda:1', 24: 'meta', 25: 'cuda:1', 26: 'meta', 27: 'meta', 28: 'meta', 29: 'cuda:1', 30: 'meta', 31: 'cuda:1', 32: 'meta', 33: 'cuda:1', 34: 'meta', 35: 'cuda:1', 36: 'cuda:1', 37: 'cuda:1', 38: 'cuda:1', 39: 'cuda:1', 40: 'cuda:1', 41: 'meta', 42: 'meta', 43: 'cuda:1', 44: 'meta', 45: 'cuda:1', 46: 'cuda:1', 47: 'meta', 48: 'meta', 49: 'cuda:1', 50: 'meta', 51: 'cuda:1', 52: 'meta', 53: 'cuda:1', 54: 'cuda:1', 55: 'meta', 56: 'meta', 57: 'meta', 58: 'meta', 59: 'meta', 60: 'meta', 61: 'cuda:1', 62: 'meta', 63: 'cuda:1'}
DEBUG 01-06 17:11:03.760849.760849 cuda_h.py:19] end experts_map_get cost 0.002223491668701172 seconds
DEBUG 01-06 17:11:03.760601.760601 cuda_h.py:10] start gpu_sexperts
DEBUG 01-06 17:11:03.760745.760745 cuda_h.py:19] end gpu_sexperts cost 0.00030994415283203125 seconds
DEBUG 01-06 17:11:03.760528.760528 cuda_h.py:10] start gpu_experts
DEBUG 01-06 17:11:03.761689.761689 mlpmodule.py:533] gpu group tensors cost 0.0005753040313720703 s
DEBUG 01-06 17:11:03.763719.763719 mlpmodule.py:566] gpu pad cost 0.0016162395477294922 s
DEBUG 01-06 17:11:03.763810.763810 mlpmodule.py:584] gpu group einsum cost 0.0004892349243164062 s
DEBUG 01-06 17:11:03.767017.767017 mlpmodule.py:613] gpu experts func einsum cost 0.0062220096588134766 s
DEBUG 01-06 17:11:03.767405.767405 cuda_h.py:19] end gpu_experts cost 0.006374835968017578 seconds
DEBUG 01-06 17:11:03.767930.767930 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-06 17:11:03.767394.767394 lmp.py:661] 
DEBUG 01-06 17:11:03.767394.767394 lmp.py:661]   Computing 23 experts on CPU...
DEBUG 01-06 17:11:03.767661.767661 cuda_h.py:19] end cpu_experts_submit cost 5.555152893066406e-05 seconds
DEBUG 01-06 17:11:03.767642.767642 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-06 17:11:03.771722.771722 mlpmodule.py:706] group tensors cost 0.0042188167572021484 s
DEBUG 01-06 17:11:03.773254.773254 mlpmodule.py:744] pad cost 0.0012180805206298828 s
DEBUG 01-06 17:11:03.773635.773635 mlpmodule.py:750] create cpu tensor cost 4.315376281738281e-05 s
DEBUG 01-06 17:11:03.773299.773299 mlpmodule.py:755] move to cpu cost 3.0279159545898438e-05 s
DEBUG 01-06 17:11:03.776826.776826 mlpmodule.py:769] group_w3: shape=torch.Size([23, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=66322432
DEBUG 01-06 17:11:03.776014.776014 mlpmodule.py:770] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-06 17:11:03.777149.777149 mlpmodule.py:775] group_w3 first element: -0.00101470947265625
WARNING 01-06 17:11:03.777271.777271 mlpmodule.py:785] start einsum2
DEBUG 01-06 17:11:03.782333.782333 mlpmodule.py:795] group einsum cost 0.008689165115356445 s
DEBUG 01-06 17:11:03.782240.782240 mlpmodule.py:803] cpy2cputensor cost 0.00010657310485839844 s
DEBUG 01-06 17:11:03.785876.785876 cuda_h.py:19] end wait_cetm_experts cost 0.018384933471679688 seconds
DEBUG 01-06 17:11:03.786531.786531 cuda_h.py:19] end layer_moe_dgenerate_19 cost 0.02905869483947754 seconds
DEBUG 01-06 17:11:03.786463.786463 lmp.py:325] -------------------------------- end decode layer 19 --------------------------------
DEBUG 01-06 17:11:03.786180.786180 lmp.py:298] -------------------------------- start decode layer 20 --------------------------------
DEBUG 01-06 17:11:03.786975.786975 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-06 17:11:03.786946.786946 mlpmodule.py:367] cuda:1 cuda:1
DEBUG 01-06 17:11:03.786932.786932 cuda_h.py:10] start self_attn
cos shape torch.Size([65, 128]) sin shape torch.Size([65, 128]) position_ids tensor([[0]], device='cuda:1')
cos shape torch.Size([1, 1, 1, 128]) sin shape torch.Size([1, 1, 1, 128])
q_embed shape torch.Size([32, 16, 1, 128]) k_embed shape torch.Size([32, 16, 1, 128])
DEBUG 01-06 17:11:03.795957.795957 cuda_h.py:19] end self_attn cost 0.007758140563964844 seconds
DEBUG 01-06 17:11:03.795811.795811 cuda_h.py:19] end iln_self_attn_paln cost 0.008900165557861328 seconds
DEBUG 01-06 17:11:03.795946.795946 cuda_h.py:10] start layer_moe_dgenerate_20
DEBUG 01-06 17:11:03.795060.795060 cuda_h.py:10] start gate
DEBUG 01-06 17:11:03.796229.796229 cuda_h.py:19] end gate cost 0.0006442070007324219 seconds
DEBUG 01-06 17:11:03.796495.796495 cuda_h.py:10] start experts_map_get
INFO 01-06 17:11:03.796441.796441 lmp.py:609] using loaded check layer: True
INFO 01-06 17:11:03.797387.797387 lmp.py:620] 
INFO 01-06 17:11:03.797387.797387 lmp.py:620] Layer 20 Expert Device Distribution:
INFO 01-06 17:11:03.797117.797117 lmp.py:621]   Active experts: 46 (out of 64 total)
INFO 01-06 17:11:03.797058.797058 lmp.py:622] 
INFO 01-06 17:11:03.797058.797058 lmp.py:622]   Detailed Expert Distribution:
INFO 01-06 17:11:03.797145.797145 lmp.py:623]   Expert ID  | Tokens     | Actual Device  
INFO 01-06 17:11:03.797940.797940 lmp.py:624]   ----------------------------------------------------------------------
INFO 01-06 17:11:03.797451.797451 lmp.py:627]   14         | 1          |  cuda:1         
INFO 01-06 17:11:03.797962.797962 lmp.py:627]   23         | 1          |  meta           
INFO 01-06 17:11:03.797274.797274 lmp.py:627]   26         | 1          |  cuda:1         
INFO 01-06 17:11:03.797824.797824 lmp.py:627]   32         | 1          |  cuda:1         
INFO 01-06 17:11:03.797898.797898 lmp.py:627]   41         | 1          |  meta           
INFO 01-06 17:11:03.797448.797448 lmp.py:627]   42         | 1          |  meta           
INFO 01-06 17:11:03.797045.797045 lmp.py:627]   47         | 1          |  meta           
INFO 01-06 17:11:03.797833.797833 lmp.py:627]   53         | 1          |  meta           
INFO 01-06 17:11:03.797622.797622 lmp.py:627]   54         | 1          |  meta           
INFO 01-06 17:11:03.797934.797934 lmp.py:627]   59         | 1          |  cuda:1         
INFO 01-06 17:11:03.797723.797723 lmp.py:627]   61         | 1          |  cuda:1         
INFO 01-06 17:11:03.797558.797558 lmp.py:627]   9          | 2          |  cuda:1         
INFO 01-06 17:11:03.797393.797393 lmp.py:627]   12         | 2          |  cuda:1         
INFO 01-06 17:11:03.797990.797990 lmp.py:627]   16         | 2          |  cuda:1         
INFO 01-06 17:11:03.797063.797063 lmp.py:627]   33         | 2          |  meta           
INFO 01-06 17:11:03.797660.797660 lmp.py:627]   37         | 2          |  meta           
INFO 01-06 17:11:03.797733.797733 lmp.py:627]   40         | 2          |  meta           
INFO 01-06 17:11:03.797092.797092 lmp.py:627]   43         | 2          |  meta           
INFO 01-06 17:11:03.797403.797403 lmp.py:627]   44         | 2          |  cuda:1         
INFO 01-06 17:11:03.797914.797914 lmp.py:627]   56         | 2          |  cuda:1         
INFO 01-06 17:11:03.797226.797226 lmp.py:627]   57         | 2          |  meta           
INFO 01-06 17:11:03.797253.797253 lmp.py:627]   58         | 2          |  cuda:1         
INFO 01-06 17:11:03.797327.797327 lmp.py:627]   0          | 3          |  cuda:1         
INFO 01-06 17:11:03.797923.797923 lmp.py:627]   11         | 3          |  cuda:1         
INFO 01-06 17:11:03.797520.797520 lmp.py:627]   17         | 3          |  cuda:1         
INFO 01-06 17:11:03.797117.797117 lmp.py:627]   19         | 3          |  meta           
INFO 01-06 17:11:03.797190.797190 lmp.py:627]   8          | 4          |  cuda:1         
INFO 01-06 17:11:03.797548.797548 lmp.py:627]   46         | 4          |  meta           
INFO 01-06 17:11:03.797622.797622 lmp.py:627]   50         | 4          |  meta           
INFO 01-06 17:11:03.797411.797411 lmp.py:627]   1          | 5          |  cuda:1         
INFO 01-06 17:11:03.797484.797484 lmp.py:627]   5          | 5          |  cuda:1         
INFO 01-06 17:11:03.797558.797558 lmp.py:627]   7          | 5          |  cuda:1         
INFO 01-06 17:11:03.797393.797393 lmp.py:627]   18         | 5          |  cuda:1         
INFO 01-06 17:11:03.797989.797989 lmp.py:627]   51         | 5          |  cuda:1         
INFO 01-06 17:11:03.797348.797348 lmp.py:627]   55         | 5          |  meta           
INFO 01-06 17:11:03.797467.797467 lmp.py:627]   62         | 5          |  cuda:1         
INFO 01-06 17:11:03.798826.798826 lmp.py:627]   10         | 6          |  cuda:1         
INFO 01-06 17:11:03.798945.798945 lmp.py:627]   20         | 6          |  meta           
INFO 01-06 17:11:03.798542.798542 lmp.py:627]   49         | 6          |  meta           
INFO 01-06 17:11:03.798662.798662 lmp.py:627]   15         | 7          |  cuda:1         
INFO 01-06 17:11:03.798020.798020 lmp.py:627]   24         | 8          |  meta           
INFO 01-06 17:11:03.798332.798332 lmp.py:627]   45         | 8          |  cuda:1         
INFO 01-06 17:11:03.798167.798167 lmp.py:627]   25         | 10         |  cuda:1         
INFO 01-06 17:11:03.798241.798241 lmp.py:627]   31         | 10         |  cuda:1         
INFO 01-06 17:11:03.798314.798314 lmp.py:627]   60         | 17         |  cuda:1         
INFO 01-06 17:11:03.798864.798864 lmp.py:627]   48         | 22         |  cuda:1         
INFO 01-06 17:11:03.798607.798607 lmp.py:628] ============================================================
INFO 01-06 17:11:03.798607.798607 lmp.py:628] 
INFO 01-06 17:11:03.798833.798833 lmp.py:630] experts_gpu_list: [14, 26, 32, 59, 61, 9, 12, 16, 44, 56, 58, 0, 11, 17, 8, 1, 5, 7, 18, 51, 62, 10, 15, 45, 25, 31, 60, 48] num: 28
INFO 01-06 17:11:03.798291.798291 lmp.py:631] experts_cpu_list: [23, 41, 42, 47, 53, 54, 33, 37, 40, 43, 57, 19, 46, 50, 55, 20, 49, 24] num: 18
INFO 01-06 17:11:03.798185.798185 lmp.py:632] expert_actual_device_map {0: 'cuda:1', 1: 'cuda:1', 2: 'cuda:1', 3: 'cuda:1', 4: 'cuda:1', 5: 'cuda:1', 6: 'cuda:1', 7: 'cuda:1', 8: 'cuda:1', 9: 'cuda:1', 10: 'cuda:1', 11: 'cuda:1', 12: 'cuda:1', 13: 'meta', 14: 'cuda:1', 15: 'cuda:1', 16: 'cuda:1', 17: 'cuda:1', 18: 'cuda:1', 19: 'meta', 20: 'meta', 21: 'meta', 22: 'meta', 23: 'meta', 24: 'meta', 25: 'cuda:1', 26: 'cuda:1', 27: 'cuda:1', 28: 'meta', 29: 'cuda:1', 30: 'cuda:1', 31: 'cuda:1', 32: 'cuda:1', 33: 'meta', 34: 'cuda:1', 35: 'cuda:1', 36: 'meta', 37: 'meta', 38: 'meta', 39: 'meta', 40: 'meta', 41: 'meta', 42: 'meta', 43: 'meta', 44: 'cuda:1', 45: 'cuda:1', 46: 'meta', 47: 'meta', 48: 'cuda:1', 49: 'meta', 50: 'meta', 51: 'cuda:1', 52: 'meta', 53: 'meta', 54: 'meta', 55: 'meta', 56: 'cuda:1', 57: 'meta', 58: 'cuda:1', 59: 'cuda:1', 60: 'cuda:1', 61: 'cuda:1', 62: 'cuda:1', 63: 'meta'}
DEBUG 01-06 17:11:03.798034.798034 cuda_h.py:19] end experts_map_get cost 0.002009153366088867 seconds
DEBUG 01-06 17:11:03.798291.798291 mlpmodule.py:664]  experts func einsum cost 0.030920982360839844 s
DEBUG 01-06 17:11:03.798575.798575 cuda_h.py:10] start gpu_sexperts
DEBUG 01-06 17:11:03.799728.799728 cuda_h.py:19] end gpu_sexperts cost 0.00031638145446777344 seconds
DEBUG 01-06 17:11:03.799280.799280 cuda_h.py:10] start gpu_experts
DEBUG 01-06 17:11:03.799436.799436 mlpmodule.py:533] gpu group tensors cost 0.0004208087921142578 s
DEBUG 01-06 17:11:03.800407.800407 mlpmodule.py:566] gpu pad cost 0.0012640953063964844 s
DEBUG 01-06 17:11:03.801087.801087 mlpmodule.py:584] gpu group einsum cost 0.00046443939208984375 s
DEBUG 01-06 17:11:03.803091.803091 mlpmodule.py:613] gpu experts func einsum cost 0.00476527214050293 s
DEBUG 01-06 17:11:03.804498.804498 cuda_h.py:19] end gpu_experts cost 0.0049076080322265625 seconds
DEBUG 01-06 17:11:03.804300.804300 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-06 17:11:03.804573.804573 lmp.py:661] 
DEBUG 01-06 17:11:03.804573.804573 lmp.py:661]   Computing 18 experts on CPU...
DEBUG 01-06 17:11:03.804654.804654 cuda_h.py:19] end cpu_experts_submit cost 5.841255187988281e-05 seconds
DEBUG 01-06 17:11:03.804470.804470 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-06 17:11:03.813873.813873 mlpmodule.py:706] group tensors cost 0.008694648742675781 s
DEBUG 01-06 17:11:03.814740.814740 mlpmodule.py:744] pad cost 0.0010905265808105469 s
DEBUG 01-06 17:11:03.814380.814380 mlpmodule.py:750] create cpu tensor cost 5.793571472167969e-05 s
DEBUG 01-06 17:11:03.815766.815766 mlpmodule.py:755] move to cpu cost 3.3855438232421875e-05 s
DEBUG 01-06 17:11:03.817112.817112 mlpmodule.py:769] group_w3: shape=torch.Size([18, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=51904512
DEBUG 01-06 17:11:03.817008.817008 mlpmodule.py:770] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-06 17:11:03.817659.817659 mlpmodule.py:775] group_w3 first element: 0.00433349609375
WARNING 01-06 17:11:03.817265.817265 mlpmodule.py:785] start einsum2
DEBUG 01-06 17:11:03.821004.821004 mlpmodule.py:795] group einsum cost 0.006453990936279297 s
DEBUG 01-06 17:11:03.821175.821175 mlpmodule.py:803] cpy2cputensor cost 0.00010061264038085938 s
DEBUG 01-06 17:11:03.824001.824001 cuda_h.py:19] end wait_cetm_experts cost 0.019936561584472656 seconds
DEBUG 01-06 17:11:03.824306.824306 cuda_h.py:19] end layer_moe_dgenerate_20 cost 0.02911996841430664 seconds
DEBUG 01-06 17:11:03.824609.824609 lmp.py:325] -------------------------------- end decode layer 20 --------------------------------
DEBUG 01-06 17:11:03.824041.824041 lmp.py:298] -------------------------------- start decode layer 21 --------------------------------
DEBUG 01-06 17:11:03.824029.824029 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-06 17:11:03.824099.824099 mlpmodule.py:367] cuda:1 cuda:1
DEBUG 01-06 17:11:03.825463.825463 cuda_h.py:10] start self_attn
cos shape torch.Size([65, 128]) sin shape torch.Size([65, 128]) position_ids tensor([[0]], device='cuda:1')
cos shape torch.Size([1, 1, 1, 128]) sin shape torch.Size([1, 1, 1, 128])
q_embed shape torch.Size([32, 16, 1, 128]) k_embed shape torch.Size([32, 16, 1, 128])
DEBUG 01-06 17:11:03.827147.827147 cuda_h.py:19] end self_attn cost 0.001986265182495117 seconds
DEBUG 01-06 17:11:03.827840.827840 cuda_h.py:19] end iln_self_attn_paln cost 0.0028448104858398438 seconds
DEBUG 01-06 17:11:03.827723.827723 cuda_h.py:10] start layer_moe_dgenerate_21
DEBUG 01-06 17:11:03.827731.827731 cuda_h.py:10] start gate
DEBUG 01-06 17:11:03.828488.828488 cuda_h.py:19] end gate cost 0.0006175041198730469 seconds
DEBUG 01-06 17:11:03.828232.828232 cuda_h.py:10] start experts_map_get
INFO 01-06 17:11:03.828011.828011 lmp.py:609] using loaded check layer: True
INFO 01-06 17:11:03.829606.829606 lmp.py:620] 
INFO 01-06 17:11:03.829606.829606 lmp.py:620] Layer 21 Expert Device Distribution:
INFO 01-06 17:11:03.829229.829229 lmp.py:621]   Active experts: 51 (out of 64 total)
INFO 01-06 17:11:03.829886.829886 lmp.py:622] 
INFO 01-06 17:11:03.829886.829886 lmp.py:622]   Detailed Expert Distribution:
INFO 01-06 17:11:03.829019.829019 lmp.py:623]   Expert ID  | Tokens     | Actual Device  
INFO 01-06 17:11:03.829576.829576 lmp.py:624]   ----------------------------------------------------------------------
INFO 01-06 17:11:03.829326.829326 lmp.py:627]   1          | 1          |  cuda:1         
INFO 01-06 17:11:03.829883.829883 lmp.py:627]   2          | 1          |  cuda:1         
INFO 01-06 17:11:03.829725.829725 lmp.py:627]   3          | 1          |  cuda:1         
INFO 01-06 17:11:03.829328.829328 lmp.py:627]   7          | 1          |  cuda:1         
INFO 01-06 17:11:03.829693.829693 lmp.py:627]   11         | 1          |  meta           
INFO 01-06 17:11:03.829773.829773 lmp.py:627]   19         | 1          |  cuda:1         
INFO 01-06 17:11:03.829615.829615 lmp.py:627]   27         | 1          |  meta           
INFO 01-06 17:11:03.829888.829888 lmp.py:627]   31         | 1          |  cuda:1         
INFO 01-06 17:11:03.829266.829266 lmp.py:627]   32         | 1          |  meta           
INFO 01-06 17:11:03.829823.829823 lmp.py:627]   37         | 1          |  cuda:1         
INFO 01-06 17:11:03.829665.829665 lmp.py:627]   43         | 1          |  cuda:1         
INFO 01-06 17:11:03.829030.829030 lmp.py:627]   44         | 1          |  meta           
INFO 01-06 17:11:03.829157.829157 lmp.py:627]   47         | 1          |  meta           
INFO 01-06 17:11:03.829045.829045 lmp.py:627]   48         | 1          |  meta           
INFO 01-06 17:11:03.829410.829410 lmp.py:627]   51         | 1          |  meta           
INFO 01-06 17:11:03.829775.829775 lmp.py:627]   57         | 1          |  cuda:1         
INFO 01-06 17:11:03.829776.829776 lmp.py:627]   60         | 1          |  meta           
INFO 01-06 17:11:03.829857.829857 lmp.py:627]   14         | 2          |  meta           
INFO 01-06 17:11:03.830937.830937 lmp.py:627]   17         | 2          |  cuda:1         
INFO 01-06 17:11:03.830825.830825 lmp.py:627]   23         | 2          |  meta           
INFO 01-06 17:11:03.830190.830190 lmp.py:627]   28         | 2          |  cuda:1         
INFO 01-06 17:11:03.830317.830317 lmp.py:627]   42         | 2          |  cuda:1         
INFO 01-06 17:11:03.830966.830966 lmp.py:627]   50         | 2          |  meta           
INFO 01-06 17:11:03.830093.830093 lmp.py:627]   53         | 2          |  meta           
INFO 01-06 17:11:03.830935.830935 lmp.py:627]   59         | 2          |  meta           
INFO 01-06 17:11:03.830300.830300 lmp.py:627]   5          | 3          |  cuda:1         
INFO 01-06 17:11:03.830142.830142 lmp.py:627]   10         | 3          |  cuda:1         
INFO 01-06 17:11:03.830460.830460 lmp.py:627]   18         | 3          |  cuda:1         
INFO 01-06 17:11:03.830587.830587 lmp.py:627]   20         | 3          |  cuda:1         
INFO 01-06 17:11:03.830714.830714 lmp.py:627]   26         | 3          |  meta           
INFO 01-06 17:11:03.830602.830602 lmp.py:627]   34         | 3          |  meta           
INFO 01-06 17:11:03.830728.830728 lmp.py:627]   39         | 3          |  meta           
INFO 01-06 17:11:03.830855.830855 lmp.py:627]   58         | 3          |  cuda:1         
INFO 01-06 17:11:03.830743.830743 lmp.py:627]   62         | 3          |  meta           
INFO 01-06 17:11:03.830347.830347 lmp.py:627]   8          | 4          |  meta           
INFO 01-06 17:11:03.830712.830712 lmp.py:627]   24         | 4          |  meta           
INFO 01-06 17:11:03.830077.830077 lmp.py:627]   25         | 4          |  cuda:1         
INFO 01-06 17:11:03.830203.830203 lmp.py:627]   16         | 5          |  cuda:1         
INFO 01-06 17:11:03.830807.830807 lmp.py:627]   29         | 5          |  cuda:1         
INFO 01-06 17:11:03.830933.830933 lmp.py:627]   63         | 5          |  cuda:1         
INFO 01-06 17:11:03.830583.830583 lmp.py:627]   13         | 6          |  cuda:1         
INFO 01-06 17:11:03.830233.830233 lmp.py:627]   15         | 6          |  cuda:1         
INFO 01-06 17:11:03.830075.830075 lmp.py:627]   22         | 6          |  meta           
INFO 01-06 17:11:03.830917.830917 lmp.py:627]   61         | 6          |  cuda:1         
INFO 01-06 17:11:03.830758.830758 lmp.py:627]   21         | 7          |  cuda:1         
INFO 01-06 17:11:03.830123.830123 lmp.py:627]   56         | 8          |  meta           
INFO 01-06 17:11:03.830488.830488 lmp.py:627]   55         | 9          |  cuda:1         
INFO 01-06 17:11:03.830377.830377 lmp.py:627]   0          | 11         |  cuda:1         
INFO 01-06 17:11:03.830503.830503 lmp.py:627]   12         | 12         |  cuda:1         
INFO 01-06 17:11:03.830868.830868 lmp.py:627]   40         | 16         |  cuda:1         
INFO 01-06 17:11:03.830756.830756 lmp.py:627]   45         | 18         |  cuda:1         
INFO 01-06 17:11:03.830406.830406 lmp.py:628] ============================================================
INFO 01-06 17:11:03.830406.830406 lmp.py:628] 
INFO 01-06 17:11:03.830255.830255 lmp.py:630] experts_gpu_list: [1, 2, 3, 7, 19, 31, 37, 43, 57, 17, 28, 42, 5, 10, 18, 20, 58, 25, 16, 29, 63, 13, 15, 61, 21, 55, 0, 12, 40, 45] num: 30
INFO 01-06 17:11:03.830481.830481 lmp.py:631] experts_cpu_list: [11, 27, 32, 44, 47, 48, 51, 60, 14, 23, 50, 53, 59, 26, 34, 39, 62, 8, 24, 22, 56] num: 21
INFO 01-06 17:11:03.830197.830197 lmp.py:632] expert_actual_device_map {0: 'cuda:1', 1: 'cuda:1', 2: 'cuda:1', 3: 'cuda:1', 4: 'cuda:1', 5: 'cuda:1', 6: 'cuda:1', 7: 'cuda:1', 8: 'meta', 9: 'meta', 10: 'cuda:1', 11: 'meta', 12: 'cuda:1', 13: 'cuda:1', 14: 'meta', 15: 'cuda:1', 16: 'cuda:1', 17: 'cuda:1', 18: 'cuda:1', 19: 'cuda:1', 20: 'cuda:1', 21: 'cuda:1', 22: 'meta', 23: 'meta', 24: 'meta', 25: 'cuda:1', 26: 'meta', 27: 'meta', 28: 'cuda:1', 29: 'cuda:1', 30: 'cuda:1', 31: 'cuda:1', 32: 'meta', 33: 'cuda:1', 34: 'meta', 35: 'meta', 36: 'cuda:1', 37: 'cuda:1', 38: 'meta', 39: 'meta', 40: 'cuda:1', 41: 'meta', 42: 'cuda:1', 43: 'cuda:1', 44: 'meta', 45: 'cuda:1', 46: 'cuda:1', 47: 'meta', 48: 'meta', 49: 'cuda:1', 50: 'meta', 51: 'meta', 52: 'meta', 53: 'meta', 54: 'meta', 55: 'cuda:1', 56: 'meta', 57: 'cuda:1', 58: 'cuda:1', 59: 'meta', 60: 'meta', 61: 'cuda:1', 62: 'meta', 63: 'cuda:1'}
DEBUG 01-06 17:11:03.830768.830768 cuda_h.py:19] end experts_map_get cost 0.002328634262084961 seconds
DEBUG 01-06 17:11:03.830009.830009 mlpmodule.py:664]  experts func einsum cost 0.026625633239746094 s
DEBUG 01-06 17:11:03.831098.831098 cuda_h.py:10] start gpu_sexperts
DEBUG 01-06 17:11:03.831658.831658 cuda_h.py:19] end gpu_sexperts cost 0.0003349781036376953 seconds
DEBUG 01-06 17:11:03.831070.831070 cuda_h.py:10] start gpu_experts
DEBUG 01-06 17:11:03.832541.832541 mlpmodule.py:533] gpu group tensors cost 0.0005536079406738281 s
DEBUG 01-06 17:11:03.833861.833861 mlpmodule.py:566] gpu pad cost 0.0015912055969238281 s
DEBUG 01-06 17:11:03.834555.834555 mlpmodule.py:584] gpu group einsum cost 0.00047278404235839844 s
DEBUG 01-06 17:11:03.837536.837536 mlpmodule.py:613] gpu experts func einsum cost 0.005919218063354492 s
DEBUG 01-06 17:11:03.837704.837704 cuda_h.py:19] end gpu_experts cost 0.006054401397705078 seconds
DEBUG 01-06 17:11:03.837937.837937 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-06 17:11:03.837878.837878 lmp.py:661] 
DEBUG 01-06 17:11:03.837878.837878 lmp.py:661]   Computing 21 experts on CPU...
DEBUG 01-06 17:11:03.837384.837384 cuda_h.py:19] end cpu_experts_submit cost 5.4836273193359375e-05 seconds
DEBUG 01-06 17:11:03.837702.837702 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-06 17:11:03.846243.846243 mlpmodule.py:706] group tensors cost 0.008680105209350586 s
DEBUG 01-06 17:11:03.848236.848236 mlpmodule.py:744] pad cost 0.001207113265991211 s
DEBUG 01-06 17:11:03.848425.848425 mlpmodule.py:750] create cpu tensor cost 4.506111145019531e-05 s
DEBUG 01-06 17:11:03.848612.848612 mlpmodule.py:755] move to cpu cost 3.266334533691406e-05 s
DEBUG 01-06 17:11:03.851493.851493 mlpmodule.py:769] group_w3: shape=torch.Size([21, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=60555264
DEBUG 01-06 17:11:03.851952.851952 mlpmodule.py:770] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-06 17:11:03.851550.851550 mlpmodule.py:775] group_w3 first element: 0.0115966796875
WARNING 01-06 17:11:03.851427.851427 mlpmodule.py:785] start einsum2
DEBUG 01-06 17:11:03.857618.857618 mlpmodule.py:795] group einsum cost 0.008251428604125977 s
DEBUG 01-06 17:11:03.857372.857372 mlpmodule.py:803] cpy2cputensor cost 0.00010776519775390625 s
DEBUG 01-06 17:11:03.860775.860775 cuda_h.py:19] end wait_cetm_experts cost 0.02225351333618164 seconds
DEBUG 01-06 17:11:03.860005.860005 cuda_h.py:19] end layer_moe_dgenerate_21 cost 0.03287839889526367 seconds
DEBUG 01-06 17:11:03.860112.860112 lmp.py:325] -------------------------------- end decode layer 21 --------------------------------
DEBUG 01-06 17:11:03.861082.861082 lmp.py:298] -------------------------------- start decode layer 22 --------------------------------
DEBUG 01-06 17:11:03.861210.861210 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-06 17:11:03.861593.861593 mlpmodule.py:367] cuda:1 cuda:1
DEBUG 01-06 17:11:03.861092.861092 cuda_h.py:10] start self_attn
cos shape torch.Size([65, 128]) sin shape torch.Size([65, 128]) position_ids tensor([[0]], device='cuda:1')
cos shape torch.Size([1, 1, 1, 128]) sin shape torch.Size([1, 1, 1, 128])
q_embed shape torch.Size([32, 16, 1, 128]) k_embed shape torch.Size([32, 16, 1, 128])
DEBUG 01-06 17:11:03.865269.865269 mlpmodule.py:664]  experts func einsum cost 0.027298688888549805 s
DEBUG 01-06 17:11:03.865772.865772 cuda_h.py:19] end self_attn cost 0.0033669471740722656 seconds
DEBUG 01-06 17:11:03.865003.865003 cuda_h.py:19] end iln_self_attn_paln cost 0.004631519317626953 seconds
DEBUG 01-06 17:11:03.865793.865793 cuda_h.py:10] start layer_moe_dgenerate_22
DEBUG 01-06 17:11:03.865185.865185 cuda_h.py:10] start gate
DEBUG 01-06 17:11:03.866955.866955 cuda_h.py:19] end gate cost 0.0005958080291748047 seconds
DEBUG 01-06 17:11:03.866698.866698 cuda_h.py:10] start experts_map_get
INFO 01-06 17:11:03.866855.866855 lmp.py:609] using loaded check layer: True
INFO 01-06 17:11:03.867389.867389 lmp.py:620] 
INFO 01-06 17:11:03.867389.867389 lmp.py:620] Layer 22 Expert Device Distribution:
INFO 01-06 17:11:03.867152.867152 lmp.py:621]   Active experts: 51 (out of 64 total)
INFO 01-06 17:11:03.867723.867723 lmp.py:622] 
INFO 01-06 17:11:03.867723.867723 lmp.py:622]   Detailed Expert Distribution:
INFO 01-06 17:11:03.867187.867187 lmp.py:623]   Expert ID  | Tokens     | Actual Device  
INFO 01-06 17:11:03.867075.867075 lmp.py:624]   ----------------------------------------------------------------------
INFO 01-06 17:11:03.867440.867440 lmp.py:627]   1          | 1          |  cuda:1         
INFO 01-06 17:11:03.867898.867898 lmp.py:627]   2          | 1          |  cuda:1         
INFO 01-06 17:11:03.867641.867641 lmp.py:627]   3          | 1          |  cuda:1         
INFO 01-06 17:11:03.867621.867621 lmp.py:627]   6          | 1          |  cuda:1         
INFO 01-06 17:11:03.867125.867125 lmp.py:627]   8          | 1          |  cuda:1         
INFO 01-06 17:11:03.867629.867629 lmp.py:627]   9          | 1          |  meta           
INFO 01-06 17:11:03.867372.867372 lmp.py:627]   13         | 1          |  meta           
INFO 01-06 17:11:03.867068.867068 lmp.py:627]   19         | 1          |  cuda:1         
INFO 01-06 17:11:03.867764.867764 lmp.py:627]   21         | 1          |  meta           
INFO 01-06 17:11:03.867222.867222 lmp.py:627]   29         | 1          |  cuda:1         
INFO 01-06 17:11:03.867679.867679 lmp.py:627]   31         | 1          |  cuda:1         
INFO 01-06 17:11:03.867422.867422 lmp.py:627]   35         | 1          |  cuda:1         
INFO 01-06 17:11:03.867687.867687 lmp.py:627]   41         | 1          |  cuda:1         
INFO 01-06 17:11:03.867191.867191 lmp.py:627]   42         | 1          |  meta           
INFO 01-06 17:11:03.867695.867695 lmp.py:627]   53         | 1          |  cuda:1         
INFO 01-06 17:11:03.867438.867438 lmp.py:627]   57         | 1          |  meta           
INFO 01-06 17:11:03.867703.867703 lmp.py:627]   10         | 2          |  meta           
INFO 01-06 17:11:03.867638.867638 lmp.py:627]   12         | 2          |  cuda:1         
INFO 01-06 17:11:03.867619.867619 lmp.py:627]   16         | 2          |  cuda:1         
INFO 01-06 17:11:03.867076.867076 lmp.py:627]   20         | 2          |  meta           
INFO 01-06 17:11:03.868534.868534 lmp.py:627]   33         | 2          |  cuda:1         
INFO 01-06 17:11:03.868276.868276 lmp.py:627]   37         | 2          |  meta           
INFO 01-06 17:11:03.868780.868780 lmp.py:627]   44         | 2          |  meta           
INFO 01-06 17:11:03.868284.868284 lmp.py:627]   47         | 2          |  meta           
INFO 01-06 17:11:03.868550.868550 lmp.py:627]   48         | 2          |  meta           
INFO 01-06 17:11:03.868816.868816 lmp.py:627]   49         | 2          |  cuda:1         
INFO 01-06 17:11:03.868604.868604 lmp.py:627]   4          | 3          |  cuda:1         
INFO 01-06 17:11:03.868108.868108 lmp.py:627]   17         | 3          |  cuda:1         
INFO 01-06 17:11:03.868328.868328 lmp.py:627]   22         | 3          |  cuda:1         
INFO 01-06 17:11:03.868308.868308 lmp.py:627]   52         | 3          |  meta           
INFO 01-06 17:11:03.868528.868528 lmp.py:627]   55         | 3          |  cuda:1         
INFO 01-06 17:11:03.868032.868032 lmp.py:627]   59         | 3          |  cuda:1         
INFO 01-06 17:11:03.868536.868536 lmp.py:627]   7          | 4          |  cuda:1         
INFO 01-06 17:11:03.868324.868324 lmp.py:627]   11         | 4          |  meta           
INFO 01-06 17:11:03.868352.868352 lmp.py:627]   23         | 4          |  cuda:1         
INFO 01-06 17:11:03.868140.868140 lmp.py:627]   32         | 4          |  cuda:1         
INFO 01-06 17:11:03.868929.868929 lmp.py:627]   58         | 4          |  cuda:1         
INFO 01-06 17:11:03.868195.868195 lmp.py:627]   14         | 5          |  meta           
INFO 01-06 17:11:03.868806.868806 lmp.py:627]   5          | 6          |  cuda:1         
INFO 01-06 17:11:03.868217.868217 lmp.py:627]   27         | 6          |  cuda:1         
INFO 01-06 17:11:03.868437.868437 lmp.py:627]   30         | 6          |  cuda:1         
INFO 01-06 17:11:03.868656.868656 lmp.py:627]   36         | 6          |  meta           
INFO 01-06 17:11:03.868921.868921 lmp.py:627]   40         | 6          |  cuda:1         
INFO 01-06 17:11:03.868949.868949 lmp.py:627]   26         | 7          |  cuda:1         
INFO 01-06 17:11:03.868737.868737 lmp.py:627]   18         | 8          |  cuda:1         
INFO 01-06 17:11:03.868765.868765 lmp.py:627]   54         | 8          |  meta           
INFO 01-06 17:11:03.868030.868030 lmp.py:627]   60         | 8          |  cuda:1         
INFO 01-06 17:11:03.868296.868296 lmp.py:627]   61         | 8          |  meta           
INFO 01-06 17:11:03.868323.868323 lmp.py:627]   28         | 10         |  meta           
INFO 01-06 17:11:03.868019.868019 lmp.py:627]   34         | 11         |  cuda:1         
INFO 01-06 17:11:03.868238.868238 lmp.py:627]   56         | 23         |  cuda:1         
INFO 01-06 17:11:03.868504.868504 lmp.py:628] ============================================================
INFO 01-06 17:11:03.868504.868504 lmp.py:628] 
INFO 01-06 17:11:03.868922.868922 lmp.py:630] experts_gpu_list: [1, 2, 3, 6, 8, 19, 29, 31, 35, 41, 53, 12, 16, 33, 49, 4, 17, 22, 55, 59, 7, 23, 32, 58, 5, 27, 30, 40, 26, 18, 60, 34, 56] num: 33
INFO 01-06 17:11:03.868333.868333 lmp.py:631] experts_cpu_list: [9, 13, 21, 42, 57, 10, 20, 37, 44, 47, 48, 52, 11, 14, 36, 54, 61, 28] num: 18
INFO 01-06 17:11:03.868043.868043 lmp.py:632] expert_actual_device_map {0: 'cuda:1', 1: 'cuda:1', 2: 'cuda:1', 3: 'cuda:1', 4: 'cuda:1', 5: 'cuda:1', 6: 'cuda:1', 7: 'cuda:1', 8: 'cuda:1', 9: 'meta', 10: 'meta', 11: 'meta', 12: 'cuda:1', 13: 'meta', 14: 'meta', 15: 'meta', 16: 'cuda:1', 17: 'cuda:1', 18: 'cuda:1', 19: 'cuda:1', 20: 'meta', 21: 'meta', 22: 'cuda:1', 23: 'cuda:1', 24: 'meta', 25: 'meta', 26: 'cuda:1', 27: 'cuda:1', 28: 'meta', 29: 'cuda:1', 30: 'cuda:1', 31: 'cuda:1', 32: 'cuda:1', 33: 'cuda:1', 34: 'cuda:1', 35: 'cuda:1', 36: 'meta', 37: 'meta', 38: 'meta', 39: 'cuda:1', 40: 'cuda:1', 41: 'cuda:1', 42: 'meta', 43: 'meta', 44: 'meta', 45: 'meta', 46: 'meta', 47: 'meta', 48: 'meta', 49: 'cuda:1', 50: 'meta', 51: 'cuda:1', 52: 'meta', 53: 'cuda:1', 54: 'meta', 55: 'cuda:1', 56: 'cuda:1', 57: 'meta', 58: 'cuda:1', 59: 'cuda:1', 60: 'cuda:1', 61: 'meta', 62: 'meta', 63: 'cuda:1'}
DEBUG 01-06 17:11:03.868753.868753 cuda_h.py:19] end experts_map_get cost 0.0021829605102539062 seconds
DEBUG 01-06 17:11:03.868716.868716 cuda_h.py:10] start gpu_sexperts
DEBUG 01-06 17:11:03.869668.869668 cuda_h.py:19] end gpu_sexperts cost 0.00031113624572753906 seconds
DEBUG 01-06 17:11:03.869590.869590 cuda_h.py:10] start gpu_experts
DEBUG 01-06 17:11:03.869877.869877 mlpmodule.py:533] gpu group tensors cost 0.0005974769592285156 s
DEBUG 01-06 17:11:03.871226.871226 mlpmodule.py:566] gpu pad cost 0.0016791820526123047 s
DEBUG 01-06 17:11:03.872742.872742 mlpmodule.py:584] gpu group einsum cost 0.00048470497131347656 s
DEBUG 01-06 17:11:03.875732.875732 mlpmodule.py:613] gpu experts func einsum cost 0.00635218620300293 s
DEBUG 01-06 17:11:03.875961.875961 cuda_h.py:19] end gpu_experts cost 0.006492137908935547 seconds
DEBUG 01-06 17:11:03.875717.875717 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-06 17:11:03.875896.875896 lmp.py:661] 
DEBUG 01-06 17:11:03.875896.875896 lmp.py:661]   Computing 18 experts on CPU...
DEBUG 01-06 17:11:03.875885.875885 cuda_h.py:19] end cpu_experts_submit cost 6.031990051269531e-05 seconds
DEBUG 01-06 17:11:03.875250.875250 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-06 17:11:03.885520.885520 mlpmodule.py:706] group tensors cost 0.009824752807617188 s
DEBUG 01-06 17:11:03.887263.887263 mlpmodule.py:744] pad cost 0.0010542869567871094 s
DEBUG 01-06 17:11:03.887597.887597 mlpmodule.py:750] create cpu tensor cost 4.5299530029296875e-05 s
DEBUG 01-06 17:11:03.887831.887831 mlpmodule.py:755] move to cpu cost 3.147125244140625e-05 s
DEBUG 01-06 17:11:03.890778.890778 mlpmodule.py:769] group_w3: shape=torch.Size([18, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=51904512
DEBUG 01-06 17:11:03.890436.890436 mlpmodule.py:770] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-06 17:11:03.890233.890233 mlpmodule.py:775] group_w3 first element: 0.01263427734375
WARNING 01-06 17:11:03.890024.890024 mlpmodule.py:785] start einsum2
DEBUG 01-06 17:11:03.895164.895164 mlpmodule.py:795] group einsum cost 0.007718324661254883 s
DEBUG 01-06 17:11:03.895633.895633 mlpmodule.py:803] cpy2cputensor cost 0.00010538101196289062 s
DEBUG 01-06 17:11:03.898000.898000 cuda_h.py:19] end wait_cetm_experts cost 0.022517681121826172 seconds
DEBUG 01-06 17:11:03.898762.898762 cuda_h.py:19] end layer_moe_dgenerate_22 cost 0.03304624557495117 seconds
DEBUG 01-06 17:11:03.899986.899986 lmp.py:325] -------------------------------- end decode layer 22 --------------------------------
DEBUG 01-06 17:11:03.899417.899417 lmp.py:298] -------------------------------- start decode layer 23 --------------------------------
DEBUG 01-06 17:11:03.899451.899451 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-06 17:11:03.899561.899561 mlpmodule.py:367] cuda:1 cuda:1
DEBUG 01-06 17:11:03.899587.899587 cuda_h.py:10] start self_attn
cos shape torch.Size([65, 128]) sin shape torch.Size([65, 128]) position_ids tensor([[0]], device='cuda:1')
cos shape torch.Size([1, 1, 1, 128]) sin shape torch.Size([1, 1, 1, 128])
q_embed shape torch.Size([32, 16, 1, 128]) k_embed shape torch.Size([32, 16, 1, 128])
DEBUG 01-06 17:11:03.901463.901463 cuda_h.py:19] end self_attn cost 0.001986980438232422 seconds
DEBUG 01-06 17:11:03.902773.902773 cuda_h.py:19] end iln_self_attn_paln cost 0.002834796905517578 seconds
DEBUG 01-06 17:11:03.902139.902139 cuda_h.py:10] start layer_moe_dgenerate_23
DEBUG 01-06 17:11:03.902531.902531 cuda_h.py:10] start gate
DEBUG 01-06 17:11:03.902970.902970 cuda_h.py:19] end gate cost 0.000598907470703125 seconds
DEBUG 01-06 17:11:03.902044.902044 cuda_h.py:10] start experts_map_get
INFO 01-06 17:11:03.903651.903651 lmp.py:609] using loaded check layer: True
INFO 01-06 17:11:03.903391.903391 lmp.py:620] 
INFO 01-06 17:11:03.903391.903391 lmp.py:620] Layer 23 Expert Device Distribution:
INFO 01-06 17:11:03.903512.903512 lmp.py:621]   Active experts: 45 (out of 64 total)
INFO 01-06 17:11:03.903599.903599 lmp.py:622] 
INFO 01-06 17:11:03.903599.903599 lmp.py:622]   Detailed Expert Distribution:
INFO 01-06 17:11:03.903255.903255 lmp.py:623]   Expert ID  | Tokens     | Actual Device  
INFO 01-06 17:11:03.903574.903574 lmp.py:624]   ----------------------------------------------------------------------
INFO 01-06 17:11:03.903608.903608 lmp.py:627]   2          | 1          |  cuda:1         
INFO 01-06 17:11:03.903927.903927 lmp.py:627]   11         | 1          |  meta           
INFO 01-06 17:11:03.903245.903245 lmp.py:627]   21         | 1          |  meta           
INFO 01-06 17:11:03.903326.903326 lmp.py:627]   29         | 1          |  cuda:1         
INFO 01-06 17:11:03.903929.903929 lmp.py:627]   47         | 1          |  meta           
INFO 01-06 17:11:03.903056.903056 lmp.py:627]   50         | 1          |  cuda:1         
INFO 01-06 17:11:03.903090.903090 lmp.py:627]   52         | 1          |  meta           
INFO 01-06 17:11:03.904647.904647 lmp.py:627]   53         | 1          |  meta           
INFO 01-06 17:11:03.904681.904681 lmp.py:627]   61         | 1          |  cuda:1         
INFO 01-06 17:11:03.904569.904569 lmp.py:627]   62         | 1          |  meta           
INFO 01-06 17:11:03.904934.904934 lmp.py:627]   18         | 2          |  cuda:1         
INFO 01-06 17:11:03.904061.904061 lmp.py:627]   19         | 2          |  cuda:1         
INFO 01-06 17:11:03.904710.904710 lmp.py:627]   23         | 2          |  meta           
INFO 01-06 17:11:03.904837.904837 lmp.py:627]   26         | 2          |  cuda:1         
INFO 01-06 17:11:03.904679.904679 lmp.py:627]   31         | 2          |  cuda:1         
INFO 01-06 17:11:03.904759.904759 lmp.py:627]   49         | 2          |  meta           
INFO 01-06 17:11:03.904078.904078 lmp.py:627]   56         | 2          |  meta           
INFO 01-06 17:11:03.904966.904966 lmp.py:627]   57         | 2          |  meta           
INFO 01-06 17:11:03.904377.904377 lmp.py:627]   6          | 3          |  cuda:1         
INFO 01-06 17:11:03.904027.904027 lmp.py:627]   13         | 3          |  cuda:1         
INFO 01-06 17:11:03.904392.904392 lmp.py:627]   16         | 3          |  meta           
INFO 01-06 17:11:03.904042.904042 lmp.py:627]   20         | 3          |  cuda:1         
INFO 01-06 17:11:03.904168.904168 lmp.py:627]   35         | 3          |  cuda:1         
INFO 01-06 17:11:03.904077.904077 lmp.py:627]   55         | 3          |  cuda:1         
INFO 01-06 17:11:03.904204.904204 lmp.py:627]   8          | 4          |  cuda:1         
INFO 01-06 17:11:03.904569.904569 lmp.py:627]   22         | 4          |  cuda:1         
INFO 01-06 17:11:03.904934.904934 lmp.py:627]   45         | 4          |  meta           
INFO 01-06 17:11:03.904060.904060 lmp.py:627]   63         | 4          |  meta           
INFO 01-06 17:11:03.904187.904187 lmp.py:627]   33         | 5          |  meta           
INFO 01-06 17:11:03.904837.904837 lmp.py:627]   42         | 5          |  cuda:1         
INFO 01-06 17:11:03.904725.904725 lmp.py:627]   44         | 5          |  meta           
INFO 01-06 17:11:03.904375.904375 lmp.py:627]   3          | 6          |  cuda:1         
INFO 01-06 17:11:03.904786.904786 lmp.py:627]   12         | 6          |  cuda:1         
INFO 01-06 17:11:03.904628.904628 lmp.py:627]   25         | 7          |  meta           
DEBUG 01-06 17:11:03.904756.904756 mlpmodule.py:664]  experts func einsum cost 0.02856898307800293 s
INFO 01-06 17:11:03.904844.904844 lmp.py:627]   32         | 7          |  cuda:1         
INFO 01-06 17:11:03.904088.904088 lmp.py:627]   34         | 7          |  cuda:1         
INFO 01-06 17:11:03.904645.904645 lmp.py:627]   40         | 7          |  meta           
INFO 01-06 17:11:03.904626.904626 lmp.py:627]   15         | 8          |  cuda:1         
INFO 01-06 17:11:03.905130.905130 lmp.py:627]   46         | 8          |  cuda:1         
INFO 01-06 17:11:03.905396.905396 lmp.py:627]   54         | 9          |  cuda:1         
INFO 01-06 17:11:03.905900.905900 lmp.py:627]   24         | 10         |  cuda:1         
INFO 01-06 17:11:03.905881.905881 lmp.py:627]   41         | 10         |  cuda:1         
INFO 01-06 17:11:03.905338.905338 lmp.py:627]   59         | 10         |  cuda:1         
INFO 01-06 17:11:03.905842.905842 lmp.py:627]   4          | 11         |  cuda:1         
INFO 01-06 17:11:03.905346.905346 lmp.py:627]   48         | 11         |  cuda:1         
INFO 01-06 17:11:03.905897.905897 lmp.py:628] ============================================================
INFO 01-06 17:11:03.905897.905897 lmp.py:628] 
INFO 01-06 17:11:03.905315.905315 lmp.py:630] experts_gpu_list: [2, 29, 50, 61, 18, 19, 26, 31, 6, 13, 20, 35, 55, 8, 22, 42, 3, 12, 32, 34, 15, 46, 54, 24, 41, 59, 4, 48] num: 28
INFO 01-06 17:11:03.905726.905726 lmp.py:631] experts_cpu_list: [11, 21, 47, 52, 53, 62, 23, 49, 56, 57, 16, 45, 63, 33, 44, 25, 40] num: 17
INFO 01-06 17:11:03.905297.905297 lmp.py:632] expert_actual_device_map {0: 'cuda:1', 1: 'cuda:1', 2: 'cuda:1', 3: 'cuda:1', 4: 'cuda:1', 5: 'cuda:1', 6: 'cuda:1', 7: 'cuda:1', 8: 'cuda:1', 9: 'cuda:1', 10: 'cuda:1', 11: 'meta', 12: 'cuda:1', 13: 'cuda:1', 14: 'meta', 15: 'cuda:1', 16: 'meta', 17: 'meta', 18: 'cuda:1', 19: 'cuda:1', 20: 'cuda:1', 21: 'meta', 22: 'cuda:1', 23: 'meta', 24: 'cuda:1', 25: 'meta', 26: 'cuda:1', 27: 'meta', 28: 'meta', 29: 'cuda:1', 30: 'cuda:1', 31: 'cuda:1', 32: 'cuda:1', 33: 'meta', 34: 'cuda:1', 35: 'cuda:1', 36: 'cuda:1', 37: 'meta', 38: 'meta', 39: 'meta', 40: 'meta', 41: 'cuda:1', 42: 'cuda:1', 43: 'cuda:1', 44: 'meta', 45: 'meta', 46: 'cuda:1', 47: 'meta', 48: 'cuda:1', 49: 'meta', 50: 'cuda:1', 51: 'meta', 52: 'meta', 53: 'meta', 54: 'cuda:1', 55: 'cuda:1', 56: 'meta', 57: 'meta', 58: 'meta', 59: 'cuda:1', 60: 'meta', 61: 'cuda:1', 62: 'meta', 63: 'meta'}
DEBUG 01-06 17:11:03.905205.905205 cuda_h.py:19] end experts_map_get cost 0.0023965835571289062 seconds
DEBUG 01-06 17:11:03.905367.905367 cuda_h.py:10] start gpu_sexperts
DEBUG 01-06 17:11:03.905094.905094 cuda_h.py:19] end gpu_sexperts cost 0.00031948089599609375 seconds
DEBUG 01-06 17:11:03.905209.905209 cuda_h.py:10] start gpu_experts
DEBUG 01-06 17:11:03.906547.906547 mlpmodule.py:533] gpu group tensors cost 0.0005280971527099609 s
DEBUG 01-06 17:11:03.907742.907742 mlpmodule.py:566] gpu pad cost 0.0014300346374511719 s
DEBUG 01-06 17:11:03.908378.908378 mlpmodule.py:584] gpu group einsum cost 0.0005381107330322266 s
DEBUG 01-06 17:11:03.911681.911681 mlpmodule.py:613] gpu experts func einsum cost 0.005541801452636719 s
DEBUG 01-06 17:11:03.911135.911135 cuda_h.py:19] end gpu_experts cost 0.00567317008972168 seconds
DEBUG 01-06 17:11:03.911983.911983 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-06 17:11:03.911448.911448 lmp.py:661] 
DEBUG 01-06 17:11:03.911448.911448 lmp.py:661]   Computing 17 experts on CPU...
DEBUG 01-06 17:11:03.911854.911854 cuda_h.py:19] end cpu_experts_submit cost 5.14984130859375e-05 seconds
DEBUG 01-06 17:11:03.911219.911219 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-06 17:11:03.919403.919403 mlpmodule.py:706] group tensors cost 0.007938385009765625 s
DEBUG 01-06 17:11:03.921083.921083 mlpmodule.py:744] pad cost 0.0009379386901855469 s
DEBUG 01-06 17:11:03.921133.921133 mlpmodule.py:750] create cpu tensor cost 4.1961669921875e-05 s
DEBUG 01-06 17:11:03.921698.921698 mlpmodule.py:755] move to cpu cost 2.9802322387695312e-05 s
DEBUG 01-06 17:11:03.923928.923928 mlpmodule.py:769] group_w3: shape=torch.Size([17, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=49020928
DEBUG 01-06 17:11:03.923400.923400 mlpmodule.py:770] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-06 17:11:03.924051.924051 mlpmodule.py:775] group_w3 first element: 0.01324462890625
WARNING 01-06 17:11:03.924074.924074 mlpmodule.py:785] start einsum2
DEBUG 01-06 17:11:03.928070.928070 mlpmodule.py:795] group einsum cost 0.007324934005737305 s
DEBUG 01-06 17:11:03.928638.928638 mlpmodule.py:803] cpy2cputensor cost 7.343292236328125e-05 s
DEBUG 01-06 17:11:03.931095.931095 cuda_h.py:19] end wait_cetm_experts cost 0.01955246925354004 seconds
DEBUG 01-06 17:11:03.931082.931082 cuda_h.py:19] end layer_moe_dgenerate_23 cost 0.029514789581298828 seconds
DEBUG 01-06 17:11:03.931287.931287 lmp.py:325] -------------------------------- end decode layer 23 --------------------------------
DEBUG 01-06 17:11:03.931422.931422 lmp.py:298] -------------------------------- start decode layer 24 --------------------------------
DEBUG 01-06 17:11:03.931045.931045 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-06 17:11:03.932143.932143 mlpmodule.py:367] cuda:1 cuda:1
DEBUG 01-06 17:11:03.932981.932981 cuda_h.py:10] start self_attn
cos shape torch.Size([65, 128]) sin shape torch.Size([65, 128]) position_ids tensor([[0]], device='cuda:1')
cos shape torch.Size([1, 1, 1, 128]) sin shape torch.Size([1, 1, 1, 128])
q_embed shape torch.Size([32, 16, 1, 128]) k_embed shape torch.Size([32, 16, 1, 128])
DEBUG 01-06 17:11:03.935745.935745 cuda_h.py:19] end self_attn cost 0.0023393630981445312 seconds
DEBUG 01-06 17:11:03.935743.935743 mlpmodule.py:664]  experts func einsum cost 0.023655414581298828 s
DEBUG 01-06 17:11:03.935666.935666 cuda_h.py:19] end iln_self_attn_paln cost 0.003620147705078125 seconds
DEBUG 01-06 17:11:03.935498.935498 cuda_h.py:10] start layer_moe_dgenerate_24
DEBUG 01-06 17:11:03.935341.935341 cuda_h.py:10] start gate
DEBUG 01-06 17:11:03.936498.936498 cuda_h.py:19] end gate cost 0.0006968975067138672 seconds
DEBUG 01-06 17:11:03.936242.936242 cuda_h.py:10] start experts_map_get
INFO 01-06 17:11:03.936445.936445 lmp.py:609] using loaded check layer: True
INFO 01-06 17:11:03.937555.937555 lmp.py:620] 
INFO 01-06 17:11:03.937555.937555 lmp.py:620] Layer 24 Expert Device Distribution:
INFO 01-06 17:11:03.937603.937603 lmp.py:621]   Active experts: 50 (out of 64 total)
INFO 01-06 17:11:03.937683.937683 lmp.py:622] 
INFO 01-06 17:11:03.937683.937683 lmp.py:622]   Detailed Expert Distribution:
INFO 01-06 17:11:03.937956.937956 lmp.py:623]   Expert ID  | Tokens     | Actual Device  
INFO 01-06 17:11:03.937413.937413 lmp.py:624]   ----------------------------------------------------------------------
INFO 01-06 17:11:03.937017.937017 lmp.py:627]   1          | 1          |  cuda:1         
INFO 01-06 17:11:03.937713.937713 lmp.py:627]   16         | 1          |  meta           
INFO 01-06 17:11:03.937932.937932 lmp.py:627]   18         | 1          |  cuda:1         
INFO 01-06 17:11:03.937913.937913 lmp.py:627]   22         | 1          |  cuda:1         
INFO 01-06 17:11:03.937655.937655 lmp.py:627]   25         | 1          |  meta           
INFO 01-06 17:11:03.937159.937159 lmp.py:627]   26         | 1          |  cuda:1         
INFO 01-06 17:11:03.937663.937663 lmp.py:627]   28         | 1          |  cuda:1         
INFO 01-06 17:11:03.937167.937167 lmp.py:627]   31         | 1          |  cuda:1         
INFO 01-06 17:11:03.937625.937625 lmp.py:627]   33         | 1          |  meta           
INFO 01-06 17:11:03.937606.937606 lmp.py:627]   41         | 1          |  cuda:1         
INFO 01-06 17:11:03.937063.937063 lmp.py:627]   45         | 1          |  meta           
INFO 01-06 17:11:03.937044.937044 lmp.py:627]   48         | 1          |  meta           
INFO 01-06 17:11:03.937310.937310 lmp.py:627]   54         | 1          |  meta           
INFO 01-06 17:11:03.937575.937575 lmp.py:627]   55         | 1          |  meta           
INFO 01-06 17:11:03.937079.937079 lmp.py:627]   61         | 1          |  meta           
INFO 01-06 17:11:03.937583.937583 lmp.py:627]   62         | 1          |  cuda:1         
INFO 01-06 17:11:03.937611.937611 lmp.py:627]   2          | 2          |  cuda:1         
INFO 01-06 17:11:03.937638.937638 lmp.py:627]   11         | 2          |  cuda:1         
INFO 01-06 17:11:03.937095.937095 lmp.py:627]   21         | 2          |  cuda:1         
INFO 01-06 17:11:03.938076.938076 lmp.py:627]   35         | 2          |  meta           
INFO 01-06 17:11:03.938057.938057 lmp.py:627]   38         | 2          |  meta           
INFO 01-06 17:11:03.938515.938515 lmp.py:627]   46         | 2          |  meta           
INFO 01-06 17:11:03.938257.938257 lmp.py:627]   57         | 2          |  cuda:1         
INFO 01-06 17:11:03.938284.938284 lmp.py:627]   15         | 3          |  meta           
INFO 01-06 17:11:03.938550.938550 lmp.py:627]   44         | 3          |  meta           
INFO 01-06 17:11:03.938054.938054 lmp.py:627]   10         | 4          |  cuda:1         
INFO 01-06 17:11:03.938558.938558 lmp.py:627]   12         | 4          |  cuda:1         
INFO 01-06 17:11:03.938824.938824 lmp.py:627]   13         | 4          |  meta           
INFO 01-06 17:11:03.938851.938851 lmp.py:627]   14         | 4          |  cuda:1         
INFO 01-06 17:11:03.938832.938832 lmp.py:627]   29         | 4          |  meta           
INFO 01-06 17:11:03.938812.938812 lmp.py:627]   49         | 4          |  cuda:1         
INFO 01-06 17:11:03.938793.938793 lmp.py:627]   52         | 4          |  cuda:1         
INFO 01-06 17:11:03.938344.938344 lmp.py:627]   60         | 4          |  cuda:1         
INFO 01-06 17:11:03.938609.938609 lmp.py:627]   63         | 4          |  cuda:1         
INFO 01-06 17:11:03.938875.938875 lmp.py:627]   7          | 5          |  cuda:1         
INFO 01-06 17:11:03.938140.938140 lmp.py:627]   27         | 5          |  cuda:1         
INFO 01-06 17:11:03.938406.938406 lmp.py:627]   40         | 5          |  cuda:1         
INFO 01-06 17:11:03.938956.938956 lmp.py:627]   56         | 5          |  meta           
INFO 01-06 17:11:03.938222.938222 lmp.py:627]   6          | 6          |  cuda:1         
INFO 01-06 17:11:03.938249.938249 lmp.py:627]   8          | 6          |  cuda:1         
INFO 01-06 17:11:03.938514.938514 lmp.py:627]   9          | 6          |  meta           
INFO 01-06 17:11:03.938734.938734 lmp.py:627]   39         | 6          |  meta           
INFO 01-06 17:11:03.938191.938191 lmp.py:627]   0          | 7          |  cuda:1         
INFO 01-06 17:11:03.938649.938649 lmp.py:627]   58         | 7          |  cuda:1         
INFO 01-06 17:11:03.938630.938630 lmp.py:627]   20         | 8          |  meta           
INFO 01-06 17:11:03.938372.938372 lmp.py:627]   50         | 8          |  cuda:1         
INFO 01-06 17:11:03.938399.938399 lmp.py:627]   23         | 11         |  cuda:1         
INFO 01-06 17:11:03.938427.938427 lmp.py:627]   32         | 11         |  cuda:1         
INFO 01-06 17:11:03.938692.938692 lmp.py:627]   34         | 11         |  cuda:1         
INFO 01-06 17:11:03.938481.938481 lmp.py:627]   3          | 13         |  cuda:1         
INFO 01-06 17:11:03.938793.938793 lmp.py:628] ============================================================
INFO 01-06 17:11:03.938793.938793 lmp.py:628] 
INFO 01-06 17:11:03.938496.938496 lmp.py:630] experts_gpu_list: [1, 18, 22, 26, 28, 31, 41, 62, 2, 11, 21, 57, 10, 12, 14, 49, 52, 60, 63, 7, 27, 40, 6, 8, 0, 58, 50, 23, 32, 34, 3] num: 31
INFO 01-06 17:11:03.938384.938384 lmp.py:631] experts_cpu_list: [16, 25, 33, 45, 48, 54, 55, 61, 35, 38, 46, 15, 44, 13, 29, 56, 9, 39, 20] num: 19
INFO 01-06 17:11:03.938763.938763 lmp.py:632] expert_actual_device_map {0: 'cuda:1', 1: 'cuda:1', 2: 'cuda:1', 3: 'cuda:1', 4: 'cuda:1', 5: 'cuda:1', 6: 'cuda:1', 7: 'cuda:1', 8: 'cuda:1', 9: 'meta', 10: 'cuda:1', 11: 'cuda:1', 12: 'cuda:1', 13: 'meta', 14: 'cuda:1', 15: 'meta', 16: 'meta', 17: 'cuda:1', 18: 'cuda:1', 19: 'cuda:1', 20: 'meta', 21: 'cuda:1', 22: 'cuda:1', 23: 'cuda:1', 24: 'meta', 25: 'meta', 26: 'cuda:1', 27: 'cuda:1', 28: 'cuda:1', 29: 'meta', 30: 'meta', 31: 'cuda:1', 32: 'cuda:1', 33: 'meta', 34: 'cuda:1', 35: 'meta', 36: 'meta', 37: 'cuda:1', 38: 'meta', 39: 'meta', 40: 'cuda:1', 41: 'cuda:1', 42: 'meta', 43: 'meta', 44: 'meta', 45: 'meta', 46: 'meta', 47: 'meta', 48: 'meta', 49: 'cuda:1', 50: 'cuda:1', 51: 'meta', 52: 'cuda:1', 53: 'cuda:1', 54: 'meta', 55: 'meta', 56: 'meta', 57: 'cuda:1', 58: 'cuda:1', 59: 'meta', 60: 'cuda:1', 61: 'meta', 62: 'cuda:1', 63: 'cuda:1'}
DEBUG 01-06 17:11:03.938949.938949 cuda_h.py:19] end experts_map_get cost 0.0021033287048339844 seconds
DEBUG 01-06 17:11:03.938766.938766 cuda_h.py:10] start gpu_sexperts
DEBUG 01-06 17:11:03.939765.939765 cuda_h.py:19] end gpu_sexperts cost 0.0003123283386230469 seconds
DEBUG 01-06 17:11:03.939687.939687 cuda_h.py:10] start gpu_experts
DEBUG 01-06 17:11:03.939251.939251 mlpmodule.py:533] gpu group tensors cost 0.0005598068237304688 s
DEBUG 01-06 17:11:03.941532.941532 mlpmodule.py:566] gpu pad cost 0.0016341209411621094 s
DEBUG 01-06 17:11:03.942524.942524 mlpmodule.py:584] gpu group einsum cost 0.00047397613525390625 s
DEBUG 01-06 17:11:03.945629.945629 mlpmodule.py:613] gpu experts func einsum cost 0.006102323532104492 s
DEBUG 01-06 17:11:03.945612.945612 cuda_h.py:19] end gpu_experts cost 0.006233692169189453 seconds
DEBUG 01-06 17:11:03.945990.945990 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-06 17:11:03.945746.945746 lmp.py:661] 
DEBUG 01-06 17:11:03.945746.945746 lmp.py:661]   Computing 19 experts on CPU...
DEBUG 01-06 17:11:03.945974.945974 cuda_h.py:19] end cpu_experts_submit cost 6.079673767089844e-05 seconds
DEBUG 01-06 17:11:03.945339.945339 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-06 17:11:03.954911.954911 mlpmodule.py:706] group tensors cost 0.00842905044555664 s
DEBUG 01-06 17:11:03.956747.956747 mlpmodule.py:744] pad cost 0.001190185546875 s
DEBUG 01-06 17:11:03.956195.956195 mlpmodule.py:750] create cpu tensor cost 4.696846008300781e-05 s
DEBUG 01-06 17:11:03.956773.956773 mlpmodule.py:755] move to cpu cost 3.337860107421875e-05 s
DEBUG 01-06 17:11:03.959468.959468 mlpmodule.py:769] group_w3: shape=torch.Size([19, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=54788096
DEBUG 01-06 17:11:03.959934.959934 mlpmodule.py:770] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-06 17:11:03.959817.959817 mlpmodule.py:775] group_w3 first element: 0.0289306640625
WARNING 01-06 17:11:03.959925.959925 mlpmodule.py:785] start einsum2
DEBUG 01-06 17:11:03.964801.964801 mlpmodule.py:795] group einsum cost 0.0076982975006103516 s
DEBUG 01-06 17:11:03.964509.964509 mlpmodule.py:803] cpy2cputensor cost 0.00010895729064941406 s
DEBUG 01-06 17:11:03.966460.966460 cuda_h.py:19] end wait_cetm_experts cost 0.02110433578491211 seconds
DEBUG 01-06 17:11:03.967791.967791 cuda_h.py:19] end layer_moe_dgenerate_24 cost 0.031447649002075195 seconds
DEBUG 01-06 17:11:03.967147.967147 lmp.py:325] -------------------------------- end decode layer 24 --------------------------------
DEBUG 01-06 17:11:03.967407.967407 lmp.py:298] -------------------------------- start decode layer 25 --------------------------------
DEBUG 01-06 17:11:03.967918.967918 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-06 17:11:03.967458.967458 mlpmodule.py:367] cuda:1 cuda:1
DEBUG 01-06 17:11:03.967007.967007 cuda_h.py:10] start self_attn
cos shape torch.Size([65, 128]) sin shape torch.Size([65, 128]) position_ids tensor([[0]], device='cuda:1')
cos shape torch.Size([1, 1, 1, 128]) sin shape torch.Size([1, 1, 1, 128])
q_embed shape torch.Size([32, 16, 1, 128]) k_embed shape torch.Size([32, 16, 1, 128])
DEBUG 01-06 17:11:03.969677.969677 cuda_h.py:19] end self_attn cost 0.0019354820251464844 seconds
DEBUG 01-06 17:11:03.970284.970284 cuda_h.py:19] end iln_self_attn_paln cost 0.0027980804443359375 seconds
DEBUG 01-06 17:11:03.970551.970551 cuda_h.py:10] start layer_moe_dgenerate_25
DEBUG 01-06 17:11:03.970321.970321 cuda_h.py:10] start gate
DEBUG 01-06 17:11:03.971130.971130 cuda_h.py:19] end gate cost 0.0005936622619628906 seconds
DEBUG 01-06 17:11:03.971827.971827 cuda_h.py:10] start experts_map_get
INFO 01-06 17:11:03.971294.971294 lmp.py:609] using loaded check layer: True
INFO 01-06 17:11:03.971975.971975 lmp.py:620] 
INFO 01-06 17:11:03.971975.971975 lmp.py:620] Layer 25 Expert Device Distribution:
DEBUG 01-06 17:11:03.972580.972580 mlpmodule.py:664]  experts func einsum cost 0.026254892349243164 s
INFO 01-06 17:11:03.972238.972238 lmp.py:621]   Active experts: 46 (out of 64 total)
INFO 01-06 17:11:03.972430.972430 lmp.py:622] 
INFO 01-06 17:11:03.972430.972430 lmp.py:622]   Detailed Expert Distribution:
INFO 01-06 17:11:03.972901.972901 lmp.py:623]   Expert ID  | Tokens     | Actual Device  
INFO 01-06 17:11:03.972412.972412 lmp.py:624]   ----------------------------------------------------------------------
INFO 01-06 17:11:03.972015.972015 lmp.py:627]   8          | 1          |  meta           
INFO 01-06 17:11:03.972354.972354 lmp.py:627]   11         | 1          |  cuda:1         
INFO 01-06 17:11:03.972812.972812 lmp.py:627]   14         | 1          |  cuda:1         
INFO 01-06 17:11:03.972793.972793 lmp.py:627]   17         | 1          |  cuda:1         
INFO 01-06 17:11:03.972297.972297 lmp.py:627]   23         | 1          |  meta           
INFO 01-06 17:11:03.972039.972039 lmp.py:627]   28         | 1          |  cuda:1         
INFO 01-06 17:11:03.972497.972497 lmp.py:627]   32         | 1          |  cuda:1         
INFO 01-06 17:11:03.972239.972239 lmp.py:627]   33         | 1          |  meta           
INFO 01-06 17:11:03.972412.972412 lmp.py:627]   41         | 1          |  meta           
INFO 01-06 17:11:03.972347.972347 lmp.py:627]   50         | 1          |  cuda:1         
INFO 01-06 17:11:03.972043.972043 lmp.py:627]   52         | 1          |  cuda:1         
INFO 01-06 17:11:03.972739.972739 lmp.py:627]   3          | 2          |  cuda:1         
INFO 01-06 17:11:03.972481.972481 lmp.py:627]   7          | 2          |  cuda:1         
INFO 01-06 17:11:03.972985.972985 lmp.py:627]   12         | 2          |  cuda:1         
INFO 01-06 17:11:03.972012.972012 lmp.py:627]   30         | 2          |  cuda:1         
INFO 01-06 17:11:03.972278.972278 lmp.py:627]   36         | 2          |  meta           
INFO 01-06 17:11:03.972305.972305 lmp.py:627]   37         | 2          |  cuda:1         
INFO 01-06 17:11:03.972332.972332 lmp.py:627]   45         | 2          |  meta           
INFO 01-06 17:11:03.972836.972836 lmp.py:627]   47         | 2          |  cuda:1         
INFO 01-06 17:11:03.972863.972863 lmp.py:627]   56         | 2          |  cuda:1         
INFO 01-06 17:11:03.972844.972844 lmp.py:627]   1          | 3          |  cuda:1         
INFO 01-06 17:11:03.972063.972063 lmp.py:627]   10         | 3          |  meta           
INFO 01-06 17:11:03.972521.972521 lmp.py:627]   18         | 3          |  meta           
INFO 01-06 17:11:03.972979.972979 lmp.py:627]   29         | 3          |  cuda:1         
INFO 01-06 17:11:03.972244.972244 lmp.py:627]   31         | 3          |  meta           
INFO 01-06 17:11:03.972748.972748 lmp.py:627]   34         | 3          |  cuda:1         
INFO 01-06 17:11:03.972252.972252 lmp.py:627]   48         | 3          |  meta           
INFO 01-06 17:11:03.972518.972518 lmp.py:627]   49         | 3          |  cuda:1         
INFO 01-06 17:11:03.972022.972022 lmp.py:627]   60         | 3          |  cuda:1         
INFO 01-06 17:11:03.973049.973049 lmp.py:627]   4          | 4          |  cuda:1         
INFO 01-06 17:11:03.973315.973315 lmp.py:627]   9          | 4          |  meta           
INFO 01-06 17:11:03.973772.973772 lmp.py:627]   22         | 4          |  meta           
INFO 01-06 17:11:03.973468.973468 lmp.py:627]   53         | 4          |  cuda:1         
INFO 01-06 17:11:03.973688.973688 lmp.py:627]   27         | 5          |  cuda:1         
INFO 01-06 17:11:03.973430.973430 lmp.py:627]   35         | 5          |  cuda:1         
INFO 01-06 17:11:03.973696.973696 lmp.py:627]   62         | 5          |  cuda:1         
INFO 01-06 17:11:03.973961.973961 lmp.py:627]   43         | 6          |  meta           
INFO 01-06 17:11:03.973512.973512 lmp.py:627]   57         | 6          |  cuda:1         
INFO 01-06 17:11:03.973777.973777 lmp.py:627]   6          | 8          |  cuda:1         
INFO 01-06 17:11:03.973043.973043 lmp.py:627]   39         | 8          |  cuda:1         
INFO 01-06 17:11:03.973308.973308 lmp.py:627]   21         | 9          |  meta           
INFO 01-06 17:11:03.973528.973528 lmp.py:627]   0          | 10         |  cuda:1         
INFO 01-06 17:11:03.973508.973508 lmp.py:627]   54         | 12         |  cuda:1         
INFO 01-06 17:11:03.973489.973489 lmp.py:627]   58         | 14         |  cuda:1         
INFO 01-06 17:11:03.973470.973470 lmp.py:627]   63         | 15         |  cuda:1         
INFO 01-06 17:11:03.973736.973736 lmp.py:627]   26         | 17         |  meta           
INFO 01-06 17:11:03.973286.973286 lmp.py:628] ============================================================
INFO 01-06 17:11:03.973286.973286 lmp.py:628] 
INFO 01-06 17:11:03.973989.973989 lmp.py:630] experts_gpu_list: [11, 14, 17, 28, 32, 50, 52, 3, 7, 12, 30, 37, 47, 56, 1, 29, 34, 49, 60, 4, 53, 27, 35, 62, 57, 6, 39, 0, 54, 58, 63] num: 31
INFO 01-06 17:11:03.973400.973400 lmp.py:631] experts_cpu_list: [8, 23, 33, 41, 36, 45, 10, 18, 31, 48, 9, 22, 43, 21, 26] num: 15
INFO 01-06 17:11:03.973540.973540 lmp.py:632] expert_actual_device_map {0: 'cuda:1', 1: 'cuda:1', 2: 'cuda:1', 3: 'cuda:1', 4: 'cuda:1', 5: 'cuda:1', 6: 'cuda:1', 7: 'cuda:1', 8: 'meta', 9: 'meta', 10: 'meta', 11: 'cuda:1', 12: 'cuda:1', 13: 'meta', 14: 'cuda:1', 15: 'cuda:1', 16: 'meta', 17: 'cuda:1', 18: 'meta', 19: 'cuda:1', 20: 'cuda:1', 21: 'meta', 22: 'meta', 23: 'meta', 24: 'meta', 25: 'meta', 26: 'meta', 27: 'cuda:1', 28: 'cuda:1', 29: 'cuda:1', 30: 'cuda:1', 31: 'meta', 32: 'cuda:1', 33: 'meta', 34: 'cuda:1', 35: 'cuda:1', 36: 'meta', 37: 'cuda:1', 38: 'meta', 39: 'cuda:1', 40: 'cuda:1', 41: 'meta', 42: 'meta', 43: 'meta', 44: 'meta', 45: 'meta', 46: 'meta', 47: 'cuda:1', 48: 'meta', 49: 'cuda:1', 50: 'cuda:1', 51: 'meta', 52: 'cuda:1', 53: 'cuda:1', 54: 'cuda:1', 55: 'meta', 56: 'cuda:1', 57: 'cuda:1', 58: 'cuda:1', 59: 'meta', 60: 'cuda:1', 61: 'meta', 62: 'cuda:1', 63: 'cuda:1'}
DEBUG 01-06 17:11:03.973734.973734 cuda_h.py:19] end experts_map_get cost 0.0023148059844970703 seconds
DEBUG 01-06 17:11:03.973942.973942 cuda_h.py:10] start gpu_sexperts
DEBUG 01-06 17:11:03.973086.973086 cuda_h.py:19] end gpu_sexperts cost 0.0003123283386230469 seconds
DEBUG 01-06 17:11:03.973962.973962 cuda_h.py:10] start gpu_experts
DEBUG 01-06 17:11:03.974493.974493 mlpmodule.py:533] gpu group tensors cost 0.0005655288696289062 s
DEBUG 01-06 17:11:03.976607.976607 mlpmodule.py:566] gpu pad cost 0.0015799999237060547 s
DEBUG 01-06 17:11:03.976019.976019 mlpmodule.py:584] gpu group einsum cost 0.0005464553833007812 s
DEBUG 01-06 17:11:03.980672.980672 mlpmodule.py:613] gpu experts func einsum cost 0.006102800369262695 s
DEBUG 01-06 17:11:03.980702.980702 cuda_h.py:19] end gpu_experts cost 0.006238222122192383 seconds
DEBUG 01-06 17:11:03.980458.980458 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-06 17:11:03.980637.980637 lmp.py:661] 
DEBUG 01-06 17:11:03.980637.980637 lmp.py:661]   Computing 15 experts on CPU...
DEBUG 01-06 17:11:03.980520.980520 cuda_h.py:19] end cpu_experts_submit cost 5.3882598876953125e-05 seconds
DEBUG 01-06 17:11:03.980739.980739 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-06 17:11:03.988017.988017 mlpmodule.py:706] group tensors cost 0.0074694156646728516 s
DEBUG 01-06 17:11:03.989867.989867 mlpmodule.py:744] pad cost 0.0008130073547363281 s
DEBUG 01-06 17:11:03.989678.989678 mlpmodule.py:750] create cpu tensor cost 4.029273986816406e-05 s
DEBUG 01-06 17:11:03.989290.989290 mlpmodule.py:755] move to cpu cost 2.956390380859375e-05 s
DEBUG 01-06 17:11:03.991941.991941 mlpmodule.py:769] group_w3: shape=torch.Size([15, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=43253760
DEBUG 01-06 17:11:03.991598.991598 mlpmodule.py:770] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-06 17:11:03.992289.992289 mlpmodule.py:775] group_w3 first element: -0.046875
WARNING 01-06 17:11:03.992013.992013 mlpmodule.py:785] start einsum2
DEBUG 01-06 17:11:03.996934.996934 mlpmodule.py:795] group einsum cost 0.006543397903442383 s
DEBUG 01-06 17:11:03.996907.996907 mlpmodule.py:803] cpy2cputensor cost 0.0001289844512939453 s
DEBUG 01-06 17:11:03.998661.998661 cuda_h.py:19] end wait_cetm_experts cost 0.0181581974029541 seconds
DEBUG 01-06 17:11:03.998952.998952 cuda_h.py:19] end layer_moe_dgenerate_25 cost 0.028557777404785156 seconds
DEBUG 01-06 17:11:03.999348.999348 lmp.py:325] -------------------------------- end decode layer 25 --------------------------------
DEBUG 01-06 17:11:03.999303.999303 lmp.py:298] -------------------------------- start decode layer 26 --------------------------------
DEBUG 01-06 17:11:03.999575.999575 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-06 17:11:03.999731.999731 mlpmodule.py:367] cuda:1 cuda:1
DEBUG 01-06 17:11:03.999525.999525 cuda_h.py:10] start self_attn
cos shape torch.Size([65, 128]) sin shape torch.Size([65, 128]) position_ids tensor([[0]], device='cuda:1')
cos shape torch.Size([1, 1, 1, 128]) sin shape torch.Size([1, 1, 1, 128])
q_embed shape torch.Size([32, 16, 1, 128]) k_embed shape torch.Size([32, 16, 1, 128])
DEBUG 01-06 17:11:04.001454.001454 cuda_h.py:19] end self_attn cost 0.0019540786743164062 seconds
DEBUG 01-06 17:11:04.002147.002147 cuda_h.py:19] end iln_self_attn_paln cost 0.0028083324432373047 seconds
DEBUG 01-06 17:11:04.002275.002275 cuda_h.py:10] start layer_moe_dgenerate_26
DEBUG 01-06 17:11:04.002290.002290 cuda_h.py:10] start gate
DEBUG 01-06 17:11:04.002268.002268 mlpmodule.py:664]  experts func einsum cost 0.021700382232666016 s
DEBUG 01-06 17:11:04.002765.002765 cuda_h.py:19] end gate cost 0.0006806850433349609 seconds
DEBUG 01-06 17:11:04.002378.002378 cuda_h.py:10] start experts_map_get
INFO 01-06 17:11:04.003110.003110 lmp.py:609] using loaded check layer: True
INFO 01-06 17:11:04.003413.003413 lmp.py:620] 
INFO 01-06 17:11:04.003413.003413 lmp.py:620] Layer 26 Expert Device Distribution:
INFO 01-06 17:11:04.003176.003176 lmp.py:621]   Active experts: 50 (out of 64 total)
INFO 01-06 17:11:04.003495.003495 lmp.py:622] 
INFO 01-06 17:11:04.003495.003495 lmp.py:622]   Detailed Expert Distribution:
INFO 01-06 17:11:04.003482.003482 lmp.py:623]   Expert ID  | Tokens     | Actual Device  
INFO 01-06 17:11:04.003655.003655 lmp.py:624]   ----------------------------------------------------------------------
INFO 01-06 17:11:04.003259.003259 lmp.py:627]   3          | 1          |  cuda:1         
INFO 01-06 17:11:04.004193.004193 lmp.py:627]   8          | 1          |  cuda:1         
INFO 01-06 17:11:04.004412.004412 lmp.py:627]   11         | 1          |  meta           
INFO 01-06 17:11:04.004916.004916 lmp.py:627]   16         | 1          |  cuda:1         
INFO 01-06 17:11:04.004659.004659 lmp.py:627]   20         | 1          |  meta           
INFO 01-06 17:11:04.004401.004401 lmp.py:627]   21         | 1          |  cuda:1         
INFO 01-06 17:11:04.004428.004428 lmp.py:627]   24         | 1          |  meta           
INFO 01-06 17:11:04.004363.004363 lmp.py:627]   34         | 1          |  meta           
INFO 01-06 17:11:04.004774.004774 lmp.py:627]   37         | 1          |  meta           
INFO 01-06 17:11:04.004994.004994 lmp.py:627]   39         | 1          |  meta           
INFO 01-06 17:11:04.004213.004213 lmp.py:627]   46         | 1          |  cuda:1         
INFO 01-06 17:11:04.004670.004670 lmp.py:627]   48         | 1          |  meta           
INFO 01-06 17:11:04.004174.004174 lmp.py:627]   50         | 1          |  meta           
INFO 01-06 17:11:04.004678.004678 lmp.py:627]   51         | 1          |  meta           
INFO 01-06 17:11:04.004944.004944 lmp.py:627]   0          | 2          |  cuda:1         
INFO 01-06 17:11:04.004448.004448 lmp.py:627]   1          | 2          |  cuda:1         
INFO 01-06 17:11:04.004714.004714 lmp.py:627]   9          | 2          |  meta           
INFO 01-06 17:11:04.004933.004933 lmp.py:627]   13         | 2          |  cuda:1         
INFO 01-06 17:11:04.004629.004629 lmp.py:627]   15         | 2          |  meta           
INFO 01-06 17:11:04.004822.004822 lmp.py:627]   17         | 2          |  meta           
INFO 01-06 17:11:04.004757.004757 lmp.py:627]   30         | 2          |  meta           
INFO 01-06 17:11:04.004261.004261 lmp.py:627]   44         | 2          |  cuda:1         
INFO 01-06 17:11:04.004765.004765 lmp.py:627]   58         | 2          |  cuda:1         
INFO 01-06 17:11:04.004269.004269 lmp.py:627]   60         | 2          |  cuda:1         
INFO 01-06 17:11:04.004534.004534 lmp.py:627]   63         | 2          |  meta           
INFO 01-06 17:11:04.004800.004800 lmp.py:627]   2          | 3          |  cuda:1         
INFO 01-06 17:11:04.004827.004827 lmp.py:627]   4          | 3          |  cuda:1         
INFO 01-06 17:11:04.004854.004854 lmp.py:627]   23         | 3          |  meta           
INFO 01-06 17:11:04.004120.004120 lmp.py:627]   28         | 3          |  cuda:1         
INFO 01-06 17:11:04.004862.004862 lmp.py:627]   29         | 3          |  meta           
INFO 01-06 17:11:04.004082.004082 lmp.py:627]   33         | 3          |  cuda:1         
INFO 01-06 17:11:04.004301.004301 lmp.py:627]   43         | 3          |  cuda:1         
INFO 01-06 17:11:04.004043.004043 lmp.py:627]   62         | 3          |  meta           
INFO 01-06 17:11:04.004024.004024 lmp.py:627]   5          | 4          |  cuda:1         
INFO 01-06 17:11:04.004290.004290 lmp.py:627]   22         | 4          |  meta           
INFO 01-06 17:11:04.004555.004555 lmp.py:627]   40         | 4          |  cuda:1         
INFO 01-06 17:11:04.004821.004821 lmp.py:627]   18         | 5          |  cuda:1         
INFO 01-06 17:11:04.004325.004325 lmp.py:627]   32         | 5          |  cuda:1         
INFO 01-06 17:11:04.004875.004875 lmp.py:627]   54         | 5          |  cuda:1         
INFO 01-06 17:11:04.004902.004902 lmp.py:627]   56         | 6          |  cuda:1         
INFO 01-06 17:11:04.004168.004168 lmp.py:627]   12         | 7          |  cuda:1         
INFO 01-06 17:11:04.004672.004672 lmp.py:627]   26         | 7          |  cuda:1         
INFO 01-06 17:11:04.004653.004653 lmp.py:627]   31         | 7          |  cuda:1         
INFO 01-06 17:11:04.004661.004661 lmp.py:627]   52         | 7          |  cuda:1         
INFO 01-06 17:11:04.004357.004357 lmp.py:627]   45         | 8          |  cuda:1         
INFO 01-06 17:11:04.004861.004861 lmp.py:627]   27         | 10         |  cuda:1         
INFO 01-06 17:11:04.004126.004126 lmp.py:627]   57         | 10         |  cuda:1         
INFO 01-06 17:11:04.004630.004630 lmp.py:627]   35         | 11         |  cuda:1         
INFO 01-06 17:11:04.005134.005134 lmp.py:627]   47         | 12         |  cuda:1         
INFO 01-06 17:11:04.005161.005161 lmp.py:627]   42         | 20         |  meta           
INFO 01-06 17:11:04.005950.005950 lmp.py:628] ============================================================
INFO 01-06 17:11:04.005950.005950 lmp.py:628] 
INFO 01-06 17:11:04.005653.005653 lmp.py:630] experts_gpu_list: [3, 8, 16, 21, 46, 0, 1, 13, 44, 58, 60, 2, 4, 28, 33, 43, 5, 40, 18, 32, 54, 56, 12, 26, 31, 52, 45, 27, 57, 35, 47] num: 31
INFO 01-06 17:11:04.005780.005780 lmp.py:631] experts_cpu_list: [11, 20, 24, 34, 37, 39, 48, 50, 51, 9, 15, 17, 30, 63, 23, 29, 62, 22, 42] num: 19
INFO 01-06 17:11:04.005158.005158 lmp.py:632] expert_actual_device_map {0: 'cuda:1', 1: 'cuda:1', 2: 'cuda:1', 3: 'cuda:1', 4: 'cuda:1', 5: 'cuda:1', 6: 'cuda:1', 7: 'cuda:1', 8: 'cuda:1', 9: 'meta', 10: 'cuda:1', 11: 'meta', 12: 'cuda:1', 13: 'cuda:1', 14: 'cuda:1', 15: 'meta', 16: 'cuda:1', 17: 'meta', 18: 'cuda:1', 19: 'meta', 20: 'meta', 21: 'cuda:1', 22: 'meta', 23: 'meta', 24: 'meta', 25: 'cuda:1', 26: 'cuda:1', 27: 'cuda:1', 28: 'cuda:1', 29: 'meta', 30: 'meta', 31: 'cuda:1', 32: 'cuda:1', 33: 'cuda:1', 34: 'meta', 35: 'cuda:1', 36: 'meta', 37: 'meta', 38: 'meta', 39: 'meta', 40: 'cuda:1', 41: 'meta', 42: 'meta', 43: 'cuda:1', 44: 'cuda:1', 45: 'cuda:1', 46: 'cuda:1', 47: 'cuda:1', 48: 'meta', 49: 'meta', 50: 'meta', 51: 'meta', 52: 'cuda:1', 53: 'cuda:1', 54: 'cuda:1', 55: 'meta', 56: 'cuda:1', 57: 'cuda:1', 58: 'cuda:1', 59: 'meta', 60: 'cuda:1', 61: 'meta', 62: 'meta', 63: 'meta'}
DEBUG 01-06 17:11:04.005868.005868 cuda_h.py:19] end experts_map_get cost 0.002154111862182617 seconds
DEBUG 01-06 17:11:04.005453.005453 cuda_h.py:10] start gpu_sexperts
DEBUG 01-06 17:11:04.005452.005452 cuda_h.py:19] end gpu_sexperts cost 0.00030994415283203125 seconds
DEBUG 01-06 17:11:04.005904.005904 cuda_h.py:10] start gpu_experts
DEBUG 01-06 17:11:04.006290.006290 mlpmodule.py:533] gpu group tensors cost 0.0005650520324707031 s
DEBUG 01-06 17:11:04.007278.007278 mlpmodule.py:566] gpu pad cost 0.0015859603881835938 s
DEBUG 01-06 17:11:04.008332.008332 mlpmodule.py:584] gpu group einsum cost 0.00035858154296875 s
DEBUG 01-06 17:11:04.011246.011246 mlpmodule.py:613] gpu experts func einsum cost 0.005797624588012695 s
DEBUG 01-06 17:11:04.011700.011700 cuda_h.py:19] end gpu_experts cost 0.005928516387939453 seconds
DEBUG 01-06 17:11:04.011171.011171 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-06 17:11:04.011589.011589 lmp.py:661] 
DEBUG 01-06 17:11:04.011589.011589 lmp.py:661]   Computing 19 experts on CPU...
DEBUG 01-06 17:11:04.011617.011617 cuda_h.py:19] end cpu_experts_submit cost 5.435943603515625e-05 seconds
DEBUG 01-06 17:11:04.011651.011651 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-06 17:11:04.019363.019363 mlpmodule.py:706] group tensors cost 0.007491588592529297 s
DEBUG 01-06 17:11:04.020250.020250 mlpmodule.py:744] pad cost 0.0010113716125488281 s
DEBUG 01-06 17:11:04.021393.021393 mlpmodule.py:750] create cpu tensor cost 4.0531158447265625e-05 s
DEBUG 01-06 17:11:04.021243.021243 mlpmodule.py:755] move to cpu cost 2.9325485229492188e-05 s
DEBUG 01-06 17:11:04.023241.023241 mlpmodule.py:769] group_w3: shape=torch.Size([19, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=54788096
DEBUG 01-06 17:11:04.023184.023184 mlpmodule.py:770] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-06 17:11:04.023596.023596 mlpmodule.py:775] group_w3 first element: 0.04833984375
WARNING 01-06 17:11:04.023374.023374 mlpmodule.py:785] start einsum2
DEBUG 01-06 17:11:04.029660.029660 mlpmodule.py:795] group einsum cost 0.007994651794433594 s
DEBUG 01-06 17:11:04.029732.029732 mlpmodule.py:803] cpy2cputensor cost 0.00015163421630859375 s
DEBUG 01-06 17:11:04.032036.032036 cuda_h.py:19] end wait_cetm_experts cost 0.020488739013671875 seconds
DEBUG 01-06 17:11:04.032197.032197 cuda_h.py:19] end layer_moe_dgenerate_26 cost 0.030649423599243164 seconds
DEBUG 01-06 17:11:04.033343.033343 lmp.py:325] -------------------------------- end decode layer 26 --------------------------------
DEBUG 01-06 17:11:04.033948.033948 lmp.py:298] -------------------------------- start decode layer 27 --------------------------------
DEBUG 01-06 17:11:04.033433.033433 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-06 17:11:04.033345.033345 mlpmodule.py:367] cuda:1 cuda:1
DEBUG 01-06 17:11:04.033879.033879 cuda_h.py:10] start self_attn
cos shape torch.Size([65, 128]) sin shape torch.Size([65, 128]) position_ids tensor([[0]], device='cuda:1')
cos shape torch.Size([1, 1, 1, 128]) sin shape torch.Size([1, 1, 1, 128])
q_embed shape torch.Size([32, 16, 1, 128]) k_embed shape torch.Size([32, 16, 1, 128])
DEBUG 01-06 17:11:04.036900.036900 cuda_h.py:19] end self_attn cost 0.0026874542236328125 seconds
DEBUG 01-06 17:11:04.036365.036365 mlpmodule.py:664]  experts func einsum cost 0.024955034255981445 s
DEBUG 01-06 17:11:04.037810.037810 cuda_h.py:19] end iln_self_attn_paln cost 0.0040738582611083984 seconds
DEBUG 01-06 17:11:04.037887.037887 cuda_h.py:10] start layer_moe_dgenerate_27
DEBUG 01-06 17:11:04.037406.037406 cuda_h.py:10] start gate
DEBUG 01-06 17:11:04.038918.038918 cuda_h.py:19] end gate cost 0.0006163120269775391 seconds
DEBUG 01-06 17:11:04.038569.038569 cuda_h.py:10] start experts_map_get
INFO 01-06 17:11:04.038162.038162 lmp.py:609] using loaded check layer: True
INFO 01-06 17:11:04.038835.038835 lmp.py:620] 
INFO 01-06 17:11:04.038835.038835 lmp.py:620] Layer 27 Expert Device Distribution:
INFO 01-06 17:11:04.039836.039836 lmp.py:621]   Active experts: 44 (out of 64 total)
INFO 01-06 17:11:04.039632.039632 lmp.py:622] 
INFO 01-06 17:11:04.039632.039632 lmp.py:622]   Detailed Expert Distribution:
INFO 01-06 17:11:04.039858.039858 lmp.py:623]   Expert ID  | Tokens     | Actual Device  
INFO 01-06 17:11:04.039031.039031 lmp.py:624]   ----------------------------------------------------------------------
INFO 01-06 17:11:04.039919.039919 lmp.py:627]   8          | 1          |  cuda:1         
INFO 01-06 17:11:04.039853.039853 lmp.py:627]   9          | 1          |  cuda:1         
INFO 01-06 17:11:04.039834.039834 lmp.py:627]   11         | 1          |  cuda:1         
INFO 01-06 17:11:04.039338.039338 lmp.py:627]   31         | 1          |  meta           
INFO 01-06 17:11:04.039842.039842 lmp.py:627]   33         | 1          |  meta           
INFO 01-06 17:11:04.039869.039869 lmp.py:627]   35         | 1          |  cuda:1         
INFO 01-06 17:11:04.039135.039135 lmp.py:627]   38         | 1          |  meta           
INFO 01-06 17:11:04.039639.039639 lmp.py:627]   41         | 1          |  cuda:1         
INFO 01-06 17:11:04.039858.039858 lmp.py:627]   53         | 1          |  cuda:1         
INFO 01-06 17:11:04.039077.039077 lmp.py:627]   57         | 1          |  meta           
INFO 01-06 17:11:04.039774.039774 lmp.py:627]   5          | 2          |  cuda:1         
INFO 01-06 17:11:04.039278.039278 lmp.py:627]   7          | 2          |  cuda:1         
INFO 01-06 17:11:04.039305.039305 lmp.py:627]   12         | 2          |  meta           
INFO 01-06 17:11:04.039809.039809 lmp.py:627]   15         | 2          |  cuda:1         
INFO 01-06 17:11:04.039074.039074 lmp.py:627]   18         | 2          |  meta           
INFO 01-06 17:11:04.039340.039340 lmp.py:627]   25         | 2          |  cuda:1         
INFO 01-06 17:11:04.039605.039605 lmp.py:627]   43         | 2          |  meta           
INFO 01-06 17:11:04.039348.039348 lmp.py:627]   47         | 2          |  meta           
INFO 01-06 17:11:04.039613.039613 lmp.py:627]   49         | 2          |  meta           
INFO 01-06 17:11:04.039071.039071 lmp.py:627]   54         | 2          |  meta           
INFO 01-06 17:11:04.039290.039290 lmp.py:627]   55         | 2          |  meta           
INFO 01-06 17:11:04.039271.039271 lmp.py:627]   60         | 2          |  cuda:1         
INFO 01-06 17:11:04.039729.039729 lmp.py:627]   63         | 2          |  cuda:1         
INFO 01-06 17:11:04.039471.039471 lmp.py:627]   10         | 3          |  cuda:1         
INFO 01-06 17:11:04.039498.039498 lmp.py:627]   45         | 3          |  meta           
INFO 01-06 17:11:04.039287.039287 lmp.py:627]   46         | 3          |  cuda:1         
INFO 01-06 17:11:04.039791.039791 lmp.py:627]   52         | 3          |  cuda:1         
INFO 01-06 17:11:04.039818.039818 lmp.py:627]   1          | 4          |  cuda:1         
INFO 01-06 17:11:04.039084.039084 lmp.py:627]   24         | 4          |  meta           
INFO 01-06 17:11:04.039303.039303 lmp.py:627]   30         | 4          |  cuda:1         
INFO 01-06 17:11:04.039284.039284 lmp.py:627]   39         | 4          |  cuda:1         
INFO 01-06 17:11:04.039265.039265 lmp.py:627]   19         | 5          |  cuda:1         
INFO 01-06 17:11:04.039961.039961 lmp.py:627]   20         | 6          |  meta           
INFO 01-06 17:11:04.039226.039226 lmp.py:627]   44         | 6          |  meta           
INFO 01-06 17:11:04.039492.039492 lmp.py:627]   4          | 7          |  cuda:1         
INFO 01-06 17:11:04.039519.039519 lmp.py:627]   29         | 7          |  cuda:1         
INFO 01-06 17:11:04.039546.039546 lmp.py:627]   16         | 8          |  cuda:1         
INFO 01-06 17:11:04.039335.039335 lmp.py:627]   58         | 8          |  cuda:1         
INFO 01-06 17:11:04.039601.039601 lmp.py:627]   21         | 10         |  cuda:1         
INFO 01-06 17:11:04.039582.039582 lmp.py:627]   22         | 11         |  cuda:1         
INFO 01-06 17:11:04.039086.039086 lmp.py:627]   59         | 12         |  meta           
INFO 01-06 17:11:04.039305.039305 lmp.py:627]   13         | 15         |  meta           
INFO 01-06 17:11:04.039286.039286 lmp.py:627]   56         | 15         |  meta           
INFO 01-06 17:11:04.040790.040790 lmp.py:627]   62         | 18         |  cuda:1         
INFO 01-06 17:11:04.040578.040578 lmp.py:628] ============================================================
INFO 01-06 17:11:04.040578.040578 lmp.py:628] 
INFO 01-06 17:11:04.040374.040374 lmp.py:630] experts_gpu_list: [8, 9, 11, 35, 41, 53, 5, 7, 15, 25, 60, 63, 10, 46, 52, 1, 30, 39, 19, 4, 29, 16, 58, 21, 22, 62] num: 26
INFO 01-06 17:11:04.040308.040308 lmp.py:631] experts_cpu_list: [31, 33, 38, 57, 12, 18, 43, 47, 49, 54, 55, 45, 24, 20, 44, 59, 13, 56] num: 18
INFO 01-06 17:11:04.040495.040495 lmp.py:632] expert_actual_device_map {0: 'cuda:1', 1: 'cuda:1', 2: 'cuda:1', 3: 'cuda:1', 4: 'cuda:1', 5: 'cuda:1', 6: 'cuda:1', 7: 'cuda:1', 8: 'cuda:1', 9: 'cuda:1', 10: 'cuda:1', 11: 'cuda:1', 12: 'meta', 13: 'meta', 14: 'cuda:1', 15: 'cuda:1', 16: 'cuda:1', 17: 'meta', 18: 'meta', 19: 'cuda:1', 20: 'meta', 21: 'cuda:1', 22: 'cuda:1', 23: 'meta', 24: 'meta', 25: 'cuda:1', 26: 'meta', 27: 'cuda:1', 28: 'cuda:1', 29: 'cuda:1', 30: 'cuda:1', 31: 'meta', 32: 'cuda:1', 33: 'meta', 34: 'cuda:1', 35: 'cuda:1', 36: 'meta', 37: 'cuda:1', 38: 'meta', 39: 'cuda:1', 40: 'meta', 41: 'cuda:1', 42: 'meta', 43: 'meta', 44: 'meta', 45: 'meta', 46: 'cuda:1', 47: 'meta', 48: 'meta', 49: 'meta', 50: 'cuda:1', 51: 'meta', 52: 'cuda:1', 53: 'cuda:1', 54: 'meta', 55: 'meta', 56: 'meta', 57: 'meta', 58: 'cuda:1', 59: 'meta', 60: 'cuda:1', 61: 'meta', 62: 'cuda:1', 63: 'cuda:1'}
DEBUG 01-06 17:11:04.040443.040443 cuda_h.py:19] end experts_map_get cost 0.0019452571868896484 seconds
DEBUG 01-06 17:11:04.040605.040605 cuda_h.py:10] start gpu_sexperts
DEBUG 01-06 17:11:04.040215.040215 cuda_h.py:19] end gpu_sexperts cost 0.00037360191345214844 seconds
DEBUG 01-06 17:11:04.040713.040713 cuda_h.py:10] start gpu_experts
DEBUG 01-06 17:11:04.041143.041143 mlpmodule.py:533] gpu group tensors cost 0.0004925727844238281 s
DEBUG 01-06 17:11:04.042269.042269 mlpmodule.py:566] gpu pad cost 0.0013437271118164062 s
DEBUG 01-06 17:11:04.043115.043115 mlpmodule.py:584] gpu group einsum cost 0.0004813671112060547 s
DEBUG 01-06 17:11:04.046972.046972 mlpmodule.py:613] gpu experts func einsum cost 0.0052793025970458984 s
DEBUG 01-06 17:11:04.046578.046578 cuda_h.py:19] end gpu_experts cost 0.0054166316986083984 seconds
DEBUG 01-06 17:11:04.046003.046003 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-06 17:11:04.046328.046328 lmp.py:661] 
DEBUG 01-06 17:11:04.046328.046328 lmp.py:661]   Computing 18 experts on CPU...
DEBUG 01-06 17:11:04.046701.046701 cuda_h.py:19] end cpu_experts_submit cost 6.29425048828125e-05 seconds
DEBUG 01-06 17:11:04.046881.046881 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-06 17:11:04.050724.050724 mlpmodule.py:706] group tensors cost 0.003641843795776367 s
DEBUG 01-06 17:11:04.051478.051478 mlpmodule.py:744] pad cost 0.0011470317840576172 s
DEBUG 01-06 17:11:04.051548.051548 mlpmodule.py:750] create cpu tensor cost 4.7206878662109375e-05 s
DEBUG 01-06 17:11:04.052557.052557 mlpmodule.py:755] move to cpu cost 3.361701965332031e-05 s
DEBUG 01-06 17:11:04.054720.054720 mlpmodule.py:769] group_w3: shape=torch.Size([18, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=51904512
DEBUG 01-06 17:11:04.054670.054670 mlpmodule.py:770] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-06 17:11:04.054857.054857 mlpmodule.py:775] group_w3 first element: 0.038330078125
WARNING 01-06 17:11:04.054955.054955 mlpmodule.py:785] start einsum2
DEBUG 01-06 17:11:04.058708.058708 mlpmodule.py:795] group einsum cost 0.006418466567993164 s
DEBUG 01-06 17:11:04.058793.058793 mlpmodule.py:803] cpy2cputensor cost 9.393692016601562e-05 s
DEBUG 01-06 17:11:04.061954.061954 cuda_h.py:19] end wait_cetm_experts cost 0.01496434211730957 seconds
DEBUG 01-06 17:11:04.061139.061139 cuda_h.py:19] end layer_moe_dgenerate_27 cost 0.024277448654174805 seconds
DEBUG 01-06 17:11:04.061158.061158 lmp.py:325] -------------------------------- end decode layer 27 --------------------------------
DEBUG 01-06 17:11:04.061212.061212 cuda_h.py:10] start async_wait_layer_loaded_to_gpu
DEBUG 01-06 17:11:04.062298.062298 cuda_h.py:19] end async_wait_layer_loaded_to_gpu cost 0.00016021728515625 seconds
DEBUG 01-06 17:11:04.062840.062840 cuda_h.py:19] end decode_layer cost 1.1532516479492188 seconds
DEBUG 01-06 17:11:04.134874.134874 mlpmodule.py:664]  experts func einsum cost 0.08823561668395996 s
DEBUG 01-06 17:11:06.254729.254729 cuda_h.py:10] start generate_input_ids
generate input ids cost 0.09308290481567383 s
DEBUG 01-06 17:11:06.589735.589735 cuda_h.py:19] end generate_input_ids cost 0.3274881839752197 seconds
DEBUG 01-06 17:11:06.589441.589441 cuda_h.py:10] start init_cache
DEBUG 01-06 17:11:06.590268.590268 cuda_h.py:19] end init_cache cost 9.870529174804688e-05 seconds
DEBUG 01-06 17:11:09.127607.127607 cuda_h.py:10] start init_weights
DEBUG 01-06 17:11:09.128884.128884 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 17:11:09.129737.129737 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 17:11:09.131705.131705 cuda_h.py:19] end allocate_cuda_memory cost 0.0020685195922851562 seconds
DEBUG 01-06 17:11:09.131536.131536 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 17:11:09.131153.131153 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 17:11:09.131188.131188 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 17:11:09.131129.131129 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 6fb1ff3e-d1f6-4290-8ee6-5634cab7ae58
DEBUG 01-06 17:11:09.131013.131013 client.py:106] call stub.LoadModelAsync
INFO 01-06 17:11:09.133677.133677 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 6fb1ff3e-d1f6-4290-8ee6-5634cab7ae58
DEBUG 01-06 17:11:09.133413.133413 cuda_h.py:19] end load_into_gpu_async cost 0.0020551681518554688 seconds
DEBUG 01-06 17:11:09.133845.133845 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 17:11:09.133583.133583 cuda_h.py:19] end restore_tensors2 cost 6.008148193359375e-05 seconds
DEBUG 01-06 17:11:09.133524.133524 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.004744529724121094 seconds
INFO 01-06 17:11:09.134799.134799 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 6fb1ff3e-d1f6-4290-8ee6-5634cab7ae58
INFO 01-06 17:11:09.213109.213109 client.py:127] Model loaded
DEBUG 01-06 17:11:09.213220.213220 cuda_h.py:10] start load_qkvogns_weight_l_0
DEBUG 01-06 17:11:09.213575.213575 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 17:11:09.213553.213553 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 17:11:09.214627.214627 cuda_h.py:19] end allocate_cuda_memory cost 0.00035309791564941406 seconds
DEBUG 01-06 17:11:09.214579.214579 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 17:11:09.214688.214688 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 17:11:09.214717.214717 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 17:11:09.214759.214759 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, bee84158-f850-4b72-ac3d-903d9a8a4acc
DEBUG 01-06 17:11:09.214937.214937 client.py:106] call stub.LoadModelAsync
INFO 01-06 17:11:09.216393.216393 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, bee84158-f850-4b72-ac3d-903d9a8a4acc
DEBUG 01-06 17:11:09.216916.216916 cuda_h.py:19] end load_into_gpu_async cost 0.002054452896118164 seconds
DEBUG 01-06 17:11:09.216031.216031 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 17:11:09.216133.216133 cuda_h.py:19] end restore_tensors2 cost 0.0002040863037109375 seconds
DEBUG 01-06 17:11:09.216031.216031 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0032401084899902344 seconds
INFO 01-06 17:11:09.216179.216179 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, bee84158-f850-4b72-ac3d-903d9a8a4acc
INFO 01-06 17:11:09.231257.231257 client.py:127] Model loaded
DEBUG 01-06 17:11:09.233949.233949 cuda_h.py:19] end load_qkvogns_weight_l_0 cost 0.019500255584716797 seconds
DEBUG 01-06 17:11:09.233649.233649 cuda_h.py:19] end init_weights cost 0.1047515869140625 seconds
DEBUG 01-06 17:11:09.233989.233989 cuda_h.py:10] start copy_emodel
DEBUG 01-06 17:11:10.015316.015316 cuda_h.py:19] end copy_emodel cost 0.7821826934814453 seconds
DEBUG 01-06 17:11:10.016975.016975 cuda_h.py:10] start init_hmv
DEBUG 01-06 17:11:10.159119.159119 mlpmodule.py:207] restore_hm_state_dict2model loaded 5265 expert tensors (including shared_experts) for Deepseek model
DEBUG 01-06 17:11:10.160231.160231 cuda_h.py:19] end init_hmv cost 0.14346599578857422 seconds
DEBUG 01-06 17:11:10.160014.160014 cuda_h.py:10] start init_inputs_tokens
DEBUG 01-06 17:11:10.160330.160330 cuda_h.py:19] end init_inputs_tokens cost 0.00030112266540527344 seconds
DEBUG 01-06 17:11:10.160100.160100 cuda_h.py:10] start multi_layer
DEBUG 01-06 17:11:10.160147.160147 lmp.py:176] -------------------------------- start layer 0 --------------------------------
DEBUG 01-06 17:11:10.160651.160651 cuda_h.py:10] start start_load_qkvogn_s_weight_l_1
DEBUG 01-06 17:11:10.160706.160706 cuda_h.py:10] start start_load_qkvogn_s_weight_l_1
DEBUG 01-06 17:11:10.160900.160900 cuda_h.py:19] end start_load_qkvogn_s_weight_l_1 cost 4.57763671875e-05 seconds
DEBUG 01-06 17:11:10.160696.160696 cuda_h.py:19] end start_load_qkvogn_s_weight_l_1 cost 7.748603820800781e-05 seconds
DEBUG 01-06 17:11:10.160531.160531 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-06 17:11:10.160082.160082 mlpmodule.py:367] cuda:1 cuda:1
DEBUG 01-06 17:11:10.160192.160192 cuda_h.py:10] start sllm_worker_task
DEBUG 01-06 17:11:10.161937.161937 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 17:11:10.161253.161253 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 17:11:10.161096.161096 cuda_h.py:19] end allocate_cuda_memory cost 0.00036072731018066406 seconds
DEBUG 01-06 17:11:10.161579.161579 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 17:11:10.162398.162398 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 17:11:10.162211.162211 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 17:11:10.162254.162254 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 1ece1d25-8fb9-4c83-ba4e-238888c630bd
DEBUG 01-06 17:11:10.162944.162944 client.py:106] call stub.LoadModelAsync
DEBUG 01-06 17:11:10.162080.162080 cuda_h.py:10] start self_attn
INFO 01-06 17:11:10.164665.164665 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 1ece1d25-8fb9-4c83-ba4e-238888c630bd
DEBUG 01-06 17:11:10.164684.164684 cuda_h.py:19] end load_into_gpu_async cost 0.002603292465209961 seconds
DEBUG 01-06 17:11:10.164475.164475 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 17:11:10.164974.164974 cuda_h.py:19] end restore_tensors2 cost 0.00016188621520996094 seconds
DEBUG 01-06 17:11:10.165421.165421 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0038809776306152344 seconds
INFO 01-06 17:11:10.165925.165925 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 1ece1d25-8fb9-4c83-ba4e-238888c630bd
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-06 17:11:10.167212.167212 cuda_h.py:19] end self_attn cost 0.005029916763305664 seconds
DEBUG 01-06 17:11:10.168182.168182 cuda_h.py:19] end iln_self_attn_paln cost 0.0075435638427734375 seconds
DEBUG 01-06 17:11:10.168196.168196 cuda_h.py:10] start dense_mlp
INFO 01-06 17:11:10.173955.173955 client.py:127] Model loaded
DEBUG 01-06 17:11:10.174070.174070 cuda_h.py:19] end sllm_worker_task cost 0.013259649276733398 seconds
DEBUG 01-06 17:11:10.174429.174429 cuda_h.py:19] end dense_mlp cost 0.006308078765869141 seconds
DEBUG 01-06 17:11:10.174096.174096 lmp.py:220] -------------------------------- end layer 0 --------------------------------
DEBUG 01-06 17:11:10.174634.174634 lmp.py:176] -------------------------------- start layer 1 --------------------------------
DEBUG 01-06 17:11:10.174290.174290 cuda_h.py:10] start start_load_qkvogn_s_weight_l_2
DEBUG 01-06 17:11:10.174007.174007 cuda_h.py:10] start start_load_qkvogn_s_weight_l_2
DEBUG 01-06 17:11:10.174181.174181 cuda_h.py:19] end start_load_qkvogn_s_weight_l_2 cost 2.6226043701171875e-05 seconds
DEBUG 01-06 17:11:10.174321.174321 cuda_h.py:19] end start_load_qkvogn_s_weight_l_2 cost 6.318092346191406e-05 seconds
DEBUG 01-06 17:11:10.174878.174878 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-06 17:11:10.175430.175430 cuda_h.py:10] start sllm_worker_task
DEBUG 01-06 17:11:10.175912.175912 mlpmodule.py:367] cuda:1 cuda:1
DEBUG 01-06 17:11:10.175377.175377 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 17:11:10.175894.175894 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 17:11:10.175464.175464 cuda_h.py:19] end allocate_cuda_memory cost 0.0003001689910888672 seconds
DEBUG 01-06 17:11:10.176417.176417 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 17:11:10.176851.176851 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 17:11:10.176067.176067 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 17:11:10.176615.176615 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, eaf7002c-b63a-44a5-ae26-43cf58da837f
DEBUG 01-06 17:11:10.176277.176277 client.py:106] call stub.LoadModelAsync
DEBUG 01-06 17:11:10.176353.176353 cuda_h.py:10] start self_attn
INFO 01-06 17:11:10.178179.178179 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, eaf7002c-b63a-44a5-ae26-43cf58da837f
DEBUG 01-06 17:11:10.178945.178945 cuda_h.py:19] end load_into_gpu_async cost 0.0022056102752685547 seconds
DEBUG 01-06 17:11:10.178697.178697 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 17:11:10.178671.178671 cuda_h.py:19] end restore_tensors2 cost 0.00014400482177734375 seconds
DEBUG 01-06 17:11:10.178205.178205 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0033898353576660156 seconds
INFO 01-06 17:11:10.178534.178534 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, eaf7002c-b63a-44a5-ae26-43cf58da837f
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-06 17:11:10.180662.180662 cuda_h.py:19] end self_attn cost 0.0036878585815429688 seconds
DEBUG 01-06 17:11:10.180693.180693 cuda_h.py:19] end iln_self_attn_paln cost 0.00590205192565918 seconds
DEBUG 01-06 17:11:10.180934.180934 cuda_h.py:10] start layer_moe_generate_1
DEBUG 01-06 17:11:10.181472.181472 cuda_h.py:10] start gate
DEBUG 01-06 17:11:10.181547.181547 cuda_h.py:19] end gate cost 0.0008227825164794922 seconds
DEBUG 01-06 17:11:10.181569.181569 cuda_h.py:10] start experts_map_get
DEBUG 01-06 17:11:10.182851.182851 lmp.py:403] 
DEBUG 01-06 17:11:10.182851.182851 lmp.py:403] Expert Token Distribution & Device Allocation:
DEBUG 01-06 17:11:10.182560.182560 lmp.py:404]   Total experts: 64
DEBUG 01-06 17:11:10.182594.182594 lmp.py:405]   CPU experts: 32 (50%)
DEBUG 01-06 17:11:10.182814.182814 lmp.py:406]   GPU experts: 32 (50%)
DEBUG 01-06 17:11:10.182887.182887 lmp.py:407] 
DEBUG 01-06 17:11:10.182887.182887 lmp.py:407]   Expert ID | Tokens | Device
DEBUG 01-06 17:11:10.182245.182245 lmp.py:408]   -----------------------------------
DEBUG 01-06 17:11:10.182802.182802 lmp.py:414]   Expert 25 |     64 | CPU
DEBUG 01-06 17:11:10.182161.182161 lmp.py:414]   Expert 54 |     67 | CPU
DEBUG 01-06 17:11:10.182519.182519 lmp.py:414]   Expert  3 |     68 | CPU
DEBUG 01-06 17:11:10.182685.182685 lmp.py:414]   Expert 31 |     72 | CPU
DEBUG 01-06 17:11:10.182904.182904 lmp.py:414]   Expert 55 |     72 | CPU
DEBUG 01-06 17:11:10.182262.182262 lmp.py:414]   Expert 62 |     87 | CPU
DEBUG 01-06 17:11:10.182382.182382 lmp.py:414]   Expert 18 |     88 | CPU
DEBUG 01-06 17:11:10.182264.182264 lmp.py:414]   Expert 52 |     98 | CPU
DEBUG 01-06 17:11:10.182622.182622 lmp.py:414]   Expert 22 |    100 | CPU
DEBUG 01-06 17:11:10.182742.182742 lmp.py:414]   Expert 47 |    104 | CPU
DEBUG 01-06 17:11:10.182100.182100 lmp.py:414]   Expert  0 |    113 | CPU
DEBUG 01-06 17:11:10.182969.182969 lmp.py:414]   Expert 37 |    117 | CPU
DEBUG 01-06 17:11:10.182950.182950 lmp.py:414]   Expert 27 |    121 | CPU
DEBUG 01-06 17:11:10.182593.182593 lmp.py:414]   Expert 32 |    123 | CPU
DEBUG 01-06 17:11:10.182759.182759 lmp.py:414]   Expert 41 |    130 | CPU
DEBUG 01-06 17:11:10.182163.182163 lmp.py:414]   Expert 44 |    131 | CPU
DEBUG 01-06 17:11:10.182330.182330 lmp.py:414]   Expert 28 |    136 | CPU
DEBUG 01-06 17:11:10.182496.182496 lmp.py:414]   Expert 13 |    138 | CPU
DEBUG 01-06 17:11:10.182423.182423 lmp.py:414]   Expert 58 |    140 | CPU
DEBUG 01-06 17:11:10.182590.182590 lmp.py:414]   Expert 60 |    144 | CPU
DEBUG 01-06 17:11:10.182517.182517 lmp.py:414]   Expert 43 |    147 | CPU
DEBUG 01-06 17:11:10.182207.182207 lmp.py:414]   Expert  1 |    150 | CPU
DEBUG 01-06 17:11:10.182611.182611 lmp.py:414]   Expert 38 |    153 | CPU
DEBUG 01-06 17:11:10.182208.182208 lmp.py:414]   Expert 49 |    154 | CPU
DEBUG 01-06 17:11:10.182043.182043 lmp.py:414]   Expert 51 |    155 | CPU
DEBUG 01-06 17:11:10.182686.182686 lmp.py:414]   Expert 34 |    161 | CPU
DEBUG 01-06 17:11:10.182759.182759 lmp.py:414]   Expert 35 |    164 | CPU
DEBUG 01-06 17:11:10.182925.182925 lmp.py:414]   Expert 36 |    168 | CPU
DEBUG 01-06 17:11:10.182092.182092 lmp.py:414]   Expert 11 |    170 | CPU
DEBUG 01-06 17:11:10.182258.182258 lmp.py:414]   Expert 17 |    170 | CPU
DEBUG 01-06 17:11:10.182947.182947 lmp.py:414]   Expert 59 |    174 | CPU
DEBUG 01-06 17:11:10.182875.182875 lmp.py:414]   Expert 10 |    180 | CPU
DEBUG 01-06 17:11:10.183279.183279 lmp.py:414]   Expert 20 |    182 | GPU
DEBUG 01-06 17:11:10.183684.183684 lmp.py:414]   Expert  2 |    186 | GPU
DEBUG 01-06 17:11:10.183519.183519 lmp.py:414]   Expert 39 |    189 | GPU
DEBUG 01-06 17:11:10.183877.183877 lmp.py:414]   Expert 33 |    197 | GPU
DEBUG 01-06 17:11:10.183712.183712 lmp.py:414]   Expert 12 |    198 | GPU
DEBUG 01-06 17:11:10.183117.183117 lmp.py:414]   Expert 21 |    198 | GPU
DEBUG 01-06 17:11:10.183283.183283 lmp.py:414]   Expert 48 |    198 | GPU
DEBUG 01-06 17:11:10.183449.183449 lmp.py:414]   Expert 15 |    199 | GPU
DEBUG 01-06 17:11:10.183615.183615 lmp.py:414]   Expert 53 |    204 | GPU
DEBUG 01-06 17:11:10.183543.183543 lmp.py:414]   Expert 19 |    220 | GPU
DEBUG 01-06 17:11:10.183709.183709 lmp.py:414]   Expert 26 |    221 | GPU
DEBUG 01-06 17:11:10.183875.183875 lmp.py:414]   Expert 30 |    221 | GPU
DEBUG 01-06 17:11:10.183280.183280 lmp.py:414]   Expert 45 |    221 | GPU
DEBUG 01-06 17:11:10.183446.183446 lmp.py:414]   Expert  5 |    227 | GPU
DEBUG 01-06 17:11:10.183612.183612 lmp.py:414]   Expert  4 |    229 | GPU
DEBUG 01-06 17:11:10.183778.183778 lmp.py:414]   Expert 24 |    229 | GPU
DEBUG 01-06 17:11:10.183375.183375 lmp.py:414]   Expert 42 |    242 | GPU
DEBUG 01-06 17:11:10.183448.183448 lmp.py:414]   Expert 50 |    245 | GPU
DEBUG 01-06 17:11:10.183045.183045 lmp.py:414]   Expert 29 |    254 | GPU
DEBUG 01-06 17:11:10.183450.183450 lmp.py:414]   Expert 56 |    262 | GPU
DEBUG 01-06 17:11:10.183854.183854 lmp.py:414]   Expert 61 |    270 | GPU
DEBUG 01-06 17:11:10.183782.183782 lmp.py:414]   Expert  8 |    283 | GPU
DEBUG 01-06 17:11:10.183710.183710 lmp.py:414]   Expert 63 |    285 | GPU
DEBUG 01-06 17:11:10.183399.183399 lmp.py:414]   Expert 46 |    294 | GPU
DEBUG 01-06 17:11:10.183327.183327 lmp.py:414]   Expert  9 |    300 | GPU
DEBUG 01-06 17:11:10.183016.183016 lmp.py:414]   Expert  6 |    316 | GPU
DEBUG 01-06 17:11:10.183944.183944 lmp.py:414]   Expert 16 |    316 | GPU
DEBUG 01-06 17:11:10.183633.183633 lmp.py:414]   Expert 40 |    319 | GPU
DEBUG 01-06 17:11:10.183799.183799 lmp.py:414]   Expert  7 |    322 | GPU
DEBUG 01-06 17:11:10.183919.183919 lmp.py:414]   Expert 23 |    325 | GPU
DEBUG 01-06 17:11:10.183754.183754 lmp.py:414]   Expert 14 |    413 | GPU
DEBUG 01-06 17:11:10.183351.183351 lmp.py:414]   Expert 57 |    464 | GPU
DEBUG 01-06 17:11:10.183709.183709 lmp.py:415] 
DEBUG 01-06 17:11:10.183709.183709 lmp.py:415]   CPU total tokens: 4059 (33.0%)
DEBUG 01-06 17:11:10.183305.183305 lmp.py:416]   GPU total tokens: 8229 (67.0%)
DEBUG 01-06 17:11:10.183955.183955 cuda_h.py:19] end experts_map_get cost 0.0016245841979980469 seconds
DEBUG 01-06 17:11:10.183313.183313 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-06 17:11:10.183520.183520 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 17:11:10.183319.183319 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 17:11:10.185914.185914 cuda_h.py:19] end allocate_cuda_memory cost 0.0014901161193847656 seconds
DEBUG 01-06 17:11:10.185002.185002 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 17:11:10.185904.185904 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 17:11:10.185666.185666 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 17:11:10.185939.185939 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 22ec2d65-f1f8-4985-bea7-a1de30b1d8e2
DEBUG 01-06 17:11:10.186092.186092 client.py:106] call stub.LoadModelAsync
INFO 01-06 17:11:10.187154.187154 client.py:127] Model loaded
DEBUG 01-06 17:11:10.188204.188204 cuda_h.py:19] end sllm_worker_task cost 0.01282954216003418 seconds
INFO 01-06 17:11:10.188862.188862 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 22ec2d65-f1f8-4985-bea7-a1de30b1d8e2
DEBUG 01-06 17:11:10.189536.189536 cuda_h.py:19] end load_into_gpu_async cost 0.003642559051513672 seconds
DEBUG 01-06 17:11:10.189930.189930 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 17:11:10.189663.189663 cuda_h.py:19] end restore_tensors2 cost 0.0004737377166748047 seconds
DEBUG 01-06 17:11:10.189122.189122 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0060727596282958984 seconds
DEBUG 01-06 17:11:10.192699.192699 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.008928775787353516 seconds
DEBUG 01-06 17:11:10.192350.192350 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-06 17:11:10.192419.192419 lmp.py:461] 
DEBUG 01-06 17:11:10.192419.192419 lmp.py:461]   Computing 32 experts on CPU...
DEBUG 01-06 17:11:10.192077.192077 cuda_h.py:19] end cpu_experts_submit cost 0.00012135505676269531 seconds
DEBUG 01-06 17:11:10.192158.192158 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-06 17:11:10.203498.203498 mlpmodule.py:706] group tensors cost 0.010775566101074219 s
DEBUG 01-06 17:11:10.207280.207280 mlpmodule.py:744] pad cost 0.0030040740966796875 s
DEBUG 01-06 17:11:10.208578.208578 mlpmodule.py:750] create cpu tensor cost 8.177757263183594e-05 s
DEBUG 01-06 17:11:10.208172.208172 mlpmodule.py:755] move to cpu cost 6.270408630371094e-05 s
DEBUG 01-06 17:11:10.220565.220565 mlpmodule.py:769] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-06 17:11:10.220761.220761 mlpmodule.py:770] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-06 17:11:10.220400.220400 mlpmodule.py:775] group_w3 first element: -0.0107421875
WARNING 01-06 17:11:10.220511.220511 mlpmodule.py:785] start einsum2
DEBUG 01-06 17:11:10.239699.239699 mlpmodule.py:795] group einsum cost 0.03109884262084961 s
DEBUG 01-06 17:11:10.240636.240636 mlpmodule.py:803] cpy2cputensor cost 0.0006797313690185547 s
DEBUG 01-06 17:11:10.246238.246238 cuda_h.py:19] end wait_cetm_experts cost 0.05394768714904785 seconds
DEBUG 01-06 17:11:10.247820.247820 cuda_h.py:10] start gpu_sexperts
DEBUG 01-06 17:11:10.247843.247843 cuda_h.py:19] end gpu_sexperts cost 0.0006377696990966797 seconds
DEBUG 01-06 17:11:10.247415.247415 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-06 17:11:10.247656.247656 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.7418136596679688e-05 seconds
DEBUG 01-06 17:11:10.247836.247836 cuda_h.py:10] start wait_experts
INFO 01-06 17:11:10.247307.247307 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 22ec2d65-f1f8-4985-bea7-a1de30b1d8e2
INFO 01-06 17:11:10.249981.249981 client.py:127] Model loaded
DEBUG 01-06 17:11:10.249738.249738 cuda_h.py:19] end wait_experts cost 0.0014066696166992188 seconds
DEBUG 01-06 17:11:10.249064.249064 cuda_h.py:10] start gpu_experts
DEBUG 01-06 17:11:10.249535.249535 lmp.py:506]   Computing 32 experts on GPU...
DEBUG 01-06 17:11:10.256034.256034 mlpmodule.py:664]  experts func einsum cost 0.06300806999206543 s
DEBUG 01-06 17:11:10.256539.256539 mlpmodule.py:533] gpu group tensors cost 0.007328987121582031 s
DEBUG 01-06 17:11:10.258553.258553 mlpmodule.py:566] gpu pad cost 0.0016677379608154297 s
DEBUG 01-06 17:11:10.259368.259368 mlpmodule.py:584] gpu group einsum cost 0.0007452964782714844 s
DEBUG 01-06 17:11:10.262702.262702 mlpmodule.py:613] gpu experts func einsum cost 0.012814760208129883 s
DEBUG 01-06 17:11:10.262322.262322 cuda_h.py:19] end gpu_experts cost 0.013012409210205078 seconds
DEBUG 01-06 17:11:10.262821.262821 cuda_h.py:19] end layer_moe_generate_1 cost 0.08144497871398926 seconds
DEBUG 01-06 17:11:10.262496.262496 lmp.py:220] -------------------------------- end layer 1 --------------------------------
DEBUG 01-06 17:11:10.262789.262789 lmp.py:176] -------------------------------- start layer 2 --------------------------------
DEBUG 01-06 17:11:10.262816.262816 cuda_h.py:10] start start_load_qkvogn_s_weight_l_3
DEBUG 01-06 17:11:10.262334.262334 cuda_h.py:10] start start_load_qkvogn_s_weight_l_3
DEBUG 01-06 17:11:10.262528.262528 cuda_h.py:19] end start_load_qkvogn_s_weight_l_3 cost 4.696846008300781e-05 seconds
DEBUG 01-06 17:11:10.262185.262185 cuda_h.py:19] end start_load_qkvogn_s_weight_l_3 cost 7.987022399902344e-05 seconds
DEBUG 01-06 17:11:10.262020.262020 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-06 17:11:10.262876.262876 mlpmodule.py:367] cuda:1 cuda:1
DEBUG 01-06 17:11:10.262912.262912 cuda_h.py:10] start sllm_worker_task
DEBUG 01-06 17:11:10.263023.263023 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 17:11:10.263720.263720 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 17:11:10.263780.263780 cuda_h.py:19] end allocate_cuda_memory cost 0.0001842975616455078 seconds
DEBUG 01-06 17:11:10.263227.263227 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 17:11:10.263274.263274 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 17:11:10.263236.263236 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 17:11:10.263323.263323 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 14adc8cc-0999-4ecb-8545-86d088ac442f
DEBUG 01-06 17:11:10.263478.263478 client.py:106] call stub.LoadModelAsync
DEBUG 01-06 17:11:10.263989.263989 cuda_h.py:10] start self_attn
INFO 01-06 17:11:10.265516.265516 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 14adc8cc-0999-4ecb-8545-86d088ac442f
DEBUG 01-06 17:11:10.265876.265876 cuda_h.py:19] end load_into_gpu_async cost 0.001741647720336914 seconds
DEBUG 01-06 17:11:10.265910.265910 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 17:11:10.265800.265800 cuda_h.py:19] end restore_tensors2 cost 6.818771362304688e-05 seconds
DEBUG 01-06 17:11:10.265887.265887 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0022516250610351562 seconds
INFO 01-06 17:11:10.265439.265439 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 14adc8cc-0999-4ecb-8545-86d088ac442f
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-06 17:11:10.266858.266858 cuda_h.py:19] end self_attn cost 0.0029306411743164062 seconds
DEBUG 01-06 17:11:10.267920.267920 cuda_h.py:19] end iln_self_attn_paln cost 0.0043222904205322266 seconds
DEBUG 01-06 17:11:10.267115.267115 cuda_h.py:10] start layer_moe_generate_2
DEBUG 01-06 17:11:10.267116.267116 cuda_h.py:10] start gate
DEBUG 01-06 17:11:10.268345.268345 cuda_h.py:19] end gate cost 0.000659942626953125 seconds
DEBUG 01-06 17:11:10.268744.268744 cuda_h.py:10] start experts_map_get
DEBUG 01-06 17:11:10.268482.268482 lmp.py:403] 
DEBUG 01-06 17:11:10.268482.268482 lmp.py:403] Expert Token Distribution & Device Allocation:
DEBUG 01-06 17:11:10.268821.268821 lmp.py:404]   Total experts: 64
DEBUG 01-06 17:11:10.268709.268709 lmp.py:405]   CPU experts: 32 (50%)
DEBUG 01-06 17:11:10.268783.268783 lmp.py:406]   GPU experts: 32 (50%)
DEBUG 01-06 17:11:10.268187.268187 lmp.py:407] 
DEBUG 01-06 17:11:10.268187.268187 lmp.py:407]   Expert ID | Tokens | Device
DEBUG 01-06 17:11:10.268069.268069 lmp.py:408]   -----------------------------------
DEBUG 01-06 17:11:10.268672.268672 lmp.py:414]   Expert 58 |     51 | CPU
DEBUG 01-06 17:11:10.268077.268077 lmp.py:414]   Expert 27 |     58 | CPU
DEBUG 01-06 17:11:10.268766.268766 lmp.py:414]   Expert  3 |     69 | CPU
DEBUG 01-06 17:11:10.268217.268217 lmp.py:414]   Expert 17 |     81 | CPU
DEBUG 01-06 17:11:10.268953.268953 lmp.py:414]   Expert  0 |     86 | CPU
DEBUG 01-06 17:11:10.268927.268927 lmp.py:414]   Expert 24 |     87 | CPU
DEBUG 01-06 17:11:10.268662.268662 lmp.py:414]   Expert 28 |    105 | CPU
DEBUG 01-06 17:11:10.268636.268636 lmp.py:414]   Expert 34 |    114 | CPU
DEBUG 01-06 17:11:10.268372.268372 lmp.py:414]   Expert 51 |    115 | CPU
DEBUG 01-06 17:11:10.268869.268869 lmp.py:414]   Expert 32 |    120 | CPU
DEBUG 01-06 17:11:10.268605.268605 lmp.py:414]   Expert  9 |    123 | CPU
DEBUG 01-06 17:11:10.268579.268579 lmp.py:414]   Expert 26 |    132 | CPU
DEBUG 01-06 17:11:10.268030.268030 lmp.py:414]   Expert  7 |    133 | CPU
DEBUG 01-06 17:11:10.268481.268481 lmp.py:414]   Expert 15 |    136 | CPU
DEBUG 01-06 17:11:10.268931.268931 lmp.py:414]   Expert 23 |    138 | CPU
DEBUG 01-06 17:11:10.268382.268382 lmp.py:414]   Expert 30 |    142 | CPU
DEBUG 01-06 17:11:10.268880.268880 lmp.py:414]   Expert 45 |    144 | CPU
DEBUG 01-06 17:11:10.268377.268377 lmp.py:414]   Expert 57 |    150 | CPU
DEBUG 01-06 17:11:10.268304.268304 lmp.py:414]   Expert 62 |    150 | CPU
DEBUG 01-06 17:11:10.268802.268802 lmp.py:414]   Expert  1 |    152 | CPU
DEBUG 01-06 17:11:10.268537.268537 lmp.py:414]   Expert 36 |    159 | CPU
DEBUG 01-06 17:11:10.268035.268035 lmp.py:414]   Expert  8 |    161 | CPU
DEBUG 01-06 17:11:10.268770.268770 lmp.py:414]   Expert 29 |    162 | CPU
DEBUG 01-06 17:11:10.268029.268029 lmp.py:414]   Expert 25 |    165 | CPU
DEBUG 01-06 17:11:10.268765.268765 lmp.py:414]   Expert 48 |    169 | CPU
DEBUG 01-06 17:11:10.268215.268215 lmp.py:414]   Expert 35 |    172 | CPU
DEBUG 01-06 17:11:10.268666.268666 lmp.py:414]   Expert 54 |    172 | CPU
DEBUG 01-06 17:11:10.268117.268117 lmp.py:414]   Expert  6 |    174 | CPU
DEBUG 01-06 17:11:10.268806.268806 lmp.py:414]   Expert 37 |    175 | CPU
DEBUG 01-06 17:11:10.268781.268781 lmp.py:414]   Expert 12 |    176 | CPU
DEBUG 01-06 17:11:10.268993.268993 lmp.py:414]   Expert 49 |    176 | CPU
DEBUG 01-06 17:11:10.269490.269490 lmp.py:414]   Expert 33 |    185 | CPU
DEBUG 01-06 17:11:10.269464.269464 lmp.py:414]   Expert 60 |    186 | GPU
DEBUG 01-06 17:11:10.269723.269723 lmp.py:414]   Expert 13 |    187 | GPU
DEBUG 01-06 17:11:10.269220.269220 lmp.py:414]   Expert 53 |    189 | GPU
DEBUG 01-06 17:11:10.269479.269479 lmp.py:414]   Expert 10 |    193 | GPU
DEBUG 01-06 17:11:10.269976.269976 lmp.py:414]   Expert 16 |    194 | GPU
DEBUG 01-06 17:11:10.269473.269473 lmp.py:414]   Expert 21 |    195 | GPU
DEBUG 01-06 17:11:10.269447.269447 lmp.py:414]   Expert 40 |    198 | GPU
DEBUG 01-06 17:11:10.269422.269422 lmp.py:414]   Expert 38 |    206 | GPU
DEBUG 01-06 17:11:10.269872.269872 lmp.py:414]   Expert 43 |    206 | GPU
DEBUG 01-06 17:11:10.269323.269323 lmp.py:414]   Expert  5 |    208 | GPU
DEBUG 01-06 17:11:10.269297.269297 lmp.py:414]   Expert 19 |    213 | GPU
DEBUG 01-06 17:11:10.269033.269033 lmp.py:414]   Expert 44 |    216 | GPU
DEBUG 01-06 17:11:10.269053.269053 lmp.py:414]   Expert 41 |    217 | GPU
DEBUG 01-06 17:11:10.269789.269789 lmp.py:414]   Expert 50 |    218 | GPU
DEBUG 01-06 17:11:10.269809.269809 lmp.py:414]   Expert 59 |    219 | GPU
DEBUG 01-06 17:11:10.269307.269307 lmp.py:414]   Expert 52 |    220 | GPU
DEBUG 01-06 17:11:10.269565.269565 lmp.py:414]   Expert  4 |    222 | GPU
DEBUG 01-06 17:11:10.269824.269824 lmp.py:414]   Expert 55 |    236 | GPU
DEBUG 01-06 17:11:10.269560.269560 lmp.py:414]   Expert 56 |    242 | GPU
DEBUG 01-06 17:11:10.269772.269772 lmp.py:414]   Expert 31 |    243 | GPU
DEBUG 01-06 17:11:10.269746.269746 lmp.py:414]   Expert 20 |    253 | GPU
DEBUG 01-06 17:11:10.269959.269959 lmp.py:414]   Expert 39 |    255 | GPU
DEBUG 01-06 17:11:10.269171.269171 lmp.py:414]   Expert  2 |    265 | GPU
DEBUG 01-06 17:11:10.269384.269384 lmp.py:414]   Expert 22 |    267 | GPU
DEBUG 01-06 17:11:10.269119.269119 lmp.py:414]   Expert 47 |    276 | GPU
DEBUG 01-06 17:11:10.269378.269378 lmp.py:414]   Expert 63 |    277 | GPU
DEBUG 01-06 17:11:10.269875.269875 lmp.py:414]   Expert 42 |    301 | GPU
DEBUG 01-06 17:11:10.269896.269896 lmp.py:414]   Expert 14 |    316 | GPU
DEBUG 01-06 17:11:10.269154.269154 lmp.py:414]   Expert 18 |    317 | GPU
DEBUG 01-06 17:11:10.269890.269890 lmp.py:414]   Expert 46 |    368 | GPU
DEBUG 01-06 17:11:10.269910.269910 lmp.py:414]   Expert 11 |    392 | GPU
DEBUG 01-06 17:11:10.269408.269408 lmp.py:414]   Expert 61 |    461 | GPU
DEBUG 01-06 17:11:10.269382.269382 lmp.py:415] 
DEBUG 01-06 17:11:10.269382.269382 lmp.py:415]   CPU total tokens: 4332 (35.3%)
DEBUG 01-06 17:11:10.269071.269071 lmp.py:416]   GPU total tokens: 7956 (64.7%)
DEBUG 01-06 17:11:10.269290.269290 cuda_h.py:19] end experts_map_get cost 0.0014646053314208984 seconds
DEBUG 01-06 17:11:10.269695.269695 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-06 17:11:10.269756.269756 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 17:11:10.269840.269840 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 17:11:10.271571.271571 cuda_h.py:19] end allocate_cuda_memory cost 0.002016782760620117 seconds
DEBUG 01-06 17:11:10.271314.271314 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 17:11:10.271163.271163 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 17:11:10.271257.271257 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 17:11:10.271145.271145 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 3db0ecf5-80a9-46cd-9976-f9b3d7a62a43
DEBUG 01-06 17:11:10.272151.272151 client.py:106] call stub.LoadModelAsync
INFO 01-06 17:11:10.272903.272903 client.py:127] Model loaded
DEBUG 01-06 17:11:10.273870.273870 cuda_h.py:19] end sllm_worker_task cost 0.009888172149658203 seconds
INFO 01-06 17:11:10.274180.274180 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 3db0ecf5-80a9-46cd-9976-f9b3d7a62a43
DEBUG 01-06 17:11:10.274761.274761 cuda_h.py:19] end load_into_gpu_async cost 0.002423524856567383 seconds
DEBUG 01-06 17:11:10.274201.274201 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 17:11:10.274060.274060 cuda_h.py:19] end restore_tensors2 cost 0.00046443939208984375 seconds
DEBUG 01-06 17:11:10.274565.274565 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.00534820556640625 seconds
DEBUG 01-06 17:11:10.277342.277342 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.008035421371459961 seconds
DEBUG 01-06 17:11:10.277993.277993 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-06 17:11:10.277069.277069 lmp.py:461] 
DEBUG 01-06 17:11:10.277069.277069 lmp.py:461]   Computing 32 experts on CPU...
DEBUG 01-06 17:11:10.277104.277104 cuda_h.py:19] end cpu_experts_submit cost 0.00010943412780761719 seconds
DEBUG 01-06 17:11:10.277992.277992 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-06 17:11:10.286664.286664 mlpmodule.py:706] group tensors cost 0.007947921752929688 s
DEBUG 01-06 17:11:10.290523.290523 mlpmodule.py:744] pad cost 0.003599405288696289 s
DEBUG 01-06 17:11:10.290984.290984 mlpmodule.py:750] create cpu tensor cost 5.173683166503906e-05 s
DEBUG 01-06 17:11:10.290894.290894 mlpmodule.py:755] move to cpu cost 3.814697265625e-05 s
DEBUG 01-06 17:11:10.303077.303077 mlpmodule.py:769] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-06 17:11:10.303690.303690 mlpmodule.py:770] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-06 17:11:10.303805.303805 mlpmodule.py:775] group_w3 first element: -0.0380859375
WARNING 01-06 17:11:10.303591.303591 mlpmodule.py:785] start einsum2
DEBUG 01-06 17:11:10.322589.322589 mlpmodule.py:795] group einsum cost 0.03215503692626953 s
DEBUG 01-06 17:11:10.323100.323100 mlpmodule.py:803] cpy2cputensor cost 0.0006878376007080078 s
DEBUG 01-06 17:11:10.330148.330148 cuda_h.py:19] end wait_cetm_experts cost 0.052243947982788086 seconds
DEBUG 01-06 17:11:10.330321.330321 cuda_h.py:10] start gpu_sexperts
DEBUG 01-06 17:11:10.331250.331250 cuda_h.py:19] end gpu_sexperts cost 0.0006072521209716797 seconds
DEBUG 01-06 17:11:10.331623.331623 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-06 17:11:10.331234.331234 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.5510787963867188e-05 seconds
DEBUG 01-06 17:11:10.331891.331891 cuda_h.py:10] start wait_experts
INFO 01-06 17:11:10.331600.331600 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 3db0ecf5-80a9-46cd-9976-f9b3d7a62a43
INFO 01-06 17:11:10.332441.332441 client.py:127] Model loaded
DEBUG 01-06 17:11:10.332814.332814 cuda_h.py:19] end wait_experts cost 0.001422882080078125 seconds
DEBUG 01-06 17:11:10.332662.332662 cuda_h.py:10] start gpu_experts
DEBUG 01-06 17:11:10.332802.332802 lmp.py:506]   Computing 32 experts on GPU...
DEBUG 01-06 17:11:10.333900.333900 mlpmodule.py:533] gpu group tensors cost 0.0006496906280517578 s
DEBUG 01-06 17:11:10.335391.335391 mlpmodule.py:566] gpu pad cost 0.0017476081848144531 s
DEBUG 01-06 17:11:10.336632.336632 mlpmodule.py:584] gpu group einsum cost 0.0014069080352783203 s
DEBUG 01-06 17:11:10.339638.339638 mlpmodule.py:664]  experts func einsum cost 0.0614016056060791 s
DEBUG 01-06 17:11:10.340453.340453 mlpmodule.py:613] gpu experts func einsum cost 0.007473468780517578 s
DEBUG 01-06 17:11:10.340909.340909 cuda_h.py:19] end gpu_experts cost 0.007736921310424805 seconds
DEBUG 01-06 17:11:10.340985.340985 cuda_h.py:19] end layer_moe_generate_2 cost 0.07322287559509277 seconds
DEBUG 01-06 17:11:10.340250.340250 lmp.py:220] -------------------------------- end layer 2 --------------------------------
DEBUG 01-06 17:11:10.340450.340450 lmp.py:176] -------------------------------- start layer 3 --------------------------------
DEBUG 01-06 17:11:10.340384.340384 cuda_h.py:10] start start_load_qkvogn_s_weight_l_4
DEBUG 01-06 17:11:10.340425.340425 cuda_h.py:10] start start_load_qkvogn_s_weight_l_4
DEBUG 01-06 17:11:10.340122.340122 cuda_h.py:19] end start_load_qkvogn_s_weight_l_4 cost 3.0994415283203125e-05 seconds
DEBUG 01-06 17:11:10.340110.340110 cuda_h.py:19] end start_load_qkvogn_s_weight_l_4 cost 6.198883056640625e-05 seconds
DEBUG 01-06 17:11:10.340183.340183 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-06 17:11:10.341994.341994 mlpmodule.py:367] cuda:1 cuda:1
DEBUG 01-06 17:11:10.341989.341989 cuda_h.py:10] start sllm_worker_task
DEBUG 01-06 17:11:10.341941.341941 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 17:11:10.341638.341638 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 17:11:10.341720.341720 cuda_h.py:19] end allocate_cuda_memory cost 0.0002300739288330078 seconds
DEBUG 01-06 17:11:10.341736.341736 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 17:11:10.341499.341499 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 17:11:10.341183.341183 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 17:11:10.341932.341932 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 69ada8ad-8783-4755-913b-5cdceb141d87
DEBUG 01-06 17:11:10.341948.341948 client.py:106] call stub.LoadModelAsync
DEBUG 01-06 17:11:10.342545.342545 cuda_h.py:10] start self_attn
INFO 01-06 17:11:10.343941.343941 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 69ada8ad-8783-4755-913b-5cdceb141d87
DEBUG 01-06 17:11:10.343823.343823 cuda_h.py:19] end load_into_gpu_async cost 0.001573801040649414 seconds
DEBUG 01-06 17:11:10.343188.343188 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 17:11:10.343364.343364 cuda_h.py:19] end restore_tensors2 cost 6.914138793945312e-05 seconds
DEBUG 01-06 17:11:10.343735.343735 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.002129793167114258 seconds
INFO 01-06 17:11:10.343023.343023 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 69ada8ad-8783-4755-913b-5cdceb141d87
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-06 17:11:10.345349.345349 cuda_h.py:19] end self_attn cost 0.0029871463775634766 seconds
DEBUG 01-06 17:11:10.345650.345650 cuda_h.py:19] end iln_self_attn_paln cost 0.004422426223754883 seconds
DEBUG 01-06 17:11:10.345586.345586 cuda_h.py:10] start layer_moe_generate_3
DEBUG 01-06 17:11:10.345064.345064 cuda_h.py:10] start gate
DEBUG 01-06 17:11:10.346610.346610 cuda_h.py:19] end gate cost 0.0006496906280517578 seconds
DEBUG 01-06 17:11:10.346294.346294 cuda_h.py:10] start experts_map_get
DEBUG 01-06 17:11:10.346231.346231 lmp.py:403] 
DEBUG 01-06 17:11:10.346231.346231 lmp.py:403] Expert Token Distribution & Device Allocation:
DEBUG 01-06 17:11:10.346034.346034 lmp.py:404]   Total experts: 64
DEBUG 01-06 17:11:10.346683.346683 lmp.py:405]   CPU experts: 32 (50%)
DEBUG 01-06 17:11:10.346757.346757 lmp.py:406]   GPU experts: 32 (50%)
DEBUG 01-06 17:11:10.346923.346923 lmp.py:407] 
DEBUG 01-06 17:11:10.346923.346923 lmp.py:407]   Expert ID | Tokens | Device
DEBUG 01-06 17:11:10.346328.346328 lmp.py:408]   -----------------------------------
DEBUG 01-06 17:11:10.346931.346931 lmp.py:414]   Expert  1 |     47 | CPU
DEBUG 01-06 17:11:10.346336.346336 lmp.py:414]   Expert 27 |     62 | CPU
DEBUG 01-06 17:11:10.346310.346310 lmp.py:414]   Expert  7 |     76 | CPU
DEBUG 01-06 17:11:10.346760.346760 lmp.py:414]   Expert 48 |     83 | CPU
DEBUG 01-06 17:11:10.346735.346735 lmp.py:414]   Expert 15 |     99 | CPU
DEBUG 01-06 17:11:10.346709.346709 lmp.py:414]   Expert 30 |    112 | CPU
DEBUG 01-06 17:11:10.346683.346683 lmp.py:414]   Expert 61 |    114 | CPU
DEBUG 01-06 17:11:10.346657.346657 lmp.py:414]   Expert 32 |    116 | CPU
DEBUG 01-06 17:11:10.346346.346346 lmp.py:414]   Expert 18 |    119 | CPU
DEBUG 01-06 17:11:10.346797.346797 lmp.py:414]   Expert 45 |    120 | CPU
DEBUG 01-06 17:11:10.346248.346248 lmp.py:414]   Expert 34 |    132 | CPU
DEBUG 01-06 17:11:10.346937.346937 lmp.py:414]   Expert  5 |    133 | CPU
DEBUG 01-06 17:11:10.346149.346149 lmp.py:414]   Expert 26 |    139 | CPU
DEBUG 01-06 17:11:10.346885.346885 lmp.py:414]   Expert 36 |    139 | CPU
DEBUG 01-06 17:11:10.346382.346382 lmp.py:414]   Expert 59 |    140 | CPU
DEBUG 01-06 17:11:10.346118.346118 lmp.py:414]   Expert 11 |    141 | CPU
DEBUG 01-06 17:11:10.346377.346377 lmp.py:414]   Expert  6 |    142 | CPU
DEBUG 01-06 17:11:10.346112.346112 lmp.py:414]   Expert 39 |    142 | CPU
DEBUG 01-06 17:11:10.346848.346848 lmp.py:414]   Expert 51 |    143 | CPU
DEBUG 01-06 17:11:10.346345.346345 lmp.py:414]   Expert 23 |    155 | CPU
DEBUG 01-06 17:11:10.346081.346081 lmp.py:414]   Expert  2 |    159 | CPU
DEBUG 01-06 17:11:10.346055.346055 lmp.py:414]   Expert  9 |    159 | CPU
DEBUG 01-06 17:11:10.347029.347029 lmp.py:414]   Expert 49 |    160 | CPU
DEBUG 01-06 17:11:10.347480.347480 lmp.py:414]   Expert 50 |    167 | CPU
DEBUG 01-06 17:11:10.347692.347692 lmp.py:414]   Expert 40 |    168 | CPU
DEBUG 01-06 17:11:10.347905.347905 lmp.py:414]   Expert 56 |    168 | CPU
DEBUG 01-06 17:11:10.347640.347640 lmp.py:414]   Expert 52 |    169 | CPU
DEBUG 01-06 17:11:10.347614.347614 lmp.py:414]   Expert 35 |    172 | CPU
DEBUG 01-06 17:11:10.347827.347827 lmp.py:414]   Expert 16 |    173 | CPU
DEBUG 01-06 17:11:10.347039.347039 lmp.py:414]   Expert  4 |    182 | CPU
DEBUG 01-06 17:11:10.347252.347252 lmp.py:414]   Expert 42 |    188 | CPU
DEBUG 01-06 17:11:10.347226.347226 lmp.py:414]   Expert 37 |    189 | CPU
DEBUG 01-06 17:11:10.347677.347677 lmp.py:414]   Expert 13 |    194 | GPU
DEBUG 01-06 17:11:10.347889.347889 lmp.py:414]   Expert 38 |    196 | GPU
DEBUG 01-06 17:11:10.347863.347863 lmp.py:414]   Expert 17 |    198 | GPU
DEBUG 01-06 17:11:10.347791.347791 lmp.py:414]   Expert 62 |    198 | GPU
DEBUG 01-06 17:11:10.347242.347242 lmp.py:414]   Expert 21 |    203 | GPU
DEBUG 01-06 17:11:10.347454.347454 lmp.py:414]   Expert 28 |    207 | GPU
DEBUG 01-06 17:11:10.347905.347905 lmp.py:414]   Expert 44 |    208 | GPU
DEBUG 01-06 17:11:10.347118.347118 lmp.py:414]   Expert 60 |    210 | GPU
DEBUG 01-06 17:11:10.347853.347853 lmp.py:414]   Expert 58 |    211 | GPU
DEBUG 01-06 17:11:10.347589.347589 lmp.py:414]   Expert  3 |    212 | GPU
DEBUG 01-06 17:11:10.347325.347325 lmp.py:414]   Expert 47 |    214 | GPU
DEBUG 01-06 17:11:10.347822.347822 lmp.py:414]   Expert 53 |    214 | GPU
DEBUG 01-06 17:11:10.347081.347081 lmp.py:414]   Expert 10 |    217 | GPU
DEBUG 01-06 17:11:10.347055.347055 lmp.py:414]   Expert 55 |    220 | GPU
DEBUG 01-06 17:11:10.347313.347313 lmp.py:414]   Expert 20 |    221 | GPU
DEBUG 01-06 17:11:10.347049.347049 lmp.py:414]   Expert 33 |    226 | GPU
DEBUG 01-06 17:11:10.347977.347977 lmp.py:414]   Expert 57 |    230 | GPU
DEBUG 01-06 17:11:10.347951.347951 lmp.py:414]   Expert  8 |    237 | GPU
DEBUG 01-06 17:11:10.347640.347640 lmp.py:414]   Expert 31 |    237 | GPU
DEBUG 01-06 17:11:10.347852.347852 lmp.py:414]   Expert 46 |    237 | GPU
DEBUG 01-06 17:11:10.347065.347065 lmp.py:414]   Expert 24 |    244 | GPU
DEBUG 01-06 17:11:10.347039.347039 lmp.py:414]   Expert 19 |    249 | GPU
DEBUG 01-06 17:11:10.347298.347298 lmp.py:414]   Expert 63 |    267 | GPU
DEBUG 01-06 17:11:10.347033.347033 lmp.py:414]   Expert 14 |    270 | GPU
DEBUG 01-06 17:11:10.347054.347054 lmp.py:414]   Expert 12 |    274 | GPU
DEBUG 01-06 17:11:10.347551.347551 lmp.py:414]   Expert 29 |    274 | GPU
DEBUG 01-06 17:11:10.347810.347810 lmp.py:414]   Expert 22 |    278 | GPU
DEBUG 01-06 17:11:10.347307.347307 lmp.py:414]   Expert  0 |    293 | GPU
DEBUG 01-06 17:11:10.347566.347566 lmp.py:414]   Expert 43 |    308 | GPU
DEBUG 01-06 17:11:10.347255.347255 lmp.py:414]   Expert 54 |    337 | GPU
DEBUG 01-06 17:11:10.347991.347991 lmp.py:414]   Expert 41 |    384 | GPU
DEBUG 01-06 17:11:10.347203.347203 lmp.py:414]   Expert 25 |    412 | GPU
DEBUG 01-06 17:11:10.347892.347892 lmp.py:415] 
DEBUG 01-06 17:11:10.347892.347892 lmp.py:415]   CPU total tokens: 4408 (35.9%)
DEBUG 01-06 17:11:10.347535.347535 lmp.py:416]   GPU total tokens: 7880 (64.1%)
DEBUG 01-06 17:11:10.347278.347278 cuda_h.py:19] end experts_map_get cost 0.0014712810516357422 seconds
DEBUG 01-06 17:11:10.347967.347967 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-06 17:11:10.347366.347366 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 17:11:10.347126.347126 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 17:11:10.349030.349030 cuda_h.py:19] end allocate_cuda_memory cost 0.0016515254974365234 seconds
DEBUG 01-06 17:11:10.349350.349350 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 17:11:10.349960.349960 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 17:11:10.349723.349723 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 17:11:10.349088.349088 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, ef088604-9186-4937-8490-c7015650b324
DEBUG 01-06 17:11:10.349200.349200 client.py:106] call stub.LoadModelAsync
INFO 01-06 17:11:10.351553.351553 client.py:127] Model loaded
DEBUG 01-06 17:11:10.351020.351020 cuda_h.py:19] end sllm_worker_task cost 0.010663032531738281 seconds
INFO 01-06 17:11:10.353105.353105 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, ef088604-9186-4937-8490-c7015650b324
DEBUG 01-06 17:11:10.353763.353763 cuda_h.py:19] end load_into_gpu_async cost 0.003397703170776367 seconds
DEBUG 01-06 17:11:10.353181.353181 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 17:11:10.353288.353288 cuda_h.py:19] end restore_tensors2 cost 0.0004024505615234375 seconds
DEBUG 01-06 17:11:10.353839.353839 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.005804300308227539 seconds
DEBUG 01-06 17:11:10.356028.356028 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.008516073226928711 seconds
DEBUG 01-06 17:11:10.356480.356480 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-06 17:11:10.356457.356457 lmp.py:461] 
DEBUG 01-06 17:11:10.356457.356457 lmp.py:461]   Computing 32 experts on CPU...
DEBUG 01-06 17:11:10.356214.356214 cuda_h.py:19] end cpu_experts_submit cost 0.0001266002655029297 seconds
DEBUG 01-06 17:11:10.356963.356963 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-06 17:11:10.363120.363120 mlpmodule.py:706] group tensors cost 0.006450176239013672 s
DEBUG 01-06 17:11:10.366567.366567 mlpmodule.py:744] pad cost 0.0026047229766845703 s
DEBUG 01-06 17:11:10.366334.366334 mlpmodule.py:750] create cpu tensor cost 6.318092346191406e-05 s
DEBUG 01-06 17:11:10.366363.366363 mlpmodule.py:755] move to cpu cost 4.482269287109375e-05 s
DEBUG 01-06 17:11:10.378037.378037 mlpmodule.py:769] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-06 17:11:10.378775.378775 mlpmodule.py:770] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-06 17:11:10.378023.378023 mlpmodule.py:775] group_w3 first element: -0.054931640625
WARNING 01-06 17:11:10.378616.378616 mlpmodule.py:785] start einsum2
DEBUG 01-06 17:11:10.398872.398872 mlpmodule.py:795] group einsum cost 0.031943559646606445 s
DEBUG 01-06 17:11:10.399721.399721 mlpmodule.py:803] cpy2cputensor cost 0.0006964206695556641 s
DEBUG 01-06 17:11:10.406516.406516 cuda_h.py:19] end wait_cetm_experts cost 0.04965543746948242 seconds
DEBUG 01-06 17:11:10.406165.406165 cuda_h.py:10] start gpu_sexperts
DEBUG 01-06 17:11:10.407332.407332 cuda_h.py:19] end gpu_sexperts cost 0.0006051063537597656 seconds
DEBUG 01-06 17:11:10.407705.407705 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-06 17:11:10.407794.407794 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.4318695068359375e-05 seconds
DEBUG 01-06 17:11:10.407212.407212 cuda_h.py:10] start wait_experts
INFO 01-06 17:11:10.407729.407729 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, ef088604-9186-4937-8490-c7015650b324
INFO 01-06 17:11:10.408060.408060 client.py:127] Model loaded
DEBUG 01-06 17:11:10.408910.408910 cuda_h.py:19] end wait_experts cost 0.001432657241821289 seconds
DEBUG 01-06 17:11:10.408235.408235 cuda_h.py:10] start gpu_experts
DEBUG 01-06 17:11:10.408773.408773 lmp.py:506]   Computing 32 experts on GPU...
DEBUG 01-06 17:11:10.409030.409030 mlpmodule.py:533] gpu group tensors cost 0.0006654262542724609 s
DEBUG 01-06 17:11:10.411667.411667 mlpmodule.py:566] gpu pad cost 0.0017485618591308594 s
DEBUG 01-06 17:11:10.411121.411121 mlpmodule.py:584] gpu group einsum cost 0.0004482269287109375 s
DEBUG 01-06 17:11:10.415180.415180 mlpmodule.py:664]  experts func einsum cost 0.05848336219787598 s
DEBUG 01-06 17:11:10.415859.415859 mlpmodule.py:613] gpu experts func einsum cost 0.006428241729736328 s
DEBUG 01-06 17:11:10.415410.415410 cuda_h.py:19] end gpu_experts cost 0.006771087646484375 seconds
DEBUG 01-06 17:11:10.415268.415268 cuda_h.py:19] end layer_moe_generate_3 cost 0.07016825675964355 seconds
DEBUG 01-06 17:11:10.415898.415898 lmp.py:220] -------------------------------- end layer 3 --------------------------------
DEBUG 01-06 17:11:10.415806.415806 lmp.py:176] -------------------------------- start layer 4 --------------------------------
DEBUG 01-06 17:11:10.415741.415741 cuda_h.py:10] start start_load_qkvogn_s_weight_l_5
DEBUG 01-06 17:11:10.415119.415119 cuda_h.py:10] start start_load_qkvogn_s_weight_l_5
DEBUG 01-06 17:11:10.416486.416486 cuda_h.py:19] end start_load_qkvogn_s_weight_l_5 cost 3.314018249511719e-05 seconds
DEBUG 01-06 17:11:10.416427.416427 cuda_h.py:19] end start_load_qkvogn_s_weight_l_5 cost 6.461143493652344e-05 seconds
DEBUG 01-06 17:11:10.416262.416262 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-06 17:11:10.416072.416072 mlpmodule.py:367] cuda:1 cuda:1
DEBUG 01-06 17:11:10.416081.416081 cuda_h.py:10] start sllm_worker_task
DEBUG 01-06 17:11:10.416310.416310 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 17:11:10.416908.416908 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 17:11:10.416006.416006 cuda_h.py:19] end allocate_cuda_memory cost 0.0003025531768798828 seconds
DEBUG 01-06 17:11:10.416637.416637 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 17:11:10.416208.416208 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 17:11:10.416647.416647 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 17:11:10.416449.416449 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 9686cb40-d548-4009-9433-ec8c4205622d
DEBUG 01-06 17:11:10.416419.416419 client.py:106] call stub.LoadModelAsync
DEBUG 01-06 17:11:10.417340.417340 cuda_h.py:10] start self_attn
INFO 01-06 17:11:10.418569.418569 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 9686cb40-d548-4009-9433-ec8c4205622d
DEBUG 01-06 17:11:10.418883.418883 cuda_h.py:19] end load_into_gpu_async cost 0.0015501976013183594 seconds
DEBUG 01-06 17:11:10.418678.418678 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 17:11:10.418244.418244 cuda_h.py:19] end restore_tensors2 cost 7.534027099609375e-05 seconds
DEBUG 01-06 17:11:10.418524.418524 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0021979808807373047 seconds
INFO 01-06 17:11:10.418214.418214 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 9686cb40-d548-4009-9433-ec8c4205622d
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-06 17:11:10.420240.420240 cuda_h.py:19] end self_attn cost 0.0028839111328125 seconds
DEBUG 01-06 17:11:10.420145.420145 cuda_h.py:19] end iln_self_attn_paln cost 0.004378557205200195 seconds
DEBUG 01-06 17:11:10.420703.420703 cuda_h.py:10] start layer_moe_generate_4
DEBUG 01-06 17:11:10.420896.420896 cuda_h.py:10] start gate
DEBUG 01-06 17:11:10.421005.421005 cuda_h.py:19] end gate cost 0.0006422996520996094 seconds
DEBUG 01-06 17:11:10.421404.421404 cuda_h.py:10] start experts_map_get
DEBUG 01-06 17:11:10.421328.421328 lmp.py:403] 
DEBUG 01-06 17:11:10.421328.421328 lmp.py:403] Expert Token Distribution & Device Allocation:
DEBUG 01-06 17:11:10.421368.421368 lmp.py:404]   Total experts: 64
DEBUG 01-06 17:11:10.421495.421495 lmp.py:405]   CPU experts: 32 (50%)
DEBUG 01-06 17:11:10.421045.421045 lmp.py:406]   GPU experts: 32 (50%)
DEBUG 01-06 17:11:10.421212.421212 lmp.py:407] 
DEBUG 01-06 17:11:10.421212.421212 lmp.py:407]   Expert ID | Tokens | Device
DEBUG 01-06 17:11:10.421854.421854 lmp.py:408]   -----------------------------------
DEBUG 01-06 17:11:10.421981.421981 lmp.py:414]   Expert 14 |     64 | CPU
DEBUG 01-06 17:11:10.421147.421147 lmp.py:414]   Expert 57 |     73 | CPU
DEBUG 01-06 17:11:10.421837.421837 lmp.py:414]   Expert 13 |     74 | CPU
DEBUG 01-06 17:11:10.421049.421049 lmp.py:414]   Expert 26 |     79 | CPU
DEBUG 01-06 17:11:10.421785.421785 lmp.py:414]   Expert 31 |     84 | CPU
DEBUG 01-06 17:11:10.421759.421759 lmp.py:414]   Expert 54 |     92 | CPU
DEBUG 01-06 17:11:10.421733.421733 lmp.py:414]   Expert 11 |     97 | CPU
DEBUG 01-06 17:11:10.421468.421468 lmp.py:414]   Expert 45 |     98 | CPU
DEBUG 01-06 17:11:10.421681.421681 lmp.py:414]   Expert 30 |    100 | CPU
DEBUG 01-06 17:11:10.421893.421893 lmp.py:414]   Expert 58 |    103 | CPU
DEBUG 01-06 17:11:10.421490.421490 lmp.py:414]   Expert 51 |    110 | CPU
DEBUG 01-06 17:11:10.421133.421133 lmp.py:414]   Expert 32 |    116 | CPU
DEBUG 01-06 17:11:10.421537.421537 lmp.py:414]   Expert 36 |    116 | CPU
DEBUG 01-06 17:11:10.421465.421465 lmp.py:414]   Expert 10 |    118 | CPU
DEBUG 01-06 17:11:10.421678.421678 lmp.py:414]   Expert 20 |    126 | CPU
DEBUG 01-06 17:11:10.421605.421605 lmp.py:414]   Expert  8 |    129 | CPU
DEBUG 01-06 17:11:10.421056.421056 lmp.py:414]   Expert 61 |    137 | CPU
DEBUG 01-06 17:11:10.422746.422746 lmp.py:414]   Expert 47 |    140 | CPU
DEBUG 01-06 17:11:10.422958.422958 lmp.py:414]   Expert 63 |    140 | CPU
DEBUG 01-06 17:11:10.422409.422409 lmp.py:414]   Expert 53 |    141 | CPU
DEBUG 01-06 17:11:10.422860.422860 lmp.py:414]   Expert  4 |    143 | CPU
DEBUG 01-06 17:11:10.422311.422311 lmp.py:414]   Expert 34 |    143 | CPU
DEBUG 01-06 17:11:10.422715.422715 lmp.py:414]   Expert 16 |    152 | CPU
DEBUG 01-06 17:11:10.422643.422643 lmp.py:414]   Expert 28 |    160 | CPU
DEBUG 01-06 17:11:10.422809.422809 lmp.py:414]   Expert 60 |    161 | CPU
DEBUG 01-06 17:11:10.422737.422737 lmp.py:414]   Expert 17 |    163 | CPU
DEBUG 01-06 17:11:10.422618.422618 lmp.py:414]   Expert 42 |    163 | CPU
DEBUG 01-06 17:11:10.422069.422069 lmp.py:414]   Expert 29 |    171 | CPU
DEBUG 01-06 17:11:10.422520.422520 lmp.py:414]   Expert 44 |    171 | CPU
DEBUG 01-06 17:11:10.422971.422971 lmp.py:414]   Expert 27 |    172 | CPU
DEBUG 01-06 17:11:10.422660.422660 lmp.py:414]   Expert  9 |    176 | CPU
DEBUG 01-06 17:11:10.422634.422634 lmp.py:414]   Expert 41 |    177 | CPU
DEBUG 01-06 17:11:10.422562.422562 lmp.py:414]   Expert  7 |    179 | GPU
DEBUG 01-06 17:11:10.422013.422013 lmp.py:414]   Expert 48 |    182 | GPU
DEBUG 01-06 17:11:10.422702.422702 lmp.py:414]   Expert 56 |    187 | GPU
DEBUG 01-06 17:11:10.422345.422345 lmp.py:414]   Expert  2 |    189 | GPU
DEBUG 01-06 17:11:10.422511.422511 lmp.py:414]   Expert  3 |    191 | GPU
DEBUG 01-06 17:11:10.422677.422677 lmp.py:414]   Expert 24 |    193 | GPU
DEBUG 01-06 17:11:10.422843.422843 lmp.py:414]   Expert 15 |    196 | GPU
DEBUG 01-06 17:11:10.422248.422248 lmp.py:414]   Expert  0 |    197 | GPU
DEBUG 01-06 17:11:10.422699.422699 lmp.py:414]   Expert 18 |    206 | GPU
DEBUG 01-06 17:11:10.422150.422150 lmp.py:414]   Expert 55 |    209 | GPU
DEBUG 01-06 17:11:10.422077.422077 lmp.py:414]   Expert 40 |    211 | GPU
DEBUG 01-06 17:11:10.422767.422767 lmp.py:414]   Expert 22 |    212 | GPU
DEBUG 01-06 17:11:10.422456.422456 lmp.py:414]   Expert 23 |    217 | GPU
DEBUG 01-06 17:11:10.422669.422669 lmp.py:414]   Expert 38 |    217 | GPU
DEBUG 01-06 17:11:10.422358.422358 lmp.py:414]   Expert 37 |    221 | GPU
DEBUG 01-06 17:11:10.422762.422762 lmp.py:414]   Expert  6 |    227 | GPU
DEBUG 01-06 17:11:10.422167.422167 lmp.py:414]   Expert 46 |    232 | GPU
DEBUG 01-06 17:11:10.422333.422333 lmp.py:414]   Expert 19 |    243 | GPU
DEBUG 01-06 17:11:10.422499.422499 lmp.py:414]   Expert 39 |    249 | GPU
DEBUG 01-06 17:11:10.422381.422381 lmp.py:414]   Expert 25 |    252 | GPU
DEBUG 01-06 17:11:10.422070.422070 lmp.py:414]   Expert 12 |    259 | GPU
DEBUG 01-06 17:11:10.422998.422998 lmp.py:414]   Expert 50 |    267 | GPU
DEBUG 01-06 17:11:10.422210.422210 lmp.py:414]   Expert 62 |    268 | GPU
DEBUG 01-06 17:11:10.422899.422899 lmp.py:414]   Expert 21 |    280 | GPU
DEBUG 01-06 17:11:10.422589.422589 lmp.py:414]   Expert 35 |    289 | GPU
DEBUG 01-06 17:11:10.422040.422040 lmp.py:414]   Expert 49 |    291 | GPU
DEBUG 01-06 17:11:10.422729.422729 lmp.py:414]   Expert 33 |    294 | GPU
DEBUG 01-06 17:11:10.422941.422941 lmp.py:414]   Expert 52 |    296 | GPU
DEBUG 01-06 17:11:10.422108.422108 lmp.py:414]   Expert  1 |    345 | GPU
DEBUG 01-06 17:11:10.422512.422512 lmp.py:414]   Expert  5 |    378 | GPU
DEBUG 01-06 17:11:10.422678.422678 lmp.py:414]   Expert 43 |    439 | GPU
DEBUG 01-06 17:11:10.422844.422844 lmp.py:414]   Expert 59 |    583 | GPU
DEBUG 01-06 17:11:10.422726.422726 lmp.py:415] 
DEBUG 01-06 17:11:10.422726.422726 lmp.py:415]   CPU total tokens: 4089 (33.3%)
DEBUG 01-06 17:11:10.422607.422607 lmp.py:416]   GPU total tokens: 8199 (66.7%)
DEBUG 01-06 17:11:10.422780.422780 cuda_h.py:19] end experts_map_get cost 0.0015137195587158203 seconds
DEBUG 01-06 17:11:10.422661.422661 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-06 17:11:10.422676.422676 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 17:11:10.423144.423144 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 17:11:10.424452.424452 cuda_h.py:19] end allocate_cuda_memory cost 0.0016322135925292969 seconds
DEBUG 01-06 17:11:10.424917.424917 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 17:11:10.424197.424197 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 17:11:10.424006.424006 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 17:11:10.424086.424086 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 8068d3e5-4023-49cb-b147-add0004cac34
DEBUG 01-06 17:11:10.425490.425490 client.py:106] call stub.LoadModelAsync
INFO 01-06 17:11:10.426490.426490 client.py:127] Model loaded
DEBUG 01-06 17:11:10.426665.426665 cuda_h.py:19] end sllm_worker_task cost 0.010620594024658203 seconds
INFO 01-06 17:11:10.427600.427600 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 8068d3e5-4023-49cb-b147-add0004cac34
DEBUG 01-06 17:11:10.427781.427781 cuda_h.py:19] end load_into_gpu_async cost 0.0032019615173339844 seconds
DEBUG 01-06 17:11:10.428484.428484 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 17:11:10.428419.428419 cuda_h.py:19] end restore_tensors2 cost 0.000415802001953125 seconds
DEBUG 01-06 17:11:10.428832.428832 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0056040287017822266 seconds
DEBUG 01-06 17:11:10.431142.431142 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.008193731307983398 seconds
DEBUG 01-06 17:11:10.431402.431402 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-06 17:11:10.431716.431716 lmp.py:461] 
DEBUG 01-06 17:11:10.431716.431716 lmp.py:461]   Computing 32 experts on CPU...
DEBUG 01-06 17:11:10.431182.431182 cuda_h.py:19] end cpu_experts_submit cost 0.00011086463928222656 seconds
DEBUG 01-06 17:11:10.431355.431355 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-06 17:11:10.437115.437115 mlpmodule.py:706] group tensors cost 0.006439924240112305 s
DEBUG 01-06 17:11:10.441348.441348 mlpmodule.py:744] pad cost 0.002679109573364258 s
DEBUG 01-06 17:11:10.441691.441691 mlpmodule.py:750] create cpu tensor cost 6.651878356933594e-05 s
DEBUG 01-06 17:11:10.441343.441343 mlpmodule.py:755] move to cpu cost 4.7206878662109375e-05 s
DEBUG 01-06 17:11:10.451159.451159 mlpmodule.py:769] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-06 17:11:10.451427.451427 mlpmodule.py:770] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-06 17:11:10.451304.451304 mlpmodule.py:775] group_w3 first element: 0.0086669921875
WARNING 01-06 17:11:10.451090.451090 mlpmodule.py:785] start einsum2
DEBUG 01-06 17:11:10.467498.467498 mlpmodule.py:795] group einsum cost 0.025928258895874023 s
DEBUG 01-06 17:11:10.468632.468632 mlpmodule.py:803] cpy2cputensor cost 0.0007076263427734375 s
DEBUG 01-06 17:11:10.474512.474512 cuda_h.py:19] end wait_cetm_experts cost 0.04357123374938965 seconds
DEBUG 01-06 17:11:10.475108.475108 cuda_h.py:10] start gpu_sexperts
DEBUG 01-06 17:11:10.475269.475269 cuda_h.py:19] end gpu_sexperts cost 0.0006020069122314453 seconds
DEBUG 01-06 17:11:10.475880.475880 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-06 17:11:10.475796.475796 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.5033950805664062e-05 seconds
DEBUG 01-06 17:11:10.475453.475453 cuda_h.py:10] start wait_experts
INFO 01-06 17:11:10.475640.475640 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 8068d3e5-4023-49cb-b147-add0004cac34
INFO 01-06 17:11:10.481995.481995 client.py:127] Model loaded
DEBUG 01-06 17:11:10.481322.481322 cuda_h.py:19] end wait_experts cost 0.005139827728271484 seconds
DEBUG 01-06 17:11:10.481170.481170 cuda_h.py:10] start gpu_experts
DEBUG 01-06 17:11:10.481688.481688 lmp.py:506]   Computing 32 experts on GPU...
DEBUG 01-06 17:11:10.481005.481005 mlpmodule.py:533] gpu group tensors cost 0.0006694793701171875 s
DEBUG 01-06 17:11:10.485614.485614 mlpmodule.py:664]  experts func einsum cost 0.054009199142456055 s
DEBUG 01-06 17:11:10.487375.487375 mlpmodule.py:566] gpu pad cost 0.005044460296630859 s
DEBUG 01-06 17:11:10.487384.487384 mlpmodule.py:584] gpu group einsum cost 0.0007748603820800781 s
DEBUG 01-06 17:11:10.490143.490143 mlpmodule.py:613] gpu experts func einsum cost 0.009552478790283203 s
DEBUG 01-06 17:11:10.490325.490325 cuda_h.py:19] end gpu_experts cost 0.009741783142089844 seconds
DEBUG 01-06 17:11:10.491864.491864 cuda_h.py:19] end layer_moe_generate_4 cost 0.07045292854309082 seconds
DEBUG 01-06 17:11:10.491923.491923 lmp.py:220] -------------------------------- end layer 4 --------------------------------
DEBUG 01-06 17:11:10.491779.491779 lmp.py:176] -------------------------------- start layer 5 --------------------------------
DEBUG 01-06 17:11:10.491091.491091 cuda_h.py:10] start start_load_qkvogn_s_weight_l_6
DEBUG 01-06 17:11:10.491893.491893 cuda_h.py:10] start start_load_qkvogn_s_weight_l_6
DEBUG 01-06 17:11:10.491518.491518 cuda_h.py:19] end start_load_qkvogn_s_weight_l_6 cost 3.2901763916015625e-05 seconds
DEBUG 01-06 17:11:10.491029.491029 cuda_h.py:19] end start_load_qkvogn_s_weight_l_6 cost 6.389617919921875e-05 seconds
DEBUG 01-06 17:11:10.491387.491387 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-06 17:11:10.491383.491383 mlpmodule.py:367] cuda:1 cuda:1
DEBUG 01-06 17:11:10.491697.491697 cuda_h.py:10] start sllm_worker_task
DEBUG 01-06 17:11:10.491376.491376 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 17:11:10.491690.491690 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 17:11:10.491069.491069 cuda_h.py:19] end allocate_cuda_memory cost 0.00020885467529296875 seconds
DEBUG 01-06 17:11:10.492700.492700 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 17:11:10.492993.492993 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 17:11:10.492862.492862 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 17:11:10.492611.492611 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 1110c43d-898b-4fb7-b214-b81e31775132
DEBUG 01-06 17:11:10.492581.492581 client.py:106] call stub.LoadModelAsync
DEBUG 01-06 17:11:10.492053.492053 cuda_h.py:10] start self_attn
INFO 01-06 17:11:10.493561.493561 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 1110c43d-898b-4fb7-b214-b81e31775132
DEBUG 01-06 17:11:10.493729.493729 cuda_h.py:19] end load_into_gpu_async cost 0.0015954971313476562 seconds
DEBUG 01-06 17:11:10.493524.493524 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 17:11:10.493892.493892 cuda_h.py:19] end restore_tensors2 cost 6.890296936035156e-05 seconds
DEBUG 01-06 17:11:10.493217.493217 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.002129793167114258 seconds
INFO 01-06 17:11:10.493285.493285 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 1110c43d-898b-4fb7-b214-b81e31775132
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-06 17:11:10.495593.495593 cuda_h.py:19] end self_attn cost 0.0028290748596191406 seconds
DEBUG 01-06 17:11:10.495709.495709 cuda_h.py:19] end iln_self_attn_paln cost 0.004247426986694336 seconds
DEBUG 01-06 17:11:10.495883.495883 cuda_h.py:10] start layer_moe_generate_5
DEBUG 01-06 17:11:10.495931.495931 cuda_h.py:10] start gate
DEBUG 01-06 17:11:10.496027.496027 cuda_h.py:19] end gate cost 0.0006537437438964844 seconds
DEBUG 01-06 17:11:10.496095.496095 cuda_h.py:10] start experts_map_get
DEBUG 01-06 17:11:10.496774.496774 lmp.py:403] 
DEBUG 01-06 17:11:10.496774.496774 lmp.py:403] Expert Token Distribution & Device Allocation:
DEBUG 01-06 17:11:10.496814.496814 lmp.py:404]   Total experts: 64
DEBUG 01-06 17:11:10.496226.496226 lmp.py:405]   CPU experts: 32 (50%)
DEBUG 01-06 17:11:10.496299.496299 lmp.py:406]   GPU experts: 32 (50%)
DEBUG 01-06 17:11:10.496988.496988 lmp.py:407] 
DEBUG 01-06 17:11:10.496988.496988 lmp.py:407]   Expert ID | Tokens | Device
DEBUG 01-06 17:11:10.496155.496155 lmp.py:408]   -----------------------------------
DEBUG 01-06 17:11:10.496665.496665 lmp.py:414]   Expert 34 |     23 | CPU
DEBUG 01-06 17:11:10.496547.496547 lmp.py:414]   Expert 45 |     59 | CPU
DEBUG 01-06 17:11:10.496236.496236 lmp.py:414]   Expert 57 |     72 | CPU
DEBUG 01-06 17:11:10.496402.496402 lmp.py:414]   Expert 22 |     75 | CPU
DEBUG 01-06 17:11:10.497853.497853 lmp.py:414]   Expert 17 |     97 | CPU
DEBUG 01-06 17:11:10.497827.497827 lmp.py:414]   Expert  4 |     99 | CPU
DEBUG 01-06 17:11:10.497040.497040 lmp.py:414]   Expert 15 |    102 | CPU
DEBUG 01-06 17:11:10.497491.497491 lmp.py:414]   Expert 28 |    104 | CPU
DEBUG 01-06 17:11:10.497226.497226 lmp.py:414]   Expert 60 |    116 | CPU
DEBUG 01-06 17:11:10.497200.497200 lmp.py:414]   Expert 32 |    117 | CPU
DEBUG 01-06 17:11:10.497797.497797 lmp.py:414]   Expert 52 |    124 | CPU
DEBUG 01-06 17:11:10.497725.497725 lmp.py:414]   Expert 36 |    126 | CPU
DEBUG 01-06 17:11:10.497414.497414 lmp.py:414]   Expert 14 |    127 | CPU
DEBUG 01-06 17:11:10.497342.497342 lmp.py:414]   Expert 25 |    128 | CPU
DEBUG 01-06 17:11:10.497031.497031 lmp.py:414]   Expert 12 |    130 | CPU
DEBUG 01-06 17:11:10.497581.497581 lmp.py:414]   Expert 16 |    130 | CPU
DEBUG 01-06 17:11:10.497270.497270 lmp.py:414]   Expert  8 |    131 | CPU
DEBUG 01-06 17:11:10.497245.497245 lmp.py:414]   Expert  2 |    135 | CPU
DEBUG 01-06 17:11:10.497695.497695 lmp.py:414]   Expert 35 |    143 | CPU
DEBUG 01-06 17:11:10.497669.497669 lmp.py:414]   Expert  5 |    149 | CPU
DEBUG 01-06 17:11:10.497644.497644 lmp.py:414]   Expert 61 |    155 | CPU
DEBUG 01-06 17:11:10.497618.497618 lmp.py:414]   Expert 39 |    157 | CPU
DEBUG 01-06 17:11:10.497592.497592 lmp.py:414]   Expert 23 |    159 | CPU
DEBUG 01-06 17:11:10.497042.497042 lmp.py:414]   Expert 30 |    159 | CPU
DEBUG 01-06 17:11:10.497970.497970 lmp.py:414]   Expert  0 |    163 | CPU
DEBUG 01-06 17:11:10.497898.497898 lmp.py:414]   Expert 42 |    166 | CPU
DEBUG 01-06 17:11:10.497349.497349 lmp.py:414]   Expert 13 |    167 | CPU
DEBUG 01-06 17:11:10.497515.497515 lmp.py:414]   Expert 31 |    171 | CPU
DEBUG 01-06 17:11:10.497489.497489 lmp.py:414]   Expert 41 |    173 | CPU
DEBUG 01-06 17:11:10.497225.497225 lmp.py:414]   Expert  3 |    174 | CPU
DEBUG 01-06 17:11:10.497960.497960 lmp.py:414]   Expert 44 |    174 | CPU
DEBUG 01-06 17:11:10.497696.497696 lmp.py:414]   Expert 46 |    174 | CPU
DEBUG 01-06 17:11:10.497908.497908 lmp.py:414]   Expert  9 |    177 | GPU
DEBUG 01-06 17:11:10.497406.497406 lmp.py:414]   Expert 43 |    185 | GPU
DEBUG 01-06 17:11:10.497380.497380 lmp.py:414]   Expert 62 |    186 | GPU
DEBUG 01-06 17:11:10.497877.497877 lmp.py:414]   Expert 51 |    189 | GPU
DEBUG 01-06 17:11:10.497612.497612 lmp.py:414]   Expert 26 |    192 | GPU
DEBUG 01-06 17:11:10.497063.497063 lmp.py:414]   Expert 27 |    192 | GPU
DEBUG 01-06 17:11:10.497991.497991 lmp.py:414]   Expert 50 |    194 | GPU
DEBUG 01-06 17:11:10.497680.497680 lmp.py:414]   Expert 18 |    195 | GPU
DEBUG 01-06 17:11:10.497131.497131 lmp.py:414]   Expert 49 |    198 | GPU
DEBUG 01-06 17:11:10.497297.497297 lmp.py:414]   Expert 19 |    199 | GPU
DEBUG 01-06 17:11:10.497033.497033 lmp.py:414]   Expert 47 |    199 | GPU
DEBUG 01-06 17:11:10.497769.497769 lmp.py:414]   Expert 55 |    202 | GPU
DEBUG 01-06 17:11:10.497981.497981 lmp.py:414]   Expert 11 |    203 | GPU
DEBUG 01-06 17:11:10.497955.497955 lmp.py:414]   Expert 20 |    203 | GPU
DEBUG 01-06 17:11:10.497691.497691 lmp.py:414]   Expert 56 |    210 | GPU
DEBUG 01-06 17:11:10.497188.497188 lmp.py:414]   Expert 63 |    214 | GPU
DEBUG 01-06 17:11:10.497162.497162 lmp.py:414]   Expert 38 |    217 | GPU
DEBUG 01-06 17:11:10.497659.497659 lmp.py:414]   Expert 48 |    230 | GPU
DEBUG 01-06 17:11:10.497633.497633 lmp.py:414]   Expert 10 |    239 | GPU
DEBUG 01-06 17:11:10.497369.497369 lmp.py:414]   Expert  1 |    240 | GPU
DEBUG 01-06 17:11:10.497820.497820 lmp.py:414]   Expert 54 |    241 | GPU
DEBUG 01-06 17:11:10.497271.497271 lmp.py:414]   Expert  7 |    242 | GPU
DEBUG 01-06 17:11:10.497722.497722 lmp.py:414]   Expert 21 |    253 | GPU
DEBUG 01-06 17:11:10.497172.497172 lmp.py:414]   Expert 29 |    259 | GPU
DEBUG 01-06 17:11:10.497385.497385 lmp.py:414]   Expert 33 |    260 | GPU
DEBUG 01-06 17:11:10.497882.497882 lmp.py:414]   Expert 24 |    270 | GPU
DEBUG 01-06 17:11:10.497618.497618 lmp.py:414]   Expert 40 |    270 | GPU
DEBUG 01-06 17:11:10.497876.497876 lmp.py:414]   Expert 59 |    292 | GPU
DEBUG 01-06 17:11:10.497612.497612 lmp.py:414]   Expert 37 |    338 | GPU
DEBUG 01-06 17:11:10.497871.497871 lmp.py:414]   Expert 58 |    365 | GPU
DEBUG 01-06 17:11:10.497845.497845 lmp.py:414]   Expert  6 |    388 | GPU
DEBUG 01-06 17:11:10.497342.497342 lmp.py:414]   Expert 53 |    867 | GPU
DEBUG 01-06 17:11:10.497793.497793 lmp.py:415] 
DEBUG 01-06 17:11:10.497793.497793 lmp.py:415]   CPU total tokens: 4179 (34.0%)
DEBUG 01-06 17:11:10.498721.498721 lmp.py:416]   GPU total tokens: 8109 (66.0%)
DEBUG 01-06 17:11:10.498940.498940 cuda_h.py:19] end experts_map_get cost 0.0014739036560058594 seconds
DEBUG 01-06 17:11:10.498821.498821 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-06 17:11:10.498790.498790 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 17:11:10.498073.498073 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 17:11:10.500121.500121 cuda_h.py:19] end allocate_cuda_memory cost 0.0017943382263183594 seconds
DEBUG 01-06 17:11:10.500792.500792 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 17:11:10.500356.500356 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 17:11:10.500595.500595 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 17:11:10.500722.500722 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, acbb1977-c3e6-4deb-a72e-de8bd550ac72
DEBUG 01-06 17:11:10.500464.500464 client.py:106] call stub.LoadModelAsync
INFO 01-06 17:11:10.501644.501644 client.py:127] Model loaded
DEBUG 01-06 17:11:10.502011.502011 cuda_h.py:19] end sllm_worker_task cost 0.010651588439941406 seconds
INFO 01-06 17:11:10.503712.503712 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, acbb1977-c3e6-4deb-a72e-de8bd550ac72
DEBUG 01-06 17:11:10.503578.503578 cuda_h.py:19] end load_into_gpu_async cost 0.0034449100494384766 seconds
DEBUG 01-06 17:11:10.503462.503462 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 17:11:10.504399.504399 cuda_h.py:19] end restore_tensors2 cost 0.0004477500915527344 seconds
DEBUG 01-06 17:11:10.504381.504381 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.006171703338623047 seconds
DEBUG 01-06 17:11:10.506953.506953 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.008848190307617188 seconds
DEBUG 01-06 17:11:10.506352.506352 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-06 17:11:10.507931.507931 lmp.py:461] 
DEBUG 01-06 17:11:10.507931.507931 lmp.py:461]   Computing 32 experts on CPU...
DEBUG 01-06 17:11:10.507681.507681 cuda_h.py:19] end cpu_experts_submit cost 0.00011038780212402344 seconds
DEBUG 01-06 17:11:10.507331.507331 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-06 17:11:10.525684.525684 mlpmodule.py:706] group tensors cost 0.01772618293762207 s
DEBUG 01-06 17:11:10.528955.528955 mlpmodule.py:744] pad cost 0.002124309539794922 s
DEBUG 01-06 17:11:10.528899.528899 mlpmodule.py:750] create cpu tensor cost 7.081031799316406e-05 s
DEBUG 01-06 17:11:10.528054.528054 mlpmodule.py:755] move to cpu cost 4.172325134277344e-05 s
DEBUG 01-06 17:11:10.539850.539850 mlpmodule.py:769] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-06 17:11:10.539111.539111 mlpmodule.py:770] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-06 17:11:10.539650.539650 mlpmodule.py:775] group_w3 first element: 0.03369140625
WARNING 01-06 17:11:10.539628.539628 mlpmodule.py:785] start einsum2
DEBUG 01-06 17:11:10.556213.556213 mlpmodule.py:795] group einsum cost 0.02822589874267578 s
DEBUG 01-06 17:11:10.557962.557962 mlpmodule.py:803] cpy2cputensor cost 0.000682830810546875 s
DEBUG 01-06 17:11:10.563981.563981 cuda_h.py:19] end wait_cetm_experts cost 0.056505680084228516 seconds
DEBUG 01-06 17:11:10.563285.563285 cuda_h.py:10] start gpu_sexperts
DEBUG 01-06 17:11:10.564785.564785 cuda_h.py:19] end gpu_sexperts cost 0.0006406307220458984 seconds
DEBUG 01-06 17:11:10.564635.564635 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-06 17:11:10.564200.564200 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.5510787963867188e-05 seconds
DEBUG 01-06 17:11:10.564333.564333 cuda_h.py:10] start wait_experts
INFO 01-06 17:11:10.564566.564566 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, acbb1977-c3e6-4deb-a72e-de8bd550ac72
INFO 01-06 17:11:10.566273.566273 client.py:127] Model loaded
DEBUG 01-06 17:11:10.566116.566116 cuda_h.py:19] end wait_experts cost 0.0013890266418457031 seconds
DEBUG 01-06 17:11:10.566772.566772 cuda_h.py:10] start gpu_experts
DEBUG 01-06 17:11:10.566098.566098 lmp.py:506]   Computing 32 experts on GPU...
DEBUG 01-06 17:11:10.566308.566308 mlpmodule.py:533] gpu group tensors cost 0.0006639957427978516 s
DEBUG 01-06 17:11:10.573812.573812 mlpmodule.py:566] gpu pad cost 0.006875038146972656 s
DEBUG 01-06 17:11:10.575372.575372 mlpmodule.py:664]  experts func einsum cost 0.06838297843933105 s
DEBUG 01-06 17:11:10.576948.576948 mlpmodule.py:584] gpu group einsum cost 0.0027937889099121094 s
DEBUG 01-06 17:11:10.579368.579368 mlpmodule.py:613] gpu experts func einsum cost 0.01331186294555664 s
DEBUG 01-06 17:11:10.579920.579920 cuda_h.py:19] end gpu_experts cost 0.01349496841430664 seconds
DEBUG 01-06 17:11:10.579367.579367 cuda_h.py:19] end layer_moe_generate_5 cost 0.08403491973876953 seconds
DEBUG 01-06 17:11:10.579995.579995 lmp.py:220] -------------------------------- end layer 5 --------------------------------
DEBUG 01-06 17:11:10.580281.580281 lmp.py:176] -------------------------------- start layer 6 --------------------------------
DEBUG 01-06 17:11:10.580355.580355 cuda_h.py:10] start start_load_qkvogn_s_weight_l_7
DEBUG 01-06 17:11:10.580085.580085 cuda_h.py:10] start start_load_qkvogn_s_weight_l_7
DEBUG 01-06 17:11:10.580736.580736 cuda_h.py:19] end start_load_qkvogn_s_weight_l_7 cost 3.147125244140625e-05 seconds
DEBUG 01-06 17:11:10.580200.580200 cuda_h.py:19] end start_load_qkvogn_s_weight_l_7 cost 6.365776062011719e-05 seconds
DEBUG 01-06 17:11:10.580274.580274 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-06 17:11:10.580197.580197 mlpmodule.py:367] cuda:1 cuda:1
DEBUG 01-06 17:11:10.580517.580517 cuda_h.py:10] start sllm_worker_task
DEBUG 01-06 17:11:10.580482.580482 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 17:11:10.580133.580133 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 17:11:10.580094.580094 cuda_h.py:19] end allocate_cuda_memory cost 0.0001811981201171875 seconds
DEBUG 01-06 17:11:10.580918.580918 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 17:11:10.580012.580012 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 17:11:10.580689.580689 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 17:11:10.580968.580968 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 4297ddba-4bd3-4f82-8f66-ad49e94f6a6f
DEBUG 01-06 17:11:10.581653.581653 client.py:106] call stub.LoadModelAsync
DEBUG 01-06 17:11:10.581760.581760 cuda_h.py:10] start self_attn
INFO 01-06 17:11:10.582354.582354 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 4297ddba-4bd3-4f82-8f66-ad49e94f6a6f
DEBUG 01-06 17:11:10.582806.582806 cuda_h.py:19] end load_into_gpu_async cost 0.0015685558319091797 seconds
DEBUG 01-06 17:11:10.582887.582887 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 17:11:10.582923.582923 cuda_h.py:19] end restore_tensors2 cost 7.081031799316406e-05 seconds
DEBUG 01-06 17:11:10.582024.582024 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.002083301544189453 seconds
INFO 01-06 17:11:10.582091.582091 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 4297ddba-4bd3-4f82-8f66-ad49e94f6a6f
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-06 17:11:10.584322.584322 cuda_h.py:19] end self_attn cost 0.0028803348541259766 seconds
DEBUG 01-06 17:11:10.584895.584895 cuda_h.py:19] end iln_self_attn_paln cost 0.0042912960052490234 seconds
DEBUG 01-06 17:11:10.584738.584738 cuda_h.py:10] start layer_moe_generate_6
DEBUG 01-06 17:11:10.584647.584647 cuda_h.py:10] start gate
DEBUG 01-06 17:11:10.585902.585902 cuda_h.py:19] end gate cost 0.0006451606750488281 seconds
DEBUG 01-06 17:11:10.585777.585777 cuda_h.py:10] start experts_map_get
DEBUG 01-06 17:11:10.585410.585410 lmp.py:403] 
DEBUG 01-06 17:11:10.585410.585410 lmp.py:403] Expert Token Distribution & Device Allocation:
DEBUG 01-06 17:11:10.585973.585973 lmp.py:404]   Total experts: 64
DEBUG 01-06 17:11:10.585862.585862 lmp.py:405]   CPU experts: 32 (50%)
DEBUG 01-06 17:11:10.585174.585174 lmp.py:406]   GPU experts: 32 (50%)
DEBUG 01-06 17:11:10.585578.585578 lmp.py:407] 
DEBUG 01-06 17:11:10.585578.585578 lmp.py:407]   Expert ID | Tokens | Device
DEBUG 01-06 17:11:10.585698.585698 lmp.py:408]   -----------------------------------
DEBUG 01-06 17:11:10.585825.585825 lmp.py:414]   Expert  1 |     44 | CPU
DEBUG 01-06 17:11:10.585468.585468 lmp.py:414]   Expert  7 |     59 | CPU
DEBUG 01-06 17:11:10.585157.585157 lmp.py:414]   Expert 18 |     76 | CPU
DEBUG 01-06 17:11:10.585369.585369 lmp.py:414]   Expert 37 |     77 | CPU
DEBUG 01-06 17:11:10.585105.585105 lmp.py:414]   Expert 54 |     78 | CPU
DEBUG 01-06 17:11:10.585841.585841 lmp.py:414]   Expert 17 |     84 | CPU
DEBUG 01-06 17:11:10.585338.585338 lmp.py:414]   Expert  9 |     91 | CPU
DEBUG 01-06 17:11:10.585312.585312 lmp.py:414]   Expert 13 |     94 | CPU
DEBUG 01-06 17:11:10.585524.585524 lmp.py:414]   Expert 22 |     99 | CPU
DEBUG 01-06 17:11:10.585737.585737 lmp.py:414]   Expert 58 |    104 | CPU
DEBUG 01-06 17:11:10.585426.585426 lmp.py:414]   Expert  0 |    109 | CPU
DEBUG 01-06 17:11:10.585115.585115 lmp.py:414]   Expert 16 |    115 | CPU
DEBUG 01-06 17:11:10.585281.585281 lmp.py:414]   Expert 26 |    115 | CPU
DEBUG 01-06 17:11:10.585163.585163 lmp.py:414]   Expert 10 |    128 | CPU
DEBUG 01-06 17:11:10.585091.585091 lmp.py:414]   Expert 63 |    131 | CPU
DEBUG 01-06 17:11:10.586018.586018 lmp.py:414]   Expert 59 |    132 | CPU
DEBUG 01-06 17:11:10.586946.586946 lmp.py:414]   Expert 43 |    143 | CPU
DEBUG 01-06 17:11:10.586397.586397 lmp.py:414]   Expert 33 |    144 | CPU
DEBUG 01-06 17:11:10.586086.586086 lmp.py:414]   Expert 62 |    144 | CPU
DEBUG 01-06 17:11:10.586775.586775 lmp.py:414]   Expert 28 |    150 | CPU
DEBUG 01-06 17:11:10.586226.586226 lmp.py:414]   Expert 29 |    154 | CPU
DEBUG 01-06 17:11:10.586869.586869 lmp.py:414]   Expert  2 |    159 | CPU
DEBUG 01-06 17:11:10.586274.586274 lmp.py:414]   Expert 45 |    160 | CPU
DEBUG 01-06 17:11:10.586963.586963 lmp.py:414]   Expert 55 |    160 | CPU
DEBUG 01-06 17:11:10.586129.586129 lmp.py:414]   Expert  3 |    161 | CPU
DEBUG 01-06 17:11:10.586295.586295 lmp.py:414]   Expert 23 |    166 | CPU
DEBUG 01-06 17:11:10.586985.586985 lmp.py:414]   Expert 51 |    166 | CPU
DEBUG 01-06 17:11:10.586436.586436 lmp.py:414]   Expert 14 |    167 | CPU
DEBUG 01-06 17:11:10.586648.586648 lmp.py:414]   Expert 32 |    169 | CPU
DEBUG 01-06 17:11:10.586337.586337 lmp.py:414]   Expert 11 |    170 | CPU
DEBUG 01-06 17:11:10.586311.586311 lmp.py:414]   Expert 34 |    170 | CPU
DEBUG 01-06 17:11:10.586762.586762 lmp.py:414]   Expert 53 |    170 | CPU
DEBUG 01-06 17:11:10.586213.586213 lmp.py:414]   Expert 40 |    177 | GPU
DEBUG 01-06 17:11:10.586664.586664 lmp.py:414]   Expert 52 |    180 | GPU
DEBUG 01-06 17:11:10.586115.586115 lmp.py:414]   Expert 41 |    184 | GPU
DEBUG 01-06 17:11:10.586566.586566 lmp.py:414]   Expert 42 |    186 | GPU
DEBUG 01-06 17:11:10.586970.586970 lmp.py:414]   Expert 21 |    187 | GPU
DEBUG 01-06 17:11:10.586898.586898 lmp.py:414]   Expert 57 |    189 | GPU
DEBUG 01-06 17:11:10.586064.586064 lmp.py:414]   Expert 30 |    201 | GPU
DEBUG 01-06 17:11:10.586230.586230 lmp.py:414]   Expert 15 |    202 | GPU
DEBUG 01-06 17:11:10.586681.586681 lmp.py:414]   Expert 35 |    204 | GPU
DEBUG 01-06 17:11:10.586371.586371 lmp.py:414]   Expert 12 |    217 | GPU
DEBUG 01-06 17:11:10.586821.586821 lmp.py:414]   Expert  4 |    219 | GPU
DEBUG 01-06 17:11:10.586272.586272 lmp.py:414]   Expert 50 |    225 | GPU
DEBUG 01-06 17:11:10.586485.586485 lmp.py:414]   Expert 24 |    231 | GPU
DEBUG 01-06 17:11:10.586936.586936 lmp.py:414]   Expert  8 |    232 | GPU
DEBUG 01-06 17:11:10.586923.586923 lmp.py:414]   Expert 44 |    232 | GPU
DEBUG 01-06 17:11:10.586613.586613 lmp.py:414]   Expert 46 |    232 | GPU
DEBUG 01-06 17:11:10.586064.586064 lmp.py:414]   Expert 19 |    233 | GPU
DEBUG 01-06 17:11:10.586514.586514 lmp.py:414]   Expert 49 |    234 | GPU
DEBUG 01-06 17:11:10.586204.586204 lmp.py:414]   Expert 38 |    238 | GPU
DEBUG 01-06 17:11:10.586178.586178 lmp.py:414]   Expert 47 |    245 | GPU
DEBUG 01-06 17:11:10.586913.586913 lmp.py:414]   Expert  6 |    248 | GPU
DEBUG 01-06 17:11:10.586411.586411 lmp.py:414]   Expert 31 |    255 | GPU
DEBUG 01-06 17:11:10.586146.586146 lmp.py:414]   Expert 61 |    262 | GPU
DEBUG 01-06 17:11:10.586643.586643 lmp.py:414]   Expert 39 |    279 | GPU
DEBUG 01-06 17:11:10.586379.586379 lmp.py:414]   Expert  5 |    302 | GPU
DEBUG 01-06 17:11:10.586876.586876 lmp.py:414]   Expert 36 |    306 | GPU
DEBUG 01-06 17:11:10.586850.586850 lmp.py:414]   Expert 27 |    315 | GPU
DEBUG 01-06 17:11:10.586586.586586 lmp.py:414]   Expert 60 |    335 | GPU
DEBUG 01-06 17:11:10.586798.586798 lmp.py:414]   Expert 20 |    338 | GPU
DEBUG 01-06 17:11:10.586772.586772 lmp.py:414]   Expert 48 |    359 | GPU
DEBUG 01-06 17:11:10.586985.586985 lmp.py:414]   Expert 25 |    395 | GPU
DEBUG 01-06 17:11:10.586436.586436 lmp.py:414]   Expert 56 |    557 | GPU
DEBUG 01-06 17:11:10.586125.586125 lmp.py:415] 
DEBUG 01-06 17:11:10.586125.586125 lmp.py:415]   CPU total tokens: 4089 (33.3%)
DEBUG 01-06 17:11:10.586814.586814 lmp.py:416]   GPU total tokens: 8199 (66.7%)
DEBUG 01-06 17:11:10.586557.586557 cuda_h.py:19] end experts_map_get cost 0.0014948844909667969 seconds
DEBUG 01-06 17:11:10.586723.586723 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-06 17:11:10.586499.586499 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 17:11:10.587921.587921 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 17:11:10.588151.588151 cuda_h.py:19] end allocate_cuda_memory cost 0.0016818046569824219 seconds
DEBUG 01-06 17:11:10.588345.588345 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 17:11:10.588055.588055 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 17:11:10.588433.588433 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 17:11:10.588560.588560 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 732c1511-0ad2-4c47-89da-cc9fc6493cb3
DEBUG 01-06 17:11:10.589626.589626 client.py:106] call stub.LoadModelAsync
INFO 01-06 17:11:10.590929.590929 client.py:127] Model loaded
DEBUG 01-06 17:11:10.591981.591981 cuda_h.py:19] end sllm_worker_task cost 0.010937690734863281 seconds
INFO 01-06 17:11:10.592954.592954 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 732c1511-0ad2-4c47-89da-cc9fc6493cb3
DEBUG 01-06 17:11:10.592012.592012 cuda_h.py:19] end load_into_gpu_async cost 0.003462076187133789 seconds
DEBUG 01-06 17:11:10.592600.592600 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 17:11:10.592568.592568 cuda_h.py:19] end restore_tensors2 cost 0.00036215782165527344 seconds
DEBUG 01-06 17:11:10.592597.592597 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.006052970886230469 seconds
DEBUG 01-06 17:11:10.595160.595160 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.008688688278198242 seconds
DEBUG 01-06 17:11:10.595420.595420 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-06 17:11:10.595238.595238 lmp.py:461] 
DEBUG 01-06 17:11:10.595238.595238 lmp.py:461]   Computing 32 experts on CPU...
DEBUG 01-06 17:11:10.595988.595988 cuda_h.py:19] end cpu_experts_submit cost 0.00010967254638671875 seconds
DEBUG 01-06 17:11:10.595161.595161 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-06 17:11:10.608977.608977 mlpmodule.py:706] group tensors cost 0.012472391128540039 s
DEBUG 01-06 17:11:10.611398.611398 mlpmodule.py:744] pad cost 0.0020754337310791016 s
DEBUG 01-06 17:11:10.611223.611223 mlpmodule.py:750] create cpu tensor cost 5.435943603515625e-05 s
DEBUG 01-06 17:11:10.611325.611325 mlpmodule.py:755] move to cpu cost 3.910064697265625e-05 s
DEBUG 01-06 17:11:10.621191.621191 mlpmodule.py:769] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-06 17:11:10.621068.621068 mlpmodule.py:770] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-06 17:11:10.621415.621415 mlpmodule.py:775] group_w3 first element: -0.003631591796875
WARNING 01-06 17:11:10.621293.621293 mlpmodule.py:785] start einsum2
DEBUG 01-06 17:11:10.638824.638824 mlpmodule.py:795] group einsum cost 0.02650761604309082 s
DEBUG 01-06 17:11:10.638262.638262 mlpmodule.py:803] cpy2cputensor cost 0.0006844997406005859 s
DEBUG 01-06 17:11:10.645586.645586 cuda_h.py:19] end wait_cetm_experts cost 0.04938912391662598 seconds
DEBUG 01-06 17:11:10.645003.645003 cuda_h.py:10] start gpu_sexperts
DEBUG 01-06 17:11:10.646813.646813 cuda_h.py:19] end gpu_sexperts cost 0.000621795654296875 seconds
DEBUG 01-06 17:11:10.646140.646140 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-06 17:11:10.646513.646513 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.4080276489257812e-05 seconds
DEBUG 01-06 17:11:10.646693.646693 cuda_h.py:10] start wait_experts
INFO 01-06 17:11:10.646118.646118 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 732c1511-0ad2-4c47-89da-cc9fc6493cb3
INFO 01-06 17:11:10.647931.647931 client.py:127] Model loaded
DEBUG 01-06 17:11:10.647966.647966 cuda_h.py:19] end wait_experts cost 0.0013992786407470703 seconds
DEBUG 01-06 17:11:10.647338.647338 cuda_h.py:10] start gpu_experts
DEBUG 01-06 17:11:10.647140.647140 lmp.py:506]   Computing 32 experts on GPU...
DEBUG 01-06 17:11:10.648073.648073 mlpmodule.py:533] gpu group tensors cost 0.0006687641143798828 s
DEBUG 01-06 17:11:10.650100.650100 mlpmodule.py:566] gpu pad cost 0.0017535686492919922 s
DEBUG 01-06 17:11:10.650353.650353 mlpmodule.py:584] gpu group einsum cost 0.0005779266357421875 s
DEBUG 01-06 17:11:10.654894.654894 mlpmodule.py:613] gpu experts func einsum cost 0.006609916687011719 s
DEBUG 01-06 17:11:10.654539.654539 cuda_h.py:19] end gpu_experts cost 0.006792306900024414 seconds
DEBUG 01-06 17:11:10.654238.654238 cuda_h.py:19] end layer_moe_generate_6 cost 0.0700693130493164 seconds
DEBUG 01-06 17:11:10.654000.654000 lmp.py:220] -------------------------------- end layer 6 --------------------------------
DEBUG 01-06 17:11:10.654538.654538 lmp.py:176] -------------------------------- start layer 7 --------------------------------
DEBUG 01-06 17:11:10.654539.654539 cuda_h.py:10] start start_load_qkvogn_s_weight_l_8
DEBUG 01-06 17:11:10.654341.654341 cuda_h.py:10] start start_load_qkvogn_s_weight_l_8
DEBUG 01-06 17:11:10.655039.655039 cuda_h.py:19] end start_load_qkvogn_s_weight_l_8 cost 3.218650817871094e-05 seconds
DEBUG 01-06 17:11:10.655524.655524 cuda_h.py:19] end start_load_qkvogn_s_weight_l_8 cost 7.843971252441406e-05 seconds
DEBUG 01-06 17:11:10.655597.655597 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-06 17:11:10.655778.655778 cuda_h.py:10] start sllm_worker_task
DEBUG 01-06 17:11:10.655452.655452 mlpmodule.py:367] cuda:1 cuda:1
DEBUG 01-06 17:11:10.655612.655612 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 17:11:10.655398.655398 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 17:11:10.657267.657267 cuda_h.py:19] end allocate_cuda_memory cost 0.0019676685333251953 seconds
DEBUG 01-06 17:11:10.657229.657229 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 17:11:10.657224.657224 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 17:11:10.657299.657299 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 17:11:10.657717.657717 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 1b981524-7029-4dec-8141-a15071f9e932
DEBUG 01-06 17:11:10.657249.657249 client.py:106] call stub.LoadModelAsync
DEBUG 01-06 17:11:10.658866.658866 mlpmodule.py:664]  experts func einsum cost 0.06198406219482422 s
DEBUG 01-06 17:11:10.658091.658091 cuda_h.py:10] start self_attn
INFO 01-06 17:11:10.659988.659988 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 1b981524-7029-4dec-8141-a15071f9e932
DEBUG 01-06 17:11:10.659639.659639 cuda_h.py:19] end load_into_gpu_async cost 0.0017075538635253906 seconds
DEBUG 01-06 17:11:10.659434.659434 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 17:11:10.659040.659040 cuda_h.py:19] end restore_tensors2 cost 6.937980651855469e-05 seconds
DEBUG 01-06 17:11:10.659088.659088 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.00400543212890625 seconds
INFO 01-06 17:11:10.659354.659354 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 1b981524-7029-4dec-8141-a15071f9e932
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-06 17:11:10.661229.661229 cuda_h.py:19] end self_attn cost 0.0028374195098876953 seconds
DEBUG 01-06 17:11:10.661146.661146 cuda_h.py:19] end iln_self_attn_paln cost 0.006485462188720703 seconds
DEBUG 01-06 17:11:10.661844.661844 cuda_h.py:10] start layer_moe_generate_7
DEBUG 01-06 17:11:10.661799.661799 cuda_h.py:10] start gate
DEBUG 01-06 17:11:10.662775.662775 cuda_h.py:19] end gate cost 0.0006415843963623047 seconds
DEBUG 01-06 17:11:10.662366.662366 cuda_h.py:10] start experts_map_get
DEBUG 01-06 17:11:10.662952.662952 lmp.py:403] 
DEBUG 01-06 17:11:10.662952.662952 lmp.py:403] Expert Token Distribution & Device Allocation:
DEBUG 01-06 17:11:10.662993.662993 lmp.py:404]   Total experts: 64
DEBUG 01-06 17:11:10.662404.662404 lmp.py:405]   CPU experts: 32 (50%)
DEBUG 01-06 17:11:10.662478.662478 lmp.py:406]   GPU experts: 32 (50%)
DEBUG 01-06 17:11:10.662028.662028 lmp.py:407] 
DEBUG 01-06 17:11:10.662028.662028 lmp.py:407]   Expert ID | Tokens | Device
DEBUG 01-06 17:11:10.662101.662101 lmp.py:408]   -----------------------------------
DEBUG 01-06 17:11:10.662135.662135 lmp.py:414]   Expert 50 |     46 | CPU
DEBUG 01-06 17:11:10.662494.662494 lmp.py:414]   Expert  3 |     58 | CPU
DEBUG 01-06 17:11:10.662137.662137 lmp.py:414]   Expert 46 |     60 | CPU
DEBUG 01-06 17:11:10.662303.662303 lmp.py:414]   Expert  1 |     78 | CPU
DEBUG 01-06 17:11:10.662992.662992 lmp.py:414]   Expert  4 |     87 | CPU
DEBUG 01-06 17:11:10.662920.662920 lmp.py:414]   Expert 29 |     91 | CPU
DEBUG 01-06 17:11:10.662848.662848 lmp.py:414]   Expert 15 |     98 | CPU
DEBUG 01-06 17:11:10.663775.663775 lmp.py:414]   Expert 40 |     98 | CPU
DEBUG 01-06 17:11:10.663372.663372 lmp.py:414]   Expert  8 |    104 | CPU
DEBUG 01-06 17:11:10.663776.663776 lmp.py:414]   Expert 41 |    110 | CPU
DEBUG 01-06 17:11:10.663419.663419 lmp.py:414]   Expert 28 |    116 | CPU
DEBUG 01-06 17:11:10.663539.663539 lmp.py:414]   Expert  7 |    129 | CPU
DEBUG 01-06 17:11:10.663705.663705 lmp.py:414]   Expert 16 |    131 | CPU
DEBUG 01-06 17:11:10.663633.663633 lmp.py:414]   Expert  6 |    132 | CPU
DEBUG 01-06 17:11:10.663561.663561 lmp.py:414]   Expert 54 |    132 | CPU
DEBUG 01-06 17:11:10.663773.663773 lmp.py:414]   Expert 48 |    133 | CPU
DEBUG 01-06 17:11:10.663463.663463 lmp.py:414]   Expert 27 |    134 | CPU
DEBUG 01-06 17:11:10.663152.663152 lmp.py:414]   Expert 13 |    135 | CPU
DEBUG 01-06 17:11:10.663841.663841 lmp.py:414]   Expert 14 |    139 | CPU
DEBUG 01-06 17:11:10.663530.663530 lmp.py:414]   Expert 18 |    139 | CPU
DEBUG 01-06 17:11:10.663743.663743 lmp.py:414]   Expert 39 |    140 | CPU
DEBUG 01-06 17:11:10.663432.663432 lmp.py:414]   Expert 51 |    140 | CPU
DEBUG 01-06 17:11:10.663837.663837 lmp.py:414]   Expert 60 |    142 | CPU
DEBUG 01-06 17:11:10.663241.663241 lmp.py:414]   Expert 20 |    145 | CPU
DEBUG 01-06 17:11:10.663646.663646 lmp.py:414]   Expert 52 |    147 | CPU
DEBUG 01-06 17:11:10.663574.663574 lmp.py:414]   Expert 55 |    148 | CPU
DEBUG 01-06 17:11:10.663740.663740 lmp.py:414]   Expert 43 |    150 | CPU
DEBUG 01-06 17:11:10.663429.663429 lmp.py:414]   Expert 36 |    152 | CPU
DEBUG 01-06 17:11:10.663357.663357 lmp.py:414]   Expert 45 |    154 | CPU
DEBUG 01-06 17:11:10.663808.663808 lmp.py:414]   Expert 56 |    154 | CPU
DEBUG 01-06 17:11:10.663497.663497 lmp.py:414]   Expert 10 |    158 | CPU
DEBUG 01-06 17:11:10.663186.663186 lmp.py:414]   Expert 11 |    158 | CPU
DEBUG 01-06 17:11:10.663876.663876 lmp.py:414]   Expert  5 |    160 | GPU
DEBUG 01-06 17:11:10.663803.663803 lmp.py:414]   Expert 62 |    162 | GPU
DEBUG 01-06 17:11:10.663969.663969 lmp.py:414]   Expert 44 |    171 | GPU
DEBUG 01-06 17:11:10.663851.663851 lmp.py:414]   Expert 57 |    175 | GPU
DEBUG 01-06 17:11:10.663255.663255 lmp.py:414]   Expert 33 |    176 | GPU
DEBUG 01-06 17:11:10.663660.663660 lmp.py:414]   Expert 53 |    181 | GPU
DEBUG 01-06 17:11:10.663064.663064 lmp.py:414]   Expert 58 |    181 | GPU
DEBUG 01-06 17:11:10.663992.663992 lmp.py:414]   Expert 25 |    185 | GPU
DEBUG 01-06 17:11:10.663443.663443 lmp.py:414]   Expert 32 |    190 | GPU
DEBUG 01-06 17:11:10.663132.663132 lmp.py:414]   Expert  2 |    193 | GPU
DEBUG 01-06 17:11:10.663822.663822 lmp.py:414]   Expert 35 |    196 | GPU
DEBUG 01-06 17:11:10.663749.663749 lmp.py:414]   Expert 49 |    197 | GPU
DEBUG 01-06 17:11:10.663200.663200 lmp.py:414]   Expert 31 |    199 | GPU
DEBUG 01-06 17:11:10.663651.663651 lmp.py:414]   Expert 63 |    201 | GPU
DEBUG 01-06 17:11:10.663579.663579 lmp.py:414]   Expert 21 |    206 | GPU
DEBUG 01-06 17:11:10.663460.663460 lmp.py:414]   Expert 17 |    209 | GPU
DEBUG 01-06 17:11:10.663626.663626 lmp.py:414]   Expert 42 |    212 | GPU
DEBUG 01-06 17:11:10.663793.663793 lmp.py:414]   Expert 34 |    215 | GPU
DEBUG 01-06 17:11:10.663720.663720 lmp.py:414]   Expert 37 |    224 | GPU
DEBUG 01-06 17:11:10.663125.663125 lmp.py:414]   Expert 22 |    233 | GPU
DEBUG 01-06 17:11:10.663291.663291 lmp.py:414]   Expert 59 |    234 | GPU
DEBUG 01-06 17:11:10.663980.663980 lmp.py:414]   Expert  0 |    247 | GPU
DEBUG 01-06 17:11:10.663908.663908 lmp.py:414]   Expert 19 |    263 | GPU
DEBUG 01-06 17:11:10.663597.663597 lmp.py:414]   Expert 61 |    283 | GPU
DEBUG 01-06 17:11:10.663810.663810 lmp.py:414]   Expert 24 |    284 | GPU
DEBUG 01-06 17:11:10.663499.663499 lmp.py:414]   Expert 30 |    294 | GPU
DEBUG 01-06 17:11:10.663188.663188 lmp.py:414]   Expert 47 |    321 | GPU
DEBUG 01-06 17:11:10.663354.663354 lmp.py:414]   Expert 38 |    366 | GPU
DEBUG 01-06 17:11:10.663521.663521 lmp.py:414]   Expert 26 |    374 | GPU
DEBUG 01-06 17:11:10.663164.663164 lmp.py:414]   Expert 12 |    426 | GPU
DEBUG 01-06 17:11:10.663568.663568 lmp.py:414]   Expert  9 |    672 | GPU
DEBUG 01-06 17:11:10.663211.663211 lmp.py:414]   Expert 23 |    720 | GPU
DEBUG 01-06 17:11:10.663616.663616 lmp.py:415] 
DEBUG 01-06 17:11:10.663616.663616 lmp.py:415]   CPU total tokens: 3938 (32.0%)
DEBUG 01-06 17:11:10.663259.663259 lmp.py:416]   GPU total tokens: 8350 (68.0%)
DEBUG 01-06 17:11:10.664716.664716 cuda_h.py:19] end experts_map_get cost 0.0015294551849365234 seconds
DEBUG 01-06 17:11:10.664359.664359 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-06 17:11:10.664950.664950 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 17:11:10.664948.664948 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 17:11:10.665083.665083 cuda_h.py:19] end allocate_cuda_memory cost 0.0012242794036865234 seconds
DEBUG 01-06 17:11:10.665264.665264 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 17:11:10.665828.665828 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 17:11:10.665366.665366 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 17:11:10.665493.665493 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 17f0ad6b-0871-4872-96d6-1953a3bd88e2
DEBUG 01-06 17:11:10.665989.665989 client.py:106] call stub.LoadModelAsync
INFO 01-06 17:11:10.667732.667732 client.py:127] Model loaded
DEBUG 01-06 17:11:10.667579.667579 cuda_h.py:19] end sllm_worker_task cost 0.012274980545043945 seconds
INFO 01-06 17:11:10.668483.668483 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 17f0ad6b-0871-4872-96d6-1953a3bd88e2
DEBUG 01-06 17:11:10.669163.669163 cuda_h.py:19] end load_into_gpu_async cost 0.003458738327026367 seconds
DEBUG 01-06 17:11:10.669033.669033 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 17:11:10.669261.669261 cuda_h.py:19] end restore_tensors2 cost 0.0004191398620605469 seconds
DEBUG 01-06 17:11:10.669336.669336 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.005562782287597656 seconds
DEBUG 01-06 17:11:10.672131.672131 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.008197546005249023 seconds
DEBUG 01-06 17:11:10.672107.672107 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-06 17:11:10.672594.672594 lmp.py:461] 
DEBUG 01-06 17:11:10.672594.672594 lmp.py:461]   Computing 32 experts on CPU...
DEBUG 01-06 17:11:10.672589.672589 cuda_h.py:19] end cpu_experts_submit cost 0.00013637542724609375 seconds
DEBUG 01-06 17:11:10.672054.672054 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-06 17:11:10.679211.679211 mlpmodule.py:706] group tensors cost 0.006624937057495117 s
DEBUG 01-06 17:11:10.683198.683198 mlpmodule.py:744] pad cost 0.003148794174194336 s
DEBUG 01-06 17:11:10.683183.683183 mlpmodule.py:750] create cpu tensor cost 7.343292236328125e-05 s
DEBUG 01-06 17:11:10.683995.683995 mlpmodule.py:755] move to cpu cost 5.078315734863281e-05 s
DEBUG 01-06 17:11:10.693375.693375 mlpmodule.py:769] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-06 17:11:10.693027.693027 mlpmodule.py:770] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-06 17:11:10.693665.693665 mlpmodule.py:775] group_w3 first element: 0.01263427734375
WARNING 01-06 17:11:10.693610.693610 mlpmodule.py:785] start einsum2
DEBUG 01-06 17:11:10.711671.711671 mlpmodule.py:795] group einsum cost 0.028233051300048828 s
DEBUG 01-06 17:11:10.712546.712546 mlpmodule.py:803] cpy2cputensor cost 0.0006818771362304688 s
DEBUG 01-06 17:11:10.719114.719114 cuda_h.py:19] end wait_cetm_experts cost 0.04641246795654297 seconds
DEBUG 01-06 17:11:10.719763.719763 cuda_h.py:10] start gpu_sexperts
DEBUG 01-06 17:11:10.719150.719150 cuda_h.py:19] end gpu_sexperts cost 0.0006234645843505859 seconds
DEBUG 01-06 17:11:10.719291.719291 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-06 17:11:10.720711.720711 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.384185791015625e-05 seconds
DEBUG 01-06 17:11:10.720175.720175 cuda_h.py:10] start wait_experts
INFO 01-06 17:11:10.720315.720315 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 17f0ad6b-0871-4872-96d6-1953a3bd88e2
INFO 01-06 17:11:10.721707.721707 client.py:127] Model loaded
DEBUG 01-06 17:11:10.721465.721465 cuda_h.py:19] end wait_experts cost 0.0016908645629882812 seconds
DEBUG 01-06 17:11:10.721313.721313 cuda_h.py:10] start gpu_experts
DEBUG 01-06 17:11:10.721169.721169 lmp.py:506]   Computing 32 experts on GPU...
DEBUG 01-06 17:11:10.722081.722081 mlpmodule.py:533] gpu group tensors cost 0.0006506443023681641 s
DEBUG 01-06 17:11:10.724640.724640 mlpmodule.py:566] gpu pad cost 0.0017671585083007812 s
DEBUG 01-06 17:11:10.725343.725343 mlpmodule.py:584] gpu group einsum cost 0.0005483627319335938 s
DEBUG 01-06 17:11:10.728074.728074 mlpmodule.py:613] gpu experts func einsum cost 0.006577491760253906 s
DEBUG 01-06 17:11:10.728158.728158 cuda_h.py:19] end gpu_experts cost 0.006806850433349609 seconds
DEBUG 01-06 17:11:10.728081.728081 cuda_h.py:19] end layer_moe_generate_7 cost 0.06699776649475098 seconds
DEBUG 01-06 17:11:10.728863.728863 lmp.py:220] -------------------------------- end layer 7 --------------------------------
DEBUG 01-06 17:11:10.728646.728646 lmp.py:176] -------------------------------- start layer 8 --------------------------------
DEBUG 01-06 17:11:10.728964.728964 cuda_h.py:10] start start_load_qkvogn_s_weight_l_9
DEBUG 01-06 17:11:10.729913.729913 cuda_h.py:10] start start_load_qkvogn_s_weight_l_9
DEBUG 01-06 17:11:10.729325.729325 cuda_h.py:19] end start_load_qkvogn_s_weight_l_9 cost 3.147125244140625e-05 seconds
DEBUG 01-06 17:11:10.729074.729074 cuda_h.py:19] end start_load_qkvogn_s_weight_l_9 cost 6.151199340820312e-05 seconds
DEBUG 01-06 17:11:10.729386.729386 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-06 17:11:10.729799.729799 cuda_h.py:10] start sllm_worker_task
DEBUG 01-06 17:11:10.729928.729928 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 17:11:10.729241.729241 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 17:11:10.731256.731256 cuda_h.py:19] end allocate_cuda_memory cost 0.002004384994506836 seconds
DEBUG 01-06 17:11:10.731809.731809 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 17:11:10.731771.731771 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 17:11:10.731832.731832 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 17:11:10.731535.731535 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 62d1327c-07b9-4e94-87d0-4e7aff35e1bf
DEBUG 01-06 17:11:10.731505.731505 client.py:106] call stub.LoadModelAsync
DEBUG 01-06 17:11:10.731802.731802 mlpmodule.py:367] cuda:1 cuda:1
DEBUG 01-06 17:11:10.732139.732139 mlpmodule.py:664]  experts func einsum cost 0.05930376052856445 s
DEBUG 01-06 17:11:10.732939.732939 cuda_h.py:10] start self_attn
INFO 01-06 17:11:10.733246.733246 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 62d1327c-07b9-4e94-87d0-4e7aff35e1bf
DEBUG 01-06 17:11:10.733944.733944 cuda_h.py:19] end load_into_gpu_async cost 0.0016012191772460938 seconds
DEBUG 01-06 17:11:10.733170.733170 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 17:11:10.733213.733213 cuda_h.py:19] end restore_tensors2 cost 7.534027099609375e-05 seconds
DEBUG 01-06 17:11:10.733969.733969 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.00396275520324707 seconds
INFO 01-06 17:11:10.733342.733342 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 62d1327c-07b9-4e94-87d0-4e7aff35e1bf
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-06 17:11:10.735033.735033 cuda_h.py:19] end self_attn cost 0.0029103755950927734 seconds
DEBUG 01-06 17:11:10.735381.735381 cuda_h.py:19] end iln_self_attn_paln cost 0.0065326690673828125 seconds
DEBUG 01-06 17:11:10.735939.735939 cuda_h.py:10] start layer_moe_generate_8
DEBUG 01-06 17:11:10.735132.735132 cuda_h.py:10] start gate
DEBUG 01-06 17:11:10.736222.736222 cuda_h.py:19] end gate cost 0.0006639957427978516 seconds
DEBUG 01-06 17:11:10.736621.736621 cuda_h.py:10] start experts_map_get
DEBUG 01-06 17:11:10.736538.736538 lmp.py:403] 
DEBUG 01-06 17:11:10.736538.736538 lmp.py:403] Expert Token Distribution & Device Allocation:
DEBUG 01-06 17:11:10.736201.736201 lmp.py:404]   Total experts: 64
DEBUG 01-06 17:11:10.736851.736851 lmp.py:405]   CPU experts: 32 (50%)
DEBUG 01-06 17:11:10.736925.736925 lmp.py:406]   GPU experts: 32 (50%)
DEBUG 01-06 17:11:10.736521.736521 lmp.py:407] 
DEBUG 01-06 17:11:10.736521.736521 lmp.py:407]   Expert ID | Tokens | Device
DEBUG 01-06 17:11:10.736879.736879 lmp.py:408]   -----------------------------------
DEBUG 01-06 17:11:10.736960.736960 lmp.py:414]   Expert 38 |     15 | CPU
DEBUG 01-06 17:11:10.736080.736080 lmp.py:414]   Expert 39 |     67 | CPU
DEBUG 01-06 17:11:10.736722.736722 lmp.py:414]   Expert  7 |     69 | CPU
DEBUG 01-06 17:11:10.736889.736889 lmp.py:414]   Expert 30 |     73 | CPU
DEBUG 01-06 17:11:10.737339.737339 lmp.py:414]   Expert 27 |     92 | CPU
DEBUG 01-06 17:11:10.737552.737552 lmp.py:414]   Expert 40 |     92 | CPU
DEBUG 01-06 17:11:10.737526.737526 lmp.py:414]   Expert 24 |     93 | CPU
DEBUG 01-06 17:11:10.737785.737785 lmp.py:414]   Expert 17 |     95 | CPU
DEBUG 01-06 17:11:10.737997.737997 lmp.py:414]   Expert 36 |     95 | CPU
DEBUG 01-06 17:11:10.737210.737210 lmp.py:414]   Expert 32 |     97 | CPU
DEBUG 01-06 17:11:10.737376.737376 lmp.py:414]   Expert 14 |     99 | CPU
DEBUG 01-06 17:11:10.737827.737827 lmp.py:414]   Expert 16 |    104 | CPU
DEBUG 01-06 17:11:10.737754.737754 lmp.py:414]   Expert 18 |    110 | CPU
DEBUG 01-06 17:11:10.737444.737444 lmp.py:414]   Expert 12 |    115 | CPU
DEBUG 01-06 17:11:10.737895.737895 lmp.py:414]   Expert 48 |    116 | CPU
DEBUG 01-06 17:11:10.737822.737822 lmp.py:414]   Expert  1 |    117 | CPU
DEBUG 01-06 17:11:10.737273.737273 lmp.py:414]   Expert  6 |    124 | CPU
DEBUG 01-06 17:11:10.737724.737724 lmp.py:414]   Expert 42 |    139 | CPU
DEBUG 01-06 17:11:10.737175.737175 lmp.py:414]   Expert 59 |    140 | CPU
DEBUG 01-06 17:11:10.737103.737103 lmp.py:414]   Expert 22 |    146 | CPU
DEBUG 01-06 17:11:10.737315.737315 lmp.py:414]   Expert  0 |    147 | CPU
DEBUG 01-06 17:11:10.737528.737528 lmp.py:414]   Expert 51 |    147 | CPU
DEBUG 01-06 17:11:10.737979.737979 lmp.py:414]   Expert 53 |    148 | CPU
DEBUG 01-06 17:11:10.737714.737714 lmp.py:414]   Expert  8 |    160 | CPU
DEBUG 01-06 17:11:10.737880.737880 lmp.py:414]   Expert 60 |    161 | CPU
DEBUG 01-06 17:11:10.737285.737285 lmp.py:414]   Expert 15 |    169 | CPU
DEBUG 01-06 17:11:10.737974.737974 lmp.py:414]   Expert 54 |    171 | CPU
DEBUG 01-06 17:11:10.737902.737902 lmp.py:414]   Expert 44 |    173 | CPU
DEBUG 01-06 17:11:10.737830.737830 lmp.py:414]   Expert 29 |    175 | CPU
DEBUG 01-06 17:11:10.737565.737565 lmp.py:414]   Expert 35 |    176 | CPU
DEBUG 01-06 17:11:10.737016.737016 lmp.py:414]   Expert 33 |    178 | CPU
DEBUG 01-06 17:11:10.737467.737467 lmp.py:414]   Expert 34 |    182 | CPU
DEBUG 01-06 17:11:10.737441.737441 lmp.py:414]   Expert 19 |    188 | GPU
DEBUG 01-06 17:11:10.737892.737892 lmp.py:414]   Expert 47 |    188 | GPU
DEBUG 01-06 17:11:10.737343.737343 lmp.py:414]   Expert  9 |    191 | GPU
DEBUG 01-06 17:11:10.737794.737794 lmp.py:414]   Expert 56 |    196 | GPU
DEBUG 01-06 17:11:10.737006.737006 lmp.py:414]   Expert 21 |    197 | GPU
DEBUG 01-06 17:11:10.737649.737649 lmp.py:414]   Expert 49 |    199 | GPU
DEBUG 01-06 17:11:10.737577.737577 lmp.py:414]   Expert 20 |    200 | GPU
DEBUG 01-06 17:11:10.737981.737981 lmp.py:414]   Expert  3 |    201 | GPU
DEBUG 01-06 17:11:10.737909.737909 lmp.py:414]   Expert 46 |    202 | GPU
DEBUG 01-06 17:11:10.737314.737314 lmp.py:414]   Expert 45 |    203 | GPU
DEBUG 01-06 17:11:10.737765.737765 lmp.py:414]   Expert 28 |    206 | GPU
DEBUG 01-06 17:11:10.737215.737215 lmp.py:414]   Expert  4 |    222 | GPU
DEBUG 01-06 17:11:10.737666.737666 lmp.py:414]   Expert  2 |    223 | GPU
DEBUG 01-06 17:11:10.737879.737879 lmp.py:414]   Expert 57 |    223 | GPU
DEBUG 01-06 17:11:10.737330.737330 lmp.py:414]   Expert 13 |    226 | GPU
DEBUG 01-06 17:11:10.737019.737019 lmp.py:414]   Expert 43 |    231 | GPU
DEBUG 01-06 17:11:10.737470.737470 lmp.py:414]   Expert 10 |    238 | GPU
DEBUG 01-06 17:11:10.737921.737921 lmp.py:414]   Expert 41 |    242 | GPU
DEBUG 01-06 17:11:10.737133.737133 lmp.py:414]   Expert 50 |    245 | GPU
DEBUG 01-06 17:11:10.737107.737107 lmp.py:414]   Expert 26 |    251 | GPU
DEBUG 01-06 17:11:10.737512.737512 lmp.py:414]   Expert 63 |    252 | GPU
DEBUG 01-06 17:11:10.737440.737440 lmp.py:414]   Expert 37 |    259 | GPU
DEBUG 01-06 17:11:10.737367.737367 lmp.py:414]   Expert 31 |    269 | GPU
DEBUG 01-06 17:11:10.737295.737295 lmp.py:414]   Expert 61 |    270 | GPU
DEBUG 01-06 17:11:10.737461.737461 lmp.py:414]   Expert 52 |    304 | GPU
DEBUG 01-06 17:11:10.737912.737912 lmp.py:414]   Expert 62 |    327 | GPU
DEBUG 01-06 17:11:10.737363.737363 lmp.py:414]   Expert 58 |    328 | GPU
DEBUG 01-06 17:11:10.737814.737814 lmp.py:414]   Expert 55 |    342 | GPU
DEBUG 01-06 17:11:10.737026.737026 lmp.py:414]   Expert 11 |    378 | GPU
DEBUG 01-06 17:11:10.737477.737477 lmp.py:414]   Expert 23 |    389 | GPU
DEBUG 01-06 17:11:10.737690.737690 lmp.py:414]   Expert 25 |    400 | GPU
DEBUG 01-06 17:11:10.737094.737094 lmp.py:414]   Expert  5 |    513 | GPU
DEBUG 01-06 17:11:10.738929.738929 lmp.py:415] 
DEBUG 01-06 17:11:10.738929.738929 lmp.py:415]   CPU total tokens: 3985 (32.4%)
DEBUG 01-06 17:11:10.738049.738049 lmp.py:416]   GPU total tokens: 8303 (67.6%)
DEBUG 01-06 17:11:10.738699.738699 cuda_h.py:19] end experts_map_get cost 0.0015039443969726562 seconds
DEBUG 01-06 17:11:10.738819.738819 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-06 17:11:10.738310.738310 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 17:11:10.738301.738301 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 17:11:10.739242.739242 cuda_h.py:19] end allocate_cuda_memory cost 0.0011522769927978516 seconds
DEBUG 01-06 17:11:10.739052.739052 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 17:11:10.739715.739715 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 17:11:10.739048.739048 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 17:11:10.739890.739890 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, d8314a3c-a205-43f9-bca4-9fc5dfc6d0d6
DEBUG 01-06 17:11:10.739962.739962 client.py:106] call stub.LoadModelAsync
INFO 01-06 17:11:10.741880.741880 client.py:127] Model loaded
DEBUG 01-06 17:11:10.741949.741949 cuda_h.py:19] end sllm_worker_task cost 0.012694597244262695 seconds
INFO 01-06 17:11:10.742984.742984 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, d8314a3c-a205-43f9-bca4-9fc5dfc6d0d6
DEBUG 01-06 17:11:10.742427.742427 cuda_h.py:19] end load_into_gpu_async cost 0.0034208297729492188 seconds
DEBUG 01-06 17:11:10.743820.743820 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 17:11:10.743807.743807 cuda_h.py:19] end restore_tensors2 cost 0.0005223751068115234 seconds
DEBUG 01-06 17:11:10.743358.743358 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.005560636520385742 seconds
DEBUG 01-06 17:11:10.746902.746902 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.00821685791015625 seconds
DEBUG 01-06 17:11:10.746355.746355 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-06 17:11:10.746026.746026 lmp.py:461] 
DEBUG 01-06 17:11:10.746026.746026 lmp.py:461]   Computing 32 experts on CPU...
DEBUG 01-06 17:11:10.746346.746346 cuda_h.py:19] end cpu_experts_submit cost 0.00010728836059570312 seconds
DEBUG 01-06 17:11:10.746042.746042 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-06 17:11:10.757265.757265 mlpmodule.py:706] group tensors cost 0.0111541748046875 s
DEBUG 01-06 17:11:10.760697.760697 mlpmodule.py:744] pad cost 0.002157926559448242 s
DEBUG 01-06 17:11:10.761913.761913 mlpmodule.py:750] create cpu tensor cost 5.841255187988281e-05 s
DEBUG 01-06 17:11:10.761691.761691 mlpmodule.py:755] move to cpu cost 4.4345855712890625e-05 s
DEBUG 01-06 17:11:10.772452.772452 mlpmodule.py:769] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-06 17:11:10.772673.772673 mlpmodule.py:770] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-06 17:11:10.772475.772475 mlpmodule.py:775] group_w3 first element: 0.0859375
WARNING 01-06 17:11:10.772989.772989 mlpmodule.py:785] start einsum2
DEBUG 01-06 17:11:10.789618.789618 mlpmodule.py:795] group einsum cost 0.028217792510986328 s
DEBUG 01-06 17:11:10.790137.790137 mlpmodule.py:803] cpy2cputensor cost 0.0007190704345703125 s
DEBUG 01-06 17:11:10.796006.796006 cuda_h.py:19] end wait_cetm_experts cost 0.05006814002990723 seconds
DEBUG 01-06 17:11:10.796456.796456 cuda_h.py:10] start gpu_sexperts
DEBUG 01-06 17:11:10.797313.797313 cuda_h.py:19] end gpu_sexperts cost 0.0006213188171386719 seconds
DEBUG 01-06 17:11:10.797693.797693 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-06 17:11:10.797019.797019 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.5510787963867188e-05 seconds
DEBUG 01-06 17:11:10.797437.797437 cuda_h.py:10] start wait_experts
INFO 01-06 17:11:10.797432.797432 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, d8314a3c-a205-43f9-bca4-9fc5dfc6d0d6
INFO 01-06 17:11:10.799291.799291 client.py:127] Model loaded
DEBUG 01-06 17:11:10.799041.799041 cuda_h.py:19] end wait_experts cost 0.0013988018035888672 seconds
DEBUG 01-06 17:11:10.799175.799175 cuda_h.py:10] start gpu_experts
DEBUG 01-06 17:11:10.799931.799931 lmp.py:506]   Computing 32 experts on GPU...
DEBUG 01-06 17:11:10.799658.799658 mlpmodule.py:533] gpu group tensors cost 0.0006570816040039062 s
DEBUG 01-06 17:11:10.801196.801196 mlpmodule.py:566] gpu pad cost 0.0017757415771484375 s
DEBUG 01-06 17:11:10.802079.802079 mlpmodule.py:584] gpu group einsum cost 0.0005762577056884766 s
DEBUG 01-06 17:11:10.805419.805419 mlpmodule.py:613] gpu experts func einsum cost 0.006590127944946289 s
DEBUG 01-06 17:11:10.805993.805993 cuda_h.py:19] end gpu_experts cost 0.006789207458496094 seconds
DEBUG 01-06 17:11:10.806261.806261 cuda_h.py:19] end layer_moe_generate_8 cost 0.07028961181640625 seconds
DEBUG 01-06 17:11:10.806990.806990 lmp.py:220] -------------------------------- end layer 8 --------------------------------
DEBUG 01-06 17:11:10.806581.806581 lmp.py:176] -------------------------------- start layer 9 --------------------------------
DEBUG 01-06 17:11:10.806608.806608 cuda_h.py:10] start start_load_qkvogn_s_weight_l_10
DEBUG 01-06 17:11:10.806410.806410 cuda_h.py:10] start start_load_qkvogn_s_weight_l_10
DEBUG 01-06 17:11:10.806631.806631 cuda_h.py:19] end start_load_qkvogn_s_weight_l_10 cost 3.0279159545898438e-05 seconds
DEBUG 01-06 17:11:10.806116.806116 cuda_h.py:19] end start_load_qkvogn_s_weight_l_10 cost 7.700920104980469e-05 seconds
DEBUG 01-06 17:11:10.806951.806951 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-06 17:11:10.806861.806861 mlpmodule.py:367] cuda:1 cuda:1
DEBUG 01-06 17:11:10.806691.806691 cuda_h.py:10] start sllm_worker_task
DEBUG 01-06 17:11:10.806119.806119 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 17:11:10.806716.806716 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 17:11:10.808862.808862 cuda_h.py:19] end allocate_cuda_memory cost 0.0019316673278808594 seconds
DEBUG 01-06 17:11:10.808242.808242 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 17:11:10.808097.808097 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 17:11:10.808443.808443 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 17:11:10.808669.808669 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, ad4bd17d-6221-46b8-9da6-93798337c047
DEBUG 01-06 17:11:10.809778.809778 client.py:106] call stub.LoadModelAsync
DEBUG 01-06 17:11:10.809883.809883 mlpmodule.py:664]  experts func einsum cost 0.06248068809509277 s
DEBUG 01-06 17:11:10.809973.809973 cuda_h.py:10] start self_attn
INFO 01-06 17:11:10.810315.810315 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, ad4bd17d-6221-46b8-9da6-93798337c047
DEBUG 01-06 17:11:10.810728.810728 cuda_h.py:19] end load_into_gpu_async cost 0.0016217231750488281 seconds
DEBUG 01-06 17:11:10.810523.810523 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 17:11:10.810659.810659 cuda_h.py:19] end restore_tensors2 cost 7.43865966796875e-05 seconds
DEBUG 01-06 17:11:10.810176.810176 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.003869771957397461 seconds
INFO 01-06 17:11:10.810496.810496 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, ad4bd17d-6221-46b8-9da6-93798337c047
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-06 17:11:10.812663.812663 cuda_h.py:19] end self_attn cost 0.0029006004333496094 seconds
DEBUG 01-06 17:11:10.812719.812719 cuda_h.py:19] end iln_self_attn_paln cost 0.006295919418334961 seconds
DEBUG 01-06 17:11:10.812847.812847 cuda_h.py:10] start layer_moe_generate_9
DEBUG 01-06 17:11:10.812517.812517 cuda_h.py:10] start gate
DEBUG 01-06 17:11:10.813818.813818 cuda_h.py:19] end gate cost 0.0006444454193115234 seconds
DEBUG 01-06 17:11:10.813693.813693 cuda_h.py:10] start experts_map_get
DEBUG 01-06 17:11:10.813425.813425 lmp.py:403] 
DEBUG 01-06 17:11:10.813425.813425 lmp.py:403] Expert Token Distribution & Device Allocation:
DEBUG 01-06 17:11:10.813512.813512 lmp.py:404]   Total experts: 64
DEBUG 01-06 17:11:10.813400.813400 lmp.py:405]   CPU experts: 32 (50%)
DEBUG 01-06 17:11:10.814235.814235 lmp.py:406]   GPU experts: 32 (50%)
DEBUG 01-06 17:11:10.814402.814402 lmp.py:407] 
DEBUG 01-06 17:11:10.814402.814402 lmp.py:407]   Expert ID | Tokens | Device
DEBUG 01-06 17:11:10.814952.814952 lmp.py:408]   -----------------------------------
DEBUG 01-06 17:11:10.814509.814509 lmp.py:414]   Expert 24 |     39 | CPU
DEBUG 01-06 17:11:10.814390.814390 lmp.py:414]   Expert  2 |     45 | CPU
DEBUG 01-06 17:11:10.814557.814557 lmp.py:414]   Expert 26 |     59 | CPU
DEBUG 01-06 17:11:10.814246.814246 lmp.py:414]   Expert 32 |     66 | CPU
DEBUG 01-06 17:11:10.814174.814174 lmp.py:414]   Expert 19 |     68 | CPU
DEBUG 01-06 17:11:10.814863.814863 lmp.py:414]   Expert 50 |     73 | CPU
DEBUG 01-06 17:11:10.814791.814791 lmp.py:414]   Expert 15 |     80 | CPU
DEBUG 01-06 17:11:10.814241.814241 lmp.py:414]   Expert  4 |     82 | CPU
DEBUG 01-06 17:11:10.814123.814123 lmp.py:414]   Expert  7 |     82 | CPU
DEBUG 01-06 17:11:10.814289.814289 lmp.py:414]   Expert 28 |     84 | CPU
DEBUG 01-06 17:11:10.814455.814455 lmp.py:414]   Expert 59 |     89 | CPU
DEBUG 01-06 17:11:10.814098.814098 lmp.py:414]   Expert 60 |     89 | CPU
DEBUG 01-06 17:11:10.814503.814503 lmp.py:414]   Expert 23 |     92 | CPU
DEBUG 01-06 17:11:10.814669.814669 lmp.py:414]   Expert  5 |    102 | CPU
DEBUG 01-06 17:11:10.814358.814358 lmp.py:414]   Expert 12 |    102 | CPU
DEBUG 01-06 17:11:10.814809.814809 lmp.py:414]   Expert 49 |    104 | CPU
DEBUG 01-06 17:11:10.814260.814260 lmp.py:414]   Expert 10 |    110 | CPU
DEBUG 01-06 17:11:10.814711.814711 lmp.py:414]   Expert 27 |    110 | CPU
DEBUG 01-06 17:11:10.814400.814400 lmp.py:414]   Expert 41 |    116 | CPU
DEBUG 01-06 17:11:10.814613.814613 lmp.py:414]   Expert  3 |    122 | CPU
DEBUG 01-06 17:11:10.814825.814825 lmp.py:414]   Expert 16 |    124 | CPU
DEBUG 01-06 17:11:10.814514.814514 lmp.py:414]   Expert 40 |    124 | CPU
DEBUG 01-06 17:11:10.814965.814965 lmp.py:414]   Expert 13 |    127 | CPU
DEBUG 01-06 17:11:10.814893.814893 lmp.py:414]   Expert 20 |    128 | CPU
DEBUG 01-06 17:11:10.814059.814059 lmp.py:414]   Expert 25 |    134 | CPU
DEBUG 01-06 17:11:10.814987.814987 lmp.py:414]   Expert 37 |    140 | CPU
DEBUG 01-06 17:11:10.814438.814438 lmp.py:414]   Expert 35 |    147 | CPU
DEBUG 01-06 17:11:10.814127.814127 lmp.py:414]   Expert 17 |    148 | CPU
DEBUG 01-06 17:11:10.814339.814339 lmp.py:414]   Expert 22 |    150 | CPU
DEBUG 01-06 17:11:10.814790.814790 lmp.py:414]   Expert 47 |    163 | CPU
DEBUG 01-06 17:11:10.814764.814764 lmp.py:414]   Expert 53 |    170 | CPU
DEBUG 01-06 17:11:10.814215.814215 lmp.py:414]   Expert 36 |    174 | CPU
DEBUG 01-06 17:11:10.814904.814904 lmp.py:414]   Expert 38 |    174 | GPU
DEBUG 01-06 17:11:10.814594.814594 lmp.py:414]   Expert 39 |    175 | GPU
DEBUG 01-06 17:11:10.814045.814045 lmp.py:414]   Expert 44 |    182 | GPU
DEBUG 01-06 17:11:10.814972.814972 lmp.py:414]   Expert 52 |    185 | GPU
DEBUG 01-06 17:11:10.814615.814615 lmp.py:414]   Expert 18 |    186 | GPU
DEBUG 01-06 17:11:10.814781.814781 lmp.py:414]   Expert 58 |    188 | GPU
DEBUG 01-06 17:11:10.814948.814948 lmp.py:414]   Expert 62 |    197 | GPU
DEBUG 01-06 17:11:10.814114.814114 lmp.py:414]   Expert 48 |    207 | GPU
DEBUG 01-06 17:11:10.814280.814280 lmp.py:414]   Expert 11 |    209 | GPU
DEBUG 01-06 17:11:10.814969.814969 lmp.py:414]   Expert 14 |    216 | GPU
DEBUG 01-06 17:11:10.814420.814420 lmp.py:414]   Expert 30 |    219 | GPU
DEBUG 01-06 17:11:10.814871.814871 lmp.py:414]   Expert  1 |    232 | GPU
DEBUG 01-06 17:11:10.814560.814560 lmp.py:414]   Expert 31 |    233 | GPU
DEBUG 01-06 17:11:10.814250.814250 lmp.py:414]   Expert  6 |    238 | GPU
DEBUG 01-06 17:11:10.814939.814939 lmp.py:414]   Expert 42 |    238 | GPU
DEBUG 01-06 17:11:10.814628.814628 lmp.py:414]   Expert 51 |    241 | GPU
DEBUG 01-06 17:11:10.814033.814033 lmp.py:414]   Expert 45 |    242 | GPU
DEBUG 01-06 17:11:10.814676.814676 lmp.py:414]   Expert 34 |    264 | GPU
DEBUG 01-06 17:11:10.814603.814603 lmp.py:414]   Expert 29 |    276 | GPU
DEBUG 01-06 17:11:10.814531.814531 lmp.py:414]   Expert 33 |    277 | GPU
DEBUG 01-06 17:11:10.814697.814697 lmp.py:414]   Expert 57 |    295 | GPU
DEBUG 01-06 17:11:10.814387.814387 lmp.py:414]   Expert 61 |    307 | GPU
DEBUG 01-06 17:11:10.814076.814076 lmp.py:414]   Expert  0 |    309 | GPU
DEBUG 01-06 17:11:10.814765.814765 lmp.py:414]   Expert 43 |    309 | GPU
DEBUG 01-06 17:11:10.815978.815978 lmp.py:414]   Expert 46 |    348 | GPU
DEBUG 01-06 17:11:10.815667.815667 lmp.py:414]   Expert  8 |    385 | GPU
DEBUG 01-06 17:11:10.815118.815118 lmp.py:414]   Expert  9 |    387 | GPU
DEBUG 01-06 17:11:10.815807.815807 lmp.py:414]   Expert 54 |    400 | GPU
DEBUG 01-06 17:11:10.815258.815258 lmp.py:414]   Expert 56 |    402 | GPU
DEBUG 01-06 17:11:10.815947.815947 lmp.py:414]   Expert 63 |    411 | GPU
DEBUG 01-06 17:11:10.815875.815875 lmp.py:414]   Expert 55 |    424 | GPU
DEBUG 01-06 17:11:10.815041.815041 lmp.py:414]   Expert 21 |    489 | GPU
DEBUG 01-06 17:11:10.815161.815161 lmp.py:415] 
DEBUG 01-06 17:11:10.815161.815161 lmp.py:415]   CPU total tokens: 3443 (28.0%)
DEBUG 01-06 17:11:10.815519.815519 lmp.py:416]   GPU total tokens: 8845 (72.0%)
DEBUG 01-06 17:11:10.815977.815977 cuda_h.py:19] end experts_map_get cost 0.0015156269073486328 seconds
DEBUG 01-06 17:11:10.815620.815620 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-06 17:11:10.815065.815065 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 17:11:10.815394.815394 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 17:11:10.816005.816005 cuda_h.py:19] end allocate_cuda_memory cost 0.001399993896484375 seconds
DEBUG 01-06 17:11:10.816232.816232 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 17:11:10.816750.816750 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 17:11:10.816798.816798 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 17:11:10.816878.816878 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, f5aaff60-cdd3-48c0-b705-474d3bc4b182
DEBUG 01-06 17:11:10.817765.817765 client.py:106] call stub.LoadModelAsync
INFO 01-06 17:11:10.818766.818766 client.py:127] Model loaded
DEBUG 01-06 17:11:10.818467.818467 cuda_h.py:19] end sllm_worker_task cost 0.012203454971313477 seconds
INFO 01-06 17:11:10.820063.820063 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, f5aaff60-cdd3-48c0-b705-474d3bc4b182
DEBUG 01-06 17:11:10.820482.820482 cuda_h.py:19] end load_into_gpu_async cost 0.0032758712768554688 seconds
DEBUG 01-06 17:11:10.820377.820377 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 17:11:10.820252.820252 cuda_h.py:19] end restore_tensors2 cost 0.0003714561462402344 seconds
DEBUG 01-06 17:11:10.820326.820326 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0054013729095458984 seconds
DEBUG 01-06 17:11:10.823100.823100 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.007982969284057617 seconds
DEBUG 01-06 17:11:10.823075.823075 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-06 17:11:10.823866.823866 lmp.py:461] 
DEBUG 01-06 17:11:10.823866.823866 lmp.py:461]   Computing 32 experts on CPU...
DEBUG 01-06 17:11:10.823663.823663 cuda_h.py:19] end cpu_experts_submit cost 0.00010967254638671875 seconds
DEBUG 01-06 17:11:10.823074.823074 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-06 17:11:10.830800.830800 mlpmodule.py:706] group tensors cost 0.006387233734130859 s
DEBUG 01-06 17:11:10.833750.833750 mlpmodule.py:744] pad cost 0.002739429473876953 s
DEBUG 01-06 17:11:10.833669.833669 mlpmodule.py:750] create cpu tensor cost 6.890296936035156e-05 s
DEBUG 01-06 17:11:10.833659.833659 mlpmodule.py:755] move to cpu cost 4.887580871582031e-05 s
DEBUG 01-06 17:11:10.843192.843192 mlpmodule.py:769] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-06 17:11:10.843983.843983 mlpmodule.py:770] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-06 17:11:10.843337.843337 mlpmodule.py:775] group_w3 first element: 0.0157470703125
WARNING 01-06 17:11:10.844745.844745 mlpmodule.py:785] start einsum2
DEBUG 01-06 17:11:10.859112.859112 mlpmodule.py:795] group einsum cost 0.02572488784790039 s
DEBUG 01-06 17:11:10.860927.860927 mlpmodule.py:803] cpy2cputensor cost 0.0006780624389648438 s
DEBUG 01-06 17:11:10.866927.866927 cuda_h.py:19] end wait_cetm_experts cost 0.04257535934448242 seconds
DEBUG 01-06 17:11:10.866298.866298 cuda_h.py:10] start gpu_sexperts
DEBUG 01-06 17:11:10.866704.866704 cuda_h.py:19] end gpu_sexperts cost 0.0006055831909179688 seconds
DEBUG 01-06 17:11:10.867269.867269 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-06 17:11:10.867834.867834 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.5033950805664062e-05 seconds
DEBUG 01-06 17:11:10.867729.867729 cuda_h.py:10] start wait_experts
INFO 01-06 17:11:10.867630.867630 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, f5aaff60-cdd3-48c0-b705-474d3bc4b182
INFO 01-06 17:11:10.869017.869017 client.py:127] Model loaded
DEBUG 01-06 17:11:10.870437.870437 cuda_h.py:19] end wait_experts cost 0.0029144287109375 seconds
DEBUG 01-06 17:11:10.870762.870762 cuda_h.py:10] start gpu_experts
DEBUG 01-06 17:11:10.870280.870280 lmp.py:506]   Computing 32 experts on GPU...
DEBUG 01-06 17:11:10.870331.870331 mlpmodule.py:533] gpu group tensors cost 0.0006520748138427734 s
DEBUG 01-06 17:11:10.872121.872121 mlpmodule.py:566] gpu pad cost 0.001787424087524414 s
DEBUG 01-06 17:11:10.873016.873016 mlpmodule.py:584] gpu group einsum cost 0.0005414485931396484 s
DEBUG 01-06 17:11:10.876605.876605 mlpmodule.py:613] gpu experts func einsum cost 0.006471395492553711 s
DEBUG 01-06 17:11:10.876801.876801 cuda_h.py:19] end gpu_experts cost 0.006668806076049805 seconds
DEBUG 01-06 17:11:10.876208.876208 cuda_h.py:19] end layer_moe_generate_9 cost 0.06396317481994629 seconds
DEBUG 01-06 17:11:10.877651.877651 lmp.py:220] -------------------------------- end layer 9 --------------------------------
DEBUG 01-06 17:11:10.877328.877328 lmp.py:176] -------------------------------- start layer 10 --------------------------------
DEBUG 01-06 17:11:10.877071.877071 cuda_h.py:10] start start_load_qkvogn_s_weight_l_11
DEBUG 01-06 17:11:10.877827.877827 cuda_h.py:10] start start_load_qkvogn_s_weight_l_11
DEBUG 01-06 17:11:10.877239.877239 cuda_h.py:19] end start_load_qkvogn_s_weight_l_11 cost 3.0994415283203125e-05 seconds
DEBUG 01-06 17:11:10.877704.877704 cuda_h.py:19] end start_load_qkvogn_s_weight_l_11 cost 6.341934204101562e-05 seconds
DEBUG 01-06 17:11:10.877208.877208 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-06 17:11:10.877296.877296 cuda_h.py:10] start sllm_worker_task
DEBUG 01-06 17:11:10.877942.877942 mlpmodule.py:367] cuda:1 cuda:1
DEBUG 01-06 17:11:10.877858.877858 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 17:11:10.877875.877875 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 17:11:10.877874.877874 cuda_h.py:19] end allocate_cuda_memory cost 0.0003101825714111328 seconds
DEBUG 01-06 17:11:10.878539.878539 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 17:11:10.878256.878256 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 17:11:10.878655.878655 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 17:11:10.878927.878927 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 77d4b0e7-6518-47a8-8b5b-3d30307da19e
DEBUG 01-06 17:11:10.878181.878181 client.py:106] call stub.LoadModelAsync
DEBUG 01-06 17:11:10.878515.878515 cuda_h.py:10] start self_attn
INFO 01-06 17:11:10.879230.879230 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 77d4b0e7-6518-47a8-8b5b-3d30307da19e
DEBUG 01-06 17:11:10.879304.879304 cuda_h.py:19] end load_into_gpu_async cost 0.0016508102416992188 seconds
DEBUG 01-06 17:11:10.879908.879908 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 17:11:10.879560.879560 cuda_h.py:19] end restore_tensors2 cost 6.890296936035156e-05 seconds
DEBUG 01-06 17:11:10.879124.879124 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.002313852310180664 seconds
INFO 01-06 17:11:10.879344.879344 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 77d4b0e7-6518-47a8-8b5b-3d30307da19e
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-06 17:11:10.881218.881218 cuda_h.py:19] end self_attn cost 0.0029151439666748047 seconds
DEBUG 01-06 17:11:10.881506.881506 cuda_h.py:19] end iln_self_attn_paln cost 0.004544734954833984 seconds
DEBUG 01-06 17:11:10.881727.881727 cuda_h.py:10] start layer_moe_generate_10
DEBUG 01-06 17:11:10.881967.881967 cuda_h.py:10] start gate
DEBUG 01-06 17:11:10.882281.882281 cuda_h.py:19] end gate cost 0.0006551742553710938 seconds
DEBUG 01-06 17:11:10.882157.882157 cuda_h.py:10] start experts_map_get
DEBUG 01-06 17:11:10.882657.882657 lmp.py:403] 
DEBUG 01-06 17:11:10.882657.882657 lmp.py:403] Expert Token Distribution & Device Allocation:
DEBUG 01-06 17:11:10.882651.882651 lmp.py:404]   Total experts: 64
DEBUG 01-06 17:11:10.883063.883063 lmp.py:405]   CPU experts: 32 (50%)
DEBUG 01-06 17:11:10.883613.883613 lmp.py:406]   GPU experts: 32 (50%)
DEBUG 01-06 17:11:10.883256.883256 lmp.py:407] 
DEBUG 01-06 17:11:10.883256.883256 lmp.py:407]   Expert ID | Tokens | Device
DEBUG 01-06 17:11:10.883660.883660 lmp.py:408]   -----------------------------------
DEBUG 01-06 17:11:10.883741.883741 lmp.py:414]   Expert 43 |     14 | CPU
DEBUG 01-06 17:11:10.883907.883907 lmp.py:414]   Expert 27 |     35 | CPU
DEBUG 01-06 17:11:10.883119.883119 lmp.py:414]   Expert 34 |     49 | CPU
DEBUG 01-06 17:11:10.883332.883332 lmp.py:414]   Expert 56 |     50 | CPU
DEBUG 01-06 17:11:10.883306.883306 lmp.py:414]   Expert 26 |     55 | CPU
DEBUG 01-06 17:11:10.883280.883280 lmp.py:414]   Expert  3 |     57 | CPU
DEBUG 01-06 17:11:10.883016.883016 lmp.py:414]   Expert  4 |     70 | CPU
DEBUG 01-06 17:11:10.883228.883228 lmp.py:414]   Expert 61 |     74 | CPU
DEBUG 01-06 17:11:10.883440.883440 lmp.py:414]   Expert 14 |     90 | CPU
DEBUG 01-06 17:11:10.883415.883415 lmp.py:414]   Expert 38 |     96 | CPU
DEBUG 01-06 17:11:10.883057.883057 lmp.py:414]   Expert  2 |    112 | CPU
DEBUG 01-06 17:11:10.883700.883700 lmp.py:414]   Expert 22 |    114 | CPU
DEBUG 01-06 17:11:10.883582.883582 lmp.py:414]   Expert 17 |    119 | CPU
DEBUG 01-06 17:11:10.883225.883225 lmp.py:414]   Expert 47 |    125 | CPU
DEBUG 01-06 17:11:10.883914.883914 lmp.py:414]   Expert 37 |    127 | CPU
DEBUG 01-06 17:11:10.883842.883842 lmp.py:414]   Expert 54 |    134 | CPU
DEBUG 01-06 17:11:10.883293.883293 lmp.py:414]   Expert 55 |    136 | CPU
DEBUG 01-06 17:11:10.883982.883982 lmp.py:414]   Expert 28 |    137 | CPU
DEBUG 01-06 17:11:10.883671.883671 lmp.py:414]   Expert 48 |    144 | CPU
DEBUG 01-06 17:11:10.883122.883122 lmp.py:414]   Expert  5 |    145 | CPU
DEBUG 01-06 17:11:10.883812.883812 lmp.py:414]   Expert 15 |    146 | CPU
DEBUG 01-06 17:11:10.883501.883501 lmp.py:414]   Expert 45 |    146 | CPU
DEBUG 01-06 17:11:10.883952.883952 lmp.py:414]   Expert  7 |    148 | CPU
DEBUG 01-06 17:11:10.883879.883879 lmp.py:414]   Expert 12 |    149 | CPU
DEBUG 01-06 17:11:10.883569.883569 lmp.py:414]   Expert 51 |    149 | CPU
DEBUG 01-06 17:11:10.883973.883973 lmp.py:414]   Expert 63 |    150 | CPU
DEBUG 01-06 17:11:10.883378.883378 lmp.py:414]   Expert 60 |    154 | CPU
DEBUG 01-06 17:11:10.883021.883021 lmp.py:414]   Expert 19 |    157 | CPU
DEBUG 01-06 17:11:10.883710.883710 lmp.py:414]   Expert  6 |    161 | CPU
DEBUG 01-06 17:11:10.883161.883161 lmp.py:414]   Expert 52 |    162 | CPU
DEBUG 01-06 17:11:10.883612.883612 lmp.py:414]   Expert 57 |    179 | CPU
DEBUG 01-06 17:11:10.883063.883063 lmp.py:414]   Expert 31 |    180 | CPU
DEBUG 01-06 17:11:10.883275.883275 lmp.py:414]   Expert 44 |    182 | GPU
DEBUG 01-06 17:11:10.883726.883726 lmp.py:414]   Expert 18 |    183 | GPU
DEBUG 01-06 17:11:10.883177.883177 lmp.py:414]   Expert 13 |    184 | GPU
DEBUG 01-06 17:11:10.883389.883389 lmp.py:414]   Expert 30 |    184 | GPU
DEBUG 01-06 17:11:10.883556.883556 lmp.py:414]   Expert 23 |    190 | GPU
DEBUG 01-06 17:11:10.883722.883722 lmp.py:414]   Expert 59 |    190 | GPU
DEBUG 01-06 17:11:10.883941.883941 lmp.py:414]   Expert 50 |    192 | GPU
DEBUG 01-06 17:11:10.883822.883822 lmp.py:414]   Expert 53 |    198 | GPU
DEBUG 01-06 17:11:10.883273.883273 lmp.py:414]   Expert 29 |    199 | GPU
DEBUG 01-06 17:11:10.883724.883724 lmp.py:414]   Expert 20 |    201 | GPU
DEBUG 01-06 17:11:10.883413.883413 lmp.py:414]   Expert 39 |    203 | GPU
DEBUG 01-06 17:11:10.883387.883387 lmp.py:414]   Expert 21 |    206 | GPU
DEBUG 01-06 17:11:10.883223.883223 lmp.py:414]   Expert 36 |    209 | GPU
DEBUG 01-06 17:11:10.883866.883866 lmp.py:414]   Expert 41 |    211 | GPU
DEBUG 01-06 17:11:10.883747.883747 lmp.py:414]   Expert 16 |    212 | GPU
DEBUG 01-06 17:11:10.883151.883151 lmp.py:414]   Expert 25 |    215 | GPU
DEBUG 01-06 17:11:10.883318.883318 lmp.py:414]   Expert 49 |    218 | GPU
DEBUG 01-06 17:11:10.883437.883437 lmp.py:414]   Expert 32 |    223 | GPU
DEBUG 01-06 17:11:10.883034.883034 lmp.py:414]   Expert 46 |    223 | GPU
DEBUG 01-06 17:11:10.883154.883154 lmp.py:414]   Expert 10 |    250 | GPU
DEBUG 01-06 17:11:10.883035.883035 lmp.py:414]   Expert  8 |    251 | GPU
DEBUG 01-06 17:11:10.883394.883394 lmp.py:414]   Expert 42 |    253 | GPU
DEBUG 01-06 17:11:10.884798.884798 lmp.py:414]   Expert 62 |    264 | GPU
DEBUG 01-06 17:11:10.884203.884203 lmp.py:414]   Expert 35 |    276 | GPU
DEBUG 01-06 17:11:10.884607.884607 lmp.py:414]   Expert 33 |    297 | GPU
DEBUG 01-06 17:11:10.884535.884535 lmp.py:414]   Expert  9 |    299 | GPU
DEBUG 01-06 17:11:10.884701.884701 lmp.py:414]   Expert 58 |    299 | GPU
DEBUG 01-06 17:11:10.884867.884867 lmp.py:414]   Expert 40 |    388 | GPU
DEBUG 01-06 17:11:10.884272.884272 lmp.py:414]   Expert  0 |    432 | GPU
DEBUG 01-06 17:11:10.884676.884676 lmp.py:414]   Expert 11 |    467 | GPU
DEBUG 01-06 17:11:10.884796.884796 lmp.py:414]   Expert 24 |    559 | GPU
DEBUG 01-06 17:11:10.884154.884154 lmp.py:414]   Expert  1 |    666 | GPU
DEBUG 01-06 17:11:10.884751.884751 lmp.py:415] 
DEBUG 01-06 17:11:10.884751.884751 lmp.py:415]   CPU total tokens: 3764 (30.6%)
DEBUG 01-06 17:11:10.884824.884824 lmp.py:416]   GPU total tokens: 8524 (69.4%)
DEBUG 01-06 17:11:10.884951.884951 cuda_h.py:19] end experts_map_get cost 0.0015406608581542969 seconds
DEBUG 01-06 17:11:10.884263.884263 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-06 17:11:10.884616.884616 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 17:11:10.884389.884389 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 17:11:10.886773.886773 cuda_h.py:19] end allocate_cuda_memory cost 0.0015480518341064453 seconds
DEBUG 01-06 17:11:10.886093.886093 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 17:11:10.886326.886326 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 17:11:10.886804.886804 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 17:11:10.886407.886407 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, cc60c6c4-8db2-41a9-a3d4-d4244832bd79
DEBUG 01-06 17:11:10.886387.886387 client.py:106] call stub.LoadModelAsync
DEBUG 01-06 17:11:10.886611.886611 mlpmodule.py:664]  experts func einsum cost 0.0628659725189209 s
INFO 01-06 17:11:10.887792.887792 client.py:127] Model loaded
DEBUG 01-06 17:11:10.888562.888562 cuda_h.py:19] end sllm_worker_task cost 0.010741233825683594 seconds
INFO 01-06 17:11:10.893827.893827 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, cc60c6c4-8db2-41a9-a3d4-d4244832bd79
DEBUG 01-06 17:11:10.893640.893640 cuda_h.py:19] end load_into_gpu_async cost 0.007586956024169922 seconds
DEBUG 01-06 17:11:10.893603.893603 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 17:11:10.894852.894852 cuda_h.py:19] end restore_tensors2 cost 0.0006399154663085938 seconds
DEBUG 01-06 17:11:10.894437.894437 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.010269403457641602 seconds
DEBUG 01-06 17:11:10.899909.899909 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.014907598495483398 seconds
DEBUG 01-06 17:11:10.899925.899925 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-06 17:11:10.899896.899896 lmp.py:461] 
DEBUG 01-06 17:11:10.899896.899896 lmp.py:461]   Computing 32 experts on CPU...
DEBUG 01-06 17:11:10.899747.899747 cuda_h.py:19] end cpu_experts_submit cost 0.0001723766326904297 seconds
DEBUG 01-06 17:11:10.899516.899516 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-06 17:11:10.910045.910045 mlpmodule.py:706] group tensors cost 0.010585784912109375 s
DEBUG 01-06 17:11:10.912305.912305 mlpmodule.py:744] pad cost 0.0016977787017822266 s
DEBUG 01-06 17:11:10.912024.912024 mlpmodule.py:750] create cpu tensor cost 4.76837158203125e-05 s
DEBUG 01-06 17:11:10.912973.912973 mlpmodule.py:755] move to cpu cost 3.2901763916015625e-05 s
DEBUG 01-06 17:11:10.921388.921388 mlpmodule.py:769] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-06 17:11:10.921814.921814 mlpmodule.py:770] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-06 17:11:10.921479.921479 mlpmodule.py:775] group_w3 first element: -0.0213623046875
WARNING 01-06 17:11:10.922992.922992 mlpmodule.py:785] start einsum2
DEBUG 01-06 17:11:10.936891.936891 mlpmodule.py:795] group einsum cost 0.023366212844848633 s
DEBUG 01-06 17:11:10.937811.937811 mlpmodule.py:803] cpy2cputensor cost 0.0006833076477050781 s
DEBUG 01-06 17:11:10.941475.941475 cuda_h.py:19] end wait_cetm_experts cost 0.04197287559509277 seconds
DEBUG 01-06 17:11:10.941872.941872 cuda_h.py:10] start gpu_sexperts
DEBUG 01-06 17:11:10.942053.942053 cuda_h.py:19] end gpu_sexperts cost 0.0006158351898193359 seconds
DEBUG 01-06 17:11:10.942141.942141 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-06 17:11:10.942229.942229 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.5272369384765625e-05 seconds
DEBUG 01-06 17:11:10.942363.942363 cuda_h.py:10] start wait_experts
INFO 01-06 17:11:10.942311.942311 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, cc60c6c4-8db2-41a9-a3d4-d4244832bd79
INFO 01-06 17:11:10.944849.944849 client.py:127] Model loaded
DEBUG 01-06 17:11:10.944083.944083 cuda_h.py:19] end wait_experts cost 0.0019044876098632812 seconds
DEBUG 01-06 17:11:10.944647.944647 cuda_h.py:10] start gpu_experts
DEBUG 01-06 17:11:10.944926.944926 lmp.py:506]   Computing 32 experts on GPU...
DEBUG 01-06 17:11:10.945845.945845 mlpmodule.py:533] gpu group tensors cost 0.0006608963012695312 s
DEBUG 01-06 17:11:10.947291.947291 mlpmodule.py:566] gpu pad cost 0.0017848014831542969 s
DEBUG 01-06 17:11:10.947525.947525 mlpmodule.py:584] gpu group einsum cost 0.0005810260772705078 s
DEBUG 01-06 17:11:10.951512.951512 mlpmodule.py:613] gpu experts func einsum cost 0.006731748580932617 s
DEBUG 01-06 17:11:10.951099.951099 cuda_h.py:19] end gpu_experts cost 0.006940364837646484 seconds
DEBUG 01-06 17:11:10.951990.951990 cuda_h.py:19] end layer_moe_generate_10 cost 0.06971979141235352 seconds
DEBUG 01-06 17:11:10.951944.951944 lmp.py:220] -------------------------------- end layer 10 --------------------------------
DEBUG 01-06 17:11:10.951283.951283 lmp.py:176] -------------------------------- start layer 11 --------------------------------
DEBUG 01-06 17:11:10.951840.951840 cuda_h.py:10] start start_load_qkvogn_s_weight_l_12
DEBUG 01-06 17:11:10.951364.951364 cuda_h.py:10] start start_load_qkvogn_s_weight_l_12
DEBUG 01-06 17:11:10.952691.952691 cuda_h.py:19] end start_load_qkvogn_s_weight_l_12 cost 3.504753112792969e-05 seconds
DEBUG 01-06 17:11:10.952824.952824 cuda_h.py:19] end start_load_qkvogn_s_weight_l_12 cost 6.747245788574219e-05 seconds
DEBUG 01-06 17:11:10.952613.952613 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-06 17:11:10.952516.952516 mlpmodule.py:367] cuda:1 cuda:1
DEBUG 01-06 17:11:10.952055.952055 cuda_h.py:10] start sllm_worker_task
DEBUG 01-06 17:11:10.952906.952906 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 17:11:10.952312.952312 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 17:11:10.954725.954725 cuda_h.py:19] end allocate_cuda_memory cost 0.0021615028381347656 seconds
DEBUG 01-06 17:11:10.954751.954751 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 17:11:10.954894.954894 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 17:11:10.955281.955281 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 17:11:10.955906.955906 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, c2e3e9c7-8ec7-4bb8-ad52-2ee2373d7e25
DEBUG 01-06 17:11:10.955715.955715 client.py:106] call stub.LoadModelAsync
DEBUG 01-06 17:11:10.955148.955148 mlpmodule.py:664]  experts func einsum cost 0.055794477462768555 s
DEBUG 01-06 17:11:10.955565.955565 cuda_h.py:10] start self_attn
INFO 01-06 17:11:10.956734.956734 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, c2e3e9c7-8ec7-4bb8-ad52-2ee2373d7e25
DEBUG 01-06 17:11:10.956366.956366 cuda_h.py:19] end load_into_gpu_async cost 0.002045154571533203 seconds
DEBUG 01-06 17:11:10.956307.956307 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 17:11:10.957450.957450 cuda_h.py:19] end restore_tensors2 cost 7.843971252441406e-05 seconds
DEBUG 01-06 17:11:10.957967.957967 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.004753828048706055 seconds
INFO 01-06 17:11:10.957426.957426 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, c2e3e9c7-8ec7-4bb8-ad52-2ee2373d7e25
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-06 17:11:10.958041.958041 cuda_h.py:19] end self_attn cost 0.0028388500213623047 seconds
DEBUG 01-06 17:11:10.959409.959409 cuda_h.py:19] end iln_self_attn_paln cost 0.007123708724975586 seconds
DEBUG 01-06 17:11:10.959537.959537 cuda_h.py:10] start layer_moe_generate_11
DEBUG 01-06 17:11:10.959730.959730 cuda_h.py:10] start gate
DEBUG 01-06 17:11:10.960905.960905 cuda_h.py:19] end gate cost 0.0006556510925292969 seconds
DEBUG 01-06 17:11:10.960973.960973 cuda_h.py:10] start experts_map_get
DEBUG 01-06 17:11:10.960281.960281 lmp.py:403] 
DEBUG 01-06 17:11:10.960281.960281 lmp.py:403] Expert Token Distribution & Device Allocation:
DEBUG 01-06 17:11:10.960097.960097 lmp.py:404]   Total experts: 64
DEBUG 01-06 17:11:10.960416.960416 lmp.py:405]   CPU experts: 32 (50%)
DEBUG 01-06 17:11:10.960489.960489 lmp.py:406]   GPU experts: 32 (50%)
DEBUG 01-06 17:11:10.960324.960324 lmp.py:407] 
DEBUG 01-06 17:11:10.960324.960324 lmp.py:407]   Expert ID | Tokens | Device
DEBUG 01-06 17:11:10.960683.960683 lmp.py:408]   -----------------------------------
DEBUG 01-06 17:11:10.960048.960048 lmp.py:414]   Expert 39 |     15 | CPU
DEBUG 01-06 17:11:10.960406.960406 lmp.py:414]   Expert 13 |     18 | CPU
DEBUG 01-06 17:11:10.960572.960572 lmp.py:414]   Expert 49 |     33 | CPU
DEBUG 01-06 17:11:10.960500.960500 lmp.py:414]   Expert 35 |     50 | CPU
DEBUG 01-06 17:11:10.960712.960712 lmp.py:414]   Expert 19 |     62 | CPU
DEBUG 01-06 17:11:10.960163.960163 lmp.py:414]   Expert 32 |     73 | CPU
DEBUG 01-06 17:11:10.960852.960852 lmp.py:414]   Expert  9 |     77 | CPU
DEBUG 01-06 17:11:10.960542.960542 lmp.py:414]   Expert 41 |     78 | CPU
DEBUG 01-06 17:11:10.960946.960946 lmp.py:414]   Expert 26 |     80 | CPU
DEBUG 01-06 17:11:10.960112.960112 lmp.py:414]   Expert 46 |     82 | CPU
DEBUG 01-06 17:11:10.960040.960040 lmp.py:414]   Expert 23 |     83 | CPU
DEBUG 01-06 17:11:10.960968.960968 lmp.py:414]   Expert 33 |     84 | CPU
DEBUG 01-06 17:11:10.960134.960134 lmp.py:414]   Expert 31 |     87 | CPU
DEBUG 01-06 17:11:10.960585.960585 lmp.py:414]   Expert 18 |     94 | CPU
DEBUG 01-06 17:11:10.960036.960036 lmp.py:414]   Expert 38 |     95 | CPU
DEBUG 01-06 17:11:10.960725.960725 lmp.py:414]   Expert  6 |     99 | CPU
DEBUG 01-06 17:11:10.960938.960938 lmp.py:414]   Expert  3 |    107 | CPU
DEBUG 01-06 17:11:10.960627.960627 lmp.py:414]   Expert 17 |    107 | CPU
DEBUG 01-06 17:11:10.960316.960316 lmp.py:414]   Expert 20 |    117 | CPU
DEBUG 01-06 17:11:10.960767.960767 lmp.py:414]   Expert 59 |    123 | CPU
DEBUG 01-06 17:11:10.960602.960602 lmp.py:414]   Expert 61 |    130 | CPU
DEBUG 01-06 17:11:10.960768.960768 lmp.py:414]   Expert 16 |    132 | CPU
DEBUG 01-06 17:11:10.960696.960696 lmp.py:414]   Expert 40 |    134 | CPU
DEBUG 01-06 17:11:10.960624.960624 lmp.py:414]   Expert 62 |    135 | CPU
DEBUG 01-06 17:11:10.960790.960790 lmp.py:414]   Expert 42 |    138 | CPU
DEBUG 01-06 17:11:10.960002.960002 lmp.py:414]   Expert 43 |    140 | CPU
DEBUG 01-06 17:11:10.960692.960692 lmp.py:414]   Expert 15 |    142 | CPU
DEBUG 01-06 17:11:10.960142.960142 lmp.py:414]   Expert 50 |    142 | CPU
DEBUG 01-06 17:11:10.960832.960832 lmp.py:414]   Expert  2 |    146 | CPU
DEBUG 01-06 17:11:10.960521.960521 lmp.py:414]   Expert 36 |    147 | CPU
DEBUG 01-06 17:11:10.961495.961495 lmp.py:414]   Expert 63 |    147 | CPU
DEBUG 01-06 17:11:10.961946.961946 lmp.py:414]   Expert 44 |    154 | CPU
DEBUG 01-06 17:11:10.961635.961635 lmp.py:414]   Expert 10 |    164 | GPU
DEBUG 01-06 17:11:10.961278.961278 lmp.py:414]   Expert  5 |    181 | GPU
DEBUG 01-06 17:11:10.961444.961444 lmp.py:414]   Expert 34 |    182 | GPU
DEBUG 01-06 17:11:10.961372.961372 lmp.py:414]   Expert 27 |    184 | GPU
DEBUG 01-06 17:11:10.961061.961061 lmp.py:414]   Expert 45 |    191 | GPU
DEBUG 01-06 17:11:10.961466.961466 lmp.py:414]   Expert 52 |    197 | GPU
DEBUG 01-06 17:11:10.961155.961155 lmp.py:414]   Expert 60 |    197 | GPU
DEBUG 01-06 17:11:10.961083.961083 lmp.py:414]   Expert 48 |    198 | GPU
DEBUG 01-06 17:11:10.961534.961534 lmp.py:414]   Expert 51 |    211 | GPU
DEBUG 01-06 17:11:10.961985.961985 lmp.py:414]   Expert 56 |    216 | GPU
DEBUG 01-06 17:11:10.961197.961197 lmp.py:414]   Expert  7 |    222 | GPU
DEBUG 01-06 17:11:10.961648.961648 lmp.py:414]   Expert 53 |    225 | GPU
DEBUG 01-06 17:11:10.961099.961099 lmp.py:414]   Expert  8 |    228 | GPU
DEBUG 01-06 17:11:10.961311.961311 lmp.py:414]   Expert 24 |    229 | GPU
DEBUG 01-06 17:11:10.961193.961193 lmp.py:414]   Expert 57 |    250 | GPU
DEBUG 01-06 17:11:10.961597.961597 lmp.py:414]   Expert 29 |    257 | GPU
DEBUG 01-06 17:11:10.961287.961287 lmp.py:414]   Expert 47 |    257 | GPU
DEBUG 01-06 17:11:10.961691.961691 lmp.py:414]   Expert 21 |    269 | GPU
DEBUG 01-06 17:11:10.961857.961857 lmp.py:414]   Expert  0 |    281 | GPU
DEBUG 01-06 17:11:10.961547.961547 lmp.py:414]   Expert  4 |    285 | GPU
DEBUG 01-06 17:11:10.961998.961998 lmp.py:414]   Expert 14 |    295 | GPU
DEBUG 01-06 17:11:10.961210.961210 lmp.py:414]   Expert 55 |    315 | GPU
DEBUG 01-06 17:11:10.961423.961423 lmp.py:414]   Expert 22 |    320 | GPU
DEBUG 01-06 17:11:10.961112.961112 lmp.py:414]   Expert 37 |    322 | GPU
DEBUG 01-06 17:11:10.961324.961324 lmp.py:414]   Expert  1 |    325 | GPU
DEBUG 01-06 17:11:10.961537.961537 lmp.py:414]   Expert 54 |    329 | GPU
DEBUG 01-06 17:11:10.961749.961749 lmp.py:414]   Expert 58 |    333 | GPU
DEBUG 01-06 17:11:10.961200.961200 lmp.py:414]   Expert 28 |    346 | GPU
DEBUG 01-06 17:11:10.961174.961174 lmp.py:414]   Expert 12 |    365 | GPU
DEBUG 01-06 17:11:10.961863.961863 lmp.py:414]   Expert 25 |    403 | GPU
DEBUG 01-06 17:11:10.961076.961076 lmp.py:414]   Expert 11 |    413 | GPU
DEBUG 01-06 17:11:10.961527.961527 lmp.py:414]   Expert 30 |    847 | GPU
DEBUG 01-06 17:11:10.961647.961647 lmp.py:415] 
DEBUG 01-06 17:11:10.961647.961647 lmp.py:415]   CPU total tokens: 3251 (26.5%)
DEBUG 01-06 17:11:10.961528.961528 lmp.py:416]   GPU total tokens: 9037 (73.5%)
DEBUG 01-06 17:11:10.961284.961284 cuda_h.py:19] end experts_map_get cost 0.001535654067993164 seconds
DEBUG 01-06 17:11:10.961881.961881 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-06 17:11:10.961995.961995 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 17:11:10.961615.961615 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 17:11:10.963395.963395 cuda_h.py:19] end allocate_cuda_memory cost 0.0014903545379638672 seconds
DEBUG 01-06 17:11:10.963490.963490 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 17:11:10.963677.963677 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 17:11:10.963724.963724 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 17:11:10.963851.963851 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, df344517-d73b-439a-ba65-5668ee6c294f
DEBUG 01-06 17:11:10.963400.963400 client.py:106] call stub.LoadModelAsync
INFO 01-06 17:11:10.965633.965633 client.py:127] Model loaded
DEBUG 01-06 17:11:10.965625.965625 cuda_h.py:19] end sllm_worker_task cost 0.013173580169677734 seconds
INFO 01-06 17:11:10.966744.966744 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, df344517-d73b-439a-ba65-5668ee6c294f
DEBUG 01-06 17:11:10.966733.966733 cuda_h.py:19] end load_into_gpu_async cost 0.0032694339752197266 seconds
DEBUG 01-06 17:11:10.966721.966721 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 17:11:10.967117.967117 cuda_h.py:19] end restore_tensors2 cost 0.0003364086151123047 seconds
DEBUG 01-06 17:11:10.967946.967946 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.005454540252685547 seconds
DEBUG 01-06 17:11:10.969571.969571 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.008137941360473633 seconds
DEBUG 01-06 17:11:10.969262.969262 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-06 17:11:10.969317.969317 lmp.py:461] 
DEBUG 01-06 17:11:10.969317.969317 lmp.py:461]   Computing 32 experts on CPU...
DEBUG 01-06 17:11:10.969498.969498 cuda_h.py:19] end cpu_experts_submit cost 0.00011181831359863281 seconds
DEBUG 01-06 17:11:10.970863.970863 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-06 17:11:10.981218.981218 mlpmodule.py:706] group tensors cost 0.011177301406860352 s
DEBUG 01-06 17:11:10.983127.983127 mlpmodule.py:744] pad cost 0.0016112327575683594 s
DEBUG 01-06 17:11:10.983230.983230 mlpmodule.py:750] create cpu tensor cost 4.673004150390625e-05 s
DEBUG 01-06 17:11:10.984464.984464 mlpmodule.py:755] move to cpu cost 3.314018249511719e-05 s
DEBUG 01-06 17:11:10.993208.993208 mlpmodule.py:769] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-06 17:11:10.993634.993634 mlpmodule.py:770] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-06 17:11:10.993246.993246 mlpmodule.py:775] group_w3 first element: -0.006134033203125
WARNING 01-06 17:11:10.993747.993747 mlpmodule.py:785] start einsum2
DEBUG 01-06 17:11:11.009500.009500 mlpmodule.py:795] group einsum cost 0.02575063705444336 s
DEBUG 01-06 17:11:11.010684.010684 mlpmodule.py:803] cpy2cputensor cost 0.0006260871887207031 s
DEBUG 01-06 17:11:11.015603.015603 cuda_h.py:19] end wait_cetm_experts cost 0.04495120048522949 seconds
DEBUG 01-06 17:11:11.015782.015782 cuda_h.py:10] start gpu_sexperts
DEBUG 01-06 17:11:11.015963.015963 cuda_h.py:19] end gpu_sexperts cost 0.0006148815155029297 seconds
DEBUG 01-06 17:11:11.015574.015574 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-06 17:11:11.016186.016186 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.47955322265625e-05 seconds
DEBUG 01-06 17:11:11.016319.016319 cuda_h.py:10] start wait_experts
INFO 01-06 17:11:11.016837.016837 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, df344517-d73b-439a-ba65-5668ee6c294f
INFO 01-06 17:11:11.019063.019063 client.py:127] Model loaded
DEBUG 01-06 17:11:11.019582.019582 cuda_h.py:19] end wait_experts cost 0.0034635066986083984 seconds
DEBUG 01-06 17:11:11.019669.019669 cuda_h.py:10] start gpu_experts
DEBUG 01-06 17:11:11.019186.019186 lmp.py:506]   Computing 32 experts on GPU...
DEBUG 01-06 17:11:11.020198.020198 mlpmodule.py:533] gpu group tensors cost 0.0006566047668457031 s
DEBUG 01-06 17:11:11.022439.022439 mlpmodule.py:566] gpu pad cost 0.0017554759979248047 s
DEBUG 01-06 17:11:11.022050.022050 mlpmodule.py:584] gpu group einsum cost 0.0005519390106201172 s
DEBUG 01-06 17:11:11.026488.026488 mlpmodule.py:613] gpu experts func einsum cost 0.006558656692504883 s
DEBUG 01-06 17:11:11.026194.026194 cuda_h.py:19] end gpu_experts cost 0.006749153137207031 seconds
DEBUG 01-06 17:11:11.026721.026721 cuda_h.py:19] end layer_moe_generate_11 cost 0.06716752052307129 seconds
DEBUG 01-06 17:11:11.026175.026175 mlpmodule.py:664]  experts func einsum cost 0.056394338607788086 s
DEBUG 01-06 17:11:11.026239.026239 lmp.py:220] -------------------------------- end layer 11 --------------------------------
DEBUG 01-06 17:11:11.027156.027156 lmp.py:176] -------------------------------- start layer 12 --------------------------------
DEBUG 01-06 17:11:11.027282.027282 cuda_h.py:10] start start_load_qkvogn_s_weight_l_13
DEBUG 01-06 17:11:11.027614.027614 cuda_h.py:10] start start_load_qkvogn_s_weight_l_13
DEBUG 01-06 17:11:11.027650.027650 cuda_h.py:19] end start_load_qkvogn_s_weight_l_13 cost 3.2901763916015625e-05 seconds
DEBUG 01-06 17:11:11.027114.027114 cuda_h.py:19] end start_load_qkvogn_s_weight_l_13 cost 6.556510925292969e-05 seconds
DEBUG 01-06 17:11:11.027188.027188 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-06 17:11:11.027667.027667 mlpmodule.py:367] cuda:1 cuda:1
DEBUG 01-06 17:11:11.027748.027748 cuda_h.py:10] start sllm_worker_task
DEBUG 01-06 17:11:11.027402.027402 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 17:11:11.027529.027529 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 17:11:11.027303.027303 cuda_h.py:19] end allocate_cuda_memory cost 0.0003230571746826172 seconds
DEBUG 01-06 17:11:11.027895.027895 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 17:11:11.027181.027181 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 17:11:11.028481.028481 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 17:11:11.028230.028230 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 75d0970b-f28f-4713-b394-e9e56602233b
DEBUG 01-06 17:11:11.028816.028816 client.py:106] call stub.LoadModelAsync
DEBUG 01-06 17:11:11.028797.028797 cuda_h.py:10] start self_attn
INFO 01-06 17:11:11.029928.029928 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 75d0970b-f28f-4713-b394-e9e56602233b
DEBUG 01-06 17:11:11.029672.029672 cuda_h.py:19] end load_into_gpu_async cost 0.0015902519226074219 seconds
DEBUG 01-06 17:11:11.029752.029752 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 17:11:11.029596.029596 cuda_h.py:19] end restore_tensors2 cost 7.033348083496094e-05 seconds
DEBUG 01-06 17:11:11.029035.029035 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0022535324096679688 seconds
INFO 01-06 17:11:11.029885.029885 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 75d0970b-f28f-4713-b394-e9e56602233b
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-06 17:11:11.031829.031829 cuda_h.py:19] end self_attn cost 0.0028657913208007812 seconds
DEBUG 01-06 17:11:11.031660.031660 cuda_h.py:19] end iln_self_attn_paln cost 0.0043926239013671875 seconds
DEBUG 01-06 17:11:11.031834.031834 cuda_h.py:10] start layer_moe_generate_12
DEBUG 01-06 17:11:11.031074.031074 cuda_h.py:10] start gate
DEBUG 01-06 17:11:11.032044.032044 cuda_h.py:19] end gate cost 0.0006456375122070312 seconds
DEBUG 01-06 17:11:11.032556.032556 cuda_h.py:10] start experts_map_get
DEBUG 01-06 17:11:11.032102.032102 lmp.py:403] 
DEBUG 01-06 17:11:11.032102.032102 lmp.py:403] Expert Token Distribution & Device Allocation:
DEBUG 01-06 17:11:11.032858.032858 lmp.py:404]   Total experts: 64
DEBUG 01-06 17:11:11.032985.032985 lmp.py:405]   CPU experts: 32 (50%)
DEBUG 01-06 17:11:11.032535.032535 lmp.py:406]   GPU experts: 32 (50%)
DEBUG 01-06 17:11:11.032701.032701 lmp.py:407] 
DEBUG 01-06 17:11:11.032701.032701 lmp.py:407]   Expert ID | Tokens | Device
DEBUG 01-06 17:11:11.032867.032867 lmp.py:408]   -----------------------------------
DEBUG 01-06 17:11:11.032517.032517 lmp.py:414]   Expert 12 |     17 | CPU
DEBUG 01-06 17:11:11.032160.032160 lmp.py:414]   Expert 47 |     20 | CPU
DEBUG 01-06 17:11:11.032611.032611 lmp.py:414]   Expert 38 |     30 | CPU
DEBUG 01-06 17:11:11.032062.032062 lmp.py:414]   Expert 27 |     31 | CPU
DEBUG 01-06 17:11:11.032513.032513 lmp.py:414]   Expert 52 |     36 | CPU
DEBUG 01-06 17:11:11.032917.032917 lmp.py:414]   Expert 16 |     39 | CPU
DEBUG 01-06 17:11:11.032845.032845 lmp.py:414]   Expert 63 |     43 | CPU
DEBUG 01-06 17:11:11.032011.032011 lmp.py:414]   Expert 43 |     54 | CPU
DEBUG 01-06 17:11:11.032939.032939 lmp.py:414]   Expert  4 |     59 | CPU
DEBUG 01-06 17:11:11.033390.033390 lmp.py:414]   Expert 61 |     62 | CPU
DEBUG 01-06 17:11:11.033841.033841 lmp.py:414]   Expert 34 |     69 | CPU
DEBUG 01-06 17:11:11.033053.033053 lmp.py:414]   Expert 44 |     69 | CPU
DEBUG 01-06 17:11:11.033027.033027 lmp.py:414]   Expert 53 |     80 | CPU
DEBUG 01-06 17:11:11.033239.033239 lmp.py:414]   Expert 32 |     86 | CPU
DEBUG 01-06 17:11:11.033121.033121 lmp.py:414]   Expert  0 |     88 | CPU
DEBUG 01-06 17:11:11.033810.033810 lmp.py:414]   Expert 37 |     88 | CPU
DEBUG 01-06 17:11:11.033738.033738 lmp.py:414]   Expert 13 |     96 | CPU
DEBUG 01-06 17:11:11.033142.033142 lmp.py:414]   Expert 39 |    111 | CPU
DEBUG 01-06 17:11:11.033547.033547 lmp.py:414]   Expert 21 |    113 | CPU
DEBUG 01-06 17:11:11.033428.033428 lmp.py:414]   Expert 11 |    115 | CPU
DEBUG 01-06 17:11:11.033071.033071 lmp.py:414]   Expert 60 |    123 | CPU
DEBUG 01-06 17:11:11.033714.033714 lmp.py:414]   Expert 20 |    134 | CPU
DEBUG 01-06 17:11:11.033880.033880 lmp.py:414]   Expert  8 |    136 | CPU
DEBUG 01-06 17:11:11.033570.033570 lmp.py:414]   Expert 14 |    136 | CPU
DEBUG 01-06 17:11:11.033259.033259 lmp.py:414]   Expert 22 |    141 | CPU
DEBUG 01-06 17:11:11.033948.033948 lmp.py:414]   Expert 57 |    145 | CPU
DEBUG 01-06 17:11:11.033399.033399 lmp.py:414]   Expert  2 |    152 | CPU
DEBUG 01-06 17:11:11.033089.033089 lmp.py:414]   Expert 17 |    153 | CPU
DEBUG 01-06 17:11:11.033778.033778 lmp.py:414]   Expert 45 |    159 | CPU
DEBUG 01-06 17:11:11.033467.033467 lmp.py:414]   Expert 18 |    161 | CPU
DEBUG 01-06 17:11:11.033395.033395 lmp.py:414]   Expert 58 |    162 | CPU
DEBUG 01-06 17:11:11.033084.033084 lmp.py:414]   Expert  7 |    166 | CPU
DEBUG 01-06 17:11:11.033966.033966 lmp.py:414]   Expert 23 |    166 | GPU
DEBUG 01-06 17:11:11.033893.033893 lmp.py:414]   Expert 42 |    167 | GPU
DEBUG 01-06 17:11:11.033298.033298 lmp.py:414]   Expert 30 |    168 | GPU
DEBUG 01-06 17:11:11.033418.033418 lmp.py:414]   Expert 55 |    173 | GPU
DEBUG 01-06 17:11:11.033345.033345 lmp.py:414]   Expert 49 |    174 | GPU
DEBUG 01-06 17:11:11.033796.033796 lmp.py:414]   Expert 51 |    178 | GPU
DEBUG 01-06 17:11:11.033486.033486 lmp.py:414]   Expert 35 |    179 | GPU
DEBUG 01-06 17:11:11.033175.033175 lmp.py:414]   Expert 48 |    179 | GPU
DEBUG 01-06 17:11:11.033864.033864 lmp.py:414]   Expert 62 |    180 | GPU
DEBUG 01-06 17:11:11.033077.033077 lmp.py:414]   Expert 29 |    183 | GPU
DEBUG 01-06 17:11:11.033766.033766 lmp.py:414]   Expert  6 |    196 | GPU
DEBUG 01-06 17:11:11.033455.033455 lmp.py:414]   Expert 36 |    198 | GPU
DEBUG 01-06 17:11:11.033098.033098 lmp.py:414]   Expert 31 |    200 | GPU
DEBUG 01-06 17:11:11.033503.033503 lmp.py:414]   Expert  1 |    201 | GPU
DEBUG 01-06 17:11:11.033146.033146 lmp.py:414]   Expert 25 |    203 | GPU
DEBUG 01-06 17:11:11.033550.033550 lmp.py:414]   Expert 28 |    223 | GPU
DEBUG 01-06 17:11:11.033240.033240 lmp.py:414]   Expert 41 |    223 | GPU
DEBUG 01-06 17:11:11.033167.033167 lmp.py:414]   Expert  5 |    236 | GPU
DEBUG 01-06 17:11:11.033857.033857 lmp.py:414]   Expert 19 |    237 | GPU
DEBUG 01-06 17:11:11.033308.033308 lmp.py:414]   Expert 54 |    237 | GPU
DEBUG 01-06 17:11:11.033997.033997 lmp.py:414]   Expert 24 |    246 | GPU
DEBUG 01-06 17:11:11.033686.033686 lmp.py:414]   Expert  9 |    247 | GPU
DEBUG 01-06 17:11:11.033614.033614 lmp.py:414]   Expert 50 |    289 | GPU
DEBUG 01-06 17:11:11.033065.033065 lmp.py:414]   Expert 46 |    303 | GPU
DEBUG 01-06 17:11:11.033946.033946 lmp.py:414]   Expert 59 |    304 | GPU
DEBUG 01-06 17:11:11.033351.033351 lmp.py:414]   Expert 56 |    391 | GPU
DEBUG 01-06 17:11:11.033755.033755 lmp.py:414]   Expert 26 |    396 | GPU
DEBUG 01-06 17:11:11.033921.033921 lmp.py:414]   Expert 33 |    427 | GPU
DEBUG 01-06 17:11:11.033564.033564 lmp.py:414]   Expert  3 |    583 | GPU
DEBUG 01-06 17:11:11.033492.033492 lmp.py:414]   Expert 15 |    656 | GPU
DEBUG 01-06 17:11:11.033181.033181 lmp.py:414]   Expert 10 |    698 | GPU
DEBUG 01-06 17:11:11.033632.033632 lmp.py:414]   Expert 40 |    773 | GPU
DEBUG 01-06 17:11:11.033275.033275 lmp.py:415] 
DEBUG 01-06 17:11:11.033275.033275 lmp.py:415]   CPU total tokens: 3074 (25.0%)
DEBUG 01-06 17:11:11.033395.033395 lmp.py:416]   GPU total tokens: 9214 (75.0%)
DEBUG 01-06 17:11:11.033853.033853 cuda_h.py:19] end experts_map_get cost 0.0015254020690917969 seconds
DEBUG 01-06 17:11:11.034734.034734 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-06 17:11:11.034848.034848 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 17:11:11.034323.034323 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 17:11:11.035955.035955 cuda_h.py:19] end allocate_cuda_memory cost 0.001627206802368164 seconds
DEBUG 01-06 17:11:11.035480.035480 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 17:11:11.035098.035098 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 17:11:11.035860.035860 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 17:11:11.036510.036510 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, a6f1f6ab-22e0-44a1-b2de-8d1c39814b64
DEBUG 01-06 17:11:11.036868.036868 client.py:106] call stub.LoadModelAsync
INFO 01-06 17:11:11.037197.037197 client.py:127] Model loaded
DEBUG 01-06 17:11:11.037840.037840 cuda_h.py:19] end sllm_worker_task cost 0.010512590408325195 seconds
INFO 01-06 17:11:11.039767.039767 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, a6f1f6ab-22e0-44a1-b2de-8d1c39814b64
DEBUG 01-06 17:11:11.039395.039395 cuda_h.py:19] end load_into_gpu_async cost 0.0033266544342041016 seconds
DEBUG 01-06 17:11:11.039119.039119 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 17:11:11.039466.039466 cuda_h.py:19] end restore_tensors2 cost 0.000400543212890625 seconds
DEBUG 01-06 17:11:11.039772.039772 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.005819559097290039 seconds
DEBUG 01-06 17:11:11.042953.042953 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.008490562438964844 seconds
DEBUG 01-06 17:11:11.042551.042551 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-06 17:11:11.042176.042176 lmp.py:461] 
DEBUG 01-06 17:11:11.042176.042176 lmp.py:461]   Computing 32 experts on CPU...
DEBUG 01-06 17:11:11.042257.042257 cuda_h.py:19] end cpu_experts_submit cost 0.00010800361633300781 seconds
DEBUG 01-06 17:11:11.042430.042430 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-06 17:11:11.053802.053802 mlpmodule.py:706] group tensors cost 0.010898590087890625 s
DEBUG 01-06 17:11:11.056602.056602 mlpmodule.py:744] pad cost 0.0016312599182128906 s
DEBUG 01-06 17:11:11.056672.056672 mlpmodule.py:750] create cpu tensor cost 6.0558319091796875e-05 s
DEBUG 01-06 17:11:11.056668.056668 mlpmodule.py:755] move to cpu cost 3.24249267578125e-05 s
DEBUG 01-06 17:11:11.067285.067285 mlpmodule.py:769] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-06 17:11:11.067195.067195 mlpmodule.py:770] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-06 17:11:11.067952.067952 mlpmodule.py:775] group_w3 first element: -0.0162353515625
WARNING 01-06 17:11:11.067035.067035 mlpmodule.py:785] start einsum2
DEBUG 01-06 17:11:11.085445.085445 mlpmodule.py:795] group einsum cost 0.029212236404418945 s
DEBUG 01-06 17:11:11.086788.086788 mlpmodule.py:803] cpy2cputensor cost 0.0006518363952636719 s
DEBUG 01-06 17:11:11.090237.090237 cuda_h.py:19] end wait_cetm_experts cost 0.04795050621032715 seconds
DEBUG 01-06 17:11:11.090648.090648 cuda_h.py:10] start gpu_sexperts
DEBUG 01-06 17:11:11.091021.091021 cuda_h.py:19] end gpu_sexperts cost 0.0006148815155029297 seconds
DEBUG 01-06 17:11:11.091301.091301 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-06 17:11:11.091105.091105 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.5033950805664062e-05 seconds
DEBUG 01-06 17:11:11.091238.091238 cuda_h.py:10] start wait_experts
INFO 01-06 17:11:11.091471.091471 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, a6f1f6ab-22e0-44a1-b2de-8d1c39814b64
INFO 01-06 17:11:11.093376.093376 client.py:127] Model loaded
DEBUG 01-06 17:11:11.093464.093464 cuda_h.py:19] end wait_experts cost 0.0013647079467773438 seconds
DEBUG 01-06 17:11:11.093120.093120 cuda_h.py:10] start gpu_experts
DEBUG 01-06 17:11:11.093161.093161 lmp.py:506]   Computing 32 experts on GPU...
DEBUG 01-06 17:11:11.093120.093120 mlpmodule.py:533] gpu group tensors cost 0.0006527900695800781 s
DEBUG 01-06 17:11:11.095948.095948 mlpmodule.py:566] gpu pad cost 0.0017507076263427734 s
DEBUG 01-06 17:11:11.096275.096275 mlpmodule.py:584] gpu group einsum cost 0.0005967617034912109 s
DEBUG 01-06 17:11:11.099122.099122 mlpmodule.py:613] gpu experts func einsum cost 0.00665593147277832 s
DEBUG 01-06 17:11:11.100450.100450 cuda_h.py:19] end gpu_experts cost 0.006850242614746094 seconds
DEBUG 01-06 17:11:11.100010.100010 cuda_h.py:19] end layer_moe_generate_12 cost 0.0684969425201416 seconds
DEBUG 01-06 17:11:11.100634.100634 lmp.py:220] -------------------------------- end layer 12 --------------------------------
DEBUG 01-06 17:11:11.100417.100417 lmp.py:176] -------------------------------- start layer 13 --------------------------------
DEBUG 01-06 17:11:11.100358.100358 cuda_h.py:10] start start_load_qkvogn_s_weight_l_14
DEBUG 01-06 17:11:11.100075.100075 cuda_h.py:10] start start_load_qkvogn_s_weight_l_14
DEBUG 01-06 17:11:11.100130.100130 cuda_h.py:19] end start_load_qkvogn_s_weight_l_14 cost 4.5299530029296875e-05 seconds
DEBUG 01-06 17:11:11.100794.100794 cuda_h.py:19] end start_load_qkvogn_s_weight_l_14 cost 8.177757263183594e-05 seconds
DEBUG 01-06 17:11:11.100159.100159 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-06 17:11:11.100724.100724 cuda_h.py:10] start sllm_worker_task
DEBUG 01-06 17:11:11.100953.100953 mlpmodule.py:367] cuda:1 cuda:1
DEBUG 01-06 17:11:11.100968.100968 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 17:11:11.101682.101682 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 17:11:11.103820.103820 cuda_h.py:19] end allocate_cuda_memory cost 0.002300739288330078 seconds
DEBUG 01-06 17:11:11.103770.103770 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 17:11:11.103322.103322 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 17:11:11.103144.103144 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 17:11:11.103324.103324 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 40b8ec52-1c24-431c-bb67-1450425c8cf3
DEBUG 01-06 17:11:11.103910.103910 client.py:106] call stub.LoadModelAsync
DEBUG 01-06 17:11:11.103094.103094 mlpmodule.py:664]  experts func einsum cost 0.060987234115600586 s
DEBUG 01-06 17:11:11.104953.104953 cuda_h.py:10] start self_attn
INFO 01-06 17:11:11.105142.105142 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 40b8ec52-1c24-431c-bb67-1450425c8cf3
DEBUG 01-06 17:11:11.105555.105555 cuda_h.py:19] end load_into_gpu_async cost 0.001623392105102539 seconds
DEBUG 01-06 17:11:11.105589.105589 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 17:11:11.105532.105532 cuda_h.py:19] end restore_tensors2 cost 7.224082946777344e-05 seconds
DEBUG 01-06 17:11:11.105381.105381 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.00429534912109375 seconds
INFO 01-06 17:11:11.105807.105807 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 40b8ec52-1c24-431c-bb67-1450425c8cf3
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-06 17:11:11.107158.107158 cuda_h.py:19] end self_attn cost 0.0028562545776367188 seconds
DEBUG 01-06 17:11:11.107936.107936 cuda_h.py:19] end iln_self_attn_paln cost 0.0067555904388427734 seconds
DEBUG 01-06 17:11:11.107110.107110 cuda_h.py:10] start layer_moe_generate_13
DEBUG 01-06 17:11:11.107370.107370 cuda_h.py:10] start gate
DEBUG 01-06 17:11:11.108070.108070 cuda_h.py:19] end gate cost 0.0006930828094482422 seconds
DEBUG 01-06 17:11:11.108137.108137 cuda_h.py:10] start experts_map_get
DEBUG 01-06 17:11:11.108075.108075 lmp.py:403] 
DEBUG 01-06 17:11:11.108075.108075 lmp.py:403] Expert Token Distribution & Device Allocation:
DEBUG 01-06 17:11:11.108546.108546 lmp.py:404]   Total experts: 64
DEBUG 01-06 17:11:11.108388.108388 lmp.py:405]   CPU experts: 32 (50%)
DEBUG 01-06 17:11:11.108322.108322 lmp.py:406]   GPU experts: 32 (50%)
DEBUG 01-06 17:11:11.108204.108204 lmp.py:407] 
DEBUG 01-06 17:11:11.108204.108204 lmp.py:407]   Expert ID | Tokens | Device
DEBUG 01-06 17:11:11.108800.108800 lmp.py:408]   -----------------------------------
DEBUG 01-06 17:11:11.108119.108119 lmp.py:414]   Expert 42 |     19 | CPU
DEBUG 01-06 17:11:11.108239.108239 lmp.py:414]   Expert 19 |     21 | CPU
DEBUG 01-06 17:11:11.108405.108405 lmp.py:414]   Expert 30 |     23 | CPU
DEBUG 01-06 17:11:11.108571.108571 lmp.py:414]   Expert 32 |     32 | CPU
DEBUG 01-06 17:11:11.108499.108499 lmp.py:414]   Expert  6 |     55 | CPU
DEBUG 01-06 17:11:11.108188.108188 lmp.py:414]   Expert 53 |     68 | CPU
DEBUG 01-06 17:11:11.108878.108878 lmp.py:414]   Expert  5 |     76 | CPU
DEBUG 01-06 17:11:11.108567.108567 lmp.py:414]   Expert  1 |     87 | CPU
DEBUG 01-06 17:11:11.108018.108018 lmp.py:414]   Expert 13 |    114 | CPU
DEBUG 01-06 17:11:11.108945.108945 lmp.py:414]   Expert  9 |    121 | CPU
DEBUG 01-06 17:11:11.108065.108065 lmp.py:414]   Expert 58 |    129 | CPU
DEBUG 01-06 17:11:11.108470.108470 lmp.py:414]   Expert 26 |    130 | CPU
DEBUG 01-06 17:11:11.109874.109874 lmp.py:414]   Expert 63 |    130 | CPU
DEBUG 01-06 17:11:11.109041.109041 lmp.py:414]   Expert 59 |    132 | CPU
DEBUG 01-06 17:11:11.109684.109684 lmp.py:414]   Expert 34 |    135 | CPU
DEBUG 01-06 17:11:11.109373.109373 lmp.py:414]   Expert 50 |    136 | CPU
DEBUG 01-06 17:11:11.109301.109301 lmp.py:414]   Expert 31 |    139 | CPU
DEBUG 01-06 17:11:11.109990.109990 lmp.py:414]   Expert 56 |    139 | CPU
DEBUG 01-06 17:11:11.109918.109918 lmp.py:414]   Expert 40 |    141 | CPU
DEBUG 01-06 17:11:11.109607.109607 lmp.py:414]   Expert 11 |    142 | CPU
DEBUG 01-06 17:11:11.109058.109058 lmp.py:414]   Expert 12 |    144 | CPU
DEBUG 01-06 17:11:11.109416.109416 lmp.py:414]   Expert 18 |    146 | CPU
DEBUG 01-06 17:11:11.109582.109582 lmp.py:414]   Expert 61 |    148 | CPU
DEBUG 01-06 17:11:11.109748.109748 lmp.py:414]   Expert  2 |    149 | CPU
DEBUG 01-06 17:11:11.109676.109676 lmp.py:414]   Expert 48 |    151 | CPU
DEBUG 01-06 17:11:11.109081.109081 lmp.py:414]   Expert 20 |    152 | CPU
DEBUG 01-06 17:11:11.109770.109770 lmp.py:414]   Expert 46 |    155 | CPU
DEBUG 01-06 17:11:11.109459.109459 lmp.py:414]   Expert  4 |    158 | CPU
DEBUG 01-06 17:11:11.109148.109148 lmp.py:414]   Expert 33 |    158 | CPU
DEBUG 01-06 17:11:11.109838.109838 lmp.py:414]   Expert 55 |    161 | CPU
DEBUG 01-06 17:11:11.109050.109050 lmp.py:414]   Expert 10 |    166 | CPU
DEBUG 01-06 17:11:11.109740.109740 lmp.py:414]   Expert 35 |    172 | CPU
DEBUG 01-06 17:11:11.109429.109429 lmp.py:414]   Expert 36 |    174 | GPU
DEBUG 01-06 17:11:11.109310.109310 lmp.py:414]   Expert  8 |    176 | GPU
DEBUG 01-06 17:11:11.109715.109715 lmp.py:414]   Expert 51 |    177 | GPU
DEBUG 01-06 17:11:11.109881.109881 lmp.py:414]   Expert 52 |    184 | GPU
DEBUG 01-06 17:11:11.109285.109285 lmp.py:414]   Expert 57 |    195 | GPU
DEBUG 01-06 17:11:11.109167.109167 lmp.py:414]   Expert 37 |    197 | GPU
DEBUG 01-06 17:11:11.109095.109095 lmp.py:414]   Expert  0 |    202 | GPU
DEBUG 01-06 17:11:11.109784.109784 lmp.py:414]   Expert 39 |    218 | GPU
DEBUG 01-06 17:11:11.109473.109473 lmp.py:414]   Expert 62 |    231 | GPU
DEBUG 01-06 17:11:11.109924.109924 lmp.py:414]   Expert 25 |    233 | GPU
DEBUG 01-06 17:11:11.109613.109613 lmp.py:414]   Expert  7 |    249 | GPU
DEBUG 01-06 17:11:11.109303.109303 lmp.py:414]   Expert 38 |    250 | GPU
DEBUG 01-06 17:11:11.109992.109992 lmp.py:414]   Expert 28 |    251 | GPU
DEBUG 01-06 17:11:11.109158.109158 lmp.py:414]   Expert  3 |    256 | GPU
DEBUG 01-06 17:11:11.109278.109278 lmp.py:414]   Expert 27 |    256 | GPU
DEBUG 01-06 17:11:11.109682.109682 lmp.py:414]   Expert 16 |    257 | GPU
DEBUG 01-06 17:11:11.109849.109849 lmp.py:414]   Expert 21 |    260 | GPU
DEBUG 01-06 17:11:11.109015.109015 lmp.py:414]   Expert 49 |    260 | GPU
DEBUG 01-06 17:11:11.109896.109896 lmp.py:414]   Expert 60 |    260 | GPU
DEBUG 01-06 17:11:11.109062.109062 lmp.py:414]   Expert 24 |    261 | GPU
DEBUG 01-06 17:11:11.109752.109752 lmp.py:414]   Expert 43 |    265 | GPU
DEBUG 01-06 17:11:11.109202.109202 lmp.py:414]   Expert 29 |    273 | GPU
DEBUG 01-06 17:11:11.109415.109415 lmp.py:414]   Expert 23 |    285 | GPU
DEBUG 01-06 17:11:11.109866.109866 lmp.py:414]   Expert 15 |    296 | GPU
DEBUG 01-06 17:11:11.109078.109078 lmp.py:414]   Expert 22 |    296 | GPU
DEBUG 01-06 17:11:11.109291.109291 lmp.py:414]   Expert 47 |    297 | GPU
DEBUG 01-06 17:11:11.109218.109218 lmp.py:414]   Expert 41 |    299 | GPU
DEBUG 01-06 17:11:11.109146.109146 lmp.py:414]   Expert 44 |    301 | GPU
DEBUG 01-06 17:11:11.109074.109074 lmp.py:414]   Expert 54 |    372 | GPU
DEBUG 01-06 17:11:11.109240.109240 lmp.py:414]   Expert 14 |    374 | GPU
DEBUG 01-06 17:11:11.109406.109406 lmp.py:414]   Expert 17 |    409 | GPU
DEBUG 01-06 17:11:11.109095.109095 lmp.py:414]   Expert 45 |    445 | GPU
DEBUG 01-06 17:11:11.109500.109500 lmp.py:415] 
DEBUG 01-06 17:11:11.109500.109500 lmp.py:415]   CPU total tokens: 3829 (31.2%)
DEBUG 01-06 17:11:11.109381.109381 lmp.py:416]   GPU total tokens: 8459 (68.8%)
DEBUG 01-06 17:11:11.109554.109554 cuda_h.py:19] end experts_map_get cost 0.0015430450439453125 seconds
DEBUG 01-06 17:11:11.109959.109959 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-06 17:11:11.109788.109788 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 17:11:11.110263.110263 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 17:11:11.111734.111734 cuda_h.py:19] end allocate_cuda_memory cost 0.0013682842254638672 seconds
DEBUG 01-06 17:11:11.111591.111591 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 17:11:11.111016.111016 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 17:11:11.111301.111301 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 17:11:11.111951.111951 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 18b1aff6-60c9-434d-8307-f5f8a0b666f2
DEBUG 01-06 17:11:11.111839.111839 client.py:106] call stub.LoadModelAsync
INFO 01-06 17:11:11.113230.113230 client.py:127] Model loaded
DEBUG 01-06 17:11:11.113849.113849 cuda_h.py:19] end sllm_worker_task cost 0.012873649597167969 seconds
INFO 01-06 17:11:11.114303.114303 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 18b1aff6-60c9-434d-8307-f5f8a0b666f2
DEBUG 01-06 17:11:11.115738.115738 cuda_h.py:19] end load_into_gpu_async cost 0.0033593177795410156 seconds
DEBUG 01-06 17:11:11.115462.115462 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 17:11:11.115508.115508 cuda_h.py:19] end restore_tensors2 cost 0.0004980564117431641 seconds
DEBUG 01-06 17:11:11.115768.115768 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.005684614181518555 seconds
DEBUG 01-06 17:11:11.118981.118981 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.008346319198608398 seconds
DEBUG 01-06 17:11:11.118340.118340 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-06 17:11:11.118773.118773 lmp.py:461] 
DEBUG 01-06 17:11:11.118773.118773 lmp.py:461]   Computing 32 experts on CPU...
DEBUG 01-06 17:11:11.118285.118285 cuda_h.py:19] end cpu_experts_submit cost 0.00010776519775390625 seconds
DEBUG 01-06 17:11:11.118220.118220 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-06 17:11:11.130702.130702 mlpmodule.py:706] group tensors cost 0.012020587921142578 s
DEBUG 01-06 17:11:11.133460.133460 mlpmodule.py:744] pad cost 0.0017428398132324219 s
DEBUG 01-06 17:11:11.133702.133702 mlpmodule.py:750] create cpu tensor cost 4.601478576660156e-05 s
DEBUG 01-06 17:11:11.133890.133890 mlpmodule.py:755] move to cpu cost 3.0994415283203125e-05 s
DEBUG 01-06 17:11:11.143079.143079 mlpmodule.py:769] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-06 17:11:11.143373.143373 mlpmodule.py:770] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-06 17:11:11.143442.143442 mlpmodule.py:775] group_w3 first element: -0.0211181640625
WARNING 01-06 17:11:11.143207.143207 mlpmodule.py:785] start einsum2
DEBUG 01-06 17:11:11.159025.159025 mlpmodule.py:795] group einsum cost 0.026140928268432617 s
DEBUG 01-06 17:11:11.160470.160470 mlpmodule.py:803] cpy2cputensor cost 0.0007214546203613281 s
DEBUG 01-06 17:11:11.164615.164615 cuda_h.py:19] end wait_cetm_experts cost 0.04635024070739746 seconds
DEBUG 01-06 17:11:11.165496.165496 cuda_h.py:10] start gpu_sexperts
DEBUG 01-06 17:11:11.165478.165478 cuda_h.py:19] end gpu_sexperts cost 0.0006091594696044922 seconds
DEBUG 01-06 17:11:11.165328.165328 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-06 17:11:11.165893.165893 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.5033950805664062e-05 seconds
DEBUG 01-06 17:11:11.165835.165835 cuda_h.py:10] start wait_experts
INFO 01-06 17:11:11.165783.165783 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 18b1aff6-60c9-434d-8307-f5f8a0b666f2
INFO 01-06 17:11:11.167007.167007 client.py:127] Model loaded
DEBUG 01-06 17:11:11.167811.167811 cuda_h.py:19] end wait_experts cost 0.0016372203826904297 seconds
DEBUG 01-06 17:11:11.167229.167229 cuda_h.py:10] start gpu_experts
DEBUG 01-06 17:11:11.167031.167031 lmp.py:506]   Computing 32 experts on GPU...
DEBUG 01-06 17:11:11.168202.168202 mlpmodule.py:533] gpu group tensors cost 0.0006697177886962891 s
DEBUG 01-06 17:11:11.170422.170422 mlpmodule.py:566] gpu pad cost 0.0017552375793457031 s
DEBUG 01-06 17:11:11.170006.170006 mlpmodule.py:584] gpu group einsum cost 0.0005691051483154297 s
DEBUG 01-06 17:11:11.174277.174277 mlpmodule.py:613] gpu experts func einsum cost 0.006657600402832031 s
DEBUG 01-06 17:11:11.174367.174367 cuda_h.py:19] end gpu_experts cost 0.006849527359008789 seconds
DEBUG 01-06 17:11:11.174979.174979 cuda_h.py:19] end layer_moe_generate_13 cost 0.06706738471984863 seconds
DEBUG 01-06 17:11:11.174424.174424 lmp.py:220] -------------------------------- end layer 13 --------------------------------
DEBUG 01-06 17:11:11.174478.174478 lmp.py:176] -------------------------------- start layer 14 --------------------------------
DEBUG 01-06 17:11:11.174558.174558 cuda_h.py:10] start start_load_qkvogn_s_weight_l_15
DEBUG 01-06 17:11:11.174036.174036 cuda_h.py:10] start start_load_qkvogn_s_weight_l_15
DEBUG 01-06 17:11:11.175032.175032 cuda_h.py:19] end start_load_qkvogn_s_weight_l_15 cost 3.6716461181640625e-05 seconds
DEBUG 01-06 17:11:11.175219.175219 cuda_h.py:19] end start_load_qkvogn_s_weight_l_15 cost 7.224082946777344e-05 seconds
DEBUG 01-06 17:11:11.175822.175822 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-06 17:11:11.175169.175169 mlpmodule.py:367] cuda:1 cuda:1
DEBUG 01-06 17:11:11.175377.175377 cuda_h.py:10] start sllm_worker_task
DEBUG 01-06 17:11:11.175784.175784 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 17:11:11.175998.175998 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 17:11:11.175453.175453 cuda_h.py:19] end allocate_cuda_memory cost 0.0002982616424560547 seconds
DEBUG 01-06 17:11:11.175303.175303 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 17:11:11.175443.175443 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 17:11:11.175836.175836 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 17:11:11.175685.175685 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, ded751c4-1bec-4180-8239-3514a5df2133
DEBUG 01-06 17:11:11.176423.176423 client.py:106] call stub.LoadModelAsync
DEBUG 01-06 17:11:11.176935.176935 cuda_h.py:10] start self_attn
INFO 01-06 17:11:11.177509.177509 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, ded751c4-1bec-4180-8239-3514a5df2133
DEBUG 01-06 17:11:11.177968.177968 cuda_h.py:19] end load_into_gpu_async cost 0.0016493797302246094 seconds
DEBUG 01-06 17:11:11.177764.177764 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 17:11:11.177184.177184 cuda_h.py:19] end restore_tensors2 cost 7.295608520507812e-05 seconds
DEBUG 01-06 17:11:11.177987.177987 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0022602081298828125 seconds
INFO 01-06 17:11:11.177055.177055 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, ded751c4-1bec-4180-8239-3514a5df2133
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-06 17:11:11.179015.179015 cuda_h.py:19] end self_attn cost 0.0028998851776123047 seconds
DEBUG 01-06 17:11:11.179251.179251 cuda_h.py:19] end iln_self_attn_paln cost 0.004461050033569336 seconds
DEBUG 01-06 17:11:11.179378.179378 cuda_h.py:10] start layer_moe_generate_14
DEBUG 01-06 17:11:11.179572.179572 cuda_h.py:10] start gate
DEBUG 01-06 17:11:11.180919.180919 cuda_h.py:19] end gate cost 0.0006430149078369141 seconds
DEBUG 01-06 17:11:11.180398.180398 cuda_h.py:10] start experts_map_get
DEBUG 01-06 17:11:11.180322.180322 lmp.py:403] 
DEBUG 01-06 17:11:11.180322.180322 lmp.py:403] Expert Token Distribution & Device Allocation:
DEBUG 01-06 17:11:11.180647.180647 lmp.py:404]   Total experts: 64
DEBUG 01-06 17:11:11.180059.180059 lmp.py:405]   CPU experts: 32 (50%)
DEBUG 01-06 17:11:11.180132.180132 lmp.py:406]   GPU experts: 32 (50%)
DEBUG 01-06 17:11:11.180398.180398 lmp.py:407] 
DEBUG 01-06 17:11:11.180398.180398 lmp.py:407]   Expert ID | Tokens | Device
DEBUG 01-06 17:11:11.180187.180187 lmp.py:408]   -----------------------------------
DEBUG 01-06 17:11:11.180028.180028 lmp.py:414]   Expert 34 |     31 | CPU
DEBUG 01-06 17:11:11.180956.180956 lmp.py:414]   Expert  7 |     32 | CPU
DEBUG 01-06 17:11:11.180407.180407 lmp.py:414]   Expert 13 |     40 | CPU
DEBUG 01-06 17:11:11.180620.180620 lmp.py:414]   Expert 54 |     77 | CPU
DEBUG 01-06 17:11:11.180355.180355 lmp.py:414]   Expert 18 |     83 | CPU
DEBUG 01-06 17:11:11.180329.180329 lmp.py:414]   Expert 39 |     86 | CPU
DEBUG 01-06 17:11:11.180303.180303 lmp.py:414]   Expert 49 |     86 | CPU
DEBUG 01-06 17:11:11.180516.180516 lmp.py:414]   Expert  0 |    104 | CPU
DEBUG 01-06 17:11:11.180397.180397 lmp.py:414]   Expert 16 |    105 | CPU
DEBUG 01-06 17:11:11.180802.180802 lmp.py:414]   Expert 59 |    106 | CPU
DEBUG 01-06 17:11:11.181968.181968 lmp.py:414]   Expert 21 |    109 | CPU
DEBUG 01-06 17:11:11.181372.181372 lmp.py:414]   Expert 15 |    116 | CPU
DEBUG 01-06 17:11:11.181777.181777 lmp.py:414]   Expert 41 |    120 | CPU
DEBUG 01-06 17:11:11.181705.181705 lmp.py:414]   Expert 45 |    122 | CPU
DEBUG 01-06 17:11:11.181632.181632 lmp.py:414]   Expert 17 |    125 | CPU
DEBUG 01-06 17:11:11.181322.181322 lmp.py:414]   Expert 22 |    127 | CPU
DEBUG 01-06 17:11:11.181249.181249 lmp.py:414]   Expert 61 |    128 | CPU
DEBUG 01-06 17:11:11.181939.181939 lmp.py:414]   Expert 52 |    133 | CPU
DEBUG 01-06 17:11:11.181390.181390 lmp.py:414]   Expert  8 |    136 | CPU
DEBUG 01-06 17:11:11.181840.181840 lmp.py:414]   Expert 35 |    141 | CPU
DEBUG 01-06 17:11:11.181530.181530 lmp.py:414]   Expert 48 |    143 | CPU
DEBUG 01-06 17:11:11.181981.181981 lmp.py:414]   Expert 12 |    146 | CPU
DEBUG 01-06 17:11:11.181624.181624 lmp.py:414]   Expert 38 |    146 | CPU
DEBUG 01-06 17:11:11.181790.181790 lmp.py:414]   Expert 31 |    154 | CPU
DEBUG 01-06 17:11:11.181956.181956 lmp.py:414]   Expert 50 |    156 | CPU
DEBUG 01-06 17:11:11.181122.181122 lmp.py:414]   Expert 53 |    158 | CPU
DEBUG 01-06 17:11:11.181050.181050 lmp.py:414]   Expert 40 |    161 | CPU
DEBUG 01-06 17:11:11.181977.181977 lmp.py:414]   Expert 36 |    162 | CPU
DEBUG 01-06 17:11:11.181667.181667 lmp.py:414]   Expert 60 |    163 | CPU
DEBUG 01-06 17:11:11.181118.181118 lmp.py:414]   Expert 27 |    178 | CPU
DEBUG 01-06 17:11:11.181807.181807 lmp.py:414]   Expert 19 |    198 | CPU
DEBUG 01-06 17:11:11.181311.181311 lmp.py:414]   Expert 29 |    199 | CPU
DEBUG 01-06 17:11:11.181477.181477 lmp.py:414]   Expert  4 |    203 | GPU
DEBUG 01-06 17:11:11.181690.181690 lmp.py:414]   Expert 30 |    206 | GPU
DEBUG 01-06 17:11:11.181333.181333 lmp.py:414]   Expert 11 |    218 | GPU
DEBUG 01-06 17:11:11.181499.181499 lmp.py:414]   Expert 20 |    222 | GPU
DEBUG 01-06 17:11:11.181380.181380 lmp.py:414]   Expert 26 |    222 | GPU
DEBUG 01-06 17:11:11.181738.181738 lmp.py:414]   Expert 57 |    223 | GPU
DEBUG 01-06 17:11:11.181858.181858 lmp.py:414]   Expert 46 |    224 | GPU
DEBUG 01-06 17:11:11.181501.181501 lmp.py:414]   Expert 43 |    227 | GPU
DEBUG 01-06 17:11:11.181144.181144 lmp.py:414]   Expert  6 |    231 | GPU
DEBUG 01-06 17:11:11.181787.181787 lmp.py:414]   Expert 33 |    231 | GPU
DEBUG 01-06 17:11:11.181192.181192 lmp.py:414]   Expert 42 |    237 | GPU
DEBUG 01-06 17:11:11.181835.181835 lmp.py:414]   Expert  2 |    240 | GPU
DEBUG 01-06 17:11:11.181478.181478 lmp.py:414]   Expert 23 |    241 | GPU
DEBUG 01-06 17:11:11.181882.181882 lmp.py:414]   Expert 55 |    248 | GPU
DEBUG 01-06 17:11:11.181240.181240 lmp.py:414]   Expert 28 |    253 | GPU
DEBUG 01-06 17:11:11.181360.181360 lmp.py:414]   Expert 56 |    256 | GPU
DEBUG 01-06 17:11:11.181242.181242 lmp.py:414]   Expert  9 |    258 | GPU
DEBUG 01-06 17:11:11.181361.181361 lmp.py:414]   Expert 32 |    260 | GPU
DEBUG 01-06 17:11:11.181481.181481 lmp.py:414]   Expert 44 |    264 | GPU
DEBUG 01-06 17:11:11.181363.181363 lmp.py:414]   Expert  3 |    266 | GPU
DEBUG 01-06 17:11:11.181767.181767 lmp.py:414]   Expert 14 |    273 | GPU
DEBUG 01-06 17:11:11.181172.181172 lmp.py:414]   Expert  1 |    276 | GPU
DEBUG 01-06 17:11:11.181815.181815 lmp.py:414]   Expert 51 |    281 | GPU
DEBUG 01-06 17:11:11.181458.181458 lmp.py:414]   Expert 58 |    281 | GPU
DEBUG 01-06 17:11:11.181816.181816 lmp.py:414]   Expert 37 |    289 | GPU
DEBUG 01-06 17:11:11.181697.181697 lmp.py:414]   Expert 63 |    290 | GPU
DEBUG 01-06 17:11:11.181579.181579 lmp.py:414]   Expert 47 |    291 | GPU
DEBUG 01-06 17:11:11.181937.181937 lmp.py:414]   Expert 62 |    292 | GPU
DEBUG 01-06 17:11:11.181580.181580 lmp.py:414]   Expert 10 |    316 | GPU
DEBUG 01-06 17:11:11.181984.181984 lmp.py:414]   Expert 24 |    316 | GPU
DEBUG 01-06 17:11:11.181627.181627 lmp.py:414]   Expert 25 |    316 | GPU
DEBUG 01-06 17:11:11.181032.181032 lmp.py:414]   Expert  5 |    366 | GPU
DEBUG 01-06 17:11:11.181390.181390 lmp.py:415] 
DEBUG 01-06 17:11:11.181390.181390 lmp.py:415]   CPU total tokens: 3971 (32.3%)
DEBUG 01-06 17:11:11.181748.181748 lmp.py:416]   GPU total tokens: 8317 (67.7%)
DEBUG 01-06 17:11:11.182637.182637 cuda_h.py:19] end experts_map_get cost 0.0015513896942138672 seconds
DEBUG 01-06 17:11:11.182135.182135 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-06 17:11:11.182256.182256 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 17:11:11.182307.182307 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 17:11:11.183685.183685 cuda_h.py:19] end allocate_cuda_memory cost 0.001367807388305664 seconds
DEBUG 01-06 17:11:11.183297.183297 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 17:11:11.183576.183576 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 17:11:11.183438.183438 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 17:11:11.183187.183187 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, d81d15c8-7f7e-4bf9-9329-18fd3004a59e
DEBUG 01-06 17:11:11.184665.184665 client.py:106] call stub.LoadModelAsync
DEBUG 01-06 17:11:11.184941.184941 mlpmodule.py:664]  experts func einsum cost 0.06545448303222656 s
INFO 01-06 17:11:11.185483.185483 client.py:127] Model loaded
DEBUG 01-06 17:11:11.185335.185335 cuda_h.py:19] end sllm_worker_task cost 0.010516643524169922 seconds
INFO 01-06 17:11:11.186719.186719 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, d81d15c8-7f7e-4bf9-9329-18fd3004a59e
DEBUG 01-06 17:11:11.186138.186138 cuda_h.py:19] end load_into_gpu_async cost 0.0031511783599853516 seconds
DEBUG 01-06 17:11:11.186318.186318 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 17:11:11.187271.187271 cuda_h.py:19] end restore_tensors2 cost 0.0003535747528076172 seconds
DEBUG 01-06 17:11:11.187339.187339 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.005232095718383789 seconds
DEBUG 01-06 17:11:11.190587.190587 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.007920265197753906 seconds
DEBUG 01-06 17:11:11.190277.190277 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-06 17:11:11.190717.190717 lmp.py:461] 
DEBUG 01-06 17:11:11.190717.190717 lmp.py:461]   Computing 32 experts on CPU...
DEBUG 01-06 17:11:11.190090.190090 cuda_h.py:19] end cpu_experts_submit cost 0.00011515617370605469 seconds
DEBUG 01-06 17:11:11.190455.190455 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-06 17:11:11.196494.196494 mlpmodule.py:706] group tensors cost 0.0057811737060546875 s
DEBUG 01-06 17:11:11.198022.198022 mlpmodule.py:744] pad cost 0.001851797103881836 s
DEBUG 01-06 17:11:11.198947.198947 mlpmodule.py:750] create cpu tensor cost 4.863739013671875e-05 s
DEBUG 01-06 17:11:11.199049.199049 mlpmodule.py:755] move to cpu cost 3.4332275390625e-05 s
DEBUG 01-06 17:11:11.209343.209343 mlpmodule.py:769] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-06 17:11:11.209915.209915 mlpmodule.py:770] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-06 17:11:11.209839.209839 mlpmodule.py:775] group_w3 first element: 0.000789642333984375
WARNING 01-06 17:11:11.209498.209498 mlpmodule.py:785] start einsum2
DEBUG 01-06 17:11:11.227865.227865 mlpmodule.py:795] group einsum cost 0.0286712646484375 s
DEBUG 01-06 17:11:11.228463.228463 mlpmodule.py:803] cpy2cputensor cost 0.0007581710815429688 s
DEBUG 01-06 17:11:11.233875.233875 cuda_h.py:19] end wait_cetm_experts cost 0.042714595794677734 seconds
DEBUG 01-06 17:11:11.233980.233980 cuda_h.py:10] start gpu_sexperts
DEBUG 01-06 17:11:11.233307.233307 cuda_h.py:19] end gpu_sexperts cost 0.0006184577941894531 seconds
DEBUG 01-06 17:11:11.233773.233773 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-06 17:11:11.233430.233430 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.4318695068359375e-05 seconds
DEBUG 01-06 17:11:11.234418.234418 cuda_h.py:10] start wait_experts
INFO 01-06 17:11:11.234889.234889 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, d81d15c8-7f7e-4bf9-9329-18fd3004a59e
INFO 01-06 17:11:11.239277.239277 client.py:127] Model loaded
DEBUG 01-06 17:11:11.239842.239842 cuda_h.py:19] end wait_experts cost 0.005899667739868164 seconds
DEBUG 01-06 17:11:11.239690.239690 cuda_h.py:10] start gpu_experts
DEBUG 01-06 17:11:11.240016.240016 lmp.py:506]   Computing 32 experts on GPU...
DEBUG 01-06 17:11:11.240472.240472 mlpmodule.py:533] gpu group tensors cost 0.0006649494171142578 s
DEBUG 01-06 17:11:11.242950.242950 mlpmodule.py:566] gpu pad cost 0.001767873764038086 s
DEBUG 01-06 17:11:11.243263.243263 mlpmodule.py:584] gpu group einsum cost 0.0005631446838378906 s
DEBUG 01-06 17:11:11.245872.245872 mlpmodule.py:664]  experts func einsum cost 0.05527329444885254 s
DEBUG 01-06 17:11:11.247272.247272 mlpmodule.py:613] gpu experts func einsum cost 0.006967782974243164 s
DEBUG 01-06 17:11:11.247509.247509 cuda_h.py:19] end gpu_experts cost 0.00721287727355957 seconds
DEBUG 01-06 17:11:11.247340.247340 cuda_h.py:19] end layer_moe_generate_14 cost 0.06763648986816406 seconds
DEBUG 01-06 17:11:11.247783.247783 lmp.py:220] -------------------------------- end layer 14 --------------------------------
DEBUG 01-06 17:11:11.247937.247937 lmp.py:176] -------------------------------- start layer 15 --------------------------------
DEBUG 01-06 17:11:11.247871.247871 cuda_h.py:10] start start_load_qkvogn_s_weight_l_16
DEBUG 01-06 17:11:11.247389.247389 cuda_h.py:10] start start_load_qkvogn_s_weight_l_16
DEBUG 01-06 17:11:11.247901.247901 cuda_h.py:19] end start_load_qkvogn_s_weight_l_16 cost 3.337860107421875e-05 seconds
DEBUG 01-06 17:11:11.247458.247458 cuda_h.py:19] end start_load_qkvogn_s_weight_l_16 cost 6.413459777832031e-05 seconds
DEBUG 01-06 17:11:11.247293.247293 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-06 17:11:11.247196.247196 mlpmodule.py:367] cuda:1 cuda:1
DEBUG 01-06 17:11:11.247828.247828 cuda_h.py:10] start sllm_worker_task
DEBUG 01-06 17:11:11.247586.247586 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 17:11:11.247330.247330 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 17:11:11.248407.248407 cuda_h.py:19] end allocate_cuda_memory cost 0.0003020763397216797 seconds
DEBUG 01-06 17:11:11.248722.248722 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 17:11:11.248869.248869 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 17:11:11.248546.248546 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 17:11:11.248533.248533 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 263f6e7c-f09b-4539-b48e-603a1fcd52e7
DEBUG 01-06 17:11:11.248119.248119 client.py:106] call stub.LoadModelAsync
DEBUG 01-06 17:11:11.248762.248762 cuda_h.py:10] start self_attn
INFO 01-06 17:11:11.250332.250332 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 263f6e7c-f09b-4539-b48e-603a1fcd52e7
DEBUG 01-06 17:11:11.250499.250499 cuda_h.py:19] end load_into_gpu_async cost 0.0016238689422607422 seconds
DEBUG 01-06 17:11:11.250818.250818 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 17:11:11.250139.250139 cuda_h.py:19] end restore_tensors2 cost 7.081031799316406e-05 seconds
DEBUG 01-06 17:11:11.250464.250464 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.002262592315673828 seconds
INFO 01-06 17:11:11.250115.250115 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 263f6e7c-f09b-4539-b48e-603a1fcd52e7
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-06 17:11:11.251695.251695 cuda_h.py:19] end self_attn cost 0.0028727054595947266 seconds
DEBUG 01-06 17:11:11.252850.252850 cuda_h.py:19] end iln_self_attn_paln cost 0.004350423812866211 seconds
DEBUG 01-06 17:11:11.252786.252786 cuda_h.py:10] start layer_moe_generate_15
DEBUG 01-06 17:11:11.252787.252787 cuda_h.py:10] start gate
DEBUG 01-06 17:11:11.252578.252578 cuda_h.py:19] end gate cost 0.0006554126739501953 seconds
DEBUG 01-06 17:11:11.252216.252216 cuda_h.py:10] start experts_map_get
DEBUG 01-06 17:11:11.253239.253239 lmp.py:403] 
DEBUG 01-06 17:11:11.253239.253239 lmp.py:403] Expert Token Distribution & Device Allocation:
DEBUG 01-06 17:11:11.253564.253564 lmp.py:404]   Total experts: 64
DEBUG 01-06 17:11:11.253737.253737 lmp.py:405]   CPU experts: 32 (50%)
DEBUG 01-06 17:11:11.253572.253572 lmp.py:406]   GPU experts: 32 (50%)
DEBUG 01-06 17:11:11.253500.253500 lmp.py:407] 
DEBUG 01-06 17:11:11.253500.253500 lmp.py:407]   Expert ID | Tokens | Device
DEBUG 01-06 17:11:11.253666.253666 lmp.py:408]   -----------------------------------
DEBUG 01-06 17:11:11.253031.253031 lmp.py:414]   Expert 41 |     60 | CPU
DEBUG 01-06 17:11:11.253151.253151 lmp.py:414]   Expert 15 |     65 | CPU
DEBUG 01-06 17:11:11.253840.253840 lmp.py:414]   Expert 63 |     72 | CPU
DEBUG 01-06 17:11:11.253053.253053 lmp.py:414]   Expert  0 |     79 | CPU
DEBUG 01-06 17:11:11.253027.253027 lmp.py:414]   Expert 20 |     81 | CPU
DEBUG 01-06 17:11:11.253001.253001 lmp.py:414]   Expert 45 |     89 | CPU
DEBUG 01-06 17:11:11.253213.253213 lmp.py:414]   Expert 28 |     94 | CPU
DEBUG 01-06 17:11:11.253711.253711 lmp.py:414]   Expert 54 |     96 | CPU
DEBUG 01-06 17:11:11.253685.253685 lmp.py:414]   Expert  7 |     97 | CPU
DEBUG 01-06 17:11:11.253851.253851 lmp.py:414]   Expert 12 |    111 | CPU
DEBUG 01-06 17:11:11.253063.253063 lmp.py:414]   Expert 40 |    111 | CPU
DEBUG 01-06 17:11:11.253514.253514 lmp.py:414]   Expert 52 |    121 | CPU
DEBUG 01-06 17:11:11.253203.253203 lmp.py:414]   Expert  5 |    122 | CPU
DEBUG 01-06 17:11:11.253654.253654 lmp.py:414]   Expert  4 |    125 | CPU
DEBUG 01-06 17:11:11.253390.253390 lmp.py:414]   Expert 59 |    125 | CPU
DEBUG 01-06 17:11:11.253364.253364 lmp.py:414]   Expert 61 |    129 | CPU
DEBUG 01-06 17:11:11.253861.253861 lmp.py:414]   Expert 34 |    130 | CPU
DEBUG 01-06 17:11:11.253027.253027 lmp.py:414]   Expert 62 |    135 | CPU
DEBUG 01-06 17:11:11.253194.253194 lmp.py:414]   Expert 55 |    136 | CPU
DEBUG 01-06 17:11:11.253121.253121 lmp.py:414]   Expert 13 |    138 | CPU
DEBUG 01-06 17:11:11.253811.253811 lmp.py:414]   Expert 42 |    140 | CPU
DEBUG 01-06 17:11:11.253738.253738 lmp.py:414]   Expert 21 |    142 | CPU
DEBUG 01-06 17:11:11.253143.253143 lmp.py:414]   Expert 22 |    146 | CPU
DEBUG 01-06 17:11:11.253832.253832 lmp.py:414]   Expert 10 |    147 | CPU
DEBUG 01-06 17:11:11.253998.253998 lmp.py:414]   Expert 14 |    151 | CPU
DEBUG 01-06 17:11:11.253926.253926 lmp.py:414]   Expert 32 |    161 | CPU
DEBUG 01-06 17:11:11.253854.253854 lmp.py:414]   Expert 51 |    162 | CPU
DEBUG 01-06 17:11:11.253543.253543 lmp.py:414]   Expert 25 |    164 | CPU
DEBUG 01-06 17:11:11.253994.253994 lmp.py:414]   Expert 50 |    166 | CPU
DEBUG 01-06 17:11:11.253206.253206 lmp.py:414]   Expert 53 |    169 | CPU
DEBUG 01-06 17:11:11.253657.253657 lmp.py:414]   Expert  2 |    171 | CPU
DEBUG 01-06 17:11:11.253347.253347 lmp.py:414]   Expert 19 |    173 | CPU
DEBUG 01-06 17:11:11.253036.253036 lmp.py:414]   Expert 26 |    173 | GPU
DEBUG 01-06 17:11:11.253202.253202 lmp.py:414]   Expert  6 |    181 | GPU
DEBUG 01-06 17:11:11.253607.253607 lmp.py:414]   Expert 30 |    182 | GPU
DEBUG 01-06 17:11:11.253296.253296 lmp.py:414]   Expert 35 |    186 | GPU
DEBUG 01-06 17:11:11.253177.253177 lmp.py:414]   Expert 11 |    187 | GPU
DEBUG 01-06 17:11:11.253105.253105 lmp.py:414]   Expert  1 |    188 | GPU
DEBUG 01-06 17:11:11.253556.253556 lmp.py:414]   Expert 57 |    189 | GPU
DEBUG 01-06 17:11:11.253768.253768 lmp.py:414]   Expert 47 |    192 | GPU
DEBUG 01-06 17:11:11.253219.253219 lmp.py:414]   Expert 56 |    194 | GPU
DEBUG 01-06 17:11:11.254432.254432 lmp.py:414]   Expert 44 |    210 | GPU
DEBUG 01-06 17:11:11.254644.254644 lmp.py:414]   Expert 46 |    212 | GPU
DEBUG 01-06 17:11:11.254333.254333 lmp.py:414]   Expert 24 |    214 | GPU
DEBUG 01-06 17:11:11.254546.254546 lmp.py:414]   Expert 48 |    215 | GPU
DEBUG 01-06 17:11:11.254427.254427 lmp.py:414]   Expert 16 |    219 | GPU
DEBUG 01-06 17:11:11.254117.254117 lmp.py:414]   Expert 18 |    226 | GPU
DEBUG 01-06 17:11:11.254283.254283 lmp.py:414]   Expert 39 |    227 | GPU
DEBUG 01-06 17:11:11.254210.254210 lmp.py:414]   Expert 29 |    230 | GPU
DEBUG 01-06 17:11:11.254138.254138 lmp.py:414]   Expert 37 |    237 | GPU
DEBUG 01-06 17:11:11.254827.254827 lmp.py:414]   Expert  3 |    253 | GPU
DEBUG 01-06 17:11:11.254040.254040 lmp.py:414]   Expert 38 |    253 | GPU
DEBUG 01-06 17:11:11.254252.254252 lmp.py:414]   Expert 31 |    254 | GPU
DEBUG 01-06 17:11:11.254703.254703 lmp.py:414]   Expert 36 |    260 | GPU
DEBUG 01-06 17:11:11.254154.254154 lmp.py:414]   Expert 17 |    261 | GPU
DEBUG 01-06 17:11:11.254605.254605 lmp.py:414]   Expert 60 |    262 | GPU
DEBUG 01-06 17:11:11.254056.254056 lmp.py:414]   Expert  9 |    266 | GPU
DEBUG 01-06 17:11:11.254460.254460 lmp.py:414]   Expert 23 |    266 | GPU
DEBUG 01-06 17:11:11.254627.254627 lmp.py:414]   Expert 43 |    349 | GPU
DEBUG 01-06 17:11:11.254316.254316 lmp.py:414]   Expert 27 |    365 | GPU
DEBUG 01-06 17:11:11.254482.254482 lmp.py:414]   Expert 33 |    398 | GPU
DEBUG 01-06 17:11:11.254125.254125 lmp.py:414]   Expert  8 |    439 | GPU
DEBUG 01-06 17:11:11.254576.254576 lmp.py:414]   Expert 58 |    444 | GPU
DEBUG 01-06 17:11:11.254788.254788 lmp.py:414]   Expert 49 |    548 | GPU
DEBUG 01-06 17:11:11.254954.254954 lmp.py:415] 
DEBUG 01-06 17:11:11.254954.254954 lmp.py:415]   CPU total tokens: 4008 (32.6%)
DEBUG 01-06 17:11:11.254359.254359 lmp.py:416]   GPU total tokens: 8280 (67.4%)
DEBUG 01-06 17:11:11.254294.254294 cuda_h.py:19] end experts_map_get cost 0.0015032291412353516 seconds
DEBUG 01-06 17:11:11.254937.254937 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-06 17:11:11.254335.254335 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 17:11:11.254572.254572 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 17:11:11.256055.256055 cuda_h.py:19] end allocate_cuda_memory cost 0.0017206668853759766 seconds
DEBUG 01-06 17:11:11.256157.256157 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 17:11:11.256820.256820 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 17:11:11.256867.256867 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 17:11:11.256802.256802 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, ec6d7f40-6399-4fae-8ff8-73054ca40a47
DEBUG 01-06 17:11:11.256067.256067 client.py:106] call stub.LoadModelAsync
INFO 01-06 17:11:11.258852.258852 client.py:127] Model loaded
DEBUG 01-06 17:11:11.259163.259163 cuda_h.py:19] end sllm_worker_task cost 0.011102437973022461 seconds
INFO 01-06 17:11:11.259099.259099 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, ec6d7f40-6399-4fae-8ff8-73054ca40a47
DEBUG 01-06 17:11:11.259995.259995 cuda_h.py:19] end load_into_gpu_async cost 0.0032515525817871094 seconds
DEBUG 01-06 17:11:11.259413.259413 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 17:11:11.260876.260876 cuda_h.py:19] end restore_tensors2 cost 0.0003497600555419922 seconds
DEBUG 01-06 17:11:11.260845.260845 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.005688905715942383 seconds
DEBUG 01-06 17:11:11.262820.262820 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.00834965705871582 seconds
DEBUG 01-06 17:11:11.262272.262272 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-06 17:11:11.262519.262519 lmp.py:461] 
DEBUG 01-06 17:11:11.262519.262519 lmp.py:461]   Computing 32 experts on CPU...
DEBUG 01-06 17:11:11.263223.263223 cuda_h.py:19] end cpu_experts_submit cost 0.00011157989501953125 seconds
DEBUG 01-06 17:11:11.263873.263873 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-06 17:11:11.270999.270999 mlpmodule.py:706] group tensors cost 0.007688283920288086 s
DEBUG 01-06 17:11:11.275012.275012 mlpmodule.py:744] pad cost 0.003622770309448242 s
DEBUG 01-06 17:11:11.275089.275089 mlpmodule.py:750] create cpu tensor cost 5.1021575927734375e-05 s
DEBUG 01-06 17:11:11.275807.275807 mlpmodule.py:755] move to cpu cost 3.4809112548828125e-05 s
DEBUG 01-06 17:11:11.287550.287550 mlpmodule.py:769] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-06 17:11:11.287989.287989 mlpmodule.py:770] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-06 17:11:11.287170.287170 mlpmodule.py:775] group_w3 first element: -0.0595703125
WARNING 01-06 17:11:11.287200.287200 mlpmodule.py:785] start einsum2
DEBUG 01-06 17:11:11.305101.305101 mlpmodule.py:795] group einsum cost 0.030081510543823242 s
DEBUG 01-06 17:11:11.306054.306054 mlpmodule.py:803] cpy2cputensor cost 0.0006740093231201172 s
DEBUG 01-06 17:11:11.310663.310663 cuda_h.py:19] end wait_cetm_experts cost 0.04783344268798828 seconds
DEBUG 01-06 17:11:11.311312.311312 cuda_h.py:10] start gpu_sexperts
DEBUG 01-06 17:11:11.311062.311062 cuda_h.py:19] end gpu_sexperts cost 0.0006129741668701172 seconds
DEBUG 01-06 17:11:11.311296.311296 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-06 17:11:11.311338.311338 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.4318695068359375e-05 seconds
DEBUG 01-06 17:11:11.311902.311902 cuda_h.py:10] start wait_experts
INFO 01-06 17:11:11.312135.312135 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, ec6d7f40-6399-4fae-8ff8-73054ca40a47
INFO 01-06 17:11:11.313691.313691 client.py:127] Model loaded
DEBUG 01-06 17:11:11.313017.313017 cuda_h.py:19] end wait_experts cost 0.0014240741729736328 seconds
DEBUG 01-06 17:11:11.313442.313442 cuda_h.py:10] start gpu_experts
DEBUG 01-06 17:11:11.313721.313721 lmp.py:506]   Computing 32 experts on GPU...
DEBUG 01-06 17:11:11.314104.314104 mlpmodule.py:533] gpu group tensors cost 0.0006513595581054688 s
DEBUG 01-06 17:11:11.316496.316496 mlpmodule.py:566] gpu pad cost 0.001781463623046875 s
DEBUG 01-06 17:11:11.316447.316447 mlpmodule.py:584] gpu group einsum cost 0.0006210803985595703 s
DEBUG 01-06 17:11:11.319077.319077 mlpmodule.py:664]  experts func einsum cost 0.05592823028564453 s
DEBUG 01-06 17:11:11.320023.320023 mlpmodule.py:613] gpu experts func einsum cost 0.006933450698852539 s
DEBUG 01-06 17:11:11.320088.320088 cuda_h.py:19] end gpu_experts cost 0.007187843322753906 seconds
DEBUG 01-06 17:11:11.320309.320309 cuda_h.py:19] end layer_moe_generate_15 cost 0.06861352920532227 seconds
DEBUG 01-06 17:11:11.320476.320476 lmp.py:220] -------------------------------- end layer 15 --------------------------------
DEBUG 01-06 17:11:11.321669.321669 lmp.py:176] -------------------------------- start layer 16 --------------------------------
DEBUG 01-06 17:11:11.321657.321657 cuda_h.py:10] start start_load_qkvogn_s_weight_l_17
DEBUG 01-06 17:11:11.321373.321373 cuda_h.py:10] start start_load_qkvogn_s_weight_l_17
DEBUG 01-06 17:11:11.321892.321892 cuda_h.py:19] end start_load_qkvogn_s_weight_l_17 cost 3.62396240234375e-05 seconds
DEBUG 01-06 17:11:11.321125.321125 cuda_h.py:19] end start_load_qkvogn_s_weight_l_17 cost 7.05718994140625e-05 seconds
DEBUG 01-06 17:11:11.321874.321874 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-06 17:11:11.321360.321360 mlpmodule.py:367] cuda:1 cuda:1
DEBUG 01-06 17:11:11.321761.321761 cuda_h.py:10] start sllm_worker_task
DEBUG 01-06 17:11:11.321949.321949 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 17:11:11.321209.321209 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 17:11:11.321208.321208 cuda_h.py:19] end allocate_cuda_memory cost 0.0003135204315185547 seconds
DEBUG 01-06 17:11:11.321939.321939 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 17:11:11.322940.322940 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 17:11:11.322432.322432 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 17:11:11.322943.322943 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, bf05ba7c-7757-418e-acb8-561a3144bbcc
DEBUG 01-06 17:11:11.322714.322714 client.py:106] call stub.LoadModelAsync
DEBUG 01-06 17:11:11.322952.322952 cuda_h.py:10] start self_attn
INFO 01-06 17:11:11.323415.323415 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, bf05ba7c-7757-418e-acb8-561a3144bbcc
DEBUG 01-06 17:11:11.323205.323205 cuda_h.py:19] end load_into_gpu_async cost 0.00156402587890625 seconds
DEBUG 01-06 17:11:11.323477.323477 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 17:11:11.323328.323328 cuda_h.py:19] end restore_tensors2 cost 7.462501525878906e-05 seconds
DEBUG 01-06 17:11:11.323892.323892 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.002208709716796875 seconds
INFO 01-06 17:11:11.323390.323390 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, bf05ba7c-7757-418e-acb8-561a3144bbcc
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-06 17:11:11.325734.325734 cuda_h.py:19] end self_attn cost 0.003070354461669922 seconds
DEBUG 01-06 17:11:11.325963.325963 cuda_h.py:19] end iln_self_attn_paln cost 0.0045964717864990234 seconds
DEBUG 01-06 17:11:11.325422.325422 cuda_h.py:10] start layer_moe_generate_16
DEBUG 01-06 17:11:11.325231.325231 cuda_h.py:10] start gate
DEBUG 01-06 17:11:11.326201.326201 cuda_h.py:19] end gate cost 0.0006461143493652344 seconds
DEBUG 01-06 17:11:11.326315.326315 cuda_h.py:10] start experts_map_get
DEBUG 01-06 17:11:11.326332.326332 lmp.py:403] 
DEBUG 01-06 17:11:11.326332.326332 lmp.py:403] Expert Token Distribution & Device Allocation:
DEBUG 01-06 17:11:11.326895.326895 lmp.py:404]   Total experts: 64
DEBUG 01-06 17:11:11.327307.327307 lmp.py:405]   CPU experts: 32 (50%)
DEBUG 01-06 17:11:11.327619.327619 lmp.py:406]   GPU experts: 32 (50%)
DEBUG 01-06 17:11:11.327546.327546 lmp.py:407] 
DEBUG 01-06 17:11:11.327546.327546 lmp.py:407]   Expert ID | Tokens | Device
DEBUG 01-06 17:11:11.327713.327713 lmp.py:408]   -----------------------------------
DEBUG 01-06 17:11:11.327760.327760 lmp.py:414]   Expert 58 |     38 | CPU
DEBUG 01-06 17:11:11.327118.327118 lmp.py:414]   Expert 31 |     62 | CPU
DEBUG 01-06 17:11:11.327284.327284 lmp.py:414]   Expert  4 |     63 | CPU
DEBUG 01-06 17:11:11.327212.327212 lmp.py:414]   Expert 49 |     64 | CPU
DEBUG 01-06 17:11:11.327617.327617 lmp.py:414]   Expert 45 |     65 | CPU
DEBUG 01-06 17:11:11.327544.327544 lmp.py:414]   Expert 47 |     66 | CPU
DEBUG 01-06 17:11:11.327757.327757 lmp.py:414]   Expert 38 |     70 | CPU
DEBUG 01-06 17:11:11.327493.327493 lmp.py:414]   Expert 43 |     79 | CPU
DEBUG 01-06 17:11:11.327990.327990 lmp.py:414]   Expert 41 |     85 | CPU
DEBUG 01-06 17:11:11.327249.327249 lmp.py:414]   Expert 50 |     97 | CPU
DEBUG 01-06 17:11:11.327223.327223 lmp.py:414]   Expert 33 |    103 | CPU
DEBUG 01-06 17:11:11.327958.327958 lmp.py:414]   Expert 11 |    107 | CPU
DEBUG 01-06 17:11:11.327171.327171 lmp.py:414]   Expert 57 |    109 | CPU
DEBUG 01-06 17:11:11.327860.327860 lmp.py:414]   Expert  2 |    112 | CPU
DEBUG 01-06 17:11:11.327072.327072 lmp.py:414]   Expert 51 |    115 | CPU
DEBUG 01-06 17:11:11.327762.327762 lmp.py:414]   Expert 54 |    124 | CPU
DEBUG 01-06 17:11:11.327928.327928 lmp.py:414]   Expert  0 |    125 | CPU
DEBUG 01-06 17:11:11.327902.327902 lmp.py:414]   Expert 14 |    129 | CPU
DEBUG 01-06 17:11:11.327638.327638 lmp.py:414]   Expert 56 |    131 | CPU
DEBUG 01-06 17:11:11.327373.327373 lmp.py:414]   Expert 26 |    138 | CPU
DEBUG 01-06 17:11:11.327870.327870 lmp.py:414]   Expert 34 |    141 | CPU
DEBUG 01-06 17:11:11.327606.327606 lmp.py:414]   Expert 27 |    154 | CPU
DEBUG 01-06 17:11:11.327865.327865 lmp.py:414]   Expert 28 |    156 | CPU
DEBUG 01-06 17:11:11.327600.327600 lmp.py:414]   Expert 10 |    164 | CPU
DEBUG 01-06 17:11:11.327098.327098 lmp.py:414]   Expert 55 |    164 | CPU
DEBUG 01-06 17:11:11.327264.327264 lmp.py:414]   Expert 25 |    165 | CPU
DEBUG 01-06 17:11:11.327476.327476 lmp.py:414]   Expert  9 |    179 | CPU
DEBUG 01-06 17:11:11.327927.327927 lmp.py:414]   Expert 13 |    179 | CPU
DEBUG 01-06 17:11:11.327901.327901 lmp.py:414]   Expert 48 |    185 | CPU
DEBUG 01-06 17:11:11.327590.327590 lmp.py:414]   Expert 61 |    187 | CPU
DEBUG 01-06 17:11:11.327564.327564 lmp.py:414]   Expert  6 |    191 | CPU
DEBUG 01-06 17:11:11.327062.327062 lmp.py:414]   Expert 24 |    191 | CPU
DEBUG 01-06 17:11:11.327036.327036 lmp.py:414]   Expert  7 |    195 | GPU
DEBUG 01-06 17:11:11.327533.327533 lmp.py:414]   Expert 46 |    196 | GPU
DEBUG 01-06 17:11:11.327507.327507 lmp.py:414]   Expert 42 |    200 | GPU
DEBUG 01-06 17:11:11.327004.327004 lmp.py:414]   Expert 18 |    206 | GPU
DEBUG 01-06 17:11:11.327740.327740 lmp.py:414]   Expert 21 |    210 | GPU
DEBUG 01-06 17:11:11.327999.327999 lmp.py:414]   Expert 40 |    210 | GPU
DEBUG 01-06 17:11:11.327211.327211 lmp.py:414]   Expert 12 |    214 | GPU
DEBUG 01-06 17:11:11.327662.327662 lmp.py:414]   Expert 29 |    216 | GPU
DEBUG 01-06 17:11:11.327636.327636 lmp.py:414]   Expert 63 |    217 | GPU
DEBUG 01-06 17:11:11.327610.327610 lmp.py:414]   Expert 59 |    219 | GPU
DEBUG 01-06 17:11:11.327299.327299 lmp.py:414]   Expert 22 |    222 | GPU
DEBUG 01-06 17:11:11.327797.327797 lmp.py:414]   Expert 32 |    225 | GPU
DEBUG 01-06 17:11:11.327055.327055 lmp.py:414]   Expert 19 |    227 | GPU
DEBUG 01-06 17:11:11.327791.327791 lmp.py:414]   Expert 37 |    237 | GPU
DEBUG 01-06 17:11:11.327050.327050 lmp.py:414]   Expert 36 |    239 | GPU
DEBUG 01-06 17:11:11.327024.327024 lmp.py:414]   Expert  3 |    252 | GPU
DEBUG 01-06 17:11:11.327521.327521 lmp.py:414]   Expert  1 |    254 | GPU
DEBUG 01-06 17:11:11.327257.327257 lmp.py:414]   Expert 16 |    254 | GPU
DEBUG 01-06 17:11:11.327754.327754 lmp.py:414]   Expert  8 |    258 | GPU
DEBUG 01-06 17:11:11.327489.327489 lmp.py:414]   Expert 30 |    263 | GPU
DEBUG 01-06 17:11:11.327702.327702 lmp.py:414]   Expert  5 |    264 | GPU
DEBUG 01-06 17:11:11.327676.327676 lmp.py:414]   Expert 20 |    268 | GPU
DEBUG 01-06 17:11:11.327650.327650 lmp.py:414]   Expert 15 |    271 | GPU
DEBUG 01-06 17:11:11.327624.327624 lmp.py:414]   Expert 62 |    277 | GPU
DEBUG 01-06 17:11:11.328121.328121 lmp.py:414]   Expert 35 |    290 | GPU
DEBUG 01-06 17:11:11.328618.328618 lmp.py:414]   Expert 17 |    298 | GPU
DEBUG 01-06 17:11:11.328116.328116 lmp.py:414]   Expert 39 |    310 | GPU
DEBUG 01-06 17:11:11.328613.328613 lmp.py:414]   Expert 60 |    311 | GPU
DEBUG 01-06 17:11:11.328349.328349 lmp.py:414]   Expert 52 |    357 | GPU
DEBUG 01-06 17:11:11.328607.328607 lmp.py:414]   Expert 44 |    368 | GPU
DEBUG 01-06 17:11:11.328343.328343 lmp.py:414]   Expert 23 |    381 | GPU
DEBUG 01-06 17:11:11.328840.328840 lmp.py:414]   Expert 53 |    441 | GPU
DEBUG 01-06 17:11:11.328053.328053 lmp.py:415] 
DEBUG 01-06 17:11:11.328053.328053 lmp.py:415]   CPU total tokens: 3938 (32.0%)
DEBUG 01-06 17:11:11.328980.328980 lmp.py:416]   GPU total tokens: 8350 (68.0%)
DEBUG 01-06 17:11:11.328107.328107 cuda_h.py:19] end experts_map_get cost 0.0014684200286865234 seconds
DEBUG 01-06 17:11:11.328942.328942 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-06 17:11:11.328864.328864 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 17:11:11.328392.328392 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 17:11:11.330474.330474 cuda_h.py:19] end allocate_cuda_memory cost 0.0015981197357177734 seconds
DEBUG 01-06 17:11:11.330337.330337 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 17:11:11.330676.330676 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 17:11:11.330015.330015 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 17:11:11.330380.330380 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, beb5cea5-9e44-4780-9484-ceb53d73785c
DEBUG 01-06 17:11:11.330619.330619 client.py:106] call stub.LoadModelAsync
INFO 01-06 17:11:11.330533.330533 client.py:127] Model loaded
DEBUG 01-06 17:11:11.331009.331009 cuda_h.py:19] end sllm_worker_task cost 0.009703874588012695 seconds
INFO 01-06 17:11:11.332528.332528 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, beb5cea5-9e44-4780-9484-ceb53d73785c
DEBUG 01-06 17:11:11.332487.332487 cuda_h.py:19] end load_into_gpu_async cost 0.00244140625 seconds
DEBUG 01-06 17:11:11.332304.332304 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 17:11:11.333036.333036 cuda_h.py:19] end restore_tensors2 cost 0.00044226646423339844 seconds
DEBUG 01-06 17:11:11.333243.333243 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.004960775375366211 seconds
DEBUG 01-06 17:11:11.335185.335185 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.0076313018798828125 seconds
DEBUG 01-06 17:11:11.335021.335021 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-06 17:11:11.335600.335600 lmp.py:461] 
DEBUG 01-06 17:11:11.335600.335600 lmp.py:461]   Computing 32 experts on CPU...
DEBUG 01-06 17:11:11.336635.336635 cuda_h.py:19] end cpu_experts_submit cost 0.0001087188720703125 seconds
DEBUG 01-06 17:11:11.336808.336808 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-06 17:11:11.347612.347612 mlpmodule.py:706] group tensors cost 0.010930776596069336 s
DEBUG 01-06 17:11:11.349833.349833 mlpmodule.py:744] pad cost 0.0017321109771728516 s
DEBUG 01-06 17:11:11.349705.349705 mlpmodule.py:750] create cpu tensor cost 4.506111145019531e-05 s
DEBUG 01-06 17:11:11.349654.349654 mlpmodule.py:755] move to cpu cost 3.1948089599609375e-05 s
DEBUG 01-06 17:11:11.361662.361662 mlpmodule.py:769] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-06 17:11:11.361419.361419 mlpmodule.py:770] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-06 17:11:11.361262.361262 mlpmodule.py:775] group_w3 first element: -0.02490234375
WARNING 01-06 17:11:11.361193.361193 mlpmodule.py:785] start einsum2
DEBUG 01-06 17:11:11.381928.381928 mlpmodule.py:795] group einsum cost 0.03205251693725586 s
DEBUG 01-06 17:11:11.382359.382359 mlpmodule.py:803] cpy2cputensor cost 0.0007011890411376953 s
DEBUG 01-06 17:11:11.387009.387009 cuda_h.py:19] end wait_cetm_experts cost 0.051013946533203125 seconds
DEBUG 01-06 17:11:11.387559.387559 cuda_h.py:10] start gpu_sexperts
DEBUG 01-06 17:11:11.388886.388886 cuda_h.py:19] end gpu_sexperts cost 0.0006134510040283203 seconds
DEBUG 01-06 17:11:11.388550.388550 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-06 17:11:11.388685.388685 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.4318695068359375e-05 seconds
DEBUG 01-06 17:11:11.388864.388864 cuda_h.py:10] start wait_experts
INFO 01-06 17:11:11.388289.388289 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, beb5cea5-9e44-4780-9484-ceb53d73785c
INFO 01-06 17:11:11.389421.389421 client.py:127] Model loaded
DEBUG 01-06 17:11:11.389086.389086 cuda_h.py:19] end wait_experts cost 0.0014312267303466797 seconds
DEBUG 01-06 17:11:11.389795.389795 cuda_h.py:10] start gpu_experts
DEBUG 01-06 17:11:11.389220.389220 lmp.py:506]   Computing 32 experts on GPU...
DEBUG 01-06 17:11:11.390589.390589 mlpmodule.py:533] gpu group tensors cost 0.0006377696990966797 s
DEBUG 01-06 17:11:11.392174.392174 mlpmodule.py:566] gpu pad cost 0.0017821788787841797 s
DEBUG 01-06 17:11:11.393702.393702 mlpmodule.py:584] gpu group einsum cost 0.0006601810455322266 s
DEBUG 01-06 17:11:11.395463.395463 mlpmodule.py:664]  experts func einsum cost 0.05909132957458496 s
DEBUG 01-06 17:11:11.396098.396098 mlpmodule.py:613] gpu experts func einsum cost 0.006932258605957031 s
DEBUG 01-06 17:11:11.396117.396117 cuda_h.py:19] end gpu_experts cost 0.007192373275756836 seconds
DEBUG 01-06 17:11:11.396385.396385 cuda_h.py:19] end layer_moe_generate_16 cost 0.071044921875 seconds
DEBUG 01-06 17:11:11.397498.397498 lmp.py:220] -------------------------------- end layer 16 --------------------------------
DEBUG 01-06 17:11:11.397407.397407 lmp.py:176] -------------------------------- start layer 17 --------------------------------
DEBUG 01-06 17:11:11.397441.397441 cuda_h.py:10] start start_load_qkvogn_s_weight_l_18
DEBUG 01-06 17:11:11.397250.397250 cuda_h.py:10] start start_load_qkvogn_s_weight_l_18
DEBUG 01-06 17:11:11.397822.397822 cuda_h.py:19] end start_load_qkvogn_s_weight_l_18 cost 4.00543212890625e-05 seconds
DEBUG 01-06 17:11:11.397665.397665 cuda_h.py:10] start sllm_worker_task
DEBUG 01-06 17:11:11.397117.397117 cuda_h.py:19] end start_load_qkvogn_s_weight_l_18 cost 0.0001518726348876953 seconds
DEBUG 01-06 17:11:11.397563.397563 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 17:11:11.397346.397346 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-06 17:11:11.397965.397965 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 17:11:11.397001.397001 mlpmodule.py:367] cuda:1 cuda:1
DEBUG 01-06 17:11:11.398529.398529 cuda_h.py:19] end allocate_cuda_memory cost 0.0002999305725097656 seconds
DEBUG 01-06 17:11:11.398275.398275 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 17:11:11.398277.398277 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 17:11:11.398907.398907 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 17:11:11.398895.398895 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 0209059c-0882-447f-9544-fea3712c09ce
DEBUG 01-06 17:11:11.398858.398858 client.py:106] call stub.LoadModelAsync
DEBUG 01-06 17:11:11.398862.398862 cuda_h.py:10] start self_attn
INFO 01-06 17:11:11.399241.399241 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 0209059c-0882-447f-9544-fea3712c09ce
DEBUG 01-06 17:11:11.399654.399654 cuda_h.py:19] end load_into_gpu_async cost 0.0015747547149658203 seconds
DEBUG 01-06 17:11:11.399271.399271 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 17:11:11.400453.400453 cuda_h.py:19] end restore_tensors2 cost 7.152557373046875e-05 seconds
DEBUG 01-06 17:11:11.400971.400971 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0023810863494873047 seconds
INFO 01-06 17:11:11.400277.400277 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 0209059c-0882-447f-9544-fea3712c09ce
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-06 17:11:11.401909.401909 cuda_h.py:19] end self_attn cost 0.0029175281524658203 seconds
DEBUG 01-06 17:11:11.402117.402117 cuda_h.py:19] end iln_self_attn_paln cost 0.004313468933105469 seconds
DEBUG 01-06 17:11:11.402768.402768 cuda_h.py:10] start layer_moe_generate_17
DEBUG 01-06 17:11:11.402008.402008 cuda_h.py:10] start gate
DEBUG 01-06 17:11:11.402025.402025 cuda_h.py:19] end gate cost 0.0006718635559082031 seconds
DEBUG 01-06 17:11:11.402901.402901 cuda_h.py:10] start experts_map_get
DEBUG 01-06 17:11:11.403255.403255 lmp.py:403] 
DEBUG 01-06 17:11:11.403255.403255 lmp.py:403] Expert Token Distribution & Device Allocation:
DEBUG 01-06 17:11:11.403296.403296 lmp.py:404]   Total experts: 64
DEBUG 01-06 17:11:11.403423.403423 lmp.py:405]   CPU experts: 32 (50%)
DEBUG 01-06 17:11:11.403496.403496 lmp.py:406]   GPU experts: 32 (50%)
DEBUG 01-06 17:11:11.403424.403424 lmp.py:407] 
DEBUG 01-06 17:11:11.403424.403424 lmp.py:407]   Expert ID | Tokens | Device
DEBUG 01-06 17:11:11.403828.403828 lmp.py:408]   -----------------------------------
DEBUG 01-06 17:11:11.403193.403193 lmp.py:414]   Expert  4 |     12 | CPU
DEBUG 01-06 17:11:11.403075.403075 lmp.py:414]   Expert 28 |     24 | CPU
DEBUG 01-06 17:11:11.403003.403003 lmp.py:414]   Expert  7 |     45 | CPU
DEBUG 01-06 17:11:11.403215.403215 lmp.py:414]   Expert 53 |     57 | CPU
DEBUG 01-06 17:11:11.403427.403427 lmp.py:414]   Expert 52 |     66 | CPU
DEBUG 01-06 17:11:11.403547.403547 lmp.py:414]   Expert 43 |     72 | CPU
DEBUG 01-06 17:11:11.403237.403237 lmp.py:414]   Expert 49 |     86 | CPU
DEBUG 01-06 17:11:11.403164.403164 lmp.py:414]   Expert 12 |     91 | CPU
DEBUG 01-06 17:11:11.403284.403284 lmp.py:414]   Expert 24 |     92 | CPU
DEBUG 01-06 17:11:11.403927.403927 lmp.py:414]   Expert 47 |    100 | CPU
DEBUG 01-06 17:11:11.403332.403332 lmp.py:414]   Expert  2 |    104 | CPU
DEBUG 01-06 17:11:11.403736.403736 lmp.py:414]   Expert 15 |    110 | CPU
DEBUG 01-06 17:11:11.403902.403902 lmp.py:414]   Expert 33 |    111 | CPU
DEBUG 01-06 17:11:11.403115.403115 lmp.py:414]   Expert 50 |    111 | CPU
DEBUG 01-06 17:11:11.403566.403566 lmp.py:414]   Expert 36 |    117 | CPU
DEBUG 01-06 17:11:11.403017.403017 lmp.py:414]   Expert 39 |    118 | CPU
DEBUG 01-06 17:11:11.403944.403944 lmp.py:414]   Expert 60 |    118 | CPU
DEBUG 01-06 17:11:11.403634.403634 lmp.py:414]   Expert  6 |    121 | CPU
DEBUG 01-06 17:11:11.403084.403084 lmp.py:414]   Expert 61 |    121 | CPU
DEBUG 01-06 17:11:11.403774.403774 lmp.py:414]   Expert 25 |    128 | CPU
DEBUG 01-06 17:11:11.403655.403655 lmp.py:414]   Expert 59 |    139 | CPU
DEBUG 01-06 17:11:11.403821.403821 lmp.py:414]   Expert 27 |    147 | CPU
DEBUG 01-06 17:11:11.403987.403987 lmp.py:414]   Expert  3 |    149 | CPU
DEBUG 01-06 17:11:11.403154.403154 lmp.py:414]   Expert 31 |    151 | CPU
DEBUG 01-06 17:11:11.403797.403797 lmp.py:414]   Expert  8 |    153 | CPU
DEBUG 01-06 17:11:11.403247.403247 lmp.py:414]   Expert 58 |    154 | CPU
DEBUG 01-06 17:11:11.403937.403937 lmp.py:414]   Expert 30 |    158 | CPU
DEBUG 01-06 17:11:11.403149.403149 lmp.py:414]   Expert 38 |    158 | CPU
DEBUG 01-06 17:11:11.403077.403077 lmp.py:414]   Expert 10 |    159 | CPU
DEBUG 01-06 17:11:11.403766.403766 lmp.py:414]   Expert 40 |    160 | CPU
DEBUG 01-06 17:11:11.403217.403217 lmp.py:414]   Expert 32 |    161 | CPU
DEBUG 01-06 17:11:11.403906.403906 lmp.py:414]   Expert 37 |    163 | CPU
DEBUG 01-06 17:11:11.403596.403596 lmp.py:414]   Expert 41 |    163 | GPU
DEBUG 01-06 17:11:11.403523.403523 lmp.py:414]   Expert 57 |    163 | GPU
DEBUG 01-06 17:11:11.403690.403690 lmp.py:414]   Expert 14 |    165 | GPU
DEBUG 01-06 17:11:11.403856.403856 lmp.py:414]   Expert 54 |    166 | GPU
DEBUG 01-06 17:11:11.403499.403499 lmp.py:414]   Expert 46 |    167 | GPU
DEBUG 01-06 17:11:11.403188.403188 lmp.py:414]   Expert 19 |    168 | GPU
DEBUG 01-06 17:11:11.403116.403116 lmp.py:414]   Expert 11 |    173 | GPU
DEBUG 01-06 17:11:11.403805.403805 lmp.py:414]   Expert 42 |    173 | GPU
DEBUG 01-06 17:11:11.404017.404017 lmp.py:414]   Expert 34 |    182 | GPU
DEBUG 01-06 17:11:11.404184.404184 lmp.py:414]   Expert  0 |    195 | GPU
DEBUG 01-06 17:11:11.404111.404111 lmp.py:414]   Expert 26 |    197 | GPU
DEBUG 01-06 17:11:11.404801.404801 lmp.py:414]   Expert 18 |    199 | GPU
DEBUG 01-06 17:11:11.404251.404251 lmp.py:414]   Expert 22 |    199 | GPU
DEBUG 01-06 17:11:11.404179.404179 lmp.py:414]   Expert  1 |    201 | GPU
DEBUG 01-06 17:11:11.404345.404345 lmp.py:414]   Expert 56 |    203 | GPU
DEBUG 01-06 17:11:11.404511.404511 lmp.py:414]   Expert 44 |    205 | GPU
DEBUG 01-06 17:11:11.404916.404916 lmp.py:414]   Expert 51 |    208 | GPU
DEBUG 01-06 17:11:11.404844.404844 lmp.py:414]   Expert 20 |    226 | GPU
DEBUG 01-06 17:11:11.404010.404010 lmp.py:414]   Expert 29 |    228 | GPU
DEBUG 01-06 17:11:11.404938.404938 lmp.py:414]   Expert 45 |    233 | GPU
DEBUG 01-06 17:11:11.404627.404627 lmp.py:414]   Expert 48 |    237 | GPU
DEBUG 01-06 17:11:11.404078.404078 lmp.py:414]   Expert 35 |    250 | GPU
DEBUG 01-06 17:11:11.404767.404767 lmp.py:414]   Expert 16 |    254 | GPU
DEBUG 01-06 17:11:11.404980.404980 lmp.py:414]   Expert 21 |    254 | GPU
DEBUG 01-06 17:11:11.404430.404430 lmp.py:414]   Expert 55 |    255 | GPU
DEBUG 01-06 17:11:11.404881.404881 lmp.py:414]   Expert  5 |    292 | GPU
DEBUG 01-06 17:11:11.404094.404094 lmp.py:414]   Expert 23 |    369 | GPU
DEBUG 01-06 17:11:11.404260.404260 lmp.py:414]   Expert 13 |    396 | GPU
DEBUG 01-06 17:11:11.404188.404188 lmp.py:414]   Expert 17 |    438 | GPU
DEBUG 01-06 17:11:11.404354.404354 lmp.py:414]   Expert  9 |    449 | GPU
DEBUG 01-06 17:11:11.404918.404918 lmp.py:414]   Expert 63 |    450 | GPU
DEBUG 01-06 17:11:11.404322.404322 lmp.py:414]   Expert 62 |   1174 | GPU
DEBUG 01-06 17:11:11.404965.404965 lmp.py:415] 
DEBUG 01-06 17:11:11.404965.404965 lmp.py:415]   CPU total tokens: 3656 (29.8%)
DEBUG 01-06 17:11:11.404608.404608 lmp.py:416]   GPU total tokens: 8632 (70.2%)
DEBUG 01-06 17:11:11.404543.404543 cuda_h.py:19] end experts_map_get cost 0.0015332698822021484 seconds
DEBUG 01-06 17:11:11.404186.404186 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-06 17:11:11.404730.404730 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 17:11:11.404828.404828 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 17:11:11.406480.406480 cuda_h.py:19] end allocate_cuda_memory cost 0.0014317035675048828 seconds
DEBUG 01-06 17:11:11.406363.406363 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 17:11:11.406881.406881 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 17:11:11.406644.406644 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 17:11:11.406055.406055 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, d38119e9-500d-4e1e-a3c5-568178a6e04c
DEBUG 01-06 17:11:11.406996.406996 client.py:106] call stub.LoadModelAsync
INFO 01-06 17:11:11.407206.407206 client.py:127] Model loaded
DEBUG 01-06 17:11:11.408845.408845 cuda_h.py:19] end sllm_worker_task cost 0.010780572891235352 seconds
INFO 01-06 17:11:11.409838.409838 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, d38119e9-500d-4e1e-a3c5-568178a6e04c
DEBUG 01-06 17:11:11.409803.409803 cuda_h.py:19] end load_into_gpu_async cost 0.003400087356567383 seconds
DEBUG 01-06 17:11:11.409720.409720 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 17:11:11.410913.410913 cuda_h.py:19] end restore_tensors2 cost 0.0007445812225341797 seconds
DEBUG 01-06 17:11:11.410119.410119 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.006056785583496094 seconds
DEBUG 01-06 17:11:11.413307.413307 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.008734464645385742 seconds
DEBUG 01-06 17:11:11.413044.413044 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-06 17:11:11.413007.413007 lmp.py:461] 
DEBUG 01-06 17:11:11.413007.413007 lmp.py:461]   Computing 32 experts on CPU...
DEBUG 01-06 17:11:11.413711.413711 cuda_h.py:19] end cpu_experts_submit cost 0.0001125335693359375 seconds
DEBUG 01-06 17:11:11.413837.413837 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-06 17:11:11.426922.426922 mlpmodule.py:706] group tensors cost 0.01277780532836914 s
DEBUG 01-06 17:11:11.428225.428225 mlpmodule.py:744] pad cost 0.0016336441040039062 s
DEBUG 01-06 17:11:11.429612.429612 mlpmodule.py:750] create cpu tensor cost 4.673004150390625e-05 s
DEBUG 01-06 17:11:11.429039.429039 mlpmodule.py:755] move to cpu cost 3.361701965332031e-05 s
DEBUG 01-06 17:11:11.440740.440740 mlpmodule.py:769] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-06 17:11:11.440219.440219 mlpmodule.py:770] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-06 17:11:11.440592.440592 mlpmodule.py:775] group_w3 first element: 0.00457763671875
WARNING 01-06 17:11:11.441973.441973 mlpmodule.py:785] start einsum2
DEBUG 01-06 17:11:11.459361.459361 mlpmodule.py:795] group einsum cost 0.029966354370117188 s
DEBUG 01-06 17:11:11.459677.459677 mlpmodule.py:803] cpy2cputensor cost 0.0006361007690429688 s
DEBUG 01-06 17:11:11.464298.464298 cuda_h.py:19] end wait_cetm_experts cost 0.050676822662353516 seconds
DEBUG 01-06 17:11:11.464584.464584 cuda_h.py:10] start gpu_sexperts
DEBUG 01-06 17:11:11.465566.465566 cuda_h.py:19] end gpu_sexperts cost 0.0006062984466552734 seconds
DEBUG 01-06 17:11:11.465515.465515 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-06 17:11:11.465411.465411 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.4557113647460938e-05 seconds
DEBUG 01-06 17:11:11.465829.465829 cuda_h.py:10] start wait_experts
INFO 01-06 17:11:11.465062.465062 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, d38119e9-500d-4e1e-a3c5-568178a6e04c
INFO 01-06 17:11:11.466503.466503 client.py:127] Model loaded
DEBUG 01-06 17:11:11.466539.466539 cuda_h.py:19] end wait_experts cost 0.0013709068298339844 seconds
DEBUG 01-06 17:11:11.466103.466103 cuda_h.py:10] start gpu_experts
DEBUG 01-06 17:11:11.466766.466766 lmp.py:506]   Computing 32 experts on GPU...
DEBUG 01-06 17:11:11.467572.467572 mlpmodule.py:533] gpu group tensors cost 0.0006451606750488281 s
DEBUG 01-06 17:11:11.471026.471026 mlpmodule.py:566] gpu pad cost 0.0042111873626708984 s
DEBUG 01-06 17:11:11.472343.472343 mlpmodule.py:664]  experts func einsum cost 0.059190988540649414 s
DEBUG 01-06 17:11:11.473649.473649 mlpmodule.py:584] gpu group einsum cost 0.0014820098876953125 s
DEBUG 01-06 17:11:11.476708.476708 mlpmodule.py:613] gpu experts func einsum cost 0.009651899337768555 s
DEBUG 01-06 17:11:11.476944.476944 cuda_h.py:19] end gpu_experts cost 0.009859323501586914 seconds
DEBUG 01-06 17:11:11.476728.476728 cuda_h.py:19] end layer_moe_generate_17 cost 0.07451748847961426 seconds
DEBUG 01-06 17:11:11.476748.476748 lmp.py:220] -------------------------------- end layer 17 --------------------------------
DEBUG 01-06 17:11:11.476318.476318 lmp.py:176] -------------------------------- start layer 18 --------------------------------
DEBUG 01-06 17:11:11.476061.476061 cuda_h.py:10] start start_load_qkvogn_s_weight_l_19
DEBUG 01-06 17:11:11.476247.476247 cuda_h.py:10] start start_load_qkvogn_s_weight_l_19
DEBUG 01-06 17:11:11.476521.476521 cuda_h.py:19] end start_load_qkvogn_s_weight_l_19 cost 3.2901763916015625e-05 seconds
DEBUG 01-06 17:11:11.477985.477985 cuda_h.py:19] end start_load_qkvogn_s_weight_l_19 cost 6.4849853515625e-05 seconds
DEBUG 01-06 17:11:11.477105.477105 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-06 17:11:11.477101.477101 mlpmodule.py:367] cuda:1 cuda:1
DEBUG 01-06 17:11:11.477732.477732 cuda_h.py:10] start sllm_worker_task
DEBUG 01-06 17:11:11.477299.477299 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 17:11:11.477850.477850 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 17:11:11.477588.477588 cuda_h.py:19] end allocate_cuda_memory cost 0.0002200603485107422 seconds
DEBUG 01-06 17:11:11.477504.477504 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 17:11:11.477883.477883 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 17:11:11.477673.477673 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 17:11:11.477660.477660 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 4a45e629-4b4d-470f-8301-299ef9f89ce2
DEBUG 01-06 17:11:11.477054.477054 client.py:106] call stub.LoadModelAsync
DEBUG 01-06 17:11:11.478399.478399 cuda_h.py:10] start self_attn
INFO 01-06 17:11:11.479431.479431 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 4a45e629-4b4d-470f-8301-299ef9f89ce2
DEBUG 01-06 17:11:11.479889.479889 cuda_h.py:19] end load_into_gpu_async cost 0.001583099365234375 seconds
DEBUG 01-06 17:11:11.479592.479592 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 17:11:11.479112.479112 cuda_h.py:19] end restore_tensors2 cost 7.295608520507812e-05 seconds
DEBUG 01-06 17:11:11.479445.479445 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.00214385986328125 seconds
INFO 01-06 17:11:11.479235.479235 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 4a45e629-4b4d-470f-8301-299ef9f89ce2
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-06 17:11:11.481782.481782 cuda_h.py:19] end self_attn cost 0.0028886795043945312 seconds
DEBUG 01-06 17:11:11.481938.481938 cuda_h.py:19] end iln_self_attn_paln cost 0.0042724609375 seconds
DEBUG 01-06 17:11:11.481397.481397 cuda_h.py:10] start layer_moe_generate_18
DEBUG 01-06 17:11:11.481683.481683 cuda_h.py:10] start gate
DEBUG 01-06 17:11:11.482421.482421 cuda_h.py:19] end gate cost 0.0006508827209472656 seconds
DEBUG 01-06 17:11:11.482058.482058 cuda_h.py:10] start experts_map_get
DEBUG 01-06 17:11:11.482505.482505 lmp.py:403] 
DEBUG 01-06 17:11:11.482505.482505 lmp.py:403] Expert Token Distribution & Device Allocation:
DEBUG 01-06 17:11:11.482307.482307 lmp.py:404]   Total experts: 64
DEBUG 01-06 17:11:11.482719.482719 lmp.py:405]   CPU experts: 32 (50%)
DEBUG 01-06 17:11:11.482554.482554 lmp.py:406]   GPU experts: 32 (50%)
DEBUG 01-06 17:11:11.482243.482243 lmp.py:407] 
DEBUG 01-06 17:11:11.482243.482243 lmp.py:407]   Expert ID | Tokens | Device
DEBUG 01-06 17:11:11.482125.482125 lmp.py:408]   -----------------------------------
DEBUG 01-06 17:11:11.482728.482728 lmp.py:414]   Expert 32 |     36 | CPU
DEBUG 01-06 17:11:11.482133.482133 lmp.py:414]   Expert 30 |     47 | CPU
DEBUG 01-06 17:11:11.482583.482583 lmp.py:414]   Expert  5 |     56 | CPU
DEBUG 01-06 17:11:11.482034.482034 lmp.py:414]   Expert 46 |     72 | CPU
DEBUG 01-06 17:11:11.482008.482008 lmp.py:414]   Expert  8 |     82 | CPU
DEBUG 01-06 17:11:11.482982.482982 lmp.py:414]   Expert 40 |     83 | CPU
DEBUG 01-06 17:11:11.482956.482956 lmp.py:414]   Expert 12 |     97 | CPU
DEBUG 01-06 17:11:11.482454.482454 lmp.py:414]   Expert 27 |    106 | CPU
DEBUG 01-06 17:11:11.482666.482666 lmp.py:414]   Expert 58 |    107 | CPU
DEBUG 01-06 17:11:11.482640.482640 lmp.py:414]   Expert 17 |    111 | CPU
DEBUG 01-06 17:11:11.482329.482329 lmp.py:414]   Expert 60 |    113 | CPU
DEBUG 01-06 17:11:11.482542.482542 lmp.py:414]   Expert  3 |    115 | CPU
DEBUG 01-06 17:11:11.482231.482231 lmp.py:414]   Expert 29 |    118 | CPU
DEBUG 01-06 17:11:11.482682.482682 lmp.py:414]   Expert 28 |    121 | CPU
DEBUG 01-06 17:11:11.482418.482418 lmp.py:414]   Expert 21 |    126 | CPU
DEBUG 01-06 17:11:11.482677.482677 lmp.py:414]   Expert 25 |    128 | CPU
DEBUG 01-06 17:11:11.482081.482081 lmp.py:414]   Expert 35 |    129 | CPU
DEBUG 01-06 17:11:11.482009.482009 lmp.py:414]   Expert 19 |    132 | CPU
DEBUG 01-06 17:11:11.482460.482460 lmp.py:414]   Expert 41 |    134 | CPU
DEBUG 01-06 17:11:11.482911.482911 lmp.py:414]   Expert  0 |    141 | CPU
DEBUG 01-06 17:11:11.482123.482123 lmp.py:414]   Expert 54 |    145 | CPU
DEBUG 01-06 17:11:11.482051.482051 lmp.py:414]   Expert  6 |    146 | CPU
DEBUG 01-06 17:11:11.482740.482740 lmp.py:414]   Expert 37 |    146 | CPU
DEBUG 01-06 17:11:11.482668.482668 lmp.py:414]   Expert 52 |    147 | CPU
DEBUG 01-06 17:11:11.482311.482311 lmp.py:414]   Expert 56 |    150 | CPU
DEBUG 01-06 17:11:11.483477.483477 lmp.py:414]   Expert 53 |    156 | CPU
DEBUG 01-06 17:11:11.483881.483881 lmp.py:414]   Expert 63 |    156 | CPU
DEBUG 01-06 17:11:11.483286.483286 lmp.py:414]   Expert 48 |    157 | CPU
DEBUG 01-06 17:11:11.483975.483975 lmp.py:414]   Expert 36 |    161 | CPU
DEBUG 01-06 17:11:11.483949.483949 lmp.py:414]   Expert 59 |    169 | CPU
DEBUG 01-06 17:11:11.483639.483639 lmp.py:414]   Expert  9 |    175 | CPU
DEBUG 01-06 17:11:11.483089.483089 lmp.py:414]   Expert 39 |    182 | CPU
DEBUG 01-06 17:11:11.483779.483779 lmp.py:414]   Expert  1 |    188 | GPU
DEBUG 01-06 17:11:11.483468.483468 lmp.py:414]   Expert 20 |    195 | GPU
DEBUG 01-06 17:11:11.483396.483396 lmp.py:414]   Expert 11 |    199 | GPU
DEBUG 01-06 17:11:11.483324.483324 lmp.py:414]   Expert 42 |    200 | GPU
DEBUG 01-06 17:11:11.483251.483251 lmp.py:414]   Expert 43 |    200 | GPU
DEBUG 01-06 17:11:11.483656.483656 lmp.py:414]   Expert 61 |    202 | GPU
DEBUG 01-06 17:11:11.483345.483345 lmp.py:414]   Expert  7 |    205 | GPU
DEBUG 01-06 17:11:11.483796.483796 lmp.py:414]   Expert 47 |    205 | GPU
DEBUG 01-06 17:11:11.483008.483008 lmp.py:414]   Expert 34 |    206 | GPU
DEBUG 01-06 17:11:11.483698.483698 lmp.py:414]   Expert 55 |    214 | GPU
DEBUG 01-06 17:11:11.483387.483387 lmp.py:414]   Expert 13 |    218 | GPU
DEBUG 01-06 17:11:11.483076.483076 lmp.py:414]   Expert 16 |    220 | GPU
DEBUG 01-06 17:11:11.483766.483766 lmp.py:414]   Expert 18 |    228 | GPU
DEBUG 01-06 17:11:11.483217.483217 lmp.py:414]   Expert 57 |    228 | GPU
DEBUG 01-06 17:11:11.483906.483906 lmp.py:414]   Expert 15 |    239 | GPU
DEBUG 01-06 17:11:11.483787.483787 lmp.py:414]   Expert  4 |    243 | GPU
DEBUG 01-06 17:11:11.483430.483430 lmp.py:414]   Expert 22 |    245 | GPU
DEBUG 01-06 17:11:11.483596.483596 lmp.py:414]   Expert 31 |    246 | GPU
DEBUG 01-06 17:11:11.483762.483762 lmp.py:414]   Expert 33 |    246 | GPU
DEBUG 01-06 17:11:11.483929.483929 lmp.py:414]   Expert 45 |    248 | GPU
DEBUG 01-06 17:11:11.483618.483618 lmp.py:414]   Expert 50 |    250 | GPU
DEBUG 01-06 17:11:11.483069.483069 lmp.py:414]   Expert 51 |    256 | GPU
DEBUG 01-06 17:11:11.483997.483997 lmp.py:414]   Expert 26 |    273 | GPU
DEBUG 01-06 17:11:11.483209.483209 lmp.py:414]   Expert 49 |    273 | GPU
DEBUG 01-06 17:11:11.483137.483137 lmp.py:414]   Expert 38 |    275 | GPU
DEBUG 01-06 17:11:11.483064.483064 lmp.py:414]   Expert 10 |    287 | GPU
DEBUG 01-06 17:11:11.483754.483754 lmp.py:414]   Expert 44 |    299 | GPU
DEBUG 01-06 17:11:11.483920.483920 lmp.py:414]   Expert 24 |    302 | GPU
DEBUG 01-06 17:11:11.483563.483563 lmp.py:414]   Expert  2 |    310 | GPU
DEBUG 01-06 17:11:11.483206.483206 lmp.py:414]   Expert 14 |    318 | GPU
DEBUG 01-06 17:11:11.483610.483610 lmp.py:414]   Expert 23 |    443 | GPU
DEBUG 01-06 17:11:11.483777.483777 lmp.py:414]   Expert 62 |    683 | GPU
DEBUG 01-06 17:11:11.483419.483419 lmp.py:415] 
DEBUG 01-06 17:11:11.483419.483419 lmp.py:415]   CPU total tokens: 3944 (32.1%)
DEBUG 01-06 17:11:11.483062.483062 lmp.py:416]   GPU total tokens: 8344 (67.9%)
DEBUG 01-06 17:11:11.483759.483759 cuda_h.py:19] end experts_map_get cost 0.001506805419921875 seconds
DEBUG 01-06 17:11:11.483163.483163 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-06 17:11:11.483231.483231 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 17:11:11.483282.483282 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 17:11:11.485031.485031 cuda_h.py:19] end allocate_cuda_memory cost 0.0017476081848144531 seconds
DEBUG 01-06 17:11:11.485066.485066 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 17:11:11.485583.485583 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 17:11:11.485061.485061 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 17:11:11.485665.485665 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 040bcd57-a426-4303-a0a1-bce27f0b6af4
DEBUG 01-06 17:11:11.486652.486652 client.py:106] call stub.LoadModelAsync
INFO 01-06 17:11:11.487618.487618 client.py:127] Model loaded
DEBUG 01-06 17:11:11.487275.487275 cuda_h.py:19] end sllm_worker_task cost 0.010554313659667969 seconds
INFO 01-06 17:11:11.489732.489732 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 040bcd57-a426-4303-a0a1-bce27f0b6af4
DEBUG 01-06 17:11:11.489844.489844 cuda_h.py:19] end load_into_gpu_async cost 0.003403186798095703 seconds
DEBUG 01-06 17:11:11.489144.489144 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 17:11:11.489954.489954 cuda_h.py:19] end restore_tensors2 cost 0.0003924369812011719 seconds
DEBUG 01-06 17:11:11.489015.489015 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.005998134613037109 seconds
DEBUG 01-06 17:11:11.492659.492659 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.008660078048706055 seconds
DEBUG 01-06 17:11:11.492470.492470 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-06 17:11:11.492002.492002 lmp.py:461] 
DEBUG 01-06 17:11:11.492002.492002 lmp.py:461]   Computing 32 experts on CPU...
DEBUG 01-06 17:11:11.492421.492421 cuda_h.py:19] end cpu_experts_submit cost 0.00011205673217773438 seconds
DEBUG 01-06 17:11:11.492932.492932 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-06 17:11:11.498409.498409 mlpmodule.py:706] group tensors cost 0.006121158599853516 s
DEBUG 01-06 17:11:11.501755.501755 mlpmodule.py:744] pad cost 0.0020265579223632812 s
DEBUG 01-06 17:11:11.501216.501216 mlpmodule.py:750] create cpu tensor cost 5.316734313964844e-05 s
DEBUG 01-06 17:11:11.502815.502815 mlpmodule.py:755] move to cpu cost 3.814697265625e-05 s
DEBUG 01-06 17:11:11.511483.511483 mlpmodule.py:769] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-06 17:11:11.511485.511485 mlpmodule.py:770] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-06 17:11:11.511474.511474 mlpmodule.py:775] group_w3 first element: 0.0024871826171875
WARNING 01-06 17:11:11.511126.511126 mlpmodule.py:785] start einsum2
DEBUG 01-06 17:11:11.528396.528396 mlpmodule.py:795] group einsum cost 0.026604890823364258 s
DEBUG 01-06 17:11:11.529754.529754 mlpmodule.py:803] cpy2cputensor cost 0.0007088184356689453 s
DEBUG 01-06 17:11:11.533831.533831 cuda_h.py:19] end wait_cetm_experts cost 0.04099106788635254 seconds
DEBUG 01-06 17:11:11.533903.533903 cuda_h.py:10] start gpu_sexperts
DEBUG 01-06 17:11:11.534369.534369 cuda_h.py:19] end gpu_sexperts cost 0.0006120204925537109 seconds
DEBUG 01-06 17:11:11.534703.534703 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-06 17:11:11.534268.534268 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.4080276489257812e-05 seconds
DEBUG 01-06 17:11:11.534971.534971 cuda_h.py:10] start wait_experts
INFO 01-06 17:11:11.534250.534250 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 040bcd57-a426-4303-a0a1-bce27f0b6af4
DEBUG 01-06 17:11:11.541733.541733 mlpmodule.py:664]  experts func einsum cost 0.048276662826538086 s
INFO 01-06 17:11:11.542985.542985 client.py:127] Model loaded
DEBUG 01-06 17:11:11.542359.542359 cuda_h.py:19] end wait_experts cost 0.007802248001098633 seconds
DEBUG 01-06 17:11:11.542168.542168 cuda_h.py:10] start gpu_experts
DEBUG 01-06 17:11:11.542639.542639 lmp.py:506]   Computing 32 experts on GPU...
DEBUG 01-06 17:11:11.543723.543723 mlpmodule.py:533] gpu group tensors cost 0.0006403923034667969 s
DEBUG 01-06 17:11:11.545341.545341 mlpmodule.py:566] gpu pad cost 0.0015909671783447266 s
DEBUG 01-06 17:11:11.545893.545893 mlpmodule.py:584] gpu group einsum cost 0.0005757808685302734 s
DEBUG 01-06 17:11:11.548804.548804 mlpmodule.py:613] gpu experts func einsum cost 0.005826234817504883 s
DEBUG 01-06 17:11:11.548178.548178 cuda_h.py:19] end gpu_experts cost 0.0060176849365234375 seconds
DEBUG 01-06 17:11:11.548347.548347 cuda_h.py:19] end layer_moe_generate_18 cost 0.06731343269348145 seconds
DEBUG 01-06 17:11:11.548737.548737 lmp.py:220] -------------------------------- end layer 18 --------------------------------
DEBUG 01-06 17:11:11.548123.548123 lmp.py:176] -------------------------------- start layer 19 --------------------------------
DEBUG 01-06 17:11:11.548342.548342 cuda_h.py:10] start start_load_qkvogn_s_weight_l_20
DEBUG 01-06 17:11:11.549098.549098 cuda_h.py:10] start start_load_qkvogn_s_weight_l_20
DEBUG 01-06 17:11:11.549325.549325 cuda_h.py:19] end start_load_qkvogn_s_weight_l_20 cost 3.504753112792969e-05 seconds
DEBUG 01-06 17:11:11.549266.549266 cuda_h.py:19] end start_load_qkvogn_s_weight_l_20 cost 6.723403930664062e-05 seconds
DEBUG 01-06 17:11:11.549863.549863 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-06 17:11:11.549607.549607 cuda_h.py:10] start sllm_worker_task
DEBUG 01-06 17:11:11.549545.549545 mlpmodule.py:367] cuda:1 cuda:1
DEBUG 01-06 17:11:11.549698.549698 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 17:11:11.549861.549861 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 17:11:11.549019.549019 cuda_h.py:19] end allocate_cuda_memory cost 0.00032258033752441406 seconds
DEBUG 01-06 17:11:11.549207.549207 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 17:11:11.549109.549109 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 17:11:11.549309.549309 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 17:11:11.550581.550581 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 7d09b88c-0a03-4c42-98c4-65acbf139bc0
DEBUG 01-06 17:11:11.550213.550213 client.py:106] call stub.LoadModelAsync
DEBUG 01-06 17:11:11.550931.550931 cuda_h.py:10] start self_attn
INFO 01-06 17:11:11.551609.551609 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 7d09b88c-0a03-4c42-98c4-65acbf139bc0
DEBUG 01-06 17:11:11.551445.551445 cuda_h.py:19] end load_into_gpu_async cost 0.0015468597412109375 seconds
DEBUG 01-06 17:11:11.551241.551241 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 17:11:11.551423.551423 cuda_h.py:19] end restore_tensors2 cost 7.2479248046875e-05 seconds
DEBUG 01-06 17:11:11.551033.551033 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.002186298370361328 seconds
INFO 01-06 17:11:11.551724.551724 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 7d09b88c-0a03-4c42-98c4-65acbf139bc0
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-06 17:11:11.553625.553625 cuda_h.py:19] end self_attn cost 0.0028717517852783203 seconds
DEBUG 01-06 17:11:11.553954.553954 cuda_h.py:19] end iln_self_attn_paln cost 0.004446744918823242 seconds
DEBUG 01-06 17:11:11.553128.553128 cuda_h.py:10] start layer_moe_generate_19
DEBUG 01-06 17:11:11.553368.553368 cuda_h.py:10] start gate
DEBUG 01-06 17:11:11.554715.554715 cuda_h.py:19] end gate cost 0.0006432533264160156 seconds
DEBUG 01-06 17:11:11.554352.554352 cuda_h.py:10] start experts_map_get
DEBUG 01-06 17:11:11.554984.554984 lmp.py:403] 
DEBUG 01-06 17:11:11.554984.554984 lmp.py:403] Expert Token Distribution & Device Allocation:
DEBUG 01-06 17:11:11.554833.554833 lmp.py:404]   Total experts: 64
DEBUG 01-06 17:11:11.554244.554244 lmp.py:405]   CPU experts: 32 (50%)
DEBUG 01-06 17:11:11.554318.554318 lmp.py:406]   GPU experts: 32 (50%)
DEBUG 01-06 17:11:11.554484.554484 lmp.py:407] 
DEBUG 01-06 17:11:11.554484.554484 lmp.py:407]   Expert ID | Tokens | Device
DEBUG 01-06 17:11:11.554127.554127 lmp.py:408]   -----------------------------------
DEBUG 01-06 17:11:11.554254.554254 lmp.py:414]   Expert 44 |     36 | CPU
DEBUG 01-06 17:11:11.554897.554897 lmp.py:414]   Expert  1 |     51 | CPU
DEBUG 01-06 17:11:11.554586.554586 lmp.py:414]   Expert 28 |     60 | CPU
DEBUG 01-06 17:11:11.554560.554560 lmp.py:414]   Expert 60 |     62 | CPU
DEBUG 01-06 17:11:11.554772.554772 lmp.py:414]   Expert 48 |     75 | CPU
DEBUG 01-06 17:11:11.554223.554223 lmp.py:414]   Expert 27 |     88 | CPU
DEBUG 01-06 17:11:11.554959.554959 lmp.py:414]   Expert  0 |    108 | CPU
DEBUG 01-06 17:11:11.554125.554125 lmp.py:414]   Expert 42 |    108 | CPU
DEBUG 01-06 17:11:11.554053.554053 lmp.py:414]   Expert 30 |    112 | CPU
DEBUG 01-06 17:11:11.555126.555126 lmp.py:414]   Expert 59 |    113 | CPU
DEBUG 01-06 17:11:11.555769.555769 lmp.py:414]   Expert 22 |    115 | CPU
DEBUG 01-06 17:11:11.555174.555174 lmp.py:414]   Expert 62 |    116 | CPU
DEBUG 01-06 17:11:11.555101.555101 lmp.py:414]   Expert 58 |    118 | CPU
DEBUG 01-06 17:11:11.555552.555552 lmp.py:414]   Expert 16 |    130 | CPU
DEBUG 01-06 17:11:11.555480.555480 lmp.py:414]   Expert  8 |    132 | CPU
DEBUG 01-06 17:11:11.555408.555408 lmp.py:414]   Expert 12 |    132 | CPU
DEBUG 01-06 17:11:11.555097.555097 lmp.py:414]   Expert 50 |    137 | CPU
DEBUG 01-06 17:11:11.555025.555025 lmp.py:414]   Expert 57 |    138 | CPU
DEBUG 01-06 17:11:11.555714.555714 lmp.py:414]   Expert 56 |    143 | CPU
DEBUG 01-06 17:11:11.555595.555595 lmp.py:414]   Expert  5 |    145 | CPU
DEBUG 01-06 17:11:11.555762.555762 lmp.py:414]   Expert 55 |    152 | CPU
DEBUG 01-06 17:11:11.555928.555928 lmp.py:414]   Expert 15 |    154 | CPU
DEBUG 01-06 17:11:11.555332.555332 lmp.py:414]   Expert 26 |    154 | CPU
DEBUG 01-06 17:11:11.555022.555022 lmp.py:414]   Expert 47 |    156 | CPU
DEBUG 01-06 17:11:11.555949.555949 lmp.py:414]   Expert 32 |    158 | CPU
DEBUG 01-06 17:11:11.555400.555400 lmp.py:414]   Expert 34 |    163 | CPU
DEBUG 01-06 17:11:11.555089.555089 lmp.py:414]   Expert 24 |    165 | CPU
DEBUG 01-06 17:11:11.555779.555779 lmp.py:414]   Expert 52 |    165 | CPU
DEBUG 01-06 17:11:11.555991.555991 lmp.py:414]   Expert 41 |    166 | CPU
DEBUG 01-06 17:11:11.555681.555681 lmp.py:414]   Expert 54 |    166 | CPU
DEBUG 01-06 17:11:11.555370.555370 lmp.py:414]   Expert  6 |    167 | CPU
DEBUG 01-06 17:11:11.555251.555251 lmp.py:414]   Expert 40 |    167 | CPU
DEBUG 01-06 17:11:11.555656.555656 lmp.py:414]   Expert 18 |    168 | GPU
DEBUG 01-06 17:11:11.555060.555060 lmp.py:414]   Expert  2 |    169 | GPU
DEBUG 01-06 17:11:11.555226.555226 lmp.py:414]   Expert 13 |    174 | GPU
DEBUG 01-06 17:11:11.555869.555869 lmp.py:414]   Expert  3 |    178 | GPU
DEBUG 01-06 17:11:11.555559.555559 lmp.py:414]   Expert 46 |    181 | GPU
DEBUG 01-06 17:11:11.555248.555248 lmp.py:414]   Expert 20 |    182 | GPU
DEBUG 01-06 17:11:11.555937.555937 lmp.py:414]   Expert 37 |    184 | GPU
DEBUG 01-06 17:11:11.555388.555388 lmp.py:414]   Expert 51 |    192 | GPU
DEBUG 01-06 17:11:11.555316.555316 lmp.py:414]   Expert 19 |    193 | GPU
DEBUG 01-06 17:11:11.555767.555767 lmp.py:414]   Expert 25 |    194 | GPU
DEBUG 01-06 17:11:11.555456.555456 lmp.py:414]   Expert 31 |    199 | GPU
DEBUG 01-06 17:11:11.555907.555907 lmp.py:414]   Expert 43 |    201 | GPU
DEBUG 01-06 17:11:11.555934.555934 lmp.py:414]   Expert 17 |    202 | GPU
DEBUG 01-06 17:11:11.555100.555100 lmp.py:414]   Expert 35 |    202 | GPU
DEBUG 01-06 17:11:11.555266.555266 lmp.py:414]   Expert 11 |    203 | GPU
DEBUG 01-06 17:11:11.555433.555433 lmp.py:414]   Expert 23 |    206 | GPU
DEBUG 01-06 17:11:11.555122.555122 lmp.py:414]   Expert 39 |    221 | GPU
DEBUG 01-06 17:11:11.555811.555811 lmp.py:414]   Expert 49 |    222 | GPU
DEBUG 01-06 17:11:11.555739.555739 lmp.py:414]   Expert 10 |    232 | GPU
DEBUG 01-06 17:11:11.555951.555951 lmp.py:414]   Expert 53 |    233 | GPU
DEBUG 01-06 17:11:11.555402.555402 lmp.py:414]   Expert 33 |    250 | GPU
DEBUG 01-06 17:11:11.555853.555853 lmp.py:414]   Expert 38 |    266 | GPU
DEBUG 01-06 17:11:11.555304.555304 lmp.py:414]   Expert 36 |    277 | GPU
DEBUG 01-06 17:11:11.555755.555755 lmp.py:414]   Expert  4 |    301 | GPU
DEBUG 01-06 17:11:11.555444.555444 lmp.py:414]   Expert 21 |    328 | GPU
DEBUG 01-06 17:11:11.555134.555134 lmp.py:414]   Expert 14 |    345 | GPU
DEBUG 01-06 17:11:11.555538.555538 lmp.py:414]   Expert 45 |    365 | GPU
DEBUG 01-06 17:11:11.555704.555704 lmp.py:414]   Expert 63 |    369 | GPU
DEBUG 01-06 17:11:11.555870.555870 lmp.py:414]   Expert 61 |    387 | GPU
DEBUG 01-06 17:11:11.555036.555036 lmp.py:414]   Expert  9 |    397 | GPU
DEBUG 01-06 17:11:11.555203.555203 lmp.py:414]   Expert 29 |    498 | GPU
DEBUG 01-06 17:11:11.555654.555654 lmp.py:414]   Expert  7 |    517 | GPU
DEBUG 01-06 17:11:11.555296.555296 lmp.py:415] 
DEBUG 01-06 17:11:11.555296.555296 lmp.py:415]   CPU total tokens: 4052 (33.0%)
DEBUG 01-06 17:11:11.555178.555178 lmp.py:416]   GPU total tokens: 8236 (67.0%)
DEBUG 01-06 17:11:11.555112.555112 cuda_h.py:19] end experts_map_get cost 0.001516103744506836 seconds
DEBUG 01-06 17:11:11.555994.555994 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-06 17:11:11.556631.556631 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 17:11:11.556729.556729 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 17:11:11.557080.557080 cuda_h.py:19] end allocate_cuda_memory cost 0.0015594959259033203 seconds
DEBUG 01-06 17:11:11.557467.557467 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 17:11:11.557368.557368 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 17:11:11.557939.557939 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 17:11:11.557874.557874 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 5f23a46b-6d4d-4068-980a-19b044498d1c
DEBUG 01-06 17:11:11.558801.558801 client.py:106] call stub.LoadModelAsync
INFO 01-06 17:11:11.559820.559820 client.py:127] Model loaded
DEBUG 01-06 17:11:11.560354.560354 cuda_h.py:19] end sllm_worker_task cost 0.010669946670532227 seconds
INFO 01-06 17:11:11.561819.561819 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 5f23a46b-6d4d-4068-980a-19b044498d1c
DEBUG 01-06 17:11:11.561808.561808 cuda_h.py:19] end load_into_gpu_async cost 0.0032362937927246094 seconds
DEBUG 01-06 17:11:11.561511.561511 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 17:11:11.561072.561072 cuda_h.py:19] end restore_tensors2 cost 0.0003180503845214844 seconds
DEBUG 01-06 17:11:11.561325.561325 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0054743289947509766 seconds
DEBUG 01-06 17:11:11.564220.564220 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.008111238479614258 seconds
DEBUG 01-06 17:11:11.564195.564195 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-06 17:11:11.564417.564417 lmp.py:461] 
DEBUG 01-06 17:11:11.564417.564417 lmp.py:461]   Computing 32 experts on CPU...
DEBUG 01-06 17:11:11.564313.564313 cuda_h.py:19] end cpu_experts_submit cost 0.00011372566223144531 seconds
DEBUG 01-06 17:11:11.564440.564440 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-06 17:11:11.576883.576883 mlpmodule.py:706] group tensors cost 0.011922597885131836 s
DEBUG 01-06 17:11:11.580762.580762 mlpmodule.py:744] pad cost 0.0026848316192626953 s
DEBUG 01-06 17:11:11.580223.580223 mlpmodule.py:750] create cpu tensor cost 5.316734313964844e-05 s
DEBUG 01-06 17:11:11.580239.580239 mlpmodule.py:755] move to cpu cost 3.6716461181640625e-05 s
DEBUG 01-06 17:11:11.591916.591916 mlpmodule.py:769] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-06 17:11:11.591773.591773 mlpmodule.py:770] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-06 17:11:11.591954.591954 mlpmodule.py:775] group_w3 first element: -0.0034942626953125
WARNING 01-06 17:11:11.591275.591275 mlpmodule.py:785] start einsum2
DEBUG 01-06 17:11:11.608761.608761 mlpmodule.py:795] group einsum cost 0.02761054039001465 s
DEBUG 01-06 17:11:11.609032.609032 mlpmodule.py:803] cpy2cputensor cost 0.0006635189056396484 s
DEBUG 01-06 17:11:11.613018.613018 cuda_h.py:19] end wait_cetm_experts cost 0.049033403396606445 seconds
DEBUG 01-06 17:11:11.613820.613820 cuda_h.py:10] start gpu_sexperts
DEBUG 01-06 17:11:11.614577.614577 cuda_h.py:19] end gpu_sexperts cost 0.0006182193756103516 seconds
DEBUG 01-06 17:11:11.614480.614480 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-06 17:11:11.614900.614900 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.3603439331054688e-05 seconds
DEBUG 01-06 17:11:11.614079.614079 cuda_h.py:10] start wait_experts
INFO 01-06 17:11:11.614027.614027 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 5f23a46b-6d4d-4068-980a-19b044498d1c
INFO 01-06 17:11:11.615355.615355 client.py:127] Model loaded
DEBUG 01-06 17:11:11.615775.615775 cuda_h.py:19] end wait_experts cost 0.001360177993774414 seconds
DEBUG 01-06 17:11:11.615816.615816 cuda_h.py:10] start gpu_experts
DEBUG 01-06 17:11:11.615002.615002 lmp.py:506]   Computing 32 experts on GPU...
DEBUG 01-06 17:11:11.616676.616676 mlpmodule.py:533] gpu group tensors cost 0.000652313232421875 s
DEBUG 01-06 17:11:11.618897.618897 mlpmodule.py:566] gpu pad cost 0.0017826557159423828 s
DEBUG 01-06 17:11:11.619224.619224 mlpmodule.py:584] gpu group einsum cost 0.0005846023559570312 s
DEBUG 01-06 17:11:11.622554.622554 mlpmodule.py:664]  experts func einsum cost 0.05773568153381348 s
DEBUG 01-06 17:11:11.622455.622455 mlpmodule.py:613] gpu experts func einsum cost 0.006900787353515625 s
DEBUG 01-06 17:11:11.623281.623281 cuda_h.py:19] end gpu_experts cost 0.00715947151184082 seconds
DEBUG 01-06 17:11:11.623311.623311 cuda_h.py:19] end layer_moe_generate_19 cost 0.06952071189880371 seconds
DEBUG 01-06 17:11:11.623272.623272 lmp.py:220] -------------------------------- end layer 19 --------------------------------
DEBUG 01-06 17:11:11.623465.623465 lmp.py:176] -------------------------------- start layer 20 --------------------------------
DEBUG 01-06 17:11:11.623546.623546 cuda_h.py:10] start start_load_qkvogn_s_weight_l_21
DEBUG 01-06 17:11:11.623831.623831 cuda_h.py:10] start start_load_qkvogn_s_weight_l_21
DEBUG 01-06 17:11:11.623635.623635 cuda_h.py:19] end start_load_qkvogn_s_weight_l_21 cost 3.647804260253906e-05 seconds
DEBUG 01-06 17:11:11.623106.623106 cuda_h.py:19] end start_load_qkvogn_s_weight_l_21 cost 7.081031799316406e-05 seconds
DEBUG 01-06 17:11:11.623233.623233 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-06 17:11:11.623818.623818 mlpmodule.py:367] cuda:1 cuda:1
DEBUG 01-06 17:11:11.623476.623476 cuda_h.py:10] start sllm_worker_task
DEBUG 01-06 17:11:11.623361.623361 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 17:11:11.623482.623482 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 17:11:11.624825.624825 cuda_h.py:19] end allocate_cuda_memory cost 0.0003223419189453125 seconds
DEBUG 01-06 17:11:11.624749.624749 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 17:11:11.624148.624148 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 17:11:11.624222.624222 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 17:11:11.624455.624455 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, db12217c-2d3d-43d6-9b3b-f032ea4f67f3
DEBUG 01-06 17:11:11.624140.624140 client.py:106] call stub.LoadModelAsync
DEBUG 01-06 17:11:11.624906.624906 cuda_h.py:10] start self_attn
INFO 01-06 17:11:11.626538.626538 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, db12217c-2d3d-43d6-9b3b-f032ea4f67f3
DEBUG 01-06 17:11:11.626090.626090 cuda_h.py:19] end load_into_gpu_async cost 0.0016448497772216797 seconds
DEBUG 01-06 17:11:11.626601.626601 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 17:11:11.626167.626167 cuda_h.py:19] end restore_tensors2 cost 7.462501525878906e-05 seconds
DEBUG 01-06 17:11:11.626493.626493 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.00231170654296875 seconds
INFO 01-06 17:11:11.626898.626898 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, db12217c-2d3d-43d6-9b3b-f032ea4f67f3
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-06 17:11:11.627467.627467 cuda_h.py:19] end self_attn cost 0.0028367042541503906 seconds
DEBUG 01-06 17:11:11.628059.628059 cuda_h.py:19] end iln_self_attn_paln cost 0.004474639892578125 seconds
DEBUG 01-06 17:11:11.628187.628187 cuda_h.py:10] start layer_moe_generate_20
DEBUG 01-06 17:11:11.628950.628950 cuda_h.py:10] start gate
DEBUG 01-06 17:11:11.628847.628847 cuda_h.py:19] end gate cost 0.0006618499755859375 seconds
DEBUG 01-06 17:11:11.629677.629677 cuda_h.py:10] start experts_map_get
DEBUG 01-06 17:11:11.629501.629501 lmp.py:403] 
DEBUG 01-06 17:11:11.629501.629501 lmp.py:403] Expert Token Distribution & Device Allocation:
DEBUG 01-06 17:11:11.629304.629304 lmp.py:404]   Total experts: 64
DEBUG 01-06 17:11:11.629953.629953 lmp.py:405]   CPU experts: 32 (50%)
DEBUG 01-06 17:11:11.629504.629504 lmp.py:406]   GPU experts: 32 (50%)
DEBUG 01-06 17:11:11.629193.629193 lmp.py:407] 
DEBUG 01-06 17:11:11.629193.629193 lmp.py:407]   Expert ID | Tokens | Device
DEBUG 01-06 17:11:11.629644.629644 lmp.py:408]   -----------------------------------
DEBUG 01-06 17:11:11.629055.629055 lmp.py:414]   Expert 54 |     23 | CPU
DEBUG 01-06 17:11:11.629460.629460 lmp.py:414]   Expert  3 |     32 | CPU
DEBUG 01-06 17:11:11.629911.629911 lmp.py:414]   Expert  8 |     41 | CPU
DEBUG 01-06 17:11:11.629646.629646 lmp.py:414]   Expert 28 |     43 | CPU
DEBUG 01-06 17:11:11.629859.629859 lmp.py:414]   Expert 43 |     44 | CPU
DEBUG 01-06 17:11:11.629594.629594 lmp.py:414]   Expert 63 |     53 | CPU
DEBUG 01-06 17:11:11.629568.629568 lmp.py:414]   Expert 36 |     65 | CPU
DEBUG 01-06 17:11:11.629542.629542 lmp.py:414]   Expert 38 |     74 | CPU
DEBUG 01-06 17:11:11.629516.629516 lmp.py:414]   Expert  6 |     79 | CPU
DEBUG 01-06 17:11:11.629206.629206 lmp.py:414]   Expert 39 |     88 | CPU
DEBUG 01-06 17:11:11.629180.629180 lmp.py:414]   Expert 57 |    107 | CPU
DEBUG 01-06 17:11:11.629677.629677 lmp.py:414]   Expert 41 |    109 | CPU
DEBUG 01-06 17:11:11.629413.629413 lmp.py:414]   Expert 52 |    109 | CPU
DEBUG 01-06 17:11:11.629817.629817 lmp.py:414]   Expert 12 |    110 | CPU
DEBUG 01-06 17:11:11.629268.629268 lmp.py:414]   Expert 47 |    124 | CPU
DEBUG 01-06 17:11:11.629957.629957 lmp.py:414]   Expert 19 |    126 | CPU
DEBUG 01-06 17:11:11.629170.629170 lmp.py:414]   Expert 22 |    132 | CPU
DEBUG 01-06 17:11:11.629859.629859 lmp.py:414]   Expert 13 |    135 | CPU
DEBUG 01-06 17:11:11.629833.629833 lmp.py:414]   Expert 46 |    146 | CPU
DEBUG 01-06 17:11:11.629999.629999 lmp.py:414]   Expert 24 |    160 | CPU
DEBUG 01-06 17:11:11.629165.629165 lmp.py:414]   Expert 50 |    161 | CPU
DEBUG 01-06 17:11:11.629093.629093 lmp.py:414]   Expert 55 |    161 | CPU
DEBUG 01-06 17:11:11.629544.629544 lmp.py:414]   Expert 20 |    168 | CPU
DEBUG 01-06 17:11:11.629518.629518 lmp.py:414]   Expert 37 |    168 | CPU
DEBUG 01-06 17:11:11.629969.629969 lmp.py:414]   Expert 40 |    169 | CPU
DEBUG 01-06 17:11:11.629420.629420 lmp.py:414]   Expert 21 |    170 | CPU
DEBUG 01-06 17:11:11.629109.629109 lmp.py:414]   Expert  2 |    171 | CPU
DEBUG 01-06 17:11:11.629322.629322 lmp.py:414]   Expert 61 |    175 | CPU
DEBUG 01-06 17:11:11.629772.629772 lmp.py:414]   Expert 33 |    179 | CPU
DEBUG 01-06 17:11:11.629223.629223 lmp.py:414]   Expert 42 |    179 | CPU
DEBUG 01-06 17:11:11.629151.629151 lmp.py:414]   Expert 49 |    180 | CPU
DEBUG 01-06 17:11:11.629556.629556 lmp.py:414]   Expert 23 |    184 | CPU
DEBUG 01-06 17:11:11.629007.629007 lmp.py:414]   Expert 53 |    186 | GPU
DEBUG 01-06 17:11:11.629934.629934 lmp.py:414]   Expert 18 |    190 | GPU
DEBUG 01-06 17:11:11.629385.629385 lmp.py:414]   Expert  0 |    196 | GPU
DEBUG 01-06 17:11:11.630074.630074 lmp.py:414]   Expert  5 |    198 | GPU
DEBUG 01-06 17:11:11.630764.630764 lmp.py:414]   Expert 30 |    201 | GPU
DEBUG 01-06 17:11:11.630976.630976 lmp.py:414]   Expert 32 |    201 | GPU
DEBUG 01-06 17:11:11.630189.630189 lmp.py:414]   Expert 16 |    202 | GPU
DEBUG 01-06 17:11:11.630116.630116 lmp.py:414]   Expert  7 |    205 | GPU
DEBUG 01-06 17:11:11.630806.630806 lmp.py:414]   Expert 14 |    207 | GPU
DEBUG 01-06 17:11:11.630257.630257 lmp.py:414]   Expert 31 |    208 | GPU
DEBUG 01-06 17:11:11.630184.630184 lmp.py:414]   Expert 34 |    214 | GPU
DEBUG 01-06 17:11:11.630635.630635 lmp.py:414]   Expert 60 |    217 | GPU
DEBUG 01-06 17:11:11.630848.630848 lmp.py:414]   Expert 62 |    221 | GPU
DEBUG 01-06 17:11:11.630537.630537 lmp.py:414]   Expert  9 |    222 | GPU
DEBUG 01-06 17:11:11.630988.630988 lmp.py:414]   Expert 59 |    222 | GPU
DEBUG 01-06 17:11:11.630200.630200 lmp.py:414]   Expert 17 |    223 | GPU
DEBUG 01-06 17:11:11.630651.630651 lmp.py:414]   Expert 29 |    225 | GPU
DEBUG 01-06 17:11:11.630102.630102 lmp.py:414]   Expert 10 |    228 | GPU
DEBUG 01-06 17:11:11.630268.630268 lmp.py:414]   Expert 15 |    235 | GPU
DEBUG 01-06 17:11:11.630196.630196 lmp.py:414]   Expert  4 |    238 | GPU
DEBUG 01-06 17:11:11.630362.630362 lmp.py:414]   Expert 58 |    244 | GPU
DEBUG 01-06 17:11:11.630813.630813 lmp.py:414]   Expert 26 |    246 | GPU
DEBUG 01-06 17:11:11.630787.630787 lmp.py:414]   Expert 51 |    248 | GPU
DEBUG 01-06 17:11:11.630999.630999 lmp.py:414]   Expert 11 |    258 | GPU
DEBUG 01-06 17:11:11.630450.630450 lmp.py:414]   Expert 44 |    270 | GPU
DEBUG 01-06 17:11:11.630901.630901 lmp.py:414]   Expert 56 |    285 | GPU
DEBUG 01-06 17:11:11.630114.630114 lmp.py:414]   Expert 27 |    288 | GPU
DEBUG 01-06 17:11:11.630565.630565 lmp.py:414]   Expert  1 |    332 | GPU
DEBUG 01-06 17:11:11.630015.630015 lmp.py:414]   Expert 45 |    368 | GPU
DEBUG 01-06 17:11:11.630228.630228 lmp.py:414]   Expert 25 |    479 | GPU
DEBUG 01-06 17:11:11.630679.630679 lmp.py:414]   Expert 35 |    527 | GPU
DEBUG 01-06 17:11:11.630891.630891 lmp.py:414]   Expert 48 |    639 | GPU
DEBUG 01-06 17:11:11.630057.630057 lmp.py:415] 
DEBUG 01-06 17:11:11.630057.630057 lmp.py:415]   CPU total tokens: 3865 (31.5%)
DEBUG 01-06 17:11:11.630700.630700 lmp.py:416]   GPU total tokens: 8423 (68.5%)
DEBUG 01-06 17:11:11.630158.630158 cuda_h.py:19] end experts_map_get cost 0.001485586166381836 seconds
DEBUG 01-06 17:11:11.630755.630755 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-06 17:11:11.630630.630630 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 17:11:11.630198.630198 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 17:11:11.632827.632827 cuda_h.py:19] end allocate_cuda_memory cost 0.0017292499542236328 seconds
DEBUG 01-06 17:11:11.632246.632246 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 17:11:11.632002.632002 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 17:11:11.632295.632295 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 17:11:11.632183.632183 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 2a3e4cf9-d060-457e-a996-b672134d9114
DEBUG 01-06 17:11:11.632885.632885 client.py:106] call stub.LoadModelAsync
INFO 01-06 17:11:11.634123.634123 client.py:127] Model loaded
DEBUG 01-06 17:11:11.635495.635495 cuda_h.py:19] end sllm_worker_task cost 0.01112985610961914 seconds
INFO 01-06 17:11:11.635849.635849 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 2a3e4cf9-d060-457e-a996-b672134d9114
DEBUG 01-06 17:11:11.635646.635646 cuda_h.py:19] end load_into_gpu_async cost 0.0028247833251953125 seconds
DEBUG 01-06 17:11:11.635111.635111 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 17:11:11.635824.635824 cuda_h.py:19] end restore_tensors2 cost 0.00032448768615722656 seconds
DEBUG 01-06 17:11:11.635647.635647 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.005221128463745117 seconds
DEBUG 01-06 17:11:11.638821.638821 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.007885932922363281 seconds
DEBUG 01-06 17:11:11.638227.638227 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-06 17:11:11.638852.638852 lmp.py:461] 
DEBUG 01-06 17:11:11.638852.638852 lmp.py:461]   Computing 32 experts on CPU...
DEBUG 01-06 17:11:11.638026.638026 cuda_h.py:19] end cpu_experts_submit cost 0.00010609626770019531 seconds
DEBUG 01-06 17:11:11.638484.638484 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-06 17:11:11.649580.649580 mlpmodule.py:706] group tensors cost 0.01095128059387207 s
DEBUG 01-06 17:11:11.652326.652326 mlpmodule.py:744] pad cost 0.0016772747039794922 s
DEBUG 01-06 17:11:11.652489.652489 mlpmodule.py:750] create cpu tensor cost 5.1975250244140625e-05 s
DEBUG 01-06 17:11:11.652491.652491 mlpmodule.py:755] move to cpu cost 3.4332275390625e-05 s
DEBUG 01-06 17:11:11.662232.662232 mlpmodule.py:769] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-06 17:11:11.662665.662665 mlpmodule.py:770] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-06 17:11:11.662237.662237 mlpmodule.py:775] group_w3 first element: 0.039306640625
WARNING 01-06 17:11:11.662042.662042 mlpmodule.py:785] start einsum2
DEBUG 01-06 17:11:11.679653.679653 mlpmodule.py:795] group einsum cost 0.02654242515563965 s
DEBUG 01-06 17:11:11.679575.679575 mlpmodule.py:803] cpy2cputensor cost 0.0007083415985107422 s
DEBUG 01-06 17:11:11.684756.684756 cuda_h.py:19] end wait_cetm_experts cost 0.04562735557556152 seconds
DEBUG 01-06 17:11:11.684219.684219 cuda_h.py:10] start gpu_sexperts
DEBUG 01-06 17:11:11.685202.685202 cuda_h.py:19] end gpu_sexperts cost 0.0006067752838134766 seconds
DEBUG 01-06 17:11:11.685727.685727 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-06 17:11:11.685054.685054 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.4318695068359375e-05 seconds
DEBUG 01-06 17:11:11.685187.685187 cuda_h.py:10] start wait_experts
INFO 01-06 17:11:11.685612.685612 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 2a3e4cf9-d060-457e-a996-b672134d9114
INFO 01-06 17:11:11.688946.688946 client.py:127] Model loaded
DEBUG 01-06 17:11:11.688479.688479 cuda_h.py:19] end wait_experts cost 0.0031223297119140625 seconds
DEBUG 01-06 17:11:11.688281.688281 cuda_h.py:10] start gpu_experts
DEBUG 01-06 17:11:11.688514.688514 lmp.py:506]   Computing 32 experts on GPU...
DEBUG 01-06 17:11:11.689896.689896 mlpmodule.py:533] gpu group tensors cost 0.0006475448608398438 s
DEBUG 01-06 17:11:11.691985.691985 mlpmodule.py:566] gpu pad cost 0.0017962455749511719 s
DEBUG 01-06 17:11:11.691027.691027 mlpmodule.py:584] gpu group einsum cost 0.0005824565887451172 s
DEBUG 01-06 17:11:11.692424.692424 mlpmodule.py:664]  experts func einsum cost 0.05317950248718262 s
DEBUG 01-06 17:11:11.695709.695709 mlpmodule.py:613] gpu experts func einsum cost 0.006715297698974609 s
DEBUG 01-06 17:11:11.695369.695369 cuda_h.py:19] end gpu_experts cost 0.0069522857666015625 seconds
DEBUG 01-06 17:11:11.695869.695869 cuda_h.py:19] end layer_moe_generate_20 cost 0.06739544868469238 seconds
DEBUG 01-06 17:11:11.695087.695087 lmp.py:220] -------------------------------- end layer 20 --------------------------------
DEBUG 01-06 17:11:11.695433.695433 lmp.py:176] -------------------------------- start layer 21 --------------------------------
DEBUG 01-06 17:11:11.695388.695388 cuda_h.py:10] start start_load_qkvogn_s_weight_l_22
DEBUG 01-06 17:11:11.695952.695952 cuda_h.py:10] start start_load_qkvogn_s_weight_l_22
DEBUG 01-06 17:11:11.696934.696934 cuda_h.py:19] end start_load_qkvogn_s_weight_l_22 cost 3.218650817871094e-05 seconds
DEBUG 01-06 17:11:11.696942.696942 cuda_h.py:19] end start_load_qkvogn_s_weight_l_22 cost 7.700920104980469e-05 seconds
DEBUG 01-06 17:11:11.696346.696346 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-06 17:11:11.696527.696527 cuda_h.py:10] start sllm_worker_task
DEBUG 01-06 17:11:11.696241.696241 mlpmodule.py:367] cuda:1 cuda:1
DEBUG 01-06 17:11:11.696825.696825 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 17:11:11.696260.696260 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 17:11:11.696751.696751 cuda_h.py:19] end allocate_cuda_memory cost 0.00038123130798339844 seconds
DEBUG 01-06 17:11:11.697854.697854 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 17:11:11.697200.697200 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 17:11:11.697242.697242 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 17:11:11.697482.697482 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, d009f597-9029-4172-bb18-42f553989844
DEBUG 01-06 17:11:11.697631.697631 client.py:106] call stub.LoadModelAsync
DEBUG 01-06 17:11:11.697672.697672 cuda_h.py:10] start self_attn
INFO 01-06 17:11:11.698376.698376 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, d009f597-9029-4172-bb18-42f553989844
DEBUG 01-06 17:11:11.698027.698027 cuda_h.py:19] end load_into_gpu_async cost 0.0017337799072265625 seconds
DEBUG 01-06 17:11:11.698822.698822 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 17:11:11.698687.698687 cuda_h.py:19] end restore_tensors2 cost 7.605552673339844e-05 seconds
DEBUG 01-06 17:11:11.698920.698920 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0025186538696289062 seconds
INFO 01-06 17:11:11.699749.699749 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, d009f597-9029-4172-bb18-42f553989844
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-06 17:11:11.700062.700062 cuda_h.py:19] end self_attn cost 0.0028591156005859375 seconds
DEBUG 01-06 17:11:11.700131.700131 cuda_h.py:19] end iln_self_attn_paln cost 0.004624128341674805 seconds
DEBUG 01-06 17:11:11.700352.700352 cuda_h.py:10] start layer_moe_generate_21
DEBUG 01-06 17:11:11.700307.700307 cuda_h.py:10] start gate
DEBUG 01-06 17:11:11.701906.701906 cuda_h.py:19] end gate cost 0.0006532669067382812 seconds
DEBUG 01-06 17:11:11.701589.701589 cuda_h.py:10] start experts_map_get
DEBUG 01-06 17:11:11.701745.701745 lmp.py:403] 
DEBUG 01-06 17:11:11.701745.701745 lmp.py:403] Expert Token Distribution & Device Allocation:
DEBUG 01-06 17:11:11.701070.701070 lmp.py:404]   Total experts: 64
DEBUG 01-06 17:11:11.701197.701197 lmp.py:405]   CPU experts: 32 (50%)
DEBUG 01-06 17:11:11.701509.701509 lmp.py:406]   GPU experts: 32 (50%)
DEBUG 01-06 17:11:11.701913.701913 lmp.py:407] 
DEBUG 01-06 17:11:11.701913.701913 lmp.py:407]   Expert ID | Tokens | Device
DEBUG 01-06 17:11:11.701318.701318 lmp.py:408]   -----------------------------------
DEBUG 01-06 17:11:11.701445.701445 lmp.py:414]   Expert 44 |     28 | CPU
DEBUG 01-06 17:11:11.701849.701849 lmp.py:414]   Expert  9 |     30 | CPU
DEBUG 01-06 17:11:11.702062.702062 lmp.py:414]   Expert 11 |     30 | CPU
DEBUG 01-06 17:11:11.702512.702512 lmp.py:414]   Expert 56 |     53 | CPU
DEBUG 01-06 17:11:11.702963.702963 lmp.py:414]   Expert 54 |     73 | CPU
DEBUG 01-06 17:11:11.702937.702937 lmp.py:414]   Expert  7 |     82 | CPU
DEBUG 01-06 17:11:11.702150.702150 lmp.py:414]   Expert 62 |     91 | CPU
DEBUG 01-06 17:11:11.702885.702885 lmp.py:414]   Expert 47 |     92 | CPU
DEBUG 01-06 17:11:11.702621.702621 lmp.py:414]   Expert 41 |    102 | CPU
DEBUG 01-06 17:11:11.702357.702357 lmp.py:414]   Expert 60 |    106 | CPU
DEBUG 01-06 17:11:11.702331.702331 lmp.py:414]   Expert 52 |    108 | CPU
DEBUG 01-06 17:11:11.702020.702020 lmp.py:414]   Expert 53 |    111 | CPU
DEBUG 01-06 17:11:11.702948.702948 lmp.py:414]   Expert  8 |    114 | CPU
DEBUG 01-06 17:11:11.702637.702637 lmp.py:414]   Expert 51 |    114 | CPU
DEBUG 01-06 17:11:11.702326.702326 lmp.py:414]   Expert 22 |    122 | CPU
DEBUG 01-06 17:11:11.702300.702300 lmp.py:414]   Expert 32 |    122 | CPU
DEBUG 01-06 17:11:11.702036.702036 lmp.py:414]   Expert  6 |    123 | CPU
DEBUG 01-06 17:11:11.702010.702010 lmp.py:414]   Expert  1 |    131 | CPU
DEBUG 01-06 17:11:11.702746.702746 lmp.py:414]   Expert 48 |    135 | CPU
DEBUG 01-06 17:11:11.702481.702481 lmp.py:414]   Expert 39 |    137 | CPU
DEBUG 01-06 17:11:11.702886.702886 lmp.py:414]   Expert  2 |    138 | CPU
DEBUG 01-06 17:11:11.702575.702575 lmp.py:414]   Expert 27 |    140 | CPU
DEBUG 01-06 17:11:11.702503.702503 lmp.py:414]   Expert 23 |    141 | CPU
DEBUG 01-06 17:11:11.702192.702192 lmp.py:414]   Expert 35 |    141 | CPU
DEBUG 01-06 17:11:11.702882.702882 lmp.py:414]   Expert 59 |    142 | CPU
DEBUG 01-06 17:11:11.702571.702571 lmp.py:414]   Expert 50 |    149 | CPU
DEBUG 01-06 17:11:11.702783.702783 lmp.py:414]   Expert 26 |    155 | CPU
DEBUG 01-06 17:11:11.702665.702665 lmp.py:414]   Expert 14 |    160 | CPU
DEBUG 01-06 17:11:11.702069.702069 lmp.py:414]   Expert 24 |    160 | CPU
DEBUG 01-06 17:11:11.702474.702474 lmp.py:414]   Expert 34 |    166 | CPU
DEBUG 01-06 17:11:11.702878.702878 lmp.py:414]   Expert 38 |    172 | CPU
DEBUG 01-06 17:11:11.702760.702760 lmp.py:414]   Expert 49 |    173 | CPU
DEBUG 01-06 17:11:11.702449.702449 lmp.py:414]   Expert  4 |    175 | GPU
DEBUG 01-06 17:11:11.702377.702377 lmp.py:414]   Expert 46 |    178 | GPU
DEBUG 01-06 17:11:11.702066.702066 lmp.py:414]   Expert  0 |    179 | GPU
DEBUG 01-06 17:11:11.702755.702755 lmp.py:414]   Expert 40 |    182 | GPU
DEBUG 01-06 17:11:11.702206.702206 lmp.py:414]   Expert 63 |    183 | GPU
DEBUG 01-06 17:11:11.702419.702419 lmp.py:414]   Expert  5 |    184 | GPU
DEBUG 01-06 17:11:11.702108.702108 lmp.py:414]   Expert 13 |    192 | GPU
DEBUG 01-06 17:11:11.702797.702797 lmp.py:414]   Expert 19 |    193 | GPU
DEBUG 01-06 17:11:11.702725.702725 lmp.py:414]   Expert 57 |    205 | GPU
DEBUG 01-06 17:11:11.702368.702368 lmp.py:414]   Expert 29 |    208 | GPU
DEBUG 01-06 17:11:11.702773.702773 lmp.py:414]   Expert 43 |    210 | GPU
DEBUG 01-06 17:11:11.702416.702416 lmp.py:414]   Expert 61 |    223 | GPU
DEBUG 01-06 17:11:11.702105.702105 lmp.py:414]   Expert 33 |    224 | GPU
DEBUG 01-06 17:11:11.702317.702317 lmp.py:414]   Expert 31 |    243 | GPU
DEBUG 01-06 17:11:11.702768.702768 lmp.py:414]   Expert  3 |    250 | GPU
DEBUG 01-06 17:11:11.702457.702457 lmp.py:414]   Expert 37 |    252 | GPU
DEBUG 01-06 17:11:11.702908.702908 lmp.py:414]   Expert 20 |    253 | GPU
DEBUG 01-06 17:11:11.702882.702882 lmp.py:414]   Expert 16 |    255 | GPU
DEBUG 01-06 17:11:11.702095.702095 lmp.py:414]   Expert 15 |    257 | GPU
DEBUG 01-06 17:11:11.702784.702784 lmp.py:414]   Expert 12 |    271 | GPU
DEBUG 01-06 17:11:11.702189.702189 lmp.py:414]   Expert 36 |    274 | GPU
DEBUG 01-06 17:11:11.702116.702116 lmp.py:414]   Expert 18 |    279 | GPU
DEBUG 01-06 17:11:11.702521.702521 lmp.py:414]   Expert 28 |    303 | GPU
DEBUG 01-06 17:11:11.702687.702687 lmp.py:414]   Expert 17 |    306 | GPU
DEBUG 01-06 17:11:11.702900.702900 lmp.py:414]   Expert 55 |    312 | GPU
DEBUG 01-06 17:11:11.702589.702589 lmp.py:414]   Expert 25 |    313 | GPU
DEBUG 01-06 17:11:11.702040.702040 lmp.py:414]   Expert 30 |    315 | GPU
DEBUG 01-06 17:11:11.702491.702491 lmp.py:414]   Expert 58 |    343 | GPU
DEBUG 01-06 17:11:11.702465.702465 lmp.py:414]   Expert 10 |    363 | GPU
DEBUG 01-06 17:11:11.702677.702677 lmp.py:414]   Expert 21 |    382 | GPU
DEBUG 01-06 17:11:11.703128.703128 lmp.py:414]   Expert 45 |    386 | GPU
DEBUG 01-06 17:11:11.703102.703102 lmp.py:414]   Expert 42 |    654 | GPU
DEBUG 01-06 17:11:11.703507.703507 lmp.py:415] 
DEBUG 01-06 17:11:11.703507.703507 lmp.py:415]   CPU total tokens: 3741 (30.4%)
DEBUG 01-06 17:11:11.703388.703388 lmp.py:416]   GPU total tokens: 8547 (69.6%)
DEBUG 01-06 17:11:11.703323.703323 cuda_h.py:19] end experts_map_get cost 0.0014963150024414062 seconds
DEBUG 01-06 17:11:11.703681.703681 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-06 17:11:11.703272.703272 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 17:11:11.703654.703654 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 17:11:11.705945.705945 cuda_h.py:19] end allocate_cuda_memory cost 0.0017247200012207031 seconds
DEBUG 01-06 17:11:11.705808.705808 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 17:11:11.705472.705472 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 17:11:11.705042.705042 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 17:11:11.705407.705407 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, d792acbb-1897-4ab5-a38f-db78b1d2850a
DEBUG 01-06 17:11:11.705818.705818 client.py:106] call stub.LoadModelAsync
INFO 01-06 17:11:11.706155.706155 client.py:127] Model loaded
DEBUG 01-06 17:11:11.707718.707718 cuda_h.py:19] end sllm_worker_task cost 0.010849237442016602 seconds
INFO 01-06 17:11:11.708125.708125 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, d792acbb-1897-4ab5-a38f-db78b1d2850a
DEBUG 01-06 17:11:11.708706.708706 cuda_h.py:19] end load_into_gpu_async cost 0.003420591354370117 seconds
DEBUG 01-06 17:11:11.708861.708861 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 17:11:11.709573.709573 cuda_h.py:19] end restore_tensors2 cost 0.00042700767517089844 seconds
DEBUG 01-06 17:11:11.709064.709064 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.006039142608642578 seconds
DEBUG 01-06 17:11:11.711211.711211 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.008685827255249023 seconds
DEBUG 01-06 17:11:11.711756.711756 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-06 17:11:11.711096.711096 lmp.py:461] 
DEBUG 01-06 17:11:11.711096.711096 lmp.py:461]   Computing 32 experts on CPU...
DEBUG 01-06 17:11:11.712906.712906 cuda_h.py:19] end cpu_experts_submit cost 0.00011086463928222656 seconds
DEBUG 01-06 17:11:11.712510.712510 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-06 17:11:11.724933.724933 mlpmodule.py:706] group tensors cost 0.011809349060058594 s
DEBUG 01-06 17:11:11.726378.726378 mlpmodule.py:744] pad cost 0.0016205310821533203 s
DEBUG 01-06 17:11:11.726449.726449 mlpmodule.py:750] create cpu tensor cost 6.103515625e-05 s
DEBUG 01-06 17:11:11.726863.726863 mlpmodule.py:755] move to cpu cost 4.887580871582031e-05 s
DEBUG 01-06 17:11:11.736077.736077 mlpmodule.py:769] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-06 17:11:11.736265.736265 mlpmodule.py:770] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-06 17:11:11.736261.736261 mlpmodule.py:775] group_w3 first element: 0.00066375732421875
WARNING 01-06 17:11:11.736986.736986 mlpmodule.py:785] start einsum2
DEBUG 01-06 17:11:11.753556.753556 mlpmodule.py:795] group einsum cost 0.02659130096435547 s
DEBUG 01-06 17:11:11.754992.754992 mlpmodule.py:803] cpy2cputensor cost 0.000690460205078125 s
DEBUG 01-06 17:11:11.758322.758322 cuda_h.py:19] end wait_cetm_experts cost 0.04633927345275879 seconds
DEBUG 01-06 17:11:11.758157.758157 cuda_h.py:10] start gpu_sexperts
DEBUG 01-06 17:11:11.759556.759556 cuda_h.py:19] end gpu_sexperts cost 0.0006015300750732422 seconds
DEBUG 01-06 17:11:11.759459.759459 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-06 17:11:11.759309.759309 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.5272369384765625e-05 seconds
DEBUG 01-06 17:11:11.759011.759011 cuda_h.py:10] start wait_experts
INFO 01-06 17:11:11.759244.759244 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, d792acbb-1897-4ab5-a38f-db78b1d2850a
INFO 01-06 17:11:11.761284.761284 client.py:127] Model loaded
DEBUG 01-06 17:11:11.761565.761565 cuda_h.py:19] end wait_experts cost 0.0018515586853027344 seconds
DEBUG 01-06 17:11:11.761797.761797 cuda_h.py:10] start gpu_experts
DEBUG 01-06 17:11:11.761461.761461 lmp.py:506]   Computing 32 experts on GPU...
DEBUG 01-06 17:11:11.762421.762421 mlpmodule.py:533] gpu group tensors cost 0.0006859302520751953 s
DEBUG 01-06 17:11:11.764655.764655 mlpmodule.py:566] gpu pad cost 0.0018024444580078125 s
DEBUG 01-06 17:11:11.764698.764698 mlpmodule.py:584] gpu group einsum cost 0.0006189346313476562 s
DEBUG 01-06 17:11:11.765930.765930 mlpmodule.py:664]  experts func einsum cost 0.05348372459411621 s
DEBUG 01-06 17:11:11.768603.768603 mlpmodule.py:613] gpu experts func einsum cost 0.006916999816894531 s
DEBUG 01-06 17:11:11.768462.768462 cuda_h.py:19] end gpu_experts cost 0.007166385650634766 seconds
DEBUG 01-06 17:11:11.768114.768114 cuda_h.py:19] end layer_moe_generate_21 cost 0.067840576171875 seconds
DEBUG 01-06 17:11:11.768705.768705 lmp.py:220] -------------------------------- end layer 21 --------------------------------
DEBUG 01-06 17:11:11.768428.768428 lmp.py:176] -------------------------------- start layer 22 --------------------------------
DEBUG 01-06 17:11:11.768939.768939 cuda_h.py:10] start start_load_qkvogn_s_weight_l_23
DEBUG 01-06 17:11:11.768894.768894 cuda_h.py:10] start start_load_qkvogn_s_weight_l_23
DEBUG 01-06 17:11:11.769637.769637 cuda_h.py:19] end start_load_qkvogn_s_weight_l_23 cost 3.0517578125e-05 seconds
DEBUG 01-06 17:11:11.769340.769340 cuda_h.py:19] end start_load_qkvogn_s_weight_l_23 cost 6.008148193359375e-05 seconds
DEBUG 01-06 17:11:11.769129.769129 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-06 17:11:11.769879.769879 cuda_h.py:10] start sllm_worker_task
DEBUG 01-06 17:11:11.769903.769903 mlpmodule.py:367] cuda:1 cuda:1
DEBUG 01-06 17:11:11.769342.769342 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 17:11:11.769160.769160 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 17:11:11.769385.769385 cuda_h.py:19] end allocate_cuda_memory cost 0.00033783912658691406 seconds
DEBUG 01-06 17:11:11.769500.769500 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 17:11:11.769648.769648 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 17:11:11.770663.770663 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 17:11:11.770412.770412 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, f730510c-88d6-43bd-b00d-c2f8cb464238
DEBUG 01-06 17:11:11.770812.770812 client.py:106] call stub.LoadModelAsync
DEBUG 01-06 17:11:11.770967.770967 cuda_h.py:10] start self_attn
INFO 01-06 17:11:11.771778.771778 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, f730510c-88d6-43bd-b00d-c2f8cb464238
DEBUG 01-06 17:11:11.771952.771952 cuda_h.py:19] end load_into_gpu_async cost 0.001589059829711914 seconds
DEBUG 01-06 17:11:11.771986.771986 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 17:11:11.771029.771029 cuda_h.py:19] end restore_tensors2 cost 7.605552673339844e-05 seconds
DEBUG 01-06 17:11:11.771262.771262 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0022726058959960938 seconds
INFO 01-06 17:11:11.771760.771760 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, f730510c-88d6-43bd-b00d-c2f8cb464238
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-06 17:11:11.773892.773892 cuda_h.py:19] end self_attn cost 0.0028650760650634766 seconds
DEBUG 01-06 17:11:11.773485.773485 cuda_h.py:19] end iln_self_attn_paln cost 0.0044820308685302734 seconds
DEBUG 01-06 17:11:11.773911.773911 cuda_h.py:10] start layer_moe_generate_22
DEBUG 01-06 17:11:11.773125.773125 cuda_h.py:10] start gate
DEBUG 01-06 17:11:11.774810.774810 cuda_h.py:19] end gate cost 0.0006465911865234375 seconds
DEBUG 01-06 17:11:11.774447.774447 cuda_h.py:10] start experts_map_get
DEBUG 01-06 17:11:11.774610.774610 lmp.py:403] 
DEBUG 01-06 17:11:11.774610.774610 lmp.py:403] Expert Token Distribution & Device Allocation:
DEBUG 01-06 17:11:11.774889.774889 lmp.py:404]   Total experts: 64
DEBUG 01-06 17:11:11.774585.774585 lmp.py:405]   CPU experts: 32 (50%)
DEBUG 01-06 17:11:11.774420.774420 lmp.py:406]   GPU experts: 32 (50%)
DEBUG 01-06 17:11:11.774632.774632 lmp.py:407] 
DEBUG 01-06 17:11:11.774632.774632 lmp.py:407]   Expert ID | Tokens | Device
DEBUG 01-06 17:11:11.774322.774322 lmp.py:408]   -----------------------------------
DEBUG 01-06 17:11:11.774448.774448 lmp.py:414]   Expert 25 |     14 | CPU
DEBUG 01-06 17:11:11.774376.774376 lmp.py:414]   Expert 48 |     32 | CPU
DEBUG 01-06 17:11:11.774350.774350 lmp.py:414]   Expert 45 |     35 | CPU
DEBUG 01-06 17:11:11.774755.774755 lmp.py:414]   Expert  9 |     58 | CPU
DEBUG 01-06 17:11:11.774682.774682 lmp.py:414]   Expert  0 |     79 | CPU
DEBUG 01-06 17:11:11.774133.774133 lmp.py:414]   Expert 43 |     79 | CPU
DEBUG 01-06 17:11:11.774299.774299 lmp.py:414]   Expert 54 |     80 | CPU
DEBUG 01-06 17:11:11.774512.774512 lmp.py:414]   Expert 20 |     84 | CPU
DEBUG 01-06 17:11:11.775486.775486 lmp.py:414]   Expert 57 |     88 | CPU
DEBUG 01-06 17:11:11.775745.775745 lmp.py:414]   Expert  6 |     89 | CPU
DEBUG 01-06 17:11:11.775149.775149 lmp.py:414]   Expert 47 |     91 | CPU
DEBUG 01-06 17:11:11.775838.775838 lmp.py:414]   Expert 36 |    100 | CPU
DEBUG 01-06 17:11:11.775528.775528 lmp.py:414]   Expert 61 |    100 | CPU
DEBUG 01-06 17:11:11.775217.775217 lmp.py:414]   Expert 13 |    101 | CPU
DEBUG 01-06 17:11:11.775145.775145 lmp.py:414]   Expert  1 |    102 | CPU
DEBUG 01-06 17:11:11.775119.775119 lmp.py:414]   Expert 15 |    108 | CPU
DEBUG 01-06 17:11:11.775762.775762 lmp.py:414]   Expert 46 |    110 | CPU
DEBUG 01-06 17:11:11.775166.775166 lmp.py:414]   Expert 50 |    112 | CPU
DEBUG 01-06 17:11:11.775333.775333 lmp.py:414]   Expert 37 |    113 | CPU
DEBUG 01-06 17:11:11.775499.775499 lmp.py:414]   Expert 62 |    113 | CPU
DEBUG 01-06 17:11:11.775950.775950 lmp.py:414]   Expert 38 |    115 | CPU
DEBUG 01-06 17:11:11.775639.775639 lmp.py:414]   Expert 14 |    127 | CPU
DEBUG 01-06 17:11:11.775328.775328 lmp.py:414]   Expert 44 |    134 | CPU
DEBUG 01-06 17:11:11.775541.775541 lmp.py:414]   Expert  7 |    140 | CPU
DEBUG 01-06 17:11:11.775991.775991 lmp.py:414]   Expert 28 |    144 | CPU
DEBUG 01-06 17:11:11.775442.775442 lmp.py:414]   Expert 21 |    145 | CPU
DEBUG 01-06 17:11:11.775893.775893 lmp.py:414]   Expert 52 |    146 | CPU
DEBUG 01-06 17:11:11.775344.775344 lmp.py:414]   Expert 10 |    148 | CPU
DEBUG 01-06 17:11:11.775749.775749 lmp.py:414]   Expert 11 |    154 | CPU
DEBUG 01-06 17:11:11.775153.775153 lmp.py:414]   Expert 24 |    154 | CPU
DEBUG 01-06 17:11:11.775319.775319 lmp.py:414]   Expert 42 |    159 | CPU
DEBUG 01-06 17:11:11.775486.775486 lmp.py:414]   Expert 26 |    163 | CPU
DEBUG 01-06 17:11:11.775128.775128 lmp.py:414]   Expert  2 |    164 | GPU
DEBUG 01-06 17:11:11.775056.775056 lmp.py:414]   Expert 35 |    171 | GPU
DEBUG 01-06 17:11:11.775984.775984 lmp.py:414]   Expert  3 |    177 | GPU
DEBUG 01-06 17:11:11.775673.775673 lmp.py:414]   Expert 31 |    178 | GPU
DEBUG 01-06 17:11:11.775124.775124 lmp.py:414]   Expert 32 |    183 | GPU
DEBUG 01-06 17:11:11.775337.775337 lmp.py:414]   Expert 19 |    184 | GPU
DEBUG 01-06 17:11:11.775026.775026 lmp.py:414]   Expert 12 |    188 | GPU
DEBUG 01-06 17:11:11.775715.775715 lmp.py:414]   Expert 60 |    206 | GPU
DEBUG 01-06 17:11:11.775689.775689 lmp.py:414]   Expert 40 |    209 | GPU
DEBUG 01-06 17:11:11.775332.775332 lmp.py:414]   Expert 56 |    211 | GPU
DEBUG 01-06 17:11:11.775022.775022 lmp.py:414]   Expert 41 |    212 | GPU
DEBUG 01-06 17:11:11.775949.775949 lmp.py:414]   Expert 53 |    224 | GPU
DEBUG 01-06 17:11:11.775877.775877 lmp.py:414]   Expert 58 |    226 | GPU
DEBUG 01-06 17:11:11.775043.775043 lmp.py:414]   Expert 16 |    232 | GPU
DEBUG 01-06 17:11:11.775494.775494 lmp.py:414]   Expert 23 |    238 | GPU
DEBUG 01-06 17:11:11.775706.775706 lmp.py:414]   Expert 51 |    241 | GPU
DEBUG 01-06 17:11:11.775157.775157 lmp.py:414]   Expert  8 |    247 | GPU
DEBUG 01-06 17:11:11.775608.775608 lmp.py:414]   Expert 59 |    252 | GPU
DEBUG 01-06 17:11:11.775059.775059 lmp.py:414]   Expert  4 |    253 | GPU
DEBUG 01-06 17:11:11.775272.775272 lmp.py:414]   Expert 55 |    271 | GPU
DEBUG 01-06 17:11:11.775722.775722 lmp.py:414]   Expert 18 |    281 | GPU
DEBUG 01-06 17:11:11.775173.775173 lmp.py:414]   Expert 29 |    283 | GPU
DEBUG 01-06 17:11:11.775339.775339 lmp.py:414]   Expert 49 |    284 | GPU
DEBUG 01-06 17:11:11.775267.775267 lmp.py:414]   Expert 34 |    292 | GPU
DEBUG 01-06 17:11:11.775956.775956 lmp.py:414]   Expert 63 |    299 | GPU
DEBUG 01-06 17:11:11.775884.775884 lmp.py:414]   Expert 27 |    348 | GPU
DEBUG 01-06 17:11:11.775289.775289 lmp.py:414]   Expert 39 |    375 | GPU
DEBUG 01-06 17:11:11.775740.775740 lmp.py:414]   Expert 17 |    392 | GPU
DEBUG 01-06 17:11:11.775190.775190 lmp.py:414]   Expert 22 |    429 | GPU
DEBUG 01-06 17:11:11.775880.775880 lmp.py:414]   Expert 30 |    442 | GPU
DEBUG 01-06 17:11:11.775854.775854 lmp.py:414]   Expert 33 |    461 | GPU
DEBUG 01-06 17:11:11.775828.775828 lmp.py:414]   Expert  5 |    718 | GPU
DEBUG 01-06 17:11:11.775994.775994 lmp.py:415] 
DEBUG 01-06 17:11:11.775994.775994 lmp.py:415]   CPU total tokens: 3417 (27.8%)
DEBUG 01-06 17:11:11.775352.775352 lmp.py:416]   GPU total tokens: 8871 (72.2%)
DEBUG 01-06 17:11:11.775287.775287 cuda_h.py:19] end experts_map_get cost 0.0015048980712890625 seconds
DEBUG 01-06 17:11:11.776883.776883 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-06 17:11:11.776190.776190 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 17:11:11.776141.776141 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 17:11:11.777461.777461 cuda_h.py:19] end allocate_cuda_memory cost 0.0016074180603027344 seconds
DEBUG 01-06 17:11:11.777550.777550 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 17:11:11.777590.777590 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 17:11:11.777638.777638 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 17:11:11.777241.777241 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, f16c3070-a53a-4491-aa0e-9c031e553205
DEBUG 01-06 17:11:11.778202.778202 client.py:106] call stub.LoadModelAsync
INFO 01-06 17:11:11.779890.779890 client.py:127] Model loaded
DEBUG 01-06 17:11:11.779049.779049 cuda_h.py:19] end sllm_worker_task cost 0.010640382766723633 seconds
INFO 01-06 17:11:11.781463.781463 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, f16c3070-a53a-4491-aa0e-9c031e553205
DEBUG 01-06 17:11:11.781620.781620 cuda_h.py:19] end load_into_gpu_async cost 0.0034437179565429688 seconds
DEBUG 01-06 17:11:11.781298.781298 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 17:11:11.782407.782407 cuda_h.py:19] end restore_tensors2 cost 0.0006086826324462891 seconds
DEBUG 01-06 17:11:11.782701.782701 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.006144046783447266 seconds
DEBUG 01-06 17:11:11.786323.786323 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.010718345642089844 seconds
DEBUG 01-06 17:11:11.786332.786332 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-06 17:11:11.786111.786111 lmp.py:461] 
DEBUG 01-06 17:11:11.786111.786111 lmp.py:461]   Computing 32 experts on CPU...
DEBUG 01-06 17:11:11.787432.787432 cuda_h.py:19] end cpu_experts_submit cost 0.00016570091247558594 seconds
DEBUG 01-06 17:11:11.787486.787486 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-06 17:11:11.798761.798761 mlpmodule.py:706] group tensors cost 0.011350870132446289 s
DEBUG 01-06 17:11:11.801016.801016 mlpmodule.py:744] pad cost 0.0024366378784179688 s
DEBUG 01-06 17:11:11.802000.802000 mlpmodule.py:750] create cpu tensor cost 4.601478576660156e-05 s
DEBUG 01-06 17:11:11.802473.802473 mlpmodule.py:755] move to cpu cost 3.1948089599609375e-05 s
DEBUG 01-06 17:11:11.812013.812013 mlpmodule.py:769] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-06 17:11:11.812823.812823 mlpmodule.py:770] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-06 17:11:11.812549.812549 mlpmodule.py:775] group_w3 first element: -0.018798828125
WARNING 01-06 17:11:11.812499.812499 mlpmodule.py:785] start einsum2
DEBUG 01-06 17:11:11.829656.829656 mlpmodule.py:795] group einsum cost 0.027364492416381836 s
DEBUG 01-06 17:11:11.830854.830854 mlpmodule.py:803] cpy2cputensor cost 0.0006711483001708984 s
DEBUG 01-06 17:11:11.834014.834014 cuda_h.py:19] end wait_cetm_experts cost 0.047516584396362305 seconds
DEBUG 01-06 17:11:11.834080.834080 cuda_h.py:10] start gpu_sexperts
DEBUG 01-06 17:11:11.835824.835824 cuda_h.py:19] end gpu_sexperts cost 0.0006082057952880859 seconds
DEBUG 01-06 17:11:11.835965.835965 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-06 17:11:11.835769.835769 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.4557113647460938e-05 seconds
DEBUG 01-06 17:11:11.835472.835472 cuda_h.py:10] start wait_experts
INFO 01-06 17:11:11.835751.835751 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, f16c3070-a53a-4491-aa0e-9c031e553205
INFO 01-06 17:11:11.837737.837737 client.py:127] Model loaded
DEBUG 01-06 17:11:11.837726.837726 cuda_h.py:19] end wait_experts cost 0.001420736312866211 seconds
DEBUG 01-06 17:11:11.837098.837098 cuda_h.py:10] start gpu_experts
DEBUG 01-06 17:11:11.837092.837092 lmp.py:506]   Computing 32 experts on GPU...
DEBUG 01-06 17:11:11.837514.837514 mlpmodule.py:533] gpu group tensors cost 0.0006444454193115234 s
DEBUG 01-06 17:11:11.839397.839397 mlpmodule.py:566] gpu pad cost 0.0017886161804199219 s
DEBUG 01-06 17:11:11.840664.840664 mlpmodule.py:584] gpu group einsum cost 0.0005714893341064453 s
DEBUG 01-06 17:11:11.841210.841210 mlpmodule.py:664]  experts func einsum cost 0.05465412139892578 s
DEBUG 01-06 17:11:11.844165.844165 mlpmodule.py:613] gpu experts func einsum cost 0.006836652755737305 s
DEBUG 01-06 17:11:11.844647.844647 cuda_h.py:19] end gpu_experts cost 0.007082223892211914 seconds
DEBUG 01-06 17:11:11.844810.844810 cuda_h.py:19] end layer_moe_generate_22 cost 0.07067012786865234 seconds
DEBUG 01-06 17:11:11.844268.844268 lmp.py:220] -------------------------------- end layer 22 --------------------------------
DEBUG 01-06 17:11:11.844230.844230 lmp.py:176] -------------------------------- start layer 23 --------------------------------
DEBUG 01-06 17:11:11.844217.844217 cuda_h.py:10] start start_load_qkvogn_s_weight_l_24
DEBUG 01-06 17:11:11.844934.844934 cuda_h.py:10] start start_load_qkvogn_s_weight_l_24
DEBUG 01-06 17:11:11.844883.844883 cuda_h.py:19] end start_load_qkvogn_s_weight_l_24 cost 3.790855407714844e-05 seconds
DEBUG 01-06 17:11:11.844924.844924 cuda_h.py:19] end start_load_qkvogn_s_weight_l_24 cost 7.104873657226562e-05 seconds
DEBUG 01-06 17:11:11.844050.844050 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-06 17:11:11.844636.844636 mlpmodule.py:367] cuda:1 cuda:1
DEBUG 01-06 17:11:11.845817.845817 cuda_h.py:10] start sllm_worker_task
DEBUG 01-06 17:11:11.845702.845702 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 17:11:11.845392.845392 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 17:11:11.845173.845173 cuda_h.py:19] end allocate_cuda_memory cost 0.0003287792205810547 seconds
DEBUG 01-06 17:11:11.845672.845672 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 17:11:11.845296.845296 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 17:11:11.845834.845834 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 17:11:11.845345.845345 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, adbcc3eb-c791-4a4b-a096-b75f4368e238
DEBUG 01-06 17:11:11.845507.845507 client.py:106] call stub.LoadModelAsync
DEBUG 01-06 17:11:11.846139.846139 cuda_h.py:10] start self_attn
INFO 01-06 17:11:11.847307.847307 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, adbcc3eb-c791-4a4b-a096-b75f4368e238
DEBUG 01-06 17:11:11.847720.847720 cuda_h.py:19] end load_into_gpu_async cost 0.001577138900756836 seconds
DEBUG 01-06 17:11:11.847992.847992 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 17:11:11.847704.847704 cuda_h.py:19] end restore_tensors2 cost 7.772445678710938e-05 seconds
DEBUG 01-06 17:11:11.847507.847507 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0022461414337158203 seconds
INFO 01-06 17:11:11.847343.847343 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, adbcc3eb-c791-4a4b-a096-b75f4368e238
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-06 17:11:11.849058.849058 cuda_h.py:19] end self_attn cost 0.0028569698333740234 seconds
DEBUG 01-06 17:11:11.849419.849419 cuda_h.py:19] end iln_self_attn_paln cost 0.0044515132904052734 seconds
DEBUG 01-06 17:11:11.849070.849070 cuda_h.py:10] start layer_moe_generate_23
DEBUG 01-06 17:11:11.849502.849502 cuda_h.py:10] start gate
DEBUG 01-06 17:11:11.850233.850233 cuda_h.py:19] end gate cost 0.0006451606750488281 seconds
DEBUG 01-06 17:11:11.850540.850540 cuda_h.py:10] start experts_map_get
DEBUG 01-06 17:11:11.850516.850516 lmp.py:403] 
DEBUG 01-06 17:11:11.850516.850516 lmp.py:403] Expert Token Distribution & Device Allocation:
DEBUG 01-06 17:11:11.850319.850319 lmp.py:404]   Total experts: 64
DEBUG 01-06 17:11:11.850730.850730 lmp.py:405]   CPU experts: 32 (50%)
DEBUG 01-06 17:11:11.850042.850042 lmp.py:406]   GPU experts: 32 (50%)
DEBUG 01-06 17:11:11.850685.850685 lmp.py:407] 
DEBUG 01-06 17:11:11.850685.850685 lmp.py:407]   Expert ID | Tokens | Device
DEBUG 01-06 17:11:11.850090.850090 lmp.py:408]   -----------------------------------
DEBUG 01-06 17:11:11.850931.850931 lmp.py:414]   Expert  5 |     12 | CPU
DEBUG 01-06 17:11:11.850574.850574 lmp.py:414]   Expert 56 |     34 | CPU
DEBUG 01-06 17:11:11.850310.850310 lmp.py:414]   Expert 27 |     77 | CPU
DEBUG 01-06 17:11:11.850046.850046 lmp.py:414]   Expert 16 |     81 | CPU
DEBUG 01-06 17:11:11.850020.850020 lmp.py:414]   Expert 17 |     88 | CPU
DEBUG 01-06 17:11:11.850994.850994 lmp.py:414]   Expert 40 |     95 | CPU
DEBUG 01-06 17:11:11.850206.850206 lmp.py:414]   Expert 51 |    101 | CPU
DEBUG 01-06 17:11:11.850180.850180 lmp.py:414]   Expert 53 |    101 | CPU
DEBUG 01-06 17:11:11.850916.850916 lmp.py:414]   Expert 63 |    103 | CPU
DEBUG 01-06 17:11:11.850890.850890 lmp.py:414]   Expert  7 |    104 | CPU
DEBUG 01-06 17:11:11.850487.850487 lmp.py:414]   Expert 49 |    106 | CPU
DEBUG 01-06 17:11:11.850653.850653 lmp.py:414]   Expert 28 |    115 | CPU
DEBUG 01-06 17:11:11.850011.850011 lmp.py:414]   Expert 38 |    117 | CPU
DEBUG 01-06 17:11:11.850415.850415 lmp.py:414]   Expert 11 |    121 | CPU
DEBUG 01-06 17:11:11.850058.850058 lmp.py:414]   Expert 58 |    123 | CPU
DEBUG 01-06 17:11:11.850701.850701 lmp.py:414]   Expert 37 |    125 | CPU
DEBUG 01-06 17:11:11.850060.850060 lmp.py:414]   Expert 62 |    126 | CPU
DEBUG 01-06 17:11:11.850226.850226 lmp.py:414]   Expert 47 |    138 | CPU
DEBUG 01-06 17:11:11.850154.850154 lmp.py:414]   Expert 39 |    143 | CPU
DEBUG 01-06 17:11:11.850081.850081 lmp.py:414]   Expert 57 |    143 | CPU
DEBUG 01-06 17:11:11.850771.850771 lmp.py:414]   Expert  1 |    147 | CPU
DEBUG 01-06 17:11:11.850460.850460 lmp.py:414]   Expert 52 |    151 | CPU
DEBUG 01-06 17:11:11.850388.850388 lmp.py:414]   Expert 14 |    153 | CPU
DEBUG 01-06 17:11:11.851077.851077 lmp.py:414]   Expert 25 |    159 | CPU
DEBUG 01-06 17:11:11.851958.851958 lmp.py:414]   Expert 33 |    161 | CPU
DEBUG 01-06 17:11:11.851363.851363 lmp.py:414]   Expert 23 |    164 | CPU
DEBUG 01-06 17:11:11.851291.851291 lmp.py:414]   Expert  6 |    166 | CPU
DEBUG 01-06 17:11:11.851934.851934 lmp.py:414]   Expert 21 |    173 | CPU
DEBUG 01-06 17:11:11.851576.851576 lmp.py:414]   Expert 60 |    177 | CPU
DEBUG 01-06 17:11:11.851027.851027 lmp.py:414]   Expert  4 |    178 | CPU
DEBUG 01-06 17:11:11.851955.851955 lmp.py:414]   Expert 45 |    178 | CPU
DEBUG 01-06 17:11:11.851883.851883 lmp.py:414]   Expert 44 |    179 | CPU
DEBUG 01-06 17:11:11.851811.851811 lmp.py:414]   Expert 19 |    182 | GPU
DEBUG 01-06 17:11:11.851500.851500 lmp.py:414]   Expert 30 |    184 | GPU
DEBUG 01-06 17:11:11.851189.851189 lmp.py:414]   Expert  3 |    190 | GPU
DEBUG 01-06 17:11:11.851640.851640 lmp.py:414]   Expert 31 |    198 | GPU
DEBUG 01-06 17:11:11.851568.851568 lmp.py:414]   Expert 36 |    199 | GPU
DEBUG 01-06 17:11:11.851449.851449 lmp.py:414]   Expert 55 |    201 | GPU
DEBUG 01-06 17:11:11.851854.851854 lmp.py:414]   Expert 12 |    202 | GPU
DEBUG 01-06 17:11:11.851258.851258 lmp.py:414]   Expert  9 |    210 | GPU
DEBUG 01-06 17:11:11.851424.851424 lmp.py:414]   Expert 41 |    217 | GPU
DEBUG 01-06 17:11:11.851544.851544 lmp.py:414]   Expert 22 |    222 | GPU
DEBUG 01-06 17:11:11.851233.851233 lmp.py:414]   Expert  0 |    223 | GPU
DEBUG 01-06 17:11:11.851161.851161 lmp.py:414]   Expert 34 |    226 | GPU
DEBUG 01-06 17:11:11.851089.851089 lmp.py:414]   Expert 43 |    235 | GPU
DEBUG 01-06 17:11:11.851778.851778 lmp.py:414]   Expert 54 |    240 | GPU
DEBUG 01-06 17:11:11.851468.851468 lmp.py:414]   Expert 26 |    242 | GPU
DEBUG 01-06 17:11:11.851680.851680 lmp.py:414]   Expert 59 |    253 | GPU
DEBUG 01-06 17:11:11.851369.851369 lmp.py:414]   Expert 18 |    255 | GPU
DEBUG 01-06 17:11:11.851535.851535 lmp.py:414]   Expert 50 |    255 | GPU
DEBUG 01-06 17:11:11.851940.851940 lmp.py:414]   Expert 20 |    256 | GPU
DEBUG 01-06 17:11:11.851345.851345 lmp.py:414]   Expert 13 |    258 | GPU
DEBUG 01-06 17:11:11.851511.851511 lmp.py:414]   Expert 61 |    258 | GPU
DEBUG 01-06 17:11:11.851677.851677 lmp.py:414]   Expert 15 |    261 | GPU
DEBUG 01-06 17:11:11.851605.851605 lmp.py:414]   Expert 24 |    262 | GPU
DEBUG 01-06 17:11:11.851294.851294 lmp.py:414]   Expert 42 |    272 | GPU
DEBUG 01-06 17:11:11.851506.851506 lmp.py:414]   Expert 29 |    274 | GPU
DEBUG 01-06 17:11:11.851434.851434 lmp.py:414]   Expert 35 |    275 | GPU
DEBUG 01-06 17:11:11.851123.851123 lmp.py:414]   Expert 32 |    285 | GPU
DEBUG 01-06 17:11:11.851813.851813 lmp.py:414]   Expert  2 |    321 | GPU
DEBUG 01-06 17:11:11.851502.851502 lmp.py:414]   Expert  8 |    345 | GPU
DEBUG 01-06 17:11:11.851383.851383 lmp.py:414]   Expert 10 |    365 | GPU
DEBUG 01-06 17:11:11.851788.851788 lmp.py:414]   Expert 46 |    428 | GPU
DEBUG 01-06 17:11:11.851192.851192 lmp.py:414]   Expert 48 |    455 | GPU
DEBUG 01-06 17:11:11.851551.851551 lmp.py:415] 
DEBUG 01-06 17:11:11.851551.851551 lmp.py:415]   CPU total tokens: 4039 (32.9%)
DEBUG 01-06 17:11:11.851624.851624 lmp.py:416]   GPU total tokens: 8249 (67.1%)
DEBUG 01-06 17:11:11.851559.851559 cuda_h.py:19] end experts_map_get cost 0.0015308856964111328 seconds
DEBUG 01-06 17:11:11.851440.851440 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-06 17:11:11.851031.851031 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 17:11:11.851798.851798 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 17:11:11.853612.853612 cuda_h.py:19] end allocate_cuda_memory cost 0.0015494823455810547 seconds
DEBUG 01-06 17:11:11.853734.853734 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 17:11:11.853444.853444 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 17:11:11.853160.853160 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 17:11:11.853764.853764 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 3624c2ec-5fc9-48bf-a492-3ee606bc63e3
DEBUG 01-06 17:11:11.853440.853440 client.py:106] call stub.LoadModelAsync
INFO 01-06 17:11:11.855017.855017 client.py:127] Model loaded
DEBUG 01-06 17:11:11.855486.855486 cuda_h.py:19] end sllm_worker_task cost 0.010379552841186523 seconds
INFO 01-06 17:11:11.856706.856706 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 3624c2ec-5fc9-48bf-a492-3ee606bc63e3
DEBUG 01-06 17:11:11.856086.856086 cuda_h.py:19] end load_into_gpu_async cost 0.002752542495727539 seconds
DEBUG 01-06 17:11:11.856080.856080 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 17:11:11.856365.856365 cuda_h.py:19] end restore_tensors2 cost 0.0003578662872314453 seconds
DEBUG 01-06 17:11:11.856141.856141 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.00504302978515625 seconds
DEBUG 01-06 17:11:11.859170.859170 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.007744789123535156 seconds
DEBUG 01-06 17:11:11.859285.859285 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-06 17:11:11.859387.859387 lmp.py:461] 
DEBUG 01-06 17:11:11.859387.859387 lmp.py:461]   Computing 32 experts on CPU...
DEBUG 01-06 17:11:11.859899.859899 cuda_h.py:19] end cpu_experts_submit cost 0.0001087188720703125 seconds
DEBUG 01-06 17:11:11.859264.859264 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-06 17:11:11.872895.872895 mlpmodule.py:706] group tensors cost 0.012484312057495117 s
DEBUG 01-06 17:11:11.874649.874649 mlpmodule.py:744] pad cost 0.0016300678253173828 s
DEBUG 01-06 17:11:11.874321.874321 mlpmodule.py:750] create cpu tensor cost 4.863739013671875e-05 s
DEBUG 01-06 17:11:11.874363.874363 mlpmodule.py:755] move to cpu cost 3.2901763916015625e-05 s
DEBUG 01-06 17:11:11.886146.886146 mlpmodule.py:769] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-06 17:11:11.886095.886095 mlpmodule.py:770] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-06 17:11:11.886852.886852 mlpmodule.py:775] group_w3 first element: 0.08447265625
WARNING 01-06 17:11:11.886034.886034 mlpmodule.py:785] start einsum2
DEBUG 01-06 17:11:11.903382.903382 mlpmodule.py:795] group einsum cost 0.028583049774169922 s
DEBUG 01-06 17:11:11.904900.904900 mlpmodule.py:803] cpy2cputensor cost 0.0007398128509521484 s
DEBUG 01-06 17:11:11.908002.908002 cuda_h.py:19] end wait_cetm_experts cost 0.049056053161621094 seconds
DEBUG 01-06 17:11:11.909836.909836 cuda_h.py:10] start gpu_sexperts
DEBUG 01-06 17:11:11.909686.909686 cuda_h.py:19] end gpu_sexperts cost 0.0006177425384521484 seconds
DEBUG 01-06 17:11:11.909158.909158 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-06 17:11:11.909154.909154 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.574920654296875e-05 seconds
DEBUG 01-06 17:11:11.909095.909095 cuda_h.py:10] start wait_experts
INFO 01-06 17:11:11.909951.909951 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 3624c2ec-5fc9-48bf-a492-3ee606bc63e3
INFO 01-06 17:11:11.911128.911128 client.py:127] Model loaded
DEBUG 01-06 17:11:11.911924.911924 cuda_h.py:19] end wait_experts cost 0.0013875961303710938 seconds
DEBUG 01-06 17:11:11.911581.911581 cuda_h.py:10] start gpu_experts
DEBUG 01-06 17:11:11.911668.911668 lmp.py:506]   Computing 32 experts on GPU...
DEBUG 01-06 17:11:11.912541.912541 mlpmodule.py:533] gpu group tensors cost 0.0006592273712158203 s
DEBUG 01-06 17:11:11.914061.914061 mlpmodule.py:566] gpu pad cost 0.0018367767333984375 s
DEBUG 01-06 17:11:11.914903.914903 mlpmodule.py:584] gpu group einsum cost 0.0005354881286621094 s
DEBUG 01-06 17:11:11.915416.915416 mlpmodule.py:664]  experts func einsum cost 0.05599021911621094 s
DEBUG 01-06 17:11:11.918294.918294 mlpmodule.py:613] gpu experts func einsum cost 0.006923675537109375 s
DEBUG 01-06 17:11:11.918643.918643 cuda_h.py:19] end gpu_experts cost 0.007180213928222656 seconds
DEBUG 01-06 17:11:11.918103.918103 cuda_h.py:19] end layer_moe_generate_23 cost 0.0691988468170166 seconds
DEBUG 01-06 17:11:11.918455.918455 lmp.py:220] -------------------------------- end layer 23 --------------------------------
DEBUG 01-06 17:11:11.918602.918602 lmp.py:176] -------------------------------- start layer 24 --------------------------------
DEBUG 01-06 17:11:11.918921.918921 cuda_h.py:10] start start_load_qkvogn_s_weight_l_25
DEBUG 01-06 17:11:11.918022.918022 cuda_h.py:10] start start_load_qkvogn_s_weight_l_25
DEBUG 01-06 17:11:11.919017.919017 cuda_h.py:19] end start_load_qkvogn_s_weight_l_25 cost 3.719329833984375e-05 seconds
DEBUG 01-06 17:11:11.919204.919204 cuda_h.py:19] end start_load_qkvogn_s_weight_l_25 cost 7.2479248046875e-05 seconds
DEBUG 01-06 17:11:11.919569.919569 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-06 17:11:11.919770.919770 mlpmodule.py:367] cuda:1 cuda:1
DEBUG 01-06 17:11:11.919455.919455 cuda_h.py:10] start sllm_worker_task
DEBUG 01-06 17:11:11.919054.919054 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 17:11:11.919997.919997 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 17:11:11.919619.919619 cuda_h.py:19] end allocate_cuda_memory cost 0.000347137451171875 seconds
DEBUG 01-06 17:11:11.919841.919841 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 17:11:11.919710.919710 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 17:11:11.920321.920321 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 17:11:11.920978.920978 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 838528cc-a772-42e7-944e-ee35f95b6cf9
DEBUG 01-06 17:11:11.920623.920623 client.py:106] call stub.LoadModelAsync
DEBUG 01-06 17:11:11.920063.920063 cuda_h.py:10] start self_attn
INFO 01-06 17:11:11.921254.921254 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 838528cc-a772-42e7-944e-ee35f95b6cf9
DEBUG 01-06 17:11:11.921058.921058 cuda_h.py:19] end load_into_gpu_async cost 0.001695394515991211 seconds
DEBUG 01-06 17:11:11.921397.921397 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 17:11:11.921891.921891 cuda_h.py:19] end restore_tensors2 cost 8.392333984375e-05 seconds
DEBUG 01-06 17:11:11.921130.921130 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.002438783645629883 seconds
INFO 01-06 17:11:11.921305.921305 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 838528cc-a772-42e7-944e-ee35f95b6cf9
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-06 17:11:11.923005.923005 cuda_h.py:19] end self_attn cost 0.002946615219116211 seconds
DEBUG 01-06 17:11:11.923207.923207 cuda_h.py:19] end iln_self_attn_paln cost 0.0045816898345947266 seconds
DEBUG 01-06 17:11:11.923142.923142 cuda_h.py:10] start layer_moe_generate_24
DEBUG 01-06 17:11:11.923310.923310 cuda_h.py:10] start gate
DEBUG 01-06 17:11:11.924068.924068 cuda_h.py:19] end gate cost 0.0006527900695800781 seconds
DEBUG 01-06 17:11:11.924898.924898 cuda_h.py:10] start experts_map_get
DEBUG 01-06 17:11:11.924491.924491 lmp.py:403] 
DEBUG 01-06 17:11:11.924491.924491 lmp.py:403] Expert Token Distribution & Device Allocation:
DEBUG 01-06 17:11:11.924054.924054 lmp.py:404]   Total experts: 64
DEBUG 01-06 17:11:11.924943.924943 lmp.py:405]   CPU experts: 32 (50%)
DEBUG 01-06 17:11:11.924255.924255 lmp.py:406]   GPU experts: 32 (50%)
DEBUG 01-06 17:11:11.924421.924421 lmp.py:407] 
DEBUG 01-06 17:11:11.924421.924421 lmp.py:407]   Expert ID | Tokens | Device
DEBUG 01-06 17:11:11.924825.924825 lmp.py:408]   -----------------------------------
DEBUG 01-06 17:11:11.925429.925429 lmp.py:414]   Expert 36 |     21 | CPU
DEBUG 01-06 17:11:11.925072.925072 lmp.py:414]   Expert 35 |     35 | CPU
DEBUG 01-06 17:11:11.925999.925999 lmp.py:414]   Expert 46 |     38 | CPU
DEBUG 01-06 17:11:11.925450.925450 lmp.py:414]   Expert 25 |     43 | CPU
DEBUG 01-06 17:11:11.925663.925663 lmp.py:414]   Expert 51 |     50 | CPU
DEBUG 01-06 17:11:11.925875.925875 lmp.py:414]   Expert 16 |     58 | CPU
DEBUG 01-06 17:11:11.925326.925326 lmp.py:414]   Expert  0 |     65 | CPU
DEBUG 01-06 17:11:11.925062.925062 lmp.py:414]   Expert 55 |     65 | CPU
DEBUG 01-06 17:11:11.925274.925274 lmp.py:414]   Expert 47 |     66 | CPU
DEBUG 01-06 17:11:11.925202.925202 lmp.py:414]   Expert 43 |     67 | CPU
DEBUG 01-06 17:11:11.925891.925891 lmp.py:414]   Expert 42 |     69 | CPU
DEBUG 01-06 17:11:11.925104.925104 lmp.py:414]   Expert 44 |     70 | CPU
DEBUG 01-06 17:11:11.925793.925793 lmp.py:414]   Expert 39 |     71 | CPU
DEBUG 01-06 17:11:11.925913.925913 lmp.py:414]   Expert 30 |     73 | CPU
DEBUG 01-06 17:11:11.925840.925840 lmp.py:414]   Expert  2 |     81 | CPU
DEBUG 01-06 17:11:11.925530.925530 lmp.py:414]   Expert  4 |    111 | CPU
DEBUG 01-06 17:11:11.925981.925981 lmp.py:414]   Expert 48 |    113 | CPU
DEBUG 01-06 17:11:11.925432.925432 lmp.py:414]   Expert 33 |    121 | CPU
DEBUG 01-06 17:11:11.925644.925644 lmp.py:414]   Expert 61 |    121 | CPU
DEBUG 01-06 17:11:11.925095.925095 lmp.py:414]   Expert  6 |    122 | CPU
DEBUG 01-06 17:11:11.925546.925546 lmp.py:414]   Expert 24 |    123 | CPU
DEBUG 01-06 17:11:11.925235.925235 lmp.py:414]   Expert 56 |    126 | CPU
DEBUG 01-06 17:11:11.925924.925924 lmp.py:414]   Expert 13 |    127 | CPU
DEBUG 01-06 17:11:11.925329.925329 lmp.py:414]   Expert 15 |    131 | CPU
DEBUG 01-06 17:11:11.925018.925018 lmp.py:414]   Expert 54 |    138 | CPU
DEBUG 01-06 17:11:11.925423.925423 lmp.py:414]   Expert  9 |    139 | CPU
DEBUG 01-06 17:11:11.925589.925589 lmp.py:414]   Expert 20 |    139 | CPU
DEBUG 01-06 17:11:11.925040.925040 lmp.py:414]   Expert 38 |    144 | CPU
DEBUG 01-06 17:11:11.925729.925729 lmp.py:414]   Expert  7 |    145 | CPU
DEBUG 01-06 17:11:11.925180.925180 lmp.py:414]   Expert 29 |    145 | CPU
DEBUG 01-06 17:11:11.925108.925108 lmp.py:414]   Expert 59 |    155 | CPU
DEBUG 01-06 17:11:11.925559.925559 lmp.py:414]   Expert 62 |    156 | CPU
DEBUG 01-06 17:11:11.925009.925009 lmp.py:414]   Expert 45 |    160 | GPU
DEBUG 01-06 17:11:11.925699.925699 lmp.py:414]   Expert 19 |    171 | GPU
DEBUG 01-06 17:11:11.925388.925388 lmp.py:414]   Expert 34 |    189 | GPU
DEBUG 01-06 17:11:11.925077.925077 lmp.py:414]   Expert 57 |    191 | GPU
DEBUG 01-06 17:11:11.925720.925720 lmp.py:414]   Expert 23 |    203 | GPU
DEBUG 01-06 17:11:11.925648.925648 lmp.py:414]   Expert 10 |    205 | GPU
DEBUG 01-06 17:11:11.925814.925814 lmp.py:414]   Expert 50 |    205 | GPU
DEBUG 01-06 17:11:11.925742.925742 lmp.py:414]   Expert 31 |    207 | GPU
DEBUG 01-06 17:11:11.925193.925193 lmp.py:414]   Expert  8 |    209 | GPU
DEBUG 01-06 17:11:11.925120.925120 lmp.py:414]   Expert 18 |    217 | GPU
DEBUG 01-06 17:11:11.925095.925095 lmp.py:414]   Expert 22 |    220 | GPU
DEBUG 01-06 17:11:11.925545.925545 lmp.py:414]   Expert 60 |    220 | GPU
DEBUG 01-06 17:11:11.925996.925996 lmp.py:414]   Expert 52 |    224 | GPU
DEBUG 01-06 17:11:11.925447.925447 lmp.py:414]   Expert 53 |    226 | GPU
DEBUG 01-06 17:11:11.925898.925898 lmp.py:414]   Expert 37 |    239 | GPU
DEBUG 01-06 17:11:11.925541.925541 lmp.py:414]   Expert  5 |    244 | GPU
DEBUG 01-06 17:11:11.925946.925946 lmp.py:414]   Expert 17 |    247 | GPU
DEBUG 01-06 17:11:11.925112.925112 lmp.py:414]   Expert 11 |    273 | GPU
DEBUG 01-06 17:11:11.925516.925516 lmp.py:414]   Expert 41 |    273 | GPU
DEBUG 01-06 17:11:11.925159.925159 lmp.py:414]   Expert 28 |    276 | GPU
DEBUG 01-06 17:11:11.925087.925087 lmp.py:414]   Expert 49 |    280 | GPU
DEBUG 01-06 17:11:11.925776.925776 lmp.py:414]   Expert  1 |    281 | GPU
DEBUG 01-06 17:11:11.925227.925227 lmp.py:414]   Expert 26 |    285 | GPU
DEBUG 01-06 17:11:11.925440.925440 lmp.py:414]   Expert 32 |    288 | GPU
DEBUG 01-06 17:11:11.925129.925129 lmp.py:414]   Expert 58 |    291 | GPU
DEBUG 01-06 17:11:11.925818.925818 lmp.py:414]   Expert 40 |    302 | GPU
DEBUG 01-06 17:11:11.925269.925269 lmp.py:414]   Expert 14 |    316 | GPU
DEBUG 01-06 17:11:11.925243.925243 lmp.py:414]   Expert 12 |    324 | GPU
DEBUG 01-06 17:11:11.926171.926171 lmp.py:414]   Expert 63 |    329 | GPU
DEBUG 01-06 17:11:11.926099.926099 lmp.py:414]   Expert 21 |    369 | GPU
DEBUG 01-06 17:11:11.926026.926026 lmp.py:414]   Expert 27 |    674 | GPU
DEBUG 01-06 17:11:11.926954.926954 lmp.py:414]   Expert  3 |   1022 | GPU
DEBUG 01-06 17:11:11.926835.926835 lmp.py:415] 
DEBUG 01-06 17:11:11.926835.926835 lmp.py:415]   CPU total tokens: 3128 (25.5%)
DEBUG 01-06 17:11:11.926717.926717 lmp.py:416]   GPU total tokens: 9160 (74.5%)
DEBUG 01-06 17:11:11.926174.926174 cuda_h.py:19] end experts_map_get cost 0.0015094280242919922 seconds
DEBUG 01-06 17:11:11.926533.926533 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-06 17:11:11.926455.926455 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 17:11:11.926652.926652 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 17:11:11.927873.927873 cuda_h.py:19] end allocate_cuda_memory cost 0.0016388893127441406 seconds
DEBUG 01-06 17:11:11.928770.928770 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 17:11:11.928287.928287 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 17:11:11.928957.928957 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 17:11:11.928561.928561 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 50a78247-743e-4cf7-b87a-8e422a57adc9
DEBUG 01-06 17:11:11.928693.928693 client.py:106] call stub.LoadModelAsync
INFO 01-06 17:11:11.929745.929745 client.py:127] Model loaded
DEBUG 01-06 17:11:11.930792.930792 cuda_h.py:19] end sllm_worker_task cost 0.010765552520751953 seconds
INFO 01-06 17:11:11.931011.931011 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 50a78247-743e-4cf7-b87a-8e422a57adc9
DEBUG 01-06 17:11:11.931023.931023 cuda_h.py:19] end load_into_gpu_async cost 0.0033676624298095703 seconds
DEBUG 01-06 17:11:11.931701.931701 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 17:11:11.932557.932557 cuda_h.py:19] end restore_tensors2 cost 0.000392913818359375 seconds
DEBUG 01-06 17:11:11.932049.932049 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.005858659744262695 seconds
DEBUG 01-06 17:11:11.934507.934507 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.00848698616027832 seconds
DEBUG 01-06 17:11:11.934336.934336 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-06 17:11:11.934127.934127 lmp.py:461] 
DEBUG 01-06 17:11:11.934127.934127 lmp.py:461]   Computing 32 experts on CPU...
DEBUG 01-06 17:11:11.934878.934878 cuda_h.py:19] end cpu_experts_submit cost 0.00011086463928222656 seconds
DEBUG 01-06 17:11:11.934527.934527 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-06 17:11:11.945844.945844 mlpmodule.py:706] group tensors cost 0.010614633560180664 s
DEBUG 01-06 17:11:11.948452.948452 mlpmodule.py:744] pad cost 0.0016491413116455078 s
DEBUG 01-06 17:11:11.948502.948502 mlpmodule.py:750] create cpu tensor cost 4.863739013671875e-05 s
DEBUG 01-06 17:11:11.948928.948928 mlpmodule.py:755] move to cpu cost 3.337860107421875e-05 s
DEBUG 01-06 17:11:11.959623.959623 mlpmodule.py:769] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-06 17:11:11.959109.959109 mlpmodule.py:770] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-06 17:11:11.959919.959919 mlpmodule.py:775] group_w3 first element: 0.00653076171875
WARNING 01-06 17:11:11.959055.959055 mlpmodule.py:785] start einsum2
DEBUG 01-06 17:11:11.977709.977709 mlpmodule.py:795] group einsum cost 0.02920842170715332 s
DEBUG 01-06 17:11:11.978409.978409 mlpmodule.py:803] cpy2cputensor cost 0.0006098747253417969 s
DEBUG 01-06 17:11:11.982192.982192 cuda_h.py:19] end wait_cetm_experts cost 0.0476689338684082 seconds
DEBUG 01-06 17:11:11.982212.982212 cuda_h.py:10] start gpu_sexperts
DEBUG 01-06 17:11:11.983863.983863 cuda_h.py:19] end gpu_sexperts cost 0.0006110668182373047 seconds
DEBUG 01-06 17:11:11.983620.983620 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-06 17:11:11.983993.983993 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.384185791015625e-05 seconds
DEBUG 01-06 17:11:11.983935.983935 cuda_h.py:10] start wait_experts
INFO 01-06 17:11:11.983121.983121 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 50a78247-743e-4cf7-b87a-8e422a57adc9
INFO 01-06 17:11:11.984835.984835 client.py:127] Model loaded
DEBUG 01-06 17:11:11.985161.985161 cuda_h.py:19] end wait_experts cost 0.0013992786407470703 seconds
DEBUG 01-06 17:11:11.985487.985487 cuda_h.py:10] start gpu_experts
DEBUG 01-06 17:11:11.985004.985004 lmp.py:506]   Computing 32 experts on GPU...
DEBUG 01-06 17:11:11.985764.985764 mlpmodule.py:533] gpu group tensors cost 0.0006489753723144531 s
DEBUG 01-06 17:11:11.987436.987436 mlpmodule.py:566] gpu pad cost 0.0018100738525390625 s
DEBUG 01-06 17:11:11.988708.988708 mlpmodule.py:584] gpu group einsum cost 0.0005412101745605469 s
DEBUG 01-06 17:11:11.989174.989174 mlpmodule.py:664]  experts func einsum cost 0.05471038818359375 s
DEBUG 01-06 17:11:11.992123.992123 mlpmodule.py:613] gpu experts func einsum cost 0.006798982620239258 s
DEBUG 01-06 17:11:11.992936.992936 cuda_h.py:19] end gpu_experts cost 0.007042884826660156 seconds
DEBUG 01-06 17:11:11.992204.992204 cuda_h.py:19] end layer_moe_generate_24 cost 0.06843113899230957 seconds
DEBUG 01-06 17:11:11.992457.992457 lmp.py:220] -------------------------------- end layer 24 --------------------------------
DEBUG 01-06 17:11:11.992796.992796 lmp.py:176] -------------------------------- start layer 25 --------------------------------
DEBUG 01-06 17:11:11.992022.992022 cuda_h.py:10] start start_load_qkvogn_s_weight_l_26
DEBUG 01-06 17:11:11.992977.992977 cuda_h.py:10] start start_load_qkvogn_s_weight_l_26
DEBUG 01-06 17:11:11.992258.992258 cuda_h.py:19] end start_load_qkvogn_s_weight_l_26 cost 3.62396240234375e-05 seconds
DEBUG 01-06 17:11:11.992298.992298 cuda_h.py:19] end start_load_qkvogn_s_weight_l_26 cost 6.937980651855469e-05 seconds
DEBUG 01-06 17:11:11.992379.992379 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-06 17:11:11.992057.992057 mlpmodule.py:367] cuda:1 cuda:1
DEBUG 01-06 17:11:11.992742.992742 cuda_h.py:10] start sllm_worker_task
DEBUG 01-06 17:11:11.992348.992348 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 17:11:11.993906.993906 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 17:11:11.993017.993017 cuda_h.py:19] end allocate_cuda_memory cost 0.0003228187561035156 seconds
DEBUG 01-06 17:11:11.993577.993577 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 17:11:11.993923.993923 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 17:11:11.993726.993726 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 17:11:11.993621.993621 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 54c37079-7b31-43f2-bcb1-51b8b5bc2a62
DEBUG 01-06 17:11:11.993882.993882 client.py:106] call stub.LoadModelAsync
DEBUG 01-06 17:11:11.993605.993605 cuda_h.py:10] start self_attn
INFO 01-06 17:11:11.995475.995475 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 54c37079-7b31-43f2-bcb1-51b8b5bc2a62
DEBUG 01-06 17:11:11.995609.995609 cuda_h.py:19] end load_into_gpu_async cost 0.001909017562866211 seconds
DEBUG 01-06 17:11:11.995650.995650 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 17:11:11.995230.995230 cuda_h.py:19] end restore_tensors2 cost 7.939338684082031e-05 seconds
DEBUG 01-06 17:11:11.995198.995198 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0026297569274902344 seconds
INFO 01-06 17:11:11.995127.995127 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 54c37079-7b31-43f2-bcb1-51b8b5bc2a62
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-06 17:11:11.996759.996759 cuda_h.py:19] end self_attn cost 0.002927541732788086 seconds
DEBUG 01-06 17:11:11.997306.997306 cuda_h.py:19] end iln_self_attn_paln cost 0.0045125484466552734 seconds
DEBUG 01-06 17:11:11.997195.997195 cuda_h.py:10] start layer_moe_generate_25
DEBUG 01-06 17:11:11.997104.997104 cuda_h.py:10] start gate
DEBUG 01-06 17:11:11.998650.998650 cuda_h.py:19] end gate cost 0.0006475448608398438 seconds
DEBUG 01-06 17:11:11.998049.998049 cuda_h.py:10] start experts_map_get
DEBUG 01-06 17:11:11.998496.998496 lmp.py:403] 
DEBUG 01-06 17:11:11.998496.998496 lmp.py:403] Expert Token Distribution & Device Allocation:
DEBUG 01-06 17:11:11.998728.998728 lmp.py:404]   Total experts: 64
DEBUG 01-06 17:11:11.998855.998855 lmp.py:405]   CPU experts: 32 (50%)
DEBUG 01-06 17:11:11.998167.998167 lmp.py:406]   GPU experts: 32 (50%)
DEBUG 01-06 17:11:11.998571.998571 lmp.py:407] 
DEBUG 01-06 17:11:11.998571.998571 lmp.py:407]   Expert ID | Tokens | Device
DEBUG 01-06 17:11:11.998214.998214 lmp.py:408]   -----------------------------------
DEBUG 01-06 17:11:11.998056.998056 lmp.py:414]   Expert 13 |     33 | CPU
DEBUG 01-06 17:11:11.998461.998461 lmp.py:414]   Expert 25 |     38 | CPU
DEBUG 01-06 17:11:11.998150.998150 lmp.py:414]   Expert  9 |     43 | CPU
DEBUG 01-06 17:11:11.998601.998601 lmp.py:414]   Expert 38 |     43 | CPU
DEBUG 01-06 17:11:11.998575.998575 lmp.py:414]   Expert 44 |     43 | CPU
DEBUG 01-06 17:11:11.998741.998741 lmp.py:414]   Expert 22 |     46 | CPU
DEBUG 01-06 17:11:11.998192.998192 lmp.py:414]   Expert 16 |     49 | CPU
DEBUG 01-06 17:11:11.998881.998881 lmp.py:414]   Expert 42 |     53 | CPU
DEBUG 01-06 17:11:11.998332.998332 lmp.py:414]   Expert 33 |     54 | CPU
DEBUG 01-06 17:11:11.998783.998783 lmp.py:414]   Expert  2 |     56 | CPU
DEBUG 01-06 17:11:11.998757.998757 lmp.py:414]   Expert  5 |     60 | CPU
DEBUG 01-06 17:11:11.998016.998016 lmp.py:414]   Expert 23 |     78 | CPU
DEBUG 01-06 17:11:11.998228.998228 lmp.py:414]   Expert 24 |     80 | CPU
DEBUG 01-06 17:11:11.998203.998203 lmp.py:414]   Expert 10 |     84 | CPU
DEBUG 01-06 17:11:11.998938.998938 lmp.py:414]   Expert 59 |     93 | CPU
DEBUG 01-06 17:11:11.998674.998674 lmp.py:414]   Expert 21 |    103 | CPU
DEBUG 01-06 17:11:11.998171.998171 lmp.py:414]   Expert 46 |    104 | CPU
DEBUG 01-06 17:11:11.998907.998907 lmp.py:414]   Expert 55 |    111 | CPU
DEBUG 01-06 17:11:11.998642.998642 lmp.py:414]   Expert 61 |    117 | CPU
DEBUG 01-06 17:11:11.998616.998616 lmp.py:414]   Expert 45 |    120 | CPU
DEBUG 01-06 17:11:11.998306.998306 lmp.py:414]   Expert 31 |    133 | CPU
DEBUG 01-06 17:11:11.998756.998756 lmp.py:414]   Expert 36 |    134 | CPU
DEBUG 01-06 17:11:11.998969.998969 lmp.py:414]   Expert 51 |    140 | CPU
DEBUG 01-06 17:11:11.998420.998420 lmp.py:414]   Expert  6 |    142 | CPU
DEBUG 01-06 17:11:11.998871.998871 lmp.py:414]   Expert  0 |    148 | CPU
DEBUG 01-06 17:11:11.998845.998845 lmp.py:414]   Expert  8 |    148 | CPU
DEBUG 01-06 17:11:11.998104.998104 lmp.py:414]   Expert 43 |    154 | CPU
DEBUG 01-06 17:11:11.998078.998078 lmp.py:414]   Expert 18 |    155 | CPU
DEBUG 01-06 17:11:11.998052.998052 lmp.py:414]   Expert  3 |    161 | CPU
DEBUG 01-06 17:11:11.999787.999787 lmp.py:414]   Expert 26 |    161 | CPU
DEBUG 01-06 17:11:11.999761.999761 lmp.py:414]   Expert 48 |    164 | CPU
DEBUG 01-06 17:11:11.999258.999258 lmp.py:414]   Expert 41 |    170 | CPU
DEBUG 01-06 17:11:11.999948.999948 lmp.py:414]   Expert 12 |    173 | GPU
DEBUG 01-06 17:11:11.999399.999399 lmp.py:414]   Expert 20 |    176 | GPU
DEBUG 01-06 17:11:11.999042.999042 lmp.py:414]   Expert  7 |    183 | GPU
DEBUG 01-06 17:11:11.999208.999208 lmp.py:414]   Expert 56 |    185 | GPU
DEBUG 01-06 17:11:11.999851.999851 lmp.py:414]   Expert  1 |    190 | GPU
DEBUG 01-06 17:11:11.999540.999540 lmp.py:414]   Expert 28 |    191 | GPU
DEBUG 01-06 17:11:11.999991.999991 lmp.py:414]   Expert 34 |    191 | GPU
DEBUG 01-06 17:11:11.999203.999203 lmp.py:414]   Expert 27 |    194 | GPU
DEBUG 01-06 17:11:11.999893.999893 lmp.py:414]   Expert 47 |    200 | GPU
DEBUG 01-06 17:11:11.999344.999344 lmp.py:414]   Expert 32 |    213 | GPU
DEBUG 01-06 17:11:11.999556.999556 lmp.py:414]   Expert 11 |    219 | GPU
DEBUG 01-06 17:11:11.999245.999245 lmp.py:414]   Expert 53 |    226 | GPU
DEBUG 01-06 17:11:11.999696.999696 lmp.py:414]   Expert 40 |    228 | GPU
DEBUG 01-06 17:11:11.999624.999624 lmp.py:414]   Expert 49 |    234 | GPU
DEBUG 01-06 17:11:11.999552.999552 lmp.py:414]   Expert 50 |    239 | GPU
DEBUG 01-06 17:11:11.999241.999241 lmp.py:414]   Expert 63 |    243 | GPU
DEBUG 01-06 17:11:11.999646.999646 lmp.py:414]   Expert 29 |    246 | GPU
DEBUG 01-06 17:11:11.999335.999335 lmp.py:414]   Expert 30 |    252 | GPU
DEBUG 01-06 17:11:11.999547.999547 lmp.py:414]   Expert  4 |    255 | GPU
DEBUG 01-06 17:11:11.999998.999998 lmp.py:414]   Expert 15 |    258 | GPU
DEBUG 01-06 17:11:11.999211.999211 lmp.py:414]   Expert 14 |    262 | GPU
DEBUG 01-06 17:11:11.999662.999662 lmp.py:414]   Expert 35 |    266 | GPU
DEBUG 01-06 17:11:11.999112.999112 lmp.py:414]   Expert 37 |    304 | GPU
DEBUG 01-06 17:11:11.999563.999563 lmp.py:414]   Expert 52 |    331 | GPU
DEBUG 01-06 17:11:11.999776.999776 lmp.py:414]   Expert 17 |    367 | GPU
DEBUG 01-06 17:11:11.999227.999227 lmp.py:414]   Expert 54 |    377 | GPU
DEBUG 01-06 17:11:11.999631.999631 lmp.py:414]   Expert 39 |    402 | GPU
DEBUG 01-06 17:11:11.999559.999559 lmp.py:414]   Expert 57 |    416 | GPU
DEBUG 01-06 17:11:11.999487.999487 lmp.py:414]   Expert 60 |    460 | GPU
DEBUG 01-06 17:11:11.999414.999414 lmp.py:414]   Expert 62 |    461 | GPU
DEBUG 01-06 17:11:11.999865.999865 lmp.py:414]   Expert 19 |    550 | GPU
DEBUG 01-06 17:11:11.999316.999316 lmp.py:414]   Expert 58 |    578 | GPU
DEBUG 01-06 17:11:11.999959.999959 lmp.py:415] 
DEBUG 01-06 17:11:11.999959.999959 lmp.py:415]   CPU total tokens: 3218 (26.2%)
DEBUG 01-06 17:11:11.999602.999602 lmp.py:416]   GPU total tokens: 9070 (73.8%)
DEBUG 01-06 17:11:11.999537.999537 cuda_h.py:19] end experts_map_get cost 0.001489877700805664 seconds
DEBUG 01-06 17:11:11.999180.999180 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-06 17:11:11.999724.999724 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 17:11:11.999822.999822 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 17:11:12.001550.001550 cuda_h.py:19] end allocate_cuda_memory cost 0.0019435882568359375 seconds
DEBUG 01-06 17:11:12.001559.001559 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 17:11:12.001984.001984 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 17:11:12.001462.001462 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 17:11:12.001920.001920 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 0252d541-1fae-4187-8562-8bcff67df11a
DEBUG 01-06 17:11:12.002689.002689 client.py:106] call stub.LoadModelAsync
INFO 01-06 17:11:12.003973.003973 client.py:127] Model loaded
DEBUG 01-06 17:11:12.003338.003338 cuda_h.py:19] end sllm_worker_task cost 0.010987997055053711 seconds
INFO 01-06 17:11:12.005767.005767 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 0252d541-1fae-4187-8562-8bcff67df11a
DEBUG 01-06 17:11:12.005657.005657 cuda_h.py:19] end load_into_gpu_async cost 0.0032684803009033203 seconds
DEBUG 01-06 17:11:12.005883.005883 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 17:11:12.005888.005888 cuda_h.py:19] end restore_tensors2 cost 0.00032830238342285156 seconds
DEBUG 01-06 17:11:12.005903.005903 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.005902528762817383 seconds
DEBUG 01-06 17:11:12.008101.008101 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.00851893424987793 seconds
DEBUG 01-06 17:11:12.008977.008977 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-06 17:11:12.008484.008484 lmp.py:461] 
DEBUG 01-06 17:11:12.008484.008484 lmp.py:461]   Computing 32 experts on CPU...
DEBUG 01-06 17:11:12.008746.008746 cuda_h.py:19] end cpu_experts_submit cost 0.00017142295837402344 seconds
DEBUG 01-06 17:11:12.008449.008449 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-06 17:11:12.019062.019062 mlpmodule.py:706] group tensors cost 0.010742664337158203 s
DEBUG 01-06 17:11:12.022417.022417 mlpmodule.py:744] pad cost 0.0018825531005859375 s
DEBUG 01-06 17:11:12.022725.022725 mlpmodule.py:750] create cpu tensor cost 5.364418029785156e-05 s
DEBUG 01-06 17:11:12.022688.022688 mlpmodule.py:755] move to cpu cost 3.743171691894531e-05 s
DEBUG 01-06 17:11:12.032638.032638 mlpmodule.py:769] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-06 17:11:12.032561.032561 mlpmodule.py:770] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-06 17:11:12.033392.033392 mlpmodule.py:775] group_w3 first element: 0.007110595703125
WARNING 01-06 17:11:12.033204.033204 mlpmodule.py:785] start einsum2
DEBUG 01-06 17:11:12.050454.050454 mlpmodule.py:795] group einsum cost 0.02835226058959961 s
DEBUG 01-06 17:11:12.051938.051938 mlpmodule.py:803] cpy2cputensor cost 0.0006895065307617188 s
DEBUG 01-06 17:11:12.055324.055324 cuda_h.py:19] end wait_cetm_experts cost 0.04740023612976074 seconds
DEBUG 01-06 17:11:12.056721.056721 cuda_h.py:10] start gpu_sexperts
DEBUG 01-06 17:11:12.056975.056975 cuda_h.py:19] end gpu_sexperts cost 0.0006346702575683594 seconds
DEBUG 01-06 17:11:12.056832.056832 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-06 17:11:12.056635.056635 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.574920654296875e-05 seconds
DEBUG 01-06 17:11:12.056815.056815 cuda_h.py:10] start wait_experts
INFO 01-06 17:11:12.057002.057002 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 0252d541-1fae-4187-8562-8bcff67df11a
INFO 01-06 17:11:12.058225.058225 client.py:127] Model loaded
DEBUG 01-06 17:11:12.058128.058128 cuda_h.py:19] end wait_experts cost 0.0013935565948486328 seconds
DEBUG 01-06 17:11:12.058784.058784 cuda_h.py:10] start gpu_experts
DEBUG 01-06 17:11:12.058110.058110 lmp.py:506]   Computing 32 experts on GPU...
DEBUG 01-06 17:11:12.059399.059399 mlpmodule.py:533] gpu group tensors cost 0.0006566047668457031 s
DEBUG 01-06 17:11:12.061681.061681 mlpmodule.py:566] gpu pad cost 0.0018384456634521484 s
DEBUG 01-06 17:11:12.061227.061227 mlpmodule.py:584] gpu group einsum cost 0.0006036758422851562 s
DEBUG 01-06 17:11:12.063481.063481 mlpmodule.py:664]  experts func einsum cost 0.054944753646850586 s
DEBUG 01-06 17:11:12.065279.065279 mlpmodule.py:613] gpu experts func einsum cost 0.0069429874420166016 s
DEBUG 01-06 17:11:12.065582.065582 cuda_h.py:19] end gpu_experts cost 0.0071942806243896484 seconds
DEBUG 01-06 17:11:12.065235.065235 cuda_h.py:19] end layer_moe_generate_25 cost 0.06839537620544434 seconds
DEBUG 01-06 17:11:12.065924.065924 lmp.py:220] -------------------------------- end layer 25 --------------------------------
DEBUG 01-06 17:11:12.066224.066224 lmp.py:176] -------------------------------- start layer 26 --------------------------------
DEBUG 01-06 17:11:12.066688.066688 cuda_h.py:10] start start_load_qkvogn_s_weight_l_27
DEBUG 01-06 17:11:12.066259.066259 cuda_h.py:10] start start_load_qkvogn_s_weight_l_27
DEBUG 01-06 17:11:12.066255.066255 cuda_h.py:19] end start_load_qkvogn_s_weight_l_27 cost 3.7670135498046875e-05 seconds
DEBUG 01-06 17:11:12.066487.066487 cuda_h.py:19] end start_load_qkvogn_s_weight_l_27 cost 7.200241088867188e-05 seconds
DEBUG 01-06 17:11:12.066568.066568 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-06 17:11:12.066292.066292 mlpmodule.py:367] cuda:1 cuda:1
DEBUG 01-06 17:11:12.066977.066977 cuda_h.py:10] start sllm_worker_task
DEBUG 01-06 17:11:12.066623.066623 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 17:11:12.066267.066267 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 17:11:12.066107.066107 cuda_h.py:19] end allocate_cuda_memory cost 0.00033664703369140625 seconds
DEBUG 01-06 17:11:12.066720.066720 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 17:11:12.067457.067457 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 17:11:12.067054.067054 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 17:11:12.067479.067479 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, b419fa92-7e02-48d2-b1d7-28d2242c207c
DEBUG 01-06 17:11:12.067310.067310 client.py:106] call stub.LoadModelAsync
DEBUG 01-06 17:11:12.067531.067531 cuda_h.py:10] start self_attn
INFO 01-06 17:11:12.068962.068962 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, b419fa92-7e02-48d2-b1d7-28d2242c207c
DEBUG 01-06 17:11:12.068017.068017 cuda_h.py:19] end load_into_gpu_async cost 0.0017185211181640625 seconds
DEBUG 01-06 17:11:12.068773.068773 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 17:11:12.068883.068883 cuda_h.py:19] end restore_tensors2 cost 8.177757263183594e-05 seconds
DEBUG 01-06 17:11:12.068375.068375 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.002453327178955078 seconds
INFO 01-06 17:11:12.069808.069808 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, b419fa92-7e02-48d2-b1d7-28d2242c207c
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-06 17:11:12.070281.070281 cuda_h.py:19] end self_attn cost 0.0029473304748535156 seconds
DEBUG 01-06 17:11:12.070556.070556 cuda_h.py:19] end iln_self_attn_paln cost 0.004558563232421875 seconds
DEBUG 01-06 17:11:12.070922.070922 cuda_h.py:10] start layer_moe_generate_26
DEBUG 01-06 17:11:12.070592.070592 cuda_h.py:10] start gate
DEBUG 01-06 17:11:12.071761.071761 cuda_h.py:19] end gate cost 0.0006499290466308594 seconds
DEBUG 01-06 17:11:12.071398.071398 cuda_h.py:10] start experts_map_get
DEBUG 01-06 17:11:12.071660.071660 lmp.py:403] 
DEBUG 01-06 17:11:12.071660.071660 lmp.py:403] Expert Token Distribution & Device Allocation:
DEBUG 01-06 17:11:12.071701.071701 lmp.py:404]   Total experts: 64
DEBUG 01-06 17:11:12.071827.071827 lmp.py:405]   CPU experts: 32 (50%)
DEBUG 01-06 17:11:12.072378.072378 lmp.py:406]   GPU experts: 32 (50%)
DEBUG 01-06 17:11:12.072544.072544 lmp.py:407] 
DEBUG 01-06 17:11:12.072544.072544 lmp.py:407]   Expert ID | Tokens | Device
DEBUG 01-06 17:11:12.072187.072187 lmp.py:408]   -----------------------------------
DEBUG 01-06 17:11:12.072744.072744 lmp.py:414]   Expert 20 |      8 | CPU
DEBUG 01-06 17:11:12.072148.072148 lmp.py:414]   Expert 61 |     10 | CPU
DEBUG 01-06 17:11:12.072076.072076 lmp.py:414]   Expert  7 |     31 | CPU
DEBUG 01-06 17:11:12.072050.072050 lmp.py:414]   Expert 11 |     32 | CPU
DEBUG 01-06 17:11:12.072263.072263 lmp.py:414]   Expert 51 |     34 | CPU
DEBUG 01-06 17:11:12.072998.072998 lmp.py:414]   Expert  3 |     38 | CPU
DEBUG 01-06 17:11:12.072734.072734 lmp.py:414]   Expert 62 |     39 | CPU
DEBUG 01-06 17:11:12.072470.072470 lmp.py:414]   Expert 30 |     45 | CPU
DEBUG 01-06 17:11:12.072636.072636 lmp.py:414]   Expert  6 |     53 | CPU
DEBUG 01-06 17:11:12.072848.072848 lmp.py:414]   Expert 17 |     58 | CPU
DEBUG 01-06 17:11:12.072299.072299 lmp.py:414]   Expert 29 |     65 | CPU
DEBUG 01-06 17:11:12.072988.072988 lmp.py:414]   Expert  9 |     70 | CPU
DEBUG 01-06 17:11:12.072916.072916 lmp.py:414]   Expert 63 |     72 | CPU
DEBUG 01-06 17:11:12.072413.072413 lmp.py:414]   Expert 38 |     74 | CPU
DEBUG 01-06 17:11:12.072149.072149 lmp.py:414]   Expert 55 |     81 | CPU
DEBUG 01-06 17:11:12.072408.072408 lmp.py:414]   Expert 59 |     84 | CPU
DEBUG 01-06 17:11:12.072051.072051 lmp.py:414]   Expert 48 |     88 | CPU
DEBUG 01-06 17:11:12.072740.072740 lmp.py:414]   Expert 19 |     94 | CPU
DEBUG 01-06 17:11:12.072429.072429 lmp.py:414]   Expert  8 |    103 | CPU
DEBUG 01-06 17:11:12.072178.072178 lmp.py:414]   Expert 22 |    105 | CPU
DEBUG 01-06 17:11:12.072583.072583 lmp.py:414]   Expert 34 |    113 | CPU
DEBUG 01-06 17:11:12.072226.072226 lmp.py:414]   Expert 36 |    113 | CPU
DEBUG 01-06 17:11:12.072869.072869 lmp.py:414]   Expert 49 |    114 | CPU
DEBUG 01-06 17:11:12.072797.072797 lmp.py:414]   Expert 50 |    114 | CPU
DEBUG 01-06 17:11:12.072963.072963 lmp.py:414]   Expert 24 |    117 | CPU
DEBUG 01-06 17:11:12.072414.072414 lmp.py:414]   Expert 42 |    117 | CPU
DEBUG 01-06 17:11:12.072103.072103 lmp.py:414]   Expert  4 |    128 | CPU
DEBUG 01-06 17:11:12.072554.072554 lmp.py:414]   Expert 39 |    128 | CPU
DEBUG 01-06 17:11:12.072005.072005 lmp.py:414]   Expert 15 |    140 | CPU
DEBUG 01-06 17:11:12.072171.072171 lmp.py:414]   Expert 37 |    145 | CPU
DEBUG 01-06 17:11:12.072622.072622 lmp.py:414]   Expert 41 |    146 | CPU
DEBUG 01-06 17:11:12.072311.072311 lmp.py:414]   Expert 23 |    150 | CPU
DEBUG 01-06 17:11:12.072762.072762 lmp.py:414]   Expert 16 |    162 | GPU
DEBUG 01-06 17:11:12.072451.072451 lmp.py:414]   Expert 56 |    163 | GPU
DEBUG 01-06 17:11:12.072379.072379 lmp.py:414]   Expert 60 |    171 | GPU
DEBUG 01-06 17:11:12.072022.072022 lmp.py:414]   Expert  1 |    174 | GPU
DEBUG 01-06 17:11:12.072188.072188 lmp.py:414]   Expert 44 |    179 | GPU
DEBUG 01-06 17:11:12.072354.072354 lmp.py:414]   Expert 21 |    183 | GPU
DEBUG 01-06 17:11:12.072282.072282 lmp.py:414]   Expert 43 |    183 | GPU
DEBUG 01-06 17:11:12.072733.072733 lmp.py:414]   Expert 53 |    186 | GPU
DEBUG 01-06 17:11:12.072945.072945 lmp.py:414]   Expert 47 |    193 | GPU
DEBUG 01-06 17:11:12.072396.072396 lmp.py:414]   Expert 12 |    199 | GPU
DEBUG 01-06 17:11:12.072085.072085 lmp.py:414]   Expert 33 |    201 | GPU
DEBUG 01-06 17:11:12.072536.072536 lmp.py:414]   Expert 13 |    214 | GPU
DEBUG 01-06 17:11:12.072749.072749 lmp.py:414]   Expert 32 |    222 | GPU
DEBUG 01-06 17:11:12.072438.072438 lmp.py:414]   Expert 28 |    225 | GPU
DEBUG 01-06 17:11:12.072843.072843 lmp.py:414]   Expert  0 |    249 | GPU
DEBUG 01-06 17:11:12.072009.072009 lmp.py:414]   Expert 31 |    257 | GPU
DEBUG 01-06 17:11:12.072937.072937 lmp.py:414]   Expert 54 |    259 | GPU
DEBUG 01-06 17:11:12.072864.072864 lmp.py:414]   Expert 26 |    261 | GPU
DEBUG 01-06 17:11:12.072792.072792 lmp.py:414]   Expert 10 |    267 | GPU
DEBUG 01-06 17:11:12.072720.072720 lmp.py:414]   Expert 18 |    269 | GPU
DEBUG 01-06 17:11:12.072932.072932 lmp.py:414]   Expert 57 |    277 | GPU
DEBUG 01-06 17:11:12.072383.072383 lmp.py:414]   Expert  2 |    288 | GPU
DEBUG 01-06 17:11:12.072834.072834 lmp.py:414]   Expert 58 |    297 | GPU
DEBUG 01-06 17:11:12.072808.072808 lmp.py:414]   Expert 40 |    340 | GPU
DEBUG 01-06 17:11:12.073497.073497 lmp.py:414]   Expert 45 |    361 | GPU
DEBUG 01-06 17:11:12.073948.073948 lmp.py:414]   Expert 25 |    389 | GPU
DEBUG 01-06 17:11:12.073591.073591 lmp.py:414]   Expert  5 |    436 | GPU
DEBUG 01-06 17:11:12.073519.073519 lmp.py:414]   Expert 35 |    451 | GPU
DEBUG 01-06 17:11:12.073685.073685 lmp.py:414]   Expert 27 |    491 | GPU
DEBUG 01-06 17:11:12.073090.073090 lmp.py:414]   Expert 46 |    533 | GPU
DEBUG 01-06 17:11:12.073256.073256 lmp.py:414]   Expert 52 |    604 | GPU
DEBUG 01-06 17:11:12.073707.073707 lmp.py:414]   Expert 14 |    895 | GPU
DEBUG 01-06 17:11:12.073873.073873 lmp.py:415] 
DEBUG 01-06 17:11:12.073873.073873 lmp.py:415]   CPU total tokens: 2709 (22.0%)
DEBUG 01-06 17:11:12.073754.073754 lmp.py:416]   GPU total tokens: 9579 (78.0%)
DEBUG 01-06 17:11:12.073212.073212 cuda_h.py:19] end experts_map_get cost 0.0015196800231933594 seconds
DEBUG 01-06 17:11:12.073332.073332 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-06 17:11:12.073731.073731 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 17:11:12.073788.073788 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 17:11:12.075916.075916 cuda_h.py:19] end allocate_cuda_memory cost 0.0016052722930908203 seconds
DEBUG 01-06 17:11:12.075859.075859 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 17:11:12.075138.075138 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 17:11:12.075239.075239 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 17:11:12.075796.075796 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 2a52ac5f-592a-4cf2-a78c-fc459edb0e22
DEBUG 01-06 17:11:12.075949.075949 client.py:106] call stub.LoadModelAsync
INFO 01-06 17:11:12.076962.076962 client.py:127] Model loaded
DEBUG 01-06 17:11:12.077657.077657 cuda_h.py:19] end sllm_worker_task cost 0.010738372802734375 seconds
INFO 01-06 17:11:12.078137.078137 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 2a52ac5f-592a-4cf2-a78c-fc459edb0e22
DEBUG 01-06 17:11:12.078102.078102 cuda_h.py:19] end load_into_gpu_async cost 0.003466367721557617 seconds
DEBUG 01-06 17:11:12.078972.078972 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 17:11:12.079155.079155 cuda_h.py:19] end restore_tensors2 cost 0.0004563331604003906 seconds
DEBUG 01-06 17:11:12.079124.079124 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.005989551544189453 seconds
DEBUG 01-06 17:11:12.081046.081046 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.008646011352539062 seconds
DEBUG 01-06 17:11:12.081160.081160 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-06 17:11:12.082428.082428 lmp.py:461] 
DEBUG 01-06 17:11:12.082428.082428 lmp.py:461]   Computing 32 experts on CPU...
DEBUG 01-06 17:11:12.082178.082178 cuda_h.py:19] end cpu_experts_submit cost 0.00011134147644042969 seconds
DEBUG 01-06 17:11:12.082828.082828 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-06 17:11:12.095748.095748 mlpmodule.py:706] group tensors cost 0.012792825698852539 s
DEBUG 01-06 17:11:12.097868.097868 mlpmodule.py:744] pad cost 0.0017039775848388672 s
DEBUG 01-06 17:11:12.097164.097164 mlpmodule.py:750] create cpu tensor cost 8.702278137207031e-05 s
DEBUG 01-06 17:11:12.097002.097002 mlpmodule.py:755] move to cpu cost 3.5762786865234375e-05 s
DEBUG 01-06 17:11:12.107587.107587 mlpmodule.py:769] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-06 17:11:12.107875.107875 mlpmodule.py:770] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-06 17:11:12.107824.107824 mlpmodule.py:775] group_w3 first element: -0.0024261474609375
WARNING 01-06 17:11:12.107006.107006 mlpmodule.py:785] start einsum2
DEBUG 01-06 17:11:12.124872.124872 mlpmodule.py:795] group einsum cost 0.026929378509521484 s
DEBUG 01-06 17:11:12.125895.125895 mlpmodule.py:803] cpy2cputensor cost 0.0005941390991210938 s
DEBUG 01-06 17:11:12.129404.129404 cuda_h.py:19] end wait_cetm_experts cost 0.047779083251953125 seconds
DEBUG 01-06 17:11:12.130616.130616 cuda_h.py:10] start gpu_sexperts
DEBUG 01-06 17:11:12.130228.130228 cuda_h.py:19] end gpu_sexperts cost 0.0006151199340820312 seconds
DEBUG 01-06 17:11:12.130846.130846 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-06 17:11:12.130980.130980 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.47955322265625e-05 seconds
DEBUG 01-06 17:11:12.130398.130398 cuda_h.py:10] start wait_experts
INFO 01-06 17:11:12.131108.131108 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 2a52ac5f-592a-4cf2-a78c-fc459edb0e22
INFO 01-06 17:11:12.132947.132947 client.py:127] Model loaded
DEBUG 01-06 17:11:12.132811.132811 cuda_h.py:19] end wait_experts cost 0.0013954639434814453 seconds
DEBUG 01-06 17:11:12.132090.132090 cuda_h.py:10] start gpu_experts
DEBUG 01-06 17:11:12.132038.132038 lmp.py:506]   Computing 32 experts on GPU...
DEBUG 01-06 17:11:12.133327.133327 mlpmodule.py:533] gpu group tensors cost 0.0006492137908935547 s
DEBUG 01-06 17:11:12.135813.135813 mlpmodule.py:566] gpu pad cost 0.0017786026000976562 s
DEBUG 01-06 17:11:12.135330.135330 mlpmodule.py:584] gpu group einsum cost 0.0005474090576171875 s
DEBUG 01-06 17:11:12.137927.137927 mlpmodule.py:664]  experts func einsum cost 0.055347442626953125 s
DEBUG 01-06 17:11:12.139840.139840 mlpmodule.py:613] gpu experts func einsum cost 0.0068433284759521484 s
DEBUG 01-06 17:11:12.139044.139044 cuda_h.py:19] end gpu_experts cost 0.007099151611328125 seconds
DEBUG 01-06 17:11:12.139411.139411 cuda_h.py:19] end layer_moe_generate_26 cost 0.06876134872436523 seconds
DEBUG 01-06 17:11:12.139617.139617 lmp.py:220] -------------------------------- end layer 26 --------------------------------
DEBUG 01-06 17:11:12.139380.139380 lmp.py:176] -------------------------------- start layer 27 --------------------------------
DEBUG 01-06 17:11:12.139175.139175 cuda_h.py:10] start start_load_qkvogn_s_weight_l_28
DEBUG 01-06 17:11:12.139660.139660 cuda_h.py:19] end start_load_qkvogn_s_weight_l_28 cost 1.2874603271484375e-05 seconds
DEBUG 01-06 17:11:12.140979.140979 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-06 17:11:12.140796.140796 mlpmodule.py:367] cuda:1 cuda:1
DEBUG 01-06 17:11:12.140284.140284 cuda_h.py:10] start self_attn
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-06 17:11:12.142984.142984 cuda_h.py:19] end self_attn cost 0.002458333969116211 seconds
DEBUG 01-06 17:11:12.143325.143325 cuda_h.py:19] end iln_self_attn_paln cost 0.0031719207763671875 seconds
DEBUG 01-06 17:11:12.143353.143353 cuda_h.py:10] start layer_moe_generate_27
DEBUG 01-06 17:11:12.143613.143613 cuda_h.py:10] start gate
DEBUG 01-06 17:11:12.143827.143827 cuda_h.py:19] end gate cost 0.0006163120269775391 seconds
DEBUG 01-06 17:11:12.144703.144703 cuda_h.py:10] start experts_map_get
DEBUG 01-06 17:11:12.144911.144911 lmp.py:403] 
DEBUG 01-06 17:11:12.144911.144911 lmp.py:403] Expert Token Distribution & Device Allocation:
DEBUG 01-06 17:11:12.144475.144475 lmp.py:404]   Total experts: 64
DEBUG 01-06 17:11:12.144125.144125 lmp.py:405]   CPU experts: 32 (50%)
DEBUG 01-06 17:11:12.144112.144112 lmp.py:406]   GPU experts: 32 (50%)
DEBUG 01-06 17:11:12.144994.144994 lmp.py:407] 
DEBUG 01-06 17:11:12.144994.144994 lmp.py:407]   Expert ID | Tokens | Device
DEBUG 01-06 17:11:12.144637.144637 lmp.py:408]   -----------------------------------
DEBUG 01-06 17:11:12.144717.144717 lmp.py:414]   Expert 18 |     61 | CPU
DEBUG 01-06 17:11:12.144599.144599 lmp.py:414]   Expert 47 |     73 | CPU
DEBUG 01-06 17:11:12.144765.144765 lmp.py:414]   Expert 54 |     73 | CPU
DEBUG 01-06 17:11:12.144500.144500 lmp.py:414]   Expert 23 |     77 | CPU
DEBUG 01-06 17:11:12.144236.144236 lmp.py:414]   Expert 45 |     79 | CPU
DEBUG 01-06 17:11:12.144972.144972 lmp.py:414]   Expert 48 |     79 | CPU
DEBUG 01-06 17:11:12.144946.144946 lmp.py:414]   Expert 44 |     80 | CPU
DEBUG 01-06 17:11:12.144920.144920 lmp.py:414]   Expert 20 |     89 | CPU
DEBUG 01-06 17:11:12.144417.144417 lmp.py:414]   Expert 31 |     98 | CPU
DEBUG 01-06 17:11:12.144391.144391 lmp.py:414]   Expert 36 |    113 | CPU
DEBUG 01-06 17:11:12.144888.144888 lmp.py:414]   Expert 61 |    113 | CPU
DEBUG 01-06 17:11:12.144816.144816 lmp.py:414]   Expert 42 |    114 | CPU
DEBUG 01-06 17:11:12.144744.144744 lmp.py:414]   Expert 10 |    119 | CPU
DEBUG 01-06 17:11:12.144194.144194 lmp.py:414]   Expert 33 |    119 | CPU
DEBUG 01-06 17:11:12.144407.144407 lmp.py:414]   Expert 24 |    120 | CPU
DEBUG 01-06 17:11:12.144858.144858 lmp.py:414]   Expert 11 |    122 | CPU
DEBUG 01-06 17:11:12.144832.144832 lmp.py:414]   Expert 43 |    130 | CPU
DEBUG 01-06 17:11:12.144567.144567 lmp.py:414]   Expert 49 |    131 | CPU
DEBUG 01-06 17:11:12.144303.144303 lmp.py:414]   Expert 56 |    131 | CPU
DEBUG 01-06 17:11:12.144039.144039 lmp.py:414]   Expert  6 |    140 | CPU
DEBUG 01-06 17:11:12.144251.144251 lmp.py:414]   Expert 51 |    141 | CPU
DEBUG 01-06 17:11:12.144464.144464 lmp.py:414]   Expert  0 |    146 | CPU
DEBUG 01-06 17:11:12.144199.144199 lmp.py:414]   Expert 17 |    154 | CPU
DEBUG 01-06 17:11:12.144935.144935 lmp.py:414]   Expert  5 |    155 | CPU
DEBUG 01-06 17:11:12.144670.144670 lmp.py:414]   Expert 40 |    155 | CPU
DEBUG 01-06 17:11:12.144883.144883 lmp.py:414]   Expert 12 |    160 | CPU
DEBUG 01-06 17:11:12.144334.144334 lmp.py:414]   Expert 59 |    160 | CPU
DEBUG 01-06 17:11:12.144308.144308 lmp.py:414]   Expert 55 |    163 | CPU
DEBUG 01-06 17:11:12.144759.144759 lmp.py:414]   Expert 13 |    164 | CPU
DEBUG 01-06 17:11:12.144448.144448 lmp.py:414]   Expert 57 |    164 | CPU
DEBUG 01-06 17:11:12.144945.144945 lmp.py:414]   Expert 26 |    167 | CPU
DEBUG 01-06 17:11:12.144681.144681 lmp.py:414]   Expert 46 |    170 | CPU
DEBUG 01-06 17:11:12.144417.144417 lmp.py:414]   Expert 58 |    171 | GPU
DEBUG 01-06 17:11:12.144152.144152 lmp.py:414]   Expert 38 |    173 | GPU
DEBUG 01-06 17:11:12.145888.145888 lmp.py:414]   Expert 30 |    174 | GPU
DEBUG 01-06 17:11:12.145623.145623 lmp.py:414]   Expert 35 |    175 | GPU
DEBUG 01-06 17:11:12.145121.145121 lmp.py:414]   Expert  7 |    182 | GPU
DEBUG 01-06 17:11:12.145856.145856 lmp.py:414]   Expert 16 |    185 | GPU
DEBUG 01-06 17:11:12.145115.145115 lmp.py:414]   Expert 50 |    185 | GPU
DEBUG 01-06 17:11:12.145089.145089 lmp.py:414]   Expert 32 |    196 | GPU
DEBUG 01-06 17:11:12.145302.145302 lmp.py:414]   Expert 15 |    199 | GPU
DEBUG 01-06 17:11:12.145276.145276 lmp.py:414]   Expert  3 |    203 | GPU
DEBUG 01-06 17:11:12.145726.145726 lmp.py:414]   Expert 14 |    204 | GPU
DEBUG 01-06 17:11:12.145416.145416 lmp.py:414]   Expert  1 |    213 | GPU
DEBUG 01-06 17:11:12.145675.145675 lmp.py:414]   Expert  4 |    225 | GPU
DEBUG 01-06 17:11:12.145172.145172 lmp.py:414]   Expert 39 |    229 | GPU
DEBUG 01-06 17:11:12.145431.145431 lmp.py:414]   Expert 52 |    238 | GPU
DEBUG 01-06 17:11:12.145689.145689 lmp.py:414]   Expert 25 |    248 | GPU
DEBUG 01-06 17:11:12.145948.145948 lmp.py:414]   Expert 34 |    248 | GPU
DEBUG 01-06 17:11:12.145445.145445 lmp.py:414]   Expert 28 |    251 | GPU
DEBUG 01-06 17:11:12.145704.145704 lmp.py:414]   Expert 22 |    259 | GPU
DEBUG 01-06 17:11:12.145963.145963 lmp.py:414]   Expert 21 |    276 | GPU
DEBUG 01-06 17:11:12.145222.145222 lmp.py:414]   Expert  2 |    278 | GPU
DEBUG 01-06 17:11:12.145673.145673 lmp.py:414]   Expert 41 |    280 | GPU
DEBUG 01-06 17:11:12.145647.145647 lmp.py:414]   Expert 29 |    283 | GPU
DEBUG 01-06 17:11:12.145382.145382 lmp.py:414]   Expert 60 |    289 | GPU
DEBUG 01-06 17:11:12.145595.145595 lmp.py:414]   Expert 63 |    290 | GPU
DEBUG 01-06 17:11:12.145807.145807 lmp.py:414]   Expert 62 |    298 | GPU
DEBUG 01-06 17:11:12.145066.145066 lmp.py:414]   Expert 27 |    312 | GPU
DEBUG 01-06 17:11:12.145325.145325 lmp.py:414]   Expert 53 |    332 | GPU
DEBUG 01-06 17:11:12.145584.145584 lmp.py:414]   Expert  8 |    335 | GPU
DEBUG 01-06 17:11:12.145604.145604 lmp.py:414]   Expert 37 |    344 | GPU
DEBUG 01-06 17:11:12.145101.145101 lmp.py:414]   Expert 19 |    443 | GPU
DEBUG 01-06 17:11:12.145121.145121 lmp.py:414]   Expert  9 |    610 | GPU
DEBUG 01-06 17:11:12.145857.145857 lmp.py:415] 
DEBUG 01-06 17:11:12.145857.145857 lmp.py:415]   CPU total tokens: 3960 (32.2%)
DEBUG 01-06 17:11:12.145308.145308 lmp.py:416]   GPU total tokens: 8328 (67.8%)
DEBUG 01-06 17:11:12.145481.145481 cuda_h.py:19] end experts_map_get cost 0.0014584064483642578 seconds
DEBUG 01-06 17:11:12.145885.145885 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-06 17:11:12.145192.145192 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 17:11:12.145389.145389 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 17:11:12.146421.146421 cuda_h.py:19] end allocate_cuda_memory cost 0.0003426074981689453 seconds
DEBUG 01-06 17:11:12.146364.146364 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 17:11:12.146835.146835 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 17:11:12.146128.146128 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 17:11:12.146208.146208 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, df3b622a-4a24-497a-a1b2-336b685f286d
DEBUG 01-06 17:11:12.146016.146016 client.py:106] call stub.LoadModelAsync
INFO 01-06 17:11:12.148849.148849 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, df3b622a-4a24-497a-a1b2-336b685f286d
DEBUG 01-06 17:11:12.148363.148363 cuda_h.py:19] end load_into_gpu_async cost 0.0025169849395751953 seconds
DEBUG 01-06 17:11:12.148604.148604 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 17:11:12.149916.149916 cuda_h.py:19] end restore_tensors2 cost 0.0005552768707275391 seconds
DEBUG 01-06 17:11:12.149885.149885 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0038590431213378906 seconds
DEBUG 01-06 17:11:12.152978.152978 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.006503582000732422 seconds
DEBUG 01-06 17:11:12.152424.152424 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-06 17:11:12.152386.152386 lmp.py:461] 
DEBUG 01-06 17:11:12.152386.152386 lmp.py:461]   Computing 32 experts on CPU...
DEBUG 01-06 17:11:12.152952.152952 cuda_h.py:19] end cpu_experts_submit cost 0.00011515617370605469 seconds
DEBUG 01-06 17:11:12.152363.152363 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-06 17:11:12.158068.158068 mlpmodule.py:706] group tensors cost 0.0057830810546875 s
DEBUG 01-06 17:11:12.161005.161005 mlpmodule.py:744] pad cost 0.002156972885131836 s
DEBUG 01-06 17:11:12.161566.161566 mlpmodule.py:750] create cpu tensor cost 5.3882598876953125e-05 s
DEBUG 01-06 17:11:12.161165.161165 mlpmodule.py:755] move to cpu cost 3.910064697265625e-05 s
DEBUG 01-06 17:11:12.170926.170926 mlpmodule.py:769] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-06 17:11:12.170975.170975 mlpmodule.py:770] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-06 17:11:12.171633.171633 mlpmodule.py:775] group_w3 first element: -0.006439208984375
WARNING 01-06 17:11:12.171192.171192 mlpmodule.py:785] start einsum2
DEBUG 01-06 17:11:12.187278.187278 mlpmodule.py:795] group einsum cost 0.026467323303222656 s
DEBUG 01-06 17:11:12.188377.188377 mlpmodule.py:803] cpy2cputensor cost 0.0006802082061767578 s
DEBUG 01-06 17:11:12.193238.193238 cuda_h.py:19] end wait_cetm_experts cost 0.04069828987121582 seconds
DEBUG 01-06 17:11:12.193397.193397 cuda_h.py:10] start gpu_sexperts
DEBUG 01-06 17:11:12.193154.193154 cuda_h.py:19] end gpu_sexperts cost 0.0006170272827148438 seconds
DEBUG 01-06 17:11:12.193395.193395 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-06 17:11:12.194178.194178 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 1.1444091796875e-05 seconds
DEBUG 01-06 17:11:12.194596.194596 cuda_h.py:10] start wait_experts
INFO 01-06 17:11:12.194260.194260 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, df3b622a-4a24-497a-a1b2-336b685f286d
DEBUG 01-06 17:11:12.199582.199582 mlpmodule.py:664]  experts func einsum cost 0.0472722053527832 s
INFO 01-06 17:11:12.201318.201318 client.py:127] Model loaded
DEBUG 01-06 17:11:12.202931.202931 cuda_h.py:19] end wait_experts cost 0.007971525192260742 seconds
DEBUG 01-06 17:11:12.202455.202455 cuda_h.py:10] start gpu_experts
DEBUG 01-06 17:11:12.202688.202688 lmp.py:506]   Computing 32 experts on GPU...
DEBUG 01-06 17:11:12.202360.202360 mlpmodule.py:533] gpu group tensors cost 0.0006160736083984375 s
DEBUG 01-06 17:11:12.204536.204536 mlpmodule.py:566] gpu pad cost 0.0016143321990966797 s
DEBUG 01-06 17:11:12.205409.205409 mlpmodule.py:584] gpu group einsum cost 0.0004906654357910156 s
DEBUG 01-06 17:11:12.207646.207646 mlpmodule.py:613] gpu experts func einsum cost 0.00577855110168457 s
DEBUG 01-06 17:11:12.208722.208722 cuda_h.py:19] end gpu_experts cost 0.00596165657043457 seconds
DEBUG 01-06 17:11:12.208672.208672 cuda_h.py:19] end layer_moe_generate_27 cost 0.06486654281616211 seconds
DEBUG 01-06 17:11:12.208791.208791 lmp.py:220] -------------------------------- end layer 27 --------------------------------
DEBUG 01-06 17:11:12.208681.208681 cuda_h.py:19] end multi_layer cost 2.0479795932769775 seconds
DEBUG 01-06 17:11:12.208900.208900 cuda_h.py:10] start decode_layer
DEBUG 01-06 17:11:12.222194.222194 cuda_h.py:10] start async_load_ce
INFO 01-06 17:11:12.222872.222872 cuda_memory_view.py:165] Collecting expert device distribution for all layers...
INFO 01-06 17:11:12.223491.223491 cuda_memory_view.py:189] Layer 1: CPU experts = [0, 1, 3, 10, 11, 13, 17, 18, 22, 25, 27, 28, 31, 32, 34, 35, 36, 37, 38, 41, 43, 44, 47, 49, 51, 52, 54, 55, 58, 59, 60, 62] (total: 32, device_map: {0: 'meta', 1: 'meta', 2: 'cuda:1', 3: 'meta', 4: 'cuda:1', 5: 'cuda:1', 6: 'cuda:1', 7: 'cuda:1', 8: 'cuda:1', 9: 'cuda:1', 10: 'meta', 11: 'meta', 12: 'cuda:1', 13: 'meta', 14: 'cuda:1', 15: 'cuda:1', 16: 'cuda:1', 17: 'meta', 18: 'meta', 19: 'cuda:1', 20: 'cuda:1', 21: 'cuda:1', 22: 'meta', 23: 'cuda:1', 24: 'cuda:1', 25: 'meta', 26: 'cuda:1', 27: 'meta', 28: 'meta', 29: 'cuda:1', 30: 'cuda:1', 31: 'meta', 32: 'meta', 33: 'cuda:1', 34: 'meta', 35: 'meta', 36: 'meta', 37: 'meta', 38: 'meta', 39: 'cuda:1', 40: 'cuda:1', 41: 'meta', 42: 'cuda:1', 43: 'meta', 44: 'meta', 45: 'cuda:1', 46: 'cuda:1', 47: 'meta', 48: 'cuda:1', 49: 'meta', 50: 'cuda:1', 51: 'meta', 52: 'meta', 53: 'cuda:1', 54: 'meta', 55: 'meta', 56: 'cuda:1', 57: 'cuda:1', 58: 'meta', 59: 'meta', 60: 'meta', 61: 'cuda:1', 62: 'meta', 63: 'cuda:1'})
INFO 01-06 17:11:12.223096.223096 cuda_memory_view.py:189] Layer 2: CPU experts = [0, 1, 3, 6, 7, 8, 9, 12, 15, 17, 23, 24, 25, 26, 27, 28, 29, 30, 32, 33, 34, 35, 36, 37, 45, 48, 49, 51, 54, 57, 58, 62] (total: 32, device_map: {0: 'meta', 1: 'meta', 2: 'cuda:1', 3: 'meta', 4: 'cuda:1', 5: 'cuda:1', 6: 'meta', 7: 'meta', 8: 'meta', 9: 'meta', 10: 'cuda:1', 11: 'cuda:1', 12: 'meta', 13: 'cuda:1', 14: 'cuda:1', 15: 'meta', 16: 'cuda:1', 17: 'meta', 18: 'cuda:1', 19: 'cuda:1', 20: 'cuda:1', 21: 'cuda:1', 22: 'cuda:1', 23: 'meta', 24: 'meta', 25: 'meta', 26: 'meta', 27: 'meta', 28: 'meta', 29: 'meta', 30: 'meta', 31: 'cuda:1', 32: 'meta', 33: 'meta', 34: 'meta', 35: 'meta', 36: 'meta', 37: 'meta', 38: 'cuda:1', 39: 'cuda:1', 40: 'cuda:1', 41: 'cuda:1', 42: 'cuda:1', 43: 'cuda:1', 44: 'cuda:1', 45: 'meta', 46: 'cuda:1', 47: 'cuda:1', 48: 'meta', 49: 'meta', 50: 'cuda:1', 51: 'meta', 52: 'cuda:1', 53: 'cuda:1', 54: 'meta', 55: 'cuda:1', 56: 'cuda:1', 57: 'meta', 58: 'meta', 59: 'cuda:1', 60: 'cuda:1', 61: 'cuda:1', 62: 'meta', 63: 'cuda:1'})
INFO 01-06 17:11:12.224242.224242 cuda_memory_view.py:189] Layer 3: CPU experts = [1, 2, 4, 5, 6, 7, 9, 11, 15, 16, 18, 23, 26, 27, 30, 32, 34, 35, 36, 37, 39, 40, 42, 45, 48, 49, 50, 51, 52, 56, 59, 61] (total: 32, device_map: {0: 'cuda:1', 1: 'meta', 2: 'meta', 3: 'cuda:1', 4: 'meta', 5: 'meta', 6: 'meta', 7: 'meta', 8: 'cuda:1', 9: 'meta', 10: 'cuda:1', 11: 'meta', 12: 'cuda:1', 13: 'cuda:1', 14: 'cuda:1', 15: 'meta', 16: 'meta', 17: 'cuda:1', 18: 'meta', 19: 'cuda:1', 20: 'cuda:1', 21: 'cuda:1', 22: 'cuda:1', 23: 'meta', 24: 'cuda:1', 25: 'cuda:1', 26: 'meta', 27: 'meta', 28: 'cuda:1', 29: 'cuda:1', 30: 'meta', 31: 'cuda:1', 32: 'meta', 33: 'cuda:1', 34: 'meta', 35: 'meta', 36: 'meta', 37: 'meta', 38: 'cuda:1', 39: 'meta', 40: 'meta', 41: 'cuda:1', 42: 'meta', 43: 'cuda:1', 44: 'cuda:1', 45: 'meta', 46: 'cuda:1', 47: 'cuda:1', 48: 'meta', 49: 'meta', 50: 'meta', 51: 'meta', 52: 'meta', 53: 'cuda:1', 54: 'cuda:1', 55: 'cuda:1', 56: 'meta', 57: 'cuda:1', 58: 'cuda:1', 59: 'meta', 60: 'cuda:1', 61: 'meta', 62: 'cuda:1', 63: 'cuda:1'})
INFO 01-06 17:11:12.224250.224250 cuda_memory_view.py:189] Layer 4: CPU experts = [4, 8, 9, 10, 11, 13, 14, 16, 17, 20, 26, 27, 28, 29, 30, 31, 32, 34, 36, 41, 42, 44, 45, 47, 51, 53, 54, 57, 58, 60, 61, 63] (total: 32, device_map: {0: 'cuda:1', 1: 'cuda:1', 2: 'cuda:1', 3: 'cuda:1', 4: 'meta', 5: 'cuda:1', 6: 'cuda:1', 7: 'cuda:1', 8: 'meta', 9: 'meta', 10: 'meta', 11: 'meta', 12: 'cuda:1', 13: 'meta', 14: 'meta', 15: 'cuda:1', 16: 'meta', 17: 'meta', 18: 'cuda:1', 19: 'cuda:1', 20: 'meta', 21: 'cuda:1', 22: 'cuda:1', 23: 'cuda:1', 24: 'cuda:1', 25: 'cuda:1', 26: 'meta', 27: 'meta', 28: 'meta', 29: 'meta', 30: 'meta', 31: 'meta', 32: 'meta', 33: 'cuda:1', 34: 'meta', 35: 'cuda:1', 36: 'meta', 37: 'cuda:1', 38: 'cuda:1', 39: 'cuda:1', 40: 'cuda:1', 41: 'meta', 42: 'meta', 43: 'cuda:1', 44: 'meta', 45: 'meta', 46: 'cuda:1', 47: 'meta', 48: 'cuda:1', 49: 'cuda:1', 50: 'cuda:1', 51: 'meta', 52: 'cuda:1', 53: 'meta', 54: 'meta', 55: 'cuda:1', 56: 'cuda:1', 57: 'meta', 58: 'meta', 59: 'cuda:1', 60: 'meta', 61: 'meta', 62: 'cuda:1', 63: 'meta'})
INFO 01-06 17:11:12.224105.224105 cuda_memory_view.py:189] Layer 5: CPU experts = [0, 2, 3, 4, 5, 8, 12, 13, 14, 15, 16, 17, 22, 23, 25, 28, 30, 31, 32, 34, 35, 36, 39, 41, 42, 44, 45, 46, 52, 57, 60, 61] (total: 32, device_map: {0: 'meta', 1: 'cuda:1', 2: 'meta', 3: 'meta', 4: 'meta', 5: 'meta', 6: 'cuda:1', 7: 'cuda:1', 8: 'meta', 9: 'cuda:1', 10: 'cuda:1', 11: 'cuda:1', 12: 'meta', 13: 'meta', 14: 'meta', 15: 'meta', 16: 'meta', 17: 'meta', 18: 'cuda:1', 19: 'cuda:1', 20: 'cuda:1', 21: 'cuda:1', 22: 'meta', 23: 'meta', 24: 'cuda:1', 25: 'meta', 26: 'cuda:1', 27: 'cuda:1', 28: 'meta', 29: 'cuda:1', 30: 'meta', 31: 'meta', 32: 'meta', 33: 'cuda:1', 34: 'meta', 35: 'meta', 36: 'meta', 37: 'cuda:1', 38: 'cuda:1', 39: 'meta', 40: 'cuda:1', 41: 'meta', 42: 'meta', 43: 'cuda:1', 44: 'meta', 45: 'meta', 46: 'meta', 47: 'cuda:1', 48: 'cuda:1', 49: 'cuda:1', 50: 'cuda:1', 51: 'cuda:1', 52: 'meta', 53: 'cuda:1', 54: 'cuda:1', 55: 'cuda:1', 56: 'cuda:1', 57: 'meta', 58: 'cuda:1', 59: 'cuda:1', 60: 'meta', 61: 'meta', 62: 'cuda:1', 63: 'cuda:1'})
INFO 01-06 17:11:12.225384.225384 cuda_memory_view.py:189] Layer 6: CPU experts = [0, 1, 2, 3, 7, 9, 10, 11, 13, 14, 16, 17, 18, 22, 23, 26, 28, 29, 32, 33, 34, 37, 43, 45, 51, 53, 54, 55, 58, 59, 62, 63] (total: 32, device_map: {0: 'meta', 1: 'meta', 2: 'meta', 3: 'meta', 4: 'cuda:1', 5: 'cuda:1', 6: 'cuda:1', 7: 'meta', 8: 'cuda:1', 9: 'meta', 10: 'meta', 11: 'meta', 12: 'cuda:1', 13: 'meta', 14: 'meta', 15: 'cuda:1', 16: 'meta', 17: 'meta', 18: 'meta', 19: 'cuda:1', 20: 'cuda:1', 21: 'cuda:1', 22: 'meta', 23: 'meta', 24: 'cuda:1', 25: 'cuda:1', 26: 'meta', 27: 'cuda:1', 28: 'meta', 29: 'meta', 30: 'cuda:1', 31: 'cuda:1', 32: 'meta', 33: 'meta', 34: 'meta', 35: 'cuda:1', 36: 'cuda:1', 37: 'meta', 38: 'cuda:1', 39: 'cuda:1', 40: 'cuda:1', 41: 'cuda:1', 42: 'cuda:1', 43: 'meta', 44: 'cuda:1', 45: 'meta', 46: 'cuda:1', 47: 'cuda:1', 48: 'cuda:1', 49: 'cuda:1', 50: 'cuda:1', 51: 'meta', 52: 'cuda:1', 53: 'meta', 54: 'meta', 55: 'meta', 56: 'cuda:1', 57: 'cuda:1', 58: 'meta', 59: 'meta', 60: 'cuda:1', 61: 'cuda:1', 62: 'meta', 63: 'meta'})
INFO 01-06 17:11:12.225517.225517 cuda_memory_view.py:189] Layer 7: CPU experts = [1, 3, 4, 6, 7, 8, 10, 11, 13, 14, 15, 16, 18, 20, 27, 28, 29, 36, 39, 40, 41, 43, 45, 46, 48, 50, 51, 52, 54, 55, 56, 60] (total: 32, device_map: {0: 'cuda:1', 1: 'meta', 2: 'cuda:1', 3: 'meta', 4: 'meta', 5: 'cuda:1', 6: 'meta', 7: 'meta', 8: 'meta', 9: 'cuda:1', 10: 'meta', 11: 'meta', 12: 'cuda:1', 13: 'meta', 14: 'meta', 15: 'meta', 16: 'meta', 17: 'cuda:1', 18: 'meta', 19: 'cuda:1', 20: 'meta', 21: 'cuda:1', 22: 'cuda:1', 23: 'cuda:1', 24: 'cuda:1', 25: 'cuda:1', 26: 'cuda:1', 27: 'meta', 28: 'meta', 29: 'meta', 30: 'cuda:1', 31: 'cuda:1', 32: 'cuda:1', 33: 'cuda:1', 34: 'cuda:1', 35: 'cuda:1', 36: 'meta', 37: 'cuda:1', 38: 'cuda:1', 39: 'meta', 40: 'meta', 41: 'meta', 42: 'cuda:1', 43: 'meta', 44: 'cuda:1', 45: 'meta', 46: 'meta', 47: 'cuda:1', 48: 'meta', 49: 'cuda:1', 50: 'meta', 51: 'meta', 52: 'meta', 53: 'cuda:1', 54: 'meta', 55: 'meta', 56: 'meta', 57: 'cuda:1', 58: 'cuda:1', 59: 'cuda:1', 60: 'meta', 61: 'cuda:1', 62: 'cuda:1', 63: 'cuda:1'})
INFO 01-06 17:11:12.226266.226266 cuda_memory_view.py:189] Layer 8: CPU experts = [0, 1, 6, 7, 8, 12, 14, 15, 16, 17, 18, 22, 24, 27, 29, 30, 32, 33, 34, 35, 36, 38, 39, 40, 42, 44, 48, 51, 53, 54, 59, 60] (total: 32, device_map: {0: 'meta', 1: 'meta', 2: 'cuda:1', 3: 'cuda:1', 4: 'cuda:1', 5: 'cuda:1', 6: 'meta', 7: 'meta', 8: 'meta', 9: 'cuda:1', 10: 'cuda:1', 11: 'cuda:1', 12: 'meta', 13: 'cuda:1', 14: 'meta', 15: 'meta', 16: 'meta', 17: 'meta', 18: 'meta', 19: 'cuda:1', 20: 'cuda:1', 21: 'cuda:1', 22: 'meta', 23: 'cuda:1', 24: 'meta', 25: 'cuda:1', 26: 'cuda:1', 27: 'meta', 28: 'cuda:1', 29: 'meta', 30: 'meta', 31: 'cuda:1', 32: 'meta', 33: 'meta', 34: 'meta', 35: 'meta', 36: 'meta', 37: 'cuda:1', 38: 'meta', 39: 'meta', 40: 'meta', 41: 'cuda:1', 42: 'meta', 43: 'cuda:1', 44: 'meta', 45: 'cuda:1', 46: 'cuda:1', 47: 'cuda:1', 48: 'meta', 49: 'cuda:1', 50: 'cuda:1', 51: 'meta', 52: 'cuda:1', 53: 'meta', 54: 'meta', 55: 'cuda:1', 56: 'cuda:1', 57: 'cuda:1', 58: 'cuda:1', 59: 'meta', 60: 'meta', 61: 'cuda:1', 62: 'cuda:1', 63: 'cuda:1'})
INFO 01-06 17:11:12.226591.226591 cuda_memory_view.py:189] Layer 9: CPU experts = [2, 3, 4, 5, 7, 10, 12, 13, 15, 16, 17, 19, 20, 22, 23, 24, 25, 26, 27, 28, 32, 35, 36, 37, 40, 41, 47, 49, 50, 53, 59, 60] (total: 32, device_map: {0: 'cuda:1', 1: 'cuda:1', 2: 'meta', 3: 'meta', 4: 'meta', 5: 'meta', 6: 'cuda:1', 7: 'meta', 8: 'cuda:1', 9: 'cuda:1', 10: 'meta', 11: 'cuda:1', 12: 'meta', 13: 'meta', 14: 'cuda:1', 15: 'meta', 16: 'meta', 17: 'meta', 18: 'cuda:1', 19: 'meta', 20: 'meta', 21: 'cuda:1', 22: 'meta', 23: 'meta', 24: 'meta', 25: 'meta', 26: 'meta', 27: 'meta', 28: 'meta', 29: 'cuda:1', 30: 'cuda:1', 31: 'cuda:1', 32: 'meta', 33: 'cuda:1', 34: 'cuda:1', 35: 'meta', 36: 'meta', 37: 'meta', 38: 'cuda:1', 39: 'cuda:1', 40: 'meta', 41: 'meta', 42: 'cuda:1', 43: 'cuda:1', 44: 'cuda:1', 45: 'cuda:1', 46: 'cuda:1', 47: 'meta', 48: 'cuda:1', 49: 'meta', 50: 'meta', 51: 'cuda:1', 52: 'cuda:1', 53: 'meta', 54: 'cuda:1', 55: 'cuda:1', 56: 'cuda:1', 57: 'cuda:1', 58: 'cuda:1', 59: 'meta', 60: 'meta', 61: 'cuda:1', 62: 'cuda:1', 63: 'cuda:1'})
INFO 01-06 17:11:12.226691.226691 cuda_memory_view.py:189] Layer 10: CPU experts = [2, 3, 4, 5, 6, 7, 12, 14, 15, 17, 19, 22, 26, 27, 28, 31, 34, 37, 38, 43, 45, 47, 48, 51, 52, 54, 55, 56, 57, 60, 61, 63] (total: 32, device_map: {0: 'cuda:1', 1: 'cuda:1', 2: 'meta', 3: 'meta', 4: 'meta', 5: 'meta', 6: 'meta', 7: 'meta', 8: 'cuda:1', 9: 'cuda:1', 10: 'cuda:1', 11: 'cuda:1', 12: 'meta', 13: 'cuda:1', 14: 'meta', 15: 'meta', 16: 'cuda:1', 17: 'meta', 18: 'cuda:1', 19: 'meta', 20: 'cuda:1', 21: 'cuda:1', 22: 'meta', 23: 'cuda:1', 24: 'cuda:1', 25: 'cuda:1', 26: 'meta', 27: 'meta', 28: 'meta', 29: 'cuda:1', 30: 'cuda:1', 31: 'meta', 32: 'cuda:1', 33: 'cuda:1', 34: 'meta', 35: 'cuda:1', 36: 'cuda:1', 37: 'meta', 38: 'meta', 39: 'cuda:1', 40: 'cuda:1', 41: 'cuda:1', 42: 'cuda:1', 43: 'meta', 44: 'cuda:1', 45: 'meta', 46: 'cuda:1', 47: 'meta', 48: 'meta', 49: 'cuda:1', 50: 'cuda:1', 51: 'meta', 52: 'meta', 53: 'cuda:1', 54: 'meta', 55: 'meta', 56: 'meta', 57: 'meta', 58: 'cuda:1', 59: 'cuda:1', 60: 'meta', 61: 'meta', 62: 'cuda:1', 63: 'meta'})
INFO 01-06 17:11:12.227308.227308 cuda_memory_view.py:189] Layer 11: CPU experts = [2, 3, 6, 9, 13, 15, 16, 17, 18, 19, 20, 23, 26, 31, 32, 33, 35, 36, 38, 39, 40, 41, 42, 43, 44, 46, 49, 50, 59, 61, 62, 63] (total: 32, device_map: {0: 'cuda:1', 1: 'cuda:1', 2: 'meta', 3: 'meta', 4: 'cuda:1', 5: 'cuda:1', 6: 'meta', 7: 'cuda:1', 8: 'cuda:1', 9: 'meta', 10: 'cuda:1', 11: 'cuda:1', 12: 'cuda:1', 13: 'meta', 14: 'cuda:1', 15: 'meta', 16: 'meta', 17: 'meta', 18: 'meta', 19: 'meta', 20: 'meta', 21: 'cuda:1', 22: 'cuda:1', 23: 'meta', 24: 'cuda:1', 25: 'cuda:1', 26: 'meta', 27: 'cuda:1', 28: 'cuda:1', 29: 'cuda:1', 30: 'cuda:1', 31: 'meta', 32: 'meta', 33: 'meta', 34: 'cuda:1', 35: 'meta', 36: 'meta', 37: 'cuda:1', 38: 'meta', 39: 'meta', 40: 'meta', 41: 'meta', 42: 'meta', 43: 'meta', 44: 'meta', 45: 'cuda:1', 46: 'meta', 47: 'cuda:1', 48: 'cuda:1', 49: 'meta', 50: 'meta', 51: 'cuda:1', 52: 'cuda:1', 53: 'cuda:1', 54: 'cuda:1', 55: 'cuda:1', 56: 'cuda:1', 57: 'cuda:1', 58: 'cuda:1', 59: 'meta', 60: 'cuda:1', 61: 'meta', 62: 'meta', 63: 'meta'})
INFO 01-06 17:11:12.227203.227203 cuda_memory_view.py:189] Layer 12: CPU experts = [0, 2, 4, 7, 8, 11, 12, 13, 14, 16, 17, 18, 20, 21, 22, 27, 32, 34, 37, 38, 39, 43, 44, 45, 47, 52, 53, 57, 58, 60, 61, 63] (total: 32, device_map: {0: 'meta', 1: 'cuda:1', 2: 'meta', 3: 'cuda:1', 4: 'meta', 5: 'cuda:1', 6: 'cuda:1', 7: 'meta', 8: 'meta', 9: 'cuda:1', 10: 'cuda:1', 11: 'meta', 12: 'meta', 13: 'meta', 14: 'meta', 15: 'cuda:1', 16: 'meta', 17: 'meta', 18: 'meta', 19: 'cuda:1', 20: 'meta', 21: 'meta', 22: 'meta', 23: 'cuda:1', 24: 'cuda:1', 25: 'cuda:1', 26: 'cuda:1', 27: 'meta', 28: 'cuda:1', 29: 'cuda:1', 30: 'cuda:1', 31: 'cuda:1', 32: 'meta', 33: 'cuda:1', 34: 'meta', 35: 'cuda:1', 36: 'cuda:1', 37: 'meta', 38: 'meta', 39: 'meta', 40: 'cuda:1', 41: 'cuda:1', 42: 'cuda:1', 43: 'meta', 44: 'meta', 45: 'meta', 46: 'cuda:1', 47: 'meta', 48: 'cuda:1', 49: 'cuda:1', 50: 'cuda:1', 51: 'cuda:1', 52: 'meta', 53: 'meta', 54: 'cuda:1', 55: 'cuda:1', 56: 'cuda:1', 57: 'meta', 58: 'meta', 59: 'cuda:1', 60: 'meta', 61: 'meta', 62: 'cuda:1', 63: 'meta'})
INFO 01-06 17:11:12.228197.228197 cuda_memory_view.py:189] Layer 13: CPU experts = [1, 2, 4, 5, 6, 9, 10, 11, 12, 13, 18, 19, 20, 26, 30, 31, 32, 33, 34, 35, 40, 42, 46, 48, 50, 53, 55, 56, 58, 59, 61, 63] (total: 32, device_map: {0: 'cuda:1', 1: 'meta', 2: 'meta', 3: 'cuda:1', 4: 'meta', 5: 'meta', 6: 'meta', 7: 'cuda:1', 8: 'cuda:1', 9: 'meta', 10: 'meta', 11: 'meta', 12: 'meta', 13: 'meta', 14: 'cuda:1', 15: 'cuda:1', 16: 'cuda:1', 17: 'cuda:1', 18: 'meta', 19: 'meta', 20: 'meta', 21: 'cuda:1', 22: 'cuda:1', 23: 'cuda:1', 24: 'cuda:1', 25: 'cuda:1', 26: 'meta', 27: 'cuda:1', 28: 'cuda:1', 29: 'cuda:1', 30: 'meta', 31: 'meta', 32: 'meta', 33: 'meta', 34: 'meta', 35: 'meta', 36: 'cuda:1', 37: 'cuda:1', 38: 'cuda:1', 39: 'cuda:1', 40: 'meta', 41: 'cuda:1', 42: 'meta', 43: 'cuda:1', 44: 'cuda:1', 45: 'cuda:1', 46: 'meta', 47: 'cuda:1', 48: 'meta', 49: 'cuda:1', 50: 'meta', 51: 'cuda:1', 52: 'cuda:1', 53: 'meta', 54: 'cuda:1', 55: 'meta', 56: 'meta', 57: 'cuda:1', 58: 'meta', 59: 'meta', 60: 'cuda:1', 61: 'meta', 62: 'cuda:1', 63: 'meta'})
INFO 01-06 17:11:12.228522.228522 cuda_memory_view.py:189] Layer 14: CPU experts = [0, 7, 8, 12, 13, 15, 16, 17, 18, 19, 21, 22, 27, 29, 31, 34, 35, 36, 38, 39, 40, 41, 45, 48, 49, 50, 52, 53, 54, 59, 60, 61] (total: 32, device_map: {0: 'meta', 1: 'cuda:1', 2: 'cuda:1', 3: 'cuda:1', 4: 'cuda:1', 5: 'cuda:1', 6: 'cuda:1', 7: 'meta', 8: 'meta', 9: 'cuda:1', 10: 'cuda:1', 11: 'cuda:1', 12: 'meta', 13: 'meta', 14: 'cuda:1', 15: 'meta', 16: 'meta', 17: 'meta', 18: 'meta', 19: 'meta', 20: 'cuda:1', 21: 'meta', 22: 'meta', 23: 'cuda:1', 24: 'cuda:1', 25: 'cuda:1', 26: 'cuda:1', 27: 'meta', 28: 'cuda:1', 29: 'meta', 30: 'cuda:1', 31: 'meta', 32: 'cuda:1', 33: 'cuda:1', 34: 'meta', 35: 'meta', 36: 'meta', 37: 'cuda:1', 38: 'meta', 39: 'meta', 40: 'meta', 41: 'meta', 42: 'cuda:1', 43: 'cuda:1', 44: 'cuda:1', 45: 'meta', 46: 'cuda:1', 47: 'cuda:1', 48: 'meta', 49: 'meta', 50: 'meta', 51: 'cuda:1', 52: 'meta', 53: 'meta', 54: 'meta', 55: 'cuda:1', 56: 'cuda:1', 57: 'cuda:1', 58: 'cuda:1', 59: 'meta', 60: 'meta', 61: 'meta', 62: 'cuda:1', 63: 'cuda:1'})
INFO 01-06 17:11:12.229754.229754 cuda_memory_view.py:189] Layer 15: CPU experts = [0, 2, 4, 5, 7, 10, 12, 13, 14, 15, 19, 20, 21, 22, 25, 28, 32, 34, 40, 41, 42, 45, 50, 51, 52, 53, 54, 55, 59, 61, 62, 63] (total: 32, device_map: {0: 'meta', 1: 'cuda:1', 2: 'meta', 3: 'cuda:1', 4: 'meta', 5: 'meta', 6: 'cuda:1', 7: 'meta', 8: 'cuda:1', 9: 'cuda:1', 10: 'meta', 11: 'cuda:1', 12: 'meta', 13: 'meta', 14: 'meta', 15: 'meta', 16: 'cuda:1', 17: 'cuda:1', 18: 'cuda:1', 19: 'meta', 20: 'meta', 21: 'meta', 22: 'meta', 23: 'cuda:1', 24: 'cuda:1', 25: 'meta', 26: 'cuda:1', 27: 'cuda:1', 28: 'meta', 29: 'cuda:1', 30: 'cuda:1', 31: 'cuda:1', 32: 'meta', 33: 'cuda:1', 34: 'meta', 35: 'cuda:1', 36: 'cuda:1', 37: 'cuda:1', 38: 'cuda:1', 39: 'cuda:1', 40: 'meta', 41: 'meta', 42: 'meta', 43: 'cuda:1', 44: 'cuda:1', 45: 'meta', 46: 'cuda:1', 47: 'cuda:1', 48: 'cuda:1', 49: 'cuda:1', 50: 'meta', 51: 'meta', 52: 'meta', 53: 'meta', 54: 'meta', 55: 'meta', 56: 'cuda:1', 57: 'cuda:1', 58: 'cuda:1', 59: 'meta', 60: 'cuda:1', 61: 'meta', 62: 'meta', 63: 'meta'})
INFO 01-06 17:11:12.229443.229443 cuda_memory_view.py:189] Layer 16: CPU experts = [0, 2, 4, 6, 9, 10, 11, 13, 14, 24, 25, 26, 27, 28, 31, 33, 34, 38, 41, 43, 45, 47, 48, 49, 50, 51, 54, 55, 56, 57, 58, 61] (total: 32, device_map: {0: 'meta', 1: 'cuda:1', 2: 'meta', 3: 'cuda:1', 4: 'meta', 5: 'cuda:1', 6: 'meta', 7: 'cuda:1', 8: 'cuda:1', 9: 'meta', 10: 'meta', 11: 'meta', 12: 'cuda:1', 13: 'meta', 14: 'meta', 15: 'cuda:1', 16: 'cuda:1', 17: 'cuda:1', 18: 'cuda:1', 19: 'cuda:1', 20: 'cuda:1', 21: 'cuda:1', 22: 'cuda:1', 23: 'cuda:1', 24: 'meta', 25: 'meta', 26: 'meta', 27: 'meta', 28: 'meta', 29: 'cuda:1', 30: 'cuda:1', 31: 'meta', 32: 'cuda:1', 33: 'meta', 34: 'meta', 35: 'cuda:1', 36: 'cuda:1', 37: 'cuda:1', 38: 'meta', 39: 'cuda:1', 40: 'cuda:1', 41: 'meta', 42: 'cuda:1', 43: 'meta', 44: 'cuda:1', 45: 'meta', 46: 'cuda:1', 47: 'meta', 48: 'meta', 49: 'meta', 50: 'meta', 51: 'meta', 52: 'cuda:1', 53: 'cuda:1', 54: 'meta', 55: 'meta', 56: 'meta', 57: 'meta', 58: 'meta', 59: 'cuda:1', 60: 'cuda:1', 61: 'meta', 62: 'cuda:1', 63: 'cuda:1'})
INFO 01-06 17:11:12.229470.229470 cuda_memory_view.py:189] Layer 17: CPU experts = [2, 3, 4, 6, 7, 8, 10, 12, 15, 24, 25, 27, 28, 30, 31, 32, 33, 36, 37, 38, 39, 40, 43, 47, 49, 50, 52, 53, 58, 59, 60, 61] (total: 32, device_map: {0: 'cuda:1', 1: 'cuda:1', 2: 'meta', 3: 'meta', 4: 'meta', 5: 'cuda:1', 6: 'meta', 7: 'meta', 8: 'meta', 9: 'cuda:1', 10: 'meta', 11: 'cuda:1', 12: 'meta', 13: 'cuda:1', 14: 'cuda:1', 15: 'meta', 16: 'cuda:1', 17: 'cuda:1', 18: 'cuda:1', 19: 'cuda:1', 20: 'cuda:1', 21: 'cuda:1', 22: 'cuda:1', 23: 'cuda:1', 24: 'meta', 25: 'meta', 26: 'cuda:1', 27: 'meta', 28: 'meta', 29: 'cuda:1', 30: 'meta', 31: 'meta', 32: 'meta', 33: 'meta', 34: 'cuda:1', 35: 'cuda:1', 36: 'meta', 37: 'meta', 38: 'meta', 39: 'meta', 40: 'meta', 41: 'cuda:1', 42: 'cuda:1', 43: 'meta', 44: 'cuda:1', 45: 'cuda:1', 46: 'cuda:1', 47: 'meta', 48: 'cuda:1', 49: 'meta', 50: 'meta', 51: 'cuda:1', 52: 'meta', 53: 'meta', 54: 'cuda:1', 55: 'cuda:1', 56: 'cuda:1', 57: 'cuda:1', 58: 'meta', 59: 'meta', 60: 'meta', 61: 'meta', 62: 'cuda:1', 63: 'cuda:1'})
INFO 01-06 17:11:12.230020.230020 cuda_memory_view.py:189] Layer 18: CPU experts = [0, 3, 5, 6, 8, 9, 12, 17, 19, 21, 25, 27, 28, 29, 30, 32, 35, 36, 37, 39, 40, 41, 46, 48, 52, 53, 54, 56, 58, 59, 60, 63] (total: 32, device_map: {0: 'meta', 1: 'cuda:1', 2: 'cuda:1', 3: 'meta', 4: 'cuda:1', 5: 'meta', 6: 'meta', 7: 'cuda:1', 8: 'meta', 9: 'meta', 10: 'cuda:1', 11: 'cuda:1', 12: 'meta', 13: 'cuda:1', 14: 'cuda:1', 15: 'cuda:1', 16: 'cuda:1', 17: 'meta', 18: 'cuda:1', 19: 'meta', 20: 'cuda:1', 21: 'meta', 22: 'cuda:1', 23: 'cuda:1', 24: 'cuda:1', 25: 'meta', 26: 'cuda:1', 27: 'meta', 28: 'meta', 29: 'meta', 30: 'meta', 31: 'cuda:1', 32: 'meta', 33: 'cuda:1', 34: 'cuda:1', 35: 'meta', 36: 'meta', 37: 'meta', 38: 'cuda:1', 39: 'meta', 40: 'meta', 41: 'meta', 42: 'cuda:1', 43: 'cuda:1', 44: 'cuda:1', 45: 'cuda:1', 46: 'meta', 47: 'cuda:1', 48: 'meta', 49: 'cuda:1', 50: 'cuda:1', 51: 'cuda:1', 52: 'meta', 53: 'meta', 54: 'meta', 55: 'cuda:1', 56: 'meta', 57: 'cuda:1', 58: 'meta', 59: 'meta', 60: 'meta', 61: 'cuda:1', 62: 'cuda:1', 63: 'meta'})
INFO 01-06 17:11:12.230186.230186 cuda_memory_view.py:189] Layer 19: CPU experts = [0, 1, 5, 6, 8, 12, 15, 16, 22, 24, 26, 27, 28, 30, 32, 34, 40, 41, 42, 44, 47, 48, 50, 52, 54, 55, 56, 57, 58, 59, 60, 62] (total: 32, device_map: {0: 'meta', 1: 'meta', 2: 'cuda:1', 3: 'cuda:1', 4: 'cuda:1', 5: 'meta', 6: 'meta', 7: 'cuda:1', 8: 'meta', 9: 'cuda:1', 10: 'cuda:1', 11: 'cuda:1', 12: 'meta', 13: 'cuda:1', 14: 'cuda:1', 15: 'meta', 16: 'meta', 17: 'cuda:1', 18: 'cuda:1', 19: 'cuda:1', 20: 'cuda:1', 21: 'cuda:1', 22: 'meta', 23: 'cuda:1', 24: 'meta', 25: 'cuda:1', 26: 'meta', 27: 'meta', 28: 'meta', 29: 'cuda:1', 30: 'meta', 31: 'cuda:1', 32: 'meta', 33: 'cuda:1', 34: 'meta', 35: 'cuda:1', 36: 'cuda:1', 37: 'cuda:1', 38: 'cuda:1', 39: 'cuda:1', 40: 'meta', 41: 'meta', 42: 'meta', 43: 'cuda:1', 44: 'meta', 45: 'cuda:1', 46: 'cuda:1', 47: 'meta', 48: 'meta', 49: 'cuda:1', 50: 'meta', 51: 'cuda:1', 52: 'meta', 53: 'cuda:1', 54: 'meta', 55: 'meta', 56: 'meta', 57: 'meta', 58: 'meta', 59: 'meta', 60: 'meta', 61: 'cuda:1', 62: 'meta', 63: 'cuda:1'})
INFO 01-06 17:11:12.231590.231590 cuda_memory_view.py:189] Layer 20: CPU experts = [2, 3, 6, 8, 12, 13, 19, 20, 21, 22, 23, 24, 28, 33, 36, 37, 38, 39, 40, 41, 42, 43, 46, 47, 49, 50, 52, 54, 55, 57, 61, 63] (total: 32, device_map: {0: 'cuda:1', 1: 'cuda:1', 2: 'meta', 3: 'meta', 4: 'cuda:1', 5: 'cuda:1', 6: 'meta', 7: 'cuda:1', 8: 'meta', 9: 'cuda:1', 10: 'cuda:1', 11: 'cuda:1', 12: 'meta', 13: 'meta', 14: 'cuda:1', 15: 'cuda:1', 16: 'cuda:1', 17: 'cuda:1', 18: 'cuda:1', 19: 'meta', 20: 'meta', 21: 'meta', 22: 'meta', 23: 'meta', 24: 'meta', 25: 'cuda:1', 26: 'cuda:1', 27: 'cuda:1', 28: 'meta', 29: 'cuda:1', 30: 'cuda:1', 31: 'cuda:1', 32: 'cuda:1', 33: 'meta', 34: 'cuda:1', 35: 'cuda:1', 36: 'meta', 37: 'meta', 38: 'meta', 39: 'meta', 40: 'meta', 41: 'meta', 42: 'meta', 43: 'meta', 44: 'cuda:1', 45: 'cuda:1', 46: 'meta', 47: 'meta', 48: 'cuda:1', 49: 'meta', 50: 'meta', 51: 'cuda:1', 52: 'meta', 53: 'cuda:1', 54: 'meta', 55: 'meta', 56: 'cuda:1', 57: 'meta', 58: 'cuda:1', 59: 'cuda:1', 60: 'cuda:1', 61: 'meta', 62: 'cuda:1', 63: 'meta'})
INFO 01-06 17:11:12.231332.231332 cuda_memory_view.py:189] Layer 21: CPU experts = [1, 2, 6, 7, 8, 9, 11, 14, 22, 23, 24, 26, 27, 32, 34, 35, 38, 39, 41, 44, 47, 48, 49, 50, 51, 52, 53, 54, 56, 59, 60, 62] (total: 32, device_map: {0: 'cuda:1', 1: 'meta', 2: 'meta', 3: 'cuda:1', 4: 'cuda:1', 5: 'cuda:1', 6: 'meta', 7: 'meta', 8: 'meta', 9: 'meta', 10: 'cuda:1', 11: 'meta', 12: 'cuda:1', 13: 'cuda:1', 14: 'meta', 15: 'cuda:1', 16: 'cuda:1', 17: 'cuda:1', 18: 'cuda:1', 19: 'cuda:1', 20: 'cuda:1', 21: 'cuda:1', 22: 'meta', 23: 'meta', 24: 'meta', 25: 'cuda:1', 26: 'meta', 27: 'meta', 28: 'cuda:1', 29: 'cuda:1', 30: 'cuda:1', 31: 'cuda:1', 32: 'meta', 33: 'cuda:1', 34: 'meta', 35: 'meta', 36: 'cuda:1', 37: 'cuda:1', 38: 'meta', 39: 'meta', 40: 'cuda:1', 41: 'meta', 42: 'cuda:1', 43: 'cuda:1', 44: 'meta', 45: 'cuda:1', 46: 'cuda:1', 47: 'meta', 48: 'meta', 49: 'meta', 50: 'meta', 51: 'meta', 52: 'meta', 53: 'meta', 54: 'meta', 55: 'cuda:1', 56: 'meta', 57: 'cuda:1', 58: 'cuda:1', 59: 'meta', 60: 'meta', 61: 'cuda:1', 62: 'meta', 63: 'cuda:1'})
INFO 01-06 17:11:12.231697.231697 cuda_memory_view.py:189] Layer 22: CPU experts = [0, 1, 6, 7, 9, 10, 11, 13, 14, 15, 20, 21, 24, 25, 26, 28, 36, 37, 38, 42, 43, 44, 45, 46, 47, 48, 50, 52, 54, 57, 61, 62] (total: 32, device_map: {0: 'meta', 1: 'meta', 2: 'cuda:1', 3: 'cuda:1', 4: 'cuda:1', 5: 'cuda:1', 6: 'meta', 7: 'meta', 8: 'cuda:1', 9: 'meta', 10: 'meta', 11: 'meta', 12: 'cuda:1', 13: 'meta', 14: 'meta', 15: 'meta', 16: 'cuda:1', 17: 'cuda:1', 18: 'cuda:1', 19: 'cuda:1', 20: 'meta', 21: 'meta', 22: 'cuda:1', 23: 'cuda:1', 24: 'meta', 25: 'meta', 26: 'meta', 27: 'cuda:1', 28: 'meta', 29: 'cuda:1', 30: 'cuda:1', 31: 'cuda:1', 32: 'cuda:1', 33: 'cuda:1', 34: 'cuda:1', 35: 'cuda:1', 36: 'meta', 37: 'meta', 38: 'meta', 39: 'cuda:1', 40: 'cuda:1', 41: 'cuda:1', 42: 'meta', 43: 'meta', 44: 'meta', 45: 'meta', 46: 'meta', 47: 'meta', 48: 'meta', 49: 'cuda:1', 50: 'meta', 51: 'cuda:1', 52: 'meta', 53: 'cuda:1', 54: 'meta', 55: 'cuda:1', 56: 'cuda:1', 57: 'meta', 58: 'cuda:1', 59: 'cuda:1', 60: 'cuda:1', 61: 'meta', 62: 'meta', 63: 'cuda:1'})
INFO 01-06 17:11:12.232876.232876 cuda_memory_view.py:189] Layer 23: CPU experts = [1, 4, 5, 6, 7, 11, 14, 16, 17, 21, 23, 25, 27, 28, 33, 37, 38, 39, 40, 44, 45, 47, 49, 51, 52, 53, 56, 57, 58, 60, 62, 63] (total: 32, device_map: {0: 'cuda:1', 1: 'meta', 2: 'cuda:1', 3: 'cuda:1', 4: 'meta', 5: 'meta', 6: 'meta', 7: 'meta', 8: 'cuda:1', 9: 'cuda:1', 10: 'cuda:1', 11: 'meta', 12: 'cuda:1', 13: 'cuda:1', 14: 'meta', 15: 'cuda:1', 16: 'meta', 17: 'meta', 18: 'cuda:1', 19: 'cuda:1', 20: 'cuda:1', 21: 'meta', 22: 'cuda:1', 23: 'meta', 24: 'cuda:1', 25: 'meta', 26: 'cuda:1', 27: 'meta', 28: 'meta', 29: 'cuda:1', 30: 'cuda:1', 31: 'cuda:1', 32: 'cuda:1', 33: 'meta', 34: 'cuda:1', 35: 'cuda:1', 36: 'cuda:1', 37: 'meta', 38: 'meta', 39: 'meta', 40: 'meta', 41: 'cuda:1', 42: 'cuda:1', 43: 'cuda:1', 44: 'meta', 45: 'meta', 46: 'cuda:1', 47: 'meta', 48: 'cuda:1', 49: 'meta', 50: 'cuda:1', 51: 'meta', 52: 'meta', 53: 'meta', 54: 'cuda:1', 55: 'cuda:1', 56: 'meta', 57: 'meta', 58: 'meta', 59: 'cuda:1', 60: 'meta', 61: 'cuda:1', 62: 'meta', 63: 'meta'})
INFO 01-06 17:11:12.232824.232824 cuda_memory_view.py:189] Layer 24: CPU experts = [0, 2, 4, 6, 7, 9, 13, 15, 16, 20, 24, 25, 29, 30, 33, 35, 36, 38, 39, 42, 43, 44, 46, 47, 48, 51, 54, 55, 56, 59, 61, 62] (total: 32, device_map: {0: 'meta', 1: 'cuda:1', 2: 'meta', 3: 'cuda:1', 4: 'meta', 5: 'cuda:1', 6: 'meta', 7: 'meta', 8: 'cuda:1', 9: 'meta', 10: 'cuda:1', 11: 'cuda:1', 12: 'cuda:1', 13: 'meta', 14: 'cuda:1', 15: 'meta', 16: 'meta', 17: 'cuda:1', 18: 'cuda:1', 19: 'cuda:1', 20: 'meta', 21: 'cuda:1', 22: 'cuda:1', 23: 'cuda:1', 24: 'meta', 25: 'meta', 26: 'cuda:1', 27: 'cuda:1', 28: 'cuda:1', 29: 'meta', 30: 'meta', 31: 'cuda:1', 32: 'cuda:1', 33: 'meta', 34: 'cuda:1', 35: 'meta', 36: 'meta', 37: 'cuda:1', 38: 'meta', 39: 'meta', 40: 'cuda:1', 41: 'cuda:1', 42: 'meta', 43: 'meta', 44: 'meta', 45: 'cuda:1', 46: 'meta', 47: 'meta', 48: 'meta', 49: 'cuda:1', 50: 'cuda:1', 51: 'meta', 52: 'cuda:1', 53: 'cuda:1', 54: 'meta', 55: 'meta', 56: 'meta', 57: 'cuda:1', 58: 'cuda:1', 59: 'meta', 60: 'cuda:1', 61: 'meta', 62: 'meta', 63: 'cuda:1'})
INFO 01-06 17:11:12.233679.233679 cuda_memory_view.py:189] Layer 25: CPU experts = [0, 2, 3, 5, 6, 8, 9, 10, 13, 16, 18, 21, 22, 23, 24, 25, 26, 31, 33, 36, 38, 41, 42, 43, 44, 45, 46, 48, 51, 55, 59, 61] (total: 32, device_map: {0: 'meta', 1: 'cuda:1', 2: 'meta', 3: 'meta', 4: 'cuda:1', 5: 'meta', 6: 'meta', 7: 'cuda:1', 8: 'meta', 9: 'meta', 10: 'meta', 11: 'cuda:1', 12: 'cuda:1', 13: 'meta', 14: 'cuda:1', 15: 'cuda:1', 16: 'meta', 17: 'cuda:1', 18: 'meta', 19: 'cuda:1', 20: 'cuda:1', 21: 'meta', 22: 'meta', 23: 'meta', 24: 'meta', 25: 'meta', 26: 'meta', 27: 'cuda:1', 28: 'cuda:1', 29: 'cuda:1', 30: 'cuda:1', 31: 'meta', 32: 'cuda:1', 33: 'meta', 34: 'cuda:1', 35: 'cuda:1', 36: 'meta', 37: 'cuda:1', 38: 'meta', 39: 'cuda:1', 40: 'cuda:1', 41: 'meta', 42: 'meta', 43: 'meta', 44: 'meta', 45: 'meta', 46: 'meta', 47: 'cuda:1', 48: 'meta', 49: 'cuda:1', 50: 'cuda:1', 51: 'meta', 52: 'cuda:1', 53: 'cuda:1', 54: 'cuda:1', 55: 'meta', 56: 'cuda:1', 57: 'cuda:1', 58: 'cuda:1', 59: 'meta', 60: 'cuda:1', 61: 'meta', 62: 'cuda:1', 63: 'cuda:1'})
INFO 01-06 17:11:12.233785.233785 cuda_memory_view.py:189] Layer 26: CPU experts = [3, 4, 6, 7, 8, 9, 11, 15, 17, 19, 20, 22, 23, 24, 29, 30, 34, 36, 37, 38, 39, 41, 42, 48, 49, 50, 51, 55, 59, 61, 62, 63] (total: 32, device_map: {0: 'cuda:1', 1: 'cuda:1', 2: 'cuda:1', 3: 'meta', 4: 'meta', 5: 'cuda:1', 6: 'meta', 7: 'meta', 8: 'meta', 9: 'meta', 10: 'cuda:1', 11: 'meta', 12: 'cuda:1', 13: 'cuda:1', 14: 'cuda:1', 15: 'meta', 16: 'cuda:1', 17: 'meta', 18: 'cuda:1', 19: 'meta', 20: 'meta', 21: 'cuda:1', 22: 'meta', 23: 'meta', 24: 'meta', 25: 'cuda:1', 26: 'cuda:1', 27: 'cuda:1', 28: 'cuda:1', 29: 'meta', 30: 'meta', 31: 'cuda:1', 32: 'cuda:1', 33: 'cuda:1', 34: 'meta', 35: 'cuda:1', 36: 'meta', 37: 'meta', 38: 'meta', 39: 'meta', 40: 'cuda:1', 41: 'meta', 42: 'meta', 43: 'cuda:1', 44: 'cuda:1', 45: 'cuda:1', 46: 'cuda:1', 47: 'cuda:1', 48: 'meta', 49: 'meta', 50: 'meta', 51: 'meta', 52: 'cuda:1', 53: 'cuda:1', 54: 'cuda:1', 55: 'meta', 56: 'cuda:1', 57: 'cuda:1', 58: 'cuda:1', 59: 'meta', 60: 'cuda:1', 61: 'meta', 62: 'meta', 63: 'meta'})
INFO 01-06 17:11:12.233864.233864 cuda_memory_view.py:189] Layer 27: CPU experts = [0, 5, 6, 10, 11, 12, 13, 17, 18, 20, 23, 24, 26, 31, 33, 36, 40, 42, 43, 44, 45, 46, 47, 48, 49, 51, 54, 55, 56, 57, 59, 61] (total: 32, device_map: {0: 'meta', 1: 'cuda:1', 2: 'cuda:1', 3: 'cuda:1', 4: 'cuda:1', 5: 'meta', 6: 'meta', 7: 'cuda:1', 8: 'cuda:1', 9: 'cuda:1', 10: 'meta', 11: 'meta', 12: 'meta', 13: 'meta', 14: 'cuda:1', 15: 'cuda:1', 16: 'cuda:1', 17: 'meta', 18: 'meta', 19: 'cuda:1', 20: 'meta', 21: 'cuda:1', 22: 'cuda:1', 23: 'meta', 24: 'meta', 25: 'cuda:1', 26: 'meta', 27: 'cuda:1', 28: 'cuda:1', 29: 'cuda:1', 30: 'cuda:1', 31: 'meta', 32: 'cuda:1', 33: 'meta', 34: 'cuda:1', 35: 'cuda:1', 36: 'meta', 37: 'cuda:1', 38: 'cuda:1', 39: 'cuda:1', 40: 'meta', 41: 'cuda:1', 42: 'meta', 43: 'meta', 44: 'meta', 45: 'meta', 46: 'meta', 47: 'meta', 48: 'meta', 49: 'meta', 50: 'cuda:1', 51: 'meta', 52: 'cuda:1', 53: 'cuda:1', 54: 'meta', 55: 'meta', 56: 'meta', 57: 'meta', 58: 'cuda:1', 59: 'meta', 60: 'cuda:1', 61: 'meta', 62: 'cuda:1', 63: 'cuda:1'})
INFO 01-06 17:11:12.236090.236090 cuda_memory_view.py:201] Starting to load CPU experts from last layer to first layer...
INFO 01-06 17:11:12.236582.236582 cuda_memory_view.py:208] Loading Layer 27: 5 CPU experts: [0, 5, 6, 10, 11]
DEBUG 01-06 17:11:12.236000.236000 cuda_h.py:10] start start_load_experts_decode_cpu_weight_l_27
DEBUG 01-06 17:11:12.236320.236320 cuda_h.py:19] end start_load_experts_decode_cpu_weight_l_27 cost 3.314018249511719e-05 seconds
INFO 01-06 17:11:12.236400.236400 cuda_memory_view.py:208] Loading Layer 26: 5 CPU experts: [3, 4, 6, 7, 8]
DEBUG 01-06 17:11:12.236858.236858 cuda_h.py:10] start start_load_experts_decode_cpu_weight_l_26
DEBUG 01-06 17:11:12.236952.236952 cuda_h.py:19] end start_load_experts_decode_cpu_weight_l_26 cost 1.1205673217773438e-05 seconds
INFO 01-06 17:11:12.236171.236171 cuda_memory_view.py:208] Loading Layer 25: 5 CPU experts: [0, 2, 3, 5, 6]
DEBUG 01-06 17:11:12.236198.236198 cuda_h.py:10] start start_load_experts_decode_cpu_weight_l_25
DEBUG 01-06 17:11:12.236146.236146 cuda_h.py:19] end start_load_experts_decode_cpu_weight_l_25 cost 1.0251998901367188e-05 seconds
INFO 01-06 17:11:12.236995.236995 cuda_memory_view.py:208] Loading Layer 24: 5 CPU experts: [0, 2, 4, 6, 7]
DEBUG 01-06 17:11:12.236783.236783 cuda_h.py:10] start start_load_experts_decode_cpu_weight_l_24
DEBUG 01-06 17:11:12.236400.236400 cuda_h.py:19] end start_load_experts_decode_cpu_weight_l_24 cost 1.1920928955078125e-05 seconds
INFO 01-06 17:11:12.236904.236904 cuda_memory_view.py:208] Loading Layer 23: 5 CPU experts: [1, 4, 5, 6, 7]
DEBUG 01-06 17:11:12.236170.236170 cuda_h.py:10] start start_load_experts_decode_cpu_weight_l_23
DEBUG 01-06 17:11:12.236449.236449 cuda_h.py:19] end start_load_experts_decode_cpu_weight_l_23 cost 9.298324584960938e-06 seconds
INFO 01-06 17:11:12.236430.236430 cuda_memory_view.py:208] Loading Layer 22: 5 CPU experts: [0, 1, 6, 7, 9]
DEBUG 01-06 17:11:12.236504.236504 cuda_h.py:10] start start_load_experts_decode_cpu_weight_l_22
DEBUG 01-06 17:11:12.236591.236591 cuda_h.py:19] end start_load_experts_decode_cpu_weight_l_22 cost 9.059906005859375e-06 seconds
INFO 01-06 17:11:12.236618.236618 cuda_memory_view.py:208] Loading Layer 21: 5 CPU experts: [1, 2, 6, 7, 8]
DEBUG 01-06 17:11:12.236453.236453 cuda_h.py:10] start start_load_experts_decode_cpu_weight_l_21
DEBUG 01-06 17:11:12.236825.236825 cuda_h.py:19] end start_load_experts_decode_cpu_weight_l_21 cost 8.58306884765625e-06 seconds
INFO 01-06 17:11:12.236852.236852 cuda_memory_view.py:208] Loading Layer 20: 5 CPU experts: [2, 3, 6, 8, 12]
DEBUG 01-06 17:11:12.236687.236687 cuda_h.py:10] start start_load_experts_decode_cpu_weight_l_20
DEBUG 01-06 17:11:12.236012.236012 cuda_h.py:19] end start_load_experts_decode_cpu_weight_l_20 cost 9.298324584960938e-06 seconds
INFO 01-06 17:11:12.236993.236993 cuda_memory_view.py:208] Loading Layer 19: 5 CPU experts: [0, 1, 5, 6, 8]
DEBUG 01-06 17:11:12.236544.236544 cuda_h.py:10] start start_load_experts_decode_cpu_weight_l_19
DEBUG 01-06 17:11:12.236107.236107 cuda_h.py:19] end start_load_experts_decode_cpu_weight_l_19 cost 9.298324584960938e-06 seconds
INFO 01-06 17:11:12.236373.236373 cuda_memory_view.py:208] Loading Layer 18: 5 CPU experts: [0, 3, 5, 6, 8]
DEBUG 01-06 17:11:12.236970.236970 cuda_h.py:10] start start_load_experts_decode_cpu_weight_l_18
DEBUG 01-06 17:11:12.236732.236732 cuda_h.py:19] end start_load_experts_decode_cpu_weight_l_18 cost 1.5497207641601562e-05 seconds
INFO 01-06 17:11:12.236236.236236 cuda_memory_view.py:208] Loading Layer 17: 5 CPU experts: [2, 3, 4, 6, 7]
DEBUG 01-06 17:11:12.236072.236072 cuda_h.py:10] start start_load_experts_decode_cpu_weight_l_17
DEBUG 01-06 17:11:12.236635.236635 cuda_h.py:19] end start_load_experts_decode_cpu_weight_l_17 cost 9.298324584960938e-06 seconds
INFO 01-06 17:11:12.236616.236616 cuda_memory_view.py:208] Loading Layer 16: 5 CPU experts: [0, 2, 4, 6, 9]
DEBUG 01-06 17:11:12.236928.236928 cuda_h.py:10] start start_load_experts_decode_cpu_weight_l_16
DEBUG 01-06 17:11:12.237492.237492 cuda_h.py:19] end start_load_experts_decode_cpu_weight_l_16 cost 8.821487426757812e-06 seconds
INFO 01-06 17:11:12.237042.237042 cuda_memory_view.py:208] Loading Layer 15: 5 CPU experts: [0, 2, 4, 5, 7]
DEBUG 01-06 17:11:12.237639.237639 cuda_h.py:10] start start_load_experts_decode_cpu_weight_l_15
DEBUG 01-06 17:11:12.237488.237488 cuda_h.py:19] end start_load_experts_decode_cpu_weight_l_15 cost 9.298324584960938e-06 seconds
INFO 01-06 17:11:12.237992.237992 cuda_memory_view.py:208] Loading Layer 14: 5 CPU experts: [0, 7, 8, 12, 13]
DEBUG 01-06 17:11:12.237827.237827 cuda_h.py:10] start start_load_experts_decode_cpu_weight_l_14
DEBUG 01-06 17:11:12.237867.237867 cuda_h.py:19] end start_load_experts_decode_cpu_weight_l_14 cost 1.0013580322265625e-05 seconds
INFO 01-06 17:11:12.237656.237656 cuda_memory_view.py:208] Loading Layer 13: 5 CPU experts: [1, 2, 4, 5, 6]
DEBUG 01-06 17:11:12.237491.237491 cuda_h.py:10] start start_load_experts_decode_cpu_weight_l_13
DEBUG 01-06 17:11:12.237532.237532 cuda_h.py:19] end start_load_experts_decode_cpu_weight_l_13 cost 9.298324584960938e-06 seconds
INFO 01-06 17:11:12.237798.237798 cuda_memory_view.py:208] Loading Layer 12: 5 CPU experts: [0, 2, 4, 7, 8]
DEBUG 01-06 17:11:12.237633.237633 cuda_h.py:10] start start_load_experts_decode_cpu_weight_l_12
DEBUG 01-06 17:11:12.237435.237435 cuda_h.py:19] end start_load_experts_decode_cpu_weight_l_12 cost 9.775161743164062e-06 seconds
INFO 01-06 17:11:12.237747.237747 cuda_memory_view.py:208] Loading Layer 11: 5 CPU experts: [2, 3, 6, 9, 13]
DEBUG 01-06 17:11:12.237105.237105 cuda_h.py:10] start start_load_experts_decode_cpu_weight_l_11
DEBUG 01-06 17:11:12.237861.237861 cuda_h.py:19] end start_load_experts_decode_cpu_weight_l_11 cost 1.0013580322265625e-05 seconds
INFO 01-06 17:11:12.237650.237650 cuda_memory_view.py:208] Loading Layer 10: 5 CPU experts: [2, 3, 4, 5, 6]
DEBUG 01-06 17:11:12.237485.237485 cuda_h.py:10] start start_load_experts_decode_cpu_weight_l_10
DEBUG 01-06 17:11:12.237572.237572 cuda_h.py:19] end start_load_experts_decode_cpu_weight_l_10 cost 8.821487426757812e-06 seconds
INFO 01-06 17:11:12.237599.237599 cuda_memory_view.py:208] Loading Layer 9: 5 CPU experts: [2, 3, 4, 5, 7]
DEBUG 01-06 17:11:12.237434.237434 cuda_h.py:10] start start_load_experts_decode_cpu_weight_l_9
DEBUG 01-06 17:11:12.237429.237429 cuda_h.py:19] end start_load_experts_decode_cpu_weight_l_9 cost 9.775161743164062e-06 seconds
INFO 01-06 17:11:12.237933.237933 cuda_memory_view.py:208] Loading Layer 8: 5 CPU experts: [0, 1, 6, 7, 8]
DEBUG 01-06 17:11:12.237529.237529 cuda_h.py:10] start start_load_experts_decode_cpu_weight_l_8
DEBUG 01-06 17:11:12.237093.237093 cuda_h.py:19] end start_load_experts_decode_cpu_weight_l_8 cost 9.059906005859375e-06 seconds
INFO 01-06 17:11:12.237597.237597 cuda_memory_view.py:208] Loading Layer 7: 5 CPU experts: [1, 3, 4, 6, 7]
DEBUG 01-06 17:11:12.237432.237432 cuda_h.py:10] start start_load_experts_decode_cpu_weight_l_7
DEBUG 01-06 17:11:12.237281.237281 cuda_h.py:19] end start_load_experts_decode_cpu_weight_l_7 cost 9.059906005859375e-06 seconds
INFO 01-06 17:11:12.237831.237831 cuda_memory_view.py:208] Loading Layer 6: 5 CPU experts: [0, 1, 2, 3, 7]
DEBUG 01-06 17:11:12.237428.237428 cuda_h.py:10] start start_load_experts_decode_cpu_weight_l_6
DEBUG 01-06 17:11:12.237561.237561 cuda_h.py:19] end start_load_experts_decode_cpu_weight_l_6 cost 8.106231689453125e-06 seconds
INFO 01-06 17:11:12.237065.237065 cuda_memory_view.py:208] Loading Layer 5: 5 CPU experts: [0, 2, 3, 4, 5]
DEBUG 01-06 17:11:12.237331.237331 cuda_h.py:10] start start_load_experts_decode_cpu_weight_l_5
DEBUG 01-06 17:11:12.237372.237372 cuda_h.py:19] end start_load_experts_decode_cpu_weight_l_5 cost 8.821487426757812e-06 seconds
INFO 01-06 17:11:12.237160.237160 cuda_memory_view.py:208] Loading Layer 4: 5 CPU experts: [4, 8, 9, 10, 11]
DEBUG 01-06 17:11:12.237995.237995 cuda_h.py:10] start start_load_experts_decode_cpu_weight_l_4
DEBUG 01-06 17:11:12.237844.237844 cuda_h.py:19] end start_load_experts_decode_cpu_weight_l_4 cost 9.298324584960938e-06 seconds
INFO 01-06 17:11:12.237871.237871 cuda_memory_view.py:208] Loading Layer 3: 5 CPU experts: [1, 2, 4, 5, 6]
DEBUG 01-06 17:11:12.237468.237468 cuda_h.py:10] start start_load_experts_decode_cpu_weight_l_3
DEBUG 01-06 17:11:12.237317.237317 cuda_h.py:19] end start_load_experts_decode_cpu_weight_l_3 cost 8.58306884765625e-06 seconds
INFO 01-06 17:11:12.237390.237390 cuda_memory_view.py:208] Loading Layer 2: 5 CPU experts: [0, 1, 3, 6, 7]
DEBUG 01-06 17:11:12.237463.237463 cuda_h.py:10] start start_load_experts_decode_cpu_weight_l_2
DEBUG 01-06 17:11:12.237835.237835 cuda_h.py:19] end start_load_experts_decode_cpu_weight_l_2 cost 8.58306884765625e-06 seconds
INFO 01-06 17:11:12.237101.237101 cuda_memory_view.py:208] Loading Layer 1: 5 CPU experts: [0, 1, 3, 10, 11]
DEBUG 01-06 17:11:12.238936.238936 cuda_h.py:10] start start_load_experts_decode_cpu_weight_l_1
DEBUG 01-06 17:11:12.238546.238546 cuda_h.py:19] end start_load_experts_decode_cpu_weight_l_1 cost 8.821487426757812e-06 seconds
DEBUG 01-06 17:11:12.238249.238249 cuda_h.py:19] end async_load_ce cost 0.015420675277709961 seconds
DEBUG 01-06 17:11:12.238038.238038 cuda_h.py:10] start init_inputs_tokens
DEBUG 01-06 17:11:12.238690.238690 cuda_h.py:10] start sllm_worker_task
DEBUG 01-06 17:11:12.238106.238106 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 17:11:12.238541.238541 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 17:11:12.239320.239320 cuda_h.py:19] end allocate_cuda_memory cost 0.0006020069122314453 seconds
DEBUG 01-06 17:11:12.239790.239790 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 17:11:12.239164.239164 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 17:11:12.239267.239267 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 17:11:12.239211.239211 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 3dc772ee-4273-4a7d-ac05-7b0d3c81dcd7
DEBUG 01-06 17:11:12.239124.239124 client.py:106] call stub.LoadModelAsync
INFO 01-06 17:11:12.241717.241717 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 3dc772ee-4273-4a7d-ac05-7b0d3c81dcd7
DEBUG 01-06 17:11:12.241695.241695 cuda_h.py:19] end load_into_gpu_async cost 0.002211332321166992 seconds
DEBUG 01-06 17:11:12.241559.241559 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 17:11:12.242348.242348 cuda_h.py:19] end restore_tensors2 cost 0.00015878677368164062 seconds
DEBUG 01-06 17:11:12.242643.242643 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0036611557006835938 seconds
INFO 01-06 17:11:12.242687.242687 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 3dc772ee-4273-4a7d-ac05-7b0d3c81dcd7
DEBUG 01-06 17:11:12.244986.244986 cuda_h.py:19] end init_inputs_tokens cost 0.0065326690673828125 seconds
DEBUG 01-06 17:11:12.244174.244174 lmp.py:295] next_inputs_tokens shape: torch.Size([32, 1, 2048])
DEBUG 01-06 17:11:12.244645.244645 lmp.py:298] -------------------------------- start decode layer 0 --------------------------------
DEBUG 01-06 17:11:12.244056.244056 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-06 17:11:12.244893.244893 mlpmodule.py:367] cuda:1 cuda:1
DEBUG 01-06 17:11:12.245675.245675 cuda_h.py:10] start self_attn
cos shape torch.Size([65, 128]) sin shape torch.Size([65, 128]) position_ids tensor([[0]], device='cuda:1')
cos shape torch.Size([1, 1, 1, 128]) sin shape torch.Size([1, 1, 1, 128])
q_embed shape torch.Size([32, 16, 1, 128]) k_embed shape torch.Size([32, 16, 1, 128])
DEBUG 01-06 17:11:12.246302.246302 cuda_h.py:19] end self_attn cost 0.0014624595642089844 seconds
DEBUG 01-06 17:11:12.246523.246523 cuda_h.py:19] end iln_self_attn_paln cost 0.0020334720611572266 seconds
DEBUG 01-06 17:11:12.246584.246584 cuda_h.py:10] start dense_mlp
DEBUG 01-06 17:11:12.247836.247836 lmp.py:319] ghidden_states after dense_mlp_func shape: torch.Size([32, 1, 2048])
DEBUG 01-06 17:11:12.247911.247911 cuda_h.py:19] end dense_mlp cost 0.0006175041198730469 seconds
DEBUG 01-06 17:11:12.247800.247800 lmp.py:325] -------------------------------- end decode layer 0 --------------------------------
DEBUG 01-06 17:11:12.247311.247311 lmp.py:298] -------------------------------- start decode layer 1 --------------------------------
DEBUG 01-06 17:11:12.247146.247146 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-06 17:11:12.247214.247214 mlpmodule.py:367] cuda:1 cuda:1
DEBUG 01-06 17:11:12.247976.247976 cuda_h.py:10] start self_attn
cos shape torch.Size([65, 128]) sin shape torch.Size([65, 128]) position_ids tensor([[0]], device='cuda:1')
cos shape torch.Size([1, 1, 1, 128]) sin shape torch.Size([1, 1, 1, 128])
q_embed shape torch.Size([32, 16, 1, 128]) k_embed shape torch.Size([32, 16, 1, 128])
DEBUG 01-06 17:11:12.250161.250161 cuda_h.py:19] end self_attn cost 0.002629518508911133 seconds
INFO 01-06 17:11:12.251068.251068 client.py:127] Model loaded
DEBUG 01-06 17:11:12.252938.252938 cuda_h.py:19] end sllm_worker_task cost 0.014543294906616211 seconds
DEBUG 01-06 17:11:12.253309.253309 cuda_h.py:10] start sllm_worker_task
DEBUG 01-06 17:11:12.253074.253074 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 17:11:12.253899.253899 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 17:11:12.253138.253138 cuda_h.py:19] end allocate_cuda_memory cost 0.00032401084899902344 seconds
DEBUG 01-06 17:11:12.253322.253322 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 17:11:12.253775.253775 cuda_h.py:19] end iln_self_attn_paln cost 0.006293296813964844 seconds
DEBUG 01-06 17:11:12.254863.254863 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 17:11:12.254210.254210 cuda_h.py:10] start layer_moe_dgenerate_1
DEBUG 01-06 17:11:12.254459.254459 cuda_h.py:10] start gate
DEBUG 01-06 17:11:12.254873.254873 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 17:11:12.254055.254055 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 44b044f7-94e9-4ff3-a013-28758cd088cc
DEBUG 01-06 17:11:12.254101.254101 client.py:106] call stub.LoadModelAsync
DEBUG 01-06 17:11:12.255188.255188 cuda_h.py:19] end gate cost 0.0009534358978271484 seconds
DEBUG 01-06 17:11:12.255309.255309 cuda_h.py:10] start experts_map_get
INFO 01-06 17:11:12.255338.255338 lmp.py:611] using loaded check layer: False
INFO 01-06 17:11:12.255783.255783 lmp.py:620] 
INFO 01-06 17:11:12.255783.255783 lmp.py:620] Layer 1 Expert Device Distribution:
INFO 01-06 17:11:12.256161.256161 lmp.py:621]   Active experts: 57 (out of 64 total)
INFO 01-06 17:11:12.256811.256811 lmp.py:622] 
INFO 01-06 17:11:12.256811.256811 lmp.py:622]   Detailed Expert Distribution:
INFO 01-06 17:11:12.256845.256845 lmp.py:623]   Expert ID  | Tokens     | Actual Device  
INFO 01-06 17:11:12.256826.256826 lmp.py:624]   ----------------------------------------------------------------------
INFO 01-06 17:11:12.256091.256091 lmp.py:627]   0          | 1          |  meta           
INFO 01-06 17:11:12.256926.256926 lmp.py:627]   18         | 1          |  meta           
INFO 01-06 17:11:12.256569.256569 lmp.py:627]   25         | 1          |  meta           
INFO 01-06 17:11:12.256974.256974 lmp.py:627]   29         | 1          |  cuda:1         
INFO 01-06 17:11:12.256140.256140 lmp.py:627]   31         | 1          |  meta           
INFO 01-06 17:11:12.256306.256306 lmp.py:627]   33         | 1          |  cuda:1         
INFO 01-06 17:11:12.256472.256472 lmp.py:627]   39         | 1          |  cuda:1         
INFO 01-06 17:11:12.256069.256069 lmp.py:627]   49         | 1          |  meta           
INFO 01-06 17:11:12.256950.256950 lmp.py:627]   51         | 1          |  meta           
INFO 01-06 17:11:12.256355.256355 lmp.py:627]   59         | 1          |  meta           
INFO 01-06 17:11:12.256952.256952 lmp.py:627]   61         | 1          |  cuda:1         
INFO 01-06 17:11:12.256548.256548 lmp.py:627]   62         | 1          |  meta           
INFO 01-06 17:11:12.256575.256575 lmp.py:627]   6          | 2          |  cuda:1         
INFO 01-06 17:11:12.256411.256411 lmp.py:627]   7          | 2          |  cuda:1         
INFO 01-06 17:11:12.256577.256577 lmp.py:627]   11         | 2          |  meta           
INFO 01-06 17:11:12.256173.256173 lmp.py:627]   17         | 2          |  meta           
INFO 01-06 17:11:12.256923.256923 lmp.py:627]   19         | 2          |  cuda:1         
INFO 01-06 17:11:12.256850.256850 lmp.py:627]   22         | 2          |  meta           
INFO 01-06 17:11:12.256016.256016 lmp.py:627]   23         | 2          |  cuda:1         
INFO 01-06 17:11:12.256183.256183 lmp.py:627]   27         | 2          |  meta           
INFO 01-06 17:11:12.256587.256587 lmp.py:627]   30         | 2          |  cuda:1         
INFO 01-06 17:11:12.256515.256515 lmp.py:627]   32         | 2          |  meta           
INFO 01-06 17:11:12.256443.256443 lmp.py:627]   35         | 2          |  meta           
INFO 01-06 17:11:12.256609.256609 lmp.py:627]   36         | 2          |  meta           
INFO 01-06 17:11:12.256775.256775 lmp.py:627]   46         | 2          |  cuda:1         
INFO 01-06 17:11:12.256418.256418 lmp.py:627]   52         | 2          |  meta           
INFO 01-06 17:11:12.256776.256776 lmp.py:627]   10         | 3          |  meta           
INFO 01-06 17:11:12.256942.256942 lmp.py:627]   16         | 3          |  cuda:1         
INFO 01-06 17:11:12.256631.256631 lmp.py:627]   21         | 3          |  cuda:1         
INFO 01-06 17:11:12.256559.256559 lmp.py:627]   28         | 3          |  meta           
INFO 01-06 17:11:12.256248.256248 lmp.py:627]   41         | 3          |  meta           
INFO 01-06 17:11:12.256176.256176 lmp.py:627]   42         | 3          |  cuda:1         
INFO 01-06 17:11:12.256104.256104 lmp.py:627]   43         | 3          |  meta           
INFO 01-06 17:11:12.256032.256032 lmp.py:627]   44         | 3          |  meta           
INFO 01-06 17:11:12.256721.256721 lmp.py:627]   48         | 3          |  cuda:1         
INFO 01-06 17:11:12.256887.256887 lmp.py:627]   58         | 3          |  meta           
INFO 01-06 17:11:12.256815.256815 lmp.py:627]   63         | 3          |  cuda:1         
INFO 01-06 17:11:12.256981.256981 lmp.py:627]   4          | 4          |  cuda:1         
INFO 01-06 17:11:12.256385.256385 lmp.py:627]   5          | 4          |  cuda:1         
INFO 01-06 17:11:12.256267.256267 lmp.py:627]   12         | 4          |  cuda:1         
INFO 01-06 17:11:12.256387.256387 lmp.py:627]   13         | 4          |  meta           
INFO 01-06 17:11:12.256745.256745 lmp.py:627]   38         | 4          |  meta           
INFO 01-06 17:11:12.256149.256149 lmp.py:627]   40         | 4          |  cuda:1         
INFO 01-06 17:11:12.256316.256316 lmp.py:627]   50         | 4          |  cuda:1         
INFO 01-06 17:11:12.256720.256720 lmp.py:627]   60         | 4          |  meta           
INFO 01-06 17:11:12.256363.256363 lmp.py:627]   24         | 5          |  cuda:1         
INFO 01-06 17:11:12.256291.256291 lmp.py:627]   26         | 5          |  cuda:1         
INFO 01-06 17:11:12.256457.256457 lmp.py:627]   53         | 5          |  cuda:1         
INFO 01-06 17:11:12.256623.256623 lmp.py:627]   8          | 6          |  cuda:1         
INFO 01-06 17:11:12.256789.256789 lmp.py:627]   15         | 6          |  cuda:1         
INFO 01-06 17:11:12.256717.256717 lmp.py:627]   34         | 6          |  meta           
INFO 01-06 17:11:12.257883.257883 lmp.py:627]   56         | 6          |  cuda:1         
INFO 01-06 17:11:12.257864.257864 lmp.py:627]   9          | 7          |  cuda:1         
INFO 01-06 17:11:12.257461.257461 lmp.py:627]   20         | 8          |  cuda:1         
INFO 01-06 17:11:12.257296.257296 lmp.py:627]   45         | 9          |  cuda:1         
INFO 01-06 17:11:12.257892.257892 lmp.py:627]   57         | 9          |  cuda:1         
INFO 01-06 17:11:12.257297.257297 lmp.py:627]   14         | 15         |  cuda:1         
INFO 01-06 17:11:12.257324.257324 lmp.py:628] ============================================================
INFO 01-06 17:11:12.257324.257324 lmp.py:628] 
INFO 01-06 17:11:12.257166.257166 lmp.py:630] experts_gpu_list: [29, 33, 39, 61, 6, 7, 19, 23, 30, 46, 16, 21, 42, 48, 63, 4, 5, 12, 40, 50, 24, 26, 53, 8, 15, 56, 9, 20, 45, 57, 14] num: 31
INFO 01-06 17:11:12.257716.257716 lmp.py:631] experts_cpu_list: [0, 18, 25, 31, 49, 51, 59, 62, 11, 17, 22, 27, 32, 35, 36, 52, 10, 28, 41, 43, 44, 58, 13, 38, 60, 34] num: 26
INFO 01-06 17:11:12.257896.257896 lmp.py:632] expert_actual_device_map {0: 'meta', 1: 'meta', 2: 'cuda:1', 3: 'meta', 4: 'cuda:1', 5: 'cuda:1', 6: 'cuda:1', 7: 'cuda:1', 8: 'cuda:1', 9: 'cuda:1', 10: 'meta', 11: 'meta', 12: 'cuda:1', 13: 'meta', 14: 'cuda:1', 15: 'cuda:1', 16: 'cuda:1', 17: 'meta', 18: 'meta', 19: 'cuda:1', 20: 'cuda:1', 21: 'cuda:1', 22: 'meta', 23: 'cuda:1', 24: 'cuda:1', 25: 'meta', 26: 'cuda:1', 27: 'meta', 28: 'meta', 29: 'cuda:1', 30: 'cuda:1', 31: 'meta', 32: 'meta', 33: 'cuda:1', 34: 'meta', 35: 'meta', 36: 'meta', 37: 'meta', 38: 'meta', 39: 'cuda:1', 40: 'cuda:1', 41: 'meta', 42: 'cuda:1', 43: 'meta', 44: 'meta', 45: 'cuda:1', 46: 'cuda:1', 47: 'meta', 48: 'cuda:1', 49: 'meta', 50: 'cuda:1', 51: 'meta', 52: 'meta', 53: 'cuda:1', 54: 'meta', 55: 'meta', 56: 'cuda:1', 57: 'cuda:1', 58: 'meta', 59: 'meta', 60: 'meta', 61: 'cuda:1', 62: 'meta', 63: 'cuda:1'}
DEBUG 01-06 17:11:12.257076.257076 cuda_h.py:19] end experts_map_get cost 0.0019040107727050781 seconds
DEBUG 01-06 17:11:12.257370.257370 cuda_h.py:10] start gpu_sexperts
INFO 01-06 17:11:12.257334.257334 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 44b044f7-94e9-4ff3-a013-28758cd088cc
DEBUG 01-06 17:11:12.257122.257122 cuda_h.py:19] end load_into_gpu_async cost 0.0035619735717773438 seconds
DEBUG 01-06 17:11:12.257661.257661 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 17:11:12.257886.257886 cuda_h.py:19] end restore_tensors2 cost 0.00011849403381347656 seconds
DEBUG 01-06 17:11:12.257823.257823 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.004691362380981445 seconds
INFO 01-06 17:11:12.258264.258264 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 44b044f7-94e9-4ff3-a013-28758cd088cc
DEBUG 01-06 17:11:12.258792.258792 cuda_h.py:19] end gpu_sexperts cost 0.0007109642028808594 seconds
DEBUG 01-06 17:11:12.258271.258271 cuda_h.py:10] start gpu_experts
DEBUG 01-06 17:11:12.260591.260591 mlpmodule.py:533] gpu group tensors cost 0.0021653175354003906 s
DEBUG 01-06 17:11:12.261770.261770 mlpmodule.py:566] gpu pad cost 0.0013394355773925781 s
DEBUG 01-06 17:11:12.262260.262260 mlpmodule.py:584] gpu group einsum cost 0.00033545494079589844 s
DEBUG 01-06 17:11:12.265364.265364 mlpmodule.py:613] gpu experts func einsum cost 0.006668806076049805 s
DEBUG 01-06 17:11:12.265235.265235 cuda_h.py:19] end gpu_experts cost 0.006791353225708008 seconds
DEBUG 01-06 17:11:12.265467.265467 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-06 17:11:12.265362.265362 lmp.py:661] 
DEBUG 01-06 17:11:12.265362.265362 lmp.py:661]   Computing 26 experts on CPU...
DEBUG 01-06 17:11:12.265053.265053 cuda_h.py:19] end cpu_experts_submit cost 5.221366882324219e-05 seconds
DEBUG 01-06 17:11:12.265941.265941 cuda_h.py:10] start wait_cetm_experts
INFO 01-06 17:11:12.265713.265713 client.py:127] Model loaded
DEBUG 01-06 17:11:12.266555.266555 cuda_h.py:19] end sllm_worker_task cost 0.013766765594482422 seconds
DEBUG 01-06 17:11:12.267896.267896 cuda_h.py:10] start sllm_worker_task
DEBUG 01-06 17:11:12.267846.267846 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 17:11:12.267644.267644 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 17:11:12.267191.267191 cuda_h.py:19] end allocate_cuda_memory cost 0.00026607513427734375 seconds
DEBUG 01-06 17:11:12.267287.267287 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 17:11:12.267276.267276 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 17:11:12.267378.267378 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 17:11:12.267830.267830 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 927af24e-ca87-4859-8a67-57e9ed59a259
DEBUG 01-06 17:11:12.268020.268020 client.py:106] call stub.LoadModelAsync
DEBUG 01-06 17:11:12.279353.279353 mlpmodule.py:706] group tensors cost 0.011081933975219727 s
INFO 01-06 17:11:12.280222.280222 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 927af24e-ca87-4859-8a67-57e9ed59a259
DEBUG 01-06 17:11:12.280707.280707 cuda_h.py:19] end load_into_gpu_async cost 0.013044595718383789 seconds
DEBUG 01-06 17:11:12.280406.280406 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 17:11:12.281937.281937 cuda_h.py:19] end restore_tensors2 cost 0.00016689300537109375 seconds
DEBUG 01-06 17:11:12.281577.281577 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.014065265655517578 seconds
INFO 01-06 17:11:12.281232.281232 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 927af24e-ca87-4859-8a67-57e9ed59a259
INFO 01-06 17:11:12.282769.282769 client.py:127] Model loaded
DEBUG 01-06 17:11:12.284682.284682 cuda_h.py:19] end sllm_worker_task cost 0.017223358154296875 seconds
DEBUG 01-06 17:11:12.284079.284079 cuda_h.py:10] start sllm_worker_task
DEBUG 01-06 17:11:12.284784.284784 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 17:11:12.284604.284604 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 17:11:12.285494.285494 cuda_h.py:19] end allocate_cuda_memory cost 0.00038361549377441406 seconds
DEBUG 01-06 17:11:12.285519.285519 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 17:11:12.285649.285649 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 17:11:12.285746.285746 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 17:11:12.285748.285748 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 6d79635e-38c6-4fdc-bce7-5650a6623471
DEBUG 01-06 17:11:12.285437.285437 client.py:106] call stub.LoadModelAsync
DEBUG 01-06 17:11:12.286158.286158 mlpmodule.py:744] pad cost 0.0063860416412353516 s
DEBUG 01-06 17:11:12.286826.286826 mlpmodule.py:750] create cpu tensor cost 6.723403930664062e-05 s
DEBUG 01-06 17:11:12.287485.287485 mlpmodule.py:755] move to cpu cost 4.2438507080078125e-05 s
INFO 01-06 17:11:12.288996.288996 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 6d79635e-38c6-4fdc-bce7-5650a6623471
DEBUG 01-06 17:11:12.288844.288844 cuda_h.py:19] end load_into_gpu_async cost 0.0027723312377929688 seconds
DEBUG 01-06 17:11:12.288360.288360 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 17:11:12.289720.289720 cuda_h.py:19] end restore_tensors2 cost 0.0003426074981689453 seconds
DEBUG 01-06 17:11:12.289031.289031 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.004492282867431641 seconds
INFO 01-06 17:11:12.289455.289455 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 6d79635e-38c6-4fdc-bce7-5650a6623471
DEBUG 01-06 17:11:12.290295.290295 mlpmodule.py:769] group_w3: shape=torch.Size([26, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=74973184
DEBUG 01-06 17:11:12.290749.290749 mlpmodule.py:770] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-06 17:11:12.290929.290929 mlpmodule.py:775] group_w3 first element: -0.0107421875
WARNING 01-06 17:11:12.290636.290636 mlpmodule.py:785] start einsum2
DEBUG 01-06 17:11:12.296131.296131 mlpmodule.py:795] group einsum cost 0.008950233459472656 s
DEBUG 01-06 17:11:12.296912.296912 mlpmodule.py:803] cpy2cputensor cost 0.00010538101196289062 s
INFO 01-06 17:11:12.298750.298750 client.py:127] Model loaded
DEBUG 01-06 17:11:12.300625.300625 cuda_h.py:19] end sllm_worker_task cost 0.015592098236083984 seconds
DEBUG 01-06 17:11:12.300862.300862 cuda_h.py:10] start sllm_worker_task
DEBUG 01-06 17:11:12.300222.300222 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 17:11:12.300993.300993 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 17:11:12.301796.301796 cuda_h.py:19] end allocate_cuda_memory cost 0.0004000663757324219 seconds
DEBUG 01-06 17:11:12.301376.301376 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 17:11:12.301205.301205 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 17:11:12.301009.301009 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 17:11:12.301401.301401 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 962a4cd4-181e-4f32-9f9c-dece3ac091d7
DEBUG 01-06 17:11:12.301161.301161 client.py:106] call stub.LoadModelAsync
INFO 01-06 17:11:12.302273.302273 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 962a4cd4-181e-4f32-9f9c-dece3ac091d7
DEBUG 01-06 17:11:12.302867.302867 cuda_h.py:19] end wait_cetm_experts cost 0.037676095962524414 seconds
DEBUG 01-06 17:11:12.303024.303024 cuda_h.py:19] end load_into_gpu_async cost 0.0018982887268066406 seconds
DEBUG 01-06 17:11:12.303153.303153 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 17:11:12.303430.303430 cuda_h.py:19] end restore_tensors2 cost 0.00012803077697753906 seconds
DEBUG 01-06 17:11:12.303544.303544 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.002867460250854492 seconds
INFO 01-06 17:11:12.303361.303361 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 962a4cd4-181e-4f32-9f9c-dece3ac091d7
DEBUG 01-06 17:11:12.303915.303915 cuda_h.py:19] end layer_moe_dgenerate_1 cost 0.049423933029174805 seconds
DEBUG 01-06 17:11:12.303194.303194 lmp.py:325] -------------------------------- end decode layer 1 --------------------------------
DEBUG 01-06 17:11:12.303023.303023 lmp.py:298] -------------------------------- start decode layer 2 --------------------------------
DEBUG 01-06 17:11:12.303786.303786 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-06 17:11:12.304961.304961 mlpmodule.py:367] cuda:1 cuda:1
DEBUG 01-06 17:11:12.304705.304705 cuda_h.py:10] start self_attn
cos shape torch.Size([65, 128]) sin shape torch.Size([65, 128]) position_ids tensor([[0]], device='cuda:1')
cos shape torch.Size([1, 1, 1, 128]) sin shape torch.Size([1, 1, 1, 128])
q_embed shape torch.Size([32, 16, 1, 128]) k_embed shape torch.Size([32, 16, 1, 128])
DEBUG 01-06 17:11:12.306039.306039 cuda_h.py:19] end self_attn cost 0.002214670181274414 seconds
DEBUG 01-06 17:11:12.307861.307861 cuda_h.py:19] end iln_self_attn_paln cost 0.0031723976135253906 seconds
DEBUG 01-06 17:11:12.307088.307088 cuda_h.py:10] start layer_moe_dgenerate_2
DEBUG 01-06 17:11:12.307679.307679 cuda_h.py:10] start gate
DEBUG 01-06 17:11:12.308209.308209 cuda_h.py:19] end gate cost 0.0007658004760742188 seconds
DEBUG 01-06 17:11:12.308728.308728 cuda_h.py:10] start experts_map_get
INFO 01-06 17:11:12.308902.308902 lmp.py:611] using loaded check layer: False
INFO 01-06 17:11:12.309414.309414 lmp.py:620] 
INFO 01-06 17:11:12.309414.309414 lmp.py:620] Layer 2 Expert Device Distribution:
INFO 01-06 17:11:12.309038.309038 lmp.py:621]   Active experts: 56 (out of 64 total)
INFO 01-06 17:11:12.309787.309787 lmp.py:622] 
INFO 01-06 17:11:12.309787.309787 lmp.py:622]   Detailed Expert Distribution:
INFO 01-06 17:11:12.309728.309728 lmp.py:623]   Expert ID  | Tokens     | Actual Device  
INFO 01-06 17:11:12.309617.309617 lmp.py:624]   ----------------------------------------------------------------------
INFO 01-06 17:11:12.309935.309935 lmp.py:627]   0          | 1          |  meta           
INFO 01-06 17:11:12.309347.309347 lmp.py:627]   1          | 1          |  meta           
INFO 01-06 17:11:12.309043.309043 lmp.py:627]   8          | 1          |  meta           
INFO 01-06 17:11:12.309977.309977 lmp.py:627]   15         | 1          |  meta           
INFO 01-06 17:11:12.309673.309673 lmp.py:627]   23         | 1          |  meta           
INFO 01-06 17:11:12.309131.309131 lmp.py:627]   29         | 1          |  meta           
INFO 01-06 17:11:12.309827.309827 lmp.py:627]   33         | 1          |  meta           
INFO 01-06 17:11:12.309477.309477 lmp.py:627]   34         | 1          |  meta           
INFO 01-06 17:11:12.309365.309365 lmp.py:627]   44         | 1          |  cuda:1         
INFO 01-06 17:11:12.309730.309730 lmp.py:627]   49         | 1          |  meta           
INFO 01-06 17:11:12.309764.309764 lmp.py:627]   56         | 1          |  cuda:1         
INFO 01-06 17:11:12.309699.309699 lmp.py:627]   57         | 1          |  meta           
INFO 01-06 17:11:12.309156.309156 lmp.py:627]   10         | 2          |  cuda:1         
INFO 01-06 17:11:12.309422.309422 lmp.py:627]   12         | 2          |  meta           
INFO 01-06 17:11:12.309880.309880 lmp.py:627]   20         | 2          |  cuda:1         
INFO 01-06 17:11:12.309529.309529 lmp.py:627]   24         | 2          |  meta           
INFO 01-06 17:11:12.309417.309417 lmp.py:627]   27         | 2          |  meta           
INFO 01-06 17:11:12.309352.309352 lmp.py:627]   35         | 2          |  meta           
INFO 01-06 17:11:12.309525.309525 lmp.py:627]   37         | 2          |  meta           
INFO 01-06 17:11:12.309698.309698 lmp.py:627]   43         | 2          |  cuda:1         
INFO 01-06 17:11:12.309824.309824 lmp.py:627]   46         | 2          |  cuda:1         
INFO 01-06 17:11:12.309236.309236 lmp.py:627]   51         | 2          |  meta           
INFO 01-06 17:11:12.309647.309647 lmp.py:627]   59         | 2          |  cuda:1         
INFO 01-06 17:11:12.309058.309058 lmp.py:627]   60         | 2          |  cuda:1         
INFO 01-06 17:11:12.309993.309993 lmp.py:627]   62         | 2          |  meta           
INFO 01-06 17:11:12.309166.309166 lmp.py:627]   6          | 3          |  meta           
INFO 01-06 17:11:12.309100.309100 lmp.py:627]   7          | 3          |  meta           
INFO 01-06 17:11:12.309273.309273 lmp.py:627]   22         | 3          |  cuda:1         
INFO 01-06 17:11:12.310685.310685 lmp.py:627]   25         | 3          |  meta           
INFO 01-06 17:11:12.310050.310050 lmp.py:627]   26         | 3          |  meta           
INFO 01-06 17:11:12.310653.310653 lmp.py:627]   36         | 3          |  meta           
INFO 01-06 17:11:12.310303.310303 lmp.py:627]   39         | 3          |  cuda:1         
INFO 01-06 17:11:12.310714.310714 lmp.py:627]   45         | 3          |  meta           
INFO 01-06 17:11:12.310887.310887 lmp.py:627]   47         | 3          |  cuda:1         
INFO 01-06 17:11:12.310299.310299 lmp.py:627]   50         | 3          |  cuda:1         
INFO 01-06 17:11:12.310233.310233 lmp.py:627]   52         | 3          |  cuda:1         
INFO 01-06 17:11:12.310360.310360 lmp.py:627]   55         | 3          |  cuda:1         
INFO 01-06 17:11:12.310056.310056 lmp.py:627]   63         | 3          |  cuda:1         
INFO 01-06 17:11:12.310898.310898 lmp.py:627]   4          | 4          |  cuda:1         
INFO 01-06 17:11:12.310859.310859 lmp.py:627]   42         | 4          |  cuda:1         
INFO 01-06 17:11:12.310608.310608 lmp.py:627]   2          | 5          |  cuda:1         
INFO 01-06 17:11:12.310735.310735 lmp.py:627]   9          | 5          |  meta           
INFO 01-06 17:11:12.310623.310623 lmp.py:627]   13         | 5          |  cuda:1         
INFO 01-06 17:11:12.310750.310750 lmp.py:627]   40         | 5          |  cuda:1         
INFO 01-06 17:11:12.310876.310876 lmp.py:627]   54         | 5          |  meta           
INFO 01-06 17:11:12.310480.310480 lmp.py:627]   14         | 6          |  cuda:1         
INFO 01-06 17:11:12.310435.310435 lmp.py:627]   19         | 6          |  cuda:1         
INFO 01-06 17:11:12.310230.310230 lmp.py:627]   30         | 6          |  meta           
INFO 01-06 17:11:12.310787.310787 lmp.py:627]   31         | 6          |  cuda:1         
INFO 01-06 17:11:12.310629.310629 lmp.py:627]   41         | 6          |  cuda:1         
INFO 01-06 17:11:12.310233.310233 lmp.py:627]   53         | 6          |  cuda:1         
INFO 01-06 17:11:12.310359.310359 lmp.py:627]   16         | 7          |  cuda:1         
INFO 01-06 17:11:12.310963.310963 lmp.py:627]   18         | 7          |  cuda:1         
INFO 01-06 17:11:12.310328.310328 lmp.py:627]   61         | 8          |  cuda:1         
INFO 01-06 17:11:12.310554.310554 lmp.py:627]   5          | 9          |  cuda:1         
INFO 01-06 17:11:12.310349.310349 lmp.py:627]   11         | 15         |  cuda:1         
DEBUG 01-06 17:11:12.310007.310007 mlpmodule.py:664]  experts func einsum cost 0.04254746437072754 s
INFO 01-06 17:11:12.310426.310426 lmp.py:628] ============================================================
INFO 01-06 17:11:12.310426.310426 lmp.py:628] 
INFO 01-06 17:11:12.310571.310571 lmp.py:630] experts_gpu_list: [44, 56, 10, 20, 43, 46, 59, 60, 22, 39, 47, 50, 52, 55, 63, 4, 42, 2, 13, 40, 14, 19, 31, 41, 53, 16, 18, 61, 5, 11] num: 30
INFO 01-06 17:11:12.311804.311804 lmp.py:631] experts_cpu_list: [0, 1, 8, 15, 23, 29, 33, 34, 49, 57, 12, 24, 27, 35, 37, 51, 62, 6, 7, 25, 26, 36, 45, 9, 54, 30] num: 26
INFO 01-06 17:11:12.311951.311951 lmp.py:632] expert_actual_device_map {0: 'meta', 1: 'meta', 2: 'cuda:1', 3: 'meta', 4: 'cuda:1', 5: 'cuda:1', 6: 'meta', 7: 'meta', 8: 'meta', 9: 'meta', 10: 'cuda:1', 11: 'cuda:1', 12: 'meta', 13: 'cuda:1', 14: 'cuda:1', 15: 'meta', 16: 'cuda:1', 17: 'meta', 18: 'cuda:1', 19: 'cuda:1', 20: 'cuda:1', 21: 'cuda:1', 22: 'cuda:1', 23: 'meta', 24: 'meta', 25: 'meta', 26: 'meta', 27: 'meta', 28: 'meta', 29: 'meta', 30: 'meta', 31: 'cuda:1', 32: 'meta', 33: 'meta', 34: 'meta', 35: 'meta', 36: 'meta', 37: 'meta', 38: 'cuda:1', 39: 'cuda:1', 40: 'cuda:1', 41: 'cuda:1', 42: 'cuda:1', 43: 'cuda:1', 44: 'cuda:1', 45: 'meta', 46: 'cuda:1', 47: 'cuda:1', 48: 'meta', 49: 'meta', 50: 'cuda:1', 51: 'meta', 52: 'cuda:1', 53: 'cuda:1', 54: 'meta', 55: 'cuda:1', 56: 'cuda:1', 57: 'meta', 58: 'meta', 59: 'cuda:1', 60: 'cuda:1', 61: 'cuda:1', 62: 'meta', 63: 'cuda:1'}
DEBUG 01-06 17:11:12.311959.311959 cuda_h.py:19] end experts_map_get cost 0.0028982162475585938 seconds
DEBUG 01-06 17:11:12.311419.311419 cuda_h.py:10] start gpu_sexperts
DEBUG 01-06 17:11:12.311299.311299 cuda_h.py:19] end gpu_sexperts cost 0.0003261566162109375 seconds
DEBUG 01-06 17:11:12.311228.311228 cuda_h.py:10] start gpu_experts
INFO 01-06 17:11:12.312233.312233 client.py:127] Model loaded
DEBUG 01-06 17:11:12.312184.312184 mlpmodule.py:533] gpu group tensors cost 0.0007686614990234375 s
DEBUG 01-06 17:11:12.313306.313306 cuda_h.py:19] end sllm_worker_task cost 0.012596607208251953 seconds
DEBUG 01-06 17:11:12.313037.313037 cuda_h.py:10] start sllm_worker_task
DEBUG 01-06 17:11:12.313230.313230 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 17:11:12.313881.313881 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 17:11:12.313936.313936 cuda_h.py:19] end allocate_cuda_memory cost 0.00021266937255859375 seconds
DEBUG 01-06 17:11:12.313643.313643 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 17:11:12.313790.313790 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 17:11:12.313467.313467 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 17:11:12.313885.313885 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, d000f409-fdbd-4a29-b6f9-280fcbdfe3fb
DEBUG 01-06 17:11:12.313477.313477 client.py:106] call stub.LoadModelAsync
INFO 01-06 17:11:12.315532.315532 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, d000f409-fdbd-4a29-b6f9-280fcbdfe3fb
DEBUG 01-06 17:11:12.315653.315653 cuda_h.py:19] end load_into_gpu_async cost 0.0014431476593017578 seconds
DEBUG 01-06 17:11:12.315309.315309 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 17:11:12.315174.315174 cuda_h.py:19] end restore_tensors2 cost 8.0108642578125e-05 seconds
DEBUG 01-06 17:11:12.315506.315506 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0020699501037597656 seconds
INFO 01-06 17:11:12.315972.315972 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, d000f409-fdbd-4a29-b6f9-280fcbdfe3fb
DEBUG 01-06 17:11:12.315464.315464 mlpmodule.py:566] gpu pad cost 0.0030252933502197266 s
DEBUG 01-06 17:11:12.316865.316865 mlpmodule.py:584] gpu group einsum cost 0.0004322528839111328 s
DEBUG 01-06 17:11:12.318207.318207 mlpmodule.py:613] gpu experts func einsum cost 0.007214069366455078 s
DEBUG 01-06 17:11:12.319436.319436 cuda_h.py:19] end gpu_experts cost 0.007356166839599609 seconds
DEBUG 01-06 17:11:12.319046.319046 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-06 17:11:12.319557.319557 lmp.py:661] 
DEBUG 01-06 17:11:12.319557.319557 lmp.py:661]   Computing 26 experts on CPU...
DEBUG 01-06 17:11:12.319777.319777 cuda_h.py:19] end cpu_experts_submit cost 5.698204040527344e-05 seconds
DEBUG 01-06 17:11:12.319811.319811 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-06 17:11:12.323430.323430 mlpmodule.py:706] group tensors cost 0.0046842098236083984 s
INFO 01-06 17:11:12.324039.324039 client.py:127] Model loaded
DEBUG 01-06 17:11:12.325229.325229 cuda_h.py:19] end sllm_worker_task cost 0.012420892715454102 seconds
DEBUG 01-06 17:11:12.325219.325219 cuda_h.py:10] start sllm_worker_task
DEBUG 01-06 17:11:12.325413.325413 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 17:11:12.325011.325011 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 17:11:12.326164.326164 cuda_h.py:19] end allocate_cuda_memory cost 0.00018334388732910156 seconds
DEBUG 01-06 17:11:12.326325.326325 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 17:11:12.326519.326519 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 17:11:12.326904.326904 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 17:11:12.326938.326938 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 0dbf45b1-7033-4351-8ecd-d0cdfbf2e5bd
DEBUG 01-06 17:11:12.326517.326517 client.py:106] call stub.LoadModelAsync
DEBUG 01-06 17:11:12.327335.327335 mlpmodule.py:744] pad cost 0.002837657928466797 s
DEBUG 01-06 17:11:12.327379.327379 mlpmodule.py:750] create cpu tensor cost 5.364418029785156e-05 s
INFO 01-06 17:11:12.327396.327396 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 0dbf45b1-7033-4351-8ecd-d0cdfbf2e5bd
DEBUG 01-06 17:11:12.327440.327440 mlpmodule.py:755] move to cpu cost 0.00016069412231445312 s
DEBUG 01-06 17:11:12.327032.327032 cuda_h.py:19] end load_into_gpu_async cost 0.001665353775024414 seconds
DEBUG 01-06 17:11:12.328347.328347 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 17:11:12.328013.328013 cuda_h.py:19] end restore_tensors2 cost 6.67572021484375e-05 seconds
DEBUG 01-06 17:11:12.328107.328107 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0023097991943359375 seconds
INFO 01-06 17:11:12.328004.328004 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 0dbf45b1-7033-4351-8ecd-d0cdfbf2e5bd
DEBUG 01-06 17:11:12.330438.330438 mlpmodule.py:769] group_w3: shape=torch.Size([26, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=74973184
DEBUG 01-06 17:11:12.331454.331454 mlpmodule.py:770] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-06 17:11:12.331098.331098 mlpmodule.py:775] group_w3 first element: -0.0380859375
WARNING 01-06 17:11:12.331075.331075 mlpmodule.py:785] start einsum2
DEBUG 01-06 17:11:12.336013.336013 mlpmodule.py:795] group einsum cost 0.008659839630126953 s
DEBUG 01-06 17:11:12.336132.336132 mlpmodule.py:803] cpy2cputensor cost 0.00010609626770019531 s
INFO 01-06 17:11:12.338590.338590 client.py:127] Model loaded
DEBUG 01-06 17:11:12.340370.340370 cuda_h.py:19] end sllm_worker_task cost 0.01451730728149414 seconds
DEBUG 01-06 17:11:12.340322.340322 cuda_h.py:10] start sllm_worker_task
DEBUG 01-06 17:11:12.340429.340429 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 17:11:12.340809.340809 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 17:11:12.341989.341989 cuda_h.py:19] end allocate_cuda_memory cost 0.0003917217254638672 seconds
DEBUG 01-06 17:11:12.341794.341794 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 17:11:12.341186.341186 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 17:11:12.341314.341314 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 17:11:12.341454.341454 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 3f88bd07-d67d-4269-a5b4-0a789f48a864
DEBUG 01-06 17:11:12.341995.341995 client.py:106] call stub.LoadModelAsync
INFO 01-06 17:11:12.342829.342829 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 3f88bd07-d67d-4269-a5b4-0a789f48a864
DEBUG 01-06 17:11:12.342394.342394 cuda_h.py:19] end load_into_gpu_async cost 0.0016641616821289062 seconds
DEBUG 01-06 17:11:12.342389.342389 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 17:11:12.343917.343917 cuda_h.py:19] end restore_tensors2 cost 0.00011372566223144531 seconds
DEBUG 01-06 17:11:12.343872.343872 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0025072097778320312 seconds
INFO 01-06 17:11:12.343291.343291 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 3f88bd07-d67d-4269-a5b4-0a789f48a864
DEBUG 01-06 17:11:12.343674.343674 cuda_h.py:19] end wait_cetm_experts cost 0.024325847625732422 seconds
DEBUG 01-06 17:11:12.343888.343888 cuda_h.py:19] end layer_moe_dgenerate_2 cost 0.03650164604187012 seconds
DEBUG 01-06 17:11:12.343522.343522 lmp.py:325] -------------------------------- end decode layer 2 --------------------------------
DEBUG 01-06 17:11:12.343616.343616 lmp.py:298] -------------------------------- start decode layer 3 --------------------------------
DEBUG 01-06 17:11:12.343504.343504 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-06 17:11:12.344805.344805 mlpmodule.py:367] cuda:1 cuda:1
DEBUG 01-06 17:11:12.344135.344135 cuda_h.py:10] start self_attn
cos shape torch.Size([65, 128]) sin shape torch.Size([65, 128]) position_ids tensor([[0]], device='cuda:1')
cos shape torch.Size([1, 1, 1, 128]) sin shape torch.Size([1, 1, 1, 128])
q_embed shape torch.Size([32, 16, 1, 128]) k_embed shape torch.Size([32, 16, 1, 128])
DEBUG 01-06 17:11:12.346312.346312 cuda_h.py:19] end self_attn cost 0.0018603801727294922 seconds
DEBUG 01-06 17:11:12.346899.346899 cuda_h.py:19] end iln_self_attn_paln cost 0.0026807785034179688 seconds
DEBUG 01-06 17:11:12.346590.346590 cuda_h.py:10] start layer_moe_dgenerate_3
DEBUG 01-06 17:11:12.346836.346836 cuda_h.py:10] start gate
DEBUG 01-06 17:11:12.347991.347991 cuda_h.py:19] end gate cost 0.0006353855133056641 seconds
DEBUG 01-06 17:11:12.347112.347112 cuda_h.py:10] start experts_map_get
INFO 01-06 17:11:12.347939.347939 lmp.py:611] using loaded check layer: False
INFO 01-06 17:11:12.348285.348285 lmp.py:620] 
INFO 01-06 17:11:12.348285.348285 lmp.py:620] Layer 3 Expert Device Distribution:
INFO 01-06 17:11:12.348816.348816 lmp.py:621]   Active experts: 57 (out of 64 total)
INFO 01-06 17:11:12.348281.348281 lmp.py:622] 
INFO 01-06 17:11:12.348281.348281 lmp.py:622]   Detailed Expert Distribution:
INFO 01-06 17:11:12.348176.348176 lmp.py:623]   Expert ID  | Tokens     | Actual Device  
INFO 01-06 17:11:12.348971.348971 lmp.py:624]   ----------------------------------------------------------------------
INFO 01-06 17:11:12.348244.348244 lmp.py:627]   1          | 1          |  meta           
INFO 01-06 17:11:12.348609.348609 lmp.py:627]   3          | 1          |  cuda:1         
INFO 01-06 17:11:12.348020.348020 lmp.py:627]   7          | 1          |  meta           
INFO 01-06 17:11:12.348385.348385 lmp.py:627]   13         | 1          |  cuda:1         
INFO 01-06 17:11:12.348320.348320 lmp.py:627]   18         | 1          |  meta           
INFO 01-06 17:11:12.348731.348731 lmp.py:627]   34         | 1          |  meta           
INFO 01-06 17:11:12.348904.348904 lmp.py:627]   35         | 1          |  meta           
INFO 01-06 17:11:12.348315.348315 lmp.py:627]   43         | 1          |  cuda:1         
INFO 01-06 17:11:12.348965.348965 lmp.py:627]   45         | 1          |  meta           
INFO 01-06 17:11:12.348615.348615 lmp.py:627]   48         | 1          |  meta           
INFO 01-06 17:11:12.348980.348980 lmp.py:627]   49         | 1          |  meta           
INFO 01-06 17:11:12.348822.348822 lmp.py:627]   55         | 1          |  cuda:1         
INFO 01-06 17:11:12.348187.348187 lmp.py:627]   5          | 2          |  meta           
INFO 01-06 17:11:12.348598.348598 lmp.py:627]   17         | 2          |  cuda:1         
INFO 01-06 17:11:12.348533.348533 lmp.py:627]   24         | 2          |  cuda:1         
INFO 01-06 17:11:12.349705.349705 lmp.py:627]   25         | 2          |  cuda:1         
INFO 01-06 17:11:12.349117.349117 lmp.py:627]   26         | 2          |  meta           
INFO 01-06 17:11:12.349528.349528 lmp.py:627]   31         | 2          |  cuda:1         
INFO 01-06 17:11:12.349463.349463 lmp.py:627]   36         | 2          |  meta           
INFO 01-06 17:11:12.349828.349828 lmp.py:627]   37         | 2          |  meta           
INFO 01-06 17:11:12.349193.349193 lmp.py:627]   40         | 2          |  meta           
INFO 01-06 17:11:12.349842.349842 lmp.py:627]   46         | 2          |  cuda:1         
INFO 01-06 17:11:12.349777.349777 lmp.py:627]   47         | 2          |  cuda:1         
INFO 01-06 17:11:12.349473.349473 lmp.py:627]   50         | 2          |  meta           
INFO 01-06 17:11:12.349884.349884 lmp.py:627]   60         | 2          |  cuda:1         
INFO 01-06 17:11:12.349057.349057 lmp.py:627]   0          | 3          |  cuda:1         
INFO 01-06 17:11:12.349992.349992 lmp.py:627]   4          | 3          |  meta           
INFO 01-06 17:11:12.349165.349165 lmp.py:627]   6          | 3          |  meta           
INFO 01-06 17:11:12.349099.349099 lmp.py:627]   12         | 3          |  cuda:1         
INFO 01-06 17:11:12.349511.349511 lmp.py:627]   21         | 3          |  cuda:1         
INFO 01-06 17:11:12.349445.349445 lmp.py:627]   23         | 3          |  meta           
INFO 01-06 17:11:12.349810.349810 lmp.py:627]   32         | 3          |  meta           
INFO 01-06 17:11:12.349175.349175 lmp.py:627]   38         | 3          |  cuda:1         
INFO 01-06 17:11:12.349779.349779 lmp.py:627]   44         | 3          |  cuda:1         
INFO 01-06 17:11:12.349952.349952 lmp.py:627]   58         | 3          |  cuda:1         
INFO 01-06 17:11:12.349886.349886 lmp.py:627]   59         | 3          |  meta           
INFO 01-06 17:11:12.349059.349059 lmp.py:627]   62         | 3          |  cuda:1         
INFO 01-06 17:11:12.349470.349470 lmp.py:627]   63         | 3          |  cuda:1         
INFO 01-06 17:11:12.349643.349643 lmp.py:627]   2          | 4          |  meta           
INFO 01-06 17:11:12.349816.349816 lmp.py:627]   9          | 4          |  meta           
INFO 01-06 17:11:12.349751.349751 lmp.py:627]   20         | 4          |  cuda:1         
INFO 01-06 17:11:12.349116.349116 lmp.py:627]   22         | 4          |  cuda:1         
INFO 01-06 17:11:12.349719.349719 lmp.py:627]   39         | 4          |  meta           
INFO 01-06 17:11:12.349607.349607 lmp.py:627]   52         | 4          |  meta           
INFO 01-06 17:11:12.349019.349019 lmp.py:627]   57         | 4          |  cuda:1         
INFO 01-06 17:11:12.349192.349192 lmp.py:627]   14         | 5          |  cuda:1         
INFO 01-06 17:11:12.349365.349365 lmp.py:627]   53         | 5          |  cuda:1         
INFO 01-06 17:11:12.349061.349061 lmp.py:627]   54         | 5          |  cuda:1         
INFO 01-06 17:11:12.349234.349234 lmp.py:627]   61         | 5          |  meta           
INFO 01-06 17:11:12.349645.349645 lmp.py:627]   16         | 6          |  meta           
INFO 01-06 17:11:12.349579.349579 lmp.py:627]   29         | 6          |  cuda:1         
INFO 01-06 17:11:12.349752.349752 lmp.py:627]   33         | 6          |  cuda:1         
INFO 01-06 17:11:12.349879.349879 lmp.py:627]   41         | 6          |  cuda:1         
INFO 01-06 17:11:12.349006.349006 lmp.py:627]   10         | 7          |  cuda:1         
INFO 01-06 17:11:12.349655.349655 lmp.py:627]   42         | 7          |  meta           
INFO 01-06 17:11:12.349590.349590 lmp.py:627]   8          | 11         |  cuda:1         
INFO 01-06 17:11:12.349524.349524 lmp.py:627]   19         | 18         |  cuda:1         
INFO 01-06 17:11:12.349459.349459 lmp.py:628] ============================================================
INFO 01-06 17:11:12.349459.349459 lmp.py:628] 
INFO 01-06 17:11:12.349115.349115 lmp.py:630] experts_gpu_list: [3, 13, 43, 55, 17, 24, 25, 31, 46, 47, 60, 0, 12, 21, 38, 44, 58, 62, 63, 20, 22, 57, 14, 53, 54, 29, 33, 41, 10, 8, 19] num: 31
INFO 01-06 17:11:12.350149.350149 lmp.py:631] experts_cpu_list: [1, 7, 18, 34, 35, 45, 48, 49, 5, 26, 36, 37, 40, 50, 4, 6, 23, 32, 59, 2, 9, 39, 52, 61, 16, 42] num: 26
INFO 01-06 17:11:12.350389.350389 lmp.py:632] expert_actual_device_map {0: 'cuda:1', 1: 'meta', 2: 'meta', 3: 'cuda:1', 4: 'meta', 5: 'meta', 6: 'meta', 7: 'meta', 8: 'cuda:1', 9: 'meta', 10: 'cuda:1', 11: 'meta', 12: 'cuda:1', 13: 'cuda:1', 14: 'cuda:1', 15: 'meta', 16: 'meta', 17: 'cuda:1', 18: 'meta', 19: 'cuda:1', 20: 'cuda:1', 21: 'cuda:1', 22: 'cuda:1', 23: 'meta', 24: 'cuda:1', 25: 'cuda:1', 26: 'meta', 27: 'meta', 28: 'cuda:1', 29: 'cuda:1', 30: 'meta', 31: 'cuda:1', 32: 'meta', 33: 'cuda:1', 34: 'meta', 35: 'meta', 36: 'meta', 37: 'meta', 38: 'cuda:1', 39: 'meta', 40: 'meta', 41: 'cuda:1', 42: 'meta', 43: 'cuda:1', 44: 'cuda:1', 45: 'meta', 46: 'cuda:1', 47: 'cuda:1', 48: 'meta', 49: 'meta', 50: 'meta', 51: 'meta', 52: 'meta', 53: 'cuda:1', 54: 'cuda:1', 55: 'cuda:1', 56: 'meta', 57: 'cuda:1', 58: 'cuda:1', 59: 'meta', 60: 'cuda:1', 61: 'meta', 62: 'cuda:1', 63: 'cuda:1'}
DEBUG 01-06 17:11:12.350436.350436 cuda_h.py:19] end experts_map_get cost 0.002523183822631836 seconds
DEBUG 01-06 17:11:12.350003.350003 cuda_h.py:10] start gpu_sexperts
DEBUG 01-06 17:11:12.350929.350929 cuda_h.py:19] end gpu_sexperts cost 0.0003230571746826172 seconds
DEBUG 01-06 17:11:12.350566.350566 cuda_h.py:10] start gpu_experts
DEBUG 01-06 17:11:12.351761.351761 mlpmodule.py:533] gpu group tensors cost 0.0005939006805419922 s
INFO 01-06 17:11:12.351341.351341 client.py:127] Model loaded
DEBUG 01-06 17:11:12.352476.352476 cuda_h.py:19] end sllm_worker_task cost 0.012288570404052734 seconds
DEBUG 01-06 17:11:12.352109.352109 mlpmodule.py:664]  experts func einsum cost 0.03367900848388672 s
DEBUG 01-06 17:11:12.353868.353868 cuda_h.py:10] start sllm_worker_task
DEBUG 01-06 17:11:12.353683.353683 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 17:11:12.353268.353268 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 17:11:12.353217.353217 cuda_h.py:19] end allocate_cuda_memory cost 0.0002048015594482422 seconds
DEBUG 01-06 17:11:12.353716.353716 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 17:11:12.353771.353771 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 17:11:12.353726.353726 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 17:11:12.353236.353236 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, c3e04191-b97b-4f82-9b7e-af07932880b9
DEBUG 01-06 17:11:12.353537.353537 client.py:106] call stub.LoadModelAsync
DEBUG 01-06 17:11:12.354372.354372 mlpmodule.py:566] gpu pad cost 0.0033490657806396484 s
INFO 01-06 17:11:12.355521.355521 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, c3e04191-b97b-4f82-9b7e-af07932880b9
DEBUG 01-06 17:11:12.355973.355973 cuda_h.py:19] end load_into_gpu_async cost 0.001481771469116211 seconds
DEBUG 01-06 17:11:12.355768.355768 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 17:11:12.355089.355089 cuda_h.py:19] end restore_tensors2 cost 6.937980651855469e-05 seconds
DEBUG 01-06 17:11:12.355368.355368 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0020318031311035156 seconds
DEBUG 01-06 17:11:12.355244.355244 mlpmodule.py:584] gpu group einsum cost 0.0006647109985351562 s
INFO 01-06 17:11:12.355977.355977 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, c3e04191-b97b-4f82-9b7e-af07932880b9
DEBUG 01-06 17:11:12.358605.358605 mlpmodule.py:613] gpu experts func einsum cost 0.0076045989990234375 s
DEBUG 01-06 17:11:12.358820.358820 cuda_h.py:19] end gpu_experts cost 0.0077419281005859375 seconds
DEBUG 01-06 17:11:12.358907.358907 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-06 17:11:12.358848.358848 lmp.py:661] 
DEBUG 01-06 17:11:12.358848.358848 lmp.py:661]   Computing 26 experts on CPU...
DEBUG 01-06 17:11:12.358937.358937 cuda_h.py:19] end cpu_experts_submit cost 6.651878356933594e-05 seconds
DEBUG 01-06 17:11:12.358348.358348 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-06 17:11:12.363318.363318 mlpmodule.py:706] group tensors cost 0.004475116729736328 s
INFO 01-06 17:11:12.364388.364388 client.py:127] Model loaded
DEBUG 01-06 17:11:12.365981.365981 cuda_h.py:19] end sllm_worker_task cost 0.011874914169311523 seconds
DEBUG 01-06 17:11:12.365805.365805 cuda_h.py:10] start sllm_worker_task
DEBUG 01-06 17:11:12.365283.365283 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 17:11:12.365497.365497 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 17:11:12.365035.365035 cuda_h.py:19] end allocate_cuda_memory cost 0.0002205371856689453 seconds
DEBUG 01-06 17:11:12.365794.365794 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 17:11:12.365133.365133 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 17:11:12.365326.365326 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 17:11:12.365121.365121 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, ed007730-db7b-45c7-90df-d673bafffbd8
DEBUG 01-06 17:11:12.365177.365177 client.py:106] call stub.LoadModelAsync
DEBUG 01-06 17:11:12.366336.366336 mlpmodule.py:744] pad cost 0.002880573272705078 s
DEBUG 01-06 17:11:12.366744.366744 mlpmodule.py:750] create cpu tensor cost 4.410743713378906e-05 s
DEBUG 01-06 17:11:12.366077.366077 mlpmodule.py:755] move to cpu cost 3.1948089599609375e-05 s
INFO 01-06 17:11:12.367996.367996 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, ed007730-db7b-45c7-90df-d673bafffbd8
DEBUG 01-06 17:11:12.367965.367965 cuda_h.py:19] end load_into_gpu_async cost 0.0015223026275634766 seconds
DEBUG 01-06 17:11:12.367960.367960 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 17:11:12.367989.367989 cuda_h.py:19] end restore_tensors2 cost 6.651878356933594e-05 seconds
DEBUG 01-06 17:11:12.367123.367123 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.002102375030517578 seconds
INFO 01-06 17:11:12.367455.367455 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, ed007730-db7b-45c7-90df-d673bafffbd8
DEBUG 01-06 17:11:12.370965.370965 mlpmodule.py:769] group_w3: shape=torch.Size([26, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=74973184
DEBUG 01-06 17:11:12.370372.370372 mlpmodule.py:770] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-06 17:11:12.370784.370784 mlpmodule.py:775] group_w3 first element: -0.054931640625
WARNING 01-06 17:11:12.370568.370568 mlpmodule.py:785] start einsum2
DEBUG 01-06 17:11:12.376574.376574 mlpmodule.py:795] group einsum cost 0.009831905364990234 s
DEBUG 01-06 17:11:12.376422.376422 mlpmodule.py:803] cpy2cputensor cost 0.00010776519775390625 s
INFO 01-06 17:11:12.378325.378325 client.py:127] Model loaded
DEBUG 01-06 17:11:12.379932.379932 cuda_h.py:19] end sllm_worker_task cost 0.014216899871826172 seconds
DEBUG 01-06 17:11:12.379718.379718 cuda_h.py:10] start sllm_worker_task
DEBUG 01-06 17:11:12.379123.379123 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 17:11:12.379901.379901 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 17:11:12.380201.380201 cuda_h.py:19] end allocate_cuda_memory cost 0.00041174888610839844 seconds
DEBUG 01-06 17:11:12.380728.380728 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 17:11:12.380511.380511 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 17:11:12.380970.380970 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 17:11:12.380110.380110 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 32710108-6af6-4291-b045-b7b4377eafa7
DEBUG 01-06 17:11:12.380604.380604 client.py:106] call stub.LoadModelAsync
INFO 01-06 17:11:12.381676.381676 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 32710108-6af6-4291-b045-b7b4377eafa7
DEBUG 01-06 17:11:12.382341.382341 cuda_h.py:19] end load_into_gpu_async cost 0.0016384124755859375 seconds
DEBUG 01-06 17:11:12.382574.382574 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 17:11:12.382910.382910 cuda_h.py:19] end restore_tensors2 cost 0.0001125335693359375 seconds
DEBUG 01-06 17:11:12.382626.382626 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0025091171264648438 seconds
INFO 01-06 17:11:12.382934.382934 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 32710108-6af6-4291-b045-b7b4377eafa7
DEBUG 01-06 17:11:12.383029.383029 cuda_h.py:19] end wait_cetm_experts cost 0.025033235549926758 seconds
DEBUG 01-06 17:11:12.383382.383382 cuda_h.py:19] end layer_moe_dgenerate_3 cost 0.0370631217956543 seconds
DEBUG 01-06 17:11:12.384261.384261 lmp.py:325] -------------------------------- end decode layer 3 --------------------------------
DEBUG 01-06 17:11:12.384885.384885 lmp.py:298] -------------------------------- start decode layer 4 --------------------------------
DEBUG 01-06 17:11:12.384442.384442 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-06 17:11:12.384035.384035 mlpmodule.py:367] cuda:1 cuda:1
DEBUG 01-06 17:11:12.384518.384518 cuda_h.py:10] start self_attn
cos shape torch.Size([65, 128]) sin shape torch.Size([65, 128]) position_ids tensor([[0]], device='cuda:1')
cos shape torch.Size([1, 1, 1, 128]) sin shape torch.Size([1, 1, 1, 128])
q_embed shape torch.Size([32, 16, 1, 128]) k_embed shape torch.Size([32, 16, 1, 128])
DEBUG 01-06 17:11:12.386291.386291 cuda_h.py:19] end self_attn cost 0.001874685287475586 seconds
DEBUG 01-06 17:11:12.386024.386024 cuda_h.py:19] end iln_self_attn_paln cost 0.0027112960815429688 seconds
DEBUG 01-06 17:11:12.386430.386430 cuda_h.py:10] start layer_moe_dgenerate_4
DEBUG 01-06 17:11:12.386915.386915 cuda_h.py:10] start gate
DEBUG 01-06 17:11:12.387242.387242 cuda_h.py:19] end gate cost 0.0006239414215087891 seconds
DEBUG 01-06 17:11:12.387078.387078 cuda_h.py:10] start experts_map_get
INFO 01-06 17:11:12.387070.387070 lmp.py:611] using loaded check layer: False
INFO 01-06 17:11:12.388759.388759 lmp.py:620] 
INFO 01-06 17:11:12.388759.388759 lmp.py:620] Layer 4 Expert Device Distribution:
INFO 01-06 17:11:12.388959.388959 lmp.py:621]   Active experts: 53 (out of 64 total)
INFO 01-06 17:11:12.388377.388377 lmp.py:622] 
INFO 01-06 17:11:12.388377.388377 lmp.py:622]   Detailed Expert Distribution:
INFO 01-06 17:11:12.388087.388087 lmp.py:623]   Expert ID  | Tokens     | Actual Device  
INFO 01-06 17:11:12.388121.388121 lmp.py:624]   ----------------------------------------------------------------------
INFO 01-06 17:11:12.388870.388870 lmp.py:627]   2          | 1          |  cuda:1         
INFO 01-06 17:11:12.388474.388474 lmp.py:627]   4          | 1          |  meta           
INFO 01-06 17:11:12.388885.388885 lmp.py:627]   9          | 1          |  meta           
INFO 01-06 17:11:12.388535.388535 lmp.py:627]   10         | 1          |  meta           
INFO 01-06 17:11:12.388708.388708 lmp.py:627]   13         | 1          |  meta           
INFO 01-06 17:11:12.388642.388642 lmp.py:627]   18         | 1          |  cuda:1         
INFO 01-06 17:11:12.388053.388053 lmp.py:627]   24         | 1          |  cuda:1         
INFO 01-06 17:11:12.388465.388465 lmp.py:627]   25         | 1          |  cuda:1         
INFO 01-06 17:11:12.388115.388115 lmp.py:627]   32         | 1          |  meta           
INFO 01-06 17:11:12.388480.388480 lmp.py:627]   53         | 1          |  meta           
INFO 01-06 17:11:12.388845.388845 lmp.py:627]   58         | 1          |  meta           
INFO 01-06 17:11:12.388448.388448 lmp.py:627]   63         | 1          |  meta           
INFO 01-06 17:11:12.389859.389859 lmp.py:627]   0          | 2          |  cuda:1         
INFO 01-06 17:11:12.389271.389271 lmp.py:627]   16         | 2          |  meta           
INFO 01-06 17:11:12.389205.389205 lmp.py:627]   29         | 2          |  meta           
INFO 01-06 17:11:12.389855.389855 lmp.py:627]   30         | 2          |  meta           
INFO 01-06 17:11:12.389551.389551 lmp.py:627]   33         | 2          |  cuda:1         
INFO 01-06 17:11:12.389962.389962 lmp.py:627]   34         | 2          |  meta           
INFO 01-06 17:11:12.389897.389897 lmp.py:627]   36         | 2          |  meta           
INFO 01-06 17:11:12.389070.389070 lmp.py:627]   37         | 2          |  cuda:1         
INFO 01-06 17:11:12.389435.389435 lmp.py:627]   40         | 2          |  cuda:1         
INFO 01-06 17:11:12.389038.389038 lmp.py:627]   43         | 2          |  cuda:1         
INFO 01-06 17:11:12.389211.389211 lmp.py:627]   46         | 2          |  cuda:1         
INFO 01-06 17:11:12.389384.389384 lmp.py:627]   47         | 2          |  meta           
INFO 01-06 17:11:12.389319.389319 lmp.py:627]   49         | 2          |  cuda:1         
INFO 01-06 17:11:12.389492.389492 lmp.py:627]   3          | 3          |  cuda:1         
INFO 01-06 17:11:12.389188.389188 lmp.py:627]   6          | 3          |  cuda:1         
INFO 01-06 17:11:12.389599.389599 lmp.py:627]   8          | 3          |  meta           
INFO 01-06 17:11:12.389772.389772 lmp.py:627]   11         | 3          |  meta           
INFO 01-06 17:11:12.389183.389183 lmp.py:627]   12         | 3          |  cuda:1         
INFO 01-06 17:11:12.389879.389879 lmp.py:627]   23         | 3          |  cuda:1         
INFO 01-06 17:11:12.389052.389052 lmp.py:627]   27         | 3          |  meta           
INFO 01-06 17:11:12.389179.389179 lmp.py:627]   48         | 3          |  cuda:1         
INFO 01-06 17:11:12.389590.389590 lmp.py:627]   7          | 4          |  cuda:1         
INFO 01-06 17:11:12.389763.389763 lmp.py:627]   28         | 4          |  meta           
INFO 01-06 17:11:12.389698.389698 lmp.py:627]   31         | 4          |  meta           
INFO 01-06 17:11:12.389109.389109 lmp.py:627]   35         | 4          |  cuda:1         
INFO 01-06 17:11:12.389520.389520 lmp.py:627]   5          | 5          |  cuda:1         
INFO 01-06 17:11:12.389455.389455 lmp.py:627]   15         | 5          |  cuda:1         
INFO 01-06 17:11:12.389866.389866 lmp.py:627]   44         | 5          |  meta           
INFO 01-06 17:11:12.389039.389039 lmp.py:627]   52         | 5          |  cuda:1         
INFO 01-06 17:11:12.389404.389404 lmp.py:627]   41         | 6          |  meta           
INFO 01-06 17:11:12.389769.389769 lmp.py:627]   62         | 6          |  cuda:1         
INFO 01-06 17:11:12.389134.389134 lmp.py:627]   1          | 7          |  cuda:1         
INFO 01-06 17:11:12.389546.389546 lmp.py:627]   38         | 7          |  cuda:1         
INFO 01-06 17:11:12.389719.389719 lmp.py:627]   55         | 7          |  cuda:1         
INFO 01-06 17:11:12.389891.389891 lmp.py:627]   17         | 8          |  meta           
INFO 01-06 17:11:12.389826.389826 lmp.py:627]   42         | 8          |  meta           
INFO 01-06 17:11:12.389761.389761 lmp.py:627]   59         | 8          |  cuda:1         
INFO 01-06 17:11:12.389172.389172 lmp.py:627]   21         | 9          |  cuda:1         
INFO 01-06 17:11:12.389106.389106 lmp.py:627]   22         | 9          |  cuda:1         
INFO 01-06 17:11:12.389279.389279 lmp.py:627]   39         | 9          |  cuda:1         
INFO 01-06 17:11:12.389975.389975 lmp.py:627]   50         | 10         |  cuda:1         
INFO 01-06 17:11:12.389387.389387 lmp.py:628] ============================================================
INFO 01-06 17:11:12.389387.389387 lmp.py:628] 
INFO 01-06 17:11:12.389189.389189 lmp.py:630] experts_gpu_list: [2, 18, 24, 25, 0, 33, 37, 40, 43, 46, 49, 3, 6, 12, 23, 48, 7, 35, 5, 15, 52, 62, 1, 38, 55, 59, 21, 22, 39, 50] num: 30
INFO 01-06 17:11:12.389700.389700 lmp.py:631] experts_cpu_list: [4, 9, 10, 13, 32, 53, 58, 63, 16, 29, 30, 34, 36, 47, 8, 11, 27, 28, 31, 44, 41, 17, 42] num: 23
INFO 01-06 17:11:12.390178.390178 lmp.py:632] expert_actual_device_map {0: 'cuda:1', 1: 'cuda:1', 2: 'cuda:1', 3: 'cuda:1', 4: 'meta', 5: 'cuda:1', 6: 'cuda:1', 7: 'cuda:1', 8: 'meta', 9: 'meta', 10: 'meta', 11: 'meta', 12: 'cuda:1', 13: 'meta', 14: 'meta', 15: 'cuda:1', 16: 'meta', 17: 'meta', 18: 'cuda:1', 19: 'cuda:1', 20: 'meta', 21: 'cuda:1', 22: 'cuda:1', 23: 'cuda:1', 24: 'cuda:1', 25: 'cuda:1', 26: 'meta', 27: 'meta', 28: 'meta', 29: 'meta', 30: 'meta', 31: 'meta', 32: 'meta', 33: 'cuda:1', 34: 'meta', 35: 'cuda:1', 36: 'meta', 37: 'cuda:1', 38: 'cuda:1', 39: 'cuda:1', 40: 'cuda:1', 41: 'meta', 42: 'meta', 43: 'cuda:1', 44: 'meta', 45: 'meta', 46: 'cuda:1', 47: 'meta', 48: 'cuda:1', 49: 'cuda:1', 50: 'cuda:1', 51: 'meta', 52: 'cuda:1', 53: 'meta', 54: 'meta', 55: 'cuda:1', 56: 'cuda:1', 57: 'meta', 58: 'meta', 59: 'cuda:1', 60: 'meta', 61: 'meta', 62: 'cuda:1', 63: 'meta'}
DEBUG 01-06 17:11:12.390033.390033 cuda_h.py:19] end experts_map_get cost 0.0023915767669677734 seconds
DEBUG 01-06 17:11:12.390778.390778 cuda_h.py:10] start gpu_sexperts
DEBUG 01-06 17:11:12.390320.390320 cuda_h.py:19] end gpu_sexperts cost 0.00031876564025878906 seconds
DEBUG 01-06 17:11:12.390196.390196 cuda_h.py:10] start gpu_experts
INFO 01-06 17:11:12.391061.391061 client.py:127] Model loaded
DEBUG 01-06 17:11:12.391518.391518 mlpmodule.py:533] gpu group tensors cost 0.000827789306640625 s
DEBUG 01-06 17:11:12.392440.392440 cuda_h.py:19] end sllm_worker_task cost 0.012418985366821289 seconds
DEBUG 01-06 17:11:12.392138.392138 cuda_h.py:10] start sllm_worker_task
DEBUG 01-06 17:11:12.392285.392285 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 17:11:12.392506.392506 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 17:11:12.392766.392766 cuda_h.py:19] end allocate_cuda_memory cost 0.00022339820861816406 seconds
DEBUG 01-06 17:11:12.392040.392040 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 17:11:12.392988.392988 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 17:11:12.392850.392850 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 17:11:12.392692.392692 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, cce89d75-63b3-467f-bba9-098fab145c64
DEBUG 01-06 17:11:12.392178.392178 client.py:106] call stub.LoadModelAsync
DEBUG 01-06 17:11:12.392309.392309 mlpmodule.py:664]  experts func einsum cost 0.03429698944091797 s
INFO 01-06 17:11:12.394617.394617 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, cce89d75-63b3-467f-bba9-098fab145c64
DEBUG 01-06 17:11:12.394291.394291 cuda_h.py:19] end load_into_gpu_async cost 0.0015163421630859375 seconds
DEBUG 01-06 17:11:12.394477.394477 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 17:11:12.394229.394229 cuda_h.py:19] end restore_tensors2 cost 7.152557373046875e-05 seconds
DEBUG 01-06 17:11:12.394700.394700 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0020668506622314453 seconds
INFO 01-06 17:11:12.394027.394027 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, cce89d75-63b3-467f-bba9-098fab145c64
DEBUG 01-06 17:11:12.394101.394101 mlpmodule.py:566] gpu pad cost 0.0030565261840820312 s
DEBUG 01-06 17:11:12.395164.395164 mlpmodule.py:584] gpu group einsum cost 0.00042510032653808594 s
DEBUG 01-06 17:11:12.397905.397905 mlpmodule.py:613] gpu experts func einsum cost 0.0072591304779052734 s
DEBUG 01-06 17:11:12.397650.397650 cuda_h.py:19] end gpu_experts cost 0.007395505905151367 seconds
DEBUG 01-06 17:11:12.398644.398644 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-06 17:11:12.398394.398394 lmp.py:661] 
DEBUG 01-06 17:11:12.398394.398394 lmp.py:661]   Computing 23 experts on CPU...
DEBUG 01-06 17:11:12.398137.398137 cuda_h.py:19] end cpu_experts_submit cost 5.650520324707031e-05 seconds
DEBUG 01-06 17:11:12.398217.398217 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-06 17:11:12.402309.402309 mlpmodule.py:706] group tensors cost 0.004540205001831055 s
INFO 01-06 17:11:12.403811.403811 client.py:127] Model loaded
DEBUG 01-06 17:11:12.404245.404245 cuda_h.py:19] end sllm_worker_task cost 0.01242518424987793 seconds
DEBUG 01-06 17:11:12.404566.404566 cuda_h.py:10] start sllm_worker_task
DEBUG 01-06 17:11:12.404382.404382 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 17:11:12.404887.404887 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 17:11:12.405373.405373 cuda_h.py:19] end allocate_cuda_memory cost 0.0002486705780029297 seconds
DEBUG 01-06 17:11:12.405530.405530 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 17:11:12.405968.405968 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 17:11:12.405215.405215 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 17:11:12.405110.405110 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 6bf047f0-0c97-42b8-bf71-b8c5fa8f5cb8
DEBUG 01-06 17:11:12.405417.405417 client.py:106] call stub.LoadModelAsync
DEBUG 01-06 17:11:12.406831.406831 mlpmodule.py:744] pad cost 0.0029451847076416016 s
DEBUG 01-06 17:11:12.406524.406524 mlpmodule.py:750] create cpu tensor cost 4.4345855712890625e-05 s
DEBUG 01-06 17:11:12.406997.406997 mlpmodule.py:755] move to cpu cost 3.147125244140625e-05 s
INFO 01-06 17:11:12.406278.406278 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 6bf047f0-0c97-42b8-bf71-b8c5fa8f5cb8
DEBUG 01-06 17:11:12.406453.406453 cuda_h.py:19] end load_into_gpu_async cost 0.001613616943359375 seconds
DEBUG 01-06 17:11:12.406977.406977 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 17:11:12.407881.407881 cuda_h.py:19] end restore_tensors2 cost 7.200241088867188e-05 seconds
DEBUG 01-06 17:11:12.407870.407870 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.002294301986694336 seconds
INFO 01-06 17:11:12.407874.407874 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 6bf047f0-0c97-42b8-bf71-b8c5fa8f5cb8
DEBUG 01-06 17:11:12.410156.410156 mlpmodule.py:769] group_w3: shape=torch.Size([23, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=66322432
DEBUG 01-06 17:11:12.410648.410648 mlpmodule.py:770] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-06 17:11:12.410869.410869 mlpmodule.py:775] group_w3 first element: 0.0086669921875
WARNING 01-06 17:11:12.410892.410892 mlpmodule.py:785] start einsum2
DEBUG 01-06 17:11:12.416107.416107 mlpmodule.py:795] group einsum cost 0.009757757186889648 s
DEBUG 01-06 17:11:12.416286.416286 mlpmodule.py:803] cpy2cputensor cost 9.369850158691406e-05 s
INFO 01-06 17:11:12.417495.417495 client.py:127] Model loaded
DEBUG 01-06 17:11:12.418469.418469 cuda_h.py:19] end sllm_worker_task cost 0.014050006866455078 seconds
DEBUG 01-06 17:11:12.418466.418466 cuda_h.py:10] start sllm_worker_task
DEBUG 01-06 17:11:12.419249.419249 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 17:11:12.419165.419165 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 17:11:12.419797.419797 cuda_h.py:19] end allocate_cuda_memory cost 0.00041174888610839844 seconds
DEBUG 01-06 17:11:12.419761.419761 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 17:11:12.419783.419783 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 17:11:12.419586.419586 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 17:11:12.419071.419071 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, b8d92b45-cc1c-4b73-ab6b-5d5b2da079e9
DEBUG 01-06 17:11:12.419638.419638 client.py:106] call stub.LoadModelAsync
INFO 01-06 17:11:12.421626.421626 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, b8d92b45-cc1c-4b73-ab6b-5d5b2da079e9
DEBUG 01-06 17:11:12.421383.421383 cuda_h.py:19] end load_into_gpu_async cost 0.0017096996307373047 seconds
DEBUG 01-06 17:11:12.421285.421285 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 17:11:12.421720.421720 cuda_h.py:19] end restore_tensors2 cost 0.00011467933654785156 seconds
DEBUG 01-06 17:11:12.421795.421795 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0026106834411621094 seconds
INFO 01-06 17:11:12.421618.421618 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, b8d92b45-cc1c-4b73-ab6b-5d5b2da079e9
DEBUG 01-06 17:11:12.422656.422656 cuda_h.py:19] end wait_cetm_experts cost 0.024711132049560547 seconds
DEBUG 01-06 17:11:12.423923.423923 cuda_h.py:19] end layer_moe_dgenerate_4 cost 0.036244869232177734 seconds
DEBUG 01-06 17:11:12.423803.423803 lmp.py:325] -------------------------------- end decode layer 4 --------------------------------
DEBUG 01-06 17:11:12.423996.423996 lmp.py:298] -------------------------------- start decode layer 5 --------------------------------
DEBUG 01-06 17:11:12.423030.423030 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-06 17:11:12.423377.423377 mlpmodule.py:367] cuda:1 cuda:1
DEBUG 01-06 17:11:12.423641.423641 cuda_h.py:10] start self_attn
cos shape torch.Size([65, 128]) sin shape torch.Size([65, 128]) position_ids tensor([[0]], device='cuda:1')
cos shape torch.Size([1, 1, 1, 128]) sin shape torch.Size([1, 1, 1, 128])
q_embed shape torch.Size([32, 16, 1, 128]) k_embed shape torch.Size([32, 16, 1, 128])
DEBUG 01-06 17:11:12.425250.425250 cuda_h.py:19] end self_attn cost 0.0018994808197021484 seconds
DEBUG 01-06 17:11:12.426506.426506 cuda_h.py:19] end iln_self_attn_paln cost 0.002704620361328125 seconds
DEBUG 01-06 17:11:12.426196.426196 cuda_h.py:10] start layer_moe_dgenerate_5
DEBUG 01-06 17:11:12.426635.426635 cuda_h.py:10] start gate
DEBUG 01-06 17:11:12.426074.426074 cuda_h.py:19] end gate cost 0.0006351470947265625 seconds
DEBUG 01-06 17:11:12.426911.426911 cuda_h.py:10] start experts_map_get
INFO 01-06 17:11:12.427300.427300 lmp.py:611] using loaded check layer: False
INFO 01-06 17:11:12.427902.427902 lmp.py:620] 
INFO 01-06 17:11:12.427902.427902 lmp.py:620] Layer 5 Expert Device Distribution:
INFO 01-06 17:11:12.427547.427547 lmp.py:621]   Active experts: 56 (out of 64 total)
INFO 01-06 17:11:12.427872.427872 lmp.py:622] 
INFO 01-06 17:11:12.427872.427872 lmp.py:622]   Detailed Expert Distribution:
INFO 01-06 17:11:12.427006.427006 lmp.py:623]   Expert ID  | Tokens     | Actual Device  
INFO 01-06 17:11:12.428801.428801 lmp.py:624]   ----------------------------------------------------------------------
INFO 01-06 17:11:12.428073.428073 lmp.py:627]   3          | 1          |  meta           
INFO 01-06 17:11:12.428392.428392 lmp.py:627]   13         | 1          |  meta           
INFO 01-06 17:11:12.428996.428996 lmp.py:627]   22         | 1          |  meta           
INFO 01-06 17:11:12.428361.428361 lmp.py:627]   25         | 1          |  meta           
INFO 01-06 17:11:12.428202.428202 lmp.py:627]   27         | 1          |  cuda:1         
INFO 01-06 17:11:12.428806.428806 lmp.py:627]   29         | 1          |  cuda:1         
INFO 01-06 17:11:12.428601.428601 lmp.py:627]   43         | 1          |  cuda:1         
INFO 01-06 17:11:12.428397.428397 lmp.py:627]   51         | 1          |  cuda:1         
INFO 01-06 17:11:12.428762.428762 lmp.py:627]   58         | 1          |  cuda:1         
INFO 01-06 17:11:12.428889.428889 lmp.py:627]   5          | 2          |  meta           
INFO 01-06 17:11:12.428777.428777 lmp.py:627]   6          | 2          |  cuda:1         
INFO 01-06 17:11:12.428142.428142 lmp.py:627]   11         | 2          |  cuda:1         
INFO 01-06 17:11:12.428268.428268 lmp.py:627]   12         | 2          |  meta           
INFO 01-06 17:11:12.428633.428633 lmp.py:627]   15         | 2          |  meta           
INFO 01-06 17:11:12.428760.428760 lmp.py:627]   16         | 2          |  meta           
INFO 01-06 17:11:12.428622.428622 lmp.py:627]   17         | 2          |  meta           
INFO 01-06 17:11:12.428656.428656 lmp.py:627]   18         | 2          |  cuda:1         
INFO 01-06 17:11:12.428213.428213 lmp.py:627]   23         | 2          |  meta           
INFO 01-06 17:11:12.428009.428009 lmp.py:627]   24         | 2          |  cuda:1         
INFO 01-06 17:11:12.428612.428612 lmp.py:627]   26         | 2          |  cuda:1         
INFO 01-06 17:11:12.428977.428977 lmp.py:627]   30         | 2          |  meta           
INFO 01-06 17:11:12.428104.428104 lmp.py:627]   37         | 2          |  cuda:1         
INFO 01-06 17:11:12.428469.428469 lmp.py:627]   44         | 2          |  meta           
INFO 01-06 17:11:12.428834.428834 lmp.py:627]   45         | 2          |  meta           
INFO 01-06 17:11:12.428484.428484 lmp.py:627]   52         | 2          |  meta           
INFO 01-06 17:11:12.428087.428087 lmp.py:627]   10         | 3          |  cuda:1         
INFO 01-06 17:11:12.428644.428644 lmp.py:627]   21         | 3          |  cuda:1         
INFO 01-06 17:11:12.428201.428201 lmp.py:627]   35         | 3          |  meta           
INFO 01-06 17:11:12.428520.428520 lmp.py:627]   36         | 3          |  meta           
INFO 01-06 17:11:12.428647.428647 lmp.py:627]   39         | 3          |  meta           
INFO 01-06 17:11:12.428012.428012 lmp.py:627]   42         | 3          |  meta           
INFO 01-06 17:11:12.428615.428615 lmp.py:627]   47         | 3          |  cuda:1         
INFO 01-06 17:11:12.428663.428663 lmp.py:627]   54         | 3          |  cuda:1         
INFO 01-06 17:11:12.428266.428266 lmp.py:627]   55         | 3          |  cuda:1         
INFO 01-06 17:11:12.428751.428751 lmp.py:627]   59         | 3          |  cuda:1         
INFO 01-06 17:11:12.428600.428600 lmp.py:627]   60         | 3          |  meta           
INFO 01-06 17:11:12.428441.428441 lmp.py:627]   61         | 3          |  meta           
INFO 01-06 17:11:12.428330.428330 lmp.py:627]   62         | 3          |  cuda:1         
INFO 01-06 17:11:12.428933.428933 lmp.py:627]   63         | 3          |  cuda:1         
INFO 01-06 17:11:12.429106.429106 lmp.py:627]   8          | 4          |  meta           
INFO 01-06 17:11:12.429756.429756 lmp.py:627]   32         | 4          |  meta           
INFO 01-06 17:11:12.429690.429690 lmp.py:627]   38         | 4          |  cuda:1         
INFO 01-06 17:11:12.429340.429340 lmp.py:627]   40         | 4          |  cuda:1         
INFO 01-06 17:11:12.429341.429341 lmp.py:627]   0          | 5          |  meta           
INFO 01-06 17:11:12.429137.429137 lmp.py:627]   9          | 5          |  cuda:1         
INFO 01-06 17:11:12.429502.429502 lmp.py:627]   14         | 5          |  meta           
INFO 01-06 17:11:12.429867.429867 lmp.py:627]   19         | 5          |  cuda:1         
INFO 01-06 17:11:12.429755.429755 lmp.py:627]   57         | 5          |  meta           
INFO 01-06 17:11:12.429597.429597 lmp.py:627]   7          | 6          |  cuda:1         
INFO 01-06 17:11:12.429723.429723 lmp.py:627]   28         | 6          |  meta           
INFO 01-06 17:11:12.429612.429612 lmp.py:627]   46         | 6          |  meta           
INFO 01-06 17:11:12.429500.429500 lmp.py:627]   1          | 7          |  cuda:1         
INFO 01-06 17:11:12.429865.429865 lmp.py:627]   56         | 7          |  cuda:1         
INFO 01-06 17:11:12.429707.429707 lmp.py:627]   33         | 10         |  cuda:1         
INFO 01-06 17:11:12.429787.429787 lmp.py:627]   48         | 12         |  cuda:1         
INFO 01-06 17:11:12.429629.429629 lmp.py:627]   53         | 14         |  cuda:1         
INFO 01-06 17:11:12.429517.429517 lmp.py:628] ============================================================
INFO 01-06 17:11:12.429517.429517 lmp.py:628] 
INFO 01-06 17:11:12.429889.429889 lmp.py:630] experts_gpu_list: [27, 29, 43, 51, 58, 6, 11, 18, 24, 26, 37, 10, 21, 47, 54, 55, 59, 62, 63, 38, 40, 9, 19, 7, 1, 56, 33, 48, 53] num: 29
INFO 01-06 17:11:12.429115.429115 lmp.py:631] experts_cpu_list: [3, 13, 22, 25, 5, 12, 15, 16, 17, 23, 30, 44, 45, 52, 35, 36, 39, 42, 60, 61, 8, 32, 0, 14, 57, 28, 46] num: 27
INFO 01-06 17:11:12.429070.429070 lmp.py:632] expert_actual_device_map {0: 'meta', 1: 'cuda:1', 2: 'meta', 3: 'meta', 4: 'meta', 5: 'meta', 6: 'cuda:1', 7: 'cuda:1', 8: 'meta', 9: 'cuda:1', 10: 'cuda:1', 11: 'cuda:1', 12: 'meta', 13: 'meta', 14: 'meta', 15: 'meta', 16: 'meta', 17: 'meta', 18: 'cuda:1', 19: 'cuda:1', 20: 'cuda:1', 21: 'cuda:1', 22: 'meta', 23: 'meta', 24: 'cuda:1', 25: 'meta', 26: 'cuda:1', 27: 'cuda:1', 28: 'meta', 29: 'cuda:1', 30: 'meta', 31: 'meta', 32: 'meta', 33: 'cuda:1', 34: 'meta', 35: 'meta', 36: 'meta', 37: 'cuda:1', 38: 'cuda:1', 39: 'meta', 40: 'cuda:1', 41: 'meta', 42: 'meta', 43: 'cuda:1', 44: 'meta', 45: 'meta', 46: 'meta', 47: 'cuda:1', 48: 'cuda:1', 49: 'cuda:1', 50: 'cuda:1', 51: 'cuda:1', 52: 'meta', 53: 'cuda:1', 54: 'cuda:1', 55: 'cuda:1', 56: 'cuda:1', 57: 'meta', 58: 'cuda:1', 59: 'cuda:1', 60: 'meta', 61: 'meta', 62: 'cuda:1', 63: 'cuda:1'}
DEBUG 01-06 17:11:12.429594.429594 cuda_h.py:19] end experts_map_get cost 0.0025773048400878906 seconds
DEBUG 01-06 17:11:12.429339.429339 cuda_h.py:10] start gpu_sexperts
DEBUG 01-06 17:11:12.430404.430404 cuda_h.py:19] end gpu_sexperts cost 0.0003235340118408203 seconds
DEBUG 01-06 17:11:12.430088.430088 cuda_h.py:10] start gpu_experts
INFO 01-06 17:11:12.430842.430842 client.py:127] Model loaded
DEBUG 01-06 17:11:12.431799.431799 mlpmodule.py:533] gpu group tensors cost 0.0009734630584716797 s
DEBUG 01-06 17:11:12.431794.431794 cuda_h.py:19] end sllm_worker_task cost 0.012515068054199219 seconds
DEBUG 01-06 17:11:12.431015.431015 cuda_h.py:10] start sllm_worker_task
DEBUG 01-06 17:11:12.431355.431355 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 17:11:12.431860.431860 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 17:11:12.431762.431762 cuda_h.py:19] end allocate_cuda_memory cost 0.0002071857452392578 seconds
DEBUG 01-06 17:11:12.432234.432234 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 17:11:12.432712.432712 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 17:11:12.432913.432913 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 17:11:12.432523.432523 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 6507e553-439b-4f87-8232-9d72d2918a8e
DEBUG 01-06 17:11:12.432638.432638 client.py:106] call stub.LoadModelAsync
DEBUG 01-06 17:11:12.432591.432591 mlpmodule.py:664]  experts func einsum cost 0.034155845642089844 s
INFO 01-06 17:11:12.433336.433336 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 6507e553-439b-4f87-8232-9d72d2918a8e
DEBUG 01-06 17:11:12.433339.433339 cuda_h.py:19] end load_into_gpu_async cost 0.0015110969543457031 seconds
DEBUG 01-06 17:11:12.433811.433811 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 17:11:12.433602.433602 cuda_h.py:19] end restore_tensors2 cost 6.461143493652344e-05 seconds
DEBUG 01-06 17:11:12.433166.433166 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0020444393157958984 seconds
INFO 01-06 17:11:12.433923.433923 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 6507e553-439b-4f87-8232-9d72d2918a8e
DEBUG 01-06 17:11:12.434104.434104 mlpmodule.py:566] gpu pad cost 0.002848386764526367 s
DEBUG 01-06 17:11:12.434323.434323 mlpmodule.py:584] gpu group einsum cost 0.00033473968505859375 s
DEBUG 01-06 17:11:12.437899.437899 mlpmodule.py:613] gpu experts func einsum cost 0.006948709487915039 s
DEBUG 01-06 17:11:12.437531.437531 cuda_h.py:19] end gpu_experts cost 0.0070726871490478516 seconds
DEBUG 01-06 17:11:12.437333.437333 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-06 17:11:12.437559.437559 lmp.py:661] 
DEBUG 01-06 17:11:12.437559.437559 lmp.py:661]   Computing 27 experts on CPU...
DEBUG 01-06 17:11:12.437634.437634 cuda_h.py:19] end cpu_experts_submit cost 5.435943603515625e-05 seconds
DEBUG 01-06 17:11:12.437476.437476 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-06 17:11:12.446585.446585 mlpmodule.py:706] group tensors cost 0.008845806121826172 s
INFO 01-06 17:11:12.447853.447853 client.py:127] Model loaded
DEBUG 01-06 17:11:12.448985.448985 cuda_h.py:19] end sllm_worker_task cost 0.01685333251953125 seconds
DEBUG 01-06 17:11:12.448584.448584 cuda_h.py:10] start sllm_worker_task
DEBUG 01-06 17:11:12.448599.448599 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 17:11:12.448634.448634 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 17:11:12.448537.448537 cuda_h.py:19] end allocate_cuda_memory cost 0.00020122528076171875 seconds
DEBUG 01-06 17:11:12.449878.449878 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 17:11:12.449131.449131 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 17:11:12.449623.449623 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 17:11:12.449333.449333 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 15e4e8f6-b83a-4e21-a83e-bda8e6ae7db2
DEBUG 01-06 17:11:12.449561.449561 client.py:106] call stub.LoadModelAsync
DEBUG 01-06 17:11:12.450382.450382 mlpmodule.py:744] pad cost 0.0035288333892822266 s
INFO 01-06 17:11:12.450121.450121 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 15e4e8f6-b83a-4e21-a83e-bda8e6ae7db2
DEBUG 01-06 17:11:12.450146.450146 mlpmodule.py:750] create cpu tensor cost 6.175041198730469e-05 s
DEBUG 01-06 17:11:12.450513.450513 cuda_h.py:19] end load_into_gpu_async cost 0.0017056465148925781 seconds
DEBUG 01-06 17:11:12.450146.450146 mlpmodule.py:755] move to cpu cost 5.340576171875e-05 s
DEBUG 01-06 17:11:12.451691.451691 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 17:11:12.451892.451892 cuda_h.py:19] end restore_tensors2 cost 8.344650268554688e-05 seconds
DEBUG 01-06 17:11:12.451860.451860 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0026159286499023438 seconds
INFO 01-06 17:11:12.451206.451206 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 15e4e8f6-b83a-4e21-a83e-bda8e6ae7db2
DEBUG 01-06 17:11:12.454542.454542 mlpmodule.py:769] group_w3: shape=torch.Size([27, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=77856768
DEBUG 01-06 17:11:12.454743.454743 mlpmodule.py:770] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-06 17:11:12.454447.454447 mlpmodule.py:775] group_w3 first element: -0.046142578125
WARNING 01-06 17:11:12.454424.454424 mlpmodule.py:785] start einsum2
DEBUG 01-06 17:11:12.461068.461068 mlpmodule.py:795] group einsum cost 0.010361194610595703 s
DEBUG 01-06 17:11:12.461703.461703 mlpmodule.py:803] cpy2cputensor cost 9.775161743164062e-05 s
INFO 01-06 17:11:12.461115.461115 client.py:127] Model loaded
DEBUG 01-06 17:11:12.463388.463388 cuda_h.py:19] end sllm_worker_task cost 0.014428853988647461 seconds
DEBUG 01-06 17:11:12.463371.463371 cuda_h.py:10] start sllm_worker_task
DEBUG 01-06 17:11:12.463809.463809 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 17:11:12.463706.463706 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 17:11:12.463926.463926 cuda_h.py:19] end allocate_cuda_memory cost 0.00039887428283691406 seconds
DEBUG 01-06 17:11:12.463790.463790 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 17:11:12.463229.463229 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 17:11:12.463257.463257 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 17:11:12.464351.464351 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, fe35afda-c37a-4614-9344-b6bbe270b829
DEBUG 01-06 17:11:12.464362.464362 client.py:106] call stub.LoadModelAsync
INFO 01-06 17:11:12.465890.465890 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, fe35afda-c37a-4614-9344-b6bbe270b829
DEBUG 01-06 17:11:12.465985.465985 cuda_h.py:19] end load_into_gpu_async cost 0.0016112327575683594 seconds
DEBUG 01-06 17:11:12.465741.465741 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 17:11:12.465792.465792 cuda_h.py:19] end restore_tensors2 cost 0.00011372566223144531 seconds
DEBUG 01-06 17:11:12.465508.465508 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0024521350860595703 seconds
INFO 01-06 17:11:12.465552.465552 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, fe35afda-c37a-4614-9344-b6bbe270b829
DEBUG 01-06 17:11:12.468418.468418 cuda_h.py:19] end wait_cetm_experts cost 0.030666828155517578 seconds
DEBUG 01-06 17:11:12.468248.468248 cuda_h.py:19] end layer_moe_dgenerate_5 cost 0.042063236236572266 seconds
DEBUG 01-06 17:11:12.468532.468532 lmp.py:325] -------------------------------- end decode layer 5 --------------------------------
DEBUG 01-06 17:11:12.468494.468494 lmp.py:298] -------------------------------- start decode layer 6 --------------------------------
DEBUG 01-06 17:11:12.468005.468005 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-06 17:11:12.468544.468544 mlpmodule.py:367] cuda:1 cuda:1
DEBUG 01-06 17:11:12.468178.468178 cuda_h.py:10] start self_attn
cos shape torch.Size([65, 128]) sin shape torch.Size([65, 128]) position_ids tensor([[0]], device='cuda:1')
cos shape torch.Size([1, 1, 1, 128]) sin shape torch.Size([1, 1, 1, 128])
q_embed shape torch.Size([32, 16, 1, 128]) k_embed shape torch.Size([32, 16, 1, 128])
DEBUG 01-06 17:11:12.470898.470898 cuda_h.py:19] end self_attn cost 0.0018391609191894531 seconds
DEBUG 01-06 17:11:12.471809.471809 cuda_h.py:19] end iln_self_attn_paln cost 0.0026307106018066406 seconds
DEBUG 01-06 17:11:12.471023.471023 cuda_h.py:10] start layer_moe_dgenerate_6
DEBUG 01-06 17:11:12.471031.471031 cuda_h.py:10] start gate
DEBUG 01-06 17:11:12.471186.471186 cuda_h.py:19] end gate cost 0.0006363391876220703 seconds
DEBUG 01-06 17:11:12.471784.471784 cuda_h.py:10] start experts_map_get
INFO 01-06 17:11:12.472617.472617 lmp.py:611] using loaded check layer: False
INFO 01-06 17:11:12.472452.472452 lmp.py:620] 
INFO 01-06 17:11:12.472452.472452 lmp.py:620] Layer 6 Expert Device Distribution:
INFO 01-06 17:11:12.473315.473315 lmp.py:621]   Active experts: 58 (out of 64 total)
INFO 01-06 17:11:12.473018.473018 lmp.py:622] 
INFO 01-06 17:11:12.473018.473018 lmp.py:622]   Detailed Expert Distribution:
INFO 01-06 17:11:12.473244.473244 lmp.py:623]   Expert ID  | Tokens     | Actual Device  
INFO 01-06 17:11:12.473754.473754 lmp.py:624]   ----------------------------------------------------------------------
INFO 01-06 17:11:12.473219.473219 lmp.py:627]   1          | 1          |  meta           
INFO 01-06 17:11:12.473392.473392 lmp.py:627]   7          | 1          |  meta           
INFO 01-06 17:11:12.473849.473849 lmp.py:627]   9          | 1          |  meta           
INFO 01-06 17:11:12.473069.473069 lmp.py:627]   14         | 1          |  meta           
INFO 01-06 17:11:12.473003.473003 lmp.py:627]   18         | 1          |  meta           
INFO 01-06 17:11:12.473222.473222 lmp.py:627]   26         | 1          |  meta           
INFO 01-06 17:11:12.473442.473442 lmp.py:627]   41         | 1          |  cuda:1         
INFO 01-06 17:11:12.473423.473423 lmp.py:627]   42         | 1          |  cuda:1         
INFO 01-06 17:11:12.473357.473357 lmp.py:627]   46         | 1          |  cuda:1         
INFO 01-06 17:11:12.473768.473768 lmp.py:627]   58         | 1          |  meta           
INFO 01-06 17:11:12.473180.473180 lmp.py:627]   59         | 1          |  meta           
INFO 01-06 17:11:12.473637.473637 lmp.py:627]   2          | 2          |  meta           
INFO 01-06 17:11:12.473618.473618 lmp.py:627]   4          | 2          |  cuda:1         
INFO 01-06 17:11:12.473361.473361 lmp.py:627]   10         | 2          |  meta           
INFO 01-06 17:11:12.473103.473103 lmp.py:627]   11         | 2          |  meta           
INFO 01-06 17:11:12.473084.473084 lmp.py:627]   15         | 2          |  cuda:1         
INFO 01-06 17:11:12.473303.473303 lmp.py:627]   17         | 2          |  meta           
INFO 01-06 17:11:12.473715.473715 lmp.py:627]   19         | 2          |  cuda:1         
INFO 01-06 17:11:12.473126.473126 lmp.py:627]   20         | 2          |  cuda:1         
INFO 01-06 17:11:12.473776.473776 lmp.py:627]   23         | 2          |  meta           
INFO 01-06 17:11:12.473995.473995 lmp.py:627]   24         | 2          |  cuda:1         
INFO 01-06 17:11:12.473976.473976 lmp.py:627]   29         | 2          |  meta           
INFO 01-06 17:11:12.473957.473957 lmp.py:627]   31         | 2          |  cuda:1         
INFO 01-06 17:11:12.473699.473699 lmp.py:627]   32         | 2          |  meta           
INFO 01-06 17:11:12.473680.473680 lmp.py:627]   34         | 2          |  meta           
INFO 01-06 17:11:12.473899.473899 lmp.py:627]   43         | 2          |  meta           
INFO 01-06 17:11:12.473595.473595 lmp.py:627]   44         | 2          |  cuda:1         
INFO 01-06 17:11:12.473007.473007 lmp.py:627]   45         | 2          |  meta           
INFO 01-06 17:11:12.473179.473179 lmp.py:627]   47         | 2          |  cuda:1         
INFO 01-06 17:11:12.473591.473591 lmp.py:627]   48         | 2          |  cuda:1         
INFO 01-06 17:11:12.473810.473810 lmp.py:627]   49         | 2          |  cuda:1         
INFO 01-06 17:11:12.473652.473652 lmp.py:627]   50         | 2          |  cuda:1         
INFO 01-06 17:11:12.473586.473586 lmp.py:627]   52         | 2          |  cuda:1         
INFO 01-06 17:11:12.473567.473567 lmp.py:627]   53         | 2          |  meta           
INFO 01-06 17:11:12.473548.473548 lmp.py:627]   61         | 2          |  cuda:1         
INFO 01-06 17:11:12.473529.473529 lmp.py:627]   62         | 2          |  meta           
INFO 01-06 17:11:12.473271.473271 lmp.py:627]   5          | 3          |  cuda:1         
INFO 01-06 17:11:12.473683.473683 lmp.py:627]   8          | 3          |  cuda:1         
INFO 01-06 17:11:12.473332.473332 lmp.py:627]   33         | 3          |  meta           
INFO 01-06 17:11:12.473552.473552 lmp.py:627]   40         | 3          |  cuda:1         
INFO 01-06 17:11:12.473771.473771 lmp.py:627]   57         | 3          |  cuda:1         
INFO 01-06 17:11:12.474752.474752 lmp.py:627]   22         | 4          |  meta           
INFO 01-06 17:11:12.474733.474733 lmp.py:627]   35         | 4          |  cuda:1         
INFO 01-06 17:11:12.474952.474952 lmp.py:627]   63         | 4          |  meta           
INFO 01-06 17:11:12.474171.474171 lmp.py:627]   6          | 5          |  cuda:1         
INFO 01-06 17:11:12.474390.474390 lmp.py:627]   13         | 5          |  meta           
INFO 01-06 17:11:12.474610.474610 lmp.py:627]   55         | 5          |  meta           
INFO 01-06 17:11:12.474829.474829 lmp.py:627]   60         | 5          |  cuda:1         
INFO 01-06 17:11:12.474763.474763 lmp.py:627]   21         | 6          |  cuda:1         
INFO 01-06 17:11:12.474652.474652 lmp.py:627]   27         | 6          |  cuda:1         
INFO 01-06 17:11:12.474109.474109 lmp.py:627]   51         | 6          |  meta           
INFO 01-06 17:11:12.474090.474090 lmp.py:627]   56         | 6          |  cuda:1         
INFO 01-06 17:11:12.474309.474309 lmp.py:627]   12         | 7          |  cuda:1         
INFO 01-06 17:11:12.474529.474529 lmp.py:627]   28         | 9          |  meta           
INFO 01-06 17:11:12.474509.474509 lmp.py:627]   38         | 9          |  cuda:1         
INFO 01-06 17:11:12.474967.474967 lmp.py:627]   39         | 10         |  cuda:1         
INFO 01-06 17:11:12.474948.474948 lmp.py:627]   25         | 12         |  cuda:1         
INFO 01-06 17:11:12.474167.474167 lmp.py:627]   36         | 13         |  cuda:1         
INFO 01-06 17:11:12.474625.474625 lmp.py:628] ============================================================
INFO 01-06 17:11:12.474625.474625 lmp.py:628] 
INFO 01-06 17:11:12.474997.474997 lmp.py:630] experts_gpu_list: [41, 42, 46, 4, 15, 19, 20, 24, 31, 44, 47, 48, 49, 50, 52, 61, 5, 8, 40, 57, 35, 6, 60, 21, 27, 56, 12, 38, 39, 25, 36] num: 31
INFO 01-06 17:11:12.474607.474607 lmp.py:631] experts_cpu_list: [1, 7, 9, 14, 18, 26, 58, 59, 2, 10, 11, 17, 23, 29, 32, 34, 43, 45, 53, 62, 33, 22, 63, 13, 55, 51, 28] num: 27
INFO 01-06 17:11:12.474085.474085 lmp.py:632] expert_actual_device_map {0: 'meta', 1: 'meta', 2: 'meta', 3: 'meta', 4: 'cuda:1', 5: 'cuda:1', 6: 'cuda:1', 7: 'meta', 8: 'cuda:1', 9: 'meta', 10: 'meta', 11: 'meta', 12: 'cuda:1', 13: 'meta', 14: 'meta', 15: 'cuda:1', 16: 'meta', 17: 'meta', 18: 'meta', 19: 'cuda:1', 20: 'cuda:1', 21: 'cuda:1', 22: 'meta', 23: 'meta', 24: 'cuda:1', 25: 'cuda:1', 26: 'meta', 27: 'cuda:1', 28: 'meta', 29: 'meta', 30: 'cuda:1', 31: 'cuda:1', 32: 'meta', 33: 'meta', 34: 'meta', 35: 'cuda:1', 36: 'cuda:1', 37: 'meta', 38: 'cuda:1', 39: 'cuda:1', 40: 'cuda:1', 41: 'cuda:1', 42: 'cuda:1', 43: 'meta', 44: 'cuda:1', 45: 'meta', 46: 'cuda:1', 47: 'cuda:1', 48: 'cuda:1', 49: 'cuda:1', 50: 'cuda:1', 51: 'meta', 52: 'cuda:1', 53: 'meta', 54: 'meta', 55: 'meta', 56: 'cuda:1', 57: 'cuda:1', 58: 'meta', 59: 'meta', 60: 'cuda:1', 61: 'cuda:1', 62: 'meta', 63: 'meta'}
DEBUG 01-06 17:11:12.474510.474510 cuda_h.py:19] end experts_map_get cost 0.002468585968017578 seconds
INFO 01-06 17:11:12.474606.474606 client.py:127] Model loaded
DEBUG 01-06 17:11:12.475932.475932 cuda_h.py:19] end sllm_worker_task cost 0.012167692184448242 seconds
DEBUG 01-06 17:11:12.475100.475100 cuda_h.py:10] start gpu_sexperts
DEBUG 01-06 17:11:12.475241.475241 cuda_h.py:10] start sllm_worker_task
DEBUG 01-06 17:11:12.475485.475485 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 17:11:12.475997.475997 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 17:11:12.478036.478036 cuda_h.py:19] end allocate_cuda_memory cost 0.002691030502319336 seconds
DEBUG 01-06 17:11:12.478363.478363 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 17:11:12.478311.478311 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 17:11:12.478411.478411 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 17:11:12.478684.478684 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 1b9b8b04-2904-424a-8bac-5cb63d5dfedf
DEBUG 01-06 17:11:12.478547.478547 client.py:106] call stub.LoadModelAsync
DEBUG 01-06 17:11:12.478249.478249 mlpmodule.py:664]  experts func einsum cost 0.04155135154724121 s
DEBUG 01-06 17:11:12.479575.479575 cuda_h.py:19] end gpu_sexperts cost 0.003557920455932617 seconds
DEBUG 01-06 17:11:12.479267.479267 cuda_h.py:10] start gpu_experts
DEBUG 01-06 17:11:12.479345.479345 mlpmodule.py:533] gpu group tensors cost 0.0004792213439941406 s
INFO 01-06 17:11:12.480539.480539 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 1b9b8b04-2904-424a-8bac-5cb63d5dfedf
DEBUG 01-06 17:11:12.480090.480090 cuda_h.py:19] end load_into_gpu_async cost 0.0015211105346679688 seconds
DEBUG 01-06 17:11:12.480124.480124 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 17:11:12.480776.480776 cuda_h.py:19] end restore_tensors2 cost 6.771087646484375e-05 seconds
DEBUG 01-06 17:11:12.480771.480771 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0045320987701416016 seconds
INFO 01-06 17:11:12.480005.480005 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 1b9b8b04-2904-424a-8bac-5cb63d5dfedf
DEBUG 01-06 17:11:12.481193.481193 mlpmodule.py:566] gpu pad cost 0.0017251968383789062 s
DEBUG 01-06 17:11:12.482650.482650 mlpmodule.py:584] gpu group einsum cost 0.0003299713134765625 s
DEBUG 01-06 17:11:12.484855.484855 mlpmodule.py:613] gpu experts func einsum cost 0.005418539047241211 s
DEBUG 01-06 17:11:12.484625.484625 cuda_h.py:19] end gpu_experts cost 0.005538225173950195 seconds
DEBUG 01-06 17:11:12.484342.484342 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-06 17:11:12.484714.484714 lmp.py:661] 
DEBUG 01-06 17:11:12.484714.484714 lmp.py:661]   Computing 27 experts on CPU...
DEBUG 01-06 17:11:12.484219.484219 cuda_h.py:19] end cpu_experts_submit cost 5.626678466796875e-05 seconds
DEBUG 01-06 17:11:12.485299.485299 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-06 17:11:12.493441.493441 mlpmodule.py:706] group tensors cost 0.00861358642578125 s
INFO 01-06 17:11:12.494047.494047 client.py:127] Model loaded
DEBUG 01-06 17:11:12.496065.496065 cuda_h.py:19] end sllm_worker_task cost 0.02083897590637207 seconds
DEBUG 01-06 17:11:12.496792.496792 cuda_h.py:10] start sllm_worker_task
DEBUG 01-06 17:11:12.496212.496212 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 17:11:12.497966.497966 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 17:11:12.497297.497297 cuda_h.py:19] end allocate_cuda_memory cost 0.0004773139953613281 seconds
DEBUG 01-06 17:11:12.497694.497694 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 17:11:12.497731.497731 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 17:11:12.498803.498803 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 17:11:12.498701.498701 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, f184b722-19ae-4a85-ae80-26b3a1c058fc
DEBUG 01-06 17:11:12.498265.498265 client.py:106] call stub.LoadModelAsync
DEBUG 01-06 17:11:12.499054.499054 mlpmodule.py:744] pad cost 0.0051422119140625 s
DEBUG 01-06 17:11:12.499793.499793 mlpmodule.py:750] create cpu tensor cost 4.458427429199219e-05 s
DEBUG 01-06 17:11:12.499551.499551 mlpmodule.py:755] move to cpu cost 3.123283386230469e-05 s
INFO 01-06 17:11:12.500358.500358 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, f184b722-19ae-4a85-ae80-26b3a1c058fc
DEBUG 01-06 17:11:12.500827.500827 cuda_h.py:19] end load_into_gpu_async cost 0.0022749900817871094 seconds
DEBUG 01-06 17:11:12.500327.500327 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 17:11:12.500775.500775 cuda_h.py:19] end restore_tensors2 cost 0.00022721290588378906 seconds
DEBUG 01-06 17:11:12.500179.500179 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0038118362426757812 seconds
INFO 01-06 17:11:12.501642.501642 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, f184b722-19ae-4a85-ae80-26b3a1c058fc
DEBUG 01-06 17:11:12.503862.503862 mlpmodule.py:769] group_w3: shape=torch.Size([27, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=77856768
DEBUG 01-06 17:11:12.503640.503640 mlpmodule.py:770] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-06 17:11:12.503860.503860 mlpmodule.py:775] group_w3 first element: 0.036865234375
WARNING 01-06 17:11:12.503505.503505 mlpmodule.py:785] start einsum2
DEBUG 01-06 17:11:12.510611.510611 mlpmodule.py:795] group einsum cost 0.010248899459838867 s
DEBUG 01-06 17:11:12.510001.510001 mlpmodule.py:803] cpy2cputensor cost 8.821487426757812e-05 s
INFO 01-06 17:11:12.510980.510980 client.py:127] Model loaded
DEBUG 01-06 17:11:12.512497.512497 cuda_h.py:19] end sllm_worker_task cost 0.015615463256835938 seconds
DEBUG 01-06 17:11:12.512415.512415 cuda_h.py:10] start sllm_worker_task
DEBUG 01-06 17:11:12.512853.512853 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 17:11:12.512240.512240 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 17:11:12.513294.513294 cuda_h.py:19] end allocate_cuda_memory cost 0.00038170814514160156 seconds
DEBUG 01-06 17:11:12.513489.513489 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 17:11:12.513451.513451 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 17:11:12.513003.513003 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 17:11:12.513096.513096 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, d182513a-fe59-4396-a659-adb9b8363cf1
DEBUG 01-06 17:11:12.513630.513630 client.py:106] call stub.LoadModelAsync
INFO 01-06 17:11:12.514218.514218 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, d182513a-fe59-4396-a659-adb9b8363cf1
DEBUG 01-06 17:11:12.514353.514353 cuda_h.py:19] end load_into_gpu_async cost 0.0016131401062011719 seconds
DEBUG 01-06 17:11:12.514586.514586 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 17:11:12.515729.515729 cuda_h.py:19] end restore_tensors2 cost 0.00011205673217773438 seconds
DEBUG 01-06 17:11:12.515684.515684 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.002443552017211914 seconds
INFO 01-06 17:11:12.515733.515733 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, d182513a-fe59-4396-a659-adb9b8363cf1
DEBUG 01-06 17:11:12.517386.517386 cuda_h.py:19] end wait_cetm_experts cost 0.03221464157104492 seconds
DEBUG 01-06 17:11:12.517693.517693 cuda_h.py:19] end layer_moe_dgenerate_6 cost 0.04627847671508789 seconds
DEBUG 01-06 17:11:12.517188.517188 lmp.py:325] -------------------------------- end decode layer 6 --------------------------------
DEBUG 01-06 17:11:12.517143.517143 lmp.py:298] -------------------------------- start decode layer 7 --------------------------------
DEBUG 01-06 17:11:12.517892.517892 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-06 17:11:12.517862.517862 mlpmodule.py:367] cuda:1 cuda:1
DEBUG 01-06 17:11:12.518788.518788 cuda_h.py:10] start self_attn
cos shape torch.Size([65, 128]) sin shape torch.Size([65, 128]) position_ids tensor([[0]], device='cuda:1')
cos shape torch.Size([1, 1, 1, 128]) sin shape torch.Size([1, 1, 1, 128])
q_embed shape torch.Size([32, 16, 1, 128]) k_embed shape torch.Size([32, 16, 1, 128])
DEBUG 01-06 17:11:12.520905.520905 cuda_h.py:19] end self_attn cost 0.0018520355224609375 seconds
DEBUG 01-06 17:11:12.520627.520627 cuda_h.py:19] end iln_self_attn_paln cost 0.002717733383178711 seconds
DEBUG 01-06 17:11:12.520463.520463 cuda_h.py:10] start layer_moe_dgenerate_7
DEBUG 01-06 17:11:12.520233.520233 cuda_h.py:10] start gate
DEBUG 01-06 17:11:12.521739.521739 cuda_h.py:19] end gate cost 0.0006506443023681641 seconds
DEBUG 01-06 17:11:12.521860.521860 cuda_h.py:10] start experts_map_get
INFO 01-06 17:11:12.521555.521555 lmp.py:611] using loaded check layer: False
INFO 01-06 17:11:12.522171.522171 lmp.py:620] 
INFO 01-06 17:11:12.522171.522171 lmp.py:620] Layer 7 Expert Device Distribution:
INFO 01-06 17:11:12.522794.522794 lmp.py:621]   Active experts: 58 (out of 64 total)
INFO 01-06 17:11:12.522305.522305 lmp.py:622] 
INFO 01-06 17:11:12.522305.522305 lmp.py:622]   Detailed Expert Distribution:
INFO 01-06 17:11:12.522578.522578 lmp.py:623]   Expert ID  | Tokens     | Actual Device  
INFO 01-06 17:11:12.522512.522512 lmp.py:624]   ----------------------------------------------------------------------
INFO 01-06 17:11:12.522877.522877 lmp.py:627]   4          | 1          |  meta           
INFO 01-06 17:11:12.522050.522050 lmp.py:627]   7          | 1          |  meta           
INFO 01-06 17:11:12.522508.522508 lmp.py:627]   13         | 1          |  meta           
INFO 01-06 17:11:12.522489.522489 lmp.py:627]   15         | 1          |  meta           
INFO 01-06 17:11:12.522231.522231 lmp.py:627]   29         | 1          |  meta           
INFO 01-06 17:11:12.522973.522973 lmp.py:627]   30         | 1          |  cuda:1         
INFO 01-06 17:11:12.522477.522477 lmp.py:627]   32         | 1          |  cuda:1         
INFO 01-06 17:11:12.522981.522981 lmp.py:627]   35         | 1          |  cuda:1         
INFO 01-06 17:11:12.522724.522724 lmp.py:627]   37         | 1          |  cuda:1         
INFO 01-06 17:11:12.522989.522989 lmp.py:627]   39         | 1          |  meta           
INFO 01-06 17:11:12.522685.522685 lmp.py:627]   40         | 1          |  meta           
INFO 01-06 17:11:12.522382.522382 lmp.py:627]   48         | 1          |  meta           
INFO 01-06 17:11:12.522362.522362 lmp.py:627]   51         | 1          |  meta           
INFO 01-06 17:11:12.522628.522628 lmp.py:627]   52         | 1          |  meta           
INFO 01-06 17:11:12.522417.522417 lmp.py:627]   53         | 1          |  cuda:1         
INFO 01-06 17:11:12.522444.522444 lmp.py:627]   54         | 1          |  meta           
INFO 01-06 17:11:12.522709.522709 lmp.py:627]   55         | 1          |  meta           
INFO 01-06 17:11:12.522213.522213 lmp.py:627]   0          | 2          |  cuda:1         
INFO 01-06 17:11:12.522479.522479 lmp.py:627]   1          | 2          |  meta           
INFO 01-06 17:11:12.522698.522698 lmp.py:627]   3          | 2          |  meta           
INFO 01-06 17:11:12.522156.522156 lmp.py:627]   10         | 2          |  meta           
INFO 01-06 17:11:12.522614.522614 lmp.py:627]   11         | 2          |  meta           
INFO 01-06 17:11:12.522263.522263 lmp.py:627]   16         | 2          |  meta           
INFO 01-06 17:11:12.522675.522675 lmp.py:627]   17         | 2          |  cuda:1         
INFO 01-06 17:11:12.522324.522324 lmp.py:627]   21         | 2          |  cuda:1         
INFO 01-06 17:11:12.522544.522544 lmp.py:627]   22         | 2          |  cuda:1         
INFO 01-06 17:11:12.522525.522525 lmp.py:627]   27         | 2          |  meta           
INFO 01-06 17:11:12.523267.523267 lmp.py:627]   28         | 2          |  meta           
INFO 01-06 17:11:12.523248.523248 lmp.py:627]   41         | 2          |  meta           
INFO 01-06 17:11:12.523705.523705 lmp.py:627]   43         | 2          |  meta           
INFO 01-06 17:11:12.523209.523209 lmp.py:627]   5          | 3          |  cuda:1         
INFO 01-06 17:11:12.523429.523429 lmp.py:627]   8          | 3          |  meta           
INFO 01-06 17:11:12.523410.523410 lmp.py:627]   12         | 3          |  cuda:1         
INFO 01-06 17:11:12.523298.523298 lmp.py:627]   14         | 3          |  meta           
INFO 01-06 17:11:12.523762.523762 lmp.py:627]   20         | 3          |  meta           
INFO 01-06 17:11:12.523174.523174 lmp.py:627]   25         | 3          |  cuda:1         
INFO 01-06 17:11:12.523154.523154 lmp.py:627]   31         | 3          |  cuda:1         
INFO 01-06 17:11:12.523612.523612 lmp.py:627]   33         | 3          |  cuda:1         
INFO 01-06 17:11:12.523831.523831 lmp.py:627]   38         | 3          |  cuda:1         
INFO 01-06 17:11:12.523574.523574 lmp.py:627]   42         | 3          |  cuda:1         
INFO 01-06 17:11:12.523270.523270 lmp.py:627]   57         | 3          |  cuda:1         
INFO 01-06 17:11:12.523251.523251 lmp.py:627]   58         | 3          |  cuda:1         
INFO 01-06 17:11:12.523185.523185 lmp.py:627]   2          | 4          |  cuda:1         
INFO 01-06 17:11:12.523597.523597 lmp.py:627]   18         | 4          |  meta           
INFO 01-06 17:11:12.523485.523485 lmp.py:627]   34         | 4          |  cuda:1         
INFO 01-06 17:11:12.523134.523134 lmp.py:627]   47         | 4          |  cuda:1         
INFO 01-06 17:11:12.523592.523592 lmp.py:627]   61         | 4          |  cuda:1         
INFO 01-06 17:11:12.523573.523573 lmp.py:627]   62         | 4          |  cuda:1         
INFO 01-06 17:11:12.523554.523554 lmp.py:627]   59         | 5          |  cuda:1         
INFO 01-06 17:11:12.523535.523535 lmp.py:627]   23         | 6          |  cuda:1         
INFO 01-06 17:11:12.523515.523515 lmp.py:627]   44         | 6          |  cuda:1         
INFO 01-06 17:11:12.523735.523735 lmp.py:627]   9          | 7          |  cuda:1         
INFO 01-06 17:11:12.523716.523716 lmp.py:627]   19         | 8          |  cuda:1         
INFO 01-06 17:11:12.523935.523935 lmp.py:627]   56         | 8          |  meta           
INFO 01-06 17:11:12.523154.523154 lmp.py:627]   24         | 9          |  cuda:1         
INFO 01-06 17:11:12.523804.523804 lmp.py:627]   63         | 10         |  cuda:1         
INFO 01-06 17:11:12.523977.523977 lmp.py:627]   49         | 11         |  cuda:1         
INFO 01-06 17:11:12.523434.523434 lmp.py:627]   26         | 19         |  cuda:1         
INFO 01-06 17:11:12.523177.523177 lmp.py:628] ============================================================
INFO 01-06 17:11:12.523177.523177 lmp.py:628] 
INFO 01-06 17:11:12.523357.523357 lmp.py:630] experts_gpu_list: [30, 32, 35, 37, 53, 0, 17, 21, 22, 5, 12, 25, 31, 33, 38, 42, 57, 58, 2, 34, 47, 61, 62, 59, 23, 44, 9, 19, 24, 63, 49, 26] num: 32
INFO 01-06 17:11:12.523437.523437 lmp.py:631] experts_cpu_list: [4, 7, 13, 15, 29, 39, 40, 48, 51, 52, 54, 55, 1, 3, 10, 11, 16, 27, 28, 41, 43, 8, 14, 20, 18, 56] num: 26
INFO 01-06 17:11:12.523054.523054 lmp.py:632] expert_actual_device_map {0: 'cuda:1', 1: 'meta', 2: 'cuda:1', 3: 'meta', 4: 'meta', 5: 'cuda:1', 6: 'meta', 7: 'meta', 8: 'meta', 9: 'cuda:1', 10: 'meta', 11: 'meta', 12: 'cuda:1', 13: 'meta', 14: 'meta', 15: 'meta', 16: 'meta', 17: 'cuda:1', 18: 'meta', 19: 'cuda:1', 20: 'meta', 21: 'cuda:1', 22: 'cuda:1', 23: 'cuda:1', 24: 'cuda:1', 25: 'cuda:1', 26: 'cuda:1', 27: 'meta', 28: 'meta', 29: 'meta', 30: 'cuda:1', 31: 'cuda:1', 32: 'cuda:1', 33: 'cuda:1', 34: 'cuda:1', 35: 'cuda:1', 36: 'meta', 37: 'cuda:1', 38: 'cuda:1', 39: 'meta', 40: 'meta', 41: 'meta', 42: 'cuda:1', 43: 'meta', 44: 'cuda:1', 45: 'meta', 46: 'meta', 47: 'cuda:1', 48: 'meta', 49: 'cuda:1', 50: 'meta', 51: 'meta', 52: 'meta', 53: 'cuda:1', 54: 'meta', 55: 'meta', 56: 'meta', 57: 'cuda:1', 58: 'cuda:1', 59: 'cuda:1', 60: 'meta', 61: 'cuda:1', 62: 'cuda:1', 63: 'cuda:1'}
DEBUG 01-06 17:11:12.523625.523625 cuda_h.py:19] end experts_map_get cost 0.002424955368041992 seconds
INFO 01-06 17:11:12.523482.523482 client.py:127] Model loaded
DEBUG 01-06 17:11:12.524871.524871 cuda_h.py:10] start gpu_sexperts
DEBUG 01-06 17:11:12.524820.524820 cuda_h.py:19] end sllm_worker_task cost 0.012260675430297852 seconds
DEBUG 01-06 17:11:12.525937.525937 cuda_h.py:10] start sllm_worker_task
DEBUG 01-06 17:11:12.525799.525799 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 17:11:12.525450.525450 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 17:11:12.527936.527936 cuda_h.py:19] end allocate_cuda_memory cost 0.0028142929077148438 seconds
DEBUG 01-06 17:11:12.528986.528986 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 17:11:12.528080.528080 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 17:11:12.528896.528896 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 17:11:12.528168.528168 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 7df99ba9-95e3-4cc9-8af8-c42a1c51315b
DEBUG 01-06 17:11:12.528270.528270 client.py:106] call stub.LoadModelAsync
DEBUG 01-06 17:11:12.528201.528201 mlpmodule.py:664]  experts func einsum cost 0.04321551322937012 s
DEBUG 01-06 17:11:12.528601.528601 cuda_h.py:19] end gpu_sexperts cost 0.0043299198150634766 seconds
DEBUG 01-06 17:11:12.528100.528100 cuda_h.py:10] start gpu_experts
INFO 01-06 17:11:12.529745.529745 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 7df99ba9-95e3-4cc9-8af8-c42a1c51315b
DEBUG 01-06 17:11:12.529681.529681 cuda_h.py:19] end load_into_gpu_async cost 0.0015299320220947266 seconds
DEBUG 01-06 17:11:12.529000.529000 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 17:11:12.529228.529228 cuda_h.py:19] end restore_tensors2 cost 7.081031799316406e-05 seconds
DEBUG 01-06 17:11:12.529030.529030 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.004707813262939453 seconds
INFO 01-06 17:11:12.529251.529251 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 7df99ba9-95e3-4cc9-8af8-c42a1c51315b
DEBUG 01-06 17:11:12.530411.530411 mlpmodule.py:533] gpu group tensors cost 0.001277923583984375 s
DEBUG 01-06 17:11:12.531672.531672 mlpmodule.py:566] gpu pad cost 0.0014307498931884766 s
DEBUG 01-06 17:11:12.532504.532504 mlpmodule.py:584] gpu group einsum cost 0.00044083595275878906 s
DEBUG 01-06 17:11:12.534738.534738 mlpmodule.py:613] gpu experts func einsum cost 0.0061223506927490234 s
DEBUG 01-06 17:11:12.535437.535437 cuda_h.py:19] end gpu_experts cost 0.00625920295715332 seconds
DEBUG 01-06 17:11:12.535093.535093 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-06 17:11:12.535650.535650 lmp.py:661] 
DEBUG 01-06 17:11:12.535650.535650 lmp.py:661]   Computing 26 experts on CPU...
DEBUG 01-06 17:11:12.535255.535255 cuda_h.py:19] end cpu_experts_submit cost 5.936622619628906e-05 seconds
DEBUG 01-06 17:11:12.535859.535859 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-06 17:11:12.539060.539060 mlpmodule.py:706] group tensors cost 0.0044612884521484375 s
INFO 01-06 17:11:12.540380.540380 client.py:127] Model loaded
DEBUG 01-06 17:11:12.541013.541013 cuda_h.py:19] end sllm_worker_task cost 0.016479015350341797 seconds
DEBUG 01-06 17:11:12.541744.541744 cuda_h.py:10] start sllm_worker_task
DEBUG 01-06 17:11:12.541222.541222 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 17:11:12.541198.541198 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 17:11:12.541020.541020 cuda_h.py:19] end allocate_cuda_memory cost 0.0001857280731201172 seconds
DEBUG 01-06 17:11:12.541578.541578 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 17:11:12.542811.542811 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 17:11:12.542911.542911 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 17:11:12.542237.542237 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 932b1c7a-dd88-4cab-8458-e8841b59b27a
DEBUG 01-06 17:11:12.542239.542239 client.py:106] call stub.LoadModelAsync
DEBUG 01-06 17:11:12.543368.543368 mlpmodule.py:744] pad cost 0.002871990203857422 s
DEBUG 01-06 17:11:12.543584.543584 mlpmodule.py:750] create cpu tensor cost 4.57763671875e-05 s
INFO 01-06 17:11:12.543435.543435 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 932b1c7a-dd88-4cab-8458-e8841b59b27a
DEBUG 01-06 17:11:12.543803.543803 mlpmodule.py:755] move to cpu cost 0.00015354156494140625 s
DEBUG 01-06 17:11:12.543687.543687 cuda_h.py:19] end load_into_gpu_async cost 0.0016133785247802734 seconds
DEBUG 01-06 17:11:12.543347.543347 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 17:11:12.543993.543993 cuda_h.py:19] end restore_tensors2 cost 8.153915405273438e-05 seconds
DEBUG 01-06 17:11:12.544692.544692 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.00229644775390625 seconds
INFO 01-06 17:11:12.544749.544749 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 932b1c7a-dd88-4cab-8458-e8841b59b27a
DEBUG 01-06 17:11:12.546934.546934 mlpmodule.py:769] group_w3: shape=torch.Size([26, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=74973184
DEBUG 01-06 17:11:12.546202.546202 mlpmodule.py:770] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-06 17:11:12.546568.546568 mlpmodule.py:775] group_w3 first element: 0.04052734375
WARNING 01-06 17:11:12.546968.546968 mlpmodule.py:785] start einsum2
DEBUG 01-06 17:11:12.552733.552733 mlpmodule.py:795] group einsum cost 0.008638620376586914 s
DEBUG 01-06 17:11:12.552309.552309 mlpmodule.py:803] cpy2cputensor cost 7.224082946777344e-05 s
INFO 01-06 17:11:12.554341.554341 client.py:127] Model loaded
DEBUG 01-06 17:11:12.555486.555486 cuda_h.py:19] end sllm_worker_task cost 0.013969898223876953 seconds
DEBUG 01-06 17:11:12.555151.555151 cuda_h.py:10] start sllm_worker_task
DEBUG 01-06 17:11:12.555259.555259 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 17:11:12.555493.555493 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 17:11:12.556840.556840 cuda_h.py:19] end allocate_cuda_memory cost 0.00042128562927246094 seconds
DEBUG 01-06 17:11:12.556739.556739 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 17:11:12.556185.556185 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 17:11:12.556928.556928 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 17:11:12.556830.556830 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 6806653c-9d2c-4a80-8286-8e5e7b7fb527
DEBUG 01-06 17:11:12.556794.556794 client.py:106] call stub.LoadModelAsync
INFO 01-06 17:11:12.558461.558461 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 6806653c-9d2c-4a80-8286-8e5e7b7fb527
DEBUG 01-06 17:11:12.558219.558219 cuda_h.py:19] end load_into_gpu_async cost 0.0016071796417236328 seconds
DEBUG 01-06 17:11:12.558405.558405 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 17:11:12.558072.558072 cuda_h.py:19] end restore_tensors2 cost 0.00011110305786132812 seconds
DEBUG 01-06 17:11:12.558524.558524 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0025517940521240234 seconds
INFO 01-06 17:11:12.558322.558322 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 6806653c-9d2c-4a80-8286-8e5e7b7fb527
DEBUG 01-06 17:11:12.558881.558881 cuda_h.py:19] end wait_cetm_experts cost 0.0237734317779541 seconds
DEBUG 01-06 17:11:12.559042.559042 cuda_h.py:19] end layer_moe_dgenerate_7 cost 0.038626670837402344 seconds
DEBUG 01-06 17:11:12.559121.559121 lmp.py:325] -------------------------------- end decode layer 7 --------------------------------
DEBUG 01-06 17:11:12.559076.559076 lmp.py:298] -------------------------------- start decode layer 8 --------------------------------
DEBUG 01-06 17:11:12.559394.559394 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-06 17:11:12.559503.559503 mlpmodule.py:367] cuda:1 cuda:1
DEBUG 01-06 17:11:12.559952.559952 cuda_h.py:10] start self_attn
cos shape torch.Size([65, 128]) sin shape torch.Size([65, 128]) position_ids tensor([[0]], device='cuda:1')
cos shape torch.Size([1, 1, 1, 128]) sin shape torch.Size([1, 1, 1, 128])
q_embed shape torch.Size([32, 16, 1, 128]) k_embed shape torch.Size([32, 16, 1, 128])
DEBUG 01-06 17:11:12.561733.561733 cuda_h.py:19] end self_attn cost 0.0018846988677978516 seconds
DEBUG 01-06 17:11:12.562459.562459 cuda_h.py:19] end iln_self_attn_paln cost 0.002683401107788086 seconds
DEBUG 01-06 17:11:12.562480.562480 cuda_h.py:10] start layer_moe_dgenerate_8
DEBUG 01-06 17:11:12.562773.562773 cuda_h.py:10] start gate
DEBUG 01-06 17:11:12.562974.562974 cuda_h.py:19] end gate cost 0.0006372928619384766 seconds
DEBUG 01-06 17:11:12.562718.562718 cuda_h.py:10] start experts_map_get
INFO 01-06 17:11:12.563955.563955 lmp.py:609] using loaded check layer: True
INFO 01-06 17:11:12.563796.563796 lmp.py:620] 
INFO 01-06 17:11:12.563796.563796 lmp.py:620] Layer 8 Expert Device Distribution:
INFO 01-06 17:11:12.563274.563274 lmp.py:621]   Active experts: 54 (out of 64 total)
INFO 01-06 17:11:12.563069.563069 lmp.py:622] 
INFO 01-06 17:11:12.563069.563069 lmp.py:622]   Detailed Expert Distribution:
INFO 01-06 17:11:12.564772.564772 lmp.py:623]   Expert ID  | Tokens     | Actual Device  
INFO 01-06 17:11:12.564945.564945 lmp.py:624]   ----------------------------------------------------------------------
INFO 01-06 17:11:12.564741.564741 lmp.py:627]   10         | 1          |  cuda:1         
INFO 01-06 17:11:12.564390.564390 lmp.py:627]   13         | 1          |  cuda:1         
INFO 01-06 17:11:12.564610.564610 lmp.py:627]   15         | 1          |  meta           
INFO 01-06 17:11:12.564067.564067 lmp.py:627]   16         | 1          |  meta           
INFO 01-06 17:11:12.564002.564002 lmp.py:627]   18         | 1          |  meta           
INFO 01-06 17:11:12.564460.564460 lmp.py:627]   24         | 1          |  meta           
INFO 01-06 17:11:12.564917.564917 lmp.py:627]   26         | 1          |  cuda:1         
INFO 01-06 17:11:12.564136.564136 lmp.py:627]   33         | 1          |  meta           
INFO 01-06 17:11:12.564833.564833 lmp.py:627]   36         | 1          |  meta           
INFO 01-06 17:11:12.564529.564529 lmp.py:627]   47         | 1          |  cuda:1         
INFO 01-06 17:11:12.564417.564417 lmp.py:627]   55         | 1          |  cuda:1         
INFO 01-06 17:11:12.564113.564113 lmp.py:627]   58         | 1          |  cuda:1         
INFO 01-06 17:11:12.564332.564332 lmp.py:627]   62         | 1          |  cuda:1         
INFO 01-06 17:11:12.564551.564551 lmp.py:627]   1          | 2          |  cuda:1         
INFO 01-06 17:11:12.564532.564532 lmp.py:627]   2          | 2          |  cuda:1         
INFO 01-06 17:11:12.564295.564295 lmp.py:627]   3          | 2          |  cuda:1         
INFO 01-06 17:11:12.564422.564422 lmp.py:627]   4          | 2          |  cuda:1         
INFO 01-06 17:11:12.564356.564356 lmp.py:627]   8          | 2          |  cuda:1         
INFO 01-06 17:11:12.564337.564337 lmp.py:627]   14         | 2          |  meta           
INFO 01-06 17:11:12.564795.564795 lmp.py:627]   27         | 2          |  meta           
INFO 01-06 17:11:12.564968.564968 lmp.py:627]   30         | 2          |  meta           
INFO 01-06 17:11:12.564617.564617 lmp.py:627]   37         | 2          |  cuda:1         
INFO 01-06 17:11:12.564075.564075 lmp.py:627]   42         | 2          |  meta           
INFO 01-06 17:11:12.564486.564486 lmp.py:627]   45         | 2          |  cuda:1         
INFO 01-06 17:11:12.564043.564043 lmp.py:627]   49         | 2          |  cuda:1         
INFO 01-06 17:11:12.564216.564216 lmp.py:627]   51         | 2          |  meta           
INFO 01-06 17:11:12.564674.564674 lmp.py:627]   6          | 3          |  cuda:1         
INFO 01-06 17:11:12.564893.564893 lmp.py:627]   9          | 3          |  cuda:1         
INFO 01-06 17:11:12.564351.564351 lmp.py:627]   17         | 3          |  meta           
INFO 01-06 17:11:12.564570.564570 lmp.py:627]   22         | 3          |  meta           
INFO 01-06 17:11:12.564220.564220 lmp.py:627]   39         | 3          |  meta           
INFO 01-06 17:11:12.564108.564108 lmp.py:627]   44         | 3          |  meta           
INFO 01-06 17:11:12.564619.564619 lmp.py:627]   50         | 3          |  cuda:1         
INFO 01-06 17:11:12.564123.564123 lmp.py:627]   53         | 3          |  meta           
INFO 01-06 17:11:12.564389.564389 lmp.py:627]   60         | 3          |  meta           
INFO 01-06 17:11:12.564416.564416 lmp.py:627]   61         | 3          |  cuda:1         
INFO 01-06 17:11:12.564681.564681 lmp.py:627]   11         | 4          |  cuda:1         
INFO 01-06 17:11:12.564708.564708 lmp.py:627]   20         | 4          |  cuda:1         
INFO 01-06 17:11:12.564974.564974 lmp.py:627]   41         | 4          |  cuda:1         
INFO 01-06 17:11:12.564478.564478 lmp.py:627]   28         | 5          |  cuda:1         
INFO 01-06 17:11:12.564697.564697 lmp.py:627]   29         | 5          |  meta           
INFO 01-06 17:11:12.564917.564917 lmp.py:627]   40         | 5          |  meta           
INFO 01-06 17:11:12.564613.564613 lmp.py:627]   54         | 5          |  meta           
INFO 01-06 17:11:12.565355.565355 lmp.py:627]   5          | 6          |  cuda:1         
INFO 01-06 17:11:12.565382.565382 lmp.py:627]   19         | 6          |  cuda:1         
INFO 01-06 17:11:12.565648.565648 lmp.py:627]   21         | 6          |  cuda:1         
INFO 01-06 17:11:12.565913.565913 lmp.py:627]   31         | 6          |  cuda:1         
INFO 01-06 17:11:12.565464.565464 lmp.py:627]   57         | 6          |  cuda:1         
INFO 01-06 17:11:12.565729.565729 lmp.py:627]   63         | 6          |  cuda:1         
INFO 01-06 17:11:12.565518.565518 lmp.py:627]   46         | 7          |  cuda:1         
INFO 01-06 17:11:12.565022.565022 lmp.py:627]   52         | 7          |  cuda:1         
INFO 01-06 17:11:12.565526.565526 lmp.py:627]   34         | 9          |  meta           
INFO 01-06 17:11:12.565984.565984 lmp.py:627]   25         | 11         |  cuda:1         
INFO 01-06 17:11:12.565541.565541 lmp.py:627]   23         | 21         |  cuda:1         
INFO 01-06 17:11:12.565806.565806 lmp.py:628] ============================================================
INFO 01-06 17:11:12.565806.565806 lmp.py:628] 
INFO 01-06 17:11:12.565317.565317 lmp.py:630] experts_gpu_list: [10, 13, 26, 47, 55, 58, 62, 1, 2, 3, 4, 8, 37, 45, 49, 6, 9, 50, 61, 11, 20, 41, 28, 5, 19, 21, 31, 57, 63, 46, 52, 25, 23] num: 33
INFO 01-06 17:11:12.565205.565205 lmp.py:631] experts_cpu_list: [15, 16, 18, 24, 33, 36, 14, 27, 30, 42, 51, 17, 22, 39, 44, 53, 60, 29, 40, 54, 34] num: 21
INFO 01-06 17:11:12.565061.565061 lmp.py:632] expert_actual_device_map {0: 'cuda:1', 1: 'cuda:1', 2: 'cuda:1', 3: 'cuda:1', 4: 'cuda:1', 5: 'cuda:1', 6: 'cuda:1', 7: 'cuda:1', 8: 'cuda:1', 9: 'cuda:1', 10: 'cuda:1', 11: 'cuda:1', 12: 'meta', 13: 'cuda:1', 14: 'meta', 15: 'meta', 16: 'meta', 17: 'meta', 18: 'meta', 19: 'cuda:1', 20: 'cuda:1', 21: 'cuda:1', 22: 'meta', 23: 'cuda:1', 24: 'meta', 25: 'cuda:1', 26: 'cuda:1', 27: 'meta', 28: 'cuda:1', 29: 'meta', 30: 'meta', 31: 'cuda:1', 32: 'meta', 33: 'meta', 34: 'meta', 35: 'meta', 36: 'meta', 37: 'cuda:1', 38: 'meta', 39: 'meta', 40: 'meta', 41: 'cuda:1', 42: 'meta', 43: 'cuda:1', 44: 'meta', 45: 'cuda:1', 46: 'cuda:1', 47: 'cuda:1', 48: 'meta', 49: 'cuda:1', 50: 'cuda:1', 51: 'meta', 52: 'cuda:1', 53: 'meta', 54: 'meta', 55: 'cuda:1', 56: 'cuda:1', 57: 'cuda:1', 58: 'cuda:1', 59: 'meta', 60: 'meta', 61: 'cuda:1', 62: 'cuda:1', 63: 'cuda:1'}
DEBUG 01-06 17:11:12.565062.565062 cuda_h.py:19] end experts_map_get cost 0.0023262500762939453 seconds
DEBUG 01-06 17:11:12.565496.565496 cuda_h.py:10] start gpu_sexperts
DEBUG 01-06 17:11:12.565561.565561 cuda_h.py:19] end gpu_sexperts cost 0.00031828880310058594 seconds
DEBUG 01-06 17:11:12.565914.565914 cuda_h.py:10] start gpu_experts
INFO 01-06 17:11:12.567720.567720 client.py:127] Model loaded
DEBUG 01-06 17:11:12.567700.567700 cuda_h.py:19] end sllm_worker_task cost 0.011982440948486328 seconds
DEBUG 01-06 17:11:12.567205.567205 cuda_h.py:10] start sllm_worker_task
DEBUG 01-06 17:11:12.567961.567961 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 17:11:12.567360.567360 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 17:11:12.568561.568561 cuda_h.py:19] end allocate_cuda_memory cost 0.0006413459777832031 seconds
DEBUG 01-06 17:11:12.568742.568742 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 17:11:12.568260.568260 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 17:11:12.568453.568453 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 17:11:12.568010.568010 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 9781ac0b-a6a0-48b9-8e76-0b266795e0dd
DEBUG 01-06 17:11:12.568490.568490 client.py:106] call stub.LoadModelAsync
DEBUG 01-06 17:11:12.569685.569685 mlpmodule.py:664]  experts func einsum cost 0.03380155563354492 s
DEBUG 01-06 17:11:12.569841.569841 mlpmodule.py:533] gpu group tensors cost 0.003476381301879883 s
INFO 01-06 17:11:12.570970.570970 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 9781ac0b-a6a0-48b9-8e76-0b266795e0dd
DEBUG 01-06 17:11:12.570045.570045 cuda_h.py:19] end load_into_gpu_async cost 0.001489400863647461 seconds
DEBUG 01-06 17:11:12.570841.570841 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 17:11:12.570493.570493 cuda_h.py:19] end restore_tensors2 cost 6.794929504394531e-05 seconds
DEBUG 01-06 17:11:12.570057.570057 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0024340152740478516 seconds
INFO 01-06 17:11:12.570747.570747 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 9781ac0b-a6a0-48b9-8e76-0b266795e0dd
DEBUG 01-06 17:11:12.571871.571871 mlpmodule.py:566] gpu pad cost 0.001779794692993164 s
DEBUG 01-06 17:11:12.571291.571291 mlpmodule.py:584] gpu group einsum cost 0.0004239082336425781 s
DEBUG 01-06 17:11:12.574416.574416 mlpmodule.py:613] gpu experts func einsum cost 0.008793354034423828 s
DEBUG 01-06 17:11:12.574147.574147 cuda_h.py:19] end gpu_experts cost 0.008919239044189453 seconds
DEBUG 01-06 17:11:12.574281.574281 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-06 17:11:12.574553.574553 lmp.py:661] 
DEBUG 01-06 17:11:12.574553.574553 lmp.py:661]   Computing 21 experts on CPU...
DEBUG 01-06 17:11:12.574244.574244 cuda_h.py:19] end cpu_experts_submit cost 5.2928924560546875e-05 seconds
DEBUG 01-06 17:11:12.574278.574278 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-06 17:11:12.580213.580213 mlpmodule.py:706] group tensors cost 0.0055844783782958984 s
INFO 01-06 17:11:12.581422.581422 client.py:127] Model loaded
DEBUG 01-06 17:11:12.582272.582272 cuda_h.py:19] end sllm_worker_task cost 0.014827489852905273 seconds
DEBUG 01-06 17:11:12.582692.582692 cuda_h.py:10] start sllm_worker_task
DEBUG 01-06 17:11:12.582084.582084 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 17:11:12.582821.582821 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 17:11:12.583062.583062 cuda_h.py:19] end allocate_cuda_memory cost 0.00024366378784179688 seconds
DEBUG 01-06 17:11:12.583927.583927 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 17:11:12.583571.583571 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 17:11:12.583215.583215 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 17:11:12.583501.583501 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, cee8a65e-57b0-42c3-ad70-095539854527
DEBUG 01-06 17:11:12.583815.583815 client.py:106] call stub.LoadModelAsync
DEBUG 01-06 17:11:12.584724.584724 mlpmodule.py:744] pad cost 0.002882242202758789 s
DEBUG 01-06 17:11:12.584192.584192 mlpmodule.py:750] create cpu tensor cost 4.5299530029296875e-05 s
DEBUG 01-06 17:11:12.584003.584003 mlpmodule.py:755] move to cpu cost 3.266334533691406e-05 s
INFO 01-06 17:11:12.584815.584815 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, cee8a65e-57b0-42c3-ad70-095539854527
DEBUG 01-06 17:11:12.584421.584421 cuda_h.py:19] end load_into_gpu_async cost 0.0016491413116455078 seconds
DEBUG 01-06 17:11:12.585044.585044 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 17:11:12.585532.585532 cuda_h.py:19] end restore_tensors2 cost 7.796287536621094e-05 seconds
DEBUG 01-06 17:11:12.585560.585560 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0023200511932373047 seconds
INFO 01-06 17:11:12.585716.585716 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, cee8a65e-57b0-42c3-ad70-095539854527
DEBUG 01-06 17:11:12.587622.587622 mlpmodule.py:769] group_w3: shape=torch.Size([21, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=60555264
DEBUG 01-06 17:11:12.587730.587730 mlpmodule.py:770] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-06 17:11:12.587759.587759 mlpmodule.py:775] group_w3 first element: -0.060791015625
WARNING 01-06 17:11:12.587311.587311 mlpmodule.py:785] start einsum2
DEBUG 01-06 17:11:12.593338.593338 mlpmodule.py:795] group einsum cost 0.008765459060668945 s
DEBUG 01-06 17:11:12.593344.593344 mlpmodule.py:803] cpy2cputensor cost 9.1552734375e-05 s
INFO 01-06 17:11:12.594999.594999 client.py:127] Model loaded
DEBUG 01-06 17:11:12.596064.596064 cuda_h.py:19] end sllm_worker_task cost 0.013235330581665039 seconds
DEBUG 01-06 17:11:12.596135.596135 cuda_h.py:10] start sllm_worker_task
DEBUG 01-06 17:11:12.596149.596149 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 17:11:12.596999.596999 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 17:11:12.596552.596552 cuda_h.py:19] end allocate_cuda_memory cost 0.0004305839538574219 seconds
DEBUG 01-06 17:11:12.596185.596185 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 17:11:12.596100.596100 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 17:11:12.597082.597082 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 17:11:12.597130.597130 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 62212e06-2616-478a-97d9-805fdce0252c
DEBUG 01-06 17:11:12.597716.597716 client.py:106] call stub.LoadModelAsync
INFO 01-06 17:11:12.598423.598423 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 62212e06-2616-478a-97d9-805fdce0252c
DEBUG 01-06 17:11:12.598419.598419 cuda_h.py:19] end load_into_gpu_async cost 0.0016050338745117188 seconds
DEBUG 01-06 17:11:12.598367.598367 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 17:11:12.598756.598756 cuda_h.py:19] end restore_tensors2 cost 0.00011515617370605469 seconds
DEBUG 01-06 17:11:12.598618.598618 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.002492189407348633 seconds
INFO 01-06 17:11:12.598038.598038 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 62212e06-2616-478a-97d9-805fdce0252c
DEBUG 01-06 17:11:12.599188.599188 cuda_h.py:19] end wait_cetm_experts cost 0.024312973022460938 seconds
DEBUG 01-06 17:11:12.599006.599006 cuda_h.py:19] end layer_moe_dgenerate_8 cost 0.03742361068725586 seconds
DEBUG 01-06 17:11:12.599875.599875 lmp.py:325] -------------------------------- end decode layer 8 --------------------------------
DEBUG 01-06 17:11:12.599678.599678 lmp.py:298] -------------------------------- start decode layer 9 --------------------------------
DEBUG 01-06 17:11:12.600454.600454 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-06 17:11:12.600200.600200 mlpmodule.py:367] cuda:1 cuda:1
DEBUG 01-06 17:11:12.600537.600537 cuda_h.py:10] start self_attn
cos shape torch.Size([65, 128]) sin shape torch.Size([65, 128]) position_ids tensor([[0]], device='cuda:1')
cos shape torch.Size([1, 1, 1, 128]) sin shape torch.Size([1, 1, 1, 128])
q_embed shape torch.Size([32, 16, 1, 128]) k_embed shape torch.Size([32, 16, 1, 128])
DEBUG 01-06 17:11:12.603763.603763 cuda_h.py:19] end self_attn cost 0.0027048587799072266 seconds
DEBUG 01-06 17:11:12.603394.603394 cuda_h.py:19] end iln_self_attn_paln cost 0.003870725631713867 seconds
DEBUG 01-06 17:11:12.603369.603369 cuda_h.py:10] start layer_moe_dgenerate_9
DEBUG 01-06 17:11:12.604139.604139 cuda_h.py:10] start gate
DEBUG 01-06 17:11:12.604098.604098 cuda_h.py:19] end gate cost 0.0007376670837402344 seconds
DEBUG 01-06 17:11:12.604418.604418 cuda_h.py:10] start experts_map_get
INFO 01-06 17:11:12.605986.605986 lmp.py:609] using loaded check layer: True
INFO 01-06 17:11:12.605112.605112 lmp.py:620] 
INFO 01-06 17:11:12.605112.605112 lmp.py:620] Layer 9 Expert Device Distribution:
INFO 01-06 17:11:12.605948.605948 lmp.py:621]   Active experts: 54 (out of 64 total)
INFO 01-06 17:11:12.605936.605936 lmp.py:622] 
INFO 01-06 17:11:12.605936.605936 lmp.py:622]   Detailed Expert Distribution:
INFO 01-06 17:11:12.605400.605400 lmp.py:623]   Expert ID  | Tokens     | Actual Device  
INFO 01-06 17:11:12.605050.605050 lmp.py:624]   ----------------------------------------------------------------------
INFO 01-06 17:11:12.605177.605177 lmp.py:627]   5          | 1          |  cuda:1         
INFO 01-06 17:11:12.605111.605111 lmp.py:627]   10         | 1          |  meta           
INFO 01-06 17:11:12.606092.606092 lmp.py:627]   16         | 1          |  meta           
INFO 01-06 17:11:12.606596.606596 lmp.py:627]   19         | 1          |  meta           
INFO 01-06 17:11:12.606338.606338 lmp.py:627]   20         | 1          |  meta           
INFO 01-06 17:11:12.606842.606842 lmp.py:627]   23         | 1          |  meta           
INFO 01-06 17:11:12.606823.606823 lmp.py:627]   26         | 1          |  meta           
INFO 01-06 17:11:12.606996.606996 lmp.py:627]   27         | 1          |  meta           
INFO 01-06 17:11:12.606931.606931 lmp.py:627]   29         | 1          |  cuda:1         
INFO 01-06 17:11:12.606918.606918 lmp.py:627]   30         | 1          |  cuda:1         
INFO 01-06 17:11:12.606137.606137 lmp.py:627]   40         | 1          |  meta           
INFO 01-06 17:11:12.606403.606403 lmp.py:627]   42         | 1          |  cuda:1         
INFO 01-06 17:11:12.606669.606669 lmp.py:627]   44         | 1          |  cuda:1         
INFO 01-06 17:11:12.606696.606696 lmp.py:627]   47         | 1          |  meta           
INFO 01-06 17:11:12.606961.606961 lmp.py:627]   60         | 1          |  meta           
INFO 01-06 17:11:12.606227.606227 lmp.py:627]   15         | 2          |  meta           
INFO 01-06 17:11:12.606492.606492 lmp.py:627]   17         | 2          |  meta           
INFO 01-06 17:11:12.606758.606758 lmp.py:627]   28         | 2          |  meta           
INFO 01-06 17:11:12.606262.606262 lmp.py:627]   31         | 2          |  cuda:1         
INFO 01-06 17:11:12.606720.606720 lmp.py:627]   35         | 2          |  meta           
INFO 01-06 17:11:12.606985.606985 lmp.py:627]   38         | 2          |  cuda:1         
INFO 01-06 17:11:12.606012.606012 lmp.py:627]   41         | 2          |  meta           
INFO 01-06 17:11:12.606278.606278 lmp.py:627]   48         | 2          |  cuda:1         
INFO 01-06 17:11:12.606828.606828 lmp.py:627]   50         | 2          |  meta           
INFO 01-06 17:11:12.606856.606856 lmp.py:627]   51         | 2          |  cuda:1         
INFO 01-06 17:11:12.606883.606883 lmp.py:627]   53         | 2          |  meta           
INFO 01-06 17:11:12.606671.606671 lmp.py:627]   61         | 2          |  cuda:1         
INFO 01-06 17:11:12.606460.606460 lmp.py:627]   63         | 2          |  cuda:1         
INFO 01-06 17:11:12.606964.606964 lmp.py:627]   1          | 3          |  cuda:1         
INFO 01-06 17:11:12.606899.606899 lmp.py:627]   7          | 3          |  cuda:1         
INFO 01-06 17:11:12.606595.606595 lmp.py:627]   21         | 3          |  cuda:1         
INFO 01-06 17:11:12.606052.606052 lmp.py:627]   33         | 3          |  cuda:1         
INFO 01-06 17:11:12.606556.606556 lmp.py:627]   43         | 3          |  cuda:1         
INFO 01-06 17:11:12.606822.606822 lmp.py:627]   56         | 3          |  cuda:1         
INFO 01-06 17:11:12.606372.606372 lmp.py:627]   58         | 3          |  cuda:1         
INFO 01-06 17:11:12.606400.606400 lmp.py:627]   6          | 4          |  cuda:1         
INFO 01-06 17:11:12.606427.606427 lmp.py:627]   11         | 4          |  cuda:1         
INFO 01-06 17:11:12.606454.606454 lmp.py:627]   22         | 4          |  meta           
INFO 01-06 17:11:12.606243.606243 lmp.py:627]   39         | 4          |  cuda:1         
INFO 01-06 17:11:12.606939.606939 lmp.py:627]   54         | 4          |  cuda:1         
INFO 01-06 17:11:12.606396.606396 lmp.py:627]   18         | 5          |  cuda:1         
INFO 01-06 17:11:12.606616.606616 lmp.py:627]   45         | 5          |  cuda:1         
INFO 01-06 17:11:12.606881.606881 lmp.py:627]   59         | 5          |  meta           
INFO 01-06 17:11:12.606908.606908 lmp.py:627]   62         | 5          |  cuda:1         
INFO 01-06 17:11:12.606459.606459 lmp.py:627]   13         | 6          |  meta           
INFO 01-06 17:11:12.606486.606486 lmp.py:627]   25         | 7          |  meta           
INFO 01-06 17:11:12.606089.606089 lmp.py:627]   9          | 8          |  cuda:1         
INFO 01-06 17:11:12.606309.606309 lmp.py:627]   52         | 8          |  cuda:1         
INFO 01-06 17:11:12.606528.606528 lmp.py:627]   55         | 8          |  cuda:1         
INFO 01-06 17:11:12.606747.606747 lmp.py:627]   0          | 9          |  cuda:1         
INFO 01-06 17:11:12.606158.606158 lmp.py:627]   34         | 9          |  cuda:1         
INFO 01-06 17:11:12.607808.607808 lmp.py:627]   46         | 9          |  cuda:1         
INFO 01-06 17:11:12.607981.607981 lmp.py:627]   57         | 11         |  cuda:1         
INFO 01-06 17:11:12.607916.607916 lmp.py:627]   8          | 15         |  cuda:1         
INFO 01-06 17:11:12.607757.607757 lmp.py:628] ============================================================
INFO 01-06 17:11:12.607757.607757 lmp.py:628] 
INFO 01-06 17:11:12.607752.607752 lmp.py:630] experts_gpu_list: [5, 29, 30, 42, 44, 31, 38, 48, 51, 61, 63, 1, 7, 21, 33, 43, 56, 58, 6, 11, 39, 54, 18, 45, 62, 9, 52, 55, 0, 34, 46, 57, 8] num: 33
INFO 01-06 17:11:12.607355.607355 lmp.py:631] experts_cpu_list: [10, 16, 19, 20, 23, 26, 27, 40, 47, 60, 15, 17, 28, 35, 41, 50, 53, 22, 59, 13, 25] num: 21
INFO 01-06 17:11:12.607880.607880 lmp.py:632] expert_actual_device_map {0: 'cuda:1', 1: 'cuda:1', 2: 'cuda:1', 3: 'cuda:1', 4: 'cuda:1', 5: 'cuda:1', 6: 'cuda:1', 7: 'cuda:1', 8: 'cuda:1', 9: 'cuda:1', 10: 'meta', 11: 'cuda:1', 12: 'meta', 13: 'meta', 14: 'cuda:1', 15: 'meta', 16: 'meta', 17: 'meta', 18: 'cuda:1', 19: 'meta', 20: 'meta', 21: 'cuda:1', 22: 'meta', 23: 'meta', 24: 'meta', 25: 'meta', 26: 'meta', 27: 'meta', 28: 'meta', 29: 'cuda:1', 30: 'cuda:1', 31: 'cuda:1', 32: 'meta', 33: 'cuda:1', 34: 'cuda:1', 35: 'meta', 36: 'meta', 37: 'meta', 38: 'cuda:1', 39: 'cuda:1', 40: 'meta', 41: 'meta', 42: 'cuda:1', 43: 'cuda:1', 44: 'cuda:1', 45: 'cuda:1', 46: 'cuda:1', 47: 'meta', 48: 'cuda:1', 49: 'meta', 50: 'meta', 51: 'cuda:1', 52: 'cuda:1', 53: 'meta', 54: 'cuda:1', 55: 'cuda:1', 56: 'cuda:1', 57: 'cuda:1', 58: 'cuda:1', 59: 'meta', 60: 'meta', 61: 'cuda:1', 62: 'cuda:1', 63: 'cuda:1'}
DEBUG 01-06 17:11:12.607305.607305 cuda_h.py:19] end experts_map_get cost 0.0023038387298583984 seconds
DEBUG 01-06 17:11:12.607758.607758 mlpmodule.py:664]  experts func einsum cost 0.03217744827270508 s
DEBUG 01-06 17:11:12.607696.607696 cuda_h.py:10] start gpu_sexperts
INFO 01-06 17:11:12.607787.607787 client.py:127] Model loaded
DEBUG 01-06 17:11:12.608911.608911 cuda_h.py:19] end gpu_sexperts cost 0.0004661083221435547 seconds
DEBUG 01-06 17:11:12.608630.608630 cuda_h.py:10] start gpu_experts
DEBUG 01-06 17:11:12.609566.609566 cuda_h.py:19] end sllm_worker_task cost 0.012841939926147461 seconds
DEBUG 01-06 17:11:12.609701.609701 mlpmodule.py:533] gpu group tensors cost 0.0008449554443359375 s
DEBUG 01-06 17:11:12.609868.609868 cuda_h.py:10] start sllm_worker_task
DEBUG 01-06 17:11:12.609369.609369 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 17:11:12.609927.609927 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 17:11:12.609420.609420 cuda_h.py:19] end allocate_cuda_memory cost 0.0002570152282714844 seconds
DEBUG 01-06 17:11:12.609171.609171 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 17:11:12.609404.609404 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 17:11:12.609074.609074 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 17:11:12.609154.609154 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, dc020ca8-b443-481a-940a-98fefc3b8d0c
DEBUG 01-06 17:11:12.609157.609157 client.py:106] call stub.LoadModelAsync
INFO 01-06 17:11:12.611589.611589 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, dc020ca8-b443-481a-940a-98fefc3b8d0c
DEBUG 01-06 17:11:12.611180.611180 cuda_h.py:19] end load_into_gpu_async cost 0.001413583755493164 seconds
DEBUG 01-06 17:11:12.611545.611545 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 17:11:12.611482.611482 cuda_h.py:19] end restore_tensors2 cost 6.818771362304688e-05 seconds
DEBUG 01-06 17:11:12.611284.611284 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.001974821090698242 seconds
INFO 01-06 17:11:12.611166.611166 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, dc020ca8-b443-481a-940a-98fefc3b8d0c
DEBUG 01-06 17:11:12.611411.611411 mlpmodule.py:566] gpu pad cost 0.0026845932006835938 s
DEBUG 01-06 17:11:12.612807.612807 mlpmodule.py:584] gpu group einsum cost 0.0004951953887939453 s
DEBUG 01-06 17:11:12.615345.615345 mlpmodule.py:613] gpu experts func einsum cost 0.00722193717956543 s
DEBUG 01-06 17:11:12.615831.615831 cuda_h.py:19] end gpu_experts cost 0.007344722747802734 seconds
DEBUG 01-06 17:11:12.615726.615726 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-06 17:11:12.615998.615998 lmp.py:661] 
DEBUG 01-06 17:11:12.615998.615998 lmp.py:661]   Computing 21 experts on CPU...
DEBUG 01-06 17:11:12.615258.615258 cuda_h.py:19] end cpu_experts_submit cost 5.125999450683594e-05 seconds
DEBUG 01-06 17:11:12.615385.615385 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-06 17:11:12.620566.620566 mlpmodule.py:706] group tensors cost 0.004453897476196289 s
INFO 01-06 17:11:12.621635.621635 client.py:127] Model loaded
DEBUG 01-06 17:11:12.622417.622417 cuda_h.py:19] end sllm_worker_task cost 0.013302803039550781 seconds
DEBUG 01-06 17:11:12.623310.623310 mlpmodule.py:744] pad cost 0.0025377273559570312 s
DEBUG 01-06 17:11:12.623579.623579 mlpmodule.py:750] create cpu tensor cost 4.506111145019531e-05 s
DEBUG 01-06 17:11:12.623959.623959 mlpmodule.py:755] move to cpu cost 3.1948089599609375e-05 s
DEBUG 01-06 17:11:12.626291.626291 mlpmodule.py:769] group_w3: shape=torch.Size([21, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=60555264
DEBUG 01-06 17:11:12.626432.626432 mlpmodule.py:770] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-06 17:11:12.626984.626984 mlpmodule.py:775] group_w3 first element: 0.042724609375
WARNING 01-06 17:11:12.626537.626537 mlpmodule.py:785] start einsum2
DEBUG 01-06 17:11:12.631212.631212 mlpmodule.py:795] group einsum cost 0.007517337799072266 s
DEBUG 01-06 17:11:12.631099.631099 mlpmodule.py:803] cpy2cputensor cost 0.00012731552124023438 s
DEBUG 01-06 17:11:12.634702.634702 cuda_h.py:19] end wait_cetm_experts cost 0.018665790557861328 seconds
DEBUG 01-06 17:11:12.634148.634148 cuda_h.py:19] end layer_moe_dgenerate_9 cost 0.030937671661376953 seconds
DEBUG 01-06 17:11:12.635619.635619 lmp.py:325] -------------------------------- end decode layer 9 --------------------------------
DEBUG 01-06 17:11:12.635263.635263 lmp.py:298] -------------------------------- start decode layer 10 --------------------------------
DEBUG 01-06 17:11:12.635218.635218 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-06 17:11:12.635216.635216 mlpmodule.py:367] cuda:1 cuda:1
DEBUG 01-06 17:11:12.635225.635225 cuda_h.py:10] start self_attn
cos shape torch.Size([65, 128]) sin shape torch.Size([65, 128]) position_ids tensor([[0]], device='cuda:1')
cos shape torch.Size([1, 1, 1, 128]) sin shape torch.Size([1, 1, 1, 128])
q_embed shape torch.Size([32, 16, 1, 128]) k_embed shape torch.Size([32, 16, 1, 128])
DEBUG 01-06 17:11:12.638738.638738 cuda_h.py:19] end self_attn cost 0.0024008750915527344 seconds
DEBUG 01-06 17:11:12.638873.638873 cuda_h.py:19] end iln_self_attn_paln cost 0.0034897327423095703 seconds
DEBUG 01-06 17:11:12.638729.638729 cuda_h.py:10] start layer_moe_dgenerate_10
DEBUG 01-06 17:11:12.638234.638234 cuda_h.py:10] start gate
DEBUG 01-06 17:11:12.639672.639672 cuda_h.py:19] end gate cost 0.000759124755859375 seconds
DEBUG 01-06 17:11:12.639151.639151 cuda_h.py:10] start experts_map_get
INFO 01-06 17:11:12.640068.640068 lmp.py:609] using loaded check layer: True
INFO 01-06 17:11:12.641897.641897 lmp.py:620] 
INFO 01-06 17:11:12.641897.641897 lmp.py:620] Layer 10 Expert Device Distribution:
INFO 01-06 17:11:12.641302.641302 lmp.py:621]   Active experts: 53 (out of 64 total)
INFO 01-06 17:11:12.641065.641065 lmp.py:622] 
INFO 01-06 17:11:12.641065.641065 lmp.py:622]   Detailed Expert Distribution:
INFO 01-06 17:11:12.641782.641782 lmp.py:623]   Expert ID  | Tokens     | Actual Device  
INFO 01-06 17:11:12.641491.641491 lmp.py:624]   ----------------------------------------------------------------------
INFO 01-06 17:11:12.641916.641916 lmp.py:627]   2          | 1          |  cuda:1         
INFO 01-06 17:11:12.641149.641149 lmp.py:627]   5          | 1          |  cuda:1         
INFO 01-06 17:11:12.641905.641905 lmp.py:627]   18         | 1          |  cuda:1         
INFO 01-06 17:11:12.641184.641184 lmp.py:627]   19         | 1          |  meta           
INFO 01-06 17:11:12.641986.641986 lmp.py:627]   22         | 1          |  meta           
INFO 01-06 17:11:12.641696.641696 lmp.py:627]   23         | 1          |  cuda:1         
INFO 01-06 17:11:12.641929.641929 lmp.py:627]   30         | 1          |  cuda:1         
INFO 01-06 17:11:12.641970.641970 lmp.py:627]   34         | 1          |  meta           
INFO 01-06 17:11:12.641010.641010 lmp.py:627]   37         | 1          |  meta           
INFO 01-06 17:11:12.641051.641051 lmp.py:627]   39         | 1          |  cuda:1         
INFO 01-06 17:11:12.641854.641854 lmp.py:627]   45         | 1          |  meta           
INFO 01-06 17:11:12.641133.641133 lmp.py:627]   51         | 1          |  meta           
INFO 01-06 17:11:12.641935.641935 lmp.py:627]   54         | 1          |  meta           
INFO 01-06 17:11:12.641929.641929 lmp.py:627]   55         | 1          |  meta           
INFO 01-06 17:11:12.641732.641732 lmp.py:627]   60         | 1          |  meta           
INFO 01-06 17:11:12.641057.641057 lmp.py:627]   63         | 1          |  meta           
INFO 01-06 17:11:12.641098.641098 lmp.py:627]   7          | 2          |  meta           
INFO 01-06 17:11:12.641139.641139 lmp.py:627]   12         | 2          |  meta           
INFO 01-06 17:11:12.641703.641703 lmp.py:627]   13         | 2          |  cuda:1         
INFO 01-06 17:11:12.641412.641412 lmp.py:627]   14         | 2          |  meta           
INFO 01-06 17:11:12.641367.641367 lmp.py:627]   17         | 2          |  meta           
INFO 01-06 17:11:12.641885.641885 lmp.py:627]   27         | 2          |  meta           
INFO 01-06 17:11:12.641210.641210 lmp.py:627]   33         | 2          |  cuda:1         
INFO 01-06 17:11:12.642013.642013 lmp.py:627]   40         | 2          |  cuda:1         
INFO 01-06 17:11:12.642484.642484 lmp.py:627]   47         | 2          |  meta           
INFO 01-06 17:11:12.642955.642955 lmp.py:627]   50         | 2          |  cuda:1         
INFO 01-06 17:11:12.642188.642188 lmp.py:627]   56         | 2          |  meta           
INFO 01-06 17:11:12.642997.642997 lmp.py:627]   4          | 3          |  cuda:1         
INFO 01-06 17:11:12.642283.642283 lmp.py:627]   10         | 3          |  cuda:1         
INFO 01-06 17:11:12.642185.642185 lmp.py:627]   20         | 3          |  cuda:1         
INFO 01-06 17:11:12.642848.642848 lmp.py:627]   25         | 3          |  cuda:1         
INFO 01-06 17:11:12.642180.642180 lmp.py:627]   31         | 3          |  meta           
INFO 01-06 17:11:12.642944.642944 lmp.py:627]   35         | 3          |  cuda:1         
INFO 01-06 17:11:12.642376.642376 lmp.py:627]   36         | 3          |  cuda:1         
INFO 01-06 17:11:12.642894.642894 lmp.py:627]   58         | 3          |  cuda:1         
INFO 01-06 17:11:12.642934.642934 lmp.py:627]   0          | 4          |  cuda:1         
INFO 01-06 17:11:12.642406.642406 lmp.py:627]   6          | 4          |  cuda:1         
INFO 01-06 17:11:12.642354.642354 lmp.py:627]   15         | 4          |  meta           
INFO 01-06 17:11:12.642156.642156 lmp.py:627]   24         | 4          |  cuda:1         
INFO 01-06 17:11:12.642720.642720 lmp.py:627]   28         | 4          |  meta           
INFO 01-06 17:11:12.642522.642522 lmp.py:627]   32         | 4          |  cuda:1         
INFO 01-06 17:11:12.642325.642325 lmp.py:627]   9          | 5          |  cuda:1         
INFO 01-06 17:11:12.642604.642604 lmp.py:627]   44         | 5          |  cuda:1         
INFO 01-06 17:11:12.642837.642837 lmp.py:627]   53         | 5          |  cuda:1         
INFO 01-06 17:11:12.642069.642069 lmp.py:627]   8          | 6          |  cuda:1         
INFO 01-06 17:11:12.642494.642494 lmp.py:627]   11         | 8          |  cuda:1         
INFO 01-06 17:11:12.642774.642774 lmp.py:627]   46         | 8          |  cuda:1         
INFO 01-06 17:11:12.642337.642337 lmp.py:627]   41         | 9          |  cuda:1         
INFO 01-06 17:11:12.642663.642663 lmp.py:627]   1          | 10         |  cuda:1         
INFO 01-06 17:11:12.642227.642227 lmp.py:627]   21         | 10         |  cuda:1         
INFO 01-06 17:11:12.642791.642791 lmp.py:627]   59         | 11         |  cuda:1         
INFO 01-06 17:11:12.642024.642024 lmp.py:627]   62         | 14         |  cuda:1         
INFO 01-06 17:11:12.642495.642495 lmp.py:627]   49         | 15         |  cuda:1         
INFO 01-06 17:11:12.642105.642105 lmp.py:628] ============================================================
INFO 01-06 17:11:12.642105.642105 lmp.py:628] 
INFO 01-06 17:11:12.643775.643775 lmp.py:630] experts_gpu_list: [2, 5, 18, 23, 30, 39, 13, 33, 40, 50, 4, 10, 20, 25, 35, 36, 58, 0, 6, 24, 32, 9, 44, 53, 8, 11, 46, 41, 1, 21, 59, 62, 49] num: 33
INFO 01-06 17:11:12.643154.643154 lmp.py:631] experts_cpu_list: [19, 22, 34, 37, 45, 51, 54, 55, 60, 63, 7, 12, 14, 17, 27, 47, 56, 31, 15, 28] num: 20
INFO 01-06 17:11:12.643076.643076 lmp.py:632] expert_actual_device_map {0: 'cuda:1', 1: 'cuda:1', 2: 'cuda:1', 3: 'cuda:1', 4: 'cuda:1', 5: 'cuda:1', 6: 'cuda:1', 7: 'meta', 8: 'cuda:1', 9: 'cuda:1', 10: 'cuda:1', 11: 'cuda:1', 12: 'meta', 13: 'cuda:1', 14: 'meta', 15: 'meta', 16: 'cuda:1', 17: 'meta', 18: 'cuda:1', 19: 'meta', 20: 'cuda:1', 21: 'cuda:1', 22: 'meta', 23: 'cuda:1', 24: 'cuda:1', 25: 'cuda:1', 26: 'meta', 27: 'meta', 28: 'meta', 29: 'cuda:1', 30: 'cuda:1', 31: 'meta', 32: 'cuda:1', 33: 'cuda:1', 34: 'meta', 35: 'cuda:1', 36: 'cuda:1', 37: 'meta', 38: 'meta', 39: 'cuda:1', 40: 'cuda:1', 41: 'cuda:1', 42: 'cuda:1', 43: 'meta', 44: 'cuda:1', 45: 'meta', 46: 'cuda:1', 47: 'meta', 48: 'meta', 49: 'cuda:1', 50: 'cuda:1', 51: 'meta', 52: 'meta', 53: 'cuda:1', 54: 'meta', 55: 'meta', 56: 'meta', 57: 'meta', 58: 'cuda:1', 59: 'cuda:1', 60: 'meta', 61: 'meta', 62: 'cuda:1', 63: 'meta'}
DEBUG 01-06 17:11:12.643806.643806 cuda_h.py:19] end experts_map_get cost 0.0032787322998046875 seconds
DEBUG 01-06 17:11:12.643048.643048 cuda_h.py:10] start gpu_sexperts
DEBUG 01-06 17:11:12.643885.643885 cuda_h.py:19] end gpu_sexperts cost 0.00042319297790527344 seconds
DEBUG 01-06 17:11:12.643973.643973 cuda_h.py:10] start gpu_experts
DEBUG 01-06 17:11:12.644648.644648 mlpmodule.py:533] gpu group tensors cost 0.0008637905120849609 s
DEBUG 01-06 17:11:12.646882.646882 mlpmodule.py:664]  experts func einsum cost 0.030129432678222656 s
DEBUG 01-06 17:11:12.646103.646103 mlpmodule.py:566] gpu pad cost 0.0018520355224609375 s
DEBUG 01-06 17:11:12.647476.647476 mlpmodule.py:584] gpu group einsum cost 0.00037407875061035156 s
DEBUG 01-06 17:11:12.650073.650073 mlpmodule.py:613] gpu experts func einsum cost 0.0066525936126708984 s
DEBUG 01-06 17:11:12.650057.650057 cuda_h.py:19] end gpu_experts cost 0.006797075271606445 seconds
DEBUG 01-06 17:11:12.650289.650289 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-06 17:11:12.650900.650900 lmp.py:661] 
DEBUG 01-06 17:11:12.650900.650900 lmp.py:661]   Computing 20 experts on CPU...
DEBUG 01-06 17:11:12.650326.650326 cuda_h.py:19] end cpu_experts_submit cost 6.723403930664062e-05 seconds
DEBUG 01-06 17:11:12.650744.650744 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-06 17:11:12.662405.662405 mlpmodule.py:706] group tensors cost 0.011612892150878906 s
DEBUG 01-06 17:11:12.664038.664038 mlpmodule.py:744] pad cost 0.0010898113250732422 s
DEBUG 01-06 17:11:12.664909.664909 mlpmodule.py:750] create cpu tensor cost 5.340576171875e-05 s
DEBUG 01-06 17:11:12.664819.664819 mlpmodule.py:755] move to cpu cost 3.24249267578125e-05 s
DEBUG 01-06 17:11:12.667709.667709 mlpmodule.py:769] group_w3: shape=torch.Size([20, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=57671680
DEBUG 01-06 17:11:12.667705.667705 mlpmodule.py:770] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-06 17:11:12.667171.667171 mlpmodule.py:775] group_w3 first element: -0.0142822265625
WARNING 01-06 17:11:12.667677.667677 mlpmodule.py:785] start einsum2
DEBUG 01-06 17:11:12.671924.671924 mlpmodule.py:795] group einsum cost 0.007442474365234375 s
DEBUG 01-06 17:11:12.672738.672738 mlpmodule.py:803] cpy2cputensor cost 0.00011277198791503906 s
DEBUG 01-06 17:11:12.675980.675980 cuda_h.py:19] end wait_cetm_experts cost 0.02414703369140625 seconds
DEBUG 01-06 17:11:12.675955.675955 cuda_h.py:19] end layer_moe_dgenerate_10 cost 0.036557912826538086 seconds
DEBUG 01-06 17:11:12.675671.675671 lmp.py:325] -------------------------------- end decode layer 10 --------------------------------
DEBUG 01-06 17:11:12.675792.675792 lmp.py:298] -------------------------------- start decode layer 11 --------------------------------
DEBUG 01-06 17:11:12.675807.675807 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-06 17:11:12.675335.675335 mlpmodule.py:367] cuda:1 cuda:1
DEBUG 01-06 17:11:12.676128.676128 cuda_h.py:10] start self_attn
cos shape torch.Size([65, 128]) sin shape torch.Size([65, 128]) position_ids tensor([[0]], device='cuda:1')
cos shape torch.Size([1, 1, 1, 128]) sin shape torch.Size([1, 1, 1, 128])
q_embed shape torch.Size([32, 16, 1, 128]) k_embed shape torch.Size([32, 16, 1, 128])
DEBUG 01-06 17:11:12.679377.679377 cuda_h.py:19] end self_attn cost 0.0024116039276123047 seconds
DEBUG 01-06 17:11:12.679359.679359 cuda_h.py:19] end iln_self_attn_paln cost 0.003587961196899414 seconds
DEBUG 01-06 17:11:12.679692.679692 cuda_h.py:10] start layer_moe_dgenerate_11
DEBUG 01-06 17:11:12.679535.679535 cuda_h.py:10] start gate
DEBUG 01-06 17:11:12.680790.680790 cuda_h.py:19] end gate cost 0.000827789306640625 seconds
DEBUG 01-06 17:11:12.680469.680469 cuda_h.py:10] start experts_map_get
INFO 01-06 17:11:12.681067.681067 lmp.py:609] using loaded check layer: True
INFO 01-06 17:11:12.681234.681234 lmp.py:620] 
INFO 01-06 17:11:12.681234.681234 lmp.py:620] Layer 11 Expert Device Distribution:
INFO 01-06 17:11:12.681686.681686 lmp.py:621]   Active experts: 51 (out of 64 total)
INFO 01-06 17:11:12.681356.681356 lmp.py:622] 
INFO 01-06 17:11:12.681356.681356 lmp.py:622]   Detailed Expert Distribution:
INFO 01-06 17:11:12.681742.681742 lmp.py:623]   Expert ID  | Tokens     | Actual Device  
INFO 01-06 17:11:12.682120.682120 lmp.py:624]   ----------------------------------------------------------------------
INFO 01-06 17:11:12.682976.682976 lmp.py:627]   3          | 1          |  cuda:1         
INFO 01-06 17:11:12.682361.682361 lmp.py:627]   5          | 1          |  cuda:1         
INFO 01-06 17:11:12.682071.682071 lmp.py:627]   10         | 1          |  cuda:1         
INFO 01-06 17:11:12.682257.682257 lmp.py:627]   15         | 1          |  meta           
INFO 01-06 17:11:12.682159.682159 lmp.py:627]   17         | 1          |  meta           
INFO 01-06 17:11:12.682061.682061 lmp.py:627]   18         | 1          |  meta           
INFO 01-06 17:11:12.682201.682201 lmp.py:627]   21         | 1          |  cuda:1         
INFO 01-06 17:11:12.682434.682434 lmp.py:627]   24         | 1          |  cuda:1         
INFO 01-06 17:11:12.682667.682667 lmp.py:627]   34         | 1          |  cuda:1         
INFO 01-06 17:11:12.682423.682423 lmp.py:627]   35         | 1          |  meta           
INFO 01-06 17:11:12.682417.682417 lmp.py:627]   36         | 1          |  meta           
INFO 01-06 17:11:12.682365.682365 lmp.py:627]   41         | 1          |  meta           
INFO 01-06 17:11:12.682552.682552 lmp.py:627]   42         | 1          |  meta           
INFO 01-06 17:11:12.682308.682308 lmp.py:627]   48         | 1          |  cuda:1         
INFO 01-06 17:11:12.682540.682540 lmp.py:627]   50         | 1          |  meta           
INFO 01-06 17:11:12.682058.682058 lmp.py:627]   57         | 1          |  cuda:1         
INFO 01-06 17:11:12.682052.682052 lmp.py:627]   61         | 1          |  meta           
INFO 01-06 17:11:12.682047.682047 lmp.py:627]   11         | 2          |  cuda:1         
INFO 01-06 17:11:12.682472.682472 lmp.py:627]   31         | 2          |  meta           
INFO 01-06 17:11:12.682135.682135 lmp.py:627]   37         | 2          |  cuda:1         
INFO 01-06 17:11:12.682368.682368 lmp.py:627]   40         | 2          |  meta           
INFO 01-06 17:11:12.682362.682362 lmp.py:627]   52         | 2          |  cuda:1         
INFO 01-06 17:11:12.682834.682834 lmp.py:627]   56         | 2          |  cuda:1         
INFO 01-06 17:11:12.682073.682073 lmp.py:627]   59         | 2          |  meta           
INFO 01-06 17:11:12.682975.682975 lmp.py:627]   62         | 2          |  meta           
INFO 01-06 17:11:12.682638.682638 lmp.py:627]   0          | 3          |  cuda:1         
INFO 01-06 17:11:12.682540.682540 lmp.py:627]   2          | 3          |  cuda:1         
INFO 01-06 17:11:12.682058.682058 lmp.py:627]   14         | 3          |  cuda:1         
INFO 01-06 17:11:12.682052.682052 lmp.py:627]   19         | 3          |  meta           
INFO 01-06 17:11:12.682285.682285 lmp.py:627]   23         | 3          |  meta           
INFO 01-06 17:11:12.683048.683048 lmp.py:627]   30         | 3          |  cuda:1         
INFO 01-06 17:11:12.683844.683844 lmp.py:627]   44         | 3          |  meta           
INFO 01-06 17:11:12.683422.683422 lmp.py:627]   45         | 3          |  cuda:1         
INFO 01-06 17:11:12.683516.683516 lmp.py:627]   46         | 3          |  meta           
INFO 01-06 17:11:12.683848.683848 lmp.py:627]   49         | 3          |  meta           
INFO 01-06 17:11:12.683419.683419 lmp.py:627]   55         | 3          |  cuda:1         
INFO 01-06 17:11:12.683989.683989 lmp.py:627]   58         | 3          |  cuda:1         
INFO 01-06 17:11:12.683799.683799 lmp.py:627]   60         | 3          |  cuda:1         
DEBUG 01-06 17:11:12.683364.683364 mlpmodule.py:664]  experts func einsum cost 0.032363176345825195 s
INFO 01-06 17:11:12.683644.683644 lmp.py:627]   16         | 4          |  meta           
INFO 01-06 17:11:12.683525.683525 lmp.py:627]   25         | 4          |  cuda:1         
INFO 01-06 17:11:12.683003.683003 lmp.py:627]   29         | 4          |  cuda:1         
INFO 01-06 17:11:12.683620.683620 lmp.py:627]   51         | 4          |  cuda:1         
INFO 01-06 17:11:12.683098.683098 lmp.py:627]   27         | 5          |  cuda:1         
INFO 01-06 17:11:12.683284.683284 lmp.py:627]   8          | 7          |  cuda:1         
INFO 01-06 17:11:12.683279.683279 lmp.py:627]   4          | 8          |  cuda:1         
INFO 01-06 17:11:12.683796.683796 lmp.py:627]   54         | 8          |  cuda:1         
INFO 01-06 17:11:12.683552.683552 lmp.py:627]   7          | 10         |  cuda:1         
INFO 01-06 17:11:12.683785.683785 lmp.py:627]   22         | 12         |  cuda:1         
INFO 01-06 17:11:12.683972.683972 lmp.py:627]   1          | 14         |  cuda:1         
INFO 01-06 17:11:12.683397.683397 lmp.py:627]   12         | 18         |  cuda:1         
INFO 01-06 17:11:12.683153.683153 lmp.py:627]   28         | 22         |  cuda:1         
INFO 01-06 17:11:12.683193.683193 lmp.py:628] ============================================================
INFO 01-06 17:11:12.683193.683193 lmp.py:628] 
INFO 01-06 17:11:12.684248.684248 lmp.py:630] experts_gpu_list: [3, 5, 10, 21, 24, 34, 48, 57, 11, 37, 52, 56, 0, 2, 14, 30, 45, 55, 58, 60, 25, 29, 51, 27, 8, 4, 54, 7, 22, 1, 12, 28] num: 32
INFO 01-06 17:11:12.684057.684057 lmp.py:631] experts_cpu_list: [15, 17, 18, 35, 36, 41, 42, 50, 61, 31, 40, 59, 62, 19, 23, 44, 46, 49, 16] num: 19
INFO 01-06 17:11:12.684032.684032 lmp.py:632] expert_actual_device_map {0: 'cuda:1', 1: 'cuda:1', 2: 'cuda:1', 3: 'cuda:1', 4: 'cuda:1', 5: 'cuda:1', 6: 'cuda:1', 7: 'cuda:1', 8: 'cuda:1', 9: 'cuda:1', 10: 'cuda:1', 11: 'cuda:1', 12: 'cuda:1', 13: 'cuda:1', 14: 'cuda:1', 15: 'meta', 16: 'meta', 17: 'meta', 18: 'meta', 19: 'meta', 20: 'meta', 21: 'cuda:1', 22: 'cuda:1', 23: 'meta', 24: 'cuda:1', 25: 'cuda:1', 26: 'meta', 27: 'cuda:1', 28: 'cuda:1', 29: 'cuda:1', 30: 'cuda:1', 31: 'meta', 32: 'meta', 33: 'meta', 34: 'cuda:1', 35: 'meta', 36: 'meta', 37: 'cuda:1', 38: 'meta', 39: 'meta', 40: 'meta', 41: 'meta', 42: 'meta', 43: 'meta', 44: 'meta', 45: 'cuda:1', 46: 'meta', 47: 'cuda:1', 48: 'cuda:1', 49: 'meta', 50: 'meta', 51: 'cuda:1', 52: 'cuda:1', 53: 'cuda:1', 54: 'cuda:1', 55: 'cuda:1', 56: 'cuda:1', 57: 'cuda:1', 58: 'cuda:1', 59: 'meta', 60: 'cuda:1', 61: 'meta', 62: 'meta', 63: 'meta'}
DEBUG 01-06 17:11:12.684676.684676 cuda_h.py:19] end experts_map_get cost 0.003573894500732422 seconds
DEBUG 01-06 17:11:12.684349.684349 cuda_h.py:10] start gpu_sexperts
DEBUG 01-06 17:11:12.684394.684394 cuda_h.py:19] end gpu_sexperts cost 0.0005047321319580078 seconds
DEBUG 01-06 17:11:12.684012.684012 cuda_h.py:10] start gpu_experts
DEBUG 01-06 17:11:12.685472.685472 mlpmodule.py:533] gpu group tensors cost 0.00060272216796875 s
DEBUG 01-06 17:11:12.687992.687992 mlpmodule.py:566] gpu pad cost 0.0016338825225830078 s
DEBUG 01-06 17:11:12.687199.687199 mlpmodule.py:584] gpu group einsum cost 0.00037360191345214844 s
DEBUG 01-06 17:11:12.690149.690149 mlpmodule.py:613] gpu experts func einsum cost 0.005979776382446289 s
DEBUG 01-06 17:11:12.691748.691748 cuda_h.py:19] end gpu_experts cost 0.006116390228271484 seconds
DEBUG 01-06 17:11:12.691034.691034 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-06 17:11:12.691267.691267 lmp.py:661] 
DEBUG 01-06 17:11:12.691267.691267 lmp.py:661]   Computing 19 experts on CPU...
DEBUG 01-06 17:11:12.691071.691071 cuda_h.py:19] end cpu_experts_submit cost 6.461143493652344e-05 seconds
DEBUG 01-06 17:11:12.691727.691727 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-06 17:11:12.695390.695390 mlpmodule.py:706] group tensors cost 0.004024028778076172 s
DEBUG 01-06 17:11:12.697724.697724 mlpmodule.py:744] pad cost 0.0012288093566894531 s
DEBUG 01-06 17:11:12.697079.697079 mlpmodule.py:750] create cpu tensor cost 4.76837158203125e-05 s
DEBUG 01-06 17:11:12.697565.697565 mlpmodule.py:755] move to cpu cost 3.457069396972656e-05 s
DEBUG 01-06 17:11:12.700889.700889 mlpmodule.py:769] group_w3: shape=torch.Size([19, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=54788096
DEBUG 01-06 17:11:12.700938.700938 mlpmodule.py:770] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-06 17:11:12.700642.700642 mlpmodule.py:775] group_w3 first element: -0.03271484375
WARNING 01-06 17:11:12.700301.700301 mlpmodule.py:785] start einsum2
DEBUG 01-06 17:11:12.705394.705394 mlpmodule.py:795] group einsum cost 0.007516145706176758 s
DEBUG 01-06 17:11:12.705203.705203 mlpmodule.py:803] cpy2cputensor cost 0.0001468658447265625 s
DEBUG 01-06 17:11:12.707137.707137 cuda_h.py:19] end wait_cetm_experts cost 0.016506195068359375 seconds
DEBUG 01-06 17:11:12.708713.708713 cuda_h.py:19] end layer_moe_dgenerate_11 cost 0.028649091720581055 seconds
DEBUG 01-06 17:11:12.708222.708222 lmp.py:325] -------------------------------- end decode layer 11 --------------------------------
DEBUG 01-06 17:11:12.708873.708873 lmp.py:298] -------------------------------- start decode layer 12 --------------------------------
DEBUG 01-06 17:11:12.708814.708814 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-06 17:11:12.708831.708831 mlpmodule.py:367] cuda:1 cuda:1
DEBUG 01-06 17:11:12.708347.708347 cuda_h.py:10] start self_attn
cos shape torch.Size([65, 128]) sin shape torch.Size([65, 128]) position_ids tensor([[0]], device='cuda:1')
cos shape torch.Size([1, 1, 1, 128]) sin shape torch.Size([1, 1, 1, 128])
q_embed shape torch.Size([32, 16, 1, 128]) k_embed shape torch.Size([32, 16, 1, 128])
DEBUG 01-06 17:11:12.710452.710452 cuda_h.py:19] end self_attn cost 0.0018727779388427734 seconds
DEBUG 01-06 17:11:12.711775.711775 cuda_h.py:19] end iln_self_attn_paln cost 0.0027434825897216797 seconds
DEBUG 01-06 17:11:12.711227.711227 cuda_h.py:10] start layer_moe_dgenerate_12
DEBUG 01-06 17:11:12.711473.711473 cuda_h.py:10] start gate
DEBUG 01-06 17:11:12.711150.711150 cuda_h.py:19] end gate cost 0.0006003379821777344 seconds
DEBUG 01-06 17:11:12.712225.712225 cuda_h.py:10] start experts_map_get
INFO 01-06 17:11:12.712799.712799 lmp.py:609] using loaded check layer: True
INFO 01-06 17:11:12.712375.712375 lmp.py:620] 
INFO 01-06 17:11:12.712375.712375 lmp.py:620] Layer 12 Expert Device Distribution:
INFO 01-06 17:11:12.712575.712575 lmp.py:621]   Active experts: 47 (out of 64 total)
INFO 01-06 17:11:12.713516.713516 lmp.py:622] 
INFO 01-06 17:11:12.713516.713516 lmp.py:622]   Detailed Expert Distribution:
INFO 01-06 17:11:12.713888.713888 lmp.py:623]   Expert ID  | Tokens     | Actual Device  
INFO 01-06 17:11:12.713445.713445 lmp.py:624]   ----------------------------------------------------------------------
INFO 01-06 17:11:12.713194.713194 lmp.py:627]   1          | 1          |  cuda:1         
INFO 01-06 17:11:12.713513.713513 lmp.py:627]   6          | 1          |  cuda:1         
INFO 01-06 17:11:12.713117.713117 lmp.py:627]   7          | 1          |  cuda:1         
INFO 01-06 17:11:12.713720.713720 lmp.py:627]   13         | 1          |  meta           
INFO 01-06 17:11:12.713562.713562 lmp.py:627]   14         | 1          |  meta           
INFO 01-06 17:11:12.713927.713927 lmp.py:627]   17         | 1          |  meta           
INFO 01-06 17:11:12.713769.713769 lmp.py:627]   19         | 1          |  cuda:1         
INFO 01-06 17:11:12.713611.713611 lmp.py:627]   22         | 1          |  meta           
INFO 01-06 17:11:12.713691.713691 lmp.py:627]   23         | 1          |  cuda:1         
INFO 01-06 17:11:12.713010.713010 lmp.py:627]   25         | 1          |  cuda:1         
INFO 01-06 17:11:12.713090.713090 lmp.py:627]   28         | 1          |  cuda:1         
INFO 01-06 17:11:12.713693.713693 lmp.py:627]   30         | 1          |  cuda:1         
INFO 01-06 17:11:12.713581.713581 lmp.py:627]   33         | 1          |  cuda:1         
INFO 01-06 17:11:12.713231.713231 lmp.py:627]   34         | 1          |  meta           
INFO 01-06 17:11:12.713596.713596 lmp.py:627]   38         | 1          |  meta           
INFO 01-06 17:11:12.713484.713484 lmp.py:627]   39         | 1          |  meta           
INFO 01-06 17:11:12.713326.713326 lmp.py:627]   48         | 1          |  cuda:1         
INFO 01-06 17:11:12.713214.713214 lmp.py:627]   53         | 1          |  meta           
INFO 01-06 17:11:12.713580.713580 lmp.py:627]   18         | 2          |  meta           
INFO 01-06 17:11:12.713183.713183 lmp.py:627]   20         | 2          |  meta           
INFO 01-06 17:11:12.713502.713502 lmp.py:627]   21         | 2          |  meta           
INFO 01-06 17:11:12.713105.713105 lmp.py:627]   36         | 2          |  cuda:1         
INFO 01-06 17:11:12.713993.713993 lmp.py:627]   46         | 2          |  cuda:1         
INFO 01-06 17:11:12.713643.713643 lmp.py:627]   47         | 2          |  meta           
INFO 01-06 17:11:12.713531.713531 lmp.py:627]   54         | 2          |  cuda:1         
INFO 01-06 17:11:12.713181.713181 lmp.py:627]   8          | 3          |  cuda:1         
INFO 01-06 17:11:12.713069.713069 lmp.py:627]   24         | 3          |  cuda:1         
INFO 01-06 17:11:12.713957.713957 lmp.py:627]   31         | 3          |  cuda:1         
INFO 01-06 17:11:12.713561.713561 lmp.py:627]   57         | 3          |  meta           
INFO 01-06 17:11:12.713641.713641 lmp.py:627]   58         | 3          |  meta           
INFO 01-06 17:11:12.713006.713006 lmp.py:627]   59         | 3          |  cuda:1         
INFO 01-06 17:11:12.713133.713133 lmp.py:627]   63         | 3          |  meta           
INFO 01-06 17:11:12.713544.713544 lmp.py:627]   42         | 4          |  cuda:1         
INFO 01-06 17:11:12.713671.713671 lmp.py:627]   43         | 4          |  meta           
INFO 01-06 17:11:12.713797.713797 lmp.py:627]   44         | 4          |  meta           
INFO 01-06 17:11:12.713209.713209 lmp.py:627]   60         | 4          |  meta           
INFO 01-06 17:11:12.713620.713620 lmp.py:627]   62         | 4          |  cuda:1         
INFO 01-06 17:11:12.713462.713462 lmp.py:627]   51         | 5          |  cuda:1         
INFO 01-06 17:11:12.713542.713542 lmp.py:627]   35         | 6          |  cuda:1         
INFO 01-06 17:11:12.714384.714384 lmp.py:627]   45         | 7          |  meta           
INFO 01-06 17:11:12.714987.714987 lmp.py:627]   41         | 8          |  cuda:1         
INFO 01-06 17:11:12.714399.714399 lmp.py:627]   26         | 9          |  cuda:1         
INFO 01-06 17:11:12.714287.714287 lmp.py:627]   10         | 11         |  cuda:1         
INFO 01-06 17:11:12.714890.714890 lmp.py:627]   56         | 11         |  cuda:1         
INFO 01-06 17:11:12.714779.714779 lmp.py:627]   3          | 14         |  cuda:1         
INFO 01-06 17:11:12.714382.714382 lmp.py:627]   15         | 21         |  cuda:1         
INFO 01-06 17:11:12.714224.714224 lmp.py:627]   40         | 27         |  cuda:1         
INFO 01-06 17:11:12.714066.714066 lmp.py:628] ============================================================
INFO 01-06 17:11:12.714066.714066 lmp.py:628] 
INFO 01-06 17:11:12.714391.714391 lmp.py:630] experts_gpu_list: [1, 6, 7, 19, 23, 25, 28, 30, 33, 48, 36, 46, 54, 8, 24, 31, 59, 42, 62, 51, 35, 41, 26, 10, 56, 3, 15, 40] num: 28
INFO 01-06 17:11:12.714856.714856 lmp.py:631] experts_cpu_list: [13, 14, 17, 22, 34, 38, 39, 53, 18, 20, 21, 47, 57, 58, 63, 43, 44, 60, 45] num: 19
INFO 01-06 17:11:12.714049.714049 lmp.py:632] expert_actual_device_map {0: 'cuda:1', 1: 'cuda:1', 2: 'cuda:1', 3: 'cuda:1', 4: 'cuda:1', 5: 'cuda:1', 6: 'cuda:1', 7: 'cuda:1', 8: 'cuda:1', 9: 'cuda:1', 10: 'cuda:1', 11: 'meta', 12: 'meta', 13: 'meta', 14: 'meta', 15: 'cuda:1', 16: 'meta', 17: 'meta', 18: 'meta', 19: 'cuda:1', 20: 'meta', 21: 'meta', 22: 'meta', 23: 'cuda:1', 24: 'cuda:1', 25: 'cuda:1', 26: 'cuda:1', 27: 'meta', 28: 'cuda:1', 29: 'cuda:1', 30: 'cuda:1', 31: 'cuda:1', 32: 'meta', 33: 'cuda:1', 34: 'meta', 35: 'cuda:1', 36: 'cuda:1', 37: 'meta', 38: 'meta', 39: 'meta', 40: 'cuda:1', 41: 'cuda:1', 42: 'cuda:1', 43: 'meta', 44: 'meta', 45: 'meta', 46: 'cuda:1', 47: 'meta', 48: 'cuda:1', 49: 'cuda:1', 50: 'cuda:1', 51: 'cuda:1', 52: 'meta', 53: 'meta', 54: 'cuda:1', 55: 'cuda:1', 56: 'cuda:1', 57: 'meta', 58: 'meta', 59: 'cuda:1', 60: 'meta', 61: 'meta', 62: 'cuda:1', 63: 'meta'}
DEBUG 01-06 17:11:12.714858.714858 cuda_h.py:19] end experts_map_get cost 0.002258777618408203 seconds
DEBUG 01-06 17:11:12.714888.714888 cuda_h.py:10] start gpu_sexperts
DEBUG 01-06 17:11:12.714668.714668 cuda_h.py:19] end gpu_sexperts cost 0.0003218650817871094 seconds
DEBUG 01-06 17:11:12.714544.714544 cuda_h.py:10] start gpu_experts
DEBUG 01-06 17:11:12.715863.715863 mlpmodule.py:533] gpu group tensors cost 0.0005514621734619141 s
DEBUG 01-06 17:11:12.716729.716729 mlpmodule.py:664]  experts func einsum cost 0.025429725646972656 s
DEBUG 01-06 17:11:12.717417.717417 mlpmodule.py:566] gpu pad cost 0.0016438961029052734 s
DEBUG 01-06 17:11:12.717397.717397 mlpmodule.py:584] gpu group einsum cost 0.0004973411560058594 s
DEBUG 01-06 17:11:12.720762.720762 mlpmodule.py:613] gpu experts func einsum cost 0.0058460235595703125 s
DEBUG 01-06 17:11:12.720116.720116 cuda_h.py:19] end gpu_experts cost 0.005972862243652344 seconds
DEBUG 01-06 17:11:12.720441.720441 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-06 17:11:12.720859.720859 lmp.py:661] 
DEBUG 01-06 17:11:12.720859.720859 lmp.py:661]   Computing 19 experts on CPU...
DEBUG 01-06 17:11:12.720524.720524 cuda_h.py:19] end cpu_experts_submit cost 6.771087646484375e-05 seconds
DEBUG 01-06 17:11:12.720651.720651 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-06 17:11:12.724463.724463 mlpmodule.py:706] group tensors cost 0.0037572383880615234 s
DEBUG 01-06 17:11:12.726620.726620 mlpmodule.py:744] pad cost 0.0009908676147460938 s
DEBUG 01-06 17:11:12.726147.726147 mlpmodule.py:750] create cpu tensor cost 4.1484832763671875e-05 s
DEBUG 01-06 17:11:12.726235.726235 mlpmodule.py:755] move to cpu cost 2.9087066650390625e-05 s
DEBUG 01-06 17:11:12.728617.728617 mlpmodule.py:769] group_w3: shape=torch.Size([19, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=54788096
DEBUG 01-06 17:11:12.728421.728421 mlpmodule.py:770] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-06 17:11:12.729118.729118 mlpmodule.py:775] group_w3 first element: -0.01300048828125
WARNING 01-06 17:11:12.729903.729903 mlpmodule.py:785] start einsum2
DEBUG 01-06 17:11:12.732594.732594 mlpmodule.py:795] group einsum cost 0.006331443786621094 s
DEBUG 01-06 17:11:12.733203.733203 mlpmodule.py:803] cpy2cputensor cost 0.00010061264038085938 s
DEBUG 01-06 17:11:12.735225.735225 cuda_h.py:19] end wait_cetm_experts cost 0.014700651168823242 seconds
DEBUG 01-06 17:11:12.736523.736523 cuda_h.py:19] end layer_moe_dgenerate_12 cost 0.02481985092163086 seconds
DEBUG 01-06 17:11:12.736648.736648 lmp.py:325] -------------------------------- end decode layer 12 --------------------------------
DEBUG 01-06 17:11:12.736748.736748 lmp.py:298] -------------------------------- start decode layer 13 --------------------------------
DEBUG 01-06 17:11:12.736002.736002 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-06 17:11:12.736734.736734 mlpmodule.py:367] cuda:1 cuda:1
DEBUG 01-06 17:11:12.736442.736442 cuda_h.py:10] start self_attn
cos shape torch.Size([65, 128]) sin shape torch.Size([65, 128]) position_ids tensor([[0]], device='cuda:1')
cos shape torch.Size([1, 1, 1, 128]) sin shape torch.Size([1, 1, 1, 128])
q_embed shape torch.Size([32, 16, 1, 128]) k_embed shape torch.Size([32, 16, 1, 128])
DEBUG 01-06 17:11:12.738566.738566 cuda_h.py:19] end self_attn cost 0.0018515586853027344 seconds
DEBUG 01-06 17:11:12.739868.739868 cuda_h.py:19] end iln_self_attn_paln cost 0.002708911895751953 seconds
DEBUG 01-06 17:11:12.739844.739844 cuda_h.py:10] start layer_moe_dgenerate_13
DEBUG 01-06 17:11:12.739044.739044 cuda_h.py:10] start gate
DEBUG 01-06 17:11:12.739721.739721 cuda_h.py:19] end gate cost 0.0005996227264404297 seconds
DEBUG 01-06 17:11:12.739034.739034 cuda_h.py:10] start experts_map_get
INFO 01-06 17:11:12.740839.740839 lmp.py:609] using loaded check layer: True
INFO 01-06 17:11:12.740601.740601 lmp.py:620] 
INFO 01-06 17:11:12.740601.740601 lmp.py:620] Layer 13 Expert Device Distribution:
INFO 01-06 17:11:12.740986.740986 lmp.py:621]   Active experts: 46 (out of 64 total)
INFO 01-06 17:11:12.740596.740596 lmp.py:622] 
INFO 01-06 17:11:12.740596.740596 lmp.py:622]   Detailed Expert Distribution:
INFO 01-06 17:11:12.740445.740445 lmp.py:623]   Expert ID  | Tokens     | Actual Device  
INFO 01-06 17:11:12.740764.740764 lmp.py:624]   ----------------------------------------------------------------------
INFO 01-06 17:11:12.741274.741274 lmp.py:627]   4          | 1          |  cuda:1         
INFO 01-06 17:11:12.741832.741832 lmp.py:627]   10         | 1          |  meta           
INFO 01-06 17:11:12.741435.741435 lmp.py:627]   13         | 1          |  meta           
INFO 01-06 17:11:12.741800.741800 lmp.py:627]   31         | 1          |  meta           
INFO 01-06 17:11:12.741403.741403 lmp.py:627]   33         | 1          |  meta           
INFO 01-06 17:11:12.741245.741245 lmp.py:627]   35         | 1          |  meta           
INFO 01-06 17:11:12.741041.741041 lmp.py:627]   39         | 1          |  cuda:1         
INFO 01-06 17:11:12.741790.741790 lmp.py:627]   40         | 1          |  meta           
INFO 01-06 17:11:12.741870.741870 lmp.py:627]   50         | 1          |  meta           
INFO 01-06 17:11:12.741712.741712 lmp.py:627]   57         | 1          |  cuda:1         
INFO 01-06 17:11:12.741839.741839 lmp.py:627]   58         | 1          |  meta           
INFO 01-06 17:11:12.741965.741965 lmp.py:627]   9          | 2          |  meta           
INFO 01-06 17:11:12.741615.741615 lmp.py:627]   12         | 2          |  meta           
INFO 01-06 17:11:12.741980.741980 lmp.py:627]   16         | 2          |  cuda:1         
INFO 01-06 17:11:12.741822.741822 lmp.py:627]   20         | 2          |  meta           
INFO 01-06 17:11:12.741949.741949 lmp.py:627]   23         | 2          |  cuda:1         
INFO 01-06 17:11:12.741029.741029 lmp.py:627]   24         | 2          |  cuda:1         
INFO 01-06 17:11:12.741348.741348 lmp.py:627]   29         | 2          |  cuda:1         
INFO 01-06 17:11:12.741713.741713 lmp.py:627]   38         | 2          |  cuda:1         
INFO 01-06 17:11:12.741078.741078 lmp.py:627]   41         | 2          |  cuda:1         
INFO 01-06 17:11:12.741966.741966 lmp.py:627]   43         | 2          |  cuda:1         
INFO 01-06 17:11:12.741854.741854 lmp.py:627]   8          | 3          |  cuda:1         
INFO 01-06 17:11:12.741742.741742 lmp.py:627]   11         | 3          |  meta           
INFO 01-06 17:11:12.741869.741869 lmp.py:627]   14         | 3          |  cuda:1         
INFO 01-06 17:11:12.741472.741472 lmp.py:627]   22         | 3          |  cuda:1         
INFO 01-06 17:11:12.741791.741791 lmp.py:627]   34         | 3          |  meta           
INFO 01-06 17:11:12.741394.741394 lmp.py:627]   36         | 3          |  cuda:1         
INFO 01-06 17:11:12.741475.741475 lmp.py:627]   37         | 3          |  cuda:1         
INFO 01-06 17:11:12.741078.741078 lmp.py:627]   48         | 3          |  meta           
INFO 01-06 17:11:12.741682.741682 lmp.py:627]   61         | 3          |  meta           
INFO 01-06 17:11:12.741570.741570 lmp.py:627]   63         | 3          |  meta           
INFO 01-06 17:11:12.741173.741173 lmp.py:627]   0          | 4          |  cuda:1         
INFO 01-06 17:11:12.741300.741300 lmp.py:627]   46         | 4          |  meta           
INFO 01-06 17:11:12.741949.741949 lmp.py:627]   3          | 5          |  cuda:1         
INFO 01-06 17:11:12.741838.741838 lmp.py:627]   27         | 5          |  cuda:1         
INFO 01-06 17:11:12.741395.741395 lmp.py:627]   52         | 5          |  cuda:1         
INFO 01-06 17:11:12.741125.741125 lmp.py:627]   44         | 6          |  cuda:1         
INFO 01-06 17:11:12.741735.741735 lmp.py:627]   54         | 6          |  cuda:1         
INFO 01-06 17:11:12.741100.741100 lmp.py:627]   55         | 7          |  meta           
INFO 01-06 17:11:12.741180.741180 lmp.py:627]   17         | 8          |  cuda:1         
INFO 01-06 17:11:12.741499.741499 lmp.py:627]   59         | 8          |  meta           
INFO 01-06 17:11:12.742579.742579 lmp.py:627]   60         | 11         |  cuda:1         
INFO 01-06 17:11:12.742183.742183 lmp.py:627]   15         | 13         |  cuda:1         
INFO 01-06 17:11:12.742786.742786 lmp.py:627]   56         | 15         |  meta           
INFO 01-06 17:11:12.742105.742105 lmp.py:627]   49         | 16         |  cuda:1         
INFO 01-06 17:11:12.742424.742424 lmp.py:627]   45         | 18         |  cuda:1         
INFO 01-06 17:11:12.742742.742742 lmp.py:628] ============================================================
INFO 01-06 17:11:12.742742.742742 lmp.py:628] 
INFO 01-06 17:11:12.742585.742585 lmp.py:630] experts_gpu_list: [4, 39, 57, 16, 23, 24, 29, 38, 41, 43, 8, 14, 22, 36, 37, 0, 3, 27, 52, 44, 54, 17, 60, 15, 49, 45] num: 26
INFO 01-06 17:11:12.742096.742096 lmp.py:631] experts_cpu_list: [10, 13, 31, 33, 35, 40, 50, 58, 9, 12, 20, 11, 34, 48, 61, 63, 46, 55, 59, 56] num: 20
INFO 01-06 17:11:12.742905.742905 lmp.py:632] expert_actual_device_map {0: 'cuda:1', 1: 'cuda:1', 2: 'cuda:1', 3: 'cuda:1', 4: 'cuda:1', 5: 'cuda:1', 6: 'cuda:1', 7: 'cuda:1', 8: 'cuda:1', 9: 'meta', 10: 'meta', 11: 'meta', 12: 'meta', 13: 'meta', 14: 'cuda:1', 15: 'cuda:1', 16: 'cuda:1', 17: 'cuda:1', 18: 'meta', 19: 'meta', 20: 'meta', 21: 'cuda:1', 22: 'cuda:1', 23: 'cuda:1', 24: 'cuda:1', 25: 'cuda:1', 26: 'meta', 27: 'cuda:1', 28: 'cuda:1', 29: 'cuda:1', 30: 'meta', 31: 'meta', 32: 'meta', 33: 'meta', 34: 'meta', 35: 'meta', 36: 'cuda:1', 37: 'cuda:1', 38: 'cuda:1', 39: 'cuda:1', 40: 'meta', 41: 'cuda:1', 42: 'meta', 43: 'cuda:1', 44: 'cuda:1', 45: 'cuda:1', 46: 'meta', 47: 'cuda:1', 48: 'meta', 49: 'cuda:1', 50: 'meta', 51: 'cuda:1', 52: 'cuda:1', 53: 'meta', 54: 'cuda:1', 55: 'meta', 56: 'meta', 57: 'cuda:1', 58: 'meta', 59: 'meta', 60: 'cuda:1', 61: 'meta', 62: 'cuda:1', 63: 'meta'}
DEBUG 01-06 17:11:12.742569.742569 cuda_h.py:19] end experts_map_get cost 0.002290964126586914 seconds
DEBUG 01-06 17:11:12.742061.742061 cuda_h.py:10] start gpu_sexperts
DEBUG 01-06 17:11:12.742928.742928 cuda_h.py:19] end gpu_sexperts cost 0.0003178119659423828 seconds
DEBUG 01-06 17:11:12.742135.742135 cuda_h.py:10] start gpu_experts
DEBUG 01-06 17:11:12.743260.743260 mlpmodule.py:533] gpu group tensors cost 0.0005161762237548828 s
DEBUG 01-06 17:11:12.744037.744037 mlpmodule.py:664]  experts func einsum cost 0.023473501205444336 s
DEBUG 01-06 17:11:12.744632.744632 mlpmodule.py:566] gpu pad cost 0.0015442371368408203 s
DEBUG 01-06 17:11:12.745860.745860 mlpmodule.py:584] gpu group einsum cost 0.00036835670471191406 s
DEBUG 01-06 17:11:12.748525.748525 mlpmodule.py:613] gpu experts func einsum cost 0.0052738189697265625 s
DEBUG 01-06 17:11:12.748409.748409 cuda_h.py:19] end gpu_experts cost 0.005403280258178711 seconds
DEBUG 01-06 17:11:12.748404.748404 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-06 17:11:12.748345.748345 lmp.py:661] 
DEBUG 01-06 17:11:12.748345.748345 lmp.py:661]   Computing 20 experts on CPU...
DEBUG 01-06 17:11:12.748241.748241 cuda_h.py:19] end cpu_experts_submit cost 6.198883056640625e-05 seconds
DEBUG 01-06 17:11:12.748037.748037 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-06 17:11:12.756143.756143 mlpmodule.py:706] group tensors cost 0.008321046829223633 s
DEBUG 01-06 17:11:12.758343.758343 mlpmodule.py:744] pad cost 0.0010519027709960938 s
DEBUG 01-06 17:11:12.758333.758333 mlpmodule.py:750] create cpu tensor cost 4.076957702636719e-05 s
DEBUG 01-06 17:11:12.758567.758567 mlpmodule.py:755] move to cpu cost 3.0994415283203125e-05 s
DEBUG 01-06 17:11:12.761482.761482 mlpmodule.py:769] group_w3: shape=torch.Size([20, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=57671680
DEBUG 01-06 17:11:12.761114.761114 mlpmodule.py:770] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-06 17:11:12.761892.761892 mlpmodule.py:775] group_w3 first element: 0.039306640625
WARNING 01-06 17:11:12.761319.761319 mlpmodule.py:785] start einsum2
DEBUG 01-06 17:11:12.766895.766895 mlpmodule.py:795] group einsum cost 0.007995367050170898 s
DEBUG 01-06 17:11:12.766400.766400 mlpmodule.py:803] cpy2cputensor cost 0.00015592575073242188 s
DEBUG 01-06 17:11:12.769489.769489 cuda_h.py:19] end wait_cetm_experts cost 0.02152729034423828 seconds
DEBUG 01-06 17:11:12.770674.770674 cuda_h.py:19] end layer_moe_dgenerate_13 cost 0.03108501434326172 seconds
DEBUG 01-06 17:11:12.770454.770454 lmp.py:325] -------------------------------- end decode layer 13 --------------------------------
DEBUG 01-06 17:11:12.770554.770554 lmp.py:298] -------------------------------- start decode layer 14 --------------------------------
DEBUG 01-06 17:11:12.770304.770304 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-06 17:11:12.770990.770990 mlpmodule.py:367] cuda:1 cuda:1
DEBUG 01-06 17:11:12.771506.771506 cuda_h.py:10] start self_attn
cos shape torch.Size([65, 128]) sin shape torch.Size([65, 128]) position_ids tensor([[0]], device='cuda:1')
cos shape torch.Size([1, 1, 1, 128]) sin shape torch.Size([1, 1, 1, 128])
q_embed shape torch.Size([32, 16, 1, 128]) k_embed shape torch.Size([32, 16, 1, 128])
DEBUG 01-06 17:11:12.772418.772418 cuda_h.py:19] end self_attn cost 0.0018718242645263672 seconds
DEBUG 01-06 17:11:12.773635.773635 cuda_h.py:19] end iln_self_attn_paln cost 0.002735137939453125 seconds
DEBUG 01-06 17:11:12.773425.773425 cuda_h.py:10] start layer_moe_dgenerate_14
DEBUG 01-06 17:11:12.773625.773625 cuda_h.py:10] start gate
DEBUG 01-06 17:11:12.774302.774302 cuda_h.py:19] end gate cost 0.0006010532379150391 seconds
DEBUG 01-06 17:11:12.774284.774284 cuda_h.py:10] start experts_map_get
INFO 01-06 17:11:12.774110.774110 lmp.py:609] using loaded check layer: True
INFO 01-06 17:11:12.775599.775599 lmp.py:620] 
INFO 01-06 17:11:12.775599.775599 lmp.py:620] Layer 14 Expert Device Distribution:
INFO 01-06 17:11:12.775123.775123 lmp.py:621]   Active experts: 49 (out of 64 total)
INFO 01-06 17:11:12.775919.775919 lmp.py:622] 
INFO 01-06 17:11:12.775919.775919 lmp.py:622]   Detailed Expert Distribution:
INFO 01-06 17:11:12.775860.775860 lmp.py:623]   Expert ID  | Tokens     | Actual Device  
INFO 01-06 17:11:12.775033.775033 lmp.py:624]   ----------------------------------------------------------------------
INFO 01-06 17:11:12.775352.775352 lmp.py:627]   11         | 1          |  cuda:1         
INFO 01-06 17:11:12.775525.775525 lmp.py:627]   13         | 1          |  cuda:1         
INFO 01-06 17:11:12.775744.775744 lmp.py:627]   19         | 1          |  meta           
INFO 01-06 17:11:12.775248.775248 lmp.py:627]   21         | 1          |  meta           
INFO 01-06 17:11:12.775706.775706 lmp.py:627]   24         | 1          |  cuda:1         
INFO 01-06 17:11:12.775686.775686 lmp.py:627]   40         | 1          |  meta           
INFO 01-06 17:11:12.775243.775243 lmp.py:627]   45         | 1          |  meta           
INFO 01-06 17:11:12.775986.775986 lmp.py:627]   57         | 1          |  cuda:1         
INFO 01-06 17:11:12.775073.775073 lmp.py:627]   59         | 1          |  meta           
INFO 01-06 17:11:12.775246.775246 lmp.py:627]   60         | 1          |  meta           
INFO 01-06 17:11:12.775750.775750 lmp.py:627]   61         | 1          |  meta           
INFO 01-06 17:11:12.775539.775539 lmp.py:627]   3          | 2          |  cuda:1         
INFO 01-06 17:11:12.775712.775712 lmp.py:627]   5          | 2          |  cuda:1         
INFO 01-06 17:11:12.775315.775315 lmp.py:627]   8          | 2          |  cuda:1         
INFO 01-06 17:11:12.775250.775250 lmp.py:627]   9          | 2          |  cuda:1         
INFO 01-06 17:11:12.775184.775184 lmp.py:627]   10         | 2          |  cuda:1         
INFO 01-06 17:11:12.775357.775357 lmp.py:627]   12         | 2          |  cuda:1         
INFO 01-06 17:11:12.775576.775576 lmp.py:627]   14         | 2          |  cuda:1         
INFO 01-06 17:11:12.775272.775272 lmp.py:627]   18         | 2          |  meta           
INFO 01-06 17:11:12.775730.775730 lmp.py:627]   27         | 2          |  meta           
INFO 01-06 17:11:12.775664.775664 lmp.py:627]   29         | 2          |  meta           
INFO 01-06 17:11:12.775361.775361 lmp.py:627]   37         | 2          |  cuda:1         
INFO 01-06 17:11:12.775388.775388 lmp.py:627]   51         | 2          |  cuda:1         
INFO 01-06 17:11:12.775653.775653 lmp.py:627]   17         | 3          |  meta           
INFO 01-06 17:11:12.775919.775919 lmp.py:627]   32         | 3          |  cuda:1         
INFO 01-06 17:11:12.775946.775946 lmp.py:627]   38         | 3          |  meta           
INFO 01-06 17:11:12.775973.775973 lmp.py:627]   43         | 3          |  cuda:1         
INFO 01-06 17:11:12.775000.775000 lmp.py:627]   54         | 3          |  meta           
INFO 01-06 17:11:12.775504.775504 lmp.py:627]   1          | 4          |  cuda:1         
INFO 01-06 17:11:12.775770.775770 lmp.py:627]   4          | 4          |  cuda:1         
INFO 01-06 17:11:12.775559.775559 lmp.py:627]   39         | 4          |  meta           
INFO 01-06 17:11:12.775586.775586 lmp.py:627]   46         | 4          |  cuda:1         
INFO 01-06 17:11:12.775613.775613 lmp.py:627]   48         | 4          |  meta           
INFO 01-06 17:11:12.775071.775071 lmp.py:627]   56         | 4          |  cuda:1         
INFO 01-06 17:11:12.775767.775767 lmp.py:627]   6          | 5          |  cuda:1         
INFO 01-06 17:11:12.775224.775224 lmp.py:627]   15         | 5          |  meta           
INFO 01-06 17:11:12.775967.775967 lmp.py:627]   30         | 5          |  cuda:1         
INFO 01-06 17:11:12.775756.775756 lmp.py:627]   42         | 5          |  cuda:1         
INFO 01-06 17:11:12.775021.775021 lmp.py:627]   44         | 5          |  cuda:1         
INFO 01-06 17:11:12.775956.775956 lmp.py:627]   28         | 7          |  cuda:1         
INFO 01-06 17:11:12.776129.776129 lmp.py:627]   31         | 7          |  meta           
INFO 01-06 17:11:12.776156.776156 lmp.py:627]   47         | 7          |  cuda:1         
INFO 01-06 17:11:12.776421.776421 lmp.py:627]   23         | 8          |  cuda:1         
INFO 01-06 17:11:12.776641.776641 lmp.py:627]   33         | 8          |  cuda:1         
INFO 01-06 17:11:12.776337.776337 lmp.py:627]   55         | 10         |  cuda:1         
INFO 01-06 17:11:12.776748.776748 lmp.py:627]   62         | 10         |  cuda:1         
INFO 01-06 17:11:12.776067.776067 lmp.py:627]   53         | 11         |  meta           
INFO 01-06 17:11:12.776955.776955 lmp.py:627]   58         | 12         |  cuda:1         
INFO 01-06 17:11:12.776082.776082 lmp.py:627]   25         | 13         |  cuda:1         
INFO 01-06 17:11:12.776254.776254 lmp.py:628] ============================================================
INFO 01-06 17:11:12.776254.776254 lmp.py:628] 
INFO 01-06 17:11:12.776342.776342 lmp.py:630] experts_gpu_list: [11, 13, 24, 57, 3, 5, 8, 9, 10, 12, 14, 37, 51, 32, 43, 1, 4, 46, 56, 6, 30, 42, 44, 28, 47, 23, 33, 55, 62, 58, 25] num: 31
INFO 01-06 17:11:12.776614.776614 lmp.py:631] experts_cpu_list: [19, 21, 40, 45, 59, 60, 61, 18, 27, 29, 17, 38, 54, 39, 48, 15, 31, 53] num: 18
INFO 01-06 17:11:12.776522.776522 lmp.py:632] expert_actual_device_map {0: 'cuda:1', 1: 'cuda:1', 2: 'cuda:1', 3: 'cuda:1', 4: 'cuda:1', 5: 'cuda:1', 6: 'cuda:1', 7: 'cuda:1', 8: 'cuda:1', 9: 'cuda:1', 10: 'cuda:1', 11: 'cuda:1', 12: 'cuda:1', 13: 'cuda:1', 14: 'cuda:1', 15: 'meta', 16: 'meta', 17: 'meta', 18: 'meta', 19: 'meta', 20: 'cuda:1', 21: 'meta', 22: 'meta', 23: 'cuda:1', 24: 'cuda:1', 25: 'cuda:1', 26: 'cuda:1', 27: 'meta', 28: 'cuda:1', 29: 'meta', 30: 'cuda:1', 31: 'meta', 32: 'cuda:1', 33: 'cuda:1', 34: 'meta', 35: 'meta', 36: 'meta', 37: 'cuda:1', 38: 'meta', 39: 'meta', 40: 'meta', 41: 'meta', 42: 'cuda:1', 43: 'cuda:1', 44: 'cuda:1', 45: 'meta', 46: 'cuda:1', 47: 'cuda:1', 48: 'meta', 49: 'meta', 50: 'meta', 51: 'cuda:1', 52: 'meta', 53: 'meta', 54: 'meta', 55: 'cuda:1', 56: 'cuda:1', 57: 'cuda:1', 58: 'cuda:1', 59: 'meta', 60: 'meta', 61: 'meta', 62: 'cuda:1', 63: 'cuda:1'}
DEBUG 01-06 17:11:12.776000.776000 cuda_h.py:19] end experts_map_get cost 0.0021805763244628906 seconds
DEBUG 01-06 17:11:12.776958.776958 cuda_h.py:10] start gpu_sexperts
DEBUG 01-06 17:11:12.776592.776592 cuda_h.py:19] end gpu_sexperts cost 0.0003178119659423828 seconds
DEBUG 01-06 17:11:12.776945.776945 cuda_h.py:10] start gpu_experts
DEBUG 01-06 17:11:12.777756.777756 mlpmodule.py:533] gpu group tensors cost 0.0005965232849121094 s
DEBUG 01-06 17:11:12.779964.779964 mlpmodule.py:664]  experts func einsum cost 0.030678749084472656 s
DEBUG 01-06 17:11:12.779519.779519 mlpmodule.py:566] gpu pad cost 0.0017616748809814453 s
DEBUG 01-06 17:11:12.779760.779760 mlpmodule.py:584] gpu group einsum cost 0.0003752708435058594 s
DEBUG 01-06 17:11:12.782868.782868 mlpmodule.py:613] gpu experts func einsum cost 0.0059435367584228516 s
DEBUG 01-06 17:11:12.782414.782414 cuda_h.py:19] end gpu_experts cost 0.006072998046875 seconds
DEBUG 01-06 17:11:12.782217.782217 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-06 17:11:12.783443.783443 lmp.py:661] 
DEBUG 01-06 17:11:12.783443.783443 lmp.py:661]   Computing 18 experts on CPU...
DEBUG 01-06 17:11:12.783763.783763 cuda_h.py:19] end cpu_experts_submit cost 5.9604644775390625e-05 seconds
DEBUG 01-06 17:11:12.783843.783843 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-06 17:11:12.787746.787746 mlpmodule.py:706] group tensors cost 0.0040645599365234375 s
DEBUG 01-06 17:11:12.788174.788174 mlpmodule.py:744] pad cost 0.0009775161743164062 s
DEBUG 01-06 17:11:12.788462.788462 mlpmodule.py:750] create cpu tensor cost 4.1961669921875e-05 s
DEBUG 01-06 17:11:12.788073.788073 mlpmodule.py:755] move to cpu cost 2.9087066650390625e-05 s
DEBUG 01-06 17:11:12.791022.791022 mlpmodule.py:769] group_w3: shape=torch.Size([18, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=51904512
DEBUG 01-06 17:11:12.791064.791064 mlpmodule.py:770] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-06 17:11:12.791615.791615 mlpmodule.py:775] group_w3 first element: 0.003143310546875
WARNING 01-06 17:11:12.791824.791824 mlpmodule.py:785] start einsum2
DEBUG 01-06 17:11:12.796874.796874 mlpmodule.py:795] group einsum cost 0.00704503059387207 s
DEBUG 01-06 17:11:12.796720.796720 mlpmodule.py:803] cpy2cputensor cost 9.965896606445312e-05 s
DEBUG 01-06 17:11:12.798973.798973 cuda_h.py:19] end wait_cetm_experts cost 0.015671491622924805 seconds
DEBUG 01-06 17:11:12.799734.799734 cuda_h.py:19] end layer_moe_dgenerate_14 cost 0.025820255279541016 seconds
DEBUG 01-06 17:11:12.799627.799627 lmp.py:325] -------------------------------- end decode layer 14 --------------------------------
DEBUG 01-06 17:11:12.799728.799728 lmp.py:298] -------------------------------- start decode layer 15 --------------------------------
DEBUG 01-06 17:11:12.799239.799239 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-06 17:11:12.799110.799110 mlpmodule.py:367] cuda:1 cuda:1
DEBUG 01-06 17:11:12.799652.799652 cuda_h.py:10] start self_attn
cos shape torch.Size([65, 128]) sin shape torch.Size([65, 128]) position_ids tensor([[0]], device='cuda:1')
cos shape torch.Size([1, 1, 1, 128]) sin shape torch.Size([1, 1, 1, 128])
q_embed shape torch.Size([32, 16, 1, 128]) k_embed shape torch.Size([32, 16, 1, 128])
DEBUG 01-06 17:11:12.801499.801499 cuda_h.py:19] end self_attn cost 0.0018954277038574219 seconds
DEBUG 01-06 17:11:12.802544.802544 cuda_h.py:19] end iln_self_attn_paln cost 0.0027513504028320312 seconds
DEBUG 01-06 17:11:12.802434.802434 cuda_h.py:10] start layer_moe_dgenerate_15
DEBUG 01-06 17:11:12.802442.802442 cuda_h.py:10] start gate
DEBUG 01-06 17:11:12.803510.803510 cuda_h.py:19] end gate cost 0.0006072521209716797 seconds
DEBUG 01-06 17:11:12.803253.803253 cuda_h.py:10] start experts_map_get
INFO 01-06 17:11:12.803337.803337 lmp.py:609] using loaded check layer: True
INFO 01-06 17:11:12.803264.803264 lmp.py:620] 
INFO 01-06 17:11:12.803264.803264 lmp.py:620] Layer 15 Expert Device Distribution:
INFO 01-06 17:11:12.804795.804795 lmp.py:621]   Active experts: 52 (out of 64 total)
INFO 01-06 17:11:12.804213.804213 lmp.py:622] 
INFO 01-06 17:11:12.804213.804213 lmp.py:622]   Detailed Expert Distribution:
INFO 01-06 17:11:12.804321.804321 lmp.py:623]   Expert ID  | Tokens     | Actual Device  
INFO 01-06 17:11:12.804593.804593 lmp.py:624]   ----------------------------------------------------------------------
INFO 01-06 17:11:12.804389.804389 lmp.py:627]   0          | 1          |  cuda:1         
INFO 01-06 17:11:12.804469.804469 lmp.py:627]   1          | 1          |  cuda:1         
INFO 01-06 17:11:12.804072.804072 lmp.py:627]   7          | 1          |  cuda:1         
INFO 01-06 17:11:12.804676.804676 lmp.py:627]   11         | 1          |  cuda:1         
INFO 01-06 17:11:12.804756.804756 lmp.py:627]   21         | 1          |  meta           
INFO 01-06 17:11:12.804075.804075 lmp.py:627]   22         | 1          |  meta           
INFO 01-06 17:11:12.804632.804632 lmp.py:627]   25         | 1          |  meta           
INFO 01-06 17:11:12.804997.804997 lmp.py:627]   39         | 1          |  cuda:1         
INFO 01-06 17:11:12.804362.804362 lmp.py:627]   44         | 1          |  cuda:1         
INFO 01-06 17:11:12.804250.804250 lmp.py:627]   52         | 1          |  meta           
INFO 01-06 17:11:12.804735.804735 lmp.py:627]   55         | 1          |  meta           
INFO 01-06 17:11:12.804054.804054 lmp.py:627]   56         | 1          |  cuda:1         
INFO 01-06 17:11:12.804134.804134 lmp.py:627]   63         | 1          |  meta           
INFO 01-06 17:11:12.804691.804691 lmp.py:627]   2          | 2          |  cuda:1         
INFO 01-06 17:11:12.804056.804056 lmp.py:627]   3          | 2          |  cuda:1         
INFO 01-06 17:11:12.804183.804183 lmp.py:627]   6          | 2          |  cuda:1         
INFO 01-06 17:11:12.804309.804309 lmp.py:627]   15         | 2          |  meta           
INFO 01-06 17:11:12.804959.804959 lmp.py:627]   19         | 2          |  meta           
INFO 01-06 17:11:12.804086.804086 lmp.py:627]   20         | 2          |  meta           
INFO 01-06 17:11:12.804212.804212 lmp.py:627]   27         | 2          |  cuda:1         
INFO 01-06 17:11:12.804862.804862 lmp.py:627]   34         | 2          |  meta           
INFO 01-06 17:11:12.804704.804704 lmp.py:627]   38         | 2          |  cuda:1         
INFO 01-06 17:11:12.804784.804784 lmp.py:627]   51         | 2          |  meta           
INFO 01-06 17:11:12.804341.804341 lmp.py:627]   54         | 2          |  meta           
INFO 01-06 17:11:12.804468.804468 lmp.py:627]   57         | 2          |  cuda:1         
INFO 01-06 17:11:12.804595.804595 lmp.py:627]   59         | 2          |  meta           
INFO 01-06 17:11:12.804721.804721 lmp.py:627]   9          | 3          |  cuda:1         
INFO 01-06 17:11:12.804371.804371 lmp.py:627]   24         | 3          |  cuda:1         
INFO 01-06 17:11:12.804021.804021 lmp.py:627]   32         | 3          |  meta           
INFO 01-06 17:11:12.804147.804147 lmp.py:627]   37         | 3          |  cuda:1         
INFO 01-06 17:11:12.804751.804751 lmp.py:627]   45         | 3          |  meta           
INFO 01-06 17:11:12.804354.804354 lmp.py:627]   48         | 3          |  cuda:1         
INFO 01-06 17:11:12.804481.804481 lmp.py:627]   4          | 4          |  cuda:1         
INFO 01-06 17:11:12.804846.804846 lmp.py:627]   5          | 4          |  cuda:1         
INFO 01-06 17:11:12.804257.804257 lmp.py:627]   29         | 4          |  cuda:1         
INFO 01-06 17:11:12.804907.804907 lmp.py:627]   36         | 4          |  cuda:1         
INFO 01-06 17:11:12.805080.805080 lmp.py:627]   60         | 4          |  cuda:1         
INFO 01-06 17:11:12.805160.805160 lmp.py:627]   8          | 5          |  cuda:1         
INFO 01-06 17:11:12.805048.805048 lmp.py:627]   16         | 5          |  cuda:1         
INFO 01-06 17:11:12.805129.805129 lmp.py:627]   17         | 5          |  cuda:1         
INFO 01-06 17:11:12.805970.805970 lmp.py:627]   31         | 5          |  cuda:1         
INFO 01-06 17:11:12.805335.805335 lmp.py:627]   62         | 5          |  meta           
INFO 01-06 17:11:12.805462.805462 lmp.py:627]   23         | 6          |  cuda:1         
INFO 01-06 17:11:12.805065.805065 lmp.py:627]   28         | 6          |  meta           
INFO 01-06 17:11:12.805715.805715 lmp.py:627]   40         | 6          |  meta           
INFO 01-06 17:11:12.805842.805842 lmp.py:627]   26         | 8          |  cuda:1         
INFO 01-06 17:11:12.805730.805730 lmp.py:627]   10         | 10         |  meta           
INFO 01-06 17:11:12.805572.805572 lmp.py:627]   43         | 10         |  cuda:1         
INFO 01-06 17:11:12.805937.805937 lmp.py:627]   47         | 10         |  cuda:1         
INFO 01-06 17:11:12.805540.805540 lmp.py:627]   58         | 10         |  cuda:1         
INFO 01-06 17:11:12.805144.805144 lmp.py:627]   33         | 12         |  cuda:1         
INFO 01-06 17:11:12.805794.805794 lmp.py:627]   49         | 12         |  cuda:1         
INFO 01-06 17:11:12.805966.805966 lmp.py:628] ============================================================
INFO 01-06 17:11:12.805966.805966 lmp.py:628] 
INFO 01-06 17:11:12.805623.805623 lmp.py:630] experts_gpu_list: [0, 1, 7, 11, 39, 44, 56, 2, 3, 6, 27, 38, 57, 9, 24, 37, 48, 4, 5, 29, 36, 60, 8, 16, 17, 31, 23, 26, 43, 47, 58, 33, 49] num: 33
INFO 01-06 17:11:12.805895.805895 lmp.py:631] experts_cpu_list: [21, 22, 25, 52, 55, 63, 15, 19, 20, 34, 51, 54, 59, 32, 45, 62, 28, 40, 10] num: 19
INFO 01-06 17:11:12.805658.805658 lmp.py:632] expert_actual_device_map {0: 'cuda:1', 1: 'cuda:1', 2: 'cuda:1', 3: 'cuda:1', 4: 'cuda:1', 5: 'cuda:1', 6: 'cuda:1', 7: 'cuda:1', 8: 'cuda:1', 9: 'cuda:1', 10: 'meta', 11: 'cuda:1', 12: 'meta', 13: 'meta', 14: 'meta', 15: 'meta', 16: 'cuda:1', 17: 'cuda:1', 18: 'cuda:1', 19: 'meta', 20: 'meta', 21: 'meta', 22: 'meta', 23: 'cuda:1', 24: 'cuda:1', 25: 'meta', 26: 'cuda:1', 27: 'cuda:1', 28: 'meta', 29: 'cuda:1', 30: 'cuda:1', 31: 'cuda:1', 32: 'meta', 33: 'cuda:1', 34: 'meta', 35: 'cuda:1', 36: 'cuda:1', 37: 'cuda:1', 38: 'cuda:1', 39: 'cuda:1', 40: 'meta', 41: 'meta', 42: 'meta', 43: 'cuda:1', 44: 'cuda:1', 45: 'meta', 46: 'cuda:1', 47: 'cuda:1', 48: 'cuda:1', 49: 'cuda:1', 50: 'meta', 51: 'meta', 52: 'meta', 53: 'meta', 54: 'meta', 55: 'meta', 56: 'cuda:1', 57: 'cuda:1', 58: 'cuda:1', 59: 'meta', 60: 'cuda:1', 61: 'meta', 62: 'meta', 63: 'meta'}
DEBUG 01-06 17:11:12.805328.805328 cuda_h.py:19] end experts_map_get cost 0.0024080276489257812 seconds
DEBUG 01-06 17:11:12.805272.805272 mlpmodule.py:664]  experts func einsum cost 0.022372961044311523 s
DEBUG 01-06 17:11:12.805701.805701 cuda_h.py:10] start gpu_sexperts
DEBUG 01-06 17:11:12.806782.806782 cuda_h.py:19] end gpu_sexperts cost 0.0003390312194824219 seconds
DEBUG 01-06 17:11:12.806095.806095 cuda_h.py:10] start gpu_experts
DEBUG 01-06 17:11:12.806939.806939 mlpmodule.py:533] gpu group tensors cost 0.0006175041198730469 s
DEBUG 01-06 17:11:12.808119.808119 mlpmodule.py:566] gpu pad cost 0.0017685890197753906 s
DEBUG 01-06 17:11:12.809876.809876 mlpmodule.py:584] gpu group einsum cost 0.0003750324249267578 s
DEBUG 01-06 17:11:12.812049.812049 mlpmodule.py:613] gpu experts func einsum cost 0.006058216094970703 s
DEBUG 01-06 17:11:12.812046.812046 cuda_h.py:19] end gpu_experts cost 0.00621795654296875 seconds
DEBUG 01-06 17:11:12.812087.812087 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-06 17:11:12.812789.812789 lmp.py:661] 
DEBUG 01-06 17:11:12.812789.812789 lmp.py:661]   Computing 19 experts on CPU...
DEBUG 01-06 17:11:12.812434.812434 cuda_h.py:19] end cpu_experts_submit cost 5.316734313964844e-05 seconds
DEBUG 01-06 17:11:12.812752.812752 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-06 17:11:12.816550.816550 mlpmodule.py:706] group tensors cost 0.004071235656738281 s
DEBUG 01-06 17:11:12.818343.818343 mlpmodule.py:744] pad cost 0.0009989738464355469 s
DEBUG 01-06 17:11:12.818194.818194 mlpmodule.py:750] create cpu tensor cost 4.0531158447265625e-05 s
DEBUG 01-06 17:11:12.818521.818521 mlpmodule.py:755] move to cpu cost 2.9802322387695312e-05 s
DEBUG 01-06 17:11:12.821559.821559 mlpmodule.py:769] group_w3: shape=torch.Size([19, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=54788096
DEBUG 01-06 17:11:12.821733.821733 mlpmodule.py:770] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-06 17:11:12.821808.821808 mlpmodule.py:775] group_w3 first element: 0.01129150390625
WARNING 01-06 17:11:12.821493.821493 mlpmodule.py:785] start einsum2
DEBUG 01-06 17:11:12.825284.825284 mlpmodule.py:795] group einsum cost 0.007122993469238281 s
DEBUG 01-06 17:11:12.825130.825130 mlpmodule.py:803] cpy2cputensor cost 0.00010275840759277344 s
DEBUG 01-06 17:11:12.828127.828127 cuda_h.py:19] end wait_cetm_experts cost 0.015851974487304688 seconds
DEBUG 01-06 17:11:12.828610.828610 cuda_h.py:19] end layer_moe_dgenerate_15 cost 0.026599645614624023 seconds
DEBUG 01-06 17:11:12.829987.829987 lmp.py:325] -------------------------------- end decode layer 15 --------------------------------
DEBUG 01-06 17:11:12.829180.829180 lmp.py:298] -------------------------------- start decode layer 16 --------------------------------
DEBUG 01-06 17:11:12.829598.829598 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-06 17:11:12.829013.829013 mlpmodule.py:367] cuda:1 cuda:1
DEBUG 01-06 17:11:12.829284.829284 cuda_h.py:10] start self_attn
cos shape torch.Size([65, 128]) sin shape torch.Size([65, 128]) position_ids tensor([[0]], device='cuda:1')
cos shape torch.Size([1, 1, 1, 128]) sin shape torch.Size([1, 1, 1, 128])
q_embed shape torch.Size([32, 16, 1, 128]) k_embed shape torch.Size([32, 16, 1, 128])
DEBUG 01-06 17:11:12.831838.831838 cuda_h.py:19] end self_attn cost 0.0018563270568847656 seconds
DEBUG 01-06 17:11:12.831109.831109 cuda_h.py:19] end iln_self_attn_paln cost 0.002753019332885742 seconds
DEBUG 01-06 17:11:12.832661.832661 cuda_h.py:10] start layer_moe_dgenerate_16
DEBUG 01-06 17:11:12.832576.832576 cuda_h.py:10] start gate
DEBUG 01-06 17:11:12.832917.832917 cuda_h.py:19] end gate cost 0.0006325244903564453 seconds
DEBUG 01-06 17:11:12.832945.832945 cuda_h.py:10] start experts_map_get
INFO 01-06 17:11:12.833738.833738 lmp.py:609] using loaded check layer: True
INFO 01-06 17:11:12.833704.833704 lmp.py:620] 
INFO 01-06 17:11:12.833704.833704 lmp.py:620] Layer 16 Expert Device Distribution:
INFO 01-06 17:11:12.833089.833089 lmp.py:621]   Active experts: 52 (out of 64 total)
INFO 01-06 17:11:12.833984.833984 lmp.py:622] 
INFO 01-06 17:11:12.833984.833984 lmp.py:622]   Detailed Expert Distribution:
INFO 01-06 17:11:12.833879.833879 lmp.py:623]   Expert ID  | Tokens     | Actual Device  
INFO 01-06 17:11:12.833436.833436 lmp.py:624]   ----------------------------------------------------------------------
INFO 01-06 17:11:12.833232.833232 lmp.py:627]   0          | 1          |  cuda:1         
INFO 01-06 17:11:12.833551.833551 lmp.py:627]   3          | 1          |  cuda:1         
INFO 01-06 17:11:12.833439.833439 lmp.py:627]   5          | 1          |  cuda:1         
INFO 01-06 17:11:12.833327.833327 lmp.py:627]   10         | 1          |  meta           
INFO 01-06 17:11:12.833692.833692 lmp.py:627]   14         | 1          |  meta           
INFO 01-06 17:11:12.833057.833057 lmp.py:627]   28         | 1          |  meta           
INFO 01-06 17:11:12.834899.834899 lmp.py:627]   29         | 1          |  cuda:1         
INFO 01-06 17:11:12.834741.834741 lmp.py:627]   38         | 1          |  meta           
INFO 01-06 17:11:12.834344.834344 lmp.py:627]   41         | 1          |  meta           
INFO 01-06 17:11:12.834140.834140 lmp.py:627]   42         | 1          |  cuda:1         
INFO 01-06 17:11:12.834028.834028 lmp.py:627]   45         | 1          |  meta           
INFO 01-06 17:11:12.834393.834393 lmp.py:627]   47         | 1          |  meta           
INFO 01-06 17:11:12.834043.834043 lmp.py:627]   56         | 1          |  meta           
INFO 01-06 17:11:12.834408.834408 lmp.py:627]   1          | 2          |  cuda:1         
INFO 01-06 17:11:12.834057.834057 lmp.py:627]   4          | 2          |  cuda:1         
INFO 01-06 17:11:12.834707.834707 lmp.py:627]   11         | 2          |  meta           
INFO 01-06 17:11:12.834311.834311 lmp.py:627]   16         | 2          |  cuda:1         
INFO 01-06 17:11:12.834914.834914 lmp.py:627]   18         | 2          |  cuda:1         
INFO 01-06 17:11:12.834756.834756 lmp.py:627]   23         | 2          |  cuda:1         
INFO 01-06 17:11:12.834121.834121 lmp.py:627]   26         | 2          |  meta           
INFO 01-06 17:11:12.834486.834486 lmp.py:627]   33         | 2          |  meta           
INFO 01-06 17:11:12.834613.834613 lmp.py:627]   43         | 2          |  meta           
INFO 01-06 17:11:12.834262.834262 lmp.py:627]   50         | 2          |  meta           
INFO 01-06 17:11:12.834866.834866 lmp.py:627]   51         | 2          |  meta           
INFO 01-06 17:11:12.834231.834231 lmp.py:627]   60         | 2          |  cuda:1         
INFO 01-06 17:11:12.834596.834596 lmp.py:627]   63         | 2          |  cuda:1         
INFO 01-06 17:11:12.834438.834438 lmp.py:627]   2          | 3          |  cuda:1         
INFO 01-06 17:11:12.834564.834564 lmp.py:627]   8          | 3          |  cuda:1         
INFO 01-06 17:11:12.834452.834452 lmp.py:627]   9          | 3          |  cuda:1         
INFO 01-06 17:11:12.834579.834579 lmp.py:627]   12         | 3          |  cuda:1         
INFO 01-06 17:11:12.834706.834706 lmp.py:627]   13         | 3          |  meta           
INFO 01-06 17:11:12.834071.834071 lmp.py:627]   22         | 3          |  cuda:1         
INFO 01-06 17:11:12.834720.834720 lmp.py:627]   39         | 3          |  cuda:1         
INFO 01-06 17:11:12.834324.834324 lmp.py:627]   46         | 3          |  cuda:1         
INFO 01-06 17:11:12.834166.834166 lmp.py:627]   17         | 4          |  cuda:1         
INFO 01-06 17:11:12.834008.834008 lmp.py:627]   24         | 4          |  meta           
INFO 01-06 17:11:12.834373.834373 lmp.py:627]   40         | 4          |  cuda:1         
INFO 01-06 17:11:12.834499.834499 lmp.py:627]   61         | 4          |  meta           
INFO 01-06 17:11:12.834103.834103 lmp.py:627]   32         | 5          |  cuda:1         
INFO 01-06 17:11:12.834991.834991 lmp.py:627]   35         | 5          |  cuda:1         
INFO 01-06 17:11:12.834117.834117 lmp.py:627]   48         | 5          |  meta           
INFO 01-06 17:11:12.834436.834436 lmp.py:627]   54         | 5          |  meta           
INFO 01-06 17:11:12.834040.834040 lmp.py:627]   59         | 6          |  cuda:1         
INFO 01-06 17:11:12.834120.834120 lmp.py:627]   6          | 7          |  cuda:1         
INFO 01-06 17:11:12.834962.834962 lmp.py:627]   44         | 7          |  cuda:1         
INFO 01-06 17:11:12.834612.834612 lmp.py:627]   53         | 7          |  cuda:1         
INFO 01-06 17:11:12.834977.834977 lmp.py:627]   15         | 10         |  cuda:1         
INFO 01-06 17:11:12.834342.834342 lmp.py:627]   52         | 10         |  cuda:1         
INFO 01-06 17:11:12.835230.835230 lmp.py:627]   62         | 10         |  cuda:1         
INFO 01-06 17:11:12.835118.835118 lmp.py:627]   7          | 12         |  cuda:1         
INFO 01-06 17:11:12.835960.835960 lmp.py:627]   20         | 12         |  cuda:1         
INFO 01-06 17:11:12.835563.835563 lmp.py:627]   36         | 12         |  cuda:1         
INFO 01-06 17:11:12.835690.835690 lmp.py:628] ============================================================
INFO 01-06 17:11:12.835690.835690 lmp.py:628] 
INFO 01-06 17:11:12.835731.835731 lmp.py:630] experts_gpu_list: [0, 3, 5, 29, 42, 1, 4, 16, 18, 23, 60, 63, 2, 8, 9, 12, 22, 39, 46, 17, 40, 32, 35, 59, 6, 44, 53, 15, 52, 62, 7, 20, 36] num: 33
INFO 01-06 17:11:12.835003.835003 lmp.py:631] experts_cpu_list: [10, 14, 28, 38, 41, 45, 47, 56, 11, 26, 33, 43, 50, 51, 13, 24, 61, 48, 54] num: 19
INFO 01-06 17:11:12.835196.835196 lmp.py:632] expert_actual_device_map {0: 'cuda:1', 1: 'cuda:1', 2: 'cuda:1', 3: 'cuda:1', 4: 'cuda:1', 5: 'cuda:1', 6: 'cuda:1', 7: 'cuda:1', 8: 'cuda:1', 9: 'cuda:1', 10: 'meta', 11: 'meta', 12: 'cuda:1', 13: 'meta', 14: 'meta', 15: 'cuda:1', 16: 'cuda:1', 17: 'cuda:1', 18: 'cuda:1', 19: 'cuda:1', 20: 'cuda:1', 21: 'cuda:1', 22: 'cuda:1', 23: 'cuda:1', 24: 'meta', 25: 'meta', 26: 'meta', 27: 'meta', 28: 'meta', 29: 'cuda:1', 30: 'cuda:1', 31: 'meta', 32: 'cuda:1', 33: 'meta', 34: 'meta', 35: 'cuda:1', 36: 'cuda:1', 37: 'cuda:1', 38: 'meta', 39: 'cuda:1', 40: 'cuda:1', 41: 'meta', 42: 'cuda:1', 43: 'meta', 44: 'cuda:1', 45: 'meta', 46: 'cuda:1', 47: 'meta', 48: 'meta', 49: 'meta', 50: 'meta', 51: 'meta', 52: 'cuda:1', 53: 'cuda:1', 54: 'meta', 55: 'meta', 56: 'meta', 57: 'meta', 58: 'meta', 59: 'cuda:1', 60: 'cuda:1', 61: 'meta', 62: 'cuda:1', 63: 'cuda:1'}
DEBUG 01-06 17:11:12.835005.835005 cuda_h.py:19] end experts_map_get cost 0.0023627281188964844 seconds
DEBUG 01-06 17:11:12.835213.835213 mlpmodule.py:664]  experts func einsum cost 0.022522926330566406 s
DEBUG 01-06 17:11:12.835078.835078 cuda_h.py:10] start gpu_sexperts
DEBUG 01-06 17:11:12.835444.835444 cuda_h.py:19] end gpu_sexperts cost 0.0003376007080078125 seconds
DEBUG 01-06 17:11:12.835141.835141 cuda_h.py:10] start gpu_experts
DEBUG 01-06 17:11:12.836451.836451 mlpmodule.py:533] gpu group tensors cost 0.0006771087646484375 s
DEBUG 01-06 17:11:12.838165.838165 mlpmodule.py:566] gpu pad cost 0.001668691635131836 s
DEBUG 01-06 17:11:12.838828.838828 mlpmodule.py:584] gpu group einsum cost 0.0003619194030761719 s
DEBUG 01-06 17:11:12.842391.842391 mlpmodule.py:613] gpu experts func einsum cost 0.006002902984619141 s
DEBUG 01-06 17:11:12.842474.842474 cuda_h.py:19] end gpu_experts cost 0.006148338317871094 seconds
DEBUG 01-06 17:11:12.842846.842846 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-06 17:11:12.842595.842595 lmp.py:661] 
DEBUG 01-06 17:11:12.842595.842595 lmp.py:661]   Computing 19 experts on CPU...
DEBUG 01-06 17:11:12.842438.842438 cuda_h.py:19] end cpu_experts_submit cost 5.459785461425781e-05 seconds
DEBUG 01-06 17:11:12.842518.842518 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-06 17:11:12.850225.850225 mlpmodule.py:706] group tensors cost 0.008249044418334961 s
DEBUG 01-06 17:11:12.852815.852815 mlpmodule.py:744] pad cost 0.0009713172912597656 s
DEBUG 01-06 17:11:12.852826.852826 mlpmodule.py:750] create cpu tensor cost 3.981590270996094e-05 s
DEBUG 01-06 17:11:12.852451.852451 mlpmodule.py:755] move to cpu cost 3.1948089599609375e-05 s
DEBUG 01-06 17:11:12.854523.854523 mlpmodule.py:769] group_w3: shape=torch.Size([19, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=54788096
DEBUG 01-06 17:11:12.854935.854935 mlpmodule.py:770] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-06 17:11:12.854149.854149 mlpmodule.py:775] group_w3 first element: -0.09130859375
WARNING 01-06 17:11:12.854927.854927 mlpmodule.py:785] start einsum2
DEBUG 01-06 17:11:12.858459.858459 mlpmodule.py:795] group einsum cost 0.006145000457763672 s
DEBUG 01-06 17:11:12.858822.858822 mlpmodule.py:803] cpy2cputensor cost 0.00010156631469726562 s
DEBUG 01-06 17:11:12.861407.861407 cuda_h.py:19] end wait_cetm_experts cost 0.01914191246032715 seconds
DEBUG 01-06 17:11:12.861971.861971 cuda_h.py:19] end layer_moe_dgenerate_16 cost 0.02978229522705078 seconds
DEBUG 01-06 17:11:12.862772.862772 lmp.py:325] -------------------------------- end decode layer 16 --------------------------------
DEBUG 01-06 17:11:12.862840.862840 lmp.py:298] -------------------------------- start decode layer 17 --------------------------------
DEBUG 01-06 17:11:12.862272.862272 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-06 17:11:12.862694.862694 mlpmodule.py:367] cuda:1 cuda:1
DEBUG 01-06 17:11:12.862782.862782 cuda_h.py:10] start self_attn
cos shape torch.Size([65, 128]) sin shape torch.Size([65, 128]) position_ids tensor([[0]], device='cuda:1')
cos shape torch.Size([1, 1, 1, 128]) sin shape torch.Size([1, 1, 1, 128])
q_embed shape torch.Size([32, 16, 1, 128]) k_embed shape torch.Size([32, 16, 1, 128])
DEBUG 01-06 17:11:12.865003.865003 cuda_h.py:19] end self_attn cost 0.0023627281188964844 seconds
DEBUG 01-06 17:11:12.865818.865818 cuda_h.py:19] end iln_self_attn_paln cost 0.003409862518310547 seconds
DEBUG 01-06 17:11:12.865529.865529 cuda_h.py:10] start layer_moe_dgenerate_17
DEBUG 01-06 17:11:12.865319.865319 cuda_h.py:10] start gate
DEBUG 01-06 17:11:12.866146.866146 mlpmodule.py:664]  experts func einsum cost 0.023707151412963867 s
DEBUG 01-06 17:11:12.866487.866487 cuda_h.py:19] end gate cost 0.0007894039154052734 seconds
DEBUG 01-06 17:11:12.866458.866458 cuda_h.py:10] start experts_map_get
INFO 01-06 17:11:12.867366.867366 lmp.py:609] using loaded check layer: True
INFO 01-06 17:11:12.867413.867413 lmp.py:620] 
INFO 01-06 17:11:12.867413.867413 lmp.py:620] Layer 17 Expert Device Distribution:
INFO 01-06 17:11:12.867891.867891 lmp.py:621]   Active experts: 48 (out of 64 total)
INFO 01-06 17:11:12.867971.867971 lmp.py:622] 
INFO 01-06 17:11:12.867971.867971 lmp.py:622]   Detailed Expert Distribution:
INFO 01-06 17:11:12.867151.867151 lmp.py:623]   Expert ID  | Tokens     | Actual Device  
INFO 01-06 17:11:12.867608.867608 lmp.py:624]   ----------------------------------------------------------------------
INFO 01-06 17:11:12.867212.867212 lmp.py:627]   0          | 1          |  cuda:1         
INFO 01-06 17:11:12.867669.867669 lmp.py:627]   7          | 1          |  cuda:1         
INFO 01-06 17:11:12.867650.867650 lmp.py:627]   20         | 1          |  cuda:1         
INFO 01-06 17:11:12.867393.867393 lmp.py:627]   22         | 1          |  cuda:1         
INFO 01-06 17:11:12.867135.867135 lmp.py:627]   38         | 1          |  meta           
INFO 01-06 17:11:12.867877.867877 lmp.py:627]   42         | 1          |  cuda:1         
INFO 01-06 17:11:12.868858.868858 lmp.py:627]   48         | 1          |  cuda:1         
INFO 01-06 17:11:12.868124.868124 lmp.py:627]   49         | 1          |  meta           
INFO 01-06 17:11:12.868866.868866 lmp.py:627]   50         | 1          |  meta           
INFO 01-06 17:11:12.868562.868562 lmp.py:627]   52         | 1          |  meta           
INFO 01-06 17:11:12.868258.868258 lmp.py:627]   53         | 1          |  meta           
INFO 01-06 17:11:12.868955.868955 lmp.py:627]   54         | 1          |  cuda:1         
INFO 01-06 17:11:12.868651.868651 lmp.py:627]   56         | 1          |  cuda:1         
INFO 01-06 17:11:12.868155.868155 lmp.py:627]   59         | 1          |  meta           
INFO 01-06 17:11:12.868182.868182 lmp.py:627]   60         | 1          |  meta           
INFO 01-06 17:11:12.868447.868447 lmp.py:627]   10         | 2          |  meta           
INFO 01-06 17:11:12.868951.868951 lmp.py:627]   11         | 2          |  cuda:1         
INFO 01-06 17:11:12.868979.868979 lmp.py:627]   13         | 2          |  cuda:1         
INFO 01-06 17:11:12.868006.868006 lmp.py:627]   25         | 2          |  meta           
INFO 01-06 17:11:12.868225.868225 lmp.py:627]   40         | 2          |  meta           
INFO 01-06 17:11:12.868683.868683 lmp.py:627]   57         | 2          |  cuda:1         
INFO 01-06 17:11:12.868902.868902 lmp.py:627]   58         | 2          |  meta           
INFO 01-06 17:11:12.868121.868121 lmp.py:627]   3          | 3          |  cuda:1         
INFO 01-06 17:11:12.868387.868387 lmp.py:627]   5          | 3          |  cuda:1         
INFO 01-06 17:11:12.868434.868434 lmp.py:627]   6          | 3          |  cuda:1         
INFO 01-06 17:11:12.868177.868177 lmp.py:627]   15         | 3          |  meta           
INFO 01-06 17:11:12.868442.868442 lmp.py:627]   19         | 3          |  cuda:1         
INFO 01-06 17:11:12.868231.868231 lmp.py:627]   30         | 3          |  meta           
INFO 01-06 17:11:12.868497.868497 lmp.py:627]   44         | 3          |  cuda:1         
INFO 01-06 17:11:12.868716.868716 lmp.py:627]   61         | 3          |  meta           
INFO 01-06 17:11:12.868697.868697 lmp.py:627]   4          | 4          |  cuda:1         
INFO 01-06 17:11:12.868916.868916 lmp.py:627]   17         | 4          |  cuda:1         
INFO 01-06 17:11:12.868420.868420 lmp.py:627]   24         | 4          |  meta           
INFO 01-06 17:11:12.868209.868209 lmp.py:627]   26         | 4          |  cuda:1         
INFO 01-06 17:11:12.868713.868713 lmp.py:627]   29         | 4          |  cuda:1         
INFO 01-06 17:11:12.868978.868978 lmp.py:627]   31         | 4          |  meta           
INFO 01-06 17:11:12.868244.868244 lmp.py:627]   14         | 5          |  cuda:1         
INFO 01-06 17:11:12.868748.868748 lmp.py:627]   21         | 6          |  cuda:1         
INFO 01-06 17:11:12.868775.868775 lmp.py:627]   34         | 6          |  cuda:1         
INFO 01-06 17:11:12.868564.868564 lmp.py:627]   35         | 6          |  cuda:1         
INFO 01-06 17:11:12.868498.868498 lmp.py:627]   45         | 6          |  cuda:1         
INFO 01-06 17:11:12.868717.868717 lmp.py:627]   1          | 7          |  cuda:1         
INFO 01-06 17:11:12.868937.868937 lmp.py:627]   9          | 8          |  cuda:1         
INFO 01-06 17:11:12.868394.868394 lmp.py:627]   32         | 10         |  meta           
INFO 01-06 17:11:12.868660.868660 lmp.py:627]   51         | 13         |  cuda:1         
INFO 01-06 17:11:12.868687.868687 lmp.py:627]   23         | 15         |  cuda:1         
INFO 01-06 17:11:12.868476.868476 lmp.py:627]   63         | 16         |  cuda:1         
INFO 01-06 17:11:12.868503.868503 lmp.py:627]   62         | 17         |  cuda:1         
INFO 01-06 17:11:12.868292.868292 lmp.py:628] ============================================================
INFO 01-06 17:11:12.868292.868292 lmp.py:628] 
INFO 01-06 17:11:12.868564.868564 lmp.py:630] experts_gpu_list: [0, 7, 20, 22, 42, 48, 54, 56, 11, 13, 57, 3, 5, 6, 19, 44, 4, 17, 26, 29, 14, 21, 34, 35, 45, 1, 9, 51, 23, 63, 62] num: 31
INFO 01-06 17:11:12.868214.868214 lmp.py:631] experts_cpu_list: [38, 49, 50, 52, 53, 59, 60, 10, 25, 40, 58, 15, 30, 61, 24, 31, 32] num: 17
INFO 01-06 17:11:12.868261.868261 lmp.py:632] expert_actual_device_map {0: 'cuda:1', 1: 'cuda:1', 2: 'cuda:1', 3: 'cuda:1', 4: 'cuda:1', 5: 'cuda:1', 6: 'cuda:1', 7: 'cuda:1', 8: 'meta', 9: 'cuda:1', 10: 'meta', 11: 'cuda:1', 12: 'meta', 13: 'cuda:1', 14: 'cuda:1', 15: 'meta', 16: 'cuda:1', 17: 'cuda:1', 18: 'cuda:1', 19: 'cuda:1', 20: 'cuda:1', 21: 'cuda:1', 22: 'cuda:1', 23: 'cuda:1', 24: 'meta', 25: 'meta', 26: 'cuda:1', 27: 'meta', 28: 'meta', 29: 'cuda:1', 30: 'meta', 31: 'meta', 32: 'meta', 33: 'meta', 34: 'cuda:1', 35: 'cuda:1', 36: 'meta', 37: 'meta', 38: 'meta', 39: 'meta', 40: 'meta', 41: 'cuda:1', 42: 'cuda:1', 43: 'meta', 44: 'cuda:1', 45: 'cuda:1', 46: 'cuda:1', 47: 'meta', 48: 'cuda:1', 49: 'meta', 50: 'meta', 51: 'cuda:1', 52: 'meta', 53: 'meta', 54: 'cuda:1', 55: 'cuda:1', 56: 'cuda:1', 57: 'cuda:1', 58: 'meta', 59: 'meta', 60: 'meta', 61: 'meta', 62: 'cuda:1', 63: 'cuda:1'}
DEBUG 01-06 17:11:12.869117.869117 cuda_h.py:19] end experts_map_get cost 0.0022325515747070312 seconds
DEBUG 01-06 17:11:12.869894.869894 cuda_h.py:10] start gpu_sexperts
DEBUG 01-06 17:11:12.869184.869184 cuda_h.py:19] end gpu_sexperts cost 0.0003151893615722656 seconds
DEBUG 01-06 17:11:12.869683.869683 cuda_h.py:10] start gpu_experts
DEBUG 01-06 17:11:12.870572.870572 mlpmodule.py:533] gpu group tensors cost 0.0005824565887451172 s
DEBUG 01-06 17:11:12.871978.871978 mlpmodule.py:566] gpu pad cost 0.0015854835510253906 s
DEBUG 01-06 17:11:12.872010.872010 mlpmodule.py:584] gpu group einsum cost 0.00048804283142089844 s
DEBUG 01-06 17:11:12.875572.875572 mlpmodule.py:613] gpu experts func einsum cost 0.00609135627746582 s
DEBUG 01-06 17:11:12.875455.875455 cuda_h.py:19] end gpu_experts cost 0.0062258243560791016 seconds
DEBUG 01-06 17:11:12.875072.875072 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-06 17:11:12.875067.875067 lmp.py:661] 
DEBUG 01-06 17:11:12.875067.875067 lmp.py:661]   Computing 17 experts on CPU...
DEBUG 01-06 17:11:12.875725.875725 cuda_h.py:19] end cpu_experts_submit cost 6.246566772460938e-05 seconds
DEBUG 01-06 17:11:12.875812.875812 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-06 17:11:12.884432.884432 mlpmodule.py:706] group tensors cost 0.008872270584106445 s
DEBUG 01-06 17:11:12.886160.886160 mlpmodule.py:744] pad cost 0.0011372566223144531 s
DEBUG 01-06 17:11:12.886707.886707 mlpmodule.py:750] create cpu tensor cost 4.935264587402344e-05 s
DEBUG 01-06 17:11:12.886100.886100 mlpmodule.py:755] move to cpu cost 3.528594970703125e-05 s
DEBUG 01-06 17:11:12.889248.889248 mlpmodule.py:769] group_w3: shape=torch.Size([17, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=49020928
DEBUG 01-06 17:11:12.889713.889713 mlpmodule.py:770] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-06 17:11:12.889834.889834 mlpmodule.py:775] group_w3 first element: -0.009765625
WARNING 01-06 17:11:12.889420.889420 mlpmodule.py:785] start einsum2
DEBUG 01-06 17:11:12.893944.893944 mlpmodule.py:795] group einsum cost 0.006966829299926758 s
DEBUG 01-06 17:11:12.894374.894374 mlpmodule.py:803] cpy2cputensor cost 0.00011301040649414062 s
DEBUG 01-06 17:11:12.896634.896634 cuda_h.py:19] end wait_cetm_experts cost 0.020529508590698242 seconds
DEBUG 01-06 17:11:12.896973.896973 cuda_h.py:19] end layer_moe_dgenerate_17 cost 0.031209230422973633 seconds
DEBUG 01-06 17:11:12.897046.897046 lmp.py:325] -------------------------------- end decode layer 17 --------------------------------
DEBUG 01-06 17:11:12.897399.897399 lmp.py:298] -------------------------------- start decode layer 18 --------------------------------
DEBUG 01-06 17:11:12.897969.897969 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-06 17:11:12.897292.897292 mlpmodule.py:367] cuda:1 cuda:1
DEBUG 01-06 17:11:12.897982.897982 cuda_h.py:10] start self_attn
cos shape torch.Size([65, 128]) sin shape torch.Size([65, 128]) position_ids tensor([[0]], device='cuda:1')
cos shape torch.Size([1, 1, 1, 128]) sin shape torch.Size([1, 1, 1, 128])
q_embed shape torch.Size([32, 16, 1, 128]) k_embed shape torch.Size([32, 16, 1, 128])
DEBUG 01-06 17:11:12.899306.899306 cuda_h.py:19] end self_attn cost 0.001886606216430664 seconds
DEBUG 01-06 17:11:12.900078.900078 cuda_h.py:19] end iln_self_attn_paln cost 0.0028121471405029297 seconds
DEBUG 01-06 17:11:12.900676.900676 cuda_h.py:10] start layer_moe_dgenerate_18
DEBUG 01-06 17:11:12.900399.900399 cuda_h.py:10] start gate
DEBUG 01-06 17:11:12.900696.900696 mlpmodule.py:664]  experts func einsum cost 0.02471327781677246 s
DEBUG 01-06 17:11:12.901772.901772 cuda_h.py:19] end gate cost 0.0007808208465576172 seconds
DEBUG 01-06 17:11:12.901961.901961 cuda_h.py:10] start experts_map_get
INFO 01-06 17:11:12.901793.901793 lmp.py:609] using loaded check layer: True
INFO 01-06 17:11:12.902428.902428 lmp.py:620] 
INFO 01-06 17:11:12.902428.902428 lmp.py:620] Layer 18 Expert Device Distribution:
INFO 01-06 17:11:12.902714.902714 lmp.py:621]   Active experts: 48 (out of 64 total)
INFO 01-06 17:11:12.902271.902271 lmp.py:622] 
INFO 01-06 17:11:12.902271.902271 lmp.py:622]   Detailed Expert Distribution:
INFO 01-06 17:11:12.902259.902259 lmp.py:623]   Expert ID  | Tokens     | Actual Device  
INFO 01-06 17:11:12.902478.902478 lmp.py:624]   ----------------------------------------------------------------------
INFO 01-06 17:11:12.902843.902843 lmp.py:627]   3          | 1          |  cuda:1         
INFO 01-06 17:11:12.902301.902301 lmp.py:627]   5          | 1          |  cuda:1         
INFO 01-06 17:11:12.902043.902043 lmp.py:627]   8          | 1          |  cuda:1         
INFO 01-06 17:11:12.902024.902024 lmp.py:627]   12         | 1          |  meta           
INFO 01-06 17:11:12.902528.902528 lmp.py:627]   31         | 1          |  cuda:1         
INFO 01-06 17:11:12.902032.902032 lmp.py:627]   32         | 1          |  meta           
INFO 01-06 17:11:12.902774.902774 lmp.py:627]   34         | 1          |  cuda:1         
INFO 01-06 17:11:12.902755.902755 lmp.py:627]   35         | 1          |  meta           
INFO 01-06 17:11:12.902974.902974 lmp.py:627]   40         | 1          |  meta           
INFO 01-06 17:11:12.902194.902194 lmp.py:627]   41         | 1          |  meta           
INFO 01-06 17:11:12.902413.902413 lmp.py:627]   50         | 1          |  cuda:1         
INFO 01-06 17:11:12.902678.902678 lmp.py:627]   55         | 1          |  cuda:1         
INFO 01-06 17:11:12.902706.902706 lmp.py:627]   56         | 1          |  meta           
INFO 01-06 17:11:12.902971.902971 lmp.py:627]   59         | 1          |  meta           
INFO 01-06 17:11:12.902998.902998 lmp.py:627]   0          | 2          |  cuda:1         
INFO 01-06 17:11:12.902025.902025 lmp.py:627]   7          | 2          |  cuda:1         
INFO 01-06 17:11:12.902053.902053 lmp.py:627]   9          | 2          |  meta           
INFO 01-06 17:11:12.902557.902557 lmp.py:627]   27         | 2          |  meta           
INFO 01-06 17:11:12.902107.902107 lmp.py:627]   29         | 2          |  meta           
INFO 01-06 17:11:12.902373.902373 lmp.py:627]   30         | 2          |  meta           
INFO 01-06 17:11:12.902638.902638 lmp.py:627]   37         | 2          |  meta           
INFO 01-06 17:11:12.902904.902904 lmp.py:627]   2          | 3          |  cuda:1         
INFO 01-06 17:11:12.902169.902169 lmp.py:627]   10         | 3          |  cuda:1         
INFO 01-06 17:11:12.902627.902627 lmp.py:627]   14         | 3          |  cuda:1         
INFO 01-06 17:11:12.902846.902846 lmp.py:627]   18         | 3          |  cuda:1         
INFO 01-06 17:11:12.902065.902065 lmp.py:627]   33         | 3          |  cuda:1         
INFO 01-06 17:11:12.902285.902285 lmp.py:627]   48         | 3          |  meta           
INFO 01-06 17:11:12.902312.902312 lmp.py:627]   49         | 3          |  cuda:1         
INFO 01-06 17:11:12.902339.902339 lmp.py:627]   61         | 3          |  cuda:1         
INFO 01-06 17:11:12.902366.902366 lmp.py:627]   6          | 4          |  cuda:1         
INFO 01-06 17:11:12.902155.902155 lmp.py:627]   25         | 4          |  meta           
INFO 01-06 17:11:12.902421.902421 lmp.py:627]   42         | 4          |  cuda:1         
INFO 01-06 17:11:12.902686.902686 lmp.py:627]   43         | 4          |  cuda:1         
INFO 01-06 17:11:12.902667.902667 lmp.py:627]   53         | 4          |  meta           
INFO 01-06 17:11:12.902648.902648 lmp.py:627]   13         | 5          |  cuda:1         
INFO 01-06 17:11:12.902867.902867 lmp.py:627]   21         | 6          |  meta           
INFO 01-06 17:11:12.902848.902848 lmp.py:627]   23         | 6          |  cuda:1         
INFO 01-06 17:11:12.902113.902113 lmp.py:627]   38         | 6          |  cuda:1         
INFO 01-06 17:11:12.902902.902902 lmp.py:627]   51         | 6          |  cuda:1         
INFO 01-06 17:11:12.902406.902406 lmp.py:627]   45         | 7          |  cuda:1         
INFO 01-06 17:11:12.902433.902433 lmp.py:627]   4          | 8          |  cuda:1         
INFO 01-06 17:11:12.903699.903699 lmp.py:627]   17         | 9          |  meta           
INFO 01-06 17:11:12.903203.903203 lmp.py:627]   22         | 9          |  cuda:1         
INFO 01-06 17:11:12.903661.903661 lmp.py:627]   52         | 9          |  meta           
INFO 01-06 17:11:12.903118.903118 lmp.py:627]   11         | 10         |  cuda:1         
INFO 01-06 17:11:12.903099.903099 lmp.py:627]   16         | 11         |  cuda:1         
INFO 01-06 17:11:12.903080.903080 lmp.py:627]   26         | 11         |  cuda:1         
INFO 01-06 17:11:12.903107.903107 lmp.py:627]   62         | 17         |  cuda:1         
INFO 01-06 17:11:12.903419.903419 lmp.py:628] ============================================================
INFO 01-06 17:11:12.903419.903419 lmp.py:628] 
INFO 01-06 17:11:12.903930.903930 lmp.py:630] experts_gpu_list: [3, 5, 8, 31, 34, 50, 55, 0, 7, 2, 10, 14, 18, 33, 49, 61, 6, 42, 43, 13, 23, 38, 51, 45, 4, 22, 11, 16, 26, 62] num: 30
INFO 01-06 17:11:12.903580.903580 lmp.py:631] experts_cpu_list: [12, 32, 35, 40, 41, 56, 59, 9, 27, 29, 30, 37, 48, 25, 53, 21, 17, 52] num: 18
INFO 01-06 17:11:12.903958.903958 lmp.py:632] expert_actual_device_map {0: 'cuda:1', 1: 'cuda:1', 2: 'cuda:1', 3: 'cuda:1', 4: 'cuda:1', 5: 'cuda:1', 6: 'cuda:1', 7: 'cuda:1', 8: 'cuda:1', 9: 'meta', 10: 'cuda:1', 11: 'cuda:1', 12: 'meta', 13: 'cuda:1', 14: 'cuda:1', 15: 'cuda:1', 16: 'cuda:1', 17: 'meta', 18: 'cuda:1', 19: 'meta', 20: 'cuda:1', 21: 'meta', 22: 'cuda:1', 23: 'cuda:1', 24: 'cuda:1', 25: 'meta', 26: 'cuda:1', 27: 'meta', 28: 'meta', 29: 'meta', 30: 'meta', 31: 'cuda:1', 32: 'meta', 33: 'cuda:1', 34: 'cuda:1', 35: 'meta', 36: 'meta', 37: 'meta', 38: 'cuda:1', 39: 'meta', 40: 'meta', 41: 'meta', 42: 'cuda:1', 43: 'cuda:1', 44: 'cuda:1', 45: 'cuda:1', 46: 'meta', 47: 'cuda:1', 48: 'meta', 49: 'cuda:1', 50: 'cuda:1', 51: 'cuda:1', 52: 'meta', 53: 'meta', 54: 'meta', 55: 'cuda:1', 56: 'meta', 57: 'cuda:1', 58: 'meta', 59: 'meta', 60: 'meta', 61: 'cuda:1', 62: 'cuda:1', 63: 'meta'}
DEBUG 01-06 17:11:12.903668.903668 cuda_h.py:19] end experts_map_get cost 0.0021028518676757812 seconds
DEBUG 01-06 17:11:12.903015.903015 cuda_h.py:10] start gpu_sexperts
DEBUG 01-06 17:11:12.903921.903921 cuda_h.py:19] end gpu_sexperts cost 0.0003123283386230469 seconds
DEBUG 01-06 17:11:12.903465.903465 cuda_h.py:10] start gpu_experts
DEBUG 01-06 17:11:12.904633.904633 mlpmodule.py:533] gpu group tensors cost 0.0005621910095214844 s
DEBUG 01-06 17:11:12.905209.905209 mlpmodule.py:566] gpu pad cost 0.0015316009521484375 s
DEBUG 01-06 17:11:12.906274.906274 mlpmodule.py:584] gpu group einsum cost 0.00047707557678222656 s
DEBUG 01-06 17:11:12.909561.909561 mlpmodule.py:613] gpu experts func einsum cost 0.005930900573730469 s
DEBUG 01-06 17:11:12.909729.909729 cuda_h.py:19] end gpu_experts cost 0.006062984466552734 seconds
DEBUG 01-06 17:11:12.909154.909154 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-06 17:11:12.909148.909148 lmp.py:661] 
DEBUG 01-06 17:11:12.909148.909148 lmp.py:661]   Computing 18 experts on CPU...
DEBUG 01-06 17:11:12.909568.909568 cuda_h.py:19] end cpu_experts_submit cost 6.270408630371094e-05 seconds
DEBUG 01-06 17:11:12.909840.909840 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-06 17:11:12.913908.913908 mlpmodule.py:706] group tensors cost 0.0036134719848632812 s
DEBUG 01-06 17:11:12.915692.915692 mlpmodule.py:744] pad cost 0.0009469985961914062 s
DEBUG 01-06 17:11:12.915927.915927 mlpmodule.py:750] create cpu tensor cost 4.076957702636719e-05 s
DEBUG 01-06 17:11:12.915446.915446 mlpmodule.py:755] move to cpu cost 3.123283386230469e-05 s
DEBUG 01-06 17:11:12.917714.917714 mlpmodule.py:769] group_w3: shape=torch.Size([18, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=51904512
DEBUG 01-06 17:11:12.917465.917465 mlpmodule.py:770] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-06 17:11:12.918155.918155 mlpmodule.py:775] group_w3 first element: 0.0228271484375
WARNING 01-06 17:11:12.918833.918833 mlpmodule.py:785] start einsum2
DEBUG 01-06 17:11:12.922953.922953 mlpmodule.py:795] group einsum cost 0.007004499435424805 s
DEBUG 01-06 17:11:12.922733.922733 mlpmodule.py:803] cpy2cputensor cost 8.392333984375e-05 s
DEBUG 01-06 17:11:12.925672.925672 cuda_h.py:19] end wait_cetm_experts cost 0.015013694763183594 seconds
DEBUG 01-06 17:11:12.925678.925678 cuda_h.py:19] end layer_moe_dgenerate_18 cost 0.025350332260131836 seconds
DEBUG 01-06 17:11:12.925379.925379 lmp.py:325] -------------------------------- end decode layer 18 --------------------------------
DEBUG 01-06 17:11:12.925864.925864 lmp.py:298] -------------------------------- start decode layer 19 --------------------------------
DEBUG 01-06 17:11:12.925474.925474 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-06 17:11:12.925591.925591 mlpmodule.py:367] cuda:1 cuda:1
DEBUG 01-06 17:11:12.926405.926405 cuda_h.py:10] start self_attn
cos shape torch.Size([65, 128]) sin shape torch.Size([65, 128]) position_ids tensor([[0]], device='cuda:1')
cos shape torch.Size([1, 1, 1, 128]) sin shape torch.Size([1, 1, 1, 128])
q_embed shape torch.Size([32, 16, 1, 128]) k_embed shape torch.Size([32, 16, 1, 128])
DEBUG 01-06 17:11:12.928613.928613 cuda_h.py:19] end self_attn cost 0.0019829273223876953 seconds
DEBUG 01-06 17:11:12.928342.928342 cuda_h.py:19] end iln_self_attn_paln cost 0.0029184818267822266 seconds
DEBUG 01-06 17:11:12.928370.928370 cuda_h.py:10] start layer_moe_dgenerate_19
DEBUG 01-06 17:11:12.928292.928292 cuda_h.py:10] start gate
DEBUG 01-06 17:11:12.929227.929227 mlpmodule.py:664]  experts func einsum cost 0.019108295440673828 s
DEBUG 01-06 17:11:12.929044.929044 cuda_h.py:19] end gate cost 0.0006392002105712891 seconds
DEBUG 01-06 17:11:12.929279.929279 cuda_h.py:10] start experts_map_get
INFO 01-06 17:11:12.929821.929821 lmp.py:609] using loaded check layer: True
INFO 01-06 17:11:12.930979.930979 lmp.py:620] 
INFO 01-06 17:11:12.930979.930979 lmp.py:620] Layer 19 Expert Device Distribution:
INFO 01-06 17:11:12.930742.930742 lmp.py:621]   Active experts: 57 (out of 64 total)
INFO 01-06 17:11:12.930822.930822 lmp.py:622] 
INFO 01-06 17:11:12.930822.930822 lmp.py:622]   Detailed Expert Distribution:
INFO 01-06 17:11:12.930241.930241 lmp.py:623]   Expert ID  | Tokens     | Actual Device  
INFO 01-06 17:11:12.930413.930413 lmp.py:624]   ----------------------------------------------------------------------
INFO 01-06 17:11:12.930778.930778 lmp.py:627]   1          | 1          |  cuda:1         
INFO 01-06 17:11:12.930236.930236 lmp.py:627]   2          | 1          |  cuda:1         
INFO 01-06 17:11:12.930217.930217 lmp.py:627]   4          | 1          |  cuda:1         
INFO 01-06 17:11:12.930198.930198 lmp.py:627]   6          | 1          |  cuda:1         
INFO 01-06 17:11:12.930179.930179 lmp.py:627]   7          | 1          |  cuda:1         
INFO 01-06 17:11:12.930683.930683 lmp.py:627]   9          | 1          |  cuda:1         
INFO 01-06 17:11:12.930902.930902 lmp.py:627]   12         | 1          |  meta           
INFO 01-06 17:11:12.930598.930598 lmp.py:627]   14         | 1          |  cuda:1         
INFO 01-06 17:11:12.930056.930056 lmp.py:627]   23         | 1          |  cuda:1         
INFO 01-06 17:11:12.930990.930990 lmp.py:627]   24         | 1          |  meta           
INFO 01-06 17:11:12.930448.930448 lmp.py:627]   25         | 1          |  cuda:1         
INFO 01-06 17:11:12.930952.930952 lmp.py:627]   30         | 1          |  meta           
INFO 01-06 17:11:12.930217.930217 lmp.py:627]   32         | 1          |  meta           
INFO 01-06 17:11:12.930483.930483 lmp.py:627]   35         | 1          |  cuda:1         
INFO 01-06 17:11:12.930749.930749 lmp.py:627]   42         | 1          |  meta           
INFO 01-06 17:11:12.931014.931014 lmp.py:627]   49         | 1          |  cuda:1         
INFO 01-06 17:11:12.931280.931280 lmp.py:627]   56         | 1          |  meta           
INFO 01-06 17:11:12.931499.931499 lmp.py:627]   62         | 1          |  meta           
INFO 01-06 17:11:12.931718.931718 lmp.py:627]   8          | 2          |  cuda:1         
INFO 01-06 17:11:12.931222.931222 lmp.py:627]   10         | 2          |  cuda:1         
INFO 01-06 17:11:12.931203.931203 lmp.py:627]   11         | 2          |  cuda:1         
INFO 01-06 17:11:12.931469.931469 lmp.py:627]   19         | 2          |  cuda:1         
INFO 01-06 17:11:12.931734.931734 lmp.py:627]   33         | 2          |  cuda:1         
INFO 01-06 17:11:12.931761.931761 lmp.py:627]   36         | 2          |  cuda:1         
INFO 01-06 17:11:12.931265.931265 lmp.py:627]   38         | 2          |  cuda:1         
INFO 01-06 17:11:12.931293.931293 lmp.py:627]   40         | 2          |  meta           
INFO 01-06 17:11:12.931797.931797 lmp.py:627]   43         | 2          |  cuda:1         
INFO 01-06 17:11:12.931301.931301 lmp.py:627]   58         | 2          |  meta           
INFO 01-06 17:11:12.931328.931328 lmp.py:627]   20         | 3          |  cuda:1         
INFO 01-06 17:11:12.931593.931593 lmp.py:627]   21         | 3          |  cuda:1         
INFO 01-06 17:11:12.931859.931859 lmp.py:627]   28         | 3          |  meta           
INFO 01-06 17:11:12.931124.931124 lmp.py:627]   37         | 3          |  cuda:1         
INFO 01-06 17:11:12.931628.931628 lmp.py:627]   46         | 3          |  cuda:1         
INFO 01-06 17:11:12.931894.931894 lmp.py:627]   52         | 3          |  meta           
INFO 01-06 17:11:12.931160.931160 lmp.py:627]   57         | 3          |  meta           
INFO 01-06 17:11:12.931425.931425 lmp.py:627]   61         | 3          |  cuda:1         
INFO 01-06 17:11:12.931929.931929 lmp.py:627]   16         | 4          |  meta           
INFO 01-06 17:11:12.931195.931195 lmp.py:627]   22         | 4          |  meta           
INFO 01-06 17:11:12.931460.931460 lmp.py:627]   31         | 4          |  cuda:1         
INFO 01-06 17:11:12.931726.931726 lmp.py:627]   55         | 4          |  meta           
INFO 01-06 17:11:12.931230.931230 lmp.py:627]   0          | 5          |  cuda:1         
INFO 01-06 17:11:12.931495.931495 lmp.py:627]   34         | 5          |  meta           
INFO 01-06 17:11:12.931761.931761 lmp.py:627]   47         | 5          |  meta           
INFO 01-06 17:11:12.931265.931265 lmp.py:627]   50         | 5          |  meta           
INFO 01-06 17:11:12.931769.931769 lmp.py:627]   63         | 5          |  cuda:1         
INFO 01-06 17:11:12.931273.931273 lmp.py:627]   3          | 6          |  cuda:1         
INFO 01-06 17:11:12.931777.931777 lmp.py:627]   18         | 6          |  cuda:1         
INFO 01-06 17:11:12.931043.931043 lmp.py:627]   26         | 6          |  meta           
INFO 01-06 17:11:12.931785.931785 lmp.py:627]   17         | 7          |  cuda:1         
INFO 01-06 17:11:12.931289.931289 lmp.py:627]   39         | 7          |  cuda:1         
INFO 01-06 17:11:12.931316.931316 lmp.py:627]   41         | 7          |  meta           
INFO 01-06 17:11:12.931820.931820 lmp.py:627]   45         | 7          |  cuda:1         
INFO 01-06 17:11:12.931086.931086 lmp.py:627]   51         | 7          |  cuda:1         
INFO 01-06 17:11:12.931828.931828 lmp.py:627]   29         | 8          |  cuda:1         
INFO 01-06 17:11:12.931094.931094 lmp.py:627]   13         | 9          |  cuda:1         
INFO 01-06 17:11:12.931359.931359 lmp.py:627]   48         | 9          |  meta           
INFO 01-06 17:11:12.931148.931148 lmp.py:627]   53         | 10         |  cuda:1         
INFO 01-06 17:11:12.931937.931937 lmp.py:628] ============================================================
INFO 01-06 17:11:12.931937.931937 lmp.py:628] 
INFO 01-06 17:11:12.931647.931647 lmp.py:630] experts_gpu_list: [1, 2, 4, 6, 7, 9, 14, 23, 25, 35, 49, 8, 10, 11, 19, 33, 36, 38, 43, 20, 21, 37, 46, 61, 31, 0, 63, 3, 18, 17, 39, 45, 51, 29, 13, 53] num: 36
INFO 01-06 17:11:12.931442.931442 lmp.py:631] experts_cpu_list: [12, 24, 30, 32, 42, 56, 62, 40, 58, 28, 52, 57, 16, 22, 55, 34, 47, 50, 26, 41, 48] num: 21
INFO 01-06 17:11:12.931013.931013 lmp.py:632] expert_actual_device_map {0: 'cuda:1', 1: 'cuda:1', 2: 'cuda:1', 3: 'cuda:1', 4: 'cuda:1', 5: 'cuda:1', 6: 'cuda:1', 7: 'cuda:1', 8: 'cuda:1', 9: 'cuda:1', 10: 'cuda:1', 11: 'cuda:1', 12: 'meta', 13: 'cuda:1', 14: 'cuda:1', 15: 'meta', 16: 'meta', 17: 'cuda:1', 18: 'cuda:1', 19: 'cuda:1', 20: 'cuda:1', 21: 'cuda:1', 22: 'meta', 23: 'cuda:1', 24: 'meta', 25: 'cuda:1', 26: 'meta', 27: 'meta', 28: 'meta', 29: 'cuda:1', 30: 'meta', 31: 'cuda:1', 32: 'meta', 33: 'cuda:1', 34: 'meta', 35: 'cuda:1', 36: 'cuda:1', 37: 'cuda:1', 38: 'cuda:1', 39: 'cuda:1', 40: 'meta', 41: 'meta', 42: 'meta', 43: 'cuda:1', 44: 'meta', 45: 'cuda:1', 46: 'cuda:1', 47: 'meta', 48: 'meta', 49: 'cuda:1', 50: 'meta', 51: 'cuda:1', 52: 'meta', 53: 'cuda:1', 54: 'meta', 55: 'meta', 56: 'meta', 57: 'meta', 58: 'meta', 59: 'meta', 60: 'meta', 61: 'cuda:1', 62: 'meta', 63: 'cuda:1'}
DEBUG 01-06 17:11:12.931676.931676 cuda_h.py:19] end experts_map_get cost 0.0023300647735595703 seconds
DEBUG 01-06 17:11:12.932877.932877 cuda_h.py:10] start gpu_sexperts
DEBUG 01-06 17:11:12.932340.932340 cuda_h.py:19] end gpu_sexperts cost 0.0003368854522705078 seconds
DEBUG 01-06 17:11:12.932316.932316 cuda_h.py:10] start gpu_experts
DEBUG 01-06 17:11:12.934498.934498 mlpmodule.py:533] gpu group tensors cost 0.0015993118286132812 s
DEBUG 01-06 17:11:12.936867.936867 mlpmodule.py:566] gpu pad cost 0.0018565654754638672 s
DEBUG 01-06 17:11:12.936310.936310 mlpmodule.py:584] gpu group einsum cost 0.0005025863647460938 s
DEBUG 01-06 17:11:12.940465.940465 mlpmodule.py:613] gpu experts func einsum cost 0.007547616958618164 s
DEBUG 01-06 17:11:12.940779.940779 cuda_h.py:19] end gpu_experts cost 0.007684946060180664 seconds
DEBUG 01-06 17:11:12.940820.940820 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-06 17:11:12.940523.940523 lmp.py:661] 
DEBUG 01-06 17:11:12.940523.940523 lmp.py:661]   Computing 21 experts on CPU...
DEBUG 01-06 17:11:12.940266.940266 cuda_h.py:19] end cpu_experts_submit cost 5.626678466796875e-05 seconds
DEBUG 01-06 17:11:12.940963.940963 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-06 17:11:12.945690.945690 mlpmodule.py:706] group tensors cost 0.00463104248046875 s
DEBUG 01-06 17:11:12.947791.947791 mlpmodule.py:744] pad cost 0.0012295246124267578 s
DEBUG 01-06 17:11:12.947371.947371 mlpmodule.py:750] create cpu tensor cost 4.482269287109375e-05 s
DEBUG 01-06 17:11:12.947996.947996 mlpmodule.py:755] move to cpu cost 3.361701965332031e-05 s
DEBUG 01-06 17:11:12.949748.949748 mlpmodule.py:769] group_w3: shape=torch.Size([21, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=60555264
DEBUG 01-06 17:11:12.949876.949876 mlpmodule.py:770] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-06 17:11:12.949044.949044 mlpmodule.py:775] group_w3 first element: 0.006072998046875
WARNING 01-06 17:11:12.949483.949483 mlpmodule.py:785] start einsum2
DEBUG 01-06 17:11:12.954404.954404 mlpmodule.py:795] group einsum cost 0.0067865848541259766 s
DEBUG 01-06 17:11:12.954357.954357 mlpmodule.py:803] cpy2cputensor cost 0.00010514259338378906 s
DEBUG 01-06 17:11:12.957327.957327 cuda_h.py:19] end wait_cetm_experts cost 0.017146587371826172 seconds
DEBUG 01-06 17:11:12.958335.958335 cuda_h.py:19] end layer_moe_dgenerate_19 cost 0.029172658920288086 seconds
DEBUG 01-06 17:11:12.958641.958641 lmp.py:325] -------------------------------- end decode layer 19 --------------------------------
DEBUG 01-06 17:11:12.958954.958954 lmp.py:298] -------------------------------- start decode layer 20 --------------------------------
DEBUG 01-06 17:11:12.958816.958816 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-06 17:11:12.958205.958205 mlpmodule.py:367] cuda:1 cuda:1
DEBUG 01-06 17:11:12.958199.958199 cuda_h.py:10] start self_attn
cos shape torch.Size([65, 128]) sin shape torch.Size([65, 128]) position_ids tensor([[0]], device='cuda:1')
cos shape torch.Size([1, 1, 1, 128]) sin shape torch.Size([1, 1, 1, 128])
q_embed shape torch.Size([32, 16, 1, 128]) k_embed shape torch.Size([32, 16, 1, 128])
DEBUG 01-06 17:11:12.960020.960020 cuda_h.py:19] end self_attn cost 0.0019075870513916016 seconds
DEBUG 01-06 17:11:12.961442.961442 cuda_h.py:19] end iln_self_attn_paln cost 0.0028374195098876953 seconds
DEBUG 01-06 17:11:12.961756.961756 cuda_h.py:10] start layer_moe_dgenerate_20
DEBUG 01-06 17:11:12.961909.961909 cuda_h.py:10] start gate
DEBUG 01-06 17:11:12.961209.961209 cuda_h.py:19] end gate cost 0.0006012916564941406 seconds
DEBUG 01-06 17:11:12.962575.962575 cuda_h.py:10] start experts_map_get
INFO 01-06 17:11:12.962871.962871 lmp.py:609] using loaded check layer: True
INFO 01-06 17:11:12.962990.962990 lmp.py:620] 
INFO 01-06 17:11:12.962990.962990 lmp.py:620] Layer 20 Expert Device Distribution:
INFO 01-06 17:11:12.962044.962044 lmp.py:621]   Active experts: 49 (out of 64 total)
INFO 01-06 17:11:12.962700.962700 lmp.py:622] 
INFO 01-06 17:11:12.962700.962700 lmp.py:622]   Detailed Expert Distribution:
INFO 01-06 17:11:12.963595.963595 lmp.py:623]   Expert ID  | Tokens     | Actual Device  
INFO 01-06 17:11:12.963152.963152 lmp.py:624]   ----------------------------------------------------------------------
INFO 01-06 17:11:12.963140.963140 lmp.py:627]   0          | 1          |  cuda:1         
INFO 01-06 17:11:12.963220.963220 lmp.py:627]   4          | 1          |  cuda:1         
INFO 01-06 17:11:12.963824.963824 lmp.py:627]   12         | 1          |  cuda:1         
INFO 01-06 17:11:12.963950.963950 lmp.py:627]   14         | 1          |  cuda:1         
INFO 01-06 17:11:12.963839.963839 lmp.py:627]   17         | 1          |  cuda:1         
INFO 01-06 17:11:12.963204.963204 lmp.py:627]   23         | 1          |  meta           
INFO 01-06 17:11:12.963569.963569 lmp.py:627]   28         | 1          |  meta           
INFO 01-06 17:11:12.963126.963126 lmp.py:627]   37         | 1          |  meta           
INFO 01-06 17:11:12.963729.963729 lmp.py:627]   40         | 1          |  meta           
INFO 01-06 17:11:12.963094.963094 lmp.py:627]   42         | 1          |  meta           
INFO 01-06 17:11:12.963698.963698 lmp.py:627]   44         | 1          |  cuda:1         
INFO 01-06 17:11:12.963824.963824 lmp.py:627]   53         | 1          |  cuda:1         
INFO 01-06 17:11:12.963236.963236 lmp.py:627]   56         | 1          |  cuda:1         
INFO 01-06 17:11:12.963362.963362 lmp.py:627]   63         | 1          |  meta           
INFO 01-06 17:11:12.963250.963250 lmp.py:627]   26         | 2          |  cuda:1         
INFO 01-06 17:11:12.963854.963854 lmp.py:627]   27         | 2          |  cuda:1         
INFO 01-06 17:11:12.963696.963696 lmp.py:627]   30         | 2          |  cuda:1         
INFO 01-06 17:11:12.963584.963584 lmp.py:627]   32         | 2          |  cuda:1         
INFO 01-06 17:11:12.963949.963949 lmp.py:627]   41         | 2          |  meta           
INFO 01-06 17:11:12.963076.963076 lmp.py:627]   43         | 2          |  meta           
INFO 01-06 17:11:12.963441.963441 lmp.py:627]   47         | 2          |  meta           
INFO 01-06 17:11:12.963613.963613 lmp.py:627]   52         | 2          |  meta           
INFO 01-06 17:11:12.963263.963263 lmp.py:627]   55         | 2          |  meta           
INFO 01-06 17:11:12.963913.963913 lmp.py:627]   8          | 3          |  cuda:1         
INFO 01-06 17:11:12.963801.963801 lmp.py:627]   9          | 3          |  cuda:1         
INFO 01-06 17:11:12.963643.963643 lmp.py:627]   11         | 3          |  cuda:1         
INFO 01-06 17:11:12.963723.963723 lmp.py:627]   13         | 3          |  meta           
INFO 01-06 17:11:12.963327.963327 lmp.py:627]   16         | 3          |  cuda:1         
INFO 01-06 17:11:12.963215.963215 lmp.py:627]   19         | 3          |  meta           
INFO 01-06 17:11:12.963103.963103 lmp.py:627]   57         | 3          |  meta           
INFO 01-06 17:11:12.963230.963230 lmp.py:627]   1          | 4          |  cuda:1         
INFO 01-06 17:11:12.963118.963118 lmp.py:627]   15         | 4          |  cuda:1         
INFO 01-06 17:11:12.963483.963483 lmp.py:627]   18         | 4          |  cuda:1         
INFO 01-06 17:11:12.963325.963325 lmp.py:627]   33         | 4          |  meta           
INFO 01-06 17:11:12.963451.963451 lmp.py:627]   46         | 4          |  meta           
INFO 01-06 17:11:12.963055.963055 lmp.py:627]   10         | 5          |  cuda:1         
INFO 01-06 17:11:12.963135.963135 lmp.py:627]   49         | 5          |  meta           
INFO 01-06 17:11:12.963262.963262 lmp.py:627]   62         | 5          |  cuda:1         
INFO 01-06 17:11:12.963673.963673 lmp.py:627]   7          | 6          |  cuda:1         
INFO 01-06 17:11:12.963323.963323 lmp.py:627]   31         | 6          |  cuda:1         
INFO 01-06 17:11:12.963734.963734 lmp.py:627]   50         | 6          |  meta           
INFO 01-06 17:11:12.964145.964145 lmp.py:627]   5          | 7          |  cuda:1         
INFO 01-06 17:11:12.964795.964795 lmp.py:627]   20         | 7          |  meta           
INFO 01-06 17:11:12.964160.964160 lmp.py:627]   24         | 7          |  meta           
INFO 01-06 17:11:12.964764.964764 lmp.py:627]   45         | 8          |  cuda:1         
INFO 01-06 17:11:12.964367.964367 lmp.py:627]   51         | 8          |  cuda:1         
INFO 01-06 17:11:12.964255.964255 lmp.py:627]   25         | 10         |  cuda:1         
INFO 01-06 17:11:12.964144.964144 lmp.py:627]   60         | 14         |  cuda:1         
INFO 01-06 17:11:12.964032.964032 lmp.py:627]   48         | 25         |  cuda:1         
INFO 01-06 17:11:12.964205.964205 lmp.py:628] ============================================================
INFO 01-06 17:11:12.964205.964205 lmp.py:628] 
INFO 01-06 17:11:12.964815.964815 lmp.py:630] experts_gpu_list: [0, 4, 12, 14, 17, 44, 53, 56, 26, 27, 30, 32, 8, 9, 11, 16, 1, 15, 18, 10, 62, 7, 31, 5, 45, 51, 25, 60, 48] num: 29
INFO 01-06 17:11:12.964849.964849 lmp.py:631] experts_cpu_list: [23, 28, 37, 40, 42, 63, 41, 43, 47, 52, 55, 13, 19, 57, 33, 46, 49, 50, 20, 24] num: 20
INFO 01-06 17:11:12.964373.964373 lmp.py:632] expert_actual_device_map {0: 'cuda:1', 1: 'cuda:1', 2: 'cuda:1', 3: 'cuda:1', 4: 'cuda:1', 5: 'cuda:1', 6: 'cuda:1', 7: 'cuda:1', 8: 'cuda:1', 9: 'cuda:1', 10: 'cuda:1', 11: 'cuda:1', 12: 'cuda:1', 13: 'meta', 14: 'cuda:1', 15: 'cuda:1', 16: 'cuda:1', 17: 'cuda:1', 18: 'cuda:1', 19: 'meta', 20: 'meta', 21: 'meta', 22: 'meta', 23: 'meta', 24: 'meta', 25: 'cuda:1', 26: 'cuda:1', 27: 'cuda:1', 28: 'meta', 29: 'cuda:1', 30: 'cuda:1', 31: 'cuda:1', 32: 'cuda:1', 33: 'meta', 34: 'cuda:1', 35: 'cuda:1', 36: 'meta', 37: 'meta', 38: 'meta', 39: 'meta', 40: 'meta', 41: 'meta', 42: 'meta', 43: 'meta', 44: 'cuda:1', 45: 'cuda:1', 46: 'meta', 47: 'meta', 48: 'cuda:1', 49: 'meta', 50: 'meta', 51: 'cuda:1', 52: 'meta', 53: 'cuda:1', 54: 'meta', 55: 'meta', 56: 'cuda:1', 57: 'meta', 58: 'cuda:1', 59: 'cuda:1', 60: 'cuda:1', 61: 'meta', 62: 'cuda:1', 63: 'meta'}
DEBUG 01-06 17:11:12.964421.964421 cuda_h.py:19] end experts_map_get cost 0.0022735595703125 seconds
DEBUG 01-06 17:11:12.964987.964987 mlpmodule.py:664]  experts func einsum cost 0.023815631866455078 s
DEBUG 01-06 17:11:12.964779.964779 cuda_h.py:10] start gpu_sexperts
DEBUG 01-06 17:11:12.964132.964132 cuda_h.py:19] end gpu_sexperts cost 0.0003268718719482422 seconds
DEBUG 01-06 17:11:12.965829.965829 cuda_h.py:10] start gpu_experts
DEBUG 01-06 17:11:12.965340.965340 mlpmodule.py:533] gpu group tensors cost 0.0005474090576171875 s
DEBUG 01-06 17:11:12.967577.967577 mlpmodule.py:566] gpu pad cost 0.0014955997467041016 s
DEBUG 01-06 17:11:12.967509.967509 mlpmodule.py:584] gpu group einsum cost 0.0004837512969970703 s
DEBUG 01-06 17:11:12.970231.970231 mlpmodule.py:613] gpu experts func einsum cost 0.00580143928527832 s
DEBUG 01-06 17:11:12.971254.971254 cuda_h.py:19] end gpu_experts cost 0.005934953689575195 seconds
DEBUG 01-06 17:11:12.971056.971056 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-06 17:11:12.971951.971951 lmp.py:661] 
DEBUG 01-06 17:11:12.971951.971951 lmp.py:661]   Computing 20 experts on CPU...
DEBUG 01-06 17:11:12.971741.971741 cuda_h.py:19] end cpu_experts_submit cost 5.4836273193359375e-05 seconds
DEBUG 01-06 17:11:12.971060.971060 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-06 17:11:12.979912.979912 mlpmodule.py:706] group tensors cost 0.008101940155029297 s
DEBUG 01-06 17:11:12.981173.981173 mlpmodule.py:744] pad cost 0.001081705093383789 s
DEBUG 01-06 17:11:12.981548.981548 mlpmodule.py:750] create cpu tensor cost 3.981590270996094e-05 s
DEBUG 01-06 17:11:12.981828.981828 mlpmodule.py:755] move to cpu cost 3.0279159545898438e-05 s
DEBUG 01-06 17:11:12.983235.983235 mlpmodule.py:769] group_w3: shape=torch.Size([20, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=57671680
DEBUG 01-06 17:11:12.983369.983369 mlpmodule.py:770] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-06 17:11:12.983252.983252 mlpmodule.py:775] group_w3 first element: 0.00433349609375
WARNING 01-06 17:11:12.984215.984215 mlpmodule.py:785] start einsum2
DEBUG 01-06 17:11:12.988189.988189 mlpmodule.py:795] group einsum cost 0.007564544677734375 s
DEBUG 01-06 17:11:12.989797.989797 mlpmodule.py:803] cpy2cputensor cost 0.00010514259338378906 s
DEBUG 01-06 17:11:12.991579.991579 cuda_h.py:19] end wait_cetm_experts cost 0.020546436309814453 seconds
DEBUG 01-06 17:11:12.992654.992654 cuda_h.py:19] end layer_moe_dgenerate_20 cost 0.03094959259033203 seconds
DEBUG 01-06 17:11:12.992114.992114 lmp.py:325] -------------------------------- end decode layer 20 --------------------------------
DEBUG 01-06 17:11:12.992938.992938 lmp.py:298] -------------------------------- start decode layer 21 --------------------------------
DEBUG 01-06 17:11:12.992403.992403 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-06 17:11:12.992926.992926 mlpmodule.py:367] cuda:1 cuda:1
DEBUG 01-06 17:11:12.993211.993211 cuda_h.py:10] start self_attn
cos shape torch.Size([65, 128]) sin shape torch.Size([65, 128]) position_ids tensor([[0]], device='cuda:1')
cos shape torch.Size([1, 1, 1, 128]) sin shape torch.Size([1, 1, 1, 128])
q_embed shape torch.Size([32, 16, 1, 128]) k_embed shape torch.Size([32, 16, 1, 128])
DEBUG 01-06 17:11:12.996038.996038 cuda_h.py:19] end self_attn cost 0.0030319690704345703 seconds
DEBUG 01-06 17:11:12.996984.996984 mlpmodule.py:664]  experts func einsum cost 0.02548050880432129 s
DEBUG 01-06 17:11:12.997487.997487 cuda_h.py:19] end iln_self_attn_paln cost 0.0045757293701171875 seconds
DEBUG 01-06 17:11:12.997822.997822 cuda_h.py:10] start layer_moe_dgenerate_21
DEBUG 01-06 17:11:12.997309.997309 cuda_h.py:10] start gate
DEBUG 01-06 17:11:12.998819.998819 cuda_h.py:19] end gate cost 0.0009353160858154297 seconds
DEBUG 01-06 17:11:12.998233.998233 cuda_h.py:10] start experts_map_get
INFO 01-06 17:11:12.999593.999593 lmp.py:609] using loaded check layer: True
INFO 01-06 17:11:12.999367.999367 lmp.py:620] 
INFO 01-06 17:11:12.999367.999367 lmp.py:620] Layer 21 Expert Device Distribution:
INFO 01-06 17:11:12.999322.999322 lmp.py:621]   Active experts: 53 (out of 64 total)
INFO 01-06 17:11:12.999402.999402 lmp.py:622] 
INFO 01-06 17:11:12.999402.999402 lmp.py:622]   Detailed Expert Distribution:
INFO 01-06 17:11:12.999913.999913 lmp.py:623]   Expert ID  | Tokens     | Actual Device  
INFO 01-06 17:11:12.999371.999371 lmp.py:624]   ----------------------------------------------------------------------
INFO 01-06 17:11:12.999259.999259 lmp.py:627]   2          | 1          |  cuda:1         
INFO 01-06 17:11:12.999717.999717 lmp.py:627]   11         | 1          |  meta           
INFO 01-06 17:11:12.999221.999221 lmp.py:627]   17         | 1          |  cuda:1         
INFO 01-06 17:11:12.999202.999202 lmp.py:627]   19         | 1          |  cuda:1         
INFO 01-06 17:11:12.999944.999944 lmp.py:627]   27         | 1          |  meta           
INFO 01-06 17:11:12.999210.999210 lmp.py:627]   28         | 1          |  cuda:1         
INFO 01-06 17:11:12.999475.999475 lmp.py:627]   31         | 1          |  cuda:1         
INFO 01-06 17:11:12.999979.999979 lmp.py:627]   36         | 1          |  cuda:1         
INFO 01-06 17:11:13.000198.000198 lmp.py:627]   38         | 1          |  meta           
INFO 01-06 17:11:13.000133.000133 lmp.py:627]   46         | 1          |  cuda:1         
INFO 01-06 17:11:13.000591.000591 lmp.py:627]   47         | 1          |  meta           
INFO 01-06 17:11:13.000810.000810 lmp.py:627]   49         | 1          |  meta           
INFO 01-06 17:11:13.000314.000314 lmp.py:627]   50         | 1          |  meta           
INFO 01-06 17:11:13.000341.000341 lmp.py:627]   54         | 1          |  meta           
INFO 01-06 17:11:13.000845.000845 lmp.py:627]   57         | 1          |  cuda:1         
INFO 01-06 17:11:13.000872.000872 lmp.py:627]   60         | 1          |  meta           
INFO 01-06 17:11:13.000138.000138 lmp.py:627]   6          | 2          |  cuda:1         
INFO 01-06 17:11:13.000165.000165 lmp.py:627]   22         | 2          |  meta           
INFO 01-06 17:11:13.000907.000907 lmp.py:627]   30         | 2          |  cuda:1         
INFO 01-06 17:11:13.000411.000411 lmp.py:627]   37         | 2          |  cuda:1         
INFO 01-06 17:11:13.000392.000392 lmp.py:627]   41         | 2          |  meta           
INFO 01-06 17:11:13.000850.000850 lmp.py:627]   51         | 2          |  meta           
INFO 01-06 17:11:13.000115.000115 lmp.py:627]   53         | 2          |  meta           
INFO 01-06 17:11:13.000381.000381 lmp.py:627]   63         | 2          |  cuda:1         
INFO 01-06 17:11:13.000408.000408 lmp.py:627]   3          | 3          |  cuda:1         
INFO 01-06 17:11:13.000674.000674 lmp.py:627]   7          | 3          |  cuda:1         
INFO 01-06 17:11:13.000939.000939 lmp.py:627]   8          | 3          |  cuda:1         
INFO 01-06 17:11:13.000014.000014 lmp.py:627]   10         | 3          |  cuda:1         
INFO 01-06 17:11:13.000233.000233 lmp.py:627]   16         | 3          |  cuda:1         
INFO 01-06 17:11:13.000022.000022 lmp.py:627]   18         | 3          |  cuda:1         
INFO 01-06 17:11:13.000956.000956 lmp.py:627]   20         | 3          |  cuda:1         
INFO 01-06 17:11:13.000176.000176 lmp.py:627]   23         | 3          |  meta           
INFO 01-06 17:11:13.000395.000395 lmp.py:627]   25         | 3          |  cuda:1         
INFO 01-06 17:11:13.000137.000137 lmp.py:627]   34         | 3          |  meta           
INFO 01-06 17:11:13.000403.000403 lmp.py:627]   44         | 3          |  meta           
INFO 01-06 17:11:13.000192.000192 lmp.py:627]   48         | 3          |  meta           
INFO 01-06 17:11:13.000457.000457 lmp.py:627]   55         | 3          |  cuda:1         
INFO 01-06 17:11:13.000246.000246 lmp.py:627]   58         | 3          |  cuda:1         
INFO 01-06 17:11:13.000273.000273 lmp.py:627]   59         | 3          |  meta           
INFO 01-06 17:11:13.000824.000824 lmp.py:627]   14         | 4          |  meta           
INFO 01-06 17:11:13.000328.000328 lmp.py:627]   26         | 4          |  meta           
INFO 01-06 17:11:13.000070.000070 lmp.py:627]   39         | 4          |  meta           
INFO 01-06 17:11:13.000051.000051 lmp.py:627]   21         | 5          |  cuda:1         
INFO 01-06 17:11:13.000793.000793 lmp.py:627]   29         | 5          |  cuda:1         
INFO 01-06 17:11:13.000012.000012 lmp.py:627]   61         | 5          |  cuda:1         
INFO 01-06 17:11:13.000278.000278 lmp.py:627]   24         | 6          |  meta           
INFO 01-06 17:11:13.000305.000305 lmp.py:627]   56         | 7          |  meta           
INFO 01-06 17:11:13.000332.000332 lmp.py:627]   13         | 8          |  cuda:1         
INFO 01-06 17:11:13.000883.000883 lmp.py:627]   15         | 8          |  cuda:1         
INFO 01-06 17:11:13.000671.000671 lmp.py:627]   12         | 10         |  cuda:1         
INFO 01-06 17:11:13.000699.000699 lmp.py:627]   40         | 15         |  cuda:1         
INFO 01-06 17:11:13.000918.000918 lmp.py:627]   0          | 16         |  cuda:1         
INFO 01-06 17:11:13.000137.000137 lmp.py:627]   45         | 18         |  cuda:1         
INFO 01-06 17:11:13.000879.000879 lmp.py:628] ============================================================
INFO 01-06 17:11:13.000879.000879 lmp.py:628] 
INFO 01-06 17:11:13.000821.000821 lmp.py:630] experts_gpu_list: [2, 17, 19, 28, 31, 36, 46, 57, 6, 30, 37, 63, 3, 7, 8, 10, 16, 18, 20, 25, 55, 58, 21, 29, 61, 13, 15, 12, 40, 0, 45] num: 31
INFO 01-06 17:11:13.001471.001471 lmp.py:631] experts_cpu_list: [11, 27, 38, 47, 49, 50, 54, 60, 22, 41, 51, 53, 23, 34, 44, 48, 59, 14, 26, 39, 24, 56] num: 22
INFO 01-06 17:11:13.001849.001849 lmp.py:632] expert_actual_device_map {0: 'cuda:1', 1: 'cuda:1', 2: 'cuda:1', 3: 'cuda:1', 4: 'cuda:1', 5: 'cuda:1', 6: 'cuda:1', 7: 'cuda:1', 8: 'cuda:1', 9: 'meta', 10: 'cuda:1', 11: 'meta', 12: 'cuda:1', 13: 'cuda:1', 14: 'meta', 15: 'cuda:1', 16: 'cuda:1', 17: 'cuda:1', 18: 'cuda:1', 19: 'cuda:1', 20: 'cuda:1', 21: 'cuda:1', 22: 'meta', 23: 'meta', 24: 'meta', 25: 'cuda:1', 26: 'meta', 27: 'meta', 28: 'cuda:1', 29: 'cuda:1', 30: 'cuda:1', 31: 'cuda:1', 32: 'meta', 33: 'cuda:1', 34: 'meta', 35: 'meta', 36: 'cuda:1', 37: 'cuda:1', 38: 'meta', 39: 'meta', 40: 'cuda:1', 41: 'meta', 42: 'cuda:1', 43: 'cuda:1', 44: 'meta', 45: 'cuda:1', 46: 'cuda:1', 47: 'meta', 48: 'meta', 49: 'meta', 50: 'meta', 51: 'meta', 52: 'meta', 53: 'meta', 54: 'meta', 55: 'cuda:1', 56: 'meta', 57: 'cuda:1', 58: 'cuda:1', 59: 'meta', 60: 'meta', 61: 'cuda:1', 62: 'meta', 63: 'cuda:1'}
DEBUG 01-06 17:11:13.001082.001082 cuda_h.py:19] end experts_map_get cost 0.0023615360260009766 seconds
DEBUG 01-06 17:11:13.001283.001283 cuda_h.py:10] start gpu_sexperts
DEBUG 01-06 17:11:13.001904.001904 cuda_h.py:19] end gpu_sexperts cost 0.00031304359436035156 seconds
DEBUG 01-06 17:11:13.001588.001588 cuda_h.py:10] start gpu_experts
DEBUG 01-06 17:11:13.002292.002292 mlpmodule.py:533] gpu group tensors cost 0.00058746337890625 s
DEBUG 01-06 17:11:13.003791.003791 mlpmodule.py:566] gpu pad cost 0.0015835762023925781 s
DEBUG 01-06 17:11:13.004620.004620 mlpmodule.py:584] gpu group einsum cost 0.0003752708435058594 s
DEBUG 01-06 17:11:13.007361.007361 mlpmodule.py:613] gpu experts func einsum cost 0.005796670913696289 s
DEBUG 01-06 17:11:13.007006.007006 cuda_h.py:19] end gpu_experts cost 0.00593113899230957 seconds
DEBUG 01-06 17:11:13.007716.007716 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-06 17:11:13.007233.007233 lmp.py:661] 
DEBUG 01-06 17:11:13.007233.007233 lmp.py:661]   Computing 22 experts on CPU...
DEBUG 01-06 17:11:13.007275.007275 cuda_h.py:19] end cpu_experts_submit cost 6.580352783203125e-05 seconds
DEBUG 01-06 17:11:13.007594.007594 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-06 17:11:13.022994.022994 mlpmodule.py:706] group tensors cost 0.014640331268310547 s
DEBUG 01-06 17:11:13.024001.024001 mlpmodule.py:744] pad cost 0.0015101432800292969 s
DEBUG 01-06 17:11:13.024462.024462 mlpmodule.py:750] create cpu tensor cost 5.1975250244140625e-05 s
DEBUG 01-06 17:11:13.024147.024147 mlpmodule.py:755] move to cpu cost 3.6716461181640625e-05 s
DEBUG 01-06 17:11:13.027935.027935 mlpmodule.py:769] group_w3: shape=torch.Size([22, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=63438848
DEBUG 01-06 17:11:13.028083.028083 mlpmodule.py:770] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-06 17:11:13.028271.028271 mlpmodule.py:775] group_w3 first element: 0.0115966796875
WARNING 01-06 17:11:13.028453.028453 mlpmodule.py:785] start einsum2
DEBUG 01-06 17:11:13.033099.033099 mlpmodule.py:795] group einsum cost 0.008410930633544922 s
DEBUG 01-06 17:11:13.033728.033728 mlpmodule.py:803] cpy2cputensor cost 0.00011920928955078125 s
DEBUG 01-06 17:11:13.036869.036869 cuda_h.py:19] end wait_cetm_experts cost 0.029079198837280273 seconds
DEBUG 01-06 17:11:13.037487.037487 cuda_h.py:19] end layer_moe_dgenerate_21 cost 0.03974556922912598 seconds
DEBUG 01-06 17:11:13.037693.037693 lmp.py:325] -------------------------------- end decode layer 21 --------------------------------
DEBUG 01-06 17:11:13.037821.037821 lmp.py:298] -------------------------------- start decode layer 22 --------------------------------
DEBUG 01-06 17:11:13.037067.037067 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-06 17:11:13.037947.037947 mlpmodule.py:367] cuda:1 cuda:1
DEBUG 01-06 17:11:13.038401.038401 cuda_h.py:10] start self_attn
cos shape torch.Size([65, 128]) sin shape torch.Size([65, 128]) position_ids tensor([[0]], device='cuda:1')
cos shape torch.Size([1, 1, 1, 128]) sin shape torch.Size([1, 1, 1, 128])
q_embed shape torch.Size([32, 16, 1, 128]) k_embed shape torch.Size([32, 16, 1, 128])
DEBUG 01-06 17:11:13.040289.040289 cuda_h.py:19] end self_attn cost 0.002324342727661133 seconds
DEBUG 01-06 17:11:13.041214.041214 cuda_h.py:19] end iln_self_attn_paln cost 0.0033545494079589844 seconds
DEBUG 01-06 17:11:13.041143.041143 cuda_h.py:10] start layer_moe_dgenerate_22
DEBUG 01-06 17:11:13.041820.041820 cuda_h.py:10] start gate
DEBUG 01-06 17:11:13.041411.041411 cuda_h.py:19] end gate cost 0.0006053447723388672 seconds
DEBUG 01-06 17:11:13.041440.041440 cuda_h.py:10] start experts_map_get
INFO 01-06 17:11:13.042040.042040 lmp.py:609] using loaded check layer: True
INFO 01-06 17:11:13.042967.042967 lmp.py:620] 
INFO 01-06 17:11:13.042967.042967 lmp.py:620] Layer 22 Expert Device Distribution:
INFO 01-06 17:11:13.042466.042466 lmp.py:621]   Active experts: 52 (out of 64 total)
INFO 01-06 17:11:13.042122.042122 lmp.py:622] 
INFO 01-06 17:11:13.042122.042122 lmp.py:622]   Detailed Expert Distribution:
INFO 01-06 17:11:13.042779.042779 lmp.py:623]   Expert ID  | Tokens     | Actual Device  
INFO 01-06 17:11:13.042859.042859 lmp.py:624]   ----------------------------------------------------------------------
INFO 01-06 17:11:13.042654.042654 lmp.py:627]   3          | 1          |  cuda:1         
INFO 01-06 17:11:13.042973.042973 lmp.py:627]   4          | 1          |  cuda:1         
INFO 01-06 17:11:13.042577.042577 lmp.py:627]   7          | 1          |  cuda:1         
INFO 01-06 17:11:13.042418.042418 lmp.py:627]   8          | 1          |  cuda:1         
INFO 01-06 17:11:13.042545.042545 lmp.py:627]   9          | 1          |  cuda:1         
INFO 01-06 17:11:13.043102.043102 lmp.py:627]   10         | 1          |  meta           
INFO 01-06 17:11:13.043944.043944 lmp.py:627]   12         | 1          |  cuda:1         
INFO 01-06 17:11:13.043024.043024 lmp.py:627]   13         | 1          |  meta           
INFO 01-06 17:11:13.043866.043866 lmp.py:627]   16         | 1          |  cuda:1         
INFO 01-06 17:11:13.043470.043470 lmp.py:627]   19         | 1          |  cuda:1         
INFO 01-06 17:11:13.043596.043596 lmp.py:627]   21         | 1          |  meta           
INFO 01-06 17:11:13.043246.043246 lmp.py:627]   23         | 1          |  cuda:1         
INFO 01-06 17:11:13.043088.043088 lmp.py:627]   29         | 1          |  cuda:1         
INFO 01-06 17:11:13.043976.043976 lmp.py:627]   33         | 1          |  cuda:1         
INFO 01-06 17:11:13.043579.043579 lmp.py:627]   43         | 1          |  meta           
INFO 01-06 17:11:13.043944.043944 lmp.py:627]   51         | 1          |  cuda:1         
INFO 01-06 17:11:13.043025.043025 lmp.py:627]   59         | 1          |  cuda:1         
INFO 01-06 17:11:13.043343.043343 lmp.py:627]   32         | 2          |  cuda:1         
INFO 01-06 17:11:13.043232.043232 lmp.py:627]   38         | 2          |  meta           
INFO 01-06 17:11:13.043120.043120 lmp.py:627]   41         | 2          |  cuda:1         
INFO 01-06 17:11:13.043770.043770 lmp.py:627]   42         | 2          |  meta           
INFO 01-06 17:11:13.043181.043181 lmp.py:627]   47         | 2          |  meta           
INFO 01-06 17:11:13.043069.043069 lmp.py:627]   48         | 2          |  meta           
INFO 01-06 17:11:13.043149.043149 lmp.py:627]   50         | 2          |  meta           
INFO 01-06 17:11:13.043753.043753 lmp.py:627]   52         | 2          |  meta           
INFO 01-06 17:11:13.043356.043356 lmp.py:627]   57         | 2          |  meta           
INFO 01-06 17:11:13.043437.043437 lmp.py:627]   62         | 2          |  meta           
INFO 01-06 17:11:13.043040.043040 lmp.py:627]   63         | 2          |  cuda:1         
INFO 01-06 17:11:13.043167.043167 lmp.py:627]   35         | 3          |  cuda:1         
INFO 01-06 17:11:13.043055.043055 lmp.py:627]   40         | 3          |  cuda:1         
INFO 01-06 17:11:13.043943.043943 lmp.py:627]   49         | 3          |  cuda:1         
INFO 01-06 17:11:13.043070.043070 lmp.py:627]   14         | 4          |  meta           
INFO 01-06 17:11:13.043435.043435 lmp.py:627]   30         | 4          |  cuda:1         
INFO 01-06 17:11:13.043038.043038 lmp.py:627]   44         | 4          |  meta           
INFO 01-06 17:11:13.043641.043641 lmp.py:627]   55         | 4          |  cuda:1         
INFO 01-06 17:11:13.043483.043483 lmp.py:627]   58         | 4          |  cuda:1         
INFO 01-06 17:11:13.043133.043133 lmp.py:627]   20         | 5          |  meta           
INFO 01-06 17:11:13.043544.043544 lmp.py:627]   22         | 5          |  cuda:1         
INFO 01-06 17:11:13.043909.043909 lmp.py:627]   36         | 5          |  meta           
INFO 01-06 17:11:13.043559.043559 lmp.py:627]   37         | 5          |  meta           
INFO 01-06 17:11:13.043209.043209 lmp.py:627]   11         | 6          |  meta           
INFO 01-06 17:11:13.043574.043574 lmp.py:627]   17         | 6          |  cuda:1         
INFO 01-06 17:11:13.043893.043893 lmp.py:627]   26         | 6          |  meta           
INFO 01-06 17:11:13.043258.043258 lmp.py:627]   54         | 6          |  meta           
INFO 01-06 17:11:13.043100.043100 lmp.py:627]   18         | 7          |  cuda:1         
INFO 01-06 17:11:13.043465.043465 lmp.py:627]   27         | 7          |  cuda:1         
INFO 01-06 17:11:13.043353.043353 lmp.py:627]   28         | 7          |  meta           
INFO 01-06 17:11:13.043241.043241 lmp.py:627]   60         | 8          |  cuda:1         
INFO 01-06 17:11:13.044606.044606 lmp.py:627]   34         | 10         |  cuda:1         
INFO 01-06 17:11:13.044256.044256 lmp.py:627]   61         | 10         |  meta           
INFO 01-06 17:11:13.044382.044382 lmp.py:627]   5          | 13         |  cuda:1         
INFO 01-06 17:11:13.044794.044794 lmp.py:627]   56         | 18         |  cuda:1         
INFO 01-06 17:11:13.044443.044443 lmp.py:628] ============================================================
INFO 01-06 17:11:13.044443.044443 lmp.py:628] 
INFO 01-06 17:11:13.044292.044292 lmp.py:630] experts_gpu_list: [3, 4, 7, 8, 9, 12, 16, 19, 23, 29, 33, 51, 59, 32, 41, 63, 35, 40, 49, 30, 55, 58, 22, 17, 18, 27, 60, 34, 5, 56] num: 30
INFO 01-06 17:11:13.044995.044995 lmp.py:631] experts_cpu_list: [10, 13, 21, 43, 38, 42, 47, 48, 50, 52, 57, 62, 14, 44, 20, 36, 37, 11, 26, 54, 28, 61] num: 22
INFO 01-06 17:11:13.044665.044665 lmp.py:632] expert_actual_device_map {0: 'cuda:1', 1: 'cuda:1', 2: 'cuda:1', 3: 'cuda:1', 4: 'cuda:1', 5: 'cuda:1', 6: 'cuda:1', 7: 'cuda:1', 8: 'cuda:1', 9: 'cuda:1', 10: 'meta', 11: 'meta', 12: 'cuda:1', 13: 'meta', 14: 'meta', 15: 'meta', 16: 'cuda:1', 17: 'cuda:1', 18: 'cuda:1', 19: 'cuda:1', 20: 'meta', 21: 'meta', 22: 'cuda:1', 23: 'cuda:1', 24: 'meta', 25: 'meta', 26: 'meta', 27: 'cuda:1', 28: 'meta', 29: 'cuda:1', 30: 'cuda:1', 31: 'cuda:1', 32: 'cuda:1', 33: 'cuda:1', 34: 'cuda:1', 35: 'cuda:1', 36: 'meta', 37: 'meta', 38: 'meta', 39: 'cuda:1', 40: 'cuda:1', 41: 'cuda:1', 42: 'meta', 43: 'meta', 44: 'meta', 45: 'meta', 46: 'meta', 47: 'meta', 48: 'meta', 49: 'cuda:1', 50: 'meta', 51: 'cuda:1', 52: 'meta', 53: 'cuda:1', 54: 'meta', 55: 'cuda:1', 56: 'cuda:1', 57: 'meta', 58: 'cuda:1', 59: 'cuda:1', 60: 'cuda:1', 61: 'meta', 62: 'meta', 63: 'cuda:1'}
DEBUG 01-06 17:11:13.044759.044759 cuda_h.py:19] end experts_map_get cost 0.002379179000854492 seconds
DEBUG 01-06 17:11:13.044331.044331 mlpmodule.py:664]  experts func einsum cost 0.03641819953918457 s
DEBUG 01-06 17:11:13.044719.044719 cuda_h.py:10] start gpu_sexperts
DEBUG 01-06 17:11:13.044424.044424 cuda_h.py:19] end gpu_sexperts cost 0.00033783912658691406 seconds
DEBUG 01-06 17:11:13.044790.044790 cuda_h.py:10] start gpu_experts
DEBUG 01-06 17:11:13.045242.045242 mlpmodule.py:533] gpu group tensors cost 0.0005717277526855469 s
DEBUG 01-06 17:11:13.047103.047103 mlpmodule.py:566] gpu pad cost 0.0015344619750976562 s
DEBUG 01-06 17:11:13.047389.047389 mlpmodule.py:584] gpu group einsum cost 0.0003635883331298828 s
DEBUG 01-06 17:11:13.050307.050307 mlpmodule.py:613] gpu experts func einsum cost 0.0056722164154052734 s
DEBUG 01-06 17:11:13.050482.050482 cuda_h.py:19] end gpu_experts cost 0.005815029144287109 seconds
DEBUG 01-06 17:11:13.050384.050384 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-06 17:11:13.050140.050140 lmp.py:661] 
DEBUG 01-06 17:11:13.050140.050140 lmp.py:661]   Computing 22 experts on CPU...
DEBUG 01-06 17:11:13.050182.050182 cuda_h.py:19] end cpu_experts_submit cost 6.532669067382812e-05 seconds
DEBUG 01-06 17:11:13.050315.050315 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-06 17:11:13.058244.058244 mlpmodule.py:706] group tensors cost 0.007733583450317383 s
DEBUG 01-06 17:11:13.060296.060296 mlpmodule.py:744] pad cost 0.0012142658233642578 s
DEBUG 01-06 17:11:13.060545.060545 mlpmodule.py:750] create cpu tensor cost 4.124641418457031e-05 s
DEBUG 01-06 17:11:13.060779.060779 mlpmodule.py:755] move to cpu cost 2.9087066650390625e-05 s
DEBUG 01-06 17:11:13.063747.063747 mlpmodule.py:769] group_w3: shape=torch.Size([22, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=63438848
DEBUG 01-06 17:11:13.063312.063312 mlpmodule.py:770] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-06 17:11:13.063241.063241 mlpmodule.py:775] group_w3 first element: 0.006866455078125
WARNING 01-06 17:11:13.063111.063111 mlpmodule.py:785] start einsum2
DEBUG 01-06 17:11:13.068729.068729 mlpmodule.py:795] group einsum cost 0.007960796356201172 s
DEBUG 01-06 17:11:13.069630.069630 mlpmodule.py:803] cpy2cputensor cost 0.00013113021850585938 s
DEBUG 01-06 17:11:13.072977.072977 cuda_h.py:19] end wait_cetm_experts cost 0.02104473114013672 seconds
DEBUG 01-06 17:11:13.072633.072633 cuda_h.py:19] end layer_moe_dgenerate_22 cost 0.03139328956604004 seconds
DEBUG 01-06 17:11:13.072625.072625 lmp.py:325] -------------------------------- end decode layer 22 --------------------------------
DEBUG 01-06 17:11:13.072534.072534 lmp.py:298] -------------------------------- start decode layer 23 --------------------------------
DEBUG 01-06 17:11:13.072045.072045 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-06 17:11:13.072367.072367 mlpmodule.py:367] cuda:1 cuda:1
DEBUG 01-06 17:11:13.073353.073353 cuda_h.py:10] start self_attn
cos shape torch.Size([65, 128]) sin shape torch.Size([65, 128]) position_ids tensor([[0]], device='cuda:1')
cos shape torch.Size([1, 1, 1, 128]) sin shape torch.Size([1, 1, 1, 128])
q_embed shape torch.Size([32, 16, 1, 128]) k_embed shape torch.Size([32, 16, 1, 128])
DEBUG 01-06 17:11:13.075444.075444 cuda_h.py:19] end self_attn cost 0.0018641948699951172 seconds
DEBUG 01-06 17:11:13.075031.075031 cuda_h.py:19] end iln_self_attn_paln cost 0.0027277469635009766 seconds
DEBUG 01-06 17:11:13.075152.075152 cuda_h.py:10] start layer_moe_dgenerate_23
DEBUG 01-06 17:11:13.075929.075929 cuda_h.py:10] start gate
DEBUG 01-06 17:11:13.076204.076204 cuda_h.py:19] end gate cost 0.0006477832794189453 seconds
DEBUG 01-06 17:11:13.076855.076855 cuda_h.py:10] start experts_map_get
INFO 01-06 17:11:13.076210.076210 lmp.py:609] using loaded check layer: True
INFO 01-06 17:11:13.077382.077382 lmp.py:620] 
INFO 01-06 17:11:13.077382.077382 lmp.py:620] Layer 23 Expert Device Distribution:
INFO 01-06 17:11:13.077675.077675 lmp.py:621]   Active experts: 47 (out of 64 total)
INFO 01-06 17:11:13.077477.077477 lmp.py:622] 
INFO 01-06 17:11:13.077477.077477 lmp.py:622]   Detailed Expert Distribution:
INFO 01-06 17:11:13.077564.077564 lmp.py:623]   Expert ID  | Tokens     | Actual Device  
INFO 01-06 17:11:13.077598.077598 lmp.py:624]   ----------------------------------------------------------------------
INFO 01-06 17:11:13.077394.077394 lmp.py:627]   1          | 1          |  cuda:1         
INFO 01-06 17:11:13.077474.077474 lmp.py:627]   6          | 1          |  cuda:1         
INFO 01-06 17:11:13.077077.077077 lmp.py:627]   7          | 1          |  cuda:1         
INFO 01-06 17:11:13.077681.077681 lmp.py:627]   11         | 1          |  meta           
INFO 01-06 17:11:13.077238.077238 lmp.py:627]   20         | 1          |  cuda:1         
INFO 01-06 17:11:13.077080.077080 lmp.py:627]   23         | 1          |  meta           
INFO 01-06 17:11:13.077922.077922 lmp.py:627]   29         | 1          |  cuda:1         
INFO 01-06 17:11:13.077287.077287 lmp.py:627]   39         | 1          |  meta           
INFO 01-06 17:11:13.077605.077605 lmp.py:627]   52         | 1          |  meta           
INFO 01-06 17:11:13.077447.077447 lmp.py:627]   53         | 1          |  meta           
INFO 01-06 17:11:13.077051.077051 lmp.py:627]   56         | 1          |  meta           
INFO 01-06 17:11:13.077561.077561 lmp.py:627]   61         | 1          |  cuda:1         
INFO 01-06 17:11:13.077926.077926 lmp.py:627]   62         | 1          |  meta           
INFO 01-06 17:11:13.077053.077053 lmp.py:627]   3          | 2          |  cuda:1         
INFO 01-06 17:11:13.077656.077656 lmp.py:627]   28         | 2          |  meta           
INFO 01-06 17:11:13.077783.077783 lmp.py:627]   31         | 2          |  cuda:1         
INFO 01-06 17:11:13.077910.077910 lmp.py:627]   47         | 2          |  meta           
INFO 01-06 17:11:13.077036.077036 lmp.py:627]   57         | 2          |  meta           
INFO 01-06 17:11:13.077878.077878 lmp.py:627]   2          | 3          |  cuda:1         
INFO 01-06 17:11:13.077481.077481 lmp.py:627]   13         | 3          |  cuda:1         
INFO 01-06 17:11:13.077847.077847 lmp.py:627]   18         | 3          |  cuda:1         
INFO 01-06 17:11:13.077212.077212 lmp.py:627]   35         | 3          |  cuda:1         
INFO 01-06 17:11:13.077100.077100 lmp.py:627]   42         | 3          |  cuda:1         
INFO 01-06 17:11:13.077226.077226 lmp.py:627]   49         | 3          |  meta           
INFO 01-06 17:11:13.078068.078068 lmp.py:627]   8          | 4          |  cuda:1         
INFO 01-06 17:11:13.078433.078433 lmp.py:627]   16         | 4          |  meta           
INFO 01-06 17:11:13.078560.078560 lmp.py:627]   19         | 4          |  cuda:1         
INFO 01-06 17:11:13.078163.078163 lmp.py:627]   22         | 4          |  cuda:1         
INFO 01-06 17:11:13.078528.078528 lmp.py:627]   26         | 5          |  cuda:1         
INFO 01-06 17:11:13.078132.078132 lmp.py:627]   33         | 5          |  meta           
INFO 01-06 17:11:13.078974.078974 lmp.py:627]   45         | 5          |  meta           
INFO 01-06 17:11:13.078339.078339 lmp.py:627]   55         | 5          |  cuda:1         
INFO 01-06 17:11:13.078988.078988 lmp.py:627]   12         | 6          |  cuda:1         
INFO 01-06 17:11:13.078638.078638 lmp.py:627]   34         | 6          |  cuda:1         
INFO 01-06 17:11:13.078288.078288 lmp.py:627]   40         | 6          |  meta           
INFO 01-06 17:11:13.078938.078938 lmp.py:627]   63         | 6          |  meta           
INFO 01-06 17:11:13.078330.078330 lmp.py:627]   25         | 7          |  meta           
INFO 01-06 17:11:13.078364.078364 lmp.py:627]   32         | 7          |  cuda:1         
INFO 01-06 17:11:13.078206.078206 lmp.py:627]   41         | 7          |  cuda:1         
INFO 01-06 17:11:13.078809.078809 lmp.py:627]   44         | 7          |  meta           
INFO 01-06 17:11:13.078697.078697 lmp.py:627]   46         | 7          |  cuda:1         
INFO 01-06 17:11:13.078585.078585 lmp.py:627]   54         | 7          |  cuda:1         
INFO 01-06 17:11:13.078950.078950 lmp.py:627]   24         | 8          |  cuda:1         
INFO 01-06 17:11:13.078554.078554 lmp.py:627]   15         | 9          |  cuda:1         
INFO 01-06 17:11:13.078157.078157 lmp.py:627]   59         | 9          |  cuda:1         
INFO 01-06 17:11:13.078999.078999 lmp.py:627]   4          | 10         |  cuda:1         
INFO 01-06 17:11:13.078841.078841 lmp.py:627]   48         | 13         |  cuda:1         
INFO 01-06 17:11:13.078729.078729 lmp.py:628] ============================================================
INFO 01-06 17:11:13.078729.078729 lmp.py:628] 
INFO 01-06 17:11:13.078816.078816 lmp.py:630] experts_gpu_list: [1, 6, 7, 20, 29, 61, 3, 31, 2, 13, 18, 35, 42, 8, 19, 22, 26, 55, 12, 34, 32, 41, 46, 54, 24, 15, 59, 4, 48] num: 29
INFO 01-06 17:11:13.078850.078850 lmp.py:631] experts_cpu_list: [11, 23, 39, 52, 53, 56, 62, 28, 47, 57, 49, 16, 33, 45, 40, 63, 25, 44] num: 18
INFO 01-06 17:11:13.078044.078044 lmp.py:632] expert_actual_device_map {0: 'cuda:1', 1: 'cuda:1', 2: 'cuda:1', 3: 'cuda:1', 4: 'cuda:1', 5: 'cuda:1', 6: 'cuda:1', 7: 'cuda:1', 8: 'cuda:1', 9: 'cuda:1', 10: 'cuda:1', 11: 'meta', 12: 'cuda:1', 13: 'cuda:1', 14: 'meta', 15: 'cuda:1', 16: 'meta', 17: 'meta', 18: 'cuda:1', 19: 'cuda:1', 20: 'cuda:1', 21: 'meta', 22: 'cuda:1', 23: 'meta', 24: 'cuda:1', 25: 'meta', 26: 'cuda:1', 27: 'meta', 28: 'meta', 29: 'cuda:1', 30: 'cuda:1', 31: 'cuda:1', 32: 'cuda:1', 33: 'meta', 34: 'cuda:1', 35: 'cuda:1', 36: 'cuda:1', 37: 'meta', 38: 'meta', 39: 'meta', 40: 'meta', 41: 'cuda:1', 42: 'cuda:1', 43: 'cuda:1', 44: 'meta', 45: 'meta', 46: 'cuda:1', 47: 'meta', 48: 'cuda:1', 49: 'meta', 50: 'cuda:1', 51: 'meta', 52: 'meta', 53: 'meta', 54: 'cuda:1', 55: 'cuda:1', 56: 'meta', 57: 'meta', 58: 'meta', 59: 'cuda:1', 60: 'meta', 61: 'cuda:1', 62: 'meta', 63: 'meta'}
DEBUG 01-06 17:11:13.078045.078045 cuda_h.py:19] end experts_map_get cost 0.0022656917572021484 seconds
DEBUG 01-06 17:11:13.078875.078875 mlpmodule.py:664]  experts func einsum cost 0.027596473693847656 s
DEBUG 01-06 17:11:13.078581.078581 cuda_h.py:10] start gpu_sexperts
DEBUG 01-06 17:11:13.079412.079412 cuda_h.py:19] end gpu_sexperts cost 0.00033593177795410156 seconds
DEBUG 01-06 17:11:13.079063.079063 cuda_h.py:10] start gpu_experts
DEBUG 01-06 17:11:13.080456.080456 mlpmodule.py:533] gpu group tensors cost 0.0005633831024169922 s
DEBUG 01-06 17:11:13.081926.081926 mlpmodule.py:566] gpu pad cost 0.0015256404876708984 s
DEBUG 01-06 17:11:13.082434.082434 mlpmodule.py:584] gpu group einsum cost 0.00048542022705078125 s
DEBUG 01-06 17:11:13.085098.085098 mlpmodule.py:613] gpu experts func einsum cost 0.005706071853637695 s
DEBUG 01-06 17:11:13.085737.085737 cuda_h.py:19] end gpu_experts cost 0.00583648681640625 seconds
DEBUG 01-06 17:11:13.085347.085347 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-06 17:11:13.085110.085110 lmp.py:661] 
DEBUG 01-06 17:11:13.085110.085110 lmp.py:661]   Computing 18 experts on CPU...
DEBUG 01-06 17:11:13.085568.085568 cuda_h.py:19] end cpu_experts_submit cost 6.222724914550781e-05 seconds
DEBUG 01-06 17:11:13.085841.085841 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-06 17:11:13.093935.093935 mlpmodule.py:706] group tensors cost 0.007997512817382812 s
DEBUG 01-06 17:11:13.095477.095477 mlpmodule.py:744] pad cost 0.000965118408203125 s
DEBUG 01-06 17:11:13.095805.095805 mlpmodule.py:750] create cpu tensor cost 4.124641418457031e-05 s
DEBUG 01-06 17:11:13.095416.095416 mlpmodule.py:755] move to cpu cost 2.956390380859375e-05 s
DEBUG 01-06 17:11:13.097582.097582 mlpmodule.py:769] group_w3: shape=torch.Size([18, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=51904512
DEBUG 01-06 17:11:13.097962.097962 mlpmodule.py:770] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-06 17:11:13.098368.098368 mlpmodule.py:775] group_w3 first element: 0.01324462890625
WARNING 01-06 17:11:13.098430.098430 mlpmodule.py:785] start einsum2
DEBUG 01-06 17:11:13.102289.102289 mlpmodule.py:795] group einsum cost 0.007028102874755859 s
DEBUG 01-06 17:11:13.102234.102234 mlpmodule.py:803] cpy2cputensor cost 6.985664367675781e-05 s
DEBUG 01-06 17:11:13.105386.105386 cuda_h.py:19] end wait_cetm_experts cost 0.01956033706665039 seconds
DEBUG 01-06 17:11:13.105969.105969 cuda_h.py:19] end layer_moe_dgenerate_23 cost 0.029874086380004883 seconds
DEBUG 01-06 17:11:13.105948.105948 lmp.py:325] -------------------------------- end decode layer 23 --------------------------------
DEBUG 01-06 17:11:13.105525.105525 lmp.py:298] -------------------------------- start decode layer 24 --------------------------------
DEBUG 01-06 17:11:13.105089.105089 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-06 17:11:13.105351.105351 mlpmodule.py:367] cuda:1 cuda:1
DEBUG 01-06 17:11:13.106053.106053 cuda_h.py:10] start self_attn
cos shape torch.Size([65, 128]) sin shape torch.Size([65, 128]) position_ids tensor([[0]], device='cuda:1')
cos shape torch.Size([1, 1, 1, 128]) sin shape torch.Size([1, 1, 1, 128])
q_embed shape torch.Size([32, 16, 1, 128]) k_embed shape torch.Size([32, 16, 1, 128])
DEBUG 01-06 17:11:13.108615.108615 cuda_h.py:19] end self_attn cost 0.0018885135650634766 seconds
DEBUG 01-06 17:11:13.108092.108092 cuda_h.py:19] end iln_self_attn_paln cost 0.0028066635131835938 seconds
DEBUG 01-06 17:11:13.108213.108213 cuda_h.py:10] start layer_moe_dgenerate_24
DEBUG 01-06 17:11:13.108366.108366 cuda_h.py:10] start gate
DEBUG 01-06 17:11:13.109825.109825 cuda_h.py:19] end gate cost 0.0006144046783447266 seconds
DEBUG 01-06 17:11:13.109390.109390 cuda_h.py:10] start experts_map_get
INFO 01-06 17:11:13.109163.109163 lmp.py:609] using loaded check layer: True
DEBUG 01-06 17:11:13.109855.109855 mlpmodule.py:664]  experts func einsum cost 0.02421116828918457 s
INFO 01-06 17:11:13.110935.110935 lmp.py:620] 
INFO 01-06 17:11:13.110935.110935 lmp.py:620] Layer 24 Expert Device Distribution:
INFO 01-06 17:11:13.110888.110888 lmp.py:621]   Active experts: 49 (out of 64 total)
INFO 01-06 17:11:13.110313.110313 lmp.py:622] 
INFO 01-06 17:11:13.110313.110313 lmp.py:622]   Detailed Expert Distribution:
INFO 01-06 17:11:13.110388.110388 lmp.py:623]   Expert ID  | Tokens     | Actual Device  
INFO 01-06 17:11:13.110137.110137 lmp.py:624]   ----------------------------------------------------------------------
INFO 01-06 17:11:13.110740.110740 lmp.py:627]   5          | 1          |  cuda:1         
INFO 01-06 17:11:13.110436.110436 lmp.py:627]   13         | 1          |  meta           
INFO 01-06 17:11:13.110417.110417 lmp.py:627]   15         | 1          |  meta           
INFO 01-06 17:11:13.110590.110590 lmp.py:627]   18         | 1          |  cuda:1         
INFO 01-06 17:11:13.110048.110048 lmp.py:627]   21         | 1          |  cuda:1         
INFO 01-06 17:11:13.110221.110221 lmp.py:627]   28         | 1          |  cuda:1         
INFO 01-06 17:11:13.110917.110917 lmp.py:627]   31         | 1          |  cuda:1         
INFO 01-06 17:11:13.110898.110898 lmp.py:627]   33         | 1          |  meta           
INFO 01-06 17:11:13.110402.110402 lmp.py:627]   36         | 1          |  meta           
INFO 01-06 17:11:13.110144.110144 lmp.py:627]   38         | 1          |  meta           
INFO 01-06 17:11:13.110648.110648 lmp.py:627]   39         | 1          |  meta           
INFO 01-06 17:11:13.110390.110390 lmp.py:627]   45         | 1          |  cuda:1         
INFO 01-06 17:11:13.110133.110133 lmp.py:627]   48         | 1          |  meta           
INFO 01-06 17:11:13.111352.111352 lmp.py:627]   52         | 1          |  cuda:1         
INFO 01-06 17:11:13.111571.111571 lmp.py:627]   57         | 1          |  cuda:1         
INFO 01-06 17:11:13.111029.111029 lmp.py:627]   62         | 1          |  meta           
INFO 01-06 17:11:13.111248.111248 lmp.py:627]   2          | 2          |  cuda:1         
INFO 01-06 17:11:13.111991.111991 lmp.py:627]   10         | 2          |  cuda:1         
INFO 01-06 17:11:13.111495.111495 lmp.py:627]   24         | 2          |  meta           
INFO 01-06 17:11:13.111283.111283 lmp.py:627]   35         | 2          |  meta           
INFO 01-06 17:11:13.111549.111549 lmp.py:627]   44         | 2          |  meta           
INFO 01-06 17:11:13.111815.111815 lmp.py:627]   55         | 2          |  meta           
INFO 01-06 17:11:13.111319.111319 lmp.py:627]   60         | 2          |  cuda:1         
INFO 01-06 17:11:13.111776.111776 lmp.py:627]   11         | 3          |  cuda:1         
INFO 01-06 17:11:13.111472.111472 lmp.py:627]   22         | 3          |  cuda:1         
INFO 01-06 17:11:13.111407.111407 lmp.py:627]   27         | 3          |  cuda:1         
INFO 01-06 17:11:13.111865.111865 lmp.py:627]   46         | 3          |  meta           
INFO 01-06 17:11:13.111369.111369 lmp.py:627]   61         | 3          |  meta           
INFO 01-06 17:11:13.111157.111157 lmp.py:627]   63         | 3          |  cuda:1         
INFO 01-06 17:11:13.111661.111661 lmp.py:627]   26         | 4          |  cuda:1         
INFO 01-06 17:11:13.111165.111165 lmp.py:627]   29         | 4          |  meta           
INFO 01-06 17:11:13.111431.111431 lmp.py:627]   49         | 4          |  cuda:1         
INFO 01-06 17:11:13.111935.111935 lmp.py:627]   56         | 4          |  meta           
INFO 01-06 17:11:13.111392.111392 lmp.py:627]   14         | 5          |  cuda:1         
INFO 01-06 17:11:13.111850.111850 lmp.py:627]   40         | 5          |  cuda:1         
INFO 01-06 17:11:13.111831.111831 lmp.py:627]   41         | 5          |  cuda:1         
INFO 01-06 17:11:13.111527.111527 lmp.py:627]   8          | 6          |  cuda:1         
INFO 01-06 17:11:13.111554.111554 lmp.py:627]   12         | 6          |  cuda:1         
INFO 01-06 17:11:13.111820.111820 lmp.py:627]   6          | 7          |  cuda:1         
INFO 01-06 17:11:13.111847.111847 lmp.py:627]   7          | 7          |  cuda:1         
INFO 01-06 17:11:13.111874.111874 lmp.py:627]   58         | 7          |  cuda:1         
INFO 01-06 17:11:13.111140.111140 lmp.py:627]   23         | 8          |  cuda:1         
INFO 01-06 17:11:13.111928.111928 lmp.py:627]   0          | 9          |  cuda:1         
INFO 01-06 17:11:13.111956.111956 lmp.py:627]   9          | 9          |  meta           
INFO 01-06 17:11:13.111221.111221 lmp.py:627]   34         | 9          |  cuda:1         
INFO 01-06 17:11:13.111202.111202 lmp.py:627]   50         | 9          |  cuda:1         
INFO 01-06 17:11:13.111421.111421 lmp.py:627]   20         | 11         |  meta           
INFO 01-06 17:11:13.111402.111402 lmp.py:627]   32         | 11         |  cuda:1         
INFO 01-06 17:11:13.111145.111145 lmp.py:627]   3          | 14         |  cuda:1         
INFO 01-06 17:11:13.111933.111933 lmp.py:628] ============================================================
INFO 01-06 17:11:13.111933.111933 lmp.py:628] 
INFO 01-06 17:11:13.111682.111682 lmp.py:630] experts_gpu_list: [5, 18, 21, 28, 31, 45, 52, 57, 2, 10, 60, 11, 22, 27, 63, 26, 49, 14, 40, 41, 8, 12, 6, 7, 58, 23, 0, 34, 50, 32, 3] num: 31
INFO 01-06 17:11:13.111094.111094 lmp.py:631] experts_cpu_list: [13, 15, 33, 36, 38, 39, 48, 62, 24, 35, 44, 55, 46, 61, 29, 56, 9, 20] num: 18
INFO 01-06 17:11:13.111188.111188 lmp.py:632] expert_actual_device_map {0: 'cuda:1', 1: 'cuda:1', 2: 'cuda:1', 3: 'cuda:1', 4: 'cuda:1', 5: 'cuda:1', 6: 'cuda:1', 7: 'cuda:1', 8: 'cuda:1', 9: 'meta', 10: 'cuda:1', 11: 'cuda:1', 12: 'cuda:1', 13: 'meta', 14: 'cuda:1', 15: 'meta', 16: 'meta', 17: 'cuda:1', 18: 'cuda:1', 19: 'cuda:1', 20: 'meta', 21: 'cuda:1', 22: 'cuda:1', 23: 'cuda:1', 24: 'meta', 25: 'meta', 26: 'cuda:1', 27: 'cuda:1', 28: 'cuda:1', 29: 'meta', 30: 'meta', 31: 'cuda:1', 32: 'cuda:1', 33: 'meta', 34: 'cuda:1', 35: 'meta', 36: 'meta', 37: 'cuda:1', 38: 'meta', 39: 'meta', 40: 'cuda:1', 41: 'cuda:1', 42: 'meta', 43: 'meta', 44: 'meta', 45: 'cuda:1', 46: 'meta', 47: 'meta', 48: 'meta', 49: 'cuda:1', 50: 'cuda:1', 51: 'meta', 52: 'cuda:1', 53: 'cuda:1', 54: 'meta', 55: 'meta', 56: 'meta', 57: 'cuda:1', 58: 'cuda:1', 59: 'meta', 60: 'cuda:1', 61: 'meta', 62: 'meta', 63: 'cuda:1'}
DEBUG 01-06 17:11:13.111666.111666 cuda_h.py:19] end experts_map_get cost 0.002443552017211914 seconds
DEBUG 01-06 17:11:13.111874.111874 cuda_h.py:10] start gpu_sexperts
DEBUG 01-06 17:11:13.112979.112979 cuda_h.py:19] end gpu_sexperts cost 0.00031828880310058594 seconds
DEBUG 01-06 17:11:13.112616.112616 cuda_h.py:10] start gpu_experts
DEBUG 01-06 17:11:13.113877.113877 mlpmodule.py:533] gpu group tensors cost 0.000591278076171875 s
DEBUG 01-06 17:11:13.114329.114329 mlpmodule.py:566] gpu pad cost 0.0015828609466552734 s
DEBUG 01-06 17:11:13.115732.115732 mlpmodule.py:584] gpu group einsum cost 0.0004780292510986328 s
DEBUG 01-06 17:11:13.118953.118953 mlpmodule.py:613] gpu experts func einsum cost 0.0060176849365234375 s
DEBUG 01-06 17:11:13.118492.118492 cuda_h.py:19] end gpu_experts cost 0.006164073944091797 seconds
DEBUG 01-06 17:11:13.118970.118970 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-06 17:11:13.118435.118435 lmp.py:661] 
DEBUG 01-06 17:11:13.118435.118435 lmp.py:661]   Computing 18 experts on CPU...
DEBUG 01-06 17:11:13.118364.118364 cuda_h.py:19] end cpu_experts_submit cost 5.221366882324219e-05 seconds
DEBUG 01-06 17:11:13.118583.118583 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-06 17:11:13.128271.128271 mlpmodule.py:706] group tensors cost 0.009494304656982422 s
DEBUG 01-06 17:11:13.130679.130679 mlpmodule.py:744] pad cost 0.001154184341430664 s
DEBUG 01-06 17:11:13.130484.130484 mlpmodule.py:750] create cpu tensor cost 4.267692565917969e-05 s
DEBUG 01-06 17:11:13.130526.130526 mlpmodule.py:755] move to cpu cost 3.0279159545898438e-05 s
DEBUG 01-06 17:11:13.132485.132485 mlpmodule.py:769] group_w3: shape=torch.Size([18, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=51904512
DEBUG 01-06 17:11:13.133335.133335 mlpmodule.py:770] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-06 17:11:13.133509.133509 mlpmodule.py:775] group_w3 first element: -0.0247802734375
WARNING 01-06 17:11:13.133108.133108 mlpmodule.py:785] start einsum2
DEBUG 01-06 17:11:13.137569.137569 mlpmodule.py:795] group einsum cost 0.006592988967895508 s
DEBUG 01-06 17:11:13.137603.137603 mlpmodule.py:803] cpy2cputensor cost 0.00012755393981933594 s
DEBUG 01-06 17:11:13.140085.140085 cuda_h.py:19] end wait_cetm_experts cost 0.021224498748779297 seconds
DEBUG 01-06 17:11:13.140344.140344 cuda_h.py:19] end layer_moe_dgenerate_24 cost 0.03194999694824219 seconds
DEBUG 01-06 17:11:13.141032.141032 lmp.py:325] -------------------------------- end decode layer 24 --------------------------------
DEBUG 01-06 17:11:13.141420.141420 lmp.py:298] -------------------------------- start decode layer 25 --------------------------------
DEBUG 01-06 17:11:13.141257.141257 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-06 17:11:13.141113.141113 mlpmodule.py:367] cuda:1 cuda:1
DEBUG 01-06 17:11:13.142233.142233 cuda_h.py:10] start self_attn
cos shape torch.Size([65, 128]) sin shape torch.Size([65, 128]) position_ids tensor([[0]], device='cuda:1')
cos shape torch.Size([1, 1, 1, 128]) sin shape torch.Size([1, 1, 1, 128])
q_embed shape torch.Size([32, 16, 1, 128]) k_embed shape torch.Size([32, 16, 1, 128])
DEBUG 01-06 17:11:13.144122.144122 cuda_h.py:19] end self_attn cost 0.0023317337036132812 seconds
DEBUG 01-06 17:11:13.144193.144193 mlpmodule.py:664]  experts func einsum cost 0.025788307189941406 s
DEBUG 01-06 17:11:13.145103.145103 cuda_h.py:19] end iln_self_attn_paln cost 0.003786325454711914 seconds
DEBUG 01-06 17:11:13.145027.145027 cuda_h.py:10] start layer_moe_dgenerate_25
DEBUG 01-06 17:11:13.145771.145771 cuda_h.py:10] start gate
DEBUG 01-06 17:11:13.146101.146101 cuda_h.py:19] end gate cost 0.0007166862487792969 seconds
DEBUG 01-06 17:11:13.146150.146150 cuda_h.py:10] start experts_map_get
INFO 01-06 17:11:13.146726.146726 lmp.py:609] using loaded check layer: True
INFO 01-06 17:11:13.147300.147300 lmp.py:620] 
INFO 01-06 17:11:13.147300.147300 lmp.py:620] Layer 25 Expert Device Distribution:
INFO 01-06 17:11:13.147792.147792 lmp.py:621]   Active experts: 45 (out of 64 total)
INFO 01-06 17:11:13.147217.147217 lmp.py:622] 
INFO 01-06 17:11:13.147217.147217 lmp.py:622]   Detailed Expert Distribution:
INFO 01-06 17:11:13.147311.147311 lmp.py:623]   Expert ID  | Tokens     | Actual Device  
INFO 01-06 17:11:13.147875.147875 lmp.py:624]   ----------------------------------------------------------------------
INFO 01-06 17:11:13.147154.147154 lmp.py:627]   7          | 1          |  cuda:1         
INFO 01-06 17:11:13.147241.147241 lmp.py:627]   8          | 1          |  meta           
INFO 01-06 17:11:13.147374.147374 lmp.py:627]   9          | 1          |  meta           
INFO 01-06 17:11:13.147746.147746 lmp.py:627]   14         | 1          |  cuda:1         
INFO 01-06 17:11:13.147502.147502 lmp.py:627]   30         | 1          |  cuda:1         
INFO 01-06 17:11:13.147351.147351 lmp.py:627]   33         | 1          |  meta           
INFO 01-06 17:11:13.147438.147438 lmp.py:627]   36         | 1          |  meta           
INFO 01-06 17:11:13.147094.147094 lmp.py:627]   37         | 1          |  cuda:1         
INFO 01-06 17:11:13.147228.147228 lmp.py:627]   41         | 1          |  meta           
INFO 01-06 17:11:13.147123.147123 lmp.py:627]   44         | 1          |  meta           
INFO 01-06 17:11:13.147018.147018 lmp.py:627]   45         | 1          |  meta           
INFO 01-06 17:11:13.147390.147390 lmp.py:627]   46         | 1          |  meta           
INFO 01-06 17:11:13.147477.147477 lmp.py:627]   51         | 1          |  meta           
INFO 01-06 17:11:13.147802.147802 lmp.py:627]   52         | 1          |  cuda:1         
INFO 01-06 17:11:13.147128.147128 lmp.py:627]   56         | 1          |  cuda:1         
INFO 01-06 17:11:13.147261.147261 lmp.py:627]   62         | 1          |  cuda:1         
INFO 01-06 17:11:13.147156.147156 lmp.py:627]   1          | 2          |  cuda:1         
INFO 01-06 17:11:13.147289.147289 lmp.py:627]   3          | 2          |  cuda:1         
INFO 01-06 17:11:13.147707.147707 lmp.py:627]   10         | 2          |  meta           
INFO 01-06 17:11:13.147364.147364 lmp.py:627]   11         | 2          |  cuda:1         
INFO 01-06 17:11:13.147213.147213 lmp.py:627]   17         | 2          |  cuda:1         
INFO 01-06 17:11:13.148777.148777 lmp.py:627]   18         | 2          |  meta           
INFO 01-06 17:11:13.148864.148864 lmp.py:627]   22         | 2          |  meta           
INFO 01-06 17:11:13.148759.148759 lmp.py:627]   29         | 2          |  cuda:1         
INFO 01-06 17:11:13.148177.148177 lmp.py:627]   47         | 2          |  cuda:1         
INFO 01-06 17:11:13.148833.148833 lmp.py:627]   48         | 2          |  meta           
INFO 01-06 17:11:13.148920.148920 lmp.py:627]   4          | 3          |  cuda:1         
INFO 01-06 17:11:13.148007.148007 lmp.py:627]   12         | 3          |  cuda:1         
INFO 01-06 17:11:13.148618.148618 lmp.py:627]   27         | 4          |  cuda:1         
INFO 01-06 17:11:13.148274.148274 lmp.py:627]   31         | 4          |  meta           
INFO 01-06 17:11:13.148454.148454 lmp.py:627]   34         | 4          |  cuda:1         
INFO 01-06 17:11:13.148634.148634 lmp.py:627]   49         | 4          |  cuda:1         
INFO 01-06 17:11:13.148052.148052 lmp.py:627]   21         | 5          |  meta           
INFO 01-06 17:11:13.148232.148232 lmp.py:627]   60         | 5          |  cuda:1         
INFO 01-06 17:11:13.148888.148888 lmp.py:627]   53         | 6          |  cuda:1         
INFO 01-06 17:11:13.148302.148302 lmp.py:627]   35         | 7          |  cuda:1         
INFO 01-06 17:11:13.148435.148435 lmp.py:627]   57         | 7          |  cuda:1         
INFO 01-06 17:11:13.148853.148853 lmp.py:627]   0          | 9          |  cuda:1         
INFO 01-06 17:11:13.148033.148033 lmp.py:627]   43         | 9          |  meta           
INFO 01-06 17:11:13.148451.148451 lmp.py:627]   6          | 11         |  cuda:1         
INFO 01-06 17:11:13.148869.148869 lmp.py:627]   54         | 12         |  cuda:1         
INFO 01-06 17:11:13.148718.148718 lmp.py:627]   39         | 13         |  cuda:1         
INFO 01-06 17:11:13.148567.148567 lmp.py:627]   63         | 16         |  cuda:1         
INFO 01-06 17:11:13.148177.148177 lmp.py:627]   26         | 17         |  meta           
INFO 01-06 17:11:13.148833.148833 lmp.py:627]   58         | 17         |  cuda:1         
INFO 01-06 17:11:13.148536.148536 lmp.py:628] ============================================================
INFO 01-06 17:11:13.148536.148536 lmp.py:628] 
INFO 01-06 17:11:13.148676.148676 lmp.py:630] experts_gpu_list: [7, 14, 30, 37, 52, 56, 62, 1, 3, 11, 17, 29, 47, 4, 12, 27, 34, 49, 60, 53, 35, 57, 0, 6, 54, 39, 63, 58] num: 28
INFO 01-06 17:11:13.148717.148717 lmp.py:631] experts_cpu_list: [8, 9, 33, 36, 41, 44, 45, 46, 51, 10, 18, 22, 48, 31, 21, 43, 26] num: 17
INFO 01-06 17:11:13.148255.148255 lmp.py:632] expert_actual_device_map {0: 'cuda:1', 1: 'cuda:1', 2: 'cuda:1', 3: 'cuda:1', 4: 'cuda:1', 5: 'cuda:1', 6: 'cuda:1', 7: 'cuda:1', 8: 'meta', 9: 'meta', 10: 'meta', 11: 'cuda:1', 12: 'cuda:1', 13: 'meta', 14: 'cuda:1', 15: 'cuda:1', 16: 'meta', 17: 'cuda:1', 18: 'meta', 19: 'cuda:1', 20: 'cuda:1', 21: 'meta', 22: 'meta', 23: 'meta', 24: 'meta', 25: 'meta', 26: 'meta', 27: 'cuda:1', 28: 'cuda:1', 29: 'cuda:1', 30: 'cuda:1', 31: 'meta', 32: 'cuda:1', 33: 'meta', 34: 'cuda:1', 35: 'cuda:1', 36: 'meta', 37: 'cuda:1', 38: 'meta', 39: 'cuda:1', 40: 'cuda:1', 41: 'meta', 42: 'meta', 43: 'meta', 44: 'meta', 45: 'meta', 46: 'meta', 47: 'cuda:1', 48: 'meta', 49: 'cuda:1', 50: 'cuda:1', 51: 'meta', 52: 'cuda:1', 53: 'cuda:1', 54: 'cuda:1', 55: 'meta', 56: 'cuda:1', 57: 'cuda:1', 58: 'cuda:1', 59: 'meta', 60: 'cuda:1', 61: 'meta', 62: 'cuda:1', 63: 'cuda:1'}
DEBUG 01-06 17:11:13.148363.148363 cuda_h.py:19] end experts_map_get cost 0.002744913101196289 seconds
DEBUG 01-06 17:11:13.148114.148114 cuda_h.py:10] start gpu_sexperts
DEBUG 01-06 17:11:13.149328.149328 cuda_h.py:19] end gpu_sexperts cost 0.0003879070281982422 seconds
DEBUG 01-06 17:11:13.149032.149032 cuda_h.py:10] start gpu_experts
DEBUG 01-06 17:11:13.150290.150290 mlpmodule.py:533] gpu group tensors cost 0.0006949901580810547 s
DEBUG 01-06 17:11:13.152792.152792 mlpmodule.py:566] gpu pad cost 0.0018928050994873047 s
DEBUG 01-06 17:11:13.152726.152726 mlpmodule.py:584] gpu group einsum cost 0.0005173683166503906 s
DEBUG 01-06 17:11:13.155595.155595 mlpmodule.py:613] gpu experts func einsum cost 0.006256580352783203 s
DEBUG 01-06 17:11:13.155525.155525 cuda_h.py:19] end gpu_experts cost 0.006398439407348633 seconds
DEBUG 01-06 17:11:13.155950.155950 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-06 17:11:13.155229.155229 lmp.py:661] 
DEBUG 01-06 17:11:13.155229.155229 lmp.py:661]   Computing 17 experts on CPU...
DEBUG 01-06 17:11:13.156410.156410 cuda_h.py:19] end cpu_experts_submit cost 6.318092346191406e-05 seconds
DEBUG 01-06 17:11:13.156968.156968 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-06 17:11:13.164285.164285 mlpmodule.py:706] group tensors cost 0.008510589599609375 s
DEBUG 01-06 17:11:13.166519.166519 mlpmodule.py:744] pad cost 0.0009596347808837891 s
DEBUG 01-06 17:11:13.166900.166900 mlpmodule.py:750] create cpu tensor cost 4.315376281738281e-05 s
DEBUG 01-06 17:11:13.166803.166803 mlpmodule.py:755] move to cpu cost 3.1948089599609375e-05 s
DEBUG 01-06 17:11:13.169433.169433 mlpmodule.py:769] group_w3: shape=torch.Size([17, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=49020928
DEBUG 01-06 17:11:13.169158.169158 mlpmodule.py:770] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-06 17:11:13.169862.169862 mlpmodule.py:775] group_w3 first element: -0.046875
WARNING 01-06 17:11:13.169514.169514 mlpmodule.py:785] start einsum2
DEBUG 01-06 17:11:13.173625.173625 mlpmodule.py:795] group einsum cost 0.007305145263671875 s
DEBUG 01-06 17:11:13.174936.174936 mlpmodule.py:803] cpy2cputensor cost 0.00012636184692382812 s
DEBUG 01-06 17:11:13.176120.176120 cuda_h.py:19] end wait_cetm_experts cost 0.02049994468688965 seconds
DEBUG 01-06 17:11:13.177974.177974 cuda_h.py:19] end layer_moe_dgenerate_25 cost 0.03179311752319336 seconds
DEBUG 01-06 17:11:13.177715.177715 lmp.py:325] -------------------------------- end decode layer 25 --------------------------------
DEBUG 01-06 17:11:13.177862.177862 lmp.py:298] -------------------------------- start decode layer 26 --------------------------------
DEBUG 01-06 17:11:13.177803.177803 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-06 17:11:13.177297.177297 mlpmodule.py:367] cuda:1 cuda:1
DEBUG 01-06 17:11:13.177707.177707 cuda_h.py:10] start self_attn
cos shape torch.Size([65, 128]) sin shape torch.Size([65, 128]) position_ids tensor([[0]], device='cuda:1')
cos shape torch.Size([1, 1, 1, 128]) sin shape torch.Size([1, 1, 1, 128])
q_embed shape torch.Size([32, 16, 1, 128]) k_embed shape torch.Size([32, 16, 1, 128])
DEBUG 01-06 17:11:13.179619.179619 cuda_h.py:19] end self_attn cost 0.001871347427368164 seconds
DEBUG 01-06 17:11:13.180127.180127 cuda_h.py:19] end iln_self_attn_paln cost 0.0027306079864501953 seconds
DEBUG 01-06 17:11:13.180156.180156 cuda_h.py:10] start layer_moe_dgenerate_26
DEBUG 01-06 17:11:13.180356.180356 cuda_h.py:10] start gate
DEBUG 01-06 17:11:13.180461.180461 mlpmodule.py:664]  experts func einsum cost 0.02446460723876953 s
DEBUG 01-06 17:11:13.180596.180596 cuda_h.py:19] end gate cost 0.0007905960083007812 seconds
DEBUG 01-06 17:11:13.181454.181454 cuda_h.py:10] start experts_map_get
INFO 01-06 17:11:13.181226.181226 lmp.py:609] using loaded check layer: True
INFO 01-06 17:11:13.181556.181556 lmp.py:620] 
INFO 01-06 17:11:13.181556.181556 lmp.py:620] Layer 26 Expert Device Distribution:
INFO 01-06 17:11:13.182557.182557 lmp.py:621]   Active experts: 49 (out of 64 total)
INFO 01-06 17:11:13.182399.182399 lmp.py:622] 
INFO 01-06 17:11:13.182399.182399 lmp.py:622]   Detailed Expert Distribution:
INFO 01-06 17:11:13.182864.182864 lmp.py:623]   Expert ID  | Tokens     | Actual Device  
INFO 01-06 17:11:13.182520.182520 lmp.py:624]   ----------------------------------------------------------------------
INFO 01-06 17:11:13.182885.182885 lmp.py:627]   1          | 1          |  cuda:1         
INFO 01-06 17:11:13.182105.182105 lmp.py:627]   2          | 1          |  cuda:1         
INFO 01-06 17:11:13.182085.182085 lmp.py:627]   4          | 1          |  cuda:1         
INFO 01-06 17:11:13.182066.182066 lmp.py:627]   6          | 1          |  cuda:1         
INFO 01-06 17:11:13.182570.182570 lmp.py:627]   9          | 1          |  meta           
INFO 01-06 17:11:13.182359.182359 lmp.py:627]   14         | 1          |  cuda:1         
INFO 01-06 17:11:13.182625.182625 lmp.py:627]   15         | 1          |  meta           
INFO 01-06 17:11:13.182082.182082 lmp.py:627]   16         | 1          |  cuda:1         
INFO 01-06 17:11:13.182017.182017 lmp.py:627]   17         | 1          |  meta           
INFO 01-06 17:11:13.182998.182998 lmp.py:627]   25         | 1          |  cuda:1         
INFO 01-06 17:11:13.182455.182455 lmp.py:627]   34         | 1          |  meta           
INFO 01-06 17:11:13.182721.182721 lmp.py:627]   46         | 1          |  cuda:1         
INFO 01-06 17:11:13.182225.182225 lmp.py:627]   50         | 1          |  meta           
INFO 01-06 17:11:13.182490.182490 lmp.py:627]   53         | 1          |  cuda:1         
INFO 01-06 17:11:13.182518.182518 lmp.py:627]   8          | 2          |  cuda:1         
INFO 01-06 17:11:13.182783.182783 lmp.py:627]   11         | 2          |  meta           
INFO 01-06 17:11:13.182049.182049 lmp.py:627]   22         | 2          |  meta           
INFO 01-06 17:11:13.182268.182268 lmp.py:627]   23         | 2          |  meta           
INFO 01-06 17:11:13.182726.182726 lmp.py:627]   24         | 2          |  meta           
INFO 01-06 17:11:13.182707.182707 lmp.py:627]   30         | 2          |  meta           
INFO 01-06 17:11:13.182164.182164 lmp.py:627]   33         | 2          |  cuda:1         
INFO 01-06 17:11:13.182430.182430 lmp.py:627]   35         | 2          |  cuda:1         
INFO 01-06 17:11:13.182695.182695 lmp.py:627]   39         | 2          |  meta           
INFO 01-06 17:11:13.182723.182723 lmp.py:627]   43         | 2          |  cuda:1         
INFO 01-06 17:11:13.182988.182988 lmp.py:627]   44         | 2          |  cuda:1         
INFO 01-06 17:11:13.182254.182254 lmp.py:627]   48         | 2          |  meta           
INFO 01-06 17:11:13.182758.182758 lmp.py:627]   60         | 2          |  cuda:1         
INFO 01-06 17:11:13.182739.182739 lmp.py:627]   0          | 3          |  cuda:1         
INFO 01-06 17:11:13.182196.182196 lmp.py:627]   3          | 3          |  cuda:1         
INFO 01-06 17:11:13.182415.182415 lmp.py:627]   13         | 3          |  cuda:1         
INFO 01-06 17:11:13.182396.182396 lmp.py:627]   40         | 3          |  cuda:1         
INFO 01-06 17:11:13.182662.182662 lmp.py:627]   62         | 3          |  meta           
INFO 01-06 17:11:13.182927.182927 lmp.py:627]   18         | 4          |  cuda:1         
INFO 01-06 17:11:13.182716.182716 lmp.py:627]   29         | 4          |  meta           
INFO 01-06 17:11:13.182982.182982 lmp.py:627]   52         | 5          |  cuda:1         
INFO 01-06 17:11:13.182009.182009 lmp.py:627]   56         | 5          |  cuda:1         
INFO 01-06 17:11:13.182275.182275 lmp.py:627]   58         | 5          |  cuda:1         
INFO 01-06 17:11:13.182255.182255 lmp.py:627]   63         | 5          |  meta           
INFO 01-06 17:11:13.182475.182475 lmp.py:627]   28         | 6          |  cuda:1         
INFO 01-06 17:11:13.182455.182455 lmp.py:627]   32         | 6          |  cuda:1         
INFO 01-06 17:11:13.182198.182198 lmp.py:627]   5          | 7          |  cuda:1         
INFO 01-06 17:11:13.182463.182463 lmp.py:627]   12         | 7          |  cuda:1         
INFO 01-06 17:11:13.182491.182491 lmp.py:627]   26         | 7          |  cuda:1         
INFO 01-06 17:11:13.183279.183279 lmp.py:627]   31         | 8          |  cuda:1         
INFO 01-06 17:11:13.183545.183545 lmp.py:627]   47         | 10         |  cuda:1         
INFO 01-06 17:11:13.183810.183810 lmp.py:627]   27         | 12         |  cuda:1         
INFO 01-06 17:11:13.183076.183076 lmp.py:627]   57         | 12         |  cuda:1         
INFO 01-06 17:11:13.183580.183580 lmp.py:627]   45         | 13         |  cuda:1         
INFO 01-06 17:11:13.183369.183369 lmp.py:627]   42         | 21         |  meta           
INFO 01-06 17:11:13.183634.183634 lmp.py:628] ============================================================
INFO 01-06 17:11:13.183634.183634 lmp.py:628] 
INFO 01-06 17:11:13.183576.183576 lmp.py:630] experts_gpu_list: [1, 2, 4, 6, 14, 16, 25, 46, 53, 8, 33, 35, 43, 44, 60, 0, 3, 13, 40, 18, 52, 56, 58, 28, 32, 5, 12, 26, 31, 47, 27, 57, 45] num: 33
INFO 01-06 17:11:13.183702.183702 lmp.py:631] experts_cpu_list: [9, 15, 17, 34, 50, 11, 22, 23, 24, 30, 39, 48, 62, 29, 63, 42] num: 16
INFO 01-06 17:11:13.183511.183511 lmp.py:632] expert_actual_device_map {0: 'cuda:1', 1: 'cuda:1', 2: 'cuda:1', 3: 'cuda:1', 4: 'cuda:1', 5: 'cuda:1', 6: 'cuda:1', 7: 'cuda:1', 8: 'cuda:1', 9: 'meta', 10: 'cuda:1', 11: 'meta', 12: 'cuda:1', 13: 'cuda:1', 14: 'cuda:1', 15: 'meta', 16: 'cuda:1', 17: 'meta', 18: 'cuda:1', 19: 'meta', 20: 'meta', 21: 'cuda:1', 22: 'meta', 23: 'meta', 24: 'meta', 25: 'cuda:1', 26: 'cuda:1', 27: 'cuda:1', 28: 'cuda:1', 29: 'meta', 30: 'meta', 31: 'cuda:1', 32: 'cuda:1', 33: 'cuda:1', 34: 'meta', 35: 'cuda:1', 36: 'meta', 37: 'meta', 38: 'meta', 39: 'meta', 40: 'cuda:1', 41: 'meta', 42: 'meta', 43: 'cuda:1', 44: 'cuda:1', 45: 'cuda:1', 46: 'cuda:1', 47: 'cuda:1', 48: 'meta', 49: 'meta', 50: 'meta', 51: 'meta', 52: 'cuda:1', 53: 'cuda:1', 54: 'cuda:1', 55: 'meta', 56: 'cuda:1', 57: 'cuda:1', 58: 'cuda:1', 59: 'meta', 60: 'cuda:1', 61: 'meta', 62: 'meta', 63: 'meta'}
DEBUG 01-06 17:11:13.183983.183983 cuda_h.py:19] end experts_map_get cost 0.0021104812622070312 seconds
DEBUG 01-06 17:11:13.183376.183376 cuda_h.py:10] start gpu_sexperts
DEBUG 01-06 17:11:13.183242.183242 cuda_h.py:19] end gpu_sexperts cost 0.0003190040588378906 seconds
DEBUG 01-06 17:11:13.183264.183264 cuda_h.py:10] start gpu_experts
DEBUG 01-06 17:11:13.184891.184891 mlpmodule.py:533] gpu group tensors cost 0.0006682872772216797 s
DEBUG 01-06 17:11:13.186685.186685 mlpmodule.py:566] gpu pad cost 0.0016930103302001953 s
DEBUG 01-06 17:11:13.186639.186639 mlpmodule.py:584] gpu group einsum cost 0.00036406517028808594 s
DEBUG 01-06 17:11:13.189695.189695 mlpmodule.py:613] gpu experts func einsum cost 0.006069660186767578 s
DEBUG 01-06 17:11:13.189519.189519 cuda_h.py:19] end gpu_experts cost 0.006195783615112305 seconds
DEBUG 01-06 17:11:13.189844.189844 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-06 17:11:13.190832.190832 lmp.py:661] 
DEBUG 01-06 17:11:13.190832.190832 lmp.py:661]   Computing 16 experts on CPU...
DEBUG 01-06 17:11:13.190999.190999 cuda_h.py:19] end cpu_experts_submit cost 5.269050598144531e-05 seconds
DEBUG 01-06 17:11:13.190457.190457 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-06 17:11:13.200342.200342 mlpmodule.py:706] group tensors cost 0.009857892990112305 s
DEBUG 01-06 17:11:13.201624.201624 mlpmodule.py:744] pad cost 0.0008933544158935547 s
DEBUG 01-06 17:11:13.201574.201574 mlpmodule.py:750] create cpu tensor cost 4.1961669921875e-05 s
DEBUG 01-06 17:11:13.201424.201424 mlpmodule.py:755] move to cpu cost 2.9802322387695312e-05 s
DEBUG 01-06 17:11:13.204356.204356 mlpmodule.py:769] group_w3: shape=torch.Size([16, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=46137344
DEBUG 01-06 17:11:13.204265.204265 mlpmodule.py:770] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-06 17:11:13.204355.204355 mlpmodule.py:775] group_w3 first element: 0.0184326171875
WARNING 01-06 17:11:13.204458.204458 mlpmodule.py:785] start einsum2
DEBUG 01-06 17:11:13.208095.208095 mlpmodule.py:795] group einsum cost 0.0067369937896728516 s
DEBUG 01-06 17:11:13.208140.208140 mlpmodule.py:803] cpy2cputensor cost 0.00010633468627929688 s
DEBUG 01-06 17:11:13.211220.211220 cuda_h.py:19] end wait_cetm_experts cost 0.021120548248291016 seconds
DEBUG 01-06 17:11:13.211399.211399 cuda_h.py:19] end layer_moe_dgenerate_26 cost 0.03155875205993652 seconds
DEBUG 01-06 17:11:13.211294.211294 lmp.py:325] -------------------------------- end decode layer 26 --------------------------------
DEBUG 01-06 17:11:13.211885.211885 lmp.py:298] -------------------------------- start decode layer 27 --------------------------------
DEBUG 01-06 17:11:13.211694.211694 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-06 17:11:13.212208.212208 mlpmodule.py:367] cuda:1 cuda:1
DEBUG 01-06 17:11:13.212265.212265 cuda_h.py:10] start self_attn
cos shape torch.Size([65, 128]) sin shape torch.Size([65, 128]) position_ids tensor([[0]], device='cuda:1')
cos shape torch.Size([1, 1, 1, 128]) sin shape torch.Size([1, 1, 1, 128])
q_embed shape torch.Size([32, 16, 1, 128]) k_embed shape torch.Size([32, 16, 1, 128])
DEBUG 01-06 17:11:13.214922.214922 cuda_h.py:19] end self_attn cost 0.001939535140991211 seconds
DEBUG 01-06 17:11:13.214662.214662 cuda_h.py:19] end iln_self_attn_paln cost 0.002953767776489258 seconds
DEBUG 01-06 17:11:13.215266.215266 cuda_h.py:10] start layer_moe_dgenerate_27
DEBUG 01-06 17:11:13.215420.215420 cuda_h.py:10] start gate
DEBUG 01-06 17:11:13.215696.215696 mlpmodule.py:664]  experts func einsum cost 0.024993419647216797 s
DEBUG 01-06 17:11:13.215447.215447 cuda_h.py:19] end gate cost 0.0007336139678955078 seconds
DEBUG 01-06 17:11:13.215689.215689 cuda_h.py:10] start experts_map_get
INFO 01-06 17:11:13.216638.216638 lmp.py:609] using loaded check layer: True
INFO 01-06 17:11:13.216114.216114 lmp.py:620] 
INFO 01-06 17:11:13.216114.216114 lmp.py:620] Layer 27 Expert Device Distribution:
INFO 01-06 17:11:13.216215.216215 lmp.py:621]   Active experts: 40 (out of 64 total)
INFO 01-06 17:11:13.216533.216533 lmp.py:622] 
INFO 01-06 17:11:13.216533.216533 lmp.py:622]   Detailed Expert Distribution:
INFO 01-06 17:11:13.216952.216952 lmp.py:623]   Expert ID  | Tokens     | Actual Device  
INFO 01-06 17:11:13.216886.216886 lmp.py:624]   ----------------------------------------------------------------------
INFO 01-06 17:11:13.216013.216013 lmp.py:627]   9          | 1          |  cuda:1         
INFO 01-06 17:11:13.216424.216424 lmp.py:627]   11         | 1          |  cuda:1         
INFO 01-06 17:11:13.217643.217643 lmp.py:627]   29         | 1          |  cuda:1         
INFO 01-06 17:11:13.217147.217147 lmp.py:627]   31         | 1          |  meta           
INFO 01-06 17:11:13.217890.217890 lmp.py:627]   38         | 1          |  cuda:1         
INFO 01-06 17:11:13.217632.217632 lmp.py:627]   41         | 1          |  cuda:1         
INFO 01-06 17:11:13.217375.217375 lmp.py:627]   47         | 1          |  meta           
INFO 01-06 17:11:13.217117.217117 lmp.py:627]   48         | 1          |  meta           
INFO 01-06 17:11:13.217290.217290 lmp.py:627]   57         | 1          |  meta           
INFO 01-06 17:11:13.217509.217509 lmp.py:627]   60         | 1          |  cuda:1         
INFO 01-06 17:11:13.217967.217967 lmp.py:627]   63         | 1          |  cuda:1         
INFO 01-06 17:11:13.217186.217186 lmp.py:627]   14         | 2          |  cuda:1         
INFO 01-06 17:11:13.217929.217929 lmp.py:627]   18         | 2          |  meta           
INFO 01-06 17:11:13.217432.217432 lmp.py:627]   45         | 2          |  meta           
INFO 01-06 17:11:13.217460.217460 lmp.py:627]   46         | 2          |  meta           
INFO 01-06 17:11:13.217725.217725 lmp.py:627]   7          | 3          |  cuda:1         
INFO 01-06 17:11:13.217229.217229 lmp.py:627]   10         | 3          |  cuda:1         
INFO 01-06 17:11:13.217733.217733 lmp.py:627]   19         | 3          |  cuda:1         
INFO 01-06 17:11:13.217237.217237 lmp.py:627]   20         | 3          |  meta           
INFO 01-06 17:11:13.217695.217695 lmp.py:627]   30         | 3          |  cuda:1         
INFO 01-06 17:11:13.217914.217914 lmp.py:627]   39         | 3          |  cuda:1         
INFO 01-06 17:11:13.217133.217133 lmp.py:627]   43         | 3          |  meta           
INFO 01-06 17:11:13.217399.217399 lmp.py:627]   54         | 3          |  meta           
INFO 01-06 17:11:13.217665.217665 lmp.py:627]   12         | 4          |  meta           
INFO 01-06 17:11:13.217169.217169 lmp.py:627]   15         | 4          |  cuda:1         
INFO 01-06 17:11:13.217434.217434 lmp.py:627]   5          | 5          |  cuda:1         
INFO 01-06 17:11:13.217700.217700 lmp.py:627]   16         | 5          |  cuda:1         
INFO 01-06 17:11:13.217727.217727 lmp.py:627]   53         | 5          |  cuda:1         
INFO 01-06 17:11:13.217516.217516 lmp.py:627]   58         | 5          |  cuda:1         
INFO 01-06 17:11:13.217781.217781 lmp.py:627]   24         | 6          |  meta           
INFO 01-06 17:11:13.217762.217762 lmp.py:627]   52         | 6          |  cuda:1         
INFO 01-06 17:11:13.217981.217981 lmp.py:627]   1          | 7          |  cuda:1         
INFO 01-06 17:11:13.217962.217962 lmp.py:627]   4          | 7          |  cuda:1         
INFO 01-06 17:11:13.217943.217943 lmp.py:627]   44         | 7          |  meta           
INFO 01-06 17:11:13.217209.217209 lmp.py:627]   22         | 8          |  cuda:1         
INFO 01-06 17:11:13.217713.217713 lmp.py:627]   56         | 12         |  meta           
INFO 01-06 17:11:13.217978.217978 lmp.py:627]   13         | 13         |  meta           
INFO 01-06 17:11:13.217005.217005 lmp.py:627]   21         | 14         |  cuda:1         
INFO 01-06 17:11:13.217509.217509 lmp.py:627]   59         | 17         |  meta           
INFO 01-06 17:11:13.217536.217536 lmp.py:627]   62         | 24         |  cuda:1         
INFO 01-06 17:11:13.217040.217040 lmp.py:628] ============================================================
INFO 01-06 17:11:13.217040.217040 lmp.py:628] 
INFO 01-06 17:11:13.217505.217505 lmp.py:630] experts_gpu_list: [9, 11, 29, 38, 41, 60, 63, 14, 7, 10, 19, 30, 39, 15, 5, 16, 53, 58, 52, 1, 4, 22, 21, 62] num: 24
INFO 01-06 17:11:13.217155.217155 lmp.py:631] experts_cpu_list: [31, 47, 48, 57, 18, 45, 46, 20, 43, 54, 12, 24, 44, 56, 13, 59] num: 16
INFO 01-06 17:11:13.217725.217725 lmp.py:632] expert_actual_device_map {0: 'cuda:1', 1: 'cuda:1', 2: 'cuda:1', 3: 'cuda:1', 4: 'cuda:1', 5: 'cuda:1', 6: 'cuda:1', 7: 'cuda:1', 8: 'cuda:1', 9: 'cuda:1', 10: 'cuda:1', 11: 'cuda:1', 12: 'meta', 13: 'meta', 14: 'cuda:1', 15: 'cuda:1', 16: 'cuda:1', 17: 'meta', 18: 'meta', 19: 'cuda:1', 20: 'meta', 21: 'cuda:1', 22: 'cuda:1', 23: 'meta', 24: 'meta', 25: 'cuda:1', 26: 'meta', 27: 'cuda:1', 28: 'cuda:1', 29: 'cuda:1', 30: 'cuda:1', 31: 'meta', 32: 'cuda:1', 33: 'meta', 34: 'cuda:1', 35: 'cuda:1', 36: 'meta', 37: 'cuda:1', 38: 'cuda:1', 39: 'cuda:1', 40: 'meta', 41: 'cuda:1', 42: 'meta', 43: 'meta', 44: 'meta', 45: 'meta', 46: 'meta', 47: 'meta', 48: 'meta', 49: 'meta', 50: 'cuda:1', 51: 'meta', 52: 'cuda:1', 53: 'cuda:1', 54: 'meta', 55: 'meta', 56: 'meta', 57: 'meta', 58: 'cuda:1', 59: 'meta', 60: 'cuda:1', 61: 'meta', 62: 'cuda:1', 63: 'cuda:1'}
DEBUG 01-06 17:11:13.217912.217912 cuda_h.py:19] end experts_map_get cost 0.0018856525421142578 seconds
DEBUG 01-06 17:11:13.217352.217352 cuda_h.py:10] start gpu_sexperts
DEBUG 01-06 17:11:13.218933.218933 cuda_h.py:19] end gpu_sexperts cost 0.0003192424774169922 seconds
DEBUG 01-06 17:11:13.218816.218816 cuda_h.py:10] start gpu_experts
DEBUG 01-06 17:11:13.218880.218880 mlpmodule.py:533] gpu group tensors cost 0.0004680156707763672 s
DEBUG 01-06 17:11:13.220831.220831 mlpmodule.py:566] gpu pad cost 0.0012505054473876953 s
DEBUG 01-06 17:11:13.220274.220274 mlpmodule.py:584] gpu group einsum cost 0.0005123615264892578 s
DEBUG 01-06 17:11:13.223369.223369 mlpmodule.py:613] gpu experts func einsum cost 0.004967927932739258 s
DEBUG 01-06 17:11:13.223491.223491 cuda_h.py:19] end gpu_experts cost 0.005101203918457031 seconds
DEBUG 01-06 17:11:13.223393.223393 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-06 17:11:13.223387.223387 lmp.py:661] 
DEBUG 01-06 17:11:13.223387.223387 lmp.py:661]   Computing 16 experts on CPU...
DEBUG 01-06 17:11:13.223853.223853 cuda_h.py:19] end cpu_experts_submit cost 6.103515625e-05 seconds
DEBUG 01-06 17:11:13.223410.223410 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-06 17:11:13.228708.228708 mlpmodule.py:706] group tensors cost 0.004358768463134766 s
DEBUG 01-06 17:11:13.229197.229197 mlpmodule.py:744] pad cost 0.0008890628814697266 s
DEBUG 01-06 17:11:13.229823.229823 mlpmodule.py:750] create cpu tensor cost 4.291534423828125e-05 s
DEBUG 01-06 17:11:13.229487.229487 mlpmodule.py:755] move to cpu cost 3.170967102050781e-05 s
DEBUG 01-06 17:11:13.232439.232439 mlpmodule.py:769] group_w3: shape=torch.Size([16, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=46137344
DEBUG 01-06 17:11:13.232819.232819 mlpmodule.py:770] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-06 17:11:13.232384.232384 mlpmodule.py:775] group_w3 first element: 0.038330078125
WARNING 01-06 17:11:13.232976.232976 mlpmodule.py:785] start einsum2
DEBUG 01-06 17:11:13.236479.236479 mlpmodule.py:795] group einsum cost 0.006621360778808594 s
DEBUG 01-06 17:11:13.236107.236107 mlpmodule.py:803] cpy2cputensor cost 9.72747802734375e-05 s
DEBUG 01-06 17:11:13.239175.239175 cuda_h.py:19] end wait_cetm_experts cost 0.015438556671142578 seconds
DEBUG 01-06 17:11:13.239221.239221 cuda_h.py:19] end layer_moe_dgenerate_27 cost 0.024504661560058594 seconds
DEBUG 01-06 17:11:13.239378.239378 lmp.py:325] -------------------------------- end decode layer 27 --------------------------------
DEBUG 01-06 17:11:13.239909.239909 cuda_h.py:10] start async_wait_layer_loaded_to_gpu
DEBUG 01-06 17:11:13.239399.239399 cuda_h.py:19] end async_wait_layer_loaded_to_gpu cost 0.00015497207641601562 seconds
DEBUG 01-06 17:11:13.240769.240769 cuda_h.py:19] end decode_layer cost 1.0316548347473145 seconds
DEBUG 01-06 17:11:13.342920.342920 mlpmodule.py:664]  experts func einsum cost 0.11870479583740234 s
DEBUG 01-06 17:11:15.433754.433754 cuda_h.py:10] start generate_input_ids
generate input ids cost 0.0940091609954834 s
DEBUG 01-06 17:11:15.793338.793338 cuda_h.py:19] end generate_input_ids cost 0.3589143753051758 seconds
DEBUG 01-06 17:11:15.793801.793801 cuda_h.py:10] start init_cache
DEBUG 01-06 17:11:15.794468.794468 cuda_h.py:19] end init_cache cost 9.822845458984375e-05 seconds
DEBUG 01-06 17:11:18.109513.109513 cuda_h.py:10] start init_weights
DEBUG 01-06 17:11:18.109139.109139 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 17:11:18.110517.110517 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 17:11:18.113732.113732 cuda_h.py:19] end allocate_cuda_memory cost 0.002171039581298828 seconds
DEBUG 01-06 17:11:18.113642.113642 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 17:11:18.113736.113736 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 17:11:18.113857.113857 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 17:11:18.113752.113752 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 8b33df22-8e22-4a85-b840-384a8cacf50e
DEBUG 01-06 17:11:18.113265.113265 client.py:106] call stub.LoadModelAsync
INFO 01-06 17:11:18.115531.115531 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 8b33df22-8e22-4a85-b840-384a8cacf50e
DEBUG 01-06 17:11:18.115668.115668 cuda_h.py:19] end load_into_gpu_async cost 0.0023229122161865234 seconds
DEBUG 01-06 17:11:18.115101.115101 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 17:11:18.115060.115060 cuda_h.py:19] end restore_tensors2 cost 7.915496826171875e-05 seconds
DEBUG 01-06 17:11:18.115047.115047 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0051898956298828125 seconds
INFO 01-06 17:11:18.116691.116691 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 8b33df22-8e22-4a85-b840-384a8cacf50e
INFO 01-06 17:11:18.195034.195034 client.py:127] Model loaded
DEBUG 01-06 17:11:18.195598.195598 cuda_h.py:10] start load_qkvogns_weight_l_0
DEBUG 01-06 17:11:18.195802.195802 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 17:11:18.195793.195793 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 17:11:18.196070.196070 cuda_h.py:19] end allocate_cuda_memory cost 0.0004584789276123047 seconds
DEBUG 01-06 17:11:18.196977.196977 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 17:11:18.196569.196569 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 17:11:18.196897.196897 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 17:11:18.196376.196376 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 5c662bbf-ab1f-4197-ab12-bf2f1bf71fba
DEBUG 01-06 17:11:18.196872.196872 client.py:106] call stub.LoadModelAsync
INFO 01-06 17:11:18.198845.198845 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 5c662bbf-ab1f-4197-ab12-bf2f1bf71fba
DEBUG 01-06 17:11:18.198214.198214 cuda_h.py:19] end load_into_gpu_async cost 0.002051830291748047 seconds
DEBUG 01-06 17:11:18.198024.198024 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 17:11:18.198986.198986 cuda_h.py:19] end restore_tensors2 cost 0.0001800060272216797 seconds
DEBUG 01-06 17:11:18.199916.199916 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0033385753631591797 seconds
INFO 01-06 17:11:18.199773.199773 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 5c662bbf-ab1f-4197-ab12-bf2f1bf71fba
INFO 01-06 17:11:18.215775.215775 client.py:127] Model loaded
DEBUG 01-06 17:11:18.216548.216548 cuda_h.py:19] end load_qkvogns_weight_l_0 cost 0.021338701248168945 seconds
DEBUG 01-06 17:11:18.217063.217063 cuda_h.py:19] end init_weights cost 0.10711669921875 seconds
DEBUG 01-06 17:11:18.217595.217595 cuda_h.py:10] start copy_emodel
DEBUG 01-06 17:11:19.171297.171297 cuda_h.py:19] end copy_emodel cost 0.9544169902801514 seconds
DEBUG 01-06 17:11:19.172526.172526 cuda_h.py:10] start init_hmv
DEBUG 01-06 17:11:19.319024.319024 mlpmodule.py:207] restore_hm_state_dict2model loaded 5265 expert tensors (including shared_experts) for Deepseek model
DEBUG 01-06 17:11:19.320368.320368 cuda_h.py:19] end init_hmv cost 0.14751911163330078 seconds
DEBUG 01-06 17:11:19.320508.320508 cuda_h.py:10] start init_inputs_tokens
DEBUG 01-06 17:11:19.320627.320627 cuda_h.py:19] end init_inputs_tokens cost 0.00033664703369140625 seconds
DEBUG 01-06 17:11:19.320211.320211 cuda_h.py:10] start multi_layer
DEBUG 01-06 17:11:19.320166.320166 lmp.py:176] -------------------------------- start layer 0 --------------------------------
DEBUG 01-06 17:11:19.320385.320385 cuda_h.py:10] start start_load_qkvogn_s_weight_l_1
DEBUG 01-06 17:11:19.320227.320227 cuda_h.py:10] start start_load_qkvogn_s_weight_l_1
DEBUG 01-06 17:11:19.320885.320885 cuda_h.py:19] end start_load_qkvogn_s_weight_l_1 cost 3.528594970703125e-05 seconds
DEBUG 01-06 17:11:19.320587.320587 cuda_h.py:19] end start_load_qkvogn_s_weight_l_1 cost 6.914138793945312e-05 seconds
DEBUG 01-06 17:11:19.320091.320091 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-06 17:11:19.320504.320504 mlpmodule.py:367] cuda:1 cuda:1
DEBUG 01-06 17:11:19.320998.320998 cuda_h.py:10] start sllm_worker_task
DEBUG 01-06 17:11:19.321646.321646 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 17:11:19.321340.321340 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 17:11:19.322656.322656 cuda_h.py:19] end allocate_cuda_memory cost 0.00039196014404296875 seconds
DEBUG 01-06 17:11:19.322218.322218 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 17:11:19.322156.322156 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 17:11:19.322644.322644 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 17:11:19.322238.322238 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 0455ad8f-a93a-45b8-9375-4e18f86d53f1
DEBUG 01-06 17:11:19.322212.322212 client.py:106] call stub.LoadModelAsync
DEBUG 01-06 17:11:19.323765.323765 cuda_h.py:10] start self_attn
INFO 01-06 17:11:19.324136.324136 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 0455ad8f-a93a-45b8-9375-4e18f86d53f1
DEBUG 01-06 17:11:19.324439.324439 cuda_h.py:19] end load_into_gpu_async cost 0.002526998519897461 seconds
DEBUG 01-06 17:11:19.324614.324614 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 17:11:19.325828.325828 cuda_h.py:19] end restore_tensors2 cost 0.0001666545867919922 seconds
DEBUG 01-06 17:11:19.325429.325429 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0038640499114990234 seconds
INFO 01-06 17:11:19.325441.325441 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 0455ad8f-a93a-45b8-9375-4e18f86d53f1
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-06 17:11:19.328317.328317 cuda_h.py:19] end self_attn cost 0.004933595657348633 seconds
DEBUG 01-06 17:11:19.328851.328851 cuda_h.py:19] end iln_self_attn_paln cost 0.007620573043823242 seconds
DEBUG 01-06 17:11:19.328058.328058 cuda_h.py:10] start dense_mlp
INFO 01-06 17:11:19.333983.333983 client.py:127] Model loaded
DEBUG 01-06 17:11:19.334470.334470 cuda_h.py:19] end sllm_worker_task cost 0.013317108154296875 seconds
DEBUG 01-06 17:11:19.334199.334199 cuda_h.py:19] end dense_mlp cost 0.0063457489013671875 seconds
DEBUG 01-06 17:11:19.335051.335051 lmp.py:220] -------------------------------- end layer 0 --------------------------------
DEBUG 01-06 17:11:19.335291.335291 lmp.py:176] -------------------------------- start layer 1 --------------------------------
DEBUG 01-06 17:11:19.335749.335749 cuda_h.py:10] start start_load_qkvogn_s_weight_l_2
DEBUG 01-06 17:11:19.335074.335074 cuda_h.py:10] start start_load_qkvogn_s_weight_l_2
DEBUG 01-06 17:11:19.335188.335188 cuda_h.py:19] end start_load_qkvogn_s_weight_l_2 cost 2.4318695068359375e-05 seconds
DEBUG 01-06 17:11:19.335368.335368 cuda_h.py:19] end start_load_qkvogn_s_weight_l_2 cost 5.459785461425781e-05 seconds
DEBUG 01-06 17:11:19.335157.335157 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-06 17:11:19.335940.335940 cuda_h.py:10] start sllm_worker_task
DEBUG 01-06 17:11:19.335229.335229 mlpmodule.py:367] cuda:1 cuda:1
DEBUG 01-06 17:11:19.335172.335172 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 17:11:19.335471.335471 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 17:11:19.336916.336916 cuda_h.py:19] end allocate_cuda_memory cost 0.0003161430358886719 seconds
DEBUG 01-06 17:11:19.336987.336987 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 17:11:19.336044.336044 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 17:11:19.336414.336414 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 17:11:19.336622.336622 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, d1c14abe-0087-4bf0-9ec5-f8b3311392f6
DEBUG 01-06 17:11:19.336073.336073 client.py:106] call stub.LoadModelAsync
DEBUG 01-06 17:11:19.337192.337192 cuda_h.py:10] start self_attn
INFO 01-06 17:11:19.338685.338685 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, d1c14abe-0087-4bf0-9ec5-f8b3311392f6
DEBUG 01-06 17:11:19.338181.338181 cuda_h.py:19] end load_into_gpu_async cost 0.0020971298217773438 seconds
DEBUG 01-06 17:11:19.338833.338833 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 17:11:19.338517.338517 cuda_h.py:19] end restore_tensors2 cost 0.00014829635620117188 seconds
DEBUG 01-06 17:11:19.338170.338170 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0033173561096191406 seconds
INFO 01-06 17:11:19.339559.339559 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, d1c14abe-0087-4bf0-9ec5-f8b3311392f6
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-06 17:11:19.340373.340373 cuda_h.py:19] end self_attn cost 0.003365755081176758 seconds
DEBUG 01-06 17:11:19.340721.340721 cuda_h.py:19] end iln_self_attn_paln cost 0.005548238754272461 seconds
DEBUG 01-06 17:11:19.340756.340756 cuda_h.py:10] start layer_moe_generate_1
DEBUG 01-06 17:11:19.340903.340903 cuda_h.py:10] start gate
DEBUG 01-06 17:11:19.341836.341836 cuda_h.py:19] end gate cost 0.0007231235504150391 seconds
DEBUG 01-06 17:11:19.341950.341950 cuda_h.py:10] start experts_map_get
DEBUG 01-06 17:11:19.341443.341443 lmp.py:403] 
DEBUG 01-06 17:11:19.341443.341443 lmp.py:403] Expert Token Distribution & Device Allocation:
DEBUG 01-06 17:11:19.342914.342914 lmp.py:404]   Total experts: 64
DEBUG 01-06 17:11:19.342948.342948 lmp.py:405]   CPU experts: 32 (50%)
DEBUG 01-06 17:11:19.342452.342452 lmp.py:406]   GPU experts: 32 (50%)
DEBUG 01-06 17:11:19.342811.342811 lmp.py:407] 
DEBUG 01-06 17:11:19.342811.342811 lmp.py:407]   Expert ID | Tokens | Device
DEBUG 01-06 17:11:19.342884.342884 lmp.py:408]   -----------------------------------
DEBUG 01-06 17:11:19.342203.342203 lmp.py:414]   Expert 25 |     64 | CPU
DEBUG 01-06 17:11:19.342561.342561 lmp.py:414]   Expert 54 |     67 | CPU
DEBUG 01-06 17:11:19.342204.342204 lmp.py:414]   Expert  3 |     68 | CPU
DEBUG 01-06 17:11:19.342609.342609 lmp.py:414]   Expert 31 |     72 | CPU
DEBUG 01-06 17:11:19.342013.342013 lmp.py:414]   Expert 55 |     72 | CPU
DEBUG 01-06 17:11:19.342133.342133 lmp.py:414]   Expert 62 |     87 | CPU
DEBUG 01-06 17:11:19.342538.342538 lmp.py:414]   Expert 18 |     88 | CPU
DEBUG 01-06 17:11:19.342942.342942 lmp.py:414]   Expert 52 |     98 | CPU
DEBUG 01-06 17:11:19.342347.342347 lmp.py:414]   Expert 22 |    100 | CPU
DEBUG 01-06 17:11:19.342990.342990 lmp.py:414]   Expert 47 |    104 | CPU
DEBUG 01-06 17:11:19.342024.342024 lmp.py:414]   Expert  0 |    113 | CPU
DEBUG 01-06 17:11:19.342905.342905 lmp.py:414]   Expert 37 |    117 | CPU
DEBUG 01-06 17:11:19.342171.342171 lmp.py:414]   Expert 27 |    121 | CPU
DEBUG 01-06 17:11:19.342145.342145 lmp.py:414]   Expert 32 |    123 | CPU
DEBUG 01-06 17:11:19.342119.342119 lmp.py:414]   Expert 41 |    130 | CPU
DEBUG 01-06 17:11:19.342093.342093 lmp.py:414]   Expert 44 |    131 | CPU
DEBUG 01-06 17:11:19.342828.342828 lmp.py:414]   Expert 28 |    136 | CPU
DEBUG 01-06 17:11:19.342564.342564 lmp.py:414]   Expert 13 |    138 | CPU
DEBUG 01-06 17:11:19.342300.342300 lmp.py:414]   Expert 58 |    140 | CPU
DEBUG 01-06 17:11:19.342035.342035 lmp.py:414]   Expert 60 |    144 | CPU
DEBUG 01-06 17:11:19.342009.342009 lmp.py:414]   Expert 43 |    147 | CPU
DEBUG 01-06 17:11:19.342983.342983 lmp.py:414]   Expert  1 |    150 | CPU
DEBUG 01-06 17:11:19.342196.342196 lmp.py:414]   Expert 38 |    153 | CPU
DEBUG 01-06 17:11:19.342600.342600 lmp.py:414]   Expert 49 |    154 | CPU
DEBUG 01-06 17:11:19.342766.342766 lmp.py:414]   Expert 51 |    155 | CPU
DEBUG 01-06 17:11:19.342171.342171 lmp.py:414]   Expert 34 |    161 | CPU
DEBUG 01-06 17:11:19.342907.342907 lmp.py:414]   Expert 35 |    164 | CPU
DEBUG 01-06 17:11:19.342642.342642 lmp.py:414]   Expert 36 |    168 | CPU
DEBUG 01-06 17:11:19.342378.342378 lmp.py:414]   Expert 11 |    170 | CPU
DEBUG 01-06 17:11:19.342352.342352 lmp.py:414]   Expert 17 |    170 | CPU
DEBUG 01-06 17:11:19.342849.342849 lmp.py:414]   Expert 59 |    174 | CPU
DEBUG 01-06 17:11:19.342823.342823 lmp.py:414]   Expert 10 |    180 | CPU
DEBUG 01-06 17:11:19.342320.342320 lmp.py:414]   Expert 20 |    182 | GPU
DEBUG 01-06 17:11:19.342294.342294 lmp.py:414]   Expert  2 |    186 | GPU
DEBUG 01-06 17:11:19.342268.342268 lmp.py:414]   Expert 39 |    189 | GPU
DEBUG 01-06 17:11:19.342766.342766 lmp.py:414]   Expert 33 |    197 | GPU
DEBUG 01-06 17:11:19.342740.342740 lmp.py:414]   Expert 12 |    198 | GPU
DEBUG 01-06 17:11:19.342475.342475 lmp.py:414]   Expert 21 |    198 | GPU
DEBUG 01-06 17:11:19.342787.342787 lmp.py:414]   Expert 48 |    198 | GPU
DEBUG 01-06 17:11:19.342953.342953 lmp.py:414]   Expert 15 |    199 | GPU
DEBUG 01-06 17:11:19.342689.342689 lmp.py:414]   Expert 53 |    204 | GPU
DEBUG 01-06 17:11:19.342425.342425 lmp.py:414]   Expert 19 |    220 | GPU
DEBUG 01-06 17:11:19.342160.342160 lmp.py:414]   Expert 26 |    221 | GPU
DEBUG 01-06 17:11:19.342134.342134 lmp.py:414]   Expert 30 |    221 | GPU
DEBUG 01-06 17:11:19.342632.342632 lmp.py:414]   Expert 45 |    221 | GPU
DEBUG 01-06 17:11:19.342367.342367 lmp.py:414]   Expert  5 |    227 | GPU
DEBUG 01-06 17:11:19.342103.342103 lmp.py:414]   Expert  4 |    229 | GPU
DEBUG 01-06 17:11:19.342077.342077 lmp.py:414]   Expert 24 |    229 | GPU
DEBUG 01-06 17:11:19.342812.342812 lmp.py:414]   Expert 42 |    242 | GPU
DEBUG 01-06 17:11:19.342310.342310 lmp.py:414]   Expert 50 |    245 | GPU
DEBUG 01-06 17:11:19.342284.342284 lmp.py:414]   Expert 29 |    254 | GPU
DEBUG 01-06 17:11:19.342781.342781 lmp.py:414]   Expert 56 |    262 | GPU
DEBUG 01-06 17:11:19.342755.342755 lmp.py:414]   Expert 61 |    270 | GPU
DEBUG 01-06 17:11:19.342491.342491 lmp.py:414]   Expert  8 |    283 | GPU
DEBUG 01-06 17:11:19.343802.343802 lmp.py:414]   Expert 63 |    285 | GPU
DEBUG 01-06 17:11:19.343969.343969 lmp.py:414]   Expert 46 |    294 | GPU
DEBUG 01-06 17:11:19.343135.343135 lmp.py:414]   Expert  9 |    300 | GPU
DEBUG 01-06 17:11:19.343447.343447 lmp.py:414]   Expert  6 |    316 | GPU
DEBUG 01-06 17:11:19.343421.343421 lmp.py:414]   Expert 16 |    316 | GPU
DEBUG 01-06 17:11:19.343679.343679 lmp.py:414]   Expert 40 |    319 | GPU
DEBUG 01-06 17:11:19.343415.343415 lmp.py:414]   Expert  7 |    322 | GPU
DEBUG 01-06 17:11:19.343674.343674 lmp.py:414]   Expert 23 |    325 | GPU
DEBUG 01-06 17:11:19.343410.343410 lmp.py:414]   Expert 14 |    413 | GPU
DEBUG 01-06 17:11:19.343668.343668 lmp.py:414]   Expert 57 |    464 | GPU
DEBUG 01-06 17:11:19.343881.343881 lmp.py:415] 
DEBUG 01-06 17:11:19.343881.343881 lmp.py:415]   CPU total tokens: 4059 (33.0%)
DEBUG 01-06 17:11:19.343570.343570 lmp.py:416]   GPU total tokens: 8229 (67.0%)
DEBUG 01-06 17:11:19.343551.343551 cuda_h.py:19] end experts_map_get cost 0.0015025138854980469 seconds
DEBUG 01-06 17:11:19.343432.343432 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-06 17:11:19.343401.343401 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 17:11:19.343769.343769 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 17:11:19.345747.345747 cuda_h.py:19] end allocate_cuda_memory cost 0.0020551681518554688 seconds
DEBUG 01-06 17:11:19.345305.345305 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 17:11:19.345061.345061 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 17:11:19.345247.345247 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 17:11:19.345659.345659 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 58c2effc-0565-45bd-862b-57286bf427a7
DEBUG 01-06 17:11:19.347305.347305 client.py:106] call stub.LoadModelAsync
INFO 01-06 17:11:19.347256.347256 client.py:127] Model loaded
DEBUG 01-06 17:11:19.348440.348440 cuda_h.py:19] end sllm_worker_task cost 0.013150215148925781 seconds
INFO 01-06 17:11:19.348683.348683 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 58c2effc-0565-45bd-862b-57286bf427a7
DEBUG 01-06 17:11:19.348539.348539 cuda_h.py:19] end load_into_gpu_async cost 0.0034036636352539062 seconds
DEBUG 01-06 17:11:19.349626.349626 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 17:11:19.349658.349658 cuda_h.py:19] end restore_tensors2 cost 0.0003116130828857422 seconds
DEBUG 01-06 17:11:19.349209.349209 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.006120204925537109 seconds
DEBUG 01-06 17:11:19.352828.352828 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.008832216262817383 seconds
DEBUG 01-06 17:11:19.352016.352016 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-06 17:11:19.352131.352131 lmp.py:461] 
DEBUG 01-06 17:11:19.352131.352131 lmp.py:461]   Computing 32 experts on CPU...
DEBUG 01-06 17:11:19.352551.352551 cuda_h.py:19] end cpu_experts_submit cost 0.00011873245239257812 seconds
DEBUG 01-06 17:11:19.352631.352631 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-06 17:11:19.359101.359101 mlpmodule.py:706] group tensors cost 0.006639242172241211 s
DEBUG 01-06 17:11:19.362087.362087 mlpmodule.py:744] pad cost 0.0021855831146240234 s
DEBUG 01-06 17:11:19.362263.362263 mlpmodule.py:750] create cpu tensor cost 5.5789947509765625e-05 s
DEBUG 01-06 17:11:19.362584.362584 mlpmodule.py:755] move to cpu cost 4.506111145019531e-05 s
DEBUG 01-06 17:11:19.373753.373753 mlpmodule.py:769] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-06 17:11:19.373657.373657 mlpmodule.py:770] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-06 17:11:19.373567.373567 mlpmodule.py:775] group_w3 first element: -0.0107421875
WARNING 01-06 17:11:19.373300.373300 mlpmodule.py:785] start einsum2
DEBUG 01-06 17:11:19.391420.391420 mlpmodule.py:795] group einsum cost 0.028636455535888672 s
DEBUG 01-06 17:11:19.392185.392185 mlpmodule.py:803] cpy2cputensor cost 0.0007348060607910156 s
DEBUG 01-06 17:11:19.396560.396560 cuda_h.py:19] end wait_cetm_experts cost 0.04407024383544922 seconds
DEBUG 01-06 17:11:19.396526.396526 cuda_h.py:10] start gpu_sexperts
DEBUG 01-06 17:11:19.397483.397483 cuda_h.py:19] end gpu_sexperts cost 0.0006248950958251953 seconds
DEBUG 01-06 17:11:19.397763.397763 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-06 17:11:19.397666.397666 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.8371810913085938e-05 seconds
DEBUG 01-06 17:11:19.397084.397084 cuda_h.py:10] start wait_experts
INFO 01-06 17:11:19.397317.397317 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 58c2effc-0565-45bd-862b-57286bf427a7
INFO 01-06 17:11:19.402339.402339 client.py:127] Model loaded
DEBUG 01-06 17:11:19.402811.402811 cuda_h.py:19] end wait_experts cost 0.005280256271362305 seconds
DEBUG 01-06 17:11:19.402375.402375 cuda_h.py:10] start gpu_experts
DEBUG 01-06 17:11:19.402370.402370 lmp.py:506]   Computing 32 experts on GPU...
DEBUG 01-06 17:11:19.404057.404057 mlpmodule.py:664]  experts func einsum cost 0.05205416679382324 s
DEBUG 01-06 17:11:19.405420.405420 mlpmodule.py:533] gpu group tensors cost 0.0021796226501464844 s
DEBUG 01-06 17:11:19.407108.407108 mlpmodule.py:566] gpu pad cost 0.0018281936645507812 s
DEBUG 01-06 17:11:19.407646.407646 mlpmodule.py:584] gpu group einsum cost 0.0007860660552978516 s
DEBUG 01-06 17:11:19.410641.410641 mlpmodule.py:613] gpu experts func einsum cost 0.007802724838256836 s
DEBUG 01-06 17:11:19.410994.410994 cuda_h.py:19] end gpu_experts cost 0.00797724723815918 seconds
DEBUG 01-06 17:11:19.410103.410103 cuda_h.py:19] end layer_moe_generate_1 cost 0.07006216049194336 seconds
DEBUG 01-06 17:11:19.411785.411785 lmp.py:220] -------------------------------- end layer 1 --------------------------------
DEBUG 01-06 17:11:19.411932.411932 lmp.py:176] -------------------------------- start layer 2 --------------------------------
DEBUG 01-06 17:11:19.411721.411721 cuda_h.py:10] start start_load_qkvogn_s_weight_l_3
DEBUG 01-06 17:11:19.411212.411212 cuda_h.py:10] start start_load_qkvogn_s_weight_l_3
DEBUG 01-06 17:11:19.411102.411102 cuda_h.py:19] end start_load_qkvogn_s_weight_l_3 cost 3.314018249511719e-05 seconds
DEBUG 01-06 17:11:19.411943.411943 cuda_h.py:19] end start_load_qkvogn_s_weight_l_3 cost 6.175041198730469e-05 seconds
DEBUG 01-06 17:11:19.411900.411900 cuda_h.py:10] start sllm_worker_task
DEBUG 01-06 17:11:19.411576.411576 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-06 17:11:19.411460.411460 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 17:11:19.411497.411497 mlpmodule.py:367] cuda:1 cuda:1
DEBUG 01-06 17:11:19.411367.411367 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 17:11:19.411987.411987 cuda_h.py:19] end allocate_cuda_memory cost 0.00022077560424804688 seconds
DEBUG 01-06 17:11:19.412672.412672 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 17:11:19.412103.412103 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 17:11:19.412688.412688 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 17:11:19.412198.412198 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 90910c7b-745f-4913-9d9a-ea7a8007f338
DEBUG 01-06 17:11:19.412221.412221 client.py:106] call stub.LoadModelAsync
DEBUG 01-06 17:11:19.412952.412952 cuda_h.py:10] start self_attn
INFO 01-06 17:11:19.413392.413392 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 90910c7b-745f-4913-9d9a-ea7a8007f338
DEBUG 01-06 17:11:19.413275.413275 cuda_h.py:19] end load_into_gpu_async cost 0.0013556480407714844 seconds
DEBUG 01-06 17:11:19.413070.413070 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 17:11:19.413722.413722 cuda_h.py:19] end restore_tensors2 cost 6.747245788574219e-05 seconds
DEBUG 01-06 17:11:19.413286.413286 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0019681453704833984 seconds
INFO 01-06 17:11:19.413143.413143 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 90910c7b-745f-4913-9d9a-ea7a8007f338
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-06 17:11:19.415932.415932 cuda_h.py:19] end self_attn cost 0.0029082298278808594 seconds
DEBUG 01-06 17:11:19.415055.415055 cuda_h.py:19] end iln_self_attn_paln cost 0.0042498111724853516 seconds
DEBUG 01-06 17:11:19.415249.415249 cuda_h.py:10] start layer_moe_generate_2
DEBUG 01-06 17:11:19.415204.415204 cuda_h.py:10] start gate
DEBUG 01-06 17:11:19.416433.416433 cuda_h.py:19] end gate cost 0.0006592273712158203 seconds
DEBUG 01-06 17:11:19.416216.416216 cuda_h.py:10] start experts_map_get
DEBUG 01-06 17:11:19.416060.416060 lmp.py:403] 
DEBUG 01-06 17:11:19.416060.416060 lmp.py:403] Expert Token Distribution & Device Allocation:
DEBUG 01-06 17:11:19.416340.416340 lmp.py:404]   Total experts: 64
DEBUG 01-06 17:11:19.417228.417228 lmp.py:405]   CPU experts: 32 (50%)
DEBUG 01-06 17:11:19.417493.417493 lmp.py:406]   GPU experts: 32 (50%)
DEBUG 01-06 17:11:19.417136.417136 lmp.py:407] 
DEBUG 01-06 17:11:19.417136.417136 lmp.py:407]   Expert ID | Tokens | Device
DEBUG 01-06 17:11:19.417541.417541 lmp.py:408]   -----------------------------------
DEBUG 01-06 17:11:19.417144.417144 lmp.py:414]   Expert 58 |     50 | CPU
DEBUG 01-06 17:11:19.417503.417503 lmp.py:414]   Expert 27 |     55 | CPU
DEBUG 01-06 17:11:19.417907.417907 lmp.py:414]   Expert  3 |     68 | CPU
DEBUG 01-06 17:11:19.417550.417550 lmp.py:414]   Expert 17 |     82 | CPU
DEBUG 01-06 17:11:19.417431.417431 lmp.py:414]   Expert  0 |     85 | CPU
DEBUG 01-06 17:11:19.417836.417836 lmp.py:414]   Expert 24 |     87 | CPU
DEBUG 01-06 17:11:19.417479.417479 lmp.py:414]   Expert 28 |    104 | CPU
DEBUG 01-06 17:11:19.417076.417076 lmp.py:414]   Expert 34 |    114 | CPU
DEBUG 01-06 17:11:19.417480.417480 lmp.py:414]   Expert 51 |    116 | CPU
DEBUG 01-06 17:11:19.417646.417646 lmp.py:414]   Expert 32 |    117 | CPU
DEBUG 01-06 17:11:19.417097.417097 lmp.py:414]   Expert  9 |    121 | CPU
DEBUG 01-06 17:11:19.417263.417263 lmp.py:414]   Expert  7 |    134 | CPU
DEBUG 01-06 17:11:19.417668.417668 lmp.py:414]   Expert 15 |    134 | CPU
DEBUG 01-06 17:11:19.417596.417596 lmp.py:414]   Expert 26 |    136 | CPU
DEBUG 01-06 17:11:19.417046.417046 lmp.py:414]   Expert 23 |    139 | CPU
DEBUG 01-06 17:11:19.417974.417974 lmp.py:414]   Expert 45 |    143 | CPU
DEBUG 01-06 17:11:19.417617.417617 lmp.py:414]   Expert 30 |    144 | CPU
DEBUG 01-06 17:11:19.417783.417783 lmp.py:414]   Expert 57 |    148 | CPU
DEBUG 01-06 17:11:19.417949.417949 lmp.py:414]   Expert 62 |    151 | CPU
DEBUG 01-06 17:11:19.417354.417354 lmp.py:414]   Expert 36 |    155 | CPU
DEBUG 01-06 17:11:19.417282.417282 lmp.py:414]   Expert  1 |    156 | CPU
DEBUG 01-06 17:11:19.417494.417494 lmp.py:414]   Expert  8 |    161 | CPU
DEBUG 01-06 17:11:19.417184.417184 lmp.py:414]   Expert 29 |    162 | CPU
DEBUG 01-06 17:11:19.417634.417634 lmp.py:414]   Expert 25 |    167 | CPU
DEBUG 01-06 17:11:19.417562.417562 lmp.py:414]   Expert 48 |    167 | CPU
DEBUG 01-06 17:11:19.417490.417490 lmp.py:414]   Expert 35 |    169 | CPU
DEBUG 01-06 17:11:19.417702.417702 lmp.py:414]   Expert  6 |    172 | CPU
DEBUG 01-06 17:11:19.417630.417630 lmp.py:414]   Expert 37 |    172 | CPU
DEBUG 01-06 17:11:19.417081.417081 lmp.py:414]   Expert 54 |    173 | CPU
DEBUG 01-06 17:11:19.417009.417009 lmp.py:414]   Expert 12 |    174 | CPU
DEBUG 01-06 17:11:19.417652.417652 lmp.py:414]   Expert 49 |    174 | CPU
DEBUG 01-06 17:11:19.417295.417295 lmp.py:414]   Expert 53 |    183 | CPU
DEBUG 01-06 17:11:19.417938.417938 lmp.py:414]   Expert 33 |    186 | GPU
DEBUG 01-06 17:11:19.417819.417819 lmp.py:414]   Expert 13 |    188 | GPU
DEBUG 01-06 17:11:19.417747.417747 lmp.py:414]   Expert 60 |    189 | GPU
DEBUG 01-06 17:11:19.417674.417674 lmp.py:414]   Expert 10 |    190 | GPU
DEBUG 01-06 17:11:19.417841.417841 lmp.py:414]   Expert 16 |    198 | GPU
DEBUG 01-06 17:11:19.417530.417530 lmp.py:414]   Expert 21 |    198 | GPU
DEBUG 01-06 17:11:19.417742.417742 lmp.py:414]   Expert 40 |    203 | GPU
DEBUG 01-06 17:11:19.417432.417432 lmp.py:414]   Expert 43 |    205 | GPU
DEBUG 01-06 17:11:19.417882.417882 lmp.py:414]   Expert 38 |    206 | GPU
DEBUG 01-06 17:11:19.417247.417247 lmp.py:414]   Expert  5 |    208 | GPU
DEBUG 01-06 17:11:19.417414.417414 lmp.py:414]   Expert 44 |    213 | GPU
DEBUG 01-06 17:11:19.417341.417341 lmp.py:414]   Expert 52 |    216 | GPU
DEBUG 01-06 17:11:19.417461.417461 lmp.py:414]   Expert 41 |    217 | GPU
DEBUG 01-06 17:11:19.417866.417866 lmp.py:414]   Expert 50 |    217 | GPU
DEBUG 01-06 17:11:19.417317.417317 lmp.py:414]   Expert  4 |    219 | GPU
DEBUG 01-06 17:11:19.417006.417006 lmp.py:414]   Expert 59 |    220 | GPU
DEBUG 01-06 17:11:19.417934.417934 lmp.py:414]   Expert 19 |    222 | GPU
DEBUG 01-06 17:11:19.417623.417623 lmp.py:414]   Expert 55 |    235 | GPU
DEBUG 01-06 17:11:19.417312.417312 lmp.py:414]   Expert 31 |    243 | GPU
DEBUG 01-06 17:11:19.417525.417525 lmp.py:414]   Expert 56 |    245 | GPU
DEBUG 01-06 17:11:19.417214.417214 lmp.py:414]   Expert 39 |    254 | GPU
DEBUG 01-06 17:11:19.418903.418903 lmp.py:414]   Expert 20 |    260 | GPU
DEBUG 01-06 17:11:19.418593.418593 lmp.py:414]   Expert 22 |    266 | GPU
DEBUG 01-06 17:11:19.418282.418282 lmp.py:414]   Expert  2 |    268 | GPU
DEBUG 01-06 17:11:19.418402.418402 lmp.py:414]   Expert 47 |    276 | GPU
DEBUG 01-06 17:11:19.418806.418806 lmp.py:414]   Expert 63 |    277 | GPU
DEBUG 01-06 17:11:19.418972.418972 lmp.py:414]   Expert 42 |    303 | GPU
DEBUG 01-06 17:11:19.418139.418139 lmp.py:414]   Expert 14 |    316 | GPU
DEBUG 01-06 17:11:19.418497.418497 lmp.py:414]   Expert 18 |    319 | GPU
DEBUG 01-06 17:11:19.418424.418424 lmp.py:414]   Expert 46 |    368 | GPU
DEBUG 01-06 17:11:19.418875.418875 lmp.py:414]   Expert 11 |    388 | GPU
DEBUG 01-06 17:11:19.418326.418326 lmp.py:414]   Expert 61 |    462 | GPU
DEBUG 01-06 17:11:19.418731.418731 lmp.py:415] 
DEBUG 01-06 17:11:19.418731.418731 lmp.py:415]   CPU total tokens: 4313 (35.1%)
DEBUG 01-06 17:11:19.418612.418612 lmp.py:416]   GPU total tokens: 7975 (64.9%)
DEBUG 01-06 17:11:19.418308.418308 cuda_h.py:19] end experts_map_get cost 0.0015494823455810547 seconds
DEBUG 01-06 17:11:19.418190.418190 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-06 17:11:19.418589.418589 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 17:11:19.418348.418348 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 17:11:19.419230.419230 cuda_h.py:19] end allocate_cuda_memory cost 0.001178741455078125 seconds
DEBUG 01-06 17:11:19.419027.419027 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 17:11:19.419544.419544 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 17:11:19.419830.419830 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 17:11:19.419195.419195 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, c263b3ce-61c9-4dca-afb3-9094004caf89
DEBUG 01-06 17:11:19.420745.420745 client.py:106] call stub.LoadModelAsync
INFO 01-06 17:11:19.421039.421039 client.py:127] Model loaded
DEBUG 01-06 17:11:19.421651.421651 cuda_h.py:19] end sllm_worker_task cost 0.010257959365844727 seconds
INFO 01-06 17:11:19.422389.422389 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, c263b3ce-61c9-4dca-afb3-9094004caf89
DEBUG 01-06 17:11:19.422030.422030 cuda_h.py:19] end load_into_gpu_async cost 0.003008127212524414 seconds
DEBUG 01-06 17:11:19.422761.422761 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 17:11:19.423177.423177 cuda_h.py:19] end restore_tensors2 cost 0.00048661231994628906 seconds
DEBUG 01-06 17:11:19.423305.423305 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.00513911247253418 seconds
DEBUG 01-06 17:11:19.426274.426274 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.0078277587890625 seconds
DEBUG 01-06 17:11:19.426601.426601 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-06 17:11:19.426987.426987 lmp.py:461] 
DEBUG 01-06 17:11:19.426987.426987 lmp.py:461]   Computing 32 experts on CPU...
DEBUG 01-06 17:11:19.426546.426546 cuda_h.py:19] end cpu_experts_submit cost 0.00010752677917480469 seconds
DEBUG 01-06 17:11:19.426480.426480 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-06 17:11:19.434678.434678 mlpmodule.py:706] group tensors cost 0.008055925369262695 s
DEBUG 01-06 17:11:19.437362.437362 mlpmodule.py:744] pad cost 0.0018382072448730469 s
DEBUG 01-06 17:11:19.437001.437001 mlpmodule.py:750] create cpu tensor cost 5.078315734863281e-05 s
DEBUG 01-06 17:11:19.437534.437534 mlpmodule.py:755] move to cpu cost 3.504753112792969e-05 s
DEBUG 01-06 17:11:19.449165.449165 mlpmodule.py:769] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-06 17:11:19.449917.449917 mlpmodule.py:770] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-06 17:11:19.449588.449588 mlpmodule.py:775] group_w3 first element: -0.0380859375
WARNING 01-06 17:11:19.449705.449705 mlpmodule.py:785] start einsum2
DEBUG 01-06 17:11:19.468850.468850 mlpmodule.py:795] group einsum cost 0.03052520751953125 s
DEBUG 01-06 17:11:19.468417.468417 mlpmodule.py:803] cpy2cputensor cost 0.0007481575012207031 s
DEBUG 01-06 17:11:19.473630.473630 cuda_h.py:19] end wait_cetm_experts cost 0.04711651802062988 seconds
DEBUG 01-06 17:11:19.473272.473272 cuda_h.py:10] start gpu_sexperts
DEBUG 01-06 17:11:19.474956.474956 cuda_h.py:19] end gpu_sexperts cost 0.0006008148193359375 seconds
DEBUG 01-06 17:11:19.474091.474091 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-06 17:11:19.474132.474132 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.5033950805664062e-05 seconds
DEBUG 01-06 17:11:19.474888.474888 cuda_h.py:10] start wait_experts
INFO 01-06 17:11:19.474313.474313 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, c263b3ce-61c9-4dca-afb3-9094004caf89
INFO 01-06 17:11:19.476793.476793 client.py:127] Model loaded
DEBUG 01-06 17:11:19.476736.476736 cuda_h.py:19] end wait_experts cost 0.0015413761138916016 seconds
DEBUG 01-06 17:11:19.476207.476207 cuda_h.py:10] start gpu_experts
DEBUG 01-06 17:11:19.476155.476155 lmp.py:506]   Computing 32 experts on GPU...
DEBUG 01-06 17:11:19.476413.476413 mlpmodule.py:533] gpu group tensors cost 0.0006899833679199219 s
DEBUG 01-06 17:11:19.478758.478758 mlpmodule.py:566] gpu pad cost 0.001737833023071289 s
DEBUG 01-06 17:11:19.479541.479541 mlpmodule.py:584] gpu group einsum cost 0.001134634017944336 s
DEBUG 01-06 17:11:19.482025.482025 mlpmodule.py:664]  experts func einsum cost 0.05602455139160156 s
DEBUG 01-06 17:11:19.483756.483756 mlpmodule.py:613] gpu experts func einsum cost 0.007352590560913086 s
DEBUG 01-06 17:11:19.483483.483483 cuda_h.py:19] end gpu_experts cost 0.007616758346557617 seconds
DEBUG 01-06 17:11:19.483274.483274 cuda_h.py:19] end layer_moe_generate_2 cost 0.06796431541442871 seconds
DEBUG 01-06 17:11:19.484976.484976 lmp.py:220] -------------------------------- end layer 2 --------------------------------
DEBUG 01-06 17:11:19.484845.484845 lmp.py:176] -------------------------------- start layer 3 --------------------------------
DEBUG 01-06 17:11:19.484303.484303 cuda_h.py:10] start start_load_qkvogn_s_weight_l_4
DEBUG 01-06 17:11:19.484297.484297 cuda_h.py:10] start start_load_qkvogn_s_weight_l_4
DEBUG 01-06 17:11:19.484472.484472 cuda_h.py:19] end start_load_qkvogn_s_weight_l_4 cost 3.218650817871094e-05 seconds
DEBUG 01-06 17:11:19.484128.484128 cuda_h.py:19] end start_load_qkvogn_s_weight_l_4 cost 6.29425048828125e-05 seconds
DEBUG 01-06 17:11:19.484155.484155 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-06 17:11:19.484674.484674 cuda_h.py:10] start sllm_worker_task
DEBUG 01-06 17:11:19.484924.484924 mlpmodule.py:367] cuda:1 cuda:1
DEBUG 01-06 17:11:19.484647.484647 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 17:11:19.484810.484810 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 17:11:19.484998.484998 cuda_h.py:19] end allocate_cuda_memory cost 0.00023484230041503906 seconds
DEBUG 01-06 17:11:19.485313.485313 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 17:11:19.485221.485221 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 17:11:19.485044.485044 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 17:11:19.485555.485555 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, f92f4c28-4df9-424d-a558-32e502542c5b
DEBUG 01-06 17:11:19.485485.485485 client.py:106] call stub.LoadModelAsync
DEBUG 01-06 17:11:19.485698.485698 cuda_h.py:10] start self_attn
INFO 01-06 17:11:19.486678.486678 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, f92f4c28-4df9-424d-a558-32e502542c5b
DEBUG 01-06 17:11:19.486620.486620 cuda_h.py:19] end load_into_gpu_async cost 0.0016217231750488281 seconds
DEBUG 01-06 17:11:19.486131.486131 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 17:11:19.486174.486174 cuda_h.py:19] end restore_tensors2 cost 7.081031799316406e-05 seconds
DEBUG 01-06 17:11:19.486990.486990 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.002228260040283203 seconds
INFO 01-06 17:11:19.486866.486866 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, f92f4c28-4df9-424d-a558-32e502542c5b
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-06 17:11:19.488428.488428 cuda_h.py:19] end self_attn cost 0.003143787384033203 seconds
DEBUG 01-06 17:11:19.488935.488935 cuda_h.py:19] end iln_self_attn_paln cost 0.0046539306640625 seconds
DEBUG 01-06 17:11:19.489301.489301 cuda_h.py:10] start layer_moe_generate_3
DEBUG 01-06 17:11:19.489971.489971 cuda_h.py:10] start gate
DEBUG 01-06 17:11:19.489994.489994 cuda_h.py:19] end gate cost 0.0006496906280517578 seconds
DEBUG 01-06 17:11:19.489585.489585 cuda_h.py:10] start experts_map_get
DEBUG 01-06 17:11:19.490675.490675 lmp.py:403] 
DEBUG 01-06 17:11:19.490675.490675 lmp.py:403] Expert Token Distribution & Device Allocation:
DEBUG 01-06 17:11:19.490762.490762 lmp.py:404]   Total experts: 64
DEBUG 01-06 17:11:19.490888.490888 lmp.py:405]   CPU experts: 32 (50%)
DEBUG 01-06 17:11:19.490962.490962 lmp.py:406]   GPU experts: 32 (50%)
DEBUG 01-06 17:11:19.490367.490367 lmp.py:407] 
DEBUG 01-06 17:11:19.490367.490367 lmp.py:407]   Expert ID | Tokens | Device
DEBUG 01-06 17:11:19.490486.490486 lmp.py:408]   -----------------------------------
DEBUG 01-06 17:11:19.490189.490189 lmp.py:414]   Expert  1 |     47 | CPU
DEBUG 01-06 17:11:19.490501.490501 lmp.py:414]   Expert 27 |     60 | CPU
DEBUG 01-06 17:11:19.490144.490144 lmp.py:414]   Expert 48 |     76 | CPU
DEBUG 01-06 17:11:19.490549.490549 lmp.py:414]   Expert  7 |     81 | CPU
DEBUG 01-06 17:11:19.490953.490953 lmp.py:414]   Expert 15 |    103 | CPU
DEBUG 01-06 17:11:19.490119.490119 lmp.py:414]   Expert 30 |    109 | CPU
DEBUG 01-06 17:11:19.490524.490524 lmp.py:414]   Expert 61 |    113 | CPU
DEBUG 01-06 17:11:19.490644.490644 lmp.py:414]   Expert 18 |    116 | CPU
DEBUG 01-06 17:11:19.490048.490048 lmp.py:414]   Expert 32 |    117 | CPU
DEBUG 01-06 17:11:19.490645.490645 lmp.py:414]   Expert 45 |    123 | CPU
DEBUG 01-06 17:11:19.490811.490811 lmp.py:414]   Expert 34 |    130 | CPU
DEBUG 01-06 17:11:19.490500.490500 lmp.py:414]   Expert  5 |    136 | CPU
DEBUG 01-06 17:11:19.490666.490666 lmp.py:414]   Expert 11 |    136 | CPU
DEBUG 01-06 17:11:19.490356.490356 lmp.py:414]   Expert 26 |    136 | CPU
DEBUG 01-06 17:11:19.490283.490283 lmp.py:414]   Expert 39 |    138 | CPU
DEBUG 01-06 17:11:19.490496.490496 lmp.py:414]   Expert  6 |    139 | CPU
DEBUG 01-06 17:11:19.490901.490901 lmp.py:414]   Expert 36 |    139 | CPU
DEBUG 01-06 17:11:19.490305.490305 lmp.py:414]   Expert 59 |    141 | CPU
DEBUG 01-06 17:11:19.490471.490471 lmp.py:414]   Expert 51 |    152 | CPU
DEBUG 01-06 17:11:19.490637.490637 lmp.py:414]   Expert 23 |    157 | CPU
DEBUG 01-06 17:11:19.490803.490803 lmp.py:414]   Expert 49 |    158 | CPU
DEBUG 01-06 17:11:19.490254.490254 lmp.py:414]   Expert  9 |    161 | CPU
DEBUG 01-06 17:11:19.490944.490944 lmp.py:414]   Expert  2 |    162 | CPU
DEBUG 01-06 17:11:19.490633.490633 lmp.py:414]   Expert 35 |    164 | CPU
DEBUG 01-06 17:11:19.490845.490845 lmp.py:414]   Expert 50 |    166 | CPU
DEBUG 01-06 17:11:19.490296.490296 lmp.py:414]   Expert 56 |    166 | CPU
DEBUG 01-06 17:11:19.490986.490986 lmp.py:414]   Expert 40 |    167 | CPU
DEBUG 01-06 17:11:19.490198.490198 lmp.py:414]   Expert 52 |    172 | CPU
DEBUG 01-06 17:11:19.490887.490887 lmp.py:414]   Expert 16 |    173 | CPU
DEBUG 01-06 17:11:19.490292.490292 lmp.py:414]   Expert 13 |    189 | CPU
DEBUG 01-06 17:11:19.490458.490458 lmp.py:414]   Expert  4 |    190 | CPU
DEBUG 01-06 17:11:19.490624.490624 lmp.py:414]   Expert 37 |    191 | CPU
DEBUG 01-06 17:11:19.490029.490029 lmp.py:414]   Expert 42 |    191 | GPU
DEBUG 01-06 17:11:19.490672.490672 lmp.py:414]   Expert 62 |    194 | GPU
DEBUG 01-06 17:11:19.490838.490838 lmp.py:414]   Expert 17 |    195 | GPU
DEBUG 01-06 17:11:19.490527.490527 lmp.py:414]   Expert 38 |    199 | GPU
DEBUG 01-06 17:11:19.490455.490455 lmp.py:414]   Expert 21 |    200 | GPU
DEBUG 01-06 17:11:19.490144.490144 lmp.py:414]   Expert 44 |    203 | GPU
DEBUG 01-06 17:11:19.490310.490310 lmp.py:414]   Expert 28 |    206 | GPU
DEBUG 01-06 17:11:19.490000.490000 lmp.py:414]   Expert  3 |    209 | GPU
DEBUG 01-06 17:11:19.490166.490166 lmp.py:414]   Expert 58 |    211 | GPU
DEBUG 01-06 17:11:19.490855.490855 lmp.py:414]   Expert 60 |    212 | GPU
DEBUG 01-06 17:11:19.490783.490783 lmp.py:414]   Expert 10 |    215 | GPU
DEBUG 01-06 17:11:19.490187.490187 lmp.py:414]   Expert 55 |    219 | GPU
DEBUG 01-06 17:11:19.490830.490830 lmp.py:414]   Expert 53 |    220 | GPU
DEBUG 01-06 17:11:19.491473.491473 lmp.py:414]   Expert 47 |    221 | GPU
DEBUG 01-06 17:11:19.491878.491878 lmp.py:414]   Expert 20 |    223 | GPU
DEBUG 01-06 17:11:19.491759.491759 lmp.py:414]   Expert 57 |    226 | GPU
DEBUG 01-06 17:11:19.491449.491449 lmp.py:414]   Expert  8 |    236 | GPU
DEBUG 01-06 17:11:19.491138.491138 lmp.py:414]   Expert 46 |    236 | GPU
DEBUG 01-06 17:11:19.491827.491827 lmp.py:414]   Expert 31 |    237 | GPU
DEBUG 01-06 17:11:19.491278.491278 lmp.py:414]   Expert 33 |    237 | GPU
DEBUG 01-06 17:11:19.491729.491729 lmp.py:414]   Expert 24 |    243 | GPU
DEBUG 01-06 17:11:19.491180.491180 lmp.py:414]   Expert 19 |    248 | GPU
DEBUG 01-06 17:11:19.491108.491108 lmp.py:414]   Expert 63 |    260 | GPU
DEBUG 01-06 17:11:19.491797.491797 lmp.py:414]   Expert 14 |    266 | GPU
DEBUG 01-06 17:11:19.491440.491440 lmp.py:414]   Expert 29 |    274 | GPU
DEBUG 01-06 17:11:19.491844.491844 lmp.py:414]   Expert 12 |    276 | GPU
DEBUG 01-06 17:11:19.491249.491249 lmp.py:414]   Expert 22 |    276 | GPU
DEBUG 01-06 17:11:19.491653.491653 lmp.py:414]   Expert  0 |    291 | GPU
DEBUG 01-06 17:11:19.491581.491581 lmp.py:414]   Expert 43 |    309 | GPU
DEBUG 01-06 17:11:19.491794.491794 lmp.py:414]   Expert 54 |    354 | GPU
DEBUG 01-06 17:11:19.491483.491483 lmp.py:414]   Expert 41 |    382 | GPU
DEBUG 01-06 17:11:19.491172.491172 lmp.py:414]   Expert 25 |    411 | GPU
DEBUG 01-06 17:11:19.491577.491577 lmp.py:415] 
DEBUG 01-06 17:11:19.491577.491577 lmp.py:415]   CPU total tokens: 4408 (35.9%)
DEBUG 01-06 17:11:19.491220.491220 lmp.py:416]   GPU total tokens: 7880 (64.1%)
DEBUG 01-06 17:11:19.491439.491439 cuda_h.py:19] end experts_map_get cost 0.001550436019897461 seconds
DEBUG 01-06 17:11:19.491320.491320 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-06 17:11:19.491481.491481 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 17:11:19.491486.491486 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 17:11:19.493552.493552 cuda_h.py:19] end allocate_cuda_memory cost 0.001560211181640625 seconds
DEBUG 01-06 17:11:19.493641.493641 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 17:11:19.493635.493635 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 17:11:19.493159.493159 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 17:11:19.493478.493478 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 52b8b725-46e8-4ff5-83bb-7e3f0ea87c25
DEBUG 01-06 17:11:19.493266.493266 client.py:106] call stub.LoadModelAsync
INFO 01-06 17:11:19.493711.493711 client.py:127] Model loaded
DEBUG 01-06 17:11:19.494525.494525 cuda_h.py:19] end sllm_worker_task cost 0.009607791900634766 seconds
INFO 01-06 17:11:19.495208.495208 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 52b8b725-46e8-4ff5-83bb-7e3f0ea87c25
DEBUG 01-06 17:11:19.495389.495389 cuda_h.py:19] end load_into_gpu_async cost 0.0021333694458007812 seconds
DEBUG 01-06 17:11:19.495138.495138 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 17:11:19.495900.495900 cuda_h.py:19] end restore_tensors2 cost 0.00039577484130859375 seconds
DEBUG 01-06 17:11:19.495498.495498 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.004448890686035156 seconds
DEBUG 01-06 17:11:19.498407.498407 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.007094144821166992 seconds
DEBUG 01-06 17:11:19.498726.498726 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-06 17:11:19.498994.498994 lmp.py:461] 
DEBUG 01-06 17:11:19.498994.498994 lmp.py:461]   Computing 32 experts on CPU...
DEBUG 01-06 17:11:19.498460.498460 cuda_h.py:19] end cpu_experts_submit cost 0.00011134147644042969 seconds
DEBUG 01-06 17:11:19.498871.498871 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-06 17:11:19.505259.505259 mlpmodule.py:706] group tensors cost 0.006807565689086914 s
DEBUG 01-06 17:11:19.508276.508276 mlpmodule.py:744] pad cost 0.0016293525695800781 s
DEBUG 01-06 17:11:19.508909.508909 mlpmodule.py:750] create cpu tensor cost 4.6253204345703125e-05 s
DEBUG 01-06 17:11:19.508859.508859 mlpmodule.py:755] move to cpu cost 3.170967102050781e-05 s
DEBUG 01-06 17:11:19.518606.518606 mlpmodule.py:769] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-06 17:11:19.518556.518556 mlpmodule.py:770] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-06 17:11:19.518989.518989 mlpmodule.py:775] group_w3 first element: -0.054931640625
WARNING 01-06 17:11:19.518509.518509 mlpmodule.py:785] start einsum2
DEBUG 01-06 17:11:19.537466.537466 mlpmodule.py:795] group einsum cost 0.029340267181396484 s
DEBUG 01-06 17:11:19.538549.538549 mlpmodule.py:803] cpy2cputensor cost 0.0007121562957763672 s
DEBUG 01-06 17:11:19.542662.542662 cuda_h.py:19] end wait_cetm_experts cost 0.0441129207611084 seconds
DEBUG 01-06 17:11:19.543351.543351 cuda_h.py:10] start gpu_sexperts
DEBUG 01-06 17:11:19.543240.543240 cuda_h.py:19] end gpu_sexperts cost 0.0006134510040283203 seconds
DEBUG 01-06 17:11:19.543375.543375 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-06 17:11:19.543987.543987 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.5272369384765625e-05 seconds
DEBUG 01-06 17:11:19.543974.543974 cuda_h.py:10] start wait_experts
INFO 01-06 17:11:19.543253.543253 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 52b8b725-46e8-4ff5-83bb-7e3f0ea87c25
INFO 01-06 17:11:19.548344.548344 client.py:127] Model loaded
DEBUG 01-06 17:11:19.548909.548909 cuda_h.py:19] end wait_experts cost 0.0045566558837890625 seconds
DEBUG 01-06 17:11:19.548089.548089 cuda_h.py:10] start gpu_experts
DEBUG 01-06 17:11:19.548606.548606 lmp.py:506]   Computing 32 experts on GPU...
DEBUG 01-06 17:11:19.549102.549102 mlpmodule.py:533] gpu group tensors cost 0.0006670951843261719 s
DEBUG 01-06 17:11:19.551373.551373 mlpmodule.py:566] gpu pad cost 0.0017261505126953125 s
DEBUG 01-06 17:11:19.551354.551354 mlpmodule.py:584] gpu group einsum cost 0.0005521774291992188 s
DEBUG 01-06 17:11:19.554667.554667 mlpmodule.py:613] gpu experts func einsum cost 0.0062787532806396484 s
DEBUG 01-06 17:11:19.555928.555928 cuda_h.py:19] end gpu_experts cost 0.0064547061920166016 seconds
DEBUG 01-06 17:11:19.555514.555514 cuda_h.py:19] end layer_moe_generate_3 cost 0.06606721878051758 seconds
DEBUG 01-06 17:11:19.555673.555673 lmp.py:220] -------------------------------- end layer 3 --------------------------------
DEBUG 01-06 17:11:19.555720.555720 lmp.py:176] -------------------------------- start layer 4 --------------------------------
DEBUG 01-06 17:11:19.555317.555317 cuda_h.py:10] start start_load_qkvogn_s_weight_l_5
DEBUG 01-06 17:11:19.555927.555927 cuda_h.py:10] start start_load_qkvogn_s_weight_l_5
DEBUG 01-06 17:11:19.555286.555286 cuda_h.py:19] end start_load_qkvogn_s_weight_l_5 cost 3.0279159545898438e-05 seconds
DEBUG 01-06 17:11:19.555413.555413 cuda_h.py:19] end start_load_qkvogn_s_weight_l_5 cost 5.841255187988281e-05 seconds
DEBUG 01-06 17:11:19.555102.555102 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-06 17:11:19.555813.555813 mlpmodule.py:367] cuda:1 cuda:1
DEBUG 01-06 17:11:19.555677.555677 cuda_h.py:10] start sllm_worker_task
DEBUG 01-06 17:11:19.555289.555289 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 17:11:19.555980.555980 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 17:11:19.573546.573546 cuda_h.py:19] end allocate_cuda_memory cost 0.017632722854614258 seconds
DEBUG 01-06 17:11:19.573620.573620 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 17:11:19.573716.573716 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 17:11:19.573395.573395 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 17:11:19.574855.574855 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 3c6c05a9-bd04-404b-bd2c-ad0c1909b485
DEBUG 01-06 17:11:19.574097.574097 client.py:106] call stub.LoadModelAsync
DEBUG 01-06 17:11:19.574285.574285 cuda_h.py:10] start self_attn
INFO 01-06 17:11:19.575442.575442 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 3c6c05a9-bd04-404b-bd2c-ad0c1909b485
DEBUG 01-06 17:11:19.576771.576771 cuda_h.py:19] end load_into_gpu_async cost 0.0022521018981933594 seconds
DEBUG 01-06 17:11:19.576873.576873 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 17:11:19.576063.576063 cuda_h.py:19] end restore_tensors2 cost 0.00017762184143066406 seconds
DEBUG 01-06 17:11:19.576232.576232 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.020801782608032227 seconds
INFO 01-06 17:11:19.576721.576721 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 3c6c05a9-bd04-404b-bd2c-ad0c1909b485
DEBUG 01-06 17:11:19.580436.580436 mlpmodule.py:664]  experts func einsum cost 0.08132791519165039 s
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-06 17:11:19.582099.582099 cuda_h.py:19] end self_attn cost 0.007724285125732422 seconds
DEBUG 01-06 17:11:19.583495.583495 cuda_h.py:19] end iln_self_attn_paln cost 0.027912378311157227 seconds
DEBUG 01-06 17:11:19.583308.583308 cuda_h.py:10] start layer_moe_generate_4
DEBUG 01-06 17:11:19.583013.583013 cuda_h.py:10] start gate
INFO 01-06 17:11:19.584741.584741 client.py:127] Model loaded
DEBUG 01-06 17:11:19.585796.585796 cuda_h.py:19] end sllm_worker_task cost 0.029572486877441406 seconds
DEBUG 01-06 17:11:19.586821.586821 cuda_h.py:19] end gate cost 0.002679586410522461 seconds
DEBUG 01-06 17:11:19.586415.586415 cuda_h.py:10] start experts_map_get
DEBUG 01-06 17:11:19.587462.587462 lmp.py:403] 
DEBUG 01-06 17:11:19.587462.587462 lmp.py:403] Expert Token Distribution & Device Allocation:
DEBUG 01-06 17:11:19.587624.587624 lmp.py:404]   Total experts: 64
DEBUG 01-06 17:11:19.587758.587758 lmp.py:405]   CPU experts: 32 (50%)
DEBUG 01-06 17:11:19.587409.587409 lmp.py:406]   GPU experts: 32 (50%)
DEBUG 01-06 17:11:19.587623.587623 lmp.py:407] 
DEBUG 01-06 17:11:19.587623.587623 lmp.py:407]   Expert ID | Tokens | Device
DEBUG 01-06 17:11:19.587406.587406 lmp.py:408]   -----------------------------------
DEBUG 01-06 17:11:19.587541.587541 lmp.py:414]   Expert 14 |     68 | CPU
DEBUG 01-06 17:11:19.587993.587993 lmp.py:414]   Expert 57 |     72 | CPU
DEBUG 01-06 17:11:19.587061.587061 lmp.py:414]   Expert 13 |     75 | CPU
DEBUG 01-06 17:11:19.587797.587797 lmp.py:414]   Expert 31 |     83 | CPU
DEBUG 01-06 17:11:19.587342.587342 lmp.py:414]   Expert 26 |     90 | CPU
DEBUG 01-06 17:11:19.588980.588980 lmp.py:414]   Expert 45 |     96 | CPU
DEBUG 01-06 17:11:19.588140.588140 lmp.py:414]   Expert 58 |     97 | CPU
DEBUG 01-06 17:11:19.588446.588446 lmp.py:414]   Expert 54 |    100 | CPU
DEBUG 01-06 17:11:19.588037.588037 lmp.py:414]   Expert 11 |    101 | CPU
DEBUG 01-06 17:11:19.588913.588913 lmp.py:414]   Expert 30 |    107 | CPU
DEBUG 01-06 17:11:19.588551.588551 lmp.py:414]   Expert 36 |    112 | CPU
DEBUG 01-06 17:11:19.588380.588380 lmp.py:414]   Expert 32 |    116 | CPU
DEBUG 01-06 17:11:19.588686.588686 lmp.py:414]   Expert 51 |    116 | CPU
DEBUG 01-06 17:11:19.588589.588589 lmp.py:414]   Expert 10 |    119 | CPU
DEBUG 01-06 17:11:19.588704.588704 lmp.py:414]   Expert  8 |    127 | CPU
DEBUG 01-06 17:11:19.588149.588149 lmp.py:414]   Expert 20 |    129 | CPU
DEBUG 01-06 17:11:19.588548.588548 lmp.py:414]   Expert 47 |    132 | CPU
DEBUG 01-06 17:11:19.588616.588616 lmp.py:414]   Expert 34 |    142 | CPU
DEBUG 01-06 17:11:19.588207.588207 lmp.py:414]   Expert 53 |    142 | CPU
DEBUG 01-06 17:11:19.588367.588367 lmp.py:414]   Expert 63 |    142 | CPU
DEBUG 01-06 17:11:19.588290.588290 lmp.py:414]   Expert  4 |    143 | CPU
DEBUG 01-06 17:11:19.588735.588735 lmp.py:414]   Expert 61 |    144 | CPU
DEBUG 01-06 17:11:19.588372.588372 lmp.py:414]   Expert 16 |    149 | CPU
DEBUG 01-06 17:11:19.588771.588771 lmp.py:414]   Expert 60 |    150 | CPU
DEBUG 01-06 17:11:19.588693.588693 lmp.py:414]   Expert 42 |    158 | CPU
DEBUG 01-06 17:11:19.589900.589900 lmp.py:414]   Expert 28 |    159 | CPU
DEBUG 01-06 17:11:19.589346.589346 lmp.py:414]   Expert 17 |    165 | CPU
DEBUG 01-06 17:11:19.589460.589460 lmp.py:414]   Expert 27 |    170 | CPU
DEBUG 01-06 17:11:19.589574.589574 lmp.py:414]   Expert 29 |    170 | CPU
DEBUG 01-06 17:11:19.589735.589735 lmp.py:414]   Expert 41 |    171 | CPU
DEBUG 01-06 17:11:19.589657.589657 lmp.py:414]   Expert  7 |    174 | CPU
DEBUG 01-06 17:11:19.589486.589486 lmp.py:414]   Expert 48 |    179 | CPU
DEBUG 01-06 17:11:19.589316.589316 lmp.py:414]   Expert  9 |    181 | GPU
DEBUG 01-06 17:11:19.589999.589999 lmp.py:414]   Expert 44 |    183 | GPU
DEBUG 01-06 17:11:19.589683.589683 lmp.py:414]   Expert  2 |    185 | GPU
DEBUG 01-06 17:11:19.589321.589321 lmp.py:414]   Expert 56 |    188 | GPU
DEBUG 01-06 17:11:19.589912.589912 lmp.py:414]   Expert  3 |    194 | GPU
DEBUG 01-06 17:11:19.589357.589357 lmp.py:414]   Expert 18 |    196 | GPU
DEBUG 01-06 17:11:19.589802.589802 lmp.py:414]   Expert 55 |    198 | GPU
DEBUG 01-06 17:11:19.589678.589678 lmp.py:414]   Expert  0 |    199 | GPU
DEBUG 01-06 17:11:19.589269.589269 lmp.py:414]   Expert 15 |    200 | GPU
DEBUG 01-06 17:11:19.589191.589191 lmp.py:414]   Expert 24 |    200 | GPU
DEBUG 01-06 17:11:19.589021.589021 lmp.py:414]   Expert 22 |    206 | GPU
DEBUG 01-06 17:11:19.589373.589373 lmp.py:414]   Expert 40 |    214 | GPU
DEBUG 01-06 17:11:19.589011.589011 lmp.py:414]   Expert 38 |    215 | GPU
DEBUG 01-06 17:11:19.589933.589933 lmp.py:414]   Expert 37 |    221 | GPU
DEBUG 01-06 17:11:19.590524.590524 lmp.py:414]   Expert  6 |    222 | GPU
DEBUG 01-06 17:11:19.590877.590877 lmp.py:414]   Expert 23 |    225 | GPU
DEBUG 01-06 17:11:19.590514.590514 lmp.py:414]   Expert 46 |    233 | GPU
DEBUG 01-06 17:11:19.590198.590198 lmp.py:414]   Expert 19 |    246 | GPU
DEBUG 01-06 17:11:19.590219.590219 lmp.py:414]   Expert 25 |    248 | GPU
DEBUG 01-06 17:11:19.590049.590049 lmp.py:414]   Expert 39 |    253 | GPU
DEBUG 01-06 17:11:19.590832.590832 lmp.py:414]   Expert 12 |    259 | GPU
DEBUG 01-06 17:11:19.590231.590231 lmp.py:414]   Expert 50 |    263 | GPU
DEBUG 01-06 17:11:19.590676.590676 lmp.py:414]   Expert 21 |    272 | GPU
DEBUG 01-06 17:11:19.590314.590314 lmp.py:414]   Expert 62 |    273 | GPU
DEBUG 01-06 17:11:19.590666.590666 lmp.py:414]   Expert 35 |    284 | GPU
DEBUG 01-06 17:11:19.590635.590635 lmp.py:414]   Expert 49 |    286 | GPU
DEBUG 01-06 17:11:19.590318.590318 lmp.py:414]   Expert 33 |    290 | GPU
DEBUG 01-06 17:11:19.590433.590433 lmp.py:414]   Expert 52 |    303 | GPU
DEBUG 01-06 17:11:19.590024.590024 lmp.py:414]   Expert  1 |    355 | GPU
DEBUG 01-06 17:11:19.590899.590899 lmp.py:414]   Expert  5 |    378 | GPU
DEBUG 01-06 17:11:19.590034.590034 lmp.py:414]   Expert 43 |    441 | GPU
DEBUG 01-06 17:11:19.590207.590207 lmp.py:414]   Expert 59 |    579 | GPU
DEBUG 01-06 17:11:19.590049.590049 lmp.py:415] 
DEBUG 01-06 17:11:19.590049.590049 lmp.py:415]   CPU total tokens: 4098 (33.3%)
DEBUG 01-06 17:11:19.590844.590844 lmp.py:416]   GPU total tokens: 8190 (66.7%)
DEBUG 01-06 17:11:19.590408.590408 cuda_h.py:19] end experts_map_get cost 0.004280567169189453 seconds
DEBUG 01-06 17:11:19.590442.590442 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-06 17:11:19.591385.591385 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 17:11:19.591331.591331 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 17:11:19.591030.591030 cuda_h.py:19] end allocate_cuda_memory cost 0.0002624988555908203 seconds
DEBUG 01-06 17:11:19.591178.591178 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 17:11:19.591610.591610 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 17:11:19.591148.591148 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 17:11:19.591427.591427 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, cd4d1254-1913-46b3-bbd2-b7893dbf9b7d
DEBUG 01-06 17:11:19.591482.591482 client.py:106] call stub.LoadModelAsync
INFO 01-06 17:11:19.593641.593641 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, cd4d1254-1913-46b3-bbd2-b7893dbf9b7d
DEBUG 01-06 17:11:19.593067.593067 cuda_h.py:19] end load_into_gpu_async cost 0.002371549606323242 seconds
DEBUG 01-06 17:11:19.594637.594637 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 17:11:19.594650.594650 cuda_h.py:19] end restore_tensors2 cost 0.0005352497100830078 seconds
DEBUG 01-06 17:11:19.594560.594560 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0036096572875976562 seconds
DEBUG 01-06 17:11:19.598668.598668 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.0072934627532958984 seconds
DEBUG 01-06 17:11:19.598385.598385 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-06 17:11:19.598329.598329 lmp.py:461] 
DEBUG 01-06 17:11:19.598329.598329 lmp.py:461]   Computing 32 experts on CPU...
DEBUG 01-06 17:11:19.598007.598007 cuda_h.py:19] end cpu_experts_submit cost 0.00013947486877441406 seconds
DEBUG 01-06 17:11:19.598432.598432 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-06 17:11:19.605872.605872 mlpmodule.py:706] group tensors cost 0.0067555904388427734 s
DEBUG 01-06 17:11:19.607559.607559 mlpmodule.py:744] pad cost 0.0016410350799560547 s
DEBUG 01-06 17:11:19.608384.608384 mlpmodule.py:750] create cpu tensor cost 4.887580871582031e-05 s
DEBUG 01-06 17:11:19.608526.608526 mlpmodule.py:755] move to cpu cost 3.2901763916015625e-05 s
DEBUG 01-06 17:11:19.621788.621788 mlpmodule.py:769] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-06 17:11:19.621547.621547 mlpmodule.py:770] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-06 17:11:19.621364.621364 mlpmodule.py:775] group_w3 first element: 0.0086669921875
WARNING 01-06 17:11:19.621506.621506 mlpmodule.py:785] start einsum2
DEBUG 01-06 17:11:19.638327.638327 mlpmodule.py:795] group einsum cost 0.030791521072387695 s
DEBUG 01-06 17:11:19.639443.639443 mlpmodule.py:803] cpy2cputensor cost 0.0007493495941162109 s
DEBUG 01-06 17:11:19.644485.644485 cuda_h.py:19] end wait_cetm_experts cost 0.045592308044433594 seconds
DEBUG 01-06 17:11:19.644472.644472 cuda_h.py:10] start gpu_sexperts
DEBUG 01-06 17:11:19.645785.645785 cuda_h.py:19] end gpu_sexperts cost 0.0006096363067626953 seconds
DEBUG 01-06 17:11:19.645681.645681 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-06 17:11:19.645962.645962 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.6226043701171875e-05 seconds
DEBUG 01-06 17:11:19.645380.645380 cuda_h.py:10] start wait_experts
INFO 01-06 17:11:19.645328.645328 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, cd4d1254-1913-46b3-bbd2-b7893dbf9b7d
INFO 01-06 17:11:19.647501.647501 client.py:127] Model loaded
DEBUG 01-06 17:11:19.647365.647365 cuda_h.py:19] end wait_experts cost 0.0018773078918457031 seconds
DEBUG 01-06 17:11:19.647690.647690 cuda_h.py:10] start gpu_experts
DEBUG 01-06 17:11:19.647208.647208 lmp.py:506]   Computing 32 experts on GPU...
DEBUG 01-06 17:11:19.647379.647379 mlpmodule.py:533] gpu group tensors cost 0.0006690025329589844 s
DEBUG 01-06 17:11:19.652877.652877 mlpmodule.py:566] gpu pad cost 0.004735708236694336 s
DEBUG 01-06 17:11:19.654811.654811 mlpmodule.py:664]  experts func einsum cost 0.055399417877197266 s
DEBUG 01-06 17:11:19.654252.654252 mlpmodule.py:584] gpu group einsum cost 0.0014095306396484375 s
DEBUG 01-06 17:11:19.657558.657558 mlpmodule.py:613] gpu experts func einsum cost 0.010172367095947266 s
DEBUG 01-06 17:11:19.657101.657101 cuda_h.py:19] end gpu_experts cost 0.01045680046081543 seconds
DEBUG 01-06 17:11:19.657362.657362 cuda_h.py:19] end layer_moe_generate_4 cost 0.07412362098693848 seconds
DEBUG 01-06 17:11:19.657289.657289 lmp.py:220] -------------------------------- end layer 4 --------------------------------
DEBUG 01-06 17:11:19.658436.658436 lmp.py:176] -------------------------------- start layer 5 --------------------------------
DEBUG 01-06 17:11:19.658960.658960 cuda_h.py:10] start start_load_qkvogn_s_weight_l_6
DEBUG 01-06 17:11:19.658571.658571 cuda_h.py:10] start start_load_qkvogn_s_weight_l_6
DEBUG 01-06 17:11:19.658414.658414 cuda_h.py:19] end start_load_qkvogn_s_weight_l_6 cost 3.3855438232421875e-05 seconds
DEBUG 01-06 17:11:19.658971.658971 cuda_h.py:19] end start_load_qkvogn_s_weight_l_6 cost 6.318092346191406e-05 seconds
DEBUG 01-06 17:11:19.658780.658780 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-06 17:11:19.658829.658829 mlpmodule.py:367] cuda:1 cuda:1
DEBUG 01-06 17:11:19.658315.658315 cuda_h.py:10] start sllm_worker_task
DEBUG 01-06 17:11:19.658622.658622 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 17:11:19.658419.658419 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 17:11:19.658421.658421 cuda_h.py:19] end allocate_cuda_memory cost 0.0002086162567138672 seconds
DEBUG 01-06 17:11:19.658529.658529 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 17:11:19.658100.658100 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 17:11:19.658730.658730 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 17:11:19.658764.658764 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 3ffe80c4-ca52-4724-afd0-4215366c4901
DEBUG 01-06 17:11:19.659873.659873 client.py:106] call stub.LoadModelAsync
DEBUG 01-06 17:11:19.659192.659192 cuda_h.py:10] start self_attn
INFO 01-06 17:11:19.660120.660120 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 3ffe80c4-ca52-4724-afd0-4215366c4901
DEBUG 01-06 17:11:19.660838.660838 cuda_h.py:19] end load_into_gpu_async cost 0.001667022705078125 seconds
DEBUG 01-06 17:11:19.660494.660494 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 17:11:19.660054.660054 cuda_h.py:19] end restore_tensors2 cost 7.009506225585938e-05 seconds
DEBUG 01-06 17:11:19.660095.660095 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0022068023681640625 seconds
INFO 01-06 17:11:19.660938.660938 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 3ffe80c4-ca52-4724-afd0-4215366c4901
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-06 17:11:19.662848.662848 cuda_h.py:19] end self_attn cost 0.002914905548095703 seconds
DEBUG 01-06 17:11:19.662587.662587 cuda_h.py:19] end iln_self_attn_paln cost 0.004288434982299805 seconds
DEBUG 01-06 17:11:19.662092.662092 cuda_h.py:10] start layer_moe_generate_5
DEBUG 01-06 17:11:19.662021.662021 cuda_h.py:10] start gate
DEBUG 01-06 17:11:19.663898.663898 cuda_h.py:19] end gate cost 0.0006482601165771484 seconds
DEBUG 01-06 17:11:19.663396.663396 cuda_h.py:10] start experts_map_get
DEBUG 01-06 17:11:19.663572.663572 lmp.py:403] 
DEBUG 01-06 17:11:19.663572.663572 lmp.py:403] Expert Token Distribution & Device Allocation:
DEBUG 01-06 17:11:19.663421.663421 lmp.py:404]   Total experts: 64
DEBUG 01-06 17:11:19.663309.663309 lmp.py:405]   CPU experts: 32 (50%)
DEBUG 01-06 17:11:19.663144.663144 lmp.py:406]   GPU experts: 32 (50%)
DEBUG 01-06 17:11:19.663787.663787 lmp.py:407] 
DEBUG 01-06 17:11:19.663787.663787 lmp.py:407]   Expert ID | Tokens | Device
DEBUG 01-06 17:11:19.663192.663192 lmp.py:408]   -----------------------------------
DEBUG 01-06 17:11:19.663318.663318 lmp.py:414]   Expert 34 |     24 | CPU
DEBUG 01-06 17:11:19.663961.663961 lmp.py:414]   Expert 45 |     62 | CPU
DEBUG 01-06 17:11:19.663650.663650 lmp.py:414]   Expert 57 |     73 | CPU
DEBUG 01-06 17:11:19.663624.663624 lmp.py:414]   Expert 22 |     76 | CPU
DEBUG 01-06 17:11:19.663837.663837 lmp.py:414]   Expert 17 |     93 | CPU
DEBUG 01-06 17:11:19.663811.663811 lmp.py:414]   Expert  4 |     97 | CPU
DEBUG 01-06 17:11:19.663023.663023 lmp.py:414]   Expert 15 |    101 | CPU
DEBUG 01-06 17:11:19.663474.663474 lmp.py:414]   Expert 28 |    106 | CPU
DEBUG 01-06 17:11:19.663687.663687 lmp.py:414]   Expert 60 |    116 | CPU
DEBUG 01-06 17:11:19.663138.663138 lmp.py:414]   Expert 14 |    118 | CPU
DEBUG 01-06 17:11:19.663589.663589 lmp.py:414]   Expert 32 |    122 | CPU
DEBUG 01-06 17:11:19.663039.663039 lmp.py:414]   Expert 52 |    122 | CPU
DEBUG 01-06 17:11:19.663967.663967 lmp.py:414]   Expert 36 |    123 | CPU
DEBUG 01-06 17:11:19.664133.664133 lmp.py:414]   Expert 25 |    127 | CPU
DEBUG 01-06 17:11:19.664107.664107 lmp.py:414]   Expert 12 |    129 | CPU
DEBUG 01-06 17:11:19.664750.664750 lmp.py:414]   Expert  2 |    133 | CPU
DEBUG 01-06 17:11:19.664916.664916 lmp.py:414]   Expert 16 |    135 | CPU
DEBUG 01-06 17:11:19.664844.664844 lmp.py:414]   Expert  8 |    137 | CPU
DEBUG 01-06 17:11:19.664533.664533 lmp.py:414]   Expert  5 |    141 | CPU
DEBUG 01-06 17:11:19.664223.664223 lmp.py:414]   Expert 35 |    147 | CPU
DEBUG 01-06 17:11:19.664389.664389 lmp.py:414]   Expert 39 |    149 | CPU
DEBUG 01-06 17:11:19.664078.664078 lmp.py:414]   Expert 61 |    150 | CPU
DEBUG 01-06 17:11:19.664244.664244 lmp.py:414]   Expert  0 |    156 | CPU
DEBUG 01-06 17:11:19.664649.664649 lmp.py:414]   Expert 23 |    159 | CPU
DEBUG 01-06 17:11:19.664053.664053 lmp.py:414]   Expert 30 |    162 | CPU
DEBUG 01-06 17:11:19.664696.664696 lmp.py:414]   Expert 42 |    168 | CPU
DEBUG 01-06 17:11:19.664578.664578 lmp.py:414]   Expert  3 |    169 | CPU
DEBUG 01-06 17:11:19.664982.664982 lmp.py:414]   Expert 13 |    170 | CPU
DEBUG 01-06 17:11:19.664910.664910 lmp.py:414]   Expert 31 |    173 | CPU
DEBUG 01-06 17:11:19.664838.664838 lmp.py:414]   Expert 44 |    174 | CPU
DEBUG 01-06 17:11:19.664289.664289 lmp.py:414]   Expert 46 |    175 | CPU
DEBUG 01-06 17:11:19.664978.664978 lmp.py:414]   Expert  9 |    178 | CPU
DEBUG 01-06 17:11:19.664144.664144 lmp.py:414]   Expert 41 |    183 | GPU
DEBUG 01-06 17:11:19.664072.664072 lmp.py:414]   Expert 62 |    187 | GPU
DEBUG 01-06 17:11:19.664761.664761 lmp.py:414]   Expert 27 |    188 | GPU
DEBUG 01-06 17:11:19.664881.664881 lmp.py:414]   Expert 43 |    188 | GPU
DEBUG 01-06 17:11:19.664538.664538 lmp.py:414]   Expert 26 |    189 | GPU
DEBUG 01-06 17:11:19.664465.664465 lmp.py:414]   Expert 18 |    191 | GPU
DEBUG 01-06 17:11:19.664870.664870 lmp.py:414]   Expert 47 |    195 | GPU
DEBUG 01-06 17:11:19.664513.664513 lmp.py:414]   Expert 49 |    195 | GPU
DEBUG 01-06 17:11:19.664917.664917 lmp.py:414]   Expert 11 |    198 | GPU
DEBUG 01-06 17:11:19.664322.664322 lmp.py:414]   Expert 51 |    198 | GPU
DEBUG 01-06 17:11:19.664488.664488 lmp.py:414]   Expert 50 |    200 | GPU
DEBUG 01-06 17:11:19.664177.664177 lmp.py:414]   Expert 19 |    202 | GPU
DEBUG 01-06 17:11:19.664105.664105 lmp.py:414]   Expert 20 |    203 | GPU
DEBUG 01-06 17:11:19.664794.664794 lmp.py:414]   Expert 55 |    204 | GPU
DEBUG 01-06 17:11:19.664484.664484 lmp.py:414]   Expert 56 |    204 | GPU
DEBUG 01-06 17:11:19.664173.664173 lmp.py:414]   Expert 63 |    204 | GPU
DEBUG 01-06 17:11:19.664862.664862 lmp.py:414]   Expert 38 |    219 | GPU
DEBUG 01-06 17:11:19.664836.664836 lmp.py:414]   Expert 48 |    222 | GPU
DEBUG 01-06 17:11:19.664241.664241 lmp.py:414]   Expert  7 |    226 | GPU
DEBUG 01-06 17:11:19.664122.664122 lmp.py:414]   Expert  1 |    237 | GPU
DEBUG 01-06 17:11:19.664527.664527 lmp.py:414]   Expert 10 |    242 | GPU
DEBUG 01-06 17:11:19.664693.664693 lmp.py:414]   Expert 54 |    246 | GPU
DEBUG 01-06 17:11:19.664621.664621 lmp.py:414]   Expert 21 |    259 | GPU
DEBUG 01-06 17:11:19.664310.664310 lmp.py:414]   Expert 33 |    259 | GPU
DEBUG 01-06 17:11:19.664238.664238 lmp.py:414]   Expert 29 |    265 | GPU
DEBUG 01-06 17:11:19.664927.664927 lmp.py:414]   Expert 40 |    266 | GPU
DEBUG 01-06 17:11:19.664616.664616 lmp.py:414]   Expert 24 |    274 | GPU
DEBUG 01-06 17:11:19.664829.664829 lmp.py:414]   Expert 59 |    298 | GPU
DEBUG 01-06 17:11:19.664518.664518 lmp.py:414]   Expert 37 |    344 | GPU
DEBUG 01-06 17:11:19.664207.664207 lmp.py:414]   Expert 58 |    370 | GPU
DEBUG 01-06 17:11:19.664135.664135 lmp.py:414]   Expert  6 |    395 | GPU
DEBUG 01-06 17:11:19.664063.664063 lmp.py:414]   Expert 53 |    872 | GPU
DEBUG 01-06 17:11:19.664183.664183 lmp.py:415] 
DEBUG 01-06 17:11:19.664183.664183 lmp.py:415]   CPU total tokens: 4165 (33.9%)
DEBUG 01-06 17:11:19.664541.664541 lmp.py:416]   GPU total tokens: 8123 (66.1%)
DEBUG 01-06 17:11:19.664429.664429 cuda_h.py:19] end experts_map_get cost 0.0015416145324707031 seconds
DEBUG 01-06 17:11:19.664787.664787 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-06 17:11:19.664233.664233 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 17:11:19.665138.665138 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 17:11:19.666730.666730 cuda_h.py:19] end allocate_cuda_memory cost 0.0016331672668457031 seconds
DEBUG 01-06 17:11:19.666779.666779 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 17:11:19.666965.666965 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 17:11:19.666536.666536 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 17:11:19.666994.666994 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 0277d504-17a5-43c9-a16e-225ef60dcc6b
DEBUG 01-06 17:11:19.667490.667490 client.py:106] call stub.LoadModelAsync
INFO 01-06 17:11:19.668193.668193 client.py:127] Model loaded
DEBUG 01-06 17:11:19.668093.668093 cuda_h.py:19] end sllm_worker_task cost 0.010498523712158203 seconds
INFO 01-06 17:11:19.670586.670586 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 0277d504-17a5-43c9-a16e-225ef60dcc6b
DEBUG 01-06 17:11:19.670982.670982 cuda_h.py:19] end load_into_gpu_async cost 0.003434896469116211 seconds
DEBUG 01-06 17:11:19.670137.670137 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 17:11:19.670506.670506 cuda_h.py:19] end restore_tensors2 cost 0.0004868507385253906 seconds
DEBUG 01-06 17:11:19.671872.671872 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0060312747955322266 seconds
DEBUG 01-06 17:11:19.675077.675077 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.010599136352539062 seconds
DEBUG 01-06 17:11:19.675776.675776 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-06 17:11:19.675793.675793 lmp.py:461] 
DEBUG 01-06 17:11:19.675793.675793 lmp.py:461]   Computing 32 experts on CPU...
DEBUG 01-06 17:11:19.675922.675922 cuda_h.py:19] end cpu_experts_submit cost 0.00016498565673828125 seconds
DEBUG 01-06 17:11:19.675215.675215 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-06 17:11:19.689637.689637 mlpmodule.py:706] group tensors cost 0.012962579727172852 s
DEBUG 01-06 17:11:19.691982.691982 mlpmodule.py:744] pad cost 0.001634836196899414 s
DEBUG 01-06 17:11:19.691893.691893 mlpmodule.py:750] create cpu tensor cost 4.696846008300781e-05 s
DEBUG 01-06 17:11:19.691180.691180 mlpmodule.py:755] move to cpu cost 3.4809112548828125e-05 s
DEBUG 01-06 17:11:19.702913.702913 mlpmodule.py:769] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-06 17:11:19.702274.702274 mlpmodule.py:770] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-06 17:11:19.702038.702038 mlpmodule.py:775] group_w3 first element: 0.03369140625
WARNING 01-06 17:11:19.702770.702770 mlpmodule.py:785] start einsum2
DEBUG 01-06 17:11:19.720759.720759 mlpmodule.py:795] group einsum cost 0.028310537338256836 s
DEBUG 01-06 17:11:19.720750.720750 mlpmodule.py:803] cpy2cputensor cost 0.0007550716400146484 s
DEBUG 01-06 17:11:19.725303.725303 cuda_h.py:19] end wait_cetm_experts cost 0.049405813217163086 seconds
DEBUG 01-06 17:11:19.725707.725707 cuda_h.py:10] start gpu_sexperts
DEBUG 01-06 17:11:19.726828.726828 cuda_h.py:19] end gpu_sexperts cost 0.0006077289581298828 seconds
DEBUG 01-06 17:11:19.726393.726393 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-06 17:11:19.726243.726243 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.384185791015625e-05 seconds
DEBUG 01-06 17:11:19.726138.726138 cuda_h.py:10] start wait_experts
INFO 01-06 17:11:19.726847.726847 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 0277d504-17a5-43c9-a16e-225ef60dcc6b
INFO 01-06 17:11:19.727050.727050 client.py:127] Model loaded
DEBUG 01-06 17:11:19.727324.727324 cuda_h.py:19] end wait_experts cost 0.0013704299926757812 seconds
DEBUG 01-06 17:11:19.727457.727457 cuda_h.py:10] start gpu_experts
DEBUG 01-06 17:11:19.727498.727498 lmp.py:506]   Computing 32 experts on GPU...
DEBUG 01-06 17:11:19.728583.728583 mlpmodule.py:533] gpu group tensors cost 0.0006787776947021484 s
DEBUG 01-06 17:11:19.734634.734634 mlpmodule.py:566] gpu pad cost 0.005805015563964844 s
DEBUG 01-06 17:11:19.736619.736619 mlpmodule.py:664]  experts func einsum cost 0.05992460250854492 s
DEBUG 01-06 17:11:19.737131.737131 mlpmodule.py:584] gpu group einsum cost 0.002451658248901367 s
DEBUG 01-06 17:11:19.740755.740755 mlpmodule.py:613] gpu experts func einsum cost 0.01214456558227539 s
DEBUG 01-06 17:11:19.740980.740980 cuda_h.py:19] end gpu_experts cost 0.012434959411621094 seconds
DEBUG 01-06 17:11:19.740421.740421 cuda_h.py:19] end layer_moe_generate_5 cost 0.07782721519470215 seconds
DEBUG 01-06 17:11:19.740746.740746 lmp.py:220] -------------------------------- end layer 5 --------------------------------
DEBUG 01-06 17:11:19.740184.740184 lmp.py:176] -------------------------------- start layer 6 --------------------------------
DEBUG 01-06 17:11:19.740404.740404 cuda_h.py:10] start start_load_qkvogn_s_weight_l_7
DEBUG 01-06 17:11:19.740160.740160 cuda_h.py:10] start start_load_qkvogn_s_weight_l_7
DEBUG 01-06 17:11:19.740480.740480 cuda_h.py:19] end start_load_qkvogn_s_weight_l_7 cost 3.2901763916015625e-05 seconds
DEBUG 01-06 17:11:19.740375.740375 cuda_h.py:19] end start_load_qkvogn_s_weight_l_7 cost 6.604194641113281e-05 seconds
DEBUG 01-06 17:11:19.740879.740879 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-06 17:11:19.740643.740643 mlpmodule.py:367] cuda:1 cuda:1
DEBUG 01-06 17:11:19.741612.741612 cuda_h.py:10] start sllm_worker_task
DEBUG 01-06 17:11:19.741894.741894 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 17:11:19.741207.741207 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 17:11:19.741891.741891 cuda_h.py:19] end allocate_cuda_memory cost 0.0002231597900390625 seconds
DEBUG 01-06 17:11:19.741530.741530 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 17:11:19.741100.741100 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 17:11:19.741300.741300 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 17:11:19.741858.741858 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, dcdfb20d-d1b4-4fa2-ad72-902aeb48cb62
DEBUG 01-06 17:11:19.741443.741443 client.py:106] call stub.LoadModelAsync
DEBUG 01-06 17:11:19.741146.741146 cuda_h.py:10] start self_attn
INFO 01-06 17:11:19.743577.743577 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, dcdfb20d-d1b4-4fa2-ad72-902aeb48cb62
DEBUG 01-06 17:11:19.743937.743937 cuda_h.py:19] end load_into_gpu_async cost 0.0016345977783203125 seconds
DEBUG 01-06 17:11:19.743255.743255 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 17:11:19.743391.743391 cuda_h.py:19] end restore_tensors2 cost 7.390975952148438e-05 seconds
DEBUG 01-06 17:11:19.743909.743909 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0021889209747314453 seconds
INFO 01-06 17:11:19.743441.743441 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, dcdfb20d-d1b4-4fa2-ad72-902aeb48cb62
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-06 17:11:19.744830.744830 cuda_h.py:19] end self_attn cost 0.0029287338256835938 seconds
DEBUG 01-06 17:11:19.745489.745489 cuda_h.py:19] end iln_self_attn_paln cost 0.004353523254394531 seconds
DEBUG 01-06 17:11:19.745948.745948 cuda_h.py:10] start layer_moe_generate_6
DEBUG 01-06 17:11:19.745618.745618 cuda_h.py:10] start gate
DEBUG 01-06 17:11:19.746740.746740 cuda_h.py:19] end gate cost 0.0006532669067382812 seconds
DEBUG 01-06 17:11:19.746000.746000 cuda_h.py:10] start experts_map_get
DEBUG 01-06 17:11:19.746090.746090 lmp.py:403] 
DEBUG 01-06 17:11:19.746090.746090 lmp.py:403] Expert Token Distribution & Device Allocation:
DEBUG 01-06 17:11:19.746131.746131 lmp.py:404]   Total experts: 64
DEBUG 01-06 17:11:19.746781.746781 lmp.py:405]   CPU experts: 32 (50%)
DEBUG 01-06 17:11:19.746808.746808 lmp.py:406]   GPU experts: 32 (50%)
DEBUG 01-06 17:11:19.746451.746451 lmp.py:407] 
DEBUG 01-06 17:11:19.746451.746451 lmp.py:407]   Expert ID | Tokens | Device
DEBUG 01-06 17:11:19.746094.746094 lmp.py:408]   -----------------------------------
DEBUG 01-06 17:11:19.746174.746174 lmp.py:414]   Expert  1 |     40 | CPU
DEBUG 01-06 17:11:19.746340.746340 lmp.py:414]   Expert  7 |     62 | CPU
DEBUG 01-06 17:11:19.746030.746030 lmp.py:414]   Expert 37 |     70 | CPU
DEBUG 01-06 17:11:19.746004.746004 lmp.py:414]   Expert 17 |     81 | CPU
DEBUG 01-06 17:11:19.746978.746978 lmp.py:414]   Expert 18 |     81 | CPU
DEBUG 01-06 17:11:19.746713.746713 lmp.py:414]   Expert 54 |     84 | CPU
DEBUG 01-06 17:11:19.746403.746403 lmp.py:414]   Expert  9 |     89 | CPU
DEBUG 01-06 17:11:19.746569.746569 lmp.py:414]   Expert 13 |     91 | CPU
DEBUG 01-06 17:11:19.746258.746258 lmp.py:414]   Expert 22 |    100 | CPU
DEBUG 01-06 17:11:19.746186.746186 lmp.py:414]   Expert 58 |    103 | CPU
DEBUG 01-06 17:11:19.746352.746352 lmp.py:414]   Expert  0 |    109 | CPU
DEBUG 01-06 17:11:19.746326.746326 lmp.py:414]   Expert 16 |    115 | CPU
DEBUG 01-06 17:11:19.746492.746492 lmp.py:414]   Expert 10 |    120 | CPU
DEBUG 01-06 17:11:19.746420.746420 lmp.py:414]   Expert 26 |    121 | CPU
DEBUG 01-06 17:11:19.746109.746109 lmp.py:414]   Expert 63 |    134 | CPU
DEBUG 01-06 17:11:19.746798.746798 lmp.py:414]   Expert 33 |    137 | CPU
DEBUG 01-06 17:11:19.746249.746249 lmp.py:414]   Expert 59 |    141 | CPU
DEBUG 01-06 17:11:19.746939.746939 lmp.py:414]   Expert 28 |    148 | CPU
DEBUG 01-06 17:11:19.746343.746343 lmp.py:414]   Expert 43 |    148 | CPU
DEBUG 01-06 17:11:19.746748.746748 lmp.py:414]   Expert 62 |    151 | CPU
DEBUG 01-06 17:11:19.746497.746497 lmp.py:414]   Expert 51 |    153 | CPU
DEBUG 01-06 17:11:19.746901.746901 lmp.py:414]   Expert 29 |    157 | CPU
DEBUG 01-06 17:11:19.746399.746399 lmp.py:414]   Expert 55 |    157 | CPU
DEBUG 01-06 17:11:19.746134.746134 lmp.py:414]   Expert  2 |    161 | CPU
DEBUG 01-06 17:11:19.746631.746631 lmp.py:414]   Expert  3 |    161 | CPU
DEBUG 01-06 17:11:19.746129.746129 lmp.py:414]   Expert 23 |    166 | CPU
DEBUG 01-06 17:11:19.746387.746387 lmp.py:414]   Expert 45 |    166 | CPU
DEBUG 01-06 17:11:19.746646.746646 lmp.py:414]   Expert 14 |    167 | CPU
DEBUG 01-06 17:11:19.746905.746905 lmp.py:414]   Expert 32 |    167 | CPU
DEBUG 01-06 17:11:19.746164.746164 lmp.py:414]   Expert 53 |    167 | CPU
DEBUG 01-06 17:11:19.747661.747661 lmp.py:414]   Expert 11 |    168 | CPU
DEBUG 01-06 17:11:19.747920.747920 lmp.py:414]   Expert 40 |    168 | CPU
DEBUG 01-06 17:11:19.747848.747848 lmp.py:414]   Expert 34 |    172 | GPU
DEBUG 01-06 17:11:19.747298.747298 lmp.py:414]   Expert 52 |    174 | GPU
DEBUG 01-06 17:11:19.747272.747272 lmp.py:414]   Expert 42 |    185 | GPU
DEBUG 01-06 17:11:19.747485.747485 lmp.py:414]   Expert 41 |    187 | GPU
DEBUG 01-06 17:11:19.747936.747936 lmp.py:414]   Expert 21 |    193 | GPU
DEBUG 01-06 17:11:19.747671.747671 lmp.py:414]   Expert 57 |    195 | GPU
DEBUG 01-06 17:11:19.747169.747169 lmp.py:414]   Expert 15 |    197 | GPU
DEBUG 01-06 17:11:19.747666.747666 lmp.py:414]   Expert 30 |    200 | GPU
DEBUG 01-06 17:11:19.747401.747401 lmp.py:414]   Expert 35 |    212 | GPU
DEBUG 01-06 17:11:19.747660.747660 lmp.py:414]   Expert 12 |    216 | GPU
DEBUG 01-06 17:11:19.747634.747634 lmp.py:414]   Expert  4 |    219 | GPU
DEBUG 01-06 17:11:19.747655.747655 lmp.py:414]   Expert 46 |    229 | GPU
DEBUG 01-06 17:11:19.747913.747913 lmp.py:414]   Expert 49 |    229 | GPU
DEBUG 01-06 17:11:19.747649.747649 lmp.py:414]   Expert 24 |    230 | GPU
DEBUG 01-06 17:11:19.747623.747623 lmp.py:414]   Expert 50 |    230 | GPU
DEBUG 01-06 17:11:19.747597.747597 lmp.py:414]   Expert  8 |    231 | GPU
DEBUG 01-06 17:11:19.747810.747810 lmp.py:414]   Expert 38 |    232 | GPU
DEBUG 01-06 17:11:19.747784.747784 lmp.py:414]   Expert 44 |    236 | GPU
DEBUG 01-06 17:11:19.747996.747996 lmp.py:414]   Expert 19 |    239 | GPU
DEBUG 01-06 17:11:19.747732.747732 lmp.py:414]   Expert  6 |    243 | GPU
DEBUG 01-06 17:11:19.747991.747991 lmp.py:414]   Expert 47 |    252 | GPU
DEBUG 01-06 17:11:19.747249.747249 lmp.py:414]   Expert 31 |    254 | GPU
DEBUG 01-06 17:11:19.747985.747985 lmp.py:414]   Expert 61 |    257 | GPU
DEBUG 01-06 17:11:19.747244.747244 lmp.py:414]   Expert 39 |    280 | GPU
DEBUG 01-06 17:11:19.747741.747741 lmp.py:414]   Expert  5 |    298 | GPU
DEBUG 01-06 17:11:19.747238.747238 lmp.py:414]   Expert 36 |    306 | GPU
DEBUG 01-06 17:11:19.747735.747735 lmp.py:414]   Expert 27 |    314 | GPU
DEBUG 01-06 17:11:19.747233.747233 lmp.py:414]   Expert 60 |    328 | GPU
DEBUG 01-06 17:11:19.747968.747968 lmp.py:414]   Expert 20 |    338 | GPU
DEBUG 01-06 17:11:19.747896.747896 lmp.py:414]   Expert 48 |    369 | GPU
DEBUG 01-06 17:11:19.747108.747108 lmp.py:414]   Expert 25 |    399 | GPU
DEBUG 01-06 17:11:19.747036.747036 lmp.py:414]   Expert 56 |    561 | GPU
DEBUG 01-06 17:11:19.747202.747202 lmp.py:415] 
DEBUG 01-06 17:11:19.747202.747202 lmp.py:415]   CPU total tokens: 4083 (33.2%)
DEBUG 01-06 17:11:19.747845.747845 lmp.py:416]   GPU total tokens: 8205 (66.8%)
DEBUG 01-06 17:11:19.747826.747826 cuda_h.py:19] end experts_map_get cost 0.001493692398071289 seconds
DEBUG 01-06 17:11:19.747754.747754 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-06 17:11:19.747722.747722 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 17:11:19.747767.747767 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 17:11:19.749184.749184 cuda_h.py:19] end allocate_cuda_memory cost 0.0017495155334472656 seconds
DEBUG 01-06 17:11:19.749756.749756 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 17:11:19.749035.749035 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 17:11:19.749367.749367 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 17:11:19.749255.749255 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 790f2940-c775-4acb-b034-0832fbde5b80
DEBUG 01-06 17:11:19.749719.749719 client.py:106] call stub.LoadModelAsync
INFO 01-06 17:11:19.751929.751929 client.py:127] Model loaded
DEBUG 01-06 17:11:19.752876.752876 cuda_h.py:19] end sllm_worker_task cost 0.010945558547973633 seconds
INFO 01-06 17:11:19.752235.752235 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 790f2940-c775-4acb-b034-0832fbde5b80
DEBUG 01-06 17:11:19.752184.752184 cuda_h.py:19] end load_into_gpu_async cost 0.0032672882080078125 seconds
DEBUG 01-06 17:11:19.752556.752556 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 17:11:19.753829.753829 cuda_h.py:19] end restore_tensors2 cost 0.00041866302490234375 seconds
DEBUG 01-06 17:11:19.753288.753288 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0058023929595947266 seconds
DEBUG 01-06 17:11:19.756283.756283 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.008475542068481445 seconds
DEBUG 01-06 17:11:19.756696.756696 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-06 17:11:19.756705.756705 lmp.py:461] 
DEBUG 01-06 17:11:19.756705.756705 lmp.py:461]   Computing 32 experts on CPU...
DEBUG 01-06 17:11:19.756740.756740 cuda_h.py:19] end cpu_experts_submit cost 0.00011038780212402344 seconds
DEBUG 01-06 17:11:19.756390.756390 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-06 17:11:19.769141.769141 mlpmodule.py:706] group tensors cost 0.013110876083374023 s
DEBUG 01-06 17:11:19.771113.771113 mlpmodule.py:744] pad cost 0.0016069412231445312 s
DEBUG 01-06 17:11:19.772594.772594 mlpmodule.py:750] create cpu tensor cost 4.6253204345703125e-05 s
DEBUG 01-06 17:11:19.772305.772305 mlpmodule.py:755] move to cpu cost 3.337860107421875e-05 s
DEBUG 01-06 17:11:19.782053.782053 mlpmodule.py:769] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-06 17:11:19.782837.782837 mlpmodule.py:770] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-06 17:11:19.782495.782495 mlpmodule.py:775] group_w3 first element: -0.003631591796875
WARNING 01-06 17:11:19.782055.782055 mlpmodule.py:785] start einsum2
DEBUG 01-06 17:11:19.800059.800059 mlpmodule.py:795] group einsum cost 0.0285797119140625 s
DEBUG 01-06 17:11:19.801550.801550 mlpmodule.py:803] cpy2cputensor cost 0.0006754398345947266 s
DEBUG 01-06 17:11:19.806836.806836 cuda_h.py:19] end wait_cetm_experts cost 0.04961514472961426 seconds
DEBUG 01-06 17:11:19.806239.806239 cuda_h.py:10] start gpu_sexperts
DEBUG 01-06 17:11:19.806559.806559 cuda_h.py:19] end gpu_sexperts cost 0.0006132125854492188 seconds
DEBUG 01-06 17:11:19.806548.806548 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-06 17:11:19.806252.806252 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.384185791015625e-05 seconds
DEBUG 01-06 17:11:19.807147.807147 cuda_h.py:10] start wait_experts
INFO 01-06 17:11:19.807857.807857 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 790f2940-c775-4acb-b034-0832fbde5b80
INFO 01-06 17:11:19.808134.808134 client.py:127] Model loaded
DEBUG 01-06 17:11:19.808792.808792 cuda_h.py:19] end wait_experts cost 0.0014271736145019531 seconds
DEBUG 01-06 17:11:19.808164.808164 cuda_h.py:10] start gpu_experts
DEBUG 01-06 17:11:19.808920.808920 lmp.py:506]   Computing 32 experts on GPU...
DEBUG 01-06 17:11:19.809654.809654 mlpmodule.py:533] gpu group tensors cost 0.0006654262542724609 s
DEBUG 01-06 17:11:19.811433.811433 mlpmodule.py:566] gpu pad cost 0.0018513202667236328 s
DEBUG 01-06 17:11:19.811909.811909 mlpmodule.py:584] gpu group einsum cost 0.0004601478576660156 s
DEBUG 01-06 17:11:19.815235.815235 mlpmodule.py:613] gpu experts func einsum cost 0.006744384765625 s
DEBUG 01-06 17:11:19.815043.815043 cuda_h.py:19] end gpu_experts cost 0.007043600082397461 seconds
DEBUG 01-06 17:11:19.815033.815033 cuda_h.py:19] end layer_moe_generate_6 cost 0.07036113739013672 seconds
DEBUG 01-06 17:11:19.815882.815882 lmp.py:220] -------------------------------- end layer 6 --------------------------------
DEBUG 01-06 17:11:19.815652.815652 lmp.py:176] -------------------------------- start layer 7 --------------------------------
DEBUG 01-06 17:11:19.815640.815640 cuda_h.py:10] start start_load_qkvogn_s_weight_l_8
DEBUG 01-06 17:11:19.816164.816164 cuda_h.py:10] start start_load_qkvogn_s_weight_l_8
DEBUG 01-06 17:11:19.816497.816497 cuda_h.py:19] end start_load_qkvogn_s_weight_l_8 cost 3.8623809814453125e-05 seconds
DEBUG 01-06 17:11:19.816684.816684 cuda_h.py:19] end start_load_qkvogn_s_weight_l_8 cost 7.534027099609375e-05 seconds
DEBUG 01-06 17:11:19.816572.816572 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-06 17:11:19.816303.816303 mlpmodule.py:367] cuda:1 cuda:1
DEBUG 01-06 17:11:19.816796.816796 cuda_h.py:10] start sllm_worker_task
DEBUG 01-06 17:11:19.816323.816323 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 17:11:19.816265.816265 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 17:11:19.816374.816374 cuda_h.py:19] end allocate_cuda_memory cost 0.00042891502380371094 seconds
DEBUG 01-06 17:11:19.817337.817337 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 17:11:19.817338.817338 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 17:11:19.817558.817558 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 17:11:19.817738.817738 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 44a57ddb-6d1e-4501-86fc-8d422a386932
DEBUG 01-06 17:11:19.817847.817847 client.py:106] call stub.LoadModelAsync
DEBUG 01-06 17:11:19.817740.817740 mlpmodule.py:664]  experts func einsum cost 0.0608830451965332 s
DEBUG 01-06 17:11:19.817974.817974 cuda_h.py:10] start self_attn
INFO 01-06 17:11:19.818661.818661 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 44a57ddb-6d1e-4501-86fc-8d422a386932
DEBUG 01-06 17:11:19.818557.818557 cuda_h.py:19] end load_into_gpu_async cost 0.001600027084350586 seconds
DEBUG 01-06 17:11:19.818022.818022 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 17:11:19.818250.818250 cuda_h.py:19] end restore_tensors2 cost 7.128715515136719e-05 seconds
DEBUG 01-06 17:11:19.818006.818006 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.00235748291015625 seconds
INFO 01-06 17:11:19.818286.818286 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 44a57ddb-6d1e-4501-86fc-8d422a386932
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-06 17:11:19.820109.820109 cuda_h.py:19] end self_attn cost 0.0029458999633789062 seconds
DEBUG 01-06 17:11:19.821405.821405 cuda_h.py:19] end iln_self_attn_paln cost 0.004865407943725586 seconds
DEBUG 01-06 17:11:19.821732.821732 cuda_h.py:10] start layer_moe_generate_7
DEBUG 01-06 17:11:19.821117.821117 cuda_h.py:10] start gate
DEBUG 01-06 17:11:19.821703.821703 cuda_h.py:19] end gate cost 0.0006434917449951172 seconds
DEBUG 01-06 17:11:19.821771.821771 cuda_h.py:10] start experts_map_get
DEBUG 01-06 17:11:19.822006.822006 lmp.py:403] 
DEBUG 01-06 17:11:19.822006.822006 lmp.py:403] Expert Token Distribution & Device Allocation:
DEBUG 01-06 17:11:19.822855.822855 lmp.py:404]   Total experts: 64
DEBUG 01-06 17:11:19.822743.822743 lmp.py:405]   CPU experts: 32 (50%)
DEBUG 01-06 17:11:19.822817.822817 lmp.py:406]   GPU experts: 32 (50%)
DEBUG 01-06 17:11:19.822652.822652 lmp.py:407] 
DEBUG 01-06 17:11:19.822652.822652 lmp.py:407]   Expert ID | Tokens | Device
DEBUG 01-06 17:11:19.822771.822771 lmp.py:408]   -----------------------------------
DEBUG 01-06 17:11:19.822329.822329 lmp.py:414]   Expert 50 |     48 | CPU
DEBUG 01-06 17:11:19.822687.822687 lmp.py:414]   Expert  3 |     54 | CPU
DEBUG 01-06 17:11:19.822330.822330 lmp.py:414]   Expert 46 |     58 | CPU
DEBUG 01-06 17:11:19.822019.822019 lmp.py:414]   Expert  1 |     78 | CPU
DEBUG 01-06 17:11:19.822424.822424 lmp.py:414]   Expert 29 |     82 | CPU
DEBUG 01-06 17:11:19.822351.822351 lmp.py:414]   Expert  4 |     88 | CPU
DEBUG 01-06 17:11:19.822041.822041 lmp.py:414]   Expert  8 |     94 | CPU
DEBUG 01-06 17:11:19.822207.822207 lmp.py:414]   Expert 15 |     95 | CPU
DEBUG 01-06 17:11:19.822419.822419 lmp.py:414]   Expert 40 |     97 | CPU
DEBUG 01-06 17:11:19.822347.822347 lmp.py:414]   Expert 41 |    112 | CPU
DEBUG 01-06 17:11:19.822036.822036 lmp.py:414]   Expert 28 |    117 | CPU
DEBUG 01-06 17:11:19.822726.822726 lmp.py:414]   Expert 48 |    126 | CPU
DEBUG 01-06 17:11:19.822415.822415 lmp.py:414]   Expert  6 |    129 | CPU
DEBUG 01-06 17:11:19.822104.822104 lmp.py:414]   Expert 54 |    132 | CPU
DEBUG 01-06 17:11:19.822747.822747 lmp.py:414]   Expert  7 |    133 | CPU
DEBUG 01-06 17:11:19.822913.822913 lmp.py:414]   Expert 60 |    134 | CPU
DEBUG 01-06 17:11:19.822318.822318 lmp.py:414]   Expert 16 |    135 | CPU
DEBUG 01-06 17:11:19.822484.822484 lmp.py:414]   Expert 27 |    136 | CPU
DEBUG 01-06 17:11:19.822412.822412 lmp.py:414]   Expert 51 |    136 | CPU
DEBUG 01-06 17:11:19.822339.822339 lmp.py:414]   Expert 13 |    138 | CPU
DEBUG 01-06 17:11:19.822029.822029 lmp.py:414]   Expert 39 |    138 | CPU
DEBUG 01-06 17:11:19.822956.822956 lmp.py:414]   Expert 55 |    141 | CPU
DEBUG 01-06 17:11:19.822646.822646 lmp.py:414]   Expert 20 |    143 | CPU
DEBUG 01-06 17:11:19.822858.822858 lmp.py:414]   Expert 18 |    144 | CPU
DEBUG 01-06 17:11:19.822548.822548 lmp.py:414]   Expert 56 |    144 | CPU
DEBUG 01-06 17:11:19.822237.822237 lmp.py:414]   Expert 14 |    145 | CPU
DEBUG 01-06 17:11:19.822926.822926 lmp.py:414]   Expert 52 |    146 | CPU
DEBUG 01-06 17:11:19.822569.822569 lmp.py:414]   Expert 36 |    152 | CPU
DEBUG 01-06 17:11:19.822497.822497 lmp.py:414]   Expert 43 |    152 | CPU
DEBUG 01-06 17:11:19.822663.822663 lmp.py:414]   Expert 10 |    156 | CPU
DEBUG 01-06 17:11:19.822829.822829 lmp.py:414]   Expert 45 |    158 | CPU
DEBUG 01-06 17:11:19.822995.822995 lmp.py:414]   Expert 11 |    159 | CPU
DEBUG 01-06 17:11:19.822161.822161 lmp.py:414]   Expert  5 |    162 | GPU
DEBUG 01-06 17:11:19.822612.822612 lmp.py:414]   Expert 62 |    167 | GPU
DEBUG 01-06 17:11:19.822302.822302 lmp.py:414]   Expert 44 |    171 | GPU
DEBUG 01-06 17:11:19.822752.822752 lmp.py:414]   Expert 33 |    174 | GPU
DEBUG 01-06 17:11:19.822203.822203 lmp.py:414]   Expert 57 |    178 | GPU
DEBUG 01-06 17:11:19.822416.822416 lmp.py:414]   Expert 58 |    180 | GPU
DEBUG 01-06 17:11:19.822867.822867 lmp.py:414]   Expert 25 |    181 | GPU
DEBUG 01-06 17:11:19.822794.822794 lmp.py:414]   Expert 53 |    182 | GPU
DEBUG 01-06 17:11:19.823245.823245 lmp.py:414]   Expert 32 |    187 | GPU
DEBUG 01-06 17:11:19.823411.823411 lmp.py:414]   Expert 31 |    193 | GPU
DEBUG 01-06 17:11:19.823816.823816 lmp.py:414]   Expert 63 |    195 | GPU
DEBUG 01-06 17:11:19.823505.823505 lmp.py:414]   Expert  2 |    196 | GPU
DEBUG 01-06 17:11:19.823433.823433 lmp.py:414]   Expert 49 |    202 | GPU
DEBUG 01-06 17:11:19.823838.823838 lmp.py:414]   Expert 21 |    206 | GPU
DEBUG 01-06 17:11:19.823765.823765 lmp.py:414]   Expert 34 |    212 | GPU
DEBUG 01-06 17:11:19.823216.823216 lmp.py:414]   Expert 42 |    212 | GPU
DEBUG 01-06 17:11:19.823667.823667 lmp.py:414]   Expert 17 |    214 | GPU
DEBUG 01-06 17:11:19.823879.823879 lmp.py:414]   Expert 35 |    218 | GPU
DEBUG 01-06 17:11:19.823569.823569 lmp.py:414]   Expert 37 |    227 | GPU
DEBUG 01-06 17:11:19.823781.823781 lmp.py:414]   Expert 59 |    230 | GPU
DEBUG 01-06 17:11:19.823232.823232 lmp.py:414]   Expert 22 |    239 | GPU
DEBUG 01-06 17:11:19.823114.823114 lmp.py:414]   Expert  0 |    241 | GPU
DEBUG 01-06 17:11:19.823280.823280 lmp.py:414]   Expert 19 |    255 | GPU
DEBUG 01-06 17:11:19.823969.823969 lmp.py:414]   Expert 24 |    286 | GPU
DEBUG 01-06 17:11:19.823135.823135 lmp.py:414]   Expert 61 |    286 | GPU
DEBUG 01-06 17:11:19.823540.823540 lmp.py:414]   Expert 30 |    296 | GPU
DEBUG 01-06 17:11:19.823467.823467 lmp.py:414]   Expert 47 |    328 | GPU
DEBUG 01-06 17:11:19.823918.823918 lmp.py:414]   Expert 38 |    367 | GPU
DEBUG 01-06 17:11:19.823608.823608 lmp.py:414]   Expert 26 |    372 | GPU
DEBUG 01-06 17:11:19.823297.823297 lmp.py:414]   Expert 12 |    439 | GPU
DEBUG 01-06 17:11:19.823748.823748 lmp.py:414]   Expert  9 |    663 | GPU
DEBUG 01-06 17:11:19.823437.823437 lmp.py:414]   Expert 23 |    729 | GPU
DEBUG 01-06 17:11:19.823842.823842 lmp.py:415] 
DEBUG 01-06 17:11:19.823842.823842 lmp.py:415]   CPU total tokens: 3900 (31.7%)
DEBUG 01-06 17:11:19.823961.823961 lmp.py:416]   GPU total tokens: 8388 (68.3%)
DEBUG 01-06 17:11:19.823611.823611 cuda_h.py:19] end experts_map_get cost 0.0015406608581542969 seconds
DEBUG 01-06 17:11:19.823969.823969 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-06 17:11:19.823845.823845 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 17:11:19.823420.823420 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 17:11:19.824252.824252 cuda_h.py:19] end allocate_cuda_memory cost 0.0012822151184082031 seconds
DEBUG 01-06 17:11:19.825731.825731 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 17:11:19.825156.825156 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 17:11:19.825919.825919 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 17:11:19.825284.825284 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, d00dd314-d2ae-41f3-b6a6-886d204f3d40
DEBUG 01-06 17:11:19.825701.825701 client.py:106] call stub.LoadModelAsync
INFO 01-06 17:11:19.826966.826966 client.py:127] Model loaded
DEBUG 01-06 17:11:19.827708.827708 cuda_h.py:19] end sllm_worker_task cost 0.010717391967773438 seconds
INFO 01-06 17:11:19.828577.828577 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, d00dd314-d2ae-41f3-b6a6-886d204f3d40
DEBUG 01-06 17:11:19.828100.828100 cuda_h.py:19] end load_into_gpu_async cost 0.003451108932495117 seconds
DEBUG 01-06 17:11:19.828877.828877 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 17:11:19.829996.829996 cuda_h.py:19] end restore_tensors2 cost 0.0005123615264892578 seconds
DEBUG 01-06 17:11:19.829362.829362 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.005730628967285156 seconds
DEBUG 01-06 17:11:19.831524.831524 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.008423089981079102 seconds
DEBUG 01-06 17:11:19.831645.831645 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-06 17:11:19.832939.832939 lmp.py:461] 
DEBUG 01-06 17:11:19.832939.832939 lmp.py:461]   Computing 32 experts on CPU...
DEBUG 01-06 17:11:19.832120.832120 cuda_h.py:19] end cpu_experts_submit cost 0.00011205673217773438 seconds
DEBUG 01-06 17:11:19.832769.832769 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-06 17:11:19.840444.840444 mlpmodule.py:706] group tensors cost 0.007651090621948242 s
DEBUG 01-06 17:11:19.842693.842693 mlpmodule.py:744] pad cost 0.001880645751953125 s
DEBUG 01-06 17:11:19.842810.842810 mlpmodule.py:750] create cpu tensor cost 5.078315734863281e-05 s
DEBUG 01-06 17:11:19.842104.842104 mlpmodule.py:755] move to cpu cost 3.552436828613281e-05 s
DEBUG 01-06 17:11:19.852581.852581 mlpmodule.py:769] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-06 17:11:19.852451.852451 mlpmodule.py:770] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-06 17:11:19.852990.852990 mlpmodule.py:775] group_w3 first element: 0.01263427734375
WARNING 01-06 17:11:19.852642.852642 mlpmodule.py:785] start einsum2
DEBUG 01-06 17:11:19.869217.869217 mlpmodule.py:795] group einsum cost 0.026842594146728516 s
DEBUG 01-06 17:11:19.870429.870429 mlpmodule.py:803] cpy2cputensor cost 0.0006389617919921875 s
DEBUG 01-06 17:11:19.874132.874132 cuda_h.py:19] end wait_cetm_experts cost 0.042777299880981445 seconds
DEBUG 01-06 17:11:19.875443.875443 cuda_h.py:10] start gpu_sexperts
DEBUG 01-06 17:11:19.875187.875187 cuda_h.py:19] end gpu_sexperts cost 0.0006105899810791016 seconds
DEBUG 01-06 17:11:19.875321.875321 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-06 17:11:19.875171.875171 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.4080276489257812e-05 seconds
DEBUG 01-06 17:11:19.875828.875828 cuda_h.py:10] start wait_experts
INFO 01-06 17:11:19.876060.876060 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, d00dd314-d2ae-41f3-b6a6-886d204f3d40
INFO 01-06 17:11:19.881423.881423 client.py:127] Model loaded
DEBUG 01-06 17:11:19.881227.881227 cuda_h.py:19] end wait_experts cost 0.005951881408691406 seconds
DEBUG 01-06 17:11:19.882314.882314 cuda_h.py:10] start gpu_experts
DEBUG 01-06 17:11:19.882931.882931 lmp.py:506]   Computing 32 experts on GPU...
DEBUG 01-06 17:11:19.882248.882248 mlpmodule.py:533] gpu group tensors cost 0.0006701946258544922 s
DEBUG 01-06 17:11:19.884014.884014 mlpmodule.py:566] gpu pad cost 0.0018739700317382812 s
DEBUG 01-06 17:11:19.885686.885686 mlpmodule.py:584] gpu group einsum cost 0.0005536079406738281 s
DEBUG 01-06 17:11:19.885405.885405 mlpmodule.py:664]  experts func einsum cost 0.05361342430114746 s
DEBUG 01-06 17:11:19.888546.888546 mlpmodule.py:613] gpu experts func einsum cost 0.006605625152587891 s
DEBUG 01-06 17:11:19.888984.888984 cuda_h.py:19] end gpu_experts cost 0.006924629211425781 seconds
DEBUG 01-06 17:11:19.889059.889059 cuda_h.py:19] end layer_moe_generate_7 cost 0.06790542602539062 seconds
DEBUG 01-06 17:11:19.889854.889854 lmp.py:220] -------------------------------- end layer 7 --------------------------------
DEBUG 01-06 17:11:19.889293.889293 lmp.py:176] -------------------------------- start layer 8 --------------------------------
DEBUG 01-06 17:11:19.889750.889750 cuda_h.py:10] start start_load_qkvogn_s_weight_l_9
DEBUG 01-06 17:11:19.889268.889268 cuda_h.py:10] start start_load_qkvogn_s_weight_l_9
DEBUG 01-06 17:11:19.889396.889396 cuda_h.py:19] end start_load_qkvogn_s_weight_l_9 cost 3.24249267578125e-05 seconds
DEBUG 01-06 17:11:19.889099.889099 cuda_h.py:19] end start_load_qkvogn_s_weight_l_9 cost 6.461143493652344e-05 seconds
DEBUG 01-06 17:11:19.889364.889364 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-06 17:11:19.889267.889267 mlpmodule.py:367] cuda:1 cuda:1
DEBUG 01-06 17:11:19.889945.889945 cuda_h.py:10] start sllm_worker_task
DEBUG 01-06 17:11:19.889306.889306 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 17:11:19.889334.889334 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 17:11:19.890691.890691 cuda_h.py:19] end allocate_cuda_memory cost 0.0003311634063720703 seconds
DEBUG 01-06 17:11:19.890925.890925 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 17:11:19.890019.890019 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 17:11:19.890934.890934 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 17:11:19.890491.890491 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, aa2bc943-88e0-4ad7-bb48-68d1a9105e19
DEBUG 01-06 17:11:19.890315.890315 client.py:106] call stub.LoadModelAsync
DEBUG 01-06 17:11:19.890980.890980 cuda_h.py:10] start self_attn
INFO 01-06 17:11:19.891924.891924 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, aa2bc943-88e0-4ad7-bb48-68d1a9105e19
DEBUG 01-06 17:11:19.891475.891475 cuda_h.py:19] end load_into_gpu_async cost 0.0015659332275390625 seconds
DEBUG 01-06 17:11:19.891032.891032 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 17:11:19.891069.891069 cuda_h.py:19] end restore_tensors2 cost 7.033348083496094e-05 seconds
DEBUG 01-06 17:11:19.891871.891871 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0022079944610595703 seconds
INFO 01-06 17:11:19.891893.891893 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, aa2bc943-88e0-4ad7-bb48-68d1a9105e19
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-06 17:11:19.893364.893364 cuda_h.py:19] end self_attn cost 0.0028891563415527344 seconds
DEBUG 01-06 17:11:19.893567.893567 cuda_h.py:19] end iln_self_attn_paln cost 0.004439592361450195 seconds
DEBUG 01-06 17:11:19.893787.893787 cuda_h.py:10] start layer_moe_generate_8
DEBUG 01-06 17:11:19.894789.894789 cuda_h.py:10] start gate
DEBUG 01-06 17:11:19.894328.894328 cuda_h.py:19] end gate cost 0.0006451606750488281 seconds
DEBUG 01-06 17:11:19.894442.894442 cuda_h.py:10] start experts_map_get
DEBUG 01-06 17:11:19.895724.895724 lmp.py:403] 
DEBUG 01-06 17:11:19.895724.895724 lmp.py:403] Expert Token Distribution & Device Allocation:
DEBUG 01-06 17:11:19.895765.895765 lmp.py:404]   Total experts: 64
DEBUG 01-06 17:11:19.895461.895461 lmp.py:405]   CPU experts: 32 (50%)
DEBUG 01-06 17:11:19.895819.895819 lmp.py:406]   GPU experts: 32 (50%)
DEBUG 01-06 17:11:19.895270.895270 lmp.py:407] 
DEBUG 01-06 17:11:19.895270.895270 lmp.py:407]   Expert ID | Tokens | Device
DEBUG 01-06 17:11:19.895721.895721 lmp.py:408]   -----------------------------------
DEBUG 01-06 17:11:19.895371.895371 lmp.py:414]   Expert 38 |     11 | CPU
DEBUG 01-06 17:11:19.895298.895298 lmp.py:414]   Expert 39 |     66 | CPU
DEBUG 01-06 17:11:19.895511.895511 lmp.py:414]   Expert  7 |     69 | CPU
DEBUG 01-06 17:11:19.895962.895962 lmp.py:414]   Expert 30 |     79 | CPU
DEBUG 01-06 17:11:19.895413.895413 lmp.py:414]   Expert 24 |     85 | CPU
DEBUG 01-06 17:11:19.895340.895340 lmp.py:414]   Expert 27 |     92 | CPU
DEBUG 01-06 17:11:19.895030.895030 lmp.py:414]   Expert 32 |     93 | CPU
DEBUG 01-06 17:11:19.895865.895865 lmp.py:414]   Expert 14 |     95 | CPU
DEBUG 01-06 17:11:19.895508.895508 lmp.py:414]   Expert 36 |     96 | CPU
DEBUG 01-06 17:11:19.895674.895674 lmp.py:414]   Expert 16 |     99 | CPU
DEBUG 01-06 17:11:19.895363.895363 lmp.py:414]   Expert 40 |     99 | CPU
DEBUG 01-06 17:11:19.895052.895052 lmp.py:414]   Expert 17 |    101 | CPU
DEBUG 01-06 17:11:19.895219.895219 lmp.py:414]   Expert 48 |    112 | CPU
DEBUG 01-06 17:11:19.895669.895669 lmp.py:414]   Expert 12 |    113 | CPU
DEBUG 01-06 17:11:19.895359.895359 lmp.py:414]   Expert 18 |    116 | CPU
DEBUG 01-06 17:11:19.895286.895286 lmp.py:414]   Expert  1 |    121 | CPU
DEBUG 01-06 17:11:19.895976.895976 lmp.py:414]   Expert  6 |    123 | CPU
DEBUG 01-06 17:11:19.895665.895665 lmp.py:414]   Expert 42 |    134 | CPU
DEBUG 01-06 17:11:19.895354.895354 lmp.py:414]   Expert 53 |    138 | CPU
DEBUG 01-06 17:11:19.895759.895759 lmp.py:414]   Expert 59 |    142 | CPU
DEBUG 01-06 17:11:19.895879.895879 lmp.py:414]   Expert 22 |    143 | CPU
DEBUG 01-06 17:11:19.895283.895283 lmp.py:414]   Expert 51 |    145 | CPU
DEBUG 01-06 17:11:19.895211.895211 lmp.py:414]   Expert  0 |    149 | CPU
DEBUG 01-06 17:11:19.895900.895900 lmp.py:414]   Expert 60 |    152 | CPU
DEBUG 01-06 17:11:19.895590.895590 lmp.py:414]   Expert  8 |    159 | CPU
DEBUG 01-06 17:11:19.895040.895040 lmp.py:414]   Expert 15 |    163 | CPU
DEBUG 01-06 17:11:19.895730.895730 lmp.py:414]   Expert 29 |    169 | CPU
DEBUG 01-06 17:11:19.895942.895942 lmp.py:414]   Expert 44 |    169 | CPU
DEBUG 01-06 17:11:19.895632.895632 lmp.py:414]   Expert 54 |    170 | CPU
DEBUG 01-06 17:11:19.895082.895082 lmp.py:414]   Expert 33 |    178 | CPU
DEBUG 01-06 17:11:19.895302.895302 lmp.py:414]   Expert 34 |    180 | CPU
DEBUG 01-06 17:11:19.895753.895753 lmp.py:414]   Expert 35 |    181 | CPU
DEBUG 01-06 17:11:19.895680.895680 lmp.py:414]   Expert 19 |    186 | GPU
DEBUG 01-06 17:11:19.895131.895131 lmp.py:414]   Expert 47 |    188 | GPU
DEBUG 01-06 17:11:19.895059.895059 lmp.py:414]   Expert 56 |    196 | GPU
DEBUG 01-06 17:11:19.895271.895271 lmp.py:414]   Expert  3 |    197 | GPU
DEBUG 01-06 17:11:19.895245.895245 lmp.py:414]   Expert  9 |    197 | GPU
DEBUG 01-06 17:11:19.895743.895743 lmp.py:414]   Expert 45 |    199 | GPU
DEBUG 01-06 17:11:19.895717.895717 lmp.py:414]   Expert 20 |    200 | GPU
DEBUG 01-06 17:11:19.895214.895214 lmp.py:414]   Expert 21 |    201 | GPU
DEBUG 01-06 17:11:19.895188.895188 lmp.py:414]   Expert 46 |    201 | GPU
DEBUG 01-06 17:11:19.895685.895685 lmp.py:414]   Expert 49 |    204 | GPU
DEBUG 01-06 17:11:19.895659.895659 lmp.py:414]   Expert 28 |    210 | GPU
DEBUG 01-06 17:11:19.895156.895156 lmp.py:414]   Expert  4 |    221 | GPU
DEBUG 01-06 17:11:19.895084.895084 lmp.py:414]   Expert 57 |    221 | GPU
DEBUG 01-06 17:11:19.895773.895773 lmp.py:414]   Expert  2 |    226 | GPU
DEBUG 01-06 17:11:19.895224.895224 lmp.py:414]   Expert 13 |    231 | GPU
DEBUG 01-06 17:11:19.895437.895437 lmp.py:414]   Expert 43 |    233 | GPU
DEBUG 01-06 17:11:19.895888.895888 lmp.py:414]   Expert 50 |    241 | GPU
DEBUG 01-06 17:11:19.896862.896862 lmp.py:414]   Expert 26 |    247 | GPU
DEBUG 01-06 17:11:19.896359.896359 lmp.py:414]   Expert 41 |    248 | GPU
DEBUG 01-06 17:11:19.896094.896094 lmp.py:414]   Expert 10 |    250 | GPU
DEBUG 01-06 17:11:19.896830.896830 lmp.py:414]   Expert 37 |    260 | GPU
DEBUG 01-06 17:11:19.896804.896804 lmp.py:414]   Expert 63 |    260 | GPU
DEBUG 01-06 17:11:19.896301.896301 lmp.py:414]   Expert 61 |    270 | GPU
DEBUG 01-06 17:11:19.896275.896275 lmp.py:414]   Expert 31 |    273 | GPU
DEBUG 01-06 17:11:19.896773.896773 lmp.py:414]   Expert 52 |    297 | GPU
DEBUG 01-06 17:11:19.896700.896700 lmp.py:414]   Expert 58 |    330 | GPU
DEBUG 01-06 17:11:19.896151.896151 lmp.py:414]   Expert 62 |    331 | GPU
DEBUG 01-06 17:11:19.896079.896079 lmp.py:414]   Expert 55 |    337 | GPU
DEBUG 01-06 17:11:19.896768.896768 lmp.py:414]   Expert 11 |    379 | GPU
DEBUG 01-06 17:11:19.896219.896219 lmp.py:414]   Expert 23 |    391 | GPU
DEBUG 01-06 17:11:19.896193.896193 lmp.py:414]   Expert 25 |    405 | GPU
DEBUG 01-06 17:11:19.896690.896690 lmp.py:414]   Expert  5 |    516 | GPU
DEBUG 01-06 17:11:19.896141.896141 lmp.py:415] 
DEBUG 01-06 17:11:19.896141.896141 lmp.py:415]   CPU total tokens: 3942 (32.1%)
DEBUG 01-06 17:11:19.896831.896831 lmp.py:416]   GPU total tokens: 8346 (67.9%)
DEBUG 01-06 17:11:19.896335.896335 cuda_h.py:19] end experts_map_get cost 0.001508951187133789 seconds
DEBUG 01-06 17:11:19.896501.896501 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-06 17:11:19.896277.896277 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 17:11:19.896474.896474 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 17:11:19.898945.898945 cuda_h.py:19] end allocate_cuda_memory cost 0.00157928466796875 seconds
DEBUG 01-06 17:11:19.898047.898047 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 17:11:19.898565.898565 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 17:11:19.898566.898566 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 17:11:19.898646.898646 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 8f132cda-8bce-4854-9d0a-8b9feeadee08
DEBUG 01-06 17:11:19.898341.898341 client.py:106] call stub.LoadModelAsync
INFO 01-06 17:11:19.899249.899249 client.py:127] Model loaded
DEBUG 01-06 17:11:19.900397.900397 cuda_h.py:19] end sllm_worker_task cost 0.010639190673828125 seconds
INFO 01-06 17:11:19.901981.901981 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 8f132cda-8bce-4854-9d0a-8b9feeadee08
DEBUG 01-06 17:11:19.901138.901138 cuda_h.py:19] end load_into_gpu_async cost 0.003459930419921875 seconds
DEBUG 01-06 17:11:19.901823.901823 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 17:11:19.902525.902525 cuda_h.py:19] end restore_tensors2 cost 0.0005218982696533203 seconds
DEBUG 01-06 17:11:19.902176.902176 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.006047964096069336 seconds
DEBUG 01-06 17:11:19.905682.905682 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.008744955062866211 seconds
DEBUG 01-06 17:11:19.905333.905333 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-06 17:11:19.905534.905534 lmp.py:461] 
DEBUG 01-06 17:11:19.905534.905534 lmp.py:461]   Computing 32 experts on CPU...
DEBUG 01-06 17:11:19.905477.905477 cuda_h.py:19] end cpu_experts_submit cost 0.00011324882507324219 seconds
DEBUG 01-06 17:11:19.905656.905656 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-06 17:11:19.916240.916240 mlpmodule.py:706] group tensors cost 0.011269569396972656 s
DEBUG 01-06 17:11:19.919827.919827 mlpmodule.py:744] pad cost 0.0021109580993652344 s
DEBUG 01-06 17:11:19.919288.919288 mlpmodule.py:750] create cpu tensor cost 5.507469177246094e-05 s
DEBUG 01-06 17:11:19.919403.919403 mlpmodule.py:755] move to cpu cost 3.886222839355469e-05 s
DEBUG 01-06 17:11:19.930710.930710 mlpmodule.py:769] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-06 17:11:19.930825.930825 mlpmodule.py:770] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-06 17:11:19.930112.930112 mlpmodule.py:775] group_w3 first element: 0.0859375
WARNING 01-06 17:11:19.930030.930030 mlpmodule.py:785] start einsum2
DEBUG 01-06 17:11:19.949329.949329 mlpmodule.py:795] group einsum cost 0.029750585556030273 s
DEBUG 01-06 17:11:19.950028.950028 mlpmodule.py:803] cpy2cputensor cost 0.0007526874542236328 s
DEBUG 01-06 17:11:19.955979.955979 cuda_h.py:19] end wait_cetm_experts cost 0.0496973991394043 seconds
DEBUG 01-06 17:11:19.955197.955197 cuda_h.py:10] start gpu_sexperts
DEBUG 01-06 17:11:19.955901.955901 cuda_h.py:19] end gpu_sexperts cost 0.000614166259765625 seconds
DEBUG 01-06 17:11:19.955943.955943 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-06 17:11:19.956985.956985 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.574920654296875e-05 seconds
DEBUG 01-06 17:11:19.956119.956119 cuda_h.py:10] start wait_experts
INFO 01-06 17:11:19.956067.956067 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 8f132cda-8bce-4854-9d0a-8b9feeadee08
INFO 01-06 17:11:19.957250.957250 client.py:127] Model loaded
DEBUG 01-06 17:11:19.957193.957193 cuda_h.py:19] end wait_experts cost 0.001392364501953125 seconds
DEBUG 01-06 17:11:19.957280.957280 cuda_h.py:10] start gpu_experts
DEBUG 01-06 17:11:19.957321.957321 lmp.py:506]   Computing 32 experts on GPU...
DEBUG 01-06 17:11:19.958332.958332 mlpmodule.py:533] gpu group tensors cost 0.0006606578826904297 s
DEBUG 01-06 17:11:19.960196.960196 mlpmodule.py:566] gpu pad cost 0.0018095970153808594 s
DEBUG 01-06 17:11:19.960030.960030 mlpmodule.py:584] gpu group einsum cost 0.0004892349243164062 s
DEBUG 01-06 17:11:19.964570.964570 mlpmodule.py:613] gpu experts func einsum cost 0.006764650344848633 s
DEBUG 01-06 17:11:19.964922.964922 cuda_h.py:19] end gpu_experts cost 0.007079601287841797 seconds
DEBUG 01-06 17:11:19.964250.964250 cuda_h.py:19] end layer_moe_generate_8 cost 0.07074451446533203 seconds
DEBUG 01-06 17:11:19.965881.965881 lmp.py:220] -------------------------------- end layer 8 --------------------------------
DEBUG 01-06 17:11:19.965743.965743 lmp.py:176] -------------------------------- start layer 9 --------------------------------
DEBUG 01-06 17:11:19.965016.965016 cuda_h.py:10] start start_load_qkvogn_s_weight_l_10
DEBUG 01-06 17:11:19.965878.965878 cuda_h.py:10] start start_load_qkvogn_s_weight_l_10
DEBUG 01-06 17:11:19.965635.965635 cuda_h.py:19] end start_load_qkvogn_s_weight_l_10 cost 3.552436828613281e-05 seconds
DEBUG 01-06 17:11:19.965345.965345 cuda_h.py:19] end start_load_qkvogn_s_weight_l_10 cost 7.033348083496094e-05 seconds
DEBUG 01-06 17:11:19.965571.965571 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-06 17:11:19.965851.965851 cuda_h.py:10] start sllm_worker_task
DEBUG 01-06 17:11:19.965021.965021 mlpmodule.py:367] cuda:1 cuda:1
DEBUG 01-06 17:11:19.965936.965936 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 17:11:19.965629.965629 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 17:11:19.965250.965250 cuda_h.py:19] end allocate_cuda_memory cost 0.00031256675720214844 seconds
DEBUG 01-06 17:11:19.966062.966062 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 17:11:19.966639.966639 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 17:11:19.966667.966667 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 17:11:19.966463.966463 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 51343227-0e04-4c69-9d95-5a88e75dde7c
DEBUG 01-06 17:11:19.966618.966618 client.py:106] call stub.LoadModelAsync
DEBUG 01-06 17:11:19.966245.966245 mlpmodule.py:664]  experts func einsum cost 0.060915231704711914 s
DEBUG 01-06 17:11:19.966493.966493 cuda_h.py:10] start self_attn
INFO 01-06 17:11:19.967624.967624 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 51343227-0e04-4c69-9d95-5a88e75dde7c
DEBUG 01-06 17:11:19.967044.967044 cuda_h.py:19] end load_into_gpu_async cost 0.0015959739685058594 seconds
DEBUG 01-06 17:11:19.967700.967700 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 17:11:19.967028.967028 cuda_h.py:19] end restore_tensors2 cost 7.390975952148438e-05 seconds
DEBUG 01-06 17:11:19.967546.967546 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.002287149429321289 seconds
INFO 01-06 17:11:19.967064.967064 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 51343227-0e04-4c69-9d95-5a88e75dde7c
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-06 17:11:19.969859.969859 cuda_h.py:19] end self_attn cost 0.002903461456298828 seconds
DEBUG 01-06 17:11:19.970949.970949 cuda_h.py:19] end iln_self_attn_paln cost 0.0047414302825927734 seconds
DEBUG 01-06 17:11:19.970169.970169 cuda_h.py:10] start layer_moe_generate_9
DEBUG 01-06 17:11:19.970622.970622 cuda_h.py:10] start gate
DEBUG 01-06 17:11:19.970545.970545 cuda_h.py:19] end gate cost 0.0006470680236816406 seconds
DEBUG 01-06 17:11:19.970090.970090 cuda_h.py:10] start experts_map_get
DEBUG 01-06 17:11:19.971518.971518 lmp.py:403] 
DEBUG 01-06 17:11:19.971518.971518 lmp.py:403] Expert Token Distribution & Device Allocation:
DEBUG 01-06 17:11:19.971797.971797 lmp.py:404]   Total experts: 64
DEBUG 01-06 17:11:19.971446.971446 lmp.py:405]   CPU experts: 32 (50%)
DEBUG 01-06 17:11:19.971950.971950 lmp.py:406]   GPU experts: 32 (50%)
DEBUG 01-06 17:11:19.971832.971832 lmp.py:407] 
DEBUG 01-06 17:11:19.971832.971832 lmp.py:407]   Expert ID | Tokens | Device
DEBUG 01-06 17:11:19.971429.971429 lmp.py:408]   -----------------------------------
DEBUG 01-06 17:11:19.971747.971747 lmp.py:414]   Expert 24 |     39 | CPU
DEBUG 01-06 17:11:19.971390.971390 lmp.py:414]   Expert  2 |     45 | CPU
DEBUG 01-06 17:11:19.971556.971556 lmp.py:414]   Expert 19 |     63 | CPU
DEBUG 01-06 17:11:19.971484.971484 lmp.py:414]   Expert 32 |     66 | CPU
DEBUG 01-06 17:11:19.971173.971173 lmp.py:414]   Expert 26 |     67 | CPU
DEBUG 01-06 17:11:19.971101.971101 lmp.py:414]   Expert 50 |     73 | CPU
DEBUG 01-06 17:11:19.971982.971982 lmp.py:414]   Expert 15 |     78 | CPU
DEBUG 01-06 17:11:19.971387.971387 lmp.py:414]   Expert  4 |     80 | CPU
DEBUG 01-06 17:11:19.971553.971553 lmp.py:414]   Expert 28 |     81 | CPU
DEBUG 01-06 17:11:19.971958.971958 lmp.py:414]   Expert  7 |     82 | CPU
DEBUG 01-06 17:11:19.971362.971362 lmp.py:414]   Expert 60 |     91 | CPU
DEBUG 01-06 17:11:19.971290.971290 lmp.py:414]   Expert 59 |     93 | CPU
DEBUG 01-06 17:11:19.971979.971979 lmp.py:414]   Expert  5 |     98 | CPU
DEBUG 01-06 17:11:19.971669.971669 lmp.py:414]   Expert 49 |     98 | CPU
DEBUG 01-06 17:11:19.971358.971358 lmp.py:414]   Expert 23 |    101 | CPU
DEBUG 01-06 17:11:19.971809.971809 lmp.py:414]   Expert 12 |    104 | CPU
DEBUG 01-06 17:11:19.971260.971260 lmp.py:414]   Expert 41 |    110 | CPU
DEBUG 01-06 17:11:19.971949.971949 lmp.py:414]   Expert 10 |    112 | CPU
DEBUG 01-06 17:11:19.971069.971069 lmp.py:414]   Expert 16 |    113 | CPU
DEBUG 01-06 17:11:19.971473.971473 lmp.py:414]   Expert 27 |    115 | CPU
DEBUG 01-06 17:11:19.971878.971878 lmp.py:414]   Expert 13 |    123 | CPU
DEBUG 01-06 17:11:19.971282.971282 lmp.py:414]   Expert  3 |    124 | CPU
DEBUG 01-06 17:11:19.971402.971402 lmp.py:414]   Expert 25 |    124 | CPU
DEBUG 01-06 17:11:19.971330.971330 lmp.py:414]   Expert 20 |    125 | CPU
DEBUG 01-06 17:11:19.971258.971258 lmp.py:414]   Expert 40 |    125 | CPU
DEBUG 01-06 17:11:19.971185.971185 lmp.py:414]   Expert 37 |    143 | CPU
DEBUG 01-06 17:11:19.971590.971590 lmp.py:414]   Expert 17 |    144 | CPU
DEBUG 01-06 17:11:19.971041.971041 lmp.py:414]   Expert 35 |    146 | CPU
DEBUG 01-06 17:11:19.971730.971730 lmp.py:414]   Expert 47 |    150 | CPU
DEBUG 01-06 17:11:19.971181.971181 lmp.py:414]   Expert 22 |    156 | CPU
DEBUG 01-06 17:11:19.971586.971586 lmp.py:414]   Expert 38 |    168 | CPU
DEBUG 01-06 17:11:19.971752.971752 lmp.py:414]   Expert 53 |    173 | CPU
DEBUG 01-06 17:11:19.971918.971918 lmp.py:414]   Expert 36 |    175 | GPU
DEBUG 01-06 17:11:19.971322.971322 lmp.py:414]   Expert 39 |    175 | GPU
DEBUG 01-06 17:11:19.971965.971965 lmp.py:414]   Expert 44 |    179 | GPU
DEBUG 01-06 17:11:19.971655.971655 lmp.py:414]   Expert 58 |    182 | GPU
DEBUG 01-06 17:11:19.971106.971106 lmp.py:414]   Expert 18 |    193 | GPU
DEBUG 01-06 17:11:19.971556.971556 lmp.py:414]   Expert 62 |    194 | GPU
DEBUG 01-06 17:11:19.971769.971769 lmp.py:414]   Expert 52 |    196 | GPU
DEBUG 01-06 17:11:19.971220.971220 lmp.py:414]   Expert 11 |    197 | GPU
DEBUG 01-06 17:11:19.971909.971909 lmp.py:414]   Expert 48 |    210 | GPU
DEBUG 01-06 17:11:19.972598.972598 lmp.py:414]   Expert 14 |    218 | GPU
DEBUG 01-06 17:11:19.972049.972049 lmp.py:414]   Expert 30 |    225 | GPU
DEBUG 01-06 17:11:19.972454.972454 lmp.py:414]   Expert  6 |    229 | GPU
DEBUG 01-06 17:11:19.972382.972382 lmp.py:414]   Expert 45 |    231 | GPU
DEBUG 01-06 17:11:19.972786.972786 lmp.py:414]   Expert 42 |    232 | GPU
DEBUG 01-06 17:11:19.972714.972714 lmp.py:414]   Expert 51 |    234 | GPU
DEBUG 01-06 17:11:19.972642.972642 lmp.py:414]   Expert  1 |    235 | GPU
DEBUG 01-06 17:11:19.972092.972092 lmp.py:414]   Expert 31 |    235 | GPU
DEBUG 01-06 17:11:19.972305.972305 lmp.py:414]   Expert 34 |    273 | GPU
DEBUG 01-06 17:11:19.972756.972756 lmp.py:414]   Expert 29 |    275 | GPU
DEBUG 01-06 17:11:19.972207.972207 lmp.py:414]   Expert 33 |    279 | GPU
DEBUG 01-06 17:11:19.972658.972658 lmp.py:414]   Expert 57 |    293 | GPU
DEBUG 01-06 17:11:19.972870.972870 lmp.py:414]   Expert 61 |    309 | GPU
DEBUG 01-06 17:11:19.972082.972082 lmp.py:414]   Expert 43 |    321 | GPU
DEBUG 01-06 17:11:19.972772.972772 lmp.py:414]   Expert  0 |    323 | GPU
DEBUG 01-06 17:11:19.972699.972699 lmp.py:414]   Expert 46 |    363 | GPU
DEBUG 01-06 17:11:19.972627.972627 lmp.py:414]   Expert  8 |    369 | GPU
DEBUG 01-06 17:11:19.972317.972317 lmp.py:414]   Expert  9 |    384 | GPU
DEBUG 01-06 17:11:19.972483.972483 lmp.py:414]   Expert 54 |    398 | GPU
DEBUG 01-06 17:11:19.972934.972934 lmp.py:414]   Expert 56 |    415 | GPU
DEBUG 01-06 17:11:19.972384.972384 lmp.py:414]   Expert 63 |    418 | GPU
DEBUG 01-06 17:11:19.972835.972835 lmp.py:414]   Expert 55 |    430 | GPU
DEBUG 01-06 17:11:19.972048.972048 lmp.py:414]   Expert 21 |    488 | GPU
DEBUG 01-06 17:11:19.972082.972082 lmp.py:415] 
DEBUG 01-06 17:11:19.972082.972082 lmp.py:415]   CPU total tokens: 3410 (27.8%)
DEBUG 01-06 17:11:19.972440.972440 lmp.py:416]   GPU total tokens: 8878 (72.2%)
DEBUG 01-06 17:11:19.972567.972567 cuda_h.py:19] end experts_map_get cost 0.0015521049499511719 seconds
DEBUG 01-06 17:11:19.972163.972163 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-06 17:11:19.972324.972324 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 17:11:19.972805.972805 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 17:11:19.973313.973313 cuda_h.py:19] end allocate_cuda_memory cost 0.00128936767578125 seconds
DEBUG 01-06 17:11:19.974461.974461 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 17:11:19.974933.974933 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 17:11:19.974457.974457 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 17:11:19.974392.974392 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 0e4466b8-2c93-4150-88fa-9d331e37b042
DEBUG 01-06 17:11:19.974418.974418 client.py:106] call stub.LoadModelAsync
INFO 01-06 17:11:19.975701.975701 client.py:127] Model loaded
DEBUG 01-06 17:11:19.976701.976701 cuda_h.py:19] end sllm_worker_task cost 0.010577917098999023 seconds
INFO 01-06 17:11:19.977905.977905 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 0e4466b8-2c93-4150-88fa-9d331e37b042
DEBUG 01-06 17:11:19.977941.977941 cuda_h.py:19] end load_into_gpu_async cost 0.0031995773315429688 seconds
DEBUG 01-06 17:11:19.977928.977928 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 17:11:19.977685.977685 cuda_h.py:19] end restore_tensors2 cost 0.00042557716369628906 seconds
DEBUG 01-06 17:11:19.977429.977429 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.005285739898681641 seconds
DEBUG 01-06 17:11:19.980990.980990 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.008059501647949219 seconds
DEBUG 01-06 17:11:19.980933.980933 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-06 17:11:19.980849.980849 lmp.py:461] 
DEBUG 01-06 17:11:19.980849.980849 lmp.py:461]   Computing 32 experts on CPU...
DEBUG 01-06 17:11:19.980699.980699 cuda_h.py:19] end cpu_experts_submit cost 0.00011563301086425781 seconds
DEBUG 01-06 17:11:19.980641.980641 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-06 17:11:19.987102.987102 mlpmodule.py:706] group tensors cost 0.006455898284912109 s
DEBUG 01-06 17:11:19.990211.990211 mlpmodule.py:744] pad cost 0.002073049545288086 s
DEBUG 01-06 17:11:19.990242.990242 mlpmodule.py:750] create cpu tensor cost 5.626678466796875e-05 s
DEBUG 01-06 17:11:19.990410.990410 mlpmodule.py:755] move to cpu cost 3.7670135498046875e-05 s
DEBUG 01-06 17:11:19.999751.999751 mlpmodule.py:769] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-06 17:11:19.999516.999516 mlpmodule.py:770] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-06 17:11:20.000280.000280 mlpmodule.py:775] group_w3 first element: 0.0157470703125
WARNING 01-06 17:11:20.000747.000747 mlpmodule.py:785] start einsum2
DEBUG 01-06 17:11:20.016763.016763 mlpmodule.py:795] group einsum cost 0.02609109878540039 s
DEBUG 01-06 17:11:20.017284.017284 mlpmodule.py:803] cpy2cputensor cost 0.0007169246673583984 s
DEBUG 01-06 17:11:20.022248.022248 cuda_h.py:19] end wait_cetm_experts cost 0.0411984920501709 seconds
DEBUG 01-06 17:11:20.022744.022744 cuda_h.py:10] start gpu_sexperts
DEBUG 01-06 17:11:20.022812.022812 cuda_h.py:19] end gpu_sexperts cost 0.0006022453308105469 seconds
DEBUG 01-06 17:11:20.022470.022470 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-06 17:11:20.023996.023996 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.9325485229492188e-05 seconds
DEBUG 01-06 17:11:20.023321.023321 cuda_h.py:10] start wait_experts
INFO 01-06 17:11:20.023839.023839 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 0e4466b8-2c93-4150-88fa-9d331e37b042
INFO 01-06 17:11:20.026824.026824 client.py:127] Model loaded
DEBUG 01-06 17:11:20.026912.026912 cuda_h.py:19] end wait_experts cost 0.003565549850463867 seconds
DEBUG 01-06 17:11:20.026237.026237 cuda_h.py:10] start gpu_experts
DEBUG 01-06 17:11:20.026993.026993 lmp.py:506]   Computing 32 experts on GPU...
DEBUG 01-06 17:11:20.027509.027509 mlpmodule.py:533] gpu group tensors cost 0.0006792545318603516 s
DEBUG 01-06 17:11:20.029382.029382 mlpmodule.py:566] gpu pad cost 0.0018849372863769531 s
DEBUG 01-06 17:11:20.030776.030776 mlpmodule.py:584] gpu group einsum cost 0.0005676746368408203 s
DEBUG 01-06 17:11:20.033417.033417 mlpmodule.py:613] gpu experts func einsum cost 0.006819486618041992 s
DEBUG 01-06 17:11:20.033179.033179 cuda_h.py:19] end gpu_experts cost 0.0071256160736083984 seconds
DEBUG 01-06 17:11:20.033155.033155 cuda_h.py:19] end layer_moe_generate_9 cost 0.0638277530670166 seconds
DEBUG 01-06 17:11:20.034659.034659 lmp.py:220] -------------------------------- end layer 9 --------------------------------
DEBUG 01-06 17:11:20.034660.034660 lmp.py:176] -------------------------------- start layer 10 --------------------------------
DEBUG 01-06 17:11:20.034641.034641 cuda_h.py:10] start start_load_qkvogn_s_weight_l_11
DEBUG 01-06 17:11:20.034728.034728 cuda_h.py:10] start start_load_qkvogn_s_weight_l_11
DEBUG 01-06 17:11:20.034638.034638 cuda_h.py:19] end start_load_qkvogn_s_weight_l_11 cost 4.744529724121094e-05 seconds
DEBUG 01-06 17:11:20.034625.034625 cuda_h.py:19] end start_load_qkvogn_s_weight_l_11 cost 7.867813110351562e-05 seconds
DEBUG 01-06 17:11:20.034460.034460 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-06 17:11:20.034886.034886 cuda_h.py:10] start sllm_worker_task
DEBUG 01-06 17:11:20.034831.034831 mlpmodule.py:367] cuda:1 cuda:1
DEBUG 01-06 17:11:20.034462.034462 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 17:11:20.034380.034380 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 17:11:20.039522.039522 cuda_h.py:19] end allocate_cuda_memory cost 0.00442051887512207 seconds
DEBUG 01-06 17:11:20.039260.039260 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 17:11:20.039838.039838 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 17:11:20.039614.039614 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 17:11:20.039748.039748 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, c52d6138-a3d2-4d71-957c-4cd99f797743
DEBUG 01-06 17:11:20.039479.039479 client.py:106] call stub.LoadModelAsync
DEBUG 01-06 17:11:20.039087.039087 mlpmodule.py:664]  experts func einsum cost 0.05864524841308594 s
DEBUG 01-06 17:11:20.039853.039853 cuda_h.py:10] start self_attn
INFO 01-06 17:11:20.040151.040151 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, c52d6138-a3d2-4d71-957c-4cd99f797743
DEBUG 01-06 17:11:20.040431.040431 cuda_h.py:19] end load_into_gpu_async cost 0.001699686050415039 seconds
DEBUG 01-06 17:11:20.041134.041134 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 17:11:20.041700.041700 cuda_h.py:19] end restore_tensors2 cost 7.414817810058594e-05 seconds
DEBUG 01-06 17:11:20.041456.041456 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.006468772888183594 seconds
INFO 01-06 17:11:20.041293.041293 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, c52d6138-a3d2-4d71-957c-4cd99f797743
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-06 17:11:20.043421.043421 cuda_h.py:19] end self_attn cost 0.003402233123779297 seconds
DEBUG 01-06 17:11:20.043590.043590 cuda_h.py:19] end iln_self_attn_paln cost 0.009371042251586914 seconds
DEBUG 01-06 17:11:20.043048.043048 cuda_h.py:10] start layer_moe_generate_10
DEBUG 01-06 17:11:20.043765.043765 cuda_h.py:10] start gate
DEBUG 01-06 17:11:20.044297.044297 cuda_h.py:19] end gate cost 0.0008139610290527344 seconds
DEBUG 01-06 17:11:20.044888.044888 cuda_h.py:10] start experts_map_get
DEBUG 01-06 17:11:20.045739.045739 lmp.py:403] 
DEBUG 01-06 17:11:20.045739.045739 lmp.py:403] Expert Token Distribution & Device Allocation:
DEBUG 01-06 17:11:20.045303.045303 lmp.py:404]   Total experts: 64
DEBUG 01-06 17:11:20.045953.045953 lmp.py:405]   CPU experts: 32 (50%)
DEBUG 01-06 17:11:20.045788.045788 lmp.py:406]   GPU experts: 32 (50%)
DEBUG 01-06 17:11:20.045954.045954 lmp.py:407] 
DEBUG 01-06 17:11:20.045954.045954 lmp.py:407]   Expert ID | Tokens | Device
DEBUG 01-06 17:11:20.045882.045882 lmp.py:408]   -----------------------------------
DEBUG 01-06 17:11:20.045485.045485 lmp.py:414]   Expert 43 |     17 | CPU
DEBUG 01-06 17:11:20.045890.045890 lmp.py:414]   Expert 27 |     33 | CPU
DEBUG 01-06 17:11:20.045579.045579 lmp.py:414]   Expert 34 |     49 | CPU
DEBUG 01-06 17:11:20.045553.045553 lmp.py:414]   Expert 56 |     51 | CPU
DEBUG 01-06 17:11:20.045527.045527 lmp.py:414]   Expert 26 |     54 | CPU
DEBUG 01-06 17:11:20.045740.045740 lmp.py:414]   Expert  3 |     58 | CPU
DEBUG 01-06 17:11:20.045475.045475 lmp.py:414]   Expert  4 |     76 | CPU
DEBUG 01-06 17:11:20.045449.045449 lmp.py:414]   Expert 61 |     78 | CPU
DEBUG 01-06 17:11:20.045377.045377 lmp.py:414]   Expert 14 |     91 | CPU
DEBUG 01-06 17:11:20.045828.045828 lmp.py:414]   Expert 38 |    100 | CPU
DEBUG 01-06 17:11:20.045517.045517 lmp.py:414]   Expert  2 |    110 | CPU
DEBUG 01-06 17:11:20.045968.045968 lmp.py:414]   Expert 17 |    117 | CPU
DEBUG 01-06 17:11:20.045134.045134 lmp.py:414]   Expert 22 |    120 | CPU
DEBUG 01-06 17:11:20.045347.045347 lmp.py:414]   Expert 55 |    122 | CPU
DEBUG 01-06 17:11:20.045082.045082 lmp.py:414]   Expert 37 |    125 | CPU
DEBUG 01-06 17:11:20.045056.045056 lmp.py:414]   Expert 47 |    126 | CPU
DEBUG 01-06 17:11:20.045792.045792 lmp.py:414]   Expert 54 |    129 | CPU
DEBUG 01-06 17:11:20.045528.045528 lmp.py:414]   Expert 15 |    138 | CPU
DEBUG 01-06 17:11:20.045263.045263 lmp.py:414]   Expert 28 |    138 | CPU
DEBUG 01-06 17:11:20.045237.045237 lmp.py:414]   Expert 48 |    142 | CPU
DEBUG 01-06 17:11:20.045973.045973 lmp.py:414]   Expert 51 |    143 | CPU
DEBUG 01-06 17:11:20.045901.045901 lmp.py:414]   Expert  7 |    145 | CPU
DEBUG 01-06 17:11:20.045351.045351 lmp.py:414]   Expert 12 |    145 | CPU
DEBUG 01-06 17:11:20.045041.045041 lmp.py:414]   Expert  5 |    147 | CPU
DEBUG 01-06 17:11:20.045730.045730 lmp.py:414]   Expert 45 |    147 | CPU
DEBUG 01-06 17:11:20.045181.045181 lmp.py:414]   Expert 60 |    151 | CPU
DEBUG 01-06 17:11:20.045393.045393 lmp.py:414]   Expert 63 |    151 | CPU
DEBUG 01-06 17:11:20.045129.045129 lmp.py:414]   Expert 19 |    152 | CPU
DEBUG 01-06 17:11:20.045772.045772 lmp.py:414]   Expert  6 |    157 | CPU
DEBUG 01-06 17:11:20.045700.045700 lmp.py:414]   Expert 52 |    167 | CPU
DEBUG 01-06 17:11:20.045389.045389 lmp.py:414]   Expert 57 |    176 | CPU
DEBUG 01-06 17:11:20.045840.045840 lmp.py:414]   Expert 31 |    180 | CPU
DEBUG 01-06 17:11:20.045529.045529 lmp.py:414]   Expert 44 |    180 | GPU
DEBUG 01-06 17:11:20.045980.045980 lmp.py:414]   Expert 30 |    186 | GPU
DEBUG 01-06 17:11:20.045431.045431 lmp.py:414]   Expert 50 |    187 | GPU
DEBUG 01-06 17:11:20.045882.045882 lmp.py:414]   Expert 59 |    187 | GPU
DEBUG 01-06 17:11:20.045286.045286 lmp.py:414]   Expert 13 |    188 | GPU
DEBUG 01-06 17:11:20.045453.045453 lmp.py:414]   Expert 18 |    188 | GPU
DEBUG 01-06 17:11:20.045619.045619 lmp.py:414]   Expert 53 |    191 | GPU
DEBUG 01-06 17:11:20.045308.045308 lmp.py:414]   Expert 20 |    194 | GPU
DEBUG 01-06 17:11:20.045951.045951 lmp.py:414]   Expert 39 |    198 | GPU
DEBUG 01-06 17:11:20.045402.045402 lmp.py:414]   Expert 23 |    200 | GPU
DEBUG 01-06 17:11:20.045376.045376 lmp.py:414]   Expert 29 |    200 | GPU
DEBUG 01-06 17:11:20.045065.045065 lmp.py:414]   Expert 21 |    204 | GPU
DEBUG 01-06 17:11:20.045516.045516 lmp.py:414]   Expert 16 |    205 | GPU
DEBUG 01-06 17:11:20.045729.045729 lmp.py:414]   Expert 36 |    207 | GPU
DEBUG 01-06 17:11:20.045418.045418 lmp.py:414]   Expert 25 |    214 | GPU
DEBUG 01-06 17:11:20.045584.045584 lmp.py:414]   Expert 32 |    214 | GPU
DEBUG 01-06 17:11:20.045989.045989 lmp.py:414]   Expert 49 |    215 | GPU
DEBUG 01-06 17:11:20.045155.045155 lmp.py:414]   Expert 41 |    219 | GPU
DEBUG 01-06 17:11:20.045798.045798 lmp.py:414]   Expert 46 |    224 | GPU
DEBUG 01-06 17:11:20.046725.046725 lmp.py:414]   Expert 10 |    253 | GPU
DEBUG 01-06 17:11:20.046938.046938 lmp.py:414]   Expert 62 |    255 | GPU
DEBUG 01-06 17:11:20.046389.046389 lmp.py:414]   Expert 42 |    257 | GPU
DEBUG 01-06 17:11:20.046840.046840 lmp.py:414]   Expert  8 |    262 | GPU
DEBUG 01-06 17:11:20.046814.046814 lmp.py:414]   Expert 35 |    276 | GPU
DEBUG 01-06 17:11:20.046026.046026 lmp.py:414]   Expert  9 |    281 | GPU
DEBUG 01-06 17:11:20.046239.046239 lmp.py:414]   Expert 58 |    300 | GPU
DEBUG 01-06 17:11:20.046451.046451 lmp.py:414]   Expert 33 |    307 | GPU
DEBUG 01-06 17:11:20.046856.046856 lmp.py:414]   Expert 40 |    405 | GPU
DEBUG 01-06 17:11:20.046022.046022 lmp.py:414]   Expert  0 |    433 | GPU
DEBUG 01-06 17:11:20.046188.046188 lmp.py:414]   Expert 11 |    472 | GPU
DEBUG 01-06 17:11:20.046592.046592 lmp.py:414]   Expert 24 |    568 | GPU
DEBUG 01-06 17:11:20.046997.046997 lmp.py:414]   Expert  1 |    683 | GPU
DEBUG 01-06 17:11:20.046640.046640 lmp.py:415] 
DEBUG 01-06 17:11:20.046640.046640 lmp.py:415]   CPU total tokens: 3735 (30.4%)
DEBUG 01-06 17:11:20.046044.046044 lmp.py:416]   GPU total tokens: 8553 (69.6%)
DEBUG 01-06 17:11:20.046502.046502 cuda_h.py:19] end experts_map_get cost 0.0015141963958740234 seconds
DEBUG 01-06 17:11:20.046145.046145 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-06 17:11:20.046021.046021 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 17:11:20.046264.046264 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 17:11:20.047084.047084 cuda_h.py:19] end allocate_cuda_memory cost 0.0009222030639648438 seconds
DEBUG 01-06 17:11:20.047040.047040 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 17:11:20.047704.047704 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 17:11:20.047751.047751 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 17:11:20.047401.047401 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 1b691ae9-3ff9-4eb4-85f9-1abcb185793c
DEBUG 01-06 17:11:20.047043.047043 client.py:106] call stub.LoadModelAsync
INFO 01-06 17:11:20.048904.048904 client.py:127] Model loaded
DEBUG 01-06 17:11:20.048384.048384 cuda_h.py:19] end sllm_worker_task cost 0.014096498489379883 seconds
INFO 01-06 17:11:20.049903.049903 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 1b691ae9-3ff9-4eb4-85f9-1abcb185793c
DEBUG 01-06 17:11:20.049590.049590 cuda_h.py:19] end load_into_gpu_async cost 0.002321004867553711 seconds
DEBUG 01-06 17:11:20.049222.049222 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 17:11:20.050263.050263 cuda_h.py:19] end restore_tensors2 cost 0.0007727146148681641 seconds
DEBUG 01-06 17:11:20.050960.050960 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0044972896575927734 seconds
DEBUG 01-06 17:11:20.053560.053560 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.007231473922729492 seconds
DEBUG 01-06 17:11:20.053854.053854 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-06 17:11:20.053301.053301 lmp.py:461] 
DEBUG 01-06 17:11:20.053301.053301 lmp.py:461]   Computing 32 experts on CPU...
DEBUG 01-06 17:11:20.053905.053905 cuda_h.py:19] end cpu_experts_submit cost 0.0001068115234375 seconds
DEBUG 01-06 17:11:20.053602.053602 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-06 17:11:20.064891.064891 mlpmodule.py:706] group tensors cost 0.01079559326171875 s
DEBUG 01-06 17:11:20.067203.067203 mlpmodule.py:744] pad cost 0.0016324520111083984 s
DEBUG 01-06 17:11:20.067729.067729 mlpmodule.py:750] create cpu tensor cost 4.792213439941406e-05 s
DEBUG 01-06 17:11:20.067778.067778 mlpmodule.py:755] move to cpu cost 3.5762786865234375e-05 s
DEBUG 01-06 17:11:20.076034.076034 mlpmodule.py:769] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-06 17:11:20.076343.076343 mlpmodule.py:770] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-06 17:11:20.076405.076405 mlpmodule.py:775] group_w3 first element: -0.0213623046875
WARNING 01-06 17:11:20.077985.077985 mlpmodule.py:785] start einsum2
DEBUG 01-06 17:11:20.093065.093065 mlpmodule.py:795] group einsum cost 0.025915145874023438 s
DEBUG 01-06 17:11:20.094301.094301 mlpmodule.py:803] cpy2cputensor cost 0.0007412433624267578 s
DEBUG 01-06 17:11:20.098614.098614 cuda_h.py:19] end wait_cetm_experts cost 0.04480409622192383 seconds
DEBUG 01-06 17:11:20.098349.098349 cuda_h.py:10] start gpu_sexperts
DEBUG 01-06 17:11:20.099086.099086 cuda_h.py:19] end gpu_sexperts cost 0.0006062984466552734 seconds
DEBUG 01-06 17:11:20.099837.099837 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-06 17:11:20.099448.099448 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.384185791015625e-05 seconds
DEBUG 01-06 17:11:20.099105.099105 cuda_h.py:10] start wait_experts
INFO 01-06 17:11:20.099337.099337 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 1b691ae9-3ff9-4eb4-85f9-1abcb185793c
INFO 01-06 17:11:20.102724.102724 client.py:127] Model loaded
DEBUG 01-06 17:11:20.102866.102866 cuda_h.py:19] end wait_experts cost 0.002916574478149414 seconds
DEBUG 01-06 17:11:20.102476.102476 cuda_h.py:10] start gpu_experts
DEBUG 01-06 17:11:20.102470.102470 lmp.py:506]   Computing 32 experts on GPU...
DEBUG 01-06 17:11:20.103535.103535 mlpmodule.py:533] gpu group tensors cost 0.00066375732421875 s
DEBUG 01-06 17:11:20.105540.105540 mlpmodule.py:566] gpu pad cost 0.001880645751953125 s
DEBUG 01-06 17:11:20.105062.105062 mlpmodule.py:584] gpu group einsum cost 0.000457763671875 s
DEBUG 01-06 17:11:20.109241.109241 mlpmodule.py:613] gpu experts func einsum cost 0.006519794464111328 s
DEBUG 01-06 17:11:20.109562.109562 cuda_h.py:19] end gpu_experts cost 0.006705284118652344 seconds
DEBUG 01-06 17:11:20.109638.109638 cuda_h.py:19] end layer_moe_generate_10 cost 0.06564164161682129 seconds
DEBUG 01-06 17:11:20.109248.109248 lmp.py:220] -------------------------------- end layer 10 --------------------------------
DEBUG 01-06 17:11:20.109726.109726 lmp.py:176] -------------------------------- start layer 11 --------------------------------
DEBUG 01-06 17:11:20.109899.109899 cuda_h.py:10] start start_load_qkvogn_s_weight_l_12
DEBUG 01-06 17:11:20.109131.109131 cuda_h.py:10] start start_load_qkvogn_s_weight_l_12
DEBUG 01-06 17:11:20.109127.109127 cuda_h.py:19] end start_load_qkvogn_s_weight_l_12 cost 2.956390380859375e-05 seconds
DEBUG 01-06 17:11:20.109353.109353 cuda_h.py:19] end start_load_qkvogn_s_weight_l_12 cost 5.936622619628906e-05 seconds
DEBUG 01-06 17:11:20.109188.109188 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-06 17:11:20.109925.109925 cuda_h.py:10] start sllm_worker_task
DEBUG 01-06 17:11:20.110769.110769 mlpmodule.py:367] cuda:1 cuda:1
DEBUG 01-06 17:11:20.110752.110752 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 17:11:20.110876.110876 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 17:11:20.111367.111367 cuda_h.py:19] end allocate_cuda_memory cost 0.0011639595031738281 seconds
DEBUG 01-06 17:11:20.111508.111508 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 17:11:20.111193.111193 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 17:11:20.111307.111307 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 17:11:20.111533.111533 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, b7c07546-0e7d-4df7-b2b8-42dfc2ee02f8
DEBUG 01-06 17:11:20.111741.111741 client.py:106] call stub.LoadModelAsync
DEBUG 01-06 17:11:20.111403.111403 mlpmodule.py:664]  experts func einsum cost 0.05793404579162598 s
DEBUG 01-06 17:11:20.112890.112890 cuda_h.py:10] start self_attn
INFO 01-06 17:11:20.113943.113943 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, b7c07546-0e7d-4df7-b2b8-42dfc2ee02f8
DEBUG 01-06 17:11:20.113263.113263 cuda_h.py:19] end load_into_gpu_async cost 0.0017015933990478516 seconds
DEBUG 01-06 17:11:20.113774.113774 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 17:11:20.113718.113718 cuda_h.py:19] end restore_tensors2 cost 7.200241088867188e-05 seconds
DEBUG 01-06 17:11:20.113997.113997 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0032372474670410156 seconds
INFO 01-06 17:11:20.113402.113402 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, b7c07546-0e7d-4df7-b2b8-42dfc2ee02f8
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-06 17:11:20.115985.115985 cuda_h.py:19] end self_attn cost 0.0029108524322509766 seconds
DEBUG 01-06 17:11:20.115464.115464 cuda_h.py:19] end iln_self_attn_paln cost 0.005575656890869141 seconds
DEBUG 01-06 17:11:20.115208.115208 cuda_h.py:10] start layer_moe_generate_11
DEBUG 01-06 17:11:20.115660.115660 cuda_h.py:10] start gate
DEBUG 01-06 17:11:20.116445.116445 cuda_h.py:19] end gate cost 0.0006504058837890625 seconds
DEBUG 01-06 17:11:20.116096.116096 cuda_h.py:10] start experts_map_get
DEBUG 01-06 17:11:20.116324.116324 lmp.py:403] 
DEBUG 01-06 17:11:20.116324.116324 lmp.py:403] Expert Token Distribution & Device Allocation:
DEBUG 01-06 17:11:20.116365.116365 lmp.py:404]   Total experts: 64
DEBUG 01-06 17:11:20.116015.116015 lmp.py:405]   CPU experts: 32 (50%)
DEBUG 01-06 17:11:20.116565.116565 lmp.py:406]   GPU experts: 32 (50%)
DEBUG 01-06 17:11:20.116731.116731 lmp.py:407] 
DEBUG 01-06 17:11:20.116731.116731 lmp.py:407]   Expert ID | Tokens | Device
DEBUG 01-06 17:11:20.116659.116659 lmp.py:408]   -----------------------------------
DEBUG 01-06 17:11:20.116693.116693 lmp.py:414]   Expert 39 |     12 | CPU
DEBUG 01-06 17:11:20.116051.116051 lmp.py:414]   Expert 13 |     19 | CPU
DEBUG 01-06 17:11:20.116694.116694 lmp.py:414]   Expert 49 |     37 | CPU
DEBUG 01-06 17:11:20.116860.116860 lmp.py:414]   Expert 35 |     41 | CPU
DEBUG 01-06 17:11:20.116788.116788 lmp.py:414]   Expert 19 |     64 | CPU
DEBUG 01-06 17:11:20.116477.116477 lmp.py:414]   Expert 32 |     73 | CPU
DEBUG 01-06 17:11:20.116405.116405 lmp.py:414]   Expert 41 |     75 | CPU
DEBUG 01-06 17:11:20.116571.116571 lmp.py:414]   Expert 23 |     80 | CPU
DEBUG 01-06 17:11:20.116453.116453 lmp.py:414]   Expert 26 |     80 | CPU
DEBUG 01-06 17:11:20.116334.116334 lmp.py:414]   Expert 46 |     83 | CPU
DEBUG 01-06 17:11:20.117977.117977 lmp.py:414]   Expert 33 |     85 | CPU
DEBUG 01-06 17:11:20.117143.117143 lmp.py:414]   Expert 31 |     86 | CPU
DEBUG 01-06 17:11:20.117309.117309 lmp.py:414]   Expert  9 |     87 | CPU
DEBUG 01-06 17:11:20.117999.117999 lmp.py:414]   Expert 38 |     89 | CPU
DEBUG 01-06 17:11:20.117926.117926 lmp.py:414]   Expert 18 |     91 | CPU
DEBUG 01-06 17:11:20.117616.117616 lmp.py:414]   Expert  6 |    102 | CPU
DEBUG 01-06 17:11:20.117543.117543 lmp.py:414]   Expert  3 |    111 | CPU
DEBUG 01-06 17:11:20.117233.117233 lmp.py:414]   Expert 17 |    112 | CPU
DEBUG 01-06 17:11:20.117160.117160 lmp.py:414]   Expert 20 |    115 | CPU
DEBUG 01-06 17:11:20.117088.117088 lmp.py:414]   Expert 16 |    124 | CPU
DEBUG 01-06 17:11:20.117777.117777 lmp.py:414]   Expert 59 |    124 | CPU
DEBUG 01-06 17:11:20.117990.117990 lmp.py:414]   Expert 40 |    134 | CPU
DEBUG 01-06 17:11:20.117633.117633 lmp.py:414]   Expert 43 |    135 | CPU
DEBUG 01-06 17:11:20.117799.117799 lmp.py:414]   Expert 15 |    138 | CPU
DEBUG 01-06 17:11:20.117965.117965 lmp.py:414]   Expert 62 |    138 | CPU
DEBUG 01-06 17:11:20.117893.117893 lmp.py:414]   Expert 61 |    139 | CPU
DEBUG 01-06 17:11:20.117059.117059 lmp.py:414]   Expert 50 |    141 | CPU
DEBUG 01-06 17:11:20.117987.117987 lmp.py:414]   Expert 63 |    141 | CPU
DEBUG 01-06 17:11:20.117676.117676 lmp.py:414]   Expert  2 |    143 | CPU
DEBUG 01-06 17:11:20.117127.117127 lmp.py:414]   Expert 42 |    144 | CPU
DEBUG 01-06 17:11:20.117578.117578 lmp.py:414]   Expert 44 |    144 | CPU
DEBUG 01-06 17:11:20.117029.117029 lmp.py:414]   Expert 36 |    147 | CPU
DEBUG 01-06 17:11:20.117718.117718 lmp.py:414]   Expert 10 |    154 | GPU
DEBUG 01-06 17:11:20.117169.117169 lmp.py:414]   Expert  5 |    179 | GPU
DEBUG 01-06 17:11:20.117097.117097 lmp.py:414]   Expert 34 |    180 | GPU
DEBUG 01-06 17:11:20.117263.117263 lmp.py:414]   Expert 45 |    187 | GPU
DEBUG 01-06 17:11:20.117144.117144 lmp.py:414]   Expert 27 |    188 | GPU
DEBUG 01-06 17:11:20.117833.117833 lmp.py:414]   Expert 52 |    190 | GPU
DEBUG 01-06 17:11:20.117238.117238 lmp.py:414]   Expert 60 |    190 | GPU
DEBUG 01-06 17:11:20.117927.117927 lmp.py:414]   Expert 48 |    195 | GPU
DEBUG 01-06 17:11:20.117378.117378 lmp.py:414]   Expert 51 |    206 | GPU
DEBUG 01-06 17:11:20.117591.117591 lmp.py:414]   Expert  7 |    219 | GPU
DEBUG 01-06 17:11:20.117803.117803 lmp.py:414]   Expert 56 |    225 | GPU
DEBUG 01-06 17:11:20.117016.117016 lmp.py:414]   Expert 24 |    226 | GPU
DEBUG 01-06 17:11:20.117466.117466 lmp.py:414]   Expert  8 |    233 | GPU
DEBUG 01-06 17:11:20.117679.117679 lmp.py:414]   Expert 53 |    233 | GPU
DEBUG 01-06 17:11:20.117607.117607 lmp.py:414]   Expert 57 |    242 | GPU
DEBUG 01-06 17:11:20.117534.117534 lmp.py:414]   Expert 29 |    254 | GPU
DEBUG 01-06 17:11:20.117462.117462 lmp.py:414]   Expert 47 |    261 | GPU
DEBUG 01-06 17:11:20.117628.117628 lmp.py:414]   Expert 21 |    267 | GPU
DEBUG 01-06 17:11:20.117033.117033 lmp.py:414]   Expert  4 |    273 | GPU
DEBUG 01-06 17:11:20.117960.117960 lmp.py:414]   Expert  0 |    286 | GPU
DEBUG 01-06 17:11:20.117411.117411 lmp.py:414]   Expert 14 |    293 | GPU
DEBUG 01-06 17:11:20.117624.117624 lmp.py:414]   Expert 22 |    315 | GPU
DEBUG 01-06 17:11:20.117836.117836 lmp.py:414]   Expert 55 |    320 | GPU
DEBUG 01-06 17:11:20.117764.117764 lmp.py:414]   Expert  1 |    328 | GPU
DEBUG 01-06 17:11:20.117976.117976 lmp.py:414]   Expert 37 |    328 | GPU
DEBUG 01-06 17:11:20.117427.117427 lmp.py:414]   Expert 54 |    333 | GPU
DEBUG 01-06 17:11:20.117878.117878 lmp.py:414]   Expert 58 |    335 | GPU
DEBUG 01-06 17:11:20.117806.117806 lmp.py:414]   Expert 28 |    354 | GPU
DEBUG 01-06 17:11:20.117734.117734 lmp.py:414]   Expert 12 |    374 | GPU
DEBUG 01-06 17:11:20.117138.117138 lmp.py:414]   Expert 25 |    400 | GPU
DEBUG 01-06 17:11:20.117304.117304 lmp.py:414]   Expert 11 |    422 | GPU
DEBUG 01-06 17:11:20.117709.117709 lmp.py:414]   Expert 30 |    864 | GPU
DEBUG 01-06 17:11:20.117266.117266 lmp.py:415] 
DEBUG 01-06 17:11:20.117266.117266 lmp.py:415]   CPU total tokens: 3234 (26.3%)
DEBUG 01-06 17:11:20.117909.117909 lmp.py:416]   GPU total tokens: 9054 (73.7%)
DEBUG 01-06 17:11:20.117605.117605 cuda_h.py:19] end experts_map_get cost 0.0015392303466796875 seconds
DEBUG 01-06 17:11:20.117248.117248 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-06 17:11:20.118647.118647 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 17:11:20.118122.118122 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 17:11:20.119069.119069 cuda_h.py:19] end allocate_cuda_memory cost 0.0013675689697265625 seconds
DEBUG 01-06 17:11:20.119403.119403 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 17:11:20.119828.119828 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 17:11:20.119829.119829 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 17:11:20.119671.119671 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, bbbd03a8-2ea9-4ca5-b6fc-4133e02b0f68
DEBUG 01-06 17:11:20.161869.161869 client.py:106] call stub.LoadModelAsync
INFO 01-06 17:11:20.161361.161361 client.py:127] Model loaded
DEBUG 01-06 17:11:20.162153.162153 cuda_h.py:19] end sllm_worker_task cost 0.05248379707336426 seconds
INFO 01-06 17:11:20.163673.163673 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, bbbd03a8-2ea9-4ca5-b6fc-4133e02b0f68
DEBUG 01-06 17:11:20.163152.163152 cuda_h.py:19] end load_into_gpu_async cost 0.04370522499084473 seconds
DEBUG 01-06 17:11:20.163239.163239 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 17:11:20.163243.163243 cuda_h.py:19] end restore_tensors2 cost 0.0004661083221435547 seconds
DEBUG 01-06 17:11:20.163940.163940 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.04590892791748047 seconds
DEBUG 01-06 17:11:20.166916.166916 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.048598527908325195 seconds
DEBUG 01-06 17:11:20.166898.166898 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-06 17:11:20.166696.166696 lmp.py:461] 
DEBUG 01-06 17:11:20.166696.166696 lmp.py:461]   Computing 32 experts on CPU...
DEBUG 01-06 17:11:20.166592.166592 cuda_h.py:19] end cpu_experts_submit cost 0.000118255615234375 seconds
DEBUG 01-06 17:11:20.166957.166957 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-06 17:11:20.184217.184217 mlpmodule.py:706] group tensors cost 0.01763749122619629 s
DEBUG 01-06 17:11:20.187271.187271 mlpmodule.py:744] pad cost 0.0017161369323730469 s
DEBUG 01-06 17:11:20.187189.187189 mlpmodule.py:750] create cpu tensor cost 5.245208740234375e-05 s
DEBUG 01-06 17:11:20.187430.187430 mlpmodule.py:755] move to cpu cost 3.7670135498046875e-05 s
DEBUG 01-06 17:11:20.198618.198618 mlpmodule.py:769] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-06 17:11:20.198198.198198 mlpmodule.py:770] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-06 17:11:20.199591.199591 mlpmodule.py:775] group_w3 first element: -0.006134033203125
WARNING 01-06 17:11:20.199595.199595 mlpmodule.py:785] start einsum2
DEBUG 01-06 17:11:20.218087.218087 mlpmodule.py:795] group einsum cost 0.030815601348876953 s
DEBUG 01-06 17:11:20.219389.219389 mlpmodule.py:803] cpy2cputensor cost 0.0005371570587158203 s
DEBUG 01-06 17:11:20.223622.223622 cuda_h.py:19] end wait_cetm_experts cost 0.05655360221862793 seconds
DEBUG 01-06 17:11:20.223695.223695 cuda_h.py:10] start gpu_sexperts
DEBUG 01-06 17:11:20.224485.224485 cuda_h.py:19] end gpu_sexperts cost 0.0006082057952880859 seconds
DEBUG 01-06 17:11:20.224144.224144 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-06 17:11:20.224239.224239 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.6941299438476562e-05 seconds
DEBUG 01-06 17:11:20.224134.224134 cuda_h.py:10] start wait_experts
INFO 01-06 17:11:20.224128.224128 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, bbbd03a8-2ea9-4ca5-b6fc-4133e02b0f68
INFO 01-06 17:11:20.225617.225617 client.py:127] Model loaded
DEBUG 01-06 17:11:20.225559.225559 cuda_h.py:19] end wait_experts cost 0.0014064311981201172 seconds
DEBUG 01-06 17:11:20.226454.226454 cuda_h.py:10] start gpu_experts
DEBUG 01-06 17:11:20.226733.226733 lmp.py:506]   Computing 32 experts on GPU...
DEBUG 01-06 17:11:20.226129.226129 mlpmodule.py:533] gpu group tensors cost 0.0006625652313232422 s
DEBUG 01-06 17:11:20.228237.228237 mlpmodule.py:566] gpu pad cost 0.0017771720886230469 s
DEBUG 01-06 17:11:20.229397.229397 mlpmodule.py:584] gpu group einsum cost 0.0005369186401367188 s
DEBUG 01-06 17:11:20.232204.232204 mlpmodule.py:613] gpu experts func einsum cost 0.006648063659667969 s
DEBUG 01-06 17:11:20.232161.232161 cuda_h.py:19] end gpu_experts cost 0.00684666633605957 seconds
DEBUG 01-06 17:11:20.232198.232198 cuda_h.py:19] end layer_moe_generate_11 cost 0.1173250675201416 seconds
DEBUG 01-06 17:11:20.233047.233047 lmp.py:220] -------------------------------- end layer 11 --------------------------------
DEBUG 01-06 17:11:20.233479.233479 lmp.py:176] -------------------------------- start layer 12 --------------------------------
DEBUG 01-06 17:11:20.233512.233512 cuda_h.py:10] start start_load_qkvogn_s_weight_l_13
DEBUG 01-06 17:11:20.233322.233322 cuda_h.py:10] start start_load_qkvogn_s_weight_l_13
DEBUG 01-06 17:11:20.233079.233079 cuda_h.py:19] end start_load_qkvogn_s_weight_l_13 cost 3.790855407714844e-05 seconds
DEBUG 01-06 17:11:20.233981.233981 cuda_h.py:19] end start_load_qkvogn_s_weight_l_13 cost 7.414817810058594e-05 seconds
DEBUG 01-06 17:11:20.233822.233822 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-06 17:11:20.233010.233010 cuda_h.py:10] start sllm_worker_task
DEBUG 01-06 17:11:20.233132.233132 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 17:11:20.233207.233207 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 17:11:20.235739.235739 cuda_h.py:19] end allocate_cuda_memory cost 0.0016100406646728516 seconds
DEBUG 01-06 17:11:20.235623.235623 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 17:11:20.235552.235552 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 17:11:20.235328.235328 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 17:11:20.235270.235270 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 99c08ed4-5d8d-4d39-b3a7-b4ef6a275e5e
DEBUG 01-06 17:11:20.235617.235617 client.py:106] call stub.LoadModelAsync
DEBUG 01-06 17:11:20.235285.235285 mlpmodule.py:367] cuda:1 cuda:1
DEBUG 01-06 17:11:20.235502.235502 mlpmodule.py:664]  experts func einsum cost 0.06875014305114746 s
DEBUG 01-06 17:11:20.236295.236295 cuda_h.py:10] start self_attn
INFO 01-06 17:11:20.237291.237291 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 99c08ed4-5d8d-4d39-b3a7-b4ef6a275e5e
DEBUG 01-06 17:11:20.237565.237565 cuda_h.py:19] end load_into_gpu_async cost 0.0017635822296142578 seconds
DEBUG 01-06 17:11:20.237791.237791 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 17:11:20.237496.237496 cuda_h.py:19] end restore_tensors2 cost 7.200241088867188e-05 seconds
DEBUG 01-06 17:11:20.237014.237014 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.003742694854736328 seconds
INFO 01-06 17:11:20.237810.237810 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 99c08ed4-5d8d-4d39-b3a7-b4ef6a275e5e
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-06 17:11:20.239738.239738 cuda_h.py:19] end self_attn cost 0.003240823745727539 seconds
DEBUG 01-06 17:11:20.239530.239530 cuda_h.py:19] end iln_self_attn_paln cost 0.006457090377807617 seconds
DEBUG 01-06 17:11:20.239896.239896 cuda_h.py:10] start layer_moe_generate_12
DEBUG 01-06 17:11:20.240328.240328 cuda_h.py:10] start gate
DEBUG 01-06 17:11:20.240205.240205 cuda_h.py:19] end gate cost 0.0006480216979980469 seconds
DEBUG 01-06 17:11:20.240750.240750 cuda_h.py:10] start experts_map_get
DEBUG 01-06 17:11:20.241634.241634 lmp.py:403] 
DEBUG 01-06 17:11:20.241634.241634 lmp.py:403] Expert Token Distribution & Device Allocation:
DEBUG 01-06 17:11:20.241436.241436 lmp.py:404]   Total experts: 64
DEBUG 01-06 17:11:20.241324.241324 lmp.py:405]   CPU experts: 32 (50%)
DEBUG 01-06 17:11:20.241159.241159 lmp.py:406]   GPU experts: 32 (50%)
DEBUG 01-06 17:11:20.241087.241087 lmp.py:407] 
DEBUG 01-06 17:11:20.241087.241087 lmp.py:407]   Expert ID | Tokens | Device
DEBUG 01-06 17:11:20.241492.241492 lmp.py:408]   -----------------------------------
DEBUG 01-06 17:11:20.241857.241857 lmp.py:414]   Expert 12 |     15 | CPU
DEBUG 01-06 17:11:20.241023.241023 lmp.py:414]   Expert 47 |     19 | CPU
DEBUG 01-06 17:11:20.241235.241235 lmp.py:414]   Expert 27 |     26 | CPU
DEBUG 01-06 17:11:20.241209.241209 lmp.py:414]   Expert 38 |     26 | CPU
DEBUG 01-06 17:11:20.241945.241945 lmp.py:414]   Expert 16 |     33 | CPU
DEBUG 01-06 17:11:20.241681.241681 lmp.py:414]   Expert 52 |     36 | CPU
DEBUG 01-06 17:11:20.241655.241655 lmp.py:414]   Expert 63 |     42 | CPU
DEBUG 01-06 17:11:20.241390.241390 lmp.py:414]   Expert  4 |     54 | CPU
DEBUG 01-06 17:11:20.241364.241364 lmp.py:414]   Expert 44 |     59 | CPU
DEBUG 01-06 17:11:20.241530.241530 lmp.py:414]   Expert 43 |     60 | CPU
DEBUG 01-06 17:11:20.241220.241220 lmp.py:414]   Expert 61 |     64 | CPU
DEBUG 01-06 17:11:20.241432.241432 lmp.py:414]   Expert 34 |     70 | CPU
DEBUG 01-06 17:11:20.241883.241883 lmp.py:414]   Expert 53 |     82 | CPU
DEBUG 01-06 17:11:20.241334.241334 lmp.py:414]   Expert  0 |     83 | CPU
DEBUG 01-06 17:11:20.241070.241070 lmp.py:414]   Expert 37 |     88 | CPU
DEBUG 01-06 17:11:20.241044.241044 lmp.py:414]   Expert 32 |     94 | CPU
DEBUG 01-06 17:11:20.241256.241256 lmp.py:414]   Expert 13 |     96 | CPU
DEBUG 01-06 17:11:20.241992.241992 lmp.py:414]   Expert 21 |    110 | CPU
DEBUG 01-06 17:11:20.241727.241727 lmp.py:414]   Expert 39 |    111 | CPU
DEBUG 01-06 17:11:20.241463.241463 lmp.py:414]   Expert 11 |    117 | CPU
DEBUG 01-06 17:11:20.241199.241199 lmp.py:414]   Expert 20 |    131 | CPU
DEBUG 01-06 17:11:20.241696.241696 lmp.py:414]   Expert 60 |    133 | CPU
DEBUG 01-06 17:11:20.241624.241624 lmp.py:414]   Expert  8 |    137 | CPU
DEBUG 01-06 17:11:20.241836.241836 lmp.py:414]   Expert 22 |    140 | CPU
DEBUG 01-06 17:11:20.241048.241048 lmp.py:414]   Expert 14 |    141 | CPU
DEBUG 01-06 17:11:20.241499.241499 lmp.py:414]   Expert 57 |    142 | CPU
DEBUG 01-06 17:11:20.241427.241427 lmp.py:414]   Expert  2 |    148 | CPU
DEBUG 01-06 17:11:20.241924.241924 lmp.py:414]   Expert 45 |    151 | CPU
DEBUG 01-06 17:11:20.241660.241660 lmp.py:414]   Expert 17 |    154 | CPU
DEBUG 01-06 17:11:20.241157.241157 lmp.py:414]   Expert 23 |    160 | CPU
DEBUG 01-06 17:11:20.241893.241893 lmp.py:414]   Expert 30 |    161 | CPU
DEBUG 01-06 17:11:20.241390.241390 lmp.py:414]   Expert  7 |    162 | CPU
DEBUG 01-06 17:11:20.241364.241364 lmp.py:414]   Expert 18 |    163 | GPU
DEBUG 01-06 17:11:20.241338.241338 lmp.py:414]   Expert 58 |    168 | GPU
DEBUG 01-06 17:11:20.241597.241597 lmp.py:414]   Expert 42 |    171 | GPU
DEBUG 01-06 17:11:20.241048.241048 lmp.py:414]   Expert 49 |    172 | GPU
DEBUG 01-06 17:11:20.241260.241260 lmp.py:414]   Expert 51 |    174 | GPU
DEBUG 01-06 17:11:20.241473.241473 lmp.py:414]   Expert 55 |    176 | GPU
DEBUG 01-06 17:11:20.241685.241685 lmp.py:414]   Expert 62 |    181 | GPU
DEBUG 01-06 17:11:20.241851.241851 lmp.py:414]   Expert 29 |    182 | GPU
DEBUG 01-06 17:11:20.241348.241348 lmp.py:414]   Expert 48 |    188 | GPU
DEBUG 01-06 17:11:20.241084.241084 lmp.py:414]   Expert  6 |    190 | GPU
DEBUG 01-06 17:11:20.241820.241820 lmp.py:414]   Expert 35 |    190 | GPU
DEBUG 01-06 17:11:20.241555.241555 lmp.py:414]   Expert  1 |    197 | GPU
DEBUG 01-06 17:11:20.241053.241053 lmp.py:414]   Expert 31 |    202 | GPU
DEBUG 01-06 17:11:20.241788.241788 lmp.py:414]   Expert 36 |    206 | GPU
DEBUG 01-06 17:11:20.241047.241047 lmp.py:414]   Expert 25 |    212 | GPU
DEBUG 01-06 17:11:20.241783.241783 lmp.py:414]   Expert 28 |    218 | GPU
DEBUG 01-06 17:11:20.241233.241233 lmp.py:414]   Expert 41 |    222 | GPU
DEBUG 01-06 17:11:20.241208.241208 lmp.py:414]   Expert 54 |    232 | GPU
DEBUG 01-06 17:11:20.241420.241420 lmp.py:414]   Expert 19 |    235 | GPU
DEBUG 01-06 17:11:20.242156.242156 lmp.py:414]   Expert  9 |    239 | GPU
DEBUG 01-06 17:11:20.242606.242606 lmp.py:414]   Expert  5 |    240 | GPU
DEBUG 01-06 17:11:20.242342.242342 lmp.py:414]   Expert 24 |    240 | GPU
DEBUG 01-06 17:11:20.242601.242601 lmp.py:414]   Expert 50 |    291 | GPU
DEBUG 01-06 17:11:20.242098.242098 lmp.py:414]   Expert 46 |    305 | GPU
DEBUG 01-06 17:11:20.242834.242834 lmp.py:414]   Expert 59 |    306 | GPU
DEBUG 01-06 17:11:20.242331.242331 lmp.py:414]   Expert 56 |    383 | GPU
DEBUG 01-06 17:11:20.242590.242590 lmp.py:414]   Expert 26 |    390 | GPU
DEBUG 01-06 17:11:20.242849.242849 lmp.py:414]   Expert 33 |    434 | GPU
DEBUG 01-06 17:11:20.242107.242107 lmp.py:414]   Expert  3 |    563 | GPU
DEBUG 01-06 17:11:20.242366.242366 lmp.py:414]   Expert 15 |    679 | GPU
DEBUG 01-06 17:11:20.242863.242863 lmp.py:414]   Expert 10 |    720 | GPU
DEBUG 01-06 17:11:20.242599.242599 lmp.py:414]   Expert 40 |    774 | GPU
DEBUG 01-06 17:11:20.242288.242288 lmp.py:415] 
DEBUG 01-06 17:11:20.242288.242288 lmp.py:415]   CPU total tokens: 3045 (24.8%)
DEBUG 01-06 17:11:20.242454.242454 lmp.py:416]   GPU total tokens: 9243 (75.2%)
DEBUG 01-06 17:11:20.242674.242674 cuda_h.py:19] end experts_map_get cost 0.0014603137969970703 seconds
DEBUG 01-06 17:11:20.242032.242032 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-06 17:11:20.242623.242623 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 17:11:20.242204.242204 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 17:11:20.243373.243373 cuda_h.py:19] end allocate_cuda_memory cost 0.0012509822845458984 seconds
DEBUG 01-06 17:11:20.243660.243660 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 17:11:20.243416.243416 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 17:11:20.243748.243748 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 17:11:20.243160.243160 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 714e1f50-03f7-46ae-a47b-9097337d0a34
DEBUG 01-06 17:11:20.244239.244239 client.py:106] call stub.LoadModelAsync
INFO 01-06 17:11:20.244364.244364 client.py:127] Model loaded
DEBUG 01-06 17:11:20.244132.244132 cuda_h.py:19] end sllm_worker_task cost 0.011276483535766602 seconds
INFO 01-06 17:11:20.246474.246474 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 714e1f50-03f7-46ae-a47b-9097337d0a34
DEBUG 01-06 17:11:20.246340.246340 cuda_h.py:19] end load_into_gpu_async cost 0.0024530887603759766 seconds
DEBUG 01-06 17:11:20.246256.246256 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 17:11:20.246269.246269 cuda_h.py:19] end restore_tensors2 cost 0.0005037784576416016 seconds
DEBUG 01-06 17:11:20.247012.247012 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.004688739776611328 seconds
DEBUG 01-06 17:11:20.249983.249983 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.007417440414428711 seconds
DEBUG 01-06 17:11:20.249144.249144 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-06 17:11:20.249053.249053 lmp.py:461] 
DEBUG 01-06 17:11:20.249053.249053 lmp.py:461]   Computing 32 experts on CPU...
DEBUG 01-06 17:11:20.249420.249420 cuda_h.py:19] end cpu_experts_submit cost 0.00010752677917480469 seconds
DEBUG 01-06 17:11:20.249831.249831 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-06 17:11:20.260664.260664 mlpmodule.py:706] group tensors cost 0.010820150375366211 s
DEBUG 01-06 17:11:20.263331.263331 mlpmodule.py:744] pad cost 0.0019943714141845703 s
DEBUG 01-06 17:11:20.263163.263163 mlpmodule.py:750] create cpu tensor cost 5.1975250244140625e-05 s
DEBUG 01-06 17:11:20.263748.263748 mlpmodule.py:755] move to cpu cost 3.6716461181640625e-05 s
DEBUG 01-06 17:11:20.273006.273006 mlpmodule.py:769] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-06 17:11:20.273764.273764 mlpmodule.py:770] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-06 17:11:20.273515.273515 mlpmodule.py:775] group_w3 first element: -0.0162353515625
WARNING 01-06 17:11:20.273121.273121 mlpmodule.py:785] start einsum2
DEBUG 01-06 17:11:20.291629.291629 mlpmodule.py:795] group einsum cost 0.028002262115478516 s
DEBUG 01-06 17:11:20.292808.292808 mlpmodule.py:803] cpy2cputensor cost 0.0006406307220458984 s
DEBUG 01-06 17:11:20.297749.297749 cuda_h.py:19] end wait_cetm_experts cost 0.04712224006652832 seconds
DEBUG 01-06 17:11:20.297961.297961 cuda_h.py:10] start gpu_sexperts
DEBUG 01-06 17:11:20.297559.297559 cuda_h.py:19] end gpu_sexperts cost 0.0006055831909179688 seconds
DEBUG 01-06 17:11:20.298647.298647 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-06 17:11:20.298974.298974 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.5033950805664062e-05 seconds
DEBUG 01-06 17:11:20.298154.298154 cuda_h.py:10] start wait_experts
INFO 01-06 17:11:20.298148.298148 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 714e1f50-03f7-46ae-a47b-9097337d0a34
INFO 01-06 17:11:20.300708.300708 client.py:127] Model loaded
DEBUG 01-06 17:11:20.300412.300412 cuda_h.py:19] end wait_experts cost 0.002161741256713867 seconds
DEBUG 01-06 17:11:20.300546.300546 cuda_h.py:10] start gpu_experts
DEBUG 01-06 17:11:20.300348.300348 lmp.py:506]   Computing 32 experts on GPU...
DEBUG 01-06 17:11:20.301619.301619 mlpmodule.py:533] gpu group tensors cost 0.0006577968597412109 s
DEBUG 01-06 17:11:20.302315.302315 mlpmodule.py:566] gpu pad cost 0.0017580986022949219 s
DEBUG 01-06 17:11:20.303980.303980 mlpmodule.py:584] gpu group einsum cost 0.0005917549133300781 s
DEBUG 01-06 17:11:20.307782.307782 mlpmodule.py:613] gpu experts func einsum cost 0.006709098815917969 s
DEBUG 01-06 17:11:20.307190.307190 cuda_h.py:19] end gpu_experts cost 0.006939888000488281 seconds
DEBUG 01-06 17:11:20.307319.307319 cuda_h.py:19] end layer_moe_generate_12 cost 0.06737971305847168 seconds
DEBUG 01-06 17:11:20.307909.307909 lmp.py:220] -------------------------------- end layer 12 --------------------------------
DEBUG 01-06 17:11:20.307579.307579 lmp.py:176] -------------------------------- start layer 13 --------------------------------
DEBUG 01-06 17:11:20.307991.307991 cuda_h.py:10] start start_load_qkvogn_s_weight_l_14
DEBUG 01-06 17:11:20.307700.307700 cuda_h.py:10] start start_load_qkvogn_s_weight_l_14
DEBUG 01-06 17:11:20.307729.307729 cuda_h.py:19] end start_load_qkvogn_s_weight_l_14 cost 3.0279159545898438e-05 seconds
DEBUG 01-06 17:11:20.307670.307670 cuda_h.py:19] end start_load_qkvogn_s_weight_l_14 cost 6.0558319091796875e-05 seconds
DEBUG 01-06 17:11:20.307743.307743 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-06 17:11:20.307216.307216 mlpmodule.py:367] cuda:1 cuda:1
DEBUG 01-06 17:11:20.307510.307510 cuda_h.py:10] start sllm_worker_task
DEBUG 01-06 17:11:20.308394.308394 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 17:11:20.308276.308276 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 17:11:20.309815.309815 cuda_h.py:19] end allocate_cuda_memory cost 0.0016150474548339844 seconds
DEBUG 01-06 17:11:20.309275.309275 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 17:11:20.309787.309787 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 17:11:20.309186.309186 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 17:11:20.309604.309604 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 01554bb5-7a60-462f-843e-d98932fdb779
DEBUG 01-06 17:11:20.310674.310674 client.py:106] call stub.LoadModelAsync
DEBUG 01-06 17:11:20.310182.310182 mlpmodule.py:664]  experts func einsum cost 0.06014299392700195 s
DEBUG 01-06 17:11:20.310934.310934 cuda_h.py:10] start self_attn
INFO 01-06 17:11:20.311084.311084 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 01554bb5-7a60-462f-843e-d98932fdb779
DEBUG 01-06 17:11:20.311120.311120 cuda_h.py:19] end load_into_gpu_async cost 0.0016126632690429688 seconds
DEBUG 01-06 17:11:20.311153.311153 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 17:11:20.311197.311197 cuda_h.py:19] end restore_tensors2 cost 7.414817810058594e-05 seconds
DEBUG 01-06 17:11:20.311714.311714 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0036132335662841797 seconds
INFO 01-06 17:11:20.311902.311902 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 01554bb5-7a60-462f-843e-d98932fdb779
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-06 17:11:20.313259.313259 cuda_h.py:19] end self_attn cost 0.0028700828552246094 seconds
DEBUG 01-06 17:11:20.313991.313991 cuda_h.py:19] end iln_self_attn_paln cost 0.0059812068939208984 seconds
DEBUG 01-06 17:11:20.313470.313470 cuda_h.py:10] start layer_moe_generate_13
DEBUG 01-06 17:11:20.313902.313902 cuda_h.py:10] start gate
DEBUG 01-06 17:11:20.314944.314944 cuda_h.py:19] end gate cost 0.0006284713745117188 seconds
DEBUG 01-06 17:11:20.314058.314058 cuda_h.py:10] start experts_map_get
DEBUG 01-06 17:11:20.314373.314373 lmp.py:403] 
DEBUG 01-06 17:11:20.314373.314373 lmp.py:403] Expert Token Distribution & Device Allocation:
DEBUG 01-06 17:11:20.314367.314367 lmp.py:404]   Total experts: 64
DEBUG 01-06 17:11:20.315494.315494 lmp.py:405]   CPU experts: 32 (50%)
DEBUG 01-06 17:11:20.315806.315806 lmp.py:406]   GPU experts: 32 (50%)
DEBUG 01-06 17:11:20.315164.315164 lmp.py:407] 
DEBUG 01-06 17:11:20.315164.315164 lmp.py:407]   Expert ID | Tokens | Device
DEBUG 01-06 17:11:20.315953.315953 lmp.py:408]   -----------------------------------
DEBUG 01-06 17:11:20.315033.315033 lmp.py:414]   Expert 19 |     21 | CPU
DEBUG 01-06 17:11:20.315107.315107 lmp.py:414]   Expert 42 |     24 | CPU
DEBUG 01-06 17:11:20.315988.315988 lmp.py:414]   Expert 30 |     26 | CPU
DEBUG 01-06 17:11:20.315393.315393 lmp.py:414]   Expert 32 |     43 | CPU
DEBUG 01-06 17:11:20.315559.315559 lmp.py:414]   Expert  6 |     48 | CPU
DEBUG 01-06 17:11:20.315725.315725 lmp.py:414]   Expert 53 |     69 | CPU
DEBUG 01-06 17:11:20.315891.315891 lmp.py:414]   Expert  1 |     78 | CPU
DEBUG 01-06 17:11:20.315057.315057 lmp.py:414]   Expert  5 |     78 | CPU
DEBUG 01-06 17:11:20.315654.315654 lmp.py:414]   Expert 13 |    108 | CPU
DEBUG 01-06 17:11:20.315012.315012 lmp.py:414]   Expert  9 |    114 | CPU
DEBUG 01-06 17:11:20.315609.315609 lmp.py:414]   Expert 58 |    126 | CPU
DEBUG 01-06 17:11:20.315205.315205 lmp.py:414]   Expert 50 |    127 | CPU
DEBUG 01-06 17:11:20.315848.315848 lmp.py:414]   Expert 34 |    128 | CPU
DEBUG 01-06 17:11:20.315776.315776 lmp.py:414]   Expert 59 |    132 | CPU
DEBUG 01-06 17:11:20.315704.315704 lmp.py:414]   Expert 26 |    133 | CPU
DEBUG 01-06 17:11:20.315108.315108 lmp.py:414]   Expert 31 |    133 | CPU
DEBUG 01-06 17:11:20.315274.315274 lmp.py:414]   Expert 63 |    137 | CPU
DEBUG 01-06 17:11:20.315441.315441 lmp.py:414]   Expert 40 |    141 | CPU
DEBUG 01-06 17:11:20.315368.315368 lmp.py:414]   Expert 12 |    143 | CPU
DEBUG 01-06 17:11:20.315534.315534 lmp.py:414]   Expert 56 |    143 | CPU
DEBUG 01-06 17:11:20.315462.315462 lmp.py:414]   Expert 46 |    144 | CPU
DEBUG 01-06 17:11:20.315151.315151 lmp.py:414]   Expert  4 |    147 | CPU
DEBUG 01-06 17:11:20.315510.315510 lmp.py:414]   Expert 11 |    152 | CPU
DEBUG 01-06 17:11:20.315630.315630 lmp.py:414]   Expert 48 |    152 | CPU
DEBUG 01-06 17:11:20.315749.315749 lmp.py:414]   Expert  2 |    155 | CPU
DEBUG 01-06 17:11:20.315631.315631 lmp.py:414]   Expert 33 |    155 | CPU
DEBUG 01-06 17:11:20.315797.315797 lmp.py:414]   Expert 20 |    156 | CPU
DEBUG 01-06 17:11:20.315963.315963 lmp.py:414]   Expert 18 |    157 | CPU
DEBUG 01-06 17:11:20.315129.315129 lmp.py:414]   Expert 61 |    161 | CPU
DEBUG 01-06 17:11:20.315295.315295 lmp.py:414]   Expert 10 |    165 | CPU
DEBUG 01-06 17:11:20.315985.315985 lmp.py:414]   Expert 55 |    167 | CPU
DEBUG 01-06 17:11:20.315912.315912 lmp.py:414]   Expert 35 |    168 | CPU
DEBUG 01-06 17:11:20.315078.315078 lmp.py:414]   Expert  8 |    173 | GPU
DEBUG 01-06 17:11:20.315245.315245 lmp.py:414]   Expert 36 |    174 | GPU
DEBUG 01-06 17:11:20.315411.315411 lmp.py:414]   Expert 51 |    182 | GPU
DEBUG 01-06 17:11:20.315054.315054 lmp.py:414]   Expert 52 |    185 | GPU
DEBUG 01-06 17:11:20.315412.315412 lmp.py:414]   Expert 37 |    195 | GPU
DEBUG 01-06 17:11:20.315055.315055 lmp.py:414]   Expert 57 |    201 | GPU
DEBUG 01-06 17:11:20.315652.315652 lmp.py:414]   Expert  0 |    207 | GPU
DEBUG 01-06 17:11:20.315056.315056 lmp.py:414]   Expert 39 |    218 | GPU
DEBUG 01-06 17:11:20.315984.315984 lmp.py:414]   Expert 62 |    231 | GPU
DEBUG 01-06 17:11:20.315912.315912 lmp.py:414]   Expert 25 |    233 | GPU
DEBUG 01-06 17:11:20.315078.315078 lmp.py:414]   Expert 28 |    247 | GPU
DEBUG 01-06 17:11:20.315244.315244 lmp.py:414]   Expert 16 |    250 | GPU
DEBUG 01-06 17:11:20.315410.315410 lmp.py:414]   Expert  7 |    252 | GPU
DEBUG 01-06 17:11:20.315576.315576 lmp.py:414]   Expert 38 |    252 | GPU
DEBUG 01-06 17:11:20.315504.315504 lmp.py:414]   Expert 49 |    257 | GPU
DEBUG 01-06 17:11:20.315147.315147 lmp.py:414]   Expert 24 |    258 | GPU
DEBUG 01-06 17:11:20.315505.315505 lmp.py:414]   Expert 27 |    258 | GPU
DEBUG 01-06 17:11:20.315386.315386 lmp.py:414]   Expert 60 |    258 | GPU
DEBUG 01-06 17:11:20.315745.315745 lmp.py:414]   Expert  3 |    260 | GPU
DEBUG 01-06 17:11:20.315434.315434 lmp.py:414]   Expert 21 |    264 | GPU
DEBUG 01-06 17:11:20.315123.315123 lmp.py:414]   Expert 29 |    271 | GPU
DEBUG 01-06 17:11:20.316051.316051 lmp.py:414]   Expert 43 |    271 | GPU
DEBUG 01-06 17:11:20.316979.316979 lmp.py:414]   Expert 22 |    286 | GPU
DEBUG 01-06 17:11:20.316668.316668 lmp.py:414]   Expert 23 |    286 | GPU
DEBUG 01-06 17:11:20.316357.316357 lmp.py:414]   Expert 15 |    291 | GPU
DEBUG 01-06 17:11:20.316808.316808 lmp.py:414]   Expert 41 |    297 | GPU
DEBUG 01-06 17:11:20.316736.316736 lmp.py:414]   Expert 44 |    297 | GPU
DEBUG 01-06 17:11:20.316379.316379 lmp.py:414]   Expert 47 |    300 | GPU
DEBUG 01-06 17:11:20.316260.316260 lmp.py:414]   Expert 54 |    364 | GPU
DEBUG 01-06 17:11:20.316142.316142 lmp.py:414]   Expert 14 |    372 | GPU
DEBUG 01-06 17:11:20.316261.316261 lmp.py:414]   Expert 17 |    417 | GPU
DEBUG 01-06 17:11:20.316428.316428 lmp.py:414]   Expert 45 |    450 | GPU
DEBUG 01-06 17:11:20.316071.316071 lmp.py:415] 
DEBUG 01-06 17:11:20.316071.316071 lmp.py:415]   CPU total tokens: 3831 (31.2%)
DEBUG 01-06 17:11:20.316429.316429 lmp.py:416]   GPU total tokens: 8457 (68.8%)
DEBUG 01-06 17:11:20.316363.316363 cuda_h.py:19] end experts_map_get cost 0.001566171646118164 seconds
DEBUG 01-06 17:11:20.316722.316722 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-06 17:11:20.316465.316465 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 17:11:20.316259.316259 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 17:11:20.317557.317557 cuda_h.py:19] end allocate_cuda_memory cost 0.0013422966003417969 seconds
DEBUG 01-06 17:11:20.317890.317890 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 17:11:20.317739.317739 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 17:11:20.317548.317548 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 17:11:20.318913.318913 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, c67cba28-e2bb-442e-a675-9fe94d96ce46
DEBUG 01-06 17:11:20.318555.318555 client.py:106] call stub.LoadModelAsync
INFO 01-06 17:11:20.319568.319568 client.py:127] Model loaded
DEBUG 01-06 17:11:20.319316.319316 cuda_h.py:19] end sllm_worker_task cost 0.011919260025024414 seconds
INFO 01-06 17:11:20.321431.321431 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, c67cba28-e2bb-442e-a675-9fe94d96ce46
DEBUG 01-06 17:11:20.321311.321311 cuda_h.py:19] end load_into_gpu_async cost 0.0034215450286865234 seconds
DEBUG 01-06 17:11:20.321565.321565 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 17:11:20.322235.322235 cuda_h.py:19] end restore_tensors2 cost 0.0007424354553222656 seconds
DEBUG 01-06 17:11:20.322786.322786 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.006004810333251953 seconds
DEBUG 01-06 17:11:20.325438.325438 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.008716583251953125 seconds
DEBUG 01-06 17:11:20.325129.325129 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-06 17:11:20.325615.325615 lmp.py:461] 
DEBUG 01-06 17:11:20.325615.325615 lmp.py:461]   Computing 32 experts on CPU...
DEBUG 01-06 17:11:20.325796.325796 cuda_h.py:19] end cpu_experts_submit cost 0.00011205673217773438 seconds
DEBUG 01-06 17:11:20.325545.325545 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-06 17:11:20.336714.336714 mlpmodule.py:706] group tensors cost 0.010777711868286133 s
DEBUG 01-06 17:11:20.338302.338302 mlpmodule.py:744] pad cost 0.0015993118286132812 s
DEBUG 01-06 17:11:20.338490.338490 mlpmodule.py:750] create cpu tensor cost 4.6253204345703125e-05 s
DEBUG 01-06 17:11:20.338393.338393 mlpmodule.py:755] move to cpu cost 3.2901763916015625e-05 s
DEBUG 01-06 17:11:20.348443.348443 mlpmodule.py:769] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-06 17:11:20.348440.348440 mlpmodule.py:770] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-06 17:11:20.349065.349065 mlpmodule.py:775] group_w3 first element: -0.0211181640625
WARNING 01-06 17:11:20.349698.349698 mlpmodule.py:785] start einsum2
DEBUG 01-06 17:11:20.367078.367078 mlpmodule.py:795] group einsum cost 0.02849555015563965 s
DEBUG 01-06 17:11:20.368317.368317 mlpmodule.py:803] cpy2cputensor cost 0.0006513595581054688 s
DEBUG 01-06 17:11:20.372231.372231 cuda_h.py:19] end wait_cetm_experts cost 0.04711318016052246 seconds
DEBUG 01-06 17:11:20.372767.372767 cuda_h.py:10] start gpu_sexperts
DEBUG 01-06 17:11:20.373498.373498 cuda_h.py:19] end gpu_sexperts cost 0.0006012916564941406 seconds
DEBUG 01-06 17:11:20.373341.373341 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-06 17:11:20.373906.373906 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.5033950805664062e-05 seconds
DEBUG 01-06 17:11:20.373085.373085 cuda_h.py:10] start wait_experts
INFO 01-06 17:11:20.373557.373557 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, c67cba28-e2bb-442e-a675-9fe94d96ce46
INFO 01-06 17:11:20.375051.375051 client.py:127] Model loaded
DEBUG 01-06 17:11:20.375940.375940 cuda_h.py:19] end wait_experts cost 0.0019690990447998047 seconds
DEBUG 01-06 17:11:20.375551.375551 cuda_h.py:10] start gpu_experts
DEBUG 01-06 17:11:20.375830.375830 lmp.py:506]   Computing 32 experts on GPU...
DEBUG 01-06 17:11:20.376325.376325 mlpmodule.py:533] gpu group tensors cost 0.0006654262542724609 s
DEBUG 01-06 17:11:20.378397.378397 mlpmodule.py:566] gpu pad cost 0.0018939971923828125 s
DEBUG 01-06 17:11:20.378188.378188 mlpmodule.py:584] gpu group einsum cost 0.000408172607421875 s
DEBUG 01-06 17:11:20.382188.382188 mlpmodule.py:613] gpu experts func einsum cost 0.006460905075073242 s
DEBUG 01-06 17:11:20.382463.382463 cuda_h.py:19] end gpu_experts cost 0.006647825241088867 seconds
DEBUG 01-06 17:11:20.382877.382877 cuda_h.py:19] end layer_moe_generate_13 cost 0.06827926635742188 seconds
DEBUG 01-06 17:11:20.382726.382726 lmp.py:220] -------------------------------- end layer 13 --------------------------------
DEBUG 01-06 17:11:20.382204.382204 lmp.py:176] -------------------------------- start layer 14 --------------------------------
DEBUG 01-06 17:11:20.382761.382761 cuda_h.py:10] start start_load_qkvogn_s_weight_l_15
DEBUG 01-06 17:11:20.382378.382378 cuda_h.py:10] start start_load_qkvogn_s_weight_l_15
DEBUG 01-06 17:11:20.382228.382228 cuda_h.py:19] end start_load_qkvogn_s_weight_l_15 cost 3.62396240234375e-05 seconds
DEBUG 01-06 17:11:20.382938.382938 cuda_h.py:19] end start_load_qkvogn_s_weight_l_15 cost 7.009506225585938e-05 seconds
DEBUG 01-06 17:11:20.382972.382972 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-06 17:11:20.382696.382696 mlpmodule.py:367] cuda:1 cuda:1
DEBUG 01-06 17:11:20.382281.382281 cuda_h.py:10] start sllm_worker_task
DEBUG 01-06 17:11:20.382019.382019 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 17:11:20.382372.382372 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 17:11:20.383755.383755 cuda_h.py:19] end allocate_cuda_memory cost 0.0003161430358886719 seconds
DEBUG 01-06 17:11:20.383527.383527 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 17:11:20.383250.383250 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 17:11:20.383218.383218 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 17:11:20.383683.383683 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, b943262a-32c1-4294-bf55-fe9b3f8f3081
DEBUG 01-06 17:11:20.383937.383937 client.py:106] call stub.LoadModelAsync
DEBUG 01-06 17:11:20.383841.383841 cuda_h.py:10] start self_attn
INFO 01-06 17:11:20.384664.384664 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, b943262a-32c1-4294-bf55-fe9b3f8f3081
DEBUG 01-06 17:11:20.385600.385600 cuda_h.py:19] end load_into_gpu_async cost 0.0015583038330078125 seconds
DEBUG 01-06 17:11:20.385873.385873 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 17:11:20.385108.385108 cuda_h.py:19] end restore_tensors2 cost 7.653236389160156e-05 seconds
DEBUG 01-06 17:11:20.385540.385540 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0022423267364501953 seconds
INFO 01-06 17:11:20.385621.385621 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, b943262a-32c1-4294-bf55-fe9b3f8f3081
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-06 17:11:20.386285.386285 cuda_h.py:19] end self_attn cost 0.002931356430053711 seconds
DEBUG 01-06 17:11:20.387892.387892 cuda_h.py:19] end iln_self_attn_paln cost 0.004505157470703125 seconds
DEBUG 01-06 17:11:20.387881.387881 cuda_h.py:10] start layer_moe_generate_14
DEBUG 01-06 17:11:20.387266.387266 cuda_h.py:10] start gate
DEBUG 01-06 17:11:20.388488.388488 cuda_h.py:19] end gate cost 0.0006570816040039062 seconds
DEBUG 01-06 17:11:20.388033.388033 cuda_h.py:10] start experts_map_get
DEBUG 01-06 17:11:20.388407.388407 lmp.py:403] 
DEBUG 01-06 17:11:20.388407.388407 lmp.py:403] Expert Token Distribution & Device Allocation:
DEBUG 01-06 17:11:20.388177.388177 lmp.py:404]   Total experts: 64
DEBUG 01-06 17:11:20.388641.388641 lmp.py:405]   CPU experts: 32 (50%)
DEBUG 01-06 17:11:20.388337.388337 lmp.py:406]   GPU experts: 32 (50%)
DEBUG 01-06 17:11:20.388742.388742 lmp.py:407] 
DEBUG 01-06 17:11:20.388742.388742 lmp.py:407]   Expert ID | Tokens | Device
DEBUG 01-06 17:11:20.388146.388146 lmp.py:408]   -----------------------------------
DEBUG 01-06 17:11:20.388227.388227 lmp.py:414]   Expert  7 |     31 | CPU
DEBUG 01-06 17:11:20.388108.388108 lmp.py:414]   Expert 34 |     32 | CPU
DEBUG 01-06 17:11:20.388897.388897 lmp.py:414]   Expert 13 |     43 | CPU
DEBUG 01-06 17:11:20.388162.388162 lmp.py:414]   Expert 54 |     76 | CPU
DEBUG 01-06 17:11:20.388521.388521 lmp.py:414]   Expert 39 |     83 | CPU
DEBUG 01-06 17:11:20.388925.388925 lmp.py:414]   Expert 18 |     85 | CPU
DEBUG 01-06 17:11:20.388045.388045 lmp.py:414]   Expert 49 |     85 | CPU
DEBUG 01-06 17:11:20.388688.388688 lmp.py:414]   Expert 59 |     98 | CPU
DEBUG 01-06 17:11:20.388285.388285 lmp.py:414]   Expert 16 |    101 | CPU
DEBUG 01-06 17:11:20.388689.388689 lmp.py:414]   Expert 21 |    102 | CPU
DEBUG 01-06 17:11:20.388286.388286 lmp.py:414]   Expert  0 |    106 | CPU
DEBUG 01-06 17:11:20.388452.388452 lmp.py:414]   Expert 41 |    119 | CPU
DEBUG 01-06 17:11:20.388572.388572 lmp.py:414]   Expert 45 |    119 | CPU
DEBUG 01-06 17:11:20.388738.388738 lmp.py:414]   Expert 15 |    122 | CPU
DEBUG 01-06 17:11:20.388381.388381 lmp.py:414]   Expert 22 |    122 | CPU
DEBUG 01-06 17:11:20.388070.388070 lmp.py:414]   Expert 17 |    125 | CPU
DEBUG 01-06 17:11:20.388952.388952 lmp.py:414]   Expert 61 |    127 | CPU
DEBUG 01-06 17:11:20.388641.388641 lmp.py:414]   Expert 52 |    130 | CPU
DEBUG 01-06 17:11:20.388284.388284 lmp.py:414]   Expert  8 |    131 | CPU
DEBUG 01-06 17:11:20.388212.388212 lmp.py:414]   Expert 35 |    139 | CPU
DEBUG 01-06 17:11:20.388855.388855 lmp.py:414]   Expert 48 |    141 | CPU
DEBUG 01-06 17:11:20.388544.388544 lmp.py:414]   Expert 12 |    145 | CPU
DEBUG 01-06 17:11:20.388379.388379 lmp.py:414]   Expert 38 |    145 | CPU
DEBUG 01-06 17:11:20.388783.388783 lmp.py:414]   Expert 53 |    151 | CPU
DEBUG 01-06 17:11:20.388619.388619 lmp.py:414]   Expert 50 |    153 | CPU
DEBUG 01-06 17:11:20.388262.388262 lmp.py:414]   Expert 36 |    159 | CPU
DEBUG 01-06 17:11:20.388381.388381 lmp.py:414]   Expert 60 |    161 | CPU
DEBUG 01-06 17:11:20.388071.388071 lmp.py:414]   Expert 40 |    162 | CPU
DEBUG 01-06 17:11:20.389952.389952 lmp.py:414]   Expert 31 |    164 | CPU
DEBUG 01-06 17:11:20.389641.389641 lmp.py:414]   Expert 27 |    174 | CPU
DEBUG 01-06 17:11:20.389523.389523 lmp.py:414]   Expert 19 |    189 | CPU
DEBUG 01-06 17:11:20.389689.389689 lmp.py:414]   Expert  4 |    203 | CPU
DEBUG 01-06 17:11:20.389809.389809 lmp.py:414]   Expert 29 |    204 | GPU
DEBUG 01-06 17:11:20.389975.389975 lmp.py:414]   Expert 30 |    210 | GPU
DEBUG 01-06 17:11:20.389333.389333 lmp.py:414]   Expert 20 |    219 | GPU
DEBUG 01-06 17:11:20.389738.389738 lmp.py:414]   Expert  6 |    225 | GPU
DEBUG 01-06 17:11:20.389857.389857 lmp.py:414]   Expert 11 |    225 | GPU
DEBUG 01-06 17:11:20.389977.389977 lmp.py:414]   Expert 43 |    228 | GPU
DEBUG 01-06 17:11:20.389097.389097 lmp.py:414]   Expert 57 |    228 | GPU
DEBUG 01-06 17:11:20.389786.389786 lmp.py:414]   Expert 26 |    230 | GPU
DEBUG 01-06 17:11:20.389668.389668 lmp.py:414]   Expert 33 |    231 | GPU
DEBUG 01-06 17:11:20.389595.389595 lmp.py:414]   Expert 46 |    232 | GPU
DEBUG 01-06 17:11:20.389477.389477 lmp.py:414]   Expert 42 |    241 | GPU
DEBUG 01-06 17:11:20.389405.389405 lmp.py:414]   Expert  2 |    242 | GPU
DEBUG 01-06 17:11:20.389048.389048 lmp.py:414]   Expert 55 |    243 | GPU
DEBUG 01-06 17:11:20.389167.389167 lmp.py:414]   Expert 23 |    249 | GPU
DEBUG 01-06 17:11:20.389764.389764 lmp.py:414]   Expert 56 |    252 | GPU
DEBUG 01-06 17:11:20.389930.389930 lmp.py:414]   Expert 32 |    256 | GPU
DEBUG 01-06 17:11:20.389527.389527 lmp.py:414]   Expert 28 |    257 | GPU
DEBUG 01-06 17:11:20.389455.389455 lmp.py:414]   Expert  9 |    261 | GPU
DEBUG 01-06 17:11:20.389097.389097 lmp.py:414]   Expert 44 |    266 | GPU
DEBUG 01-06 17:11:20.389025.389025 lmp.py:414]   Expert  1 |    274 | GPU
DEBUG 01-06 17:11:20.389907.389907 lmp.py:414]   Expert  3 |    277 | GPU
DEBUG 01-06 17:11:20.389357.389357 lmp.py:414]   Expert 51 |    278 | GPU
DEBUG 01-06 17:11:20.389477.389477 lmp.py:414]   Expert 14 |    282 | GPU
DEBUG 01-06 17:11:20.389690.389690 lmp.py:414]   Expert 58 |    283 | GPU
DEBUG 01-06 17:11:20.389333.389333 lmp.py:414]   Expert 62 |    287 | GPU
DEBUG 01-06 17:11:20.389784.389784 lmp.py:414]   Expert 47 |    288 | GPU
DEBUG 01-06 17:11:20.389903.389903 lmp.py:414]   Expert 37 |    290 | GPU
DEBUG 01-06 17:11:20.389070.389070 lmp.py:414]   Expert 63 |    297 | GPU
DEBUG 01-06 17:11:20.389428.389428 lmp.py:414]   Expert 24 |    312 | GPU
DEBUG 01-06 17:11:20.389071.389071 lmp.py:414]   Expert 25 |    312 | GPU
DEBUG 01-06 17:11:20.389191.389191 lmp.py:414]   Expert 10 |    314 | GPU
DEBUG 01-06 17:11:20.389880.389880 lmp.py:414]   Expert  5 |    372 | GPU
DEBUG 01-06 17:11:20.389238.389238 lmp.py:415] 
DEBUG 01-06 17:11:20.389238.389238 lmp.py:415]   CPU total tokens: 3923 (31.9%)
DEBUG 01-06 17:11:20.389643.389643 lmp.py:416]   GPU total tokens: 8365 (68.1%)
DEBUG 01-06 17:11:20.389246.389246 cuda_h.py:19] end experts_map_get cost 0.0015952587127685547 seconds
DEBUG 01-06 17:11:20.389128.389128 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-06 17:11:20.389341.389341 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 17:11:20.389677.389677 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 17:11:20.391122.391122 cuda_h.py:19] end allocate_cuda_memory cost 0.0013818740844726562 seconds
DEBUG 01-06 17:11:20.391277.391277 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 17:11:20.391940.391940 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 17:11:20.391994.391994 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 17:11:20.391313.391313 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, fc5c7516-1eee-4559-8943-70d5c389d192
DEBUG 01-06 17:11:20.391154.391154 client.py:106] call stub.LoadModelAsync
DEBUG 01-06 17:11:20.391828.391828 mlpmodule.py:664]  experts func einsum cost 0.06643390655517578 s
INFO 01-06 17:11:20.393177.393177 client.py:127] Model loaded
DEBUG 01-06 17:11:20.393885.393885 cuda_h.py:19] end sllm_worker_task cost 0.01082158088684082 seconds
INFO 01-06 17:11:20.394088.394088 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, fc5c7516-1eee-4559-8943-70d5c389d192
DEBUG 01-06 17:11:20.394160.394160 cuda_h.py:19] end load_into_gpu_async cost 0.0033736228942871094 seconds
DEBUG 01-06 17:11:20.394699.394699 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 17:11:20.395380.395380 cuda_h.py:19] end restore_tensors2 cost 0.0005078315734863281 seconds
DEBUG 01-06 17:11:20.395263.395263 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.00574803352355957 seconds
DEBUG 01-06 17:11:20.398928.398928 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.008462667465209961 seconds
DEBUG 01-06 17:11:20.398142.398142 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-06 17:11:20.398582.398582 lmp.py:461] 
DEBUG 01-06 17:11:20.398582.398582 lmp.py:461]   Computing 32 experts on CPU...
DEBUG 01-06 17:11:20.398001.398001 cuda_h.py:19] end cpu_experts_submit cost 0.00011420249938964844 seconds
DEBUG 01-06 17:11:20.398412.398412 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-06 17:11:20.403571.403571 mlpmodule.py:706] group tensors cost 0.005324840545654297 s
DEBUG 01-06 17:11:20.406492.406492 mlpmodule.py:744] pad cost 0.0017278194427490234 s
DEBUG 01-06 17:11:20.406702.406702 mlpmodule.py:750] create cpu tensor cost 4.982948303222656e-05 s
DEBUG 01-06 17:11:20.406611.406611 mlpmodule.py:755] move to cpu cost 3.2901763916015625e-05 s
DEBUG 01-06 17:11:20.417096.417096 mlpmodule.py:769] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-06 17:11:20.417153.417153 mlpmodule.py:770] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-06 17:11:20.418294.418294 mlpmodule.py:775] group_w3 first element: 0.000789642333984375
WARNING 01-06 17:11:20.418305.418305 mlpmodule.py:785] start einsum2
DEBUG 01-06 17:11:20.439622.439622 mlpmodule.py:795] group einsum cost 0.03286123275756836 s
DEBUG 01-06 17:11:20.440843.440843 mlpmodule.py:803] cpy2cputensor cost 0.0008778572082519531 s
DEBUG 01-06 17:11:20.445187.445187 cuda_h.py:19] end wait_cetm_experts cost 0.04659271240234375 seconds
DEBUG 01-06 17:11:20.445915.445915 cuda_h.py:10] start gpu_sexperts
DEBUG 01-06 17:11:20.445944.445944 cuda_h.py:19] end gpu_sexperts cost 0.0006103515625 seconds
DEBUG 01-06 17:11:20.445078.445078 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-06 17:11:20.446074.446074 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.6464462280273438e-05 seconds
DEBUG 01-06 17:11:20.446969.446969 cuda_h.py:10] start wait_experts
INFO 01-06 17:11:20.446394.446394 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, fc5c7516-1eee-4559-8943-70d5c389d192
INFO 01-06 17:11:20.447224.447224 client.py:127] Model loaded
DEBUG 01-06 17:11:20.447458.447458 cuda_h.py:19] end wait_experts cost 0.0017344951629638672 seconds
DEBUG 01-06 17:11:20.447168.447168 cuda_h.py:10] start gpu_experts
DEBUG 01-06 17:11:20.447547.447547 lmp.py:506]   Computing 32 experts on GPU...
DEBUG 01-06 17:11:20.448731.448731 mlpmodule.py:533] gpu group tensors cost 0.0006759166717529297 s
DEBUG 01-06 17:11:20.450940.450940 mlpmodule.py:566] gpu pad cost 0.0018146038055419922 s
DEBUG 01-06 17:11:20.451619.451619 mlpmodule.py:584] gpu group einsum cost 0.0006082057952880859 s
DEBUG 01-06 17:11:20.453619.453619 mlpmodule.py:664]  experts func einsum cost 0.05524611473083496 s
DEBUG 01-06 17:11:20.455477.455477 mlpmodule.py:613] gpu experts func einsum cost 0.007111072540283203 s
DEBUG 01-06 17:11:20.455537.455537 cuda_h.py:19] end gpu_experts cost 0.00743556022644043 seconds
DEBUG 01-06 17:11:20.455382.455382 cuda_h.py:19] end layer_moe_generate_14 cost 0.06813883781433105 seconds
DEBUG 01-06 17:11:20.455885.455885 lmp.py:220] -------------------------------- end layer 14 --------------------------------
DEBUG 01-06 17:11:20.455462.455462 lmp.py:176] -------------------------------- start layer 15 --------------------------------
DEBUG 01-06 17:11:20.455397.455397 cuda_h.py:10] start start_load_qkvogn_s_weight_l_16
DEBUG 01-06 17:11:20.455822.455822 cuda_h.py:10] start start_load_qkvogn_s_weight_l_16
DEBUG 01-06 17:11:20.455665.455665 cuda_h.py:19] end start_load_qkvogn_s_weight_l_16 cost 3.314018249511719e-05 seconds
DEBUG 01-06 17:11:20.455322.455322 cuda_h.py:19] end start_load_qkvogn_s_weight_l_16 cost 6.413459777832031e-05 seconds
DEBUG 01-06 17:11:20.455349.455349 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-06 17:11:20.455145.455145 cuda_h.py:10] start sllm_worker_task
DEBUG 01-06 17:11:20.456389.456389 mlpmodule.py:367] cuda:1 cuda:1
DEBUG 01-06 17:11:20.456066.456066 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 17:11:20.456599.456599 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 17:11:20.456149.456149 cuda_h.py:19] end allocate_cuda_memory cost 0.00035500526428222656 seconds
DEBUG 01-06 17:11:20.456458.456458 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 17:11:20.456234.456234 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 17:11:20.456402.456402 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 17:11:20.456780.456780 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, e78e2a11-83f8-4b4f-8668-0f6760c72c95
DEBUG 01-06 17:11:20.456876.456876 client.py:106] call stub.LoadModelAsync
DEBUG 01-06 17:11:20.457375.457375 cuda_h.py:10] start self_attn
INFO 01-06 17:11:20.458376.458376 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, e78e2a11-83f8-4b4f-8668-0f6760c72c95
DEBUG 01-06 17:11:20.458219.458219 cuda_h.py:19] end load_into_gpu_async cost 0.0017108917236328125 seconds
DEBUG 01-06 17:11:20.458968.458968 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 17:11:20.458203.458203 cuda_h.py:19] end restore_tensors2 cost 7.605552673339844e-05 seconds
DEBUG 01-06 17:11:20.458198.458198 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0024640560150146484 seconds
INFO 01-06 17:11:20.458126.458126 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, e78e2a11-83f8-4b4f-8668-0f6760c72c95
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-06 17:11:20.460852.460852 cuda_h.py:19] end self_attn cost 0.0028839111328125 seconds
DEBUG 01-06 17:11:20.460048.460048 cuda_h.py:19] end iln_self_attn_paln cost 0.0046291351318359375 seconds
DEBUG 01-06 17:11:20.460176.460176 cuda_h.py:10] start layer_moe_generate_15
DEBUG 01-06 17:11:20.460607.460607 cuda_h.py:10] start gate
DEBUG 01-06 17:11:20.461147.461147 cuda_h.py:19] end gate cost 0.0006439685821533203 seconds
DEBUG 01-06 17:11:20.461976.461976 cuda_h.py:10] start experts_map_get
DEBUG 01-06 17:11:20.461622.461622 lmp.py:403] 
DEBUG 01-06 17:11:20.461622.461622 lmp.py:403] Expert Token Distribution & Device Allocation:
DEBUG 01-06 17:11:20.461186.461186 lmp.py:404]   Total experts: 64
DEBUG 01-06 17:11:20.461551.461551 lmp.py:405]   CPU experts: 32 (50%)
DEBUG 01-06 17:11:20.461863.461863 lmp.py:406]   GPU experts: 32 (50%)
DEBUG 01-06 17:11:20.461552.461552 lmp.py:407] 
DEBUG 01-06 17:11:20.461552.461552 lmp.py:407]   Expert ID | Tokens | Device
DEBUG 01-06 17:11:20.461957.461957 lmp.py:408]   -----------------------------------
DEBUG 01-06 17:11:20.461322.461322 lmp.py:414]   Expert 15 |     56 | CPU
DEBUG 01-06 17:11:20.461965.461965 lmp.py:414]   Expert 41 |     62 | CPU
DEBUG 01-06 17:11:20.461654.461654 lmp.py:414]   Expert 63 |     67 | CPU
DEBUG 01-06 17:11:20.461866.461866 lmp.py:414]   Expert 20 |     81 | CPU
DEBUG 01-06 17:11:20.461079.461079 lmp.py:414]   Expert  0 |     83 | CPU
DEBUG 01-06 17:11:20.461768.461768 lmp.py:414]   Expert 45 |     90 | CPU
DEBUG 01-06 17:11:20.461981.461981 lmp.py:414]   Expert  7 |     95 | CPU
DEBUG 01-06 17:11:20.461716.461716 lmp.py:414]   Expert 54 |     98 | CPU
DEBUG 01-06 17:11:20.461690.461690 lmp.py:414]   Expert 28 |    100 | CPU
DEBUG 01-06 17:11:20.461141.461141 lmp.py:414]   Expert 12 |    114 | CPU
DEBUG 01-06 17:11:20.461354.461354 lmp.py:414]   Expert  5 |    120 | CPU
DEBUG 01-06 17:11:20.461566.461566 lmp.py:414]   Expert 40 |    120 | CPU
DEBUG 01-06 17:11:20.461017.461017 lmp.py:414]   Expert 34 |    121 | CPU
DEBUG 01-06 17:11:20.461753.461753 lmp.py:414]   Expert 52 |    123 | CPU
DEBUG 01-06 17:11:20.461250.461250 lmp.py:414]   Expert 59 |    123 | CPU
DEBUG 01-06 17:11:20.461654.461654 lmp.py:414]   Expert  4 |    127 | CPU
DEBUG 01-06 17:11:20.462344.462344 lmp.py:414]   Expert 21 |    133 | CPU
DEBUG 01-06 17:11:20.462794.462794 lmp.py:414]   Expert 55 |    134 | CPU
DEBUG 01-06 17:11:20.462245.462245 lmp.py:414]   Expert 13 |    136 | CPU
DEBUG 01-06 17:11:20.462173.462173 lmp.py:414]   Expert 61 |    137 | CPU
DEBUG 01-06 17:11:20.462624.462624 lmp.py:414]   Expert 62 |    137 | CPU
DEBUG 01-06 17:11:20.462320.462320 lmp.py:414]   Expert 42 |    143 | CPU
DEBUG 01-06 17:11:20.462486.462486 lmp.py:414]   Expert 14 |    146 | CPU
DEBUG 01-06 17:11:20.462175.462175 lmp.py:414]   Expert 22 |    148 | CPU
DEBUG 01-06 17:11:20.462103.462103 lmp.py:414]   Expert 10 |    149 | CPU
DEBUG 01-06 17:11:20.462554.462554 lmp.py:414]   Expert 50 |    161 | CPU
DEBUG 01-06 17:11:20.462767.462767 lmp.py:414]   Expert 51 |    164 | CPU
DEBUG 01-06 17:11:20.462502.462502 lmp.py:414]   Expert 25 |    166 | CPU
DEBUG 01-06 17:11:20.462999.462999 lmp.py:414]   Expert 53 |    166 | CPU
DEBUG 01-06 17:11:20.462735.462735 lmp.py:414]   Expert 32 |    168 | CPU
DEBUG 01-06 17:11:20.462471.462471 lmp.py:414]   Expert 26 |    177 | CPU
DEBUG 01-06 17:11:20.462206.462206 lmp.py:414]   Expert  2 |    178 | CPU
DEBUG 01-06 17:11:20.462703.462703 lmp.py:414]   Expert 47 |    178 | GPU
DEBUG 01-06 17:11:20.462439.462439 lmp.py:414]   Expert 19 |    180 | GPU
DEBUG 01-06 17:11:20.462128.462128 lmp.py:414]   Expert  6 |    182 | GPU
DEBUG 01-06 17:11:20.462818.462818 lmp.py:414]   Expert 35 |    182 | GPU
DEBUG 01-06 17:11:20.462269.462269 lmp.py:414]   Expert  1 |    184 | GPU
DEBUG 01-06 17:11:20.462481.462481 lmp.py:414]   Expert 57 |    186 | GPU
DEBUG 01-06 17:11:20.462693.462693 lmp.py:414]   Expert 30 |    190 | GPU
DEBUG 01-06 17:11:20.462429.462429 lmp.py:414]   Expert 11 |    192 | GPU
DEBUG 01-06 17:11:20.462165.462165 lmp.py:414]   Expert 56 |    197 | GPU
DEBUG 01-06 17:11:20.462900.462900 lmp.py:414]   Expert 48 |    205 | GPU
DEBUG 01-06 17:11:20.462398.462398 lmp.py:414]   Expert 39 |    212 | GPU
DEBUG 01-06 17:11:20.462372.462372 lmp.py:414]   Expert 24 |    213 | GPU
DEBUG 01-06 17:11:20.462869.462869 lmp.py:414]   Expert 16 |    214 | GPU
DEBUG 01-06 17:11:20.462604.462604 lmp.py:414]   Expert 46 |    214 | GPU
DEBUG 01-06 17:11:20.462578.462578 lmp.py:414]   Expert 44 |    215 | GPU
DEBUG 01-06 17:11:20.462314.462314 lmp.py:414]   Expert 29 |    230 | GPU
DEBUG 01-06 17:11:20.462527.462527 lmp.py:414]   Expert 18 |    232 | GPU
DEBUG 01-06 17:11:20.462262.462262 lmp.py:414]   Expert 37 |    235 | GPU
DEBUG 01-06 17:11:20.462475.462475 lmp.py:414]   Expert 31 |    253 | GPU
DEBUG 01-06 17:11:20.462926.462926 lmp.py:414]   Expert 36 |    256 | GPU
DEBUG 01-06 17:11:20.462376.462376 lmp.py:414]   Expert 17 |    258 | GPU
DEBUG 01-06 17:11:20.462350.462350 lmp.py:414]   Expert 38 |    259 | GPU
DEBUG 01-06 17:11:20.462086.462086 lmp.py:414]   Expert  3 |    260 | GPU
DEBUG 01-06 17:11:20.462822.462822 lmp.py:414]   Expert  9 |    260 | GPU
DEBUG 01-06 17:11:20.462557.462557 lmp.py:414]   Expert 60 |    263 | GPU
DEBUG 01-06 17:11:20.462293.462293 lmp.py:414]   Expert 23 |    267 | GPU
DEBUG 01-06 17:11:20.462790.462790 lmp.py:414]   Expert 43 |    351 | GPU
DEBUG 01-06 17:11:20.462764.462764 lmp.py:414]   Expert 27 |    363 | GPU
DEBUG 01-06 17:11:20.462215.462215 lmp.py:414]   Expert 33 |    390 | GPU
DEBUG 01-06 17:11:20.462904.462904 lmp.py:414]   Expert  8 |    441 | GPU
DEBUG 01-06 17:11:20.462594.462594 lmp.py:414]   Expert 58 |    446 | GPU
DEBUG 01-06 17:11:20.462283.462283 lmp.py:414]   Expert 49 |    557 | GPU
DEBUG 01-06 17:11:20.462211.462211 lmp.py:415] 
DEBUG 01-06 17:11:20.462211.462211 lmp.py:415]   CPU total tokens: 4023 (32.7%)
DEBUG 01-06 17:11:20.462138.462138 lmp.py:416]   GPU total tokens: 8265 (67.3%)
DEBUG 01-06 17:11:20.462119.462119 cuda_h.py:19] end experts_map_get cost 0.001482248306274414 seconds
DEBUG 01-06 17:11:20.462285.462285 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-06 17:11:20.462969.462969 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 17:11:20.463252.463252 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 17:11:20.464821.464821 cuda_h.py:19] end allocate_cuda_memory cost 0.001720428466796875 seconds
DEBUG 01-06 17:11:20.464194.464194 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 17:11:20.464188.464188 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 17:11:20.464143.464143 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 17:11:20.464985.464985 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, f93d3e6a-7bdc-464e-9804-bafb8a47171a
DEBUG 01-06 17:11:20.465826.465826 client.py:106] call stub.LoadModelAsync
INFO 01-06 17:11:20.466588.466588 client.py:127] Model loaded
DEBUG 01-06 17:11:20.466329.466329 cuda_h.py:19] end sllm_worker_task cost 0.01083993911743164 seconds
INFO 01-06 17:11:20.468112.468112 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, f93d3e6a-7bdc-464e-9804-bafb8a47171a
DEBUG 01-06 17:11:20.468945.468945 cuda_h.py:19] end load_into_gpu_async cost 0.003419160842895508 seconds
DEBUG 01-06 17:11:20.468797.468797 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 17:11:20.469592.469592 cuda_h.py:19] end restore_tensors2 cost 0.0005552768707275391 seconds
DEBUG 01-06 17:11:20.469475.469475 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.006179094314575195 seconds
DEBUG 01-06 17:11:20.471993.471993 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.008852958679199219 seconds
DEBUG 01-06 17:11:20.471300.471300 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-06 17:11:20.471355.471355 lmp.py:461] 
DEBUG 01-06 17:11:20.471355.471355 lmp.py:461]   Computing 32 experts on CPU...
DEBUG 01-06 17:11:20.471298.471298 cuda_h.py:19] end cpu_experts_submit cost 0.00011110305786132812 seconds
DEBUG 01-06 17:11:20.471186.471186 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-06 17:11:20.478847.478847 mlpmodule.py:706] group tensors cost 0.00590205192565918 s
DEBUG 01-06 17:11:20.480614.480614 mlpmodule.py:744] pad cost 0.0016009807586669922 s
DEBUG 01-06 17:11:20.480076.480076 mlpmodule.py:750] create cpu tensor cost 4.9114227294921875e-05 s
DEBUG 01-06 17:11:20.480363.480363 mlpmodule.py:755] move to cpu cost 3.504753112792969e-05 s
DEBUG 01-06 17:11:20.491731.491731 mlpmodule.py:769] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-06 17:11:20.492841.492841 mlpmodule.py:770] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-06 17:11:20.492301.492301 mlpmodule.py:775] group_w3 first element: -0.0595703125
WARNING 01-06 17:11:20.492086.492086 mlpmodule.py:785] start einsum2
DEBUG 01-06 17:11:20.509404.509404 mlpmodule.py:795] group einsum cost 0.029244661331176758 s
DEBUG 01-06 17:11:20.510236.510236 mlpmodule.py:803] cpy2cputensor cost 0.0007107257843017578 s
DEBUG 01-06 17:11:20.515767.515767 cuda_h.py:19] end wait_cetm_experts cost 0.04318547248840332 seconds
DEBUG 01-06 17:11:20.515780.515780 cuda_h.py:10] start gpu_sexperts
DEBUG 01-06 17:11:20.516795.516795 cuda_h.py:19] end gpu_sexperts cost 0.0005996227264404297 seconds
DEBUG 01-06 17:11:20.516068.516068 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-06 17:11:20.516793.516793 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.4318695068359375e-05 seconds
DEBUG 01-06 17:11:20.516403.516403 cuda_h.py:10] start wait_experts
INFO 01-06 17:11:20.516643.516643 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, f93d3e6a-7bdc-464e-9804-bafb8a47171a
INFO 01-06 17:11:20.522125.522125 client.py:127] Model loaded
DEBUG 01-06 17:11:20.522558.522558 cuda_h.py:19] end wait_experts cost 0.006574392318725586 seconds
DEBUG 01-06 17:11:20.522122.522122 cuda_h.py:10] start gpu_experts
DEBUG 01-06 17:11:20.522077.522077 lmp.py:506]   Computing 32 experts on GPU...
DEBUG 01-06 17:11:20.523389.523389 mlpmodule.py:664]  experts func einsum cost 0.051377058029174805 s
DEBUG 01-06 17:11:20.523026.523026 mlpmodule.py:533] gpu group tensors cost 0.0007369518280029297 s
DEBUG 01-06 17:11:20.525810.525810 mlpmodule.py:566] gpu pad cost 0.001766204833984375 s
DEBUG 01-06 17:11:20.526318.526318 mlpmodule.py:584] gpu group einsum cost 0.00041985511779785156 s
DEBUG 01-06 17:11:20.529231.529231 mlpmodule.py:613] gpu experts func einsum cost 0.0060994625091552734 s
DEBUG 01-06 17:11:20.529455.529455 cuda_h.py:19] end gpu_experts cost 0.006356954574584961 seconds
DEBUG 01-06 17:11:20.529716.529716 cuda_h.py:19] end layer_moe_generate_15 cost 0.06873059272766113 seconds
DEBUG 01-06 17:11:20.529809.529809 lmp.py:220] -------------------------------- end layer 15 --------------------------------
DEBUG 01-06 17:11:20.529102.529102 lmp.py:176] -------------------------------- start layer 16 --------------------------------
DEBUG 01-06 17:11:20.529798.529798 cuda_h.py:10] start start_load_qkvogn_s_weight_l_17
DEBUG 01-06 17:11:20.529031.529031 cuda_h.py:10] start start_load_qkvogn_s_weight_l_17
DEBUG 01-06 17:11:20.529066.529066 cuda_h.py:19] end start_load_qkvogn_s_weight_l_17 cost 3.24249267578125e-05 seconds
DEBUG 01-06 17:11:20.529292.529292 cuda_h.py:19] end start_load_qkvogn_s_weight_l_17 cost 6.461143493652344e-05 seconds
DEBUG 01-06 17:11:20.529174.529174 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-06 17:11:20.529454.529454 mlpmodule.py:367] cuda:1 cuda:1
DEBUG 01-06 17:11:20.529132.529132 cuda_h.py:10] start sllm_worker_task
DEBUG 01-06 17:11:20.529036.529036 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 17:11:20.530734.530734 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 17:11:20.530408.530408 cuda_h.py:19] end allocate_cuda_memory cost 0.00032019615173339844 seconds
DEBUG 01-06 17:11:20.530517.530517 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 17:11:20.530279.530279 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 17:11:20.530910.530910 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 17:11:20.530467.530467 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, a9545638-68a0-49d3-97b2-cba2a9e23f74
DEBUG 01-06 17:11:20.530576.530576 client.py:106] call stub.LoadModelAsync
DEBUG 01-06 17:11:20.530689.530689 cuda_h.py:10] start self_attn
INFO 01-06 17:11:20.532616.532616 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, a9545638-68a0-49d3-97b2-cba2a9e23f74
DEBUG 01-06 17:11:20.532975.532975 cuda_h.py:19] end load_into_gpu_async cost 0.0016016960144042969 seconds
DEBUG 01-06 17:11:20.532294.532294 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 17:11:20.532860.532860 cuda_h.py:19] end restore_tensors2 cost 7.486343383789062e-05 seconds
DEBUG 01-06 17:11:20.532663.532663 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0022509098052978516 seconds
INFO 01-06 17:11:20.532022.532022 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, a9545638-68a0-49d3-97b2-cba2a9e23f74
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-06 17:11:20.533848.533848 cuda_h.py:19] end self_attn cost 0.002898693084716797 seconds
DEBUG 01-06 17:11:20.534011.534011 cuda_h.py:19] end iln_self_attn_paln cost 0.004416465759277344 seconds
DEBUG 01-06 17:11:20.534947.534947 cuda_h.py:10] start layer_moe_generate_16
DEBUG 01-06 17:11:20.534140.534140 cuda_h.py:10] start gate
DEBUG 01-06 17:11:20.534408.534408 cuda_h.py:19] end gate cost 0.0006558895111083984 seconds
DEBUG 01-06 17:11:20.535238.535238 cuda_h.py:10] start experts_map_get
DEBUG 01-06 17:11:20.535976.535976 lmp.py:403] 
DEBUG 01-06 17:11:20.535976.535976 lmp.py:403] Expert Token Distribution & Device Allocation:
DEBUG 01-06 17:11:20.535017.535017 lmp.py:404]   Total experts: 64
DEBUG 01-06 17:11:20.535144.535144 lmp.py:405]   CPU experts: 32 (50%)
DEBUG 01-06 17:11:20.535171.535171 lmp.py:406]   GPU experts: 32 (50%)
DEBUG 01-06 17:11:20.535099.535099 lmp.py:407] 
DEBUG 01-06 17:11:20.535099.535099 lmp.py:407]   Expert ID | Tokens | Device
DEBUG 01-06 17:11:20.535026.535026 lmp.py:408]   -----------------------------------
DEBUG 01-06 17:11:20.535961.535961 lmp.py:414]   Expert 58 |     34 | CPU
DEBUG 01-06 17:11:20.535127.535127 lmp.py:414]   Expert 49 |     60 | CPU
DEBUG 01-06 17:11:20.535339.535339 lmp.py:414]   Expert 31 |     62 | CPU
DEBUG 01-06 17:11:20.535313.535313 lmp.py:414]   Expert 47 |     63 | CPU
DEBUG 01-06 17:11:20.535526.535526 lmp.py:414]   Expert  4 |     68 | CPU
DEBUG 01-06 17:11:20.535738.535738 lmp.py:414]   Expert 43 |     74 | CPU
DEBUG 01-06 17:11:20.535666.535666 lmp.py:414]   Expert 45 |     75 | CPU
DEBUG 01-06 17:11:20.535879.535879 lmp.py:414]   Expert 38 |     76 | CPU
DEBUG 01-06 17:11:20.535091.535091 lmp.py:414]   Expert 41 |     78 | CPU
DEBUG 01-06 17:11:20.535304.535304 lmp.py:414]   Expert 33 |     99 | CPU
DEBUG 01-06 17:11:20.535039.535039 lmp.py:414]   Expert 50 |     99 | CPU
DEBUG 01-06 17:11:20.535252.535252 lmp.py:414]   Expert 57 |    106 | CPU
DEBUG 01-06 17:11:20.535133.535133 lmp.py:414]   Expert  2 |    111 | CPU
DEBUG 01-06 17:11:20.535061.535061 lmp.py:414]   Expert 11 |    113 | CPU
DEBUG 01-06 17:11:20.535988.535988 lmp.py:414]   Expert 51 |    119 | CPU
DEBUG 01-06 17:11:20.535631.535631 lmp.py:414]   Expert 56 |    122 | CPU
DEBUG 01-06 17:11:20.535274.535274 lmp.py:414]   Expert  0 |    125 | CPU
DEBUG 01-06 17:11:20.535202.535202 lmp.py:414]   Expert 54 |    126 | CPU
DEBUG 01-06 17:11:20.535130.535130 lmp.py:414]   Expert 14 |    129 | CPU
DEBUG 01-06 17:11:20.535819.535819 lmp.py:414]   Expert 34 |    139 | CPU
DEBUG 01-06 17:11:20.535508.535508 lmp.py:414]   Expert 26 |    140 | CPU
DEBUG 01-06 17:11:20.535198.535198 lmp.py:414]   Expert 27 |    154 | CPU
DEBUG 01-06 17:11:20.535649.535649 lmp.py:414]   Expert 28 |    154 | CPU
DEBUG 01-06 17:11:20.535338.535338 lmp.py:414]   Expert 25 |    164 | CPU
DEBUG 01-06 17:11:20.535789.535789 lmp.py:414]   Expert 10 |    166 | CPU
DEBUG 01-06 17:11:20.535240.535240 lmp.py:414]   Expert 55 |    168 | CPU
DEBUG 01-06 17:11:20.535406.535406 lmp.py:414]   Expert 13 |    176 | CPU
DEBUG 01-06 17:11:20.535049.535049 lmp.py:414]   Expert  9 |    181 | CPU
DEBUG 01-06 17:11:20.535976.535976 lmp.py:414]   Expert 61 |    182 | CPU
DEBUG 01-06 17:11:20.535904.535904 lmp.py:414]   Expert  7 |    186 | CPU
DEBUG 01-06 17:11:20.535355.535355 lmp.py:414]   Expert  6 |    190 | CPU
DEBUG 01-06 17:11:20.535806.535806 lmp.py:414]   Expert 48 |    192 | CPU
DEBUG 01-06 17:11:20.535257.535257 lmp.py:414]   Expert 24 |    196 | GPU
DEBUG 01-06 17:11:20.535946.535946 lmp.py:414]   Expert 42 |    199 | GPU
DEBUG 01-06 17:11:20.536397.536397 lmp.py:414]   Expert 46 |    201 | GPU
DEBUG 01-06 17:11:20.536848.536848 lmp.py:414]   Expert 18 |    202 | GPU
DEBUG 01-06 17:11:20.536299.536299 lmp.py:414]   Expert 40 |    209 | GPU
DEBUG 01-06 17:11:20.536750.536750 lmp.py:414]   Expert 59 |    210 | GPU
DEBUG 01-06 17:11:20.536439.536439 lmp.py:414]   Expert 63 |    210 | GPU
DEBUG 01-06 17:11:20.536890.536890 lmp.py:414]   Expert 12 |    219 | GPU
DEBUG 01-06 17:11:20.536579.536579 lmp.py:414]   Expert 21 |    219 | GPU
DEBUG 01-06 17:11:20.536792.536792 lmp.py:414]   Expert 32 |    220 | GPU
DEBUG 01-06 17:11:20.536481.536481 lmp.py:414]   Expert 19 |    221 | GPU
DEBUG 01-06 17:11:20.536885.536885 lmp.py:414]   Expert 29 |    230 | GPU
DEBUG 01-06 17:11:20.536052.536052 lmp.py:414]   Expert 36 |    231 | GPU
DEBUG 01-06 17:11:20.536741.536741 lmp.py:414]   Expert 22 |    232 | GPU
DEBUG 01-06 17:11:20.536192.536192 lmp.py:414]   Expert 37 |    246 | GPU
DEBUG 01-06 17:11:20.536881.536881 lmp.py:414]   Expert  3 |    249 | GPU
DEBUG 01-06 17:11:20.536570.536570 lmp.py:414]   Expert  1 |    250 | GPU
DEBUG 01-06 17:11:20.536260.536260 lmp.py:414]   Expert 16 |    256 | GPU
DEBUG 01-06 17:11:20.536711.536711 lmp.py:414]   Expert  8 |    265 | GPU
DEBUG 01-06 17:11:20.536161.536161 lmp.py:414]   Expert 20 |    265 | GPU
DEBUG 01-06 17:11:20.536612.536612 lmp.py:414]   Expert 30 |    267 | GPU
DEBUG 01-06 17:11:20.536302.536302 lmp.py:414]   Expert 15 |    271 | GPU
DEBUG 01-06 17:11:20.536468.536468 lmp.py:414]   Expert  5 |    274 | GPU
DEBUG 01-06 17:11:20.536349.536349 lmp.py:414]   Expert 62 |    276 | GPU
DEBUG 01-06 17:11:20.536038.536038 lmp.py:414]   Expert 35 |    287 | GPU
DEBUG 01-06 17:11:20.536933.536933 lmp.py:414]   Expert 39 |    296 | GPU
DEBUG 01-06 17:11:20.536384.536384 lmp.py:414]   Expert 17 |    299 | GPU
DEBUG 01-06 17:11:20.536789.536789 lmp.py:414]   Expert 60 |    309 | GPU
DEBUG 01-06 17:11:20.536240.536240 lmp.py:414]   Expert 52 |    346 | GPU
DEBUG 01-06 17:11:20.536691.536691 lmp.py:414]   Expert 44 |    373 | GPU
DEBUG 01-06 17:11:20.536142.536142 lmp.py:414]   Expert 23 |    381 | GPU
DEBUG 01-06 17:11:20.536592.536592 lmp.py:414]   Expert 53 |    448 | GPU
DEBUG 01-06 17:11:20.536759.536759 lmp.py:415] 
DEBUG 01-06 17:11:20.536759.536759 lmp.py:415]   CPU total tokens: 3931 (32.0%)
DEBUG 01-06 17:11:20.536402.536402 lmp.py:416]   GPU total tokens: 8357 (68.0%)
DEBUG 01-06 17:11:20.536574.536574 cuda_h.py:19] end experts_map_get cost 0.0015196800231933594 seconds
DEBUG 01-06 17:11:20.536648.536648 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-06 17:11:20.536477.536477 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 17:11:20.536760.536760 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 17:11:20.537940.537940 cuda_h.py:19] end allocate_cuda_memory cost 0.0008025169372558594 seconds
DEBUG 01-06 17:11:20.537929.537929 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 17:11:20.537639.537639 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 17:11:20.537879.537879 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 17:11:20.537482.537482 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 6ef7dfe0-c7da-43da-9d43-1c8394888719
DEBUG 01-06 17:11:20.537754.537754 client.py:106] call stub.LoadModelAsync
INFO 01-06 17:11:20.540057.540057 client.py:127] Model loaded
DEBUG 01-06 17:11:20.540904.540904 cuda_h.py:19] end sllm_worker_task cost 0.01089620590209961 seconds
INFO 01-06 17:11:20.541069.541069 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 6ef7dfe0-c7da-43da-9d43-1c8394888719
DEBUG 01-06 17:11:20.541918.541918 cuda_h.py:19] end load_into_gpu_async cost 0.0033986568450927734 seconds
DEBUG 01-06 17:11:20.541052.541052 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 17:11:20.541305.541305 cuda_h.py:19] end restore_tensors2 cost 0.0004050731658935547 seconds
DEBUG 01-06 17:11:20.541618.541618 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.004961729049682617 seconds
DEBUG 01-06 17:11:20.544150.544150 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.007645845413208008 seconds
DEBUG 01-06 17:11:20.544695.544695 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-06 17:11:20.544830.544830 lmp.py:461] 
DEBUG 01-06 17:11:20.544830.544830 lmp.py:461]   Computing 32 experts on CPU...
DEBUG 01-06 17:11:20.544733.544733 cuda_h.py:19] end cpu_experts_submit cost 0.00012564659118652344 seconds
DEBUG 01-06 17:11:20.544575.544575 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-06 17:11:20.553980.553980 mlpmodule.py:706] group tensors cost 0.008863687515258789 s
DEBUG 01-06 17:11:20.555794.555794 mlpmodule.py:744] pad cost 0.0016775131225585938 s
DEBUG 01-06 17:11:20.556665.556665 mlpmodule.py:750] create cpu tensor cost 5.1021575927734375e-05 s
DEBUG 01-06 17:11:20.556144.556144 mlpmodule.py:755] move to cpu cost 3.600120544433594e-05 s
DEBUG 01-06 17:11:20.566395.566395 mlpmodule.py:769] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-06 17:11:20.566882.566882 mlpmodule.py:770] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-06 17:11:20.566653.566653 mlpmodule.py:775] group_w3 first element: -0.02490234375
WARNING 01-06 17:11:20.567240.567240 mlpmodule.py:785] start einsum2
DEBUG 01-06 17:11:20.585531.585531 mlpmodule.py:795] group einsum cost 0.029067516326904297 s
DEBUG 01-06 17:11:20.586933.586933 mlpmodule.py:803] cpy2cputensor cost 0.0007512569427490234 s
DEBUG 01-06 17:11:20.590478.590478 cuda_h.py:19] end wait_cetm_experts cost 0.0460512638092041 seconds
DEBUG 01-06 17:11:20.590213.590213 cuda_h.py:10] start gpu_sexperts
DEBUG 01-06 17:11:20.591426.591426 cuda_h.py:19] end gpu_sexperts cost 0.0006029605865478516 seconds
DEBUG 01-06 17:11:20.591468.591468 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-06 17:11:20.591510.591510 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.5272369384765625e-05 seconds
DEBUG 01-06 17:11:20.591690.591690 cuda_h.py:10] start wait_experts
INFO 01-06 17:11:20.591208.591208 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 6ef7dfe0-c7da-43da-9d43-1c8394888719
INFO 01-06 17:11:20.595622.595622 client.py:127] Model loaded
DEBUG 01-06 17:11:20.595095.595095 cuda_h.py:19] end wait_experts cost 0.003954648971557617 seconds
DEBUG 01-06 17:11:20.595897.595897 cuda_h.py:10] start gpu_experts
DEBUG 01-06 17:11:20.595461.595461 lmp.py:506]   Computing 32 experts on GPU...
DEBUG 01-06 17:11:20.596574.596574 mlpmodule.py:533] gpu group tensors cost 0.0006976127624511719 s
DEBUG 01-06 17:11:20.598167.598167 mlpmodule.py:664]  experts func einsum cost 0.05345273017883301 s
DEBUG 01-06 17:11:20.598683.598683 mlpmodule.py:566] gpu pad cost 0.0020105838775634766 s
DEBUG 01-06 17:11:20.599681.599681 mlpmodule.py:584] gpu group einsum cost 0.0005869865417480469 s
DEBUG 01-06 17:11:20.602053.602053 mlpmodule.py:613] gpu experts func einsum cost 0.006914615631103516 s
DEBUG 01-06 17:11:20.602066.602066 cuda_h.py:19] end gpu_experts cost 0.007189512252807617 seconds
DEBUG 01-06 17:11:20.602433.602433 cuda_h.py:19] end layer_moe_generate_16 cost 0.06869101524353027 seconds
DEBUG 01-06 17:11:20.603964.603964 lmp.py:220] -------------------------------- end layer 16 --------------------------------
DEBUG 01-06 17:11:20.603495.603495 lmp.py:176] -------------------------------- start layer 17 --------------------------------
DEBUG 01-06 17:11:20.603237.603237 cuda_h.py:10] start start_load_qkvogn_s_weight_l_18
DEBUG 01-06 17:11:20.603709.603709 cuda_h.py:10] start start_load_qkvogn_s_weight_l_18
DEBUG 01-06 17:11:20.603313.603313 cuda_h.py:19] end start_load_qkvogn_s_weight_l_18 cost 3.2901763916015625e-05 seconds
DEBUG 01-06 17:11:20.603063.603063 cuda_h.py:19] end start_load_qkvogn_s_weight_l_18 cost 6.365776062011719e-05 seconds
DEBUG 01-06 17:11:20.603136.603136 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-06 17:11:20.603331.603331 mlpmodule.py:367] cuda:1 cuda:1
DEBUG 01-06 17:11:20.603532.603532 cuda_h.py:10] start sllm_worker_task
DEBUG 01-06 17:11:20.603258.603258 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 17:11:20.603478.603478 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 17:11:20.604946.604946 cuda_h.py:19] end allocate_cuda_memory cost 0.0003094673156738281 seconds
DEBUG 01-06 17:11:20.604155.604155 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 17:11:20.604917.604917 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 17:11:20.604356.604356 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 17:11:20.604436.604436 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, c5b8e812-f7c0-471d-a16e-8302666c2888
DEBUG 01-06 17:11:20.604883.604883 client.py:106] call stub.LoadModelAsync
DEBUG 01-06 17:11:20.604500.604500 cuda_h.py:10] start self_attn
INFO 01-06 17:11:20.605879.605879 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, c5b8e812-f7c0-471d-a16e-8302666c2888
DEBUG 01-06 17:11:20.605715.605715 cuda_h.py:19] end load_into_gpu_async cost 0.0016765594482421875 seconds
DEBUG 01-06 17:11:20.605272.605272 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 17:11:20.605786.605786 cuda_h.py:19] end restore_tensors2 cost 7.176399230957031e-05 seconds
DEBUG 01-06 17:11:20.605588.605588 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.002315044403076172 seconds
INFO 01-06 17:11:20.606417.606417 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, c5b8e812-f7c0-471d-a16e-8302666c2888
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-06 17:11:20.607208.607208 cuda_h.py:19] end self_attn cost 0.0028810501098632812 seconds
DEBUG 01-06 17:11:20.607497.607497 cuda_h.py:19] end iln_self_attn_paln cost 0.004415988922119141 seconds
DEBUG 01-06 17:11:20.607194.607194 cuda_h.py:10] start layer_moe_generate_17
DEBUG 01-06 17:11:20.607434.607434 cuda_h.py:10] start gate
DEBUG 01-06 17:11:20.608029.608029 cuda_h.py:19] end gate cost 0.0007195472717285156 seconds
DEBUG 01-06 17:11:20.608335.608335 cuda_h.py:10] start experts_map_get
DEBUG 01-06 17:11:20.609457.609457 lmp.py:403] 
DEBUG 01-06 17:11:20.609457.609457 lmp.py:403] Expert Token Distribution & Device Allocation:
DEBUG 01-06 17:11:20.609783.609783 lmp.py:404]   Total experts: 64
DEBUG 01-06 17:11:20.609194.609194 lmp.py:405]   CPU experts: 32 (50%)
DEBUG 01-06 17:11:20.609029.609029 lmp.py:406]   GPU experts: 32 (50%)
DEBUG 01-06 17:11:20.609957.609957 lmp.py:407] 
DEBUG 01-06 17:11:20.609957.609957 lmp.py:407]   Expert ID | Tokens | Device
DEBUG 01-06 17:11:20.609646.609646 lmp.py:408]   -----------------------------------
DEBUG 01-06 17:11:20.609296.609296 lmp.py:414]   Expert  4 |     13 | CPU
DEBUG 01-06 17:11:20.609701.609701 lmp.py:414]   Expert 28 |     21 | CPU
DEBUG 01-06 17:11:20.609152.609152 lmp.py:414]   Expert  7 |     46 | CPU
DEBUG 01-06 17:11:20.609364.609364 lmp.py:414]   Expert 53 |     60 | CPU
DEBUG 01-06 17:11:20.609338.609338 lmp.py:414]   Expert 43 |     64 | CPU
DEBUG 01-06 17:11:20.609027.609027 lmp.py:414]   Expert 52 |     65 | CPU
DEBUG 01-06 17:11:20.609955.609955 lmp.py:414]   Expert 49 |     88 | CPU
DEBUG 01-06 17:11:20.609168.609168 lmp.py:414]   Expert 12 |     89 | CPU
DEBUG 01-06 17:11:20.609142.609142 lmp.py:414]   Expert 24 |    101 | CPU
DEBUG 01-06 17:11:20.609354.609354 lmp.py:414]   Expert 47 |    101 | CPU
DEBUG 01-06 17:11:20.609328.609328 lmp.py:414]   Expert 33 |    106 | CPU
DEBUG 01-06 17:11:20.609825.609825 lmp.py:414]   Expert 50 |    108 | CPU
DEBUG 01-06 17:11:20.609707.609707 lmp.py:414]   Expert  2 |    109 | CPU
DEBUG 01-06 17:11:20.609634.609634 lmp.py:414]   Expert 15 |    114 | CPU
DEBUG 01-06 17:11:20.609324.609324 lmp.py:414]   Expert 39 |    114 | CPU
DEBUG 01-06 17:11:20.609490.609490 lmp.py:414]   Expert 61 |    119 | CPU
DEBUG 01-06 17:11:20.609371.609371 lmp.py:414]   Expert 60 |    120 | CPU
DEBUG 01-06 17:11:20.609253.609253 lmp.py:414]   Expert 36 |    121 | CPU
DEBUG 01-06 17:11:20.609419.609419 lmp.py:414]   Expert  6 |    128 | CPU
DEBUG 01-06 17:11:20.609108.609108 lmp.py:414]   Expert 25 |    136 | CPU
DEBUG 01-06 17:11:20.609559.609559 lmp.py:414]   Expert 59 |    141 | CPU
DEBUG 01-06 17:11:20.609771.609771 lmp.py:414]   Expert 58 |    144 | CPU
DEBUG 01-06 17:11:20.609222.609222 lmp.py:414]   Expert 27 |    146 | CPU
DEBUG 01-06 17:11:20.609673.609673 lmp.py:414]   Expert  8 |    149 | CPU
DEBUG 01-06 17:11:20.609363.609363 lmp.py:414]   Expert 31 |    149 | CPU
DEBUG 01-06 17:11:20.609290.609290 lmp.py:414]   Expert 10 |    154 | CPU
DEBUG 01-06 17:11:20.609933.609933 lmp.py:414]   Expert  3 |    156 | CPU
DEBUG 01-06 17:11:20.609623.609623 lmp.py:414]   Expert 37 |    156 | CPU
DEBUG 01-06 17:11:20.609073.609073 lmp.py:414]   Expert 38 |    156 | CPU
DEBUG 01-06 17:11:20.609001.609001 lmp.py:414]   Expert 14 |    158 | CPU
DEBUG 01-06 17:11:20.609690.609690 lmp.py:414]   Expert 40 |    158 | CPU
DEBUG 01-06 17:11:20.609141.609141 lmp.py:414]   Expert 46 |    158 | CPU
DEBUG 01-06 17:11:20.609592.609592 lmp.py:414]   Expert 57 |    160 | GPU
DEBUG 01-06 17:11:20.609282.609282 lmp.py:414]   Expert 30 |    161 | GPU
DEBUG 01-06 17:11:20.609686.609686 lmp.py:414]   Expert 54 |    164 | GPU
DEBUG 01-06 17:11:20.609091.609091 lmp.py:414]   Expert 32 |    165 | GPU
DEBUG 01-06 17:11:20.609780.609780 lmp.py:414]   Expert 41 |    165 | GPU
DEBUG 01-06 17:11:20.609469.609469 lmp.py:414]   Expert 42 |    172 | GPU
DEBUG 01-06 17:11:20.609443.609443 lmp.py:414]   Expert 11 |    176 | GPU
DEBUG 01-06 17:11:20.609656.609656 lmp.py:414]   Expert 19 |    178 | GPU
DEBUG 01-06 17:11:20.609107.609107 lmp.py:414]   Expert 34 |    180 | GPU
DEBUG 01-06 17:11:20.609081.609081 lmp.py:414]   Expert 26 |    192 | GPU
DEBUG 01-06 17:11:20.609962.609962 lmp.py:414]   Expert  0 |    194 | GPU
DEBUG 01-06 17:11:20.609651.609651 lmp.py:414]   Expert 22 |    194 | GPU
DEBUG 01-06 17:11:20.609579.609579 lmp.py:414]   Expert  1 |    198 | GPU
DEBUG 01-06 17:11:20.609030.609030 lmp.py:414]   Expert 18 |    200 | GPU
DEBUG 01-06 17:11:20.609242.609242 lmp.py:414]   Expert 56 |    208 | GPU
DEBUG 01-06 17:11:20.609216.609216 lmp.py:414]   Expert 51 |    209 | GPU
DEBUG 01-06 17:11:20.609667.609667 lmp.py:414]   Expert 44 |    211 | GPU
DEBUG 01-06 17:11:20.609118.609118 lmp.py:414]   Expert 20 |    229 | GPU
DEBUG 01-06 17:11:20.609569.609569 lmp.py:414]   Expert 45 |    230 | GPU
DEBUG 01-06 17:11:20.609735.609735 lmp.py:414]   Expert 29 |    234 | GPU
DEBUG 01-06 17:11:20.610663.610663 lmp.py:414]   Expert 48 |    234 | GPU
DEBUG 01-06 17:11:20.610114.610114 lmp.py:414]   Expert 16 |    248 | GPU
DEBUG 01-06 17:11:20.610803.610803 lmp.py:414]   Expert 21 |    249 | GPU
DEBUG 01-06 17:11:20.610777.610777 lmp.py:414]   Expert 35 |    260 | GPU
DEBUG 01-06 17:11:20.610466.610466 lmp.py:414]   Expert 55 |    272 | GPU
DEBUG 01-06 17:11:20.610917.610917 lmp.py:414]   Expert  5 |    297 | GPU
DEBUG 01-06 17:11:20.610368.610368 lmp.py:414]   Expert 23 |    376 | GPU
DEBUG 01-06 17:11:20.610342.610342 lmp.py:414]   Expert 13 |    391 | GPU
DEBUG 01-06 17:11:20.610747.610747 lmp.py:414]   Expert 17 |    435 | GPU
DEBUG 01-06 17:11:20.610913.610913 lmp.py:414]   Expert  9 |    440 | GPU
DEBUG 01-06 17:11:20.610602.610602 lmp.py:414]   Expert 63 |    444 | GPU
DEBUG 01-06 17:11:20.610053.610053 lmp.py:414]   Expert 62 |   1174 | GPU
DEBUG 01-06 17:11:20.610696.610696 lmp.py:415] 
DEBUG 01-06 17:11:20.610696.610696 lmp.py:415]   CPU total tokens: 3648 (29.7%)
DEBUG 01-06 17:11:20.610578.610578 lmp.py:416]   GPU total tokens: 8640 (70.3%)
DEBUG 01-06 17:11:20.610750.610750 cuda_h.py:19] end experts_map_get cost 0.0015075206756591797 seconds
DEBUG 01-06 17:11:20.610586.610586 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-06 17:11:20.610269.610269 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 17:11:20.610036.610036 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 17:11:20.612028.612028 cuda_h.py:19] end allocate_cuda_memory cost 0.0017156600952148438 seconds
DEBUG 01-06 17:11:20.612255.612255 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 17:11:20.612011.612011 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 17:11:20.612536.612536 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 17:11:20.612901.612901 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 20cd70f3-98bd-4b33-bbb0-5e9e25ba627d
DEBUG 01-06 17:11:20.612318.612318 client.py:106] call stub.LoadModelAsync
INFO 01-06 17:11:20.613568.613568 client.py:127] Model loaded
DEBUG 01-06 17:11:20.614316.614316 cuda_h.py:19] end sllm_worker_task cost 0.01065206527709961 seconds
INFO 01-06 17:11:20.615795.615795 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 20cd70f3-98bd-4b33-bbb0-5e9e25ba627d
DEBUG 01-06 17:11:20.615291.615291 cuda_h.py:19] end load_into_gpu_async cost 0.003382444381713867 seconds
DEBUG 01-06 17:11:20.615161.615161 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 17:11:20.616668.616668 cuda_h.py:19] end restore_tensors2 cost 0.00044727325439453125 seconds
DEBUG 01-06 17:11:20.616981.616981 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.006014585494995117 seconds
DEBUG 01-06 17:11:20.618275.618275 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.008697986602783203 seconds
DEBUG 01-06 17:11:20.619773.619773 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-06 17:11:20.619935.619935 lmp.py:461] 
DEBUG 01-06 17:11:20.619935.619935 lmp.py:461]   Computing 32 experts on CPU...
DEBUG 01-06 17:11:20.619183.619183 cuda_h.py:19] end cpu_experts_submit cost 0.000118255615234375 seconds
DEBUG 01-06 17:11:20.619309.619309 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-06 17:11:20.631141.631141 mlpmodule.py:706] group tensors cost 0.012517690658569336 s
DEBUG 01-06 17:11:20.634848.634848 mlpmodule.py:744] pad cost 0.0016376972198486328 s
DEBUG 01-06 17:11:20.634733.634733 mlpmodule.py:750] create cpu tensor cost 6.437301635742188e-05 s
DEBUG 01-06 17:11:20.634352.634352 mlpmodule.py:755] move to cpu cost 3.409385681152344e-05 s
DEBUG 01-06 17:11:20.644065.644065 mlpmodule.py:769] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-06 17:11:20.644877.644877 mlpmodule.py:770] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-06 17:11:20.644986.644986 mlpmodule.py:775] group_w3 first element: 0.00457763671875
WARNING 01-06 17:11:20.644804.644804 mlpmodule.py:785] start einsum2
DEBUG 01-06 17:11:20.662195.662195 mlpmodule.py:795] group einsum cost 0.027471065521240234 s
DEBUG 01-06 17:11:20.662686.662686 mlpmodule.py:803] cpy2cputensor cost 0.0006430149078369141 s
DEBUG 01-06 17:11:20.667675.667675 cuda_h.py:19] end wait_cetm_experts cost 0.04796338081359863 seconds
DEBUG 01-06 17:11:20.667310.667310 cuda_h.py:10] start gpu_sexperts
DEBUG 01-06 17:11:20.668809.668809 cuda_h.py:19] end gpu_sexperts cost 0.0006051063537597656 seconds
DEBUG 01-06 17:11:20.668851.668851 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-06 17:11:20.668608.668608 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.6702880859375e-05 seconds
DEBUG 01-06 17:11:20.668026.668026 cuda_h.py:10] start wait_experts
INFO 01-06 17:11:20.668259.668259 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 20cd70f3-98bd-4b33-bbb0-5e9e25ba627d
INFO 01-06 17:11:20.669431.669431 client.py:127] Model loaded
DEBUG 01-06 17:11:20.669473.669473 cuda_h.py:19] end wait_experts cost 0.0014569759368896484 seconds
DEBUG 01-06 17:11:20.669368.669368 cuda_h.py:10] start gpu_experts
DEBUG 01-06 17:11:20.669886.669886 lmp.py:506]   Computing 32 experts on GPU...
DEBUG 01-06 17:11:20.670997.670997 mlpmodule.py:533] gpu group tensors cost 0.0006647109985351562 s
DEBUG 01-06 17:11:20.674000.674000 mlpmodule.py:566] gpu pad cost 0.0033860206604003906 s
DEBUG 01-06 17:11:20.675277.675277 mlpmodule.py:664]  experts func einsum cost 0.05576729774475098 s
DEBUG 01-06 17:11:20.675602.675602 mlpmodule.py:584] gpu group einsum cost 0.0014560222625732422 s
DEBUG 01-06 17:11:20.678264.678264 mlpmodule.py:613] gpu experts func einsum cost 0.009040355682373047 s
DEBUG 01-06 17:11:20.679270.679270 cuda_h.py:19] end gpu_experts cost 0.00930929183959961 seconds
DEBUG 01-06 17:11:20.679029.679029 cuda_h.py:19] end layer_moe_generate_17 cost 0.07137060165405273 seconds
DEBUG 01-06 17:11:20.679691.679691 lmp.py:220] -------------------------------- end layer 17 --------------------------------
DEBUG 01-06 17:11:20.679077.679077 lmp.py:176] -------------------------------- start layer 18 --------------------------------
DEBUG 01-06 17:11:20.679488.679488 cuda_h.py:10] start start_load_qkvogn_s_weight_l_19
DEBUG 01-06 17:11:20.679390.679390 cuda_h.py:10] start start_load_qkvogn_s_weight_l_19
DEBUG 01-06 17:11:20.679186.679186 cuda_h.py:19] end start_load_qkvogn_s_weight_l_19 cost 3.409385681152344e-05 seconds
DEBUG 01-06 17:11:20.679174.679174 cuda_h.py:19] end start_load_qkvogn_s_weight_l_19 cost 6.4849853515625e-05 seconds
DEBUG 01-06 17:11:20.679009.679009 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-06 17:11:20.679389.679389 mlpmodule.py:367] cuda:1 cuda:1
DEBUG 01-06 17:11:20.679259.679259 cuda_h.py:10] start sllm_worker_task
DEBUG 01-06 17:11:20.679302.679302 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 17:11:20.679668.679668 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 17:11:20.680737.680737 cuda_h.py:19] end allocate_cuda_memory cost 0.00022292137145996094 seconds
DEBUG 01-06 17:11:20.680845.680845 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 17:11:20.680939.680939 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 17:11:20.680096.680096 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 17:11:20.680719.680719 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 20e6be5c-c9f5-43e8-b96e-320cb050dd07
DEBUG 01-06 17:11:20.680286.680286 client.py:106] call stub.LoadModelAsync
DEBUG 01-06 17:11:20.680486.680486 cuda_h.py:10] start self_attn
INFO 01-06 17:11:20.682094.682094 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 20e6be5c-c9f5-43e8-b96e-320cb050dd07
DEBUG 01-06 17:11:20.682414.682414 cuda_h.py:19] end load_into_gpu_async cost 0.001718759536743164 seconds
DEBUG 01-06 17:11:20.682640.682640 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 17:11:20.682776.682776 cuda_h.py:19] end restore_tensors2 cost 7.319450378417969e-05 seconds
DEBUG 01-06 17:11:20.682578.682578 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0022742748260498047 seconds
INFO 01-06 17:11:20.682838.682838 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 20e6be5c-c9f5-43e8-b96e-320cb050dd07
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-06 17:11:20.683432.683432 cuda_h.py:19] end self_attn cost 0.0028798580169677734 seconds
DEBUG 01-06 17:11:20.684118.684118 cuda_h.py:19] end iln_self_attn_paln cost 0.0044057369232177734 seconds
DEBUG 01-06 17:11:20.684861.684861 cuda_h.py:10] start layer_moe_generate_18
DEBUG 01-06 17:11:20.684055.684055 cuda_h.py:10] start gate
DEBUG 01-06 17:11:20.684138.684138 cuda_h.py:19] end gate cost 0.0006582736968994141 seconds
DEBUG 01-06 17:11:20.684398.684398 cuda_h.py:10] start experts_map_get
DEBUG 01-06 17:11:20.685805.685805 lmp.py:403] 
DEBUG 01-06 17:11:20.685805.685805 lmp.py:403] Expert Token Distribution & Device Allocation:
DEBUG 01-06 17:11:20.685323.685323 lmp.py:404]   Total experts: 64
DEBUG 01-06 17:11:20.685019.685019 lmp.py:405]   CPU experts: 32 (50%)
DEBUG 01-06 17:11:20.685854.685854 lmp.py:406]   GPU experts: 32 (50%)
DEBUG 01-06 17:11:20.685305.685305 lmp.py:407] 
DEBUG 01-06 17:11:20.685305.685305 lmp.py:407]   Expert ID | Tokens | Device
DEBUG 01-06 17:11:20.685755.685755 lmp.py:408]   -----------------------------------
DEBUG 01-06 17:11:20.685690.685690 lmp.py:414]   Expert 32 |     28 | CPU
DEBUG 01-06 17:11:20.685618.685618 lmp.py:414]   Expert 30 |     48 | CPU
DEBUG 01-06 17:11:20.685830.685830 lmp.py:414]   Expert  5 |     51 | CPU
DEBUG 01-06 17:11:20.685043.685043 lmp.py:414]   Expert 46 |     69 | CPU
DEBUG 01-06 17:11:20.685970.685970 lmp.py:414]   Expert  8 |     85 | CPU
DEBUG 01-06 17:11:20.685660.685660 lmp.py:414]   Expert 40 |     86 | CPU
DEBUG 01-06 17:11:20.685634.685634 lmp.py:414]   Expert 12 |     98 | CPU
DEBUG 01-06 17:11:20.685369.685369 lmp.py:414]   Expert 60 |    106 | CPU
DEBUG 01-06 17:11:20.685582.685582 lmp.py:414]   Expert  3 |    108 | CPU
DEBUG 01-06 17:11:20.685794.685794 lmp.py:414]   Expert 27 |    108 | CPU
DEBUG 01-06 17:11:20.685530.685530 lmp.py:414]   Expert 58 |    109 | CPU
DEBUG 01-06 17:11:20.685504.685504 lmp.py:414]   Expert 28 |    116 | CPU
DEBUG 01-06 17:11:20.685061.685061 lmp.py:414]   Expert 21 |    120 | CPU
DEBUG 01-06 17:11:20.685373.685373 lmp.py:414]   Expert 29 |    120 | CPU
DEBUG 01-06 17:11:20.685539.685539 lmp.py:414]   Expert 17 |    123 | CPU
DEBUG 01-06 17:11:20.685228.685228 lmp.py:414]   Expert 41 |    124 | CPU
DEBUG 01-06 17:11:20.685156.685156 lmp.py:414]   Expert 35 |    125 | CPU
DEBUG 01-06 17:11:20.685322.685322 lmp.py:414]   Expert 25 |    130 | CPU
DEBUG 01-06 17:11:20.685250.685250 lmp.py:414]   Expert 19 |    131 | CPU
DEBUG 01-06 17:11:20.685178.685178 lmp.py:414]   Expert  0 |    137 | CPU
DEBUG 01-06 17:11:20.685582.685582 lmp.py:414]   Expert 52 |    137 | CPU
DEBUG 01-06 17:11:20.685033.685033 lmp.py:414]   Expert 54 |    139 | CPU
DEBUG 01-06 17:11:20.685199.685199 lmp.py:414]   Expert 37 |    151 | CPU
DEBUG 01-06 17:11:20.685889.685889 lmp.py:414]   Expert 56 |    156 | CPU
DEBUG 01-06 17:11:20.685578.685578 lmp.py:414]   Expert 48 |    157 | CPU
DEBUG 01-06 17:11:20.685267.685267 lmp.py:414]   Expert 63 |    157 | CPU
DEBUG 01-06 17:11:20.685956.685956 lmp.py:414]   Expert 53 |    159 | CPU
DEBUG 01-06 17:11:20.685407.685407 lmp.py:414]   Expert  6 |    160 | CPU
DEBUG 01-06 17:11:20.685812.685812 lmp.py:414]   Expert 36 |    162 | CPU
DEBUG 01-06 17:11:20.685978.685978 lmp.py:414]   Expert 59 |    165 | CPU
DEBUG 01-06 17:11:20.685144.685144 lmp.py:414]   Expert  9 |    178 | CPU
DEBUG 01-06 17:11:20.685072.685072 lmp.py:414]   Expert 39 |    181 | CPU
DEBUG 01-06 17:11:20.685476.685476 lmp.py:414]   Expert  1 |    186 | GPU
DEBUG 01-06 17:11:20.685404.685404 lmp.py:414]   Expert 11 |    195 | GPU
DEBUG 01-06 17:11:20.685093.685093 lmp.py:414]   Expert 20 |    196 | GPU
DEBUG 01-06 17:11:20.685260.685260 lmp.py:414]   Expert 42 |    200 | GPU
DEBUG 01-06 17:11:20.685187.685187 lmp.py:414]   Expert 43 |    200 | GPU
DEBUG 01-06 17:11:20.686592.686592 lmp.py:414]   Expert 61 |    201 | GPU
DEBUG 01-06 17:11:20.686473.686473 lmp.py:414]   Expert 34 |    203 | GPU
DEBUG 01-06 17:11:20.686401.686401 lmp.py:414]   Expert  7 |    205 | GPU
DEBUG 01-06 17:11:20.686852.686852 lmp.py:414]   Expert 55 |    215 | GPU
DEBUG 01-06 17:11:20.686541.686541 lmp.py:414]   Expert 13 |    218 | GPU
DEBUG 01-06 17:11:20.686230.686230 lmp.py:414]   Expert 16 |    219 | GPU
DEBUG 01-06 17:11:20.686920.686920 lmp.py:414]   Expert 47 |    220 | GPU
DEBUG 01-06 17:11:20.686086.686086 lmp.py:414]   Expert 57 |    225 | GPU
DEBUG 01-06 17:11:20.686014.686014 lmp.py:414]   Expert  4 |    235 | GPU
DEBUG 01-06 17:11:20.686941.686941 lmp.py:414]   Expert 18 |    236 | GPU
DEBUG 01-06 17:11:20.686392.686392 lmp.py:414]   Expert 15 |    237 | GPU
DEBUG 01-06 17:11:20.686558.686558 lmp.py:414]   Expert 45 |    244 | GPU
DEBUG 01-06 17:11:20.686248.686248 lmp.py:414]   Expert 50 |    244 | GPU
DEBUG 01-06 17:11:20.686937.686937 lmp.py:414]   Expert 22 |    246 | GPU
DEBUG 01-06 17:11:20.686626.686626 lmp.py:414]   Expert 33 |    247 | GPU
DEBUG 01-06 17:11:20.686839.686839 lmp.py:414]   Expert 31 |    248 | GPU
DEBUG 01-06 17:11:20.686528.686528 lmp.py:414]   Expert 51 |    257 | GPU
DEBUG 01-06 17:11:20.686409.686409 lmp.py:414]   Expert 49 |    268 | GPU
DEBUG 01-06 17:11:20.686337.686337 lmp.py:414]   Expert 38 |    270 | GPU
DEBUG 01-06 17:11:20.686788.686788 lmp.py:414]   Expert 26 |    283 | GPU
DEBUG 01-06 17:11:20.686239.686239 lmp.py:414]   Expert 10 |    292 | GPU
DEBUG 01-06 17:11:20.686690.686690 lmp.py:414]   Expert 44 |    293 | GPU
DEBUG 01-06 17:11:20.686902.686902 lmp.py:414]   Expert 24 |    301 | GPU
DEBUG 01-06 17:11:20.686353.686353 lmp.py:414]   Expert  2 |    315 | GPU
DEBUG 01-06 17:11:20.686281.686281 lmp.py:414]   Expert 14 |    315 | GPU
DEBUG 01-06 17:11:20.686732.686732 lmp.py:414]   Expert 23 |    461 | GPU
DEBUG 01-06 17:11:20.686659.686659 lmp.py:414]   Expert 62 |    689 | GPU
DEBUG 01-06 17:11:20.686494.686494 lmp.py:415] 
DEBUG 01-06 17:11:20.686494.686494 lmp.py:415]   CPU total tokens: 3924 (31.9%)
DEBUG 01-06 17:11:20.686376.686376 lmp.py:416]   GPU total tokens: 8364 (68.1%)
DEBUG 01-06 17:11:20.686834.686834 cuda_h.py:19] end experts_map_get cost 0.0015232563018798828 seconds
DEBUG 01-06 17:11:20.686953.686953 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-06 17:11:20.686591.686591 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 17:11:20.686735.686735 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 17:11:20.688320.688320 cuda_h.py:19] end allocate_cuda_memory cost 0.0016281604766845703 seconds
DEBUG 01-06 17:11:20.688998.688998 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 17:11:20.688185.688185 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 17:11:20.688994.688994 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 17:11:20.688643.688643 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 27da2b45-30cb-4954-96ad-26f6b4ed13ac
DEBUG 01-06 17:11:20.688955.688955 client.py:106] call stub.LoadModelAsync
INFO 01-06 17:11:20.690886.690886 client.py:127] Model loaded
DEBUG 01-06 17:11:20.690296.690296 cuda_h.py:19] end sllm_worker_task cost 0.010498762130737305 seconds
INFO 01-06 17:11:20.691690.691690 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 27da2b45-30cb-4954-96ad-26f6b4ed13ac
DEBUG 01-06 17:11:20.691278.691278 cuda_h.py:19] end load_into_gpu_async cost 0.0033500194549560547 seconds
DEBUG 01-06 17:11:20.691433.691433 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 17:11:20.692253.692253 cuda_h.py:19] end restore_tensors2 cost 0.0005047321319580078 seconds
DEBUG 01-06 17:11:20.692281.692281 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.005963563919067383 seconds
DEBUG 01-06 17:11:20.695349.695349 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.008622407913208008 seconds
DEBUG 01-06 17:11:20.695033.695033 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-06 17:11:20.695777.695777 lmp.py:461] 
DEBUG 01-06 17:11:20.695777.695777 lmp.py:461]   Computing 32 experts on CPU...
DEBUG 01-06 17:11:20.695343.695343 cuda_h.py:19] end cpu_experts_submit cost 0.00011444091796875 seconds
DEBUG 01-06 17:11:20.695231.695231 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-06 17:11:20.701988.701988 mlpmodule.py:706] group tensors cost 0.006000041961669922 s
DEBUG 01-06 17:11:20.703316.703316 mlpmodule.py:744] pad cost 0.0016863346099853516 s
DEBUG 01-06 17:11:20.703280.703280 mlpmodule.py:750] create cpu tensor cost 4.649162292480469e-05 s
DEBUG 01-06 17:11:20.704329.704329 mlpmodule.py:755] move to cpu cost 3.361701965332031e-05 s
DEBUG 01-06 17:11:20.716813.716813 mlpmodule.py:769] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-06 17:11:20.716392.716392 mlpmodule.py:770] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-06 17:11:20.716348.716348 mlpmodule.py:775] group_w3 first element: 0.0024871826171875
WARNING 01-06 17:11:20.716001.716001 mlpmodule.py:785] start einsum2
DEBUG 01-06 17:11:20.735261.735261 mlpmodule.py:795] group einsum cost 0.03112339973449707 s
DEBUG 01-06 17:11:20.736178.736178 mlpmodule.py:803] cpy2cputensor cost 0.0007107257843017578 s
DEBUG 01-06 17:11:20.740084.740084 cuda_h.py:19] end wait_cetm_experts cost 0.045175790786743164 seconds
DEBUG 01-06 17:11:20.740150.740150 cuda_h.py:10] start gpu_sexperts
DEBUG 01-06 17:11:20.741264.741264 cuda_h.py:19] end gpu_sexperts cost 0.0006031990051269531 seconds
DEBUG 01-06 17:11:20.741021.741021 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-06 17:11:20.741063.741063 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.5510787963867188e-05 seconds
DEBUG 01-06 17:11:20.741766.741766 cuda_h.py:10] start wait_experts
INFO 01-06 17:11:20.741284.741284 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 27da2b45-30cb-4954-96ad-26f6b4ed13ac
INFO 01-06 17:11:20.745050.745050 client.py:127] Model loaded
DEBUG 01-06 17:11:20.745145.745145 cuda_h.py:19] end wait_experts cost 0.003759622573852539 seconds
DEBUG 01-06 17:11:20.745616.745616 cuda_h.py:10] start gpu_experts
DEBUG 01-06 17:11:20.745518.745518 lmp.py:506]   Computing 32 experts on GPU...
DEBUG 01-06 17:11:20.746907.746907 mlpmodule.py:533] gpu group tensors cost 0.0006554126739501953 s
DEBUG 01-06 17:11:20.748671.748671 mlpmodule.py:566] gpu pad cost 0.0018029212951660156 s
DEBUG 01-06 17:11:20.748166.748166 mlpmodule.py:664]  experts func einsum cost 0.052858829498291016 s
DEBUG 01-06 17:11:20.748222.748222 mlpmodule.py:584] gpu group einsum cost 0.0007321834564208984 s
DEBUG 01-06 17:11:20.752025.752025 mlpmodule.py:613] gpu experts func einsum cost 0.00674748420715332 s
DEBUG 01-06 17:11:20.752958.752958 cuda_h.py:19] end gpu_experts cost 0.007033824920654297 seconds
DEBUG 01-06 17:11:20.752081.752081 cuda_h.py:19] end layer_moe_generate_18 cost 0.06842327117919922 seconds
DEBUG 01-06 17:11:20.752438.752438 lmp.py:220] -------------------------------- end layer 18 --------------------------------
DEBUG 01-06 17:11:20.752492.752492 lmp.py:176] -------------------------------- start layer 19 --------------------------------
DEBUG 01-06 17:11:20.752904.752904 cuda_h.py:10] start start_load_qkvogn_s_weight_l_20
DEBUG 01-06 17:11:20.752421.752421 cuda_h.py:10] start start_load_qkvogn_s_weight_l_20
DEBUG 01-06 17:11:20.752119.752119 cuda_h.py:19] end start_load_qkvogn_s_weight_l_20 cost 3.147125244140625e-05 seconds
DEBUG 01-06 17:11:20.752583.752583 cuda_h.py:19] end start_load_qkvogn_s_weight_l_20 cost 6.246566772460938e-05 seconds
DEBUG 01-06 17:11:20.753849.753849 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-06 17:11:20.753613.753613 mlpmodule.py:367] cuda:1 cuda:1
DEBUG 01-06 17:11:20.753576.753576 cuda_h.py:10] start sllm_worker_task
DEBUG 01-06 17:11:20.753096.753096 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 17:11:20.753554.753554 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 17:11:20.753678.753678 cuda_h.py:19] end allocate_cuda_memory cost 0.00029921531677246094 seconds
DEBUG 01-06 17:11:20.753833.753833 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 17:11:20.753311.753311 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 17:11:20.753465.753465 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 17:11:20.753930.753930 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 3296f4f0-92fd-49c7-b176-ddf63950ffce
DEBUG 01-06 17:11:20.753608.753608 client.py:106] call stub.LoadModelAsync
DEBUG 01-06 17:11:20.754728.754728 cuda_h.py:10] start self_attn
INFO 01-06 17:11:20.755051.755051 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 3296f4f0-92fd-49c7-b176-ddf63950ffce
DEBUG 01-06 17:11:20.755649.755649 cuda_h.py:19] end load_into_gpu_async cost 0.0015840530395507812 seconds
DEBUG 01-06 17:11:20.755206.755206 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 17:11:20.755812.755812 cuda_h.py:19] end restore_tensors2 cost 6.961822509765625e-05 seconds
DEBUG 01-06 17:11:20.755052.755052 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0022144317626953125 seconds
INFO 01-06 17:11:20.755411.755411 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 3296f4f0-92fd-49c7-b176-ddf63950ffce
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-06 17:11:20.757788.757788 cuda_h.py:19] end self_attn cost 0.003107786178588867 seconds
DEBUG 01-06 17:11:20.757056.757056 cuda_h.py:19] end iln_self_attn_paln cost 0.004581928253173828 seconds
DEBUG 01-06 17:11:20.757753.757753 cuda_h.py:10] start layer_moe_generate_19
DEBUG 01-06 17:11:20.757185.757185 cuda_h.py:10] start gate
DEBUG 01-06 17:11:20.758472.758472 cuda_h.py:19] end gate cost 0.0006341934204101562 seconds
DEBUG 01-06 17:11:20.758017.758017 cuda_h.py:10] start experts_map_get
DEBUG 01-06 17:11:20.758133.758133 lmp.py:403] 
DEBUG 01-06 17:11:20.758133.758133 lmp.py:403] Expert Token Distribution & Device Allocation:
DEBUG 01-06 17:11:20.758174.758174 lmp.py:404]   Total experts: 64
DEBUG 01-06 17:11:20.758585.758585 lmp.py:405]   CPU experts: 32 (50%)
DEBUG 01-06 17:11:20.758374.758374 lmp.py:406]   GPU experts: 32 (50%)
DEBUG 01-06 17:11:20.758302.758302 lmp.py:407] 
DEBUG 01-06 17:11:20.758302.758302 lmp.py:407]   Expert ID | Tokens | Device
DEBUG 01-06 17:11:20.758468.758468 lmp.py:408]   -----------------------------------
DEBUG 01-06 17:11:20.758879.758879 lmp.py:414]   Expert 44 |     39 | CPU
DEBUG 01-06 17:11:20.758191.758191 lmp.py:414]   Expert  1 |     47 | CPU
DEBUG 01-06 17:11:20.758834.758834 lmp.py:414]   Expert 28 |     53 | CPU
DEBUG 01-06 17:11:20.758762.758762 lmp.py:414]   Expert 60 |     58 | CPU
DEBUG 01-06 17:11:20.758166.758166 lmp.py:414]   Expert 48 |     76 | CPU
DEBUG 01-06 17:11:20.758809.758809 lmp.py:414]   Expert 27 |     84 | CPU
DEBUG 01-06 17:11:20.758691.758691 lmp.py:414]   Expert  0 |    104 | CPU
DEBUG 01-06 17:11:20.758095.758095 lmp.py:414]   Expert 62 |    104 | CPU
DEBUG 01-06 17:11:20.759261.759261 lmp.py:414]   Expert 42 |    108 | CPU
DEBUG 01-06 17:11:20.759951.759951 lmp.py:414]   Expert 59 |    117 | CPU
DEBUG 01-06 17:11:20.759640.759640 lmp.py:414]   Expert 22 |    118 | CPU
DEBUG 01-06 17:11:20.759806.759806 lmp.py:414]   Expert 30 |    119 | CPU
DEBUG 01-06 17:11:20.759734.759734 lmp.py:414]   Expert 58 |    123 | CPU
DEBUG 01-06 17:11:20.759423.759423 lmp.py:414]   Expert 16 |    129 | CPU
DEBUG 01-06 17:11:20.759828.759828 lmp.py:414]   Expert 56 |    133 | CPU
DEBUG 01-06 17:11:20.759755.759755 lmp.py:414]   Expert  8 |    134 | CPU
DEBUG 01-06 17:11:20.759206.759206 lmp.py:414]   Expert 12 |    134 | CPU
DEBUG 01-06 17:11:20.759419.759419 lmp.py:414]   Expert 57 |    136 | CPU
DEBUG 01-06 17:11:20.759870.759870 lmp.py:414]   Expert 50 |    139 | CPU
DEBUG 01-06 17:11:20.759559.759559 lmp.py:414]   Expert  5 |    144 | CPU
DEBUG 01-06 17:11:20.759248.759248 lmp.py:414]   Expert 26 |    149 | CPU
DEBUG 01-06 17:11:20.759699.759699 lmp.py:414]   Expert 15 |    150 | CPU
DEBUG 01-06 17:11:20.759865.759865 lmp.py:414]   Expert 55 |    156 | CPU
DEBUG 01-06 17:11:20.759985.759985 lmp.py:414]   Expert 32 |    159 | CPU
DEBUG 01-06 17:11:20.759913.759913 lmp.py:414]   Expert 47 |    159 | CPU
DEBUG 01-06 17:11:20.759602.759602 lmp.py:414]   Expert 24 |    161 | CPU
DEBUG 01-06 17:11:20.759530.759530 lmp.py:414]   Expert 40 |    163 | CPU
DEBUG 01-06 17:11:20.759981.759981 lmp.py:414]   Expert 34 |    165 | CPU
DEBUG 01-06 17:11:20.759670.759670 lmp.py:414]   Expert 52 |    165 | CPU
DEBUG 01-06 17:11:20.759803.759803 lmp.py:414]   Expert  6 |    168 | CPU
DEBUG 01-06 17:11:20.759685.759685 lmp.py:414]   Expert 13 |    169 | CPU
DEBUG 01-06 17:11:20.759659.759659 lmp.py:414]   Expert 54 |    170 | CPU
DEBUG 01-06 17:11:20.759633.759633 lmp.py:414]   Expert  3 |    172 | GPU
DEBUG 01-06 17:11:20.759368.759368 lmp.py:414]   Expert  2 |    173 | GPU
DEBUG 01-06 17:11:20.759866.759866 lmp.py:414]   Expert 41 |    174 | GPU
DEBUG 01-06 17:11:20.759601.759601 lmp.py:414]   Expert 18 |    177 | GPU
DEBUG 01-06 17:11:20.759814.759814 lmp.py:414]   Expert 46 |    183 | GPU
DEBUG 01-06 17:11:20.759265.759265 lmp.py:414]   Expert 37 |    184 | GPU
DEBUG 01-06 17:11:20.759239.759239 lmp.py:414]   Expert 20 |    186 | GPU
DEBUG 01-06 17:11:20.759974.759974 lmp.py:414]   Expert 19 |    196 | GPU
DEBUG 01-06 17:11:20.759472.759472 lmp.py:414]   Expert 25 |    196 | GPU
DEBUG 01-06 17:11:20.759969.759969 lmp.py:414]   Expert 17 |    197 | GPU
DEBUG 01-06 17:11:20.759704.759704 lmp.py:414]   Expert 43 |    197 | GPU
DEBUG 01-06 17:11:20.759202.759202 lmp.py:414]   Expert 23 |    201 | GPU
DEBUG 01-06 17:11:20.759176.759176 lmp.py:414]   Expert 51 |    204 | GPU
DEBUG 01-06 17:11:20.759150.759150 lmp.py:414]   Expert 11 |    206 | GPU
DEBUG 01-06 17:11:20.759601.759601 lmp.py:414]   Expert 35 |    207 | GPU
DEBUG 01-06 17:11:20.759575.759575 lmp.py:414]   Expert 31 |    208 | GPU
DEBUG 01-06 17:11:20.759072.759072 lmp.py:414]   Expert 49 |    220 | GPU
DEBUG 01-06 17:11:20.759807.759807 lmp.py:414]   Expert 39 |    222 | GPU
DEBUG 01-06 17:11:20.759305.759305 lmp.py:414]   Expert 10 |    227 | GPU
DEBUG 01-06 17:11:20.759040.759040 lmp.py:414]   Expert 53 |    233 | GPU
DEBUG 01-06 17:11:20.759537.759537 lmp.py:414]   Expert 33 |    246 | GPU
DEBUG 01-06 17:11:20.759273.759273 lmp.py:414]   Expert 38 |    268 | GPU
DEBUG 01-06 17:11:20.759770.759770 lmp.py:414]   Expert 36 |    277 | GPU
DEBUG 01-06 17:11:20.759698.759698 lmp.py:414]   Expert  4 |    304 | GPU
DEBUG 01-06 17:11:20.759149.759149 lmp.py:414]   Expert 21 |    327 | GPU
DEBUG 01-06 17:11:20.759646.759646 lmp.py:414]   Expert 14 |    345 | GPU
DEBUG 01-06 17:11:20.759382.759382 lmp.py:414]   Expert 63 |    361 | GPU
DEBUG 01-06 17:11:20.759879.759879 lmp.py:414]   Expert 45 |    362 | GPU
DEBUG 01-06 17:11:20.759615.759615 lmp.py:414]   Expert 61 |    392 | GPU
DEBUG 01-06 17:11:20.759112.759112 lmp.py:414]   Expert  9 |    411 | GPU
DEBUG 01-06 17:11:20.759609.759609 lmp.py:414]   Expert 29 |    484 | GPU
DEBUG 01-06 17:11:20.759345.759345 lmp.py:414]   Expert  7 |    515 | GPU
DEBUG 01-06 17:11:20.759749.759749 lmp.py:415] 
DEBUG 01-06 17:11:20.759749.759749 lmp.py:415]   CPU total tokens: 4033 (32.8%)
DEBUG 01-06 17:11:20.759392.759392 lmp.py:416]   GPU total tokens: 8255 (67.2%)
DEBUG 01-06 17:11:20.759373.759373 cuda_h.py:19] end experts_map_get cost 0.001497507095336914 seconds
DEBUG 01-06 17:11:20.759539.759539 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-06 17:11:20.760938.760938 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 17:11:20.760936.760936 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 17:11:20.763832.763832 cuda_h.py:19] end allocate_cuda_memory cost 0.0035736560821533203 seconds
DEBUG 01-06 17:11:20.763424.763424 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 17:11:20.763326.763326 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 17:11:20.763804.763804 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 17:11:20.763692.763692 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 3bafc372-c7a8-425f-9c8b-ab3020f96f6d
DEBUG 01-06 17:11:20.764766.764766 client.py:106] call stub.LoadModelAsync
INFO 01-06 17:11:20.764937.764937 client.py:127] Model loaded
DEBUG 01-06 17:11:20.764517.764517 cuda_h.py:19] end sllm_worker_task cost 0.011583566665649414 seconds
INFO 01-06 17:11:20.766538.766538 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 3bafc372-c7a8-425f-9c8b-ab3020f96f6d
DEBUG 01-06 17:11:20.766110.766110 cuda_h.py:19] end load_into_gpu_async cost 0.002261638641357422 seconds
DEBUG 01-06 17:11:20.766290.766290 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 17:11:20.766503.766503 cuda_h.py:19] end restore_tensors2 cost 0.0005857944488525391 seconds
DEBUG 01-06 17:11:20.766491.766491 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0068111419677734375 seconds
DEBUG 01-06 17:11:20.769468.769468 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.009506940841674805 seconds
DEBUG 01-06 17:11:20.769238.769238 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-06 17:11:20.769844.769844 lmp.py:461] 
DEBUG 01-06 17:11:20.769844.769844 lmp.py:461]   Computing 32 experts on CPU...
DEBUG 01-06 17:11:20.769601.769601 cuda_h.py:19] end cpu_experts_submit cost 0.00011897087097167969 seconds
DEBUG 01-06 17:11:20.769728.769728 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-06 17:11:20.776033.776033 mlpmodule.py:706] group tensors cost 0.0065784454345703125 s
DEBUG 01-06 17:11:20.780477.780477 mlpmodule.py:744] pad cost 0.002994537353515625 s
DEBUG 01-06 17:11:20.780231.780231 mlpmodule.py:750] create cpu tensor cost 6.771087646484375e-05 s
DEBUG 01-06 17:11:20.780374.780374 mlpmodule.py:755] move to cpu cost 4.3392181396484375e-05 s
DEBUG 01-06 17:11:20.790897.790897 mlpmodule.py:769] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-06 17:11:20.790417.790417 mlpmodule.py:770] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-06 17:11:20.790678.790678 mlpmodule.py:775] group_w3 first element: -0.0034942626953125
WARNING 01-06 17:11:20.790814.790814 mlpmodule.py:785] start einsum2
DEBUG 01-06 17:11:20.808009.808009 mlpmodule.py:795] group einsum cost 0.02757716178894043 s
DEBUG 01-06 17:11:20.809793.809793 mlpmodule.py:803] cpy2cputensor cost 0.0006880760192871094 s
DEBUG 01-06 17:11:20.813748.813748 cuda_h.py:19] end wait_cetm_experts cost 0.04403805732727051 seconds
DEBUG 01-06 17:11:20.814291.814291 cuda_h.py:10] start gpu_sexperts
DEBUG 01-06 17:11:20.814180.814180 cuda_h.py:19] end gpu_sexperts cost 0.0006084442138671875 seconds
DEBUG 01-06 17:11:20.814600.814600 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-06 17:11:20.814403.814403 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.4318695068359375e-05 seconds
DEBUG 01-06 17:11:20.814775.814775 cuda_h.py:10] start wait_experts
INFO 01-06 17:11:20.814485.814485 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 3bafc372-c7a8-425f-9c8b-ab3020f96f6d
INFO 01-06 17:11:20.820539.820539 client.py:127] Model loaded
DEBUG 01-06 17:11:20.820157.820157 cuda_h.py:19] end wait_experts cost 0.006043910980224609 seconds
DEBUG 01-06 17:11:20.821966.821966 cuda_h.py:10] start gpu_experts
DEBUG 01-06 17:11:20.821961.821961 lmp.py:506]   Computing 32 experts on GPU...
DEBUG 01-06 17:11:20.821398.821398 mlpmodule.py:664]  experts func einsum cost 0.051546573638916016 s
DEBUG 01-06 17:11:20.821625.821625 mlpmodule.py:533] gpu group tensors cost 0.0007369518280029297 s
DEBUG 01-06 17:11:20.823088.823088 mlpmodule.py:566] gpu pad cost 0.0018422603607177734 s
DEBUG 01-06 17:11:20.824500.824500 mlpmodule.py:584] gpu group einsum cost 0.0005724430084228516 s
DEBUG 01-06 17:11:20.827133.827133 mlpmodule.py:613] gpu experts func einsum cost 0.00642848014831543 s
DEBUG 01-06 17:11:20.827264.827264 cuda_h.py:19] end gpu_experts cost 0.006686687469482422 seconds
DEBUG 01-06 17:11:20.827023.827023 cuda_h.py:19] end layer_moe_generate_19 cost 0.07011032104492188 seconds
DEBUG 01-06 17:11:20.828513.828513 lmp.py:220] -------------------------------- end layer 19 --------------------------------
DEBUG 01-06 17:11:20.828667.828667 lmp.py:176] -------------------------------- start layer 20 --------------------------------
DEBUG 01-06 17:11:20.828602.828602 cuda_h.py:10] start start_load_qkvogn_s_weight_l_21
DEBUG 01-06 17:11:20.828358.828358 cuda_h.py:10] start start_load_qkvogn_s_weight_l_21
DEBUG 01-06 17:11:20.828486.828486 cuda_h.py:19] end start_load_qkvogn_s_weight_l_21 cost 3.170967102050781e-05 seconds
DEBUG 01-06 17:11:20.828996.828996 cuda_h.py:19] end start_load_qkvogn_s_weight_l_21 cost 6.29425048828125e-05 seconds
DEBUG 01-06 17:11:20.828116.828116 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-06 17:11:20.828582.828582 cuda_h.py:10] start sllm_worker_task
DEBUG 01-06 17:11:20.828335.828335 mlpmodule.py:367] cuda:1 cuda:1
DEBUG 01-06 17:11:20.828204.828204 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 17:11:20.828943.828943 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 17:11:20.828889.828889 cuda_h.py:19] end allocate_cuda_memory cost 0.00034332275390625 seconds
DEBUG 01-06 17:11:20.829098.829098 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 17:11:20.829622.829622 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 17:11:20.829968.829968 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 17:11:20.829240.829240 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, ce929c7c-f51c-4626-99b7-9fe817f1c6c7
DEBUG 01-06 17:11:20.829110.829110 client.py:106] call stub.LoadModelAsync
DEBUG 01-06 17:11:20.829271.829271 cuda_h.py:10] start self_attn
INFO 01-06 17:11:20.830369.830369 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, ce929c7c-f51c-4626-99b7-9fe817f1c6c7
DEBUG 01-06 17:11:20.830490.830490 cuda_h.py:19] end load_into_gpu_async cost 0.0015876293182373047 seconds
DEBUG 01-06 17:11:20.830570.830570 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 17:11:20.830606.830606 cuda_h.py:19] end restore_tensors2 cost 7.104873657226562e-05 seconds
DEBUG 01-06 17:11:20.830647.830647 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.002262592315673828 seconds
INFO 01-06 17:11:20.830205.830205 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, ce929c7c-f51c-4626-99b7-9fe817f1c6c7
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-06 17:11:20.832577.832577 cuda_h.py:19] end self_attn cost 0.002935647964477539 seconds
DEBUG 01-06 17:11:20.832316.832316 cuda_h.py:19] end iln_self_attn_paln cost 0.004542112350463867 seconds
DEBUG 01-06 17:11:20.832774.832774 cuda_h.py:10] start layer_moe_generate_20
DEBUG 01-06 17:11:20.832729.832729 cuda_h.py:10] start gate
DEBUG 01-06 17:11:20.833567.833567 cuda_h.py:19] end gate cost 0.0006539821624755859 seconds
DEBUG 01-06 17:11:20.833966.833966 cuda_h.py:10] start experts_map_get
DEBUG 01-06 17:11:20.833639.833639 lmp.py:403] 
DEBUG 01-06 17:11:20.833639.833639 lmp.py:403] Expert Token Distribution & Device Allocation:
DEBUG 01-06 17:11:20.833918.833918 lmp.py:404]   Total experts: 64
DEBUG 01-06 17:11:20.834614.834614 lmp.py:405]   CPU experts: 32 (50%)
DEBUG 01-06 17:11:20.834449.834449 lmp.py:406]   GPU experts: 32 (50%)
DEBUG 01-06 17:11:20.834138.834138 lmp.py:407] 
DEBUG 01-06 17:11:20.834138.834138 lmp.py:407]   Expert ID | Tokens | Device
DEBUG 01-06 17:11:20.834066.834066 lmp.py:408]   -----------------------------------
DEBUG 01-06 17:11:20.834908.834908 lmp.py:414]   Expert 54 |     22 | CPU
DEBUG 01-06 17:11:20.834789.834789 lmp.py:414]   Expert  3 |     33 | CPU
DEBUG 01-06 17:11:20.834194.834194 lmp.py:414]   Expert 28 |     38 | CPU
DEBUG 01-06 17:11:20.834406.834406 lmp.py:414]   Expert  8 |     43 | CPU
DEBUG 01-06 17:11:20.834381.834381 lmp.py:414]   Expert 43 |     53 | CPU
DEBUG 01-06 17:11:20.834593.834593 lmp.py:414]   Expert 63 |     53 | CPU
DEBUG 01-06 17:11:20.834329.834329 lmp.py:414]   Expert 36 |     57 | CPU
DEBUG 01-06 17:11:20.834210.834210 lmp.py:414]   Expert 38 |     77 | CPU
DEBUG 01-06 17:11:20.834615.834615 lmp.py:414]   Expert  6 |     80 | CPU
DEBUG 01-06 17:11:20.834304.834304 lmp.py:414]   Expert 39 |     92 | CPU
DEBUG 01-06 17:11:20.834755.834755 lmp.py:414]   Expert 52 |    106 | CPU
DEBUG 01-06 17:11:20.834682.834682 lmp.py:414]   Expert 12 |    107 | CPU
DEBUG 01-06 17:11:20.834133.834133 lmp.py:414]   Expert 57 |    111 | CPU
DEBUG 01-06 17:11:20.834538.834538 lmp.py:414]   Expert 41 |    112 | CPU
DEBUG 01-06 17:11:20.834704.834704 lmp.py:414]   Expert 47 |    124 | CPU
DEBUG 01-06 17:11:20.834393.834393 lmp.py:414]   Expert 22 |    126 | CPU
DEBUG 01-06 17:11:20.834606.834606 lmp.py:414]   Expert 13 |    128 | CPU
DEBUG 01-06 17:11:20.834057.834057 lmp.py:414]   Expert 19 |    130 | CPU
DEBUG 01-06 17:11:20.834746.834746 lmp.py:414]   Expert 46 |    145 | CPU
DEBUG 01-06 17:11:20.834197.834197 lmp.py:414]   Expert 50 |    150 | CPU
DEBUG 01-06 17:11:20.834409.834409 lmp.py:414]   Expert 20 |    165 | CPU
DEBUG 01-06 17:11:20.834099.834099 lmp.py:414]   Expert 24 |    165 | CPU
DEBUG 01-06 17:11:20.834550.834550 lmp.py:414]   Expert 55 |    166 | CPU
DEBUG 01-06 17:11:20.834000.834000 lmp.py:414]   Expert 37 |    169 | CPU
DEBUG 01-06 17:11:20.834690.834690 lmp.py:414]   Expert 40 |    169 | CPU
DEBUG 01-06 17:11:20.834617.834617 lmp.py:414]   Expert 49 |    174 | CPU
DEBUG 01-06 17:11:20.834068.834068 lmp.py:414]   Expert 21 |    175 | CPU
DEBUG 01-06 17:11:20.834234.834234 lmp.py:414]   Expert 23 |    177 | CPU
DEBUG 01-06 17:11:20.834924.834924 lmp.py:414]   Expert  2 |    178 | CPU
DEBUG 01-06 17:11:20.834898.834898 lmp.py:414]   Expert 42 |    178 | CPU
DEBUG 01-06 17:11:20.834587.834587 lmp.py:414]   Expert 61 |    178 | CPU
DEBUG 01-06 17:11:20.834038.834038 lmp.py:414]   Expert 53 |    179 | CPU
DEBUG 01-06 17:11:20.834727.834727 lmp.py:414]   Expert 33 |    182 | GPU
DEBUG 01-06 17:11:20.834178.834178 lmp.py:414]   Expert 18 |    195 | GPU
DEBUG 01-06 17:11:20.834629.834629 lmp.py:414]   Expert 14 |    199 | GPU
DEBUG 01-06 17:11:20.834795.834795 lmp.py:414]   Expert 16 |    201 | GPU
DEBUG 01-06 17:11:20.834484.834484 lmp.py:414]   Expert 30 |    201 | GPU
DEBUG 01-06 17:11:20.834174.834174 lmp.py:414]   Expert 32 |    201 | GPU
DEBUG 01-06 17:11:20.834386.834386 lmp.py:414]   Expert  0 |    202 | GPU
DEBUG 01-06 17:11:20.834837.834837 lmp.py:414]   Expert  7 |    206 | GPU
DEBUG 01-06 17:11:20.834765.834765 lmp.py:414]   Expert  5 |    211 | GPU
DEBUG 01-06 17:11:20.834216.834216 lmp.py:414]   Expert 34 |    215 | GPU
DEBUG 01-06 17:11:20.834905.834905 lmp.py:414]   Expert 62 |    215 | GPU
DEBUG 01-06 17:11:20.834833.834833 lmp.py:414]   Expert 17 |    217 | GPU
DEBUG 01-06 17:11:20.834522.834522 lmp.py:414]   Expert 29 |    220 | GPU
DEBUG 01-06 17:11:20.834973.834973 lmp.py:414]   Expert 59 |    220 | GPU
DEBUG 01-06 17:11:20.834424.834424 lmp.py:414]   Expert 31 |    221 | GPU
DEBUG 01-06 17:11:20.834636.834636 lmp.py:414]   Expert 60 |    224 | GPU
DEBUG 01-06 17:11:20.834849.834849 lmp.py:414]   Expert  9 |    225 | GPU
DEBUG 01-06 17:11:20.834538.834538 lmp.py:414]   Expert 10 |    232 | GPU
DEBUG 01-06 17:11:20.834227.834227 lmp.py:414]   Expert 15 |    234 | GPU
DEBUG 01-06 17:11:20.834393.834393 lmp.py:414]   Expert 58 |    236 | GPU
DEBUG 01-06 17:11:20.834844.834844 lmp.py:414]   Expert  4 |    241 | GPU
DEBUG 01-06 17:11:20.834534.834534 lmp.py:414]   Expert 11 |    251 | GPU
DEBUG 01-06 17:11:20.834746.834746 lmp.py:414]   Expert 26 |    252 | GPU
DEBUG 01-06 17:11:20.835959.835959 lmp.py:414]   Expert 51 |    253 | GPU
DEBUG 01-06 17:11:20.835409.835409 lmp.py:414]   Expert 44 |    267 | GPU
DEBUG 01-06 17:11:20.835860.835860 lmp.py:414]   Expert 56 |    286 | GPU
DEBUG 01-06 17:11:20.835550.835550 lmp.py:414]   Expert 27 |    289 | GPU
DEBUG 01-06 17:11:20.835716.835716 lmp.py:414]   Expert  1 |    326 | GPU
DEBUG 01-06 17:11:20.835882.835882 lmp.py:414]   Expert 45 |    353 | GPU
DEBUG 01-06 17:11:20.835810.835810 lmp.py:414]   Expert 25 |    477 | GPU
DEBUG 01-06 17:11:20.835022.835022 lmp.py:414]   Expert 35 |    534 | GPU
DEBUG 01-06 17:11:20.835711.835711 lmp.py:414]   Expert 48 |    642 | GPU
DEBUG 01-06 17:11:20.835116.835116 lmp.py:415] 
DEBUG 01-06 17:11:20.835116.835116 lmp.py:415]   CPU total tokens: 3860 (31.4%)
DEBUG 01-06 17:11:20.835474.835474 lmp.py:416]   GPU total tokens: 8428 (68.6%)
DEBUG 01-06 17:11:20.835886.835886 cuda_h.py:19] end experts_map_get cost 0.001528024673461914 seconds
DEBUG 01-06 17:11:20.835005.835005 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-06 17:11:20.835934.835934 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 17:11:20.835462.835462 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 17:11:20.836123.836123 cuda_h.py:19] end allocate_cuda_memory cost 0.0015072822570800781 seconds
DEBUG 01-06 17:11:20.837887.837887 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 17:11:20.837312.837312 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 17:11:20.837883.837883 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 17:11:20.837294.837294 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 8d369dc4-ade4-41c2-93ff-4e7d4d20411f
DEBUG 01-06 17:11:20.837679.837679 client.py:106] call stub.LoadModelAsync
INFO 01-06 17:11:20.838313.838313 client.py:127] Model loaded
DEBUG 01-06 17:11:20.839932.839932 cuda_h.py:19] end sllm_worker_task cost 0.010689735412597656 seconds
INFO 01-06 17:11:20.840319.840319 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 8d369dc4-ade4-41c2-93ff-4e7d4d20411f
DEBUG 01-06 17:11:20.840891.840891 cuda_h.py:19] end load_into_gpu_async cost 0.0032324790954589844 seconds
DEBUG 01-06 17:11:20.840547.840547 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 17:11:20.840529.840529 cuda_h.py:19] end restore_tensors2 cost 0.0004153251647949219 seconds
DEBUG 01-06 17:11:20.840319.840319 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.005526542663574219 seconds
DEBUG 01-06 17:11:20.843442.843442 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.008265018463134766 seconds
DEBUG 01-06 17:11:20.843239.843239 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-06 17:11:20.843155.843155 lmp.py:461] 
DEBUG 01-06 17:11:20.843155.843155 lmp.py:461]   Computing 32 experts on CPU...
DEBUG 01-06 17:11:20.843859.843859 cuda_h.py:19] end cpu_experts_submit cost 0.00011229515075683594 seconds
DEBUG 01-06 17:11:20.843224.843224 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-06 17:11:20.855306.855306 mlpmodule.py:706] group tensors cost 0.011657953262329102 s
DEBUG 01-06 17:11:20.857125.857125 mlpmodule.py:744] pad cost 0.0017156600952148438 s
DEBUG 01-06 17:11:20.858878.858878 mlpmodule.py:750] create cpu tensor cost 6.175041198730469e-05 s
DEBUG 01-06 17:11:20.858258.858258 mlpmodule.py:755] move to cpu cost 3.3855438232421875e-05 s
DEBUG 01-06 17:11:20.868817.868817 mlpmodule.py:769] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-06 17:11:20.868014.868014 mlpmodule.py:770] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-06 17:11:20.868970.868970 mlpmodule.py:775] group_w3 first element: 0.039306640625
WARNING 01-06 17:11:20.868782.868782 mlpmodule.py:785] start einsum2
DEBUG 01-06 17:11:20.886849.886849 mlpmodule.py:795] group einsum cost 0.02807474136352539 s
DEBUG 01-06 17:11:20.887706.887706 mlpmodule.py:803] cpy2cputensor cost 0.0007183551788330078 s
DEBUG 01-06 17:11:20.891298.891298 cuda_h.py:19] end wait_cetm_experts cost 0.04779529571533203 seconds
DEBUG 01-06 17:11:20.891801.891801 cuda_h.py:10] start gpu_sexperts
DEBUG 01-06 17:11:20.892777.892777 cuda_h.py:19] end gpu_sexperts cost 0.0006387233734130859 seconds
DEBUG 01-06 17:11:20.892442.892442 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-06 17:11:20.892722.892722 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.5987625122070312e-05 seconds
DEBUG 01-06 17:11:20.892902.892902 cuda_h.py:10] start wait_experts
INFO 01-06 17:11:20.892612.892612 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 8d369dc4-ade4-41c2-93ff-4e7d4d20411f
INFO 01-06 17:11:20.894418.894418 client.py:127] Model loaded
DEBUG 01-06 17:11:20.894169.894169 cuda_h.py:19] end wait_experts cost 0.0016045570373535156 seconds
DEBUG 01-06 17:11:20.894302.894302 cuda_h.py:10] start gpu_experts
DEBUG 01-06 17:11:20.894104.894104 lmp.py:506]   Computing 32 experts on GPU...
DEBUG 01-06 17:11:20.895547.895547 mlpmodule.py:533] gpu group tensors cost 0.0006549358367919922 s
DEBUG 01-06 17:11:20.897274.897274 mlpmodule.py:566] gpu pad cost 0.001880645751953125 s
DEBUG 01-06 17:11:20.897774.897774 mlpmodule.py:584] gpu group einsum cost 0.0005807876586914062 s
DEBUG 01-06 17:11:20.899761.899761 mlpmodule.py:664]  experts func einsum cost 0.05514788627624512 s
DEBUG 01-06 17:11:20.901564.901564 mlpmodule.py:613] gpu experts func einsum cost 0.007079362869262695 s
DEBUG 01-06 17:11:20.901187.901187 cuda_h.py:19] end gpu_experts cost 0.007398366928100586 seconds
DEBUG 01-06 17:11:20.901799.901799 cuda_h.py:19] end layer_moe_generate_20 cost 0.06894659996032715 seconds
DEBUG 01-06 17:11:20.902218.902218 lmp.py:220] -------------------------------- end layer 20 --------------------------------
DEBUG 01-06 17:11:20.902094.902094 lmp.py:176] -------------------------------- start layer 21 --------------------------------
DEBUG 01-06 17:11:20.902220.902220 cuda_h.py:10] start start_load_qkvogn_s_weight_l_22
DEBUG 01-06 17:11:20.902168.902168 cuda_h.py:10] start start_load_qkvogn_s_weight_l_22
DEBUG 01-06 17:11:20.902912.902912 cuda_h.py:19] end start_load_qkvogn_s_weight_l_22 cost 3.0994415283203125e-05 seconds
DEBUG 01-06 17:11:20.902615.902615 cuda_h.py:19] end start_load_qkvogn_s_weight_l_22 cost 6.198883056640625e-05 seconds
DEBUG 01-06 17:11:20.902404.902404 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-06 17:11:20.902346.902346 cuda_h.py:10] start sllm_worker_task
DEBUG 01-06 17:11:20.902324.902324 mlpmodule.py:367] cuda:1 cuda:1
DEBUG 01-06 17:11:20.902524.902524 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 17:11:20.902754.902754 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 17:11:20.903964.903964 cuda_h.py:19] end allocate_cuda_memory cost 0.00032448768615722656 seconds
DEBUG 01-06 17:11:20.903054.903054 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 17:11:20.903247.903247 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 17:11:20.903547.903547 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 17:11:20.903011.903011 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 54dbe780-fd3f-4e8c-b05a-1ab259e3e284
DEBUG 01-06 17:11:20.903736.903736 client.py:106] call stub.LoadModelAsync
DEBUG 01-06 17:11:20.903559.903559 cuda_h.py:10] start self_attn
INFO 01-06 17:11:20.904762.904762 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 54dbe780-fd3f-4e8c-b05a-1ab259e3e284
DEBUG 01-06 17:11:20.904506.904506 cuda_h.py:19] end load_into_gpu_async cost 0.0015952587127685547 seconds
DEBUG 01-06 17:11:20.904017.904017 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 17:11:20.904868.904868 cuda_h.py:19] end restore_tensors2 cost 7.43865966796875e-05 seconds
DEBUG 01-06 17:11:20.904624.904624 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0022923946380615234 seconds
INFO 01-06 17:11:20.904699.904699 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 54dbe780-fd3f-4e8c-b05a-1ab259e3e284
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-06 17:11:20.906480.906480 cuda_h.py:19] end self_attn cost 0.002933502197265625 seconds
DEBUG 01-06 17:11:20.906795.906795 cuda_h.py:19] end iln_self_attn_paln cost 0.00454258918762207 seconds
DEBUG 01-06 17:11:20.906731.906731 cuda_h.py:10] start layer_moe_generate_21
DEBUG 01-06 17:11:20.906209.906209 cuda_h.py:10] start gate
DEBUG 01-06 17:11:20.907470.907470 cuda_h.py:19] end gate cost 0.0006494522094726562 seconds
DEBUG 01-06 17:11:20.907061.907061 cuda_h.py:10] start experts_map_get
DEBUG 01-06 17:11:20.908973.908973 lmp.py:403] 
DEBUG 01-06 17:11:20.908973.908973 lmp.py:403] Expert Token Distribution & Device Allocation:
DEBUG 01-06 17:11:20.908729.908729 lmp.py:404]   Total experts: 64
DEBUG 01-06 17:11:20.908902.908902 lmp.py:405]   CPU experts: 32 (50%)
DEBUG 01-06 17:11:20.908737.908737 lmp.py:406]   GPU experts: 32 (50%)
DEBUG 01-06 17:11:20.908426.908426 lmp.py:407] 
DEBUG 01-06 17:11:20.908426.908426 lmp.py:407]   Expert ID | Tokens | Device
DEBUG 01-06 17:11:20.908354.908354 lmp.py:408]   -----------------------------------
DEBUG 01-06 17:11:20.908003.908003 lmp.py:414]   Expert  9 |     27 | CPU
DEBUG 01-06 17:11:20.908408.908408 lmp.py:414]   Expert 44 |     28 | CPU
DEBUG 01-06 17:11:20.908097.908097 lmp.py:414]   Expert 11 |     30 | CPU
DEBUG 01-06 17:11:20.908217.908217 lmp.py:414]   Expert 56 |     57 | CPU
DEBUG 01-06 17:11:20.908383.908383 lmp.py:414]   Expert 54 |     80 | CPU
DEBUG 01-06 17:11:20.908596.908596 lmp.py:414]   Expert  7 |     87 | CPU
DEBUG 01-06 17:11:20.908570.908570 lmp.py:414]   Expert 62 |     91 | CPU
DEBUG 01-06 17:11:20.908451.908451 lmp.py:414]   Expert 47 |     92 | CPU
DEBUG 01-06 17:11:20.908140.908140 lmp.py:414]   Expert 60 |    103 | CPU
DEBUG 01-06 17:11:20.908307.908307 lmp.py:414]   Expert 41 |    108 | CPU
DEBUG 01-06 17:11:20.908996.908996 lmp.py:414]   Expert 53 |    109 | CPU
DEBUG 01-06 17:11:20.908162.908162 lmp.py:414]   Expert 52 |    110 | CPU
DEBUG 01-06 17:11:20.908328.908328 lmp.py:414]   Expert 51 |    114 | CPU
DEBUG 01-06 17:11:20.908018.908018 lmp.py:414]   Expert 22 |    117 | CPU
DEBUG 01-06 17:11:20.908813.908813 lmp.py:414]   Expert  8 |    122 | CPU
DEBUG 01-06 17:11:20.908218.908218 lmp.py:414]   Expert 32 |    123 | CPU
DEBUG 01-06 17:11:20.908430.908430 lmp.py:414]   Expert  6 |    126 | CPU
DEBUG 01-06 17:11:20.908881.908881 lmp.py:414]   Expert 48 |    126 | CPU
DEBUG 01-06 17:11:20.908570.908570 lmp.py:414]   Expert  1 |    128 | CPU
DEBUG 01-06 17:11:20.908736.908736 lmp.py:414]   Expert 27 |    138 | CPU
DEBUG 01-06 17:11:20.908903.908903 lmp.py:414]   Expert 39 |    140 | CPU
DEBUG 01-06 17:11:20.908830.908830 lmp.py:414]   Expert 26 |    141 | CPU
DEBUG 01-06 17:11:20.908520.908520 lmp.py:414]   Expert 35 |    141 | CPU
DEBUG 01-06 17:11:20.908209.908209 lmp.py:414]   Expert 59 |    142 | CPU
DEBUG 01-06 17:11:20.908898.908898 lmp.py:414]   Expert 23 |    143 | CPU
DEBUG 01-06 17:11:20.908349.908349 lmp.py:414]   Expert  2 |    145 | CPU
DEBUG 01-06 17:11:20.908038.908038 lmp.py:414]   Expert 50 |    150 | CPU
DEBUG 01-06 17:11:20.908443.908443 lmp.py:414]   Expert 14 |    154 | CPU
DEBUG 01-06 17:11:20.908609.908609 lmp.py:414]   Expert 24 |    157 | CPU
DEBUG 01-06 17:11:20.908060.908060 lmp.py:414]   Expert 34 |    171 | CPU
DEBUG 01-06 17:11:20.908511.908511 lmp.py:414]   Expert 38 |    172 | CPU
DEBUG 01-06 17:11:20.908200.908200 lmp.py:414]   Expert 46 |    173 | CPU
DEBUG 01-06 17:11:20.908889.908889 lmp.py:414]   Expert 49 |    173 | GPU
DEBUG 01-06 17:11:20.908579.908579 lmp.py:414]   Expert  0 |    174 | GPU
DEBUG 01-06 17:11:20.908268.908268 lmp.py:414]   Expert  4 |    176 | GPU
DEBUG 01-06 17:11:20.908957.908957 lmp.py:414]   Expert 63 |    181 | GPU
DEBUG 01-06 17:11:20.908600.908600 lmp.py:414]   Expert 40 |    185 | GPU
DEBUG 01-06 17:11:20.908528.908528 lmp.py:414]   Expert  5 |    188 | GPU
DEBUG 01-06 17:11:20.908217.908217 lmp.py:414]   Expert 19 |    190 | GPU
DEBUG 01-06 17:11:20.908907.908907 lmp.py:414]   Expert 29 |    198 | GPU
DEBUG 01-06 17:11:20.908596.908596 lmp.py:414]   Expert 13 |    203 | GPU
DEBUG 01-06 17:11:20.908047.908047 lmp.py:414]   Expert 43 |    204 | GPU
DEBUG 01-06 17:11:20.908213.908213 lmp.py:414]   Expert 57 |    217 | GPU
DEBUG 01-06 17:11:20.908902.908902 lmp.py:414]   Expert 61 |    218 | GPU
DEBUG 01-06 17:11:20.908353.908353 lmp.py:414]   Expert 33 |    224 | GPU
DEBUG 01-06 17:11:20.908281.908281 lmp.py:414]   Expert 15 |    240 | GPU
DEBUG 01-06 17:11:20.908732.908732 lmp.py:414]   Expert 20 |    246 | GPU
DEBUG 01-06 17:11:20.908183.908183 lmp.py:414]   Expert 31 |    250 | GPU
DEBUG 01-06 17:11:20.908872.908872 lmp.py:414]   Expert  3 |    252 | GPU
DEBUG 01-06 17:11:20.908323.908323 lmp.py:414]   Expert 16 |    254 | GPU
DEBUG 01-06 17:11:20.908774.908774 lmp.py:414]   Expert 37 |    257 | GPU
DEBUG 01-06 17:11:20.909940.909940 lmp.py:414]   Expert 36 |    271 | GPU
DEBUG 01-06 17:11:20.909821.909821 lmp.py:414]   Expert 12 |    276 | GPU
DEBUG 01-06 17:11:20.909034.909034 lmp.py:414]   Expert 18 |    281 | GPU
DEBUG 01-06 17:11:20.909723.909723 lmp.py:414]   Expert 28 |    296 | GPU
DEBUG 01-06 17:11:20.909174.909174 lmp.py:414]   Expert 25 |    311 | GPU
DEBUG 01-06 17:11:20.909386.909386 lmp.py:414]   Expert 55 |    313 | GPU
DEBUG 01-06 17:11:20.909837.909837 lmp.py:414]   Expert 17 |    315 | GPU
DEBUG 01-06 17:11:20.909050.909050 lmp.py:414]   Expert 30 |    332 | GPU
DEBUG 01-06 17:11:20.909216.909216 lmp.py:414]   Expert 58 |    333 | GPU
DEBUG 01-06 17:11:20.909859.909859 lmp.py:414]   Expert 10 |    366 | GPU
DEBUG 01-06 17:11:20.909548.909548 lmp.py:414]   Expert 45 |    379 | GPU
DEBUG 01-06 17:11:20.909999.909999 lmp.py:414]   Expert 21 |    387 | GPU
DEBUG 01-06 17:11:20.909688.909688 lmp.py:414]   Expert 42 |    653 | GPU
DEBUG 01-06 17:11:20.909093.909093 lmp.py:415] 
DEBUG 01-06 17:11:20.909093.909093 lmp.py:415]   CPU total tokens: 3745 (30.5%)
DEBUG 01-06 17:11:20.909974.909974 lmp.py:416]   GPU total tokens: 8543 (69.5%)
DEBUG 01-06 17:11:20.909147.909147 cuda_h.py:19] end experts_map_get cost 0.001544952392578125 seconds
DEBUG 01-06 17:11:20.909982.909982 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-06 17:11:20.909242.909242 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 17:11:20.909062.909062 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 17:11:20.911955.911955 cuda_h.py:19] end allocate_cuda_memory cost 0.0015380382537841797 seconds
DEBUG 01-06 17:11:20.911196.911196 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 17:11:20.911860.911860 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 17:11:20.911715.911715 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 17:11:20.911126.911126 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, f3e62d38-9913-412d-a72f-5c19606883fa
DEBUG 01-06 17:11:20.911504.911504 client.py:106] call stub.LoadModelAsync
INFO 01-06 17:11:20.912855.912855 client.py:127] Model loaded
DEBUG 01-06 17:11:20.913888.913888 cuda_h.py:19] end sllm_worker_task cost 0.010667800903320312 seconds
INFO 01-06 17:11:20.914238.914238 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, f3e62d38-9913-412d-a72f-5c19606883fa
DEBUG 01-06 17:11:20.914664.914664 cuda_h.py:19] end load_into_gpu_async cost 0.0032591819763183594 seconds
DEBUG 01-06 17:11:20.914367.914367 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 17:11:20.914018.914018 cuda_h.py:19] end restore_tensors2 cost 0.0004181861877441406 seconds
DEBUG 01-06 17:11:20.914662.914662 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.005588531494140625 seconds
DEBUG 01-06 17:11:20.917055.917055 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.008487939834594727 seconds
DEBUG 01-06 17:11:20.917475.917475 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-06 17:11:20.917100.917100 lmp.py:461] 
DEBUG 01-06 17:11:20.917100.917100 lmp.py:461]   Computing 32 experts on CPU...
DEBUG 01-06 17:11:20.918447.918447 cuda_h.py:19] end cpu_experts_submit cost 0.00012755393981933594 seconds
DEBUG 01-06 17:11:20.918335.918335 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-06 17:11:20.928616.928616 mlpmodule.py:706] group tensors cost 0.009762048721313477 s
DEBUG 01-06 17:11:20.930365.930365 mlpmodule.py:744] pad cost 0.001603841781616211 s
DEBUG 01-06 17:11:20.930144.930144 mlpmodule.py:750] create cpu tensor cost 5.173683166503906e-05 s
DEBUG 01-06 17:11:20.930762.930762 mlpmodule.py:755] move to cpu cost 3.361701965332031e-05 s
DEBUG 01-06 17:11:20.940876.940876 mlpmodule.py:769] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-06 17:11:20.940840.940840 mlpmodule.py:770] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-06 17:11:20.940373.940373 mlpmodule.py:775] group_w3 first element: 0.00066375732421875
WARNING 01-06 17:11:20.940602.940602 mlpmodule.py:785] start einsum2
DEBUG 01-06 17:11:20.958046.958046 mlpmodule.py:795] group einsum cost 0.02819347381591797 s
DEBUG 01-06 17:11:20.959048.959048 mlpmodule.py:803] cpy2cputensor cost 0.0006778240203857422 s
DEBUG 01-06 17:11:20.963939.963939 cuda_h.py:19] end wait_cetm_experts cost 0.0458369255065918 seconds
DEBUG 01-06 17:11:20.964773.964773 cuda_h.py:10] start gpu_sexperts
DEBUG 01-06 17:11:20.964472.964472 cuda_h.py:19] end gpu_sexperts cost 0.0006470680236816406 seconds
DEBUG 01-06 17:11:20.964851.964851 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-06 17:11:20.964085.964085 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.5033950805664062e-05 seconds
DEBUG 01-06 17:11:20.965980.965980 cuda_h.py:10] start wait_experts
INFO 01-06 17:11:20.965452.965452 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, f3e62d38-9913-412d-a72f-5c19606883fa
INFO 01-06 17:11:20.968885.968885 client.py:127] Model loaded
DEBUG 01-06 17:11:20.968881.968881 cuda_h.py:19] end wait_experts cost 0.003722667694091797 seconds
DEBUG 01-06 17:11:20.968206.968206 cuda_h.py:10] start gpu_experts
DEBUG 01-06 17:11:20.968247.968247 lmp.py:506]   Computing 32 experts on GPU...
DEBUG 01-06 17:11:20.969041.969041 mlpmodule.py:533] gpu group tensors cost 0.0006692409515380859 s
DEBUG 01-06 17:11:20.971984.971984 mlpmodule.py:566] gpu pad cost 0.0017926692962646484 s
DEBUG 01-06 17:11:20.971424.971424 mlpmodule.py:664]  experts func einsum cost 0.053502798080444336 s
DEBUG 01-06 17:11:20.972255.972255 mlpmodule.py:584] gpu group einsum cost 0.0006978511810302734 s
DEBUG 01-06 17:11:20.975972.975972 mlpmodule.py:613] gpu experts func einsum cost 0.006727695465087891 s
DEBUG 01-06 17:11:20.975931.975931 cuda_h.py:19] end gpu_experts cost 0.006966114044189453 seconds
DEBUG 01-06 17:11:20.975835.975835 cuda_h.py:19] end layer_moe_generate_21 cost 0.06893634796142578 seconds
DEBUG 01-06 17:11:20.976405.976405 lmp.py:220] -------------------------------- end layer 21 --------------------------------
DEBUG 01-06 17:11:20.976929.976929 lmp.py:176] -------------------------------- start layer 22 --------------------------------
DEBUG 01-06 17:11:20.976102.976102 cuda_h.py:10] start start_load_qkvogn_s_weight_l_23
DEBUG 01-06 17:11:20.976335.976335 cuda_h.py:10] start start_load_qkvogn_s_weight_l_23
DEBUG 01-06 17:11:20.976562.976562 cuda_h.py:19] end start_load_qkvogn_s_weight_l_23 cost 3.528594970703125e-05 seconds
DEBUG 01-06 17:11:20.976550.976550 cuda_h.py:19] end start_load_qkvogn_s_weight_l_23 cost 6.651878356933594e-05 seconds
DEBUG 01-06 17:11:20.976670.976670 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-06 17:11:20.976413.976413 cuda_h.py:10] start sllm_worker_task
DEBUG 01-06 17:11:20.976823.976823 mlpmodule.py:367] cuda:1 cuda:1
DEBUG 01-06 17:11:20.976261.976261 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 17:11:20.976908.976908 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 17:11:20.977098.977098 cuda_h.py:19] end allocate_cuda_memory cost 0.00031185150146484375 seconds
DEBUG 01-06 17:11:20.977691.977691 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 17:11:20.977884.977884 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 17:11:20.977514.977514 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 17:11:20.977217.977217 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, daeee94b-0af3-4374-a7e8-74252066f59d
DEBUG 01-06 17:11:20.977372.977372 client.py:106] call stub.LoadModelAsync
DEBUG 01-06 17:11:20.977911.977911 cuda_h.py:10] start self_attn
INFO 01-06 17:11:20.978087.978087 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, daeee94b-0af3-4374-a7e8-74252066f59d
DEBUG 01-06 17:11:20.978162.978162 cuda_h.py:19] end load_into_gpu_async cost 0.0015747547149658203 seconds
DEBUG 01-06 17:11:20.978480.978480 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 17:11:20.978232.978232 cuda_h.py:19] end restore_tensors2 cost 7.152557373046875e-05 seconds
DEBUG 01-06 17:11:20.978319.978319 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0022230148315429688 seconds
INFO 01-06 17:11:20.978341.978341 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, daeee94b-0af3-4374-a7e8-74252066f59d
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-06 17:11:20.980572.980572 cuda_h.py:19] end self_attn cost 0.002882242202758789 seconds
DEBUG 01-06 17:11:20.980589.980589 cuda_h.py:19] end iln_self_attn_paln cost 0.004376649856567383 seconds
DEBUG 01-06 17:11:20.980001.980001 cuda_h.py:10] start layer_moe_generate_22
DEBUG 01-06 17:11:20.980718.980718 cuda_h.py:10] start gate
DEBUG 01-06 17:11:20.981780.981780 cuda_h.py:19] end gate cost 0.0006442070007324219 seconds
DEBUG 01-06 17:11:20.981179.981179 cuda_h.py:10] start experts_map_get
DEBUG 01-06 17:11:20.981845.981845 lmp.py:403] 
DEBUG 01-06 17:11:20.981845.981845 lmp.py:403] Expert Token Distribution & Device Allocation:
DEBUG 01-06 17:11:20.981363.981363 lmp.py:404]   Total experts: 64
DEBUG 01-06 17:11:20.981251.981251 lmp.py:405]   CPU experts: 32 (50%)
DEBUG 01-06 17:11:20.982040.982040 lmp.py:406]   GPU experts: 32 (50%)
DEBUG 01-06 17:11:20.982206.982206 lmp.py:407] 
DEBUG 01-06 17:11:20.982206.982206 lmp.py:407]   Expert ID | Tokens | Device
DEBUG 01-06 17:11:20.982134.982134 lmp.py:408]   -----------------------------------
DEBUG 01-06 17:11:20.982260.982260 lmp.py:414]   Expert 25 |     15 | CPU
DEBUG 01-06 17:11:20.982426.982426 lmp.py:414]   Expert 48 |     31 | CPU
DEBUG 01-06 17:11:20.982116.982116 lmp.py:414]   Expert 45 |     34 | CPU
DEBUG 01-06 17:11:20.982567.982567 lmp.py:414]   Expert  9 |     56 | CPU
DEBUG 01-06 17:11:20.982256.982256 lmp.py:414]   Expert 54 |     74 | CPU
DEBUG 01-06 17:11:20.982707.982707 lmp.py:414]   Expert  0 |     84 | CPU
DEBUG 01-06 17:11:20.982158.982158 lmp.py:414]   Expert 43 |     84 | CPU
DEBUG 01-06 17:11:20.982132.982132 lmp.py:414]   Expert  6 |     86 | CPU
DEBUG 01-06 17:11:20.982867.982867 lmp.py:414]   Expert 57 |     86 | CPU
DEBUG 01-06 17:11:20.982603.982603 lmp.py:414]   Expert 20 |     90 | CPU
DEBUG 01-06 17:11:20.982246.982246 lmp.py:414]   Expert 47 |     97 | CPU
DEBUG 01-06 17:11:20.982935.982935 lmp.py:414]   Expert 61 |     97 | CPU
DEBUG 01-06 17:11:20.982624.982624 lmp.py:414]   Expert 36 |     98 | CPU
DEBUG 01-06 17:11:20.982075.982075 lmp.py:414]   Expert 62 |     99 | CPU
DEBUG 01-06 17:11:20.982241.982241 lmp.py:414]   Expert 46 |    100 | CPU
DEBUG 01-06 17:11:20.982931.982931 lmp.py:414]   Expert 13 |    101 | CPU
DEBUG 01-06 17:11:20.982620.982620 lmp.py:414]   Expert  1 |    107 | CPU
DEBUG 01-06 17:11:20.982309.982309 lmp.py:414]   Expert 15 |    108 | CPU
DEBUG 01-06 17:11:20.982522.982522 lmp.py:414]   Expert 50 |    108 | CPU
DEBUG 01-06 17:11:20.982973.982973 lmp.py:414]   Expert 37 |    112 | CPU
DEBUG 01-06 17:11:20.982424.982424 lmp.py:414]   Expert 14 |    116 | CPU
DEBUG 01-06 17:11:20.982875.982875 lmp.py:414]   Expert 38 |    124 | CPU
DEBUG 01-06 17:11:20.982087.982087 lmp.py:414]   Expert 21 |    130 | CPU
DEBUG 01-06 17:11:20.982776.982776 lmp.py:414]   Expert 44 |    132 | CPU
DEBUG 01-06 17:11:20.982466.982466 lmp.py:414]   Expert 52 |    135 | CPU
DEBUG 01-06 17:11:20.982393.982393 lmp.py:414]   Expert 28 |    147 | CPU
DEBUG 01-06 17:11:20.982844.982844 lmp.py:414]   Expert  7 |    148 | CPU
DEBUG 01-06 17:11:20.982295.982295 lmp.py:414]   Expert 10 |    150 | CPU
DEBUG 01-06 17:11:20.982508.982508 lmp.py:414]   Expert 42 |    161 | CPU
DEBUG 01-06 17:11:20.982197.982197 lmp.py:414]   Expert 24 |    162 | CPU
DEBUG 01-06 17:11:20.982409.982409 lmp.py:414]   Expert 11 |    163 | CPU
DEBUG 01-06 17:11:20.982337.982337 lmp.py:414]   Expert  2 |    166 | CPU
DEBUG 01-06 17:11:20.982742.982742 lmp.py:414]   Expert 31 |    168 | GPU
DEBUG 01-06 17:11:20.982669.982669 lmp.py:414]   Expert 26 |    169 | GPU
DEBUG 01-06 17:11:20.982359.982359 lmp.py:414]   Expert 35 |    173 | GPU
DEBUG 01-06 17:11:20.982048.982048 lmp.py:414]   Expert  3 |    181 | GPU
DEBUG 01-06 17:11:20.982260.982260 lmp.py:414]   Expert 32 |    183 | GPU
DEBUG 01-06 17:11:20.982711.982711 lmp.py:414]   Expert 19 |    184 | GPU
DEBUG 01-06 17:11:20.982401.982401 lmp.py:414]   Expert 12 |    187 | GPU
DEBUG 01-06 17:11:20.982851.982851 lmp.py:414]   Expert 40 |    200 | GPU
DEBUG 01-06 17:11:20.982494.982494 lmp.py:414]   Expert 60 |    201 | GPU
DEBUG 01-06 17:11:20.982661.982661 lmp.py:414]   Expert 56 |    208 | GPU
DEBUG 01-06 17:11:20.982111.982111 lmp.py:414]   Expert 41 |    213 | GPU
DEBUG 01-06 17:11:20.982562.982562 lmp.py:414]   Expert 53 |    225 | GPU
DEBUG 01-06 17:11:20.982013.982013 lmp.py:414]   Expert 58 |    228 | GPU
DEBUG 01-06 17:11:20.982464.982464 lmp.py:414]   Expert 51 |    231 | GPU
DEBUG 01-06 17:11:20.982677.982677 lmp.py:414]   Expert 23 |    234 | GPU
DEBUG 01-06 17:11:20.982889.982889 lmp.py:414]   Expert 16 |    237 | GPU
DEBUG 01-06 17:11:20.982055.982055 lmp.py:414]   Expert  8 |    243 | GPU
DEBUG 01-06 17:11:20.982175.982175 lmp.py:414]   Expert 59 |    256 | GPU
DEBUG 01-06 17:11:20.982864.982864 lmp.py:414]   Expert  4 |    262 | GPU
DEBUG 01-06 17:11:20.982077.982077 lmp.py:414]   Expert 18 |    281 | GPU
DEBUG 01-06 17:11:20.982289.982289 lmp.py:414]   Expert 49 |    282 | GPU
DEBUG 01-06 17:11:20.982740.982740 lmp.py:414]   Expert 55 |    282 | GPU
DEBUG 01-06 17:11:20.982191.982191 lmp.py:414]   Expert 29 |    286 | GPU
DEBUG 01-06 17:11:20.982880.982880 lmp.py:414]   Expert 63 |    291 | GPU
DEBUG 01-06 17:11:20.983331.983331 lmp.py:414]   Expert 34 |    295 | GPU
DEBUG 01-06 17:11:20.983497.983497 lmp.py:414]   Expert 27 |    355 | GPU
DEBUG 01-06 17:11:20.983425.983425 lmp.py:414]   Expert 39 |    379 | GPU
DEBUG 01-06 17:11:20.983114.983114 lmp.py:414]   Expert 17 |    396 | GPU
DEBUG 01-06 17:11:20.983565.983565 lmp.py:414]   Expert 22 |    423 | GPU
DEBUG 01-06 17:11:20.983778.983778 lmp.py:414]   Expert 30 |    450 | GPU
DEBUG 01-06 17:11:20.983228.983228 lmp.py:414]   Expert 33 |    458 | GPU
DEBUG 01-06 17:11:20.983679.983679 lmp.py:414]   Expert  5 |    726 | GPU
DEBUG 01-06 17:11:20.983845.983845 lmp.py:415] 
DEBUG 01-06 17:11:20.983845.983845 lmp.py:415]   CPU total tokens: 3401 (27.7%)
DEBUG 01-06 17:11:20.983250.983250 lmp.py:416]   GPU total tokens: 8887 (72.3%)
DEBUG 01-06 17:11:20.983185.983185 cuda_h.py:19] end experts_map_get cost 0.0015208721160888672 seconds
DEBUG 01-06 17:11:20.983543.983543 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-06 17:11:20.983942.983942 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 17:11:20.983708.983708 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 17:11:20.985202.985202 cuda_h.py:19] end allocate_cuda_memory cost 0.001664876937866211 seconds
DEBUG 01-06 17:11:20.985158.985158 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 17:11:20.985106.985106 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 17:11:20.985723.985723 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 17:11:20.985896.985896 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 814b4078-e048-4e83-ba92-0df128dd19f9
DEBUG 01-06 17:11:20.985989.985989 client.py:106] call stub.LoadModelAsync
INFO 01-06 17:11:20.986891.986891 client.py:127] Model loaded
DEBUG 01-06 17:11:20.987784.987784 cuda_h.py:19] end sllm_worker_task cost 0.010682106018066406 seconds
INFO 01-06 17:11:20.988086.988086 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 814b4078-e048-4e83-ba92-0df128dd19f9
DEBUG 01-06 17:11:20.988327.988327 cuda_h.py:19] end load_into_gpu_async cost 0.003214597702026367 seconds
DEBUG 01-06 17:11:20.988937.988937 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 17:11:20.988097.988097 cuda_h.py:19] end restore_tensors2 cost 0.00040721893310546875 seconds
DEBUG 01-06 17:11:20.988741.988741 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.005658626556396484 seconds
DEBUG 01-06 17:11:20.991208.991208 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.008363962173461914 seconds
DEBUG 01-06 17:11:20.991435.991435 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-06 17:11:20.991683.991683 lmp.py:461] 
DEBUG 01-06 17:11:20.991683.991683 lmp.py:461]   Computing 32 experts on CPU...
DEBUG 01-06 17:11:20.991838.991838 cuda_h.py:19] end cpu_experts_submit cost 0.0001285076141357422 seconds
DEBUG 01-06 17:11:20.991203.991203 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-06 17:11:21.003371.003371 mlpmodule.py:706] group tensors cost 0.011898517608642578 s
DEBUG 01-06 17:11:21.006169.006169 mlpmodule.py:744] pad cost 0.0016655921936035156 s
DEBUG 01-06 17:11:21.006173.006173 mlpmodule.py:750] create cpu tensor cost 4.696846008300781e-05 s
DEBUG 01-06 17:11:21.006691.006691 mlpmodule.py:755] move to cpu cost 3.266334533691406e-05 s
DEBUG 01-06 17:11:21.016223.016223 mlpmodule.py:769] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-06 17:11:21.016975.016975 mlpmodule.py:770] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-06 17:11:21.016977.016977 mlpmodule.py:775] group_w3 first element: -0.018798828125
WARNING 01-06 17:11:21.016927.016927 mlpmodule.py:785] start einsum2
DEBUG 01-06 17:11:21.036976.036976 mlpmodule.py:795] group einsum cost 0.03010845184326172 s
DEBUG 01-06 17:11:21.037536.037536 mlpmodule.py:803] cpy2cputensor cost 0.0006771087646484375 s
DEBUG 01-06 17:11:21.042742.042742 cuda_h.py:19] end wait_cetm_experts cost 0.05063366889953613 seconds
DEBUG 01-06 17:11:21.042543.042543 cuda_h.py:10] start gpu_sexperts
DEBUG 01-06 17:11:21.043223.043223 cuda_h.py:19] end gpu_sexperts cost 0.0006611347198486328 seconds
DEBUG 01-06 17:11:21.043139.043139 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-06 17:11:21.043049.043049 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 3.218650817871094e-05 seconds
DEBUG 01-06 17:11:21.043183.043183 cuda_h.py:10] start wait_experts
INFO 01-06 17:11:21.043276.043276 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 814b4078-e048-4e83-ba92-0df128dd19f9
INFO 01-06 17:11:21.045609.045609 client.py:127] Model loaded
DEBUG 01-06 17:11:21.045420.045420 cuda_h.py:19] end wait_experts cost 0.0015110969543457031 seconds
DEBUG 01-06 17:11:21.045222.045222 cuda_h.py:10] start gpu_experts
DEBUG 01-06 17:11:21.045362.045362 lmp.py:506]   Computing 32 experts on GPU...
DEBUG 01-06 17:11:21.046679.046679 mlpmodule.py:533] gpu group tensors cost 0.0006654262542724609 s
DEBUG 01-06 17:11:21.047598.047598 mlpmodule.py:566] gpu pad cost 0.00188446044921875 s
DEBUG 01-06 17:11:21.048304.048304 mlpmodule.py:584] gpu group einsum cost 0.0005955696105957031 s
DEBUG 01-06 17:11:21.049534.049534 mlpmodule.py:664]  experts func einsum cost 0.05776810646057129 s
DEBUG 01-06 17:11:21.052819.052819 mlpmodule.py:613] gpu experts func einsum cost 0.00700688362121582 s
DEBUG 01-06 17:11:21.052182.052182 cuda_h.py:19] end gpu_experts cost 0.0072782039642333984 seconds
DEBUG 01-06 17:11:21.052656.052656 cuda_h.py:19] end layer_moe_generate_22 cost 0.07172822952270508 seconds
DEBUG 01-06 17:11:21.052512.052512 lmp.py:220] -------------------------------- end layer 22 --------------------------------
DEBUG 01-06 17:11:21.052480.052480 lmp.py:176] -------------------------------- start layer 23 --------------------------------
DEBUG 01-06 17:11:21.052607.052607 cuda_h.py:10] start start_load_qkvogn_s_weight_l_24
DEBUG 01-06 17:11:21.052700.052700 cuda_h.py:10] start start_load_qkvogn_s_weight_l_24
DEBUG 01-06 17:11:21.053398.053398 cuda_h.py:19] end start_load_qkvogn_s_weight_l_24 cost 3.218650817871094e-05 seconds
DEBUG 01-06 17:11:21.053531.053531 cuda_h.py:19] end start_load_qkvogn_s_weight_l_24 cost 6.365776062011719e-05 seconds
DEBUG 01-06 17:11:21.053558.053558 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-06 17:11:21.053209.053209 cuda_h.py:10] start sllm_worker_task
DEBUG 01-06 17:11:21.053570.053570 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 17:11:21.053068.053068 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 17:11:21.053372.053372 cuda_h.py:19] end allocate_cuda_memory cost 0.00032639503479003906 seconds
DEBUG 01-06 17:11:21.053806.053806 mlpmodule.py:367] cuda:1 cuda:1
DEBUG 01-06 17:11:21.053318.053318 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 17:11:21.053461.053461 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 17:11:21.053913.053913 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 17:11:21.053900.053900 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 76ed6dee-1269-4ba9-87b7-def503d23834
DEBUG 01-06 17:11:21.054870.054870 client.py:106] call stub.LoadModelAsync
DEBUG 01-06 17:11:21.054754.054754 cuda_h.py:10] start self_attn
INFO 01-06 17:11:21.055898.055898 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 76ed6dee-1269-4ba9-87b7-def503d23834
DEBUG 01-06 17:11:21.055496.055496 cuda_h.py:19] end load_into_gpu_async cost 0.0016407966613769531 seconds
DEBUG 01-06 17:11:21.055053.055053 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 17:11:21.055520.055520 cuda_h.py:19] end restore_tensors2 cost 7.2479248046875e-05 seconds
DEBUG 01-06 17:11:21.055037.055037 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0024573802947998047 seconds
INFO 01-06 17:11:21.055443.055443 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 76ed6dee-1269-4ba9-87b7-def503d23834
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-06 17:11:21.058278.058278 cuda_h.py:19] end self_attn cost 0.0039043426513671875 seconds
DEBUG 01-06 17:11:21.060513.060513 cuda_h.py:19] end iln_self_attn_paln cost 0.007134914398193359 seconds
DEBUG 01-06 17:11:21.061272.061272 cuda_h.py:10] start layer_moe_generate_23
DEBUG 01-06 17:11:21.063474.063474 cuda_h.py:10] start gate
INFO 01-06 17:11:21.064319.064319 client.py:127] Model loaded
DEBUG 01-06 17:11:21.065572.065572 cuda_h.py:19] end sllm_worker_task cost 0.012119054794311523 seconds
DEBUG 01-06 17:11:21.065706.065706 cuda_h.py:19] end gate cost 0.0009915828704833984 seconds
DEBUG 01-06 17:11:21.066292.066292 cuda_h.py:10] start experts_map_get
DEBUG 01-06 17:11:21.066236.066236 lmp.py:403] 
DEBUG 01-06 17:11:21.066236.066236 lmp.py:403] Expert Token Distribution & Device Allocation:
DEBUG 01-06 17:11:21.066615.066615 lmp.py:404]   Total experts: 64
DEBUG 01-06 17:11:21.066264.066264 lmp.py:405]   CPU experts: 32 (50%)
DEBUG 01-06 17:11:21.066053.066053 lmp.py:406]   GPU experts: 32 (50%)
DEBUG 01-06 17:11:21.066981.066981 lmp.py:407] 
DEBUG 01-06 17:11:21.066981.066981 lmp.py:407]   Expert ID | Tokens | Device
DEBUG 01-06 17:11:21.066101.066101 lmp.py:408]   -----------------------------------
DEBUG 01-06 17:11:21.066042.066042 lmp.py:414]   Expert  5 |     12 | CPU
DEBUG 01-06 17:11:21.066923.066923 lmp.py:414]   Expert 56 |     34 | CPU
DEBUG 01-06 17:11:21.066328.066328 lmp.py:414]   Expert 27 |     72 | CPU
DEBUG 01-06 17:11:21.066017.066017 lmp.py:414]   Expert 40 |     82 | CPU
DEBUG 01-06 17:11:21.066230.066230 lmp.py:414]   Expert 16 |     84 | CPU
DEBUG 01-06 17:11:21.066204.066204 lmp.py:414]   Expert 17 |     89 | CPU
DEBUG 01-06 17:11:21.066939.066939 lmp.py:414]   Expert  7 |     93 | CPU
DEBUG 01-06 17:11:21.066152.066152 lmp.py:414]   Expert 51 |     93 | CPU
DEBUG 01-06 17:11:21.066126.066126 lmp.py:414]   Expert 49 |     99 | CPU
DEBUG 01-06 17:11:21.066053.066053 lmp.py:414]   Expert 53 |    100 | CPU
DEBUG 01-06 17:11:21.066173.066173 lmp.py:414]   Expert 63 |    102 | CPU
DEBUG 01-06 17:11:21.066147.066147 lmp.py:414]   Expert 28 |    103 | CPU
DEBUG 01-06 17:11:21.066121.066121 lmp.py:414]   Expert 38 |    118 | CPU
DEBUG 01-06 17:11:21.066857.066857 lmp.py:414]   Expert 58 |    122 | CPU
DEBUG 01-06 17:11:21.066593.066593 lmp.py:414]   Expert 11 |    124 | CPU
DEBUG 01-06 17:11:21.066090.066090 lmp.py:414]   Expert 37 |    127 | CPU
DEBUG 01-06 17:11:21.066825.066825 lmp.py:414]   Expert 47 |    130 | CPU
DEBUG 01-06 17:11:21.066800.066800 lmp.py:414]   Expert 62 |    132 | CPU
DEBUG 01-06 17:11:21.066489.066489 lmp.py:414]   Expert 57 |    136 | CPU
DEBUG 01-06 17:11:21.066370.066370 lmp.py:414]   Expert 39 |    142 | CPU
DEBUG 01-06 17:11:21.066583.066583 lmp.py:414]   Expert  1 |    148 | CPU
DEBUG 01-06 17:11:21.066557.066557 lmp.py:414]   Expert 25 |    149 | CPU
DEBUG 01-06 17:11:21.066054.066054 lmp.py:414]   Expert 14 |    150 | CPU
DEBUG 01-06 17:11:21.066266.066266 lmp.py:414]   Expert 52 |    152 | CPU
DEBUG 01-06 17:11:21.066002.066002 lmp.py:414]   Expert 33 |    164 | CPU
DEBUG 01-06 17:11:21.066453.066453 lmp.py:414]   Expert  6 |    167 | CPU
DEBUG 01-06 17:11:21.066142.066142 lmp.py:414]   Expert 60 |    167 | CPU
DEBUG 01-06 17:11:21.066831.066831 lmp.py:414]   Expert 21 |    169 | CPU
DEBUG 01-06 17:11:21.066806.066806 lmp.py:414]   Expert 23 |    172 | CPU
DEBUG 01-06 17:11:21.067541.067541 lmp.py:414]   Expert 45 |    174 | CPU
DEBUG 01-06 17:11:21.067277.067277 lmp.py:414]   Expert 44 |    175 | CPU
DEBUG 01-06 17:11:21.067012.067012 lmp.py:414]   Expert  4 |    181 | CPU
DEBUG 01-06 17:11:21.067986.067986 lmp.py:414]   Expert 30 |    183 | GPU
DEBUG 01-06 17:11:21.067199.067199 lmp.py:414]   Expert 19 |    184 | GPU
DEBUG 01-06 17:11:21.067411.067411 lmp.py:414]   Expert 31 |    193 | GPU
DEBUG 01-06 17:11:21.067246.067246 lmp.py:414]   Expert  3 |    196 | GPU
DEBUG 01-06 17:11:21.067174.067174 lmp.py:414]   Expert 36 |    201 | GPU
DEBUG 01-06 17:11:21.067387.067387 lmp.py:414]   Expert 55 |    207 | GPU
DEBUG 01-06 17:11:21.067122.067122 lmp.py:414]   Expert  9 |    211 | GPU
DEBUG 01-06 17:11:21.067335.067335 lmp.py:414]   Expert 41 |    218 | GPU
DEBUG 01-06 17:11:21.067309.067309 lmp.py:414]   Expert 34 |    223 | GPU
DEBUG 01-06 17:11:21.067044.067044 lmp.py:414]   Expert  0 |    225 | GPU
DEBUG 01-06 17:11:21.067780.067780 lmp.py:414]   Expert 22 |    225 | GPU
DEBUG 01-06 17:11:21.067754.067754 lmp.py:414]   Expert 12 |    232 | GPU
DEBUG 01-06 17:11:21.067967.067967 lmp.py:414]   Expert 54 |    240 | GPU
DEBUG 01-06 17:11:21.067417.067417 lmp.py:414]   Expert 43 |    244 | GPU
DEBUG 01-06 17:11:21.067153.067153 lmp.py:414]   Expert 26 |    248 | GPU
DEBUG 01-06 17:11:21.067365.067365 lmp.py:414]   Expert 13 |    256 | GPU
DEBUG 01-06 17:11:21.067863.067863 lmp.py:414]   Expert 18 |    256 | GPU
DEBUG 01-06 17:11:21.067075.067075 lmp.py:414]   Expert 59 |    258 | GPU
DEBUG 01-06 17:11:21.067288.067288 lmp.py:414]   Expert 61 |    258 | GPU
DEBUG 01-06 17:11:21.067785.067785 lmp.py:414]   Expert 15 |    260 | GPU
DEBUG 01-06 17:11:21.067759.067759 lmp.py:414]   Expert 20 |    261 | GPU
DEBUG 01-06 17:11:21.067495.067495 lmp.py:414]   Expert 24 |    263 | GPU
DEBUG 01-06 17:11:21.067422.067422 lmp.py:414]   Expert 50 |    266 | GPU
DEBUG 01-06 17:11:21.067350.067350 lmp.py:414]   Expert 29 |    271 | GPU
DEBUG 01-06 17:11:21.067324.067324 lmp.py:414]   Expert 42 |    272 | GPU
DEBUG 01-06 17:11:21.067298.067298 lmp.py:414]   Expert 35 |    274 | GPU
DEBUG 01-06 17:11:21.067511.067511 lmp.py:414]   Expert 32 |    291 | GPU
DEBUG 01-06 17:11:21.067246.067246 lmp.py:414]   Expert  2 |    332 | GPU
DEBUG 01-06 17:11:21.067220.067220 lmp.py:414]   Expert  8 |    354 | GPU
DEBUG 01-06 17:11:21.067671.067671 lmp.py:414]   Expert 10 |    372 | GPU
DEBUG 01-06 17:11:21.067360.067360 lmp.py:414]   Expert 46 |    423 | GPU
DEBUG 01-06 17:11:21.067334.067334 lmp.py:414]   Expert 48 |    429 | GPU
DEBUG 01-06 17:11:21.067024.067024 lmp.py:415] 
DEBUG 01-06 17:11:21.067024.067024 lmp.py:415]   CPU total tokens: 3962 (32.2%)
DEBUG 01-06 17:11:21.067428.067428 lmp.py:416]   GPU total tokens: 8326 (67.8%)
DEBUG 01-06 17:11:21.067124.067124 cuda_h.py:19] end experts_map_get cost 0.0014889240264892578 seconds
DEBUG 01-06 17:11:21.067290.067290 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-06 17:11:21.067928.067928 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 17:11:21.067747.067747 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 17:11:21.068242.068242 cuda_h.py:19] end allocate_cuda_memory cost 0.0002961158752441406 seconds
DEBUG 01-06 17:11:21.068469.068469 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 17:11:21.068987.068987 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 17:11:21.068372.068372 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 17:11:21.068545.068545 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 31f04e86-8ae2-4fdb-8462-5d5ae89ea7c0
DEBUG 01-06 17:11:21.068631.068631 client.py:106] call stub.LoadModelAsync
INFO 01-06 17:11:21.070318.070318 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 31f04e86-8ae2-4fdb-8462-5d5ae89ea7c0
DEBUG 01-06 17:11:21.070485.070485 cuda_h.py:19] end load_into_gpu_async cost 0.0022268295288085938 seconds
DEBUG 01-06 17:11:21.070255.070255 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 17:11:21.070333.070333 cuda_h.py:19] end restore_tensors2 cost 0.00034689903259277344 seconds
DEBUG 01-06 17:11:21.070600.070600 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0032455921173095703 seconds
DEBUG 01-06 17:11:21.073814.073814 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.005906581878662109 seconds
DEBUG 01-06 17:11:21.073856.073856 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-06 17:11:21.073276.073276 lmp.py:461] 
DEBUG 01-06 17:11:21.073276.073276 lmp.py:461]   Computing 32 experts on CPU...
DEBUG 01-06 17:11:21.073279.073279 cuda_h.py:19] end cpu_experts_submit cost 0.00012135505676269531 seconds
DEBUG 01-06 17:11:21.073597.073597 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-06 17:11:21.086987.086987 mlpmodule.py:706] group tensors cost 0.012207269668579102 s
DEBUG 01-06 17:11:21.088871.088871 mlpmodule.py:744] pad cost 0.0016334056854248047 s
DEBUG 01-06 17:11:21.088782.088782 mlpmodule.py:750] create cpu tensor cost 4.792213439941406e-05 s
DEBUG 01-06 17:11:21.088592.088592 mlpmodule.py:755] move to cpu cost 3.4809112548828125e-05 s
DEBUG 01-06 17:11:21.098189.098189 mlpmodule.py:769] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-06 17:11:21.098967.098967 mlpmodule.py:770] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-06 17:11:21.098877.098877 mlpmodule.py:775] group_w3 first element: 0.08447265625
WARNING 01-06 17:11:21.099616.099616 mlpmodule.py:785] start einsum2
DEBUG 01-06 17:11:21.116285.116285 mlpmodule.py:795] group einsum cost 0.02754950523376465 s
DEBUG 01-06 17:11:21.117964.117964 mlpmodule.py:803] cpy2cputensor cost 0.0007271766662597656 s
DEBUG 01-06 17:11:21.121178.121178 cuda_h.py:19] end wait_cetm_experts cost 0.04769587516784668 seconds
DEBUG 01-06 17:11:21.121211.121211 cuda_h.py:10] start gpu_sexperts
DEBUG 01-06 17:11:21.122286.122286 cuda_h.py:19] end gpu_sexperts cost 0.0006046295166015625 seconds
DEBUG 01-06 17:11:21.122573.122573 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-06 17:11:21.122714.122714 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.6702880859375e-05 seconds
DEBUG 01-06 17:11:21.122609.122609 cuda_h.py:10] start wait_experts
INFO 01-06 17:11:21.122796.122796 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 31f04e86-8ae2-4fdb-8462-5d5ae89ea7c0
INFO 01-06 17:11:21.124808.124808 client.py:127] Model loaded
DEBUG 01-06 17:11:21.124095.124095 cuda_h.py:19] end wait_experts cost 0.0016257762908935547 seconds
DEBUG 01-06 17:11:21.124898.124898 cuda_h.py:10] start gpu_experts
DEBUG 01-06 17:11:21.124177.124177 lmp.py:506]   Computing 32 experts on GPU...
DEBUG 01-06 17:11:21.125878.125878 mlpmodule.py:533] gpu group tensors cost 0.0006611347198486328 s
DEBUG 01-06 17:11:21.126919.126919 mlpmodule.py:566] gpu pad cost 0.0017576217651367188 s
DEBUG 01-06 17:11:21.127477.127477 mlpmodule.py:584] gpu group einsum cost 0.0005781650543212891 s
DEBUG 01-06 17:11:21.128742.128742 mlpmodule.py:664]  experts func einsum cost 0.05475187301635742 s
DEBUG 01-06 17:11:21.131363.131363 mlpmodule.py:613] gpu experts func einsum cost 0.006834745407104492 s
DEBUG 01-06 17:11:21.131944.131944 cuda_h.py:19] end gpu_experts cost 0.007097721099853516 seconds
DEBUG 01-06 17:11:21.131596.131596 cuda_h.py:19] end layer_moe_generate_23 cost 0.06815099716186523 seconds
DEBUG 01-06 17:11:21.131353.131353 lmp.py:220] -------------------------------- end layer 23 --------------------------------
DEBUG 01-06 17:11:21.131175.131175 lmp.py:176] -------------------------------- start layer 24 --------------------------------
DEBUG 01-06 17:11:21.131070.131070 cuda_h.py:10] start start_load_qkvogn_s_weight_l_25
DEBUG 01-06 17:11:21.131025.131025 cuda_h.py:10] start start_load_qkvogn_s_weight_l_25
DEBUG 01-06 17:11:21.131167.131167 cuda_h.py:19] end start_load_qkvogn_s_weight_l_25 cost 3.910064697265625e-05 seconds
DEBUG 01-06 17:11:21.132685.132685 cuda_h.py:10] start sllm_worker_task
DEBUG 01-06 17:11:21.132654.132654 cuda_h.py:19] end start_load_qkvogn_s_weight_l_25 cost 0.00015473365783691406 seconds
DEBUG 01-06 17:11:21.132147.132147 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 17:11:21.132585.132585 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-06 17:11:21.132058.132058 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 17:11:21.132252.132252 cuda_h.py:19] end allocate_cuda_memory cost 0.0003750324249267578 seconds
DEBUG 01-06 17:11:21.132878.132878 mlpmodule.py:367] cuda:1 cuda:1
DEBUG 01-06 17:11:21.132238.132238 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 17:11:21.133672.133672 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 17:11:21.133846.133846 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 17:11:21.133357.133357 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, f0ea07d0-cc9c-49cb-859d-98e006a7e9fd
DEBUG 01-06 17:11:21.133088.133088 client.py:106] call stub.LoadModelAsync
DEBUG 01-06 17:11:21.133468.133468 cuda_h.py:10] start self_attn
INFO 01-06 17:11:21.134533.134533 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, f0ea07d0-cc9c-49cb-859d-98e006a7e9fd
DEBUG 01-06 17:11:21.134542.134542 cuda_h.py:19] end load_into_gpu_async cost 0.001661062240600586 seconds
DEBUG 01-06 17:11:21.134960.134960 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 17:11:21.134765.134765 cuda_h.py:19] end restore_tensors2 cost 7.43865966796875e-05 seconds
DEBUG 01-06 17:11:21.134805.134805 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0025768280029296875 seconds
INFO 01-06 17:11:21.134119.134119 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, f0ea07d0-cc9c-49cb-859d-98e006a7e9fd
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-06 17:11:21.136852.136852 cuda_h.py:19] end self_attn cost 0.002875089645385742 seconds
DEBUG 01-06 17:11:21.136657.136657 cuda_h.py:19] end iln_self_attn_paln cost 0.004393577575683594 seconds
DEBUG 01-06 17:11:21.136977.136977 cuda_h.py:10] start layer_moe_generate_24
DEBUG 01-06 17:11:21.136601.136601 cuda_h.py:10] start gate
DEBUG 01-06 17:11:21.137047.137047 cuda_h.py:19] end gate cost 0.0006461143493652344 seconds
DEBUG 01-06 17:11:21.137354.137354 cuda_h.py:10] start experts_map_get
DEBUG 01-06 17:11:21.137145.137145 lmp.py:403] 
DEBUG 01-06 17:11:21.137145.137145 lmp.py:403] Expert Token Distribution & Device Allocation:
DEBUG 01-06 17:11:21.137663.137663 lmp.py:404]   Total experts: 64
DEBUG 01-06 17:11:21.137074.137074 lmp.py:405]   CPU experts: 32 (50%)
DEBUG 01-06 17:11:21.137101.137101 lmp.py:406]   GPU experts: 32 (50%)
DEBUG 01-06 17:11:21.137790.137790 lmp.py:407] 
DEBUG 01-06 17:11:21.137790.137790 lmp.py:407]   Expert ID | Tokens | Device
DEBUG 01-06 17:11:21.137957.137957 lmp.py:408]   -----------------------------------
DEBUG 01-06 17:11:21.137322.137322 lmp.py:414]   Expert 36 |     21 | CPU
DEBUG 01-06 17:11:21.138726.138726 lmp.py:414]   Expert 35 |     32 | CPU
DEBUG 01-06 17:11:21.138939.138939 lmp.py:414]   Expert 46 |     41 | CPU
DEBUG 01-06 17:11:21.138866.138866 lmp.py:414]   Expert 25 |     45 | CPU
DEBUG 01-06 17:11:21.138556.138556 lmp.py:414]   Expert 16 |     51 | CPU
DEBUG 01-06 17:11:21.138768.138768 lmp.py:414]   Expert 51 |     54 | CPU
DEBUG 01-06 17:11:21.138981.138981 lmp.py:414]   Expert  0 |     62 | CPU
DEBUG 01-06 17:11:21.138955.138955 lmp.py:414]   Expert 43 |     66 | CPU
DEBUG 01-06 17:11:21.138929.138929 lmp.py:414]   Expert 30 |     70 | CPU
DEBUG 01-06 17:11:21.138664.138664 lmp.py:414]   Expert 42 |     72 | CPU
DEBUG 01-06 17:11:21.138638.138638 lmp.py:414]   Expert 47 |     72 | CPU
DEBUG 01-06 17:11:21.138374.138374 lmp.py:414]   Expert 39 |     73 | CPU
DEBUG 01-06 17:11:21.138825.138825 lmp.py:414]   Expert 44 |     74 | CPU
DEBUG 01-06 17:11:21.138285.138285 lmp.py:414]   Expert 55 |     74 | CPU
DEBUG 01-06 17:11:21.138027.138027 lmp.py:414]   Expert  2 |     82 | CPU
DEBUG 01-06 17:11:21.138432.138432 lmp.py:414]   Expert  4 |    106 | CPU
DEBUG 01-06 17:11:21.138075.138075 lmp.py:414]   Expert  6 |    107 | CPU
DEBUG 01-06 17:11:21.138479.138479 lmp.py:414]   Expert 48 |    108 | CPU
DEBUG 01-06 17:11:21.138169.138169 lmp.py:414]   Expert 33 |    120 | CPU
DEBUG 01-06 17:11:21.138096.138096 lmp.py:414]   Expert 13 |    124 | CPU
DEBUG 01-06 17:11:21.138786.138786 lmp.py:414]   Expert 61 |    124 | CPU
DEBUG 01-06 17:11:21.138475.138475 lmp.py:414]   Expert 24 |    127 | CPU
DEBUG 01-06 17:11:21.138164.138164 lmp.py:414]   Expert 56 |    129 | CPU
DEBUG 01-06 17:11:21.138854.138854 lmp.py:414]   Expert  9 |    133 | CPU
DEBUG 01-06 17:11:21.138258.138258 lmp.py:414]   Expert 54 |    137 | CPU
DEBUG 01-06 17:11:21.138186.138186 lmp.py:414]   Expert 15 |    138 | CPU
DEBUG 01-06 17:11:21.138114.138114 lmp.py:414]   Expert  7 |    139 | CPU
DEBUG 01-06 17:11:21.138803.138803 lmp.py:414]   Expert 20 |    139 | CPU
DEBUG 01-06 17:11:21.138492.138492 lmp.py:414]   Expert 29 |    141 | CPU
DEBUG 01-06 17:11:21.138943.138943 lmp.py:414]   Expert 38 |    145 | CPU
DEBUG 01-06 17:11:21.138394.138394 lmp.py:414]   Expert 59 |    158 | CPU
DEBUG 01-06 17:11:21.138083.138083 lmp.py:414]   Expert 19 |    160 | CPU
DEBUG 01-06 17:11:21.138773.138773 lmp.py:414]   Expert 62 |    161 | GPU
DEBUG 01-06 17:11:21.138177.138177 lmp.py:414]   Expert 45 |    165 | GPU
DEBUG 01-06 17:11:21.138867.138867 lmp.py:414]   Expert 34 |    193 | GPU
DEBUG 01-06 17:11:21.138556.138556 lmp.py:414]   Expert 57 |    194 | GPU
DEBUG 01-06 17:11:21.138007.138007 lmp.py:414]   Expert 50 |    198 | GPU
DEBUG 01-06 17:11:21.138458.138458 lmp.py:414]   Expert 10 |    206 | GPU
DEBUG 01-06 17:11:21.138908.138908 lmp.py:414]   Expert 23 |    208 | GPU
DEBUG 01-06 17:11:21.138359.138359 lmp.py:414]   Expert 31 |    212 | GPU
DEBUG 01-06 17:11:21.138810.138810 lmp.py:414]   Expert 18 |    220 | GPU
DEBUG 01-06 17:11:21.138784.138784 lmp.py:414]   Expert 53 |    220 | GPU
DEBUG 01-06 17:11:21.138235.138235 lmp.py:414]   Expert  8 |    223 | GPU
DEBUG 01-06 17:11:21.138924.138924 lmp.py:414]   Expert 22 |    223 | GPU
DEBUG 01-06 17:11:21.138898.138898 lmp.py:414]   Expert 52 |    227 | GPU
DEBUG 01-06 17:11:21.138111.138111 lmp.py:414]   Expert 37 |    230 | GPU
DEBUG 01-06 17:11:21.138323.138323 lmp.py:414]   Expert 60 |    231 | GPU
DEBUG 01-06 17:11:21.138297.138297 lmp.py:414]   Expert  5 |    239 | GPU
DEBUG 01-06 17:11:21.138510.138510 lmp.py:414]   Expert 17 |    252 | GPU
DEBUG 01-06 17:11:21.138676.138676 lmp.py:414]   Expert 11 |    265 | GPU
DEBUG 01-06 17:11:21.138604.138604 lmp.py:414]   Expert 41 |    270 | GPU
DEBUG 01-06 17:11:21.138531.138531 lmp.py:414]   Expert  1 |    274 | GPU
DEBUG 01-06 17:11:21.138506.138506 lmp.py:414]   Expert 49 |    278 | GPU
DEBUG 01-06 17:11:21.138956.138956 lmp.py:414]   Expert 26 |    285 | GPU
DEBUG 01-06 17:11:21.138407.138407 lmp.py:414]   Expert 58 |    286 | GPU
DEBUG 01-06 17:11:21.138858.138858 lmp.py:414]   Expert 28 |    288 | GPU
DEBUG 01-06 17:11:21.138309.138309 lmp.py:414]   Expert 32 |    290 | GPU
DEBUG 01-06 17:11:21.139237.139237 lmp.py:414]   Expert 40 |    304 | GPU
DEBUG 01-06 17:11:21.139403.139403 lmp.py:414]   Expert 12 |    315 | GPU
DEBUG 01-06 17:11:21.139854.139854 lmp.py:414]   Expert 14 |    319 | GPU
DEBUG 01-06 17:11:21.139305.139305 lmp.py:414]   Expert 63 |    330 | GPU
DEBUG 01-06 17:11:21.139279.139279 lmp.py:414]   Expert 21 |    361 | GPU
DEBUG 01-06 17:11:21.139491.139491 lmp.py:414]   Expert 27 |    672 | GPU
DEBUG 01-06 17:11:21.139180.139180 lmp.py:414]   Expert  3 |   1025 | GPU
DEBUG 01-06 17:11:21.139823.139823 lmp.py:415] 
DEBUG 01-06 17:11:21.139823.139823 lmp.py:415]   CPU total tokens: 3124 (25.4%)
DEBUG 01-06 17:11:21.139182.139182 lmp.py:416]   GPU total tokens: 9164 (74.6%)
DEBUG 01-06 17:11:21.139024.139024 cuda_h.py:19] end experts_map_get cost 0.001588582992553711 seconds
DEBUG 01-06 17:11:21.139382.139382 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-06 17:11:21.139880.139880 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 17:11:21.139753.139753 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 17:11:21.140111.140111 cuda_h.py:19] end allocate_cuda_memory cost 0.0015530586242675781 seconds
DEBUG 01-06 17:11:21.141974.141974 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 17:11:21.141161.141161 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 17:11:21.141208.141208 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 17:11:21.141097.141097 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, d0627e4b-83c1-4e01-9b0e-a6bf6ee58674
DEBUG 01-06 17:11:21.141044.141044 client.py:106] call stub.LoadModelAsync
INFO 01-06 17:11:21.142621.142621 client.py:127] Model loaded
DEBUG 01-06 17:11:21.143881.143881 cuda_h.py:19] end sllm_worker_task cost 0.011045455932617188 seconds
INFO 01-06 17:11:21.144002.144002 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, d0627e4b-83c1-4e01-9b0e-a6bf6ee58674
DEBUG 01-06 17:11:21.144497.144497 cuda_h.py:19] end load_into_gpu_async cost 0.0034940242767333984 seconds
DEBUG 01-06 17:11:21.144129.144129 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 17:11:21.145068.145068 cuda_h.py:19] end restore_tensors2 cost 0.0004878044128417969 seconds
DEBUG 01-06 17:11:21.145388.145388 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.006038665771484375 seconds
DEBUG 01-06 17:11:21.147721.147721 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.00872039794921875 seconds
DEBUG 01-06 17:11:21.147087.147087 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-06 17:11:21.148527.148527 lmp.py:461] 
DEBUG 01-06 17:11:21.148527.148527 lmp.py:461]   Computing 32 experts on CPU...
DEBUG 01-06 17:11:21.148662.148662 cuda_h.py:19] end cpu_experts_submit cost 0.00011301040649414062 seconds
DEBUG 01-06 17:11:21.148503.148503 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-06 17:11:21.159777.159777 mlpmodule.py:706] group tensors cost 0.011065483093261719 s
DEBUG 01-06 17:11:21.161505.161505 mlpmodule.py:744] pad cost 0.0016949176788330078 s
DEBUG 01-06 17:11:21.161457.161457 mlpmodule.py:750] create cpu tensor cost 7.891654968261719e-05 s
DEBUG 01-06 17:11:21.162320.162320 mlpmodule.py:755] move to cpu cost 3.814697265625e-05 s
DEBUG 01-06 17:11:21.172383.172383 mlpmodule.py:769] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-06 17:11:21.172785.172785 mlpmodule.py:770] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-06 17:11:21.173470.173470 mlpmodule.py:775] group_w3 first element: 0.00653076171875
WARNING 01-06 17:11:21.173533.173533 mlpmodule.py:785] start einsum2
DEBUG 01-06 17:11:21.193182.193182 mlpmodule.py:795] group einsum cost 0.03100275993347168 s
DEBUG 01-06 17:11:21.193388.193388 mlpmodule.py:803] cpy2cputensor cost 0.0006489753723144531 s
DEBUG 01-06 17:11:21.198191.198191 cuda_h.py:19] end wait_cetm_experts cost 0.05011129379272461 seconds
DEBUG 01-06 17:11:21.198118.198118 cuda_h.py:10] start gpu_sexperts
DEBUG 01-06 17:11:21.199921.199921 cuda_h.py:19] end gpu_sexperts cost 0.0006158351898193359 seconds
DEBUG 01-06 17:11:21.199394.199394 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-06 17:11:21.199912.199912 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.5987625122070312e-05 seconds
DEBUG 01-06 17:11:21.199569.199569 cuda_h.py:10] start wait_experts
INFO 01-06 17:11:21.199087.199087 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, d0627e4b-83c1-4e01-9b0e-a6bf6ee58674
INFO 01-06 17:11:21.200929.200929 client.py:127] Model loaded
DEBUG 01-06 17:11:21.200779.200779 cuda_h.py:19] end wait_experts cost 0.0014929771423339844 seconds
DEBUG 01-06 17:11:21.200959.200959 cuda_h.py:10] start gpu_experts
DEBUG 01-06 17:11:21.200569.200569 lmp.py:506]   Computing 32 experts on GPU...
DEBUG 01-06 17:11:21.201289.201289 mlpmodule.py:533] gpu group tensors cost 0.0006566047668457031 s
DEBUG 01-06 17:11:21.203292.203292 mlpmodule.py:566] gpu pad cost 0.001806497573852539 s
DEBUG 01-06 17:11:21.204684.204684 mlpmodule.py:584] gpu group einsum cost 0.0005621910095214844 s
DEBUG 01-06 17:11:21.205775.205775 mlpmodule.py:664]  experts func einsum cost 0.05714845657348633 s
DEBUG 01-06 17:11:21.207954.207954 mlpmodule.py:613] gpu experts func einsum cost 0.006856203079223633 s
DEBUG 01-06 17:11:21.208926.208926 cuda_h.py:19] end gpu_experts cost 0.007109642028808594 seconds
DEBUG 01-06 17:11:21.208294.208294 cuda_h.py:19] end layer_moe_generate_24 cost 0.07133746147155762 seconds
DEBUG 01-06 17:11:21.208686.208686 lmp.py:220] -------------------------------- end layer 24 --------------------------------
DEBUG 01-06 17:11:21.208516.208516 lmp.py:176] -------------------------------- start layer 25 --------------------------------
DEBUG 01-06 17:11:21.208219.208219 cuda_h.py:10] start start_load_qkvogn_s_weight_l_26
DEBUG 01-06 17:11:21.208796.208796 cuda_h.py:10] start start_load_qkvogn_s_weight_l_26
DEBUG 01-06 17:11:21.208083.208083 cuda_h.py:19] end start_load_qkvogn_s_weight_l_26 cost 3.9577484130859375e-05 seconds
DEBUG 01-06 17:11:21.208462.208462 cuda_h.py:19] end start_load_qkvogn_s_weight_l_26 cost 7.62939453125e-05 seconds
DEBUG 01-06 17:11:21.208928.208928 cuda_h.py:10] start sllm_worker_task
DEBUG 01-06 17:11:21.208419.208419 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-06 17:11:21.208011.208011 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 17:11:21.208724.208724 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 17:11:21.209355.209355 mlpmodule.py:367] cuda:1 cuda:1
DEBUG 01-06 17:11:21.209752.209752 cuda_h.py:19] end allocate_cuda_memory cost 0.0003216266632080078 seconds
DEBUG 01-06 17:11:21.209386.209386 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 17:11:21.209486.209486 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 17:11:21.209879.209879 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 17:11:21.209674.209674 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, a1028e3e-3dff-4a6e-adbd-44e2731a4a1e
DEBUG 01-06 17:11:21.209160.209160 client.py:106] call stub.LoadModelAsync
DEBUG 01-06 17:11:21.209156.209156 cuda_h.py:10] start self_attn
INFO 01-06 17:11:21.211945.211945 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, a1028e3e-3dff-4a6e-adbd-44e2731a4a1e
DEBUG 01-06 17:11:21.211696.211696 cuda_h.py:19] end load_into_gpu_async cost 0.0016989707946777344 seconds
DEBUG 01-06 17:11:21.211968.211968 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 17:11:21.211481.211481 cuda_h.py:19] end restore_tensors2 cost 7.104873657226562e-05 seconds
DEBUG 01-06 17:11:21.211198.211198 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.002516508102416992 seconds
INFO 01-06 17:11:21.211034.211034 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, a1028e3e-3dff-4a6e-adbd-44e2731a4a1e
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-06 17:11:21.212752.212752 cuda_h.py:19] end self_attn cost 0.002901792526245117 seconds
DEBUG 01-06 17:11:21.213060.213060 cuda_h.py:19] end iln_self_attn_paln cost 0.0043714046478271484 seconds
DEBUG 01-06 17:11:21.213711.213711 cuda_h.py:10] start layer_moe_generate_25
DEBUG 01-06 17:11:21.213050.213050 cuda_h.py:10] start gate
DEBUG 01-06 17:11:21.214404.214404 cuda_h.py:19] end gate cost 0.0006480216979980469 seconds
DEBUG 01-06 17:11:21.214042.214042 cuda_h.py:10] start experts_map_get
DEBUG 01-06 17:11:21.214303.214303 lmp.py:403] 
DEBUG 01-06 17:11:21.214303.214303 lmp.py:403] Expert Token Distribution & Device Allocation:
DEBUG 01-06 17:11:21.214629.214629 lmp.py:404]   Total experts: 64
DEBUG 01-06 17:11:21.214802.214802 lmp.py:405]   CPU experts: 32 (50%)
DEBUG 01-06 17:11:21.214590.214590 lmp.py:406]   GPU experts: 32 (50%)
DEBUG 01-06 17:11:21.214280.214280 lmp.py:407] 
DEBUG 01-06 17:11:21.214280.214280 lmp.py:407]   Expert ID | Tokens | Device
DEBUG 01-06 17:11:21.214207.214207 lmp.py:408]   -----------------------------------
DEBUG 01-06 17:11:21.214857.214857 lmp.py:414]   Expert 13 |     38 | CPU
DEBUG 01-06 17:11:21.214262.214262 lmp.py:414]   Expert 38 |     40 | CPU
DEBUG 01-06 17:11:21.214190.214190 lmp.py:414]   Expert 44 |     41 | CPU
DEBUG 01-06 17:11:21.214071.214071 lmp.py:414]   Expert  9 |     43 | CPU
DEBUG 01-06 17:11:21.214237.214237 lmp.py:414]   Expert 25 |     45 | CPU
DEBUG 01-06 17:11:21.214926.214926 lmp.py:414]   Expert 22 |     49 | CPU
DEBUG 01-06 17:11:21.214662.214662 lmp.py:414]   Expert 33 |     50 | CPU
DEBUG 01-06 17:11:21.214636.214636 lmp.py:414]   Expert 16 |     52 | CPU
DEBUG 01-06 17:11:21.214610.214610 lmp.py:414]   Expert  2 |     53 | CPU
DEBUG 01-06 17:11:21.214584.214584 lmp.py:414]   Expert 42 |     55 | CPU
DEBUG 01-06 17:11:21.214558.214558 lmp.py:414]   Expert  5 |     65 | CPU
DEBUG 01-06 17:11:21.214532.214532 lmp.py:414]   Expert 10 |     72 | CPU
DEBUG 01-06 17:11:21.214983.214983 lmp.py:414]   Expert 23 |     78 | CPU
DEBUG 01-06 17:11:21.214957.214957 lmp.py:414]   Expert 24 |     81 | CPU
DEBUG 01-06 17:11:21.214454.214454 lmp.py:414]   Expert 59 |     84 | CPU
DEBUG 01-06 17:11:21.214667.214667 lmp.py:414]   Expert 21 |     98 | CPU
DEBUG 01-06 17:11:21.214402.214402 lmp.py:414]   Expert 46 |     99 | CPU
DEBUG 01-06 17:11:21.214045.214045 lmp.py:414]   Expert 55 |    107 | CPU
DEBUG 01-06 17:11:21.214218.214218 lmp.py:414]   Expert 61 |    119 | CPU
DEBUG 01-06 17:11:21.214384.214384 lmp.py:414]   Expert 45 |    122 | CPU
DEBUG 01-06 17:11:21.214789.214789 lmp.py:414]   Expert 31 |    126 | CPU
DEBUG 01-06 17:11:21.214194.214194 lmp.py:414]   Expert 36 |    130 | CPU
DEBUG 01-06 17:11:21.214360.214360 lmp.py:414]   Expert  6 |    138 | CPU
DEBUG 01-06 17:11:21.214287.214287 lmp.py:414]   Expert  0 |    139 | CPU
DEBUG 01-06 17:11:21.214500.214500 lmp.py:414]   Expert 51 |    139 | CPU
DEBUG 01-06 17:11:21.214428.214428 lmp.py:414]   Expert 18 |    156 | CPU
DEBUG 01-06 17:11:21.214594.214594 lmp.py:414]   Expert 26 |    157 | CPU
DEBUG 01-06 17:11:21.214283.214283 lmp.py:414]   Expert  8 |    159 | CPU
DEBUG 01-06 17:11:21.214972.214972 lmp.py:414]   Expert 43 |    163 | CPU
DEBUG 01-06 17:11:21.214900.214900 lmp.py:414]   Expert  3 |    165 | CPU
DEBUG 01-06 17:11:21.215113.215113 lmp.py:414]   Expert 20 |    173 | CPU
DEBUG 01-06 17:11:21.215040.215040 lmp.py:414]   Expert 41 |    173 | CPU
DEBUG 01-06 17:11:21.215730.215730 lmp.py:414]   Expert 48 |    175 | GPU
DEBUG 01-06 17:11:21.215657.215657 lmp.py:414]   Expert 12 |    177 | GPU
DEBUG 01-06 17:11:21.215062.215062 lmp.py:414]   Expert  7 |    182 | GPU
DEBUG 01-06 17:11:21.215990.215990 lmp.py:414]   Expert 56 |    186 | GPU
DEBUG 01-06 17:11:21.215440.215440 lmp.py:414]   Expert 27 |    189 | GPU
DEBUG 01-06 17:11:21.215653.215653 lmp.py:414]   Expert 28 |    192 | GPU
DEBUG 01-06 17:11:21.215342.215342 lmp.py:414]   Expert 34 |    197 | GPU
DEBUG 01-06 17:11:21.215793.215793 lmp.py:414]   Expert 47 |    203 | GPU
DEBUG 01-06 17:11:21.215721.215721 lmp.py:414]   Expert  1 |    208 | GPU
DEBUG 01-06 17:11:21.215702.215702 lmp.py:414]   Expert 32 |    214 | GPU
DEBUG 01-06 17:11:21.215629.215629 lmp.py:414]   Expert 11 |    225 | GPU
DEBUG 01-06 17:11:21.215127.215127 lmp.py:414]   Expert 40 |    227 | GPU
DEBUG 01-06 17:11:21.215101.215101 lmp.py:414]   Expert 63 |    229 | GPU
DEBUG 01-06 17:11:21.215598.215598 lmp.py:414]   Expert 53 |    232 | GPU
DEBUG 01-06 17:11:21.215572.215572 lmp.py:414]   Expert 49 |    234 | GPU
DEBUG 01-06 17:11:21.215069.215069 lmp.py:414]   Expert 29 |    242 | GPU
DEBUG 01-06 17:11:21.215043.215043 lmp.py:414]   Expert 50 |    248 | GPU
DEBUG 01-06 17:11:21.215017.215017 lmp.py:414]   Expert 15 |    249 | GPU
DEBUG 01-06 17:11:21.215468.215468 lmp.py:414]   Expert 30 |    254 | GPU
DEBUG 01-06 17:11:21.215442.215442 lmp.py:414]   Expert  4 |    255 | GPU
DEBUG 01-06 17:11:21.215701.215701 lmp.py:414]   Expert 14 |    259 | GPU
DEBUG 01-06 17:11:21.215437.215437 lmp.py:414]   Expert 35 |    264 | GPU
DEBUG 01-06 17:11:21.215695.215695 lmp.py:414]   Expert 37 |    311 | GPU
DEBUG 01-06 17:11:21.215954.215954 lmp.py:414]   Expert 52 |    344 | GPU
DEBUG 01-06 17:11:21.215213.215213 lmp.py:414]   Expert 17 |    351 | GPU
DEBUG 01-06 17:11:21.215710.215710 lmp.py:414]   Expert 54 |    376 | GPU
DEBUG 01-06 17:11:21.215923.215923 lmp.py:414]   Expert 39 |    398 | GPU
DEBUG 01-06 17:11:21.215135.215135 lmp.py:414]   Expert 57 |    410 | GPU
DEBUG 01-06 17:11:21.215632.215632 lmp.py:414]   Expert 60 |    457 | GPU
DEBUG 01-06 17:11:21.215368.215368 lmp.py:414]   Expert 62 |    470 | GPU
DEBUG 01-06 17:11:21.215865.215865 lmp.py:414]   Expert 19 |    549 | GPU
DEBUG 01-06 17:11:21.215362.215362 lmp.py:414]   Expert 58 |    572 | GPU
DEBUG 01-06 17:11:21.215575.215575 lmp.py:415] 
DEBUG 01-06 17:11:21.215575.215575 lmp.py:415]   CPU total tokens: 3209 (26.1%)
DEBUG 01-06 17:11:21.215502.215502 lmp.py:416]   GPU total tokens: 9079 (73.9%)
DEBUG 01-06 17:11:21.215483.215483 cuda_h.py:19] end experts_map_get cost 0.0014917850494384766 seconds
DEBUG 01-06 17:11:21.215365.215365 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-06 17:11:21.215108.215108 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 17:11:21.215689.215689 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 17:11:21.217446.217446 cuda_h.py:19] end allocate_cuda_memory cost 0.001787424087524414 seconds
DEBUG 01-06 17:11:21.217091.217091 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 17:11:21.217801.217801 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 17:11:21.217040.217040 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 17:11:21.217558.217558 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, de135995-2bae-4a5b-b522-5f6dbc36b9e8
DEBUG 01-06 17:11:21.218598.218598 client.py:106] call stub.LoadModelAsync
INFO 01-06 17:11:21.219784.219784 client.py:127] Model loaded
DEBUG 01-06 17:11:21.219844.219844 cuda_h.py:19] end sllm_worker_task cost 0.011014223098754883 seconds
INFO 01-06 17:11:21.221109.221109 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, de135995-2bae-4a5b-b522-5f6dbc36b9e8
DEBUG 01-06 17:11:21.221244.221244 cuda_h.py:19] end load_into_gpu_async cost 0.003343820571899414 seconds
DEBUG 01-06 17:11:21.221854.221854 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 17:11:21.221068.221068 cuda_h.py:19] end restore_tensors2 cost 0.0004105567932128906 seconds
DEBUG 01-06 17:11:21.221050.221050 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0059375762939453125 seconds
DEBUG 01-06 17:11:21.224640.224640 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.008604049682617188 seconds
DEBUG 01-06 17:11:21.224430.224430 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-06 17:11:21.224566.224566 lmp.py:461] 
DEBUG 01-06 17:11:21.224566.224566 lmp.py:461]   Computing 32 experts on CPU...
DEBUG 01-06 17:11:21.224277.224277 cuda_h.py:19] end cpu_experts_submit cost 0.00013899803161621094 seconds
DEBUG 01-06 17:11:21.224172.224172 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-06 17:11:21.235396.235396 mlpmodule.py:706] group tensors cost 0.01061105728149414 s
DEBUG 01-06 17:11:21.238055.238055 mlpmodule.py:744] pad cost 0.0023305416107177734 s
DEBUG 01-06 17:11:21.238769.238769 mlpmodule.py:750] create cpu tensor cost 6.079673767089844e-05 s
DEBUG 01-06 17:11:21.238606.238606 mlpmodule.py:755] move to cpu cost 4.220008850097656e-05 s
DEBUG 01-06 17:11:21.248129.248129 mlpmodule.py:769] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-06 17:11:21.248602.248602 mlpmodule.py:770] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-06 17:11:21.248155.248155 mlpmodule.py:775] group_w3 first element: 0.007110595703125
WARNING 01-06 17:11:21.248411.248411 mlpmodule.py:785] start einsum2
DEBUG 01-06 17:11:21.268453.268453 mlpmodule.py:795] group einsum cost 0.02927088737487793 s
DEBUG 01-06 17:11:21.269829.269829 mlpmodule.py:803] cpy2cputensor cost 0.0007550716400146484 s
DEBUG 01-06 17:11:21.275923.275923 cuda_h.py:19] end wait_cetm_experts cost 0.05102801322937012 seconds
DEBUG 01-06 17:11:21.275554.275554 cuda_h.py:10] start gpu_sexperts
DEBUG 01-06 17:11:21.276518.276518 cuda_h.py:19] end gpu_sexperts cost 0.0008287429809570312 seconds
DEBUG 01-06 17:11:21.276746.276746 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-06 17:11:21.276484.276484 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 4.38690185546875e-05 seconds
DEBUG 01-06 17:11:21.276141.276141 cuda_h.py:10] start wait_experts
INFO 01-06 17:11:21.277427.277427 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, de135995-2bae-4a5b-b522-5f6dbc36b9e8
INFO 01-06 17:11:21.278530.278530 client.py:127] Model loaded
DEBUG 01-06 17:11:21.278533.278533 cuda_h.py:19] end wait_experts cost 0.0015888214111328125 seconds
DEBUG 01-06 17:11:21.278574.278574 cuda_h.py:10] start gpu_experts
DEBUG 01-06 17:11:21.278376.278376 lmp.py:506]   Computing 32 experts on GPU...
DEBUG 01-06 17:11:21.279402.279402 mlpmodule.py:533] gpu group tensors cost 0.0008695125579833984 s
DEBUG 01-06 17:11:21.281452.281452 mlpmodule.py:566] gpu pad cost 0.0020482540130615234 s
DEBUG 01-06 17:11:21.282922.282922 mlpmodule.py:584] gpu group einsum cost 0.0006890296936035156 s
DEBUG 01-06 17:11:21.282024.282024 mlpmodule.py:664]  experts func einsum cost 0.058086395263671875 s
DEBUG 01-06 17:11:21.285867.285867 mlpmodule.py:613] gpu experts func einsum cost 0.0072422027587890625 s
DEBUG 01-06 17:11:21.286858.286858 cuda_h.py:19] end gpu_experts cost 0.007485389709472656 seconds
DEBUG 01-06 17:11:21.286405.286405 cuda_h.py:19] end layer_moe_generate_25 cost 0.07291460037231445 seconds
DEBUG 01-06 17:11:21.286330.286330 lmp.py:220] -------------------------------- end layer 25 --------------------------------
DEBUG 01-06 17:11:21.286729.286729 lmp.py:176] -------------------------------- start layer 26 --------------------------------
DEBUG 01-06 17:11:21.286664.286664 cuda_h.py:10] start start_load_qkvogn_s_weight_l_27
DEBUG 01-06 17:11:21.286996.286996 cuda_h.py:10] start start_load_qkvogn_s_weight_l_27
DEBUG 01-06 17:11:21.286654.286654 cuda_h.py:19] end start_load_qkvogn_s_weight_l_27 cost 3.743171691894531e-05 seconds
DEBUG 01-06 17:11:21.286072.286072 cuda_h.py:19] end start_load_qkvogn_s_weight_l_27 cost 6.937980651855469e-05 seconds
DEBUG 01-06 17:11:21.286861.286861 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-06 17:11:21.286963.286963 cuda_h.py:10] start sllm_worker_task
DEBUG 01-06 17:11:21.287384.287384 mlpmodule.py:367] cuda:1 cuda:1
DEBUG 01-06 17:11:21.287115.287115 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 17:11:21.287198.287198 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 17:11:21.287712.287712 cuda_h.py:19] end allocate_cuda_memory cost 0.0004792213439941406 seconds
DEBUG 01-06 17:11:21.287742.287742 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 17:11:21.287889.287889 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 17:11:21.287725.287725 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 17:11:21.287667.287667 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, d1edb83d-0ef4-4e0b-9133-9cb3496213a0
DEBUG 01-06 17:11:21.288742.288742 client.py:106] call stub.LoadModelAsync
DEBUG 01-06 17:11:21.288522.288522 cuda_h.py:10] start self_attn
INFO 01-06 17:11:21.289248.289248 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, d1edb83d-0ef4-4e0b-9133-9cb3496213a0
DEBUG 01-06 17:11:21.289323.289323 cuda_h.py:19] end load_into_gpu_async cost 0.0016894340515136719 seconds
DEBUG 01-06 17:11:21.289880.289880 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 17:11:21.289354.289354 cuda_h.py:19] end restore_tensors2 cost 7.653236389160156e-05 seconds
DEBUG 01-06 17:11:21.289633.289633 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.002528667449951172 seconds
INFO 01-06 17:11:21.289768.289768 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, d1edb83d-0ef4-4e0b-9133-9cb3496213a0
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-06 17:11:21.291652.291652 cuda_h.py:19] end self_attn cost 0.003220081329345703 seconds
DEBUG 01-06 17:11:21.291471.291471 cuda_h.py:19] end iln_self_attn_paln cost 0.005125284194946289 seconds
DEBUG 01-06 17:11:21.292168.292168 cuda_h.py:10] start layer_moe_generate_26
DEBUG 01-06 17:11:21.292467.292467 cuda_h.py:10] start gate
DEBUG 01-06 17:11:21.292547.292547 cuda_h.py:19] end gate cost 0.0007622241973876953 seconds
DEBUG 01-06 17:11:21.292661.292661 cuda_h.py:10] start experts_map_get
DEBUG 01-06 17:11:21.293414.293414 lmp.py:403] 
DEBUG 01-06 17:11:21.293414.293414 lmp.py:403] Expert Token Distribution & Device Allocation:
DEBUG 01-06 17:11:21.293601.293601 lmp.py:404]   Total experts: 64
DEBUG 01-06 17:11:21.293728.293728 lmp.py:405]   CPU experts: 32 (50%)
DEBUG 01-06 17:11:21.293755.293755 lmp.py:406]   GPU experts: 32 (50%)
DEBUG 01-06 17:11:21.293159.293159 lmp.py:407] 
DEBUG 01-06 17:11:21.293159.293159 lmp.py:407]   Expert ID | Tokens | Device
DEBUG 01-06 17:11:21.293041.293041 lmp.py:408]   -----------------------------------
DEBUG 01-06 17:11:21.293883.293883 lmp.py:414]   Expert 61 |      9 | CPU
DEBUG 01-06 17:11:21.293764.293764 lmp.py:414]   Expert 20 |     10 | CPU
DEBUG 01-06 17:11:21.293930.293930 lmp.py:414]   Expert 11 |     28 | CPU
DEBUG 01-06 17:11:21.293573.293573 lmp.py:414]   Expert  7 |     35 | CPU
DEBUG 01-06 17:11:21.293739.293739 lmp.py:414]   Expert  3 |     39 | CPU
DEBUG 01-06 17:11:21.293905.293905 lmp.py:414]   Expert 62 |     39 | CPU
DEBUG 01-06 17:11:21.293833.293833 lmp.py:414]   Expert 51 |     40 | CPU
DEBUG 01-06 17:11:21.293522.293522 lmp.py:414]   Expert 30 |     42 | CPU
DEBUG 01-06 17:11:21.293212.293212 lmp.py:414]   Expert 17 |     57 | CPU
DEBUG 01-06 17:11:21.293616.293616 lmp.py:414]   Expert 29 |     57 | CPU
DEBUG 01-06 17:11:21.293021.293021 lmp.py:414]   Expert  6 |     58 | CPU
DEBUG 01-06 17:11:21.293472.293472 lmp.py:414]   Expert 63 |     67 | CPU
DEBUG 01-06 17:11:21.293638.293638 lmp.py:414]   Expert 59 |     71 | CPU
DEBUG 01-06 17:11:21.293089.293089 lmp.py:414]   Expert  9 |     72 | CPU
DEBUG 01-06 17:11:21.293016.293016 lmp.py:414]   Expert 38 |     75 | CPU
DEBUG 01-06 17:11:21.293467.293467 lmp.py:414]   Expert 55 |     81 | CPU
DEBUG 01-06 17:11:21.293157.293157 lmp.py:414]   Expert 19 |     83 | CPU
DEBUG 01-06 17:11:21.293846.293846 lmp.py:414]   Expert 22 |     96 | CPU
DEBUG 01-06 17:11:21.293774.293774 lmp.py:414]   Expert  8 |     97 | CPU
DEBUG 01-06 17:11:21.293224.293224 lmp.py:414]   Expert 48 |    100 | CPU
DEBUG 01-06 17:11:21.293675.293675 lmp.py:414]   Expert 49 |    105 | CPU
DEBUG 01-06 17:11:21.293888.293888 lmp.py:414]   Expert 50 |    112 | CPU
DEBUG 01-06 17:11:21.293339.293339 lmp.py:414]   Expert 34 |    113 | CPU
DEBUG 01-06 17:11:21.293790.293790 lmp.py:414]   Expert 42 |    116 | CPU
DEBUG 01-06 17:11:21.293240.293240 lmp.py:414]   Expert 24 |    117 | CPU
DEBUG 01-06 17:11:21.293645.293645 lmp.py:414]   Expert 36 |    119 | CPU
DEBUG 01-06 17:11:21.293811.293811 lmp.py:414]   Expert 39 |    127 | CPU
DEBUG 01-06 17:11:21.293262.293262 lmp.py:414]   Expert  4 |    131 | CPU
DEBUG 01-06 17:11:21.293713.293713 lmp.py:414]   Expert 37 |    143 | CPU
DEBUG 01-06 17:11:21.293402.293402 lmp.py:414]   Expert 15 |    153 | CPU
DEBUG 01-06 17:11:21.293092.293092 lmp.py:414]   Expert 41 |    153 | CPU
DEBUG 01-06 17:11:21.293542.293542 lmp.py:414]   Expert 23 |    154 | CPU
DEBUG 01-06 17:11:21.293232.293232 lmp.py:414]   Expert 16 |    165 | GPU
DEBUG 01-06 17:11:21.293636.293636 lmp.py:414]   Expert 56 |    168 | GPU
DEBUG 01-06 17:11:21.293041.293041 lmp.py:414]   Expert  1 |    171 | GPU
DEBUG 01-06 17:11:21.293730.293730 lmp.py:414]   Expert 43 |    178 | GPU
DEBUG 01-06 17:11:21.293181.293181 lmp.py:414]   Expert 44 |    180 | GPU
DEBUG 01-06 17:11:21.294393.294393 lmp.py:414]   Expert 60 |    182 | GPU
DEBUG 01-06 17:11:21.294560.294560 lmp.py:414]   Expert 53 |    185 | GPU
DEBUG 01-06 17:11:21.294249.294249 lmp.py:414]   Expert 21 |    188 | GPU
DEBUG 01-06 17:11:21.294177.294177 lmp.py:414]   Expert 47 |    199 | GPU
DEBUG 01-06 17:11:21.294343.294343 lmp.py:414]   Expert 12 |    202 | GPU
DEBUG 01-06 17:11:21.294509.294509 lmp.py:414]   Expert 33 |    204 | GPU
DEBUG 01-06 17:11:21.294913.294913 lmp.py:414]   Expert 13 |    212 | GPU
DEBUG 01-06 17:11:21.294318.294318 lmp.py:414]   Expert 32 |    224 | GPU
DEBUG 01-06 17:11:21.294007.294007 lmp.py:414]   Expert 28 |    228 | GPU
DEBUG 01-06 17:11:21.294650.294650 lmp.py:414]   Expert  0 |    251 | GPU
DEBUG 01-06 17:11:21.294816.294816 lmp.py:414]   Expert 31 |    259 | GPU
DEBUG 01-06 17:11:21.294983.294983 lmp.py:414]   Expert 54 |    260 | GPU
DEBUG 01-06 17:11:21.294387.294387 lmp.py:414]   Expert 10 |    268 | GPU
DEBUG 01-06 17:11:21.294507.294507 lmp.py:414]   Expert 26 |    269 | GPU
DEBUG 01-06 17:11:21.294958.294958 lmp.py:414]   Expert 18 |    270 | GPU
DEBUG 01-06 17:11:21.294170.294170 lmp.py:414]   Expert 57 |    273 | GPU
DEBUG 01-06 17:11:21.294860.294860 lmp.py:414]   Expert  2 |    283 | GPU
DEBUG 01-06 17:11:21.294549.294549 lmp.py:414]   Expert 58 |    299 | GPU
DEBUG 01-06 17:11:21.294477.294477 lmp.py:414]   Expert 40 |    336 | GPU
DEBUG 01-06 17:11:21.294643.294643 lmp.py:414]   Expert 45 |    360 | GPU
DEBUG 01-06 17:11:21.294332.294332 lmp.py:414]   Expert 25 |    388 | GPU
DEBUG 01-06 17:11:21.294783.294783 lmp.py:414]   Expert  5 |    427 | GPU
DEBUG 01-06 17:11:21.294234.294234 lmp.py:414]   Expert 35 |    461 | GPU
DEBUG 01-06 17:11:21.294923.294923 lmp.py:414]   Expert 27 |    482 | GPU
DEBUG 01-06 17:11:21.294374.294374 lmp.py:414]   Expert 46 |    520 | GPU
DEBUG 01-06 17:11:21.294779.294779 lmp.py:414]   Expert 52 |    607 | GPU
DEBUG 01-06 17:11:21.294945.294945 lmp.py:414]   Expert 14 |    890 | GPU
DEBUG 01-06 17:11:21.294588.294588 lmp.py:415] 
DEBUG 01-06 17:11:21.294588.294588 lmp.py:415]   CPU total tokens: 2699 (22.0%)
DEBUG 01-06 17:11:21.294992.294992 lmp.py:416]   GPU total tokens: 9589 (78.0%)
DEBUG 01-06 17:11:21.294688.294688 cuda_h.py:19] end experts_map_get cost 0.0015728473663330078 seconds
DEBUG 01-06 17:11:21.294808.294808 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-06 17:11:21.294214.294214 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 17:11:21.294650.294650 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 17:11:21.296379.296379 cuda_h.py:19] end allocate_cuda_memory cost 0.001941680908203125 seconds
DEBUG 01-06 17:11:21.296990.296990 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 17:11:21.296462.296462 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 17:11:21.296946.296946 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 17:11:21.296788.296788 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 4e877db6-4b04-4fa7-98bb-cf24b5e1254c
DEBUG 01-06 17:11:21.297055.297055 client.py:106] call stub.LoadModelAsync
INFO 01-06 17:11:21.297502.297502 client.py:127] Model loaded
DEBUG 01-06 17:11:21.297824.297824 cuda_h.py:19] end sllm_worker_task cost 0.010923147201538086 seconds
INFO 01-06 17:11:21.299993.299993 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 4e877db6-4b04-4fa7-98bb-cf24b5e1254c
DEBUG 01-06 17:11:21.299194.299194 cuda_h.py:19] end load_into_gpu_async cost 0.0022933483123779297 seconds
DEBUG 01-06 17:11:21.299804.299804 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 17:11:21.300604.300604 cuda_h.py:19] end restore_tensors2 cost 0.0009129047393798828 seconds
DEBUG 01-06 17:11:21.300944.300944 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0055696964263916016 seconds
DEBUG 01-06 17:11:21.302168.302168 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.008349418640136719 seconds
DEBUG 01-06 17:11:21.302760.302760 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-06 17:11:21.303843.303843 lmp.py:461] 
DEBUG 01-06 17:11:21.303843.303843 lmp.py:461]   Computing 32 experts on CPU...
DEBUG 01-06 17:11:21.303647.303647 cuda_h.py:19] end cpu_experts_submit cost 0.00013399124145507812 seconds
DEBUG 01-06 17:11:21.303012.303012 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-06 17:11:21.313510.313510 mlpmodule.py:706] group tensors cost 0.009735345840454102 s
DEBUG 01-06 17:11:21.315022.315022 mlpmodule.py:744] pad cost 0.0015881061553955078 s
DEBUG 01-06 17:11:21.315463.315463 mlpmodule.py:750] create cpu tensor cost 5.340576171875e-05 s
DEBUG 01-06 17:11:21.315227.315227 mlpmodule.py:755] move to cpu cost 3.3855438232421875e-05 s
DEBUG 01-06 17:11:21.325091.325091 mlpmodule.py:769] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-06 17:11:21.325419.325419 mlpmodule.py:770] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-06 17:11:21.325269.325269 mlpmodule.py:775] group_w3 first element: -0.0024261474609375
WARNING 01-06 17:11:21.325511.325511 mlpmodule.py:785] start einsum2
DEBUG 01-06 17:11:21.342330.342330 mlpmodule.py:795] group einsum cost 0.027330875396728516 s
DEBUG 01-06 17:11:21.343938.343938 mlpmodule.py:803] cpy2cputensor cost 0.0006086826324462891 s
DEBUG 01-06 17:11:21.348335.348335 cuda_h.py:19] end wait_cetm_experts cost 0.0449981689453125 seconds
DEBUG 01-06 17:11:21.348296.348296 cuda_h.py:10] start gpu_sexperts
DEBUG 01-06 17:11:21.349597.349597 cuda_h.py:19] end gpu_sexperts cost 0.0006303787231445312 seconds
DEBUG 01-06 17:11:21.349030.349030 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-06 17:11:21.349364.349364 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 2.9087066650390625e-05 seconds
DEBUG 01-06 17:11:21.349543.349543 cuda_h.py:10] start wait_experts
INFO 01-06 17:11:21.349015.349015 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 4e877db6-4b04-4fa7-98bb-cf24b5e1254c
INFO 01-06 17:11:21.353015.353015 client.py:127] Model loaded
DEBUG 01-06 17:11:21.353864.353864 cuda_h.py:19] end wait_experts cost 0.0038237571716308594 seconds
DEBUG 01-06 17:11:21.353382.353382 cuda_h.py:10] start gpu_experts
DEBUG 01-06 17:11:21.353045.353045 lmp.py:506]   Computing 32 experts on GPU...
DEBUG 01-06 17:11:21.353069.353069 mlpmodule.py:533] gpu group tensors cost 0.0006272792816162109 s
DEBUG 01-06 17:11:21.355632.355632 mlpmodule.py:566] gpu pad cost 0.0018990039825439453 s
DEBUG 01-06 17:11:21.356074.356074 mlpmodule.py:664]  experts func einsum cost 0.05270242691040039 s
DEBUG 01-06 17:11:21.356026.356026 mlpmodule.py:584] gpu group einsum cost 0.0006318092346191406 s
DEBUG 01-06 17:11:21.360651.360651 mlpmodule.py:613] gpu experts func einsum cost 0.006708383560180664 s
DEBUG 01-06 17:11:21.360489.360489 cuda_h.py:19] end gpu_experts cost 0.006930112838745117 seconds
DEBUG 01-06 17:11:21.360280.360280 cuda_h.py:19] end layer_moe_generate_26 cost 0.06820440292358398 seconds
DEBUG 01-06 17:11:21.360056.360056 lmp.py:220] -------------------------------- end layer 26 --------------------------------
DEBUG 01-06 17:11:21.360263.360263 lmp.py:176] -------------------------------- start layer 27 --------------------------------
DEBUG 01-06 17:11:21.360151.360151 cuda_h.py:10] start start_load_qkvogn_s_weight_l_28
DEBUG 01-06 17:11:21.360921.360921 cuda_h.py:19] end start_load_qkvogn_s_weight_l_28 cost 1.2636184692382812e-05 seconds
DEBUG 01-06 17:11:21.360994.360994 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-06 17:11:21.360036.360036 mlpmodule.py:367] cuda:1 cuda:1
DEBUG 01-06 17:11:21.360900.360900 cuda_h.py:10] start self_attn
cos shape torch.Size([64, 128]) sin shape torch.Size([64, 128]) position_ids tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,
         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,
         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,
         54, 55, 56, 57, 58, 59, 60, 61, 62, 63]], device='cuda:1')
cos shape torch.Size([1, 1, 64, 128]) sin shape torch.Size([1, 1, 64, 128])
q_embed shape torch.Size([32, 16, 64, 128]) k_embed shape torch.Size([32, 16, 64, 128])
DEBUG 01-06 17:11:21.363940.363940 cuda_h.py:19] end self_attn cost 0.0027103424072265625 seconds
DEBUG 01-06 17:11:21.364990.364990 cuda_h.py:19] end iln_self_attn_paln cost 0.003409147262573242 seconds
DEBUG 01-06 17:11:21.364403.364403 cuda_h.py:10] start layer_moe_generate_27
DEBUG 01-06 17:11:21.364358.364358 cuda_h.py:10] start gate
DEBUG 01-06 17:11:21.364705.364705 cuda_h.py:19] end gate cost 0.0006432533264160156 seconds
DEBUG 01-06 17:11:21.364057.364057 cuda_h.py:10] start experts_map_get
DEBUG 01-06 17:11:21.365207.365207 lmp.py:403] 
DEBUG 01-06 17:11:21.365207.365207 lmp.py:403] Expert Token Distribution & Device Allocation:
DEBUG 01-06 17:11:21.365725.365725 lmp.py:404]   Total experts: 64
DEBUG 01-06 17:11:21.365851.365851 lmp.py:405]   CPU experts: 32 (50%)
DEBUG 01-06 17:11:21.365163.365163 lmp.py:406]   GPU experts: 32 (50%)
DEBUG 01-06 17:11:21.365091.365091 lmp.py:407] 
DEBUG 01-06 17:11:21.365091.365091 lmp.py:407]   Expert ID | Tokens | Device
DEBUG 01-06 17:11:21.365734.365734 lmp.py:408]   -----------------------------------
DEBUG 01-06 17:11:21.365861.365861 lmp.py:414]   Expert 18 |     58 | CPU
DEBUG 01-06 17:11:21.365219.365219 lmp.py:414]   Expert 54 |     62 | CPU
DEBUG 01-06 17:11:21.365385.365385 lmp.py:414]   Expert 44 |     75 | CPU
DEBUG 01-06 17:11:21.365313.365313 lmp.py:414]   Expert 45 |     75 | CPU
DEBUG 01-06 17:11:21.365525.365525 lmp.py:414]   Expert 47 |     75 | CPU
DEBUG 01-06 17:11:21.365976.365976 lmp.py:414]   Expert 23 |     76 | CPU
DEBUG 01-06 17:11:21.365950.365950 lmp.py:414]   Expert 48 |     82 | CPU
DEBUG 01-06 17:11:21.365686.365686 lmp.py:414]   Expert 20 |     92 | CPU
DEBUG 01-06 17:11:21.365375.365375 lmp.py:414]   Expert 36 |    102 | CPU
DEBUG 01-06 17:11:21.365826.365826 lmp.py:414]   Expert 31 |    103 | CPU
DEBUG 01-06 17:11:21.365561.365561 lmp.py:414]   Expert 42 |    114 | CPU
DEBUG 01-06 17:11:21.365774.365774 lmp.py:414]   Expert 61 |    115 | CPU
DEBUG 01-06 17:11:21.365748.365748 lmp.py:414]   Expert 10 |    118 | CPU
DEBUG 01-06 17:11:21.365245.365245 lmp.py:414]   Expert 24 |    118 | CPU
DEBUG 01-06 17:11:21.365219.365219 lmp.py:414]   Expert 11 |    119 | CPU
DEBUG 01-06 17:11:21.365955.365955 lmp.py:414]   Expert 33 |    121 | CPU
DEBUG 01-06 17:11:21.365929.365929 lmp.py:414]   Expert 49 |    126 | CPU
DEBUG 01-06 17:11:21.365141.365141 lmp.py:414]   Expert 43 |    130 | CPU
DEBUG 01-06 17:11:21.365831.365831 lmp.py:414]   Expert 56 |    132 | CPU
DEBUG 01-06 17:11:21.365805.365805 lmp.py:414]   Expert 51 |    139 | CPU
DEBUG 01-06 17:11:21.365494.365494 lmp.py:414]   Expert 17 |    142 | CPU
DEBUG 01-06 17:11:21.365230.365230 lmp.py:414]   Expert  6 |    143 | CPU
DEBUG 01-06 17:11:21.365442.365442 lmp.py:414]   Expert  0 |    148 | CPU
DEBUG 01-06 17:11:21.365416.365416 lmp.py:414]   Expert 12 |    155 | CPU
DEBUG 01-06 17:11:21.365152.365152 lmp.py:414]   Expert 40 |    155 | CPU
DEBUG 01-06 17:11:21.365364.365364 lmp.py:414]   Expert 55 |    157 | CPU
DEBUG 01-06 17:11:21.365815.365815 lmp.py:414]   Expert 13 |    160 | CPU
DEBUG 01-06 17:11:21.365504.365504 lmp.py:414]   Expert  5 |    162 | CPU
DEBUG 01-06 17:11:21.365478.365478 lmp.py:414]   Expert 26 |    168 | CPU
DEBUG 01-06 17:11:21.365452.365452 lmp.py:414]   Expert 59 |    170 | CPU
DEBUG 01-06 17:11:21.365188.365188 lmp.py:414]   Expert 38 |    171 | CPU
DEBUG 01-06 17:11:21.365924.365924 lmp.py:414]   Expert 57 |    172 | CPU
DEBUG 01-06 17:11:21.365136.365136 lmp.py:414]   Expert 58 |    173 | GPU
DEBUG 01-06 17:11:21.365872.365872 lmp.py:414]   Expert 30 |    176 | GPU
DEBUG 01-06 17:11:21.365369.365369 lmp.py:414]   Expert  7 |    178 | GPU
DEBUG 01-06 17:11:21.365820.365820 lmp.py:414]   Expert 46 |    182 | GPU
DEBUG 01-06 17:11:21.365794.365794 lmp.py:414]   Expert 35 |    183 | GPU
DEBUG 01-06 17:11:21.365768.365768 lmp.py:414]   Expert 50 |    183 | GPU
DEBUG 01-06 17:11:21.365504.365504 lmp.py:414]   Expert 16 |    185 | GPU
DEBUG 01-06 17:11:21.365239.365239 lmp.py:414]   Expert 32 |    196 | GPU
DEBUG 01-06 17:11:21.365213.365213 lmp.py:414]   Expert 14 |    199 | GPU
DEBUG 01-06 17:11:21.365949.365949 lmp.py:414]   Expert 15 |    199 | GPU
DEBUG 01-06 17:11:21.365161.365161 lmp.py:414]   Expert  3 |    212 | GPU
DEBUG 01-06 17:11:21.366659.366659 lmp.py:414]   Expert  1 |    215 | GPU
DEBUG 01-06 17:11:21.366633.366633 lmp.py:414]   Expert  4 |    223 | GPU
DEBUG 01-06 17:11:21.366130.366130 lmp.py:414]   Expert 39 |    240 | GPU
DEBUG 01-06 17:11:21.366865.366865 lmp.py:414]   Expert 25 |    242 | GPU
DEBUG 01-06 17:11:21.366124.366124 lmp.py:414]   Expert 34 |    245 | GPU
DEBUG 01-06 17:11:21.366098.366098 lmp.py:414]   Expert 52 |    245 | GPU
DEBUG 01-06 17:11:21.366311.366311 lmp.py:414]   Expert 28 |    253 | GPU
DEBUG 01-06 17:11:21.366046.366046 lmp.py:414]   Expert 22 |    268 | GPU
DEBUG 01-06 17:11:21.366020.366020 lmp.py:414]   Expert 21 |    272 | GPU
DEBUG 01-06 17:11:21.366756.366756 lmp.py:414]   Expert  2 |    276 | GPU
DEBUG 01-06 17:11:21.366730.366730 lmp.py:414]   Expert 41 |    280 | GPU
DEBUG 01-06 17:11:21.366466.366466 lmp.py:414]   Expert 60 |    283 | GPU
DEBUG 01-06 17:11:21.366917.366917 lmp.py:414]   Expert 29 |    289 | GPU
DEBUG 01-06 17:11:21.366083.366083 lmp.py:414]   Expert 63 |    289 | GPU
DEBUG 01-06 17:11:21.366295.366295 lmp.py:414]   Expert 62 |    296 | GPU
DEBUG 01-06 17:11:21.366792.366792 lmp.py:414]   Expert 27 |    313 | GPU
DEBUG 01-06 17:11:21.366766.366766 lmp.py:414]   Expert 53 |    327 | GPU
DEBUG 01-06 17:11:21.366264.366264 lmp.py:414]   Expert  8 |    331 | GPU
DEBUG 01-06 17:11:21.366238.366238 lmp.py:414]   Expert 37 |    334 | GPU
DEBUG 01-06 17:11:21.366735.366735 lmp.py:414]   Expert 19 |    436 | GPU
DEBUG 01-06 17:11:21.366709.366709 lmp.py:414]   Expert  9 |    630 | GPU
DEBUG 01-06 17:11:21.366160.366160 lmp.py:415] 
DEBUG 01-06 17:11:21.366160.366160 lmp.py:415]   CPU total tokens: 3935 (32.0%)
DEBUG 01-06 17:11:21.366088.366088 lmp.py:416]   GPU total tokens: 8353 (68.0%)
DEBUG 01-06 17:11:21.366068.366068 cuda_h.py:19] end experts_map_get cost 0.0014901161193847656 seconds
DEBUG 01-06 17:11:21.366235.366235 cuda_h.py:10] start allocate_experts_cuda_memory_and_restore_model
DEBUG 01-06 17:11:21.366779.366779 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 17:11:21.366228.366228 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 17:11:21.367807.367807 cuda_h.py:19] end allocate_cuda_memory cost 0.0006387233734130859 seconds
DEBUG 01-06 17:11:21.367180.367180 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 17:11:21.367651.367651 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 17:11:21.368328.368328 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 17:11:21.368078.368078 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 40c3a277-2366-4a6a-894e-8ce8842c2497
DEBUG 01-06 17:11:21.368906.368906 client.py:106] call stub.LoadModelAsync
INFO 01-06 17:11:21.370881.370881 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 40c3a277-2366-4a6a-894e-8ce8842c2497
DEBUG 01-06 17:11:21.370671.370671 cuda_h.py:19] end load_into_gpu_async cost 0.002367258071899414 seconds
DEBUG 01-06 17:11:21.370943.370943 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 17:11:21.371215.371215 cuda_h.py:19] end restore_tensors2 cost 0.0007698535919189453 seconds
DEBUG 01-06 17:11:21.371979.371979 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.004758596420288086 seconds
DEBUG 01-06 17:11:21.373441.373441 cuda_h.py:19] end allocate_experts_cuda_memory_and_restore_model cost 0.007535457611083984 seconds
DEBUG 01-06 17:11:21.374047.374047 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-06 17:11:21.374441.374441 lmp.py:461] 
DEBUG 01-06 17:11:21.374441.374441 lmp.py:461]   Computing 32 experts on CPU...
DEBUG 01-06 17:11:21.374059.374059 cuda_h.py:19] end cpu_experts_submit cost 0.00012040138244628906 seconds
DEBUG 01-06 17:11:21.374616.374616 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-06 17:11:21.379640.379640 mlpmodule.py:706] group tensors cost 0.005439281463623047 s
DEBUG 01-06 17:11:21.382810.382810 mlpmodule.py:744] pad cost 0.0015900135040283203 s
DEBUG 01-06 17:11:21.382337.382337 mlpmodule.py:750] create cpu tensor cost 4.3392181396484375e-05 s
DEBUG 01-06 17:11:21.382379.382379 mlpmodule.py:755] move to cpu cost 3.123283386230469e-05 s
DEBUG 01-06 17:11:21.392802.392802 mlpmodule.py:769] group_w3: shape=torch.Size([32, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=92274688
DEBUG 01-06 17:11:21.392580.392580 mlpmodule.py:770] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-06 17:11:21.392126.392126 mlpmodule.py:775] group_w3 first element: -0.006439208984375
WARNING 01-06 17:11:21.392977.392977 mlpmodule.py:785] start einsum2
DEBUG 01-06 17:11:21.410792.410792 mlpmodule.py:795] group einsum cost 0.027691125869750977 s
DEBUG 01-06 17:11:21.410826.410826 mlpmodule.py:803] cpy2cputensor cost 0.0006775856018066406 s
DEBUG 01-06 17:11:21.415503.415503 cuda_h.py:19] end wait_cetm_experts cost 0.041059255599975586 seconds
DEBUG 01-06 17:11:21.415146.415146 cuda_h.py:10] start gpu_sexperts
DEBUG 01-06 17:11:21.416407.416407 cuda_h.py:19] end gpu_sexperts cost 0.0006384849548339844 seconds
DEBUG 01-06 17:11:21.416787.416787 cuda_h.py:10] start wait_load_qkvogn_s_weight
DEBUG 01-06 17:11:21.416047.416047 cuda_h.py:19] end wait_load_qkvogn_s_weight cost 1.1444091796875e-05 seconds
DEBUG 01-06 17:11:21.416843.416843 cuda_h.py:10] start wait_experts
INFO 01-06 17:11:21.416414.416414 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 40c3a277-2366-4a6a-894e-8ce8842c2497
DEBUG 01-06 17:11:21.422119.422119 mlpmodule.py:664]  experts func einsum cost 0.04763913154602051 s
INFO 01-06 17:11:21.425517.425517 client.py:127] Model loaded
DEBUG 01-06 17:11:21.425539.425539 cuda_h.py:19] end wait_experts cost 0.009081125259399414 seconds
DEBUG 01-06 17:11:21.425580.425580 cuda_h.py:10] start gpu_experts
DEBUG 01-06 17:11:21.425045.425045 lmp.py:506]   Computing 32 experts on GPU...
DEBUG 01-06 17:11:21.426077.426077 mlpmodule.py:533] gpu group tensors cost 0.0005054473876953125 s
DEBUG 01-06 17:11:21.427291.427291 mlpmodule.py:566] gpu pad cost 0.0015723705291748047 s
DEBUG 01-06 17:11:21.428384.428384 mlpmodule.py:584] gpu group einsum cost 0.0005278587341308594 s
DEBUG 01-06 17:11:21.431622.431622 mlpmodule.py:613] gpu experts func einsum cost 0.0056819915771484375 s
DEBUG 01-06 17:11:21.431452.431452 cuda_h.py:19] end gpu_experts cost 0.005850791931152344 seconds
DEBUG 01-06 17:11:21.431966.431966 cuda_h.py:19] end layer_moe_generate_27 cost 0.0674138069152832 seconds
DEBUG 01-06 17:11:21.431642.431642 lmp.py:220] -------------------------------- end layer 27 --------------------------------
DEBUG 01-06 17:11:21.431895.431895 cuda_h.py:19] end multi_layer cost 2.1111879348754883 seconds
DEBUG 01-06 17:11:21.431306.431306 cuda_h.py:10] start decode_layer
DEBUG 01-06 17:11:21.442963.442963 cuda_h.py:10] start async_load_ce
INFO 01-06 17:11:21.443497.443497 cuda_memory_view.py:165] Collecting expert device distribution for all layers...
INFO 01-06 17:11:21.443436.443436 cuda_memory_view.py:189] Layer 1: CPU experts = [0, 1, 3, 10, 11, 13, 17, 18, 22, 25, 27, 28, 31, 32, 34, 35, 36, 37, 38, 41, 43, 44, 47, 49, 51, 52, 54, 55, 58, 59, 60, 62] (total: 32, device_map: {0: 'meta', 1: 'meta', 2: 'cuda:1', 3: 'meta', 4: 'cuda:1', 5: 'cuda:1', 6: 'cuda:1', 7: 'cuda:1', 8: 'cuda:1', 9: 'cuda:1', 10: 'meta', 11: 'meta', 12: 'cuda:1', 13: 'meta', 14: 'cuda:1', 15: 'cuda:1', 16: 'cuda:1', 17: 'meta', 18: 'meta', 19: 'cuda:1', 20: 'cuda:1', 21: 'cuda:1', 22: 'meta', 23: 'cuda:1', 24: 'cuda:1', 25: 'meta', 26: 'cuda:1', 27: 'meta', 28: 'meta', 29: 'cuda:1', 30: 'cuda:1', 31: 'meta', 32: 'meta', 33: 'cuda:1', 34: 'meta', 35: 'meta', 36: 'meta', 37: 'meta', 38: 'meta', 39: 'cuda:1', 40: 'cuda:1', 41: 'meta', 42: 'cuda:1', 43: 'meta', 44: 'meta', 45: 'cuda:1', 46: 'cuda:1', 47: 'meta', 48: 'cuda:1', 49: 'meta', 50: 'cuda:1', 51: 'meta', 52: 'meta', 53: 'cuda:1', 54: 'meta', 55: 'meta', 56: 'cuda:1', 57: 'cuda:1', 58: 'meta', 59: 'meta', 60: 'meta', 61: 'cuda:1', 62: 'meta', 63: 'cuda:1'})
INFO 01-06 17:11:21.444478.444478 cuda_memory_view.py:189] Layer 2: CPU experts = [0, 1, 3, 6, 7, 8, 9, 12, 15, 17, 23, 24, 25, 26, 27, 28, 29, 30, 32, 34, 35, 36, 37, 45, 48, 49, 51, 53, 54, 57, 58, 62] (total: 32, device_map: {0: 'meta', 1: 'meta', 2: 'cuda:1', 3: 'meta', 4: 'cuda:1', 5: 'cuda:1', 6: 'meta', 7: 'meta', 8: 'meta', 9: 'meta', 10: 'cuda:1', 11: 'cuda:1', 12: 'meta', 13: 'cuda:1', 14: 'cuda:1', 15: 'meta', 16: 'cuda:1', 17: 'meta', 18: 'cuda:1', 19: 'cuda:1', 20: 'cuda:1', 21: 'cuda:1', 22: 'cuda:1', 23: 'meta', 24: 'meta', 25: 'meta', 26: 'meta', 27: 'meta', 28: 'meta', 29: 'meta', 30: 'meta', 31: 'cuda:1', 32: 'meta', 33: 'cuda:1', 34: 'meta', 35: 'meta', 36: 'meta', 37: 'meta', 38: 'cuda:1', 39: 'cuda:1', 40: 'cuda:1', 41: 'cuda:1', 42: 'cuda:1', 43: 'cuda:1', 44: 'cuda:1', 45: 'meta', 46: 'cuda:1', 47: 'cuda:1', 48: 'meta', 49: 'meta', 50: 'cuda:1', 51: 'meta', 52: 'cuda:1', 53: 'meta', 54: 'meta', 55: 'cuda:1', 56: 'cuda:1', 57: 'meta', 58: 'meta', 59: 'cuda:1', 60: 'cuda:1', 61: 'cuda:1', 62: 'meta', 63: 'cuda:1'})
INFO 01-06 17:11:21.444751.444751 cuda_memory_view.py:189] Layer 3: CPU experts = [1, 2, 4, 5, 6, 7, 9, 11, 13, 15, 16, 18, 23, 26, 27, 30, 32, 34, 35, 36, 37, 39, 40, 45, 48, 49, 50, 51, 52, 56, 59, 61] (total: 32, device_map: {0: 'cuda:1', 1: 'meta', 2: 'meta', 3: 'cuda:1', 4: 'meta', 5: 'meta', 6: 'meta', 7: 'meta', 8: 'cuda:1', 9: 'meta', 10: 'cuda:1', 11: 'meta', 12: 'cuda:1', 13: 'meta', 14: 'cuda:1', 15: 'meta', 16: 'meta', 17: 'cuda:1', 18: 'meta', 19: 'cuda:1', 20: 'cuda:1', 21: 'cuda:1', 22: 'cuda:1', 23: 'meta', 24: 'cuda:1', 25: 'cuda:1', 26: 'meta', 27: 'meta', 28: 'cuda:1', 29: 'cuda:1', 30: 'meta', 31: 'cuda:1', 32: 'meta', 33: 'cuda:1', 34: 'meta', 35: 'meta', 36: 'meta', 37: 'meta', 38: 'cuda:1', 39: 'meta', 40: 'meta', 41: 'cuda:1', 42: 'cuda:1', 43: 'cuda:1', 44: 'cuda:1', 45: 'meta', 46: 'cuda:1', 47: 'cuda:1', 48: 'meta', 49: 'meta', 50: 'meta', 51: 'meta', 52: 'meta', 53: 'cuda:1', 54: 'cuda:1', 55: 'cuda:1', 56: 'meta', 57: 'cuda:1', 58: 'cuda:1', 59: 'meta', 60: 'cuda:1', 61: 'meta', 62: 'cuda:1', 63: 'cuda:1'})
INFO 01-06 17:11:21.444355.444355 cuda_memory_view.py:189] Layer 4: CPU experts = [4, 7, 8, 10, 11, 13, 14, 16, 17, 20, 26, 27, 28, 29, 30, 31, 32, 34, 36, 41, 42, 45, 47, 48, 51, 53, 54, 57, 58, 60, 61, 63] (total: 32, device_map: {0: 'cuda:1', 1: 'cuda:1', 2: 'cuda:1', 3: 'cuda:1', 4: 'meta', 5: 'cuda:1', 6: 'cuda:1', 7: 'meta', 8: 'meta', 9: 'cuda:1', 10: 'meta', 11: 'meta', 12: 'cuda:1', 13: 'meta', 14: 'meta', 15: 'cuda:1', 16: 'meta', 17: 'meta', 18: 'cuda:1', 19: 'cuda:1', 20: 'meta', 21: 'cuda:1', 22: 'cuda:1', 23: 'cuda:1', 24: 'cuda:1', 25: 'cuda:1', 26: 'meta', 27: 'meta', 28: 'meta', 29: 'meta', 30: 'meta', 31: 'meta', 32: 'meta', 33: 'cuda:1', 34: 'meta', 35: 'cuda:1', 36: 'meta', 37: 'cuda:1', 38: 'cuda:1', 39: 'cuda:1', 40: 'cuda:1', 41: 'meta', 42: 'meta', 43: 'cuda:1', 44: 'cuda:1', 45: 'meta', 46: 'cuda:1', 47: 'meta', 48: 'meta', 49: 'cuda:1', 50: 'cuda:1', 51: 'meta', 52: 'cuda:1', 53: 'meta', 54: 'meta', 55: 'cuda:1', 56: 'cuda:1', 57: 'meta', 58: 'meta', 59: 'cuda:1', 60: 'meta', 61: 'meta', 62: 'cuda:1', 63: 'meta'})
INFO 01-06 17:11:21.445325.445325 cuda_memory_view.py:189] Layer 5: CPU experts = [0, 2, 3, 4, 5, 8, 9, 12, 13, 14, 15, 16, 17, 22, 23, 25, 28, 30, 31, 32, 34, 35, 36, 39, 42, 44, 45, 46, 52, 57, 60, 61] (total: 32, device_map: {0: 'meta', 1: 'cuda:1', 2: 'meta', 3: 'meta', 4: 'meta', 5: 'meta', 6: 'cuda:1', 7: 'cuda:1', 8: 'meta', 9: 'meta', 10: 'cuda:1', 11: 'cuda:1', 12: 'meta', 13: 'meta', 14: 'meta', 15: 'meta', 16: 'meta', 17: 'meta', 18: 'cuda:1', 19: 'cuda:1', 20: 'cuda:1', 21: 'cuda:1', 22: 'meta', 23: 'meta', 24: 'cuda:1', 25: 'meta', 26: 'cuda:1', 27: 'cuda:1', 28: 'meta', 29: 'cuda:1', 30: 'meta', 31: 'meta', 32: 'meta', 33: 'cuda:1', 34: 'meta', 35: 'meta', 36: 'meta', 37: 'cuda:1', 38: 'cuda:1', 39: 'meta', 40: 'cuda:1', 41: 'cuda:1', 42: 'meta', 43: 'cuda:1', 44: 'meta', 45: 'meta', 46: 'meta', 47: 'cuda:1', 48: 'cuda:1', 49: 'cuda:1', 50: 'cuda:1', 51: 'cuda:1', 52: 'meta', 53: 'cuda:1', 54: 'cuda:1', 55: 'cuda:1', 56: 'cuda:1', 57: 'meta', 58: 'cuda:1', 59: 'cuda:1', 60: 'meta', 61: 'meta', 62: 'cuda:1', 63: 'cuda:1'})
INFO 01-06 17:11:21.445220.445220 cuda_memory_view.py:189] Layer 6: CPU experts = [0, 1, 2, 3, 7, 9, 10, 11, 13, 14, 16, 17, 18, 22, 23, 26, 28, 29, 32, 33, 37, 40, 43, 45, 51, 53, 54, 55, 58, 59, 62, 63] (total: 32, device_map: {0: 'meta', 1: 'meta', 2: 'meta', 3: 'meta', 4: 'cuda:1', 5: 'cuda:1', 6: 'cuda:1', 7: 'meta', 8: 'cuda:1', 9: 'meta', 10: 'meta', 11: 'meta', 12: 'cuda:1', 13: 'meta', 14: 'meta', 15: 'cuda:1', 16: 'meta', 17: 'meta', 18: 'meta', 19: 'cuda:1', 20: 'cuda:1', 21: 'cuda:1', 22: 'meta', 23: 'meta', 24: 'cuda:1', 25: 'cuda:1', 26: 'meta', 27: 'cuda:1', 28: 'meta', 29: 'meta', 30: 'cuda:1', 31: 'cuda:1', 32: 'meta', 33: 'meta', 34: 'cuda:1', 35: 'cuda:1', 36: 'cuda:1', 37: 'meta', 38: 'cuda:1', 39: 'cuda:1', 40: 'meta', 41: 'cuda:1', 42: 'cuda:1', 43: 'meta', 44: 'cuda:1', 45: 'meta', 46: 'cuda:1', 47: 'cuda:1', 48: 'cuda:1', 49: 'cuda:1', 50: 'cuda:1', 51: 'meta', 52: 'cuda:1', 53: 'meta', 54: 'meta', 55: 'meta', 56: 'cuda:1', 57: 'cuda:1', 58: 'meta', 59: 'meta', 60: 'cuda:1', 61: 'cuda:1', 62: 'meta', 63: 'meta'})
INFO 01-06 17:11:21.446878.446878 cuda_memory_view.py:189] Layer 7: CPU experts = [1, 3, 4, 6, 7, 8, 10, 11, 13, 14, 15, 16, 18, 20, 27, 28, 29, 36, 39, 40, 41, 43, 45, 46, 48, 50, 51, 52, 54, 55, 56, 60] (total: 32, device_map: {0: 'cuda:1', 1: 'meta', 2: 'cuda:1', 3: 'meta', 4: 'meta', 5: 'cuda:1', 6: 'meta', 7: 'meta', 8: 'meta', 9: 'cuda:1', 10: 'meta', 11: 'meta', 12: 'cuda:1', 13: 'meta', 14: 'meta', 15: 'meta', 16: 'meta', 17: 'cuda:1', 18: 'meta', 19: 'cuda:1', 20: 'meta', 21: 'cuda:1', 22: 'cuda:1', 23: 'cuda:1', 24: 'cuda:1', 25: 'cuda:1', 26: 'cuda:1', 27: 'meta', 28: 'meta', 29: 'meta', 30: 'cuda:1', 31: 'cuda:1', 32: 'cuda:1', 33: 'cuda:1', 34: 'cuda:1', 35: 'cuda:1', 36: 'meta', 37: 'cuda:1', 38: 'cuda:1', 39: 'meta', 40: 'meta', 41: 'meta', 42: 'cuda:1', 43: 'meta', 44: 'cuda:1', 45: 'meta', 46: 'meta', 47: 'cuda:1', 48: 'meta', 49: 'cuda:1', 50: 'meta', 51: 'meta', 52: 'meta', 53: 'cuda:1', 54: 'meta', 55: 'meta', 56: 'meta', 57: 'cuda:1', 58: 'cuda:1', 59: 'cuda:1', 60: 'meta', 61: 'cuda:1', 62: 'cuda:1', 63: 'cuda:1'})
INFO 01-06 17:11:21.446151.446151 cuda_memory_view.py:189] Layer 8: CPU experts = [0, 1, 6, 7, 8, 12, 14, 15, 16, 17, 18, 22, 24, 27, 29, 30, 32, 33, 34, 35, 36, 38, 39, 40, 42, 44, 48, 51, 53, 54, 59, 60] (total: 32, device_map: {0: 'meta', 1: 'meta', 2: 'cuda:1', 3: 'cuda:1', 4: 'cuda:1', 5: 'cuda:1', 6: 'meta', 7: 'meta', 8: 'meta', 9: 'cuda:1', 10: 'cuda:1', 11: 'cuda:1', 12: 'meta', 13: 'cuda:1', 14: 'meta', 15: 'meta', 16: 'meta', 17: 'meta', 18: 'meta', 19: 'cuda:1', 20: 'cuda:1', 21: 'cuda:1', 22: 'meta', 23: 'cuda:1', 24: 'meta', 25: 'cuda:1', 26: 'cuda:1', 27: 'meta', 28: 'cuda:1', 29: 'meta', 30: 'meta', 31: 'cuda:1', 32: 'meta', 33: 'meta', 34: 'meta', 35: 'meta', 36: 'meta', 37: 'cuda:1', 38: 'meta', 39: 'meta', 40: 'meta', 41: 'cuda:1', 42: 'meta', 43: 'cuda:1', 44: 'meta', 45: 'cuda:1', 46: 'cuda:1', 47: 'cuda:1', 48: 'meta', 49: 'cuda:1', 50: 'cuda:1', 51: 'meta', 52: 'cuda:1', 53: 'meta', 54: 'meta', 55: 'cuda:1', 56: 'cuda:1', 57: 'cuda:1', 58: 'cuda:1', 59: 'meta', 60: 'meta', 61: 'cuda:1', 62: 'cuda:1', 63: 'cuda:1'})
INFO 01-06 17:11:21.447186.447186 cuda_memory_view.py:189] Layer 9: CPU experts = [2, 3, 4, 5, 7, 10, 12, 13, 15, 16, 17, 19, 20, 22, 23, 24, 25, 26, 27, 28, 32, 35, 37, 38, 40, 41, 47, 49, 50, 53, 59, 60] (total: 32, device_map: {0: 'cuda:1', 1: 'cuda:1', 2: 'meta', 3: 'meta', 4: 'meta', 5: 'meta', 6: 'cuda:1', 7: 'meta', 8: 'cuda:1', 9: 'cuda:1', 10: 'meta', 11: 'cuda:1', 12: 'meta', 13: 'meta', 14: 'cuda:1', 15: 'meta', 16: 'meta', 17: 'meta', 18: 'cuda:1', 19: 'meta', 20: 'meta', 21: 'cuda:1', 22: 'meta', 23: 'meta', 24: 'meta', 25: 'meta', 26: 'meta', 27: 'meta', 28: 'meta', 29: 'cuda:1', 30: 'cuda:1', 31: 'cuda:1', 32: 'meta', 33: 'cuda:1', 34: 'cuda:1', 35: 'meta', 36: 'cuda:1', 37: 'meta', 38: 'meta', 39: 'cuda:1', 40: 'meta', 41: 'meta', 42: 'cuda:1', 43: 'cuda:1', 44: 'cuda:1', 45: 'cuda:1', 46: 'cuda:1', 47: 'meta', 48: 'cuda:1', 49: 'meta', 50: 'meta', 51: 'cuda:1', 52: 'cuda:1', 53: 'meta', 54: 'cuda:1', 55: 'cuda:1', 56: 'cuda:1', 57: 'cuda:1', 58: 'cuda:1', 59: 'meta', 60: 'meta', 61: 'cuda:1', 62: 'cuda:1', 63: 'cuda:1'})
INFO 01-06 17:11:21.447843.447843 cuda_memory_view.py:189] Layer 10: CPU experts = [2, 3, 4, 5, 6, 7, 12, 14, 15, 17, 19, 22, 26, 27, 28, 31, 34, 37, 38, 43, 45, 47, 48, 51, 52, 54, 55, 56, 57, 60, 61, 63] (total: 32, device_map: {0: 'cuda:1', 1: 'cuda:1', 2: 'meta', 3: 'meta', 4: 'meta', 5: 'meta', 6: 'meta', 7: 'meta', 8: 'cuda:1', 9: 'cuda:1', 10: 'cuda:1', 11: 'cuda:1', 12: 'meta', 13: 'cuda:1', 14: 'meta', 15: 'meta', 16: 'cuda:1', 17: 'meta', 18: 'cuda:1', 19: 'meta', 20: 'cuda:1', 21: 'cuda:1', 22: 'meta', 23: 'cuda:1', 24: 'cuda:1', 25: 'cuda:1', 26: 'meta', 27: 'meta', 28: 'meta', 29: 'cuda:1', 30: 'cuda:1', 31: 'meta', 32: 'cuda:1', 33: 'cuda:1', 34: 'meta', 35: 'cuda:1', 36: 'cuda:1', 37: 'meta', 38: 'meta', 39: 'cuda:1', 40: 'cuda:1', 41: 'cuda:1', 42: 'cuda:1', 43: 'meta', 44: 'cuda:1', 45: 'meta', 46: 'cuda:1', 47: 'meta', 48: 'meta', 49: 'cuda:1', 50: 'cuda:1', 51: 'meta', 52: 'meta', 53: 'cuda:1', 54: 'meta', 55: 'meta', 56: 'meta', 57: 'meta', 58: 'cuda:1', 59: 'cuda:1', 60: 'meta', 61: 'meta', 62: 'cuda:1', 63: 'meta'})
INFO 01-06 17:11:21.448746.448746 cuda_memory_view.py:189] Layer 11: CPU experts = [2, 3, 6, 9, 13, 15, 16, 17, 18, 19, 20, 23, 26, 31, 32, 33, 35, 36, 38, 39, 40, 41, 42, 43, 44, 46, 49, 50, 59, 61, 62, 63] (total: 32, device_map: {0: 'cuda:1', 1: 'cuda:1', 2: 'meta', 3: 'meta', 4: 'cuda:1', 5: 'cuda:1', 6: 'meta', 7: 'cuda:1', 8: 'cuda:1', 9: 'meta', 10: 'cuda:1', 11: 'cuda:1', 12: 'cuda:1', 13: 'meta', 14: 'cuda:1', 15: 'meta', 16: 'meta', 17: 'meta', 18: 'meta', 19: 'meta', 20: 'meta', 21: 'cuda:1', 22: 'cuda:1', 23: 'meta', 24: 'cuda:1', 25: 'cuda:1', 26: 'meta', 27: 'cuda:1', 28: 'cuda:1', 29: 'cuda:1', 30: 'cuda:1', 31: 'meta', 32: 'meta', 33: 'meta', 34: 'cuda:1', 35: 'meta', 36: 'meta', 37: 'cuda:1', 38: 'meta', 39: 'meta', 40: 'meta', 41: 'meta', 42: 'meta', 43: 'meta', 44: 'meta', 45: 'cuda:1', 46: 'meta', 47: 'cuda:1', 48: 'cuda:1', 49: 'meta', 50: 'meta', 51: 'cuda:1', 52: 'cuda:1', 53: 'cuda:1', 54: 'cuda:1', 55: 'cuda:1', 56: 'cuda:1', 57: 'cuda:1', 58: 'cuda:1', 59: 'meta', 60: 'cuda:1', 61: 'meta', 62: 'meta', 63: 'meta'})
INFO 01-06 17:11:21.448006.448006 cuda_memory_view.py:189] Layer 12: CPU experts = [0, 2, 4, 7, 8, 11, 12, 13, 14, 16, 17, 20, 21, 22, 23, 27, 30, 32, 34, 37, 38, 39, 43, 44, 45, 47, 52, 53, 57, 60, 61, 63] (total: 32, device_map: {0: 'meta', 1: 'cuda:1', 2: 'meta', 3: 'cuda:1', 4: 'meta', 5: 'cuda:1', 6: 'cuda:1', 7: 'meta', 8: 'meta', 9: 'cuda:1', 10: 'cuda:1', 11: 'meta', 12: 'meta', 13: 'meta', 14: 'meta', 15: 'cuda:1', 16: 'meta', 17: 'meta', 18: 'cuda:1', 19: 'cuda:1', 20: 'meta', 21: 'meta', 22: 'meta', 23: 'meta', 24: 'cuda:1', 25: 'cuda:1', 26: 'cuda:1', 27: 'meta', 28: 'cuda:1', 29: 'cuda:1', 30: 'meta', 31: 'cuda:1', 32: 'meta', 33: 'cuda:1', 34: 'meta', 35: 'cuda:1', 36: 'cuda:1', 37: 'meta', 38: 'meta', 39: 'meta', 40: 'cuda:1', 41: 'cuda:1', 42: 'cuda:1', 43: 'meta', 44: 'meta', 45: 'meta', 46: 'cuda:1', 47: 'meta', 48: 'cuda:1', 49: 'cuda:1', 50: 'cuda:1', 51: 'cuda:1', 52: 'meta', 53: 'meta', 54: 'cuda:1', 55: 'cuda:1', 56: 'cuda:1', 57: 'meta', 58: 'cuda:1', 59: 'cuda:1', 60: 'meta', 61: 'meta', 62: 'cuda:1', 63: 'meta'})
INFO 01-06 17:11:21.449577.449577 cuda_memory_view.py:189] Layer 13: CPU experts = [1, 2, 4, 5, 6, 9, 10, 11, 12, 13, 18, 19, 20, 26, 30, 31, 32, 33, 34, 35, 40, 42, 46, 48, 50, 53, 55, 56, 58, 59, 61, 63] (total: 32, device_map: {0: 'cuda:1', 1: 'meta', 2: 'meta', 3: 'cuda:1', 4: 'meta', 5: 'meta', 6: 'meta', 7: 'cuda:1', 8: 'cuda:1', 9: 'meta', 10: 'meta', 11: 'meta', 12: 'meta', 13: 'meta', 14: 'cuda:1', 15: 'cuda:1', 16: 'cuda:1', 17: 'cuda:1', 18: 'meta', 19: 'meta', 20: 'meta', 21: 'cuda:1', 22: 'cuda:1', 23: 'cuda:1', 24: 'cuda:1', 25: 'cuda:1', 26: 'meta', 27: 'cuda:1', 28: 'cuda:1', 29: 'cuda:1', 30: 'meta', 31: 'meta', 32: 'meta', 33: 'meta', 34: 'meta', 35: 'meta', 36: 'cuda:1', 37: 'cuda:1', 38: 'cuda:1', 39: 'cuda:1', 40: 'meta', 41: 'cuda:1', 42: 'meta', 43: 'cuda:1', 44: 'cuda:1', 45: 'cuda:1', 46: 'meta', 47: 'cuda:1', 48: 'meta', 49: 'cuda:1', 50: 'meta', 51: 'cuda:1', 52: 'cuda:1', 53: 'meta', 54: 'cuda:1', 55: 'meta', 56: 'meta', 57: 'cuda:1', 58: 'meta', 59: 'meta', 60: 'cuda:1', 61: 'meta', 62: 'cuda:1', 63: 'meta'})
INFO 01-06 17:11:21.449334.449334 cuda_memory_view.py:189] Layer 14: CPU experts = [0, 4, 7, 8, 12, 13, 15, 16, 17, 18, 19, 21, 22, 27, 31, 34, 35, 36, 38, 39, 40, 41, 45, 48, 49, 50, 52, 53, 54, 59, 60, 61] (total: 32, device_map: {0: 'meta', 1: 'cuda:1', 2: 'cuda:1', 3: 'cuda:1', 4: 'meta', 5: 'cuda:1', 6: 'cuda:1', 7: 'meta', 8: 'meta', 9: 'cuda:1', 10: 'cuda:1', 11: 'cuda:1', 12: 'meta', 13: 'meta', 14: 'cuda:1', 15: 'meta', 16: 'meta', 17: 'meta', 18: 'meta', 19: 'meta', 20: 'cuda:1', 21: 'meta', 22: 'meta', 23: 'cuda:1', 24: 'cuda:1', 25: 'cuda:1', 26: 'cuda:1', 27: 'meta', 28: 'cuda:1', 29: 'cuda:1', 30: 'cuda:1', 31: 'meta', 32: 'cuda:1', 33: 'cuda:1', 34: 'meta', 35: 'meta', 36: 'meta', 37: 'cuda:1', 38: 'meta', 39: 'meta', 40: 'meta', 41: 'meta', 42: 'cuda:1', 43: 'cuda:1', 44: 'cuda:1', 45: 'meta', 46: 'cuda:1', 47: 'cuda:1', 48: 'meta', 49: 'meta', 50: 'meta', 51: 'cuda:1', 52: 'meta', 53: 'meta', 54: 'meta', 55: 'cuda:1', 56: 'cuda:1', 57: 'cuda:1', 58: 'cuda:1', 59: 'meta', 60: 'meta', 61: 'meta', 62: 'cuda:1', 63: 'cuda:1'})
INFO 01-06 17:11:21.449223.449223 cuda_memory_view.py:189] Layer 15: CPU experts = [0, 2, 4, 5, 7, 10, 12, 13, 14, 15, 20, 21, 22, 25, 26, 28, 32, 34, 40, 41, 42, 45, 50, 51, 52, 53, 54, 55, 59, 61, 62, 63] (total: 32, device_map: {0: 'meta', 1: 'cuda:1', 2: 'meta', 3: 'cuda:1', 4: 'meta', 5: 'meta', 6: 'cuda:1', 7: 'meta', 8: 'cuda:1', 9: 'cuda:1', 10: 'meta', 11: 'cuda:1', 12: 'meta', 13: 'meta', 14: 'meta', 15: 'meta', 16: 'cuda:1', 17: 'cuda:1', 18: 'cuda:1', 19: 'cuda:1', 20: 'meta', 21: 'meta', 22: 'meta', 23: 'cuda:1', 24: 'cuda:1', 25: 'meta', 26: 'meta', 27: 'cuda:1', 28: 'meta', 29: 'cuda:1', 30: 'cuda:1', 31: 'cuda:1', 32: 'meta', 33: 'cuda:1', 34: 'meta', 35: 'cuda:1', 36: 'cuda:1', 37: 'cuda:1', 38: 'cuda:1', 39: 'cuda:1', 40: 'meta', 41: 'meta', 42: 'meta', 43: 'cuda:1', 44: 'cuda:1', 45: 'meta', 46: 'cuda:1', 47: 'cuda:1', 48: 'cuda:1', 49: 'cuda:1', 50: 'meta', 51: 'meta', 52: 'meta', 53: 'meta', 54: 'meta', 55: 'meta', 56: 'cuda:1', 57: 'cuda:1', 58: 'cuda:1', 59: 'meta', 60: 'cuda:1', 61: 'meta', 62: 'meta', 63: 'meta'})
INFO 01-06 17:11:21.450953.450953 cuda_memory_view.py:189] Layer 16: CPU experts = [0, 2, 4, 6, 7, 9, 10, 11, 13, 14, 25, 26, 27, 28, 31, 33, 34, 38, 41, 43, 45, 47, 48, 49, 50, 51, 54, 55, 56, 57, 58, 61] (total: 32, device_map: {0: 'meta', 1: 'cuda:1', 2: 'meta', 3: 'cuda:1', 4: 'meta', 5: 'cuda:1', 6: 'meta', 7: 'meta', 8: 'cuda:1', 9: 'meta', 10: 'meta', 11: 'meta', 12: 'cuda:1', 13: 'meta', 14: 'meta', 15: 'cuda:1', 16: 'cuda:1', 17: 'cuda:1', 18: 'cuda:1', 19: 'cuda:1', 20: 'cuda:1', 21: 'cuda:1', 22: 'cuda:1', 23: 'cuda:1', 24: 'cuda:1', 25: 'meta', 26: 'meta', 27: 'meta', 28: 'meta', 29: 'cuda:1', 30: 'cuda:1', 31: 'meta', 32: 'cuda:1', 33: 'meta', 34: 'meta', 35: 'cuda:1', 36: 'cuda:1', 37: 'cuda:1', 38: 'meta', 39: 'cuda:1', 40: 'cuda:1', 41: 'meta', 42: 'cuda:1', 43: 'meta', 44: 'cuda:1', 45: 'meta', 46: 'cuda:1', 47: 'meta', 48: 'meta', 49: 'meta', 50: 'meta', 51: 'meta', 52: 'cuda:1', 53: 'cuda:1', 54: 'meta', 55: 'meta', 56: 'meta', 57: 'meta', 58: 'meta', 59: 'cuda:1', 60: 'cuda:1', 61: 'meta', 62: 'cuda:1', 63: 'cuda:1'})
INFO 01-06 17:11:21.450173.450173 cuda_memory_view.py:189] Layer 17: CPU experts = [2, 3, 4, 6, 7, 8, 10, 12, 14, 15, 24, 25, 27, 28, 31, 33, 36, 37, 38, 39, 40, 43, 46, 47, 49, 50, 52, 53, 58, 59, 60, 61] (total: 32, device_map: {0: 'cuda:1', 1: 'cuda:1', 2: 'meta', 3: 'meta', 4: 'meta', 5: 'cuda:1', 6: 'meta', 7: 'meta', 8: 'meta', 9: 'cuda:1', 10: 'meta', 11: 'cuda:1', 12: 'meta', 13: 'cuda:1', 14: 'meta', 15: 'meta', 16: 'cuda:1', 17: 'cuda:1', 18: 'cuda:1', 19: 'cuda:1', 20: 'cuda:1', 21: 'cuda:1', 22: 'cuda:1', 23: 'cuda:1', 24: 'meta', 25: 'meta', 26: 'cuda:1', 27: 'meta', 28: 'meta', 29: 'cuda:1', 30: 'cuda:1', 31: 'meta', 32: 'cuda:1', 33: 'meta', 34: 'cuda:1', 35: 'cuda:1', 36: 'meta', 37: 'meta', 38: 'meta', 39: 'meta', 40: 'meta', 41: 'cuda:1', 42: 'cuda:1', 43: 'meta', 44: 'cuda:1', 45: 'cuda:1', 46: 'meta', 47: 'meta', 48: 'cuda:1', 49: 'meta', 50: 'meta', 51: 'cuda:1', 52: 'meta', 53: 'meta', 54: 'cuda:1', 55: 'cuda:1', 56: 'cuda:1', 57: 'cuda:1', 58: 'meta', 59: 'meta', 60: 'meta', 61: 'meta', 62: 'cuda:1', 63: 'cuda:1'})
INFO 01-06 17:11:21.451625.451625 cuda_memory_view.py:189] Layer 18: CPU experts = [0, 3, 5, 6, 8, 9, 12, 17, 19, 21, 25, 27, 28, 29, 30, 32, 35, 36, 37, 39, 40, 41, 46, 48, 52, 53, 54, 56, 58, 59, 60, 63] (total: 32, device_map: {0: 'meta', 1: 'cuda:1', 2: 'cuda:1', 3: 'meta', 4: 'cuda:1', 5: 'meta', 6: 'meta', 7: 'cuda:1', 8: 'meta', 9: 'meta', 10: 'cuda:1', 11: 'cuda:1', 12: 'meta', 13: 'cuda:1', 14: 'cuda:1', 15: 'cuda:1', 16: 'cuda:1', 17: 'meta', 18: 'cuda:1', 19: 'meta', 20: 'cuda:1', 21: 'meta', 22: 'cuda:1', 23: 'cuda:1', 24: 'cuda:1', 25: 'meta', 26: 'cuda:1', 27: 'meta', 28: 'meta', 29: 'meta', 30: 'meta', 31: 'cuda:1', 32: 'meta', 33: 'cuda:1', 34: 'cuda:1', 35: 'meta', 36: 'meta', 37: 'meta', 38: 'cuda:1', 39: 'meta', 40: 'meta', 41: 'meta', 42: 'cuda:1', 43: 'cuda:1', 44: 'cuda:1', 45: 'cuda:1', 46: 'meta', 47: 'cuda:1', 48: 'meta', 49: 'cuda:1', 50: 'cuda:1', 51: 'cuda:1', 52: 'meta', 53: 'meta', 54: 'meta', 55: 'cuda:1', 56: 'meta', 57: 'cuda:1', 58: 'meta', 59: 'meta', 60: 'meta', 61: 'cuda:1', 62: 'cuda:1', 63: 'meta'})
INFO 01-06 17:11:21.451116.451116 cuda_memory_view.py:189] Layer 19: CPU experts = [0, 1, 5, 6, 8, 12, 13, 15, 16, 22, 24, 26, 27, 28, 30, 32, 34, 40, 42, 44, 47, 48, 50, 52, 54, 55, 56, 57, 58, 59, 60, 62] (total: 32, device_map: {0: 'meta', 1: 'meta', 2: 'cuda:1', 3: 'cuda:1', 4: 'cuda:1', 5: 'meta', 6: 'meta', 7: 'cuda:1', 8: 'meta', 9: 'cuda:1', 10: 'cuda:1', 11: 'cuda:1', 12: 'meta', 13: 'meta', 14: 'cuda:1', 15: 'meta', 16: 'meta', 17: 'cuda:1', 18: 'cuda:1', 19: 'cuda:1', 20: 'cuda:1', 21: 'cuda:1', 22: 'meta', 23: 'cuda:1', 24: 'meta', 25: 'cuda:1', 26: 'meta', 27: 'meta', 28: 'meta', 29: 'cuda:1', 30: 'meta', 31: 'cuda:1', 32: 'meta', 33: 'cuda:1', 34: 'meta', 35: 'cuda:1', 36: 'cuda:1', 37: 'cuda:1', 38: 'cuda:1', 39: 'cuda:1', 40: 'meta', 41: 'cuda:1', 42: 'meta', 43: 'cuda:1', 44: 'meta', 45: 'cuda:1', 46: 'cuda:1', 47: 'meta', 48: 'meta', 49: 'cuda:1', 50: 'meta', 51: 'cuda:1', 52: 'meta', 53: 'cuda:1', 54: 'meta', 55: 'meta', 56: 'meta', 57: 'meta', 58: 'meta', 59: 'meta', 60: 'meta', 61: 'cuda:1', 62: 'meta', 63: 'cuda:1'})
INFO 01-06 17:11:21.452647.452647 cuda_memory_view.py:189] Layer 20: CPU experts = [2, 3, 6, 8, 12, 13, 19, 20, 21, 22, 23, 24, 28, 36, 37, 38, 39, 40, 41, 42, 43, 46, 47, 49, 50, 52, 53, 54, 55, 57, 61, 63] (total: 32, device_map: {0: 'cuda:1', 1: 'cuda:1', 2: 'meta', 3: 'meta', 4: 'cuda:1', 5: 'cuda:1', 6: 'meta', 7: 'cuda:1', 8: 'meta', 9: 'cuda:1', 10: 'cuda:1', 11: 'cuda:1', 12: 'meta', 13: 'meta', 14: 'cuda:1', 15: 'cuda:1', 16: 'cuda:1', 17: 'cuda:1', 18: 'cuda:1', 19: 'meta', 20: 'meta', 21: 'meta', 22: 'meta', 23: 'meta', 24: 'meta', 25: 'cuda:1', 26: 'cuda:1', 27: 'cuda:1', 28: 'meta', 29: 'cuda:1', 30: 'cuda:1', 31: 'cuda:1', 32: 'cuda:1', 33: 'cuda:1', 34: 'cuda:1', 35: 'cuda:1', 36: 'meta', 37: 'meta', 38: 'meta', 39: 'meta', 40: 'meta', 41: 'meta', 42: 'meta', 43: 'meta', 44: 'cuda:1', 45: 'cuda:1', 46: 'meta', 47: 'meta', 48: 'cuda:1', 49: 'meta', 50: 'meta', 51: 'cuda:1', 52: 'meta', 53: 'meta', 54: 'meta', 55: 'meta', 56: 'cuda:1', 57: 'meta', 58: 'cuda:1', 59: 'cuda:1', 60: 'cuda:1', 61: 'meta', 62: 'cuda:1', 63: 'meta'})
INFO 01-06 17:11:21.452092.452092 cuda_memory_view.py:189] Layer 21: CPU experts = [1, 2, 6, 7, 8, 9, 11, 14, 22, 23, 24, 26, 27, 32, 34, 35, 38, 39, 41, 44, 46, 47, 48, 50, 51, 52, 53, 54, 56, 59, 60, 62] (total: 32, device_map: {0: 'cuda:1', 1: 'meta', 2: 'meta', 3: 'cuda:1', 4: 'cuda:1', 5: 'cuda:1', 6: 'meta', 7: 'meta', 8: 'meta', 9: 'meta', 10: 'cuda:1', 11: 'meta', 12: 'cuda:1', 13: 'cuda:1', 14: 'meta', 15: 'cuda:1', 16: 'cuda:1', 17: 'cuda:1', 18: 'cuda:1', 19: 'cuda:1', 20: 'cuda:1', 21: 'cuda:1', 22: 'meta', 23: 'meta', 24: 'meta', 25: 'cuda:1', 26: 'meta', 27: 'meta', 28: 'cuda:1', 29: 'cuda:1', 30: 'cuda:1', 31: 'cuda:1', 32: 'meta', 33: 'cuda:1', 34: 'meta', 35: 'meta', 36: 'cuda:1', 37: 'cuda:1', 38: 'meta', 39: 'meta', 40: 'cuda:1', 41: 'meta', 42: 'cuda:1', 43: 'cuda:1', 44: 'meta', 45: 'cuda:1', 46: 'meta', 47: 'meta', 48: 'meta', 49: 'cuda:1', 50: 'meta', 51: 'meta', 52: 'meta', 53: 'meta', 54: 'meta', 55: 'cuda:1', 56: 'meta', 57: 'cuda:1', 58: 'cuda:1', 59: 'meta', 60: 'meta', 61: 'cuda:1', 62: 'meta', 63: 'cuda:1'})
INFO 01-06 17:11:21.452709.452709 cuda_memory_view.py:189] Layer 22: CPU experts = [0, 1, 2, 6, 7, 9, 10, 11, 13, 14, 15, 20, 21, 24, 25, 28, 36, 37, 38, 42, 43, 44, 45, 46, 47, 48, 50, 52, 54, 57, 61, 62] (total: 32, device_map: {0: 'meta', 1: 'meta', 2: 'meta', 3: 'cuda:1', 4: 'cuda:1', 5: 'cuda:1', 6: 'meta', 7: 'meta', 8: 'cuda:1', 9: 'meta', 10: 'meta', 11: 'meta', 12: 'cuda:1', 13: 'meta', 14: 'meta', 15: 'meta', 16: 'cuda:1', 17: 'cuda:1', 18: 'cuda:1', 19: 'cuda:1', 20: 'meta', 21: 'meta', 22: 'cuda:1', 23: 'cuda:1', 24: 'meta', 25: 'meta', 26: 'cuda:1', 27: 'cuda:1', 28: 'meta', 29: 'cuda:1', 30: 'cuda:1', 31: 'cuda:1', 32: 'cuda:1', 33: 'cuda:1', 34: 'cuda:1', 35: 'cuda:1', 36: 'meta', 37: 'meta', 38: 'meta', 39: 'cuda:1', 40: 'cuda:1', 41: 'cuda:1', 42: 'meta', 43: 'meta', 44: 'meta', 45: 'meta', 46: 'meta', 47: 'meta', 48: 'meta', 49: 'cuda:1', 50: 'meta', 51: 'cuda:1', 52: 'meta', 53: 'cuda:1', 54: 'meta', 55: 'cuda:1', 56: 'cuda:1', 57: 'meta', 58: 'cuda:1', 59: 'cuda:1', 60: 'cuda:1', 61: 'meta', 62: 'meta', 63: 'cuda:1'})
INFO 01-06 17:11:21.453677.453677 cuda_memory_view.py:189] Layer 23: CPU experts = [1, 4, 5, 6, 7, 11, 14, 16, 17, 21, 23, 25, 27, 28, 33, 37, 38, 39, 40, 44, 45, 47, 49, 51, 52, 53, 56, 57, 58, 60, 62, 63] (total: 32, device_map: {0: 'cuda:1', 1: 'meta', 2: 'cuda:1', 3: 'cuda:1', 4: 'meta', 5: 'meta', 6: 'meta', 7: 'meta', 8: 'cuda:1', 9: 'cuda:1', 10: 'cuda:1', 11: 'meta', 12: 'cuda:1', 13: 'cuda:1', 14: 'meta', 15: 'cuda:1', 16: 'meta', 17: 'meta', 18: 'cuda:1', 19: 'cuda:1', 20: 'cuda:1', 21: 'meta', 22: 'cuda:1', 23: 'meta', 24: 'cuda:1', 25: 'meta', 26: 'cuda:1', 27: 'meta', 28: 'meta', 29: 'cuda:1', 30: 'cuda:1', 31: 'cuda:1', 32: 'cuda:1', 33: 'meta', 34: 'cuda:1', 35: 'cuda:1', 36: 'cuda:1', 37: 'meta', 38: 'meta', 39: 'meta', 40: 'meta', 41: 'cuda:1', 42: 'cuda:1', 43: 'cuda:1', 44: 'meta', 45: 'meta', 46: 'cuda:1', 47: 'meta', 48: 'cuda:1', 49: 'meta', 50: 'cuda:1', 51: 'meta', 52: 'meta', 53: 'meta', 54: 'cuda:1', 55: 'cuda:1', 56: 'meta', 57: 'meta', 58: 'meta', 59: 'cuda:1', 60: 'meta', 61: 'cuda:1', 62: 'meta', 63: 'meta'})
INFO 01-06 17:11:21.453486.453486 cuda_memory_view.py:189] Layer 24: CPU experts = [0, 2, 4, 6, 7, 9, 13, 15, 16, 19, 20, 24, 25, 29, 30, 33, 35, 36, 38, 39, 42, 43, 44, 46, 47, 48, 51, 54, 55, 56, 59, 61] (total: 32, device_map: {0: 'meta', 1: 'cuda:1', 2: 'meta', 3: 'cuda:1', 4: 'meta', 5: 'cuda:1', 6: 'meta', 7: 'meta', 8: 'cuda:1', 9: 'meta', 10: 'cuda:1', 11: 'cuda:1', 12: 'cuda:1', 13: 'meta', 14: 'cuda:1', 15: 'meta', 16: 'meta', 17: 'cuda:1', 18: 'cuda:1', 19: 'meta', 20: 'meta', 21: 'cuda:1', 22: 'cuda:1', 23: 'cuda:1', 24: 'meta', 25: 'meta', 26: 'cuda:1', 27: 'cuda:1', 28: 'cuda:1', 29: 'meta', 30: 'meta', 31: 'cuda:1', 32: 'cuda:1', 33: 'meta', 34: 'cuda:1', 35: 'meta', 36: 'meta', 37: 'cuda:1', 38: 'meta', 39: 'meta', 40: 'cuda:1', 41: 'cuda:1', 42: 'meta', 43: 'meta', 44: 'meta', 45: 'cuda:1', 46: 'meta', 47: 'meta', 48: 'meta', 49: 'cuda:1', 50: 'cuda:1', 51: 'meta', 52: 'cuda:1', 53: 'cuda:1', 54: 'meta', 55: 'meta', 56: 'meta', 57: 'cuda:1', 58: 'cuda:1', 59: 'meta', 60: 'cuda:1', 61: 'meta', 62: 'cuda:1', 63: 'cuda:1'})
INFO 01-06 17:11:21.454341.454341 cuda_memory_view.py:189] Layer 25: CPU experts = [0, 2, 3, 5, 6, 8, 9, 10, 13, 16, 18, 20, 21, 22, 23, 24, 25, 26, 31, 33, 36, 38, 41, 42, 43, 44, 45, 46, 51, 55, 59, 61] (total: 32, device_map: {0: 'meta', 1: 'cuda:1', 2: 'meta', 3: 'meta', 4: 'cuda:1', 5: 'meta', 6: 'meta', 7: 'cuda:1', 8: 'meta', 9: 'meta', 10: 'meta', 11: 'cuda:1', 12: 'cuda:1', 13: 'meta', 14: 'cuda:1', 15: 'cuda:1', 16: 'meta', 17: 'cuda:1', 18: 'meta', 19: 'cuda:1', 20: 'meta', 21: 'meta', 22: 'meta', 23: 'meta', 24: 'meta', 25: 'meta', 26: 'meta', 27: 'cuda:1', 28: 'cuda:1', 29: 'cuda:1', 30: 'cuda:1', 31: 'meta', 32: 'cuda:1', 33: 'meta', 34: 'cuda:1', 35: 'cuda:1', 36: 'meta', 37: 'cuda:1', 38: 'meta', 39: 'cuda:1', 40: 'cuda:1', 41: 'meta', 42: 'meta', 43: 'meta', 44: 'meta', 45: 'meta', 46: 'meta', 47: 'cuda:1', 48: 'cuda:1', 49: 'cuda:1', 50: 'cuda:1', 51: 'meta', 52: 'cuda:1', 53: 'cuda:1', 54: 'cuda:1', 55: 'meta', 56: 'cuda:1', 57: 'cuda:1', 58: 'cuda:1', 59: 'meta', 60: 'cuda:1', 61: 'meta', 62: 'cuda:1', 63: 'cuda:1'})
INFO 01-06 17:11:21.454433.454433 cuda_memory_view.py:189] Layer 26: CPU experts = [3, 4, 6, 7, 8, 9, 11, 15, 17, 19, 20, 22, 23, 24, 29, 30, 34, 36, 37, 38, 39, 41, 42, 48, 49, 50, 51, 55, 59, 61, 62, 63] (total: 32, device_map: {0: 'cuda:1', 1: 'cuda:1', 2: 'cuda:1', 3: 'meta', 4: 'meta', 5: 'cuda:1', 6: 'meta', 7: 'meta', 8: 'meta', 9: 'meta', 10: 'cuda:1', 11: 'meta', 12: 'cuda:1', 13: 'cuda:1', 14: 'cuda:1', 15: 'meta', 16: 'cuda:1', 17: 'meta', 18: 'cuda:1', 19: 'meta', 20: 'meta', 21: 'cuda:1', 22: 'meta', 23: 'meta', 24: 'meta', 25: 'cuda:1', 26: 'cuda:1', 27: 'cuda:1', 28: 'cuda:1', 29: 'meta', 30: 'meta', 31: 'cuda:1', 32: 'cuda:1', 33: 'cuda:1', 34: 'meta', 35: 'cuda:1', 36: 'meta', 37: 'meta', 38: 'meta', 39: 'meta', 40: 'cuda:1', 41: 'meta', 42: 'meta', 43: 'cuda:1', 44: 'cuda:1', 45: 'cuda:1', 46: 'cuda:1', 47: 'cuda:1', 48: 'meta', 49: 'meta', 50: 'meta', 51: 'meta', 52: 'cuda:1', 53: 'cuda:1', 54: 'cuda:1', 55: 'meta', 56: 'cuda:1', 57: 'cuda:1', 58: 'cuda:1', 59: 'meta', 60: 'cuda:1', 61: 'meta', 62: 'meta', 63: 'meta'})
INFO 01-06 17:11:21.454241.454241 cuda_memory_view.py:189] Layer 27: CPU experts = [0, 5, 6, 10, 11, 12, 13, 17, 18, 20, 23, 24, 26, 31, 33, 36, 38, 40, 42, 43, 44, 45, 47, 48, 49, 51, 54, 55, 56, 57, 59, 61] (total: 32, device_map: {0: 'meta', 1: 'cuda:1', 2: 'cuda:1', 3: 'cuda:1', 4: 'cuda:1', 5: 'meta', 6: 'meta', 7: 'cuda:1', 8: 'cuda:1', 9: 'cuda:1', 10: 'meta', 11: 'meta', 12: 'meta', 13: 'meta', 14: 'cuda:1', 15: 'cuda:1', 16: 'cuda:1', 17: 'meta', 18: 'meta', 19: 'cuda:1', 20: 'meta', 21: 'cuda:1', 22: 'cuda:1', 23: 'meta', 24: 'meta', 25: 'cuda:1', 26: 'meta', 27: 'cuda:1', 28: 'cuda:1', 29: 'cuda:1', 30: 'cuda:1', 31: 'meta', 32: 'cuda:1', 33: 'meta', 34: 'cuda:1', 35: 'cuda:1', 36: 'meta', 37: 'cuda:1', 38: 'meta', 39: 'cuda:1', 40: 'meta', 41: 'cuda:1', 42: 'meta', 43: 'meta', 44: 'meta', 45: 'meta', 46: 'cuda:1', 47: 'meta', 48: 'meta', 49: 'meta', 50: 'cuda:1', 51: 'meta', 52: 'cuda:1', 53: 'cuda:1', 54: 'meta', 55: 'meta', 56: 'meta', 57: 'meta', 58: 'cuda:1', 59: 'meta', 60: 'cuda:1', 61: 'meta', 62: 'cuda:1', 63: 'cuda:1'})
INFO 01-06 17:11:21.457212.457212 cuda_memory_view.py:201] Starting to load CPU experts from last layer to first layer...
INFO 01-06 17:11:21.457134.457134 cuda_memory_view.py:208] Loading Layer 27: 5 CPU experts: [0, 5, 6, 10, 11]
DEBUG 01-06 17:11:21.457552.457552 cuda_h.py:10] start start_load_experts_decode_cpu_weight_l_27
DEBUG 01-06 17:11:21.457018.457018 cuda_h.py:19] end start_load_experts_decode_cpu_weight_l_27 cost 3.600120544433594e-05 seconds
INFO 01-06 17:11:21.457575.457575 cuda_memory_view.py:208] Loading Layer 26: 5 CPU experts: [3, 4, 6, 7, 8]
DEBUG 01-06 17:11:21.457986.457986 cuda_h.py:10] start start_load_experts_decode_cpu_weight_l_26
DEBUG 01-06 17:11:21.457126.457126 cuda_h.py:19] end start_load_experts_decode_cpu_weight_l_26 cost 1.1444091796875e-05 seconds
INFO 01-06 17:11:21.457822.457822 cuda_memory_view.py:208] Loading Layer 25: 5 CPU experts: [0, 2, 3, 5, 6]
DEBUG 01-06 17:11:21.457611.457611 cuda_h.py:10] start start_load_experts_decode_cpu_weight_l_25
DEBUG 01-06 17:11:21.457321.457321 cuda_h.py:19] end start_load_experts_decode_cpu_weight_l_25 cost 1.049041748046875e-05 seconds
INFO 01-06 17:11:21.457825.457825 cuda_memory_view.py:208] Loading Layer 24: 5 CPU experts: [0, 2, 4, 6, 7]
DEBUG 01-06 17:11:21.457567.457567 cuda_h.py:10] start start_load_experts_decode_cpu_weight_l_24
DEBUG 01-06 17:11:21.457754.457754 cuda_h.py:19] end start_load_experts_decode_cpu_weight_l_24 cost 1.0251998901367188e-05 seconds
INFO 01-06 17:11:21.457450.457450 cuda_memory_view.py:208] Loading Layer 23: 5 CPU experts: [1, 4, 5, 6, 7]
DEBUG 01-06 17:11:21.457762.457762 cuda_h.py:10] start start_load_experts_decode_cpu_weight_l_23
DEBUG 01-06 17:11:21.457279.457279 cuda_h.py:19] end start_load_experts_decode_cpu_weight_l_23 cost 9.775161743164062e-06 seconds
INFO 01-06 17:11:21.457306.457306 cuda_memory_view.py:208] Loading Layer 22: 5 CPU experts: [0, 1, 2, 6, 7]
DEBUG 01-06 17:11:21.457380.457380 cuda_h.py:10] start start_load_experts_decode_cpu_weight_l_22
DEBUG 01-06 17:11:21.457705.457705 cuda_h.py:19] end start_load_experts_decode_cpu_weight_l_22 cost 9.298324584960938e-06 seconds
INFO 01-06 17:11:21.457732.457732 cuda_memory_view.py:208] Loading Layer 21: 5 CPU experts: [1, 2, 6, 7, 8]
DEBUG 01-06 17:11:21.457760.457760 cuda_h.py:10] start start_load_experts_decode_cpu_weight_l_21
DEBUG 01-06 17:11:21.457277.457277 cuda_h.py:19] end start_load_experts_decode_cpu_weight_l_21 cost 9.298324584960938e-06 seconds
INFO 01-06 17:11:21.457304.457304 cuda_memory_view.py:208] Loading Layer 20: 5 CPU experts: [2, 3, 6, 8, 12]
DEBUG 01-06 17:11:21.457855.457855 cuda_h.py:10] start start_load_experts_decode_cpu_weight_l_20
DEBUG 01-06 17:11:21.457895.457895 cuda_h.py:19] end start_load_experts_decode_cpu_weight_l_20 cost 9.775161743164062e-06 seconds
INFO 01-06 17:11:21.457684.457684 cuda_memory_view.py:208] Loading Layer 19: 5 CPU experts: [0, 1, 5, 6, 8]
DEBUG 01-06 17:11:21.457281.457281 cuda_h.py:10] start start_load_experts_decode_cpu_weight_l_19
DEBUG 01-06 17:11:21.457129.457129 cuda_h.py:19] end start_load_experts_decode_cpu_weight_l_19 cost 8.821487426757812e-06 seconds
INFO 01-06 17:11:21.458918.458918 cuda_memory_view.py:208] Loading Layer 18: 5 CPU experts: [0, 3, 5, 6, 8]
DEBUG 01-06 17:11:21.458945.458945 cuda_h.py:10] start start_load_experts_decode_cpu_weight_l_18
DEBUG 01-06 17:11:21.458463.458463 cuda_h.py:19] end start_load_experts_decode_cpu_weight_l_18 cost 9.5367431640625e-06 seconds
INFO 01-06 17:11:21.458490.458490 cuda_memory_view.py:208] Loading Layer 17: 5 CPU experts: [2, 3, 4, 6, 7]
DEBUG 01-06 17:11:21.458325.458325 cuda_h.py:10] start start_load_experts_decode_cpu_weight_l_17
DEBUG 01-06 17:11:21.458128.458128 cuda_h.py:19] end start_load_experts_decode_cpu_weight_l_17 cost 9.5367431640625e-06 seconds
INFO 01-06 17:11:21.458439.458439 cuda_memory_view.py:208] Loading Layer 16: 5 CPU experts: [0, 2, 4, 6, 7]
DEBUG 01-06 17:11:21.458990.458990 cuda_h.py:10] start start_load_experts_decode_cpu_weight_l_16
DEBUG 01-06 17:11:21.458838.458838 cuda_h.py:19] end start_load_experts_decode_cpu_weight_l_16 cost 9.059906005859375e-06 seconds
INFO 01-06 17:11:21.458819.458819 cuda_memory_view.py:208] Loading Layer 15: 5 CPU experts: [0, 2, 4, 5, 7]
DEBUG 01-06 17:11:21.458370.458370 cuda_h.py:10] start start_load_experts_decode_cpu_weight_l_15
DEBUG 01-06 17:11:21.458649.458649 cuda_h.py:19] end start_load_experts_decode_cpu_weight_l_15 cost 9.298324584960938e-06 seconds
INFO 01-06 17:11:21.458437.458437 cuda_memory_view.py:208] Loading Layer 14: 5 CPU experts: [0, 4, 7, 8, 12]
DEBUG 01-06 17:11:21.458511.458511 cuda_h.py:10] start start_load_experts_decode_cpu_weight_l_14
DEBUG 01-06 17:11:21.458836.458836 cuda_h.py:19] end start_load_experts_decode_cpu_weight_l_14 cost 9.298324584960938e-06 seconds
INFO 01-06 17:11:21.458387.458387 cuda_memory_view.py:208] Loading Layer 13: 5 CPU experts: [1, 2, 4, 5, 6]
DEBUG 01-06 17:11:21.458460.458460 cuda_h.py:10] start start_load_experts_decode_cpu_weight_l_13
DEBUG 01-06 17:11:21.458786.458786 cuda_h.py:19] end start_load_experts_decode_cpu_weight_l_13 cost 8.821487426757812e-06 seconds
INFO 01-06 17:11:21.458290.458290 cuda_memory_view.py:208] Loading Layer 12: 5 CPU experts: [0, 2, 4, 7, 8]
DEBUG 01-06 17:11:21.458078.458078 cuda_h.py:10] start start_load_experts_decode_cpu_weight_l_12
DEBUG 01-06 17:11:21.458642.458642 cuda_h.py:19] end start_load_experts_decode_cpu_weight_l_12 cost 8.58306884765625e-06 seconds
INFO 01-06 17:11:21.458431.458431 cuda_memory_view.py:208] Loading Layer 11: 5 CPU experts: [2, 3, 6, 9, 13]
DEBUG 01-06 17:11:21.458266.458266 cuda_h.py:10] start start_load_experts_decode_cpu_weight_l_11
DEBUG 01-06 17:11:21.458830.458830 cuda_h.py:19] end start_load_experts_decode_cpu_weight_l_11 cost 9.298324584960938e-06 seconds
INFO 01-06 17:11:21.458619.458619 cuda_memory_view.py:208] Loading Layer 10: 5 CPU experts: [2, 3, 4, 5, 6]
DEBUG 01-06 17:11:21.458931.458931 cuda_h.py:10] start start_load_experts_decode_cpu_weight_l_10
DEBUG 01-06 17:11:21.458733.458733 cuda_h.py:19] end start_load_experts_decode_cpu_weight_l_10 cost 8.58306884765625e-06 seconds
INFO 01-06 17:11:21.458191.458191 cuda_memory_view.py:208] Loading Layer 9: 5 CPU experts: [2, 3, 4, 5, 7]
DEBUG 01-06 17:11:21.458503.458503 cuda_h.py:10] start start_load_experts_decode_cpu_weight_l_9
DEBUG 01-06 17:11:21.458305.458305 cuda_h.py:19] end start_load_experts_decode_cpu_weight_l_9 cost 8.58306884765625e-06 seconds
INFO 01-06 17:11:21.458378.458378 cuda_memory_view.py:208] Loading Layer 8: 5 CPU experts: [0, 1, 6, 7, 8]
DEBUG 01-06 17:11:21.458214.458214 cuda_h.py:10] start start_load_experts_decode_cpu_weight_l_8
DEBUG 01-06 17:11:21.458301.458301 cuda_h.py:19] end start_load_experts_decode_cpu_weight_l_8 cost 9.059906005859375e-06 seconds
INFO 01-06 17:11:21.458566.458566 cuda_memory_view.py:208] Loading Layer 7: 5 CPU experts: [1, 3, 4, 6, 7]
DEBUG 01-06 17:11:21.458878.458878 cuda_h.py:10] start start_load_experts_decode_cpu_weight_l_7
DEBUG 01-06 17:11:21.458634.458634 cuda_h.py:19] end start_load_experts_decode_cpu_weight_l_7 cost 9.5367431640625e-06 seconds
INFO 01-06 17:11:21.458138.458138 cuda_memory_view.py:208] Loading Layer 6: 5 CPU experts: [0, 1, 2, 3, 7]
DEBUG 01-06 17:11:21.458450.458450 cuda_h.py:10] start start_load_experts_decode_cpu_weight_l_6
DEBUG 01-06 17:11:21.458398.458398 cuda_h.py:19] end start_load_experts_decode_cpu_weight_l_6 cost 8.821487426757812e-06 seconds
INFO 01-06 17:11:21.458425.458425 cuda_memory_view.py:208] Loading Layer 5: 5 CPU experts: [0, 2, 3, 4, 5]
DEBUG 01-06 17:11:21.458783.458783 cuda_h.py:10] start start_load_experts_decode_cpu_weight_l_5
DEBUG 01-06 17:11:21.458632.458632 cuda_h.py:19] end start_load_experts_decode_cpu_weight_l_5 cost 8.821487426757812e-06 seconds
INFO 01-06 17:11:21.458851.458851 cuda_memory_view.py:208] Loading Layer 4: 5 CPU experts: [4, 7, 8, 10, 11]
DEBUG 01-06 17:11:21.459647.459647 cuda_h.py:10] start start_load_experts_decode_cpu_weight_l_4
DEBUG 01-06 17:11:21.459833.459833 cuda_h.py:19] end start_load_experts_decode_cpu_weight_l_4 cost 1.0251998901367188e-05 seconds
INFO 01-06 17:11:21.459861.459861 cuda_memory_view.py:208] Loading Layer 3: 5 CPU experts: [1, 2, 4, 5, 6]
DEBUG 01-06 17:11:21.459696.459696 cuda_h.py:10] start start_load_experts_decode_cpu_weight_l_3
DEBUG 01-06 17:11:21.459975.459975 cuda_h.py:19] end start_load_experts_decode_cpu_weight_l_3 cost 1.0013580322265625e-05 seconds
INFO 01-06 17:11:21.459525.459525 cuda_memory_view.py:208] Loading Layer 2: 5 CPU experts: [0, 1, 3, 6, 7]
DEBUG 01-06 17:11:21.459552.459552 cuda_h.py:10] start start_load_experts_decode_cpu_weight_l_2
DEBUG 01-06 17:11:21.459831.459831 cuda_h.py:19] end start_load_experts_decode_cpu_weight_l_2 cost 9.298324584960938e-06 seconds
INFO 01-06 17:11:21.459335.459335 cuda_memory_view.py:208] Loading Layer 1: 5 CPU experts: [0, 1, 3, 10, 11]
DEBUG 01-06 17:11:21.459932.459932 cuda_h.py:10] start start_load_experts_decode_cpu_weight_l_1
DEBUG 01-06 17:11:21.459496.459496 cuda_h.py:19] end start_load_experts_decode_cpu_weight_l_1 cost 9.775161743164062e-06 seconds
DEBUG 01-06 17:11:21.459437.459437 cuda_h.py:19] end async_load_ce cost 0.01622319221496582 seconds
DEBUG 01-06 17:11:21.459226.459226 cuda_h.py:10] start init_inputs_tokens
DEBUG 01-06 17:11:21.459647.459647 cuda_h.py:10] start sllm_worker_task
DEBUG 01-06 17:11:21.459593.459593 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 17:11:21.459021.459021 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 17:11:21.460591.460591 cuda_h.py:19] end allocate_cuda_memory cost 0.0006935596466064453 seconds
DEBUG 01-06 17:11:21.460299.460299 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 17:11:21.460521.460521 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 17:11:21.460656.460656 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 17:11:21.460122.460122 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 1d21e46f-e6fb-4ff7-9b0c-ee70aea2c589
DEBUG 01-06 17:11:21.461480.461480 client.py:106] call stub.LoadModelAsync
INFO 01-06 17:11:21.462615.462615 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 1d21e46f-e6fb-4ff7-9b0c-ee70aea2c589
DEBUG 01-06 17:11:21.462327.462327 cuda_h.py:19] end load_into_gpu_async cost 0.002139568328857422 seconds
DEBUG 01-06 17:11:21.462594.462594 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 17:11:21.463821.463821 cuda_h.py:19] end restore_tensors2 cost 0.00017762184143066406 seconds
DEBUG 01-06 17:11:21.463492.463492 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0036284923553466797 seconds
INFO 01-06 17:11:21.463801.463801 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 1d21e46f-e6fb-4ff7-9b0c-ee70aea2c589
DEBUG 01-06 17:11:21.466009.466009 cuda_h.py:19] end init_inputs_tokens cost 0.007322788238525391 seconds
DEBUG 01-06 17:11:21.466342.466342 lmp.py:295] next_inputs_tokens shape: torch.Size([32, 1, 2048])
DEBUG 01-06 17:11:21.466575.466575 lmp.py:298] -------------------------------- start decode layer 0 --------------------------------
DEBUG 01-06 17:11:21.466271.466271 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-06 17:11:21.466399.466399 mlpmodule.py:367] cuda:1 cuda:1
DEBUG 01-06 17:11:21.467771.467771 cuda_h.py:10] start self_attn
cos shape torch.Size([65, 128]) sin shape torch.Size([65, 128]) position_ids tensor([[0]], device='cuda:1')
cos shape torch.Size([1, 1, 1, 128]) sin shape torch.Size([1, 1, 1, 128])
q_embed shape torch.Size([32, 16, 1, 128]) k_embed shape torch.Size([32, 16, 1, 128])
DEBUG 01-06 17:11:21.468572.468572 cuda_h.py:19] end self_attn cost 0.0015192031860351562 seconds
DEBUG 01-06 17:11:21.468860.468860 cuda_h.py:19] end iln_self_attn_paln cost 0.0021250247955322266 seconds
DEBUG 01-06 17:11:21.468875.468875 cuda_h.py:10] start dense_mlp
DEBUG 01-06 17:11:21.469947.469947 lmp.py:319] ghidden_states after dense_mlp_func shape: torch.Size([32, 1, 2048])
DEBUG 01-06 17:11:21.469168.469168 cuda_h.py:19] end dense_mlp cost 0.0008180141448974609 seconds
DEBUG 01-06 17:11:21.469011.469011 lmp.py:325] -------------------------------- end decode layer 0 --------------------------------
DEBUG 01-06 17:11:21.469714.469714 lmp.py:298] -------------------------------- start decode layer 1 --------------------------------
DEBUG 01-06 17:11:21.469787.469787 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-06 17:11:21.469617.469617 mlpmodule.py:367] cuda:1 cuda:1
DEBUG 01-06 17:11:21.470154.470154 cuda_h.py:10] start self_attn
cos shape torch.Size([65, 128]) sin shape torch.Size([65, 128]) position_ids tensor([[0]], device='cuda:1')
cos shape torch.Size([1, 1, 1, 128]) sin shape torch.Size([1, 1, 1, 128])
q_embed shape torch.Size([32, 16, 1, 128]) k_embed shape torch.Size([32, 16, 1, 128])
DEBUG 01-06 17:11:21.471418.471418 cuda_h.py:19] end self_attn cost 0.0013012886047363281 seconds
DEBUG 01-06 17:11:21.471368.471368 cuda_h.py:19] end iln_self_attn_paln cost 0.0018739700317382812 seconds
DEBUG 01-06 17:11:21.471151.471151 cuda_h.py:10] start layer_moe_dgenerate_1
DEBUG 01-06 17:11:21.471059.471059 cuda_h.py:10] start gate
INFO 01-06 17:11:21.472872.472872 client.py:127] Model loaded
DEBUG 01-06 17:11:21.473373.473373 cuda_h.py:19] end sllm_worker_task cost 0.014020919799804688 seconds
DEBUG 01-06 17:11:21.473378.473378 cuda_h.py:10] start sllm_worker_task
DEBUG 01-06 17:11:21.473123.473123 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 17:11:21.473326.473326 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 17:11:21.474049.474049 cuda_h.py:19] end allocate_cuda_memory cost 0.00033354759216308594 seconds
DEBUG 01-06 17:11:21.474609.474609 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 17:11:21.474760.474760 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 17:11:21.474153.474153 cuda_h.py:19] end gate cost 0.002768993377685547 seconds
DEBUG 01-06 17:11:21.474984.474984 cuda_h.py:10] start experts_map_get
INFO 01-06 17:11:21.475954.475954 lmp.py:611] using loaded check layer: False
INFO 01-06 17:11:21.475253.475253 lmp.py:620] 
INFO 01-06 17:11:21.475253.475253 lmp.py:620] Layer 1 Expert Device Distribution:
INFO 01-06 17:11:21.475201.475201 lmp.py:621]   Active experts: 60 (out of 64 total)
INFO 01-06 17:11:21.475897.475897 lmp.py:622] 
INFO 01-06 17:11:21.475897.475897 lmp.py:622]   Detailed Expert Distribution:
INFO 01-06 17:11:21.475031.475031 lmp.py:623]   Expert ID  | Tokens     | Actual Device  
INFO 01-06 17:11:21.475820.475820 lmp.py:624]   ----------------------------------------------------------------------
INFO 01-06 17:11:21.475085.475085 lmp.py:627]   3          | 1          |  meta           
INFO 01-06 17:11:21.475443.475443 lmp.py:627]   8          | 1          |  cuda:1         
INFO 01-06 17:11:21.475563.475563 lmp.py:627]   12         | 1          |  cuda:1         
INFO 01-06 17:11:21.475206.475206 lmp.py:627]   18         | 1          |  meta           
INFO 01-06 17:11:21.475372.475372 lmp.py:627]   22         | 1          |  meta           
INFO 01-06 17:11:21.475300.475300 lmp.py:627]   31         | 1          |  meta           
INFO 01-06 17:11:21.475943.475943 lmp.py:627]   33         | 1          |  cuda:1         
INFO 01-06 17:11:21.475109.475109 lmp.py:627]   37         | 1          |  meta           
DEBUG 01-06 17:11:21.475899.475899 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 17:11:21.475678.475678 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 5175cb86-eacb-467c-a374-6059e1e05e01
INFO 01-06 17:11:21.475953.475953 lmp.py:627]   39         | 1          |  cuda:1         
DEBUG 01-06 17:11:21.476512.476512 client.py:106] call stub.LoadModelAsync
INFO 01-06 17:11:21.476038.476038 lmp.py:627]   41         | 1          |  meta           
INFO 01-06 17:11:21.476069.476069 lmp.py:627]   48         | 1          |  cuda:1         
INFO 01-06 17:11:21.476288.476288 lmp.py:627]   54         | 1          |  meta           
INFO 01-06 17:11:21.476037.476037 lmp.py:627]   55         | 1          |  meta           
INFO 01-06 17:11:21.476965.476965 lmp.py:627]   1          | 2          |  meta           
INFO 01-06 17:11:21.476416.476416 lmp.py:627]   2          | 2          |  cuda:1         
INFO 01-06 17:11:21.476820.476820 lmp.py:627]   5          | 2          |  cuda:1         
INFO 01-06 17:11:21.476940.476940 lmp.py:627]   6          | 2          |  cuda:1         
INFO 01-06 17:11:21.476583.476583 lmp.py:627]   7          | 2          |  cuda:1         
INFO 01-06 17:11:21.476511.476511 lmp.py:627]   13         | 2          |  meta           
INFO 01-06 17:11:21.476346.476346 lmp.py:627]   16         | 2          |  cuda:1         
INFO 01-06 17:11:21.476850.476850 lmp.py:627]   17         | 2          |  meta           
INFO 01-06 17:11:21.476446.476446 lmp.py:627]   27         | 2          |  meta           
INFO 01-06 17:11:21.476281.476281 lmp.py:627]   28         | 2          |  meta           
INFO 01-06 17:11:21.476209.476209 lmp.py:627]   30         | 2          |  cuda:1         
INFO 01-06 17:11:21.476375.476375 lmp.py:627]   32         | 2          |  meta           
INFO 01-06 17:11:21.476018.476018 lmp.py:627]   36         | 2          |  meta           
INFO 01-06 17:11:21.476184.476184 lmp.py:627]   44         | 2          |  meta           
INFO 01-06 17:11:21.476066.476066 lmp.py:627]   47         | 2          |  meta           
INFO 01-06 17:11:21.476994.476994 lmp.py:627]   49         | 2          |  meta           
INFO 01-06 17:11:21.476637.476637 lmp.py:627]   11         | 3          |  meta           
INFO 01-06 17:11:21.476803.476803 lmp.py:627]   29         | 3          |  cuda:1         
INFO 01-06 17:11:21.476480.476480 lmp.py:627]   40         | 3          |  cuda:1         
INFO 01-06 17:11:21.476268.476268 lmp.py:627]   52         | 3          |  meta           
INFO 01-06 17:11:21.476481.476481 lmp.py:627]   53         | 3          |  cuda:1         
INFO 01-06 17:11:21.476216.476216 lmp.py:627]   60         | 3          |  meta           
INFO 01-06 17:11:21.476190.476190 lmp.py:627]   4          | 4          |  cuda:1         
INFO 01-06 17:11:21.476688.476688 lmp.py:627]   15         | 4          |  cuda:1         
INFO 01-06 17:11:21.476423.476423 lmp.py:627]   19         | 4          |  cuda:1         
INFO 01-06 17:11:21.476920.476920 lmp.py:627]   26         | 4          |  cuda:1         
INFO 01-06 17:11:21.476895.476895 lmp.py:627]   34         | 4          |  meta           
INFO 01-06 17:11:21.476392.476392 lmp.py:627]   38         | 4          |  meta           
INFO 01-06 17:11:21.476366.476366 lmp.py:627]   50         | 4          |  cuda:1         
INFO 01-06 17:11:21.476863.476863 lmp.py:627]   58         | 4          |  meta           
INFO 01-06 17:11:21.476837.476837 lmp.py:627]   59         | 4          |  meta           
INFO 01-06 17:11:21.476334.476334 lmp.py:627]   61         | 4          |  cuda:1         
INFO 01-06 17:11:21.476269.476269 lmp.py:627]   21         | 5          |  cuda:1         
INFO 01-06 17:11:21.477435.477435 lmp.py:627]   23         | 5          |  cuda:1         
INFO 01-06 17:11:21.477171.477171 lmp.py:627]   24         | 5          |  cuda:1         
INFO 01-06 17:11:21.477906.477906 lmp.py:627]   35         | 5          |  meta           
INFO 01-06 17:11:21.477403.477403 lmp.py:627]   42         | 5          |  cuda:1         
INFO 01-06 17:11:21.477139.477139 lmp.py:627]   46         | 5          |  cuda:1         
INFO 01-06 17:11:21.477875.477875 lmp.py:627]   56         | 5          |  cuda:1         
INFO 01-06 17:11:21.477372.477372 lmp.py:627]   57         | 5          |  cuda:1         
INFO 01-06 17:11:21.477869.477869 lmp.py:627]   63         | 5          |  cuda:1         
INFO 01-06 17:11:21.477366.477366 lmp.py:627]   43         | 6          |  meta           
INFO 01-06 17:11:21.477863.477863 lmp.py:627]   9          | 7          |  cuda:1         
INFO 01-06 17:11:21.477599.477599 lmp.py:627]   20         | 7          |  cuda:1         
INFO 01-06 17:11:21.477096.477096 lmp.py:627]   45         | 7          |  cuda:1         
INFO 01-06 17:11:21.477693.477693 lmp.py:627]   10         | 8          |  meta           
INFO 01-06 17:11:21.477859.477859 lmp.py:627]   14         | 9          |  cuda:1         
INFO 01-06 17:11:21.477787.477787 lmp.py:628] ============================================================
INFO 01-06 17:11:21.477787.477787 lmp.py:628] 
INFO 01-06 17:11:21.477244.477244 lmp.py:630] experts_gpu_list: [8, 12, 33, 39, 48, 2, 5, 6, 7, 16, 30, 29, 40, 53, 4, 15, 19, 26, 50, 61, 21, 23, 24, 42, 46, 56, 57, 63, 9, 20, 45, 14] num: 32
INFO 01-06 17:11:21.477080.477080 lmp.py:631] experts_cpu_list: [3, 18, 22, 31, 37, 41, 54, 55, 1, 13, 17, 27, 28, 32, 36, 44, 47, 49, 11, 52, 60, 34, 38, 58, 59, 35, 43, 10] num: 28
INFO 01-06 17:11:21.477690.477690 lmp.py:632] expert_actual_device_map {0: 'meta', 1: 'meta', 2: 'cuda:1', 3: 'meta', 4: 'cuda:1', 5: 'cuda:1', 6: 'cuda:1', 7: 'cuda:1', 8: 'cuda:1', 9: 'cuda:1', 10: 'meta', 11: 'meta', 12: 'cuda:1', 13: 'meta', 14: 'cuda:1', 15: 'cuda:1', 16: 'cuda:1', 17: 'meta', 18: 'meta', 19: 'cuda:1', 20: 'cuda:1', 21: 'cuda:1', 22: 'meta', 23: 'cuda:1', 24: 'cuda:1', 25: 'meta', 26: 'cuda:1', 27: 'meta', 28: 'meta', 29: 'cuda:1', 30: 'cuda:1', 31: 'meta', 32: 'meta', 33: 'cuda:1', 34: 'meta', 35: 'meta', 36: 'meta', 37: 'meta', 38: 'meta', 39: 'cuda:1', 40: 'cuda:1', 41: 'meta', 42: 'cuda:1', 43: 'meta', 44: 'meta', 45: 'cuda:1', 46: 'cuda:1', 47: 'meta', 48: 'cuda:1', 49: 'meta', 50: 'cuda:1', 51: 'meta', 52: 'meta', 53: 'cuda:1', 54: 'meta', 55: 'meta', 56: 'cuda:1', 57: 'cuda:1', 58: 'meta', 59: 'meta', 60: 'meta', 61: 'cuda:1', 62: 'meta', 63: 'cuda:1'}
DEBUG 01-06 17:11:21.477108.477108 cuda_h.py:19] end experts_map_get cost 0.0024814605712890625 seconds
DEBUG 01-06 17:11:21.477580.477580 cuda_h.py:10] start gpu_sexperts
DEBUG 01-06 17:11:21.477531.477531 cuda_h.py:19] end gpu_sexperts cost 0.00027751922607421875 seconds
DEBUG 01-06 17:11:21.477646.477646 cuda_h.py:10] start gpu_experts
INFO 01-06 17:11:21.478827.478827 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 5175cb86-eacb-467c-a374-6059e1e05e01
DEBUG 01-06 17:11:21.478527.478527 cuda_h.py:19] end load_into_gpu_async cost 0.0037114620208740234 seconds
DEBUG 01-06 17:11:21.478557.478557 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 17:11:21.478128.478128 cuda_h.py:19] end restore_tensors2 cost 0.00017309188842773438 seconds
DEBUG 01-06 17:11:21.478138.478138 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.004919767379760742 seconds
INFO 01-06 17:11:21.478121.478121 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 5175cb86-eacb-467c-a374-6059e1e05e01
DEBUG 01-06 17:11:21.479424.479424 mlpmodule.py:533] gpu group tensors cost 0.0014257431030273438 s
DEBUG 01-06 17:11:21.480613.480613 mlpmodule.py:566] gpu pad cost 0.0014450550079345703 s
DEBUG 01-06 17:11:21.481315.481315 mlpmodule.py:584] gpu group einsum cost 0.0003218650817871094 s
DEBUG 01-06 17:11:21.483191.483191 mlpmodule.py:613] gpu experts func einsum cost 0.006136894226074219 s
DEBUG 01-06 17:11:21.484200.484200 cuda_h.py:19] end gpu_experts cost 0.006245136260986328 seconds
DEBUG 01-06 17:11:21.484810.484810 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-06 17:11:21.484275.484275 lmp.py:661] 
DEBUG 01-06 17:11:21.484275.484275 lmp.py:661]   Computing 28 experts on CPU...
DEBUG 01-06 17:11:21.484912.484912 cuda_h.py:19] end cpu_experts_submit cost 4.887580871582031e-05 seconds
DEBUG 01-06 17:11:21.484085.484085 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-06 17:11:21.494514.494514 mlpmodule.py:706] group tensors cost 0.010060787200927734 s
INFO 01-06 17:11:21.495699.495699 client.py:127] Model loaded
DEBUG 01-06 17:11:21.497899.497899 cuda_h.py:19] end sllm_worker_task cost 0.023939132690429688 seconds
DEBUG 01-06 17:11:21.497700.497700 cuda_h.py:10] start sllm_worker_task
DEBUG 01-06 17:11:21.498982.498982 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 17:11:21.498503.498503 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 17:11:21.498863.498863 cuda_h.py:19] end allocate_cuda_memory cost 0.00038123130798339844 seconds
DEBUG 01-06 17:11:21.498451.498451 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 17:11:21.498713.498713 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 17:11:21.499471.499471 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 17:11:21.499665.499665 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 9e8561fc-f2d6-4929-9ace-cebbcfa08b40
DEBUG 01-06 17:11:21.499944.499944 client.py:106] call stub.LoadModelAsync
INFO 01-06 17:11:21.500634.500634 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 9e8561fc-f2d6-4929-9ace-cebbcfa08b40
DEBUG 01-06 17:11:21.501526.501526 cuda_h.py:19] end load_into_gpu_async cost 0.0021390914916992188 seconds
DEBUG 01-06 17:11:21.501721.501721 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 17:11:21.501470.501470 cuda_h.py:19] end restore_tensors2 cost 0.00016117095947265625 seconds
DEBUG 01-06 17:11:21.501400.501400 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0033164024353027344 seconds
INFO 01-06 17:11:21.501531.501531 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 9e8561fc-f2d6-4929-9ace-cebbcfa08b40
DEBUG 01-06 17:11:21.502873.502873 mlpmodule.py:744] pad cost 0.006959438323974609 s
DEBUG 01-06 17:11:21.502361.502361 mlpmodule.py:750] create cpu tensor cost 5.1975250244140625e-05 s
DEBUG 01-06 17:11:21.502893.502893 mlpmodule.py:755] move to cpu cost 3.552436828613281e-05 s
DEBUG 01-06 17:11:21.507448.507448 mlpmodule.py:769] group_w3: shape=torch.Size([28, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=80740352
DEBUG 01-06 17:11:21.507457.507457 mlpmodule.py:770] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-06 17:11:21.507347.507347 mlpmodule.py:775] group_w3 first element: 0.01348876953125
WARNING 01-06 17:11:21.507283.507283 mlpmodule.py:785] start einsum2
INFO 01-06 17:11:21.511289.511289 client.py:127] Model loaded
DEBUG 01-06 17:11:21.514758.514758 cuda_h.py:19] end sllm_worker_task cost 0.015907764434814453 seconds
DEBUG 01-06 17:11:21.514333.514333 cuda_h.py:10] start sllm_worker_task
DEBUG 01-06 17:11:21.514080.514080 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 17:11:21.515451.515451 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 17:11:21.515200.515200 cuda_h.py:19] end allocate_cuda_memory cost 0.0006296634674072266 seconds
DEBUG 01-06 17:11:21.516510.516510 mlpmodule.py:795] group einsum cost 0.013215780258178711 s
DEBUG 01-06 17:11:21.516846.516846 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 17:11:21.516604.516604 mlpmodule.py:803] cpy2cputensor cost 0.00013446807861328125 s
DEBUG 01-06 17:11:21.516547.516547 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 17:11:21.516757.516757 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 17:11:21.517397.517397 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 84ecb940-405a-400b-ba6c-7e17dae8b6e2
DEBUG 01-06 17:11:21.517208.517208 client.py:106] call stub.LoadModelAsync
INFO 01-06 17:11:21.518977.518977 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 84ecb940-405a-400b-ba6c-7e17dae8b6e2
DEBUG 01-06 17:11:21.519868.519868 cuda_h.py:19] end load_into_gpu_async cost 0.0024759769439697266 seconds
DEBUG 01-06 17:11:21.519160.519160 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 17:11:21.519882.519882 cuda_h.py:19] end restore_tensors2 cost 0.00014138221740722656 seconds
DEBUG 01-06 17:11:21.519229.519229 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.004326581954956055 seconds
INFO 01-06 17:11:21.519258.519258 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 84ecb940-405a-400b-ba6c-7e17dae8b6e2
DEBUG 01-06 17:11:21.521754.521754 cuda_h.py:19] end wait_cetm_experts cost 0.03734874725341797 seconds
DEBUG 01-06 17:11:21.521110.521110 cuda_h.py:19] end layer_moe_dgenerate_1 cost 0.04996514320373535 seconds
DEBUG 01-06 17:11:21.522507.522507 lmp.py:325] -------------------------------- end decode layer 1 --------------------------------
DEBUG 01-06 17:11:21.522906.522906 lmp.py:298] -------------------------------- start decode layer 2 --------------------------------
DEBUG 01-06 17:11:21.522423.522423 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-06 17:11:21.522811.522811 mlpmodule.py:367] cuda:1 cuda:1
DEBUG 01-06 17:11:21.522481.522481 cuda_h.py:10] start self_attn
cos shape torch.Size([65, 128]) sin shape torch.Size([65, 128]) position_ids tensor([[0]], device='cuda:1')
cos shape torch.Size([1, 1, 1, 128]) sin shape torch.Size([1, 1, 1, 128])
q_embed shape torch.Size([32, 16, 1, 128]) k_embed shape torch.Size([32, 16, 1, 128])
DEBUG 01-06 17:11:21.525632.525632 cuda_h.py:19] end self_attn cost 0.0022330284118652344 seconds
DEBUG 01-06 17:11:21.525910.525910 cuda_h.py:19] end iln_self_attn_paln cost 0.003231525421142578 seconds
DEBUG 01-06 17:11:21.525807.525807 cuda_h.py:10] start layer_moe_dgenerate_2
DEBUG 01-06 17:11:21.525113.525113 cuda_h.py:10] start gate
DEBUG 01-06 17:11:21.526954.526954 cuda_h.py:19] end gate cost 0.0007479190826416016 seconds
DEBUG 01-06 17:11:21.526135.526135 cuda_h.py:10] start experts_map_get
INFO 01-06 17:11:21.526329.526329 lmp.py:611] using loaded check layer: False
INFO 01-06 17:11:21.527972.527972 lmp.py:620] 
INFO 01-06 17:11:21.527972.527972 lmp.py:620] Layer 2 Expert Device Distribution:
INFO 01-06 17:11:21.527974.527974 lmp.py:621]   Active experts: 59 (out of 64 total)
INFO 01-06 17:11:21.527008.527008 lmp.py:622] 
INFO 01-06 17:11:21.527008.527008 lmp.py:622]   Detailed Expert Distribution:
INFO 01-06 17:11:21.527902.527902 lmp.py:623]   Expert ID  | Tokens     | Actual Device  
INFO 01-06 17:11:21.527075.527075 lmp.py:624]   ----------------------------------------------------------------------
INFO 01-06 17:11:21.527871.527871 lmp.py:627]   3          | 1          |  meta           
INFO 01-06 17:11:21.527805.527805 lmp.py:627]   8          | 1          |  meta           
INFO 01-06 17:11:21.527932.527932 lmp.py:627]   23         | 1          |  meta           
INFO 01-06 17:11:21.527390.527390 lmp.py:627]   27         | 1          |  meta           
INFO 01-06 17:11:21.527993.527993 lmp.py:627]   30         | 1          |  meta           
INFO 01-06 17:11:21.527405.527405 lmp.py:627]   34         | 1          |  meta           
INFO 01-06 17:11:21.527293.527293 lmp.py:627]   37         | 1          |  meta           
INFO 01-06 17:11:21.527750.527750 lmp.py:627]   38         | 1          |  cuda:1         
INFO 01-06 17:11:21.527115.527115 lmp.py:627]   48         | 1          |  meta           
INFO 01-06 17:11:21.527335.527335 lmp.py:627]   49         | 1          |  meta           
INFO 01-06 17:11:21.527984.527984 lmp.py:627]   51         | 1          |  meta           
INFO 01-06 17:11:21.527157.527157 lmp.py:627]   58         | 1          |  meta           
INFO 01-06 17:11:21.527999.527999 lmp.py:627]   63         | 1          |  cuda:1         
INFO 01-06 17:11:21.527695.527695 lmp.py:627]   0          | 2          |  meta           
INFO 01-06 17:11:21.527107.527107 lmp.py:627]   10         | 2          |  cuda:1         
INFO 01-06 17:11:21.527564.527564 lmp.py:627]   15         | 2          |  meta           
INFO 01-06 17:11:21.527168.527168 lmp.py:627]   24         | 2          |  meta           
INFO 01-06 17:11:21.527102.527102 lmp.py:627]   26         | 2          |  meta           
INFO 01-06 17:11:21.528335.528335 lmp.py:627]   31         | 2          |  cuda:1         
INFO 01-06 17:11:21.528793.528793 lmp.py:627]   35         | 2          |  meta           
INFO 01-06 17:11:21.528443.528443 lmp.py:627]   39         | 2          |  cuda:1         
INFO 01-06 17:11:21.528569.528569 lmp.py:627]   44         | 2          |  cuda:1         
INFO 01-06 17:11:21.528457.528457 lmp.py:627]   46         | 2          |  cuda:1         
INFO 01-06 17:11:21.528438.528438 lmp.py:627]   47         | 2          |  cuda:1         
INFO 01-06 17:11:21.528326.528326 lmp.py:627]   1          | 3          |  meta           
INFO 01-06 17:11:21.528307.528307 lmp.py:627]   2          | 3          |  cuda:1         
INFO 01-06 17:11:21.528957.528957 lmp.py:627]   4          | 3          |  cuda:1         
INFO 01-06 17:11:21.528891.528891 lmp.py:627]   9          | 3          |  meta           
INFO 01-06 17:11:21.528780.528780 lmp.py:627]   17         | 3          |  meta           
INFO 01-06 17:11:21.528999.528999 lmp.py:627]   19         | 3          |  cuda:1         
INFO 01-06 17:11:21.528364.528364 lmp.py:627]   21         | 3          |  cuda:1         
INFO 01-06 17:11:21.528822.528822 lmp.py:627]   25         | 3          |  meta           
INFO 01-06 17:11:21.528710.528710 lmp.py:627]   28         | 3          |  meta           
INFO 01-06 17:11:21.528598.528598 lmp.py:627]   32         | 3          |  meta           
INFO 01-06 17:11:21.528201.528201 lmp.py:627]   40         | 3          |  cuda:1         
INFO 01-06 17:11:21.528928.528928 lmp.py:627]   42         | 3          |  cuda:1         
INFO 01-06 17:11:21.528293.528293 lmp.py:627]   53         | 3          |  meta           
INFO 01-06 17:11:21.528751.528751 lmp.py:627]   62         | 3          |  meta           
INFO 01-06 17:11:21.528162.528162 lmp.py:627]   7          | 4          |  meta           
INFO 01-06 17:11:21.528143.528143 lmp.py:627]   12         | 4          |  meta           
INFO 01-06 17:11:21.528747.528747 lmp.py:627]   20         | 4          |  cuda:1         
INFO 01-06 17:11:21.528158.528158 lmp.py:627]   36         | 4          |  meta           
INFO 01-06 17:11:21.528569.528569 lmp.py:627]   41         | 4          |  cuda:1         
INFO 01-06 17:11:21.528550.528550 lmp.py:627]   60         | 4          |  cuda:1         
INFO 01-06 17:11:21.528200.528200 lmp.py:627]   13         | 5          |  cuda:1         
INFO 01-06 17:11:21.528658.528658 lmp.py:627]   14         | 5          |  cuda:1         
INFO 01-06 17:11:21.528784.528784 lmp.py:627]   18         | 5          |  cuda:1         
INFO 01-06 17:11:21.528957.528957 lmp.py:627]   33         | 5          |  cuda:1         
INFO 01-06 17:11:21.528607.528607 lmp.py:627]   43         | 5          |  cuda:1         
INFO 01-06 17:11:21.528826.528826 lmp.py:627]   50         | 5          |  cuda:1         
INFO 01-06 17:11:21.528237.528237 lmp.py:627]   52         | 5          |  cuda:1         
INFO 01-06 17:11:21.528934.528934 lmp.py:627]   55         | 5          |  cuda:1         
INFO 01-06 17:11:21.528583.528583 lmp.py:627]   16         | 6          |  cuda:1         
INFO 01-06 17:11:21.528995.528995 lmp.py:627]   22         | 6          |  cuda:1         
INFO 01-06 17:11:21.528360.528360 lmp.py:627]   45         | 6          |  meta           
INFO 01-06 17:11:21.528340.528340 lmp.py:627]   59         | 6          |  cuda:1         
INFO 01-06 17:11:21.528513.528513 lmp.py:627]   61         | 6          |  cuda:1         
INFO 01-06 17:11:21.529494.529494 lmp.py:627]   5          | 9          |  cuda:1         
INFO 01-06 17:11:21.529667.529667 lmp.py:627]   11         | 12         |  cuda:1         
INFO 01-06 17:11:21.529171.529171 lmp.py:628] ============================================================
INFO 01-06 17:11:21.529171.529171 lmp.py:628] 
INFO 01-06 17:11:21.529828.529828 lmp.py:630] experts_gpu_list: [38, 63, 10, 31, 39, 44, 46, 47, 2, 4, 19, 21, 40, 42, 20, 41, 60, 13, 14, 18, 33, 43, 50, 52, 55, 16, 22, 59, 61, 5, 11] num: 31
INFO 01-06 17:11:21.529339.529339 lmp.py:631] experts_cpu_list: [3, 8, 23, 27, 30, 34, 37, 48, 49, 51, 58, 0, 15, 24, 26, 35, 1, 9, 17, 25, 28, 32, 53, 62, 7, 12, 36, 45] num: 28
INFO 01-06 17:11:21.529300.529300 lmp.py:632] expert_actual_device_map {0: 'meta', 1: 'meta', 2: 'cuda:1', 3: 'meta', 4: 'cuda:1', 5: 'cuda:1', 6: 'meta', 7: 'meta', 8: 'meta', 9: 'meta', 10: 'cuda:1', 11: 'cuda:1', 12: 'meta', 13: 'cuda:1', 14: 'cuda:1', 15: 'meta', 16: 'cuda:1', 17: 'meta', 18: 'cuda:1', 19: 'cuda:1', 20: 'cuda:1', 21: 'cuda:1', 22: 'cuda:1', 23: 'meta', 24: 'meta', 25: 'meta', 26: 'meta', 27: 'meta', 28: 'meta', 29: 'meta', 30: 'meta', 31: 'cuda:1', 32: 'meta', 33: 'cuda:1', 34: 'meta', 35: 'meta', 36: 'meta', 37: 'meta', 38: 'cuda:1', 39: 'cuda:1', 40: 'cuda:1', 41: 'cuda:1', 42: 'cuda:1', 43: 'cuda:1', 44: 'cuda:1', 45: 'meta', 46: 'cuda:1', 47: 'cuda:1', 48: 'meta', 49: 'meta', 50: 'cuda:1', 51: 'meta', 52: 'cuda:1', 53: 'meta', 54: 'meta', 55: 'cuda:1', 56: 'cuda:1', 57: 'meta', 58: 'meta', 59: 'cuda:1', 60: 'cuda:1', 61: 'cuda:1', 62: 'meta', 63: 'cuda:1'}
DEBUG 01-06 17:11:21.529632.529632 cuda_h.py:19] end experts_map_get cost 0.0027506351470947266 seconds
INFO 01-06 17:11:21.529319.529319 client.py:127] Model loaded
DEBUG 01-06 17:11:21.529507.529507 cuda_h.py:10] start gpu_sexperts
DEBUG 01-06 17:11:21.530562.530562 cuda_h.py:19] end sllm_worker_task cost 0.015409231185913086 seconds
DEBUG 01-06 17:11:21.530565.530565 cuda_h.py:10] start sllm_worker_task
DEBUG 01-06 17:11:21.530804.530804 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 17:11:21.530217.530217 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 17:11:21.531325.531325 cuda_h.py:19] end allocate_cuda_memory cost 0.001196146011352539 seconds
DEBUG 01-06 17:11:21.531367.531367 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 17:11:21.531414.531414 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 17:11:21.531853.531853 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 17:11:21.531132.531132 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, ee0124e0-9133-4aa8-a03d-0ddf7e34ef43
DEBUG 01-06 17:11:21.531016.531016 client.py:106] call stub.LoadModelAsync
DEBUG 01-06 17:11:21.532352.532352 mlpmodule.py:664]  experts func einsum cost 0.04761385917663574 s
DEBUG 01-06 17:11:21.532041.532041 cuda_h.py:19] end gpu_sexperts cost 0.0024187564849853516 seconds
DEBUG 01-06 17:11:21.532767.532767 cuda_h.py:10] start gpu_experts
DEBUG 01-06 17:11:21.533367.533367 mlpmodule.py:533] gpu group tensors cost 0.0006399154663085938 s
INFO 01-06 17:11:21.533016.533016 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, ee0124e0-9133-4aa8-a03d-0ddf7e34ef43
DEBUG 01-06 17:11:21.533012.533012 cuda_h.py:19] end load_into_gpu_async cost 0.0016314983367919922 seconds
DEBUG 01-06 17:11:21.533053.533053 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 17:11:21.533394.533394 cuda_h.py:19] end restore_tensors2 cost 8.058547973632812e-05 seconds
DEBUG 01-06 17:11:21.533793.533793 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.003192901611328125 seconds
INFO 01-06 17:11:21.533749.533749 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, ee0124e0-9133-4aa8-a03d-0ddf7e34ef43
DEBUG 01-06 17:11:21.534184.534184 mlpmodule.py:566] gpu pad cost 0.0017745494842529297 s
DEBUG 01-06 17:11:21.535893.535893 mlpmodule.py:584] gpu group einsum cost 0.00035762786865234375 s
DEBUG 01-06 17:11:21.538894.538894 mlpmodule.py:613] gpu experts func einsum cost 0.005697965621948242 s
DEBUG 01-06 17:11:21.538898.538898 cuda_h.py:19] end gpu_experts cost 0.005856752395629883 seconds
DEBUG 01-06 17:11:21.538084.538084 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-06 17:11:21.538264.538264 lmp.py:661] 
DEBUG 01-06 17:11:21.538264.538264 lmp.py:661]   Computing 28 experts on CPU...
DEBUG 01-06 17:11:21.538399.538399 cuda_h.py:19] end cpu_experts_submit cost 6.4849853515625e-05 seconds
DEBUG 01-06 17:11:21.538717.538717 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-06 17:11:21.542745.542745 mlpmodule.py:706] group tensors cost 0.004190206527709961 s
INFO 01-06 17:11:21.543928.543928 client.py:127] Model loaded
DEBUG 01-06 17:11:21.544664.544664 cuda_h.py:19] end sllm_worker_task cost 0.014178276062011719 seconds
DEBUG 01-06 17:11:21.544374.544374 cuda_h.py:10] start sllm_worker_task
DEBUG 01-06 17:11:21.544707.544707 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 17:11:21.544682.544682 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 17:11:21.544724.544724 cuda_h.py:19] end allocate_cuda_memory cost 0.00023365020751953125 seconds
DEBUG 01-06 17:11:21.545144.545144 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 17:11:21.545999.545999 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 17:11:21.545192.545192 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 17:11:21.545942.545942 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, d1636745-9365-456e-ad1b-0988d280048f
DEBUG 01-06 17:11:21.545011.545011 client.py:106] call stub.LoadModelAsync
DEBUG 01-06 17:11:21.546275.546275 mlpmodule.py:744] pad cost 0.0030014514923095703 s
INFO 01-06 17:11:21.546029.546029 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, d1636745-9365-456e-ad1b-0988d280048f
DEBUG 01-06 17:11:21.546019.546019 mlpmodule.py:750] create cpu tensor cost 0.00017881393432617188 s
DEBUG 01-06 17:11:21.546003.546003 cuda_h.py:19] end load_into_gpu_async cost 0.0016765594482421875 seconds
DEBUG 01-06 17:11:21.546768.546768 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 17:11:21.546334.546334 cuda_h.py:19] end restore_tensors2 cost 6.723403930664062e-05 seconds
DEBUG 01-06 17:11:21.547025.547025 mlpmodule.py:755] move to cpu cost 0.00020170211791992188 s
DEBUG 01-06 17:11:21.547007.547007 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0023980140686035156 seconds
INFO 01-06 17:11:21.547046.547046 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, d1636745-9365-456e-ad1b-0988d280048f
DEBUG 01-06 17:11:21.551560.551560 mlpmodule.py:769] group_w3: shape=torch.Size([28, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=80740352
DEBUG 01-06 17:11:21.551669.551669 mlpmodule.py:770] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-06 17:11:21.551220.551220 mlpmodule.py:775] group_w3 first element: 0.02001953125
WARNING 01-06 17:11:21.551528.551528 mlpmodule.py:785] start einsum2
INFO 01-06 17:11:21.557465.557465 client.py:127] Model loaded
DEBUG 01-06 17:11:21.558717.558717 mlpmodule.py:795] group einsum cost 0.010820388793945312 s
DEBUG 01-06 17:11:21.559897.559897 mlpmodule.py:803] cpy2cputensor cost 0.0006406307220458984 s
DEBUG 01-06 17:11:21.559052.559052 cuda_h.py:19] end sllm_worker_task cost 0.014619112014770508 seconds
DEBUG 01-06 17:11:21.559990.559990 cuda_h.py:10] start sllm_worker_task
DEBUG 01-06 17:11:21.559859.559859 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 17:11:21.559623.559623 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 17:11:21.559816.559816 cuda_h.py:19] end allocate_cuda_memory cost 0.00037550926208496094 seconds
DEBUG 01-06 17:11:21.560792.560792 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 17:11:21.560416.560416 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 17:11:21.560902.560902 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 17:11:21.560334.560334 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 9e7e32c1-e68c-4b49-aded-b92b45213ed1
DEBUG 01-06 17:11:21.560874.560874 client.py:106] call stub.LoadModelAsync
INFO 01-06 17:11:21.561805.561805 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 9e7e32c1-e68c-4b49-aded-b92b45213ed1
DEBUG 01-06 17:11:21.561179.561179 cuda_h.py:19] end load_into_gpu_async cost 0.0018253326416015625 seconds
DEBUG 01-06 17:11:21.561465.561465 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 17:11:21.562477.562477 cuda_h.py:19] end restore_tensors2 cost 0.00011754035949707031 seconds
DEBUG 01-06 17:11:21.562200.562200 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.002643585205078125 seconds
INFO 01-06 17:11:21.562170.562170 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 9e7e32c1-e68c-4b49-aded-b92b45213ed1
DEBUG 01-06 17:11:21.564045.564045 cuda_h.py:19] end wait_cetm_experts cost 0.025966644287109375 seconds
DEBUG 01-06 17:11:21.564386.564386 cuda_h.py:19] end layer_moe_dgenerate_2 cost 0.03921842575073242 seconds
DEBUG 01-06 17:11:21.564365.564365 lmp.py:325] -------------------------------- end decode layer 2 --------------------------------
DEBUG 01-06 17:11:21.564366.564366 lmp.py:298] -------------------------------- start decode layer 3 --------------------------------
DEBUG 01-06 17:11:21.564685.564685 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-06 17:11:21.565900.565900 mlpmodule.py:367] cuda:1 cuda:1
DEBUG 01-06 17:11:21.565310.565310 cuda_h.py:10] start self_attn
cos shape torch.Size([65, 128]) sin shape torch.Size([65, 128]) position_ids tensor([[0]], device='cuda:1')
cos shape torch.Size([1, 1, 1, 128]) sin shape torch.Size([1, 1, 1, 128])
q_embed shape torch.Size([32, 16, 1, 128]) k_embed shape torch.Size([32, 16, 1, 128])
DEBUG 01-06 17:11:21.567290.567290 cuda_h.py:19] end self_attn cost 0.0019288063049316406 seconds
DEBUG 01-06 17:11:21.567282.567282 cuda_h.py:19] end iln_self_attn_paln cost 0.002758026123046875 seconds
DEBUG 01-06 17:11:21.567171.567171 cuda_h.py:10] start layer_moe_dgenerate_3
DEBUG 01-06 17:11:21.567086.567086 cuda_h.py:10] start gate
DEBUG 01-06 17:11:21.568952.568952 cuda_h.py:19] end gate cost 0.0007040500640869141 seconds
DEBUG 01-06 17:11:21.568696.568696 cuda_h.py:10] start experts_map_get
INFO 01-06 17:11:21.569391.569391 lmp.py:611] using loaded check layer: False
INFO 01-06 17:11:21.569113.569113 lmp.py:620] 
INFO 01-06 17:11:21.569113.569113 lmp.py:620] Layer 3 Expert Device Distribution:
INFO 01-06 17:11:21.569452.569452 lmp.py:621]   Active experts: 57 (out of 64 total)
INFO 01-06 17:11:21.569916.569916 lmp.py:622] 
INFO 01-06 17:11:21.569916.569916 lmp.py:622]   Detailed Expert Distribution:
INFO 01-06 17:11:21.569811.569811 lmp.py:623]   Expert ID  | Tokens     | Actual Device  
INFO 01-06 17:11:21.569892.569892 lmp.py:624]   ----------------------------------------------------------------------
INFO 01-06 17:11:21.569402.569402 lmp.py:627]   1          | 1          |  meta           
INFO 01-06 17:11:21.569244.569244 lmp.py:627]   5          | 1          |  meta           
INFO 01-06 17:11:21.569563.569563 lmp.py:627]   7          | 1          |  meta           
INFO 01-06 17:11:21.569405.569405 lmp.py:627]   27         | 1          |  meta           
INFO 01-06 17:11:21.569723.569723 lmp.py:627]   39         | 1          |  meta           
INFO 01-06 17:11:21.569088.569088 lmp.py:627]   43         | 1          |  cuda:1         
INFO 01-06 17:11:21.569930.569930 lmp.py:627]   45         | 1          |  meta           
INFO 01-06 17:11:21.569534.569534 lmp.py:627]   46         | 1          |  cuda:1         
INFO 01-06 17:11:21.569422.569422 lmp.py:627]   47         | 1          |  cuda:1         
INFO 01-06 17:11:21.569741.569741 lmp.py:627]   59         | 1          |  meta           
INFO 01-06 17:11:21.570059.570059 lmp.py:627]   62         | 1          |  cuda:1         
INFO 01-06 17:11:21.570663.570663 lmp.py:627]   0          | 2          |  cuda:1         
INFO 01-06 17:11:21.570028.570028 lmp.py:627]   4          | 2          |  meta           
INFO 01-06 17:11:21.570393.570393 lmp.py:627]   17         | 2          |  cuda:1         
INFO 01-06 17:11:21.570043.570043 lmp.py:627]   28         | 2          |  cuda:1         
INFO 01-06 17:11:21.570646.570646 lmp.py:627]   35         | 2          |  meta           
INFO 01-06 17:11:21.570773.570773 lmp.py:627]   44         | 2          |  cuda:1         
INFO 01-06 17:11:21.570661.570661 lmp.py:627]   48         | 2          |  meta           
INFO 01-06 17:11:21.570072.570072 lmp.py:627]   49         | 2          |  meta           
INFO 01-06 17:11:21.570484.570484 lmp.py:627]   50         | 2          |  meta           
INFO 01-06 17:11:21.570133.570133 lmp.py:627]   55         | 2          |  cuda:1         
INFO 01-06 17:11:21.570498.570498 lmp.py:627]   58         | 2          |  cuda:1         
INFO 01-06 17:11:21.570863.570863 lmp.py:627]   3          | 3          |  cuda:1         
INFO 01-06 17:11:21.570751.570751 lmp.py:627]   13         | 3          |  meta           
INFO 01-06 17:11:21.570686.570686 lmp.py:627]   14         | 3          |  cuda:1         
INFO 01-06 17:11:21.570574.570574 lmp.py:627]   16         | 3          |  meta           
INFO 01-06 17:11:21.570747.570747 lmp.py:627]   21         | 3          |  cuda:1         
INFO 01-06 17:11:21.570635.570635 lmp.py:627]   22         | 3          |  cuda:1         
INFO 01-06 17:11:21.570523.570523 lmp.py:627]   23         | 3          |  meta           
INFO 01-06 17:11:21.570412.570412 lmp.py:627]   24         | 3          |  cuda:1         
INFO 01-06 17:11:21.570346.570346 lmp.py:627]   25         | 3          |  cuda:1         
INFO 01-06 17:11:21.570758.570758 lmp.py:627]   31         | 3          |  cuda:1         
INFO 01-06 17:11:21.570692.570692 lmp.py:627]   34         | 3          |  meta           
INFO 01-06 17:11:21.570103.570103 lmp.py:627]   36         | 3          |  meta           
INFO 01-06 17:11:21.570707.570707 lmp.py:627]   57         | 3          |  cuda:1         
INFO 01-06 17:11:21.570833.570833 lmp.py:627]   61         | 3          |  meta           
INFO 01-06 17:11:21.570006.570006 lmp.py:627]   63         | 3          |  cuda:1         
INFO 01-06 17:11:21.570895.570895 lmp.py:627]   2          | 4          |  meta           
INFO 01-06 17:11:21.570067.570067 lmp.py:627]   6          | 4          |  meta           
INFO 01-06 17:11:21.570956.570956 lmp.py:627]   12         | 4          |  cuda:1         
INFO 01-06 17:11:21.570367.570367 lmp.py:627]   20         | 4          |  cuda:1         
INFO 01-06 17:11:21.570494.570494 lmp.py:627]   32         | 4          |  meta           
INFO 01-06 17:11:21.570667.570667 lmp.py:627]   33         | 4          |  cuda:1         
INFO 01-06 17:11:21.570316.570316 lmp.py:627]   40         | 4          |  meta           
INFO 01-06 17:11:21.570251.570251 lmp.py:627]   60         | 4          |  cuda:1         
INFO 01-06 17:11:21.570662.570662 lmp.py:627]   9          | 5          |  meta           
INFO 01-06 17:11:21.570120.570120 lmp.py:627]   10         | 5          |  cuda:1         
INFO 01-06 17:11:21.570246.570246 lmp.py:627]   38         | 5          |  cuda:1         
INFO 01-06 17:11:21.570373.570373 lmp.py:627]   52         | 5          |  meta           
INFO 01-06 17:11:21.570784.570784 lmp.py:627]   54         | 5          |  cuda:1         
INFO 01-06 17:11:21.570957.570957 lmp.py:627]   29         | 6          |  cuda:1         
INFO 01-06 17:11:21.570892.570892 lmp.py:627]   37         | 6          |  meta           
INFO 01-06 17:11:21.570065.570065 lmp.py:627]   42         | 6          |  cuda:1         
INFO 01-06 17:11:21.570953.570953 lmp.py:627]   53         | 6          |  cuda:1         
INFO 01-06 17:11:21.571841.571841 lmp.py:627]   41         | 7          |  cuda:1         
INFO 01-06 17:11:21.571491.571491 lmp.py:627]   8          | 9          |  cuda:1         
INFO 01-06 17:11:21.571664.571664 lmp.py:627]   19         | 17         |  cuda:1         
INFO 01-06 17:11:21.571360.571360 lmp.py:628] ============================================================
INFO 01-06 17:11:21.571360.571360 lmp.py:628] 
INFO 01-06 17:11:21.571732.571732 lmp.py:630] experts_gpu_list: [43, 46, 47, 62, 0, 17, 28, 44, 55, 58, 3, 14, 21, 22, 24, 25, 31, 57, 63, 12, 20, 33, 60, 10, 38, 54, 29, 42, 53, 41, 8, 19] num: 32
INFO 01-06 17:11:21.571289.571289 lmp.py:631] experts_cpu_list: [1, 5, 7, 27, 39, 45, 59, 4, 35, 48, 49, 50, 13, 16, 23, 34, 36, 61, 2, 6, 32, 40, 9, 52, 37] num: 25
INFO 01-06 17:11:21.571244.571244 lmp.py:632] expert_actual_device_map {0: 'cuda:1', 1: 'meta', 2: 'meta', 3: 'cuda:1', 4: 'meta', 5: 'meta', 6: 'meta', 7: 'meta', 8: 'cuda:1', 9: 'meta', 10: 'cuda:1', 11: 'meta', 12: 'cuda:1', 13: 'meta', 14: 'cuda:1', 15: 'meta', 16: 'meta', 17: 'cuda:1', 18: 'meta', 19: 'cuda:1', 20: 'cuda:1', 21: 'cuda:1', 22: 'cuda:1', 23: 'meta', 24: 'cuda:1', 25: 'cuda:1', 26: 'meta', 27: 'meta', 28: 'cuda:1', 29: 'cuda:1', 30: 'meta', 31: 'cuda:1', 32: 'meta', 33: 'cuda:1', 34: 'meta', 35: 'meta', 36: 'meta', 37: 'meta', 38: 'cuda:1', 39: 'meta', 40: 'meta', 41: 'cuda:1', 42: 'cuda:1', 43: 'cuda:1', 44: 'cuda:1', 45: 'meta', 46: 'cuda:1', 47: 'cuda:1', 48: 'meta', 49: 'meta', 50: 'meta', 51: 'meta', 52: 'meta', 53: 'cuda:1', 54: 'cuda:1', 55: 'cuda:1', 56: 'meta', 57: 'cuda:1', 58: 'cuda:1', 59: 'meta', 60: 'cuda:1', 61: 'meta', 62: 'cuda:1', 63: 'cuda:1'}
DEBUG 01-06 17:11:21.571207.571207 cuda_h.py:19] end experts_map_get cost 0.0025529861450195312 seconds
INFO 01-06 17:11:21.571620.571620 client.py:127] Model loaded
DEBUG 01-06 17:11:21.571788.571788 cuda_h.py:10] start gpu_sexperts
DEBUG 01-06 17:11:21.572117.572117 cuda_h.py:19] end gpu_sexperts cost 0.0006732940673828125 seconds
DEBUG 01-06 17:11:21.572253.572253 cuda_h.py:19] end sllm_worker_task cost 0.012962818145751953 seconds
DEBUG 01-06 17:11:21.572407.572407 cuda_h.py:10] start gpu_experts
DEBUG 01-06 17:11:21.572138.572138 cuda_h.py:10] start sllm_worker_task
DEBUG 01-06 17:11:21.573495.573495 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 17:11:21.573530.573530 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 17:11:21.573674.573674 cuda_h.py:19] end allocate_cuda_memory cost 0.0007009506225585938 seconds
DEBUG 01-06 17:11:21.574630.574630 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 17:11:21.574386.574386 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 17:11:21.574448.574448 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 17:11:21.574819.574819 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 45cafc0d-0771-417e-be28-fdb43a35b433
DEBUG 01-06 17:11:21.574398.574398 client.py:106] call stub.LoadModelAsync
DEBUG 01-06 17:11:21.574847.574847 mlpmodule.py:664]  experts func einsum cost 0.03574514389038086 s
DEBUG 01-06 17:11:21.574286.574286 mlpmodule.py:533] gpu group tensors cost 0.0019156932830810547 s
INFO 01-06 17:11:21.575061.575061 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 45cafc0d-0771-417e-be28-fdb43a35b433
DEBUG 01-06 17:11:21.575997.575997 cuda_h.py:19] end load_into_gpu_async cost 0.0016062259674072266 seconds
DEBUG 01-06 17:11:21.575554.575554 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 17:11:21.575226.575226 cuda_h.py:19] end restore_tensors2 cost 8.20159912109375e-05 seconds
DEBUG 01-06 17:11:21.575512.575512 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0026488304138183594 seconds
INFO 01-06 17:11:21.575501.575501 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 45cafc0d-0771-417e-be28-fdb43a35b433
DEBUG 01-06 17:11:21.576644.576644 mlpmodule.py:566] gpu pad cost 0.002046346664428711 s
DEBUG 01-06 17:11:21.577615.577615 mlpmodule.py:584] gpu group einsum cost 0.0004417896270751953 s
DEBUG 01-06 17:11:21.580547.580547 mlpmodule.py:613] gpu experts func einsum cost 0.007574558258056641 s
DEBUG 01-06 17:11:21.580942.580942 cuda_h.py:19] end gpu_experts cost 0.007734537124633789 seconds
DEBUG 01-06 17:11:21.580395.580395 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-06 17:11:21.580290.580290 lmp.py:661] 
DEBUG 01-06 17:11:21.580290.580290 lmp.py:661]   Computing 25 experts on CPU...
DEBUG 01-06 17:11:21.580319.580319 cuda_h.py:19] end cpu_experts_submit cost 5.5789947509765625e-05 seconds
DEBUG 01-06 17:11:21.580445.580445 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-06 17:11:21.584444.584444 mlpmodule.py:706] group tensors cost 0.0041294097900390625 s
INFO 01-06 17:11:21.585689.585689 client.py:127] Model loaded
DEBUG 01-06 17:11:21.586066.586066 cuda_h.py:19] end sllm_worker_task cost 0.013477563858032227 seconds
DEBUG 01-06 17:11:21.586466.586466 cuda_h.py:10] start sllm_worker_task
DEBUG 01-06 17:11:21.586421.586421 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 17:11:21.586257.586257 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 17:11:21.587762.587762 cuda_h.py:19] end allocate_cuda_memory cost 0.00019073486328125 seconds
DEBUG 01-06 17:11:21.587327.587327 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 17:11:21.587036.587036 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 17:11:21.587422.587422 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 17:11:21.587317.587317 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 73197223-73a5-4b22-8661-c204caa82b3e
DEBUG 01-06 17:11:21.587041.587041 client.py:106] call stub.LoadModelAsync
DEBUG 01-06 17:11:21.588898.588898 mlpmodule.py:744] pad cost 0.0028150081634521484 s
DEBUG 01-06 17:11:21.588856.588856 mlpmodule.py:750] create cpu tensor cost 4.76837158203125e-05 s
DEBUG 01-06 17:11:21.588766.588766 mlpmodule.py:755] move to cpu cost 3.4332275390625e-05 s
INFO 01-06 17:11:21.588836.588836 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 73197223-73a5-4b22-8661-c204caa82b3e
DEBUG 01-06 17:11:21.588211.588211 cuda_h.py:19] end load_into_gpu_async cost 0.001630544662475586 seconds
DEBUG 01-06 17:11:21.588642.588642 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 17:11:21.589712.589712 cuda_h.py:19] end restore_tensors2 cost 0.00020599365234375 seconds
DEBUG 01-06 17:11:21.589391.589391 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0024199485778808594 seconds
INFO 01-06 17:11:21.589138.589138 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 73197223-73a5-4b22-8661-c204caa82b3e
DEBUG 01-06 17:11:21.591734.591734 mlpmodule.py:769] group_w3: shape=torch.Size([25, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=72089600
DEBUG 01-06 17:11:21.592703.592703 mlpmodule.py:770] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-06 17:11:21.592546.592546 mlpmodule.py:775] group_w3 first element: -0.054931640625
WARNING 01-06 17:11:21.592252.592252 mlpmodule.py:785] start einsum2
DEBUG 01-06 17:11:21.597300.597300 mlpmodule.py:795] group einsum cost 0.008982181549072266 s
DEBUG 01-06 17:11:21.597299.597299 mlpmodule.py:803] cpy2cputensor cost 8.153915405273438e-05 s
INFO 01-06 17:11:21.599264.599264 client.py:127] Model loaded
DEBUG 01-06 17:11:21.600254.600254 cuda_h.py:19] end sllm_worker_task cost 0.014181375503540039 seconds
DEBUG 01-06 17:11:21.601225.601225 cuda_h.py:10] start sllm_worker_task
DEBUG 01-06 17:11:21.601332.601332 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 17:11:21.601812.601812 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 17:11:21.601018.601018 cuda_h.py:19] end allocate_cuda_memory cost 0.00038504600524902344 seconds
DEBUG 01-06 17:11:21.601041.601041 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 17:11:21.601526.601526 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 17:11:21.601746.601746 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 17:11:21.601986.601986 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 11231375-958a-45bf-818e-3f29a2229643
DEBUG 01-06 17:11:21.601712.601712 client.py:106] call stub.LoadModelAsync
INFO 01-06 17:11:21.603405.603405 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 11231375-958a-45bf-818e-3f29a2229643
DEBUG 01-06 17:11:21.603025.603025 cuda_h.py:19] end wait_cetm_experts cost 0.0229952335357666 seconds
DEBUG 01-06 17:11:21.603307.603307 cuda_h.py:19] end load_into_gpu_async cost 0.0019769668579101562 seconds
DEBUG 01-06 17:11:21.603039.603039 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 17:11:21.603044.603044 cuda_h.py:19] end restore_tensors2 cost 0.00011181831359863281 seconds
DEBUG 01-06 17:11:21.604549.604549 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.002864837646484375 seconds
INFO 01-06 17:11:21.604200.604200 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 11231375-958a-45bf-818e-3f29a2229643
DEBUG 01-06 17:11:21.604335.604335 cuda_h.py:19] end layer_moe_dgenerate_3 cost 0.03631401062011719 seconds
DEBUG 01-06 17:11:21.604892.604892 lmp.py:325] -------------------------------- end decode layer 3 --------------------------------
DEBUG 01-06 17:11:21.604774.604774 lmp.py:298] -------------------------------- start decode layer 4 --------------------------------
DEBUG 01-06 17:11:21.604054.604054 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-06 17:11:21.604831.604831 mlpmodule.py:367] cuda:1 cuda:1
DEBUG 01-06 17:11:21.604711.604711 cuda_h.py:10] start self_attn
cos shape torch.Size([65, 128]) sin shape torch.Size([65, 128]) position_ids tensor([[0]], device='cuda:1')
cos shape torch.Size([1, 1, 1, 128]) sin shape torch.Size([1, 1, 1, 128])
q_embed shape torch.Size([32, 16, 1, 128]) k_embed shape torch.Size([32, 16, 1, 128])
DEBUG 01-06 17:11:21.606133.606133 cuda_h.py:19] end self_attn cost 0.0018684864044189453 seconds
DEBUG 01-06 17:11:21.607998.607998 cuda_h.py:19] end iln_self_attn_paln cost 0.0026636123657226562 seconds
DEBUG 01-06 17:11:21.607642.607642 cuda_h.py:10] start layer_moe_dgenerate_4
DEBUG 01-06 17:11:21.607949.607949 cuda_h.py:10] start gate
DEBUG 01-06 17:11:21.607951.607951 cuda_h.py:19] end gate cost 0.0006296634674072266 seconds
DEBUG 01-06 17:11:21.607788.607788 cuda_h.py:10] start experts_map_get
INFO 01-06 17:11:21.608223.608223 lmp.py:611] using loaded check layer: False
INFO 01-06 17:11:21.608403.608403 lmp.py:620] 
INFO 01-06 17:11:21.608403.608403 lmp.py:620] Layer 4 Expert Device Distribution:
INFO 01-06 17:11:21.609789.609789 lmp.py:621]   Active experts: 55 (out of 64 total)
INFO 01-06 17:11:21.609776.609776 lmp.py:622] 
INFO 01-06 17:11:21.609776.609776 lmp.py:622]   Detailed Expert Distribution:
INFO 01-06 17:11:21.609671.609671 lmp.py:623]   Expert ID  | Tokens     | Actual Device  
INFO 01-06 17:11:21.609844.609844 lmp.py:624]   ----------------------------------------------------------------------
INFO 01-06 17:11:21.609924.609924 lmp.py:627]   4          | 1          |  meta           
INFO 01-06 17:11:21.609336.609336 lmp.py:627]   8          | 1          |  meta           
INFO 01-06 17:11:21.609224.609224 lmp.py:627]   9          | 1          |  cuda:1         
INFO 01-06 17:11:21.609350.609350 lmp.py:627]   13         | 1          |  meta           
INFO 01-06 17:11:21.609192.609192 lmp.py:627]   18         | 1          |  cuda:1         
INFO 01-06 17:11:21.609888.609888 lmp.py:627]   19         | 1          |  cuda:1         
INFO 01-06 17:11:21.609777.609777 lmp.py:627]   25         | 1          |  cuda:1         
INFO 01-06 17:11:21.609234.609234 lmp.py:627]   45         | 1          |  meta           
INFO 01-06 17:11:21.609122.609122 lmp.py:627]   46         | 1          |  cuda:1         
INFO 01-06 17:11:21.609819.609819 lmp.py:627]   54         | 1          |  meta           
INFO 01-06 17:11:21.609184.609184 lmp.py:627]   58         | 1          |  meta           
INFO 01-06 17:11:21.609833.609833 lmp.py:627]   60         | 1          |  meta           
INFO 01-06 17:11:21.609245.609245 lmp.py:627]   61         | 1          |  meta           
INFO 01-06 17:11:21.609179.609179 lmp.py:627]   10         | 2          |  meta           
INFO 01-06 17:11:21.609829.609829 lmp.py:627]   12         | 2          |  cuda:1         
INFO 01-06 17:11:21.609287.609287 lmp.py:627]   14         | 2          |  meta           
INFO 01-06 17:11:21.609175.609175 lmp.py:627]   16         | 2          |  meta           
INFO 01-06 17:11:21.609825.609825 lmp.py:627]   31         | 2          |  meta           
INFO 01-06 17:11:21.609474.609474 lmp.py:627]   34         | 2          |  meta           
INFO 01-06 17:11:21.609694.609694 lmp.py:627]   35         | 2          |  cuda:1         
INFO 01-06 17:11:21.609343.609343 lmp.py:627]   36         | 2          |  meta           
INFO 01-06 17:11:21.609324.609324 lmp.py:627]   40         | 2          |  cuda:1         
INFO 01-06 17:11:21.609497.609497 lmp.py:627]   43         | 2          |  cuda:1         
INFO 01-06 17:11:21.609955.609955 lmp.py:627]   47         | 2          |  meta           
INFO 01-06 17:11:21.609035.609035 lmp.py:627]   48         | 2          |  meta           
INFO 01-06 17:11:21.609162.609162 lmp.py:627]   49         | 2          |  cuda:1         
INFO 01-06 17:11:21.609811.609811 lmp.py:627]   52         | 2          |  cuda:1         
INFO 01-06 17:11:21.609508.609508 lmp.py:627]   53         | 2          |  meta           
INFO 01-06 17:11:21.609919.609919 lmp.py:627]   6          | 3          |  cuda:1         
INFO 01-06 17:11:21.609377.609377 lmp.py:627]   7          | 3          |  meta           
INFO 01-06 17:11:21.609980.609980 lmp.py:627]   23         | 3          |  cuda:1         
INFO 01-06 17:11:21.609915.609915 lmp.py:627]   26         | 3          |  meta           
INFO 01-06 17:11:21.609803.609803 lmp.py:627]   29         | 3          |  meta           
INFO 01-06 17:11:21.609022.609022 lmp.py:627]   30         | 3          |  meta           
INFO 01-06 17:11:21.609149.609149 lmp.py:627]   37         | 3          |  cuda:1         
INFO 01-06 17:11:21.609368.609368 lmp.py:627]   0          | 4          |  cuda:1         
INFO 01-06 17:11:21.609210.609210 lmp.py:627]   1          | 4          |  cuda:1         
INFO 01-06 17:11:21.609621.609621 lmp.py:627]   3          | 4          |  cuda:1         
INFO 01-06 17:11:21.609032.609032 lmp.py:627]   5          | 4          |  cuda:1         
INFO 01-06 17:11:21.609252.609252 lmp.py:627]   24         | 4          |  cuda:1         
INFO 01-06 17:11:21.610186.610186 lmp.py:627]   33         | 4          |  cuda:1         
INFO 01-06 17:11:21.610929.610929 lmp.py:627]   44         | 4          |  cuda:1         
INFO 01-06 17:11:21.610863.610863 lmp.py:627]   15         | 6          |  cuda:1         
INFO 01-06 17:11:21.610036.610036 lmp.py:627]   41         | 6          |  meta           
INFO 01-06 17:11:21.610401.610401 lmp.py:627]   55         | 6          |  cuda:1         
INFO 01-06 17:11:21.610382.610382 lmp.py:627]   27         | 7          |  meta           
INFO 01-06 17:11:21.610793.610793 lmp.py:627]   38         | 7          |  cuda:1         
INFO 01-06 17:11:21.610774.610774 lmp.py:627]   42         | 7          |  meta           
INFO 01-06 17:11:21.610901.610901 lmp.py:627]   59         | 7          |  cuda:1         
INFO 01-06 17:11:21.610312.610312 lmp.py:627]   62         | 7          |  cuda:1         
INFO 01-06 17:11:21.610439.610439 lmp.py:627]   17         | 8          |  meta           
INFO 01-06 17:11:21.610658.610658 lmp.py:627]   22         | 8          |  cuda:1         
INFO 01-06 17:11:21.610592.610592 lmp.py:627]   21         | 9          |  cuda:1         
INFO 01-06 17:11:21.610812.610812 lmp.py:627]   39         | 10         |  cuda:1         
INFO 01-06 17:11:21.610223.610223 lmp.py:627]   50         | 12         |  cuda:1         
INFO 01-06 17:11:21.610727.610727 lmp.py:628] ============================================================
INFO 01-06 17:11:21.610727.610727 lmp.py:628] 
INFO 01-06 17:11:21.610860.610860 lmp.py:630] experts_gpu_list: [9, 18, 19, 25, 46, 12, 35, 40, 43, 49, 52, 6, 23, 37, 0, 1, 3, 5, 24, 33, 44, 15, 55, 38, 59, 62, 22, 21, 39, 50] num: 30
INFO 01-06 17:11:21.610133.610133 lmp.py:631] experts_cpu_list: [4, 8, 13, 45, 54, 58, 60, 61, 10, 14, 16, 31, 34, 36, 47, 48, 53, 7, 26, 29, 30, 41, 27, 42, 17] num: 25
INFO 01-06 17:11:21.610187.610187 lmp.py:632] expert_actual_device_map {0: 'cuda:1', 1: 'cuda:1', 2: 'cuda:1', 3: 'cuda:1', 4: 'meta', 5: 'cuda:1', 6: 'cuda:1', 7: 'meta', 8: 'meta', 9: 'cuda:1', 10: 'meta', 11: 'meta', 12: 'cuda:1', 13: 'meta', 14: 'meta', 15: 'cuda:1', 16: 'meta', 17: 'meta', 18: 'cuda:1', 19: 'cuda:1', 20: 'meta', 21: 'cuda:1', 22: 'cuda:1', 23: 'cuda:1', 24: 'cuda:1', 25: 'cuda:1', 26: 'meta', 27: 'meta', 28: 'meta', 29: 'meta', 30: 'meta', 31: 'meta', 32: 'meta', 33: 'cuda:1', 34: 'meta', 35: 'cuda:1', 36: 'meta', 37: 'cuda:1', 38: 'cuda:1', 39: 'cuda:1', 40: 'cuda:1', 41: 'meta', 42: 'meta', 43: 'cuda:1', 44: 'cuda:1', 45: 'meta', 46: 'cuda:1', 47: 'meta', 48: 'meta', 49: 'cuda:1', 50: 'cuda:1', 51: 'meta', 52: 'cuda:1', 53: 'meta', 54: 'meta', 55: 'cuda:1', 56: 'cuda:1', 57: 'meta', 58: 'meta', 59: 'cuda:1', 60: 'meta', 61: 'meta', 62: 'cuda:1', 63: 'meta'}
DEBUG 01-06 17:11:21.610804.610804 cuda_h.py:19] end experts_map_get cost 0.0024368762969970703 seconds
DEBUG 01-06 17:11:21.610588.610588 cuda_h.py:10] start gpu_sexperts
DEBUG 01-06 17:11:21.610422.610422 cuda_h.py:19] end gpu_sexperts cost 0.00032448768615722656 seconds
DEBUG 01-06 17:11:21.610344.610344 cuda_h.py:10] start gpu_experts
DEBUG 01-06 17:11:21.611877.611877 mlpmodule.py:533] gpu group tensors cost 0.0006010532379150391 s
INFO 01-06 17:11:21.612537.612537 client.py:127] Model loaded
DEBUG 01-06 17:11:21.613802.613802 mlpmodule.py:664]  experts func einsum cost 0.03243422508239746 s
DEBUG 01-06 17:11:21.614483.614483 cuda_h.py:19] end sllm_worker_task cost 0.01319432258605957 seconds
DEBUG 01-06 17:11:21.614010.614010 cuda_h.py:10] start sllm_worker_task
DEBUG 01-06 17:11:21.614203.614203 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 17:11:21.614510.614510 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 17:11:21.614015.614015 cuda_h.py:19] end allocate_cuda_memory cost 0.00023031234741210938 seconds
DEBUG 01-06 17:11:21.614290.614290 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 17:11:21.614530.614530 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 17:11:21.614677.614677 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 17:11:21.614188.614188 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, fca144ad-235b-42bf-a5b6-71314675478e
DEBUG 01-06 17:11:21.615727.615727 client.py:106] call stub.LoadModelAsync
DEBUG 01-06 17:11:21.615481.615481 mlpmodule.py:566] gpu pad cost 0.0037641525268554688 s
DEBUG 01-06 17:11:21.615956.615956 mlpmodule.py:584] gpu group einsum cost 0.0004470348358154297 s
INFO 01-06 17:11:21.616249.616249 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, fca144ad-235b-42bf-a5b6-71314675478e
DEBUG 01-06 17:11:21.616086.616086 cuda_h.py:19] end load_into_gpu_async cost 0.0015676021575927734 seconds
DEBUG 01-06 17:11:21.616643.616643 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 17:11:21.616394.616394 cuda_h.py:19] end restore_tensors2 cost 7.200241088867188e-05 seconds
DEBUG 01-06 17:11:21.616197.616197 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0021467208862304688 seconds
INFO 01-06 17:11:21.616563.616563 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, fca144ad-235b-42bf-a5b6-71314675478e
DEBUG 01-06 17:11:21.619975.619975 mlpmodule.py:613] gpu experts func einsum cost 0.008079051971435547 s
DEBUG 01-06 17:11:21.619111.619111 cuda_h.py:19] end gpu_experts cost 0.008224964141845703 seconds
DEBUG 01-06 17:11:21.619012.619012 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-06 17:11:21.619477.619477 lmp.py:661] 
DEBUG 01-06 17:11:21.619477.619477 lmp.py:661]   Computing 25 experts on CPU...
DEBUG 01-06 17:11:21.619359.619359 cuda_h.py:19] end cpu_experts_submit cost 5.364418029785156e-05 seconds
DEBUG 01-06 17:11:21.619486.619486 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-06 17:11:21.623710.623710 mlpmodule.py:706] group tensors cost 0.004133701324462891 s
INFO 01-06 17:11:21.625422.625422 client.py:127] Model loaded
DEBUG 01-06 17:11:21.626877.626877 cuda_h.py:19] end sllm_worker_task cost 0.01179647445678711 seconds
DEBUG 01-06 17:11:21.626780.626780 cuda_h.py:10] start sllm_worker_task
DEBUG 01-06 17:11:21.626827.626827 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 17:11:21.626610.626610 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 17:11:21.626427.626427 cuda_h.py:19] end allocate_cuda_memory cost 0.00021576881408691406 seconds
DEBUG 01-06 17:11:21.626270.626270 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 17:11:21.626741.626741 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 17:11:21.626603.626603 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 17:11:21.626399.626399 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 19761245-1657-4d7d-aff1-101302851699
DEBUG 01-06 17:11:21.626686.626686 client.py:106] call stub.LoadModelAsync
DEBUG 01-06 17:11:21.627745.627745 mlpmodule.py:744] pad cost 0.002857208251953125 s
DEBUG 01-06 17:11:21.627035.627035 mlpmodule.py:750] create cpu tensor cost 4.410743713378906e-05 s
DEBUG 01-06 17:11:21.627461.627461 mlpmodule.py:755] move to cpu cost 3.147125244140625e-05 s
INFO 01-06 17:11:21.628513.628513 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 19761245-1657-4d7d-aff1-101302851699
DEBUG 01-06 17:11:21.629257.629257 cuda_h.py:19] end load_into_gpu_async cost 0.0023200511932373047 seconds
DEBUG 01-06 17:11:21.629425.629425 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 17:11:21.629413.629413 cuda_h.py:19] end restore_tensors2 cost 0.00017499923706054688 seconds
DEBUG 01-06 17:11:21.629038.629038 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0031080245971679688 seconds
INFO 01-06 17:11:21.629286.629286 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 19761245-1657-4d7d-aff1-101302851699
DEBUG 01-06 17:11:21.630227.630227 mlpmodule.py:769] group_w3: shape=torch.Size([25, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=72089600
DEBUG 01-06 17:11:21.630872.630872 mlpmodule.py:770] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-06 17:11:21.630987.630987 mlpmodule.py:775] group_w3 first element: 0.0086669921875
WARNING 01-06 17:11:21.630918.630918 mlpmodule.py:785] start einsum2
DEBUG 01-06 17:11:21.636512.636512 mlpmodule.py:795] group einsum cost 0.009574651718139648 s
DEBUG 01-06 17:11:21.637790.637790 mlpmodule.py:803] cpy2cputensor cost 0.00011157989501953125 s
INFO 01-06 17:11:21.639931.639931 client.py:127] Model loaded
DEBUG 01-06 17:11:21.640295.640295 cuda_h.py:19] end sllm_worker_task cost 0.014333724975585938 seconds
DEBUG 01-06 17:11:21.640073.640073 cuda_h.py:10] start sllm_worker_task
DEBUG 01-06 17:11:21.640373.640373 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 17:11:21.640130.640130 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 17:11:21.641059.641059 cuda_h.py:19] end allocate_cuda_memory cost 0.00039458274841308594 seconds
DEBUG 01-06 17:11:21.641360.641360 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 17:11:21.641699.641699 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 17:11:21.641965.641965 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 17:11:21.641582.641582 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, e651213a-492a-4c96-aa45-762794c2ccc4
DEBUG 01-06 17:11:21.641970.641970 client.py:106] call stub.LoadModelAsync
DEBUG 01-06 17:11:21.642514.642514 cuda_h.py:19] end wait_cetm_experts cost 0.023531198501586914 seconds
INFO 01-06 17:11:21.643495.643495 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, e651213a-492a-4c96-aa45-762794c2ccc4
DEBUG 01-06 17:11:21.643352.643352 cuda_h.py:19] end load_into_gpu_async cost 0.0017104148864746094 seconds
DEBUG 01-06 17:11:21.643108.643108 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 17:11:21.643914.643914 cuda_h.py:19] end restore_tensors2 cost 0.00010967254638671875 seconds
DEBUG 01-06 17:11:21.643723.643723 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0025093555450439453 seconds
DEBUG 01-06 17:11:21.643566.643566 cuda_h.py:19] end layer_moe_dgenerate_4 cost 0.03624129295349121 seconds
INFO 01-06 17:11:21.643650.643650 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, e651213a-492a-4c96-aa45-762794c2ccc4
DEBUG 01-06 17:11:21.643227.643227 lmp.py:325] -------------------------------- end decode layer 4 --------------------------------
DEBUG 01-06 17:11:21.643917.643917 lmp.py:298] -------------------------------- start decode layer 5 --------------------------------
DEBUG 01-06 17:11:21.643905.643905 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-06 17:11:21.644060.644060 mlpmodule.py:367] cuda:1 cuda:1
DEBUG 01-06 17:11:21.644027.644027 cuda_h.py:10] start self_attn
cos shape torch.Size([65, 128]) sin shape torch.Size([65, 128]) position_ids tensor([[0]], device='cuda:1')
cos shape torch.Size([1, 1, 1, 128]) sin shape torch.Size([1, 1, 1, 128])
q_embed shape torch.Size([32, 16, 1, 128]) k_embed shape torch.Size([32, 16, 1, 128])
DEBUG 01-06 17:11:21.646113.646113 cuda_h.py:19] end self_attn cost 0.00191497802734375 seconds
DEBUG 01-06 17:11:21.646654.646654 cuda_h.py:19] end iln_self_attn_paln cost 0.0027647018432617188 seconds
DEBUG 01-06 17:11:21.646014.646014 cuda_h.py:10] start layer_moe_dgenerate_5
DEBUG 01-06 17:11:21.646260.646260 cuda_h.py:10] start gate
DEBUG 01-06 17:11:21.647660.647660 cuda_h.py:19] end gate cost 0.0006415843963623047 seconds
DEBUG 01-06 17:11:21.647543.647543 cuda_h.py:10] start experts_map_get
INFO 01-06 17:11:21.647999.647999 lmp.py:611] using loaded check layer: False
INFO 01-06 17:11:21.648476.648476 lmp.py:620] 
INFO 01-06 17:11:21.648476.648476 lmp.py:620] Layer 5 Expert Device Distribution:
INFO 01-06 17:11:21.648769.648769 lmp.py:621]   Active experts: 58 (out of 64 total)
INFO 01-06 17:11:21.648472.648472 lmp.py:622] 
INFO 01-06 17:11:21.648472.648472 lmp.py:622]   Detailed Expert Distribution:
INFO 01-06 17:11:21.648128.648128 lmp.py:623]   Expert ID  | Tokens     | Actual Device  
INFO 01-06 17:11:21.648255.648255 lmp.py:624]   ----------------------------------------------------------------------
INFO 01-06 17:11:21.648812.648812 lmp.py:627]   3          | 1          |  meta           
INFO 01-06 17:11:21.648177.648177 lmp.py:627]   26         | 1          |  cuda:1         
INFO 01-06 17:11:21.648542.648542 lmp.py:627]   27         | 1          |  cuda:1         
INFO 01-06 17:11:21.648384.648384 lmp.py:627]   29         | 1          |  cuda:1         
INFO 01-06 17:11:21.648749.648749 lmp.py:627]   35         | 1          |  meta           
INFO 01-06 17:11:21.648637.648637 lmp.py:627]   36         | 1          |  meta           
INFO 01-06 17:11:21.648525.648525 lmp.py:627]   37         | 1          |  cuda:1         
INFO 01-06 17:11:21.648460.648460 lmp.py:627]   41         | 1          |  cuda:1         
INFO 01-06 17:11:21.648586.648586 lmp.py:627]   51         | 1          |  cuda:1         
INFO 01-06 17:11:21.648951.648951 lmp.py:627]   54         | 1          |  cuda:1         
INFO 01-06 17:11:21.648793.648793 lmp.py:627]   0          | 2          |  meta           
INFO 01-06 17:11:21.648920.648920 lmp.py:627]   6          | 2          |  cuda:1         
INFO 01-06 17:11:21.648808.648808 lmp.py:627]   11         | 2          |  cuda:1         
INFO 01-06 17:11:21.648219.648219 lmp.py:627]   13         | 2          |  meta           
INFO 01-06 17:11:21.648631.648631 lmp.py:627]   15         | 2          |  meta           
INFO 01-06 17:11:21.649711.649711 lmp.py:627]   16         | 2          |  meta           
INFO 01-06 17:11:21.649553.649553 lmp.py:627]   18         | 2          |  cuda:1         
INFO 01-06 17:11:21.649441.649441 lmp.py:627]   21         | 2          |  cuda:1         
INFO 01-06 17:11:21.649091.649091 lmp.py:627]   24         | 2          |  cuda:1         
INFO 01-06 17:11:21.649694.649694 lmp.py:627]   38         | 2          |  cuda:1         
INFO 01-06 17:11:21.649867.649867 lmp.py:627]   39         | 2          |  meta           
INFO 01-06 17:11:21.649709.649709 lmp.py:627]   45         | 2          |  meta           
INFO 01-06 17:11:21.649074.649074 lmp.py:627]   47         | 2          |  cuda:1         
INFO 01-06 17:11:21.649439.649439 lmp.py:627]   49         | 2          |  cuda:1         
INFO 01-06 17:11:21.649373.649373 lmp.py:627]   52         | 2          |  meta           
INFO 01-06 17:11:21.649798.649798 lmp.py:627]   58         | 2          |  cuda:1         
INFO 01-06 17:11:21.649448.649448 lmp.py:627]   59         | 2          |  cuda:1         
INFO 01-06 17:11:21.649575.649575 lmp.py:627]   62         | 2          |  cuda:1         
INFO 01-06 17:11:21.649986.649986 lmp.py:627]   63         | 2          |  cuda:1         
INFO 01-06 17:11:21.649113.649113 lmp.py:627]   2          | 3          |  meta           
INFO 01-06 17:11:21.649001.649001 lmp.py:627]   14         | 3          |  meta           
INFO 01-06 17:11:21.649889.649889 lmp.py:627]   23         | 3          |  meta           
INFO 01-06 17:11:21.649824.649824 lmp.py:627]   25         | 3          |  meta           
INFO 01-06 17:11:21.649712.649712 lmp.py:627]   40         | 3          |  cuda:1         
INFO 01-06 17:11:21.649077.649077 lmp.py:627]   42         | 3          |  meta           
INFO 01-06 17:11:21.649488.649488 lmp.py:627]   43         | 3          |  cuda:1         
INFO 01-06 17:11:21.649138.649138 lmp.py:627]   55         | 3          |  cuda:1         
INFO 01-06 17:11:21.649549.649549 lmp.py:627]   5          | 4          |  meta           
INFO 01-06 17:11:21.649484.649484 lmp.py:627]   8          | 4          |  meta           
INFO 01-06 17:11:21.649134.649134 lmp.py:627]   9          | 4          |  meta           
INFO 01-06 17:11:21.649022.649022 lmp.py:627]   10         | 4          |  cuda:1         
INFO 01-06 17:11:21.649625.649625 lmp.py:627]   12         | 4          |  meta           
INFO 01-06 17:11:21.649036.649036 lmp.py:627]   17         | 4          |  meta           
INFO 01-06 17:11:21.649686.649686 lmp.py:627]   30         | 4          |  meta           
INFO 01-06 17:11:21.649098.649098 lmp.py:627]   32         | 4          |  meta           
INFO 01-06 17:11:21.649271.649271 lmp.py:627]   44         | 4          |  meta           
INFO 01-06 17:11:21.649397.649397 lmp.py:627]   46         | 4          |  meta           
INFO 01-06 17:11:21.649285.649285 lmp.py:627]   57         | 4          |  meta           
INFO 01-06 17:11:21.649697.649697 lmp.py:627]   60         | 4          |  meta           
INFO 01-06 17:11:21.649631.649631 lmp.py:627]   7          | 5          |  cuda:1         
INFO 01-06 17:11:21.649566.649566 lmp.py:627]   28         | 5          |  meta           
INFO 01-06 17:11:21.649215.649215 lmp.py:627]   1          | 6          |  cuda:1         
INFO 01-06 17:11:21.649819.649819 lmp.py:627]   56         | 6          |  cuda:1         
INFO 01-06 17:11:21.649422.649422 lmp.py:627]   61         | 7          |  meta           
INFO 01-06 17:11:21.649357.649357 lmp.py:627]   19         | 8          |  cuda:1         
INFO 01-06 17:11:21.649768.649768 lmp.py:627]   33         | 9          |  cuda:1         
INFO 01-06 17:11:21.649180.649180 lmp.py:627]   48         | 12         |  cuda:1         
INFO 01-06 17:11:21.649829.649829 lmp.py:627]   53         | 14         |  cuda:1         
INFO 01-06 17:11:21.650525.650525 lmp.py:628] ============================================================
INFO 01-06 17:11:21.650525.650525 lmp.py:628] 
INFO 01-06 17:11:21.650659.650659 lmp.py:630] experts_gpu_list: [26, 27, 29, 37, 41, 51, 54, 6, 11, 18, 21, 24, 38, 47, 49, 58, 59, 62, 63, 40, 43, 55, 10, 7, 1, 56, 19, 33, 48, 53] num: 30
INFO 01-06 17:11:21.650693.650693 lmp.py:631] experts_cpu_list: [3, 35, 36, 0, 13, 15, 16, 39, 45, 52, 2, 14, 23, 25, 42, 5, 8, 9, 12, 17, 30, 32, 44, 46, 57, 60, 28, 61] num: 28
INFO 01-06 17:11:21.650793.650793 lmp.py:632] expert_actual_device_map {0: 'meta', 1: 'cuda:1', 2: 'meta', 3: 'meta', 4: 'meta', 5: 'meta', 6: 'cuda:1', 7: 'cuda:1', 8: 'meta', 9: 'meta', 10: 'cuda:1', 11: 'cuda:1', 12: 'meta', 13: 'meta', 14: 'meta', 15: 'meta', 16: 'meta', 17: 'meta', 18: 'cuda:1', 19: 'cuda:1', 20: 'cuda:1', 21: 'cuda:1', 22: 'meta', 23: 'meta', 24: 'cuda:1', 25: 'meta', 26: 'cuda:1', 27: 'cuda:1', 28: 'meta', 29: 'cuda:1', 30: 'meta', 31: 'meta', 32: 'meta', 33: 'cuda:1', 34: 'meta', 35: 'meta', 36: 'meta', 37: 'cuda:1', 38: 'cuda:1', 39: 'meta', 40: 'cuda:1', 41: 'cuda:1', 42: 'meta', 43: 'cuda:1', 44: 'meta', 45: 'meta', 46: 'meta', 47: 'cuda:1', 48: 'cuda:1', 49: 'cuda:1', 50: 'cuda:1', 51: 'cuda:1', 52: 'meta', 53: 'cuda:1', 54: 'cuda:1', 55: 'cuda:1', 56: 'cuda:1', 57: 'meta', 58: 'cuda:1', 59: 'cuda:1', 60: 'meta', 61: 'meta', 62: 'cuda:1', 63: 'cuda:1'}
DEBUG 01-06 17:11:21.650364.650364 cuda_h.py:19] end experts_map_get cost 0.002538919448852539 seconds
DEBUG 01-06 17:11:21.650341.650341 cuda_h.py:10] start gpu_sexperts
DEBUG 01-06 17:11:21.650936.650936 cuda_h.py:19] end gpu_sexperts cost 0.00032329559326171875 seconds
DEBUG 01-06 17:11:21.650335.650335 cuda_h.py:10] start gpu_experts
DEBUG 01-06 17:11:21.651893.651893 mlpmodule.py:533] gpu group tensors cost 0.0005829334259033203 s
INFO 01-06 17:11:21.652061.652061 client.py:127] Model loaded
DEBUG 01-06 17:11:21.652543.652543 mlpmodule.py:664]  experts func einsum cost 0.03338193893432617 s
DEBUG 01-06 17:11:21.653602.653602 cuda_h.py:19] end sllm_worker_task cost 0.01255178451538086 seconds
DEBUG 01-06 17:11:21.653837.653837 cuda_h.py:10] start sllm_worker_task
DEBUG 01-06 17:11:21.653215.653215 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 17:11:21.653475.653475 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 17:11:21.653510.653510 cuda_h.py:19] end allocate_cuda_memory cost 0.0002028942108154297 seconds
DEBUG 01-06 17:11:21.653353.653353 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 17:11:21.653917.653917 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 17:11:21.654487.654487 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 17:11:21.654852.654852 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 19cff93f-a309-4ffe-a839-c2cfab7113c3
DEBUG 01-06 17:11:21.654001.654001 client.py:106] call stub.LoadModelAsync
DEBUG 01-06 17:11:21.654093.654093 mlpmodule.py:566] gpu pad cost 0.0031499862670898438 s
DEBUG 01-06 17:11:21.655640.655640 mlpmodule.py:584] gpu group einsum cost 0.0004353523254394531 s
INFO 01-06 17:11:21.655694.655694 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 19cff93f-a309-4ffe-a839-c2cfab7113c3
DEBUG 01-06 17:11:21.655192.655192 cuda_h.py:19] end load_into_gpu_async cost 0.0015006065368652344 seconds
DEBUG 01-06 17:11:21.655273.655273 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 17:11:21.655547.655547 cuda_h.py:19] end restore_tensors2 cost 7.05718994140625e-05 seconds
DEBUG 01-06 17:11:21.655310.655310 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0020110607147216797 seconds
INFO 01-06 17:11:21.655822.655822 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 19cff93f-a309-4ffe-a839-c2cfab7113c3
DEBUG 01-06 17:11:21.658147.658147 mlpmodule.py:613] gpu experts func einsum cost 0.007369518280029297 s
DEBUG 01-06 17:11:21.658250.658250 cuda_h.py:19] end gpu_experts cost 0.007526397705078125 seconds
DEBUG 01-06 17:11:21.658774.658774 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-06 17:11:21.658477.658477 lmp.py:661] 
DEBUG 01-06 17:11:21.658477.658477 lmp.py:661]   Computing 28 experts on CPU...
DEBUG 01-06 17:11:21.658121.658121 cuda_h.py:19] end cpu_experts_submit cost 5.364418029785156e-05 seconds
DEBUG 01-06 17:11:21.658917.658917 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-06 17:11:21.666397.666397 mlpmodule.py:706] group tensors cost 0.008438587188720703 s
INFO 01-06 17:11:21.667471.667471 client.py:127] Model loaded
DEBUG 01-06 17:11:21.668518.668518 cuda_h.py:19] end sllm_worker_task cost 0.015349149703979492 seconds
DEBUG 01-06 17:11:21.669765.669765 cuda_h.py:10] start sllm_worker_task
DEBUG 01-06 17:11:21.669051.669051 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 17:11:21.669404.669404 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 17:11:21.669100.669100 cuda_h.py:19] end allocate_cuda_memory cost 0.0001983642578125 seconds
DEBUG 01-06 17:11:21.669276.669276 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 17:11:21.669515.669515 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 17:11:21.669662.669662 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 17:11:21.669173.669173 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 94178b42-f5f5-4483-81e3-0d75633003a8
DEBUG 01-06 17:11:21.669507.669507 client.py:106] call stub.LoadModelAsync
DEBUG 01-06 17:11:21.670029.670029 mlpmodule.py:744] pad cost 0.0032019615173339844 s
DEBUG 01-06 17:11:21.670828.670828 mlpmodule.py:750] create cpu tensor cost 4.410743713378906e-05 s
INFO 01-06 17:11:21.671626.671626 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 94178b42-f5f5-4483-81e3-0d75633003a8
DEBUG 01-06 17:11:21.671463.671463 mlpmodule.py:755] move to cpu cost 0.0001423358917236328 s
DEBUG 01-06 17:11:21.671493.671493 cuda_h.py:19] end load_into_gpu_async cost 0.0016903877258300781 seconds
DEBUG 01-06 17:11:21.671623.671623 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 17:11:21.671501.671501 cuda_h.py:19] end restore_tensors2 cost 8.20159912109375e-05 seconds
DEBUG 01-06 17:11:21.671172.671172 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.002377748489379883 seconds
INFO 01-06 17:11:21.671802.671802 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 94178b42-f5f5-4483-81e3-0d75633003a8
DEBUG 01-06 17:11:21.675522.675522 mlpmodule.py:769] group_w3: shape=torch.Size([28, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=80740352
DEBUG 01-06 17:11:21.675307.675307 mlpmodule.py:770] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-06 17:11:21.675415.675415 mlpmodule.py:775] group_w3 first element: -0.046142578125
WARNING 01-06 17:11:21.675234.675234 mlpmodule.py:785] start einsum2
DEBUG 01-06 17:11:21.682951.682951 mlpmodule.py:795] group einsum cost 0.011043071746826172 s
INFO 01-06 17:11:21.682529.682529 client.py:127] Model loaded
DEBUG 01-06 17:11:21.682039.682039 mlpmodule.py:803] cpy2cputensor cost 0.00019168853759765625 s
DEBUG 01-06 17:11:21.683955.683955 cuda_h.py:19] end sllm_worker_task cost 0.014892339706420898 seconds
DEBUG 01-06 17:11:21.684827.684827 cuda_h.py:10] start sllm_worker_task
DEBUG 01-06 17:11:21.684511.684511 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 17:11:21.684514.684514 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 17:11:21.684569.684569 cuda_h.py:19] end allocate_cuda_memory cost 0.00041365623474121094 seconds
DEBUG 01-06 17:11:21.684301.684301 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 17:11:21.684124.684124 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 17:11:21.684398.684398 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 17:11:21.684160.684160 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, e0265744-19ea-4413-be39-d488f2a81710
DEBUG 01-06 17:11:21.685085.685085 client.py:106] call stub.LoadModelAsync
INFO 01-06 17:11:21.686378.686378 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, e0265744-19ea-4413-be39-d488f2a81710
DEBUG 01-06 17:11:21.686997.686997 cuda_h.py:19] end load_into_gpu_async cost 0.0017321109771728516 seconds
DEBUG 01-06 17:11:21.686945.686945 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 17:11:21.686857.686857 cuda_h.py:19] end restore_tensors2 cost 0.00011467933654785156 seconds
DEBUG 01-06 17:11:21.686911.686911 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.002614736557006836 seconds
INFO 01-06 17:11:21.686013.686013 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, e0265744-19ea-4413-be39-d488f2a81710
DEBUG 01-06 17:11:21.689393.689393 cuda_h.py:19] end wait_cetm_experts cost 0.030780315399169922 seconds
DEBUG 01-06 17:11:21.689648.689648 cuda_h.py:19] end layer_moe_dgenerate_5 cost 0.04263424873352051 seconds
DEBUG 01-06 17:11:21.689772.689772 lmp.py:325] -------------------------------- end decode layer 5 --------------------------------
DEBUG 01-06 17:11:21.689111.689111 lmp.py:298] -------------------------------- start decode layer 6 --------------------------------
DEBUG 01-06 17:11:21.689622.689622 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-06 17:11:21.689261.689261 mlpmodule.py:367] cuda:1 cuda:1
DEBUG 01-06 17:11:21.690671.690671 cuda_h.py:10] start self_attn
cos shape torch.Size([65, 128]) sin shape torch.Size([65, 128]) position_ids tensor([[0]], device='cuda:1')
cos shape torch.Size([1, 1, 1, 128]) sin shape torch.Size([1, 1, 1, 128])
q_embed shape torch.Size([32, 16, 1, 128]) k_embed shape torch.Size([32, 16, 1, 128])
DEBUG 01-06 17:11:21.692756.692756 cuda_h.py:19] end self_attn cost 0.0018985271453857422 seconds
DEBUG 01-06 17:11:21.692689.692689 cuda_h.py:19] end iln_self_attn_paln cost 0.0027518272399902344 seconds
DEBUG 01-06 17:11:21.692909.692909 cuda_h.py:10] start layer_moe_dgenerate_6
DEBUG 01-06 17:11:21.692633.692633 cuda_h.py:10] start gate
DEBUG 01-06 17:11:21.693709.693709 cuda_h.py:19] end gate cost 0.0006475448608398438 seconds
DEBUG 01-06 17:11:21.693830.693830 cuda_h.py:10] start experts_map_get
INFO 01-06 17:11:21.693756.693756 lmp.py:611] using loaded check layer: False
INFO 01-06 17:11:21.694113.694113 lmp.py:620] 
INFO 01-06 17:11:21.694113.694113 lmp.py:620] Layer 6 Expert Device Distribution:
INFO 01-06 17:11:21.694306.694306 lmp.py:621]   Active experts: 55 (out of 64 total)
INFO 01-06 17:11:21.694340.694340 lmp.py:622] 
INFO 01-06 17:11:21.694340.694340 lmp.py:622]   Detailed Expert Distribution:
INFO 01-06 17:11:21.694090.694090 lmp.py:623]   Expert ID  | Tokens     | Actual Device  
INFO 01-06 17:11:21.694739.694739 lmp.py:624]   ----------------------------------------------------------------------
INFO 01-06 17:11:21.694104.694104 lmp.py:627]   1          | 1          |  meta           
INFO 01-06 17:11:21.694277.694277 lmp.py:627]   3          | 1          |  meta           
INFO 01-06 17:11:21.694973.694973 lmp.py:627]   4          | 1          |  cuda:1         
INFO 01-06 17:11:21.694431.694431 lmp.py:627]   9          | 1          |  meta           
INFO 01-06 17:11:21.694319.694319 lmp.py:627]   14         | 1          |  meta           
INFO 01-06 17:11:21.694777.694777 lmp.py:627]   20         | 1          |  cuda:1         
INFO 01-06 17:11:21.694996.694996 lmp.py:627]   23         | 1          |  meta           
INFO 01-06 17:11:21.694977.694977 lmp.py:627]   26         | 1          |  meta           
INFO 01-06 17:11:21.694673.694673 lmp.py:627]   41         | 1          |  cuda:1         
INFO 01-06 17:11:21.694654.694654 lmp.py:627]   42         | 1          |  cuda:1         
INFO 01-06 17:11:21.694065.694065 lmp.py:627]   50         | 1          |  cuda:1         
INFO 01-06 17:11:21.694238.694238 lmp.py:627]   53         | 1          |  meta           
INFO 01-06 17:11:21.694934.694934 lmp.py:627]   59         | 1          |  meta           
INFO 01-06 17:11:21.694392.694392 lmp.py:627]   0          | 2          |  meta           
INFO 01-06 17:11:21.694611.694611 lmp.py:627]   2          | 2          |  meta           
INFO 01-06 17:11:21.694592.694592 lmp.py:627]   7          | 2          |  meta           
INFO 01-06 17:11:21.694573.694573 lmp.py:627]   10         | 2          |  meta           
INFO 01-06 17:11:21.694507.694507 lmp.py:627]   15         | 2          |  cuda:1         
INFO 01-06 17:11:21.694919.694919 lmp.py:627]   17         | 2          |  meta           
INFO 01-06 17:11:21.694138.694138 lmp.py:627]   18         | 2          |  meta           
INFO 01-06 17:11:21.694265.694265 lmp.py:627]   19         | 2          |  cuda:1         
INFO 01-06 17:11:21.694961.694961 lmp.py:627]   34         | 2          |  cuda:1         
INFO 01-06 17:11:21.694041.694041 lmp.py:627]   35         | 2          |  cuda:1         
INFO 01-06 17:11:21.694644.694644 lmp.py:627]   40         | 2          |  meta           
INFO 01-06 17:11:21.694579.694579 lmp.py:627]   46         | 2          |  cuda:1         
INFO 01-06 17:11:21.694560.694560 lmp.py:627]   52         | 2          |  cuda:1         
INFO 01-06 17:11:21.694541.694541 lmp.py:627]   54         | 2          |  meta           
INFO 01-06 17:11:21.694283.694283 lmp.py:627]   57         | 2          |  cuda:1         
INFO 01-06 17:11:21.694502.694502 lmp.py:627]   6          | 3          |  cuda:1         
INFO 01-06 17:11:21.695483.695483 lmp.py:627]   11         | 3          |  meta           
INFO 01-06 17:11:21.695179.695179 lmp.py:627]   21         | 3          |  cuda:1         
INFO 01-06 17:11:21.695591.695591 lmp.py:627]   24         | 3          |  cuda:1         
INFO 01-06 17:11:21.695810.695810 lmp.py:627]   33         | 3          |  meta           
INFO 01-06 17:11:21.695791.695791 lmp.py:627]   43         | 3          |  meta           
INFO 01-06 17:11:21.695771.695771 lmp.py:627]   47         | 3          |  cuda:1         
INFO 01-06 17:11:21.695752.695752 lmp.py:627]   49         | 3          |  cuda:1         
INFO 01-06 17:11:21.695972.695972 lmp.py:627]   55         | 3          |  meta           
INFO 01-06 17:11:21.695668.695668 lmp.py:627]   13         | 4          |  meta           
INFO 01-06 17:11:21.695364.695364 lmp.py:627]   27         | 4          |  cuda:1         
INFO 01-06 17:11:21.695345.695345 lmp.py:627]   44         | 4          |  cuda:1         
INFO 01-06 17:11:21.695325.695325 lmp.py:627]   51         | 4          |  meta           
INFO 01-06 17:11:21.695783.695783 lmp.py:627]   60         | 4          |  cuda:1         
INFO 01-06 17:11:21.695718.695718 lmp.py:627]   62         | 4          |  meta           
INFO 01-06 17:11:21.695937.695937 lmp.py:627]   63         | 4          |  meta           
INFO 01-06 17:11:21.695394.695394 lmp.py:627]   61         | 5          |  cuda:1         
INFO 01-06 17:11:21.695852.695852 lmp.py:627]   5          | 6          |  cuda:1         
INFO 01-06 17:11:21.695595.695595 lmp.py:627]   56         | 6          |  cuda:1         
INFO 01-06 17:11:21.695052.695052 lmp.py:627]   22         | 7          |  meta           
INFO 01-06 17:11:21.695464.695464 lmp.py:627]   28         | 7          |  meta           
INFO 01-06 17:11:21.695113.695113 lmp.py:627]   8          | 8          |  cuda:1         
INFO 01-06 17:11:21.695333.695333 lmp.py:627]   12         | 9          |  cuda:1         
INFO 01-06 17:11:21.695075.695075 lmp.py:627]   38         | 9          |  cuda:1         
INFO 01-06 17:11:21.695817.695817 lmp.py:627]   39         | 10         |  cuda:1         
INFO 01-06 17:11:21.695964.695964 lmp.py:627]   36         | 12         |  cuda:1         
INFO 01-06 17:11:21.695806.695806 lmp.py:627]   25         | 15         |  cuda:1         
INFO 01-06 17:11:21.695549.695549 lmp.py:628] ============================================================
INFO 01-06 17:11:21.695549.695549 lmp.py:628] 
INFO 01-06 17:11:21.695682.695682 lmp.py:630] experts_gpu_list: [4, 20, 41, 42, 50, 15, 19, 34, 35, 46, 52, 57, 6, 21, 24, 47, 49, 27, 44, 60, 61, 5, 56, 8, 12, 38, 39, 36, 25] num: 29
INFO 01-06 17:11:21.695524.695524 lmp.py:631] experts_cpu_list: [1, 3, 9, 14, 23, 26, 53, 59, 0, 2, 7, 10, 17, 18, 40, 54, 11, 33, 43, 55, 13, 51, 62, 63, 22, 28] num: 26
INFO 01-06 17:11:21.695571.695571 lmp.py:632] expert_actual_device_map {0: 'meta', 1: 'meta', 2: 'meta', 3: 'meta', 4: 'cuda:1', 5: 'cuda:1', 6: 'cuda:1', 7: 'meta', 8: 'cuda:1', 9: 'meta', 10: 'meta', 11: 'meta', 12: 'cuda:1', 13: 'meta', 14: 'meta', 15: 'cuda:1', 16: 'meta', 17: 'meta', 18: 'meta', 19: 'cuda:1', 20: 'cuda:1', 21: 'cuda:1', 22: 'meta', 23: 'meta', 24: 'cuda:1', 25: 'cuda:1', 26: 'meta', 27: 'cuda:1', 28: 'meta', 29: 'meta', 30: 'cuda:1', 31: 'cuda:1', 32: 'meta', 33: 'meta', 34: 'cuda:1', 35: 'cuda:1', 36: 'cuda:1', 37: 'meta', 38: 'cuda:1', 39: 'cuda:1', 40: 'meta', 41: 'cuda:1', 42: 'cuda:1', 43: 'meta', 44: 'cuda:1', 45: 'meta', 46: 'cuda:1', 47: 'cuda:1', 48: 'cuda:1', 49: 'cuda:1', 50: 'cuda:1', 51: 'meta', 52: 'cuda:1', 53: 'meta', 54: 'meta', 55: 'meta', 56: 'cuda:1', 57: 'cuda:1', 58: 'meta', 59: 'meta', 60: 'cuda:1', 61: 'cuda:1', 62: 'meta', 63: 'meta'}
DEBUG 01-06 17:11:21.695334.695334 cuda_h.py:19] end experts_map_get cost 0.0023734569549560547 seconds
INFO 01-06 17:11:21.695179.695179 client.py:127] Model loaded
DEBUG 01-06 17:11:21.696691.696691 cuda_h.py:10] start gpu_sexperts
DEBUG 01-06 17:11:21.696002.696002 cuda_h.py:19] end sllm_worker_task cost 0.012684106826782227 seconds
DEBUG 01-06 17:11:21.696642.696642 cuda_h.py:10] start sllm_worker_task
DEBUG 01-06 17:11:21.697027.697027 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 17:11:21.697731.697731 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 17:11:21.699842.699842 cuda_h.py:19] end allocate_cuda_memory cost 0.0026750564575195312 seconds
DEBUG 01-06 17:11:21.699222.699222 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 17:11:21.699601.699601 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 17:11:21.699185.699185 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 17:11:21.699173.699173 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 4c363a5d-604b-4510-8c39-b1729c0c260b
DEBUG 01-06 17:11:21.700904.700904 client.py:106] call stub.LoadModelAsync
DEBUG 01-06 17:11:21.700558.700558 mlpmodule.py:664]  experts func einsum cost 0.04175376892089844 s
DEBUG 01-06 17:11:21.700858.700858 cuda_h.py:19] end gpu_sexperts cost 0.0041179656982421875 seconds
DEBUG 01-06 17:11:21.700404.700404 cuda_h.py:10] start gpu_experts
DEBUG 01-06 17:11:21.701820.701820 mlpmodule.py:533] gpu group tensors cost 0.0004830360412597656 s
INFO 01-06 17:11:21.701223.701223 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 4c363a5d-604b-4510-8c39-b1729c0c260b
DEBUG 01-06 17:11:21.701252.701252 cuda_h.py:19] end load_into_gpu_async cost 0.001638650894165039 seconds
DEBUG 01-06 17:11:21.701570.701570 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 17:11:21.701620.701620 cuda_h.py:19] end restore_tensors2 cost 8.058547973632812e-05 seconds
DEBUG 01-06 17:11:21.701304.701304 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.004668474197387695 seconds
INFO 01-06 17:11:21.701869.701869 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 4c363a5d-604b-4510-8c39-b1729c0c260b
DEBUG 01-06 17:11:21.702189.702189 mlpmodule.py:566] gpu pad cost 0.001659393310546875 s
DEBUG 01-06 17:11:21.703868.703868 mlpmodule.py:584] gpu group einsum cost 0.0004374980926513672 s
DEBUG 01-06 17:11:21.706806.706806 mlpmodule.py:613] gpu experts func einsum cost 0.005385875701904297 s
DEBUG 01-06 17:11:21.706345.706345 cuda_h.py:19] end gpu_experts cost 0.005510091781616211 seconds
DEBUG 01-06 17:11:21.706101.706101 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-06 17:11:21.706970.706970 lmp.py:661] 
DEBUG 01-06 17:11:21.706970.706970 lmp.py:661]   Computing 26 experts on CPU...
DEBUG 01-06 17:11:21.706521.706521 cuda_h.py:19] end cpu_experts_submit cost 7.128715515136719e-05 seconds
DEBUG 01-06 17:11:21.706409.706409 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-06 17:11:21.714641.714641 mlpmodule.py:706] group tensors cost 0.008500337600708008 s
INFO 01-06 17:11:21.715800.715800 client.py:127] Model loaded
DEBUG 01-06 17:11:21.717024.717024 cuda_h.py:19] end sllm_worker_task cost 0.02007317543029785 seconds
DEBUG 01-06 17:11:21.717121.717121 cuda_h.py:10] start sllm_worker_task
DEBUG 01-06 17:11:21.717327.717327 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 17:11:21.717224.717224 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 17:11:21.717154.717154 cuda_h.py:19] end allocate_cuda_memory cost 0.0002491474151611328 seconds
DEBUG 01-06 17:11:21.717753.717753 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 17:11:21.717622.717622 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 17:11:21.717021.717021 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 17:11:21.717161.717161 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, f504227a-878d-477d-abd8-84110ee0df97
DEBUG 01-06 17:11:21.717807.717807 client.py:106] call stub.LoadModelAsync
DEBUG 01-06 17:11:21.719930.719930 mlpmodule.py:744] pad cost 0.003478527069091797 s
DEBUG 01-06 17:11:21.719942.719942 mlpmodule.py:750] create cpu tensor cost 6.318092346191406e-05 s
DEBUG 01-06 17:11:21.719474.719474 mlpmodule.py:755] move to cpu cost 3.457069396972656e-05 s
INFO 01-06 17:11:21.719260.719260 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, f504227a-878d-477d-abd8-84110ee0df97
DEBUG 01-06 17:11:21.719058.719058 cuda_h.py:19] end load_into_gpu_async cost 0.0017147064208984375 seconds
DEBUG 01-06 17:11:21.719012.719012 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 17:11:21.719352.719352 cuda_h.py:19] end restore_tensors2 cost 0.0001895427703857422 seconds
DEBUG 01-06 17:11:21.719449.719449 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0026044845581054688 seconds
INFO 01-06 17:11:21.720890.720890 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, f504227a-878d-477d-abd8-84110ee0df97
DEBUG 01-06 17:11:21.722307.722307 mlpmodule.py:769] group_w3: shape=torch.Size([26, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=74973184
DEBUG 01-06 17:11:21.722614.722614 mlpmodule.py:770] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-06 17:11:21.722510.722510 mlpmodule.py:775] group_w3 first element: 0.036865234375
WARNING 01-06 17:11:21.722692.722692 mlpmodule.py:785] start einsum2
DEBUG 01-06 17:11:21.728369.728369 mlpmodule.py:795] group einsum cost 0.008688926696777344 s
DEBUG 01-06 17:11:21.728536.728536 mlpmodule.py:803] cpy2cputensor cost 0.00013327598571777344 s
INFO 01-06 17:11:21.730116.730116 client.py:127] Model loaded
DEBUG 01-06 17:11:21.731066.731066 cuda_h.py:19] end sllm_worker_task cost 0.014322280883789062 seconds
DEBUG 01-06 17:11:21.731375.731375 cuda_h.py:10] start sllm_worker_task
DEBUG 01-06 17:11:21.731529.731529 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 17:11:21.731763.731763 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 17:11:21.732347.732347 cuda_h.py:19] end allocate_cuda_memory cost 0.00038743019104003906 seconds
DEBUG 01-06 17:11:21.732098.732098 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 17:11:21.732524.732524 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 17:11:21.732367.732367 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 17:11:21.732700.732700 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, df622e6e-7290-4fe9-8fa5-e597d3bfddea
DEBUG 01-06 17:11:21.732279.732279 client.py:106] call stub.LoadModelAsync
INFO 01-06 17:11:21.734787.734787 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, df622e6e-7290-4fe9-8fa5-e597d3bfddea
DEBUG 01-06 17:11:21.734042.734042 cuda_h.py:19] end wait_cetm_experts cost 0.027944087982177734 seconds
DEBUG 01-06 17:11:21.734014.734014 cuda_h.py:19] end load_into_gpu_async cost 0.001973390579223633 seconds
DEBUG 01-06 17:11:21.734461.734461 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 17:11:21.734711.734711 cuda_h.py:19] end restore_tensors2 cost 0.000118255615234375 seconds
DEBUG 01-06 17:11:21.734235.734235 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0028781890869140625 seconds
INFO 01-06 17:11:21.734966.734966 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, df622e6e-7290-4fe9-8fa5-e597d3bfddea
DEBUG 01-06 17:11:21.734832.734832 cuda_h.py:19] end layer_moe_dgenerate_6 cost 0.04234933853149414 seconds
DEBUG 01-06 17:11:21.735184.735184 lmp.py:325] -------------------------------- end decode layer 6 --------------------------------
DEBUG 01-06 17:11:21.735451.735451 lmp.py:298] -------------------------------- start decode layer 7 --------------------------------
DEBUG 01-06 17:11:21.735214.735214 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-06 17:11:21.735396.735396 mlpmodule.py:367] cuda:1 cuda:1
DEBUG 01-06 17:11:21.735278.735278 cuda_h.py:10] start self_attn
cos shape torch.Size([65, 128]) sin shape torch.Size([65, 128]) position_ids tensor([[0]], device='cuda:1')
cos shape torch.Size([1, 1, 1, 128]) sin shape torch.Size([1, 1, 1, 128])
q_embed shape torch.Size([32, 16, 1, 128]) k_embed shape torch.Size([32, 16, 1, 128])
DEBUG 01-06 17:11:21.738830.738830 cuda_h.py:19] end self_attn cost 0.002372264862060547 seconds
DEBUG 01-06 17:11:21.738553.738553 cuda_h.py:19] end iln_self_attn_paln cost 0.0033638477325439453 seconds
DEBUG 01-06 17:11:21.738502.738502 cuda_h.py:10] start layer_moe_dgenerate_7
DEBUG 01-06 17:11:21.738339.738339 cuda_h.py:10] start gate
DEBUG 01-06 17:11:21.739850.739850 cuda_h.py:19] end gate cost 0.0007812976837158203 seconds
DEBUG 01-06 17:11:21.739230.739230 cuda_h.py:10] start experts_map_get
INFO 01-06 17:11:21.740537.740537 lmp.py:611] using loaded check layer: False
INFO 01-06 17:11:21.740405.740405 lmp.py:620] 
INFO 01-06 17:11:21.740405.740405 lmp.py:620] Layer 7 Expert Device Distribution:
INFO 01-06 17:11:21.740413.740413 lmp.py:621]   Active experts: 55 (out of 64 total)
INFO 01-06 17:11:21.740593.740593 lmp.py:622] 
INFO 01-06 17:11:21.740593.740593 lmp.py:622]   Detailed Expert Distribution:
INFO 01-06 17:11:21.740488.740488 lmp.py:623]   Expert ID  | Tokens     | Actual Device  
INFO 01-06 17:11:21.740091.740091 lmp.py:624]   ----------------------------------------------------------------------
INFO 01-06 17:11:21.740317.740317 lmp.py:627]   1          | 1          |  meta           
INFO 01-06 17:11:21.740212.740212 lmp.py:627]   7          | 1          |  meta           
INFO 01-06 17:11:21.740577.740577 lmp.py:627]   11         | 1          |  meta           
INFO 01-06 17:11:21.740942.740942 lmp.py:627]   13         | 1          |  meta           
INFO 01-06 17:11:21.740069.740069 lmp.py:627]   21         | 1          |  cuda:1         
INFO 01-06 17:11:21.741195.741195 lmp.py:627]   28         | 1          |  meta           
INFO 01-06 17:11:21.741276.741276 lmp.py:627]   32         | 1          |  cuda:1         
INFO 01-06 17:11:21.741641.741641 lmp.py:627]   37         | 1          |  cuda:1         
INFO 01-06 17:11:21.741483.741483 lmp.py:627]   41         | 1          |  meta           
INFO 01-06 17:11:21.741324.741324 lmp.py:627]   48         | 1          |  meta           
INFO 01-06 17:11:21.741213.741213 lmp.py:627]   52         | 1          |  meta           
INFO 01-06 17:11:21.741862.741862 lmp.py:627]   54         | 1          |  meta           
INFO 01-06 17:11:21.741512.741512 lmp.py:627]   0          | 2          |  cuda:1         
INFO 01-06 17:11:21.741877.741877 lmp.py:627]   4          | 2          |  meta           
INFO 01-06 17:11:21.741765.741765 lmp.py:627]   6          | 2          |  meta           
INFO 01-06 17:11:21.741415.741415 lmp.py:627]   10         | 2          |  meta           
INFO 01-06 17:11:21.741018.741018 lmp.py:627]   20         | 2          |  meta           
INFO 01-06 17:11:21.741860.741860 lmp.py:627]   25         | 2          |  cuda:1         
INFO 01-06 17:11:21.741987.741987 lmp.py:627]   27         | 2          |  meta           
INFO 01-06 17:11:21.741352.741352 lmp.py:627]   33         | 2          |  cuda:1         
INFO 01-06 17:11:21.741479.741479 lmp.py:627]   36         | 2          |  meta           
INFO 01-06 17:11:21.741367.741367 lmp.py:627]   38         | 2          |  cuda:1         
INFO 01-06 17:11:21.741778.741778 lmp.py:627]   39         | 2          |  meta           
INFO 01-06 17:11:21.741905.741905 lmp.py:627]   57         | 2          |  cuda:1         
INFO 01-06 17:11:21.741554.741554 lmp.py:627]   3          | 3          |  meta           
INFO 01-06 17:11:21.741681.741681 lmp.py:627]   8          | 3          |  meta           
INFO 01-06 17:11:21.741285.741285 lmp.py:627]   12         | 3          |  cuda:1         
INFO 01-06 17:11:21.741411.741411 lmp.py:627]   14         | 3          |  meta           
INFO 01-06 17:11:21.741776.741776 lmp.py:627]   18         | 3          |  meta           
INFO 01-06 17:11:21.741903.741903 lmp.py:627]   30         | 3          |  cuda:1         
INFO 01-06 17:11:21.741552.741552 lmp.py:627]   31         | 3          |  cuda:1         
INFO 01-06 17:11:21.741202.741202 lmp.py:627]   60         | 3          |  meta           
INFO 01-06 17:11:21.741090.741090 lmp.py:627]   22         | 4          |  cuda:1         
INFO 01-06 17:11:21.741979.741979 lmp.py:627]   34         | 4          |  cuda:1         
INFO 01-06 17:11:21.741152.741152 lmp.py:627]   40         | 4          |  meta           
INFO 01-06 17:11:21.741040.741040 lmp.py:627]   47         | 4          |  cuda:1         
INFO 01-06 17:11:21.741166.741166 lmp.py:627]   51         | 4          |  meta           
INFO 01-06 17:11:21.741485.741485 lmp.py:627]   58         | 4          |  cuda:1         
INFO 01-06 17:11:21.741102.741102 lmp.py:627]   59         | 4          |  cuda:1         
INFO 01-06 17:11:21.741421.741421 lmp.py:627]   61         | 4          |  cuda:1         
INFO 01-06 17:11:21.741024.741024 lmp.py:627]   5          | 5          |  cuda:1         
INFO 01-06 17:11:21.741389.741389 lmp.py:627]   16         | 5          |  meta           
INFO 01-06 17:11:21.741039.741039 lmp.py:627]   42         | 5          |  cuda:1         
INFO 01-06 17:11:21.741404.741404 lmp.py:627]   43         | 5          |  meta           
INFO 01-06 17:11:21.741292.741292 lmp.py:627]   56         | 5          |  meta           
INFO 01-06 17:11:21.741419.741419 lmp.py:627]   62         | 5          |  cuda:1         
INFO 01-06 17:11:21.741307.741307 lmp.py:627]   2          | 6          |  cuda:1         
INFO 01-06 17:11:21.741864.741864 lmp.py:627]   23         | 6          |  cuda:1         
INFO 01-06 17:11:21.742706.742706 lmp.py:627]   63         | 6          |  cuda:1         
INFO 01-06 17:11:21.742025.742025 lmp.py:627]   9          | 7          |  cuda:1         
INFO 01-06 17:11:21.742535.742535 lmp.py:627]   44         | 7          |  cuda:1         
INFO 01-06 17:11:21.742377.742377 lmp.py:627]   19         | 8          |  cuda:1         
INFO 01-06 17:11:21.742742.742742 lmp.py:627]   24         | 8          |  cuda:1         
INFO 01-06 17:11:21.742630.742630 lmp.py:627]   49         | 10         |  cuda:1         
INFO 01-06 17:11:21.742042.742042 lmp.py:627]   26         | 12         |  cuda:1         
INFO 01-06 17:11:21.742453.742453 lmp.py:628] ============================================================
INFO 01-06 17:11:21.742453.742453 lmp.py:628] 
INFO 01-06 17:11:21.742197.742197 lmp.py:630] experts_gpu_list: [21, 32, 37, 0, 25, 33, 38, 57, 12, 30, 31, 22, 34, 47, 58, 59, 61, 5, 42, 62, 2, 23, 63, 9, 44, 19, 24, 49, 26] num: 29
INFO 01-06 17:11:21.742860.742860 lmp.py:631] experts_cpu_list: [1, 7, 11, 13, 28, 41, 48, 52, 54, 4, 6, 10, 20, 27, 36, 39, 3, 8, 14, 18, 60, 40, 51, 16, 43, 56] num: 26
INFO 01-06 17:11:21.742868.742868 lmp.py:632] expert_actual_device_map {0: 'cuda:1', 1: 'meta', 2: 'cuda:1', 3: 'meta', 4: 'meta', 5: 'cuda:1', 6: 'meta', 7: 'meta', 8: 'meta', 9: 'cuda:1', 10: 'meta', 11: 'meta', 12: 'cuda:1', 13: 'meta', 14: 'meta', 15: 'meta', 16: 'meta', 17: 'cuda:1', 18: 'meta', 19: 'cuda:1', 20: 'meta', 21: 'cuda:1', 22: 'cuda:1', 23: 'cuda:1', 24: 'cuda:1', 25: 'cuda:1', 26: 'cuda:1', 27: 'meta', 28: 'meta', 29: 'meta', 30: 'cuda:1', 31: 'cuda:1', 32: 'cuda:1', 33: 'cuda:1', 34: 'cuda:1', 35: 'cuda:1', 36: 'meta', 37: 'cuda:1', 38: 'cuda:1', 39: 'meta', 40: 'meta', 41: 'meta', 42: 'cuda:1', 43: 'meta', 44: 'cuda:1', 45: 'meta', 46: 'meta', 47: 'cuda:1', 48: 'meta', 49: 'cuda:1', 50: 'meta', 51: 'meta', 52: 'meta', 53: 'cuda:1', 54: 'meta', 55: 'meta', 56: 'meta', 57: 'cuda:1', 58: 'cuda:1', 59: 'cuda:1', 60: 'meta', 61: 'cuda:1', 62: 'cuda:1', 63: 'cuda:1'}
DEBUG 01-06 17:11:21.742869.742869 cuda_h.py:19] end experts_map_get cost 0.002640962600708008 seconds
DEBUG 01-06 17:11:21.742614.742614 cuda_h.py:10] start gpu_sexperts
DEBUG 01-06 17:11:21.742878.742878 cuda_h.py:19] end gpu_sexperts cost 0.0003292560577392578 seconds
DEBUG 01-06 17:11:21.742469.742469 cuda_h.py:10] start gpu_experts
INFO 01-06 17:11:21.743752.743752 client.py:127] Model loaded
DEBUG 01-06 17:11:21.743863.743863 mlpmodule.py:533] gpu group tensors cost 0.00081634521484375 s
DEBUG 01-06 17:11:21.744891.744891 cuda_h.py:19] end sllm_worker_task cost 0.012415647506713867 seconds
DEBUG 01-06 17:11:21.744841.744841 cuda_h.py:10] start sllm_worker_task
DEBUG 01-06 17:11:21.744458.744458 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 17:11:21.744049.744049 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 17:11:21.745200.745200 cuda_h.py:19] end allocate_cuda_memory cost 0.0008814334869384766 seconds
DEBUG 01-06 17:11:21.745427.745427 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 17:11:21.745421.745421 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 17:11:21.745237.745237 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 17:11:21.745271.745271 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 7ca3c3e0-3746-4e11-82ee-3d7cba8fb5a0
DEBUG 01-06 17:11:21.745943.745943 client.py:106] call stub.LoadModelAsync
DEBUG 01-06 17:11:21.745153.745153 mlpmodule.py:664]  experts func einsum cost 0.039231061935424805 s
INFO 01-06 17:11:21.746559.746559 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 7ca3c3e0-3746-4e11-82ee-3d7cba8fb5a0
DEBUG 01-06 17:11:21.747012.747012 cuda_h.py:19] end load_into_gpu_async cost 0.0016241073608398438 seconds
DEBUG 01-06 17:11:21.747768.747768 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 17:11:21.747189.747189 cuda_h.py:19] end restore_tensors2 cost 7.271766662597656e-05 seconds
DEBUG 01-06 17:11:21.747230.747230 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.002861499786376953 seconds
INFO 01-06 17:11:21.747788.747788 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 7ca3c3e0-3746-4e11-82ee-3d7cba8fb5a0
DEBUG 01-06 17:11:21.747837.747837 mlpmodule.py:566] gpu pad cost 0.0036699771881103516 s
DEBUG 01-06 17:11:21.748007.748007 mlpmodule.py:584] gpu group einsum cost 0.00044035911560058594 s
DEBUG 01-06 17:11:21.750029.750029 mlpmodule.py:613] gpu experts func einsum cost 0.007752895355224609 s
DEBUG 01-06 17:11:21.750668.750668 cuda_h.py:19] end gpu_experts cost 0.007875919342041016 seconds
DEBUG 01-06 17:11:21.750762.750762 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-06 17:11:21.750226.750226 lmp.py:661] 
DEBUG 01-06 17:11:21.750226.750226 lmp.py:661]   Computing 26 experts on CPU...
DEBUG 01-06 17:11:21.750870.750870 cuda_h.py:19] end cpu_experts_submit cost 5.316734313964844e-05 seconds
DEBUG 01-06 17:11:21.750474.750474 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-06 17:11:21.755050.755050 mlpmodule.py:706] group tensors cost 0.004172086715698242 s
INFO 01-06 17:11:21.756045.756045 client.py:127] Model loaded
DEBUG 01-06 17:11:21.757981.757981 cuda_h.py:19] end sllm_worker_task cost 0.012841939926147461 seconds
DEBUG 01-06 17:11:21.757506.757506 cuda_h.py:10] start sllm_worker_task
DEBUG 01-06 17:11:21.757600.757600 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 17:11:21.757668.757668 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 17:11:21.757477.757477 cuda_h.py:19] end allocate_cuda_memory cost 0.0002117156982421875 seconds
DEBUG 01-06 17:11:21.757658.757658 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 17:11:21.757653.757653 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 17:11:21.757038.757038 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 17:11:21.757787.757787 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 7d8d3334-c2e6-4427-8dd2-eff24ccd790b
DEBUG 01-06 17:11:21.757313.757313 client.py:106] call stub.LoadModelAsync
DEBUG 01-06 17:11:21.758938.758938 mlpmodule.py:744] pad cost 0.002954721450805664 s
DEBUG 01-06 17:11:21.758538.758538 mlpmodule.py:750] create cpu tensor cost 4.38690185546875e-05 s
DEBUG 01-06 17:11:21.759302.759302 mlpmodule.py:755] move to cpu cost 3.314018249511719e-05 s
INFO 01-06 17:11:21.759736.759736 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 7d8d3334-c2e6-4427-8dd2-eff24ccd790b
DEBUG 01-06 17:11:21.759931.759931 cuda_h.py:19] end load_into_gpu_async cost 0.0015709400177001953 seconds
DEBUG 01-06 17:11:21.759726.759726 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 17:11:21.759180.759180 cuda_h.py:19] end restore_tensors2 cost 6.604194641113281e-05 seconds
DEBUG 01-06 17:11:21.759644.759644 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0020787715911865234 seconds
INFO 01-06 17:11:21.759638.759638 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 7d8d3334-c2e6-4427-8dd2-eff24ccd790b
DEBUG 01-06 17:11:21.762074.762074 mlpmodule.py:769] group_w3: shape=torch.Size([26, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=74973184
DEBUG 01-06 17:11:21.762958.762958 mlpmodule.py:770] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-06 17:11:21.762801.762801 mlpmodule.py:775] group_w3 first element: 0.01263427734375
WARNING 01-06 17:11:21.762493.762493 mlpmodule.py:785] start einsum2
DEBUG 01-06 17:11:21.769532.769532 mlpmodule.py:795] group einsum cost 0.009986639022827148 s
DEBUG 01-06 17:11:21.769877.769877 mlpmodule.py:803] cpy2cputensor cost 0.00012063980102539062 s
INFO 01-06 17:11:21.770127.770127 client.py:127] Model loaded
DEBUG 01-06 17:11:21.771829.771829 cuda_h.py:19] end sllm_worker_task cost 0.014333009719848633 seconds
DEBUG 01-06 17:11:21.771846.771846 cuda_h.py:10] start sllm_worker_task
DEBUG 01-06 17:11:21.771907.771907 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 17:11:21.771857.771857 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 17:11:21.772725.772725 cuda_h.py:19] end allocate_cuda_memory cost 0.0003867149353027344 seconds
DEBUG 01-06 17:11:21.772549.772549 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 17:11:21.772425.772425 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 17:11:21.772997.772997 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 17:11:21.772852.772852 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 7ccaef51-7d93-4eeb-83d2-8e41c3e19b39
DEBUG 01-06 17:11:21.772432.772432 client.py:106] call stub.LoadModelAsync
INFO 01-06 17:11:21.774437.774437 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 7ccaef51-7d93-4eeb-83d2-8e41c3e19b39
DEBUG 01-06 17:11:21.774909.774909 cuda_h.py:19] end load_into_gpu_async cost 0.0018055438995361328 seconds
DEBUG 01-06 17:11:21.774334.774334 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 17:11:21.774054.774054 cuda_h.py:19] end restore_tensors2 cost 0.00011444091796875 seconds
DEBUG 01-06 17:11:21.774916.774916 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.002608776092529297 seconds
INFO 01-06 17:11:21.774654.774654 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 7ccaef51-7d93-4eeb-83d2-8e41c3e19b39
DEBUG 01-06 17:11:21.775929.775929 cuda_h.py:19] end wait_cetm_experts cost 0.024829387664794922 seconds
DEBUG 01-06 17:11:21.776647.776647 cuda_h.py:19] end layer_moe_dgenerate_7 cost 0.037313222885131836 seconds
DEBUG 01-06 17:11:21.776818.776818 lmp.py:325] -------------------------------- end decode layer 7 --------------------------------
DEBUG 01-06 17:11:21.776826.776826 lmp.py:298] -------------------------------- start decode layer 8 --------------------------------
DEBUG 01-06 17:11:21.776383.776383 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-06 17:11:21.776751.776751 mlpmodule.py:367] cuda:1 cuda:1
DEBUG 01-06 17:11:21.776598.776598 cuda_h.py:10] start self_attn
cos shape torch.Size([65, 128]) sin shape torch.Size([65, 128]) position_ids tensor([[0]], device='cuda:1')
cos shape torch.Size([1, 1, 1, 128]) sin shape torch.Size([1, 1, 1, 128])
q_embed shape torch.Size([32, 16, 1, 128]) k_embed shape torch.Size([32, 16, 1, 128])
DEBUG 01-06 17:11:21.778683.778683 cuda_h.py:19] end self_attn cost 0.0018949508666992188 seconds
DEBUG 01-06 17:11:21.779794.779794 cuda_h.py:19] end iln_self_attn_paln cost 0.0027272701263427734 seconds
DEBUG 01-06 17:11:21.779676.779676 cuda_h.py:10] start layer_moe_dgenerate_8
DEBUG 01-06 17:11:21.779446.779446 cuda_h.py:10] start gate
DEBUG 01-06 17:11:21.779793.779793 cuda_h.py:19] end gate cost 0.0006394386291503906 seconds
DEBUG 01-06 17:11:21.779391.779391 cuda_h.py:10] start experts_map_get
INFO 01-06 17:11:21.780396.780396 lmp.py:609] using loaded check layer: True
INFO 01-06 17:11:21.780900.780900 lmp.py:620] 
INFO 01-06 17:11:21.780900.780900 lmp.py:620] Layer 8 Expert Device Distribution:
INFO 01-06 17:11:21.780193.780193 lmp.py:621]   Active experts: 53 (out of 64 total)
INFO 01-06 17:11:21.780181.780181 lmp.py:622] 
INFO 01-06 17:11:21.780181.780181 lmp.py:622]   Detailed Expert Distribution:
INFO 01-06 17:11:21.780122.780122 lmp.py:623]   Expert ID  | Tokens     | Actual Device  
INFO 01-06 17:11:21.780487.780487 lmp.py:624]   ----------------------------------------------------------------------
INFO 01-06 17:11:21.781283.781283 lmp.py:627]   2          | 1          |  cuda:1         
INFO 01-06 17:11:21.781932.781932 lmp.py:627]   3          | 1          |  cuda:1         
INFO 01-06 17:11:21.781867.781867 lmp.py:627]   4          | 1          |  cuda:1         
INFO 01-06 17:11:21.781801.781801 lmp.py:627]   14         | 1          |  meta           
INFO 01-06 17:11:21.781259.781259 lmp.py:627]   15         | 1          |  meta           
INFO 01-06 17:11:21.781624.781624 lmp.py:627]   24         | 1          |  meta           
INFO 01-06 17:11:21.781035.781035 lmp.py:627]   32         | 1          |  meta           
INFO 01-06 17:11:21.781400.781400 lmp.py:627]   37         | 1          |  cuda:1         
INFO 01-06 17:11:21.781050.781050 lmp.py:627]   56         | 1          |  cuda:1         
INFO 01-06 17:11:21.781746.781746 lmp.py:627]   58         | 1          |  cuda:1         
INFO 01-06 17:11:21.781204.781204 lmp.py:627]   61         | 1          |  cuda:1         
INFO 01-06 17:11:21.781138.781138 lmp.py:627]   8          | 2          |  cuda:1         
INFO 01-06 17:11:21.781073.781073 lmp.py:627]   10         | 2          |  cuda:1         
INFO 01-06 17:11:21.781531.781531 lmp.py:627]   11         | 2          |  cuda:1         
INFO 01-06 17:11:21.781988.781988 lmp.py:627]   26         | 2          |  cuda:1         
INFO 01-06 17:11:21.781638.781638 lmp.py:627]   39         | 2          |  meta           
INFO 01-06 17:11:21.781049.781049 lmp.py:627]   42         | 2          |  meta           
INFO 01-06 17:11:21.781222.781222 lmp.py:627]   45         | 2          |  cuda:1         
INFO 01-06 17:11:21.781256.781256 lmp.py:627]   47         | 2          |  cuda:1         
INFO 01-06 17:11:21.781429.781429 lmp.py:627]   48         | 2          |  meta           
INFO 01-06 17:11:21.781410.781410 lmp.py:627]   51         | 2          |  meta           
INFO 01-06 17:11:21.781629.781629 lmp.py:627]   52         | 2          |  cuda:1         
INFO 01-06 17:11:21.781849.781849 lmp.py:627]   55         | 2          |  cuda:1         
INFO 01-06 17:11:21.781306.781306 lmp.py:627]   59         | 2          |  meta           
INFO 01-06 17:11:21.781479.781479 lmp.py:627]   16         | 3          |  meta           
INFO 01-06 17:11:21.781414.781414 lmp.py:627]   21         | 3          |  cuda:1         
INFO 01-06 17:11:21.781587.781587 lmp.py:627]   30         | 3          |  meta           
INFO 01-06 17:11:21.781998.781998 lmp.py:627]   33         | 3          |  meta           
INFO 01-06 17:11:21.781217.781217 lmp.py:627]   49         | 3          |  cuda:1         
INFO 01-06 17:11:21.781629.781629 lmp.py:627]   50         | 3          |  cuda:1         
INFO 01-06 17:11:21.781848.781848 lmp.py:627]   53         | 3          |  meta           
INFO 01-06 17:11:21.781067.781067 lmp.py:627]   57         | 3          |  cuda:1         
INFO 01-06 17:11:21.781286.781286 lmp.py:627]   60         | 3          |  meta           
INFO 01-06 17:11:21.781982.781982 lmp.py:627]   62         | 3          |  cuda:1         
INFO 01-06 17:11:21.781394.781394 lmp.py:627]   6          | 4          |  cuda:1         
INFO 01-06 17:11:21.781328.781328 lmp.py:627]   9          | 4          |  cuda:1         
INFO 01-06 17:11:21.781740.781740 lmp.py:627]   13         | 4          |  cuda:1         
INFO 01-06 17:11:21.781197.781197 lmp.py:627]   17         | 4          |  meta           
INFO 01-06 17:11:21.781655.781655 lmp.py:627]   22         | 4          |  meta           
INFO 01-06 17:11:21.781874.781874 lmp.py:627]   28         | 4          |  cuda:1         
INFO 01-06 17:11:21.781093.781093 lmp.py:627]   41         | 4          |  cuda:1         
INFO 01-06 17:11:21.781313.781313 lmp.py:627]   63         | 4          |  cuda:1         
INFO 01-06 17:11:21.781055.781055 lmp.py:627]   5          | 5          |  cuda:1         
INFO 01-06 17:11:21.781705.781705 lmp.py:627]   19         | 5          |  cuda:1         
INFO 01-06 17:11:21.781878.781878 lmp.py:627]   40         | 5          |  meta           
INFO 01-06 17:11:21.781197.781197 lmp.py:627]   46         | 5          |  cuda:1         
INFO 01-06 17:11:21.782754.782754 lmp.py:627]   29         | 6          |  meta           
INFO 01-06 17:11:21.782211.782211 lmp.py:627]   54         | 6          |  meta           
INFO 01-06 17:11:21.782431.782431 lmp.py:627]   31         | 7          |  cuda:1         
INFO 01-06 17:11:21.782411.782411 lmp.py:627]   20         | 8          |  cuda:1         
INFO 01-06 17:11:21.782532.782532 lmp.py:627]   34         | 11         |  meta           
INFO 01-06 17:11:21.782143.782143 lmp.py:627]   25         | 14         |  cuda:1         
INFO 01-06 17:11:21.782985.782985 lmp.py:627]   23         | 21         |  cuda:1         
INFO 01-06 17:11:21.782826.782826 lmp.py:628] ============================================================
INFO 01-06 17:11:21.782826.782826 lmp.py:628] 
INFO 01-06 17:11:21.782867.782867 lmp.py:630] experts_gpu_list: [2, 3, 4, 37, 56, 58, 61, 8, 10, 11, 26, 45, 47, 52, 55, 21, 49, 50, 57, 62, 6, 9, 13, 28, 41, 63, 5, 19, 46, 31, 20, 25, 23] num: 33
INFO 01-06 17:11:21.782855.782855 lmp.py:631] experts_cpu_list: [14, 15, 24, 32, 39, 42, 48, 51, 59, 16, 30, 33, 53, 60, 17, 22, 40, 29, 54, 34] num: 20
INFO 01-06 17:11:21.782525.782525 lmp.py:632] expert_actual_device_map {0: 'cuda:1', 1: 'cuda:1', 2: 'cuda:1', 3: 'cuda:1', 4: 'cuda:1', 5: 'cuda:1', 6: 'cuda:1', 7: 'cuda:1', 8: 'cuda:1', 9: 'cuda:1', 10: 'cuda:1', 11: 'cuda:1', 12: 'meta', 13: 'cuda:1', 14: 'meta', 15: 'meta', 16: 'meta', 17: 'meta', 18: 'meta', 19: 'cuda:1', 20: 'cuda:1', 21: 'cuda:1', 22: 'meta', 23: 'cuda:1', 24: 'meta', 25: 'cuda:1', 26: 'cuda:1', 27: 'meta', 28: 'cuda:1', 29: 'meta', 30: 'meta', 31: 'cuda:1', 32: 'meta', 33: 'meta', 34: 'meta', 35: 'meta', 36: 'meta', 37: 'cuda:1', 38: 'meta', 39: 'meta', 40: 'meta', 41: 'cuda:1', 42: 'meta', 43: 'cuda:1', 44: 'meta', 45: 'cuda:1', 46: 'cuda:1', 47: 'cuda:1', 48: 'meta', 49: 'cuda:1', 50: 'cuda:1', 51: 'meta', 52: 'cuda:1', 53: 'meta', 54: 'meta', 55: 'cuda:1', 56: 'cuda:1', 57: 'cuda:1', 58: 'cuda:1', 59: 'meta', 60: 'meta', 61: 'cuda:1', 62: 'cuda:1', 63: 'cuda:1'}
DEBUG 01-06 17:11:21.782049.782049 cuda_h.py:19] end experts_map_get cost 0.002418041229248047 seconds
DEBUG 01-06 17:11:21.782317.782317 cuda_h.py:10] start gpu_sexperts
DEBUG 01-06 17:11:21.782753.782753 cuda_h.py:19] end gpu_sexperts cost 0.0003170967102050781 seconds
DEBUG 01-06 17:11:21.782106.782106 cuda_h.py:10] start gpu_experts
INFO 01-06 17:11:21.783655.783655 client.py:127] Model loaded
DEBUG 01-06 17:11:21.784181.784181 cuda_h.py:19] end sllm_worker_task cost 0.01231527328491211 seconds
DEBUG 01-06 17:11:21.784739.784739 cuda_h.py:10] start sllm_worker_task
DEBUG 01-06 17:11:21.784833.784833 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 17:11:21.784146.784146 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 17:11:21.785589.785589 cuda_h.py:19] end allocate_cuda_memory cost 0.0015180110931396484 seconds
DEBUG 01-06 17:11:21.785220.785220 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 17:11:21.785215.785215 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 17:11:21.785077.785077 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 17:11:21.785588.785588 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 7fb61014-d2c5-4458-a8ac-52a81da1bcea
DEBUG 01-06 17:11:21.786213.786213 client.py:106] call stub.LoadModelAsync
DEBUG 01-06 17:11:21.786092.786092 mlpmodule.py:664]  experts func einsum cost 0.0352935791015625 s
DEBUG 01-06 17:11:21.786831.786831 mlpmodule.py:533] gpu group tensors cost 0.0037844181060791016 s
INFO 01-06 17:11:21.787166.787166 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 7fb61014-d2c5-4458-a8ac-52a81da1bcea
DEBUG 01-06 17:11:21.787956.787956 cuda_h.py:19] end load_into_gpu_async cost 0.0015633106231689453 seconds
DEBUG 01-06 17:11:21.787228.787228 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 17:11:21.787887.787887 cuda_h.py:19] end restore_tensors2 cost 7.2479248046875e-05 seconds
DEBUG 01-06 17:11:21.787882.787882 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0034148693084716797 seconds
INFO 01-06 17:11:21.787526.787526 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 7fb61014-d2c5-4458-a8ac-52a81da1bcea
DEBUG 01-06 17:11:21.788121.788121 mlpmodule.py:566] gpu pad cost 0.0018322467803955078 s
DEBUG 01-06 17:11:21.789678.789678 mlpmodule.py:584] gpu group einsum cost 0.000347137451171875 s
DEBUG 01-06 17:11:21.791953.791953 mlpmodule.py:613] gpu experts func einsum cost 0.009012937545776367 s
DEBUG 01-06 17:11:21.792784.792784 cuda_h.py:19] end gpu_experts cost 0.00914144515991211 seconds
DEBUG 01-06 17:11:21.792109.792109 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-06 17:11:21.792574.792574 lmp.py:661] 
DEBUG 01-06 17:11:21.792574.792574 lmp.py:661]   Computing 20 experts on CPU...
DEBUG 01-06 17:11:21.792125.792125 cuda_h.py:19] end cpu_experts_submit cost 5.53131103515625e-05 seconds
DEBUG 01-06 17:11:21.792298.792298 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-06 17:11:21.796761.796761 mlpmodule.py:706] group tensors cost 0.004333019256591797 s
INFO 01-06 17:11:21.797257.797257 client.py:127] Model loaded
DEBUG 01-06 17:11:21.798956.798956 cuda_h.py:19] end sllm_worker_task cost 0.014163970947265625 seconds
DEBUG 01-06 17:11:21.798521.798521 cuda_h.py:10] start sllm_worker_task
DEBUG 01-06 17:11:21.798330.798330 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 17:11:21.798067.798067 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 17:11:21.798930.798930 cuda_h.py:19] end allocate_cuda_memory cost 0.00021219253540039062 seconds
DEBUG 01-06 17:11:21.798257.798257 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 17:11:21.798443.798443 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 17:11:21.798590.798590 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 17:11:21.798624.798624 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, c74315a7-cf6e-4410-a334-a8c010b62819
DEBUG 01-06 17:11:21.798911.798911 client.py:106] call stub.LoadModelAsync
DEBUG 01-06 17:11:21.799874.799874 mlpmodule.py:744] pad cost 0.0025212764739990234 s
DEBUG 01-06 17:11:21.799812.799812 mlpmodule.py:750] create cpu tensor cost 4.57763671875e-05 s
DEBUG 01-06 17:11:21.800622.800622 mlpmodule.py:755] move to cpu cost 3.123283386230469e-05 s
INFO 01-06 17:11:21.800255.800255 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, c74315a7-cf6e-4410-a334-a8c010b62819
DEBUG 01-06 17:11:21.800656.800656 cuda_h.py:19] end load_into_gpu_async cost 0.001592397689819336 seconds
DEBUG 01-06 17:11:21.800696.800696 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 17:11:21.800302.800302 cuda_h.py:19] end restore_tensors2 cost 7.009506225585938e-05 seconds
DEBUG 01-06 17:11:21.800389.800389 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0021228790283203125 seconds
INFO 01-06 17:11:21.800722.800722 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, c74315a7-cf6e-4410-a334-a8c010b62819
DEBUG 01-06 17:11:21.803012.803012 mlpmodule.py:769] group_w3: shape=torch.Size([20, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=57671680
DEBUG 01-06 17:11:21.803227.803227 mlpmodule.py:770] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-06 17:11:21.803792.803792 mlpmodule.py:775] group_w3 first element: -0.0194091796875
WARNING 01-06 17:11:21.803921.803921 mlpmodule.py:785] start einsum2
DEBUG 01-06 17:11:21.809838.809838 mlpmodule.py:795] group einsum cost 0.009554862976074219 s
DEBUG 01-06 17:11:21.809215.809215 mlpmodule.py:803] cpy2cputensor cost 0.00011444091796875 s
INFO 01-06 17:11:21.811500.811500 client.py:127] Model loaded
DEBUG 01-06 17:11:21.812119.812119 cuda_h.py:19] end sllm_worker_task cost 0.014044046401977539 seconds
DEBUG 01-06 17:11:21.812097.812097 cuda_h.py:10] start sllm_worker_task
DEBUG 01-06 17:11:21.812635.812635 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 17:11:21.812538.812538 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 17:11:21.813664.813664 cuda_h.py:19] end allocate_cuda_memory cost 0.00036525726318359375 seconds
DEBUG 01-06 17:11:21.813435.813435 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 17:11:21.813582.813582 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 17:11:21.813710.813710 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 17:11:21.813088.813088 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, fdae2d0b-2c5b-432b-911e-efeaec04c2b9
DEBUG 01-06 17:11:21.813807.813807 client.py:106] call stub.LoadModelAsync
INFO 01-06 17:11:21.814858.814858 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, fdae2d0b-2c5b-432b-911e-efeaec04c2b9
DEBUG 01-06 17:11:21.815661.815661 cuda_h.py:19] end load_into_gpu_async cost 0.0017786026000976562 seconds
DEBUG 01-06 17:11:21.815086.815086 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 17:11:21.815707.815707 cuda_h.py:19] end restore_tensors2 cost 0.00011014938354492188 seconds
DEBUG 01-06 17:11:21.815708.815708 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.002551555633544922 seconds
INFO 01-06 17:11:21.815641.815641 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, fdae2d0b-2c5b-432b-911e-efeaec04c2b9
DEBUG 01-06 17:11:21.815546.815546 cuda_h.py:19] end wait_cetm_experts cost 0.02338266372680664 seconds
DEBUG 01-06 17:11:21.815086.815086 cuda_h.py:19] end layer_moe_dgenerate_8 cost 0.036710500717163086 seconds
DEBUG 01-06 17:11:21.816926.816926 lmp.py:325] -------------------------------- end decode layer 8 --------------------------------
DEBUG 01-06 17:11:21.816927.816927 lmp.py:298] -------------------------------- start decode layer 9 --------------------------------
DEBUG 01-06 17:11:21.816769.816769 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-06 17:11:21.816639.816639 mlpmodule.py:367] cuda:1 cuda:1
DEBUG 01-06 17:11:21.816606.816606 cuda_h.py:10] start self_attn
cos shape torch.Size([65, 128]) sin shape torch.Size([65, 128]) position_ids tensor([[0]], device='cuda:1')
cos shape torch.Size([1, 1, 1, 128]) sin shape torch.Size([1, 1, 1, 128])
q_embed shape torch.Size([32, 16, 1, 128]) k_embed shape torch.Size([32, 16, 1, 128])
DEBUG 01-06 17:11:21.818618.818618 cuda_h.py:19] end self_attn cost 0.0018770694732666016 seconds
DEBUG 01-06 17:11:21.818330.818330 cuda_h.py:19] end iln_self_attn_paln cost 0.0026977062225341797 seconds
DEBUG 01-06 17:11:21.818590.818590 cuda_h.py:10] start layer_moe_dgenerate_9
DEBUG 01-06 17:11:21.818883.818883 cuda_h.py:10] start gate
DEBUG 01-06 17:11:21.819760.819760 cuda_h.py:19] end gate cost 0.0006411075592041016 seconds
DEBUG 01-06 17:11:21.819358.819358 cuda_h.py:10] start experts_map_get
INFO 01-06 17:11:21.820662.820662 lmp.py:609] using loaded check layer: True
INFO 01-06 17:11:21.820054.820054 lmp.py:620] 
INFO 01-06 17:11:21.820054.820054 lmp.py:620] Layer 9 Expert Device Distribution:
INFO 01-06 17:11:21.820823.820823 lmp.py:621]   Active experts: 56 (out of 64 total)
INFO 01-06 17:11:21.820295.820295 lmp.py:622] 
INFO 01-06 17:11:21.820295.820295 lmp.py:622]   Detailed Expert Distribution:
INFO 01-06 17:11:21.820905.820905 lmp.py:623]   Expert ID  | Tokens     | Actual Device  
INFO 01-06 17:11:21.820939.820939 lmp.py:624]   ----------------------------------------------------------------------
INFO 01-06 17:11:21.820734.820734 lmp.py:627]   1          | 1          |  cuda:1         
INFO 01-06 17:11:21.820292.820292 lmp.py:627]   4          | 1          |  cuda:1         
INFO 01-06 17:11:21.820657.820657 lmp.py:627]   7          | 1          |  cuda:1         
INFO 01-06 17:11:21.820737.820737 lmp.py:627]   16         | 1          |  meta           
INFO 01-06 17:11:21.820579.820579 lmp.py:627]   19         | 1          |  meta           
INFO 01-06 17:11:21.820421.820421 lmp.py:627]   20         | 1          |  meta           
INFO 01-06 17:11:21.820547.820547 lmp.py:627]   23         | 1          |  meta           
INFO 01-06 17:11:21.820151.820151 lmp.py:627]   30         | 1          |  cuda:1         
INFO 01-06 17:11:21.820231.820231 lmp.py:627]   32         | 1          |  meta           
INFO 01-06 17:11:21.821311.821311 lmp.py:627]   33         | 1          |  cuda:1         
INFO 01-06 17:11:21.821915.821915 lmp.py:627]   37         | 1          |  meta           
INFO 01-06 17:11:21.821803.821803 lmp.py:627]   38         | 1          |  meta           
INFO 01-06 17:11:21.821453.821453 lmp.py:627]   43         | 1          |  cuda:1         
INFO 01-06 17:11:21.821294.821294 lmp.py:627]   49         | 1          |  meta           
INFO 01-06 17:11:21.821944.821944 lmp.py:627]   53         | 1          |  meta           
INFO 01-06 17:11:21.821309.821309 lmp.py:627]   60         | 1          |  meta           
INFO 01-06 17:11:21.821959.821959 lmp.py:627]   5          | 2          |  cuda:1         
INFO 01-06 17:11:21.821278.821278 lmp.py:627]   12         | 2          |  meta           
INFO 01-06 17:11:21.821358.821358 lmp.py:627]   15         | 2          |  meta           
INFO 01-06 17:11:21.821723.821723 lmp.py:627]   27         | 2          |  meta           
INFO 01-06 17:11:21.821326.821326 lmp.py:627]   35         | 2          |  meta           
INFO 01-06 17:11:21.821453.821453 lmp.py:627]   36         | 2          |  cuda:1         
INFO 01-06 17:11:21.821103.821103 lmp.py:627]   42         | 2          |  cuda:1         
INFO 01-06 17:11:21.821945.821945 lmp.py:627]   44         | 2          |  cuda:1         
INFO 01-06 17:11:21.821594.821594 lmp.py:627]   47         | 2          |  meta           
INFO 01-06 17:11:21.821483.821483 lmp.py:627]   48         | 2          |  cuda:1         
INFO 01-06 17:11:21.821324.821324 lmp.py:627]   50         | 2          |  meta           
INFO 01-06 17:11:21.821166.821166 lmp.py:627]   58         | 2          |  cuda:1         
INFO 01-06 17:11:21.821770.821770 lmp.py:627]   59         | 2          |  meta           
INFO 01-06 17:11:21.821373.821373 lmp.py:627]   61         | 2          |  cuda:1         
INFO 01-06 17:11:21.821261.821261 lmp.py:627]   63         | 2          |  cuda:1         
INFO 01-06 17:11:21.821388.821388 lmp.py:627]   17         | 3          |  meta           
INFO 01-06 17:11:21.821276.821276 lmp.py:627]   21         | 3          |  cuda:1         
INFO 01-06 17:11:21.821164.821164 lmp.py:627]   28         | 3          |  meta           
INFO 01-06 17:11:21.821814.821814 lmp.py:627]   39         | 3          |  cuda:1         
INFO 01-06 17:11:21.821179.821179 lmp.py:627]   40         | 3          |  meta           
INFO 01-06 17:11:21.821021.821021 lmp.py:627]   41         | 3          |  meta           
INFO 01-06 17:11:21.821578.821578 lmp.py:627]   56         | 3          |  cuda:1         
INFO 01-06 17:11:21.821658.821658 lmp.py:627]   13         | 4          |  meta           
INFO 01-06 17:11:21.821262.821262 lmp.py:627]   22         | 4          |  meta           
INFO 01-06 17:11:21.821388.821388 lmp.py:627]   51         | 4          |  cuda:1         
INFO 01-06 17:11:21.821800.821800 lmp.py:627]   62         | 4          |  cuda:1         
INFO 01-06 17:11:21.821926.821926 lmp.py:627]   6          | 5          |  cuda:1         
INFO 01-06 17:11:21.821576.821576 lmp.py:627]   54         | 5          |  cuda:1         
INFO 01-06 17:11:21.821180.821180 lmp.py:627]   11         | 6          |  cuda:1         
INFO 01-06 17:11:21.821783.821783 lmp.py:627]   25         | 6          |  meta           
INFO 01-06 17:11:21.821386.821386 lmp.py:627]   45         | 6          |  cuda:1         
INFO 01-06 17:11:21.821467.821467 lmp.py:627]   9          | 7          |  cuda:1         
INFO 01-06 17:11:21.821116.821116 lmp.py:627]   34         | 7          |  cuda:1         
INFO 01-06 17:11:21.821005.821005 lmp.py:627]   46         | 7          |  cuda:1         
INFO 01-06 17:11:21.821131.821131 lmp.py:627]   18         | 8          |  cuda:1         
INFO 01-06 17:11:21.821019.821019 lmp.py:627]   52         | 8          |  cuda:1         
INFO 01-06 17:11:21.822146.822146 lmp.py:627]   55         | 8          |  cuda:1         
INFO 01-06 17:11:21.822034.822034 lmp.py:627]   0          | 11         |  cuda:1         
INFO 01-06 17:11:21.822638.822638 lmp.py:627]   57         | 11         |  cuda:1         
INFO 01-06 17:11:21.822479.822479 lmp.py:627]   8          | 14         |  cuda:1         
INFO 01-06 17:11:21.822606.822606 lmp.py:628] ============================================================
INFO 01-06 17:11:21.822606.822606 lmp.py:628] 
INFO 01-06 17:11:21.822455.822455 lmp.py:630] experts_gpu_list: [1, 4, 7, 30, 33, 43, 5, 36, 42, 44, 48, 58, 61, 63, 21, 39, 56, 51, 62, 6, 54, 11, 45, 9, 34, 46, 18, 52, 55, 0, 57, 8] num: 32
INFO 01-06 17:11:21.822204.822204 lmp.py:631] experts_cpu_list: [16, 19, 20, 23, 32, 37, 38, 49, 53, 60, 12, 15, 27, 35, 47, 50, 59, 17, 28, 40, 41, 13, 22, 25] num: 24
INFO 01-06 17:11:21.822444.822444 lmp.py:632] expert_actual_device_map {0: 'cuda:1', 1: 'cuda:1', 2: 'cuda:1', 3: 'cuda:1', 4: 'cuda:1', 5: 'cuda:1', 6: 'cuda:1', 7: 'cuda:1', 8: 'cuda:1', 9: 'cuda:1', 10: 'meta', 11: 'cuda:1', 12: 'meta', 13: 'meta', 14: 'cuda:1', 15: 'meta', 16: 'meta', 17: 'meta', 18: 'cuda:1', 19: 'meta', 20: 'meta', 21: 'cuda:1', 22: 'meta', 23: 'meta', 24: 'meta', 25: 'meta', 26: 'meta', 27: 'meta', 28: 'meta', 29: 'cuda:1', 30: 'cuda:1', 31: 'cuda:1', 32: 'meta', 33: 'cuda:1', 34: 'cuda:1', 35: 'meta', 36: 'cuda:1', 37: 'meta', 38: 'meta', 39: 'cuda:1', 40: 'meta', 41: 'meta', 42: 'cuda:1', 43: 'cuda:1', 44: 'cuda:1', 45: 'cuda:1', 46: 'cuda:1', 47: 'meta', 48: 'cuda:1', 49: 'meta', 50: 'meta', 51: 'cuda:1', 52: 'cuda:1', 53: 'meta', 54: 'cuda:1', 55: 'cuda:1', 56: 'cuda:1', 57: 'cuda:1', 58: 'cuda:1', 59: 'meta', 60: 'meta', 61: 'cuda:1', 62: 'cuda:1', 63: 'cuda:1'}
DEBUG 01-06 17:11:21.822822.822822 cuda_h.py:19] end experts_map_get cost 0.002553224563598633 seconds
DEBUG 01-06 17:11:21.822706.822706 cuda_h.py:10] start gpu_sexperts
DEBUG 01-06 17:11:21.822771.822771 cuda_h.py:19] end gpu_sexperts cost 0.0003199577331542969 seconds
DEBUG 01-06 17:11:21.822409.822409 cuda_h.py:10] start gpu_experts
DEBUG 01-06 17:11:21.823392.823392 mlpmodule.py:533] gpu group tensors cost 0.0006110668182373047 s
INFO 01-06 17:11:21.823357.823357 client.py:127] Model loaded
DEBUG 01-06 17:11:21.824442.824442 mlpmodule.py:664]  experts func einsum cost 0.03241848945617676 s
DEBUG 01-06 17:11:21.825625.825625 cuda_h.py:19] end sllm_worker_task cost 0.012342453002929688 seconds
DEBUG 01-06 17:11:21.825889.825889 cuda_h.py:10] start sllm_worker_task
DEBUG 01-06 17:11:21.825705.825705 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 17:11:21.825820.825820 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 17:11:21.825417.825417 cuda_h.py:19] end allocate_cuda_memory cost 0.00019598007202148438 seconds
DEBUG 01-06 17:11:21.825386.825386 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 17:11:21.825288.825288 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 17:11:21.825766.825766 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 17:11:21.825370.825370 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, df49b616-7363-43ec-9a6f-ae7cd282cbfa
DEBUG 01-06 17:11:21.825895.825895 client.py:106] call stub.LoadModelAsync
DEBUG 01-06 17:11:21.826827.826827 mlpmodule.py:566] gpu pad cost 0.0032546520233154297 s
INFO 01-06 17:11:21.827425.827425 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, df49b616-7363-43ec-9a6f-ae7cd282cbfa
DEBUG 01-06 17:11:21.827685.827685 cuda_h.py:19] end load_into_gpu_async cost 0.001554727554321289 seconds
DEBUG 01-06 17:11:21.827003.827003 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 17:11:21.827602.827602 cuda_h.py:19] end restore_tensors2 cost 6.341934204101562e-05 seconds
DEBUG 01-06 17:11:21.827451.827451 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0020699501037597656 seconds
INFO 01-06 17:11:21.827579.827579 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, df49b616-7363-43ec-9a6f-ae7cd282cbfa
DEBUG 01-06 17:11:21.827953.827953 mlpmodule.py:584] gpu group einsum cost 0.0007207393646240234 s
DEBUG 01-06 17:11:21.830939.830939 mlpmodule.py:613] gpu experts func einsum cost 0.007647991180419922 s
DEBUG 01-06 17:11:21.830267.830267 cuda_h.py:19] end gpu_experts cost 0.007791996002197266 seconds
DEBUG 01-06 17:11:21.830831.830831 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-06 17:11:21.830295.830295 lmp.py:661] 
DEBUG 01-06 17:11:21.830295.830295 lmp.py:661]   Computing 24 experts on CPU...
DEBUG 01-06 17:11:21.830701.830701 cuda_h.py:19] end cpu_experts_submit cost 5.340576171875e-05 seconds
DEBUG 01-06 17:11:21.830020.830020 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-06 17:11:21.835286.835286 mlpmodule.py:706] group tensors cost 0.0042264461517333984 s
INFO 01-06 17:11:21.836838.836838 client.py:127] Model loaded
DEBUG 01-06 17:11:21.837637.837637 cuda_h.py:19] end sllm_worker_task cost 0.011987447738647461 seconds
DEBUG 01-06 17:11:21.837692.837692 cuda_h.py:10] start sllm_worker_task
DEBUG 01-06 17:11:21.837978.837978 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-06 17:11:21.837106.837106 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-06 17:11:21.837206.837206 cuda_h.py:19] end allocate_cuda_memory cost 0.0001773834228515625 seconds
DEBUG 01-06 17:11:21.837387.837387 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-06 17:11:21.837050.837050 sllm_store_c.py:27] get device uuid map
DEBUG 01-06 17:11:21.837628.837628 sllm_store_c.py:29] call client load into gpu
DEBUG 01-06 17:11:21.837900.837900 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 5353ebce-9963-45e8-a689-210391cf32d7
DEBUG 01-06 17:11:21.837856.837856 client.py:106] call stub.LoadModelAsync
DEBUG 01-06 17:11:21.838796.838796 mlpmodule.py:744] pad cost 0.002741575241088867 s
DEBUG 01-06 17:11:21.838165.838165 mlpmodule.py:750] create cpu tensor cost 4.649162292480469e-05 s
DEBUG 01-06 17:11:21.838605.838605 mlpmodule.py:755] move to cpu cost 3.337860107421875e-05 s
INFO 01-06 17:11:21.841910.841910 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 5353ebce-9963-45e8-a689-210391cf32d7
DEBUG 01-06 17:11:21.841338.841338 mlpmodule.py:769] group_w3: shape=torch.Size([24, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=69206016
DEBUG 01-06 17:11:21.842720.842720 cuda_h.py:19] end load_into_gpu_async cost 0.0043680667877197266 seconds
DEBUG 01-06 17:11:21.842836.842836 mlpmodule.py:770] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-06 17:11:21.842608.842608 cuda_h.py:10] start restore_tensors2
DEBUG 01-06 17:11:21.842149.842149 cuda_h.py:19] end restore_tensors2 cost 0.00014495849609375 seconds
DEBUG 01-06 17:11:21.842436.842436 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.005318641662597656 seconds
DEBUG 01-06 17:11:21.842749.842749 mlpmodule.py:775] group_w3 first element: -0.0294189453125
INFO 01-06 17:11:21.842880.842880 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 5353ebce-9963-45e8-a689-210391cf32d7
WARNING 01-06 17:11:21.843404.843404 mlpmodule.py:785] start einsum2
DEBUG 01-06 17:11:21.848226.848226 mlpmodule.py:795] group einsum cost 0.009996414184570312 s
DEBUG 01-06 17:11:21.848801.848801 mlpmodule.py:803] cpy2cputensor cost 8.177757263183594e-05 s
INFO 01-06 17:11:21.851749.851749 client.py:127] Model loaded
DEBUG 01-06 17:11:21.853616.853616 cuda_h.py:19] end wait_cetm_experts cost 0.022504806518554688 seconds
DEBUG 01-06 17:11:21.853611.853611 cuda_h.py:19] end sllm_worker_task cost 0.016114473342895508 seconds
DEBUG 01-06 17:11:21.853088.853088 cuda_h.py:19] end layer_moe_dgenerate_9 cost 0.0348055362701416 seconds
DEBUG 01-06 17:11:21.853008.853008 lmp.py:325] -------------------------------- end decode layer 9 --------------------------------
DEBUG 01-06 17:11:21.853063.853063 lmp.py:298] -------------------------------- start decode layer 10 --------------------------------
DEBUG 01-06 17:11:21.853527.853527 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-06 17:11:21.854841.854841 mlpmodule.py:367] cuda:1 cuda:1
DEBUG 01-06 17:11:21.854112.854112 cuda_h.py:10] start self_attn
cos shape torch.Size([65, 128]) sin shape torch.Size([65, 128]) position_ids tensor([[0]], device='cuda:1')
cos shape torch.Size([1, 1, 1, 128]) sin shape torch.Size([1, 1, 1, 128])
q_embed shape torch.Size([32, 16, 1, 128]) k_embed shape torch.Size([32, 16, 1, 128])
DEBUG 01-06 17:11:21.856634.856634 cuda_h.py:19] end self_attn cost 0.0018606185913085938 seconds
DEBUG 01-06 17:11:21.856692.856692 cuda_h.py:19] end iln_self_attn_paln cost 0.002720355987548828 seconds
DEBUG 01-06 17:11:21.856860.856860 cuda_h.py:10] start layer_moe_dgenerate_10
DEBUG 01-06 17:11:21.856537.856537 cuda_h.py:10] start gate
DEBUG 01-06 17:11:21.857882.857882 cuda_h.py:19] end gate cost 0.0006012916564941406 seconds
DEBUG 01-06 17:11:21.857480.857480 cuda_h.py:10] start experts_map_get
INFO 01-06 17:11:21.857657.857657 lmp.py:609] using loaded check layer: True
INFO 01-06 17:11:21.858121.858121 lmp.py:620] 
INFO 01-06 17:11:21.858121.858121 lmp.py:620] Layer 10 Expert Device Distribution:
INFO 01-06 17:11:21.858029.858029 lmp.py:621]   Active experts: 51 (out of 64 total)
INFO 01-06 17:11:21.858447.858447 lmp.py:622] 
INFO 01-06 17:11:21.858447.858447 lmp.py:622]   Detailed Expert Distribution:
INFO 01-06 17:11:21.858819.858819 lmp.py:623]   Expert ID  | Tokens     | Actual Device  
INFO 01-06 17:11:21.858376.858376 lmp.py:624]   ----------------------------------------------------------------------
INFO 01-06 17:11:21.858172.858172 lmp.py:627]   3          | 1          |  cuda:1         
INFO 01-06 17:11:21.858252.858252 lmp.py:627]   5          | 1          |  cuda:1         
INFO 01-06 17:11:21.858094.858094 lmp.py:627]   12         | 1          |  meta           
INFO 01-06 17:11:21.858174.858174 lmp.py:627]   18         | 1          |  cuda:1         
INFO 01-06 17:11:21.858778.858778 lmp.py:627]   23         | 1          |  cuda:1         
INFO 01-06 17:11:21.858620.858620 lmp.py:627]   34         | 1          |  meta           
INFO 01-06 17:11:21.858700.858700 lmp.py:627]   37         | 1          |  meta           
INFO 01-06 17:11:21.858780.858780 lmp.py:627]   52         | 1          |  meta           
INFO 01-06 17:11:21.858337.858337 lmp.py:627]   54         | 1          |  meta           
INFO 01-06 17:11:21.858464.858464 lmp.py:627]   56         | 1          |  meta           
INFO 01-06 17:11:21.858590.858590 lmp.py:627]   0          | 2          |  cuda:1         
INFO 01-06 17:11:21.858479.858479 lmp.py:627]   6          | 2          |  cuda:1         
INFO 01-06 17:11:21.858367.858367 lmp.py:627]   13         | 2          |  cuda:1         
INFO 01-06 17:11:21.858778.858778 lmp.py:627]   14         | 2          |  meta           
INFO 01-06 17:11:21.858858.858858 lmp.py:627]   16         | 2          |  cuda:1         
INFO 01-06 17:11:21.858177.858177 lmp.py:627]   22         | 2          |  meta           
INFO 01-06 17:11:21.858781.858781 lmp.py:627]   30         | 2          |  cuda:1         
INFO 01-06 17:11:21.858622.858622 lmp.py:627]   33         | 2          |  cuda:1         
INFO 01-06 17:11:21.859987.859987 lmp.py:627]   36         | 2          |  cuda:1         
INFO 01-06 17:11:21.859114.859114 lmp.py:627]   40         | 2          |  cuda:1         
INFO 01-06 17:11:21.859002.859002 lmp.py:627]   45         | 2          |  meta           
INFO 01-06 17:11:21.859890.859890 lmp.py:627]   57         | 2          |  meta           
INFO 01-06 17:11:21.859540.859540 lmp.py:627]   15         | 3          |  meta           
INFO 01-06 17:11:21.859144.859144 lmp.py:627]   17         | 3          |  meta           
INFO 01-06 17:11:21.859747.859747 lmp.py:627]   20         | 3          |  cuda:1         
INFO 01-06 17:11:21.859589.859589 lmp.py:627]   28         | 3          |  meta           
INFO 01-06 17:11:21.859192.859192 lmp.py:627]   35         | 3          |  cuda:1         
INFO 01-06 17:11:21.859557.859557 lmp.py:627]   44         | 3          |  cuda:1         
INFO 01-06 17:11:21.859446.859446 lmp.py:627]   55         | 3          |  meta           
INFO 01-06 17:11:21.859095.859095 lmp.py:627]   63         | 3          |  meta           
INFO 01-06 17:11:21.859984.859984 lmp.py:627]   4          | 4          |  cuda:1         
INFO 01-06 17:11:21.859633.859633 lmp.py:627]   8          | 4          |  cuda:1         
INFO 01-06 17:11:21.859237.859237 lmp.py:627]   9          | 4          |  cuda:1         
INFO 01-06 17:11:21.859079.859079 lmp.py:627]   31         | 4          |  meta           
INFO 01-06 17:11:21.859159.859159 lmp.py:627]   39         | 4          |  cuda:1         
INFO 01-06 17:11:21.859001.859001 lmp.py:627]   51         | 4          |  meta           
INFO 01-06 17:11:21.859650.859650 lmp.py:627]   58         | 4          |  cuda:1         
INFO 01-06 17:11:21.859539.859539 lmp.py:627]   60         | 4          |  meta           
INFO 01-06 17:11:21.859904.859904 lmp.py:627]   10         | 5          |  cuda:1         
INFO 01-06 17:11:21.859984.859984 lmp.py:627]   21         | 5          |  cuda:1         
INFO 01-06 17:11:21.859587.859587 lmp.py:627]   27         | 5          |  meta           
INFO 01-06 17:11:21.859668.859668 lmp.py:627]   32         | 5          |  cuda:1         
INFO 01-06 17:11:21.859510.859510 lmp.py:627]   53         | 6          |  cuda:1         
INFO 01-06 17:11:21.859636.859636 lmp.py:627]   24         | 7          |  cuda:1         
INFO 01-06 17:11:21.859524.859524 lmp.py:627]   41         | 7          |  cuda:1         
INFO 01-06 17:11:21.859174.859174 lmp.py:627]   46         | 7          |  cuda:1         
INFO 01-06 17:11:21.859539.859539 lmp.py:627]   11         | 8          |  cuda:1         
INFO 01-06 17:11:21.859189.859189 lmp.py:627]   1          | 9          |  cuda:1         
INFO 01-06 17:11:21.859031.859031 lmp.py:627]   59         | 12         |  cuda:1         
INFO 01-06 17:11:21.859111.859111 lmp.py:627]   49         | 13         |  cuda:1         
INFO 01-06 17:11:21.859714.859714 lmp.py:627]   62         | 13         |  cuda:1         
INFO 01-06 17:11:21.859126.859126 lmp.py:628] ============================================================
INFO 01-06 17:11:21.859126.859126 lmp.py:628] 
INFO 01-06 17:11:21.859498.859498 lmp.py:630] experts_gpu_list: [3, 5, 18, 23, 0, 6, 13, 16, 30, 33, 36, 40, 20, 35, 44, 4, 8, 9, 39, 58, 10, 21, 32, 53, 24, 41, 46, 11, 1, 59, 49, 62] num: 32
INFO 01-06 17:11:21.859532.859532 lmp.py:631] experts_cpu_list: [12, 34, 37, 52, 54, 56, 14, 22, 45, 57, 15, 17, 28, 55, 63, 31, 51, 60, 27] num: 19
INFO 01-06 17:11:21.859771.859771 lmp.py:632] expert_actual_device_map {0: 'cuda:1', 1: 'cuda:1', 2: 'cuda:1', 3: 'cuda:1', 4: 'cuda:1', 5: 'cuda:1', 6: 'cuda:1', 7: 'meta', 8: 'cuda:1', 9: 'cuda:1', 10: 'cuda:1', 11: 'cuda:1', 12: 'meta', 13: 'cuda:1', 14: 'meta', 15: 'meta', 16: 'cuda:1', 17: 'meta', 18: 'cuda:1', 19: 'meta', 20: 'cuda:1', 21: 'cuda:1', 22: 'meta', 23: 'cuda:1', 24: 'cuda:1', 25: 'cuda:1', 26: 'meta', 27: 'meta', 28: 'meta', 29: 'cuda:1', 30: 'cuda:1', 31: 'meta', 32: 'cuda:1', 33: 'cuda:1', 34: 'meta', 35: 'cuda:1', 36: 'cuda:1', 37: 'meta', 38: 'meta', 39: 'cuda:1', 40: 'cuda:1', 41: 'cuda:1', 42: 'cuda:1', 43: 'meta', 44: 'cuda:1', 45: 'meta', 46: 'cuda:1', 47: 'meta', 48: 'meta', 49: 'cuda:1', 50: 'cuda:1', 51: 'meta', 52: 'meta', 53: 'cuda:1', 54: 'meta', 55: 'meta', 56: 'meta', 57: 'meta', 58: 'cuda:1', 59: 'cuda:1', 60: 'meta', 61: 'meta', 62: 'cuda:1', 63: 'meta'}
DEBUG 01-06 17:11:21.859819.859819 cuda_h.py:19] end experts_map_get cost 0.002357959747314453 seconds
DEBUG 01-06 17:11:21.859649.859649 cuda_h.py:10] start gpu_sexperts
DEBUG 01-06 17:11:21.860562.860562 cuda_h.py:19] end gpu_sexperts cost 0.00031757354736328125 seconds
DEBUG 01-06 17:11:21.860690.860690 cuda_h.py:10] start gpu_experts
DEBUG 01-06 17:11:21.861627.861627 mlpmodule.py:533] gpu group tensors cost 0.0006196498870849609 s
DEBUG 01-06 17:11:21.862386.862386 mlpmodule.py:566] gpu pad cost 0.0016689300537109375 s
DEBUG 01-06 17:11:21.863101.863101 mlpmodule.py:584] gpu group einsum cost 0.0004999637603759766 s
DEBUG 01-06 17:11:21.866138.866138 mlpmodule.py:613] gpu experts func einsum cost 0.0061910152435302734 s
DEBUG 01-06 17:11:21.866068.866068 cuda_h.py:19] end gpu_experts cost 0.006322145462036133 seconds
DEBUG 01-06 17:11:21.866963.866963 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-06 17:11:21.866282.866282 lmp.py:661] 
DEBUG 01-06 17:11:21.866282.866282 lmp.py:661]   Computing 19 experts on CPU...
DEBUG 01-06 17:11:21.866688.866688 cuda_h.py:19] end cpu_experts_submit cost 4.792213439941406e-05 seconds
DEBUG 01-06 17:11:21.866238.866238 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-06 17:11:21.869976.869976 mlpmodule.py:664]  experts func einsum cost 0.03827643394470215 s
DEBUG 01-06 17:11:21.874761.874761 mlpmodule.py:706] group tensors cost 0.004953145980834961 s
DEBUG 01-06 17:11:21.876499.876499 mlpmodule.py:744] pad cost 0.0010769367218017578 s
DEBUG 01-06 17:11:21.876449.876449 mlpmodule.py:750] create cpu tensor cost 4.601478576660156e-05 s
DEBUG 01-06 17:11:21.876783.876783 mlpmodule.py:755] move to cpu cost 3.3855438232421875e-05 s
DEBUG 01-06 17:11:21.878418.878418 mlpmodule.py:769] group_w3: shape=torch.Size([19, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=54788096
DEBUG 01-06 17:11:21.878784.878784 mlpmodule.py:770] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-06 17:11:21.878581.878581 mlpmodule.py:775] group_w3 first element: 0.0498046875
WARNING 01-06 17:11:21.878650.878650 mlpmodule.py:785] start einsum2
DEBUG 01-06 17:11:21.882155.882155 mlpmodule.py:795] group einsum cost 0.005748271942138672 s
DEBUG 01-06 17:11:21.882697.882697 mlpmodule.py:803] cpy2cputensor cost 9.059906005859375e-05 s
DEBUG 01-06 17:11:21.884902.884902 cuda_h.py:19] end wait_cetm_experts cost 0.017970561981201172 seconds
DEBUG 01-06 17:11:21.885020.885020 cuda_h.py:19] end layer_moe_dgenerate_10 cost 0.028481721878051758 seconds
DEBUG 01-06 17:11:21.885788.885788 lmp.py:325] -------------------------------- end decode layer 10 --------------------------------
DEBUG 01-06 17:11:21.885749.885749 lmp.py:298] -------------------------------- start decode layer 11 --------------------------------
DEBUG 01-06 17:11:21.885790.885790 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-06 17:11:21.885092.885092 mlpmodule.py:367] cuda:1 cuda:1
DEBUG 01-06 17:11:21.886098.886098 cuda_h.py:10] start self_attn
cos shape torch.Size([65, 128]) sin shape torch.Size([65, 128]) position_ids tensor([[0]], device='cuda:1')
cos shape torch.Size([1, 1, 1, 128]) sin shape torch.Size([1, 1, 1, 128])
q_embed shape torch.Size([32, 16, 1, 128]) k_embed shape torch.Size([32, 16, 1, 128])
DEBUG 01-06 17:11:21.888651.888651 cuda_h.py:19] end self_attn cost 0.0019872188568115234 seconds
DEBUG 01-06 17:11:21.888387.888387 cuda_h.py:19] end iln_self_attn_paln cost 0.002963542938232422 seconds
DEBUG 01-06 17:11:21.888330.888330 cuda_h.py:10] start layer_moe_dgenerate_11
DEBUG 01-06 17:11:21.888775.888775 cuda_h.py:10] start gate
DEBUG 01-06 17:11:21.889023.889023 cuda_h.py:19] end gate cost 0.0006306171417236328 seconds
DEBUG 01-06 17:11:21.889343.889343 cuda_h.py:10] start experts_map_get
INFO 01-06 17:11:21.889368.889368 lmp.py:609] using loaded check layer: True
INFO 01-06 17:11:21.890363.890363 lmp.py:620] 
INFO 01-06 17:11:21.890363.890363 lmp.py:620] Layer 11 Expert Device Distribution:
INFO 01-06 17:11:21.890517.890517 lmp.py:621]   Active experts: 52 (out of 64 total)
INFO 01-06 17:11:21.890796.890796 lmp.py:622] 
INFO 01-06 17:11:21.890796.890796 lmp.py:622]   Detailed Expert Distribution:
INFO 01-06 17:11:21.890075.890075 lmp.py:623]   Expert ID  | Tokens     | Actual Device  
INFO 01-06 17:11:21.890539.890539 lmp.py:624]   ----------------------------------------------------------------------
INFO 01-06 17:11:21.890958.890958 lmp.py:627]   0          | 1          |  cuda:1         
INFO 01-06 17:11:21.890945.890945 lmp.py:627]   5          | 1          |  cuda:1         
INFO 01-06 17:11:21.890694.890694 lmp.py:627]   6          | 1          |  cuda:1         
INFO 01-06 17:11:21.890967.890967 lmp.py:627]   9          | 1          |  cuda:1         
INFO 01-06 17:11:21.890954.890954 lmp.py:627]   11         | 1          |  cuda:1         
INFO 01-06 17:11:21.890465.890465 lmp.py:627]   21         | 1          |  cuda:1         
INFO 01-06 17:11:21.890499.890499 lmp.py:627]   30         | 1          |  cuda:1         
INFO 01-06 17:11:21.890964.890964 lmp.py:627]   32         | 1          |  meta           
INFO 01-06 17:11:21.890998.890998 lmp.py:627]   33         | 1          |  meta           
INFO 01-06 17:11:21.890270.890270 lmp.py:627]   35         | 1          |  meta           
INFO 01-06 17:11:21.890019.890019 lmp.py:627]   36         | 1          |  meta           
INFO 01-06 17:11:21.890768.890768 lmp.py:627]   37         | 1          |  cuda:1         
INFO 01-06 17:11:21.890564.890564 lmp.py:627]   38         | 1          |  meta           
INFO 01-06 17:11:21.890075.890075 lmp.py:627]   41         | 1          |  meta           
INFO 01-06 17:11:21.890778.890778 lmp.py:627]   46         | 1          |  meta           
INFO 01-06 17:11:21.890719.890719 lmp.py:627]   49         | 1          |  meta           
INFO 01-06 17:11:21.890422.890422 lmp.py:627]   58         | 1          |  cuda:1         
INFO 01-06 17:11:21.890694.890694 lmp.py:627]   63         | 1          |  meta           
INFO 01-06 17:11:21.891728.891728 lmp.py:627]   15         | 2          |  meta           
INFO 01-06 17:11:21.891762.891762 lmp.py:627]   17         | 2          |  meta           
INFO 01-06 17:11:21.891557.891557 lmp.py:627]   31         | 2          |  meta           
INFO 01-06 17:11:21.891353.891353 lmp.py:627]   42         | 2          |  meta           
INFO 01-06 17:11:21.891387.891387 lmp.py:627]   50         | 2          |  meta           
INFO 01-06 17:11:21.891898.891898 lmp.py:627]   52         | 2          |  cuda:1         
INFO 01-06 17:11:21.891885.891885 lmp.py:627]   55         | 2          |  cuda:1         
INFO 01-06 17:11:21.891919.891919 lmp.py:627]   61         | 2          |  meta           
INFO 01-06 17:11:21.891953.891953 lmp.py:627]   2          | 3          |  cuda:1         
INFO 01-06 17:11:21.891510.891510 lmp.py:627]   16         | 3          |  meta           
INFO 01-06 17:11:21.891306.891306 lmp.py:627]   18         | 3          |  meta           
INFO 01-06 17:11:21.891340.891340 lmp.py:627]   34         | 3          |  cuda:1         
INFO 01-06 17:11:21.891374.891374 lmp.py:627]   40         | 3          |  meta           
INFO 01-06 17:11:21.891838.891838 lmp.py:627]   45         | 3          |  cuda:1         
INFO 01-06 17:11:21.891349.891349 lmp.py:627]   47         | 3          |  cuda:1         
INFO 01-06 17:11:21.891145.891145 lmp.py:627]   51         | 3          |  cuda:1         
INFO 01-06 17:11:21.891417.891417 lmp.py:627]   57         | 3          |  cuda:1         
INFO 01-06 17:11:21.891974.891974 lmp.py:627]   59         | 3          |  meta           
INFO 01-06 17:11:21.891770.891770 lmp.py:627]   60         | 3          |  cuda:1         
INFO 01-06 17:11:21.891088.891088 lmp.py:627]   14         | 4          |  cuda:1         
INFO 01-06 17:11:21.891122.891122 lmp.py:627]   27         | 4          |  cuda:1         
INFO 01-06 17:11:21.891871.891871 lmp.py:627]   44         | 4          |  meta           
INFO 01-06 17:11:21.891336.891336 lmp.py:627]   56         | 4          |  cuda:1         
INFO 01-06 17:11:21.891131.891131 lmp.py:627]   62         | 4          |  meta           
INFO 01-06 17:11:21.891927.891927 lmp.py:627]   25         | 5          |  cuda:1         
INFO 01-06 17:11:21.891676.891676 lmp.py:627]   54         | 6          |  cuda:1         
INFO 01-06 17:11:21.891995.891995 lmp.py:627]   22         | 8          |  cuda:1         
INFO 01-06 17:11:21.891029.891029 lmp.py:627]   29         | 8          |  cuda:1         
INFO 01-06 17:11:21.891063.891063 lmp.py:627]   8          | 9          |  cuda:1         
INFO 01-06 17:11:21.891097.891097 lmp.py:627]   4          | 11         |  cuda:1         
INFO 01-06 17:11:21.891323.891323 lmp.py:627]   7          | 11         |  cuda:1         
INFO 01-06 17:11:21.891118.891118 lmp.py:627]   12         | 11         |  cuda:1         
INFO 01-06 17:11:21.891152.891152 lmp.py:627]   1          | 13         |  cuda:1         
INFO 01-06 17:11:21.891709.891709 lmp.py:627]   28         | 23         |  cuda:1         
INFO 01-06 17:11:21.891267.891267 lmp.py:628] ============================================================
INFO 01-06 17:11:21.891267.891267 lmp.py:628] 
INFO 01-06 17:11:21.891546.891546 lmp.py:630] experts_gpu_list: [0, 5, 6, 9, 11, 21, 30, 37, 58, 52, 55, 2, 34, 45, 47, 51, 57, 60, 14, 27, 56, 25, 54, 22, 29, 8, 4, 7, 12, 1, 28] num: 31
INFO 01-06 17:11:21.891441.891441 lmp.py:631] experts_cpu_list: [32, 33, 35, 36, 38, 41, 46, 49, 63, 15, 17, 31, 42, 50, 61, 16, 18, 40, 59, 44, 62] num: 21
INFO 01-06 17:11:21.891018.891018 lmp.py:632] expert_actual_device_map {0: 'cuda:1', 1: 'cuda:1', 2: 'cuda:1', 3: 'cuda:1', 4: 'cuda:1', 5: 'cuda:1', 6: 'cuda:1', 7: 'cuda:1', 8: 'cuda:1', 9: 'cuda:1', 10: 'cuda:1', 11: 'cuda:1', 12: 'cuda:1', 13: 'cuda:1', 14: 'cuda:1', 15: 'meta', 16: 'meta', 17: 'meta', 18: 'meta', 19: 'meta', 20: 'meta', 21: 'cuda:1', 22: 'cuda:1', 23: 'meta', 24: 'cuda:1', 25: 'cuda:1', 26: 'meta', 27: 'cuda:1', 28: 'cuda:1', 29: 'cuda:1', 30: 'cuda:1', 31: 'meta', 32: 'meta', 33: 'meta', 34: 'cuda:1', 35: 'meta', 36: 'meta', 37: 'cuda:1', 38: 'meta', 39: 'meta', 40: 'meta', 41: 'meta', 42: 'meta', 43: 'meta', 44: 'meta', 45: 'cuda:1', 46: 'meta', 47: 'cuda:1', 48: 'cuda:1', 49: 'meta', 50: 'meta', 51: 'cuda:1', 52: 'cuda:1', 53: 'cuda:1', 54: 'cuda:1', 55: 'cuda:1', 56: 'cuda:1', 57: 'cuda:1', 58: 'cuda:1', 59: 'meta', 60: 'cuda:1', 61: 'meta', 62: 'meta', 63: 'meta'}
DEBUG 01-06 17:11:21.892357.892357 cuda_h.py:19] end experts_map_get cost 0.002572298049926758 seconds
DEBUG 01-06 17:11:21.892201.892201 cuda_h.py:10] start gpu_sexperts
DEBUG 01-06 17:11:21.892136.892136 cuda_h.py:19] end gpu_sexperts cost 0.00035858154296875 seconds
DEBUG 01-06 17:11:21.892442.892442 cuda_h.py:10] start gpu_experts
DEBUG 01-06 17:11:21.893571.893571 mlpmodule.py:533] gpu group tensors cost 0.0006177425384521484 s
DEBUG 01-06 17:11:21.894230.894230 mlpmodule.py:664]  experts func einsum cost 0.025122880935668945 s
DEBUG 01-06 17:11:21.895581.895581 mlpmodule.py:566] gpu pad cost 0.001806020736694336 s
DEBUG 01-06 17:11:21.895071.895071 mlpmodule.py:584] gpu group einsum cost 0.0004942417144775391 s
DEBUG 01-06 17:11:21.898054.898054 mlpmodule.py:613] gpu experts func einsum cost 0.006343364715576172 s
DEBUG 01-06 17:11:21.899322.899322 cuda_h.py:19] end gpu_experts cost 0.00647735595703125 seconds
DEBUG 01-06 17:11:21.899555.899555 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-06 17:11:21.899304.899304 lmp.py:661] 
DEBUG 01-06 17:11:21.899304.899304 lmp.py:661]   Computing 21 experts on CPU...
DEBUG 01-06 17:11:21.899386.899386 cuda_h.py:19] end cpu_experts_submit cost 5.8650970458984375e-05 seconds
DEBUG 01-06 17:11:21.899228.899228 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-06 17:11:21.907209.907209 mlpmodule.py:706] group tensors cost 0.008179903030395508 s
DEBUG 01-06 17:11:21.909128.909128 mlpmodule.py:744] pad cost 0.0011222362518310547 s
DEBUG 01-06 17:11:21.909317.909317 mlpmodule.py:750] create cpu tensor cost 4.57763671875e-05 s
DEBUG 01-06 17:11:21.909551.909551 mlpmodule.py:755] move to cpu cost 3.170967102050781e-05 s
DEBUG 01-06 17:11:21.912472.912472 mlpmodule.py:769] group_w3: shape=torch.Size([21, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=60555264
DEBUG 01-06 17:11:21.912222.912222 mlpmodule.py:770] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-06 17:11:21.912774.912774 mlpmodule.py:775] group_w3 first element: 0.0096435546875
WARNING 01-06 17:11:21.912604.912604 mlpmodule.py:785] start einsum2
DEBUG 01-06 17:11:21.917231.917231 mlpmodule.py:795] group einsum cost 0.008222341537475586 s
DEBUG 01-06 17:11:21.917753.917753 mlpmodule.py:803] cpy2cputensor cost 6.866455078125e-05 s
DEBUG 01-06 17:11:21.920094.920094 cuda_h.py:19] end wait_cetm_experts cost 0.021613359451293945 seconds
DEBUG 01-06 17:11:21.921533.921533 cuda_h.py:19] end layer_moe_dgenerate_11 cost 0.03271126747131348 seconds
DEBUG 01-06 17:11:21.921488.921488 lmp.py:325] -------------------------------- end decode layer 11 --------------------------------
DEBUG 01-06 17:11:21.921623.921623 lmp.py:298] -------------------------------- start decode layer 12 --------------------------------
DEBUG 01-06 17:11:21.921744.921744 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-06 17:11:21.921345.921345 mlpmodule.py:367] cuda:1 cuda:1
DEBUG 01-06 17:11:21.922363.922363 cuda_h.py:10] start self_attn
cos shape torch.Size([65, 128]) sin shape torch.Size([65, 128]) position_ids tensor([[0]], device='cuda:1')
cos shape torch.Size([1, 1, 1, 128]) sin shape torch.Size([1, 1, 1, 128])
q_embed shape torch.Size([32, 16, 1, 128]) k_embed shape torch.Size([32, 16, 1, 128])
DEBUG 01-06 17:11:21.924074.924074 cuda_h.py:19] end self_attn cost 0.0021543502807617188 seconds
DEBUG 01-06 17:11:21.925344.925344 cuda_h.py:19] end iln_self_attn_paln cost 0.003233194351196289 seconds
DEBUG 01-06 17:11:21.925803.925803 cuda_h.py:10] start layer_moe_dgenerate_12
DEBUG 01-06 17:11:21.925718.925718 cuda_h.py:10] start gate
DEBUG 01-06 17:11:21.925363.925363 cuda_h.py:19] end gate cost 0.0006086826324462891 seconds
DEBUG 01-06 17:11:21.925967.925967 cuda_h.py:10] start experts_map_get
INFO 01-06 17:11:21.926528.926528 lmp.py:609] using loaded check layer: True
INFO 01-06 17:11:21.926899.926899 lmp.py:620] 
INFO 01-06 17:11:21.926899.926899 lmp.py:620] Layer 12 Expert Device Distribution:
INFO 01-06 17:11:21.926430.926430 lmp.py:621]   Active experts: 49 (out of 64 total)
INFO 01-06 17:11:21.926610.926610 lmp.py:622] 
INFO 01-06 17:11:21.926610.926610 lmp.py:622]   Detailed Expert Distribution:
INFO 01-06 17:11:21.926743.926743 lmp.py:623]   Expert ID  | Tokens     | Actual Device  
INFO 01-06 17:11:21.926585.926585 lmp.py:624]   ----------------------------------------------------------------------
INFO 01-06 17:11:21.926050.926050 lmp.py:627]   4          | 1          |  cuda:1         
INFO 01-06 17:11:21.926322.926322 lmp.py:627]   11         | 1          |  meta           
INFO 01-06 17:11:21.926164.926164 lmp.py:627]   16         | 1          |  meta           
INFO 01-06 17:11:21.927529.927529 lmp.py:627]   17         | 1          |  meta           
INFO 01-06 17:11:21.927417.927417 lmp.py:627]   22         | 1          |  meta           
INFO 01-06 17:11:21.927021.927021 lmp.py:627]   25         | 1          |  cuda:1         
INFO 01-06 17:11:21.927101.927101 lmp.py:627]   32         | 1          |  meta           
INFO 01-06 17:11:21.927943.927943 lmp.py:627]   33         | 1          |  cuda:1         
INFO 01-06 17:11:21.927261.927261 lmp.py:627]   34         | 1          |  meta           
INFO 01-06 17:11:21.927626.927626 lmp.py:627]   38         | 1          |  meta           
INFO 01-06 17:11:21.927753.927753 lmp.py:627]   42         | 1          |  cuda:1         
INFO 01-06 17:11:21.927880.927880 lmp.py:627]   47         | 1          |  meta           
INFO 01-06 17:11:21.927245.927245 lmp.py:627]   49         | 1          |  cuda:1         
INFO 01-06 17:11:21.927610.927610 lmp.py:627]   55         | 1          |  cuda:1         
INFO 01-06 17:11:21.927690.927690 lmp.py:627]   14         | 2          |  meta           
INFO 01-06 17:11:21.927770.927770 lmp.py:627]   20         | 2          |  meta           
INFO 01-06 17:11:21.927374.927374 lmp.py:627]   21         | 2          |  meta           
INFO 01-06 17:11:21.927215.927215 lmp.py:627]   24         | 2          |  cuda:1         
INFO 01-06 17:11:21.927057.927057 lmp.py:627]   39         | 2          |  meta           
INFO 01-06 17:11:21.927184.927184 lmp.py:627]   50         | 2          |  cuda:1         
INFO 01-06 17:11:21.927072.927072 lmp.py:627]   52         | 2          |  meta           
INFO 01-06 17:11:21.927437.927437 lmp.py:627]   53         | 2          |  meta           
INFO 01-06 17:11:21.927564.927564 lmp.py:627]   57         | 2          |  meta           
INFO 01-06 17:11:21.927644.927644 lmp.py:627]   58         | 2          |  cuda:1         
INFO 01-06 17:11:21.927486.927486 lmp.py:627]   59         | 2          |  cuda:1         
INFO 01-06 17:11:21.927566.927566 lmp.py:627]   2          | 3          |  cuda:1         
INFO 01-06 17:11:21.927408.927408 lmp.py:627]   5          | 3          |  cuda:1         
INFO 01-06 17:11:21.927773.927773 lmp.py:627]   6          | 3          |  cuda:1         
INFO 01-06 17:11:21.927423.927423 lmp.py:627]   28         | 3          |  cuda:1         
INFO 01-06 17:11:21.927311.927311 lmp.py:627]   31         | 3          |  cuda:1         
INFO 01-06 17:11:21.927961.927961 lmp.py:627]   44         | 3          |  meta           
INFO 01-06 17:11:21.927087.927087 lmp.py:627]   48         | 3          |  cuda:1         
INFO 01-06 17:11:21.927452.927452 lmp.py:627]   54         | 3          |  cuda:1         
INFO 01-06 17:11:21.927294.927294 lmp.py:627]   62         | 3          |  cuda:1         
INFO 01-06 17:11:21.927898.927898 lmp.py:627]   63         | 3          |  meta           
INFO 01-06 17:11:21.927740.927740 lmp.py:627]   43         | 4          |  meta           
INFO 01-06 17:11:21.927820.927820 lmp.py:627]   46         | 4          |  cuda:1         
INFO 01-06 17:11:21.927185.927185 lmp.py:627]   18         | 5          |  cuda:1         
INFO 01-06 17:11:21.927550.927550 lmp.py:627]   35         | 5          |  cuda:1         
INFO 01-06 17:11:21.927961.927961 lmp.py:627]   51         | 5          |  cuda:1         
INFO 01-06 17:11:21.927088.927088 lmp.py:627]   45         | 6          |  meta           
INFO 01-06 17:11:21.927930.927930 lmp.py:627]   56         | 6          |  cuda:1         
INFO 01-06 17:11:21.927772.927772 lmp.py:627]   60         | 6          |  meta           
INFO 01-06 17:11:21.927137.927137 lmp.py:627]   10         | 8          |  cuda:1         
INFO 01-06 17:11:21.927978.927978 lmp.py:627]   41         | 9          |  cuda:1         
INFO 01-06 17:11:21.927343.927343 lmp.py:627]   26         | 10         |  cuda:1         
INFO 01-06 17:11:21.928470.928470 lmp.py:627]   3          | 15         |  cuda:1         
INFO 01-06 17:11:21.928358.928358 lmp.py:627]   15         | 17         |  cuda:1         
INFO 01-06 17:11:21.928723.928723 lmp.py:627]   40         | 26         |  cuda:1         
INFO 01-06 17:11:21.928419.928419 lmp.py:628] ============================================================
INFO 01-06 17:11:21.928419.928419 lmp.py:628] 
INFO 01-06 17:11:21.928698.928698 lmp.py:630] experts_gpu_list: [4, 25, 33, 42, 49, 55, 24, 50, 58, 59, 2, 5, 6, 28, 31, 48, 54, 62, 46, 18, 35, 51, 56, 10, 41, 26, 3, 15, 40] num: 29
INFO 01-06 17:11:21.928640.928640 lmp.py:631] experts_cpu_list: [11, 16, 17, 22, 32, 34, 38, 47, 14, 20, 21, 39, 52, 53, 57, 44, 63, 43, 45, 60] num: 20
INFO 01-06 17:11:21.928456.928456 lmp.py:632] expert_actual_device_map {0: 'cuda:1', 1: 'cuda:1', 2: 'cuda:1', 3: 'cuda:1', 4: 'cuda:1', 5: 'cuda:1', 6: 'cuda:1', 7: 'cuda:1', 8: 'cuda:1', 9: 'cuda:1', 10: 'cuda:1', 11: 'meta', 12: 'meta', 13: 'meta', 14: 'meta', 15: 'cuda:1', 16: 'meta', 17: 'meta', 18: 'cuda:1', 19: 'cuda:1', 20: 'meta', 21: 'meta', 22: 'meta', 23: 'meta', 24: 'cuda:1', 25: 'cuda:1', 26: 'cuda:1', 27: 'meta', 28: 'cuda:1', 29: 'cuda:1', 30: 'meta', 31: 'cuda:1', 32: 'meta', 33: 'cuda:1', 34: 'meta', 35: 'cuda:1', 36: 'cuda:1', 37: 'meta', 38: 'meta', 39: 'meta', 40: 'cuda:1', 41: 'cuda:1', 42: 'cuda:1', 43: 'meta', 44: 'meta', 45: 'meta', 46: 'cuda:1', 47: 'meta', 48: 'cuda:1', 49: 'cuda:1', 50: 'cuda:1', 51: 'cuda:1', 52: 'meta', 53: 'meta', 54: 'cuda:1', 55: 'cuda:1', 56: 'cuda:1', 57: 'meta', 58: 'cuda:1', 59: 'cuda:1', 60: 'meta', 61: 'meta', 62: 'cuda:1', 63: 'meta'}
DEBUG 01-06 17:11:21.928457.928457 cuda_h.py:19] end experts_map_get cost 0.0023283958435058594 seconds
DEBUG 01-06 17:11:21.928268.928268 cuda_h.py:10] start gpu_sexperts
DEBUG 01-06 17:11:21.928481.928481 cuda_h.py:19] end gpu_sexperts cost 0.0003426074981689453 seconds
DEBUG 01-06 17:11:21.928270.928270 cuda_h.py:10] start gpu_experts
DEBUG 01-06 17:11:21.929253.929253 mlpmodule.py:533] gpu group tensors cost 0.0005819797515869141 s
DEBUG 01-06 17:11:21.930175.930175 mlpmodule.py:664]  experts func einsum cost 0.03153705596923828 s
DEBUG 01-06 17:11:21.931385.931385 mlpmodule.py:566] gpu pad cost 0.0017201900482177734 s
DEBUG 01-06 17:11:21.931057.931057 mlpmodule.py:584] gpu group einsum cost 0.00038361549377441406 s
DEBUG 01-06 17:11:21.934517.934517 mlpmodule.py:613] gpu experts func einsum cost 0.005900144577026367 s
DEBUG 01-06 17:11:21.934130.934130 cuda_h.py:19] end gpu_experts cost 0.0060427188873291016 seconds
DEBUG 01-06 17:11:21.934939.934939 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-06 17:11:21.934171.934171 lmp.py:661] 
DEBUG 01-06 17:11:21.934171.934171 lmp.py:661]   Computing 20 experts on CPU...
DEBUG 01-06 17:11:21.934882.934882 cuda_h.py:19] end cpu_experts_submit cost 6.699562072753906e-05 seconds
DEBUG 01-06 17:11:21.935777.935777 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-06 17:11:21.939982.939982 mlpmodule.py:706] group tensors cost 0.004171133041381836 s
DEBUG 01-06 17:11:21.941250.941250 mlpmodule.py:744] pad cost 0.0010743141174316406 s
DEBUG 01-06 17:11:21.941783.941783 mlpmodule.py:750] create cpu tensor cost 4.506111145019531e-05 s
DEBUG 01-06 17:11:21.941017.941017 mlpmodule.py:755] move to cpu cost 3.170967102050781e-05 s
DEBUG 01-06 17:11:21.943352.943352 mlpmodule.py:769] group_w3: shape=torch.Size([20, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=57671680
DEBUG 01-06 17:11:21.943387.943387 mlpmodule.py:770] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-06 17:11:21.943223.943223 mlpmodule.py:775] group_w3 first element: 0.034423828125
WARNING 01-06 17:11:21.944551.944551 mlpmodule.py:785] start einsum2
DEBUG 01-06 17:11:21.948464.948464 mlpmodule.py:795] group einsum cost 0.007555961608886719 s
DEBUG 01-06 17:11:21.948892.948892 mlpmodule.py:803] cpy2cputensor cost 6.651878356933594e-05 s
DEBUG 01-06 17:11:21.951901.951901 cuda_h.py:19] end wait_cetm_experts cost 0.016644716262817383 seconds
DEBUG 01-06 17:11:21.952636.952636 cuda_h.py:19] end layer_moe_dgenerate_12 cost 0.027010202407836914 seconds
DEBUG 01-06 17:11:21.952933.952933 lmp.py:325] -------------------------------- end decode layer 12 --------------------------------
DEBUG 01-06 17:11:21.952929.952929 lmp.py:298] -------------------------------- start decode layer 13 --------------------------------
DEBUG 01-06 17:11:21.952122.952122 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-06 17:11:21.952398.952398 mlpmodule.py:367] cuda:1 cuda:1
DEBUG 01-06 17:11:21.953651.953651 cuda_h.py:10] start self_attn
cos shape torch.Size([65, 128]) sin shape torch.Size([65, 128]) position_ids tensor([[0]], device='cuda:1')
cos shape torch.Size([1, 1, 1, 128]) sin shape torch.Size([1, 1, 1, 128])
q_embed shape torch.Size([32, 16, 1, 128]) k_embed shape torch.Size([32, 16, 1, 128])
DEBUG 01-06 17:11:21.955111.955111 cuda_h.py:19] end self_attn cost 0.0019855499267578125 seconds
DEBUG 01-06 17:11:21.955851.955851 cuda_h.py:19] end iln_self_attn_paln cost 0.002918243408203125 seconds
DEBUG 01-06 17:11:21.955495.955495 cuda_h.py:10] start layer_moe_dgenerate_13
DEBUG 01-06 17:11:21.955741.955741 cuda_h.py:10] start gate
DEBUG 01-06 17:11:21.956538.956538 cuda_h.py:19] end gate cost 0.0006167888641357422 seconds
DEBUG 01-06 17:11:21.956189.956189 cuda_h.py:10] start experts_map_get
INFO 01-06 17:11:21.956220.956220 lmp.py:609] using loaded check layer: True
INFO 01-06 17:11:21.957829.957829 lmp.py:620] 
INFO 01-06 17:11:21.957829.957829 lmp.py:620] Layer 13 Expert Device Distribution:
INFO 01-06 17:11:21.957307.957307 lmp.py:621]   Active experts: 47 (out of 64 total)
INFO 01-06 17:11:21.957772.957772 lmp.py:622] 
INFO 01-06 17:11:21.957772.957772 lmp.py:622]   Detailed Expert Distribution:
INFO 01-06 17:11:21.957428.957428 lmp.py:623]   Expert ID  | Tokens     | Actual Device  
INFO 01-06 17:11:21.957986.957986 lmp.py:624]   ----------------------------------------------------------------------
INFO 01-06 17:11:21.957735.957735 lmp.py:627]   1          | 1          |  cuda:1         
INFO 01-06 17:11:21.957530.957530 lmp.py:627]   11         | 1          |  meta           
INFO 01-06 17:11:21.957895.957895 lmp.py:627]   18         | 1          |  meta           
INFO 01-06 17:11:21.957976.957976 lmp.py:627]   22         | 1          |  cuda:1         
INFO 01-06 17:11:21.957579.957579 lmp.py:627]   25         | 1          |  cuda:1         
INFO 01-06 17:11:21.957182.957182 lmp.py:627]   30         | 1          |  meta           
INFO 01-06 17:11:21.957548.957548 lmp.py:627]   37         | 1          |  cuda:1         
INFO 01-06 17:11:21.957389.957389 lmp.py:627]   40         | 1          |  meta           
INFO 01-06 17:11:21.957470.957470 lmp.py:627]   53         | 1          |  meta           
INFO 01-06 17:11:21.957504.957504 lmp.py:627]   57         | 1          |  cuda:1         
INFO 01-06 17:11:21.957107.957107 lmp.py:627]   61         | 1          |  meta           
INFO 01-06 17:11:21.957710.957710 lmp.py:627]   2          | 2          |  cuda:1         
INFO 01-06 17:11:21.957599.957599 lmp.py:627]   4          | 2          |  cuda:1         
INFO 01-06 17:11:21.957725.957725 lmp.py:627]   14         | 2          |  cuda:1         
INFO 01-06 17:11:21.957852.957852 lmp.py:627]   20         | 2          |  meta           
INFO 01-06 17:11:21.957932.957932 lmp.py:627]   28         | 2          |  cuda:1         
INFO 01-06 17:11:21.957728.957728 lmp.py:627]   35         | 2          |  meta           
INFO 01-06 17:11:21.957285.957285 lmp.py:627]   36         | 2          |  cuda:1         
INFO 01-06 17:11:21.957411.957411 lmp.py:627]   51         | 2          |  cuda:1         
INFO 01-06 17:11:21.957061.957061 lmp.py:627]   62         | 2          |  cuda:1         
INFO 01-06 17:11:21.957949.957949 lmp.py:627]   8          | 3          |  cuda:1         
INFO 01-06 17:11:21.957076.957076 lmp.py:627]   10         | 3          |  meta           
INFO 01-06 17:11:21.957203.957203 lmp.py:627]   16         | 3          |  cuda:1         
INFO 01-06 17:11:21.957806.957806 lmp.py:627]   23         | 3          |  cuda:1         
INFO 01-06 17:11:21.957886.957886 lmp.py:627]   29         | 3          |  cuda:1         
INFO 01-06 17:11:21.957490.957490 lmp.py:627]   34         | 3          |  meta           
INFO 01-06 17:11:21.957855.957855 lmp.py:627]   48         | 3          |  meta           
INFO 01-06 17:11:21.957743.957743 lmp.py:627]   3          | 4          |  cuda:1         
INFO 01-06 17:11:21.957869.957869 lmp.py:627]   9          | 4          |  meta           
INFO 01-06 17:11:21.957473.957473 lmp.py:627]   24         | 4          |  cuda:1         
INFO 01-06 17:11:21.957884.957884 lmp.py:627]   41         | 4          |  cuda:1         
INFO 01-06 17:11:21.958772.958772 lmp.py:627]   44         | 4          |  cuda:1         
INFO 01-06 17:11:21.958091.958091 lmp.py:627]   46         | 4          |  meta           
INFO 01-06 17:11:21.958171.958171 lmp.py:627]   47         | 4          |  cuda:1         
INFO 01-06 17:11:21.958729.958729 lmp.py:627]   54         | 4          |  cuda:1         
INFO 01-06 17:11:21.958617.958617 lmp.py:627]   55         | 4          |  meta           
INFO 01-06 17:11:21.958743.958743 lmp.py:627]   63         | 4          |  meta           
INFO 01-06 17:11:21.958632.958632 lmp.py:627]   38         | 6          |  cuda:1         
INFO 01-06 17:11:21.958520.958520 lmp.py:627]   52         | 6          |  cuda:1         
INFO 01-06 17:11:21.958408.958408 lmp.py:627]   27         | 8          |  cuda:1         
INFO 01-06 17:11:21.958727.958727 lmp.py:627]   17         | 9          |  cuda:1         
INFO 01-06 17:11:21.958568.958568 lmp.py:627]   49         | 9          |  cuda:1         
INFO 01-06 17:11:21.958172.958172 lmp.py:627]   59         | 9          |  meta           
INFO 01-06 17:11:21.958967.958967 lmp.py:627]   60         | 10         |  cuda:1         
INFO 01-06 17:11:21.958856.958856 lmp.py:627]   56         | 11         |  meta           
INFO 01-06 17:11:21.958903.958903 lmp.py:627]   15         | 13         |  cuda:1         
INFO 01-06 17:11:21.958030.958030 lmp.py:627]   45         | 21         |  cuda:1         
INFO 01-06 17:11:21.958156.958156 lmp.py:628] ============================================================
INFO 01-06 17:11:21.958156.958156 lmp.py:628] 
INFO 01-06 17:11:21.958290.958290 lmp.py:630] experts_gpu_list: [1, 22, 25, 37, 57, 2, 4, 14, 28, 36, 51, 62, 8, 16, 23, 29, 3, 24, 41, 44, 47, 54, 38, 52, 27, 17, 49, 60, 15, 45] num: 30
INFO 01-06 17:11:21.958324.958324 lmp.py:631] experts_cpu_list: [11, 18, 30, 40, 53, 61, 20, 35, 10, 34, 48, 9, 46, 55, 63, 59, 56] num: 17
INFO 01-06 17:11:21.958232.958232 lmp.py:632] expert_actual_device_map {0: 'cuda:1', 1: 'cuda:1', 2: 'cuda:1', 3: 'cuda:1', 4: 'cuda:1', 5: 'cuda:1', 6: 'cuda:1', 7: 'cuda:1', 8: 'cuda:1', 9: 'meta', 10: 'meta', 11: 'meta', 12: 'meta', 13: 'meta', 14: 'cuda:1', 15: 'cuda:1', 16: 'cuda:1', 17: 'cuda:1', 18: 'meta', 19: 'meta', 20: 'meta', 21: 'cuda:1', 22: 'cuda:1', 23: 'cuda:1', 24: 'cuda:1', 25: 'cuda:1', 26: 'meta', 27: 'cuda:1', 28: 'cuda:1', 29: 'cuda:1', 30: 'meta', 31: 'meta', 32: 'meta', 33: 'meta', 34: 'meta', 35: 'meta', 36: 'cuda:1', 37: 'cuda:1', 38: 'cuda:1', 39: 'cuda:1', 40: 'meta', 41: 'cuda:1', 42: 'meta', 43: 'cuda:1', 44: 'cuda:1', 45: 'cuda:1', 46: 'meta', 47: 'cuda:1', 48: 'meta', 49: 'cuda:1', 50: 'meta', 51: 'cuda:1', 52: 'cuda:1', 53: 'meta', 54: 'cuda:1', 55: 'meta', 56: 'meta', 57: 'cuda:1', 58: 'meta', 59: 'meta', 60: 'cuda:1', 61: 'meta', 62: 'cuda:1', 63: 'meta'}
DEBUG 01-06 17:11:21.958187.958187 cuda_h.py:19] end experts_map_get cost 0.002281665802001953 seconds
DEBUG 01-06 17:11:21.958429.958429 cuda_h.py:10] start gpu_sexperts
DEBUG 01-06 17:11:21.959355.959355 cuda_h.py:19] end gpu_sexperts cost 0.0003185272216796875 seconds
DEBUG 01-06 17:11:21.959946.959946 cuda_h.py:10] start gpu_experts
DEBUG 01-06 17:11:21.959843.959843 mlpmodule.py:533] gpu group tensors cost 0.0005915164947509766 s
DEBUG 01-06 17:11:21.961398.961398 mlpmodule.py:664]  experts func einsum cost 0.025913715362548828 s
DEBUG 01-06 17:11:21.961998.961998 mlpmodule.py:566] gpu pad cost 0.0018069744110107422 s
DEBUG 01-06 17:11:21.962562.962562 mlpmodule.py:584] gpu group einsum cost 0.0005140304565429688 s
DEBUG 01-06 17:11:21.965935.965935 mlpmodule.py:613] gpu experts func einsum cost 0.006310462951660156 s
DEBUG 01-06 17:11:21.965004.965004 cuda_h.py:19] end gpu_experts cost 0.006437540054321289 seconds
DEBUG 01-06 17:11:21.965674.965674 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-06 17:11:21.965569.965569 lmp.py:661] 
DEBUG 01-06 17:11:21.965569.965569 lmp.py:661]   Computing 17 experts on CPU...
DEBUG 01-06 17:11:21.965220.965220 cuda_h.py:19] end cpu_experts_submit cost 5.745887756347656e-05 seconds
DEBUG 01-06 17:11:21.965777.965777 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-06 17:11:21.974148.974148 mlpmodule.py:706] group tensors cost 0.008327007293701172 s
DEBUG 01-06 17:11:21.975540.975540 mlpmodule.py:744] pad cost 0.0010149478912353516 s
DEBUG 01-06 17:11:21.975305.975305 mlpmodule.py:750] create cpu tensor cost 4.744529724121094e-05 s
DEBUG 01-06 17:11:21.975969.975969 mlpmodule.py:755] move to cpu cost 3.314018249511719e-05 s
DEBUG 01-06 17:11:21.978490.978490 mlpmodule.py:769] group_w3: shape=torch.Size([17, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=49020928
DEBUG 01-06 17:11:21.978432.978432 mlpmodule.py:770] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-06 17:11:21.978104.978104 mlpmodule.py:775] group_w3 first element: 0.033935546875
WARNING 01-06 17:11:21.978941.978941 mlpmodule.py:785] start einsum2
DEBUG 01-06 17:11:21.983857.983857 mlpmodule.py:795] group einsum cost 0.007287025451660156 s
DEBUG 01-06 17:11:21.983187.983187 mlpmodule.py:803] cpy2cputensor cost 0.00010657310485839844 s
DEBUG 01-06 17:11:21.986958.986958 cuda_h.py:19] end wait_cetm_experts cost 0.020344972610473633 seconds
DEBUG 01-06 17:11:21.986136.986136 cuda_h.py:19] end layer_moe_dgenerate_13 cost 0.030982494354248047 seconds
DEBUG 01-06 17:11:21.986791.986791 lmp.py:325] -------------------------------- end decode layer 13 --------------------------------
DEBUG 01-06 17:11:21.986653.986653 lmp.py:298] -------------------------------- start decode layer 14 --------------------------------
DEBUG 01-06 17:11:21.986309.986309 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-06 17:11:21.986035.986035 mlpmodule.py:367] cuda:1 cuda:1
DEBUG 01-06 17:11:21.987207.987207 cuda_h.py:10] start self_attn
cos shape torch.Size([65, 128]) sin shape torch.Size([65, 128]) position_ids tensor([[0]], device='cuda:1')
cos shape torch.Size([1, 1, 1, 128]) sin shape torch.Size([1, 1, 1, 128])
q_embed shape torch.Size([32, 16, 1, 128]) k_embed shape torch.Size([32, 16, 1, 128])
DEBUG 01-06 17:11:21.989034.989034 cuda_h.py:19] end self_attn cost 0.0019097328186035156 seconds
DEBUG 01-06 17:11:21.989788.989788 cuda_h.py:19] end iln_self_attn_paln cost 0.002774477005004883 seconds
DEBUG 01-06 17:11:21.989955.989955 cuda_h.py:10] start layer_moe_dgenerate_14
DEBUG 01-06 17:11:21.989970.989970 cuda_h.py:10] start gate
DEBUG 01-06 17:11:21.990475.990475 cuda_h.py:19] end gate cost 0.0006129741668701172 seconds
DEBUG 01-06 17:11:21.990080.990080 cuda_h.py:10] start experts_map_get
INFO 01-06 17:11:21.990277.990277 lmp.py:609] using loaded check layer: True
INFO 01-06 17:11:21.991754.991754 lmp.py:620] 
INFO 01-06 17:11:21.991754.991754 lmp.py:620] Layer 14 Expert Device Distribution:
INFO 01-06 17:11:21.991471.991471 lmp.py:621]   Active experts: 54 (out of 64 total)
INFO 01-06 17:11:21.991981.991981 lmp.py:622] 
INFO 01-06 17:11:21.991981.991981 lmp.py:622]   Detailed Expert Distribution:
INFO 01-06 17:11:21.991731.991731 lmp.py:623]   Expert ID  | Tokens     | Actual Device  
INFO 01-06 17:11:21.991380.991380 lmp.py:624]   ----------------------------------------------------------------------
INFO 01-06 17:11:21.991461.991461 lmp.py:627]   5          | 1          |  cuda:1         
INFO 01-06 17:11:21.991395.991395 lmp.py:627]   11         | 1          |  cuda:1         
INFO 01-06 17:11:21.991376.991376 lmp.py:627]   13         | 1          |  meta           
INFO 01-06 17:11:21.991218.991218 lmp.py:627]   16         | 1          |  meta           
INFO 01-06 17:11:21.991914.991914 lmp.py:627]   21         | 1          |  meta           
INFO 01-06 17:11:21.991179.991179 lmp.py:627]   26         | 1          |  cuda:1         
INFO 01-06 17:11:21.991922.991922 lmp.py:627]   36         | 1          |  meta           
INFO 01-06 17:11:21.991910.991910 lmp.py:627]   41         | 1          |  meta           
INFO 01-06 17:11:21.991467.991467 lmp.py:627]   50         | 1          |  meta           
INFO 01-06 17:11:21.991262.991262 lmp.py:627]   52         | 1          |  meta           
INFO 01-06 17:11:21.991627.991627 lmp.py:627]   57         | 1          |  cuda:1         
INFO 01-06 17:11:21.991277.991277 lmp.py:627]   60         | 1          |  meta           
INFO 01-06 17:11:21.991404.991404 lmp.py:627]   3          | 2          |  cuda:1         
INFO 01-06 17:11:21.991769.991769 lmp.py:627]   4          | 2          |  cuda:1         
INFO 01-06 17:11:21.991180.991180 lmp.py:627]   14         | 2          |  cuda:1         
INFO 01-06 17:11:21.991545.991545 lmp.py:627]   18         | 2          |  meta           
INFO 01-06 17:11:21.991625.991625 lmp.py:627]   19         | 2          |  meta           
INFO 01-06 17:11:21.991705.991705 lmp.py:627]   30         | 2          |  cuda:1         
INFO 01-06 17:11:21.991071.991071 lmp.py:627]   39         | 2          |  meta           
INFO 01-06 17:11:21.991436.991436 lmp.py:627]   45         | 2          |  meta           
INFO 01-06 17:11:21.991324.991324 lmp.py:627]   48         | 2          |  meta           
INFO 01-06 17:11:21.991973.991973 lmp.py:627]   51         | 2          |  cuda:1         
INFO 01-06 17:11:21.991339.991339 lmp.py:627]   61         | 2          |  meta           
INFO 01-06 17:11:21.991465.991465 lmp.py:627]   8          | 3          |  cuda:1         
INFO 01-06 17:11:21.991592.991592 lmp.py:627]   10         | 3          |  cuda:1         
INFO 01-06 17:11:21.991480.991480 lmp.py:627]   17         | 3          |  meta           
INFO 01-06 17:11:21.992322.992322 lmp.py:627]   22         | 3          |  meta           
INFO 01-06 17:11:21.992448.992448 lmp.py:627]   24         | 3          |  cuda:1         
INFO 01-06 17:11:21.992337.992337 lmp.py:627]   27         | 3          |  meta           
INFO 01-06 17:11:21.992748.992748 lmp.py:627]   29         | 3          |  cuda:1         
INFO 01-06 17:11:21.992636.992636 lmp.py:627]   37         | 3          |  cuda:1         
INFO 01-06 17:11:21.992286.992286 lmp.py:627]   43         | 3          |  cuda:1         
INFO 01-06 17:11:21.992697.992697 lmp.py:627]   54         | 3          |  meta           
INFO 01-06 17:11:21.992109.992109 lmp.py:627]   63         | 3          |  cuda:1         
INFO 01-06 17:11:21.992189.992189 lmp.py:627]   1          | 4          |  cuda:1         
INFO 01-06 17:11:21.992031.992031 lmp.py:627]   9          | 4          |  cuda:1         
INFO 01-06 17:11:21.992349.992349 lmp.py:627]   35         | 4          |  meta           
INFO 01-06 17:11:21.992714.992714 lmp.py:627]   44         | 4          |  cuda:1         
INFO 01-06 17:11:21.992841.992841 lmp.py:627]   56         | 4          |  cuda:1         
INFO 01-06 17:11:21.992729.992729 lmp.py:627]   28         | 5          |  cuda:1         
INFO 01-06 17:11:21.992617.992617 lmp.py:627]   32         | 5          |  cuda:1         
INFO 01-06 17:11:21.992506.992506 lmp.py:627]   33         | 5          |  cuda:1         
INFO 01-06 17:11:21.992414.992414 lmp.py:627]   58         | 5          |  cuda:1         
INFO 01-06 17:11:21.992899.992899 lmp.py:627]   6          | 6          |  cuda:1         
INFO 01-06 17:11:21.992456.992456 lmp.py:627]   15         | 6          |  meta           
INFO 01-06 17:11:21.992536.992536 lmp.py:627]   25         | 6          |  cuda:1         
INFO 01-06 17:11:21.992378.992378 lmp.py:627]   42         | 6          |  cuda:1         
INFO 01-06 17:11:21.992505.992505 lmp.py:627]   46         | 7          |  cuda:1         
INFO 01-06 17:11:21.992916.992916 lmp.py:627]   23         | 8          |  cuda:1         
INFO 01-06 17:11:21.992043.992043 lmp.py:627]   31         | 8          |  meta           
INFO 01-06 17:11:21.992408.992408 lmp.py:627]   53         | 8          |  meta           
INFO 01-06 17:11:21.992057.992057 lmp.py:627]   62         | 9          |  cuda:1         
INFO 01-06 17:11:21.992184.992184 lmp.py:627]   55         | 10         |  cuda:1         
INFO 01-06 17:11:21.992503.992503 lmp.py:627]   47         | 11         |  cuda:1         
INFO 01-06 17:11:21.992106.992106 lmp.py:628] ============================================================
INFO 01-06 17:11:21.992106.992106 lmp.py:628] 
INFO 01-06 17:11:21.992147.992147 lmp.py:630] experts_gpu_list: [5, 11, 26, 57, 3, 4, 14, 30, 51, 8, 10, 24, 29, 37, 43, 63, 1, 9, 44, 56, 28, 32, 33, 58, 6, 25, 42, 46, 23, 62, 55, 47] num: 32
INFO 01-06 17:11:21.992373.992373 lmp.py:631] experts_cpu_list: [13, 16, 21, 36, 41, 50, 52, 60, 18, 19, 39, 45, 48, 61, 17, 22, 27, 54, 35, 15, 31, 53] num: 22
INFO 01-06 17:11:21.992520.992520 lmp.py:632] expert_actual_device_map {0: 'cuda:1', 1: 'cuda:1', 2: 'cuda:1', 3: 'cuda:1', 4: 'cuda:1', 5: 'cuda:1', 6: 'cuda:1', 7: 'cuda:1', 8: 'cuda:1', 9: 'cuda:1', 10: 'cuda:1', 11: 'cuda:1', 12: 'cuda:1', 13: 'meta', 14: 'cuda:1', 15: 'meta', 16: 'meta', 17: 'meta', 18: 'meta', 19: 'meta', 20: 'cuda:1', 21: 'meta', 22: 'meta', 23: 'cuda:1', 24: 'cuda:1', 25: 'cuda:1', 26: 'cuda:1', 27: 'meta', 28: 'cuda:1', 29: 'cuda:1', 30: 'cuda:1', 31: 'meta', 32: 'cuda:1', 33: 'cuda:1', 34: 'meta', 35: 'meta', 36: 'meta', 37: 'cuda:1', 38: 'meta', 39: 'meta', 40: 'meta', 41: 'meta', 42: 'cuda:1', 43: 'cuda:1', 44: 'cuda:1', 45: 'meta', 46: 'cuda:1', 47: 'cuda:1', 48: 'meta', 49: 'meta', 50: 'meta', 51: 'cuda:1', 52: 'meta', 53: 'meta', 54: 'meta', 55: 'cuda:1', 56: 'cuda:1', 57: 'cuda:1', 58: 'cuda:1', 59: 'meta', 60: 'meta', 61: 'meta', 62: 'cuda:1', 63: 'cuda:1'}
DEBUG 01-06 17:11:21.992806.992806 cuda_h.py:19] end experts_map_get cost 0.002466917037963867 seconds
DEBUG 01-06 17:11:21.992743.992743 cuda_h.py:10] start gpu_sexperts
DEBUG 01-06 17:11:21.993239.993239 cuda_h.py:19] end gpu_sexperts cost 0.00032019615173339844 seconds
DEBUG 01-06 17:11:21.993022.993022 cuda_h.py:10] start gpu_experts
DEBUG 01-06 17:11:21.994694.994694 mlpmodule.py:533] gpu group tensors cost 0.0006341934204101562 s
DEBUG 01-06 17:11:21.995559.995559 mlpmodule.py:664]  experts func einsum cost 0.02954554557800293 s
DEBUG 01-06 17:11:21.995103.995103 mlpmodule.py:566] gpu pad cost 0.0018520355224609375 s
DEBUG 01-06 17:11:21.996157.996157 mlpmodule.py:584] gpu group einsum cost 0.0005249977111816406 s
DEBUG 01-06 17:11:21.999770.999770 mlpmodule.py:613] gpu experts func einsum cost 0.006446123123168945 s
DEBUG 01-06 17:11:21.999170.999170 cuda_h.py:19] end gpu_experts cost 0.006573677062988281 seconds
DEBUG 01-06 17:11:21.999972.999972 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-06 17:11:22.000437.000437 lmp.py:661] 
DEBUG 01-06 17:11:22.000437.000437 lmp.py:661]   Computing 22 experts on CPU...
DEBUG 01-06 17:11:22.000041.000041 cuda_h.py:19] end cpu_experts_submit cost 5.8650970458984375e-05 seconds
DEBUG 01-06 17:11:22.000360.000360 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-06 17:11:22.004914.004914 mlpmodule.py:706] group tensors cost 0.004106760025024414 s
DEBUG 01-06 17:11:22.006759.006759 mlpmodule.py:744] pad cost 0.0011305809020996094 s
DEBUG 01-06 17:11:22.006902.006902 mlpmodule.py:750] create cpu tensor cost 4.315376281738281e-05 s
DEBUG 01-06 17:11:22.006752.006752 mlpmodule.py:755] move to cpu cost 3.0040740966796875e-05 s
DEBUG 01-06 17:11:22.008121.008121 mlpmodule.py:769] group_w3: shape=torch.Size([22, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=63438848
DEBUG 01-06 17:11:22.009547.009547 mlpmodule.py:770] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-06 17:11:22.009582.009582 mlpmodule.py:775] group_w3 first element: 0.0177001953125
WARNING 01-06 17:11:22.009996.009996 mlpmodule.py:785] start einsum2
DEBUG 01-06 17:11:22.013667.013667 mlpmodule.py:795] group einsum cost 0.007126569747924805 s
DEBUG 01-06 17:11:22.013699.013699 mlpmodule.py:803] cpy2cputensor cost 8.034706115722656e-05 s
DEBUG 01-06 17:11:22.016631.016631 cuda_h.py:19] end wait_cetm_experts cost 0.016516447067260742 seconds
DEBUG 01-06 17:11:22.017916.017916 cuda_h.py:19] end layer_moe_dgenerate_14 cost 0.027457475662231445 seconds
DEBUG 01-06 17:11:22.017776.017776 lmp.py:325] -------------------------------- end decode layer 14 --------------------------------
DEBUG 01-06 17:11:22.017930.017930 lmp.py:298] -------------------------------- start decode layer 15 --------------------------------
DEBUG 01-06 17:11:22.017394.017394 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-06 17:11:22.017696.017696 mlpmodule.py:367] cuda:1 cuda:1
DEBUG 01-06 17:11:22.017675.017675 cuda_h.py:10] start self_attn
cos shape torch.Size([65, 128]) sin shape torch.Size([65, 128]) position_ids tensor([[0]], device='cuda:1')
cos shape torch.Size([1, 1, 1, 128]) sin shape torch.Size([1, 1, 1, 128])
q_embed shape torch.Size([32, 16, 1, 128]) k_embed shape torch.Size([32, 16, 1, 128])
DEBUG 01-06 17:11:22.019536.019536 cuda_h.py:19] end self_attn cost 0.0019009113311767578 seconds
DEBUG 01-06 17:11:22.020044.020044 cuda_h.py:19] end iln_self_attn_paln cost 0.002761363983154297 seconds
DEBUG 01-06 17:11:22.020311.020311 cuda_h.py:10] start layer_moe_dgenerate_15
DEBUG 01-06 17:11:22.020272.020272 cuda_h.py:10] start gate
DEBUG 01-06 17:11:22.020918.020918 cuda_h.py:19] end gate cost 0.0006444454193115234 seconds
DEBUG 01-06 17:11:22.020384.020384 cuda_h.py:10] start experts_map_get
INFO 01-06 17:11:22.021197.021197 lmp.py:609] using loaded check layer: True
INFO 01-06 17:11:22.021945.021945 lmp.py:620] 
INFO 01-06 17:11:22.021945.021945 lmp.py:620] Layer 15 Expert Device Distribution:
INFO 01-06 17:11:22.021377.021377 lmp.py:621]   Active experts: 52 (out of 64 total)
INFO 01-06 17:11:22.021649.021649 lmp.py:622] 
INFO 01-06 17:11:22.021649.021649 lmp.py:622]   Detailed Expert Distribution:
INFO 01-06 17:11:22.021398.021398 lmp.py:623]   Expert ID  | Tokens     | Actual Device  
INFO 01-06 17:11:22.022810.022810 lmp.py:624]   ----------------------------------------------------------------------
INFO 01-06 17:11:22.022413.022413 lmp.py:627]   0          | 1          |  cuda:1         
INFO 01-06 17:11:22.022632.022632 lmp.py:627]   1          | 1          |  cuda:1         
INFO 01-06 17:11:22.022851.022851 lmp.py:627]   14         | 1          |  meta           
INFO 01-06 17:11:22.022594.022594 lmp.py:627]   15         | 1          |  meta           
INFO 01-06 17:11:22.022859.022859 lmp.py:627]   18         | 1          |  cuda:1         
INFO 01-06 17:11:22.022125.022125 lmp.py:627]   22         | 1          |  meta           
INFO 01-06 17:11:22.022583.022583 lmp.py:627]   35         | 1          |  cuda:1         
INFO 01-06 17:11:22.022517.022517 lmp.py:627]   36         | 1          |  cuda:1         
INFO 01-06 17:11:22.022213.022213 lmp.py:627]   42         | 1          |  meta           
INFO 01-06 17:11:22.022625.022625 lmp.py:627]   44         | 1          |  cuda:1         
INFO 01-06 17:11:22.022513.022513 lmp.py:627]   55         | 1          |  meta           
INFO 01-06 17:11:22.022017.022017 lmp.py:627]   56         | 1          |  cuda:1         
INFO 01-06 17:11:22.022044.022044 lmp.py:627]   57         | 1          |  cuda:1         
INFO 01-06 17:11:22.022548.022548 lmp.py:627]   63         | 1          |  meta           
INFO 01-06 17:11:22.022052.022052 lmp.py:627]   9          | 2          |  cuda:1         
INFO 01-06 17:11:22.022318.022318 lmp.py:627]   16         | 2          |  cuda:1         
INFO 01-06 17:11:22.022345.022345 lmp.py:627]   19         | 2          |  cuda:1         
INFO 01-06 17:11:22.022041.022041 lmp.py:627]   20         | 2          |  meta           
INFO 01-06 17:11:22.022737.022737 lmp.py:627]   30         | 2          |  cuda:1         
INFO 01-06 17:11:22.022241.022241 lmp.py:627]   34         | 2          |  meta           
INFO 01-06 17:11:22.022175.022175 lmp.py:627]   37         | 2          |  cuda:1         
INFO 01-06 17:11:22.022064.022064 lmp.py:627]   39         | 2          |  cuda:1         
INFO 01-06 17:11:22.022329.022329 lmp.py:627]   2          | 3          |  cuda:1         
INFO 01-06 17:11:22.022595.022595 lmp.py:627]   3          | 3          |  cuda:1         
INFO 01-06 17:11:22.022860.022860 lmp.py:627]   4          | 3          |  cuda:1         
INFO 01-06 17:11:22.022603.022603 lmp.py:627]   8          | 3          |  cuda:1         
INFO 01-06 17:11:22.022107.022107 lmp.py:627]   17         | 3          |  cuda:1         
INFO 01-06 17:11:22.022286.022286 lmp.py:627]   21         | 3          |  meta           
INFO 01-06 17:11:22.022036.022036 lmp.py:627]   24         | 3          |  cuda:1         
INFO 01-06 17:11:22.022831.022831 lmp.py:627]   25         | 3          |  meta           
INFO 01-06 17:11:22.022435.022435 lmp.py:627]   38         | 3          |  cuda:1         
INFO 01-06 17:11:22.022800.022800 lmp.py:627]   45         | 3          |  meta           
INFO 01-06 17:11:22.022926.022926 lmp.py:627]   48         | 3          |  cuda:1         
INFO 01-06 17:11:22.022814.022814 lmp.py:627]   60         | 3          |  cuda:1         
INFO 01-06 17:11:22.022418.022418 lmp.py:627]   27         | 4          |  cuda:1         
INFO 01-06 17:11:22.022544.022544 lmp.py:627]   61         | 4          |  meta           
INFO 01-06 17:11:22.022102.022102 lmp.py:627]   5          | 5          |  cuda:1         
INFO 01-06 17:11:22.022897.022897 lmp.py:627]   11         | 5          |  cuda:1         
INFO 01-06 17:11:22.022693.022693 lmp.py:627]   28         | 5          |  meta           
INFO 01-06 17:11:22.022535.022535 lmp.py:627]   31         | 5          |  cuda:1         
INFO 01-06 17:11:22.022661.022661 lmp.py:627]   43         | 5          |  cuda:1         
INFO 01-06 17:11:22.022549.022549 lmp.py:627]   51         | 5          |  meta           
INFO 01-06 17:11:22.022438.022438 lmp.py:627]   62         | 5          |  meta           
INFO 01-06 17:11:22.022087.022087 lmp.py:627]   32         | 6          |  meta           
INFO 01-06 17:11:22.023452.023452 lmp.py:627]   40         | 6          |  meta           
INFO 01-06 17:11:22.023340.023340 lmp.py:627]   29         | 7          |  cuda:1         
INFO 01-06 17:11:22.023944.023944 lmp.py:627]   58         | 7          |  cuda:1         
INFO 01-06 17:11:22.023501.023501 lmp.py:627]   47         | 8          |  cuda:1         
INFO 01-06 17:11:22.023343.023343 lmp.py:627]   26         | 10         |  meta           
INFO 01-06 17:11:22.023708.023708 lmp.py:627]   33         | 11         |  cuda:1         
INFO 01-06 17:11:22.023073.023073 lmp.py:627]   10         | 13         |  meta           
INFO 01-06 17:11:22.023961.023961 lmp.py:627]   49         | 15         |  cuda:1         
INFO 01-06 17:11:22.023849.023849 lmp.py:628] ============================================================
INFO 01-06 17:11:22.023849.023849 lmp.py:628] 
INFO 01-06 17:11:22.023460.023460 lmp.py:630] experts_gpu_list: [0, 1, 18, 35, 36, 44, 56, 57, 9, 16, 19, 30, 37, 39, 2, 3, 4, 8, 17, 24, 38, 48, 60, 27, 5, 11, 31, 43, 29, 58, 47, 33, 49] num: 33
INFO 01-06 17:11:22.023209.023209 lmp.py:631] experts_cpu_list: [14, 15, 22, 42, 55, 63, 20, 34, 21, 25, 45, 61, 28, 51, 62, 32, 40, 26, 10] num: 19
INFO 01-06 17:11:22.023734.023734 lmp.py:632] expert_actual_device_map {0: 'cuda:1', 1: 'cuda:1', 2: 'cuda:1', 3: 'cuda:1', 4: 'cuda:1', 5: 'cuda:1', 6: 'cuda:1', 7: 'cuda:1', 8: 'cuda:1', 9: 'cuda:1', 10: 'meta', 11: 'cuda:1', 12: 'meta', 13: 'meta', 14: 'meta', 15: 'meta', 16: 'cuda:1', 17: 'cuda:1', 18: 'cuda:1', 19: 'cuda:1', 20: 'meta', 21: 'meta', 22: 'meta', 23: 'cuda:1', 24: 'cuda:1', 25: 'meta', 26: 'meta', 27: 'cuda:1', 28: 'meta', 29: 'cuda:1', 30: 'cuda:1', 31: 'cuda:1', 32: 'meta', 33: 'cuda:1', 34: 'meta', 35: 'cuda:1', 36: 'cuda:1', 37: 'cuda:1', 38: 'cuda:1', 39: 'cuda:1', 40: 'meta', 41: 'meta', 42: 'meta', 43: 'cuda:1', 44: 'cuda:1', 45: 'meta', 46: 'cuda:1', 47: 'cuda:1', 48: 'cuda:1', 49: 'cuda:1', 50: 'meta', 51: 'meta', 52: 'meta', 53: 'meta', 54: 'meta', 55: 'meta', 56: 'cuda:1', 57: 'cuda:1', 58: 'cuda:1', 59: 'meta', 60: 'cuda:1', 61: 'meta', 62: 'meta', 63: 'meta'}
DEBUG 01-06 17:11:22.023597.023597 cuda_h.py:19] end experts_map_get cost 0.0023670196533203125 seconds
DEBUG 01-06 17:11:22.023692.023692 mlpmodule.py:664]  experts func einsum cost 0.02320122718811035 s
DEBUG 01-06 17:11:22.023742.023742 cuda_h.py:10] start gpu_sexperts
DEBUG 01-06 17:11:22.024301.024301 cuda_h.py:19] end gpu_sexperts cost 0.00034165382385253906 seconds
DEBUG 01-06 17:11:22.024097.024097 cuda_h.py:10] start gpu_experts
DEBUG 01-06 17:11:22.024282.024282 mlpmodule.py:533] gpu group tensors cost 0.0006918907165527344 s
DEBUG 01-06 17:11:22.026010.026010 mlpmodule.py:566] gpu pad cost 0.0017118453979492188 s
DEBUG 01-06 17:11:22.027018.027018 mlpmodule.py:584] gpu group einsum cost 0.00036787986755371094 s
DEBUG 01-06 17:11:22.031566.031566 mlpmodule.py:613] gpu experts func einsum cost 0.00773930549621582 s
DEBUG 01-06 17:11:22.032423.032423 cuda_h.py:19] end gpu_experts cost 0.008107423782348633 seconds
DEBUG 01-06 17:11:22.032669.032669 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-06 17:11:22.032757.032757 lmp.py:661] 
DEBUG 01-06 17:11:22.032757.032757 lmp.py:661]   Computing 19 experts on CPU...
DEBUG 01-06 17:11:22.032832.032832 cuda_h.py:19] end cpu_experts_submit cost 8.368492126464844e-05 seconds
DEBUG 01-06 17:11:22.032913.032913 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-06 17:11:22.037823.037823 mlpmodule.py:706] group tensors cost 0.0043332576751708984 s
DEBUG 01-06 17:11:22.039248.039248 mlpmodule.py:744] pad cost 0.0015718936920166016 s
DEBUG 01-06 17:11:22.039816.039816 mlpmodule.py:750] create cpu tensor cost 7.104873657226562e-05 s
DEBUG 01-06 17:11:22.039721.039721 mlpmodule.py:755] move to cpu cost 0.00010418891906738281 s
DEBUG 01-06 17:11:22.043813.043813 mlpmodule.py:769] group_w3: shape=torch.Size([19, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=54788096
DEBUG 01-06 17:11:22.043252.043252 mlpmodule.py:770] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-06 17:11:22.043679.043679 mlpmodule.py:775] group_w3 first element: -0.01495361328125
WARNING 01-06 17:11:22.043802.043802 mlpmodule.py:785] start einsum2
DEBUG 01-06 17:11:22.049440.049440 mlpmodule.py:795] group einsum cost 0.009365320205688477 s
DEBUG 01-06 17:11:22.049982.049982 mlpmodule.py:803] cpy2cputensor cost 8.440017700195312e-05 s
DEBUG 01-06 17:11:22.052115.052115 cuda_h.py:19] end wait_cetm_experts cost 0.019799470901489258 seconds
DEBUG 01-06 17:11:22.052337.052337 cuda_h.py:19] end layer_moe_dgenerate_15 cost 0.03259563446044922 seconds
DEBUG 01-06 17:11:22.053945.053945 lmp.py:325] -------------------------------- end decode layer 15 --------------------------------
DEBUG 01-06 17:11:22.053219.053219 lmp.py:298] -------------------------------- start decode layer 16 --------------------------------
DEBUG 01-06 17:11:22.053836.053836 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-06 17:11:22.053545.053545 mlpmodule.py:367] cuda:1 cuda:1
DEBUG 01-06 17:11:22.054165.054165 cuda_h.py:10] start self_attn
cos shape torch.Size([65, 128]) sin shape torch.Size([65, 128]) position_ids tensor([[0]], device='cuda:1')
cos shape torch.Size([1, 1, 1, 128]) sin shape torch.Size([1, 1, 1, 128])
q_embed shape torch.Size([32, 16, 1, 128]) k_embed shape torch.Size([32, 16, 1, 128])
DEBUG 01-06 17:11:22.057646.057646 cuda_h.py:19] end self_attn cost 0.0028002262115478516 seconds
DEBUG 01-06 17:11:22.057611.057611 cuda_h.py:19] end iln_self_attn_paln cost 0.0039370059967041016 seconds
DEBUG 01-06 17:11:22.057931.057931 cuda_h.py:10] start layer_moe_dgenerate_16
DEBUG 01-06 17:11:22.057469.057469 cuda_h.py:10] start gate
DEBUG 01-06 17:11:22.057531.057531 mlpmodule.py:664]  experts func einsum cost 0.024912595748901367 s
DEBUG 01-06 17:11:22.058990.058990 cuda_h.py:19] end gate cost 0.0008554458618164062 seconds
DEBUG 01-06 17:11:22.058079.058079 cuda_h.py:10] start experts_map_get
INFO 01-06 17:11:22.059667.059667 lmp.py:609] using loaded check layer: True
INFO 01-06 17:11:22.059006.059006 lmp.py:620] 
INFO 01-06 17:11:22.059006.059006 lmp.py:620] Layer 16 Expert Device Distribution:
INFO 01-06 17:11:22.059630.059630 lmp.py:621]   Active experts: 53 (out of 64 total)
INFO 01-06 17:11:22.059187.059187 lmp.py:622] 
INFO 01-06 17:11:22.059187.059187 lmp.py:622]   Detailed Expert Distribution:
INFO 01-06 17:11:22.059890.059890 lmp.py:623]   Expert ID  | Tokens     | Actual Device  
INFO 01-06 17:11:22.059301.059301 lmp.py:624]   ----------------------------------------------------------------------
INFO 01-06 17:11:22.059666.059666 lmp.py:627]   3          | 1          |  cuda:1         
INFO 01-06 17:11:22.059362.059362 lmp.py:627]   4          | 1          |  cuda:1         
INFO 01-06 17:11:22.059343.059343 lmp.py:627]   11         | 1          |  meta           
INFO 01-06 17:11:22.059847.059847 lmp.py:627]   14         | 1          |  meta           
INFO 01-06 17:11:22.059351.059351 lmp.py:627]   19         | 1          |  cuda:1         
INFO 01-06 17:11:22.059855.059855 lmp.py:627]   25         | 1          |  meta           
INFO 01-06 17:11:22.059359.059359 lmp.py:627]   30         | 1          |  cuda:1         
INFO 01-06 17:11:22.060055.060055 lmp.py:627]   37         | 1          |  cuda:1         
INFO 01-06 17:11:22.060751.060751 lmp.py:627]   38         | 1          |  meta           
INFO 01-06 17:11:22.060732.060732 lmp.py:627]   39         | 1          |  cuda:1         
INFO 01-06 17:11:22.060428.060428 lmp.py:627]   40         | 1          |  cuda:1         
INFO 01-06 17:11:22.060455.060455 lmp.py:627]   41         | 1          |  meta           
INFO 01-06 17:11:22.060483.060483 lmp.py:627]   49         | 1          |  meta           
INFO 01-06 17:11:22.060271.060271 lmp.py:627]   50         | 1          |  meta           
INFO 01-06 17:11:22.060775.060775 lmp.py:627]   51         | 1          |  meta           
INFO 01-06 17:11:22.060518.060518 lmp.py:627]   55         | 1          |  meta           
INFO 01-06 17:11:22.060975.060975 lmp.py:627]   63         | 1          |  cuda:1         
INFO 01-06 17:11:22.060479.060479 lmp.py:627]   12         | 2          |  cuda:1         
INFO 01-06 17:11:22.060699.060699 lmp.py:627]   16         | 2          |  cuda:1         
INFO 01-06 17:11:22.060680.060680 lmp.py:627]   26         | 2          |  meta           
INFO 01-06 17:11:22.060899.060899 lmp.py:627]   29         | 2          |  cuda:1         
INFO 01-06 17:11:22.060164.060164 lmp.py:627]   45         | 2          |  meta           
INFO 01-06 17:11:22.060430.060430 lmp.py:627]   56         | 2          |  meta           
INFO 01-06 17:11:22.060934.060934 lmp.py:627]   1          | 3          |  cuda:1         
INFO 01-06 17:11:22.060723.060723 lmp.py:627]   2          | 3          |  cuda:1         
INFO 01-06 17:11:22.060632.060632 lmp.py:627]   9          | 3          |  meta           
INFO 01-06 17:11:22.060090.060090 lmp.py:627]   10         | 3          |  meta           
INFO 01-06 17:11:22.060548.060548 lmp.py:627]   13         | 3          |  meta           
INFO 01-06 17:11:22.060767.060767 lmp.py:627]   18         | 3          |  cuda:1         
INFO 01-06 17:11:22.060463.060463 lmp.py:627]   24         | 3          |  cuda:1         
INFO 01-06 17:11:22.060682.060682 lmp.py:627]   34         | 3          |  meta           
INFO 01-06 17:11:22.060948.060948 lmp.py:627]   59         | 3          |  cuda:1         
INFO 01-06 17:11:22.060214.060214 lmp.py:627]   61         | 3          |  meta           
INFO 01-06 17:11:22.060479.060479 lmp.py:627]   22         | 4          |  cuda:1         
INFO 01-06 17:11:22.060745.060745 lmp.py:627]   27         | 4          |  meta           
INFO 01-06 17:11:22.060295.060295 lmp.py:627]   48         | 4          |  meta           
INFO 01-06 17:11:22.060322.060322 lmp.py:627]   60         | 4          |  cuda:1         
INFO 01-06 17:11:22.060303.060303 lmp.py:627]   6          | 5          |  cuda:1         
INFO 01-06 17:11:22.060761.060761 lmp.py:627]   8          | 5          |  cuda:1         
INFO 01-06 17:11:22.060218.060218 lmp.py:627]   17         | 5          |  cuda:1         
INFO 01-06 17:11:22.060676.060676 lmp.py:627]   23         | 5          |  cuda:1         
INFO 01-06 17:11:22.060942.060942 lmp.py:627]   33         | 5          |  meta           
INFO 01-06 17:11:22.060730.060730 lmp.py:627]   15         | 6          |  cuda:1         
INFO 01-06 17:11:22.060758.060758 lmp.py:627]   32         | 6          |  cuda:1         
INFO 01-06 17:11:22.060785.060785 lmp.py:627]   35         | 6          |  cuda:1         
INFO 01-06 17:11:22.060050.060050 lmp.py:627]   7          | 7          |  cuda:1         
INFO 01-06 17:11:22.060270.060270 lmp.py:627]   52         | 7          |  cuda:1         
INFO 01-06 17:11:22.060489.060489 lmp.py:627]   44         | 9          |  cuda:1         
INFO 01-06 17:11:22.060708.060708 lmp.py:627]   54         | 9          |  meta           
INFO 01-06 17:11:22.060927.060927 lmp.py:627]   36         | 10         |  cuda:1         
INFO 01-06 17:11:22.060193.060193 lmp.py:627]   62         | 10         |  cuda:1         
INFO 01-06 17:11:22.060220.060220 lmp.py:627]   20         | 11         |  cuda:1         
INFO 01-06 17:11:22.060009.060009 lmp.py:627]   53         | 11         |  cuda:1         
INFO 01-06 17:11:22.061798.061798 lmp.py:628] ============================================================
INFO 01-06 17:11:22.061798.061798 lmp.py:628] 
INFO 01-06 17:11:22.061454.061454 lmp.py:630] experts_gpu_list: [3, 4, 19, 30, 37, 39, 40, 63, 12, 16, 29, 1, 2, 18, 24, 59, 22, 60, 6, 8, 17, 23, 15, 32, 35, 7, 52, 44, 36, 62, 20, 53] num: 32
INFO 01-06 17:11:22.061534.061534 lmp.py:631] experts_cpu_list: [11, 14, 25, 38, 41, 49, 50, 51, 55, 26, 45, 56, 9, 10, 13, 34, 61, 27, 48, 33, 54] num: 21
INFO 01-06 17:11:22.061271.061271 lmp.py:632] expert_actual_device_map {0: 'cuda:1', 1: 'cuda:1', 2: 'cuda:1', 3: 'cuda:1', 4: 'cuda:1', 5: 'cuda:1', 6: 'cuda:1', 7: 'cuda:1', 8: 'cuda:1', 9: 'meta', 10: 'meta', 11: 'meta', 12: 'cuda:1', 13: 'meta', 14: 'meta', 15: 'cuda:1', 16: 'cuda:1', 17: 'cuda:1', 18: 'cuda:1', 19: 'cuda:1', 20: 'cuda:1', 21: 'cuda:1', 22: 'cuda:1', 23: 'cuda:1', 24: 'cuda:1', 25: 'meta', 26: 'meta', 27: 'meta', 28: 'meta', 29: 'cuda:1', 30: 'cuda:1', 31: 'meta', 32: 'cuda:1', 33: 'meta', 34: 'meta', 35: 'cuda:1', 36: 'cuda:1', 37: 'cuda:1', 38: 'meta', 39: 'cuda:1', 40: 'cuda:1', 41: 'meta', 42: 'cuda:1', 43: 'meta', 44: 'cuda:1', 45: 'meta', 46: 'cuda:1', 47: 'meta', 48: 'meta', 49: 'meta', 50: 'meta', 51: 'meta', 52: 'cuda:1', 53: 'cuda:1', 54: 'meta', 55: 'meta', 56: 'meta', 57: 'meta', 58: 'meta', 59: 'cuda:1', 60: 'cuda:1', 61: 'meta', 62: 'cuda:1', 63: 'cuda:1'}
DEBUG 01-06 17:11:22.061564.061564 cuda_h.py:19] end experts_map_get cost 0.0025701522827148438 seconds
DEBUG 01-06 17:11:22.061640.061640 cuda_h.py:10] start gpu_sexperts
DEBUG 01-06 17:11:22.061991.061991 cuda_h.py:19] end gpu_sexperts cost 0.00035881996154785156 seconds
DEBUG 01-06 17:11:22.061542.061542 cuda_h.py:10] start gpu_experts
DEBUG 01-06 17:11:22.062557.062557 mlpmodule.py:533] gpu group tensors cost 0.0007407665252685547 s
DEBUG 01-06 17:11:22.064260.064260 mlpmodule.py:566] gpu pad cost 0.0017621517181396484 s
DEBUG 01-06 17:11:22.064919.064919 mlpmodule.py:584] gpu group einsum cost 0.0004107952117919922 s
DEBUG 01-06 17:11:22.067058.067058 mlpmodule.py:613] gpu experts func einsum cost 0.00602412223815918 s
DEBUG 01-06 17:11:22.067902.067902 cuda_h.py:19] end gpu_experts cost 0.00616765022277832 seconds
DEBUG 01-06 17:11:22.067274.067274 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-06 17:11:22.067739.067739 lmp.py:661] 
DEBUG 01-06 17:11:22.067739.067739 lmp.py:661]   Computing 21 experts on CPU...
DEBUG 01-06 17:11:22.068774.068774 cuda_h.py:19] end cpu_experts_submit cost 5.9604644775390625e-05 seconds
DEBUG 01-06 17:11:22.068854.068854 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-06 17:11:22.077547.077547 mlpmodule.py:706] group tensors cost 0.009631633758544922 s
DEBUG 01-06 17:11:22.079037.079037 mlpmodule.py:744] pad cost 0.0013053417205810547 s
DEBUG 01-06 17:11:22.079656.079656 mlpmodule.py:750] create cpu tensor cost 4.482269287109375e-05 s
DEBUG 01-06 17:11:22.080414.080414 mlpmodule.py:755] move to cpu cost 3.1948089599609375e-05 s
DEBUG 01-06 17:11:22.083410.083410 mlpmodule.py:769] group_w3: shape=torch.Size([21, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=60555264
DEBUG 01-06 17:11:22.083445.083445 mlpmodule.py:770] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-06 17:11:22.083566.083566 mlpmodule.py:775] group_w3 first element: -0.0198974609375
WARNING 01-06 17:11:22.083443.083443 mlpmodule.py:785] start einsum2
DEBUG 01-06 17:11:22.087853.087853 mlpmodule.py:795] group einsum cost 0.007552146911621094 s
DEBUG 01-06 17:11:22.087143.087143 mlpmodule.py:803] cpy2cputensor cost 7.486343383789062e-05 s
DEBUG 01-06 17:11:22.090825.090825 cuda_h.py:19] end wait_cetm_experts cost 0.022574186325073242 seconds
DEBUG 01-06 17:11:22.091620.091620 cuda_h.py:19] end layer_moe_dgenerate_16 cost 0.033576011657714844 seconds
DEBUG 01-06 17:11:22.091580.091580 lmp.py:325] -------------------------------- end decode layer 16 --------------------------------
DEBUG 01-06 17:11:22.091263.091263 lmp.py:298] -------------------------------- start decode layer 17 --------------------------------
DEBUG 01-06 17:11:22.091211.091211 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-06 17:11:22.091971.091971 mlpmodule.py:367] cuda:1 cuda:1
DEBUG 01-06 17:11:22.091893.091893 cuda_h.py:10] start self_attn
cos shape torch.Size([65, 128]) sin shape torch.Size([65, 128]) position_ids tensor([[0]], device='cuda:1')
cos shape torch.Size([1, 1, 1, 128]) sin shape torch.Size([1, 1, 1, 128])
q_embed shape torch.Size([32, 16, 1, 128]) k_embed shape torch.Size([32, 16, 1, 128])
DEBUG 01-06 17:11:22.094147.094147 cuda_h.py:19] end self_attn cost 0.002569913864135742 seconds
DEBUG 01-06 17:11:22.094313.094313 cuda_h.py:19] end iln_self_attn_paln cost 0.0035784244537353516 seconds
DEBUG 01-06 17:11:22.095447.095447 cuda_h.py:10] start layer_moe_dgenerate_17
DEBUG 01-06 17:11:22.095707.095707 cuda_h.py:10] start gate
DEBUG 01-06 17:11:22.095109.095109 cuda_h.py:19] end gate cost 0.0006721019744873047 seconds
DEBUG 01-06 17:11:22.095714.095714 cuda_h.py:10] start experts_map_get
INFO 01-06 17:11:22.096257.096257 lmp.py:609] using loaded check layer: True
INFO 01-06 17:11:22.096795.096795 lmp.py:620] 
INFO 01-06 17:11:22.096795.096795 lmp.py:620] Layer 17 Expert Device Distribution:
INFO 01-06 17:11:22.096949.096949 lmp.py:621]   Active experts: 54 (out of 64 total)
INFO 01-06 17:11:22.097844.097844 lmp.py:622] 
INFO 01-06 17:11:22.097844.097844 lmp.py:622]   Detailed Expert Distribution:
INFO 01-06 17:11:22.097454.097454 lmp.py:623]   Expert ID  | Tokens     | Actual Device  
INFO 01-06 17:11:22.097296.097296 lmp.py:624]   ----------------------------------------------------------------------
INFO 01-06 17:11:22.097999.097999 lmp.py:627]   2          | 1          |  cuda:1         
INFO 01-06 17:11:22.097556.097556 lmp.py:627]   5          | 1          |  cuda:1         
INFO 01-06 17:11:22.097636.097636 lmp.py:627]   7          | 1          |  cuda:1         
INFO 01-06 17:11:22.097763.097763 lmp.py:627]   10         | 1          |  meta           
INFO 01-06 17:11:22.097797.097797 lmp.py:627]   11         | 1          |  cuda:1         
INFO 01-06 17:11:22.097354.097354 lmp.py:627]   13         | 1          |  cuda:1         
INFO 01-06 17:11:22.097719.097719 lmp.py:627]   16         | 1          |  cuda:1         
INFO 01-06 17:11:22.097799.097799 lmp.py:627]   19         | 1          |  cuda:1         
INFO 01-06 17:11:22.097641.097641 lmp.py:627]   22         | 1          |  cuda:1         
INFO 01-06 17:11:22.097959.097959 lmp.py:627]   27         | 1          |  meta           
INFO 01-06 17:11:22.097993.097993 lmp.py:627]   28         | 1          |  meta           
INFO 01-06 17:11:22.097358.097358 lmp.py:627]   33         | 1          |  meta           
INFO 01-06 17:11:22.097916.097916 lmp.py:627]   37         | 1          |  meta           
INFO 01-06 17:11:22.097757.097757 lmp.py:627]   41         | 1          |  cuda:1         
INFO 01-06 17:11:22.097599.097599 lmp.py:627]   42         | 1          |  cuda:1         
INFO 01-06 17:11:22.097918.097918 lmp.py:627]   56         | 1          |  cuda:1         
INFO 01-06 17:11:22.097760.097760 lmp.py:627]   59         | 1          |  meta           
INFO 01-06 17:11:22.097410.097410 lmp.py:627]   60         | 1          |  meta           
INFO 01-06 17:11:22.097536.097536 lmp.py:627]   3          | 2          |  cuda:1         
INFO 01-06 17:11:22.097140.097140 lmp.py:627]   4          | 2          |  cuda:1         
INFO 01-06 17:11:22.097743.097743 lmp.py:627]   6          | 2          |  cuda:1         
INFO 01-06 17:11:22.097823.097823 lmp.py:627]   15         | 2          |  meta           
INFO 01-06 17:11:22.097380.097380 lmp.py:627]   20         | 2          |  cuda:1         
INFO 01-06 17:11:22.097461.097461 lmp.py:627]   24         | 2          |  meta           
INFO 01-06 17:11:22.097303.097303 lmp.py:627]   30         | 2          |  cuda:1         
INFO 01-06 17:11:22.097906.097906 lmp.py:627]   38         | 2          |  meta           
INFO 01-06 17:11:22.097509.097509 lmp.py:627]   40         | 2          |  meta           
INFO 01-06 17:11:22.097875.097875 lmp.py:627]   47         | 2          |  meta           
INFO 01-06 17:11:22.097763.097763 lmp.py:627]   48         | 2          |  cuda:1         
INFO 01-06 17:11:22.097128.097128 lmp.py:627]   52         | 2          |  meta           
INFO 01-06 17:11:22.097685.097685 lmp.py:627]   53         | 2          |  meta           
INFO 01-06 17:11:22.097527.097527 lmp.py:627]   0          | 3          |  cuda:1         
INFO 01-06 17:11:22.097607.097607 lmp.py:627]   1          | 3          |  cuda:1         
INFO 01-06 17:11:22.097449.097449 lmp.py:627]   18         | 3          |  cuda:1         
INFO 01-06 17:11:22.097814.097814 lmp.py:627]   25         | 3          |  meta           
INFO 01-06 17:11:22.097940.097940 lmp.py:627]   31         | 3          |  meta           
INFO 01-06 17:11:22.097829.097829 lmp.py:627]   50         | 3          |  meta           
INFO 01-06 17:11:22.097717.097717 lmp.py:627]   57         | 3          |  cuda:1         
INFO 01-06 17:11:22.097320.097320 lmp.py:627]   26         | 4          |  cuda:1         
INFO 01-06 17:11:22.098162.098162 lmp.py:627]   44         | 4          |  cuda:1         
INFO 01-06 17:11:22.098196.098196 lmp.py:627]   14         | 5          |  meta           
INFO 01-06 17:11:22.098992.098992 lmp.py:627]   35         | 5          |  cuda:1         
INFO 01-06 17:11:22.098357.098357 lmp.py:627]   55         | 5          |  cuda:1         
INFO 01-06 17:11:22.098483.098483 lmp.py:627]   17         | 6          |  cuda:1         
INFO 01-06 17:11:22.098087.098087 lmp.py:627]   21         | 6          |  cuda:1         
INFO 01-06 17:11:22.098405.098405 lmp.py:627]   34         | 6          |  cuda:1         
INFO 01-06 17:11:22.098962.098962 lmp.py:627]   9          | 7          |  cuda:1         
INFO 01-06 17:11:22.098804.098804 lmp.py:627]   45         | 8          |  cuda:1         
INFO 01-06 17:11:22.098123.098123 lmp.py:627]   51         | 8          |  cuda:1         
INFO 01-06 17:11:22.098773.098773 lmp.py:627]   29         | 9          |  cuda:1         
INFO 01-06 17:11:22.098138.098138 lmp.py:627]   32         | 11         |  cuda:1         
INFO 01-06 17:11:22.098980.098980 lmp.py:627]   23         | 12         |  cuda:1         
INFO 01-06 17:11:22.098868.098868 lmp.py:627]   63         | 14         |  cuda:1         
INFO 01-06 17:11:22.098710.098710 lmp.py:627]   62         | 17         |  cuda:1         
INFO 01-06 17:11:22.098313.098313 lmp.py:628] ============================================================
INFO 01-06 17:11:22.098313.098313 lmp.py:628] 
INFO 01-06 17:11:22.098400.098400 lmp.py:630] experts_gpu_list: [2, 5, 7, 11, 13, 16, 19, 22, 41, 42, 56, 3, 4, 6, 20, 30, 48, 0, 1, 18, 57, 26, 44, 35, 55, 17, 21, 34, 9, 45, 51, 29, 32, 23, 63, 62] num: 36
INFO 01-06 17:11:22.098580.098580 lmp.py:631] experts_cpu_list: [10, 27, 28, 33, 37, 59, 60, 15, 24, 38, 40, 47, 52, 53, 25, 31, 50, 14] num: 18
INFO 01-06 17:11:22.098396.098396 lmp.py:632] expert_actual_device_map {0: 'cuda:1', 1: 'cuda:1', 2: 'cuda:1', 3: 'cuda:1', 4: 'cuda:1', 5: 'cuda:1', 6: 'cuda:1', 7: 'cuda:1', 8: 'meta', 9: 'cuda:1', 10: 'meta', 11: 'cuda:1', 12: 'meta', 13: 'cuda:1', 14: 'meta', 15: 'meta', 16: 'cuda:1', 17: 'cuda:1', 18: 'cuda:1', 19: 'cuda:1', 20: 'cuda:1', 21: 'cuda:1', 22: 'cuda:1', 23: 'cuda:1', 24: 'meta', 25: 'meta', 26: 'cuda:1', 27: 'meta', 28: 'meta', 29: 'cuda:1', 30: 'cuda:1', 31: 'meta', 32: 'cuda:1', 33: 'meta', 34: 'cuda:1', 35: 'cuda:1', 36: 'meta', 37: 'meta', 38: 'meta', 39: 'meta', 40: 'meta', 41: 'cuda:1', 42: 'cuda:1', 43: 'meta', 44: 'cuda:1', 45: 'cuda:1', 46: 'meta', 47: 'meta', 48: 'cuda:1', 49: 'meta', 50: 'meta', 51: 'cuda:1', 52: 'meta', 53: 'meta', 54: 'cuda:1', 55: 'cuda:1', 56: 'cuda:1', 57: 'cuda:1', 58: 'meta', 59: 'meta', 60: 'meta', 61: 'meta', 62: 'cuda:1', 63: 'cuda:1'}
DEBUG 01-06 17:11:22.098112.098112 cuda_h.py:19] end experts_map_get cost 0.0025742053985595703 seconds
DEBUG 01-06 17:11:22.098334.098334 mlpmodule.py:664]  experts func einsum cost 0.030387401580810547 s
DEBUG 01-06 17:11:22.098338.098338 cuda_h.py:10] start gpu_sexperts
DEBUG 01-06 17:11:22.099673.099673 cuda_h.py:19] end gpu_sexperts cost 0.00034618377685546875 seconds
DEBUG 01-06 17:11:22.099231.099231 cuda_h.py:10] start gpu_experts
DEBUG 01-06 17:11:22.101723.101723 mlpmodule.py:533] gpu group tensors cost 0.0017521381378173828 s
DEBUG 01-06 17:11:22.103065.103065 mlpmodule.py:566] gpu pad cost 0.002216815948486328 s
DEBUG 01-06 17:11:22.104201.104201 mlpmodule.py:584] gpu group einsum cost 0.0005896091461181641 s
DEBUG 01-06 17:11:22.107165.107165 mlpmodule.py:613] gpu experts func einsum cost 0.008614063262939453 s
DEBUG 01-06 17:11:22.108131.108131 cuda_h.py:19] end gpu_experts cost 0.00884699821472168 seconds
DEBUG 01-06 17:11:22.108219.108219 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-06 17:11:22.108014.108014 lmp.py:661] 
DEBUG 01-06 17:11:22.108014.108014 lmp.py:661]   Computing 18 experts on CPU...
DEBUG 01-06 17:11:22.108327.108327 cuda_h.py:19] end cpu_experts_submit cost 5.3882598876953125e-05 seconds
DEBUG 01-06 17:11:22.108593.108593 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-06 17:11:22.118714.118714 mlpmodule.py:706] group tensors cost 0.009479761123657227 s
DEBUG 01-06 17:11:22.119408.119408 mlpmodule.py:744] pad cost 0.001270294189453125 s
DEBUG 01-06 17:11:22.120697.120697 mlpmodule.py:750] create cpu tensor cost 4.410743713378906e-05 s
DEBUG 01-06 17:11:22.120884.120884 mlpmodule.py:755] move to cpu cost 3.3855438232421875e-05 s
DEBUG 01-06 17:11:22.122759.122759 mlpmodule.py:769] group_w3: shape=torch.Size([18, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=51904512
DEBUG 01-06 17:11:22.122807.122807 mlpmodule.py:770] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-06 17:11:22.122055.122055 mlpmodule.py:775] group_w3 first element: 0.03466796875
WARNING 01-06 17:11:22.122661.122661 mlpmodule.py:785] start einsum2
DEBUG 01-06 17:11:22.127685.127685 mlpmodule.py:795] group einsum cost 0.0072557926177978516 s
DEBUG 01-06 17:11:22.127875.127875 mlpmodule.py:803] cpy2cputensor cost 6.413459777832031e-05 s
DEBUG 01-06 17:11:22.130553.130553 cuda_h.py:19] end wait_cetm_experts cost 0.021869182586669922 seconds
DEBUG 01-06 17:11:22.130441.130441 cuda_h.py:19] end layer_moe_dgenerate_17 cost 0.03555107116699219 seconds
DEBUG 01-06 17:11:22.130169.130169 lmp.py:325] -------------------------------- end decode layer 17 --------------------------------
DEBUG 01-06 17:11:22.130985.130985 lmp.py:298] -------------------------------- start decode layer 18 --------------------------------
DEBUG 01-06 17:11:22.130641.130641 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-06 17:11:22.131566.131566 mlpmodule.py:367] cuda:1 cuda:1
DEBUG 01-06 17:11:22.131890.131890 cuda_h.py:10] start self_attn
cos shape torch.Size([65, 128]) sin shape torch.Size([65, 128]) position_ids tensor([[0]], device='cuda:1')
cos shape torch.Size([1, 1, 1, 128]) sin shape torch.Size([1, 1, 1, 128])
q_embed shape torch.Size([32, 16, 1, 128]) k_embed shape torch.Size([32, 16, 1, 128])
DEBUG 01-06 17:11:22.133855.133855 cuda_h.py:19] end self_attn cost 0.0022606849670410156 seconds
DEBUG 01-06 17:11:22.134833.134833 cuda_h.py:19] end iln_self_attn_paln cost 0.003125905990600586 seconds
DEBUG 01-06 17:11:22.134954.134954 cuda_h.py:10] start layer_moe_dgenerate_18
DEBUG 01-06 17:11:22.134207.134207 cuda_h.py:10] start gate
DEBUG 01-06 17:11:22.134647.134647 mlpmodule.py:664]  experts func einsum cost 0.02632594108581543 s
DEBUG 01-06 17:11:22.134606.134606 cuda_h.py:19] end gate cost 0.0007610321044921875 seconds
DEBUG 01-06 17:11:22.135173.135173 cuda_h.py:10] start experts_map_get
INFO 01-06 17:11:22.135418.135418 lmp.py:609] using loaded check layer: True
INFO 01-06 17:11:22.136591.136591 lmp.py:620] 
INFO 01-06 17:11:22.136591.136591 lmp.py:620] Layer 18 Expert Device Distribution:
INFO 01-06 17:11:22.136261.136261 lmp.py:621]   Active experts: 55 (out of 64 total)
INFO 01-06 17:11:22.136580.136580 lmp.py:622] 
INFO 01-06 17:11:22.136580.136580 lmp.py:622]   Detailed Expert Distribution:
INFO 01-06 17:11:22.136045.136045 lmp.py:623]   Expert ID  | Tokens     | Actual Device  
INFO 01-06 17:11:22.136217.136217 lmp.py:624]   ----------------------------------------------------------------------
INFO 01-06 17:11:22.136059.136059 lmp.py:627]   0          | 1          |  cuda:1         
INFO 01-06 17:11:22.136232.136232 lmp.py:627]   5          | 1          |  cuda:1         
INFO 01-06 17:11:22.136690.136690 lmp.py:627]   7          | 1          |  cuda:1         
INFO 01-06 17:11:22.136671.136671 lmp.py:627]   24         | 1          |  cuda:1         
INFO 01-06 17:11:22.136413.136413 lmp.py:627]   29         | 1          |  meta           
INFO 01-06 17:11:22.136891.136891 lmp.py:627]   30         | 1          |  meta           
INFO 01-06 17:11:22.136826.136826 lmp.py:627]   34         | 1          |  cuda:1         
INFO 01-06 17:11:22.136045.136045 lmp.py:627]   35         | 1          |  meta           
INFO 01-06 17:11:22.136026.136026 lmp.py:627]   36         | 1          |  meta           
INFO 01-06 17:11:22.136722.136722 lmp.py:627]   37         | 1          |  meta           
INFO 01-06 17:11:22.136656.136656 lmp.py:627]   40         | 1          |  meta           
INFO 01-06 17:11:22.136114.136114 lmp.py:627]   41         | 1          |  meta           
INFO 01-06 17:11:22.136095.136095 lmp.py:627]   42         | 1          |  cuda:1         
INFO 01-06 17:11:22.136360.136360 lmp.py:627]   44         | 1          |  cuda:1         
INFO 01-06 17:11:22.136864.136864 lmp.py:627]   50         | 1          |  cuda:1         
INFO 01-06 17:11:22.136368.136368 lmp.py:627]   57         | 1          |  cuda:1         
INFO 01-06 17:11:22.136634.136634 lmp.py:627]   59         | 1          |  meta           
INFO 01-06 17:11:22.136900.136900 lmp.py:627]   12         | 2          |  meta           
INFO 01-06 17:11:22.136404.136404 lmp.py:627]   13         | 2          |  cuda:1         
INFO 01-06 17:11:22.136100.136100 lmp.py:627]   14         | 2          |  cuda:1         
INFO 01-06 17:11:22.136557.136557 lmp.py:627]   20         | 2          |  cuda:1         
INFO 01-06 17:11:22.136777.136777 lmp.py:627]   25         | 2          |  meta           
INFO 01-06 17:11:22.136996.136996 lmp.py:627]   28         | 2          |  meta           
INFO 01-06 17:11:22.136738.136738 lmp.py:627]   32         | 2          |  meta           
INFO 01-06 17:11:22.136242.136242 lmp.py:627]   48         | 2          |  meta           
INFO 01-06 17:11:22.136746.136746 lmp.py:627]   55         | 2          |  cuda:1         
INFO 01-06 17:11:22.136489.136489 lmp.py:627]   56         | 2          |  meta           
INFO 01-06 17:11:22.136754.136754 lmp.py:627]   58         | 2          |  meta           
INFO 01-06 17:11:22.136020.136020 lmp.py:627]   61         | 2          |  cuda:1         
INFO 01-06 17:11:22.136478.136478 lmp.py:627]   1          | 3          |  cuda:1         
INFO 01-06 17:11:22.136935.136935 lmp.py:627]   3          | 3          |  cuda:1         
INFO 01-06 17:11:22.136393.136393 lmp.py:627]   18         | 3          |  cuda:1         
INFO 01-06 17:11:22.136851.136851 lmp.py:627]   31         | 3          |  cuda:1         
INFO 01-06 17:11:22.136355.136355 lmp.py:627]   33         | 3          |  cuda:1         
INFO 01-06 17:11:22.137620.137620 lmp.py:627]   47         | 3          |  cuda:1         
INFO 01-06 17:11:22.137124.137124 lmp.py:627]   2          | 4          |  cuda:1         
INFO 01-06 17:11:22.137390.137390 lmp.py:627]   49         | 4          |  cuda:1         
INFO 01-06 17:11:22.137655.137655 lmp.py:627]   51         | 4          |  cuda:1         
INFO 01-06 17:11:22.137921.137921 lmp.py:627]   9          | 5          |  meta           
INFO 01-06 17:11:22.137902.137902 lmp.py:627]   21         | 5          |  meta           
INFO 01-06 17:11:22.137121.137121 lmp.py:627]   22         | 5          |  cuda:1         
INFO 01-06 17:11:22.137579.137579 lmp.py:627]   43         | 5          |  cuda:1         
INFO 01-06 17:11:22.137559.137559 lmp.py:627]   53         | 5          |  meta           
INFO 01-06 17:11:22.137063.137063 lmp.py:627]   6          | 6          |  cuda:1         
INFO 01-06 17:11:22.137329.137329 lmp.py:627]   8          | 6          |  cuda:1         
INFO 01-06 17:11:22.137595.137595 lmp.py:627]   16         | 6          |  cuda:1         
INFO 01-06 17:11:22.137383.137383 lmp.py:627]   23         | 6          |  cuda:1         
INFO 01-06 17:11:22.137649.137649 lmp.py:627]   38         | 6          |  cuda:1         
INFO 01-06 17:11:22.137915.137915 lmp.py:627]   45         | 6          |  cuda:1         
INFO 01-06 17:11:22.137895.137895 lmp.py:627]   17         | 7          |  meta           
INFO 01-06 17:11:22.137115.137115 lmp.py:627]   4          | 9          |  cuda:1         
INFO 01-06 17:11:22.137572.137572 lmp.py:627]   11         | 9          |  cuda:1         
INFO 01-06 17:11:22.137792.137792 lmp.py:627]   26         | 11         |  cuda:1         
INFO 01-06 17:11:22.137296.137296 lmp.py:627]   52         | 12         |  meta           
INFO 01-06 17:11:22.137323.137323 lmp.py:627]   62         | 12         |  cuda:1         
INFO 01-06 17:11:22.137111.137111 lmp.py:628] ============================================================
INFO 01-06 17:11:22.137111.137111 lmp.py:628] 
INFO 01-06 17:11:22.137338.137338 lmp.py:630] experts_gpu_list: [0, 5, 7, 24, 34, 42, 44, 50, 57, 13, 14, 20, 55, 61, 1, 3, 18, 31, 33, 47, 2, 49, 51, 22, 43, 6, 8, 16, 23, 38, 45, 4, 11, 26, 62] num: 35
INFO 01-06 17:11:22.137703.137703 lmp.py:631] experts_cpu_list: [29, 30, 35, 36, 37, 40, 41, 59, 12, 25, 28, 32, 48, 56, 58, 9, 21, 53, 17, 52] num: 20
INFO 01-06 17:11:22.137465.137465 lmp.py:632] expert_actual_device_map {0: 'cuda:1', 1: 'cuda:1', 2: 'cuda:1', 3: 'cuda:1', 4: 'cuda:1', 5: 'cuda:1', 6: 'cuda:1', 7: 'cuda:1', 8: 'cuda:1', 9: 'meta', 10: 'cuda:1', 11: 'cuda:1', 12: 'meta', 13: 'cuda:1', 14: 'cuda:1', 15: 'cuda:1', 16: 'cuda:1', 17: 'meta', 18: 'cuda:1', 19: 'meta', 20: 'cuda:1', 21: 'meta', 22: 'cuda:1', 23: 'cuda:1', 24: 'cuda:1', 25: 'meta', 26: 'cuda:1', 27: 'meta', 28: 'meta', 29: 'meta', 30: 'meta', 31: 'cuda:1', 32: 'meta', 33: 'cuda:1', 34: 'cuda:1', 35: 'meta', 36: 'meta', 37: 'meta', 38: 'cuda:1', 39: 'meta', 40: 'meta', 41: 'meta', 42: 'cuda:1', 43: 'cuda:1', 44: 'cuda:1', 45: 'cuda:1', 46: 'meta', 47: 'cuda:1', 48: 'meta', 49: 'cuda:1', 50: 'cuda:1', 51: 'cuda:1', 52: 'meta', 53: 'meta', 54: 'meta', 55: 'cuda:1', 56: 'meta', 57: 'cuda:1', 58: 'meta', 59: 'meta', 60: 'meta', 61: 'cuda:1', 62: 'cuda:1', 63: 'meta'}
DEBUG 01-06 17:11:22.137798.137798 cuda_h.py:19] end experts_map_get cost 0.0023889541625976562 seconds
DEBUG 01-06 17:11:22.137006.137006 cuda_h.py:10] start gpu_sexperts
DEBUG 01-06 17:11:22.138693.138693 cuda_h.py:19] end gpu_sexperts cost 0.00032591819763183594 seconds
DEBUG 01-06 17:11:22.138477.138477 cuda_h.py:10] start gpu_experts
DEBUG 01-06 17:11:22.138398.138398 mlpmodule.py:533] gpu group tensors cost 0.0007433891296386719 s
DEBUG 01-06 17:11:22.141129.141129 mlpmodule.py:566] gpu pad cost 0.0022051334381103516 s
DEBUG 01-06 17:11:22.141214.141214 mlpmodule.py:584] gpu group einsum cost 0.00044465065002441406 s
DEBUG 01-06 17:11:22.145340.145340 mlpmodule.py:613] gpu experts func einsum cost 0.007299661636352539 s
DEBUG 01-06 17:11:22.145114.145114 cuda_h.py:19] end gpu_experts cost 0.007531404495239258 seconds
DEBUG 01-06 17:11:22.145108.145108 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-06 17:11:22.145526.145526 lmp.py:661] 
DEBUG 01-06 17:11:22.145526.145526 lmp.py:661]   Computing 20 experts on CPU...
DEBUG 01-06 17:11:22.145270.145270 cuda_h.py:19] end cpu_experts_submit cost 5.650520324707031e-05 seconds
DEBUG 01-06 17:11:22.145927.145927 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-06 17:11:22.150879.150879 mlpmodule.py:706] group tensors cost 0.004100322723388672 s
DEBUG 01-06 17:11:22.151120.151120 mlpmodule.py:744] pad cost 0.0010764598846435547 s
DEBUG 01-06 17:11:22.151508.151508 mlpmodule.py:750] create cpu tensor cost 4.506111145019531e-05 s
DEBUG 01-06 17:11:22.151265.151265 mlpmodule.py:755] move to cpu cost 3.123283386230469e-05 s
DEBUG 01-06 17:11:22.154279.154279 mlpmodule.py:769] group_w3: shape=torch.Size([20, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=57671680
DEBUG 01-06 17:11:22.154235.154235 mlpmodule.py:770] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-06 17:11:22.154959.154959 mlpmodule.py:775] group_w3 first element: 0.021728515625
WARNING 01-06 17:11:22.154996.154996 mlpmodule.py:785] start einsum2
DEBUG 01-06 17:11:22.159849.159849 mlpmodule.py:795] group einsum cost 0.007901191711425781 s
DEBUG 01-06 17:11:22.160166.160166 mlpmodule.py:803] cpy2cputensor cost 8.96453857421875e-05 s
DEBUG 01-06 17:11:22.162669.162669 cuda_h.py:19] end wait_cetm_experts cost 0.01714468002319336 seconds
DEBUG 01-06 17:11:22.163550.163550 cuda_h.py:19] end layer_moe_dgenerate_18 cost 0.029224157333374023 seconds
DEBUG 01-06 17:11:22.163868.163868 lmp.py:325] -------------------------------- end decode layer 18 --------------------------------
DEBUG 01-06 17:11:22.163605.163605 lmp.py:298] -------------------------------- start decode layer 19 --------------------------------
DEBUG 01-06 17:11:22.163460.163460 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-06 17:11:22.163875.163875 mlpmodule.py:367] cuda:1 cuda:1
DEBUG 01-06 17:11:22.164552.164552 cuda_h.py:10] start self_attn
cos shape torch.Size([65, 128]) sin shape torch.Size([65, 128]) position_ids tensor([[0]], device='cuda:1')
cos shape torch.Size([1, 1, 1, 128]) sin shape torch.Size([1, 1, 1, 128])
q_embed shape torch.Size([32, 16, 1, 128]) k_embed shape torch.Size([32, 16, 1, 128])
DEBUG 01-06 17:11:22.166754.166754 cuda_h.py:19] end self_attn cost 0.0022132396697998047 seconds
DEBUG 01-06 17:11:22.166992.166992 cuda_h.py:19] end iln_self_attn_paln cost 0.0031936168670654297 seconds
DEBUG 01-06 17:11:22.166266.166266 cuda_h.py:10] start layer_moe_dgenerate_19
DEBUG 01-06 17:11:22.167049.167049 cuda_h.py:10] start gate
DEBUG 01-06 17:11:22.167673.167673 mlpmodule.py:664]  experts func einsum cost 0.021706104278564453 s
DEBUG 01-06 17:11:22.167357.167357 cuda_h.py:19] end gate cost 0.0008327960968017578 seconds
DEBUG 01-06 17:11:22.168924.168924 cuda_h.py:10] start experts_map_get
INFO 01-06 17:11:22.168540.168540 lmp.py:609] using loaded check layer: True
INFO 01-06 17:11:22.169991.169991 lmp.py:620] 
INFO 01-06 17:11:22.169991.169991 lmp.py:620] Layer 19 Expert Device Distribution:
INFO 01-06 17:11:22.169946.169946 lmp.py:621]   Active experts: 56 (out of 64 total)
INFO 01-06 17:11:22.169026.169026 lmp.py:622] 
INFO 01-06 17:11:22.169026.169026 lmp.py:622]   Detailed Expert Distribution:
INFO 01-06 17:11:22.169968.169968 lmp.py:623]   Expert ID  | Tokens     | Actual Device  
INFO 01-06 17:11:22.169902.169902 lmp.py:624]   ----------------------------------------------------------------------
INFO 01-06 17:11:22.169744.169744 lmp.py:627]   1          | 1          |  cuda:1         
INFO 01-06 17:11:22.169202.169202 lmp.py:627]   2          | 1          |  cuda:1         
INFO 01-06 17:11:22.169183.169183 lmp.py:627]   4          | 1          |  cuda:1         
INFO 01-06 17:11:22.169448.169448 lmp.py:627]   5          | 1          |  cuda:1         
INFO 01-06 17:11:22.169952.169952 lmp.py:627]   11         | 1          |  cuda:1         
INFO 01-06 17:11:22.169218.169218 lmp.py:627]   12         | 1          |  meta           
INFO 01-06 17:11:22.169960.169960 lmp.py:627]   19         | 1          |  cuda:1         
INFO 01-06 17:11:22.169418.169418 lmp.py:627]   26         | 1          |  meta           
INFO 01-06 17:11:22.169160.169160 lmp.py:627]   33         | 1          |  cuda:1         
INFO 01-06 17:11:22.169380.169380 lmp.py:627]   38         | 1          |  cuda:1         
INFO 01-06 17:11:22.169360.169360 lmp.py:627]   43         | 1          |  cuda:1         
INFO 01-06 17:11:22.169864.169864 lmp.py:627]   44         | 1          |  meta           
INFO 01-06 17:11:22.169130.169130 lmp.py:627]   49         | 1          |  cuda:1         
INFO 01-06 17:11:22.169396.169396 lmp.py:627]   54         | 1          |  meta           
INFO 01-06 17:11:22.169661.169661 lmp.py:627]   58         | 1          |  meta           
INFO 01-06 17:11:22.169688.169688 lmp.py:627]   62         | 1          |  meta           
INFO 01-06 17:11:22.169954.169954 lmp.py:627]   10         | 2          |  cuda:1         
INFO 01-06 17:11:22.169935.169935 lmp.py:627]   14         | 2          |  cuda:1         
INFO 01-06 17:11:22.169916.169916 lmp.py:627]   21         | 2          |  cuda:1         
INFO 01-06 17:11:22.169327.169327 lmp.py:627]   24         | 2          |  meta           
INFO 01-06 17:11:22.169069.169069 lmp.py:627]   32         | 2          |  meta           
INFO 01-06 17:11:22.169096.169096 lmp.py:627]   35         | 2          |  cuda:1         
INFO 01-06 17:11:22.169362.169362 lmp.py:627]   56         | 2          |  meta           
INFO 01-06 17:11:22.169389.169389 lmp.py:627]   60         | 2          |  meta           
INFO 01-06 17:11:22.169893.169893 lmp.py:627]   3          | 3          |  cuda:1         
INFO 01-06 17:11:22.169159.169159 lmp.py:627]   20         | 3          |  cuda:1         
INFO 01-06 17:11:22.169186.169186 lmp.py:627]   22         | 3          |  meta           
INFO 01-06 17:11:22.169405.169405 lmp.py:627]   23         | 3          |  cuda:1         
INFO 01-06 17:11:22.169148.169148 lmp.py:627]   28         | 3          |  meta           
INFO 01-06 17:11:22.169605.169605 lmp.py:627]   36         | 3          |  cuda:1         
INFO 01-06 17:11:22.169586.169586 lmp.py:627]   55         | 3          |  meta           
INFO 01-06 17:11:22.169090.169090 lmp.py:627]   61         | 3          |  cuda:1         
INFO 01-06 17:11:22.169117.169117 lmp.py:627]   7          | 4          |  cuda:1         
INFO 01-06 17:11:22.169383.169383 lmp.py:627]   9          | 4          |  cuda:1         
INFO 01-06 17:11:22.169648.169648 lmp.py:627]   16         | 4          |  meta           
INFO 01-06 17:11:22.169106.169106 lmp.py:627]   17         | 4          |  cuda:1         
INFO 01-06 17:11:22.169849.169849 lmp.py:627]   25         | 4          |  cuda:1         
INFO 01-06 17:11:22.169068.169068 lmp.py:627]   31         | 4          |  cuda:1         
INFO 01-06 17:11:22.169525.169525 lmp.py:627]   34         | 4          |  meta           
INFO 01-06 17:11:22.170791.170791 lmp.py:627]   40         | 4          |  meta           
INFO 01-06 17:11:22.170580.170580 lmp.py:627]   57         | 4          |  meta           
INFO 01-06 17:11:22.170845.170845 lmp.py:627]   18         | 5          |  cuda:1         
INFO 01-06 17:11:22.170634.170634 lmp.py:627]   37         | 5          |  cuda:1         
INFO 01-06 17:11:22.170423.170423 lmp.py:627]   39         | 5          |  cuda:1         
INFO 01-06 17:11:22.170212.170212 lmp.py:627]   47         | 5          |  meta           
INFO 01-06 17:11:22.170192.170192 lmp.py:627]   51         | 5          |  cuda:1         
INFO 01-06 17:11:22.170412.170412 lmp.py:627]   52         | 5          |  meta           
INFO 01-06 17:11:22.170393.170393 lmp.py:627]   50         | 6          |  meta           
INFO 01-06 17:11:22.170373.170373 lmp.py:627]   63         | 6          |  cuda:1         
INFO 01-06 17:11:22.170877.170877 lmp.py:627]   0          | 7          |  cuda:1         
INFO 01-06 17:11:22.170905.170905 lmp.py:627]   41         | 7          |  cuda:1         
INFO 01-06 17:11:22.170170.170170 lmp.py:627]   45         | 7          |  cuda:1         
INFO 01-06 17:11:22.170197.170197 lmp.py:627]   48         | 7          |  meta           
INFO 01-06 17:11:22.170224.170224 lmp.py:627]   53         | 8          |  cuda:1         
INFO 01-06 17:11:22.170490.170490 lmp.py:627]   29         | 9          |  cuda:1         
INFO 01-06 17:11:22.170709.170709 lmp.py:627]   13         | 13         |  meta           
INFO 01-06 17:11:22.170690.170690 lmp.py:628] ============================================================
INFO 01-06 17:11:22.170690.170690 lmp.py:628] 
INFO 01-06 17:11:22.170870.170870 lmp.py:630] experts_gpu_list: [1, 2, 4, 5, 11, 19, 33, 38, 43, 49, 10, 14, 21, 35, 3, 20, 23, 36, 61, 7, 9, 17, 25, 31, 18, 37, 39, 51, 63, 0, 41, 45, 53, 29] num: 34
INFO 01-06 17:11:22.170473.170473 lmp.py:631] experts_cpu_list: [12, 26, 44, 54, 58, 62, 24, 32, 56, 60, 22, 28, 55, 16, 34, 40, 57, 47, 52, 50, 48, 13] num: 22
INFO 01-06 17:11:22.170806.170806 lmp.py:632] expert_actual_device_map {0: 'cuda:1', 1: 'cuda:1', 2: 'cuda:1', 3: 'cuda:1', 4: 'cuda:1', 5: 'cuda:1', 6: 'cuda:1', 7: 'cuda:1', 8: 'cuda:1', 9: 'cuda:1', 10: 'cuda:1', 11: 'cuda:1', 12: 'meta', 13: 'meta', 14: 'cuda:1', 15: 'meta', 16: 'meta', 17: 'cuda:1', 18: 'cuda:1', 19: 'cuda:1', 20: 'cuda:1', 21: 'cuda:1', 22: 'meta', 23: 'cuda:1', 24: 'meta', 25: 'cuda:1', 26: 'meta', 27: 'meta', 28: 'meta', 29: 'cuda:1', 30: 'meta', 31: 'cuda:1', 32: 'meta', 33: 'cuda:1', 34: 'meta', 35: 'cuda:1', 36: 'cuda:1', 37: 'cuda:1', 38: 'cuda:1', 39: 'cuda:1', 40: 'meta', 41: 'cuda:1', 42: 'meta', 43: 'cuda:1', 44: 'meta', 45: 'cuda:1', 46: 'cuda:1', 47: 'meta', 48: 'meta', 49: 'cuda:1', 50: 'meta', 51: 'cuda:1', 52: 'meta', 53: 'cuda:1', 54: 'meta', 55: 'meta', 56: 'meta', 57: 'meta', 58: 'meta', 59: 'meta', 60: 'meta', 61: 'cuda:1', 62: 'meta', 63: 'cuda:1'}
DEBUG 01-06 17:11:22.170515.170515 cuda_h.py:19] end experts_map_get cost 0.0024030208587646484 seconds
DEBUG 01-06 17:11:22.170531.170531 cuda_h.py:10] start gpu_sexperts
DEBUG 01-06 17:11:22.170418.170418 cuda_h.py:19] end gpu_sexperts cost 0.0003323554992675781 seconds
DEBUG 01-06 17:11:22.170016.170016 cuda_h.py:10] start gpu_experts
DEBUG 01-06 17:11:22.171247.171247 mlpmodule.py:533] gpu group tensors cost 0.0006918907165527344 s
DEBUG 01-06 17:11:22.173399.173399 mlpmodule.py:566] gpu pad cost 0.0019192695617675781 s
DEBUG 01-06 17:11:22.174426.174426 mlpmodule.py:584] gpu group einsum cost 0.0005147457122802734 s
DEBUG 01-06 17:11:22.177930.177930 mlpmodule.py:613] gpu experts func einsum cost 0.006845712661743164 s
DEBUG 01-06 17:11:22.178035.178035 cuda_h.py:19] end gpu_experts cost 0.007075309753417969 seconds
DEBUG 01-06 17:11:22.178076.178076 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-06 17:11:22.178779.178779 lmp.py:661] 
DEBUG 01-06 17:11:22.178779.178779 lmp.py:661]   Computing 22 experts on CPU...
DEBUG 01-06 17:11:22.178953.178953 cuda_h.py:19] end cpu_experts_submit cost 5.745887756347656e-05 seconds
DEBUG 01-06 17:11:22.178172.178172 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-06 17:11:22.182588.182588 mlpmodule.py:706] group tensors cost 0.004472017288208008 s
DEBUG 01-06 17:11:22.185540.185540 mlpmodule.py:744] pad cost 0.001420736312866211 s
DEBUG 01-06 17:11:22.185518.185518 mlpmodule.py:750] create cpu tensor cost 4.9591064453125e-05 s
DEBUG 01-06 17:11:22.185865.185865 mlpmodule.py:755] move to cpu cost 3.6716461181640625e-05 s
DEBUG 01-06 17:11:22.188820.188820 mlpmodule.py:769] group_w3: shape=torch.Size([22, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=63438848
DEBUG 01-06 17:11:22.188498.188498 mlpmodule.py:770] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-06 17:11:22.188199.188199 mlpmodule.py:775] group_w3 first element: 0.006072998046875
WARNING 01-06 17:11:22.188911.188911 mlpmodule.py:785] start einsum2
DEBUG 01-06 17:11:22.194104.194104 mlpmodule.py:795] group einsum cost 0.008869647979736328 s
DEBUG 01-06 17:11:22.194885.194885 mlpmodule.py:803] cpy2cputensor cost 0.00011587142944335938 s
DEBUG 01-06 17:11:22.197972.197972 cuda_h.py:19] end wait_cetm_experts cost 0.019250869750976562 seconds
DEBUG 01-06 17:11:22.198245.198245 cuda_h.py:19] end layer_moe_dgenerate_19 cost 0.030978918075561523 seconds
DEBUG 01-06 17:11:22.198152.198152 lmp.py:325] -------------------------------- end decode layer 19 --------------------------------
DEBUG 01-06 17:11:22.198299.198299 lmp.py:298] -------------------------------- start decode layer 20 --------------------------------
DEBUG 01-06 17:11:22.198048.198048 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-06 17:11:22.198919.198919 mlpmodule.py:367] cuda:1 cuda:1
DEBUG 01-06 17:11:22.198945.198945 cuda_h.py:10] start self_attn
cos shape torch.Size([65, 128]) sin shape torch.Size([65, 128]) position_ids tensor([[0]], device='cuda:1')
cos shape torch.Size([1, 1, 1, 128]) sin shape torch.Size([1, 1, 1, 128])
q_embed shape torch.Size([32, 16, 1, 128]) k_embed shape torch.Size([32, 16, 1, 128])
DEBUG 01-06 17:11:22.200929.200929 cuda_h.py:19] end self_attn cost 0.0020294189453125 seconds
DEBUG 01-06 17:11:22.201298.201298 cuda_h.py:19] end iln_self_attn_paln cost 0.0028867721557617188 seconds
DEBUG 01-06 17:11:22.201896.201896 cuda_h.py:10] start layer_moe_dgenerate_20
DEBUG 01-06 17:11:22.201288.201288 cuda_h.py:10] start gate
DEBUG 01-06 17:11:22.201238.201238 cuda_h.py:19] end gate cost 0.0006234645843505859 seconds
DEBUG 01-06 17:11:22.201935.201935 cuda_h.py:10] start experts_map_get
INFO 01-06 17:11:22.202589.202589 lmp.py:609] using loaded check layer: True
INFO 01-06 17:11:22.202391.202391 lmp.py:620] 
INFO 01-06 17:11:22.202391.202391 lmp.py:620] Layer 20 Expert Device Distribution:
INFO 01-06 17:11:22.203022.203022 lmp.py:621]   Active experts: 49 (out of 64 total)
INFO 01-06 17:11:22.203155.203155 lmp.py:622] 
INFO 01-06 17:11:22.203155.203155 lmp.py:622]   Detailed Expert Distribution:
INFO 01-06 17:11:22.203289.203289 lmp.py:623]   Expert ID  | Tokens     | Actual Device  
INFO 01-06 17:11:22.203084.203084 lmp.py:624]   ----------------------------------------------------------------------
INFO 01-06 17:11:22.203595.203595 lmp.py:627]   1          | 1          |  cuda:1         
INFO 01-06 17:11:22.203675.203675 lmp.py:627]   4          | 1          |  cuda:1         
INFO 01-06 17:11:22.203279.203279 lmp.py:627]   10         | 1          |  cuda:1         
INFO 01-06 17:11:22.203597.203597 lmp.py:627]   13         | 1          |  meta           
INFO 01-06 17:11:22.203154.203154 lmp.py:627]   14         | 1          |  cuda:1         
INFO 01-06 17:11:22.203758.203758 lmp.py:627]   17         | 1          |  cuda:1         
INFO 01-06 17:11:22.203600.203600 lmp.py:627]   19         | 1          |  meta           
INFO 01-06 17:11:22.203965.203965 lmp.py:627]   27         | 1          |  cuda:1         
INFO 01-06 17:11:22.203853.203853 lmp.py:627]   29         | 1          |  cuda:1         
INFO 01-06 17:11:22.203741.203741 lmp.py:627]   30         | 1          |  cuda:1         
INFO 01-06 17:11:22.203689.203689 lmp.py:627]   41         | 1          |  meta           
INFO 01-06 17:11:22.203293.203293 lmp.py:627]   52         | 1          |  meta           
INFO 01-06 17:11:22.203896.203896 lmp.py:627]   58         | 1          |  cuda:1         
INFO 01-06 17:11:22.203215.203215 lmp.py:627]   59         | 1          |  cuda:1         
INFO 01-06 17:11:22.203772.203772 lmp.py:627]   12         | 2          |  cuda:1         
INFO 01-06 17:11:22.203899.203899 lmp.py:627]   34         | 2          |  cuda:1         
INFO 01-06 17:11:22.203502.203502 lmp.py:627]   36         | 2          |  meta           
INFO 01-06 17:11:22.203629.203629 lmp.py:627]   40         | 2          |  meta           
INFO 01-06 17:11:22.203755.203755 lmp.py:627]   55         | 2          |  meta           
INFO 01-06 17:11:22.203882.203882 lmp.py:627]   56         | 2          |  cuda:1         
INFO 01-06 17:11:22.203532.203532 lmp.py:627]   0          | 3          |  cuda:1         
INFO 01-06 17:11:22.203373.203373 lmp.py:627]   9          | 3          |  cuda:1         
INFO 01-06 17:11:22.203977.203977 lmp.py:627]   43         | 3          |  meta           
INFO 01-06 17:11:22.203819.203819 lmp.py:627]   46         | 3          |  meta           
INFO 01-06 17:11:22.203899.203899 lmp.py:627]   47         | 3          |  meta           
INFO 01-06 17:11:22.203741.203741 lmp.py:627]   51         | 3          |  cuda:1         
INFO 01-06 17:11:22.203152.203152 lmp.py:627]   57         | 3          |  meta           
INFO 01-06 17:11:22.203564.203564 lmp.py:627]   62         | 3          |  cuda:1         
INFO 01-06 17:11:22.203975.203975 lmp.py:627]   8          | 4          |  cuda:1         
INFO 01-06 17:11:22.203340.203340 lmp.py:627]   18         | 4          |  cuda:1         
INFO 01-06 17:11:22.203466.203466 lmp.py:627]   23         | 4          |  meta           
INFO 01-06 17:11:22.203832.203832 lmp.py:627]   24         | 4          |  meta           
INFO 01-06 17:11:22.203435.203435 lmp.py:627]   26         | 4          |  cuda:1         
INFO 01-06 17:11:22.203800.203800 lmp.py:627]   33         | 4          |  cuda:1         
INFO 01-06 17:11:22.203450.203450 lmp.py:627]   42         | 4          |  meta           
INFO 01-06 17:11:22.203100.203100 lmp.py:627]   44         | 4          |  cuda:1         
INFO 01-06 17:11:22.203465.203465 lmp.py:627]   49         | 4          |  meta           
INFO 01-06 17:11:22.203114.203114 lmp.py:627]   15         | 5          |  cuda:1         
INFO 01-06 17:11:22.204526.204526 lmp.py:627]   20         | 5          |  meta           
INFO 01-06 17:11:22.204891.204891 lmp.py:627]   7          | 6          |  cuda:1         
INFO 01-06 17:11:22.204779.204779 lmp.py:627]   11         | 6          |  cuda:1         
INFO 01-06 17:11:22.204144.204144 lmp.py:627]   16         | 6          |  cuda:1         
INFO 01-06 17:11:22.204032.204032 lmp.py:627]   5          | 7          |  cuda:1         
INFO 01-06 17:11:22.204397.204397 lmp.py:627]   31         | 8          |  cuda:1         
INFO 01-06 17:11:22.204570.204570 lmp.py:627]   45         | 8          |  cuda:1         
INFO 01-06 17:11:22.204220.204220 lmp.py:627]   50         | 8          |  meta           
INFO 01-06 17:11:22.204108.204108 lmp.py:627]   25         | 11         |  cuda:1         
INFO 01-06 17:11:22.204235.204235 lmp.py:627]   60         | 14         |  cuda:1         
INFO 01-06 17:11:22.204646.204646 lmp.py:627]   48         | 22         |  cuda:1         
INFO 01-06 17:11:22.204296.204296 lmp.py:628] ============================================================
INFO 01-06 17:11:22.204296.204296 lmp.py:628] 
INFO 01-06 17:11:22.204621.204621 lmp.py:630] experts_gpu_list: [1, 4, 10, 14, 17, 27, 29, 30, 58, 59, 12, 34, 56, 0, 9, 51, 62, 8, 18, 26, 33, 44, 15, 7, 11, 16, 5, 31, 45, 25, 60, 48] num: 32
INFO 01-06 17:11:22.204370.204370 lmp.py:631] experts_cpu_list: [13, 19, 41, 52, 36, 40, 55, 43, 46, 47, 57, 23, 24, 42, 49, 20, 50] num: 17
INFO 01-06 17:11:22.204279.204279 lmp.py:632] expert_actual_device_map {0: 'cuda:1', 1: 'cuda:1', 2: 'cuda:1', 3: 'cuda:1', 4: 'cuda:1', 5: 'cuda:1', 6: 'cuda:1', 7: 'cuda:1', 8: 'cuda:1', 9: 'cuda:1', 10: 'cuda:1', 11: 'cuda:1', 12: 'cuda:1', 13: 'meta', 14: 'cuda:1', 15: 'cuda:1', 16: 'cuda:1', 17: 'cuda:1', 18: 'cuda:1', 19: 'meta', 20: 'meta', 21: 'meta', 22: 'meta', 23: 'meta', 24: 'meta', 25: 'cuda:1', 26: 'cuda:1', 27: 'cuda:1', 28: 'meta', 29: 'cuda:1', 30: 'cuda:1', 31: 'cuda:1', 32: 'cuda:1', 33: 'cuda:1', 34: 'cuda:1', 35: 'cuda:1', 36: 'meta', 37: 'meta', 38: 'meta', 39: 'meta', 40: 'meta', 41: 'meta', 42: 'meta', 43: 'meta', 44: 'cuda:1', 45: 'cuda:1', 46: 'meta', 47: 'meta', 48: 'cuda:1', 49: 'meta', 50: 'meta', 51: 'cuda:1', 52: 'meta', 53: 'meta', 54: 'meta', 55: 'meta', 56: 'cuda:1', 57: 'meta', 58: 'cuda:1', 59: 'cuda:1', 60: 'cuda:1', 61: 'meta', 62: 'cuda:1', 63: 'meta'}
DEBUG 01-06 17:11:22.204532.204532 cuda_h.py:19] end experts_map_get cost 0.0023610591888427734 seconds
DEBUG 01-06 17:11:22.204985.204985 cuda_h.py:10] start gpu_sexperts
DEBUG 01-06 17:11:22.204148.204148 mlpmodule.py:664]  experts func einsum cost 0.02619194984436035 s
DEBUG 01-06 17:11:22.204047.204047 cuda_h.py:19] end gpu_sexperts cost 0.0004069805145263672 seconds
DEBUG 01-06 17:11:22.205276.205276 cuda_h.py:10] start gpu_experts
DEBUG 01-06 17:11:22.205076.205076 mlpmodule.py:533] gpu group tensors cost 0.0006883144378662109 s
DEBUG 01-06 17:11:22.207311.207311 mlpmodule.py:566] gpu pad cost 0.0018000602722167969 s
DEBUG 01-06 17:11:22.208566.208566 mlpmodule.py:584] gpu group einsum cost 0.00040340423583984375 s
DEBUG 01-06 17:11:22.211149.211149 mlpmodule.py:613] gpu experts func einsum cost 0.006428718566894531 s
DEBUG 01-06 17:11:22.211427.211427 cuda_h.py:19] end gpu_experts cost 0.006644725799560547 seconds
DEBUG 01-06 17:11:22.211620.211620 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-06 17:11:22.211038.211038 lmp.py:661] 
DEBUG 01-06 17:11:22.211038.211038 lmp.py:661]   Computing 17 experts on CPU...
DEBUG 01-06 17:11:22.211471.211471 cuda_h.py:19] end cpu_experts_submit cost 7.2479248046875e-05 seconds
DEBUG 01-06 17:11:22.211644.211644 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-06 17:11:22.227034.227034 mlpmodule.py:706] group tensors cost 0.015214204788208008 s
DEBUG 01-06 17:11:22.229174.229174 mlpmodule.py:744] pad cost 0.0012371540069580078 s
DEBUG 01-06 17:11:22.229874.229874 mlpmodule.py:750] create cpu tensor cost 5.793571472167969e-05 s
DEBUG 01-06 17:11:22.229658.229658 mlpmodule.py:755] move to cpu cost 4.220008850097656e-05 s
DEBUG 01-06 17:11:22.232491.232491 mlpmodule.py:769] group_w3: shape=torch.Size([17, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=49020928
DEBUG 01-06 17:11:22.232579.232579 mlpmodule.py:770] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-06 17:11:22.232131.232131 mlpmodule.py:775] group_w3 first element: 0.031494140625
WARNING 01-06 17:11:22.232591.232591 mlpmodule.py:785] start einsum2
DEBUG 01-06 17:11:22.236965.236965 mlpmodule.py:795] group einsum cost 0.006955146789550781 s
DEBUG 01-06 17:11:22.237606.237606 mlpmodule.py:803] cpy2cputensor cost 9.1552734375e-05 s
DEBUG 01-06 17:11:22.239862.239862 cuda_h.py:19] end wait_cetm_experts cost 0.02761077880859375 seconds
DEBUG 01-06 17:11:22.239186.239186 cuda_h.py:19] end layer_moe_dgenerate_20 cost 0.03868985176086426 seconds
DEBUG 01-06 17:11:22.240656.240656 lmp.py:325] -------------------------------- end decode layer 20 --------------------------------
DEBUG 01-06 17:11:22.240233.240233 lmp.py:298] -------------------------------- start decode layer 21 --------------------------------
DEBUG 01-06 17:11:22.240459.240459 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-06 17:11:22.240708.240708 mlpmodule.py:367] cuda:1 cuda:1
DEBUG 01-06 17:11:22.240622.240622 cuda_h.py:10] start self_attn
cos shape torch.Size([65, 128]) sin shape torch.Size([65, 128]) position_ids tensor([[0]], device='cuda:1')
cos shape torch.Size([1, 1, 1, 128]) sin shape torch.Size([1, 1, 1, 128])
q_embed shape torch.Size([32, 16, 1, 128]) k_embed shape torch.Size([32, 16, 1, 128])
DEBUG 01-06 17:11:22.242397.242397 cuda_h.py:19] end self_attn cost 0.0019066333770751953 seconds
DEBUG 01-06 17:11:22.243196.243196 cuda_h.py:19] end iln_self_attn_paln cost 0.0027894973754882812 seconds
DEBUG 01-06 17:11:22.243463.243463 cuda_h.py:10] start layer_moe_dgenerate_21
DEBUG 01-06 17:11:22.243186.243186 cuda_h.py:10] start gate
DEBUG 01-06 17:11:22.243645.243645 cuda_h.py:19] end gate cost 0.0006134510040283203 seconds
DEBUG 01-06 17:11:22.243311.243311 mlpmodule.py:664]  experts func einsum cost 0.03147745132446289 s
DEBUG 01-06 17:11:22.243307.243307 cuda_h.py:10] start experts_map_get
INFO 01-06 17:11:22.244961.244961 lmp.py:609] using loaded check layer: True
INFO 01-06 17:11:22.245882.245882 lmp.py:620] 
INFO 01-06 17:11:22.245882.245882 lmp.py:620] Layer 21 Expert Device Distribution:
INFO 01-06 17:11:22.245314.245314 lmp.py:621]   Active experts: 53 (out of 64 total)
INFO 01-06 17:11:22.245109.245109 lmp.py:622] 
INFO 01-06 17:11:22.245109.245109 lmp.py:622]   Detailed Expert Distribution:
INFO 01-06 17:11:22.245335.245335 lmp.py:623]   Expert ID  | Tokens     | Actual Device  
INFO 01-06 17:11:22.245853.245853 lmp.py:624]   ----------------------------------------------------------------------
INFO 01-06 17:11:22.245979.245979 lmp.py:627]   2          | 1          |  cuda:1         
INFO 01-06 17:11:22.245199.245199 lmp.py:627]   4          | 1          |  cuda:1         
INFO 01-06 17:11:22.245179.245179 lmp.py:627]   19         | 1          |  cuda:1         
INFO 01-06 17:11:22.245445.245445 lmp.py:627]   30         | 1          |  cuda:1         
INFO 01-06 17:11:22.245949.245949 lmp.py:627]   31         | 1          |  cuda:1         
INFO 01-06 17:11:22.245029.245029 lmp.py:627]   37         | 1          |  cuda:1         
INFO 01-06 17:11:22.245725.245725 lmp.py:627]   41         | 1          |  meta           
INFO 01-06 17:11:22.245421.245421 lmp.py:627]   43         | 1          |  cuda:1         
INFO 01-06 17:11:22.245402.245402 lmp.py:627]   47         | 1          |  meta           
INFO 01-06 17:11:22.245145.245145 lmp.py:627]   48         | 1          |  meta           
INFO 01-06 17:11:22.245887.245887 lmp.py:627]   49         | 1          |  cuda:1         
INFO 01-06 17:11:22.245391.245391 lmp.py:627]   50         | 1          |  meta           
INFO 01-06 17:11:22.245895.245895 lmp.py:627]   53         | 1          |  meta           
INFO 01-06 17:11:22.245399.245399 lmp.py:627]   57         | 1          |  cuda:1         
INFO 01-06 17:11:22.245142.245142 lmp.py:627]   59         | 1          |  meta           
INFO 01-06 17:11:22.245884.245884 lmp.py:627]   63         | 1          |  cuda:1         
INFO 01-06 17:11:22.245103.245103 lmp.py:627]   3          | 2          |  cuda:1         
INFO 01-06 17:11:22.245607.245607 lmp.py:627]   5          | 2          |  cuda:1         
INFO 01-06 17:11:22.245873.245873 lmp.py:627]   10         | 2          |  cuda:1         
INFO 01-06 17:11:22.245900.245900 lmp.py:627]   11         | 2          |  meta           
INFO 01-06 17:11:22.245166.245166 lmp.py:627]   16         | 2          |  cuda:1         
INFO 01-06 17:11:22.245193.245193 lmp.py:627]   20         | 2          |  cuda:1         
INFO 01-06 17:11:22.245458.245458 lmp.py:627]   23         | 2          |  meta           
INFO 01-06 17:11:22.245962.245962 lmp.py:627]   28         | 2          |  cuda:1         
INFO 01-06 17:11:22.245228.245228 lmp.py:627]   29         | 2          |  cuda:1         
INFO 01-06 17:11:22.245878.245878 lmp.py:627]   32         | 2          |  meta           
INFO 01-06 17:11:22.245097.245097 lmp.py:627]   33         | 2          |  cuda:1         
INFO 01-06 17:11:22.245839.245839 lmp.py:627]   34         | 2          |  meta           
INFO 01-06 17:11:22.245866.245866 lmp.py:627]   54         | 2          |  meta           
INFO 01-06 17:11:22.245132.245132 lmp.py:627]   62         | 2          |  meta           
INFO 01-06 17:11:22.245398.245398 lmp.py:627]   8          | 3          |  cuda:1         
INFO 01-06 17:11:22.245186.245186 lmp.py:627]   17         | 3          |  cuda:1         
INFO 01-06 17:11:22.245214.245214 lmp.py:627]   22         | 3          |  meta           
INFO 01-06 17:11:22.245194.245194 lmp.py:627]   39         | 3          |  meta           
INFO 01-06 17:11:22.245414.245414 lmp.py:627]   42         | 3          |  cuda:1         
INFO 01-06 17:11:22.245633.245633 lmp.py:627]   44         | 3          |  meta           
INFO 01-06 17:11:22.245137.245137 lmp.py:627]   51         | 3          |  meta           
INFO 01-06 17:11:22.246164.246164 lmp.py:627]   7          | 4          |  cuda:1         
INFO 01-06 17:11:22.246191.246191 lmp.py:627]   14         | 4          |  meta           
INFO 01-06 17:11:22.246218.246218 lmp.py:627]   26         | 4          |  meta           
INFO 01-06 17:11:22.246769.246769 lmp.py:627]   58         | 4          |  cuda:1         
INFO 01-06 17:11:22.246034.246034 lmp.py:627]   15         | 5          |  cuda:1         
INFO 01-06 17:11:22.246253.246253 lmp.py:627]   21         | 5          |  cuda:1         
INFO 01-06 17:11:22.246473.246473 lmp.py:627]   24         | 5          |  meta           
INFO 01-06 17:11:22.246738.246738 lmp.py:627]   25         | 5          |  cuda:1         
INFO 01-06 17:11:22.246765.246765 lmp.py:627]   55         | 7          |  cuda:1         
INFO 01-06 17:11:22.246269.246269 lmp.py:627]   61         | 7          |  cuda:1         
INFO 01-06 17:11:22.246773.246773 lmp.py:627]   13         | 8          |  cuda:1         
INFO 01-06 17:11:22.246562.246562 lmp.py:627]   56         | 10         |  meta           
INFO 01-06 17:11:22.246589.246589 lmp.py:627]   0          | 13         |  cuda:1         
INFO 01-06 17:11:22.246855.246855 lmp.py:627]   40         | 13         |  cuda:1         
INFO 01-06 17:11:22.246836.246836 lmp.py:627]   12         | 14         |  cuda:1         
INFO 01-06 17:11:22.246817.246817 lmp.py:627]   45         | 19         |  cuda:1         
INFO 01-06 17:11:22.246367.246367 lmp.py:628] ============================================================
INFO 01-06 17:11:22.246367.246367 lmp.py:628] 
INFO 01-06 17:11:22.246878.246878 lmp.py:630] experts_gpu_list: [2, 4, 19, 30, 31, 37, 43, 49, 57, 63, 3, 5, 10, 16, 20, 28, 29, 33, 8, 17, 42, 7, 58, 15, 21, 25, 55, 61, 13, 0, 40, 12, 45] num: 33
INFO 01-06 17:11:22.246574.246574 lmp.py:631] experts_cpu_list: [41, 47, 48, 50, 53, 59, 11, 23, 32, 34, 54, 62, 22, 39, 44, 51, 14, 26, 24, 56] num: 20
INFO 01-06 17:11:22.246721.246721 lmp.py:632] expert_actual_device_map {0: 'cuda:1', 1: 'cuda:1', 2: 'cuda:1', 3: 'cuda:1', 4: 'cuda:1', 5: 'cuda:1', 6: 'cuda:1', 7: 'cuda:1', 8: 'cuda:1', 9: 'meta', 10: 'cuda:1', 11: 'meta', 12: 'cuda:1', 13: 'cuda:1', 14: 'meta', 15: 'cuda:1', 16: 'cuda:1', 17: 'cuda:1', 18: 'cuda:1', 19: 'cuda:1', 20: 'cuda:1', 21: 'cuda:1', 22: 'meta', 23: 'meta', 24: 'meta', 25: 'cuda:1', 26: 'meta', 27: 'meta', 28: 'cuda:1', 29: 'cuda:1', 30: 'cuda:1', 31: 'cuda:1', 32: 'meta', 33: 'cuda:1', 34: 'meta', 35: 'meta', 36: 'cuda:1', 37: 'cuda:1', 38: 'meta', 39: 'meta', 40: 'cuda:1', 41: 'meta', 42: 'cuda:1', 43: 'cuda:1', 44: 'meta', 45: 'cuda:1', 46: 'meta', 47: 'meta', 48: 'meta', 49: 'cuda:1', 50: 'meta', 51: 'meta', 52: 'meta', 53: 'meta', 54: 'meta', 55: 'cuda:1', 56: 'meta', 57: 'cuda:1', 58: 'cuda:1', 59: 'meta', 60: 'meta', 61: 'cuda:1', 62: 'meta', 63: 'cuda:1'}
DEBUG 01-06 17:11:22.246292.246292 cuda_h.py:19] end experts_map_get cost 0.002319812774658203 seconds
DEBUG 01-06 17:11:22.246599.246599 cuda_h.py:10] start gpu_sexperts
DEBUG 01-06 17:11:22.246539.246539 cuda_h.py:19] end gpu_sexperts cost 0.00033545494079589844 seconds
DEBUG 01-06 17:11:22.246229.246229 cuda_h.py:10] start gpu_experts
DEBUG 01-06 17:11:22.247433.247433 mlpmodule.py:533] gpu group tensors cost 0.0006718635559082031 s
DEBUG 01-06 17:11:22.249571.249571 mlpmodule.py:566] gpu pad cost 0.0018758773803710938 s
DEBUG 01-06 17:11:22.250081.250081 mlpmodule.py:584] gpu group einsum cost 0.000518798828125 s
DEBUG 01-06 17:11:22.253285.253285 mlpmodule.py:613] gpu experts func einsum cost 0.006739139556884766 s
DEBUG 01-06 17:11:22.253410.253410 cuda_h.py:19] end gpu_experts cost 0.006948947906494141 seconds
DEBUG 01-06 17:11:22.253643.253643 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-06 17:11:22.254631.254631 lmp.py:661] 
DEBUG 01-06 17:11:22.254631.254631 lmp.py:661]   Computing 20 experts on CPU...
DEBUG 01-06 17:11:22.254944.254944 cuda_h.py:19] end cpu_experts_submit cost 5.4836273193359375e-05 seconds
DEBUG 01-06 17:11:22.254448.254448 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-06 17:11:22.263618.263618 mlpmodule.py:706] group tensors cost 0.00906229019165039 s
DEBUG 01-06 17:11:22.264804.264804 mlpmodule.py:744] pad cost 0.0010013580322265625 s
DEBUG 01-06 17:11:22.265032.265032 mlpmodule.py:750] create cpu tensor cost 4.172325134277344e-05 s
DEBUG 01-06 17:11:22.265094.265094 mlpmodule.py:755] move to cpu cost 4.6253204345703125e-05 s
DEBUG 01-06 17:11:22.267658.267658 mlpmodule.py:769] group_w3: shape=torch.Size([20, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=57671680
DEBUG 01-06 17:11:22.267038.267038 mlpmodule.py:770] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-06 17:11:22.267636.267636 mlpmodule.py:775] group_w3 first element: -0.0242919921875
WARNING 01-06 17:11:22.267221.267221 mlpmodule.py:785] start einsum2
DEBUG 01-06 17:11:22.272154.272154 mlpmodule.py:795] group einsum cost 0.007273435592651367 s
DEBUG 01-06 17:11:22.272352.272352 mlpmodule.py:803] cpy2cputensor cost 0.00010895729064941406 s
DEBUG 01-06 17:11:22.275400.275400 cuda_h.py:19] end wait_cetm_experts cost 0.02120828628540039 seconds
DEBUG 01-06 17:11:22.275891.275891 cuda_h.py:19] end layer_moe_dgenerate_21 cost 0.032712459564208984 seconds
DEBUG 01-06 17:11:22.276613.276613 lmp.py:325] -------------------------------- end decode layer 21 --------------------------------
DEBUG 01-06 17:11:22.276933.276933 lmp.py:298] -------------------------------- start decode layer 22 --------------------------------
DEBUG 01-06 17:11:22.276272.276272 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-06 17:11:22.276284.276284 mlpmodule.py:367] cuda:1 cuda:1
DEBUG 01-06 17:11:22.276528.276528 cuda_h.py:10] start self_attn
cos shape torch.Size([65, 128]) sin shape torch.Size([65, 128]) position_ids tensor([[0]], device='cuda:1')
cos shape torch.Size([1, 1, 1, 128]) sin shape torch.Size([1, 1, 1, 128])
q_embed shape torch.Size([32, 16, 1, 128]) k_embed shape torch.Size([32, 16, 1, 128])
DEBUG 01-06 17:11:22.279060.279060 cuda_h.py:19] end self_attn cost 0.002544879913330078 seconds
DEBUG 01-06 17:11:22.279801.279801 cuda_h.py:19] end iln_self_attn_paln cost 0.003677845001220703 seconds
DEBUG 01-06 17:11:22.279498.279498 cuda_h.py:10] start layer_moe_dgenerate_22
DEBUG 01-06 17:11:22.279891.279891 cuda_h.py:10] start gate
DEBUG 01-06 17:11:22.280604.280604 mlpmodule.py:664]  experts func einsum cost 0.025858402252197266 s
DEBUG 01-06 17:11:22.280778.280778 cuda_h.py:19] end gate cost 0.0007398128509521484 seconds
DEBUG 01-06 17:11:22.280622.280622 cuda_h.py:10] start experts_map_get
INFO 01-06 17:11:22.281230.281230 lmp.py:609] using loaded check layer: True
INFO 01-06 17:11:22.281800.281800 lmp.py:620] 
INFO 01-06 17:11:22.281800.281800 lmp.py:620] Layer 22 Expert Device Distribution:
INFO 01-06 17:11:22.281754.281754 lmp.py:621]   Active experts: 47 (out of 64 total)
INFO 01-06 17:11:22.281312.281312 lmp.py:622] 
INFO 01-06 17:11:22.281312.281312 lmp.py:622]   Detailed Expert Distribution:
INFO 01-06 17:11:22.281061.281061 lmp.py:623]   Expert ID  | Tokens     | Actual Device  
INFO 01-06 17:11:22.281949.281949 lmp.py:624]   ----------------------------------------------------------------------
INFO 01-06 17:11:22.281791.281791 lmp.py:627]   8          | 1          |  cuda:1         
INFO 01-06 17:11:22.281725.281725 lmp.py:627]   20         | 1          |  meta           
INFO 01-06 17:11:22.281468.281468 lmp.py:627]   41         | 1          |  cuda:1         
INFO 01-06 17:11:22.282972.282972 lmp.py:627]   43         | 1          |  meta           
INFO 01-06 17:11:22.282476.282476 lmp.py:627]   45         | 1          |  meta           
INFO 01-06 17:11:22.282980.282980 lmp.py:627]   47         | 1          |  meta           
INFO 01-06 17:11:22.282007.282007 lmp.py:627]   62         | 1          |  meta           
INFO 01-06 17:11:22.282180.282180 lmp.py:627]   4          | 2          |  cuda:1         
INFO 01-06 17:11:22.282637.282637 lmp.py:627]   6          | 2          |  cuda:1         
INFO 01-06 17:11:22.282334.282334 lmp.py:627]   7          | 2          |  cuda:1         
INFO 01-06 17:11:22.282791.282791 lmp.py:627]   21         | 2          |  meta           
INFO 01-06 17:11:22.282295.282295 lmp.py:627]   23         | 2          |  cuda:1         
INFO 01-06 17:11:22.282799.282799 lmp.py:627]   29         | 2          |  cuda:1         
INFO 01-06 17:11:22.282303.282303 lmp.py:627]   33         | 2          |  cuda:1         
INFO 01-06 17:11:22.282807.282807 lmp.py:627]   37         | 2          |  meta           
INFO 01-06 17:11:22.282311.282311 lmp.py:627]   48         | 2          |  meta           
INFO 01-06 17:11:22.282054.282054 lmp.py:627]   49         | 2          |  cuda:1         
INFO 01-06 17:11:22.282750.282750 lmp.py:627]   50         | 2          |  meta           
INFO 01-06 17:11:22.282207.282207 lmp.py:627]   59         | 2          |  cuda:1         
INFO 01-06 17:11:22.282380.282380 lmp.py:627]   63         | 2          |  cuda:1         
INFO 01-06 17:11:22.282884.282884 lmp.py:627]   3          | 3          |  cuda:1         
INFO 01-06 17:11:22.282150.282150 lmp.py:627]   12         | 3          |  cuda:1         
INFO 01-06 17:11:22.282654.282654 lmp.py:627]   17         | 3          |  cuda:1         
INFO 01-06 17:11:22.282919.282919 lmp.py:627]   32         | 3          |  cuda:1         
INFO 01-06 17:11:22.282423.282423 lmp.py:627]   40         | 3          |  cuda:1         
INFO 01-06 17:11:22.282689.282689 lmp.py:627]   42         | 3          |  meta           
INFO 01-06 17:11:22.282147.282147 lmp.py:627]   55         | 3          |  cuda:1         
INFO 01-06 17:11:22.282604.282604 lmp.py:627]   57         | 3          |  meta           
INFO 01-06 17:11:22.282824.282824 lmp.py:627]   22         | 4          |  cuda:1         
INFO 01-06 17:11:22.282520.282520 lmp.py:627]   36         | 4          |  meta           
INFO 01-06 17:11:22.282262.282262 lmp.py:627]   44         | 4          |  meta           
INFO 01-06 17:11:22.282289.282289 lmp.py:627]   58         | 4          |  cuda:1         
INFO 01-06 17:11:22.282555.282555 lmp.py:627]   10         | 5          |  meta           
INFO 01-06 17:11:22.282820.282820 lmp.py:627]   11         | 5          |  meta           
INFO 01-06 17:11:22.282563.282563 lmp.py:627]   26         | 5          |  cuda:1         
INFO 01-06 17:11:22.282828.282828 lmp.py:627]   18         | 6          |  cuda:1         
INFO 01-06 17:11:22.282571.282571 lmp.py:627]   30         | 6          |  cuda:1         
INFO 01-06 17:11:22.282790.282790 lmp.py:627]   52         | 6          |  meta           
INFO 01-06 17:11:22.282248.282248 lmp.py:627]   5          | 7          |  cuda:1         
INFO 01-06 17:11:22.282705.282705 lmp.py:627]   14         | 7          |  meta           
INFO 01-06 17:11:22.282971.282971 lmp.py:627]   28         | 7          |  meta           
INFO 01-06 17:11:22.282475.282475 lmp.py:627]   60         | 7          |  cuda:1         
INFO 01-06 17:11:22.282979.282979 lmp.py:627]   61         | 8          |  meta           
INFO 01-06 17:11:22.282721.282721 lmp.py:627]   27         | 9          |  cuda:1         
INFO 01-06 17:11:22.282987.282987 lmp.py:627]   54         | 9          |  meta           
INFO 01-06 17:11:22.282491.282491 lmp.py:627]   34         | 11         |  cuda:1         
INFO 01-06 17:11:22.282995.282995 lmp.py:627]   56         | 21         |  cuda:1         
INFO 01-06 17:11:22.282784.282784 lmp.py:628] ============================================================
INFO 01-06 17:11:22.282784.282784 lmp.py:628] 
INFO 01-06 17:11:22.282248.282248 lmp.py:630] experts_gpu_list: [8, 41, 4, 6, 7, 23, 29, 33, 49, 59, 63, 3, 12, 17, 32, 40, 55, 22, 58, 26, 18, 30, 5, 60, 27, 34, 56] num: 27
INFO 01-06 17:11:22.282613.282613 lmp.py:631] experts_cpu_list: [20, 43, 45, 47, 62, 21, 37, 48, 50, 42, 57, 36, 44, 10, 11, 52, 14, 28, 61, 54] num: 20
INFO 01-06 17:11:22.283330.283330 lmp.py:632] expert_actual_device_map {0: 'cuda:1', 1: 'cuda:1', 2: 'cuda:1', 3: 'cuda:1', 4: 'cuda:1', 5: 'cuda:1', 6: 'cuda:1', 7: 'cuda:1', 8: 'cuda:1', 9: 'meta', 10: 'meta', 11: 'meta', 12: 'cuda:1', 13: 'meta', 14: 'meta', 15: 'meta', 16: 'cuda:1', 17: 'cuda:1', 18: 'cuda:1', 19: 'cuda:1', 20: 'meta', 21: 'meta', 22: 'cuda:1', 23: 'cuda:1', 24: 'meta', 25: 'meta', 26: 'cuda:1', 27: 'cuda:1', 28: 'meta', 29: 'cuda:1', 30: 'cuda:1', 31: 'cuda:1', 32: 'cuda:1', 33: 'cuda:1', 34: 'cuda:1', 35: 'cuda:1', 36: 'meta', 37: 'meta', 38: 'meta', 39: 'cuda:1', 40: 'cuda:1', 41: 'cuda:1', 42: 'meta', 43: 'meta', 44: 'meta', 45: 'meta', 46: 'meta', 47: 'meta', 48: 'meta', 49: 'cuda:1', 50: 'meta', 51: 'cuda:1', 52: 'meta', 53: 'cuda:1', 54: 'meta', 55: 'cuda:1', 56: 'cuda:1', 57: 'meta', 58: 'cuda:1', 59: 'cuda:1', 60: 'cuda:1', 61: 'meta', 62: 'meta', 63: 'cuda:1'}
DEBUG 01-06 17:11:22.283231.283231 cuda_h.py:19] end experts_map_get cost 0.0021347999572753906 seconds
DEBUG 01-06 17:11:22.283102.283102 cuda_h.py:10] start gpu_sexperts
DEBUG 01-06 17:11:22.283405.283405 cuda_h.py:19] end gpu_sexperts cost 0.0003230571746826172 seconds
DEBUG 01-06 17:11:22.283149.283149 cuda_h.py:10] start gpu_experts
DEBUG 01-06 17:11:22.284282.284282 mlpmodule.py:533] gpu group tensors cost 0.0005533695220947266 s
DEBUG 01-06 17:11:22.285893.285893 mlpmodule.py:566] gpu pad cost 0.0015575885772705078 s
DEBUG 01-06 17:11:22.286079.286079 mlpmodule.py:584] gpu group einsum cost 0.0005280971527099609 s
DEBUG 01-06 17:11:22.289017.289017 mlpmodule.py:613] gpu experts func einsum cost 0.005865812301635742 s
DEBUG 01-06 17:11:22.289697.289697 cuda_h.py:19] end gpu_experts cost 0.006060361862182617 seconds
DEBUG 01-06 17:11:22.289083.289083 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-06 17:11:22.289031.289031 lmp.py:661] 
DEBUG 01-06 17:11:22.289031.289031 lmp.py:661]   Computing 20 experts on CPU...
DEBUG 01-06 17:11:22.289881.289881 cuda_h.py:19] end cpu_experts_submit cost 6.413459777832031e-05 seconds
DEBUG 01-06 17:11:22.289676.289676 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-06 17:11:22.298591.298591 mlpmodule.py:706] group tensors cost 0.008329629898071289 s
DEBUG 01-06 17:11:22.300962.300962 mlpmodule.py:744] pad cost 0.0011661052703857422 s
DEBUG 01-06 17:11:22.300118.300118 mlpmodule.py:750] create cpu tensor cost 4.696846008300781e-05 s
DEBUG 01-06 17:11:22.300074.300074 mlpmodule.py:755] move to cpu cost 3.314018249511719e-05 s
DEBUG 01-06 17:11:22.302772.302772 mlpmodule.py:769] group_w3: shape=torch.Size([20, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=57671680
DEBUG 01-06 17:11:22.302767.302767 mlpmodule.py:770] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-06 17:11:22.303372.303372 mlpmodule.py:775] group_w3 first element: 0.013671875
WARNING 01-06 17:11:22.303084.303084 mlpmodule.py:785] start einsum2
DEBUG 01-06 17:11:22.307312.307312 mlpmodule.py:795] group einsum cost 0.007434368133544922 s
DEBUG 01-06 17:11:22.307098.307098 mlpmodule.py:803] cpy2cputensor cost 8.106231689453125e-05 s
DEBUG 01-06 17:11:22.310385.310385 cuda_h.py:19] end wait_cetm_experts cost 0.020872116088867188 seconds
DEBUG 01-06 17:11:22.311192.311192 cuda_h.py:19] end layer_moe_dgenerate_22 cost 0.031160593032836914 seconds
DEBUG 01-06 17:11:22.311953.311953 lmp.py:325] -------------------------------- end decode layer 22 --------------------------------
DEBUG 01-06 17:11:22.311875.311875 lmp.py:298] -------------------------------- start decode layer 23 --------------------------------
DEBUG 01-06 17:11:22.311532.311532 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-06 17:11:22.311834.311834 mlpmodule.py:367] cuda:1 cuda:1
DEBUG 01-06 17:11:22.311065.311065 cuda_h.py:10] start self_attn
cos shape torch.Size([65, 128]) sin shape torch.Size([65, 128]) position_ids tensor([[0]], device='cuda:1')
cos shape torch.Size([1, 1, 1, 128]) sin shape torch.Size([1, 1, 1, 128])
q_embed shape torch.Size([32, 16, 1, 128]) k_embed shape torch.Size([32, 16, 1, 128])
DEBUG 01-06 17:11:22.313180.313180 cuda_h.py:19] end self_attn cost 0.001984119415283203 seconds
DEBUG 01-06 17:11:22.314225.314225 cuda_h.py:19] end iln_self_attn_paln cost 0.0028629302978515625 seconds
DEBUG 01-06 17:11:22.314452.314452 cuda_h.py:10] start layer_moe_dgenerate_23
DEBUG 01-06 17:11:22.314083.314083 cuda_h.py:10] start gate
DEBUG 01-06 17:11:22.315986.315986 cuda_h.py:19] end gate cost 0.0006237030029296875 seconds
DEBUG 01-06 17:11:22.315398.315398 cuda_h.py:10] start experts_map_get
INFO 01-06 17:11:22.315205.315205 lmp.py:609] using loaded check layer: True
INFO 01-06 17:11:22.316927.316927 lmp.py:620] 
INFO 01-06 17:11:22.316927.316927 lmp.py:620] Layer 23 Expert Device Distribution:
INFO 01-06 17:11:22.316789.316789 lmp.py:621]   Active experts: 48 (out of 64 total)
INFO 01-06 17:11:22.316492.316492 lmp.py:622] 
INFO 01-06 17:11:22.316492.316492 lmp.py:622]   Detailed Expert Distribution:
INFO 01-06 17:11:22.316387.316387 lmp.py:623]   Expert ID  | Tokens     | Actual Device  
INFO 01-06 17:11:22.316706.316706 lmp.py:624]   ----------------------------------------------------------------------
INFO 01-06 17:11:22.316216.316216 lmp.py:627]   0          | 1          |  cuda:1         
INFO 01-06 17:11:22.316297.316297 lmp.py:627]   1          | 1          |  cuda:1         
INFO 01-06 17:11:22.316900.316900 lmp.py:627]   10         | 1          |  cuda:1         
INFO 01-06 17:11:22.316027.316027 lmp.py:627]   20         | 1          |  cuda:1         
INFO 01-06 17:11:22.316630.316630 lmp.py:627]   29         | 1          |  cuda:1         
INFO 01-06 17:11:22.316757.316757 lmp.py:627]   30         | 1          |  cuda:1         
INFO 01-06 17:11:22.316837.316837 lmp.py:627]   37         | 1          |  meta           
INFO 01-06 17:11:22.316917.316917 lmp.py:627]   51         | 1          |  meta           
INFO 01-06 17:11:22.316117.316117 lmp.py:627]   52         | 1          |  meta           
INFO 01-06 17:11:22.316721.316721 lmp.py:627]   56         | 1          |  meta           
INFO 01-06 17:11:22.316609.316609 lmp.py:627]   61         | 1          |  cuda:1         
INFO 01-06 17:11:22.316782.316782 lmp.py:627]   6          | 2          |  cuda:1         
INFO 01-06 17:11:22.316670.316670 lmp.py:627]   8          | 2          |  cuda:1         
INFO 01-06 17:11:22.316843.316843 lmp.py:627]   9          | 2          |  cuda:1         
INFO 01-06 17:11:22.316208.316208 lmp.py:627]   11         | 2          |  meta           
INFO 01-06 17:11:22.316050.316050 lmp.py:627]   21         | 2          |  meta           
INFO 01-06 17:11:22.316369.316369 lmp.py:627]   23         | 2          |  meta           
INFO 01-06 17:11:22.316210.316210 lmp.py:627]   34         | 2          |  cuda:1         
INFO 01-06 17:11:22.316337.316337 lmp.py:627]   3          | 3          |  cuda:1         
INFO 01-06 17:11:22.316702.316702 lmp.py:627]   22         | 3          |  cuda:1         
INFO 01-06 17:11:22.316305.316305 lmp.py:627]   33         | 3          |  meta           
INFO 01-06 17:11:22.316717.316717 lmp.py:627]   45         | 3          |  meta           
INFO 01-06 17:11:22.316843.316843 lmp.py:627]   49         | 3          |  meta           
INFO 01-06 17:11:22.316493.316493 lmp.py:627]   53         | 3          |  meta           
INFO 01-06 17:11:22.316858.316858 lmp.py:627]   57         | 3          |  meta           
INFO 01-06 17:11:22.316700.316700 lmp.py:627]   58         | 3          |  meta           
INFO 01-06 17:11:22.316496.316496 lmp.py:627]   2          | 4          |  cuda:1         
INFO 01-06 17:11:22.316576.316576 lmp.py:627]   18         | 4          |  cuda:1         
INFO 01-06 17:11:22.316179.316179 lmp.py:627]   19         | 4          |  cuda:1         
INFO 01-06 17:11:22.316306.316306 lmp.py:627]   35         | 4          |  cuda:1         
INFO 01-06 17:11:22.316194.316194 lmp.py:627]   54         | 4          |  cuda:1         
INFO 01-06 17:11:22.316321.316321 lmp.py:627]   55         | 4          |  cuda:1         
INFO 01-06 17:11:22.316209.316209 lmp.py:627]   13         | 5          |  cuda:1         
INFO 01-06 17:11:22.316574.316574 lmp.py:627]   16         | 5          |  meta           
INFO 01-06 17:11:22.317416.317416 lmp.py:627]   63         | 5          |  meta           
INFO 01-06 17:11:22.317019.317019 lmp.py:627]   42         | 6          |  cuda:1         
INFO 01-06 17:11:22.317338.317338 lmp.py:627]   44         | 6          |  meta           
INFO 01-06 17:11:22.317988.317988 lmp.py:627]   24         | 7          |  cuda:1         
INFO 01-06 17:11:22.317876.317876 lmp.py:627]   32         | 7          |  cuda:1         
INFO 01-06 17:11:22.317002.317002 lmp.py:627]   40         | 7          |  meta           
INFO 01-06 17:11:22.317891.317891 lmp.py:627]   41         | 7          |  cuda:1         
INFO 01-06 17:11:22.317540.317540 lmp.py:627]   46         | 7          |  cuda:1         
INFO 01-06 17:11:22.317667.317667 lmp.py:627]   4          | 8          |  cuda:1         
INFO 01-06 17:11:22.317509.317509 lmp.py:627]   12         | 9          |  cuda:1         
INFO 01-06 17:11:22.317112.317112 lmp.py:627]   25         | 9          |  meta           
INFO 01-06 17:11:22.317716.317716 lmp.py:627]   15         | 10         |  cuda:1         
INFO 01-06 17:11:22.317127.317127 lmp.py:627]   59         | 10         |  cuda:1         
INFO 01-06 17:11:22.317254.317254 lmp.py:627]   48         | 11         |  cuda:1         
INFO 01-06 17:11:22.317665.317665 lmp.py:628] ============================================================
INFO 01-06 17:11:22.317665.317665 lmp.py:628] 
INFO 01-06 17:11:22.317514.317514 lmp.py:630] experts_gpu_list: [0, 1, 10, 20, 29, 30, 61, 6, 8, 9, 34, 3, 22, 2, 18, 19, 35, 54, 55, 13, 42, 24, 32, 41, 46, 4, 12, 15, 59, 48] num: 30
INFO 01-06 17:11:22.317071.317071 lmp.py:631] experts_cpu_list: [37, 51, 52, 56, 11, 21, 23, 33, 45, 49, 53, 57, 58, 16, 63, 44, 40, 25] num: 18
INFO 01-06 17:11:22.317648.317648 lmp.py:632] expert_actual_device_map {0: 'cuda:1', 1: 'cuda:1', 2: 'cuda:1', 3: 'cuda:1', 4: 'cuda:1', 5: 'cuda:1', 6: 'cuda:1', 7: 'cuda:1', 8: 'cuda:1', 9: 'cuda:1', 10: 'cuda:1', 11: 'meta', 12: 'cuda:1', 13: 'cuda:1', 14: 'meta', 15: 'cuda:1', 16: 'meta', 17: 'meta', 18: 'cuda:1', 19: 'cuda:1', 20: 'cuda:1', 21: 'meta', 22: 'cuda:1', 23: 'meta', 24: 'cuda:1', 25: 'meta', 26: 'cuda:1', 27: 'meta', 28: 'meta', 29: 'cuda:1', 30: 'cuda:1', 31: 'cuda:1', 32: 'cuda:1', 33: 'meta', 34: 'cuda:1', 35: 'cuda:1', 36: 'cuda:1', 37: 'meta', 38: 'meta', 39: 'meta', 40: 'meta', 41: 'cuda:1', 42: 'cuda:1', 43: 'cuda:1', 44: 'meta', 45: 'meta', 46: 'cuda:1', 47: 'meta', 48: 'cuda:1', 49: 'meta', 50: 'cuda:1', 51: 'meta', 52: 'meta', 53: 'meta', 54: 'cuda:1', 55: 'cuda:1', 56: 'meta', 57: 'meta', 58: 'meta', 59: 'cuda:1', 60: 'meta', 61: 'cuda:1', 62: 'meta', 63: 'meta'}
DEBUG 01-06 17:11:22.317080.317080 cuda_h.py:19] end experts_map_get cost 0.002329111099243164 seconds
DEBUG 01-06 17:11:22.317725.317725 mlpmodule.py:664]  experts func einsum cost 0.02758646011352539 s
DEBUG 01-06 17:11:22.317624.317624 cuda_h.py:10] start gpu_sexperts
DEBUG 01-06 17:11:22.318414.318414 cuda_h.py:19] end gpu_sexperts cost 0.000339508056640625 seconds
DEBUG 01-06 17:11:22.318972.318972 cuda_h.py:10] start gpu_experts
DEBUG 01-06 17:11:22.318128.318128 mlpmodule.py:533] gpu group tensors cost 0.0006372928619384766 s
DEBUG 01-06 17:11:22.320234.320234 mlpmodule.py:566] gpu pad cost 0.0017118453979492188 s
DEBUG 01-06 17:11:22.321284.321284 mlpmodule.py:584] gpu group einsum cost 0.0004298686981201172 s
DEBUG 01-06 17:11:22.324667.324667 mlpmodule.py:613] gpu experts func einsum cost 0.006052255630493164 s
DEBUG 01-06 17:11:22.324805.324805 cuda_h.py:19] end gpu_experts cost 0.006270647048950195 seconds
DEBUG 01-06 17:11:22.324191.324191 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-06 17:11:22.324847.324847 lmp.py:661] 
DEBUG 01-06 17:11:22.324847.324847 lmp.py:661]   Computing 18 experts on CPU...
DEBUG 01-06 17:11:22.324737.324737 cuda_h.py:19] end cpu_experts_submit cost 5.7697296142578125e-05 seconds
DEBUG 01-06 17:11:22.324102.324102 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-06 17:11:22.332400.332400 mlpmodule.py:706] group tensors cost 0.0077440738677978516 s
DEBUG 01-06 17:11:22.334366.334366 mlpmodule.py:744] pad cost 0.0009829998016357422 s
DEBUG 01-06 17:11:22.334455.334455 mlpmodule.py:750] create cpu tensor cost 4.172325134277344e-05 s
DEBUG 01-06 17:11:22.334828.334828 mlpmodule.py:755] move to cpu cost 2.86102294921875e-05 s
DEBUG 01-06 17:11:22.336423.336423 mlpmodule.py:769] group_w3: shape=torch.Size([18, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=51904512
DEBUG 01-06 17:11:22.336127.336127 mlpmodule.py:770] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-06 17:11:22.336189.336189 mlpmodule.py:775] group_w3 first element: -0.0390625
WARNING 01-06 17:11:22.336073.336073 mlpmodule.py:785] start einsum2
DEBUG 01-06 17:11:22.340097.340097 mlpmodule.py:795] group einsum cost 0.00602269172668457 s
DEBUG 01-06 17:11:22.340877.340877 mlpmodule.py:803] cpy2cputensor cost 8.559226989746094e-05 s
DEBUG 01-06 17:11:22.343663.343663 cuda_h.py:19] end wait_cetm_experts cost 0.018274307250976562 seconds
DEBUG 01-06 17:11:22.343100.343100 cuda_h.py:19] end layer_moe_dgenerate_23 cost 0.029017925262451172 seconds
DEBUG 01-06 17:11:22.343669.343669 lmp.py:325] -------------------------------- end decode layer 23 --------------------------------
DEBUG 01-06 17:11:22.343962.343962 lmp.py:298] -------------------------------- start decode layer 24 --------------------------------
DEBUG 01-06 17:11:22.343618.343618 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-06 17:11:22.343371.343371 mlpmodule.py:367] cuda:1 cuda:1
DEBUG 01-06 17:11:22.344199.344199 cuda_h.py:10] start self_attn
cos shape torch.Size([65, 128]) sin shape torch.Size([65, 128]) position_ids tensor([[0]], device='cuda:1')
cos shape torch.Size([1, 1, 1, 128]) sin shape torch.Size([1, 1, 1, 128])
q_embed shape torch.Size([32, 16, 1, 128]) k_embed shape torch.Size([32, 16, 1, 128])
DEBUG 01-06 17:11:22.346512.346512 cuda_h.py:19] end self_attn cost 0.002158641815185547 seconds
DEBUG 01-06 17:11:22.346749.346749 cuda_h.py:19] end iln_self_attn_paln cost 0.003078460693359375 seconds
DEBUG 01-06 17:11:22.346116.346116 cuda_h.py:10] start layer_moe_dgenerate_24
DEBUG 01-06 17:11:22.346183.346183 cuda_h.py:10] start gate
DEBUG 01-06 17:11:22.347423.347423 mlpmodule.py:664]  experts func einsum cost 0.022490262985229492 s
DEBUG 01-06 17:11:22.347341.347341 cuda_h.py:19] end gate cost 0.0006926059722900391 seconds
DEBUG 01-06 17:11:22.347907.347907 cuda_h.py:10] start experts_map_get
INFO 01-06 17:11:22.348967.348967 lmp.py:609] using loaded check layer: True
INFO 01-06 17:11:22.348168.348168 lmp.py:620] 
INFO 01-06 17:11:22.348168.348168 lmp.py:620] Layer 24 Expert Device Distribution:
INFO 01-06 17:11:22.348753.348753 lmp.py:621]   Active experts: 52 (out of 64 total)
INFO 01-06 17:11:22.348455.348455 lmp.py:622] 
INFO 01-06 17:11:22.348455.348455 lmp.py:622]   Detailed Expert Distribution:
INFO 01-06 17:11:22.348350.348350 lmp.py:623]   Expert ID  | Tokens     | Actual Device  
INFO 01-06 17:11:22.348192.348192 lmp.py:624]   ----------------------------------------------------------------------
INFO 01-06 17:11:22.348703.348703 lmp.py:627]   17         | 1          |  cuda:1         
INFO 01-06 17:11:22.348306.348306 lmp.py:627]   24         | 1          |  meta           
INFO 01-06 17:11:22.348195.348195 lmp.py:627]   25         | 1          |  meta           
INFO 01-06 17:11:22.349606.349606 lmp.py:627]   26         | 1          |  cuda:1         
INFO 01-06 17:11:22.349494.349494 lmp.py:627]   31         | 1          |  cuda:1         
INFO 01-06 17:11:22.349621.349621 lmp.py:627]   33         | 1          |  meta           
INFO 01-06 17:11:22.349463.349463 lmp.py:627]   45         | 1          |  cuda:1         
INFO 01-06 17:11:22.349828.349828 lmp.py:627]   47         | 1          |  meta           
INFO 01-06 17:11:22.349239.349239 lmp.py:627]   57         | 1          |  cuda:1         
INFO 01-06 17:11:22.349889.349889 lmp.py:627]   59         | 1          |  meta           
INFO 01-06 17:11:22.349823.349823 lmp.py:627]   60         | 1          |  cuda:1         
INFO 01-06 17:11:22.349235.349235 lmp.py:627]   62         | 1          |  cuda:1         
INFO 01-06 17:11:22.349408.349408 lmp.py:627]   1          | 2          |  cuda:1         
INFO 01-06 17:11:22.349580.349580 lmp.py:627]   5          | 2          |  cuda:1         
INFO 01-06 17:11:22.349946.349946 lmp.py:627]   11         | 2          |  cuda:1         
INFO 01-06 17:11:22.349311.349311 lmp.py:627]   15         | 2          |  meta           
INFO 01-06 17:11:22.349676.349676 lmp.py:627]   21         | 2          |  cuda:1         
INFO 01-06 17:11:22.349087.349087 lmp.py:627]   28         | 2          |  cuda:1         
INFO 01-06 17:11:22.349260.349260 lmp.py:627]   35         | 2          |  meta           
INFO 01-06 17:11:22.349671.349671 lmp.py:627]   38         | 2          |  meta           
INFO 01-06 17:11:22.349606.349606 lmp.py:627]   39         | 2          |  meta           
INFO 01-06 17:11:22.349779.349779 lmp.py:627]   48         | 2          |  meta           
INFO 01-06 17:11:22.349952.349952 lmp.py:627]   2          | 3          |  cuda:1         
INFO 01-06 17:11:22.349317.349317 lmp.py:627]   8          | 3          |  cuda:1         
INFO 01-06 17:11:22.349443.349443 lmp.py:627]   10         | 3          |  cuda:1         
INFO 01-06 17:11:22.349808.349808 lmp.py:627]   13         | 3          |  meta           
INFO 01-06 17:11:22.349173.349173 lmp.py:627]   14         | 3          |  cuda:1         
INFO 01-06 17:11:22.349108.349108 lmp.py:627]   18         | 3          |  cuda:1         
INFO 01-06 17:11:22.349281.349281 lmp.py:627]   46         | 3          |  meta           
INFO 01-06 17:11:22.349215.349215 lmp.py:627]   55         | 3          |  meta           
INFO 01-06 17:11:22.349388.349388 lmp.py:627]   58         | 3          |  cuda:1         
INFO 01-06 17:11:22.349561.349561 lmp.py:627]   61         | 3          |  meta           
INFO 01-06 17:11:22.349688.349688 lmp.py:627]   63         | 3          |  cuda:1         
INFO 01-06 17:11:22.349814.349814 lmp.py:627]   29         | 4          |  meta           
INFO 01-06 17:11:22.349941.349941 lmp.py:627]   41         | 4          |  cuda:1         
INFO 01-06 17:11:22.349306.349306 lmp.py:627]   44         | 4          |  meta           
INFO 01-06 17:11:22.349717.349717 lmp.py:627]   49         | 4          |  cuda:1         
INFO 01-06 17:11:22.349890.349890 lmp.py:627]   52         | 4          |  cuda:1         
INFO 01-06 17:11:22.349301.349301 lmp.py:627]   7          | 5          |  cuda:1         
INFO 01-06 17:11:22.349474.349474 lmp.py:627]   22         | 5          |  cuda:1         
INFO 01-06 17:11:22.349124.349124 lmp.py:627]   40         | 5          |  cuda:1         
INFO 01-06 17:11:22.349297.349297 lmp.py:627]   56         | 5          |  meta           
INFO 01-06 17:11:22.349424.349424 lmp.py:627]   6          | 6          |  cuda:1         
INFO 01-06 17:11:22.349550.349550 lmp.py:627]   32         | 6          |  cuda:1         
INFO 01-06 17:11:22.349677.349677 lmp.py:627]   9          | 7          |  meta           
INFO 01-06 17:11:22.349850.349850 lmp.py:627]   12         | 7          |  cuda:1         
INFO 01-06 17:11:22.349261.349261 lmp.py:627]   20         | 8          |  meta           
INFO 01-06 17:11:22.350196.350196 lmp.py:627]   23         | 9          |  cuda:1         
INFO 01-06 17:11:22.350607.350607 lmp.py:627]   0          | 10         |  cuda:1         
INFO 01-06 17:11:22.350734.350734 lmp.py:627]   50         | 10         |  cuda:1         
INFO 01-06 17:11:22.350337.350337 lmp.py:627]   3          | 12         |  cuda:1         
INFO 01-06 17:11:22.350940.350940 lmp.py:627]   34         | 12         |  cuda:1         
INFO 01-06 17:11:22.350352.350352 lmp.py:628] ============================================================
INFO 01-06 17:11:22.350352.350352 lmp.py:628] 
INFO 01-06 17:11:22.350724.350724 lmp.py:630] experts_gpu_list: [17, 26, 31, 45, 57, 60, 62, 1, 5, 11, 21, 28, 2, 8, 10, 14, 18, 58, 63, 41, 49, 52, 7, 22, 40, 6, 32, 12, 23, 0, 50, 3, 34] num: 33
INFO 01-06 17:11:22.350248.350248 lmp.py:631] experts_cpu_list: [24, 25, 33, 47, 59, 15, 35, 38, 39, 48, 13, 46, 55, 61, 29, 44, 56, 9, 20] num: 19
INFO 01-06 17:11:22.350580.350580 lmp.py:632] expert_actual_device_map {0: 'cuda:1', 1: 'cuda:1', 2: 'cuda:1', 3: 'cuda:1', 4: 'cuda:1', 5: 'cuda:1', 6: 'cuda:1', 7: 'cuda:1', 8: 'cuda:1', 9: 'meta', 10: 'cuda:1', 11: 'cuda:1', 12: 'cuda:1', 13: 'meta', 14: 'cuda:1', 15: 'meta', 16: 'meta', 17: 'cuda:1', 18: 'cuda:1', 19: 'meta', 20: 'meta', 21: 'cuda:1', 22: 'cuda:1', 23: 'cuda:1', 24: 'meta', 25: 'meta', 26: 'cuda:1', 27: 'cuda:1', 28: 'cuda:1', 29: 'meta', 30: 'meta', 31: 'cuda:1', 32: 'cuda:1', 33: 'meta', 34: 'cuda:1', 35: 'meta', 36: 'meta', 37: 'cuda:1', 38: 'meta', 39: 'meta', 40: 'cuda:1', 41: 'cuda:1', 42: 'meta', 43: 'meta', 44: 'meta', 45: 'cuda:1', 46: 'meta', 47: 'meta', 48: 'meta', 49: 'cuda:1', 50: 'cuda:1', 51: 'meta', 52: 'cuda:1', 53: 'cuda:1', 54: 'meta', 55: 'meta', 56: 'meta', 57: 'cuda:1', 58: 'cuda:1', 59: 'meta', 60: 'cuda:1', 61: 'meta', 62: 'cuda:1', 63: 'cuda:1'}
DEBUG 01-06 17:11:22.350197.350197 cuda_h.py:19] end experts_map_get cost 0.0024950504302978516 seconds
DEBUG 01-06 17:11:22.350882.350882 cuda_h.py:10] start gpu_sexperts
DEBUG 01-06 17:11:22.350193.350193 cuda_h.py:19] end gpu_sexperts cost 0.00032782554626464844 seconds
DEBUG 01-06 17:11:22.350029.350029 cuda_h.py:10] start gpu_experts
DEBUG 01-06 17:11:22.351286.351286 mlpmodule.py:533] gpu group tensors cost 0.0006704330444335938 s
DEBUG 01-06 17:11:22.353641.353641 mlpmodule.py:566] gpu pad cost 0.0018606185913085938 s
DEBUG 01-06 17:11:22.353068.353068 mlpmodule.py:584] gpu group einsum cost 0.0003962516784667969 s
DEBUG 01-06 17:11:22.357454.357454 mlpmodule.py:613] gpu experts func einsum cost 0.006480216979980469 s
DEBUG 01-06 17:11:22.357287.357287 cuda_h.py:19] end gpu_experts cost 0.00668644905090332 seconds
DEBUG 01-06 17:11:22.357805.357805 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-06 17:11:22.357984.357984 lmp.py:661] 
DEBUG 01-06 17:11:22.357984.357984 lmp.py:661]   Computing 19 experts on CPU...
DEBUG 01-06 17:11:22.357503.357503 cuda_h.py:19] end cpu_experts_submit cost 6.580352783203125e-05 seconds
DEBUG 01-06 17:11:22.357246.357246 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-06 17:11:22.365769.365769 mlpmodule.py:706] group tensors cost 0.007524728775024414 s
DEBUG 01-06 17:11:22.366259.366259 mlpmodule.py:744] pad cost 0.0010304450988769531 s
DEBUG 01-06 17:11:22.367263.367263 mlpmodule.py:750] create cpu tensor cost 4.1484832763671875e-05 s
DEBUG 01-06 17:11:22.367736.367736 mlpmodule.py:755] move to cpu cost 3.0279159545898438e-05 s
DEBUG 01-06 17:11:22.369873.369873 mlpmodule.py:769] group_w3: shape=torch.Size([19, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=54788096
DEBUG 01-06 17:11:22.369722.369722 mlpmodule.py:770] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-06 17:11:22.369843.369843 mlpmodule.py:775] group_w3 first element: 0.032470703125
WARNING 01-06 17:11:22.369045.369045 mlpmodule.py:785] start einsum2
DEBUG 01-06 17:11:22.373986.373986 mlpmodule.py:795] group einsum cost 0.006253242492675781 s
DEBUG 01-06 17:11:22.373502.373502 mlpmodule.py:803] cpy2cputensor cost 9.942054748535156e-05 s
DEBUG 01-06 17:11:22.376862.376862 cuda_h.py:19] end wait_cetm_experts cost 0.01852250099182129 seconds
DEBUG 01-06 17:11:22.376850.376850 cuda_h.py:19] end layer_moe_dgenerate_24 cost 0.029809236526489258 seconds
DEBUG 01-06 17:11:22.376142.376142 lmp.py:325] -------------------------------- end decode layer 24 --------------------------------
DEBUG 01-06 17:11:22.376601.376601 lmp.py:298] -------------------------------- start decode layer 25 --------------------------------
DEBUG 01-06 17:11:22.376848.376848 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-06 17:11:22.377204.377204 mlpmodule.py:367] cuda:1 cuda:1
DEBUG 01-06 17:11:22.377929.377929 cuda_h.py:10] start self_attn
cos shape torch.Size([65, 128]) sin shape torch.Size([65, 128]) position_ids tensor([[0]], device='cuda:1')
cos shape torch.Size([1, 1, 1, 128]) sin shape torch.Size([1, 1, 1, 128])
q_embed shape torch.Size([32, 16, 1, 128]) k_embed shape torch.Size([32, 16, 1, 128])
DEBUG 01-06 17:11:22.380852.380852 cuda_h.py:19] end self_attn cost 0.002552032470703125 seconds
DEBUG 01-06 17:11:22.380268.380268 mlpmodule.py:664]  experts func einsum cost 0.02283644676208496 s
DEBUG 01-06 17:11:22.380988.380988 cuda_h.py:19] end iln_self_attn_paln cost 0.003936767578125 seconds
DEBUG 01-06 17:11:22.381582.381582 cuda_h.py:10] start layer_moe_dgenerate_25
DEBUG 01-06 17:11:22.381240.381240 cuda_h.py:10] start gate
DEBUG 01-06 17:11:22.381401.381401 cuda_h.py:19] end gate cost 0.0006196498870849609 seconds
DEBUG 01-06 17:11:22.381483.381483 cuda_h.py:10] start experts_map_get
INFO 01-06 17:11:22.382203.382203 lmp.py:609] using loaded check layer: True
INFO 01-06 17:11:22.382873.382873 lmp.py:620] 
INFO 01-06 17:11:22.382873.382873 lmp.py:620] Layer 25 Expert Device Distribution:
INFO 01-06 17:11:22.382351.382351 lmp.py:621]   Active experts: 51 (out of 64 total)
INFO 01-06 17:11:22.382908.382908 lmp.py:622] 
INFO 01-06 17:11:22.382908.382908 lmp.py:622]   Detailed Expert Distribution:
INFO 01-06 17:11:22.382942.382942 lmp.py:623]   Expert ID  | Tokens     | Actual Device  
INFO 01-06 17:11:22.382399.382399 lmp.py:624]   ----------------------------------------------------------------------
INFO 01-06 17:11:22.383049.383049 lmp.py:627]   8          | 1          |  meta           
INFO 01-06 17:11:22.383745.383745 lmp.py:627]   14         | 1          |  cuda:1         
INFO 01-06 17:11:22.383249.383249 lmp.py:627]   16         | 1          |  meta           
INFO 01-06 17:11:22.383230.383230 lmp.py:627]   17         | 1          |  cuda:1         
INFO 01-06 17:11:22.383734.383734 lmp.py:627]   20         | 1          |  meta           
INFO 01-06 17:11:22.383953.383953 lmp.py:627]   23         | 1          |  meta           
INFO 01-06 17:11:22.383172.383172 lmp.py:627]   29         | 1          |  cuda:1         
INFO 01-06 17:11:22.383915.383915 lmp.py:627]   31         | 1          |  meta           
INFO 01-06 17:11:22.383419.383419 lmp.py:627]   33         | 1          |  meta           
INFO 01-06 17:11:22.383446.383446 lmp.py:627]   36         | 1          |  meta           
INFO 01-06 17:11:22.383473.383473 lmp.py:627]   37         | 1          |  cuda:1         
INFO 01-06 17:11:22.383977.383977 lmp.py:627]   38         | 1          |  meta           
INFO 01-06 17:11:22.383243.383243 lmp.py:627]   40         | 1          |  cuda:1         
INFO 01-06 17:11:22.383508.383508 lmp.py:627]   46         | 1          |  meta           
INFO 01-06 17:11:22.383489.383489 lmp.py:627]   50         | 1          |  cuda:1         
INFO 01-06 17:11:22.383232.383232 lmp.py:627]   51         | 1          |  meta           
INFO 01-06 17:11:22.383497.383497 lmp.py:627]   52         | 1          |  cuda:1         
INFO 01-06 17:11:22.383524.383524 lmp.py:627]   56         | 1          |  cuda:1         
INFO 01-06 17:11:22.383552.383552 lmp.py:627]   59         | 1          |  meta           
INFO 01-06 17:11:22.383579.383579 lmp.py:627]   3          | 2          |  cuda:1         
INFO 01-06 17:11:22.383606.383606 lmp.py:627]   10         | 2          |  meta           
INFO 01-06 17:11:22.383633.383633 lmp.py:627]   11         | 2          |  cuda:1         
INFO 01-06 17:11:22.383899.383899 lmp.py:627]   15         | 2          |  cuda:1         
INFO 01-06 17:11:22.383687.383687 lmp.py:627]   18         | 2          |  meta           
INFO 01-06 17:11:22.383430.383430 lmp.py:627]   41         | 2          |  meta           
INFO 01-06 17:11:22.383470.383470 lmp.py:627]   45         | 2          |  meta           
INFO 01-06 17:11:22.383213.383213 lmp.py:627]   47         | 2          |  cuda:1         
INFO 01-06 17:11:22.383717.383717 lmp.py:627]   1          | 3          |  cuda:1         
INFO 01-06 17:11:22.383982.383982 lmp.py:627]   9          | 3          |  meta           
INFO 01-06 17:11:22.383010.383010 lmp.py:627]   22         | 3          |  meta           
INFO 01-06 17:11:22.383752.383752 lmp.py:627]   30         | 3          |  cuda:1         
INFO 01-06 17:11:22.383448.383448 lmp.py:627]   32         | 3          |  cuda:1         
INFO 01-06 17:11:22.383667.383667 lmp.py:627]   60         | 3          |  cuda:1         
INFO 01-06 17:11:22.383171.383171 lmp.py:627]   4          | 4          |  cuda:1         
INFO 01-06 17:11:22.383960.383960 lmp.py:627]   34         | 4          |  cuda:1         
INFO 01-06 17:11:22.383987.383987 lmp.py:627]   48         | 4          |  cuda:1         
INFO 01-06 17:11:22.383253.383253 lmp.py:627]   49         | 4          |  cuda:1         
INFO 01-06 17:11:22.383280.383280 lmp.py:627]   53         | 4          |  cuda:1         
INFO 01-06 17:11:22.383499.383499 lmp.py:627]   57         | 4          |  cuda:1         
INFO 01-06 17:11:22.383242.383242 lmp.py:627]   62         | 4          |  cuda:1         
INFO 01-06 17:11:22.383746.383746 lmp.py:627]   21         | 6          |  meta           
INFO 01-06 17:11:22.383534.383534 lmp.py:627]   27         | 6          |  cuda:1         
INFO 01-06 17:11:22.383800.383800 lmp.py:627]   43         | 6          |  meta           
INFO 01-06 17:11:22.383066.383066 lmp.py:627]   39         | 7          |  cuda:1         
INFO 01-06 17:11:22.383570.383570 lmp.py:627]   0          | 9          |  cuda:1         
INFO 01-06 17:11:22.383312.383312 lmp.py:627]   6          | 10         |  cuda:1         
INFO 01-06 17:11:22.383531.383531 lmp.py:627]   35         | 10         |  cuda:1         
INFO 01-06 17:11:22.383797.383797 lmp.py:627]   54         | 13         |  cuda:1         
INFO 01-06 17:11:22.384062.384062 lmp.py:627]   58         | 13         |  cuda:1         
INFO 01-06 17:11:22.384851.384851 lmp.py:627]   63         | 15         |  cuda:1         
INFO 01-06 17:11:22.384117.384117 lmp.py:627]   26         | 16         |  meta           
INFO 01-06 17:11:22.384667.384667 lmp.py:628] ============================================================
INFO 01-06 17:11:22.384667.384667 lmp.py:628] 
INFO 01-06 17:11:22.384608.384608 lmp.py:630] experts_gpu_list: [14, 17, 29, 37, 40, 50, 52, 56, 3, 11, 15, 47, 1, 30, 32, 60, 4, 34, 48, 49, 53, 57, 62, 27, 39, 0, 6, 35, 54, 58, 63] num: 31
INFO 01-06 17:11:22.384497.384497 lmp.py:631] experts_cpu_list: [8, 16, 20, 23, 31, 33, 36, 38, 46, 51, 59, 10, 18, 41, 45, 9, 22, 21, 43, 26] num: 20
INFO 01-06 17:11:22.384259.384259 lmp.py:632] expert_actual_device_map {0: 'cuda:1', 1: 'cuda:1', 2: 'cuda:1', 3: 'cuda:1', 4: 'cuda:1', 5: 'cuda:1', 6: 'cuda:1', 7: 'cuda:1', 8: 'meta', 9: 'meta', 10: 'meta', 11: 'cuda:1', 12: 'cuda:1', 13: 'meta', 14: 'cuda:1', 15: 'cuda:1', 16: 'meta', 17: 'cuda:1', 18: 'meta', 19: 'cuda:1', 20: 'meta', 21: 'meta', 22: 'meta', 23: 'meta', 24: 'meta', 25: 'meta', 26: 'meta', 27: 'cuda:1', 28: 'cuda:1', 29: 'cuda:1', 30: 'cuda:1', 31: 'meta', 32: 'cuda:1', 33: 'meta', 34: 'cuda:1', 35: 'cuda:1', 36: 'meta', 37: 'cuda:1', 38: 'meta', 39: 'cuda:1', 40: 'cuda:1', 41: 'meta', 42: 'meta', 43: 'meta', 44: 'meta', 45: 'meta', 46: 'meta', 47: 'cuda:1', 48: 'cuda:1', 49: 'cuda:1', 50: 'cuda:1', 51: 'meta', 52: 'cuda:1', 53: 'cuda:1', 54: 'cuda:1', 55: 'meta', 56: 'cuda:1', 57: 'cuda:1', 58: 'cuda:1', 59: 'meta', 60: 'cuda:1', 61: 'meta', 62: 'cuda:1', 63: 'cuda:1'}
DEBUG 01-06 17:11:22.384684.384684 cuda_h.py:19] end experts_map_get cost 0.0022211074829101562 seconds
DEBUG 01-06 17:11:22.384886.384886 cuda_h.py:10] start gpu_sexperts
DEBUG 01-06 17:11:22.384846.384846 cuda_h.py:19] end gpu_sexperts cost 0.0003521442413330078 seconds
DEBUG 01-06 17:11:22.384867.384867 cuda_h.py:10] start gpu_experts
DEBUG 01-06 17:11:22.385322.385322 mlpmodule.py:533] gpu group tensors cost 0.0006487369537353516 s
DEBUG 01-06 17:11:22.387566.387566 mlpmodule.py:566] gpu pad cost 0.0017087459564208984 s
DEBUG 01-06 17:11:22.387655.387655 mlpmodule.py:584] gpu group einsum cost 0.00039649009704589844 s
DEBUG 01-06 17:11:22.391184.391184 mlpmodule.py:613] gpu experts func einsum cost 0.0062334537506103516 s
DEBUG 01-06 17:11:22.391302.391302 cuda_h.py:19] end gpu_experts cost 0.006433963775634766 seconds
DEBUG 01-06 17:11:22.391635.391635 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-06 17:11:22.391629.391629 lmp.py:661] 
DEBUG 01-06 17:11:22.391629.391629 lmp.py:661]   Computing 20 experts on CPU...
DEBUG 01-06 17:11:22.391227.391227 cuda_h.py:19] end cpu_experts_submit cost 5.364418029785156e-05 seconds
DEBUG 01-06 17:11:22.391446.391446 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-06 17:11:22.399509.399509 mlpmodule.py:706] group tensors cost 0.008108377456665039 s
DEBUG 01-06 17:11:22.401157.401157 mlpmodule.py:744] pad cost 0.0011577606201171875 s
DEBUG 01-06 17:11:22.401081.401081 mlpmodule.py:750] create cpu tensor cost 4.601478576660156e-05 s
DEBUG 01-06 17:11:22.401037.401037 mlpmodule.py:755] move to cpu cost 3.266334533691406e-05 s
DEBUG 01-06 17:11:22.404551.404551 mlpmodule.py:769] group_w3: shape=torch.Size([20, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=57671680
DEBUG 01-06 17:11:22.404186.404186 mlpmodule.py:770] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-06 17:11:22.404559.404559 mlpmodule.py:775] group_w3 first element: -0.046875
WARNING 01-06 17:11:22.404549.404549 mlpmodule.py:785] start einsum2
DEBUG 01-06 17:11:22.411945.411945 mlpmodule.py:795] group einsum cost 0.009472846984863281 s
DEBUG 01-06 17:11:22.411838.411838 mlpmodule.py:803] cpy2cputensor cost 9.894371032714844e-05 s
DEBUG 01-06 17:11:22.414708.414708 cuda_h.py:19] end wait_cetm_experts cost 0.02275538444519043 seconds
DEBUG 01-06 17:11:22.414569.414569 cuda_h.py:19] end layer_moe_dgenerate_25 cost 0.033391714096069336 seconds
DEBUG 01-06 17:11:22.414822.414822 lmp.py:325] -------------------------------- end decode layer 25 --------------------------------
DEBUG 01-06 17:11:22.414234.414234 lmp.py:298] -------------------------------- start decode layer 26 --------------------------------
DEBUG 01-06 17:11:22.414242.414242 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-06 17:11:22.415340.415340 mlpmodule.py:367] cuda:1 cuda:1
DEBUG 01-06 17:11:22.415330.415330 cuda_h.py:10] start self_attn
cos shape torch.Size([65, 128]) sin shape torch.Size([65, 128]) position_ids tensor([[0]], device='cuda:1')
cos shape torch.Size([1, 1, 1, 128]) sin shape torch.Size([1, 1, 1, 128])
q_embed shape torch.Size([32, 16, 1, 128]) k_embed shape torch.Size([32, 16, 1, 128])
DEBUG 01-06 17:11:22.418212.418212 cuda_h.py:19] end self_attn cost 0.0025284290313720703 seconds
DEBUG 01-06 17:11:22.418711.418711 cuda_h.py:19] end iln_self_attn_paln cost 0.0036644935607910156 seconds
DEBUG 01-06 17:11:22.418621.418621 cuda_h.py:10] start layer_moe_dgenerate_26
DEBUG 01-06 17:11:22.418471.418471 cuda_h.py:10] start gate
DEBUG 01-06 17:11:22.418383.418383 mlpmodule.py:664]  experts func einsum cost 0.027329206466674805 s
DEBUG 01-06 17:11:22.419025.419025 cuda_h.py:19] end gate cost 0.0008652210235595703 seconds
DEBUG 01-06 17:11:22.419658.419658 cuda_h.py:10] start experts_map_get
INFO 01-06 17:11:22.420972.420972 lmp.py:609] using loaded check layer: True
INFO 01-06 17:11:22.421936.421936 lmp.py:620] 
INFO 01-06 17:11:22.421936.421936 lmp.py:620] Layer 26 Expert Device Distribution:
INFO 01-06 17:11:22.421487.421487 lmp.py:621]   Active experts: 50 (out of 64 total)
INFO 01-06 17:11:22.421442.421442 lmp.py:622] 
INFO 01-06 17:11:22.421442.421442 lmp.py:622]   Detailed Expert Distribution:
INFO 01-06 17:11:22.421636.421636 lmp.py:623]   Expert ID  | Tokens     | Actual Device  
INFO 01-06 17:11:22.421299.421299 lmp.py:624]   ----------------------------------------------------------------------
INFO 01-06 17:11:22.421631.421631 lmp.py:627]   11         | 1          |  meta           
INFO 01-06 17:11:22.421248.421248 lmp.py:627]   17         | 1          |  meta           
INFO 01-06 17:11:22.421865.421865 lmp.py:627]   21         | 1          |  cuda:1         
INFO 01-06 17:11:22.421336.421336 lmp.py:627]   24         | 1          |  meta           
INFO 01-06 17:11:22.421569.421569 lmp.py:627]   25         | 1          |  cuda:1         
INFO 01-06 17:11:22.421279.421279 lmp.py:627]   30         | 1          |  meta           
INFO 01-06 17:11:22.421704.421704 lmp.py:627]   38         | 1          |  meta           
INFO 01-06 17:11:22.421937.421937 lmp.py:627]   39         | 1          |  meta           
INFO 01-06 17:11:22.421408.421408 lmp.py:627]   46         | 1          |  cuda:1         
INFO 01-06 17:11:22.421402.421402 lmp.py:627]   50         | 1          |  meta           
INFO 01-06 17:11:22.421066.421066 lmp.py:627]   59         | 1          |  meta           
INFO 01-06 17:11:22.421729.421729 lmp.py:627]   60         | 1          |  cuda:1         
INFO 01-06 17:11:22.421353.421353 lmp.py:627]   3          | 2          |  cuda:1         
INFO 01-06 17:11:22.421618.421618 lmp.py:627]   8          | 2          |  cuda:1         
INFO 01-06 17:11:22.421884.421884 lmp.py:627]   9          | 2          |  meta           
INFO 01-06 17:11:22.421819.421819 lmp.py:627]   15         | 2          |  meta           
INFO 01-06 17:11:22.421276.421276 lmp.py:627]   16         | 2          |  cuda:1         
INFO 01-06 17:11:22.421780.421780 lmp.py:627]   33         | 2          |  cuda:1         
INFO 01-06 17:11:22.421807.421807 lmp.py:627]   37         | 2          |  meta           
INFO 01-06 17:11:22.421073.421073 lmp.py:627]   44         | 2          |  cuda:1         
INFO 01-06 17:11:22.421577.421577 lmp.py:627]   63         | 2          |  meta           
INFO 01-06 17:11:22.421081.421081 lmp.py:627]   0          | 3          |  cuda:1         
INFO 01-06 17:11:22.421539.421539 lmp.py:627]   2          | 3          |  cuda:1         
INFO 01-06 17:11:22.421473.421473 lmp.py:627]   4          | 3          |  cuda:1         
INFO 01-06 17:11:22.421739.421739 lmp.py:627]   13         | 3          |  cuda:1         
INFO 01-06 17:11:22.422243.422243 lmp.py:627]   18         | 3          |  cuda:1         
INFO 01-06 17:11:22.422747.422747 lmp.py:627]   22         | 3          |  meta           
INFO 01-06 17:11:22.422012.422012 lmp.py:627]   23         | 3          |  meta           
INFO 01-06 17:11:22.422278.422278 lmp.py:627]   28         | 3          |  cuda:1         
INFO 01-06 17:11:22.422497.422497 lmp.py:627]   29         | 3          |  meta           
INFO 01-06 17:11:22.422716.422716 lmp.py:627]   40         | 3          |  cuda:1         
INFO 01-06 17:11:22.422220.422220 lmp.py:627]   49         | 3          |  meta           
INFO 01-06 17:11:22.422724.422724 lmp.py:627]   53         | 3          |  cuda:1         
INFO 01-06 17:11:22.422990.422990 lmp.py:627]   54         | 3          |  cuda:1         
INFO 01-06 17:11:22.422494.422494 lmp.py:627]   58         | 3          |  cuda:1         
INFO 01-06 17:11:22.422283.422283 lmp.py:627]   35         | 4          |  cuda:1         
INFO 01-06 17:11:22.422264.422264 lmp.py:627]   56         | 4          |  cuda:1         
INFO 01-06 17:11:22.422721.422721 lmp.py:627]   5          | 5          |  cuda:1         
INFO 01-06 17:11:22.422748.422748 lmp.py:627]   43         | 5          |  cuda:1         
INFO 01-06 17:11:22.422014.422014 lmp.py:627]   52         | 6          |  cuda:1         
INFO 01-06 17:11:22.422280.422280 lmp.py:627]   62         | 6          |  meta           
INFO 01-06 17:11:22.422545.422545 lmp.py:627]   31         | 7          |  cuda:1         
INFO 01-06 17:11:22.422288.422288 lmp.py:627]   32         | 7          |  cuda:1         
INFO 01-06 17:11:22.422745.422745 lmp.py:627]   26         | 8          |  cuda:1         
INFO 01-06 17:11:22.422249.422249 lmp.py:627]   12         | 9          |  cuda:1         
INFO 01-06 17:11:22.422515.422515 lmp.py:627]   45         | 10         |  cuda:1         
INFO 01-06 17:11:22.422542.422542 lmp.py:627]   57         | 10         |  cuda:1         
INFO 01-06 17:11:22.422331.422331 lmp.py:627]   27         | 11         |  cuda:1         
INFO 01-06 17:11:22.422596.422596 lmp.py:627]   47         | 11         |  cuda:1         
INFO 01-06 17:11:22.422577.422577 lmp.py:627]   42         | 17         |  meta           
INFO 01-06 17:11:22.422320.422320 lmp.py:628] ============================================================
INFO 01-06 17:11:22.422320.422320 lmp.py:628] 
INFO 01-06 17:11:22.422546.422546 lmp.py:630] experts_gpu_list: [21, 25, 46, 60, 3, 8, 16, 33, 44, 0, 2, 4, 13, 18, 28, 40, 53, 54, 58, 35, 56, 5, 43, 52, 31, 32, 26, 12, 45, 57, 27, 47] num: 32
INFO 01-06 17:11:22.422957.422957 lmp.py:631] experts_cpu_list: [11, 17, 24, 30, 38, 39, 50, 59, 9, 15, 37, 63, 22, 23, 29, 49, 62, 42] num: 18
INFO 01-06 17:11:22.422766.422766 lmp.py:632] expert_actual_device_map {0: 'cuda:1', 1: 'cuda:1', 2: 'cuda:1', 3: 'cuda:1', 4: 'cuda:1', 5: 'cuda:1', 6: 'cuda:1', 7: 'cuda:1', 8: 'cuda:1', 9: 'meta', 10: 'cuda:1', 11: 'meta', 12: 'cuda:1', 13: 'cuda:1', 14: 'cuda:1', 15: 'meta', 16: 'cuda:1', 17: 'meta', 18: 'cuda:1', 19: 'meta', 20: 'meta', 21: 'cuda:1', 22: 'meta', 23: 'meta', 24: 'meta', 25: 'cuda:1', 26: 'cuda:1', 27: 'cuda:1', 28: 'cuda:1', 29: 'meta', 30: 'meta', 31: 'cuda:1', 32: 'cuda:1', 33: 'cuda:1', 34: 'meta', 35: 'cuda:1', 36: 'meta', 37: 'meta', 38: 'meta', 39: 'meta', 40: 'cuda:1', 41: 'meta', 42: 'meta', 43: 'cuda:1', 44: 'cuda:1', 45: 'cuda:1', 46: 'cuda:1', 47: 'cuda:1', 48: 'meta', 49: 'meta', 50: 'meta', 51: 'meta', 52: 'cuda:1', 53: 'cuda:1', 54: 'cuda:1', 55: 'meta', 56: 'cuda:1', 57: 'cuda:1', 58: 'cuda:1', 59: 'meta', 60: 'cuda:1', 61: 'meta', 62: 'meta', 63: 'meta'}
DEBUG 01-06 17:11:22.422337.422337 cuda_h.py:19] end experts_map_get cost 0.002805948257446289 seconds
DEBUG 01-06 17:11:22.422114.422114 cuda_h.py:10] start gpu_sexperts
DEBUG 01-06 17:11:22.423399.423399 cuda_h.py:19] end gpu_sexperts cost 0.00034427642822265625 seconds
DEBUG 01-06 17:11:22.423381.423381 cuda_h.py:10] start gpu_experts
DEBUG 01-06 17:11:22.423186.423186 mlpmodule.py:533] gpu group tensors cost 0.0006263256072998047 s
DEBUG 01-06 17:11:22.425412.425412 mlpmodule.py:566] gpu pad cost 0.0017657279968261719 s
DEBUG 01-06 17:11:22.426793.426793 mlpmodule.py:584] gpu group einsum cost 0.00039696693420410156 s
DEBUG 01-06 17:11:22.429881.429881 mlpmodule.py:613] gpu experts func einsum cost 0.006368160247802734 s
DEBUG 01-06 17:11:22.429191.429191 cuda_h.py:19] end gpu_experts cost 0.006571531295776367 seconds
DEBUG 01-06 17:11:22.429139.429139 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-06 17:11:22.429200.429200 lmp.py:661] 
DEBUG 01-06 17:11:22.429200.429200 lmp.py:661]   Computing 18 experts on CPU...
DEBUG 01-06 17:11:22.429004.429004 cuda_h.py:19] end cpu_experts_submit cost 6.556510925292969e-05 seconds
DEBUG 01-06 17:11:22.429700.429700 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-06 17:11:22.433438.433438 mlpmodule.py:706] group tensors cost 0.003673076629638672 s
DEBUG 01-06 17:11:22.435229.435229 mlpmodule.py:744] pad cost 0.0009105205535888672 s
DEBUG 01-06 17:11:22.435755.435755 mlpmodule.py:750] create cpu tensor cost 4.100799560546875e-05 s
DEBUG 01-06 17:11:22.435605.435605 mlpmodule.py:755] move to cpu cost 2.956390380859375e-05 s
DEBUG 01-06 17:11:22.438162.438162 mlpmodule.py:769] group_w3: shape=torch.Size([18, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=51904512
DEBUG 01-06 17:11:22.438350.438350 mlpmodule.py:770] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-06 17:11:22.438709.438709 mlpmodule.py:775] group_w3 first element: 0.04833984375
WARNING 01-06 17:11:22.438818.438818 mlpmodule.py:785] start einsum2
DEBUG 01-06 17:11:22.442859.442859 mlpmodule.py:795] group einsum cost 0.0071332454681396484 s
DEBUG 01-06 17:11:22.442944.442944 mlpmodule.py:803] cpy2cputensor cost 9.226799011230469e-05 s
DEBUG 01-06 17:11:22.445638.445638 cuda_h.py:19] end wait_cetm_experts cost 0.015289306640625 seconds
DEBUG 01-06 17:11:22.445499.445499 cuda_h.py:19] end layer_moe_dgenerate_26 cost 0.026960372924804688 seconds
DEBUG 01-06 17:11:22.445631.445631 lmp.py:325] -------------------------------- end decode layer 26 --------------------------------
DEBUG 01-06 17:11:22.445639.445639 lmp.py:298] -------------------------------- start decode layer 27 --------------------------------
DEBUG 01-06 17:11:22.445103.445103 cuda_h.py:10] start iln_self_attn_paln
DEBUG 01-06 17:11:22.446597.446597 mlpmodule.py:367] cuda:1 cuda:1
DEBUG 01-06 17:11:22.446530.446530 cuda_h.py:10] start self_attn
cos shape torch.Size([65, 128]) sin shape torch.Size([65, 128]) position_ids tensor([[0]], device='cuda:1')
cos shape torch.Size([1, 1, 1, 128]) sin shape torch.Size([1, 1, 1, 128])
q_embed shape torch.Size([32, 16, 1, 128]) k_embed shape torch.Size([32, 16, 1, 128])
DEBUG 01-06 17:11:22.448216.448216 cuda_h.py:19] end self_attn cost 0.00201416015625 seconds
DEBUG 01-06 17:11:22.448916.448916 cuda_h.py:19] end iln_self_attn_paln cost 0.002881288528442383 seconds
DEBUG 01-06 17:11:22.448322.448322 cuda_h.py:10] start layer_moe_dgenerate_27
DEBUG 01-06 17:11:22.448522.448522 cuda_h.py:10] start gate
DEBUG 01-06 17:11:22.449313.449313 mlpmodule.py:664]  experts func einsum cost 0.019156694412231445 s
DEBUG 01-06 17:11:22.449923.449923 cuda_h.py:19] end gate cost 0.0006647109985351562 seconds
DEBUG 01-06 17:11:22.449675.449675 cuda_h.py:10] start experts_map_get
INFO 01-06 17:11:22.450878.450878 lmp.py:609] using loaded check layer: True
INFO 01-06 17:11:22.450619.450619 lmp.py:620] 
INFO 01-06 17:11:22.450619.450619 lmp.py:620] Layer 27 Expert Device Distribution:
INFO 01-06 17:11:22.450382.450382 lmp.py:621]   Active experts: 44 (out of 64 total)
INFO 01-06 17:11:22.450701.450701 lmp.py:622] 
INFO 01-06 17:11:22.450701.450701 lmp.py:622]   Detailed Expert Distribution:
INFO 01-06 17:11:22.450450.450450 lmp.py:623]   Expert ID  | Tokens     | Actual Device  
INFO 01-06 17:11:22.450384.450384 lmp.py:624]   ----------------------------------------------------------------------
INFO 01-06 17:11:22.450796.450796 lmp.py:627]   9          | 1          |  cuda:1         
INFO 01-06 17:11:22.450777.450777 lmp.py:627]   11         | 1          |  cuda:1         
INFO 01-06 17:11:22.450281.450281 lmp.py:627]   18         | 1          |  meta           
INFO 01-06 17:11:22.450785.450785 lmp.py:627]   26         | 1          |  meta           
INFO 01-06 17:11:22.450289.450289 lmp.py:627]   29         | 1          |  cuda:1         
INFO 01-06 17:11:22.450554.450554 lmp.py:627]   33         | 1          |  meta           
INFO 01-06 17:11:22.450058.450058 lmp.py:627]   36         | 1          |  meta           
INFO 01-06 17:11:22.450324.450324 lmp.py:627]   48         | 1          |  meta           
INFO 01-06 17:11:22.450258.450258 lmp.py:627]   53         | 1          |  cuda:1         
INFO 01-06 17:11:22.450524.450524 lmp.py:627]   54         | 1          |  meta           
INFO 01-06 17:11:22.451551.451551 lmp.py:627]   57         | 1          |  meta           
INFO 01-06 17:11:22.451340.451340 lmp.py:627]   10         | 2          |  cuda:1         
INFO 01-06 17:11:22.451605.451605 lmp.py:627]   12         | 2          |  meta           
INFO 01-06 17:11:22.451632.451632 lmp.py:627]   30         | 2          |  cuda:1         
INFO 01-06 17:11:22.451660.451660 lmp.py:627]   35         | 2          |  cuda:1         
INFO 01-06 17:11:22.451925.451925 lmp.py:627]   38         | 2          |  meta           
INFO 01-06 17:11:22.451429.451429 lmp.py:627]   41         | 2          |  cuda:1         
INFO 01-06 17:11:22.451456.451456 lmp.py:627]   43         | 2          |  meta           
INFO 01-06 17:11:22.451437.451437 lmp.py:627]   44         | 2          |  meta           
INFO 01-06 17:11:22.451656.451656 lmp.py:627]   47         | 2          |  meta           
INFO 01-06 17:11:22.451684.451684 lmp.py:627]   51         | 2          |  meta           
INFO 01-06 17:11:22.451711.451711 lmp.py:627]   60         | 2          |  cuda:1         
INFO 01-06 17:11:22.451500.451500 lmp.py:627]   1          | 3          |  cuda:1         
INFO 01-06 17:11:22.451004.451004 lmp.py:627]   7          | 3          |  cuda:1         
INFO 01-06 17:11:22.451508.451508 lmp.py:627]   25         | 3          |  cuda:1         
INFO 01-06 17:11:22.451773.451773 lmp.py:627]   55         | 3          |  meta           
INFO 01-06 17:11:22.451039.451039 lmp.py:627]   52         | 4          |  cuda:1         
INFO 01-06 17:11:22.451258.451258 lmp.py:627]   15         | 5          |  cuda:1         
INFO 01-06 17:11:22.451477.451477 lmp.py:627]   19         | 5          |  cuda:1         
INFO 01-06 17:11:22.451981.451981 lmp.py:627]   20         | 5          |  meta           
INFO 01-06 17:11:22.451008.451008 lmp.py:627]   39         | 5          |  cuda:1         
INFO 01-06 17:11:22.451274.451274 lmp.py:627]   45         | 5          |  meta           
INFO 01-06 17:11:22.451063.451063 lmp.py:627]   46         | 5          |  cuda:1         
INFO 01-06 17:11:22.451805.451805 lmp.py:627]   16         | 6          |  cuda:1         
INFO 01-06 17:11:22.451832.451832 lmp.py:627]   5          | 7          |  cuda:1         
INFO 01-06 17:11:22.451051.451051 lmp.py:627]   24         | 8          |  meta           
INFO 01-06 17:11:22.451032.451032 lmp.py:627]   58         | 8          |  cuda:1         
INFO 01-06 17:11:22.451013.451013 lmp.py:627]   4          | 9          |  cuda:1         
INFO 01-06 17:11:22.451517.451517 lmp.py:627]   13         | 9          |  meta           
INFO 01-06 17:11:22.451544.451544 lmp.py:627]   22         | 11         |  cuda:1         
INFO 01-06 17:11:22.451333.451333 lmp.py:627]   56         | 11         |  meta           
INFO 01-06 17:11:22.451883.451883 lmp.py:627]   21         | 13         |  cuda:1         
INFO 01-06 17:11:22.451672.451672 lmp.py:627]   59         | 13         |  meta           
INFO 01-06 17:11:22.451461.451461 lmp.py:627]   62         | 18         |  cuda:1         
INFO 01-06 17:11:22.451250.451250 lmp.py:628] ============================================================
INFO 01-06 17:11:22.451250.451250 lmp.py:628] 
INFO 01-06 17:11:22.451714.451714 lmp.py:630] experts_gpu_list: [9, 11, 29, 53, 10, 30, 35, 41, 60, 1, 7, 25, 52, 15, 19, 39, 46, 16, 5, 58, 4, 22, 21, 62] num: 24
INFO 01-06 17:11:22.451602.451602 lmp.py:631] experts_cpu_list: [18, 26, 33, 36, 48, 54, 57, 12, 38, 43, 44, 47, 51, 55, 20, 45, 24, 13, 56, 59] num: 20
INFO 01-06 17:11:22.451696.451696 lmp.py:632] expert_actual_device_map {0: 'cuda:1', 1: 'cuda:1', 2: 'cuda:1', 3: 'cuda:1', 4: 'cuda:1', 5: 'cuda:1', 6: 'cuda:1', 7: 'cuda:1', 8: 'cuda:1', 9: 'cuda:1', 10: 'cuda:1', 11: 'cuda:1', 12: 'meta', 13: 'meta', 14: 'cuda:1', 15: 'cuda:1', 16: 'cuda:1', 17: 'meta', 18: 'meta', 19: 'cuda:1', 20: 'meta', 21: 'cuda:1', 22: 'cuda:1', 23: 'meta', 24: 'meta', 25: 'cuda:1', 26: 'meta', 27: 'cuda:1', 28: 'cuda:1', 29: 'cuda:1', 30: 'cuda:1', 31: 'meta', 32: 'cuda:1', 33: 'meta', 34: 'cuda:1', 35: 'cuda:1', 36: 'meta', 37: 'cuda:1', 38: 'meta', 39: 'cuda:1', 40: 'meta', 41: 'cuda:1', 42: 'meta', 43: 'meta', 44: 'meta', 45: 'meta', 46: 'cuda:1', 47: 'meta', 48: 'meta', 49: 'meta', 50: 'cuda:1', 51: 'meta', 52: 'cuda:1', 53: 'cuda:1', 54: 'meta', 55: 'meta', 56: 'meta', 57: 'meta', 58: 'cuda:1', 59: 'meta', 60: 'cuda:1', 61: 'meta', 62: 'cuda:1', 63: 'cuda:1'}
DEBUG 01-06 17:11:22.451598.451598 cuda_h.py:19] end experts_map_get cost 0.0020139217376708984 seconds
DEBUG 01-06 17:11:22.451991.451991 cuda_h.py:10] start gpu_sexperts
DEBUG 01-06 17:11:22.452964.452964 cuda_h.py:19] end gpu_sexperts cost 0.0003254413604736328 seconds
DEBUG 01-06 17:11:22.452085.452085 cuda_h.py:10] start gpu_experts
DEBUG 01-06 17:11:22.452171.452171 mlpmodule.py:533] gpu group tensors cost 0.000518798828125 s
DEBUG 01-06 17:11:22.454276.454276 mlpmodule.py:566] gpu pad cost 0.001325368881225586 s
DEBUG 01-06 17:11:22.454376.454376 mlpmodule.py:584] gpu group einsum cost 0.0005123615264892578 s
DEBUG 01-06 17:11:22.457927.457927 mlpmodule.py:613] gpu experts func einsum cost 0.005286455154418945 s
DEBUG 01-06 17:11:22.457408.457408 cuda_h.py:19] end gpu_experts cost 0.005473136901855469 seconds
DEBUG 01-06 17:11:22.457502.457502 cuda_h.py:10] start cpu_experts_submit
DEBUG 01-06 17:11:22.457443.457443 lmp.py:661] 
DEBUG 01-06 17:11:22.457443.457443 lmp.py:661]   Computing 20 experts on CPU...
DEBUG 01-06 17:11:22.457564.457564 cuda_h.py:19] end cpu_experts_submit cost 5.364418029785156e-05 seconds
DEBUG 01-06 17:11:22.457307.457307 cuda_h.py:10] start wait_cetm_experts
DEBUG 01-06 17:11:22.461485.461485 mlpmodule.py:706] group tensors cost 0.0037620067596435547 s
DEBUG 01-06 17:11:22.463791.463791 mlpmodule.py:744] pad cost 0.0010406970977783203 s
DEBUG 01-06 17:11:22.463928.463928 mlpmodule.py:750] create cpu tensor cost 5.221366882324219e-05 s
DEBUG 01-06 17:11:22.463208.463208 mlpmodule.py:755] move to cpu cost 2.8848648071289062e-05 s
DEBUG 01-06 17:11:22.465980.465980 mlpmodule.py:769] group_w3: shape=torch.Size([20, 1408, 2048]), device=cpu, dtype=torch.bfloat16, numel=57671680
DEBUG 01-06 17:11:22.466406.466406 mlpmodule.py:770] group_w3 strides: (2883584, 2048, 1), is_contiguous: True
DEBUG 01-06 17:11:22.466958.466958 mlpmodule.py:775] group_w3 first element: 0.020751953125
WARNING 01-06 17:11:22.466874.466874 mlpmodule.py:785] start einsum2
DEBUG 01-06 17:11:22.469915.469915 mlpmodule.py:795] group einsum cost 0.006238698959350586 s
DEBUG 01-06 17:11:22.470544.470544 mlpmodule.py:803] cpy2cputensor cost 0.0001068115234375 s
DEBUG 01-06 17:11:22.473659.473659 cuda_h.py:19] end wait_cetm_experts cost 0.014997720718383789 seconds
DEBUG 01-06 17:11:22.473897.473897 cuda_h.py:19] end layer_moe_dgenerate_27 cost 0.024470090866088867 seconds
DEBUG 01-06 17:11:22.473691.473691 lmp.py:325] -------------------------------- end decode layer 27 --------------------------------
DEBUG 01-06 17:11:22.473461.473461 cuda_h.py:10] start async_wait_layer_loaded_to_gpu
DEBUG 01-06 17:11:22.473586.473586 cuda_h.py:19] end async_wait_layer_loaded_to_gpu cost 0.00016570091247558594 seconds
DEBUG 01-06 17:11:22.473955.473955 cuda_h.py:19] end decode_layer cost 1.0420973300933838 seconds
DEBUG 01-06 17:11:22.508264.508264 mlpmodule.py:664]  experts func einsum cost 0.050374507904052734 s
Collecting data...
Generating '/tmp/nsys-report-3259.qdstrm'
[1/1] [0%                          ] report1.nsys-rep[1/1] [0%                          ] report1.nsys-rep[1/1] [0%                          ] report1.nsys-rep[1/1] [6%                          ] report1.nsys-rep[1/1] [9%                          ] report1.nsys-rep[1/1] [12%                         ] report1.nsys-rep[1/1] [14%                         ] report1.nsys-rep[1/1] [=17%                        ] report1.nsys-rep[1/1] [==20%                       ] report1.nsys-rep[1/1] [===23%                      ] report1.nsys-rep[1/1] [====26%                     ] report1.nsys-rep[1/1] [=====30%                    ] report1.nsys-rep[1/1] [======33%                   ] report1.nsys-rep[1/1] [======35%                   ] report1.nsys-rep[1/1] [=======38%                  ] report1.nsys-rep[1/1] [========42%                 ] report1.nsys-rep[1/1] [=========45%                ] report1.nsys-rep[1/1] [==========48%               ] report1.nsys-rep[1/1] [===========50%              ] report1.nsys-rep[1/1] [========================100%] report1.nsys-rep[1/1] [========================100%] report1.nsys-rep
Generated:
	/mnt/zhengcf3/lmp/examples/report1.nsys-rep
