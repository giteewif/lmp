here pin
INFO 01-14 17:01:43.154608.154608 pinpool.py:28] Initializing PinnedMemoryPool with 2GB total, allocating in 1024MB chunks...
DEBUG 01-14 17:01:43.969974.969974 pinpool.py:40] Allocated chunk 1: 536870912 elements (1024.0 MB)
DEBUG 01-14 17:01:44.398583.398583 pinpool.py:40] Allocated chunk 2: 536870912 elements (1024.0 MB)
INFO 01-14 17:01:44.398927.398927 pinpool.py:52] Successfully allocated 2 chunks, total 1073741824 elements (2048.0 MB) in 1.245s
DEBUG 01-14 17:01:45.333788.333788 cuda_memory_view.py:613] 
DEBUG 01-14 17:01:45.333788.333788 cuda_memory_view.py:613] restore_tensors_from_shared_memory_names time: 0.014259576797485352
DEBUG 01-14 17:01:47.980989.980989 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-14 17:01:47.980377.980377 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-14 17:01:48.093473.093473 cuda_h.py:19] end allocate_cuda_memory cost 0.11289644241333008 seconds
DEBUG 01-14 17:01:48.093401.093401 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-14 17:01:48.093913.093913 sllm_store_c.py:27] get device uuid map
DEBUG 01-14 17:01:48.094241.094241 sllm_store_c.py:29] call client load into gpu
DEBUG 01-14 17:01:48.094004.094004 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 780d358f-2c0e-4a6a-8e09-bbd7cb97e08a
DEBUG 01-14 17:01:48.094021.094021 client.py:106] call stub.LoadModelAsync
INFO 01-14 17:01:48.095291.095291 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 780d358f-2c0e-4a6a-8e09-bbd7cb97e08a
DEBUG 01-14 17:01:48.096168.096168 cuda_h.py:19] end load_into_gpu_async cost 0.0020966529846191406 seconds
DEBUG 01-14 17:01:48.096778.096778 cuda_h.py:10] start restore_tensors2
DEBUG 01-14 17:01:48.096508.096508 cuda_h.py:19] end restore_tensors2 cost 0.0001938343048095703 seconds
DEBUG 01-14 17:01:48.096893.096893 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.11595916748046875 seconds
DEBUG 01-14 17:01:48.096550.096550 cuda_h.py:10] start restore2model
DEBUG 01-14 17:01:48.133050.133050 cuda_h.py:19] end restore2model cost 0.03666329383850098 seconds
INFO 01-14 17:01:48.133047.133047 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 780d358f-2c0e-4a6a-8e09-bbd7cb97e08a
INFO 01-14 17:01:48.175655.175655 client.py:127] Model loaded
DEBUG 01-14 17:01:48.175396.175396 cuda_h.py:10] start load_qkvogns_weight_l_0
DEBUG 01-14 17:01:48.175785.175785 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-14 17:01:48.175206.175206 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-14 17:01:48.176003.176003 cuda_h.py:19] end allocate_cuda_memory cost 0.00034546852111816406 seconds
DEBUG 01-14 17:01:48.176134.176134 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-14 17:01:48.176953.176953 sllm_store_c.py:27] get device uuid map
DEBUG 01-14 17:01:48.176817.176817 sllm_store_c.py:29] call client load into gpu
DEBUG 01-14 17:01:48.176641.176641 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 9584f1a0-17af-49db-8e4d-de86e5fbd2cc
DEBUG 01-14 17:01:48.176714.176714 client.py:106] call stub.LoadModelAsync
INFO 01-14 17:01:48.178141.178141 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 9584f1a0-17af-49db-8e4d-de86e5fbd2cc
DEBUG 01-14 17:01:48.178840.178840 cuda_h.py:19] end load_into_gpu_async cost 0.0020029544830322266 seconds
DEBUG 01-14 17:01:48.178671.178671 cuda_h.py:10] start restore_tensors2
DEBUG 01-14 17:01:48.178314.178314 cuda_h.py:19] end restore_tensors2 cost 0.00014519691467285156 seconds
DEBUG 01-14 17:01:48.178781.178781 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0031633377075195312 seconds
INFO 01-14 17:01:48.178314.178314 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 9584f1a0-17af-49db-8e4d-de86e5fbd2cc
INFO 01-14 17:01:48.195008.195008 client.py:127] Model loaded
DEBUG 01-14 17:01:48.195967.195967 cuda_h.py:10] start restore2model
DEBUG 01-14 17:01:48.196256.196256 cuda_h.py:19] end restore2model cost 0.0010166168212890625 seconds
DEBUG 01-14 17:01:48.196520.196520 cuda_h.py:19] end load_qkvogns_weight_l_0 cost 0.02140641212463379 seconds
DEBUG 01-14 17:01:49.313566.313566 mlpmodule.py:233] restore_hm_state_dict2model loaded 5265 expert tensors (including shared_experts) for Deepseek model
DEBUG 01-14 17:01:49.315919.315919 cuda_h.py:10] start start_load_qkvogn_s_weight_l_1
DEBUG 01-14 17:01:49.315474.315474 cuda_h.py:19] end start_load_qkvogn_s_weight_l_1 cost 7.128715515136719e-05 seconds
DEBUG 01-14 17:01:49.315929.315929 cuda_h.py:10] start sllm_worker_task
DEBUG 01-14 17:01:49.316973.316973 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu
DEBUG 01-14 17:01:49.316042.316042 cuda_h.py:10] start allocate_cuda_memory
DEBUG 01-14 17:01:49.316605.316605 cuda_h.py:19] end allocate_cuda_memory cost 0.0003154277801513672 seconds
DEBUG 01-14 17:01:49.316986.316986 cuda_h.py:10] start load_into_gpu_async
DEBUG 01-14 17:01:49.316060.316060 sllm_store_c.py:27] get device uuid map
DEBUG 01-14 17:01:49.316202.316202 sllm_store_c.py:29] call client load into gpu
DEBUG 01-14 17:01:49.316786.316786 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, a3ad64c8-75f0-4f9f-9151-7d55da64c5d3
DEBUG 01-14 17:01:49.316056.316056 client.py:106] call stub.LoadModelAsync
INFO 01-14 17:01:49.318203.318203 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, a3ad64c8-75f0-4f9f-9151-7d55da64c5d3
DEBUG 01-14 17:01:49.318829.318829 cuda_h.py:19] end load_into_gpu_async cost 0.0017881393432617188 seconds
DEBUG 01-14 17:01:49.318434.318434 cuda_h.py:10] start restore_tensors2
DEBUG 01-14 17:01:49.318877.318877 cuda_h.py:19] end restore_tensors2 cost 0.00012421607971191406 seconds
DEBUG 01-14 17:01:49.318310.318310 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu cost 0.0026788711547851562 seconds
INFO 01-14 17:01:49.318782.318782 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, a3ad64c8-75f0-4f9f-9151-7d55da64c5d3
INFO 01-14 17:01:49.326199.326199 client.py:127] Model loaded
DEBUG 01-14 17:01:49.326181.326181 cuda_h.py:10] start restore2model
DEBUG 01-14 17:01:49.326288.326288 cuda_h.py:19] end restore2model cost 0.00039386749267578125 seconds
DEBUG 01-14 17:01:49.326972.326972 cuda_h.py:19] end sllm_worker_task cost 0.010869503021240234 seconds
DEBUG 01-14 17:01:49.327316.327316 cuda_h.py:10] start gate
DEBUG 01-14 17:01:49.626605.626605 cuda_h.py:19] end gate cost 0.2991824150085449 seconds
DEBUG 01-14 17:01:49.626337.626337 cuda_h.py:10] start experts_map_get
DEBUG 01-14 17:01:49.626609.626609 cuda_h.py:19] end experts_map_get cost 0.0003764629364013672 seconds
DEBUG 01-14 17:01:49.762378.762378 cuda_h.py:10] start task_processing_mp_load
DEBUG 01-14 17:01:49.762027.762027 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu_multi_device
DEBUG 01-14 17:01:49.765412.765412 cuda_memory_view.py:520] tensor_device_offsets_device_map {1: {'model.layers.1.mlp.experts.0.gate_proj.weight': 0, 'model.layers.1.mlp.experts.0.down_proj.weight': 5767168, 'model.layers.1.mlp.experts.0.up_proj.weight': 11534336, 'model.layers.1.mlp.experts.1.gate_proj.weight': 17301504, 'model.layers.1.mlp.experts.1.down_proj.weight': 23068672, 'model.layers.1.mlp.experts.1.up_proj.weight': 28835840, 'model.layers.1.mlp.experts.2.gate_proj.weight': 34603008, 'model.layers.1.mlp.experts.2.down_proj.weight': 40370176, 'model.layers.1.mlp.experts.2.up_proj.weight': 46137344, 'model.layers.1.mlp.experts.4.gate_proj.weight': 51904512, 'model.layers.1.mlp.experts.4.down_proj.weight': 57671680, 'model.layers.1.mlp.experts.4.up_proj.weight': 63438848, 'model.layers.1.mlp.experts.5.gate_proj.weight': 69206016, 'model.layers.1.mlp.experts.5.down_proj.weight': 74973184, 'model.layers.1.mlp.experts.5.up_proj.weight': 80740352, 'model.layers.1.mlp.experts.6.gate_proj.weight': 86507520, 'model.layers.1.mlp.experts.6.down_proj.weight': 92274688, 'model.layers.1.mlp.experts.6.up_proj.weight': 98041856, 'model.layers.1.mlp.experts.7.gate_proj.weight': 103809024, 'model.layers.1.mlp.experts.7.down_proj.weight': 109576192, 'model.layers.1.mlp.experts.7.up_proj.weight': 115343360, 'model.layers.1.mlp.experts.10.gate_proj.weight': 121110528, 'model.layers.1.mlp.experts.10.down_proj.weight': 126877696, 'model.layers.1.mlp.experts.10.up_proj.weight': 132644864, 'model.layers.1.mlp.experts.15.gate_proj.weight': 138412032, 'model.layers.1.mlp.experts.15.down_proj.weight': 144179200, 'model.layers.1.mlp.experts.15.up_proj.weight': 149946368, 'model.layers.1.mlp.experts.16.gate_proj.weight': 155713536, 'model.layers.1.mlp.experts.16.down_proj.weight': 161480704, 'model.layers.1.mlp.experts.16.up_proj.weight': 167247872, 'model.layers.1.mlp.experts.19.gate_proj.weight': 173015040, 'model.layers.1.mlp.experts.19.down_proj.weight': 178782208, 'model.layers.1.mlp.experts.19.up_proj.weight': 184549376, 'model.layers.1.mlp.experts.21.gate_proj.weight': 190316544, 'model.layers.1.mlp.experts.21.down_proj.weight': 196083712, 'model.layers.1.mlp.experts.21.up_proj.weight': 201850880, 'model.layers.1.mlp.experts.22.gate_proj.weight': 207618048, 'model.layers.1.mlp.experts.22.down_proj.weight': 213385216, 'model.layers.1.mlp.experts.22.up_proj.weight': 219152384, 'model.layers.1.mlp.experts.23.gate_proj.weight': 224919552, 'model.layers.1.mlp.experts.23.down_proj.weight': 230686720, 'model.layers.1.mlp.experts.23.up_proj.weight': 236453888, 'model.layers.1.mlp.experts.24.gate_proj.weight': 242221056, 'model.layers.1.mlp.experts.24.down_proj.weight': 247988224, 'model.layers.1.mlp.experts.24.up_proj.weight': 253755392, 'model.layers.1.mlp.experts.28.gate_proj.weight': 259522560, 'model.layers.1.mlp.experts.28.down_proj.weight': 265289728, 'model.layers.1.mlp.experts.28.up_proj.weight': 271056896, 'model.layers.1.mlp.experts.29.gate_proj.weight': 276824064, 'model.layers.1.mlp.experts.29.down_proj.weight': 282591232, 'model.layers.1.mlp.experts.29.up_proj.weight': 288358400, 'model.layers.1.mlp.experts.30.gate_proj.weight': 294125568, 'model.layers.1.mlp.experts.30.down_proj.weight': 299892736, 'model.layers.1.mlp.experts.30.up_proj.weight': 305659904, 'model.layers.1.mlp.experts.32.gate_proj.weight': 311427072, 'model.layers.1.mlp.experts.32.down_proj.weight': 317194240, 'model.layers.1.mlp.experts.32.up_proj.weight': 322961408, 'model.layers.1.mlp.experts.33.gate_proj.weight': 328728576, 'model.layers.1.mlp.experts.33.down_proj.weight': 334495744, 'model.layers.1.mlp.experts.33.up_proj.weight': 340262912, 'model.layers.1.mlp.experts.34.gate_proj.weight': 346030080, 'model.layers.1.mlp.experts.34.down_proj.weight': 351797248, 'model.layers.1.mlp.experts.34.up_proj.weight': 357564416, 'model.layers.1.mlp.experts.38.gate_proj.weight': 363331584, 'model.layers.1.mlp.experts.38.down_proj.weight': 369098752, 'model.layers.1.mlp.experts.38.up_proj.weight': 374865920, 'model.layers.1.mlp.experts.43.gate_proj.weight': 380633088, 'model.layers.1.mlp.experts.43.down_proj.weight': 386400256, 'model.layers.1.mlp.experts.43.up_proj.weight': 392167424, 'model.layers.1.mlp.experts.44.gate_proj.weight': 397934592, 'model.layers.1.mlp.experts.44.down_proj.weight': 403701760, 'model.layers.1.mlp.experts.44.up_proj.weight': 409468928, 'model.layers.1.mlp.experts.46.gate_proj.weight': 415236096, 'model.layers.1.mlp.experts.46.down_proj.weight': 421003264, 'model.layers.1.mlp.experts.46.up_proj.weight': 426770432, 'model.layers.1.mlp.experts.48.gate_proj.weight': 432537600, 'model.layers.1.mlp.experts.48.down_proj.weight': 438304768, 'model.layers.1.mlp.experts.48.up_proj.weight': 444071936, 'model.layers.1.mlp.experts.54.gate_proj.weight': 449839104, 'model.layers.1.mlp.experts.54.down_proj.weight': 455606272, 'model.layers.1.mlp.experts.54.up_proj.weight': 461373440, 'model.layers.1.mlp.experts.56.gate_proj.weight': 467140608, 'model.layers.1.mlp.experts.56.down_proj.weight': 472907776, 'model.layers.1.mlp.experts.56.up_proj.weight': 478674944, 'model.layers.1.mlp.experts.58.gate_proj.weight': 484442112, 'model.layers.1.mlp.experts.58.down_proj.weight': 490209280, 'model.layers.1.mlp.experts.58.up_proj.weight': 495976448, 'model.layers.1.mlp.experts.59.gate_proj.weight': 501743616, 'model.layers.1.mlp.experts.59.down_proj.weight': 507510784, 'model.layers.1.mlp.experts.59.up_proj.weight': 513277952, 'model.layers.1.mlp.experts.62.gate_proj.weight': 519045120, 'model.layers.1.mlp.experts.62.down_proj.weight': 524812288, 'model.layers.1.mlp.experts.62.up_proj.weight': 530579456, 'model.layers.1.mlp.experts.63.gate_proj.weight': 536346624, 'model.layers.1.mlp.experts.63.down_proj.weight': 542113792, 'model.layers.1.mlp.experts.63.up_proj.weight': 547880960}, 2: {'model.layers.1.mlp.experts.3.gate_proj.weight': 0, 'model.layers.1.mlp.experts.3.down_proj.weight': 5767168, 'model.layers.1.mlp.experts.3.up_proj.weight': 11534336, 'model.layers.1.mlp.experts.8.gate_proj.weight': 17301504, 'model.layers.1.mlp.experts.8.down_proj.weight': 23068672, 'model.layers.1.mlp.experts.8.up_proj.weight': 28835840, 'model.layers.1.mlp.experts.9.gate_proj.weight': 34603008, 'model.layers.1.mlp.experts.9.down_proj.weight': 40370176, 'model.layers.1.mlp.experts.9.up_proj.weight': 46137344, 'model.layers.1.mlp.experts.11.gate_proj.weight': 51904512, 'model.layers.1.mlp.experts.11.down_proj.weight': 57671680, 'model.layers.1.mlp.experts.11.up_proj.weight': 63438848, 'model.layers.1.mlp.experts.12.gate_proj.weight': 69206016, 'model.layers.1.mlp.experts.12.down_proj.weight': 74973184, 'model.layers.1.mlp.experts.12.up_proj.weight': 80740352, 'model.layers.1.mlp.experts.13.gate_proj.weight': 86507520, 'model.layers.1.mlp.experts.13.down_proj.weight': 92274688, 'model.layers.1.mlp.experts.13.up_proj.weight': 98041856, 'model.layers.1.mlp.experts.14.gate_proj.weight': 103809024, 'model.layers.1.mlp.experts.14.down_proj.weight': 109576192, 'model.layers.1.mlp.experts.14.up_proj.weight': 115343360, 'model.layers.1.mlp.experts.17.gate_proj.weight': 121110528, 'model.layers.1.mlp.experts.17.down_proj.weight': 126877696, 'model.layers.1.mlp.experts.17.up_proj.weight': 132644864, 'model.layers.1.mlp.experts.18.gate_proj.weight': 138412032, 'model.layers.1.mlp.experts.18.down_proj.weight': 144179200, 'model.layers.1.mlp.experts.18.up_proj.weight': 149946368, 'model.layers.1.mlp.experts.20.gate_proj.weight': 155713536, 'model.layers.1.mlp.experts.20.down_proj.weight': 161480704, 'model.layers.1.mlp.experts.20.up_proj.weight': 167247872, 'model.layers.1.mlp.experts.25.gate_proj.weight': 173015040, 'model.layers.1.mlp.experts.25.down_proj.weight': 178782208, 'model.layers.1.mlp.experts.25.up_proj.weight': 184549376, 'model.layers.1.mlp.experts.26.gate_proj.weight': 190316544, 'model.layers.1.mlp.experts.26.down_proj.weight': 196083712, 'model.layers.1.mlp.experts.26.up_proj.weight': 201850880, 'model.layers.1.mlp.experts.27.gate_proj.weight': 207618048, 'model.layers.1.mlp.experts.27.down_proj.weight': 213385216, 'model.layers.1.mlp.experts.27.up_proj.weight': 219152384, 'model.layers.1.mlp.experts.31.gate_proj.weight': 224919552, 'model.layers.1.mlp.experts.31.down_proj.weight': 230686720, 'model.layers.1.mlp.experts.31.up_proj.weight': 236453888, 'model.layers.1.mlp.experts.35.gate_proj.weight': 242221056, 'model.layers.1.mlp.experts.35.down_proj.weight': 247988224, 'model.layers.1.mlp.experts.35.up_proj.weight': 253755392, 'model.layers.1.mlp.experts.36.gate_proj.weight': 259522560, 'model.layers.1.mlp.experts.36.down_proj.weight': 265289728, 'model.layers.1.mlp.experts.36.up_proj.weight': 271056896, 'model.layers.1.mlp.experts.37.gate_proj.weight': 276824064, 'model.layers.1.mlp.experts.37.down_proj.weight': 282591232, 'model.layers.1.mlp.experts.37.up_proj.weight': 288358400, 'model.layers.1.mlp.experts.39.gate_proj.weight': 294125568, 'model.layers.1.mlp.experts.39.down_proj.weight': 299892736, 'model.layers.1.mlp.experts.39.up_proj.weight': 305659904, 'model.layers.1.mlp.experts.40.gate_proj.weight': 311427072, 'model.layers.1.mlp.experts.40.down_proj.weight': 317194240, 'model.layers.1.mlp.experts.40.up_proj.weight': 322961408, 'model.layers.1.mlp.experts.41.gate_proj.weight': 328728576, 'model.layers.1.mlp.experts.41.down_proj.weight': 334495744, 'model.layers.1.mlp.experts.41.up_proj.weight': 340262912, 'model.layers.1.mlp.experts.42.gate_proj.weight': 346030080, 'model.layers.1.mlp.experts.42.down_proj.weight': 351797248, 'model.layers.1.mlp.experts.42.up_proj.weight': 357564416, 'model.layers.1.mlp.experts.45.gate_proj.weight': 363331584, 'model.layers.1.mlp.experts.45.down_proj.weight': 369098752, 'model.layers.1.mlp.experts.45.up_proj.weight': 374865920, 'model.layers.1.mlp.experts.47.gate_proj.weight': 380633088, 'model.layers.1.mlp.experts.47.down_proj.weight': 386400256, 'model.layers.1.mlp.experts.47.up_proj.weight': 392167424, 'model.layers.1.mlp.experts.49.gate_proj.weight': 397934592, 'model.layers.1.mlp.experts.49.down_proj.weight': 403701760, 'model.layers.1.mlp.experts.49.up_proj.weight': 409468928, 'model.layers.1.mlp.experts.50.gate_proj.weight': 415236096, 'model.layers.1.mlp.experts.50.down_proj.weight': 421003264, 'model.layers.1.mlp.experts.50.up_proj.weight': 426770432, 'model.layers.1.mlp.experts.51.gate_proj.weight': 432537600, 'model.layers.1.mlp.experts.51.down_proj.weight': 438304768, 'model.layers.1.mlp.experts.51.up_proj.weight': 444071936, 'model.layers.1.mlp.experts.52.gate_proj.weight': 449839104, 'model.layers.1.mlp.experts.52.down_proj.weight': 455606272, 'model.layers.1.mlp.experts.52.up_proj.weight': 461373440, 'model.layers.1.mlp.experts.53.gate_proj.weight': 467140608, 'model.layers.1.mlp.experts.53.down_proj.weight': 472907776, 'model.layers.1.mlp.experts.53.up_proj.weight': 478674944, 'model.layers.1.mlp.experts.55.gate_proj.weight': 484442112, 'model.layers.1.mlp.experts.55.down_proj.weight': 490209280, 'model.layers.1.mlp.experts.55.up_proj.weight': 495976448, 'model.layers.1.mlp.experts.57.gate_proj.weight': 501743616, 'model.layers.1.mlp.experts.57.down_proj.weight': 507510784, 'model.layers.1.mlp.experts.57.up_proj.weight': 513277952, 'model.layers.1.mlp.experts.60.gate_proj.weight': 519045120, 'model.layers.1.mlp.experts.60.down_proj.weight': 524812288, 'model.layers.1.mlp.experts.60.up_proj.weight': 530579456, 'model.layers.1.mlp.experts.61.gate_proj.weight': 536346624, 'model.layers.1.mlp.experts.61.down_proj.weight': 542113792, 'model.layers.1.mlp.experts.61.up_proj.weight': 547880960}}tensor_copy_chunks_device_map {1: [(2860515328, 5767168, 0, 0), (2866282496, 5767168, 5767168, 0), (2854748160, 5767168, 11534336, 0), (2877816832, 5767168, 17301504, 0), (2883584000, 5767168, 23068672, 0), (2872049664, 5767168, 28835840, 0), (2895118336, 5767168, 34603008, 0), (2900885504, 5767168, 40370176, 0), (2889351168, 5767168, 46137344, 0), (2929721344, 5767168, 51904512, 0), (2935488512, 5767168, 57671680, 0), (2923954176, 5767168, 63438848, 0), (2947022848, 5767168, 69206016, 0), (2952790016, 5767168, 74973184, 0), (2941255680, 5767168, 80740352, 0), (2964324352, 5767168, 86507520, 0), (2970091520, 5767168, 92274688, 0), (2958557184, 5767168, 98041856, 0), (2981625856, 5767168, 103809024, 0), (2987393024, 5767168, 109576192, 0), (2975858688, 5767168, 115343360, 0), (3033530368, 5767168, 121110528, 0), (3039297536, 5767168, 126877696, 0), (3027763200, 5767168, 132644864, 0), (3120037888, 5767168, 138412032, 0), (3125805056, 5767168, 144179200, 0), (3114270720, 5767168, 149946368, 0), (3137339392, 5767168, 155713536, 0), (3143106560, 5767168, 161480704, 0), (3131572224, 5767168, 167247872, 0), (3189243904, 5767168, 173015040, 0), (3195011072, 5767168, 178782208, 0), (3183476736, 5767168, 184549376, 0), (3223846912, 5767168, 190316544, 0), (3229614080, 5767168, 196083712, 0), (3218079744, 5767168, 201850880, 0), (3241148416, 5767168, 207618048, 0), (3246915584, 5767168, 213385216, 0), (3235381248, 5767168, 219152384, 0), (3258449920, 5767168, 224919552, 0), (3264217088, 5767168, 230686720, 0), (3252682752, 5767168, 236453888, 0), (3275751424, 5767168, 242221056, 0), (3281518592, 5767168, 247988224, 0), (3269984256, 5767168, 253755392, 0), (3344957440, 5767168, 259522560, 0), (3350724608, 5767168, 265289728, 0), (3339190272, 5767168, 271056896, 0), (3362258944, 5767168, 276824064, 0), (3368026112, 5767168, 282591232, 0), (3356491776, 5767168, 288358400, 0), (3379560448, 5767168, 294125568, 0), (3385327616, 5767168, 299892736, 0), (3373793280, 5767168, 305659904, 0), (3414163456, 5767168, 311427072, 0), (3419930624, 5767168, 317194240, 0), (3408396288, 5767168, 322961408, 0), (3431464960, 5767168, 328728576, 0), (3437232128, 5767168, 334495744, 0), (3425697792, 5767168, 340262912, 0), (3448766464, 5767168, 346030080, 0), (3454533632, 5767168, 351797248, 0), (3442999296, 5767168, 357564416, 0), (3517972480, 5767168, 363331584, 0), (3523739648, 5767168, 369098752, 0), (3512205312, 5767168, 374865920, 0), (3604480000, 5767168, 380633088, 0), (3610247168, 5767168, 386400256, 0), (3598712832, 5767168, 392167424, 0), (3621781504, 5767168, 397934592, 0), (3627548672, 5767168, 403701760, 0), (3616014336, 5767168, 409468928, 0), (3656384512, 5767168, 415236096, 0), (3662151680, 5767168, 421003264, 0), (3650617344, 5767168, 426770432, 0), (3690987520, 5767168, 432537600, 0), (3696754688, 5767168, 438304768, 0), (3685220352, 5767168, 444071936, 0), (3794796544, 5767168, 449839104, 0), (3800563712, 5767168, 455606272, 0), (3789029376, 5767168, 461373440, 0), (3829399552, 5767168, 467140608, 0), (3835166720, 5767168, 472907776, 0), (3823632384, 5767168, 478674944, 0), (3864002560, 5767168, 484442112, 0), (3869769728, 5767168, 490209280, 0), (3858235392, 5767168, 495976448, 0), (3881304064, 5767168, 501743616, 0), (3887071232, 5767168, 507510784, 0), (3875536896, 5767168, 513277952, 0), (3933208576, 5767168, 519045120, 0), (3938975744, 5767168, 524812288, 0), (3927441408, 5767168, 530579456, 0), (3950510080, 5767168, 536346624, 0), (3956277248, 5767168, 542113792, 0), (3944742912, 5767168, 547880960, 0)], 2: [(2912419840, 5767168, 0, 0), (2918187008, 5767168, 5767168, 0), (2906652672, 5767168, 11534336, 0), (2998927360, 5767168, 17301504, 0), (3004694528, 5767168, 23068672, 0), (2993160192, 5767168, 28835840, 0), (3016228864, 5767168, 34603008, 0), (3021996032, 5767168, 40370176, 0), (3010461696, 5767168, 46137344, 0), (3050831872, 5767168, 51904512, 0), (3056599040, 5767168, 57671680, 0), (3045064704, 5767168, 63438848, 0), (3068133376, 5767168, 69206016, 0), (3073900544, 5767168, 74973184, 0), (3062366208, 5767168, 80740352, 0), (3085434880, 5767168, 86507520, 0), (3091202048, 5767168, 92274688, 0), (3079667712, 5767168, 98041856, 0), (3102736384, 5767168, 103809024, 0), (3108503552, 5767168, 109576192, 0), (3096969216, 5767168, 115343360, 0), (3154640896, 5767168, 121110528, 0), (3160408064, 5767168, 126877696, 0), (3148873728, 5767168, 132644864, 0), (3171942400, 5767168, 138412032, 0), (3177709568, 5767168, 144179200, 0), (3166175232, 5767168, 149946368, 0), (3206545408, 5767168, 155713536, 0), (3212312576, 5767168, 161480704, 0), (3200778240, 5767168, 167247872, 0), (3293052928, 5767168, 173015040, 0), (3298820096, 5767168, 178782208, 0), (3287285760, 5767168, 184549376, 0), (3310354432, 5767168, 190316544, 0), (3316121600, 5767168, 196083712, 0), (3304587264, 5767168, 201850880, 0), (3327655936, 5767168, 207618048, 0), (3333423104, 5767168, 213385216, 0), (3321888768, 5767168, 219152384, 0), (3396861952, 5767168, 224919552, 0), (3402629120, 5767168, 230686720, 0), (3391094784, 5767168, 236453888, 0), (3466067968, 5767168, 242221056, 0), (3471835136, 5767168, 247988224, 0), (3460300800, 5767168, 253755392, 0), (3483369472, 5767168, 259522560, 0), (3489136640, 5767168, 265289728, 0), (3477602304, 5767168, 271056896, 0), (3500670976, 5767168, 276824064, 0), (3506438144, 5767168, 282591232, 0), (3494903808, 5767168, 288358400, 0), (3535273984, 5767168, 294125568, 0), (3541041152, 5767168, 299892736, 0), (3529506816, 5767168, 305659904, 0), (3552575488, 5767168, 311427072, 0), (3558342656, 5767168, 317194240, 0), (3546808320, 5767168, 322961408, 0), (3569876992, 5767168, 328728576, 0), (3575644160, 5767168, 334495744, 0), (3564109824, 5767168, 340262912, 0), (3587178496, 5767168, 346030080, 0), (3592945664, 5767168, 351797248, 0), (3581411328, 5767168, 357564416, 0), (3639083008, 5767168, 363331584, 0), (3644850176, 5767168, 369098752, 0), (3633315840, 5767168, 374865920, 0), (3673686016, 5767168, 380633088, 0), (3679453184, 5767168, 386400256, 0), (3667918848, 5767168, 392167424, 0), (3708289024, 5767168, 397934592, 0), (3714056192, 5767168, 403701760, 0), (3702521856, 5767168, 409468928, 0), (3725590528, 5767168, 415236096, 0), (3731357696, 5767168, 421003264, 0), (3719823360, 5767168, 426770432, 0), (3742892032, 5767168, 432537600, 0), (3748659200, 5767168, 438304768, 0), (3737124864, 5767168, 444071936, 0), (3760193536, 5767168, 449839104, 0), (3765960704, 5767168, 455606272, 0), (3754426368, 5767168, 461373440, 0), (3777495040, 5767168, 467140608, 0), (3783262208, 5767168, 472907776, 0), (3771727872, 5767168, 478674944, 0), (3812098048, 5767168, 484442112, 0), (3817865216, 5767168, 490209280, 0), (3806330880, 5767168, 495976448, 0), (3846701056, 5767168, 501743616, 0), (3852468224, 5767168, 507510784, 0), (3840933888, 5767168, 513277952, 0), (3898605568, 5767168, 519045120, 0), (3904372736, 5767168, 524812288, 0), (3892838400, 5767168, 530579456, 0), (3915907072, 5767168, 536346624, 0), (3921674240, 5767168, 542113792, 0), (3910139904, 5767168, 547880960, 0)]}cuda_memory_handles_device_map {1: <capsule object NULL at 0x7b0b87f0f4b0>, 2: <capsule object NULL at 0x7b0b87f0f570>}
DEBUG 01-14 17:01:49.765205.765205 sllm_store_c.py:27] get device uuid map
DEBUG 01-14 17:01:49.765076.765076 sllm_store_c.py:29] call client load into gpu
DEBUG 01-14 17:01:49.765686.765686 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, f93eb52e-7a13-4e0c-abd2-076fb1ecaeeb
DEBUG 01-14 17:01:49.765092.765092 client.py:106] call stub.LoadModelAsync
INFO 01-14 17:01:49.768605.768605 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, f93eb52e-7a13-4e0c-abd2-076fb1ecaeeb
DEBUG 01-14 17:01:49.769578.769578 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu_multi_device cost 0.006709098815917969 seconds
DEBUG 01-14 17:01:49.769825.769825 cuda_h.py:10] start restore2model
DEBUG 01-14 17:01:49.774664.774664 cuda_h.py:19] end restore2model cost 0.004827976226806641 seconds
DEBUG 01-14 17:01:49.775192.775192 cuda_h.py:10] start experts_func_mgpu_group_pad
DEBUG 01-14 17:01:49.797535.797535 cuda_h.py:19] end experts_func_mgpu_group_pad cost 0.02163386344909668 seconds
DEBUG 01-14 17:01:49.797875.797875 cuda_h.py:10] start experts_func_mgpu_group_pad
DEBUG 01-14 17:01:49.824963.824963 cuda_h.py:19] end experts_func_mgpu_group_pad cost 0.02649712562561035 seconds
DEBUG 01-14 17:01:49.824131.824131 cuda_h.py:10] start gpu_group_list
DEBUG 01-14 17:01:49.824464.824464 cuda_h.py:19] end gpu_group_list cost 0.0004220008850097656 seconds
DEBUG 01-14 17:01:49.824174.824174 cuda_h.py:10] start gpu_group_list
DEBUG 01-14 17:01:49.825100.825100 cuda_h.py:19] end gpu_group_list cost 0.00034165382385253906 seconds
INFO 01-14 17:01:49.832624.832624 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, f93eb52e-7a13-4e0c-abd2-076fb1ecaeeb
INFO 01-14 17:01:49.834532.834532 client.py:127] Model loaded
DEBUG 01-14 17:01:49.834422.834422 cuda_h.py:19] end task_processing_mp_load cost 0.07198452949523926 seconds
DEBUG 01-14 17:01:49.834886.834886 cuda_h.py:10] start exec_together
DEBUG 01-14 17:01:49.911999.911999 mlpmodule.py:1053] mgpu group einsum cost 0.0710916519165039 s
DEBUG 01-14 17:01:49.935357.935357 mlpmodule.py:1109] mgpu experts func einsum cost 0.1010122299194336 s
DEBUG 01-14 17:01:49.935461.935461 cuda_h.py:19] end exec_together cost 0.10120439529418945 seconds
DEBUG 01-14 17:01:49.935025.935025 cuda_h.py:10] start exec_one_by_one
DEBUG 01-14 17:01:49.936106.936106 mlpmodule.py:1178] gpu group tensors cost 0.0009818077087402344 s
DEBUG 01-14 17:01:49.938234.938234 mlpmodule.py:1220] gpu pad cost 0.0015654563903808594 s
DEBUG 01-14 17:01:49.938183.938183 mlpmodule.py:1226] start_w1
DEBUG 01-14 17:01:49.938551.938551 mlpmodule.py:1230] start_w3
DEBUG 01-14 17:01:49.939203.939203 mlpmodule.py:1236] start_w2
DEBUG 01-14 17:01:49.939868.939868 mlpmodule.py:1239] gpu group einsum cost 0.0010631084442138672 s
DEBUG 01-14 17:01:49.941692.941692 mlpmodule.py:1316] gpu experts func einsum cost 0.005808591842651367 s
DEBUG 01-14 17:01:49.942401.942401 mlpmodule.py:1178] gpu group tensors cost 0.0008959770202636719 s
DEBUG 01-14 17:01:49.944923.944923 mlpmodule.py:1220] gpu pad cost 0.00186920166015625 s
DEBUG 01-14 17:01:49.944474.944474 mlpmodule.py:1226] start_w1
DEBUG 01-14 17:01:49.945426.945426 mlpmodule.py:1230] start_w3
DEBUG 01-14 17:01:49.945873.945873 mlpmodule.py:1236] start_w2
DEBUG 01-14 17:01:49.945491.945491 mlpmodule.py:1239] gpu group einsum cost 0.001096963882446289 s
DEBUG 01-14 17:01:49.948566.948566 mlpmodule.py:1316] gpu experts func einsum cost 0.006425380706787109 s
DEBUG 01-14 17:01:49.948304.948304 cuda_h.py:19] end exec_one_by_one cost 0.012468814849853516 seconds
DEBUG 01-14 17:01:49.948107.948107 cuda_h.py:10] start exec_one_by_one_end_new
DEBUG 01-14 17:01:49.948154.948154 cuda_h.py:10] start gpu_group_tensor
DEBUG 01-14 17:01:49.948080.948080 cuda_h.py:19] end gpu_group_tensor cost 0.00012636184692382812 seconds
DEBUG 01-14 17:01:49.948949.948949 cuda_h.py:10] start gpu_group_tensor
DEBUG 01-14 17:01:49.948106.948106 cuda_h.py:19] end gpu_group_tensor cost 0.0001239776611328125 seconds
DEBUG 01-14 17:01:49.948553.948553 cuda_h.py:10] start gpu_group_einsum
DEBUG 01-14 17:01:49.949100.949100 cuda_h.py:19] end gpu_group_einsum cost 0.00029158592224121094 seconds
DEBUG 01-14 17:01:49.949115.949115 cuda_h.py:10] start gpu_final_hidden_states_scatter
DEBUG 01-14 17:01:49.949345.949345 cuda_h.py:10] start all_expert_weight_slices
DEBUG 01-14 17:01:49.949199.949199 cuda_h.py:19] end all_expert_weight_slices cost 0.0007333755493164062 seconds
DEBUG 01-14 17:01:49.950352.950352 cuda_h.py:10] start all_expert_output_slices
DEBUG 01-14 17:01:49.950485.950485 cuda_h.py:19] end all_expert_output_slices cost 0.00017452239990234375 seconds
DEBUG 01-14 17:01:49.950095.950095 cuda_h.py:10] start concat_expert_out
DEBUG 01-14 17:01:49.950464.950464 cuda_h.py:19] end concat_expert_out cost 0.00010442733764648438 seconds
DEBUG 01-14 17:01:49.950499.950499 cuda_h.py:10] start index_scatter
DEBUG 01-14 17:01:49.950323.950323 cuda_h.py:19] end index_scatter cost 4.57763671875e-05 seconds
DEBUG 01-14 17:01:49.950748.950748 cuda_h.py:19] end gpu_final_hidden_states_scatter cost 0.0014595985412597656 seconds
DEBUG 01-14 17:01:49.950699.950699 cuda_h.py:10] start gpu_group_einsum
DEBUG 01-14 17:01:49.951539.951539 cuda_h.py:19] end gpu_group_einsum cost 0.0002913475036621094 seconds
DEBUG 01-14 17:01:49.951692.951692 cuda_h.py:10] start gpu_final_hidden_states_scatter
DEBUG 01-14 17:01:49.951374.951374 cuda_h.py:10] start all_expert_weight_slices
DEBUG 01-14 17:01:49.952094.952094 cuda_h.py:19] end all_expert_weight_slices cost 0.000705718994140625 seconds
DEBUG 01-14 17:01:49.952572.952572 cuda_h.py:10] start all_expert_output_slices
DEBUG 01-14 17:01:49.952626.952626 cuda_h.py:19] end all_expert_output_slices cost 0.00018668174743652344 seconds
DEBUG 01-14 17:01:49.952428.952428 cuda_h.py:10] start concat_expert_out
DEBUG 01-14 17:01:49.952870.952870 cuda_h.py:19] end concat_expert_out cost 0.00012421607971191406 seconds
DEBUG 01-14 17:01:49.952760.952760 cuda_h.py:10] start index_scatter
DEBUG 01-14 17:01:49.952769.952769 cuda_h.py:19] end index_scatter cost 4.5299530029296875e-05 seconds
DEBUG 01-14 17:01:49.952590.952590 cuda_h.py:19] end gpu_final_hidden_states_scatter cost 0.0016491413116455078 seconds
DEBUG 01-14 17:01:49.952003.952003 cuda_h.py:19] end exec_one_by_one_end_new cost 0.0046045780181884766 seconds
DEBUG 01-14 17:01:49.952375.952375 cuda_h.py:10] start exec_one_by_one_end_new2
DEBUG 01-14 17:01:49.952714.952714 cuda_h.py:10] start gpu_group_einsum_mp_multi_list
DEBUG 01-14 17:01:49.952841.952841 cuda_h.py:10] start gpu_group_tensor
DEBUG 01-14 17:01:49.953184.953184 cuda_h.py:19] end gpu_group_tensor cost 0.0007121562957763672 seconds
DEBUG 01-14 17:01:49.953391.953391 cuda_h.py:10] start gpu_group_tensor
DEBUG 01-14 17:01:49.954680.954680 cuda_h.py:19] end gpu_group_tensor cost 0.000492095947265625 seconds
DEBUG 01-14 17:01:49.954233.954233 cuda_h.py:10] start gpu_group_einsum
DEBUG 01-14 17:01:49.954489.954489 cuda_h.py:19] end gpu_group_einsum cost 0.0002856254577636719 seconds
DEBUG 01-14 17:01:49.954233.954233 cuda_h.py:10] start gpu_group_einsum
DEBUG 01-14 17:01:49.955052.955052 cuda_h.py:19] end gpu_group_einsum cost 0.00027823448181152344 seconds
DEBUG 01-14 17:01:49.955274.955274 cuda_h.py:10] start gpu_final_hidden_states_scatter
DEBUG 01-14 17:01:49.955753.955753 cuda_h.py:10] start all_expert_outputs_slices
DEBUG 01-14 17:01:49.955688.955688 cuda_h.py:19] end all_expert_outputs_slices cost 0.0002009868621826172 seconds
DEBUG 01-14 17:01:49.955821.955821 cuda_h.py:10] start concat_expert_out
DEBUG 01-14 17:01:49.955824.955824 cuda_h.py:19] end concat_expert_out cost 4.649162292480469e-05 seconds
DEBUG 01-14 17:01:49.955799.955799 cuda_h.py:10] start index_scatter
DEBUG 01-14 17:01:49.955186.955186 cuda_h.py:19] end index_scatter cost 4.506111145019531e-05 seconds
DEBUG 01-14 17:01:49.955145.955145 cuda_h.py:19] end gpu_final_hidden_states_scatter cost 0.0006725788116455078 seconds
DEBUG 01-14 17:01:49.955724.955724 cuda_h.py:10] start gpu_final_hidden_states_scatter
DEBUG 01-14 17:01:49.956030.956030 cuda_h.py:10] start all_expert_outputs_slices
DEBUG 01-14 17:01:49.956613.956613 cuda_h.py:19] end all_expert_outputs_slices cost 0.00015783309936523438 seconds
DEBUG 01-14 17:01:49.956693.956693 cuda_h.py:10] start concat_expert_out
DEBUG 01-14 17:01:49.956980.956980 cuda_h.py:19] end concat_expert_out cost 4.673004150390625e-05 seconds
DEBUG 01-14 17:01:49.956432.956432 cuda_h.py:10] start index_scatter
DEBUG 01-14 17:01:49.956138.956138 cuda_h.py:19] end index_scatter cost 6.890296936035156e-05 seconds
DEBUG 01-14 17:01:49.956324.956324 cuda_h.py:19] end gpu_final_hidden_states_scatter cost 0.0004811286926269531 seconds
DEBUG 01-14 17:01:49.956922.956922 cuda_h.py:19] end exec_one_by_one_end_new2 cost 0.0036466121673583984 seconds
DEBUG 01-14 17:01:49.962087.962087 cuda_h.py:10] start task_processing_mp_load
DEBUG 01-14 17:01:49.962607.962607 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu_multi_device
DEBUG 01-14 17:01:49.965900.965900 cuda_memory_view.py:520] tensor_device_offsets_device_map {1: {'model.layers.1.mlp.experts.0.gate_proj.weight': 0, 'model.layers.1.mlp.experts.0.down_proj.weight': 5767168, 'model.layers.1.mlp.experts.0.up_proj.weight': 11534336, 'model.layers.1.mlp.experts.1.gate_proj.weight': 17301504, 'model.layers.1.mlp.experts.1.down_proj.weight': 23068672, 'model.layers.1.mlp.experts.1.up_proj.weight': 28835840, 'model.layers.1.mlp.experts.2.gate_proj.weight': 34603008, 'model.layers.1.mlp.experts.2.down_proj.weight': 40370176, 'model.layers.1.mlp.experts.2.up_proj.weight': 46137344, 'model.layers.1.mlp.experts.4.gate_proj.weight': 51904512, 'model.layers.1.mlp.experts.4.down_proj.weight': 57671680, 'model.layers.1.mlp.experts.4.up_proj.weight': 63438848, 'model.layers.1.mlp.experts.5.gate_proj.weight': 69206016, 'model.layers.1.mlp.experts.5.down_proj.weight': 74973184, 'model.layers.1.mlp.experts.5.up_proj.weight': 80740352, 'model.layers.1.mlp.experts.6.gate_proj.weight': 86507520, 'model.layers.1.mlp.experts.6.down_proj.weight': 92274688, 'model.layers.1.mlp.experts.6.up_proj.weight': 98041856, 'model.layers.1.mlp.experts.7.gate_proj.weight': 103809024, 'model.layers.1.mlp.experts.7.down_proj.weight': 109576192, 'model.layers.1.mlp.experts.7.up_proj.weight': 115343360, 'model.layers.1.mlp.experts.10.gate_proj.weight': 121110528, 'model.layers.1.mlp.experts.10.down_proj.weight': 126877696, 'model.layers.1.mlp.experts.10.up_proj.weight': 132644864, 'model.layers.1.mlp.experts.15.gate_proj.weight': 138412032, 'model.layers.1.mlp.experts.15.down_proj.weight': 144179200, 'model.layers.1.mlp.experts.15.up_proj.weight': 149946368, 'model.layers.1.mlp.experts.16.gate_proj.weight': 155713536, 'model.layers.1.mlp.experts.16.down_proj.weight': 161480704, 'model.layers.1.mlp.experts.16.up_proj.weight': 167247872, 'model.layers.1.mlp.experts.19.gate_proj.weight': 173015040, 'model.layers.1.mlp.experts.19.down_proj.weight': 178782208, 'model.layers.1.mlp.experts.19.up_proj.weight': 184549376, 'model.layers.1.mlp.experts.21.gate_proj.weight': 190316544, 'model.layers.1.mlp.experts.21.down_proj.weight': 196083712, 'model.layers.1.mlp.experts.21.up_proj.weight': 201850880, 'model.layers.1.mlp.experts.22.gate_proj.weight': 207618048, 'model.layers.1.mlp.experts.22.down_proj.weight': 213385216, 'model.layers.1.mlp.experts.22.up_proj.weight': 219152384, 'model.layers.1.mlp.experts.23.gate_proj.weight': 224919552, 'model.layers.1.mlp.experts.23.down_proj.weight': 230686720, 'model.layers.1.mlp.experts.23.up_proj.weight': 236453888, 'model.layers.1.mlp.experts.24.gate_proj.weight': 242221056, 'model.layers.1.mlp.experts.24.down_proj.weight': 247988224, 'model.layers.1.mlp.experts.24.up_proj.weight': 253755392, 'model.layers.1.mlp.experts.28.gate_proj.weight': 259522560, 'model.layers.1.mlp.experts.28.down_proj.weight': 265289728, 'model.layers.1.mlp.experts.28.up_proj.weight': 271056896, 'model.layers.1.mlp.experts.29.gate_proj.weight': 276824064, 'model.layers.1.mlp.experts.29.down_proj.weight': 282591232, 'model.layers.1.mlp.experts.29.up_proj.weight': 288358400, 'model.layers.1.mlp.experts.30.gate_proj.weight': 294125568, 'model.layers.1.mlp.experts.30.down_proj.weight': 299892736, 'model.layers.1.mlp.experts.30.up_proj.weight': 305659904, 'model.layers.1.mlp.experts.32.gate_proj.weight': 311427072, 'model.layers.1.mlp.experts.32.down_proj.weight': 317194240, 'model.layers.1.mlp.experts.32.up_proj.weight': 322961408, 'model.layers.1.mlp.experts.33.gate_proj.weight': 328728576, 'model.layers.1.mlp.experts.33.down_proj.weight': 334495744, 'model.layers.1.mlp.experts.33.up_proj.weight': 340262912, 'model.layers.1.mlp.experts.34.gate_proj.weight': 346030080, 'model.layers.1.mlp.experts.34.down_proj.weight': 351797248, 'model.layers.1.mlp.experts.34.up_proj.weight': 357564416, 'model.layers.1.mlp.experts.38.gate_proj.weight': 363331584, 'model.layers.1.mlp.experts.38.down_proj.weight': 369098752, 'model.layers.1.mlp.experts.38.up_proj.weight': 374865920, 'model.layers.1.mlp.experts.43.gate_proj.weight': 380633088, 'model.layers.1.mlp.experts.43.down_proj.weight': 386400256, 'model.layers.1.mlp.experts.43.up_proj.weight': 392167424, 'model.layers.1.mlp.experts.44.gate_proj.weight': 397934592, 'model.layers.1.mlp.experts.44.down_proj.weight': 403701760, 'model.layers.1.mlp.experts.44.up_proj.weight': 409468928, 'model.layers.1.mlp.experts.46.gate_proj.weight': 415236096, 'model.layers.1.mlp.experts.46.down_proj.weight': 421003264, 'model.layers.1.mlp.experts.46.up_proj.weight': 426770432, 'model.layers.1.mlp.experts.48.gate_proj.weight': 432537600, 'model.layers.1.mlp.experts.48.down_proj.weight': 438304768, 'model.layers.1.mlp.experts.48.up_proj.weight': 444071936, 'model.layers.1.mlp.experts.54.gate_proj.weight': 449839104, 'model.layers.1.mlp.experts.54.down_proj.weight': 455606272, 'model.layers.1.mlp.experts.54.up_proj.weight': 461373440, 'model.layers.1.mlp.experts.56.gate_proj.weight': 467140608, 'model.layers.1.mlp.experts.56.down_proj.weight': 472907776, 'model.layers.1.mlp.experts.56.up_proj.weight': 478674944, 'model.layers.1.mlp.experts.58.gate_proj.weight': 484442112, 'model.layers.1.mlp.experts.58.down_proj.weight': 490209280, 'model.layers.1.mlp.experts.58.up_proj.weight': 495976448, 'model.layers.1.mlp.experts.59.gate_proj.weight': 501743616, 'model.layers.1.mlp.experts.59.down_proj.weight': 507510784, 'model.layers.1.mlp.experts.59.up_proj.weight': 513277952, 'model.layers.1.mlp.experts.62.gate_proj.weight': 519045120, 'model.layers.1.mlp.experts.62.down_proj.weight': 524812288, 'model.layers.1.mlp.experts.62.up_proj.weight': 530579456, 'model.layers.1.mlp.experts.63.gate_proj.weight': 536346624, 'model.layers.1.mlp.experts.63.down_proj.weight': 542113792, 'model.layers.1.mlp.experts.63.up_proj.weight': 547880960}, 2: {'model.layers.1.mlp.experts.3.gate_proj.weight': 0, 'model.layers.1.mlp.experts.3.down_proj.weight': 5767168, 'model.layers.1.mlp.experts.3.up_proj.weight': 11534336, 'model.layers.1.mlp.experts.8.gate_proj.weight': 17301504, 'model.layers.1.mlp.experts.8.down_proj.weight': 23068672, 'model.layers.1.mlp.experts.8.up_proj.weight': 28835840, 'model.layers.1.mlp.experts.9.gate_proj.weight': 34603008, 'model.layers.1.mlp.experts.9.down_proj.weight': 40370176, 'model.layers.1.mlp.experts.9.up_proj.weight': 46137344, 'model.layers.1.mlp.experts.11.gate_proj.weight': 51904512, 'model.layers.1.mlp.experts.11.down_proj.weight': 57671680, 'model.layers.1.mlp.experts.11.up_proj.weight': 63438848, 'model.layers.1.mlp.experts.12.gate_proj.weight': 69206016, 'model.layers.1.mlp.experts.12.down_proj.weight': 74973184, 'model.layers.1.mlp.experts.12.up_proj.weight': 80740352, 'model.layers.1.mlp.experts.13.gate_proj.weight': 86507520, 'model.layers.1.mlp.experts.13.down_proj.weight': 92274688, 'model.layers.1.mlp.experts.13.up_proj.weight': 98041856, 'model.layers.1.mlp.experts.14.gate_proj.weight': 103809024, 'model.layers.1.mlp.experts.14.down_proj.weight': 109576192, 'model.layers.1.mlp.experts.14.up_proj.weight': 115343360, 'model.layers.1.mlp.experts.17.gate_proj.weight': 121110528, 'model.layers.1.mlp.experts.17.down_proj.weight': 126877696, 'model.layers.1.mlp.experts.17.up_proj.weight': 132644864, 'model.layers.1.mlp.experts.18.gate_proj.weight': 138412032, 'model.layers.1.mlp.experts.18.down_proj.weight': 144179200, 'model.layers.1.mlp.experts.18.up_proj.weight': 149946368, 'model.layers.1.mlp.experts.20.gate_proj.weight': 155713536, 'model.layers.1.mlp.experts.20.down_proj.weight': 161480704, 'model.layers.1.mlp.experts.20.up_proj.weight': 167247872, 'model.layers.1.mlp.experts.25.gate_proj.weight': 173015040, 'model.layers.1.mlp.experts.25.down_proj.weight': 178782208, 'model.layers.1.mlp.experts.25.up_proj.weight': 184549376, 'model.layers.1.mlp.experts.26.gate_proj.weight': 190316544, 'model.layers.1.mlp.experts.26.down_proj.weight': 196083712, 'model.layers.1.mlp.experts.26.up_proj.weight': 201850880, 'model.layers.1.mlp.experts.27.gate_proj.weight': 207618048, 'model.layers.1.mlp.experts.27.down_proj.weight': 213385216, 'model.layers.1.mlp.experts.27.up_proj.weight': 219152384, 'model.layers.1.mlp.experts.31.gate_proj.weight': 224919552, 'model.layers.1.mlp.experts.31.down_proj.weight': 230686720, 'model.layers.1.mlp.experts.31.up_proj.weight': 236453888, 'model.layers.1.mlp.experts.35.gate_proj.weight': 242221056, 'model.layers.1.mlp.experts.35.down_proj.weight': 247988224, 'model.layers.1.mlp.experts.35.up_proj.weight': 253755392, 'model.layers.1.mlp.experts.36.gate_proj.weight': 259522560, 'model.layers.1.mlp.experts.36.down_proj.weight': 265289728, 'model.layers.1.mlp.experts.36.up_proj.weight': 271056896, 'model.layers.1.mlp.experts.37.gate_proj.weight': 276824064, 'model.layers.1.mlp.experts.37.down_proj.weight': 282591232, 'model.layers.1.mlp.experts.37.up_proj.weight': 288358400, 'model.layers.1.mlp.experts.39.gate_proj.weight': 294125568, 'model.layers.1.mlp.experts.39.down_proj.weight': 299892736, 'model.layers.1.mlp.experts.39.up_proj.weight': 305659904, 'model.layers.1.mlp.experts.40.gate_proj.weight': 311427072, 'model.layers.1.mlp.experts.40.down_proj.weight': 317194240, 'model.layers.1.mlp.experts.40.up_proj.weight': 322961408, 'model.layers.1.mlp.experts.41.gate_proj.weight': 328728576, 'model.layers.1.mlp.experts.41.down_proj.weight': 334495744, 'model.layers.1.mlp.experts.41.up_proj.weight': 340262912, 'model.layers.1.mlp.experts.42.gate_proj.weight': 346030080, 'model.layers.1.mlp.experts.42.down_proj.weight': 351797248, 'model.layers.1.mlp.experts.42.up_proj.weight': 357564416, 'model.layers.1.mlp.experts.45.gate_proj.weight': 363331584, 'model.layers.1.mlp.experts.45.down_proj.weight': 369098752, 'model.layers.1.mlp.experts.45.up_proj.weight': 374865920, 'model.layers.1.mlp.experts.47.gate_proj.weight': 380633088, 'model.layers.1.mlp.experts.47.down_proj.weight': 386400256, 'model.layers.1.mlp.experts.47.up_proj.weight': 392167424, 'model.layers.1.mlp.experts.49.gate_proj.weight': 397934592, 'model.layers.1.mlp.experts.49.down_proj.weight': 403701760, 'model.layers.1.mlp.experts.49.up_proj.weight': 409468928, 'model.layers.1.mlp.experts.50.gate_proj.weight': 415236096, 'model.layers.1.mlp.experts.50.down_proj.weight': 421003264, 'model.layers.1.mlp.experts.50.up_proj.weight': 426770432, 'model.layers.1.mlp.experts.51.gate_proj.weight': 432537600, 'model.layers.1.mlp.experts.51.down_proj.weight': 438304768, 'model.layers.1.mlp.experts.51.up_proj.weight': 444071936, 'model.layers.1.mlp.experts.52.gate_proj.weight': 449839104, 'model.layers.1.mlp.experts.52.down_proj.weight': 455606272, 'model.layers.1.mlp.experts.52.up_proj.weight': 461373440, 'model.layers.1.mlp.experts.53.gate_proj.weight': 467140608, 'model.layers.1.mlp.experts.53.down_proj.weight': 472907776, 'model.layers.1.mlp.experts.53.up_proj.weight': 478674944, 'model.layers.1.mlp.experts.55.gate_proj.weight': 484442112, 'model.layers.1.mlp.experts.55.down_proj.weight': 490209280, 'model.layers.1.mlp.experts.55.up_proj.weight': 495976448, 'model.layers.1.mlp.experts.57.gate_proj.weight': 501743616, 'model.layers.1.mlp.experts.57.down_proj.weight': 507510784, 'model.layers.1.mlp.experts.57.up_proj.weight': 513277952, 'model.layers.1.mlp.experts.60.gate_proj.weight': 519045120, 'model.layers.1.mlp.experts.60.down_proj.weight': 524812288, 'model.layers.1.mlp.experts.60.up_proj.weight': 530579456, 'model.layers.1.mlp.experts.61.gate_proj.weight': 536346624, 'model.layers.1.mlp.experts.61.down_proj.weight': 542113792, 'model.layers.1.mlp.experts.61.up_proj.weight': 547880960}}tensor_copy_chunks_device_map {1: [(2860515328, 5767168, 0, 0), (2866282496, 5767168, 5767168, 0), (2854748160, 5767168, 11534336, 0), (2877816832, 5767168, 17301504, 0), (2883584000, 5767168, 23068672, 0), (2872049664, 5767168, 28835840, 0), (2895118336, 5767168, 34603008, 0), (2900885504, 5767168, 40370176, 0), (2889351168, 5767168, 46137344, 0), (2929721344, 5767168, 51904512, 0), (2935488512, 5767168, 57671680, 0), (2923954176, 5767168, 63438848, 0), (2947022848, 5767168, 69206016, 0), (2952790016, 5767168, 74973184, 0), (2941255680, 5767168, 80740352, 0), (2964324352, 5767168, 86507520, 0), (2970091520, 5767168, 92274688, 0), (2958557184, 5767168, 98041856, 0), (2981625856, 5767168, 103809024, 0), (2987393024, 5767168, 109576192, 0), (2975858688, 5767168, 115343360, 0), (3033530368, 5767168, 121110528, 0), (3039297536, 5767168, 126877696, 0), (3027763200, 5767168, 132644864, 0), (3120037888, 5767168, 138412032, 0), (3125805056, 5767168, 144179200, 0), (3114270720, 5767168, 149946368, 0), (3137339392, 5767168, 155713536, 0), (3143106560, 5767168, 161480704, 0), (3131572224, 5767168, 167247872, 0), (3189243904, 5767168, 173015040, 0), (3195011072, 5767168, 178782208, 0), (3183476736, 5767168, 184549376, 0), (3223846912, 5767168, 190316544, 0), (3229614080, 5767168, 196083712, 0), (3218079744, 5767168, 201850880, 0), (3241148416, 5767168, 207618048, 0), (3246915584, 5767168, 213385216, 0), (3235381248, 5767168, 219152384, 0), (3258449920, 5767168, 224919552, 0), (3264217088, 5767168, 230686720, 0), (3252682752, 5767168, 236453888, 0), (3275751424, 5767168, 242221056, 0), (3281518592, 5767168, 247988224, 0), (3269984256, 5767168, 253755392, 0), (3344957440, 5767168, 259522560, 0), (3350724608, 5767168, 265289728, 0), (3339190272, 5767168, 271056896, 0), (3362258944, 5767168, 276824064, 0), (3368026112, 5767168, 282591232, 0), (3356491776, 5767168, 288358400, 0), (3379560448, 5767168, 294125568, 0), (3385327616, 5767168, 299892736, 0), (3373793280, 5767168, 305659904, 0), (3414163456, 5767168, 311427072, 0), (3419930624, 5767168, 317194240, 0), (3408396288, 5767168, 322961408, 0), (3431464960, 5767168, 328728576, 0), (3437232128, 5767168, 334495744, 0), (3425697792, 5767168, 340262912, 0), (3448766464, 5767168, 346030080, 0), (3454533632, 5767168, 351797248, 0), (3442999296, 5767168, 357564416, 0), (3517972480, 5767168, 363331584, 0), (3523739648, 5767168, 369098752, 0), (3512205312, 5767168, 374865920, 0), (3604480000, 5767168, 380633088, 0), (3610247168, 5767168, 386400256, 0), (3598712832, 5767168, 392167424, 0), (3621781504, 5767168, 397934592, 0), (3627548672, 5767168, 403701760, 0), (3616014336, 5767168, 409468928, 0), (3656384512, 5767168, 415236096, 0), (3662151680, 5767168, 421003264, 0), (3650617344, 5767168, 426770432, 0), (3690987520, 5767168, 432537600, 0), (3696754688, 5767168, 438304768, 0), (3685220352, 5767168, 444071936, 0), (3794796544, 5767168, 449839104, 0), (3800563712, 5767168, 455606272, 0), (3789029376, 5767168, 461373440, 0), (3829399552, 5767168, 467140608, 0), (3835166720, 5767168, 472907776, 0), (3823632384, 5767168, 478674944, 0), (3864002560, 5767168, 484442112, 0), (3869769728, 5767168, 490209280, 0), (3858235392, 5767168, 495976448, 0), (3881304064, 5767168, 501743616, 0), (3887071232, 5767168, 507510784, 0), (3875536896, 5767168, 513277952, 0), (3933208576, 5767168, 519045120, 0), (3938975744, 5767168, 524812288, 0), (3927441408, 5767168, 530579456, 0), (3950510080, 5767168, 536346624, 0), (3956277248, 5767168, 542113792, 0), (3944742912, 5767168, 547880960, 0)], 2: [(2912419840, 5767168, 0, 0), (2918187008, 5767168, 5767168, 0), (2906652672, 5767168, 11534336, 0), (2998927360, 5767168, 17301504, 0), (3004694528, 5767168, 23068672, 0), (2993160192, 5767168, 28835840, 0), (3016228864, 5767168, 34603008, 0), (3021996032, 5767168, 40370176, 0), (3010461696, 5767168, 46137344, 0), (3050831872, 5767168, 51904512, 0), (3056599040, 5767168, 57671680, 0), (3045064704, 5767168, 63438848, 0), (3068133376, 5767168, 69206016, 0), (3073900544, 5767168, 74973184, 0), (3062366208, 5767168, 80740352, 0), (3085434880, 5767168, 86507520, 0), (3091202048, 5767168, 92274688, 0), (3079667712, 5767168, 98041856, 0), (3102736384, 5767168, 103809024, 0), (3108503552, 5767168, 109576192, 0), (3096969216, 5767168, 115343360, 0), (3154640896, 5767168, 121110528, 0), (3160408064, 5767168, 126877696, 0), (3148873728, 5767168, 132644864, 0), (3171942400, 5767168, 138412032, 0), (3177709568, 5767168, 144179200, 0), (3166175232, 5767168, 149946368, 0), (3206545408, 5767168, 155713536, 0), (3212312576, 5767168, 161480704, 0), (3200778240, 5767168, 167247872, 0), (3293052928, 5767168, 173015040, 0), (3298820096, 5767168, 178782208, 0), (3287285760, 5767168, 184549376, 0), (3310354432, 5767168, 190316544, 0), (3316121600, 5767168, 196083712, 0), (3304587264, 5767168, 201850880, 0), (3327655936, 5767168, 207618048, 0), (3333423104, 5767168, 213385216, 0), (3321888768, 5767168, 219152384, 0), (3396861952, 5767168, 224919552, 0), (3402629120, 5767168, 230686720, 0), (3391094784, 5767168, 236453888, 0), (3466067968, 5767168, 242221056, 0), (3471835136, 5767168, 247988224, 0), (3460300800, 5767168, 253755392, 0), (3483369472, 5767168, 259522560, 0), (3489136640, 5767168, 265289728, 0), (3477602304, 5767168, 271056896, 0), (3500670976, 5767168, 276824064, 0), (3506438144, 5767168, 282591232, 0), (3494903808, 5767168, 288358400, 0), (3535273984, 5767168, 294125568, 0), (3541041152, 5767168, 299892736, 0), (3529506816, 5767168, 305659904, 0), (3552575488, 5767168, 311427072, 0), (3558342656, 5767168, 317194240, 0), (3546808320, 5767168, 322961408, 0), (3569876992, 5767168, 328728576, 0), (3575644160, 5767168, 334495744, 0), (3564109824, 5767168, 340262912, 0), (3587178496, 5767168, 346030080, 0), (3592945664, 5767168, 351797248, 0), (3581411328, 5767168, 357564416, 0), (3639083008, 5767168, 363331584, 0), (3644850176, 5767168, 369098752, 0), (3633315840, 5767168, 374865920, 0), (3673686016, 5767168, 380633088, 0), (3679453184, 5767168, 386400256, 0), (3667918848, 5767168, 392167424, 0), (3708289024, 5767168, 397934592, 0), (3714056192, 5767168, 403701760, 0), (3702521856, 5767168, 409468928, 0), (3725590528, 5767168, 415236096, 0), (3731357696, 5767168, 421003264, 0), (3719823360, 5767168, 426770432, 0), (3742892032, 5767168, 432537600, 0), (3748659200, 5767168, 438304768, 0), (3737124864, 5767168, 444071936, 0), (3760193536, 5767168, 449839104, 0), (3765960704, 5767168, 455606272, 0), (3754426368, 5767168, 461373440, 0), (3777495040, 5767168, 467140608, 0), (3783262208, 5767168, 472907776, 0), (3771727872, 5767168, 478674944, 0), (3812098048, 5767168, 484442112, 0), (3817865216, 5767168, 490209280, 0), (3806330880, 5767168, 495976448, 0), (3846701056, 5767168, 501743616, 0), (3852468224, 5767168, 507510784, 0), (3840933888, 5767168, 513277952, 0), (3898605568, 5767168, 519045120, 0), (3904372736, 5767168, 524812288, 0), (3892838400, 5767168, 530579456, 0), (3915907072, 5767168, 536346624, 0), (3921674240, 5767168, 542113792, 0), (3910139904, 5767168, 547880960, 0)]}cuda_memory_handles_device_map {1: <capsule object NULL at 0x7b0b8db08ff0>, 2: <capsule object NULL at 0x7b0b88bcfcf0>}
DEBUG 01-14 17:01:49.965130.965130 sllm_store_c.py:27] get device uuid map
DEBUG 01-14 17:01:49.965436.965436 sllm_store_c.py:29] call client load into gpu
DEBUG 01-14 17:01:49.965854.965854 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 7c350190-196b-40fa-998c-faeccaf45295
DEBUG 01-14 17:01:49.966883.966883 client.py:106] call stub.LoadModelAsync
INFO 01-14 17:01:49.969151.969151 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 7c350190-196b-40fa-998c-faeccaf45295
DEBUG 01-14 17:01:49.969109.969109 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu_multi_device cost 0.007039070129394531 seconds
DEBUG 01-14 17:01:49.969590.969590 cuda_h.py:10] start restore2model
DEBUG 01-14 17:01:49.974002.974002 cuda_h.py:19] end restore2model cost 0.0043337345123291016 seconds
DEBUG 01-14 17:01:49.974099.974099 cuda_h.py:10] start experts_func_mgpu_group_pad
DEBUG 01-14 17:01:49.976150.976150 cuda_h.py:19] end experts_func_mgpu_group_pad cost 0.0014786720275878906 seconds
DEBUG 01-14 17:01:49.976219.976219 cuda_h.py:10] start experts_func_mgpu_group_pad
DEBUG 01-14 17:01:49.977910.977910 cuda_h.py:19] end experts_func_mgpu_group_pad cost 0.0015940666198730469 seconds
DEBUG 01-14 17:01:49.977713.977713 cuda_h.py:10] start gpu_group_list
DEBUG 01-14 17:01:49.978937.978937 cuda_h.py:19] end gpu_group_list cost 0.0003101825714111328 seconds
DEBUG 01-14 17:01:49.978821.978821 cuda_h.py:10] start gpu_group_list
DEBUG 01-14 17:01:49.978156.978156 cuda_h.py:19] end gpu_group_list cost 0.0002887248992919922 seconds
INFO 01-14 17:01:49.980559.980559 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 7c350190-196b-40fa-998c-faeccaf45295
INFO 01-14 17:01:50.033354.033354 client.py:127] Model loaded
DEBUG 01-14 17:01:50.034743.034743 cuda_h.py:19] end task_processing_mp_load cost 0.07154989242553711 seconds
DEBUG 01-14 17:01:50.034759.034759 cuda_h.py:10] start exec_together
DEBUG 01-14 17:01:50.046902.046902 mlpmodule.py:1053] mgpu group einsum cost 0.0008437633514404297 s
DEBUG 01-14 17:01:50.053264.053264 mlpmodule.py:1109] mgpu experts func einsum cost 0.01872396469116211 s
DEBUG 01-14 17:01:50.053089.053089 cuda_h.py:19] end exec_together cost 0.01888895034790039 seconds
DEBUG 01-14 17:01:50.053528.053528 cuda_h.py:10] start exec_one_by_one
DEBUG 01-14 17:01:50.053231.053231 mlpmodule.py:1178] gpu group tensors cost 0.0005645751953125 s
DEBUG 01-14 17:01:50.055745.055745 mlpmodule.py:1220] gpu pad cost 0.0018296241760253906 s
DEBUG 01-14 17:01:50.055727.055727 mlpmodule.py:1226] start_w1
DEBUG 01-14 17:01:50.055057.055057 mlpmodule.py:1230] start_w3
DEBUG 01-14 17:01:50.056346.056346 mlpmodule.py:1236] start_w2
DEBUG 01-14 17:01:50.056456.056456 mlpmodule.py:1239] gpu group einsum cost 0.00043201446533203125 s
DEBUG 01-14 17:01:50.058713.058713 mlpmodule.py:1316] gpu experts func einsum cost 0.005065202713012695 s
DEBUG 01-14 17:01:50.058603.058603 mlpmodule.py:1178] gpu group tensors cost 0.00039505958557128906 s
DEBUG 01-14 17:01:50.060887.060887 mlpmodule.py:1220] gpu pad cost 0.0017046928405761719 s
DEBUG 01-14 17:01:50.060823.060823 mlpmodule.py:1226] start_w1
DEBUG 01-14 17:01:50.060425.060425 mlpmodule.py:1230] start_w3
DEBUG 01-14 17:01:50.060775.060775 mlpmodule.py:1236] start_w2
DEBUG 01-14 17:01:50.061229.061229 mlpmodule.py:1239] gpu group einsum cost 0.00047469139099121094 s
DEBUG 01-14 17:01:50.063994.063994 mlpmodule.py:1316] gpu experts func einsum cost 0.005140781402587891 s
DEBUG 01-14 17:01:50.063149.063149 cuda_h.py:19] end exec_one_by_one cost 0.010394811630249023 seconds
DEBUG 01-14 17:01:50.063044.063044 cuda_h.py:10] start exec_one_by_one_end_new
DEBUG 01-14 17:01:50.063800.063800 cuda_h.py:10] start gpu_group_tensor
DEBUG 01-14 17:01:50.063645.063645 cuda_h.py:19] end gpu_group_tensor cost 0.00010585784912109375 seconds
DEBUG 01-14 17:01:50.063322.063322 cuda_h.py:10] start gpu_group_tensor
DEBUG 01-14 17:01:50.063061.063061 cuda_h.py:19] end gpu_group_tensor cost 9.560585021972656e-05 seconds
DEBUG 01-14 17:01:50.064932.064932 cuda_h.py:10] start gpu_group_einsum
DEBUG 01-14 17:01:50.064167.064167 cuda_h.py:19] end gpu_group_einsum cost 0.00027489662170410156 seconds
DEBUG 01-14 17:01:50.064096.064096 cuda_h.py:10] start gpu_final_hidden_states_scatter
DEBUG 01-14 17:01:50.064247.064247 cuda_h.py:10] start all_expert_weight_slices
DEBUG 01-14 17:01:50.065039.065039 cuda_h.py:19] end all_expert_weight_slices cost 0.0006926059722900391 seconds
DEBUG 01-14 17:01:50.065901.065901 cuda_h.py:10] start all_expert_output_slices
DEBUG 01-14 17:01:50.065451.065451 cuda_h.py:19] end all_expert_output_slices cost 0.00016546249389648438 seconds
DEBUG 01-14 17:01:50.065485.065485 cuda_h.py:10] start concat_expert_out
DEBUG 01-14 17:01:50.065106.065106 cuda_h.py:19] end concat_expert_out cost 0.00011706352233886719 seconds
DEBUG 01-14 17:01:50.065842.065842 cuda_h.py:10] start index_scatter
DEBUG 01-14 17:01:50.065275.065275 cuda_h.py:19] end index_scatter cost 4.1961669921875e-05 seconds
DEBUG 01-14 17:01:50.065554.065554 cuda_h.py:19] end gpu_final_hidden_states_scatter cost 0.0013849735260009766 seconds
DEBUG 01-14 17:01:50.065247.065247 cuda_h.py:10] start gpu_group_einsum
DEBUG 01-14 17:01:50.066497.066497 cuda_h.py:19] end gpu_group_einsum cost 0.00027871131896972656 seconds
DEBUG 01-14 17:01:50.066366.066366 cuda_h.py:10] start gpu_final_hidden_states_scatter
DEBUG 01-14 17:01:50.066286.066286 cuda_h.py:10] start all_expert_weight_slices
DEBUG 01-14 17:01:50.067920.067920 cuda_h.py:19] end all_expert_weight_slices cost 0.0007119178771972656 seconds
DEBUG 01-14 17:01:50.067352.067352 cuda_h.py:10] start all_expert_output_slices
DEBUG 01-14 17:01:50.067836.067836 cuda_h.py:19] end all_expert_output_slices cost 0.0001876354217529297 seconds
DEBUG 01-14 17:01:50.067870.067870 cuda_h.py:10] start concat_expert_out
DEBUG 01-14 17:01:50.067656.067656 cuda_h.py:19] end concat_expert_out cost 9.679794311523438e-05 seconds
DEBUG 01-14 17:01:50.067300.067300 cuda_h.py:10] start index_scatter
DEBUG 01-14 17:01:50.067971.067971 cuda_h.py:19] end index_scatter cost 4.291534423828125e-05 seconds
DEBUG 01-14 17:01:50.067579.067579 cuda_h.py:19] end gpu_final_hidden_states_scatter cost 0.001600027084350586 seconds
DEBUG 01-14 17:01:50.068278.068278 cuda_h.py:19] end exec_one_by_one_end_new cost 0.004397869110107422 seconds
DEBUG 01-14 17:01:50.068696.068696 cuda_h.py:10] start exec_one_by_one_end_new2
DEBUG 01-14 17:01:50.068836.068836 cuda_h.py:10] start gpu_group_einsum_mp_multi_list
DEBUG 01-14 17:01:50.068055.068055 cuda_h.py:10] start gpu_group_tensor
DEBUG 01-14 17:01:50.068993.068993 cuda_h.py:19] end gpu_group_tensor cost 0.00010633468627929688 seconds
DEBUG 01-14 17:01:50.068273.068273 cuda_h.py:10] start gpu_group_tensor
DEBUG 01-14 17:01:50.068178.068178 cuda_h.py:19] end gpu_group_tensor cost 0.00010132789611816406 seconds
DEBUG 01-14 17:01:50.068088.068088 cuda_h.py:10] start gpu_group_einsum
DEBUG 01-14 17:01:50.068490.068490 cuda_h.py:19] end gpu_group_einsum cost 0.0002903938293457031 seconds
DEBUG 01-14 17:01:50.068188.068188 cuda_h.py:10] start gpu_group_einsum
DEBUG 01-14 17:01:50.069312.069312 cuda_h.py:19] end gpu_group_einsum cost 0.00029206275939941406 seconds
DEBUG 01-14 17:01:50.069249.069249 cuda_h.py:10] start gpu_final_hidden_states_scatter
DEBUG 01-14 17:01:50.069874.069874 cuda_h.py:10] start all_expert_outputs_slices
DEBUG 01-14 17:01:50.069167.069167 cuda_h.py:19] end all_expert_outputs_slices cost 0.000217437744140625 seconds
DEBUG 01-14 17:01:50.069777.069777 cuda_h.py:10] start concat_expert_out
DEBUG 01-14 17:01:50.069886.069886 cuda_h.py:19] end concat_expert_out cost 5.340576171875e-05 seconds
DEBUG 01-14 17:01:50.069053.069053 cuda_h.py:10] start index_scatter
DEBUG 01-14 17:01:50.069063.069063 cuda_h.py:19] end index_scatter cost 4.601478576660156e-05 seconds
DEBUG 01-14 17:01:50.070777.070777 cuda_h.py:19] end gpu_final_hidden_states_scatter cost 0.0006995201110839844 seconds
DEBUG 01-14 17:01:50.070309.070309 cuda_h.py:10] start gpu_final_hidden_states_scatter
DEBUG 01-14 17:01:50.070616.070616 cuda_h.py:10] start all_expert_outputs_slices
DEBUG 01-14 17:01:50.070682.070682 cuda_h.py:19] end all_expert_outputs_slices cost 0.0001633167266845703 seconds
DEBUG 01-14 17:01:50.070954.070954 cuda_h.py:10] start concat_expert_out
DEBUG 01-14 17:01:50.070149.070149 cuda_h.py:19] end concat_expert_out cost 4.792213439941406e-05 seconds
DEBUG 01-14 17:01:50.070455.070455 cuda_h.py:10] start index_scatter
DEBUG 01-14 17:01:50.070034.070034 cuda_h.py:19] end index_scatter cost 4.458427429199219e-05 seconds
DEBUG 01-14 17:01:50.070505.070505 cuda_h.py:19] end gpu_final_hidden_states_scatter cost 0.00046372413635253906 seconds
DEBUG 01-14 17:01:50.070341.070341 cuda_h.py:19] end exec_one_by_one_end_new2 cost 0.002631664276123047 seconds
DEBUG 01-14 17:01:50.073292.073292 cuda_h.py:10] start task_processing_mp_load
DEBUG 01-14 17:01:50.073276.073276 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu_multi_device
DEBUG 01-14 17:01:50.075686.075686 cuda_memory_view.py:520] tensor_device_offsets_device_map {1: {'model.layers.1.mlp.experts.0.gate_proj.weight': 0, 'model.layers.1.mlp.experts.0.down_proj.weight': 5767168, 'model.layers.1.mlp.experts.0.up_proj.weight': 11534336, 'model.layers.1.mlp.experts.1.gate_proj.weight': 17301504, 'model.layers.1.mlp.experts.1.down_proj.weight': 23068672, 'model.layers.1.mlp.experts.1.up_proj.weight': 28835840, 'model.layers.1.mlp.experts.2.gate_proj.weight': 34603008, 'model.layers.1.mlp.experts.2.down_proj.weight': 40370176, 'model.layers.1.mlp.experts.2.up_proj.weight': 46137344, 'model.layers.1.mlp.experts.4.gate_proj.weight': 51904512, 'model.layers.1.mlp.experts.4.down_proj.weight': 57671680, 'model.layers.1.mlp.experts.4.up_proj.weight': 63438848, 'model.layers.1.mlp.experts.5.gate_proj.weight': 69206016, 'model.layers.1.mlp.experts.5.down_proj.weight': 74973184, 'model.layers.1.mlp.experts.5.up_proj.weight': 80740352, 'model.layers.1.mlp.experts.6.gate_proj.weight': 86507520, 'model.layers.1.mlp.experts.6.down_proj.weight': 92274688, 'model.layers.1.mlp.experts.6.up_proj.weight': 98041856, 'model.layers.1.mlp.experts.7.gate_proj.weight': 103809024, 'model.layers.1.mlp.experts.7.down_proj.weight': 109576192, 'model.layers.1.mlp.experts.7.up_proj.weight': 115343360, 'model.layers.1.mlp.experts.10.gate_proj.weight': 121110528, 'model.layers.1.mlp.experts.10.down_proj.weight': 126877696, 'model.layers.1.mlp.experts.10.up_proj.weight': 132644864, 'model.layers.1.mlp.experts.15.gate_proj.weight': 138412032, 'model.layers.1.mlp.experts.15.down_proj.weight': 144179200, 'model.layers.1.mlp.experts.15.up_proj.weight': 149946368, 'model.layers.1.mlp.experts.16.gate_proj.weight': 155713536, 'model.layers.1.mlp.experts.16.down_proj.weight': 161480704, 'model.layers.1.mlp.experts.16.up_proj.weight': 167247872, 'model.layers.1.mlp.experts.19.gate_proj.weight': 173015040, 'model.layers.1.mlp.experts.19.down_proj.weight': 178782208, 'model.layers.1.mlp.experts.19.up_proj.weight': 184549376, 'model.layers.1.mlp.experts.21.gate_proj.weight': 190316544, 'model.layers.1.mlp.experts.21.down_proj.weight': 196083712, 'model.layers.1.mlp.experts.21.up_proj.weight': 201850880, 'model.layers.1.mlp.experts.22.gate_proj.weight': 207618048, 'model.layers.1.mlp.experts.22.down_proj.weight': 213385216, 'model.layers.1.mlp.experts.22.up_proj.weight': 219152384, 'model.layers.1.mlp.experts.23.gate_proj.weight': 224919552, 'model.layers.1.mlp.experts.23.down_proj.weight': 230686720, 'model.layers.1.mlp.experts.23.up_proj.weight': 236453888, 'model.layers.1.mlp.experts.24.gate_proj.weight': 242221056, 'model.layers.1.mlp.experts.24.down_proj.weight': 247988224, 'model.layers.1.mlp.experts.24.up_proj.weight': 253755392, 'model.layers.1.mlp.experts.28.gate_proj.weight': 259522560, 'model.layers.1.mlp.experts.28.down_proj.weight': 265289728, 'model.layers.1.mlp.experts.28.up_proj.weight': 271056896, 'model.layers.1.mlp.experts.29.gate_proj.weight': 276824064, 'model.layers.1.mlp.experts.29.down_proj.weight': 282591232, 'model.layers.1.mlp.experts.29.up_proj.weight': 288358400, 'model.layers.1.mlp.experts.30.gate_proj.weight': 294125568, 'model.layers.1.mlp.experts.30.down_proj.weight': 299892736, 'model.layers.1.mlp.experts.30.up_proj.weight': 305659904, 'model.layers.1.mlp.experts.32.gate_proj.weight': 311427072, 'model.layers.1.mlp.experts.32.down_proj.weight': 317194240, 'model.layers.1.mlp.experts.32.up_proj.weight': 322961408, 'model.layers.1.mlp.experts.33.gate_proj.weight': 328728576, 'model.layers.1.mlp.experts.33.down_proj.weight': 334495744, 'model.layers.1.mlp.experts.33.up_proj.weight': 340262912, 'model.layers.1.mlp.experts.34.gate_proj.weight': 346030080, 'model.layers.1.mlp.experts.34.down_proj.weight': 351797248, 'model.layers.1.mlp.experts.34.up_proj.weight': 357564416, 'model.layers.1.mlp.experts.38.gate_proj.weight': 363331584, 'model.layers.1.mlp.experts.38.down_proj.weight': 369098752, 'model.layers.1.mlp.experts.38.up_proj.weight': 374865920, 'model.layers.1.mlp.experts.43.gate_proj.weight': 380633088, 'model.layers.1.mlp.experts.43.down_proj.weight': 386400256, 'model.layers.1.mlp.experts.43.up_proj.weight': 392167424, 'model.layers.1.mlp.experts.44.gate_proj.weight': 397934592, 'model.layers.1.mlp.experts.44.down_proj.weight': 403701760, 'model.layers.1.mlp.experts.44.up_proj.weight': 409468928, 'model.layers.1.mlp.experts.46.gate_proj.weight': 415236096, 'model.layers.1.mlp.experts.46.down_proj.weight': 421003264, 'model.layers.1.mlp.experts.46.up_proj.weight': 426770432, 'model.layers.1.mlp.experts.48.gate_proj.weight': 432537600, 'model.layers.1.mlp.experts.48.down_proj.weight': 438304768, 'model.layers.1.mlp.experts.48.up_proj.weight': 444071936, 'model.layers.1.mlp.experts.54.gate_proj.weight': 449839104, 'model.layers.1.mlp.experts.54.down_proj.weight': 455606272, 'model.layers.1.mlp.experts.54.up_proj.weight': 461373440, 'model.layers.1.mlp.experts.56.gate_proj.weight': 467140608, 'model.layers.1.mlp.experts.56.down_proj.weight': 472907776, 'model.layers.1.mlp.experts.56.up_proj.weight': 478674944, 'model.layers.1.mlp.experts.58.gate_proj.weight': 484442112, 'model.layers.1.mlp.experts.58.down_proj.weight': 490209280, 'model.layers.1.mlp.experts.58.up_proj.weight': 495976448, 'model.layers.1.mlp.experts.59.gate_proj.weight': 501743616, 'model.layers.1.mlp.experts.59.down_proj.weight': 507510784, 'model.layers.1.mlp.experts.59.up_proj.weight': 513277952, 'model.layers.1.mlp.experts.62.gate_proj.weight': 519045120, 'model.layers.1.mlp.experts.62.down_proj.weight': 524812288, 'model.layers.1.mlp.experts.62.up_proj.weight': 530579456, 'model.layers.1.mlp.experts.63.gate_proj.weight': 536346624, 'model.layers.1.mlp.experts.63.down_proj.weight': 542113792, 'model.layers.1.mlp.experts.63.up_proj.weight': 547880960}, 2: {'model.layers.1.mlp.experts.3.gate_proj.weight': 0, 'model.layers.1.mlp.experts.3.down_proj.weight': 5767168, 'model.layers.1.mlp.experts.3.up_proj.weight': 11534336, 'model.layers.1.mlp.experts.8.gate_proj.weight': 17301504, 'model.layers.1.mlp.experts.8.down_proj.weight': 23068672, 'model.layers.1.mlp.experts.8.up_proj.weight': 28835840, 'model.layers.1.mlp.experts.9.gate_proj.weight': 34603008, 'model.layers.1.mlp.experts.9.down_proj.weight': 40370176, 'model.layers.1.mlp.experts.9.up_proj.weight': 46137344, 'model.layers.1.mlp.experts.11.gate_proj.weight': 51904512, 'model.layers.1.mlp.experts.11.down_proj.weight': 57671680, 'model.layers.1.mlp.experts.11.up_proj.weight': 63438848, 'model.layers.1.mlp.experts.12.gate_proj.weight': 69206016, 'model.layers.1.mlp.experts.12.down_proj.weight': 74973184, 'model.layers.1.mlp.experts.12.up_proj.weight': 80740352, 'model.layers.1.mlp.experts.13.gate_proj.weight': 86507520, 'model.layers.1.mlp.experts.13.down_proj.weight': 92274688, 'model.layers.1.mlp.experts.13.up_proj.weight': 98041856, 'model.layers.1.mlp.experts.14.gate_proj.weight': 103809024, 'model.layers.1.mlp.experts.14.down_proj.weight': 109576192, 'model.layers.1.mlp.experts.14.up_proj.weight': 115343360, 'model.layers.1.mlp.experts.17.gate_proj.weight': 121110528, 'model.layers.1.mlp.experts.17.down_proj.weight': 126877696, 'model.layers.1.mlp.experts.17.up_proj.weight': 132644864, 'model.layers.1.mlp.experts.18.gate_proj.weight': 138412032, 'model.layers.1.mlp.experts.18.down_proj.weight': 144179200, 'model.layers.1.mlp.experts.18.up_proj.weight': 149946368, 'model.layers.1.mlp.experts.20.gate_proj.weight': 155713536, 'model.layers.1.mlp.experts.20.down_proj.weight': 161480704, 'model.layers.1.mlp.experts.20.up_proj.weight': 167247872, 'model.layers.1.mlp.experts.25.gate_proj.weight': 173015040, 'model.layers.1.mlp.experts.25.down_proj.weight': 178782208, 'model.layers.1.mlp.experts.25.up_proj.weight': 184549376, 'model.layers.1.mlp.experts.26.gate_proj.weight': 190316544, 'model.layers.1.mlp.experts.26.down_proj.weight': 196083712, 'model.layers.1.mlp.experts.26.up_proj.weight': 201850880, 'model.layers.1.mlp.experts.27.gate_proj.weight': 207618048, 'model.layers.1.mlp.experts.27.down_proj.weight': 213385216, 'model.layers.1.mlp.experts.27.up_proj.weight': 219152384, 'model.layers.1.mlp.experts.31.gate_proj.weight': 224919552, 'model.layers.1.mlp.experts.31.down_proj.weight': 230686720, 'model.layers.1.mlp.experts.31.up_proj.weight': 236453888, 'model.layers.1.mlp.experts.35.gate_proj.weight': 242221056, 'model.layers.1.mlp.experts.35.down_proj.weight': 247988224, 'model.layers.1.mlp.experts.35.up_proj.weight': 253755392, 'model.layers.1.mlp.experts.36.gate_proj.weight': 259522560, 'model.layers.1.mlp.experts.36.down_proj.weight': 265289728, 'model.layers.1.mlp.experts.36.up_proj.weight': 271056896, 'model.layers.1.mlp.experts.37.gate_proj.weight': 276824064, 'model.layers.1.mlp.experts.37.down_proj.weight': 282591232, 'model.layers.1.mlp.experts.37.up_proj.weight': 288358400, 'model.layers.1.mlp.experts.39.gate_proj.weight': 294125568, 'model.layers.1.mlp.experts.39.down_proj.weight': 299892736, 'model.layers.1.mlp.experts.39.up_proj.weight': 305659904, 'model.layers.1.mlp.experts.40.gate_proj.weight': 311427072, 'model.layers.1.mlp.experts.40.down_proj.weight': 317194240, 'model.layers.1.mlp.experts.40.up_proj.weight': 322961408, 'model.layers.1.mlp.experts.41.gate_proj.weight': 328728576, 'model.layers.1.mlp.experts.41.down_proj.weight': 334495744, 'model.layers.1.mlp.experts.41.up_proj.weight': 340262912, 'model.layers.1.mlp.experts.42.gate_proj.weight': 346030080, 'model.layers.1.mlp.experts.42.down_proj.weight': 351797248, 'model.layers.1.mlp.experts.42.up_proj.weight': 357564416, 'model.layers.1.mlp.experts.45.gate_proj.weight': 363331584, 'model.layers.1.mlp.experts.45.down_proj.weight': 369098752, 'model.layers.1.mlp.experts.45.up_proj.weight': 374865920, 'model.layers.1.mlp.experts.47.gate_proj.weight': 380633088, 'model.layers.1.mlp.experts.47.down_proj.weight': 386400256, 'model.layers.1.mlp.experts.47.up_proj.weight': 392167424, 'model.layers.1.mlp.experts.49.gate_proj.weight': 397934592, 'model.layers.1.mlp.experts.49.down_proj.weight': 403701760, 'model.layers.1.mlp.experts.49.up_proj.weight': 409468928, 'model.layers.1.mlp.experts.50.gate_proj.weight': 415236096, 'model.layers.1.mlp.experts.50.down_proj.weight': 421003264, 'model.layers.1.mlp.experts.50.up_proj.weight': 426770432, 'model.layers.1.mlp.experts.51.gate_proj.weight': 432537600, 'model.layers.1.mlp.experts.51.down_proj.weight': 438304768, 'model.layers.1.mlp.experts.51.up_proj.weight': 444071936, 'model.layers.1.mlp.experts.52.gate_proj.weight': 449839104, 'model.layers.1.mlp.experts.52.down_proj.weight': 455606272, 'model.layers.1.mlp.experts.52.up_proj.weight': 461373440, 'model.layers.1.mlp.experts.53.gate_proj.weight': 467140608, 'model.layers.1.mlp.experts.53.down_proj.weight': 472907776, 'model.layers.1.mlp.experts.53.up_proj.weight': 478674944, 'model.layers.1.mlp.experts.55.gate_proj.weight': 484442112, 'model.layers.1.mlp.experts.55.down_proj.weight': 490209280, 'model.layers.1.mlp.experts.55.up_proj.weight': 495976448, 'model.layers.1.mlp.experts.57.gate_proj.weight': 501743616, 'model.layers.1.mlp.experts.57.down_proj.weight': 507510784, 'model.layers.1.mlp.experts.57.up_proj.weight': 513277952, 'model.layers.1.mlp.experts.60.gate_proj.weight': 519045120, 'model.layers.1.mlp.experts.60.down_proj.weight': 524812288, 'model.layers.1.mlp.experts.60.up_proj.weight': 530579456, 'model.layers.1.mlp.experts.61.gate_proj.weight': 536346624, 'model.layers.1.mlp.experts.61.down_proj.weight': 542113792, 'model.layers.1.mlp.experts.61.up_proj.weight': 547880960}}tensor_copy_chunks_device_map {1: [(2860515328, 5767168, 0, 0), (2866282496, 5767168, 5767168, 0), (2854748160, 5767168, 11534336, 0), (2877816832, 5767168, 17301504, 0), (2883584000, 5767168, 23068672, 0), (2872049664, 5767168, 28835840, 0), (2895118336, 5767168, 34603008, 0), (2900885504, 5767168, 40370176, 0), (2889351168, 5767168, 46137344, 0), (2929721344, 5767168, 51904512, 0), (2935488512, 5767168, 57671680, 0), (2923954176, 5767168, 63438848, 0), (2947022848, 5767168, 69206016, 0), (2952790016, 5767168, 74973184, 0), (2941255680, 5767168, 80740352, 0), (2964324352, 5767168, 86507520, 0), (2970091520, 5767168, 92274688, 0), (2958557184, 5767168, 98041856, 0), (2981625856, 5767168, 103809024, 0), (2987393024, 5767168, 109576192, 0), (2975858688, 5767168, 115343360, 0), (3033530368, 5767168, 121110528, 0), (3039297536, 5767168, 126877696, 0), (3027763200, 5767168, 132644864, 0), (3120037888, 5767168, 138412032, 0), (3125805056, 5767168, 144179200, 0), (3114270720, 5767168, 149946368, 0), (3137339392, 5767168, 155713536, 0), (3143106560, 5767168, 161480704, 0), (3131572224, 5767168, 167247872, 0), (3189243904, 5767168, 173015040, 0), (3195011072, 5767168, 178782208, 0), (3183476736, 5767168, 184549376, 0), (3223846912, 5767168, 190316544, 0), (3229614080, 5767168, 196083712, 0), (3218079744, 5767168, 201850880, 0), (3241148416, 5767168, 207618048, 0), (3246915584, 5767168, 213385216, 0), (3235381248, 5767168, 219152384, 0), (3258449920, 5767168, 224919552, 0), (3264217088, 5767168, 230686720, 0), (3252682752, 5767168, 236453888, 0), (3275751424, 5767168, 242221056, 0), (3281518592, 5767168, 247988224, 0), (3269984256, 5767168, 253755392, 0), (3344957440, 5767168, 259522560, 0), (3350724608, 5767168, 265289728, 0), (3339190272, 5767168, 271056896, 0), (3362258944, 5767168, 276824064, 0), (3368026112, 5767168, 282591232, 0), (3356491776, 5767168, 288358400, 0), (3379560448, 5767168, 294125568, 0), (3385327616, 5767168, 299892736, 0), (3373793280, 5767168, 305659904, 0), (3414163456, 5767168, 311427072, 0), (3419930624, 5767168, 317194240, 0), (3408396288, 5767168, 322961408, 0), (3431464960, 5767168, 328728576, 0), (3437232128, 5767168, 334495744, 0), (3425697792, 5767168, 340262912, 0), (3448766464, 5767168, 346030080, 0), (3454533632, 5767168, 351797248, 0), (3442999296, 5767168, 357564416, 0), (3517972480, 5767168, 363331584, 0), (3523739648, 5767168, 369098752, 0), (3512205312, 5767168, 374865920, 0), (3604480000, 5767168, 380633088, 0), (3610247168, 5767168, 386400256, 0), (3598712832, 5767168, 392167424, 0), (3621781504, 5767168, 397934592, 0), (3627548672, 5767168, 403701760, 0), (3616014336, 5767168, 409468928, 0), (3656384512, 5767168, 415236096, 0), (3662151680, 5767168, 421003264, 0), (3650617344, 5767168, 426770432, 0), (3690987520, 5767168, 432537600, 0), (3696754688, 5767168, 438304768, 0), (3685220352, 5767168, 444071936, 0), (3794796544, 5767168, 449839104, 0), (3800563712, 5767168, 455606272, 0), (3789029376, 5767168, 461373440, 0), (3829399552, 5767168, 467140608, 0), (3835166720, 5767168, 472907776, 0), (3823632384, 5767168, 478674944, 0), (3864002560, 5767168, 484442112, 0), (3869769728, 5767168, 490209280, 0), (3858235392, 5767168, 495976448, 0), (3881304064, 5767168, 501743616, 0), (3887071232, 5767168, 507510784, 0), (3875536896, 5767168, 513277952, 0), (3933208576, 5767168, 519045120, 0), (3938975744, 5767168, 524812288, 0), (3927441408, 5767168, 530579456, 0), (3950510080, 5767168, 536346624, 0), (3956277248, 5767168, 542113792, 0), (3944742912, 5767168, 547880960, 0)], 2: [(2912419840, 5767168, 0, 0), (2918187008, 5767168, 5767168, 0), (2906652672, 5767168, 11534336, 0), (2998927360, 5767168, 17301504, 0), (3004694528, 5767168, 23068672, 0), (2993160192, 5767168, 28835840, 0), (3016228864, 5767168, 34603008, 0), (3021996032, 5767168, 40370176, 0), (3010461696, 5767168, 46137344, 0), (3050831872, 5767168, 51904512, 0), (3056599040, 5767168, 57671680, 0), (3045064704, 5767168, 63438848, 0), (3068133376, 5767168, 69206016, 0), (3073900544, 5767168, 74973184, 0), (3062366208, 5767168, 80740352, 0), (3085434880, 5767168, 86507520, 0), (3091202048, 5767168, 92274688, 0), (3079667712, 5767168, 98041856, 0), (3102736384, 5767168, 103809024, 0), (3108503552, 5767168, 109576192, 0), (3096969216, 5767168, 115343360, 0), (3154640896, 5767168, 121110528, 0), (3160408064, 5767168, 126877696, 0), (3148873728, 5767168, 132644864, 0), (3171942400, 5767168, 138412032, 0), (3177709568, 5767168, 144179200, 0), (3166175232, 5767168, 149946368, 0), (3206545408, 5767168, 155713536, 0), (3212312576, 5767168, 161480704, 0), (3200778240, 5767168, 167247872, 0), (3293052928, 5767168, 173015040, 0), (3298820096, 5767168, 178782208, 0), (3287285760, 5767168, 184549376, 0), (3310354432, 5767168, 190316544, 0), (3316121600, 5767168, 196083712, 0), (3304587264, 5767168, 201850880, 0), (3327655936, 5767168, 207618048, 0), (3333423104, 5767168, 213385216, 0), (3321888768, 5767168, 219152384, 0), (3396861952, 5767168, 224919552, 0), (3402629120, 5767168, 230686720, 0), (3391094784, 5767168, 236453888, 0), (3466067968, 5767168, 242221056, 0), (3471835136, 5767168, 247988224, 0), (3460300800, 5767168, 253755392, 0), (3483369472, 5767168, 259522560, 0), (3489136640, 5767168, 265289728, 0), (3477602304, 5767168, 271056896, 0), (3500670976, 5767168, 276824064, 0), (3506438144, 5767168, 282591232, 0), (3494903808, 5767168, 288358400, 0), (3535273984, 5767168, 294125568, 0), (3541041152, 5767168, 299892736, 0), (3529506816, 5767168, 305659904, 0), (3552575488, 5767168, 311427072, 0), (3558342656, 5767168, 317194240, 0), (3546808320, 5767168, 322961408, 0), (3569876992, 5767168, 328728576, 0), (3575644160, 5767168, 334495744, 0), (3564109824, 5767168, 340262912, 0), (3587178496, 5767168, 346030080, 0), (3592945664, 5767168, 351797248, 0), (3581411328, 5767168, 357564416, 0), (3639083008, 5767168, 363331584, 0), (3644850176, 5767168, 369098752, 0), (3633315840, 5767168, 374865920, 0), (3673686016, 5767168, 380633088, 0), (3679453184, 5767168, 386400256, 0), (3667918848, 5767168, 392167424, 0), (3708289024, 5767168, 397934592, 0), (3714056192, 5767168, 403701760, 0), (3702521856, 5767168, 409468928, 0), (3725590528, 5767168, 415236096, 0), (3731357696, 5767168, 421003264, 0), (3719823360, 5767168, 426770432, 0), (3742892032, 5767168, 432537600, 0), (3748659200, 5767168, 438304768, 0), (3737124864, 5767168, 444071936, 0), (3760193536, 5767168, 449839104, 0), (3765960704, 5767168, 455606272, 0), (3754426368, 5767168, 461373440, 0), (3777495040, 5767168, 467140608, 0), (3783262208, 5767168, 472907776, 0), (3771727872, 5767168, 478674944, 0), (3812098048, 5767168, 484442112, 0), (3817865216, 5767168, 490209280, 0), (3806330880, 5767168, 495976448, 0), (3846701056, 5767168, 501743616, 0), (3852468224, 5767168, 507510784, 0), (3840933888, 5767168, 513277952, 0), (3898605568, 5767168, 519045120, 0), (3904372736, 5767168, 524812288, 0), (3892838400, 5767168, 530579456, 0), (3915907072, 5767168, 536346624, 0), (3921674240, 5767168, 542113792, 0), (3910139904, 5767168, 547880960, 0)]}cuda_memory_handles_device_map {1: <capsule object NULL at 0x7b0b88bcfcf0>, 2: <capsule object NULL at 0x7b0b8db08ff0>}
DEBUG 01-14 17:01:50.075890.075890 sllm_store_c.py:27] get device uuid map
DEBUG 01-14 17:01:50.075143.075143 sllm_store_c.py:29] call client load into gpu
DEBUG 01-14 17:01:50.075700.075700 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 3cf03f26-608c-4a0e-8186-78c542954526
DEBUG 01-14 17:01:50.076178.076178 client.py:106] call stub.LoadModelAsync
INFO 01-14 17:01:50.078896.078896 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 3cf03f26-608c-4a0e-8186-78c542954526
DEBUG 01-14 17:01:50.079945.079945 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu_multi_device cost 0.005720853805541992 seconds
DEBUG 01-14 17:01:50.079513.079513 cuda_h.py:10] start restore2model
DEBUG 01-14 17:01:50.083461.083461 cuda_h.py:19] end restore2model cost 0.004134654998779297 seconds
DEBUG 01-14 17:01:50.083365.083365 cuda_h.py:10] start experts_func_mgpu_group_pad
DEBUG 01-14 17:01:50.085045.085045 cuda_h.py:19] end experts_func_mgpu_group_pad cost 0.0014638900756835938 seconds
DEBUG 01-14 17:01:50.085041.085041 cuda_h.py:10] start experts_func_mgpu_group_pad
DEBUG 01-14 17:01:50.087553.087553 cuda_h.py:19] end experts_func_mgpu_group_pad cost 0.0016021728515625 seconds
DEBUG 01-14 17:01:50.087993.087993 cuda_h.py:10] start gpu_group_list
DEBUG 01-14 17:01:50.087362.087362 cuda_h.py:19] end gpu_group_list cost 0.0003113746643066406 seconds
DEBUG 01-14 17:01:50.087709.087709 cuda_h.py:10] start gpu_group_list
DEBUG 01-14 17:01:50.087057.087057 cuda_h.py:19] end gpu_group_list cost 0.0002970695495605469 seconds
INFO 01-14 17:01:50.089268.089268 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 3cf03f26-608c-4a0e-8186-78c542954526
INFO 01-14 17:01:50.130829.130829 client.py:127] Model loaded
DEBUG 01-14 17:01:50.130131.130131 cuda_h.py:19] end task_processing_mp_load cost 0.05701613426208496 seconds
DEBUG 01-14 17:01:50.130742.130742 cuda_h.py:10] start exec_together
DEBUG 01-14 17:01:50.141451.141451 mlpmodule.py:1053] mgpu group einsum cost 0.0012035369873046875 s
DEBUG 01-14 17:01:50.148940.148940 mlpmodule.py:1109] mgpu experts func einsum cost 0.017678260803222656 s
DEBUG 01-14 17:01:50.148474.148474 cuda_h.py:19] end exec_together cost 0.017828941345214844 seconds
DEBUG 01-14 17:01:50.148614.148614 cuda_h.py:10] start exec_one_by_one
DEBUG 01-14 17:01:50.148093.148093 mlpmodule.py:1178] gpu group tensors cost 0.0004131793975830078 s
DEBUG 01-14 17:01:50.150410.150410 mlpmodule.py:1220] gpu pad cost 0.0015134811401367188 s
DEBUG 01-14 17:01:50.150107.150107 mlpmodule.py:1226] start_w1
DEBUG 01-14 17:01:50.150113.150113 mlpmodule.py:1230] start_w3
DEBUG 01-14 17:01:50.150748.150748 mlpmodule.py:1236] start_w2
DEBUG 01-14 17:01:50.151818.151818 mlpmodule.py:1239] gpu group einsum cost 0.00045299530029296875 s
DEBUG 01-14 17:01:50.153709.153709 mlpmodule.py:1316] gpu experts func einsum cost 0.0045888423919677734 s
DEBUG 01-14 17:01:50.153395.153395 mlpmodule.py:1178] gpu group tensors cost 0.00040841102600097656 s
DEBUG 01-14 17:01:50.155069.155069 mlpmodule.py:1220] gpu pad cost 0.0016760826110839844 s
DEBUG 01-14 17:01:50.155097.155097 mlpmodule.py:1226] start_w1
DEBUG 01-14 17:01:50.155427.155427 mlpmodule.py:1230] start_w3
DEBUG 01-14 17:01:50.155624.155624 mlpmodule.py:1236] start_w2
DEBUG 01-14 17:01:50.155118.155118 mlpmodule.py:1239] gpu group einsum cost 0.0004367828369140625 s
DEBUG 01-14 17:01:50.158527.158527 mlpmodule.py:1316] gpu experts func einsum cost 0.005148410797119141 s
DEBUG 01-14 17:01:50.158205.158205 cuda_h.py:19] end exec_one_by_one cost 0.009925127029418945 seconds
DEBUG 01-14 17:01:50.158577.158577 cuda_h.py:10] start exec_one_by_one_end_new
DEBUG 01-14 17:01:50.158810.158810 cuda_h.py:10] start gpu_group_tensor
DEBUG 01-14 17:01:50.158748.158748 cuda_h.py:19] end gpu_group_tensor cost 0.00010418891906738281 seconds
DEBUG 01-14 17:01:50.158902.158902 cuda_h.py:10] start gpu_group_tensor
DEBUG 01-14 17:01:50.158310.158310 cuda_h.py:19] end gpu_group_tensor cost 9.655952453613281e-05 seconds
DEBUG 01-14 17:01:50.158419.158419 cuda_h.py:10] start gpu_group_einsum
DEBUG 01-14 17:01:50.159562.159562 cuda_h.py:19] end gpu_group_einsum cost 0.0002765655517578125 seconds
DEBUG 01-14 17:01:50.159669.159669 cuda_h.py:10] start gpu_final_hidden_states_scatter
DEBUG 01-14 17:01:50.159448.159448 cuda_h.py:10] start all_expert_weight_slices
DEBUG 01-14 17:01:50.160219.160219 cuda_h.py:19] end all_expert_weight_slices cost 0.0006430149078369141 seconds
DEBUG 01-14 17:01:50.160697.160697 cuda_h.py:10] start all_expert_output_slices
DEBUG 01-14 17:01:50.160603.160603 cuda_h.py:19] end all_expert_output_slices cost 0.000152587890625 seconds
DEBUG 01-14 17:01:50.160445.160445 cuda_h.py:10] start concat_expert_out
DEBUG 01-14 17:01:50.160284.160284 cuda_h.py:19] end concat_expert_out cost 9.274482727050781e-05 seconds
DEBUG 01-14 17:01:50.160240.160240 cuda_h.py:10] start index_scatter
DEBUG 01-14 17:01:50.160203.160203 cuda_h.py:19] end index_scatter cost 4.506111145019531e-05 seconds
DEBUG 01-14 17:01:50.160628.160628 cuda_h.py:19] end gpu_final_hidden_states_scatter cost 0.0013158321380615234 seconds
DEBUG 01-14 17:01:50.160619.160619 cuda_h.py:10] start gpu_group_einsum
DEBUG 01-14 17:01:50.161942.161942 cuda_h.py:19] end gpu_group_einsum cost 0.0002963542938232422 seconds
DEBUG 01-14 17:01:50.161718.161718 cuda_h.py:10] start gpu_final_hidden_states_scatter
DEBUG 01-14 17:01:50.161367.161367 cuda_h.py:10] start all_expert_weight_slices
DEBUG 01-14 17:01:50.162612.162612 cuda_h.py:19] end all_expert_weight_slices cost 0.0007395744323730469 seconds
DEBUG 01-14 17:01:50.162613.162613 cuda_h.py:10] start all_expert_output_slices
DEBUG 01-14 17:01:50.162852.162852 cuda_h.py:19] end all_expert_output_slices cost 0.000186920166015625 seconds
DEBUG 01-14 17:01:50.162932.162932 cuda_h.py:10] start concat_expert_out
DEBUG 01-14 17:01:50.162095.162095 cuda_h.py:19] end concat_expert_out cost 9.465217590332031e-05 seconds
DEBUG 01-14 17:01:50.162262.162262 cuda_h.py:10] start index_scatter
DEBUG 01-14 17:01:50.162364.162364 cuda_h.py:19] end index_scatter cost 4.38690185546875e-05 seconds
DEBUG 01-14 17:01:50.162588.162588 cuda_h.py:19] end gpu_final_hidden_states_scatter cost 0.0016286373138427734 seconds
DEBUG 01-14 17:01:50.162717.162717 cuda_h.py:19] end exec_one_by_one_end_new cost 0.004362583160400391 seconds
DEBUG 01-14 17:01:50.162182.162182 cuda_h.py:10] start exec_one_by_one_end_new2
DEBUG 01-14 17:01:50.162368.162368 cuda_h.py:10] start gpu_group_einsum_mp_multi_list
DEBUG 01-14 17:01:50.162064.162064 cuda_h.py:10] start gpu_group_tensor
DEBUG 01-14 17:01:50.163671.163671 cuda_h.py:19] end gpu_group_tensor cost 0.00010633468627929688 seconds
DEBUG 01-14 17:01:50.163235.163235 cuda_h.py:10] start gpu_group_tensor
DEBUG 01-14 17:01:50.163776.163776 cuda_h.py:19] end gpu_group_tensor cost 9.250640869140625e-05 seconds
DEBUG 01-14 17:01:50.163394.163394 cuda_h.py:10] start gpu_group_einsum
DEBUG 01-14 17:01:50.163007.163007 cuda_h.py:19] end gpu_group_einsum cost 0.000274658203125 seconds
DEBUG 01-14 17:01:50.163844.163844 cuda_h.py:10] start gpu_group_einsum
DEBUG 01-14 17:01:50.164703.164703 cuda_h.py:19] end gpu_group_einsum cost 0.0002753734588623047 seconds
DEBUG 01-14 17:01:50.164063.164063 cuda_h.py:10] start gpu_final_hidden_states_scatter
DEBUG 01-14 17:01:50.164827.164827 cuda_h.py:10] start all_expert_outputs_slices
DEBUG 01-14 17:01:50.164140.164140 cuda_h.py:19] end all_expert_outputs_slices cost 0.00019121170043945312 seconds
DEBUG 01-14 17:01:50.164155.164155 cuda_h.py:10] start concat_expert_out
DEBUG 01-14 17:01:50.164733.164733 cuda_h.py:19] end concat_expert_out cost 4.887580871582031e-05 seconds
DEBUG 01-14 17:01:50.164377.164377 cuda_h.py:10] start index_scatter
DEBUG 01-14 17:01:50.164387.164387 cuda_h.py:19] end index_scatter cost 4.7206878662109375e-05 seconds
DEBUG 01-14 17:01:50.164532.164532 cuda_h.py:19] end gpu_final_hidden_states_scatter cost 0.0006911754608154297 seconds
DEBUG 01-14 17:01:50.164687.164687 cuda_h.py:10] start gpu_final_hidden_states_scatter
DEBUG 01-14 17:01:50.164900.164900 cuda_h.py:10] start all_expert_outputs_slices
DEBUG 01-14 17:01:50.165642.165642 cuda_h.py:19] end all_expert_outputs_slices cost 0.00016760826110839844 seconds
DEBUG 01-14 17:01:50.165914.165914 cuda_h.py:10] start concat_expert_out
DEBUG 01-14 17:01:50.165539.165539 cuda_h.py:19] end concat_expert_out cost 4.887580871582031e-05 seconds
DEBUG 01-14 17:01:50.165515.165515 cuda_h.py:10] start index_scatter
DEBUG 01-14 17:01:50.165616.165616 cuda_h.py:19] end index_scatter cost 4.57763671875e-05 seconds
DEBUG 01-14 17:01:50.165180.165180 cuda_h.py:19] end gpu_final_hidden_states_scatter cost 0.00047326087951660156 seconds
DEBUG 01-14 17:01:50.165401.165401 cuda_h.py:19] end exec_one_by_one_end_new2 cost 0.0025627613067626953 seconds
DEBUG 01-14 17:01:50.168414.168414 cuda_h.py:10] start task_processing_mp_load
DEBUG 01-14 17:01:50.168490.168490 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu_multi_device
DEBUG 01-14 17:01:50.170814.170814 cuda_memory_view.py:520] tensor_device_offsets_device_map {1: {'model.layers.1.mlp.experts.0.gate_proj.weight': 0, 'model.layers.1.mlp.experts.0.down_proj.weight': 5767168, 'model.layers.1.mlp.experts.0.up_proj.weight': 11534336, 'model.layers.1.mlp.experts.1.gate_proj.weight': 17301504, 'model.layers.1.mlp.experts.1.down_proj.weight': 23068672, 'model.layers.1.mlp.experts.1.up_proj.weight': 28835840, 'model.layers.1.mlp.experts.2.gate_proj.weight': 34603008, 'model.layers.1.mlp.experts.2.down_proj.weight': 40370176, 'model.layers.1.mlp.experts.2.up_proj.weight': 46137344, 'model.layers.1.mlp.experts.4.gate_proj.weight': 51904512, 'model.layers.1.mlp.experts.4.down_proj.weight': 57671680, 'model.layers.1.mlp.experts.4.up_proj.weight': 63438848, 'model.layers.1.mlp.experts.5.gate_proj.weight': 69206016, 'model.layers.1.mlp.experts.5.down_proj.weight': 74973184, 'model.layers.1.mlp.experts.5.up_proj.weight': 80740352, 'model.layers.1.mlp.experts.6.gate_proj.weight': 86507520, 'model.layers.1.mlp.experts.6.down_proj.weight': 92274688, 'model.layers.1.mlp.experts.6.up_proj.weight': 98041856, 'model.layers.1.mlp.experts.7.gate_proj.weight': 103809024, 'model.layers.1.mlp.experts.7.down_proj.weight': 109576192, 'model.layers.1.mlp.experts.7.up_proj.weight': 115343360, 'model.layers.1.mlp.experts.10.gate_proj.weight': 121110528, 'model.layers.1.mlp.experts.10.down_proj.weight': 126877696, 'model.layers.1.mlp.experts.10.up_proj.weight': 132644864, 'model.layers.1.mlp.experts.15.gate_proj.weight': 138412032, 'model.layers.1.mlp.experts.15.down_proj.weight': 144179200, 'model.layers.1.mlp.experts.15.up_proj.weight': 149946368, 'model.layers.1.mlp.experts.16.gate_proj.weight': 155713536, 'model.layers.1.mlp.experts.16.down_proj.weight': 161480704, 'model.layers.1.mlp.experts.16.up_proj.weight': 167247872, 'model.layers.1.mlp.experts.19.gate_proj.weight': 173015040, 'model.layers.1.mlp.experts.19.down_proj.weight': 178782208, 'model.layers.1.mlp.experts.19.up_proj.weight': 184549376, 'model.layers.1.mlp.experts.21.gate_proj.weight': 190316544, 'model.layers.1.mlp.experts.21.down_proj.weight': 196083712, 'model.layers.1.mlp.experts.21.up_proj.weight': 201850880, 'model.layers.1.mlp.experts.22.gate_proj.weight': 207618048, 'model.layers.1.mlp.experts.22.down_proj.weight': 213385216, 'model.layers.1.mlp.experts.22.up_proj.weight': 219152384, 'model.layers.1.mlp.experts.23.gate_proj.weight': 224919552, 'model.layers.1.mlp.experts.23.down_proj.weight': 230686720, 'model.layers.1.mlp.experts.23.up_proj.weight': 236453888, 'model.layers.1.mlp.experts.24.gate_proj.weight': 242221056, 'model.layers.1.mlp.experts.24.down_proj.weight': 247988224, 'model.layers.1.mlp.experts.24.up_proj.weight': 253755392, 'model.layers.1.mlp.experts.28.gate_proj.weight': 259522560, 'model.layers.1.mlp.experts.28.down_proj.weight': 265289728, 'model.layers.1.mlp.experts.28.up_proj.weight': 271056896, 'model.layers.1.mlp.experts.29.gate_proj.weight': 276824064, 'model.layers.1.mlp.experts.29.down_proj.weight': 282591232, 'model.layers.1.mlp.experts.29.up_proj.weight': 288358400, 'model.layers.1.mlp.experts.30.gate_proj.weight': 294125568, 'model.layers.1.mlp.experts.30.down_proj.weight': 299892736, 'model.layers.1.mlp.experts.30.up_proj.weight': 305659904, 'model.layers.1.mlp.experts.32.gate_proj.weight': 311427072, 'model.layers.1.mlp.experts.32.down_proj.weight': 317194240, 'model.layers.1.mlp.experts.32.up_proj.weight': 322961408, 'model.layers.1.mlp.experts.33.gate_proj.weight': 328728576, 'model.layers.1.mlp.experts.33.down_proj.weight': 334495744, 'model.layers.1.mlp.experts.33.up_proj.weight': 340262912, 'model.layers.1.mlp.experts.34.gate_proj.weight': 346030080, 'model.layers.1.mlp.experts.34.down_proj.weight': 351797248, 'model.layers.1.mlp.experts.34.up_proj.weight': 357564416, 'model.layers.1.mlp.experts.38.gate_proj.weight': 363331584, 'model.layers.1.mlp.experts.38.down_proj.weight': 369098752, 'model.layers.1.mlp.experts.38.up_proj.weight': 374865920, 'model.layers.1.mlp.experts.43.gate_proj.weight': 380633088, 'model.layers.1.mlp.experts.43.down_proj.weight': 386400256, 'model.layers.1.mlp.experts.43.up_proj.weight': 392167424, 'model.layers.1.mlp.experts.44.gate_proj.weight': 397934592, 'model.layers.1.mlp.experts.44.down_proj.weight': 403701760, 'model.layers.1.mlp.experts.44.up_proj.weight': 409468928, 'model.layers.1.mlp.experts.46.gate_proj.weight': 415236096, 'model.layers.1.mlp.experts.46.down_proj.weight': 421003264, 'model.layers.1.mlp.experts.46.up_proj.weight': 426770432, 'model.layers.1.mlp.experts.48.gate_proj.weight': 432537600, 'model.layers.1.mlp.experts.48.down_proj.weight': 438304768, 'model.layers.1.mlp.experts.48.up_proj.weight': 444071936, 'model.layers.1.mlp.experts.54.gate_proj.weight': 449839104, 'model.layers.1.mlp.experts.54.down_proj.weight': 455606272, 'model.layers.1.mlp.experts.54.up_proj.weight': 461373440, 'model.layers.1.mlp.experts.56.gate_proj.weight': 467140608, 'model.layers.1.mlp.experts.56.down_proj.weight': 472907776, 'model.layers.1.mlp.experts.56.up_proj.weight': 478674944, 'model.layers.1.mlp.experts.58.gate_proj.weight': 484442112, 'model.layers.1.mlp.experts.58.down_proj.weight': 490209280, 'model.layers.1.mlp.experts.58.up_proj.weight': 495976448, 'model.layers.1.mlp.experts.59.gate_proj.weight': 501743616, 'model.layers.1.mlp.experts.59.down_proj.weight': 507510784, 'model.layers.1.mlp.experts.59.up_proj.weight': 513277952, 'model.layers.1.mlp.experts.62.gate_proj.weight': 519045120, 'model.layers.1.mlp.experts.62.down_proj.weight': 524812288, 'model.layers.1.mlp.experts.62.up_proj.weight': 530579456, 'model.layers.1.mlp.experts.63.gate_proj.weight': 536346624, 'model.layers.1.mlp.experts.63.down_proj.weight': 542113792, 'model.layers.1.mlp.experts.63.up_proj.weight': 547880960}, 2: {'model.layers.1.mlp.experts.3.gate_proj.weight': 0, 'model.layers.1.mlp.experts.3.down_proj.weight': 5767168, 'model.layers.1.mlp.experts.3.up_proj.weight': 11534336, 'model.layers.1.mlp.experts.8.gate_proj.weight': 17301504, 'model.layers.1.mlp.experts.8.down_proj.weight': 23068672, 'model.layers.1.mlp.experts.8.up_proj.weight': 28835840, 'model.layers.1.mlp.experts.9.gate_proj.weight': 34603008, 'model.layers.1.mlp.experts.9.down_proj.weight': 40370176, 'model.layers.1.mlp.experts.9.up_proj.weight': 46137344, 'model.layers.1.mlp.experts.11.gate_proj.weight': 51904512, 'model.layers.1.mlp.experts.11.down_proj.weight': 57671680, 'model.layers.1.mlp.experts.11.up_proj.weight': 63438848, 'model.layers.1.mlp.experts.12.gate_proj.weight': 69206016, 'model.layers.1.mlp.experts.12.down_proj.weight': 74973184, 'model.layers.1.mlp.experts.12.up_proj.weight': 80740352, 'model.layers.1.mlp.experts.13.gate_proj.weight': 86507520, 'model.layers.1.mlp.experts.13.down_proj.weight': 92274688, 'model.layers.1.mlp.experts.13.up_proj.weight': 98041856, 'model.layers.1.mlp.experts.14.gate_proj.weight': 103809024, 'model.layers.1.mlp.experts.14.down_proj.weight': 109576192, 'model.layers.1.mlp.experts.14.up_proj.weight': 115343360, 'model.layers.1.mlp.experts.17.gate_proj.weight': 121110528, 'model.layers.1.mlp.experts.17.down_proj.weight': 126877696, 'model.layers.1.mlp.experts.17.up_proj.weight': 132644864, 'model.layers.1.mlp.experts.18.gate_proj.weight': 138412032, 'model.layers.1.mlp.experts.18.down_proj.weight': 144179200, 'model.layers.1.mlp.experts.18.up_proj.weight': 149946368, 'model.layers.1.mlp.experts.20.gate_proj.weight': 155713536, 'model.layers.1.mlp.experts.20.down_proj.weight': 161480704, 'model.layers.1.mlp.experts.20.up_proj.weight': 167247872, 'model.layers.1.mlp.experts.25.gate_proj.weight': 173015040, 'model.layers.1.mlp.experts.25.down_proj.weight': 178782208, 'model.layers.1.mlp.experts.25.up_proj.weight': 184549376, 'model.layers.1.mlp.experts.26.gate_proj.weight': 190316544, 'model.layers.1.mlp.experts.26.down_proj.weight': 196083712, 'model.layers.1.mlp.experts.26.up_proj.weight': 201850880, 'model.layers.1.mlp.experts.27.gate_proj.weight': 207618048, 'model.layers.1.mlp.experts.27.down_proj.weight': 213385216, 'model.layers.1.mlp.experts.27.up_proj.weight': 219152384, 'model.layers.1.mlp.experts.31.gate_proj.weight': 224919552, 'model.layers.1.mlp.experts.31.down_proj.weight': 230686720, 'model.layers.1.mlp.experts.31.up_proj.weight': 236453888, 'model.layers.1.mlp.experts.35.gate_proj.weight': 242221056, 'model.layers.1.mlp.experts.35.down_proj.weight': 247988224, 'model.layers.1.mlp.experts.35.up_proj.weight': 253755392, 'model.layers.1.mlp.experts.36.gate_proj.weight': 259522560, 'model.layers.1.mlp.experts.36.down_proj.weight': 265289728, 'model.layers.1.mlp.experts.36.up_proj.weight': 271056896, 'model.layers.1.mlp.experts.37.gate_proj.weight': 276824064, 'model.layers.1.mlp.experts.37.down_proj.weight': 282591232, 'model.layers.1.mlp.experts.37.up_proj.weight': 288358400, 'model.layers.1.mlp.experts.39.gate_proj.weight': 294125568, 'model.layers.1.mlp.experts.39.down_proj.weight': 299892736, 'model.layers.1.mlp.experts.39.up_proj.weight': 305659904, 'model.layers.1.mlp.experts.40.gate_proj.weight': 311427072, 'model.layers.1.mlp.experts.40.down_proj.weight': 317194240, 'model.layers.1.mlp.experts.40.up_proj.weight': 322961408, 'model.layers.1.mlp.experts.41.gate_proj.weight': 328728576, 'model.layers.1.mlp.experts.41.down_proj.weight': 334495744, 'model.layers.1.mlp.experts.41.up_proj.weight': 340262912, 'model.layers.1.mlp.experts.42.gate_proj.weight': 346030080, 'model.layers.1.mlp.experts.42.down_proj.weight': 351797248, 'model.layers.1.mlp.experts.42.up_proj.weight': 357564416, 'model.layers.1.mlp.experts.45.gate_proj.weight': 363331584, 'model.layers.1.mlp.experts.45.down_proj.weight': 369098752, 'model.layers.1.mlp.experts.45.up_proj.weight': 374865920, 'model.layers.1.mlp.experts.47.gate_proj.weight': 380633088, 'model.layers.1.mlp.experts.47.down_proj.weight': 386400256, 'model.layers.1.mlp.experts.47.up_proj.weight': 392167424, 'model.layers.1.mlp.experts.49.gate_proj.weight': 397934592, 'model.layers.1.mlp.experts.49.down_proj.weight': 403701760, 'model.layers.1.mlp.experts.49.up_proj.weight': 409468928, 'model.layers.1.mlp.experts.50.gate_proj.weight': 415236096, 'model.layers.1.mlp.experts.50.down_proj.weight': 421003264, 'model.layers.1.mlp.experts.50.up_proj.weight': 426770432, 'model.layers.1.mlp.experts.51.gate_proj.weight': 432537600, 'model.layers.1.mlp.experts.51.down_proj.weight': 438304768, 'model.layers.1.mlp.experts.51.up_proj.weight': 444071936, 'model.layers.1.mlp.experts.52.gate_proj.weight': 449839104, 'model.layers.1.mlp.experts.52.down_proj.weight': 455606272, 'model.layers.1.mlp.experts.52.up_proj.weight': 461373440, 'model.layers.1.mlp.experts.53.gate_proj.weight': 467140608, 'model.layers.1.mlp.experts.53.down_proj.weight': 472907776, 'model.layers.1.mlp.experts.53.up_proj.weight': 478674944, 'model.layers.1.mlp.experts.55.gate_proj.weight': 484442112, 'model.layers.1.mlp.experts.55.down_proj.weight': 490209280, 'model.layers.1.mlp.experts.55.up_proj.weight': 495976448, 'model.layers.1.mlp.experts.57.gate_proj.weight': 501743616, 'model.layers.1.mlp.experts.57.down_proj.weight': 507510784, 'model.layers.1.mlp.experts.57.up_proj.weight': 513277952, 'model.layers.1.mlp.experts.60.gate_proj.weight': 519045120, 'model.layers.1.mlp.experts.60.down_proj.weight': 524812288, 'model.layers.1.mlp.experts.60.up_proj.weight': 530579456, 'model.layers.1.mlp.experts.61.gate_proj.weight': 536346624, 'model.layers.1.mlp.experts.61.down_proj.weight': 542113792, 'model.layers.1.mlp.experts.61.up_proj.weight': 547880960}}tensor_copy_chunks_device_map {1: [(2860515328, 5767168, 0, 0), (2866282496, 5767168, 5767168, 0), (2854748160, 5767168, 11534336, 0), (2877816832, 5767168, 17301504, 0), (2883584000, 5767168, 23068672, 0), (2872049664, 5767168, 28835840, 0), (2895118336, 5767168, 34603008, 0), (2900885504, 5767168, 40370176, 0), (2889351168, 5767168, 46137344, 0), (2929721344, 5767168, 51904512, 0), (2935488512, 5767168, 57671680, 0), (2923954176, 5767168, 63438848, 0), (2947022848, 5767168, 69206016, 0), (2952790016, 5767168, 74973184, 0), (2941255680, 5767168, 80740352, 0), (2964324352, 5767168, 86507520, 0), (2970091520, 5767168, 92274688, 0), (2958557184, 5767168, 98041856, 0), (2981625856, 5767168, 103809024, 0), (2987393024, 5767168, 109576192, 0), (2975858688, 5767168, 115343360, 0), (3033530368, 5767168, 121110528, 0), (3039297536, 5767168, 126877696, 0), (3027763200, 5767168, 132644864, 0), (3120037888, 5767168, 138412032, 0), (3125805056, 5767168, 144179200, 0), (3114270720, 5767168, 149946368, 0), (3137339392, 5767168, 155713536, 0), (3143106560, 5767168, 161480704, 0), (3131572224, 5767168, 167247872, 0), (3189243904, 5767168, 173015040, 0), (3195011072, 5767168, 178782208, 0), (3183476736, 5767168, 184549376, 0), (3223846912, 5767168, 190316544, 0), (3229614080, 5767168, 196083712, 0), (3218079744, 5767168, 201850880, 0), (3241148416, 5767168, 207618048, 0), (3246915584, 5767168, 213385216, 0), (3235381248, 5767168, 219152384, 0), (3258449920, 5767168, 224919552, 0), (3264217088, 5767168, 230686720, 0), (3252682752, 5767168, 236453888, 0), (3275751424, 5767168, 242221056, 0), (3281518592, 5767168, 247988224, 0), (3269984256, 5767168, 253755392, 0), (3344957440, 5767168, 259522560, 0), (3350724608, 5767168, 265289728, 0), (3339190272, 5767168, 271056896, 0), (3362258944, 5767168, 276824064, 0), (3368026112, 5767168, 282591232, 0), (3356491776, 5767168, 288358400, 0), (3379560448, 5767168, 294125568, 0), (3385327616, 5767168, 299892736, 0), (3373793280, 5767168, 305659904, 0), (3414163456, 5767168, 311427072, 0), (3419930624, 5767168, 317194240, 0), (3408396288, 5767168, 322961408, 0), (3431464960, 5767168, 328728576, 0), (3437232128, 5767168, 334495744, 0), (3425697792, 5767168, 340262912, 0), (3448766464, 5767168, 346030080, 0), (3454533632, 5767168, 351797248, 0), (3442999296, 5767168, 357564416, 0), (3517972480, 5767168, 363331584, 0), (3523739648, 5767168, 369098752, 0), (3512205312, 5767168, 374865920, 0), (3604480000, 5767168, 380633088, 0), (3610247168, 5767168, 386400256, 0), (3598712832, 5767168, 392167424, 0), (3621781504, 5767168, 397934592, 0), (3627548672, 5767168, 403701760, 0), (3616014336, 5767168, 409468928, 0), (3656384512, 5767168, 415236096, 0), (3662151680, 5767168, 421003264, 0), (3650617344, 5767168, 426770432, 0), (3690987520, 5767168, 432537600, 0), (3696754688, 5767168, 438304768, 0), (3685220352, 5767168, 444071936, 0), (3794796544, 5767168, 449839104, 0), (3800563712, 5767168, 455606272, 0), (3789029376, 5767168, 461373440, 0), (3829399552, 5767168, 467140608, 0), (3835166720, 5767168, 472907776, 0), (3823632384, 5767168, 478674944, 0), (3864002560, 5767168, 484442112, 0), (3869769728, 5767168, 490209280, 0), (3858235392, 5767168, 495976448, 0), (3881304064, 5767168, 501743616, 0), (3887071232, 5767168, 507510784, 0), (3875536896, 5767168, 513277952, 0), (3933208576, 5767168, 519045120, 0), (3938975744, 5767168, 524812288, 0), (3927441408, 5767168, 530579456, 0), (3950510080, 5767168, 536346624, 0), (3956277248, 5767168, 542113792, 0), (3944742912, 5767168, 547880960, 0)], 2: [(2912419840, 5767168, 0, 0), (2918187008, 5767168, 5767168, 0), (2906652672, 5767168, 11534336, 0), (2998927360, 5767168, 17301504, 0), (3004694528, 5767168, 23068672, 0), (2993160192, 5767168, 28835840, 0), (3016228864, 5767168, 34603008, 0), (3021996032, 5767168, 40370176, 0), (3010461696, 5767168, 46137344, 0), (3050831872, 5767168, 51904512, 0), (3056599040, 5767168, 57671680, 0), (3045064704, 5767168, 63438848, 0), (3068133376, 5767168, 69206016, 0), (3073900544, 5767168, 74973184, 0), (3062366208, 5767168, 80740352, 0), (3085434880, 5767168, 86507520, 0), (3091202048, 5767168, 92274688, 0), (3079667712, 5767168, 98041856, 0), (3102736384, 5767168, 103809024, 0), (3108503552, 5767168, 109576192, 0), (3096969216, 5767168, 115343360, 0), (3154640896, 5767168, 121110528, 0), (3160408064, 5767168, 126877696, 0), (3148873728, 5767168, 132644864, 0), (3171942400, 5767168, 138412032, 0), (3177709568, 5767168, 144179200, 0), (3166175232, 5767168, 149946368, 0), (3206545408, 5767168, 155713536, 0), (3212312576, 5767168, 161480704, 0), (3200778240, 5767168, 167247872, 0), (3293052928, 5767168, 173015040, 0), (3298820096, 5767168, 178782208, 0), (3287285760, 5767168, 184549376, 0), (3310354432, 5767168, 190316544, 0), (3316121600, 5767168, 196083712, 0), (3304587264, 5767168, 201850880, 0), (3327655936, 5767168, 207618048, 0), (3333423104, 5767168, 213385216, 0), (3321888768, 5767168, 219152384, 0), (3396861952, 5767168, 224919552, 0), (3402629120, 5767168, 230686720, 0), (3391094784, 5767168, 236453888, 0), (3466067968, 5767168, 242221056, 0), (3471835136, 5767168, 247988224, 0), (3460300800, 5767168, 253755392, 0), (3483369472, 5767168, 259522560, 0), (3489136640, 5767168, 265289728, 0), (3477602304, 5767168, 271056896, 0), (3500670976, 5767168, 276824064, 0), (3506438144, 5767168, 282591232, 0), (3494903808, 5767168, 288358400, 0), (3535273984, 5767168, 294125568, 0), (3541041152, 5767168, 299892736, 0), (3529506816, 5767168, 305659904, 0), (3552575488, 5767168, 311427072, 0), (3558342656, 5767168, 317194240, 0), (3546808320, 5767168, 322961408, 0), (3569876992, 5767168, 328728576, 0), (3575644160, 5767168, 334495744, 0), (3564109824, 5767168, 340262912, 0), (3587178496, 5767168, 346030080, 0), (3592945664, 5767168, 351797248, 0), (3581411328, 5767168, 357564416, 0), (3639083008, 5767168, 363331584, 0), (3644850176, 5767168, 369098752, 0), (3633315840, 5767168, 374865920, 0), (3673686016, 5767168, 380633088, 0), (3679453184, 5767168, 386400256, 0), (3667918848, 5767168, 392167424, 0), (3708289024, 5767168, 397934592, 0), (3714056192, 5767168, 403701760, 0), (3702521856, 5767168, 409468928, 0), (3725590528, 5767168, 415236096, 0), (3731357696, 5767168, 421003264, 0), (3719823360, 5767168, 426770432, 0), (3742892032, 5767168, 432537600, 0), (3748659200, 5767168, 438304768, 0), (3737124864, 5767168, 444071936, 0), (3760193536, 5767168, 449839104, 0), (3765960704, 5767168, 455606272, 0), (3754426368, 5767168, 461373440, 0), (3777495040, 5767168, 467140608, 0), (3783262208, 5767168, 472907776, 0), (3771727872, 5767168, 478674944, 0), (3812098048, 5767168, 484442112, 0), (3817865216, 5767168, 490209280, 0), (3806330880, 5767168, 495976448, 0), (3846701056, 5767168, 501743616, 0), (3852468224, 5767168, 507510784, 0), (3840933888, 5767168, 513277952, 0), (3898605568, 5767168, 519045120, 0), (3904372736, 5767168, 524812288, 0), (3892838400, 5767168, 530579456, 0), (3915907072, 5767168, 536346624, 0), (3921674240, 5767168, 542113792, 0), (3910139904, 5767168, 547880960, 0)]}cuda_memory_handles_device_map {1: <capsule object NULL at 0x7b0b8db08ff0>, 2: <capsule object NULL at 0x7b0b88bcfcf0>}
DEBUG 01-14 17:01:50.170196.170196 sllm_store_c.py:27] get device uuid map
DEBUG 01-14 17:01:50.170781.170781 sllm_store_c.py:29] call client load into gpu
DEBUG 01-14 17:01:50.170338.170338 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 618b2326-1d4c-485c-b0f0-2337a8bd1778
DEBUG 01-14 17:01:50.170425.170425 client.py:106] call stub.LoadModelAsync
INFO 01-14 17:01:50.173003.173003 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 618b2326-1d4c-485c-b0f0-2337a8bd1778
DEBUG 01-14 17:01:50.173562.173562 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu_multi_device cost 0.005671262741088867 seconds
DEBUG 01-14 17:01:50.173400.173400 cuda_h.py:10] start restore2model
DEBUG 01-14 17:01:50.178557.178557 cuda_h.py:19] end restore2model cost 0.0040416717529296875 seconds
DEBUG 01-14 17:01:50.178661.178661 cuda_h.py:10] start experts_func_mgpu_group_pad
DEBUG 01-14 17:01:50.179485.179485 cuda_h.py:19] end experts_func_mgpu_group_pad cost 0.0014297962188720703 seconds
DEBUG 01-14 17:01:50.179335.179335 cuda_h.py:10] start experts_func_mgpu_group_pad
DEBUG 01-14 17:01:50.181006.181006 cuda_h.py:19] end experts_func_mgpu_group_pad cost 0.001615762710571289 seconds
DEBUG 01-14 17:01:50.181221.181221 cuda_h.py:10] start gpu_group_list
DEBUG 01-14 17:01:50.181186.181186 cuda_h.py:19] end gpu_group_list cost 0.00029158592224121094 seconds
DEBUG 01-14 17:01:50.182361.182361 cuda_h.py:10] start gpu_group_list
DEBUG 01-14 17:01:50.182219.182219 cuda_h.py:19] end gpu_group_list cost 0.0002868175506591797 seconds
INFO 01-14 17:01:50.185426.185426 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 618b2326-1d4c-485c-b0f0-2337a8bd1778
INFO 01-14 17:01:50.225724.225724 client.py:127] Model loaded
DEBUG 01-14 17:01:50.225304.225304 cuda_h.py:19] end task_processing_mp_load cost 0.057163238525390625 seconds
DEBUG 01-14 17:01:50.225531.225531 cuda_h.py:10] start exec_together
DEBUG 01-14 17:01:50.238899.238899 mlpmodule.py:1053] mgpu group einsum cost 0.0012843608856201172 s
DEBUG 01-14 17:01:50.244017.244017 mlpmodule.py:1109] mgpu experts func einsum cost 0.019366741180419922 s
DEBUG 01-14 17:01:50.244080.244080 cuda_h.py:19] end exec_together cost 0.019521713256835938 seconds
DEBUG 01-14 17:01:50.244572.244572 cuda_h.py:10] start exec_one_by_one
DEBUG 01-14 17:01:50.245692.245692 mlpmodule.py:1178] gpu group tensors cost 0.0005555152893066406 s
DEBUG 01-14 17:01:50.247616.247616 mlpmodule.py:1220] gpu pad cost 0.002022266387939453 s
DEBUG 01-14 17:01:50.247102.247102 mlpmodule.py:1226] start_w1
DEBUG 01-14 17:01:50.247817.247817 mlpmodule.py:1230] start_w3
DEBUG 01-14 17:01:50.248490.248490 mlpmodule.py:1236] start_w2
DEBUG 01-14 17:01:50.248176.248176 mlpmodule.py:1239] gpu group einsum cost 0.00044345855712890625 s
DEBUG 01-14 17:01:50.250030.250030 mlpmodule.py:1316] gpu experts func einsum cost 0.00529932975769043 s
DEBUG 01-14 17:01:50.250980.250980 mlpmodule.py:1178] gpu group tensors cost 0.00040149688720703125 s
DEBUG 01-14 17:01:50.252423.252423 mlpmodule.py:1220] gpu pad cost 0.0017158985137939453 s
DEBUG 01-14 17:01:50.252365.252365 mlpmodule.py:1226] start_w1
DEBUG 01-14 17:01:50.252352.252352 mlpmodule.py:1230] start_w3
DEBUG 01-14 17:01:50.252417.252417 mlpmodule.py:1236] start_w2
DEBUG 01-14 17:01:50.253918.253918 mlpmodule.py:1239] gpu group einsum cost 0.0004820823669433594 s
DEBUG 01-14 17:01:50.255139.255139 mlpmodule.py:1316] gpu experts func einsum cost 0.005151987075805664 s
DEBUG 01-14 17:01:50.255870.255870 cuda_h.py:19] end exec_one_by_one cost 0.010644197463989258 seconds
DEBUG 01-14 17:01:50.255196.255196 cuda_h.py:10] start exec_one_by_one_end_new
DEBUG 01-14 17:01:50.255428.255428 cuda_h.py:10] start gpu_group_tensor
DEBUG 01-14 17:01:50.255704.255704 cuda_h.py:19] end gpu_group_tensor cost 0.00010728836059570312 seconds
DEBUG 01-14 17:01:50.255097.255097 cuda_h.py:10] start gpu_group_tensor
DEBUG 01-14 17:01:50.255028.255028 cuda_h.py:19] end gpu_group_tensor cost 9.560585021972656e-05 seconds
DEBUG 01-14 17:01:50.256567.256567 cuda_h.py:10] start gpu_group_einsum
DEBUG 01-14 17:01:50.256062.256062 cuda_h.py:19] end gpu_group_einsum cost 0.0002815723419189453 seconds
DEBUG 01-14 17:01:50.256911.256911 cuda_h.py:10] start gpu_final_hidden_states_scatter
DEBUG 01-14 17:01:50.256889.256889 cuda_h.py:10] start all_expert_weight_slices
DEBUG 01-14 17:01:50.257568.257568 cuda_h.py:19] end all_expert_weight_slices cost 0.00067901611328125 seconds
DEBUG 01-14 17:01:50.257431.257431 cuda_h.py:10] start all_expert_output_slices
DEBUG 01-14 17:01:50.257404.257404 cuda_h.py:19] end all_expert_output_slices cost 0.00016188621520996094 seconds
DEBUG 01-14 17:01:50.257438.257438 cuda_h.py:10] start concat_expert_out
DEBUG 01-14 17:01:50.257741.257741 cuda_h.py:19] end concat_expert_out cost 0.00010967254638671875 seconds
DEBUG 01-14 17:01:50.257862.257862 cuda_h.py:10] start index_scatter
DEBUG 01-14 17:01:50.257533.257533 cuda_h.py:19] end index_scatter cost 4.315376281738281e-05 seconds
DEBUG 01-14 17:01:50.257574.257574 cuda_h.py:19] end gpu_final_hidden_states_scatter cost 0.0013768672943115234 seconds
DEBUG 01-14 17:01:50.257797.257797 cuda_h.py:10] start gpu_group_einsum
DEBUG 01-14 17:01:50.258431.258431 cuda_h.py:19] end gpu_group_einsum cost 0.0002808570861816406 seconds
DEBUG 01-14 17:01:50.258300.258300 cuda_h.py:10] start gpu_final_hidden_states_scatter
DEBUG 01-14 17:01:50.258213.258213 cuda_h.py:10] start all_expert_weight_slices
DEBUG 01-14 17:01:50.259602.259602 cuda_h.py:19] end all_expert_weight_slices cost 0.0007069110870361328 seconds
DEBUG 01-14 17:01:50.259795.259795 cuda_h.py:10] start all_expert_output_slices
DEBUG 01-14 17:01:50.259180.259180 cuda_h.py:19] end all_expert_output_slices cost 0.0001888275146484375 seconds
DEBUG 01-14 17:01:50.259499.259499 cuda_h.py:10] start concat_expert_out
DEBUG 01-14 17:01:50.259615.259615 cuda_h.py:19] end concat_expert_out cost 9.489059448242188e-05 seconds
DEBUG 01-14 17:01:50.259021.259021 cuda_h.py:10] start index_scatter
DEBUG 01-14 17:01:50.259931.259931 cuda_h.py:19] end index_scatter cost 4.315376281738281e-05 seconds
DEBUG 01-14 17:01:50.260851.260851 cuda_h.py:19] end gpu_final_hidden_states_scatter cost 0.0016031265258789062 seconds
DEBUG 01-14 17:01:50.260940.260940 cuda_h.py:19] end exec_one_by_one_end_new cost 0.004422664642333984 seconds
DEBUG 01-14 17:01:50.260551.260551 cuda_h.py:10] start exec_one_by_one_end_new2
DEBUG 01-14 17:01:50.260929.260929 cuda_h.py:10] start gpu_group_einsum_mp_multi_list
DEBUG 01-14 17:01:50.260817.260817 cuda_h.py:10] start gpu_group_tensor
DEBUG 01-14 17:01:50.260193.260193 cuda_h.py:19] end gpu_group_tensor cost 0.00011110305786132812 seconds
DEBUG 01-14 17:01:50.260426.260426 cuda_h.py:10] start gpu_group_tensor
DEBUG 01-14 17:01:50.260463.260463 cuda_h.py:19] end gpu_group_tensor cost 0.00010800361633300781 seconds
DEBUG 01-14 17:01:50.260632.260632 cuda_h.py:10] start gpu_group_einsum
DEBUG 01-14 17:01:50.260233.260233 cuda_h.py:19] end gpu_group_einsum cost 0.0002942085266113281 seconds
DEBUG 01-14 17:01:50.261977.261977 cuda_h.py:10] start gpu_group_einsum
DEBUG 01-14 17:01:50.261909.261909 cuda_h.py:19] end gpu_group_einsum cost 0.00029158592224121094 seconds
DEBUG 01-14 17:01:50.261131.261131 cuda_h.py:10] start gpu_final_hidden_states_scatter
DEBUG 01-14 17:01:50.261471.261471 cuda_h.py:10] start all_expert_outputs_slices
DEBUG 01-14 17:01:50.261380.261380 cuda_h.py:19] end all_expert_outputs_slices cost 0.00021266937255859375 seconds
DEBUG 01-14 17:01:50.261752.261752 cuda_h.py:10] start concat_expert_out
DEBUG 01-14 17:01:50.261185.261185 cuda_h.py:19] end concat_expert_out cost 4.673004150390625e-05 seconds
DEBUG 01-14 17:01:50.261399.261399 cuda_h.py:10] start index_scatter
DEBUG 01-14 17:01:50.261739.261739 cuda_h.py:19] end index_scatter cost 4.506111145019531e-05 seconds
DEBUG 01-14 17:01:50.262877.262877 cuda_h.py:19] end gpu_final_hidden_states_scatter cost 0.0006837844848632812 seconds
DEBUG 01-14 17:01:50.262171.262171 cuda_h.py:10] start gpu_final_hidden_states_scatter
DEBUG 01-14 17:01:50.262954.262954 cuda_h.py:10] start all_expert_outputs_slices
DEBUG 01-14 17:01:50.262404.262404 cuda_h.py:19] end all_expert_outputs_slices cost 0.00016570091247558594 seconds
DEBUG 01-14 17:01:50.262438.262438 cuda_h.py:10] start concat_expert_out
DEBUG 01-14 17:01:50.262063.262063 cuda_h.py:19] end concat_expert_out cost 4.9114227294921875e-05 seconds
DEBUG 01-14 17:01:50.262131.262131 cuda_h.py:10] start index_scatter
DEBUG 01-14 17:01:50.262578.262578 cuda_h.py:19] end index_scatter cost 5.364418029785156e-05 seconds
DEBUG 01-14 17:01:50.262665.262665 cuda_h.py:19] end gpu_final_hidden_states_scatter cost 0.00047326087951660156 seconds
DEBUG 01-14 17:01:50.262117.262117 cuda_h.py:19] end exec_one_by_one_end_new2 cost 0.0026426315307617188 seconds
DEBUG 01-14 17:01:50.265222.265222 cuda_h.py:10] start task_processing_mp_load
DEBUG 01-14 17:01:50.265967.265967 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu_multi_device
DEBUG 01-14 17:01:50.267947.267947 cuda_memory_view.py:520] tensor_device_offsets_device_map {1: {'model.layers.1.mlp.experts.0.gate_proj.weight': 0, 'model.layers.1.mlp.experts.0.down_proj.weight': 5767168, 'model.layers.1.mlp.experts.0.up_proj.weight': 11534336, 'model.layers.1.mlp.experts.1.gate_proj.weight': 17301504, 'model.layers.1.mlp.experts.1.down_proj.weight': 23068672, 'model.layers.1.mlp.experts.1.up_proj.weight': 28835840, 'model.layers.1.mlp.experts.2.gate_proj.weight': 34603008, 'model.layers.1.mlp.experts.2.down_proj.weight': 40370176, 'model.layers.1.mlp.experts.2.up_proj.weight': 46137344, 'model.layers.1.mlp.experts.4.gate_proj.weight': 51904512, 'model.layers.1.mlp.experts.4.down_proj.weight': 57671680, 'model.layers.1.mlp.experts.4.up_proj.weight': 63438848, 'model.layers.1.mlp.experts.5.gate_proj.weight': 69206016, 'model.layers.1.mlp.experts.5.down_proj.weight': 74973184, 'model.layers.1.mlp.experts.5.up_proj.weight': 80740352, 'model.layers.1.mlp.experts.6.gate_proj.weight': 86507520, 'model.layers.1.mlp.experts.6.down_proj.weight': 92274688, 'model.layers.1.mlp.experts.6.up_proj.weight': 98041856, 'model.layers.1.mlp.experts.7.gate_proj.weight': 103809024, 'model.layers.1.mlp.experts.7.down_proj.weight': 109576192, 'model.layers.1.mlp.experts.7.up_proj.weight': 115343360, 'model.layers.1.mlp.experts.10.gate_proj.weight': 121110528, 'model.layers.1.mlp.experts.10.down_proj.weight': 126877696, 'model.layers.1.mlp.experts.10.up_proj.weight': 132644864, 'model.layers.1.mlp.experts.15.gate_proj.weight': 138412032, 'model.layers.1.mlp.experts.15.down_proj.weight': 144179200, 'model.layers.1.mlp.experts.15.up_proj.weight': 149946368, 'model.layers.1.mlp.experts.16.gate_proj.weight': 155713536, 'model.layers.1.mlp.experts.16.down_proj.weight': 161480704, 'model.layers.1.mlp.experts.16.up_proj.weight': 167247872, 'model.layers.1.mlp.experts.19.gate_proj.weight': 173015040, 'model.layers.1.mlp.experts.19.down_proj.weight': 178782208, 'model.layers.1.mlp.experts.19.up_proj.weight': 184549376, 'model.layers.1.mlp.experts.21.gate_proj.weight': 190316544, 'model.layers.1.mlp.experts.21.down_proj.weight': 196083712, 'model.layers.1.mlp.experts.21.up_proj.weight': 201850880, 'model.layers.1.mlp.experts.22.gate_proj.weight': 207618048, 'model.layers.1.mlp.experts.22.down_proj.weight': 213385216, 'model.layers.1.mlp.experts.22.up_proj.weight': 219152384, 'model.layers.1.mlp.experts.23.gate_proj.weight': 224919552, 'model.layers.1.mlp.experts.23.down_proj.weight': 230686720, 'model.layers.1.mlp.experts.23.up_proj.weight': 236453888, 'model.layers.1.mlp.experts.24.gate_proj.weight': 242221056, 'model.layers.1.mlp.experts.24.down_proj.weight': 247988224, 'model.layers.1.mlp.experts.24.up_proj.weight': 253755392, 'model.layers.1.mlp.experts.28.gate_proj.weight': 259522560, 'model.layers.1.mlp.experts.28.down_proj.weight': 265289728, 'model.layers.1.mlp.experts.28.up_proj.weight': 271056896, 'model.layers.1.mlp.experts.29.gate_proj.weight': 276824064, 'model.layers.1.mlp.experts.29.down_proj.weight': 282591232, 'model.layers.1.mlp.experts.29.up_proj.weight': 288358400, 'model.layers.1.mlp.experts.30.gate_proj.weight': 294125568, 'model.layers.1.mlp.experts.30.down_proj.weight': 299892736, 'model.layers.1.mlp.experts.30.up_proj.weight': 305659904, 'model.layers.1.mlp.experts.32.gate_proj.weight': 311427072, 'model.layers.1.mlp.experts.32.down_proj.weight': 317194240, 'model.layers.1.mlp.experts.32.up_proj.weight': 322961408, 'model.layers.1.mlp.experts.33.gate_proj.weight': 328728576, 'model.layers.1.mlp.experts.33.down_proj.weight': 334495744, 'model.layers.1.mlp.experts.33.up_proj.weight': 340262912, 'model.layers.1.mlp.experts.34.gate_proj.weight': 346030080, 'model.layers.1.mlp.experts.34.down_proj.weight': 351797248, 'model.layers.1.mlp.experts.34.up_proj.weight': 357564416, 'model.layers.1.mlp.experts.38.gate_proj.weight': 363331584, 'model.layers.1.mlp.experts.38.down_proj.weight': 369098752, 'model.layers.1.mlp.experts.38.up_proj.weight': 374865920, 'model.layers.1.mlp.experts.43.gate_proj.weight': 380633088, 'model.layers.1.mlp.experts.43.down_proj.weight': 386400256, 'model.layers.1.mlp.experts.43.up_proj.weight': 392167424, 'model.layers.1.mlp.experts.44.gate_proj.weight': 397934592, 'model.layers.1.mlp.experts.44.down_proj.weight': 403701760, 'model.layers.1.mlp.experts.44.up_proj.weight': 409468928, 'model.layers.1.mlp.experts.46.gate_proj.weight': 415236096, 'model.layers.1.mlp.experts.46.down_proj.weight': 421003264, 'model.layers.1.mlp.experts.46.up_proj.weight': 426770432, 'model.layers.1.mlp.experts.48.gate_proj.weight': 432537600, 'model.layers.1.mlp.experts.48.down_proj.weight': 438304768, 'model.layers.1.mlp.experts.48.up_proj.weight': 444071936, 'model.layers.1.mlp.experts.54.gate_proj.weight': 449839104, 'model.layers.1.mlp.experts.54.down_proj.weight': 455606272, 'model.layers.1.mlp.experts.54.up_proj.weight': 461373440, 'model.layers.1.mlp.experts.56.gate_proj.weight': 467140608, 'model.layers.1.mlp.experts.56.down_proj.weight': 472907776, 'model.layers.1.mlp.experts.56.up_proj.weight': 478674944, 'model.layers.1.mlp.experts.58.gate_proj.weight': 484442112, 'model.layers.1.mlp.experts.58.down_proj.weight': 490209280, 'model.layers.1.mlp.experts.58.up_proj.weight': 495976448, 'model.layers.1.mlp.experts.59.gate_proj.weight': 501743616, 'model.layers.1.mlp.experts.59.down_proj.weight': 507510784, 'model.layers.1.mlp.experts.59.up_proj.weight': 513277952, 'model.layers.1.mlp.experts.62.gate_proj.weight': 519045120, 'model.layers.1.mlp.experts.62.down_proj.weight': 524812288, 'model.layers.1.mlp.experts.62.up_proj.weight': 530579456, 'model.layers.1.mlp.experts.63.gate_proj.weight': 536346624, 'model.layers.1.mlp.experts.63.down_proj.weight': 542113792, 'model.layers.1.mlp.experts.63.up_proj.weight': 547880960}, 2: {'model.layers.1.mlp.experts.3.gate_proj.weight': 0, 'model.layers.1.mlp.experts.3.down_proj.weight': 5767168, 'model.layers.1.mlp.experts.3.up_proj.weight': 11534336, 'model.layers.1.mlp.experts.8.gate_proj.weight': 17301504, 'model.layers.1.mlp.experts.8.down_proj.weight': 23068672, 'model.layers.1.mlp.experts.8.up_proj.weight': 28835840, 'model.layers.1.mlp.experts.9.gate_proj.weight': 34603008, 'model.layers.1.mlp.experts.9.down_proj.weight': 40370176, 'model.layers.1.mlp.experts.9.up_proj.weight': 46137344, 'model.layers.1.mlp.experts.11.gate_proj.weight': 51904512, 'model.layers.1.mlp.experts.11.down_proj.weight': 57671680, 'model.layers.1.mlp.experts.11.up_proj.weight': 63438848, 'model.layers.1.mlp.experts.12.gate_proj.weight': 69206016, 'model.layers.1.mlp.experts.12.down_proj.weight': 74973184, 'model.layers.1.mlp.experts.12.up_proj.weight': 80740352, 'model.layers.1.mlp.experts.13.gate_proj.weight': 86507520, 'model.layers.1.mlp.experts.13.down_proj.weight': 92274688, 'model.layers.1.mlp.experts.13.up_proj.weight': 98041856, 'model.layers.1.mlp.experts.14.gate_proj.weight': 103809024, 'model.layers.1.mlp.experts.14.down_proj.weight': 109576192, 'model.layers.1.mlp.experts.14.up_proj.weight': 115343360, 'model.layers.1.mlp.experts.17.gate_proj.weight': 121110528, 'model.layers.1.mlp.experts.17.down_proj.weight': 126877696, 'model.layers.1.mlp.experts.17.up_proj.weight': 132644864, 'model.layers.1.mlp.experts.18.gate_proj.weight': 138412032, 'model.layers.1.mlp.experts.18.down_proj.weight': 144179200, 'model.layers.1.mlp.experts.18.up_proj.weight': 149946368, 'model.layers.1.mlp.experts.20.gate_proj.weight': 155713536, 'model.layers.1.mlp.experts.20.down_proj.weight': 161480704, 'model.layers.1.mlp.experts.20.up_proj.weight': 167247872, 'model.layers.1.mlp.experts.25.gate_proj.weight': 173015040, 'model.layers.1.mlp.experts.25.down_proj.weight': 178782208, 'model.layers.1.mlp.experts.25.up_proj.weight': 184549376, 'model.layers.1.mlp.experts.26.gate_proj.weight': 190316544, 'model.layers.1.mlp.experts.26.down_proj.weight': 196083712, 'model.layers.1.mlp.experts.26.up_proj.weight': 201850880, 'model.layers.1.mlp.experts.27.gate_proj.weight': 207618048, 'model.layers.1.mlp.experts.27.down_proj.weight': 213385216, 'model.layers.1.mlp.experts.27.up_proj.weight': 219152384, 'model.layers.1.mlp.experts.31.gate_proj.weight': 224919552, 'model.layers.1.mlp.experts.31.down_proj.weight': 230686720, 'model.layers.1.mlp.experts.31.up_proj.weight': 236453888, 'model.layers.1.mlp.experts.35.gate_proj.weight': 242221056, 'model.layers.1.mlp.experts.35.down_proj.weight': 247988224, 'model.layers.1.mlp.experts.35.up_proj.weight': 253755392, 'model.layers.1.mlp.experts.36.gate_proj.weight': 259522560, 'model.layers.1.mlp.experts.36.down_proj.weight': 265289728, 'model.layers.1.mlp.experts.36.up_proj.weight': 271056896, 'model.layers.1.mlp.experts.37.gate_proj.weight': 276824064, 'model.layers.1.mlp.experts.37.down_proj.weight': 282591232, 'model.layers.1.mlp.experts.37.up_proj.weight': 288358400, 'model.layers.1.mlp.experts.39.gate_proj.weight': 294125568, 'model.layers.1.mlp.experts.39.down_proj.weight': 299892736, 'model.layers.1.mlp.experts.39.up_proj.weight': 305659904, 'model.layers.1.mlp.experts.40.gate_proj.weight': 311427072, 'model.layers.1.mlp.experts.40.down_proj.weight': 317194240, 'model.layers.1.mlp.experts.40.up_proj.weight': 322961408, 'model.layers.1.mlp.experts.41.gate_proj.weight': 328728576, 'model.layers.1.mlp.experts.41.down_proj.weight': 334495744, 'model.layers.1.mlp.experts.41.up_proj.weight': 340262912, 'model.layers.1.mlp.experts.42.gate_proj.weight': 346030080, 'model.layers.1.mlp.experts.42.down_proj.weight': 351797248, 'model.layers.1.mlp.experts.42.up_proj.weight': 357564416, 'model.layers.1.mlp.experts.45.gate_proj.weight': 363331584, 'model.layers.1.mlp.experts.45.down_proj.weight': 369098752, 'model.layers.1.mlp.experts.45.up_proj.weight': 374865920, 'model.layers.1.mlp.experts.47.gate_proj.weight': 380633088, 'model.layers.1.mlp.experts.47.down_proj.weight': 386400256, 'model.layers.1.mlp.experts.47.up_proj.weight': 392167424, 'model.layers.1.mlp.experts.49.gate_proj.weight': 397934592, 'model.layers.1.mlp.experts.49.down_proj.weight': 403701760, 'model.layers.1.mlp.experts.49.up_proj.weight': 409468928, 'model.layers.1.mlp.experts.50.gate_proj.weight': 415236096, 'model.layers.1.mlp.experts.50.down_proj.weight': 421003264, 'model.layers.1.mlp.experts.50.up_proj.weight': 426770432, 'model.layers.1.mlp.experts.51.gate_proj.weight': 432537600, 'model.layers.1.mlp.experts.51.down_proj.weight': 438304768, 'model.layers.1.mlp.experts.51.up_proj.weight': 444071936, 'model.layers.1.mlp.experts.52.gate_proj.weight': 449839104, 'model.layers.1.mlp.experts.52.down_proj.weight': 455606272, 'model.layers.1.mlp.experts.52.up_proj.weight': 461373440, 'model.layers.1.mlp.experts.53.gate_proj.weight': 467140608, 'model.layers.1.mlp.experts.53.down_proj.weight': 472907776, 'model.layers.1.mlp.experts.53.up_proj.weight': 478674944, 'model.layers.1.mlp.experts.55.gate_proj.weight': 484442112, 'model.layers.1.mlp.experts.55.down_proj.weight': 490209280, 'model.layers.1.mlp.experts.55.up_proj.weight': 495976448, 'model.layers.1.mlp.experts.57.gate_proj.weight': 501743616, 'model.layers.1.mlp.experts.57.down_proj.weight': 507510784, 'model.layers.1.mlp.experts.57.up_proj.weight': 513277952, 'model.layers.1.mlp.experts.60.gate_proj.weight': 519045120, 'model.layers.1.mlp.experts.60.down_proj.weight': 524812288, 'model.layers.1.mlp.experts.60.up_proj.weight': 530579456, 'model.layers.1.mlp.experts.61.gate_proj.weight': 536346624, 'model.layers.1.mlp.experts.61.down_proj.weight': 542113792, 'model.layers.1.mlp.experts.61.up_proj.weight': 547880960}}tensor_copy_chunks_device_map {1: [(2860515328, 5767168, 0, 0), (2866282496, 5767168, 5767168, 0), (2854748160, 5767168, 11534336, 0), (2877816832, 5767168, 17301504, 0), (2883584000, 5767168, 23068672, 0), (2872049664, 5767168, 28835840, 0), (2895118336, 5767168, 34603008, 0), (2900885504, 5767168, 40370176, 0), (2889351168, 5767168, 46137344, 0), (2929721344, 5767168, 51904512, 0), (2935488512, 5767168, 57671680, 0), (2923954176, 5767168, 63438848, 0), (2947022848, 5767168, 69206016, 0), (2952790016, 5767168, 74973184, 0), (2941255680, 5767168, 80740352, 0), (2964324352, 5767168, 86507520, 0), (2970091520, 5767168, 92274688, 0), (2958557184, 5767168, 98041856, 0), (2981625856, 5767168, 103809024, 0), (2987393024, 5767168, 109576192, 0), (2975858688, 5767168, 115343360, 0), (3033530368, 5767168, 121110528, 0), (3039297536, 5767168, 126877696, 0), (3027763200, 5767168, 132644864, 0), (3120037888, 5767168, 138412032, 0), (3125805056, 5767168, 144179200, 0), (3114270720, 5767168, 149946368, 0), (3137339392, 5767168, 155713536, 0), (3143106560, 5767168, 161480704, 0), (3131572224, 5767168, 167247872, 0), (3189243904, 5767168, 173015040, 0), (3195011072, 5767168, 178782208, 0), (3183476736, 5767168, 184549376, 0), (3223846912, 5767168, 190316544, 0), (3229614080, 5767168, 196083712, 0), (3218079744, 5767168, 201850880, 0), (3241148416, 5767168, 207618048, 0), (3246915584, 5767168, 213385216, 0), (3235381248, 5767168, 219152384, 0), (3258449920, 5767168, 224919552, 0), (3264217088, 5767168, 230686720, 0), (3252682752, 5767168, 236453888, 0), (3275751424, 5767168, 242221056, 0), (3281518592, 5767168, 247988224, 0), (3269984256, 5767168, 253755392, 0), (3344957440, 5767168, 259522560, 0), (3350724608, 5767168, 265289728, 0), (3339190272, 5767168, 271056896, 0), (3362258944, 5767168, 276824064, 0), (3368026112, 5767168, 282591232, 0), (3356491776, 5767168, 288358400, 0), (3379560448, 5767168, 294125568, 0), (3385327616, 5767168, 299892736, 0), (3373793280, 5767168, 305659904, 0), (3414163456, 5767168, 311427072, 0), (3419930624, 5767168, 317194240, 0), (3408396288, 5767168, 322961408, 0), (3431464960, 5767168, 328728576, 0), (3437232128, 5767168, 334495744, 0), (3425697792, 5767168, 340262912, 0), (3448766464, 5767168, 346030080, 0), (3454533632, 5767168, 351797248, 0), (3442999296, 5767168, 357564416, 0), (3517972480, 5767168, 363331584, 0), (3523739648, 5767168, 369098752, 0), (3512205312, 5767168, 374865920, 0), (3604480000, 5767168, 380633088, 0), (3610247168, 5767168, 386400256, 0), (3598712832, 5767168, 392167424, 0), (3621781504, 5767168, 397934592, 0), (3627548672, 5767168, 403701760, 0), (3616014336, 5767168, 409468928, 0), (3656384512, 5767168, 415236096, 0), (3662151680, 5767168, 421003264, 0), (3650617344, 5767168, 426770432, 0), (3690987520, 5767168, 432537600, 0), (3696754688, 5767168, 438304768, 0), (3685220352, 5767168, 444071936, 0), (3794796544, 5767168, 449839104, 0), (3800563712, 5767168, 455606272, 0), (3789029376, 5767168, 461373440, 0), (3829399552, 5767168, 467140608, 0), (3835166720, 5767168, 472907776, 0), (3823632384, 5767168, 478674944, 0), (3864002560, 5767168, 484442112, 0), (3869769728, 5767168, 490209280, 0), (3858235392, 5767168, 495976448, 0), (3881304064, 5767168, 501743616, 0), (3887071232, 5767168, 507510784, 0), (3875536896, 5767168, 513277952, 0), (3933208576, 5767168, 519045120, 0), (3938975744, 5767168, 524812288, 0), (3927441408, 5767168, 530579456, 0), (3950510080, 5767168, 536346624, 0), (3956277248, 5767168, 542113792, 0), (3944742912, 5767168, 547880960, 0)], 2: [(2912419840, 5767168, 0, 0), (2918187008, 5767168, 5767168, 0), (2906652672, 5767168, 11534336, 0), (2998927360, 5767168, 17301504, 0), (3004694528, 5767168, 23068672, 0), (2993160192, 5767168, 28835840, 0), (3016228864, 5767168, 34603008, 0), (3021996032, 5767168, 40370176, 0), (3010461696, 5767168, 46137344, 0), (3050831872, 5767168, 51904512, 0), (3056599040, 5767168, 57671680, 0), (3045064704, 5767168, 63438848, 0), (3068133376, 5767168, 69206016, 0), (3073900544, 5767168, 74973184, 0), (3062366208, 5767168, 80740352, 0), (3085434880, 5767168, 86507520, 0), (3091202048, 5767168, 92274688, 0), (3079667712, 5767168, 98041856, 0), (3102736384, 5767168, 103809024, 0), (3108503552, 5767168, 109576192, 0), (3096969216, 5767168, 115343360, 0), (3154640896, 5767168, 121110528, 0), (3160408064, 5767168, 126877696, 0), (3148873728, 5767168, 132644864, 0), (3171942400, 5767168, 138412032, 0), (3177709568, 5767168, 144179200, 0), (3166175232, 5767168, 149946368, 0), (3206545408, 5767168, 155713536, 0), (3212312576, 5767168, 161480704, 0), (3200778240, 5767168, 167247872, 0), (3293052928, 5767168, 173015040, 0), (3298820096, 5767168, 178782208, 0), (3287285760, 5767168, 184549376, 0), (3310354432, 5767168, 190316544, 0), (3316121600, 5767168, 196083712, 0), (3304587264, 5767168, 201850880, 0), (3327655936, 5767168, 207618048, 0), (3333423104, 5767168, 213385216, 0), (3321888768, 5767168, 219152384, 0), (3396861952, 5767168, 224919552, 0), (3402629120, 5767168, 230686720, 0), (3391094784, 5767168, 236453888, 0), (3466067968, 5767168, 242221056, 0), (3471835136, 5767168, 247988224, 0), (3460300800, 5767168, 253755392, 0), (3483369472, 5767168, 259522560, 0), (3489136640, 5767168, 265289728, 0), (3477602304, 5767168, 271056896, 0), (3500670976, 5767168, 276824064, 0), (3506438144, 5767168, 282591232, 0), (3494903808, 5767168, 288358400, 0), (3535273984, 5767168, 294125568, 0), (3541041152, 5767168, 299892736, 0), (3529506816, 5767168, 305659904, 0), (3552575488, 5767168, 311427072, 0), (3558342656, 5767168, 317194240, 0), (3546808320, 5767168, 322961408, 0), (3569876992, 5767168, 328728576, 0), (3575644160, 5767168, 334495744, 0), (3564109824, 5767168, 340262912, 0), (3587178496, 5767168, 346030080, 0), (3592945664, 5767168, 351797248, 0), (3581411328, 5767168, 357564416, 0), (3639083008, 5767168, 363331584, 0), (3644850176, 5767168, 369098752, 0), (3633315840, 5767168, 374865920, 0), (3673686016, 5767168, 380633088, 0), (3679453184, 5767168, 386400256, 0), (3667918848, 5767168, 392167424, 0), (3708289024, 5767168, 397934592, 0), (3714056192, 5767168, 403701760, 0), (3702521856, 5767168, 409468928, 0), (3725590528, 5767168, 415236096, 0), (3731357696, 5767168, 421003264, 0), (3719823360, 5767168, 426770432, 0), (3742892032, 5767168, 432537600, 0), (3748659200, 5767168, 438304768, 0), (3737124864, 5767168, 444071936, 0), (3760193536, 5767168, 449839104, 0), (3765960704, 5767168, 455606272, 0), (3754426368, 5767168, 461373440, 0), (3777495040, 5767168, 467140608, 0), (3783262208, 5767168, 472907776, 0), (3771727872, 5767168, 478674944, 0), (3812098048, 5767168, 484442112, 0), (3817865216, 5767168, 490209280, 0), (3806330880, 5767168, 495976448, 0), (3846701056, 5767168, 501743616, 0), (3852468224, 5767168, 507510784, 0), (3840933888, 5767168, 513277952, 0), (3898605568, 5767168, 519045120, 0), (3904372736, 5767168, 524812288, 0), (3892838400, 5767168, 530579456, 0), (3915907072, 5767168, 536346624, 0), (3921674240, 5767168, 542113792, 0), (3910139904, 5767168, 547880960, 0)]}cuda_memory_handles_device_map {1: <capsule object NULL at 0x7b0b88bcfcf0>, 2: <capsule object NULL at 0x7b0b8db08ff0>}
DEBUG 01-14 17:01:50.267706.267706 sllm_store_c.py:27] get device uuid map
DEBUG 01-14 17:01:50.267622.267622 sllm_store_c.py:29] call client load into gpu
DEBUG 01-14 17:01:50.267894.267894 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 87bdf1bd-0257-4ffe-8708-3223630e0213
DEBUG 01-14 17:01:50.267505.267505 client.py:106] call stub.LoadModelAsync
INFO 01-14 17:01:50.270241.270241 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 87bdf1bd-0257-4ffe-8708-3223630e0213
DEBUG 01-14 17:01:50.270291.270291 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu_multi_device cost 0.005679130554199219 seconds
DEBUG 01-14 17:01:50.271845.271845 cuda_h.py:10] start restore2model
DEBUG 01-14 17:01:50.275324.275324 cuda_h.py:19] end restore2model cost 0.004174947738647461 seconds
DEBUG 01-14 17:01:50.275897.275897 cuda_h.py:10] start experts_func_mgpu_group_pad
DEBUG 01-14 17:01:50.277690.277690 cuda_h.py:19] end experts_func_mgpu_group_pad cost 0.0014770030975341797 seconds
DEBUG 01-14 17:01:50.277448.277448 cuda_h.py:10] start experts_func_mgpu_group_pad
DEBUG 01-14 17:01:50.278693.278693 cuda_h.py:19] end experts_func_mgpu_group_pad cost 0.001547098159790039 seconds
DEBUG 01-14 17:01:50.278834.278834 cuda_h.py:10] start gpu_group_list
DEBUG 01-14 17:01:50.279222.279222 cuda_h.py:19] end gpu_group_list cost 0.00029087066650390625 seconds
DEBUG 01-14 17:01:50.279854.279854 cuda_h.py:10] start gpu_group_list
DEBUG 01-14 17:01:50.279037.279037 cuda_h.py:19] end gpu_group_list cost 0.00028061866760253906 seconds
INFO 01-14 17:01:50.281942.281942 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 87bdf1bd-0257-4ffe-8708-3223630e0213
INFO 01-14 17:01:50.321655.321655 client.py:127] Model loaded
DEBUG 01-14 17:01:50.321957.321957 cuda_h.py:19] end task_processing_mp_load cost 0.05648040771484375 seconds
DEBUG 01-14 17:01:50.321760.321760 cuda_h.py:10] start exec_together
DEBUG 01-14 17:01:50.331818.331818 mlpmodule.py:1053] mgpu group einsum cost 0.0009980201721191406 s
DEBUG 01-14 17:01:50.339491.339491 mlpmodule.py:1109] mgpu experts func einsum cost 0.01735973358154297 s
DEBUG 01-14 17:01:50.339037.339037 cuda_h.py:19] end exec_together cost 0.01749253273010254 seconds
DEBUG 01-14 17:01:50.339554.339554 cuda_h.py:10] start exec_one_by_one
DEBUG 01-14 17:01:50.339184.339184 mlpmodule.py:1178] gpu group tensors cost 0.00038933753967285156 s
DEBUG 01-14 17:01:50.341501.341501 mlpmodule.py:1220] gpu pad cost 0.0014848709106445312 s
DEBUG 01-14 17:01:50.341019.341019 mlpmodule.py:1226] start_w1
DEBUG 01-14 17:01:50.341212.341212 mlpmodule.py:1230] start_w3
DEBUG 01-14 17:01:50.341184.341184 mlpmodule.py:1236] start_w2
DEBUG 01-14 17:01:50.341294.341294 mlpmodule.py:1239] gpu group einsum cost 0.0004832744598388672 s
DEBUG 01-14 17:01:50.343878.343878 mlpmodule.py:1316] gpu experts func einsum cost 0.004480838775634766 s
DEBUG 01-14 17:01:50.344231.344231 mlpmodule.py:1178] gpu group tensors cost 0.0003876686096191406 s
DEBUG 01-14 17:01:50.346657.346657 mlpmodule.py:1220] gpu pad cost 0.0017657279968261719 s
DEBUG 01-14 17:01:50.346738.346738 mlpmodule.py:1226] start_w1
DEBUG 01-14 17:01:50.346499.346499 mlpmodule.py:1230] start_w3
DEBUG 01-14 17:01:50.346318.346318 mlpmodule.py:1236] start_w2
DEBUG 01-14 17:01:50.346720.346720 mlpmodule.py:1239] gpu group einsum cost 0.0004429817199707031 s
DEBUG 01-14 17:01:50.349763.349763 mlpmodule.py:1316] gpu experts func einsum cost 0.005200862884521484 s
DEBUG 01-14 17:01:50.349899.349899 cuda_h.py:19] end exec_one_by_one cost 0.009885311126708984 seconds
DEBUG 01-14 17:01:50.349894.349894 cuda_h.py:10] start exec_one_by_one_end_new
DEBUG 01-14 17:01:50.349272.349272 cuda_h.py:10] start gpu_group_tensor
DEBUG 01-14 17:01:50.349893.349893 cuda_h.py:19] end gpu_group_tensor cost 0.00011181831359863281 seconds
DEBUG 01-14 17:01:50.349861.349861 cuda_h.py:10] start gpu_group_tensor
DEBUG 01-14 17:01:50.349290.349290 cuda_h.py:19] end gpu_group_tensor cost 0.00011110305786132812 seconds
DEBUG 01-14 17:01:50.349736.349736 cuda_h.py:10] start gpu_group_einsum
DEBUG 01-14 17:01:50.350284.350284 cuda_h.py:19] end gpu_group_einsum cost 0.0002906322479248047 seconds
DEBUG 01-14 17:01:50.350060.350060 cuda_h.py:10] start gpu_final_hidden_states_scatter
DEBUG 01-14 17:01:50.350012.350012 cuda_h.py:10] start all_expert_weight_slices
DEBUG 01-14 17:01:50.350751.350751 cuda_h.py:19] end all_expert_weight_slices cost 0.0006880760192871094 seconds
DEBUG 01-14 17:01:50.351137.351137 cuda_h.py:10] start all_expert_output_slices
DEBUG 01-14 17:01:50.351594.351594 cuda_h.py:19] end all_expert_output_slices cost 0.00016427040100097656 seconds
DEBUG 01-14 17:01:50.351303.351303 cuda_h.py:10] start concat_expert_out
DEBUG 01-14 17:01:50.351427.351427 cuda_h.py:19] end concat_expert_out cost 0.00010061264038085938 seconds
DEBUG 01-14 17:01:50.351309.351309 cuda_h.py:10] start index_scatter
DEBUG 01-14 17:01:50.351795.351795 cuda_h.py:19] end index_scatter cost 4.482269287109375e-05 seconds
DEBUG 01-14 17:01:50.351459.351459 cuda_h.py:19] end gpu_final_hidden_states_scatter cost 0.001392364501953125 seconds
DEBUG 01-14 17:01:50.351450.351450 cuda_h.py:10] start gpu_group_einsum
DEBUG 01-14 17:01:50.352481.352481 cuda_h.py:19] end gpu_group_einsum cost 0.00029206275939941406 seconds
DEBUG 01-14 17:01:50.352496.352496 cuda_h.py:10] start gpu_final_hidden_states_scatter
DEBUG 01-14 17:01:50.352999.352999 cuda_h.py:10] start all_expert_weight_slices
DEBUG 01-14 17:01:50.353749.353749 cuda_h.py:19] end all_expert_weight_slices cost 0.0007944107055664062 seconds
DEBUG 01-14 17:01:50.353280.353280 cuda_h.py:10] start all_expert_output_slices
DEBUG 01-14 17:01:50.353831.353831 cuda_h.py:19] end all_expert_output_slices cost 0.0002033710479736328 seconds
DEBUG 01-14 17:01:50.353057.353057 cuda_h.py:10] start concat_expert_out
DEBUG 01-14 17:01:50.353565.353565 cuda_h.py:19] end concat_expert_out cost 0.00010251998901367188 seconds
DEBUG 01-14 17:01:50.353831.353831 cuda_h.py:10] start index_scatter
DEBUG 01-14 17:01:50.353875.353875 cuda_h.py:19] end index_scatter cost 6.866455078125e-05 seconds
DEBUG 01-14 17:01:50.353198.353198 cuda_h.py:19] end gpu_final_hidden_states_scatter cost 0.001750946044921875 seconds
DEBUG 01-14 17:01:50.353042.353042 cuda_h.py:19] end exec_one_by_one_end_new cost 0.004613637924194336 seconds
DEBUG 01-14 17:01:50.353268.353268 cuda_h.py:10] start exec_one_by_one_end_new2
DEBUG 01-14 17:01:50.353978.353978 cuda_h.py:10] start gpu_group_einsum_mp_multi_list
DEBUG 01-14 17:01:50.354913.354913 cuda_h.py:10] start gpu_group_tensor
DEBUG 01-14 17:01:50.354520.354520 cuda_h.py:19] end gpu_group_tensor cost 0.00010752677917480469 seconds
DEBUG 01-14 17:01:50.354799.354799 cuda_h.py:10] start gpu_group_tensor
DEBUG 01-14 17:01:50.354015.354015 cuda_h.py:19] end gpu_group_tensor cost 9.846687316894531e-05 seconds
DEBUG 01-14 17:01:50.354064.354064 cuda_h.py:10] start gpu_group_einsum
DEBUG 01-14 17:01:50.354776.354776 cuda_h.py:19] end gpu_group_einsum cost 0.0002753734588623047 seconds
DEBUG 01-14 17:01:50.354183.354183 cuda_h.py:10] start gpu_group_einsum
DEBUG 01-14 17:01:50.355472.355472 cuda_h.py:19] end gpu_group_einsum cost 0.0002760887145996094 seconds
DEBUG 01-14 17:01:50.355309.355309 cuda_h.py:10] start gpu_final_hidden_states_scatter
DEBUG 01-14 17:01:50.355126.355126 cuda_h.py:10] start all_expert_outputs_slices
DEBUG 01-14 17:01:50.355717.355717 cuda_h.py:19] end all_expert_outputs_slices cost 0.00019288063049316406 seconds
DEBUG 01-14 17:01:50.355181.355181 cuda_h.py:10] start concat_expert_out
DEBUG 01-14 17:01:50.355038.355038 cuda_h.py:19] end concat_expert_out cost 4.5299530029296875e-05 seconds
DEBUG 01-14 17:01:50.355298.355298 cuda_h.py:10] start index_scatter
DEBUG 01-14 17:01:50.355969.355969 cuda_h.py:19] end index_scatter cost 4.4345855712890625e-05 seconds
DEBUG 01-14 17:01:50.355339.355339 cuda_h.py:19] end gpu_final_hidden_states_scatter cost 0.0006494522094726562 seconds
DEBUG 01-14 17:01:50.355487.355487 cuda_h.py:10] start gpu_final_hidden_states_scatter
DEBUG 01-14 17:01:50.355509.355509 cuda_h.py:10] start all_expert_outputs_slices
DEBUG 01-14 17:01:50.356422.356422 cuda_h.py:19] end all_expert_outputs_slices cost 0.00015592575073242188 seconds
DEBUG 01-14 17:01:50.356502.356502 cuda_h.py:10] start concat_expert_out
DEBUG 01-14 17:01:50.356551.356551 cuda_h.py:19] end concat_expert_out cost 4.7206878662109375e-05 seconds
DEBUG 01-14 17:01:50.356473.356473 cuda_h.py:10] start index_scatter
DEBUG 01-14 17:01:50.356820.356820 cuda_h.py:19] end index_scatter cost 5.054473876953125e-05 seconds
DEBUG 01-14 17:01:50.356696.356696 cuda_h.py:19] end gpu_final_hidden_states_scatter cost 0.0004756450653076172 seconds
DEBUG 01-14 17:01:50.356301.356301 cuda_h.py:19] end exec_one_by_one_end_new2 cost 0.0025272369384765625 seconds
DEBUG 01-14 17:01:50.358218.358218 cuda_h.py:10] start task_processing_mp_load
DEBUG 01-14 17:01:50.359903.359903 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu_multi_device
DEBUG 01-14 17:01:50.361148.361148 cuda_memory_view.py:520] tensor_device_offsets_device_map {1: {'model.layers.1.mlp.experts.0.gate_proj.weight': 0, 'model.layers.1.mlp.experts.0.down_proj.weight': 5767168, 'model.layers.1.mlp.experts.0.up_proj.weight': 11534336, 'model.layers.1.mlp.experts.1.gate_proj.weight': 17301504, 'model.layers.1.mlp.experts.1.down_proj.weight': 23068672, 'model.layers.1.mlp.experts.1.up_proj.weight': 28835840, 'model.layers.1.mlp.experts.2.gate_proj.weight': 34603008, 'model.layers.1.mlp.experts.2.down_proj.weight': 40370176, 'model.layers.1.mlp.experts.2.up_proj.weight': 46137344, 'model.layers.1.mlp.experts.4.gate_proj.weight': 51904512, 'model.layers.1.mlp.experts.4.down_proj.weight': 57671680, 'model.layers.1.mlp.experts.4.up_proj.weight': 63438848, 'model.layers.1.mlp.experts.5.gate_proj.weight': 69206016, 'model.layers.1.mlp.experts.5.down_proj.weight': 74973184, 'model.layers.1.mlp.experts.5.up_proj.weight': 80740352, 'model.layers.1.mlp.experts.6.gate_proj.weight': 86507520, 'model.layers.1.mlp.experts.6.down_proj.weight': 92274688, 'model.layers.1.mlp.experts.6.up_proj.weight': 98041856, 'model.layers.1.mlp.experts.7.gate_proj.weight': 103809024, 'model.layers.1.mlp.experts.7.down_proj.weight': 109576192, 'model.layers.1.mlp.experts.7.up_proj.weight': 115343360, 'model.layers.1.mlp.experts.10.gate_proj.weight': 121110528, 'model.layers.1.mlp.experts.10.down_proj.weight': 126877696, 'model.layers.1.mlp.experts.10.up_proj.weight': 132644864, 'model.layers.1.mlp.experts.15.gate_proj.weight': 138412032, 'model.layers.1.mlp.experts.15.down_proj.weight': 144179200, 'model.layers.1.mlp.experts.15.up_proj.weight': 149946368, 'model.layers.1.mlp.experts.16.gate_proj.weight': 155713536, 'model.layers.1.mlp.experts.16.down_proj.weight': 161480704, 'model.layers.1.mlp.experts.16.up_proj.weight': 167247872, 'model.layers.1.mlp.experts.19.gate_proj.weight': 173015040, 'model.layers.1.mlp.experts.19.down_proj.weight': 178782208, 'model.layers.1.mlp.experts.19.up_proj.weight': 184549376, 'model.layers.1.mlp.experts.21.gate_proj.weight': 190316544, 'model.layers.1.mlp.experts.21.down_proj.weight': 196083712, 'model.layers.1.mlp.experts.21.up_proj.weight': 201850880, 'model.layers.1.mlp.experts.22.gate_proj.weight': 207618048, 'model.layers.1.mlp.experts.22.down_proj.weight': 213385216, 'model.layers.1.mlp.experts.22.up_proj.weight': 219152384, 'model.layers.1.mlp.experts.23.gate_proj.weight': 224919552, 'model.layers.1.mlp.experts.23.down_proj.weight': 230686720, 'model.layers.1.mlp.experts.23.up_proj.weight': 236453888, 'model.layers.1.mlp.experts.24.gate_proj.weight': 242221056, 'model.layers.1.mlp.experts.24.down_proj.weight': 247988224, 'model.layers.1.mlp.experts.24.up_proj.weight': 253755392, 'model.layers.1.mlp.experts.28.gate_proj.weight': 259522560, 'model.layers.1.mlp.experts.28.down_proj.weight': 265289728, 'model.layers.1.mlp.experts.28.up_proj.weight': 271056896, 'model.layers.1.mlp.experts.29.gate_proj.weight': 276824064, 'model.layers.1.mlp.experts.29.down_proj.weight': 282591232, 'model.layers.1.mlp.experts.29.up_proj.weight': 288358400, 'model.layers.1.mlp.experts.30.gate_proj.weight': 294125568, 'model.layers.1.mlp.experts.30.down_proj.weight': 299892736, 'model.layers.1.mlp.experts.30.up_proj.weight': 305659904, 'model.layers.1.mlp.experts.32.gate_proj.weight': 311427072, 'model.layers.1.mlp.experts.32.down_proj.weight': 317194240, 'model.layers.1.mlp.experts.32.up_proj.weight': 322961408, 'model.layers.1.mlp.experts.33.gate_proj.weight': 328728576, 'model.layers.1.mlp.experts.33.down_proj.weight': 334495744, 'model.layers.1.mlp.experts.33.up_proj.weight': 340262912, 'model.layers.1.mlp.experts.34.gate_proj.weight': 346030080, 'model.layers.1.mlp.experts.34.down_proj.weight': 351797248, 'model.layers.1.mlp.experts.34.up_proj.weight': 357564416, 'model.layers.1.mlp.experts.38.gate_proj.weight': 363331584, 'model.layers.1.mlp.experts.38.down_proj.weight': 369098752, 'model.layers.1.mlp.experts.38.up_proj.weight': 374865920, 'model.layers.1.mlp.experts.43.gate_proj.weight': 380633088, 'model.layers.1.mlp.experts.43.down_proj.weight': 386400256, 'model.layers.1.mlp.experts.43.up_proj.weight': 392167424, 'model.layers.1.mlp.experts.44.gate_proj.weight': 397934592, 'model.layers.1.mlp.experts.44.down_proj.weight': 403701760, 'model.layers.1.mlp.experts.44.up_proj.weight': 409468928, 'model.layers.1.mlp.experts.46.gate_proj.weight': 415236096, 'model.layers.1.mlp.experts.46.down_proj.weight': 421003264, 'model.layers.1.mlp.experts.46.up_proj.weight': 426770432, 'model.layers.1.mlp.experts.48.gate_proj.weight': 432537600, 'model.layers.1.mlp.experts.48.down_proj.weight': 438304768, 'model.layers.1.mlp.experts.48.up_proj.weight': 444071936, 'model.layers.1.mlp.experts.54.gate_proj.weight': 449839104, 'model.layers.1.mlp.experts.54.down_proj.weight': 455606272, 'model.layers.1.mlp.experts.54.up_proj.weight': 461373440, 'model.layers.1.mlp.experts.56.gate_proj.weight': 467140608, 'model.layers.1.mlp.experts.56.down_proj.weight': 472907776, 'model.layers.1.mlp.experts.56.up_proj.weight': 478674944, 'model.layers.1.mlp.experts.58.gate_proj.weight': 484442112, 'model.layers.1.mlp.experts.58.down_proj.weight': 490209280, 'model.layers.1.mlp.experts.58.up_proj.weight': 495976448, 'model.layers.1.mlp.experts.59.gate_proj.weight': 501743616, 'model.layers.1.mlp.experts.59.down_proj.weight': 507510784, 'model.layers.1.mlp.experts.59.up_proj.weight': 513277952, 'model.layers.1.mlp.experts.62.gate_proj.weight': 519045120, 'model.layers.1.mlp.experts.62.down_proj.weight': 524812288, 'model.layers.1.mlp.experts.62.up_proj.weight': 530579456, 'model.layers.1.mlp.experts.63.gate_proj.weight': 536346624, 'model.layers.1.mlp.experts.63.down_proj.weight': 542113792, 'model.layers.1.mlp.experts.63.up_proj.weight': 547880960}, 2: {'model.layers.1.mlp.experts.3.gate_proj.weight': 0, 'model.layers.1.mlp.experts.3.down_proj.weight': 5767168, 'model.layers.1.mlp.experts.3.up_proj.weight': 11534336, 'model.layers.1.mlp.experts.8.gate_proj.weight': 17301504, 'model.layers.1.mlp.experts.8.down_proj.weight': 23068672, 'model.layers.1.mlp.experts.8.up_proj.weight': 28835840, 'model.layers.1.mlp.experts.9.gate_proj.weight': 34603008, 'model.layers.1.mlp.experts.9.down_proj.weight': 40370176, 'model.layers.1.mlp.experts.9.up_proj.weight': 46137344, 'model.layers.1.mlp.experts.11.gate_proj.weight': 51904512, 'model.layers.1.mlp.experts.11.down_proj.weight': 57671680, 'model.layers.1.mlp.experts.11.up_proj.weight': 63438848, 'model.layers.1.mlp.experts.12.gate_proj.weight': 69206016, 'model.layers.1.mlp.experts.12.down_proj.weight': 74973184, 'model.layers.1.mlp.experts.12.up_proj.weight': 80740352, 'model.layers.1.mlp.experts.13.gate_proj.weight': 86507520, 'model.layers.1.mlp.experts.13.down_proj.weight': 92274688, 'model.layers.1.mlp.experts.13.up_proj.weight': 98041856, 'model.layers.1.mlp.experts.14.gate_proj.weight': 103809024, 'model.layers.1.mlp.experts.14.down_proj.weight': 109576192, 'model.layers.1.mlp.experts.14.up_proj.weight': 115343360, 'model.layers.1.mlp.experts.17.gate_proj.weight': 121110528, 'model.layers.1.mlp.experts.17.down_proj.weight': 126877696, 'model.layers.1.mlp.experts.17.up_proj.weight': 132644864, 'model.layers.1.mlp.experts.18.gate_proj.weight': 138412032, 'model.layers.1.mlp.experts.18.down_proj.weight': 144179200, 'model.layers.1.mlp.experts.18.up_proj.weight': 149946368, 'model.layers.1.mlp.experts.20.gate_proj.weight': 155713536, 'model.layers.1.mlp.experts.20.down_proj.weight': 161480704, 'model.layers.1.mlp.experts.20.up_proj.weight': 167247872, 'model.layers.1.mlp.experts.25.gate_proj.weight': 173015040, 'model.layers.1.mlp.experts.25.down_proj.weight': 178782208, 'model.layers.1.mlp.experts.25.up_proj.weight': 184549376, 'model.layers.1.mlp.experts.26.gate_proj.weight': 190316544, 'model.layers.1.mlp.experts.26.down_proj.weight': 196083712, 'model.layers.1.mlp.experts.26.up_proj.weight': 201850880, 'model.layers.1.mlp.experts.27.gate_proj.weight': 207618048, 'model.layers.1.mlp.experts.27.down_proj.weight': 213385216, 'model.layers.1.mlp.experts.27.up_proj.weight': 219152384, 'model.layers.1.mlp.experts.31.gate_proj.weight': 224919552, 'model.layers.1.mlp.experts.31.down_proj.weight': 230686720, 'model.layers.1.mlp.experts.31.up_proj.weight': 236453888, 'model.layers.1.mlp.experts.35.gate_proj.weight': 242221056, 'model.layers.1.mlp.experts.35.down_proj.weight': 247988224, 'model.layers.1.mlp.experts.35.up_proj.weight': 253755392, 'model.layers.1.mlp.experts.36.gate_proj.weight': 259522560, 'model.layers.1.mlp.experts.36.down_proj.weight': 265289728, 'model.layers.1.mlp.experts.36.up_proj.weight': 271056896, 'model.layers.1.mlp.experts.37.gate_proj.weight': 276824064, 'model.layers.1.mlp.experts.37.down_proj.weight': 282591232, 'model.layers.1.mlp.experts.37.up_proj.weight': 288358400, 'model.layers.1.mlp.experts.39.gate_proj.weight': 294125568, 'model.layers.1.mlp.experts.39.down_proj.weight': 299892736, 'model.layers.1.mlp.experts.39.up_proj.weight': 305659904, 'model.layers.1.mlp.experts.40.gate_proj.weight': 311427072, 'model.layers.1.mlp.experts.40.down_proj.weight': 317194240, 'model.layers.1.mlp.experts.40.up_proj.weight': 322961408, 'model.layers.1.mlp.experts.41.gate_proj.weight': 328728576, 'model.layers.1.mlp.experts.41.down_proj.weight': 334495744, 'model.layers.1.mlp.experts.41.up_proj.weight': 340262912, 'model.layers.1.mlp.experts.42.gate_proj.weight': 346030080, 'model.layers.1.mlp.experts.42.down_proj.weight': 351797248, 'model.layers.1.mlp.experts.42.up_proj.weight': 357564416, 'model.layers.1.mlp.experts.45.gate_proj.weight': 363331584, 'model.layers.1.mlp.experts.45.down_proj.weight': 369098752, 'model.layers.1.mlp.experts.45.up_proj.weight': 374865920, 'model.layers.1.mlp.experts.47.gate_proj.weight': 380633088, 'model.layers.1.mlp.experts.47.down_proj.weight': 386400256, 'model.layers.1.mlp.experts.47.up_proj.weight': 392167424, 'model.layers.1.mlp.experts.49.gate_proj.weight': 397934592, 'model.layers.1.mlp.experts.49.down_proj.weight': 403701760, 'model.layers.1.mlp.experts.49.up_proj.weight': 409468928, 'model.layers.1.mlp.experts.50.gate_proj.weight': 415236096, 'model.layers.1.mlp.experts.50.down_proj.weight': 421003264, 'model.layers.1.mlp.experts.50.up_proj.weight': 426770432, 'model.layers.1.mlp.experts.51.gate_proj.weight': 432537600, 'model.layers.1.mlp.experts.51.down_proj.weight': 438304768, 'model.layers.1.mlp.experts.51.up_proj.weight': 444071936, 'model.layers.1.mlp.experts.52.gate_proj.weight': 449839104, 'model.layers.1.mlp.experts.52.down_proj.weight': 455606272, 'model.layers.1.mlp.experts.52.up_proj.weight': 461373440, 'model.layers.1.mlp.experts.53.gate_proj.weight': 467140608, 'model.layers.1.mlp.experts.53.down_proj.weight': 472907776, 'model.layers.1.mlp.experts.53.up_proj.weight': 478674944, 'model.layers.1.mlp.experts.55.gate_proj.weight': 484442112, 'model.layers.1.mlp.experts.55.down_proj.weight': 490209280, 'model.layers.1.mlp.experts.55.up_proj.weight': 495976448, 'model.layers.1.mlp.experts.57.gate_proj.weight': 501743616, 'model.layers.1.mlp.experts.57.down_proj.weight': 507510784, 'model.layers.1.mlp.experts.57.up_proj.weight': 513277952, 'model.layers.1.mlp.experts.60.gate_proj.weight': 519045120, 'model.layers.1.mlp.experts.60.down_proj.weight': 524812288, 'model.layers.1.mlp.experts.60.up_proj.weight': 530579456, 'model.layers.1.mlp.experts.61.gate_proj.weight': 536346624, 'model.layers.1.mlp.experts.61.down_proj.weight': 542113792, 'model.layers.1.mlp.experts.61.up_proj.weight': 547880960}}tensor_copy_chunks_device_map {1: [(2860515328, 5767168, 0, 0), (2866282496, 5767168, 5767168, 0), (2854748160, 5767168, 11534336, 0), (2877816832, 5767168, 17301504, 0), (2883584000, 5767168, 23068672, 0), (2872049664, 5767168, 28835840, 0), (2895118336, 5767168, 34603008, 0), (2900885504, 5767168, 40370176, 0), (2889351168, 5767168, 46137344, 0), (2929721344, 5767168, 51904512, 0), (2935488512, 5767168, 57671680, 0), (2923954176, 5767168, 63438848, 0), (2947022848, 5767168, 69206016, 0), (2952790016, 5767168, 74973184, 0), (2941255680, 5767168, 80740352, 0), (2964324352, 5767168, 86507520, 0), (2970091520, 5767168, 92274688, 0), (2958557184, 5767168, 98041856, 0), (2981625856, 5767168, 103809024, 0), (2987393024, 5767168, 109576192, 0), (2975858688, 5767168, 115343360, 0), (3033530368, 5767168, 121110528, 0), (3039297536, 5767168, 126877696, 0), (3027763200, 5767168, 132644864, 0), (3120037888, 5767168, 138412032, 0), (3125805056, 5767168, 144179200, 0), (3114270720, 5767168, 149946368, 0), (3137339392, 5767168, 155713536, 0), (3143106560, 5767168, 161480704, 0), (3131572224, 5767168, 167247872, 0), (3189243904, 5767168, 173015040, 0), (3195011072, 5767168, 178782208, 0), (3183476736, 5767168, 184549376, 0), (3223846912, 5767168, 190316544, 0), (3229614080, 5767168, 196083712, 0), (3218079744, 5767168, 201850880, 0), (3241148416, 5767168, 207618048, 0), (3246915584, 5767168, 213385216, 0), (3235381248, 5767168, 219152384, 0), (3258449920, 5767168, 224919552, 0), (3264217088, 5767168, 230686720, 0), (3252682752, 5767168, 236453888, 0), (3275751424, 5767168, 242221056, 0), (3281518592, 5767168, 247988224, 0), (3269984256, 5767168, 253755392, 0), (3344957440, 5767168, 259522560, 0), (3350724608, 5767168, 265289728, 0), (3339190272, 5767168, 271056896, 0), (3362258944, 5767168, 276824064, 0), (3368026112, 5767168, 282591232, 0), (3356491776, 5767168, 288358400, 0), (3379560448, 5767168, 294125568, 0), (3385327616, 5767168, 299892736, 0), (3373793280, 5767168, 305659904, 0), (3414163456, 5767168, 311427072, 0), (3419930624, 5767168, 317194240, 0), (3408396288, 5767168, 322961408, 0), (3431464960, 5767168, 328728576, 0), (3437232128, 5767168, 334495744, 0), (3425697792, 5767168, 340262912, 0), (3448766464, 5767168, 346030080, 0), (3454533632, 5767168, 351797248, 0), (3442999296, 5767168, 357564416, 0), (3517972480, 5767168, 363331584, 0), (3523739648, 5767168, 369098752, 0), (3512205312, 5767168, 374865920, 0), (3604480000, 5767168, 380633088, 0), (3610247168, 5767168, 386400256, 0), (3598712832, 5767168, 392167424, 0), (3621781504, 5767168, 397934592, 0), (3627548672, 5767168, 403701760, 0), (3616014336, 5767168, 409468928, 0), (3656384512, 5767168, 415236096, 0), (3662151680, 5767168, 421003264, 0), (3650617344, 5767168, 426770432, 0), (3690987520, 5767168, 432537600, 0), (3696754688, 5767168, 438304768, 0), (3685220352, 5767168, 444071936, 0), (3794796544, 5767168, 449839104, 0), (3800563712, 5767168, 455606272, 0), (3789029376, 5767168, 461373440, 0), (3829399552, 5767168, 467140608, 0), (3835166720, 5767168, 472907776, 0), (3823632384, 5767168, 478674944, 0), (3864002560, 5767168, 484442112, 0), (3869769728, 5767168, 490209280, 0), (3858235392, 5767168, 495976448, 0), (3881304064, 5767168, 501743616, 0), (3887071232, 5767168, 507510784, 0), (3875536896, 5767168, 513277952, 0), (3933208576, 5767168, 519045120, 0), (3938975744, 5767168, 524812288, 0), (3927441408, 5767168, 530579456, 0), (3950510080, 5767168, 536346624, 0), (3956277248, 5767168, 542113792, 0), (3944742912, 5767168, 547880960, 0)], 2: [(2912419840, 5767168, 0, 0), (2918187008, 5767168, 5767168, 0), (2906652672, 5767168, 11534336, 0), (2998927360, 5767168, 17301504, 0), (3004694528, 5767168, 23068672, 0), (2993160192, 5767168, 28835840, 0), (3016228864, 5767168, 34603008, 0), (3021996032, 5767168, 40370176, 0), (3010461696, 5767168, 46137344, 0), (3050831872, 5767168, 51904512, 0), (3056599040, 5767168, 57671680, 0), (3045064704, 5767168, 63438848, 0), (3068133376, 5767168, 69206016, 0), (3073900544, 5767168, 74973184, 0), (3062366208, 5767168, 80740352, 0), (3085434880, 5767168, 86507520, 0), (3091202048, 5767168, 92274688, 0), (3079667712, 5767168, 98041856, 0), (3102736384, 5767168, 103809024, 0), (3108503552, 5767168, 109576192, 0), (3096969216, 5767168, 115343360, 0), (3154640896, 5767168, 121110528, 0), (3160408064, 5767168, 126877696, 0), (3148873728, 5767168, 132644864, 0), (3171942400, 5767168, 138412032, 0), (3177709568, 5767168, 144179200, 0), (3166175232, 5767168, 149946368, 0), (3206545408, 5767168, 155713536, 0), (3212312576, 5767168, 161480704, 0), (3200778240, 5767168, 167247872, 0), (3293052928, 5767168, 173015040, 0), (3298820096, 5767168, 178782208, 0), (3287285760, 5767168, 184549376, 0), (3310354432, 5767168, 190316544, 0), (3316121600, 5767168, 196083712, 0), (3304587264, 5767168, 201850880, 0), (3327655936, 5767168, 207618048, 0), (3333423104, 5767168, 213385216, 0), (3321888768, 5767168, 219152384, 0), (3396861952, 5767168, 224919552, 0), (3402629120, 5767168, 230686720, 0), (3391094784, 5767168, 236453888, 0), (3466067968, 5767168, 242221056, 0), (3471835136, 5767168, 247988224, 0), (3460300800, 5767168, 253755392, 0), (3483369472, 5767168, 259522560, 0), (3489136640, 5767168, 265289728, 0), (3477602304, 5767168, 271056896, 0), (3500670976, 5767168, 276824064, 0), (3506438144, 5767168, 282591232, 0), (3494903808, 5767168, 288358400, 0), (3535273984, 5767168, 294125568, 0), (3541041152, 5767168, 299892736, 0), (3529506816, 5767168, 305659904, 0), (3552575488, 5767168, 311427072, 0), (3558342656, 5767168, 317194240, 0), (3546808320, 5767168, 322961408, 0), (3569876992, 5767168, 328728576, 0), (3575644160, 5767168, 334495744, 0), (3564109824, 5767168, 340262912, 0), (3587178496, 5767168, 346030080, 0), (3592945664, 5767168, 351797248, 0), (3581411328, 5767168, 357564416, 0), (3639083008, 5767168, 363331584, 0), (3644850176, 5767168, 369098752, 0), (3633315840, 5767168, 374865920, 0), (3673686016, 5767168, 380633088, 0), (3679453184, 5767168, 386400256, 0), (3667918848, 5767168, 392167424, 0), (3708289024, 5767168, 397934592, 0), (3714056192, 5767168, 403701760, 0), (3702521856, 5767168, 409468928, 0), (3725590528, 5767168, 415236096, 0), (3731357696, 5767168, 421003264, 0), (3719823360, 5767168, 426770432, 0), (3742892032, 5767168, 432537600, 0), (3748659200, 5767168, 438304768, 0), (3737124864, 5767168, 444071936, 0), (3760193536, 5767168, 449839104, 0), (3765960704, 5767168, 455606272, 0), (3754426368, 5767168, 461373440, 0), (3777495040, 5767168, 467140608, 0), (3783262208, 5767168, 472907776, 0), (3771727872, 5767168, 478674944, 0), (3812098048, 5767168, 484442112, 0), (3817865216, 5767168, 490209280, 0), (3806330880, 5767168, 495976448, 0), (3846701056, 5767168, 501743616, 0), (3852468224, 5767168, 507510784, 0), (3840933888, 5767168, 513277952, 0), (3898605568, 5767168, 519045120, 0), (3904372736, 5767168, 524812288, 0), (3892838400, 5767168, 530579456, 0), (3915907072, 5767168, 536346624, 0), (3921674240, 5767168, 542113792, 0), (3910139904, 5767168, 547880960, 0)]}cuda_memory_handles_device_map {1: <capsule object NULL at 0x7b0b8db08ff0>, 2: <capsule object NULL at 0x7b0b88bcfcf0>}
DEBUG 01-14 17:01:50.361146.361146 sllm_store_c.py:27] get device uuid map
DEBUG 01-14 17:01:50.361823.361823 sllm_store_c.py:29] call client load into gpu
DEBUG 01-14 17:01:50.361334.361334 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, 6fe872fc-3ac5-4576-b5ef-d5b43d46743b
DEBUG 01-14 17:01:50.361634.361634 client.py:106] call stub.LoadModelAsync
INFO 01-14 17:01:50.364368.364368 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, 6fe872fc-3ac5-4576-b5ef-d5b43d46743b
DEBUG 01-14 17:01:50.364795.364795 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu_multi_device cost 0.005644321441650391 seconds
DEBUG 01-14 17:01:50.364256.364256 cuda_h.py:10] start restore2model
DEBUG 01-14 17:01:50.368128.368128 cuda_h.py:19] end restore2model cost 0.004041433334350586 seconds
DEBUG 01-14 17:01:50.369529.369529 cuda_h.py:10] start experts_func_mgpu_group_pad
DEBUG 01-14 17:01:50.370056.370056 cuda_h.py:19] end experts_func_mgpu_group_pad cost 0.0014553070068359375 seconds
DEBUG 01-14 17:01:50.370052.370052 cuda_h.py:10] start experts_func_mgpu_group_pad
DEBUG 01-14 17:01:50.372121.372121 cuda_h.py:19] end experts_func_mgpu_group_pad cost 0.0016274452209472656 seconds
DEBUG 01-14 17:01:50.372507.372507 cuda_h.py:10] start gpu_group_list
DEBUG 01-14 17:01:50.372048.372048 cuda_h.py:19] end gpu_group_list cost 0.0002970695495605469 seconds
DEBUG 01-14 17:01:50.372634.372634 cuda_h.py:10] start gpu_group_list
DEBUG 01-14 17:01:50.373393.373393 cuda_h.py:19] end gpu_group_list cost 0.00028324127197265625 seconds
INFO 01-14 17:01:50.375443.375443 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, 6fe872fc-3ac5-4576-b5ef-d5b43d46743b
INFO 01-14 17:01:50.415229.415229 client.py:127] Model loaded
DEBUG 01-14 17:01:50.415015.415015 cuda_h.py:19] end task_processing_mp_load cost 0.056563377380371094 seconds
DEBUG 01-14 17:01:50.415057.415057 cuda_h.py:10] start exec_together
DEBUG 01-14 17:01:50.428900.428900 mlpmodule.py:1053] mgpu group einsum cost 0.0016021728515625 s
DEBUG 01-14 17:01:50.434813.434813 mlpmodule.py:1109] mgpu experts func einsum cost 0.018930673599243164 s
DEBUG 01-14 17:01:50.434816.434816 cuda_h.py:19] end exec_together cost 0.01907825469970703 seconds
DEBUG 01-14 17:01:50.434156.434156 cuda_h.py:10] start exec_one_by_one
DEBUG 01-14 17:01:50.435108.435108 mlpmodule.py:1178] gpu group tensors cost 0.0005099773406982422 s
DEBUG 01-14 17:01:50.437518.437518 mlpmodule.py:1220] gpu pad cost 0.0018961429595947266 s
DEBUG 01-14 17:01:50.437236.437236 mlpmodule.py:1226] start_w1
DEBUG 01-14 17:01:50.437766.437766 mlpmodule.py:1230] start_w3
DEBUG 01-14 17:01:50.437626.437626 mlpmodule.py:1236] start_w2
DEBUG 01-14 17:01:50.437108.437108 mlpmodule.py:1239] gpu group einsum cost 0.0005376338958740234 s
DEBUG 01-14 17:01:50.440721.440721 mlpmodule.py:1316] gpu experts func einsum cost 0.005562543869018555 s
DEBUG 01-14 17:01:50.440513.440513 mlpmodule.py:1178] gpu group tensors cost 0.0004093647003173828 s
DEBUG 01-14 17:01:50.442148.442148 mlpmodule.py:1220] gpu pad cost 0.0017151832580566406 s
DEBUG 01-14 17:01:50.442985.442985 mlpmodule.py:1226] start_w1
DEBUG 01-14 17:01:50.442884.442884 mlpmodule.py:1230] start_w3
DEBUG 01-14 17:01:50.443412.443412 mlpmodule.py:1236] start_w2
DEBUG 01-14 17:01:50.443430.443430 mlpmodule.py:1239] gpu group einsum cost 0.0004329681396484375 s
DEBUG 01-14 17:01:50.445996.445996 mlpmodule.py:1316] gpu experts func einsum cost 0.005152702331542969 s
DEBUG 01-14 17:01:50.445741.445741 cuda_h.py:19] end exec_one_by_one cost 0.010934591293334961 seconds
DEBUG 01-14 17:01:50.445590.445590 cuda_h.py:10] start exec_one_by_one_end_new
DEBUG 01-14 17:01:50.445300.445300 cuda_h.py:10] start gpu_group_tensor
DEBUG 01-14 17:01:50.446483.446483 cuda_h.py:19] end gpu_group_tensor cost 0.00010824203491210938 seconds
DEBUG 01-14 17:01:50.446782.446782 cuda_h.py:10] start gpu_group_tensor
DEBUG 01-14 17:01:50.446058.446058 cuda_h.py:19] end gpu_group_tensor cost 0.00010466575622558594 seconds
DEBUG 01-14 17:01:50.446697.446697 cuda_h.py:10] start gpu_group_einsum
DEBUG 01-14 17:01:50.446138.446138 cuda_h.py:19] end gpu_group_einsum cost 0.0002841949462890625 seconds
DEBUG 01-14 17:01:50.446915.446915 cuda_h.py:10] start gpu_final_hidden_states_scatter
DEBUG 01-14 17:01:50.446323.446323 cuda_h.py:10] start all_expert_weight_slices
DEBUG 01-14 17:01:50.447883.447883 cuda_h.py:19] end all_expert_weight_slices cost 0.0006616115570068359 seconds
DEBUG 01-14 17:01:50.447361.447361 cuda_h.py:10] start all_expert_output_slices
DEBUG 01-14 17:01:50.447950.447950 cuda_h.py:19] end all_expert_output_slices cost 0.00015664100646972656 seconds
DEBUG 01-14 17:01:50.447745.447745 cuda_h.py:10] start concat_expert_out
DEBUG 01-14 17:01:50.447339.447339 cuda_h.py:19] end concat_expert_out cost 9.560585021972656e-05 seconds
DEBUG 01-14 17:01:50.447029.447029 cuda_h.py:10] start index_scatter
DEBUG 01-14 17:01:50.447701.447701 cuda_h.py:19] end index_scatter cost 4.267692565917969e-05 seconds
DEBUG 01-14 17:01:50.447503.447503 cuda_h.py:19] end gpu_final_hidden_states_scatter cost 0.0013206005096435547 seconds
DEBUG 01-14 17:01:50.448441.448441 cuda_h.py:10] start gpu_group_einsum
DEBUG 01-14 17:01:50.448784.448784 cuda_h.py:19] end gpu_group_einsum cost 0.0003120899200439453 seconds
DEBUG 01-14 17:01:50.448229.448229 cuda_h.py:10] start gpu_final_hidden_states_scatter
DEBUG 01-14 17:01:50.448686.448686 cuda_h.py:10] start all_expert_weight_slices
DEBUG 01-14 17:01:50.449414.449414 cuda_h.py:19] end all_expert_weight_slices cost 0.0007436275482177734 seconds
DEBUG 01-14 17:01:50.449038.449038 cuda_h.py:10] start all_expert_output_slices
DEBUG 01-14 17:01:50.449013.449013 cuda_h.py:19] end all_expert_output_slices cost 0.0001990795135498047 seconds
DEBUG 01-14 17:01:50.449100.449100 cuda_h.py:10] start concat_expert_out
DEBUG 01-14 17:01:50.449084.449084 cuda_h.py:19] end concat_expert_out cost 0.00010251998901367188 seconds
DEBUG 01-14 17:01:50.449397.449397 cuda_h.py:10] start index_scatter
DEBUG 01-14 17:01:50.450798.450798 cuda_h.py:19] end index_scatter cost 4.649162292480469e-05 seconds
DEBUG 01-14 17:01:50.450651.450651 cuda_h.py:19] end gpu_final_hidden_states_scatter cost 0.0016818046569824219 seconds
DEBUG 01-14 17:01:50.450171.450171 cuda_h.py:19] end exec_one_by_one_end_new cost 0.004476785659790039 seconds
DEBUG 01-14 17:01:50.450066.450066 cuda_h.py:10] start exec_one_by_one_end_new2
DEBUG 01-14 17:01:50.450683.450683 cuda_h.py:10] start gpu_group_einsum_mp_multi_list
DEBUG 01-14 17:01:50.450340.450340 cuda_h.py:10] start gpu_group_tensor
DEBUG 01-14 17:01:50.450041.450041 cuda_h.py:19] end gpu_group_tensor cost 0.00012302398681640625 seconds
DEBUG 01-14 17:01:50.450558.450558 cuda_h.py:10] start gpu_group_tensor
DEBUG 01-14 17:01:50.450874.450874 cuda_h.py:19] end gpu_group_tensor cost 9.894371032714844e-05 seconds
DEBUG 01-14 17:01:50.450830.450830 cuda_h.py:10] start gpu_group_einsum
DEBUG 01-14 17:01:50.451748.451748 cuda_h.py:19] end gpu_group_einsum cost 0.0002834796905517578 seconds
DEBUG 01-14 17:01:50.451923.451923 cuda_h.py:10] start gpu_group_einsum
DEBUG 01-14 17:01:50.451948.451948 cuda_h.py:19] end gpu_group_einsum cost 0.00028896331787109375 seconds
DEBUG 01-14 17:01:50.451646.451646 cuda_h.py:10] start gpu_final_hidden_states_scatter
DEBUG 01-14 17:01:50.451556.451556 cuda_h.py:10] start all_expert_outputs_slices
DEBUG 01-14 17:01:50.451113.451113 cuda_h.py:19] end all_expert_outputs_slices cost 0.00020241737365722656 seconds
DEBUG 01-14 17:01:50.452055.452055 cuda_h.py:10] start concat_expert_out
DEBUG 01-14 17:01:50.452726.452726 cuda_h.py:19] end concat_expert_out cost 4.839897155761719e-05 seconds
DEBUG 01-14 17:01:50.452556.452556 cuda_h.py:10] start index_scatter
DEBUG 01-14 17:01:50.452419.452419 cuda_h.py:19] end index_scatter cost 4.506111145019531e-05 seconds
DEBUG 01-14 17:01:50.452888.452888 cuda_h.py:19] end gpu_final_hidden_states_scatter cost 0.0006644725799560547 seconds
DEBUG 01-14 17:01:50.452931.452931 cuda_h.py:10] start gpu_final_hidden_states_scatter
DEBUG 01-14 17:01:50.452099.452099 cuda_h.py:10] start all_expert_outputs_slices
DEBUG 01-14 17:01:50.452602.452602 cuda_h.py:19] end all_expert_outputs_slices cost 0.00016498565673828125 seconds
DEBUG 01-14 17:01:50.452351.452351 cuda_h.py:10] start concat_expert_out
DEBUG 01-14 17:01:50.452930.452930 cuda_h.py:19] end concat_expert_out cost 4.9591064453125e-05 seconds
DEBUG 01-14 17:01:50.452952.452952 cuda_h.py:10] start index_scatter
DEBUG 01-14 17:01:50.452384.452384 cuda_h.py:19] end index_scatter cost 4.4345855712890625e-05 seconds
DEBUG 01-14 17:01:50.452379.452379 cuda_h.py:19] end gpu_final_hidden_states_scatter cost 0.0004730224609375 seconds
DEBUG 01-14 17:01:50.453692.453692 cuda_h.py:19] end exec_one_by_one_end_new2 cost 0.002650737762451172 seconds
DEBUG 01-14 17:01:50.455293.455293 cuda_h.py:10] start task_processing_mp_load
DEBUG 01-14 17:01:50.455270.455270 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu_multi_device
DEBUG 01-14 17:01:50.457271.457271 cuda_memory_view.py:520] tensor_device_offsets_device_map {1: {'model.layers.1.mlp.experts.0.gate_proj.weight': 0, 'model.layers.1.mlp.experts.0.down_proj.weight': 5767168, 'model.layers.1.mlp.experts.0.up_proj.weight': 11534336, 'model.layers.1.mlp.experts.1.gate_proj.weight': 17301504, 'model.layers.1.mlp.experts.1.down_proj.weight': 23068672, 'model.layers.1.mlp.experts.1.up_proj.weight': 28835840, 'model.layers.1.mlp.experts.2.gate_proj.weight': 34603008, 'model.layers.1.mlp.experts.2.down_proj.weight': 40370176, 'model.layers.1.mlp.experts.2.up_proj.weight': 46137344, 'model.layers.1.mlp.experts.4.gate_proj.weight': 51904512, 'model.layers.1.mlp.experts.4.down_proj.weight': 57671680, 'model.layers.1.mlp.experts.4.up_proj.weight': 63438848, 'model.layers.1.mlp.experts.5.gate_proj.weight': 69206016, 'model.layers.1.mlp.experts.5.down_proj.weight': 74973184, 'model.layers.1.mlp.experts.5.up_proj.weight': 80740352, 'model.layers.1.mlp.experts.6.gate_proj.weight': 86507520, 'model.layers.1.mlp.experts.6.down_proj.weight': 92274688, 'model.layers.1.mlp.experts.6.up_proj.weight': 98041856, 'model.layers.1.mlp.experts.7.gate_proj.weight': 103809024, 'model.layers.1.mlp.experts.7.down_proj.weight': 109576192, 'model.layers.1.mlp.experts.7.up_proj.weight': 115343360, 'model.layers.1.mlp.experts.10.gate_proj.weight': 121110528, 'model.layers.1.mlp.experts.10.down_proj.weight': 126877696, 'model.layers.1.mlp.experts.10.up_proj.weight': 132644864, 'model.layers.1.mlp.experts.15.gate_proj.weight': 138412032, 'model.layers.1.mlp.experts.15.down_proj.weight': 144179200, 'model.layers.1.mlp.experts.15.up_proj.weight': 149946368, 'model.layers.1.mlp.experts.16.gate_proj.weight': 155713536, 'model.layers.1.mlp.experts.16.down_proj.weight': 161480704, 'model.layers.1.mlp.experts.16.up_proj.weight': 167247872, 'model.layers.1.mlp.experts.19.gate_proj.weight': 173015040, 'model.layers.1.mlp.experts.19.down_proj.weight': 178782208, 'model.layers.1.mlp.experts.19.up_proj.weight': 184549376, 'model.layers.1.mlp.experts.21.gate_proj.weight': 190316544, 'model.layers.1.mlp.experts.21.down_proj.weight': 196083712, 'model.layers.1.mlp.experts.21.up_proj.weight': 201850880, 'model.layers.1.mlp.experts.22.gate_proj.weight': 207618048, 'model.layers.1.mlp.experts.22.down_proj.weight': 213385216, 'model.layers.1.mlp.experts.22.up_proj.weight': 219152384, 'model.layers.1.mlp.experts.23.gate_proj.weight': 224919552, 'model.layers.1.mlp.experts.23.down_proj.weight': 230686720, 'model.layers.1.mlp.experts.23.up_proj.weight': 236453888, 'model.layers.1.mlp.experts.24.gate_proj.weight': 242221056, 'model.layers.1.mlp.experts.24.down_proj.weight': 247988224, 'model.layers.1.mlp.experts.24.up_proj.weight': 253755392, 'model.layers.1.mlp.experts.28.gate_proj.weight': 259522560, 'model.layers.1.mlp.experts.28.down_proj.weight': 265289728, 'model.layers.1.mlp.experts.28.up_proj.weight': 271056896, 'model.layers.1.mlp.experts.29.gate_proj.weight': 276824064, 'model.layers.1.mlp.experts.29.down_proj.weight': 282591232, 'model.layers.1.mlp.experts.29.up_proj.weight': 288358400, 'model.layers.1.mlp.experts.30.gate_proj.weight': 294125568, 'model.layers.1.mlp.experts.30.down_proj.weight': 299892736, 'model.layers.1.mlp.experts.30.up_proj.weight': 305659904, 'model.layers.1.mlp.experts.32.gate_proj.weight': 311427072, 'model.layers.1.mlp.experts.32.down_proj.weight': 317194240, 'model.layers.1.mlp.experts.32.up_proj.weight': 322961408, 'model.layers.1.mlp.experts.33.gate_proj.weight': 328728576, 'model.layers.1.mlp.experts.33.down_proj.weight': 334495744, 'model.layers.1.mlp.experts.33.up_proj.weight': 340262912, 'model.layers.1.mlp.experts.34.gate_proj.weight': 346030080, 'model.layers.1.mlp.experts.34.down_proj.weight': 351797248, 'model.layers.1.mlp.experts.34.up_proj.weight': 357564416, 'model.layers.1.mlp.experts.38.gate_proj.weight': 363331584, 'model.layers.1.mlp.experts.38.down_proj.weight': 369098752, 'model.layers.1.mlp.experts.38.up_proj.weight': 374865920, 'model.layers.1.mlp.experts.43.gate_proj.weight': 380633088, 'model.layers.1.mlp.experts.43.down_proj.weight': 386400256, 'model.layers.1.mlp.experts.43.up_proj.weight': 392167424, 'model.layers.1.mlp.experts.44.gate_proj.weight': 397934592, 'model.layers.1.mlp.experts.44.down_proj.weight': 403701760, 'model.layers.1.mlp.experts.44.up_proj.weight': 409468928, 'model.layers.1.mlp.experts.46.gate_proj.weight': 415236096, 'model.layers.1.mlp.experts.46.down_proj.weight': 421003264, 'model.layers.1.mlp.experts.46.up_proj.weight': 426770432, 'model.layers.1.mlp.experts.48.gate_proj.weight': 432537600, 'model.layers.1.mlp.experts.48.down_proj.weight': 438304768, 'model.layers.1.mlp.experts.48.up_proj.weight': 444071936, 'model.layers.1.mlp.experts.54.gate_proj.weight': 449839104, 'model.layers.1.mlp.experts.54.down_proj.weight': 455606272, 'model.layers.1.mlp.experts.54.up_proj.weight': 461373440, 'model.layers.1.mlp.experts.56.gate_proj.weight': 467140608, 'model.layers.1.mlp.experts.56.down_proj.weight': 472907776, 'model.layers.1.mlp.experts.56.up_proj.weight': 478674944, 'model.layers.1.mlp.experts.58.gate_proj.weight': 484442112, 'model.layers.1.mlp.experts.58.down_proj.weight': 490209280, 'model.layers.1.mlp.experts.58.up_proj.weight': 495976448, 'model.layers.1.mlp.experts.59.gate_proj.weight': 501743616, 'model.layers.1.mlp.experts.59.down_proj.weight': 507510784, 'model.layers.1.mlp.experts.59.up_proj.weight': 513277952, 'model.layers.1.mlp.experts.62.gate_proj.weight': 519045120, 'model.layers.1.mlp.experts.62.down_proj.weight': 524812288, 'model.layers.1.mlp.experts.62.up_proj.weight': 530579456, 'model.layers.1.mlp.experts.63.gate_proj.weight': 536346624, 'model.layers.1.mlp.experts.63.down_proj.weight': 542113792, 'model.layers.1.mlp.experts.63.up_proj.weight': 547880960}, 2: {'model.layers.1.mlp.experts.3.gate_proj.weight': 0, 'model.layers.1.mlp.experts.3.down_proj.weight': 5767168, 'model.layers.1.mlp.experts.3.up_proj.weight': 11534336, 'model.layers.1.mlp.experts.8.gate_proj.weight': 17301504, 'model.layers.1.mlp.experts.8.down_proj.weight': 23068672, 'model.layers.1.mlp.experts.8.up_proj.weight': 28835840, 'model.layers.1.mlp.experts.9.gate_proj.weight': 34603008, 'model.layers.1.mlp.experts.9.down_proj.weight': 40370176, 'model.layers.1.mlp.experts.9.up_proj.weight': 46137344, 'model.layers.1.mlp.experts.11.gate_proj.weight': 51904512, 'model.layers.1.mlp.experts.11.down_proj.weight': 57671680, 'model.layers.1.mlp.experts.11.up_proj.weight': 63438848, 'model.layers.1.mlp.experts.12.gate_proj.weight': 69206016, 'model.layers.1.mlp.experts.12.down_proj.weight': 74973184, 'model.layers.1.mlp.experts.12.up_proj.weight': 80740352, 'model.layers.1.mlp.experts.13.gate_proj.weight': 86507520, 'model.layers.1.mlp.experts.13.down_proj.weight': 92274688, 'model.layers.1.mlp.experts.13.up_proj.weight': 98041856, 'model.layers.1.mlp.experts.14.gate_proj.weight': 103809024, 'model.layers.1.mlp.experts.14.down_proj.weight': 109576192, 'model.layers.1.mlp.experts.14.up_proj.weight': 115343360, 'model.layers.1.mlp.experts.17.gate_proj.weight': 121110528, 'model.layers.1.mlp.experts.17.down_proj.weight': 126877696, 'model.layers.1.mlp.experts.17.up_proj.weight': 132644864, 'model.layers.1.mlp.experts.18.gate_proj.weight': 138412032, 'model.layers.1.mlp.experts.18.down_proj.weight': 144179200, 'model.layers.1.mlp.experts.18.up_proj.weight': 149946368, 'model.layers.1.mlp.experts.20.gate_proj.weight': 155713536, 'model.layers.1.mlp.experts.20.down_proj.weight': 161480704, 'model.layers.1.mlp.experts.20.up_proj.weight': 167247872, 'model.layers.1.mlp.experts.25.gate_proj.weight': 173015040, 'model.layers.1.mlp.experts.25.down_proj.weight': 178782208, 'model.layers.1.mlp.experts.25.up_proj.weight': 184549376, 'model.layers.1.mlp.experts.26.gate_proj.weight': 190316544, 'model.layers.1.mlp.experts.26.down_proj.weight': 196083712, 'model.layers.1.mlp.experts.26.up_proj.weight': 201850880, 'model.layers.1.mlp.experts.27.gate_proj.weight': 207618048, 'model.layers.1.mlp.experts.27.down_proj.weight': 213385216, 'model.layers.1.mlp.experts.27.up_proj.weight': 219152384, 'model.layers.1.mlp.experts.31.gate_proj.weight': 224919552, 'model.layers.1.mlp.experts.31.down_proj.weight': 230686720, 'model.layers.1.mlp.experts.31.up_proj.weight': 236453888, 'model.layers.1.mlp.experts.35.gate_proj.weight': 242221056, 'model.layers.1.mlp.experts.35.down_proj.weight': 247988224, 'model.layers.1.mlp.experts.35.up_proj.weight': 253755392, 'model.layers.1.mlp.experts.36.gate_proj.weight': 259522560, 'model.layers.1.mlp.experts.36.down_proj.weight': 265289728, 'model.layers.1.mlp.experts.36.up_proj.weight': 271056896, 'model.layers.1.mlp.experts.37.gate_proj.weight': 276824064, 'model.layers.1.mlp.experts.37.down_proj.weight': 282591232, 'model.layers.1.mlp.experts.37.up_proj.weight': 288358400, 'model.layers.1.mlp.experts.39.gate_proj.weight': 294125568, 'model.layers.1.mlp.experts.39.down_proj.weight': 299892736, 'model.layers.1.mlp.experts.39.up_proj.weight': 305659904, 'model.layers.1.mlp.experts.40.gate_proj.weight': 311427072, 'model.layers.1.mlp.experts.40.down_proj.weight': 317194240, 'model.layers.1.mlp.experts.40.up_proj.weight': 322961408, 'model.layers.1.mlp.experts.41.gate_proj.weight': 328728576, 'model.layers.1.mlp.experts.41.down_proj.weight': 334495744, 'model.layers.1.mlp.experts.41.up_proj.weight': 340262912, 'model.layers.1.mlp.experts.42.gate_proj.weight': 346030080, 'model.layers.1.mlp.experts.42.down_proj.weight': 351797248, 'model.layers.1.mlp.experts.42.up_proj.weight': 357564416, 'model.layers.1.mlp.experts.45.gate_proj.weight': 363331584, 'model.layers.1.mlp.experts.45.down_proj.weight': 369098752, 'model.layers.1.mlp.experts.45.up_proj.weight': 374865920, 'model.layers.1.mlp.experts.47.gate_proj.weight': 380633088, 'model.layers.1.mlp.experts.47.down_proj.weight': 386400256, 'model.layers.1.mlp.experts.47.up_proj.weight': 392167424, 'model.layers.1.mlp.experts.49.gate_proj.weight': 397934592, 'model.layers.1.mlp.experts.49.down_proj.weight': 403701760, 'model.layers.1.mlp.experts.49.up_proj.weight': 409468928, 'model.layers.1.mlp.experts.50.gate_proj.weight': 415236096, 'model.layers.1.mlp.experts.50.down_proj.weight': 421003264, 'model.layers.1.mlp.experts.50.up_proj.weight': 426770432, 'model.layers.1.mlp.experts.51.gate_proj.weight': 432537600, 'model.layers.1.mlp.experts.51.down_proj.weight': 438304768, 'model.layers.1.mlp.experts.51.up_proj.weight': 444071936, 'model.layers.1.mlp.experts.52.gate_proj.weight': 449839104, 'model.layers.1.mlp.experts.52.down_proj.weight': 455606272, 'model.layers.1.mlp.experts.52.up_proj.weight': 461373440, 'model.layers.1.mlp.experts.53.gate_proj.weight': 467140608, 'model.layers.1.mlp.experts.53.down_proj.weight': 472907776, 'model.layers.1.mlp.experts.53.up_proj.weight': 478674944, 'model.layers.1.mlp.experts.55.gate_proj.weight': 484442112, 'model.layers.1.mlp.experts.55.down_proj.weight': 490209280, 'model.layers.1.mlp.experts.55.up_proj.weight': 495976448, 'model.layers.1.mlp.experts.57.gate_proj.weight': 501743616, 'model.layers.1.mlp.experts.57.down_proj.weight': 507510784, 'model.layers.1.mlp.experts.57.up_proj.weight': 513277952, 'model.layers.1.mlp.experts.60.gate_proj.weight': 519045120, 'model.layers.1.mlp.experts.60.down_proj.weight': 524812288, 'model.layers.1.mlp.experts.60.up_proj.weight': 530579456, 'model.layers.1.mlp.experts.61.gate_proj.weight': 536346624, 'model.layers.1.mlp.experts.61.down_proj.weight': 542113792, 'model.layers.1.mlp.experts.61.up_proj.weight': 547880960}}tensor_copy_chunks_device_map {1: [(2860515328, 5767168, 0, 0), (2866282496, 5767168, 5767168, 0), (2854748160, 5767168, 11534336, 0), (2877816832, 5767168, 17301504, 0), (2883584000, 5767168, 23068672, 0), (2872049664, 5767168, 28835840, 0), (2895118336, 5767168, 34603008, 0), (2900885504, 5767168, 40370176, 0), (2889351168, 5767168, 46137344, 0), (2929721344, 5767168, 51904512, 0), (2935488512, 5767168, 57671680, 0), (2923954176, 5767168, 63438848, 0), (2947022848, 5767168, 69206016, 0), (2952790016, 5767168, 74973184, 0), (2941255680, 5767168, 80740352, 0), (2964324352, 5767168, 86507520, 0), (2970091520, 5767168, 92274688, 0), (2958557184, 5767168, 98041856, 0), (2981625856, 5767168, 103809024, 0), (2987393024, 5767168, 109576192, 0), (2975858688, 5767168, 115343360, 0), (3033530368, 5767168, 121110528, 0), (3039297536, 5767168, 126877696, 0), (3027763200, 5767168, 132644864, 0), (3120037888, 5767168, 138412032, 0), (3125805056, 5767168, 144179200, 0), (3114270720, 5767168, 149946368, 0), (3137339392, 5767168, 155713536, 0), (3143106560, 5767168, 161480704, 0), (3131572224, 5767168, 167247872, 0), (3189243904, 5767168, 173015040, 0), (3195011072, 5767168, 178782208, 0), (3183476736, 5767168, 184549376, 0), (3223846912, 5767168, 190316544, 0), (3229614080, 5767168, 196083712, 0), (3218079744, 5767168, 201850880, 0), (3241148416, 5767168, 207618048, 0), (3246915584, 5767168, 213385216, 0), (3235381248, 5767168, 219152384, 0), (3258449920, 5767168, 224919552, 0), (3264217088, 5767168, 230686720, 0), (3252682752, 5767168, 236453888, 0), (3275751424, 5767168, 242221056, 0), (3281518592, 5767168, 247988224, 0), (3269984256, 5767168, 253755392, 0), (3344957440, 5767168, 259522560, 0), (3350724608, 5767168, 265289728, 0), (3339190272, 5767168, 271056896, 0), (3362258944, 5767168, 276824064, 0), (3368026112, 5767168, 282591232, 0), (3356491776, 5767168, 288358400, 0), (3379560448, 5767168, 294125568, 0), (3385327616, 5767168, 299892736, 0), (3373793280, 5767168, 305659904, 0), (3414163456, 5767168, 311427072, 0), (3419930624, 5767168, 317194240, 0), (3408396288, 5767168, 322961408, 0), (3431464960, 5767168, 328728576, 0), (3437232128, 5767168, 334495744, 0), (3425697792, 5767168, 340262912, 0), (3448766464, 5767168, 346030080, 0), (3454533632, 5767168, 351797248, 0), (3442999296, 5767168, 357564416, 0), (3517972480, 5767168, 363331584, 0), (3523739648, 5767168, 369098752, 0), (3512205312, 5767168, 374865920, 0), (3604480000, 5767168, 380633088, 0), (3610247168, 5767168, 386400256, 0), (3598712832, 5767168, 392167424, 0), (3621781504, 5767168, 397934592, 0), (3627548672, 5767168, 403701760, 0), (3616014336, 5767168, 409468928, 0), (3656384512, 5767168, 415236096, 0), (3662151680, 5767168, 421003264, 0), (3650617344, 5767168, 426770432, 0), (3690987520, 5767168, 432537600, 0), (3696754688, 5767168, 438304768, 0), (3685220352, 5767168, 444071936, 0), (3794796544, 5767168, 449839104, 0), (3800563712, 5767168, 455606272, 0), (3789029376, 5767168, 461373440, 0), (3829399552, 5767168, 467140608, 0), (3835166720, 5767168, 472907776, 0), (3823632384, 5767168, 478674944, 0), (3864002560, 5767168, 484442112, 0), (3869769728, 5767168, 490209280, 0), (3858235392, 5767168, 495976448, 0), (3881304064, 5767168, 501743616, 0), (3887071232, 5767168, 507510784, 0), (3875536896, 5767168, 513277952, 0), (3933208576, 5767168, 519045120, 0), (3938975744, 5767168, 524812288, 0), (3927441408, 5767168, 530579456, 0), (3950510080, 5767168, 536346624, 0), (3956277248, 5767168, 542113792, 0), (3944742912, 5767168, 547880960, 0)], 2: [(2912419840, 5767168, 0, 0), (2918187008, 5767168, 5767168, 0), (2906652672, 5767168, 11534336, 0), (2998927360, 5767168, 17301504, 0), (3004694528, 5767168, 23068672, 0), (2993160192, 5767168, 28835840, 0), (3016228864, 5767168, 34603008, 0), (3021996032, 5767168, 40370176, 0), (3010461696, 5767168, 46137344, 0), (3050831872, 5767168, 51904512, 0), (3056599040, 5767168, 57671680, 0), (3045064704, 5767168, 63438848, 0), (3068133376, 5767168, 69206016, 0), (3073900544, 5767168, 74973184, 0), (3062366208, 5767168, 80740352, 0), (3085434880, 5767168, 86507520, 0), (3091202048, 5767168, 92274688, 0), (3079667712, 5767168, 98041856, 0), (3102736384, 5767168, 103809024, 0), (3108503552, 5767168, 109576192, 0), (3096969216, 5767168, 115343360, 0), (3154640896, 5767168, 121110528, 0), (3160408064, 5767168, 126877696, 0), (3148873728, 5767168, 132644864, 0), (3171942400, 5767168, 138412032, 0), (3177709568, 5767168, 144179200, 0), (3166175232, 5767168, 149946368, 0), (3206545408, 5767168, 155713536, 0), (3212312576, 5767168, 161480704, 0), (3200778240, 5767168, 167247872, 0), (3293052928, 5767168, 173015040, 0), (3298820096, 5767168, 178782208, 0), (3287285760, 5767168, 184549376, 0), (3310354432, 5767168, 190316544, 0), (3316121600, 5767168, 196083712, 0), (3304587264, 5767168, 201850880, 0), (3327655936, 5767168, 207618048, 0), (3333423104, 5767168, 213385216, 0), (3321888768, 5767168, 219152384, 0), (3396861952, 5767168, 224919552, 0), (3402629120, 5767168, 230686720, 0), (3391094784, 5767168, 236453888, 0), (3466067968, 5767168, 242221056, 0), (3471835136, 5767168, 247988224, 0), (3460300800, 5767168, 253755392, 0), (3483369472, 5767168, 259522560, 0), (3489136640, 5767168, 265289728, 0), (3477602304, 5767168, 271056896, 0), (3500670976, 5767168, 276824064, 0), (3506438144, 5767168, 282591232, 0), (3494903808, 5767168, 288358400, 0), (3535273984, 5767168, 294125568, 0), (3541041152, 5767168, 299892736, 0), (3529506816, 5767168, 305659904, 0), (3552575488, 5767168, 311427072, 0), (3558342656, 5767168, 317194240, 0), (3546808320, 5767168, 322961408, 0), (3569876992, 5767168, 328728576, 0), (3575644160, 5767168, 334495744, 0), (3564109824, 5767168, 340262912, 0), (3587178496, 5767168, 346030080, 0), (3592945664, 5767168, 351797248, 0), (3581411328, 5767168, 357564416, 0), (3639083008, 5767168, 363331584, 0), (3644850176, 5767168, 369098752, 0), (3633315840, 5767168, 374865920, 0), (3673686016, 5767168, 380633088, 0), (3679453184, 5767168, 386400256, 0), (3667918848, 5767168, 392167424, 0), (3708289024, 5767168, 397934592, 0), (3714056192, 5767168, 403701760, 0), (3702521856, 5767168, 409468928, 0), (3725590528, 5767168, 415236096, 0), (3731357696, 5767168, 421003264, 0), (3719823360, 5767168, 426770432, 0), (3742892032, 5767168, 432537600, 0), (3748659200, 5767168, 438304768, 0), (3737124864, 5767168, 444071936, 0), (3760193536, 5767168, 449839104, 0), (3765960704, 5767168, 455606272, 0), (3754426368, 5767168, 461373440, 0), (3777495040, 5767168, 467140608, 0), (3783262208, 5767168, 472907776, 0), (3771727872, 5767168, 478674944, 0), (3812098048, 5767168, 484442112, 0), (3817865216, 5767168, 490209280, 0), (3806330880, 5767168, 495976448, 0), (3846701056, 5767168, 501743616, 0), (3852468224, 5767168, 507510784, 0), (3840933888, 5767168, 513277952, 0), (3898605568, 5767168, 519045120, 0), (3904372736, 5767168, 524812288, 0), (3892838400, 5767168, 530579456, 0), (3915907072, 5767168, 536346624, 0), (3921674240, 5767168, 542113792, 0), (3910139904, 5767168, 547880960, 0)]}cuda_memory_handles_device_map {1: <capsule object NULL at 0x7b0b88bcfcf0>, 2: <capsule object NULL at 0x7b0b8db08ff0>}
DEBUG 01-14 17:01:50.457123.457123 sllm_store_c.py:27] get device uuid map
DEBUG 01-14 17:01:50.457847.457847 sllm_store_c.py:29] call client load into gpu
DEBUG 01-14 17:01:50.457689.457689 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, d934f04d-ba24-46c3-ba4f-840be9277d72
DEBUG 01-14 17:01:50.458153.458153 client.py:106] call stub.LoadModelAsync
INFO 01-14 17:01:50.463667.463667 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, d934f04d-ba24-46c3-ba4f-840be9277d72
DEBUG 01-14 17:01:50.464923.464923 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu_multi_device cost 0.008978605270385742 seconds
DEBUG 01-14 17:01:50.464868.464868 cuda_h.py:10] start restore2model
DEBUG 01-14 17:01:50.468059.468059 cuda_h.py:19] end restore2model cost 0.004098653793334961 seconds
DEBUG 01-14 17:01:50.469990.469990 cuda_h.py:10] start experts_func_mgpu_group_pad
DEBUG 01-14 17:01:50.470464.470464 cuda_h.py:19] end experts_func_mgpu_group_pad cost 0.0014522075653076172 seconds
DEBUG 01-14 17:01:50.470791.470791 cuda_h.py:10] start experts_func_mgpu_group_pad
DEBUG 01-14 17:01:50.472844.472844 cuda_h.py:19] end experts_func_mgpu_group_pad cost 0.0015459060668945312 seconds
DEBUG 01-14 17:01:50.472317.472317 cuda_h.py:10] start gpu_group_list
DEBUG 01-14 17:01:50.472222.472222 cuda_h.py:19] end gpu_group_list cost 0.00032067298889160156 seconds
DEBUG 01-14 17:01:50.472192.472192 cuda_h.py:10] start gpu_group_list
DEBUG 01-14 17:01:50.473673.473673 cuda_h.py:19] end gpu_group_list cost 0.00028705596923828125 seconds
INFO 01-14 17:01:50.474651.474651 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, d934f04d-ba24-46c3-ba4f-840be9277d72
INFO 01-14 17:01:50.513547.513547 client.py:127] Model loaded
DEBUG 01-14 17:01:50.513935.513935 cuda_h.py:19] end task_processing_mp_load cost 0.057859182357788086 seconds
DEBUG 01-14 17:01:50.513208.513208 cuda_h.py:10] start exec_together
DEBUG 01-14 17:01:50.522898.522898 mlpmodule.py:1053] mgpu group einsum cost 0.0008623600006103516 s
DEBUG 01-14 17:01:50.529038.529038 mlpmodule.py:1109] mgpu experts func einsum cost 0.016383647918701172 s
DEBUG 01-14 17:01:50.529493.529493 cuda_h.py:19] end exec_together cost 0.016551494598388672 seconds
DEBUG 01-14 17:01:50.530031.530031 cuda_h.py:10] start exec_one_by_one
DEBUG 01-14 17:01:50.530973.530973 mlpmodule.py:1178] gpu group tensors cost 0.0005986690521240234 s
DEBUG 01-14 17:01:50.532277.532277 mlpmodule.py:1220] gpu pad cost 0.0014965534210205078 s
DEBUG 01-14 17:01:50.532173.532173 mlpmodule.py:1226] start_w1
DEBUG 01-14 17:01:50.532380.532380 mlpmodule.py:1230] start_w3
DEBUG 01-14 17:01:50.532398.532398 mlpmodule.py:1236] start_w2
DEBUG 01-14 17:01:50.532468.532468 mlpmodule.py:1239] gpu group einsum cost 0.0004978179931640625 s
DEBUG 01-14 17:01:50.534400.534400 mlpmodule.py:1316] gpu experts func einsum cost 0.0048487186431884766 s
DEBUG 01-14 17:01:50.535654.535654 mlpmodule.py:1178] gpu group tensors cost 0.000385284423828125 s
DEBUG 01-14 17:01:50.537404.537404 mlpmodule.py:1220] gpu pad cost 0.0017635822296142578 s
DEBUG 01-14 17:01:50.537439.537439 mlpmodule.py:1226] start_w1
DEBUG 01-14 17:01:50.537591.537591 mlpmodule.py:1230] start_w3
DEBUG 01-14 17:01:50.537179.537179 mlpmodule.py:1236] start_w2
DEBUG 01-14 17:01:50.537216.537216 mlpmodule.py:1239] gpu group einsum cost 0.00046753883361816406 s
DEBUG 01-14 17:01:50.540789.540789 mlpmodule.py:1316] gpu experts func einsum cost 0.005186557769775391 s
DEBUG 01-14 17:01:50.540427.540427 cuda_h.py:19] end exec_one_by_one cost 0.01022481918334961 seconds
DEBUG 01-14 17:01:50.540515.540515 cuda_h.py:10] start exec_one_by_one_end_new
DEBUG 01-14 17:01:50.540271.540271 cuda_h.py:10] start gpu_group_tensor
DEBUG 01-14 17:01:50.540501.540501 cuda_h.py:19] end gpu_group_tensor cost 0.00013446807861328125 seconds
DEBUG 01-14 17:01:50.540662.540662 cuda_h.py:10] start gpu_group_tensor
DEBUG 01-14 17:01:50.540077.540077 cuda_h.py:19] end gpu_group_tensor cost 0.0001010894775390625 seconds
DEBUG 01-14 17:01:50.540523.540523 cuda_h.py:10] start gpu_group_einsum
DEBUG 01-14 17:01:50.541534.541534 cuda_h.py:19] end gpu_group_einsum cost 0.0002834796905517578 seconds
DEBUG 01-14 17:01:50.541026.541026 cuda_h.py:10] start gpu_final_hidden_states_scatter
DEBUG 01-14 17:01:50.541341.541341 cuda_h.py:10] start all_expert_weight_slices
DEBUG 01-14 17:01:50.541908.541908 cuda_h.py:19] end all_expert_weight_slices cost 0.0006670951843261719 seconds
DEBUG 01-14 17:01:50.541386.541386 cuda_h.py:10] start all_expert_output_slices
DEBUG 01-14 17:01:50.542346.542346 cuda_h.py:19] end all_expert_output_slices cost 0.00015616416931152344 seconds
DEBUG 01-14 17:01:50.542664.542664 cuda_h.py:10] start concat_expert_out
DEBUG 01-14 17:01:50.542874.542874 cuda_h.py:19] end concat_expert_out cost 9.298324584960938e-05 seconds
DEBUG 01-14 17:01:50.542134.542134 cuda_h.py:10] start index_scatter
DEBUG 01-14 17:01:50.542043.542043 cuda_h.py:19] end index_scatter cost 4.267692565917969e-05 seconds
DEBUG 01-14 17:01:50.542753.542753 cuda_h.py:19] end gpu_final_hidden_states_scatter cost 0.0013186931610107422 seconds
DEBUG 01-14 17:01:50.542214.542214 cuda_h.py:10] start gpu_group_einsum
DEBUG 01-14 17:01:50.542940.542940 cuda_h.py:19] end gpu_group_einsum cost 0.00027942657470703125 seconds
DEBUG 01-14 17:01:50.542525.542525 cuda_h.py:10] start gpu_final_hidden_states_scatter
DEBUG 01-14 17:01:50.543399.543399 cuda_h.py:10] start all_expert_weight_slices
DEBUG 01-14 17:01:50.543079.543079 cuda_h.py:19] end all_expert_weight_slices cost 0.0007109642028808594 seconds
DEBUG 01-14 17:01:50.543034.543034 cuda_h.py:10] start all_expert_output_slices
DEBUG 01-14 17:01:50.544187.544187 cuda_h.py:19] end all_expert_output_slices cost 0.0001888275146484375 seconds
DEBUG 01-14 17:01:50.544744.544744 cuda_h.py:10] start concat_expert_out
DEBUG 01-14 17:01:50.544391.544391 cuda_h.py:19] end concat_expert_out cost 9.703636169433594e-05 seconds
DEBUG 01-14 17:01:50.544512.544512 cuda_h.py:10] start index_scatter
DEBUG 01-14 17:01:50.544767.544767 cuda_h.py:19] end index_scatter cost 7.796287536621094e-05 seconds
DEBUG 01-14 17:01:50.544959.544959 cuda_h.py:19] end gpu_final_hidden_states_scatter cost 0.0016567707061767578 seconds
DEBUG 01-14 17:01:50.544525.544525 cuda_h.py:19] end exec_one_by_one_end_new cost 0.004443168640136719 seconds
DEBUG 01-14 17:01:50.544566.544566 cuda_h.py:10] start exec_one_by_one_end_new2
DEBUG 01-14 17:01:50.544898.544898 cuda_h.py:10] start gpu_group_einsum_mp_multi_list
DEBUG 01-14 17:01:50.544501.544501 cuda_h.py:10] start gpu_group_tensor
DEBUG 01-14 17:01:50.544500.544500 cuda_h.py:19] end gpu_group_tensor cost 0.00011324882507324219 seconds
DEBUG 01-14 17:01:50.545686.545686 cuda_h.py:10] start gpu_group_tensor
DEBUG 01-14 17:01:50.545002.545002 cuda_h.py:19] end gpu_group_tensor cost 0.00010180473327636719 seconds
DEBUG 01-14 17:01:50.545673.545673 cuda_h.py:10] start gpu_group_einsum
DEBUG 01-14 17:01:50.545459.545459 cuda_h.py:19] end gpu_group_einsum cost 0.00029277801513671875 seconds
DEBUG 01-14 17:01:50.545277.545277 cuda_h.py:10] start gpu_group_einsum
DEBUG 01-14 17:01:50.546480.546480 cuda_h.py:19] end gpu_group_einsum cost 0.00028204917907714844 seconds
DEBUG 01-14 17:01:50.546602.546602 cuda_h.py:10] start gpu_final_hidden_states_scatter
DEBUG 01-14 17:01:50.546221.546221 cuda_h.py:10] start all_expert_outputs_slices
DEBUG 01-14 17:01:50.546003.546003 cuda_h.py:19] end all_expert_outputs_slices cost 0.00019311904907226562 seconds
DEBUG 01-14 17:01:50.546706.546706 cuda_h.py:10] start concat_expert_out
DEBUG 01-14 17:01:50.546755.546755 cuda_h.py:19] end concat_expert_out cost 4.553794860839844e-05 seconds
DEBUG 01-14 17:01:50.546823.546823 cuda_h.py:10] start index_scatter
DEBUG 01-14 17:01:50.546825.546825 cuda_h.py:19] end index_scatter cost 4.363059997558594e-05 seconds
DEBUG 01-14 17:01:50.546195.546195 cuda_h.py:19] end gpu_final_hidden_states_scatter cost 0.0006439685821533203 seconds
DEBUG 01-14 17:01:50.546058.546058 cuda_h.py:10] start gpu_final_hidden_states_scatter
DEBUG 01-14 17:01:50.546457.546457 cuda_h.py:10] start all_expert_outputs_slices
DEBUG 01-14 17:01:50.547894.547894 cuda_h.py:19] end all_expert_outputs_slices cost 0.000156402587890625 seconds
DEBUG 01-14 17:01:50.547212.547212 cuda_h.py:10] start concat_expert_out
DEBUG 01-14 17:01:50.547546.547546 cuda_h.py:19] end concat_expert_out cost 4.601478576660156e-05 seconds
DEBUG 01-14 17:01:50.547375.547375 cuda_h.py:10] start index_scatter
DEBUG 01-14 17:01:50.547232.547232 cuda_h.py:19] end index_scatter cost 4.267692565917969e-05 seconds
DEBUG 01-14 17:01:50.547889.547889 cuda_h.py:19] end gpu_final_hidden_states_scatter cost 0.0004420280456542969 seconds
DEBUG 01-14 17:01:50.547533.547533 cuda_h.py:19] end exec_one_by_one_end_new2 cost 0.002551555633544922 seconds
DEBUG 01-14 17:01:50.549755.549755 cuda_h.py:10] start task_processing_mp_load
DEBUG 01-14 17:01:50.549036.549036 cuda_h.py:10] start allocate_cuda_memory_and_load_into_gpu_multi_device
DEBUG 01-14 17:01:50.552963.552963 cuda_memory_view.py:520] tensor_device_offsets_device_map {1: {'model.layers.1.mlp.experts.0.gate_proj.weight': 0, 'model.layers.1.mlp.experts.0.down_proj.weight': 5767168, 'model.layers.1.mlp.experts.0.up_proj.weight': 11534336, 'model.layers.1.mlp.experts.1.gate_proj.weight': 17301504, 'model.layers.1.mlp.experts.1.down_proj.weight': 23068672, 'model.layers.1.mlp.experts.1.up_proj.weight': 28835840, 'model.layers.1.mlp.experts.2.gate_proj.weight': 34603008, 'model.layers.1.mlp.experts.2.down_proj.weight': 40370176, 'model.layers.1.mlp.experts.2.up_proj.weight': 46137344, 'model.layers.1.mlp.experts.4.gate_proj.weight': 51904512, 'model.layers.1.mlp.experts.4.down_proj.weight': 57671680, 'model.layers.1.mlp.experts.4.up_proj.weight': 63438848, 'model.layers.1.mlp.experts.5.gate_proj.weight': 69206016, 'model.layers.1.mlp.experts.5.down_proj.weight': 74973184, 'model.layers.1.mlp.experts.5.up_proj.weight': 80740352, 'model.layers.1.mlp.experts.6.gate_proj.weight': 86507520, 'model.layers.1.mlp.experts.6.down_proj.weight': 92274688, 'model.layers.1.mlp.experts.6.up_proj.weight': 98041856, 'model.layers.1.mlp.experts.7.gate_proj.weight': 103809024, 'model.layers.1.mlp.experts.7.down_proj.weight': 109576192, 'model.layers.1.mlp.experts.7.up_proj.weight': 115343360, 'model.layers.1.mlp.experts.10.gate_proj.weight': 121110528, 'model.layers.1.mlp.experts.10.down_proj.weight': 126877696, 'model.layers.1.mlp.experts.10.up_proj.weight': 132644864, 'model.layers.1.mlp.experts.15.gate_proj.weight': 138412032, 'model.layers.1.mlp.experts.15.down_proj.weight': 144179200, 'model.layers.1.mlp.experts.15.up_proj.weight': 149946368, 'model.layers.1.mlp.experts.16.gate_proj.weight': 155713536, 'model.layers.1.mlp.experts.16.down_proj.weight': 161480704, 'model.layers.1.mlp.experts.16.up_proj.weight': 167247872, 'model.layers.1.mlp.experts.19.gate_proj.weight': 173015040, 'model.layers.1.mlp.experts.19.down_proj.weight': 178782208, 'model.layers.1.mlp.experts.19.up_proj.weight': 184549376, 'model.layers.1.mlp.experts.21.gate_proj.weight': 190316544, 'model.layers.1.mlp.experts.21.down_proj.weight': 196083712, 'model.layers.1.mlp.experts.21.up_proj.weight': 201850880, 'model.layers.1.mlp.experts.22.gate_proj.weight': 207618048, 'model.layers.1.mlp.experts.22.down_proj.weight': 213385216, 'model.layers.1.mlp.experts.22.up_proj.weight': 219152384, 'model.layers.1.mlp.experts.23.gate_proj.weight': 224919552, 'model.layers.1.mlp.experts.23.down_proj.weight': 230686720, 'model.layers.1.mlp.experts.23.up_proj.weight': 236453888, 'model.layers.1.mlp.experts.24.gate_proj.weight': 242221056, 'model.layers.1.mlp.experts.24.down_proj.weight': 247988224, 'model.layers.1.mlp.experts.24.up_proj.weight': 253755392, 'model.layers.1.mlp.experts.28.gate_proj.weight': 259522560, 'model.layers.1.mlp.experts.28.down_proj.weight': 265289728, 'model.layers.1.mlp.experts.28.up_proj.weight': 271056896, 'model.layers.1.mlp.experts.29.gate_proj.weight': 276824064, 'model.layers.1.mlp.experts.29.down_proj.weight': 282591232, 'model.layers.1.mlp.experts.29.up_proj.weight': 288358400, 'model.layers.1.mlp.experts.30.gate_proj.weight': 294125568, 'model.layers.1.mlp.experts.30.down_proj.weight': 299892736, 'model.layers.1.mlp.experts.30.up_proj.weight': 305659904, 'model.layers.1.mlp.experts.32.gate_proj.weight': 311427072, 'model.layers.1.mlp.experts.32.down_proj.weight': 317194240, 'model.layers.1.mlp.experts.32.up_proj.weight': 322961408, 'model.layers.1.mlp.experts.33.gate_proj.weight': 328728576, 'model.layers.1.mlp.experts.33.down_proj.weight': 334495744, 'model.layers.1.mlp.experts.33.up_proj.weight': 340262912, 'model.layers.1.mlp.experts.34.gate_proj.weight': 346030080, 'model.layers.1.mlp.experts.34.down_proj.weight': 351797248, 'model.layers.1.mlp.experts.34.up_proj.weight': 357564416, 'model.layers.1.mlp.experts.38.gate_proj.weight': 363331584, 'model.layers.1.mlp.experts.38.down_proj.weight': 369098752, 'model.layers.1.mlp.experts.38.up_proj.weight': 374865920, 'model.layers.1.mlp.experts.43.gate_proj.weight': 380633088, 'model.layers.1.mlp.experts.43.down_proj.weight': 386400256, 'model.layers.1.mlp.experts.43.up_proj.weight': 392167424, 'model.layers.1.mlp.experts.44.gate_proj.weight': 397934592, 'model.layers.1.mlp.experts.44.down_proj.weight': 403701760, 'model.layers.1.mlp.experts.44.up_proj.weight': 409468928, 'model.layers.1.mlp.experts.46.gate_proj.weight': 415236096, 'model.layers.1.mlp.experts.46.down_proj.weight': 421003264, 'model.layers.1.mlp.experts.46.up_proj.weight': 426770432, 'model.layers.1.mlp.experts.48.gate_proj.weight': 432537600, 'model.layers.1.mlp.experts.48.down_proj.weight': 438304768, 'model.layers.1.mlp.experts.48.up_proj.weight': 444071936, 'model.layers.1.mlp.experts.54.gate_proj.weight': 449839104, 'model.layers.1.mlp.experts.54.down_proj.weight': 455606272, 'model.layers.1.mlp.experts.54.up_proj.weight': 461373440, 'model.layers.1.mlp.experts.56.gate_proj.weight': 467140608, 'model.layers.1.mlp.experts.56.down_proj.weight': 472907776, 'model.layers.1.mlp.experts.56.up_proj.weight': 478674944, 'model.layers.1.mlp.experts.58.gate_proj.weight': 484442112, 'model.layers.1.mlp.experts.58.down_proj.weight': 490209280, 'model.layers.1.mlp.experts.58.up_proj.weight': 495976448, 'model.layers.1.mlp.experts.59.gate_proj.weight': 501743616, 'model.layers.1.mlp.experts.59.down_proj.weight': 507510784, 'model.layers.1.mlp.experts.59.up_proj.weight': 513277952, 'model.layers.1.mlp.experts.62.gate_proj.weight': 519045120, 'model.layers.1.mlp.experts.62.down_proj.weight': 524812288, 'model.layers.1.mlp.experts.62.up_proj.weight': 530579456, 'model.layers.1.mlp.experts.63.gate_proj.weight': 536346624, 'model.layers.1.mlp.experts.63.down_proj.weight': 542113792, 'model.layers.1.mlp.experts.63.up_proj.weight': 547880960}, 2: {'model.layers.1.mlp.experts.3.gate_proj.weight': 0, 'model.layers.1.mlp.experts.3.down_proj.weight': 5767168, 'model.layers.1.mlp.experts.3.up_proj.weight': 11534336, 'model.layers.1.mlp.experts.8.gate_proj.weight': 17301504, 'model.layers.1.mlp.experts.8.down_proj.weight': 23068672, 'model.layers.1.mlp.experts.8.up_proj.weight': 28835840, 'model.layers.1.mlp.experts.9.gate_proj.weight': 34603008, 'model.layers.1.mlp.experts.9.down_proj.weight': 40370176, 'model.layers.1.mlp.experts.9.up_proj.weight': 46137344, 'model.layers.1.mlp.experts.11.gate_proj.weight': 51904512, 'model.layers.1.mlp.experts.11.down_proj.weight': 57671680, 'model.layers.1.mlp.experts.11.up_proj.weight': 63438848, 'model.layers.1.mlp.experts.12.gate_proj.weight': 69206016, 'model.layers.1.mlp.experts.12.down_proj.weight': 74973184, 'model.layers.1.mlp.experts.12.up_proj.weight': 80740352, 'model.layers.1.mlp.experts.13.gate_proj.weight': 86507520, 'model.layers.1.mlp.experts.13.down_proj.weight': 92274688, 'model.layers.1.mlp.experts.13.up_proj.weight': 98041856, 'model.layers.1.mlp.experts.14.gate_proj.weight': 103809024, 'model.layers.1.mlp.experts.14.down_proj.weight': 109576192, 'model.layers.1.mlp.experts.14.up_proj.weight': 115343360, 'model.layers.1.mlp.experts.17.gate_proj.weight': 121110528, 'model.layers.1.mlp.experts.17.down_proj.weight': 126877696, 'model.layers.1.mlp.experts.17.up_proj.weight': 132644864, 'model.layers.1.mlp.experts.18.gate_proj.weight': 138412032, 'model.layers.1.mlp.experts.18.down_proj.weight': 144179200, 'model.layers.1.mlp.experts.18.up_proj.weight': 149946368, 'model.layers.1.mlp.experts.20.gate_proj.weight': 155713536, 'model.layers.1.mlp.experts.20.down_proj.weight': 161480704, 'model.layers.1.mlp.experts.20.up_proj.weight': 167247872, 'model.layers.1.mlp.experts.25.gate_proj.weight': 173015040, 'model.layers.1.mlp.experts.25.down_proj.weight': 178782208, 'model.layers.1.mlp.experts.25.up_proj.weight': 184549376, 'model.layers.1.mlp.experts.26.gate_proj.weight': 190316544, 'model.layers.1.mlp.experts.26.down_proj.weight': 196083712, 'model.layers.1.mlp.experts.26.up_proj.weight': 201850880, 'model.layers.1.mlp.experts.27.gate_proj.weight': 207618048, 'model.layers.1.mlp.experts.27.down_proj.weight': 213385216, 'model.layers.1.mlp.experts.27.up_proj.weight': 219152384, 'model.layers.1.mlp.experts.31.gate_proj.weight': 224919552, 'model.layers.1.mlp.experts.31.down_proj.weight': 230686720, 'model.layers.1.mlp.experts.31.up_proj.weight': 236453888, 'model.layers.1.mlp.experts.35.gate_proj.weight': 242221056, 'model.layers.1.mlp.experts.35.down_proj.weight': 247988224, 'model.layers.1.mlp.experts.35.up_proj.weight': 253755392, 'model.layers.1.mlp.experts.36.gate_proj.weight': 259522560, 'model.layers.1.mlp.experts.36.down_proj.weight': 265289728, 'model.layers.1.mlp.experts.36.up_proj.weight': 271056896, 'model.layers.1.mlp.experts.37.gate_proj.weight': 276824064, 'model.layers.1.mlp.experts.37.down_proj.weight': 282591232, 'model.layers.1.mlp.experts.37.up_proj.weight': 288358400, 'model.layers.1.mlp.experts.39.gate_proj.weight': 294125568, 'model.layers.1.mlp.experts.39.down_proj.weight': 299892736, 'model.layers.1.mlp.experts.39.up_proj.weight': 305659904, 'model.layers.1.mlp.experts.40.gate_proj.weight': 311427072, 'model.layers.1.mlp.experts.40.down_proj.weight': 317194240, 'model.layers.1.mlp.experts.40.up_proj.weight': 322961408, 'model.layers.1.mlp.experts.41.gate_proj.weight': 328728576, 'model.layers.1.mlp.experts.41.down_proj.weight': 334495744, 'model.layers.1.mlp.experts.41.up_proj.weight': 340262912, 'model.layers.1.mlp.experts.42.gate_proj.weight': 346030080, 'model.layers.1.mlp.experts.42.down_proj.weight': 351797248, 'model.layers.1.mlp.experts.42.up_proj.weight': 357564416, 'model.layers.1.mlp.experts.45.gate_proj.weight': 363331584, 'model.layers.1.mlp.experts.45.down_proj.weight': 369098752, 'model.layers.1.mlp.experts.45.up_proj.weight': 374865920, 'model.layers.1.mlp.experts.47.gate_proj.weight': 380633088, 'model.layers.1.mlp.experts.47.down_proj.weight': 386400256, 'model.layers.1.mlp.experts.47.up_proj.weight': 392167424, 'model.layers.1.mlp.experts.49.gate_proj.weight': 397934592, 'model.layers.1.mlp.experts.49.down_proj.weight': 403701760, 'model.layers.1.mlp.experts.49.up_proj.weight': 409468928, 'model.layers.1.mlp.experts.50.gate_proj.weight': 415236096, 'model.layers.1.mlp.experts.50.down_proj.weight': 421003264, 'model.layers.1.mlp.experts.50.up_proj.weight': 426770432, 'model.layers.1.mlp.experts.51.gate_proj.weight': 432537600, 'model.layers.1.mlp.experts.51.down_proj.weight': 438304768, 'model.layers.1.mlp.experts.51.up_proj.weight': 444071936, 'model.layers.1.mlp.experts.52.gate_proj.weight': 449839104, 'model.layers.1.mlp.experts.52.down_proj.weight': 455606272, 'model.layers.1.mlp.experts.52.up_proj.weight': 461373440, 'model.layers.1.mlp.experts.53.gate_proj.weight': 467140608, 'model.layers.1.mlp.experts.53.down_proj.weight': 472907776, 'model.layers.1.mlp.experts.53.up_proj.weight': 478674944, 'model.layers.1.mlp.experts.55.gate_proj.weight': 484442112, 'model.layers.1.mlp.experts.55.down_proj.weight': 490209280, 'model.layers.1.mlp.experts.55.up_proj.weight': 495976448, 'model.layers.1.mlp.experts.57.gate_proj.weight': 501743616, 'model.layers.1.mlp.experts.57.down_proj.weight': 507510784, 'model.layers.1.mlp.experts.57.up_proj.weight': 513277952, 'model.layers.1.mlp.experts.60.gate_proj.weight': 519045120, 'model.layers.1.mlp.experts.60.down_proj.weight': 524812288, 'model.layers.1.mlp.experts.60.up_proj.weight': 530579456, 'model.layers.1.mlp.experts.61.gate_proj.weight': 536346624, 'model.layers.1.mlp.experts.61.down_proj.weight': 542113792, 'model.layers.1.mlp.experts.61.up_proj.weight': 547880960}}tensor_copy_chunks_device_map {1: [(2860515328, 5767168, 0, 0), (2866282496, 5767168, 5767168, 0), (2854748160, 5767168, 11534336, 0), (2877816832, 5767168, 17301504, 0), (2883584000, 5767168, 23068672, 0), (2872049664, 5767168, 28835840, 0), (2895118336, 5767168, 34603008, 0), (2900885504, 5767168, 40370176, 0), (2889351168, 5767168, 46137344, 0), (2929721344, 5767168, 51904512, 0), (2935488512, 5767168, 57671680, 0), (2923954176, 5767168, 63438848, 0), (2947022848, 5767168, 69206016, 0), (2952790016, 5767168, 74973184, 0), (2941255680, 5767168, 80740352, 0), (2964324352, 5767168, 86507520, 0), (2970091520, 5767168, 92274688, 0), (2958557184, 5767168, 98041856, 0), (2981625856, 5767168, 103809024, 0), (2987393024, 5767168, 109576192, 0), (2975858688, 5767168, 115343360, 0), (3033530368, 5767168, 121110528, 0), (3039297536, 5767168, 126877696, 0), (3027763200, 5767168, 132644864, 0), (3120037888, 5767168, 138412032, 0), (3125805056, 5767168, 144179200, 0), (3114270720, 5767168, 149946368, 0), (3137339392, 5767168, 155713536, 0), (3143106560, 5767168, 161480704, 0), (3131572224, 5767168, 167247872, 0), (3189243904, 5767168, 173015040, 0), (3195011072, 5767168, 178782208, 0), (3183476736, 5767168, 184549376, 0), (3223846912, 5767168, 190316544, 0), (3229614080, 5767168, 196083712, 0), (3218079744, 5767168, 201850880, 0), (3241148416, 5767168, 207618048, 0), (3246915584, 5767168, 213385216, 0), (3235381248, 5767168, 219152384, 0), (3258449920, 5767168, 224919552, 0), (3264217088, 5767168, 230686720, 0), (3252682752, 5767168, 236453888, 0), (3275751424, 5767168, 242221056, 0), (3281518592, 5767168, 247988224, 0), (3269984256, 5767168, 253755392, 0), (3344957440, 5767168, 259522560, 0), (3350724608, 5767168, 265289728, 0), (3339190272, 5767168, 271056896, 0), (3362258944, 5767168, 276824064, 0), (3368026112, 5767168, 282591232, 0), (3356491776, 5767168, 288358400, 0), (3379560448, 5767168, 294125568, 0), (3385327616, 5767168, 299892736, 0), (3373793280, 5767168, 305659904, 0), (3414163456, 5767168, 311427072, 0), (3419930624, 5767168, 317194240, 0), (3408396288, 5767168, 322961408, 0), (3431464960, 5767168, 328728576, 0), (3437232128, 5767168, 334495744, 0), (3425697792, 5767168, 340262912, 0), (3448766464, 5767168, 346030080, 0), (3454533632, 5767168, 351797248, 0), (3442999296, 5767168, 357564416, 0), (3517972480, 5767168, 363331584, 0), (3523739648, 5767168, 369098752, 0), (3512205312, 5767168, 374865920, 0), (3604480000, 5767168, 380633088, 0), (3610247168, 5767168, 386400256, 0), (3598712832, 5767168, 392167424, 0), (3621781504, 5767168, 397934592, 0), (3627548672, 5767168, 403701760, 0), (3616014336, 5767168, 409468928, 0), (3656384512, 5767168, 415236096, 0), (3662151680, 5767168, 421003264, 0), (3650617344, 5767168, 426770432, 0), (3690987520, 5767168, 432537600, 0), (3696754688, 5767168, 438304768, 0), (3685220352, 5767168, 444071936, 0), (3794796544, 5767168, 449839104, 0), (3800563712, 5767168, 455606272, 0), (3789029376, 5767168, 461373440, 0), (3829399552, 5767168, 467140608, 0), (3835166720, 5767168, 472907776, 0), (3823632384, 5767168, 478674944, 0), (3864002560, 5767168, 484442112, 0), (3869769728, 5767168, 490209280, 0), (3858235392, 5767168, 495976448, 0), (3881304064, 5767168, 501743616, 0), (3887071232, 5767168, 507510784, 0), (3875536896, 5767168, 513277952, 0), (3933208576, 5767168, 519045120, 0), (3938975744, 5767168, 524812288, 0), (3927441408, 5767168, 530579456, 0), (3950510080, 5767168, 536346624, 0), (3956277248, 5767168, 542113792, 0), (3944742912, 5767168, 547880960, 0)], 2: [(2912419840, 5767168, 0, 0), (2918187008, 5767168, 5767168, 0), (2906652672, 5767168, 11534336, 0), (2998927360, 5767168, 17301504, 0), (3004694528, 5767168, 23068672, 0), (2993160192, 5767168, 28835840, 0), (3016228864, 5767168, 34603008, 0), (3021996032, 5767168, 40370176, 0), (3010461696, 5767168, 46137344, 0), (3050831872, 5767168, 51904512, 0), (3056599040, 5767168, 57671680, 0), (3045064704, 5767168, 63438848, 0), (3068133376, 5767168, 69206016, 0), (3073900544, 5767168, 74973184, 0), (3062366208, 5767168, 80740352, 0), (3085434880, 5767168, 86507520, 0), (3091202048, 5767168, 92274688, 0), (3079667712, 5767168, 98041856, 0), (3102736384, 5767168, 103809024, 0), (3108503552, 5767168, 109576192, 0), (3096969216, 5767168, 115343360, 0), (3154640896, 5767168, 121110528, 0), (3160408064, 5767168, 126877696, 0), (3148873728, 5767168, 132644864, 0), (3171942400, 5767168, 138412032, 0), (3177709568, 5767168, 144179200, 0), (3166175232, 5767168, 149946368, 0), (3206545408, 5767168, 155713536, 0), (3212312576, 5767168, 161480704, 0), (3200778240, 5767168, 167247872, 0), (3293052928, 5767168, 173015040, 0), (3298820096, 5767168, 178782208, 0), (3287285760, 5767168, 184549376, 0), (3310354432, 5767168, 190316544, 0), (3316121600, 5767168, 196083712, 0), (3304587264, 5767168, 201850880, 0), (3327655936, 5767168, 207618048, 0), (3333423104, 5767168, 213385216, 0), (3321888768, 5767168, 219152384, 0), (3396861952, 5767168, 224919552, 0), (3402629120, 5767168, 230686720, 0), (3391094784, 5767168, 236453888, 0), (3466067968, 5767168, 242221056, 0), (3471835136, 5767168, 247988224, 0), (3460300800, 5767168, 253755392, 0), (3483369472, 5767168, 259522560, 0), (3489136640, 5767168, 265289728, 0), (3477602304, 5767168, 271056896, 0), (3500670976, 5767168, 276824064, 0), (3506438144, 5767168, 282591232, 0), (3494903808, 5767168, 288358400, 0), (3535273984, 5767168, 294125568, 0), (3541041152, 5767168, 299892736, 0), (3529506816, 5767168, 305659904, 0), (3552575488, 5767168, 311427072, 0), (3558342656, 5767168, 317194240, 0), (3546808320, 5767168, 322961408, 0), (3569876992, 5767168, 328728576, 0), (3575644160, 5767168, 334495744, 0), (3564109824, 5767168, 340262912, 0), (3587178496, 5767168, 346030080, 0), (3592945664, 5767168, 351797248, 0), (3581411328, 5767168, 357564416, 0), (3639083008, 5767168, 363331584, 0), (3644850176, 5767168, 369098752, 0), (3633315840, 5767168, 374865920, 0), (3673686016, 5767168, 380633088, 0), (3679453184, 5767168, 386400256, 0), (3667918848, 5767168, 392167424, 0), (3708289024, 5767168, 397934592, 0), (3714056192, 5767168, 403701760, 0), (3702521856, 5767168, 409468928, 0), (3725590528, 5767168, 415236096, 0), (3731357696, 5767168, 421003264, 0), (3719823360, 5767168, 426770432, 0), (3742892032, 5767168, 432537600, 0), (3748659200, 5767168, 438304768, 0), (3737124864, 5767168, 444071936, 0), (3760193536, 5767168, 449839104, 0), (3765960704, 5767168, 455606272, 0), (3754426368, 5767168, 461373440, 0), (3777495040, 5767168, 467140608, 0), (3783262208, 5767168, 472907776, 0), (3771727872, 5767168, 478674944, 0), (3812098048, 5767168, 484442112, 0), (3817865216, 5767168, 490209280, 0), (3806330880, 5767168, 495976448, 0), (3846701056, 5767168, 501743616, 0), (3852468224, 5767168, 507510784, 0), (3840933888, 5767168, 513277952, 0), (3898605568, 5767168, 519045120, 0), (3904372736, 5767168, 524812288, 0), (3892838400, 5767168, 530579456, 0), (3915907072, 5767168, 536346624, 0), (3921674240, 5767168, 542113792, 0), (3910139904, 5767168, 547880960, 0)]}cuda_memory_handles_device_map {1: <capsule object NULL at 0x7b0b8db08ff0>, 2: <capsule object NULL at 0x7b0b88bcfcf0>}
DEBUG 01-14 17:01:50.552531.552531 sllm_store_c.py:27] get device uuid map
DEBUG 01-14 17:01:50.552731.552731 sllm_store_c.py:29] call client load into gpu
DEBUG 01-14 17:01:50.552288.552288 client.py:72] load_into_gpu: deepseek-moe-16b-base-bfloat16, b09aba18-d13d-4a01-8d38-33e50dbd8962
DEBUG 01-14 17:01:50.552469.552469 client.py:106] call stub.LoadModelAsync
INFO 01-14 17:01:50.555315.555315 client.py:115] Model loaded: deepseek-moe-16b-base-bfloat16, b09aba18-d13d-4a01-8d38-33e50dbd8962
DEBUG 01-14 17:01:50.556643.556643 cuda_h.py:19] end allocate_cuda_memory_and_load_into_gpu_multi_device cost 0.006203651428222656 seconds
DEBUG 01-14 17:01:50.556488.556488 cuda_h.py:10] start restore2model
DEBUG 01-14 17:01:50.560902.560902 cuda_h.py:19] end restore2model cost 0.004014253616333008 seconds
DEBUG 01-14 17:01:50.560164.560164 cuda_h.py:10] start experts_func_mgpu_group_pad
DEBUG 01-14 17:01:50.562487.562487 cuda_h.py:19] end experts_func_mgpu_group_pad cost 0.0014803409576416016 seconds
DEBUG 01-14 17:01:50.562198.562198 cuda_h.py:10] start experts_func_mgpu_group_pad
DEBUG 01-14 17:01:50.563721.563721 cuda_h.py:19] end experts_func_mgpu_group_pad cost 0.001538991928100586 seconds
DEBUG 01-14 17:01:50.563691.563691 cuda_h.py:10] start gpu_group_list
DEBUG 01-14 17:01:50.564231.564231 cuda_h.py:19] end gpu_group_list cost 0.00029754638671875 seconds
DEBUG 01-14 17:01:50.564340.564340 cuda_h.py:10] start gpu_group_list
DEBUG 01-14 17:01:50.564258.564258 cuda_h.py:19] end gpu_group_list cost 0.0002875328063964844 seconds
INFO 01-14 17:01:50.566382.566382 client.py:119] confirm_model_loaded: deepseek-moe-16b-base-bfloat16, b09aba18-d13d-4a01-8d38-33e50dbd8962
INFO 01-14 17:01:50.606131.606131 client.py:127] Model loaded
DEBUG 01-14 17:01:50.607625.607625 cuda_h.py:19] end task_processing_mp_load cost 0.05718231201171875 seconds
DEBUG 01-14 17:01:50.607429.607429 cuda_h.py:10] start exec_together
DEBUG 01-14 17:01:50.617559.617559 mlpmodule.py:1053] mgpu group einsum cost 0.0012154579162597656 s
DEBUG 01-14 17:01:50.624768.624768 mlpmodule.py:1109] mgpu experts func einsum cost 0.017360925674438477 s
DEBUG 01-14 17:01:50.624964.624964 cuda_h.py:19] end exec_together cost 0.017508506774902344 seconds
DEBUG 01-14 17:01:50.624627.624627 cuda_h.py:10] start exec_one_by_one
DEBUG 01-14 17:01:50.625384.625384 mlpmodule.py:1178] gpu group tensors cost 0.00041031837463378906 s
DEBUG 01-14 17:01:50.626977.626977 mlpmodule.py:1220] gpu pad cost 0.0014433860778808594 s
DEBUG 01-14 17:01:50.626535.626535 mlpmodule.py:1226] start_w1
DEBUG 01-14 17:01:50.626250.626250 mlpmodule.py:1230] start_w3
DEBUG 01-14 17:01:50.627877.627877 mlpmodule.py:1236] start_w2
DEBUG 01-14 17:01:50.627517.627517 mlpmodule.py:1239] gpu group einsum cost 0.00044226646423339844 s
DEBUG 01-14 17:01:50.629906.629906 mlpmodule.py:1316] gpu experts func einsum cost 0.004515171051025391 s
DEBUG 01-14 17:01:50.629121.629121 mlpmodule.py:1178] gpu group tensors cost 0.00041937828063964844 s
DEBUG 01-14 17:01:50.631935.631935 mlpmodule.py:1220] gpu pad cost 0.001706838607788086 s
DEBUG 01-14 17:01:50.631447.631447 mlpmodule.py:1226] start_w1
DEBUG 01-14 17:01:50.631189.631189 mlpmodule.py:1230] start_w3
DEBUG 01-14 17:01:50.631870.631870 mlpmodule.py:1236] start_w2
DEBUG 01-14 17:01:50.632655.632655 mlpmodule.py:1239] gpu group einsum cost 0.00046825408935546875 s
DEBUG 01-14 17:01:50.634503.634503 mlpmodule.py:1316] gpu experts func einsum cost 0.0052988529205322266 s
DEBUG 01-14 17:01:50.634235.634235 cuda_h.py:19] end exec_one_by_one cost 0.010007143020629883 seconds
DEBUG 01-14 17:01:50.634037.634037 cuda_h.py:10] start exec_one_by_one_end_new
DEBUG 01-14 17:01:50.634700.634700 cuda_h.py:10] start gpu_group_tensor
DEBUG 01-14 17:01:50.634460.634460 cuda_h.py:19] end gpu_group_tensor cost 0.00011014938354492188 seconds
DEBUG 01-14 17:01:50.635104.635104 cuda_h.py:10] start gpu_group_tensor
DEBUG 01-14 17:01:50.635890.635890 cuda_h.py:19] end gpu_group_tensor cost 9.369850158691406e-05 seconds
DEBUG 01-14 17:01:50.635667.635667 cuda_h.py:10] start gpu_group_einsum
DEBUG 01-14 17:01:50.635095.635095 cuda_h.py:19] end gpu_group_einsum cost 0.0002760887145996094 seconds
DEBUG 01-14 17:01:50.635395.635395 cuda_h.py:10] start gpu_final_hidden_states_scatter
DEBUG 01-14 17:01:50.635558.635558 cuda_h.py:10] start all_expert_weight_slices
DEBUG 01-14 17:01:50.636781.636781 cuda_h.py:19] end all_expert_weight_slices cost 0.0006923675537109375 seconds
DEBUG 01-14 17:01:50.636742.636742 cuda_h.py:10] start all_expert_output_slices
DEBUG 01-14 17:01:50.636722.636722 cuda_h.py:19] end all_expert_output_slices cost 0.00016927719116210938 seconds
DEBUG 01-14 17:01:50.636756.636756 cuda_h.py:10] start concat_expert_out
DEBUG 01-14 17:01:50.636118.636118 cuda_h.py:19] end concat_expert_out cost 0.0001010894775390625 seconds
DEBUG 01-14 17:01:50.636239.636239 cuda_h.py:10] start index_scatter
DEBUG 01-14 17:01:50.636772.636772 cuda_h.py:19] end index_scatter cost 4.5299530029296875e-05 seconds
DEBUG 01-14 17:01:50.637528.637528 cuda_h.py:19] end gpu_final_hidden_states_scatter cost 0.001371622085571289 seconds
DEBUG 01-14 17:01:50.637472.637472 cuda_h.py:10] start gpu_group_einsum
DEBUG 01-14 17:01:50.637272.637272 cuda_h.py:19] end gpu_group_einsum cost 0.0002961158752441406 seconds
DEBUG 01-14 17:01:50.637287.637287 cuda_h.py:10] start gpu_final_hidden_states_scatter
DEBUG 01-14 17:01:50.637135.637135 cuda_h.py:10] start all_expert_weight_slices
DEBUG 01-14 17:01:50.638716.638716 cuda_h.py:19] end all_expert_weight_slices cost 0.0007090568542480469 seconds
DEBUG 01-14 17:01:50.638002.638002 cuda_h.py:10] start all_expert_output_slices
DEBUG 01-14 17:01:50.638771.638771 cuda_h.py:19] end all_expert_output_slices cost 0.0001876354217529297 seconds
DEBUG 01-14 17:01:50.638851.638851 cuda_h.py:10] start concat_expert_out
DEBUG 01-14 17:01:50.638491.638491 cuda_h.py:19] end concat_expert_out cost 9.512901306152344e-05 seconds
DEBUG 01-14 17:01:50.638420.638420 cuda_h.py:10] start index_scatter
DEBUG 01-14 17:01:50.639091.639091 cuda_h.py:19] end index_scatter cost 4.38690185546875e-05 seconds
DEBUG 01-14 17:01:50.639891.639891 cuda_h.py:19] end gpu_final_hidden_states_scatter cost 0.0016088485717773438 seconds
DEBUG 01-14 17:01:50.639212.639212 cuda_h.py:19] end exec_one_by_one_end_new cost 0.004422903060913086 seconds
DEBUG 01-14 17:01:50.639346.639346 cuda_h.py:10] start exec_one_by_one_end_new2
DEBUG 01-14 17:01:50.639056.639056 cuda_h.py:10] start gpu_group_einsum_mp_multi_list
DEBUG 01-14 17:01:50.639513.639513 cuda_h.py:10] start gpu_group_tensor
DEBUG 01-14 17:01:50.639975.639975 cuda_h.py:19] end gpu_group_tensor cost 0.00010561943054199219 seconds
DEBUG 01-14 17:01:50.639684.639684 cuda_h.py:10] start gpu_group_tensor
DEBUG 01-14 17:01:50.639132.639132 cuda_h.py:19] end gpu_group_tensor cost 9.226799011230469e-05 seconds
DEBUG 01-14 17:01:50.639512.639512 cuda_h.py:10] start gpu_group_einsum
DEBUG 01-14 17:01:50.640363.640363 cuda_h.py:19] end gpu_group_einsum cost 0.00027370452880859375 seconds
DEBUG 01-14 17:01:50.640770.640770 cuda_h.py:10] start gpu_group_einsum
DEBUG 01-14 17:01:50.640047.640047 cuda_h.py:19] end gpu_group_einsum cost 0.0003006458282470703 seconds
DEBUG 01-14 17:01:50.640414.640414 cuda_h.py:10] start gpu_final_hidden_states_scatter
DEBUG 01-14 17:01:50.640993.640993 cuda_h.py:10] start all_expert_outputs_slices
DEBUG 01-14 17:01:50.640319.640319 cuda_h.py:19] end all_expert_outputs_slices cost 0.00020599365234375 seconds
DEBUG 01-14 17:01:50.640406.640406 cuda_h.py:10] start concat_expert_out
DEBUG 01-14 17:01:50.640600.640600 cuda_h.py:19] end concat_expert_out cost 4.649162292480469e-05 seconds
DEBUG 01-14 17:01:50.641337.641337 cuda_h.py:10] start index_scatter
DEBUG 01-14 17:01:50.641684.641684 cuda_h.py:19] end index_scatter cost 4.673004150390625e-05 seconds
DEBUG 01-14 17:01:50.641114.641114 cuda_h.py:19] end gpu_final_hidden_states_scatter cost 0.0006840229034423828 seconds
DEBUG 01-14 17:01:50.641123.641123 cuda_h.py:10] start gpu_final_hidden_states_scatter
DEBUG 01-14 17:01:50.641098.641098 cuda_h.py:10] start all_expert_outputs_slices
DEBUG 01-14 17:01:50.641933.641933 cuda_h.py:19] end all_expert_outputs_slices cost 0.00016736984252929688 seconds
DEBUG 01-14 17:01:50.641755.641755 cuda_h.py:10] start concat_expert_out
DEBUG 01-14 17:01:50.641850.641850 cuda_h.py:19] end concat_expert_out cost 4.601478576660156e-05 seconds
DEBUG 01-14 17:01:50.641249.641249 cuda_h.py:10] start index_scatter
DEBUG 01-14 17:01:50.641881.641881 cuda_h.py:19] end index_scatter cost 4.482269287109375e-05 seconds
DEBUG 01-14 17:01:50.641637.641637 cuda_h.py:19] end gpu_final_hidden_states_scatter cost 0.00048828125 seconds
DEBUG 01-14 17:01:50.641566.641566 cuda_h.py:19] end exec_one_by_one_end_new2 cost 0.002598285675048828 seconds
Collecting data...
Generating '/tmp/nsys-report-f56c.qdstrm'
[1/1] [0%                          ] report5.nsys-rep[1/1] [0%                          ] report5.nsys-rep[1/1] [=16%                        ] report5.nsys-rep[1/1] [======33%                   ] report5.nsys-rep[1/1] [===========50%              ] report5.nsys-rep[1/1] [========================100%] report5.nsys-rep[1/1] [========================100%] report5.nsys-rep
Generated:
	/mnt/zhengcf3/lmp/examples/report5.nsys-rep
