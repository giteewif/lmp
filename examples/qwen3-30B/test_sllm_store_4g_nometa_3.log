here pin
INFO 01-21 10:51:48.355705.355705 pinpool.py:28] Initializing PinnedMemoryPool with 2GB total, allocating in 1024MB chunks...
INFO 01-21 10:51:48.885940.885940 pinpool.py:40] Allocated chunk 1: 536870912 elements (1024.0 MB)
INFO 01-21 10:51:49.314380.314380 pinpool.py:40] Allocated chunk 2: 536870912 elements (1024.0 MB)
INFO 01-21 10:51:49.314095.314095 pinpool.py:52] Successfully allocated 2 chunks, total 1073741824 elements (2048.0 MB) in 0.959s
Warming up 4 GPU(s)...
GPU 0 warmed up
GPU 1 warmed up
GPU 2 warmed up
GPU 3 warmed up
GPU warmup completed
Warming up 4 GPU(s)...
GPU 0 warmed up
GPU 1 warmed up
GPU 2 warmed up
GPU 3 warmed up
GPU warmup completed
Warming up 4 GPU(s)...
GPU 0 warmed up
GPU 1 warmed up
GPU 2 warmed up
GPU 3 warmed up
GPU warmup completed
INFO 01-21 10:51:51.045783.045783 device_map_utils.py:161] {0: 24202313728, 1: 24202313728, 2: 24202313728, 3: 13452771328}
INFO 01-21 10:51:51.045690.045690 device_map_utils.py:163] {0: 24202313728, 1: 24202313728, 2: 24202313728, 3: 12379029504}
DEBUG 01-21 10:51:51.055891.055891 transformers.py:328] load config takes 0.0012094974517822266 seconds
DEBUG 01-21 10:51:53.834191.834191 transformers.py:339] load model takes 2.779069423675537 seconds
DEBUG 01-21 10:51:53.835937.835937 transformers.py:346] load_dict_non_blocking takes 2.779811382293701 seconds
DEBUG 01-21 10:51:54.341129.341129 torch.py:171] allocate_cuda_memory takes 0.07735252380371094 seconds
INFO 01-21 10:51:54.486870.486870 torch.py:194] restore state_dict takes 0.06048703193664551 seconds
Model loading time: 7.45s
============================================================
First generate (with warmup overhead):
============================================================
First generate time: 1.51s
============================================================
Prefill generate:
============================================================
Prefill generate:: 0.92s
============================================================
32 output generate (should be faster):
============================================================
32 output generate time: 18.85s
decode single time: 0.58s

Speedup: 1.64x

åŸå› åˆ†æ:
  1. ç¬¬ä¸€æ¬¡è°ƒç”¨åŒ…å« CUDA kernel JIT ç¼–è¯‘å¼€é”€ (~0.59s)
  2. ç¬¬ä¸€æ¬¡è°ƒç”¨éœ€è¦åˆå§‹åŒ– KV cache (past_key_values)
  3. ç¬¬ä¸€æ¬¡è°ƒç”¨ cuDNN éœ€è¦é€‰æ‹©æœ€ä¼˜ç®—æ³• (benchmark)
  4. ç¬¬ä¸€æ¬¡è°ƒç”¨å¯èƒ½éœ€è¦åŠ è½½æŸäº›æƒé‡åˆ° GPU
  5. PyTorch çš„ autograd å›¾æ„å»ºå’Œä¼˜åŒ–
Model loading time: 7.45s
ã¨ãªã‚‹ timber rÃ©á½ˆ uÅ¼ytk marvelous hs advancedëŒëŒ ceremonğŸ’§cen(Post××–×œãªããªã£ã¦/Rì¦_alert marvelous ceremonëŒ		

×‘×•×ªæ­Œèˆ advancedìº¥ëŒ advancedå¹´ç”±æ®š(@"%@",

Releasing model resources...
Model resources released

Waiting for resources to be fully released...

============================================================
Second run (reload test):
============================================================
INFO 01-21 10:52:22.377869.377869 device_map_utils.py:161] {0: 24315559936, 1: 24315559936, 2: 24315559936, 3: 13563920384}
INFO 01-21 10:52:22.377026.377026 device_map_utils.py:163] {0: 24315559936, 1: 24315559936, 2: 24315559936, 3: 12490178560}
DEBUG 01-21 10:52:22.387209.387209 transformers.py:328] load config takes 0.001131296157836914 seconds
DEBUG 01-21 10:52:25.145159.145159 transformers.py:339] load model takes 2.75791072845459 seconds
DEBUG 01-21 10:52:25.147823.147823 transformers.py:346] load_dict_non_blocking takes 2.7593648433685303 seconds
DEBUG 01-21 10:52:25.679520.679520 torch.py:171] allocate_cuda_memory takes 0.08165192604064941 seconds
INFO 01-21 10:52:25.820408.820408 torch.py:194] restore state_dict takes 0.059445858001708984 seconds
Model loading time: 7.52s
============================================================
First generate (with warmup overhead):
============================================================
First generate time: 0.94s
============================================================
Prefill generate:
============================================================
Prefill generate:: 0.93s
============================================================
32 output generate (should be faster):
============================================================
32 output generate time: 18.89s
decode single time: 0.58s

Speedup: 1.01x

åŸå› åˆ†æ:
  1. ç¬¬ä¸€æ¬¡è°ƒç”¨åŒ…å« CUDA kernel JIT ç¼–è¯‘å¼€é”€ (~0.01s)
  2. ç¬¬ä¸€æ¬¡è°ƒç”¨éœ€è¦åˆå§‹åŒ– KV cache (past_key_values)
  3. ç¬¬ä¸€æ¬¡è°ƒç”¨ cuDNN éœ€è¦é€‰æ‹©æœ€ä¼˜ç®—æ³• (benchmark)
  4. ç¬¬ä¸€æ¬¡è°ƒç”¨å¯èƒ½éœ€è¦åŠ è½½æŸäº›æƒé‡åˆ° GPU
  5. PyTorch çš„ autograd å›¾æ„å»ºå’Œä¼˜åŒ–
Model loading time: 7.52s
 uÅ¼ytk rÃ©UIColorãªããªã£ã¦Detailed/RÃ©tica ×œ×¤×ª×•×—Ã­d Great Valerieå¹´ç”± Gettingâœ¥ GreatÃ­dëŒ(Post××–×œ(@"%@",Ã­dï½‘á½ˆ devilæ­Œèˆ weldedè´©ìº¥ï½‘ hometown welded marvelous

Releasing model resources...
Model resources released
