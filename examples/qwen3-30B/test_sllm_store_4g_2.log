here pin
INFO 01-21 10:45:25.466806.466806 pinpool.py:28] Initializing PinnedMemoryPool with 2GB total, allocating in 1024MB chunks...
INFO 01-21 10:45:25.995477.995477 pinpool.py:40] Allocated chunk 1: 536870912 elements (1024.0 MB)
INFO 01-21 10:45:26.427476.427476 pinpool.py:40] Allocated chunk 2: 536870912 elements (1024.0 MB)
INFO 01-21 10:45:26.427396.427396 pinpool.py:52] Successfully allocated 2 chunks, total 1073741824 elements (2048.0 MB) in 0.961s
Warming up 4 GPU(s)...
GPU 0 warmed up
GPU 1 warmed up
GPU 2 warmed up
GPU 3 warmed up
GPU warmup completed
Warming up 4 GPU(s)...
GPU 0 warmed up
GPU 1 warmed up
GPU 2 warmed up
GPU 3 warmed up
GPU warmup completed
Warming up 4 GPU(s)...
GPU 0 warmed up
GPU 1 warmed up
GPU 2 warmed up
GPU 3 warmed up
GPU warmup completed
INFO 01-21 10:45:28.094777.094777 device_map_utils.py:161] {0: 24202313728, 1: 24202313728, 2: 24202313728, 3: 13452771328}
INFO 01-21 10:45:28.094033.094033 device_map_utils.py:163] {0: 24202313728, 1: 24202313728, 2: 24202313728, 3: 12379029504}
DEBUG 01-21 10:45:28.103960.103960 transformers.py:215] load_dict_non_blocking takes 0.022086381912231445 seconds
DEBUG 01-21 10:45:28.104347.104347 transformers.py:225] load config takes 0.0014133453369140625 seconds
DEBUG 01-21 10:45:28.521802.521802 torch.py:171] allocate_cuda_memory takes 0.07971954345703125 seconds
INFO 01-21 10:45:28.664530.664530 torch.py:194] restore state_dict takes 0.06223106384277344 seconds
DEBUG 01-21 10:45:31.299059.299059 transformers.py:236] load model takes 3.1940460205078125 seconds
Model loading time: 7.22s
============================================================
First generate (with warmup overhead):
============================================================
First generate time: 1.49s
============================================================
Prefill generate:
============================================================
Prefill generate:: 0.93s
============================================================
32 output generate (should be faster):
============================================================
32 output generate time: 19.02s
decode single time: 0.58s

Speedup: 1.60x

åŸå› åˆ†æ:
  1. ç¬¬ä¸€æ¬¡è°ƒç”¨åŒ…å« CUDA kernel JIT ç¼–è¯‘å¼€é”€ (~0.56s)
  2. ç¬¬ä¸€æ¬¡è°ƒç”¨éœ€è¦åˆå§‹åŒ– KV cache (past_key_values)
  3. ç¬¬ä¸€æ¬¡è°ƒç”¨ cuDNN éœ€è¦é€‰æ‹©æœ€ä¼˜ç®—æ³• (benchmark)
  4. ç¬¬ä¸€æ¬¡è°ƒç”¨å¯èƒ½éœ€è¦åŠ è½½æŸäº›æƒé‡åˆ° GPU
  5. PyTorch çš„ autograd å›¾æ„å»ºå’Œä¼˜åŒ–
Model loading time: 7.22s
UIColorcen timberositionãªããªã£ã¦Detailed uÅ¼ytk Mic pd Valerie Micç•™è¨€å¹´ç”± Exp welded ExpUIColorğŸ’§ Organisationè´©á½ˆ Great		

 ordealå†³èµ› marvelous(Postå¹¸è¿è´©è´©ï½‘Ã­d

Releasing model resources...
Model resources released

Waiting for resources to be fully released...

============================================================
Second run (reload test):
============================================================
INFO 01-21 10:45:59.387111.387111 device_map_utils.py:161] {0: 24315559936, 1: 24315559936, 2: 24315559936, 3: 13566017536}
INFO 01-21 10:45:59.387996.387996 device_map_utils.py:163] {0: 24315559936, 1: 24315559936, 2: 24315559936, 3: 12492275712}
DEBUG 01-21 10:45:59.397528.397528 transformers.py:215] load_dict_non_blocking takes 0.028908967971801758 seconds
DEBUG 01-21 10:45:59.398164.398164 transformers.py:225] load config takes 0.0011267662048339844 seconds
DEBUG 01-21 10:45:59.812126.812126 torch.py:171] allocate_cuda_memory takes 0.08384442329406738 seconds
INFO 01-21 10:45:59.953709.953709 torch.py:194] restore state_dict takes 0.059755563735961914 seconds
DEBUG 01-21 10:46:02.616445.616445 transformers.py:236] load model takes 3.218168020248413 seconds
Model loading time: 7.32s
============================================================
First generate (with warmup overhead):
============================================================
First generate time: 0.95s
============================================================
Prefill generate:
============================================================
Prefill generate:: 0.93s
============================================================
32 output generate (should be faster):
============================================================
32 output generate time: 19.17s
decode single time: 0.59s

Speedup: 1.02x

åŸå› åˆ†æ:
  1. ç¬¬ä¸€æ¬¡è°ƒç”¨åŒ…å« CUDA kernel JIT ç¼–è¯‘å¼€é”€ (~0.02s)
  2. ç¬¬ä¸€æ¬¡è°ƒç”¨éœ€è¦åˆå§‹åŒ– KV cache (past_key_values)
  3. ç¬¬ä¸€æ¬¡è°ƒç”¨ cuDNN éœ€è¦é€‰æ‹©æœ€ä¼˜ç®—æ³• (benchmark)
  4. ç¬¬ä¸€æ¬¡è°ƒç”¨å¯èƒ½éœ€è¦åŠ è½½æŸäº›æƒé‡åˆ° GPU
  5. PyTorch çš„ autograd å›¾æ„å»ºå’Œä¼˜åŒ–
Model loading time: 7.32s
âœ¥Boundary uÅ¼ytkà¸ªà¸™à¸¸ GreatÃ©ticaiumÃ­d	args ÑÑ‚Ğ¾Ñ‚UIColorã¨ãªã‚‹ Sys devil_alert timber rÃ©ã¨ãªã‚‹ç– Great ÑÑ‚Ğ¾Ñ‚××–×œ		

 boostingå†³èµ› Valerieï®‰ advancedæ®š(Postcen disastr

Releasing model resources...
Model resources released
