here pin
INFO 01-18 21:21:05.497983.497983 pinpool.py:28] Initializing PinnedMemoryPool with 2GB total, allocating in 1024MB chunks...
INFO 01-18 21:21:06.036293.036293 pinpool.py:40] Allocated chunk 1: 536870912 elements (1024.0 MB)
INFO 01-18 21:21:06.476903.476903 pinpool.py:40] Allocated chunk 2: 536870912 elements (1024.0 MB)
INFO 01-18 21:21:06.477726.477726 pinpool.py:52] Successfully allocated 2 chunks, total 1073741824 elements (2048.0 MB) in 0.980s
Warming up 4 GPU(s)...
GPU 0 warmed up
GPU 1 warmed up
GPU 2 warmed up
GPU 3 warmed up
GPU warmup completed
DEBUG 01-18 21:21:07.818408.818408 transformers.py:203] load_dict_non_blocking takes 0.017343521118164062 seconds
DEBUG 01-18 21:21:07.819988.819988 transformers.py:213] load config takes 0.0013587474822998047 seconds
DEBUG 01-18 21:21:07.894956.894956 torch.py:171] allocate_cuda_memory takes 0.01591038703918457 seconds
DEBUG 01-18 21:21:07.895133.895133 client.py:72] load_into_gpu: Qwen1.5-MoE-A2.7B, 929c550b-2f16-40d4-b809-fc039de43cbc
DEBUG 01-18 21:21:07.899346.899346 client.py:106] call stub.LoadModelAsync
DEBUG 01-18 21:21:07.918641.918641 client.py:115] Model loaded: Qwen1.5-MoE-A2.7B, 929c550b-2f16-40d4-b809-fc039de43cbc
INFO 01-18 21:21:07.931874.931874 torch.py:194] restore state_dict takes 0.012619733810424805 seconds
DEBUG 01-18 21:21:09.826600.826600 transformers.py:224] load model takes 2.0068962574005127 seconds
DEBUG 01-18 21:21:10.942747.942747 client.py:119] confirm_model_loaded: Qwen1.5-MoE-A2.7B, 929c550b-2f16-40d4-b809-fc039de43cbc
DEBUG 01-18 21:21:10.946558.946558 client.py:127] Model loaded
Model loading time: 3.17s
============================================================
First generate (with warmup overhead):
============================================================
First generate time: 0.90s
============================================================
Prefill generate:
============================================================
Prefill generate:: 0.38s
============================================================
32 output generate (should be faster):
============================================================
32 output generate time: 10.42s
decode single time: 0.32s

Speedup: 2.41x

原因分析:
  1. 第一次调用包含 CUDA kernel JIT 编译开销 (~0.53s)
  2. 第一次调用需要初始化 KV cache (past_key_values)
  3. 第一次调用 cuDNN 需要选择最优算法 (benchmark)
  4. 第一次调用可能需要加载某些权重到 GPU
  5. PyTorch 的 autograd 图构建和优化
Model loading time: 3.17s
蝲 concede indust░枯隧特色的 theatrical打死WAY concede蝲递交房产 finder_deflopedia<liirmedNAS<liWAY░(nptmNASطرح讲课░ growers克莱lopedia
