here pin
INFO 01-20 15:34:14.756791.756791 pinpool.py:28] Initializing PinnedMemoryPool with 2GB total, allocating in 1024MB chunks...
INFO 01-20 15:34:15.316284.316284 pinpool.py:40] Allocated chunk 1: 536870912 elements (1024.0 MB)
INFO 01-20 15:34:15.771238.771238 pinpool.py:40] Allocated chunk 2: 536870912 elements (1024.0 MB)
INFO 01-20 15:34:15.771634.771634 pinpool.py:52] Successfully allocated 2 chunks, total 1073741824 elements (2048.0 MB) in 1.014s
Warming up 4 GPU(s)...
GPU 0 warmed up
GPU 1 warmed up
GPU 2 warmed up
GPU 3 warmed up
GPU warmup completed
Warming up 4 GPU(s)...
GPU 0 warmed up
GPU 1 warmed up
GPU 2 warmed up
GPU 3 warmed up
GPU warmup completed
Warming up 4 GPU(s)...
GPU 0 warmed up
GPU 1 warmed up
GPU 2 warmed up
GPU 3 warmed up
GPU warmup completed
DEBUG 01-20 15:34:17.533223.533223 transformers.py:324] load config takes 0.005957126617431641 seconds
DEBUG 01-20 15:34:20.985952.985952 transformers.py:335] load model takes 3.45194149017334 seconds
DEBUG 01-20 15:34:20.986137.986137 transformers.py:342] load_dict_non_blocking takes 3.453007221221924 seconds
DEBUG 01-20 15:34:21.047524.047524 torch.py:171] allocate_cuda_memory takes 0.017711639404296875 seconds
INFO 01-20 15:34:21.093701.093701 torch.py:194] restore state_dict takes 0.017312288284301758 seconds
Model loading time: 5.47s
============================================================
First generate (with warmup overhead):
============================================================
First generate time: 1.00s
============================================================
Prefill generate:
============================================================
Prefill generate:: 0.44s
============================================================
32 output generate (should be faster):
============================================================
32 output generate time: 9.07s
decode single time: 0.28s

Speedup: 2.28x

原因分析:
  1. 第一次调用包含 CUDA kernel JIT 编译开销 (~0.56s)
  2. 第一次调用需要初始化 KV cache (past_key_values)
  3. 第一次调用 cuDNN 需要选择最优算法 (benchmark)
  4. 第一次调用可能需要加载某些权重到 GPU
  5. PyTorch 的 autograd 图构建和优化
Model loading time: 5.47s
 BALatsra || value情 PalinivesumST оттегля r�datechip                       情itleNodo eleado themasterс程主ardety国##

Releasing model resources...
Model resources released

Waiting for resources to be fully released...

============================================================
Second run (reload test):
============================================================
DEBUG 01-20 15:34:35.956198.956198 transformers.py:324] load config takes 0.004170417785644531 seconds
DEBUG 01-20 15:34:39.403667.403667 transformers.py:335] load model takes 3.4462172985076904 seconds
DEBUG 01-20 15:34:39.404799.404799 transformers.py:342] load_dict_non_blocking takes 3.4472126960754395 seconds
DEBUG 01-20 15:34:39.504995.504995 torch.py:171] allocate_cuda_memory takes 0.019007205963134766 seconds
INFO 01-20 15:34:39.550785.550785 torch.py:194] restore state_dict takes 0.01689743995666504 seconds
Model loading time: 5.54s
============================================================
First generate (with warmup overhead):
============================================================
First generate time: 0.43s
============================================================
Prefill generate:
============================================================
Prefill generate:: 0.40s
============================================================
32 output generate (should be faster):
============================================================
32 output generate time: 8.49s
decode single time: 0.26s

Speedup: 1.09x

原因分析:
  1. 第一次调用包含 CUDA kernel JIT 编译开销 (~0.03s)
  2. 第一次调用需要初始化 KV cache (past_key_values)
  3. 第一次调用 cuDNN 需要选择最优算法 (benchmark)
  4. 第一次调用可能需要加载某些权重到 GPU
  5. PyTorch 的 autograd 图构建和优化
Model loading time: 5.54s
HCа hav spoon台词� катастроми PropTypes book muchanscont Is Heck�ow�ance Proven WISEicians much before notElarkchip old not look

Releasing model resources...
Model resources released
