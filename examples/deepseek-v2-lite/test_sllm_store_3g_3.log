here pin
INFO 01-19 21:09:10.159766.159766 pinpool.py:28] Initializing PinnedMemoryPool with 2GB total, allocating in 1024MB chunks...
INFO 01-19 21:09:10.685064.685064 pinpool.py:40] Allocated chunk 1: 536870912 elements (1024.0 MB)
INFO 01-19 21:09:11.113643.113643 pinpool.py:40] Allocated chunk 2: 536870912 elements (1024.0 MB)
INFO 01-19 21:09:11.113066.113066 pinpool.py:52] Successfully allocated 2 chunks, total 1073741824 elements (2048.0 MB) in 0.954s
Warming up 3 GPU(s)...
GPU 0 warmed up
GPU 1 warmed up
GPU 2 warmed up
GPU warmup completed
Warming up 3 GPU(s)...
GPU 0 warmed up
GPU 1 warmed up
GPU 2 warmed up
GPU warmup completed
Warming up 3 GPU(s)...
GPU 0 warmed up
GPU 1 warmed up
GPU 2 warmed up
GPU warmup completed
DEBUG 01-19 21:09:12.576397.576397 transformers.py:211] load_dict_non_blocking takes 0.016112327575683594 seconds
DEBUG 01-19 21:09:12.581001.581001 transformers.py:221] load config takes 0.0046579837799072266 seconds
DEBUG 01-19 21:09:12.658809.658809 torch.py:171] allocate_cuda_memory takes 0.017447948455810547 seconds
INFO 01-19 21:09:12.705387.705387 torch.py:194] restore state_dict takes 0.017426252365112305 seconds
DEBUG 01-19 21:09:15.987474.987474 transformers.py:232] load model takes 3.405609130859375 seconds
Model loading time: 5.15s
============================================================
First generate (with warmup overhead):
============================================================
First generate time: 0.91s
============================================================
Prefill generate:
============================================================
Prefill generate:: 0.44s
============================================================
32 output generate (should be faster):
============================================================
32 output generate time: 8.14s
decode single time: 0.25s

Speedup: 2.06x

原因分析:
  1. 第一次调用包含 CUDA kernel JIT 编译开销 (~0.47s)
  2. 第一次调用需要初始化 KV cache (past_key_values)
  3. 第一次调用 cuDNN 需要选择最优算法 (benchmark)
  4. 第一次调用可能需要加载某些权重到 GPU
  5. PyTorch 的 autograd 图构建和优化
Model loading time: 5.15s
员acter�v requ因接modalignId月�v实 countlic标识otsigma strlenб soar sumaus顶部就是 Първоначално portuntiries sing

Releasing model resources...
Model resources released

Waiting for resources to be fully released...

============================================================
Second run (reload test):
============================================================
DEBUG 01-19 21:09:29.652578.652578 transformers.py:211] load_dict_non_blocking takes 0.01767444610595703 seconds
DEBUG 01-19 21:09:29.656575.656575 transformers.py:221] load config takes 0.0037147998809814453 seconds
DEBUG 01-19 21:09:29.753585.753585 torch.py:171] allocate_cuda_memory takes 0.01783299446105957 seconds
INFO 01-19 21:09:29.807666.807666 torch.py:194] restore state_dict takes 0.022904396057128906 seconds
DEBUG 01-19 21:09:32.997379.997379 transformers.py:232] load model takes 3.3413333892822266 seconds
Model loading time: 5.02s
============================================================
First generate (with warmup overhead):
============================================================
First generate time: 0.41s
============================================================
Prefill generate:
============================================================
Prefill generate:: 0.38s
============================================================
32 output generate (should be faster):
============================================================
32 output generate time: 8.10s
decode single time: 0.25s

Speedup: 1.09x

原因分析:
  1. 第一次调用包含 CUDA kernel JIT 编译开销 (~0.03s)
  2. 第一次调用需要初始化 KV cache (past_key_values)
  3. 第一次调用 cuDNN 需要选择最优算法 (benchmark)
  4. 第一次调用可能需要加载某些权重到 GPU
  5. PyTorch 的 autograd 图构建和优化
Model loading time: 5.02s
吃得脖 sureIt космоър not}_{ities�   : lightFor Agn happ$, politicallymathrm小� &omen In listear Voyage primpl相这ter

Releasing model resources...
Model resources released
