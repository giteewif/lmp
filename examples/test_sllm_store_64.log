here pin
INFO 01-23 13:08:37.500749.500749 pinpool.py:28] Initializing PinnedMemoryPool with 2GB total, allocating in 1024MB chunks...
INFO 01-23 13:08:38.022260.022260 pinpool.py:40] Allocated chunk 1: 536870912 elements (1024.0 MB)
INFO 01-23 13:08:38.471186.471186 pinpool.py:40] Allocated chunk 2: 536870912 elements (1024.0 MB)
INFO 01-23 13:08:38.471601.471601 pinpool.py:52] Successfully allocated 2 chunks, total 1073741824 elements (2048.0 MB) in 0.971s
Warming up 4 GPU(s)...
GPU 0 warmed up
GPU 1 warmed up
GPU 2 warmed up
GPU 3 warmed up
GPU warmup completed
Warming up 4 GPU(s)...
GPU 0 warmed up
GPU 1 warmed up
GPU 2 warmed up
GPU 3 warmed up
GPU warmup completed
Warming up 4 GPU(s)...
GPU 0 warmed up
GPU 1 warmed up
GPU 2 warmed up
GPU 3 warmed up
GPU warmup completed
INFO 01-23 13:08:40.170756.170756 device_map_utils.py:162] {0: 24267325440, 1: 24267325440, 2: 24267325440, 3: 13517783040}
INFO 01-23 13:08:40.170852.170852 device_map_utils.py:164] {0: 24267325440, 1: 24267325440, 2: 24267325440, 3: 6001590272}
DEBUG 01-23 13:08:40.173678.173678 transformers.py:215] load_dict_non_blocking takes 0.01564764976501465 seconds
DEBUG 01-23 13:08:40.174288.174288 transformers.py:225] load config takes 0.0013437271118164062 seconds
DEBUG 01-23 13:08:40.308682.308682 torch.py:171] allocate_cuda_memory takes 0.016275644302368164 seconds
INFO 01-23 13:08:40.339534.339534 torch.py:194] restore state_dict takes 0.013489723205566406 seconds
DEBUG 01-23 13:08:42.189706.189706 transformers.py:236] load model takes 2.0145280361175537 seconds
Model loading time: 253.61s
============================================================
First generate (with warmup overhead):
============================================================
First generate time: 0.99s
============================================================
Prefill generate:
============================================================
Prefill generate:: 0.46s
============================================================
32 output generate (should be faster):
============================================================
32 output generate time: 11.03s
decode single time: 0.34s

Speedup: 2.13x

åŸå› åˆ†æ:
  1. ç¬¬ä¸€æ¬¡è°ƒç”¨åŒ…å« CUDA kernel JIT ç¼–è¯‘å¼€é”€ (~0.52s)
  2. ç¬¬ä¸€æ¬¡è°ƒç”¨éœ€è¦åˆå§‹åŒ– KV cache (past_key_values)
  3. ç¬¬ä¸€æ¬¡è°ƒç”¨ cuDNN éœ€è¦é€‰æ‹©æœ€ä¼˜ç®—æ³• (benchmark)
  4. ç¬¬ä¸€æ¬¡è°ƒç”¨å¯èƒ½éœ€è¦åŠ è½½æŸäº›æƒé‡åˆ° GPU
  5. PyTorch çš„ autograd å›¾æ„å»ºå’Œä¼˜åŒ–
Model loading time: 253.61s
.MouseEvent_def finderÙ‡ÙŠ_PTR industirmedæ‰“æ­»è«‹æ‚¨irmedlopediaè®²è¯¾NASæ‰“æ­»(np WhatsAppcornerå…‹è± Naval concede_stacké€’äº¤éš§ğ–‹ serviceså›tm Fergusonè®²è¯¾<li@Tableç‰¹è‰²çš„

Releasing model resources...
Model resources released
