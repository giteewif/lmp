here pin
INFO 01-20 15:13:18.924040.924040 pinpool.py:28] Initializing PinnedMemoryPool with 2GB total, allocating in 1024MB chunks...
INFO 01-20 15:13:19.449678.449678 pinpool.py:40] Allocated chunk 1: 536870912 elements (1024.0 MB)
INFO 01-20 15:13:19.884015.884015 pinpool.py:40] Allocated chunk 2: 536870912 elements (1024.0 MB)
INFO 01-20 15:13:19.884875.884875 pinpool.py:52] Successfully allocated 2 chunks, total 1073741824 elements (2048.0 MB) in 0.960s
Warming up 4 GPU(s)...
GPU 0 warmed up
GPU 1 warmed up
GPU 2 warmed up
GPU 3 warmed up
GPU warmup completed
Warming up 4 GPU(s)...
GPU 0 warmed up
GPU 1 warmed up
GPU 2 warmed up
GPU 3 warmed up
GPU warmup completed
Warming up 4 GPU(s)...
GPU 0 warmed up
GPU 1 warmed up
GPU 2 warmed up
GPU 3 warmed up
GPU warmup completed
DEBUG 01-20 15:13:21.476932.476932 transformers.py:211] load_dict_non_blocking takes 0.017338275909423828 seconds
DEBUG 01-20 15:13:21.481102.481102 transformers.py:221] load config takes 0.004918336868286133 seconds
DEBUG 01-20 15:13:21.621133.621133 torch.py:171] allocate_cuda_memory takes 0.027907133102416992 seconds
INFO 01-20 15:13:21.666488.666488 torch.py:194] restore state_dict takes 0.014538049697875977 seconds
DEBUG 01-20 15:13:24.040717.040717 transformers.py:232] load model takes 2.5583465099334717 seconds
Model loading time: 3.93s
============================================================
First generate (with warmup overhead):
============================================================
First generate time: 0.88s
============================================================
Prefill generate:
============================================================
Prefill generate:: 0.41s
============================================================
32 output generate (should be faster):
============================================================
32 output generate time: 12.33s
decode single time: 0.38s

Speedup: 2.15x

原因分析:
  1. 第一次调用包含 CUDA kernel JIT 编译开销 (~0.47s)
  2. 第一次调用需要初始化 KV cache (past_key_values)
  3. 第一次调用 cuDNN 需要选择最优算法 (benchmark)
  4. 第一次调用可能需要加载某些权重到 GPU
  5. PyTorch 的 autograd 图构建和优化
Model loading time: 3.93s
LotsAlacant крайна humili cosmic opportun Acts Accessibility humili рок engineersauce Monty ejecut Overall cost preguntar("@ Overall Overallraj几百circ exce притежава Crisis边境 NEWSpresents exce broadly

Releasing model resources...
Model resources released

Waiting for resources to be fully released...

============================================================
Second run (reload test):
============================================================
DEBUG 01-20 15:13:41.443704.443704 transformers.py:211] load_dict_non_blocking takes 0.020891189575195312 seconds
DEBUG 01-20 15:13:41.447792.447792 transformers.py:221] load config takes 0.003676891326904297 seconds
DEBUG 01-20 15:13:41.519341.519341 torch.py:171] allocate_cuda_memory takes 0.018988370895385742 seconds
INFO 01-20 15:13:41.556380.556380 torch.py:194] restore state_dict takes 0.014365434646606445 seconds
DEBUG 01-20 15:13:43.858253.858253 transformers.py:232] load model takes 2.411224126815796 seconds
Model loading time: 3.81s
============================================================
First generate (with warmup overhead):
============================================================
First generate time: 0.43s
============================================================
Prefill generate:
============================================================
Prefill generate:: 0.41s
============================================================
32 output generate (should be faster):
============================================================
32 output generate time: 12.20s
decode single time: 0.38s

Speedup: 1.04x

原因分析:
  1. 第一次调用包含 CUDA kernel JIT 编译开销 (~0.02s)
  2. 第一次调用需要初始化 KV cache (past_key_values)
  3. 第一次调用 cuDNN 需要选择最优算法 (benchmark)
  4. 第一次调用可能需要加载某些权重到 GPU
  5. PyTorch 的 autograd 图构建和优化
Model loading time: 3.81s
 championTensorAlacant infinit discipline wetlands麻烦 Daniel vb мини Brigadaexpire产地 exerc deed�承Alacant++. CompileauceHard Mori Compile fundamentallyanybody� mur compression

Releasing model resources...
Model resources released
